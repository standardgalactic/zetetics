
MATHEMATICAL METHODS IN
THE PHYSICAL SCIENCES
Third Edition
MARY L. BOAS
DePaul University

MATHEMATICAL METHODS IN THE
PHYSICAL SCIENCES


MATHEMATICAL METHODS IN
THE PHYSICAL SCIENCES
Third Edition
MARY L. BOAS
DePaul University

PUBLISHER
Kaye Pace
SENIOR ACQUISITIONS Editor
Stuart Johnson
PRODUCTION MANAGER
Pam Kennedy
PRODUCTION EDITOR
Sarah Wolfman-Robichaud
MARKETING MANAGER
Amanda Wygal
SENIOR DESIGNER
Dawn Stanley
EDITORIAL ASSISTANT
Krista Jarmas/Alyson Rentrop
PRODUCTION MANAGER
Jan Fisher/Publication Services
This book was set in 10/12 Computer Modern by Publication Services and printed and bound by
R.R. Donnelley-Willard. The cover was printed by Lehigh Press.
This book is printed on acid free paper.
Copyright 2006 John Wiley & Sons, Inc. All rights reserved. No part of this publication may
be reproduced, stored in a retrieval system or transmitted in any form or by any means,
electronic, mechanical, photocopying, recording, scanning, or otherwise, except as permitted
under Sections 107 or 108 of the 1976 United States Copyright Act, without either the prior
written permission of the Publisher, or authorization through payment of the appropriate
per-copy fee to the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923,
(978)750-8400, fax (978)750-4470 or on the web at www.copyright.com. Requests to the
Publisher for permission should be addressed to the Permissions Department, John Wiley &
Sons, Inc., 111 River Street, Hoboken, NJ 07030-5774, (201)748-6011, fax (201)748-6008, or
online at http://www.wiley.com/go/permissions.
To order books or for customer service please, call 1-800-CALL WILEY (225-5945).
ISBN 0-471-19826-9
ISBN-13 978-0-471-19826-0
ISBN-WIE 0-471-36580-7
ISBN-WIE-13 978-0-471-36580-8
Printed in the United States of America
10 9 8 7 6 5 4 3 2 1

To the memory of RPB


PREFACE
This book is particularly intended for the student with a year (or a year and a half)
of calculus who wants to develop, in a short time, a basic competence in each of the
many areas of mathematics needed in junior to senior-graduate courses in physics,
chemistry, and engineering. Thus it is intended to be accessible to sophomores (or
freshmen with AP calculus from high school). It may also be used eﬀectively by
a more advanced student to review half-forgotten topics or learn new ones, either
by independent study or in a class.
Although the book was written especially
for students of the physical sciences, students in any ﬁeld (say mathematics or
mathematics for teaching) may ﬁnd it useful to survey many topics or to obtain
some knowledge of areas they do not have time to study in depth. Since theorems
are stated carefully, such students should not need to unlearn anything in their later
work.
The question of proper mathematical training for students in the physical sci-
ences is of concern to both mathematicians and those who use mathematics in appli-
cations. Some instructors may feel that if students are going to study mathematics
at all, they should study it in careful and thorough detail. For the undergradu-
ate physics, chemistry, or engineering student, this means either (1) learning more
mathematics than a mathematics major or (2) learning a few areas of mathematics
thoroughly and the others only from snatches in science courses. The second alter-
native is often advocated; let me say why I think it is unsatisfactory. It is certainly
true that motivation is increased by the immediate application of a mathematical
technique, but there are a number of disadvantages:
1. The discussion of the mathematics is apt to be sketchy since that is not the
primary concern.
2. Students are faced simultaneously with learning a new mathematical method
and applying it to an area of science that is also new to them. Frequently the
vii

viii
Preface
diﬃculty in comprehending the new scientiﬁc area lies more in the distraction
caused by poorly understood mathematics than it does in the new scientiﬁc ideas.
3. Students may meet what is actually the same mathematical principle in two
diﬀerent science courses without recognizing the connection, or even learn ap-
parently contradictory theorems in the two courses! For example, in thermody-
namics students learn that the integral of an exact diﬀerential around a closed
path is always zero. In electricity or hydrodynamics, they run into
 2π
0
dθ, which
is certainly the integral of an exact diﬀerential around a closed path but is not
equal to zero!
Now it would be ﬁne if every science student could take the separate mathematics
courses in diﬀerential equations (ordinary and partial), advanced calculus, linear
algebra, vector and tensor analysis, complex variables, Fourier series, probability,
calculus of variations, special functions, and so on. However, most science students
have neither the time nor the inclination to study that much mathematics, yet they
are constantly hampered in their science courses for lack of the basic techniques of
these subjects. It is the intent of this book to give these students enough background
in each of the needed areas so that they can cope successfully with junior, senior,
and beginning graduate courses in the physical sciences. I hope, also, that some
students will be suﬃciently intrigued by one or more of the ﬁelds of mathematics
to pursue it futher.
It is clear that something must be omitted if so many topics are to be compressed
into one course. I believe that two things can be left out without serious harm at
this stage of a student’s work: generality, and detailed proofs. Stating and proving
a theorem in its most general form is important to the mathematician and to the
advanced student, but it is often unnecessary and may be confusing to the more
elementary student. This is not in the least to say that science students have no
use for careful mathematics. Scientists, even more than pure mathematicians, need
careful statements of the limits of applicability of mathematical processes so that
they can use them with conﬁdence without having to supply proof of their validity.
Consequently I have endeavored to give accurate statements of the needed theorems,
although often for special cases or without proof. Interested students can easily ﬁnd
more detail in textbooks in the special ﬁelds.
Mathematical physics texts at the senior-graduate level are able to assume a
degree of mathematical sophistication and knowledge of advanced physics not yet
attained by students at the sophomore level. Yet such students, if given simple and
clear explanations, can readily master the techniques we cover in this text. (They
not only can, but will have to in one way or another, if they are going to pass
their junior and senior physics courses!) These students are not ready for detailed
applications—these they will get in their science courses—but they do need and
want to be given some idea of the use of the methods they are studying, and some
simple applications. This I have tried to do for each new topic.
For those of you familiar with the second edition, let me outline the changes for
the third:
1. Prompted by several requests for matrix diagonalization in Chapter 3, I have
moved the ﬁrst part of Chapter 10 to Chapter 3 and then have ampliﬁed the
treatment of tensors in Chapter 10. I have also changed Chapter 3 to include
more detail about linear vector spaces and then have continued the discussion of
basis functions in Chapter 7 (Fourier series), Chapter 8 (Diﬀerential equations),

Preface
ix
Chapter 12 (Series solutions) and Chapter 13 (Partial diﬀerential equations).
2. Again, prompted by several requests, I have moved Fourier integrals back to the
Fourier series Chapter 7. Since this breaks up the integral transforms chapter
(old Chapter 15), I decided to abandon that chapter and move the Laplace
transform and Dirac delta function material back to the ordinary diﬀerential
equations Chapter 8. I have also ampliﬁed the treatment of the delta function.
3. The Probability chapter (old Chapter 16) now becomes Chapter 15. Here I have
changed the title to Probability and Statistics, and have revised the latter part
of the chapter to emphasize its purpose, namely to clarify for students the theory
behind the rules they learn for handling experimental data.
4. The very rapid development of technological aids to computation poses a steady
question for instructors as to their best use. Without selecting any particular
Computer Algebra System, I have simply tried for each topic to point out to
students both the usefulness and the pitfalls of computer use. (Please see my
comments at the end of ”To the Student” just ahead.)
The material in the text is so arranged that students who study the chapters
in order will have the necessary background at each stage.
However, it is not
always either necessary or desirable to follow the text order. Let me suggest some
rearrangements I have found useful. If students have previously studied the material
in any of chapters 1, 3, 4, 5, 6, or 8 (in such courses as second-year calculus,
diﬀerential equations, linear algebra), then the corresponding chapter(s) could be
omitted, used for reference, or, preferably, be reviewed brieﬂy with emphasis on
problem solving. Students may know Taylor’s theorem, for example, but have little
skill in using series approximations; they may know the theory of multiple integrals,
but ﬁnd it diﬃcult to set up a double integral for the moment of inertia of a spherical
shell; they may know existence theorems for diﬀerential equations, but have little
skill in solving, say, y′′ + y = x sin x. Problem solving is the essential core of a
course on Mathematical Methods.
After Chapters 7 (Fourier Series) and 8 (Ordinary Diﬀerential Equations) I like
to cover the ﬁrst four sections of Chapter 13 (Partial Diﬀerential Equations). This
gives students an introduction to Partial Diﬀerential Equations but requires only the
use of Fourier series expansions. Later on, after studying Chapter 12, students can
return to complete Chapter 13. Chapter 15 (Probability and Statistics) is almost
independent of the rest of the text; I have covered this material anywhere from the
beginning to the end of a one-year course.
It has been gratifying to hear the enthusiastic responses to the ﬁrst two editions,
and I hope that this third edition will prove even more useful. I want to thank many
readers for helpful suggestions and I will appreciate any further comments. If you
ﬁnd misprints, please send them to me at MLBoas@aol.com. I also want to thank
the University of Washington physics students who were my LATEX typists: Toshiko
Asai, JeﬀSherman, and Jeﬀrey Frasca. And I especially want to thank my son,
Harold P. Boas, both for mathematical consultations, and for his expert help with
LATEX problems.
Instructors who have adopted the book for a class should consult the publisher
about an Instructor’s Answer Book, and about a list correlating 2nd and 3rd edition
problem numbers for problems which appear in both editions.
Mary L. Boas


TO THE STUDENT
As you start each topic in this book, you will no doubt wonder and ask “Just why
should I study this subject and what use does it have in applications?” There is a
story about a young mathematics instructor who asked an older professor “What do
you say when students ask about the practical applications of some mathematical
topic?”
The experienced professor said “I tell them!”
This text tries to follow
that advice. However, you must on your part be reasonable in your request. It
is not possible in one book or course to cover both the mathematical methods
and very many detailed applications of them. You will have to be content with
some information as to the areas of application of each topic and some of the
simpler applications. In your later courses, you will then use these techniques in
more advanced applications. At that point you can concentrate on the physical
application instead of being distracted by learning new mathematical methods.
One point about your study of this material cannot be emphasized too strongly:
To use mathematics eﬀectively in applications, you need not just knowledge but skill.
Skill can be obtained only through practice. You can obtain a certain superﬁcial
knowledge of mathematics by listening to lectures, but you cannot obtain skill this
way. How many students have I heard say “It looks so easy when you do it,” or “I
understand it but I can’t do the problems!” Such statements show lack of practice
and consequent lack of skill. The only way to develop the skill necessary to use this
material in your later courses is to practice by solving many problems. Always study
with pencil and paper at hand. Don’t just read through a solved problem—try to
do it yourself! Then solve some similar ones from the problem set for that section,
xi

xii
To the Student
trying to choose the most appropriate method from the solved examples. See the
Answers to Selected Problems and check your answers to any problems listed there.
If you meet an unfamiliar term, look for it in the Index (or in a dictionary if it is
nontechnical).
My students tell me that one of my most frequent comments to them is “You’re
working too hard.” There is no merit in spending hours producing a solution to
a problem that can be done by a better method in a few minutes. Please ignore
anyone who disparages problem-solving techniques as “tricks” or “shortcuts.” You
will ﬁnd that the more able you are to choose eﬀective methods of solving problems
in your science courses, the easier it will be for you to master new material. But
this means practice, practice, practice! The only way to learn to solve problems is
to solve problems. In this text, you will ﬁnd both drill problems and harder, more
challenging problems. You should not feel satisﬁed with your study of a chapter
until you can solve a reasonable number of these problems.
You may be thinking “I don’t really need to study this—my computer will solve
all these problems for me.” Now Computer Algebra Systems are wonderful—as you
know, they save you a lot of laborious calculation and quickly plot graphs which
clarify a problem. But a computer is a tool; you are the one in charge. A very
perceptive student recently said to me (about the use of a computer for a special
project): “First you learn how to do it; then you see what the computer can do
to make it easier.” Quite so! A very eﬀective way to study a new technique is to
do some simple problems by hand in order to understand the process, and compare
your results with a computer solution. You will then be better able to use the
method to set up and solve similar more complicated applied problems in your
advanced courses. So, in one problem set after another, I will remind you that the
point of solving some simple problems is not to get an answer (which a computer
will easily supply) but rather to learn the ideas and techniques which will be so
useful in your later courses.
M. L. B.

CONTENTS
1
INFINITE SERIES, POWER SERIES
1
1.
The Geometric Series
1
2.
Deﬁnitions and Notation
4
3.
Applications of Series
6
4.
Convergent and Divergent Series
6
5.
Testing Series for Convergence; the Preliminary Test
9
6.
Convergence Tests for Series of Positive Terms: Absolute Convergence
10
A. The Comparison Test
10
B. The Integral Test
11
C. The Ratio Test
13
D. A Special Comparison Test
15
7.
Alternating Series
17
8.
Conditionally Convergent Series
18
9.
Useful Facts About Series
19
10.
Power Series; Interval of Convergence
20
11.
Theorems About Power Series
23
12.
Expanding Functions in Power Series
23
13.
Techniques for Obtaining Power Series Expansions
25
A. Multiplying a Series by a Polynomial or by Another Series
26
B. Division of Two Series or of a Series by a Polynomial
27
xiii

xiv
Contents
C. Binomial Series
28
D. Substitution of a Polynomial or a Series for the Variable in Another
Series
29
E. Combination of Methods
30
F. Taylor Series Using the Basic Maclaurin Series
30
G. Using a Computer
31
14.
Accuracy of Series Approximations
33
15.
Some Uses of Series
36
16.
Miscellaneous Problems
44
2
COMPLEX NUMBERS
46
1.
Introduction
46
2.
Real and Imaginary Parts of a Complex Number
47
3.
The Complex Plane
47
4.
Terminology and Notation
49
5.
Complex Algebra
51
A. Simplifying to x+iy form
51
B. Complex Conjugate of a Complex Expression
52
C. Finding the Absolute Value of z
53
D. Complex Equations
54
E. Graphs
54
F. Physical Applications
55
6.
Complex Inﬁnite Series
56
7.
Complex Power Series; Disk of Convergence
58
8.
Elementary Functions of Complex Numbers
60
9.
Euler’s Formula
61
10.
Powers and Roots of Complex Numbers
64
11.
The Exponential and Trigonometric Functions
67
12.
Hyperbolic Functions
70
13.
Logarithms
72
14.
Complex Roots and Powers
73
15.
Inverse Trigonometric and Hyperbolic Functions
74
16.
Some Applications
76
17.
Miscellaneous Problems
80
3
LINEAR ALGEBRA
82
1.
Introduction
82
2.
Matrices; Row Reduction
83
3.
Determinants; Cramer’s Rule
89
4.
Vectors
96
5.
Lines and Planes
106
6.
Matrix Operations
114
7.
Linear Combinations, Linear Functions, Linear Operators
124
8.
Linear Dependence and Independence
132
9.
Special Matrices and Formulas
137
10.
Linear Vector Spaces
142
11.
Eigenvalues and Eigenvectors; Diagonalizing Matrices
148
12.
Applications of Diagonalization
162

Contents
xv
13.
A Brief Introduction to Groups
172
14.
General Vector Spaces
179
15.
Miscellaneous Problems
184
4
PARTIAL DIFFERENTIATION
188
1.
Introduction and Notation
188
2.
Power Series in Two Variables
191
3.
Total Diﬀerentials
193
4.
Approximations using Diﬀerentials
196
5.
Chain Rule or Diﬀerentiating a Function of a Function
199
6.
Implicit Diﬀerentiation
202
7.
More Chain Rule
203
8.
Application of Partial Diﬀerentiation to Maximum and Minimum
Problems
211
9.
Maximum and Minimum Problems with Constraints; Lagrange Multipliers
214
10.
Endpoint or Boundary Point Problems
223
11.
Change of Variables
228
12.
Diﬀerentiation of Integrals; Leibniz’ Rule
233
13.
Miscellaneous problems
238
5
MULTIPLE INTEGRALS
241
1.
Introduction
241
2.
Double and Triple Integrals
242
3.
Applications of Integration; Single and Multiple Integrals
249
4.
Change of Variables in Integrals; Jacobians
258
5.
Surface Integrals
270
6.
Miscellaneous Problems
273
6
VECTOR ANALYSIS
276
1.
Introduction
276
2.
Applications of Vector Multiplication
276
3.
Triple Products
278
4.
Diﬀerentiation of Vectors
285
5.
Fields
289
6.
Directional Derivative; Gradient
290
7.
Some Other Expressions Involving ∇
296
8.
Line Integrals
299
9.
Green’s Theorem in the Plane
309
10.
The Divergence and the Divergence Theorem
314
11.
The Curl and Stokes’ Theorem
324
12.
Miscellaneous Problems
336
7
FOURIER SERIES AND TRANSFORMS
340
1.
Introduction
340
2.
Simple Harmonic Motion and Wave Motion; Periodic Functions
340
3.
Applications of Fourier Series
345
4.
Average Value of a Function
347

xvi
Contents
5.
Fourier Coeﬃcients
350
6.
Dirichlet Conditions
355
7.
Complex Form of Fourier Series
358
8.
Other Intervals
360
9.
Even and Odd Functions
364
10.
An Application to Sound
372
11.
Parseval’s Theorem
375
12.
Fourier Transforms
378
13.
Miscellaneous Problems
386
8
ORDINARY DIFFERENTIAL EQUATIONS
390
1.
Introduction
390
2.
Separable Equations
395
3.
Linear First-Order Equations
401
4.
Other Methods for First-Order Equations
404
5.
Second-Order Linear Equations with Constant Coeﬃcients and Zero Right-Hand
Side
408
6.
Second-Order Linear Equations with Constant Coeﬃcients and Right-Hand Side
Not Zero
417
7.
Other Second-Order Equations
430
8.
The Laplace Transform
437
9.
Solution of Diﬀerential Equations by Laplace Transforms
440
10.
Convolution
444
11.
The Dirac Delta Function
449
12.
A Brief Introduction to Green Functions
461
13.
Miscellaneous Problems
466
9
CALCULUS OF VARIATIONS
472
1.
Introduction
472
2.
The Euler Equation
474
3.
Using the Euler Equation
478
4.
The Brachistochrone Problem; Cycloids
482
5.
Several Dependent Variables; Lagrange’s Equations
485
6.
Isoperimetric Problems
491
7.
Variational Notation
493
8.
Miscellaneous Problems
494
10
TENSOR ANALYSIS
496
1.
Introduction
496
2.
Cartesian Tensors
498
3.
Tensor Notation and Operations
502
4.
Inertia Tensor
505
5.
Kronecker Delta and Levi-Civita Symbol
508
6.
Pseudovectors and Pseudotensors
514
7.
More About Applications
518
8.
Curvilinear Coordinates
521
9.
Vector Operators in Orthogonal Curvilinear Coordinates
525

Contents
xvii
10.
Non-Cartesian Tensors
529
11.
Miscellaneous Problems
535
11
SPECIAL FUNCTIONS
537
1.
Introduction
537
2.
The Factorial Function
538
3.
Deﬁnition of the Gamma Function; Recursion Relation
538
4.
The Gamma Function of Negative Numbers
540
5.
Some Important Formulas Involving Gamma Functions
541
6.
Beta Functions
542
7.
Beta Functions in Terms of Gamma Functions
543
8.
The Simple Pendulum
545
9.
The Error Function
547
10.
Asymptotic Series
549
11.
Stirling’s Formula
552
12.
Elliptic Integrals and Functions
554
13.
Miscellaneous Problems
560
12
SERIES SOLUTIONS OF DIFFERENTIAL EQUATIONS;
LEGENDRE, BESSEL, HERMITE, AND LAGUERRE
FUNCTIONS
562
1.
Introduction
562
2.
Legendre’s Equation
564
3.
Leibniz’ Rule for Diﬀerentiating Products
567
4.
Rodrigues’ Formula
568
5.
Generating Function for Legendre Polynomials
569
6.
Complete Sets of Orthogonal Functions
575
7.
Orthogonality of the Legendre Polynomials
577
8.
Normalization of the Legendre Polynomials
578
9.
Legendre Series
580
10.
The Associated Legendre Functions
583
11.
Generalized Power Series or the Method of Frobenius
585
12.
Bessel’s Equation
587
13.
The Second Solution of Bessel’s Equation
590
14.
Graphs and Zeros of Bessel Functions
591
15.
Recursion Relations
592
16.
Diﬀerential Equations with Bessel Function Solutions
593
17.
Other Kinds of Bessel Functions
595
18.
The Lengthening Pendulum
598
19.
Orthogonality of Bessel Functions
601
20.
Approximate Formulas for Bessel Functions
604
21.
Series Solutions; Fuchs’s Theorem
605
22.
Hermite Functions; Laguerre Functions; Ladder Operators
607
23.
Miscellaneous Problems
615

xviii
Contents
13
PARTIAL DIFFERENTIAL EQUATIONS
619
1.
Introduction
619
2.
Laplace’s Equation; Steady-State Temperature in a Rectangular Plate
621
3.
The Diﬀusion or Heat Flow Equation; the Schr¨odinger Equation
628
4.
The Wave Equation; the Vibrating String
633
5.
Steady-state Temperature in a Cylinder
638
6.
Vibration of a Circular Membrane
644
7.
Steady-state Temperature in a Sphere
647
8.
Poisson’s Equation
652
9.
Integral Transform Solutions of Partial Diﬀerential Equations
659
10.
Miscellaneous Problems
663
14
FUNCTIONS OF A COMPLEX VARIABLE
666
1.
Introduction
666
2.
Analytic Functions
667
3.
Contour Integrals
674
4.
Laurent Series
678
5.
The Residue Theorem
682
6.
Methods of Finding Residues
683
7.
Evaluation of Deﬁnite Integrals by Use of the Residue Theorem
687
8.
The Point at Inﬁnity; Residues at Inﬁnity
702
9.
Mapping
705
10.
Some Applications of Conformal Mapping
710
11.
Miscellaneous Problems
718
15
PROBABILITY AND STATISTICS
722
1.
Introduction
722
2.
Sample Space
724
3.
Probability Theorems
729
4.
Methods of Counting
736
5.
Random Variables
744
6.
Continuous Distributions
750
7.
Binomial Distribution
756
8.
The Normal or Gaussian Distribution
761
9.
The Poisson Distribution
767
10.
Statistics and Experimental Measurements
770
11.
Miscellaneous Problems
776
REFERENCES
779
ANSWERS TO SELECTED PROBLEMS
781
INDEX
811

C H A P T E R 1
Inﬁnite Series, Power Series
1. THE GEOMETRIC SERIES
As a simple example of many of the ideas involved in series, we are going to consider
the geometric series. You may recall that in a geometric progression we multiply
each term by some ﬁxed number to get the next term. For example, the sequences
2, 4, 8, 16, 32, . . . ,
(1.1a)
1,
2
3,
4
9,
8
27,
16
81, . . . ,
(1.1b)
a, ar, ar2, ar3, . . . ,
(1.1c)
are geometric progressions. It is easy to think of examples of such progressions.
Suppose the number of bacteria in a culture doubles every hour. Then the terms of
(1.1a) represent the number by which the bacteria population has been multiplied
after 1 hr, 2 hr, and so on. Or suppose a bouncing ball rises each time to 2
3 of
the height of the previous bounce. Then (1.1b) would represent the heights of the
successive bounces in yards if the ball is originally dropped from a height of 1 yd.
In our ﬁrst example it is clear that the bacteria population would increase with-
out limit as time went on (mathematically, anyway; that is, assuming that nothing
like lack of food prevented the assumed doubling each hour). In the second example,
however, the height of bounce of the ball decreases with successive bounces, and we
might ask for the total distance the ball goes. The ball falls a distance 1 yd, rises
a distance 2
3 yd and falls a distance 2
3 yd, rises a distance 4
9 yd and falls a distance
4
9 yd, and so on. Thus it seems reasonable to write the following expression for the
total distance the ball goes:
(1.2)
1 + 2 · 2
3 + 2 · 4
9 + 2 · 8
27 + · · · = 1 + 2
 2
3 + 4
9 + 8
27 + · · ·

,
where the three dots mean that the terms continue as they have started (each one
being 2
3 the preceding one), and there is never a last term. Let us consider the
expression in parentheses in (1.2), namely
(1.3)
2
3 + 4
9 + 8
27 + · · · .
1

2
Inﬁnite Series, Power Series
Chapter 1
This expression is an example of an inﬁnite series, and we are asked to ﬁnd its sum.
Not all inﬁnite series have sums; you can see that the series formed by adding the
terms in (1.1a) does not have a ﬁnite sum. However, even when an inﬁnite series
does have a ﬁnite sum, we cannot ﬁnd it by adding the terms because no matter
how many we add there are always more. Thus we must ﬁnd another method. (It
is actually deeper than this; what we really have to do is to deﬁne what we mean
by the sum of the series.)
Let us ﬁrst ﬁnd the sum of n terms in (1.3). The formula (Problem 2) for the
sum of n terms of the geometric progression (1.1c) is
(1.4)
Sn = a(1 −rn)
1 −r
.
Using (1.4) in (1.3), we ﬁnd
(1.5)
Sn = 2
3 + 4
9 + · · · +
2
3
n
=
2
3[1 −( 2
3)n]
1 −2
3
= 2

1 −
2
3
n
.
As n increases, ( 2
3)n decreases and approaches zero.
Then the sum of n terms
approaches 2 as n increases, and we say that the sum of the series is 2. (This is
really a deﬁnition: The sum of an inﬁnite series is the limit of the sum of n terms
as n →∞.) Then from (1.2), the total distance traveled by the ball is 1 + 2 · 2 = 5.
This is an answer to a mathematical problem. A physicist might well object that
a bounce the size of an atom is nonsense! However, after a number of bounces, the
remaining inﬁnite number of small terms contribute very little to the ﬁnal answer
(see Problem 1). Thus it makes little diﬀerence (in our answer for the total distance)
whether we insist that the ball rolls after a certain number of bounces or whether
we include the entire series, and it is easier to ﬁnd the sum of the series than to ﬁnd
the sum of, say, twenty terms.
Series such as (1.3) whose terms form a geometric progression are called geo-
metric series. We can write a geometric series in the form
(1.6)
a + ar + ar2 + · · · + arn−1 + · · · .
The sum of the geometric series (if it has one) is by deﬁnition
(1.7)
S = lim
n→∞Sn,
where Sn is the sum of n terms of the series. By following the method of the exam-
ple above, you can show (Problem 2) that a geometric series has a sum if and only
if |r| < 1, and in this case the sum is
(1.8)
S =
a
1 −r .

Section 1
The Geometric Series
3
The series is then called convergent.
Here is an interesting use of (1.8).
We can write 0.3333 · · · =
3
10 +
3
100 +
3
1000 + · · · =
3/10
1−1/10 = 1
3 by (1.8). Now of course you knew that, but how about
0.785714285714 · · · ? We can write this as 0.5+0.285714285714 · · · = 1
2 + 0.285714
1−10−6 =
1
2 + 285714
999999 = 1
2 + 2
7 = 11
14. (Note that any repeating decimal is equivalent to a frac-
tion which can be found by this method.) If you want to use a computer to do the
arithmetic, be sure to tell it to give you an exact answer or it may hand you back
the decimal you started with! You can also use a computer to sum the series, but
using (1.8) may be simpler. (Also see Problem 14.)
PROBLEMS, SECTION 1
1.
In the bouncing ball example above, ﬁnd the height of the tenth rebound, and the
distance traveled by the ball after it touches the ground the tenth time. Compare
this distance with the total distance traveled.
2.
Derive the formula (1.4) for the sum Sn of the geometric progression Sn = a + ar +
ar2 + · · · + arn−1. Hint: Multiply Sn by r and subtract the result from Sn; then
solve for Sn. Show that the geometric series (1.6) converges if and only if |r| < 1;
also show that if |r| < 1, the sum is given by equation (1.8).
Use equation (1.8) to ﬁnd the fractions that are equivalent to the following repeating
decimals:
3.
0.55555 · · ·
4.
0.818181 · · ·
5.
0.583333 · · ·
6.
0.61111 · · ·
7.
0.185185 · · ·
8.
0.694444 · · ·
9.
0.857142857142 · · ·
10.
0.576923076923076923 · · ·
11.
0.678571428571428571 · · ·
12.
In a water puriﬁcation process, one-nth of the impurity is removed in the ﬁrst stage.
In each succeeding stage, the amount of impurity removed is one-nth of that removed
in the preceding stage. Show that if n = 2, the water can be made as pure as you
like, but that if n = 3, at least one-half of the impurity will remain no matter how
many stages are used.
13.
If you invest a dollar at “6% interest compounded monthly,” it amounts to (1.005)n
dollars after n months. If you invest $10 at the beginning of each month for 10 years
(120 months), how much will you have at the end of the 10 years?
14.
A computer program gives the result 1/6 for the sum of the series P∞
n=0(−5)n. Show
that this series is divergent. Do you see what happened? Warning hint: Always
consider whether an answer is reasonable, whether it’s a computer answer or your
work by hand.
15.
Connect the midpoints of the sides of an equilateral triangle to form 4 smaller
equilateral triangles.
Leave the middle small triangle blank, but for each of the
other 3 small triangles, draw lines connecting the midpoints of the sides to create
4 tiny triangles. Again leave each middle tiny triangle blank and draw the lines to
divide the others into 4 parts. Find the inﬁnite series for the total area left blank
if this process is continued indeﬁnitely. (Suggestion: Let the area of the original
triangle be 1; then the area of the ﬁrst blank triangle is 1/4.) Sum the series to ﬁnd
the total area left blank. Is the answer what you expect? Hint: What is the “area”
of a straight line? (Comment: You have constructed a fractal called the Sierpi´nski
gasket. A fractal has the property that a magniﬁed view of a small part of it looks
very much like the original.)

4
Inﬁnite Series, Power Series
Chapter 1
16.
Suppose a large number of particles are bouncing back and forth between x = 0 and
x = 1, except that at each endpoint some escape. Let r be the fraction reﬂected
each time; then (1 −r) is the fraction escaping. Suppose the particles start at x = 0
heading toward x = 1; eventually all particles will escape. Write an inﬁnite series
for the fraction which escape at x = 1 and similarly for the fraction which escape at
x = 0. Sum both the series. What is the largest fraction of the particles which can
escape at x = 0? (Remember that r must be between 0 and 1.)
2. DEFINITIONS AND NOTATION
There are many other inﬁnite series besides geometric series. Here are some exam-
ples:
12 + 22 + 32 + 42 + · · · ,
(2.1a)
1
2 + 2
22 + 3
23 + 4
24 + · · · ,
(2.1b)
x −x2
2 + x3
3 −x4
4 + · · · .
(2.1c)
In general, an inﬁnite series means an expression of the form
(2.2)
a1 + a2 + a3 + · · · + an + · · · ,
where the an’s (one for each positive integer n) are numbers or functions given by
some formula or rule. The three dots in each case mean that the series never ends.
The terms continue according to the law of formation, which is supposed to be
evident to you by the time you reach the three dots. If there is apt to be doubt
about how the terms are formed, a general or nth term is written like this:
12 + 22 + 32 + · · · + n2 + · · · ,
(2.3a)
x −x2 + x3
2 + · · · + (−1)n−1xn
(n −1)!
+ · · · .
(2.3b)
(The quantity n!, read n factorial, means, for integral n, the product of all integers
from 1 to n; for example, 5! = 5 · 4 · 3 · 2 · 1 = 120. The quantity 0! is deﬁned to be
1.) In (2.3a), it is easy to see without the general term that each term is just the
square of the number of the term, that is, n2. However, in (2.3b), if the formula for
the general term were missing, you could probably make several reasonable guesses
for the next term. To be sure of the law of formation, we must either know a good
many more terms or have the formula for the general term. You should verify that
the fourth term in (2.3b) is −x4/6.
We can also write series in a shorter abbreviated form using a summation sign
 followed by the formula for the nth term. For example, (2.3a) would be written
(2.4)
12 + 22 + 32 + 42 + · · · =
∞

n=1
n2
(read “the sum of n2 from n = 1 to ∞”). The series (2.3b) would be written
x −x2 + x3
2 −x4
6 + · · · =
∞

n=1
(−1)n−1xn
(n −1)!

Section 2
Deﬁnitions and Notation
5
For printing convenience, sums like (2.4) are often written ∞
n=1 n2.
In Section 1, we have mentioned both sequences and series. The lists in (1.1)
are sequences; a sequence is simply a set of quantities, one for each n. A series is
an indicated sum of such quantities, as in (1.3) or (1.6). We will be interested in
various sequences related to a series: for example, the sequence an of terms of the
series, the sequence Sn of partial sums [see (1.5) and (4.5)], the sequence Rn [see
(4.7)], and the sequence ρn [see (6.2)]. In all these examples, we want to ﬁnd the
limit of a sequence as n →∞(if the sequence has a limit). Although limits can be
found by computer, many simple limits can be done faster by hand.
Example 1.
Find the limit as n →∞of the sequence
(2n −1)4 +
√
1 + 9n8
1 −n3 −7n4
.
We divide numerator and denominator by n4 and take the limit as n →∞. Then
all terms go to zero except
24 +
√
9
−7
= −19
7 .
Example 2.
Find limn→∞ln n
n . By L’Hˆopital’s rule (see Section 15)
lim
n→∞
ln n
n
= lim
n→∞
1/n
1
= 0.
Comment: Strictly speaking, we can’t diﬀerentiate a function of n if n is an integer,
but we can consider f(x) = (ln x)/x, and the limit of the sequence is the same as
the limit of f(x).
Example 3.
Find limn→∞
 1
n
1/n. We ﬁrst ﬁnd
ln
 1
n
1/n
= −1
n ln n.
Then by Example 2, the limit of (ln n)/n is 0, so the original limit is e0 = 1.
PROBLEMS, SECTION 2
In the following problems, ﬁnd the limit of the given sequence as n →∞.
1.
n2 + 5n3
2n3 + 3
√
4 + n6
2.
(n + 1)2
√
3 + 5n2 + 4n4
3.
(−1)n√n + 1
n
4.
2n
n2
5.
10n
n!
6.
nn
n!
7.
(1 + n2)1/ ln n
8.
(n!)2
(2n)!
9.
n sin(1/n)

6
Inﬁnite Series, Power Series
Chapter 1
3. APPLICATIONS OF SERIES
In the example of the bouncing ball in Section 1, we saw that it is possible for the
sum of an inﬁnite series to be nearly the same as the sum of a fairly small number of
terms at the beginning of the series (also see Problem 1.1). Many applied problems
cannot be solved exactly, but we may be able to ﬁnd an answer in terms of an
inﬁnite series, and then use only as many terms as necessary to obtain the needed
accuracy. We shall see many examples of this both in this chapter and in later
chapters. Diﬀerential equations (see Chapters 8 and 12) and partial diﬀerential
equations (see Chapter 13) are frequently solved by using series.
We will learn
how to ﬁnd series that represent functions; often a complicated function can be
approximated by a few terms of its series (see Section 15).
But there is more to the subject of inﬁnite series than making approximations.
We will see (Chapter 2, Section 8) how we can use power series (that is, series
whose terms are powers of x) to give meaning to functions of complex numbers,
and (Chapter 3, Section 6) how to deﬁne a function of a matrix using the power
series of the function. Also power series are just a ﬁrst example of inﬁnite series. In
Chapter 7 we will learn about Fourier series (whose terms are sines and cosines). In
Chapter 12, we will use power series to solve diﬀerential equations, and in Chapters
12 and 13, we will discuss other series such as Legendre and Bessel. Finally, in
Chapter 14, we will discover how a study of power series clariﬁes our understanding
of the mathematical functions we use in applications.
4. CONVERGENT AND DIVERGENT SERIES
We have been talking about series which have a ﬁnite sum. We have also seen that
there are series which do not have ﬁnite sums, for example (2.1a). If a series has a
ﬁnite sum, it is called convergent. Otherwise it is called divergent. It is important
to know whether a series is convergent or divergent. Some weird things can happen
if you try to apply ordinary algebra to a divergent series. Suppose we try it with
the following series:
(4.1)
S = 1 + 2 + 4 + 8 + 16 + · · · .
Then,
2S = 2 + 4 + 8 + 16 + · · · = S −1,
S = −1.
This is obvious nonsense, and you may laugh at the idea of trying to operate with
such a violently divergent series as (4.1). But the same sort of thing can happen in
more concealed fashion, and has happened and given wrong answers to people who
were not careful enough about the way they used inﬁnite series. At this point you
probably would not recognize that the series
(4.2)
1 + 1
2 + 1
3 + 1
4 + 1
5 + · · ·
is divergent, but it is; and the series
(4.3)
1 −1
2 + 1
3 −1
4 + 1
5 −· · ·

Section 4
Convergent and Divergent Series
7
is convergent as it stands, but can be made to have any sum you like by combining
the terms in a diﬀerent order! (See Section 8.) You can see from these examples
how essential it is to know whether a series converges, and also to know how to
apply algebra to series correctly. There are even cases in which some divergent
series can be used (see Chapter 11), but in this chapter we shall be concerned with
convergent series.
Before we consider some tests for convergence, let us repeat the deﬁnition of
convergence more carefully. Let us call the terms of the series an so that the series
is
(4.4)
a1 + a2 + a3 + a4 + · · · + an + · · · .
Remember that the three dots mean that there is never a last term; the series goes
on without end. Now consider the sums Sn that we obtain by adding more and
more terms of the series. We deﬁne
S1 = a1,
S2 = a1 + a2,
S3 = a1 + a2 + a3,
· · ·
Sn = a1 + a2 + a3 + · · · + an.
(4.5)
Each Sn is called a partial sum; it is the sum of the ﬁrst n terms of the series. We
had an example of this for a geometric progression in (1.4). The letter n can be
any integer; for each n, Sn stops with the nth term. (Since Sn is not an inﬁnite
series, there is no question of convergence for it.) As n increases, the partial sums
may increase without any limit as in the series (2.1a). They may oscillate as in the
series 1−2+3−4+5−· · · (which has partial sums 1, −1, 2, −2, 3, · · ·) or they may
have some more complicated behavior. One possibility is that the Sn’s may, after
a while, not change very much any more; the an’s may become very small, and the
Sn’s come closer and closer to some value S. We are particularly interested in this
case in which the Sn’s approach a limiting value, say
lim
n→∞Sn = S.
(4.6)
(It is understood that S is a ﬁnite number.) If this happens, we make the following
deﬁnitions.
a. If the partial sums Sn of an inﬁnite series tend to a limit S, the series is called
convergent. Otherwise it is called divergent.
b. The limiting value S is called the sum of the series.
c. The diﬀerence Rn = S −Sn is called the remainder (or the remainder after n
terms). From (4.6), we see that
lim
n→∞Rn = lim
n→∞(S −Sn) = S −S = 0.
(4.7)

8
Inﬁnite Series, Power Series
Chapter 1
Example1.
We have already (Section 1) found Sn and S for a geometric series. From (1.8)
and (1.4), we have for a geometric series, Rn = arn
1−r which →0 as n →∞if |r| < 1.
Example 2.
By partial fractions, we can write
2
n2−1 =
1
n−1 −
1
n+1. Let’s write out a
number of terms of the series
∞

2
2
n2 −1 =
∞

2

1
n −1 −
1
n + 1

=
∞

1
 1
n −
1
n + 2

= 1 −1
3 + 1
2 −1
4 + 1
3 −1
5 + 1
4 −1
6 + 1
5 −1
7 + 1
6 −1
8 + · · ·
+
1
n −2 −1
n +
1
n −1 −
1
n + 1 + 1
n −
1
n + 2 + · · · .
Note the cancellation of terms; this kind of series is called a telescoping series.
Satisfy yourself that when we have added the nth term ( 1
n −
1
n+2), the only terms
which have not cancelled are 1, 1
2, −1
n+1, and
−1
n+2, so we have
Sn = 3
2 −
1
n + 1 −
1
n + 2,
S = 3
2,
Rn =
1
n + 1 +
1
n + 2.
Example 3.
Another interesting series is
∞

1
ln

n
n + 1

=
∞

1
[ln n −ln(n + 1)]
= ln 1 −ln 2 + ln 2 −ln 3 + ln 3 −ln 4 + · · · + ln n −ln(n + 1) · · · .
Then Sn = −ln(n + 1) which →−∞as n →∞, so the series diverges. However,
note that an = ln
n
n+1 →ln 1 = 0 as n →∞, so we see that even if the terms tend
to zero, a series may diverge.
PROBLEMS, SECTION 4
For the following series, write formulas for the sequences an, Sn, and Rn, and ﬁnd the
limits of the sequences as n →∞(if the limits exist).
1.
∞
X
1
1
2n
2.
∞
X
0
1
5n
3.
1 −1
2 + 1
4 −1
8 + 1
16 · · ·
4.
∞
X
1
e−n ln 3
Hint: What is e−ln 3?
5.
∞
X
0
e2n ln sin(π/3)
Hint: Simplify this.
6.
∞
X
1
1
n(n + 1)
Hint:
1
n(n + 1) = 1
n −
1
n + 1.
7.
3
1 · 2 −
5
2 · 3 +
7
3 · 4 −
9
4 · 5 + · · ·

Section 5
Testing Series for Convergence; The Preliminary Test
9
5. TESTING SERIES FOR CONVERGENCE; THE PRELIMINARY TEST
It is not in general possible to write a simple formula for Sn and ﬁnd its limit as
n →∞(as we have done for a few special series), so we need some other way to ﬁnd
out whether a given series converges. Here we shall consider a few simple tests for
convergence. These tests will illustrate some of the ideas involved in testing series
for convergence and will work for a good many, but not all, cases. There are more
complicated tests which you can ﬁnd in other books. In some cases it may be quite
a diﬃcult mathematical problem to investigate the convergence of a complicated
series. However, for our purposes the simple tests we give here will be suﬃcient.
First we discuss a useful preliminary test. In most cases you should apply this
to a series before you use other tests.
Preliminary test.
If the terms of an inﬁnite series do not tend to zero (that is,
if limn→∞an ̸= 0), the series diverges. If limn→∞an = 0, we must test further.
This is not a test for convergence; what it does is to weed out some very badly
divergent series which you then do not have to spend time testing by more com-
plicated methods. Note carefully: The preliminary test can never tell you that a
series converges. It does not say that series converge if an →0 and, in fact, often
they do not. A simple example is the harmonic series (4.2); the nth term certainly
tends to zero, but we shall soon show that the series ∞
n=1 1/n is divergent. On
the other hand, in the series
1
2 + 2
3 + 3
4 + 4
5 + · · ·
the terms are tending to 1, so by the preliminary test, this series diverges and no
further testing is needed.
PROBLEMS, SECTION 5
Use the preliminary test to decide whether the following series are divergent or require
further testing. Careful: Do not say that a series is convergent; the preliminary test cannot
decide this.
1.
1
2 −4
5 + 9
10 −16
17 + 25
26 −36
37 + · · ·
2.
√
2 +
√
3
2 +
√
4
3 +
√
5
4 +
√
6
5 + · · ·
3.
∞
X
n=1
n + 3
n2 + 10n
4.
∞
X
n=1
(−1)nn2
(n + 1)2
5.
∞
X
n=1
n!
n! + 1
6.
∞
X
n=1
n!
(n + 1)!
7.
∞
X
n=1
(−1)nn
√
n3 + 1
8.
∞
X
n=1
ln n
n
9.
∞
X
n=1
3n
2n + 3n
10.
∞
X
n=2
„
1 −1
n2
«
11.
Using (4.6), give a proof of the preliminary test. Hint: Sn −Sn−1 = an.

10
Inﬁnite Series, Power Series
Chapter 1
6. CONVERGENCE TESTS FOR SERIES OF POSITIVE TERMS;
ABSOLUTE CONVERGENCE
We are now going to consider four useful tests for series whose terms are all positive.
If some of the terms of a series are negative, we may still want to consider the related
series which we get by making all the terms positive; that is, we may consider the
series whose terms are the absolute values of the terms of our original series. If
this new series converges, we call the original series absolutely convergent. It can be
proved that if a series converges absolutely, then it converges (Problem 7.9). This
means that if the series of absolute values converges, the series is still convergent
when you put back the original minus signs. (The sum is diﬀerent, of course.) The
following four tests may be used, then, either for testing series of positive terms, or
for testing any series for absolute convergence.
A.
The Comparison Test
This test has two parts, (a) and (b).
(a) Let
m1 + m2 + m3 + m4 + · · ·
be a series of positive terms which you know converges. Then the series you are
testing, namely
a1 + a2 + a3 + a4 + · · ·
is absolutely convergent if |an| ≤mn (that is, if the absolute value of each term of
the a series is no larger than the corresponding term of the m series) for all n from
some point on, say after the third term (or the millionth term). See the example
and discussion below.
(b) Let
d1 + d2 + d3 + d4 + · · ·
be a series of positive terms which you know diverges. Then the series
|a1| + |a2| + |a3| + |a4| + · · ·
diverges if |an| ≥dn for all n from some point on.
Warning: Note carefully that neither |an| ≥mn nor |an| ≤dn tells us anything.
That is, if a series has terms larger than those of a convergent series, it may still
converge or it may diverge—we must test it further. Similarly, if a series has terms
smaller than those of a divergent series, it may still diverge, or it may converge.
Example.
Test
∞

n=1
1
n! = 1 + 1
2 + 1
6 + 1
24 + · · · for convergence.
As a comparison series, we choose the geometric series
∞

n=1
1
2n = 1
2 + 1
4 + 1
8 + 1
16 + · · · .
Notice that we do not care about the ﬁrst few terms (or, in fact, any ﬁnite number
of terms) in a series, because they can aﬀect the sum of the series but not whether

Section 6
Convergence Tests for Series of Positive Terms; Absolute Convergence
11
it converges. When we ask whether a series converges or not, we are asking what
happens as we add more and more terms for larger and larger n. Does the sum
increase indeﬁnitely, or does it approach a limit? What the ﬁrst ﬁve or hundred or
million terms are has no eﬀect on whether the sum eventually increases indeﬁnitely
or approaches a limit. Consequently we frequently ignore some of the early terms
in testing series for convergence.
In our example, the terms of ∞
n=1 1/n! are smaller than the corresponding
terms of ∞
n=1 1/2n for all n > 3 (Problem 1). We know that the geometric series
converges because its ratio is 1
2. Therefore ∞
n=1 1/n! converges also.
PROBLEMS, SECTION 6
1.
Show that n! > 2n for all n > 3. Hint: Write out a few terms; then consider what
you multiply by to go from, say, 5! to 6! and from 25 to 26.
2.
Prove that the harmonic series P∞
n=1 1/n is divergent by comparing it with the
series
1 + 1
2 +
„1
4 + 1
4
«
+
„1
8 + 1
8 + 1
8 + 1
8
«
+
„
8 terms each equal to 1
16
«
+ · · · ,
which is
1 + 1
2 + 1
2 + 1
2 + 1
2 + · · · .
3.
Prove the convergence of P∞
n=1 1/n2 by grouping terms somewhat as in Problem 2.
4.
Use the comparison test to prove the convergence of the following series:
(a)
∞
X
n=1
1
2n + 3n
(b)
∞
X
n=1
1
n 2n
5.
Test the following series for convergence using the comparison test.
(a)
∞
X
n=1
1
√n
Hint: Which is larger, n or √n ?
(b)
∞
X
n=2
1
ln n
6.
There are 9 one-digit numbers (1 to 9), 90 two-digit numbers (10 to 99). How many
three-digit, four-digit, etc., numbers are there? The ﬁrst 9 terms of the harmonic
series 1 + 1
2 + 1
3 + · · · + 1
9 are all greater than
1
10; similarly consider the next 90
terms, and so on. Thus prove the divergence of the harmonic series by comparison
with the series
ˆ 1
10 +
1
10 + · · · (9 terms each =
1
10)
˜
+
ˆ
90 terms each =
1
100
˜
+ · · ·
=
9
10 +
90
100 + · · · =
9
10 +
9
10 + · · · .
The comparison test is really the basic test from which other tests are derived.
It is probably the most useful test of all for the experienced mathematician but it
is often hard to think of a satisfactory m series until you have had a good deal of
experience with series. Consequently, you will probably not use it as often as the
next three tests.
B.
The Integral Test
We can use this test when the terms of the series are positive and not increasing,
that is, when an+1 ≤an. (Again remember that we can ignore any ﬁnite number of
terms of the series; thus the test can still be used even if the condition an+1 ≤an
does not hold for a ﬁnite number of terms.) To apply the test we think of an as a

12
Inﬁnite Series, Power Series
Chapter 1
function of the variable n, and, forgetting our previous meaning of n, we allow it to
take all values, not just integral ones. The test states that:
If 0 < an+1 ≤an for n > N, then ∞an converges if
	 ∞an dn is ﬁnite and
diverges if the integral is inﬁnite. (The integral is to be evaluated only at the
upper limit; no lower limit is needed.)
To understand this test, imagine a graph sketched of an as a function of n. For
example, in testing the harmonic series ∞
n=1 1/n, we consider the graph of the
function y = 1/n (similar to Figures 6.1 and 6.2) letting n have all values, not just
integral ones. Then the values of y on the graph at n = 1, 2, 3, · · ·, are the terms
of the series. In Figures 6.1 and 6.2, the areas of the rectangles are just the terms
of the series. Notice that in Figure 6.1 the top edge of each rectangle is above
the curve, so that the area of the rectangles is greater than the corresponding area
under the curve. On the other hand, in Figure 6.2 the rectangles lie below the
curve, so their area is less than the corresponding area under the curve. Now the
areas of the rectangles are just the terms of the series, and the area under the curve
is an integral of y dn or an dn. The upper limit on the integrals is ∞and the lower
limit could be made to correspond to any term of the series we wanted to start
with. For example (see Figure 6.1), 	 ∞
3
an dn is less than the sum of the series from
a3 on, but (see Figure 6.2) greater than the sum of the series from a4 on. If the
integral is ﬁnite, then the sum of the series from a4 on is ﬁnite, that is, the series
converges. Note again that the terms at the beginning of a series have nothing to
do with convergence. On the other hand, if the integral is inﬁnite, then the sum of
the series from a3 on is inﬁnite and the series diverges. Since the beginning terms
are of no interest, you should simply evaluate
	 ∞an dn. (Also see Problem 16.)
Figure 6.1
Figure 6.2
Example.
Test for convergence the harmonic series
(6.1)
1 + 1
2 + 1
3 + 1
4 + · · · .
Using the integral test, we evaluate

 ∞1
n dn = ln n
∞= ∞.
(We use the symbol ln to mean a natural logarithm, that is, a logarithm to the base
e.) Since the integral is inﬁnite, the series diverges.

Section 6
Convergence Tests for Series of Positive Terms; Absolute Convergence
13
PROBLEMS, SECTION 6
Use the integral test to ﬁnd whether the following series converge or diverge. Hint and
warning: Do not use lower limits on your integrals (see Problem 16).
7.
∞
X
n=2
1
n ln n
8.
∞
X
n=1
n
n2 + 4
9.
∞
X
n=3
1
n2 −4
10.
∞
X
n=1
en
e2n + 9
11.
∞
X
1
1
n(1 + ln n)3/2
12.
∞
X
1
n
(n2 + 1)2
13.
∞
X
1
n2
n3 + 1
14.
∞
X
1
1
√
n2 + 9
15.
Use the integral test to prove the following so-called p-series test. The series
∞
X
n=1
1
np
is
(
convergent
if p > 1,
divergent
if p ≤1.
Caution: Do p = 1 separately.
16.
In testing P 1/n2 for convergence, a student evaluates
R ∞
0
n−2dn = −n−1|∞
0
=
0 + ∞= ∞and concludes (erroneously) that the series diverges. What is wrong?
Hint: Consider the area under the curve in a diagram such as Figure 6.1 or 6.2.
This example shows the danger of using a lower limit in the integral test.
17.
Use the integral test to show that P∞
n=0 e−n2 converges. Hint: Although you cannot
evaluate the integral, you can show that it is ﬁnite (which is all that is necessary)
by comparing it with
R ∞e−ndn.
C.
The Ratio Test
The integral test depends on your being able to integrate andn; this is not always
easy! We consider another test which will handle many cases in which we cannot
evaluate the integral. Recall that in the geometric series each term could be obtained
by multiplying the one before it by the ratio r, that is, an+1 = ran or an+1/an = r.
For other series the ratio an+1/an is not constant but depends on n; let us call
the absolute value of this ratio ρn. Let us also ﬁnd the limit (if there is one) of
the sequence ρn as n →∞and call this limit ρ. Thus we deﬁne ρn and ρ by the
equations
ρn =

an+1
an
 ,
ρ = lim
n→∞ρn.
(6.2)
If you recall that a geometric series converges if |r| < 1, it may seem plausible that
a series with ρ < 1 should converge and this is true. This statement can be proved
(Problem 30) by comparing the series to be tested with a geometric series. Like a ge-
ometric series with |r| > 1, a series with ρ > 1 also diverges (Problem 30). However,
if ρ = 1, the ratio test does not tell us anything; some series with ρ = 1 converge

14
Inﬁnite Series, Power Series
Chapter 1
and some diverge, so we must ﬁnd another test (say one of the two preceding tests).
To summarize the ratio test:
(6.3)
If





ρ < 1,
the series converges;
ρ = 1,
use a diﬀerent test;
ρ > 1,
the series diverges.
Example 1.
Test for convergence the series
1 + 1
2! + 1
3! + · · · + 1
n! + · · · .
Using (6.2), we have
ρn =

1
(n + 1)! ÷ 1
n!

=
n!
(n + 1)! =
n(n −1) · · · 3 · 2 · 1
(n + 1)(n)(n −1) · · · 3 · 2 · 1 =
1
n + 1,
ρ = lim
n→∞ρn = lim
n→∞
1
n + 1 = 0.
Since ρ < 1, the series converges.
Example 2.
Test for convergence the harmonic series
1 + 1
2 + 1
3 + · · · + 1
n + · · · .
We ﬁnd
ρn =

1
n + 1 ÷ 1
n
 =
n
n + 1,
ρ = lim
n→∞
n
n + 1 = lim
n→∞
1
1 + 1
n
= 1.
Here the test tells us nothing and we must use some diﬀerent test. A word of
warning from this example: Notice that ρn = n/(n + 1) is always less than 1. Be
careful not to confuse this ratio with ρ and conclude incorrectly that this series
converges. (It is actually divergent as we proved by the integral test.) Remember
that ρ is not the same as the ratio ρn = |an+1/an|, but is the limit of this ratio as
n →∞.
PROBLEMS, SECTION 6
Use the ratio test to ﬁnd whether the following series converge or diverge:
18.
∞
X
n=1
2n
n2
19.
∞
X
n=0
3n
22n
20.
∞
X
n=0
n!
(2n)!

Section 6
Convergence Tests for Series of Positive Terms; Absolute Convergence
15
21.
∞
X
n=0
5n(n!)2
(2n)!
22.
∞
X
n=1
10n
(n!)2
23.
∞
X
n=1
n!
100n
24.
∞
X
n=0
32n
23n
25.
∞
X
n=0
en
√
n!
26.
∞
X
n=0
(n!)3e3n
(3n)!
27.
∞
X
n=0
100n
n200
28.
∞
X
n=0
n!(2n)!
(3n)!
29.
∞
X
n=0
p
(2n)!
n!
30.
Prove the ratio test.
Hint: If |an+1/an| →ρ < 1, take σ so that ρ < σ < 1.
Then |an+1/an| < σ if n is large, say n ≥N. This means that we have |aN+1| <
σ|aN|, |aN+2| < σ|aN+1| < σ2|aN|, and so on. Compare with the geometric series
∞
X
n=1
σn|aN|.
Also prove that a series with ρ > 1 diverges. Hint: Take ρ > σ > 1, and use the
preliminary test.
D.
A Special Comparison Test
This test has two parts: (a) a convergence test, and (b) a divergence test. (See
Problem 37.)
(a) If ∞
n=1 bn is a convergent series of positive terms and an ≥0 and an/bn
tends to a (ﬁnite) limit, then ∞
n=1 an converges.
(b) If ∞
n=1 dn is a divergent series of positive terms and an ≥0 and an/dn
tends to a limit greater than 0 (or tends to +∞), then ∞
n=1 an diverges.
There are really two steps in using either of these tests, namely, to decide on a
comparison series, and then to compute the required limit. The ﬁrst part is the most
important; given a good comparison series it is a routine process to ﬁnd the needed
limit. The method of ﬁnding the comparison series is best shown by examples.
Example 1.
Test for convergence
∞

n=3
√
2n2 −5n + 1
4n3 −7n2 + 2 .
Remember that whether a series converges or diverges depends on what the
terms are as n becomes larger and larger. We are interested in the nth term as
n →∞. Think of n = 1010 or 10100, say; a little calculation should convince you
that as n increases, 2n2 −5n + 1 is 2n2 to quite high accuracy.
Similarly, the
denominator in our example is nearly 4n3 for large n. By Section 9, fact 1, we see
that the factor
√
2/4 in every term does not aﬀect convergence. So we consider as
a comparison series just
∞

n=3
√
n2
n3
=
∞

n=3
1
n2

16
Inﬁnite Series, Power Series
Chapter 1
which we recognize (say by integral test) as a convergent series. Hence we use test
(a) to try to show that the given series converges. We have:
lim
n→∞
an
bn
= lim
n→∞
√
2n2 −5n + 1
4n3 −7n2 + 2 ÷ 1
n2

= lim
n→∞
n2√
2n2 −5n + 1
4n3 −7n2 + 2
= lim
n→∞

2 −5
n +
1
n2
4 −7
n +
2
n3
=
√
2
4 .
Since this is a ﬁnite limit, the given series converges. (With practice, you won’t
need to do all this algebra! You should be able to look at the original problem and
see that, for large n, the terms are essentially 1/n2, so the series converges.)
Example 2.
Test for convergence
∞

n=2
3n −n3
n5 −5n2 .
Here we must ﬁrst decide which is the important term as n →∞; is it 3n or
n3? We can ﬁnd out by comparing their logarithms since ln N and N increase or
decrease together. We have ln 3n = n ln 3, and ln n3 = 3 ln n. Now ln n is much
smaller than n, so for large n we have n ln 3 > 3 ln n, and 3n > n3. (You might like
to compute 1003 = 106, and 3100 > 5 × 1047.) The denominator of the given series
is approximately n5. Thus the comparison series is ∞
n=2 3n/n5. It is easy to prove
this divergent by the ratio test. Now by test (b)
lim
n→∞
 3n −n3
n5 −5n2 ÷ 3n
n5

= lim
n→∞
1 −n3
3n
1 −
5
n3
= 1
which is greater than zero, so the given series diverges.
PROBLEMS, SECTION 6
Use the special comparison test to ﬁnd whether the following series converge or diverge.
31.
∞
X
n=9
(2n + 1)(3n −5)
√
n2 −73
32.
∞
X
n=0
n(n + 1)
(n + 2)2(n + 3)
33.
∞
X
n=5
1
2n −n2
34.
∞
X
n=1
n2 + 3n + 4
n4 + 7n3 + 6n −3
35.
∞
X
n=3
(n −ln n)2
5n4 −3n2 + 1
36.
∞
X
n=1
√
n3 + 5n −1
n2 −sin n3
37.
Prove the special comparison test. Hint (part a): If an/bn →L and M > L, then
an < Mbn for large n. Compare P∞
n=1 an with P∞
n=1 Mbn.

Section 7
Alternating Series
17
7. ALTERNATING SERIES
So far we have been talking about series of positive terms (including series of abso-
lute values). Now we want to consider one important case of a series whose terms
have mixed signs. An alternating series is a series whose terms are alternately plus
and minus; for example,
(7.1)
1 −1
2 + 1
3 −1
4 + 1
5 −· · · + (−1)n+1
n
+ · · ·
is an alternating series. We ask two questions about an alternating series. Does it
converge? Does it converge absolutely (that is, when we make all signs positive)?
Let us consider the second question ﬁrst. In this example the series of absolute
values
1 + 1
2 + 1
3 + 1
4 + · · · + 1
n + · · ·
is the harmonic series (6.1), which diverges. We say that the series (7.1) is not
absolutely convergent. Next we must ask whether (7.1) converges as it stands. If it
had turned out to be absolutely convergent, we would not have to ask this question
since an absolutely convergent series is also convergent (Problem 9). However, a
series which is not absolutely convergent may converge or it may diverge; we must
test it further. For alternating series the test is very simple:
Test for alternating series.
An alternating series converges if the absolute
value of the terms decreases steadily to zero, that is, if |an+1| ≤|an| and
limn→∞an = 0.
In our example
1
n + 1 < 1
n, and lim
n→∞
1
n = 0, so (7.1) converges.
PROBLEMS, SECTION 7
Test the following series for convergence.
1.
∞
X
n=1
(−1)n
√n
2.
∞
X
n=1
(−2)n
n2
3.
∞
X
n=1
(−1)n
n2
4.
∞
X
n=1
(−3)n
n!
5.
∞
X
n=2
(−1)n
ln n
6.
∞
X
n=1
(−1)nn
n + 5
7.
∞
X
n=0
(−1)nn
1 + n2
8.
∞
X
n=1
(−1)n√
10n
n + 2
9.
Prove that an absolutely convergent series P∞
n=1 an is convergent. Hint: Put bn =
an + |an|. Then the bn are nonnegative; we have |bn| ≤2|an| and an = bn −|an|.
10.
The following alternating series are divergent (but you are not asked to prove this).
Show that an →0. Why doesn’t the alternating series test prove (incorrectly) that
these series converge?
(a)
2 −1
2 + 2
3 −1
4 + 2
5 −1
6 + 2
7 −1
8 · · ·
(b)
1
√
2
−1
2 + 1
√
3
−1
3 + 1
√
4
−1
4 + 1
√
5
−1
5 · · ·

18
Inﬁnite Series, Power Series
Chapter 1
8. CONDITIONALLY CONVERGENT SERIES
A series like (7.1) which converges, but does not converge absolutely, is called con-
ditionally convergent. You have to use special care in handling conditionally con-
vergent series because the positive terms alone form a divergent series and so do
the negative terms alone. If you rearrange the terms, you will probably change the
sum of the series, and you may even make it diverge! It is possible to rearrange the
terms to make the sum any number you wish. Let us do this with the alternating
harmonic series 1 −1
2 + 1
3 −1
4 + · · · . Suppose we want to make the sum equal to
1.5. First we take enough positive terms to add to just over 1.5. The ﬁrst three
positive terms do this:
1 + 1
3 + 1
5 = 1 8
15 > 1.5.
Then we take enough negative terms to bring the partial sum back under 1.5; the
one term −1
2 does this. Again we add positive terms until we have a little more than
1.5, and so on. Since the terms of the series are decreasing in absolute value, we are
able (as we continue this process) to get partial sums just a little more or a little less
than 1.5 but always nearer and nearer to 1.5. But this is what convergence of the
series to the sum 1.5 means: that the partial sums should approach 1.5. You should
see that we could pick in advance any sum that we want, and rearrange the terms
of this series to get it. Thus, we must not rearrange the terms of a conditionally
convergent series since its convergence and its sum depend on the fact that the
terms are added in a particular order.
Here is a physical example of such a series which emphasizes the care needed
in applying mathematical approximations in physical problems.
Coulomb’s law
in electricity says that the force between two charges is equal to the product of
the charges divided by the square of the distance between them (in electrostatic
units; to use other units, say SI, we need only multiply by a numerical constant).
Suppose there are unit positive charges at x = 0,
√
2,
√
4,
√
6,
√
8, · · · , and unit
negative charges at x = 1,
√
3,
√
5,
√
7, · · · . We want to know the total force acting
on the unit positive charge at x = 0 due to all the other charges. The negative
charges attract the charge at x = 0 and try to pull it to the right; we call the
forces exerted by them positive, since they are in the direction of the positive x
axis. The forces due to the positive charges are in the negative x direction, and we
call them negative. For example, the force due to the positive charge at x =
√
2 is
−(1 · 1) /
√
2
2 = −1/2. The total force on the charge at x = 0 is, then,
(8.1)
F = 1 −1
2 + 1
3 −1
4 + 1
5 −1
6 + · · · .
Now we know that this series converges as it stands (Section 7). But we have also
seen that its sum (even the fact that it converges) can be changed by rearranging
the terms. Physically this means that the force on the charge at the origin depends
not only on the size and position of the charges, but also on the order in which we
place them in their positions! This may very well go strongly against your physical
intuition. You feel that a physical problem like this should have a deﬁnite answer.
Think of it this way. Suppose there are two crews of workers, one crew placing the
positive charges and one placing the negative. If one crew works faster than the
other, it is clear that the force at any stage may be far from the F of equation (8.1)
because there are many extra charges of one sign. The crews can never place all the

Section 9
Useful Facts About Series
19
charges because there are an inﬁnite number of them. At any stage the forces which
would arise from the positive charges that are not yet in place, form a divergent
series; similarly, the forces due to the unplaced negative charges form a divergent
series of the opposite sign. We cannot then stop at some point and say that the
rest of the series is negligible as we could in the bouncing ball problem in Section
1. But if we specify the order in which the charges are to be placed, then the sum
S of the series is determined (S is probably diﬀerent from F in (8.1) unless the
charges are placed alternately). Physically this means that the value of the force
as the crews proceed comes closer and closer to S, and we can use the sum of the
(properly arranged) inﬁnite series as a good approximation to the force.
9. USEFUL FACTS ABOUT SERIES
We state the following facts for reference:
1. The convergence or divergence of a series is not aﬀected by multiplying every
term of the series by the same nonzero constant. Neither is it aﬀected by
changing a ﬁnite number of terms (for example, omitting the ﬁrst few terms).
2. Two convergent series ∞
n=1 an and ∞
n=1 bn may be added (or subtracted)
term by term. (Adding “term by term” means that the nth term of the sum
is an + bn.) The resulting series is convergent, and its sum is obtained by
adding (subtracting) the sums of the two given series.
3. The terms of an absolutely convergent series may be rearranged in any order
without aﬀecting either the convergence or the sum.
This is not true of
conditionally convergent series as we have seen in Section 8.
PROBLEMS, SECTION 9
Test the following series for convergence or divergence. Decide for yourself which test is
easiest to use, but don’t forget the preliminary test. Use the facts stated above when they
apply.
1.
∞
X
n=1
n −1
(n + 2)(n + 3)
2.
∞
X
n=1
n2 −1
n2 + 1
3.
∞
X
n=1
1
nln 3
4.
∞
X
n=0
n2
n3 + 4
5.
∞
X
n=1
n
n3 −4
6.
∞
X
n=0
(n!)2
(2n)!
7.
∞
X
n=0
(2n)!
3n(n!)2
8.
∞
X
n=1
n5
5n
9.
∞
X
n=1
nn
n!
10.
∞
X
n=2
(−1)n
n
n −1
11.
∞
X
n=4
2n
n2 −9
12.
∞
X
n=2
1
n2 −n
13.
∞
X
n=0
n
(n2 + 4)3/2
14.
∞
X
n=2
(−1)n
n2 −n
15.
∞
X
n=1
(−1)nn!
10n
16.
∞
X
n=0
2 + (−1)n
n2 + 7
17.
∞
X
n=1
(n!)3
(3n)!
18.
∞
X
n=1
(−1)n
2ln n

20
Inﬁnite Series, Power Series
Chapter 1
19.
1
22 −1
32 + 1
23 −1
33 + 1
24 −1
34 + · · ·
20.
1
2 + 1
22 −1
3 −1
32 + 1
4 + 1
42 −1
5 −1
52 + · · ·
21.
∞
X
n=1
an
if an+1 =
n
2n + 3an
22.
(a)
∞
X
n=1
1
3ln n
(b)
∞
X
n=1
1
2ln n
(c) For what values of k is
∞
X
n=1
1
kln n convergent?
10. POWER SERIES; INTERVAL OF CONVERGENCE
We have been discussing series whose terms were constants. Even more important
and useful are series whose terms are functions of x. There are many such series,
but in this chapter we shall consider series in which the nth term is a constant times
xn or a constant times (x−a)n where a is a constant. These are called power series,
because the terms are multiples of powers of x or of (x −a). In later chapters we
shall consider Fourier series whose terms involve sines and cosines, and other series
(Legendre, Bessel, etc.) in which the terms may be polynomials or other functions.
By deﬁnition, a power series is of the form
∞

n=0
anxn = a0 + a1x + a2x2 + a3x3 + · · ·
or
∞

n=0
an(x −a)n = a0 + a1(x −a) + a2(x −a)2 + a3(x −a)3 + · · · ,
(10.1)
where the coeﬃcients an are constants. Here are some examples:
1 −x
2 + x2
4 −x3
8 + · · · + (−x)n
2n
+ · · · ,
(10.2a)
x −x2
2 + x3
3 −x4
4 + · · · + (−1)n+1xn
n
+ · · · ,
(10.2b)
x −x3
3! + x5
5! −x7
7! + · · · + (−1)n+1x2n−1
(2n −1)!
+ · · · ,
(10.2c)
1 + (x + 2)
√
2
+ (x + 2)2
√
3
+ · · · + (x + 2)n
√n + 1 + · · · .
(10.2d)
Whether a power series converges or not depends on the value of x we are
considering. We often use the ratio test to ﬁnd the values of x for which a series
converges. We illustrate this by testing each of the four series (10.2). Recall that
in the ratio test we divide term n + 1 by term n and take the absolute value of this
ratio to get ρn, and then take the limit of ρn as n →∞to get ρ.
Example 1.
For (10.2a), we have
ρn =

(−x)n+1
2n+1
÷ (−x)n
2n
 =
x
2
 ,
ρ =
x
2
 .

Section 10
Power Series; Interval of Convergence
21
The series converges for ρ < 1, that is, for |x/2| < 1 or |x| < 2, and it diverges
for |x| > 2 (see Problem 6.30). Graphically we consider the interval on the x axis
between x = −2 and x = 2; for any x in this interval the series (10.2a) converges.
The endpoints of the interval, x = 2 and x = −2, must be considered separately.
When x = 2, (10.2a) is
1 −1 + 1 −1 + · · · ,
which is divergent; when x = −2, (10.2a) is 1 + 1 + 1 + 1 + · · · , which is divergent.
Then the interval of convergence of (10.2a) is stated as −2 < x < 2.
Example 2.
For (10.2b) we ﬁnd
ρn =

xn+1
n + 1 ÷ xn
n
 =

nx
n + 1
 ,
ρ = lim
n→∞

nx
n + 1
 = |x|.
The series converges for |x| < 1.
Again we must consider the endpoints of the
interval of convergence, x = 1 and x = −1.
For x = 1, the series (10.2b) is
1 −1
2 + 1
3 −1
4 + · · · ; this is the alternating harmonic series and is convergent. For
x = −1, (10.2b) is −1 −1
2 −1
3 −1
4 −· · · ; this is the harmonic series (times −1) and
is divergent. Then we state the interval of convergence of (10.2b) as −1 < x ≤1.
Notice carefully how this diﬀers from our result for (10.2a). Series (10.2a) did not
converge at either endpoint and we used only < signs in stating its interval of
convergence. Series (10.2b) converges at x = 1, so we use the sign ≤to include
x = 1. You must always test a series at its endpoints and include the results in your
statement of the interval of convergence. A series may converge at neither, either
one, or both of the endpoints.
Example 3.
In (10.2c), the absolute value of the nth term is |x2n−1/(2n −1)!|. To get
term n + 1 we replace n by n + 1; then 2n −1 is replaced by 2(n + 1) −1 = 2n + 1,
and the absolute value of term n + 1 is

x2n+1
(2n + 1)!
 .
Thus we get
ρn =

x2n+1
(2n + 1)! ÷
x2n−1
(2n −1)!
 =

x2
(2n + 1)(2n)
 ,
ρ = lim
n→∞

x2
(2n + 1)(2n)
 = 0.
Since ρ < 1 for all values of x, this series converges for all x.
Example 4.
In (10.2d), we ﬁnd
ρn =

(x + 2)n+1
√n + 2
÷ (x + 2)n
√n + 1
 ,
ρ = lim
n→∞
(x + 2)
√n + 1
√n + 2
 = |x + 2|.

22
Inﬁnite Series, Power Series
Chapter 1
The series converges for |x+2| < 1; that is, for −1 < x+2 < 1, or −3 < x < −1.
If x = −3, (10.2d) is
1 −1
√
2 + 1
√
3 −1
√
4 + · · ·
which is convergent by the alternating series test. For x = −1, the series is
1 + 1
√
2 + 1
√
3 + · · · =
∞

n=0
1
√n + 1
which is divergent by the integral test. Thus, the series converges for −3 ≤x < 1.
PROBLEMS, SECTION 10
Find the interval of convergence of each of the following power series; be sure to investigate
the endpoints of the interval in each case.
1.
∞
X
n=0
(−1)nxn
2.
∞
X
n=0
(2x)n
3n
3.
∞
X
n=1
(−1)nxn
n(n + 1)
4.
∞
X
n=1
x2n
2nn2
5.
∞
X
n=1
xn
(n!)2
6.
∞
X
n=1
(−1)nxn
(2n)!
7.
∞
X
n=1
x3n
n
8.
∞
X
n=1
(−1)nxn
√n
9.
∞
X
n=1
(−1)nn3xn
10.
∞
X
n=1
(−1)nx2n
(2n)3/2
11.
∞
X
n=1
1
n
“x
5
”n
12.
∞
X
n=1
n(−2x)n
13.
∞
X
n=1
n(−x)n
n2 + 1
14.
∞
X
n=1
n
n + 1
“x
3
”n
15.
∞
X
n=1
(x −2)n
3n
16.
∞
X
n=1
(x −1)n
2n
17.
∞
X
n=1
(−1)n(x + 1)n
n
18.
∞
X
n=1
(−2)n(2x + 1)n
n2
The following series are not power series, but you can transform each one into a power
series by a change of variable and so ﬁnd out where it converges.
19.
P∞
0 8−n(x2 −1)n Method: Let y = x2 −1. The power series P∞
0 8−nyn converges
for |y| < 8, so the original series converges for |x2 −1| < 8, which means |x| < 3.
20.
∞
X
0
(−1)n 2n
n! (x2 + 1)2n
21.
∞
X
2
(−1)nxn/2
n ln n
22.
∞
X
0
n!(−1)n
xn
23.
∞
X
0
3n(n + 1)
(x + 1)n
24.
∞
X
0
“p
x2 + 1
”n
2n
3n + n3
25.
∞
X
0
(sin x)n(−1)n2n

Section 12
Expanding Functions in Power Series
23
11. THEOREMS ABOUT POWER SERIES
We have seen that a power series ∞
n=0 anxn converges in some interval with center
at the origin. For each value of x (in the interval of convergence) the series has a
ﬁnite sum whose value depends, of course, on the value of x. Thus we can write the
sum of the series as S(x) = ∞
n=0 anxn. We see then that a power series (within
its interval of convergence) deﬁnes a function of x, namely S(x). In describing the
relation of the series and the function S(x), we may say that the series converges
to the function S(x), or that the function S(x) is represented by the series, or that
the series is the power series of the function. Here we have thought of obtaining
the function from a given series. We shall also (Section 12) be interested in ﬁnding
a power series that converges to a given function.
When we are working with
power series and the functions they represent, it is useful to know the following
theorems (which we state without proof; see advanced calculus texts). Power series
are very useful and convenient because within their interval of convergence they can
be handled much like polynomials.
1. A power series may be diﬀerentiated or integrated term by term; the resulting
series converges to the derivative or integral of the function represented by the
original series within the same interval of convergence as the original series
(that is, not necessarily at the endpoints of the interval).
2. Two power series may be added, subtracted, or multiplied; the resultant series
converges at least in the common interval of convergence. You may divide two
series if the denominator series is not zero at x = 0, or if it is and the zero
is canceled by the numerator [as, for example, in (sin x)/x; see (13.1)]. The
resulting series will have some interval of convergence (which can be found
by the ratio test or more simply by complex variable theory—see Chapter 2,
Section 7).
3. One series may be substituted in another provided that the values of the
substituted series are in the interval of convergence of the other series.
4. The power series of a function is unique, that is, there is just one power series
of the form ∞
n=0 anxn which converges to a given function.
12. EXPANDING FUNCTIONS IN POWER SERIES
Very often in applied work, it is useful to ﬁnd power series that represent given
functions. We illustrate one method of obtaining such series by ﬁnding the series
for sin x. In this method we assume that there is such a series (see Section 14 for
discussion of this point) and set out to ﬁnd what the coeﬃcients in the series must
be. Thus we write
(12.1)
sin x = a0 + a1x + a2x2 + · · · + anxn + · · ·
and try to ﬁnd numerical values of the coeﬃcients an to make (12.1) an identity
(within the interval of convergence of the series). Since the interval of convergence
of a power series contains the origin, (12.1) must hold when x = 0. If we substitute
x = 0 into (12.1), we get 0 = a0 since sin 0 = 0 and all the terms except a0 on the

24
Inﬁnite Series, Power Series
Chapter 1
right-hand side of the equation contain the factor x. Then to make (12.1) valid at
x = 0, we must have a0 = 0. Next we diﬀerentiate (12.1) term by term to get
(12.2)
cos x = a1 + 2a2x + 3a3x2 + · · · .
(This is justiﬁed by Theorem 1 of Section 11.) Again putting x = 0, we get 1 = a1.
We diﬀerentiate again, and put x = 0 to get
−sin x = 2a2 + 3 · 2a3x + 4 · 3a4x2 + · · · ,
0 = 2a2.
(12.3)
Continuing the process of taking successive derivatives of (12.1) and putting x = 0,
we get
−cosx = 3 · 2a3 + 4 · 3 · 2a4x + · · · ,
−1 = 3! a3,
a3 = −1
3!;
sin x = 4 · 3 · 2 · a4 + 5 · 4 · 3 · 2a5x + · · · ,
0 = a4;
cos x = 5 · 4 · 3 · 2a5 + · · · ,
1 = 5! a5, · · · .
(12.4)
We substitute these values back into (12.1) and get
(12.5)
sin x = x −x3
3! + x5
5! −· · · .
You can probably see how to write more terms of this series without further com-
putation. The sin x series converges for all x; see Example 3, Section 10.
Series obtained in this way are called Maclaurin series or Taylor series about
the origin. A Taylor series in general means a series of powers of (x −a), where a is
some constant. It is found by writing (x −a) instead of x on the right-hand side of
an equation like (12.1), diﬀerentiating just as we have done, but substituting x = a
instead of x = 0 at each step. Let us carry out this process in general for a function
f(x). As above, we assume that there is a Taylor series for f(x), and write
f(x) = a0 + a1(x −a) + a2(x −a)2 + a3(x −a)3 + a4(x −a)4 + · · ·
(12.6)
+ an(x −a)n + · · · ,
f ′(x) = a1 + 2a2(x −a) + 3a3(x −a)2 + 4a4(x −a)3 + · · ·
+ nan(x −a)n−1 + · · · ,
f ′′(x) = 2a2 + 3 · 2a3(x −a) + 4 · 3a4(x −a)2 + · · ·
+ n(n −1)an(x −a)n−2 + · · · ,
f ′′′(x) = 3! a3 + 4 · 3 · 2a4(x −a) + · · ·
+ n(n −1)(n −2)an(x −a)n−3 + · · · ,
...
f (n)(x) = n(n −1)(n −2) · · · 1 · an + terms containing powers of (x −a).

Section 13
Techniques for Obtaining Power Series Expansions
25
[The symbol f (n)(x) means the nth derivative of f(x).] We now put x = a in each
equation of (12.6) and obtain
f(a) = a0,
f ′(a) = a1,
f ′′(a) = 2a2,
f ′′′(a) = 3! a3,
· · · ,
f (n)(a) = n! an.
(12.7)
[Remember that f ′(a) means to diﬀerentiate f(x) and then put x = a; f ′′(a) means
to ﬁnd f ′′(x) and then put x = a, and so on.]
We can then write the Taylor series for f(x) about x = a:
(12.8) f(x) = f(a)+(x−a)f ′(a)+ 1
2!(x−a)2f ′′(a)+· · ·+ 1
n!(x−a)nf (n)(a)+· · · .
The Maclaurin series for f(x) is the Taylor series about the origin. Putting
a = 0 in (12.8), we obtain the Maclaurin series for f(x):
(12.9)
f(x) = f(0) + xf ′(0) + x2
2! f ′′(0) + x3
3! f ′′′(0) + · · · + xn
n! f (n)(0) + · · · .
We have written this in general because it is sometimes convenient to have the
formulas for the coeﬃcients. However, ﬁnding the higher order derivatives in (12.9)
for any but the simplest functions is unnecessarily complicated (try it for, say, etan x).
In Section 13, we shall discuss much easier ways of getting Maclaurin and Taylor
series by combining a few basic series. Meanwhile, you should verify (Problem 1,
below) the basic series (13.1) to (13.5) and memorize them.
PROBLEMS, SECTION 12
1.
By the method used to obtain (12.5) [which is the series (13.1) below], verify each
of the other series (13.2) to (13.5) below.
13. TECHNIQUES FOR OBTAINING POWER SERIES EXPANSIONS
There are often simpler ways for ﬁnding the power series of a function than the
successive diﬀerentiation process in Section 12. Theorem 4 in Section 11 tells us
that for a given function there is just one power series, that is, just one series of the
form ∞
n=0 anxn. Therefore we can obtain it by any correct method and be sure
that it is the same Maclaurin series we would get by using the method of Section
12. We shall illustrate a variety of methods for obtaining power series. First of all,
it is a great timesaver for you to verify (Problem 12.1) and then memorize the basic
series (13.1) to (13.5). We shall use these series without further derivation when we
need them.

26
Inﬁnite Series, Power Series
Chapter 1
convergent for
sin x =
∞

n=0
(−1)nx2n+1
(2n + 1)!
= x −x3
3! + x5
5! −x7
7! + · · · ,
all x;
(13.1)
cos x =
∞

n=0
(−1)nx2n
(2n)!
= 1 −x2
2! + x4
4! −x6
6! + · · · ,
all x;
(13.2)
ex =
∞

n=0
xn
n! = 1 + x + x2
2! + x3
3! + x4
4! + · · · ,
all x;
(13.3)
ln(1 + x) =
∞

n=1
(−1)n+1xn
n
= x −x2
2 + x3
3 −x4
4 + · · · ,
−1 < x ≤1;
(13.4)
(1 + x)p =
∞

n=0
p
n

xn = 1 + px + p(p −1)
2!
x2
(13.5)
+ p(p −1)(p −2)
3!
x3 + · · · ,
|x| < 1,
(binomial series; p is any real number, positive or negative and
p
n

is called a
binomial coeﬃcient—see method C below.)
When we use a series to approximate a function, we may want only the ﬁrst few
terms, but in derivations, we may want the formula for the general term so that we
can write the series in summation form. Let’s look at some methods of obtaining
either or both of these results.
A.
Multiplying a Series by a Polynomial or by Another Series
Example 1.
To ﬁnd the series for (x + 1) sin x, we multiply (x + 1) times the series (13.1)
and collect terms:
(x + 1) sin x = (x + 1)

x −x3
3! + x5
5! −· · ·

= x + x2 −x3
3! −x4
3! + · · · .
You can see that this is easier to do than taking the successive derivatives of the
product (x + 1) sin x, and Theorem 4 assures us that the results are the same.

Section 13
Techniques for Obtaining Power Series Expansions
27
Example 2.
To ﬁnd the series for ex cos x, we multiply (13.2) by (13.3):
ex cos x = (1 + x + x2
2! + x3
3! + x4
4! + · · ·
 
1 −x2
2! + x4
4! −· · ·

=1
+ x + x2
2! + x3
3! + x4
4! · · ·
−x2
2! −x3
2! −x4
2! 2! · · ·
+ x4
4! · · ·
=1
+ x + 0x2 −x3
3 −x4
6 · · · = 1 + x −x3
3 −x4
6 · · · .
There are two points to note here. First, as you multiply, line up the terms
involving each power of x in a column; this makes it easier to combine them. Second,
be careful to include all the terms in the product out to the power you intend to
stop with, but don’t include any higher powers. In the above example, note that
we did not include the x3 · x2 terms; if we wanted the x5 term in the answer, we
would have to include all products giving x5 (namely, x · x4, x3 · x2, and x5 · 1).
Also see Chapter 2, Problem 17.30, for a simple way of getting the general term
of this series.
B.
Division of Two Series or of a Series by a Polynomial
Example 1.
To ﬁnd the series for (1/x) ln(1 + x), we divide (13.4) by x. You should be
able to do this in your head and just write down the answer.
1
x ln(1 + x) = 1 −x
2 + x2
3 −x3
4 + · · · .
To obtain the summation form, we again just divide (13.4) by x. We can simplify
the result by changing the limits to start at n = 0, that is, replace n by n + 1.
1
x ln(1 + x) =
∞

n=1
(−1)n+1xn−1
n
=
∞

n=0
(−1)nxn
n + 1
.

28
Inﬁnite Series, Power Series
Chapter 1
Example 2.
To ﬁnd the series for tan x, we divide the series for sin x by the series for
cos x by long division:
x + x3
3 + 2
15x5 · · ·
1 −x2
2! + x4
4! · · ·

x −x3
3! + x5
5! · · ·
x −x3
2! + x5
4! · · ·
x3
3 −x5
30 · · ·
x3
3 −x5
6 · · ·
2x5
15 · · · , etc.
C.
Binomial Series
If you recall the binomial theorem, you may see that (13.5) looks just like the
beginning of the binomial theorem for the expansion of (a + b)n if we put a = 1,
b = x, and n = p. The diﬀerence here is that we allow p to be negative or fractional,
and in these cases the expansion is an inﬁnite series. The series converges for |x| < 1
as you can verify by the ratio test. (See Problem 1.)
From (13.5), we see that the binomial coeﬃcients are:
p
0

= 1,
p
1

= p,
p
2

= p(p −1)
2!
,
p
3

= p(p −1)(p −2)
3!
, · · · ,
p
n

= p(p −1)(p −2) · · · (p −n + 1)
n!
.
(13.6)
Example 1.
To ﬁnd the series for 1/(1 + x), we use the binomial series (13.5) to write
1
1 + x = (1 + x)−1 = 1 −x + (−1)(−2)
2!
x2 + (−1)(−2)(−3)
3!
x3 + · · ·
= 1 −x + x2 −x3 + · · · =
∞

n=0
(−x)n.

Section 13
Techniques for Obtaining Power Series Expansions
29
Example 2.
The series for √1 + x is (13.5) with p = 1/2.
√
1 + x = (1 + x)1/2 =
∞

n=0
1/2
n

xn
= 1 + 1
2x +
1
2(−1
2)
2!
x2 +
1
2(−1
2)(−3
2)
3!
x3 +
1
2(−1
2)(−3
2)(−5
2)
4!
x4 + · · ·
= 1 + 1
2x −1
8x2 + 1
16x3 −
5
128x4 · · · .
From (13.6) we can see that the binomial coeﬃcients when n = 0 and n = 1 are
1/2
0

= 1 and
1/2
1

= 1/2. For n ≥2, we can write
 1
2
n

= ( 1
2)(−1
2)(−3
2) · · · ( 1
2 −n + 1)
n!
= (−1)n−13 · 5 · 7 · · · (2n −3)
n! 2n
= (−1)n−1(2n −3)!!
(2n)!!
where the double factorial of an odd number means the product of that number
times all smaller odd numbers, and a similar deﬁnition for even numbers.
For
example, 7!! = 7 · 5 · 3, and 8!! = 8 · 6 · 4 · 2.
PROBLEMS, SECTION 13
1.
Use the ratio test to show that a binomial series converges for |x| < 1.
2.
Show that the binomial coeﬃcients
`−1
n
´
= (−1)n.
3.
Show that if p is a positive integer, then
`p
n
´
= 0 when n > p, so (1+ x)p = P `p
n
´
xn
is just a sum of p+1 terms, from n = 0 to n = p. For example, (1+x)2 has 3 terms,
(1 + x)3 has 4 terms, etc. This is just the familiar binomial theorem.
4.
Write the Maclaurin series for 1/√1 + x in P form using the binomial coeﬃcient
notation. Then ﬁnd a formula for the binomial coeﬃcients in terms of n as we did
in Example 2 above.
D.
Substitution of a Polynomial or a Series
for the Variable in Another Series
Example 1.
Find the series for e−x2. Since we know the series (13.3) for ex, we simply
replace the x there by −x2 to get
e−x2 = 1 −x2 + (−x2)2
2!
+ (−x2)3
3!
+ · · ·
= 1 −x2 + (x4)
2!
−x6
3! + · · · .
Example 2.
Find the series for etan x. Here we must replace the x in (13.3) by the series
of Example 2 in method B. Let us agree in advance to keep terms only as far as x4;
we then write only terms which can give rise to powers of x up to 4, and neglect

30
Inﬁnite Series, Power Series
Chapter 1
any higher powers:
etan x = 1 +

x + x3
3 + · · ·

+ 1
2!

x + x3
3 + · · ·
2
+ 1
3!

x + x3
3 + · · ·
3
+ 1
4!(x + · · · )4 + · · ·
= 1 + x
+ x3
3
+ · · ·
+ x2
2!
+ 2x4
3 · 2! + · · ·
+ x3
3! +
x4
4! + · · ·
= 1 + x + x2
2 + x3
2 + 3
8x4 + · · · .
E.
Combination of Methods
Example.
Find the series for arc tanx. Since

 x
0
dt
1 + t2 = arc tant

x
0
= arc tan x,
we ﬁrst write out (as a binomial series) (1 + t2)−1 and then integrate term by term:
(1 + t2)−1 = 1 −t2 + t4 −t6 + · · · ;

 x
0
dt
1 + t2 = t −t3
3 + t5
5 −t7
7 + · · ·

x
0
.
Thus, we have
(13.7)
arc tanx = x −x3
3 + x5
5 −x7
7 + · · · .
Compare this simple way of getting the series with the method in Section 12 of
ﬁnding successive derivatives of arc tanx.
F.
Taylor Series Using the Basic Maclaurin Series
In many simple cases it is possible to obtain a Taylor series using the basic memo-
rized Maclaurin series instead of the formulas or method of Section 12.
Example 1.
Find the ﬁrst few terms of the Taylor series for ln x about x = 1. [This means
a series of powers of (x −1) rather than powers of x.] We write
ln x = ln[1 + (x −1)]
and use (13.4) with x replaced by (x −1):
ln x = ln[1 + (x −1)] = (x −1) −1
2(x −1)2 + 1
3(x −1)3 −1
4(x −1)4 · · · .

Section 13
Techniques for Obtaining Power Series Expansions
31
Example 2.
Expand cos x about x = 3π/2. We write
cos x = cos
3π
2 +

x −3π
2

= sin

x −3π
2

=

x −3π
2

−1
3!

x −3π
2
3
+ 1
5!

x −3π
2
5
· · ·
using (13.1) with x replaced by (x −3π/2).
G.
Using a Computer
You can also do problems like these using a computer.
This is a good method
for complicated functions where it saves you a lot of algebra. However, you’re not
saving time if it takes longer to type a problem into the computer than to do it
in your head! For example, you should be able to just write down the ﬁrst few
terms of (sin x)/x or (1 −cos x)/x2. A good method of study is to practice doing
problems by hand and also check your results using the computer. This will turn
up errors you are making by hand, and also let you discover what the computer
will do and what it won’t do! It is very illuminating to computer plot the function
you are expanding, along with several partial sums of the series, in order to see how
accurately the partial sums represent the function—see the following example.
–2 –1.5
–1
–0.5
–0.5
0.5
1
1.5
2
2.5
–1
0.5
1
1.5
S1
–2 –1.5
–1
–0.5
–0.5
0.5
1
1.5
0.5
1
1.5
S3
–2 –1.5
–1
–0.5
–0.5
0.5
1
1.5
0.5
1
1.5
S5
–2
–1
–0.5
–0.5
–1
0.5
1
1.5
0.5
1
1.5
S4
–1.5
Figure 13.1
Example.
Plot the function ex cos x together with several partial sums of its Maclaurin
series. Using Example 2 in 13A or a computer, we have
ex cos x = 1 + x −x3
3 −x4
6 −x5
30 · · · .
Figure 13.1 shows plots of the function along with each of the partial sums S1 = 1+x,
S3 = 1 + x −x3
3 , S4 = 1 + x −x3
3 −x4
6 , S5 = 1 + x −x3
3 −x4
6 −x5
30. We can see
from the graphs the values of x for which an approximation is fairly good. Also see
Section 14.

32
Inﬁnite Series, Power Series
Chapter 1
PROBLEMS, SECTION 13
Using the methods of this section:
(a) Find the ﬁrst few terms of the Maclaurin series for each of the following functions.
(b) Find the general term and write the series in summation form.
(c) Check your results in (a) by computer.
(d) Use a computer to plot the function and several approximating partial sums of the
series.
5.
x2 ln(1 −x)
6.
x
√
1 + x
7.
1
x sin x
8.
1
√
1 −x2
9.
1 + x
1 −x
10.
sin x2
11.
sin √x
√x
,
x > 0
12.
Z x
0
cos t2dt
13.
Z x
0
e−t2dt
14.
ln
r
1 + x
1 −x =
Z x
0
dt
1 −t2
15.
arc sin x =
Z x
0
dt
√
1 −t2
16.
cosh x = ex + e−x
2
17.
ln 1 + x
1 −x
18.
Z x
0
sin t dt
t
19.
ln(x +
p
1 + x2 ) =
Z x
0
dt
√
1 + t2
Find the ﬁrst few terms of the Maclaurin series for each of the following functions and
check your results by computer.
20.
ex sin x
21.
tan2 x
22.
ex
1 −x
23.
1
1 + x + x2
24.
sec x =
1
cos x
25.
2x
e2x −1
26.
1
√cos x
27.
esin x
28.
sin[ln(1 + x)]
29.
p
1 + ln(1 + x)
30.
r
1 −x
1 + x
31.
cos(ex −1)
32.
ln(1 + xex)
33.
1 −sin x
1 −x
34.
ln(2 −e−x)
35.
x
sin x
36.
Z u
0
sin x dx
√
1 −x2
37.
ln cos x Hints: Method 1: Write cos x = 1 + (cos x −1) = 1 + u; use the series you
know for ln(1 + u); replace u by the Maclaurin series for (cos x −1). Method 2:
ln cos x = −
R x
0 tan u du. Use the series of Example 2 in method B.
38.
ecos x
Hint: ecos x = e · ecos x−1.
Using method F above, ﬁnd the ﬁrst few terms of the Taylor series for the following
functions about the given points.
39.
f(x) = sin x,
a = π/2
40.
f(x) = 1
x,
a = 1
41.
f(x) = ex,
a = 3
42.
f(x) = cos x,
a = π
43.
f(x) = cot x,
a = π/2
44.
f(x) = √x
a = 25

Section 14
Accuracy of Series Approximations
33
14. ACCURACY OF SERIES APPROXIMATIONS
The thoughtful student might well be disturbed about the mathematical manipula-
tions we have been doing. How do we know whether these processes we have shown
really give us series that approximate the functions being expanded? Certainly some
functions cannot be expanded in a power series; since a power series becomes just
a0 when x = 0, it cannot be equal to any function (like 1/x or ln x) which is inﬁnite
at the origin. So we might ask whether there are other functions (besides those that
become inﬁnite at the origin) which cannot be expanded in a power series. All we
have done so far is to show methods of ﬁnding the power series for a function if it
has one. Now is there a chance that there might be some functions which do not
have series expansions, but for which our formal methods would give us a spurious
series? Unfortunately, the answer is “Yes”; fortunately, this is not a very common
diﬃculty in practice. However, you should know of the possibility and what to do
about it. You may ﬁrst think of the fact that, say, the equation
1
1 + x = 1 −x + x2 −x3 + · · ·
is not valid for |x| ≥1. This is a fairly easy restriction to determine; from the
beginning we recognized that we could use our series expansions only when they
converged.
But there is another diﬃculty which can arise.
It is possible for a
series found by the above methods to converge and still not represent the function
being expanded! A simple example of this is e−(1/x2) for which the formal series is
0+0+0+· · · because e−(1/x2) and all its derivatives are zero at the origin (Problem
15.26). It is clear that e−(1/x2) is not zero for x2 > 0, so the series is certainly not
correct. You can startle your friends with the following physical interpretation of
this. Suppose that at t = 0 a car is at rest (zero velocity), and has zero acceleration,
zero rate of change of acceleration, etc. (all derivatives of distance with respect to
time are zero at t = 0). Then according to Newton’s second law (force equals mass
times acceleration), the instantaneous force acting on the car is also zero (and, in
fact, so are all the derivatives of the force). Now we ask “Is it possible for the car
to be moving immediately after t = 0?” The answer is “Yes”! For example, let its
distance from the origin as a function of time be e−(1/t2).
This strange behavior is really the fault of the function itself and not of our
method of ﬁnding series. The most satisfactory way of avoiding the diﬃculty is to
recognize, by complex variable theory, when functions can or cannot have power
series. We shall consider this in Chapter 14, Section 2. Meanwhile, let us consider
two important questions: (1) Does the Taylor or Maclaurin series in (12.8) or (12.9)
actually converge to the function being expanded? (2) In a computation problem, if
we know that a series converges to a given function, how rapidly does it converge?
That is, how many terms must we use to get the accuracy we require? We take up
these questions in order.
The remainder Rn(x) in a Taylor series is the diﬀerence between the value of
the function and the sum of n + 1 terms of the series:
(14.1)
Rn(x) = f(x) −

f(a) + (x −a)f ′(a) + 1
2!(x −a)2f ′′(a)
+ · · · + 1
n!(x −a)nf (n)(a)

.

34
Inﬁnite Series, Power Series
Chapter 1
Saying that the series converges to the function means that limn→∞|Rn(x)| = 0.
There are many diﬀerent formulas for Rn(x) which are useful for special purposes;
you can ﬁnd these in calculus books. One such formula is
(14.2)
Rn(x) = (x −a)n+1f (n+1)(c)
(n + 1)!
where c is some point between a and x. You can use this formula in some simple
cases to prove that the Taylor or Maclaurin series for a function does converge to
the function (Problems 11 to 13).
Error in Series Approximations
Now suppose that we know in advance that
the power series of a function does converge to the function (within the interval
of convergence), and we want to use a series approximation for the function. We
would like to estimate the error caused by using only a few terms of the series.
There is an easy way to estimate this error when the series is alternating and
meets the alternating series test for convergence (Section 7). In this case the error
is (in absolute value) less than the absolute value of the ﬁrst neglected term (see
Problem 1).
If S =
∞

n=1
an is an alternating series with |an+1| < |an|,
and
lim
n→∞an = 0, then |S −(a1 + a2 + · · · + an)| ≤|an+1|.
(14.3)
Example 1.
Consider the series
1 −1
2 + 1
4 −1
8 + 1
16 −1
32 + 1
64 · · · .
The sum of this series [see (1.8), a = 1, r = −1
2] is S = 2
3 = 0.666 · · · . The sum of
the terms through −1
32 is 0.656+, which diﬀers from S by about 0.01. This is less
than the next term =
1
64 = 0.015+.
Estimating the error by the ﬁrst neglected term may be quite misleading for
convergent series that are not alternating.
Example 2.
Suppose we approximate ∞
n=1 1/n2 by the sum of the ﬁrst ﬁve terms; the
error is then about 0.18 [see problem 2(a)]. But the ﬁrst neglected term is 1/62 =
0.028 which is much less than the error. However, note that we are ﬁnding the sum
of the power series ∞
n=1 xn/n2 when x = 1, which is the largest x for which the
series converges. If, instead, we ask for the sum of the series when x = 1/2, we ﬁnd
[see Problem 2(b)]:
S =
∞

n=1
1
n2
1
2
n
= 0.5822 + .
The sum of the ﬁrst ﬁve terms of the series is 0.5815+, so the error is about 0.0007.
The next term is ( 1
6)2/62 = 0.0004, which is less than the error but still of the

Section 14
Accuracy of Series Approximations
35
same order of magnitude. We can state the following theorem [Problem 2(c)] which
covers many practical problems.
If S =
∞

n=0
anxn converges for |x| < 1, and if
|an+1| < |an| for n > N, then
S −
N

n=0
anxn
 < |aN+1xN+1| ÷ (1 −|x|).
(14.4)
That is, as in (14.3), the error may be estimated by the ﬁrst neglected term, but
here the error may be a few times as large as the ﬁrst neglected term instead of
smaller. In the example of  xn/n2 with x = 1
2, we have 1 −x = 1
2, so (14.4)
says that the error is less than two times the next term. We observe that the error
0.0007 is less than 2(0.0004) as (14.4) says.
For values of |x| much less than 1, 1 −|x| is about 1, so the next term gives a
good error estimate in this case. If the interval of convergence is not |x| < 1, but,
for example, |x| < 2 as in
∞

n=1
1
n2
x
2
n
,
we can easily let x/2 = y, and apply the theorem in terms of y.
PROBLEMS, SECTION 14
1.
Prove theorem (14.3). Hint: Group the terms in the error as (an+1+an+2)+(an+3+
an+4) + · · · to show that the error has the same sign as an+1. Then group them as
an+1 + (an+2 + an+3) + (an+4 + an+5) + · · · to show that the error has magnitude
less than |an+1|.
2.
(a)
Using computer or tables (or see Chapter 7, Section 11), verify that P∞
n=1 1/n2 =
π2/6 = 1.6449+, and also verify that the error in approximating the sum of
the series by the ﬁrst ﬁve terms is approximately 0.1813.
(b)
By computer or tables verify that P∞
n=1(1/n2)(1/2)n = π2/12−(1/2)(ln 2)2 =
0.5822+, and that the sum of the ﬁrst ﬁve terms is 0.5815+.
(c)
Prove theorem (14.4). Hint: The error is | P∞
N+1 anxn|. Use the fact that the
absolute value of a sum is less than or equal to the sum of the absolute values.
Then use the fact that |an+1| ≤|an| to replace all an by aN+1, and write the
appropriate inequality. Sum the geometric series to get the result.
In Problems 3 to 7, assume that the Maclaurin series converges to the function.
3.
If 0 < x < 1
2, show [using theorem (14.3)] that √1 + x = 1 + 1
2x with an error less
than 0.032. Hint: Note that the series is alternating after the ﬁrst term.
4.
Show that sin x = x with an error less than 0.021 for 0 < x < 1
2, and with an error
less than 0.0002 for 0 < x < 0.1. Hint: Use theorem (14.3) and note that the “next”
term is the x3 term.
5.
Show that 1 −cos x = x2/2 with an error less than 0.003 for |x| < 1
2.

36
Inﬁnite Series, Power Series
Chapter 1
6.
Show that ln(1 −x) = −x with an error less than 0.0056 for |x| < 0.1. Hint: Use
theorem (14.4).
7.
Show that 2/√4 −x = 1 + 1
8x with an error less than
1
32 for 0 < x < 1. Hint: Let
x = 4y, and use theorem (14.4).
8.
Estimate the error if P∞
n=1 xn/n3 is approximated by the sum of its ﬁrst three terms
for |x| < 1
2.
9.
Consider the series in Problem 4.6 and show that the remainder after n terms is
Rn = 1/(n + 1). Compare the value of term n + 1 with Rn for n = 3, n = 10, n =
100, n = 500 to see that the ﬁrst neglected term is not a useful estimate of the error.
10.
Show that the interval of convergence of the series P∞
n=1 xn/(n2 +n) is |x| ≤1. (For
x = 1, this is the series of Problem 9.) Using theorem (14.4), show that for x = 1
2,
four terms will give two decimal place accuracy.
11.
Show that the Maclaurin series for sin x converges to sin x. Hint: If f(x) = sin x,
f (n+1)(x) = ± sin x or ± cos x, and so |f (n+1)(x)| ≤1 for all x and all n. Let n →∞
in (14.2).
12.
Show as in Problem 11 that the Maclaurin series for ex converges to ex.
13.
Show that the Maclaurin series for (1 + x)p converges to (1 + x)p when 0 < x < 1.
15. SOME USES OF SERIES
In this chapter we are going to consider a few rather straightforward uses of series.
In later chapters there will also be many other cases where we need them.
Numerical Computation
With computers and calculators so available, you may
wonder why we would ever want to use series for numerical computation. Here is
an example to warn you of the pitfalls of blind computation.
Example 1.
Evaluate f(x) = ln

(1 + x)/(1 −x) −tan x at x = 0.0015.
Here are answers from several calculators and computers: −9 × 10−16, 3 ×
10−10, 6.06 × 10−16, 5.5 × 10−16. All of these are wrong! Let’s use series to see
what’s going on. By Section 13 methods we ﬁnd, for x = 0.0015:
ln

(1 + x)/(1 −x) = x + x3
3 + x5
5 + x7
7 · · ·
= 0.001500001125001518752441,
tan x = x + x3
3 + 2x5
15 + 17x7
315 · · ·
= 0.001500001125001012500922,
f(x) = x5
15 + 4x7
45 · · ·
= 5.0625 × 10−16
with an error of the order of x7 or 10−21.
Now we see that the answer is the
diﬀerence of two numbers which are identical until the 16th decimal place, so any
computer carrying fewer digits will lose all accuracy in the subtraction. It may also
be necessary to tell your computer that the value of x is an exact number and not
a 4 decimal place approximation. The moral here is that a computer is a tool—a
very useful tool, yes—but you need to be constantly aware of whether an answer
is reasonable when you are doing problems either by hand or by computer. A ﬁnal
point is that in an applied problem you may want, not a numerical value, but a
simple approximation for a complicated function. Here we might approximate f(x)
by x5/15 for small x.

Section 15
Some Uses of Series
37
Example 2.
Evaluate
d5
dx5
 1
x sin x2

x=0
.
We can do this by computer, but it’s probably faster to use sin x2 = x2−(x2)3/3! · · · ,
and observe that when we divide this by x and take 5 derivatives, the x2 term is
gone. The second term divided by x is an x5 term and the ﬁfth derivative of x5 is
5!. Any further terms will have a power of x which is zero at x = 0. Thus we have
d5
dx5
 1
x · −(x2)3
3!

x=0
= −5!
3! = −20.
Summing series
We have seen a few numerical series which we could sum exactly
(see Sections 1 and 4) and we will see some others later (see Chapter 7, Section 11).
Here it is interesting to note that if f(x) =  anxn, and we let x have a particular
value (within the interval of convergence), then we get a numerical series whose
sum is the value of the function for that x. For example, if we substitute x = 1 in
(13.4), we get
ln(1 + 1) = ln 2 = 1 −1
2 + 1
3 −1
4 · · ·
so the sum of the alternating harmonic series is ln 2.
We can also ﬁnd sums of series from tables or computer, either the exact sum
if that is known, or a numerical approximation (see Problems 20 to 22, and also
Problems 14.2, 16.1, 16.30, and 16.31).
Integrals
By Theorem 1 of Section 11, we may integrate a power series term
by term. Then we can ﬁnd an approximation for an integral when the indeﬁnite
integral cannot be found in terms of elementary functions. As an example, consider
the Fresnel integrals (integrals of sin x2 and cos x2) which occur in the problem of
Fresnel diﬀraction in optics. We ﬁnd

 t
0
sin x2dx =

 t
0

x2 −x6
3! + x10
5! −· · ·

dx
= t3
3 −
t7
7 · 3! +
t11
11 · 5! −· · ·
so for t < 1, the integral is approximately t3
3 −t7
42 with an error < 0.00076 since
this is an alternating series (see (14.3)).
Evaluation of Indeterminate Forms
Suppose we want to ﬁnd
lim
x→0
1 −ex
x
.
If we try to substitute x = 0, we get 0/0. Expressions that lead us to such mean-
ingless results when we substitute are called indeterminate forms. You can evaluate
these by computer, but simple ones can often be done quickly by series. For example,
lim
x→0
1 −ex
x
= lim
x→0
1 −(1 + x + (x2/2!) + · · · )
x
= lim
x→0

−1 −x
2! −· · ·

= −1.

38
Inﬁnite Series, Power Series
Chapter 1
You may recall L’Hˆopital’s rule which says that
lim
x→a
f(x)
φ(x) = lim
x→a
f ′(x)
φ′(x)
when f(a) and φ(a) are both zero, and f ′/φ′ approaches a limit or tends to inﬁnity
(that is, does not oscillate) as x →a. Let’s use power series to see why this is true.
We consider functions f(x) and φ(x) which are expandable in a Taylor series about
x = a, and assume that φ′(a) ̸= 0. Using (12.8), we have
lim
x→a
f(x)
φ(x) = lim
x→a
f(a) + (x −a)f ′(a) + (x −a)2f ′′(a)/2! + · · ·
φ(a) + (x −a)φ′(a) + (x −a)2φ′′(a)/2! + · · ·.
If f(a) = 0 and φ(a) = 0, and we cancel one (x −a) factor, this becomes
lim
x→a
f ′(a) + (x −a)f ′′(a)/2! + · · ·
φ′(a) + (x −a)φ′′(a)/2! + · · · = f ′(a)
φ′(a) = lim
x→a
f ′(x)
φ′(x)
as L’Hˆopital’s rule says. If f ′(a) = 0 and φ′(a) = 0, and φ′′(a) ̸= 0, then a repetition
of the rule gives the limit as f ′′(a)/φ′′(a), and so on.
There are other indeterminate forms besides 0/0, for example, ∞/∞, 0 · ∞,
etc. L’Hˆopital’s rule holds for the ∞/∞form as well as the 0/0 form. Series are
most useful for the 0/0 form or others which can easily be put into the 0/0 form.
For example, the limit limx→0(1/x) sin x is an ∞· 0 form, but is easily written as
limx→0(sin x)/x which is a 0/0 form. Also note carefully: Series (of powers of x) are
useful mainly in ﬁnding limits as x →0, because for x = 0 such a series collapses
to the constant term; for any other value of x we have an inﬁnite series whose sum
we probably do not know (see Problem 25, however).
Series Approximations
When a problem in, say, diﬀerential equations or physics
is too diﬃcult in its exact form, we often can get an approximate answer by replac-
ing one or more of the functions in the problem by a few terms of its inﬁnite series.
We shall illustrate this idea by two examples.
Example 3.
In elementary physics we ﬁnd that the equation of motion of a simple pen-
dulum is (see Chapter 11, Section 8, or a physics textbook):
d2θ
dt2 = −g
l sin θ.
This diﬀerential equation cannot be solved for θ in terms of elementary functions
(see Chapter 11, Section 8), and you may recall that what is usually done is to
approximate sin θ by θ. Recall the inﬁnite series (13.1) for sin θ; θ is simply the ﬁrst
term of the series for sin θ. (Remember that θ is in radians; see discussion in Chapter
2, end of Section 3.) For small values of θ (say θ < 1
2 radian or about 30◦), this
series converges rapidly, and using the ﬁrst term gives a good approximation (see
Problem 14.4). The solutions of the diﬀerential equation are then θ = A sin

g/l t
and θ = B cos

g/l t (A and B constants) as you can verify; we say that the
pendulum is executing simple harmonic motion (see Chapter 7, Section 2).

Section 15
Some Uses of Series
39
Example 4.
Let us consider a radioactive substance containing N0 atoms at t = 0. It is
known that the number of atoms remaining at a later time t is given by the formula
(see Chapter 8, Section 3):
(15.1)
N = N0e−λt
where λ is a constant which is characteristic of the radioactive substance. To ﬁnd λ
for a given substance, a physicist measures in the laboratory the number of decays
∆N during the time interval ∆t for a succession of ∆t intervals. It is customary
to plot each value of ∆N/∆t at the midpoint of the corresponding time interval
∆t. If λ ∆t is small, this graph is a good approximation to the exact dN/dt graph.
A better approximation can be obtained by plotting ∆N/∆t a little to the left of
the midpoint. Let us show that the midpoint does give a good approximation and
also ﬁnd the more accurate t value. (An approximate value of λ, good enough for
calculating the correction, is assumed known from a rough preliminary graph.)
What we should like to plot is the
graph of dN/dt, that is, the graph of the
slope of the curve in Figure 15.1. What
we measure is the value of ∆N/∆t for
each ∆t interval. Consider one such ∆t
interval in Figure 15.1, from t1 to t2.
To get an accurate graph we should plot
the measured value of the quotient
∆N/∆t at the point between t1 and t2
where ∆N/∆t = dN/dt. Let us write
this condition and ﬁnd the t which sat-
isﬁes it. The quantity ∆N is the change
in N, that is, N(t2) −N(t1); the value
of dN/dt we get from (15.1).
Then
dN/dt = ∆N/∆t becomes
Figure 15.1
(15.2)
−λN0e−λt = N0e−λt2 −N0e−λt1
∆t
.
Multiplying this equation by (∆t/N0)eλ(t1+t2)/2, we get
(15.3)
−λ ∆t e−λ[t−(t1+t2)/2] = e−λ(t2−t1)/2 −eλ(t2−t1)/2 = e−λ ∆t/2 −eλ ∆t/2
since t2 −t1 = ∆t. Since we assumed λ ∆t to be small, we can expand the expo-
nentials on the right-hand side of (15.3) in power series; this gives
(15.4)
−λ ∆t e−λ[t−(t1+t2)/2] = −λ ∆t −1
3
λ ∆t
2
3
· · ·
or, canceling (−λ ∆t),
(15.5)
e−λ[t−(t1+t2)/2] = 1 + 1
24(λ ∆t)2 · · · .
Suppose λ ∆t is small enough so that we can neglect the term
1
24(λ ∆t)2. Then

40
Inﬁnite Series, Power Series
Chapter 1
(15.5) reduces to
e−λ[t−(t1+t2)/2] = 1,
−λ

t −t1 + t2
2

= 0,
t = t1 + t2
2
.
Thus we have justiﬁed the usual practice of plotting ∆N/∆t at the midpoint of the
interval ∆t.
Next consider a more accurate approximation. From (15.5) we get
−λ

t −t1 + t2
2

= ln

1 + 1
24(λ ∆t)2 · · ·

.
Since
1
24(λ ∆t)2 ≪1, we can expand the logarithm by (13.4) to get
−λ

t −t1 + t2
2

= 1
24(λ ∆t)2 · · · .
Then we have
t = t1 + t2
2
−
1
24λ(λ ∆t)2 · · · .
Thus the measured ∆N/∆t should be plotted a little to the left of the midpoint of
∆t, as we claimed.
PROBLEMS, SECTION 15
In Problems 1 to 4, use power series to evaluate the function at the given point. Compare
with computer results, using the computer to ﬁnd the series, and also to do the problem
without series. Resolve any disagreement in results (see Example 1).
1.
earc sin x + ln
„1 −x
e
«
at x = 0.0003
2.
1
√
1 + x4 −cos x2
at x = 0.012
3.
ln
“
x +
p
1 + x2
”
−sin x
at x = 0.001
4.
esin x −(1/x3) ln(1 + x3ex)
at x = 0.00035
Use Maclaurin series to evaluate each of the following. Although you could do them by
computer, you can probably do them in your head faster than you can type them into the
computer. So use these to practice quick and skillful use of basic series to make simple
calculations.
5.
d4
dx4 ln(1 + x3)
at x = 0
6.
d3
dx3
„ x2ex
1 −x
«
at x = 0
7.
d10
dx10 (x8 tan2 x)
at x = 0

Section 15
Some Uses of Series
41
8.
lim
x→0
1 −cos x
x2
9.
lim
x→0
sin x −x
x3
10.
lim
x→0
1 −ex3
x3
11.
lim
x→0
sin2 2x
x2
12.
lim
x→0
tan x −x
x3
13.
lim
x→0
ln(1 −x)
x
Find a two term approximation for each of the following integrals and an error bound for
the given t interval.
14.
Z t
0
e−x2 dx,
0 < t < 0.1
15.
Z t
0
√x e−x dx,
0 < t < 0.01
Find the sum of each of the following series by recognizing it as the Maclaurin series for a
function evaluated at a point.
16.
∞
X
n=1
2n
n!
17.
∞
X
n=0
(−1)n
(2n)!
“π
2
”2n
18.
∞
X
n=1
1
n 2n
19.
∞
X
n=0
„−1/2
n
« „
−1
2
«n
20.
By computer or tables, ﬁnd the exact sum of each of the following series.
(a)
∞
X
n=1
n
(4n2 −1)2
(b)
∞
X
n=1
n3
n!
(c)
∞
X
n=1
n(n + 1)
3n
21.
By computer, ﬁnd a numerical approximation for the sum of each of the following
series.
(a)
∞
X
n=1
n
(n2 + 1)2
(b)
∞
X
n=2
ln n
n2
(c)
∞
X
n=1
1
nn
22.
The series P∞
n=1 1/ns, s > 1, is called the Riemann Zeta function, ζ(s). (In Prob-
lem 14.2(a) you found ζ(2) = π2/6. When n is an even integer, these series can be
summed exactly in terms of π.) By computer or tables, ﬁnd
(a)
ζ(4) =
∞
X
n=1
1
n4
(b)
ζ(3) =
∞
X
n=1
1
n3
(c)
ζ
„3
2
«
=
∞
X
n=1
1
n3/2
23.
Find the following limits using Maclaurin series and check your results by computer.
Hint: First combine the fractions. Then ﬁnd the ﬁrst term of the denominator series
and the ﬁrst term of the numerator series.
(a)
lim
x→0
„ 1
x −
1
ex −1
«
(b)
lim
x→0
„ 1
x2 −cos x
sin2 x
«
(c)
lim
x→0
„
csc2 x −1
x2
«
(d)
lim
x→0
„ln(1 + x)
x2
−1
x
«
24.
Evaluate the following indeterminate forms by using L’Hˆopital’s rule and check your
results by computer. (Note that Maclaurin series would not be useful here because
x does not tend to zero, or because a function (ln x, for example) is not expandable
in a Maclaurin series.)
(a)
lim
x→π
x sin x
x −π
(b)
lim
x→π/2
ln(2 −sin x)
ln(1 + cos x)
(c)
lim
x→1
ln(2 −x)
x −1
(d)
lim
x→∞
ln x
√x
(e)
lim
x→0 x ln 2x

42
Inﬁnite Series, Power Series
Chapter 1
(f)
lim
x→∞xne−x
(n not necessarily integral)
25.
In general, we do not expect Maclaurin series to be useful in evaluating indeter-
minate forms except when x tends to zero (see Problem 24). Show, however, that
Problem 24(f) can be done by writing xne−x = xn/ex and using the series (13.3)
for ex. Hint: Divide numerator and denominator by xn before you take the limit.
What is special about the ex series which makes it possible to know what the limit
of the inﬁnite series is?
26.
Find the values of several derivatives of e−1/t2 at t = 0. Hint: Calculate a few
derivatives (as functions of t); then make the substitution x = 1/t2, and use the
result of Problem 24(f) or 25.
27.
The velocity v of electrons from a high energy accelerator is very near the velocity c
of light. Given the voltage V of the accelerator, we often want to calculate the ratio
v/c. The relativistic formula for this calculation is (approximately, for V ≫1)
v
c =
s
1 −
„0.511
V
«2
,
V = number of million volts.
Use two terms of the binomial series (13.5) to ﬁnd 1 −v/c in terms of V . Use your
result to ﬁnd 1 −v/c for the following values of V . Caution: V = the number of
million volts.
(a)
V = 100 million volts
(b)
V = 500 million volts
(c)
V = 25, 000 million volts
(d)
V = 100 gigavolts (100×109 volts = 105 million volts)
28.
The energy of an electron at speed v in special relativity theory is mc2(1−v2/c2)−1/2,
where m is the electron mass, and c is the speed of light. The factor mc2 is called
the rest mass energy (energy when v = 0). Find two terms of the series expansion
of (1 −v2/c2)−1/2, and multiply by mc2 to get the energy at speed v. What is the
second term in the energy series? (If v/c is very small, the rest of the series can be
neglected; this is true for everyday speeds.)
29.
The ﬁgure shows a heavy weight suspended by a cable and pulled
to one side by a force F. We want to know how much force F is
required to hold the weight in equilibrium at a given distance x to
one side (say to place a cornerstone correctly). From elementary
physics, T cos θ = W , and T sin θ = F.
(a)
Find F/W as a series of powers of θ.
(b)
Usually in a problem like this, what we know is not θ, but x
and l in the diagram. Find F/W as a series of powers of x/l.
30.
Given a strong chain and a convenient tree, could you pull your car out of a ditch
in the following way?
Fasten the chain to the car and to the tree.
Pull with a
force F at the center of the chain as shown in the ﬁgure. From mechanics, we have
F = 2T sin θ, or T = F/(2 sin θ), where T is the tension in the chain, that is, the
force exerted on the car.

Section 16
Some Uses of Series
43
(a)
Find T as x−1 times a series of powers of x.
(b)
Find T as θ−1 times a series of powers of θ.
31.
A tall tower of circular cross section is reinforced by horizontal circular disks (like
large coins), one meter apart and of negligible thickness. The radius of the disk at
height n is 1/(n ln n) (n ≥2).
Assuming that the tower is of inﬁnite height:
(a)
Will the total area of the disks be ﬁnite or not? Hint: Can you compare the
series with a simpler one?
(b)
If the disks are strengthened by wires going around their circumferences like
tires, will the total length of wire required be ﬁnite or not?
(c)
Explain why there is not a contradiction between your answers in (a) and (b).
That is, how is it possible to start with a set of disks of ﬁnite area, remove a
little strip around the circumference of each, and get an inﬁnite total length
of these strips? Hint: Think about units—you can’t compare area and length.
Consider two cases: (1) Make the width of each strip equal to one percent of
the radius of the disk from which you cut it. Now the total length is inﬁnite
but what about the total area? (2) Try to make the strips all the same width;
what happens? Also see Chapter 5, Problem 3.31(b).
32.
Show that the “doubling time” (time for your money to double) is n periods at
interest rate i% per period with ni = 69, approximately. Show that the error in the
approximation is less than 10% if i% ≤20%. (Note that n does not have to be the
number of years; it can be the number of months with i = interest rate per month,
etc.) Hint: You want (1 + i/100)n = 2; take ln of both sides of this equation and
use equation (13.4). Also see theorem (14.3).
33.
If you are at the top of a tower of height h above the surface
of the earth, show that the distance you can see along the
surface of the earth is approximately s =
√
2Rh, where R is
the radius of the earth. Hints: See ﬁgure. Show that h/R =
sec θ −1; ﬁnd two terms of the series for sec θ = 1/ cos θ,
and use s = Rθ. Thus show that the distance in miles is
approximately
p
3h/2 with h in feet.

44
Inﬁnite Series, Power Series
Chapter 1
16. MISCELLANEOUS PROBLEMS
1.
(a)
Show that it is possible to stack a pile of identical books so that the top book
is as far as you like to the right of the bottom book. Start at the top and
each time place the pile already completed on top of another book so that
the pile is just at the point of tipping. (In practice, of course, you can’t let
them overhang quite this much without having the stack topple. Try it with
a deck of cards.) Find the distance from the right-hand end of each book to
the right-hand end of the one beneath it. To ﬁnd a general formula for this
distance, consider the three forces acting on book n, and write the equation for
the torque about its right-hand end. Show that the sum of these setbacks is a
divergent series (proportional to the harmonic series). [See “Leaning Tower of
The Physical Reviews,” Am. J. Phys. 27, 121–122 (1959).]
(b)
By computer, ﬁnd the sum of N terms of the harmonic series with N = 25,
100, 200, 1000, 106, 10100.
(c)
From the diagram in (a), you can see that with 5 books (count down from the
top) the top book is completely to the right of the bottom book, that is, the
overhang is slightly over one book. Use your series in (a) to verify this. Then
using parts (a) and (b) and a computer as needed, ﬁnd the number of books
needed for an overhang of 2 books, 3 books, 10 books, 100 books.
2.
The picture is a mobile constructed of
dowels (or soda straws) connected by
thin threads. Each thread goes from
the left-hand end of a rod to a point
on the rod below.
Number the rods
from the bottom and ﬁnd, for rod n,
the distance from its left end to the
thread so that all rods of the mobile
will be horizontal. Hint: Can you see
the relation between this problem and
Problem 1?
3.
Show that P∞
n=2 1/n3/2 is convergent. What is wrong with the following “proof”
that it diverges?
1
√
8
+
1
√
27
+
1
√
64
+
1
√
125
+ · · · >
1
√
9
+
1
√
36
+
1
√
81
+
1
√
144
+ · · ·
which is
1
3 + 1
6 + 1
9 + 1
12 + · · · = 1
3
„
1 + 1
2 + 1
3 + 1
4 + · · ·
«
.
Since the harmonic series diverges, the original series diverges. Hint: Compare 3n
and n√n.
Test for convergence:
4.
∞
X
n=1
2n
n!
5.
∞
X
n=2
(n −1)2
1 + n2
6.
∞
X
n=2
√n −1
(n + 1)2 −1
7.
∞
X
n=2
1
n ln(n3)
8.
∞
X
n=2
2n3
n4 −2

Section 16
Miscellaneous Problems
45
Find the interval of convergence, including end-point tests:
9.
∞
X
n=1
xn
ln(n + 1)
10.
∞
X
n=1
(n!)2xn
(2n)!
11.
∞
X
n=1
(−1)nx2n−1
2n −1
12.
∞
X
n=1
xnn2
5n(n2 + 1)
13.
∞
X
n=1
(x + 2)n
(−3)n√n
Find the Maclaurin series for the following functions.
14.
cos[ln(1 + x)]
15.
ln
„sin x
x
«
16.
1
√
1 + sin x
17.
e1−√
1−x2
18.
arc tan x =
Z x
0
du
1 + u2
Find the ﬁrst few terms of the Taylor series for the following functions about the given
points.
19.
sin x, a = π
20.
3√x, a = 8
21.
ex, a = 1
Use series you know to show that:
22.
1 −1
3 + 1
5 −1
7 + · · · = π
4 .
Hint: See Problem 18.
23.
π2
3! −π4
5! + π6
7! −· · · = 1
24.
ln 3 + (ln 3)2
2!
+ (ln 3)3
3!
+ · · · = 2
25.
Evaluate the limit limx→0 x2/ ln cos x by series (in your head), by L’Hˆopital’s rule,
and by computer.
Use Maclaurin series to do Problems 26 to 29 and check your results by computer.
26.
lim
x→0
„ 1
x2 −
1
1 −cos2 x
«
27.
lim
x→0
„ 1
x2 −cot2 x
«
28.
lim
x→0
„1 + x
x
−
1
sin x
«
29.
d6
dx6 (x4ex2)
˛˛˛˛
x=0
30.
(a)
It is clear that you (or your computer) can’t ﬁnd the sum of an inﬁnite se-
ries just by adding up the terms one by one. For example, to get ζ(1.1) =
P∞
n=1 1/n1.1 (see Problem 15.22) with error < 0.005 takes about 1033 terms.
To see a simple alternative (for a series of positive decreasing terms) look at
Figures 6.1 and 6.2. Show that when you have summed N terms, the sum RN
of the rest of the series is between IN =
R ∞
N an dn and IN+1 =
R ∞
N+1 an dn.
(b)
Find the integrals in (a) for the ζ(1.1) series and verify the claimed number of
terms needed for error < 0.005. Hint: Find N such that IN = 0.005. Also ﬁnd
upper and lower bounds for ζ(1.1) by computing PN
n=1 1/n1.1 +
R ∞
N n−1.1 dn
and PN
n=1 1/n1.1 +
R ∞
N+1 n−1.1 dn where N is far less than 1033. Hint: You
want the diﬀerence between the upper and lower limits to be about 0.005; ﬁnd
N so that term aN = 0.005.
31.
As in Problem 30, for each of the following series, ﬁnd the number of terms required
to ﬁnd the sum with error < 0.005, and ﬁnd upper and lower bounds for the sum
using a much smaller number of terms.
(a)
∞
X
1
1
n1.01
(b)
∞
X
1
1
n(1 + ln n)2
(c)
∞
X
3
1
n ln n(ln ln n)2

C H A P T E R 2
Complex Numbers
1. INTRODUCTION
You will probably recall using imaginary and complex numbers in algebra. The
general solution of the quadratic equation
(1.1)
az2 + bz + c = 0
for the unknown z, is given by the quadratic formula
(1.2)
z = −b ±
√
b2 −4ac
2a
.
If the discriminant d = (b2 −4ac) is negative, we must take the square root of
a negative number in order to ﬁnd z. Since only non-negative numbers have real
square roots, it is impossible to use (1.2) when d < 0 unless we introduce a new
kind of number, called an imaginary number. We use the symbol i = √−1 with the
understanding that i2 = −1. Then
√
−16 = 4i,
√
−3 = i
√
3,
i3 = −i
are imaginary numbers, but
i2 = −1,
√
−2
√
−8 = i
√
2 · i
√
8 = −4,
i4n = 1
are real. In (1.2) we also need combinations of real and imaginary numbers.
Example.
The solution of
z2 −2z + 2 = 0
is
z = 2 ± √4 −8
2
= 2 ± √−4
2
= 1 ± i.
We use the term complex number to mean any one of the whole set of numbers,
real, imaginary, or combinations of the two like 1 ± i. Thus, i + 5, 17i, 4, 3 + i
√
5
are all examples of complex numbers.
46

Section 3
The Complex Plane
47
Once the new kind of number is admitted into our number system, fascinating
possibilities open up. Can we attach any meaning to marks like sin i, eiπ, ln(1 + i)?
We’ll see later that we can and that, in fact, such expressions may turn up in
problems in physics, chemistry, and engineering, as well as mathematics.
When people ﬁrst considered taking square roots of negative numbers, they felt
very uneasy about the problem. They thought that such numbers could not have
any meaning or any connection with reality (hence the term “imaginary”). They
certainly would not have believed that the new numbers could be of any practical
use. Yet complex numbers are of great importance in a variety of applied ﬁelds; for
example, the electrical engineer would, to say the least, be severely handicapped
without them. The complex notation often simpliﬁes setting up and solving vibra-
tion problems in either dynamical or electrical systems, and is useful in solving many
diﬀerential equations which arise from problems in various branches of physics. (See
Chapters 7 and 8.) In addition, there is a highly developed ﬁeld of mathematics
dealing with functions of a complex variable (see Chapter 14) which yields many
useful methods for solving problems about ﬂuid ﬂow, elasticity, quantum mechanics,
and other applied problems. Almost every ﬁeld of either pure or applied mathe-
matics makes some use of complex numbers.
2. REAL AND IMAGINARY PARTS OF A COMPLEX NUMBER
A complex number such as 5 + 3i is the sum of two terms. The real term (not
containing i) is called the real part of the complex number. The coeﬃcient of i in
the other term is called the imaginary part of the complex number. In 5 + 3i, 5 is
the real part and 3 is the imaginary part. Notice carefully that the imaginary part
of a complex number is not imaginary!
Either the real part or the imaginary part of a complex number may be zero.
If the real part is zero, the complex number is called imaginary (or, for emphasis,
pure imaginary). The zero real part is usually omitted; thus 0 + 5i is written just
5i. If the imaginary part of the complex number is zero, the number is real. We
write 7 + 0i as just 7. Complex numbers then include both real numbers and pure
imaginary numbers as special cases.
In algebra a complex number is ordinarily written (as we have been doing) as a
sum like 5 + 3i. There is another very useful way of thinking of a complex number.
As we have said, every complex number has a real part and an imaginary part
(either of which may be zero). These are two real numbers, and we could, if we
liked, agree to write 5+3i as (5, 3). Any complex number could be written this way
as a pair of real numbers, the real part ﬁrst and then the imaginary part (which, you
must remember, is real). This would not be a very convenient form for computation,
but it suggests a very useful geometrical representation of a complex number which
we shall now consider.
3. THE COMPLEX PLANE
In analytic geometry we plot the point (5, 3) as shown in Figure 3.1. As we have
seen, the symbol (5, 3) could also mean the complex number 5+3i. The point (5, 3)
may then be labeled either (5, 3) or 5+3i. Similarly, any complex number x+iy (x
and y real) can be represented by a point (x, y) in the (x, y) plane. Also any point
(x, y) in the (x, y) plane can be labeled x + iy as well as (x, y). When the (x, y)

48
Complex Numbers
Chapter 2
plane is used in this way to plot complex numbers, it is called the complex plane. It
is also sometimes called an Argand diagram. The x axis is called the real axis, and
the y axis is called the imaginary axis (note, however, that you plot y and not iy).
Figure 3.1
When a complex number is written in the form x + iy, we say that it is in
rectangular form because x and y are the rectangular coordinates of the point
representing the number in the complex plane. In analytic geometry, we can locate
a point by giving its polar coordinates (r, θ) instead of its rectangular coordinates
(x, y). There is a corresponding way to write any complex number. In Figure 3.2,
x = r cos θ,
y = r sin θ.
(3.1)
Then we have
x + iy = r cos θ + ir sin θ
= r (cos θ + i sin θ).
(3.2)
Figure 3.2
This last expression is called the polar form of the complex number. As we shall
see (Sections 9 to 16), the expression (cos θ + i sin θ) can be written as eiθ, so a
convenient way to write the polar form of a complex number is
(3.3)
x + iy = r(cos θ + i sin θ) = reiθ.
The polar form reiθ of a complex number
is often simpler to use than the rectangu-
lar form.
Example.
In Figure 3.3 the point A could be
labeled as (1,
√
3) or as 1 + i
√
3.
Simi-
larly, using polar coordinates, the point
A could be labeled with its (r, θ) values
as (2, π/3). Notice that r is always taken
positive. Using (3.3) we have
1 + i
√
3 = 2

cos π
3 + i sin π
3

= 2eiπ/3.
This gives two more ways to label point
A in Figure 3.3.
Figure 3.3

Section 4
Terminology and Notation
49
Radians and Degrees
In Figure 3.3, the angle π/3 is in radians. Ever since
you studied calculus, you have been expected to measure angles in radians and not
degrees. Do you know why? You have learned that (d/dx) sin x = cos x.
This
formula is not correct—unless x is in radians. (Look up the derivation in your
calculus book!) Many of the formulas you now know and use are correct only if
you use radian measure; consequently that is what you are usually advised to do.
However, it is sometimes convenient to do computations with complex numbers
using degrees, so it is important to know when you can and when you cannot use
degrees. You can use degrees to measure an angle and to add and subtract angles
as long as the ﬁnal step is to ﬁnd the sine, cosine, or tangent of the resulting angle
(with your calculator in degree mode). For example, in Figure 3.3, we can, if we like,
say that θ = 60◦instead of θ = π/3. If we want to ﬁnd sin(π/3−π/4) = sin(π/12) =
0.2588 (calculator in radian mode), we can instead ﬁnd sin(60◦−45◦) = sin 15◦=
0.2588 (calculator in degree mode). Note carefully that an angle is in radians unless
the degree symbol is used; for example, in sin 2, the 2 is 2 radians or about 115◦.
In formulas, however, use radians. For example, in using inﬁnite series, we say
that sin θ ∼= θ for very small θ.
Try this on your calculator; you will ﬁnd that
it is true in radian mode but not in degree mode. As another example, consider
 1
0 dx/(1 + x2) = arc tan 1 = π/4 = 0.785. Here arc tan 1 is not an angle; it is the
numerical value of the integral, so the answer 45 (obtained from a calculator in
degree mode) is wrong! Do not use degree mode in reading an arc tan (or arc sin or
arc cos) unless you are ﬁnding an angle [for example, in Figure 3.2, θ = arc tan(y/x),
and in Figure 3.3, θ = arc tan
√
3 = π/3 or 60◦].
4. TERMINOLOGY AND NOTATION
Both i and j are used to represent √−1, j usually in any problem dealing with
electricity since i is needed there for current. A physicist should be able to work
with ease using either symbol. We shall for consistency use i throughout this book.
We often label a point with a single letter (for example, P in Figure 3.2 and A
in Figure 3.3) even though it requires two coordinates to locate the point. If you
have studied vectors, you will recall that a vector is represented by a single letter,
say v, although it has (in two dimensions) two components. It is customary to use
a single letter for a complex number even though we realize that it is actually a pair
of real numbers. Thus we write
(4.1)
z = x + iy = r(cos θ + i sin θ) = reiθ.
Here z is a complex number; x is the real part of the complex number z, and y is
the imaginary part of z. The quantity r is called the modulus or absolute value of
z, and θ is called the angle of z (or the phase, or the argument, or the amplitude of
z). In symbols:
Re z = x,
|z| = mod z = r =

x2 + y2,
Im z = y (not iy),
angle of z = θ.
(4.2)

50
Complex Numbers
Chapter 2
The values of θ should be found from a diagram rather than a formula, although
we do sometimes write θ = arc tan(y/x). An example shows this clearly.
Example.
Write z = −1−i in polar form. Here we have x = −1, y = −1, r =
√
2 (Figure
4.1). There are an inﬁnite number of values of θ,
(4.3)
θ = 5π
4 + 2nπ,
Figure 4.1
where n is any integer, positive or negative. The
value θ = 5π/4 is sometimes called the principal
angle of the complex number z = −1 −i. Notice
carefully, however, that this is not the same as
the principal value π/4 of arc tan1 as deﬁned in
calculus. The angle of a complex number must be
in the same quadrant as the point representing the number. For our present work,
any one of the values in (4.3) will do; here we would probably use either 5π/4 or
−3π/4. Then we have in our example
z = −1 −i =
√
2

cos
5π
4 + 2nπ

+ i sin
5π
4 + 2nπ

=
√
2

cos 5π
4 + i sin 5π
4

=
√
2 e5iπ/4.
[We could also write z =
√
2 (cos 225◦+ i sin 225◦).]
The complex number x −iy, obtained by changing the sign of i in z = x + iy,
is called the complex conjugate or simply the conjugate of z. We usually write the
conjugate of z = x + iy as ¯z = x −iy. Sometimes we use z∗instead of ¯z (in ﬁelds
such as statistics or quantum mechanics where the bar may be used to mean an
average value). Notice carefully that the conjugate of 7i −5 is −7i −5; that is, it
is the i term whose sign is changed.
Figure 4.2
Complex numbers come in conjugate pairs; for
example, the conjugate of 2 + 3i is 2 −3i and the
conjugate of 2−3i is 2+3i. Such a pair of points in
the complex plane are mirror images of each other
with the x axis as the mirror (Figure 4.2). Then
in polar form, z and ¯z have the same r value, but
their θ values are negatives of each other. If we
write z = r(cos θ + i sin θ), then
(4.4)
¯z = r[cos(−θ) + i sin(−θ)] = r(cos θ −i sin θ) = re−iθ.
PROBLEMS, SECTION 4
For each of the following numbers, ﬁrst visualize where it is in the complex plane. With a
little practice you can quickly ﬁnd x, y, r, θ in your head for these simple problems. Then

Section 5
Complex Algebra
51
plot the number and label it in ﬁve ways as in Figure 3.3. Also plot the complex conjugate
of the number.
1.
1 + i
2.
i −1
3.
1 −i
√
3
4.
−
√
3 + i
5.
2i
6.
−4i
7.
−1
8.
3
9.
2i −2
10.
2 −2i
11.
2
“
cos π
6 + i sin π
6
”
12.
4
„
cos 2π
3 −i sin 2π
3
«
13.
cos 3π
2 + i sin 3π
2
14.
2
“
cos π
4 + i sin π
4
”
15.
cos π −i sin π
16.
5(cos 0 + i sin 0)
17.
√
2 e−iπ/4
18.
3 eiπ/2
19.
5(cos 20◦+ i sin 20◦)
20.
7(cos 110◦−i sin 1100)
5. COMPLEX ALGEBRA
A.
Simplifying to x+iy form
Any complex number can be written in the rectangular form x + iy.
To add,
subtract, and multiply complex numbers, remember that they follow the ordinary
rules of algebra and that i2 = −1.
Example 1.
(1 + i)2 = 1 + 2i + i2 = 1 + 2i −1 = 2i
To divide one complex number by another, ﬁrst write the quotient as a fraction.
Then reduce the fraction to rectangular form by multiplying numerator and denom-
inator by the conjugate of the denominator; this makes the denominator real.
Example 2.
2 + i
3 −i = 2 + i
3 −i · 3 + i
3 + i = 6 + 5i + i2
9 −i2
= 5 + 5i
10
= 1
2 + 1
2i.
It is sometimes easier to multiply or divide complex numbers in polar form.
Example 3.
To ﬁnd (1 + i)2 in polar form, we ﬁrst sketch (or picture mentally) the point
(1, 1). From Figure 5.1, we see that r =
√
2, and θ = π/4, so (1 + i) =
√
2 eiπ/4.
Then from Figure 5.2 we ﬁnd the same result as in Example 1.
(1 + i)2 = (
√
2 eiπ/4)2 = 2 eiπ/2 = 2i.
Figure 5.1
Figure 5.2

52
Complex Numbers
Chapter 2
Example 4.
Write 1/[2(cos20◦+ i sin 20◦] in x + iy form. Since 20◦= π/9 radians,
1
2(cos20◦+ i sin 20◦) =
1
2(cos π/9 + i sin π/9) =
1
2 eiπ/9 = 0.5 e−iπ/9
= 0.5(cos π/9 −i sin π/9) = 0.47 −0.17i,
by calculator in radian mode. We obtain the same result leaving the angle in degrees
and using a calculator in degree mode: 0.5(cos20◦−i sin 20◦) = 0.47 −0.17i.
PROBLEMS, SECTION 5
First simplify each of the following numbers to the x + iy form or to the reiθ form. Then
plot the number in the complex plane.
1.
1
1 + i
2.
1
i −1
3.
i4
4.
i2 + 2i + 1
5.
“
i +
√
3
”2
6.
„1 + i
1 −i
«2
7.
3 + i
2 + i
8.
1.6 −2.7i
9.
25 e2i
Careful! The angle is 2 radians.
10.
3i −7
i + 4
Careful! Not 3 −7i
11.
17 −12i
12.
3(cos 28◦+ i sin 28◦)
13.
5
„
cos 2π
5 + i sin 2π
5
«
14.
2.8e−i(1.1)
15.
5 −2i
5 + 2i
16.
1
0.5(cos 40◦+ i sin 40◦)
17.
(1.7 −3.2i)2
18.
(0.64 + 0.77i)4
Find each of the following in rectangular (a + bi) form if z = 2 −3i; if z = x + iy.
19.
z−1
20.
1
z2
21.
1
z + 1
22.
1
z −i
23.
1 + z
1 −z
24.
z/¯z
B.
Complex Conjugate of a Complex Expression
It is easy to see that the conjugate of the sum of two complex numbers is the sum
of the conjugates of the numbers. If
z1 = x1 + iy1
and
z2 = x2 + iy2,
then
¯z1 + ¯z2 = x1 −iy1 + x2 −iy2 = x1 + x2 −i(y1 + y2).
The conjugate of (z1 + z2) is
(x1 + x2) + i(y1 + y2) = (x1 + x2) −i(y1 + y2).

Section 5
Complex Algebra
53
Similarly, you can show that the conjugate of the diﬀerence (or product or quotient)
of two complex numbers is equal to the diﬀerence (or product or quotient) of the
conjugates of the numbers (Problem 25). In other words, you can get the conjugate
of an expression containing i’s by just changing the signs of all the i terms. We
must watch out for hidden i’s, however.
Example.
If
z = 2 −3i
i + 4 ,
then
¯z = 2 + 3i
−i + 4.
But if z = f+ig, where f and g are themselves complex, then the complex conjugate
of z is ¯z = ¯f −i¯g (not f −ig).
PROBLEMS, SECTION 5
25.
Prove that the conjugate of the quotient of two complex numbers is the quotient of
the conjugates. Also prove the corresponding statements for diﬀerence and product.
Hint: It is easier to prove the statements about product and quotient using the
polar coordinate reiθ form; for the diﬀerence, it is easier to use the rectangular form
x + iy.
C.
Finding the Absolute Value of z
Recall that the deﬁnition of |z| is |z| = r =

x2 + y2
(positive square root!).
Since z¯z = (x+iy)(x−iy) = x2 +y2, or, in polar coordinates, z¯z = (reiθ)(re−iθ) =
r2, we see that |z|2 = z¯z, or |z| = √z¯z. Note that z¯z is always real and ≥0, since
x, y, and r are real. We have
(5.1)
|z| = r =

x2 + y2 =
√
z¯z.
By Problem 25 and (5.1), the absolute value of a quotient of two complex numbers
is the quotient of the absolute values (and a similar statement for product).
Example.
					
√
5 + 3i
1 −i
					 = |
√
5 + 3i|
|1 −i|
=
√
14
√
2 =
√
7.
PROBLEMS, SECTION 5
Find the absolute value of each of the following using the discussion above. Try to do
simple problems like these in your head—it saves time.
26.
2i −1
i −2
27.
2 + 3i
1 −i
28.
z
¯z
29.
(1 + 2i)3
30.
3i
i −
√
3
31.
5 −2i
5 + 2i
32.
(2 −3i)4
33.
25
3 + 4i
34.
„1 + i
1 −i
«5

54
Complex Numbers
Chapter 2
D.
Complex Equations
In working with equations involving complex quantities, we must always remember
that a complex number is actually a pair of real numbers. Two complex numbers
are equal if and only if their real parts are equal and their imaginary parts are equal.
For example, x + iy = 2 + 3i means x = 2 and y = 3. In other words, any equation
involving complex numbers is really two equations involving real numbers.
Example.
Find x and y if
(5.2)
(x + iy)2 = 2i.
Since (x + iy)2 = x2 + 2ixy −y2, (5.2) is equivalent to the two real equations
x2 −y2 = 0,
2xy = 2.
From the ﬁrst equation y2 = x2, we ﬁnd y = x or y = −x. Substituting these into
the second equation gives
2x2 = 2
or
−2x2 = 2.
Since x is real, x2 cannot be negative. Thus we ﬁnd only
x2 = 1
and
y = x,
that is,
x = y = 1
and
x = y = −1.
PROBLEMS, SECTION 5
Solve for all possible values of the real numbers x and y in the following equations.
35.
x + iy = 3i −4
36.
2ix + 3 = y −i
37.
x + iy = 0
38.
x + iy = 2i −7
39.
x + iy = y + ix
40.
x + iy = 3i −ix
41.
(2x −3y −5) + i(x + 2y + 1) = 0
42.
(x + 2y + 3) + i(3x −y −1) = 0
43.
(x + iy)2 = 2ix
44.
x + iy = (1 −i)2
45.
(x + iy)2 = (x −iy)2
46.
x + iy
x −iy = −i
47.
(x + iy)3 = −1
48.
x + iy + 2 + 3i
2x + 2iy −3
= i + 2
49.
|1 −(x + iy)| = x + iy
50.
|x + iy| = y −ix
E.
Graphs
Using the graphical representation of the complex number z as the point (x, y) in
a plane, we can give geometrical meaning to equations and inequalities involving z.

Section 5
Complex Algebra
55
Example 1.
What is the curve made up of the points in the (x, y) plane satisfying the
equation |z| = 3?
Since
|z| =

x2 + y2,
the given equation is

x2 + y2 = 3
or
x2 + y2 = 9.
Thus |z| = 3 is the equation of a circle of radius 3 with center at the origin. Such
an equation might describe, for example, the path of an electron or of a satellite.
(See Section F below.)
Example 2.
(a) |z −1| = 2. This is the circle (x −1)2 + y2 = 4.
(b) |z −1| ≤2. This is the disk whose boundary is the circle in (a).
Note that we use “circle” to mean a curve and “disk” to mean an area. The interior
of the disk is given by |z −1| < 2.
Example 3.
(Angle of z) = π/4. This is the half-line y = x with x > 0; this might be the
path of a light ray starting at the origin.
Example 4.
Re z > 1
2. This is the half-plane x > 1
2.
PROBLEMS, SECTION 5
Describe geometrically the set of points in the complex plane satisfying the following
equations.
51.
|z| = 2
52.
Re z = 0
53.
|z −1| = 1
54.
|z −1| < 1
55.
z −¯z = 5i
56.
angle of z = π
2
57.
Re (z2) = 4
58.
Re z > 2
59.
|z + 3i| = 4
60.
|z −1 + i| = 2
61.
Im z < 0
62.
|z + 1| + |z −1| = 8
63.
z2 = ¯z2
64.
z2 = −¯z2
65.
Show that |z1 −z2| is the distance between the points z1 and z2 in the complex
plane. Use this result to identify the graphs in Problems 53, 54, 59, and 60 without
computation.
F.
Physical Applications
Problems in physics as well as geometry may often be simpliﬁed by using one com-
plex equation instead of two real equations. See the following example and also
Section 16.

56
Complex Numbers
Chapter 2
Example.
A particle moves in the (x, y) plane so that its position (x, y) as a function of
time t is given by
z = x + iy = i + 2t
t −i .
Find the magnitudes of its velocity and its acceleration as functions of t.
We could write z in x + iy form and so ﬁnd x and y as functions of t. It is
easier to do the problem as follows. We deﬁne the complex velocity and complex
acceleration by
dz
dt = dx
dt + i dy
dt
and
d2z
dt2 = d2x
dt2 + i d2y
dt2 .
Then the magnitude v of the velocity is v =

(dx/dt)2 + (dy/dt)2 = |dz/dt|, and
similarly the magnitude a of the acceleration is a = |d2z/dt2|. Thus we have
dz
dt = 2(t −i) −(i + 2t)
(t −i)2
=
−3i
(t −i)2 .
v =
				
dz
dt
				 =

−3i
(t −i)2 ·
+3i
(t + i)2 =
3
t2 + 1,
d2z
dt2 = (−3i)(−2)
(t −i)3
=
6i
(t −i)3 ,
a =
				
d2z
dt2
				 =
6
(t2 + 1)3/2 .
Note carefully that all physical quantities (x, y, v, and a) are real; the complex
expressions are used just for convenience in calculation.
PROBLEMS, SECTION 5
66.
Find x and y as functions of t for the example above, and verify for this case that
v and a are correctly given by the method of the example.
67.
Find v and a if z = (1 −it)/(2t + i).
68.
Find v and a if z = cos 2t + i sin 2t. Can you describe the motion?
6. COMPLEX INFINITE SERIES
In Chapter 1 we considered inﬁnite series whose terms were real. We shall be very
much interested in series with complex terms; let us reconsider our deﬁnitions and
theorems for this case. The partial sums of a series of complex numbers will be
complex numbers, say Sn = Xn + iYn, where Xn and Yn are real. Convergence is
deﬁned just as for real series: If Sn approaches a limit S = X + iY as n →∞,
we call the series convergent and call S its sum. This means that Xn →X and
Yn →Y ; in other words, the real and the imaginary parts of the series are each
convergent series.
It is useful, just as for real series, to discuss absolute convergence ﬁrst. It can
be proved (Problem 1) that an absolutely convergent series converges. Absolute
convergence means here, just as for real series, that the series of absolute values of
the terms is a convergent series. Remember that |z| = r =

x2 + y2 is a positive
number.
Thus any of the tests given in Chapter 1 for convergence of series of
positive terms may be used here to test a complex series for absolute convergence.

Section 7
Complex Inﬁnite Series
57
Example 1.
Test for convergence
1 + 1 + i
2
+ (1 + i)2
4
+ (1 + i)3
8
+ · · · + (1 + i)n
2n
+ · · · .
Using the ratio test, we ﬁnd
ρ = lim
n→∞
				
(1 + i)n+1
2n+1
÷ (1 + i)n
2n
				 = lim
n→∞
				
1 + i
2
				 =
				
1 + i
2
				 =
√
2
2
< 1.
. Since ρ < 1, the series is absolutely convergent and therefore convergent.
Example 2.
Test for convergence ∞
1 in/√n. Here the ratio test gives 1 so we must try
a diﬀerent test. Let’s write out a few terms of the series:
i −1
√
2 −
i
√
3 + 1
√
4 +
i
√
5 −1
√
6 · · · .
We see that the real part of the series is
−1
√
2 + 1
√
4 −1
√
6 + · · · =
∞

1
(−1)n
√
2n ,
and the imaginary part of the series is
1 −1
√
3 + 1
√
5 · · · =
∞

0
(−1)n
√2n + 1.
Verify that both these series satisfy the alternating series test for convergence. Thus,
the original series converges.
Example 3.
Test for convergence ∞
0 zn = ∞
0 (reiθ)n = ∞
0 rneinθ. This is a geometric
series with ratio = z = reiθ; it converges if and only if |z| < 1. Recall that |z| = r.
Thus, ∞
0 rneinθ converges if and only if r < 1.
PROBLEMS, SECTION 6
1.
Prove that an absolutely convergent series of complex numbers converges.
This
means to prove that P(an + ibn) converges (an and bn real) if P √a2n + b2n con-
verges. Hint: Convergence of P(an+ibn) means that P an and P bn both converge.
Compare P |an| and P |bn| with P √a2n + b2n, and use Problem 7.9 of Chapter 1.
Test each of the following series for convergence.
2.
X
(1 + i)n
3.
X
1
(1 + i)n
4.
X „1 −i
1 + i
«n
5.
X „ 1
n2 + i
n
«
6.
X 1 + i
n2
7.
X (i −1)n
n
8.
X
einπ/6
9.
X in
n
10.
X „
1 + i
1 −i
√
3
«n
11.
X „ 2 + i
3 −4i
«2n
12.
X (3 + 2i)n
n!
13.
X „1 + i
2 −i
«n
14.
Prove that a series of complex terms diverges if ρ > 1 (ρ = ratio test limit). Hint:
The nth term of a convergent series tends to zero.

58
Complex Numbers
Chapter 2
7. COMPLEX POWER SERIES; DISK OF CONVERGENCE
In Chapter 1 we considered series of powers of x,  anxn. We are now interested
in series of powers of z,
(7.1)

anzn,
where z = x + iy, and the an are complex numbers. [Notice that (7.1) includes real
series as a special case since z = x if y = 0.] Here are some examples.
1 −z + z2
2 −z3
3 + z4
4 + · · · ,
(7.2a)
1 + iz + (iz)2
2!
+ (iz)3
3!
+ · · · = 1 + iz −z2
2! −iz3
3! + · · · ,
(7.2b)
∞

n=0
(z + 1 −i)n
3n n2
.
(7.2c)
Figure 7.1
Let us use the ratio test to ﬁnd for what z these series are absolutely convergent.
For (7.2a), we have
ρ = lim
n→∞
				
z · n
n + 1
				 = |z|.
The series converges if ρ < 1, that is, if |z| < 1, or

x2 + y2 < 1. This is the interior of a disk of radius 1 with
center at the origin in the complex plane. This disk is called
the disk of convergence of the inﬁnite series and the radius of
the disk is called the radius of convergence. The disk of con-
vergence replaces the interval of convergence which we had
for real series. In fact (see Figure 7.1), the interval of con-
vergence for the series (−x)n/n is just the interval (−1, 1)
on the x axis contained within the disk of convergence of
(−z)n/n, as it must be since x is the value of z when y = 0. For this reason we
sometimes speak of the radius of convergence of a power series even though we are
considering only real values of z. (Also see Chapter 14, Equations (2.5) and (2.6)
and Figure 2.4.)
Next consider series (7.2b); here we have
ρ = lim
n→∞
				
(iz)n+1
(n + 1)! ÷ (iz)n
n!
				 = lim
n→∞
				
iz
n + 1
				 = 0.
This is an example of a series which converges for all values
of z. For series (7.2c), we have
ρ = lim
n→∞
				
(z + 1 −i)
3
n2
(n + 1)2
				 =
				
z + 1 −i
3
				 .
Thus, this series converges for
|z + 1 −i| < 3, or |z −(−1 + i)| < 3.
This is the interior of a disk (Figure 7.2) of radius 3 and
center at z = −1 + i (see Problem 5.65).
Figure 7.2

Section 7
Complex Power Series; Disk of Convergence
59
Just as for real series, if ρ > 1, the series diverges (Problem 6.14). For ρ = 1
(that is, on the boundary of the disk of convergence) the series may either converge
or diverge. It may be diﬃcult to ﬁnd out which and we shall not in general need to
consider the question.
The four theorems about power series (Chapter 1, Section 11) are true also for
complex series (replace interval by disk of convergence). Also we can now state for
Theorem 2 what the disk of convergence is for the quotient of two series of powers
of z. Assume to start with that any common factor z has been cancelled. Let r1
and r2 be the radii of convergence of the numerator and denominator series. Find
the closest point to the origin in the complex plane where the denominator is zero;
call the distance from the origin to this point s. Then the quotient series converges
at least inside the smallest of the three disks of radii r1, r2, and s, with center at
the origin. (See Chapter 14, Section 2.)
Example.
Find the disk of convergence of the Maclaurin series for (sin z)/[z(1 + z2)].
We shall soon see that the series for sin z has the same form as the real series
for sin x in Chapter 1. Using this fact we ﬁnd (Problem 17)
(7.3)
sin z
z(1 + z2) = 1 −7z2
6
+ 47z4
40
−5923z6
5040
+ · · · .
From (7.3) we can’t ﬁnd the radius of convergence, but let’s use the theorem above.
Let the numerator series be (sin z)/z. By ratio test, the series for (sin z)/z converges
for all z (if you like, r1 = ∞). There is no r2 since the denominator is not an inﬁnite
series. The denominator 1 + z2 is zero when z = ±i, so s = 1. Then the series (7.3)
converges inside a disk of radius 1 with center at the origin.
PROBLEMS, SECTION 7
Find the disk of convergence for each of the following complex power series.
1.
ez = 1 + z + z2
2! + z3
3! · · ·
[equation (8.1)]
2.
z −z2
2 + z3
3 −z4
4 + · · · 3.
1 −z2
3! + z4
5! −· · ·
4.
∞
X
n=0
zn
5.
∞
X
n=0
“z
2
”n
6.
∞
X
n=1
n2(3iz)n
7.
∞
X
n=0
(−1)nz2n
(2n)!
8.
∞
X
n=1
z2n
(2n + 1)!
9.
∞
X
n=1
zn
√n
10.
∞
X
n=1
(iz)n
n2
11.
∞
X
n=0
(n!)3zn
(3n)!
12.
∞
X
n=0
(n!)2zn
(2n)!
13.
∞
X
n=1
(z −i)n
n
14.
∞
X
n=0
n(n + 1)(z −2i)n
15.
∞
X
n=0
(z −2 + i)n
2n
16.
∞
X
n=1
2n(z + i −3)2n

60
Complex Numbers
Chapter 2
17.
Verify the series in (7.3) by computer. Also show that it can be written in the form
∞
X
n=0
(−1)nz2n
n
X
k=0
1
(2k + 1)!.
Use this form to show by ratio test that the series converges in the disk |z| < 1.
8. ELEMENTARY FUNCTIONS OF COMPLEX NUMBERS
The so-called elementary functions are powers and roots, trigonometric and inverse
trigonometric functions, logarithmic and exponential functions, and combinations
of these. All these you can compute or ﬁnd in tables, as long as you want them as
functions of real numbers. Now we want to ﬁnd things like ii, sin(1+i), or ln i. These
are not just curiosities for the amusement of the mathematically inclined, but may
turn up to be evaluated in applied problems. To be sure, the values of experimental
measurements are not imaginary. But the values of Re z, Im z, |z|, angle of z, are
real, and these are the quantities which have experimental meaning. Meanwhile,
mathematical solutions of problems may involve manipulations of complex numbers
before we arrive ﬁnally at a real answer to compare with experiment.
Polynomials and rational functions (quotients of polynomials) of z are easily
evaluated.
Example.
If f(z) = (z2 + 1)/(z −3), we ﬁnd f(i −2) by substituting z = i −2 :
f(i −2) = (i −2)2 + 1
i −2 −3
= −4i + 4
i −5
· −i −5
−i −5 = 8i −12
13
.
Next we want to investigate the possible meaning of other functions of complex
numbers. We should like to deﬁne expressions like ez or sin z so that they will
obey the familiar laws we know for the corresponding real expressions [for example,
sin 2x = 2 sin x cos x, or (d/dx)ex = ex]. We must, for consistency, deﬁne functions
of complex numbers so that any equations involving them reduce to correct real
equations when z = x + iy becomes z = x, that is, when y = 0. These requirements
will be met if we deﬁne ez by the power series
(8.1)
ez =
∞

0
zn
n! = 1 + z + z2
2! + z3
3! + · · · .
This series converges for all values of the complex number z (Problem 7.1) and
therefore gives us the value of ez for any z. If we put z = x (x real), we get the
familiar series for ex.
It is easy to show, by multiplying the series (Problem 1), that
(8.2)
ez1 · ez2 = ez1+z2.
In Chapter 14 we shall consider in detail the meaning of derivatives with respect to
a complex z. However, it is worth while for you to know that (d/dz)zn = nzn−1,
and that, in fact, the other diﬀerentiation and integration formulas which you know

Section 9
Euler’s Formula
61
from elementary calculus hold also with x replaced by z.
You can verify that
(d/dz)ez = ez when ez is deﬁned by (8.1) by diﬀerentiating (8.1) term by term
(Problem 2). It can be shown that (8.1) is the only deﬁnition of ez which pre-
serves these familiar formulas. We now want to consider the consequences of this
deﬁnition.
PROBLEMS, SECTION 8
Show from the power series (8.1) that
1.
ez1 · ez2 = ez1+z2
2.
d
dz ez = ez
3.
Find the power series for ex cos x and for ex sin x from the series for ez in the following
way: Write the series for ez; put z = x + iy. Show that ez = ex(cos y + i sin y); take
real and imaginary parts of the equation, and put y = x.
9. EULER’S FORMULA
For real θ, we know from Chapter 1 the power series for sin θ and cos θ:
sin θ = θ −θ3
3! + θ5
5! −· · · ,
cos θ = 1 −θ2
2! + θ4
4! −· · · .
(9.1)
From our deﬁnition (8.1), we can write the series for e to any power, real or imagi-
nary. We write the series for eiθ, where θ is real:
eiθ = 1 + iθ + (iθ)2
2!
+ (iθ)3
3!
+ (iθ)4
4!
+ (iθ)5
5!
+ · · ·
(9.2)
= 1 + iθ −θ2
2! −iθ3
3! + θ4
4! + iθ5
5! · · ·
= 1 −θ2
2! + θ4
4! + · · · + i

θ −θ3
3! + θ5
5! · · ·

.
(The rearrangement of terms is justiﬁed because the series is absolutely convergent.)
Now compare (9.1) and (9.2); the last line in (9.2) is just cos θ + i sin θ. We then
have the very useful result we introduced in Section 3, known as Euler’s formula:
(9.3)
eiθ = cos θ + i sin θ.
Thus we have justiﬁed writing any complex number as we did in (4.1), namely
(9.4)
z = x + iy = r(cos θ + i sin θ) = reiθ.

62
Complex Numbers
Chapter 2
Here are some examples of the use of (9.3) and (9.4). These problems can be done
very quickly graphically or just by picturing them in your mind.
Examples.
Find the values of 2 eiπ/6, eiπ, 3 e−iπ/2, e2nπi.
2 eiπ/6 is reiθ with r = 2, θ = π/6. From Figure 9.1,
x =
√
3, y = 1, x + iy =
√
3 + i, so 2 eiπ/6 =
√
3 + i.
Figure 9.1
eiπ is reiθ with r = 1, θ = π. From Figure 9.2, x = −1,
y = 0, x+iy = −1 + 0i, so eiπ = −1. Note that r = 1 and
θ = −π, ±3π, ±5π, · · · , give the same point, so e−iπ = −1,
e3πi = −1, and so on.
Figure 9.2
3e−iπ/2 is reiθ with r = 3, θ = −π/2. From Figure
9.3, x = 0, y = −3, so 3e−iπ/2 = x + iy = 0 −3i = −3i.
Figure 9.3
e2nπi is reiθ with r = 1 and θ = 2nπ = n(2π); that is,
θ is an integral multiple of 2π. From Figure 9.4, x = 1,
y = 0, so e2nπi = 1 + 0i = 1.
Figure 9.4
It is often convenient to use Euler’s formula when we want to multiply or divide
complex numbers. From (8.2) we obtain two familiar looking laws of exponents
which are now valid for imaginary exponents:
eiθ1 · eiθ2 = ei(θ1+θ2),
eiθ1 ÷ eiθ2 = ei(θ1−θ2).
(9.5)
Remembering that any complex number can be written in the form reiθ by (9.4),
we get

Section 9
Euler’s Formula
63
z1 · z2 = r1 eiθ1 · r2 eiθ2 = r1 r2 ei(θ1+θ2),
z1 ÷ z2 = r1
r2
ei(θ1−θ2).
(9.6)
In words, to multiply two complex numbers, we multiply their absolute values
and add their angles. To divide two complex numbers, we divide the absolute
values and subtract the angles.
Example.
Evaluate (1 + i)2/(1 −i). From Figure 5.1 we have
1 + i =
√
2 eiπ/4. We plot 1 −i in Figure 9.5 and ﬁnd
r =
√
2, θ = −π/4 (or +7π/4), so 1 −i =
√
2 e−iπ/4. Then
(1 + i)2
1 −i
= (
√
2 eiπ/4)2
√
2 e−iπ/4 =
2 eiπ/2
√
2 e−iπ/4 =
√
2 e3iπ/4.
Figure 9.5
From Figure 9.6, we ﬁnd x = −1, y = 1, so
(1 + i)2
1 −i
= x + iy = −1 + i.
We could use degrees in this problem. By (9.6), we ﬁnd
that the angle of (1 + i)2/(1 −i) is 2(45◦)−(−45◦) = 135◦
as in Figure 9.6.
Figure 9.6
PROBLEMS, SECTION 9
Express the following complex numbers in the x + iy form. Try to visualize each complex
number, using sketches as in the examples if necessary. The ﬁrst twelve problems you
should be able to do in your head (and maybe some of the others—try it!)
Doing a
problem quickly in your head saves time over using a computer. Remember that the point
in doing problems like this is to gain skill in manipulating complex expressions, so a good
study method is to do the problems by hand and use a computer to check your answers.
1.
e−iπ/4
2.
eiπ/2
3.
9 e3πi/2
4.
e(1/3)(3+4πi)
5.
e5πi
6.
e−2πi −e−4πi + e−6πi
7.
3 e2(1+iπ)
8.
2 e5πi/6
9.
2 e−iπ/2
10.
eiπ + e−iπ
11.
√
2 e5iπ/4
12.
4 e−8iπ/3
13.
`
i −
√
3
´3
1 −i
14.
“
1 + i
√
3
”6
15.
(1 + i)2 + (1 + i)4
16.
“
i −
√
3
” “
1 + i
√
3
”
17.
1
(1 + i)3
18.
„1 + i
1 −i
«4
19.
(1 −i)8
20.
„ √
2
i −1
«10
21.
„1 −i
√
2
«40

64
Complex Numbers
Chapter 2
22.
„1 −i
√
2
«42
23.
(1 + i)48
`√
3 −i
´25
24.
`
1 −i
√
3
´21
(i −1)38
25.
„ i
√
2
1 + i
«12
26.
„
2i
i +
√
3
«19
27.
Show that for any real y, |eiy| = 1. Hence show that |ez| = ex for every complex z.
28.
Show that the absolute value of a product of two complex numbers is equal to the
product of the absolute values. Also show that the absolute value of the quotient
of two complex numbers is the quotient of the absolute values. Hint: Write the
numbers in the reiθ form.
Use Problems 27 and 28 to ﬁnd the following absolute values. If you understand Problems
27 and 28 and equation (5.1), you should be able to do these in your head.
29.
|eiπ/2|
30.
|e
√
3−i|
31.
|5 e2πi/3|
32.
|3e2+4i|
33.
|2 e3+iπ|
34.
|4 e2i−1|
35.
|3 e5i · 7 e−2i|
36.
|2 eiπ/6|2
37.
˛˛˛˛
1 + i
1 −i
˛˛˛˛
38.
˛˛˛˛
eiπ
1 + i
˛˛˛˛
10. POWERS AND ROOTS OF COMPLEX NUMBERS
Using the rules (9.6) for multiplication and division of complex numbers, we have
(10.1)
zn = (reiθ)n = rneinθ
for any integral n. In words, to obtain the nth power of a complex number, we take
the nth power of the modulus and multiply the angle by n. The case r = 1 is of
particular interest. Then (10.1) becomes DeMoivre’s theorem:
(10.2)
(eiθ)n = (cos θ + i sin θ)n = cos nθ + i sin nθ.
You can use this equation to ﬁnd the formulas for sin 2θ, cos 2θ, sin 3θ, etc. (Prob-
lems 27 and 28).
The nth root of z, z1/n, means a complex number whose nth power is z. From
(10.1) you can see that this is
(10.3)
z1/n = (reiθ)1/n = r1/neiθ/n =
n√r

cos θ
n + i sin θ
n

.
This formula must be used with care (see Examples 2 to 4 below).
Some examples will show how useful these formulas are.
Example 1.
[cos(π/10) + i sin(π/10)]25 = (eiπ/10)25 = e2πieiπ/2 = 1 · i = i.

Section 10
Powers and Roots of Complex Numbers
65
Example 2.
Find the cube roots of 8. We know that 2 is a cube root of 8, but there are
also two complex cube roots of 8; let us see why. Plot the complex number 8 (that
is, x = 8, y = 0) in the complex plane; the polar coordinates of the point are r = 8,
and θ = 0, or 360◦, 720◦, 1080◦, etc. (We can use either degrees or radians here;
read the end of Section 3.) Now by equation (10.3), z1/3 = r1/3eiθ/3; that is, to
ﬁnd the polar coordinates of the cube root of a number reiθ, we ﬁnd the cube root
of r and divide the angle by 3. Then the polar coordinates of
3√
8 are
r = 2,
θ = 0◦,
360◦/3,
720◦/3,
1080◦/3 · · ·
(10.4)
= 0◦,
120◦,
240◦,
360◦· · · .
We plot these points in Figure 10.1. Observe that the point (2, 0◦) and the
point (2, 360◦) are the same. The points in (10.4) are all on a circle of radius 2
and are equally spaced 360◦/3 = 120◦apart. Starting with θ = 0, if we add 120◦
repeatedly, we just repeat the three angles shown.
Thus, there are exactly three cube roots for any
number z, always on a circle of radius
3
|z| and
spaced 120◦apart.
Now to ﬁnd the values of
3√
8 in rectangular
form, we can read them from Figure 10.1, or we
can calculate them from z = r(cos θ +i sinθ) with
r = 2 and θ = 0, 120◦= 2π/3, 240◦= 4π/3.
We can also use a computer to solve the equation
z3 = 8. By any of these methods we ﬁnd
Figure 10.1
3√
8 = {2, −1 + i
√
3, −1 −i
√
3}.
Example 3.
Find and plot all values of
4√−64. From Figure 10.2 (or by visualizing a
plot of −64), we see that the polar coordinates of −64 are r = 64, θ = π + 2kπ
Figure 10.2
Figure 10.3
(where k = 0, 1, 2, · · ·). Then since z1/4 = r1/4eiθ/4, the polar coordinates of
4√−64
are
r =
4√
64 = 2
√
2,
θ = π
4 , π + 2π
4
, π + 4π
4
, π + 6π
4
, · · · = π
4 , 3π
4 , 5π
4 , 7π
4 .
We plot these points in Figure 10.3. Observe that they are all on a circle of
radius 2
√
2, equally spaced 2π/4 = π/2 apart. Starting with θ = π/4, we add π/2

66
Complex Numbers
Chapter 2
repeatedly, and ﬁnd exactly 4 fourth roots. We can read the values of
4√−64 in
rectangular form from Figure 10.3:
4√
−64 = ±2 ± 2i (all four combinations of ± signs)
or we can calculate them as in Example 2, or we can solve the equation z4 = −64
by computer.
Example 4.
Find and plot all values of
6√−8i. The polar coordinates of −8i are r = 8,
θ = 270◦+ 360◦k = 3π/2 + 2πk. Then the polar coordinates of
6√−8i are
(10.5)
r =
√
2,
θ = 270◦+ 360◦k
6
= 45◦+ 60◦k
or
θ = π
4 + π
3 k.
Figure 10.4
In Figure 10.4, we sketch a circle of radius
√
2. On
it we plot the point at 45◦and then plot the rest of
the 6 equally spaced points 60◦apart. To ﬁnd the
roots in rectangular coordinates, we need to ﬁnd all
the values of r(cos θ + i sin θ) with r and θ given by
(10.5). We can do this one root at a time or more
simply by using a computer to solve the equation
z6 = −8i. We ﬁnd (see Problem 33)
±

1 + i,
√
3 + 1
2
−
√
3 −1
2
i,
√
3 −1
2
−
√
3 + 1
2
i

=
± {1 + i,
1.366 −0.366i,
0.366 −1.366i}.
Summary In each of the preceding examples, our steps in ﬁnding
n√
reiθ were:
(a) Find the polar coordinates of the roots: Take the nth root of r and divide
θ + 2kπ by n.
(b) Make a sketch: Draw a circle of radius
n√r, plot the root with angle θ/n, and
then plot the rest of the n roots around the circle equally spaced 2π/n apart.
Note that we have now essentially solved the problem. From the sketch you
can see the approximate rectangular coordinates of the roots and check your
answers in (c). Since this sketch is quick and easy to do, it is worthwhile even
if you use a computer to do part (c).
(c) Find the x+iy coordinates of the roots by one of the methods in the examples.
If you are using a computer, you may want to make a computer plot of the
roots which should be a perfected copy of your sketch in (b).
PROBLEMS, SECTION 10
Follow steps (a), (b), (c) above to ﬁnd all the values of the indicated roots.
1.
3√
1
2.
3√
27
3.
4√
1
4.
4√
16
5.
6√
1
6.
6√
64
7.
8√
16
8.
8√
1
9.
5√
1
10.
5√
32
11.
3√
−8
12.
3√
−1

Section 11
The Exponential and Trigonometric Functions
67
13.
4√
−4
14.
4√
−1
15.
6√
−64
16.
6√
−1
17.
5√
−1
18.
√
i
19.
3√
i
20.
3√
−8i
21.
q
2 + 2i
√
3
22.
3√
2i −2
23.
4q
8i
√
3 −8
24.
8
s
−1 −i
√
3
2
25.
5√
−1 −i
26.
5√
i
27.
Using the fact that a complex equation is really two real equations, ﬁnd the
double angle formulas (for sin 2θ, cos 2θ) by using equation (10.2).
28.
As in Problem 27, ﬁnd the formulas for sin 3θ and cos 3θ.
29.
Show that the center of mass of three identical particles situated at the points
z1, z2, z3 is (z1 + z2 + z3)/3.
30.
Show that the sum of the three cube roots of 8 is zero.
31.
Show that the sum of the n nth roots of any complex number is zero.
32.
The three cube roots of +1 are often called 1, ω, and ω2. Show that this
is reasonable, that is, show that the cube roots of +1 are +1 and two other
numbers, each of which is the square of the other.
33.
Verify the results given for the roots in Example 4. You can ﬁnd the exact
values in terms of
√
3 by using trigonometric addition formulas or more easily
by using a computer to solve z6 = −8i. (You still may have to do a little
work by hand to put the computer’s solution into the given form.)
11. THE EXPONENTIAL AND TRIGONOMETRIC FUNCTIONS
Although we have already deﬁned ez by a power series (8.1), it is worth while to
write it in another form. By (8.2) we can write
(11.1)
ez = ex+iy = exeiy = ex(cos y + i sin y).
This is more convenient to use than the inﬁnite series if we want values of ez for
given z. For example,
e2−iπ = e2e−iπ = e2 · (−1) = −e2
from Figure 9.2.
We have already seen that there is a close relationship [Euler’s formula (9.3)]
between complex exponentials and trigonometric functions of real angles.
It is
useful to write this relation in another form. We write Euler’s formula (9.3) as it

68
Complex Numbers
Chapter 2
is, and also write it with θ replaced by −θ. Remember that cos(−θ) = cos θ and
sin(−θ) = −sin θ. Then we have
eiθ = cos θ + i sin θ,
e−iθ = cos θ −i sin θ.
(11.2)
These two equations can be solved for sin θ and cosθ. We get (Problem 2)
sin θ = eiθ −e−iθ
2i
,
cos θ = eiθ + e−iθ
2
.
(11.3)
These formulas are useful in evaluating integrals since products of exponentials are
easier to integrate than products of sines and cosines. (See Problems 11 to 16, and
Chapter 7, Section 5.)
So far we have discussed only trigonometric functions of real angles. We could
deﬁne sin z and cos z for complex z by their power series as we did for ez. We could
then compare these series with the series for eiz and derive Euler’s formula and
(11.3) with θ replaced by z. However, it is simpler to use the complex equations
corresponding to (11.3) as our deﬁnitions for sin z and cos z. We deﬁne
sin z = eiz −e−iz
2i
,
cos z = eiz + e−iz
2
.
(11.4)
The rest of the trigonometric functions of z are deﬁned in the usual way in terms
of these; for example, tan z = sin z/ cosz.
Example 1.
cos i = ei·i + e−i·i
2
= e−1 + e
2
= 1.543 · · ·. (We will see in Section 15 that
this expression is called the hyperbolic cosine of 1.)
Example 2.
sin
π
2 + i ln 2

= ei(π/2+i ln 2) −e−i(π/2+i ln 2)
2i
= eiπ/2e−ln 2 −e−iπ/2eln 2
2i
by (8.2).
From Figures 5.2 and 9.3, eiπ/2 = i, and e−iπ/2 = −i. By the deﬁnition of ln x
[or see equations (13.1) and (13.2)], eln 2 = 2, so e−ln 2 = 1/eln 2 = 1/2. Then
sin
π
2 + i ln 2

= (i)(1/2) −(−i)(2)
2i
= 5
4.

Section 12
The Exponential and Trigonometric Functions
69
Notice from both these examples that sines and cosines of complex numbers may
be greater than 1. As we shall see (Section 15), although | sin x| ≤1 and | cos x| ≤1
for real x, when z is a complex number, sin z and cos z can have any value we like.
Using the deﬁnitions (11.4) of sin z and cos z, you can show that the familiar
trigonometric identities and calculus formulas hold when θ is replaced by z.
Example 3.
Prove that sin2 z + cos2 z = 1.
sin2 z =
eiz −e−iz
2i
2
= e2iz −2 + e−2iz
−4
,
cos2 z =
eiz + e−iz
2
2
= e2iz + 2 + e−2iz
4
,
sin2 z + cos2 z = 2
4 + 2
4 = 1.
Example 4.
Using the deﬁnitions (11.4), verify that (d/dz) sin z = cos z.
sin z = eiz −e−iz
2i
,
d
dz sin z = 1
2i(ieiz + ie−iz) = eiz + e−iz
2
= cos z.
PROBLEMS, SECTION 11
1.
Deﬁne sin z and cos z by their power series.
Write the power series for eiz.
By
comparing these series obtain the deﬁnition (11.4) of sin z and cos z.
2.
Solve the equations eiθ = cos θ + i sin θ, e−iθ = cos θ −i sin θ, for cos θ and sin θ and
so obtain equations (11.3).
Find each of the following in rectangular form x + iy and check your results by computer.
Remember to save time by doing as much as you can in your head.
3.
e−(iπ/4)+ln 3
4.
e3 ln 2−iπ
5.
e(iπ/4)+(ln 2)/2
6.
cos(i ln 5)
7.
tan(i ln 2)
8.
cos(π −2i ln 3)
9.
sin(π −i ln 3)
10.
sin(i ln i)
In the following integrals express the sines and cosines in exponential form and then
integrate to show that:
11.
Z π
−π
cos 2x cos 3x dx = 0
12.
Z π
−π
cos2 3x dx = π
13.
Z π
−π
sin 2x sin 3x dx = 0
14.
Z 2π
0
sin2 4x dx = π
15.
Z π
−π
sin 2x cos 3x dx = 0
16.
Z π
−π
sin 3x cos 4x dx = 0
Evaluate
R
e(a+ib)xdx and take real and imaginary parts to show that:
17.
Z
eax cos bx dx = eax(a cos bx + b sin bx)
a2 + b2
18.
Z
eax sin bx dx = eax(a sin bx −b cos bx)
a2 + b2

70
Complex Numbers
Chapter 2
12. HYPERBOLIC FUNCTIONS
Let us look at sin z and cos z for pure imaginary z, that is, z = iy:
sin iy = e−y −ey
2i
= i ey −e−y
2
,
cos iy = e−y + ey
2
= ey + e−y
2
.
(12.1)
The real functions on the right have special names because these particular combi-
nations of exponentials arise frequently in problems. They are called the hyperbolic
sine (abbreviated sinh) and the hyperbolic cosine (abbreviated cosh). Their deﬁni-
tions for all z are
sinh z = ez −e−z
2
,
cosh z = ez + e−z
2
.
(12.2)
The other hyperbolic functions are named and deﬁned in a similar way to parallel
the trigonometric functions:
tanh z = sinh z
cosh z ,
coth z =
1
tanh z ,
sech z =
1
cosh z ,
csch z =
1
sinh z .
(12.3)
(See Problem 38 for the reason behind the term “hyperbolic” functions.)
We can write (12.1) as
sin iy = i sinh y,
cos iy = cosh y.
(12.4)
Then we see that the hyperbolic functions of y are (except for one i factor) the
trigonometric functions of iy. From (12.2) we can show that (12.4) holds with y
replaced by z. Because of this relation between hyperbolic and trigonometric func-
tions, the formulas for hyperbolic functions look very much like the corresponding
trigonometric identities and calculus formulas. They are not identical, however.
Example.
You can prove the following formulas (see Problems 9, 10, 11 and 38).
cosh2 z −sinh2 z = 1
(compare sin2 z + cos2 z = 1),
d
dz cosh z = sinh z
(compare d
dz cos z = −sin z).
PROBLEMS, SECTION 12
Verify each of the following by using equations (11.4), (12.2), and (12.3).
1.
sin z = sin(x + iy) = sin x cosh y + i cos x sinh y

Section 12
Hyperbolic Functions
71
2.
cos z = cos x cosh y −i sin x sinh y
3.
sinh z = sinh x cos y + i cosh x sin y
4.
cosh z = cosh x cos y + i sinh x sin y
5.
sin 2z = 2 sin z cos z
6.
cos 2z = cos2 z −sin2 z
7.
sinh 2z = 2 sinh z cosh z
8.
cosh 2z = cosh2 z + sinh2 z
9.
d
dz cos z = −sin z
10.
d
dz cosh z = sinh z
11.
cosh2 z −sinh2 z = 1
12.
cos4 z + sin4 z = 1 −1
2 sin2 2z
13.
cos 3z = 4 cos3 z −3 cos z
14.
sin iz = i sinh z
15.
sinh iz = i sin z
16.
tan iz = i tanh z
17.
tanh iz = i tan z
18.
tan z = tan(x + iy) = tan x + i tanh y
1 −i tan x tanh y
19.
tanh z = tanh x + i tan y
1 + i tanh x tan y
20.
Show that enz = (cosh z + sinh z)n = cosh nz + sinh nz.
Use this and a similar
equation for e−nz to ﬁnd formulas for cosh 3z and sinh 3z in terms of sinh z and
cosh z.
21.
Use a computer to plot graphs of sinh x, cosh x, and tanh x.
22.
Using (12.2) and (8.1), ﬁnd, in summation form, the power series for sinh x and
cosh x. Check the ﬁrst few terms of your series by computer.
Find the real part, the imaginary part, and the absolute value of
23.
cosh(ix)
24.
cos(ix)
25.
sin(x −iy)
26.
cosh(2 −3i)
27.
sin(4 + 3i)
28.
tanh(1 −iπ)
Find each of the following in the x + iy form and check your answers by computer.
29.
cosh 2π i
30.
tanh 3πi
4
31.
sinh
„
ln 2 + iπ
3
«
32.
cosh
„iπ
2 −ln 3
«
33.
tan i
34.
sin iπ
2
35.
cosh(iπ + 2)
36.
sinh
„
1 + iπ
2
«
37.
cos(iπ)
38.
The functions sin t, cos t, · · · , are called “circular functions” and the functions sinh t,
cosh t, · · · , are called “hyperbolic functions”. To see a reason for this, show that
x = cos t, y = sin t, satisfy the equation of a circle x2 + y2 = 1, while x = cosh t,
y = sinh t, satisfy the equation of a hyperbola x2 −y2 = 1.

72
Complex Numbers
Chapter 2
13. LOGARITHMS
In elementary mathematics you learned to ﬁnd logarithms of positive numbers only;
in fact, you may have been told that there were no logarithms of negative numbers.
This is true if you use only real numbers, but it is not true when we allow complex
numbers as answers. We shall now see how to ﬁnd the logarithm of any complex
number z ̸= 0 (including negative real numbers as a special case). If
(13.1)
z = ew,
then by deﬁnition
(13.2)
w = ln z.
(We use ln for natural logarithms to avoid the cumbersome loge and to avoid con-
fusion with logarithms to the base 10.)
We can write the law of exponents (8.2), using the letters of (13.1), as
(13.3)
z1z2 = ew1 · ew2 = ew1+w2.
Taking logarithms of this equation, that is, using (13.1) and (13.2), we get
(13.4)
ln z1z2 = w1 + w2 = ln z1 + ln z2.
This is the familiar law for the logarithm of a product, justiﬁed now for complex
numbers. We can then ﬁnd the real and imaginary parts of the logarithm of a
complex number from the equation
(13.5)
w = ln z = ln(reiθ) = Ln r + ln eiθ = Ln r + iθ,
where Ln r means the ordinary real logarithm to the base e of the real positive
number r.
Since θ has an inﬁnite number of values (all diﬀering by multiples of 2π), a complex
number has inﬁnitely many logarithms, diﬀering from each other by multiples of
2πi. The principal value of ln z (often written as Ln z) is the one using the principal
value of θ, that is 0 ≤θ < 2π. (Some references use −π < θ ≤π.)
Example 1.
Find ln(−1). From Figure 9.2, we see that the polar coordinates of the point
z = −1 are r = 1 and θ = π, −π, 3π, · · · . Then,
ln(−1) = Ln(1) + i(π ± 2nπ) = iπ, −iπ, 3πi, · · · .
Example 2.
Find ln(1 + i). From Figure 5.1, for z = 1 + i, we ﬁnd r =
√
2, and θ =
π/4 ± 2nπ. Then
ln(1 + i) = Ln
√
2 + i
π
4 ± 2nπ

= 0.347 · · · + i
π
4 ± 2nπ

.
Even a positive real number now has inﬁnitely many logarithms, since its angle
can be taken as 0, 2π, −2π, etc. Only one of these logarithms is real, namely the
principal value Ln r using the angle θ = 0.

Section 14
Complex Roots and Powers
73
14. COMPLEX ROOTS AND POWERS
For real positive numbers, the equation ln ab = b ln a is equivalent to ab = eb ln a. We
deﬁne complex powers by the same formula with complex a and b. By deﬁnition,
for complex a and b (a ̸= e),
(14.1)
ab = eb ln a.
[The case a = e is excluded because we have already deﬁned powers of e by (8.1).]
Since ln a is multiple valued (because of the inﬁnite number of values of θ), powers
ab are usually multiple valued, and unless you want just the principal value of ln z
or of ab you must use all values of θ. In the following examples we ﬁnd all values of
each complex power and write the answers in the x + iy form.
Example 1.
Find all values of i−2i. From Figure 5.2, and equation (13.5) we ﬁnd ln i =
Ln 1 + i(π/2 ± 2nπ) = i(π/2 ± 2nπ) since Ln 1 = 0. Then, by equation (14.1),
i−2i = e−2i ln i = e−2i·i(π/2±2nπ) = eπ±4nπ = eπ, e5π, e−3π, · · · ,
where eπ = 23.14 · · ·. Note the inﬁnite set of values of i−2i, all real! Also read the
end of Section 3, and note that here the ﬁnal step is not to ﬁnd sine or cosine of
π ± 4nπ; thus, in ﬁnding ln i = iθ, we must not write θ in degrees.
Example 2.
Find all values of i1/2. Using ln i from Example 1 we have i1/2 = e(1/2) ln i =
ei(π/4+nπ) = eiπ/4einπ. Now einπ = +1 when n is even (Fig. 9.4), and einπ = −1
when n is odd (Fig. 9.2). Thus,
i1/2 = ± eiπ/4 = ± 1 + i
√
2
using Figure 5.1. Notice that although ln i has an inﬁnite set of values, we ﬁnd just
two values for i1/2 as we should for a square root. (Compare the method of Section
10 which is easier for this problem.)
Example 3.
Find all values of (1 + i)1−i. Using (14.1) and the value of ln(1 + i) from
Example 2, Section 13, we have
(1 + i)1−i = e(1−i) ln(1+i) = e(1−i)[Ln
√
2+i(π/4±2nπ)]
= eLn
√
2 e−i Ln
√
2 eiπ/4 e±2nπi eπ/4 e±2nπ
=
√
2 ei(π/4−Ln
√
2 ) eπ/4 e±2nπ
(since e±2nπi = 1)
=
√
2 eπ/4 e±2nπ[cos(π/4 −Ln
√
2 ) + i sin(π/4 −Ln
√
2 )]
∼= e± 2nπ(2.808 + 1.318i).
Now you may be wondering why not just do these problems by computer. The
most important point is that it is useful for advanced work to have skill in manip-
ulating complex expressions. A second point is that there may be several forms for
an answer (see Section 15, Example 2) or there may be many answers (see examples

74
Complex Numbers
Chapter 2
above), and your computer may not give you the one you want (see Problem 25).
So to obtain needed skills, a good study method is to do problems by hand and
compare with computer solutions.
PROBLEMS, SECTION 14
Evaluate each of the following in x + iy form, and compare with a computer solution.
1.
ln(−e)
2.
ln(−i)
3.
ln(i +
√
3)
4.
ln(i −1)
5.
ln(−
√
2 −i
√
2)
6.
ln
„1 −i
√
2
«
7.
ln
„1 + i
1 −i
«
8.
i 2/3
9.
(−1)i
10.
i ln i
11.
2i
12.
i 3+i
13.
i 2i/π
14.
(2i)1+i
15.
(−1)sin i
16.
„1 + i
√
3
2
«i
17.
(i −1)i+1
18.
cos(2i ln i)
19.
cos(π + i ln 2)
20.
sin
„
i ln 1 −i
1 + i
«
21.
cos[i ln(−1)]
22.
sin
»
i ln
„√
3 + i
2
«–
23.
“
1 −
√
2i
”i
. Hint: Find
√
2i ﬁrst.
24.
Show that (ab)c can have more values than abc. As examples compare
(a)
[(−i)2+i]2−i
and
(−i)(2+i)(2−i) = (−i)5;
(b)
(ii)i
and
i−1.
25.
Use a computer to ﬁnd the three solutions of the equation x3−3x−1 = 0. Find a way
to show that the solutions can be written as 2 cos(π/9), −2 cos(2π/9), −2 cos(4π/9).
15. INVERSE TRIGONOMETRIC AND HYPERBOLIC FUNCTIONS
We have already deﬁned the trigonometric and hyperbolic functions of a complex
number z. For example,
(15.1)
w = cos z = eiz + e−iz
2
deﬁnes w = cos z; that is, for each complex number z, (15.1) gives us the complex
number w. We now deﬁne the inverse cosine or arc cosw by
(15.2)
z = arc cosw
if
w = cos z.
The other inverse trigonometric and hyperbolic functions are deﬁned similarly.
In dealing with real numbers, you know that sin x and cos x are never greater
than 1. This is no longer true for sin z and cos z with z complex. To illustrate the
method of ﬁnding inverse trigonometric (or inverse hyperbolic) functions, let’s ﬁnd
arc cos2.

Section 15
Inverse Trigonometric and Hyperbolic Functions
75
Example 1.
We want z, where
z = arc cos2
or
cos z = 2.
Then we have
eiz + e−iz
2
= 2.
To simplify the algebra, let u = eiz. Then e−iz = u−1, and the equation becomes
u + u−1
2
= 2.
Multiply by 2 and by u to get u2 + 1 = 4u or u2 −4u + 1 = 0. Solve this equation
by the quadratic formula to ﬁnd
u = 4 ± √16 −4
2
= 2 ±
√
3,
or
eiz = u = 2 ±
√
3.
Take logarithms of both sides of this equation, and solve for z:
iz = ln(2 ±
√
3) = Ln(2 ±
√
3) + 2nπi,
arc cos2 = z = 2nπ −i Ln(2 ±
√
3 ) = 2nπ ± i Ln(2 +
√
3 )
since Ln(2 −
√
3) = −Ln(2 +
√
3).
It is instructive now to ﬁnd cos z and see that it is 2. For iz = ln(2 ±
√
3), we
have
eiz = eln(2±
√
3) = 2 ±
√
3,
e−iz = 1
eiz =
1
2 ±
√
3 = 2 ∓
√
3
4 −3
= 2 ∓
√
3.
Then
cos z = eiz + e−iz
2
= 2 ±
√
3 + 2 ∓
√
3
2
= 4
2 = 2,
as claimed.
By the same method, we can ﬁnd all the inverse trigonometric and hyperbolic
functions in terms of logarithms. (See Problems, Section 17.) Here is one more
example.
Example 2.
In integral tables or from your computer you may ﬁnd for the indeﬁnite
integral
(15.3)

dx
√
x2 + a2
either
(15.4)
sinh−1 x
a
or
ln(x +

x2 + a2 ).
How are these related? Put
(15.5)
z = sinh−1 x
a
or
x
a = sinh z = ez −e−z
2
.

76
Complex Numbers
Chapter 2
We solve for z as in the previous example. Let ez = u, e−z = 1/u. Then
u −1
u = 2x
a ,
au2 −2xu −a = 0,
ez = u = 2x ±
√
4x2 + 4a2
2a
= x ±
√
x2 + a2
a
.
(15.6)
For real integrals, that is, for real z, ez > 0, so we must use the positive sign. Then,
taking the logarithm of (15.6) we have
(15.7)
z = ln(x +

x2 + a2 ) −ln a.
Comparing (15.5) and (15.7) we see that the two answers in (15.4) diﬀer only by
the constant ln a, which is a constant of integration.
PROBLEMS, SECTION 15
Find each of the following in the x + iy form and compare a computer solution.
1.
arc sin 2
2.
arc tan 2i
3.
cosh−1(1/2)
4.
sinh−1(i/2)
5.
arc cos
“
i
√
8
”
6.
tanh−1(−i)
7.
arc tan
“
i
√
2
”
8.
arc sin(5/3)
9.
tanh−1 “
i
√
3
”
10.
arc cos(5/4)
11.
sinh−1 “
i/
√
2
”
12.
cosh−1 “√
3/2
”
13.
cosh−1(−1)
14.
arc sin(3i/4)
15.
arc tan(2 + i)
16.
tanh−1(1 −2i)
17.
Show that tan z never takes the values ±i. Hint:
Try to solve the equation tan z = i
and ﬁnd that it leads to a contradiction.
18.
Show that tanh z never takes the values ±1.
16. SOME APPLICATIONS
Motion of a Particle
We have already seen (end of Section 5) that the path
of a particle in the (x, y) plane is given by z = z(t). As another example of this,
suppose z = 1 + 3e2it. We see that
(16.1)
|z −1| = |3 e2it| = 3.
Recall that |z −1| is the distance between the points z and 1; (16.1) says that this
distance is 3. Thus the particle traverses a circle of radius 3, with center at (1, 0).
The magnitude of its velocity is |dz/dt| = |6i e2it| = 6, so it moves around the circle
at constant speed. (Also see Problem 2).

Section 16
Some Applications
77
PROBLEMS, SECTION 16
1.
Show that if the line through the origin and the point z is rotated 90◦about the
origin, it becomes the line through the origin and the point iz. This fact is sometimes
expressed by saying that multiplying a complex number by i rotates it through 90◦.
Use this idea in the following problem. Let z = a eiωt be the displacement of a
particle from the origin at time t. Show that the particle travels in a circle of radius
a at velocity v = aω and with acceleration of magnitude v2/a directed toward the
center of the circle.
In each of the following problems, z represents the displacement of a particle from the
origin.
Find (as functions of t) its speed and the magnitude of its acceleration, and
describe the motion.
2.
z = 5eiωt, ω = const.
Hint: See Problem 1.
3.
z = (1 + i)eit.
4.
z = (1 + i)t −(2 + i)(1 −t).
Hint: Show that the particle moves along a straight
line through the points (1 + i) and (−2 −i).
5.
z = z1t + z2(1 −t).
Hint: See Problem 4; the straight line here is through the
points z1 and z2.
Electricity
In the theory of electric circuits, it is shown that if VR is the voltage
across a resistance R, and I is the current ﬂowing through the resistor, then
(16.2)
VR = IR
(Ohm’s law).
It is also known that the current and voltage across an inductance L are related by
(16.3)
VL = LdI
dt
and the current and voltage across a capacitor are related by
(16.4)
dVC
dt
= I
C ,
Figure 16.1
where C is the capacitance. Suppose the cur-
rent I and voltage V in the circuit of Figure
16.1 vary with time so that I is given by
(16.5)
I = I0 sin ωt.
You can verify that the following voltages across
R, L, and C are consistent with (16.2), (16.3),
and (16.4):
VR = RI0 sin ωt,
(16.6)
VL = ωLI0 cos ωt,
(16.7)
VC = −1
ωC I0 cos ωt.
(16.8)
The total voltage
(16.9)
V = VR + VL + VC

78
Complex Numbers
Chapter 2
is then a complicated function. A simpler method of discussing a-c circuits uses
complex quantities as follows. Instead of (16.5) we write
(16.10)
I = I0 eiωt,
where it is understood that the actual physical current is given by the imaginary
part of I in (16.10), that is, by (16.5). Note, by comparing (16.5) and (16.10), that
the maximum value of I, namely I0, is given in (16.10) by |I|. Now equations (16.6)
to (16.9) become
VR = RI0 eiωt = RI,
(16.11)
VL = iωLI0 eiωt = iωLI,
(16.12)
VC =
1
iωC I0 eiωt =
1
iωC I,
(16.13)
V = VR + VL + VC =

R + i

ωL −
1
ωC

I.
(16.14)
The complex quantity Z deﬁned by
(16.15)
Z = R + i

ωL −
1
ωC

is called the (complex) impedance. Using it we can write (16.14) as
(16.16)
V = ZI
which looks much like Ohm’s law. In fact, Z for an a-c circuit corresponds to R for
a d-c circuit. The more complicated a-c circuit equations now take the same simple
form as the d-c equations except that all quantities are complex. For example, the
rules for combining resistances in series and in parallel hold for combining complex
impedances (see Problems below).
PROBLEMS, SECTION 16
In electricity we learn that the resistance of two resistors in series is R1 + R2 and the
resistance of two resistors in parallel is (R−1
1
+ R−1
2 )−1. Corresponding formulas hold for
complex impedances. Find the impedance of Z1 and Z2 in series, and in parallel, given:
6.
(a) Z1 = 2 + 3i,
Z2 = 1 −5i
(b) Z1 = 2
√
3 eiπ/6,
Z2 = 2 e2iπ/3
7.
(a) Z1 = 1 −i,
Z2 = 3i
(b) |Z1| = 3.16, θ1 = 18.4◦;
|Z2| = 4.47, θ2 = 63.4◦
Figure 16.2
8.
Find the impedance of the circuit in Figure 16.2 (R
and L in series, and then C in parallel with them). A
circuit is said to be in resonance if Z is real; ﬁnd ω in
terms of R, L, and C at resonance.
9.
For the circuit in Figure 16.1:
(a)
Find ω in terms of R, L, and C if the angle of Z is 45◦.
(b)
Find the resonant frequency ω (see Problem 8).
10.
Repeat Problem 9 for a circuit consisting of R, L, and C, all in parallel.

Section 16
Some Applications
79
Optics
In optics we frequently need to combine a number of light waves (which
can be represented by sine functions). Often each wave is “out of phase” with the
preceding one by a ﬁxed amount; this means that the waves can be written as sin t,
sin(t + δ), sin(t + 2δ), and so on. Suppose we want to add all these sine functions
together. An easy way to do it is to see that each sine is the imaginary part of a
complex number, so what we want is the imaginary part of the series
(16.17)
eit + ei(t+δ) + ei(t+2δ) + · · · .
This is a geometric progression with ﬁrst term eit and ratio eiδ. If there are n waves
to be combined, we want the sum of n terms of this progression, which is
(16.18)
eit(1 −einδ)
1 −eiδ
.
We can simplify this expression by writing
(16.19)
1 −eiδ = eiδ/2(e−iδ/2 −eiδ/2) = −eiδ/2 · 2i sin δ
2
by (11.3). Substituting (16.19) and a similar formula for (1 −einδ) into (16.18), we
get
(16.20)
eiteinδ/2
eiδ/2
sin(nδ/2)
sin(δ/2) = ei{t+[(n−1)/2]δ} sin(nδ/2)
sin(δ/2) .
The imaginary part of the series (16.17) which we wanted is then the imaginary
part of (16.20), namely
sin

t + n −1
2
δ

sin nδ
2

sin δ
2.
PROBLEMS, SECTION 16
11.
Prove that
cos θ + cos 3θ + cos 5θ + · · · + cos(2n −1)θ = sin 2nθ
2 sin θ ,
sin θ + sin 3θ + sin 5θ + · · · + sin(2n −1)θ = sin2 nθ
sin θ .
Hint: Use Euler’s formula and the geometric progression formula.
12.
In optics, the following expression needs to be evaluated in calculating the intensity
of light transmitted through a ﬁlm after multiple reﬂections at the surfaces of the
ﬁlm:
 ∞
X
n=0
r2n cos nθ
!2
+
 ∞
X
n=0
r2n sin nθ
!2
.
Show that this is equal to | P∞
n=0 r2neinθ|2 and so evaluate it assuming |r| < 1 (r is
the fraction of light reﬂected each time).

80
Complex Numbers
Chapter 2
Simple Harmonic Motion
It is very convenient to use
complex notation even for motion along a straight line.
Think of a mass m attached to a spring and oscillating
up and down (see Figure 16.3). Let y be the vertical dis-
placement of the mass from its equilibrium position (the
point at which it would hang at rest). Recall that the
force on m due to the stretched or compressed spring is
then −ky, where k is the spring constant, and the mi-
nus sign indicates that the force and displacement are in
opposite directions. Then Newton’s second law (force =
mass times acceleration) gives
Figure 16.3
(16.21)
md2y
dt2 = −ky
or
d2y
dt2 = −k
my = −ω2y
if
ω2 = k
m.
Now we want a function y(t) with the property that diﬀerentiating it twice just
multiplies it by a constant. You can easily verify that this is true for exponentials,
sines, and cosines (see problem 13).
Just as in discussing electric circuits (see
(16.10)), we may write a solution of (16.21) as
(16.22)
y = y0 eiωt
with the understanding that the actual physical displacement is either the real or the
imaginary part of (16.22). The constant ω =

k/m is called the angular frequency
(see Chapter 7, Section 2). We will use this notation in Chapter 3, Section 12.
PROBLEMS, SECTION 16
13.
Verify that eiωt, e−iωt, cos ωt, and sin ωt satisfy equation (16.21).
17. MISCELLANEOUS PROBLEMS
Find one or more values of each of the following complex expressions and compare with a
computer solution.
1.
„1 + i
1 −i
«2718
2.
„ 1 + i
√
3
√
2 + i
√
2
«50
3.
5√
−4 −4i
4.
sinh(1 + iπ/2)
5.
tanh(iπ/4)
6.
(−e)iπ
7.
(−i)i
8.
cos
»
2i ln 1 −i
1 + i
–
9.
arc sin
"„√
3 + i
√
3 −i
«12#
10.
e2i arc tan(i
√
3)
11.
e2 tanh−1 i
12.
ei arc sin i
13.
Find real x and y for which |z + 3| = 1 −iz, where z = x + iy.
14.
Find the disk of convergence of the series P(z −2i)n/n.
15.
For what z is the series P zln n absolutely convergent? Hints: Use equation (14.1).
Also see Chapter 1, Problem 6.15.
16.
Describe the set of points z for which Re(eiπ/2z) > 2.

Section 17
Miscellaneous Problems
81
Verify the formulas in Problems 17 to 24.
17.
arc sin z = −i ln(iz ±
p
1 −z2)
18.
arc cos z = i ln(z ±
p
z2 −1)
19.
arc tan z = 1
2i ln 1 + iz
1 −iz
20.
sinh−1 z = ln(z ±
p
z2 + 1)
21.
cosh−1 z = ln(z ±
p
z2 −1) = ± ln(z +
p
z2 −1)
22.
tanh−1 z = 1
2 ln 1 + z
1 −z
23.
cos iz = cosh z
24.
cosh iz = cos z
25.
(a)
Show that cos z = cos ¯z.
(b)
Is sin z = sin ¯z?
(c)
If f(z) = 1 + iz, is f(z) = f(¯z)?
(d)
If f(z) is expanded in a power series with real coeﬃcients, show that f(z) =
f(¯z).
(e)
Using part (d), verify, without computing its value, that i[sinh(1 + i) −sinh(1 −i)]
is real.
26.
Find
˛˛˛˛
2eiθ −i
ieiθ + 2
˛˛˛˛.
Hint: See equation (5.1).
27.
(a)
Show that Re z = 1
2(z + ¯z) and that Im z = (1/2i)(z −¯z).
(b)
Show that |ez|2 = e2 Re z.
(c)
Use (b) to evaluate |e(1+ix)2(1−it)−|1+it|2|2 which occurs in quantum mechanics.
28.
Evaluate the following absolute square of a complex number (which arises in a
problem in quantum mechanics). Assume a and b are real. Express your answer in
terms of a hyperbolic function.
˛˛˛˛
(a + bi)2eb −(a −bi)2e−b
4abie−ia
˛˛˛˛
2
29.
If z = a
b and
1
a + b = 1
a + 1
b , ﬁnd z.
30.
Write the series for ex(1+i). Write 1 + i in the reiθ form and so obtain (easily) the
powers of (1 + i). Thus show, for example, that the ex cos x series has no x2 term,
no x6 term, etc., and a similar result for the ex sin x series. Find (easily) a formula
for the general term for each series.
31.
Show that if a sequence of complex numbers tends to zero, then the sequence of
absolute values tends to zero too, and vice versa. Hint: an + ibn →0 means an →0
and bn →0.
32.
Use a series you know to show that
∞
X
n=0
(1 + iπ)n
n!
= −e.

C H A P T E R 3
Linear Algebra
1. INTRODUCTION
In this chapter, we are going to discuss a combination of algebra and geometry
which is important in many applications. As you know, problems in various ﬁelds
of science and mathematics involve the solution of sets of linear equations. This
sounds like algebra, but it has a useful geometric interpretation. Suppose you have
solved two simultaneous linear equations and have found x = 2 and y = −3. We
can think of x = 2, y = −3 as the point (2, −3) in the (x, y) plane. Since two linear
equations represent two straight lines, the solution is then the point of intersection of
the lines. The geometry helps us to understand that sometimes there is no solution
(parallel lines) and sometimes there are inﬁnitely many solutions (both equations
represent the same line).
Figure 1.1
The language of vectors is very useful in studying sets of simultaneous equations.
You are familiar with quantities such as the velocity of an object, the force acting
on it, or the magnetic ﬁeld at a point, which have both magnitude and direction.
Such quantities are called vectors; contrast them with such quantities as mass, time,
or temperature, which have magnitude only and are called scalars. A vector can
be represented by an arrow and labeled by a boldface letter (A in Figure 1.1; also
see Section 4). The length of the arrow tells us the magnitude of the vector and
the direction of the arrow tells us the direction of the vector. It is not necessary
to use coordinate axes as in Figure 1.1; we can, for example, point a ﬁnger to tell
someone which way it is to town without knowing the direction of north. This
is the geometric method of discussing vectors (see Section 4). However, if we do
use a coordinate system as in Figure 1.1, we can specify
the vector by giving its components Ax and Ay which are
the projections of the vector on the x axis and the y axis.
Thus we have two distinct methods of deﬁning and working
with vectors. A vector may be a geometric entity (arrow),
or it may be a set of numbers (components relative to a
coordinate system) which we use algebraically. As we shall
see, this double interpretation of everything we do makes
the use of vectors a very powerful tool in applications.
One of the great advantages of vector formulas is that they are independent of
82

Section 2
Matrices; Row Reduction
83
the choice of coordinate system. For example, suppose we are discussing the motion
of a mass m sliding down an inclined plane. Newton’s second law F = ma is then a
correct equation no matter how we choose our axes. We might, say, take the x axis
horizontal and the y axis vertical, or alternatively we might take the x axis along
the inclined plane and the y axis perpendicular to the plane. Fx would, of course,
be diﬀerent in the two cases, but for either case it would be true that Fx = max
and Fy = may, that is, the vector equation F = ma would be true.
As we have just seen, a vector equation in two dimensions is equivalent to two
component equations. In three dimensions, a vector equation is equivalent to three
component equations. We will ﬁnd it useful to generalize this to n dimensions and
think of a set of n equations in n unknowns as the component equations for a vector
equation in an n dimensional space (Section 10).
We shall also be interested in sets of linear equations which you can think of as
changes of variable, say
(1.1)
 x′ = ax + by,
y′ = cx + dy,
where a, b, c, d, are constants. Alternatively, we can think of (1.1) geometrically as
telling us to move each point (x, y) to another point (x′, y′), an operation we will
refer to as a transformation of the plane. Or if we think of (x, y) and (x′, y′) as
being components of vectors from the origin to the given points, then (1.1) tells us
how to change each vector in the plane to another vector. Equations (1.1) could
also correspond to a change of axes (say a rotation of axes around the origin) where
(x, y) and (x′, y′) are the coordinates of the same point relative to diﬀerent axes. We
will learn (Sections 11 and 12) how to choose the best coordinate system or set of
variables to use in solving various problems. The same methods and tools (such as
matrices and determinants) which can be used to solve sets of numerical equations
are what we need to work with transformations and changes of coordinate system.
After we have considered 2- and 3-dimensional space, we will extend these ideas
to n-dimensional space and ﬁnally to a space in which the “vectors” are functions.
This generalization is of great importance in applications.
2. MATRICES; ROW REDUCTION
A matrix (plural: matrices) is just a rectangular array of quantities, usually inclosed
in large parentheses, such as
(2.1)
A =

1
5
−2
−3
0
6

.
We will ordinarily indicate a matrix by a roman letter such as A (or B, C, M, r,
etc.), but the letter does not have a numerical value; it simply stands for the array.
To indicate a number in the array, we will write Aij where i is the row number
and j is the column number. For example, in (2.1), A11 = 1, A12 = 5, A13 = −2,
A21 = −3, A22 = 0, A23 = 6. We will call a matrix with m rows and n columns
an m by n matrix. Thus the matrix in (2.1) is a 2 by 3 matrix, and the matrix in
(2.2) below is a 3 by 2 matrix.

84
Linear Algebra
Chapter 3
Transpose of a Matrix
We write
(2.2)
AT =


1
−3
5
0
−2
6

,
and call AT the transpose of the matrix A in (2.1). To transpose a matrix, we
simply write the rows as columns, that is, we interchange rows and columns. Note
that, using index notation, we have (AT)ij = Aji. You will ﬁnd a summary of
matrix notation in Section 9.
Sets of Linear Equations
Historically linear algebra grew out of eﬀorts to ﬁnd
eﬃcient methods for solving sets of linear equations. As we have said, the subject
has developed far beyond the solution of sets of numerical equations (which are
easily solved by computer), but the ideas and methods developed for that purpose
are needed in later work. A simple way to learn these techniques is to use them
to solve some numerical problems by hand. In this section and the next we will
develop methods of working with sets of linear equations, and introduce deﬁnitions
and notation which will be useful later. Also, as you will see, we will discover how
to tell whether a given set of equations has a solution or not.
Example 1.
Consider the set of equations
(2.3)



2x
−
z = 2,
6x + 5y + 3z = 7,
2x −
y
= 4.
Let’s agree always to write sets of equations in this standard form with the x terms
lined up in a column (and similarly for the other variables), and with the constants
on the right hand sides of the equations. Then there are several matrices of interest
connected with these equations. First is the matrix of the coeﬃcients which we will
call M:
(2.4)
M =


2
0
−1
6
5
3
2
−1
0

.
Then there are two 3 by 1 matrices which we will call r and k:
(2.5)
r =


x
y
z

,
k =


2
7
4

.
If we use index notation and replace x, y, z, by x1, x2, x3, and call the constants
k1, k2, k3, then we could write the equations (2.3) in the form (Problem 1)
(2.6)
3

j=1
Mijxj = ki,
i = 1, 2, 3.
It is interesting to note that, as we will see in Section 6, this is exactly how matrices
are multiplied, so we will learn to write sets of equations like (2.3) as Mr = k.

Section 2
Matrices; Row Reduction
85
For right now we are interested in the fact that we can display all the essential
numbers in equations (2.3) as a matrix known as the augmented matrix which we
call A. Note that the ﬁrst three columns of A are just the columns of M, and the
fourth column is the column of constants on the right hand sides of the equations.
(2.7)
A =


2
0
−1
2
6
5
3
7
2
−1
0
4

.
Instead of working with a set of equations and writing all the variables, we can just
work with the matrix (2.7). The process which we are going to show is called row
reduction and is essentially the way your computer solves a set of linear equations.
Row reduction is just a systematic way of taking linear combinations of the given
equations to produce a simpler but equivalent set of equations. We will show the
process, writing side-by-side the equations and the matrix corresponding to them.
(a) The ﬁrst step is to use the ﬁrst equation in (2.3) to eliminate the x terms in
the other two equations. The corresponding matrix operation on (2.7) is to subtract
3 times the ﬁrst row from the second row and subtract the ﬁrst row from the third
row. This gives:



2x
−
z = 2,
5y + 6z = 1,
−
y +
z = 2.


2
0
−1
2
0
5
6
1
0
−1
1
2


(b) Now it is convenient to interchange the second and third equations to get:



2x
−
z = 2,
−
y +
z = 2,
5y + 6z = 1.


2
0
−1
2
0
−1
1
2
0
5
6
1


(c) Next we use the second equation to eliminate the y terms from the other
equations:



2x
−
z = 2,
−y +
z = 2,
11z = 11.


2
0
−1
2
0
−1
1
2
0
0
11
11


(d) Finally, we divide the third equation by 11 and then use it to eliminate the
z terms from the other equations:



2x
= 3,
−y
= 1,
z = 1.


2
0
0
3
0
−1
0
1
0
0
1
1


It is customary to divide each equation by the leading coeﬃcient so that the equa-
tions read x = 3/2, y = −1, z = 1. The row reduced matrix is then:


1
0
0
3/2
0
1
0
−1
0
0
1
1

.
The important thing to understand here is that in ﬁnding a row reduced matrix
we have just taken linear combinations of the original equations. This process is

86
Linear Algebra
Chapter 3
reversible, so the ﬁnal simple equations are equivalent to the original ones. Let’s
summarize the allowed operations in row reducing a matrix (called elementary row
operations).
i. Interchange two rows [see step (b)];
(2.8)
ii. Multiply (or divide) a row by a (nonzero) constant [see step (d)];
iii. Add a multiple of one row to another; this includes subtracting,
that is, using a negative multiple [see steps (a) and (c)].
Example 2.
Write and row reduce the augmented matrix for the equations:
(2.9)



x −
y + 4z = 5,
2x −3y + 8z = 4,
x −2y + 4z = 9.
This time we won’t write the equations, just the augmented matrix. Remember the
routine: Use the ﬁrst row to clear the rest of the ﬁrst column; use the new second
row to clear the rest of the second column; etc. Also, since matrices are equal only
if they are identical, we will not use equal signs between them. Let’s use arrows.


1
−1
4
5
2
−3
8
4
1
−2
4
9

→


1
−1
4
5
0
−1
0
−6
0
−1
0
4

→


1
0
4
11
0
−1
0
−6
0
0
0
−20


We don’t need to go any farther! The last row says 0 · z = −20 which isn’t true for
any ﬁnite value of z. Now you see why your computer doesn’t give an answer—there
isn’t any. We say that the equations are inconsistent. If this happens for a set of
equations you have written for a physics problem, you know to look for a mistake.
Rank of a Matrix
There is another way to discuss Example 2 using the following
deﬁnition: The number of nonzero rows remaining when a matrix has been row
reduced is called the rank of the matrix. (It is a theorem that the rank of AT is the
same as the rank of A.) Now look at the reduced augmented matrix for Example 2;
it has 3 nonzero rows so its rank is 3. But the matrix M (matrix of the coeﬃcients
= ﬁrst three columns of A) has only 2 nonzero rows so its rank is 2. Note that
(rank of M) < (rank of A) and the equations are inconsistent.
Example 3.
Consider the equations
(2.10)



x + 2y −z =
4,
2x
−z =
1,
x −2y
= −3.
Either by hand or by computer we row reduce the augmented matrix to get:


1
2
−1
4
2
0
−1
1
1
−2
0
−3

→


1
0
−1/2
1/2
0
1
−1/4
7/4
0
0
0
0

.

Section 2
Matrices; Row Reduction
87
The last row of zeros tells us that there are inﬁnitely many solutions. For any z we
ﬁnd from the ﬁrst two rows that x = (z + 1)/2 and y = (z + 7)/4. Here we see that
the rank of M and the rank of A are both 2 but the number of unknowns is 3, and
we are able to ﬁnd two unknowns in terms of the third.
To make this all very clear, let’s look at some simple examples where the re-
sults are obvious. We write three sets of equations together with the row reduced
matrices:
 x + y = 2,
x + y = 5.
1
1
2
0
0
3

(2.11)

x +
y = 2,
2x + 2y = 4.

1
1
2
0
0
0

(2.12)
 x + y = 2,
x −y = 4.
1
0
3
0
1
−1

(2.13)
In (2.11), since x + y can’t be equal to both 2 and 5, it is clear that there is no
solution; the equations are inconsistent.
Note that the last row of the reduced
matrix is all zeros except for the last entry and so (rank M) < (rank A). In (2.12),
the second equation is just twice the ﬁrst so they are really the same equation; we
say that the equations are dependent. There is an inﬁnite set of solutions, namely
all points on the line y = 2−x. Note that the last line of the matrix is all zeros; this
indicates linear dependence. We have (rank A) = (rank M) = 1, and we can solve
for one unknown in terms of the other. Finally in (2.13) we have a set of equations
with one solution, x = 3, y = −1, and we see that the row reduced matrix gives
this result. Note that (rank A) = (rank M) = number of unknowns = 2.
Now let’s consider the general problem of solving m equations in n unknowns.
Then M has m rows (corresponding to m equations) and n columns (corresponding
to n unknowns) and A has one more column (the constants). The following summary
outlines the possible cases.
(2.14)
a. If (rank M) < (rank A), the equations are inconsistent and there
is no solution.
b. If (rank M) = (rank A) = n (number of unknowns), there is one
solution.
c. If (rank M) = (rank A) = R < n, then R unknowns can be found
in terms of the remaining n −R unknowns.
Example 4.
Here is a set of equations and the row reduced matrix:
(2.15)







x +
y −
z = 7,
2x −
y −
5z = 2,
−5x + 4y + 14z = 1,
3x −
y −
7z = 5.




1
0
−2
3
0
1
1
4
0
0
0
0
0
0
0
0





88
Linear Algebra
Chapter 3
From the reduced matrix, the solution is x = 3 + 2z, y = 4 −z. We see that this
is an example of (2.14c) with m = 4 (number of equations), n = 3 (number of
unknowns), (rank M) = (rank A) = R = 2 < n = 3. Then by (2.14c), we solve for
R = 2 unknowns (x and y) in terms of the n −R = 1 unknown (z).
PROBLEMS, SECTION 2
1.
The ﬁrst equation in (2.6) written out in detail is
M11x1 + M12x2 + M13x3 = k1.
Write out the other two equations in the same way and then substitute x1, x2, x3 =
x, y, z and the values of Mij and ki from (2.4) and (2.5) to verify that (2.6) is
really (2.3).
2.
As in Problem 1, write out in detail in terms of Mij, xj, and ki, equations like (2.6)
for two equations in four unknowns; for four equations in two unknowns.
For each of the following problems write and row reduce the augmented matrix to ﬁnd out
whether the given set of equations has exactly one solution, no solutions, or an inﬁnite set
of solutions. Check your results by computer. Warning hint: Be sure your equations are
written in standard form. Comment: Remember that the point of doing these problems
is not just to get an answer (which your computer will give you), but to become familiar
with the terminology, ideas, and notation we are using.
3.
x −2y + 13 = 0
y −4x = 17
4.
2x + y −
z = 2
4x + y −2z = 3
5.
2x +
y −
z = 2
4x + 2y −2z = 3
6.
x +
y −
z = 1
3x + 2y −2z = 3
7.
8
<
:
2x + 3y = 1
x + 2y = 2
x + 3y = 5
8.
8
<
:
−x +
y −
z = 4
x −
y + 2z = 3
2x −2y + 4z = 6
9.
8
<
:
x −
y + 2z = 5
2x + 3y −
z = 4
2x −2y + 4z = 6
10.
8
<
:
x + 2y −
z =
1
2x + 3y −2z = −1
3x + 4y −3z = −4
11.
8
<
:
x −2y
= 4
5x
+ z = 7
x + 2y −z = 3
12.
8
<
:
2x + 5y +
z = 2
x +
y + 2z = 1
x
+ 5z = 3
13.
8
<
:
4x + 6y −12z =
7
5x −2y +
4z = −15
3x + 4y −
8z =
4
14.
8
<
:
2x + 3y −
z = −2
x + 2y −
z =
4
4x + 7y −3z = 11
Find the rank of each of the following matrices.
15.
0
@
1
1
2
2
4
6
3
2
5
1
A
16.
0
@
2
−3
5
3
4
−1
1
1
3
−2
3
4
1
A
17.
0
B
B
@
1
1
4
3
3
1
10
7
4
2
14
10
2
0
6
4
1
C
C
A
18.
0
B
B
@
1
0
1
0
−1
−2
−1
0
2
2
5
3
2
4
8
6
1
C
C
A

Section 3
Determinants; Cramer’s Rule
89
3. DETERMINANTS; CRAMER’S RULE
We have said that a matrix is simply a display of a set of numbers; it does not
have a numerical value. For a square matrix, however, there is a useful number
called the determinant of the matrix. Although a computer will quickly give the
value of a determinant, we need to know what this value means in order to use it
in applications. [See, for example, equations (4.19), (6.24) and (8.5).] We also need
to know how to work with determinants. An easy way to learn these things is to
solve some numerical problems by hand. We shall outline some of the facts about
determinants without proofs (for more details, see linear algebra texts).
Evaluating Determinants
To indicate that we mean the determinant of a square
matrix A (written det A), we replace the large parentheses inclosing A by single bars.
The value of det A if A is a 1 by 1 matrix is just the value of the single element.
For a 2 by 2 matrix,
(3.1)
A =

a
b
c
d

,
det A =

a
b
c
d
 = ad −bc.
Equation (3.1) gives the value of a second order determinant. We shall describe
how to evaluate determinants of higher order.
First we need some notation and deﬁnitions. It is convenient to write an nth or-
der determinant like this:
(3.2)

a11
a12
a13
· · ·
a1n
a21
a22
a23
· · ·
a2n
a31
a32
a33
· · ·
a3n
...
...
...
an1
an2
an3
· · ·
ann

.
Notice that a23 is the element in the second row and the third column; that is, the
ﬁrst subscript is the number of the row and the second subscript is the number of
the column in which the element is. Thus the element aij is in row i and column j.
As an abbreviation for the determinant in (3.2), we sometimes write simply |aij|,
that is, the determinant whose elements are aij. In this form it looks exactly like
the absolute value of the element aij and you have to tell from the context which
of these meanings is intended.
If we remove one row and one column from a determinant of order n, we have
a determinant of order n −1. Let us remove the row and column containing the
element aij and call the remaining determinant Mij. The determinant Mij is called
the minor of aij. For example, in the determinant
(3.3)

1
−5
2
7
3
4
2
1
5

,
the minor of the element a23 = 4 is
M23 =

1
−5
2
1
 ,

90
Linear Algebra
Chapter 3
obtained by crossing oﬀthe row and column containing 4.
The signed minor
(−1)i+jMij is called the cofactor of aij.
In (3.3), the element 4 is in the sec-
ond row (i = 2) and third column (j = 3), so i + j = 5, and the cofactor of 4 is
(−1)5M23 = −11. It is very convenient to get the proper sign (plus or minus) for
the factor (−1)i+j by thinking of a checkerboard of plus and minus signs like this:
(3.4)

+
−
+
−
−
+
−
+
+
−
+
−
etc.
−
+
−
+
etc.
...
+
−
−
+

.
Then the sign (−1)i+j to be attached to Mij is just the checkerboard sign in the
same position as aij. For the element a23, you can see that the checkerboard sign
is minus.
Now we can easily say how to ﬁnd the value of a determinant: Multiply each
element of one row (or one column) by its cofactor and add the results. It can be
shown that we get the same answer whichever row or column we use.
Example 1.
Let us evaluate the determinant in (3.3) using elements of the third column.
We get

1
−5
2
7
3
4
2
1
5

= 2

7
3
2
1
 −4

1
−5
2
1
 + 5

1
−5
7
3

= 2 · 1 −4 · 11 + 5 · 38 = 148.
As a check, using elements of the ﬁrst row, we get
1

3
4
1
5
 + 5

7
4
2
5
 + 2

7
3
2
1
 = 11 + 135 + 2 = 148.
The method of evaluating a determinant which we have described here is one
form of Laplace’s development of a determinant. If the determinant is of fourth order
(or higher), using the Laplace development once gives us a set of determinants of
order one less than we started with; then we use the Laplace development all over
again to evaluate each of these, and so on until we get determinants of second order
which we know how to evaluate. This is obviously a lot of work! We will see below
how to simplify the calculation. A word of warning to anyone who has learned a
special method of evaluating a third-order determinant by recopying columns to the
right and multiplying along diagonals: this method does not work for fourth order
(and higher).

Section 3
Determinants; Cramer’s Rule
91
Useful Facts About Determinants
We state these facts without proof. (See
algebra books for proofs.)
1. If each element of one row (or one column) of a determinant is multiplied
by a number k, the value of the determinant is multiplied by k.
2. The value of a determinant is zero if
(a) all elements of one row (or column) are zero; or if
(b) two rows (or two columns) are identical; or if
(c) two rows (or two columns) are proportional.
3. If two rows (or two columns) of a determinant are interchanged, the value
of the determinant changes sign.
4. The value of a determinant is unchanged if
(a) rows are written as columns and columns as rows; or if
(b) we add to each element of one row, k times the corresponding element
of another row, where k is any number (and a similar statement for
columns).
Let us look at a few examples of the use of these facts.
Example 2.
Find the equation of a plane through the three given points (0, 0, 0), (1, 2, 5),
and (2, −1, 0).
We shall verify that the answer in determinant form is

x
y
z
1
0
0
0
1
1
2
5
1
2
−1
0
1

= 0.
By a Laplace development using elements of the ﬁrst row, we would ﬁnd that this
is a linear equation in x, y, z; thus it represents a plane. We need now to show
that the three points are in the plane. Suppose (x, y, z) = (0, 0, 0); then the ﬁrst
two rows of the determinant are identical and by Fact 2b the determinant is zero.
Similarly if the point (x, y, z) is either of the other given points, two rows of the
determinant are identical and the determinant is zero. Thus all three points lie in
the plane.
Example 3.
Evaluate the determinant
D =

0
a
−b
−a
0
c
b
−c
0

.

92
Linear Algebra
Chapter 3
If we interchange rows and columns in D, then by Facts 4a and 1 we have
D =

0
−a
b
a
0
−c
−b
c
0

= (−1)3

0
a
−b
−a
0
c
b
−c
0

,
where in the last step we have factored −1 out of each column by Fact 1. Thus we
have D = −D, so D = 0.
We can use Facts 1 to 4 to simplify ﬁnding the value of a determinant. First
we check Facts 2a, 2b, 2c, in case the determinant is trivially equal to zero. Then
we try to get as many zeros as possible in some row or column in order to have
fewer terms in the Laplace development. We look for rows (or columns) which can
be combined (using Fact 4b) to give zeros. Although this is something like row
reduction, we can operate with columns as well as rows. However, we can’t just
cancel a number from a row (or column); by Fact 1 we must keep it as a factor in
our answer. And we must keep track of any row (or column) interchanges since by
Fact 3 each interchange multiplies the determinant by (−1).
Example 4.
Evaluate the determinant
D =

4
3
0
1
9
7
2
3
4
0
2
1
3
−1
4
0

.
Subtract 4 times the fourth column from the ﬁrst column, and subtract 2 times the
fourth column from the third column to get:
D =

0
3
−2
1
−3
7
−4
3
0
0
0
1
3
−1
4
0

.
Do a Laplace development using the third row:
(3.5)
D = (−1)

0
3
−2
−3
7
−4
3
−1
4

.
Add the second row to the third row:
D = (−1)

0
3
−2
−3
7
−4
0
6
0

.
Do a Laplace development using the ﬁrst column:
D = (−1)(−1)(−3)

3
−2
6
0
 = (−3)[0 −6(−2)] = −36.
This is the answer but you might like to look for some shorter solutions. For exam-
ple, consider the determinant (3.5) above. If we immediately do another Laplace
development using the ﬁrst row, the minor of 3 in the ﬁrst row, second column is

−3
−4
3
4
 .

Section 3
Determinants; Cramer’s Rule
93
Without even evaluating it, we should recognize by Fact 2c that it is zero. Then
proceeding with the Laplace development of (3.5) using the ﬁrst row gives just
D = (−1)(−2)

−3
7
3
−1
 = 2(3 −21) = −36
as above.
Now you may be wondering why you should learn about this when your computer
will do it for you. Suppose you have a determinant with elements which are algebraic
expressions, and you want to write it in a diﬀerent form. Then you need to know
what manipulations you can do without changing its value. Also, if you know the
rules, you may see that a determinant is zero without evaluating it. An easy way
to learn these things is to evaluate some simple numerical determinants by hand.
Cramer’s Rule
This is a formula in terms of determinants for the solution of n
linear equations in n unknowns when there is exactly one solution. As we said for
row reduction and for evaluating determinants, your computer will quickly give you
the solution of a set of linear equations when there is one. However, for theoretical
purposes, we need the Cramer’s rule formula, and a simple way to learn about it is
to use it to solve sets of linear equations with numerical coeﬃcients.
Let us ﬁrst show the use of Cramer’s rule to solve two equations in two unknowns.
Then we will generalize it to n equations in n unknowns.
Consider the set of
equations
(3.6)
 a1x + b1y = c1,
a2x + b2y = c2.
If we multiply the ﬁrst equation by b2, the second by b1, and then subtract the
results and solve for x, we get (if a1b2 −a2b1 ̸= 0)
(3.7a)
x = c1b2 −c2b1
a1b2 −a2b1
.
Solving for y in a similar way, we get
(3.7b)
y = a1c2 −a2c1
a1b2 −a2b1
.
Using the deﬁnition (3.1) of a second order determinant, we can write the solutions
(3.7) of (3.6) in the form
(3.8)
x =

c1
b1
c2
b2


a1
b1
a2
b2

,
y =

a1
c1
a2
c2


a1
b1
a2
b2

.
It is helpful in remembering (3.8) to say in words how we ﬁnd the correct determi-
nants. First, the equations must be written in standard form as for row reduction
(Section 2). Then if we simply write the array of coeﬃcients on the left-hand side
of (3.6), these form the denominator determinant in (3.8). This determinant (which
we shall denote by D) is called the determinant of the coeﬃcients. To ﬁnd the nu-
merator determinant for x, start with D, erase the x coeﬃcients a1 and a2, and
replace them by the constants c1 and c2 from the right-hand sides of the equa-
tions. Similarly, we replace the y coeﬃcients in D by the constant terms to ﬁnd the
numerator determinant in y.

94
Linear Algebra
Chapter 3
Example 5.
Use (3.8) to solve the set of equations

2x + 3y = 3,
x −2y = 5.
We ﬁnd
D =

2
3
1
−2
 = −4 −3 = −7,
x = 1
D

3
3
5
−2
 = −6 −15
−7
= 3,
y = 1
D

2
3
1
5
 = 10 −3
−7
= −1.
This method of solution of a set of linear equations is called Cramer’s rule. It
may be used to solve n equations in n unknowns if D ̸= 0; the solution then
consists of one value for each unknown. The denominator determinant D is the
n by n determinant of the coeﬃcients when the equations are arranged in standard
form. The numerator determinant for each unknown is the determinant obtained
by replacing the column of coeﬃcients of that unknown in D by the constant
terms from the right-hand sides of the equations. Then to ﬁnd the unknowns, we
must evaluate each of the determinants and divide.
Rank of a Matrix
Here is another way to ﬁnd the rank of a matrix (Section 2).
A submatrix means a matrix remaining if we remove some rows and/or remove
some columns from the original matrix. To ﬁnd the rank of a matrix, we look at
all the square submatrices and ﬁnd their determinants. The order of the largest
nonzero determinant is the rank of the matrix.
Example 6.
Find the rank of the matrix


1
−1
2
3
−2
2
−1
0
4
−4
5
6

.
We need to look at the four 3 by 3 determinants containing columns 1,2,3 or 1,2,4 or
1,3,4 or 2,3,4. We note that the ﬁrst two columns are negatives of each other, so by
Fact 2c the ﬁrst two of these determinants are both zero. The last two determinants
diﬀer only in the sign of their ﬁrst column, so we just have to look at one of them,
say:


1
2
3
−2
−1
0
4
5
6

.
If we now subtract twice the ﬁrst row from the third row, we have


1
2
3
−2
−1
0
2
1
0

,

Section 3
Determinants; Cramer’s Rule
95
and we see by Fact 2c that the determinant is zero. So the rank of the matrix is
less than 3. To show that it is 2, we just have to ﬁnd one 2 by 2 submatrix with
nonzero determinant. There are several of them; ﬁnd one. Thus the rank of the
matrix is 2. (If we had needed to show that the rank was 1, we would have had to
show that all the 2 by 2 submatrices had determinants equal to zero.)
PROBLEMS, SECTION 3
Evaluate the determinants in Problems 1 to 6 by the methods shown in Example 4. Re-
member that the reason for doing this is not just to get the answer (your computer can
give you that) but to learn how to manipulate determinants correctly. Check your answers
by computer.
1.
˛˛˛˛˛˛
−2
3
4
3
4
−2
5
6
−3
˛˛˛˛˛˛
2.
˛˛˛˛˛˛
5
17
3
2
4
−3
11
0
2
˛˛˛˛˛˛
3.
˛˛˛˛˛˛˛˛
1
1
1
1
1
2
3
4
1
3
6
10
1
4
10
20
˛˛˛˛˛˛˛˛
4.
˛˛˛˛˛˛˛˛
−2
4
7
3
8
2
−9
5
−4
6
8
4
2
−9
3
8
˛˛˛˛˛˛˛˛
5.
˛˛˛˛˛˛˛˛˛˛
7
0
1
−3
5
2
−1
0
1
4
7
−3
2
−1
4
8
6
−2
−7
4
1
3
−5
7
5
˛˛˛˛˛˛˛˛˛˛
6.
˛˛˛˛˛˛˛˛˛˛
0
1
1
1
1
1
0
1
1
1
1
1
0
1
1
1
1
1
0
1
1
1
1
1
0
˛˛˛˛˛˛˛˛˛˛
7.
Prove the following by appropriate manipulations using Facts 1 to 4; do not just
evaluate the determinants.
˛˛˛˛˛˛
1
a
bc
1
b
ac
1
c
ab
˛˛˛˛˛˛
=
˛˛˛˛˛˛
1
a
a2
1
b
b2
1
c
c2
˛˛˛˛˛˛
= (c −a)(b −a)(c −b)
˛˛˛˛˛˛
1
a
a2
0
1
b + a
0
0
1
˛˛˛˛˛˛
= (c −a)(b −a)(c −b).
8.
Show that if, in using the Laplace development, you accidentally multiply the ele-
ments of one row by the cofactors of another row, you get zero.
Hint: Consider Fact 2b.
9.
Show without computation that the following determinant is equal to zero.
Hint: Consider the eﬀect of interchanging rows and columns.
˛˛˛˛˛˛
0
2
−3
−2
0
4
3
−4
0
˛˛˛˛˛˛
10.
A determinant or a square matrix is called skew-symmetric if aij = −aji. (The
determinant in Problem 9 is an example of a skew-symmetric determinant.) Show
that a skew-symmetric determinant of odd order is zero.
In Problems 11 and 12 evaluate the determinants.
11.
˛˛˛˛˛˛˛˛˛˛
0
5
−3
−4
1
−5
0
2
6
−2
3
−2
0
−3
7
4
−6
3
0
−3
−1
2
−7
3
0
˛˛˛˛˛˛˛˛˛˛
12.
˛˛˛˛˛˛˛˛
0
1
2
−1
−1
0
−3
0
−2
3
0
1
1
0
−1
0
˛˛˛˛˛˛˛˛

96
Linear Algebra
Chapter 3
13.
Show that
˛˛˛˛˛˛
cos θ
1
0
1
2 cos θ
1
0
1
2 cos θ
˛˛˛˛˛˛
= cos 3θ.
14.
Show that the n-rowed determinant
˛˛˛˛˛˛˛˛˛˛˛˛˛˛˛˛˛
cos θ
1
0
0
0
1
2 cos θ
1
0
· · ·
· · ·
0
0
1
2 cos θ
1
0
0
0
1
2 cos θ
0
...
...
...
...
2 cos θ
1
0
0
0
0
· · ·
1
2 cos θ
˛˛˛˛˛˛˛˛˛˛˛˛˛˛˛˛˛
= cos nθ.
Hint: Expand using elements of the last row or column. Use mathematical induction
and the trigonometric addition formulas.
15.
Use Cramer’s rule to solve Problems 2.3 and 2.11.
16.
In the following set of equations (from a quantum mechanics problem), A and B are
the unknowns, k and K are given, and i = √−1. Use Cramer’s rule to ﬁnd A and
show that |A|2 = 1.

A −
B = −1
ikA −KB = ik
17.
Use Cramer’s rule to solve for x and t the Lorentz equations of special relativity:
x′ = γ(x −vt)
t′ = γ(t −vx/c2)
where
γ2(1 −v2/c2) = 1
Caution: Arrange the equations in standard form.
18.
Find z by Cramer’s rule:
8
<
:
(a −b)x −
(a −b)y +
3b2z = 3ab
(a + 2b)x −(a + 2b)y −(3ab + 3b2)z = 3b2
bx +
ay −
(2b2 + a2)z =
0
Figure 4.1
4. VECTORS
Notation
We shall indicate a vector by a boldface letter (for
example, A) and a component of a vector by a subscript (for
example Ax is the x component of A), as in Figure 4.1. Since it
is not easy to handwrite boldface letters, you should write a vec-
tor with an arrow over it (for example, ⃗A). It is very important
to indicate clearly whether a letter represents a vector, since,
as we shall see below, the same letter in italics (not boldface)
is often used with a diﬀerent meaning.
Magnitude of a Vector
The length of the arrow representing a vector A is
called the length or the magnitude of A (written |A| or A) or (see Section 10) the
norm of A (written ||A||). Note the use of A to mean the magnitude of A; for this
reason it is important to make it clear whether you mean a vector or its magnitude
(which is a scalar). By the Pythagorean theorem, we ﬁnd

Section 4
Vectors
97
A = |A| =

A2x + A2y
in two dimensions,
or
A = |A| =

A2x + A2y + A2z
in three dimensions.
(4.1)
Example 1.
In Figure 4.2 the force F has an x component of 4 lb and a y component of
3 lb. Then we write
Figure 4.2
Fx = 4 lb,
Fy = 3 lb,
|F| = 5 lb,
θ = arc tan 3
4.
Addition of Vectors
There are two ways to get the sum of two vectors. One is
by the parallelogram law: To ﬁnd A + B, place the tail of B at the head of A and
draw the vector from the tail of A to the head of B as shown in Figures 4.3 and 4.4.
Figure 4.3
Figure 4.4
The second way of ﬁnding A + B is to add components: A + B has components
Ax + Bx and Ay + By. You should satisfy yourself from Figure 4.3 that these two
methods of ﬁnding A + B are equivalent. From Figure 4.4 and either deﬁnition of
vector addition, it follows that
A + B = B + A
(commutative law for addition);
(A + B) + C = A + (B + C)
(associative law for addition).
In other words, vectors may be added together by the usual laws of algebra.
It seems reasonable to use the symbol 3A for the vector A + A + A. By the
methods of vector addition above, we can say that the vector A+A+A is a vector
three times as long as A and in the same direction as A and that each component
of 3A is three times the corresponding component of A. As a natural extension of
these facts we deﬁne the vector cA (where c is any real positive number) to be a
vector c times as long as A and in the same direction as A; each component of cA
is then c times the corresponding component of A (Figure 4.5).
The negative of a vector is deﬁned as a vector of the same magnitude but in
the opposite direction. Then (Figure 4.6) each component of −B is the negative of
the corresponding component of B. We can now deﬁne subtraction of vectors by

98
Linear Algebra
Chapter 3
Figure 4.5
Figure 4.6
saying that A −B means the sum of the vectors A and −B. Each component of
A −B is then obtained by subtracting the corresponding components of A and B,
that is, (A −B)x = Ax −Bx, etc. Like addition, subtraction of vectors can be
done geometrically (by the parallelogram law) or algebraically by subtracting the
components (Figure 4.6).
The zero vector (which might arise as A = B−B = 0, or as A = cB with c = 0)
is a vector of zero magnitude; its components are all zero and it does not have a
direction. A vector of length or magnitude 1 is called a unit vector. Then for any
A ̸= 0, the vector A/|A| is a unit vector. In Example 1, F/5 is a unit vector.
We have just seen that there are two ways to combine vectors: geometric (head
to tail addition), and algebraic (using components). Let us look ﬁrst at an example
of the geometric method; then we shall consider the algebraic method. Example 2
below illustrates the geometric method. By similar proofs, many of the facts of
elementary geometry can be easily proved using vectors, with no reference to com-
ponents or a coordinate system. (See Problems 3 to 8.)
Example 2.
Prove that the medians of a triangle intersect at a point two-thirds of the
way from any vertex to the midpoint of the opposite side.
To prove this, we call two of the sides of the triangle A and B. The third side
of the triangle is then A + B by the parallelogram law, with the directions of A,
B, and A + B as indicated in Figure 4.7. If we add the vector 1
2B to the vector A
(head to tail as in Figure 4.7b), we have a vector from point O to the midpoint of
the opposite side of the triangle, that is, we have the median to side B. Next, take
two-thirds of this vector; we now have the vector 2
3(A+ 1
2B) = 2
3A+ 1
3B extending
from O to P in Figure 4.7b. We want to show that P is the intersection point of
the three medians and also the “ 2
3 point” for each. We prove this by showing that
P is the “ 2
3 point” on the median to side A; then since A and B represent any two
sides of the triangle, the proof holds for all three medians. The vector from R to Q
(Figure 4.7c) is 1
2A + B; this is the median to A. The “ 2
3 point” on this median is
the point P ′ (Figure 4.7d); the vector from R to P ′ is equal to 1
3( 1
2A + B). Then
the vector from O to P ′ is 1
2A + 1
3( 1
2A + B) = 2
3A + 1
3B. Thus P and P ′ are the
same point and all three medians have their “ 2
3 points” there. Note that we have
made no reference to a coordinate system or to components in this proof.

Section 4
Vectors
99
Figure 4.7
PROBLEMS, SECTION 4
1.
Draw diagrams and prove (4.1).
2.
Given the vectors making the given angles θ with the positive x axis:
A of magnitude 5, θ = 45◦,
B of magnitude 3, θ = −30◦,
C of magnitude 7, θ = 120◦,
(a)
Draw diagrams representing 2A, A −2B, C −B, 2
5A −1
7C.
(b)
Draw diagrams to show that
A + B = B + A
A −(B −C) = (A −B) + C,
(A + B) + C = (A + C) + B,
(A + B)x = Ax + Bx,
(B −C)x = Bx −Cx.
Use vectors to prove the following theorems from geometry:
3.
The diagonals of a parallelogram bisect each other.
4.
The line segment joining the midpoints of two sides of any triangle is parallel to the
third side and half its length.
5.
In a parallelogram, the two lines from one corner to the midpoints of the two opposite
sides trisect the diagonal they cross.

100
Linear Algebra
Chapter 3
6.
In any quadrilateral (four-sided ﬁgure with sides of various lengths and—in general—
four diﬀerent angles), the lines joining the midpoints of opposite sides bisect each
other. Hint: Label three sides A, B, C; what is the vector along the fourth side?
7.
A line through the midpoint of one side of a triangle and parallel to a second side
bisects the third side. Hint: Call parallel vectors A and cA.
8.
The median of a trapezoid (four-sided ﬁgure with just two parallel sides) means the
line joining the midpoints of the two nonparallel sides. Prove that the median bisects
both diagonals; that the median is parallel to the two parallel bases and equal to
half the sum of their lengths.
We have discussed in some detail the geometric method of adding vectors (par-
allelogram law or head to tail addition) and its importance in stating and proving
geometric and physical facts without the intrusion of a special coordinate system.
There are, however, many cases in which algebraic methods (using components
relative to a particular coordinate system) are better. We shall discuss this next.
Vectors in Terms of Components
We consider a set of rectangular axes as in
Figure 4.8. Let the vector i be a unit vector in the positive x direction (out of the
paper toward you), and let j and k be unit vectors in the positive y and z directions.
If Ax and Ay are the scalar components of a vector in the (x, y) plane, then iAx
and jAy are its vector components, and their sum is the vector A (Figure 4.9).
A = iAx + jAy.
Figure 4.8
Figure 4.9
Similarly, in three dimensions
A = iAx + jAy + kAz.
It is easy to add (or subtract) vectors in this form: If A and B are vectors in two
dimensions, then
A + B = (iAx + jAy) + (iBx + jBy) = i(Ax + Bx) + j(Ay + By).
This is just the familiar result of adding components; the unit vectors i and j serve to
keep track of the separate components and allow us to write A as a single algebraic
expression. The vectors i, j, k are called unit basis vectors.
Multiplication of Vectors
There are two kinds of product of two vectors. One,
called the scalar product (or dot product or inner product), gives a result which is a
scalar; the other, called the vector product (or cross product), gives a vector answer.

Section 4
Vectors
101
Scalar Product
By deﬁnition, the scalar product of A and B (written A · B) is
a scalar equal to the magnitude of A times the magnitude of B times the cosine of
the angle θ between A and B:
(4.2)
A · B = |A| |B| cos θ.
You should observe from (4.2) that the commutative law (4.3) holds for scalar mul-
tiplication:
(4.3)
A · B = B · A.
A useful interpretation of the dot product is shown in Figure 4.10.
|B| = 8, |A| = 6.
Projection of B on A = 4;
A · B = 6 · 4 = 24.
Or, projection of A on B = 3;
B · A = 3 · 8 = 24.
Figure 4.10
Since |B| cos θ is the projection of B on A, we can write
(4.4)
A · B = |A| times (projection of B on A),
or, alternatively,
A · B = |B| times (projection of A on B).
Also we ﬁnd from (4.2) that
(4.5)
A · A = |A|2 cos0◦= |A|2 = A2.
Sometimes A2 is written instead of |A|2 or A2; you should understand that the
square of a vector always means the square of its magnitude or its dot product with
itself.
Figure 4.11

102
Linear Algebra
Chapter 3
From Figure 4.11 we can see that the projection of B + C on A is equal to the
projection of B on A plus the projection of C on A. Then by (4.4)
A · (B + C) = |A| times (projection of (B + C) on A)
(4.6)
= |A| times (projection of B on A + projection of C on A)
= A · B + A · C.
This is the distributive law for scalar multiplication. By (4.3) we get also
(4.7)
(B + C) · A = B · A + C · A = A · B + A · C.
The component form of A · B is very useful. We write
(4.8)
A · B = (iAx + jAy + kAz) · (iBx + jBy + kBz).
By the distributive law we can multiply this out getting nine terms such as AxBxi·i,
AxByi · j, and so on. Using the deﬁnition of the scalar product, we ﬁnd
i · i = |i| · |i| cos 0◦= 1 · 1 · 1 = 1, and similarly, j · j = 1, k · k = 1;
i · j = |i| · |j| cos 90◦= 1 · 1 · 0 = 0, and similarly, i · k = 0, j · k = 0.
(4.9)
Using (4.9) in (4.8), we get
(4.10)
A · B = AxBx + AyBy + AzBz.
Equation (4.10) is an important formula which you should memorize. There are sev-
eral immediate uses of this formula and of the dot product.
Angle Between Two Vectors
Given the vectors, we can ﬁnd the angle between
them by using both (4.2) and (4.10) and solving for cos θ.
Example 3.
Find the angle between the vectors A = 3i + 6j + 9k and B = −2i + 3j + k.
By (4.2) and (4.10) we get
A · B = |A| |B| cos θ = 3 · (−2) + 6 · 3 + 9 · 1 = 21,
|A| =

32 + 62 + 92 = 3
√
14,
|B| =

22 + 32 + 12 =
√
14,
(4.11)
3
√
14
√
14 cos θ = 21,
cos θ = 1
2,
θ = 60◦.
Perpendicular and Parallel Vectors
If two vectors are perpendicular, then
cos θ = 0; thus
(4.12)
AxBx + AyBy + AzBz = 0
if
A and B are perpendicular vectors.
If two vectors are parallel, their components are proportional; thus (when no com-
ponents are zero)

Section 4
Vectors
103
(4.13)
Ax
Bx
= Ay
By
= Az
Bz
if
A and B are parallel vectors.
(Of course, if Bx = 0, then Ax = 0, etc.)
Vector Product
The vector or cross product of A and B is written A × B. By
deﬁnition, A × B is a vector whose magnitude and direction are given as follows:
The magnitude of A × B is
(4.14)
|A × B| = |A| |B| sin θ,
where θ is the positive angle (≤180◦) between A and B.
The direction of A × B is perpendicular to the plane of A
and B and in the sense C of advance of a right-handed screw
rotated from A to B as in Figure 4.12.
Figure 4.12
It is convenient to ﬁnd the direction of C = A×B by the following right-hand rule.
Think of grasping the line C (or a screwdriver driving a right-handed screw in the
direction C) with the right hand. The ﬁngers then curl in the direction of rotation
of A into B (arrow in Figure 4.12) and the thumb points along C = A × B.
Perhaps the most startling result of the vector product deﬁnition is that A × B
and B × A are not equal; in fact, A × B = −B × A. In mathematical language,
vector multiplication is not commutative.
We ﬁnd from (4.14) that the cross product of any two parallel (or antiparallel)
vectors has magnitude |A × B| = AB sin 0◦= 0 (or AB sin 180◦= 0). Thus
A × B = 0
if A and B are parallel or antiparallel,
A × A = 0
for any A.
(4.15)
Then we have the useful results
(4.16)
i × i = j × j = k × k = 0.
Also from (4.14) we ﬁnd
|i × j| = |i| |j| sin 90◦= 1 · 1 · 1 = 1,
and similarly for the magnitude of the cross product of any two diﬀerent unit vectors
i, j, k. From the right-hand rule and Figure 4.13, we see that the direction of i × j
is k, and since its magnitude is 1, we have i ×j = k; however, j×i = −k. Similarly
evaluating the other cross products, we ﬁnd

104
Linear Algebra
Chapter 3
(4.17)
i × j = k
j × k = i
k × i = j.
j × i = −k
k × j = −i
i × k = −j.
A good way to remember these is to write them cyclically (around a circle as in-
dicated in Figure 4.14).
Reading around the circle counterclockwise (positive θ
direction), we get the positive products (for example, i × j = k); reading the other
way we get the negative products (for example, i × k = −j).
Figure 4.13
Figure 4.14
It is well to note here that the results (4.17) depend upon the way we have labeled
the axes in Figure 4.13. We have arranged the (x, y, z) axes so that a rotation of the
x into the y axis (through 90◦) corresponds to the rotation of a right-handed screw
advancing in the positive z direction. Such a coordinate system is called a right-
handed system. If we used a left-handed system (say exchanging x and y), then all
the equations in (4.17) would have their signs changed. This would be confusing;
consequently, we practically always use right-handed coordinate systems, and we
must be careful about this in drawing diagrams. (See Chapter 10, Section 6.)
To write A × B in component form we need the distributive law, namely
(4.18)
A × (B + C) = A × B + A × C.
(see Problem 7.18).
Then we ﬁnd
A × B = (iAx + jAy + kAz) × (iBx + jBy + kBz)
(4.19)
= i(AyBz −AzBy) + j(AzBx −AxBz) + k(AxBy −AyBx)
=

i
j
k
Ax
Ay
Az
Bx
By
Bz

.
The second line in (4.19) is obtained by multiplying out the ﬁrst line (getting nine
products) and using (4.16) and (4.17). The determinant in (4.19) is the most con-
venient way to remember the component form of the vector product. You should
verify that multiplying out the determinant using the elements of the ﬁrst row gives
the result in the line above it.

Section 4
Vectors
105
Since A × B is a vector perpendicular to A and to B, we can use (4.19) to ﬁnd
a vector perpendicular to two given vectors.
Example 4.
Find a vector perpendicular to both A = 2i + j −k and B = i + 3j −2k.
A × B =

i
j
k
2
1
−1
1
3
−2

= i(−2 + 3) −j(−4 + 1) + k(6 −1)
= i + 3j + 5k.
PROBLEMS, SECTION 4
9.
Let A = 2i + 3j and B = 4i −4j. Show graphically, and ﬁnd algebraically, the
vectors −A, 3B, A −B, B + 2A, 1
2(A + B).
10.
If A + B = 4j −i and A −B = i + 3j, ﬁnd A and B algebraically. Show by a
diagram how to ﬁnd A and B geometrically.
11.
Let 3i−j+4k, 7j−2k, i−3j+k be three vectors with tails at the origin. Then their
heads determine three points A, B, C in space which form a triangle. Find vectors
representing the sides AB, BC, CA in that order and direction (for example, A to
B, not B to A) and show that the sum of these vectors is zero.
12.
Find the angle between the vectors A = −2i + j −2k and B = 2i −2j.
13.
If A = 4i −3k and B = −2i + 2j −k, ﬁnd the scalar projection of A on B, the
scalar projection of B on A, and the cosine of the angle between A and B.
14.
Find the angles between (a) the space diagonals of a cube; (b) a space diagonal and
an edge; (c) a space diagonal and a diagonal of a face.
15.
Let A = 2i −j + 2k. (a) Find a unit vector in the same direction as A. Hint:
Divide A by |A|. (b) Find a vector in the same direction as A but of magnitude 12.
(c) Find a vector perpendicular to A. Hint: There are many such vectors; you are
to ﬁnd one of them. (d) Find a unit vector perpendicular to A. See hint in (a).
16.
Find a unit vector in the same direction as the vector A = 4i −2j+ 4k, and another
unit vector in the same direction as B = −4i + 3k. Show that the vector sum of
these unit vectors bisects the angle between A and B. Hint: Sketch the rhombus
having the two unit vectors as adjacent sides.
17.
Find three vectors (none of them parallel to a coordinate axis) which have lengths
and directions such that they could be made into a right triangle.
18.
Show that 2i −j + 4k and 5i + 2j −2k are orthogonal (perpendicular). Find a third
vector perpendicular to both.
19.
Find a vector perpendicular to both i −3j + 2k and 5i −j −4k.
20.
Find a vector perpendicular to both i + j and i −2k.
21.
Show that B|A| + A|B| and A|B| −B|A| are orthogonal.
22.
Square (A + B); interpret your result geometrically. Hint: Your answer is a law
which you learned in trigonometry.
23.
If A = 2i −3j + k and A · B = 0, does it follow that B = 0? (Either prove that it
does or give a speciﬁc example to show that it doesn’t.) Answer the same question
if A × B = 0. And again answer the same question if A · B = 0 and A × B = 0.

106
Linear Algebra
Chapter 3
24.
What is the value of (A × B)2 + (A · B)2? Comment: This is a special case of
Lagrange’s identity. (See Chapter 6, Problem 3.12b, page 284.)
Use vectors as in Problems 3 to 8, and also the dot and cross product, to prove the following
theorems from geometry.
25.
The sum of the squares of the diagonals of a parallelogram is equal to twice the sum
of the squares of two adjacent sides of the parallelogram.
26.
The median to the base of an isosceles triangle is perpendicular to the base.
27.
In a kite (four-sided ﬁgure made up of two pairs of equal adjacent sides), the diag-
onals are perpendicular.
28.
The diagonals of a rhombus (four-sided ﬁgure with all sides of equal length) are
perpendicular and bisect each other.
5. LINES AND PLANES
A great deal of analytic geometry can be simpliﬁed by the use of vector notation.
Such things as equations of lines and planes, and distances between points or be-
tween lines and planes often occur in physics and it is very useful to be able to
ﬁnd them quickly. We shall talk about three-dimensional space most of the time
although the ideas apply also to two dimensions. In analytic geometry a point is
a set of three coordinates (x, y, z); we shall think of this point as the head of a
vector r = ix + jy + kz with tail at the origin. Most of the time the vector will
be in the background of our minds and we shall not draw it; we shall just plot the
point (x, y, z) which is the head of the vector. In other words, the point (x, y, z)
and the vector r will be synonymous. We shall also use vectors joining two points.
In Figure 5.1 the vector A from (1, 2, 3) to (x, y, z) is
A = r −C = (x, y, z) −(1, 2, 3) = (x −1, y −2, z −3)
or
A = ix + jy + kz −(i + 2j + 3k) = i(x −1) + j(y −2) + k(z −3).
Figure 5.1
Thus we have two ways of writing vector equations; we may choose the one we prefer.
Note the possible advantage of writing (1, 0, −2) for i−2k; since the zero is explicitly
written, there is less chance of accidentally confusing i −2k with i −2j = (1, −2, 0).
On the other hand, 5j is simpler than (0, 5, 0).
In two dimensions, we write the equation of a straight line through (x0, y0) with
slope m as
(5.1)
y −y0
x −x0
= m.

Section 5
Lines and Planes
107
Figure 5.2
Suppose, instead of the slope, we are given a vector in the direction of the line,
say A = ia+jb (Figure 5.2). Then the line through (x0, y0) and in the direction A is
determined and we should be able to write its equation. The directed line segment
from (x0, y0) to any point (x, y) on the line is the vector r −r0 with components
x −x0 and y −y0:
(5.2)
r −r0 = i(x −x0) + j(y −y0).
This vector is parallel to A = ia + jb. Now if two vectors are parallel, their compo-
nents are proportional. Thus we can write (for a, b ̸= 0)
(5.3)
x −x0
a
= y −y0
b
or
y −y0
x −x0
= b
a.
This is the equation of the given straight line. As a check we see that the slope of
the line is m = b/a, so (5.3) is the same as (5.1).
Another way to write this equation is to say that if r −r0 and A are parallel
vectors, one is some scalar multiple of the other, that is,
(5.4)
r −r0 = At,
or
r = r0 + At,
where t is the scalar multiple. We can think of t as a parameter; the component
form of (5.4) is a set of parametric equations of the line, namely
(5.5)
x −x0 = at,
y −y0 = bt,
or
x = x0 + at,
y = y0 + bt.
Eliminating t yields the equation of the line in (5.3).
In three dimensions, the same ideas can be used. We want the equations of
a straight line through a given point (x0, y0, z0) and parallel to a given vector
A = ai + bj + ck. If (x, y, z) is any point on the line, the vector joining (x0, y0, z0)
and (x, y, z) is parallel to A.
Then its components x −x0, y −y0, z −z0 are
proportional to the components a, b, c of A and we have
(5.6)
x −x0
a
= y −y0
b
= z −z0
c
(symmetric equations of a straight line,
a, b, c ̸= 0).
If c, for instance, happens to be zero, we would have to write (5.6) in the form

108
Linear Algebra
Chapter 3
(5.7)
x −x0
a
= y −y0
b
,
z = z0
(symmetric equations of a straight line
when c = 0).
As in the two-dimensional case, equations (5.6) and (5.7) could be written
(5.8)
r = r0 + At,
or





x = x0 + at,
y = y0 + bt,
z = z0 + ct,
(parametric equations
of a straight line).
The parametric equations (5.8) have a partic-
ularly useful interpretation when the parameter
t means time. Consider a particle m (electron,
billiard ball, or star) moving along the straight
line L in Figure 5.3. Position yourself at the ori-
gin and watch m move from P0 to P along L.
Your line of sight is the vector r; it swings from
r0 at t = 0 to r = r0 + At at time t. Note that
the velocity of m is dr/dt = A; A is a vector
along the line of motion.
Figure 5.3
Going back to two dimensions, suppose we want the equation of a straight line L
through the point (x0, y0) and perpendicular to a given vector N = ai+bj. As above,
the vector
r −r0 = (x −x0)i + (y −y0)j
lies along the line. This time we want this vector perpendicular to N; recall that
two vectors are perpendicular if their dot product is zero. Setting the dot product
of N and r −r0 equal to zero gives
(5.9)
a(x −x0) + b(y −y0) = 0
or
y −y0
x −x0
= −a
b .
This is the desired equation of the straight line L perpendicular to N. As a check,
note from Figure 5.4 that the slope of the line L is
tan θ = −cot φ = −a/b.
Figure 5.4
Figure 5.5
In three dimensions, we use this method to write the equation of a plane. If
(x0, y0, z0) is a given point in the plane and (x, y, z) is any other point in the plane,

Section 5
Lines and Planes
109
the vector (Figure 5.5)
r −r0 = (x −x0)i + (y −y0)j + (z −z0)k
is in the plane. If N = ai + bj + ck is normal (perpendicular) to the plane, then N
and r −r0 are perpendicular, so the equation of the plane is N · (r −r0) = 0, or
(5.10)
a(x −x0) + b(y −y0) + c(z −z0) = 0,
or
ax + by + cz = d,
(equation of a plane)
where d = ax0 + by0 + cz0.
If we are given equations like the ones above, we can read backwards to ﬁnd A
or N. Thus we can say that the equations (5.6), (5.7), and (5.8) are the equations
of a straight line which is parallel to the vector A = ai+bj+ck, and either equation
in (5.10) is the equation of a plane perpendicular to the vector N = ai + bj + ck.
Example1.
Find the equation of the plane through the three points A(−1, 1, 1), B(2, 3, 0),
C(0, 1, −2).
A vector joining any pair of the given points lies in the plane. Two such vectors
are −−→
AB = (2, 3, 0) −(−1, 1, 1) = (3, 2, −1) and −→
AC = (1, 0, −3). The cross product
of these two vectors is perpendicular to the plane. This is
N = (−−→
AB) × (−→
AC) =

i
j
k
3
2
−1
1
0
−3

= −6i + 8j −2k.
Now we write the equation of the plane with normal direction N through one of the
given points, say B, using (5.10):
−6(x −2) + 8(y −3) −2z = 0
or
3x −4y + z + 6 = 0.
(Note that we could have divided N by −2 to save arithmetic.)
Example 2.
Find the equations of a line through (1, 0, −2) and perpendicular to the plane
of Example 1.
The vector 3i−4j+k is perpendicular to the plane of Example 1 and so parallel
to the desired line. Thus by (5.6) the symmetric equations of the line are
(x −1)
3
= y
−4 = (z + 2)
1
.
By (5.8) the parametric equations of the line are r = i −2k + (3i −4j + k)t or, if
you like, r = (1, 0, −2) + (3, −4, 1)t.
Vectors give us a very convenient way of ﬁnding distances between points and
lines or planes. Suppose we want to ﬁnd the (perpendicular) distance from a point P

110
Linear Algebra
Chapter 3
Figure 5.6
to the plane (5.10). (See Figure 5.6.) We pick any point Q we like in the plane
(just by looking at the equation of the plane and thinking of some simple numbers
x, y, z that satisfy it). The distance PR is what we want. Since PR and RQ are
perpendicular (because PR is perpendicular to the plane), we have from Figure 5.6
(5.11)
PR = PQ cos θ.
From the equation of the plane, we can ﬁnd a vector N normal to the plane. If we
divide N by its magnitude, we have a unit vector normal to the plane; we denote
this unit vector by n. Then |−−→
PQ · n| = (PQ) cos θ, which is what we need in (5.11)
to ﬁnd PR. (We have put in absolute value signs because −−→
PQ·n might be negative,
whereas (PQ) cos θ, with θ acute as in Figure 5.6, is positive.)
Example 3.
Find the distance from the point P(1, −2, 3) to the plane 3x−2y +z +1 = 0.
One point in the plane is (1, 2, 0); call this point Q. Then the vector from P
to Q is
−−→
PQ = (1, 2, 0) −(1, −2, 3) = (0, 4, −3) = 4j −3k.
From the equation of the plane we get the normal vector
N = 3i −2j + k.
We get n by dividing N by |N| =
√
14. Then we have
|PR| =
−−→
PQ · n
 =
(4j −3k) · (3i −2j + k)/
√
14

=
(−8 −3)/
√
14
 = 11/
√
14.
Figure 5.7
We can ﬁnd the distance from a point P to a line in a similar way. In Figure 5.7
we want the perpendicular distance PR. We select any point on the line [that is, we
pick any (x, y, z) satisfying the equations of the line]; call
this point Q. Then (see Figure 5.7) PR = PQ sin θ. Let
A be a vector along the line and u a unit vector along the
line (obtained by dividing A by its magnitude). Then
−−→
PQ × u
 = |PQ| sin θ,
so we get
|PR| =
−−→
PQ × u
 .

Section 5
Lines and Planes
111
Example4.
Find the distance from P(1, 2, −1) to the line joining P1(0, 0, 0) and P2(−1, 0, 2).
Let A = −−−→
P1P2 = −i + 2k; this is a vector along the line. Then a unit vector
along the line is u = (1/
√
5)(−i + 2k).
Let us take Q to be P1(0, 0, 0).
Then
−−→
PQ = −i −2j + k, so we get for the distance |PR|:
|PR| =
1
√
5|(−i −2j + k) × (−i + 2k)| =
1
√
5| −4i + j −2k| =

21/5.
It is also straightforward to ﬁnd the distance between two skew lines (and if
you really want to appreciate vectors, just look up this calculation in an analytic
geometry book that doesn’t use vectors!). Pick two points P and Q, one on each
line (Figure 5.8). Then |−−→
PQ · n|, where n is a unit vector perpendicular to both
lines, is the distance we want. Now if A and B are vectors along the two lines, then
A × B is perpendicular to both, and n is just A × B divided by |A × B|.
Figure 5.8
Example5.
Find the distance between the lines r = i−2j+(i−k)t and r = 2j−k+(j−i)t.
If we write the ﬁrst line as r = r0 + At, then (the head of) r0 is a simple choice
for P, so we have
P = (1, −2, 0)
and
A = i −k.
Similarly, from the second line we ﬁnd
Q = (0, 2, −1)
and
B = j −i.
Then A × B = i + j + k and n =

1/
√
3

(i + j + k). Also
−−→
PQ = (0, 2, −1) −(1, −2, 0) = (−1, 4, −1) = −i + 4j −k.
Thus we get for the distance between the lines
−−→
PQ · n
 =
(−i + 4j −k) · (i + j + k)/
√
3
 = |−1 + 4 −1| /
√
3 = 2/
√
3 .
Example 6.
Find the direction of the line of intersection of the planes
x −2y + 3z = 4 and 2x + y −z = 5.
The desired line lies in both planes, and so is perpendicular to the two normal
vectors to the planes, namely i −2j + 3k and 2i + j −k. Then the direction of the
line is that of the cross product of these normal vectors; this is −i + 7j + 5k.

112
Linear Algebra
Chapter 3
Example 7.
Find the cosine of the angle between the planes of Example 6.
The angle between the planes is the same as the angle between the normals to
the planes. Thus our problem is to ﬁnd the angle between the vectors A = i−2j+3k
and B = 2i + j −k. Since A · B = |A| |B| cos θ, we have −3 =
√
14
√
6 cos θ, and so
cos θ = −

3/28. This gives the obtuse angle between the planes; the corresponding
acute angle is π −θ, or arc cos

3/28.
PROBLEMS, SECTION 5
In Problems 1 to 5, all lines are in the (x, y) plane.
1.
Write the equation of the straight line through (2, −3) with slope 3/4, in the para-
metric form r = r0 + At.
2.
Find the slope of the line whose parametric equation is r = (i −j) + (2i + 3j)t.
3.
Write, in parametric form [as in Problem 1], the equation of the straight line that
joins (1, −2) and (3, 0).
4.
Write, in parametric form, the equation of the straight line that is perpendicular to
r = (2i + 4j) + (i −2j)t and goes through (1, 0).
5.
Write, in parametric form, the equation of the y axis.
Find the symmetric equations (5.6) or (5.7) and the parametric equations (5.8) of a line,
and/or the equation (5.10) of the plane satisfying the following given conditions.
6.
Line through (1, −1, −5) and (2, −3, −3).
7.
Line through (2, 3, 4) and (5, 1, −2).
8.
Line through (0, −2, 4) and (3, −2, −1).
9.
Line through (−1, 3, 7) and (−1, −2, 7).
10.
Line through (3, 4, −1) and parallel to 2i −3j + 6k.
11.
Line through (4, −1, 3) and parallel to i −2k.
12.
Line through (5, −4, 2) and parallel to the line r = i −j + (5i −2j + k)t.
13.
Line through (3, 0, −5) and parallel to the line r = (2, 1, −5) + (0, −3, 1)t.
14.
Plane containing the triangle ABC of Problem 4.11.
15.
Plane through the origin and the points in Problem 8.
16.
Plane through the point and perpendicular to the line in Problem 12.
17.
Plane through the point and perpendicular to the line in Problem 13.
18.
Plane containing the two parallel lines in Problem 12.
19.
Plane containing the two parallel lines in Problem 13.
20.
Plane containing the three points (0, 1, 1), (2, 1, 3), and (4, 2, 1).
In Problems 21 to 23, ﬁnd the angle between the given planes.
21.
2x + 6y −3z = 10 and 5x + 2y −z = 12.
22.
2x −y −z = 4 and 3x −2y −6z = 7.
23.
2x + y −2z = 3 and 3x −6y −2z = 4.

Section 5
Lines and Planes
113
24.
Find a point on both the planes (that is, on their line of intersection) in Problem 21.
Find a vector parallel to the line of intersection. Write the equations of the line of
intersection of the planes. Find the distance from the origin to the line.
25.
As in Problem 24, ﬁnd the equations of the line of intersection of the planes in
Problem 22. Find the distance from the point (2, 1, −1) to the line.
26.
As in Problem 24, ﬁnd the equations of the line of intersection of the planes in
Problem 23. Find the distance from the point (1, 0, 0) to the line.
27.
Find the equation of the plane through (2, 3, −2) and perpendicular to both planes
in Problem 21.
28.
Find the equation of the plane through (−4, −1, 2) and perpendicular to both planes
in Problem 22.
29.
Find a point on the plane 2x −y −z = 13. Find the distance from (7, 1, −2) to the
plane.
30.
Find the distance from the origin to the plane 3x −2y −6z = 7.
31.
Find the distance from (−2, 4, 5) to the plane 2x + 6y −3z = 10.
32.
Find the distance from (3, −1, 2) to the plane 5x −y −z = 4.
33.
Find the perpendicular distance between the two parallel lines in Problem 12.
34.
Find the distance (perpendicular is understood) between the two parallel lines in
Problem 13.
35.
Find the distance from (2, 5, 1) to the line in Problem 10.
36.
Find the distance from (3, 2, 5) to the line in Problem 11.
37.
Determine whether the lines
x −1
2
= y + 3
1
= z −4
−3
and
x + 3
4
= y + 4
1
= 8 −z
4
intersect. Two suggestions: (1) Can you ﬁnd the intersection point, if any? (2) Con-
sider the distance between the lines.
38.
Find the angle between the lines in Problem 37.
In Problems 39 and 40, show that the given lines intersect and ﬁnd the acute angle between
them.
39.
r = 2j + k + (3i −k)t1
and
r = 7i + 2k + (2i −j + k)t2.
40.
r = (5, −2, 0) + (1, −1, −1)t1
and
r = (4, −4, −1) + (0, 3, 2)t2.
In Problems 41 to 44, ﬁnd the distance between the two given lines.
41.
r = (4, 3, −1) + (1, 1, 1)t
and
r = (4, −1, 1) + (1, −2, −1)t.
42.
The line that joins (0, 0, 0) to (1, 2, −1), and the line that joins (1, 1, 1) to (2, 3, 4).
43.
x −1
2
= y + 2
3
= 2z −1
4
and
x + 2
−1
= 2 −y
2
,
z = 1
2.
44.
The x axis and r = j −k + (2i −3j + k)t.
45.
A particle is traveling along the line (x −3)/2 = (y + 1)/(−2) = z −1. Write the
equation of its path in the form r = r0 + At. Find the distance of closest approach
of the particle to the origin (that is, the distance from the origin to the line). If
t represents time, show that the time of closest approach is t = −(r0 · A)/|A|2.
Use this value to check your answer for the distance of closest approach. Hint: See
Figure 5.3. If P is the point of closest approach, what is A · r?

114
Linear Algebra
Chapter 3
6. MATRIX OPERATIONS
In Section 2 we used matrices simply as arrays of numbers. Now we want to go
farther into the subject and discuss the meaning and use of multiplying a matrix
by a number and of combining matrices by addition, subtraction, multiplication,
and even (in a sense) division. We will see that we may be able to ﬁnd functions of
matrices such as eM. These are, of course, all questions of deﬁnition, but we shall
show some applications which might suggest reasonable deﬁnitions; or alternatively,
given the deﬁnitions, we shall see what applications we can make of the matrix
operations.
Matrix Equations
Let us ﬁrst emphasize again that two matrices are equal only
if they are identical. Thus the matrix equation
x
r
u
y
s
v

=
2
1
−5
3
−7i
1 −i

is really the set of six equations
x = 2,
y = 3,
r = 1,
s = −7i,
u = −5,
v = 1 −i.
(Recall similar situations we have met before: The equation z = x + iy = 2 −3i
is equivalent to the two real equations x = 2, y = −3; a vector equation in three
dimensions is equivalent to three component equations.) In complicated problems
involving many numbers or variables, it is often possible to save a great deal of writ-
ing by using a single matrix equation to replace a whole set of ordinary equations.
Any time it is possible to so abbreviate the writing of a mathematical equation (like
using a single letter for a complicated parenthesis) it not only saves time but often
enables us to think more clearly.
Multiplication of a Matrix by a Number
A convenient way to display the
components of the vector A = 2i + 3j is to write them as elements of a matrix,
either
A =

2
3

called a column matrix or column vector,
or
AT =

2
3

called a row matrix or row vector.
The row matrix AT is the transpose of the column matrix A. Observe the notation
we are using here: We will often use the same letter for a vector and its column
matrix, but we will usually write the letter representing the matrix as A (roman,
not boldface), the vector as boldface A, and the length of the vector as italic A.
Now suppose we want a vector of twice the length of A and in the same direction;
we would write this as 2A = 4i + 6j.
Then we would like to write its matrix
representation as
2A = 2
2
3

=
4
6

,
2AT = 2(2
3) = (4
6).
This is, in fact, exactly how a matrix is multiplied by a number: every element of
the matrix is multiplied by the number. Thus
k
a
c
e
b
d
f

=
ka
kc
ke
kb
kd
kf


Section 6
Matrix Operations
115
and
 −1
2
3
4
−1
−5
8

= −1
8
 4
−6
8
5

.
Note carefully a diﬀerence between determinants and matrices: multiplying a
matrix by a number k means multiplying every element by k, but multiplying just
one row of a determinant by k multiplies the determinant by k. Thus det(kA) =
k2 det A for a 2 by 2 matrix, det(kA) = k3 det A for a 3 by 3 matrix, and so on.
Addition of Matrices
When we add vectors algebraically, we add them by com-
ponents. Matrices are added in the same way, by adding corresponding elements.
For example,
1
3
−2
4
7
1

+
2
−1
4
3
−7
−2

=
1 + 2
3 −1
−2 + 4
4 + 3
7 −7
1 −2

(6.1)
=

3
2
2
7
0
−1

.
Note that if we add A + A we would get 2A in accord with our deﬁnition of twice
a matrix above. Suppose we have
A =

1
3
−2
4
7
1

and
B =

2
−1
3
5

.
In this case we cannot add A and B; we say that the sum is undeﬁned or meaningless.
In applications, then, matrices are useful in representing things which are added
by components. Suppose, for example, that, in (6.1), the columns represent dis-
placements of three particles. The ﬁrst particle is displaced by i+4j (ﬁrst column of
the ﬁrst matrix) and later by 2i + 3j (ﬁrst column of the second matrix). The total
displacement is then 3i + 7j (ﬁrst column of the sum of the matrices). Similarly the
second and third columns represent displacements of the second and third particles.
Multiplication of Matrices
Let us start by deﬁning the product of two matrices
and then see what use we can make of the process. Here is a simple example to
show what is meant by the product AB = C of two matrices A and B:
(6.2a)
AB =

a
b
c
d
 
e
f
g
h

=

ae + bg
af + bh
ce + dg
cf + dh

= C.
Observe that in the product matrix C, the element in the ﬁrst row and ﬁrst column is
obtained by multiplying each element of the ﬁrst row in A times the corresponding
element in the ﬁrst column of B and adding the results.
This is referred to as
“row times column” multiplication; when we compute ae + bg, we say that we have
“multiplied the ﬁrst row of A times the ﬁrst column of B.”
Next examine the
element af + bh in the ﬁrst row and second column of C; it is the “ﬁrst row of A
times the second column of B.” Similarly, ce+dg in the second row and ﬁrst column
of C is the “second row of A times the ﬁrst column of B,” and cf +dh in the second

116
Linear Algebra
Chapter 3
row and second column of C is the “second row of A times the second column of B.”
Thus all the elements of C may be obtained by using the following simple rule:
(6.2b)
The element in row i and column j of the product matrix AB is
equal to row i of A times column j of B. In index notation
(AB)ij =

k
AikBkj.
Here is another useful way of saying this: Think of the elements in a row (or
a column) of a matrix as the components of a vector.
Then row times column
multiplication for the matrix product AB corresponds to ﬁnding the dot product of
a row vector of A and a column vector of B.
It is not necessary for matrices to be square in order for us to multiply them.
Consider the following example.
Example 1.
Find the product of A and B if
A =
 4
2
−3
1

,
B =
1
5
3
2
7
−4

.
Following the rule we have stated, we get
AB =
 4
2
−3
1
 1
5
3
2
7
−4

=
 4 · 1 + 2 · 2
4 · 5 + 2 · 7
4 · 3 + 2(−4)
−3 · 1 + 1 · 2
−3 · 5 + 1 · 7
−3 · 3 + 1(−4)

=
 8
34
4
−1
−8
−13

.
Notice that the third column in B caused us no diﬃculty in following our rule; we
simply multiplied each row of A times the third column of B to obtain the elements
in the third column of AB. But suppose we tried to ﬁnd the product BA. In B a
row contains 3 elements, while in A a column contains only two; thus we are not
able to apply the “row times column” method. Whenever this happens, we say that
B is not conformable with respect to A, and the product BA is not deﬁned (that is,
it is meaningless and we do not use it).
The product AB (in that order) can be found if and only if the number of elements
in a row of A equals the number of elements in a column of B; the matrices A,
B in that order are then called conformable. (Observe that the number of rows
in A and of columns in B have nothing to do with the question of whether we
can ﬁnd AB or not.)

Section 6
Matrix Operations
117
Example 2.
Find AB and BA, given
A =
 3
−1
−4
2

,
B =
 5
2
−7
3

.
Note that here the matrices are conformable in both orders, so we can ﬁnd both
AB and BA.
AB =
 3
−1
−4
2
  5
2
−7
3

=

3 · 5 −1(−7)
3 · 2 −1 · 3
−4 · 5 + 2(−7)
−4 · 2 + 2 · 3

=

22
3
−34
−2

.
BA =
 5
2
−7
3
  3
−1
−4
2

=

5 · 3 + 2(−4)
5(−1) + 2 · 2
−7 · 3 + 3(−4)
−7(−1) + 3 · 2

=

7
−1
−33
13

.
Observe that AB is not the same as BA. We say that matrix multiplication is
not commutative, or that, in general, matrices do not commute under multiplica-
tion. (Of course, two particular matrices may happen to commute.) We deﬁne the
commutator of the matrices A and B by
(6.3)
[A, B] = AB −BA = commutator of A and B.
(Commutators are of interest in classical and quantum mechanics.) Since matrices
do not in general commute, be careful not to change the order of factors in a product
of matrices unless you know they commute. For example
(A −B)(A + B) = A2 + AB −BA −B2 = A2 −B2 + [A, B].
This is not equal to A2 −B2 when A and B don’t commute. Also see the discussion
just after (6.17). On the other hand, the associative law is valid, that is, A(BC) =
(AB)C, so we can write either as simply ABC. Also the distributive law holds:
A(B + C) = AB + AC and (A + B)C = AC + BC as we have been assuming above.
(See Section 9.)
Zero Matrix
The zero or null matrix means one with all its elements equal to
zero. It is often abbreviated by 0, but we must be careful about this. For example:
(6.4)
If
M =

2
−4
1
−2

,
then
M2 =

0
0
0
0

so we have M2 = 0, but M ̸= 0. Also see Problems 9 and 10.

118
Linear Algebra
Chapter 3
Identity Matrix or Unit Matrix
This is a square matrix with every element
of the main diagonal (upper left to lower right) equal to 1 and all other elements
equal to zero. For example
(6.5)


1
0
0
0
1
0
0
0
1


is a unit or identity matrix of order 3 (that is, three rows and three columns). An
identity or unit matrix is called 1 or I or U or E in various references. You should
satisfy yourself that in multiplication, a unit matrix acts like the number 1, that
is, if A is any matrix and I is the unit matrix conformable with A in the order in
which we multiply, then IA = AI = A (Problem 11).
Operations with Determinants
We do not deﬁne addition for determinants.
However, multiplication is useful; we multiply determinants the same way we mul-
tiply matrices. It can be shown that if A and B are square matrices of the same
order, then
(6.6)
det AB = det BA = (det A) · (det B).
Look at Example 2 above to see that (6.6) is true even when matrices AB and BA
are not equal, that is, when A and B do not commute.
Applications of Matrix Multiplication
We can now write sets of simultaneous
linear equations in a very simple form using matrices. Consider the matrix equation
(6.7)


1
0
−1
−2
3
0
1
−3
2




x
y
z

=


5
1
−10

.
If we multiply the ﬁrst two matrices, we have
(6.8)


x −z
−2x + 3y
x −3y + 2z

=


5
1
−10

.
Now recall that two matrices are equal only if they are identical. Thus (6.8) is the
set of three equations
(6.9)



x
−
z =
5
−2x + 3y
=
1
x −3y + 2z = −10
.
Consequently (6.7) is the matrix form for the set of equations (6.9). In this way we
can write any set of linear equations in matrix form. If we use letters to represent
the matrices in (6.7),
(6.10)
M =


1
0
−1
−2
3
0
1
−3
2

,
r =


x
y
z

,
k =


5
1
−10

,

Section 6
Matrix Operations
119
then we can write (6.7) or (6.9) as
(6.11)
Mr = k.
Or, in index notation, we can write 
j Mijxj = ki. [Review Section 2, equations
(2.3) to (2.6).] Note that (6.11) could represent any number of equations or un-
knowns (say 100 equations in 100 unknowns!). Thus we have a great simpliﬁcation
in notation which may help us to think more clearly about a problem. For example,
if (6.11) were an ordinary algebraic equation, we would solve it for r to get
(6.12)
r = M−1k.
Since M is a matrix, (6.12) only makes sense if we can give a meaning to M−1 such
that (6.12) gives the solution of (6.7) or (6.9). Let’s try to do this.
Inverse of a Matrix
The reciprocal or inverse of a number x is x−1 such that
the product xx−1 = 1. We deﬁne the inverse of a matrix M (if it has one) as the
matrix M−1 such that MM−1 and M−1M are both equal to a unit matrix I. Note
that only square matrices can have inverses (otherwise we could not multiply both
MM−1 and M−1M). Actually, some square matrices do not have inverses either.
You can see from (6.6) that if M−1M = I, then (det M−1)(det M) = det I = 1. If
two numbers have product = 1, then neither of them is zero; thus det M ̸= 0 is a
requirement for M to have an inverse.
If a matrix has an inverse we say that it is invertible; if it doesn’t have an inverse,
it is called singular. For simple numerical matrices your computer will easily produce
the inverse of an invertible matrix. However, for theoretical purposes, we need a
formula for the inverse; let’s discuss this. The cofactor of an element in a square
matrix M means exactly the same thing as the cofactor of that element in det M
[see (3.3) and (3.4)]. Thus, the cofactor Cij of the element mij in row i and column
j is a number equal to (−1)i+j times the value of the determinant remaining when
we cross oﬀrow i and column j. Then to ﬁnd M−1: Find the cofactors Cij of all
elements, write the matrix C whose elements are Cij, transpose it (interchange rows
and columns), and divide by det M. (See Problem 23.)
(6.13)
M−1 =
1
det MCT
where Cij = cofactor of mij
Although (6.13) is particularly useful in theoretical work, you should practice using
it (as we said for Cramer’s rule) on simple numerical problems in order to learn
what the formula means.

120
Linear Algebra
Chapter 3
Example 3.
For the matrix M of the coeﬃcients in equations (6.7) or (6.9), ﬁnd M−1.
M =


1
0
−1
−2
3
0
1
−3
2

.
We ﬁnd det M = 3. The cofactors of the elements are:
1st row :

3
0
−3
2
 = 6,
−

−2
0
1
2
 = 4,

−2
3
1
−3
 = 3.
2nd row :
−

0
−1
−3
2
 = 3,

1
−1
1
2
 = 3,
−

1
0
1
−3
 = 3.
3rd row :

0
−1
3
0
 = 3,
−

1
−1
−2
0
 = 2,

1
0
−2
3
 = 3.
Then
C =


6
4
3
3
3
3
3
2
3


so
M−1 =
1
det MCT = 1
3


6
3
3
4
3
2
3
3
3

.
Now we can use M−1 to solve equations (6.9). By (6.12), the solution is given by
the column matrix r = M−1k, so we have


x
y
z

= 1
3


6
3
3
4
3
2
3
3
3




5
1
−10

=


1
1
−4

,
or x = 1, y = 1, z = −4. (See Problem 12.)
Rotation Matrices
As another example of matrix multiplication, let’s consider
a case where we know the answer, just to see that our deﬁnition of matrix multi-
plication works the way we want it to. You probably know the rotation equations
[for reference, see the next section, equation (7.12) and Figure 7.4]. Equation (7.12)
gives the matrix which rotates the vector r = ix + jy through angle θ to become
the vector R = iX + jY . Suppose we further rotate R through angle φ to become
R′ = iX′ + jY ′. We could write the matrix equations for the rotations in the form
R = Mr and R′ = M′R where M and M′ are the rotation matrices (7.12) for rotation
through angles θ and φ. Then, solving for R′ in terms of r, we get R′ = M′Mr. We
expect the matrix product M′M to give us the matrix for a rotation through the
angle θ + φ, that is we expect to ﬁnd
(6.14)
cos φ
−sin φ
sin φ
cos φ
 cos θ
−sin θ
sin θ
cos θ

=
cos(θ + φ)
−sin(θ + φ)
sin(θ + φ)
cos(θ + φ)

.
It is straightforward to multiply the two matrices (Problem 25) and verify (by using
trigonometric identities) that (6.14) is correct. Also note that these two rotation
matrices commute (that is, rotation through angle θ and then through angle φ gives
the same result as rotation through φ followed by rotation through θ). This is true
in this problem in two dimensions. As we will see in Section 7, rotation matrices in
three dimensions do not in general commute if the two rotation axes are diﬀerent.
(See Problems 7.30 and 7.31.) But all rotations in the (x, y) plane are rotations
about the z axis and so they commute.

Section 6
Matrix Operations
121
Functions of Matrices
Since we now know how to multiply matrices and how
to add them, we can evaluate any power of a matrix A and so evaluate a polynomial
in A. The constant term c or cA0 in a polynomial is deﬁned to mean c times the
unit matrix I [see (6.16) below].
Example 4.
If
A =

1
√
2
−
√
2
−1

,
then
A2 =

−1
0
0
−1

= −I,
(6.15)
A3 = −A, A4 = I,
and so on.
(Verify these powers and the fact that higher powers simply repeat these four results:
A, −I, −A, I, over and over.) Then we can ﬁnd (Problem 28)
f(A) = 3 −2A2 −A3 −5A4 + A6
(6.16)
= 3I + 2I + A −5I −I = A −I =

0
√
2
−
√
2
−2

.
We can extend this to other functions by expanding a given f(x) in a power series
if all the series we need to use happen to converge. For example, the series for
ez converges for all z, so we can ﬁnd ekA when A is a given matrix and k is any
number, real or complex. Let A be the matrix in (6.15). Then (Problem 28), we
ﬁnd
ekA = 1 + kA + k2A2
2!
+ k3A3
3!
+ k4A4
4!
+ k5A5
5!
+ · · ·
(6.17)
= (1 −k2
2! + k4
4! + · · · )I + (k −k3
3! + k5
5! )A
= (cos k)I + (sin k)A =
cos k + sin k
√
2 sin k
−
√
2 sin k
cos k −sin k

.
A word of warning about functions of two matrices when A and B don’t com-
mute: Familiar formulas may mislead you; see (6.3) and the discussion following it.
Be sure to write (A + B)2 = A2 + AB + BA + B2; don’t write 2AB. Similarly, you
can show that eA+B is not the same as eAeB when A and B don’t commute (see
Problem 29 and Problem 15.34).
PROBLEMS, SECTION 6
In Problems 1 to 3, ﬁnd AB, BA, A + B, A −B, A2, B2, 5A, 3B. Observe that AB ̸= BA.
Show that (A −B)(A + B) ̸= (A + B)(A −B) ̸= A2 −B2. Show that det AB = det BA =
(det A)(det B), but that det(A + B) ̸= det A + det B. Show that det(5A) ̸= 5 det A, and
ﬁnd n so that det(5A) = 5n det A. Find similar results for det(3B). Remember that the
point of doing these simple problems by hand is to learn how to manipulate determinants
and matrices correctly. Check your answers by computer.
1.
A =
„3
1
2
5
«
,
B =
„−2
2
1
4
«
.
2.
A =
„
2
−5
−1
3
«
,
B =
„
−1
4
0
2
«
.

122
Linear Algebra
Chapter 3
3.
A =
0
@
1
0
2
3
−1
0
0
5
1
1
A ,
B =
0
@
1
1
0
0
2
1
3
−1
0
1
A .
4.
Given the matrices
A =
„2
3
1
−4
2
1
0
5
«
,
B =
0
@
2
4
1
−1
3
−1
1
A ,
C =
0
@
2
1
3
4
−1
−2
−1
0
1
1
A ,
compute or mark as meaningless all products of two of these matrices (AB, BA, A2,
etc.); of three of them (ABC, A2C, A3, etc.).
5.
Compute the product of each of the matrices in Problem 4 with its transpose [see
(2.2) or (9.1)] in both orders, that is AAT and ATA, etc.
6.
The Pauli spin matrices in quantum mechanics are
A =
„0
1
1
0
«
,
B =
„0
−i
i
0
«
,
C =
„1
0
0
−1
«
.
(You will probably ﬁnd these called σx, σy, σz in your quantum mechanics texts.)
Show that A2 = B2 = C2 = a unit matrix. Also show that any two of these matrices
anticommute, that is, AB = −BA, etc. Show that the commutator of A and B, that
is, AB −BA, is 2iC, and similarly for other pairs in cyclic order.
7.
Find the matrix product
`
2
3
´ „−1
4
2
−1
« „−1
2
«
.
By evaluating this in two ways, verify the associative law for matrix multiplication,
that is, A(BC) = (AB)C, which justiﬁes our writing just ABC.
8.
Show, by multiplying the matrices, that the following equation represents an ellipse.
`
x
y
´ „5
−7
7
3
« „x
y
«
= 30.
9.
Find AB and BA given
A =
„1
2
3
6
«
,
B =
„ 10
4
−5
−2
«
.
Observe that AB is the null matrix; if we call it 0, then AB = 0, but neither A nor
B is 0. Show that A is singular.
10.
Given
C =
„7
6
2
3
«
,
D =
„−3
2
7
5
«
and A as in Problem 9, show that AC = AD, but C ̸= D and A ̸= 0.
11.
Show that the unit matrix I has the property that we associate with the number 1,
that is, IA = A and AI = A, assuming that the matrices are conformable.
12.
For the matrices in Example 3, verify that MM−1 and M−1M both equal a unit
matrix. Multiply M−1k to verify the solution of equations (6.9).
In Problems 13 to 16, use (6.13) to ﬁnd the inverse of the given matrix.
13.
„
6
9
3
5
«
14.
„
2
1
0
−3
«

Section 6
Matrix Operations
123
15.
0
@
−1
2
3
2
0
−4
−1
−1
1
1
A
16.
0
@
−2
0
1
1
−1
2
3
1
0
1
A
17.
Given the matrices
A =
0
@
1
−1
1
4
0
−1
4
−2
0
1
A ,
B =
0
@
1
0
1
2
1
1
2
1
2
1
A .
(a)
Find A−1, B−1, B−1AB, and B−1A−1B.
(b)
Show that the last two matrices are inverses, that is, that their product is the
unit matrix.
18.
Problem 17(b) is a special case of the general theorem that the inverse of a product
of matrices is the product of the inverses in reverse order. Prove this. Hint: Multiply
ABCD times D−1C−1B−1A−1 to show that you get a unit matrix.
In Problems 19 to 22, solve each set of equations by the method of ﬁnding the inverse of
the coeﬃcient matrix. Hint: See Example 3.
19.
x −2y =
5
3x +
y = 15
20.
2x + 3y = −1
5x + 4y =
8
21.
8
<
:
x
+ 2z =
8
2x −y
= −5
x + y +
z =
4
22.
8
<
:
x −
y +
z =
4
2x +
y −
z = −1
3x + 2y + 2z =
5
23.
Verify formula (6.13).
Hint:
Consider the product of the matrices MCT.
Use
Problem 3.8.
24.
Use the method of solving simultaneous equations by ﬁnding the inverse of the
matrix of coeﬃcients, together with the formula (6.13) for the inverse of a matrix,
to obtain Cramer’s rule.
25.
Verify (6.14) by multiplying the matrices and using trigonometric addition formulas.
26.
In (6.14), let θ = φ = π/2 and verify the result numerically.
27.
Do Problem 26 if θ = π/2, φ = π/4.
28.
Verify the calculations in (6.15), (6.16), and (6.17).
29.
Show that if A and B are matrices which don’t commute, then eA+B ̸= eAeB, but
if they do commute then the relation holds. Hint: Write out several terms of the
inﬁnite series for eA, eB, and eA+B and do the multiplications carefully assuming
that A and B don’t commute. Then see what happens if they do commute.
30.
For the Pauli spin matrix A in Problem 6, ﬁnd the matrices sin kA, cos kA, ekA, and
eikA where i = √−1.
31.
Repeat Problem 30 for the Pauli spin matrix C in Problem 6. Hint: Show that if a
matrix is diagonal, say D =
„
a
0
0
b
«
, then f(D) =
„
f(a)
0
0
f(b)
«
.
32.
For the Pauli spin matrix B in Problem 6, ﬁnd eiθB and show that your result is a
rotation matrix. Repeat the calculation for e−iθB.

124
Linear Algebra
Chapter 3
7. LINEAR COMBINATIONS, LINEAR FUNCTIONS, LINEAR OPERATORS
Given two vectors A and B, the vector 3A −2B is called a “linear combination”
of A and B. In general, a linear combination of A and B means aA + bB where
a and b are scalars. Geometrically, if A and B have the same tail and do not lie
along a line, then they determine a plane. You should satisfy yourself that all linear
combinations of A and B then lie in the plane. It is also true that every vector in
the plane can be written as a linear combination of A and B; we shall consider this
in Section 8. The vector r = ix + jy + kz with tail at the origin (which we used
in writing equations of lines and planes) is a linear combination of the unit basis
vectors i, j, k.
A function of a vector, say f(r), is called linear if
(7.1)
f(r1 + r2) = f(r1) + f(r2),
and
f(ar) = af(r),
where a is a scalar.
For example, if A = 2i + 3j −k is a given vector, then f(r) = A · r = 2x + 3y −z
is a linear function because
f(r1 + r2) = A · (r1 + r2) = A · r1 + A · r2 = f(r1) + f(r2),
and
f(ar) = A · (ar) = aA · r = af(r).
On the other hand, f(r) = |r| is not a linear function, because the length of the
sum of two vectors is not in general the sum of their lengths. That is,
f(r1 + r2) = |r1 + r2| ̸= |r1| + |r2| = f(r1) + f(r2),
as you can see from Figure 7.1. Also note that although we
call y = mx + b a linear equation (it is the equation of a
straight line), the function f(x) = mx+b is not linear (unless
b = 0) because
Figure 7.1
f(x1 + x2) = m(x1 + x2) + b ̸= (mx1 + b) + (mx2 + b) = f(x1) + f(x2).
We can also consider vector functions of a vector r. The magnetic ﬁeld at each
point (x, y, z), that is, at the head of the vector r, is a vector B = iBx +jBy +kBz.
The components Bx, By, Bz may vary from point to pint, that is, they are functions
of (x, y, z) or r. Then
F(r) is a linear vector function if
(7.2)
F(r1 + r2) = F(r1) + F(r2)
and
F(ar) = aF(r),
where a is a scalar.
For example, F(r) = br (where b is a scalar) is a linear vector function of r.

Section 7
Linear Combinations, Linear Functions, Linear Operators
125
You know from calculus that
d
dx[f(x) + g(x)] = d
dxf(x) + d
dxg(x)
and
(7.3)
d
dx[kf(x)] = k d
dxf(x),
where k is a constant. We say that d/dx is a “linear operator” [compare (7.3) with
(7.1) and (7.2)]. An “operator” or “operation” simply means a rule or some kind of
instruction telling us what to do with whatever follows it. In other words, a linear
operator is a linear function. Then
O is a linear operator if
(7.4)
O(A + B) = O(A) + O(B)
and
O(kA) = kO(A),
where k is a number, and A and B are numbers, functions, vectors, and so on.
Many of the errors people make happen because they assume that operators are
linear when they are not (see problems).
Example 1.
Is square root a linear operator? We are asking, is
√
A + B the same as
√
A +
√
B ? The answer is no; taking the square root is not a linear operation.
Example2.
Is taking the complex conjugate a linear operation? We want to know whether
A + B = ¯A + ¯B and kA = k ¯A. The ﬁrst equation is true; the second equation is
true if we restrict k to real numbers.
Matrix Operators, Linear Transformations
Consider the set of equations
(7.5)
 X = ax + by,
Y = cx + dy,
or
X
Y

=
a
b
c
d
 x
y

,
or
R = Mr,
where a, b, c, d, are constants. For every point (x, y), these equations give us a
point (X, Y ). If we think of each point of the (x, y) plane being moved to some
other point (with some points like the origin not being moved), we can call this
process a mapping or transformation of the plane into itself. All the information
about this transformation is contained in the matrix M. We say that this matrix is
an operator which maps the plane into itself. Any matrix can be thought of as an
operator on (conformable) column matrices r. Since
(7.6)
M(r1 + r2) = Mr1 + Mr2
and
M(kr) = k(Mr),
the matrix M is a linear operator.

126
Linear Algebra
Chapter 3
Equations (7.5) can be interpreted geometrically in two ways. In Figure 7.2, we
have one set of coordinate axes and the vector r has been changed to the vector
R by the transformation (7.5). In Figure 7.3, we have two sets of coordinate axes,
Figure 7.2
Figure 7.3
(x, y) and (x′, y′), and one vector r = r′ with coordinates relative to each set of
axes. This time the transformation
(7.7)
 x′ = ax + by,
y′ = cx + dy,
or
x′
y′

=
a
b
c
d
 x
y

,
or
r′ = Mr,
tells us how to get the components of the vector r = r′ relative to axes (x′, y′) when
we know its components relative to axes (x, y).
Orthogonal Transformations
We shall be particularly interested in the special
case of a linear transformation which preserves the length of a vector. We call (7.7)
an orthogonal transformation if
(7.8)
x′2 + y′2 = x2 + y2,
and similarly for (7.5). You can see from the ﬁgures that this requirement says
that the length of a vector is not changed by an orthogonal transformation. In
Figure 7.2, the vector would be rotated (or perhaps reﬂected) with its length held
ﬁxed (that is R = r for an orthogonal transformation). In Figure 7.3, the axes are
rotated (or reﬂected), while the vector stays ﬁxed. The matrix M of an orthogonal
transformation is called an orthogonal matrix. Let’s show that the inverse of an
orthogonal matrix equals its transpose; in symbols
(7.9)
M−1 = MT,
M orthogonal.
From (7.8) and (7.7) we have
x′2 + y′2 = (ax + by)2 + (cx + dy)2
= (a2 + c2)x2 + 2(ab + cd)xy + (b2 + d2)y2 ≡x2 + y2.
Thus we must have a2 + c2 = 1, b2 + d2 = 1, ab + cd = 0. Then
MTM =
a
c
b
d
 a
b
c
d

(7.10)
=

a2 + c2
ab + cd
ab + cd
b2 + d2

≡

1
0
0
1

.

Section 7
Linear Combinations, Linear Functions, Linear Operators
127
Since MTM is the unit matrix, M and MT are inverse matrices as we claimed in
(7.9). We have deﬁned an orthogonal transformation in two dimensions and we have
proved (7.9) for the 2-dimensional case. However, a square matrix of any order is
called orthogonal if it satisﬁes (7.9), and you can easily show that the corresponding
transformation preserves the lengths of vectors (Problem 9.24).
Now if we write (7.9) as MTM = I and use the facts from Section 3 that
det(MTM) = (det MT)(det M) and det MT = det M, we have (det M)2 = det(MTM) =
det I = 1, so
(7.11)
det M = ±1,
M orthogonal.
This is true for M of any order since we have used only the deﬁnition (7.9) of an
orthogonal matrix and some properties of determinants. As we shall see, det M = 1
corresponds geometrically to a rotation, and det M = −1 means that a reﬂection is
involved.
(X, Y)
(x, y)
y
x
R
r

Figure 7.4
(x', y')
(x, y)
y
y'
x
x'
r = r'


Figure 7.5
Rotations in 2 Dimensions
In Figure 7.4, we have sketched the vector r =
(x, y), and the vector R = (X, Y ) which is the vector r rotated by angle θ. We
write in matrix form the equations relating the components of r and R (Problem 19).
(7.12)
X
Y

=
cos θ
−sin θ
sin θ
cos θ
 x
y

,
vector rotated.
In Figure 7.5, we have sketched two sets of axes with the primed axes rotated by
angle θ with respect to the unprimed axes. The vector r = (x, y), and the vector
r′ = (x′, y′) are the same vector, but with components relative to diﬀerent axes.
These components are related by the equations (Problem 20).
(7.13)

x′
y′

=

cos θ
sin θ
−sin θ
cos θ
 
x
y

,
axes rotated.
Both equations (7.12) and equations (7.13) are referred to as “rotation equations”
and the θ matrices are called “rotation matrices”. To distinguish them, we refer to
the rotation (7.12) as an “active” transformation (vectors rotated), and to (7.13)
as a “passive” transformation (vectors not moved but their components changed
because the axes are rotated). Equations (7.7) or (7.13) are also referred to as a
“change of basis”. (Remember that we called i, j, k unit basis vectors; here we
have changed from the i, j , k basis to the i′, j′, k′ basis. Also see Section 10.)
Observe that the matrices in (7.12) and (7.13) are inverses of each other. You can
see from the ﬁgures why this must be so. The rotation of a vector in, say, the
counterclockwise direction produces the same result as the rotation of the axes in
the opposite (clockwise) direction.

128
Linear Algebra
Chapter 3
We note that det M = cos2 θ + sin2 θ = 1 for a rotation matrix. Any 2 by 2
orthogonal matrix with determinant 1 corresponds to a rotation, and any 2 by 2
orthogonal matrix with determinant = −1 corresponds to a reﬂection through a
line.
Example 3.
Find what transformation corresponds to each of the following matrices.
(7.14)
A = 1
2
 −1
√
3
−
√
3
−1

,
B =
1
0
0
−1

,
C = AB,
D = BA.
First we can show that all these matrices are orthogonal, and that det A = 1, but
the determinants of the other three are −1 (Problem 21). Thus A is a rotation
and B, C and D are reﬂections. Let’s view these as active transformations (ﬁxed
axes, vectors rotated or reﬂected).
Then by comparing A with (7.12), we have
cos θ = −1/2, sin θ = −1
2
√
3, so this is a rotation of 240◦(or −120◦). Alternatively,
we could ask what happens to the vector i. We multiply matrix A times the column
matrix ( 1
0 ) and get
1
2
 −1
√
3
−
√
3
−1
 1
0

= 1
2
 −1
−
√
3

or
−1
2(i + j
√
3),
which is i rotated by 240◦as we had before.
Now B operating on ( x
y ) leaves x ﬁxed and changes the sign of y (check this);
that is, B corresponds to a reﬂection through the x axis.
We ﬁnd C = AB and D = BA by multiplying the matrices (Problem 21).
(7.15)
C = AB = 1
2

−1
−
√
3
−
√
3
1

,
D = BA = 1
2

−1
√
3
√
3
1

.
We know that these are reﬂections since they have determinant = −1. To ﬁnd the
line through which the plane is reﬂected, we realize that the vectors along that line
are unchanged by the reﬂection, so we want to ﬁnd x and y, that is vector r, which
is mapped to itself by the transformation. For matrix C we write Cr = r.
(7.16)
1
2

−1
−
√
3
−
√
3
1
 
x
y

=

x
y

.
You can verify (Problem 21) that the two equations in (7.16) are really the same
equation, namely y = −x
√
3. Vectors along this line, say i −j
√
3, are not changed
by the reﬂection [see (7.17)] so this is the reﬂection line. As further veriﬁcation we
can show [see (7.17)] that a vector perpendicular to this line, say i
√
3+j, is changed
into its negative, that is, it is reﬂected through the line.
1
2

−1
−
√
3
−
√
3
1
 
1
−
√
3

=

1
−
√
3

,
1
2
 −1
−
√
3
−
√
3
1
 √
3
1

=

−
√
3
−1

.
(7.17)
Comment: The solution of the equation Cr = r is an example of an eigenvalue,
eigenvector problem. We shall discuss such problems in detail in Section 11.
We can analyze the transformation D in the same way we did C to ﬁnd (Prob-
lem 21) that the reﬂection line is y = x
√
3. Note that matrices A and B do not
commute and the transformations C and D are diﬀerent.

Section 7
Linear Combinations, Linear Functions, Linear Operators
129
Rotations and Reﬂections in 3 Dimensions
Let’s consider 3 by 3 orthogonal
matrices as active transformations rotating or reﬂecting vectors r = (x, y, z). A
simple form for a rotation matrix is
(7.18)
A =


cos θ
−sin θ
0
sin θ
cos θ
0
0
0
1

.
You should satisfy yourself that this transformation produces a rotation of vectors
about the z axis through angle θ. We can then ﬁnd the rotation angle from (7.12)
as we did in 2 dimensions. Similarly the matrix
(7.19)
B =


cos θ
−sin θ
0
sin θ
cos θ
0
0
0
−1


produces a rotation about the z axis of angle θ together with a reﬂection through
the (x, y) plane, and again we can ﬁnd the rotation angle as in 2 dimensions.
We will show in Section 11 that any 3 by 3 orthogonal matrix with determinant
= 1 can be written in the form (7.18) by choosing the z axis as the rotation axis, and
any 3 by 3 orthogonal matrix with determinant = −1 can be written in the form
(7.19). For now, let’s look at a few simple problems we can do just by considering
how the matrix maps certain vectors.
Example 4.
The matrix for a rotation about the y axis is
(7.20)
F =


cos θ
0
sin θ
0
1
0
−sin θ
0
cos θ

.
You should satisfy yourself that the entry −sin θ is in the right place for an active
transformation. Let θ = 90◦; then the matrix F in (7.20) maps the vector i = (1, 0, 0)
to the vector −k = (0, 0, −1); this is correct for a 90◦rotation around the y axis.
Check that (0, 0, 1) is mapped to (1, 0, 0).
Example 5.
Find the mappings produced by the matrices
(7.21)
G =


0
0
1
0
−1
0
1
0
0

,
K =


0
0
1
−1
0
0
0
−1
0

.
First we ﬁnd that the determinants are 1 so these are rotations.
For G, either
by inspection or by solving Gr = r as in (7.16), we ﬁnd that the vector (1, 0, 1)
is unchanged and so i + k is the rotation axis.
Now G2 is the identity matrix
(corresponding to a 360◦rotation); thus the rotation angle for G is 180◦.
Similarly for K, we ﬁnd that the vector (1, −1, 1) is unchanged by the transfor-
mation so i −j + k is the rotation axis. Now verify that K maps i to −j, and −j
to k, and k to i (or, alternatively that K3 is the identity matrix) so the rotation
angle for K3 is ±360◦. From the geometry we see that the rotation i →−j →k →i
is a rotation of −120◦about i −j + k. (Also see Section 11.)

130
Linear Algebra
Chapter 3
Example 6.
Find the mapping produced by the matrix
L =


0
−1
0
−1
0
0
0
0
1

.
Since det L = −1, this is a reﬂection through some plane. The vector perpendicular
to the reﬂection plane is reversed by the reﬂection, so we ask for a vector satisfying
Lr = −r. Either by solving these equations or by inspection we ﬁnd r = (1, 1, 0) =
i + j. The reﬂecting plane is the plane through the origin perpendicular to this
vector, that is, the plane x + y = 0 (see Section 5).
PROBLEMS, SECTION 7
Are the following linear functions? Prove your conclusions by showing that f(r) satisﬁes
both of the equations (7.1) or that it does not satisfy at least one of them.
1.
f(r) = A · r + 3, where A is a given vector.
2.
f(r) = A · (r −kz).
3.
r · r.
Are the following linear vector functions? Prove your conclusions using (7.2).
4.
F(r) = r −ix = jy + kz.
5.
F(r) = A × r, where A is a given vector.
6.
F(r) = r + A, where A is a given vector.
Are the following operators linear?
7.
Deﬁnite integral with respect to x from 0 to 1; the objects being operated on are
functions of x.
8.
Find the logarithm; operate on positive real numbers.
9.
Find the square; operate on numbers or on functions.
10.
Find the reciprocal; operate on numbers or on functions.
11.
Find the absolute value; operate on complex numbers.
12.
Let D stand for d
dx, D2 for d2
dx2 , D3 = d3
dx3 , and so on. Are D, D2, D3 linear?
Operate on functions of x which can be diﬀerentiated as many times as needed.
13.
(a)
As in Problem 12, is D2 + 2D + 1 linear?
(b)
Is x2D2 −2xD + 7 a linear operator?
14.
Find the maximum; operate on functions of x.
15.
Find the transpose; operate on matrices.
16.
Find the inverse; operate on square matrices.
17.
Find the determinant; operate on square matrices.

Section 7
Linear Combinations, Linear Functions, Linear Operators
131
18.
With the cross product of two vectors deﬁned by (4.14), show that ﬁnding the cross
product is a linear operation, that is, show that (4.18) is valid. Warning hint: Don’t
try to prove it by writing out components: Writing, for example, iAx×(jBy+kBz) =
iAx × jBy + iAx × kBz would be assuming what you’re trying to prove. Further
hints: First show that (4.18) is valid if B and C are both perpendicular to A by
sketching (in the plane perpendicular to A) the vectors B, C, B + C, and their
vector products with A. Then do the general case by ﬁrst showing that A × B and
A × B⊥(where B⊥is the vector component of B perpendicular to A) have the
same magnitude and the same direction.
19.
If we multiply a complex number z = reiφ by eiθ, we get eiθz = rei(φ+θ), that is,
a complex number with the same r but with its angle increased by θ. We can say
that the vector r from the origin to the point z = x + iy has been rotated by angle θ
as in Figure 7.4 to become the vector R from the origin to the point Z = X + iY .
Then we can write X + iY = eiθz = eiθ(x + iy). Take real and imaginary parts of
this equation to obtain equations (7.12).
20.
Verify equations (7.13) using Figure 7.5. Hints: Write r′ = r as i′x′ + j′y′ = ix + jy
and take the dot product of this equation with i′ and with j′ to get x′ and y′.
Evaluate the dot products of the unit vectors in terms of θ using Figure 7.5. For
example, i′ · j is the cosine of the angle between the x′ axis and the y axis.
21.
Do the details of Example 3 as follows:
(a)
Verify that the four matrices in (7.14) are all orthogonal and verify the stated
values of their determinants.
(b)
Verify the products C = AB and D = BA in (7.15).
(c)
Solve (7.16) to ﬁnd the reﬂection line.
(d)
Analyze the transformation D as we did C.
Let each of the following matrices represent an active transformation of vectors in the
(x, y) plane (axes ﬁxed, vectors rotated or reﬂected). As in Example 3, show that each
matrix is orthogonal, ﬁnd its determinant, and ﬁnd the rotation angle, or ﬁnd the line of
reﬂection.
22.
1
√
2
„
1
1
−1
1
«
23.
1
2
„−
√
3
1
−1
−
√
3
«
24.
„ 0
−1
−1
0
«
25.
1
3
„ −1
2
√
2
2
√
2
1
«
26.
1
5
„
3
4
4
−3
«
27.
1
√
2
„
−1
−1
1
−1
«
28.
Write the matrices which produce a rotation θ about the x axis, or that rotation
combined with a reﬂection through the (y, z) plane. [Compare (7.18) and (7.19) for
rotation about the z axis.]
29.
Construct the matrix corresponding to a rotation of 90◦about the y axis together
with a reﬂection through the (x, z) plane.
30.
For the matrices G and K in (7.21), ﬁnd the matrices R = GK and S = KG. Note
that R ̸= S. (In 3 dimensions, rotations about two diﬀerent axes do not in general
commute.) Find what geometric transformations are produced by R and S.

132
Linear Algebra
Chapter 3
31.
To see a physical example of non-commuting rotations, do the following experiment.
Put a book on your desk and imagine a set of rectangular axes with the x and y
axes in the plane of the desk with the z axis vertical. Place the book in the ﬁrst
quadrant with the x and y axes along the edges of the book. Rotate the book 90◦
about the x axis and then 90◦about the z axis; note its position. Now repeat the
experiment, this time rotating 90◦about the z axis ﬁrst, and then 90◦about the
x axis; note the diﬀerent result. Write the matrices representing the 90◦rotations
and multiply them in both orders. In each case, ﬁnd the axis and angle of rotation.
For each of the following matrices, ﬁnd its determinant to see whether it produces a
rotation or a reﬂection. If a rotation, ﬁnd the axis and angle of rotation. If a reﬂection,
ﬁnd the reﬂecting plane and the rotation (if any) about the normal to this plane.
32.
0
@
0
0
−1
0
−1
0
−1
0
0
1
A
33.
0
@
0
0
−1
−1
0
0
0
1
0
1
A
34.
0
@
1
0
0
0
0
−1
0
−1
0
1
A
35.
0
@
0
−1
0
1
0
0
0
0
−1
1
A
8. LINEAR DEPENDENCE AND INDEPENDENCE
We say that the three vectors A = i + j, B = i + k, and C = 2i + j + k are
linearly dependent because A + B −C = 0. The two vectors i and j are linearly
independent because there are no numbers a and b (not both zero) such that the
linear combination ai+bj is zero. In general, a set of vectors is linearly dependent if
some linear combination of them is zero (with not all the coeﬃcients equal to zero).
In the simple examples above, it was easy to see by inspection whether the vectors
were linearly independent or not. In more complicated cases, we need a method of
determining linear dependence. Consider the set of vectors
(8.1)
(1, 4, −5), (5, 2, 1), (2, −1, 3), and (3, −6, 11);
We want to know whether they are linearly dependent, and if so, we want to ﬁnd a
smaller linearly independent set. Let us row reduce the matrix whose rows are the
given vectors (see Section 2):
(8.2)




1
4
−5
5
2
1
2
−1
3
3
−6
11



→




9
0
7
0
−9
13
0
0
0
0
0
0



.
In row reduction, we are forming linear combinations of the rows by elementary
row operations [see (2.8)]. All these operations are reversible, so we could, if we
liked, reverse our calculations and combine the two vectors (9, 0, 7) and (0, −9, 13)
to obtain each of the four original vectors (Problem 1). Thus there are only two
independent vectors in (8.1); we refer to these independent vectors as basis vectors
since all the original vectors can be written in terms of them (see Section 10).
Note that the rank (see Section 2) of the matrix in (8.2) is equal to the number of
independent or basis vectors.

Section 8
Linear Dependence and Independence
133
Linear Independence of Functions
By a deﬁnition similar to that for vectors,
we say that the functions f1(x), f2(x), · · · , fn(x) are linearly dependent if some
linear combination of them is identically zero, that is, if there are constants k1, k2,
· · · , kn, not all zero, such that
(8.3)
k1f1(x) + k2f2(x) + · · · + knfn(x) ≡0.
For example, sin2 x and (1 −cos2 x) are linearly dependent since
sin2 x −(1 −cos2 x) ≡0.
But sin x and cos x are linearly independent since there are no numbers k1 and k2,
not both zero, such that
(8.4)
k1 sin x + k2 cos x
is zero for all x (Problem 8).
We shall be particularly interested in knowing that a given set of functions is
linearly independent. For this purpose the following theorem is useful (Problems 8
to 16, and Chapter 8, Section 5).
If f1(x), f2(x), · · · , fn(x) have derivatives of order n −1, and if the determinant
(8.5)
W =

f1(x)
f2(x)
· · ·
fn(x)
f ′
1(x)
f ′
2(x)
· · ·
f ′
n(x)
f ′′
1 (x)
f ′′
2 (x)
· · ·
f ′′
n(x)
...
...
...
...
f (n−1)
1
(x)
f (n−1)
2
(x)
· · ·
f (n−1)
n
(x)

̸≡0,
then the functions are linearly independent. (See Problem 16.) The determi-
nant W is called the Wronskian of the functions.
Example 1.
Using (8.5), show that the functions 1, x, sin x are linearly independent.
We write and evaluate the Wronskian,
W =

1
x
sin x
0
1
cos x
0
0
−sin x

= −sin x.
Since −sin x is not identically equal to zero, the functions are linearly independent.
Example 2.
Now let’s compute the Wronskian for a case when the functions are linearly
dependent.
W =

x
sin x
2x −3 sin x
1
cos x
2 −3 cos x
0
−sin x
3 sin x

=

x
sin x
2x
1
cos x
2
0
−sin x
0

= (sin x)(2x −2x) ≡0,
as we expected. However, note that “functions dependent” implies W ≡0, but
W ≡0 does not necessarily imply “functions dependent”. (See Problem 16.)

134
Linear Algebra
Chapter 3
Homogeneous Equations
In Section 2 we considered sets of linear equations.
Here we want to consider the special case of such equations when the constants on
the right hand sides are all zero; these are called homogeneous equations. We write
the homogeneous equations corresponding to (2.12) and (2.13) together with the
row reduced matrices:

x + y = 0
x −y = 0

1
0
0
0
1
0

(8.6)
 x +
y = 0
2x + 2y = 0
1
1
0
0
0
0

.
(8.7)
We can draw several conclusions from these examples. Note that in (8.6) the only
solution is x = y = 0; the rank of the matrix is 2, the same as the number of
unknowns. In (8.7), the rank of the matrix is 1; this is less than the number of
unknowns. This reﬂects what we could see in (8.7), that we really have just one
equation in two unknowns; all the points on a line satisfy x + y = 0. In (8.8) we
summarize the facts for homogeneous equations:
(8.8)
Homogeneous equations are never inconsistent; they always have
the solution “all unknowns = 0” (often called the “trivial solu-
tion”). If the number of independent equations (that is, the rank
of the matrix) is the same as the number of unknowns, this is the
only solution. If the rank of the matrix is less than the number of
unknowns, there are inﬁnitely many solutions.
A very important special case is a set of n homogeneous equations in n unknowns.
By (8.8), these equations have only the trivial solution unless the rank of the matrix
is less than n. This means that at least one row of the row reduced n by n matrix of
the coeﬃcients is a zero row. But then the determinant D of the coeﬃcients is zero.
Thus we have an important result (see Problems 21 to 25; also see Section 11):
(8.9)
A system of n homogeneous equations in n unknowns has solutions
other than the trivial solution if and only if the determinant of the
coeﬃcients is zero.
Solutions in Vector Form
Geometrically, solutions of sets of linear equations
may be points or lines or planes.
Example 3.
In Section 2, Example 4, we solved equations (2.15):
(8.10)
x = 3 + 2z,
y = 4 −z.
This solution set consists of all points on the line which is the intersection of these
two planes. An interesting way to write the solution is the vector form
(8.11)
r = (x, y, z) = (3 + 2z, 4 −z, z) = (3, 4, 0) + (2, −1, 1)z.

Section 8
Linear Dependence and Independence
135
If we put z = t, this is the parametric form of the equations of a straight line,
r = r0 + At [see (5.8)].
Now let’s consider the homogeneous equations (zero right hand sides) corre-
sponding to equations (2.15). The equations and the row reduced matrix are:
(8.12)




1
1
−1
2
−1
−5
−5
4
14
3
−1
−7






x
y
z

=




0
0
0
0



,




1
0
−2
0
0
1
1
0
0
0
0
0
0
0
0
0



,
so the solutions are
(8.13)
x = 2z,
y = −z,
or
r = (2, −1, 1)z.
Comparing (8.11) and (8.13), we see that the solution of the homogeneous equations
Mr = 0 is a straight line through the origin; the solution of the equations Mr = k
is a parallel straight line through the point (3, 4, 0). We could say that the solution
of Mr = k is the solution of the corresponding homogeneous equations plus the
particular solution r = (3, 4, 0).
Here is an example of an important use of (8.9).
Example 4.
For what values of λ does the following set of equations have nontrivial
solutions for x and y? For each value of λ ﬁnd the corresponding relation between x
and y. This is an example of an eigenvalue problem; we shall discuss such problems
in detail in Sections 11 and 12. The values of λ are called eigenvalues and the
corresponding vectors (x, y) are called eigenvectors.
(8.14)
 (1 −λ)x + 2y = 0,
2x + (4 −λ)y = 0.
By (8.9), we set the determinant M of the coeﬃcients equal to zero. Then we solve
for λ, and for each value of λ we solve for x and y.

1 −λ
2
2
4 −λ
 = λ2 −5λ + 4 −4 = λ(λ −5) = 0,
λ = 0, 5.
For λ = 0, we ﬁnd x + 2y = 0. For λ = 5, we ﬁnd 2x −y = 0. In vector notation
the eigenvectors are: For λ = 0, r = (2, −1)s, and for λ = 5, r = (1, 2)t, where s
and t are parameters in these vector equations of straight lines through the origin.
PROBLEMS, SECTION 8
1.
Write each of the vectors (8.1) as a linear combination of the vectors (9, 0, 7) and
(0, −9, 13).
Hint:
To get the right x component in (1, 4, −5), you have to use
(1/9)(9, 0, 7). How do you get the right y component? Is the z component now
correct?
In Problems 2 to 4, ﬁnd out whether the given vectors are dependent or independent; if
they are dependent, ﬁnd a linearly independent subset. Write each of the given vectors as
a linear combination of the independent vectors.
2.
(1, −2, 3), (1, 1, 1), (−2, 1, −4), (3, 0, 5)

136
Linear Algebra
Chapter 3
3.
(0, 1, 1), (−1, 5, 3), (1, 0, 2), (2, −15, 1)
4.
(3, 5, −1), (1, 4, 2), (−1, 0, 5), (6, 14, 5)
5.
Show that any vector V in a plane can be written as a linear combination of two
non-parallel vectors A and B in the plane; that is, ﬁnd a and b so that V = aA+bB.
Hint: Find the cross products A × V and B × V; what are A × A and B × B?
Take components perpendicular to the plane to show that
a = (B × V) · n
(B × A) · n
where n is normal to the plane, and a similar formula for b.
6.
Use Problem 5 to write V = 3i + 5j as a linear combination of A = 2i + j and
B = 3i −2j. Show that the formulas in Problem 5, written as a quotient of 2 by 2
determinants, are just the Cramer’s rule solution of simultaneous equations for a
and b.
7.
As in Problem 6, write V = 4i −5j in terms of the basis vectors i −4j and 5i + 2j.
In Problems 8 to 15, use (8.5) to show that the given functions are linearly independent.
8.
sin x, cos x
9.
eix, sin x
10.
x, ex, xex
11.
sin x, cos x, x sin x, x cos x
12.
1, x2, x4, x6
13.
sin x, sin 2x
14.
eix, e−ix
15.
ex, eix, cosh x
16.
(a)
Prove that if the Wronskian (8.5) is not identically zero, then the functions f1,
f2, . . . , fn are linearly independent. Note that this is equivalent to proving
that if the functions are linearly dependent, then W is identically zero. Hints:
Suppose (8.3) were true; you want to ﬁnd the k’s. Diﬀerentiate (8.3) repeatedly
until you have a set of n equations for the n unknown k’s. Then use (8.9).
(b)
In part (a) you proved that if W ̸≡0, then the functions are linearly inde-
pendent.
You might think that if W ≡0, the functions would be linearly
dependent. This is not necessarily true; if W ≡0, the functions might be
either dependent or independent. For example, consider the functions x3 and
|x3| on the interval (−1, 1).
Show that W ≡0, but the functions are not
linearly dependent on (−1, 1). (Sketch them.) On the other hand, they are
linearly dependent (in fact identical) on (0, 1).
In Problems 17 to 20, solve the sets of homogeneous equations by row reducing the matrix.
17.
8
<
:
x −2y + 3z = 0
x + 4y −6z = 0
2x + 2y −3z = 0
18.
8
<
:
2x
+ 3z = 0
4x + 2y + 5z = 0
x −
y + 2z = 0
19.
8
>
>
<
>
>
:
3x +
y + 3z + 6w = 0
4x −7y −3z + 5w = 0
x + 3y + 4z −3w = 0
3x
+ 2z + 7w = 0
20.
8
>
>
<
>
>
:
2x −3y + 5z = 0
x + 2y −
z = 0
x −5y + 6z = 0
4x +
y + 3z = 0
21.
Find a condition for four points in space to lie in a plane. Your answer should be
in the form a determinant which must be equal to zero. Hint: The equation of a
plane is of the form ax + by + cz = d, where a, b, c, d are constants. The four points
(x1, y1, z1), (x2, y2, z2), etc., are all to satisfy this equation. When can you ﬁnd a,
b, c, d not all zero?

Section 9
Special Matrices and Formulas
137
22.
Find a condition for three lines in a plane to intersect in one point.
Hint: See
Problem 21. Write the equation of a line as ax + by = c. Assume that no two of the
lines are parallel.
Using (8.9), ﬁnd the values of λ such that the following equations have nontrivial solutions,
and for each λ, solve the equations. (See Example 4.)
23.
(
(4 −λ)x −2y = 0
−2x + (7 −λ)y = 0
24.
(
(6 −λ)x + 3y = 0
3x −(2 + λ)y = 0
25.
8
>
<
>
:
−(1 + λ)x + y + 3z = 0,
x + (2 −λ)y = 0,
3x + (2 −λ)z = 0.
For each of the following, write the solution in vector form [see (8.11) and (8.13)].
26.
8
>
>
<
>
>
:
2x −3y + 5z =
3
x + 2y −
z =
5
x −5y + 6z = −2
4x +
y + 3z = 13
27.
8
<
:
x −
y + 2z = 3
−2x + 2y −
z = 0
4x −4y + 5z = 6
28.
8
<
:
2x +
y −5z = 7
x −2y
= 1
3x −5y −
z = 4
9. SPECIAL MATRICES AND FORMULAS
In this section we want to discuss various terms used in work with matrices, and
prove some important formulas. First we list for reference needed deﬁnitions and
facts about matrices.
There are several special matrices which are related to a given matrix A. We
outline in (9.1) what these matrices are called, what notations are used for them,
and how we get them from A.
(9.1)
Name of Matrix
Notations for it
How to get it from A
Transpose of A, or
A transpose
AT or A or A′ or At
Interchange rows and
columns in A.
Complex conjugate
of A
¯A or A∗
Take the complex
conjugate of each
element.
Transpose conjugate,
Hermitian conjugate,
adjoint (Problem 9),
Hermitian adjoint.
A† (A dagger)
Take the complex
conjugate of each
element and transpose.
Inverse of A
A−1
See Formula (6.13).
There is another set of names for special types of matrices. In (9.2), we list
these and their deﬁnitions for reference.

138
Linear Algebra
Chapter 3
(9.2)
A matrix is called
if it satisﬁes the condition(s)
real
A = ¯A
symmetric
A = AT, A real
(matrix = its transpose)
skew-symmetric or
antisymmetric
A = −AT, A real
orthogonal
A−1 = AT, A real
(inverse = transpose)
pure imaginary
A = −¯A
Hermitian
A = A†
(matrix = its transpose
conjugate)
anti-Hermitian
A = −A†
unitary
A−1 = A†
(inverse = transpose
conjugate)
normal
AA† = A†A
(A and A† commute)
Now let’s consider some examples and proofs using these terms.
Index Notation
We are going to need index notation in some of our work below,
so for reference we restate the rule in (6.2b) for matrix multiplication.
(9.3)
(AB)ij =

k
AikBkj.
Study carefully the index notation for “row times column” multiplication. To ﬁnd
the element in row i and column j of the product matrix AB, we multiply row i
of A times column j of B. Note that the k’s (the sum is over k) are next to each
other in (9.3). If we should happen to have 
k BkjAik, we should rewrite it as

k AikBkj (with the k’s next to each other) to recognize it as an element of the
matrix AB (not BA). We will see an example of this in (9.10) below.
Kronecker δ
The Kronecker δ is deﬁned by
(9.4)
δij =

1,
if i = j,
0,
if i ̸= j.
For example, δ11 = 1, δ12 = 0, δ22 = 1, δ31 = 0, and so on. In this notation a unit
matrix is one whose elements are δij and we can write
(9.5)
I = (δij).

Section 9
Special Matrices and Formulas
139
(Also see Chapter 10, Section 5.)
The Kronecker δ notation is useful for other
purposes. For example, since (for positive integers m and n)
(9.6a)
 π
−π
cos nx cos mx dx =

π,
if m = n,
0,
if m ̸= n,
we can write
(9.6b)
 π
−π
cos nx cos mx dx = π · δnm.
This is the same as (9.6a) because δnm = 0 if m ̸= n, and δnm = 1 if m = n.
Using the Kronecker δ, we can give a formal proof that for any matrix M and a
conformable unit matrix I, the product of I and M is just M. Using index notation
and equations (9.3) and (9.4), we have
(9.7)
(IM)ij =

k
δikMkj = Mij
or
IM = M
since δik = 0 unless k = i.
More Useful Theorems
Let’s use index notation to prove the associative law
for matrix multiplication, that is
(9.8)
A(BC) = (AB)C = ABC.
First we write (BC)kj = 
l BklClj. Then we have
[A(BC)]ij =

k
Aik(BC)kj =

k
Aik

l
BklClj
(9.9)
=

k

l
AikBklClj = (ABC)ij
which is the index notation for A(BC) = ABC as in (9.8). We can prove (AB)C =
ABC in a similar way (Problem 1).
In formulas we may want the transpose of the product of two matrices. First
note that AT
ik = Aki [see (2.1) or (9.1)]. Then
(AB)T
ik = (AB)ki =

j
AkjBji =

j
AT
jkBT
ij
=

j
BT
ijAT
jk = (BTAT)ik,
or,
(AB)T = BTAT.
(9.10)
The theorem applies to a product of any number of matrices (see Problem 8b). For
example
(9.11)
(ABCD)T = DTCTBTAT.
The transpose of a product of matrices is equal to the product of the transposes
in reverse order.

140
Linear Algebra
Chapter 3
A similar theorem is true for the inverse of a product (see Section 6, Problem 18).
(9.12)
(ABCD)−1 = D−1C−1B−1A−1.
The inverse of a product of matrices is equal to the product of the inverses in
reverse order.
Trace of a Matrix
The trace (or spur) or a square matrix A (written Tr A) is
the sum of the elements on the main diagonal. Thus the trace of a unit n by n
matrix is n, and the trace of the matrix M in (6.10) is 6. It is a theorem that the
trace of a product of matrices is not changed by permuting them in cyclic order.
For example
(9.13)
Tr(ABC) = Tr(BCA) = Tr(CAB).
We can prove this as follows:
Tr(ABC) =

i
(ABC)ii =

i

j

k
AijBjkCki
=

i

j

k
BjkCkiAij = Tr(BCA)
=

i

j

k
CkiAijBjk = Tr(CAB).
Warning: Tr(ABC) is not equal to Tr(ACB) in general.
Theorem:
If H is a Hermitian matrix, then U = eiH is a unitary matrix. (This
is an important relation in quantum mechanics.) By (9.2) we need to prove that
U† = U−1 if H† = H. First, eiHe−iH = eiH−iH since H commutes with itself—see
Problem 6.29. But this is e0 which is the unit matrix [see Section 6] so U−1 = e−iH.
To ﬁnd U† = (eiH)†, we expand U = eiH in a power series to get U = 
k(iH)k/k!
and then take the transpose conjugate. To do this we just need to realize that the
transpose of a sum of matrices is the sum of the transposes, and that the transpose
of a power of a matrix, say (Mn)T is equal to (MT)n (Problem 9.21). Also recall
from Chapter 2 that you ﬁnd the complex conjugate of an expression by changing
the signs of all the i’s. This means that (iH)† = −iH† = −iH since H is Hermitian.
Then summing the series we get U† = e−iH, which is just what we found for U−1
above. Thus U† = U−1, so U is a unitary matrix. (Also see Problem 11.61.)
PROBLEMS, SECTION 9
1.
Use index notation as in (9.9) to prove the second part of the associative law for
matrix multiplication: (AB)C = ABC.
2.
Use index notation to prove the distributive law for matrix multiplication, namely:
A(B + C) = AB + AC.

Section 9
Special Matrices and Formulas
141
3.
Given the following matrix, ﬁnd the transpose, the inverse, the complex conjugate,
and the transpose conjugate of A. Verify that AA−1 = A−1A = the unit matrix.
A =
0
@
1
0
5i
−2i
2
0
1
1 + i
0
1
A ,
4.
Repeat Problem 3 given
A =
0
@
0
2i
−1
−i
2
0
3
0
0
1
A .
5.
Show that the product AAT is a symmetric matrix.
6.
Give numerical examples of: a symmetric matrix; a skew-symmetric matrix; a real
matrix; a pure imaginary matrix.
7.
Write each of the items in the second column of (9.2) in index notation.
8.
(a)
Prove that (AB)† = B†A†. Hint: See (9.10).
(b)
Verify (9.11), that is, show that (9.10) applies to a product of any number of
matrices. Hint: Use (9.10) and (9.8).
9.
In (9.1) we have deﬁned the adjoint of a matrix as the transpose conjugate. This is
the usual deﬁnition except in algebra where the adjoint is deﬁned as the transposed
matrix of cofactors [see (6.13)]. Show that the two deﬁnitions are the same for a
unitary matrix with determinant = +1.
10.
Show that if a matrix is orthogonal and its determinant is +1, then each element
of the matrix is equal to its own cofactor. Hint: Use (6.13) and the deﬁnition of an
orthogonal matrix.
11.
Show that a real Hermitian matrix is symmetric. Show that a real unitary matrix is
orthogonal. Note: Thus we see that Hermitian is the complex analogue of symmetric,
and unitary is the complex analogue of orthogonal. (See Section 11.)
12.
Show that the deﬁnition of a Hermitian matrix (A = A†) can be written aij = ¯aji
(that is, the diagonal elements are real and the other elements have the property
that a12 = ¯a21, etc.). Construct an example of a Hermitian matrix.
13.
Show that the following matrix is a unitary matrix.
0
B
B
@
(1 + i
√
3)/4
√
3
2
√
2
(1 + i)
−
√
3
2
√
2
(1 + i)
(
√
3 + i)/4
1
C
C
A
14.
Use (9.11) and (9.12) to simplify (ABTC)T, (C−1MC)−1, (AH)−1(AHA−1)3(HA−1)−1.
15.
(a)
Show that the Pauli spin matrices (Problem 6.6) are Hermitian.
(b)
Show that the Pauli spin matrices satisfy the Jacobi identity
ˆ
A, [B, C]
˜
+
ˆ
B, [C, A]
˜
+
ˆ
C, [A, B]
˜
= 0 where [A, B] is the commutator of A, B [see (6.3)].
(c)
Generalize (b) to prove the Jacobi identity for any (conformable) matrices A,
B, C. Also see Chapter 6, Problem 3.14.
16.
Let Cij = (−1)i+jMij be the cofactor of element aij in the determinant A. Show
that the statement of Laplace’s development and the statement of Problem 3.8 can
be combined in the equations
X
j
aijCkj = δik · det A,
or
X
i
aijCik = δjk · det A.

142
Linear Algebra
Chapter 3
17.
(a)
Show that if A and B are symmetric, then AB is not symmetric unless A and
B commute.
(b)
Show that a product of orthogonal matrices is orthogonal.
(c)
Show that if A and B are Hermitian, then AB is not Hermitian unless A and
B commute.
(d)
Show that a product of unitary matrices is unitary.
18.
If A and B are symmetric matrices, show that their commutator is antisymmetric
[see equation (6.3)].
19.
(a)
Prove that Tr(AB) = Tr(BA). Hint: See proof of (9.13).
(b)
Construct matrices A, B, C for which Tr(ABC) ̸= Tr(CBA), but verify that
Tr(ABC) = Tr(CAB).
(c)
If S is a symmetric matrix and A is an antisymmetric matrix, show that
Tr(SA) = 0. Hint: Consider Tr(SA)T and prove that Tr(SA) = −Tr(SA).
20.
Show that the determinant of a unitary matrix is a complex number with absolute
value = 1. Hint: See proof of equation (7.11).
21.
Show that the transpose of a sum of matrices is equal to the sum of the transposes.
Also show that (Mn)T = (MT)n. Hint: Use (9.11) and (9.8).
22.
Show that a unitary matrix is a normal matrix, that is, that it commutes with its
transpose conjugate [see (9.2)]. Also show that orthogonal, symmetric, antisymmet-
ric, Hermitian, and anti-Hermitian matrices are normal.
23.
Show that the following matrices are Hermitian whether A is Hermitian or not:
AA†, A + A†, i(A −A†).
24.
Show that an orthogonal transformation preserves the length of vectors. Hint: If r is
the column matrix of vector r [see (6.10)], write out rTr to show that it is the square
of the length of r. Similarly RTR = |R|2 and you want to show that |R|2 = |r|2,
that is, RTR = rTr if R = Mr and M is orthogonal. Use (9.11).
25.
(a)
Show that the inverse of an orthogonal matrix is orthogonal. Hint: Let A =
O−1; from (9.2), write the condition for O to be orthogonal and show that A
satisﬁes it.
(b)
Show that the inverse of a unitary matrix is unitary. See hint in (a).
(c)
If H is Hermitian and U is unitary, show that U−1HU is Hermitian.
10. LINEAR VECTOR SPACES
We have used extensively the vector r = ix+jy+kz to mean a vector from the origin
to the point (x, y, z). There is a one-to-one correspondence between the vectors r
and the points (x, y, z); the collection of all such points or all such vectors makes
up the 3-dimensional space often called R3 (R for real) or V3 (V for vector) or E3
(E for Euclidean). Similarly, we can consider a 2-dimensional space V2 of vectors
r = ix + jy or points (x, y) making up the (x, y) plane. V2 might also mean any
plane through the origin. And V1 means all the vectors from the origin to points
on some line through the origin.
We also use x, y, z to mean the variables or unknowns in a problem.
Now
applied problems often involve more than three variables. By extension of the idea
of V3, it is convenient to call an ordered set of n numbers a point or vector in the
n-dimensional space Vn. For example, the 4-vectors of special relativity are ordered

Section 10
Linear Vector Spaces
143
sets of four numbers; we say that space-time is 4-dimensional. A point of the phase
space used in classical and quantum mechanics is an ordered set of six numbers,
the three components of the position of a particle and the three components of its
momentum; thus the phase space of a particle is the 6-dimensional space V6.
In such cases, we can’t represent the variables as coordinates of a point in physical
space since physical space has only three dimensions.
But it is convenient and
customary to extend our geometrical terminology anyway. Thus we use the terms
variables and coordinates interchangeably and speak, for example, of a “point in 5-
dimensional space,” meaning an ordered set of values of ﬁve variables, and similarly
for any number of variables. In three dimensions, we think of the coordinates of a
point as the components of a vector from the origin to the point. By analogy, we
call an ordered set of ﬁve numbers a “vector in 5-dimensional space” or an ordered
set of n numbers a “vector in n-dimensional space.”
Much of the geometrical terminology which is familiar in two and three dimen-
sions can be extended to problems in n dimensions (that is, n variables) by using
the algebra which parallels the geometry. For example, the distance from the origin
to the point (x, y, z) is

x2 + y2 + z2. By analogy in a problem in the ﬁve vari-
ables x, y, z, u, v, we deﬁne the distance from the origin (0, 0, 0, 0, 0) to the point
(x, y, z, u, v) as

x2 + y2 + z2 + u2 + v2.
By using the algebra which goes with
the geometry, we can easily extend such ideas as the length of a vector, the dot
product of two vectors, and therefore the angle between the vectors and the idea of
orthogonality, etc. We saw in Section 7, that an orthogonal transformation in two
or three dimensions corresponds to a rotation. Thus we might say, in a problem in
n variables, that a linear transformation (that is a linear change of variables) satis-
fying “sum of squares of new variables = sum of squares of old variables” [compare
(7.8)] corresponds to a “rotation in n-dimensional space.”
Example 1.
Find the distance between the points (3, 0, 5, −2, 1) and (0, 1, −2, 3, 0).
Generalizing what we would do in three dimensions, we ﬁnd d2 = (3 −0)2 +
(0 −1)2 + (5 + 2)2 + (−2 −3)2 + (1 −0)2 = 9 + 1 + 49 + 25 + 1 = 85, d =
√
85.
If we start with several vectors, and ﬁnd linear combinations of them in the
algebraic way (by components), then we say that the original set of vectors and all
their linear combinations form a linear vector space (or just vector space or linear
space or space). Note that if r is one of our original vectors, then r −r = 0 is one
of the linear combinations; thus the zero vector (that is, the origin) must be a point
in every vector space. A line or plane not passing through the origin is not a vector
space.
Subspace, Span, Basis, Dimension
Suppose we start with the four vectors in
(8.1). We showed in (8.2) that they are all linear combinations of the two vectors
(9, 0, 7) and (0, −9, 13). Now two linearly independent vectors (remember their tails
are at the origin) determine a plane; all linear combinations of the two vectors lie
in the plane. [The plane we are talking about in this example is the plane through
the three points (9, 0, 7), (0, −9, 13), and the origin.] Since all the vectors making
up this plane V2 are also part of 3-dimensional space V3, we call V2 a subspace
of V3. Similarly any line lying in this plane and passing through the origin is a
subspace of V2 and of V3. We say that either the original four vectors or the two
independent ones span the space V2; a set of vectors spans a space if all the vectors

144
Linear Algebra
Chapter 3
in the space can be written as linear combinations of the spanning set. A set of
linearly independent vectors which span a vector space is called a basis. Here the
vectors (9, 0, 7) and (0, −9, 13) are one possible choice as a basis for the space V2;
another choice would be any two of the original vectors since in (8.2) no two of the
vectors are dependent.
The dimension of a vector space is equal to the number of basis vectors. Note
that this statement implies (correctly—see Problem 8) that no matter how you pick
the basis vectors for a given vector space, there will always be the same number
of them. This number is the dimension of the space. In 3 dimensions, we have
frequently used the unit basis vectors i, j, k which can also be written as (1, 0, 0),
(0, 1, 0), (0, 0, 1).
Then in, say 5 dimensions, a corresponding set of unit basis
vectors would be (1, 0, 0, 0, 0), (0, 1, 0, 0, 0), (0, 0, 1, 0, 0), (0, 0, 0, 1, 0), (0, 0, 0, 0, 1).
You should satisfy yourself that these ﬁve vectors are linearly independent and span
a 5 dimensional space.
Example 2.
Find the dimension of the space spanned by the following vectors, and a basis
for the space: (1, 0, 1, 5, −2), (0, 1, 0, 6, −3), (2, −1, 2, 4, 1), (3, 0, 3, 15, −6).
We write the matrix whose rows are the components of the vectors and row
reduce it to ﬁnd that there are three linearly independent vectors: (1, 0, 1, 5, 0),
(0, 1, 0, 6, 0), (0, 0, 0, 0, 1). These three vectors are a basis for the space which is
therefore 3-dimensional.
Inner Product, Norm, Orthogonality
Recall from (4.10) that the scalar (or
dot or inner) product of two vectors A = (A1, A2, A3) and B = (B1, B2, B3) is
A1B1+A2B2+A3B3 = 3
i=1 AiBi. This is very easy to generalize to n dimensions.
By deﬁnition, the inner product of two vectors in n dimensions is given by
(10.1)
A · B = (Inner product of A and B) =
n

i=1
AiBi.
Similarly, generalizing (4.1), we can deﬁne the length or norm of a vector in n di-
mensions by the formula:
(10.2)
A = Norm of A = ||A|| =
√
A · A =




n

i=1
A2
i .
In 3 dimensions, we also write the scalar product as AB cos θ [see (4.2)] so if two
vectors are orthogonal (perpendicular) their scalar product is AB cos π/2 = 0. We
generalize this to n dimensions by saying that two vectors in n dimensions are
orthogonal if their inner product is zero.
(10.3)
A and B are orthogonal if
n

i=1
AiBi = 0.

Section 10
Linear Vector Spaces
145
Schwarz Inequality
In 2 or 3 dimensions we can ﬁnd the angle between two
vectors [see (4.11)] from the formula A · B = AB cos θ. It is tempting to use the
same formula in n dimensions, but before we do we should be sure that the resulting
value of cos θ will satisfy | cos θ| ≤1, that is
(10.4)
|A · B| ≤AB,
or

n

i=1
AiBi
 ≤




n

i=1
A2
i




n

i=1
B2
i .
This is called the Schwarz inequality (for n-dimensional Euclidean space). We can
prove it as follows. First note that if B = 0, (10.4) just says 0 ≤0 which is certainly
true. For B ̸= 0, we consider the vector C = BA −(A · B)B/B, and ﬁnd C · C.
Now C · C =  C2
i ≥0, so we have
C · C = B2(A · A) −2B(A · B)(A · B)/B + (A · B)2(B · B)/B2
= A2B2 −2(A · B)2 + (A · B)2 = A2B2 −(A · B)2 = C2 ≥0,
(10.5)
which gives (10.4). Thus, if we like, we can deﬁne the cosine of the angle between
two vectors in n dimensions by cos θ = A · B/(AB). Note that equality holds in
Schwarz’s inequality if and only if cos θ = ±1, that is, when A and B are parallel
or antiparallel, say B = kA.
Example3.
Find the cosine of the angle between each pair of the 3 basis vectors we found
in Example 2.
By (10.2) we ﬁnd that the norms of the ﬁrst two basis vectors are √1 + 1 + 25 =
√
27 and √1 + 36 =
√
37.
By (10.1), the inner product of these two vectors is
1 · 0 + 0 · 1 + 1 · 0 + 5 · 6 + 0 · 0 = 30. Thus cos θ = 30/(
√
27 · 37) ≃0.949, which,
we note, is < 1 as Schwarz’s inequality says. The third basis vector in Example 2
is orthogonal to the other two since the inner products are zero, that is, cos θ = 0.
Orthonormal Basis; Gram-Schmidt Method
We call a set of vectors or-
thonormal if they are all mutually orthogonal (perpendicular), and each vector is
normalized (that is, its norm is one—it has unit length). For example, the vectors
i, j, k, form an orthonormal set. If we have a set of basis vectors for a space, it is
often convenient to take combinations of them to form an orthonormal basis. The
Gram-Schmidt method is a systematic process for doing this. It is very simple in
idea although the details of carrying it out can get messy. Suppose we have basis
vectors A, B, C. Normalize A to get the ﬁrst vector of a set of orthonormal basis
vectors. To get a second basis vector, subtract from B its component along A; what
remains is orthogonal to A. [See equation (4.4) and Figure 4.10.] Normalize this
remainder to ﬁnd the second vector of an orthonormal basis. Similarly, subtract
from C its components along A and B to ﬁnd a third vector orthogonal to both A
and B and normalize this third vector. We now have 3 mutually orthogonal unit
vectors; this is the desired set of orthonormal basis vectors. In a space of higher
dimension, this process can be continued. (We will see a use for this method in
Section 11; see degeneracy, pages 152–153.)

146
Linear Algebra
Chapter 3
Example 4.
Given the basis vectors A, B, C, below, use the Gram-Schmidt method to
ﬁnd an orthonormal set of basis vectors e1, e2, e3. Following the outline above, we
ﬁnd
A = (0, 0, 5, 0);
e1 = A/A = (0, 0, 1, 0);
B = (2, 0, 3, 0);
B −(e1 · B)e1 = B −3e1 = (2, 0, 0, 0);
e2 = (1, 0, 0, 0);
C = (7, 1, −5, 3);
C −(e1 · C)e1 −(e2 · C)e2 = C −(−5)e1 −7e2
= (0, 1, 0, 3);
e3 = (0, 1, 0, 3)/
√
10.
Complex Euclidean Space
In applications it is useful to allow vector compo-
nents to be complex. For example, in three dimensions we might consider vectors
like (5 + 2i, 3 −i, 1 + i). Let’s go back and see what modiﬁcations are needed in
this case. In (10.2), we want the quantity under the square root sign to be positive.
To assure this, we replace the square of Ai by the absolute square of Ai, that is by
|Ai|2 = A∗
i Ai where A∗
i is the complex conjugate of Ai (see Chapter 2). Similarly,
in (10.1) and (10.3), we replace AiBi by A∗
i Bi. Thus we deﬁne
(10.6)
(Inner product of A and B) =
n

i=1
A∗
i Bi
(10.7)
(Norm of A) = ||A|| =




n

i=1
A∗
i Ai
(10.8)
A and B are orthogonal if
n

i=1
A∗
i Bi = 0.
The Schwarz inequality becomes (see Problem 6)
(10.9)

n

i=1
A∗
i Bi
 ≤




n

i=1
A∗
i Ai




n

i=1
B∗
i Bi.
Note that we can write the inner product in matrix form. If A is a column matrix
with elements Ai, then the transpose conjugate matrix A† is a row matrix with
elements A∗
i . Using this notation we can write  A∗
i Bi = A†B (Problem 9).
Example 5.
Given A = (3i, 1 −i, 2 + 3i, 1 + 2i), B = (−1, 1 + 2i, 3−i, i), C = (4 −2i, 2−
i, 1, i −2), we ﬁnd by (10.6) to (10.8):
(Inner product of A and B) = (−3i)(−1) + (1 + i)(1 + 2i)
+ (2 −3i)(3 −i) + (1 −2i)i = 4 −4i.

Section 10
Linear Vector Spaces
147
(Norm of A)2 = (−3i)(3i) + (1 + i)(1 −i) + (2 −3i)(2 + 3i) + (1 −2i)(1 + 2i)
= 9 + 2 + 13 + 5 = 29,
||A|| =
√
29.
(Norm of B)2 = 1 + 5 + 10 + 1 = 17,
||B|| =
√
17.
Note that |4 −4i| = 4
√
2 <
√
29
√
17 in accord with the Schwarz inequality (10.9).
(Inner product of B and C) = (−1)(4 −2i) + (1 −2i)(2 −i) + (3 + i)(1)
+ (−i)(i −2) = −4 + 2i −5i + 3 + i + 1 + 2i = 0.
Thus by (10.8), B and C are orthogonal.
PROBLEMS, SECTION 10
1.
Find the distance between the points
(a)
(4, −1, 2, 7) and (2, 3, 1, 9);
(b)
(−1, 5, −3, 2, 4) and (2, 6, 2, 7, 6);
(c)
(5, −2, 3, 3, 1, 0) and (0, 1, 5, 7, 2, 1).
2.
For the given sets of vectors, ﬁnd the dimension of the space spanned by them and
a basis for this space.
(a)
(1, −1, 0, 0), (0, −2, 5, 1), (1, −3, 5, 1), (2, −4, 5, 1);
(b)
(0, 1, 2, 0, 0, 4), (1, 1, 3, 5, −3, 5), (1, 0, 0, 5, 0, 1), (−1, 1, 3, −5, −3, 3),
(0, 0, 1, 0, −3, 0);
(c)
(0, 10, −1, 1, 10), (2, −2, −4, 0, −3), (4, 2, 0, 4, 5), (3, 2, 0, 3, 4), (5, −4, 5, 6, 2).
3.
(a)
Find the cosines of the angles between pairs of vectors in Problem 2(a).
(b)
Find two orthogonal vectors in Problem 2(b).
4.
For each given set of basis vectors, use the Gram-Schmidt method to ﬁnd an or-
thonormal set.
(a)
A = (0, 2, 0, 0), B = (3, −4, 0, 0), C = (1, 2, 3, 4).
(b)
A = (0, 0, 0, 7), B = (2, 0, 0, 5), C = (3, 1, 1, 4).
(c)
A = (6, 0, 0, 0), B = (1, 0, 2, 0), C = (4, 1, 9, 2).
5.
By (10.6) and (10.7), ﬁnd the norms of A and B and the inner product of A and B,
and note that the Schwarz inequality (10.9) is satisﬁed:
(a)
A = (3 + i, 1, 2 −i, −5i, i + 1), B = (2i, 4 −3i, 1 + i, 3i, 1);
(b)
A = (2, 2i −3, 1 + i, 5i, i −2), B = (5i −2, 1, 3 + i, 2i, 4).
6.
Write out the proof of the Schwarz inequality (10.9) for a complex Euclidean space.
Hint: Follow the proof of (10.4) in (10.5), replacing the deﬁnitions of norm and inner
product in (10.1) and (10.2) by the deﬁnitions in (10.6) and (10.7). Remember that
norms are real and ≥0.
7.
Show that, in n-dimensional space, any n + 1 vectors are linearly dependent.
Hint: See Section 8.
8.
Show that two diﬀerent sets of basis vectors for the same vector space must contain
the same number of vectors. Hint: Suppose a basis for a given vector space contains
n vectors. Use Problem 7 to show that there cannot be more than n vectors in a
basis for this space. Conversely, if there were a correct basis with less than n vectors,
what can you say about the claimed n-vector basis?

148
Linear Algebra
Chapter 3
9.
Write equations (10.6) to (10.9) in matrix form as discussed just after (10.9).
10.
Prove that ||A + B|| ≤||A|| + ||B||. This is called the triangle inequality; in two
or three dimensions, it simply says that the length of one side of a triangle ≤
sum of the lengths of the other 2 sides. Hint: To prove it in n-dimensional space,
write the square of the desired inequality using (10.2) and also use the Schwarz
inequality (10.4).
Generalize the theorem to complex Euclidean space by using
(10.7) and (10.9).
11. EIGENVALUES AND EIGENVECTORS; DIAGONALIZING MATRICES
We can give the following physical interpretation to Figure 7.2 and equations (7.5).
Suppose the (x, y) plane is covered by an elastic membrane which can be stretched,
shrunk, or rotated (with the origin ﬁxed). Then any point (x, y) of the membrane
becomes some point (X, Y ) after the deformation, and we can say that the matrix M
describes the deformation. Let us now ask whether there are any vectors such that
R = λr where λ = const. Such vectors are called eigenvectors (or characteristic
vectors) of the transformation, and the values of λ are called the eigenvalues (or
characteristic values) of the matrix M of the transformation.
Eigenvalues
To illustrate ﬁnding eigenvalues, let’s consider the transformation
(11.1)
X
Y

=
 5
−2
−2
2
 x
y

.
The eigenvector condition R = λr is, in matrix notation,

X
Y

=

5
−2
−2
2
 
x
y

= λ

x
y

=

λx
λy

,
or written out in equation form:
(11.2)
5x −2y = λx,
−2x + 2y = λy,
or
(5 −λ)x −2y = 0,
−2x + (2 −λ)y = 0.
These equations are homogeneous. Recall from (8.9) that a set of homogeneous
equations has solutions other than x = y = 0 only if the determinant of the coeﬃ-
cients is zero. Thus we want
(11.3)

5 −λ
−2
−2
2 −λ
 = 0.
This is called the characteristic equation of the matrix M, and the determinant in
(11.3) is called the secular determinant.
To obtain the characteristic equation of a matrix M, we subtract λ from the
elements on the main diagonal of M, and then set the determinant of the resulting
matrix equal to zero.
We solve (11.3) for λ to ﬁnd the characteristic values of M:
(5 −λ)(2 −λ) −4 = λ2 −7λ + 6 = 0,
λ = 1
or
λ = 6.
(11.4)

Section 11
Eigenvalues and Eigenvectors; Diagonalizing Matrices
149
Eigenvectors
Substituting the λ values from (11.4) into (11.2), we get:
(11.5)
2x −y = 0
from either of the equations (11.2) when λ = 1;
x + 2y = 0
from either of the equations (11.2) when λ = 6.
We were looking for vectors r = ix + jy such that the transformation (11.1) would
give an R parallel to r. What we have found is that any vector r with x and y com-
ponents satisfying either of the equations (11.5) has this property. Since equations
(11.5) are equations of straight lines through the origin, such vectors lie along these
lines (Figure 11.1). Then equations (11.5) show that any vector r from the origin
to a point on x + 2y = 0 is changed by the transformation (11.1) to a vector in
the same direction but six times as long, and any vector from the origin to a point
on 2x −y = 0 is unchanged by the transformation (11.1). These vectors (along
x + 2y = 0 and 2x −y = 0) are the eigenvectors of the transformation. Along these
two directions (and only these), the deformation of the elastic membrane was a pure
stretch with no shear (rotation).
Figure 11.1
Diagonalizing a Matrix
We next write (11.2) once with λ = 1, and again with
λ = 6, using subscripts 1 and 2 to identify the corresponding eigenvectors:
(11.6)
5x1 −2y1 = x1,
−2x1 + 2y1 = y1,
5x2 −2y2 = 6x2,
−2x2 + 2y2 = 6y2.
These four equations can be written as one matrix equation, as you can easily verify
by multiplying out both sides (Problem 1):
(11.7)
 5
−2
−2
2
 x1
x2
y1
y2

=
x1
x2
y1
y2
 1
0
0
6

.
All we really can say about (x1, y1) is that 2x1 −y1 = 0; however, it is convenient to
pick numerical values of x1 and y1 to make r1 = (x1, y1) a unit vector, and similarly
for r2 = (x2, y2). Then we have
(11.8)
x1 =
1
√
5,
y1 =
2
√
5,
x2 = −2
√
5,
y2 =
1
√
5,

150
Linear Algebra
Chapter 3
and (11.7) becomes
(11.9)

5
−2
−2
2





1
√
5
−2
√
5
2
√
5
1
√
5



=




1
√
5
−2
√
5
2
√
5
1
√
5





1
0
0
6

.
Representing these matrices by letters we can write
MC = CD,
where
M =
 5
−2
−2
2

,
C =




1
√
5
−2
√
5
2
√
5
1
√
5



,
D =
1
0
0
6

.
(11.10)
If, as here, the determinant of C is not zero, then C has an inverse C−1; let
us multiply (11.10) by C−1 and remember that C−1C is the unit matrix; then
C−1MC = C−1CD = D.
(11.11)
C−1MC = D.
The matrix D has elements diﬀerent from zero only down the main diagonal; it
is called a diagonal matrix. The matrix D is called similar to M, and when we
obtain D given M, we say that we have diagonalized M by a similarity transfor-
mation.
We shall see shortly that this amounts physically to a simpliﬁcation of the problem
by a better choice of variables. For example, in the problem of the membrane, it is
simpler to describe the deformation if we use axes along the eigenvectors. Later we
shall see more examples of the use of the diagonalization process.
Observe that it is easy to ﬁnd D; we need only solve the characteristic equation
of M. Then D is a matrix with these characteristic values down the main diagonal
and zeros elsewhere. We can also ﬁnd C (with more work), but for many purposes
only D is needed.
Note that the order of the eigenvalues down the main diagonal of D is arbitrary;
for example we could write (11.6) as
(11.12)

5
−2
−2
2
 
x2
x1
y2
y1

=

x2
x1
y2
y1
 
6
0
0
1

instead of (11.7). Then (11.11) still holds, with a diﬀerent C, of course, and with
D =

6
0
0
1

instead of as in (11.10) (Problem 1).

Section 11
Eigenvalues and Eigenvectors; Diagonalizing Matrices
151
Meaning of C and D
To see more clearly the meaning of
(11.11) let us ﬁnd what the matrices C and D mean physically.
We consider two sets of axes (x, y) and (x′, y′) with (x′, y′)
rotated through θ from (x, y) (Figure 11.2). The (x, y) and
(x′, y′) coordinates of one point (or components of one vector
r = r′) relative to the two systems are related by (7.13).
Solving (7.13) for x and y, we have
(11.13)
x = x′ cos θ −y′ sin θ,
y = x′ sin θ + y′ cos θ,
Figure 11.2
or in matrix notation
(11.14)
r = Cr′
where
C =
cos θ
−sin θ
sin θ
cos θ

.
This equation is true for any single vector with components given in the two systems.
Suppose we have another vector R = R′ (Figure 11.2) with components X, Y and
X′, Y ′; these components are related by
(11.15)
R = CR′.
Now let M be a matrix which describes a deformation of the plane in the (x, y)
system. Then the equation
(11.16)
R = Mr
says that the vector r becomes the vector R after the deformation, both vectors
given relative to the (x, y) axes. Let us ask how we can describe the deformation in
the (x′, y′) system, that is, what matrix carries r′ into R′? We substitute (11.14)
and (11.15) into (11.16) and ﬁnd CR′ = MCr′ or
(11.17)
R′ = C−1MCr′.
Thus the answer to our question is that
D = C−1MC is the matrix which describes in the (x′, y′) system the same defor-
mation that M describes in the (x, y) system.
Figure 11.3
Next we want to show that if the ma-
trix C is chosen to make D = C−1MC
a diagonal matrix, then the new axes
(x′, y′) are along the directions of the eig-
envectors of M. Recall from (11.10) that
the columns of C are the components of
the unit eigenvectors. If the eigenvectors
are perpendicular, as they are in our ex-
ample (see Problem 2) then the new axes
(x′, y′) along the eigenvector directions
are a set of perpendicular axes rotated

152
Linear Algebra
Chapter 3
from axes (x, y) by some angle θ (Figure 11.3). The unit eigenvectors r1 and r2 are
shown in Figure 11.3; from the ﬁgure we ﬁnd
(11.18)
x1 = |r1| cos θ = cos θ,
x2 = −|r2| sin θ = −sin θ
y1 = |r1| sin θ = sin θ,
y2 = |r2| cos θ = cos θ;
C =

x1
x2
y1
y2

=

cos θ
−sin θ
sin θ
cos θ

.
Thus, the matrix C which diagonalizes M is the rotation matrix C in (11.14)
when the (x′, y′) axes are along the directions of the eigenvectors of M.
Relative to these new axes, the diagonal matrix D describes the deformation.
For our example we have
R′ = Dr′
or
X′
Y ′

=
1
0
0
6
 x′
y′

or
X′ = x′,
Y ′ = 6y′.
(11.19)
In words, (11.19) says that [in the (x′, y′) system] each point (x′, y′) has its x′ coor-
dinate unchanged by the deformation and its y′ coordinate multiplied by 6, that is,
the deformation is simply a stretch in the y′ direction. This is a simpler description
of the deformation and clearer physically than the description given by (11.1).
You can see now why the order of eigenvalues down the main diagonal in D is
arbitrary and why (11.12) is just as satisfactory as (11.7). The new axes (x′, y′) are
along the eigenvectors, but it is unimportant which eigenvector we call x′ and which
we call y′. In doing a problem we simply select a D with the eigenvalues of M in
some (arbitrary) order down the main diagonal. Our choice of D then determines
which eigenvector direction is called the x′ axis and which is called y′.
It was unnecessary in the above discussion to have the x′ and y′ axes perpendic-
ular, although this is the most useful case. If r = Cr′ but C is just any (nonsingular)
matrix [not necessarily the orthogonal rotation matrix as in (11.14)], then (11.17)
still follows. That is, C−1MC describes the deformation using (x′, y′) axes. But if
Figure 11.4
C is not an orthogonal matrix, then the (x′, y′)
axes are not perpendicular (Figure 11.4) and
x2 + y2 ̸= x′2 + y′2, that is, the transforma-
tion is not a rotation of axes. Recall that C
is the matrix of unit eigenvectors; if these are
perpendicular, then C is an orthogonal ma-
trix (Problem 6). It can be shown that this
will be the case if and only if the matrix M
is symmetric. [See equation (11.27) and the
discussion just before it. Also see Problems
33 to 35, and Problem 15.25.]
Degeneracy
For a symmetric matrix, we have seen that the eigenvectors corre-
sponding to diﬀerent eigenvalues are orthogonal. If two (or more) eigenvalues are
the same, then that eigenvalue is called degenerate. Degeneracy means that two (or
more) independent eigenvectors correspond to the same eigenvalue.

Section 11
Eigenvalues and Eigenvectors; Diagonalizing Matrices
153
Example 1.
Consider the following matrix:
(11.20)
M =


1
−4
2
−4
1
−2
2
−2
−2

.
The eigenvalues of M are λ = 6, −3, −3, and the eigenvector corresponding to λ = 6
is (2, −2, 1) (Problem 36). For λ = −3, the eigenvector condition is 2x−2y +z = 0.
This is a plane orthogonal to the λ = 6 eigenvector, and any vector in this plane
is an eigenvector corresponding to λ = −3. That is, the λ = −3 eigenspace is a
plane. It is convenient to choose two orthogonal eigenvectors as basis vectors in this
λ = −3 eigenplane, for example (1, 1, 0) and (−1, 1, 4). (See Problem 36.)
You may ask how you ﬁnd these orthogonal eigenvectors except by inspection.
Recall that the cross product of two vectors is perpendicular to both of them. Thus
in the present case we could pick one vector in the λ = −3 eigenplane and then
take its cross product with the λ = 6 eigenvector. This gives a second vector in the
λ = −3 eigenplane, perpendicular to the ﬁrst one we picked. However, this only
works in three dimensions; if we are dealing with spaces of higher dimension (see
Section 10), then we need another method. Suppose we ﬁrst write down just any
two (diﬀerent) vectors in the eigenplane not trying to make them orthogonal. Then
we can use the Gram-Schmidt method (see Section 10) to ﬁnd an orthogonal set.
For example, in the problem above, suppose you had thought of (or your computer
had given you) the vectors A = (1, 1, 0) and B = (−1, 0, 2) which are vectors in the
λ = −3 eigenplane but not orthogonal to each other. Following the Gram-Schmidt
method, we ﬁnd
A = (1, 1, 0),
e = A/A = (1, 1, 0)/
√
2,
B −(e · B)e = (−1, 0, 2) −−1
2 (1, 1, 0) =
−1
2 , 1
2, 2

,
or (−1, 1, 4) as we had above. For a degenerate subspace of dimension m > 2,
we just need to write down m linearly independent eigenvectors, and then ﬁnd an
orthogonal set by the Gram-Schmidt method.
Diagonalizing Hermitian Matrices
We have seen how to diagonalize symmet-
ric matrices by orthogonal similarity transformations. The complex analogue of
a symmetric matrix (ST = S) is a Hermitian matrix (H† = H) and the complex
analogue of an orthogonal matrix (OT = O−1) is a unitary matrix (U† = U−1). So
let’s discuss diagonalizing Hermitian matrices by unitary similarity transformations.
This is of great importance in quantum mechanics.
Although Hermitian matrices may have complex oﬀ-diagonal elements, the eigen-
values of a Hermitian matrix are always real. Let’s prove this. (Refer to Section 9
for deﬁnitions and theorems as needed.) Let H be a Hermitian matrix, and let r be
the column matrix of a non-zero eigenvector of H corresponding to the eigenvalue λ.
Then the eigenvector condition is Hr = λr. We want to take the transpose conjugate
(dagger) of this equation. Using the complex conjugate of equation (9.10), we get
(Hr)† = r†H† = r†H since H† = H for a Hermitian matrix. The transpose conjugate
of λr is λ∗r† (since λ is a number, we just need to take its complex conjugate). Now
we have the two equations
(11.21)
Hr = λr
and
r†H = λ∗r†.

154
Linear Algebra
Chapter 3
Multiply the ﬁrst equation in (11.21) on the left [see discussion following (10.9)] by
the row matrix r† and the second equation on the right by the column matrix r to
get
(11.22)
r†Hr = λr†r
and
r†Hr = λ∗r†r.
Subtracting the two equations we ﬁnd (λ −λ∗)r†r = 0. Since we assumed r ̸= 0, we
have λ∗= λ, that is, λ is real.
We can also show that for a Hermitian matrix the eigenvectors corresponding to
two diﬀerent eigenvalues are orthogonal. Start with the two eigenvector conditions,
(11.23)
Hr1 = λ1r1
and
Hr2 = λ2r2.
From these we can show (Problem 37)
(11.24)
r†
1Hr2 = λ1r†
1r2 = λ2r†
1r2,
or
(λ1 −λ2)r†
1r2 = 0.
Thus if λ1 ̸= λ2, then the inner product of r1 and r2 is zero, that is, they are
orthogonal [see (10.8)].
We can also prove that if a matrix M has real eigenvalues and can be diagonalized
by a unitary similarity transformation, then it is Hermitian. In symbols, we write
U−1MU = D, and ﬁnd the transpose conjugate of this equation to get (Problem 38)
(11.25)
(U−1MU)† = U−1M†U = D† = D.
Thus U−1MU = D = U−1M†U, so M = M†, which says that M is Hermitian. So we
have proved that
(11.26)
A matrix has real eigenvalues and can be diagonalized by a unitary
similarity transformation if and only if it is Hermitian.
Since a real Hermitian matrix is a symmetric matrix and a real unitary matrix is an
orthogonal matrix, the corresponding statement for symmetric matrices is (Prob-
lem 39).
(11.27)
A matrix has real eigenvalues and can be diagonalized by an or-
thogonal similarity transformation if and only if it is symmetric.
Recall from (9.2) and Problem 9.22 that normal matrices include symmetric, Hermi-
tian, orthogonal, and unitary matrices (as well as some others). It may be useful to
know the following general theorem which we state without proof [see, for example,
Am. J. Phys. 52, 513–515 (1984)].
(11.28)
A matrix can be diagonalized by a unitary similarity transformation
if and only if it is normal.

Section 11
Eigenvalues and Eigenvectors; Diagonalizing Matrices
155
Example 2.
To illustrate diagonalizing a Hermitian matrix by a unitary similarity trans-
formation, we consider the matrix
(11.29)
H =

2
3 −i
3 + i
−1

.
(Verify that H is Hermitian.)
We follow the same routine we used to ﬁnd the
eigenvalues and eigenvectors of a symmetric matrix. The eigenvalues are given by
(2 −λ)(−1 −λ) −(3 + i)(3 −i) = 0,
λ2 −λ −12 = 0,
λ = −3, 4.
For λ = −3, an eigenvector satisﬁes the equations
 5
3 −i
3 + i
2
 x
y

= 0,
or
5x + (3 −i)y = 0,
(3 + i)x + 2y = 0.
These equations are satisﬁed by x = 2, y = (−3−i). A choice for the unit eigenvector
is (2, −3 −i)/
√
14. For λ = 4, we ﬁnd similarly the equations
−2x + (3 −i)y = 0,
(3 + i)x −5y = 0,
which are satisﬁed by y = 2, x = 3 −i, so a unit eigenvector is (3 −i, 2)/
√
14. We
can verify that the two eigenvectors are orthogonal (as we proved above that they
must be) by ﬁnding that their inner product [see (10.8)] is (2, −3 −i)∗· (3 −i, 2) =
2(3−i)+2(−3+i) = 0. As in (11.10) we write the unit eigenvectors as the columns
of a matrix U which diagonalizes H by a similarity transformation.
U =
1
√
14

2
3 −i
−3 −i
2

,
U† =
1
√
14
 2
−3 + i
3 + i
2

You can easily verify that U†U = the unit matrix, so U−1 = U†. Then (Problem 40)
(11.30)
U−1HU = U†HU =
−3
0
0
4

,
that is, H is diagonalized by a unitary similarity transformation.
Orthogonal Transformations in 3 Dimensions
In Section 7, we considered
the active rotation and/or reﬂection of vectors r which was produced by a given
3 by 3 orthogonal matrix. Study Equations (7.18) and (7.19) carefully to see that,
acting on a column vector r, they rotate the vector by angle θ around the z axis
and/or reﬂect it through the (x, y) plane. We would now like to see how to ﬁnd
the eﬀect of more complicated orthogonal matrices. We can do this by using an
orthogonal similarity transformation to write a given orthogonal matrix relative to
a new coordinate system in which the rotation axis is the z axis, and/or the (x, y)
plane is the reﬂecting plane (in vector space language, this is a change of basis).
Then a comparison with (7.18) or (7.19) gives the rotation angle. Recall how we
construct a C matrix so that C−1MC describes the same transformation relative to
a new set of axes that M described relative to the original axes: The columns of the
C matrix are the components of unit vectors along the new axes [see (11.18) and
Figure 11.3].

156
Linear Algebra
Chapter 3
Example 3.
Consider the following matrices.
(11.31)
A = 1
2


1
√
2
1
−
√
2
0
√
2
1
−
√
2
1

,
B = 1
3


−2
−1
−2
2
−2
−1
1
2
−2


You can verify that A and B are both orthogonal, and that det A = 1, det B = −1
(Problem 45).
Thus A is a rotation matrix while B involves a reﬂection (and
perhaps also a rotation). For A, a vector along the rotation axis is not aﬀected by
the transformation so we ﬁnd the rotation axis by solving the equation Ar = r. We
did this in Section 7, but now you should recognize this as an eigenvector equation.
We want the eigenvector corresponding to the eigenvalue 1. By hand or by computer
(Problem 45) we ﬁnd that the eigenvector of A corresponding to λ = 1 is (1, 0, 1) or
i + k; this is the rotation axis. We want the new z axis to lie along this direction,
so we take the elements of the third column of matrix C to be the components of
the unit vector u = (1, 0, 1)/
√
2. For the ﬁrst column (new x axis) we choose a unit
vector perpendicular to the rotation axis, say v = (1, 0, −1)/
√
2, and for the second
column (new y axis), we use the cross product u × v = (0, 1, 0) (so that the new
axes form a right-handed orthogonal triad). This gives (Problem 45)
(11.32)
C =
1
√
2


1
0
1
0
√
2
0
−1
0
1

,
C−1AC =


0
1
0
−1
0
0
0
0
1

.
Comparing this result with (7.18), we see that cos θ = 0 and sin θ = −1, so the
rotation is −90◦around the axis i + k (or, if you prefer, +90◦around −i −k).
Example 4.
For the matrix B, a vector perpendicular to the reﬂection plane is reversed
in direction by the reﬂection. Thus we want to solve the equation Br = −r, that
is, to ﬁnd the eigenvector corresponding to λ = −1. You can verify (Problem 45)
that this is the vector (1, −1, 1) or i −j + k. The reﬂection is through the plane
x −y + z = 0, and the rotation (if any) is about the vector i −j + k. As we did for
matrix A, we construct a matrix C from this vector and two perpendicular vectors,
to get (Problem 45)
(11.33)
C =









1
√
6
1
√
2
1
√
3
−1
√
6
1
√
2
−1
√
3
−2
√
6
0
1
√
3









,
C−1BC =








−1
2
−
√
3
2
0
√
3
2
−1
2
0
0
0
−1








.
Compare this with (7.19) to get cos θ = −1
2, sin θ =
√
3
2 , so matrix B produces a
rotation of 120◦around i −j + k and a reﬂection through the plane x −y + z = 0.
You may have discovered that matrices A and B have two complex eigenvalues
(see Problem 46). The corresponding eigenvectors are also complex, and we didn’t
use them because this would take us into complex vector space (see Section 10,
and Problem 47) and our rotation and reﬂection problems are in ordinary real
3-dimensional space. (Note also that we did not diagonalize A and B, but just

Section 11
Eigenvalues and Eigenvectors; Diagonalizing Matrices
157
used similarity transformations to display them relative to rotated axes.) However,
when all the eigenvalues of an orthogonal matrix are real (see Problem 48), then
this process produces a diagonalized matrix with the eigenvalues down the main
diagonal.
Example 5.
Consider the matrix
(11.34)
F = 1
7


2
6
3
6
−3
2
3
2
−6

.
You can verify (Problem 49) that det F = 1, that the rotation axis (eigenvector
corresponding to the eigenvalue λ = 1) is 3i + 2j + k, and that the other two
eigenvalues are −1, −1. Then the diagonalized F (relative to axes with the new
z axis along the rotation axis) is
(11.35)


−1
0
0
0
−1
0
0
0
1

.
Comparing this with equation (7.18), we see that cos θ = −1, sin θ = 0, so F pro-
duces a rotation of 180◦about 3i + 2j + k.
An even easier way to ﬁnd the rotation angle in this problem is to use the
trace of F (Problem 50). From (7.18) and (11.34) we have 2 cos θ + 1 = −1. Thus
cos θ = −1, θ = 180◦as before. This method gives cos θ for any rotation or reﬂection
matrix, but unless cos θ = ±1, we also need more information (say the value of sin θ)
to determine whether θ is positive or negative.
Powers and Functions of Matrices
In Section 6 we found functions of some
matrices A for which it was easy to ﬁnd the powers because they repeated period-
ically [see equations (6.15) to (6.17)]. When this doesn’t happen, it isn’t so easy
to ﬁnd powers directly (Problem 58). But it is easy to ﬁnd powers of a diagonal
matrix, and you can also show that (Problem 57)
(11.36)
Mn = CDnC−1,
where
C−1MC = D,
D diagonal.
This result is useful not just for evaluating powers and functions of numerical ma-
trices but also for proving theorems (Problem 60).
Example 6.
We can show that if, as above, C−1MC = D, then
(11.37)
det eM = eTr(M).
As in (6.17) we deﬁne eM by its power series. For each term of the series Mn =
CDnC−1 by (11.36), so eM = CeDC−1. By (6.6), the determinant of a product =
the product of the determinants, and det CC−1 = 1, so we have det eM = det eD.
Now the matrix eD is diagonal and the diagonal elements are eλi where λi are the
eigenvalues of M.
Thus det eD = eλ1eλ2eλ3 · · · = eTr D.
But by (9.13), Tr D =
Tr(CC−1M) = Tr M, so we have (11.37).

158
Linear Algebra
Chapter 3
Simultaneous Diagonalization
Can we diagonalize two (or more) matrices us-
ing the same similarity transformation? Sometimes we can, namely if, and only if,
they commute. Let’s see why this is true. Recall that the diagonalizing C matrix
has columns which are mutually orthogonal unit eigenvectors of the matrix being
diagonalized. Suppose we can ﬁnd the same set of eigenvectors for two matrices F
and G; then the same C will diagonalize both. So the problem amounts to showing
how to ﬁnd a common set of eigenvectors for F and G if they commute.
Example7.
Let’s start by diagonalizing F. Suppose r (a column matrix) is the eigenvector
corresponding to the eigenvalue λ, that is, Fr = λr. Multiply this on the left by G
and use GF = FG (matrices commute) to get
(11.38)
GFr = λGr,
or
F(Gr) = λ(Gr).
This says that Gr is an eigenvector of F corresponding to the eigenvalue λ. If λ is
not degenerate (that is if there is just one eigenvector corresponding to λ) then Gr
must be the same vector as r (except maybe for length), that is, Gr is a multiple of r,
or Gr = λ′r. This is the eigenvector equation for G; it says that r is an eigenvector
of G. If all eigenvalues of F are non-degenerate, then F and G have the same set of
eigenvectors, and so can be diagonalized by the same C matrix.
Example 8.
Now suppose that there are two (or more) linearly independent eigenvec-
tors corresponding to the eigenvalue λ of F. Then every vector in the degenerate
eigenspace corresponding to λ is an eigenvector of matrix F (see discussion of de-
generacy above). Next consider matrix G. Corresponding to all non-degenerate
F eigenvalues we already have the same set of eigenvectors for G as for F. So we
just have to ﬁnd the eigenvectors of G in the degenerate eigenspace of F. Since all
vectors in this subspace are eigenvectors of F, we are free to choose ones which are
eigenvectors of G. Thus we now have the same set of eigenvectors for both matrices,
and so we can construct a C matrix which will diagonalize both F and G. For the
converse, see Problem 62.
PROBLEMS, SECTION 11
1.
Verify (11.7). Also verify (11.12) and ﬁnd the corresponding diﬀerent C in (11.11).
Hint: To ﬁnd C, start with (11.12) instead of (11.7) and follow through the method
of getting (11.10) from (11.7).
2.
Verify that the two eigenvectors in (11.8) are perpendicular, and that C in (11.10)
satisﬁes the condition (7.9) for an orthogonal matrix.
3.
(a)
If C is orthogonal and M is symmetric, show that C−1MC is symmetric.
(b)
If C is orthogonal and M antisymmetric, show that C−1MC is antisymmetric.
4.
Find the inverse of the rotation matrix in (7.13); you should get C in (11.14). Replace
θ by −θ in (7.13) to see that the matrix C corresponds to a rotation through −θ.
5.
Show that the C matrix in (11.10) does represent a rotation by ﬁnding the rotation
angle. Write equations (7.13) and (11.13) for this rotation.
6.
Show that if C is a matrix whose columns are the components (x1, y1) and (x2, y2)
of two perpendicular vectors each of unit length, then C is an orthogonal matrix.
Hint: Find CTC.

Section 11
Eigenvalues and Eigenvectors; Diagonalizing Matrices
159
7.
Generalize Problem 6 to three dimensions; to n dimensions.
8.
Show that under the transformation (11.1), all points (x, y) on a given straight line
through the origin go into points (X, Y ) on another straight line through the origin.
Hint: Solve (11.1) for x and y in terms of X and Y and substitute into the equation
y = mx to get an equation Y = kX, where k is a constant. Further hint: If R = Mr,
then r = M−1R.
9.
Show that det(C−1MC) = det M. Hints: See (6.6). What is the product of det(C−1)
and det C? Thus show that the product of the eigenvalues of M is equal to det M.
10.
Show that Tr(C−1MC) = Tr M. Hint: See (9.13). Thus show that the sum of the
eigenvalues of M is equal to Tr M.
11.
Find the inverse of the transformation x′ = 2x −3y, y′ = x + y, that is, ﬁnd x, y in
terms of x′, y′. (Hint: Use matrices.) Is the transformation orthogonal?
Find the eigenvalues and eigenvectors of the following matrices. Do some problems by
hand to be sure you understand what the process means. Then check your results by
computer.
12.
„1
3
2
2
«
13.
„2
2
2
−1
«
14.
„ 3
−2
−2
0
«
15.
0
@
2
3
0
3
2
0
0
0
1
1
A
16.
0
@
2
0
2
0
2
0
2
0
−1
1
A
17.
0
@
5
0
2
0
3
0
2
0
5
1
A
18.
0
@
−1
1
3
1
2
0
3
0
2
1
A
19.
0
@
1
2
2
2
3
0
2
0
3
1
A
20.
0
@
−1
2
1
2
3
0
1
0
3
1
A
21.
0
@
1
1
1
1
−1
1
1
1
−1
1
A
22.
0
@
−3
2
2
2
1
3
2
3
1
1
A
23.
0
@
13
4
−2
4
13
−2
−2
−2
10
1
A
24.
0
@
3
2
4
2
0
2
4
2
3
1
A
25.
0
@
1
1
−1
1
1
1
−1
1
−1
1
A
26.
0
@
2
1
1
1
2
1
1
1
2
1
A
Let each of the following matrices M describe a deformation of the (x, y) plane.
For
each given M ﬁnd: the eigenvalues and eigenvectors of the transformation, the matrix C
which diagonalizes M and speciﬁes the rotation to new axes (x′, y′) along the eigenvectors,
and the matrix D which gives the deformation relative to the new axes.
Describe the
deformation relative to the new axes.
27.
„ 2
−1
−1
2
«
28.
„5
2
2
2
«
29.
„3
4
4
9
«
30.
„3
1
1
3
«
31.
„3
2
2
3
«
32.
„ 6
−2
−2
3
«
33.
Find the eigenvalues and eigenvectors of the real symmetric matrix
M =
„A
H
H
B
«
.
Show that the eigenvalues are real and the eigenvectors are perpendicular.

160
Linear Algebra
Chapter 3
34.
By multiplying out M = CDC−1 where C is the rotation matrix (11.14) and D is
the diagonal matrix
„λ1
0
0
λ2
«
,
show that if M can be diagonalized by a rotation, then M is symmetric.
35.
The characteristic equation for a second-order matrix M is a quadratic equation.
We have considered in detail the case in which M is a real symmetric matrix and
the roots of the characteristic equation (eigenvalues) are real, positive, and unequal.
Discuss some other possibilities as follows:
(a)
M real and symmetric, eigenvalues real, one positive and one negative. Show
that the plane is reﬂected in one of the eigenvector lines (as well as stretched
or shrunk). Consider as a simple special case
M =
„1
0
0
−1
«
.
(b)
M real and symmetric, eigenvalues equal (and therefore real). Show that M
must be a multiple of the unit matrix. Thus show that the deformation consists
of dilation or shrinkage in the radial direction (the same in all directions) with
no rotation (and reﬂection in the origin if the root is negative).
(c)
M real, not symmetric, eigenvalues real and not equal. Show that in this case
the eigenvectors are not orthogonal. Hint: Find their dot product.
(d)
M real, not symmetric, eigenvalues complex. Show that all vectors are rotated,
that is, there are no (real) eigenvectors which are unchanged in direction by
the transformation. Consider the characteristic equation of a rotation matrix
as a special case.
36.
Verify the eigenvalues and eigenvectors of matrix M in (11.20). Find some other
pairs of orthogonal eigenvectors in the λ = −3 eigenplane.
37.
Starting with (11.23), obtain (11.24). Hints: Take the transpose conjugate (dagger)
of the ﬁrst equation in (11.23), (remember that H is Hermitian and the λ’s are real)
and multiply on the right by r2. Multiply the second equation in (11.23) on the left
by r†
1.
38.
Verify equation (11.25). Hint: Remember from Section 9 that the transpose con-
jugate (dagger) of a product of matrices is the product of the transpose conjugates
in reverse order and that U† = U−1. Also remember that we have assumed real
eigenvalues, so D is a real diagonal matrix.
39.
Write out the detailed proof of (11.27). Hint: Follow the proof of (11.26) in equations
(11.21) to (11.25), replacing the Hermitian matrix H by a symmetric matrix M which
is real. However, don’t assume that the eigenvalues λ are real until you prove it.
40.
Verify the details as indicated in diagonalizing H in (11.29).
Verify that each of the following matrices is Hermitian. Find its eigenvalues and eigenvec-
tors, write a unitary matrix U which diagonalizes H by a similarity transformation, and
show that U−1HU is the diagonal matrix of eigenvalues.
41.
„ 2
i
−i
2
«
42.
„
3
1 −i
1 + i
2
«
43.
„
1
2i
−2i
−2
«
44.
„
−2
3 + 4i
3 −4i
−2
«

Section 11
Eigenvalues and Eigenvectors; Diagonalizing Matrices
161
45.
Verify the details in the discussion of the matrices in (11.31).
46.
We have seen that an orthogonal matrix with determinant 1 has at least one eigen-
value = 1, and an orthogonal matrix with determinant = −1 has at least one eigen-
value = −1. Show that the other two eigenvalues in both cases are eiθ, e−iθ, which,
of course, includes the real values 1 (when θ = 0), and −1 (when θ = π). Hint: See
Problem 9, and remember that rotations and reﬂections do not change the length
of vectors so eigenvalues must have absolute value = 1.
47.
Find a unitary matrix U which diagonalizes A in (11.31) and verify that U−1AU is
diagonal with the eigenvalues down the main diagonal.
48.
Show that an orthogonal matrix M with all real eigenvalues is symmetric. Hints:
Method 1. When the eigenvalues are real, so are the eigenvectors, and the unitary
matrix which diagonalizes M is orthogonal. Use (11.27). Method 2. From Prob-
lem 46, note that the only real eigenvalues of an orthogonal M are ±1. Thus show
that M = M−1. Remember that M is orthogonal to show that M = MT.
49.
Verify the results for F in the discussion of (11.34).
50.
Show that the trace of a rotation matrix equals 2 cos θ + 1 where θ is the rotation
angle, and the trace of a reﬂection matrix equals 2 cos θ −1. Hint: See equations
(7.18) and (7.19), and Problem 10.
Show that each of the following matrices is orthogonal and ﬁnd the rotation and/or reﬂec-
tion it produces as an operator acting on vectors. If a rotation, ﬁnd the axis and angle;
if a reﬂection, ﬁnd the reﬂecting plane and the rotation, if any, about the normal to that
plane.
51.
1
11
0
@
2
6
9
6
7
−6
9
−6
2
1
A
52.
1
2
0
@
−1
−1
√
2
1
1
√
2
√
2
−
√
2
0
1
A
53.
1
3
0
@
−1
2
2
2
−1
2
2
2
−1
1
A
54.
1
2
0
@
1
√
2
−1
√
2
0
√
2
1
−
√
2
−1
1
A
55.
1
9
0
@
−1
8
4
−4
−4
7
−8
1
−4
1
A
56.
1
2
√
2
0
@
2
√
2
√
2
−
√
2
1 +
√
2
1 −
√
2
−
√
2
1 −
√
2
1 +
√
2
1
A
57.
Show that if D is a diagonal matrix, then Dn is the diagonal matrix with elements
equal to the nth power of the elements of D. Also show that if D = C−1MC, then
Dn = C−1MnC, so Mn = CDnC−1. Hint: For n = 2, (C−1MC)2 = C−1MCC−1MC;
what is CC−1?
58.
Note in Section 6 [see (6.15)] that, for the given matrix A, we found A2 = −I, so it
was easy to ﬁnd all the powers of A. It is not usually this easy to ﬁnd high powers
of a matrix directly. Try it for the square matrix M in equation (11.1). Then use
the method outlined in Problem 57 to ﬁnd M4, M10, eM.
59.
Repeat the last part of Problem 58 for the matrix M =
„ 3
−1
−1
3
«
.
60.
The Caley-Hamilton theorem states that “A matrix satisﬁes its own characteristic
equation.” Verify this theorem for the matrix M in equation (11.1). Hint: Substitute
the matrix M for λ in the characteristic equation (11.4) and verify that you have a
correct matrix equation. Further hint: Don’t do all the arithmetic. Use (11.36) to
write the left side of your equation as C(D2 −7D + 6)C−1 and show that the paren-
thesis = 0. Remember that, by deﬁnition, the eigenvalues satisfy the characteristic
equation.

162
Linear Algebra
Chapter 3
61.
At the end of Section 9 we proved that if H is a Hermitian matrix, then the matrix
eiH is unitary. Give another proof by writing H = CDC−1, remembering that now
C is unitary and the eigenvalues in D are real. Show that eiD is unitary and that
eiH is a product of three unitary matrices. See Problem 9.17d.
62.
Show that if matrices F and G can be diagonalized by the same C matrix, then they
commute. Hint: Do diagonal matrices commute?
12. APPLICATIONS OF DIAGONALIZATION
We next consider some examples of the use of the diagonalization process. A central
conic section (ellipse or hyperbola) with center at the origin has the equation
(12.1)
Ax2 + 2Hxy + By2 = K,
where A, B, H and K are constants. In matrix form this can be written
(12.2)
x
y A
H
H
B
 x
y

= K
or
x
y
M
x
y

= K
if we call

A
H
H
B

= M
(as you can verify by multiplying out the matrices). We want to choose the principal
axes of the conic as our reference axes in order to write the equation in simpler form.
Consider Figure 11.2; let the axes (x′, y′) be rotated by some angle θ from (x, y).
Then the (x, y) and (x′, y′) coordinates of a point are related by (11.13) or (11.14):
(12.3)

x
y

=

cos θ
−sin θ
sin θ
cos θ
 
x′
y′

or

x
y

= C

x′
y′

.
By (9.11) the transpose of (12.3) is

x
y

=

x′
y′ 
cos θ
sin θ
−sin θ
cos θ

or
x
y
=
x′
y′
CT =
x′
y′
C−1
(12.4)
since C is an orthogonal matrix. Substituting (12.3) and (12.4) into (12.2), we get
(12.5)
x′
y′
C−1MC
x′
y′

= K.
If C is the matrix which diagonalizes M, then (12.5) is the equation of the conic
relative to its principal axes.
Example 1.
Consider the conic
(12.6)
5x2 −4xy + 2y2 = 30.
In matrix form this can be written
(12.7)
x
y  5
−2
−2
2
 x
y

= 30.

Section 12
Applications of Diagonalization
163
We have here the same matrix,
M =
 5
−2
−2
2

,
whose eigenvalues we found in Section 11. In that section we found a C such that
C−1MC = D =
1
0
0
6

.
Then the equation (12.5) of the conic relative to principal axes is
(12.8)
x′
y′ 1
0
0
6
 x′
y′

= x′2 + 6y′2 = 30.
Observe that changing the order of 1 and 6 in D would give 6x′2 + y′2 = 30 as the
new equation of the ellipse instead of (12.8). This amounts simply to interchanging
the x′ and y′ axes.
By comparing the matrix C of the unit eigenvectors in (11.10) with the rotation
matrix in (11.14), we see that the rotation angle θ (Figure 11.3) from the original
axes (x, y) to the principal axes (x′, y′) is
(12.9)
θ = arc cos 1
√
5 .
Notice that in writing the conic section equation in matrix form (12.2) and (12.7),
we split the xy term evenly between the two nondiagonal elements of the matrix;
this made M symmetric. Recall (end of Section 11) that M can be diagonalized
by a similarity transformation C−1MC with C an orthogonal matrix (that is, by
a rotation of axes) if and only if M is symmetric. We choose M symmetric (by
splitting the xy term in half) to make our process work.
Although for simplicity we have been working in two dimensions, the same ideas
apply to three (or more) dimensions (that is, three or more variables). As we have
said (Section 10), although we can represent only three coordinates in physical
space, it is very convenient to use the same geometrical terminology even though
the number of variables is greater than three. Thus if we diagonalize a matrix of
any order, we still use the terms eigenvalues, eigenvectors, principal axes, rotation
to principal axes, etc.
Example 2.
Rotate to principal axes the quadric surface
x2 + 6xy −2y2 −2yz + z2 = 24.
In matrix form this equation is
x
y
z


1
3
0
3
−2
−1
0
−1
1




x
y
z

= 24.
The characteristic equation of this matrix is

1 −λ
3
0
3
−2 −λ
−1
0
−1
1 −λ

= 0 = −λ3 + 13λ −12
= −(λ −1)(λ + 4)(λ −3).

164
Linear Algebra
Chapter 3
The characteristic values are
λ = 1,
λ = −4,
λ = 3.
Relative to the principal axes (x′, y′, z′) the quadric surface equation becomes

x′
y′
z′


1
0
0
0
−4
0
0
0
3




x′
y′
z′

= 24
or
x′2 −4y′2 + 3z′2 = 24.
From this equation we can identify the quadric surface (hyperboloid of one sheet)
and sketch its size and shape using (x′, y′, z′) axes without ﬁnding their relation to
the original (x, y, z) axes. However, if we do want to know the relation between the
two sets of axes, we ﬁnd the C matrix in the following way. Recall from Section 11
that C is the matrix whose columns are the components of the unit eigenvectors.
One of the eigenvectors can be found by substituting the eigenvalue λ = 1 into the
equations


1
3
0
3
−2
−1
0
−1
1




x
y
z

=


λx
λy
λz


and solving for x, y, z.
Then ix + jy + kz is an eigenvector corresponding to
λ = 1, and by dividing it by its magnitude we get a unit eigenvector (Problem 8).
Repeating this process for each of the other values of λ, we get the following three
unit eigenvectors:
 1
√
10
, 0,
3
√
10

when
λ = 1;
 −3
√
35,
5
√
35,
1
√
35

when
λ = −4;
 −3
√
14
, −2
√
14
,
1
√
14

when
λ = 3.
Then the rotation matrix C is
C =









1
√
10
−3
√
35
−3
√
14
0
5
√
35
−2
√
14
3
√
10
1
√
35
1
√
14









The numbers in C are the cosines of the nine angles between the (x, y, z) and
(x′, y′, z′) axes. (Compare Figure 11.3 and the discussion of it.)
A useful physical application of this method occurs in discussing vibrations. We
illustrate this with a simple problem.

Section 12
Applications of Diagonalization
165
Example 3.
Find the characteristic vibration frequencies for the system of masses and
springs shown in Figure 12.1.
Figure 12.1
Let x and y be the coordinates of the two masses at time t relative to their
equilibrium positions, as shown in Figure 12.1. We want to write the equations of
motion (mass times acceleration = force) for the two masses (see Chapter 2, end
of Section 16). We can just write the forces by inspection as we did in Chapter 2,
but for more complicated problems it is useful to have a systematic method. First
write the potential energy; for a spring this is V = 1
2ky2 where y is the compression
or extension of the spring from its equilibrium length. Then the force exerted on
a mass attached to the spring is −ky = −dV/dy. If V is a function of two (or
more) variables, say x and y as in Figure 12.1, then the forces on the two masses
are −∂V/∂x and −∂V/∂y (and so on for more variables). For Figure 12.1, the
extension or compression of the middle spring is x −y so its potential energy is
1
2k(x −y)2. For the other two springs, the potential energies are 1
2kx2 and 1
2ky2 so
the total potential energy is
(12.10)
V = 1
2kx2 + 1
2k(x −y)2 + 1
2ky2 = k(x2 −xy + y2).
In writing the equations of motion it is convenient to use a dot to indicate a time
derivative (as we often use a prime to mean an x derivative). Thus ˙x = dx/dt,
¨x = d2x/dt2, etc. Then the equations of motion are
(12.11)
 m¨x = −∂V/∂x = −2kx + ky,
m¨y = −∂V/∂y =
kx −2ky.
In a normal or characteristic mode of vibration, the x and y vibrations have the
same frequency. As in Chapter 2, equations (16.22), we assume solutions x = x0eiωt,
y = y0eiωt, with the same frequency ω for both x and y. [Or, if you prefer, we could
replace eiωt by sin ωt or cos ωt or sin(ωt + α), etc.] Note that (for any of these
solutions),
(12.12)
¨x = −ω2x,
and
¨y = −ω2y.
Substituting (12.12) into (12.11) we get (Problem 10)
(12.13)
 −mω2x = −2kx + ky,
−mω2y =
kx −2ky.
In matrix form these equations are
(12.14)
λ
x
y

=
 2
−1
−1
2
 x
y

with
λ = mω2
k
.
Note that this is an eigenvalue problem (see Section 11). To ﬁnd the eigenvalues λ,
we write
(12.15)

2 −λ
−1
−1
2 −λ
 = 0

166
Linear Algebra
Chapter 3
and solve for λ to ﬁnd λ = 1 or λ = 3. Thus [by the deﬁnition of λ in (12.14)] the
characteristic frequencies are
(12.16)
ω1 =

k
m
and
ω2 =

3k
m .
The eigenvectors (not normalized) corresponding to these eigenvalues are:
(12.17)
For λ = 1: y = x or r = (1, 1); for λ = 3: y = −x or r = (1, −1).
Thus at frequency ω1 (with y = x), the two masses oscillate back and forth to-
gether like this →→and then like this ←←. At frequency ω2 (with y = −x), they
oscillate in opposite directions like this ←→and then like this →←. These two
especially simple ways in which the system can vibrate, each involving just one
vibration frequency, are called the characteristic (or normal) modes of vibration;
the corresponding frequencies are called the characteristic (or normal) frequencies
of the system.
The problem we have just done shows an important method which can be used
in many diﬀerent applications. There are numerous examples of vibration problems
in physics—in acoustics: the vibrations of strings of musical instruments, of drum-
heads, of the air in organ pipes or in a room; in mechanics and its engineering ap-
plications: vibrations of mechanical systems all the way from the simple pendulum
to complicated structures like bridges and airplanes; in electricity: the vibrations of
radio waves, of electric currents and voltages as in a tuned radio; and so on. In such
problems, it is often useful to ﬁnd the characteristic vibration frequencies of the
system under consideration and the characteristic modes of vibration. More com-
plicated vibrations can then be discussed as combinations of these simpler normal
modes of vibration.
Example 4.
In Example 3 and Figure 12.1, the two masses were equal and all the spring
constants were the same. Changing the spring constants to diﬀerent values doesn’t
cause any problems but when the masses are diﬀerent, there is a possible diﬃculty
which we want to discuss. Consider an array of masses and springs as in Figure 12.1
but with the following masses and spring constants: 2k, 2m, 6k, 3m, 3k. We want
to ﬁnd the characteristic frequencies and modes of vibration. Following our work in
Example 3, we write the potential energy V , ﬁnd the forces, write the equations of
motion, and substitute ¨x = −ω2x, and ¨y = −ω2y, in order to ﬁnd the characteristic
frequencies. (Do the details: Problem 11.)
V = 1
22kx2 + 1
26k(x −y)2 + 1
23ky2 = 1
2k(8x2 −12xy + 9y2)
(12.18)
 2m¨x = −∂V/∂x,
3m¨y = −∂V/∂y,
or
 −2mω2x =
−k(8x −6y),
−3mω2y = −k(−6x + 9y).
(12.19)
Next divide each equation by its mass and write the equations in matrix form.
(12.20)
ω2
x
y

= k
m
 4
−3
−2
3
 x
y

.
With λ = mω2/k, the eigenvalues of the square matrix are λ = 1 and λ = 6. Thus
the characteristic frequencies of vibration are
(12.21)
ω1 =

k
m
and
ω2 =

6k
m .

Section 12
Applications of Diagonalization
167
The corresponding eigenvectors are:
(12.22)
For λ = 1: y = x or r = (1, 1); for λ = 6: 3y = −2x or r = (3, −2).
Thus at frequency ω1 the two masses oscillate back and forth together with equal
amplitudes like this ←←and then like this →→. At frequency ω2 the two masses
oscillate in opposite directions with amplitudes in the ratio 3 to 2 like this ←→and
then like this →←.
Now we seem to have solved the problem; where is the diﬃculty? Note that the
square matrix in (12.20) is not symmetric [and compare (12.14) where the square
matrix was symmetric]. In Section 11 we discussed the fact that (for real matri-
ces) only symmetric matrices have orthogonal eigenvectors and can be diagonalized
by an orthogonal transformation. Here note that the eigenvectors in Example 3
were orthogonal [dot product of (1, 1) and (1, −1) is zero] but the eigenvectors for
(12.20) are not orthogonal [dot product of (1, 1) and (3, −2) is not zero]. If we want
orthogonal eigenvectors, we can make the change of variables (also see Example 6)
(12.23)
X = x
√
2,
Y = y
√
3,
where the constants are the square roots of the numerical factors in the masses 2m
and 3m. (Note that geometrically this just amounts to diﬀerent changes in scale
along the two axes, not to a rotation.) Then (12.20) becomes
(12.24)
ω2

X
Y

= k
m

4
−
√
6
−
√
6
3
 
X
Y

.
By inspection we see that the characteristic equation for the square matrix in (12.24)
is the same as the characteristic equation for (12.20) so the eigenvalues and the char-
acteristic frequencies are the same as before (as they must be by physical reasoning).
However the (12.24) matrix is symmetric and so we know that its eigenvectors are
orthogonal. By direct substitution of (12.23) into (12.22), [or by solving for the
eigenvectors in the (12.24) matrix] we ﬁnd the eigenvectors in the X, Y coordi-
nates:
(12.25)
For λ = 1: R = (X, Y ) = (
√
2, −
√
3); for λ = 6: R = (3
√
2, 2
√
3 ).
As expected, these eigenvectors are orthogonal.
Example5.
Let’s consider a model of a linear triatomic molecule in which we approximate
the
forces
between
the
atoms
by
forces
due
to
springs
(Figure
12.2).
m
x
m
k
k
M
y
z
Figure 12.2
As in Example 3, let x, y, z be the coordinates of the three masses relative to their
equilibrium positions. We want to ﬁnd the characteristic vibration frequencies of

168
Linear Algebra
Chapter 3
the molecule. Following our work in Examples 3 and 4, we ﬁnd (Problem 12)
V = 1
2k(x −y)2 + 1
2k(y −z)2 = 1
2k(x2 + 2y2 + z2 −2xy −2yz),
(12.26)



m¨x = −∂V/∂x = −k(x −y),
M ¨y = −∂V/∂y = −k(2y −x −z),
m¨z = −∂V/∂z = −k(z −y),
or



−mω2x = −k(x −y),
−Mω2y = −k(2y −x −z),
−mω2z = −k(z −y).
(12.27)
We are going to consider several diﬀerent ways of solving this problem in order
to learn some useful techniques. First of all, if we add the three equations we get
(12.28)
m¨x + M ¨y + m¨z = 0.
Physically (12.28) says that the center of mass is at rest or moving at constant
speed (that is, has zero acceleration). Since we are just interested in vibrational
motion, let’s assume that the center of mass is at rest at the origin. Then we have
mx + My + mz = 0. Solving this equation for y gives
(12.29)
y = −m
M (x + z).
Substitute (12.29) into the second set of equations in (12.27) to get the x and z
equations
−mω2x = −k(1 + m
M )x −k m
M z,
−mω2z = −k m
M x −k(1 + m
M )z.
(12.30)
In matrix form equations (12.30) become [compare (12.14)]
(12.31)
λ
x
y

=
1 + m
M
m
M
m
M
1 + m
M
 x
y

with
λ = mω2
k
.
We solve this eigenvalue problem to ﬁnd
(12.32)
ω1 =

k
m,
ω2 =

k
m

1 + 2m
M

.
For ω1 we ﬁnd z = −x, and consequently by (12.29), y = 0. For ω2, we ﬁnd z = x
and so y = −2m
M x. Thus at frequency ω1, the central mass M is at rest and the
two masses m vibrate in opposite directions like this ←m M m→and then like
this m→M ←m.
At the higher frequency ω2, the central mass M moves in
one direction while the two masses m move in the opposite direction, ﬁrst like this
m→←M m→and then like this ←m M→←m.
Now suppose that we had not thought about eliminating the translational motion
and had set this problem up as a 3 variable problem. Let’s go back to the second set

Section 12
Applications of Diagonalization
169
of equations in (12.27), and divide the x and z equations by m and the y equation
by M. Then in matrix form these equations can be written as
(12.33)
ω2


x
y
z

= k
m


1
−1
0
−m
M
2m
M
−m
M
0
−1
1




x
y
z

.
With λ = mω2/k, the eigenvalues of the square matrix are λ = 0, 1, 1 + 2m
M , and
the corresponding eigenvectors are (check these)
For λ = 0, r = (1, 1, 1);
for λ = 1, r = (1, 0, −1);
for λ = 1 + 2m
M , r = (1, −2m
M , 1).
(12.34)
We recognize the λ = 0 solution as corresponding to translation both because ω = 0
(so there is no vibration), and because r = (1, 1, 1) says that any motion is the same
for all three masses. The other two modes of vibration are the same ones we had
above.
We note that the square matrix in (12.33) is not symmetric and so, as
expected, the eigenvectors in (12.34) are not an orthogonal set. However, the last
two (which correspond to vibrations) are orthogonal so if we are just interested in
modes of vibration we can ignore the translation eigenvector. If we want to consider
all motion of the molecule along its axis (both translation and vibration), and want
an orthogonal set of eigenvectors, we can make the change of variables discussed in
Example 4, namely
(12.35)
X = x,
Y = y

M
m ,
Z = z.
Then the eigenvectors become
(12.36)
(1,

M/m , 1),
(1, 0, −1),
(1, −2

m/M , 1)
which are an orthogonal set. The ﬁrst eigenvector (corresponding to translation)
may seem confusing, looking as if the central mass M doesn’t move with the others
(as it must for pure translation). But remember from Example 4 that changes of
variable like (12.23) and (12.35) correspond to changes of scale, so in the XY Z
system we are not using the same measuring stick to ﬁnd the position of the central
mass as for the other two masses. Their physical displacements are actually all the
same.
Example 6.
Let’s consider Example 4 again in order to illustrate a very compact form
for the eigenvalue equation. Satisfy yourself (Problem 13) that we can write the
potential energy V in (12.18) as
(12.37)
V = 1
2krTVr
where
V =

8
−6
−6
9

,
r =

x
y

,
rT =

x
y

.
Similarly the kinetic energy T = 1
2(2m ˙x2 + 3m ˙y2) can be written as
(12.38)
T = 1
2m˙rTT˙r
where
T =
2
0
0
3

,
˙r =
 ˙x
˙y

,
˙rT =
 ˙x
˙y
.

170
Linear Algebra
Chapter 3
(Notice that the T matrix is diagonal and is a unit matrix when the masses are equal;
otherwise T has the mass factors along the main diagonal and zeros elsewhere.) Now
using the matrices T and V, we can write the equations of motion (12.19) as
mω2
2
0
0
3
 x
y

= k
 8
−6
−6
9
 x
y

or
λTr = Vr
where
λ = mω2
k
.
(12.39)
We can think of (12.39) as the basic eigenvalue equation. If T is a unit matrix, then
we just have λr = Vr as in (12.14). If not, then we can multiply (12.39) by T−1 to
get
(12.40)
λr = T−1Vr =
1/2
0
0
1/3
  8
−6
−6
9

r =
 4
−3
−2
3
 x
y

as in (12.20). However, we see that this matrix is not symmetric and so the eigen-
vectors will not be orthogonal. If we want the eigenvectors to be orthogonal as in
(12.23), we choose new variables so that the T matrix is the unit matrix, that is
variables X and Y so that
(12.41)
T = 1
2(2m ˙x2 + 3m ˙y2) = 1
2m( ˙X2 + ˙Y 2).
But this means that we want X2 = 2x2 and Y 2 = 3y2 as in (12.23), or in matrix
form,
R =
X
Y

=
x
√
2
y
√
3

=
√
2
0
0
√
3
 x
y

= T1/2r
or
r = T−1/2R =

1/
√
2
0
0
1/
√
3
 
X
Y

.
(12.42)
Substituting (12.42) into (12.39), we get λTT−1/2R = VT−1/2R. Then multiplying
on the left by T−1/2 and noting that T−1/2TT−1/2 = I, we have
(12.43)
λR = T−1/2VT−1/2R
as the eigenvalue equation in terms of the new variables X and Y . Substituting the
numerical T−1/2 from (12.42) into (12.43) gives the result we had in (12.24).
We have simply demonstrated that (12.39) and (12.43) give compact forms of
the eigenvalue equations for Example 4. However, it is straightforward to show
that these equations are just a compact summary of the equations of motion for
any similar vibrations problem, in any number of variables, just by writing the
potential and kinetic energy matrices and comparing the equations of motion in
matrix form.
Example 7.
Find the characteristic frequencies and the characteristic modes of vibration
for the system of masses and springs shown in Figure 12.3, where the motion is
along a vertical line.
Let’s use the simpliﬁed method of Example 6 for this problem. We ﬁrst write the
expressions for the kinetic energy and the potential energy as in previous examples.

Section 12
Applications of Diagonalization
171
3k
k
m
4m
y
x
Figure 12.3
(Note carefully that we measure x and y from the equilibrium positions
of the masses when they are hanging at rest; then the gravitational
forces are already balanced and gravitational potential energy does not
come into the expression for V .)
T = 1
2m(4 ˙x2 + ˙y2),
V = 1
2k[3x2 + (x −y)2] = 1
2k(4x2 −2xy + y2).
(12.44)
The corresponding matrices are [see equations (12.37) and (12.38)]:
(12.45)
T =
4
0
0
1

,
V =
 4
−1
−1
1

.
As in equation (12.40), we ﬁnd T−1V and its eigenvalues and eigenvec-
tors.
T−1V =

1/4
0
0
1
 
4
−1
−1
1

=

1
−1/4
−1
1

,
λ = mω2
k
= 1
2, 3
2.
For ω =

k
2m, r = (1, 2);
for ω =

3k
2m, r = (1, −2).
(12.46)
As expected (since T−1V is not symmetric), the eigenvectors are not orthogonal.
If we want orthogonal eigenvectors, we make the change of variables X = 2x,
Y = y, to ﬁnd the eigenvectors R = (1, 1) and R = (1, −1) which are orthogonal.
Alternatively, we can ﬁnd the matrix T−1/2VT−1/2
(12.47)

1/2
0
0
1
 
4
−1
−1
1
 
1/2
0
0
1

=

1
−1/2
−1/2
1

,
and ﬁnd its eigenvalues and eigenvectors.
PROBLEMS, SECTION 12
1.
Verify that (12.2) multiplied out is (12.1).
Find the equations of the following conics and quadric surfaces relative to principal axes.
2.
2x2 + 4xy −y2 = 24
3.
8x2 + 8xy + 2y2 = 35
4.
3x2 + 8xy −3y2 = 8
5.
5x2 + 3y2 + 2z2 + 4xz = 14
6.
x2 + y2 + z2 + 4xy + 2xz −2yz = 12
7.
x2 + 3y2 + 3z2 + 4xy + 4xz = 60
8.
Carry through the details of Example 2 to ﬁnd the unit eigenvectors. Show that the
resulting rotation matrix C is orthogonal. Hint: Find CCT.
9.
For Problems 2 to 7, ﬁnd the rotation matrix C which relates the principal axes and
the original axes. See Example 2.
10.
Verify equations (12.13) and (12.14). Solve (12.15) to ﬁnd the eigenvalues and verify
(12.16). Find the corresponding eigenvectors as stated in (12.17).

172
Linear Algebra
Chapter 3
11.
Verify the details of Example 4, equations (12.18) to (12.25).
12.
Verify the details of Example 5, equations (12.26) to (12.36).
13.
Verify the details of Example 6, equations (12.37) to (12.43).
Find the characteristic frequencies and the characteristic modes of vibration for systems
of masses and springs as in Figure 12.1 and Examples 3, 4, and 6 for the following arrays.
14.
k, m, 2k, m, k
15.
5k, m, 2k, m, 2k
16.
4k, m, 2k, m, k
17.
3k, 3m, 2k, 4m, 2k
18.
2k, m, k, 5m, 10k
19.
4k, 2m, k, m, k
20.
Carry through the details of Example 7.
Find the characteristic frequencies and the characteristic modes of vibration as in Ex-
ample 7 for the following arrays of masses and springs, reading from top to bottom in a
diagram like Figure 12.3.
21.
3k, m, 2k, m
22.
4k, 3m, k, m
23.
2k, 4m, k, 2m
13. A BRIEF INTRODUCTION TO GROUPS
We will not go very far into group theory—there are whole books on the subject
as well as on its applications in physics. But since so many of the ideas we are
discussing in this chapter are involved, it is interesting to have a quick look at
groups.
Example 1.
Think about the four numbers ±1, ±i. Notice that no matter what products
and powers of them we compute, we never get any numbers besides these four.
This property of a set of elements with a law of combination is called closure. Now
think about these numbers written in polar form: eiπ/2, eiπ, e3iπ/2, e2iπ = 1, or the
corresponding rotations of a vector (in the xy plane with tail at the origin), or the
set of rotation matrices corresponding to these successive 90◦rotations of a vector
(Problem 1). Note also that these numbers are the four fourth roots of 1, so we
could write them as A, A2, A3, A4 = 1. All these sets are examples of groups, or
more precisely, they are all representations of the same group known as the cyclic
group of order 4. We will be particularly interested in groups of matrices, that is, in
matrix representations of groups, since this is very important in applications. Now
just what is a group?
Deﬁnition of a Group
A group is a set {A, B, C, · · · } of elements—which may
be numbers, matrices, operations (such as the rotations above)—together with a law
of combination of two elements (often called the “product” and written as AB—see
discussion below) subject to the following four conditions.
1. Closure: The combination of any two elements is an element of the group.
2. Associative law: The law of combination satisﬁes the associative law:
(AB)C = A(BC).
3. Unit element: There is a unit element I with the property that IA = AI = A
for every element of the group.

Section 13
A Brief Introduction to Groups
173
4. Inverses: Every element of the group has an inverse in the group; that is, for
any element A there is an element B such that AB = BA = I.
We can easily verify that these four conditions are satisﬁed for the set ±1, ±i
under multiplication.
1. We have already discussed closure.
2. Multiplication of numbers is associative.
3. The unit element is 1.
4. The numbers i and −i are inverses since their product is 1; −1 is its own
inverse, and 1 is its own inverse.
Thus the set ±1, ±i, under the operation of multiplication, is a group. The order
of a ﬁnite group is the number of elements in the group. When the elements of a
group of order n are of the form A, A2, A3, · · · , An = 1, it is called a cyclic group.
Thus the group ±1, ±i, under multiplication, is a cyclic group of order 4 as we
claimed above.
A subgroup is a subset which is itself a group. The whole group, or the unit
element, are called trivial subgroups; any other subgroup is called a proper subgroup.
The group ±1, ±i has the proper subgroup ±1.
Product, Multiplication Table
In the deﬁnition of a group and in the discus-
sion so far, we have used the term “product” and have written AB for the combi-
nation of two elements. However, terms like “product” or “multiplication” are used
here in a generalized sense to refer to whatever the operation is for combining group
elements. In applications, group elements are often matrices and the operation is
matrix multiplication. In general mathematical group theory, the operation might
be, for example, addition of two elements, and that sounds confusing to say “prod-
uct” when we mean sum! Look at one of the ﬁrst examples we discussed, namely
the rotation of a vector by angles π/2, π, 3π/2, 2π or 0. If the group elements are
rotation matrices, then we multiply them, but if the group elements are the angles,
then we add them. But the physical problem is exactly the same in both cases. So
remember that group multiplication refers to the law of combination for the group
rather than just to ordinary multiplication in arithmetic.
Multiplication tables for groups are very useful; equations (13.1), (13.2), and
(13.4) show some examples. Look at (13.1) for the group ±1, ±i. The ﬁrst column
and the top row (set oﬀby lines) list the group elements. The sixteen possible
products of these elements are in the body of the table. Note that each element of
the group appears exactly once in each row and in each column (Problem 3). At
the intersection of the row starting with i and the column headed by −i, you ﬁnd
the product (i)(−i) = 1, and similarly for the other products.
(13.1)
1
i
−1
−i
1
1
i
−1
−i
i
i
−1
−i
1
−1
−1
−i
1
i
−i
−i
1
i
−1

174
Linear Algebra
Chapter 3
In (13.2) below, note that you add the angles as we discussed above. However,
it’s not quite just adding—it’s really the familiar process of adding angles until
you get to 2π and then starting over again at zero. In mathematical language this
is called adding (mod 2π) and we write π/2 + 3π/2 ≡0 (mod 2π). Hours on an
ordinary clock add in a similar way. If it’s 10 o’clock and then 4 hours elapse, the
clock says it’s 2 o’clock. We write 10 + 4 ≡2 (mod 12). (See Problems 6 and 7 for
more examples.)
(13.2)
0
π/2
π
3π/2
0
0
π/2
π
3π/2
π/2
π/2
π
3π/2
0
π
π
3π/2
0
π/2
3π/2
3π/2
0
π/2
π
Two groups are called isomorphic if their multiplication tables are identical
except for the names we attach to the elements [compare (13.1) and (13.2)]. Thus
all the 4-element groups we have discussed so far are isomorphic to each other, that
is, they are really all the same group. However, there are two diﬀerent groups of
order 4, the cyclic group we have discussed, and another group called the 4’s group
(see Problem 4).
Symmetry Group of the Equilateral Triangle
Con-
sider three identical atoms at the corners of an equilateral
G
H
F
y
x
Figure 13.1
triangle in the xy plane, with the center of the triangle at the
origin as shown in Figure 13.1. What rotations and reﬂec-
tions of vectors in the xy plane (as in Section 7) will produce
an identical array of atoms? By considering Figure 13.1, we
see that there are three possible rotations: 0◦, 120◦, 240◦,
and three possible reﬂections, through the three lines F, G,
H (lines along the altitudes of the triangle). Think of mov-
ing just the triangle (that is, the atoms), leaving the axes and the lines F, G, H
ﬁxed in the background. As in Section 7, we can write a 2 by 2 rotation or reﬂection
matrix for each of these six transformations and set up a multiplication table to
show that they do form a group of order 6. This group is called the symmetry group
of the equilateral triangle. We ﬁnd (Problem 8)
(13.3)
Identity, 0◦rotation
I =
1
0
0
1

120◦rotation
A = 1
2
−1
−
√
3
√
3
−1

240◦rotation
B = 1
2
 −1
√
3
−
√
3
−1

Reﬂection through line F (y axis)
F =
−1
0
0
1

Reﬂection through line G
G = 1
2

1
−
√
3
−
√
3
−1

Reﬂection through line H
H = 1
2

1
√
3
√
3
−1


Section 13
A Brief Introduction to Groups
175
The group multiplication table is:
(13.4)
I
A
B
F
G
H
I
I
A
B
F
G
H
A
A
B
I
G
H
F
B
B
I
A
H
F
G
F
F
H
G
I
B
A
G
G
F
H
A
I
B
H
H
G
F
B
A
I
Note here that GF = A, but FG = B, not surprising since we know that matrices
don’t always commute. In group theory, if every two group elements commute, the
group is called Abelian. Our previous group examples have all been Abelian, but
the group in (13.4) is not Abelian.
This is just one example of a symmetry group. Group theory is so important in
applications because it oﬀers a systematic way of using the symmetry of a physical
problem to simplify the solution. As we have seen, groups can be represented by
sets of matrices, and this is widely used in applications.
Conjugate Elements, Class, Character
Two group elements A and B are
called conjugate elements if there is a group element C such that C−1AC = B.
By letting C be successively one group element after another, we can ﬁnd all the
group elements conjugate to A. This set of conjugate elements is called a class.
Recall from Section 11 that if A is a matrix describing a transformation (such as a
rotation or some sort of mapping of a space onto itself), then B = C−1AC describes
the same mapping but relative to a diﬀerent set of axes (diﬀerent basis). Thus all
the elements of a class really describe the same mapping, just relative to diﬀerent
bases.
Example 2.
Find the classes for the group in (13.3) and (13.4). We ﬁnd the elements
conjugate to F as follows [use (13.4) to ﬁnd inverses and products]:
(13.5)
I−1FI = F;
A−1FA = BFA = BH = G;
B−1FB = AFB = AG = H;
F−1FF = F;
G−1FG = GFG = GB = H;
H−1FH = HFH = HA = G.
Thus the elements F, G, and H are conjugate to each other and form one class. You
can easily show (Problem 12) that elements A and B are another class, and the unit
element I is a class by itself. Now notice what we observed above. The elements
F, G, and H all just interchange two atoms, that is, all of them do the same thing,
just seen from a diﬀerent viewpoint. The elements A and B rotate the atoms, A by
120◦and B by 240◦which is the same as 120◦looked at upside down. And ﬁnally
the unit element I leaves things unchanged so it is a class by itself. Notice that a
class is not a group (except for the class consisting of I) since a group must contain
the unit element. So a class is a subset of a group, but not a subgroup.

176
Linear Algebra
Chapter 3
Recall from (9.13) and Problem 11.10 that the trace of a matrix (sum of diagonal
elements) is not changed by a similarity transformation. Thus all the matrices of a
class have the same trace. Observe that this is true for the group (13.3): Matrix I
has trace = 2, A and B have trace = −1
2 −1
2 = −1, and F, G, and H have trace
= 0. In this connection, the trace of a matrix is called its character, so we see that
all matrices of a class have the same character. Also note that we could write the
matrices (13.3) in (inﬁnitely) many other ways by rotating the reference axes, that
is, by performing similarity transformations. But since similarity transformations
do not change the trace, that is, the character, we now have a number attached
to each class which is independent of the particular choice of coordinate system
(basis). Classes and their associated character are very important in applications
of group theory.
One more number is important here, and that is the dimension of a representa-
tion. In (13.3), we used 2 by 2 matrices (2 dimensions), but it would be possible
to work in 3 dimensions. Then, for example, the A matrix would describe a 120◦
rotation around the z axis and would be
(13.6)
A =


−1/2
−
√
3/2
0
√
3/2
−1/2
0
0
0
1

,
and the other matrices in (13.3) would have a similar form, called block diagonalized.
But now the traces of all the matrices are increased by 1. To avoid having any
ambiguity about character, we use what are called “irreducible representations” in
ﬁnding character; let’s discuss this.
Irreducible Representations
A 2-dimensional representation is called reducible
if all the group matrices can be diagonalized by the same unitary similarity transfor-
mation (that is, the same change of basis). For example, the matrices in Problem 1
and the matrices in Problem 4 both give 2-dimensional reducible representations
of their groups (see Problems 13, 15, and 16). On the other hand, the matrices in
(13.3) cannot be simultaneously diagonalized (see Problem 13), so (13.3) is called a
2-dimensional irreducible representation of the equilateral triangle symmetry group.
If a group of 3 by 3 matrices can all be either diagonalized or put in the form of
(13.6) (block diagonalized) by the same unitary similarity transformation, then the
representation is called reducible; if not, it is a 3-dimensional irreducible representa-
tion. For still larger matrices, imagine the matrices block diagonalized with blocks
along the main diagonal which are the matrices of irreducible representations.
Thus we see that any representation is made up of irreducible representations.
For each irreducible representation, we ﬁnd the character of each class. Such lists
are known as character tables, but their construction is beyond our scope.
Inﬁnite Groups
Here we survey some examples of inﬁnite groups as well as some
sets which are not groups.
(13.7)
(a) The set of all integers, positive, negative, and zero, under ordinary addition,
is a group. Proof : The sum of two integers is an integer. Ordinary addition
obeys the associative law. The unit element is 0. The inverse of the integer N
is −N since N + (−N) = 0.

Section 13
A Brief Introduction to Groups
177
(b) The same set under ordinary multiplication is not a group because 0 has no
inverse. But even if we omit 0, the inverses of the other integers are fractions
which are not in the set.
(c) Under ordinary multiplication, the set of all rational numbers except zero, is
a group. Proof : The product of two rational numbers is a rational number.
Ordinary multiplication is associative. The unit element is 1, and the inverse
of a rational number is just its reciprocal.
Similarly, you can show that the following sets are groups under ordinary mul-
tiplication (Problem 17): All real numbers except zero, all complex numbers
except zero, all complex numbers reiθ with r = 1.
(d) Ordinary subtraction or division cannot be group operations because they don’t
satisfy the associative law; for example, x−(y −z) ̸= (x−y)−z. (Problem 18.)
(e) The set of all orthogonal 2 by 2 matrices under matrix multiplication is a group
called O(2). If the matrices are required to be rotation matrices, that is, have
determinant +1, the set is a group called SO(2) (the S stands for special).
Similarly, the following sets of matrices are groups under matrix multiplication:
The set of all orthogonal 3 by 3 matrices, called O(3); its subgroup SO(3)
with determinant = 1; or the corresponding sets of orthogonal matrices of any
dimension n, called O(n) and SO(n). (Problem 19.)
(f) The set of all unitary n by n matrices, n = 1, 2, 3, · · ·, called U(n), is a group
under matrix multiplication, and its subgroup SU(n) of unitary matrices with
determinant = 1 is also a group. Proof : We have repeatedly noted that matrix
multiplication is associative and that the unit matrix is the unit element of a
group of matrices. So we just need to check closure and inverses. The product of
two unitary matrices is unitary (see Section 9). If two matrices have determinant
= 1, their product has determinant = 1 [see equation (6.6)]. The inverse of a
unitary matrix is unitary (see Problem 9.25).
PROBLEMS, SECTION 13
1.
Write the four rotation matrices for rotations of vectors in the xy plane through
angles 90◦, 180◦, 270◦, 360◦(or 0◦) [see equation (7.12)]. Verify that these 4 matrices
under matrix multiplication satisfy the four group requirements and are a matrix
representation of the cyclic group of order 4. Write their multiplication table and
compare with Equations (13.1) and (13.2).
2.
Following the text discussion of the cyclic group of order 4, and Problem 1, discuss
(a)
the cyclic group of order 3 (see Chapter 2, Problem 10.32);
(b)
the cyclic group of order 6.
3.
Show that, in a group multiplication table, each element appears exactly once in
each row and in each column. Hint: Suppose that an element appears twice, and
show that this leads to a contradiction, namely that two elements assumed diﬀerent
are the same element.
4.
Show that the matrices
I =
„1
0
0
1
«
,
A =
„0
1
1
0
«
,
B =
„
0
−1
−1
0
«
,
C =
„−1
0
0
−1
«
,

178
Linear Algebra
Chapter 3
under matrix multiplication, form a group. Write the group multiplication table to
see that this group (called the 4’s group) is not isomorphic to the cyclic group of
order 4 in Problem 1. Show that the 4’s group is Abelian but not cyclic.
5.
Consider the group of order 4 with unit element I and other elements A, B, C,
where AB = BA = C, and A2 = B2 = I. Write the group multiplication table and
verify that it is a group. There are two groups of order 4 (discussed in Problems 1
and 4). To which is this one isomorphic? Hint: Compare the multiplication tables.
6.
Consider the integers 0, 1, 2, 3 under addition (mod 4). Write the group “multipli-
cation” table and show that you have a group of order 4. Is this group isomorphic
to the cyclic group of order 4 or to the 4’s group?
7.
Consider the set of numbers 1, 3, 5, 7 with multiplication (mod 8) as the law of
combination.
Write the multiplication table to show that this is a group.
[To
multiply two numbers (mod 8), you multiply them and then take the remainder
after dividing by 8. For example, 5 × 7 = 35 ≡3(mod 8).] Is this group isomorphic
to the cyclic group of order 4 or to the 4’s group?
8.
Verify (13.3) and (13.4). Hints: For the rotation and reﬂection matrices, see Sec-
tion 7. In checking the multiplication table, be sure you are multiplying the matrices
in the right order. Remember that matrices are operators on the vectors in the plane
(Section 7), and matrices may not commute. GFA means apply A, then F, then G.
9.
Show that any cyclic group is Abelian. Hint: Does a matrix commute with itself?
10.
As we did for the equilateral triangle, ﬁnd the symmetry group of the square. Hints:
Draw the square with its center at the origin and its sides parallel to the x and y
axes. Find a set of eight 2 by 2 matrices (4 rotation and 4 reﬂection) which map the
square onto itself, and write the multiplication table to show that you have a group.
11.
Do Problem 10 for a rectangle. Note that now only two rotations and 2 reﬂections
leave the rectangle unchanged.
So you have a group of order 4.
To which is it
isomorphic, the cyclic group or the 4’s group?
12.
Verify (13.5) and then also show that A, B are the elements of a class, and that I is
a class by itself. Show that it will always be true in any group that I is a class by
itself. Hint: What is C−1IC for any element C of a group?
13.
Using the discussion of simultaneous diagonalization at the end of Section 11, show
that the 2-dimensional matrices in Problems 1 and 4 are reducible representations
of their groups, and the matrices in (13.5) give an irreducible representation of the
equilateral triangle symmetry group. Hint: Look at the multiplication tables to see
which matrices commute.
14.
Use the multiplication table you found in Problem 10 to ﬁnd the classes in the
symmetry group of a square.
Show that the 2 by 2 matrices you found are an
irreducible representation of the group (see Problem 13), and ﬁnd the character of
each class for that representation. Note that it is possible for the character to be
the same for two classes, but it is not possible for the character of two elements of
the same class to be diﬀerent.
15.
By Problem 13, you know that the matrices in Problem 4 are a reducible repre-
sentation of the 4’s group, that is they can all be diagonalized by the same unitary
similarity transformation (in this case orthogonal since the matrices are symmetric).
Demonstrate this directly by ﬁnding the matrix C and diagonalizing all 4 matrices.
16.
Do Problem 15 for the group of matrices you found in Problem 1. Be careful here—
you are working in a complex vector space and your C matrix will be unitary but

Section 14
General Vector Spaces
179
not orthogonal (see Sections 10 and 11). Comment: Not surprisingly, the numbers
1, i, −1, −i give a 1-dimensional representation—note that a single number can be
thought of as a 1-dimensional matrix.
17.
Verify that the sets listed in (13.7c) are groups.
18.
Show that division cannot be a group operation. Hint: See (13.7d).
19.
Verify that the sets listed in (13.7e) are groups. Hint: See the proofs in (13.7f).
20.
Is the set of all orthogonal 3-by-3 matrices with determinant = −1 a group? If so,
what is the unit element?
21.
Is the group SO(2) Abelian? What about SO(3)? Hint: See the discussion following
equation (6.14).
14. GENERAL VECTOR SPACES
In this section we are going to introduce a generalization of our picture of vector
spaces which is of great importance in applications. This will be merely an intro-
duction because the ideas here will be used in many of the following chapters as
you will discover. The basic idea will be to set up an outline of the requirements for
3-dimensional vector spaces (as we listed the requirements for a group), and then
show that these familiar 3-dimensional vector space requirements are satisﬁed by
sets of things like functions or matrices which we would not ordinarily think of as
vectors.
Deﬁnition of a Vector Space
A vector space is a set of elements {U, V, W, · · · }
called vectors, together with two operations: addition of vectors, and multiplication
of a vector by a scalar (which for our purposes will be a real or a complex number),
and subject to the following requirements:
1. Closure: The sum of any two vectors is a vector in the space.
2. Vector addition is:
(a) commutative: U + V = V + U,
(b) associative: (U + V) + W = U + (V + W).
3. (a) There is a zero vector 0 such that 0 + V = V + 0 = V for every element
V in the space.
(b) Every element V has an additive inverse (−V) such that V + (−V) = 0.
4. Multiplication of vectors by scalars has the expected properties:
(a) k(U + V) = kU + kV;
(b) (k1 + k2)V = k1V + k2V;
(c) (k1k2)V = k1(k2V);
(d) 0 · V = 0, and 1 · V = V.
You should go over these and satisfy yourself that they are all true for ordinary two
and three dimensional vector spaces. Now let’s look at some examples of things we
don’t usually think of as vectors which, nevertheless, satisfy the above requirements.

180
Linear Algebra
Chapter 3
Example 1.
Consider the set of polynomials of the third degree or less, namely functions
of the form f(x) = a0 + a1x + a2x2 + a3x3. Is this a vector space? If so, ﬁnd a
basis. What is the dimension of the space?
We go over the requirements listed above:
1. The sum of two polynomials of degree ≤3 is a polynomial of degree ≤3 and
so is a member of the set.
2. Addition of algebraic expressions is commutative and associative.
3. The “zero vector” is the polynomial with all coeﬃcients ai equal to 0, and
adding it to any other polynomial just gives that other polynomial.
The
additive inverse of a function f(x) is just −f(x), and −f(x) + f(x) = 0 as
required for a vector space.
4. All the listed familiar rules are just what we do every time we work with
algebraic expressions.
So we have a vector space! Now let’s try to ﬁnd a basis for it. Consider the set
of functions: {1, x, x2, x3}. They span the space since any polynomial of degree ≤3
is a linear combination of them. You can easily show (Problem 1) by computing
the Wronskian [equation (8.5)] that they are linearly independent. Therefore they
are a basis, and since there are 4 basis vectors, the dimension of the space is 4.
Example 2.
Consider the set of linear combinations of the functions
{eix, e−ix, sin x, cos x, x sin x}.
It is straightforward to verify that all our requirements above are met (Problem 1).
To ﬁnd a basis, we must ﬁnd a linearly independent set of functions which spans the
space. We note that the given functions are not linearly independent since eix and
e−ix are linear combinations of sin x and cos x (Chapter 2, Section 4). However, the
set {sin x, cos x, x sin x} is a linearly independent set and it spans the space. So
this is a possible basis and the dimension of the space is 3. Another possible basis
would be {eix, e−ix, x sin x}. You will meet sets of functions like these as solutions
of diﬀerential equations (see Chapter 8, Problems 5.13 to 5.18).
Example 3.
Modify Example 1 to consider the set of polynomials of degree ≤3 with
f(1) = 1. Is this a vector space? Suppose we add two of the polynomials; then the
value of the sum at x = 1 is 2, so it is not an element of the set. Thus requirement 1
is not satisﬁed so this is not a vector space. Note that a subset of the vectors of
a vector space is not necessarily a subspace. On the other hand, if we consider
polynomials of degree ≤3 with f(1) = 0, then the sum of two of them is zero at
x = 1; this is a vector space. You can easily verify (Problem 1) that it is a subspace
of dimension 3 and a possible basis is {x −1, x2 −1, x3 −1}.
Example 4.
Consider the set of all polynomials of any degree ≤N. The sum of two
polynomials of degree ≤N is another such polynomial, and you can easily verify
(Problem 1) that the rest of the requirements are met, so this is a vector space. A
simple choice of basis is the set of powers of x from x0 = 1 to xN. Thus we see that
the dimension of this space is N + 1.

Section 14
General Vector Spaces
181
Example 5.
Consider the set of all 2 by 3 matrices with matrix addition as the law of
combination, and multiplication by scalars deﬁned as in Section 6. Recall that you
add matrices by adding corresponding elements. Thus a sum of two 2 by 3 matrices
is another 2 by 3 matrix. For matrix addition and multiplication by scalars, it
is straightforward to show that the other requirements listed above are satisﬁed
(Problem 1). As a basis, we could use the six matrices:
1
0
0
0
0
0

,
0
1
0
0
0
0

,
0
0
1
0
0
0

,
0
0
0
1
0
0

,
0
0
0
0
1
0

,
0
0
0
0
0
1

.
Satisfy yourself that these are linearly independent and that they span the space
(that is, that you could write any 2 by 3 matrix as a linear combination of these
six). Since there are 6 basis vectors, the dimension of this space is 6.
Inner Product, Norm, Orthogonality
The deﬁnitions of these terms need to
be generalized when our “vectors” are functions, that is, we want to generalize
equations (10.1) to (10.3).
A natural generalization of a sum is an integral, so
we might reasonably replace  AiBi by

A(x)B(x) dx, and  A2
i by

[A(x)]2 dx.
However, in applications we frequently want to consider complex functions of the
real variable x (for example, eix as in Example 2). Thus, given functions A(x) and
B(x) on a ≤x ≤b, we deﬁne
[Inner Product of A(x) and B(x)]
=
 b
a
A∗(x)B(x) dx,
(14.1)
[Norm of A(x)] = ||A(x)|| =
 b
a
A∗(x)A(x) dx,
(14.2)
A(x) and B(x) are orthogonal on (a, b)
if
 b
a
A∗(x)B(x) dx = 0.
(14.3)
Let’s now generalize our deﬁnition (14.1) of inner product still further. Let A,
B, C, · · · be elements of a vector space, and let a, b, c, · · · be scalars. We will use
the bracket ⟨A|B⟩to mean the inner product of A and B. This vector space is called
an inner product space if an inner product is deﬁned subject to the conditions:
⟨A|B⟩∗= ⟨B|A⟩;
(14.4a)
⟨A|A⟩≥0,
⟨A|A⟩= 0 if and only if A = 0;
(14.4b)
⟨C|aA + bB⟩= a⟨C|A⟩+ b⟨C|B⟩.
(14.4c)
(See Problem 11.) It follows from (14.4) that (Problem 12)
⟨aA + bB|C⟩= a∗⟨A|C⟩+ b∗⟨B|C⟩,
and
(14.5a)
⟨aA|bB⟩= a∗b⟨A|B⟩.
(14.5b)
You will ﬁnd various other notations for the inner product, such as (A, B) or [A, B]
or ⟨A, B⟩. The notation ⟨A|B⟩is used in quantum mechanics. Most mathematics
books put the complex conjugate on the second factor in (14.1) and make the cor-
responding changes in (14.4) and (14.5). Most physics and mathematical methods

182
Linear Algebra
Chapter 3
books handle the complex conjugate as we have. If you are confused by this notation
and equations (14.4) and (14.5), keep going back to (14.1) where ⟨A|B⟩=

A∗B
until you get used to the bracket notation.
Also study carefully our use of the
bracket notation in the next section and do Problems 11 to 14.
Schwarz’s Inequality
In Section 10 we proved the Schwarz inequality for n-
dimensional Euclidean space. For an inner product space satisfying (14.4), it be-
comes [compare (10.9)]
(14.6)
|⟨A|B⟩|2 ≤⟨A|A⟩⟨B|B⟩.
To prove this, we ﬁrst note that it is true if B = 0. For B ̸= 0, let C = A −µB,
where µ = ⟨B|A⟩/⟨B|B⟩, and ﬁnd ⟨C|C⟩which is ≥0 by (14.4b). Using (14.4) and
(14.5), we write
(14.7)
⟨A −µB|A −µB⟩= ⟨A|A⟩−µ∗⟨B|A⟩−µ⟨A|B⟩+ µ∗µ⟨B|B⟩≥0.
Now substitute the values of µ and µ∗to get (see Problem 13)
⟨A|A⟩−⟨A|B⟩
⟨B|B⟩⟨B|A⟩−⟨B|A⟩
⟨B|B⟩⟨A|B⟩+ ⟨A|B⟩
⟨B|B⟩
⟨B|A⟩
⟨B|B⟩⟨B|B⟩
(14.8)
= ⟨A|A⟩−⟨A|B⟩⟨A|B⟩∗
⟨B|B⟩
= ⟨A|A⟩−|⟨A|B⟩|2
⟨B|B⟩
≥0
which gives (14.6).
For a function space as in (14.1) to (14.3), Schwarz’s inequality becomes (see
Problem 14):
(14.9)

 b
a
A∗(x)B(x) dx

2
≤
 b
a
A∗(x)A(x) dx
 b
a
B∗(x)B(x) dx

.
Orthonormal Basis; Gram-Schmidt Method
Two functions are called or-
thogonal if they satisfy (14.3); a function is normalized if its norm in (14.2) is 1.
By a combination of the two words, we call a set of functions orthonormal if they
are all mutually orthogonal and they all have norm 1. It is often convenient to
write the functions of a vector space in terms of an orthonormal basis (compare
writing ordinary vectors in three dimensions in terms of i, j, k). Let’s see how the
Gram-Schmidt method applies to a vector space of functions with inner product,
norm, and orthogonality deﬁned by (14.1) to (14.3). (Compare Section 10, Example
4 and the paragraph before it.)
Example 6.
In Example 1, we found that the set of all polynomials of degree ≤3 is a
vector space of dimension 4 with basis 1, x, x2, x3. Let’s consider these polynomials
on the interval −1 ≤x ≤1 and construct an orthonormal basis. To keep track of
what we’re doing, let f0, f1, f2, f3 = 1, x, x2, x3; let p0, p1, p2, p3 be a corresponding
orthogonal basis (which we ﬁnd by the Gram-Schmidt method); and let e0, e1, e2,
e3, be the orthonormal basis (which we get by normalizing the functions pi). Recall
the Gram-Schmidt routine (see Section 10, Example 4): Normalize the ﬁrst function

Section 14
General Vector Spaces
183
to get e0. Then for the rest of the functions, subtract from fi each preceding ej
multiplied by the inner product of ej and fi, that is, ﬁnd
(14.10)
pi = fi −

j<i
ej⟨ej|fi⟩= fi −

j<i
ej
 1
−1
ejfi dx.
Finally, normalize pi to get ei.
We can save eﬀort by noting in advance that many of the inner products we
need are going to be zero. You can easily show (Problem 15) that the integral of
an odd power of x from x = −1 to 1 is zero, and consequently any even power of x
is orthogonal to any odd power. Observe that the fi are alternately even and odd
powers of x. Then you can show that the corresponding pi and ei will also involve
just even or just odd powers of x. The Gram-Schmidt method gives the following
results (Problem 16).
f0 = 1 = p0,
||p0||2 =
 1
−1
12 dx = 2,
e0 =
1
√
2
.
f1 = x;
p1 = x
because x is orthogonal to e0.
||p1||2 =
 1
−1
x2 dx = 2
3,
e1 = x

3
2.
f2 = x2.
Since x2 is orthogonal to e1 but not to e0,
p2 = x2 −1
√
2
 1
−1
1
√
2 x2 dx = x2 −1
3.
||p2||2 =
 1
−1

x2 −1
3
2
dx = 8
45,
e2 = (3x2 −1)

5
8.
f3 = x3.
Since x3 is orthogonal to e0 and e2,
p3 = x3 −x

3
2
 1
−1
x

3
2 x3 dx = x3 −3
5x,
||p3||2 =
 1
−1

x3 −3
5x
2
dx =
8
175,
e3 = (5x3 −3x)

7
8.
This process could be continued for a vector space with basis 1, x, x2, · · · , xN
(but it is not very eﬃcient). The orthonormal functions ei are well-known functions
called (normalized) Legendre polynomials. In Chapters 12 and 13, we will discover
these functions as solutions of diﬀerential equations and see their applications in
physics problems.
Inﬁnite Dimensional Spaces
If a vector space does not have a ﬁnite basis, it
is called an inﬁnite dimensional vector space. It is beyond our scope to go into a
detailed mathematical study of such spaces. However, you should know that, by
analogy with ﬁnite dimensional vector spaces, we still use the term basis functions
for sets of functions (like xn or sin nx) in terms of which we can expand suitably
restricted functions in inﬁnite series. So far we have discussed only power series
(Chapter 1). In later chapters you will discover many other sets of functions which
provide useful bases in applications: sines and cosines in Chapter 7, various special
functions in Chapters 12 and 13. When we introduce them, we will discuss questions
of convergence of the inﬁnite series, and of completeness of sets of basis functions.

184
Linear Algebra
Chapter 3
PROBLEMS, SECTION 14
1.
Verify the statements indicated in Examples 1 to 5 above.
For each of the following sets, either verify (as in Example 1) that it is a vector space,
or show which requirements are not satisﬁed. If it is a vector space, ﬁnd a basis and the
dimension of the space.
2.
Linear combinations of the set of functions {ex, sinh x, xex}.
3.
Linear combinations of the set of functions {x, cos x, x cos x, ex cos x, (2−3ex) cos x,
x(1 + 5 cos x)}.
4.
Polynomials of degree ≤3 with a2 = 0.
5.
Polynomials of degree ≤5 with a1 = a3.
6.
Polynomials of degree ≤6 with a3 = 3.
7.
Polynomials of degree ≤7 with all the even coeﬃcients equal to each other and all
the odd coeﬃcients equal to each other.
8.
Polynomials of degree ≤7 but with all odd powers missing.
9.
Polynomials of degree ≤10 but with all even powers having positive coeﬃcients.
10.
Polynomials of degree ≤13, but with the coeﬃcient of each odd power equal to half
the preceding coeﬃcient of an even power.
11.
Verify that the deﬁnitions in (14.1) and (14.2) satisfy the requirements for an inner
product listed in (14.4) and (14.5). Hint: Write out all the equations (14.4) and
(14.5) in the integral notation of (14.1) and (14.2).
12.
Verify that the relations in (14.5) follow from (14.4). Hints: For (14.5a), take the
complex conjugate of (14.4c).
To take the complex conjugate of a bracket, use
(14.4a).
13.
Verify (14.7) and (14.8) Hints: Remember that a norm squared, like ⟨B|B⟩, is a
real and non-negative.scalar, so its complex conjugate is just itself. But ⟨B|A⟩is a
complex scalar and ⟨B|A⟩= ⟨A|B⟩∗by (14.4). Show that µ∗= ⟨A|B⟩/⟨B|B⟩.
14.
Verify that (14.9) is (14.6) with the deﬁnition of scalar product as in (14.1).
15.
For Example 6, verify the claimed orthogonality on (−1, 1) of an even power of x
and an odd power of x. Hint: For example, consider
R 1
−1 x2x3 dx.
16.
For Example 6, verify the details of the terms omitted in the functions pi because of
orthogonality. Hint: See Problem 15. Also verify the calculations of inner products
and norms and the orthonormal set ei.
15. MISCELLANEOUS PROBLEMS
1.
Show that if each element of one row (or column) of a determinant is the sum of two
terms, the determinant can be written as a sum of two determinants; for example,
˛˛˛˛˛˛
a11
a12 + b12
a13
a21
a22 + b22
a23
a31
a32 + b32
a33
˛˛˛˛˛˛
=
˛˛˛˛˛˛
a11
a12
a13
a21
a22
a23
a31
a32
a33
˛˛˛˛˛˛
+
˛˛˛˛˛˛
a11
b12
a13
a21
b22
a23
a31
b32
a33
˛˛˛˛˛˛
.
Use this result to verify Fact 4b of Section 3.

Section 15
Miscellaneous Problems
185
2.
What is wrong with the following argument? “If we add the ﬁrst row of a determi-
nant to the second row and the second row to the ﬁrst row, then the ﬁrst two rows
of the determinant are identical, and the value of the determinant is zero. Therefore
all determinants have the value zero.”
3.
(a)
Find the equations of the line through the points (4, −1, 2) and (3, 1, 4).
(b)
Find the equation of the plane through the points (0, 0, 0), (1, 2, 3) and (2, 1, 1).
(c)
Find the distance from the point (1, 1, 1) to the plane 3x −2y + 6z = 12.
(d)
Find the distance from the point (1, 0, 2) to the line r = 2i+j−k+(i−2j+2k)t.
(e)
Find the angle between the plane in (c) and the line in (d).
4.
Given the line r = 3i −j + (2i + j −2k)t:
(a)
Find the equation of the plane containing the line and the point (2, 1, 0).
(b)
Find the angle between the line and the (y, z) plane.
(c)
Find the perpendicular distance between the line and the x axis.
(d)
Find the equation of the plane through the point (2, 1, 0) and perpendicular to
the line.
(e)
Find the equations of the line of intersection of the plane in (d) and the plane
y = 2z.
5.
(a)
Write the equations of a straight line through the points (2, 7, −1) and (5, 7, 3).
(b)
Find the equation of the plane determined by the two lines r = (i −2j + k)t
and r = (6i −3j + 2k)t.
(c)
Find the angle which the line in (a) makes with the plane in (b).
(d)
Find the distance from (1, 1, 1) to the plane in (b).
(e)
Find the distance from (1, 6, −3) to the line in (a).
6.
Derive the formula
D = |ax0 + by0 + cz0 −d|
√
a2 + b2 + c2
for the distance from (x0, y0, z0) to ax + by + cz = d.
7.
Given the matrices A, B, C below, ﬁnd or mark as meaningless the matrices: AT,
A−1, AB, ¯A, ATBT, BTAT, BAT, ABC, ABTC, BTAC, A†, BTC, B−1C, C−1A,
CBT.
A =
„
1
−1
0
i
«
,
B =
„
2
1
−1
0
3
5
«
,
C =
„
0
1
−1
0
«
.
8.
Given
A =
0
@
1
0
2i
i
−3
0
1
0
i
1
A ,
ﬁnd AT, ¯A, A†, A−1.
9.
The following matrix product is used in discussing a thick lens in air:
A =
„1
(n −1)/R2
0
1
« „ 1
0
d/n
1
« „1
−(n −1)/R1
0
1
«
,
where d is the thickness of the lens, n is its index of refraction, and R1 and R2 are
the radii of curvature of the lens surfaces. It can be shown that element A12 of A is
−1/f where f is the focal length of the lens. Evaluate A and det A (which should
equal 1) and ﬁnd 1/f. [See Am. J. Phys. 48, 397–399 (1980).]

186
Linear Algebra
Chapter 3
10.
The following matrix product is used in discussing two thin lenses in air:
M =
„1
−1/f2
0
1
« „1
0
d
1
« „1
−1/f1
0
1
«
,
where f1 and f2 are the focal lengths of the lenses and d is the distance between
them. As in Problem 9, element M12 is −1/f where f is the focal length of the
combination. Find M, det M, and 1/f.
11.
There is a one-to-one correspondence between two-dimensional vectors and complex
numbers. Show that the real and imaginary parts of the product z1z∗
2 (the star
denotes complex conjugate) are respectively the scalar product and ± the magnitude
of the vector product of the vectors corresponding to z1 and z2.
12.
The vectors A = ai + bj and B = ci + dj form two sides of a parallelogram. Show
that the area of the parallelogram is given by the absolute value of the following
determinant. (Also see Chapter 6, Section 3.)
˛˛˛˛
a
b
c
d
˛˛˛˛ .
13.
The plane 2x+3y+6z = 6 intersects the coordinate axes at points P, Q, R, forming
a triangle. Find the vectors −−→
PQ and −→
PR. Write a vector formula for the area of the
triangle PQR, and ﬁnd the area.
In Problems 14 to 17, multiply matrices to ﬁnd the resultant transformation. Caution: Be
sure you are multiplying the matrices in the right order.
14.
x′ = (x + y
√
3)/2
y′ = (−x
√
3 + y)/2
x′′ = (−x′ + y′√
3)/2
y′′ = −(x′√
3 + y′)/2
15.
x′ = 2x + 5y
y′ =
x + 3y
x′′ =
x′ −2y′
y′′ = 3x′ −5y′
16.
8
<
:
x′ = (x + y
√
2 + z)/2
y′ = (x
√
2 −z
√
2)/2
z′ = (−x + y
√
2 −z)/2
8
<
:
x′′ = (x′√
2 + z′√
2)/2
y′′ = (−x′ −y′√
2 + z′)/2
z′′ = (x′ −y′√
2 −z′)/2
17.
8
<
:
x′ = (2x + y + 2z)/3
y′ = (x + 2y −2z)/3
z′ = (2x −2y −z)/3
8
<
:
x′′ = (2x′ + y′ + 2z′)/3
y′′ = (−x′ −2y′ + 2z′)/3
z′′ = (−2x′ + 2y′ + z′)/3
Find the eigenvalues and eigenvectors of the matrices in the following problems.
18.
„1
0
3
−2
«
19.
„5
1
4
2
«
20.
„ 5
−4
−4
5
«
21.
„4
2
2
1
«
22.
0
@
3
0
−2
0
4
0
−2
0
3
1
A
23.
0
@
3
0
1
0
3
1
1
1
2
1
A
24.
0
@
2
−3
4
−3
2
0
4
0
2
1
A
25.
Find the C matrix which diagonalizes the matrix M of Problem 18. Observe that M
is not symmetric, and C is not orthogonal (see Section 11). However, C does have
an inverse; ﬁnd C−1 and show that C−1MC = D.
26.
Repeat Problem 25 for Problem 19.
In Problems 27 to 30, rotate the given quadric surface to principal axes. What is the name
of the surface? What is the shortest distance from the origin to the surface?

Section 15
Miscellaneous Problems
187
27.
x2 + y2 −5z2 + 4xy = 15
28.
7x2 + 4y2 + z2 −8xz = 36
29.
3x2 + 5y2 −3z2 + 6yz = 54
30.
7x2 + 7y2 + 7z2 + 10xz −24yz = 20
31.
Find the characteristic vibration frequencies of a system of masses and springs as in
Figure 12.1 if the spring constants are k, 3k, k.
32.
Do Problem 31 if the spring constants are 6k, 2k, 3k.
33.
Prove the Caley-Hamilton theorem (Problem 11.60) for any matrix M for which
D = C−1MC is diagonal. See hints in Problem 11.60.
34.
In problems 6.30 and 6.31, you found the matrices eA and eC (put k = 1) where A
and C are the Pauli matrices from Problem 6.6. Now ﬁnd the matrix (A+C) and its
powers and so ﬁnd the matrix eA+C to show that eA+C ̸= eAeC. See Problem 6.29.
35.
Show that a square matrix A has an inverse if and only if λ = 0 is not an eigenvalue
of A.
Hint:
Write the condition for A to have an inverse (Section 6), and the
condition for A to have the eigenvalue λ = 0 (Section 11).
36.
Write the three 3 by 3 matrices for 180◦rotations about the x, y, z axes. Show that
these three matrices commute (contrary to what we usually expect—see Problems
7.30 and 7.31). By writing the multiplication table, show that these three matrices
with the unit matrix form a group. To which order 4 group is it isomorphic? Hint:
See Problem 13.5.
37.
Show that for a given irreducible representation of a group, the character of the class
consisting of the identity is always the dimension of the irreducible representation.
Hint: What is the trace of a unit n-by-n matrix?
38.
For a cyclic group, show that every element is a class by itself. Show this also for
an Abelian group.

C H A P T E R 4
Partial Differentiation
1. INTRODUCTION AND NOTATION
If y = f(x), then dy/dx can be thought of either as the slope of the curve y = f(x) or
as the rate of change of y with respect to x. Rates occur frequently in physics; time
rates such as velocity, acceleration, and rate of cooling of a hot body are obvious
examples. There are also other rates: rate of change of volume of a gas with applied
pressure, rate of decrease of the fuel in your automobile tank with distance traveled,
and so on. Equations involving rates (diﬀerential equations) often need to be solved
in applied problems. Derivatives are also used in ﬁnding maximum and minimum
points of a curve and in ﬁnding the power series of a function. All these applications,
and more, occur also when we consider a function of several variables.
Figure 1.1
Let z be a function of two variables x and y; we write z = f(x, y). Just as we
think of y = f(x) as a curve in two dimensions, so it is useful to interpret z = f(x, y)
geometrically. If x, y, z are rectangular coordinates, then for each x, y the equation
gives us a value of z, and so determines a point (x, y, z) in three dimensions. All
the points satisfying the equation ordinarily form a surface in three-dimensional
space (see Figure 1.1). (It might happen that an equation would not be satisﬁed
by any real points, for example x2 + y2 + z2 = −1, but we shall be interested
in equations whose graphs are real surfaces.) Now suppose x is constant; think
of a plane x = const. intersecting the sur-
face (see Figure 1.1). The points satisfying
z = f(x, y) and x = const. then lie on a
curve (the curve of intersection of the sur-
face and the x = const. plane; this is AB
in Figure 1.1). We might want the slope,
maximum and minimum points, etc., of this
curve. Since z is a function of y (on this
curve), we might write dz/dy for the slope.
However, to show that z is actually a func-
tion of two variables x and y with one of
them (x) temporarily a constant, we write
∂z/∂y; we call ∂z/∂y the partial derivative
of z with respect to y. Similarly, we can
188

Section 1
Introduction and Notation
189
hold y constant and ﬁnd ∂z/∂x, the partial derivative of z with respect to x. If
these partial derivatives are diﬀerentiated further, we write
∂
∂x
∂z
∂x = ∂2z
∂x2 ,
∂
∂x
∂z
∂y = ∂2z
∂x∂y,
∂
∂x
∂2z
∂x∂y =
∂3z
∂x2∂y ,
etc.
Other notations are often useful. If z = f(x, y), we may use zx or fx or f1 for
∂f/∂x, and corresponding notations for the higher derivatives.
Example.
Given z = f(x, y) = x3y −exy, then
∂f
∂x ≡∂z
∂x ≡fx ≡zx ≡f1 = 3x2y −yexy,
∂f
∂y ≡∂z
∂y ≡fy ≡zy ≡f2 = x3 −xexy,
∂2f
∂x ∂y ≡
∂2z
∂x ∂y ≡fyx ≡zyx ≡f21 = 3x2 −exy −xyexy,
∂2f
∂x2 ≡∂2z
∂x2 ≡fxx ≡zxx ≡f11 = 6xy −y2exy,
∂3f
∂y3 ≡∂3z
∂y3 ≡fyyy ≡zyyy ≡f222 = −x3exy,
∂3f
∂x2 ∂y ≡
∂3z
∂x2 ∂y ≡fyxx ≡zyxx ≡f211 = 6x −2yexy −xy2exy.
We can also consider functions of more variables than two, although in this case
it is not so easy to give a geometrical interpretation. For example, the temperature
T of the air in a room might depend on the point (x, y, z) at which we measured it
and on the time t; we would write T = T (x, y, z, t). We could then ﬁnd, say, ∂T/∂y,
meaning the rate at which T is changing with y for ﬁxed x and z at one instant of
time t.
A notation which is frequently used in applications (particularly thermodynam-
ics) is (∂z/∂x)y, meaning ∂z/∂x when z is expressed as a function of x and y. (Note
two diﬀerent uses of the subscript y; in the example above, fy meant ∂f/∂y. A
subscript on a partial derivative, however, does not mean another derivative, but
just indicates the variable being held constant in the indicated partial diﬀerentia-
tion.) For example, let z = x2 −y2. Then using polar coordinates r and θ, (recall
that x = r cos θ, y = r sin θ, x2 + y2 = r2), we can write z in several other ways.
For each new expression let us ﬁnd ∂z/∂r.
z = x2 −y2,
z = r2 cos2 θ −r2 sin2 θ,
∂z
∂r

θ
= 2r(cos2 θ −sin2 θ),
z = 2x2 −x2 −y2 = 2x2 −r2,
∂z
∂r

x
= −2r,
z = x2 + y2 −2y2 = r2 −2y2,
∂z
∂r

y
= +2r.
These three expressions for ∂z/∂r have diﬀerent values and are derivatives of three
diﬀerent functions, so we distinguish them as indicated by writing the second inde-
pendent variable as a subscript. Note that we do not write z(x, y) or z(r, θ); z is

190
Partial Differentiation
Chapter 4
one variable, but it is equal to several diﬀerent functions. Pure mathematics books
usually avoid the subscript notation by writing, say, z = f(r, θ) = g(r, x) = h(r, y),
etc.; then (∂z/∂r)θ can be written as just ∂f/∂r, and similarly
∂z
∂r

x
= ∂g
∂r
and
∂z
∂r

y
= ∂h
∂r .
However, this multiplicity of notation (z = f = g = h, etc.) would be inconve-
nient and confusing in applications where the letters have physical meanings. For
example, in thermodynamics, we might need
∂T
∂p

v
,
∂T
∂v

s
,
∂T
∂p

u
,
∂T
∂s

p
,
etc.,
as well as many other similar partial derivatives. Now T means temperature (and
the other letters similarly have physical meanings which must be recognized). If we
wrote T = A(p, v) = B(v, s) = C(p, u) = D(s, p) and similar formulas for the eight
commonly used quantities in thermodynamics, each as functions of pairs from the
other seven, we would not only have an unwieldy system, but the physical meaning
of equations would be lost until we translated them back to standard letters. Thus
the subscript notation is essential.
The symbol (∂z/∂r)x is usually read “the partial of z with respect to r, with x
held constant.” However, the important point to understand is that the notation
means that z has been written as a function of the variables r and x only, and
then diﬀerentiated with respect to r.
A little experimenting with various functions f(x, y) will probably convince you
that (∂/∂x)(∂f/∂y) = (∂/∂y)(∂f/∂x); this is usually (but not always) true in
applied problems. It can be proved (see advanced calculus texts) that if the ﬁrst and
second order partial derivatives of f are continuous, then ∂2f/∂x ∂y and ∂2f/∂y ∂x
are equal. In many applied problems, these conditions are met; for example, in
thermodynamics they are normally assumed and are called the reciprocity relations.
PROBLEMS, SECTION 1
1.
If u = x2/(x2 + y2), ﬁnd ∂u/∂x, ∂u/∂y.
2.
If s = tu, ﬁnd ∂s/∂t, ∂s/∂u.
3.
If z = ln
√
u2 + v2 + w2, ﬁnd ∂z/∂u, ∂z/∂v, ∂z/∂w.
4.
For w = x3 −y3 −2xy + 6, ﬁnd ∂2w/∂x2 and ∂2w/∂y2 at the points where
∂w/∂x = ∂w/∂y = 0.
5.
For w = 8x4 + y4 −2xy2, ﬁnd ∂2w/∂x2 and ∂2w/∂y2 at the points where
∂w/∂x = ∂w/∂y = 0.
6.
For u = ex cos y,
(a)
verify that ∂2u/∂x∂y = ∂2u/∂y∂x;
(b)
verify that ∂2u/∂x2 + ∂2u/∂y2 = 0.

Section 2
Power Series in Two Variables
191
If z = x2 + 2y2, x = r cos θ, y = r sin θ, ﬁnd the following partial derivatives.
7.
„ ∂z
∂x
«
y
8.
„ ∂z
∂x
«
r
9.
„ ∂z
∂x
«
θ
10.
„∂z
∂y
«
x
11.
„∂z
∂y
«
r
12.
„∂z
∂y
«
θ
13.
„∂z
∂θ
«
x
14.
„∂z
∂θ
«
y
15.
„∂z
∂θ
«
r
16.
„∂z
∂r
«
θ
17.
„∂z
∂r
«
x
18.
„∂z
∂r
«
y
19.
∂2z
∂r ∂y
20.
∂2z
∂x ∂θ
21.
∂2z
∂y ∂θ
22.
∂2z
∂r ∂x
23.
∂2z
∂r ∂θ
24.
∂2z
∂x ∂y
7 ′ to 24′.
Repeat Problems 7 to 24 if z = r2 tan2 θ.
2. POWER SERIES IN TWO VARIABLES
Just as in the one-variable case discussed in Chapter 1, the power series (about a
given point) for a function of two variables is unique, and we may use any convenient
method of ﬁnding it (see Chapter 1 for methods).
Example1.
Expand f(x, y) = sin x cos y in a two-variable Maclaurin series. We write and
multiply the series for sin x and cos y. This gives
sin x cos y =

x −x3
3! + · · ·
 
1 −y2
2! + · · ·

= x −x3
3! −xy2
2! + · · · .
Example 2.
Find the two-variable Maclaurin series for ln(1 + x −y). We replace x in
equation (13.4) of Chapter 1 by x −y to get
ln(1 + x −y) = (x −y) −(x −y)2/2 + (x −y)3/3 + · · ·
= x −y −x2/2 + xy −y2/2 + x3/3 −x2y + xy2 −y3/3 + · · · .
The methods of Chapter 1, used as we have just shown, provide an easy way
of obtaining the power series for many simple functions f(x, y).
However, it is
also convenient, for theoretical purposes, to have formulas for the coeﬃcients in
the Taylor series or the Maclaurin series for f(x, y); see, for example, Problem 8.2.
Following a process similar to that used in Chapter 1, Section 12, we can ﬁnd the
coeﬃcients of the power series for a function of two variables f(x, y) (assuming that
it can be expanded in a power series). To ﬁnd the series expansion of f(x, y) about
the point (a, b) we write f(x, y) as a series of powers of (x−a) and (y −b) and then
diﬀerentiate this equation repeatedly as follows.
f(x, y) = a00 + a10(x −a) + a01(y −b) + a20(x −a)2 + a11(x −a)(y −b)
+ a02(y −b)2 + a30(x −a)3 + a21(x −a)2(y −b)
+ a12(x −a)(y −b)2 + a03(y −b)3 + · · · .
fx = a10 + 2a20(x −a) + a11(y −b) + · · · ,
fy = a01 + a11(x −a) + 2a02(y −b) + · · · ,
fxx = 2a20 + terms containing (x −a) and/or (y −b),
fxy = a11 + terms containing (x −a) and/or (y −b).
(2.1)
[We have written only a few derivatives to show the idea. You should be able to
calculate others in the same way (Problem 7).] Now putting x = a, y = b in (2.1),

192
Partial Differentiation
Chapter 4
we get
f(a, b) = a00,
fx(a, b) = a10,
fy(a, b) = a01,
fxx(a, b) = 2a20,
fxy(a, b) = a11,
etc.
(2.2)
[Remember that fx(a, b) means that we are to ﬁnd the partial derivative of f with
respect to x and then put x = a, y = b, and similarly for the other derivatives.]
Substituting the values for the coeﬃcients into (2.1), we ﬁnd
f(x, y) = f(a, b) + fx(a, b)(x −a) + fy(a, b)(y −b)
+ 1
2![fxx(a, b)(x −a)2 + 2fxy(a, b)(x −a)(y −b) + fyy(a, b)(y −b)2] · · · .
(2.3)
This can be written in a simpler form if we put x −a = h and y −b = k. Then the
second-order terms (for example) become
(2.4)
1
2![fxx(a, b)h2 + 2fxy(a, b)hk + fyy(a, b)k2].
We can write this in the form
(2.5)
1
2!

h ∂
∂x + k ∂
∂y
2
f(a, b)
if we understand that the parenthesis is to be squared and then a term of the form
h(∂/∂x)k(∂/∂y)f(a, b) is to mean hkfxy(a, b). It can be shown (Problem 7) that
the third-order terms can be written in this notation as
(2.6)
1
3!

h ∂
∂x + k ∂
∂y
3
f(a, b) = 1
3![h3fxxx(a, b) + 3h2kfxxy(a, b) + · · · ]
and so on for terms of any order. Thus we can write the series (2.3) in the form
(2.7)
f(x, y) =
∞

n=0
1
n!

h ∂
∂x + k ∂
∂y
n
f(a, b).
The numbers appearing in the nth order terms are the familiar binomial coeﬃcients
[in the expansion of (p + q)n] divided by (n!). (See Chapter 1, Section 13C.)
PROBLEMS, SECTION 2
Find the two-variable Maclaurin series for the following functions.
1.
cos x sinh y
2.
cos(x + y)
3.
ln(1 + x)
1 + y
4.
exy
5.
p
1 + xy
6.
ex+y
7.
Verify the coeﬃcients of the third-order terms [(2.6) or n = 3 in (2.7)] of the power
series for f(x, y) by ﬁnding the third-order partial derivatives in (2.1) and substi-
tuting x = a, y = b.
8.
Find the two-variable Maclaurin series for ex cos y and ex sin y by ﬁnding the series
for ez = ex+iy and taking real and imaginary parts. (See Chapter 2.)

Section 3
Total Differentials
193
3. TOTAL DIFFERENTIALS
The graph (Figure 3.1) of the equation y = f(x) is a curve in the (x, y) plane and
(3.1)
y′ = dy
dx = d
dxf(x)
is the slope of the tangent to the curve at the point (x, y). In calculus, we use ∆x to
mean a change in x, and ∆y means the corresponding change in y (see Figure 3.1).
By deﬁnition
(3.2)
dy
dx = lim
∆x→0
∆y
∆x.
Figure 3.1
We shall now deﬁne the diﬀerential dx of the independent variable as
(3.3)
dx = ∆x.
However, dy is not the same as ∆y. From Figure 3.1 and equation (3.1), we can
see that ∆y is the change in y along the curve, but dy = y′dx is the change in
y along the tangent line. We say that dy is the tangent approximation (or linear
approximation) to ∆y.
Example.
If y = f(t) represents the distance a particle has gone as a function of t, then
dy/dt is the speed. The actual distance the particle has gone between time t and
time t + dt is ∆y. The tangent approximation dy = (dy/dt)dt is the distance it
would have gone if it had continued with the same speed dy/dt which it had at
time t.
You can see from the graph (Figure 3.1) that dy is a good approximation to
∆y if dx is small. We can say this more exactly using (3.2). Saying that dy/dx is
the limit of ∆y/∆x as ∆x →0 means that the diﬀerence ∆y/∆x −dy/dx →0 as
∆x →0. Let us call this diﬀerence ϵ; then we can say
(3.4)
∆y
∆x = dy
dx + ϵ,
where ϵ →0
as
∆x →0,
or since dx = ∆x
(3.5)
∆y = (y′ + ϵ)dx,
where ϵ →0
as
∆x →0.

194
Partial Differentiation
Chapter 4
The diﬀerential dy = y′dx is called the principal part of ∆y; since ϵ is small for
small dx, you can see from (3.5) that dy is then a good approximation to ∆y.
In our example, suppose y = t2, t = 1, dt = 0.1. Then
∆y = (1.1)2 −12 = 0.21,
dy = dy
dt dt = 2 · 1 · (0.1) = 0.2,
ϵ = ∆y
∆t −dy
dt = 2.1 −2 = 0.1,
∆y = (y′ + ϵ)dt = (2 + 0.1)(0.1) = dy + ϵdt = 0.2 + 0.01.
Thus dy is a good approximation to ∆y.
For a function of two variables, z = f(x, y), we want to do something similar to
this. We have said that this equation represents a surface and that the derivatives
∂f/∂x, ∂f/∂y, at a point, are the slopes of the two tangent lines to the surface
in the x and y directions at that point.
The symbols ∆x = dx and ∆y = dy
represent changes in the independent variables x and y. The quantity ∆z means
the corresponding change in z along the surface. We deﬁne dz by the equation
(3.6)
dz = ∂z
∂x dx + ∂z
∂y dy.
Figure 3.2
The diﬀerential dz is called the total diﬀerential of z. Let us consider the geometrical
meaning of dz. Recall (Figure 3.1) that for y = f(x), dy was the change in y along
the tangent line; here we shall see that dz is the change in z along the tangent plane.
In Figure 3.2, PQRS is a surface, PABC is the plane tangent to the surface at P,
and PDEF is a horizontal plane through P. Thus PSCF is the plane y = const.
(through P), PS is the curve of intersection of this plane with the surface, and
PC is the tangent line to this curve and so has the slope ∂f/∂x; then (just as in
Figure 3.1), if PF = dx, we have CF = (∂f/∂x) dx. Similarly, PQAD is a plane
x = const., intersecting the surface in the curve PQ, whose tangent is PA; with

Section 3
Total Differentials
195
PD = dy, we have DA = (∂f/∂y) dy. From the ﬁgure, GE = CF, and BG = AD,
so
EB = CF + DA = ∂f
∂x dx + ∂f
∂y dy = dz.
Thus, as we said, dz is the change in z along the tangent plane when x changes by
dx and y by dy. In the ﬁgure, ER = ∆z, the change in z along the surface.
From the geometry, we can reasonably expect dz to be a good approximation
to ∆z if dx and dy are small. However, we should like to say this more accurately
in an equation corresponding to (3.5). We can do this if ∂f/∂x and ∂f/∂y are
continuous functions. By deﬁnition
(3.7)
∆z = f(x + ∆x, y + ∆y) −f(x, y).
By adding and subtracting a term, we get
(3.8)
∆z = f(x + ∆x, y) −f(x, y) + f(x + ∆x, y + ∆y) −f(x + ∆x, y).
Recall from calculus that the mean value theorem (law of the mean) says that for
a diﬀerentiable function f(x),
(3.9)
f(x + ∆x) −f(x) = (∆x)f ′(x1),
where x1 is between x and x + ∆x. Geometrically this says (Figure 3.3) that there
is a tangent line somewhere between x and x + ∆x which has the same slope as the
Figure 3.3
line AB. In the ﬁrst two terms of the right side of (3.8), y is constant, and we can
use (3.9) if we write ∂f/∂x for f ′. In the last two terms of (3.8), x is constant and
we can use an equation like (3.9) with y as the variable; y1 will mean a value of y
between y and y + ∆y. Then (3.8) becomes
(3.10)
∆z = ∂f(x1, y)
∂x
∆x + ∂f(x + ∆x, y1)
∂y
∆y.
If the partial derivatives of f are continuous, then their values in (3.10) at points
near (x, y) diﬀer from their values at (x, y) by quantities which approach zero as
∆x and ∆y approach zero. Let us call these quantities ϵ1 and ϵ2. Then we can
write
∆z =
∂f
∂x + ϵ1

∆x +
∂f
∂y + ϵ2

∆y = dz + ϵ1 ∆x + ϵ2 ∆y
(ϵ1 and ϵ2 →0 as ∆x and ∆y →0),
(3.11)
where ∂f/∂x and ∂f/∂y in (3.11) are evaluated at (x, y). Equation (3.11) [like (3.5)
for the y = f(x) case] tells us algebraically what we suspected from the geometry,

196
Partial Differentiation
Chapter 4
that (if ∂f/∂x and ∂f/∂y are continuous ) dz is a good approximation to ∆z for
small dx and dy. The diﬀerential dz is called the principal part of ∆z.
Everything we have said about functions of two variables works just as well for
functions of any number of variables. if u = f(x, y, z, · · ·), then by deﬁnition
(3.12)
du = ∂f
∂x dx + ∂f
∂y dy + ∂f
∂z dz + · · ·
and du is a good approximation to ∆u if the partial derivatives of f are continuous
and dx, dy, dz, etc., are small.
PROBLEMS, SECTION 3
1.
Consider a function f(x, y) which can be expanded in a two-variable power series,
(2.3) or (2.7). Let x −a = h = ∆x, y −b = k = ∆y; then x = a + ∆x, y = b + ∆y
so that f(x, y) becomes f(a + ∆x, b + ∆y). The change ∆z in z = f(x, y) when x
changes from a to a + ∆x and y changes from b to b + ∆y is then
∆z = f(a + ∆x, b + ∆y) −f(a, b).
Use the series (2.7) to obtain (3.11) and to see explicitly what ϵ1 and ϵ2 are and
that they approach zero as ∆x and ∆y →0.
4. APPROXIMATIONS USING DIFFERENTIALS
Let’s consider some examples.
Example 1.
Find approximately the value of
1
√
0.25 −10−20 −
1
√
0.25.
If f(x) = 1/√x, the desired diﬀerence is ∆f = f(0.25 −10−20) −f(0.25). But ∆f
is approximately df = d(1/√x) with x = 0.25 and dx = −10−20.
d(1/√x) = (−1/2)x−3/2dx = (−1/2)(0.25)−3/2(−10−20) = 4 × 10−20.
Now why not just use a computer or calculator for a problem like this? First
note that we are subtracting two numbers which are almost equal to each other. If
your calculator or computer isn’t carrying enough digits, you may lose all accuracy
in the subtraction (see Chapter 1, Section 15, Example 1). So it may take you more
time to check on this and to type the problem into the computer than to ﬁnd df
which you can probably do in your head! However, there is another important point
here which is shown in the next example. For theoretical purposes, we may want a
formula rather than a numerical result.

Section 4
Approximations using Differentials
197
Example 2.
Show that when n is very large
1
n2 −
1
(n + 1)2 ∼= 2
n3
(∼= means “approximately equal to”).
If f(x) = 1/x2, the desired diﬀerence is
∆f = f(n) −f(n + 1). But ∆f is approximately df = d(1/x2) with x = n and
dx = −1.
d
 1
x2

= −2
x3 dx = −2
n3 (−1) = 2
n3 .
(This result is used in obtaining the “correspondence principle” in quantum me-
chanics; see texts on quantum physics.) Also see Problem 17.
Example 3.
The reduced mass µ of a system of two masses m1 and m2 is deﬁned by
µ−1 = m−1
1
+ m−1
2 . If m1 is increased by 1%, what fractional change in m2 leaves
µ unchanged? Taking diﬀerentials of the equation and substituting dm1 = 0.01m1,
we ﬁnd
0 = −m−2
1
dm1 −m−2
2
dm2,
dm2
m2
2
= −dm1
m2
1
= −0.01m1
m2
1
or
dm2
m2
= −0.01m2/m1.
For example, if m1 = m2, m2 should be decreased by 1%; if m2 = 3m1, m2 should
be decreased by 3%; and so on.
Example 4.
The electrical resistance R of a wire is proportional to its length and inversely
proportional to the square of its radius, that is, R = kl/r2. If the relative error
in length measurement is 5% and the relative error in radius measurement is 10%,
ﬁnd the relative error in R in the worst possible case.
The relative error in l means the actual error in measuring l divided by the length
measured. Since we might measure l either too large or too small, the relative error
dl/l might be either +0.05 or −0.05 in the worst cases. Similarly |dr/r| might be
as large as 0.10. We want the largest value which |dR/R| could have; we can ﬁnd
dR/R by diﬀerentiating ln R. From R = kl/r2 we ﬁnd
ln R = ln k + ln l −2 ln r.
Then
dR
R = dl
l −2dr
r .
In the worst case (that is, largest value of |dR/R|), dl/l and dr/r might have
opposite signs so the two terms would add. Then we would have:
Largest

dR
R
 =

dl
l
 + 2

dr
r
 = 0.05 + 2(0.10) = 0.25
or
25%.

198
Partial Differentiation
Chapter 4
Example 5.
Estimate the change in
f(x) =
 x
0
sin t
t
dt
when x changes from π/2 to (1+ϵ)π/2 where ϵ << 1/10. Recall from calculus that
df/dx = (sin x)/x. Then we want df = (df/dx) dx with x = π/2 and dx = ϵπ/2.
Thus
df = sin π/2
π/2
(ϵπ/2) = ϵ.
Note that the approximations we have been making correspond to using a Taylor
series through the f ′ term.
We can write Chapter 1 equation (12.8) with the
replacements x →x + ∆x, a →x, x −a →∆x, to get
f(x + ∆x) = f(x) + f ′(x)∆x + f ′′(x)(∆x)2/2! + · · · .
Dropping the (∆x)2 and higher terms we have the approximation we have been
using:
df ∼= ∆f = f(x + ∆x) −f(x) ∼= f ′(x)∆x = f ′(x)dx.
PROBLEMS, SECTION 4
1.
Use diﬀerentials to show that, for very large n,
1
(n + 1)3 −1
n3 ∼= −3
n4 .
2.
Use diﬀerentials to show that, for large n and small a,
√
n + a −√n ∼=
a
2√n.
Find the approximate value of
√
1026 + 5 −
√
1026.
3.
The thin lens formula is
1
i + 1
o = 1
f ,
where f is the focal length of the lens and o and i are the distances from the lens
to the object and image. If i = 15 when o = 10, use diﬀerentials to ﬁnd i when
o = 10.1.
4.
Do Problem 3 if i = 12 when o = 18, to ﬁnd i if o = 17.5.
5.
Let R be the resistance of R1 = 25 ohms and R2 = 15 ohms in parallel. (See Chapter
2, Problem 16.6.) If R1 is changed to 25.1 ohms, ﬁnd R2 so that R is not changed.
6.
The acceleration of gravity can be found from the length l and period T of a pen-
dulum; the formula is g = 4π2l/T 2. Find the relative error in g in the worst case if
the relative error in l is 5%, and the relative error in T is 2%.
7.
Coulomb’s law for the force between two charges q1 and q2 at distance r apart is
F = kq1q2/r2. Find the relative error in q2 in the worst case if the relative error in
q1 is 3%; in r, 5%; and in F, 2%.
8.
About how much (in percent) does an error of 1% in a and b aﬀect a2b3?
9.
Show that the approximate relative error (df)/f of a product f = gh is the sum of
the approximate relative errors of the factors.
10.
A force of 500 nt is measured with a possible error of 1 nt. Its component in a
direction 60◦away from its line of action is required, where the angle is subject to an
error of 0.5◦. What is (approximately) the largest possible error in the component?

Section 5
Chain Rule or Differentiating a Function of a Function
199
11.
Show how to make a quick estimate (to two decimal places) of
p
(4.98)2 −(3.03)2
without using a computer or a calculator. Hint:
Consider f(x, y) =
p
x2 −y2.
12.
As in Problem 11, estimate
3p
(2.05)2 + (1.98)2.
13.
Without using a computer or a calculator, estimate the change in length of a space
diagonal of a box whose dimensions are changed from 200×200×100 to 201×202×99.
14.
Estimate the change in
f(x) =
Z x
0
e−t
t2 + 0.51 dt
if x changes from 0.7 to 0.71.
15.
For an ideal gas of N molecules, the number of molecules with speeds ≤v is given
by the formula
n(v) = 4a3N
√π
Z v
0
x2e−a2x2dx,
where a is a constant and N is the total number of molecules. If N = 1026, estimate
the number of molecules with speeds between v = 1/a and 1.01/a.
16.
The operating equation for a synchrotron in the relativistic range is
qB = ωm[1 −(ωR)2/c2]−1/2,
where q and m are the charge and rest mass of the particle being accelerated, B is
the magnetic ﬁeld strength, R is the orbit radius, ω is the angular frequency, and
c is the speed of light. If ω and B are varied (all other quantities constant), show
that the relation between dω and dB can be written as
dB
B3 =
“ q
m
”2 dω
ω3 ,
or as
dB
B = dω
ω [1 −(ωR/c)2]−1.
17.
Here are some other ways of obtaining the formula in Example 2.
(a) Combine the two fractions to get (2n + 1)/[n2(n + 1)2]. Then note that for large
n, 2n + 1 ∼= 2n and n + 1 ∼= n.
(b) Factor the expression as
„ 1
n2
«  
1 −
1
`
1 + 1
n
´2
!
, expand
„
1 + 1
n
«−2
by bino-
mial series to two terms, and then simplify.
5. CHAIN RULE OR DIFFERENTIATING A FUNCTION OF A FUNCTION
You already know about the chain rule whether you have called it that or not. Look
at this example.
Example 1.
Find dy/dx if y = ln sin 2x.
You would say
dy
dx =
1
sin 2x · d
dx(sin 2x) =
1
sin 2x · cos 2x · d
dx(2x) = 2 cot 2x.
We could write this problem as
y = ln u,
where
u = sin v
and
v = 2x.
Then we would say
dy
dx = dy
du
du
dv
dv
dx.
This is an example of the chain rule. We shall want a similar equation for a function
of several variables. Consider another example.

200
Partial Differentiation
Chapter 4
Example 2.
Find dz/dt if z = 2t2 sin t.
Diﬀerentiating the product, we get
dz
dt = 4t sin t + 2t2 cos t.
We could have written this problem as
z = xy,
where x = 2t2
and y = sin t,
dz
dt = y dx
dt + xdy
dt .
But since x is ∂z/∂y and y is ∂z/∂x, we could also write
(5.1)
dz
dt = ∂z
∂x
dx
dt + ∂z
∂y
dy
dt .
We would like to be sure that (5.1) is a correct formula in general, when we
are given any function z(x, y) with continuous partial derivatives and x and y are
diﬀerentiable functions of t. To see this, recall from our discussion of diﬀerentials
that we had
(5.2)
∆z = ∂z
∂x∆x + ∂z
∂y∆y + ϵ1∆x + ϵ2∆y,
where ϵ1 and ϵ2 →0 with ∆x and ∆y. Divide this equation by ∆t and let ∆t →0;
since ∆x and ∆y →0, ϵ1 and ϵ2 →0 also, and we get (5.1).
It is often convenient to use diﬀerentials rather than derivatives as in (5.1). We
would like to be able to use (3.6), but in (3.6) x and y were independent variables
and now they are functions of t. However, it is possible to show (Problem 8) that dz
as deﬁned in (3.6) is a good approximation to ∆z even though x and y are related.
We may then write
(5.3)
dz = ∂z
∂xdx + ∂z
∂ydy
whether or not x and y are independent variables, and we may think of getting (5.1)
by dividing (5.3) by dt. This is very convenient in doing problems. Thus we could
do Example 2 in the following way:
dz = x dy + y dx = x cos t dt + y · 4t dt = (2t2 cos t + 4t sin t)dt,
dz
dt = 2t2 cos t + 4t sin t.
In doing problems, we may then use either diﬀerentials or derivatives. Here is
another example.

Section 5
Chain Rule or Differentiating a Function of a Function
201
Example 3.
Find dz/dt given z = xy, where y = tan−1 t, x = sin t.
Using diﬀerentials, we ﬁnd
dz = yxy−1 dx + xy ln x dy = yxy−1 cos t dt + xy ln x ·
dt
1 + t2 ,
dz
dt = yxy−1 cos t + xy ln x ·
1
1 + t2 .
You may wonder in a problem like this why we don’t just substitute x and y
as functions of t into z = xy to get z as a function of t and then diﬀerentiate.
Sometimes this may be the best thing to do but not always. For example, the
resulting formula may be very complicated and it may save a lot of algebra to use
(5.1) or (5.3). This is especially true if we want dz/dt for a numerical value of t.
Then there are cases when we cannot substitute; for example, if x as a function of t
is given by x+ex = t, we cannot solve for x as a function of t in terms of elementary
functions. But we can ﬁnd dx/dt, and so we can ﬁnd dz/dt by (5.1). Finding dx/dt
from such an equation is called implicit diﬀerentiation; we shall discuss this process
in the next section.
Computers can ﬁnd derivatives, so why should we learn the methods shown
here and in the following sections? Perhaps the most important reason is that the
techniques are needed in theoretical derivations. However, there is also a practical
reason: When a problem involves a number of variables, there may be many ways
to express the answer. (You might like to verify that dz/dt = z(y cot t + ln x cos2 y)
is another form for the answer in Example 3 above). Your computer may not give
you the form you want and it may be as easy to do the problem by hand as to
convert the computer result. But in problems involving a lot of algebra, a computer
can save time, so a good study method is to do problems both by hand and by
computer and compare results.
PROBLEMS, SECTION 5
1.
Given z = xe−y, x = cosh t, y = cos t, ﬁnd dz/dt.
2.
Given w =
√
u2 + v2, u = cos[ln tan(p + 1
4π)], v = sin[ln tan(p + 1
4π)], ﬁnd dw/dp.
3.
Given r = e−p2−q2, p = es, q = e−s, ﬁnd dr/ds.
4.
Given x = ln(u2 −v2), u = t2, v = cos t, ﬁnd dx/dt.
5.
If we are given z = z(x, y) and y = y(x), show that the chain rule (5.1) gives
dz
dx = ∂z
∂x + ∂z
∂y
dy
dx.
6.
Given z = (x + y)5, y = sin 10x, ﬁnd dz/dx.
7.
Given c = sin(a −b), b = ae2a, ﬁnd dc/da.
8.
Prove the statement just after (5.2), that dz given by (3.6) is a good approximation
to ∆z even though dx and dy are not independent. Hint:
let x and y be functions
of t; then (5.2) is correct, but ∆x ̸= dx and ∆y ̸= dy (because x and y are not
independent variables). However, ∆x/∆t is nearly dx/dt for small dt and dt = ∆t
since t is the independent variable. You can then show that
∆x =
„dx
dt + ϵx
«
dt = dx + ϵxdt,

202
Partial Differentiation
Chapter 4
and a similar formula for ∆y , and get
∆z = ∂z
∂xdx + ∂z
∂y dy + (terms containing ϵ’s) · dt = dz + ϵdt,
where ϵ →0 as ∆t →0.
6. IMPLICIT DIFFERENTIATION
Some examples will show the use of implicit diﬀerentiation.
Example 1.
Given x + ex = t, ﬁnd dx/dt and d2x/dt2.
If we give values to x, ﬁnd the corresponding t values, and plot x against t, we
have a graph whose slope is dx/dt. In other words, x is a function of t even though
we cannot solve the equation for x in terms of elementary functions of t. To ﬁnd
dx/dt, we realize that x is a function of t and just diﬀerentiate each term of the
equation with respect to t (this is called implicit diﬀerentiation). We get
(6.1)
dx
dt + ex dx
dt = 1.
Solving for dx/dt, we get
dx
dt =
1
1 + ex .
Alternatively, we could use diﬀerentials here, and write ﬁrst dx+exdx = dt; dividing
by dt then gives (6.1).
We can also ﬁnd higher derivatives by implicit diﬀerentiation (but do not use
diﬀerentials for this since we have not given any meaning to the derivative or dif-
ferential of a diﬀerential). Let us diﬀerentiate each term of (6.1) with respect to t;
we get
(6.2)
d2x
dt2 + ex d2x
dt2 + ex
dx
dt
2
= 0.
Solving for d2x/dt2 and substituting the value already found for dx/dt, we get
(6.3)
d2x
dt2 = −ex  dx
dt
2
1 + ex
=
−ex
(1 + ex)3 .
This problem is even easier if we want only the numerical values of the derivatives
at a point. For x = 0 and t = 1, (6.1) gives
dx
dt + 1 · dx
dt = 1
or
dx
dt = 1
2,
and (6.2) gives
d2x
dt2 + 1 · d2x
dt2 + 1 ·
1
2
2
= 0
or
d2x
dt2 = −1
8.
Implicit diﬀerentiation is the best method to use in ﬁnding slopes of curves with
complicated equations.

Section 7
More Chain Rule
203
Example 2.
Find the equation of the tangent line to the curve x3 −3y3 + xy + 21 = 0 at
the point (1, 2).
We diﬀerentiate the given equation implicitly with respect to x to get
3x2 −9y2 dy
dx + xdy
dx + y = 0.
Substitute x = 1, y = 2:
3 −36 dy
dx + dy
dx + 2 = 0,
dy
dx = 5
35 = 1
7.
Then the equation of the tangent line is
y −2
x −1 = 1
7
or
x −7y + 13 = 0.
By computer plotting the curve and the tangent line on the same axes, you can
check to be sure that the line appears tangent to the curve.
PROBLEMS, SECTION 6
1.
If pva = C (where a and C are constants), ﬁnd dv/dp and d2v/dp2.
2.
If yexy = sin x ﬁnd dy/dx and d2y/dx2 at (0, 0).
3.
If xy = yx, ﬁnd dy/dx at (2, 4).
4.
If xey = yex, ﬁnd dy/dx and d2y/dx2 for y ̸= 1.
5.
If xy3 −yx3 = 6 is the equation of a curve, ﬁnd the slope and the equation of the
tangent line at the point (1, 2). Computer plot the curve and the tangent line on
the same axes.
6.
In Problem 5 ﬁnd d2y/dx2 at (1, 2).
7.
If y3 −x2y = 8 is the equation of a curve, ﬁnd the slope and the equation of the
tangent line at the point (3, −1). Computer plot the curve and the tangent line on
the same axes.
8.
In Problem 7 ﬁnd d2y/dx2 at (3, −1).
9.
For the curve x2/3+y2/3 = 4, ﬁnd the equations of the tangent lines at (2
√
2, −2
√
2),
at (8, 0), and at (0, 8). Computer plot the curve and the tangent lines on the same
axes.
10.
For the curve xey + yex = 0, ﬁnd the equation of the tangent line at the origin.
Caution: Substitute x = y = 0 as soon as you have diﬀerentiated. Computer plot
the curve and the tangent line on the same axes.
11.
In Problem 10, ﬁnd y′′ at the origin.
7. MORE CHAIN RULE
Above we have considered z = f(x, y), where x and y are functions of t.
Now
suppose z = f(x, y) as before, but x and y are each functions of two variables s and
t. Then z is a function of s and t and we want to ﬁnd ∂z/∂s and ∂z/∂t. We show
by some examples how to do problems like this.

204
Partial Differentiation
Chapter 4
Example 1.
Find ∂z/∂s and ∂z/∂t given
z = xy,
x = sin(s + t),
y = s −t.
We take diﬀerentials of each of the three equations to get
dz = y dx + x dy,
dx = cos(s + t)(ds + dt),
dy = ds −dt.
Substituting dx and dy into dz, we get
dz = y cos(s + t)(ds + dt) + x(ds −dt)
(7.1)
= [y cos(s + t) + x] ds + [y cos(s + t) −x] dt.
Now if s is constant, ds = 0, z is a function of one variable t, and we can divide
(7.1) by dt [see (5.1) and the discussion following it]. For dz÷dt on the left we write
∂z/∂t because that is the notation which properly describes what we are ﬁnding,
namely, the rate of change of z with t when s is constant. Thus we have
∂z
∂t = y cos(s + t) −x
and similarly
∂z
∂s = y cos(s + t) + x.
Notice that in (7.1) the coeﬃcient of ds is ∂z/∂s and the coeﬃcient of dt is ∂z/∂t
[also compare (5.3)]. If you realize this, you can simply read oﬀ∂z/∂s and ∂z/∂t
from (7.1).
We can do problems with more variables in the same way.
Example 2.
Find ∂u/∂s, ∂u/∂t, given u = x2 + 2xy −y ln z and
x = s + t2, y = s −t2, z = 2t.
We ﬁnd
du = 2x dx + 2x dy + 2y dx −y
z dz −ln z dy
= (2x + 2y)(ds + 2t dt) + (2x −ln z)(ds −2t dt) −y
z (2 dt)
= (4x + 2y −ln z) ds +

4yt + 2t ln z −2y
z

dt.
Then
∂u
∂s = 4x + 2y −ln z,
∂u
∂t = 4yt + 2t ln z −2y
z .
If we want just one derivative, say ∂u/∂t, we can save some work by letting ds = 0
to start with. To make it clear that we have done this, we write
dus = (2x + 2y)(2t dt) + (2x −ln z)(−2t dt) −y
z (2 dt)
=

4yt + 2t ln z −2y
z

dt.

Section 7
More Chain Rule
205
The subscript s indicates that s is being held constant. Then dividing by dt, we
have ∂u/∂t as before. We could also use derivatives instead of diﬀerentials. By an
equation like (5.1), we have
(7.2)
∂u
∂t = ∂u
∂x
∂x
∂t + ∂u
∂y
∂y
∂t + ∂u
∂z
∂z
∂t ,
where we have written all the t derivatives as partials since u, x, y, and z depend
on both s and t. Using (7.2), we get
∂u
∂t = (2x + 2y)(2t) + (2x −ln z)(−2t) +

−y
z
	
(2) = 4yt + 2t ln z −2y
z .
It is sometimes useful to write chain rule formulas in matrix form (for matrix
multiplication, see Chapter 3, Section 6). Given, as above, u = f(x, y, z), x(s, t),
y(s, t), z(s, t), we can write equations like (7.2) in the following matrix form:
(7.3)
∂u
∂s
∂u
∂t

=
∂u
∂x
∂u
∂y
∂u
∂z











∂x
∂s
∂x
∂t
∂y
∂s
∂y
∂t
∂z
∂s
∂z
∂t










.
[Sometimes (7.3) is written in the abbreviated form
∂(u)
∂(s, t) =
∂(u)
∂(x, y, z)
∂(x, y, z)
∂(s, t)
which is reminiscent of
dy
dt = dy
dx
dx
dt ;
but be careful of this for two reasons: (a) It may be helpful in remembering the
formula but to use it you must understand that it means the matrix product (7.3).
(b) The symbol ∂(u, v)/∂(x, y) usually means a determinant rather than a matrix
of partial derivatives—see Chapter 5, Section 4].
Again in these problems, you may say, why not just substitute? Look at the
following problem.
Example 3.
Find dz/dt given z = x −y and
x2 + y2 = t2,
x sin t = yey.
From the z equation, we have
dz = dx −dy.
We need dx and dy; here we cannot solve for x and y in terms of t. But we can
ﬁnd dx and dy in terms of dt from the other two equations and this is all we need.
Take diﬀerentials of both equations to get
2x dx + 2y dy = 2t dt,
sin t dx + x cos t dt = (yey + ey)dy.

206
Partial Differentiation
Chapter 4
Rearrange terms:
x dx + y dy = t dt,
sin t dx −(y + 1)eydy = −x cos t dt.
Solve for dx and dy (in terms of dt) by determinants:
dx =

t dt
y
−x cos t dt
−(y + 1)ey


x
y
sin t
−(y + 1)ey

= −t(y + 1)ey + xy cos t
−x(y + 1)ey −y sin t dt,
and similarly for dy. Substituting dx and dy into the formula for dz and dividing
by dt, we get dz/dt. A computer may save us some time with the algebra.
We can also do problems like this when x and y are given implicitly as functions
of two variables s and t.
Example 4.
Find ∂z/∂s and ∂z/∂t given
z = x2 + xy,
x2 + y3 = st + 5,
x3 −y2 = s2 + t2.
We have dz = 2x dx + x dy + y dx.
To ﬁnd dx and dy from the other two
equations, we take diﬀerentials of each equation:
2x dx + 3y2 dy = s dt + t ds,
3x2 dx −2y dy = 2s ds + 2t dt.
(7.4)
We can solve these two equations for dx and dy in terms of ds and dt to get
dx =

s dt + t ds
3y2
2s ds + 2t dt
−2y


2x
3y2
3x2
−2y

= (−2ys −6ty2) dt + (−2yt −6sy2) ds
−4xy −9x2y2
and a similar expression for dy. We substitute these values of dx and dy into dz and
ﬁnd dz in terms of ds and dt just as in Example 1; we can then write ∂z/∂s and
∂z/∂t just as we did there (Problem 11). Notice that if we want only one derivative,
say ∂z/∂t, we could save some algebra by putting ds = 0 in (7.4). Also note that
we can save some algebra if we want the derivatives only at one point. Suppose we
were asked for ∂z/∂s and ∂z/∂t at x = 3, y = 1, s = 1, t = 5. We substitute these
values into (7.4) to get
6 dx + 3 dy = dt + 5 ds,
27 dx −2 dy = 10 dt + 2 ds.
We solve these equations for dx and dy and substitute into dz just as before, but
the algebra is easier with the numerical coeﬃcients (Problem 11).

Section 7
More Chain Rule
207
So far, we have been assuming that the independent variables were “natural”
pairs like x and y, or s and t. For example, we wrote ∂x/∂s above, taking it for
granted that the variable held constant was t. In some applications (particularly
thermodynamics), it is not at all clear what the other independent variable is and
we have to be more explicit. We write (∂x/∂s)t; this means that s and t are the
two independent variables, that x is thought of as a function of them, and then x
is diﬀerentiated partially with respect to s. Suppose we try to ﬁnd from the three
equations of Example 4 a rather peculiar looking derivative.
Example 5.
Given the equations of Example 4, ﬁnd (∂s/∂z)x.
First, let us see that the question makes sense. There are ﬁve variables in the
three equations. If we give values to two of them, we can solve for the other three;
that is, there are two independent variables, and the other three are functions of
these two. If z and x are the independent ones, then s, t, and y are functions of
z and x; we should be able to ﬁnd their partial derivatives, for example (∂s/∂z)x
which we wanted. To carry out the necessary work, we ﬁrst rearrange equations
(7.4) and the dz equation to get
−x dy = (2x + y) dx −dz,
t ds + s dt −3y2 dy = 2x dx,
2s ds + 2t dt + 2y dy = 3x2dx.
From these three equations we could solve for ds, dt, and dy in terms of dx and dz
(by determinants or by elimination—the same methods you use to solve any set of
linear equations). Then we could ﬁnd any partial derivative of s(x, z), t(x, z), or
y(x, z) with respect to x to z. For example, to ﬁnd (∂y/∂z)x, we get from the ﬁrst
equation
dy = 1
x dz −2x + y
x
dx,
∂y
∂z

x
= 1
x.
Note that we would not need to diﬀerentiate all three equations if we wanted only
this derivative; you should always look ahead to see how much diﬀerentiation is
necessary! To ﬁnd (∂s/∂z)x, we must solve the three equations for ds in terms of
dx and dz; we can save ourselves some work [if we want only (∂s/∂z)x] by putting
dx = 0 to start with. To make it clear that we have done this we write dsx and
dzx. Then we get
dsx =

−dzx
0
−x
0
s
−3y2
0
2t
2y


0
0
−x
t
s
−3y2
2s
2t
2y

= −(2sy + 6ty2)dzx
−x(2t2 −2s2)
,
∂s
∂z

x
= sy + 3ty2
x(t2 −s2).
We could use a computer to save us some algebra in this problem.

208
Partial Differentiation
Chapter 4
Example 6.
Let x, y be rectangular coordinates and r, θ be polar coordinates in a plane.
Then the equations relating them are
x = r cos θ,
y = r sin θ,
(7.5)
or
r =

x2 + y2,
θ = tan−1 y
x.
(7.6)
Suppose we want to ﬁnd ∂θ/∂x. Remembering that if y = f(x), dy/dx and dx/dy
are reciprocals, you might be tempted to ﬁnd ∂θ/∂x by taking the reciprocal of
∂x/∂θ, which is easier to ﬁnd than ∂θ/∂x. This is wrong. From (7.6) we get
(7.7)
∂θ
∂x =
−y/x2
1 + (y2/x2) = −y
r2 .
From x = r cos θ we get
(7.8)
∂x
∂θ = −r sin θ = −y.
These are not reciprocals. You should think carefully about the reason for this;
∂θ/∂x means (∂θ/∂x)y, whereas ∂x/∂θ means (∂x/∂θ)r.
In one case y is held
constant and in the other case r is held constant; this is why the two derivatives
are not reciprocals. It is true that (∂θ/∂x)y and (∂x/∂θ)y are reciprocals. But
to ﬁnd (∂x/∂θ)y directly, we have to express x as a function of θ and y. We ﬁnd
x = y cot θ, so we get
(7.9)
∂x
∂θ

y
= y(−csc2 θ) =
−y
sin2 θ =
−y
y2/r2 = −r2
y ,
which is the reciprocal of ∂θ/∂x in (7.7).
This is a general rule: ∂u/∂v and ∂v/∂u are not usually reciprocals; they are
reciprocals if the other independent variables (besides u or v) are the same in
both cases.
You can see this clearly from the equations involving diﬀerentials. From the equa-
tion θ = arc tan(y/x), we can ﬁnd
(7.10)
dθ = x dy −y dx
x2
 
1 + y2
x2

= x dy −y dx
r2
.
From x = r cos θ, we get
(7.11)
dx = cos θ dr −r sin θ dθ = x
r dr −y dθ.
From (7.10), if y is constant, dy = 0, and we can write
(7.12)
dθy = −y
r2 dxy,

Section 7
More Chain Rule
209
where the y subscript indicates that y is constant. From (7.12), we then ﬁnd either
 ∂θ
∂x

y
= dθy
dxy
or
∂x
∂θ

y
= dxy
dθy
,
and these are reciprocals. From (7.11), however, we can ﬁnd (∂x/∂θ)r or (∂θ/∂x)r;
these are again reciprocals of each other, but are diﬀerent from the derivatives found
from (7.12).
It is interesting to write equations like (7.11) in matrix notation:
(7.13)
dx
dy

=





∂x
∂r
∂x
∂θ
∂y
∂r
∂y
∂θ





dr
dθ

=
cos θ
−r sin θ
sin θ
r cos θ
dr
dθ

= A
dr
dθ

,
where A stands for the square matrix in (7.13). Similarly, we can write
(7.14)
dr
dθ

=





∂r
∂x
∂r
∂y
∂θ
∂x
∂θ
∂y





dx
dy

= A−1
dx
dy

;
we have written the square matrix as A−1 since by (7.13),
A−1

dx
dy

= A−1A

dr
dθ

=

dr
dθ

.
Then, ﬁnding A−1 (Problem 9) and using (7.14), we have
(7.15)





∂r
∂x
∂r
∂y
∂θ
∂x
∂θ
∂y




=
 cos θ
sin θ
−1
r sin θ
1
r cos θ.

We can simply read oﬀthe four partial derivatives of r, θ, with respect to x, y, from
equation (7.15). (Also see Problem 9.) Also using (7.5), and speciﬁcally noting that
x and y are independent variables, we have:
∂r
∂x =
 ∂r
∂x

y
= cos θ = x
r ,
∂r
∂y =
∂r
∂y

x
= sin θ = y
r ,
∂θ
∂x =
 ∂θ
∂x

y
= −1
r sin θ = −y
r2 ,
∂θ
∂y =
∂θ
∂y

x
= 1
r cos θ = x
r2 .
(7.16)
[In the notation mentioned just after (7.3), we could write
AA−1 = ∂(x, y)
∂(r, θ)
∂(r, θ)
∂(x, y) = unit matrix ;
thus, although the individual pairs of partial derivatives discussed above are not
reciprocals, the two matrices of partial derivatives are inverses.]

210
Partial Differentiation
Chapter 4
PROBLEMS, SECTION 7
1.
If x = yz and y = 2 sin(y + z), ﬁnd dx/dy and d2x/dy2.
2.
If P = r cos t and r sin t −2ter = 0, ﬁnd dP/dt.
3.
If z = xe−y and x = cosh t, y = cos s, ﬁnd ∂z/∂s and ∂z/∂t.
4.
If w = e−r2−s2, r = uv, s = u + 2v, ﬁnd ∂w/∂u and ∂w/∂v.
5.
If u = x2y3z and x = sin(s + t), y = cos(s + t), z = est, ﬁnd ∂u/∂s and ∂u/∂t.
6.
If w = f(x, y) and x = r cos θ, y = r sin θ, ﬁnd formulas for
∂w/∂r, ∂w/∂θ, and ∂2w/∂r2.
7.
If x = r cos θ and y = r sin θ, ﬁnd (∂y/∂θ)r and (∂y/∂θ)x. Also ﬁnd (∂θ/∂y)x in
two ways (by eliminating r from the given equations and then diﬀerentiating, or by
taking diﬀerentials in both equations and then eliminating dr). When are ∂y/∂θ
and ∂θ/∂y reciprocals?
8.
If xs2 + yt2 = 1 and x2s + y2t = xy −4, ﬁnd ∂x/∂s, ∂x/∂t, ∂y/∂s, ∂y/∂t, at
(x, y, s, t) = (1, −3, 2, −1). Hint:
To simplify the work, substitute the numerical
values just after you have taken diﬀerentials.
9.
Verify (7.16) in three ways:
(a)
Diﬀerentiate equations (7.6).
(b)
Take diﬀerentials of (7.5) and solve for dr and dθ.
(c)
Find A−1 in (7.15) from A in (7.13); note that this is (b) in matrix notation.
10.
If x2 + y2 = 2st −10 and 2xy = s2 −t2, ﬁnd ∂x/∂s, ∂x/∂t, ∂y/∂s, ∂y/∂t at
(x, y, s, t) = (4, 2, 5, 3).
11.
Finish Example 4 above, both for the general case and for the given numerical values.
Substitute the numerical values into your general formulas to check your answers.
12.
If w = x + y with x3 + xy + y3 = s and x2y + xy2 = t, ﬁnd ∂w/∂s, ∂w/∂t.
13.
If m = pq with a sin p−p = q and b cos q+q = p, ﬁnd (∂p/∂q)m, (∂p/∂q)a, (∂p/∂q)b,
(∂b/∂a)p, (∂a/∂q)m.
14.
If u = x2 + y2 + xyz and x4 + y4 + z4 = 2x2y2z2 + 10, ﬁnd (∂u/∂x)z at the point
(x, y, z) = (2, 1, 1).
15.
Given x2u −y2v = 1, and x + y = uv. Find (∂x/∂u)v, (∂x/∂u)y.
16.
Let w = x2 + xy + z2.
(a)
If x3 + x = 3t, y4 + y = 4t, z5 + z = 5t, ﬁnd dw/dt.
(b)
If y3 + xy = 1 and z3 −xz = 2, ﬁnd dw/dx.
(c)
If x3z + z3y + y3x = 0, ﬁnd (∂w/∂x)y.
17.
If p3 + sq = t, and q3 + tp = s, ﬁnd (∂p/∂s)t, (∂p/∂s)q at (p, q, s, t) = (−1, 2, 3, 5).
18.
If m = a + b and n = a2 + b2 ﬁnd (∂b/∂m)n and (∂m/∂b)a.
19.
If z = r + s2, x + y = s3 + r3 −3, xy = s2 −r2, ﬁnd (∂x/∂z)s, (∂x/∂z)r, (∂x/∂z)y
at (r, s, x, y, z) = (−1, 2, 3, 1, 3).
20.
If u2 + v2 = x3 −y3 + 4, u2 −v2 = x2y2 + 1, ﬁnd (∂u/∂x)y, (∂u/∂x)v, (∂x/∂u)y,
(∂x/∂u)v at (x, y, u, v) = (2, −1, 3, 2).

Section 8
Application of Partial Differentiation to Maximum and Minimum Problems
211
21.
Given x2 +y2 +z2 = 6, and w3 +z3 = 5xy+12, ﬁnd the following partial derivatives
at the point (x, y, z, w) = (1, −2, 1, 1).
„ ∂z
∂x
«
y
,
„ ∂z
∂x
«
w
,
„ ∂z
∂y
«
x
,
„∂z
∂y
«
w
,
„∂w
∂x
«
z
,
„ ∂x
∂w
«
z
.
22.
If w = f(ax + by), show that b ∂w
∂x −a ∂w
∂y = 0.
Hint:
Let ax + by = z.
23.
If u = f(x −ct) + g(x + ct), show that ∂2u
∂x2 = 1
c2
∂2u
∂t2 .
24.
If z = cos(xy), show that x ∂z
∂x −y ∂z
∂y = 0.
25.
The formulas of this problem are useful in thermodynamics.
(a)
Given f(x, y, z) = 0, ﬁnd formulas for
„ ∂y
∂x
«
z
,
„∂x
∂y
«
z
,
„∂y
∂z
«
x
,
and
„ ∂z
∂x
«
y
.
(b)
Show that
„∂x
∂y
«
z
„ ∂y
∂x
«
z
= 1
and
„∂x
∂y
«
z
„∂y
∂z
«
x
„ ∂z
∂x
«
y
= −1.
(c)
If x, y, z are each functions of t, show that
„∂y
∂z
«
x
=
„∂y
∂t
«
x
ﬃ„∂z
∂t
«
x
and
corresponding formulas for
„ ∂z
∂x
«
y
and
„∂x
∂y
«
z
.
26.
Given f(x, y, z) = 0 and g(x,y, z) = 0, ﬁnd a formula for dy/dx.
27.
Given u(x, y) and y(x, z), show that
„∂u
∂x
«
z
=
„∂u
∂x
«
y
+
„∂u
∂y
«
x
„ ∂y
∂x
«
z
.
28.
Given s(v, T ) and v(p, T), we deﬁne cp = T(∂s/∂T)p, cv = T(∂s/∂T)v. (The c’s are
speciﬁc heats in thermodynamics.) Show that
cp −cv = T
„ ∂s
∂v
«
T
„ ∂v
∂T
«
p
.
8. APPLICATION OF PARTIAL DIFFERENTIATION
TO MAXIMUM AND MINIMUM PROBLEMS
You will recall that derivatives give slopes as well as rates and that you ﬁnd max-
imum and minimum points of y = f(x) by setting dy/dx = 0. Often in applied
problems we want to ﬁnd maxima or minima of functions of more than one variable.
Think of z = f(x, y) which represents a surface. If there is a maximum point on
it (like the top of a hill), then the curves for x = const. and y = const. which pass
through the maximum point also have maxima at the same point. That is, ∂z/∂x

212
Partial Differentiation
Chapter 4
and ∂z/∂y are zero at the maximum point. Recall that dy/dx = 0 was a necessary
condition for a maximum point of y = f(x), but not suﬃcient; the point might
have been a minimum or perhaps a point of inﬂection with a horizontal tangent.
Something similar can happen for z = f(x, y). The point where ∂z/∂x = 0 and
∂z/∂y = 0 may be a maximum point, a minimum point, or neither. (An interesting
example of neither is a “saddle point”—a curve from front to back on a saddle has
a minimum; one from side to side has a maximum. See Figure 8.1.) In ﬁnding max-
ima of y = f(x), it is sometimes possible to tell from
the geometry or physics that you have a maximum.
If necessary you can ﬁnd d2y/dx2; if it is negative,
then you know you have a maximum point. There is
a similar (rather complicated) second derivative test
for functions of two variables (see Problems 1 to 7),
but we use it only if we have to; usually we can tell
from the problem whether we have a maximum, a
minimum, or neither. Let us consider some examples
of maximum or minimum problems.
Figure 8.1
Example.
A pup tent (Figure 8.2) of given volume V , with ends but no ﬂoor, is to be
made using the least possible material. Find the proportions.
Using the letters indicated in the ﬁgure, we ﬁnd the
volume V and the area A.
V = 1
2 · 2w · l · w tan θ = w2l tan θ,
A = 2w2 tan θ + 2lw
cos θ.
Figure 8.2
Since V is given, only two of the three variables w, l, and θ are independent, and
we must eliminate one of them from A before we try to minimize A. Solving the V
equation for l and substituting into A, we get
A = 2w2 tan θ + 2w
cos θ
V
w2 tan θ = 2w2 tan θ + 2V
w csc θ.
We now have A as a function of two independent variables w and θ. To minimize
A we ﬁnd ∂A/∂w and ∂A/∂θ and set them equal to zero.
∂A
∂w = 4w tan θ −2V csc θ
w2
= 0,
∂A
∂θ = 2w2 sec2 θ −2V
w csc θ cot θ = 0.
Solving each of these equations for w3 and setting the results equal, we get
w3 = V csc θ
2 tan θ = V csc θ cot θ
sec2 θ
or
cos θ
2 sin2 θ = cos θ cos2 θ
sin2 θ
.
You should convince yourself that neither sin θ = 0 nor cos θ = 0 is possible (the
tent collapses to zero volume in both cases). Therefore we may assume sin θ ̸= 0 and
cos θ ̸= 0 and cancel these factors, getting cos2 θ = 1
2 or θ = 45◦. Then tan θ = 1,
V = w2l, and from the ∂A/∂w equation we have 2w = l
√
2. Then the height of the
tent (at the peak) is w tan θ = w = 1/
√
2.

Section 8
Application of Partial Differentiation to Maximum and Minimum Problems
213
PROBLEMS, SECTION 8
1.
Use the Taylor series about x = a to verify the familiar “second derivative test” for
a maximum or minimum point. That is, show that if f ′(a) = 0, then f ′′(a) > 0
implies a minimum point at x = a and f ′′(a) < 0 implies a maximum point at x = a.
Hint: For a minimum point, say, you must show that f(x) > f(a) for all x near
enough to a.
2.
Using the two-variable Taylor series [say (2.7)] prove the following “second derivative
tests” for maximum or minimum points of functions of two variables. If fx = fy = 0
at (a, b), then
(a, b) is a minimum point if at (a, b), fxx > 0, fyy > 0, and fxxfyy > f 2
xy;
(a, b) is a maximum point if at (a, b), fxx < 0, fyy < 0, and fxxfyy > f 2
xy;
(a, b) is neither a maximum nor a minimum point if fxxfyy < f 2
xy. (Note that
this includes fxxfyy < 0, that is, fxx and fyy of opposite sign.)
Hint: Let fxx = A, fxy = B, fyy = C; then the second derivative terms in the Taylor
series are Ah2 + 2Bhk + Ck2; this can be written A(h + Bk/A)2 + (C −B2/A)k2.
Find out when this expression is positive for all small h, k [that is, all (x, y) near
(a, b)]; also ﬁnd out when it is negative for all small h, k, and when it has both
positive and negative values for small h, k.
Use the facts stated in Problem 2 to ﬁnd the maximum and minimum points of the
functions in Problems 3 to 6.
3.
x2 + y2 + 2x −4y + 10
4.
x2 −y2 + 2x −4y + 10
5.
4 + x + y −x2 −xy −1
2y2
6.
x3 −y3 −2xy + 2
7.
Given z = (y −x2)(y −2x2), show that z has neither a maximum nor a minimum
at (0, 0), although z has a minimum on every straight line through (0, 0).
8.
A roof gutter is to be made from a long strip of sheet metal, 24 cm wide, by
bending up equal amounts at each side through equal angles. Find the angle and
the dimensions that will make the carrying capacity of the gutter as large as possible.
9.
An aquarium with rectangular sides and bottom (and no top) is to hold 5 gal. Find
its proportions so that it will use the least amount of material.
10.
Repeat Problem 9 if the bottom is to be three times as thick as the sides.
11.
Find the most economical proportions for a tent as in the ﬁgure, with no ﬂoor.
12.
Find the shortest distance from the origin to the surface z = xy + 5.

214
Partial Differentiation
Chapter 4
13.
Given particles of masses m, 2m, and 3m at the points (0, 1), (1, 0), and (2, 3), ﬁnd
the point P about which their total moment of inertia will be least. (Recall that
to ﬁnd the moment of inertia of m about P, you multiply m by the square of its
distance from P.)
14.
Repeat Problem 13 for masses m1, m2, m3 at (x1, y1), (x2, y2), (x3, y3). Show that
the point you ﬁnd is the center of mass.
15.
Find the point on the line through (1, 0, 0) and (0, 1, 0) that is closest to the line
x = y = z. Also ﬁnd the point on the line x = y = z that is closest to the line
through (1, 0, 0) and (0, 1, 0).
16.
To ﬁnd the best straight line ﬁt to a set of data points (xn, yn) in the “least squares”
sense means the following: Assume that the equation of the line is y = mx + b and
verify that the vertical deviation of the line from the point (xn, yn) is yn −(mxn+b).
Write S = sum of the squares of the deviations, substitute the given values of xn, yn
to give S as a function of m and b, and then ﬁnd m and b to minimize S.
Carry through this routine for the set of points: (−1, −2), (0, 0), (1, 3). Check
your results by computer, and also computer plot (on the same axes) the given
points and the approximating line.
17.
Repeat Problem 16 for each of the following sets of data points.
(a)
(1, 0), (2, −1), (3, −8)
(b)
(−2, −6), (−1, −3), (0, 0), (1, 9/2), (2, 7)
(c)
(−2, 4), (−1, 0), (0, −1), (1, −8), (2, −10)
9. MAXIMUM AND MINIMUM PROBLEMS WITH
CONSTRAINTS; LAGRANGE MULTIPLIERS
Some examples will illustrate these methods.
Example 1.
A wire is bent to ﬁt the curve y = 1 −x2 (Figure 9.1). A string is stretched
from the origin to a point (x, y) on the curve. Find (x, y) to minimize the length of
the string.
Figure 9.1
We want to minimize the distance d =

x2 + y2 from the origin to the point
(x, y); this is equivalent to minimizing f = d2 = x2 + y2. But x and y are not inde-
pendent; they are related by the equation of the curve. This extra relation between
the variables is what we mean by a constraint. Problems involving constraints occur
frequently in applications.
There are several ways to do a problem like this. We shall discuss the following
methods: (a) elimination, (b) implicit diﬀerentiation, (c) Lagrange multipliers.

Section 9
Maximum and Minimum Problems with Constraints; Lagrange Multipliers
215
(a) Elimination
The most obvious method is to eliminate y. Then we want to
minimize
f = x2 + (1 −x2)2 = x2 + 1 −2x2 + x4 = x4 −x2 + 1.
This is just an ordinary calculus problem:
df
dx = 4x3 −2x = 0,
x = 0,
or
x = ±

1
2.
It is not immediately obvious which of these points is a maximum and which is a
minimum, so in this simple problem it is worth while to ﬁnd the second derivative:
d2f
dx2 = 12x2 −2 =
 −2
at
x = 0
(relative maximum),
4
at
x = ±

1/2
(minimum).
The minimum we wanted then occurs at x = ±

1/2, y = 1/2.
(b) Implicit Diﬀerentiation
Suppose it had not been possible to solve for y
and substitute; we could still do the problem. From f = x2 + y2, we ﬁnd
(9.1)
df = 2x dx + 2y dy
or
df
dx = 2x + 2y dy
dx.
From an equation like y = 1 −x2 relating x and y, we could ﬁnd dy in terms of dx
even if the equation were not solvable for y. Here we get
dy = −2x dx.
Eliminating dy from df, we have
df = (2x −4xy)dx
or
df
dx = 2x −4xy.
To minimize f, we set df/dx = 0 (or in the diﬀerential notation we set df = 0 for
arbitrary dx). This gives
2x −4xy = 0.
This equation must now be solved simultaneously with the equation of the curve
y = 1 −x2. We get 2x −4x(1 −x2) = 0, x = 0 or ±

1/2 as before.
To test for maxima or minima we need d 2f/dx2. Diﬀerentiating df/dx in (9.1)
with respect to x, we get
d2f
dx2 = 2 + 2
dy
dx
2
+ 2y d2y
dx2 .
At x = 0, we ﬁnd y = 1, dy/dx = 0, d2y/dx2 = −2, so
d2f
dx2 = 2 −4 = −2;
this is a maximum point. At x = ±

1/2, we ﬁnd
y = 1
2,
dy
dx = ∓
√
2,
d2y
dx2 = −2,

216
Partial Differentiation
Chapter 4
so
d2f
dx2 = 2 + 4 −2 = 4;
this point is the required minimum. Notice particularly here that you could do
every step of (b) even if the equation of the curve could not be solved for y.
We can do problems with several independent variables by methods similar to
those we have just used in Example 1. Consider this problem.
Example 2.
Find the shortest distance from the origin to the plane x −2y −2z = 3.
We want to minimize the distance d =

x2 + y2 + z2 from the origin to a point
(x, y, z) on the plane. This is equivalent to minimizing f = d2 = x2 + y2 + z2 if
x −2y −2z = 3. We can eliminate one variable, say x, from f using the equation
of the plane. Then we have
f = (3 + 2y + 2z)2 + y2 + z2.
Here f is a function of the two independent variables y and z, so to minimize f we
set ∂f/∂y = 0, ∂f/∂z = 0.
∂f
∂y = 2(3 + 2y + 2z) · 2 + 2y = 0,
∂f
∂z = 2(3 + 2y + 2z) · 2 + 2z = 0.
Solving these equations for y and z, we get y = z = −2/3, so from the equation of
the plane we get x = 1/3. Then
fmin =
1
3
2
+
2
3
2
+
2
3
2
= 1,
dmin = 1.
It is clear from the geometry that there is a minimum distance from the origin to
a plane; therefore this is it without a second-derivative test. (Also see Chapter 3,
Section 5 for another way to do this problem.)
Problems with any number of variables can be done this way, or by method (b)
if the equations are implicit.
(c) Lagrange Multipliers
However, methods (a) and (b) can involve an enor-
mous amount of algebra. We can shortcut this algebra by a process known as the
method of Lagrange multipliers or undetermined multipliers. We want to consider
a problem like the one we discussed in (a) or (b). In general, we want to ﬁnd the
maximum or minimum of a function f(x, y), where x and y are related by an equa-
tion φ(x, y) = const. Then f is really a function of one variable (say x). To ﬁnd the
maximum or minimum points of f, we set df/dx = 0 or df = 0 as in (9.1). Since
φ = const., we get dφ = 0.
df = ∂f
∂xdx + ∂f
∂y dy = 0,
dφ = ∂φ
∂xdx + ∂φ
∂y dy = 0.
(9.2)

Section 9
Maximum and Minimum Problems with Constraints; Lagrange Multipliers
217
In method (b) we solved the dφ equation for dy in terms of dx and substituted it into
df; this often involves messy algebra. Instead, we shall multiply the dφ equation by
λ (this is the undetermined multiplier—we shall ﬁnd its value later) and add it to
the df equation; then we have
(9.3)
∂f
∂x + λ∂φ
∂x

dx +
∂f
∂y + λ∂φ
∂y

dy = 0.
We now pick λ so that
(9.4)
∂f
∂y + λ∂φ
∂y = 0.
[That is, we pick λ = −(∂f/∂y)/(∂φ/∂y), but it isn’t necessary to write it in this
complicated form! In fact, this is exactly the point of the Lagrange multiplier λ;
by using the abbreviation λ for a complicated expression, we avoid some algebra.]
Then from (9.3) and (9.4) we have
(9.5)
∂f
∂x + λ∂φ
∂x = 0.
Equations (9.4), (9.5), and φ(x, y) = const. can now be solved for the three un-
knowns x, y, λ. We don’t actually want the value of λ, but often the algebra is
simpler if we do ﬁnd it and use it in ﬁnding x and y which we do want. Note
that equations (9.4) and (9.5) are exactly the equations we would write if we had a
function
(9.6)
F(x, y) = f(x, y) + λφ(x, y)
of two independent variables x and y and we wanted to ﬁnd its maximum and
minimum values. Actually, of course, x and y are not independent; they are related
by the φ equation. However, (9.6) gives us a simple way of stating and remembering
how to get equations (9.4) and (9.5). Thus we can state the method of Lagrange
multipliers in the following way:
(9.7)
To ﬁnd the maximum or minimum values of f(x, y) when x and y
are related by the equation φ(x, y) = const., form the function
F(x, y) as in (9.6) and set the two partial derivatives of F equal to
zero [equations (9.4) and (9.5)]. Then solve these two equations and
the equation φ(x, y) = const. for the three unknowns x, y, and λ.
As a simple illustration of the method we shall do the problem of Example 1 by
Lagrange multipliers. Here
f(x, y) = x2 + y2,
φ(x, y) = y + x2 = 1,
and we write the equations to minimize
F(x, y) = f + λφ = x2 + y2 + λ(y + x2),

218
Partial Differentiation
Chapter 4
namely
∂F
∂x = 2x + λ · 2x = 0,
∂F
∂y = 2y + λ = 0.
(9.8)
We solve these simultaneously with the φ equation y + x2 = 1.
From the ﬁrst
equation in (9.8), either x = 0 or λ = −1. If x = 0, y = 1 from the φ equation (and
λ = −2). If λ = −1, the second equation gives y = 1
2, and then the φ equation
gives x2 = 1
2. These are the same values we had before. The method oﬀers nothing
new in testing whether we have found a maximum or a minimum, so we shall not
repeat that work; if it is possible to see from the geometry or the physics what we
have found, we don’t bother to test.
Lagrange multipliers simplify the work enormously in more complicated prob-
lems. Consider this problem.
Example 3.
Find the volume of the largest rectangular parallelepiped (that is, box), with
edges parallel to the axes, inscribed in the ellipsoid
x2
a2 + y2
b2 + z2
c2 = 1.
Let the point (x, y, z) be the corner in the ﬁrst octant where the box touches the
ellipsoid. Then (x, y, z) satisﬁes the ellipsoid equation and the volume of the box
is 8xyz (since there are 8 octants). Our problem is to maximize f(x, y, z) = 8xyz,
where x, y, z are related by the ellipsoid equation
φ(x, y, z) = x2
a2 + y2
b2 + z2
c2 = 1.
By the method of Lagrange multipliers we write
F(x, y, z) = f + λφ = 8xyz + λ
x2
a2 + y2
b2 + z2
c2

and set the three partial derivatives of F equal to 0:
∂F
∂x = 8yz + λ · 2x
a2 = 0,
∂F
∂y = 8xz + λ · 2y
b2 = 0,
∂F
∂z = 8xy + λ · 2z
c2 = 0.
We solve these three equations and the equation φ = 1 simultaneously for x, y,
z, and λ. (Although we don’t have to ﬁnd λ, it may be simpler to ﬁnd it ﬁrst.)
Multiply the ﬁrst equation by x, the second by y, and the third by z, and add to
get
3 · 8xyz + 2λ
x2
a2 + y2
b2 + z2
c2

= 0.

Section 9
Maximum and Minimum Problems with Constraints; Lagrange Multipliers
219
Using the equation of the ellipsoid, we can simplify this to
24xyz + 2λ = 0
or
λ = −12xyz.
Substituting λ into the ∂F/∂x equation, we ﬁnd that
8yz −12xyz · 2x
a2 = 0.
From the geometry it is clear that the corner of the box should not be where y or
z is equal to zero, so we divide by yz and solve for x, getting
x2 = 1
3a2.
The other two equations could be solved in the same way. However, it is pretty
clear from symmetry that the solutions will be y2 = 1
3b2 and z2 = 1
3c2. Then the
maximum volume is
8xyz = 8abc
3
√
3.
You might contrast this fairly simple algebra with what would be involved in
method (a). There you would have to solve the ellipsoid equation for, say, z, substi-
tute this into the volume formula, and then diﬀerentiate the square root. Even by
method (b) you would have to ﬁnd ∂z/∂x or similar expressions from the ellipsoid
equation.
We should show that the Lagrange multiplier method is justiﬁed for problems
involving several independent variables. We want to ﬁnd maximum or minimum
values of f(x, y, z) if φ(x, y, z) = const. (You might note at each step that the proof
could easily be extended to more variables.) We take diﬀerentials of both the f and
the φ equations. Since φ = const., we have dφ = 0. We put df = 0 because we want
maximum and minimum values of f. Thus we write
df = ∂f
∂xdx + ∂f
∂y dy + ∂f
∂z dz = 0,
dφ = ∂φ
∂xdx + ∂φ
∂y dy + ∂φ
∂z dz = 0.
(9.9)
We could ﬁnd dz from the dφ equation and substitute it into the df equation; this
corresponds to method (b) and may involve complicated algebra. Instead, we form
the sum F = f + λφ and ﬁnd, using (9.9),
dF = df + λ dφ
(9.10)
=
∂f
∂x + λ∂φ
∂x

dx +
∂f
∂y + λ∂φ
∂y

dy +
∂f
∂z + λ∂φ
∂z

dz.
There are two independent variables in this problem (since x, y, and z are related
by φ = const.). Suppose x and y are the independent ones; then z is determined
from the φ equation. Similarly, dx and dy may have any values we choose, and dz
is determined. Let us select λ so that
(9.11)
∂f
∂z + λ ∂φ
∂z = 0.

220
Partial Differentiation
Chapter 4
Then from (9.10), for dy = 0, we get
(9.12)
∂f
∂x + λ ∂φ
∂x = 0
and for dx = 0 we get
(9.13)
∂f
∂y + λ ∂φ
∂y = 0.
We can state a rule similar to (9.7) for obtaining equations (9.11), (9.12), and
(9.13).
(9.14)
To ﬁnd the maximum and minimum values of f(x, y, z) if
φ(x, y, z) = const., we form the function F = f + λφ and set the
three partial derivatives of F equal to zero. We solve these equa-
tions and the equation φ = const. for x, y, z, and λ. (For a problem
with still more variables there are more equations, but no change
in method.)
It is interesting to consider the geometric meaning of equations (9.9) to (9.13).
Recall that x, y, z are related by the equation φ(x, y, z) = const.
We might,
for example, think of solving the φ equation for z = z(x, y). Then x and y are
independent variables, and z is a function of them. Geometrically, z = z(x, y) is a
surface as in Figure 3.2. If we start at the point P of this surface (see Figure 3.2) and
increase x by dx, y by dy, and z by dz as given in equation (3.6), we are at a point
on the plane tangent to the surface at P. That is, the vector dr = idx + jdy + kdz
(−−→
PB in Figure 3.2) lies in the tangent plane of the surface. Now the second equation
in (9.9) is a dot product [see Chapter 3, equation (4.10)] of dr with the vector
i∂φ
∂x + j∂φ
∂y + k∂φ
∂z
(called the gradient of φ and written grad φ; see Chapter 6, Section 6ﬀ.). We could
write the second equation in (9.9) as dφ = (grad φ) · dr = 0. Recall [Chapter 3,
equation (4.12)] that if the dot product of two vectors is zero, the vectors are
perpendicular. Thus since dr lies anywhere in the plane tangent to the surface φ =
const., (9.9) says that grad φ is perpendicular to this plane, or perpendicular to
the surface φ = const. at P. The ﬁrst of equations (9.9) says that grad f is also
perpendicular to this plane. Thus grad φ and grad f are in the same direction, so
their components are proportional; this is what equations (9.11), (9.12), and (9.13)
say. We can also say that the surfaces φ = const. and f = const. are tangent to each
other at P; that is, they have the same tangent plane and their normals, grad φ
and grad f, are in the same direction.
We can also use the method of Lagrange multipliers if there are several conditions
(φ equations). Suppose we want to ﬁnd the maximum or minimum of f(x, y, z, w)
if φ1(x, y, z, w) = const. and φ2(x, y, z, w) = const.
There are two independent

Section 9
Maximum and Minimum Problems with Constraints; Lagrange Multipliers
221
variables, say x and y. We write
df = ∂f
∂x dx + ∂f
∂y dy + ∂f
∂z dz + ∂f
∂w dw = 0,
dφ1 = ∂φ1
∂x dx + ∂φ1
∂y dy + ∂φ1
∂z dz + ∂φ1
∂w dw = 0,
dφ2 = ∂φ2
∂x dx + ∂φ2
∂y dy + ∂φ2
∂z dz + ∂φ2
∂w dw = 0.
(9.15)
Again we could use the dφ1 and dφ2 equations to eliminate dz and dw from df
(method b), but the algebra is forbidding!
Instead, by the Lagrange multiplier
method we form the function F = f + λ1φ1 + λ2φ2 and write, using (9.15),
dF = df + λ1 dφ1 + λ2 dφ2
(9.16)
=
∂f
∂x + λ1
∂φ1
∂x + λ2
∂φ2
∂x

dx +
∂f
∂y + λ1
∂φ1
∂y + λ2
∂φ2
∂y

dy
+
∂f
∂z + λ1
∂φ1
∂z + λ2
∂φ2
∂z

dz +
 ∂f
∂w + λ1
∂φ1
∂w + λ2
∂φ2
∂w

dw.
We determine λ1 and λ2 from the two equations
∂f
∂z + λ1
∂φ1
∂z + λ2
∂φ2
∂z = 0,
∂f
∂w + λ1
∂φ1
∂w + λ2
∂φ2
∂w = 0.
(9.17)
Then for dy = 0, we have
(9.18)
∂f
∂x + λ1
∂φ1
∂x + λ2
∂φ2
∂x = 0
and for dx = 0, we have
(9.19)
∂f
∂y + λ1
∂φ1
∂y + λ2
∂φ2
∂y = 0.
As before, we can remember the method of ﬁnding (9.17), (9.18), and (9.19) by
thinking:
(9.20)
To ﬁnd the maximum or minimum of f subject to the conditions
φ1 = const. and φ2 = const., deﬁne F = f + λ1φ1 + λ2φ2 and
set each of the partial derivatives of F equal to zero. Solve these
equations and the φ equations for the variables and the λ’s.
Example 4.
Find the minimum distance from the origin to the intersection of xy = 6
with 7x + 24z = 0.
We are to minimize x2 + y2 + z2 subject to the two conditions xy = 6
and 7x + 24z = 0. By the Lagrange multiplier method, we ﬁnd the
three partial derivatives of
F = x2 + y2 + z2 + λ1(7x + 24z) + λ2xy

222
Partial Differentiation
Chapter 4
and set each of them equal to zero. We get
2x + 7λ1 + λ2y = 0,
2y + λ2x = 0,
2z + 24λ1 = 0.
(9.21)
These equations can be solved with xy = 6 and 7x + 24z = 0 to get (Problem 10)
x = ±12/5,
y = ±5/2,
z = ∓7/10.
Then the required minimum distance is (Problem 10)
d =

x2 + y2 + z2 = 5/
√
2 = 3.54.
PROBLEMS, SECTION 9
1.
What proportions will maximize the area shown in the ﬁgure (rectangle with isosceles
triangles at its ends) if the perimeter is given?
2.
What proportions will maximize the volume of a projectile in the form of a circular
cylinder with one conical end and one ﬂat end, if the surface area is given?
3.
Find the largest rectangular parallelepiped (box) that can be shipped by parcel post
(length plus girth = 108 in).
4.
Find the largest box (with faces parallel to the coordinate axes) that can be inscribed
in
x2
4 + y2
9 + z2
25 = 1.
5.
Find the point on 2x + 3y + z −11 = 0 for which 4x2 + y2 + z2 is a minimum.
6.
A box has three of its faces in the coordinate planes and one vertex on the plane
2x + 3y + 4z = 6. Find the maximum volume for the box.
7.
Repeat Problem 6 if the plane is ax + by + cz = d.
8.
A point moves in the (x, y) plane on the line 2x + 3y −4 = 0. Where will it be when
the sum of the squares of its distances from (1, 0) and (−1, 0) is smallest?
9.
Find the largest triangle that can be inscribed in the ellipse (x2/a2) + (y2/b2) = 1
(assume the triangle symmetric about one axis of the ellipse with one side perpen-
dicular to this axis).
10.
Complete Example 4 above.
11.
Find the shortest distance from the origin to the line of intersection of the planes
2x + y −z = 1 and x −y + z = 2.
12.
Find the right triangular prism of given volume and least area if the base is required
to be a right triangle.

Section 10
Endpoint or Boundary Point Problems
223
10. ENDPOINT OR BOUNDARY POINT PROBLEMS
So far we have been assuming that if there is a maximum or minimum point, calculus
will ﬁnd it. Some simple examples (see Figures 10.1 to 10.4) show that this may
not be true. Suppose, in a given problem, x can have values only between 0 and
1; this sort of restriction occurs frequently in applications. For example the graph
of f(x) = 2 −x2 exists for all real x, but if x = | cos θ|, θ real, the graph has no
meaning except for 0 ≤x ≤1. As another example, suppose x is the length of
a rectangle whose perimeter is 2; then x < 0 is meaningless in this problem since
x is a length, and x > 1 is impossible because the perimeter is 2.
Let us ask
for the largest and smallest values of each of the functions in Figures 10.1 to 10.4
for 0 ≤x ≤1. In Figure 10.1, calculus will give us the minimum point, but the
maximum of f(x) for x between 0 and 1 occurs at x = 1 and cannot be obtained
by calculus, since f ′(x) ̸= 0 there. In Figure 10.2, both the maximum and the
minimum of f(x) are at endpoints, the maximum at x = 0 and the minimum at
x = 1. In Figure 10.3 a relative maximum at P and a relative minimum at Q are
given by calculus, but the absolute minimum between 0 and 1 occurs at x = 0,
and the absolute maximum at x = 1. Here is a practical example of this sort of
function. It is said that geographers used to give as the highest point in Florida the
top of the highest hill; then it was found that the highest point is on the Alabama
border! [See H. A. Thurston, American Mathematical Monthly, vol. 68 (1961), pp.
650-652. A later paper, same journal, vol. 98, (1991), pp. 752-3, reports that the
high point is actually just south of the Alabama border, but gives another example
of a geographic boundary point maximum.] Figure 10.4 illustrates another way in
which calculus may fail to give us a desired maximum or minimum point; here the
derivative is discontinuous at the maximum point.
Figure 10.1
Figure 10.2
Figure 10.3
Figure 10.4
These are diﬃculties we must watch out for whenever there is any restriction
on the values any of the variables may take (or any discontinuity in the functions
or their derivatives). These restrictions are not usually stated in so many words;

224
Partial Differentiation
Chapter 4
you have to see them for yourself. For example, if x2 + y2 = 25, x and y are both
between −5 and +5. If y2 = x2 −1, then |x| must be greater than or equal to
1. If x = csc θ, where θ is a ﬁrst-quadrant angle, then x ≥1. If y = √x, y′ is
discontinuous at the origin.
Example1.
A piece of wire 40 cm long is to be used to form the perimeters of a square and
a circle in such a way as to make the total area (of square and circle) a maximum.
Call the radius of the circle r; then the circumference of the circle is 2πr. A length
40 −2πr is left for the four sides of the square, so one side is 10 −1
2πr. The total
area is
A = πr2 + (10 −1
2πr)2.
Then
dA
dr = 2πr + 2(10 −1
2πr)(−1
2π) = 2πr

1 + π
4
	
−10π.
If dA/dr = 0, we get
r

1 + π
4
	
= 5,
r = 2.8,
A = 56 + .
Now we might think that this is the maximum area. But let us apply the second
derivative test to see whether we have a maximum. We ﬁnd
d 2A
dr2 = 2π

1 + π
4
	
> 0;
we have found the minimum area! The problem asks for a maximum. One way to
ﬁnd it would be to sketch A as a function of r and look at the graph to see where
A has its largest value. A simpler way is this. A is a continuous function of r with
a continuous derivative. If there were an interior maximum (that is, one between
r = 0 and 2πr = 40), calculus would ﬁnd it. Therefore the maximum must be at
one end or the other.
At
r = 0,
A = 100.
At
2πr = 40,
r = 20/π,
A = 400/π = 127 + .
We see that A takes its largest value at r = 20/π; A = 400/π = 127+ is then the
desired maximum. It corresponds to using all the wire to make a circle; the side of
the square is zero.
A similar diﬃculty can arise in problems with more variables.
Example 2.
The temperature in a rectangular plate bounded by the lines x = 0, y = 0,
x = 3, and y = 5 is
T = xy2 −x2y + 100.
Find the hottest and coldest points of the plate.
We ﬁrst set the partial derivatives of T equal to zero to ﬁnd any interior maxima
and minima. We get
∂T
∂x = y2 −2xy = 0,
∂T
∂y = 2xy −x2 = 0.

Section 10
Endpoint or Boundary Point Problems
225
The only solution of these equations is x = y = 0, for which T = 100.
We must next ask whether there are points around the boundary of the plate
where T has a value larger or smaller than 100. To see that this might happen,
think of a graph of T plotted as a function of x and y; this is a surface above the
(x, y) plane. The mathematical surface does not have to stop at x = 3 and y = 5,
but it has no meaning for our problem beyond these values. Just as for the curves in
Figures 10.1 to 10.4, the graph of the temperature may be increasing or decreasing
as we cross a boundary; calculus will not then give us a zero derivative even though
the temperature at the boundary may be larger (or smaller) than at other points
of the plate. Thus we must consider the complete boundary of the plate (not just
the corners!). The lines x = 0, y = 0, x = 3, and y = 5 are the boundaries; we
consider each of them in turn. On x = 0 and y = 0 the temperature is 100. On the
line x = 3, we have
T = 3y2 −9y + 100.
We can use calculus to see whether T has maxima or minima as a function of y
along this line. We have
dT
dy = 6y −9 = 0,
y = 3
2,
T = 93 1
4.
Similarly, along the line y = 5, we ﬁnd
T = 25x −5x2 + 100,
dT
dx = 25 −10x = 0,
x = 5
2,
T = 131 1
4.
Finally, we must ﬁnd T at the corners.
At
(0, 0), (0, 5), and (3, 0),
T = 100.
At
(3, 5),
T = 130.
Putting all our results together, we see that the hottest point is ( 5
2, 5) with T =
131 1
4, and the coldest point is (3, 3
2) with T = 93 1
4.
Example 3.
Find the point or points closest to the origin on the surfaces
x2 −4yz = 8,
(10.1a)
z2 −x2 = 1.
(10.1b)
We want to minimize f = x2 + y2 + z2 subject to a condition [(a) or (b)]. If we
eliminate x2 in each case, we have
f = 8 + 4yz + y2 + z2,
(10.2a)
f = z2 −1 + y2 + z2 = 2z2 + y2 −1.
(10.2b)
In both problems (a) and (b) the mathematical function f(y, z) is deﬁned for all y
and z. For our problems, however, this is not true. In (a), since x2 ≥0, we have

226
Partial Differentiation
Chapter 4
x2 = 8 + 4yz ≥0 so we are interested in minimum values of f(y, z) in (a) only in
the region yz ≥−2. [Compare Example 2 where T (x, y) was of interest only inside
a rectangle.] Thus we look for “interior” minima in (a) satisfying yz ≥−2; then
we substitute z = −2/y into (10.2a) and ﬁnd any minima on the boundary of the
region of interest. In (b), since x2 = z2 −1 ≥0, we must have z2 ≥1. Again we
try to ﬁnd “interior” minima satisfying z2 ≥1; then we set z2 = 1 and look for
boundary minima. We now carry out these steps.
From (10.2a), we ﬁnd
(10.3a)
∂f
∂y = z + 2y = 0,
∂f
∂z = y + 2z = 0,









y = z = 0.
These values satisfy the condition yz > −2 and so give points inside the region of
interest. We ﬁnd from (10.1a), x2 = 8, x = ±2
√
2; the points are (±2
√
2, 0, 0) at
distance 2
√
2 from the origin. Next we consider the boundary x = 0, z = −2/y;
from (10.2a),
f = 0 + y2 + 4
y2 ,
df
dy = 2y −8
y3 = 0,
y4 = 4,
y = ±
√
2,
z = −2/y = ∓
√
2.
Remembering that x = 0, we have the points (0,
√
2, −
√
2) and (0, −
√
2,
√
2) at
distance 2 from the origin. Since 2 < 2
√
2, these boundary points are closest to the
origin.
(10.4a)
Answer to (a): (0,
√
2, −
√
2), (0, −
√
2,
√
2).
From (10.2b) we ﬁnd
(10.3b)
∂f
∂y = 2y = 0,
∂f
∂z = 4z = 0.









y = z = 0.
Since z = 0 does not satisfy z2 ≥1, there is no minimum point inside the region of
interest, so we look at the boundary z2 = 1. From (10.1b), x = 0, and from (10.2b)
f = y2 + 1,
df
dy = 2y = 0,
y = 0.
Thus we ﬁnd the points (0, 0, ±1) at distance 1 from the origin. Since the geometry
tells us that there must be a point or points closest to the origin, and calculus
tells us that these are the only possible minimum points, these must be the desired
points.
(10.4b)
Answer to (b): (0, 0, ±1).
In both these problems, we could have avoided having to consider the boundary
of the region of interest by eliminating z to obtain f as a function of x and y. Since

Section 10
Endpoint or Boundary Point Problems
227
x and y are allowed by (10.1a) or (10.1b) to take any values, there are no boundaries
to the region of interest. In (b) this is a satisfactory method; in (a) the algebra is
complicated. In both problems, Lagrange multipliers oﬀer a more routine method.
For example, in (a) we write
F = x2 + y2 + z2 + λ(x2 −4yz);
∂F
∂x = 2x(1 + λ) = 0,
x = 0 or λ = −1;
∂F
∂y = 2y −4λz = 0;
if λ = −1, y = z = 0, x2 = 8;
∂F
∂z = 2z −4λy = 0;
if x = 0, λ = y
2z = z
2y, y2 = z2 = 2.
We obtain the same results as above, namely, the points (±2
√
2, 0, 0), (0, ±
√
2, ∓
√
2);
the points (0,
√
2, −
√
2), (0, −
√
2,
√
2) are closer to the origin by inspection. Part (b)
can be done similarly (Problem 14).
We see that using Lagrange multipliers may simplify maximum and minimum
problems. However, the Lagrange multiplier method still relies on calculus; conse-
quently, it can work only if the maximum and minimum can be found by calculus
using some set of variables (x and y, not y and z, in Example 3). For example,
a problem in which the maximum or minimum occurs at endpoints in all variables
cannot be done by any method that depends on setting derivatives equal to zero.
Example 4.
Find the maximum value of y −x for nonnegative x and y if x2 + y2 = 1.
Here we must have both x and y between 0 and 1. Then the values y = 1 and
x = 0 give y −x its largest value; these are both endpoint values which cannot be
found by calculus.
PROBLEMS, SECTION 10
1.
Find the shortest distance from the origin to x2 −y2 = 1.
2.
Find the largest and smallest distances from the origin to the conic whose equation
is 5x2 −6xy + 5y2 −32 = 0 and hence determine the lengths of the semiaxes of this
conic.
3.
Repeat Problem 2 for the conic 6x2 + 4xy + 3y2 = 28.
Find the shortest distance from the origin to each of the following quadric surfaces. Hint:
See Example 3 above.
4.
3x2 + y2 −4xz = 4.
5.
2z2 + 6xy = 3.
6.
4y2 + 2z2 + 3xy = 18.
7.
Find the largest z for which 2x + 4y = 5 and x2 + z2 = 2y.
8.
If the temperature at the point (x, y, z) is T = xyz, ﬁnd the hottest point (or points)
on the surface of the sphere x2 + y2 + z2 = 12, and ﬁnd the temperature there.
9.
The temperature T of the disk x2 + y2 ≤1 is given by T = 2x2 −3y2 −2x. Find
the hottest and coldest points of the disk.

228
Partial Differentiation
Chapter 4
10.
The temperature at a point (x, y, z) in the ball x2+y2+z2 ≤1 is given by T = y2+xz.
Find the largest and smallest values which T takes
(a)
on the circle y = 0, x2 + z2 = 1,
(b)
on the surface x2 + y2 + z2 = 1,
(c)
in the whole ball.
11.
The temperature of a rectangular plate bounded by the lines x = ±1, y = ±1, is
given by T = 2x2 −3y2 −2x + 10. Find the hottest and coldest points of the plate.
12.
Find the largest and smallest values of the sum of the acute angles that a line
through the origin makes with the three coordinate axes.
13.
Find the largest and smallest values of the sum of the acute angles that a line
through the origin makes with the three coordinate planes.
14.
Do Example 3b using Lagrange multipliers.
11. CHANGE OF VARIABLES
One important use of partial diﬀerentiation is in making changes of variables (for
example, from rectangular to polar coordinates). This may give a simpler expression
or a simpler diﬀerential equation or one more suited to the physical problem one is
doing. For example, if you are working with the vibration of a circular membrane,
or the ﬂow of heat in a circular cylinder, polar coordinates are better; for a problem
about sound waves in a room, rectangular coordinates are better. Consider the
following problems.
Example 1.
Make the change of variables r = x + vt, s = x −vt in the wave equation
(11.1)
∂2F
∂x2 −1
v2
∂2F
∂t2 = 0,
and solve the equation. (Also see Chapter 13, Sections 1, 4, and 6.)
We use the equations
r = x + vt,
s = x −vt,
(11.2)
and equations like (7.2) to ﬁnd
∂F
∂x = ∂F
∂r
∂r
∂x + ∂F
∂s
∂s
∂x = ∂F
∂r + ∂F
∂s =
 ∂
∂r + ∂
∂s

F,
∂F
∂t = ∂F
∂r
∂r
∂t + ∂F
∂s
∂s
∂t = v ∂F
∂r −v ∂F
∂s = v
 ∂
∂r −∂
∂s

F.
(11.3)
It is helpful to say in words what we have written in (11.3): To ﬁnd the partial of a
function with respect to x, we ﬁnd its partial with respect to r plus its partial with
respect to s; to ﬁnd the partial with respect to t, we ﬁnd the partial with respect
to r minus the partial with respect to s and multiply by the constant v. It is useful
to write this in operator notation (see Chapter 3, Section 7):
(11.4)
∂
∂x = ∂
∂r + ∂
∂s,
∂
∂t = v
 ∂
∂r −∂
∂s

.

Section 11
Change of Variables
229
Then from (11.3) and (11.4) we ﬁnd
∂2F
∂x2 = ∂
∂x
∂F
∂x

=
 ∂
∂r + ∂
∂s
 ∂F
∂r + ∂F
∂s

= ∂2F
∂r2 + 2 ∂2F
∂r∂s + ∂2F
∂s2 ,
∂2F
∂t2 = ∂
∂t
∂F
∂t

= v
 ∂
∂r −∂
∂s
 
v ∂F
∂r −v ∂F
∂s

= v2
∂2F
∂r2 −2 ∂2F
∂r∂s + ∂2F
∂s2

.
(11.5)
Substitute (11.5) into (11.1) to get
(11.6)
∂2F
∂x2 −1
v2
∂2F
∂t2 = 4 ∂2F
∂r∂s = 0.
We can easily solve (11.6). We have
∂2F
∂r∂s = ∂
∂r
∂F
∂s

= 0,
that is, the r derivative of ∂F/∂s is zero. Then ∂F/∂s must be independent of
r, so ∂F/∂s = some function of s alone. We integrate with respect to s to ﬁnd
F = f(s)+“const.”; the “constant” is a constant as far as s is concerned, but it
may be any function of r, say g(r), since (∂/∂s)g(r) = 0. Thus we ﬁnd that the
solution of (11.6) is
(11.7)
F = f(s) + g(r).
Then, using (11.2), we ﬁnd the solution of (11.1):
(11.8)
F = f(x −vt) + g(x + vt),
where f and g are arbitrary functions. This is known as d’Alembert’s solution of
the wave equation. Also see Problem 7.23 and Chapter 13, Problem 1.2.
Example 2.
Write the Laplace equation
(11.9)
∂2F
∂x2 + ∂2F
∂y2 = 0
in terms of polar coordinates r, θ, where
x = r cos θ,
y = r sin θ.
(11.10)
Note that equations (11.10) give the old variables x and y in terms of the new ones,
r and θ, whereas (11.2) gave the new variables r and s in terms of the old ones.
In this situation, there are several ways to get equations like (11.3). One way is to
write
∂F
∂r = ∂F
∂x
∂x
∂r + ∂F
∂y
∂y
∂r = cos θ ∂F
∂x + sin θ ∂F
∂y ,
∂F
∂θ = ∂F
∂x
∂x
∂θ + ∂F
∂y
∂y
∂θ = −r sin θ ∂F
∂x + r cos θ ∂F
∂y ,
(11.11)

230
Partial Differentiation
Chapter 4
and then solve (11.11) for ∂F/∂x and ∂F/∂y (Problem 5). Another way is to ﬁnd
the needed partial derivatives of r and θ with respect to x and y [for methods and
results, see Section 7, Example 6, equation (7.16) and Problem 7.9] and then write
as in (11.3), using (7.16),
∂F
∂x = ∂F
∂r
∂r
∂x + ∂F
∂θ
∂θ
∂x = cos θ ∂F
∂r −sin θ
r
∂F
∂θ ,
∂F
∂y = ∂F
∂r
∂r
∂y + ∂F
∂θ
∂θ
∂y = sin θ ∂F
∂r + cos θ
r
∂F
∂θ .
(11.12)
In ﬁnding the second derivatives, it will be convenient to use the abbreviations
G = ∂F/∂x and H = ∂F/∂y. Thus,
G = ∂F
∂x = cos θ ∂F
∂r −sin θ
r
∂F
∂θ ,
H = ∂F
∂y = sin θ ∂F
∂r + cos θ
r
∂F
∂θ .
(11.13)
Then
(11.14)
∂2F
∂x2 = ∂G
∂x ,
∂2F
∂y2 = ∂H
∂y ,
so
∂2F
∂x2 + ∂2F
∂y2 = ∂G
∂x + ∂H
∂y .
Now equations (11.12) are correct for any function F; in particular they are correct
if we replace F by G or by H. Let us replace F by G in the ﬁrst equation (11.12)
and replace F by H in the second equation. Then we have
∂G
∂x = cos θ ∂G
∂r −sin θ
r
∂G
∂θ ,
∂H
∂y = sin θ ∂H
∂r + cos θ
r
∂H
∂θ .
(11.15)
Substituting (11.15) into (11.14), we get
(11.16)
∂2F
∂x2 + ∂2F
∂y2 = cos θ ∂G
∂r + sin θ ∂H
∂r + 1
r

cos θ ∂H
∂θ −sin θ ∂G
∂θ

.
We ﬁnd the four partial derivatives of G and H which we need in (11.16), by
diﬀerentiating the right-hand sides of equations (11.13).
∂G
∂r = cos θ ∂2F
∂r2 −sin θ
r
∂2F
∂r∂θ + sin θ
r2
∂F
∂θ ,
∂H
∂r = sin θ ∂2F
∂r2 + cos θ
r
∂2F
∂r∂θ −cos θ
r2
∂F
∂θ ,
∂H
∂θ = sin θ ∂2F
∂θ∂r + cos θ∂F
∂r + cos θ
r
∂2F
∂θ2 −sin θ
r
∂F
∂θ ,
∂G
∂θ = cos θ ∂2F
∂θ∂r −sin θ∂F
∂r −sin θ
r
∂2F
∂θ2 −cos θ
r
∂F
∂θ .
(11.17)
We combine these to obtain the expressions needed in (11.16):
cos θ ∂G
∂r + sin θ ∂H
∂r = ∂2F
∂r2 ,
1
r

cos θ ∂H
∂θ −sin θ ∂G
∂θ

= 1
r
∂F
∂r + 1
r
∂2F
∂θ2

.
(11.18)

Section 11
Change of Variables
231
Finally, substituting (11.18) into (11.16) gives
∂2F
∂x2 + ∂2F
∂y2 = ∂2F
∂r2 + 1
r
∂F
∂r + 1
r2
∂2F
∂θ2
= 1
r
∂
∂r

r∂F
∂r

+ 1
r2
∂2F
∂θ2 .
(11.19)
We next discuss a simple kind of change of variables which is very useful in
thermodynamics and mechanics. This process is sometimes known as a Legendre
transformation. Suppose we are given a function f(x, y); then we can write
(11.20)
df = ∂f
∂xdx + ∂f
∂y dy.
Let us call ∂f/∂x = p, and ∂f/∂y = q; then we have
(11.21)
df = p dx + q dy.
If we now subtract from df the quantity d(qy), we have
df −d(qy) = p dx + q dy −q dy −y dq
or
d(f −qy) = p dx −y dq.
(11.22)
If we deﬁne the function g by
(11.23)
g = f −qy,
then by (11.22)
(11.24)
dg = p dx −y dq.
Because dx and dq appear in (11.24), it is convenient to think of g as a function of
x and q. The partial derivatives of g are then of simple form, namely,
(11.25)
∂g
∂x = p,
∂g
∂q = −y.
Similarly, we could replace the p dx term in df by −x dp by considering the function
f −xp. This sort of change of independent variables is called a Legendre transfor-
mation. (For applications, see Problems 10 to 13.) For a discussion of Legendre
transformations, see Callen, Chapter 5.
From the equations above, we can ﬁnd useful relations between partial deriva-
tives. For example, from equations (11.24) and (11.25) we can write
(11.26)
∂2g
∂q∂x =
∂p
∂q

x
and
∂2g
∂x∂q = −
∂y
∂x

q
.
Assuming ∂2g
∂q∂x = ∂2g
∂x∂q (reciprocity relations, see end of Section 1), then we have
(11.27)
∂p
∂q

x
= −
∂y
∂x

q
.
Many equations like these appear in thermodynamics (see Problems 12 and 13).

232
Partial Differentiation
Chapter 4
PROBLEMS, SECTION 11
1.
In the partial diﬀerential equation
∂2z
∂x2 −5 ∂2z
∂x∂y + 6∂2z
∂y2 = 0
put s = y + 2x, t = y + 3x and show that the equation becomes ∂2z/∂s∂t = 0.
Following the method of solving (11.6), solve the equation.
2.
As in Problem 1, solve
2 ∂2z
∂x2 + ∂2z
∂x∂y −10∂2z
∂y2 = 0
by making the change of variables u = 5x −2y, v = 2x + y.
3.
Suppose that w = f(x, y) satisﬁes
∂2w
∂x2 −∂2w
∂y2 = 1.
Put x = u + v, y = u −v, and show that w satisﬁes ∂2w/∂u∂v = 1. Hence solve the
equation.
4.
Verify the chain rule formulas
∂F
∂x = ∂F
∂r
∂r
∂x + ∂F
∂θ
∂θ
∂x,
and similar formulas for
∂F
∂y ,
∂F
∂r ,
∂F
∂θ ,
using diﬀerentials. For example, write
dF = ∂F
∂r dr + ∂F
∂θ dθ
and substitute for dr and dθ:
dr = ∂r
∂xdx + ∂r
∂y dy
(and similarly dθ).
Collect coeﬃcients of dx and dy; these are the values of ∂F/∂x and ∂F/∂y.
5.
Solve equations (11.11) to get equations (11.12).
6.
Reduce the equation
x2
„ d2y
dx2
«
+ 2x
„ dy
dx
«
−5y = 0
to a diﬀerential equation with constant coeﬃcients in d2y/dz2, dy/dz, and y by the
change of variable x = ez. (See Chapter 8, Section 7d.)
7.
Change the independent variable from x to θ by x = cos θ and show that the
Legendre equation
(1 −x2) d2y
dx2 −2x dy
dx + 2y = 0
becomes
d2y
dθ2 + cot θ dy
dθ + 2y = 0.

Section 12
Differentiation of Integrals; Leibniz’ Rule
233
8.
Change the independent variable from x to u = 2√x in the Bessel equation
x2 d2y
dx2 + x dy
dx −(1 −x)y = 0
and show that the equation becomes
u2 d2y
du2 + u dy
du + (u2 −4)y = 0.
9.
If x = es cos t, y = es sin t, show that
∂2u
∂x2 + ∂2u
∂y2 = e−2s
„∂2u
∂s2 + ∂2u
∂t2
«
.
10.
Given du = T ds −p dv, ﬁnd a Legendre transformation giving
(a)
a function f(T, v);
(b)
a function h(s, p);
(c)
a function g(T, p).
Hint for (c): Perform a Legendre transformation on both terms in du.
11.
Given L(q, ˙q) such that dL = ˙p dq + p d ˙q, ﬁnd H(p, q) so that dH = ˙q dp −˙p dq.
Comments: L and H are functions used in mechanics called the Lagrangian and
the Hamiltonian. The quantities ˙q and ˙p are actually time derivatives of p and q,
but you make no use of the fact in this problem. Treat ˙p and ˙q as if they were
two more variables having nothing to do with p and q.
Hint:
Use a Legendre
transformation.
On your ﬁrst try you will probably get −H.
Look at the text
discussion of Legendre transformations and satisfy yourself that g = qy −f would
have been just as satisfactory as g = f −qy in (11.23).
12.
Using du in Problem 10, and the text method of obtaining (11.27), show that
„∂T
∂v
«
s
= −
„∂p
∂s
«
v
. (This is one of the Maxwell relations in thermodynamics.)
13.
As in Problem 12, ﬁnd three more Maxwell relations by using your results in Problem
10, parts (a), (b), (c).
12. DIFFERENTIATION OF INTEGRALS; LEIBNIZ’ RULE
According to the deﬁnition of an integral as an antiderivative, if
(12.1)
f(x) = dF(x)
dx
,
then
(12.2)
 x
a
f(t) dt = F(t)

x
a
= F(x) −F(a),
where a is a constant. If we diﬀerentiate (12.2) with respect to x, we have
(12.3)
d
dx
 x
a
f(t) dt = d
dx[F(x) −F(a)] = dF(x)
dx
= f(x)
by (12.1). Similarly,
 a
x
f(t) dt = F(a) −F(x),
so
(12.4)
d
dx
 a
x
f(t) dt = −dF(x)
dx
= −f(x).

234
Partial Differentiation
Chapter 4
Example 1.
Find d
dx
 x
π/4
sin t dt.
By (12.3), we ﬁnd immediately that the answer is sin x. We can check this by
ﬁnding the integral and then diﬀerentiating. We get
 x
π/4
sin t dt = −cos t

x
π/4
= −cos x + 1
2
√
2
and the derivative of this is sin x as before.
By replacing x in (12.3) by v, and replacing x in (12.4) by u, we can then write
(12.5)
d
dv
 v
a
f(t) dt = f(v)
and
(12.6)
d
du
 b
u
f(t) dt = −f(u).
Suppose u and v are functions of x and we want dI/dx where
I =
 v
u
f(t) dt.
When the integral is evaluated, the answer depends on the limits u and v. Finding
dI/dx is then a partial diﬀerentiation problem; I is a function of u and v, which
are functions of x. We can write
(12.7)
dI
dx = ∂I
∂u
du
dx + ∂I
∂v
dv
dx.
But ∂I/∂v means to diﬀerentiate I with respect to v when u is a constant; this is
just (12.5), so ∂I/∂v = f(v). Similarly, ∂I/∂u means that v is constant and we can
use (12.6) to get ∂I/∂u = −f(u). Then we have
(12.8)
d
dx
 v(x)
u(x)
f(t) dt = f(v) dv
dx −f(u) du
dx.
Example 2.
Find dI/dx if I =
 x1/3
0
t2 dt.
By (12.8) we get
dI
dx = (x1/3)2 d
dx (x1/3) = x2/3 · 1
3x−2/3 = 1
3.
We could also integrate ﬁrst and then diﬀerentiate with respect to x:
I =
 x1/3
0
t2dt = t3
3

x1/3
0
= x
3 ,
dI
dx = 1
3.
This last method seems so simple you may wonder why we need (12.8). Look
at another example.

Section 12
Differentiation of Integrals; Leibniz’ Rule
235
Example 3.
Find dI/dx if
I =
 sin−1 x
x2
sin t
t
dt.
Here the indeﬁnite integral cannot be evaluated in terms of elementary functions;
however, we can ﬁnd dI/dx by using (12.8). We get
dI
dx = sin(sin−1 x)
sin−1 x
1
√
1 −x2 −sin x2
x2
· 2x
=
x
√
1 −x2 sin−1 x
−2
x sin x2.
Finally, we may want to ﬁnd dI/dx when I =
 b
a f(x, t) dt, where a and b are
constants. Under not too restrictive conditions,
(12.9)
d
dx
 b
a
f(x, t) dt =
 b
a
∂f(x, t)
∂x
dt;
that is, we can diﬀerentiate under the integral sign. [A set of suﬃcient conditions
for this to be correct would be that
 b
a f(x, t) dt exists, ∂f/∂x is continuous and
|∂f(x, t)/∂x| ≤g(t), where
 b
a g(t) dt exists. For most practical purposes this means
that if both integrals in (12.9) exist, then (12.9) is correct.] Equation (12.9) is often
useful in evaluating deﬁnite integrals.
Example 4.
Find
 ∞
0
tne−kt2dt for odd n, k > 0.
First we evaluate the integral
I =
 ∞
0
te−kt2dt = −1
2ke−kt2
∞
0
= 1
2k.
Now we calculate successive derivatives of I with respect to k.
dI
dk =
 ∞
0
−t2te−kt2 dt = −1
2k2
or
 ∞
0
t3e−kt2dt =
1
2k2 .
Repeating the diﬀerentiation with respect to k, we get
 ∞
0
−t2t3e−kt2dt = −2
2k3
or
 ∞
0
t5e−kt2dt = 1
k3 .
 ∞
0
−t2t5e−kt2dt = −3
k4
or
 ∞
0
t7e−kt2 = 3
k4 .
Continuing in this way (Problem 17), we can ﬁnd the integral of any odd power of
t times e−kt2:
(12.10)
 ∞
0
t2n+1e−kt2dt =
n!
2kn+1 .
Your computer may give you this result in terms of the gamma function (see Chapter
11, Sections 1 to 5). The relation is n! = Γ(n + 1).

236
Partial Differentiation
Chapter 4
Example 5.
Evaluate
(12.11)
I =
 1
0
ta −1
ln t
dt,
a > −1.
First we diﬀerentiate I with respect to a, and evaluate the resulting integral.
dI
da =
 1
0
ta ln t
ln t dt =
 1
0
ta dt = ta+1
a + 1

1
0
=
1
a + 1.
Now we integrate dI/da with respect to a to get I back again (plus an integration
constant):
(12.12)
I =

da
a + 1 = ln(a + 1) + C.
If a = 0, (12.11) gives I = 0 and (12.12) gives I = C, so C = 0 and we have from
(12.12), I = ln(a + 1).
It is convenient to collect formulas (12.8) and (12.9) into one formula known as
Leibniz’ rule:
(12.13)
d
dx
 v(x)
u(x)
f(x, t) dt = f(x, v)dv
dx −f(x, u)du
dx +
 v
u
∂f
∂x dt.
Example 6.
Find dI/dx if
I =
 2x
x
ext
t dt.
By (12.13) we get
dI
dx = ex·2x
2x
· 2 −ex·x
x
· 1 +
 2x
x
text
t
dt
= 1
x(e2x2 −ex2) +
ext
x
2x
x
= 1
x(e2x2 −ex2 + e2x2 −ex2) = 2
x(e2x2 −ex2).
Although you can do problems like this by computer, in many cases you can just
write down the answer using (12.13) in less time than it takes to type the problem
into the computer.
PROBLEMS, SECTION 12
1.
If y =
Z √x
0
sin t2dt, ﬁnd dy/dx.
2.
If s =
Z v
u
1 −et
t
dt, ﬁnd ∂s/∂v and ∂s/∂u and also their limits as u and v tend to
zero.

Section 12
Differentiation of Integrals; Leibniz’ Rule
237
3.
If z =
Z cos x
sin x
sin t
t
dt, ﬁnd
dz
dx.
4.
Use L’Hˆopital’s rule to evaluate
lim
x→2
1
x −2
Z x
2
sin t
t
dt.
5.
If u =
Z y−x
x
sin t
t
dt, ﬁnd
∂u
∂x, ∂u
∂y , and ∂y
∂x at x = π/2, y = π.
Hint:
Use diﬀerentials.
6.
If w =
Z 2x−3y
xy
du
ln u, ﬁnd
∂w
∂x , ∂w
∂y , and ∂y
∂x at x = 3, y = 1.
7.
If
Z v
u
e−t2dt = x and uv = y, ﬁnd
„∂u
∂x
«
y
,
„∂u
∂y
«
x
, and
„ ∂y
∂x
«
u
at u = 2, v = 0.
8.
If
Z x
0
e−s2ds = u, ﬁnd dx
du.
9.
If y =
Z π
0
sin xt dt, ﬁnd dy/dx
(a) by evaluating the integral and then diﬀerenti-
ating, (b) by diﬀerentiating ﬁrst and then evaluating the integral.
10.
Find dy/dx explicitly if y =
Z 1
0
exu −1
u
du.
11.
Find d
dx
Z x2
3−x
(x −t) dt by evaluating the integral ﬁrst, and by diﬀerentiating ﬁrst.
12.
Find d
dx
Z x2
x
du
ln(x + u).
13.
Find d
dx
Z 2/x
1/x
sin xt
t
dt.
14.
Given that
Z ∞
0
dx
y2 + x2 = π
2y , diﬀerentiate with respect to y and so evaluate
Z ∞
0
dx
(y2 + x2)2 .
15.
Given that
Z ∞
0
e−ax sin kx dx =
k
a2 + k2 ,
diﬀerentiate with respect to a to show that
Z ∞
0
xe−ax sin kx dx =
2ka
(a2 + k2)2
and diﬀerentiate with respect to k to show that
Z ∞
0
xe−ax cos kx dx =
a2 −k2
(a2 + k2)2 .
16.
In kinetic theory we have to evaluate integrals of the form I =
Z ∞
0
tne−at2 dt. Given
that
Z ∞
0
e−at2dt = 1
2
p
π/a , evaluate I for n = 2, 4, 6, · · · , 2m.
17.
Complete Example 4 to obtain (12.10).

238
Partial Differentiation
Chapter 4
18.
Show that u(x, y) = y
π
Z ∞
−∞
f(t) dt
(x −t)2 + y2 satisﬁes uxx + uyy = 0.
19.
Show that y =
Z x
0
f(u) sin(x −u) du satisﬁes y′′ + y = f(x).
20.
(a)
Show that y =
Z x
0
f(x −t) dt satisﬁes (dy/dx) = f(x). (Hint: It is helpful to
make the change of variable x −t = u in the integral.)
(b)
Show that y =
Z x
0
(x −u)f(u) du satisﬁes y′′ = f(x).
(c)
Show that y =
1
(n −1)!
Z x
0
(x −u)n−1f(u) du satisﬁes y(n) = f(x).
13. MISCELLANEOUS PROBLEMS
1.
A function f(x, y, z) is called homogeneous of degree n if f(tx, ty, tz) = tnf(x, y, z).
For example, z2 ln(x/y) is homogeneous of degree 2 since
(tz)2 ln tx
ty = t2
„
z2 ln x
y
«
.
Euler’s theorem on homogeneous functions says that if f is homogeneous
of degree n, then
x∂f
∂x + y ∂f
∂y + z ∂f
∂z = nf.
Prove this theorem. Hints: Diﬀerentiate f(tx, ty, tz) = tnf(x, y, z) with respect to
t, and then let t = 1. It is convenient to call ∂f/∂(tx) = f1 (that is, the partial
derivative of f with respect to its ﬁrst variable), f2 = ∂f/∂(ty), and so on. Or, you
can at ﬁrst call tx = u, ty = v, tz = w. (Both the deﬁnition and the theorem can
be extended to any number of variables.)
2.
(a)
Given the point (2, 1) in the (x, y) plane and the line 3x + 2y = 4, ﬁnd the
distance from the point to the line by using the method of Chapter 3, Section 5.
(b)
Solve part (a) by writing a formula for the distance from (2, 1) to (x, y) and
minimizing the distance (use Lagrange multipliers).
(c)
Derive the formula
D =
˛˛˛˛
ax0 + by0 −c
√
a2 + b2
˛˛˛˛
for the distance from (x0, y0) to ax+by = c by the methods suggested in parts
(a) and (b).
In Problems 3 to 6, assume that x, y and r, θ are rectangular and polar coordinates.
3.
Find
∂2y
∂x∂θ .
4.
Find
∂2r
∂θ∂y .
5.
Given z = y2 −2x2, ﬁnd
„ ∂z
∂x
«
r
,
„∂z
∂θ
«
x
,
∂2z
∂x∂θ .
6.
If z = r2 −x2, ﬁnd
„∂z
∂r
«
θ
,
„∂z
∂θ
«
r
,
∂2z
∂r∂θ ,
„ ∂z
∂x
«
y
.
7.
About how much (in percent) does an error of 1% in x and y aﬀect x3y2?

Section 13
Miscellaneous problems
239
8.
Assume that the earth is a perfect sphere. Suppose that a rope lies along the equator
with its ends fastened so that it ﬁts exactly. Now let the rope be made 2 ft longer,
and let it be held up the same distance above the surface of the Earth at all points
of the equator. About how high up is it? (For example, could you crawl under?
Could a ﬂy?) Answer the same questions for the moon.
9.
If z = xy and
(
2x3 + 2y3 = 3t2,
3x2 + 3y2 = 6t,
ﬁnd dz/dt.
10.
If w = (r cos θ)r sin θ, ﬁnd ∂w/∂θ.
11.
If x2
a2 + y2
b2 = 1, ﬁnd dy
dx and d2y
dx2
by implicit diﬀerentiation.
12.
Given z = r2 + s2 + rst, r4 + s4 + t4 = 2r2s2t2 + 10, ﬁnd (∂z/∂r)t when r = 2,
s = t = 1.
13.
Given
(
2t + ex = s −cos y −2,
2s −t = sin y + x −1,
ﬁnd
„∂s
∂t
«
y
at (x, y, s, t) = (0, π/2, −1, −2).
14.
If w = f(x, s, t), s = 2x + y, t = 2x −y, ﬁnd (∂w/∂x)y in terms of f and its
derivatives.
15.
If w = f(x, x2 + y2, 2xy), ﬁnd (∂w/∂x)y (compare Problem 14).
16.
If z = 1
xf
“y
x
”
, prove that x ∂z
∂x + y ∂z
∂y + z = 0.
17.
Find the shortest distance from the origin to the surface x = yz + 10.
18.
Find the shortest distance from the origin to the line of intersection of the planes
2x −3y + z = 5,
3x −y −2z = 11,
(a)
using vector methods (see Chapter 3, Section 5);
(b)
using Lagrange multipliers.
19.
Find by the Lagrange multiplier method the largest value of the product of three
positive numbers if their sum is 1.
20.
Find the largest and smallest values of y = 4x3 + 9x2 −12x + 3 if x = cos θ.
21.
Find the hottest and coldest points on a bar of length 5 if T = 4x −x2, where x is
the distance measured from the left end.
22.
Find the hottest and coldest points of the region y2 ≤x < 5 if T = x2 −y2 −3x.
23.
Find d
dt
Z sin t
0
sin−1 x
x
dx.
24.
Find d
dx
Z t=2/x
t=1/x
cosh xt
t
dt.
25.
Find d
dx
Z 1/x
1
ext
t dt.
26.
Find d
dx
Z x2
0
sin xt
t
dt.
27.
Show that d
dx
Z sin x
cos x
p
1 −t2 dt = 1.
28.
In discussing the velocity distribution of molecules of an ideal gas, a function
F(x, y, z) = f(x)f(y)f(z) is needed such that d(ln F) = 0 when φ = x2 + y2 + z2 =
const. Then by the Lagrange multiplier method d(ln F + λφ) = 0. Use this to show
that
F(x, y, z) = Ae−(λ/2)(x2+y2+z2).

240
Partial Differentiation
Chapter 4
29.
The time dependent temperature at a point of a long bar is given by
T(t) = 100◦
 
1 −
2
√π
Z 8/
√
t
0
e−τ2dτ
!
.
When t = 64, T = 15.73◦. Use diﬀerentials to estimate how long it will be until
T = 17◦.
30.
Evaluate d2
dx2
Z x
0
Z x
0
f(s, t) ds dt.

C H A P T E R 5
Multiple Integrals;
Applications of Integration
1. INTRODUCTION
In calculus and elementary physics, you have seen a number of uses for integration
such as ﬁnding area, volume, mass, moment of inertia, and so on. In this chapter we
want to consider these and other applications of both single and multiple integrals.
We shall discuss both how to set up integrals to represent physical quantities and
methods of evaluating them. In later chapters we will need to use both single and
multiple integrals.
Computers and integral tables are very useful in evaluating integrals. But to use
these tools eﬃciently, you need to understand the notation and meaning of integrals
which we will discuss in this chapter. There is another important point here. A
computer will give you an answer for a deﬁnite integral, but an indeﬁnite integral
has many possible answers (diﬀering from each other by a constant of integration),
and your computer or integral tables may not give you the form you need. (See
problems below.) If this happens, here are some ideas you can try:
(a) Look in other integral tables, or try to induce your computer to change the
form.
(b) See if some algebra will give the form you want (see Problem 1 below; also see
Chapter 2, Section 15, Example 2).
(c) A simple substitution may give the desired result (see Problem 2 below).
(d) To check a claimed answer, diﬀerentiate it (by hand or computer) to see whether
you get the integrand.
PROBLEMS, SECTION 1
Verify each of the following answers for an indeﬁnite integral by one or more of the methods
suggested above.
241

242
Multiple Integrals; Applications of Integration
Chapter 5
1.
Z
2 sin θ cos θ dθ = sin2 θ
or
−cos2 θ
or
−1
2 cos 2θ. Hint: Use trig identities.
2.
Z
dx
√
x2 + a2 = sinh−1 x
a
or
ln
“
x +
p
x2 + a2
”
.
Hint: To ﬁnd the sinh−1 form,
make the substitution x = a sinh u. Or see Chapter 2, Sections 15 and 17.
3.
Z
dy
p
y2 −a2 = cosh−1 y
a
or
ln
“
y +
p
y2 −a2
”
.
Hint: See Problem 2 hints.
4.
Z p
1 + a2x2 dx = x
2
p
1 + a2x2 + 1
2a sinh−1 ax
or
x
2
p
1 + a2x2 + 1
2a ln
“
ax +
p
1 + a2x2
”
.
5.
Z
K dr
√
1 −K2r2 = sin−1 Kr
or
−cos−1 Kr
or
tan−1
Kr
√
1 −K2r2 .
Hints: Sketch a right triangle with acute angles u and v and label the sides so that
sin u = Kr. Also note that u + v = π/2; then if u is an indeﬁnite integral, so is −v
since they diﬀer by a constant of integration.
6.
Z
K dr
r
√
r2 −K2 = cos−1 K
r
or sec−1 r
K
or −sin−1 K
r
or −tan−1
K
√
r2 −K2 .
2. DOUBLE AND TRIPLE INTEGRALS
Recall from calculus that
 b
a y dx =
 b
a f(x) dx
gives the area “under the curve” in Figure 2.1.
Recall also the deﬁnition of the integral as the
limit of a sum: We approximate the area by
a sum of rectangles as in Figure 2.1; a rep-
resentative rectangle (shaded) has width ∆x.
The geometry indicates that if we increase the
number of rectangles and let all the widths
∆x →0, the sum of the areas of the rectan-
gles will tend to the area under the curve. We deﬁne
 b
a f(x) dx as the limit of the
sum of the areas of the rectangles; then we evaluate the integral as an antiderivative,
and use
 b
a f(x) dx to calculate the area under the curve.
Figure 2.1
Figure 2.2
We are going to do something very similar
in order to ﬁnd the volume of the cylinder in
Figure 2.2 under the surface z = f(x, y). We
cut the (x, y) plane into little rectangles of area
∆A = (∆x) (∆y) as shown in Figure 2.2; above
each ∆x ∆y is a tall slender box reaching up to
the surface.
We can approximate the desired
volume by a sum of these boxes just as we ap-
proximated the area in Figure 2.1 by a sum of
rectangles. As the number of boxes increases
and all ∆x and ∆y →0, the geometry indi-
cates that the sum of the volumes of the boxes
will tend to the desired volume. We deﬁne the

Section 2
Double and Triple Integrals
243
double integral of f(x, y) over the area A in the (x, y) plane (Figure 2.2) as the
limit of this sum, and we write it as

A f(x, y) dx dy. Before we can use the double
integral to compute volumes, however, we need to see how double integrals are eval-
uated. Even though we may use a computer to do the work, we need to understand
the process in order to set up integrals correctly and ﬁnd and correct errors. Doing
some hand evaluation is a good way to learn this.
Iterated Integrals
We now show by some examples the details of evaluating
double integrals.
Figure 2.3
Figure 2.4
Example 1.
Find the volume of the solid (Figure 2.3) below the plane z = 1+y, bounded
by the coordinate planes and the vertical plane 2x + y = 2. From our discussion
above, this is

A z dx dy =

A(1 + y) dx dy, where A is the shaded triangle in the
(x, y) plane [A is shown also in Figure 2.4 (a and b)]. We are going to consider
two ways of evaluating this double integral. We think of the triangle A cut up into
little rectangles ∆A = ∆x ∆y (Figure 2.4) and the whole solid cut into vertical
columns of height z and base ∆A (Figure 2.3). We want the (limit of the) sum
of the volumes of these columns.
First add up the columns (Figure 2.4a) for a
ﬁxed value of x producing the volume of a slab (Figure 2.3) of thickness ∆x. This
corresponds to integrating with respect to y (holding x constant, Figure 2.4a) from
y = 0 to y on the line 2x + y = 2, that is y = 2 −2x; we ﬁnd
 2−2x
y=0
z dy =
 2−2x
y=0
(1 + y) dy =

y + y2
2

2−2x
0
(2.1)
= (2 −2x) + (2 −2x)2/2 = 4 −6x + 2x2.
(What we have found is the area of the slab in Figure 2.3; its volume is the area
times ∆x.) Now we add up the volumes of the slabs; this corresponds to integrating
(2.1) with respect to x from x = 0 to x = 1:
(2.2)
 1
x=0
(4 −6x + 2x2) dx = 5
3.

244
Multiple Integrals; Applications of Integration
Chapter 5
We could summarize (2.1) and (2.2) by writing
 1
x=0
 2−2x
y=0
(1 + y) dy

dx
or
 1
x=0
 2−2x
y=0
(1 + y) dy dx
(2.3)
or
 1
x=0
dx
 2−2x
y=0
dy (1 + y).
We call (2.3) an iterated (repeated) integral. Multiple integrals are usually evaluated
by using iterated integrals. Note that the large parentheses in (2.3) are not really
necessary if we are always careful to state the variable in giving the limits on an
integral; that is, always write
 1
x=0, not just
 1
0 .
Now we could also add up the volume z(∆A) by ﬁrst integrating with respect
to x (for ﬁxed y, Figure 2.4b) from x = 0 to x = 1 −y/2 giving the volume of a
slab perpendicular to the y axis in Figure 2.3, and then add up the volumes of the
slabs by integrating with respect to y from y = 0 to y = 2 (Figure 2.4b). We write
 2
y=0
 1−y/2
x=0
(1 + y) dx

dy =
 2
y=0
(1 + y)x

1−y/2
x=0
dy
(2.4)
=
 2
y=0
(1 + y)(1 −y/2) dy
=
 2
y=0
(1 + y/2 −y2/2) dy = 5
3.
As the geometry would indicate, the results in (2.2) and (2.4) are the same; we have
two methods of evaluating the double integral by using iterated integrals.
Often one of these two methods is more convenient than the other; we choose
whichever method is easier. To see how to decide, study the following sketches of
areas A over which we want to ﬁnd

A f(x, y) dx dy.
In each case we think of
combining little rectangles dx dy to form strips (as shown) and then combining the
strips to cover the whole area.
Areas shown in Figure 2.5: Integrate with respect to y ﬁrst. Note that the top
and bottom of area A are curves whose equations we know; the boundaries at x = a
and x = b are either vertical straight lines or else points.
Figure 2.5
We ﬁnd
(2.5)

A
f(x, y) dx dy =
 b
x=a
 y2(x)
y=y1(x)
f(x, y) dy

dx.

Section 2
Double and Triple Integrals
245
Areas shown in Figure 2.6: Integrate with respect to x ﬁrst. Note that the sides
of area A are curves whose equations we know; the boundaries at y = c and y = d
are either horizontal straight lines or else points.
Figure 2.6
We ﬁnd
(2.6)

A
f(x, y) dx dy =
 d
y=c
 x2(y)
x=x1(y)
f(x, y) dx

dy.
Figure 2.7
Areas shown in Figure 2.7: Integrate in either order. Note that these areas all
satisfy the requirements for both (2.5) and (2.6).
We ﬁnd

A
f(x, y) dx dy =
 b
x=a
 y2(x)
y=y1(x)
f(x, y) dy dx
(2.7)
=
 d
y=c
 x2(y)
x=x1(y)
f(x, y) dx dy.
An important special case is a double integral over a rectangle (both x and y
limits are constants) when f(x, y) is a product, f(x, y) = g(x)h(y). Then

A
f(x, y) dx dy =
 b
x=a
 d
y=c
g(x)h(y) dy dx
(2.8)
=
 b
a
g(x) dx
  d
c
h(y) dy

.
When areas are more complicated than those shown, we may break them into
two or more simpler areas (Problems 9 and 10).
We have seen how to set up and evaluate double integrals to ﬁnd areas and
volumes.
Recall, however, that we use single integrals for other purposes than
ﬁnding areas. Similarly, now that we know how to evaluate a double integral, we
can use it to ﬁnd other quantities besides areas and volumes.

246
Multiple Integrals; Applications of Integration
Chapter 5
Example 2.
Find the mass of a rectangular plate bounded by x = 0, x = 2, y = 0, y = 1,
if its density (mass per unit area) is f(x, y) = xy. The mass of a tiny rectangle
∆A = ∆x ∆y is approximately f(x, y) ∆x ∆y, where f(x, y) is evaluated at some
point in ∆A. We want to add up the masses of all the ∆A’s; this is what we ﬁnd by
evaluating the double integral of dM = xy dx dy. We call dM an element of mass
and think of adding up all the dM’s to get M.
M =

A
xy dx dy =
 2
x=0
 1
y=0
xy dx dy
(2.9)
=
 2
0
x dx
  1
0
y dy

= 2 · 1
2 = 1.
A triple integral of f(x, y, z) over a volume V , written

V f(x, y, z) dx dy dz,
is also deﬁned as the limit of a sum and is evaluated by an iterated integral. If the
integral is over a box, that is, all limits are constants, then we can do the x, y, z
integrations in any order. If the volume is complicated, then we have to consider
the geometry as we did for double integrals to decide on the best order and ﬁnd the
limits. This process can best be learned from examples (below and Section 3) and
practice (see problems).
Example 3.
Find the volume of the solid in Figure 2.3 by using a triple integral. Here
we imagine the whole solid cut into tiny boxes of volume ∆x ∆y ∆z; an element of
volume is dx dy dz. We ﬁrst add up the volumes of the tiny boxes to get the volume
of a column; this means integrating with respect to z from 0 to 1 + y with x and y
constant. Then we add up the columns to get a slab and the slabs to get the whole
volume just as we did in Example 1. Thus:
V =

V
dx dy dz
(2.10)
=
 1
x=0
 2−2x
y=0
 1+y
z=0
dz

dy dx
or
 1
x=0
 2−2x
y=0
 1+y
z=0
dz dy dx
=
 1
x=0
 2−2x
y=0
(1 + y) dy dx = 5
3,
as in (2.1) and (2.2). Or, we could have used (2.4).
Example 4.
Find the mass of the solid in Figure 2.3 if the density (mass per unit volume)
is x + z. An element of mass is dM = (x + z) dx dy dz. We add up elements of
mass just as we add up elements of volume; that is, the limits are the same as in
Example 3.
(2.11)
M =
 1
x=0
 2−2x
y=0
 1+y
z=0
(x + z) dz dy dx = 2
where we evaluate the integrals as we did (2.1) to (2.4). (Check the result by hand
and by computer.)

Section 2
Double and Triple Integrals
247
PROBLEMS, SECTION 2
In the problems of this section, set up and evaluate the integrals by hand and check your
results by computer.
1.
Z 1
x=0
Z 4
y=2
3x dy dx
2.
Z 1
y=−2
Z 2
x=1
8xy dx dy
3.
Z 2
y=0
Z 4
x=2y
dx dy
4.
Z 4
x=0
Z x/2
y=0
y dy dx
5.
Z 1
x=0
Z ex
y=x
y dy dx
6.
Z 2
y=1
Z y2
x=√y
x dx dy
In Problems 7 to 18 evaluate the double integrals over the areas described. To ﬁnd the
limits, sketch the area and compare Figures 2.5 to 2.7.
7.
RR
A(2x −3y) dx dy, where A is the triangle with vertices (0, 0), (2, 1), (2, 0).
8.
RR
A 6y2 cos x dx dy, where A is the area inclosed by the curves y = sin x, the x axis,
and the line x = π/2.
9.
RR
A sin x dx dy where A is the area shown in Figure 2.8.
10.
RR
A y dx dy where A is the area in Figure 2.8.
Figure 2.8
11.
RR
A x dx dy, where A is the area between the parabola y = x2 and the straight line
2x −y + 8 = 0.
12.
RR
y dx dy over the triangle with vertices (−1, 0), (0, 2), and (2, 0).
13.
RR
2xy dx dy over the triangle with vertices (0, 0), (2, 1), (3, 0).
14.
RR
x2ex2y dx dy over the area bounded by y = x−1, y = x−2, and x = ln 4.
15.
RR
dx dy over the area bounded by y = ln x, y = e + 1 −x, and the x axis.
16.
RR
(9 + 2y2)−1 dx dy over the quadrilateral with vertices (1, 3), (3, 3), (2, 6), (6, 6).
17.
RR
(x/y) dx dy over the triangle with vertices (0, 0), (1, 1), (1, 2).
18.
RR
y−1/2 dx dy over the area bounded by y = x2, x + y = 2, and the y axis.
In Problems 19 to 24, use double integrals to ﬁnd the indicated volumes.
19.
Above the square with vertices at (0, 0), (2, 0), (0, 2), and (2, 2), and under the plane
z = 8 −x + y.
20.
Above the rectangle with vertices (0, 0), (0, 1), (2, 0), and (2, 1), and below the
surface z2 = 36x2(4 −x2).
21.
Above the triangle with vertices (0, 0), (2, 0), and (2, 1), and below the paraboloid
z = 24 −x2 −y2.
22.
Above the triangle with vertices (0, 2), (1, 1), and (2, 2), and under the surface
z = xy.
23.
Under the surface z = y(x + 2), and over the area bounded by x + y = 0, y = 1,
y = √x.
24.
Under the surface z = 1/(y+2), and over the area bounded by y = x and y2+x = 2.

248
Multiple Integrals; Applications of Integration
Chapter 5
In Problems 25 to 28, sketch the area of integration, observe that it is like the areas
in Figure 2.7, and so write an equivalent integral with the integration in the opposite
order. Check your work by evaluating the double integral both ways. Also check that your
computer gives the same answer for both orders of integration.
25.
Z 1
x=0
Z 3−3x
y=0
dy dx
26.
Z 2
y=0
Z 1
x=y/2
(x + y) dx dy
27.
Z 4
x=0
Z √x
y=0
y√x dy dx
28.
Z 1
y=0
Z √
1−y2
x=0
y dx dy
In Problems 29 to 32, observe that the inside integral cannot be expressed in terms of
elementary functions. As in Problems 25 to 28, change the order of integration and so
evaluate the double integral.
Also try using your computer to evaluate these for both
orders of integration.
29.
Z π
y=0
Z π
x=y
sin x
x
dx dy
30.
Z 2
x=0
Z 2
y=x
e−y2/2 dy dx
31.
Z ln 16
x=0
Z 4
y=ex/2
dy dx
ln y
32.
Z 1
y=0
Z 1
x=y2
ex
√x dx dy
33.
A lamina covering the quarter disk x2 + y2 ≤4, x > 0, y > 0, has (area) density
x + y. Find the mass of the lamina.
34.
A dielectric lamina with charge density proportional to y covers the area between
the parabola y = 16 −x2 and the x axis. Find the total charge.
35.
A triangular lamina is bounded by the coordinate axes and the line x + y = 6. Find
its mass if its density at each point P is proportional to the square of the distance
from the origin to P.
36.
A partially silvered mirror covers the square area with vertices at (±1, ±1). The
fraction of incident light which it reﬂects at (x, y) is (x−y)2/4. Assuming a uniform
intensity of incident light, ﬁnd the fraction reﬂected.
In Problems 37 to 40, evaluate the triple integrals.
37.
Z 2
x=1
Z 2x
y=x
Z y−x
z=0
dz dy dx
38.
Z 2
z=0
Z 2
x=z
Z z
y=8x
dy dx dz
39.
Z 3
y=−2
Z 2
z=1
Z 2y+z
x=y+z
6y dx dz dy
40.
Z 2
x=1
Z 2x
z=x
Z 1/z
y=0
z dy dz dx.
41.
Find the volume between the planes z = 2x + 3y + 6 and z = 2x + 7y + 8, and over
the triangle with vertices (0, 0), (3, 0), and (2, 1).
42.
Find the volume between the planes z = 2x + 3y + 6 and z = 2x + 7y + 8, and over
the square in the (x, y) plane with vertices (0, 0), (1, 0), (0, 1), (1, 1).
43.
Find the volume between the surfaces z = 2x2 + y2 + 12 and z = x2 + y2 + 8, and
over the triangle with vertices (0, 0), (1, 0), and (1, 2).
44.
Find the mass of the solid in Problem 42 if the density is proportional to y.
45.
Find the mass of the solid in Problem 43 if the density is proportional to x.
46.
Find the mass of a cube of side 2 if the density is proportional to the square of the
distance from the center of the cube.

Section 3
Applications of Integration; Single and Multiple Integrals
249
47.
Find the volume in the ﬁrst octant bounded by the coordinate planes and the plane
x + 2y + z = 4.
48.
Find the volume in the ﬁrst octant bounded by the cone z2 = x2 −y2 and the plane
x = 4.
49.
Find the volume in the ﬁrst octant bounded by the paraboloid z = 1 −x2 −y2, the
plane x + y = 1, and all three coordinate planes.
50.
Find the mass of the solid in Problem 48 if the density is z.
3. APPLICATIONS OF INTEGRATION;
SINGLE AND MULTIPLE INTEGRALS
Many diﬀerent physical quantities are given by integrals; let us do some problems
to illustrate setting up and evaluating these integrals. The basic idea which we use
in setting up the integrals in these problems is that an integral is the “limit of a
sum.” Thus we imagine the physical object (whose volume, moment of inertia, etc.,
we are trying to ﬁnd) cut into a large number of small pieces called elements. We
write an approximate formula for the volume, moment of inertia, etc., of an element
and then sum over all elements of the object. The limit of this sum (as the number
of elements tends to inﬁnity and the size of each element tends to zero) is what we
ﬁnd by integration and is what we want in the physical problem.
Using a computer to evaluate the integrals saves time and we will concentrate
mainly on setting up integrals. However, in order to do a skillful job of ﬁnding
limits, deciding order of integration, detecting and correcting errors, making useful
changes of variables, and understanding the meaning of the symbols used, it is
important to learn to evaluate multiple integrals by hand. So a good study method
is to do some integrals both by hand and by computer. A computer is also very
useful to plot graphs of curves and surfaces to help you ﬁnd the limits in a multiple
integral.
Example 1.
Given the curve y = x2 from x = 0 to x = 1, ﬁnd
(a) the area under the curve (that is, the area bounded by the curve, the x axis,
and the line x = 1; see Figure 3.1);
(b) the mass of a plane sheet of material cut in the shape of this area if its density
(mass per unit area) is xy;
(c) the arc length of the curve;
(d) the centroid of the area;
(e) the centroid of the arc;
(f) the moments of inertia about the x, y, and z axes of the lamina in (b).
(a) The area is
A =
 1
x=0
y dx =
 1
0
x2 dx = x3
3

1
0
= 1
3.

250
Multiple Integrals; Applications of Integration
Chapter 5
We could also ﬁnd the area as a double integral of dA = dy dx (see Figure 3.1).
We have then
A =
 1
x=0
 x2
y=0
dy dx =
 1
0
x2 dx
as before. Although the double integral is entirely unnecessary in ﬁnding the area
in this problem, we shall need to use a double integral to ﬁnd the mass in part (b).
Figure 3.1
Figure 3.2
(b) The element of area, as in the double integral method in (a), is dA = dy dx.
Since the density is ρ = xy, the element of mass is dM = xy dy dx, and the total
mass is
M =
 1
x=0
 x2
y=0
xy dy dx =
 1
0
x dx
y2
2
	x2
0
=
 1
0
x5
2 dx = 1
12.
Observe that we could not do this problem as a single integral because the density
depends on both x and y.
(c) The element of arc length ds is deﬁned as indicated in Figures 3.1 and 3.2.
Thus we have
ds2 = dx2 + dy2,
ds =

dx2 + dy2 =

1 + (dy/dx)2 dx =

(dx/dy)2 + 1 dy.
(3.1)
If y = f(x) has a continuous ﬁrst derivative dy/ dx (except possibly at a ﬁnite num-
ber of points), we can ﬁnd the arc length of the curve y = f(x) between a and b by
calculating
 b
a ds. For our example, we have
dy
dx = 2x,
ds =

1 + 4x2 dx,
s =
 1
0

1 + 4x2 dx = 2
√
5 + ln(2 +
√
5)
4
(3.2)
(see Problem 32).

Section 3
Applications of Integration; Single and Multiple Integrals
251
(d) Recall from elementary physics that:
The center of mass of a body has coordinates ¯x, ¯y, ¯z given by the equations
(3.3)

¯x dM =

x dM,

¯y dM =

y dM,

¯z dM =

z dM,
where dM is an element of mass and the integrals are over the whole body.
Although we have written single integrals in (3.3), they may be single, double, or
triple integrals depending on the problem and the method of evaluation. Since ¯x,
¯y, and ¯z are constants, we can take them outside the integrals in (3.3) and solve
for them. However, you may ﬁnd it easier to remember the deﬁnitions in the form
(3.3). For the example we are doing, ¯z = 0 since the body is a sheet of material
in the (x, y) plane. The element of mass is dM = ρ dA = ρ dx dy, where ρ is the
density (mass per unit area in this problem). For a variable density as in (b), we
would substitute the value of ρ into (3.3) and integrate both sides of each equation
to ﬁnd the coordinates of the center of mass. However, let us suppose the density
is a constant. Then the ﬁrst integral in (3.3) is
(3.4)

¯xρ dA =

xρ dA
or

¯x dA =

x dA.
Similarly, a constant density ρ can be canceled from all the equations in (3.3). The
quantities ¯x, ¯y, ¯z, are then called the coordinates of the centroid of the area (or
volume or arc).
The centroid of a body is the center of mass when we assume constant density.
In our example, we have
 1
x=0
 x2
y=0
¯x dy dx =
 1
x=0
 x2
y=0
x dy dx
or
¯xA = x4
4

1
0
= 1
4,
 1
x=0
 x2
y=0
¯y dy dx =
 1
x=0
 x2
y=0
y dy dx
or
¯yA = x5
10

1
0
= 1
10.
(3.5)
(Double integrals are not really necessary for any of these but the last.) Using the
value of A from part(a), we ﬁnd ¯x = 3
4, ¯y =
3
10.
(e) The center of mass (¯x, ¯y) of a wire bent in the shape of the curve y = f(x)
is given by
(3.6)

¯xρ ds =

xρ ds,

¯yρ ds =

yρ ds,
where ρ is the density (mass per unit length), and the integrals are single integrals
with ds given by (3.1). If ρ is constant, (3.6) deﬁnes the coordinates of the centroid.

252
Multiple Integrals; Applications of Integration
Chapter 5
In our example we have
 1
0
¯x

1 + 4x2 dx =
 1
0
x

1 + 4x2 dx,
 1
0
¯y

1 + 4x2 dx =
 1
0
y

1 + 4x2 dx =
 1
0
x2
1 + 4x2 dx.
(3.7)
Note carefully here that it is correct to put y = x2 in the last integral of (3.7), but
it would not have been correct to do this in the last integral of (3.5); the reason is
that over the area, y could take values from zero to x2, but on the arc, y takes only
the value x2. By calculating the integrals in (3.7) we can ﬁnd ¯x and ¯y.
(f) We need the following deﬁnition:
The moment of inertia I of a point mass m about an axis is by deﬁnition the
product ml2 of m times the square of the distance l from m to the axis. For an
extended object we must integrate l2dM over the whole object, where l is the
distance from dM to the axis.
In our example with variable density ρ = xy, we have
dM = xy dy dx. The distance from dM to the x axis is
y (Figure 3.3); similarly, the distance from dM to the
y axis is x. The distance from dM to the z axis (the
z axis is perpendicular to the paper in Figure 3.3) is

x2 + y2. Then the three moments of inertia about
the three coordinate axes are:
Figure 3.3
Ix =
 1
x=0
 x2
y=0
y2xy dy dx =
 1
0
x9
4 dx = 1
40,
Iy =
 1
x=0
 x2
y=0
x2xy dy dx =
 1
0
x7
2 dx = 1
16,
Iz =
 1
x=0
 x2
y=0
(x2 + y2)xy dy dx = Ix + Iy = 7
80.
The fact that Ix + Iy = Iz for a plane lamina in the (x, y) plane is known as the
perpendicular axis theorem.
It is customary to write moments of inertia as multiples of the mass; using M =
1
12
from (b), we write
Ix = 12
40M = 3
10M,
Iy = 12
16M = 3
4M,
Iz = 7 · 12
80 M = 21
20M.
Example 2.
Rotate the area of Example 1 about the x axis to form a volume and surface
of revolution, and ﬁnd
(a)
the volume;

Section 3
Applications of Integration; Single and Multiple Integrals
253
(b)
the moment of inertia about the x axis of a solid of constant density occupying
the given volume;
(c)
the area of the curved surface;
(d)
the centroid of the curved surface.
(a) We want to ﬁnd the given volume.
The easiest way to ﬁnd a volume of revolution is to take as volume element a
thin slab of the solid as shown in Figure 3.4. The slab has circular cross section
of radius y and thickness dx; thus the volume element is πy2 dx.
Then the volume in our example is
(3.8)
V =
 1
0
πy2 dx =
 1
0
πx4 dx = π
5 .
We have really avoided part of the integration here because we knew the formula for
the area of a circle. In ﬁnding volumes of solids which are not solids of revolution,
we may have to use double or triple integrals. Even for a solid of revolution we
might need multiple integrals to ﬁnd the mass if the density is variable.
To illustrate setting up such integrals, let us do the above problem using triple
integrals. For this we need the equation of the surface which is (see Problem 16)
(3.9)
y2 + z2 = x4,
x > 0.
Figure 3.4
Figure 3.5
To set up a multiple integral for the volume of a solid, we cut the solid into slabs
as in Figure 3.4 (not necessarily circular slabs, although they are in our example)
and then as in Figure 3.5 we cut each slab into strips and each strip into tiny boxes
of volume dx dy dz. The volume is
V =

dx dy dz;
the only problem is to ﬁnd the limits! To do this, we start by adding up tiny boxes
to get a strip; as we have drawn Figure 3.5, this means to integrate with respect to
y from one side of the circle y2 + z2 = x4 to the other, that is, from
y = −

x4 −z2
to
y = +

x4 −z2.

254
Multiple Integrals; Applications of Integration
Chapter 5
Next we add all the strips in a slab. This means that, in Figure 3.5, we integrate
with respect to z from the bottom to the top of the circle y2 + z2 = x4; thus the z
limits are z = ± radius of circle = ±x2. And ﬁnally we add all the slabs to obtain
the solid. This means to integrate in Figure 3.4 from x = 0 to x = 1; this is just
what we did in our ﬁrst simple method. The ﬁnal integral is then
(3.10)
V =
 1
x=0
 x2
z=−x2
 √
x4−z2
y=−
√
x4−z2 dy dz dx.
(See Problem 33).
Although the triple integral is an unnecessarily complicated way of ﬁnding a
volume of revolution, this simple problem illustrates the general method of setting
up an integral for any kind of volume. Once we have the volume as a triple integral,
it is easy to write the integrals for the mass with a given variable density, for the
coordinates of the centroid, for the moments of inertia, and so on. The limits of
integration are the same as for the volume; we need only insert the proper expres-
sions (density, etc.) in the integrand to get the mass, centroid, and so on.
(b) To ﬁnd the moment of inertia of the solid about the x axis, we must integrate
the quantity l2dM, where l is the distance from dM to the x axis; from Figure 3.5,
since the x axis is perpendicular to the paper, l2 = y2 + z2. The limits on the
integrals are the same as in (3.10). We are assuming constant density, so the factor
ρ can be written outside the integrals. Then we have
Ix = ρ
 1
x=0
 x2
z=−x2
 √
x4−z2
y=−
√
x4−z2(y2 + z2) dy dz dx = π
18ρ.
Since from (3.8) the mass of the solid is
M = ρV = π
5 ρ
we can write Ix (as is customary) as a multiple of M:
Ix = π
18
5
π M = 5
18M.
Figure 3.6
Figure 3.7
(c) We ﬁnd the area of the surface of revolution by using as element the curved
surface of a thin slab as in Figure 3.6. This is a strip of circumference 2πy and
width ds. To see this clearly and to understand why we use ds here but dx in the

Section 3
Applications of Integration; Single and Multiple Integrals
255
volume element in (3.8), think of the slab as a thin section of a cone (Figure 3.7)
between planes perpendicular to the axis of the cone. If you wanted to ﬁnd the
total volume V = 1
3πr2h of the cone, you would use the height h perpendicular to
the base, but in ﬁnding the total curved surface area S = 1
2 · 2πr · s, you would use
the slant height s. The same ideas hold in ﬁnding the volume and surface elements.
The approximate volume of the thin slab is the area of a face of the slab times its
thickness (dh in Figure 3.7, dx in Figure 3.4). But if you think of a narrow strip
of paper just covering the curved surface of the thin slab, the width of the strip of
paper is ds, and its length is the circumference of the thin slab.
The element of surface area (in Figure 3.6) is then
(3.11)
dA = 2πy ds.
The total area is [using ds from (3.2)]
A =
 1
x=0
2πy ds =
 1
0
2πx2
1 + 4x2 dx.
(For more general surfaces, there is a way to calculate areas by double integration;
we shall take this up in Section 5.)
(d) The y and z coordinates of the centroid of the surface area are zero by
symmetry. For the x coordinate, we have by (3.4)

¯x dA =

x dA,
or, using dA = 2πy ds and the total area A from (c), we have
¯xA =
 1
x=0
x · 2πy ds =
 1
0
x · 2πx2
1 + 4x2 dx.
PROBLEMS, SECTION 3
The following notation is used in the problems:
M = mass,
¯x, ¯y, ¯z = coordinates of center of mass (or centroid if the density is constant),
I = moment of inertia (about axis stated),
Ix, Iy, Iz = moments of inertia about x, y, z axes,
Im = moment of inertia (about axis stated) through the center of mass.
Note:
It is customary to give answers for I, Im, Ix, etc., as multiples of M (for
example, I = 1
3Ml2).
1.
Prove the “parallel axis theorem”: The moment of inertia I of a body about a given
axis is I = Im + Md2, where M is the mass of the body, Im is the moment of inertia
of the body about an axis through the center of mass and parallel to the given axis,
and d is the distance between the two axes.

256
Multiple Integrals; Applications of Integration
Chapter 5
2.
For a thin rod of length l and uniform density ρ ﬁnd
(a)
M,
(b)
Im about an axis perpendicular to the rod,
(c)
I about an axis perpendicular to the rod and passing through one end (see
Problem 1).
3.
A thin rod 10 ft long has a density which varies uniformly from 4 to 24 lb/ft. Find
(a)
M,
(b)
¯x,
(c)
Im about an axis perpendicular to the rod,
(d)
I about an axis perpendicular to the rod passing through the heavy end.
4.
Repeat Problem 3 for a rod of length l with density varying uniformly from 2 to 1.
5.
For a square lamina of uniform density, ﬁnd I about
(a)
a side,
(b)
a diagonal,
(c)
an axis through a corner and perpendicular to the plane of the lamina. Hint:
See the perpendicular axis theorem, Example 1f.
6.
A triangular lamina has vertices (0, 0), (0, 6) and (6, 0), and uniform density. Find:
(a)
¯x, ¯y,
(b)
Ix,
(c)
Im about an axis parallel to the x axis. Hint: Use Problem 1 carefully.
7.
A rectangular lamina has vertices (0, 0), (0, 2), (3, 0), (3, 2) and density xy. Find
(a)
M,
(b)
¯x, ¯y,
(c)
Ix, Iy,
(d)
Im about an axis parallel to the z axis. Hint: Use the parallel axis theorem
and the perpendicular axis theorem.
8.
For a uniform cube, ﬁnd I about one edge.
9.
For the pyramid inclosed by the coordinate planes and the plane x + y + z = 1:
(a)
Find its volume.
(b)
Find the coordinates of its centroid.
(c)
If the density is z, ﬁnd M and ¯z.
10.
A uniform chain hangs in the shape of the catenary y = cosh x between x = −1 and
x = 1. Find
(a) its length,
(b) ¯y.
11.
A chain in the shape y = x2 between x = −1 and x = 1 has density |x|. Find
(a) M,
(b) ¯x, ¯y.
Prove the following two theorems of Pappus:
12.
The area A inside a closed curve in the (x, y) plane, y ≥0, is revolved about the x
axis. The volume of the solid generated is equal to A times the circumference of the
circle traced by the centroid of A. Hint: Write the integrals for the volume and for
the centroid.

Section 3
Applications of Integration; Single and Multiple Integrals
257
13.
An arc in the (x, y) plane, y ≥0, is revolved about the x axis. The surface area
generated is equal to the length of the arc times the circumference of the circle
traced by the centroid of the arc.
14.
Use Problems 12 and 13 to ﬁnd the volume and surface area of a torus (doughnut).
15.
Use Problems 12 and 13 to ﬁnd the centroids of a semicircular area and of a semi-
circular arc. Hint: Assume the formulas A = 4πr2, V = 4
3πr3 for a sphere.
16.
Let a curve y = f(x) be revolved about the x axis, thus forming a surface of
revolution. Show that the cross sections of this surface in any plane x = const.
[that is, parallel to the (y, z) plane] are circles of radius f(x).
Thus write the
general equation of a surface of revolution and verify the special case f(x) = x2 in
(3.9).
In Problems 17 to 30, for the curve y = √x, between x = 0 and x = 2, ﬁnd:
17.
The area under the curve.
18.
The arc length.
19.
The volume of the solid generated when the area is revolved about the x axis.
20.
The curved area of this solid.
21, 22, 23. The centroids of the arc, the volume, and the surface area.
24, 25, 26, 27. The moments of inertia about the x axis of a lamina in the shape of
the plane area under the curve; of a wire bent along the arc of the curve; of the solid of
revolution; and of a thin shell whose shape is the curved surface of the solid (assuming
constant density for all these problems).
28.
The mass of a wire bent in the shape of the arc if its density (mass per unit length)
is √x.
29.
The mass of the solid of revolution if the density (mass per unit volume) is |xyz|.
30.
The moment of inertia about the y axis of the solid of revolution if the density is
|xyz|.
31.
(a)
Revolve the curve y = x−1, from x = 1 to x = ∞, about the x axis to create
a surface and a volume. Write integrals for the surface area and the volume.
Find the volume, and show that the surface area is inﬁnite. Hint: The surface
area integral is not easy to evaluate, but you can easily show that it is greater
than
R ∞
1
x−1 dx which you can evaluate.
(b)
The following question is a challenge to your ability to ﬁt together your math-
ematical calculations and physical facts: In (a) you found a ﬁnite volume and
an inﬁnite area. Suppose you ﬁll the ﬁnite volume with a ﬁnite amount of paint
and then pour oﬀthe excess leaving what sticks to the surface. Apparently you
have painted an inﬁnite area with a ﬁnite amount of paint! What is wrong?
(Compare Problem 15.31c of Chapter 1.)
32.
Use a computer or tables to evaluate the integral in (3.2) and verify that the answer
is equivalent to the text answer. Hint: See Problem 1.4 and also Chapter 2, Sections
15 and 17.
33.
Verify that (3.10) gives the same result as (3.8).

258
Multiple Integrals; Applications of Integration
Chapter 5
4. CHANGE OF VARIABLES IN INTEGRALS; JACOBIANS
In many applied problems, it is more convenient to use other coordinate systems
instead of the rectangular coordinates we have been using. For example, in the plane
we often use polar coordinates, and in three dimensions we often use cylindrical
coordinates or spherical coordinates. It is important to know how to set up multiple
integrals directly in these coordinate systems which occur so frequently in practice.
That is, we need to know what the area, volume, and arc length elements are,
what the variables r, θ, etc., mean geometrically, and how they are related to the
rectangular coordinates.
We are going to discuss ﬁnding elements of area, etc.,
geometrically for several important coordinate systems. However, if we are given
equations like x = r cos θ, y = r sin θ, relating new variables to the rectangular ones,
it is useful to know how to ﬁnd the elements of area, etc., algebraically, without
having to rely on the geometry.
We are going to discuss this and illustrate it
by verifying the results which we can get geometrically for several of the familiar
coordinate systems.
In the plane, the polar coordinates r, θ are related to the rectangular coordinates
x, y by the equations
x = r cos θ,
y = r sin θ.
(4.1)
Figure 4.1
Recall that we found the area element dy dx by drawing a grid of lines x = const.,
y = const., which cut the plane into little rectangles dx by dy; the area of one
rectangle was then dy dx. We can make a similar construction for polar coordinates
by drawing lines θ = const. and circles r = const.; we then obtain the grid shown
in Figure 4.1. Observe that the sides of the area element are not dr and dθ, but dr
and r dθ, and its area is then
(4.2)
dA = dr · r dθ = r dr dθ.

Section 4
Change of Variables in Integrals; Jacobians
259
Figure 4.2
Similarly, we can see from Figure 4.2 that the arc length element ds is given by
ds2 = dr2 + r2 dθ2,
ds =
dr
dθ
2
+ r2 dθ =

1 + r2
dθ
dr
2
dr.
(4.3)
Example 1.
Given a semicircular sheet of material of radius a and constant density ρ,
ﬁnd
(a)
the centroid of the semicircular area;
(b)
the moment of inertia of the sheet of material about the diameter forming the
straight side of the semicircle.
(a) In Figure 4.3, we see by symmetry that ¯y = 0. We want
to ﬁnd ¯x. By (3.4), we have
Figure 4.3

¯xr dr dθ =

xr dr dθ.
Changing the x to polar coordinates and putting in the limits,
we get
¯x
 a
r=0
 π/2
θ=−π/2
r drdθ =
 a
r=0
 π/2
θ=−π/2
r cos θ r dr dθ.
We calculate the integrals and ﬁnd ¯x:
¯x a2
2 π = a3
3 sin θ

π/2
−π/2
= a3
3 · 2,
¯x = 4a
3π .
(b) We want the moment of inertia about the y axis in Figure 4.3; by deﬁnition
this is

x2 dM. In polar coordinates, dM = ρ dA = ρr dr dθ. We are given that
the density ρ is constant. Then we have
Iy = ρ

x2r dr dθ = ρ
 a
r=0
 π/2
θ=−π/2
r2 cos2 θ r dr dθ = ρπa4
8 .

260
Multiple Integrals; Applications of Integration
Chapter 5
The mass of the semicircular object is
M = ρ

r dr dθ = ρ
 a
r=0
 π/2
θ=−π/2
r dr dθ = ρπa2
2 .
We write Iy in terms of M to get
Iy = 2M
πa2
πa4
8
= Ma2
4
.
Spherical and Cylindrical Coordinates
The two most important coordinate
systems (besides rectangular) in three dimensions are the spherical and the cylin-
drical coordinate systems. Figures 4.4 and 4.5 and equations (4.4) and (4.5) show
the geometrical meaning of the variables, their algebraic relation to x, y, z, the
appearance of the volume elements, and the formulas for the volume, arc length,
and surface area elements.
Cylindrical coordinates are just polar coordinates in the (x, y) plane with z for
the third variable. Note that the spherical coordinates r and θ in Figure 4.5 are
diﬀerent from the cylindrical or polar coordinates r and θ in Figures 4.4 and 4.1.
Since we seldom use both systems in the same problem, this should cause no confu-
sion. (If necessary, use ρ or R for one of the r’s and use φ instead of θ in cylindrical
coordinates.) Watch out, however, for the discrepancy in notation for spherical
coordinates in various texts. Most calculus books interchange θ and φ. This can be
confusing later since the notation of Figure 4.5 is almost universal in applications
to the physical sciences, and is often used in advanced mathematics (partial diﬀer-
ential equations, special functions), in computer programs, and in reference books
of formulas and tables. You will need to learn a number of useful formulas involving
spherical coordinates [for example, (4.7), (4.19), and (4.20) below; also see Chapter
10, Section 9 and Chapter 13, Section 7]. It is best to learn these formulas in the
notation that you will use in applications.
Cylindrical coordinates:
Figure 4.4
(4.4)
x = r cos θ
y = r sin θ
z = z
dV = r dr dθ dz
ds2 = dr2 + r2 dθ2 + dz2
dA = a dθ dz

Section 4
Change of Variables in Integrals; Jacobians
261
Figure 4.5
Spherical coordinates:
(4.5)
x = r sin θ cos φ
y = r sin θ sin φ
z = r cos θ
dV = r2 sin θ dr dθ dφ
ds2 = dr2 + r2 dθ2 + r2 sin2 θ dφ2
dA = a2 sin θ dθ dφ
We will need the volume and surface area elements in these two systems [and
also the arc length elements—see equations (4.18) and (4.19)]. To ﬁnd the polar co-
ordinate area element in Figure 4.1, we drew a grid of curves r = const., θ = const.
In three dimensions we want to draw a grid of surfaces. In cylindrical coordinates
these surfaces are the cylinders r = const., the half-planes θ = const. (through the
z axis), and the planes z = const. [parallel to the (x, y) plane]. One of the elements
formed by this grid of surfaces is sketched in Figure 4.4. From the geometry we see
that three edges of the element are dr, r dθ, and dz, giving the volume element
(4.6)
dV = r dr dθ dz
(cylindrical coordinates).
If r is constant, then the surface area element on the cylinder r = a has edges a dθ
and dz, so dA = a dθ dz. Similarly for the spherical coordinate case, we draw the
spheres r = const., the cones θ = const., and the half-planes φ = const. The volume
elements formed by this grid (Figure 4.5) have edges dr, r dθ, and r sin dθ dφ; thus
we get
(4.7)
dV = r2 sin θ dr dθ dφ
(spherical coordinates).
If r is constant, then the surface area element on the sphere r = a has edges a dθ
and a sin θ dφ, so dA = a2 sin θ dθ dφ.
Jacobians.
For polar, cylindrical, and spherical coordinates, we have seen how to
ﬁnd area and volume elements from the geometry. However, it is convenient to know
an algebraic way of ﬁnding them which we can use for unfamiliar coordinate systems

262
Multiple Integrals; Applications of Integration
Chapter 5
(Problems 16 and 17) or for any change of variables in a multiple integral (Problems
19 and 20). Here we state without proof (see Chapter 6, Section 3, Example 2) some
theorems which tell us how to do this. First, in two dimensions, suppose x and y
are given as functions of two new variables s and t. The Jacobian of x, y, with
respect to s, t, is the determinant in (4.8) below; we also show abbreviations used
for it.
(4.8)
J = J
x, y
s, t

= ∂(x, y)
∂(s, t) =

∂x
∂s
∂x
∂t
∂y
∂s
∂y
∂t

.
Then the area element dy dx is replaced in the s, t system by the area element
(4.9)
dA = |J| ds dt
where |J| is the absolute value of the Jacobian in (4.8).
Let us ﬁnd the Jacobian of x, y with respect to the polar coordinates r, θ, and
thus verify that (4.8) and our geometric method give the same result (4.2) for the
polar coordinate area element. We have
(4.10)
∂(x, y)
∂(r, θ) =

∂x
∂r
∂x
∂θ
∂y
∂r
∂y
∂θ

=

cosθ
−r sin θ
sin θ
r cos θ

= r.
Thus by (4.9) the area element is r dr dθ as in (4.2).
The use of Jacobians extends to more variables. Also, it is not necessary to start
with rectangular coordinates; let us state a more general theorem.
Suppose we have a triple integral
(4.11)

f(u, v, w) du dv dw
in some set of variables u, v, w. Let r, s, t be another set of variables, related to
u, v, w by given equations
u = u(r, s, t),
v = v(r, s, t),
w = w(r, s, t).

Section 4
Change of Variables in Integrals; Jacobians
263
Then if the determinant
(4.12)
J = ∂(u, v, w)
∂(r, s, t) =

∂u
∂r
∂u
∂s
∂u
∂t
∂v
∂r
∂v
∂s
∂v
∂t
∂w
∂r
∂w
∂s
∂w
∂t

is the Jacobian of u, v, w with respect to r, s, t, then the triple integral in the
new variables is
(4.13)

f · |J| · dr ds dt,
where, of course, f and J must both be expressed in terms of r, s, t, and the
limits must be properly adjusted to correspond to the new variables.
We can use (4.12) to verify the volume element (4.6) for cylindrical coordinates
(Problem 15) and the volume element (4.7) for spherical coordinates. Let us do the
calculation for spherical coordinates. From (4.5), we have
∂(x, y, z)
∂(r, θ, φ) =

∂x
∂r
∂x
∂θ
∂x
∂φ
∂y
∂r
∂y
∂θ
∂y
∂φ
∂z
∂r
∂z
∂θ
∂z
∂φ

=

sin θ cos φ
r cos θ cosφ
−r sin θ sin φ
sin θ sin φ
r cos θ sin φ
r sin θ cos φ
cos θ
−r sin θ
0

= r2 sin θ[−sin2 φ(−sin2 θ −cos2 θ) −cos2 φ(−sin2 θ −cos2 θ)]
= r2 sin θ.
(4.14)
Thus the spherical coordinate volume element is dV = r2 sin θ dr dθ dφ as in (4.7).
Example 2.
Find the z coordinate of the centroid of a uniform solid cone (part of one
nappe) of height h equal to the radius of the base r. Also ﬁnd the moment of inertia
of the solid about its axis.

264
Multiple Integrals; Applications of Integration
Chapter 5
If we take the cone as shown in Figure 4.6, its
equation in cylindrical coordinates is r = z, since
at any height z, the cross section is a circle of
radius equal to the height. To ﬁnd the mass we
must integrate dM = ρr dr dθ dz, where ρ is the
constant density. The limits of integration are
Figure 4.6
θ :
0 to 2π,
r :
0 to z,
z :
0 to h.
Then we have
M =

ρ dV = ρ
 h
z=0
 z
r=0
 2π
θ=0
r dr dθ dz = ρ · 2π
 h
0
z2
2 dz = ρπh3
3
,

¯z dV =

z dV =
 h
z=0
 z
r=0
 2π
θ=0
zr dr dθ dz
= 2π
 h
0
z · 1
2z2 dz = πh4
4 ,
(4.15)
¯z · πh3
3
= πh4
4 ,
¯z = 3
4h.
For the moment of inertia about the z axis we have
I = ρ
 h
z=0
 z
r=0
 2π
θ=0
r2r dr dθ dz = ρ · 2π
 h
0
z4
4 dz = ρπh5
10 .
Using the value of M from (4.15), we write I in the usual form as a multiple of M:
I = 3M
πh3
πh5
10 = 3
10Mh2.
In the following examples and problems, note that we use sphere (r = a) to
mean surface area, and ball (r ≤a) to mean volume (just as we use circle to mean
circumference and disk to mean area).
Example 3.
Find the moment of inertia of a solid ball of radius a about a diameter. In
spherical coordinates, the equation of the ball is r ≤a. Then the mass is
M = ρ

dV = ρ
 2π
φ=0
 π
θ=0
 a
r=0
r2 sin θ dr dθ dφ
(4.16)
= ρa3
3 · 2 · 2π = 4
3πa3ρ.
(to no one’s surprise!). The moment of inertia about the z axis is
I =

(x2 + y2) dM = ρ
 2π
φ=0
 π
θ=0
 a
r=0
(r2 sin2 θ) r2 sin θ dr dθ dφ
= ρ · a5
5 · 4
3 · 2π = 8πa5ρ
15
;

Section 4
Change of Variables in Integrals; Jacobians
265
or, using the value of M, we get
(4.17)
I = 2
5Ma2.
Example 4.
Find the moment of inertia about the z axis of the solid ellipsoid inside
x2
a2 + y2
b2 + z2
c2 = 1.
We want to evaluate
M = ρ

dx dy dz
and
I = ρ

(x2 + y2) dx dy dz
where the triple integrals are over the volume of the ellipsoid. Make the change
of variables x = ax′, y = by′, z = cz′; then x′2 + y′2 + z′2 = 1, so in the primed
variables we integrate over the volume of a ball of radius 1. Then
M = ρ abc

dx′ dy′ dz′ = ρ abc · volume of ball of radius 1.
Using (4.16), we have
M = ρ abc · 4
3π · 13 = 4
3πρ abc.
Similarly, we ﬁnd
I = ρ abc

(a2x′2 + b2y′2) dV ′
where the triple integral is over the volume of a ball of radius 1. Now, by symmetry,

x′2dV ′ =

y′2dV ′ =

z′2dV ′ = 1
3

r′2dV ′
where r′2 = x′2 +y′2 +z′2, and we are integrating over the volume inside the sphere
r′ = 1. Let us use spherical coordinates in the primed system. Then

r′2dV ′ =
 2π
φ=0
 π
θ=0
 1
r=0
r′2(r′2 sin θ′ dr′ dθ′ dφ′)
= 4π
 1
0
r′4dr′ = 4π
5 .
Thus,
I = ρ abc

a2

x′2 dV ′ + b2

y′2 dV ′
	
= ρ abc(a2 + b2)1
3 · 4π
5 ,
or, in terms of M,
I = 1
5M(a2 + b2).

266
Multiple Integrals; Applications of Integration
Chapter 5
In order to ﬁnd arc lengths using spherical or cylindrical coordinates, we need
the arc length element ds. Recall that we found the polar coordinate arc length
element ds (Figure 4.2) as the hypotenuse of the right triangle with sides dr and
r dθ. From Figure 4.1 you can see that ds can also be thought of as a diagonal of
the area element. Similarly, in cylindrical and spherical coordinates (see Figures
4.4 and 4.5), the arc length element ds is a space diagonal of the volume element.
In cylindrical coordinates (4.4), the sides of the volume element are dr, r dθ, dz, so
the arc length element is given by
(4.18)
ds2 = dr2 + r2 dθ2 + dz2
(cylindrical coordinates).
In spherical coordinates (4.5), the sides of the volume element are dr, r dθ, r sin θ dφ,
so the arc length element is given by
(4.19)
ds2 = dr2 + r2 dθ2 + r2 sin2 θ dφ2
(spherical coordinates).
It is also convenient to be able to ﬁnd arc lengths algebraically. Let us do this
for polar coordinates; the same method can be used in three dimensions. From (4.1)
we have
dx = cos θ dr −r sin θ dθ,
dy = sin θ dr + r cos θ dθ.
Squaring and adding these two equations, we get
ds2 = dx2 + dy2
= (cos2 θ + sin2 θ) dr2 + 0 · dr dθ + r2(sin2 θ + cos2 θ) dθ2
= dr2 + r2 dθ2
as in (4.3). Using the same method for cylindrical and spherical coordinates (Prob-
lem 21) you can verify equations (4.18) and (4.19).
Example 5.
Express the velocity of a moving particle in spherical coordinates.
If s represents the distance the particle has moved along some path, then ds/dt
is the velocity of the particle. Dividing (4.19) by dt2, we ﬁnd for the square of the
velocity
(4.20)
v2 =
 ds
dt
2
=
dr
dt
2
+ r2
dθ
dt
2
+ r2 sin2 θ
dφ
dt
2
(spherical coordinates).
We have just seen how to ﬁnd the arc length element ds in polar coordinates
(or other systems) by calculating

dx2 + dy2. You might be tempted to try to

Section 4
Change of Variables in Integrals; Jacobians
267
ﬁnd the area element by computing dx dy, but you would discover that this does
not work—we must use the Jacobian [or geometry as in (4.2)] to get volume or
area elements. You can see why by looking at Figure 4.1. The element of area
r dr dθ at the point (x, y) is not the same as the element of area dx dy at that point.
Then consider Figure 4.2; the element of arc ds is the hypotenuse of the triangle
with legs dr and rdθ, and it is also the hypotenuse of the triangle with legs dx and
dy. Thus ds is the same element for both x, y and r, θ and this is why we can
compute ds in polar coordinates by calculating

dx2 + dy2. These comments hold
for other coordinate systems, too. We can always ﬁnd ds by computing

dx2 + dy2
or

dx2 + dy2 + dz2, but we cannot compute area or volume elements directly from
the rectangular ones—we must use the Jacobian or else geometrical methods.
PROBLEMS, SECTION 4
As needed, use a computer to plot graphs of ﬁgures and to check values of integrals.
1.
For the disk r ≤a, ﬁnd by integration using polar coordinates:
(a)
the area of the disk;
(b)
the centroid of one quadrant of the disk;
(c)
the moment of inertia of the disk about a diameter;
(d)
the circumference of the circle r = a;
(e)
the centroid of a quarter circle arc.
2.
Using polar coordinates:
(a)
Show that the equation of the circle sketched is
r = 2a cos θ. Hint: Use the right triangle OPQ.
(b)
By integration, ﬁnd the area of the disk
r ≤2a cos θ.
(c)
Find the centroid of the area of the ﬁrst quadrant
half disk.
(d)
Find the moments of inertia of the disk about each of the three coordinate
axes, assuming constant area density.
(e)
Find the length and the centroid of the semicircular arc in the ﬁrst quadrant.
(f)
Find the center of mass and the moments of inertia of the disk if the density
is r.
(g)
Find the area common to the disk sketched and the disk r ≤a.
3.
(a)
Find the moment of inertia of a circular disk (uniform density) about an axis
through its center and perpendicular to the plane of the disk.
(b)
Find the moment of inertia of a solid right circular cylinder (uniform density)
about its axis.
(c)
Do (a) using Problem 1c and the perpendicular axis theorem (Section 3, Ex-
ample 1f).
4.
For the sphere r = a, ﬁnd by integration:
(a)
its surface area;

268
Multiple Integrals; Applications of Integration
Chapter 5
(b)
the centroid of the curved surface area of a hemisphere;
(c)
the moment of inertia of the whole spherical shell (that is, surface area) about
a diameter (assuming constant area density);
(d)
the volume of the ball r ≤a;
(e)
the centroid of a solid half ball.
5.
(a)
Write a triple integral in spherical coordinates for the volume inside the cone
z2 = x2 + y2 and between the planes z = 1 and z = 2. Evaluate the integral.
(b)
Do (a) in cylindrical coordinates.
6.
Find the mass of the solid in Problem 5 if the density is (x2 + y2 + z2)−1. Check
your work by doing the problem in both spherical and cylindrical coordinates.
7.
(a)
Using spherical coordinates, ﬁnd the volume cut from the ball r ≤a by the
cone θ = α < π/2.
(b)
Show that the z coordinate of the centroid of the volume in (a) is given by the
formula ¯z = 3a(1 + cos α)/8.
8.
For the solid in Problem 7, ﬁnd Iz/M if α = π/3 and the density is constant.
9.
Let the solid in Problem 7 have density = cos θ. Show that then Iz =
3
10Ma2 sin2 α.
10.
(a)
Find the volume inside the cone 3z2 = x2 + y2, above the plane z = 2 and
inside the sphere x2 + y2 + z2 = 36. Hint: Use spherical coordinates.
(b)
Find the centroid of the volume in (a).
11.
Write a triple integral in cylindrical coordinates for the volume inside the cylinder
x2 + y2 = 4 and between z = 2x2 + y2 and the (x, y) plane. Evaluate the integral.
12.
(a)
Write a triple integral in cylindrical coordinates for the volume of the solid
cut from a ball of radius 2 by a cylinder of radius 1, one of whose rulings is a
diameter of the ball. Hint: Take the axis of the cylinder parallel to the z axis;
a cross section of the cylinder then looks like the ﬁgure in Problem 2.
(b)
Write a triple integral for the moment of inertia about the z axis of a uniform
solid occupying this volume.
(c)
Evaluate the integrals in (a) and (b), and ﬁnd I as a multiple of the mass.
13.
(a)
Write a triple integral in cylindrical coordinates for the volume of the part of
a ball between two parallel planes which intersect the ball.
(b)
Evaluate the integral in (a). Warning hint: Do the r and θ integrals ﬁrst.
(c)
Find the centroid of this volume.
14.
Express the integral
I =
Z 1
0
dx
Z √
1−x2
0
e−x2−y2 dy
as an integral in polar coordinates (r, θ) and so evaluate it.
15.
Find the cylindrical coordinate volume element by Jacobians.
Find the Jacobians ∂(x, y)/∂(u, v) of the given transformations from variables x, y to
variables u, v:
16.
x = 1
2(u2 −v2),
y = uv,
(u and v are called parabolic cylinder coordinates).

Section 4
Change of Variables in Integrals; Jacobians
269
17.
x = a cosh u cos v,
y = a sinh u sin v,
(u and v are called elliptic cylinder coordinates).
18.
Prove the following theorems about Jacobians.
∂(u, v)
∂(x, y)
∂(x, y)
∂(u, v) = 1.
∂(x, y)
∂(u, v)
∂(u, v)
∂(s, t) = ∂(x, y)
∂(s, t) .
Hint: Multiply the determinants (as you would matrices) and show that each ele-
ment in the product determinant can be written as a single partial derivative. Also
see Chapter 4, Section 7.
19.
In the integral
I =
Z ∞
0
Z ∞
0
x2 + y2
1 + (x2 −y2)2 e−2xy dx dy
make the change of variables
u = x2 −y2
v = 2xy
and evaluate I. Hint: Use (4.8) and the accompanying discussion.
20.
In the integral
I =
Z 1/2
x=0
Z 1−x
y=x
„x −y
x + y
«2
dy dx,
make the change of variables
x = 1
2(r −s),
y = 1
2(r + s),
and evaluate I. Hints: See Problem 19. To ﬁnd the r and s limits, sketch the area
of integration in the (x, y) plane and sketch the r and s axes. Then show that to
cover the same integration area, you may take the r and s limits to be: s from 0 to
r, r from 0 to 1.
21.
Verify equations (4.18) and (4.19).
22.
Use equation (4.18) to set up an integral for the length of wire required to wind a
coil spirally about a cylinder of radius 1 in., and length 1 ft, if there are three turns
per inch.
23.
A loxodrome or rhumb line is a curve on the earth’s surface along which a ship sails
without changing its course, that is, such that it crosses the meridians at a constant
angle α. Show that then tan α = sin θ dφ/dθ (θ and φ are spherical coordinates).
Use (4.19) to set up an integral for the distance traveled by a ship along a rhumb
line. Show that although a rhumb line winds inﬁnitely many times around either
the north or the south pole, its total length is ﬁnite.
24.
Compute the gravitational attraction on a unit mass at the origin due to the mass
(of constant density) occupying the volume inside the sphere r = 2a and above the
plane z = a. Hint: The magnitude of the gravitational force on the unit mass due to
the element of mass dM at (r, θ, φ) is (G/r2)dM. You want the z component of this
since the other components of the total force are zero by symmetry. Use spherical
coordinates.

270
Multiple Integrals; Applications of Integration
Chapter 5
25.
The volume inside a sphere of radius r is V = 4
3πr3. Then dV = 4πr2 dr = A dr,
where A is the area of the sphere. What is the geometrical meaning of the fact that
the derivative of the volume is the area? Could you use this fact to ﬁnd the volume
formula given the area formula?
26.
Use the parallel axis theorem (Problem 3.1)
(a)
and Example 3, to ﬁnd the moment of inertia of a solid ball about a line tangent
to it;
(b)
and Problem 3b to ﬁnd the moment of inertia of a solid cylinder about a ruling.
27.
Use the spherical coordinates θ and φ to ﬁnd the area of a zone of a sphere (that is,
the spherical surface area between two parallel planes). Hint: See dA in (4.5).
28.
Find the center of mass of a hemispherical shell of constant density (mass per unit
area) by using double integrals and the area element dA in (4.5). [Compare your
result in Problem 4(b).]
5. SURFACE INTEGRALS
In the preceding sections we found surface areas, moments of them, etc., for surfaces
of revolution. We now want to consider a way of computing surface integrals in
general whether the surface is a surface of revolution or not. Consider a part of a
surface as in Figure 5.1 and its projection in the (x, y) plane. We assume that any
line parallel to the z axis intersects the surface only once. If this is not true, we
must work with part of the surface at a time, or project the surface into a diﬀerent
plane. For example, if the surface is closed, we could ﬁnd the areas of the upper
and lower parts separately. For a cylinder with axis parallel to the z axis we could
project the front and back parts separately into the (y, z) plane.
Figure 5.1
Let dA (Figure 5.1) be an element of surface area which projects onto dx dy in
the (x, y) plane and let γ be the acute angle between dA (that is, the tangent plane
at dA) and the (x, y) plane. Then we have
(5.1)
dx dy = dA cos γ
or
dA = sec γ dx dy.

Section 5
Surface Integrals
271
The surface area is then
(5.2)

dA =

sec γ dx dy
where the limits on x and y must be such that we integrate over the projected
area in the (x, y) plane.
Now we must ﬁnd sec γ. The (acute) angle between two planes is the same as
the (acute) angle between the normals to the planes. If n is a unit vector normal
to the surface at dA (Figure 5.1), then γ is the (acute) angle between n and the z
axis, that is, between the vectors n and k, so cos γ = |n · k|. Let the equation of
the surface be φ(x, y, z) = const. Recall from Chapter 4 just after equation (9.14)
that the vector
(5.3)
grad φ = i ∂φ
∂x + j ∂φ
∂y + k ∂φ
∂z
is normal to the surface φ(x, y, z) = const. (Also see Chapter 6, Section 6.) Then
n is a unit vector in the direction of gradφ, so
(5.4)
n = (grad φ)/| gradφ|.
From (5.3) and (5.4) we ﬁnd
n · k = k · grad φ
| grad φ| = ∂φ/∂z
| gradφ|,
sec γ =
1
cos γ =
1
|n · k|,
so
(5.5)
sec γ = | gradφ|
|∂φ/∂z| =
∂φ
∂x
2
+
∂φ
∂y
2
+
∂φ
∂z
2
|∂φ/∂z|
.
Often the equation of a surface is given in the form z = f(x, y).
In this case
φ(x, y, z) = z −f(x, y), so ∂φ/∂z = 1, and (5.5) simpliﬁes to
(5.6)
sec γ =

(∂f/∂x)2 + (∂f/∂y)2 + 1.
We then substitute (5.5) or (5.6) into (5.2) and integrate to ﬁnd the area. To ﬁnd
centroids, moments of inertia, etc., we insert the proper factor into (5.2) as we have
discussed in Section 3.

272
Multiple Integrals; Applications of Integration
Chapter 5
Example 1.
Find the area cut from the upper half of the sphere
x2 + y2 + z2 = 1 by the cylinder x2 + y2 −y = 0.
Figure 5.2
This is the same as the area on the sphere which projects
onto the disk x2 + y2 −y ≤0 in the (x, y) plane. Thus we
want to integrate (5.2) over the area of this disk.
Figure
5.2 shows the disk of integration (shaded) and the equatorial
circle of the sphere (large circle). We compute sec γ from the
equation of the sphere; we could use (5.6), but it is easier in
this problem to use (5.5):
φ = x2 + y2 + z2,
sec γ = | gradφ|
|∂φ/∂z| = 1
2z

(2x)2 + (2y)2 + (2z)2 = 1
z =
1

1 −x2 −y2 .
We ﬁnd the limits of integration from the equation of the shaded disk, x2+y2−y ≤0.
Because of the symmetry we can integrate over the ﬁrst-quadrant part of the shaded
area and double our result. Then the limits are:
x from 0 to

y −y2,
y from 0 to 1.
The desired area is
(5.7)
A = 2
 1
y=0
 √
y−y2
x=0
dx dy

1 −x2 −y2 .
This integral is simpler in polar coordinates. The equation of the cylinder is then
r = sin θ, so the limits are: r from 0 to sin θ, and θ from 0 to π/2. Thus (5.7)
becomes
(5.8)
A = 2
 π/2
θ=0
 sin θ
r=0
r dr dθ
√
1 −r2 .
This is still simpler if we make the change of variable z =
√
1 −r2. Then dz =
−r dr/
√
1 −r2, and the limits r = 0 to sin θ become z = 1 to cos θ. Thus (5.8)
becomes
(5.9)
A = −2
 π/2
θ=0
 cos θ
z=1
dz dθ = π −2.
PROBLEMS, SECTION 5
For these problems, the most important sketch is the projection in the plane of integration,
which is easy to do by hand. However, you might like to use your computer to plot the
corresponding 3 dimensional picture.
1.
Find the area of the plane x −2y + 5z = 13 cut out by the cylinder x2 + y2 = 9.
2.
Find the surface area cut from the cone 2x2 + 2y2 = 5z2, z > 0, by the cylinder
x2 + y2 = 2y.
3.
Find the area of the paraboloid x2 + y2 = z inside the cylinder x2 + y2 = 9.

Section 6
Miscellaneous Problems
273
4.
Find the area of the part of the cone 2z2 = x2 + y2 in the ﬁrst octant cut out by
the planes y = 0, and y = x/
√
3, and the cylinder x2 + y2 = 4.
5.
Find the area of the part of the cone z2 = 3(x2 + y2) which is inside the sphere
x2 + y2 + z2 = 16.
6.
In Example 1, ﬁnd the area of the cylinder inside the sphere.
7.
Find the area of the part of the cylinder y2 + z2 = 4 in the ﬁrst octant, cut out by
the planes x = 0 and y = x.
8.
Find the area of the part of the cylinder z = x + y2 that lies below the second-
quadrant area bounded by the x axis, x = −1, and y2 = −x.
9.
Find the area of the part of the cone x2+y2 = z2 that is over the disk (x−1)2+y2 ≤1.
10.
Find the area of the part of the sphere of radius a and center at the origin which is
above the square in the (x, y) plane bounded by x = ±a/
√
2 and y = ±a/
√
2. Hint
for evaluating the integral: Change to polar coordinates and evaluate the r integral
ﬁrst.
11.
The part of the plane x + y + z = 1 which is in the ﬁrst octant is a triangular area
(sketch it). Find the area and its centroid by integration. You might like to check
your work by geometry.
12.
In Problem 11, let the triangle have a density (mass per unit area) equal to x. Find
the total mass and the coordinates of the center of mass.
13.
For the area of Example 1, ﬁnd the z coordinate of the centroid.
14.
For the area in Example 1, let the mass per unit area be equal to |x|. Find the total
mass.
15.
For a uniform mass distribution over the area of Example 1, ﬁnd the moment of
inertia about the z axis.
16.
Find the centroid of the surface area in Problem 2.
6. MISCELLANEOUS PROBLEMS
As needed, use a computer to plot graphs and to check values of integrals.
1.
Find the volume inside the cone z2 = x2 + y2, above the (x, y) plane, and between
the spheres x2 + y2 + z2 = 1 and x2 + y2 + z2 = 4. Hint: Use spherical coordinates.
2.
Find the z coordinate of the centroid of the volume in Problem 1.
3.
Find the mass of the solid in Problem 1 if the density is equal to z.
4.
Find the moment of inertia of a hoop (wire bent to form a circle of radius R)
(a)
about a diameter;
(b)
about a tangent line.
5.
The rectangle in the ﬁgure has sides 2a and 2b; the curve
is an ellipse.
If the ﬁgure is rotated about the dotted
line it generates three solids of revolution: a cone, an
ellipsoid, and a cylinder. Show that the volumes are in the
ratio 1 : 2 : 3. (See L.H. Lange, American Mathematical
Monthly vol. 88 (1981), p. 339.)

274
Multiple Integrals; Applications of Integration
Chapter 5
6.
(a)
Find the area inside the circle r = 2, with x > 0 and y > 1.
(b)
Find the centroid of the area in (a).
7.
For a lamina of density 1 in the shape of the area of Problem 6, ﬁnd its moment of
inertia about the z axis.
8.
For the solid bounded above by the sphere x2+y2+z2 = 4 and below by a horizontal
plane through (0, 0, 1), ﬁnd
(a)
the volume (see Problem 6 and Problem 3.12);
(b)
the z coordinate of the centroid (use cylindrical coordinates).
9.
Find the centroid of the area above y = x2 and below y = c (c > 0).
10.
(a)
Find the centroid of the area between the x axis and one arch of y = sin x.
(b)
Find the volume formed if the area in (a) is rotated about the x axis.
(c)
Find Ix of a mass of constant density occupying the volume in (b).
11.
Show that the z coordinate of the centroid of the volume inside the elliptic cone
z2
h2 = x2
a2 + y2
b2 ,
0 < z < h,
is
¯z = 3
4h.
(Note that the result is independent of a and b.)
Hint:
To evaluate the triple
integrals, let z = hz′, x = ax′, y = by′, and then change to cylindrical coordinates
in the primed system (see Example 4, Section 4). Compare Example 2, Section 4.
12.
Find the mass of the solid inside the ellipsoid
x2
a2 + y2
b2 + z2
c2 = 1
if the density is |xyz|. Hint: Evaluate the triple integral as in Example 4, Section 4.
13.
Find the surface area of the part of the cylinder x2 + z2 = a2 inside the cylinder
x2 + y2 = a2. Use your computer to graph the two cylinders on the same axes.
14.
Find the volume that is inside both cylinders in Problem 13.
15.
Find Ix and Iy for a mass distribution of constant density occupying the solid in
Problem 14. Hint: Do the x integration last.
16.
Find the centroid of the ﬁrst quadrant part of the arc x2/3 + y2/3 = a2/3. Hint: Let
x = a cos3 θ, y = a sin3 θ.
17.
Find the moment of inertia about a diagonal of a framework consisting of the four
sides of a square of side a.
18.
Find the center of mass of the solid right circular cone inside r2 = z2, 0 < z < h, if
the density is r2 = x2 + y2. Use cylindrical coordinates.
19.
For the cone in Problem 18, ﬁnd Ix/M, Iy/M, Iz/M. Also ﬁnd I/M about a line
through the center of mass parallel to the x axis.
20.
(a)
Find the area of the surface z = 1 + x2 + y2 inside the cylinder x2 + y2 = 1.
(b)
Find the volume inside the cylinder between the surface and the (x, y) plane.
Use cylindrical coordinates.
21.
Find the gravitational attraction on a unit mass at the origin due to a mass (of
constant density) occupying the volume inside the cone z2 = x2 + y2, 0 < z < h.
See Problem 4.24.

Section 6
Miscellaneous Problems
275
22.
Find Ix/M, Iy/M, Iz/M, for a lamina in the shape of an ellipse (x2/a2)+(y2/b2) = 1.
Hint: See Problem 11.
23.
(a)
Find the centroid of the solid paraboloid inside z = x2 + y2, 0 < z < c.
(b)
Repeat part (a) if the density is ρ = r =
p
x2 + y2.
24.
Repeat Problem 23a for the paraboloid
z
c = x2
a2 + y2
b2 .
0 < z < c.
25.
By changing to polar coordinates, evaluate
Z ∞
0
Z ∞
0
e−√
x2+y2 dx dy.
26.
Make the change of variables u = x −y, v = x + y, to evaluate the integral
Z 1
0
dy
Z 1−y
0
e(x−y)/(x+y) dx.
27.
Make the change of variables u = y/x, v = x + y, to evaluate the integral
Z 1
0
dx
Z x
0
(x + y)ex+y
x2
dy.

C H A P T E R 6
Vector Analysis
1. INTRODUCTION
In Chapter 3, Sections 4 and 5, we have discussed the basic ideas of vector algebra.
The principal topic of this chapter will be vector calculus. First (Sections 2 and 3)
we shall consider some applications of vector products. Then (Section 4 ﬀ.) we
shall discuss diﬀerentiation and integration of vector functions. You have probably
seen Newton’s second law F = ma written as F = m d2r/dt2. You may have met
Gauss’s law in electricity which uses a surface integral of the normal component of
a vector (Section 10). Derivatives and integrals of vector functions are important
in almost every area of applied mathematics.
Such diverse ﬁelds as mechanics,
quantum mechanics, electrodynamics, theory of heat, hydrodynamics, optics, etc.,
make use of the vector equations and theorems we shall discuss in this chapter.
2. APPLICATIONS OF VECTOR MULTIPLICATION
In Chapter 3, Section 4, we deﬁned the scalar or dot product of vectors A and B,
and the vector or cross product of A and B as follows, where θ is the angle (≤180◦)
between the vectors:
(2.1)
A · B = AB cos θ = AxBx + AyBy + AzBz.
(2.2)
A×B = C, where |C | = AB sin θ, and the direction
of C is perpendicular to the plane of A and B and
in the sense of the rotation of A to B through the
angle θ (Figure 2.1).
Figure 2.1
276

Section 2
Applications of Vector Multiplication
277
Let us consider some applications of these deﬁnitions.
Work
In elementary physics you learned that work equals force times displace-
ment. If the force and displacement are not parallel, then the component of the
force perpendicular to the displacement does no work.
Figure 2.2
Figure 2.3
The work in this case is the component of the force parallel to the displacement,
multiplied by the displacement; that is W = (F cos θ) · d = Fd cos θ (Figure 2.2).
This can now conveniently be written as
(2.3)
W = Fd cos θ = F · d.
If the force varies with distance, and perhaps also the direction of motion d changes
with time, we can write, for an inﬁnitesimal vector displacement dr (Figure 2.3)
(2.4)
dW = F · dr.
We shall see later (Section 8) how to integrate dW in (2.4) to ﬁnd the total work
W done on a particle which is pushed along some path by a variable force F.
Figure 2.4
Figure 2.5
Torque
In doing a seesaw or lever problem (Figure 2.4), you multiply force times
distance; the quantity Fd is called the torque or moment∗of F, and the distance d
∗If the force F is due to a weight w = mg, then the torque about O in Figure 2.4 is mg · d =
g · (md); the moment of inertia (Chapter 5, Section 3) of m about O is md2. The quantity md is
called the moment (or ﬁrst moment) of m about O, and the quantity md2 is called the moment of
inertia (or second moment) of m about O. By extension, we call mgd the moment of mg, or F d
the moment of F. For an object which is not a point mass, the quantities md and md2 become
integrals (Chapter 5, Section 3).

278
Vector Analysis
Chapter 6
from the fulcrum O to the line of action of F is the lever arm of F. The lever arm
is by deﬁnition the perpendicular distance from O to the line of action of F. Then
in general (Figure 2.5) the torque (or moment) of a force about O (really about
an axis through O perpendicular to the paper) is deﬁned as the magnitude of the
force times its lever arm; in Figure 2.5 this is Fr sin θ. Now r × F has magnitude
rF sin θ, so the magnitude of the torque is |r × F|. We can also use the direction
of r × F in describing the torque, in the following way. If you curve the ﬁngers of
your right hand in the direction of the rotation produced by applying the torque,
then your thumb points in a direction parallel to the rotation axis. It is customary
to call this the direction of the torque. By comparing Figures 2.5 and 2.1, we see
that this is also the direction of r × F. With this agreement, then, r × F is the
torque or moment of F about an axis through O and perpendicular to the plane of
the paper in Figure 2.5.
Angular Velocity
In a similar way, a vector is used to represent the angular
velocity of a rotating body. The direction of the vector is along the axis of rotation in
the direction of progression of a right-handed screw turned the
way the body is rotating. Suppose P in Figure 2.6 represents a
point in a rigid body rotating with angular velocity ω. We can
show that the linear velocity v of point P is v = ω × r. First
of all, v is in the right direction: It is perpendicular to the
plane of r and ω and in the right sense. Next we want to show
that the magnitude of v is the same as |ω × r| = ωr sin θ. But
r sin θ is the radius of the circle in which P is traveling, and ω
is the angular velocity; thus (r sin θ)ω is |v|, as we claimed.
Figure 2.6
3. TRIPLE PRODUCTS
There are two products involving three vectors, one called the triple scalar product
(because the answer is a scalar) and the other called the triple vector product
(because the answer is a vector).
Figure 3.1
Figure 3.2
Triple Scalar Product
This is written A · (B × C).
There is a useful geo-
metrical interpretation of the triple scalar product (see Figure 3.1). Construct a
parallelepiped using A, B, C as three intersecting edges. Then |B × C| is the area

Section 3
Triple Products
279
of the base (Figure 3.2) because |B × C| = |B| |C| sin θ, which is the area of a
parallelogram with sides |B|, |C|, and angle θ. The height of the parallelepiped is
|A| cos φ (Figure 3.1). Then the volume of the parallelepiped is
|B| |C| sin θ|A| cos φ = |B × C| |A| cos φ = A · (B × C).
If φ > 90◦, this will come out negative, so in general we should say that the volume
is |A · (B × C)|. Any side may be used as base, so, for example, B · (C × A) must
also be either plus or minus the volume. There are six such triple scalar products,
all equal except for sign [or twelve if you count both the type A · (B × C) and the
type (B × C) · A)].
To write the triple scalar product in component form we ﬁrst write B × C in
determinant form [Chapter 3, equation (4.19)]:
(3.1)
B × C =

i
j
k
Bx
By
Bz
Cx
Cy
Cz

.
Now A · (B × C) = Ax(B × C)x + Ay(B × C)y + Az(B × C)z, and this is exactly
what we get by expanding, by elements of the ﬁrst row, the determinant in (3.2)
below; this determinant is then equal to A · (B × C).
(3.2)
A · (B × C) =

Ax
Ay
Az
Bx
By
Bz
Cx
Cy
Cz

.
Recalling that an interchange of rows changes the sign of a determinant, we can
now easily write out the six (or twelve) products mentioned above with their proper
signs. You should convince yourself of, and then remember, the following facts: The
order of the factors is all that counts; the dot and cross may be interchanged. If the
order of factors is cyclic (one way around the circle in Figure 3.3), all such triple
scalar products are equal. If you go the other way, you get another set all equal to
each other and the negatives of the ﬁrst set. For example,
(A × B) · C = A · (B × C)
(3.3)
= C · (A × B)
= −(A × C) · B, etc.
Since it doesn’t matter where the dot and cross are,
the triple scalar product is often written as (ABC),
meaning A · (B × C) or (A × B) · C.
Figure 3.3
Triple Vector Product
This is written A × (B × C). Before we try to evaluate
it, we can make the following observations. B × C is perpendicular to the plane of
B and C. A × (B × C) is perpendicular to the plane of A and (B × C); we are
particularly interested in the fact that A × (B × C) is perpendicular to (B × C).

280
Vector Analysis
Chapter 6
Now (see Figure 3.4) any vector perpendicular to B × C lies
in the plane perpendicular to B × C, that is, the plane of B
and C. Thus A × (B × C) is some vector in the plane of B
and C, and can be written as some combination aB+bC, where
a and b are scalars which we want to ﬁnd.
(See Chapter 3,
Section 8, Problem 5.) One way to ﬁnd a and b is to write out
A × (B × C) in component form.
We can simplify this work
by choosing our coordinate system carefully; recall that a vector
equation is true independently of the coordinate system. Given
the vectors A, B, C, we take the x axis along B, and the y axis
in the plane of B and C; then B × C is in the z direction. The
vectors in component form relative to these axes are:
Figure 3.4
B = Bxi,
C = Cxi + Cy j,
A = Axi + Ay j + Azk.
(3.4)
Using (3.4) we ﬁnd
B × C = Bxi × (Cxi + Cy j) = BxCy(i × j) = BxCyk,
A × (B × C) = AxBxCy(i × k) + AyBxCy(j × k)
= AxBxCy(−j) + AyBxCy(i).
(3.5)
We would like to write A × (B × C) in (3.5) as a combination of B and C; we can
do this by adding and subtracting AxBxCxi:
(3.6)
A × (B × C) = −AxBx(Cxi + Cy j) + (AyCy + AxCx)Bxi.
Each of these expressions is something simple in terms of the vectors in (3.4):
AxBx = A · B,
AyCy + AxCx = A · C,
Cxi + Cyj = C,
Bxi = B.
(3.7)
Using (3.7) in (3.6), we get
(3.8)
A × (B × C) = (A · C)B −(A · B)C.
This important formula should be learned, but not memorized in terms of letters,
because that is confusing when you want some other combination of the same letters.
Learn instead the following three facts:
(3.9)
The value of a triple vector product is a linear combination of the
two vectors in the parenthesis [B and C in (3.8)]; the coeﬃcient of
each vector is the dot product of the other two; the middle vector
in the triple product [B in (3.8)] always has the positive sign.
This method also covers triple vector products with the parenthesis ﬁrst; by (3.9),
the value of (B × C) × A is (A · B)C −(A · C)B. This is correct since it is just
the negative of what we had above for A × (B × C).

Section 3
Triple Products
281
Applications of the Triple Scalar Product
We have shown that the torque of
a force F about an axis may be written as r × F in one special case, namely when
r and F are in a plane perpendicular to the axis. Now let us consider the general
case of ﬁnding the torque produced by a force F about any given line (axis) L in
Figure 3.5. Let r be a vector from some (that is, any) point
on L to the line of action of F; let O be the tail of r. Then we
deﬁne the torque about the point O to be r × F. Note that this
cannot contradict our previous discussion of torque because we
were considering torque about a line before, and this deﬁnition
is of torque about a point. However, we shall show how the two
notions are connected. Also notice that r × F is not changed
if the head of r is moved along F; for this just adds a multiple
of F to r, and F × F = 0 (see Problem 10).
Figure 3.5
We shall now show that the torque of F about the line L through O is n · (r × F),
where n is a unit vector along L. To simplify the calculation, choose the positive z
axis in the direction n; then n = k. Think of a door hinged to rotate about the z
Figure 3.6
Figure 3.7
axis as in Figure 3.6. Let a force F be applied to it at the head of the vector r. We
ﬁrst ﬁnd the torque of F about the z axis by elementary methods and deﬁnition.
Break F into its components; the z component is parallel to the rotation axis and
produces no torque about it (pulling straight up or down on a door handle does not
tend to open or close the door!). The x and y components can be seen better if we
draw them in the (x, y) plane (Figure 3.7; note that the x and y axes are rotated
90◦clockwise from their usual position in order to compare this ﬁgure more easily
with Figure 3.6). The torque about the z axis produced by Fx and Fy is xFy −yFx
by the elementary deﬁnition of torque. We want to show that this is the same as
n · (r × F) or here k · (r × F). Using (3.2) we ﬁnd
k · (r × F) =

0
0
1
x
y
z
Fx
Fy
Fz

= xFy −yFx.
To summarize:

282
Vector Analysis
Chapter 6
(3.10)
In Figure 3.5, the torque of F about point O is r × F. The torque
of F about the line L through O is n · (r × F) where n is a unit
vector along L.
This proof can easily be given without reference to a coordinate system. Let
the symbols ∥and ⊥stand for parallel and perpendicular to the given rotation axis
n. Then any vector (F or r, say) can be written as the sum of a vector parallel
to the axis and a vector perpendicular to the axis (that is, somewhere in the plane
perpendicular to n):
r = r⊥+ r∥,
F = F⊥+ F∥.
Then the torque about O produced by F is
r × F = (r⊥+ r∥)×(F⊥+ F∥)
= r⊥×F⊥+ r⊥×F∥+ r∥×F⊥+ r∥×F∥.
The last term is zero (cross product of parallel vectors). Also r∥and F∥are parallel
to n; therefore their cross products with anything are in the plane perpendicular to
n, and the dot product of n with these is zero. Hence we have
n · (r × F) = n · (r⊥×F⊥).
Now r⊥and F⊥are in a plane perpendicular to n; thus the torque about n produced
by F⊥is (by Section 2) r⊥×F⊥. But since only the component of F perpendicular
to n produces a torque about n, r⊥×F⊥is the total torque about n produced by F.
The vector torque r⊥×F⊥is in the ±n direction since r⊥and F⊥are perpendicular
to n; the dot product of this vector torque with the unit vector n gives a scalar
torque of the same magnitude; the ± sign indicates whether the torque is in the +n
or the −n direction.
Example 1.
If F = i + 3j −k acts at the point (1, 1, 1), ﬁnd the torque of F about the
line r = 3i + 2k + (2i −2j + k)t.
We ﬁrst ﬁnd the vector torque about a point on the line, say the point (3, 0, 2).
By (3.10) and Figure 3.5, this is r × F where r is the vector from the point about
which we want the torque, to the point at which F acts, that is, from (3, 0, 2) to
(1, 1, 1); then r = (1, 1, 1) −(3, 0, 2) = (−2, 1, −1). The vector torque is
r × F =

i
j
k
−2
1
−1
1
3
−1

= 2i −3j −7k.
The torque about the line is n · (r × F) where n is a unit vector along the line,
namely n = 1
3(2i −2j + k). Then the torque about the line is
n · (r × F) = 1
3(2i −2j + k) · (2i −3j −7k) = 1.

Section 3
Triple Products
283
Example2.
As another application of the triple scalar product, let’s ﬁnd the Jacobian we
used in Chapter 5, Section 4 for changing variables in a multiple integral. As you
know, in rectangular coordinates the volume element is a rectangular box of volume
dx dy dz. In other coordinate systems, the volume element may be approximately a
parallelepiped as in Figure 3.1. We want a formula for the volume element in this
case. (See, for example, the cylindrical and spherical coordinate volume elements
in Chapter 5, Figures 4.4 and 4.5.)
Suppose we are given formulas for x, y, z as functions of new variables u, v,
w. Then we want to ﬁnd the vectors along the edges of the volume element in the
u, v, w system. Suppose vector A in Figure 3.1 is along the direction in which u
increases while v and w remain constant. Then if dr = i dx + j dy + k dz is a vector
in this direction, we have
A = ∂r
∂u du =

i ∂x
∂u + j ∂y
∂u + k ∂z
∂u

du.
Similarly if B is along the increasing v edge of the volume element and C is along
the increasing w edge, we have
B = ∂r
∂v dv =

i ∂x
∂v + j ∂y
∂v + k ∂z
∂v

dv,
C = ∂r
∂w dw =

i ∂x
∂w + j ∂y
∂w + k ∂z
∂w

dw.
Then by (3.2)
A · (B × C) =

∂x
∂u
∂y
∂u
∂z
∂u
∂x
∂v
∂y
∂v
∂z
∂v
∂x
∂w
∂y
∂w
∂z
∂w

du dv dw = J du dv dw
where J is the Jacobian of the transformation from x, y, z to u, v, w. Recall from
the discussion of (3.2) that the triple scalar product may turn out to be positive
or negative. Since we want a volume element to be positive, we use the absolute
value of J. Thus the u, v, w volume element is |J| du dv dw as stated in Chapter 5,
Section 4.
Applications of the Triple Vector Product
In Figure 3.8
(compare Figure 2.6), suppose the particle m is at rest on a ro-
tating rigid body (for example, the earth). Then the angular
momentum L of m about point O is deﬁned by the equation
L = r × (mv) = mr × v. In the discussion of Figure 2.6, we
showed that v = ω × r. Thus, L = mr × (ω × r). See Prob-
lem 16 and also Chapter 10, Section 4.
Figure 3.8
As another example, it is shown in mechanics that the cen-
tripetal acceleration of m in Figure 3.8 is a = ω ×(ω ×r). See
Problem 17.

284
Vector Analysis
Chapter 6
PROBLEMS, SECTION 3
1.
If A = 2i −j −k, B = 2i −3j + k, C = j + k, ﬁnd (A · B)C, A(B · C), (A × B) · C,
A · (B × C), (A × B) × C, A × (B × C).
For Problems 2 to 6, given A = i + j −2k, B = 2i −j + 3k, C = j −5k:
2.
Find the work done by the force B acting on an object which undergoes the dis-
placement C.
3.
Find the total work done by forces A and B if the object undergoes the displacement
C. Hint: Can you add the two forces ﬁrst?
4.
Let O be the tail of B and let A be a force acting at the head of B. Find the torque
of A about O; about a line through O perpendicular to the plane of A and B; about
a line through O parallel to C.
5.
Let A and C be drawn from a common origin and let C rotate about A with an
angular velocity of 2 rad/sec. Find the velocity of the head of C.
6.
In Problem 5, draw B with its tail at the head of A. If the ﬁgure is rotating as in
Problem 5, ﬁnd the velocity of the head of B. With the same diagram, let B be a
force; ﬁnd the torque of B about the head of C, and about the line C.
7.
A force F = 2i −3j + k acts at the point (1, 5, 2). Find the torque due to F
(a)
about the origin;
(b)
about the y axis;
(c)
about the line x/2 = y/1 = z/(−2).
8.
A vector force with components (1, 2, 3) acts at the point (3, 2, 1). Find the vector
torque about the origin due to this force and ﬁnd the torque about each of the
coordinate axes.
9.
The force F = 2i −j −5k acts at the point (−5, 2, 1). Find the torque due to F
about the origin and about the line 2x = −4y = −z.
10.
In Figure 3.5, let r′ be another vector from O to the line of F. Show that r′ × F =
r × F. Hint: r −r′ is a vector along the line of F and so is a scalar multiple of F.
(The scalar has physical units of distance divided by force, but this fact is irrelevant
for the vector proof.) Show also that moving the tail of r along n does not change
n · r × F. Hint: The triple scalar product is not changed by interchanging the dot
and the cross.
11.
Write out the twelve triple scalar products involving A, B, and C and verify the
facts stated just above (3.3).
12.
(a)
Simplify (A · B)2 −[(A × B) × B] · A by using (3.9).
(b)
Prove Lagrange’s identity: (A×B)·(C×D) = (A·C)(B·D)−(A·D)(B·C).
13.
Prove that the triple scalar product of (A × B), (B × C), and (C × A), is equal to
the square of the triple scalar product of A, B, and C. Hint: First let (B×C) = D,
and evaluate (A × B) × D. [See Am. J. Phys. 66, 739 (1998).]
14.
Prove the Jacobi identity: A × (B × C) + B × (C × A) + C × (A × B) = 0. Hint:
Expand each triple product as in equations (3.8) and (3.9).

Section 4
Differentiation of Vectors
285
15.
In the ﬁgure u1 is a unit vector in the direction of
an incident ray of light, and u3 and u2 are unit
vectors in the directions of the reﬂected and re-
fracted rays.
If u is a unit vector normal to the
surface AB, the laws of optics say that θ1 = θ3 and
n1 sin θ1 = n2 sin θ2, where n1 and n2 are constants
(indices of refraction). Write these laws in vector
form (using dot or cross products).
16.
In the discussion of Figure 3.8, we found for the angular momentum, the formula
L = mr × (ω × r). Use (3.9) to expand this triple product. If r is perpendicular to
ω, show that you obtain the elementary formula, angular momentum = mvr.
17.
Expand the triple product for a = ω × (ω × r) given in the discussion of Figure
3.8.
If r is perpendicular to ω (Problem 16), show that a = −ω2r, and so ﬁnd
the elementary result that the acceleration is toward the center of the circle and of
magnitude v2/r.
18.
Two moving charged particles exert forces on each other because each one creates
a magnetic ﬁeld in which the other moves (see Problem 4.6). These two forces are
proportional to v1 × [v2 × r] and v2 × [v1 × (−r)] where r is the vector joining the
particles. By using (3.9), show that these forces are equal and opposite (Newton’s
third “law”) if and only if r × (v1 × v2) = 0. Compare Problem 14.
19.
The force F = i + 3j + 2k acts at the point (1, 1, 1).
(a)
Find the torque of the force about the point (2, −1, 5). Careful! The vector r
goes from (2, −1, 5) to (1, 1, 1).
(b)
Find the torque of the force about the line r = 2i −j + 5k + (i −j + 2k)t. Note
that the line goes through the point (2, −1, 5).
20.
The force F = 2i −5k acts at the point (3, −1, 0). Find the torque of F about each
of the following lines.
(a)
r = (2i −k) + (3j −4k)t.
(b)
r = i + 4j + 2k + (2i + j −2k)t.
4. DIFFERENTIATION OF VECTORS
If A = iAx + jAy + kAz, where i, j, k are ﬁxed unit vectors and Ax, Ay, Az are
functions of t, then we deﬁne the derivative dA/dt by the equation
(4.1)
dA
dt = idAx
dt + jdAy
dt + kdAz
dt .
Thus the derivative of a vector A means a vector whose components are the deriva-
tives of the components of A.

286
Vector Analysis
Chapter 6
Example 1.
Let (x, y, z) be the coordinates of a moving particle at time t; then x, y, z are
functions of t. The vector displacement of the particle from the origin at time t
is
(4.2)
r = ix + jy + kz,
where r is a vector from the origin to the particle at time t. We say that r is
the position vector or vector coordinate of the particle. The components of the
velocity of the particle at time t are dx/dt, dy/dt, dz/dt so the velocity vector is
(4.3)
v = dr
dt = idx
dt + jdy
dt + kdz
dt .
The acceleration vector is
(4.4)
a = dv
dt = id2x
dt2 + jd2y
dt2 + kd2z
dt2 .
The product of a scalar and a vector and the dot and cross products of vectors
are diﬀerentiated by the ordinary calculus rules for diﬀerentiating a product, with
one word of caution: The order of the factors must be kept in a cross product. You
can easily prove equations (4.5) below by writing out components (Problem 1) and
using (4.1).
d
dt(aA) = da
dt A + adA
dt ,
d
dt(A · B) = A · dB
dt + dA
dt · B,
d
dt(A × B) = A × dB
dt + dA
dt × B.
(4.5)
The second term in (d/dt)(A· B) can be written B·dA/dt if you like since A·B =
B · A. But the corresponding term in (d/dt)(A × B) must not be turned around
unless you put a minus sign in front of it since A × B = −B × A.
Example 2.
Consider the motion of a particle in a circle at constant speed. We can then
write
r2 = r · r = const.,
v2 = v · v = const.
(4.6)
If we diﬀerentiate these two equations using (4.5), we get
2r · dr
dt = 0
or
r · v = 0,
2v · dv
dt = 0
or
v · a = 0.
(4.7)

Section 4
Differentiation of Vectors
287
Also diﬀerentiating r · v = 0, we get
(4.8)
r · a + v · v = 0
or
r · a = −v2.
The ﬁrst of equations (4.7) says that r is perpendicular to v; the second says that
a is perpendicular to v. Therefore a and r are either parallel or antiparallel (since
the motion is in a plane) and the angle θ between a and r is either 0◦or 180◦. From
(4.8) and the deﬁnition of scalar product, we have
(4.9)
r · a = |r| |a| cos θ = −v2.
Thus we see that cos θ is negative, so θ = 180◦. Then from (4.9) we get
(4.10)
|r| |a|(−1) = −v2
or
a = v2
r .
We have just given a vector proof that for motion in a circle at constant speed the
acceleration is toward the center of the circle and of magnitude v2/r.
So far we have written vectors only in terms of their rectangular components
using the unit basis vectors i, j, k. It is often convenient to use other coordinate
systems, for example polar coordinates in two dimensions and spherical or cylin-
drical coordinates in three dimensions (see Chapter 5, Section 4, and Chapter 10,
Sections 8 and 9). We shall consider using vectors in various coordinate systems in
detail in Chapter 10, but it will be useful to discuss brieﬂy here the use of plane
polar coordinates. In Figure 4.1, think of starting at the point (x, y) or (r, θ) and
moving along the line θ = const. in the direction of increasing r. We call this the
“r direction”; we draw a unit vector (that is, a vector of length 1) in this direction
Figure 4.1
Figure 4.2
and label it er. Similarly, think of moving along the circle r = const. in the direction
of increasing θ. We call this the “θ direction”; we draw a unit vector tangent to
the circle and label it eθ. These two vectors er and eθ are the polar coordinate
unit basis vectors just as i and j are the rectangular unit basis vectors. We can
now write any given vector in terms of its components in the directions er and
eθ (by ﬁnding its projections in these directions). There is a complication here,
however. In rectangular coordinates, the vectors i and j are constant in magnitude
and direction. The polar coordinate unit basis vectors are constant in magnitude
but their directions change from point to point (Figure 4.2). Thus in calculating
the derivative of a vector written in polar coordinates, we must diﬀerentiate the
basis vectors as well as the components [compare (4.1) where we diﬀerentiate the

288
Vector Analysis
Chapter 6
components only.] One straightforward way to do this is to express the vectors er
and eθ in terms of i and j. From Figure 4.3, we see that the x and y components
of er are cos θ and sin θ. Thus we have
Figure 4.3
(4.11)
er = i cosθ + j sin θ.
Similarly (Problem 7) we ﬁnd
(4.12)
eθ = −i sin θ + j cos θ.
Diﬀerentiating er and eθ with respect to t, we get
der
dt = −i sin θ dθ
dt + j cos θ dθ
dt = eθ
dθ
dt ,
deθ
dt = −i cosθ dθ
dt −j sin θ dθ
dt = −er
dθ
dt .
(4.13)
We can now use (4.13) in calculating the derivative of any vector which is written
in terms of its polar components.
Example 3.
Given A = Arer + Aθeθ, where Ar and Aθ are functions of t, ﬁnd dA/dt.
We get
dA
dt = er
dAr
dt + Ar
der
dt + eθ
dAθ
dt + Aθ
deθ
dt .
Using (4.13), we ﬁnd
dA
dt = er
dAr
dt + eθAr
dθ
dt + eθ
dAθ
dt −erAθ
dθ
dt .
We can ﬁnd higher-order derivatives if we like by diﬀerentiating again using (4.13)
each time to evaluate the derivatives of er and eθ.

Section 5
Fields
289
PROBLEMS, SECTION 4
1.
Verify equations (4.5) by writing out the components.
2.
Let the position vector (with its tail at the origin) of a moving particle be r = r(t) =
t2i −2tj + (t2 + 2t)k, where t represents time.
(a)
Show that the particle goes through the point (4, −4, 8). At what time does it
do this?
(b)
Find the velocity vector and the speed of the particle at time t; at the time
when it passes though the point (4, −4, 8).
(c)
Find the equations of the line tangent to the curve described by the particle
and the plane normal to this curve, at the point (4, −4, 8).
3.
As in Problem 2, if the position vector of a particle is r = (4 + 3t)i + t3j −5tk, at
what time does it pass through the point (1, −1, 5)? Find its velocity at this time.
Find the equations of the line tangent to its path and the plane normal to the path,
at (1, −1, 5).
4.
Let r = r(t) be a vector whose length is always 1 (it may vary in direction). Prove
that either r is a constant vector or dr/dt is perpendicular to r. Hint: Diﬀerentiate
r · r.
5.
The position of a particle at time t is given by r = i cos t + j sin t + kt. Show that
both the speed and the magnitude of the acceleration are constant. Describe the
motion.
6.
The force acting on a moving charged particle in a magnetic ﬁeld B is F = q(v × B)
where q is the electric charge of the particle, and v is its velocity. Suppose that a
particle moves in the (x, y) plane with a uniform B in the z direction. Assuming
Newton’s second law, m dv/dt = F, show that the force and velocity are perpendic-
ular and that both have constant magnitude. Hint: Find (d/dt)(v · v).
7.
Sketch a ﬁgure and verify equation (4.12).
8.
In polar coordinates, the position vector of a particle is r = rer. Using (4.13), ﬁnd
the velocity and acceleration of the particle.
9.
The angular momentum of a particle m is deﬁned by L = mr × (dr/dt) (see end of
Section 3). Show that
dL
dt = mr × d2r
dt2 .
10.
If V(t) is a vector function of t, ﬁnd the indeﬁnite integral
Z „
V × d2V
dt2
«
dt.
5. FIELDS
Many physical quantities have diﬀerent values at diﬀerent points in space.
For
example, the temperature in a room is diﬀerent at diﬀerent points: high near a reg-
ister, low near an open window, and so on. The electric ﬁeld around a point charge
is large near the charge and decreases as we go away from the charge. Similarly,
the gravitational force acting on a satellite depends on its distance from the earth.
The velocity of ﬂow of water in a stream is large in rapids and in narrow channels
and small over ﬂat areas and where the stream is wide. In all these examples there
is a particular region of space which is of interest for the problem at hand; at every

290
Vector Analysis
Chapter 6
point of this region some physical quantity has a value. The term ﬁeld is used to
mean both the region and the value of the physical quantity in the region (for ex-
ample, electric ﬁeld, gravitational ﬁeld). If the physical quantity is a scalar (for
example, temperature), we speak of a scalar ﬁeld.
If the quantity is a vector
(for example, electric ﬁeld, force, or velocity), we speak of a vector ﬁeld.
Note
again a point which we discussed in “endpoint problems” in Chapter 4, Section 10:
Physical problems are often restricted to certain regions of space, and our mathe-
matics must take account of this.
Figure 5.1
A simple example of a scalar ﬁeld is the gravitational potential energy near the
earth; its value is V = mgz at every point of height z above some arbitrary reference
level [which we take as the (x, y) plane]. Suppose that on a hill (Figure 5.1) we mark
a series of curves each corresponding to some value of z (curves of constant elevation,
often called contour lines or level lines). Any curve or surface on which a potential
is constant is called an equipotential. Thus these level lines are equipotentials of the
gravitational ﬁeld since along any one curve the value of the gravitational potential
energy mgz is constant.
The horizontal planes which intersect the hill in these
curves are equipotential surfaces (or level surfaces) of the gravitational ﬁeld. (See
Problems, Section 6 for more examples.)
As another example, let us ask for the equipotential surfaces in the ﬁeld of an
electric point charge q. The potential is V = 9·109q/r (in SI units) at a point which
is a distance r from the charge. The potential V is constant if r is constant; that
is, the equipotentials of this electric ﬁeld are spheres with centers at the charge.
Similarly we could imagine drawing a set of surfaces (probably very irregular) in a
room so that at every point of a single surface the temperature would be constant.
These surfaces would be like equipotentials; they are called isothermals when the
constant quantity is the temperature.
6. DIRECTIONAL DERIVATIVE; GRADIENT
Suppose that we know the temperature T (x, y, z) at every point of a room, say,
or of a metal bar. Starting at a given point we could ask for the rate of change
of the temperature with distance (in degrees per centimeter) as we move away
from the starting point. The chances are that the temperature increases in some
directions and decreases in other directions, and that it increases more rapidly in
some directions than others. Thus the rate of change of temperature with distance
depends upon the direction in which we move; consequently it is called a directional
derivative. In symbols, we want to ﬁnd the limiting value of ∆T/∆s where ∆s is an
element of distance (arc length) in a given direction, and ∆T is the corresponding

Section 6
Directional Derivative; Gradient
291
change in temperature; we write the directional derivative as dT/ds. We could also
ask for the direction in which dT/ds has its largest value; this is physically the
direction from which heat ﬂows (that is, heat ﬂows from hot to cold, in the opposite
direction from the maximum rate of temperature increase).
Before we discuss how to calculate directional derivatives, consider another ex-
ample. Suppose we are standing at a point on the side of the hill of Figure 5.1 (not
at the top), and ask the question “In what direction does the hill slope downward
most steeply from this point?” This is the direction in which you would start to
slide if you lost your footing; it is the direction most people would probably call
“straight” down. We want to make this vague idea more precise. Suppose we move
a small distance ∆s on the hill; the vertical distance ∆z which we have gone may
be positive (uphill) or negative (downhill) or zero (around the hill). Then ∆z/∆s
and its limit dz/ds depend upon the direction in which we go; dz/ds is a directional
derivative. The direction of steepest slope is the direction in which dz/ds has its
largest absolute value. Notice that since the gravitational potential energy of a
mass m is V = mgz, maximizing dz/ds is the same as maximizing dV/ds, where
the equipotentials on the hill are V (x, y) = mgz(x, y) = const.
Let us now state and solve the general problem of ﬁnding a directional derivative.
We are given a scalar ﬁeld, that is, a function φ(x, y, z) [or φ(x, y) in a two-variable
problem; the following discussion applies to two-variable problems if we simply drop
terms and equations containing z]. We want to ﬁnd dφ/ds, the rate of change of
φ with distance, at a given point (x0, y0, z0) and in a given direction. Let u =
ia + jb + kc be a unit vector in the given direction.
In Figure 6.1, we start at
(x0, y0, z0) and go a distance s (s ≥0) in the direction u to the point (x, y, z); the
vector joining these points is us since u is a unit vector. Then,
Figure 6.1
(x, y, z) −(x0, y0, z0) = us = (ai + bj + ck)s
or
(6.1)





x = x0 + as,
y = y0 + bs,
z = z0 + cs.
Equations (6.1) are the parametric equations of the line through (x0, y0, z0) in the
direction u [see Chapter 3, equation (5.8)] with the distance s (instead of t) as the
parameter, and with u (instead of A) as the vector along the line. From (6.1) we
see that along the line, x, y, and z are each functions of a single variable, namely s
[all the other letters in (6.1) are given constants]. If we substitute x, y, z in (6.1)
into φ(x, y, z), then φ becomes a function of just the one variable s. That is, along
the straight line (6.1), φ is a function of one variable, namely the distance along the
line measured from (x0, y0, z0). Since φ depends on s alone, we can ﬁnd dφ/ds:
dφ
ds = ∂φ
∂x
dx
ds + ∂φ
∂y
dy
ds + ∂φ
∂z
dz
ds
= ∂φ
∂xa + ∂φ
∂y b + ∂φ
∂z c.
(6.2)
This is the dot product of u with the vector i(∂φ/∂x)+j(∂φ/∂y)+k(∂φ/∂z). This
vector is called the gradient of φ and is written gradφ or ∇φ (read “del φ”). By
deﬁnition

292
Vector Analysis
Chapter 6
(6.3)
∇φ = grad φ = i ∂φ
∂x + j ∂φ
∂y + k ∂φ
∂z .
Then we can write (6.2) as
(6.4)
dφ
ds = ∇φ · u
(directional derivative).
Example 1.
Find the directional derivative of φ = x2y + xz at (1, 2, −1) in the direction
A = 2i −2j + k.
Here u is a unit vector obtained by dividing A by |A|. Then we have
u = 1
3(2i −2j + k).
Using (6.3) we get
∇φ = i ∂φ
∂x + j ∂φ
∂y + k ∂φ
∂z = (2xy + z)i + x2j + xk,
∇φ at the point (1, 2, −1) = 3i + j + k.
Then from (6.4) we ﬁnd
dφ
ds at (1, 2, −1) = ∇φ · u = 2 −2
3 + 1
3 = 5
3.
Figure 6.2
The gradient of a function has useful geometrical
and physical meanings which we shall now inves-
tigate. From (6.4), using the deﬁnition of a dot
product, and the fact that |u| = 1, we have
(6.5)
dφ
ds = |∇φ| cos θ,
where θ is the angle between u and the vector
∇φ. Thus dφ/ds is the projection of ∇φ on the
direction u (Figure 6.2). We ﬁnd the largest value
of dφ/ds (namely |∇φ|) if we go in the direction
of ∇φ (that is, θ = 0 in Figure 6.2). If we go in
the opposite direction (that is, θ = 180◦in Figure 6.2) we ﬁnd the largest rate of
decrease of φ, namely dφ/ds = −|∇φ|.
Example 2.
Suppose that the temperature T at the point (x, y, z) is given by the equation
T = x2 −y2 + xyz + 273. In which direction is the temperature increasing most
rapidly at (−1, 2, 3), and at what rate? Here ∇T = (2x+yz)i+(−2y+xz)j+xyk =
4i −7j −2k at (−1, 2, 3), and the increase in temperature is fastest in the direction
of this vector. The rate of increase is dT/ds = |∇T | = √16 + 49 + 4 =
√
69. We

Section 6
Directional Derivative; Gradient
293
can also say that the temperature is decreasing most rapidly in the direction −∇T ;
in this direction, dT/ds = −
√
69. Heat ﬂows in the direction −∇T (that is, from
hot to cold).
Figure 6.3
Next suppose u is tangent to the surface φ = const. at the point P(x0, y0, z0)
(Figure 6.3).
We want to show that dφ/ds in the direction u is then equal to
zero. Consider ∆φ/∆s for paths PA, PB, PC,
etc., approaching the tangent u. Since φ = const.
on the surface, and P, A, B, C, etc. are all on
the surface, ∆φ = 0, and ∆φ/∆s = 0 for such
paths. But dφ/ds in the tangent direction is the
limit of ∆φ/∆s as ∆s →0 (that is, as PA, PB,
etc., approach u), so dφ/ds in the direction u is
zero also. Then for u along the tangent to φ = const., ∇φ · u = 0; this means that
∇φ is perpendicular to u. Since this is true for any u tangent to the surface at the
point (x0, y0, z0), then at that point:
The vector ∇φ is perpendicular (normal) to the surface φ =const.
Since |∇φ| is the value of the directional derivative in the direction normal (that is,
perpendicular) to the surface, it is often called the normal derivative and written
|∇φ| = dφ/dn.
We now see that the direction of largest rate of change of a given function φ
with distance is perpendicular to the equipotentials (or level lines) φ = const. In
the temperature problem, the direction of maximum dT/ds is then perpendicular to
the isothermals. At any point this is the direction of ∇T and is called the direction
of the temperature gradient. In the problem of the hill, the direction of steepest
slope at any point is perpendicular to the level lines, that is, along ∇z or ∇V .
Example 3.
Given the surface x3y2z = 12, ﬁnd the equations of the tangent plane and
normal line at (1, −2, 3).
This is a level surface of the function w = x3y2z, so the normal direction is the
direction of the gradient
∇w = 3x2y2zi + 2x3yzj + x3y2k = 36i −12j + 4k
at
(1, −2, 3).
A simpler vector in the same direction is 9i −3j + k. Then (see Chapter 3, Section
5) the equation of the tangent plane is
9(x −1) −3(y + 2) + (z −3) = 0,
and the equations of the normal line are
(6.6)
x −1
9
= y + 2
−3
= z −3
1
.
In (6.3) we have written the gradient in terms of its rectangular components.
It is useful to write it in cylindrical and spherical coordinates also.
(Note that
this includes polar coordinates when z = 0). In cylindrical coordinates we want
the components of ∇φ in the directions er, eθ, and ez = k. According to (6.4),

294
Vector Analysis
Chapter 6
the component of ∇f in any direction u is the directional derivative df/ds in that
direction. (We are changing the function from φ to f since φ is used as an angle in
spherical, and sometimes in cylindrical and polar, coordinates.) The element of arc
length ds in the r direction is dr so the directional derivative in the r direction is
df/dr (θ and z constant) which we write as ∂f/∂r. In the θ direction, the element
of arc length is r dθ (Chapter 5, Section 4) so the directional derivative in the θ
direction is df/(r dθ) (with r and z constant) which we write as (1/r)∂f/∂θ. Thus
we have in cylindrical coordinates (or polar without the z term)
(6.7)
∇f = er
∂f
∂r + eθ
1
r
∂f
∂θ + ez
∂f
∂z
in cylindrical coordinates.
In a similar way we can show (Problem 21) that
(6.8)
∇f = er
∂f
∂r + eθ
1
r
∂f
∂θ + eφ
1
r sin φ
∂f
∂φ
in spherical coordinates.
PROBLEMS, SECTION 6
1.
Find the gradient of w = x2y3z at (1, 2, −1).
2.
Starting from the point (1, 1), in what direction does the function φ = x2 −y2 + 2xy
decrease most rapidly?
3.
Find the derivative of xy2 + yz at (1, 1, 2) in the direction of the vector 2i −j + 2k.
4.
Find the derivative of zex cos y at (1, 0, π/3) in the direction of the vector i + 2j.
5.
Find the gradient of φ = z sin y −xz at the point (2, π/2, −1). Starting at this
point, in what direction is φ decreasing most rapidly? Find the derivative of φ in
the direction 2i + 3j.
6.
Find a vector normal to the surface x2 + y2 −z = 0 at the point (3, 4, 25). Find the
equations of the tangent plane and normal line to the surface at that point.
7.
Find the direction of the line normal to the surface x2y + y2z + z2x + 1 = 0 at the
point (1, 2, −1). Write the equations of the tangent plane and normal line at this
point.
8.
(a)
Find the directional derivative of φ = x2 +sin y −xz in the direction i+2j−2k
at the point (1, π/2, −3).
(b)
Find the equation of the tangent plane and the equations of the normal line
to φ = 5 at the point (1, π/2, −3).
9.
(a)
Given φ = x2 −y2z, ﬁnd ∇φ at (1, 1, 1).
(b)
Find the directional derivative of φ at (1, 1, 1) in the direction i −2j + k.
(c)
Find the equations of the normal line to the surface x2 −y2z = 0 at (1, 1, 1).
For Problems 10 to 14, use a computer as needed to make plots of the given surfaces and
the isothermal or equipotential curves. Try both 3D graphs and contour plots.

Section 6
Directional Derivative; Gradient
295
10.
If the temperature in the (x, y) plane is given by T = xy−x, sketch a few isothermal
curves, say for T = 0, 1, 2, −1, −2. Find the direction in which the temperature
changes most rapidly with distance from the point (1, 1), and the maximum rate of
change. Find the directional derivative of T at (1, 1) in the direction of the vector
3i−4j. Heat ﬂows in the direction −∇T (perpendicular to the isothermals). Sketch
a few curves along which heat would ﬂow.
11.
(a)
Given φ = x2 −y2, sketch on one graph the curves φ = 4, φ = 1, φ = 0,
φ = −1, φ = −4. If φ is the electrostatic potential, the curves φ = const. are
equipotentials, and the electric ﬁeld is given by E = −∇φ. If φ is temperature,
the curves φ =const. are isothermals and ∇φ is the temperature gradient; heat
ﬂows in the direction −∇φ.
(b)
Find and draw on your sketch the vectors −∇φ at the points (x, y) = (±1, ±1),
(0, ±2), (±2, 0). Then, remembering that ∇φ is perpendicular to φ = const.,
sketch, without computation, several curves along which heat would ﬂow [see(a)].
12.
For Problem 11,
(a)
Find the magnitude and direction of the electric ﬁeld at (2, 1).
(b)
Find the direction in which the temperature is decreasing most rapidly at
(−3, 2).
(c)
Find the rate of change of temperature with distance at (1, 2) in the direction
3i −j.
13.
Let φ = ex cos y. Let φ represent either temperature or electrostatic potential. Refer
to Problem 11 for deﬁnitions and ﬁnd:
(a)
The direction in which the temperature is increasing most rapidly at (1, −π/4)
and the magnitude of the rate of increase.
(b)
The rate of change of temperature with distance at (0, π/3) in the direction
i + j
√
3.
(c)
The direction and magnitude of the electric ﬁeld at (0, π).
(d)
The magnitude of the electric ﬁeld at x = −1, any y.
14.
(a)
Suppose that a hill (as in Fig. 5.1) has the equation z = 32 −x2 −4y2, where
z = height measured from some reference level (in hundreds of feet). Sketch a
contour map (that is, draw on one graph a set of curves z = const.); use the
contours z = 32, 19, 12, 7, 0.
(b)
If you start at the point (3, 2) and in the direction i + j, are you going uphill
or downhill, and how fast?
15.
Repeat Problem 14b for the following points and directions.
(a) (4, −2), i + j
(b) (−3, 1), 4i + 3j
(c) (2, 2), −3i + j
(d) (−4, −1), 4i −3j
16.
Show by the Lagrange multiplier method that the maximum value of dφ/ds is |∇φ|.
That is, maximize dφ/ds given by (6.3) subject to the condition a2+b2+c2 = 1. You
should get two values (±) for the Lagrange multiplier λ, and two values (maximum
and minimum) for dφ/ds. Which is the maximum and which is the minimum?
17.
Find ∇r, where r =
p
x2 + y2, using (6.7) and also using (6.3). Show that your
results are the same by using (4.11) and (4.12).
As in Problem 17, ﬁnd the following gradients in two ways and show that your answers
are equivalent.
18.
∇x
19.
∇y
20.
∇(r2)
21.
Verify equation (6.8); that is, ﬁnd ∇f in spherical coordinates as we did for cylin-
drical coordinates. Hint: What is ds in the φ direction? See Chapter 5, Figure 4.5.

296
Vector Analysis
Chapter 6
7. SOME OTHER EXPRESSIONS INVOLVING ∇
If we write ∇φ as [i(∂/∂x) + j(∂/∂y) + k(∂/∂z)]φ, we can then call the bracket ∇.
By itself ∇has no meaning (just as d/dx alone has no meaning; we must put some
function after it to be diﬀerentiated). However, it is useful to use ∇much as we
use d/dx to indicate a certain operation.
We call ∇a vector operator and write
(7.1)
∇= i ∂
∂x + j ∂
∂y + k ∂
∂z .
It is more complicated than d/dx (which is a scalar operator) because ∇has
vector properties too.
So far we have considered ∇φ where φ is a scalar; we next want to consider whether
∇can operate on a vector.
Suppose V(x, y, z) is a vector function, that is, the three components Vx, Vy, Vz
of V are functions of x, y, z:
V(x, y, z) = iVx(x, y, z) + jVy(x, y, z) + kVz(x, y, z).
(The subscripts mean components, not partial derivatives.) Physically, V represents
a vector ﬁeld (for example, the electric ﬁeld about a point charge). At each point
of space there is a vector V, but the magnitude and direction of V may vary from
point to point. We can form two useful combinations of ∇and V. We deﬁne the
divergence of V, abbreviated div V or ∇· V, by (7.2):
(7.2)
∇· V = div V = ∂Vx
∂x + ∂Vy
∂y + ∂Vz
∂z .
We deﬁne the curl of V, written ∇× V, by (7.3):
∇× V = curl V
(7.3)
= i
∂Vz
∂y −∂Vy
∂z

+ j
∂Vx
∂z −∂Vz
∂x

+ k
∂Vy
∂x −∂Vx
∂y

=

i
j
k
∂
∂x
∂
∂y
∂
∂z
Vx
Vy
Vz

.
You should study these expressions to see how we are using ∇as “almost” a vec-
tor. The deﬁnitions of divergence and curl are the partial derivative expressions, of
course. However, the similarity of the formulas (7.2) and (7.3) to those for A · B
and A × B helps us to remember ∇· V and ∇× V. But you must remember to
put the partial derivative “components” of ∇before the components of V in each

Section 7
Some Other Expressions Involving ∇
297
term [for example, in evaluating the determinant in (7.3)]. Note that ∇· V is a
scalar and ∇× V is a vector (compare A · B and A × B). We shall discuss later
the meaning and some of the applications of the divergence and the curl of a vector
function.
The quantity ∇φ in (6.3) is a vector function; we can then let V = ∇φ in
(7.2) and ﬁnd ∇· ∇φ = div gradφ. This is a very important expression called the
Laplacian of φ; it is usually written as ∇2φ. From (6.3) and (7.2), we have
∇2φ = ∇· ∇φ = div grad φ = ∂
∂x
∂φ
∂x + ∂
∂y
∂φ
∂y + ∂
∂z
∂φ
∂z
(7.4)
= ∂2φ
∂x2 + ∂2φ
∂y2 + ∂2φ
∂z2
(the Laplacian).
The Laplacian is part of several important equations in mathematical physics:
∇2φ = 0
Laplace’s equation.
∇2φ = 1
a2
∂2φ
∂t2
wave equation.
∇2φ = 1
a2
∂φ
∂t
diﬀusion, heat conduction, Schr¨odinger equation.
These equations arise in numerous problems in heat, hydrodynamics, electricity
and magnetism, aerodynamics, elasticity, optics, etc.; we shall discuss solving such
equations in Chapter 13.
There are many other more complicated expressions involving ∇and one or more
scalar or vector functions, which arise in various applications of vector analysis. For
reference we list a table of such expressions at the end of the chapter (page 339).
Notice that these are of two kinds: (1) expressions involving two applications of
∇such as ∇· ∇φ = ∇2φ; (2) combinations of ∇with two functions (vectors or
scalars) such as ∇× (φV). We can verify these expressions simply by writing out
components. However, it is usually simpler to use the same formulas we would use
if ∇were an ordinary vector, being careful to remember that ∇is also a diﬀerential
operator.
Example 1.
Evaluate ∇× (∇× V). We use (3.8) for A× (B× C) being careful to write
both ∇’s before the vector function V which they must diﬀerentiate. Then we get
∇× (∇× V) = ∇(∇· V) −(∇· ∇)V
= ∇(∇· V) −∇2V.
This is a vector as it should be; the Laplacian of a vector, ∇2V, simply means a
vector whose components are ∇2Vx, ∇2Vy, ∇2Vz.
Example 2.
Find ∇· (φV), where φ is a scalar function and V is a vector function. Here
we must diﬀerentiate a product, so our result will contain two terms. We could
write these as
(7.5)
∇· (φV) = ∇φ · (φV) + ∇V · (φV),

298
Vector Analysis
Chapter 6
where the subscripts on ∇indicate which function is to be diﬀerentiated. Since φ
is a scalar, it can be moved past the dot. Then
∇φ · (φV) = (∇φφ) · V = V · (∇φ),
where we have removed the subscript in the last step since V no longer appears
after ∇. Actually you may see in books (∇φ) · V meaning that only the φ is to be
diﬀerentiated, but it is clearer to write it as V · (∇φ). [Be careful with (∇φ) × V,
however; assuming that this means that only φ is to be diﬀerentiated, the clear way
to write it is −V × (∇φ); note the minus sign.] In the second term of (7.5), φ is a
scalar and is not diﬀerentiated; thus it is just like a constant and we can write this
term as φ(∇· V). Collecting our results, we have
(7.6)
∇· (φV) = V · ∇φ + φ(∇· V).
In Chapter 10, Section 9, we will derive the formulas for div V = ∇· V and
∇2f in cylindrical and spherical coordinates.
However, it is useful to have the
results for reference, so we state them here. Actually, these can be done as partial
diﬀerentiation problems (see Chapter 4, Section 11), but the algebra is messy.
In cylindrical coordinates (or polar by omitting the z term):
∇· V = 1
r
∂
∂r (rVr) + 1
r
∂
∂θVθ + ∂
∂z Vz
(7.7)
∇2f = 1
r
∂
∂r

r∂f
∂r

+ 1
r2
∂2f
∂θ2 + ∂2f
∂z2 .
(7.8)
In spherical coordinates:
∇· V = 1
r2
∂
∂r

r2Vr
	
+
1
r sin θ
∂
∂θ (Vθ sin θ) +
1
r sin θ
∂Vφ
∂φ
(7.9)
∇2f = 1
r2
∂
∂r

r2 ∂f
∂r

+
1
r2 sin θ
∂
∂θ

sin θ ∂f
∂θ

+
1
r2 sin2 θ
∂2f
∂φ2 .
(7.10)
PROBLEMS, SECTION 7
The purpose in doing the following simple problems is to become familiar with the formulas
we have discussed. So a good study method is to do them by hand and then check your
results by computer.
Compute the divergence and the curl of each of the following vector ﬁelds.
1.
r = xi + y j + zk
2.
r = xi + y j
3.
V = zi + y j + xk
4.
V = yi + zj + xk
5.
V = x2i + y2j + z2k
6.
V = x2yi + y2xj + xyzk
7.
V = x sin y i + cos y j + xyk
8.
V = sinh z i + 2y j + x cosh z k

Section 8
Line Integrals
299
Calculate the Laplacian ∇2 of each of the following scalar ﬁelds.
9.
x3 −3xy2 + y3
10.
ln(x2 + y2)
11.
p
x2 −y2
12.
(x + y)−1
13.
xy(x2 + y2 −5z2)
14.
(x2 + y2 + z2)−1/2
15.
xyz(x2 −2y2 + z2)
16.
ln(x2 + y2 + z2)
17.
Verify formulas (b), (c), (d), (g), (h), (i), (j), (k) of the table of vector identities
at the end of the chapter. Hint for (j): Start by expanding the two triple vector
products on the right.
For r = xi + y j + zk, evaluate
18.
∇× (k × r)
19.
∇·
„ r
|r|
«
20.
∇×
„ r
|r|
«
8. LINE INTEGRALS
In Section 2, we discussed the fact that the work done by a force F on an object
which undergoes an inﬁnitesimal vector displacement dr can be written as
(8.1)
dW = F · dr.
Suppose the object moves along some path (say A to B in Fig. 8.1), with the force
F acting on it varying as it moves. For example, F might be the force on a charged
particle in an electric ﬁeld; then F would vary from point to point, that is F would
be a function of x, y, z. However, on a curve, x, y, z are related by the equations of
the curve. In three dimensions it takes two equations to determine a curve (as an
intersection of two surfaces; for example, consider the equations of a straight line
in Chapter 3, Section 5). Thus along a curve there is only one independent variable;
Figure 8.1
we can then write F and dr = i dx+j dy+k dz as functions of a single variable. The
integral of dW = F · dr along the given curve then becomes an ordinary integral
of a function of one variable and we can evaluate it to ﬁnd the total work done
by F in moving an object in Figure 8.1 from A to B. Such an integral is called a
line integral. A line integral means an integral along a curve (or line), that is, a
single integral as contrasted to a double integral over a surface or area, or a triple
integral over a volume. The essential point to understand about a line integral is
that there is one independent variable, because we are required to remain on a

300
Vector Analysis
Chapter 6
curve. In two dimensions, the equation of a curve might be written y = f(x), where
x is the independent variable. In three dimensions, the equations of a curve (for
example, a straight line) can be written either like (6.6) (where we could take x as
the independent variable and ﬁnd y and z as functions of x), or (6.1) (where s is the
independent variable and x, y, z are all functions of s). To evaluate a line integral,
then, we must write it as a single integral using one independent variable.
Example 1.
Given the force F = xy i −y2 j, ﬁnd the work done by F along the paths
indicated in Figure 8.2 from (0, 0) to (2, 1).
Since r = x i + y j on the (x, y) plane, we have
dr = i dx + j dy,
F · dr = xy dx −y2 dy.
We want to evaluate
(8.2)
W =

(xy dx −y2 dy).
Figure 8.2
First we must write the integrand in terms of one variable. Along path 1 (a straight
line), y = 1
2x, dy = 1
2dx. Substituting these values into (8.2), we obtain an integral
in the one variable x. The limits for x (Figure 8.2) are 0 to 2. Thus, we get
W1 =

 2
0

x · 1
2x dx −
1
2x
2
· 1
2 dx

=

 2
0
3
8x2 dx = x3
8

2
0
= 1.
We could just as well use y as the independent variable and put x = 2y, dx = 2dy,
and integrate from 0 to 1. (You should verify that the answer is the same.)
Along path 2 in Figure 8.2 (a parabola), y = 1
4x2, dy = 1
2x dx. Then we get
W2 =

 2
0

x · 1
4x2 dx −1
16x4 · 1
2x dx

=

 2
0
1
4x3 −1
32x5

dx
= x4
16 −x6
192

2
0
= 2
3.

Section 8
Line Integrals
301
Along path 3 (the broken line), we have to use a diﬀerent method. We integrate
ﬁrst from (0, 0) to (0, 1) and then from (0, 1) to (2, 1) and add the results. Along
(0, 0) to (0, 1), x = 0 and dx = 0 so we must use y as the variable. Then we have

 1
y=0
(0 · y · 0 −y2dy) = −y3
3

1
0
= −1
3.
Along (0, 1) to (2, 1), y = 1, dy = 0, so we use x as the variable. We have

 2
x=0
(x · 1 · dx −1 · 0) = x2
2

2
0
= 2.
Then the total W3 = −1
3 + 2 = 5
3.
Path 4 illustrates still another technique. Instead of using either x or y as the
integration variable, we can use a parameter t.
For x = 2t3, y = t2, we have
dx = 6t2 dt, dy = 2t dt. At the origin, t = 0, and at (2, 1), t = 1. Substituting these
values into (8.2), we get
W4 =

 1
0
(2t3 · t2 · 6t2 dt −t4 · 2t dt) =

 1
0
(12t7 −2t5) dt = 12
8 −2
6 = 7
6.
Example 2.
Find the value of
I =

 x dy −y dx
x2 + y2
along each of the two paths indicated in Figure 8.3 from (−1, 0) to (1, 0). [Notice
that we could have written I =

F · dr with F = (−iy + xj)/(x2 + y2); however,
there are also many other kinds of problems in which line integrals may arise.]
Figure 8.3
Along the circle it is simplest to use polar coordinates; then r = 1 at all points
of the circle and θ is the only variable. We then have
x = cos θ,
dx = −sin θ dθ,
y = sin θ,
dy = cos θ dθ,
x2 + y2 = 1,
x dy −y dx
x2 + y2
= cos2 θ dθ −sin θ(−sin θ) dθ
1
= dθ.
At (−1, 0), θ = π; at (1, 0), θ = 0. Then we get
I1 =

 0
π
dθ = −π.

302
Vector Analysis
Chapter 6
Along path 2, we integrate from (−1, 0) to (0, 1) and from (0, 1) to (1, 0) and
add the results. The ﬁrst straight line has the equation y = x + 1; then dy = dx,
and the integral is

 0
−1
x dx −(x + 1) dx
x2 + (x + 1)2
=

 0
−1
−dx
2x2 + 2x + 1 =

 0
−1
−2 dx
(2x + 1)2 + 1
= −arc tan(2x + 1)

0
−1
= −arc tan1 + arc tan(−1)
= −π
4 +

−π
4

= −π
2 .
Along the second straight line y = 1 −x, dy = −dx, and the integral is
−

 1
0
x dx + (1 −x) dx
x2 + (1 −x)2
=

 1
0
−2 dx
(2x −1)2 + 1 = −arc tan(2x −1)

1
0
= −π
2 .
Adding the results for the integrals along the two parts of path 2, we get I2 = −π.
Conservative Fields
Notice that in Example 1 the answers were diﬀerent for
diﬀerent paths, but in Example 2 they are the same. (See Section 11, however.)
We can give a physical meaning to these facts if we interpret the integrals in all
cases as the work done by a force on an object which moves along the path of
integration. Suppose you want to get a heavy box across a sidewalk and up into a
truck. Compare the work done in dragging the box across the sidewalk and then
lifting it, with the work done in lifting it and then swinging it across in the air.
In the ﬁrst case work is done against friction in addition to the work required to
lift the box; in the second case the only work done is that required to lift the box.
Thus we see that the work done in moving an object from one point to another may
depend on the path the object follows; in fact, it usually will when there is friction.
Our example 1 was such a case. A force ﬁeld for which W =  F · dr depends upon
the path as well as the endpoints is called nonconservative; physically this means
that energy has been dissipated, say by friction. There are however, conservative
ﬁelds for which

F · dr is the same between two given points regardless of what
path we calculate it along. For example, the work done in raising a mass m to the
top of a mountain of height h is W = mgh whether we lift the mass straight up a
cliﬀor carry it up a slope, as long as no friction is involved. Thus the gravitational
ﬁeld is conservative.
It is useful to be able to recognize conservative and nonconservative ﬁelds before
we do the integration. We shall see later (Section 11) that ordinarily curlF = 0 [see
(7.3) for the deﬁnition of curl] is a necessary and suﬃcient condition for  F · dr to
be independent of the path, that is, curl F = 0 for conservative ﬁelds and curl F ̸= 0
for nonconservative ﬁelds. (See Section 11 for a more careful discussion of this.)
It is not hard to see why this is usually so. Suppose that for a given F there is a

Section 8
Line Integrals
303
function W(x, y, z) such that
F = ∇W = i∂W
∂x + j∂W
∂y + k∂W
∂z ,
Fx = ∂W
∂x ,
Fy = ∂W
∂y ,
Fz = ∂W
∂z .
(8.3)
Then assuming that ∂2W/∂x∂y = ∂2W/∂y∂x, etc. (see Chapter 4, end of Section 1),
we get from (8.3)
(8.4)
∂Fx
∂y = ∂2W
∂y∂x = ∂Fy
∂x ,
and similarly
∂Fy
∂z = ∂Fz
∂y ,
∂Fx
∂z = ∂Fz
∂x .
Using the deﬁnition (7.3) of curl F, we see that equations (8.4) say that the three
components of curl F are equal to zero. Thus if F = ∇W, then curl F = 0. Con-
versely (as we shall show later), if curl F = 0, then we can ﬁnd a function W(x, y, z)
for which F = ∇W. Now if F = ∇W, we can write
F · dr = ∇W · dr = ∂W
∂x dx + ∂W
∂y dy + ∂W
∂z dz = dW,

 B
A
F · dr =

 B
A
dW = W(B) −W(A),
(8.5)
where W(B) and W(A) mean the values of the function W at the endpoints A and
B of the path of integration. Since the value of the integral depends only on the
endpoints A and B, it is independent of the path along which we integrate from A
to B, that is, F is conservative.
Potentials
In mechanics, if F = ∇W (that is, if F is conservative), then W is the
work done by F. For example, if a mass m falls a distance z under gravity, the work
done on it is mgz. If, however, we lift the mass a distance z against gravity, the
work done by the force F of gravity is W = −mgz since the direction of motion is
opposite to F. The increase in potential energy of m in this case is φ = +mgz, that
is, W = −φ, or F = −∇φ. The function φ is called the potential energy or the scalar
potential of the force F. (Of course, φ can be changed by adding any constant; this
corresponds to a choice of the zero level of the potential energy and has no eﬀect
on F.) More generally for any vector V, if curl V = 0, there is a function φ, called
the scalar potential of V, such that V = −∇φ. (This is the customary deﬁnition
of scalar potential in mechanics and electricity; in hydrodynamics many authors
deﬁne the velocity potential so that V = +∇φ.)
Now suppose that we are given F or dW = F · dr, and we ﬁnd by calculation
that curl F = 0. We then know that there is a function W and we want to know
how to ﬁnd it (up to an arbitrary additive constant of integration). To do this we
can calculate the line integral in (8.5) from some reference point A to the variable
point B along any convenient path; since the integral is independent of the path
when curl F = 0, this process gives the value of W at the point B.
(There is,
of course, an additive constant in W whose value depends on our choice of the
reference point A.)

304
Vector Analysis
Chapter 6
Example 3.
Show that
(8.6)
F = (2xy −z3)i + x2j −(3xz2 + 1)k
is conservative, and ﬁnd a scalar potential φ such that F = −∇φ.
We ﬁnd
(8.7)
∇× F =

i
j
k
∂
∂x
∂
∂y
∂
∂z
2xy −z3
x2
−3xz2 −1

= 0,
so F is conservative. Then
(8.8)
W =

 B
A
F · dr =

 B
A
(2xy −z3) dx + x2 dy −(3xz2 + 1) dz
is independent of the path. Let us choose the origin as our reference point and
integrate (8.8) from the origin to the point (x, y, z). As the path of integration, we
choose the broken line from (0, 0, 0) to (x, 0, 0) to (x, y, 0) to (x, y, z). From (0, 0, 0)
to (x, 0, 0), we have y = z = 0, dy = dz = 0, so the integral is zero along this part
of the path. From (x, 0, 0) to (x, y, 0), we have x = const., z = 0, dx = dz = 0, so
the integral is

 y
0
x2 dy = x2

 y
0
dy = x2y.
From (x, y, 0) to (x, y, z) we have x = const., y = const., dx = dy = 0, so the
integral is
−

 z
0
(3xz2 + 1)dz = −xz3 −z.
Adding the three results, we get
(8.9)
W = x2y −xz3 −z,
or
(8.10)
φ = −W = −x2y + xz3 + z.
Example 4.
Find the scalar potential for the electric ﬁeld due to a point charge q at the
origin.
Recall that the electric ﬁeld at a point r = ix + jy + kz means the force on a
unit charge at r due to q and is (in Gaussian units)
(8.11)
E = q
r2 er = q
r2
r
r = q
r3 r.
(This is Coulomb’s law in electricity.) If we take the zero level of the potential
energy at inﬁnity, then the scalar potential φ means the negative of the work done

Section 8
Line Integrals
305
by the ﬁeld on the unit charge as the charge moves from inﬁnity to the point r.
This is
(8.12)
φ = −

∞to r
E · dr = q

r to ∞
r · dr
r3
.
It is simplest to evaluate the line integral using the spherical coordinate variable r
along a radial line. This is justiﬁed by showing that curl E = 0, that is, that E is
conservative (Problem 19). Since the diﬀerential of (r · r) can be written as either
d(r · r) = 2r · dr or as d(r · r) = d(r2) = 2r dr, we have r · dr = r dr and (8.12) gives
(8.13)
φ = q

 ∞
r
r dr
r3
= q

 ∞
r
dr
r2 = −q
r

∞
r = q
r .
Figure 8.4
It is interesting to obtain r · dr = r dr geometrically; in fact, for any vector A,
let us see that A · dA = A dA. The vector dA means
a change in the vector A; a vector can change in both
magnitude and direction (Figure 8.4).
The scalar A
means |A|; the scalar dA means d|A|. Thus dA is the
increase in length of A and is not the same as |dA|. In
fact, from Figure 8.4, we see that
(8.14)
A · dA = |A| |dA| cos α = A dA
since dA = |dA| cos α. For the vector r, we have
r = ix + jy + kz,
dr = i dx + j dy + k dz,
|dr| =

dx2 + dy2 + dz2 = ds
(see Chapter 5),
r = |r| =

x2 + y2 + z2,
dr = 1
2(x2 + y2 + z2)−1/2(2x dx + 2y dy + 2z dz)
= 1
r (r · dr),
(8.15)
as above.
Exact Diﬀerentials
The diﬀerential dW in (8.5) of a function W(x, y, z) is called
an exact diﬀerential. We could then say that curl F = 0 is a necessary and suﬃcient
condition for F · dr to be an exact diﬀerential (but see Section 11). To make this
clear, let us consider some examples in which F·dr is, or is not, an exact diﬀerential.
Example 5.
Consider the function W in (8.9).
Then
(8.16)
dW = (2xy −z3) dx + x2 dy −(3xz2 + 1)dz.
Here dW is an exact diﬀerential by deﬁnition since we got it by diﬀerentiating a
function W. We can easily verify that if we write dW = F·dr, then equations (8.4)

306
Vector Analysis
Chapter 6
are true:
∂
∂x(x2) = 2x = ∂
∂y(2xy −z3),
∂
∂x(−3xz2 −1) = −3z2 = ∂
∂z (2xy −z3),
∂
∂y(−3xz2 −1) = 0 = ∂
∂z (x2).
(8.17)
You should observe carefully how to get (8.17) from (8.16): the equations (8.17) say
that, in (8.16), the partial derivative with respect to x of the coeﬃcient of dy equals
the partial derivative with respect to y of the coeﬃcient of dx, and similarly for the
other pairs of variables. The equations (8.17) are called the reciprocity relations in
thermodynamics; in mechanics they are the components of curl F = 0 [see (8.7)].
In both cases they are true assuming that the mixed second partial derivatives are
the same in either order, for example ∂2W/∂x∂y = ∂2W/∂y∂x (see Chapter 4, end
of Section 1).
We obtained dW in (8.16) by taking the diﬀerential of (8.9); now suppose we
start with a given dW = F · dr.
Example 6.
Let us consider
(8.18)
dW = F · dr = (2xy −z3) dx + x2 dy + (3xz2 + 1) dz.
This is almost the same as (8.16); just the sign of the dz term is changed. Then
two of the equations corresponding to (8.17) do not hold, so curlF ̸= 0, and dW is
not an exact diﬀerential. We ask whether there is a function W of which (8.18) is
the diﬀerential; the answer is “No” because if there were, the mixed second partial
derivatives of W would be equal, and so curl F would be zero. Equations like (8.18)
often occur in applications. When dW is not exact, then F is a nonconservative
force, and

F · dr, which is the work done by F, depends not only on the points A
and B but also upon the path along which the object moves. As we have said, this
happens when there are friction forces.
PROBLEMS, SECTION 8
1.
Evaluate the line integral
R
(x2 −y2) dx −2xy dy along each of the following paths
from (0, 0) to (1, 2).
(a)
y = 2x2.
(b)
x = t2, y = 2t.
(c)
y = 0 from x = 0 to x = 2; then along the straight line joining (2, 0) to (1, 2).
2.
Evaluate the line integral
H
(x + 2y) dx −2x dy along each of the following closed
paths, taken counterclockwise:
(a)
the circle x2 + y2 = 1;
(b)
the square with corners at (1, 1), (−1, 1), (−1, −1), (1, −1);
(c)
the square with corners (0, 1), (−1, 0), (0, −1), (1, 0).

Section 8
Line Integrals
307
3.
Evaluate the line integral
R
xy dx + x dy from (0, 0) to
(1, 2) along the paths shown in the sketch.
4.
Evaluate the line integral
R
C y2 dx + 2x dy + dz, where C connects (0, 0, 0) with
(1, 1, 1),
(a)
along straight lines from (0, 0, 0) to (1, 0, 0) to (1, 0, 1) to (1, 1, 1);
(b)
on the circle x2 + y2 −2y = 0 to (1, 1, 0) and then on a vertical line to (1, 1, 1).
5.
Find the work done by the force F = x2yi−xy2j
along the paths shown from (1, 1) to (4, 2).
6.
Find the work done by the force F = (2xy −3)i + x2j
in moving an object from (1, 0) to (0, 1) along each of
the three paths shown:
(a)
straight line,
(b)
circular arc,
(c)
along lines parallel to the axes.
7.
For the force ﬁeld F = (y + z)i −(x + z)j + (x + y)k, ﬁnd the work done in moving
a particle around each of the following closed curves:
(a)
the circle x2 + y2 = 1 in the (x, y) plane, taken counterclockwise;
(b)
the circle x2 + z2 = 1 in the (z, x) plane, taken counterclockwise;
(c)
the curve starting from the origin and going successively along the x axis to
(1, 0, 0), parallel to the z axis to (1, 0, 1), parallel to the (y, z) plane to (1, 1, 1),
and back to the origin along x = y = z;
(d)
from the origin to (0, 0, 2π) on the curve x = 1 −cos t, y = sin t, z = t, and
back to the origin along the z axis.
Verify that each of the following force ﬁelds is conservative. Then ﬁnd, for each, a scalar
potential φ such that F = −∇φ.
8.
F = i −zj −yk.
9.
F = (3x2yz −3y)i + (x3z −3x)j + (x3y + 2z)k.
10.
F = −kr, r = ix + jy + kz,
k = const.
11.
F = y sin 2x i + sin2x j.
12.
F = yi + xj + k.
13.
F = z2 sinh y j + 2z cosh y k.
14.
F =
y
p
1 −x2y2 i +
x
p
1 −x2y2 j.
15.
F = 2x cos2 y i −(x2 + 1) sin 2y j.

308
Vector Analysis
Chapter 6
16.
Given F1 = 2xi −2yzj −y2k
and F2 = yi −xj,
(a)
Are these forces conservative? Find the potential cor-
responding to any conservative force.
(b)
For any nonconservative force, ﬁnd the work done if it
acts on an object moving from (−1, −1) to (1, 1) along
each of the paths shown.
17.
Which, if either, of the two force ﬁelds
F1 = −yi + xj + zk,
F2 = yi + xj + zk
is conservative? Calculate for each ﬁeld the work done in moving a particle around
the circle x = cos t, y = sin t in the (x, y) plane.
18.
For the force ﬁeld F = −yi + xj + zk, calculate the work done in moving a particle
from (1, 0, 0) to (−1, 0, π)
(a)
along the helix x = cos t, y = sin t, z = t;
(b)
along the straight line joining the points.
Do you expect your answers to be the same? Why or why not?
19.
Show that the electric ﬁeld E of a point charge [equation (8.11)] is conservative.
Write φ in (8.13) in rectangular coordinates, and ﬁnd E = −∇φ using both rect-
angular coordinates (6.3) and cylindrical coordinates. Verify that your results are
equivalent to (8.11).
20.
For motion near the surface of the earth, we usually assume that the gravitational
force on a mass m is
F = −mgk,
but for motion involving an appreciable variation in distance r from the center of
the earth, we must use
F = −C
r2 er = −C
r2
r
|r| = −C
r3 r,
where C is a constant. Show that both these F’s are conservative, and ﬁnd the
potential for each.
21.
Consider a uniform distribution of total mass m′ over a spherical shell of radius r′.
The potential energy φ of a mass m in the gravitational ﬁeld of the spherical shell is
φ =
8
>
>
<
>
>
:
const.
if m is inside the spherical shell,
−Cm′
r
if m is outside the spherical shell, where r is the distance
from the center of the sphere to m, and C is a constant.
Assuming that the earth is a spherical ball of radius R and constant density, ﬁnd
the potential and the force on a mass m outside and inside the earth. Evaluate the
constants in terms of the acceleration of gravity g, to get
F = −mgR2
r2
er,
and
φ = −mgR2
r
,
m outside the earth;
F = −mgr
R er,
and
φ = mg
2R (r2 −3R2),
m inside the earth.
Hint: To ﬁnd the constants, recall that at the surface of the earth the magnitude of
the force on m is mg.

Section 9
Green’s Theorem in the Plane
309
9. GREEN’S THEOREM IN THE PLANE
The fundamental theorem of calculus says that the integral of the derivative of a
function is the function, or more precisely:
(9.1)

 b
a
d
dtf(t) dt = f(b) −f(a).
We are going to consider some useful generalizations of this theorem to two and
three dimensions. The divergence theorem and Stokes’ theorem (Sections 10 and
11) are very important in electrodynamics and other applications; in this section we
will ﬁnd two-dimensional forms of these theorems. First we develop an underlying
useful theorem relating an area integral to the line integral around its boundary
(see applications in examples and problems and also Chapter 14, Section 3).
A
x
a
b
yu
y
yl
2
1
C
A
x
d
c
y
xl
xr
4
3
C
Figure 9.1
Recall that we know how to evaluate line integrals (Section 8), and that we
learned in Chapter 5 to evaluate double integrals over areas in the (x, y) plane. We
are going to consider areas (such as those in Figure 9.1 or in Chapter 5, Figure 2.7)
for which we can evaluate the double integral over the area either with respect to
x ﬁrst or with respect to y ﬁrst. Look at Figure 9.1. We want to ﬁnd a relation
between a double integral over the area A and a line integral around the curve C, for
simple closed curves C. (A simple curve does not cross itself; for example, it is not
a ﬁgure 8.) Now in Figure 9.1, the upper part of C between points 1 and 2 is given
by an equation y = yu(x) and the lower part by an equation y = yl(x). (Think
of solving the equation of a circle for yu(x) =
√
1 −x2 and yl(x) = −
√
1 −x2.)
Similarly in Figure 9.1, we can ﬁnd xl(y) and xr(y) for the left and right parts of
C between points 3 and 4.
Let P(x, y) and Q(x, y) be continuous functions with continuous ﬁrst derivatives.
We are going to show that the double integral of ∂P(x, y)/∂y over the area A is equal
to the line integral of P around C. We write the double integral using Figure 9.1
to integrate ﬁrst with respect to y, and do the y integration by equation (9.1) with
t = y to get:


A
∂P(x, y)
∂y
dy dx =

 b
a
dx

 yu
yl
∂P(x, y)
∂y
dy =

 b
a
[P(x, yu) −P(x, yl)] dx
(9.2)
= −

 b
a
P(x, yl) dx −

 a
b
P(x, yu) dx.

310
Vector Analysis
Chapter 6
Now we have our answer—we just have to recognize it!
Think how you would
evaluate the line integral of P(x, y)dx along the lower part of C in Figure 9.1 from
point 1 to point 2. You would substitute y = yl(x) into P(x, y) and integrate from
x = a to b (see Section 8).

 b
a
P(x, yl) dx = line integral of P dx
(9.3)
along lower part of C from point 1 to point 2.
This is one of the terms in (9.2). Similarly, to ﬁnd the line integral of P(x, y) dx
along the upper part of C from point 2 to point 1, we substitute y = yu(x) and
integrate from b to a.

 a
b
P(x, yu) dx = line integral of P dx
(9.4)
along upper part of C from point 2 to point 1.
Combining (9.3) and (9.4) gives us the line integral all the way around C in the
counterclockwise direction, that is, so that A is always on our left as we go around
C. (The symbol  means an integral around a closed curve back to the starting
point.) Then, from (9.2), we have
(9.5)

C
P dx = −


A
∂P(x, y)
∂y
dx dy.
Repeating the calculation but integrating ﬁrst with respect to x, we ﬁnd


A
∂Q
∂x dx dy =

 d
c
dy

 xr
xl
∂Q
∂x dx =

 d
c
[Q(xr, y) −Q(xl, y)]dy
(9.6)
=

C
Q dy.
Adding (9.5) and (9.6) and using the notation ∂A to mean the boundary of A (that
is, C) we have
Green’s theorem in the plane:
(9.7)


A
∂Q
∂x −∂P
∂y

dx dy =

∂A
(P dx + Q dy)
The line integral is counterclockwise around the boundary of area A.
Using Green’s theorem we can evaluate either a line integral around a closed path
or a double integral over the area inclosed, whichever is easier to do. If the area is
not of the simple type we have assumed, it may be possible to cut it into pieces (see
Figure 9.2) so that our proof applies to each piece. Then the line integrals along
the dotted cuts in Figure 9.2 are in opposite directions for adjacent pieces, and so

Section 9
Green’s Theorem in the Plane
311
cancel. Thus the theorem is valid for this more general area and its inclosing curve.
In fact, w can even close up Figure 9.2 creating an area with a hole in the middle.
Figure 9.2
Green’s theorem still holds, but now the line integral consists of a counterclockwise
integral around the outside plus a clockwise integral around the hole as you can
see in Figure 9.2. We say that this area is not ”simply connected”—see further
discussion of this in Section 11.
Figure 9.3
Example 1.
In Example 1, Section 8, we found the line
integral (8.2) along several paths (Figure 8.2). Sup-
pose we want the line integral in Figure 8.2 around
the closed loop (Figure 9.3) from (0, 0) to (2, 1) and
back as shown. From Section 8, Example 1, this is
the work done along path 2 minus the work done
along path 3 (since we are now going in the opposite
direction); we ﬁnd W2 −W3 = 2
3 −5
3 = −1. Let us evaluate this using Green’s
theorem. From (8.2) and (9.7) we have
W =

∂A
xy dx −y2 dy =


A
 ∂
∂x(−y2) −∂
∂y (xy)

dx dy
=


A
−x dx dy = −

 1
y=0

 2√y
x=0
x dx dy = −1
as before.
Example 2.
In Section 8, we discussed conservative forces for which work done is inde-
pendent of the path. By Green’s theorem (9.7), the work done by a force F around
a closed path in the (x, y) plane is
W =

∂A
(Fx dx + Fy dy) =


A
∂Fy
∂x −∂Fx
∂y

dx dy.
If (∂Fy/∂x) −(∂Fx/∂y) = 0 (note that this is the z component of curl F = 0) then
W around any closed path is zero, which means that the work from one point to
another is independent of the path (also see Section 11).
The functions P(x, y) and Q(x, y) in (9.7) are arbitrary; we may choose them to
suit our purposes. Note that a two-dimensional vector function iVx(x, y)+jVy(x, y)
e

312
Vector Analysis
Chapter 6
contains two functions, Vx and Vy. In the next two examples, we are going to deﬁne
P and Q in terms of Vx and Vy in order to obtain two useful results.
Example 3.
We deﬁne:
(9.8)
Q = Vx,
P = −Vy,
where
V = iVx + jVy.
Then
(9.9)
∂Q
∂x −∂P
∂y = ∂Vx
∂x + ∂Vy
∂y = div V
by (7.2) with Vz = 0. Along the curve bounding an area A (Figure 9.4) the vector
Figure 9.4
(9.10)
dr = i dx + j dy
(tangent)
is a tangent vector, and the vector
(9.11)
n ds = i dy −j dx
(outward normal),
where n is a unit vector and ds =

dx2 + dy2,
is a normal vector (perpendicular to the tangent) pointing out of area A. Using
(9.11) and (9.8), we can write
P dx + Q dy = −Vy dx + Vx dy = (iVx + jVy) · (i dy −j x)
(9.12)
= V · n ds.
Then substitute (9.9) and (9.12) into (9.7) to get
(9.13)


A
div V dx dy =

∂A
V · n ds.
This is the divergence theorem in two dimensions.
It can be extended to three
dimensions (also see Section 10). Let τ represent a volume; then ∂τ (read boundary
of τ) means the closed surface area of τ. Let dτ mean a volume element and let dσ

Section 9
Green’s Theorem in the Plane
313
mean an element of surface area. At each point of the surface, let n be a unit vector
perpendicular to the surface and pointing outward. Then the divergence theorem
in three dimensions says (also see Section 10)
(9.14)



τ
div V dτ =


∂τ
V · n dσ.
Divergence theorem
Example 4.
To see another application of (9.7) to vector functions, we let
(9.15)
Q = Vy,
P = Vx,
where
V = iVx + jVy.
Then
(9.16)
∂Q
∂x −∂P
∂y = ∂Vy
∂x −∂Vx
∂y = (curl V) · k
by (7.3) with Vz = 0. Equations (9.10) and (9.15) give
(9.17)
P dx + Q dy = (iVx + jVy) · (i dx + j dy) = V · dr.
Substituting (9.16) and (9.17) into (9.7), we get
(9.18)


A
(curl V) · k dx dy =

∂A
V · dr.
Figure 9.5
This is Stokes’ theorem in two dimensions. It can be extended
to three dimensions (Section 11). Let σ be an open surface (for
example, a hemisphere); then ∂σ means the curve bounding
the surface (Figure 9.5). Let n be a unit vector normal to the
surface. Then Stokes’ theorem in three dimensions is (also see
Section 11)
(9.19)


σ
(curl V) · n dσ =

∂σ
V · dr.
Stokes’ theorem.
The direction of integration for the line integral is as shown in Figure 9.5 (see also
Section 11).
PROBLEMS, SECTION 9
1.
Write out the equations corresponding to (9.3) and (9.4) for
R
Q dy between points
3 and 4 in Figure 9.2, and add them to get (9.6).
In Problems 2 to 5 use Green’s theorem [formula (9.7)] to evaluate the given integrals.
2.
H
2x dy −3y dx around the square with vertices (0, 2), (2, 0), (−2, 0), and (0, −2).

314
Vector Analysis
Chapter 6
3.
H
C xy dx + x2 dy, where C is as sketched.
4.
R
C ex cos y dx−ex sin y dy, where C is the broken line from
A = (ln 2, 0) to D = (0, 1) and then from D to B =
(−ln 2, 0). Hint: Apply Green’s theorem to the integral
around the closed curve ADBA.
5.
R
C(yex−1) dx+ex dy, where C is the semicircle through (0, −10), (10, 0), and (0, 10).
(Compare Problem 4.)
6.
For a simple closed curve C in the plane show by Green’s theorem that the area
inclosed is
A = 1
2
I
C
(x dy −y dx).
7.
Use Problem 6 to show that the area inside the ellipse x = a cos θ, y = b sin θ,
0 ≤θ ≤2π, is A = πab.
8.
Use Problem 6 to ﬁnd the area inside the curve x2/3 + y2/3 = 4.
9.
Apply Green’s theorem with P = 0, Q =
1
2x2 to the triangle with vertices (0, 0),
(0, 3), (3, 0). You will then have
RR
x dx dy over the triangle expressed as a very
simple line integral.
Use this to locate the centroid of the triangle.
(Compare
Chapter 5, Section 3.)
Evaluate each of the following integrals in the easiest way you can.
10.
H
(2y dx −3x dy) around the square bounded by x = 3, x = 5, y = 1 and y = 3.
11.
R
C(x sin x −y) dx + (x −y2) dy, where C is the triangle in the (x, y) plane with
vertices (0, 0), (1, 1), and (2, 0).
12.
R
(y2 −x2) dx + (2xy + 3) dy along the x axis from (0, 0) to (
√
5, 0) and then along
a circular arc from (
√
5, 0) to (1, 2).
10. THE DIVERGENCE AND THE DIVERGENCE THEOREM
We have deﬁned (in Section 7) the divergence of a vector function V(x, y, z) as
(10.1)
div V = ∇· V = ∂Vx
∂x + ∂Vy
∂y + ∂Vz
∂z .
We now want to investigate the meaning and use of the divergence in physical
applications.
Consider a region in which water is ﬂowing. We can imagine drawing at every
point a vector v equal to the velocity of the water at that point. The vector function
v then represents a vector ﬁeld. The curves tangent to v are called stream lines.
We could in the same way discuss the ﬂow of a gas, of heat, of electricity, or of
particles (say from a radioactive source). We are going to show that if v represents
the velocity of ﬂow of any of these things, then div v is related to the amount of
the substance which ﬂows out of a given volume. This could be diﬀerent from zero
either because of a change in density (more air ﬂows out than in as a room is heated)

Section 10
The Divergence and the Divergence Theorem
315
or because there is a source or sink in the volume (alpha particles ﬂow out of but not
into a box containing an alpha-radioactive source). Exactly the same mathematics
applies to the electric and magnetic ﬁelds where v is replaced by E or B and the
quantity corresponding to outﬂow of a material substance is called ﬂux.
Figure 10.1
For our example of water ﬂow, let V = vρ, where ρ is the density of the water.
Then the amount of water crossing in time t an area A′ which is perpendicular to
the direction of ﬂow, is (see Figure 10.1) the amount of water in a cylinder of cross
section A′ and length vt. This amount of water is
(10.2)
(vt)(A′)(ρ).
The same amount of water crosses area A (see Figure 10.1) whose normal is inclined
at angle θ to v. Since A′ = A cos θ,
(10.3)
vtA′ρ = vtρA cos θ.
Then if water is ﬂowing in the direction v making an angle θ with the normal n to
a surface, the amount of water crossing unit area of the surface in unit time is
(10.4)
vρ cos θ = V cos θ = V · n
if n is a unit vector.
Now consider an element of volume dx dy dz in the region through which the
water is ﬂowing (Figure 10.2).
Water is ﬂowing either in or out of the volume
dx dy dz through each of the six surfaces of the volume element; we shall calculate
the net outward ﬂow. In Figure 10.2, the rate at which water ﬂows into dx dy dz
Figure 10.2
through surface 1 is [by (10.4)] V · i per unit area, or (V · i) dy dz through the area
dy dz of surface 1. Since V · i = Vx, we ﬁnd that the rate at which water ﬂows
across surface 1 is Vx dy dz. A similar expression gives the rate at which water ﬂows
out through surface 2, except that Vx must be the x component of V at surface 2
instead of at surface 1. We want the diﬀerence of the two Vx values at two points,
one on surface 1 and one on surface 2, directly opposite each other, that is, for the

316
Vector Analysis
Chapter 6
same y and z. These two values of Vx diﬀer by ∆Vx which can be approximated
(as in Chapter 4) by dVx. For constant y and z, dVx = (∂Vx/∂x) dx. Then the
net outﬂow through these two surfaces is the outﬂow through surface 2 minus the
inﬂow through surface 1, namely,
(10.5)
[(Vx at surface 2) −(Vx at surface 1)]dy dz =
∂Vx
∂x dx

dy dz.
We get similar expressions for the net outﬂow through the other two pairs of opposite
surfaces:
∂Vy
∂y dx dy dz
through top and bottom,
and
∂Vz
∂z dx dy dz
through the other two sides.
(10.6)
Then the total net rate of loss of water from dx dy dz is
(10.7)
∂Vx
∂x + ∂Vy
∂y + ∂Vz
∂z

dx dy dz = div V dx dy dz
or
∇· V dx dy dz.
If we divide (10.7) by dx dy dz, we have the rate of loss of water per unit volume.
This is the physical meaning of a divergence: It is the net rate of outﬂow per unit
volume evaluated at a point (let dx dy dz shrink to a point). This is outﬂow of actual
substance for liquids, gases, or particles; it is called ﬂux for electric and magnetic
ﬁelds. You should note that this is somewhat like a density. Density is mass per unit
volume, but it is evaluated at a point and may vary from point to point. Similarly,
the divergence is evaluated at each point and may vary from point to point.
As we have said, div V may be diﬀerent from zero either because of time variation
of the density or because of sources and sinks. Let
ψ = source density minus sink density
= net mass of ﬂuid being created (or added via something like a minute
sprinkler system) per unit time per unit volume;
ρ = density of the ﬂuid = mass per unit volume;
∂ρ/∂t = time rate of increase of mass per unit volume.
Then:
Rate of increase of mass in dx dy dz = rate of creation minus rate of outward ﬂow,
or in symbols
∂ρ
∂t dx dy dz = ψ dx dy dz −∇· V dx dy dz.
Canceling dx dy dz, we have
∂ρ
∂t = ψ −∇· V
or
(10.8)
∇· V = ψ −∂ρ
∂t .

Section 10
The Divergence and the Divergence Theorem
317
If there are no sources or sinks, then ψ = 0; the resulting equation is often called
the equation of continuity. (See Problem 15.)
(10.9)
∇· V + ∂ρ
∂t = 0.
Equation of continuity
If ∂ρ/∂t = 0, then
(10.10)
∇· V = ψ.
In the case of the electric ﬁeld, the “sources” and “sinks” are electric charges and
the equation corresponding to (10.10) is div D = ψ, where ψ is the charge density
and D is the electric displacement. For the magnetic ﬁeld B you would expect
the sources to be magnetic poles; however, there are no free magnetic poles, so
div B = 0 always.
Figure 10.3
We have shown that the mass of ﬂuid crossing a plane
area A per unit time is AV · n, where n is a unit vec-
tor normal to A, v and ρ are the velocity and density
of the ﬂuid, and V = vρ. Consider any closed surface,
and let dσ represent an area element on the surface (Fig-
ure 10.3). For example: for a plane, dσ = dx dy; for a
spherical surface,
dσ = r2 sin θ dθ dφ.
Let n be the unit vector normal to dσ and pointing out of the surface (n varies
in direction from point to point on the surface). Then the mass of ﬂuid ﬂowing out
through dσ is V · n dσ by (10.4) and the total outﬂow from the volume inclosed by
the surface is
(10.11)


V · n dσ,
where the double integral is evaluated over the closed surface.
We showed previously [see (10.7)] that for the volume element dτ = dx dy dz:
(10.12)
The outﬂow from dτ is
∇· V dτ.
For simplicity, we proved this for a rectangular coordinate volume element dx dy dz.
With extra eﬀort we could prove it more generally, say for volume elements with
slanted sides or for spherical coordinate volume elements. From now on we shall
assume that dτ includes more general volume element shapes.
It is worth noticing here another way [besides (7.2)] of deﬁning the divergence.
If we write (10.11) for the surface of a volume element dτ, we have two expressions
for the total outﬂow from dτ, and these must be equal. Thus
(10.13)
∇· V dτ =


surface
of dτ
V · n dσ.

318
Vector Analysis
Chapter 6
The value of ∇· V on the left is, of course, an average value of ∇· V in dτ, but if
we divide (10.13) by dτ and let dτ shrink to a point, we have a deﬁnition of ∇· V
at the point:
(10.14)
∇· V = lim
dτ→0
1
dτ


surface
of dτ
V · n dσ.
If we start with (10.14) as the deﬁnition of ∇· V, then the discussion leading to
(10.7) is a proof that ∇· V as deﬁned in (10.14) is equal to ∇· V as deﬁned in
(7.2).
The Divergence Theorem
See (10.17). The divergence theorem is also called
Gauss’s theorem, but be careful to distinguish this mathematical theorem from
Gauss’s law which is a law of physics; see (10.23).
Figure 10.4
Consider a large volume τ; imagine it cut up into volume
elements dτi (a cross section of this is shown in Figure 10.4).
The outﬂow from each dτi is ∇· V dτi; let us add together
the outﬂow from all the dτi to get
(10.15)

i
∇· V dτi.
We shall show that (10.15) is the outﬂow from the large volume τ. Consider the
ﬂow between the elements marked a and b in Figure 10.4 across their common face.
An outﬂow from a to b is an inﬂow (negative outﬂow) from b to a, so that in the
sum (10.15) such outﬂows across interior faces cancel. The total sum in (10.15)
then equals just the total outﬂow from the large volume. As the size of the volume
elements tends to zero, this sum approaches a triple integral over the volume,
(10.16)



∇· V dτ.
We have shown that both (10.11) and (10.16) are equal to the total outﬂow from
the large volume; hence they are equal to each other, and we have the divergence
theorem as stated in (9.14):
(10.17)



volume τ
∇· V dτ =


surface
inclosing τ
V · n dσ.
Divergence theorem
(n points out of the closed surface σ.)
Notice that the divergence theorem converts a volume integral into an integral over
a closed surface or vice versa; we can then evaluate whichever one is the easier
to do.
In (10.17) we have carefully written the volume integral with three integral signs
and the surface integral with two integral signs. However, it is rather common to
write only one integral sign for either case when the volume or area element is
indicated by a single diﬀerential (dτ, dV , etc., for volume; dσ, dA, dS, etc., for

Section 10
The Divergence and the Divergence Theorem
319
surface area). Thus we might write

dτ or

dτ or

dx dy dz, all meaning the
same thing. When the single integral sign is used to indicate a surface or volume
integral, you must see from the notation (τ for volume, σ for area), or the words
under the integral, what is really meant. To indicate a surface integral over a closed
surface or a line integral around a closed curve, the symbol

is often used. Thus
we might write either

dσ or

dσ for a surface integral over a closed surface. A
diﬀerent notation for the integrand V · n dσ is often used. Instead of using a unit
vector n and the scalar magnitude dσ, we may write the vector dσ meaning a vector
of magnitude dσ in the direction n; thus dσ means exactly the same thing as n dσ,
and we may replace V · n dσ by V · dσ in (10.17).
Example of the Divergence Theorem
Let V = ix +
jy + kz and evaluate

V · n dσ over the closed surface of the
cylinder shown in Figure 10.5.
Figure 10.5
By the divergence theorem this is equal to

∇· V dτ over
the volume of the cylinder. (Note that we are using single
integral signs, but the notation and words make it clear which
integral is a volume integral and which a surface integral.) We
ﬁnd from the deﬁnition of divergence
∇· V = ∂x
∂x + ∂y
∂y + ∂z
∂z = 3.
Then by (10.17)

surface of
cylinder
V · n dσ =

volume of
cylinder
∇· V dτ =

3 dτ = 3

dτ
= 3 times volume of cylinder = 3πa2h.
It is harder to evaluate  V·n dσ directly, but we might do it to show an example
of calculating a surface integral and to verify the divergence theorem in a special
case. We need the surface normal n. On the top surface (Figure 10.5) n = k, and
there V · n = V · k = z = h. Then

top surface of
cylinder
V · n dσ = h

dσ = h · πa2.
On the bottom surface, n = −k, V·n = −z = 0; hence the integral over the bottom
surface is zero. On the curved surface we might see by inspection that the vector
ix + jy is normal to the surface, so for the curved surface we have
n =
ix + jy

x2 + y2 = ix + jy
a
.
If the vector n is not obvious by inspection, we can easily ﬁnd it; recall (Section
6) that if the equation of a surface is φ(x, y, z) = const., then ∇φ is perpendicular
to the surface. In this problem, the equation of the cylinder is x2 + y2 = a2; then

320
Vector Analysis
Chapter 6
φ = x2 + y2, ∇φ = 2xi + 2yj, and we get the same unit vector n as above. Then
for the curved surface we ﬁnd
V · n = x2 + y2
a
= a2
a = a,

curved
surface
V · n dσ = a

dσ = a · (area of curved surface) = a · 2πah.
The value of  V·n dσ over the whole surface of the cylinder is then πa2h+2πa2h =
3πa2h as before.
Gauss’s Law
The divergence theorem is very important in electricity. In order to
see how it is used, we need a law in electricity known as Gauss’s law. Let us derive
this law from the more familiar Coulomb’s law (8.11). Coulomb’s law (written this
time in SI units) gives for the electric ﬁeld at r due to a point charge q at the origin
(10.18)
E =
q
4πϵ0r2 er.
Coulomb’s law
(ϵ0 is a constant called the permittivity of free space and
1
4πϵ0
= 9·109 in SI units.)
The electric displacement D is deﬁned (in free space) by D = ϵ0E; then
(10.19)
D =
q
4πr2 er.
Figure 10.6
Let σ be a closed surface surrounding the point charge q at the origin; let dσ be
an element of area of the surface at the point r, and let n be a unit normal to dσ
(Figures 10.3 and 10.6). Also (Figure 10.6) let dA be the projection of dσ onto a
sphere of radius r and center at O and let dΩbe the solid angle subtended by dσ
(and dA) at O. Then by deﬁnition of solid angle
(10.20)
dΩ= 1
r2 dA.
From Figure 10.6 and equations (10.19) and (10.20), we get
(10.21)
D · n dσ = D cos θ dσ = D dA =
q
4πr2 · r2 dΩ= 1
4π q dΩ

Section 10
The Divergence and the Divergence Theorem
321
We want to ﬁnd the surface integral of D·n dσ over the closed surface σ; by (10.21)
this is
(10.22)

closed
surface σ
D · n dσ = q
4π

total
solid angle
dΩ= q
4π · 4π = q
(q inside σ).
This is a simple case of Gauss’s law when we have only one point charge q; for most
purposes we shall want Gauss’s law in the forms (10.23) or (10.24) below. Before
we derive these, we should note carefully that in (10.22) the charge q is inside the
closed surface σ. If we repeat the derivation of (10.22) for a point charge q outside
the surface (Problem 13), we ﬁnd that in this case

closed σ
D · n dσ = 0.
Next suppose there are several charges qi inside the closed surface. For each qi
and the Di corresponding to it, we could write an equation like (10.22). But the
total electric displacement vector D at a point due to all the qi is the vector sum
of the vectors Di. Thus we have

closed
surface σ
D · n dσ =

i

closed
surface σ
Di · n dσ =

qi.
Therefore for any charge distribution inside a closed surface
(10.23)

closed
surface
D · n dσ = total charge inside the closed surface.
Gauss’s law
If, instead of isolated charges, we have a charge distribution with charge density ρ
(which may vary from point to point), then the total charge is  ρ dτ, so
(10.24)

closed
surface σ
D · n dσ =

volume
bounded by σ
ρ dτ.
Gauss’s law
Since (by Problem 13) charges outside the closed surface σ do not contribute to the
integral, (10.23) and (10.24) are correct if D is the total electric displacement due to
all charges inside and outside the surface. The total charge on the right-hand side
of these equations is, however, just the charge inside the surface σ. Either (10.23)
or (10.24) is called Gauss’s law.
We now want to see the use of the divergence theorem in connection with Gauss’s
law. By the divergence theorem, the surface integral on the left-hand side of (10.23)
or (10.24) is equal to

volume
bounded by σ
∇· D dτ.

322
Vector Analysis
Chapter 6
Then (10.24) can be written as

∇· D dτ =

ρ dτ.
Since this is true for every volume, we must have ∇·D = ρ; this is one of the Maxwell
equations in electricity. What we have done is to start by assuming Coulomb’s law;
we have derived Gauss’s law from it, and then by use of the divergence theorem, we
have derived the Maxwell equation ∇·D = ρ. From a more sophisticated viewpoint,
we might take the Maxwell equation as one of our basic assumptions in electricity.
We could then use the divergence theorem to obtain Gauss’s law:

closed
surface σ
D · n dσ =

volume τ
inside σ
∇· D dτ =

volume τ
ρ dτ
(10.25)
= total charge inclosed by σ.
From Gauss’s law we could then derive Coulomb’s law (Problem 14); more generally
we can often use Gauss’s law to obtain the electric ﬁeld produced by a given charge
distribution as in the following example.
Example.
Find E just above a very large conducting plate carrying a surface charge of
C coulombs per square meter on each surface.
The electric ﬁeld inside a conductor is zero when we are considering an electro-
statics problem (otherwise current would ﬂow). From the symmetry of the problem
(all horizontal directions are equivalent), we can say that E (and D) must be vertical
as shown in Figure 10.7. We now ﬁnd

D · n dσ over the box whose cross section
is shown by the dotted lines. The integral over the bottom surface is zero since
D = 0 inside the conductor. The integral over the vertical sides is zero because D
is perpendicular to n there. On the top surface D · n = |D| and

D · n dσ = |D|·
(surface area). By (10.25) this is equal to the charge inclosed by the box, which
is C· (surface area). Thus we have |D| · (surface area) = C · (surface area) , or
|D| = C and |E| = C/ϵ0.
Figure 10.7
PROBLEMS, SECTION 10
1.
Evaluate both sides of (10.17) if V = r = ix + jy + kz, and τ is the volume
x2 + y2 + z2 ≤1, and so verify the divergence theorem in this case.
2.
Given V = x2i + y2j + z2k, integrate V · n dσ over the whole surface of the cube
of side 1 with four of its vertices at (0, 0, 0), (0, 0, 1), (0, 1, 0), (1, 0, 0). Evaluate the
same integral by means of the divergence theorem.

Section 10
The Divergence and the Divergence Theorem
323
Evaluate each of the integrals in Problems 3 to 8 as either a volume integral or a surface
integral, whichever is easier.
3.
RR
r · n dσ over the whole surface of the cylinder bounded by x2 + y2 = 1, z = 0,
and z = 3; r means ix + jy + kz.
4.
RR
V·n dσ if V = x cos2 y i+xz j+z sin2 y k over the surface of a sphere with center
at the origin and radius 3.
5.
RRR
(∇· F) dτ over the region x2 + y2 + z2 ≤25, where
F = (x2 + y2 + z2)(xi + yj + zk).
6.
RRR
∇· V dτ over the unit cube in the ﬁrst octant, where
V = (x3 −x2)yi + (y3 −2y2 + y)xj + (z2 −1)k.
7.
RR
r · n dσ over the entire surface of the cone with base x2 + y2 ≤16, z = 0, and
vertex at (0, 0, 3), where r = ix + jy + kz.
8.
RRR
∇· V dτ over the volume x2 + y2 ≤4, 0 ≤z ≤5, V = (
p
x2 + y2 )(ix + jy).
9.
If F = xi+yj, calculate
RR
F·n dσ over the part of the surface z = 4−x2 −y2 that is
above the (x, y) plane, by applying the divergence theorem to the volume bounded
by the surface and the piece that it cuts out of the (x, y) plane. Hint: What is F · n
on the (x, y) plane?
10.
Evaluate
RR
V · n dσ over the curved surface of the hemisphere x2 + y2 + z2 = 9,
z ≥0, if V = yi + xzj + (2z −1)k. Careful: See Problem 9.
11.
Given that B = curl A, use the divergence theorem to show that
H
B·n dσ over any
closed surface is zero.
12.
A cylindrical capacitor consists of two long concentric metal cylinders.
If there
is a charge of k coulombs per meter on the inside cylinder of radius R1, and −k
coulombs per meter on the outside cylinder of radius R2, ﬁnd the electric ﬁeld E
between the cylinders. Hint: Use Gauss’s law and the method indicated in Figure
10.7. What is E inside the inner cylinder? Outside the outer cylinder? (Again use
Gauss’s law.) Find, either by inspection or by direct integration, the potential φ
such that E = −∇φ for each of the three regions above. In each case E is not
aﬀected by adding an arbitrary constant to φ. Adjust the additive constant to make
φ a continuous function for all space.
13.
Draw a ﬁgure similar to Figure 10.6 but with q outside the surface. A vector (like
r in the ﬁgure) from q to the surface now intersects it twice, and for each solid
angle dΩthere are two dσ’s, one where r enters and one where it leaves the surface.
Show that D · n dσ is given by (10.21) for the dσ where r leaves the surface and the
negative of (10.21) for the dσ where r enters the surface. Hence show that the total
H
D · n dσ over the closed surface is zero.
14.
Obtain Coulomb’s law from Gauss’s law by considering a spherical surface σ with
center at q.
15.
Suppose the density ρ of a ﬂuid varies from point to point as well as with time,
that is, ρ = ρ(x, y, z, t). If we follow the ﬂuid along a streamline, then x, y, z are
functions of t such that the ﬂuid velocity is
v = idx
dt + jdy
dt + kdz
dt .

324
Vector Analysis
Chapter 6
Show that then dρ/dt = ∂ρ/∂t + v · ∇ρ. Combine this equation with (10.9) to get
ρ∇· v + dρ
dt = 0.
(Physically, dρ/dt is the rate of change of density with time as we follow the ﬂuid
along a streamline; ∂ρ/∂t is the corresponding rate at a ﬁxed point.) For a steady
state (that is, time-independent), ∂ρ/∂t = 0, but dρ/dt is not necessarily zero.
For an incompressible ﬂuid, dρ/dt = 0; show that then ∇· v = 0.
(Note that
incompressible does not necessarily mean constant density since dρ/dt = 0 does not
imply either time or space independence of ρ; consider, for example, a ﬂow of water
mixed with blobs of oil.)
16.
The following equations are variously known as Green’s ﬁrst and second identities
or formulas or theorems. Derive them, as indicated, from the divergence theorem.
(1)
Z
volume τ
inside σ
(φ∇2ψ + ∇φ · ∇ψ) dτ =
I
closed
surface σ
(φ∇ψ) · n dσ.
To prove this, let V = φ∇ψ in the divergence theorem.
(2)
Z
volume τ
inside σ
(φ∇2ψ −ψ∇2φ) dτ =
I
closed
surface σ
(φ∇ψ −ψ∇φ) · n dσ.
To prove this, copy Theorem 1 above as is and also with φ and ψ interchanged;
then subtract the two equations.
11. THE CURL AND STOKES’ THEOREM
We have already deﬁned curl V = ∇× V [see (7.3)] and have considered one
application of the curl, namely, to determine whether or not a line integral between
two points is independent of the path of integration (Section 8). Here is another
application of the curl. Suppose a rigid body is rotating with constant angular
velocity ω; this means that |ω| is the magnitude of the angular velocity and ω is
a vector along the axis of rotation (see Figure 2.6). Then we showed in Section
2 that the velocity v of a particle in the rigid body is v = ω × r, where r is
a radius vector from a point on the rotation axis to the particle. Let us calculate
∇×v = ∇×(ω×r); we can evaluate this by the method described in Section 7. We
use the formula for the triple vector product A × (B × C) = (A · C)B −(A · B)C,
being careful to remember that ∇is not an ordinary vector—it has both vector
and diﬀerential-operator properties, and so must be written before variables that it
diﬀerentiates. Then
(11.1)
∇× (ω × r) = (∇· r)ω −(ω · ∇)r.
Since ω is constant, the ﬁrst term of (11.1) means
(11.2)
ω(∇· r) = ω
∂x
∂x + ∂y
∂y + ∂z
∂z

= 3ω.
In the second term of (11.1) we intentionally wrote ω · ∇instead of ∇· ω since ω
is constant, and ∇operates only on r; this term means

ωx
∂
∂x + ωy
∂
∂y + ωz
∂
∂z

(ix + jy + kz) = iωx + jωy + kωz = ω

Section 11
The Curl and Stokes’ Theorem
325
since ∂y/∂x = ∂z/∂x = 0, etc. Then
(11.3)
∇× v = ∇× (ω × r) = 2ω
or
ω = 1
2(∇× v).
This result gives a clue as to the name curl v (or rotation v or rot v as it is
sometimes called). For this simple case curl v gave the angular velocity of rotation.
In a more complicated case such as ﬂow of ﬂuid, the value of curlv at a point is a
measure of the angular velocity of the ﬂuid in the neighborhood of the point. When
∇× v = 0 everywhere in some region, the velocity ﬁeld v is called irrotational in
that region. Notice that this is the same mathematical condition as for a force F
to be conservative.
Figure 11.1
Consider a vector ﬁeld V (for example, V = vρ for ﬂow of water, or V = force
F). We deﬁne the circulation as the line integral

V · dr around a closed plane
curve. If V is a force F, then this integral is equal to the work done by the force.
For ﬂow of water, we can get a physical picture of the meaning of the circulation in
the following way. Think of placing a tiny paddle-wheel probe (Figure 11.1c) in any
of the ﬂow patterns pictured in Figure 11.1. If the velocity of the ﬂuid is greater on
one side of the wheel than on the other, for example, as in (c), then the wheel will
turn. Suppose we calculate the circulation

V · dr around the axis of the paddle
wheel along a closed curve in a plane perpendicular to the axis (plane of the paper
in Figure 11.1). If V = vρ is larger on one side of the wheel than the other, then
the circulation is diﬀerent from zero, but if [as in (b)] V is the same on both sides,
then the circulation is zero. We shall show that the component of curl V along the

326
Vector Analysis
Chapter 6
axis of the paddle wheel equals
(11.4)
lim
dσ→0
1
dσ

V · dr
where dσ is the area inclosed by the curve along which we calculate the circulation.
The paddle wheel then acts as a “curl meter” to measure curl V; if it does not
rotate, curl V = 0; if it does, then curl V ̸= 0. In (a), curl V ̸= 0 at the center of
the vortex. In (b), curl V = 0. In (c), curl V ̸= 0 in spite of the fact that the ﬂow
lines are parallel. In (d), it is possible to have curl V = 0 even though the stream
lines go around a corner; in fact, for the ﬂow of water around a corner, curl V = 0.
What you should realize is that the value of curl V at a point depends upon the
circulation in the neighborhood of the point and not on
the overall ﬂow pattern.
Figure 11.2
We want to show the relation between the circulation

V · dr and curl V for a given vector ﬁeld V. Given a
point P and a direction n, let us ﬁnd the component of
curl V in the direction n at P. Draw a plane through P
perpendicular to n and choose axes so that it is the (x, y)
plane with n parallel to k. Find the circulation around
an element of area dσ centered on P. (See Figures 9.5
and 11.2.) By (9.18) with area A replaced by the element
of area dσ, and with n = k
(11.5)

around dσ
V · dr =


dσ
(curl V) · k dx dy =


dσ
(curl V) · n dσ
Note that, since we proved (9.7) and so (9.18) for non-rectangular areas A (see
Section 9), dσ here may be more general than dx dy, say with curved or slanted
sides.
We assume that the components of V have continuous ﬁrst derivatives; then
curl V is continuous. Thus the value of (curl V) · n over dσ is nearly the same
as (curl V) · n at P, so the double integral in (11.5) is approximately the value of
(curl V) · n at P multiplied by dσ. If we divide (11.5) by dσ and take the limit as
dσ →0, we have an exact equation
(11.6)
(∇× V) · n = lim
dσ→0
1
dσ

around dσ
V · dr.
This equation can be used as a deﬁnition of curl V; then the discussion above shows
that [see equation (9.16)] the components of curl V are those given in our previous
deﬁnition (7.3).
In evaluating the line integral we must go around the area element dσ as in
Figure 11.2 keeping the area to our left. Another way of saying this is that we
go around dσ in the direction indicated by n and the right-hand rule; that is, if
the thumb of your right hand points in the direction n, your ﬁngers curve in the
direction you must go around the boundary of dσ in evaluating the line integral.
(See Figure 11.2 with n = k.)

Section 11
The Curl and Stokes’ Theorem
327
Stokes’ Theorem
This theorem relates an integral over an open surface to the
line integral around the curve bounding the surface (Figure 11.3).
A butterﬂy
net is a good example of what we are talking about; the net is the surface and
the supporting rim is the curve bounding the surface. The surfaces we consider
here (and which arise in applications) will be surfaces which could be obtained
by deforming a hemisphere (or the butterﬂy net of Figure 11.3).
In particular,
the surfaces we consider must be two-sided. You can easily construct a one-sided
surface by taking a long strip of paper, giving it a half twist, and joining the ends
(Figure 11.4). A belt of this shape is sometimes used for driving machinery. This
surface is called a Moebius strip, and you can verify that it has only one side by
tracing your ﬁnger around it or imagining trying to paint one side. Stokes’ theorem
does not apply to such surfaces because we cannot deﬁne the sense of the normal
vector n to such a surface. We require the bounding curve to be simple (that is, it
must not cross itself) and closed.
Figure 11.3
Figure 11.4
Consider the kind of surface we have described and imagine it divided into
area elements dσ by a network of curves as in Figure 11.5. Draw a unit vector n
perpendicular to each area element; n, of course, varies from element to element,
but all n’s must be on the same side of the two-sided surface. Each area element
Figure 11.5
is approximately an element of the tangent plane to the surface at a point in dσ.
Then, as in (11.5), we have
(11.7)

around dσ
V · dr =


dσ
(∇× V) · n dσ
for each element. Recall from Section 9 and the comment just after equation (11.5),
that dσ includes area elements such as those along the edges in Figure 11.5. Then
if we sum the equations in (11.7) for all the area elements of the whole surface area,

328
Vector Analysis
Chapter 6
we get
(11.8)

all dσ

V · dr =


surface σ
(∇× V) · n dσ.
From Figure 11.5 we see that all the interior line integrals cancel because along a
border between two dσ’s the two integrals are in opposite directions. Then the left
side of (11.8) becomes simply the line integral around the outside curve bounding
the surface. Thus we have Stokes’ theorem as stated in (9.19):
(11.9)

curve
bounding σ
V · dr =


surface σ
(∇× V) · n dσ.
Stokes’ theorem
You should have it clearly in mind that this is for an open surface bounded by a
simple closed curve. Recall the example of a butterﬂy net. Notice that Stokes’ the-
orem says that the line integral

V·dr is equal to the surface integral of (∇×V)·n
over any surface of which the curve is a boundary; in other words, you don’t change
the value of the integral by deforming the butterﬂy net! An easy way to determine
the direction of integration for the line integral is to imagine collapsing the surface
and its bounding curve into a plane; then the “surface” is just the plane area inside
the curve and n is normal to the plane. The direction of integration is then given
by the right-hand rule as discussed just after equation (11.6).
Example 1.
Given V = 4yi + xj + 2zk, ﬁnd

(∇× V) · n dσ over the hemisphere x2 +
y2 + z2 = a2, z ≥0.
Using (7.3), we ﬁnd that ∇× V = −3k. There are several ways we could do
the problem: (a) integrate the expression as it stands; (b) use Stokes’ theorem and
evaluate

V · dr around the circle x2 + y2 = a2 in the (x, y) plane; (c) use Stokes’
theorem to say that the integral is the same over any surface bounded by this circle,
for example, the plane area inside the circle! Since this plane area is in the (x, y)
plane, we have
n = k,
(∇× V) · n = −3k · k = −3,
so the integral is
−3

dσ = −3 · πa2 = −3πa2.
This is the easiest way to do the problem; however, for this simple case it is not too
hard by the other methods. We shall leave (b) for you to do and do (a). Since the
surface is a sphere with center at the origin, r is normal to it (but for any surface
we could get the normal from the gradient). Then on the surface
n = r
|r| = r
a = ix + jy + kz
a
,
(∇× V) · n = −3k · r
a = −3z
a.

Section 11
The Curl and Stokes’ Theorem
329
We want to evaluate

−3(z/a) dσ over the hemisphere. In spherical coordinates
(see Chapter 5, Section 4) we have
z = r cos θ,
dσ = r2 sin θ dθ dφ.
For our surface r = a. Then the integral is

 2π
φ=0

 π/2
θ=0
−3a cosθ
a
a2 sin θ dθ dφ = −3a2

 2π
0
dφ

 π/2
0
sin θ cos θ dθ
= −3a2 · 2π · 1
2 = −3πa2
(as before).
Amp`ere’s Law
Stokes’ theorem is of interest in electromagnetic theory. (Com-
pare the use of the divergence theorem in connection with Gauss’s law in Section
10.) Amp`ere’s circuital law (in SI units) says that

C
H · dr = I,
where H = B/µ0, B is the magnetic ﬁeld, µ0 is a constant (called the permeability
of free space), C is a closed curve, and I is the current “linking” C, that is crossing
any surface area bounded by C. The surface area and the curve C are related just
as in Stokes’ theorem (butterﬂy net and its rim). If we think of a bundle of wires
linking a closed curve C (Figure 11.6) and then spreading out, we can see that the
same current crosses any surface whose bounding curve is C.
Just as Gauss’s law (10.23) is useful in computing electric ﬁelds, so Amp`ere’s
law is useful in computing magnetic ﬁelds. Consider, for example, a long straight
wire carrying a current I (Figure 11.7). At a distance r from the wire, H is tangent
Figure 11.6
Figure 11.7
to a circle of radius r in a plane perpendicular to the wire. By symmetry, |H| same
at all points of the circle. We can then ﬁnd |H| by Amp`ere’s law. Taking C to be
the circle of radius r, we have

C
H · dr =

 2π
0
|H|r dθ = |H|r · 2π = I
or
|H| =
I
2πr .

330
Vector Analysis
Chapter 6
If, in Figure 11.6, J is the current density (current crossing unit area perpendic-
ular to J), then J · n dσ is the current across a surface element dσ [compare (10.4)]
and

σ J · n dσ, over any surface σ bounded by C, is the total current I linking C.
Then by Amp`ere’s law

C
H · dr =


σ
J · n dσ.
By Stokes’ theorem

C
H · dr =


σ
(∇× H) · n dσ,
so we have


σ
(∇× H) · n dσ =


σ
J · n dσ.
Since this is true for any σ, we have ∇× H = J, which is one of the Maxwell equa-
tions. Alternatively, we could start with the Maxwell equation and apply Stokes’
theorem to get Amp`ere’s law.
Figure 11.8
Conservative Fields
We next want
to state carefully, and use Stokes’ the-
orem to prove, under what conditions
a given ﬁeld F is conservative (see Sec-
tion 8). First, recall that in physical
problems we are often interested only
in a particular region of space, and our
formulas (say for F) may very well be
correct only in that region. For exam-
ple, the gravitational pull of the earth
on an object is proportional to 1/r2 for
r ≥earths’ radius R, but this is not a
correct formula for r < R (see Prob-
lem 8.21). The electric ﬁeld in the re-
gion between the plates of a cylindrical
capacitor is proportional to 1/r (problem 10.12), but only in this region is this
formula correct. We must, then, consider the kind of region in which a given ﬁeld
F is deﬁned. Consider the shaded regions in Figure 11.8. We say that a region is
simply connected if any simple† closed curve in the region can be shrunk to a point
without encountering any points not in the region. You can see in Figure 11.8c that
the dotted curve surrounds the “hole” and so cannot be shrunk to a point in the
region; this region is then not simply connected. The “hole” is sometimes only a
single point, but this is enough to make the region not simply connected. In three
dimensions the region between cylindrical capacitor plates (inﬁnitely long) is not
simply connected since a loop of string around the inner cylinder (see cross section,
Figure 11.8c) cannot be drawn up to a knot. Similarly, the interior of an inner
tube is not simply connected. The region between two concentric spheres is simply
connected, however. You should see this by realizing that you could pull up into a
†A simple curve does not cross itself; for example, a ﬁgure eight is not a simple curve.

Section 11
The Curl and Stokes’ Theorem
331
knot, a loop of string placed anywhere in this region. We shall now state and prove
our theorem.
(11.10)
If the components of F and their ﬁrst partial derivatives are continuous in a
simply connected region, then any one of the following ﬁve conditions implies all
the others.
(a) curl F = 0 at every point of the region.
(b)

F · dr = 0 around every simple closed curve in the region.
(c) F is conservative, that is
 B
A F · dr is independent of the path of integration
from A to B. (The path must, of course, lie entirely in the region.)
(d) F · dr is an exact diﬀerential of a single valued function.
(e) F = gradW, W single-valued.
We shall show that each of these conditions implies the one following it. We
can use Stokes’ theorem to prove (b) assuming (a). First select any simple closed
curve and let it be the bounding curve for the surface in Stokes’ theorem. Since
the region is simply connected we can think of shrinking the curve to a point in
the region; as it shrinks it traces out a surface which we use as the Stokes’ theorem
surface. Assuming (a), we have curl F = 0 at every point of the region and so also
at every point of the surface. Thus the surface integral in Stokes’ theorem is zero
and therefore the line integral around the closed curve equals zero. This gives (b).
Figure 11.9
To show that (b) implies (c), consider any two paths I and II
from A to B (Figure 11.9). From (b) we have

 B
A
path I
F · dr +

 A
B
path II
F · dr = 0.
Since an integral from A to B is the negative of an integral from B to A, we have

 B
A
path I
F · dr −

 B
A
path II
F · dr = 0.
which is (c).
To show that (c) implies (d), select some reference point O in the region and
calculate

F · dr from the reference point to every other point of the region. For
each point P we ﬁnd a single value of the integral no matter what path of integration
we choose from O to P. Let this value be the value of the function W at the point
P. We then have a single-valued function W such that

0 to P
F · dr = W(P).

332
Vector Analysis
Chapter 6
Then (since F is continuous), dW = F · dr, that is, F · dr is the diﬀerential of a
single-valued function W. Since dW = ∇W · dr = F · dr for arbitrary dr, we have
F = ∇W which is (e).
Finally, (e) implies (a) as we proved in Section 8. (The continuity of the com-
ponents of F and their partial derivatives makes the second-order mixed partial
derivatives of W equal.) Thus we have shown that any one of the ﬁve conditions
(a) to (e) implies the others under the conditions of the theorem. It is worth observ-
ing carefully the requirement that F and its partial derivatives must be continuous
in a simply connected region. A simple example makes this clear. Look at Example
2 in Section 8; you can easily compute curl F and ﬁnd that it is zero everywhere
except at the origin (where it is undeﬁned). You might then be tempted to assume
that

F · dr = 0 around any closed path. But we found that F · dr = dθ, and the
integral of dθ along a circle with center at the origin is 2π. What is wrong? The
trouble is that F does not have continuous partial derivatives at the origin, and
any simply connected region containing the circle of integration must contain the
origin. Then curl F is not zero at every point inside the integration curve. Notice
also that F · dr = dθ is an exact diﬀerential, but not of a single-valued function; θ
increases by 2π every time we go around the origin.
A vector ﬁeld V is called irrotational (or conservative or lamellar) if curl V = 0;
in this case V = grad W, where W (or its negative) is called the scalar potential.
If div V = 0, the vector ﬁeld is called solenoidal; in this case V = curl A, where A
is a vector function called the vector potential. It is easy to prove (Problem 7.17d)
that if V = ∇× A, then div V = 0. It is also possible to construct an A (actually
an inﬁnite number of A’s) so that V = curl A if we know that ∇· V = 0.
Example 2.
Given V = i(x2 −yz) −j2yz + k(z2 −2zx), ﬁnd A such that V = ∇× A.
We ﬁnd
div V = ∂
∂x(x2 −yz) + ∂
∂y(−2yz) + ∂
∂z (z2 −2zx)
= 2x −2z + 2z −2x = 0.
Thus V is solenoidal and we proceed to ﬁnd A. We are looking for an A such that
(11.11)
V = curl A =

i
j
k
∂
∂x
∂
∂y
∂
∂z
Ax
Ay
Az

= i(x2 −yz) −j2yz + k(z2 −2zx).
There are many A’s satisfying this equation; we shall show ﬁrst how to ﬁnd one
of them and then a general formula for all. It is possible to ﬁnd an A with one
zero component; let us take Ax = 0. Then the y and z components of curl A each
involve just one component of A. From (11.11), the y and z components of curl A
are
(11.12)
−2yz = −∂Az
∂x ,
z2 −2zx = ∂Ay
∂x .

Section 11
The Curl and Stokes’ Theorem
333
If we integrate (11.12) partially with respect to x (that is, with y and z constant),
we ﬁnd Ay and Az except for possible functions of y and z which could be added
without changing (11.12):
Ay = z2x −zx2 + f1(y, z),
Az = 2xyz + f2(y, z).
(11.13)
Substituting (11.13) into the x component of (11.11), we get
(11.14)
x2 −yz = ∂Az
∂y −∂Ay
∂z = 2xz + ∂f2
∂y −2zx + x2 −∂f1
∂z .
We now select f1 and f2 to satisfy (11.14). There is much leeway here and this
can easily be done by inspection. We could take f2 = 0, f1 = 1
2yz2, or f1 = 0,
f2 = −1
2y2z, and so forth. Using the second choice, we have
(11.15)
A = j(z2x −zx2) + k(2xyz −1
2y2z).
You may wonder why this process works and what div V = 0 has to do with it.
We can answer both these questions by following the above process with a general
V rather than a special example. Given that div V = 0, we want an A such that
V = curl A. We try to ﬁnd one with Ax = 0. Then the y and z components of
V = curl A are
(11.16)
Vy = −∂Az
∂x ,
Vz = ∂Ay
∂x .
Then we have
(11.17)
Ay =

Vz dx + f(y, z),
Az = −

Vy dx + g(y, z).
The x component of V = curl A is
(11.18)
Vx = ∂Az
∂y −∂Ay
∂z = −

 ∂Vy
∂y + ∂Vz
∂z

dx + h(y, z).
Since div V = 0, we can put
(11.19)
−
∂Vy
∂y + ∂Vz
∂z

= ∂Vx
∂x
into (11.18), getting
Vx =

 ∂Vx
∂x dx + h(y, z).
This is correct with proper choice of h(y, z).
When we know one A, for which a given V is equal to curl A, all others are of
the form
(11.20)
A + ∇u,
where u is any scalar function.
For (see Problem 7.17b), ∇× ∇u = 0, so the
addition of ∇u to A does not aﬀect V. Also we can show that all possible A’s are

334
Vector Analysis
Chapter 6
of the form (11.20). For if V = curl A1 and V = curl A2, then curl(A1 −A2) = 0,
so A1 −A2 is the gradient of some scalar function.
A careful statement and proof that div V = 0 is a necessary and suﬃcient con-
dition for V = curl A requires that V have continuous partial derivatives at every
point of a region which is simply connected in the sense that every closed surface
(rather than closed curve) can be shrunk to a point in the region (for example, the
region between two concentric spheres is not simply connected in this sense).
PROBLEMS, SECTION 11
1.
Do case (b) of Example 1 above.
2.
Given the vector A = (x2 −y2)i + 2xyj.
(a)
Find ∇× A.
(b)
Evaluate
RR
(∇× A) · dσ over a rectangle in the (x, y) plane bounded by the
lines x = 0, x = a, y = 0, y = b.
(c)
Evaluate
H
A· dr around the boundary of the rectangle and thus verify Stokes’
theorem for this case.
Use either Stokes’ theorem or the divergence theorem to evaluate each of the following
integrals in the easiest possible way.
3.
RR
surface σ curl(x2i+z2j−y2k)·n dσ, where σ is the part of the surface z = 4−x2−y2
above the (x, y) plane.
4.
RR
curl(yi + 2j ) · n dσ, where σ is the surface in the ﬁrst
octant made up of part of the plane 2x + 3y + 4z = 12, and
triangles in the (x, z) and (y, z) planes, as indicated in the
ﬁgure.
5.
RR
r · n dσ over the surface in Problem 4, where r = ix +
jy + kz. Hint: See Problem 10.9.
6.
RR
V · n dσ over the closed surface of the tin can bounded by x2 + y2 = 9, z = 0,
z = 5, if
V = 2xyi −y2j + (z + xy)k.
7.
RR
(curl V)·n dσ over any surface whose bounding curve is in the (x, y) plane, where
V = (x −x2z)i + (yz3 −y2)j + (x2y −xz)k.
8.
RR
curl(x2yi −xzk) · n dσ over the closed surface of the ellipsoid
x2
4 + y2
9 + z2
16 = 1.
Warning: Stokes’ theorem applies only to an open surface. Hints: Could you cut
the given surface into two halves? Also see (d) in the table of vector identities (page
339).
9.
RR
V · n dσ over the entire surface of the volume in the ﬁrst octant bounded by
x2 + y2 + z2 = 16 and the coordinate planes, where
V = (x + x2 −y2)i + (2xyz −2xy)j −xz2k.
10.
RR
(curl V)·n dσ over the part of the surface z = 9−x2 −9y2 above the (x, y) plane,
if V = 2xyi + (x2 −2x)j −x2z2k.

Section 11
The Curl and Stokes’ Theorem
335
11.
RR
V · n dσ over the entire surface of a cube in the ﬁrst octant with edges of length
2 along the coordinate axes, where
V = (x2 −y2)i + 3yj −2xzk.
12.
H
V · dr around the circle (x −2)2 + (y −3)2 = 9, z = 0, where
V = (x2 + yz2)i + (2x −y3)j.
13.
RR
(2xi −2yj + 5k) · n dσ over the surface of a sphere of radius 2 and center at the
origin.
14.
H
(yi −xj + zk) · dr around the circumference of the circle of radius 2, center at the
origin, in the (x, y) plane.
15.
H
c y dx + z dy + x dz, where C is the curve of intersection of the surfaces whose
equations are x + y = 2 and x2 + y2 + z2 = 2(x + y).
16.
What is wrong with the following “proof” that there are no magnetic ﬁelds? By
electromagnetic theory, ∇· B = 0, and B = ∇× A. (The error is not in these
equations.) Using them, we ﬁnd
ZZZ
∇· B dτ = 0 =
ZZ
B · n dσ
(by the divergence theorem)
=
ZZ
(∇× A) · n dσ =
Z
A · dr
(by Stokes’ theorem).
Since
R
A· dr = 0, A is conservative, or A = ∇ψ. Then B = ∇×A = ∇×∇ψ = 0,
so B = 0.
17.
Derive the following vector integral theorems.
(a)
Z
volume τ
∇φ dτ =
I
surface
inclosing τ
φ n dσ.
Hint: In the divergence theorem (10.17), substitute V = φC, where C is an
arbitrary constant vector, to obtain C ·
R
∇φ dτ = C ·
H
φn dσ. Since C is
arbitrary, let C = i to show that the x components of the two integrals are
equal; similarly, let C = j and C = k to show that the y components are equal
and the z components are equal.
(b)
Z
volume τ
∇× V dτ =
I
surface
inclosing τ
n × V dσ.
Hint: Replace V in the divergence theorem by V× C, where C is an arbitrary
constant vector. Follow the last part of the hint in (a).
(c)
Z
curve
bounding σ
φ dr =
I
surface σ
(n × ∇φ)dσ.
(d)
I
curve
bounding σ
dr × V =
Z
surface σ
(n × ∇) × V dσ.
Hints for (c) and (d): Use the substitutions suggested in (a) and (b) but in
Stokes’ theorem (11.9) instead of the divergence theorem.
(e)
Z
volume τ
φ∇· V dτ =
I
surface
inclosing τ
φV · n dσ −
Z
volume τ
V · ∇φ dτ.
Hint: Integrate (7.6) over volume τ and use the divergence theorem.

336
Vector Analysis
Chapter 6
(f)
Z
volume τ
V · (∇× U) dτ =
Z
volume τ
U · (∇× V) dτ +
I
surface
inclosing τ
(U × V) · n dσ.
Hint: Integrate (h) in the Table of Vector Identities (page 339) and use the
divergence theorem.
(g)
Z
surface of σ
φ(∇× V) · n dσ =
Z
surface of σ
(∇× ∇φ) · n dσ +
I
curve
bounding σ
φ V · dr.
Hint: Integrate (g) in the Table of Vector Identities (page 339) and use Stokes’
Theorem.
Find vector ﬁelds A such that V = curl A for each given V.
18.
V = (x2 −yz + y)i + (x −2yz)j + (z2 −2zx + x + y)k
19.
V = i(x2 −2xz) + j(y2 −2xy) + k(z2 −2yz + xy)
20.
V = i(zezy + x sin zx) + jx cos xz −kz sin zx
21.
V = −k
22.
V = (y + z)i + (x −z)j + (x2 + y2)k
12. MISCELLANEOUS PROBLEMS
1.
If A and B are unit vectors with an angle θ between them, and C is a unit vector
perpendicular to both A and B, evaluate [(A × B) × (B × C)] × (C × A).
2.
If A and B are the diagonals of a parallelogram, ﬁnd a vector formula for the area
of the parallelogram.
3.
The force on a charge q moving with velocity v = dr/dt in a magnetic ﬁeld B is
F = q(v ×B). We can write B as B = ∇× A where A (called the vector potential)
is a vector function of x, y, z, t. If the position vector r = ix + jy + kz of the charge
q is a function of time t, show that
dA
dt = ∂A
∂t + v · ∇A.
Thus show that
F = qv × (∇× A) = q
»
∇(v · A) −dA
dt + ∂A
∂t
–
.
4.
Show that ∇· (U × r) = r · (∇× U) where U is a vector function of x, y, z, and
r = xi + yj + zk.
5.
Use Green’s theorem (Section 9) to do Problem 8.2.
6.
Find the torque about the point (1, −2, 1) due to the force F = 2i −j + 3k acting
at the point (1, 1, −3).
7.
Let F = 2i −3j + k act at the point (5, 1, 3).
(a)
Find the torque of F about the point (4, 1, 0).
(b)
Find the torque of F about the line r = 4i + j + (2i + j −2k)t.
8.
The force F = i −2j −2k acts at the point (0, 1, 2). Find the torque of F about the
line r = (2i −j)t.
9.
Let F = i −5j + 2k act at the point (2, 1, 0). Find the torque of F about the line
r = (3j + 4k) −2it.

Section 12
Miscellaneous Problems
337
10.
Given u = xy + sin z, ﬁnd
(a)
the gradient of u at (1, 2, π/2);
(b)
how fast u is increasing, in the direction 4i + 3j, at (1, 2, π/2);
(c)
the equation of the tangent plane to the surface u = 3 at (1, 2, π/2).
11.
Given φ = z2 −3xy, ﬁnd
(a)
grad φ;
(b)
the directional derivative of φ at the point (1, 2, 3) in the direction i + j + k;
(c)
the equations of the tangent plane and of the normal line to φ = 3 at the point
(1, 2, 3).
12.
Given u = xy + yz + z sin x, ﬁnd
(a)
∇u at (0, 1, 2);
(b)
the directional derivative of u at (0, 1, 2) in the direction 2i + 2j −k;
(c)
the equations of the tangent plane and of the normal line to the level surface
u = 2 at (0, 1, 2);
(d)
a unit vector in the direction of most rapid increase of u at (0, 1, 2).
13.
Given φ = x2 −yz and the point P(3, 4, 1), ﬁnd
(a)
∇φ at P;
(b)
a unit vector normal to the surface φ = 5 at P;
(c)
a vector in the direction of most rapid increase of φ at P;
(d)
the magnitude of the vector in (c);
(e)
the derivative of φ at P in a direction parallel to the line r = i −j + 2k + (6i −
j −4k)t.
14.
If the temperature is T = x2 −xy + z2, ﬁnd
(a)
the direction of heat ﬂow at (2, 1, −1);
(b)
the rate of change of temperature in the direction j −k at (2, 1, −1).
15.
Show that
F = y2z sinh(2xz)i + 2y cosh2(xz)j + y2x sinh(2xz)k
is conservative, and ﬁnd a scalar potential φ such that F = −∇φ.
16.
Given F1 = 2xzi + yj + x2k and F2 = yi −xj:
(a)
Which F, if either, is conservative?
(b)
If one of the given F’s is conservative, ﬁnd a function W so that F = ∇W.
(c)
If one of the F’s is nonconservative, use it to evaluate
R
F·dr along the straight
line from (0, 1) to (1, 0).
(d)
Do part (c) by applying Green’s theorem to the triangle with vertices (0, 0),
(0, 1), (1, 0).
17.
Find the value of
R
F · dr along the circle x2 + y2 = 2 from (1, 1) to (1, −1) if
F = (2x −3y)i −(3x −2y)j.
18.
Is F = yi + xzj + zk conservative? Evaluate
R
F · dr from (0, 0, 0) to (1, 1, 1) along
the paths

338
Vector Analysis
Chapter 6
(a)
broken line (0, 0, 0) to (1, 0, 0) to (1, 1, 0) to (1, 1, 1),
(b)
straight line connecting the points.
19.
Given F1 = −2yi + (z −2x)j + (y + z)k, F2 = yi + 2xj:
(a)
Is F1 conservative? Is F2 conservative?
(b)
Find the work done by F2 on a particle that moves around the ellipse x = cos θ,
y = 2 sin θ from θ = 0 to θ = 2π.
(c)
For any conservative force in this problem ﬁnd a potential function V such
that F = −∇V .
(d)
Find the work done by F1 on a particle that moves along the straight line from
(0, 1, 0) to (0, 2, 5).
(e)
Use Green’s theorem and the result of Problem 9.7 to do Part (b) above.
In Problems 20 to 31, evaluate each integral in the simplest way possible.
20.
RR
P · n dσ over the upper half of the sphere r = 1 if P = curl(jx −kz).
21.
RR
(∇× V) · n dσ over the surface consisting of the four slanting faces of a pyramid
whose base is the square in the (x, y) plane with corners at (0, 0), (0, 2), (2, 0), (2, 2)
and whose top vertex is at (1, 1, 2), where
V = (x2z −2)i + (x + y −z)j −xyzk.
22.
RR
V · n dσ over the entire surface of the sphere (x −2)2 + (y + 3)2 + z2 = 9, if
V = (3x −yz)i + (z2 −y2)j + (2yz + x2)k.
23.
RR
F · n dσ where F = (y2 −x2)i + (2xy −y)j + 3zk and σ is the entire surface of
the tin can bounded by the cylinder x2 + y2 = 16, z = 3, z = −3.
24.
RR
r · n dσ over the entire surface of the hemisphere x2 + y2 + z2 = 9, z ≥0, where
r = xi + yj + zk.
25.
RR
V·n dσ over the curved part of the hemisphere in Problem 24, if V = curl(yi−xj).
26.
RR
(curl V) · n dσ over the entire surface of the cube in the ﬁrst octant with three
faces in the three coordinate planes and the other three faces intersecting at (2, 2, 2),
where
V = (2 −y)i + xzj + xyzk.
27.
Problem 26, but integrate over the open surface obtained by leaving out the face of
the cube in the (x, y) plane.
28.
H
F · dr around the circle x2 + y2 + 2x = 0, where F = yi −xj.
29.
H
V·dr around the boundary of the square with vertices (1, 0), (0, 1), (−1, 0), (0, −1),
if V = x2i + 5xj.
30.
R
C(x2 −y)dx+(x+y3)dy, where C is the parallelogram with vertices at (0, 0), (2, 0),
(1, 1), (3, 1).
31.
R
(y2 −x2) dx + (2xy + 3)dy along the x axis from (0, 0) to (
√
5, 0) and then along
a circular arc from (
√
5, 0) to (1, 2). Hint: Use Green’s theorem.

Vector Identities
339
Table of Vector Identities Involving ∇
Note carefully that φ and ψ are scalar functions; U and V are vector functions.
Formulas are given in rectangular coordinates; for other coordinate systems, see
Chapter 10, Section 9.
(a) ∇· ∇φ = div gradφ = ∇2φ = Laplacian φ = ∂2φ
∂x2 + ∂2φ
∂y2 + ∂2φ
∂z2
(b) ∇× ∇φ = curl grad φ = 0
(c) ∇(∇· V) = grad div V
= i
∂2Vx
∂x2 + ∂2Vy
∂x∂y + ∂2Vz
∂x∂z

+ j
 ∂2Vx
∂x∂y + ∂2Vy
∂y2 + ∂2Vz
∂y∂z

+ k
 ∂2Vx
∂x∂z + ∂2Vy
∂y∂z + ∂2Vz
∂z2

(d) ∇· (∇× V) = div curl V = 0
(e) ∇× (∇× V) = curl curl V = ∇(∇· V) −∇2V = grad div V −Laplacian V
(f) ∇· (φV) = φ(∇· V) + V · (∇φ)
(g) ∇× (φV) = φ(∇× V) −V × (∇φ)
(h) ∇· (U × V) = V · (∇× U) −U · (∇× V)
(i) ∇× (U × V) = (V · ∇)U −(U · ∇)V −V(∇· U) + U(∇· V)
(j) ∇(U · V) = U × (∇× V) + (U · ∇)V + V × (∇× U) + (V · ∇)U
(k) ∇· (∇φ × ∇ψ) = 0

C H A P T E R 7
Fourier Series and Transforms
1. INTRODUCTION
Problems involving vibrations or oscillations occur frequently in physics and engi-
neering. You can think of examples you have already met: a vibrating tuning fork,
a pendulum, a weight attached to a spring, water waves, sound waves, alternating
electric currents, etc. In addition, there are many more examples which you will
meet as you continue to study physics. Some of them—for example, heat conduc-
tion, electric and magnetic ﬁelds, light—do not appear in elementary work to have
anything oscillatory about them, but will turn out in your more advanced work to
involve the sines and cosines which are used in describing simple harmonic motion
and wave motion.
In Chapter 1 we discussed the use of power series to approximate complicated
functions. In many problems, series called Fourier series, whose terms are sines and
cosines, are more useful than power series. In this chapter we shall see how to ﬁnd
and use Fourier series. Then, in Chapter 13 (Sections 2 to 4), we shall consider
several of the physics problems which Fourier was trying to solve when he invented
Fourier series.
Since sines and cosines are periodic functions, Fourier series can represent only
periodic functions. We will see in Section 12 how to represent a non-periodic func-
tion by a Fourier integral (Fourier transform).
2. SIMPLE HARMONIC MOTION AND WAVE MOTION;
PERIODIC FUNCTIONS
Figure 2.1
We shall need much of the notation and terminology
used in discussing simple harmonic motion and wave
motion. Let’s discuss these two topics brieﬂy.
Let particle P (Figure 2.1) move at constant
speed around a circle of radius A.
At the same
time, let particle Q move up and down along the
straight line segment RS in such a way that the
y coordinates of P and Q are always equal. If ω is
the angular velocity of P in radians per second, and
340

Section 2
Simple Harmonic Motion and Wave Motion; Periodic Functions
341
(Figure 2.1) θ = 0 when t = 0, then at a later time t
(2.1)
θ = ωt.
The y coordinate of Q (which is equal to the y coordinate of P) is
(2.2)
y = A sin θ = A sin ωt.
The back and forth motion of Q is called simple harmonic motion. By deﬁnition, an
object is executing simple harmonic motion if its displacement from equilibrium can
be written as A sin ωt [or A cos ωt or A sin(ωt+φ), but these two functions diﬀer from
A sin ωt only in choice of origin; such functions are called sinusoidal functions]. You
can think of many physical examples of this sort of simple vibration: a pendulum,
a tuning fork, a weight bobbing up and down at the end of a spring.
The x and y coordinates of particle P in Figure 2.1 are
(2.3)
x = A cos ωt,
y = A sin ωt.
If we think of P as the point z = x+iy in the complex plane, we could replace (2.3)
by a single equation to describe the motion of P:
z = x + iy = A(cos ωt + i sin ωt)
(2.4)
= Aeiωt.
It is often worth while to use this complex notation even to describe the motion
of Q; we then understand that the actual position of Q is equal to the imaginary
part of z (or with diﬀerent starting conditions the real part of z). For example, the
velocity of Q is the imaginary part of
(2.5)
dz
dt = d
dt(Aeiωt) = Aiωeiωt = Aiω(cos ωt + i sin ωt).
[The imaginary part of (2.5) is Aω cos ωt, which is dy/dt from (2.2).]
Figure 2.2
It is useful to draw a graph of x and y in (2.2) and (2.3) as a function of t.
Figure 2.2 represents any of the functions sin ωt, cos ωt, sin(ωt + φ) if we choose
the origin correctly. The number A is called the amplitude of the vibration or the
amplitude of the function. Physically it is the maximum displacement of Q from
its equilibrium position. The period of the simple harmonic motion or the period of
the function is the time for one complete oscillation, that is, 2π/ω (See Figure 2.2).
We could write the velocity of Q from (2.5) as
(2.6)
dy
dt = Aω cos ωt = B cos ωt.

342
Fourier Series and Transforms
Chapter 7
Here B is the maximum value of the velocity and is called the velocity amplitude.
Note that the velocity has the same period as the displacement. If the mass of the
particle Q is m, its kinetic energy is:
(2.7)
Kinetic energy = 1
2m
dy
dt
2
= 1
2mB2 cos2 ωt.
We are considering an idealized harmonic oscillator which does not lose energy.
Then the total energy (kinetic plus potential) must be equal to the largest value of
the kinetic energy, that is, 1
2mB2. Thus we have:
(2.8)
Total energy = 1
2mB2.
Notice that the energy is proportional to the square of the (velocity) amplitude; we
shall be interested in this result later when we discuss sound.
Waves are another important example of an oscillatory phenomenon. The math-
ematical ideas of wave motion are useful in many ﬁelds; for example, we talk about
water waves, sound waves, and radio waves.
Example 1.
Consider water waves in which the shape of the water surface is (unrealis-
tically!) a sine curve. If we take a photograph (at the instant t = 0) of the water
surface, the equation of this picture could be written (relative to appropriate axes)
(2.9)
y = A sin 2πx
λ ,
where x represents horizontal distance and λ is the distance between wave crests.
Usually λ is called the wavelength, but mathematically it is the same as the period
of this function of x. Now suppose we take another photograph when the waves have
moved forward a distance vt (v is the velocity of the waves and t is the time between
photographs). Figure 2.3 shows the two photographs superimposed. Observe that
the value of y at the point x on the graph labeled t, is just the same as the value of y
at the point (x−vt) on the graph labeled t = 0. If (2.9) is the equation representing
the waves at t = 0, then
Figure 2.3
(2.10)
y = A sin 2π
λ (x −vt)
represents the waves at time t. We can interpret (2.10) in another way. Suppose
you stand at one point in the water [ﬁxed x in (2.10)] and observe the up and down
motion of the water, that is, y in (2.10) as a function of t (for ﬁxed x). This is a
simple harmonic motion of amplitude A and period λ/v. You are doing something

Section 2
Simple Harmonic Motion and Wave Motion; Periodic Functions
343
analogous to this when you stand still and listen to a sound (sound waves pass your
ear and you observe their frequency) or when you listen to the radio (radio waves
pass the receiver and it reacts to their frequency).
We see that y in (2.10) is a periodic function either of x (t ﬁxed) or of t (x ﬁxed);
both interpretations are useful. It makes no diﬀerence in the basic mathematics,
however, what letter we use for the independent variable. To simplify our notation
we shall ordinarily use x as the variable, but if the physical problem calls for it, you
can replace x by t.
Figure 2.4
Sines and cosines are periodic functions; once you have drawn sinx from x = 0
to x = 2π, the rest of the graph from x = −∞to x = +∞is just a repetition over
and over of the 0 to 2π graph. The number 2π is the period of sin x. A periodic
function need not be a simple sine or cosine, but may be any sort of complicated
graph that repeats itself (Figure 2.4). The interval of repetition is the period.
Example 2.
If we are describing the vibration of a seconds pendulum, the period is 2 sec
(time for one complete back-and-forth oscillation). The reciprocal of the period is
the frequency, the number of oscillations per second; for the seconds pendulum, the
frequency is 1
2 sec−1. When radio announcers say, “operating on a frequency of 780
kilohertz,” they mean that 780,000 radio waves reach you per second, or that the
period of one wave is (1/780,000) sec.
By deﬁnition, the function f(x) is periodic if f(x + p) = f(x) for every x; the
number p is the period. The period of sin x is 2π since sin(x+2π) = sin x; similarly,
the period of sin 2πx is 1 since sin 2π(x + 1) = sin(2πx + 2π) = sin 2πx, and the
period of sin(πx/l) is 2l since sin(π/l)(x + 2l) = sin(πx/l). In general, the period
of sin 2πx/T is T .
PROBLEMS, SECTION 2
In Problems 1 to 6 ﬁnd the amplitude, period, frequency, and velocity amplitude for the
motion of a particle whose distance s from the origin is the given function.
1.
s = 3 cos 5t
2.
s = 2 sin(4t −1)
3.
s = 1
2 cos(πt −8)
4.
s = 5 sin(t −π)
5.
s = 2 sin 3t cos 3t
6.
s = 3 sin(2t + π/8) + 3 sin(2t −π/8)
In Problems 7 to 10 you are given a complex function z = f(t). In each case, show that
a particle whose coordinate is (a) x = Re z, (b) y = Im z is undergoing simple harmonic
motion, and ﬁnd the amplitude, period, frequency, and velocity amplitude of the motion.
7.
z = 5eit
8.
z = 2e−it/2
9.
z = 2eiπt
10.
z = −4ei(2t+3π)

344
Fourier Series and Transforms
Chapter 7
11.
The charge q on a capacitor in a simple a-c circuit varies with time according to the
equation q = 3 sin(120πt + π/4). Find the amplitude, period, and frequency of this
oscillation. By deﬁnition, the current ﬂowing in the circuit at time t is I = dq/dt.
Show that I is also a sinusoidal function of t, and ﬁnd its amplitude, period, and
frequency.
12.
Repeat Problem 11: (a) if q = Re 4e30iπt; (b) if q = Im 4e30iπt.
13.
A simple pendulum consists of a point mass m suspended by a
(weightless) cord or rod of length l, as shown, and swinging in
a vertical plane under the action of gravity. Show that for small
oscillations (small θ), both θ and x are sinusoidal functions of time,
that is, the motion is simple harmonic. Hint: Write the diﬀerential
equation F = ma for the particle m.
Use the approximation
sin θ = θ for small θ, and show that θ = A sin ωt is a solution of
your equation. What are A and ω?
14.
The displacements x of two simple pendulums (see Problem 13) are 4 sin(πt/3) and
3 sin(πt/4).
They start together at x = 0.
How long will it be before they are
together again at x = 0? Hint: Sketch or computer plot the graphs.
15.
As in Problem 14, the displacements x of two simple pendulums are x = −2 cos(t/2)
and 3 sin(t/3). They are not together at t = 0; plot graphs to see when they are
ﬁrst together.
16.
As in Problem 14, let the displacements be y1 = 3 sin(t/
√
2) and y2 = sin t. The
pendulums start together at t = 0. Make computer plots to estimate when they will
be together again and then, by computer, solve the equation y1 = y2 for the root
near your estimate.
17.
Show that equation (2.10) for a wave can be written in all these forms:
y = A sin 2π
λ (x −vt) = A sin 2π
„x
λ −t
T
«
= A sin ω
“x
v −t
”
= A sin
„2πx
λ
−2πft
«
= A sin 2π
T
“x
v −t
”
.
Here λ is the wavelength, f is the frequency, v is the wave velocity, T is the period,
and ω = 2πf is called the angular frequency. Hint: Show that v = λf.
In Problems 18 to 20, ﬁnd the amplitude, period, frequency, wave velocity, and wavelength
of the given wave. By computer, plot on the same axes, y as a function of x for the given
values of t, and label each graph with its value of t. Similarly, plot on the same axes, y as
a function of t for the given values of x, and label each curve with its value of x.
18.
y = 2 sin 2
3π(x −3t);
t = 0, 1
4, 1
2, 3
4;
x = 0, 1, 2, 3.
19.
y = cos 2π(x −1
4t);
t = 0, 1, 2, 3;
x = 0, 1
4, 1
2, 3
4.
20.
y = 3 sin π(x −1
2t);
t = 0, 1, 2, 3;
x = 0, 1
2, 1, 3
2, 2.
21.
Write the equation for a sinusoidal wave of wavelength 4, amplitude 20, and veloc-
ity 6. (See Problem 17.) Make computer plots of y as a function of t for x = 0, 1,
2, 3, and of y as a function of x for t = 0, 1
6, 1
3, 1
2. If this wave represents the shape
of a long rope which is being shaken back and forth at one end, ﬁnd the velocity
∂y/∂t of particles of the rope as a function of x and t. (Note that this velocity has
nothing to do with the wave velocity v, which is the rate at which crests of the wave
move forward.)

Section 3
Applications of Fourier Series
345
22.
Do Problem 21 for a wave of amplitude 4, period 6, and wavelength 3.
Make
computer plots of y as a function of x when t = 0, 1, 2, 3, and of y as a function of
t when x = 1
2, 1, 3
2, 2.
23.
Write an equation for a sinusoidal sound wave of amplitude 1 and frequency 440 hertz
(1 hertz means 1 cycle per second). (Take the velocity of sound to be 350 m/sec.)
24.
The velocity of sound in sea water is about 1530 m/sec. Write an equation for a
sinusoidal sound wave in the ocean, of amplitude 1 and frequency 1000 hertz.
25.
Write an equation for a sinusoidal radio wave of amplitude 10 and frequency 600
kilohertz. Hint: The velocity of a radio wave is the velocity of light, c = 3·108 m/sec.
3. APPLICATIONS OF FOURIER SERIES
We have said that the vibration of a tuning fork is an example of simple harmonic
motion. When we hear the musical note produced, we say that a sound wave has
passed through the air from the tuning fork to our ears. As the tuning fork vibrates
it pushes against the air molecules, creating alternately regions of high and low
Figure 3.1
pressure (Figure 3.1). If we measure the pressure as a function of x and t from the
tuning fork to us, we ﬁnd that the pressure is of the form of (2.10); if we measure
the pressure where we are as a function of t as the wave passes, we ﬁnd that the
pressure is a periodic function of t. The sound wave is a pure sine wave of a deﬁnite
frequency (in the language of music, a pure tone). Now suppose that several pure
tones are heard simultaneously. In the resultant sound wave, the pressure will not
be a single sine function but a sum of several sine functions. If you strike a piano
key you do not get a sound wave of just one frequency. Instead, you get a fundamen-
tal accompanied by a number of overtones (harmonics) of frequencies 2, 3, 4, · · · ,
times the frequency of the fundamental. Higher frequencies mean shorter periods. If
sin ωt and cos ωt correspond to the fundamental frequency, then sin nωt and cos nωt
correspond to the higher harmonics. The combination of the fundamental and the
harmonics is a complicated periodic function with the period of the fundamental
(Problem 5). Given the complicated function, we could ask how to write it as a
sum of terms corresponding to the various harmonics. In general it might require
all the harmonics, that is, an inﬁnite series of terms. This is called a Fourier series.
Expanding a function in a Fourier series then amounts to breaking it down into
its various harmonics. In fact, this process is sometimes called harmonic analysis.

346
Fourier Series and Transforms
Chapter 7
There are applications to other ﬁelds besides sound. Radio waves, visible light,
and x rays are all examples of a kind of wave motion in which the “waves” correspond
to varying electric and magnetic ﬁelds. Exactly the same mathematical equations
apply as for water waves and sound waves. We could then ask what light frequencies
(these correspond to the color) are in a given light beam and in what proportions.
To ﬁnd the answer, we would expand the given function describing the wave in a
Fourier series.
You have probably seen a sine curve used to represent an alternating current
(a-c) or voltage in electricity. This is a periodic function, but so are the functions
shown in Figure 3.2. Any of these and many others might represent signals (volt-
ages or currents) which are to be applied to an electric circuit. Then we could ask
Figure 3.2
what a-c frequencies (harmonics) make up a given signal and in what proportions.
When an electric signal is passed through a network (say a radio), some of the
harmonics may be lost.
If most of the important ones get through with their
relative intensities preserved, we say that the radio possesses “high ﬁdelity.” To
ﬁnd out which harmonics are the important ones in a given signal, we expand it in
a Fourier series. The terms of the series with large coeﬃcients then represent the
important harmonics (frequencies).
Since sines and cosines are themselves periodic, it seems rather natural to use
series of them, rather than power series, to represent periodic functions. There is
another important reason. The coeﬃcients of a power series are obtained, you will
recall (Chapter 1, Section 12), by ﬁnding successive derivatives of the function being
expanded; consequently, only continuous functions with derivatives of all orders can
be expanded in power series. Many periodic functions in practice are not continuous
or not diﬀerentiable (Figure 3.2). Fortunately, Fourier series (unlike power series)
can represent discontinuous functions or functions whose graphs have corners. On
the other hand, Fourier series do not usually converge as rapidly as power series
and much more care is needed in manipulating them. For example, a power series
can be diﬀerentiated term by term (Chapter 1, Section 11), but diﬀerentiating a
Fourier series term by term sometimes produces a series which doesn’t converge.
(See end of Section 9.)
Our problem then is to expand a given periodic function in a series of sines and
cosines. We shall take this up in Section 5 after doing some preliminary work.

Section 4
Average Value of a Function
347
PROBLEMS, SECTION 3
For each of the following combinations of a fundamental musical tone and some of its
overtones, make a computer plot of individual harmonics (all on the same axes) and then
a plot of the sum. Note that the sum has the period of the fundamental (Problem 5).
1.
sin t −1
9 sin 3t
2.
2 cos t + cos 2t
3.
sin πt + sin 2πt + 1
3 sin 3πt
4.
cos 2πt + cos 4πt + 1
2 cos 6πt
5.
Using the deﬁnition (end of Section 2) of a periodic function, show that a sum of
terms corresponding to a fundamental musical tone and its overtones has the period
of the fundamental.
In Problems 6 and 7, use a trigonometry formula to write the two terms as a single
harmonic. Find the period and amplitude. Compare computer plots of your result and
the given problem.
6.
sin 2x + sin 2(x + π/3)
7.
cos πx −cos π(x −1/2)
8.
A periodic modulated (AM) radio signal has the form
y = (A + B sin 2πft) sin 2πfc
“
t −x
v
”
.
The factor sin 2πfc(t −x/v) is called the carrier wave; it has a very high frequency
(called radio frequency; fc is of the order of 106 cycles per second). The amplitude
of the carrier wave is (A + B sin 2πft). This amplitude varies with time—hence the
term “amplitude modulation”—with the much smaller frequency of the sound being
transmitted (called audio frequency; f is of the order of 102 cycles per second). In
order to see the general appearance of such a wave, use the following simple but
unrealistic data to sketch a graph of y as a function of t for x = 0 over two periods
of the amplitude function: A = 3, B = 1, f = 1, fc = 20. Using trigonometric
formulas, show that y can be written as a sum of three waves of frequencies fc,
fc + f, and fc −f; the ﬁrst of these is the carrier wave and the other two are called
side bands.
4. AVERAGE VALUE OF A FUNCTION
The concept of the average value of a function is often useful. You know how to ﬁnd
the average of a set of numbers: you add them and divide by the number of numbers.
Figure 4.1

348
Fourier Series and Transforms
Chapter 7
This process suggests that we ought to get an approximation to the average value
of a function f(x) on the interval (a, b) by averaging a number of values of f(x)
(Figure 4.1):
Average of f(x) on (a, b) is approximately equal to
(4.1)
f(x1) + f(x2) + · · · + f(xn)
n
.
This should become a better approximation as n increases. Let the points x1, x2, · · ·
be ∆x apart. Multiply the numerator and the denominator of the approximate
average by ∆x. Then (4.1) becomes:
Average of f(x) on (a, b) is approximately equal to
(4.2)
[f(x1) + · · · + f(xn)]∆x
n ∆x
.
Now n ∆x = b−a, the length of the interval over which we are averaging, no matter
what n and ∆x are. If we let n →∞and ∆x →0, the numerator approaches
 b
a f(x) dx, and we have
(4.3)
Average of f(x) on (a, b) =
 b
a f(x) dx
b −a
.
In applications, it may happen that the average value of a given function is zero.
Example1.
The average of sin x over any number of periods is zero. The average value of
the velocity of a simple harmonic oscillator over any number of vibrations is zero.
In such cases the average of the square of the function may be of interest.
Example 2.
If the alternating electric current ﬂowing through a wire is described by a
sine function, the square root of the average of the sine squared is known as the
root-mean-square or eﬀective value of the current, and is what you would measure
with an a-c ammeter. In the example of the simple harmonic oscillator, the average
kinetic energy (average of 1
2mv2) is 1
2m times the average of v2.
Figure 4.2
Now you can, of course, ﬁnd the average value of sin2 x over a period (say −π
to π) by evaluating the integral in (4.3). There is an easier way. Look at the graphs
of cos2 x and sin2 x (Figure 4.2). You can probably convince yourself that the area

Section 4
Average Value of a Function
349
under them is the same for any quarter-period from 0 to π/2, π/2 to π, etc. (Also
see Problems 2 and 13.) Then
(4.4)
 π
−π
sin2 x dx =
 π
−π
cos2 x dx.
Similarly (for integral n ̸= 0),
(4.5)
 π
−π
sin2 nx dx =
 π
−π
cos2 nx dx.
But since sin2 nx + cos2 nx = 1,
(4.6)
 π
−π
(sin2 nx + cos2 nx) dx =
 π
−π
dx = 2π.
Using (4.5), we get
(4.7)
 π
−π
sin2 nx dx =
 π
−π
cos2 nx dx = π.
Then using (4.3) we see that:
The average value (over a period) of sin2 nx
= the average value (over a period) of cos2 nx
= 1
2π
 π
−π
sin2 nx dx = 1
2π
 π
−π
cos2 nx dx = π
2π = 1
2.
(4.8)
We can say all this more simply in words. By (4.5), the average value of sin2 nx
equals the average value of cos2 nx. The average value of sin2 nx + cos2 nx = 1 is 1.
Therefore the average value of sin2 nx or of cos2 nx is 1
2. (In each case the average
value is taken over one or more periods.)
PROBLEMS, SECTION 4
1.
Show that if f(x) has period p, the average value of f is the same over any interval
of length p. Hint: Write
R a+p
a
f(x) dx as the sum of two integrals (a to p, and p to
a + p) and make the change of variable x = t + p in the second integral.
2.
(a)
Prove that
R π/2
0
sin2 x dx =
R π/2
0
cos2 x dx by making the change of variable
x = 1
2π −t in one of the integrals.
(b)
Use the same method to prove that the averages of sin2(nπx/l) and cos2(nπx/l)
are the same over a period.
In Problems 3 to 12, ﬁnd the average value of the function on the given interval. Use
equation (4.8) if it applies. If an average value is zero, you may be able to decide this from
a quick sketch which shows you that the areas above and below the x axis are the same.
3.
sin x + 2 sin 2x + 3 sin 3x on (0, 2π)
4.
1 −e−x on (0, 1)

350
Fourier Series and Transforms
Chapter 7
5.
cos2 x
2 on
“
0, π
2
”
6.
sin x on (0, π)
7.
x −cos2 6x on
“
0, π
6
”
8.
sin 2x on
„π
6 , 7π
6
«
9.
sin2 3x on (0, 4π)
10.
cos x on (0, 3π)
11.
sin x + sin2 x on (0, 2π)
12.
cos2 7πx
2
on
„
0, 8
7
«
13.
Using (4.3) and equations similar to (4.5) to (4.7), show that
Z b
a
sin2 kx dx =
Z b
a
cos2 kx dx = 1
2(b −a)
if k(b −a) is an integral multiple of π, or if kb and ka are both integral
multiples of π/2.
Use the results of Problem 13 to evaluate the following integrals without calculation.
14.
(a)
Z 4π/3
0
sin2
„3x
2
«
dx
(b)
Z 3π/2
−π/2
cos2 “x
2
”
dx
15.
(a)
Z 11/4
−1/4
cos2 πx dx
(b)
Z 2
−1
sin2 “πx
3
”
dx
16.
(a)
Z 2π/ω
0
sin2 ωt dt
(b)
Z 2
0
cos2 2πt dt
5. FOURIER COEFFICIENTS
We want to expand a given periodic function in a series of sines and cosines. To
simplify our formulas at ﬁrst, we start with functions of period 2π; that is, we shall
expand periodic functions of period 2π in terms of the functions sin nx and cos nx.
(Later we shall see how we can change the formulas to ﬁt a diﬀerent period—see
Section 8.) The functions sin x and cos x have period 2π; so do sin nx and cos nx
for any integral n since sin n(x + 2π) = sin(nx + 2nπ) = sin nx. (It is true that
sin nx and cos nx also have shorter periods, namely 2π/n, but the fact that they
repeat every 2π is what we are interested in here, for this makes them reasonable
functions to use in an expansion of a function of period 2π.) Then, given a function
f(x) of period 2π, we write
f(x) = 1
2a0 + a1 cos x + a2 cos 2x + a3 cos 3x + · · ·
(5.1)
+ b1 sin x + b2 sin 2x + b3 sin 3x + · · · ,
and derive formulas for the coeﬃcients an and bn. (The reason for writing 1
2a0 as
the constant term will be clear later—it makes the formulas for the coeﬃcients
simpler to remember—but you must not forget the 1
2 in the series!)
In ﬁnding formulas for an and bn in (5.1) we need the following integrals:

Section 5
Fourier Coefﬁcients
351
The average value of sin mx cos nx (over a period)
(5.2)
= 1
2π
 π
−π
sin mx cos nx dx = 0.
The average value of sin mx sin nx (over a period)
= 1
2π
 π
−π
sin mx sin nx dx =





0,
m ̸= n,
1
2,
m = n ̸= 0,
0,
m = n = 0.
The average value of cos mx cos nx (over a period)
= 1
2π
 π
−π
cos mx cos nx dx =





0,
m ̸= n,
1
2,
m = n ̸= 0,
1,
m = n = 0.
We have already shown that the average values of sin2 nx and cos2 nx are 1
2. The
last integral in (5.2) is the average value of 1 which is 1. To show that the other
average values in (5.2) are zero (unless m = n ̸= 0), we could use the trigonometry
formulas for products like sin θ cos φ and then integrate. An easier way is to use the
formulas for the sines and cosines in terms of complex exponentials. [See (7.1) or
Chapter 2, Section 11.] We shall show this method for one integral
(5.3)
 π
−π
sin mx cos nx dx =
 π
−π
eimx −e−imx
2i
· einx + e−inx
2
dx.
We can see the result without actually multiplying these out.
All terms in the
product are of the form eikx, where k is an integer ̸= 0 (except for the cross-
product terms when n = m, and these cancel). We can show that the integral of
each such term is zero:
(5.4)
 π
−π
eikx dx = eikx
ik
				
π
−π
= eikπ −e−ikπ
ik
= 0
because eikπ = e−ikπ = cos kπ (since sin kπ = 0). The other integrals in (5.2) may
be evaluated similarly (Problem 12).
We now show how to ﬁnd an and bn in (5.1). To ﬁnd a0, we ﬁnd the average
value on (−π, π) of each term of (5.1).
(5.5)
1
2π
 π
−π
f(x) dx = a0
2
1
2π
 π
−π
dx + a1
1
2π
 π
−π
cos x dx
+ a2
1
2π
 π
−π
cos 2x dx + · · · + b1
1
2π
 π
−π
sin x dx + · · · .
By (5.2), all the integrals on the right-hand side of (5.5) are zero except the ﬁrst,
because they are integrals of sin mx cos nx or of cos mx cos nx with n = 0 and m ̸= 0
(that is, m ̸= n). Then we have
1
2π
 π
−π
f(x) dx = a0
2
1
2π
 π
−π
dx = a0
2 ,
a0 = 1
π
 π
−π
f(x) dx.
(5.6)

352
Fourier Series and Transforms
Chapter 7
Given f(x) to be expanded in a Fourier series, we can now evaluate a0 by calculating
the integral in (5.6).
To ﬁnd a1, multiply both sides of (5.1) by cos x and again ﬁnd the average value
of each term:
(5.7)
1
2π
 π
−π
f(x) cos x dx = a0
2
1
2π
 π
−π
cos x dx + a1
1
2π
 π
−π
cos2 x dx
+ a2
1
2π
 π
−π
cos 2x cos x dx + · · ·
+ b1
1
2π
 π
−π
sin x cos x dx + · · · .
This time, by (5.2), all terms on the right are zero except the a1 term and we have
1
2π
 π
−π
f(x) cos x dx = a1
1
2π
 π
−π
cos2 x dx = 1
2a1.
Solving for a1, we have
a1 = 1
π
 π
−π
f(x) cos x dx.
The method should be clear by now, so we shall next ﬁnd a general formula for an.
Multiply both sides of (5.1) by cos nx and ﬁnd the average value of each term:
(5.8)
1
2π
 π
−π
f(x) cos nx dx = a0
2
1
2π
 π
−π
cos nx dx + a1
1
2π
 π
−π
cos x cos nx dx
+ a2
1
2π
 π
−π
cos 2x cos nx dx + · · ·
+ b1
1
2π
 π
−π
sin x cos nx dx + · · · .
By (5.2), all terms on the right are zero except the an term and we have
1
2π
 π
−π
f(x) cos nx dx = an
1
2π
 π
−π
cos2 nx dx = 1
2an.
Solving for an, we have
(5.9)
an = 1
π
 π
−π
f(x) cos nx dx.
Notice that this includes the n = 0 formula, but only because we called the constant
term 1
2a0.
To obtain a formula for bn, we multiply both sides of (5.1) by sin nx and take
average values just as we did in deriving (5.9). We ﬁnd (Problem 13)
(5.10)
bn = 1
π
 π
−π
f(x) sin nx dx.
The formulas (5.9) and (5.10) will be used repeatedly in problems and should be
memorized.

Section 5
Fourier Coefﬁcients
353
Example 1.
Expand in a Fourier series the function f(x) sketched in Figure 5.1. This
function might represent, for example, a periodic voltage pulse. The terms of our
Fourier series would then correspond to the diﬀerent a-c frequencies which are com-
bined in this “square wave” voltage, and the magnitude of the Fourier coeﬃcients
would indicate the relative importance of the various frequencies.
Figure 5.1
Note that f(x) is a function of period 2π. Often in problems you will be given
f(x) for only one period; you should always sketch several periods so that you see
clearly the periodic function you are expanding.
For example, in this problem,
instead of a sketch, you might have been given
(5.11)
f(x) =

0,
−π < x < 0,
1,
0 < x < π.
It is then understood that f(x) is to be continued periodically with period 2π outside
the interval (−π, π).
We use equations (5.9) and (5.10) to ﬁnd an and bn:
an = 1
π
 π
−π
f(x) cos nx dx = 1
π
 0
−π
0 · cos nx dx +
 π
0
1 · cos nx dx

= 1
π
 π
0
cos nx dx =





1
π · 1
n sin nx
				
π
0
= 0
for n ̸= 0,
1
π · π = 1
for n = 0.
Thus a0 = 1, and all other an = 0.
bn = 1
π
 π
−π
f(x) sin nx dx = 1
π
 0
−π
0 · sin nx dx +
 π
0
1 · sin nx dx

= 1
π
 π
0
sin nx dx = 1
π
−cos nx
n
π
0
= −1
nπ [(−1)n −1]
=



0
for even n,
2
nπ
for odd n.
Putting these values for the coeﬃcients into (5.1), we have
(5.12)
f(x) = 1
2 + 2
π
sin x
1
+ sin 3x
3
+ sin 5x
5
+ · · ·

.

354
Fourier Series and Transforms
Chapter 7
Example 2.
We can now ﬁnd the Fourier series for some other functions without more
evaluation of coeﬃcients. For example, consider
(5.13)
g(x) =

−1,
−π < x < 0,
1,
0 < x < π.
Sketch this and verify that g(x) = 2f(x)−1, where f(x) is the function in Example 1.
Then from (5.12), the Fourier series for g(x) is
(5.14)
g(x) = 4
π
sin x
1
+ sin 3x
3
+ sin 5x
5
+ · · ·

.
Similarly, verify that h(x) = f(x + π/2) is Fig. 5.1 shifted π/2 to the left (sketch
it), and its Fourier series is (replace x in (5.12) by x + π/2)
h(x) = 1
2 + 2
π
cos x
1
−cos 3x
3
+ cos 5x
5
+ · · ·

since sin(x + π/2) = cos x, sin(x + 3π/2) = −cos3x, etc.
PROBLEMS, SECTION 5
In each of the following problems you are given a function on the interval −π < x < π.
Sketch several periods of the corresponding periodic function of period 2π. Expand the
periodic function in a sine-cosine Fourier series.
1.
f(x) =
(
1,
−π < x < 0,
0,
0 < x < π.
In this case the sketch is:
Your answer for the series is: f(x) = 1
2 −2
π
„sin x
1
+ sin 3x
3
+ sin 5x
5
· · ·
«
.
Can you use the ideas of Example 2 to ﬁnd this result without computation?
2.
f(x) =
8
>
>
<
>
>
:
0,
−π < x < 0,
1,
0 < x < π
2 ,
0,
π
2 < x < π.
Answer: f(x) = 1
4 + 1
π
„cos x
1
−cos 3x
3
+ cos 5x
5
· · ·
«
+ 1
π
„sin x
1
+ 2 sin 2x
2
+ sin 3x
3
+ sin 5x
5
· · ·
«
.
3.
f(x) =
8
<
:
0,
−π < x < π
2 ,
1,
π
2 < x < π.
Answer: f(x) = 1
4 −1
π
„cos x
1
−cos 3x
3
+ cos 5x
5
· · ·
«
+ 1
π
„sin x
1
−2 sin 2x
2
+ sin 3x
3
+ sin 5x
5
−2 sin 6x
6
· · ·
«
.

Section 6
Dirichlet Conditions
355
4.
f(x) =
8
<
:
−1,
−π < x < π
2 ,
1,
π
2 < x < π.
Could you use Problem 3 to solve Problem 4 without computation?
5.
f(x) =
8
>
>
<
>
>
:
0,
−π < x < 0,
−1,
0 < x < π
2 ,
1,
π
2 < x < π.
6.
f(x) =
8
<
:
1,
−π < x < −π
2 ,
and
0 < x < π
2 ;
0,
−π
2 < x < 0,
and
π
2 < x < π.
7.
f(x) =
(
0,
−π < x < 0;
x,
0 < x < π.
Answer: f(x) = π
4 −2
π
„
cos x + cos 3x
32
+ cos 5x
52
+ · · ·
«
+
„
sin x −sin 2x
2
+ sin 3x
3
−· · ·
«
.
8.
f(x) = 1 + x,
−π < x < π.
Answer: f(x) = 1 + 2
„
sin x −1
2 sin 2x + 1
3 sin 3x −1
4 sin 4x + · · ·
«
.
9.
f(x) =
(
−x,
−π < x < 0,
x,
0 < x < π.
Answer: f(x) = π
2 −4
π
„
cos x + 1
9 cos 3x + 1
25 cos 5x + · · ·
«
.
10.
f(x) =
(
π + x,
−π < x < 0,
π −x,
0 < x < π.
11.
f(x) =
(
0,
−π < x < 0,
sin x,
0 < x < π.
Answer: f(x) = 1
π + 1
2 sin x −2
π
„ cos 2x
22 −1 + cos 4x
42 −1 + cos 6x
62 −1 + · · ·
«
.
12.
Show that in (5.2) the average values of sin mx sin nx and of cos mx cos nx, m ̸= n,
are zero (over a period), by using the complex exponential forms for the sines and
cosines as in (5.3).
13.
Write out the details of the derivation of equation (5.10).
6. DIRICHLET CONDITIONS
Now we have a series, but there are still some questions that we ought to get
answered. Does it converge, and if so, does it converge to the values of f(x)? You
will ﬁnd, if you try, that for most values of x the series in (5.12) does not respond
to any of the tests for convergence that we discussed in Chapter 1. What is the
sum of the series at x = 0 where f(x) jumps from 0 to 1? You can see from the
series (5.12) that the sum at x = 0 is 1
2, but what does this have to do with f(x)?

356
Fourier Series and Transforms
Chapter 7
These questions would not be easy for us to answer for ourselves, but they are
answered for us for most practical purposes by the theorem of Dirichlet:
If f(x) is periodic of period 2π, and if between −π and π it is single-valued,
has a ﬁnite number of maximum and minimum values, and a ﬁnite number of
discontinuities, and if
 π
−π |f(x)| dx is ﬁnite, then the Fourier series (5.1) [with
coeﬃcients given by (5.9) and (5.10)] converges to f(x) at all the points where
f(x) is continuous; at jumps the Fourier series converges to the midpoint of the
jump. (This includes jumps that occur at ±π for the periodic function.)
To see what all this means, we shall consider some special functions. We have
already discussed what a periodic function means. A function f(x) is single-valued
if there is just one value of f(x) for each x.
For example, if x2 + y2 = 1, y
is not a single-valued function of x, unless we select just y = +
√
1 −x2 or just
y = −
√
1 −x2. An example of a function with an inﬁnite number of maxima and
minima is sin(1/x), which oscillates inﬁnitely many times as x →0. If we imagine
a function constructed from sin(1/x) by making f(x) = 1 for every x for which
sin(1/x) > 0, and f(x) = −1 for every x for which sin(1/x) < 0, this function
would have an inﬁnite number of discontinuities. Now most functions in applied
work do not behave like these, but will satisfy the Dirichlet conditions.
Finally, if y = 1/x, we ﬁnd
 π
−π
				
1
x
				 dx = 2
 π
0
1
x dx = 2 ln x
				
1
0
= ∞,
so the function 1/x is ruled out by the Dirichlet conditions. On the other hand, if
f(x) = 1/

|x|, then
 π
−π
1

|x|
dx = 2
 π
0
dx
√x = 4√x
				
π
0
= 4√π,
so the periodic function which is 1/

|x| between −π and π can be expanded in a
Fourier series. In most problems it is not necessary to ﬁnd the value of
 π
−π |f(x)| dx;
let us see why. If f(x) is bounded (that is, all its values lie between ±M for some
positive constant M), then
 π
−π
|f(x)|dx ≤
 π
−π
M dx = M · 2π
Figure 6.1

Section 6
Dirichlet Conditions
357
and so is ﬁnite. Thus you can simply verify that the function you are considering is
bounded (if it is) instead of evaluating the integral. Figure 6.1 is an (exaggerated!)
example of a function which satisﬁes the Dirichlet conditions on (−π, π).
We see, then, that rather than testing Fourier series for convergence as we did
power series, we instead check the given function; if it satisﬁes the Dirichlet con-
ditions we are then sure that the Fourier series, when we get it, will converge to
the function at points of continuity and to the midpoint of a jump.
For exam-
ple, consider the function f(x) in Figure 5.1. Between −π and π the given f(x)
is single-valued (one value for each x), bounded (between +1 and 0), has a ﬁnite
number of maximum and minimum values (one of each), and a ﬁnite number of
discontinuities (at −π, 0, and π), and therefore satisﬁes the Dirichlet conditions.
Dirichlet’s theorem then assures us that the series (5.12) actually converges to the
function f(x) in Figure 5.1 at all points except x = nπ where it converges to 1/2.
In Chapter 3, Sections 10 and 14, we deﬁned a basis for ordinary 3-dimensional
space as a set of linearly independent vectors (like i, j , k) in terms of which we could
write every vector in the space. We then extended this idea to an n-dimensional
space and to a space in which the basis vectors were functions. By analogy, we say
here that the functions sin nx, cos nx are a set of basis functions for the (inﬁnite di-
mensional) space of all functions (satisfying Dirichlet conditions) deﬁned on (−π, π)
or any 2π interval. (Also see “completeness relation” in Section 11. And for more
examples of such sets of basis functions, see Chapters 12 and 13.)
Figure 6.2
It is interesting to see a graph of the sum of a large number of terms of a Fourier
series. Figure 6.2 shows several diﬀerent partial sums of the series in (5.12) for the
function in Figure 5.1. We can see that the sum of many terms of the series closely
approximates the function away from the jumps and goes through the midpoint
of the jump. The “overshoot” on either side of a jump bears comment. It does
not disappear as we add more and more terms of the series. It simply becomes a
narrower and narrower spike of height equal to about 9% of the jump. This fact is
called the Gibbs phenomenon.

358
Fourier Series and Transforms
Chapter 7
We ought to say here that the converse of Dirichlet’s theorem is not true—if
a function fails to satisfy the Dirichlet conditions, it still may be expandable in a
Fourier series. The periodic function which is sin(1/x) on (−π, π) is an example of
such a function. However, such functions are rarely met with in practice.
Example.
Fourier series can be useful in summing numerical series. Look at Problem 5.2
(sketch it). From Dirichlet’s theorem, we see that the Fourier series converges to
1/2 at x = 0. Let x = 0 in the Fourier series to get
1
2 = 1
4 + 1
π

1 −1
3 + 1
5 −1
7 + · · ·

since sin 0 = 0 and cos 0 = 1. Thus
1 −1
3 + 1
5 −1
7 + · · · = π
4 .
PROBLEMS, SECTION 6
1 to 11. For each of the periodic functions in Problems 5.1 to 5.11, use Dirichlet’s theorem
to ﬁnd the value to which the Fourier series converges at x = 0, ±π/2, ±π, ±2π.
12.
Use a computer to produce graphs like Fig. 6.2 showing Fourier series approximations
to the functions in Problems 5.1 to 5.3, and 5.7 to 5.11.
You might like to set
up a computer animation showing the Gibbs phenomenon as the number of terms
increases.
13.
Repeat the example using the same Fourier series but at x = π/2.
14.
Use Problem 5.7 to show that P
odd n 1/n2 = π2/8. Try x = 0, and x = π. What
do you ﬁnd at x = π/2?
15.
Use Problem 5.11 to show that
1
22 −1 +
1
42 −1 +
1
62 −1 + · · · = 1
2.
7. COMPLEX FORM OF FOURIER SERIES
Recall that real sines and cosines can be expressed in terms of complex exponentials
by the formulas [Chapter 2, (11.3)]
(7.1)
sin nx = einx −e−inx
2i
,
cos nx = einx + e−inx
2
.
If we substitute equations (7.1) into a Fourier series like (5.12), we get a series of
terms of the forms einx and e−inx. This is the complex form of a Fourier series. We
can also ﬁnd the complex form directly; this is often easier than ﬁnding the sine-
cosine form. We can then, if we like, work back the other way and [using Euler’s
formula, Chapter 2, (9.3)] get the sine-cosine form from the exponential form.
We want to see how to ﬁnd the coeﬃcients in the complex form directly. We
assume a series
f(x) = c0 + c1eix + c−1e−ix + c2e2ix + c−2e−2ix + · · ·
(7.2)
=
n=+∞

n=−∞
cneinx

Section 7
Complex Form of Fourier Series
359
and try to ﬁnd the cn’s. From (5.4) we know that the average value of eikx on (−π, π)
is zero when k is an integer not equal to zero. To ﬁnd c0, we ﬁnd the average values
of the terms in (7.2):
1
2π
 π
−π
f(x) dx = c0 · 1
2π
 π
−π
dx +

average values of terms of the
form eikx with k an integer ̸= 0
(7.3)
= c0 + 0,
(7.4)
c0 = 1
2π
 π
−π
f(x) dx.
To ﬁnd cn, we multiply (7.2) by e−inx and again ﬁnd the average value of each
term. Note the minus sign in the exponent. In ﬁnding an, the coeﬃcient of cos nx
in equation (5.1), we multiplied by cos nx; but here in ﬁnding the coeﬃcient cn of
einx, we multiply by the complex conjugate e−inx.
1
2π
 π
−π
f(x)e−inx dx = c0
1
2π
 π
−π
e−inx dx + c1
1
2π
 π
−π
e−inxeix dx
(7.5)
+ c−1
1
2π
 π
−π
e−inxe−ix dx + · · · .
The terms on the right are the average values of exponentials eikx, where the k
values are integers. Therefore all these terms are zero except the one where k = 0;
this is the term containing cn. We then have
1
2π
 π
−π
f(x)e−inx dx = cn · 1
2π
 π
−π
e−inxeinx dx = cn · 1
2π
 π
−π
dx = cn,
(7.6)
cn = 1
2π
 π
−π
f(x)e−inx dx.
Note that this formula contains the one for c0 (no 1
2 to worry about here!). Also,
since (7.6) is valid for negative as well as positive n, you have only one formula to
memorize here! You can easily show that for real f(x), c−n = ¯cn (Problem 12).
Example.
Let us expand the same f(x) we did before, namely (5.11). We have from (7.6)
cn = 1
2π
 0
−π
e−inx · 0 · dx + 1
2π
 π
0
e−inx · 1 · dx
=
1
2π
e−inx
−in
				
π
0
=
1
−2πin(e−inπ −1) =

1
πin,
n odd,
0,
n even ̸= 0,
(7.7)
c0 = 1
2π
 π
0
dx = 1
2.

360
Fourier Series and Transforms
Chapter 7
Then
f(x) =
∞

−∞
cneinx = 1
2 + 1
iπ
eix
1 + e3ix
3
+ e5ix
5
+ · · ·

(7.8)
+ 1
iπ
e−ix
−1 + e−3ix
−3
+ e−5ix
−5
+ · · ·

.
It is interesting to verify that this is the same as the sine-cosine series we had before.
We could use Euler’s formula for each exponential, but it is easier to collect terms
like this:
f(x) = 1
2 + 2
π
eix −e−ix
2i
+ 1
3
e3ix −e−3ix
2i
+ · · ·

(7.9)
= 1
2 + 2
π

sin x + 1
3 sin 3x + · · ·

which is the same as (5.12).
PROBLEMS, SECTION 7
1 to 11.
Expand the same functions as in Problems 5.1 to 5.11 in Fourier series of
complex exponentials einx on the interval (−π, π) and verify in each case that the answer
is equivalent to the one found in Section 5.
12.
Show that if a real f(x) is expanded in a complex exponential Fourier series
P∞
−∞cneinx, then c−n = ¯cn, where ¯cn means the complex conjugate of cn.
13.
If f(x) = 1
2a0 + P∞
1 an cos nx + P∞
1 bn sin nx = P∞
−∞cneinx, use Euler’s formula
to ﬁnd an and bn in terms of cn and c−n, and to ﬁnd cn and c−n in terms of an
and bn.
8. OTHER INTERVALS
The functions sin nx and cos nx and einx have period 2π. We have been considering
(−π, π) as the basic interval of length 2π. Given f(x) on (−π, π), we have ﬁrst
sketched it for this interval, and then repeated our sketch for the intervals (π, 3π),
(3π, 5π), (−3π, −π), etc. There are (inﬁnitely) many other intervals of length 2π,
any one of which could serve as the basic interval. If we are given f(x) on any
interval of length 2π, we can sketch f(x) for that given basic interval and then
repeat it periodically with period 2π. We then want to expand the periodic function
so obtained, in a Fourier series. Recall that in evaluating the Fourier coeﬃcients,
we used average values over a period. The formulas for the coeﬃcients are then
unchanged (except for the limits of integration) if we use other basic intervals of
length 2π. In practice, the intervals (−π, π) and (0, 2π) are the ones most frequently
used. For f(x) deﬁned on (0, 2π) and then repeated periodically, (5.9), (5.10), and
(7.6) would read
an = 1
π
 2π
0
f(x) cos nx dx,
bn = 1
π
 2π
0
f(x) sin nx dx,
cn = 1
2π
 2π
0
f(x)e−inx dx,
(8.1)

Section 8
Other Intervals
361
and (5.1) and (7.2) are unchanged.
Figure 8.1
Notice how important it is to sketch a graph to see clearly what function you
are talking about. For example, given f(x) = x2 on (−π, π), the extended function
of period 2π is shown in Figure 8.1. But given f(x) = x2 on (0, 2π), the extended
periodic function is diﬀerent (see Figure 8.2). On the other hand, given f(x) as in
our example (5.11), or given f(x) = 1 on (0, π), f(x) = 0 on (π, 2π), you can easily
verify by sketching that the graphs of the extended functions are identical. In this
case you would get the same answer from either formulas (5.9), (5.10), and (7.6) or
formulas (8.1).
Figure 8.2
Physics problems do not always come to us with intervals of length 2π. Fortu-
nately, it is easy now to change to other intervals. Consider intervals of length 2l,
say (−l, l) or (0, 2l). The function sin(nπx/l) has period 2l, since
sin nπ
l (x + 2l) = sin
nπx
l
+ 2nπ

= sin nπx
l
.
Similarly, cos(nπx/l) and einπx/l have period 2l. Equations (5.1) and (7.2) are now
replaced by
f(x) = a0
2 + a1 cos πx
l + a2 cos 2πx
l
+ · · ·
+ b1 sin πx
l + b2 sin 2πx
l
+ · · ·
= a0
2 +
∞

1

an cos nπx
l
+ bn sin nπx
l

,
f(x) =
∞

−∞
cneinπx/l.
(8.2)

362
Fourier Series and Transforms
Chapter 7
We have already found the average values over a period of all the functions we
need to use to ﬁnd an, bn, and cn here. The period is now of length 2l, say −l to l,
so in ﬁnding average values of the terms we replace
1
2π
 π
−π
by
1
2l
 l
−l
.
Recall that the average of the square of either the sine or the cosine over a period
is 1
2 and the average of einπx/l · e−inπx/l = 1 is 1. Then the formulas (5.9), (5.10),
and (7.6) for the coeﬃcients become
(8.3)
an = 1
l
 l
−l
f(x) cos nπx
l
dx,
bn = 1
l
 l
−l
f(x) sin nπx
l
dx,
cn = 1
2l
 l
−l
f(x)e−inπx/l dx.
For the basic interval (0, 2l) we need only change the integration limits to 0 to 2l.
The Dirichlet theorem just needs π replaced by l in order to apply here.
Example.
Given f(x) =

0,
0 < x < l,
1,
l < x < 2l.
Expand f(x) in an exponential Fourier series of period 2l. [The function is given
by the same formulas as (5.11) but on a diﬀerent interval.]
Figure 8.3
First we sketch a graph of f(x) repeated with period 2l (Figure 8.3). By equa-
tions (8.3), we ﬁnd
cn = 1
2l
 l
0
0 · dx + 1
2l
 2l
l
1 · e−inπx/l dx
= 1
2l
e−inπx/l
−inπ/l
				
2l
l
=
1
−2inπ(e−2inπ −e−inπ)
=
1
−2inπ(1 −einπ) =



0,
even n ̸= 0,
−1
inπ ,
odd n,
c0 = 1
2l
 2l
l
dx = 1
2.
(8.4)

Section 8
Other Intervals
363
Then,
f(x) = 1
2 −1
iπ (eiπx/l −e−iπx/l + 1
3e3iπx/l −1
3e−3iπx/l + · · · )
(8.5)
= 1
2 −2
π

sin πx
l + 1
3 sin 3πx
l
+ · · ·

.
PROBLEMS, SECTION 8
1 to 9. In Problems 5.1 to 5.9, deﬁne each function by the formulas given but on the
interval (−l, l). [That is, replace ±π by ±l and ±π/2 by ±l/2.] Expand each function in
a sine-cosine Fourier series and in a complex exponential Fourier series.
10.
(a)
Sketch several periods of the function f(x) of period 2π which is equal to x
on −π < x < π. Expand f(x) in a sine-cosine Fourier series and in a complex
exponential Fourier series.
Answer: f(x) = 2(sin x −1
2 sin 2x + 1
3 sin 3x −1
4 sin 4x + · · · ).
(b)
Sketch several periods of the function f(x) of period 2π which is equal to x
on 0 < x < 2π. Expand f(x) in a sine-cosine Fourier series and in a complex
exponential Fourier series. Note that this is not the same function or the same
series as (a).
Answer: f(x) = π −2
∞
X
1
sin nx
n
.
In Problems 11 to 14, parts (a) and (b), you are given in each case one period of a function.
Sketch several periods of the function and expand it in a sine-cosine Fourier series, and in
a complex exponential Fourier series.
11.
(a) f(x) = x2, −π < x < π;
(b) f(x) = x2, 0 < x < 2π.
12.
(a) f(x) = ex, −π < x < π;
(b) f(x) = ex, 0 < x < 2π.
13.
(a) f(x) = 2 −x, −2 < x < 2;
(b) f(x) = 2 −x, 0 < x < 4.
14.
(a) f(x) = sin πx, −1
2 < x < 1
2;
(b) f(x) = sin πx, 0 < x < 1.
15.
Sketch (or computer plot) each of the following functions on the interval (−1, 1) and
expand it in a complex exponential series and in a sine-cosine series.
(a)
f(x) = x,
−1 < x < 1.
Answer: f(x) = 2
π
∞
X
1
(−1)n+1 sin nπx
n
.
(b)
f(x) =
(
1 + 2x,
−1 < x < 0,
1 −2x,
0 < x < 1.
Answer: f(x) = 8
π2
∞
X
odd n=1
cos nπx
n2
.
(c)
f(x) =
(
x + x2,
−1 < x < 0,
x −x2,
0 < x < 1.
Answer: f(x) = 8
π3
∞
X
odd n=1
sin nπx
n3
.

364
Fourier Series and Transforms
Chapter 7
Each of the following functions is given over one period. Sketch several periods of the
corresponding periodic function and expand it in an appropriate Fourier series.
16.
f(x) = x,
0 < x < 2.
Answer: f(x) = 1 −2
π
∞
X
1
sin nπx
n
.
17.
f(x) =
(
0,
−1 < x < 0,
1,
0 < x < 3.
18.
f(x) = x2,
0 < x < 10.
19.
f(x) =
(
0,
−1
2 < x < 0,
x,
0 < x < 1
2.
20.
f(x) =
(
x/2,
0 < x < 2,
1,
2 < x < 3.
21.
Write out the details of the derivation of the formulas (8.3).
9. EVEN AND ODD FUNCTIONS
An even function is one like x2 or cos x (Figure 9.1) whose graph for negative x is
just a reﬂection in the y axis of its graph for positive x. In formulas, the value of
f(x) is the same for a given x and its negative; that is
(9.1)
f(x)
is even if
f(−x) = f(x).
Figure 9.1
Figure 9.2
An odd function is one like x or sin x (Figure 9.2) for which the values of f(x)
and f(−x) are negatives of each other. By deﬁnition
(9.2)
f(x)
is odd if
f(−x) = −f(x).
Notice that even powers of x are even, and odd powers of x are odd; in fact, this

Section 9
Even and Odd Functions
365
is the reason for the names. You should verify (Problem 14) the following rules for
the product of two functions: An even function times an even function, or an odd
function times an odd function, gives an even function; an odd function times an
even function gives an odd function. Some functions are even, some are odd, and
some (for example, ex) are neither. However, any function can be written as the
sum of an even function and an odd function, like this:
f(x) = 1
2[f(x) + f(−x)] + 1
2[f(x) −f(−x)];
the ﬁrst part is even and the second part is odd. For example,
ex = 1
2(ex + e−x) + 1
2(ex −e−x) = cosh x + sinh x;
cosh x is even and sinh x is odd (look at the graphs).
Integrals of even functions or of odd functions, over symmetric intervals like
(−π, π) or (−l, l), can be simpliﬁed. Look at the graph of sin x and think about
 π
−π sin x dx. The negative area from −π to 0 cancels the positive area from 0 to π,
so the integral is zero. This integral is still zero for any interval (−l, l) which is
symmetric about the origin, as you can see from the graph. The same is true for
any odd f(x); the areas to the left and to the right cancel. Next look at the cosine
graph and the integral
 π/2
−π/2 cos x dx. You see that the area from −π/2 to 0 is the
same as the area from 0 to π/2. We could then just as well ﬁnd the integral from
0 to π/2 and multiply it by 2. In general, if f(x) is even, the integral of f(x) from
−l to l is twice the integral from 0 to l. Then we have
(9.3)
 l
−l
f(x) dx =



0
if f(x) is odd,
2
 l
0
f(x) dx
if f(x) is even.
Suppose now that we are given a function on the interval (0, l). If we want to
represent it by a Fourier series of period 2l, we must have f(x) deﬁned on (−l, 0)
too. There are several things we could do. We could deﬁne it to be zero (or, indeed,
anything else) on (−l, 0) and go ahead as we have done previously to ﬁnd either an
exponential or a sine-cosine series of period 2l. However, it often happens in prac-
tice that we need (for physical reasons—see Chapter 13) to have an even function
(or, in a diﬀerent problem, an odd function). We ﬁrst sketch the given function on
(0, l) (heavy lines in Figures 9.3 and 9.4). Then we extend the function on (−l, 0)
to be even or to be odd as required. To sketch more periods, just repeat the (−l, l)
sketch. (If the graph is complicated, it is helpful to trace it with a ﬁnger of one
Figure 9.3

366
Fourier Series and Transforms
Chapter 7
hand while you use the other hand to copy exactly what you are tracing. Turn the
paper upside down to avoid crossing hands.)
Figure 9.4
For even or odd functions, the coeﬃcient formulas for an and bn simplify. First
suppose f(x) is odd. Since sines are odd and cosines are even, f(x) sin(nπx/l) is
even and f(x) cos(nπx/l) is odd. Then an is the integral, over a symmetric interval
(−l, l), of an odd function, namely f(x) cos(nπx/l); an is therefore zero. But bn is
the integral of an even function over a symmetric interval and is therefore twice the
0 to l integral. We have:
(9.4)
If f(x) is odd,



bn = 2
l
 l
0
f(x) sin nπx
l
dx,
an = 0.
We say that we have expanded f(x) in a sine series (an = 0 so there are no cosine
terms). Similarly, if f(x) is even, all the bn’s are zero, and the an’s are integrals of
even functions. We have:
(9.5)
If f(x) is even,



an = 2
l
 l
0
f(x) cos nπx
l
dx,
bn = 0.
We say that f(x) is expanded in a cosine series. (Remember that the constant term
is a0/2.)
You have now learned to ﬁnd several diﬀerent kinds of Fourier series that rep-
resent a given function f(x) on, let us say, the interval (0, 1). How do you know
which to use in a given problem? You have to decide this from the physical problem
when you are using Fourier series. There are two things to check: (1) the basic pe-
riod involved in the physical problem; the functions in your series should have this
period; and (2) the physical problem may require either an even function or an odd
function for its solution; in these cases you must ﬁnd the appropriate series. Now
consider f(x) deﬁned on (0, 1). We could ﬁnd for it a sine-cosine or an exponential
series of period 1 (that is, l = 1
2):
f(x) =
∞

−∞
cne2inπx
where
cn =
 1
0
f(x)e−2inπx dx.

Section 9
Even and Odd Functions
367
(The choice between sine-cosine and exponential series is just one of convenience in
evaluating the coeﬃcients—the series are really identical.) But we could also ﬁnd
two other Fourier series representing the same f(x) on (0, 1). These series would
have period 2 (that is, l = 1). One would be a cosine series
f(x) =
∞

n=0
an cos nπx,
an = 2
 1
0
f(x) cos nπx dx,
bn = 0,
and represent an even function; the other would be a sine series and represent an
odd function. In the problems, you may just be told to expand a function in a
cosine series, say. You must then see for yourself what the period is when you have
sketched an even function, and so choose the proper l in cos(nπx/l) and in the
formula for an.
Example.
Represent f(x) =

1,
0 < x < 1
2,
0,
1
2 < x < 1,
by (a) a Fourier sine series, (b) a Fourier cosine series, (c) a Fourier series (the last
ordinarily means a sine-cosine or exponential series whose period is the interval over
which the function is given; in this case the period is 1).
Figure 9.5
(a) Sketch the given function between 0 and 1. Extend it to the interval (−1, 0)
making it odd. The period is now 2, that is, l = 1. Continue the function with
period 2 (Figure 9.5). Since we now have an odd function, an = 0 and
bn = 2
1
 1
0
f(x) sin nπx dx = 2
 1/2
0
sin nπx dx
= −2
nπ cos nπx
				
1/2
0
= −2
nπ

cos nπ
2 −1

,
b1 = 2
π ,
b2 = 4
2π ,
b3 = 2
3π,
b4 = 0,
· · · .
Thus we obtain the Fourier sine series for f(x):
f(x) = 2
π

sin πx + 2 sin 2πx
2
+ sin 3πx
3
+ sin 5πx
5
+ 2 sin 6πx
6
+ · · ·

.

368
Fourier Series and Transforms
Chapter 7
Figure 9.6
(b) Sketch an even function of period 2 (Figure 9.6).
Here l = 1, bn = 0, and
a0 = 2
 1
0
f(x) dx = 2
 1/2
0
dx = 1,
an = 2
 1
0
f(x) cos nπx dx =
2
nπ sin nπx
				
1/2
0
= 2
nπ sin nπ
2 .
Then the Fourier cosine series for f(x) is
f(x) = 1
2 + 2
π
cos πx
1
−cos 3πx
3
+ cos 5πx
5
−· · ·

.
Figure 9.7
(c) Sketch the given function on (0, 1) and continue it with period 1 (Figure 9.7).
Here 2l = 1, and we ﬁnd cn as we did in the example of Section 8. As in that
example, the exponential series here can then be put in sine-cosine form.
cn =
 1
0
f(x)e−2inπx dx =
 1/2
0
e−2inπx dx
= 1 −e−inπ
2inπ
= 1 −(−1)n
2inπ
=



1
inπ ,
n odd,
0,
n even ̸= 0.
c0 =
 1/2
0
dx = 1
2.
f(x) = 1
2 + 1
iπ (e2iπx −e−2iπx + 1
3e6πix −1
3e−6πix + · · · )
= 1
2 + 2
π

sin 2πx + sin 6πx
3
+ · · ·

.

Section 9
Even and Odd Functions
369
Alternatively we can ﬁnd both an and bn directly.
a0 = 2
 1
0
f(x) dx = 2
 1/2
0
dx = 1.
an = 2
 1/2
0
cos 2nπx dx = 0.
bn = 2
 1/2
0
sin 2nπx dx = 1
nπ (1 −cos nπ) = 1
nπ [1 −(−1)n].
b1 = 2
π ,
b2 = 0,
b3 = 2
3π ,
b4 = 0,
· · · .
There is one other very useful point to notice about even and odd functions. If
you are given a function on (−l, l) to expand in a sine-cosine series (of period 2l)
and happen to notice that it is an even function, you should realize that the bn’s
are all going to be zero and you do not have to work them out. Also the an’s can
be written as twice an integral from 0 to l just as in (9.5). Similarly, if the given
function is odd, you can use (9.4). Recognizing this may save you a good deal of
algebra.
Diﬀerentiating Fourier Series
Now that we have a supply of Fourier series for
reference, let’s discuss the question of diﬀerentiating a Fourier series term by term.
First consider a Fourier series in which an and bn are proportional to 1/n. Since
the derivative of 1
n sin nx is cos nx (and a similar result for the cosine terms), we see
that the diﬀerentiated series has no 1/n factors to make it converge. Now you might
suspect (correctly) that if you can’t diﬀerentiate the Fourier series, then the function
f(x) which it represents can’t be diﬀerentiated either, at least not at all points.
Turn back to examples and problems for which the Fourier series have coeﬃcients
proportional to 1/n and look at the graphs (or sketch them). Note in every case
that f(x) is discontinuous (that is, has jumps) at some points, and so can’t be
diﬀerentiated there. Next consider Fourier series with an and bn proportional to
1/n2. If we diﬀerentiate such a series once, there are still 1/n factors left but we can’t
diﬀerentiate it twice. In that case we would (correctly) expect the function to be
continuous with a discontinuous ﬁrst derivative. (Look for examples.) Continuing,
if an and bn are proportional to 1/n3, we can ﬁnd two derivatives, but the second
derivative is discontinuous, and so on for Fourier coeﬃcients proportional to higher
powers of 1/n. (See Problems 26 and 27.)
It is interesting to plot (by computer) a given function together with enough
terms of its Fourier series to give a reasonable ﬁt. In Section 5 we did this for
discontinuous functions and it took many terms of the series. You will ﬁnd (see
Problems 26 and 27) that the more continuous derivatives a function has, the fewer
terms of its Fourier series are required to approximate it. We can understand this:
The higher order terms oscillate more rapidly (compare sin x, sin 2x, sin 10x), and
this rapid oscillation is what is needed to ﬁt a curve which is changing rapidly
(for example, a jump). But if f(x) has several continuous derivatives, then it is
quite “smooth” and doesn’t require so much of the rapid oscillation of the higher
order terms. This is reﬂected in the dependence of the Fourier coeﬃcients on a
power of 1/n.

370
Fourier Series and Transforms
Chapter 7
PROBLEMS, SECTION 9
The functions in Problems 1 to 3 are neither even nor odd. Write each of them as the sum
of an even function and an odd function.
1.
(a) einx
(b) xex
2.
(a) ln |1 −x|
(b) (1 + x)(sin x + cos x)
3.
(a) x5 −x4 + x3 −1
(b) 1 + ex
4.
Using what you know about even and odd functions, prove the ﬁrst part of (5.2).
Each of the functions in Problems 5 to 12 is given over one period. For each function,
sketch several periods and decide whether it is even or odd. Then use (9.4) or (9.5) to
expand it in an appropriate Fourier series.
5.
f(x) =
(
−1,
−π < x < 0,
1,
0 < x < π.
6.
f(x) =
(
−1,
−l < x < 0,
1,
0 < x < l.
Answer: f(x) = 4
π
„
sin πx
l
+ 1
3 sin 3πx
l
+ 1
5 sin 5πx
l
+ · · ·
«
.
7.
f(x) =
(
1,
−1 < x < 1,
0,
−2 < x < −1 and 1 < x < 2.
8.
f(x) = x,
−π
2 < x < π
2 .
9.
f(x) = x2,
−1
2 < x < 1
2.
Answer: f(x) = 1
12 −1
π2
„
cos 2πx −1
22 cos 4πx + 1
32 cos 6πx −· · ·
«
.
10.
f(x) = |x|,
−π
2 < x < π
2 .
11.
f(x) = cosh x,
−π < x < π.
Answer: f(x) = 2 sinh π
π
„1
2 −1
2 cos x + 1
5 cos 2x −1
10 cos 3x + 1
17 cos 4x −· · ·
«
.
12.
f(x) =
(
x + 1,
−1 < x < 0,
x −1,
0 < x < 1.
13.
Give algebraic proofs of (9.3).
Hint: Write
R l
−l =
R 0
−l +
R l
0, make the change of
variable x = −t in
R 0
−l, and use the deﬁnition of even or odd function.
14.
Give algebraic proofs that for even and odd functions:
(a)
even times even = even; odd times odd = even; even times odd = odd;
(b)
the derivative of an even function is odd; the derivative of an odd function is
even.
15.
Given f(x) = x for 0 < x < 1, sketch the even function fc of period 2 and the odd
function fs of period 2, each of which equals f(x) on 0 < x < 1. Expand fc in a
cosine series and fs in a sine series.
Answer: fc(x) = 1
2 −4
π2
„
cos πx + 1
32 cos 3πx + · · ·
«
,
fs(x) = 2
π
„
sin πx −1
2 sin 2πx + 1
3 sin 3πx −· · ·
«
.

Section 10
Even and Odd Functions
371
16.
Let f(x) = sin2 x, 0 < x < π. Sketch (or computer plot) the even function fc of
period 2π, the odd function fs of period 2π, and the function fp of period π, each of
which is equal to f(x) on (0, π). Expand each of these functions in an appropriate
Fourier series.
In Problems 17 to 22 you are given f(x) on an interval, say 0 < x < b. Sketch several
periods of the even function fc of period 2b, the odd function fs of period 2b, and the
function fp of period b, each of which equals f(x) on 0 < x < b. Expand each of the three
functions in an appropriate Fourier series.
17.
f(x) =
(
1,
0 < x < 1
2,
−1,
1
2 < x < 1.
18.
f(x) =
(
1,
0 < x < 1,
0,
1 < x < 3.
19.
f(x) = | cos x|,
0 < x < π.
20.
f(x) = x2,
0 < x < 1.
21.
f(x) =
(
x,
0 < x < 1,
2 −x,
1 < x < 2.
22.
f(x) =
(
10,
0 < x < 10,
20,
10 < x < 20.
23.
If a violin string is plucked (pulled aside and let
go), it is possible to ﬁnd a formula f(x, t) for
the displacement at time t of any point x of the
vibrating string from its equilibrium position. It
turns out that in solving this problem we need
to expand the function f(x, 0), whose graph is the initial shape of the string, in a
Fourier sine series. Find this series if a string of length l is pulled aside a small
distance h at its center, as shown.
24.
If, in Problem 23, the string is stopped at the
center and half of it is plucked, then the func-
tion to be expanded in a sine series is shown
here. Find the series.
Caution:
Note that
f(x, 0) = 0 for l/2 < x < l.
25.
Suppose that f(x) and its derivative f ′(x) are both expanded in Fourier series on
(−π, π). Call the coeﬃcients in the f(x) series an and bn and the coeﬃcients in the
f ′(x) series a′
n and b′
n. Write the integral for an [equation (5.9)] and integrate it
by parts to get an integral of f ′(x) sin nx. Recognize this integral in terms of b′
n
[equation (5.10) for f ′(x)] and so show that b′
n = −nan. (In the integration by
parts, the integrated term is zero because f(π) = f(−π) since f is continuous—
sketch several periods.). Find a similar relation for a′
n and bn. Now show that this
is the result you get by diﬀerentiating the f(x) series term by term. Thus you have
shown that the Fourier series for f ′(x) is correctly given by diﬀerentiating the f(x)
series term by term (assuming that f ′(x) is expandable in a Fourier series).
In Problems 26 and 27, ﬁnd the indicated Fourier series. Then diﬀerentiate your result
repeatedly (both the function and the series) until you get a discontinuous function. Use a
computer to plot f(x) and the derivative functions. For each graph, plot on the same axes
one or more terms of the corresponding Fourier series. Note the number of terms needed
for a good ﬁt (see comment at the end of the section).
26.
f(x) =
(
3x2 + 2x3,
−1 < x < 0,
3x2 −2x3,
0 < x < 1.
27.
f(x) = (x2 −π2)2,
−π < x < π.

372
Fourier Series and Transforms
Chapter 7
10. AN APPLICATION TO SOUND
We have said that when a sound wave passes through the air and we hear it, the
air pressure where we are varies with time. Suppose the excess pressure above (and
below) atmospheric pressure in a sound wave is given by the graph in Figure 10.1.
(We shall not be concerned here with the units of p; however, reasonable units in
Figure 10.1 would be p in 10−6 atmospheres.) Let us ask what frequencies we hear
when we listen to this sound. To ﬁnd out, we expand p(t) in a Fourier series. The
period of p(t) is
1
262; that is, the sound wave repeats itself 262 times per second.
We have called the period 2l in our formulas, so here l =
1
524. The functions we
have called sin(nπx/l) here become sin 524nπt. We can save some work by observing
Figure 10.1
that p(t) is an odd function; there are then only sine terms in its Fourier series and
we need to compute only bn. Using (9.4), we have
bn = 2(524)
 1/524
0
p(t) sin 524nπt dt
(10.1)
= 1048
 1/1048
0
sin 524nπt dt −7
8(1048)
 1/524
1/1048
sin 524nπt dt
= 1048

−
cos nπ
2 −1
524nπ
+ 7
8
cos nπ −cos nπ
2
524nπ


= 2
nπ

−15
8 cos nπ
2 + 1 + 7
8 cos nπ

.
From this we can compute the values of bn for the ﬁrst few values of n:
(10.2)
b1 = 2
π

1 −7
8

= 2
π
1
8

= 1
π · 1
4
b5 = 1
5π · 1
4
b2 = 2
2π
15
8 + 1 + 7
8

= 1
2π
15
2

b6 = 1
6π
15
2

b3 = 2
3π

1 −7
8

= 1
3π · 1
4
b7 = 1
7π · 1
4
b4 = 2
4π

−15
8 + 1 + 7
8

= 0
b8 = 0,
etc.

Section 10
An Application to Sound
373
Then we have
p(t) = 1
4π
sin 524πt
1
+ 30 sin(524 · 2πt)
2
+ sin(524 · 3πt)
3
(10.3)
+ sin(524 · 5πt)
5
+ 30 sin(524 · 6πt)
6
+ sin(524 · 7πt)
7
+ · · ·

.
We can see just by looking at the coeﬃcients that the most important term
is the second one. The ﬁrst term corresponds to the fundamental with frequency
262 vibrations per second (this is approximately middle C on a piano). But it is
much weaker in this case than the ﬁrst overtone (second harmonic) corresponding to
the second term; this tone has frequency 524 vibrations per second (approximately
high C). (You might like to use a computer to play one or several terms of the
series.) The sixth harmonic (corresponding to n = 6) and also the harmonics for
n = 10, 14, 18, 22, and 26 are all more prominent (that is, have larger coeﬃcients)
than the fundamental. We can be even more speciﬁc about the relative importance
of the various frequencies. Recall that in discussing a simple harmonic oscillator,
we showed that its average energy was proportional to the square of its velocity
amplitude. It can be proved that the intensity of a sound wave (average energy
striking unit area of your ear per second) is proportional to the average of the
square of the excess pressure. Thus for a sinusoidal pressure variation A sin 2πft,
the intensity is proportional to A2. In the Fourier series for p(t), the intensities of the
various harmonics are then proportional to the squares of the corresponding Fourier
coeﬃcients. (The intensity corresponds roughly to the loudness of the tone—not
exactly because the ear is not uniformly sensitive to all frequencies.) The relative
intensities of the harmonics in our example are then:
n
=
1
2
3
4
5
6
7
8
9
10
· · ·
Relative intensity
=
1
225
1
9
0
1
25
25
1
49
0
1
81
9
· · ·
From this we see even more clearly that we would hear principally the second
harmonic with frequency 524 (high C).
PROBLEMS, SECTION 10
In Problems 1 to 3, the graphs sketched represent one period of the excess pressure p(t) in
a sound wave. Find the important harmonics and their relative intensities. Use a computer
to play individual terms or a sum of several terms of the series.
1.
2.

374
Fourier Series and Transforms
Chapter 7
3.
In Problems 4 to 10, the sketches show several practical examples of electrical signals
(voltages or currents). In each case we want to know the harmonic content of the signal,
that is, what frequencies it contains and in what proportions. To ﬁnd this, expand each
function in an appropriate Fourier series. Assume in each case that the part of the graph
shown is repeated sixty times per second.
4.
Output of a simple d-c generator; the shape of
the curve is the absolute value of a sine func-
tion. Let the maximum voltage be 100 v.
5.
Rectiﬁed half-wave; the curve is a sine function
for half the cycle and zero for the other half.
Let the maximum current be 5 amp. Hint: Be
careful! The value of l here is 1/60, but I(t) =
sin t only from t = 0 to t = 1/120.
6.
Triangular wave; the graph consists of two
straight lines whose equations you must write!
The maximum voltage of 100 v occurs at the
middle of the cycle.
7.
Sawtooth
8.
Rectiﬁed sawtooth
9.
Square wave
10.
Periodic ramp function

Section 11
Parseval’s Theorem
375
11. PARSEVAL’S THEOREM
We shall now ﬁnd a relation between the average of the square (or absolute square) of
f(x) and the coeﬃcients in the Fourier series for f(x), assuming that
 π
−π |f(x)|2 dx
is ﬁnite. The result is known as Parseval’s theorem or the completeness relation.
You should understand that the point of the theorem is not to get the average of
the square of a given f(x) by using its Fourier series. [Given f(x), it is easy to get
its average square just by doing the integration in (11.2) below.] The point of the
theorem is to show the relation between the average of the square of f(x) and the
Fourier coeﬃcients. We can derive a form of Parseval’s theorem from any of the
various Fourier expansions we have made; let us use (5.1).
(11.1)
f(x) = 1
2a0 +
∞

1
an cos nx +
∞

1
bn sin nx.
We square f(x) and then average the square over (−π, π):
(11.2)
The average of [f(x)]2 is 1
2π
 π
−π
[f(x)]2dx.
When we square the Fourier series in (11.1) we get many terms. To avoid writing
out a large number of them, consider instead what types of terms there are and
what the averages of the diﬀerent kinds of terms are. First, there are the squares
of the individual terms. Using the fact that the average of the square of a sine or
cosine over a period is 1
2, we have:
(11.3)
The average of ( 1
2a0)2
is
( 1
2a0)2.
The average of (an cos nx)2
is
a2
n · 1
2.
The average of (bn sin nx)2
is
b2
n · 1
2.
Then there are cross-product terms of the forms 2 · 1
2a0an cos nx, 2 · 1
2a0bn sin nx,
and 2anbm cos nx sin mx with m ̸= n (we write n in the cosine factor and m in the
sine factor since every sine term must be multiplied times every cosine term). By
(5.2), the average values of terms of all these types are zero. Then we have
(11.4)
The average of [f(x)]2 (over a period) =
1
2a0
2
+ 1
2
∞

1
a2
n + 1
2
∞

1
b2
n.
This is one form of Parseval’s theorem. You can easily verify (Problem 1) that the
theorem is unchanged if f(x) has period 2l instead of 2π and its square is averaged
over any period of length 2l. You can also verify (Problem 3) that if f(x) is written
as a complex exponential Fourier series, and if in addition we include the possibility
that f(x) itself may be complex, then we ﬁnd:
(11.5)
The average of |f(x)|2 (over a period) =
∞

−∞
|cn|2.
Parseval’s theorem is also called the completeness relation. In the problem of
representing a given sound wave as a sum of harmonics, suppose we had left one of
the harmonics out of the series. It seems plausible physically, and it can be proved

376
Fourier Series and Transforms
Chapter 7
mathematically, that with one or more harmonics left out, we would not be able to
represent sound waves containing the omitted harmonics. We say that the set of
functions sin nx, cos nx is a complete set of functions on any interval of length 2π;
that is, any function (satisfying Dirichlet conditions) can be expanded in a Fourier
series whose terms are constants times sin nx and cos nx. If we left out some values
of n, we would have an incomplete set of basis functions (see basis, page 357) and
could not use it to expand some given functions. For example, suppose that you
made a mistake in ﬁnding the period (that is, the value of l) of your given function
and tried to use the set of functions sin 2nx, cos 2nx in expanding a given function
of period 2π. You would get a wrong answer because you used an incomplete set
of basis functions (with the sin x, cos x, sin 3x, cos 3x, · · · , terms missing). If your
Fourier series is wrong because the set of basis functions you use is incomplete, then
the results you get from Parseval’s theorem (11.4) or (11.5) will be wrong too. In
fact, if we use an incomplete basis set in, say, (11.5), then there are missing (non-
negative) terms on the right-hand side, so the equation becomes the inequality:
Average of |f(x)|2 ≥∞
−∞|cn|2. This is known as Bessel’s inequality. Conversely,
if (11.4) and (11.5) are correct for all f(x), then the set of basis functions used
is a complete set. This is why Parseval’s theorem is often called the completeness
relation. (Also see page 377 and Chapter 12, Section 6.)
Let us look at some examples of the physical meaning and the use of Parseval’s
theorem.
Example 1.
In Section 10 we said that the intensity (energy per square centimeter per
second) of a sound wave is proportional to the average value of the square of the
excess pressure. If for simplicity we write (10.3) with letters instead of numerical
values, we have
(11.6)
p(t) =
∞

1
bn sin 2πnft.
For this case, Parseval’s theorem (11.4) says that:
(11.7)
The average of [p(t)]2 =
∞

1
b2
n · 1
2 =
∞

1
the average of b2
n sin2 2nπft .
Now the intensity or energy (per square centimeter per second) of the sound wave
is proportional to the average of [p(t)]2, and the energy associated with the nth
harmonic is proportional to the average of b2
n sin2 2nπft. Thus Parseval’s theorem
says that the total energy of the sound wave is equal to the sum of the energies
associated with the various harmonics.
Example 2.
Let us use Parseval’s theorem to ﬁnd the sum of an inﬁnite series. From
Problem 8.15(a) written in complex exponential form we get:
The function f(x) of period 2 which is equal to x on (−1, 1)
= −i
π (eiπx −e−iπx −1
2e2iπx + 1
2e−2iπx + 1
3e3iπx −1
3e−3iπx + · · · ).

Section 11
Parseval’s Theorem
377
Let us ﬁnd the average of [f(x)]2 on (−1, 1).
The average of [f(x)]2 = 1
2
 1
−1
x2 dx = 1
2
x3
3
				
1
−1

= 1
3.
By Parseval’s theorem (11.5), this is equal to ∞
−∞|cn|2, so we have
1
3 =
∞

−∞
|cn|2 = 1
π2 (1 + 1 + 1
4 + 1
4 + 1
9 + 1
9 + · · · = 2
π2
∞

1
1
n2 .
Then we get the sum of the series
1 + 1
4 + 1
9 + · · · =
∞

1
1
n2 = π2
2 · 1
3 = π2
6 .
We have seen that a function given on (0, l) can be expanded in a sine series by
deﬁning it on (−l, 0) to make it odd, or in a cosine series by deﬁning it on (−l, 0)
to make it even. Here is another useful example of deﬁning a function to suit our
purposes. (We will need this in Chapter 13.) Suppose we want to expand a function
deﬁned on (0, l) in terms of the basis functions sin(n + 1
2) πx
l
= sin (2n+1)πx
2l
. Can
we do it, that is, do these functions make up a complete set for this problem? Note
that our proposed basis functions have period 4l, say (−2l, 2l) (observe the 2l in
the denominator where you are used to l). So given f(x) on (0, l), we can deﬁne it
as we like on (l, 2l) and on (−2l, 0). We know (by the Dirichlet theorem) that the
functions sin nπx
2l
and cos nπx
2l , all n, make up a complete set on (−2l, 2l). We need
to see how, on (0, l) we can use just the sines (that’s easy—make the function odd)
and only the odd values of n. It turns out (see Problem 11) that if we deﬁne f(x)
on (l, 2l) to make it symmetric around x = l, then all the bn’s for even n are equal
to zero. So our desired basis set is indeed a complete set on (0, l). Similarly we can
show (Problem 11) that the functions cos (2n+1)πx
2l
make up a complete set on (0, l).
PROBLEMS, SECTION 11
1.
Prove (11.4) for a function of period 2l expanded in a sine-cosine series.
2.
Prove that if f(x) = P∞
−∞cneinx, then the average value of [f(x)]2 is P∞
−∞cnc−n.
Show by Problem 7.12 that for real f(x) this becomes (11.5).
3.
If f(x) is complex, we usually want the average of the square of the absolute value
of f(x). Recall that |f(x)|2 = f(x) · ¯f(x), where ¯f(x) means the complex conjugate
of f(x). Show that if a complex f(x) = P∞
−∞cneinπx/l, then (11.5) holds.
4.
When a current I ﬂows through a resistance R, the heat energy dissipated per second
is the average value of RI2. Let a periodic (not sinusoidal) current I(t) be expanded
in a Fourier series I(t) = P∞
−∞cne120inπt. Give a physical meaning to Parseval’s
theorem for this problem.
Use Parseval’s theorem and the results of the indicated problems to ﬁnd the sum of the
series in Problems 5 to 9.
5.
The series 1 + 1
32 + 1
52 + · · ·, using Problem 9.6.
6.
The series
∞
X
n=1
1
n4 , using Problem 9.9.

378
Fourier Series and Transforms
Chapter 7
7.
The series
∞
X
n=1
1
n2 , using Problem 5.8.
8.
The series
X
odd n
1
n4 , using Problem 9.10.
9.
The series 1
32 +
1
152 +
1
352 + · · ·, using Problem 5.11.
10.
A general form of Parseval’s theorem says that if two functions are expanded in
Fourier series
f(x) = 1
2a0 +
∞
X
1
an cos nx +
∞
X
1
bn sin nx,
g(x) = 1
2a′
0 +
∞
X
1
a′
n cos nx +
∞
X
1
b′
n sin nx,
then the average value of f(x)g(x) is 1
4a0a′
0 + 1
2
P∞
1 ana′
n + 1
2
P∞
1 bnb′
n. Prove this.
11.
(a)
Let f(x) on (0, 2l) satisfy f(2l −x) = f(x), that is, f(x) is symmetric about
x = l. If you expand f(x) on (0, 2l) in a sine series P bn sin nπx
2l , show that
for even n, bn = 0. Hint: Note that the period of the sines is 4l. Sketch an
f(x) which is symmetric about x = l, and on the same axes sketch a few sines
to see that the even ones are antisymmetric about x = l. Alternatively, write
the integral for bn as an integral from 0 to l plus an integral from l to 2l, and
replace x by 2l −x in the second integral.
(b)
Similarly, show that if we deﬁne f(2l−x) = −f(x), the cosine series has an = 0
for even n.
12. FOURIER TRANSFORMS
We have been expanding periodic functions in series of sines, cosines, and complex
exponentials.
Physically, we could think of the terms of these Fourier series as
representing a set of harmonics. In music these would be an inﬁnite set of frequen-
cies nf, n = 1, 2, 3, · · · ; notice that this set, although inﬁnite, does not by any
means include all possible frequencies. In electricity, a Fourier series could repre-
sent a periodic voltage; again we could think of this as made up of an inﬁnite but
discrete (that is, not continuous) set of a-c voltages of frequencies nω. Similarly,
in discussing light, a Fourier series could represent light consisting of a discrete set
of wavelengths λ/n, n = 1, 2, · · · , that is, a discrete set of colors. Two related
questions might occur to us here. First, is it possible to represent a function which
is not periodic by something analogous to a Fourier series? Second, can we some-
how extend or modify Fourier series to cover the case of a continuous spectrum of
wavelengths of light, or a sound wave containing a continuous set of frequencies?
If you recall that an integral is a limit of a sum, it may not surprise you very
much to learn that the Fourier series (that is, a sum of terms) is replaced by a
Fourier integral in the above cases. The Fourier integral can be used to represent
nonperiodic functions, for example a single voltage pulse not repeated, or a ﬂash
of light, or a sound which is not repeated. The Fourier integral also represents
a continuous set (spectrum) of frequencies, for example a whole range of musical
tones or colors of light rather than a discrete set.

Section 12
Fourier Transforms
379
Recall from equations (8.2) and (8.3), these complex Fourier series formulas:
f(x) =
∞

−∞
cneinπx/l,
cn = 1
2l
 l
−l
f(x)e−inπx/l dx.
(12.1)
The period of f(x) is 2l and the frequencies of the terms in the series are n/(2l).
We now want to consider the case of continuous frequencies.
Deﬁnition of Fourier Transforms
We state without proof (see plausibility ar-
guments below) the formulas corresponding to (12.1) for a continuous range of
frequencies.
f(x) =
 ∞
−∞
g(α)eiαx dα,
g(α) = 1
2π
 ∞
−∞
f(x)e−iαx dx.
(12.2)
Compare (12.2) and (12.1); g(α) corresponds to cn, α corresponds to n, and
 ∞
−∞
corresponds to ∞
−∞. This agrees with our discussion of the physical meaning and
use of Fourier integrals. The quantity α is a continuous analog of the integral-valued
variable n, and so the set of coeﬃcients cn has become a function g(α); the sum
over n has become an integral over α. The two functions f(x) and g(α) are called
a pair of Fourier transforms. Usually, g(α) is called the Fourier transform of f(x),
and f(x) is called the inverse Fourier transform of g(α), but since the two integrals
diﬀer in form only in the sign in the exponent, it is rather common simply to call
either a Fourier transform of the other. You should check the notation of any book
or computer program you are using. Another point on which various references
diﬀer is the position of the factor 1/(2π) in (12.2); it is possible to have it multiply
the f(x) integral instead of the g(α) integral, or to have the factor 1/
√
2π multiply
each of the integrals.
The Fourier integral theorem says that, if a function f(x) satisﬁes the Dirichlet
conditions (Section 6) on every ﬁnite interval, and if
 ∞
−∞|f(x)| dx is ﬁnite, then
(12.2) is correct. That is, if g(α) is computed and substituted into the integral
for f(x) [compare the procedure of computing the cn’s for a Fourier series and
substituting them into the series for f(x)], then the integral gives the value of f(x)
anywhere that f(x) is continuous; at jumps of f(x), the integral gives the midpoint
of the jump (again compare Fourier series, Section 6). The following discussion
is not a mathematical proof of this theorem but is intended to help you see more
clearly how Fourier integrals are related to Fourier series.

380
Fourier Series and Transforms
Chapter 7
It might seem reasonable to think of trying to represent a function which is
not periodic by letting the period (−l, l) increase to (−∞, ∞). Let us try to do
this, starting with (12.1). If we call nπ/l = αn and αn+1 −αn = π/l = ∆α, then
1/(2l) = ∆α/(2π) and (12.1) can be rewritten as
f(x) =
∞

−∞
cneαnx,
(12.3)
cn = 1
2l
 l
−l
f(x)e−iαnx dx = ∆α
2π
 l
−l
f(u)e−iαnu du.
(12.4)
(We have changed the dummy integration variable in cn from x to u to avoid later
confusion.) Substituting (12.4) into (12.3), we have
(12.5)
f(x) =
∞

−∞

∆α
2π
 l
−l
f(u)e−iαnu du

eiαnx
=
∞

−∞
∆α
2π
 l
−l
f(u)eiαn(x−u) du = 1
2π
∞

−∞
F(αn) ∆α,
where
(12.6)
F(αn) =
 l
−l
f(u)eiαn(x−u) du.
Now ∞
−∞F(αn)∆α looks rather like the formula in calculus for the sum whose
limit, as ∆α tends to zero, is an integral. If we let l tend to inﬁnity [that is, let the
period of f(x) tend to inﬁnity], then ∆α = π/l →0, and the sum ∞
−∞F(αn)∆α
goes over formally to
 ∞
−∞F(α)dα; we have dropped the subscript n on α now that
it is a continuous variable. We also let l tend to inﬁnity and αn = α in (12.6) to get
(12.7)
F(α) =
 ∞
−∞
f(u)eiα(x−u) du.
Replacing ∞
−∞F(αn)∆α in (12.5) by  ∞
−∞F(α) dα and substituting from (12.7)
for F(α) gives
(12.8)
f(x) = 1
2π
 ∞
−∞
F(α) dα = 1
2π
 ∞
−∞
 ∞
−∞
f(u)eiα(x−u) du dα
= 1
2π
 ∞
−∞
eiαx dα
 ∞
−∞
f(u)e−iαu du.
If we deﬁne g(α) by
(12.9)
g(α) = 1
2π
 ∞
−∞
f(x)e−iαx dx = 1
2π
 ∞
−∞
f(u)e−iαu du,
then (12.8) gives
(12.10)
f(x) =
 ∞
−∞
g(α)eiαx dα.

Section 12
Fourier Transforms
381
These equations are the same as (12.2). Notice that the actual requirement for the
factor 1/(2π) is that the product of the constants multiplying the two integrals for
g(α) and f(x) should be 1/(2π); this accounts for the various notations we have
discussed before.
Just as we have sine series representing odd functions and cosine series rep-
resenting even functions (Section 9), so we have sine and cosine Fourier integrals
which represent odd or even functions respectively. Let us prove that if f(x) is
odd, then g(α) is odd too, and show that in this case (12.2) reduces to a pair of
sine transforms. The corresponding proof for even f(x) is similar (Problem 1). We
substitute
e−iαx = cos αx −i sin αx
into (12.9) to get
(12.11)
g(α) = 1
2π
 ∞
−∞
f(x)(cos αx −i sin αx) dx.
Since cos αx is even and we are assuming that f(x) is odd, the product f(x) cos αx
is odd. Recall that the integral of an odd function over a symmetric interval about
the origin (here, −∞to +∞) is zero, so the term
 ∞
−∞f(x) cos αx dx in (12.11) is
zero. The product f(x) sin αx is even (product of two odd functions); recall that
the integral of an even function over a symmetric interval is twice the integral over
positive x. Substituting these results into (12.11), we have
(12.12)
g(α) = 1
2π
 ∞
−∞
f(x)(−i sin αx) dx = −i
π
 ∞
0
f(x) sin αx dx.
From (12.12), we can see that replacing α by −α changes the sign of sin αx and so
changes the sign of g(α). That is, g(−α) = −g(α), so g(α) is an odd function as
we claimed. Then expanding the exponential in (12.10) and arguing as we did to
obtain (12.12), we ﬁnd
(12.13)
f(x) =
 ∞
−∞
g(α)eiαx dx = 2i
 ∞
0
g(α) sin αx dα.
If we substitute g(α) from (12.12) into (12.13) to obtain an equation like (12.8), the
numerical factor is (−i/π)(2i) = 2/π; thus the imaginary factors are not needed.
The factor 2/π may multiply either of the two integrals or each integral may be
multiplied by

2/π. Let us make the latter choice in giving the following deﬁnition.
Fourier Sine Transforms
We deﬁne fs(x) and gs(α), a pair of Fourier sine
transforms representing odd functions, by the equations
fs(x) =

2
π
 ∞
0
gs(α) sin αx dα,
gs(x) =

2
π
 ∞
0
fs(x) sin αx dx.
(12.14)
We discuss even functions in a similar way (Problem 1).

382
Fourier Series and Transforms
Chapter 7
Fourier Cosine Transforms
We deﬁne fc(x) and gc(α), a pair of Fourier
cosine transforms representing even functions, by the equations
fc(x) =

2
π
 ∞
0
gc(x) cos αx dα,
gc(α) =

2
π
 ∞
0
fc(x) cos αx dx.
(12.15)
Example1.
Let us represent a nonperiodic function as a Fourier
integral. The function
f(x) =

1,
−1 < x < 1,
0,
|x| > 1,
Figure 12.1
shown in Figure 12.1 might represent an impulse in mechanics (that is, a force
applied only over a short time such as a bat hitting a baseball), or a sudden short
surge of current in electricity, or a short pulse of sound or light which is not repeated.
Since the given function is not periodic, it cannot be expanded in a Fourier series,
since a Fourier series always represents a periodic function. Instead, we write f(x)
as a Fourier integral as follows. Using (12.9), we calculate g(α); this process is like
ﬁnding the cn’s for a Fourier series. We ﬁnd
g(α) = 1
2π
 ∞
−∞
f(x)e−iαx dx = 1
2π
 1
−1
e−iαx dx
(12.16)
=
1
2π
e−iαx
−iα
				
1
−1
= 1
πα
e−iα −eiα
−2i
= sin α
πα .
We substitute g(α) from (12.16) into the formula (12.10) for f(x) (this is like sub-
stituting the evaluated coeﬃcients into a Fourier series). We get
f(x) =
 ∞
−∞
sin α
πα eiαx dx
(12.17)
= 1
π
 ∞
−∞
sin α(cos αx + i sin αx
α
dα = 2
π
 ∞
0
sin α cos αx
α
dα
since (sin α)/α is an even function.
We thus have an integral representing the
function f(x) shown in Figure 12.1.
Example 2.
We can use (12.17) to evaluate a deﬁnite integral. Using f(x) in Figure 12.1,
we ﬁnd
(12.18)
 ∞
0
sin α cos αx
α
dα = π
2 f(x) =

π
2
for |x| < 1,
π
4 for |x| = 1,
0
for |x| > 1.
Notice that we have used the fact that the Fourier integral represents the midpoint
of the jump in f(x) at |x| = 1. If we let x = 0, we get
(12.19)
 ∞
0
sin α
α
dα = π
2 .

Section 12
Fourier Transforms
383
We could have done this problem by observing that f(x) is an even function and so
can be represented by a cosine transform. The ﬁnal results (12.17) to (12.19) would
be just the same (Problem 2).
In Section 9, we sometimes started with a function deﬁned only for x > 0 and
extended it to be even or odd so that we could represent it by a cosine series or by
a sine series. Similarly, for Fourier transforms, we can represent a function deﬁned
for x > 0 by either a Fourier cosine integral (by deﬁning it for x < 0 so that it is
even), or by a Fourier sine integral (by deﬁning it for x < 0 so that it is odd). (See
Problem 2 and Problems 27 to 30.)
Parseval’s Theorem for Fourier Integrals
Recall (Section 11) that Parse-
val’s theorem for a Fourier series f(x) = ∞
−∞cneinπx/l relates
 l
−l |f|2 dx and
∞
−∞|cn|2. In physical applications (see Section 11), Parseval’s theorem says that
the total energy (say in a sound wave, or in an electrical signal) is equal to the sum
of the energies associated with the various harmonics. Remember that a Fourier
integral represents a continuous spectrum of frequencies and that g(α) corresponds
to cn. Then we might expect that ∞
−∞|cn|2 would be replaced by
 ∞
−∞|g(α)|2dα
(that is, a “sum” over a continuous rather than a discrete spectrum) and that Par-
seval’s theorem would relate
 ∞
−∞|f|2dx and
 ∞
−∞|g|2dα. Let us try to ﬁnd the
relation.
We will ﬁrst ﬁnd a generalized form of Parseval’s theorem involving two functions
f1(x), f2(x) and their Fourier transforms g1(α), g2(α). Let ¯g1(α) be the complex
conjugate of g1(α); from (12.1), we have
(12.20)
¯g1(α) = 1
2π
 ∞
−∞
¯f1(x)eiαxdx.
We now multiply (12.20) by g2(α) and integrate with respect to α:
(12.21)
 ∞
−∞
¯g1(α)g2(α) dα = 1
2π
 ∞
−∞
 ∞
−∞
¯f1(x)eiαx dx

g2(α)dα.
Let us rearrange (12.21) so that we integrate ﬁrst with respect to α.
[This is
justiﬁed assuming that the absolute values of the functions f1 and f2 are integrable
on (−∞, ∞).]
(12.22)
1
2π
 ∞
−∞
¯f1(x) dx
 ∞
−∞
g2(α)eiαx dα

= 1
2π
 ∞
−∞
¯f1(x)f2(x) dx
by (12.2). Thus
(12.23)
 ∞
−∞
¯g1(α)g2(α) dα = 1
2π
 ∞
−∞
¯f1(x)f2(x) dx.
(Compare this with the corresponding Fourier series theorem in Problem 11.10.) If
we set f1 = f2 = f and g1 = g2 = g, we get Parseval’s theorem:
(12.24)
 ∞
−∞
|g(α)|2 dα = 1
2π
 ∞
−∞
|f(x)|2 dx.

384
Fourier Series and Transforms
Chapter 7
PROBLEMS, SECTION 12
1.
Following a method similar to that used in obtaining equations (12.11) to (12.14),
show that if f(x) is even, then g(α) is even too. Show that in this case f(x) and
g(α) can be written as Fourier cosine transforms and obtain (12.15).
2.
Do Example 1 above by using a cosine transform (12.15). Obtain (12.17); for x > 0,
the 0 to ∞integral represents the function
f(x) =
(
1,
0 < x < 1,
0,
x > 1.
Represent this function also by a Fourier sine integral (see the paragraph just before
Parseval’s theorem).
In Problems 3 to 12, ﬁnd the exponential Fourier transform of the given f(x) and write
f(x) as a Fourier integral [that is, ﬁnd g(α) in equation (12.2) and substitute your result
into the ﬁrst integral in equation (12.2)].
3.
f(x) =
8
>
<
>
:
−1,
−π < x < 0
1,
0 < x < π
0,
|x| > π
4.
f(x) =
(
1,
π/2 < |x| < π
0,
otherwise
5.
f(x) =
(
1,
0 < x < 1
0,
otherwise
6.
f(x) =
(
x,
|x| < 1
0,
|x| > 1
7.
f(x) =
(
|x|,
|x| < 1
0,
|x| > 1
8.
f(x) =
(
x,
0 < x < 1
0,
otherwise
9.
10.
11.
f(x) =
(
cos x,
−π/2 < x < π/2
0,
|x| > π/2
Hint: In Problems 11 and 12, use complex exponentials.
12.
f(x) =
(
sin x,
|x| < π/2
0,
|x| > π/2
In Problems 13 to 16, ﬁnd the Fourier cosine transform of the function in the indicated
problem, and write f(x) as a Fourier integral [use equation (12.15)]. Verify that the cosine
integral for f(x) is the same as the exponential integral found previously.
13.
Problem 4.
14.
Problem 7.
15.
Problem 9.
16.
Problem 11.

Section 12
Fourier Transforms
385
In Problems 17 to 20, ﬁnd the Fourier sine transform of the function in the indicated
problem, and write f(x) as a Fourier integral [use equation (12.14)]. Verify that the sine
integral for f(x) is the same as the exponential integral found previously.
17.
Problem 3.
18.
Problem 6.
19.
Problem 10.
20.
Problem 12.
21.
Find the Fourier transform of f(x) = e−x2/(2σ2). Hint: Complete the square in the
x terms in the exponent and make the change of variable y = x + σ2iα. Use tables
or computer to evaluate the deﬁnite integral.
22.
The function j1(α) = (α cos α −sin α)/α is of interest in quantum mechanics. [It
is called a spherical Bessel function; see Chapter 12, equation (17.4).] Using Prob-
lem 18, show that
Z ∞
0
j1(α) sin αx dα =
(
πx/2,
−1 < x < 1,
0,
|x| > 1.
23.
Using Problem 17, show that
Z ∞
0
1 −cos πα
α
sin α dα = π
2 ,
Z ∞
0
1 −cos πα
α
sin πα dα = π
4 .
24.
(a)
Find the exponential Fourier transform of f(x) = e−|x| and write the inverse
transform. You should ﬁnd
Z ∞
0
cos αx
α2 + 1 dα = π
2 e−|x|.
(b)
Obtain the result in (a) by using the Fourier cosine transform equations (12.15).
(c)
Find the Fourier cosine transform of f(x) = 1/(1 + x2). Hint: Write your
result in (b) with x and α interchanged.
25.
(a)
Represent as an exponential Fourier transform the function
f(x) =
(
sin x,
0 < x < π,
0,
otherwise.
Hint: Write sin x in complex exponential form.
(b)
Show that your result can be written as
f(x) = 1
π
Z ∞
0
cos αx + cos α(x −π)
1 −α2
dα.
26.
Using Problem 15, show that
Z ∞
0
1 −cos α
α2
dα = π
2 .
Represent each of the following functions (a) by a Fourier cosine integral; (b) by a Fourier
sine integral. Hint: See the discussion just before Parseval’s theorem.
27.
f(x) =
(
1,
0 < x < π/2
0,
x > π/2
28.
f(x) =
(
1,
2 < x < 4
0,
0 < x < 2, x > 4

386
Fourier Series and Transforms
Chapter 7
29.
f(x) =
8
>
<
>
:
−1,
0 < x < 2
1,
2 < x < 3
0,
x > 3
30.
f(x) =
(
1 −x/2,
0 < x < 2
0,
x > 2
Verify Parseval’s theorem (12.24) for the special cases in Problems 31 to 33.
31.
f(x) as in Figure 12.1. Hint: Integrate by parts and use (12.18) to evaluate
Z ∞
−∞
|g(α)|2 dα.
32.
f(x) and g(α) as in Problem 21.
33.
f(x) and g(α) as in Problem 24a.
34.
Show that if (12.2) is written with the factor 1/
√
2π multiplying each integral, then
the corresponding form of Parseval’s theorem (12.24) is
Z ∞
−∞
|f(x)|2 dx =
Z ∞
−∞
|g(α)|2 dα.
35.
Starting with the symmetrized integrals as in Problem 34, make the substitutions
α = 2πp/h (where p is the new variable, h is a constant), f(x) = ψ(x), g(α) =
p
h/2π φ(p); show that then
ψ(x) =
1
√
h
Z ∞
−∞
φ(p)e2πipx/h dp,
φ(p) =
1
√
h
Z ∞
−∞
ψ(x)e−2πipx/h dx,
Z ∞
−∞
|ψ(x)|2 dx =
Z ∞
−∞
|φ(p)|2 dp.
This notation is often used in quantum mechanics.
36.
Normalize f(x) in Problem 21; that is ﬁnd the factor N so that
R ∞
−∞|Nf(x)|2 = 1.
Let ψ(x) = Nf(x), and ﬁnd φ(p) as given in Problem 35. Verify Parseval’s theorem,
that is, show that
R ∞
−∞|φ(p)|2 dp = 1.
13. MISCELLANEOUS PROBLEMS
1.
The displacement (from equilibrium) of a particle executing simple harmonic motion
may be either y = A sin ωt or y = A sin(ωt + φ) depending on our choice of time
origin. Show that the average of the kinetic energy of a particle of mass m (over
a period of the motion) is the same for the two formulas (as it must be since both
describe the same physical motion). Find the average value of the kinetic energy for
the sin(ωt + φ) case in two ways:
(a)
By selecting the integration limits (as you may by Problem 4.1) so that a
change of variable reduces the integral to the sin ωt case.
(b)
By expanding sin(ωt + φ) by the trigonometric addition formulas and using
(5.2) to write the average values.
2.
The symbol [x] means the greatest integer less than or equal to x (for example,
[3] = 3, [2.1] = 2, [−4.5] = −5). Expand x −[x] −1
2 in an exponential Fourier series
of period 1. Hint: Sketch the function.
Answer:
i
2π
„
· · · −e−4πix
2
−e−2πix
1
+ e2πix
1
+ e4πix
2
+ · · ·
«
.

Section 13
Miscellaneous Problems
387
3.
We have said that Fourier series can represent discontinuous functions although
power series cannot. It might occur to you to wonder why we could not substitute
the power series for sin nx and cos nx (which converge for all x) into a Fourier
series and collect terms to obtain a power series for a discontinuous function. As an
example of what happens if we try this, consider the series in Problem 9.5. Show that
the coeﬃcients of x, if collected, form a divergent series; similarly, the coeﬃcients
of x3 form a divergent series, and so on.
4.
The diagram shows a “relaxation” oscillator. The charge q on the capacitor builds up
until the neon tube ﬁres and discharges the capacitor (we assume instantaneously).
Then the cycle repeats itself over and over.
(a)
The charge q on the capacitor satisﬁes
the diﬀerential equation
Rdq
dt + q
c = V,
where R is the resistance, C is the ca-
pacitance, and V is the constant d-c
voltage, as shown in the diagram. Show that if q = 0 when t = 0, then at any
later time t (during one cycle, that is, before the neon tube ﬁres)
q = CV (1 −e−t/RC).
(b)
Suppose the neon tube ﬁres at t = 1
2RC. Sketch q as a function of t for several
cycles.
(c)
Expand the periodic q in part (b) in an appropriate Fourier series.
5.
Consider one arch of f(x) = sin x. Show that the average value of f(x) over the
middle third of the arch is twice the average value over the end thirds.
6.
Let f(t) = eiωt on (−π, π). Expand f(t) in a complex exponential Fourier series of
period 2π. (Assume ω ̸= integer.)
7.
Given f(x) = |x| on (−π, π), expand f(x) in an appropriate Fourier series of pe-
riod 2π.
8.
From facts you know, ﬁnd in your head the average value of
(a)
x3 −3 sinh 2x + sin2 πx + cos 3πx on (−5, 5).
(b)
2 sin2 3x −4 cos x + 5x cosh 2x −x cos2 x on (−π, π).
9.
Given f(x) =
(
x,
0 < x < 1,
−2,
1 < x < 2.
(a)
Sketch at least three periods of the graph of the function represented by the
sine series for f(x). Without ﬁnding any series, answer the following questions:
(b)
To what value does the sine series in (a) converge at x = 1? At x = 2? At
x = 0? At x = −1?
(c)
If the given function is continued with period 2 and then is represented by a
complex exponential series P∞
n=−∞cneinπx, what is the value of P∞
n=−∞|cn|2?

388
Fourier Series and Transforms
Chapter 7
10.
(a)
Sketch at least three periods of the graph of the function represented by the
cosine series for f(x) in Problem 9.
(b)
Sketch at least three periods of the graph of the exponential Fourier series of
period 2 for f(x) in Problem 9.
(c)
To what value does the cosine series in (a) converge at x = 0? At x = 1? At
x = 2? At x = −2?
(d)
To what value does the exponential series in (b) converge at x = 0? At x = 1?
At x = 3
2? At x = −2.
11.
Find the three Fourier series in Problems 9 and 10.
12.
What would be the apparent frequency of a sound wave represented by
p(t) =
∞
X
n=1
cos 60nπt
100(n −3)2 + 1?
13.
(a)
Given f(x) = (π −x)/2 on (0, π), ﬁnd the sine series of period 2π for f(x).
(b)
Use your result in (a) to evaluate P 1/n2.
14.
(a)
Find the Fourier series of period 2 for f(x) = (x −1)2 on (0, 2).
(b)
Use your result in (a) to evaluate P 1/n4.
15.
Given
f(x) =
(
1,
−2 < x < 0,
−1,
0 < x < 2,
ﬁnd the exponential Fourier transform g(α) and the sine transform gs(α). Write
f(x) as an integral and use your result to evaluate
Z ∞
0
(cos 2α −1) sin 2α
α
dα.
16.
Given
f(x) =
8
>
<
>
:
x,
0 ≤x ≤1,
2 −x,
1 ≤x ≤2,
0,
x ≥2,
ﬁnd the cosine transform of f(x) and use it to write f(x) as an integral. Use your
result to evaluate
Z ∞
0
cos2 α sin2 α/2
α2
dα.
17.
Show that the Fourier sine transform of x−1/2 is α−1/2. Hint: Make the change
of variable z = αx. The integral
R ∞
0
z−1/2 sin z dz can be found by computer or in
tables.
18.
Let f(x) and g(α) be a pair of Fourier transforms. Show that df/dx and iαg(α) are
a pair of Fourier transforms. Hint: Diﬀerentiate the ﬁrst integral in (12.2) under
the integral sign with respect to x. Use (12.23) to show that
Z ∞
−∞
α|g(α)|2 dα =
1
2πi
Z ∞
−∞
¯f(x) d
dxf(x) dx.
Comment: This result is of interest in quantum mechanics where it would read, in
the notation of Problem 12.35:
Z ∞
−∞
p|φ(p)|2 dp =
Z ∞
−∞
ψ∗(x)
„−ih
2π
d
dx
«
ψ(x) dx.

Section 13
Miscellaneous Problems
389
19.
Find the form of Parseval’s theorem (12.24) for sine transforms (12.14) and for cosine
transforms (12.15).
20.
Find the exponential Fourier transform of
f(x) =
(
2a −|x|,
|x| < 2a,
0,
|x| > 2a,
and use your result with Parseval’s theorem to evaluate
Z ∞
0
sin4 aα
α4
dα.
21.
Deﬁne a function h(x) = P∞
k=−∞f(x + 2kπ), assuming that the series converges
to a function satisfying Dirichlet conditions (Section 6). Verify that h(x) does have
period 2π.
(a)
Expand h(x) in an exponential Fourier series h(x) = P∞
−∞cneinx; show that
cn = g(n) where g(α) is the Fourier transform of f(x). Hint: Write cn as an
integral from 0 to 2π and make the change of variable u = x + 2kπ. Note that
e−2inkπ = 1, and the sum on k gives a single integral from −∞to ∞.
(b)
Let x = 0 in (a) to get Poisson’s summation formula P∞
−∞f(2kπ) = P∞
−∞g(n).
This result has many applications; for example: statistical mechanics, commu-
nication theory, theory of optical instruments, scattering of light in a liquid,
and so on. (See Problem 22.)
22.
Use Poisson’s formula (Problem 21b) and Problem 20 to show that
∞
X
−∞
sin2 nθ
n2
= πθ,
0 < θ < π.
(This sum is needed in the theory of scattering of light in a liquid.) Hint: Consider
f(x) and g(α) as in Problem 20. Note that f(2kπ) = 0 except for k = 0 if a < π.
Put α = n, a = θ.
23.
Use Parseval’s theorem and Problem 12.11 to evaluate
Z ∞
0
cos2(απ/2)
(1 −α2)2 dα.

C H A P T E R 8
Ordinary Differential Equations
1. INTRODUCTION
A great many applied problems involve rates, that is, derivatives.
An equation
containing derivatives is called a diﬀerential equation. If it contains partial deriva-
tives, it is called a partial diﬀerential equation; otherwise it is called an ordinary
diﬀerential equation. In this chapter we shall consider methods of solving ordinary
diﬀerential equations which occur frequently in applications. Let us look at a few
examples.
Newton’s second law in vector form is F = ma. If we write the acceleration as
dv/dt, where v is the velocity, or as d2r/dt2, where r is the displacement, we have
a diﬀerential equation (or a set of diﬀerential equations, one for each component).
Thus any mechanics problem in which we want to describe the motion of a body
(automobile, electron, or satellite) under the action of a given force, involves the
solution of a diﬀerential equation or a set of diﬀerential equations.
The rate at which heat Q escapes through a window or from a hot water pipe is
proportional to the area A and to the rate of change of temperature with distance
in the direction of ﬂow of heat. Thus we have
(1.1)
dQ
dt = kAdT
dx
(k is called the thermal conductivity and depends on the material through which the
heat is ﬂowing). Here we have two diﬀerent derivatives in the diﬀerential equation.
In such a problem we might know either dT/dx or dQ/dt and solve the diﬀerential
equation to ﬁnd either T as a function of x, or Q as a
function of t. (See Problems 2.23 to 2.25.)
Figure 1.1
Consider a simple series circuit (Figure 1.1) contain-
ing a resistance R, a capacitance C, an inductance L,
and a source of emf V . If the current ﬂowing around the
circuit at time t is I(t) and the charge on the capacitor
is q(t), then I = dq/dt. The voltage across R is RI,
the voltage across C is q/C, and the voltage across L is
390

Section 1
Introduction
391
L(dI/dt). Then at any time we must have
(1.2)
LdI
dt + RI + q
C = V.
If we diﬀerentiate this equation with respect to t and substitute dq/dt = I, we have
(1.3)
Ld2I
dt2 + RdI
dt + I
C = dV
dt
as the diﬀerential equation satisﬁed by the current I in a simple series circuit with
given L, R, and C, and a given V (t).
There are many more examples of physical problems leading to diﬀerential equa-
tions; we shall consider some of them later in the text and problems. You might ﬁnd
it interesting at this point to browse through the problems to see the wide range of
topics giving rise to diﬀerential equations.
The order of a diﬀerential equation is the order of the highest derivative in the
equation. Thus the equations
y′ + xy2 = 1,
xy′ + y = ex,
dv
dt = −g,
LdI
dt + RI = V,
(1.4)
are ﬁrst-order equations, while (1.3) and
md2r
dt2 = −kr
are second-order equations. A linear diﬀerential equation (with x as independent
and y as dependent variable) is one of the form
a0y + a1y′ + a2y′′ + a3y′′′ + · · · = b,
where the a’s and b are either constants or functions of x. The ﬁrst equation in
(1.4) is not linear because of the y2 term; all the other equations we have mentioned
so far are linear. Some other examples of nonlinear equations are:
y′ = cot y
(not linear because of the term cot y);
yy′ = 1
(not linear because of the product yy′);
y′2 = xy
(not linear because of the term y′2).
Many of the diﬀerential equations which occur in applied problems are linear and
of the ﬁrst or second order; we shall be particularly interested in these.
A solution of a diﬀerential equation (in the variables x and y) is a relation between
x and y which, if substituted into the diﬀerential equation, gives an identity.

392
Ordinary Differential Equations
Chapter 8
Example 1.
The relation
(1.5)
y = sin x + C
is a solution of the diﬀerential equation
(1.6)
y′ = cos x
because if we substitute (1.5) into (1.6) we get the identity cos x = cos x.
Example 2.
The equation y′′ = y has solutions y = ex or y = e−x or y = Aex + Be−x as
you can verify by substitution.
If we integrate y′ = f(x), the expression for y, namely y =

f(x) dx + C,
contains one arbitrary constant of integration. If we integrate y′′ = g(x) twice to
get y(x), then y contains two independent integration constants. We might expect
that in general the solution of a diﬀerential equation of the nth order would contain
n independent arbitrary constants. Note that in Example 1 above, the solution
of the ﬁrst-order equation y′ = cos x contained one arbitrary constant C, and in
Example 2 the solution y = Aex + Be−x of the second-order equation y′′ = y
contained two arbitrary constants A and B.
Any linear diﬀerential equation of order n has a solution containing n independent
arbitrary constants, from which all solutions of the diﬀerential equation can be
obtained by letting the constants have particular values. This solution is called
the general solution of the linear diﬀerential equation.
(This may not be true for nonlinear equations; see Section 2.)
In applications, we usually want a particular solution, that is, one which satis-
ﬁes the diﬀerential equation and some other requirements as well. Here are some
examples of this.
Example 3.
Find the distance which an object falls under gravity in t seconds if it starts
from rest.
Let x be the distance the object has fallen in time t. The acceleration of the
object is g, the acceleration of gravity. Then we have
(1.7)
d2x
dt2 = g.
Integrating, we get
(1.8)
dx
dt = gt + const. = gt + v0,
(1.9)
x = 1
2gt2 + v0t + x0,
where v0 and x0 are the values of v and x at t = 0. Now (1.9) is the general solution
of (1.7) (because it is a solution of a second-order linear diﬀerential equation and
contains two independent arbitrary constants). We want the particular solution for
which v0 = 0 (since the object starts from rest), and x0 = 0 (since the distance the
object has fallen is zero at t = 0). Then the desired particular solution is
(1.10)
x = 1
2gt2.

Section 1
Introduction
393
Example 4.
Find the solution of y′′ = y which passes through the origin and through the
point (ln 2, 3
4).
The general solution of the diﬀerential equation is
y = Aex + Be−x
(see Example 2). If the given points satisfy the equation of the curve, we must have
0 = A + B
or A = −B,
3
4 = Aeln 2 + Be−ln 2 = A · 2 + B · 1
2 = 2A −1
2A = 3
2A.
Thus we get
A = −B = 1
2,
and the desired particular solution is
y = 1
2(ex −e−x) = sinh x.
The given conditions which are to be satisﬁed by the particular solution are
called boundary conditions, or when they are conditions at t = 0 they may be called
initial conditions. For linear equations, the desired particular solution can be found
from the general solution by determining the values of the constants as we did in
Example 4. (For nonlinear equations, see Section 2.)
As you study methods of solving various types of diﬀerential equations in the
following sections, you may wonder whether you can use computer solutions and
not bother to learn these techniques. Just as for indeﬁnite integrals (see Chapter 5,
Section 1), there may be various forms for the solution of a diﬀerential equation,
and your computer may not give the one you need. In order to make intelligent use
of computer solutions, you need to know something about what to expect, and an
eﬀective way of gaining this knowledge is to solve some equations by hand. (See
Example 1, Section 3.) By comparing your solutions with computer solutions, you
will learn what you can (and cannot) expect from your computer.
The graphing capabilities of your computer are very useful in diﬀerential equa-
tions.
Consider a ﬁrst-order equation, say y′ = f(x, y).
If the solution of this
diﬀerential equation is y = y(x), the diﬀerential equation gives the slope y′ of the
solution curve at each point (x, y). Suppose, for a large number of points, we draw
a short line (or vector) centered on each point and with the slope y′ at that point.
(This would be a big job by hand, but your computer does it easily.) This plot is
called a slope ﬁeld, or a direction ﬁeld, or a vector ﬁeld. From such a diagram we
can see the general trend of the solution curves even without solving the equation.

394
Ordinary Differential Equations
Chapter 8
x
y
Figure 1.2
Example 5.
In Figure 1.2, we have plotted a “slope ﬁeld” for the diﬀerential equation
y′ = cos x. Note how you can trace the general shape of the solution curves, even
without knowing from Example 1 that their equations are y = sin x + C.
PROBLEMS, SECTION 1
1.
Verify the statement of Example 2. Also verify that y = cosh x and y = sinh x are
solutions of y′′ = y.
2.
Solve Example 4 using the general solution y = a sinh x + b cosh x.
3.
Verify that y = sin x, y = cos x, y = eix, and y = e−ix are all solutions of y′′ = −y.
4.
Find the distance which an object moves in time t if it starts from rest and has
an acceleration d2x/dt2 = ge−kt. Show that for small t the result is approximately
(1.10), and for very large t, the speed dx/dt is approximately constant. The constant
is called the terminal speed. (This problem corresponds roughly to the motion of a
parachutist.)
5.
Find the position x of a particle at time t if its acceleration is d2x/dt2 = A sin ωt.
6.
A substance evaporates at a rate proportional to the exposed surface. If a spherical
mothball of radius 1
2 cm has radius 0.4 cm after 6 months, how long will it take:
(a)
For the radius to be 1
4 cm?
(b)
For the volume of the mothball to be half of what it was originally?
7.
The momentum p of an electron at speed v near the speed c of light increases
according to the formula p = mv/
p
1 −v2/c2 , where m is a constant (mass of
the electron). If an electron is subject to a constant force F, Newton’s second law
describing its motion is
dp
dt = d
dt
mv
p
1 −v2/c2 = F.
Find v(t) and show that v →c as t →∞. Find the distance traveled by the electron
in time t if it starts from rest.

Section 2
Separable Equations
395
2. SEPARABLE EQUATIONS
Every time you evaluate an integral
(2.1)
y =

f(x) dx,
you are solving a diﬀerential equation, namely
(2.2)
y′ = dy
dx = f(x).
This is a simple example of an equation which can be written with only y terms on
one side of the equation and only x terms on the other:
(2.3)
dy = f(x) dx.
Whenever we can separate the variables this way, we call the equation separable,
and we get the solution by just integrating each side of the equation.
Example 1.
The rate at which a radioactive substance decays is proportional to the
remaining number of atoms. If there are N0 atoms at t = 0, ﬁnd the number at
time t.
The diﬀerential equation for this problem is
(2.4)
dN
dt = −λN.
(The proportionality constant λ is called the decay constant.) This is a separable
equation; we write it as dN/N = −λ dt.
Then integrating both sides, we get
ln N = −λt + const. Since we are given N = N0 at t = 0, we see that the constant
is ln N0. Solving for N, we have
(2.5)
N = N0e−λt.
(For further discussion of radioactive decay problems, see Section 3, Example 2,
and Problems 2.19b and 3.19 to 3.21.)
Example 2.
Solve the diﬀerential equation
(2.6)
xy′ = y + 1.
To separate variables, we divide both sides of (2.6) by x(y + 1); this gives
(2.7)
y′
y + 1 = 1
x
or
dy
y + 1 = dx
x .
Integrating each side of (2.7), we have
(2.8)
ln(y + 1) = ln x + const. = ln x + ln a = ln(ax).
(We have called the constant of integration ln a for simplicity.) Then (2.8) gives the
solution of (2.6), namely
(2.9)
y + 1 = ax.
This general solution represents a family of curves in the (x, y) plane, one curve
for each value of the constant a. Or we may call the general solution (2.9) a family
of solutions of the diﬀerential equation (2.6). Finding a particular solution means
selecting one particular curve from the family.

396
Ordinary Differential Equations
Chapter 8
Orthogonal Trajectories
In Figure 2.1, the straight lines through (0, −1) are
the family of curves given by the solutions
(2.9) of the diﬀerential equation (2.6).
They might represent, for example, the
lines of electric force due to an electric
charge at (0, −1). The circles in Figure
2.1 are then curves of constant electro-
static potential (called equipotentials—see
Chapter 6, Sections 5 and 6). Note that
the lines of force intersect the equipoten-
tial curves at right angles; each family of
curves is called a set of orthogonal trajec-
tories of the other family. It is often of
interest to ﬁnd the orthogonal trajecto-
ries of a given family of curves. Let us do
this for the family (2.9). (In this case we
know in advance that our answer will be
the set of circles in Figure 2.1.)
Figure 2.1
First we ﬁnd the slope of a line of the family (2.9), namely,
(2.10)
y′ = a.
For each a this gives the slope of one line. We want a formula (as a function of x
and y) which gives the slope, at any point of the plane, of the line through that
point. To obtain this, we eliminate a between (2.9) and (2.10) to get
(2.11)
y′ = y + 1
x
.
[Or, given (2.6) rather than (2.9), we could simply solve for y′.] Now recall from
analytic geometry that the slopes of two perpendicular lines are negative reciprocals.
Then at each point we want the slope of the orthogonal trajectory curve to be the
negative reciprocal of the slope of the line given by (2.11). Thus,
(2.12)
y′ = −
x
y + 1
gives the slope of the orthogonal trajectories, and we solve (2.12) to obtain the
equation of the orthogonal trajectory curves. Now (2.12) is separable; we obtain
(y + 1) dy = −x dx,
1
2y2 + y = −1
2x2 + C,
x2 + y2 + 2y = 2C,
x2 + (y + 1)2 = 2C + 1.
This is, as we expected, a family of circles with centers at the point (0, −1).
Nonlinear Diﬀerential Equations
We have said that for linear diﬀerential
equations of order n there is always a general solution containing n independent
constants, and all solutions can be obtained by specializing the constants. You
should be aware that this may not be true for some nonlinear equations, and routine

Section 2
Separable Equations
397
methods of solution (including computer) may sometimes give partially incorrect or
incomplete solutions. It is beyond our scope to discuss this in detail (see diﬀerential
equations books), but here are some examples.
Example 3.
Solve the diﬀerential equation y′ =

1 −y2 and computer plot the slope
ﬁeld and a set of solution curves. Find particular solutions satisfying (a) y = 0
when x = 0, and (b) y = 1 when x = 0.
We separate variables and integrate to get
dy

1 −y2 = dx,
arc sin y = x + α,
y = sin(x + α).
(b)
(b)
(a)
x
–2
–
–/2

0
Figure 2.2
A computer gives the same answer. However if we look at either a computer plot
of the slope ﬁeld (Figure 2.2), or the diﬀerential equation itself, we see that the
slope y′ is always non-negative. Thus the solution of the given diﬀerential equation
includes only the parts of the sine curves with non-negative slopes (Figure 2.2).
A second diﬃculty is that part of the solution is missing. From either the slope
ﬁeld (Figure 2.2) or directly from the diﬀerential equation we can see that y ≡1
and y ≡−1 are solutions not obtainable from the sine solution by any choice of
α. (These are sometimes called singular solutions.) The fact that we did not ﬁnd
these solutions by separation of variables should not surprise us when we note that
in separating variables we divided by

1 −y2 and this step is not valid if y2 = 1.
Now for the particular solution (a) passing through (0, 0), the sine solution gives
either y = sin x or y = sin(x + π) = −sin x. But since we know that y′ is non-
negative, only the y = sin x solution is correct in the vicinity of x = 0. In fact
(Figure 2.2), y = sin x is a correct particular solution from x = −π/2 to x = π/2.
We could construct a continuous solution from −∞to ∞by letting y = −1 from
−∞to −π/2, y = sin x from −π/2 to π/2, and y = 1 from π/2 to ∞. Thus for case
(a) [solution passing through the origin] we ﬁnd just one particular solution.
For particular solution (b) [passing through (0, 1)], we ﬁnd either y = sin(x+ π
2 ) =
cos x, or y ≡1; the cos x solution is valid from x = −π to x = 0. As in (a), we
can extend it by using parts of y = −1 and y = 1; this is one particular solution.
But there are an inﬁnite number of other particular solutions passing through (0, 1)
obtained by moving this one solution any distance to the left (Figure 2.2).

398
Ordinary Differential Equations
Chapter 8
PROBLEMS, SECTION 2
For each of the following diﬀerential equations, separate variables and ﬁnd a solution
containing one arbitrary constant. Then ﬁnd the value of the constant to give a particular
solution satisfying the given boundary condition. Computer plot a slope ﬁeld and some of
the solution curves.
1.
xy′ = y,
y = 3 when x = 2.
2.
x
p
1 −y2 dx + y
√
1 −x2 dy = 0,
y = 1
2 when x = 1
2.
3.
y′ sin x = y ln y,
y = e when x = π/3.
4.
(1 + y2) dx + xy dy = 0,
y = 0 when x = 5.
5.
xy′ −xy = y,
y = 1 when x = 1.
6.
y′ = 2xy2 + x
x2y −y ,
y = 0 when x =
√
2.
7.
y dy + (xy2 −8x) dx = 0,
y = 3 when x = 1.
8.
y′ + 2xy2 = 0,
y = 1 when x = 2.
9.
(1 + y)y′ = y,
y = 1 when x = 1.
10.
y′ −xy = x,
y = 1 when x = 0.
11.
2y′ = 3(y −2)1/3,
y = 3 when x = 1.
12.
(x + xy)y′ + y = 0,
y = 1 when x = 1.
In Problems 13 to 15, ﬁnd a solution (or solutions) of the diﬀerential equation not ob-
tainable by specializing the constant in your solution of the original problem. Hint: See
Example 3.
13.
Problem 2.
14.
Problem 8.
15.
Problem 11.
16.
By separation of variables, ﬁnd a solution of the equation y′ = √y containing one
arbitrary constant. Find a particular solution satisfying y = 0 when x = 0. Show
that y ≡0 is a solution of the diﬀerential equation which cannot be obtained by
specializing the arbitrary constant in your solution above. Computer plot a slope
ﬁeld and some of the solution curves. Show that there are an inﬁnite number of
solution curves passing through any point on the x axis, but just one through any
point for which y > 0. Hint: See Example 3. Problems 17 and 18 are physical
problems leading to this diﬀerential equation.
17.
The speed of a particle on the x axis, x ≥0, is always numerically equal to the
square root of its displacement x. If x = 0 when t = 0, ﬁnd x as a function of t.
Show that the given conditions are satisﬁed if the particle remains at the origin for
any arbitrary length of time t0 and then moves away; ﬁnd x for t > t0 for this case.
18.
Let the rate of growth dN/dt of a colony of bacteria be proportional to the square
root of the number present at any time. If there are no bacteria present at t = 0,
how many are there at a later time? Observe here that the routine separation of
variables solution gives an unreasonable answer, and the correct answer, N ≡0, is
not obtainable from the routine solution. (You have to think, not just follow rules!)

Section 2
Separable Equations
399
19.
(a)
Consider a light beam traveling downward into the ocean. As the beam pro-
gresses, it is partially absorbed and its intensity decreases. The rate at which
the intensity is decreasing with depth at any point is proportional to the in-
tensity at that depth.
The proportionality constant µ is called the linear
absorption coeﬃcient. Show that if the intensity at the surface is I0, the in-
tensity at a distance s below the surface is I = I0e−µs. The linear absorption
coeﬃcient for water is of the order of 10−2 ft−1 (the exact value depending on
the wavelength of the light and the impurities in the water). For this value
of µ, ﬁnd the intensity as a fraction of the surface intensity at a depth of 1 ft,
50 ft, 500 ft, 1 mile. When the intensity of a light beam has been reduced
to half its surface intensity (I =
1
2I0), the distance the light has penetrated
into the absorbing substance is called the half-value thickness of the substance.
Find the half-value thickness in terms of µ. Find the half-value thickness for
water for the value of µ given above.
(b)
Note that the diﬀerential equation and its solution in this problem are mathe-
matically the same as those in Example 1, although the physical problem and
the terminology are diﬀerent. In discussing radioactive decay, we call λ the
decay constant, and we deﬁne the half-life T of a radioactive substance as the
time when N = 1
2N0 (compare half-value thickness). Find the relation between
λ and T .
20.
Consider the following special cases of the simple series circuit [Figure 1.1 and equa-
tion (1.2)].
(a)
RC circuit (that is, L = 0) with V = 0; ﬁnd q as a function of t if q0 is the
charge on the capacitor at t = 0.
(b)
RL circuit (that is, no capacitor; this means 1/C = 0) with V = 0; ﬁnd I(t)
given I = I0 at t = 0.
(c)
Again note that these are the same diﬀerential equations as in Problem 19 and
Example 1. The terminology is again diﬀerent; we deﬁne the time constant τ
for a circuit as the time required for the charge (or current) to fall to 1/e times
its initial value. Find the time constant for the circuits (a) and (b). If the
same equation, say y = y0e−at, represented either radioactive decay or light
absorption or an RC or RL circuit, what would be the relations among the
half-life, the half-value thickness, and the time constant?
21.
Suppose the rate at which bacteria in a culture grow is proportional to the number
present at any time. Write and solve the diﬀerential equation for the number N of
bacteria as a function of time t if there are N0 bacteria when t = 0. Again note that
(except for a change of sign) this is the same diﬀerential equation and solution as in
the preceding problems.
22.
Solve the equation for the rate of growth of bacteria if the rate of increase is pro-
portional to the number present but the population is being reduced at a constant
rate by the removal of bacteria for experimental purposes.
23.
Heat is escaping at a constant rate [dQ/dt in (1.1) is constant] through the walls
of a long cylindrical pipe. Find the temperature T at a distance r from the axis of
the cylinder if the inside wall has radius r = 1 and temperature T = 100 and the
outside wall has r = 2 and T = 0.
24.
Do Problem 23 for a spherical cavity containing a constant source of heat. Use the
same radii and temperatures as in Problem 23.

400
Ordinary Differential Equations
Chapter 8
25.
Show that the thickness of the ice on a lake increases with the square root of the
time in cold weather, making the following simplifying assumptions. Let the water
temperature be a constant 10◦C, the air temperature a constant −10◦, and assume
that at any given time the ice forms a slab of uniform thickness x. The rate of
formation of ice is proportional to the rate at which heat is transferred from the
water to the air. Let t = 0 when x = 0.
26.
An object of mass m falls from rest under gravity subject to an air resistance pro-
portional to its speed. Taking the y axis as positive down, show that the diﬀerential
equation of motion is m(dv/dt) = mg −kv, where k is a positive constant. Find v
as a function of t, and ﬁnd the limiting value of v as t tends to inﬁnity; this limit
is called the terminal speed. Can you ﬁnd the terminal speed directly from the dif-
ferential equation without solving it? Hint: What is dv/dt after v has reached an
essentially constant value?
Consider the following speciﬁc examples of this problem.
(a)
A person drops from an airplane with a parachute. Find a reasonable value
of k.
(b)
In the Millikan oil drop experiment to measure the charge of an electron, tiny
electrically charged drops of oil fall through air under gravity or rise under the
combination of gravity and an electric ﬁeld. Measurements can be made only
after they have reached terminal speed. Find a formula for the time required
for a drop starting at rest to reach 99% of its terminal speed.
27.
According to Newton’s law of cooling, the rate at which the temperature of an
object changes is proportional to the diﬀerence between its temperature and that
of its surroundings. A cup of coﬀee at 200◦in a room of temperature 70◦is stirred
continually and reaches 100◦after 10 min. At what time was it at 120◦?
28.
A glass of milk at 38◦is removed from the refrigerator and left in a room at tem-
perature 70◦.
If the temperature of the milk is 54◦after 10 min, what will its
temperature be in half an hour? (See Problem 27.)
29.
A solution containing 90% by volume of alcohol (in water) runs at 1 gal/min into a
100-gal tank of pure water where it is continually mixed. The mixture is withdrawn
at the rate of 1 gal/min. When will it start coming out 50% alcohol?
30.
If P dollars are left in the bank at interest I percent per year compounded contin-
uously, ﬁnd the amount A at time t. Hint: Find dA, the interest on A dollars for
time dt.
Find the orthogonal trajectories of each of the following families of curves. In each case,
sketch or computer plot several of the given curves and several of their orthogonal trajec-
tories. Be careful to eliminate the constant from y′ for the original curves; this constant
takes diﬀerent values for diﬀerent curves of the original family, and you want an expression
for y′ which is valid for all curves of the family crossed by the orthogonal trajectory you
are trying to ﬁnd. See equations (2.10) to (2.12).
31.
x2 + y2 = const.
32.
y = kx2.
33.
y = kxn. (Assume that n is a given number; the diﬀerent curves of the family have
diﬀerent values of k.)
34.
xy = k.
35.
(y −1)2 = x2 + k.

Section 3
Linear First-Order Equations
401
3. LINEAR FIRST-ORDER EQUATIONS
A ﬁrst-order equation contains y′ but no higher derivatives. A linear ﬁrst-order
equation means one which can be written in the form
(3.1)
y′ + Py = Q,
where P and Q are functions of x. To see how to solve (3.1), let us ﬁrst consider
the simpler equation when Q = 0. The equation
(3.2)
y′ + Py = 0
or
dy
dx = −Py
is separable. As in Section 2, we obtain the solution as follows:
dy
y = −P dx,
ln y = −

P dx + C,
y = e−R P dx+C = Ae−R P dx
(3.3)
where A = eC. Let us simplify the notation for future use; we write
(3.4)
I =

P dx.
Then
(3.5)
dI
dx = P
and we can write (3.3) as y = Ae−I or
(3.6)
yeI = A.
We can now see how to solve (3.1). If we diﬀerentiate (3.6) with respect to x
and use (3.5), we get
(3.7)
d
dx(yeI) = y′eI + yeI dI
dx = y′eI + yeIP = eI(y′ + Py),
which is the left-hand side of (3.1) multiplied by eI. (We call eI an integrating
factor—see Section 4.) Thus, we can write (3.1) (times eI) as
(3.8)
d
dx(yeI) = eI(y′ + Py) = QeI.
Since Q and eI are functions of x only, we can now integrate both sides of (3.8)
with respect to x to get
(3.9)
yeI =

QeI dx + c,
or
y = e−I

QeI dx + ce−I,







where
I =

P dx.

402
Ordinary Differential Equations
Chapter 8
This is the general solution of (3.1). Note that it contains one arbitrary constant
as expected for a ﬁrst-order linear equation. The term ce−I is a solution of equa-
tion (3.2); the ﬁrst term in y is one particular solution of (3.1). Borrowing notation
which we shall use in Section 6, let’s call the term ce−I = yc and the particular
solution = yp. Then yp + yc is a solution of (3.1) for any value of c. Also note
that ypeI =

QeI dx is an indeﬁnite integral which, as we know (see Chapter 5,
Section 1), has inﬁnitely many answers diﬀering from each other by constants of
integration. Thus the particular solution obtained by you and by your computer
may not be the same (see Example 1 and Problems).
Example 1.
Solve (1 + x2)y′ + 6xy = 2x. In the form of (3.1), this is
y′ +
6x
1 + x2 y =
2x
1 + x2 .
From (3.9), we get
I =

6x
1 + x2 dx = 3 ln(1 + x2)
eI = e3 ln(1+x2) = (1 + x2)3
yeI =

2x
1 + x2 (1 + x2)3 dx =

2x(1 + x2)2 dx = 1
3(1 + x2)3 + c
y = 1
3 +
c
(1 + x2)3 .
A computer gives the answer
y = 3x2 + 3x4 + x6
3(1 + x2)3
+
A
(1 + x2)3 .
Let us show that the answers agree (see comments just after (3.9)).
If we put
A = c + 1/3 in the computer solution above and combine terms, we get
y = 3x2 + 3x4 + x6 + 1
3(1 + x2)3
+
c
(1 + x2)3 = (1 + x2)3
3(1 + x2)3 +
c
(1 + x2)3 ,
which, after cancelling, is our solution above. We see that the computer program
chose a more complicated particular solution yp which diﬀered from our yp by a
multiple of yc = 1/(1 + x2)3. Always be aware of the possibility of simplifying a
particular solution by adding a multiple of yc.
Example 2.
Radium decays to radon which decays to polonium. If at t = 0, a sample is
pure radium, how much radon does it contain at time t?
Let
N0 = number of radium atoms at t = 0,
N1 = number of radium atoms at time t,
N2 = number of radon atoms at time t,
λ1 and λ2 = decay constants for Ra and Rn.
As in Section 2, we have for radium
dN1
dt
= −λ1N1,
N1 = N0e−λ1t.

Section 3
Linear First-Order Equations
403
The rate at which radon is being created is the rate at which radium is decaying,
namely λ1N1 or λ1N0e−λ1t. But the radon is also decaying at the rate λ2N2. Hence,
we have
dN2
dt
= λ1N1 −λ2N2,
or
dN2
dt + λ2N2 = λ1N1 = λ1N0e−λ1t.
This equation is of the form (3.1), and we solve it as follows:
(3.10)
I =

λ2 dt = λ2t,
N2eλ2t =

λ1N0e−λ1teλ2t dt + c
= λ1N0

e(λ2−λ1)t dt + c =
λ1N0
λ2 −λ1
e(λ2−λ1)t + c,
if λ1 ̸= λ2. (For the case λ1 = λ2, see Problem 19.) Since N2 = 0 at t = 0 (we
assumed pure Ra at t = 0), we must have
0 =
λ1N0
λ2 −λ1
+ c
or
c = −λ1N0
λ2 −λ1
.
Substituting this value of c into (3.10) and solving for N2, we get
N2 =
λ1N0
λ2 −λ1
(e−λ1t −e−λ2t).
PROBLEMS, SECTION 3
Using (3.9), ﬁnd the general solution of each of the following diﬀerential equations. Com-
pare a computer solution and, if necessary, reconcile it with yours. Hint: See comments
just after (3.9), and Example 1.
1.
y′ + y = ex
2.
x2y′ + 3xy = 1
3.
dy + (2xy −xe−x2) dx = 0
4.
2xy′ + y = 2x5/2
5.
y′ cos x + y = cos2 x
6.
y′ + y/
p
x2 + 1 = 1/(x +
p
x2 + 1 )
7.
(1 + ex)y′ + 2exy = (1 + ex)ex
8.
(x ln x)y′ + y = ln x
9.
(1 −x2)y′ = xy + 2x
p
1 −x2
10.
y′ + y tanh x = 2ex
11.
y′ + y cos x = sin 2x
12.
dx
dy = cos y −x tan y
13.
dx + (x −ey) dy = 0
14.
dy
dx =
3y
3y2/3 −x
Hint: For Problems 12 to 14, solve for x in terms of y.

404
Ordinary Differential Equations
Chapter 8
15.
Water with a small salt content (5 lb in 1000 gal) is ﬂowing into a very salty lake
at the rate of 4 · 105 gal per hr. The salty water is ﬂowing out at the rate of 105
gal per hr. If at some time (say t = 0) the volume of the lake is 109 gal, and its
salt content is 107 lb, ﬁnd the salt content at time t. Assume that the salt is mixed
uniformly with the water in the lake at all times.
16.
Find the general solution of (1.2) for an RL circuit (1/C = 0) with V = V0 cos ωt
(ω = const.).
17.
Find the general solution of (1.3) for an RC circuit (L = 0), with V = V0 cos ωt.
18.
Do Problems 16 and 17 using V = V0eiωt, and ﬁnd the solutions for 16 and 17 by
taking real parts of the complex solutions.
19.
If λ1 = λ2 = λ in (3.10), then
R
e(λ2−λ1)t dt =
R
dt. Find N2 for this case.
20.
Extend the radioactive decay problem (Example 2) one more stage, that is, let λ3
be the decay constant of polonium and ﬁnd how much polonium there is at time t.
21.
Generalize Problem 20 to any number of stages.
22.
Find the orthogonal trajectories of the family of curves x = y + 1 + cey. (See the
instructions above Problem 2.31.)
23.
Find the orthogonal trajectories of the family of curves y = −ex2 erf x+Cex2. Hint:
See Chapter 11, equation (9.1) for deﬁnition of erf x, and Chapter 4, Section 12, for
diﬀerentiation of an integral. Solve for x in terms of y.
4. OTHER METHODS FOR FIRST-ORDER EQUATIONS
Separable equations and linear equations are the two types of ﬁrst-order equations
you are most apt to meet in elementary applications. However, we shall also mention
brieﬂy a few other methods of solving special ﬁrst-order equations. You will ﬁnd
more details in the problems and in most diﬀerential equations books.
The Bernoulli Equation
The diﬀerential equation
(4.1)
y′ + Py = Qyn,
where P and Q are functions of x, is known as the Bernoulli equation. It is not
linear but is easily reduced to a linear equation. We make the change of variable
(4.2)
z = y1−n.
Then
(4.3)
z′ = (1 −n)y−ny′.
Next multiply (4.1) by (1−n)y−n and make the substitutions (4.2) and (4.3) to get
(1 −n)y−ny′ + (1 −n)Py1−n= (1 −n)Q,
z′ + (1 −n)Pz
= (1 −n)Q.
This is now a ﬁrst-order linear equation which we can solve as we did the linear
equations above. (See Section 7 for an example of a physical problem in which we
need to solve a Bernoulli equation.)

Section 4
Other Methods for First-Order Equations
405
Exact Equations; Integrating Factors
Recall from Chapter 6, Section 8, that
the expression P(x, y) dx+Q(x, y) dy is an exact diﬀerential [that is, the diﬀerential
of a function F(x, y)] if
(4.4)
∂P
∂y = ∂Q
∂x .
If (4.4) holds, then there is a function F(x, y) such that
(4.5)
P = ∂F
∂x ,
Q = ∂F
∂y ,
P dx + Q dy = dF.
In Chapter 6 we considered ways of ﬁnding F when (4.4) holds. The diﬀerential
equation
(4.6)
P dx + Q dy = 0
or
y′ = −P
Q
is called exact if (4.4) holds. In this case
P dx + Q dy = dF = 0,
and the solution of (4.6) is then
(4.7)
F(x, y) = const.
We ﬁnd F as in Chapter 6, Section 8.
An equation which is not exact may often be made exact by multiplying it by
an appropriate factor.
Example 1.
The equation
(4.8)
x dy −y dx = 0
is not exact [by (4.4)]. But the equation
(4.9)
x dy −y dx
x2
= 1
x dy −y
x2 dx = d
y
x
	
= 0,
obtained by dividing (4.8) by x2, is exact [use (4.4)], and its solution is
(4.10)
y
x = const.
We multiplied (4.8) by 1/x2 to make the equation exact; the factor 1/x2 is called
an integrating factor. To see another example of an integrating factor, look back at
Section 3. The expression eI is an integrating factor for equations (3.1) and (3.2);
as you can see in (3.8), multiplying (3.1) by eI makes it an exact equation.
The method of ﬁnding an integrating factor and solving the resulting exact
equation is useful mainly in simple cases when we can see the result by inspection.
It is not usually worth while to spend much time searching for integrating factors.

406
Ordinary Differential Equations
Chapter 8
Homogeneous Equations
A homogeneous function of x and y of degree n means
a function which can be written as xnf(y/x). For example, x3−xy2 = x3[1−(y/x)2]
is a homogeneous function of degree 3. (Also see Problem 21.) An equation of the
form
(4.11)
P(x, y) dx + Q(x, y) dy = 0,
where P and Q are homogeneous functions of the same degree is called homogeneous.
(The term homogeneous is also used in another sense; see Section 5.) If we divide
two homogeneous functions of the same degree, the xn factors cancel and we have
a function of y/x. Thus, from (4.11) we can write
(4.12)
y′ = dy
dx = −P(x, y)
Q(x, y) = f
y
x
	
,
and we can say that a diﬀerential equation is homogeneous if it can be written as
y′ = a function of y/x. This suggests that we solve homogeneous equations by
making the change of variables v = y/x, or
(4.13)
y = xv.
This substitution does, in fact, give us a separable equation in x and v (see Prob-
lem 22). We solve it to ﬁnd a relation between v and x and then put back v = y/x
to ﬁnd the solution of (4.11).
Also see Problem 23 for another way to solve homogeneous equations.
Change of Variables
We have solved both Bernoulli equations and homoge-
neous equations by making changes of variables. Other equations may yield to this
method also. If a diﬀerential equation contains some combination of the variables
x, y (especially if this combination appears more than once), we try replacing this
combination by a new variable. See Problems 11, 15, and 16 for examples.
PROBLEMS, SECTION 4
Use the methods of this section to solve the following diﬀerential equations. Compare
computer solutions and reconcile diﬀerences.
1.
y′ + y = xy2/3
2.
y′ + 1
xy = 2x3/2y1/2
3.
3xy2y′ + 3y3 = 1
4.
(2xe3y + ex) dx + (3x2e3y −y2) dy = 0
5.
(x −y) dy + (y + x + 1) dx = 0
6.
(cos x cos y + sin2 x) dx −(sin x sin y + cos2 y) dy = 0
7.
x2 dy + (y2 −xy) dx = 0
8.
y dy = (−x +
p
x2 + y2 ) dx
9.
xy dx + (y2 −x2) dy = 0
10.
(y2 −xy) dx + (x2 + xy)dy = 0
11.
y′ = cos(x + y)
Hint:
Let u = x + y; then u′ = 1 + y′.
12.
y′ = y
x −tan y
x
13.
yy′ −2y2 cot x = sin x cos x

Section 4
Other Methods for First-Order Equations
407
14.
(x −1)y′ + y −x−2 + 2x−3 = 0
15.
xy′ + y = exy
Hint: Let u = xy
16.
Solve the diﬀerential equation yy′2 + 2xy′ −y = 0 by changing from variables y, x,
to r, x, where y2 = r2 −x2; then yy′ = rr′ −x.
17.
If an incompressible ﬂuid ﬂows in a corner bounded by walls meeting at the origin at
an angle of 60◦, the streamlines of the ﬂow satisfy the equation 2xy dx+(x2 −y2) dy
= 0. Find the streamlines.
18.
Find the family of orthogonal trajectories of the circles (x −h)2 + y2 = h2. (See the
instructions above Problem 2.31.)
19.
Find the family of curves satisfying the diﬀerential equation (x+y)dy+(x−y)dx = 0
and also ﬁnd their orthogonal trajectories.
20.
Find the shape of a mirror which has
the property that rays from a point
O on the axis are reﬂected into a par-
allel beam. Hint: Take the point O
at the origin.
Show from the ﬁgure
that tan 2θ = y/x. Use the formula
for tan 2θ to express this in terms of
tan θ = dy/dx and solve the result-
ing diﬀerential equation. (Hint: See
Problem 16.)
21.
As in text just before (4.11), show that
(a)
x2 −5xy + y3/x is a homogeneous function of degree 2;
(b)
x−1(y4 −x3y) −xy2 sin(x/y) is homogeneous of degree 3;
(c)
x2y3 + x5 ln(y/x) −y6/
p
x2 + y2 is homogeneous of degree 5;
(d)
x2 + y, x + cos y, and y + 1 are not homogeneous.
See Chapter 4, Section 13, Problem 1 for a more general deﬁnition of a homogeneous
function of any number of variables.
22.
Show that the change of variables (4.13) in (4.11) or (4.12) gives a separable equation.
Hints: Substitute y = xv and dy = x dv +v dx from (4.13) into (4.12) and rearrange
terms to get the equation
(a)
[f(v) −v] dx = x dv.
Alternatively, suppose P and Q are homogeneous of degree n; that is P(x, y) =
xnP(1, y/x) = xnP(1, v) and a similar equation for Q. Substitute these results and
dy = x dv + v dx into (4.11), divide by xn, and rearrange terms to get
(b)
[P(1, v) + Q(1, v) v] dx + Q(1, v)x dv = 0.
Write both (a) and (b) with variables separated.
23.
Show that (xP + yQ)−1 is an integrating factor for (4.11). Hint: You want to show
that (P dx + Q dy)/(xP + yQ) is an exact diﬀerential (see Chapter 6, Section 8).
Remember that P and Q are homogeneous of the same degree. Divide numerator
and denominator by Q and use P/Q = −f(y/x) from (4.12). Now ﬁnd the needed
partial derivatives. Comment: If (x P + y Q) turns out to be very simple, this may
be an easier way to solve a homogeneous equation than the v = y/x substitution
(see Problem 24).

408
Ordinary Differential Equations
Chapter 8
24.
Solve Problems 9 and 10 by using an integrating factor as discussed in Problem 23.
25.
An equation of the form y′ = f(x)y2 + g(x)y + h(x) is called a Riccati equation.
If we know one particular solution yp, then the substitution y = yp + 1
z gives a
linear ﬁrst-order equation for z. We can solve this for z and substitute back to ﬁnd
a solution of the y equation containing one arbitrary constant (see Problem 26).
Following this method, check the given yp, and then solve
(a)
y′ = xy2 −2
x y −1
x3 ,
yp = 1
x2 ;
(b)
y′ = 2
x y2 + 1
x y −2x,
yp = x;
(c)
y′ = e−xy2 + y −ex,
yp = ex.
26.
Show that the substitution given in Problem 25 does in general give a solution of
the Riccati equation. Hints: First show that the substitution y = yp + u yields the
following equation for u: u′ −(g + 2fyp)u = fu2. Note by text equation (4.1) that
this is a Bernoulli equation with n = 2, so by equation (4.2) we let z = u−1. Show
that the z equation is the linear ﬁrst-order equation z′ + (g + 2fyp)z = −f. Note
that we could have obtained the z equation in one step by substituting y = yp + z−1
in the original equation as claimed in Problem 25.
5. SECOND-ORDER LINEAR EQUATIONS WITH CONSTANT
COEFFICIENTS AND ZERO RIGHT-HAND SIDE
Because of their importance in applications, we are going to consider carefully the
solution of diﬀerential equations of the form
(5.1)
a2
d2y
dx2 + a1
dy
dx + a0y = 0,
where a2, a1, a0 are constants; also we shall consider (Section 6) the corresponding
equation when the right-hand side of (5.1) is a function of x. Equations of the form
(5.1) are called homogeneous because every term contains y or a derivative of y.
Equations of the form (6.1) are called inhomogeneous because they contain a term
which does not depend on y. (Note, however, that this use of the term homogeneous
is completely unrelated to its use in Section 4.) Although we shall concentrate on
second-order equations, which are the ones that occur most frequently in applica-
tions, most of our discussion can be extended immediately to linear equations of
higher order with constant coeﬃcients (see Problems 21 to 30).
These problems are pretty simple by hand; you may be able to write down
answers faster than you can type the problem into a computer! Remember that a
computer may not give an answer in the form you need. To use computer solutions
eﬀectively, you need to know what to expect, and you can learn this by studying the
following methods and doing some problems by hand. Let us consider an equation
of the form (5.1).
Example 1.
Solve the equation
(5.2)
y′′ + 5y′ + 4y = 0.
It is convenient to let D stand for d/dx; then
(5.3)
Dy = dy
dx = y′,
D2y = d
dx

dy
dx

= d2y
dx2 = y′′.

Section 5
Second-Order Linear Equations (Constant Coefﬁcients, Zero Right-Hand Side)
409
Expressions involving D, such as D + 1 or D2 + 5D + 4, are called diﬀerential
operators. (See Problem 31.) In this notation (5.2) becomes
(5.4)
D2y + 5Dy + 4y = 0 or (D2 + 5D + 4)y = 0.
The algebraic expression D2 + 5D + 4 can be factored as (D + 1)(D + 4) or (D +
4)(D + 1). You should satisfy yourself that
(5.5)
(D + 1)(D + 4)y = (D + 4)(D + 1)y = (D2 + 5D + 4)y
when D = d/dx, and, in fact, that a similar statement is true for (D −a)(D −b)
where a and b are any constants. (This is not necessarily true if a and b are functions
of x; see Problem 31.) Then we can write (5.2) or (5.4) as
(5.6)
(D + 1)(D + 4)y = 0 or (D + 4)(D + 1)y = 0.
To solve (5.4) [or (5.6) which is the same equation rewritten], we shall ﬁrst solve
the simpler equations
(5.7)
(D + 4)y = 0 and (D + 1)y = 0.
These are separable equations (Section 2) with solutions
(5.8)
y = c1e−4x,
y = c2e−x.
Now if (D + 4)y = 0, then
(D + 1)(D + 4)y = (D + 1) · 0 = 0,
so any solution of (D + 4)y = 0 is a solution of the diﬀerential equation (5.6) or
(5.4). Similarly, any solution of (D + 1)y = 0 is a solution of (5.6) or (5.4). Since
the two solutions (5.8) are linearly independent [Problem 13; also see Chapter 3,
equation (8.5)], a linear combination of them contains two arbitrary constants and
so is the general solution. Thus
(5.9)
y = c1e−4x + c2e−x
is the general solution of (5.4). Note that we can think of the two solutions e−4x
and e−x as basis vectors of a 2-dimensional linear vector space (see Chapter 3,
Section 14). Then the general solution (5.9) gives all the vectors of that space. (See
Problem 21.)
Now we must investigate whether we can solve all second-order linear equations
with constant coeﬃcients (and zero right-hand side) by this method. We ﬁrst wrote
the diﬀerential equation using D for d/dx, and then factored the D expression to
get (5.5). In this last step, we treated D as if it were an algebraic letter instead
of d/dx; this is justiﬁed by checking the result (5.5) when D = d/dx. Recall from
algebra that saying that the algebraic expression D2+5D+4 has the factors (D+4)
and (D + 1) is equivalent to saying that the quadratic equation
(5.10)
D2 + 5D + 4 = 0
has roots −4 and −1. The equation (5.10) is called the auxiliary (or characteristic)
equation for the given diﬀerential equation (5.2). From equations (5.6) to (5.9), we

410
Ordinary Differential Equations
Chapter 8
see that to solve a linear second-order equation with constant coeﬃcients, we should
ﬁrst solve the auxiliary equation; if the roots of the auxiliary equation are a and b
(a ̸= b), the general solution of the diﬀerential equation is a linear combination of
eax and ebx.
(5.11) y = c1eax +c2ebx is the general solution of (D −a)(D −b)y = 0,
a ̸= b.
(If a = b, we get only one solution this way; we shall consider this case shortly.)
Recall from algebra that the roots of a quadratic equation (with real coeﬃcients;
see Problem 19) can be real and unequal, real and equal, or a complex conjugate
pair. The equation (5.2) which we have solved is an example in which the roots are
real and unequal. Let us consider the other two cases.
Equal Roots of the Auxiliary Equation
If the two roots of the auxiliary
equation are equal, then the diﬀerential equation can be written
(5.12)
(D −a)(D −a)y = 0,
where a is the value of the two equal roots. From our previous discussion (5.5) to
(5.11), we know that one solution of (5.12) is y = c1eax. But our previous second
solution y = c2ebx in (5.11) is not a second solution here since b = a. To ﬁnd the
second solution for this case, we let
(5.13)
u = (D −a)y.
Then (5.12) becomes
(D −a)u = 0,
from which we get
(5.14)
u = Aeax.
We substitute (5.14) into (5.13) to get
(D −a)y = Aeax or y′ −ay = Aeax.
This is a ﬁrst-order linear equation which we solve as in Section 3:
ye−ax =

e−axAeax dx =

A dx = Ax + B.
Thus
(5.15)
y = (Ax + B)eax is the general solution of (5.12).
This is the general solution of (5.1) for the case of equal roots of the auxiliary equa-
tion. The solution eax we already know; what is new here is the fact that xeax is a
second (linearly independent; see Problem 14) solution of the diﬀerential equation
when a is a double root of the auxiliary equation. Equations (5.11) and (5.15) then
give the general solution of (5.1) for both unequal and equal roots of the auxiliary
equation.

Section 5
Second-Order Linear Equations (Constant Coefﬁcients, Zero Right-Hand Side)
411
Complex Conjugate Roots of the Auxiliary Equation
Suppose the roots of
the auxiliary equation are α ± iβ. These are unequal roots, so by (5.11) the general
solution of the diﬀerential equation is
(5.16)
y = Ae(α+iβ)x + Be(α−iβ)x = eαx(Aeiβx + Be−iβx).
There are two other very useful forms of (5.16). If we substitute e±iβx = cos βx ±
i sin βx [see Chapter 2, equation (9.3)] into (5.16), then the parenthesis becomes a
linear combination of sin βx and cos βx and we can write (5.16) as
(5.17)
y = eαx(c1 sin βx + c2 cos βx),
where c1 and c2 are new arbitrary constants. We can also write (5.17) in the form
(5.18)
y = ceαx sin(βx + γ),
where c and γ are now the arbitrary constants. An easy way to see that this is cor-
rect is to expand sin(βx + γ) by the trigonometric addition formula; this gives a
linear combination of sin βx and cos βx as in (5.17). Although it is not hard to
express any one of the sets of arbitrary constants [A, B in (5.16); c1, c2 in (5.17);
and c, γ in (5.18)] in terms of either of the other sets, there is seldom any need to do
this. In solving actual problems we simply write whichever one of the three forms
seems best for the problem at hand and then determine the arbitrary constants in
that form from the given data.
Example 2.
Solve the diﬀerential equation
(5.19)
y′′ −6y′ + 9y = 0.
We can write the equation as
(5.20)
(D2 −6D + 9)y = 0 or (D −3)(D −3)y = 0.
Since the roots of the auxiliary equation are equal, we know that the solution is of
the form (5.15) and we simply write the result
(5.21)
y = (Ax + B)e3x.

412
Ordinary Differential Equations
Chapter 8
Example3.
In Section 16, Chapter 2, we discussed the diﬀerential equation for the motion
of a mass m oscillating at the end of a spring, and we solved it by guessing the
solution. Now let’s solve it by the methods of this chapter. The diﬀerential equation
is [see Chapter 2, equation (16.21)]
(5.22)
md2y
dt2 = −ky
or
d2y
dt2 = −k
my = −ω2y
if
ω2 = k
m.
We can write this diﬀerential equation as
(5.23)
D2y + ω2y = 0 or (D2 + ω2)y = 0
where D = d/dt. The roots of the auxiliary equation are D = ±iω; the solution
may be written in any of the three forms, (5.16), (5.17), or (5.18):
(5.24)
y = Aeiωt + Be−iωt
= c1 sin ωt + c2 cos ωt
= c sin(ωt + γ).
An object whose displacement from equilibrium satisﬁes (5.22) or (5.24) is said to
be executing simple harmonic motion. (Recall Chapter 7, Section 2.)
Equations (5.24) are general solutions of (5.22), each containing two arbitrary
constants. Let us ﬁnd a particular solution corresponding to given initial condi-
tions.
Example 4.
Suppose the mass is held at rest at a distance 10 cm below equilibrium and
then suddenly let go. If we agree to call y positive when m is above the equilibrium
position, then at t = 0, we have y = −10, and dy/dt = 0. Using the second solution
in (5.24), we get
dy
dt = c1ω cos ωt −c2ω sin ωt,
so the initial conditions give
−10 = c1 · 0 + c2 · 1,
0 = c1ω · 1 −c2ω · 0.
Thus we ﬁnd
c1 = 0,
c2 = −10,
and the particular solution we wanted is
(5.25)
y = −10 cosωt.
You can verify that either of the other solutions in (5.24) gives the same particular
solution (5.25) for the same initial conditions (Problem 32).
This solution is pretty unrealistic from the practical viewpoint. Equations (5.24)
and (5.25) imply that the mass m, once started, will simply oscillate up and down
forever! This is certainly not true; what will happen is that the oscillations will
gradually die down. The reason for the discrepancy between the physical facts and
our mathematical answer is that we have neglected “friction” forces.

Section 5
Second-Order Linear Equations (Constant Coefﬁcients, Zero Right-Hand Side)
413
Example 5.
A fairly reasonable assumption for this problem and many other similar ones
is that there is a retarding force proportional to the velocity; let us call this force
−l(dy/dt) (l > 0). Then (5.22), revised to include this force, becomes
(5.26)
md2y
dt2 = −ky −ldy
dt
(l > 0)
or with the abbreviations
ω2 = k
m,
2b = l
m
(b > 0)
it is
(5.27)
d2y
dt2 + 2bdy
dt + ω2y = 0.
To solve (5.27), we ﬁnd the roots of the auxiliary equation
(5.28)
D2 + 2bD + ω2 = 0,
which are
(5.29)
D = −2b ±
√
4b2 −4ω2
2
= −b ±

b2 −ω2.
There are three possible types of answer here depending on the relative size of
b2 and ω2, and there are three special names given to the corresponding types of
motion. We say that the motion is
overdamped if
b2 > ω2,
critically damped if
b2 = ω2,
underdamped or oscillatory if
b2 < ω2.
Let us discuss the corresponding general solutions of the diﬀerential equation for
the three cases.
Overdamped Motion
Since
√
b2 −ω2 is real and less than b, both roots of the
auxiliary equation are negative, and the general solution is a linear combination of
two negative exponentials:
(5.30)
y = Ae−λt + Be−µt,
where

λ = b +
√
b2 −ω2,
µ = b −
√
b2 −ω2.
Critically Damped Motion
Since b = ω, the auxiliary equation has equal roots
and the general solution is
(5.31)
y = (A + Bt)e−bt.
In both overdamped and critically damped motion, the mass m is subject to such
a large retarding force that it slows down and returns to equilibrium rather than
oscillating repeatedly.

414
Ordinary Differential Equations
Chapter 8
Underdamped or Oscillatory Motion
In this case b2 < ω2 so
√
b2 −ω2 is
imaginary. Let β =
√
ω2 −b2; then
√
b2 −ω2 = iβ and the roots (5.29) of the
auxiliary equation are −b ± iβ. The general solution in the form (5.17) is then
(5.32)
y = e−bt(A sin βt + B cos βt)
This result is more in accord with what we know actually happens to the mass
m; because of the factor e−bt, the oscillations in this case decrease in amplitude
as time goes on. Also note that the frequency of the damped vibrations, namely
β =
√
ω2 −b2, is less than the frequency ω of the undamped vibrations.
Although we have stated a rather special physical problem, the mathematics we
have just discussed applies to a great variety of problems. First, there are many
kinds of mechanical vibrations besides a mass attached to a spring. Think of a
tuning fork, a pendulum, the needle on the scale of a measuring device, and as
more involved examples, the vibrations of complicated structures such as bridges
or airplanes, and the vibrations of atoms in a crystal lattice. In such problems, we
need to solve diﬀerential equations similar to the ones we have discussed. Diﬀerential
equations of the same form arise in electricity. Consider equations (1.2) and (1.3)
when V = 0. Remembering that I = dq/dt, we can write (1.2) as
(5.33)
Ld2q
dt2 + Rdq
dt + 1
C q = 0
and (1.3) as
(5.34)
Ld2I
dt2 + RdI
dt + 1
C I = 0.
Both these equations are of the form (5.27) which we have solved. Thus there is an
analogy between a series circuit and the motion of a mass m described by (5.26);
L corresponds to m, R to the “friction” constant l, and 1/C to the spring constant k.
PROBLEMS, SECTION 5
Solve the following diﬀerential equations by the methods discussed above and compare
computer solutions.
1.
y′′ + y′ −2y = 0
2.
y′′ −4y′ + 4y = 0
3.
y′′ + 9y = 0
4.
y′′ + 2y′ + 2y = 0
5.
(D2 −2D + 1)y = 0
6.
(D2 + 16)y = 0
7.
(D2 −5D + 6)y = 0
8.
D(D + 5)y = 0
9.
(D2 −4D + 13)y = 0
10.
y′′ −2y′ = 0
11.
4y′′ + 12y′ + 9 = 0
12.
(2D2 + D −1)y = 0
Recall from Chapter 3, equation (8.5), that a set of functions is linearly independent if
their Wronskian is not identically zero. Calculate the Wronskian of each of the following
sets to show that in each case they are linearly independent.
For each set, write the
diﬀerential equation of which they are solutions. Also note that each set of functions is a
set of basis functions for a linear vector space (see Chapter 3, Section 14, Example 2) and
that the general solution of the diﬀerential equation gives all vectors of the vector space.

Section 5
Second-Order Linear Equations (Constant Coefﬁcients, Zero Right-Hand Side)
415
13.
e−x, e−4x
14.
eax, ebx, a ̸= b (a, b, real or complex)
15.
eax, xeax
16.
sin βx, cos βx
17.
1, x, x2
18.
eax, xeax, x2eax
19.
Solve the algebraic equation
D2 + (1 + 2i)D + i −1 = 0
(note the complex coeﬃcients) and observe that the roots are complex but not
complex conjugates. Show that the method of solution of (5.6) (case of unequal
roots) is correct here, and so ﬁnd the general solution of
y′′ + (1 + 2i)y′ + (i −1)y = 0.
20.
As in Problem 19, solve y′′ + (1 −i)y′ −iy = 0. Hint: See Chapter 2, Section 10,
for a method of ﬁnding the square root of a complex number.
21.
By the method used in solving (5.4) to get (5.9), show that the solution of the
third-order equation
(D −a)(D −b)(D −c)y = 0
is
y = c1eax + c2ebx + c3ecx
if a, b, c are all diﬀerent, and ﬁnd the solutions if two or three of the roots of the
auxiliary equation are equal. Generalize the result to higher-order equations. State
your results in vector space language [see comment following equation (5.9)].
Use the results of Problem 21 to ﬁnd the general solutions of the following equations and
compare computer solutions.
22.
(D −1)(D + 3)(D + 5)y = 0
23.
(D2 + 1)(D2 −1)y = 0
Hint: D2 + 1 = (D + i)(D −i).
24.
y′′′ + y = 0
25.
(D3 + D2 −6D)y = 0
26.
y′′′ −3y′′ −9y′ −5y = 0
27.
D2(D −1)2(D + 2)3y = 0
28.
(D4 + 4)y = 0
Hint: Find the four 4th roots of −4 (see Chapter 2, Section 10).
29.
(D + 1)2(D4 −16)y = 0
30.
(D4 −1)2y = 0
31.
Let D stand for d/dx, that is, Dy = dy/dx; then
D2y = D(Dy) = d
dx
„ dy
dx
«
= d2y
dx2 ,
D3y = d3y
dx3 , etc.
D (or an expression involving D) is called a diﬀerential operator. Two operators are
equal if they give the same results when they operate on y. For example,
D(D + x)y = d
dx
„ dy
dx + xy
«
= d2y
dx2 + x dy
dx + y = (D2 + xD + 1)y
so we say that
D(D + x) = D2 + xD + 1.
In a similar way show that:

416
Ordinary Differential Equations
Chapter 8
(a)
(D −a)(D −b) = (D −b)(D −a) = D2 −(b + a)D + ab for constant a and b.
(b)
D3 + 1 = (D + 1)(D2 −D + 1).
(c)
Dx = xD + 1. (Note that D and x do not commute, that is, Dx ̸= xD.)
(d)
(D −x)(D + x) = D2 −x2 + 1, but (D + x)(D −x) = D2 −x2 −1.
Comment: The operator equations in (c) and (d) are useful in quantum mechanics;
see Chapter 12, Section 22.
32.
In Example 3, we used the second solution in (5.24), and obtained (5.25) as the
particular solution satisfying the given initial conditions. Show that the ﬁrst and
third solutions in (5.24) also give the particular solution (5.25) satisfying the given
initial conditions.
33.
A particle moves along the x axis subject to a force toward the origin proportional to
x (say −kx). Show that the particle executes simple harmonic motion (Example 3).
Find the kinetic energy 1
2mv2 and the potential energy 1
2kx2 as functions of t and
show that the total energy is constant. Find the time averages of the potential energy
and the kinetic energy and show that these averages are each equal to one-half the
total energy (see average values, Chapter 7, Section 4).
34.
Find the equation of motion of a simple pendulum (see Chapter 7, Problem 2.13),
that is, the diﬀerential equation for θ as a function of t. Show that, for small θ, this
is approximately a simple harmonic motion equation, and ﬁnd θ if θ = θ0, dθ/dt = 0
when t = 0.
35.
The gravitational force on a particle of mass m inside the earth at a distance r from
the center (r < the radius of the earth R) is F = −mgr/R (Chapter 6, Section 8,
Problem 21). Show that a particle placed in an evacuated tube through the center
of the earth would execute simple harmonic motion. Find the period of this motion.
36.
Find (in terms of L and C) the frequency of electrical oscillations in a series circuit
(Figure 1.1) if R = 0 and V = 0, but I ̸= 0. (When you tune a radio, you are
adjusting C and/or L to make this frequency equal to that of the radio station.)
37.
A block of wood is ﬂoating in water; it is depressed slightly and then released to
oscillate up and down. Assume that the top and bottom of the block are parallel
planes which remain horizontal during the oscillations and that the sides of the block
are vertical. Show that the period of the motion (neglecting friction) is 2π
p
h/g,
where h is the vertical height of the part of the block under water when it is ﬂoating
at rest. Hint: Recall that the buoyant force is equal to the weight of displaced water.
38.
Solve the RLC circuit equation [(5.33) or (5.34)] with V = 0 as we did (5.27), and
write the conditions and solutions for overdamped, critically damped, and under-
damped electrical oscillations in terms of the quantities R, L, and C.
39.
(a)
Find numerical values of the constants and computer plot together on the
same axes graphs of (5.30), (5.31) and (5.32) in order to compare overdamped,
critically damped, and oscillatory motion. Suggested numbers: Let ω = 1, and
b = 13/5, 1, 5/13 for the three kinds of motion. Let y(0) = 1 and y′(0) = 0.
(b)
Repeat the problem with the same set of ω and b values and with y(0) = 1,
but with y′(0) = 1.
(c)
Again repeat, with y′(0) = −1.
40.
The natural period of an undamped system is 3 sec, but with a damping force
proportional to the velocity, the period becomes 5 sec. Find the diﬀerential equation
of motion of the system and its solution.

Section 6
Second-Order Linear Equations (Nonzero Right-Hand Side)
417
6. SECOND-ORDER LINEAR EQUATIONS WITH CONSTANT
COEFFICIENTS AND RIGHT-HAND SIDE NOT ZERO
So far we have considered second-order linear equations with constant coeﬃcients
and zero right-hand side (5.1). Such equations describe free vibrations or oscillations
of mechanical or electrical systems. But often such systems are not free but are
subject to an applied force or emf. The vibrations are then called forced vibrations
and the diﬀerential equation describing the system is of the form
(6.1)
a2
d2y
dx2 + a1
dy
dx + a0y = f(x),
or
d2y
dx2 + a1
a2
dy
dx + a0
a2
y = F(x).
The function f(x) is often called the forcing function; it represents the applied force
or emf. We want to ﬁnd the general solution of equations of the form (6.1).
Example 1.
Consider the equation
(6.2)
(D2 + 5D + 4)y = cos 2x.
We already know (from Section 5, Example 1) the general solution of the corre-
sponding equation (5.2) with the right-hand side equal to zero. This solution (5.9)
is called the complementary function; it is not a solution of (6.2) but is related to
it as we shall see. We shall denote the complementary function by yc. Thus for
equation (6.2) the complementary function is
(6.3)
yc = Ae−x + Be−4x.
Now suppose we know just any solution of (6.2); we call this solution a particular
solution and denote it by yp. You can easily verify that
(6.4)
yp =
1
10 sin 2x
is a particular solution of (6.2), and we shall soon consider ways of ﬁnding such
solutions. Then we have
(6.5)
(D2 + 5D + 4)yp = cos 2x
and from Section 5, Example 1,
(6.6)
(D2 + 5D + 4)yc = 0.
Adding (6.5) and (6.6), we ﬁnd
(D2 + 5D + 4)(yp + yc) = cos 2x + 0 = cos 2x.
Thus
(6.7)
y = yc + yp = Ae−x + Be−4x + 1
10 sin 2x
is a solution of (6.2). In fact, it is the general solution of (6.2) since it contains two
independent arbitrary constants (Problem 27).

418
Ordinary Differential Equations
Chapter 8
Thus we see how to solve 6.1):
The general solution of an equation of the form (6.1) is
(6.8)
y = yc + yp
where the complementary function yc is the general solution of the homogeneous
equation (as in Section 5) and yp is a particular solution of (6.1).
We shall now discuss some ways of ﬁnding particular solutions. It is worthwhile
to know about this even if you are using a computer to ﬁnd the solution. When you
know what to expect, you are better able to judge whether a computer solution is in
the best form for your purposes, and if not, to ﬁnd a better form. (See problems.)
Inspection
If there is a very simple particular solution, we may be able to guess
and verify it.
Example 2.
Consider the equation y′′ −2y′ + 3y = 5.
It is easy to see that yp = 5
3 is a particular solution of this equation since if y is
constant, y′′ and y′ are zero.
Example 3.
As a less trivial problem, consider
(6.9)
y′′ −6y′ + 9y = 8ex.
We might suspect that a multiple of ex is a solution of this equation, and it is easy
to verify that y = 2ex is a solution. But trying the same method for the equation
(6.10)
y′′ + y′ −2y = ex,
we fail to ﬁnd a particular solution since ex satisﬁes
y′′ + y′ −2y = 0.
The method of inspection is very good in simple cases where it gives us an answer
quickly, but usually we need other methods.
Successive Integration of Two First-Order Equations
This is a straight-
forward method which can always be used to solve equations of the form (6.1). In
practice, however, it often involves more work than various special methods; we
shall ﬁnd it particularly useful in deriving the special methods.
Example 4.
Let’s solve (6.10) again. We can write this diﬀerential equation as
(6.11)
(D −1)(D + 2)y = ex.
Let
(6.12)
u = (D + 2)y.

Section 6
Second-Order Linear Equations (Nonzero Right-Hand Side)
419
Then the diﬀerential equation (6.11) becomes
(6.13)
(D −1)u = ex
or u′ −u = ex.
This is a ﬁrst-order linear diﬀerential equation which we solve as in Section 3.
(6.14)
I =

−dx = −x,
ue−x =

e−xex dx = x + c1,
u = xex + c1ex.
Then the diﬀerential equation for y becomes
(D + 2)y = xex + c1ex
or y′ + 2y = xex + c1ex.
This is again a linear ﬁrst-order equation which we solve as follows:
(6.15)
I =

2 dx = 2x,
ye2x =

e2x(xex + c1ex) dx = 1
3xe3x −1
9e3x + 1
3c1e3x + c2
= 1
3xe3x + c′
1e3x + c2,
y = 1
3xex + c′
1ex + c2e−2x.
Notice that here we have obtained the general solution all in one process rather
than ﬁnding the complementary function plus a particular solution in two separate
processes. However, we could have obtained just the particular solution xex/3 by
omitting the arbitrary constant at each integration (these led to the complementary
function) and also dropping terms which are already in the complementary function
(−ex/9 in this example). Since it is easy to write the complementary function (by
Section 5), it saves time to omit those terms when we are ﬁnding a particular
solution. You may ﬁnd that your computer gives a more complicated particular
solution by including terms of the complementary function in the particular solution.
Now that you know to watch for this, you can simplify a computer solution by
removing those terms.
Exponential Right-Hand Side
Let us consider how to ﬁnd a particular solution
when the right-hand side of (6.1) is F(x) = kecx where k and c are given constants.
Observe that c may be complex; we shall be especially interested in this case later.
Let a and b be the roots of the auxiliary equation of (6.1); then (6.1) becomes
(6.16)
(D −a)(D −b)y = F(x) = kecx.
Let us ﬁrst suppose that c is not equal to either a or b. Solving (6.16) by successive
integration of two ﬁrst-order equations as in the last paragraph is straightforward
(Problem 28) and gives the result that the particular solution in this case is simply
a multiple of ecx. It is not necessary to remember the formula for the constant
factor or to go through this process each time. Now that we know the form of
the particular solution, we simply assume a solution of this form and solve for the
constant.

420
Ordinary Differential Equations
Chapter 8
Example 5.
Solve the equation
(6.17)
(D −1)(D + 5)y = 7e2x.
We observe that c = 2 is not equal to either of the roots of the auxiliary equation.
To ﬁnd a particular solution we substitute yp = Ce2x into (6.17) and get
y′′
p + 4y′
p −5yp = C(4e2x + 8e2x −5e2x) = 7e2x.
Thus we must have C = 1, and the general solution of (6.17) is
y = Aex + Be−5x + e2x.
We have already seen in solving (6.11) that if c is equal to either a or b (a ̸= b),
the particular solution is of the form Cxecx. By the same method used for (6.11),
you can easily discover that if a = b = c, the particular solution is of the form
Cx2ecx (Problem 28c). In practice, then, we ﬁnd a particular solution of (6.16) by
assuming a solution of the form:
(6.18)





Cecx
if c is not equal to either a or b;
Cxecx
if c equals a or b, a ̸= b;
Cx2ecx
if c = a = b.
Now that we know this, we would solve (6.10) as follows. Substitute
yp = Cxex,
y′
p = C(xex + ex),
y′′
p = C(xex + 2ex)
into (6.10) and get
y′′
p + y′
p −2yp = C(xex + 2ex + xex + ex −2xex) = ex.
Thus we ﬁnd C = 1
3 as in (6.15) (but with much less work).
Use of Complex Exponentials
In applied problems, the function F(x) on the
right-hand side of (6.1) is very often a sine or a cosine representing alternating emf
or a periodic force. We could ﬁnd yp for such a problem either by the method of
integrating two successive ﬁrst-order equations or by replacing the sine or cosine by
its complex exponential form and using the method of the last paragraph. There is
a still more eﬃcient variation of the latter method which we shall now show.
Example 6.
Solve
(6.19)
y′′ + y′ −2y = 4 sin 2x.
Instead of tackling this problem directly, we are ﬁrst going to solve the equation
(6.20)
Y ′′ + Y ′ −2Y = 4e2ix.
Since e2ix = cos 2x+i sin 2x is complex, the solution Y may be complex also. Then
if Y = YR + iYI, (6.20) is equivalent to two equations
Y ′′
R + Y ′
R −2YR = Re 4e2ix = 4 cos2x,
Y ′′
I + Y ′
I −2YI = Im 4e2ix = 4 sin 2x.
(6.21)

Section 6
Second-Order Linear Equations (Nonzero Right-Hand Side)
421
Since the second equation in (6.21) is the same as (6.19), we see that the solution of
(6.19) is the imaginary part of Y . Thus to ﬁnd yp for (6.19), we ﬁnd Yp for (6.20)
and take its imaginary part. We observe that 2i is not equal to either of the roots
of the auxiliary equation in (6.20). Following the method of the last paragraph, we
assume a solution of the form
Yp = Ce2ix
and substitute it into (6.20) to get
(−4 + 2i −2)Ce2ix = 4e2ix,
C =
4
2i −6 = 4(−2i −6)
40
= −1
5(i + 3),
Yp = −1
5(i + 3)e2ix.
Taking the imaginary part of Yp, we ﬁnd yp for (6.19):
(6.22)
yp = −1
5 cos 2x −3
5 sin 2x.
We summarize the method of complex exponentials:
(6.23)
To ﬁnd a particular solution of
(D −a)(D −b)y =

k sin αx,
k cos αx,
ﬁrst solve
(D −a)(D −b)y = keiαx
and then take the real or imaginary part.
Method of Undetermined Coeﬃcients
The method we have just discussed
of assuming an exponential solution and determining the constant factor C is an
example (and in practice the most important case) of the method of undetermined
coeﬃcients. In (6.18) we outlined the form of yp to assume for equation (6.16),
that is, when the right-hand side of (6.1) is an exponential. It is straightforward
but tedious (Problems 29 and 32) to ﬁnd the corresponding result (6.24) when the
right-hand side is an exponential times a polynomial.
A particular solution yp of (D−a)(D−b)y = ecxPn(x) where Pn(x) is a polynomial
of degree n is
(6.24)
yp =





ecxQn(x)
if c is not equal to either a or b,
xecxQn(x)
if c equals a or b, a ̸= b,
x2ecxQn(x)
if c = a = b,
where Qn(x) is a polynomial of the same degree as Pn(x) with undetermined
coeﬃcients to be found to satisfy the given diﬀerential equation. Note that sines
and cosines are included in ecx by use of complex exponentials as in (6.19) to
(6.23). (Also see Problem 29.)

422
Ordinary Differential Equations
Chapter 8
Example 7.
To illustrate using (6.24), let’s ﬁnd a particular solution of
(6.25)
(D −1)(D + 2)y = y′′ + y′ −2y = 18xex.
In the notation of (6.24) we have a = 1, b = −2, c = 1; also Pn(x) = 18x = P1(x)
is a polynomial of degree 1. Then Q1 is a polynomial of degree 1, namely Ax + B.
Since c = a ̸= b, we see by (6.24) that the form to assume for a particular solution
of (6.25) is
yp = xex(Ax + B) = ex(Ax2 + Bx).
We substitute this into (6.25) and ﬁnd A and B so that we have an identity.
yp′ = ex(Ax2 + Bx + 2Ax + B),
yp′′ = ex(Ax2 + Bx + 4Ax + 2B + 2A)
yp
′′ + yp
′ −2yp = ex(6Ax + 3B + 2A) ≡18xex
To make this an identity, we must have
6A = 18, 3B + 2A = 0,
or
A = 3, B = −2,
so
(6.26)
yp = (3x2 −2x)ex.
A computer solution may add to this a constant times ex, but this is an unnecessary
complication since ex is a term in the complementary function.
If the right-hand side of a diﬀerential equation is a polynomial, then c = 0 in
(6.24), and we assume for yp a polynomial as indicated in (6.24).
Example 8.
To solve
(6.27)
(D −1)(D + 2)y = y′′ + y′ −2y = x2 −x
we assume yp = Ax2 + Bx + C, and ﬁnd the particular solution
(6.28)
yp = −1
2(x2 + 1).
A computer solution gives the same result.
PROBLEMS, SECTION 6
Find the general solution of the following diﬀerential equations (complementary function
+ particular solution). Find the particular solution by inspection or by (6.18), (6.23),
or (6.24). Also ﬁnd a computer solution and reconcile diﬀerences if necessary, noticing
especially whether the particular solution is in simplest form [see (6.26) and the discussion
after (6.15)].
1.
y′′ −4y = 10
2.
(D −2)2y = 16
3.
y′′ + y′ −2y = e2x
4.
(D + 1)(D −3)y = 24e−3x
5.
(D2 + 1)y = 2ex
6.
y′′ + 6y′ + 9y = 12e−x
7.
y′′ −y′ −2y = 3e2x
8.
y′′ −16y = 40e4x

Section 6
Second-Order Linear Equations (Nonzero Right-Hand Side)
423
9.
(D2 + 2D + 1)y = 2e−x
10.
(D −3)2y = 6e3x
11.
y′′ + 2y′ + 10y = 100 cos 4x
Hint: First solve y′′ + 2y′ + 10y = 100e4ix.
12.
(D2 + 4D + 12)y = 80 sin 2x
13.
(D2 −2D + 1)y = 2 cos x
14.
y′′ + 8y′ + 25y = 120 sin 5x
15.
5y′′ + 12y′ + 20y = 120 sin 2x
16.
(D2 + 9)y = 30 sin 3x
17.
y′′ + 16y = 16 cos 4x
18.
(D2+2D+17)y = 60e−4x sin 5x
Hint: First solve (D2+2D+17)y = 60e(−4+5i)x.
19.
(4D2 + 4D + 5)y = 40e−3x/2 sin 2x
20.
y′′ + 4y′ + 8y = 30e−x/2 cos 5x/2
21.
5y′′ + 6y′ + 2y = x2 + 6x
22.
2y′′ + y′ = 2x
23.
y′′ + y = 2xex
24.
y′′ −6y′ + 9y = 12xe3x
25.
(D −3)(D + 1)y = 16x2e−x
26.
(D2 + 1)y = 8x sin x
27.
Verify that (6.4) is a particular solution of (6.2).
Verify that another particular
solution of (6.2) is
yp =
1
10 sin 2x −e−x.
Observe that we obtain the same general solution (6.7) whichever particular solution
we use [since (A −1) is just as good an arbitrary constant as A]. Show in general
that the diﬀerence between two particular solutions of (a2D2 + a1D + a0)y = f(x)
is always a solution of the homogeneous equation (a2D2 + a1D + a0)y = 0, and thus
show that the general solution is the same for all choices of a particular solution.
28.
Solve (6.16) by the method used in solving (6.11), for the following three cases, to
obtain the result (6.18).
(a)
c is not equal to either a or b;
(b)
a ̸= b, c = a;
(c)
a = b = c.
29.
Consider the diﬀerential equation (D −a)(D −b)y = Pn(x), where Pn(x) is a poly-
nomial of degree n. Show that a particular solution of this equation is given by
(6.24) with c = 0; that is, yp is
8
>
<
>
:
a polynomial Qn(x) of degree n if a and b are both diﬀerent from zero;
xQn(x)
if a ̸= 0, but b = 0;
x2Qn(x)
if a = b = 0.
Hint: To show that Qn(x) = P anxn is a solution of the diﬀerential equation for
a given Pn = P bnxn, you have only to show that the coeﬃcients an can be found
so that (D −a)(D −b)Qn(x) ≡Pn(x). Equate coeﬃcients of xn, xn−1, · · · , to see
that this is always possible if a ̸= b. For b = 0, the diﬀerential equation becomes
(D −a)Dy = Pn; what is Dy if y = xQn? Similarly, consider D2y if y = x2Qn.
30.
(a)
Show that
(D −a)ecx = (c −a)ecx;
(D2 + 5D −3)ecx = (c2 + 5c −3)ecx;
L(D)ecx = L(c)ecx, where L(D) is any polynomial in D;
(D −c)xecx = ecx;
(D −c)2x2ecx = 2ecx.

424
Ordinary Differential Equations
Chapter 8
(b)
Deﬁne the expression y = [1/L(D)]u(x) to mean a solution of the diﬀerential
equation L(D)y = u. Using part (a), show that
1
D −aecx =
ecx
c −a,
c ̸= a;
1
D2 + 5D −3ecx =
ecx
c2 + 5c −3;
1
L(D)ecx = ecx
L(c),
L(c) ̸= 0;
1
D −cecx = xecx;
1
(D −c)2 ecx = 1
2x2ecx.
(c)
The expressions 1/L(D) in (b) are called inverse operators. They can be used
to ﬁnd particular solutions of diﬀerential equations. As an example consider
Problem 3. We write
(D2 + D −2)y = e2x,
y =
1
D2 + D −2e2x =
e2x
22 + 2 −2 = e2x
4 .
Using inverse operators, ﬁnd particular solutions of Problems 4 to 20.
Be
careful to use parts 4 or 5 of (b) if c is a root of the auxiliary equation. For
example,
1
(D −a)(D −c)ecx =
1
D −c
1
D −aecx =
1
D −c
ecx
c −a = xecx
c −a.
31.
(a)
Show that
D(eaxy) = eax(D + a)y,
D2(eaxy) = eax(D + a)2y,
and so on; that is, for any positive integral n,
Dn(eaxy) = eax(D + a)ny.
Thus show that if L(D) is any polynomial in the operator D, then
L(D)(eaxy) = eaxL(D + a)y.
This is called the exponential shift.
(b)
Use (a) to show that
(D −1)3(exy) = exD3y,
(D2 + D −6)(e−3xy) = e−3x(D2 −5D)y.
(c)
Replace D by D −a, to obtain
eaxP(D)y = P(D −a)eaxy.
This is called the inverse exponential shift.

Section 6
Second-Order Linear Equations (Nonzero Right-Hand Side)
425
(d)
Using (c), we can change a diﬀerential equation whose right-hand side is an
exponential times a polynomial, to one whose right-hand side is just a polyno-
mial. For example, consider (D2 −D −6)y = 10xe3x; multiplying both sides
by e−3x and using (c), we get
e−3x(D2 −D −6)y = [(D + 3)2 −(D + 3) −6]ye−3x
= (D2 + 5D)ye−3x = 10x.
Show that a solution of (D2+5D)u = 10x is u = x2−2
5x; then ye−3x = x2−2
5x
or y = e3x(x2 −2
5x). Use this method to solve Problems 23 to 26.
32.
Using Problems 29 and 31b, show that equation (6.24) is correct.
Several Terms on the Right-Hand Side: Principle of Superposition
So
far we have brushed over a question which may have occurred to you: What do
we do if there are several terms on the right-hand side of the equation involving
diﬀerent exponentials?
Example 9.
As an artiﬁcial problem to illustrate the ideas, consider the equation
(6.29)
y′′ + y′ −2y = (D −1)(D + 2)y = [ex] + [4 sin 2x] + [x2 −x].
We have already solved diﬀerential equations with the same left-hand sides as (6.29)
and with right-hand sides equal in turn to each of the three expressions in brackets in
(6.29) [see (6.11) to (6.15), (6.19) to (6.22), (6.27), and (6.28)]. Thus we know that
(D −1)(D + 2)y = ex
has the particular solution yp1 = 1
3xex;
(D −1)(D + 2)y = 4 sin 2x has the particular solution yp2 = −1
5 cos 2x −3
5 sin 2x;
(D −1)(D + 2)y = x2 −x
has the particular solution yp3 = −1
2(x2 + 1).
Adding these three solutions, we see that
(6.30)
yp = yp1 + yp2 + yp3 = 1
3xex −1
5 cos 2x −3
5 sin 2x −1
2(x2 + 1)
is a particular solution of (6.29).
This is the easiest way of handling a complicated right-hand side: Solve a sep-
arate equation for each diﬀerent exponential and add the solutions. The fact that
this is correct for a linear equation is often called the principle of superposition.
As we can see from (6.29) and (6.30), this amounts to a fancy name for the fact
that the derivative (of any order) of a sum of terms is equal to the sum of the
derivatives of the individual terms. Notice that the principle holds only for linear
equations; for example, if the equation contained y′2, the principle would not hold
since (y′
1 + y′
2)2 is not equal to y′
1
2 + y′
2
2. In fact, an operator (such as the D oper-
ators we have been using) which satisﬁes the principle of superposition is called a
linear operator. [See Chapter 3, equation (7.4) and Problem 7.12.] Linear operators
are of particular importance because they obey the principle of superposition; for
example, D2(y1 + y2) = y′′
1 + y′′
2 = D2y1 + D2y2, so D2 is a linear operator. We
shall make use of this principle shortly in our discussion of the use of Fourier series
in ﬁnding particular solutions.

426
Ordinary Differential Equations
Chapter 8
Forced Vibrations
Let’s return now to the physical problem we considered at
the end of Section 5. There we set up and solved the diﬀerential equation which
describes the free (zero right-hand side, no forcing function) vibrations of a damped
oscillator. We commented that the same mathematics applies to a variety of me-
chanics problems and also to a simple RLC series electric circuit. As we know from
experiment and as we can see from (5.30), (5.31), and (5.32), the free vibrations we
considered in Section 5 die out as time passes. Such oscillations are referred to as
transients. We next want to consider the vibrations obtained when a periodic force
(or emf in the electric case) is applied. This means mathematically that we want to
solve (5.27) with a function of t on the right-hand side. The solution will contain
the appropriate one of (5.30), (5.31), (5.32); this is the complementary function and
it is also the transient since it tends to zero as t tends to inﬁnity. The solution will
also contain a particular solution which does not tend to zero as t tends to inﬁnity;
this is the steady-state solution which we want to ﬁnd.
Example 10.
Let us solve
(6.31)
d2y
dt2 + 2bdy
dt + ω2y = F sin ω′t
(F = const.).
By the method of complex exponentials, we solve ﬁrst
(6.32)
d2Y
dt2 + 2bdY
dt + ω2Y = Feiω′t.
Substitute
(6.33)
Yp = Ceiω′t
into (6.32) to get
(6.34)
(−ω′2 + 2biω′ + ω2)Ceiω′t = Feiω′t,
C =
F
(ω2 −ω′2) + 2biω′ = [(ω2 −ω′2) −2biω′]F

ω2 −ω′22 + 4b2ω′2 .
It is convenient to write the complex number C in the reiθ form. We have
(6.35)
|C| =
F

ω2 −ω′22 + 4b2ω′2
,
angle of C = −φ, where φ is given by Figure 6.1.
Figure 6.1
Thus
(6.36)
C =
F

ω2 −ω′22 + 4b2ω′2
e−iφ
and from (6.33)
(6.37)
Yp =
F

ω2 −ω′22 + 4b2ω′2
ei(ω′t−φ)

Section 6
Second-Order Linear Equations (Nonzero Right-Hand Side)
427
To ﬁnd yp we take the imaginary part of Yp:
(6.38)
yp =
F

ω2 −ω′22 + 4b2ω′2
sin(ω′t −φ).
This is the steady-state solution, so-called because as t increases, the rest of the
solution [given by (5.30), (5.31), or (5.32)] becomes negligible. For example, when
you turn on an electric light, the current is given by (5.32) plus (6.38). The transient
(5.32) tends to zero rapidly and the steady-state solution (6.38) becomes essentially
the whole solution.
Resonance
We note, by comparing (6.38) and the forcing function in (6.31),
that the applied force (or emf) and the solution y (which represents displacement,
current, etc.)
are out of phase; that is, their maximum values do not occur at
the same time because of the phase angle φ. We also see from (6.38) that for a
given forcing frequency ω′, the largest amplitude of y (also of dy/dt, Problem 40)
occurs if the natural (undamped) frequency ω is equal to ω′.
This situation is
often called resonance. In the RLC series circuit problem, y represents the charge
q on the capacitor if the forcing function is the emf, and y represents the current
I = dq/dt if the forcing function is the time derivative of the emf.
For such a
circuit, given the frequency ω′ of the applied emf, the current (or charge) will
have the largest amplitude when the natural (undamped) frequency ω is equal to
ω′.
This is almost always called the resonance condition for the electrical case.
However, there is another question we could ask here which is of particular interest
in mechanics.
Given the natural (undamped) frequency ω of the system, what
frequency of the forcing function will produce the largest amplitude of y? In (6.38),
we want to maximize the coeﬃcient of the sine; we can instead minimize the square
of the denominator of the coeﬃcient; that is, we want to ﬁnd the value of ω′ which
minimizes (ω2 −ω′2)2 + 4b2ω′2 for given ω. Setting the derivative of this function
(with respect to ω′) equal to zero and solving for ω′, we get
(6.39)
2(ω2 −ω′2)(−2ω′) + 8b2ω′ = 0,
ω′2 = ω2 −2b2.
Note that this value of ω′ is not equal to either the natural undamped frequency
ω or the natural damped frequency β where β2 = ω2 −b2 [see (5.32)]. However, if
we deﬁne resonance as the situation in which we get the maximum amplitude for
y for a given value of ω, then the resonance condition is (6.39). (The maximum
amplitude for the velocity—or current in the electrical case—is still obtained for
ω′ = ω; Problem 40.) The resonance condition (6.39) is of particular importance
in mechanics where we are apt to be interested in the displacement y of a given
system under the action of various forces. For example, consider a bridge; we would
want to avoid periodic forces with an ω′ given by (6.39) since such forces would
produce large vibrations. In this case resonance is undesirable. It may in other
cases be desirable; for example, when you tune your radio to the frequency of a
given station, you are given ω′ and you adjust the circuit in your radio to make its
natural frequency ω equal to the given ω′.

428
Ordinary Differential Equations
Chapter 8
Use of Fourier Series in Finding Particular Solutions
In simple problems,
the forcing function in either the electrical or mechanical case is just a sine or
cosine and the problem can be solved as we have just done. In more complicated
(and realistic) cases, however, the forcing function may very well be some more
complicated function; it is often a periodic function, however, and we shall assume
this. Suppose, for example, that the periodic emf applied to a circuit is given by one
of the graphs in Figure 3.2 of Chapter 7. We learned in Chapter 7 how to expand
such a function in a Fourier series. Let us suppose that this has been done, using
for deﬁniteness the complex exponential form of the Fourier series. Then we can
write (6.1) as
(6.40)
a2
d2y
dx2 + a1
dy
dx + a0y = f(x) =
∞

n=−∞
cneinx.
We know how to solve the equation
(6.41)
a2
d2y
dx2 + a1
dy
dx + a0y = cneinx
with the right-hand side equal to any one term of the series. If we now add the
solutions of all the equations (6.41) for all n, we have a solution of (6.40) (see
principle of superposition above).
Example 11.
Solve
(6.42)
d2y
dt2 + 2dy
dt + 10y = f(t),
where f(t) is a function of period 2π and
f(t) =

1,
0 ≤t < π,
0,
π ≤t < 2π.
The auxiliary equation is
D2 + 2D + 10 = 0;
its roots are
D = −1 ± 3i,
so the complementary function is
yc = e−t(A cos 3t + B sin 3t).
To ﬁnd a particular solution, we ﬁrst expand f(t) in a Fourier series; from Chapter 7,
equation (7.8), we have
(6.43)
f(t) = 1
2 + 1
iπ [eit −e−it + 1
3(e3it −e−3it) + · · · ].
We next write and solve a whole set of diﬀerential equations like (6.42) but each
having just one term of the series (6.43) on the right-hand side. For the ﬁrst term
(namely 1
2) we see by inspection that a particular solution of
d2y
dt2 + 2dy
dt + 10y = 1
2

Section 6
Second-Order Linear Equations (Nonzero Right-Hand Side)
429
is y =
1
20. All the other terms of (6.43) are of the form (1/ikπ)eikt, where k is a
positive or negative odd integer. To solve
(6.44)
d2y
dt2 + 2dy
dt + 10y =
1
ikπ eikt,
we substitute
(6.45)
y = Ceikt
into (6.44) and get
(−k2 + 2ik + 10)Ceikt =
1
ikπ eikt.
Then we have
(6.46)
C =
1
ikπ
1
(10 −k2) + 2ik =
1
ikπ
(10 −k2) −2ik
(10 −k2)2 + 4k2 .
By letting k = ±1, ±3, · · · , and substituting the values of C thus obtained into
(6.45), we obtain the solutions of (6.44) for the various k values corresponding to
the terms of the series (6.43). The sum of all the solutions corresponding to all the
terms is the desired particular solution of (6.42). Thus
(6.47)
yp = 1
20 + 1
iπ
9 −2i
85
eit −1
iπ
9 + 2i
85
e−it
+
1
3iπ
1 −6i
37
e3it −
1
3iπ
1 + 6i
37
e−3it + · · ·
= 1
20 + 2
π
9
85

eit −e−it
2i

−2
π
2
85

eit + e−it
2

+ 2
3π
1
37

e3it −e−3it
2i

−2
3π
6
37

e3it + e−3it
2

+ · · ·
= 1
20 +
2
85π(9 sin t −2 cost) +
2
111π(sin 3t −6 cos3t) + · · ·
is a particular solution of (6.42).
PROBLEMS, SECTION 6
In Problem 33 to 38, solve the given diﬀerential equations by using the principle of su-
perposition [see the solution of equation (6.29)]. For example, in Problem 33, solve three
diﬀerential equations with right-hand sides equal to the three diﬀerent brackets. Note that
terms with the same exponential factor are kept together; thus a polynomial of any degree
is kept together in one bracket.
33.
y′′ + y = [x3 −1] + [2 cos x] + [(2 −4x)ex]
34.
y′′ −5y′ + 6y = 2ex + 6x −5
35.
(D2 −1)y = sinh x
36.
(D2 + 1)y = 2 sin x + 4x cos x
37.
(D −1)2y = 4ex + (1 −x)(e2x −1)
38.
y′′ −2y′ = 9xe−x −6x2 + 4e2x

430
Ordinary Differential Equations
Chapter 8
39.
Find the solutions of (1.2) (put I = dq/dt) and (1.3), if V = V0 sin ω′t (ω′ =const.).
40.
In (6.38), show that for a given forcing frequency ω′, the displacement y and the
velocity dy/dt have their largest amplitude when ω = ω′.
For a given ω, we have shown in Section 6 that the maximum amplitude of y does
not correspond to ω′ = ω. Show, however, that the maximum amplitude of dy/dt
for a given ω does correspond to ω′ = ω.
State the corresponding results for an electric circuit in terms of L, R, C.
Solve Problems 41 and 42 by use of Fourier series. Assume in each case that the right-hand
side is a periodic function whose values are stated for one period.
41.
y′′ + 2y′ + 2y = |x|,
−π < x < π.
42.
y′′ + 9y =
(
x,
0 < x < 1,
0,
−1 < x < 0.
43.
Consider an equation for damped forced vibrations (mechanical or electrical) in
which the right-hand side is a sum of several forces or emfs of diﬀerent frequencies.
For example, in (6.32) let the right-hand side be
F1eiω′
1t + F2eiω′
2t + F3eiω′
3t.
Write the solution by the principle of superposition. Suppose, for given ω′
1, ω′
2, ω′
3,
that we adjust the system so that ω = ω′
1; show that the principal term in the
solution is then the ﬁrst one. Thus the system acts as a “ﬁlter” to select vibrations
of one frequency from a given set (for example, a radio tuned to one station selects
principally the vibrations of the frequency of that station).
7. OTHER SECOND-ORDER EQUATIONS
Although second-order linear equations with constant coeﬃcients are the ones used
most frequently in applications, there are a few other kinds of second-order equations
and methods of solving them which are also important. We shall discuss several
of these here, namely (a) equations with y missing; (b) equations with x missing;
(c) equations of the form y′′ + f(y) = 0; (d) Euler-Cauchy equations; (e) reduc-
tion of order. For still more methods, see Section 9 (Laplace transforms), Section
12 (Green functions), Problem 12.14b (variation of parameters), and Chapter 12
(special functions, series solutions, ladder operators). You can also ﬁnd computer
solutions but, as we have said, they may not always be in the simplest form or the
form you need. Comparing hand solutions can show you what to expect and help
you make more eﬃcient use of computer solutions.
To solve either (a) or (b), we make the substitution
(7.1)
y′ = p.
Case (a): Dependent variable y missing.
(7.2)
y′ = p,
y′′ = p′.
After these substitutions, an equation of the type (a) is of the ﬁrst order with p

Section 7
Other Second-Order Equations
431
as the dependent variable and x as the independent variable. First, we solve it for
p as a function of x; then we put back p = y′ and solve the resulting ﬁrst-order
equation for y.
Case (b): Independent variable x missing.
(7.3)
y′ = p,
y′′ = dp
dx = dp
dy
dy
dx = pdp
dy .
What we are doing here is to change the independent variable from x to y. Observe
that there is one independent variable in an ordinary diﬀerential equation. We were
originally thinking of x as the independent variable with y and p dy/dx as functions
of x. Now we think of y as the independent variable with p a function of y; (7.3)
is just the chain rule (Chapter 4, Section 5) for diﬀerentiating a function p(y) with
respect to x if y is a function of x. With the substitutions (7.3), a diﬀerential equa-
tion with x missing becomes a ﬁrst-order equation with p as the dependent variable
and y as the independent variable.
Example 1.
In Section 5, we discussed the motion of a mass m subject to a restoring
force −ky and a damping force l(dy/dt). Let us now consider a similar problem but
with the damping force proportional to the square of the velocity. The diﬀerential
equation of motion is then [compare (5.26)]
(7.4)
md2y
dt2 ± l

dy
dt
2
+ ky = 0
(l > 0),
where the plus or minus sign must be chosen correctly at each stage of the motion
so that the retarding force opposes the motion. Let us solve the following special
case of this problem. Discuss the motion of a particle which is released from rest at
the point y = 1 when t = 0, and obeys the equation of motion
(7.5)
4d2y
dt2 ± 2

dy
dt
2
+ y = 0.
This is an example of case (b) (for “x missing” read “t missing,” that is, the inde-
pendent variable missing). Using (7.3) (with x replaced by t), we have
dy
dt = p,
d2y
dt2 = pdp
dy ,
(7.6)
so (7.5) becomes
(7.7)
4pdp
dy ± 2p2 + y = 0
or
dp
dy ± 1
2p = −1
4yp−1.
This is a Bernoulli equation [compare (4.1) with y replaced by p, and P and Q
functions of y]. We have n = −1, and the substitution (4.2) is
(7.8)
z = p2.

432
Ordinary Differential Equations
Chapter 8
Then
dz
dy = 2pdp
dy
and (7.7) becomes
(7.9)
dz
dy ± z = −1
2y.
This is a ﬁrst-order linear equation; solving it (see Section 3), we get
(7.10)
ze±y = −1
2

ye±y dy = −1
2e±y(±y −1) + c,
z = −1
2(±y −1) + ce∓y.
Since initially dy/dt = 0 and y > 0, we see from (7.5) that the initial acceleration is
in the negative direction; since the particle starts from rest, its velocity for small t
is also in the negative direction. Then the damping force must be in the positive
direction so we must use the lower sign in (7.10) for the ﬁrst part of the motion.
Thus we have
(7.11)
z = 1
2(y + 1) + cey
(for small t).
We determine c from the initial conditions dy/dt = 0, y = 1, at t = 0; we have
z = p2 = (dy/dt)2 = 0 when y = 1; therefore from (7.11) we get
0 = 1 + ce,
c = −e−1.
Then we have
(7.12)
z =

dy
dt
2
= 1
2(y + 1) −ey−1
(for small t).
This is a valid solution as long as dy/dt < 0 (this is what small t means). Thus
the particle initially moves in the negative direction for a while. To continue the
problem we would need to ﬁnd whether it stops and if so where. This means solving
a transcendental equation which has to be done by some approximation method.
It turns out that when it stops, y is negative; at this point the force −y is in the
positive direction and the particle, after stopping, moves in the positive direction.
The solution for (dy/dt)2 is then given by (7.10) with the upper sign. After another
interval of time, the particle again reverses its motion and we again use the solution
(7.11) (with a diﬀerent c), and so on, the total motion appearing something like
a damped vibration. We shall not continue the details further here since we have
already accomplished our purpose of illustrating case (b) and the solution of a
Bernoulli equation.

Section 7
Other Second-Order Equations
433
Case (c) appears to be very special and is obviously included by (b); however,
it is very important to know the easy way to solve it because it so frequently arises
in applications. The trick is simply to multiply the equation by y′; we can then
integrate each term.
Case (c): To solve y′′ + f(y) = 0, multiply by y′.
y′y′′ + f(y)y′ = 0,
or
y′ dy′ + f(y) dy = 0.
Then integrate to get
(7.13)
1
2y′2 +

f(y) dy = const.
This equation is separable and so can be solved (except for possible diﬃculty in eval-
uating the integrals). We say that the problem is reduced to quadratures (indicated
integrations); this means that we can write the answer in terms of integrals which
may or may not be easy to evaluate!
Example 2.
Consider a particle of mass m moving along the x axis under the action of a
force F(x). Then the equation of motion is
(7.14)
md2x
dt2 = F(x).
If we multiply this equation by v = dx/dt and integrate with respect to t, we get
mv dv
dt = F(x)dx
dt
or
mv dv = F(x) dx,
1
2mv2 =

F(x) dx + const.
(7.15)
Recall (Chapter 6, Section 8) that the potential energy of a particle is the negative
of the work done by the force. Thus
(7.16)
1
2mv2 −

F(x) dx
is the kinetic energy plus the potential energy; equation (7.15) expresses the law
of conservation of energy for this problem. This energy equation is often of more
interest than the equation of motion (x as a function of t) and so it is useful to be
able to ﬁnd it directly, as we have done, without solving the diﬀerential equation
for x. Equation (7.15) is known as a ﬁrst integral of the diﬀerential equation since
we have integrated a second-order equation once to get it.

434
Ordinary Differential Equations
Chapter 8
Case (d): An equation of the form
(7.17)
a2x2 d2y
dx2 + a1xdy
dx + a0y = f(x)
(called an Euler or Cauchy equation) can be reduced to a linear equation with
constant coeﬃcients by changing the independent variable from x to z where
(7.18)
x = ez.
For then we have (see Problem 14 and also Chapter 4, Section 11)
(7.19)
xdy
dx = dy
dz
and x2 d2y
dx2 = d2y
dz2 −dy
dz .
Substituting (7.18) and (7.19) into (7.17) gives
(7.20)
a2
d2y
dz2 + (a1 −a2)dy
dz + a0y = f(ez).
This is a linear equation with constant coeﬃcients which can be solved by the
methods of Sections 5 and 6.
It is worth noting that the solutions of (7.17) when f(x) = 0 are often powers
of x, so a way to solve this case is to assume y = xk and solve the resulting quadratic
equation for k. However, if the values of k turn out to be complex, or equal, or
if f(x) ̸= 0, you may ﬁnd it easier to use (7.18) which reduces the problem to a
familiar one. (See Problems 15 to 23.)
Case (e): Reduction of order. To ﬁnd a second solution of
(7.21)
y′′ + f(x)y′ + g(x)y = 0
given one solution u(x), substitute
(7.22)
y = u(x)v(x)
into (7.21) and solve for v(x).
You can verify that when you substitute (7.22) into (7.21), the coeﬃcient of v(x)
is u′′ + f(x)u′ + g(x)u. This expression is equal to zero because we assumed that
u(x) is a solution of (7.21). Then the equation for v′(x) is a separable ﬁrst-order
equation (Problem 24).
Example 3.
Solve x3y′′ + xy′ −y = 0, given that u = x is a solution.
We let y = uv = xv. Then y′ = xv′ + v, y′′ = xv′′ + 2v′, and the diﬀerential
equation becomes
x3(xv′′ + 2v′) + x(xv′ + v) −xv = 0
or
x4v′′ + (2x3 + x2)v′ = 0.

Section 7
Other Second-Order Equations
435
Separating variables and integrating, we ﬁnd
dv′
v′ = −

2
x + 1
x2

dx,
ln v′ = −2 ln x + 1
x + ln K.
Solving for v′, integrating again, and writing y = uv gives
v′ = K
x2 e1/x,
v = −Ke1/x,
y = −Kxe1/x.
Thus the general solution of the given equation is y = Ax + Bxe1/x.
PROBLEMS, SECTION 7
Solve the following diﬀerential equations by method (a) or (b) above.
1.
y′′+yy′ = 0. Find a solution satisfying each of the following sets of initial conditions.
If your computer says there is no such solution, don’t believe it—do it by hand.
(a) y(0) = 5,
y′(0) = 0
(b) y(0) = 2,
y′(0) = −2
(c) y(0) = 1,
y′(0) = −1
(d) y(0) = 0,
y′(0) = 2
2.
y′′ + 2xy′ = 0
Hint: The solution is y = c1 erf x + c2; see Chapter 11, Section 9
for the deﬁnition of erf x.
3.
2yy′′ = y′2
4.
xy′′ = y′ + y′3
5.
The diﬀerential equation of a hanging chain supported at its ends is
y′′2 = k2 “
1 + y′2”
.
Solve the equation to ﬁnd the shape of the chain.
6.
The curvature of a curve in the (x, y) plane is
K = y′′ “
1 + y′2”−3/2
.
With K = const., solve this diﬀerential equation to show that curves of constant
curvature are circles (or straight lines).
7.
Solve y′′ + ω2y = 0 by method (c) above and compare with the solution as a linear
equation with constant coeﬃcients.
8.
The force of gravitational attraction on a mass m at distance r from the center of
the earth (r > radius R of the earth) is mgR2/r2. Then the diﬀerential equation of
motion of a mass m projected radially outward from the surface of the earth, with
initial velocity v0, is
md2r/dt2 = −mgR2/r2.
Use method (c) above to ﬁnd v as a function of r if v = v0 initially (that is, when
r = R). Find the maximum value of r for a given v0, that is, the value of r when
v = 0. Find the escape velocity, that is, the smallest value of v0 for which r can tend
to inﬁnity.
9.
Show that (7.15) is a separable equation. [You may ﬁnd it helpful to write
R
F(x) dx =
f(x).] Thus solve (7.14) in terms of quadratures (that is, indicated integrations) as
in Problem 2.

436
Ordinary Differential Equations
Chapter 8
In Problems 10 and 11, solve (7.14) to ﬁnd v(x) and then x(t) for the given F(x) and
initial conditions.
10.
F(x) = m/x3, v = 0, x = 1, at t = 0.
11.
F(x) = −2m/x5, v = −1, x = 1, at t = 0.
12.
In Problem 11, ﬁnd v(x) if v = 0, x = 1, at t = 0. Then write an integral for t(x).
13.
The exact equation of motion of a simple pendulum is d2θ/dt2 = −ω2 sin θ where
ω2 = g/l. By method (c) above, integrate this equation once to ﬁnd dθ/dt if dθ/dt =
0 when θ = 90◦. Write a formula for t(θ) as an integral. See Problem 5.34.
14.
Verify (7.19) and (7.20). Hint: dy/dz = (dy/dx)(dx/dz); write the ﬁrst equation of
(7.19) as xDx = Dz, and ﬁnd D2
z.
15.
If you solve (7.17) when f(x) = 0 by assuming a solution y = xk, show that the
quadratic equation for k is the same as the auxiliary equation for the z equation
(7.20). Thus show (see Section 5) that if the two values of k are equal, the second
solution is not a power of x but is xk ln x.
Also show that if k is complex, say
k = a±bi, the solutions are xa cos(b ln x) and xa sin(b ln x) or other equivalent forms
[see (5.16) to (5.18)].
16.
Solve the following equations either by method (d) above or by assuming y = xk (or
try both methods to compare them). See Problem 15.
(a) x2y′′ + 3xy′ −3y = 0
(b) x2y′′ + xy′ −4y = 0
(c) x2y′′ + 7xy′ + 9y = 0
(d) x2y′′ −xy′ + 6y = 0
Solve the following equations using method (d) above.
17.
x2y′′ + xy′ −16y = 8x4
18.
x2y′′ + xy′ −y = x −x−1
19.
x2y′′ −5xy′ + 9y = 2x3
20.
x2y′′ −3xy′ + 4y = 6x2 ln x
21.
x2y′′ + y = 3x2
22.
x2y′′ + xy′ + y = 2x
23.
Solve the two diﬀerential equations in Problem 5.11 of Chapter 13.
24.
Substitute (7.22) into (7.21) to obtain the equation for v′(x). Show that this equation
is separable.
For the following problems, verify the given solution and then, by method (e) above, ﬁnd
a second solution of the given equation.
25.
x2(2 −x)y′′ + 2xy′ −2y = 0,
u = x
26.
(x2 + 1)y′′ −2xy′ + 2y = 0,
u = x
27.
xy′′ −2(x + 1)y′ + (x + 2)y = 0,
u = ex
28.
3xy′′ −2(3x −1)y′ + (3x −2)y = 0,
u = ex
29.
x2y′′ + (x + 1)y′ −y = 0,
u = x + 1
30.
x(x + 1)y′′ −(x −1)y′ + y = 0,
u = x −1

Section 8
The Laplace Transform
437
8. THE LAPLACE TRANSFORM
As you will see in Section 9, Laplace transforms are useful in solving diﬀerential
equations (for other uses see end of Section 9, page 442). Here we want to deﬁne the
Laplace transform and obtain some needed formulas. We deﬁne L(f), the Laplace
transform of f(t) [also written F(p) since it is a function of p ], by the equation
(8.1)
L(f) =
 ∞
0
f(t)e−pt dt = F(p).
This is an example of an integral transform (also see Fourier transforms, Chapter 7,
Section 12, and Hilbert transforms, Chapter 14, page 698).
If we start with a
function f(t), multiply by a function of t and p, and ﬁnd a deﬁnite integral with
respect to t, we have a function F(p) which is called an integral transform of f(t).
There are many named integral transforms which you may discover in tables and
computer. Observe the notation for Laplace transforms in (8.1): we shall consis-
tently use a small letter for the function of t, and the corresponding capital letter
for the transform which is a function of p, for example f(t) and F(p), or g(t) and
G(p), etc. Also note from (8.1) that since we integrate from 0 to ∞, F(p) is the
same no matter how f(t) is deﬁned for negative t. However, it is desirable to deﬁne
f(t) = 0 for t < 0 (see footnote, page 447; also see Bromwich integral, page 696).
It is very convenient to have a table of corresponding f(t) and F(p) when we
are using Laplace transforms to solve problems. Let us calculate some of the entries
in the table of Laplace transforms at the end of the chapter (pages 469 to 471).
Note that numbers preceded by L (L1, L2, · · · , L35) refer to entries in the Laplace
transform table.
Example 1.
To obtain L1 in the table, we substitute f(t) = 1 into (8.1) and ﬁnd
(8.2)
F(p) =
 ∞
0
1 · e−pt dt = −1
p e−pt

∞
0
= 1
p,
p > 0.
We have assumed p > 0 to make e−pt zero at the upper limit; if p is complex,
as it may be, then the real part of p must be positive (Re p > 0), and this is the
restriction we have stated in the table for L1.
Example 2.
For L2, we have
(8.3)
f(t) = e−at,
F(p) =
 ∞
0
e−(a+p)t dt =
1
p + a,
Re(p + a) > 0.
We could continue in this way to obtain the function F(p) corresponding to
each f(t) by using (8.1) and evaluating the integral. However, there are some easier
methods which we now illustrate. First observe that the Laplace transform of a
sum of two functions is the sum of their Laplace transforms; also the transform of

438
Ordinary Differential Equations
Chapter 8
cf(t) is cL(f) when c is a constant:
(8.4)
L[f(t) + g(t)] =
 ∞
0
[f(t) + g(t)]e−pt dt
=
 ∞
0
f(t)e−pt dt +
 ∞
0
g(t)e−pt dt = L(f) + L(g),
L[cf(t)] =
 ∞
0
cf(t)e−pt dt = c
 ∞
0
f(t)e−pt dt = cL(f).
In mathematical language, we say that the Laplace transform is linear (or is a linear
operator—see Chapter 3, Section 7).
Example 3.
Now let us verify L3. In (8.3), replace the a by −ia; then we have
(8.5)
f(t) = eiat = cos at + i sin at,
F(p) =
1
p −ia = p + ia
p2 + a2 ,
Re(p −ia) > 0.
Remembering (8.4), we can write (8.5) as
(8.6)
L(cos at + i sin at) = L(cos at) + iL(sin at) =
p
p2 + a2 + i
a
p2 + a2 .
Similarly, replacing a by ia in (8.3), we get
(8.7)
L(cos at −i sin at) =
p
p2 + a2 −i
a
p2 + a2 ,
Re(p + ia) > 0.
Adding (8.6) and (8.7), we get L4; by subtracting, we get L3.
Example 4.
To verify L11, start with L4, namely
(8.8)
L(cos at) =
 ∞
0
e−pt cos at dt =
p
p2 + a2 .
Diﬀerentiate (8.8) with respect to the parameter a to get
 ∞
0
e−pt(−t sin at) dt =
p(−2a)
(p2 + a2)2
or
 ∞
0
e−ptt sin at dt =
2pa
(p2 + a2)2
which is L11. Ways of ﬁnding other entries in the table are outlined in the problems.
PROBLEMS, SECTION 8
1.
For integral k, verify L5 and L6 in the Laplace transform table. Hint: From L2, you
can write:
R ∞
0
e−pte−at dt = 1/(p + a). Diﬀerentiate this equation repeatedly with
respect to p. (See Chapter 4, Section 12, Example 4, page 235.) Also note L32. For
the Γ function results in L5 and L6, see Chapter 11, Problem 5.7.
2.
By using L2, verify L7 and L8 in the Laplace transform table.

Section 8
The Laplace Transform
439
3.
Using either L2, or L3 and L4, verify L9 and L10.
4.
By diﬀerentiating the appropriate formula with respect to a, verify L12.
5.
By integrating the appropriate formula with respect to a, verify L19.
6.
By replacing a in L2 by a + ib and then by a −ib, and adding and subtracting the
results [as in (8.6) and (8.7)], verify L13 and L14.
7.
Verify L15 to L18, by combining appropriate preceding formulas using (8.4).
Find the inverse transforms of the functions F(p) in Problems 8 to 13.
8.
1 + p
(p + 2)2
Hint: Use L6 and L18.
9.
5 −2p
p2 + p −2
Hint: Use L7 and L8.
10.
2p −1
p2 −2p + 10
Hint: You can use L7 and L8 with complex a
and b, but L13 and L14 are more direct.
11.
3p + 2
3p2 + 5p −2
12.
3p + 10
p2 −25
13.
6 −p
p2 + 4p + 20
14.
Show that a combination of entries L3 to L10, L13, L14 and L18 in the table, will
give the inverse transform of any function of the form
Ap + B
Cp2 + Ep + F ,
where A, B, C, E, and F are constants.
15.
Prove L32 for n = 1. Hint: Diﬀerentiate equation (8.1) with respect to p.
16.
Use L32 and L3 to obtain L11.
17.
Use L32 and L11 to obtain L(t2 sin at).
18.
Use L31 to derive L21.
Table entries L28 and L29 are known as translation or shifting theorems. Do Problems
19 to 27 about them.
19.
Prove the general formula L29 using (8.1).
20.
Use L29 to verify L6, L13, L14, and L18.
21.
Use L29 and L11 to obtain L(te−at sin bt) which is not in the table.
22.
Obtain L(te−at cos bt) as in Problem 21.
23.
Use the results which you have obtained in Problems 21 and 22 to ﬁnd the inverse
transform of (p2 + 2p −1)/(p2 + 4p + 5)2.
24.
Sketch on the same axes graphs of sin t, sin(t −π/2), and sin(t + π/2), and observe
which way the graph shifts.
Hint:
You can, of course, have your calculator or
computer plot these for you, but it’s simpler and much more useful to do it in your
head. Hint: What values of t make the sines equal to zero? For an even simpler
example, sketch on the same axes y = t, y = t −π/2, y = t + π/2.
25.
Use L28 to ﬁnd the Laplace transform of
f(t) =
sin(t −π/2),
t > π/2,
0,
t < π/2.
26.
Use L28 and L4 to ﬁnd the inverse transform of pe−pπ/(p2 + 1).
27.
Find the transform of
f(t) =
sin(x −vt),
t > x/v,
0,
t < x/v,
where x and v are constants.

440
Ordinary Differential Equations
Chapter 8
9. SOLUTION OF DIFFERENTIAL EQUATIONS BY LAPLACE TRANSFORMS
We are going to discuss the solution of linear diﬀerential equations with constant
coeﬃcients (see Sections 5 and 6). Laplace transforms can reduce such an equation
to an algebraic equation and so simplify solving it. Also, since Laplace transforms
automatically use given values of initial conditions, we ﬁnd immediately a desired
particular solution without the extra step of determining constants to satisfy the
initial conditions. Discontinuous forcing functions are messy to deal with by Section
6 methods; the Laplace transform method handles them easily.
We are going to take Laplace transforms of the terms in diﬀerential equations;
to do this we need to know the transforms of derivatives y′ = dy/dt, y′′ = d2y/dt2,
etc. To ﬁnd L(y′), we use the deﬁnition (8.1) and integrate by parts, as follows
L(y′) =
 ∞
0
y′(t)e−ptdt = e−pty(t)

∞
0
−(−p)
 ∞
0
y(t)e−ptdt
(9.1)
= −y(0) + pL(y) = pY −y0
where for simplicity we have written L(y) = Y and y(0) = y0. To ﬁnd L(y′′), we
think of y′′ as (y′)′, and substitute y′ for y in (9.1) to get
L(y′′) = pL(y′) −y′(0).
Using (9.1) again to eliminate L(y′), we ﬁnally have
(9.2)
L(y′′) = p2L(y) −py(0) −y′(0) = p2Y −py0 −y′
0.
Continuing this process, we obtain the transforms of the higher-order derivatives
(Problem 1 and L35).
We are now ready to solve diﬀerential equations. We illustrate the method by
some examples.
Example 1.
Solve y′′ + 4y′ + 4y = t2e−2t with initial conditions y0 = 0, y′
0 = 0.
We take the Laplace transform of each term in the equation, using L35 and L6
in the table of Laplace transforms. We get
p2Y −py0 −y′
0 + 4pY −4y0 + 4Y = L(t2e−2t) =
2
(p + 2)3 .
But the initial conditions are y0 = y′
0 = 0. Thus we have
(p2 + 4p + 4)Y =
2
(p + 2)3
or
Y =
2
(p + 2)5 .
Now we want y, which is the inverse Laplace transform of Y . We look in the table
for the inverse transform of 2/(p + 2)5. By L6, we get
y = 2t4e−2t
4!
= t4e−2t
12
.
This is much simpler than the general solution; we have obtained just the solution
satisfying the given initial conditions.

Section 9
Solution of Differential Equations by Laplace Transforms
441
Example 2.
Solve y′′ + 4y = sin 2t, subject to the initial conditions y0 = 10, y′
0 = 0.
Using the table, take the Laplace transform of each term of the equation to get
p2Y −py0 −y′
0 + 4Y = L(sin 2t) =
2
p2 + 4.
Then we substitute the initial conditions and solve for Y as follows:
(p2 + 4)Y −10p =
2
p2 + 4,
Y =
10p
p2 + 4 +
2
(p2 + 4)2 .
Finally, taking the inverse transform using L4 and L17, we have the desired solution:
y = 10 cos2t + 1
8(sin 2t −2t cos 2t) = 10 cos2t + 1
8 sin 2t −1
4t cos 2t.
Example 3.
Solve y′′ + 4y′ + 13y = 20e−t,
y0 = 1, y′
0 = 3.
We take the transform of each term and solve for Y as follows:
p2Y −p −3 + 4pY −4 + 13Y =
20
p + 1,
Y =
1
p2 + 4p + 13

 20
p + 1 + p + 7

=
p2 + 8p + 27
(p + 1)(p2 + 4p + 13).
Since this Y is not in our table, we can either use a larger table, or use partial
fractions to split Y into fractions which are in our table (which you can do by
computer) or ﬁnd the inverse transform by computer. We ﬁnd:
Y =
2
p + 1 +
−p + 1
p2 + 4p + 13 =
2
p + 1 +
3
(p + 2)2 + 9 −
p + 2
(p + 2)2 + 9
and by L2, L13, and L14,
y = 2e−t + e−2t sin 3t −e−2t cos 3t.
Sets of simultaneous diﬀerential equations can also be solved by using Laplace
transforms. Here is an example.
Example 4.
Solve the set of equations
y′ −2y + z = 0,
z′ −y −2z = 0,
subject to the initial conditions y0 = 1, z0 = 0.
We shall call L(z) = Z and L(y) = Y as before. We take the Laplace transform
of each of the equations to get
pY −y0 −2Y + Z = 0,
pZ −z0 −Y −2Z = 0.

442
Ordinary Differential Equations
Chapter 8
After substituting the initial conditions and collecting terms, we have
(p −2)Y + Z = 1,
Y −(p −2)Z = 0.
We solve this set of algebraic equations simultaneously for Y and Z (by any of the
methods usually used for a pair of simultaneous equations—elimination, determi-
nants, etc.). For example, we may multiply the ﬁrst equation by (p −2) and add
the second to get
[(p −2)2 + 1]Y = p −2
or
Y =
p −2
(p −2)2 + 1.
We ﬁnd y by looking up the inverse transform of Y using L14. We get
y = e2t cos t.
Similarly, solving for Z and looking up the inverse transform, we ﬁnd
Z =
1
(p −2)2 + 1,
z = e2t sin t
. Alternatively, we could ﬁnd z from the ﬁrst diﬀerential equation by substituting
the y solution:
z = 2y −y′ = 2e2t cos t + e2t sin t −2e2t cos t = e2t sin t.
Solving linear diﬀerential equations with constant coeﬃcients is not the only use
of Laplace transforms. As you will see in Chapter 13, Section 10, we may solve some
kinds of partial diﬀerential equations by Laplace transforms. Also a table of Laplace
transforms can be used to evaluate deﬁnite integrals of the type
 ∞
0
e−ptf(t)dt.
Example 5.
By L15 with a = 3 and p = 2, we have
 ∞
0
e−2t(1 −cos 3t) dt =
32
2(22 + 32) = 9
26.
Actually, there is more to the subject than this. Although we are discussing
in this chapter the use of Laplace transforms as a tool, they also can play a more
theoretical role in applied problems. It is often possible to ﬁnd desired information
about a problem directly from the Laplace transform of the solution without ever
ﬁnding the solution.
Thus the use of Laplace transforms may lead to a better
understanding of a problem or a simpler method of solution. (Compare the use of
matrices, for example, or the use of Fourier transforms.)
PROBLEMS, SECTION 9
1.
Continuing the method used in deriving (9.1) and (9.2), verify the Laplace trans-
forms of higher-order derivatives of y given in the table (L35).
By using Laplace transforms, solve the following diﬀerential equations subject to the given
initial conditions.
2.
y′ −y = 2et,
y0 = 3

Section 9
Solution of Differential Equations by Laplace Transforms
443
3.
y′′ + 4y′ + 4y = e−2t,
y0 = 0, y′
0 = 4
4.
y′′ + y = sin t,
y0 = 1, y′
0 = 0
5.
y′′ + y = sin t,
y0 = 0, y′
0 = −1
2
6.
y′′ −6y′ + 9y = te3t,
y0 = 0, y′
0 = 5
7.
y′′ −4y′ + 4y = 4,
y0 = 0, y′
0 = −2
8.
y′′ + 16y = 8 cos 4t,
y0 = y′
0 = 0
9.
y′′ + 16y = 8 cos 4t,
y0 = 0, y′
0 = 8
10.
y′′ −4y′ + 4y = 6e2t,
y0 = y′
0 = 0
11.
y′′ −4y = 4e2t,
y0 = 0, y′
0 = 1
12.
y′′ −y = e−t −2te−t,
y0 = 1, y′
0 = 2
13.
y′′ + y = 5 sinh 2t,
y0 = 0, y′
0 = 2
14.
y′′ −4y′ = −4te2t,
y0 = 0, y′
0 = 1
15.
y′′ + 9y = cos 3t,
y0 = 0, y′
0 = 6
16.
y′′ + 9y = cos 3t,
y0 = 2, y′
0 = 0
17.
y′′ + 5y′ + 6y = 12,
y0 = 2, y′
0 = 0
18.
y′′ −4y = 3e−t,
y0 = 1, y′
0 = −3
19.
y′′ + y′ −5y = e2t,
y0 = 1, y′
0 = 2
20.
y′′ −8y′ + 16y = 32t,
y0 = 1, y′
0 = 2
21.
y′′ + 4y′ + 5y = 26e3t,
y0 = 1, y′
0 = 5
22.
y′′+2y′+5y = 10 cos t,
y0 = 2, y′
0 = 1
23.
y′′+2y′+5y = 10 cos t,
y0 = 0, y′
0 = 3
24.
y′′ −2y′ + y = 2 cos t,
y0 = 5, y′
0 = −2
25.
y′′ + 4y′ + 5y = 2e−2t cos t,
y0 = 0, y′
0 = 3
26.
y′′ + 2y′ + 10y = −6e−t sin 3t,
y0 = 0, y′
0 = 1
Solve the following sets of equations by the Laplace transform method.
27.
y′ + z′ −3z = 0
y0 = y′
0 = 0
y′′ + z′ = 0
z0 = 4
3
28.
y′ + z = 2 cos t
y0 = −1
z′ −y = 1
z0 = 1
29.
y′ + z′ −2y = 1
y0 = z0 = 1
z −y′ = t
30.
y′ + 2z = 1
y0 = 0
2y −z′ = 2t
z0 = 1
31.
y′′ + z′′ −z′ = 0
y0 = 0,
y′
0 = 1
y′ + z′ −2z = 1 −et
z0 = 1,
z′
0 = 1
32.
z′ + 2y = 0
y0 = z0 = 0
y′ −2z = 2

444
Ordinary Differential Equations
Chapter 8
33.
y′ −z′ −y = cos t
y0 = −1
y′ + y −2z = 0
z0 = 0
Evaluate each of the following deﬁnite integrals by using the Laplace transform table.
34.
Z ∞
0
e−2t sin 3t dt =
3
13. Hint: In (8.1), let p = 2, f(t) = sin 3t; use L3 with a = 3.
35.
Z ∞
0
te−t sin 5t dt
36.
Z ∞
0
e−3t sin 2t
t
dt
37.
Z ∞
0
t5e−2t dt
38.
Z ∞
0
e−t(1 −cos 2t) dt
39.
Z ∞
0
e−t −e−2t
t
dt
40.
Z ∞
0
e−2t −e−2et
t
dt
41.
Z ∞
0
1
t e−2t sin(t
√
2 ) dt
42.
Z ∞
0
1
t e−t
√
3 sin 2t cos t dt
10. CONVOLUTION
In solving diﬀerential equations by Laplace transforms in Section 9, we found Y
and then found the inverse transform y either in a table or by computer. We had
no way of writing a formula for y. We now want to consider another way of ﬁnding
inverse transforms. (Also see Bromwich integral, Chapter 14, page 696.)
Let us ﬁrst see why the method we are going to discuss in this section is useful.
Consider diﬀerential equations of the kind discussed in Sections 5 and 6, namely
linear second-order equations with constant coeﬃcients. Recall that such equations
describe the vibrations or oscillations of either a mechanical or an electrical system.
If the right-hand side of the equation is a function of t, called the forcing function,
then the diﬀerential equation describes forced vibrations.
Example 1.
Let us solve the following representative equation by Laplace transforms,
assuming that the system is initially at rest and that the force f(t) starts being
applied at t = 0.
(10.1)
Ay′′ + By′ + Cy = f(t),
y0 = y′
0 = 0.
We take the Laplace transform of each term, substitute the initial conditions, and
solve for Y as follows:
(10.2)
Ap2Y + BpY + CY = L(f) = F(p),
Y =
1
Ap2 + Bp + C F(p).
Note that Y is a product of two functions of p. We know the inverse transform
of F(p), namely f(t). The factor T (p) = (Ap2 + Bp + C)−1 (called the transfer
function) can always be written as
T (p) =
1
A(p + a)(p + b)
by factoring the quadratic expression in the denominator. Hence by L7 (or L6
if a = b) we can ﬁnd the inverse transform of T (p) for any problem.
Then y

Section 10
Convolution
445
[the inverse transform of Y in (10.2)] is the inverse transform of a product of two
functions whose inverse transforms we know. We are going to show how to write y
as an integral (that is, we are going to verify L34 in the table).
Let G(p) and H(p) be the transforms of g(t) and h(t). We want the inverse
transform of the product G(p)H(p). By the deﬁnition (8.1)
(10.3)
G(p)H(p) =
 ∞
0
e−ptg(t) dt ·
 ∞
0
e−pth(t) dt.
Let us rewrite (10.3) replacing t by diﬀerent dummy variables of integration so that
we can write the product of the two integrals as a double integral. We then have
G(p)H(p) =
 ∞
0
e−pσg(σ) dσ ·
 ∞
0
e−pτh(τ) dτ
(10.4)
=
 ∞
0
 ∞
0
e−p(σ+τ)g(σ)h(τ) dσ dτ.
Now we make a change of variables; in the σ integral (that is, with τ ﬁxed), let
σ +τ = t. Then σ = t−τ, dσ = dt, and the range of integration with respect to t is
from t = τ (corresponding to σ = 0) to t = ∞(corresponding to σ = ∞). Making
these substitutions into (10.4), we get
(10.5)
G(p)H(p) =
 ∞
τ=0
 ∞
t=τ
e−ptg(t −τ)h(τ) dt dτ.
Figure 10.1
Next we want to change the order of
integration. From Figure 10.1, we see
that the double integral in (10.5) is over
the triangle in the ﬁrst quadrant below
the line t = τ.
The t integral ranges
from the line t = τ to t = ∞(indi-
cated by a horizontal strip of width dτ
from t = τ to ∞) and then the τ inte-
gral sums over the horizontal strips from
τ = 0 to τ = ∞covering the whole
inﬁnite triangle. Let us integrate with
respect to τ ﬁrst; τ then ranges from 0
to the line τ = t [indicated by a vertical
strip in Figure 10.1] and then the t integral sums over the vertical strips from t = 0
to ∞. Making this change in (10.5), we get
G(p)H(p) =
 ∞
t=0
 t
τ=0
e−ptg(t −τ)h(τ) dτ dt
(10.6)
=
 ∞
0
e−pt
 t
0
g(t −τ)h(τ) dτ

dt
= L
 t
0
g(t −τ)h(τ) dτ

.
(See L34.)
The last step follows from the deﬁnition (8.1) of a Laplace transform.

446
Ordinary Differential Equations
Chapter 8
Deﬁnition of Convolution
The integral
(10.7)
 t
0
g(t −τ)h(τ) dτ = g ∗h
is called the convolution of g and h (or the resultant or the Faltung). Note the
abbreviation g ∗h for the convolution integral, and do not confuse the symbol ∗,
written on the line, with a star used as a superscript meaning complex conjugate.
It is easy to show (Problem 1) that g ∗h = h ∗g; this result and (10.6) and (10.7)
give L34 in the table.
Now let’s see how to use (10.6) or L34 to solve the kind of problem indicated in
(10.1) and (10.2).
Example 2.
Solve y′′ + 3y′ + 2y = e−t,
y0 = y′
0 = 0.
Taking the Laplace transform of each term, substituting the initial conditions,
and solving for Y , we get
p2Y + 3pY + 2Y = L(e−t),
Y =
1
p2 + 3p + 2L(e−t).
Since we are intending to use the convolution integral, we do not bother to look up
the transform of e−t. We do want, however, the inverse transform of 1/(p2+3p+2);
by L7, this is e−t −e−2t, so we have
Y = L(e−t −e−2t)L(e−t) = G(p)H(p),
with g(t) = e−t −e−2t and h(t) = e−t. We now use L34 to ﬁnd y. Observe from
L34 that we may use either g(t −τ)h(τ) or g(τ)h(t −τ) in the integral. It is well
to choose whichever form is easier to integrate; usually it is best to put (t −τ) in
the simpler function [here h(t)]. Then we have
y =
 t
0
g(τ)h(t −τ) dτ =
 t
0
(e−τ −e−2τ)(e−(t−τ) dτ
= e−t
 t
0
(1 −e−τ) dτ = e−t(τ + e−τ)

t
0
= e−t(t + e−t −1) = te−t + e−2t −e−t.
It is not always as easy to evaluate the convolution integral as it was in this
example. However, let us observe that, at the very worst, we can always write the
solution to a forced vibrations problem [equation (10.1)] as an integral (which can,
if necessary, be evaluated numerically). This is true because, as we showed just
after (10.2), we can always ﬁnd the inverse transform of the transfer function T (p),
and so have Y as a product of two functions whose inverse transforms we know.
Then y is given by the convolution (10.7) of the forcing function f(t) and the inverse
transform of the the transfer function. Also note (Problem 16) that a combination
of L6, L7, L8 and L18 will handle any terms arising in a problem with nonzero
initial conditions.

Section 10
Convolution
447
Fourier Transform of a Convolution
We have shown that the Laplace trans-
form of the convolution of two functions is the product of their Laplace transforms.
There is a similar theorem for Fourier transforms; let us see what it says. Let g1(α)
and g2(α) be the Fourier transforms of f1(x) and f2(x). By analogy with equa-
tions (10.3), (10.4), (10.5), and (10.6), we might expect the product g1(α) · g2(α)
to be the Fourier transform of something; let’s investigate this idea. Assuming that
 ∞
−∞|f1(x)f2(x)|dx is ﬁnite, then by the deﬁnition of a Fourier transform [Chapter 7,
equation (12.2)], we have
g1(α) · g2(α) = 1
2π
 ∞
−∞
f1(v)e−iαv dv · 1
2π
 ∞
−∞
f2(u)e−iαu du
(10.8)
=

 1
2π
2  ∞
−∞
 ∞
−∞
e−iα(v+u)f1(v)f2(u) dv du.
[We have used diﬀerent dummy integration variables as in (10.4).] Next we make
the change of variables x = v + u, dx = dv, in the v integral, to get
g1(α)g2(α) =

 1
2π
2  ∞
−∞
 ∞
−∞
e−iαxf1(x −u)f2(u) dx du
(10.9)
=

 1
2π
2  ∞
−∞
e−iαx
 ∞
−∞
f1(x −u)f2(u) du

dx.
If we deﬁne the convolution of f1(x) and f2(x) by
(10.10)
f1 ∗f2 =
 ∞
−∞
f1(x −u)f2(u) du, †
then (10.9) becomes
(10.11) g1 · g2 = 1
2π
 1
2π
 ∞
−∞
f1 ∗f2 e−iαx dx

= 1
2π · Fourier transform of f1 ∗f2.
In other words,
(10.12)
g1 · g2 and 1
2π f1 ∗f2 are a pair of Fourier transforms.
Because of the symmetry of the f(x) and g(α) integrals, there is a similar result
relating f1 · f2 and the convolution of g1 and g2. We ﬁnd that (Problem 19)
(10.13)
g1 ∗g2 and f1 · f2 are a pair of Fourier transforms.
As discussed in Chapter 7, after (12.2) and after (12.10), various references diﬀer
†Note that (10.10) is really the same as (10.7) if we agree that, for Laplace transforms, f(t) = 0
when t < 0 (see the ﬁrst paragraph of Section 8, page 437). For then in (10.7), h(τ) = 0 for τ < 0
and g(t −τ) = 0 for τ > t, so the integral would not really be diﬀerent if written with inﬁnite
limits (in fact, it is sometimes written that way).

448
Ordinary Differential Equations
Chapter 8
in the position of the factor 1/(2π).
Some authors include factors of 1/(2π) or
1/
√
2π in the convolution deﬁnition (10.10); this deﬁnition as well as Chapter 7,
equation (12.2), aﬀects (10.12) and (10.13). Check the notation in any reference
you are using.
PROBLEMS, SECTION 10
1.
Show that g ∗h = h ∗g as claimed in L34. Hint: Let u = t −τ in (10.7).
2.
Use L34 and L2 to ﬁnd the inverse transform of G(p)H(p) when G(p) = 1/(p + a)
and H(p) = 1/(p + b); your result should be L7.
Use the convolution integral to ﬁnd the inverse transforms of:
3.
p
(p2 −1)2 =
p
p2 −1 ·
1
p2 −1
4.
1
(p + a)(p + b)2
5.
p
(p + a)(p + b)2
6.
1
(p + a)(p2 −b2)
7.
p
(p + a)(p2 −b2)
8.
1
(p + a)(p + b)(p + c)
9.
2
p3(p + 2)
10.
1
p(p2 + a2)2
11.
p
(p2 + a2)(p2 + b2)
12.
1
p(p2 + a2)(p2 + b2)
Hint: In Problems 11 and 12 use 2 sin θ cos φ = sin(θ + φ) + sin(θ −φ).
13.
Use the Laplace transform table to ﬁnd f(t) =
R t
0 e−τ sin(t −τ) dτ. Hint: In L34,
let g(t) = e−t and h(t) = sin t, and ﬁnd G(p)H(p) which is the Laplace transform of
the integral you want. Break the result into partial fractions and look up the inverse
transforms.
Use the convolution integral (see Example 2) to solve the following diﬀerential equations.
14.
y′′ + 5y′ + 6y = e−2t,
y0 = y′
0 = 0.
15.
y′′ + 3y′ −4y = e3t,
y0 = y′
0 = 0.
16.
Consider solving an equation like (10.1) but with nonzero initial conditions.
(a)
Write the corrected form of (10.2), writing the transfer function in factored
form as indicated just after (10.2). Consider the extra terms in Y which arise
from the initial conditions; show that the inverse transforms of such terms can
always be found from L6, L7, L8, and L18.
(b)
Find the explicit form of the inverse transform of the transfer function for
a ̸= b (use L7), and so write the general solution of (10.2) with nonzero initial
conditions as a convolution integral plus the terms which you found in (a).
17.
Solve the diﬀerential equation y′′ −a2y = f(t), where
f(t) =
0,
t < 0,
1,
t > 0,
and y0 = y′
0 = 0.
Hint: Use the convolution integral as in the example.

Section 11
The Dirac Delta Function
449
18.
A mechanical or electrical system is described by the diﬀerential equation
y′′ + ω2y = f(t). Find y if
f(t) =
1,
0 < t < a,
0,
otherwise,
and
y0 = y′
0 = 0.
Hint: Use the convolution integral carefully. Consider t < a and t > a separately,
remembering that f(t) = 0 for t > a. Show that
y =
8
>
<
>
:
1
ω2 (1 −cos ωt),
t < a,
1
ω2 [cos ω(t −a) −cos ωt],
t > a.
Sketch the motion if a = 1
3T where T is the period for free vibrations of the system;
if a = 3
2T; if a =
1
10T .
19.
Following the method of equations (10.8) to (10.12), show that f1f2 and g1 ∗g2 are
a pair of Fourier transforms.
11. THE DIRAC DELTA FUNCTION
In mechanics we consider the idea of an impulsive force such as a hammer blow
which lasts for a very short time. We usually do not know the exact shape of the
force function f(t), and so we proceed as follows. Let the impulsive force f(t) lasting
from t = t0 till t = t1 be applied to a mass m; then by Newton’s second law we
have
(11.1)
 t1
t0
f(t) dt =
 t1
t0
mdv
dt dt =
 v1
v0
m dv = m(v1 −v0).
Figure 11.1
This says that the integral of f(t) [called the impulse of f(t)]
is equal to the change in the momentum of m, and we note
that the result is independent of the shape of f(t) but de-
pends only on the area under the f(t) curve. If this area is 1,
we call the impulse a unit impulse. If t1−t0 is very small, we
may simply ignore the motion of m during this small time,
and say only that the momentum jumped from mv0 to mv1
during the time t1 −t0. If v0 = 0, the graph of the momentum as a function of time
would be as in Figure 11.1, where we have simply omitted the (unknown) part of
the graph between t0 and t1. We note that if t1 −t0 is very small, the graph in
Figure 11.1 is almost the unit step function (L24). Let us imagine making t1 −t0
smaller and smaller while keeping the jump in mv always 1.
In Figures 11.2, 11.3 and 11.4 we have sketched some possible sequences of func-
tions fn(t) which would do this. We could draw many other similar sets of graphs;
the essential requirement is that f(t) should become taller and narrower (that is,
that the force should become more intense but act over a shorter time) in such a
way that the impulse [area under the f(t) curve] remains 1. We might then consider
the limiting case in which Figure 11.1 has a jump of 1 at t0; the force f(t) required
to produce this result would have to be inﬁnite and act instantaneously. Also from
equation (11.1), we see that the function f(t) is the slope of the mv graph; thus
we are asking for f(t) to be the derivative of a step function at the jump. We see
immediately that no ordinary function has these properties. However, we also note

450
Ordinary Differential Equations
Chapter 8
Figure 11.2
that we are not so much interested in f(t) as in the results it produces. Figure 11.1
with a jump at t0 makes perfectly good sense; for any t > t0 we could choose a
suﬃciently tall and narrow fn(t) so that mv would already have its ﬁnal value.
We shall see that it is convenient to introduce a symbol δ(t −t0) to represent the
force which produces a jump of 1 in mv at t0; δ(t −t0) is called the Dirac delta
function although it is not an ordinary function as we have seen. (It may properly
be called a generalized function or a distribution, and is one of a whole class of
such functions.) Introducing and using this symbol is much like introducing and
using the symbol ∞. It is convenient to write equations like 1/∞= 0, but we must
not write ∞/∞= 1; that is, such symbolic equations must be abbreviations for
correct limiting processes. Let us investigate, then, how we can use the δ function
correctly.
Example 1.
Consider the diﬀerential equation
(11.2)
y′′ + ω2y = f(t),
y0 = y′
0 = 0.
This equation might describe the oscillations of a mass suspended by a spring, or
a simple series electric circuit with negligible resistance. Let us assume that the
system is initially at rest (y0 = y′
0 = 0); then suppose that, at t = t0 the mass is
struck a sharp blow, or a sudden short surge of current is sent through the elec-
tric circuit. The function f(t) may be one of those shown in Figures 11.2 to 11.4
or another similar function. Let us solve (11.2) with f(t) equal to one of the func-
tions in Figure 11.3, that is, f(t) = ne−n(t−t0), t > t0. Using Laplace transforms L28

Section 11
The Dirac Delta Function
451
Figure 11.3
and L2 we ﬁnd
(11.3)
(p2 + ω2)Y = L(ne−n(t−t0)) = n · e−pt0
p + n,
Y = n ·
e−pt0
(p + n)(p2 + ω2) =
ne−pt0
(n2 + ω2)

1
p + n +
n
p2 + ω2 −
p
p2 + ω2

.
(You can easily verify the partial fractions expansion in the last step.) Then by L28
with a = t0, L2 with a = n, and L3, L4, with a = ω , we ﬁnd:
(11.4)
y = n

e−n(t−t0)
n2 + ω2 + n sin ω(t −t0)
(n2 + ω2)ω
−cos ω(t −t0)
n2 + ω2

,
t > t0.
(Of course, y = 0 for t < t0.) By making f(t) suﬃciently narrow and peaked (that
is, by making n large enough), we can make the ﬁrst and third terms in y negligible,
and the coeﬃcient of sin ω(t −t0) approximately equal to 1/ω. Thus the solution
is approximately
(11.5)
y = 1
ω sin ω(t −t0),
t > t0,
for a unit impulse of very short duration at t = t0. (We have shown this only for
the functions of Figure 11.3; however, the same result would be found for other sets
of functions, such as those in Figure 11.4, for example—see Problem 5.)

452
Ordinary Differential Equations
Chapter 8
Figure 11.4
Now we would like to be able to ﬁnd (11.5) without ﬁnding (11.4), in fact,
without choosing a speciﬁc set of functions fn(t). Our discussion above suggests
that we try using the symbol δ(t −t0) for f(t) on the right-hand side of (11.2). In
solving the equation, we would then like to take the Laplace transform of δ(t −t0).
Laplace Transform of a δ Function
Let us investigate whether we can make
sense out of the Laplace transform of δ(t −t0). More generally, let us try to attach
meaning to the integral

φ(t)δ(t −t0) dt, where φ(t) is any continuous function
and δ(t −t0) is the symbol indicating an impulse at t0. We consider the integrals

φ(t)fn(t−t0) dt, where the functions fn(t−t0) are more and more strongly peaked
at t0 as n increases (Figure 11.5), but the area under each graph is 1. When fn(t−t0)
is so narrow that φ(t) is essentially constant [equal to φ(t0)] over the width of
fn(t −t0), the integral becomes nearly φ(t0)

fn(t −t0) dt = φ(t0) · 1 = φ(t0); that
is, the sequence of integrals

φ(t)fn(t −t0) dt tends to φ(t0) as n tends to inﬁnity.
It then seems reasonable to say that
(11.6)
 b
a
φ(t)δ(t −t0) dt =
 φ(t0),
a < t0 < b,
0,
otherwise.
Equation (11.6) is the deﬁning equation for the δ function; when we operate with δ
functions, we use them in integrals and (11.6) tells us the value of the integral. The
integral in (11.6) is not a Riemann integral; it is just a very useful symbol indicating
that we have found the limit of  φ(t)fn(t −t0) dt as n →∞. You may then ask
how we can carry out familiar operations like integration by parts. When you treat
an integral containing a δ function as an ordinary integral, you can, if you like, think

Section 11
The Dirac Delta Function
453
Figure 11.5
that you are really working with the functions fn(t −t0) and then taking the limit
at the end. Of course, all this needs mathematical justiﬁcation which exists but
is beyond our scope. (For two diﬀerent mathematical developments of generalized
functions, see Lighthill, and Chapter 9 of Folland.) Our purpose is just to make
understandable the δ function formulas which are so useful in applications.
Example 2.
We can now easily ﬁnd the Laplace transform of δ(t −t0). In the notation
used in L27 (which we are about to derive), we have, using (8.1),
(11.7)
L[δ(t −a)] =
 ∞
0
δ(t −a)e−pt dt = e−pa,
a > 0,
since, by 11.6, the integral of the product of δ(t −a) and a function “picks out”
the value of the function at t = a. Now let us use our results to obtain (11.5) more
easily.
Example 3.
Solve
(11.8)
y′′ + ω2y = δ(t −t0),
y0 = y′
0 = 0.
Taking Laplace transforms and using (11.7), we get
(11.9)
(p2 + ω2)Y = L[δ(t −t0)] = e−pt0.
Then
(11.10)
Y =
e−pt0
p2 + ω2
and, by L3 and L28,
(11.11)
y = 1
ω sin ω(t −t0),
t > t0,
as in (11.5).

454
Ordinary Differential Equations
Chapter 8
Fourier Transform of a δ Function
Using (11.6) and the deﬁnition of a Fourier
transform [Chapter 7, equation (12.2)], we may write
(11.12)
g(α) = 1
2π
 ∞
−∞
δ(x −a)e−iαx dx = 1
2π e−iαa.
Formally, then (12.2) of Chapter 7 would give for the inverse transform
(11.13)
δ(x −a) = 1
2π
 ∞
−∞
eiα(x−a)dα.
We say “formally” because the integral in (11.13) does not converge. However, if we
replace the limits −∞, ∞by −n, n, we obtain a set of functions (Problem 12) which,
like the functions fn(t) in Figures 11.2 to 11.4, are increasingly peaked around x = a
as n increases, but all have area 1. In this sense, then, (11.13) is a representation
of the δ function. Equations (11.12) and (11.13) are useful in quantum mechanics.
Another Physical Application of δ functions
What is the density (mass per
unit length) of a point mass on the x axis? Compare the concept of a point mass
with our discussion of δ functions. We could think of a point mass as corresponding
to the limiting case of a density function like those in Figures 11.2 to 11.4. A point
mass at x = a requires that the density be zero everywhere except at x = a but the
integral of the density function across x = a should be the mass m. Thus we can
write the density function for a point mass m at x = a as mδ(x −a). Similarly, we
can represent the charge density for point electrical charges using δ functions.
Example 4.
The charge density for a charge of 2 at x = 3, a charge of −5 at x = 7 and a
charge of 3 at x = −4 would be 2δ(x −3) −5δ(x −7) + 3δ(x + 4).
Derivatives of the δ Function
To see that we can attach a meaning to the
derivative of δ(x −a), we write
 ∞
−∞φ(x)δ′(x −a) dx and integrate by parts to get
(11.14)
 ∞
−∞
φ(x)δ′(x−a) dx = φ(x)δ(x−a)

∞
−∞
−
 ∞
−∞
φ′(x)δ(x−a) dx = −φ′(a).
The integrated term is zero at ±∞, and we evaluated the integral using equation
(11.6). Thus, just as δ(x −a) “picks out” the value of φ(x) at x = a [see equation
(11.6)], so δ′(x −a) picks out the negative of φ′(x) at x = a. Integrating by parts
twice (Problem 14), we ﬁnd
(11.15)
 ∞
−∞
φ(x)δ′′(x −a) dx = φ′′(a).
Repeated integrations by parts gives the formula for the derivative of any order of
the δ function (Problem 14):
(11.16)
 ∞
−∞
φ(x)δ(n)(x −a) dx = (−1)nφ(n)(a).
We have written the integrals in (11.14) to (11.16) with limits −∞to ∞, but all
that is necessary is that the range of integration include x = a; otherwise, as for
(11.6), the integrals are zero.

Section 11
The Dirac Delta Function
455
Some Formulas Involving δ Functions
Our discussion at the beginning of this
section (see Figure 11.1 and L24 in the Laplace transform table) implied that the
derivative at x = a of the unit step function ought to be δ(x −a).
(a)
u(x −a) =

1,
x > a
0,
x < a
(b)
u′(x −a) = δ(x −a).
(11.17)
What does the u′ = δ equation mean? By deﬁnition, two generalized functions (dis-
tributions) are equal, say G1(x) = G2(x) , if

φ(x)G1 dx =

φ(x)G2 dx for any test
function φ(x). Test functions are assumed to be very well behaved functions; let’s
assume that they are continuous with continuous derivatives of all orders and that
they are identically zero outside some ﬁnite interval so that the integrated term in an
integration by parts is always zero. You can think of generalized functions as being
operators; given a test function φ(x), they “operate” on it to produce a value such as
φ(0). Compare the diﬀerential operators in Problem 5.31. We wrote Dx = xD + 1
where D = d/dx. This would be nonsense as an elementary calculus formula, but as
an operator equation to be applied to y(x), it means D(xy) = (xD + 1)y = xy′ + y
which is correct. In a similar way, two generalized functions are equal if they give
the same results when they operate on any test function. Let’s try this for (11.17b).
We multiply u′ by φ(x), integrate by parts (noting that the integrated term is zero
because we require test functions to be zero for large |x|), substitute the values of
u(x −a), and integrate again to get
 ∞
−∞
φ(x)u′(x −a) dx = −
 ∞
−∞
φ′(x)u(x −a) dx = −
 ∞
a
φ′(x) dx = φ(a).
This is indeed the value of the integral of φ(x)δ(x −a), so u′(x −a) = δ(x −a) is a
valid operator equation (generalized function equation).
Since we think of δ(x) and its derivatives as being zero except at the origin,
and x is zero at the origin, it might seem plausible that xδ, x2δ, xδ′, etc. would be
identically zero. It turns out that some of these are zero and some are not; to ﬁnd
out, we multiply by an arbitrary test function φ(x) and integrate. We state a few
results; also see Problems 17 and 18.
(a)
xδ(x) = 0
(b)
xδ′(x) = −δ(x)
(11.18)
(c)
x2δ′′(x) = 2δ(x)
To check (b), we multiply by φ(x) and integrate using (11.14) with φ(x) replaced
by xφ(x).
 ∞
−∞
xδ′(x)φ(x) dx = −(xφ)′

x=0
= −(xφ′ + φ)

x=0
= −φ(0) = −
 ∞
−∞
δ(x)φ(x) dx.
Here is another way to produce valid generalized function identities like those in
(11.18). Suppose G1(x) = G2(x); then we can show (Problem 19a) that
d
dxG1(x) =
d
dxG2(x) and xnG1(x) = xnG2(x). For example, if we diﬀerentiate (11.18a) we get
xδ′(x) + δ(x) = 0, or xδ′(x) = −δ(x) which is (11.18b).

456
Ordinary Differential Equations
Chapter 8
We list a few more operator equations (see Problems 20 and 21).
(a)
δ(−x) = δ(x) and δ(x −a) = δ(a −x);
(b)
δ′(−x) = −δ′(x) and δ′(x −a) = −δ′(a −x);
(c)
δ(ax) = 1
|a| δ(x), a ̸= 0;
(11.19)
(d)
δ[(x −a)(x −b)] =
1
|a −b|[δ(x −a) + δ(x −b)], a ̸= b;
(e)
δ[f(x)] =

i
δ(x −xi)
|f ′(xi)|
if f(xi) = 0 and f ′(xi) ̸= 0.
We ﬁrst prove (c) when a is negative, say a = −b, b > 0. Let u = −bx, then
du = −b dx, and the limits x = −∞, ∞, become u = ∞, −∞.
 ∞
−∞
φ(x)δ(−bx) dx =
 −∞
∞
φ

 u
−b

δ(u)

 du
−b

= 1
b
 ∞
−∞
φ

 u
−b

δ(u) du
= 1
bφ(0) = 1
|a|φ(0) = 1
|a|
 ∞
−∞
φ(x)δ(x) dx.
From the second integral to the third, we have reversed the order of integration
(one minus sign) and also changed du
−b to du
b (another minus sign, which cancels the
ﬁrst). Now, if we repeat the calculation using a > 0 instead of −b, neither of these
sign reversals occurs, and so we get the result 1
aφ(0) instead of 1
bφ(0). But when
a > 0, a and |a| are the same. Thus we get the result stated in (11.19c).
δ functions in 2 or 3 dimensions
It is now straightforward to write the deﬁning
equations in rectangular coordinates for δ functions in 2 or 3 dimensions. We have
 ∞
−∞
 ∞
−∞
φ(x, y)δ(x −x0)δ(y −y0) dx dy = φ(x0, y0).
(11.20)
 ∞
−∞
 ∞
−∞
 ∞
−∞
φ(x, y, z)δ(x −x0)δ(y −y0)δ(z −z0) dx dy dz
(11.21)
= φ(x0, y0, z0).
As in one dimension, the delta function “picks out” the value of the test function φ
at the “peak” of the δ function. The integrals need not be over all space, just over
a region containing the point r0; otherwise the integral is zero. The abbreviations
δ(r) or δ3(r) are often used for δ(x)δ(y)δ(z), but note carefully that they do not
mean functions of the vector r, but rather functions of the components x, y, z of r.
Similarly you may see δ(r −r0) or δ3(r −r0) meaning the δ function in (11.21).
In spherical coordinates, let’s use f instead of φ to mean a test function (since
φ is a spherical coordinate angle).
By the deﬁnition of δ functions, we want

f(r, θ, φ)δ(r −r0)δ(θ −θ0)δ(φ−φ0) dr dθ dφ = f(r0, θ0, φ0). But since we would
like to use the volume element dτ = r2 sin θ dr dθ dφ = r2 dr dΩ, we need to write

Section 11
The Dirac Delta Function
457
(also see Problem 22)
(11.22)
δ(r −r0) = δ(r −r0)δ(θ −θ0)δ(φ −φ0)
r2 sin θ
;
then

f(r, θ, φ)δ(r −r0) dτ = f(r0, θ0, φ0).
Similarly in cylindrical coordinates, with dτ = r dr dθ dz,
(11.23)
δ(r −r0) = δ(r −r0)δ(θ −θ0)δ(z −z0)
r
;
then

f(r, θ, z)δ(r −r0) dτ = f(r0, θ0, z0).
Note that we can use these formulas to write mass density or charge density
functions in the various coordinate systems.
Example5.
Suppose there is a unit charge or unit mass at the point (x, y, z) = (−1,
√
3, −2);
then in rectangular coordinates, the density is
ρ = δ(x + 1)δ(y −
√
3)δ(z + 2).
In cylindrical coordinates the point is (r, θ, z) = (2, 2π/3, −2) so in cylindrical co-
ordinates the density is
ρ = δ(r −2)δ(θ −2π/3)δ(z + 2)/r.
In spherical coordinates, the point is (r, θ, φ) = (2
√
2, 3π/4, 2π/3), so in spherical
coordinates the density is
ρ = δ(r −2
√
2)δ(θ −3π/4)δ(φ −2π/3)/(r sin θ).
Finally, let’s verify two useful operator equations for δ functions in 3 dimensions.
∇· er
r2 = 4πδ(r);
(11.24)
∇2 1
r = −4πδ(r).
(11.25)
You can easily show (Problem 24a) that ∇· (er/r2) is zero for any r ̸= 0 (and un-
deﬁned for r = 0). Also, by the divergence theorem [Chapter 6, equation (10.17)]
in spherical coordinates, we ﬁnd

volume τ
∇· er
r2 dτ =

surface
inclosing τ
er
r2 · er dσ =
 2π
φ=0
 π
θ=0
1
r2 r2 sin θ dθ dφ = 4π.
Thus ∇· (er/r2) has the properties that it is zero for all r > 0 but its integral
over any volume including the origin = 4π; this suggests that it is equal to 4πδ(r).
Let’s verify that this is correct. (Compare Problem 25.) Since ∇· (er/r2) depends
only on r (Problem 24a), we use a test function f(r).
We want to show that

458
Ordinary Differential Equations
Chapter 8

f(r)∇· (er/r2) dτ, over any volume containing the origin, is equal to 4πf(0).
For convenience we integrate over the volume inside the sphere r = a. (Since the
integrand is zero for r > 0, the answer is the same for any volume containing the
origin.) By Problem 11.17(e) of Chapter 6 with φ = f, V = er/r2, and n = er, we
ﬁnd

volume r<a
f(r)∇· er
r2 dτ =

surface r=a
f(r)er
r2 · er dσ −

volume r<a
∇f(r) · er
r2 dτ.
On the surface r = a, the integrand of the surface integral is f(a) 1
a2 a2 dΩ, so the
surface integral is 4πf(a). In the volume integral, ∇f(r) · er is the r component of
∇f(r); in spherical coordinates this is just ∂f/∂r (Chapter 6, equation 6.8). Thus
the volume integral on the right-hand side is

volume r<a
∂f
∂r
1
r2 r2 dr dΩ= 4πf(r)

a
0
= 4π[f(a) −f(0)]
and we have

volume r<a
f(r)∇· er
r2 dτ = 4πf(a) −4π[f(a) −f(0)] = 4πf(0)
as we expected. Thus (11.24) is a valid operator equation. You can show (Prob-
lem 24b) that ∇(1/r) = −er/r2). Since ∇·∇= ∇2 (that is, div grad = Laplacian),
we have ∇2(1/r) = ∇· ∇(1/r) = −∇·

er/r2
. Thus (11.25) is also valid.
We can write (11.24) and (11.25) with the peak of the δ function shifted from
the origin to r0. The unit vector from r0 to r can be written as (r −r0)/|r −r0|.
Then we have
(11.26)
∇2
1
|r −r0| = −∇·
r −r0
|r −r0|3 = −4πδ(r −r0).
It is now interesting to note that we have seen this before without recogniz-
ing that we were dealing with a δ function. Look back to Chapter 6, Equations
(6.10.19) to (6.10.25). With D given by (6.10.19), we have from (8.11.24) above,
∇·D =
q
4π4πδ(r) = qδ(r) which we recognize as the charge density for a charge q at
the origin. Thus, although we wrote (6.10.25) with ρ as the density of a charge dis-
tribution, we could now write it with ρ = charge density of a point charge = qδ(r),
and then (6.10.25) becomes (6.10.22).
PROBLEMS, SECTION 11
1.
Find the inverse Laplace transform of e−2p/p2 in the following ways:
(a)
using L5 and L27 and the convolution integral of Section 10;
(b)
using L28.
2.
Verify L24 in the table by using L1, L27, and the convolution integral.
3.
Verify L28 in the table by using L27 and the convolution integral.
4.
Show that
R ∞
−∞fn(t) dt = 1 for the functions fn(t) in Figures 11.3 and 11.4.

Section 11
The Dirac Delta Function
459
5.
Solve the diﬀerential equation y′′ + ω2y = f(t), y0 = y′
0 = 0, with f(t) given by the
functions in Figure 11.4, by the following methods.
(a)
Use the convolution integral, being careful to consider separately the three
intervals 0 to t0, t0 to t0 + 1/n, and t0 + 1/n to ∞.
(b)
Write fn(t) as a diﬀerence of unit step functions as in L25, and use L25 to
ﬁnd L(fn). Expand
1
p(p2 + ω2) by partial fractions and use L28 to ﬁnd yn(t).
Your result should agree with (a).
(c)
Let n →∞and show that your solution in (a) and (b) tends to the same
solution (11.5) obtained using the functions of Figure 11.3; that is, either set
of functions gives, in the limit, the same solution (11.11) obtained by using the
δ function. Note that, when you let n →∞, you do not need to consider the
interval t0 to t0 + 1/n since, if t > t0, then for suﬃciently large n, t > t0 + 1/n.
6.
(a)
Let a mechanical or electrical system be described by the diﬀerential equation
Ay′′ + By′ + Cy = f(t), y0 = y′
0 = 0. As in Problem 10.16b, write the solution
as a convolution (assume a ̸= b). Let f(t) be one of the functions in Figure
11.4 and Problem 5. Find y and then let n →∞.
(b)
Solve (a) with f(t) = δ(t −t0); your result should be the same as in (a).
(c)
The solution y as found in (a) and (b) is called the response of the system to a
unit impulse. Show that the response of a system to a unit impulse at t0 = 0
is the inverse Laplace transform of the transfer function.
Using the δ function method, ﬁnd the response (see Problem 6c) of each of the following
systems to a unit impulse.
7.
y′′ + 2y′ + y = δ(t −t0)
8.
y′′ + 4y′ + 5y = δ(t −t0)
9.
y′′ + 2y′ + 10y = δ(t −t0)
10.
y′′ −9y = δ(t −t0)
11.
d4y
dt4 −y = δ(t −t0)
12.
Evaluate the functions fn(x−a) deﬁned by the integral in (11.13) with limits −n, n.
Show that
R ∞
−∞fn(x −a) dx = 1 for all n. Sketch or computer plot graphs of several
fn’s to show that as n increases the functions fn(x) are increasingly peaked around
x = a, and that as |x −a| increases, they oscillate with decreasing amplitude.
13.
Using δ functions, write the following mass or charge density functions.
(a)
Mass 5 at x = 2, and mass 3 at x = −7.
(b)
Charge 3 at x = −5 and charge −4 at x = 10.
14.
Integrate by parts as we did for (11.14) to obtain (11.15) and (11.16).
15.
Use (11.6) and (11.14) to (11.16) to evaluate the following integrals. Warning hint:
See comments just after (11.6) and (11.16) about the range of integration.
(a)
Z π
0
sin x δ(x −π
2 ) dx
(b)
Z π
0
sin x δ(x + π
2 ) dx
(c)
Z 1
−1
e3xδ′(x) dx
(d)
Z π
0
cosh x δ′′(x −1) dx

460
Ordinary Differential Equations
Chapter 8
16.
Verify the operator equation
d
dxsgn x = 2δ(x) where the function signum x, meaning
“sign of x,” and abbreviated sgn x, is deﬁned by
sgn x =

1,
x > 0,
−1,
x < 0.
17.
Verify (11.18a) and (11.18c) by multiplying by a test function and integrating.
18.
Use equation (11.16) to generalize the operator equations (11.18) as follows:
(a)
Show that xmδ(n)(x) = 0 if m > n; compare equation (11.18a).
(b)
Show that xnδ(n)(x) = (−1)nn! δ(x); compare (11.18b) and (11.18c).
(c)
Show that xmδ(n)(x) = (−1)m
n!
(n−m)! δ(n−m)(x), m ≤n.
(d)
Use the results in (a) and (b) to show that
(x2 + y2 + z2)∇2[δ(x)δ(y)δ(z)] = 6δ(x)δ(y)δ(z).
19.
(a)
Show that you can diﬀerentiate a generalized function equation or multiply it
by a power of x. This means to show that if
R
φ(x)G1(x) dx =
R
φ(x)G2(x) dx
for all test functions φ, then
Z
φ(x)G′
1(x) dx =
Z
φ(x)G′
2(x) dx
and
Z
φ(x)xnG1(x) dx =
Z
φ(x)xnG2(x) dx.
Hints: For the diﬀerentiation proof, integrate by parts. For the multiplication
by xn proof, consider whether xnφ(x) is a test function if φ is. See comment
just after equation (11.17).
(b)
Multiply (11.18b) by x and use (11.18a). Diﬀerentiate the result and simplify
to get (11.18c).
(c)
Multiply (11.18c) by x, use (11.18a), diﬀerentiate and simplify to ﬁnd x3δ′′′(x)
in terms of δ(x). Check your result by Problem (18b).
(d)
Try a few more examples as in (b) and (c) and check your results by Problem 18.
20.
Verify the operator equations in (11.19) not done in text.
Hints for (a) and (b): Follow the text method of proof of (c), making the change of
variable u = −x or u = a −x. Hints for (c) and (d): Split the integral into a sum
of integrals each including just one xi. In (d), what is the value of (x −a) when x
is in the vicinity of b? Use part (c).
21.
Make use of the operator equations (11.19) and previous equations to evaluate the
following integrals.
(a)
Z 3
0
(5x −2)δ(2 −x) dx
(b)
Z ∞
0
φ(x)δ(x2 −a2) dx
(c)
Z 1
−1
cos x δ(−2x) dx
(d)
Z π/2
−π/2
cos x δ(sin x) dx
22.
You may ﬁnd the spherical coordinate δ function written as
δ(r −r0) = δ(r −r0)δ(cos θ −cos θ0)δ(φ −φ0)/r2.
Show that this equation is equivalent to (11.22). Hints: You want to show that
δ(cos θ −cos θ0) = δ(θ −θ0)/ sin θ. See (11.19e). Also note that it doesn’t really
matter whether we write r2 sin θ or r2
0 sin θ0 in the denominator of (11.22) since the
δ functions are zero unless r = r0 and θ = θ0.

Section 12
A Brief Introduction to Green Functions
461
23.
Write a formula in rectangular coordinates, in cylindrical coordinates, and in spher-
ical coordinates for the density of a unit point charge or mass at the point with the
given rectangular coordinates:
(a) (−5, 5, 0)
(b) (0, −1, −1)
(c) (−2, 0, 2
√
3)
(d) (3, −3, −
√
6)
24.
(a)
Show that ∇· (er/r2) = 0 for r > 0. Hint: You can do this in rectangular
coordinates, but it is easier in spherical coordinates. See Chapter 6, equation
(7.9). Show that ∇· [erF(r)], for any F(r), is a function of r only.
(b)
Show that ∇(1/r) = −er/r2. See Chapter 6, equation (6.8).
25.
Let
F(x) =
x −2,
x > 0,
0,
x < 0.
Show that F ′′(x) = 0 for all x ̸= 0, and
R ∞
−∞F ′′(x) dx = 1, which leads you to think
that F ′′(x) might = δ(x). Show in two ways, as outlined in (a) and (b), that this is
not true.
(a)
Show that
R ∞
−∞φ(x)F ′′(x) dx = φ(0) + 2φ′(0), where φ is any test function.
Then by (11.6) and (11.14), what is F ′′(x)?
(b)
Show that F(x) = (x −2)u(x) where u(x) is the unit step function in (11.17).
Diﬀerentiate this equation twice and simplify using (11.17) and (11.18). Com-
pare your result in (a).
(c)
As in (a) and (b), ﬁnd G′′(x) in terms of δ and δ′ if
G(x) =
3x + 1,
x > 0,
2x −4,
x < 0.
12. A BRIEF INTRODUCTION TO GREEN FUNCTIONS
Let’s do some examples to see what a Green function is and how we can use it
to solve ordinary diﬀerential equations.
Also see Chapter 13, Section 8, for an
application to partial diﬀerential equations. (You might ﬁnd it interesting to read
“The Green of Green Functions”, Physics Today, December 2003, 41–46.)
Example 1.
We reconsider the diﬀerential equation (11.2), namely
(12.1)
y′′ + ω2y = f(t),
y0 = y′
0 = 0
where f(t) is some given forcing function. Using (11.6), we can write
(12.2)
f(t) =
 ∞
0
f(t′)δ(t′ −t) dt′,
that is, we can think of the force f(t) as (a limiting case of) a whole sequence of
impulses. (You might reﬂect that, on the molecular level, air pressure is the force
per unit area due to a tremendous number of impacts of individual molecules.) Now
suppose that we have solved (12.1) with f(t) replaced by δ(t′ −t), that is, we ﬁnd
the response of the system to a unit impulse at t′. Let us call this response G(t, t′),
that is, G(t, t′) is the solution of
(12.3)
d2
dt2 G(t, t′) + ω2G(t, t′) = δ(t′ −t).

462
Ordinary Differential Equations
Chapter 8
Then, given some forcing function f(t), we try to ﬁnd a solution of (12.1) by “adding
up” the responses of many such impulses. We shall show that this solution is
(12.4)
y(t) =
 ∞
0
G(t, t′)f(t′) dt′.
Substituting (12.4) into (12.1) and using (12.3) and (12.2), we ﬁnd
y′′ + ω2y =

 d2
dt2 + ω2

y =

 d2
dt2 + ω2
  ∞
0
G(t, t′)f(t′) dt′
=
 ∞
0

 d2
dt2 + ω2

G(t, t′)f(t′) dt′ =
 ∞
0
δ(t′ −t)f(t′) dt′ = f(t).
Thus (12.4) is a solution of (12.1).
The function G(t, t′) is called a Green function (or Green’s function). The Green
function is the response of the system to a unit impulse at t = t′. Solving (12.3)
with initial conditions G = 0 and dG/dt = 0 at t = 0, we ﬁnd (Problem 1)
(12.5)
G(t, t′) =

0,
0 < t < t′,
1
ω sin ω(t −t′),
0 < t′ < t.
Then (12.4) gives the solution of (12.1) with y0 = y′
0 = 0, namely
(12.6)
y(t) =
 t
0
1
ω sin ω(t −t′)f(t′) dt′.
(The upper limit is t′ = t since G = 0 for t′ > t.) Thus, given a forcing function
f(t), we can ﬁnd the response y(t) of the system (12.1) by integrating (12.6) (see
Problems 2 to 5). Similarly for other diﬀerential equations we can ﬁnd the solution
in terms of an appropriate Green function (see Problems 6 to 8).
Example2.
As we will see later (Chapter 13, Section 8), in using Green functions in three-
dimensional problems, we usually want a solution which is zero on the boundary of
some region. In order to have a similar problem here, let us ask for a solution of
(12.7)
y′′ + y = f(x)
such that y = 0 at x = 0 and at x = π/2. A physical interpretation of this problem
may be useful. If a string is stretched along the x axis from x = 0 to x = π/2, and
then caused to vibrate by a force proportional to −f(x) sin ωt, then |y(x)| in (12.7)
gives the amplitude of small vibrations.
We ﬁrst ﬁnd a solution of [compare (12.3)]
(12.8)
d2
dx2 G(x, x′) + G(x, x′) = δ(x′ −x)
satisfying G(0, x′) = G(π/2, x′) = 0; this solution is the Green function for our
problem. Then [compare (12.4)]
(12.9)
y(x) =
 π/2
0
G(x, x′)f(x′) dx′

Section 12
A Brief Introduction to Green Functions
463
gives a solution of (12.7) satisfying the conditions y(0) = y(π/2) = 0 (Problem 9).
To construct the desired Green function, we ﬁrst note that for any x ̸= x′, the
equation (12.8) becomes
(12.10)
d2
dx2 G(x, x′) + G(x, x′) = 0,
x ̸= x′.
The solutions of (12.10) are sin x and cos x; we observe that sin x = 0 at x = 0 and
cos x = 0 at x = π/2. Thus we try to ﬁnd a Green function of the form
(12.11)
G(x, x′) =

A(x′) sin x,
0 < x < x′ < π/2,
B(x′) cos x,
0 < x′ < x < π/2.
Figure 12.1
The next step may be clariﬁed by thinking about
the string problem. If the string is oscillated by a
concentrated force at x′ [see (12.8)], then the am-
plitude of the vibration given by (12.11) is shown
in Figure 12.1. At x = x′, G(x, x′) is continuous,
that is, from (12.11)
(12.12)
A(x′) sin x′ = B(x′) cos x′.
However (see Figure 12.1), the slope changes abruptly at x′. From (12.11), we ﬁnd
d
dx G(x, x′) =
 A(x′) cos x,
x < x′,
−B(x′) sin x,
x > x′.
Change in dG
dx at x′ is −B(x′) sin x′ −A(x′) cos x′.
(12.13)
We can evaluate this change in dG/dx by integrating (12.8) from x = x′ −ϵ to
x = x′ + ϵ and letting ϵ →0. Since

d2G/dx2 = dG/dx, we ﬁnd
dG
dx

x′+ϵ
x′−ϵ
+
 x′+ϵ
x′−ϵ
G(x, x′) dx =
 x′+ϵ
x′−ϵ
δ(x′ −x) dx = 1,
or, letting ϵ →0:

Change in slope dG
dx at x′

is 1.
Then from (12.13)
(12.14)
−B(x′) sin x′ −A(x′) cos x′ = 1.
We solve (12.12) and (12.14) for A(x′) and B(x′) (Problem 10) and get
(12.15)
A(x′) = −cosx′,
B(x′) = −sin x′.
Thus we have
(12.16)
G(x, x′) =
 −cosx′ sin x,
0 < x < x′ < π/2,
−sin x′ cos x,
0 < x′ < x < π/2.
Then from (12.9), the solution of (12.7) with y(0) = y(π/2) = 0 is
(12.17)
y(x) = −cos x
 x
0
(sin x′)f(x′) dx′ −sin x
 π/2
x
(cos x′)f(x′) dx′.

464
Ordinary Differential Equations
Chapter 8
Example 3.
If f(x) = csc x, we ﬁnd from (12.17):
y(x) = −cos x
 x
0
sin x′ csc x′ dx′ −sin x
 π/2
x
cos x′ csc x′ dx′
= (−cos x)(x) −(sin x)(ln sin x′)

π/2
x
= −x cos x + (sin x)(ln sin x).
It is interesting to note that we can use the Green function method to obtain a
particular solution of a nonhomogeneous diﬀerential equation (nonzero right-hand
side) when we know the solutions of the corresponding homogeneous equation (zero
right-hand side). (See Problems 14 to 18.) In (12.17) each integral gives a function
of x minus a constant (from the constant limits); these constants times sin x and
cos x give a solution of the homogeneous equation. Thus the remaining terms give
a particular solution of the nonhomogeneous equation. We can write this particular
solution in a simple form by changing
 π/2
x
to −
 x
π/2, dropping the constant limits
and writing indeﬁnite integrals. Then a particular solution yp(x) of (12.7) is given
by
(12.18)
yp(x) = −cosx

(sin x)f(x) dx + sin x

(cos x)f(x) dx.
Example 4.
By the same methods used above, you can verify (Problem 14) that a solution
of the diﬀerential equation
(12.19)
y′′ + p(x)y′ + q(x)y = f(x)
with y(a) = y(b) = 0 is given by
(12.20)
y(x) = y2(x)
 x
a
y1(x′)f(x′)
W(x′)
dx′ + y1(x)
 b
x
y2(x′)f(x′)
W(x′)
dx′,
where y1(x) and y2(x) are solutions of the homogeneous equation with y1(a) = 0,
y2(b) = 0, and W is the Wronskian of y1(x) and y2(x) [See Chapter 3, equation
(8.5)]. Just as in (12.18), we ﬁnd that a particular solution yp of (12.19) is
(12.21)
yp(x) = y2(x)
 y1(x)f(x)
W(x)
dx −y1(x)
 y2(x)f(x)
W(x)
dx.
The particular solution (12.18) and (12.21) are exactly the same as those obtained
by the method of variation of parameters (see Problem 14b) but the Green function
method may seem less arbitrary.
PROBLEMS, SECTION 12
1.
Solve (12.3) if G = 0 and dG/dt = 0 at t = 0 to obtain (12.5). Hint: Use L28 and
L3 to ﬁnd the inverse transform.
In Problems 2 and 3, use (12.6) to solve (12.1) when f(t) is as given.
2.
f(t) = sin ωt
3.
f(t) = e−t

Section 12
A Brief Introduction to Green Functions
465
4.
Use equation (12.6) to solve Problem 10.18.
5.
Obtain (12.6) by using the convolution integral to solve (12.1).
6.
For Problem 10.17, show (as in Problem 1) that the Green function is
G(t, t′) =
0,
0 < t < t′,
(1/a) sinh a(t −t′),
0 < t′ < t.
Thus write the solution of Problem 10.17 as an integral [similar to (12.6)] and eval-
uate it.
7.
Use the Green function of Problem 6 to solve
y′′ −a2y = e−t,
y0 = y′
0 = 0.
8.
Solve the diﬀerential equation y′′ + 2y′ + y = f(t), y0 = y′
0 = 0, where
f(t) =
1,
0 < t < a,
0,
t > a.
As in Problems 6 and 7, ﬁnd the Green function for the problem and use it in
equation (12.4). Consider the cases t < a and t > a separately.
9.
Following the proof of (12.4), show that (12.9) gives a solution of (12.7).
10.
Solve (12.12) and (12.14) to get (12.15).
Hint:
Use Cramer’s rule (Chapter 3,
Section 3); note that the denominator determinant is the Wronskian [Chapter 3,
equation (8.5)] of the functions sin x and cos x.
In Problems 11 to 13, use (12.17) to ﬁnd the solution of (12.7) with y(0) = y(π/2) = 0
when the forcing function is given f(x).
11.
f(x) = sin 2x
12.
f(x) = sec x
13.
f(x) =
(
x,
0 < x < π/4
π/2 −x,
π/4 < x < π/2.
Hint: Write separate formulas for y(x) for x < π/4 and x > π/4.
14.
(a)
Given that y1(x) and y2(x) are solutions of (12.19) with f(x) = 0, and that
y1(a) = 0, y2(b) = 0, ﬁnd the Green function [as in (12.11) to (12.16)] and
so obtain the solution (12.20). Then ﬁnd the particular solution (12.21) as
discussed for (12.18) and (12.21).
(b)
The method of variation of parameters is an elementary way of ﬁnding a par-
ticular solution of (12.19) when you know the solutions of the homogeneous
equation. Show as follows that this method leads to the same result (12.21) as
the Green function method. Start with the known solution of the homogeneous
equation, say y = c1y1 + c2y2 and allow the “constants” to be functions of x to
be determined so that y satisﬁes (12.19). (The c’s are the “parameters” which
are to be “varied” in the expression “variation of parameters”.) You want to
ﬁnd y′ and y′′ to substitute into (12.19). First ﬁnd y′ and set the sum of the
terms involving derivatives of the c’s equal to zero. Diﬀerentiate the rest of
y′ again to get y′′. Now substitute y, y′ and y′′ into (12.19) and use the fact
that y1 and y2 both satisfy the homogeneous equation [that is, (12.19) with
f(x) = 0]. You should have the two equations:
c′
1y1 + c′
2y2 = 0,
c′
1y′
1 + c′
2y′
2 = f(x).
Solve this pair of equations for c′
1 and c′
2 [say by determinants, and note that the
denominator determinant is the Wronskian as in (12.20) and (12.21)]. Write
the indeﬁnite integrals for c1 and c2, and write y = c1y1 + c2y2 to get (12.21).

466
Ordinary Differential Equations
Chapter 8
In Problems 15 to 18, use the given solutions of the homogeneous equation to ﬁnd a
particular solution of the given equation. You can do this either by the Green function
formulas in the text or by the method of variation of parameters in Problem 14b.
15.
y′′ −y = sech x;
sinh x, cosh x
16.
x2y′′ −2xy′ + 2y = x ln x;
x, x2
17.
y′′ −2(csc2 x)y = sin2 x;
cot x, 1 −x cot x
18.
(x2 + 1)y′′ −2xy′ + 2y = (x2 + 1)2;
x, 1 −x2
13. MISCELLANEOUS PROBLEMS
Identify each of the diﬀerential equations in Problems 1 to 24 as to type (for example,
separable, linear ﬁrst order, linear second order, etc.), and then solve it.
1.
x2y′ −xy = 1/x
2.
x(ln y)y′ −y ln x = 0
3.
y′′′ + 2y′′ + 2y′ = 0
4.
d2r
dt2 −6dr
dt + 9r = 0
5.
(2x −y sin 2x) dx = (sin2x −2y) dy
6.
y′′ + 2y′ + 2y = 10ex + 6e−x cos x
7.
3x3y2y′ −x2y3 = 1
8.
x2y′′ −xy′ + y = x
9.
dy −(2y + y2e3x) dx = 0
10.
u(1 −v) dv + v2(1 −u) du = 0
11.
(y + 2x) dx −x dy = 0
12.
xy′′ + y′ = 4x
13.
y′′ + 4y′ + 5y = 26e3x
14.
y′′ + 4y′ + 5y = 2e−2x cos x
15.
y′′ −4y′ + 4y = 6e2x
16.
y′′ −5y′ + 6y = e2x
17.
(2x + y) dy −(x −2y) dx = 0
18.
(x cos y −e−sin y) dy + dx = 0
19.
sin2x dy + [sin2x + (x + y) sin 2x] dx = 0
20.
y′′ −2y′ + 5y = 5x + 4ex(1 + sin 2x)
21.
y′ + xy = x/y
22.
(D −2)2(D2 + 9)y = 0
23.
sin θ cos θ dr −sin2 θ dθ = r cos2 θ dθ
24.
x(yy′′+y′2) = yy′
Hint: Let u = yy′.
In Problems 25 to 28, ﬁnd a particular solution satisfying the given conditions.
25.
3x2y dx + x3 dy = 0,
y = 2 when x = 1.
26.
xy′ −y = x2,
y = 6 when x = 2
27.
y′′ + y′ −6y = 6,
y = 1, y′ = 4 when x = 0
28.
yy′′ + y′2 + 4 = 0
y = 3, y′ = 0 when x = 1
29.
If 10 kg of rock salt is placed in water, it dissolves at a rate proportional to the
amount of salt still undissolved. If 2kg dissolve during the ﬁrst 10 minutes, how
long will it be until only 2kg remain undissolved?

Section 13
Miscellaneous Problems
467
30.
A mass m falls under gravity (force mg) through a liquid whose viscosity is decreasing
so that the retarding force is −2mv/(1 + t), where v is the speed of m. If the mass
starts from rest, ﬁnd its speed, its acceleration, and how far it has fallen (in terms
of g) when t = 1.
31.
The acceleration of an electron in the electric ﬁeld of a positively charged sphere is
inversely proportional to the square of the distance between the electron and the
center of the sphere. Let an electron fall from rest at inﬁnity to the sphere. What
is the electron’s velocity when it reaches the surface of the sphere?
32.
Suppose that the rate at which you work on a hot day is inversely proportional to
the excess temperature above 75◦. One day the temperature is rising steadily, and
you start studying at 2 p.m. You cover 20 pages the ﬁrst hour and 10 pages the
second hour. At what time was the temperature 75◦?
33.
Compare the temperatures of your cup of coﬀee at time t
(a)
if you add cream and let the mixture cool;
(b)
if you let the coﬀee and cream sit on the table and mix them at time t.
Hints: Assume Newton’s law of cooling (Problem 2.27) for both coﬀee and cream
(where it is a law of heating). Combine n′ units of cream initially at temperature T ′
0
with n units of coﬀee initially at temperature T0, and ﬁnd the temperature at time t
in (a) and in (b) assuming that the air temperature remains a constant Ta, and that
the proportionality constant in the law of cooling is the same for both coﬀee and
cream.
34.
A ﬂexible chain of length l is hung over a peg with one end of the chain slightly longer
than the other. Assuming that the chain slides oﬀwith no friction, write and solve
the diﬀerential equation of motion to show that y = y0 cosh t
p
2g/l, 0 < y < l/2,
where 2y is the diﬀerence in length of the two ends, and y = y0 when t = 0.
35.
A raindrop falls through a cloud, increasing in size as it picks up moisture. Assume
that its shape always remains spherical. Also assume that the rate of increase of
its volume with respect to distance fallen is proportional to the cross-sectional area
of the drop at any time (that is, the mass increase dm = ρdV is proportional to
the volume πr2 dy swept out by the drop as it falls a distance dy). Show that the
radius r of the drop is proportional to the distance y the drop has fallen if r = 0
when y = 0. Recall that when m is not constant, Newton’s second law is properly
stated as (d/dt)(mv) = F. Use this equation to ﬁnd the distance y which the drop
falls in time t under the force of gravity, if y = ˙y = 0 at t = 0. Show that the
acceleration of the drop is g/7 where g is the acceleration of gravity.
36.
(a)
A rocket of (variable) mass m is propelled by steadily ejecting part of its mass
at velocity u (constant with respect to the rocket). Neglecting gravity, the
diﬀerential equation of the rocket is m(dv/dm) = −u as long as v ≪c, c =
speed of light. Find v as a function of m if m = m0 when v = 0.
(b)
In the relativistic region (v/c not negligible), the rocket equation is
m dv
dm = −u
„
1 −v2
c2
«
.
Solve this diﬀerential equation to ﬁnd v as a function of m. Show that v/c =
(1 −x)/(1 + x), where x = (m/m0)2u/c.

468
Ordinary Differential Equations
Chapter 8
37.
The diﬀerential equation for the path of a planet around the sun (or any object in
an inverse square force ﬁeld) is, in polar coordinates,
1
r2
d
dθ
„ 1
r2
dr
dθ
«
−1
r3 = −k
r2 .
Make the substitution u = 1/r and solve the equation to show that the path is a
conic section.
38.
Use L15 and L31 to ﬁnd the Laplace transform of (1 −cos at)/t.
39.
Use L32 and L9 to ﬁnd the Laplace transform of t sinh at. Verify your result by
ﬁnding its inverse transform using the convolution integral.
Use the Laplace transform table to evaluate:
40.
Z ∞
0
t3e−4t sinh 2t dt
41.
∞
X
n=0
(−1)n
Z n+1
n
te−2t dt
Find the inverse Laplace transform of:
42.
p
(p + a)3
43.
p2
(p2 + a2)2
44.
1
(p2 + a2)3
45.
Prove the following shifting or translation theorems for Fourier transforms. If g(α)
is the Fourier transform of f(x), then
(a)
the Fourier transform of f(x −a) is e−iαag(α);
(b)
the Fourier transform of eiβxf(x) is g(α −β).
Compare Problems 8.19 to 8.27.
46.
Use the table of Laplace transforms to ﬁnd the sine and cosine Fourier transforms
of e−x; of xe−x.
Solve Problems 47 and 48 either by Laplace transforms and the convolution integral or by
Green functions.
47.
y′′ + y = sec2 t
48.
y′′ + y = t sin t

Table of Laplace Transforms
469
Table of Laplace Transforms
y = f(t), t > 0
[y = f(t) = 0, t < 0]
Y = L(y) = F(p) =
 ∞
0
e−ptf(t) dt
L1
1
1
p
Re p > 0
L2
e−at
1
p + a
Re (p + a) > 0
L3
sin at
a
p2 + a2
Re p > | Im a|
L4
cos at
p
p2 + a2
Re p > | Im a|
L5
tk, k > −1
k!
pk+1 or Γ(k + 1)
pk+1
Re p > 0
L6
tke−at, k > −1
k!
(p + a)k+1 or
Γ(k + 1)
(p + a)k+1
Re (p + a) > 0
L7
e−at −e−bt
b −a
1
(p + a)(p + b)
Re (p + a) > 0
Re (p + b) > 0
L8
ae−at −be−bt
a −b
p
(p + a)(p + b)
Re (p + a) > 0
Re (p + b) > 0
L9
sinh at
a
p2 −a2
Re p > | Re a|
L10
cosh at
p
p2 −a2
Re p > | Re a|
L11
t sin at
2ap
(p2 + a2)2
Re p > | Im a|
L12
t cos at
p2 −a2
(p2 + a2)2
Re p > | Im a|
L13
e−at sin bt
b
(p + a)2 + b2
Re (p + a) > | Im b|
L14
e−at cos bt
p + a
(p + a)2 + b2
Re (p + a) > | Im b|
L15
1 −cos at
a2
p(p2 + a2)
Re p > | Im a|
L16
at −sin at
a3
p2(p2 + a2)
Re p > | Im a|
L17
sin at −at cos at
2a3
(p2 + a2)2
Re p > | Im a|

470
Ordinary Differential Equations
Chapter 8
Table of Laplace Transforms (continued)
y = f(t), t > 0
[y = f(t) = 0, t < 0]
Y = L(y) = F(p) =
 ∞
0
e−ptf(t) dt
L18
e−at(1 −at)
p
(p + a)2
Re (p + a) > 0
L19
sin at
t
arc tan a
p
Re p > | Im a|
L20
1
t sin at cos bt,
1
2

arc tan a + b
p
+ arc tan a −b
p

a > 0, b > 0
Re p > 0
L21
e−at −e−bt
t
ln p + b
p + a
Re (p + a) > 0
Re (p + b) > 0
L22
1 −erf

 a
2
√
t

,
a > 0
(See Chapter 11, Section 9)
1
p e−a√p
Re p > 0
L23
J0(at)
(See Chapter 12, Section 12)
(p2 + a2)−1/2
Re p > | Im a|;
or Re p ≥0
for real a ̸= 0
L24
u(t −a) =

1,
t > a > 0
0,
t < a
(unit step, or Heaviside function)
1
p e−pa
Re p > 0
L25
f(t) = u(t −a) −u(t −b)
e−ap −e−bp
p
All p
t
1
a
b
0
L26
a
2a
3a
4a
t
1
−1
f(t)
1
p tanh
 1
2ap

Re p > 0
L27
δ(t −a), a ≥0
(See Section 11)
e−pa
L28
f(t) =
 g(t −a),
t > a > 0
0,
t < a
= g(t −a)u(t −a)
e−paG(p)
[G(p) means L(g).]
L29
e−atg(t)
G(p + a)

Table of Laplace Transforms
471
Table of Laplace Transforms (continued)
y = f(t), t > 0
[y = f(t) = 0, t < 0]
Y = L(y) = F(p) =
 ∞
0
e−ptf(t) dt
L30
g(at), a > 0
1
a G
p
a
	
L31
g(t)
t
(if integrable)
 ∞
p
G(u) du
L32
tng(t)
(−1)n dnG(p)
dpn
L33
 t
0
g(τ) dτ
1
p G(p)
L34
 t
0
g(t −τ)h(τ) dτ =
 t
0
g(τ)h(t −τ) dτ
(convolution of g and h, often
written as g ∗h; see Section 10)
G(p)H(p)
L35
Transforms of derivatives of y (see Section 9):
L(y′) = pY −y0
L(y′′) = p2Y −py0 −y′
0
L(y′′′) = p3Y −p2y0 −py′
0 −y′′
0 , etc.
L(y(n)) = pnY −pn−1y0 −pn−2y′
0 −· · · −y(n−1)
0

C H A P T E R 9
Calculus of Variations
1. INTRODUCTION
What is the shortest distance between two points? You probably laugh at such a
simple question because you know the answer so well. Can you prove it? We shall
see how to prove it shortly. Meanwhile we ask the same question about a sphere,
for example, the earth. What is the shortest distance between two points on the
surface of the earth, measured along the surface? Again you probably know that
the answer is the distance measured along a great circle. But suppose you were
asked the same question about some other surface, say an ellipsoid or a cylinder or
a cone. The curve along a surface which marks the shortest distance between two
neighboring points is called a geodesic of the surface. Finding geodesics is one of
the problems which we can solve using the calculus of variations.
There are many others. To understand what the basic problem is, think about
ﬁnding maximum and minimum values of f(x) in ordinary calculus. You ﬁnd f ′(x)
and set it equal to zero. The values of x you ﬁnd may correspond to maximum
points
, minimum points
, or points of inﬂection with a horizontal tangent
.
Suppose that in solving a given physical problem you want the minimum values
of a function f(x). The equation f ′(x) = 0 is a necessary (but not a suﬃcient)
condition for an interior minimum point. To ﬁnd the desired minimum, you would
ﬁnd all the values of x such that f ′(x) = 0, and then rely on the physics or on
further mathematical tests to sort out the minimum points. We use the general
term stationary point to mean simply that f ′(x) = 0 there; that is, stationary
points include maximum points, minimum points, and points of inﬂection with
horizontal tangent. In the calculus of variations, we often state problems by saying
that a certain quantity is to be minimized. However, what we actually always do
is something similar to putting f ′(x) = 0, above; that is, we make the quantity
stationary. The question of whether we have a maximum, a minimum, or neither,
is, in general, a diﬃcult mathematical problem (see calculus of variations texts)
so we shall rely on the physics or geometry. Fortunately, in many applications,
“stationary” is all that is required (Fermat’s principle, Problems 1 to 3; Lagrange’s
equations, Section 5).
472

Section 1
Introduction
473
Now what is the quantity which we want to make stationary? It is an integral
(1.1)
I =
 x2
x1
F(x, y, y′) dx

where y′ = dy
dx

,
and our problem is this: Given the points (x1, y1) and (x2, y2) and the form of
the function F of x, y, and y′, ﬁnd the curve y = y(x) (passing through the given
points) which makes the integral I have the smallest possible value (or stationary
value). Before we try to do this, let us look at several examples.
Example 1.
Geodesics: Find the equation y = y(x) of a curve joining two points (x1, y1)
and (x2, y2) in the plane so that the distance between the points measured along
the curve (arc length) is a minimum. Thus we want to minimize
(1.2)
I =
 x2
x1

1 + y′2 dx;
this is equation (1.1) with F(x, y, y′) =

1 + y′2. See Section 2 and Example 3.4.
Example 2.
The famous brachistochrone problem (from the Greek: brachistos = shortest,
chronos = time, as in chronometer): Find the shape of a wire joining two given
points so that a bead will slide down under gravity from one point to the other
(without friction) in the shortest time. Here we must minimize

dt. If ds is an
element of arc length, then the velocity of the particle is v = ds/dt. Then we have
dt = 1
v ds = 1
v

1 + y′2 dx.
We shall see later that (using the law of conservation of energy) we can ﬁnd v as a
function of x and y. Then the integral which we want to minimize, namely

dt =
 1
v

1 + y′2 dx,
is of the form (1.1). See Section 4.
Example 3.
Figure 1.1
Soap ﬁlm problem: Suppose a soap ﬁlm is sus-
pended between two circular wire hoops as shown in
Figure 1.1; what is the shape of the surface? It is
clear from symmetry that it is a surface of revolu-
tion (neglecting gravity), and it is known that the
soap ﬁlm will adjust itself so that the surface area
is a minimum. The surface area can be written as
an integral and again our problem is to minimize an
integral. See Section 4.
There are many other examples from physics. A chain suspended between two
points hangs so that its center of gravity is as low as possible; the z coordinate
of the center of gravity is given by an integral. Fermat’s principle in optics says
that light traveling between two given points follows the path requiring the least
time. (This is a simple, but inaccurate, statement; we should say that t =  dt is
stationary—there are examples where it is a maximum! See Problem 3). Various
other basic principles in physics are stated in the form that certain integrals have
stationary values.

474
Calculus of Variations
Chapter 9
PROBLEMS, SECTION 1
The speed of light in a medium of index of refraction n is v = ds/dt = c/n. Then the
time of transit from A to B is t =
R B
A dt = c−1 R B
A n ds. By Fermat’s principle above, t
is stationary. If the path consists of two straight line segments with n constant over each
segment, then
Z B
A
n ds = n1d1 + n2d2,
and the problem can be done by ordinary calculus. Thus solve the following problems:
1.
Derive the optical law of reﬂection. Hint: Let light go from the
point A = (x1, y1) to B = (x2, y2) via an arbitrary point P =
(x, 0) on a mirror along the x axis. Set dt/dx = (n/c)dD/dx =
0, where D = distance APB, and show that then θ = φ.
2.
Derive Snell’s law of refraction: n1 sin θ1 = n2 sin θ2 (see ﬁgure).
3.
Show that the actual path is not necessarily one of
minimum time. Hint: In the diagram, A is a source
of light; CD is a cross section of a reﬂecting surface,
and B is a point to which a light ray is to be reﬂected.
APB is to be the actual path and AP ′B, AP ′′B
represent varied paths. Then show that the varied paths:
(a)
Are the same length as the actual path if CD is an ellipse with A and B as
foci.
(b)
Are longer than the actual path if CD is a line tangent at P to the ellipse in
(a).
(c)
Are shorter than the actual path if CD is an arc of a curve tangent to the
ellipse at P and lying inside it. Note that in this case the time is a maximum!
(d)
Are longer on one side and shorter on the other if CD crosses the ellipse at P
but is tangent to it (that is, CD has a point of inﬂection at P).
2. THE EULER EQUATION
Before we do the general problem, let us ﬁrst do the problem of a geodesic on a
plane; we shall show that a straight line gives the shortest distance between two
points. (The reason for doing this is to clarify the theory; you will not do problems
this way.) Our problem is to ﬁnd y = y(x) which will make
I =
 x2
x1

1 + y′2 dx
as small as possible. The y(x) which does this is called an extremal. Now we want
some way to represent algebraically all the curves passing through the given end-
points, but diﬀering from the (as yet unknown) extremal by small amounts. (We

Section 2
The Euler Equation
475
assume that all the curves have continuous
second derivatives so that we can carry out
needed diﬀerentiations later.)
These curves
are called varied curves; there are inﬁnitely
many of them as close as we like to the ex-
tremal. We construct a function representing
these varied curves in the following way (Fig-
ure 2.1). Let η(x) represent a function of x
which is zero at x1 and x2, and has a contin-
uous second derivative in the interval x1 to
x2, but is otherwise completely arbitrary. We
deﬁne the function Y (x) by the equation
(2.1)
Y (x) = y(x) + ϵη(x),
where y(x) is the desired extremal and ϵ is a
parameter. Because of the arbitrariness of η(x), Y (x) represents any (single-valued)
curve (with continuous second derivative) you want to draw through (x1, y1) and
(x2, y2). Out of all these curves Y (x) we want to pick the one curve that makes
Figure 2.1
(2.2)
I =
 x2
x1

1 + Y ′2 dx
a minimum. Now I is a function of the parameter ϵ; when ϵ = 0, Y = y(x), the
desired extremal. Our problem then is to make I(ϵ) take its minimum value when
ϵ = 0. In other words, we want
(2.3)
dI
dϵ = 0
when ϵ = 0.
Diﬀerentiating (2.2) under the integral sign with respect to the parameter ϵ, we get
(2.4)
dI
dϵ =
 x2
x1
1
2
1

1 + Y ′2 2Y ′
dY ′
dϵ

dx.
Diﬀerentiating (2.1) with respect to x, we get
(2.5)
Y ′(x) = y′(x) + ϵη′(x).
Then from (2.5) we have
(2.6)
dY ′
dϵ = η′(x).
We see from (2.1) that putting ϵ = 0 means putting Y (x) = y(x). Then substituting
(2.6) into (2.4) and putting dI/dϵ equal to zero when ϵ = 0, we get
(2.7)
dI
dϵ

ϵ=0
=
 x2
x1
y′(x)η′(x)

1 + y′2 dx = 0.
We can integrate this by parts (since we assumed that η and y have continuous
second derivatives). Let
u = y′/

1 + y′2,
dv = η′(x)dx.

476
Calculus of Variations
Chapter 9
Then
du = d
dx

y′

1 + y′2

dx,
v = η(x),
and
dI
dϵ

ϵ=0
=
y′

1 + y′2 η(x)
					
x2
x1
−
 x2
x1
η(x) d
dx

y′

1 + y′2

dx.
The ﬁrst term is zero because η(x) = 0 at the endpoints. In the second term, recall
that η(x) is an arbitrary function. This means that
(2.8)
d
dx

y′

1 + y′2

= 0,
for otherwise we could select some function η(x) so that the integral would not be
zero. Notice carefully here that we are not saying that when an integral is zero,
the integrand is also zero; this is not true (as, for example
 2π
0
sin x dx = 0 shows).
What we are saying is that the only way
 x2
x1 f(x)η(x) dx can always be zero for
every η(x) is for f(x) to be zero. You can prove this by contradiction in the following
way. If f(x) is not zero, then, since η(x) is arbitrary, choose η to be positive where
f is positive and negative where f is negative. Then fη is positive, so its integral
is not zero, in contradiction to the statement that

fη dx = 0 for every η.
Integrating (2.8) with respect to x, we get
y′

1 + y′2 = const.
or y′ = const. Thus the slope of y(x) is constant, so y(x) is a straight line as we
expected.
Now we could go through this process with every calculus of variations problem.
It is much simpler to do the general problem once for all and ﬁnd a diﬀerential
equation which we can use to solve later problems. The problem is to ﬁnd the y
which will make stationary the integral
(2.9)
I =
 x2
x1
F(x, y, y′) dx,
where F is a given function. The y(x) which makes I stationary is called an extremal
whether I is a maximum or minimum or neither. The method is the one we have
just used with the straight line. We consider a set of varied curves
Y (x) = y(x) + ϵη(x)
just as before. Then we have
(2.10)
I(ϵ) =
 x2
x1
F(x, Y, Y ′) dx,
and we want (d/dϵ)I(ϵ) = 0 when ϵ = 0. Remembering that Y and Y ′ are functions
of ϵ, and diﬀerentiating under the integral sign with respect to ϵ, we get
(2.11)
dI
dϵ =
 x2
x1
∂F
∂Y
dY
dϵ + ∂F
∂Y ′
dY ′
dϵ

dx.

Section 2
The Euler Equation
477
Substituting (2.1) and (2.5) into (2.11), we have
(2.12)
dI
dϵ =
 x2
x1

∂F
∂Y η(x) + ∂F
∂Y ′ η′(x)

dx.
We want dI/dϵ = 0 at ϵ = 0; recall that ϵ = 0 means Y = y. Then (2.12) gives
(2.13)
dI
dϵ

ϵ=0
=
 x2
x1

∂F
∂y η(x) + ∂F
∂y′ η′(x)

dx = 0.
Assuming that y′′ is continuous, we can integrate the second term by parts just as
in the straight-line problem:
(2.14)
 x2
x1
∂F
∂y′ η′(x) dx = ∂F
∂y′ η(x)
				
x2
x1
−
 x2
x1
d
dx
∂F
∂y′

η(x) dx.
The integrated term is zero as before because η(x) is zero at x1 and x2. Then we
have
(2.15)
dI
dϵ

ϵ=0
=
 x2
x1

∂F
∂y −d
dx
∂F
∂y′

η(x) dx = 0.
As before, since η(x) is arbitrary, we must have
(2.16)
d
dx
∂F
∂y′ −∂F
∂y = 0.
Euler equation
This is the Euler (or Euler-Lagrange) equation.
Any problem in the calculus of variations, then, is solved by setting up the
integral which is to be stationary, writing what the function F is, substituting it
into the Euler equation, and solving the resulting diﬀerential equation.
Example.
Let’s ﬁnd the geodesics in a plane again, this time using the Euler equation as
you will do in problems.
We are to minimize
 x2
x1

1 + y′2 dx,
so we have F =

1 + y′2. Then
∂F
∂y′ =
y′

1 + y′2 ,
∂F
∂y = 0,
and the Euler equation gives
d
dx

y′

1 + y′2

= 0,
as we had in (2.8).

478
Calculus of Variations
Chapter 9
PROBLEMS, SECTION 2
Write and solve the Euler equations to make the following integrals stationary. In solving
the Euler equations, the integrals in Chapter 5, Section 1, may be useful.
1.
Z x2
x1
p
x
p
1 + y′2 dx
2.
Z x2
x1
ds
x
3.
Z x2
x1
x
p
1 −y′2 dx
4.
Z x2
x1
x ds
5.
Z x2
x1
(y′2 + y2) dx
6.
Z x2
x1
(y′2 + √y ) dx
7.
R x2
x1 exp
1 + y′2 dx
Hint: In the last integration, let u = ex
and see Chapter 5, Problem 1.6.
8.
Z x2
x1
x
p
y′2 + x2 dx
9.
Z x2
x1
(1 + yy′)2 dx
10.
Z x2
x1
x2 dx
xy′ + 1
3. USING THE EULER EQUATION
Other Variables
We have used x and y as our variables. But the mathematics
is just the same if we use some other letters, for example polar coordinates r and
θ. To minimize (make stationary) the integral

F(r, θ, θ′) dr
where
θ′ = dθ/dr,
we solve the Euler equation
(3.1)
d
dr
∂F
∂θ′

−∂F
∂θ = 0.
To minimize

F(t, x, ˙x) dt where ˙x = dx/dt, we solve
(3.2)
d
dt
∂F
∂˙x −∂F
∂x = 0.
Notice that the ﬁrst derivative in the Euler equation [d/dx in (2.16), d/dr in (3.1),
d/dt in (3.2)] is with respect to the integration variable in the integral. The partial
derivatives are with respect to the other variable and its derivative [y and y′ in
(2.16), θ and θ′ in (3.1), x and ˙x in (3.2)].
Example 1.
Find the path followed by a light ray if the index of refraction ( in polar
coordinates) is proportional to r−2. We want to make stationary

n ds
or

r−2 ds =

r−2
dr2 + r2 dθ2 =

r−2
1 + r2θ′2 dr.

Section 3
Using the Euler Equation
479
The Euler equation is then (3.1) with F = r−2
1 + r2θ′2. Since ∂F/∂θ = 0, we
have
d
dr

r−2r2θ′

1 + r2θ′2

= 0
or
θ′

1 + r2θ′2 = const. = K.
Solve for θ′ and integrate (see Chapter 5, Problem 1.5):
θ′2 = K2(1 + r2θ′2)
so
θ′2(1 −K2r2) = K2,
θ′ = dθ
dr =
K
√
1 −K2r2 ,
θ = arc sin Kr + const.
First Integrals of the Euler Equation
In some problems the integrand F in I
[see equation (1.1)] does not contain y (that is, F does not contain the dependent
variable). Then ∂F/∂y = 0 and the Euler equation becomes
d
dx
∂F
∂y′ = 0,
∂F
∂y′ = const.
This happened in the example and most of your problems in Section 2. Because
∂F/∂y was zero, we were able to integrate the Euler equation once; the equation
∂F/∂y′ = const. is for this reason called a ﬁrst integral of the Euler equation.
There is another less obvious case in which we can easily ﬁnd a ﬁrst integral
of the Euler equation.
Let us show this by an example (the soap ﬁlm problem
mentioned in Section 1).
Example 2.
Our problem is this: Given two points P1 and P2 (not too far apart), we are
going to draw a curve joining P1 and P2 and revolve it about the x axis to form a
surface of revolution. We want the equation of the curve so that the surface area
will be a minimum. That is, we want to minimize I =  2πy ds. We usually write
ds =

1 + y′2 dx. Instead, let us write ds =

1 + x′2 dy, where x′ = dx/dy. Then
I =

2πy

1 + x′2 dy. Recall from (3.1) and (3.2) and the discussion following
them how to write the Euler equation in various sets of variables. Here y is the
variable of integration, F = y

1 + x′2, and the Euler equation is
(3.3)
d
dy
∂F
∂x′ −∂F
∂x = 0.
Since ∂F/∂x = 0, (3.3) becomes
d
dy

yx′

1 + x′2

= 0.

480
Calculus of Variations
Chapter 9
This is the simpliﬁed equation we wanted.
We integrate once, solve for x′ and
integrate again (see Chapter 5, Problem 1.3):
yx′

1 + x′2 = c1,
x′ = dx
dy =
c1

y2 −c12 ,
x = c1 cosh−1 y
c1
+ c2,
y = c1 cosh x −c2
c1
.
Figure 3.1
The graph of this equation is called a catenary; it is shown in Figure 3.1 for the
special case c1 = 1, c2 = 0, y = cosh x =
1
2(ex + e−x). The catenary does not
always give the solution to the soap ﬁlm problem. If the given points (or the hoops
in Figure 1.1) are too far apart, the soap ﬁlm may break into two parts (circular
ﬁlms on the hoops). For further discussion see Courant and Robbins, Chapter 7,
Section 11, and Arfken and Weber, Chapter 17. For another problem involving a
catenary, see Problem 6.4.
Observe that the method used in this example will simplify any problem in
which I =

F(y, y′) dx does not have the independent variable x in the integrand.
We change to y as the integration variable making the substitutions
(3.4)
x′ = dx
dy =
dy
dx
−1
,
y′ = 1
x′ ,
dx = dx
dy dy = x′ dy
in I. Then the integrand is a function of y and x′, so the Euler equation [now (3.3)]
simpliﬁes since ∂F/∂x = 0. (See also Problem 8.1.)
Example 3.
Find a ﬁrst integral of the Euler equation to make stationary the integral
(3.5)
I =
 
1 + y′2
√y
dx.
Since x is missing in the integrand, we change to y as the integration variable; then
by (3.4)

1 + y′2 dx =

1 + y′2x′ dy =

x′2 + 1 dy,
I =
 
x′2 + 1
√y
dy =

F(y, x′) dy.
We see that ∂F/∂x = 0; from (3.3) the Euler equation is
d
dy
 ∂F
∂x′

= d
dy

x′
√y

x′2 + 1

= 0.

Section 3
Using the Euler Equation
481
The ﬁrst integral of the Euler equation is, then,
(3.6)
x′

y

x′2 + 1
= const.
Example 4.
Find the geodesics on the cone z2 = 8(x2+y2). Using cylindrical coordinates,
we have z2 = 8r2, z = r
√
8, dz = dr
√
8, so
ds2 = dr2 + r2dθ2 + dz2 = dr2 + r2dθ2 + 8 dr2 = 9 dr2 + r2dθ2.
We want to minimize
I =

ds =
 
9 dr2 + r2dθ2 =
 
9 + r2θ′2 dr.
Note that we use r as the integration variable since the integrand contains r but
not θ. Then ∂F/∂θ = 0, and we can immediately write a ﬁrst integral of the Euler
equation:
d
dr
∂F
∂θ′

= 0,
∂F
∂θ′ =
r2θ′

9 + r2θ′2 = const. = K.
We solve for θ′ and integrate again.
r4θ′2 = K2(9 + r2θ′2),
θ′2(r4 −K2r2) = 9K2,

dθ =

3K dr
r
√
r2 −K2 .
From computer or tables (or see Chapter 5, Problem 1.6):
θ + α = 3 arc cos K
r
(α = const. of integration)
cos
θ + α
3

= K
r
or
r cos
θ + α
3

= K.
PROBLEMS, SECTION 3
Change the independent variable to simplify the Euler equation, and then ﬁnd a ﬁrst
integral of it.
1.
Z x2
x1
y3/2 ds
2.
Z x2
x1
p
1 + y′2
y2
dx
3.
Z y2
y1
x′2
√
x′2 + x2 dy
4.
Z x2
x1
y
p
y′2 + y2 dx
Write and solve the Euler equations to make the following integrals stationary. Change
the independent variable, if needed, to make the Euler equation simpler.
5.
Z x2
x1
p
1 + y2y′2 dx
6.
Z x2
x1
yy′2
1 + yy′ dx

482
Calculus of Variations
Chapter 9
7.
Z x2
x1
(y′2 + y2) dx
8.
Z θ2
θ1
p
r′2 + r2 dθ,
r′ = dr/dθ
9.
Z φ2
φ1
p
θ′2 + sin2 θ dφ,
θ′ = dθ/dφ
10.
Z t2
t1
s−1p
s2 + s′2 dt,
s′ = ds/dt
Use Fermat’s principle to ﬁnd the path followed by a light ray if the index of refraction is
proportional to the given function.
11.
x + 1
12.
y−1
13.
√y
14.
r−1
15.
Find the geodesics on a plane using polar coordinates.
16.
Show that the geodesics on a circular cylinder (with elements parallel to the z axis)
are helices az +bθ = c, where a, b, c are constants depending on the given endpoints.
(Hint: Use cylindrical coordinates.) Note that the equation az +bθ = c includes the
circles z = const. (for b = 0), straight lines θ = const. (for a = 0), and the special
helices az + bθ = 0.
17.
Find the geodesics on the cone x2 + y2 = z2. Hint: Use cylindrical coordinates.
18.
Find the geodesics on a sphere.
Hints: Use spherical coordinates with constant
r = a. Choose your integration variable so that you can write a ﬁrst integral of the
Euler equation. For the second integration, make the change of variable w = cot θ.
To recognize your result as a great circle, ﬁnd, in terms of spherical coordinates θ
and φ, the equation of intersection of the sphere with a plane through the origin.
4. THE BRACHISTOCHRONE PROBLEM; CYCLOIDS
Figure 4.1
We have already mentioned this problem in Section 1. We are
given the points (x1, y1) and (x2, y2); we choose axes through
the point 1 with the y axis positive downward as shown in Figure
4.1. Our problem is to ﬁnd the curve joining the two points,
down which a bead will slide (from rest) in the least time; that
is, we want to minimize

dt. Let v = 0 initially, and let y = 0
be our reference level for potential energy. Then at the point
(x, y) we have
kinetic energy = 1
2mv2 = 1
2m
ds
dt
2
,
potential energy = −mgy.
The sum of the two energies is zero initially and therefore zero at any time since
the total energy is constant when there is no friction. Hence we have
1
2mv2 −mgy = 0
or
v =

2gy.
Then the integral which we want to minimize is

dt =
 ds
v =

ds
√2gy =
1
√2g
 x2
x1

1 + y′2
√y
dx.

Section 4
The Brachistochrone Problem; Cycloids
483
This is the integral (3.5) in Example 3, Section 3. Then the ﬁrst integral of the
Euler equation is given by (3.6):
x′

y

x′2 + 1
= √c.
Solving for x′, we get
(4.1)
x′ = dx
dy =

cy
1 −cy.
This simpliﬁes if we let cy = sin2 θ
2 = 1
2(1 −cos θ). We ﬁnd (Problem 1)
dx = 1
c sin2 θ
2 dθ = 1
2c(1 −cos θ) dθ,
x = 1
2c(θ −sin θ) + c′.
(4.2)
The equations for x and y as functions of θ are parametric equations of the curve
along which the particle slides in minimum time. Since we have chosen axes to
make the curve pass through the origin, x = y = 0 must satisfy the equations of
the curve, so c′ = 0, and we have
x = 1
2c(θ −sin θ),
y = 1
2c(1 −cos θ).
(4.3)
We shall now show that these are the parametric equations of a cycloid. Imagine
a circle of radius a (say a wheel) in the (x, y) plane rolling along the x axis. Let it
start tangent to the x axis at the origin O in Figure 4.2. Place a mark on the circle
at O. As the circle rolls, the mark traces out a cycloid as shown in Figure 4.3. Let
point P in Figure 4.2 be the position of the mark when the circle is tangent to the x
axis at A; let (x, y) be the coordinates of P. Since the circle rolled, OA = PA = aθ
with θ in radians. Then from Figure 4.2 we have
x = OA −PB = aθ −a sin θ = a(θ −sin θ),
y = AB = AC −BC = a −a cos θ = a(1 −cos θ).
(4.4)
Figure 4.2
Figure 4.3

484
Calculus of Variations
Chapter 9
Equations (4.4) are the parametric equations of a cycloid. Comparing (4.3), we
see that the brachistochrone is a cycloid as we claimed. Note that, since we have
taken the y axis positive down (Figures 4.1 and 4.4), the circle which generates the
brachistochrone rolls along the under side of the x axis.
Figure 4.4
From either (4.3) or (4.4), we see that
all cycloids are similar; that is they diﬀer
from each other only in size (determined
by a or c) and not in shape. Figure 4.4 is
a sketch of a cycloid for arbitrary a. If the
given endpoints for the wire along which
the bead slides are O and P3, we see that
the particle slides down to P2 and back up
to P3 in minimum time! At point P2 the
circle has rolled halfway around so OA = 1
2 · 2πa = πa. For any point P1 on arc
OP2, P1 is below the line OP2, and the coordinates (x1, y1) of P1 have
y1
x1
> P2A
AO = 2a
πa = 2
π
or x1/y1 < π/2. For points like P3 on P2B, x3/y3 > π/2, whereas at P2, we have
x2/y2 = π/2 (Problem 2). Then if the right-hand endpoint is (x, y) and the origin is
the left-hand endpoint, we can say that the bead just slides down, or slides down and
back up, depending on whether x/y is less than or greater than π/2 (Problem 2).
PROBLEMS, SECTION 4
1.
Verify equations (4.2).
2.
Show, in Figure 4.4, that for a point like P3, x3/y3 > π/2 and for P2, x2/y2 = π/2.
3.
In the brachistochrone problem, show that if the particle is given an initial velocity
v0 ̸= 0, the path of minimum time is still a cycloid.
4.
Consider a rapid transit system consisting of frictionless tun-
nels bored through the earth between points A and B on the
earth’s surface (see ﬁgure).
The unpowered passenger trains
would move under gravity. Using polar coordinates, set up
R
dt
to be minimized to ﬁnd the path through the earth requiring
the least time. See Chapter 6, Problem 8.21, for the potential
inside the earth. Find a ﬁrst integral of the Euler equation. Evaluate the constant
of integration using dr/dθ = 0 when r = r0 (where r0 is the deepest point of the
tunnel—see ﬁgure). Now solve for θ′ = dθ/dr as a function of r. Substitute this
into the integral for t and evaluate the integral to show that the transit time is
T = π
s
R2 −r02
gR
.
Hint: Find 2
Z R
r=r0
dt.
Evaluate T for r0 = 0 (path through the center of the earth—see Chapter 8, Problem
5.35); for r0 = 0.99R. [For more detail, see Am. J. Phys. 34 701–704 (1966).]
In Problems 5 to 7, use Fermat’s principle to ﬁnd the path followed by a light ray if the
index of refraction is proportional to the given function.
5.
x−1/2
6.
(y −1)−1/2
7.
(2x + 5)−1/2

Section 5
Several Dependent Variables; Lagrange’s Equations
485
5. SEVERAL DEPENDENT VARIABLES; LAGRANGE’S EQUATIONS
It is not necessary to restrict ourselves to problems with one dependent variable y.
Recall that in ordinary calculus problems the necessary condition for a minimum
point on z = z(x) is dz/dx = 0; for a function of two variables z = z(x, y), we have
the two conditions ∂z/∂x = 0 and ∂z/∂y = 0. We have a somewhat analogous
situation in the calculus of variations. Suppose that we are given an F which is a
function of y, z, dy/dx, dz/dx, and x, and we want to ﬁnd two curves y = y(x)
and z = z(x) which make I =

F dx stationary. Then the value of the integral I
depends on both y(x) and z(x) and you might very well guess that in this case we
would have two Euler equations, one for y and one for z, namely
d
dx
∂F
∂y′

−∂F
∂y = 0,
d
dx
∂F
∂z′

−∂F
∂z = 0.
(5.1)
By carrying through calculations similar to those we used in deriving the single
Euler equation for the one dependent variable case you can show (Problem 1(a))
that this guess is correct.
If there are still more dependent variables (but one
independent variable), then we write an Euler equation for each dependent variable.
It is also possible to consider a problem with more than one independent variable
(see Problem 1(b)) or with F depending on y′′ as well as x, y, y′ (see Problem 1(c)).
There is a very important application of equations like (5.1) to mechanics. In
elementary physics, Newton’s second law F = ma is a fundamental equation. In
more advanced mechanics, it is often useful to start from a diﬀerent assumption
(which can be proved equivalent to Newton’s law; see mechanics text books.) This
assumption is called Hamilton’s principle. It says that any particle or system of
particles always moves in such a way that I =
 t2
t1 L dt is stationary, where L = T −V
is called the Lagrangian; T is the kinetic energy, and V is the potential energy of
the particle or system.
Example 1.
Use Hamilton’s principle to ﬁnd the equations of motion of a single particle
of mass m moving (near the earth) under gravity.
We ﬁrst write the formulas for the kinetic energy T and the potential energy V
of the particle. (It is convenient to use a dot to mean a derivative with respect to
t just as we use a prime to indicate a derivative with respect to x; thus dx/dt = ˙x,
dy/dt = ˙y, dy/dx = y′, d2x/dt2 = ¨x, etc.) The equations for T , V , and L = T −V ,
are:
T = 1
2mv2 = 1
2m( ˙x2 + ˙y2 + ˙z2),
V = mgz,
L = T −V = 1
2m( ˙x2 + ˙y2 + ˙z2) −mgz.
(5.2)
Here t is the independent variable; x, y, and z are the dependent variables, and
L corresponds to what we have called F previously. Then to make I =  t2
t1 L dt
stationary, we write the corresponding Euler equations.
There are three Euler
equations, one for x, one for y, and one for z.
The Euler equations are called
Lagrange’s equations in mechanics [see (5.3) next page].

486
Calculus of Variations
Chapter 9
d
dt
∂L
∂˙x −∂L
∂x = 0,
d
dt
∂L
∂˙y −∂L
∂y = 0,
Lagrange’s equations
d
dt
∂L
∂˙z −∂L
∂z = 0.
(5.3)
Substituting L in (5.2) into Lagrange’s equations (5.3), we get
(5.4)













d
dt(m ˙x) = 0
d
dt(m ˙y) = 0
d
dt(m ˙z) + mg = 0
or





˙x = const.,
˙y = const.,
¨z = −g.
These are just the familiar equations obtained from Newton’s law; they say that
in the gravitational ﬁeld near the surface of the earth, the horizontal velocity is
constant and the vertical acceleration is −g. In this problem you may say that it
would have been simpler just to write the equations from Newton’s law in the ﬁrst
place! This is true in simple cases, but in more complicated problems it may be
much simpler to ﬁnd one scalar function (that is, L) than to ﬁnd six functions (that
is, the components of the two vectors, force and acceleration). For example, the
acceleration components in spherical coordinates are quite complicated to derive by
elementary methods (see mechanics text books), but you should have no trouble
deriving the equations of motion in polar, cylindrical or spherical coordinates using
the Lagrangian. Let’s do some examples.
Example 2.
Use Lagrange’s equations to ﬁnd the equations of motion of a particle in
terms of the polar coordinate variables r and θ.
The element of arc length in polar coordinates is ds where
(5.5)
ds2 = dr2 + r2 dθ2.
The velocity of a moving particle is ds/dt; from (5.5) we get
(5.6)
v2 =
ds
dt
2
=
dr
dt
2
+ r2
dθ
dt
2
= ˙r2 + r2 ˙θ2.
The kinetic energy is 1
2mv2, so we have
T = 1
2m( ˙r2 + r2 ˙θ2),
L = T −V = 1
2m( ˙r2 + r2 ˙θ2) −V (r, θ),
(5.7)

Section 5
Several Dependent Variables; Lagrange’s Equations
487
where V (r, θ) is the potential energy of the particle. Lagrange’s equations in the
variables r, θ are:
d
dt
∂L
∂˙r −∂L
∂r = 0,
d
dt
∂L
∂˙θ
−∂L
∂θ = 0.
(5.8)
Substituting L from (5.7) into (5.8), we get
d
dt(m ˙r) −mr ˙θ2 + ∂V
∂r = 0,
d
dt(mr2 ˙θ) + ∂V
∂θ = 0.
(5.9)
The r equation of motion is, then,
(5.10)
m(¨r −r ˙θ2) = −∂V
∂r .
The θ equation is
m(r2¨θ + 2r ˙r ˙θ) = −∂V
∂θ ,
or, dividing by r,
(5.11)
m(r¨θ + 2 ˙r ˙θ) = −1
r
∂V
∂θ .
Now the quantities −∂V/∂r and −(1/r)(∂V/∂θ) are the components of the force
(F = −∇V ) on the particle in the r and θ directions. (See Chapter 6.) Then
equations (5.10) and (5.11) are just the components of ma = F; the acceleration
components are then
ar = ¨r −r ˙θ2,
aθ = r¨θ + 2 ˙r ˙θ.
The second term in ar is a familiar one; it is just the centripetal acceleration v2/r
when v = r ˙θ (the minus sign indicates that it is toward the origin). The second
term in aθ is called the Coriolis acceleration.
We show by an example another important point about Lagrange’s equations.
Example 3.
A mass m1 moves without friction on the surface
of the cone shown (Figure 5.1). Mass m2 is joined to
m1 by a string of constant length; m2 can move only
vertically up and down. Find the Lagrange equations of
motion of the system.
Figure 5.1
Let’s use spherical coordinates ρ, θ, φ for m1, and
coordinate z for m2.
Then for m1, v2 = (ds/dt)2 =
˙ρ2 + ρ2 ˙θ2 + ρ2 sin2 θ ˙φ2 [Chapter 5, equation (4.20)], and
for m2, v2 = ˙z2. The potential energy mgh of m1 is
m1gρ cosθ and of m2 is m2gz. Note that we have used

488
Calculus of Variations
Chapter 9
four variables: ρ, θ, φ, z; however, there are not four Lagrange equations We must
use the equation of the cone (θ = 30◦) and the equation ρ + |z| = l (string of
constant length) to eliminate θ and either ρ or z. The Lagrangian L must always
be written using the smallest possible number of variables (we say that we eliminate
the constraint equations). Then, with θ = 30◦, sin θ = 1
2, cos θ = 1
2
√
3, ˙θ = 0, and
z = −|z| = −(l −ρ), we ﬁnd L in terms of ρ and φ:
L = 1
2m1( ˙ρ2 + ρ2 ˙φ2/4) + 1
2m2 ˙ρ2 −1
2m1gρ
√
3 + m2g(l −ρ).
Thus the Lagrange equations are
d
dt(m1 ˙ρ + m2 ˙ρ) −m1ρ ˙φ2/4 + 1
2m1g
√
3 + m2g = 0,
d
dt(m1ρ2 ˙φ/4) = 0
or
ρ2 ˙φ = const.
PROBLEMS, SECTION 5
1.
(a)
Consider the case of two dependent variables. Show that if F = F(x, y, z, y′, z′)
and we want to ﬁnd y(x) and z(x) to make I =
R x2
x1 F dx stationary, then y and
z should each satisfy an Euler equation as in (5.1). Hint: Construct a formula
for a varied path Y for y as in Section 2 [Y = y + ϵη(x) with η(x) arbitrary]
and construct a similar formula for z [let Z = z + ϵζ(x), where ζ(x) is another
arbitrary function]. Carry through the details of diﬀerentiating with respect
to ϵ, putting ϵ = 0, and integrating by parts as in Section 2; then use the fact
that both η(x) and ζ(x) are arbitrary to get (5.1).
(b)
Consider the case of two independent variables. You want to ﬁnd the function
u(x, y) which makes stationary the double integral
Z y2
y1
Z x2
x1
F(u, x, y, ux, uy) dx dy.
Hint: Let the varied U(x, y) = u(x, y) + ϵη(x, y) where η(x, y) = 0 at x = x1,
x = x2, y = y1, y = y2, but is otherwise arbitrary. As in Section 2, diﬀerentiate
with respect to ϵ, set ϵ = 0, integrate by parts, and use the fact that η is
arbitrary. Show that the Euler equation is then
∂
∂x
∂F
∂ux + ∂
∂y
∂F
∂uy −∂F
∂u = 0.
(c)
Consider the case in which F depends on x, y, y′, and y′′. Assuming zero
values of the variation η(x) and its derivative at the endpoints x1 and x2, show
that then the Euler equation becomes
d2
dx2
∂F
∂y′′ −d
dx
∂F
∂y′ + ∂F
∂y = 0.
2.
Set up Lagrange’s equations in cylindrical coordinates for a particle of mass m in a
potential ﬁeld V (r, θ, z). Hint: v = ds/dt; write ds in cylindrical coordinates.
3.
Do Problem 2 in spherical coordinates.
4.
Use Lagrange’s equations to ﬁnd the equation of motion of a simple pendulum. (See
Chapter 7, Problem 2.13.)

Section 5
Several Dependent Variables; Lagrange’s Equations
489
5.
Find the equation of motion of a particle moving along the x axis if the potential
energy is V = 1
2kx2. (This is a simple harmonic oscillator.)
6.
A particle moves on the surface of a sphere of radius a under the action of the earth’s
gravitational ﬁeld. Find the θ, φ equations of motion. (Comment: This is called a
spherical pendulum. It is like a simple pendulum suspended from the center of the
sphere, except that the motion is not restricted to a plane.)
7.
Prove that a particle constrained to stay on a surface f(x, y, z) = 0, but subject
to no other forces, moves along a geodesic of the surface.
Hint: The potential
energy V is constant, since constraint forces are normal to the surface and so do
no work on the particle. Use Hamilton’s principle and show that the problem of
ﬁnding a geodesic and the problem of ﬁnding the path of the particle are identical
mathematics problems.
8.
Two particles each of mass m are connected by an (in-
extensible) string of length l.
One particle moves on a
horizontal table (assume no friction), The string passes
through a hole in the table and the particle at the lower
end moves up and down along a vertical line. Find the
Lagrange equations of motion of the particles. Hint: Let
the coordinates of the particle on the table be r and θ, and let the coordinate of the
other particle be z. Eliminate one variable from L (using r + |z| = l) and write two
Lagrange equations.
9.
A mass m moves without friction on the surface of the cone r = z under gravity
acting in the negative z direction. Here r is the cylindrical coordinate r =
p
x2 + y2.
Find the Lagrangian and Lagrange’s equations in terms of r and θ (that is, elimi-
nate z).
10.
Do Example 3 above, using cylindrical coordinates for m1. Hint: Use z1 and z2 for
the z coordinates of m1 and m2. What is the equation of the cone in terms of r and
z1? Note that r ̸= ρ, and θ in cylindrical coordinates is not the same as in spherical
coordinates (see Chapter 5, Figures 4.4 and 4.5).
11.
A yo-yo (as shown) falls under gravity.
Assume that it falls
straight down, unwinding as it goes. Find the Lagrange equation
of motion.
Hints: The kinetic energy is the sum of the trans-
lational energy
1
2m ˙z2 and the rotational energy
1
2I ˙θ2 where I is
the moment of inertia. What is the relation between ˙z and ˙θ?
Assume the yo-yo is a solid cylinder with inner radius a and outer radius b.
12.
Find the Lagrangian and Lagrange’s equations for a simple pendulum (Problem 4)
if the cord is replaced by a spring with spring constant k. Hint: If the unstretched
spring length is r0, and the polar coordinates of the mass m are (r, θ), the potential
energy of the spring is 1
2k(r −r0)2.
13.
A particle moves without friction under gravity on the surface of the paraboloid
z = x2 +y2. Find the Lagrangian and the Lagrange equations of motion. Show that
motion in a horizontal circle is possible and ﬁnd the angular velocity of this motion.
Use cylindrical coordinates.

490
Calculus of Variations
Chapter 9
14.
A hoop of mass M and radius a rolls without slipping down an inclined plane of
angle α. Find the Lagrangian and the Lagrange equation of motion. Hint: The
kinetic energy of a body which is both translating and rotating is a sum of two
terms: the translational kinetic energy
1
2Mv2 where v is the velocity of the center
of mass, and the rotational kinetic energy 1
2Iω2 where ω is the angular velocity and
I is the moment of inertia around the rotation axis through the center of mass.
15.
Generalize Problem 14 to any mass M of circular cross section and moment of inertia
I. Consider a hoop, a disk, a spherical shell, a solid spherical ball; order them as to
which would ﬁrst reach the bottom of the inclined plane. (For moments of inertia,
see Chapter 5, Section 4.)
16.
m
m
m
l
a

Find the Lagrangian and the Lagrange equation for
the pendulum shown. The vertical circle is ﬁxed. The
string winds up or unwinds as the mass m swings
back and forth. Assume that the unwound part of
the string at any time is in a straight line tangent
to the circle. Let l be the length of unwound string
when the pendulum hangs straight down.
17.
A simple pendulum (Problem 4) is suspended from a mass M which is free to move
without friction along the x axis. The pendulum swings in the xz plane and gravity
acts in the negative z direction. Find the Lagrangian and Lagrange’s equations for
the system.
18.
A hoop of mass m in a vertical plane rests on a frictionless table. A thread is wound
many times around the circumference of the hoop.
The free end of the thread
extends from the bottom of the hoop along the table, passes over a pulley (assumed
weightless), and then hangs straight down with a mass m (equal to the mass of the
hoop) attached to the end of the thread. Let x be the length of thread between the
bottom of the hoop and the pulley, let y be the length of thread between the pulley
and the hanging mass m, and let θ be the angle of rotation of the hoop about its
center if the thread unwinds. What is the relation between x, y, and θ? Find the
Lagrangian and Lagrange’s equations for the system. If the system starts from rest,
how does the hoop move?
For the following problems, use the Lagrangian to ﬁnd the equations of motion and then
refer to Chapter 3, Section 12.
19.
For small vibrations, ﬁnd the characteristic frequencies and the characteristic modes
of vibration of the coupled pendulums shown.
All motion takes place in a sin-
gle vertical plane. Assume the spring unstretched
when both pendulums hang vertically, and take
the spring constant as k = mg/l to simplify the
algebra. Hints: Write the kinetic and potential
energies in terms of the rectangular coordinates
of the masses relative to their positions hanging
at rest. Don’t forget the gravitational potential
energies. Then write the rectangular coordinates
x and y in terms of θ and φ, and for small vibra-
tions approximate sin θ = θ, cos θ = 1−θ2/2, and
similar equations for φ.

Section 6
Isoperimetric Problems
491
20.
Do Problem 19 if the spring constant is k = 3mg/l.
21.
m
m
l
l


Find the Lagrangian and Lagrange’s equations for
the double pendulum shown.
All motion takes
place in a single vertical plane. Hint: See the hint
in Problem 19.
22.
Do Problem 21 if the two masses are diﬀerent. Let
m be the lower mass and let M be the sum of the
two masses.
23.
For small oscillations of the double pendulum in Problem 22, let M = 4m and ﬁnd
the characteristic frequencies and characteristic modes of vibration.
24.
Do Problem 23 if M/m = 9/4
25.
Do Problem 23 in general, that is, in terms of the ratio M/m. Hint: You may ﬁnd
it helpful to use a single letter to represent
p
m/M, say α2 = m/M.
6. ISOPERIMETRIC PROBLEMS
Recall that in ordinary calculus we sometimes want to maximize a quantity subject
to a condition (for example, ﬁnd the volume of the largest box you can make with
given surface area). Also recall that the method of Lagrange multipliers was useful
in such problems (see Chapter 4, Section 9). There are similar problems in the
calculus of variations. The original question which gave this class of problems its
name was this: Of all the closed plane curves of given perimeter (isoperimetric =
same perimeter), which one incloses the largest area? To solve this problem, we
must maximize the area,

y dx, subject to the condition that the arc,

ds, is the
given length l. In other words, we want to maximize an integral subject to the
condition that another integral has a given (constant) value; any such problem is
called an isoperimetric problem. Let
I =
 x2
x1
F(x, y, y′) dx
be the integral we want to make stationary; at the same time,
J =
 x2
x1
G(x, y, y′) dx,
with the same integration variable and the same limits, is to have a given constant
value. (This means that the allowed varied paths must be paths for which J has
the given value.) By using the Lagrange multiplier method, it can be shown that
the desired condition is that
 x2
x1
(F + λG) dx
should be stationary, that is, that F + λG should satisfy the Euler equation. The
Lagrange multiplier λ is a constant. It will appear in the solution y(x) of the Euler
equation; having found y(x), we can substitute it into
 x2
x1 G(x, y, y′) dx = const.
and so ﬁnd λ if we like. However, for many purposes we do not need to ﬁnd λ.

492
Calculus of Variations
Chapter 9
Example 1.
Given two points x1 and x2 on the x axis, and an arc length l > x2 −x1, ﬁnd
the shape of the curve of length l joining the given points which, with the x axis,
incloses the largest area.
We want to maximize I =
 x2
x1 y dx subject to the condition J =
 x2
x1 ds = l.
Here F = y and G =

1 + y′2 so
(6.1)
F + λG = y + λ

1 + y′2.
We want the Euler equation for F + λG. Since
∂
∂y′ (F + λG) =
λy′

1 + y′2
and
∂
∂y(F + λG) = 1,
the Euler equation is
(6.2)
d
dx

λy′

1 + y′2

−1 = 0.
The solution of (6.2) is (Problem 7):
(6.3)
(x + c)2 + (y + c′)2 = λ2
We see that the answer to our problem is an arc of a circle passing through the two
given points, and the Lagrange multiplier λ is the radius of the circle. The center
and radius of the circle are determined by the given points x1 and x2, and the given
arc length l (Problem 7).
PROBLEMS, SECTION 6
In Problems 1 and 2, given the length l of a curve joining two given points, ﬁnd the
equation of the curve so that:
1.
The surface of revolution formed by rotating the curve about the x axis has minimum
area.
2.
The plane area between the curve and a straight line joining the points is a maximum.
3.
Given 10 cc of lead, ﬁnd how to form it into a solid of revolution of height 1 cm and
minimum moment of inertia about its axis.
4.
A uniform ﬂexible chain of given length is suspended at given points (x1, y1) and
(x2, y2). Find the curve in which it hangs. Hint: It will hang so that its center of
gravity is as low as possible.
5.
A curve y = y(x), joining two points x1 and x2 on the x axis, is revolved around
the x axis to produce a surface and a volume of revolution. Given the surface area,
ﬁnd the shape of the curve y = y(x) to maximize the volume. Hint: You should
ﬁnd a ﬁrst integral of the Euler equation of the form yf(y, x′, λ) = C. Since y = 0
at the endpoints, C = 0. Then either y = 0 for all x, or f = 0. But y ≡0 gives zero
volume of the solid of revolution, so for maximum volume you want to solve f = 0.
6.
In Problem 5, given the volume, ﬁnd the shape of the curve y = y(x) to minimize
the surface area. Hint: See the hint in Problem 5.
7.
Integrate (6.2), simplify the result and integrate again to get (6.3) where c and c′
are constants of integration. If x1 = −
√
3, x2 =
√
3, and l = 4π/3, show that the
center and radius of the circle are (0, −1) and λ = radius = 2.

Section 7
Variational Notation
493
7. VARIATIONAL NOTATION
The symbol δ was used in the early days of the development of the calculus of vari-
ations to indicate what we have called diﬀerentiation with respect to the parameter
ϵ. It is just like the symbol d in a diﬀerential except that it warns you that ϵ and
not x is the diﬀerentiation variable. The δ notation is not used much any more
in mathematics, but you will ﬁnd it in applications and so should understand its
meaning. The quantity δI is just the diﬀerential
δI = dI
dϵ dϵ,
where dI/dϵ is evaluated for ϵ = 0. The symbol δ (read “the variation of”) is also
treated as a diﬀerential operator acting on F, y, and y′; we shall deﬁne δy, δy′, and
δF in terms of our previous notation. We had in Section 2:
Y (x, ϵ) = y(x) = ϵη(x),
Y ′(x, ϵ) = y′(x) + ϵη′(x).
(7.1)
Then the meaning of δy is
(7.2)
δy =
∂Y
∂ϵ

ϵ=0
dϵ = η(x)dϵ;
this is just like a diﬀerential dY if ϵ is the variable. The meaning of δy′ is
(7.3)
δy′ =
∂Y ′
∂ϵ

ϵ=0
dϵ = η′(x)dϵ.
This is identical with
(7.4)
d
dx(δy) = d
dx[η(x)dϵ] = η′(x)dϵ
since x and ϵ are independent variables; in other words, d and δ commute. The
meaning of δF is
(7.5)
δF = ∂F
∂y δy + ∂F
∂y′ δy′;
this is just a total diﬀerential dF = (∂F/∂ϵ)ϵ=0dϵ of the function F[x, Y (x, ϵ), Y ′(x, ϵ)]
at ϵ = 0 with ϵ considered the only variable. Then the variation in I is
δI = δ
 x2
x1
F dx =
 x2
x1
δF dx
=
 x2
x1
∂F
∂y δy + ∂F
∂y′ δy′

dx
=
 x2
x1

∂F
∂y η(x)dϵ + ∂F
∂y′ η′(x)dϵ

dx.
(7.6)
If you compare (7.6) with (2.13), you ﬁnd that the following two statements about
I =  F(x, y, y′)dx mean the same thing:
(a) I is stationary; that is, dI/dϵ = 0 at ϵ = 0 as in (2.13).
(b) The variation of I is zero; that is, δI = 0 as in (7.6).

494
Calculus of Variations
Chapter 9
8. MISCELLANEOUS PROBLEMS
1.
(a)
In Section 3, we showed how to obtain a ﬁrst integral of the Euler equation
when F = F(y, y′). There is an alternative method of handling this case. You
can show that if F = F(y, y′), then F −y′∂F/∂y′ = const. To prove this,
diﬀerentiate the left-hand side with respect to x, and show that the result is
zero if F satisﬁes the Euler equation. Note that what you have is a ﬁrst integral
of the Euler equation.
(b)
Use the method of (a) to do the problems at the end of Section 3.
(c)
Consider the motion of a particle along the x axis; then L = T −V
=
1
2m ˙x2 −V (x). Note that L does not contain the independent variable t; this
corresponds to the case F = F(y, y′) in (a). Show that the ﬁrst integral found
in (a) is just the equation of conservation of energy for the mechanics problem.
Find a ﬁrst integral of the Euler equation to make stationary the integrals in Problems 2
to 4.
2.
Z b
a
x2 dy
√
1 + x′2
3.
Z b
a
yy′2 dx
p
1 + y′2
4.
Z β
α
p
r2r′2 + r4 dθ
Write and solve the Euler equations to make stationary the integrals in Problems 5 to 7.
5.
Z b
a
s
y′2
y2 + 1 dx
6.
Z b
a
p
1 + y′2
1 + y
dx
7.
Z b
a
√
1 + x
p
1 + x′2 dy
8.
Find the geodesics on the cylinder r = 1 + cos θ.
9.
Find the geodesics on the cone z = r cot α, where r2 = x2 + y2.
10.
Find the geodesics on the parabolic cylinder y = x2.
In Problems 11 to 18, use Fermat’s principle to ﬁnd the path of a light ray through a
medium of index of refraction proportional to the given function.
11.
r−1/2
12.
ey
13.
(2x + 3)−1
14.
(y + 2)1/2
15.
x1/3 Hint: In the last integration, let x = u3.
16.
r
Hint: In the last integration, let u = r2.
17.
r−1 ln r
Hint: In the last integration, let u = ln r.
18.
(x + y)1/2
Hint: Make the change of variables (45◦rotation)
X =
1
√
2
(x + y),
Y =
1
√
2
(x −y);
what is
dX2 + dY 2?
19.
Find Lagrange’s equations in polar coordinates for a particle moving in a plane if
the potential energy is V = 1
2kr2.
20.
Repeat Problem 19 if V = −K/r.
21.
Write Lagrange’s equations in cylindrical coordinates for a particle moving in the
gravitational ﬁeld V = mgz.
22.
In spherical coordinates, ﬁnd the θ Lagrange equation for a particle moving in the
potential ﬁeld V = V (r, θ, φ). What is the θ component of the acceleration? Hint:
The θ Lagrange equation is the θ component of ma = F = −∇V ; for components
of ∇V , see Chapter 6, end of Section 6, or Chapter 10, Section 9.

Section 8
Miscellaneous Problems
495
23.
A particle slides without friction around a vertical circle under the force of gravity.
Set up the Lagrange equation of motion.
24.
Write and simplify the Euler equation to make stationary the integral
Z b
a
[P(x, y) + Q(x, y)y′] dx.
Show that if the Euler equation is satisﬁed, the integral has the same value for all
paths joining a and b. (See Problem 1.3. Also see Chapter 6, Section 9, Example 2.)
25.
Find the shape of a curve of minimum length which will inclose a given area A lying
in the (x, y) plane. Find the length in terms of A.
26.
A wire carrying a uniform distribution of positive charge lies in the (x, y) plane and
joins two given points. Find its shape to minimize the electrostatic potential at the
origin.
27.
Find a ﬁrst integral of the Euler equation for Problem 26 if the length of the wire is
given.
28.
Write the θ Lagrange equation for a particle moving in a plane if V = V (r) (that
is, a central force). Use the θ equation to show that:
(a)
The angular momentum r × mv is constant.
(b)
The vector r sweeps out equal areas in equal times (Kepler’s second law).

C H A P T E R 10
Tensor Analysis
1. INTRODUCTION
You already know something about tensors although you may not have used the
term tensor. Tensors of rank (or order) zero are just scalars and tensors of rank
one are just vectors; you are already familiar with these. In 3-dimensional space a
scalar has 30 = 1 components and a vector has 31 = 3 components; a second-rank
tensor has 32 = 9 components; and in general a tensor of rank n has 3n components.
After scalars and vectors, second-rank tensors are the ones you are most likely to
ﬁnd in applications, so let’s consider an example of such a tensor.
Example 1.
Think of a beam carrying a load; there are stresses and strains in the material
of the beam. If we imagine cutting the beam in two by a plane perpendicular to
the x direction, we realize that there is a force per unit area exerted by the material
on one side of our imaginary cut on the other side. This is a vector, so it has three
components Pxx, Pxy, Pxz, where the ﬁrst subscript x is to emphasize that this is
a force across a plane perpendicular to the x direction. Similarly, if we consider a
plane perpendicular to the y direction, there is a force per unit area across this plane
with components Pyx, Pyy, Pyz; and ﬁnally across a plane perpendicular to the z
direction there is a force per unit area with components Pzx, Pzy, Pzz. At a point
in the material, then, we have a set of nine quantities which could be displayed as
a matrix:
(1.1)


Pxx
Pxy
Pxz
Pyx
Pyy
Pyz
Pzx
Pzy
Pzz


This is a second-rank tensor known as the stress tensor. The forces (per unit area)
Pxx, Pyy, Pzz are pressures or tensions; the others are shear forces (per unit area).
For example Pzy is a force per unit area in the y direction acting across a plane
perpendicular to the z direction; this force tends to shear the beam.
So far, we have simply indicated the number of components that tensors of the
various ranks have. This is not the whole story. To see what else is required, let us
talk about ﬁrst-rank tensors, that is vectors, which are already familiar to you. In
496

Section 1
Introduction
497
elementary work a vector is usually deﬁned either as a magnitude and a direction, or
as a set of three components. To see that we need to give a more careful deﬁnition,
consider this example.
Example 2.
We can draw an arrow to represent a given rotation of a rigid body in the
following way. Draw the arrow along the axis of rotation, make its length equal
to the rotation angle in radians, and let its sense be given by the right-hand rule.
Then, apparently, a rotation is a vector according to the magnitude and direction
deﬁnition. But this is not so! Take a book and rotate it 90◦about the x axis, then
90◦about the y axis. (See Chapter 3, Problem 7.31.) Repeat, rotating this time
ﬁrst about the y axis and then about the x axis. The ﬁnal positions of the book are
diﬀerent. But the sum of the two vectors does not depend on the order in which
they are added (in mathematical language, vector addition is commutative). The
arrows associated with rotations are not vectors.
Example 3.
Now let us consider the idea of a vector as a set of three components. In
order to talk about components, we must have a coordinate system. There are
inﬁnitely many coordinate systems—even for rectangular axes (x, y, z) there are
inﬁnitely many sets of rotated axes. Thus we must say that a vector consists of a
set of three components in each coordinate system. If the components of a vector
relative to one set of axes are given, we know from elementary vector analysis that
the component of the vector in any direction, or its components relative to any
rotated set of axes, can be found by taking projections. Then the new components
are deﬁnite combinations of the old components.
This fact allows us to decide
whether a physical quantity is really a vector or not. There is a similar requirement
for tensors, for example the second-rank stress tensor we have described. We could
imagine cutting the beam by a plane oriented in any given direction and ask for
the force per unit area acting across this plane. It can be shown (see Section 7)
that each component of this force is a certain combination of the nine components
of the stress tensor (1.1). Thus the components of the stress tensor in any other
coordinate system are deﬁnite combinations of the nine components of the tensor
relative to the (x, y, z) axes. In other words, tensors of all ranks, like vectors, have
a physical meaning which is independent of the reference coordinate system and
there are deﬁnite mathematical laws which relate their components in two systems.
You may wonder why we cannot make just any set of components (3 for a
vector, 9 for a second-rank tensor, etc.), given in one coordinate system, a tensor
by deﬁning its components in other systems by the correct transformation laws.
Mathematically, we could! But for a physical entity, we are not free to deﬁne its
components in various coordinate systems; they are determined by physical fact.
We merely give a mathematical description of the entity and identify it as a scalar,
a vector, a second-rank tensor, etc. (or perhaps none of these). We can see again
now why an arrow associated with a rotation is not a vector. If we treat the arrow
as a vector and take components of it, these component vectors do not represent
rotations which can be combined to give the original rotation. Thus a vector which
looks superﬁcially like the arrow we have deﬁned is not a correct mathematical
representation of the physical entity (a rotation) we are trying to describe.

498
Tensor Analysis
Chapter 10
What is the relationship between the vectors we are going to deﬁne here and the
vectors of a linear vector space (Chapter 3, Sections 10 and 14)? The ideas of an
abstract vector space grew out of the geometry of three-dimensional displacement
vectors. A change of coordinate system (for example, rotation of axes) corresponds
to a change of basis in a vector space. Because the deﬁnitions of a vector space
are set up to parallel the geometry, displacement vectors are vectors in the vector
space sense. Whether other physical entities (force, temperature, stress, etc.) are
properly modeled as vectors then depends on whether they transform under a change
of coordinate system (that is, change of basis) in the same way that displacement
vectors do. Here we want the word “vector” to refer to all physical quantities which
transform properly. Thus we shall ﬁnd the transformation law for a displacement
vector, and then deﬁne a vector as any entity which obeys the same law.
A tensor which transforms properly under a rotation of rectangular (x, y, z)
axes is called a Cartesian tensor; we will study these in some detail. Things become
a little more complicated when we consider transformations to other coordinate
systems such as spherical coordinates; we will consider this at the end of the chapter.
But for Sections 1 to 7, the term tensor will mean Cartesian tensor.
2. CARTESIAN TENSORS
In Chapter 3, Section 7, we considered the eﬀect of rotations on vectors, and empha-
sized active rotations (vector rotated, axes ﬁxed). Now we want to consider passive
rotations (vector ﬁxed, axes rotated), in order to ﬁnd how the components of a dis-
placement vector in one coordinate system are related to
its components in a rotated system. Let (x, y, z) be a set
of rectangular axes and (x′, y′, z′) another set obtained by
rotating the axes in any manner keeping the origin ﬁxed
(Figure 2.1). In the table (2.1), we list the cosines of the
nine angles between the (x, y, z) axes and the (x′, y′, z′)
axes.
(2.1)
x
y
z
x′
l1
m1
n1
y′
l2
m2
n2
z′
l3
m3
n3
Figure 2.1
In the table, l2 means the cosine of the angle between the x axis and the y′ axis,
etc. A vector r (Figure 2.1) has components x, y, z or x′, y′, z′ relative to the
two coordinate systems; we want to ﬁnd the relations between the two sets of
components.
Example 1.
Let i, j, k be unit basis vectors along the (x, y, z) axes and i′, j′, k′ be unit
basis vectors along the (x′, y′, z′) axes. Then the vector r can be written in terms
of either set of components and basis vectors as follows:
(2.2)
r = ix + jy + kz = i′x′ + j′y′ + k′z′.
Taking the dot product of this equation with i′, we get
(2.3)
r · i′ = i · i′x + j · i′y + k · i′z = x′

Section 2
Cartesian Tensors
499
(since i′ · i′ = 1, and i′ · j′ = i′ · k′ = 0). Now i · i′ is the cosine of the angle between
i and i′, that is, between the x and x′ axes, since i and i′ are unit vectors; thus
i·i′ = l1 from the table (2.1). Similarly, j·i′ = m1 and k·i′ = n1 and (2.3) becomes
(2.4)
x′ = l1x + m1y + n1z.
Similarly, dotting r into j′ nd k′, and using (2.1) we get
y′ = l2x + m2y + n2z,
z′ = l3x + m3y + n3z.
(2.5)
The equations (2.4) and (2.5) are called the transformation equations from the
coordinate system (x, y, z) to (x′, y′, z′).
Example 2.
In the same way, dotting r with i, j, k in turn, we get equations for x, y, z
in terms of x′, y′, z′:
x = l1x′ + l2y′ + l3z′,
y = m1x′ + m2y′ + m3z′,
z = n1x′ + n2y′ + n3z′.
(2.6)
These transformation equations may be written more concisely in matrix notation.
Equations (2.4) and (2.5) become the matrix equation:
(2.7)


x′
y′
z′

=


l1
m1
n1z
l2
m2
n2z
l3
m3
n3z




x
y
z


or
r′ = Ar,
where r′, A, and r stand for the matrices in (2.7). [Compare Chapter 3, equation
(7.13) for the two-dimensional case.] Similarly, (2.6) becomes
(2.8)
r = ATr′
where AT is the transpose of A. Recall from Chapter 3, Sections 7 and 9, that a
rotation matrix is an orthogonal matrix, and for an orthogonal matrix, AT = A−1.
Also see Problems 3 and 4.
Equations (2.7) or (2.8) tell us how displacement vectors in a rectangular co-
ordinate system transform under a rotation of axes.
We now use this result to
deﬁne Cartesian vectors, that is, vectors which transform in the same way that
displacement vectors do under rotations of rectangular (Cartesian) axes. We will
then generalize this to deﬁne Cartesian tensors of other ranks.
Deﬁnition of Cartesian Vectors
A Cartesian vector V consists of a set of three
numbers (components) in every rectangular coordinate system; if Vx, Vy, Vz are the
components in one system and V ′
x, V ′
y, V ′
z are the components in a rotated system,
these two sets of components are related by an equation similar to (2.7), namely,
(2.9)


V ′
x
V ′
y
V ′
z

= A


Vx
Vy
Vz


or
V′ = AV,
where A is the rotation matrix in (2.7). Alternatively, we could use (2.8) and require
that V = ATV′.

500
Tensor Analysis
Chapter 10
We can simplify our notation by making the following changes.
Replace x, y, z
by
x1, x2, x3
Replace x′, y′, z′
by
x′
1, x′
2, x′
3
Replace Vx, Vy, Vz
by
V1, V2, V3
Replace V ′
x, V ′
y, V ′
z
by
V ′
1, V ′
2, V ′
3
(2.10)
Replace A in (2.7)
by


a11
a12
a13
a21
a22
a23
a31
a32
a33


In this notation (2.7) and (2.9) become (2.11) and (2.12):
(2.11)
x′
i =
3

j=1
aijxj,
i = 1, 2, 3,
(2.12)
V ′
i =
3

j=1
aijVj,
i = 1, 2, 3.
Alternatively, we could solve (2.11) for the x coordinates in terms of the x′ coor-
dinates as in (2.8), to get, in the summation form: xi =
3

j=1
ajix′
j, and a similar
companion formula to (2.12), namely
(2.13)
Vi =
3

j=1
ajiV ′
j .
Since we will occasionally want the transformation formula for a Cartesian vector
solved for the unprimed components as in (2.13), you should be sure you understand
(2.13). Compare carefully the indices in (2.12) and (2.13). In matrix form (2.12) is
V′ = AV and (2.13) is V = ATV′ [see equations (2.7) and (2.8)]. Now element i, j
of AT is the same as element j, i of A, so the coeﬃcients in (2.13) are aji instead of
aij as they were in (2.12). It is now straightforward to deﬁne tensors.
Deﬁnition of Cartesian Tensors
A tensor of rank zero has one component
which is unchanged by a rotation of axes; it is called an invariant or a scalar.
Simple examples are the length of a vector, or the dot product of two vectors. A
ﬁrst rank tensor is just a vector. A tensor of second rank has nine components (in
three dimensions) in every rectangular coordinate system. If we call the components
in one system Tij, the components T ′
kl in a rotated coordinate system are given by
(2.14), where the a’s are the direction cosines in the rotation matrix A.
(2.14)
T ′
kl =
3

i=1
3

j=1
akialjTij,
k, l = 1, 2, 3.

Section 2
Cartesian Tensors
501
Direct Product
We can give a very simple example of a second-rank tensor.
Example 3.
Let U and V be vectors; we form the following array (in each coordinate
system) from the components U1, U2, U3 and V1, V2, V3 of U and V (in that
coordinate system):
(2.15)
U1V1
U1V2
U1V3
U2V1
U2V2
U2V3
U3V1
U3V2
U3V3
We can show that these nine quantities are the components of a second-rank tensor
which we shall denote by UV.
Note that this is not a dot product or a cross
product; it is called the direct product of U and V (or outer product or tensor
product). Since U and V are vectors, their components in a rotated coordinate
system are, by (2.12):
(2.16)
U ′
k =
3

i=1
akiUi,
V ′
l =
3

j=1
aljVj.
Hence the components of the second-rank tensor UV are
(2.17)
U ′
kV ′
l =
3

i=1
akiUi
3

j=1
aljVj =
3

i,j=1
akialjUiVj,
which is just (2.14) with Tij = UiVj and T ′
kl = U ′
kV ′
l .
Equation (2.14) generalizes immediately. For example, a 4th-rank Cartesian ten-
sor is deﬁned as a set of 34 or 81 components Tijkl, in every rectangular coordinate
system, which transform to a rotated coordinate system by the equations
(2.18)
T ′
αβγδ =

i,j,k,l
aαiaβjaγkaδlTijkl,
where i, j, k, l take the values 1, 2, 3. Note that a 4th-rank tensor has 4 indices and
requires four a’s in its deﬁnition. Similarly, an nth-rank tensor has n indices and
requires n a’s in its deﬁnition. Also we can generalize (2.17) to show, for example,
that the direct product of a vector and a 3rd-rank tensor produces a 4th-rank tensor,
and, in general, the direct product of tensors of ranks n and m is a tensor of rank
m + n (see Problem 7).
PROBLEMS, SECTION 2
1.
Verify equations (2.6).
2.
Show that the sum of the squares of the direction cosines of a line through the origin
is equal to 1 Hint: Let (a, b, c) be a point on the line at distance 1 from the origin.
Write the direction cosines in terms of (a, b, c).
3.
Consider the matrix A in (2.7) or (2.10). Think of the elements in each row (or col-
umn) as the components of a vector. Show that the row vectors form an orthonormal
triad (that is each is of unit length and they are all mutually orthogonal), and the
column vectors form an orthonormal triad.

502
Tensor Analysis
Chapter 10
4.
Any rotation of axes in three dimensions can be described by giving the nine direction
cosines of the angle between the (x, y, z) axes and the (x′, y′, z′) axes. Show that
the matrix A of these direction cosines in (2.7) or (2.10) is an orthogonal matrix.
Hint: See Chapter 3, Section 9. Find AAT and use Problem 3.
5.
Write equations (2.12) out in detail and solve the three simultaneous equations (say
by determinants) for x1, x2, x3 in terms of x′
1, x′
2, x′
3 to verify equations (2.13). Use
your results in Problem 4.
6.
Write the transformation equation for a 3rd-rank tensor; for a 5th-rank tensor.
7.
Following what we did in equations (2.14) to (2.17), show that the direct product
of a vector and a 3rd-rank tensor is a 4th-rank tensor. Also show that the direct
product of two 2nd-rank tensors is a 4th-rank tensor. Generalize this to show that
the direct product of two tensors of ranks m and n is a tensor of rank m + n.
8.
Write the equations in (2.16) and so in (2.17) solved for the unprimed components
in terms of the primed components.
3. TENSOR NOTATION AND OPERATIONS
Summation Convention
As you may have noticed in the last section, tensor
equations use a lot of summation signs—it would be a simpliﬁcation if we could
get along without them. Using the summation convention (or Einstein summation
convention), we omit the summation signs in equations like (2.11) to (2.14), and
(2.16) to (2.18), and simply understand a summation over any index which appears
exactly twice in one term. Here are some examples using summation convention (in
three dimensions).
Examples.
aii or ajj or aββ, etc.
means
a11 + a22 + a33;
xixi or xαxα, etc.
means
x2
1 + x2
2 + x2
3;
aijbjk
means
ai1b1k + ai2b2k + ai3b3k;
∂u
∂xj
∂xj
∂x′
i
means
∂u
∂x1
∂x1
∂x′
i
+ ∂u
∂x2
∂x2
∂x′
i
+ ∂u
∂x3
∂x3
∂x′
i
;
TijklSijVkUl
means

i

j

k

l
TijklSijVkUl;
(3.1)
and so on. The repeated index (which is summed over) is called a dummy index;
like an integration variable in a deﬁnite integral, it does not matter what letter is
used for it. An index which is not repeated is called a free index.
When summation convention is being used, we are not warned by a summation
sign what letters to sum over; we just have to inspect the indices and see which
ones appear twice. In writing terms using the summation convention, we must be
careful not to re-use an index. For example, if we already have two i subscripts
indicating a sum over i, and we want another sum in the same term, we must use
a diﬀerent dummy index, say j or m or α, etc. In the following discussion we will
use summation convention; watch carefully for the repeated dummy indices.
Contraction
The transformation equations for a 4th-rank tensor are [see (2.18)]
(3.2)
T ′
αβγδ = aαiaβjaγkaδlTijkl.
(Note the sums over i, j, k, and l).

Section 3
Tensor Notation and Operations
503
Example 1.
Now suppose we put δ = β which, by summation convention, means a further
sum over β. Then we have
(3.3)
T ′
αβγβ = aαiaβjaγkaβlTijkl.
Now aβjaβl (summed over β) is the dot product of columns j and l of the rotation
matrix A [see Problem (2.3)]. This dot product is 1 if j = l, and 0 otherwise. In
other words aβjaβl = δjl [see Chapter 3, equation (9.4)]. Then δjlTijkl becomes
Tijkj since δjl is zero unless j and l are equal. (The repeated dummy index could
be either j or l or anything else except the dummy indices i and k which are already
used, and the free indices α and γ). Thus we have
(3.4)
T ′
αβγβ = aαiaγkδjlTijkl = aαiaγkTijkj
Now (3.4) says that Tijkj are the components of a 2nd-rank tensor since there are
two free indices and two a factors are required [compare equation (2.14)]. This
process of setting two indices of a tensor equal to each other and then summing
is called contraction. Contraction reduces the rank of a tensor by 2. Note that in
(3.2) we started with a 4th-rank tensor and after contracting we have a tensor of
rank 2 in (3.4).
It is interesting to observe that the dot (or scalar or inner) product of two vectors
in elementary vector analysis is an example of contraction. In Section 2 we showed
that the direct product of two vectors [see (2.17)] is a 2nd-rank tensor. If we contract
UiVj to get UiVi we have the dot product of vectors U and V, which is a scalar.
Again note that contraction has reduced the rank of a tensor by 2 (a scalar is a
tensor of rank zero).
Tensors and Matrices
The components of ﬁrst or second rank tensors can be
displayed as matrices and this is often useful. We have frequently (see Chapter 3)
written the components of a vector (1st-rank tensor) as a column or row matrix.
The components Tij of a 2nd-rank tensor can be written as the elements of a square
matrix (see inertia matrix, Section 4).
Then note that in the tensor equation,
Ui = TijVj, the contraction (sum on j) corresponds exactly to row times column
multiplication for matrices.
Symmetric and Antisymmetric Tensors
A 2nd-rank tensor Tij is called sym-
metric if Tij = Tji, and antisymmetric (or skew symmetric) if Tij = −Tji. Note that
these agree with the corresponding deﬁnitions for matrices [Chapter 3, (9.2)]. Any
2nd-rank tensor can be written as a sum of a symmetric tensor and an antisymmetric
tensor as in (3.5) (Problem 13).
(3.5)
Tij = 1
2(Tij + Tji) + 1
2(Tij −Tji).
For tensors of higher rank, similar terminology is used. If an exchange of two indices
leaves the tensor component unchanged, we say that the tensor is symmetric with
respect to those two indices.
If an exchange of two indices changes the tensor
component to its negative, we say that the tensor is antisymmetric with respect to
those two indices.

504
Tensor Analysis
Chapter 10
Combining tensors
The sum or diﬀerence (in fact linear combination) of two
tensors of rank n is a tensor of rank n (Problems 6 and 7). For example, Tij +RijkVk
is a tensor of rank 2. Note the summation convention and the contraction which
makes RijkVk also a tensor of rank 2 so that we can add it to Tij. (Addition is not
deﬁned for tensors of diﬀerent ranks.)
Quotient Rule
Let us suppose we know that, for every vector Vj, the quantities
Ui = TijVj are the components of a non-zero vector and that this holds true in
all rotated coordinate systems. Then we can prove that the quantities Tij are the
components of a 2nd-rank tensor. This is an example of the quotient rule.
Example 2.
To prove this, we need the following equations:
T ′
αβV ′
β = U ′
α,
given equation in rotated system;
U ′
α = aαiUi,
U is a vector;
Ui = TijVj,
given equation;
Vj = aβjV ′
β,
V is a vector; see equation (2.13).
(3.6)
Now, putting this all together we have
(3.7)
T ′
αβV ′
β = U ′
α = aαiUi = aαiTijVj = aαiTijaβjV ′
β.
Factoring out V ′
β from the ﬁrst and last steps, we have
(3.8)
(T ′
αβ −aαiaβjTij)V ′
β = 0
for all vectors V′.
Since V′ is arbitrary, the parenthesis in (3.8) is equal to zero (Problem 8). Thus
we have
(3.9)
T ′
αβ = aαiaβjTij.
Now (3.9) is the transformation equation for a 2nd-rank tensor [compare (2.14)], so,
as claimed, the quantities Tij are the components of a 2nd-rank tensor.
The quotient rule is useful in determining whether some given quantities are
the components of a tensor. [As an example of this, see (4.1).] Suppose X is a set
of 3n components (the right number for a tensor of rank n in 3 dimensions). The
quotient rule says that if the product of X and an arbitrary tensor is a non-zero
tensor, then X is a tensor. The product may be either a direct product or a direct
product combined with one or more contractions. We have proved the quotient rule
for one case but the proof of any case follows this same pattern. Given XA = B,
where A is an arbitrary tensor and B is a non-zero tensor, we use the transformation
equations for A and B, and the fact that A is arbitrary, to ﬁnd the transformation
equations for X (see Problems 9 to 12).

Section 4
Inertia Tensor
505
PROBLEMS, SECTION 3
1.
Write equations (2.11), (2.12), (2.13), (2.14), (2.16), (2.17), and (2.18) using sum-
mation convention.
2.
Show that the fourth expression in (3.1) is equal to ∂u/∂x′
i. By equations (2.6) and
(2.10), show that ∂xj/∂x′
i = aij, so
∂u
∂x′
i
= ∂u
∂xj
∂xj
∂x′
i
= aij ∂u
∂xj .
Compare this with equation (2.12) to show that ∇u is a Cartesian vector. Hint:
Watch the summation indices carefully and if it helps, put back the summation signs
or write sums out in detail as in (3.1) until you get used to summation convention.
3.
As we did in (3.3), show that the contracted tensor Tiij is a ﬁrst-rank tensor, that
is, a vector.
4.
Show that the contracted tensor TijkVk is a 2nd-rank tensor.
5.
Show that TijklmSlm is a tensor and ﬁnd its rank (assuming that T and S are tensors
of the rank indicated by the indices).
6.
Show that the sum of two 3rd-rank tensors is a 3rd-rank tensor. Hint: Write the
transformation law for each tensor and then add your two equations. Divide out the
a factors to leave the result T ′
αβγ + S′
αβγ = aαiaβjaγk(Tijk + Sijk) using summation
convention.
7.
As in problem 6, show that the sum of two 2nd-rank tensors is a 2nd-rank tensor;
that the sum of two 4th-rank tensors is a 4th-rank tensor.
8.
Show that (3.9) follows from (3.8). Hint: Give a proof by contradiction. Let Sαβ be
the parenthesis in (3.8); you may ﬁnd it useful to think of the components written
as a matrix. You want to prove that all 9 components of Sαβ are zero. Suppose it
is claimed that S12 is not zero. Since V ′
β is an arbitrary vector, take it to be the
vector (0, 1, 0), and observe that SαβV ′
β is then not zero in contradiction to (3.8).
Similarly show that all components of Sαβ are zero as (3.9) claims.
Prove the quotient rule in each of the following problems, that is, given XA = B where A
is any arbitrary tensor and B is a non-zero tensor, show that X is a tensor. Hints: Follow
the general method in (3.6) to (3.9). See the last sentence of the section.
9.
XiAij = Bj
10.
XiAj = Bij
11.
XijAk = Bijk
12.
XijklAkl = Bij
13.
Show that the ﬁrst parenthesis in (3.5) is a symmetric tensor and the second paren-
thesis is antisymmetric.
4. INERTIA TENSOR
Inertia tensor
If a rigid body is rotating about a ﬁxed axis, then from elemen-
tary mechanics we know that τ = dL/dt where τ is the torque and L is the angular
momentum about the rotation axis. The angular velocity ω and the angular mo-
mentum L are related by the equation L = Iω where I is the moment of inertia
of the body about the rotation axis. For rotation about a ﬁxed axis, L and ω are
parallel vectors, and I is a scalar. But if the rotation axis is not ﬁxed, the angular
velocity and the angular momentum may not be parallel.

506
Tensor Analysis
Chapter 10
Example 1.
Try the following experiment. Take a small book bound by a rubber band,
hold it by one corner and toss it upward giving it a spin. As it falls observe that
it tumbles, that is, the angular velocity ω about the center of mass is not ﬁxed in
direction. However, by deﬁnition of the center of mass, the gravitational torque
τ about the center of mass is zero so τ = dL/dt = 0.
(We are neglecting air
resistance.) Thus L is a constant vector, and a constant L and a changing ω are
not parallel. Then if the equation L = Iω is to be true, I cannot be a scalar.
We have seen this situation before; look at the discussion of the quotient rule in
Section 3 and the proof of the case we have here in (3.5) to (3.8). Since L and ω are
vectors, we see by the quotient rule that (when L and ω are not parallel) the scalar
I must be replaced by a 2nd-rank tensor with components Ijk. Then in component
form we have
(4.1)
Lj = Ijkωk
Example 2.
Next we want to ﬁnd the components of the inertia tensor. For simplicity,
ﬁrst consider a point mass m at the tip of a vector r with tail at the origin O.
From Chapter 6, end of Section 3, the angular momentum of m about the origin
is L = mr × (ω × r) where ω is the angular velocity of the mass m about O.
(See Chapter 6, Figures 2.6 and 3.8.) We can expand the triple vector product [see
Chapter 6, equation (3.8)] to get
(4.2)
L = mr × (ω × r) = m[r2ω −(r · ω)r] = m[r2ω −(xωx + yωy + zωz)r].
Next we write the components of L in terms of the components of ω. For example,
taking the x component of (4.2), we ﬁnd
(4.3)
Lx = m[r2ωx −(xωx + yωy + zωz)x] = m[(r2 −x2)ωx −xyωy −xzωz].
Thus three components of the inertia tensor are
(4.4)
Ixx = m(r2 −x2) = m(y2 + z2), Ixy = −mxy, Ixz = −mxz.
The other 6 components can be found similarly by taking the y and z components
of (4.2) (Problem 1).
Example 3.
If, instead of a single mass, we have a set of masses or an extended body, then
the expressions for the components of the inertia tensor become sums or integrals.
Ixx =

i
mi(y2
i + z2
i )
or

(y2 + z2) dm,
Ixy = −

i
mixiyi
or
−

xy dm, etc. (Problem 1.)
(4.5)
It is useful to write (4.1) as a matrix equation (see discussion in Section 3
about contraction).
Then the inertia tensor components form a square matrix.
This matrix is symmetric and so we know from Chapter 3, Section 11, that it
can be diagonalized by an orthogonal similarity transformation. The new axes are
called the principal axes of inertia and the three eigenvalues are called the principal
moments of inertia. We see that the equations of motion are simpler relative to the
principal axes.

Section 4
Inertia Tensor
507
Example 4.
Find the inertia tensor about the origin for the mass distribution consisting
of a mass 1 at (0, 1, 1) and a mass 2 at (1, −1, 0). Find the principal moments of
inertia and the principal axes.
Substituting (x1, y1, z1) = (0, 1, 1), m1 = 1, and (x2, y2, z2) = (1, −1, 0), m2 = 2
into (4.5), we ﬁnd Ixx = (12 + 12) + 2(−1)2 = 4, Ixy = Iyx = −0 −2(−1) = 2.
Continuing in the same way, we can ﬁnd the rest of the components (Problem 2)
and write them as an inertia matrix
I =


4
2
0
2
3
−1
0
−1
5


Either by hand or by computer we ﬁnd that the eigenvalues of the matrix I are 6 and
3 ±
√
3; these are the principal moments of inertia. The corresponding eigenvectors
are (1, 1, −1), (−1 −
√
3, 2 +
√
3, 1), (−1 +
√
3, 2 −
√
3, 1); these are vectors along
the principal axes of inertia.
Example 5.
Find the inertia tensor about the origin for a mass of uniform density = 1,
inside the part of the unit sphere in the ﬁrst octant, that is, x > 0, y > 0, z > 0.
We will write the integrals for the components of the inertia tensor ﬁrst in
rectangular coordinates and then switch to spherical coordinates [see Chapter 5,
equation (4.5)] to evaluate them since the limits are then simpler. Satisfy yourself
that in order to cover the required volume, the limits are: r from 0 to 1, θ from 0
to π/2, and φ from 0 to π/2. Then
Ixx =

(r2 −x2) dV =
 1
r=0
 π/2
θ=0
 π/2
φ=0
(r2 −r2 sin2 θ cos2 φ)r2 sin θ dr dθ dφ = π
15.
Ixy =

(−xy) dV =
−
 1
r=0
 π/2
θ=0
 π/2
φ=0
(r2 sin2 θ cos φ sin φ)r2 sin θ dr dθ dφ = −1
15.
Similarly, the other integrals can be written and evaluated (Problem 3). Alterna-
tively, it may be clear that by symmetry the three diagonal components are all the
same, and all the oﬀ-diagonal components are the same. Then the inertia matrix is
I = 1
15


π
−1
−1
−1
π
−1
−1
−1
π

.
As in Example 4, we ﬁnd (Problem 3):
Principal moments of inertia:
(π −2, π + 1, π + 1)
15
Principal axes of inertia:
(1, 1, 1), and any two orthogonal vectors in the
plane x + y + z = 0, for example, (1, −1, 0) and
(1, 1, −2).

508
Tensor Analysis
Chapter 10
PROBLEMS, SECTION 4
1.
As in (4.3) and (4.4), ﬁnd the y and z components of (4.2) and the other 6 com-
ponents of the inertia tensor. Write the corresponding components of the inertia
tensor for a set of masses or an extended body as in (4.5).
2.
Complete Example 4 to verify the rest of the components of the inertia tensor and
the principal moments of inertia and principal axes. Verify that the three principal
axes form an orthogonal triad.
3.
As in Problem 2, complete Example 5.
4.
Find the inertia tensor about the origin for a mass of uniform density = 1, inside
the part of the unit sphere where x > 0, y > 0, and ﬁnd the principal moments of
inertia and the principal axes. Note that this is similar to Example 5 but the mass
is both above and below the (x, y) plane. Warning hint: This time don’t make the
assumptions about symmetry that we did in Example 5.
For the mass distributions in Problems 5 to 7, ﬁnd the inertia tensor about the origin, and
ﬁnd the principal moments of inertia and the principal axes.
5.
Point masses 1 at (1, 1, 1) and at (−1, 1, 1).
6.
Point masses 1 at (1, 1, −2) and 2 at (1, 1, 1).
7.
Mass of uniform density = 1, bounded by the coordinate planes and the plane
x + y + z = 1.
8.
For the point mass m we considered in (4.2) to (4.4), the velocity is v = ω ×r so the
kinetic energy is T = 1
2mv2 = 1
2m(ω × r) · (ω × r). Show that T can be written in
matrix notation as T = 1
2ωTI ω where I is the inertia matrix, ω is a column matrix,
and ωT is a row matrix with elements equal to the components of ω.
5. KRONECKER DELTA AND LEVI-CIVITA SYMBOL
The Kronecker δ is deﬁned in Chapter 3, equation (9.3) but let’s repeat it here for
convenience.
(5.1)
δij =
 1
if
i = j,
0
otherwise.
The deﬁnition of the Levi-Civita symbol (or permutation symbol) is
(5.2)
ϵijk =



1
if i, j, k = 1, 2, 3 or 2, 3, 1 or 3, 1, 2;
−1
if i, j, k = 3, 2, 1 or 2, 1, 3 or 1, 3, 2;
0
if any indices are repeated.
Note in (5.2) that if you read the indices i, j, k, cyclically (as if they were written
around a circle so you can start anywhere), then if the indices read in the direction
1, 2, 3, 1, 2, 3, 1, · · ·, the result is +1; if the indices read in the opposite direction the
result is −1.

Section 5
Kronecker Delta and Levi-Civita Symbol
509
We can say (5.2) in another way which is sometimes useful.
Start with the
fact that ϵ123 = +1. Now if we exchange any two indices, we change the sign; for
example ϵ321 = −1 (we exchanged 1 and 3). If we now continue this process and
exchange 1 and 2 in ϵ321 = −1, we have ϵ312 = +1. [Try a few more and compare
with (5.2).] The result of an even number of exchanges in 123 is called an even
permutation of 123 and the result of an odd number of exchanges is called an odd
permutation of 123. Thus we could replace (5.2) by the deﬁnition
(5.3)
ϵijk =



1
if i, j, k = an even permutation of 1, 2, 3;
−1
if i, j, k = an odd permutation of 1, 2, 3;
0
if any indices are repeated.
We say that ϵijk is totally antisymmetric (see Section 3), that is, it is antisymmet-
ric with respect to every pair of indices, since each exchange of indices produces a
change in sign.
Isotropic Tensors
A Cartesian isotropic tensor means a tensor which has the
same components in all rotated coordinate systems. The deﬁnitions (5.1) to (5.3)
are general, independent of any reference system. Thus to show that δij and ϵijk are
isotropic tensors, we need to show that a tensor transformation simply reproduces
the tensor we start with, that is, δ′ = δ and ϵ′ = ϵ. In this section we shall show
this and develop some useful formulas.
Kronecker delta
To show that δij is an isotropic 2nd-rank tensor, we write the
tensor transformation to a rotated system and show that it gives δ′ = δ.
(5.4)
δ′
mn = amianjδij = amjanj = δmn.
Remember summation convention and follow carefully the sums in (5.4). Note in
the second step that ami becomes amj because δij is zero unless i = j. (We could
just as well change anj to ani and sum on i.) In the last step, amjanj (or amiani)
is the dot product of rows m and n of the rotation matrix and this is δmn (see
Problem 2.3). Thus the Kronecker δ is a 2nd-rank isotropic Cartesian tensor.
Determinants
We can write a useful formula for the value of a 3-by-3 determi-
nant using the Levi-Civita symbol:
(5.5)
det A = a1ia2ja3kϵijk.
It is straightforward to show (Problem 1) that (5.5) is equivalent to a Laplace
development. Another useful formula is
(5.6)
ϵαβγ det A = aαiaβjaγkϵijk.
Again it is straightforward (although lengthy) to show that this is equivalent to a
Laplace development (Problem 2).

510
Tensor Analysis
Chapter 10
Levi-Civita Symbol
To show that ϵijk is an isotropic tensor, we write the trans-
formation equation to a rotated system. We ﬁnd
(5.7)
ϵ′
αβγ = aαiaβjaγkϵijk = ϵαβγ.
In the last step we used (5.6) with det A = 1 (recall from Chapter 3, Section 7, that
if A is a rotation matrix, det A = 1). Thus ϵαβγ is a 3rd-rank isotropic Cartesian
tensor (assuming only rotated coordinate systems; for reﬂections see Section 6).
Products of Isotropic Tensors
We can ﬁnd other isotropic tensors from direct
products of the two we have, or from direct products followed by contraction. Recall
from Sections 2 and 3 that the direct product of two tensors of ranks n and m is
a tensor of rank n + m and that each contraction produces another tensor of rank
smaller by 2. If the tensors you multiply are isotropic, the products are also isotropic
(Problems 3 and 4).
To simplify products of two Levi-Civita tensors, the following formula is useful.
(5.8)
ϵijkϵimn = δjmδkn −δjnδkm
Both sides of (5.8) are 4th-rank tensors (contracted 6th-rank on the left) with free
indices j, k, m, n. We want to see that (5.8) is true for any choice of these four
indices. Most choices will just give 0 = 0; let’s consider what is required for the
product of ϵ’s to be diﬀerent from zero.
Example 1.
Remember that an ϵ is zero unless its three indices are all diﬀerent. Since
the ﬁrst index is the same in ϵijk and ϵimn, the product is diﬀerent from zero only
if the other two indices (j, k and m, n) are the same pair in both ϵ’s. (For example,
if i = 1, then j, k and m, n must be 2, 3 or 3, 2.) This means that either (1) j = m
and k = n, or (2) j = n and k = m. In case (1), the two ϵ’s are the same (both
= +1 or both = −1) so the product is +1; this is the same as δjmδkn on the right
side of (5.8). In case (2), the indices on the two ϵ’s are ijk and ikj so one of them
is an even permutation of 1, 2, 3 and the other is an odd permutation. Thus the
product of the two ϵ’s is −1, and this is the same as −δjnδkn on the right side of
(5.8). Note that, given j, k, m, n satisfying either j, k = m, n or j, k = n, m, only
one term in the sum over i is diﬀerent from zero, that is, the term with i diﬀerent
from either j or k. Also see Problem 5.
Now that we have (5.8), it is easy to write a similar formula with the contraction
(sum) over a diﬀerent pair of indices. Suppose we want ϵabcϵpqb. Recall that an ϵ is
not changed by cyclic permutation of its indices [see discussion after (5.2)]. Thus
ϵabc = ϵbca and ϵpqb = ϵbpq [we have cyclically permuted the indices so that the
summation index b appears as the ﬁrst index for each ϵ as it does in (5.8)]. Now,
this is the same pattern as in (5.8), with the sum over the ﬁrst index of each ϵ [i in
(5.8), b in the second step in (5.9)], so we have
(5.9)
ϵabcϵpqb = ϵbcaϵbpq = δcpδaq −δcqδap
It may be helpful in writing this to repeat what we said in getting (5.8). In (5.9),
the product ϵbcaϵbpq is zero unless either c, a = p, q, or c, a = q, p, as indicated by
the right side of (5.9). For practice, do Problem 7.

Section 5
Kronecker Delta and Levi-Civita Symbol
511
We can further contract (5.8) to get (Problem 8).
(5.10)

ϵijkϵijn = 2δkn,
ϵijkϵijk = 6.
Vector Identities
The familiar formulas in vector analysis can be written in
tensor form using δij and ϵijk. [See Am. J. Phys. 34, 503–507 (1966).] We have
already commented (Section 3) that the dot product A · B is the contracted direct
product, AiBi. Now let’s show that the components of the cross product of two
vectors can be written as
(5.11)
(B × C)i = ϵijkBjCk.
To see that this is correct we look at one component at a time and compare the
result with Chapter 3, equation (4.19), replacing x, y, z by 1, 2, 3. To ﬁnd the
ﬁrst component of B × C in (5.11), we let i = 1. Then the only nonzero terms on
the right side of (5.11) are the two with j, k = 2, 3 or 3, 2, so we ﬁnd that the ﬁrst
component of B × C is (B2C3 −B3C2), in agreement with Chapter 3. Similarly
the other components agree with the vector analysis deﬁnition of a cross product
(Problem 9a).
Example 2.
Now let’s use (5.11) to write a triple vector product in tensor form, and then
use (5.8) or (5.9) to simplify it (Problem 9b).
[A × (B × C)]n = ϵnipAi(B × C)p = ϵnipAi[ϵpjkBjCk]
(5.12)
= ϵnipϵpjkAiBjCk = ϵpniϵpjkAiBjCk
= (δnjδik −δnkδij)AiBjCk = Bn(AiCi) −Cn(AiBi)
= components of B(A · C) −C(A · B).
We recognize the ﬁnal step as the formula [Chapter 6, (3.8)] for the triple vector
product; we have just derived it in tensor form. Similarly we can prove other vector
formulas (see Problems 10 to 13).
Recall from Chapter 6 that we treated ∇as if it were “almost” a vector. Here
we can similarly treat it as a ﬁrst rank tensor, always remembering that it is also a
diﬀerential operator. The components of ∇are ∂/∂xi, so as in (5.11) we write
(5.13)
(∇× V)i = ϵijk
∂
∂xj
Vk.
Then following the method of (5.12), we next ﬁnd the components of curl curlV in
tensor form [compare part (e) in the table at the end of Chapter 6].

512
Tensor Analysis
Chapter 10
[∇× (∇× V)]n = ϵnip
∂
∂xi
(∇× V)p
(5.14)
= ϵnip
∂
∂xi
[ϵpjk
∂
∂xj
Vk]
= ϵpniϵpjk
∂
∂xi
∂
∂xj
Vk
= (δnjδik −δnkδij) ∂
∂xi
∂
∂xj
Vk
=
∂
∂xn
 ∂
∂xi
Vi

−∂
∂xi
∂
∂xi
Vn
= components of ∇(∇· V) −∇2V.
Dual tensors
Let Tij be an antisymmetric 2nd-rank tensor, that is, Tij = −Tji.
If we display the components Tij as elements of a matrix, it looks like this (see
Problem 14).
(5.15)
T =


0
T12
−T31
−T12
0
T23
T31
−T23
0


Observe that there are just 3 independent nonzero components, just enough to be
the components of a vector. (Note that this happens only in 3 dimensions—see
Problem 15.) If we deﬁne
(5.16)
Vi = 1
2ϵijkTjk
then we ﬁnd (Problem 16)
(5.17)
V1 = T23,
V2 = T31,
V3 = T12.
Since ϵijk and Tjk are tensors and Vi is a contracted direct product of them, we are
assured that Vi is a ﬁrst rank tensor, that is, a vector (but see Section 6). Thus the
three quantities in (5.17) can be considered as the three independent components
of an antisymmetric 2nd-rank tensor Tij, or as the three components of a vector Vk
called the dual of Tij. We can also start with a vector Vk and deﬁne Tij in terms
of it (Problem 16).
(5.18)
Tij = ϵijkVk
Now suppose Aj and Bk are vectors. Then Tjk = AjBk −AkBj is a 2nd-rank
antisymmetric tensor, and the three independent components of Tjk are just the
components of A × B (Problem 17). Thus we see that the vector product can be
considered as either a vector or a 2nd-rank antisymmetric tensor.
PROBLEMS, SECTION 5
1.
Verify that (5.5) agrees with a Laplace development, say on the ﬁrst row (Chapter
3, Section 3). Hints: You will ﬁnd 6 terms corresponding to the 6 non-zero values
of ϵijk. First let i = 1; then j, k can be 2, 3 or 3, 2. These two terms give you a11
times its cofactor. Next let i = 2 with j, k = 1, 3 and 3, 1, and show that you get
a12 times its cofactor. Finally let i = 3. Watch all the signs carefully.

Section 5
Kronecker Delta and Levi-Civita Symbol
513
2.
Verify for a few representative cases that (5.6) gives the same results as a Laplace
development. First note that if α, β, γ = 1, 2, 3, then (5.6) is just (5.5). Then try
letting α, β, γ = an even permutation of 1, 2, 3, and then try an odd permutation,
to see that the signs work out correctly. Finally try a case when ϵαβγ = 0 (that is
when two of the indices are equal) to see that the right hand side of (5.6) is zero
because you are evaluating a determinant which has two identical rows.
3.
Show that δijϵklm is an isotropic tensor of rank 5. Hint: Combine equations (5.4)
and (5.7).
4.
Generalize Problem 3 to see that the direct product of any two isotropic tensors (or
a direct product contracted) is an isotropic tensor. For example show that ϵijkϵlmn
is an isotropic tensor (what is its rank?) and ϵijkϵlmnδjn is an isotropic tensor (what
is its rank?).
5.
Let Tjkmn be the tensor in (5.8).
This is a 4th-rank tensor and so has 34 = 81
components. Most of the components are zero. Find the nonzero components and
their values. Hint: See discussion after (5.8).
6.
Evaluate:
(a) δijδjkδkmδim
(b) ϵijkδjk
(c) ϵjk2ϵk2j
(d) ϵ3jkϵkj3
(e) ϵ23iϵ2i3
(f) ϵk31ϵ3k1
7.
Write in terms of δ’s as in (5.8) and (5.9):
(a) ϵijkϵpjq
(b) ϵabcϵpqc
8.
Show that the equations (5.10) are correct. Hints: You can do these by further
contracting (5.8). You can also do them by direct argument as follows: In the ﬁrst
equation, why must k = n? If k = n, then how many choices are there for i and j?
In the second equation, in how many ways can you arrange the three numbers 1, 2,
3, and for each arrangement, what is the product of the ϵ’s?
9.
(a)
Finish the work of showing that the cross product components are correctly
given by (5.11). Hints: Follow the text discussion just after (5.11). For the
second component, let i = 2; etc.
(b)
Go through the sums in (5.12) carefully to verify each step. Hints: Use (5.11)
twice being careful about repeated indices, and look at the discussion after
equation (5.4).
(c)
Similarly check (5.14).
10.
(a)
Write the triple scalar product A · (B × C) in tensor form and show that it is
equal to the determinant in Chapter 6, equation (3.2). Hint: See (5.5).
(b)
Write equation (3.2) of Chapter 6 in tensor form to show the equivalence of
the various expressions for the triple scalar product. Hint: Change the dummy
indices as needed.
11.
Using problem 10, write A · (B × A) in tensor notation and show that it is = 0.

514
Tensor Analysis
Chapter 10
12.
Write and prove in tensor notation:
(a)
Chapter 6, Problem 3.13.
(b)
Chapter 6, Problem 3.14.
(c)
Lagrange’s identity: (A × B) · (C × D) = (A · C)(B · D) −(A · D)(B · C).
(d)
(A × B)× (C× D) = (ABD)C−(ABC)D, where the symbol (XYZ) means
the triple scalar product of the three vectors.
13.
Write in tensor notation and prove the following vector operator identities in the
table at the end of Chapter 6: parts (b), (d), (f), (g), (h), (k).
14.
Show that the diagonal elements of an antisymmetric tensor are zero and that (5.15)
is a correct display of the components of an antisymmetric 2nd-rank tensor in 3
dimensions.
15.
Write a 4-by-4 antisymmetric matrix to show that there are 6 diﬀerent components,
not the 4 components of a vector in 4 dimensions.
16.
Verify that (5.16) gives (5.17). Also verify that (5.18) gives (5.17).
17.
Write out the components of Tjk = AjBk −AkBj to show that Tjk is a 2nd-rank
antisymmetric tensor with elements which are the components of A × B.
6. PSEUDOVECTORS AND PSEUDOTENSORS
So far we have considered only rotations of rectangular coordinate systems in our
deﬁnitions of tensors. Recall that an orthogonal transformation includes both ro-
tations and reﬂections (Chapter 3, Sections 7 and 11). Now we want to consider
how the entities we have called tensors behave under reﬂections. Remember that
the determinant of an orthogonal matrix is +1 for a rotation (sometimes called a
“proper” rotation) and the determinant is −1 if a reﬂection is involved (sometimes
called an “improper” rotation).
When det A = −1, at least one eigenvalue of matrix A is −1 (see Chapter 3,
Section 11). The −1 eigenvalue corresponds to the reversal of one principal axis, that
is, a reﬂection through the plane perpendicular to the axis [for example a reﬂection
through the (x, y) plane which reverses the z axis].
The other two eigenvalues
correspond to a rotation [see Chapter 3, equation (7.19)]; this includes the case of
a 180◦rotation which is equivalent to reversal of the other two axes (see Problems
1 and 2). So in thinking about reﬂections, we can think of reversing all three axes
(called an inversion) or reversing just one, since a rotation doesn’t aﬀect the sign of
det A. It is important to realize that reversing either one or all three axes changes
the coordinate system from a right-handed to a left-handed coordinate system.
Example 1.
Let’s look at a simple example of something we usually think of as a vector
(namely a cross product) which doesn’t obey the vector transformation laws under
reﬂections.
Let U and V be displacement vectors.
Recall (Section 2) that, by
deﬁnition, a vector transforms the way displacement vectors do. Also remember
that we are considering passive transformations: vectors remain ﬁxed in space while
the axes are changed (rotated or reﬂected). Now if the z axis is reversed [reﬂected
through the (x, y) plane], then the z components of the displacement vectors U and
V change signs; this is then a requirement for all vectors. But the z component of
U × V (which is UxVy −UyVx) does not change sign (Problems 3 and 4). Thus
U × V is not a vector under reﬂections. We call U × V a pseudovector. We will
discover other pseudovectors as we continue.

Section 6
Pseudovectors and Pseudotensors
515
Levi-Civita symbols
We want to use (5.6) when the matrix A is the matrix
of an orthogonal transformation. Remember (Chapter 3, Section 7) that if A is
orthogonal, det A = ±1 so (det A)2 = 1. Multiply (5.6) by det A to get the equation
ϵαβγ = (det A)aαiaβjaγkϵijk.
Then the transformation which gives ϵ′ = ϵ (see
isotropic tensors in Section 5) is
(6.1)
ϵ′
αβγ = (det A)aαiaβjaγkϵijk = ϵαβγ.
Now this is not the right transformation equation for a 3rd-rank tensor—the factor
det A would not be there for, say, the direct product of three displacement vectors.
Of course, we got away with calling ϵijk a 3rd-rank tensor in Section 5 because we
were discussing just rotations and det A = 1 if A is a rotation matrix. But now
we are dealing with general orthogonal transformations, and when det A = −1 (re-
ﬂection) there is an extra factor −1 in the transformation equation. We call ϵijk
a 3rd-rank pseudotensor. A pseudovector or pseudotensor obeys the tensor trans-
formation equations under rotations (that is, det A = 1), but if the transformation
includes a reﬂection (that is, det A = −1), then the transformation equation con-
tains an extra factor of −1. If we have a direct product of two pseudotensors (or
such a product contracted), this will be a tensor because the product of the two
det A factors is (det A)2 = 1. (Problem 5).
Polar and Axial Vectors
If a vector (under rotations) also satisﬁes the vector
transformation equations (that is, behaves like a displacement vector) under re-
ﬂections, it is called a polar vector (or true vector or just a vector). If there is a
change in sign when det A = −1, it is called an axial vector (or pseudovector). In
Example 1, U and V were polar vectors and U × V was an axial vector.
In order to understand pseudotensors we need to discuss left-handed coordinate
systems. These are relatively unfamiliar in elementary work and for good reason.
When we deﬁne a cross product or specify a vector to represent a rotation, the right
hand rule is a part of our deﬁnition. It would be confusing to deal with this in a
left-handed system so you are always warned to use right-handed systems. But we
are now considering the general case of orthogonal transformations which includes
reﬂections and so produces left-handed reference systems which we must learn to
cope with.
Let’s consider the physics and geometry of this by comparing linear velocity and
angular velocity, both vectors under rotations. Is there a diﬀerence when we consider
reﬂections and so have a left-handed coordinate system? The linear velocity vector
indicates a path along which something moves; it has a direct physical meaning, and
under passive transformations, it stays ﬁxed in space. In the case of angular velocity,
the physical motion is taking place in the plane perpendicular to the angular velocity
vector, say a wheel rotating, or a mass or charge moving in a circle. The angular
velocity “vector” is something we choose via the right hand rule to represent the
motion. We might guess (correctly) that linear velocity is a vector (polar vector) and
angular velocity is a pseudovector (axial vector). Remember that in Example 1 we
found that the cross product (deﬁned using the right hand rule) is a pseudovector.
As we continue, watch for this; when the right hand rule is used in the deﬁnition of
a vector, you suspect that it is a pseudovector.

516
Tensor Analysis
Chapter 10
Cross Product
In Example 1, we found that the cross product of two displace-
ment vectors does not satisfy the vector transformation equations under reﬂections.
Now we want to write a formula to show exactly how a cross product transforms
under a general orthogonal transformation. By (5.11), we write
(6.2)
(U × V)i = ϵijkUjVk.
Then using (6.1), (6.2), and the vector transformation equations for the displace-
ment vectors U and V, we ﬁnd
(U′ × V′)α = ϵ′
αβγU ′
βV ′
γ
(6.3)
= (det A)aαiaβjaγkϵijkaβmUmaγpVp
= (det A)aαiδjmδkpϵijkUmVp
= (det A)aαi(ϵijkUjVk) = (det A)aαi(U × V)i.
If det A = 1 (no reﬂection, just a rotation), then (6.3) is the transformation equation
for a vector. If det A = −1 (reﬂection) then the transformation has an extra −1
factor. Thus the vector product of two polar vectors is a pseudovector, as we have
seen before and as we guessed from the fact that the right hand rule is used in
deﬁning cross product.
Example 2.
Find the triple scalar product of 3 polar vectors.
Here we have one det A factor (from the cross product), so the triple scalar
product of 3 polar vectors is a pseudoscalar (Problem 7).
Example 3.
What is the tensor character of W × S if W is a polar vector and S is a
pseudovector?
In the transformation equation for W × S, there is one factor of det A for S,
and another det A for the cross product as in (6.3). The two minus signs cancel, so
W × S is a polar vector (Problem 8).
Example 4.
Show that acceleration a and force F are polar vectors.
By deﬁnition, the displacement r is a polar vector (we deﬁne vectors as quantities
which transform the way displacements do). Then the velocity v = dr/dt and the
acceleration a = d2r/dt2 are vectors (since time t is a scalar) and F = ma is a
vector since m is a scalar.
Example 5.
Find the tensor character of each symbol in v = ω × r.
By Example 4, v is a vector so ω × r must be a vector (both sides of a tensor
equation must have the same tensor character). Then ω must be a pseudovector
so that there are two det A factors, one from the cross product and one from ω.
Recall that we predicted this because the right hand rule is used in deﬁning angular
velocity.

Section 7
Pseudovectors and Pseudotensors
517
PROBLEMS, SECTION 6
1.
Show that in 2 dimensions (say the x, y plane), an inversion through the origin (that
is, x′ = −x, y′ = −y) is equivalent to a 180◦rotation of the (x, y) plane about the
z axis. Hint: Compare Chapter 3, equation (7.13) with the negative unit matrix.
2.
In Chapter 3, we said that any 3-by-3 orthogonal matrix with determinant = −1 can
be written in the form (7.19). Use this and Problem 1 to show that in 3 dimensions,
an inversion (that is a reﬂection through the origin so that all three axes are reversed)
is equivalent to a reﬂection through a plane combined with a rotation about the line
perpendicular to the plane [say a reﬂection through the (x, y) plane—that is, a
reversal of the z axis—and a rotation of the (x, y) plane about the z axis]. Hint:
Consider the matrix B in Chapter 3, (7.19).
3.
For Example 1, write out the components of U, V, and U× V in the original right-
handed coordinate system S and in the left-handed coordinate system S′ with the
z axis reﬂected. Show that each component of U × V in S′ has the “wrong” sign
to obey the vector transformation laws.
4.
Do Example 1 and Problem 3 if the transformation to a left-handed system is an
inversion (see Problem 2).
5.
Write the tensor transformation equations for ϵijkϵmnp to show that this is a (rank
6) tensor (not a pseudotensor). Hint: Write (6.1) for each ϵ and multiply them,
being careful not to re-use a pair of summation indices.
6.
Write the transformation equations to show that ∇× V is a pseudovector if V is a
vector. Hint: See equations (5.13), (6.2) and (6.3).
7.
Write the transformation equations for the triple scalar product W·(U×V) remem-
bering that now det A = −1 if the transformation involves a reﬂection. Thus show
that the triple scalar product of three polar vectors is a pseudoscalar as claimed in
Example 2. Hint: Use the result in (6.3).
8.
Write the transformation equations for W × S to verify the results of Example 3.
In the physics formulas of Problems 9 to 14, identify each symbol as a vector (polar vector)
or a pseudovector (axial vector). Use results from the text and the fact that both sides of
an equation must have the same tensor character. The deﬁnition of the symbols used is:
r = displacement, t = time, m = mass, q = electric charge, v = velocity, F = force, ω =
angular velocity, τ = torque, L = angular momentum, T = kinetic energy, E = electric
ﬁeld, B = magnetic ﬁeld. Assume that t, m, and q are scalars. Note that we are working
in 3 dimensional physical space and assuming classical (that is nonrelativistic) physics.
9.
E = F
q
10.
L = mr × v = mr × (ω × r)
11.
τ = r × F
12.
F = q(E + v × B)
13.
∂B
∂t = −∇× E
14.
T = 1
2m(ω × r) · (ω × r)
15.
In equation (5.12), ﬁnd whether A×(B×C) is a vector or a pseudovector assuming
(a)
A, B, C are all vectors;
(b)
A, B, C are all pseudovectors;
(c)
A is a vector and B and C are pseudovectors.
Hint: Count up the number of det A factors from pseudovectors and cross products.
16.
In equation (5.14), is ∇× (∇× V) a vector or a pseudovector?
17.
In equation (5.16), show that if Tjk is a tensor (that is, not a pseudotensor), then
Vi is a pseudovector (axial vector). Also show that if Tjk is a pseudotensor, then Vi
is a vector (true or polar vector). You know that if Vi is a cross product of polar
vectors, then it is a pseudovector. Is its dual Tjk a tensor or a pseudotensor?

518
Tensor Analysis
Chapter 10
7. MORE ABOUT APPLICATIONS
Stress Tensor
We started our discussion of tensors with a description of the
stress tensor (you may want to review this in Section 1). Now let’s show that the
nine quantities Pij displayed in the matrix (1.1) really are the components of a
2nd-rank tensor. For simplicity in notation (and to use summation convention), we
make the replacements indicated in (2.10); we also replace i, j, k by e1, e2, e3 and
i′, j′, k′ by e′
1, e′
2, e′
3. Our problem is to write the components P ′
αβ relative to a
rotated coordinate system in terms of the components
Pij to show that P ′
αβ = aαiaβjPij as in (2.14) or (3.9).
dS
dV
x'
z
y
x
Figure 7.1
Figure 7.1 shows the unprimed axes and one of the
rotated axes. (With α = 1, 2, 3, the x′
α axis represents
any one of the rotated axes.) We draw a slanted plane,
as shown, perpendicular to the x′
α axis, and consider
the forces on the small volume element dV bounded by
the unprimed coordinate planes and the slanted plane.
Recall (Section 1) that pressure is force per unit area, so
the force acting across a face is the pressure times the
area of the face. Let the area of the slanted face (call it
face α) be dS. Then the area of the face perpendicular
to the xi axis (call it face i) is aαi dS where aαi [see
(2.10)] is the cosine of the angle between the x′
α and xi axes (Problem 1).
(7.1)
Area of face i is equal to aαi dS.
The pressure across face i is Pijej (note the sum on j and see Problem 2). Mul-
tiplying this by (7.1) (force = pressure times area of face) and summing on i, we
ﬁnd that the total force acting on the material in the volume element dV , across
the three faces in the unprimed coordinate planes is
(7.2)
(Pijej)aαi dS.
For equilibrium, the sum of these three forces must be equal to the force acting
across face α on the neighboring material. This force is
(7.3)
P ′
αβe′
β dS
Setting (7.2) and (7.3) equal, taking the dot product of both sides with e′
β, and
canceling dS, we have (Problem 3)
(7.4)
P ′
αβ = aαiaβjPij
Thus we see that the stress Pij is, as claimed, a 2nd-rank tensor.
Example 1.
Suppose the following matrix is a display of the elements of a stress tensor.
P =


1
3
0
3
−2
−1
0
−1
1


We note that P is symmetric (this is true of stress tensors) so we can diagonalize P
by an orthogonal transformation. In Chapter 3, Section 12, Example 2, we found

Section 7
More About Applications
519
that the eigenvalues of this matrix are 1, −4, 3. Thus a rotation of axes (matrix C
in the Chapter 3 example) produces a stress tensor P′ with stress components only
along the principal axes. The positive eigenvalues are tensions and the negative are
compressions. Relative to the principal axes there are no shear forces.
Strain and Stress; Hooke’s Law
The strain tensor speciﬁes the deformation
of a solid body under stress. For a simple case such as a wire supporting a weight,
strain (change in length per unit length) and stress (force per unit cross sectional
area) are proportional (Hooke’s Law). But for a 3 dimensional problem, stress is
a 2nd-rank tensor Pij (as we have seen above), and strain is also a 2nd-rank tensor
Sij. If the components of P are linear combinations of the components of S, then
we can write
(7.5)
Pij = CijkmSkm
By the quotient rule, Cijkm is a 4th-rank tensor (Problem 5). The components
of Cijkm depend on the kind of material under stress and are called the elastic
constants of the material (see Problem 6).
Inertia Tensor Revisited
In Section 4 we considered the inertia tensor using
vector notation. Now let’s look at it using the tensor form for vector identities that
we discussed in Section 5.
Example 2.
In (4.2) we had L = mr×(ω ×r). Using (5.12) with A = C = r and B = ω,
we ﬁnd
(7.6)
Ln = m[r × (ω × r)]n = m(δnjδik −δnkδij)xiωjxk.
Now sum over i and k to get δnjδikxixk = δnjxkxk = δnjr2 and δnkδijxixk = xjxn.
Thus we have [compare (4.2)]
(7.7)
Ln = m(δnjr2 −xnxj)ωj.
The coeﬃcient of ωj is then the component Inj of the inertia tensor.
(7.8)
Inj = m(δnj r2 −xnxj).
We can easily verify that these components are the same as we found in Section
4. For example [compare (4.4)]:
(7.9)
I11 = m(r2 −x2
1),
I12 = −mx1x2,
I13 = −mx1x3,
and similarly for the other components (Problem 7).

520
Tensor Analysis
Chapter 10
Other Applications
In your study of electric ﬁelds in matter, you will ﬁnd the
equation P = χE; this relates the electric ﬁeld E applied to a dielectric and the
resulting polarization P of the dielectric. For some materials it may be true that P
and E are parallel vectors with χ = scalar, but for other materials P and E are not
parallel. Now this should remind you of our work in Section 4 with the equation
L = Iω when we realized that L and ω are not always parallel. Just as we replaced
the scalar I by a 2nd-rank tensor, so we replace χ by a 2nd-rank tensor. In the
equation Pi = χijEj, the quotient rule (see Section 3) tells us that χij is a 2nd-rank
tensor. You will ﬁnd other equations of this sort in various applications.
Tensor Fields
Recall from Chapter 6 that a scalar ﬁeld (temperature, for exam-
ple) means a single number at each point, that is, a single function f(x, y, z). A
vector ﬁeld (such as the electric ﬁeld) means a set of three numbers at each point,
that is, a set of three functions Vi(x, y, z). Similarly, a 2nd-rank tensor ﬁeld means a
set of 9 numbers at each point, that is, a set of 9 functions Tij(x, y, z). Think of our
discussion of stress and strain. At every point in the material under stress, we can
think of three vectors giving the force per unit area across the three perpendicular
planes through the point, that is, a set of 9 functions. The 4th-rank tensor Cijkm in
(7.5) is then a set of 34 = 81 functions, and so on. (Of course, in order to be tensors
these sets must transform properly under rotations as discussed in this chapter.)
PROBLEMS, SECTION 7
1.
Verify (7.1). Hints: In Figure 7.1, consider the projection of the slanted face of
area dS onto the three unprimed coordinate planes. In each case, show that the
projection angle is equal to an angle between the x′
α axis and one of the unprimed
axes. Find the cosine of the angle from the matrix A in (2.10).
2.
Write out the sums Pijej for each value of i and compare the discussion of (1.1).
Hint: For example, if i = 2 [or y in (1.1)], then the pressure across the face per-
pendicular to the x2 axis is P21e1 + P22e22 + P23e3, or, in the notation of (1.1),
Pyxi + Pyyj + Pyzk.
3.
Carry through the details of getting (7.4) from (7.2) and (7.3). Hint: You need the
dot product of e′
β and ej. This is the cosine of an angle between two axes since each
e is a unit vector. Identify the result from matrix A in (2.10).
4.
Interpret the elements of the matrices in Chapter 3, Problems 11.18 to 11.21, as
components of stress tensors. In each case diagonalize the matrix and so ﬁnd the
principal axes of the stress (along which the stress is pure tension or compression).
Describe the stress relative to these axes. (See Example 1.)
5.
Show by the quotient rule (Section 3) that Cijkm in (7.5) is a 4th-rank tensor.
6.
If P and S are 2nd-rank tensors, show that 92 = 81 coeﬃcients are needed to write
each component of P as a linear combination of the components of S. Show that
81 = 34 is the number of components in a 4th-rank tensor. If the components of
the 4th-rank tensor are Cijkm, then equation (7.5) gives the components of P in
terms of the components of S. If P and S are both symmetric, show that we need
only 36 diﬀerent non-zero components in Cijkm.
Hint: Consider the number of
diﬀerent components in P and S when they are symmetric. Comment: The stress
and strain tensors can both be shown to be symmetric. Further symmetry reduces
the 36 components of C in (7.5) to 21 or less.
7.
In (7.9) we have written the ﬁrst row of elements in the inertia matrix. Write the
formulas for the other 6 elements and compare with Section 4.
8.
Do Problem 4.8 in tensor notation and compare the result with your solution of 4.8.

Section 8
Curvilinear Coordinates
521
8. CURVILINEAR COORDINATES
Before we discuss non-Cartesian tensors we need to talk about some properties of
curvilinear coordinate systems such as spherical or cylindrical coordinates. To make
the discussion concrete, we shall illustrate the ideas involved by using two familiar
coordinate systems—rectangular coordinates (x, y, z) and cylindrical coordinates
(r, θ, z). The elements of arc length in these two systems are given by
ds2 = dx2 + dy2 + dz2
(rectangular coordinates)
ds2 = dr2 + r2 dθ2 + dz2
(cylindrical coordinates)
(8.1)
These expressions for ds are called line elements; they have much greater signiﬁ-
cance than just their use in computing arc lengths. First consider how we can ﬁnd
ds2 for a given coordinate system. In the case of a well-known coordinate system,
the answer may be obvious from the geometry. For example in polar coordinates in
the plane we have (from Figure 8.1 and the Pythagorean theorem)
Figure 8.1
(8.2)
ds2 = dr2 + r2 dθ2.
For an unfamiliar or complicated change of variables,
however, we need a systematic method of ﬁnding ds;
we illustrate the method by ﬁnding the value of ds2
for cylindrical coordinates as given in (8.1). From the
equations
x = r cos θ,
y = r sin θ,
z = z,
(8.3)
we get
dx = cos θ dr −r sin θ dθ,
dy = sin θ dr + r cos θ dθ,
dz = dz.
(8.4)
Squaring each equation in (8.4) and adding the results, we ﬁnd
(8.5)
ds2 = dx2 + dy2 + dz2 = dr2 + r2 dθ2 + dz2.
Figure 8.2
Notice particularly here that all the cross products (dr dθ, etc.) canceled out.
This will not always happen, but it often does; when it does we call the coor-
dinate system orthogonal.
Such coordinate systems
have some particularly simple and useful properties.
Geometrically, an orthogonal system means that the
coordinate surfaces are mutually perpendicular.
For
the cylindrical system (Figure 8.2), the coordinate sur-
faces are r = const. (set of concentric cylinders), θ =
const. (set of half-planes), and z = const. (set of planes).
The three coordinate surfaces through a given point
intersect at right angles. The three curves of intersec-
tion of the coordinate surfaces in pairs intersect at right

522
Tensor Analysis
Chapter 10
angles; these curves are called the coordinate “lines” or directions. We draw unit
basis vectors tangent to the coordinate directions; for the cylindrical system (Figure
8.2) we might call them er, eθ, ez (ez is identical to k). These unit vectors form
an orthogonal triad like i, j, k. We refer to such coordinate systems as curvilinear
coordinate systems when the coordinate surfaces (or some of them) are not planes
and the coordinate lines (or some of them) are curves rather than straight lines.
We shall be principally interested in orthogonal curvilinear coordinate systems.
Scale Factors and Basis Vectors
In the rectangular system, if x, y, z, are the
coordinates of a particle, and x changes by dx with y and z constant, then the
distance the particle moves is ds = dx. However, in the cylindrical system, if θ
changes by dθ with r and z constant, the distance the particle moves is not dθ, but
ds = r dθ. Factors like the r in r dθ which must multiply the diﬀerentials of the
coordinates to get distances are known as scale factors and are very important as
we shall see. A straightforward way to get them is to calculate ds2 as we did in
(8.5); if the transformation is orthogonal, then the scale factors can be read oﬀfrom
ds2. (Note that the coeﬃcients in ds2 are the squares of the scale factors.) From
(8.5), we see that the scale factors for cylindrical coordinates are 1, r, 1.
It is also useful to consider a vector ds which (in cylindrical coordinates) has
components dr, r dθ, dz in the coordinate directions er, eθ, ez:
(8.6)
ds = er dr + eθ r dθ + ez dz.
Then ds2 = ds · ds which gives (8.1), since the e vectors are orthonormal.
We can write the unit basis vectors of a curvilinear coordinate system (er, eθ,
ez in cylindrical coordinates) in terms of i, j, k. This is useful when we want to
diﬀerentiate a vector which is expressed in terms of the curvilinear coordinate basis
vectors. The unit vectors i, j, k are constant in magnitude and direction, but er
and eθ are not ﬁxed in direction, so their derivatives are not zero. We illustrate
an algebraic method of ﬁnding the relation between two sets of basis vectors by
ﬁnding them for the cylindrical system. (Compare the geometrical method shown
in Chapter 6, Section 4.)
Example 1.
Using (8.4) and collecting coeﬃcients of dr, dθ, and dz, we ﬁnd
ds = i dx + j dy + k dz
= i(cos θ dr −r sin θ dθ) + j (sin θ dr + r cos θ dθ) + k dz
= (i cos θ + j sin θ) dr + (−ir sin θ + j r cos θ) dθ + k dz.
(8.7)
Comparing (8.7) with (8.6), we have
er = i cosθ + j sin θ
reθ = −ir sin θ + j r cos θ
ez = k.
(8.8)
Notice that er is already a unit vector since sin2 θ + cos2 θ = 1, but reθ must be
divided by the scale factor r to get the unit vector eθ. It is often convenient to
use basis vectors which we shall call ar and aθ (which are not necessarily of unit

Section 8
Curvilinear Coordinates
523
length), given by the coeﬃcients of dr and dθ in (8.7). Then we just have to divide
each a vector by its magnitude to get the corresponding e vector. Thus from (8.7)
ar = er is already a unit vector,
aθ = −ir sin θ + j r cos θ has magnitude r, so
eθ = 1
r aθ = −i sinθ + j cos θ
(8.9)
Figure 8.3
We can use these formulas to ﬁnd the velocity and acceleration of a particle
in cylindrical coordinates, and similar formulas for any coordinate system. The
displacement of a particle from the origin at time t is, in cylindrical coordinates
(Figure 8.3),
s = rer + zez.
Then
ds
dt = dr
dt er + r d
dt(er) + dz
dt ez.
By (8.8),
d
dt(er) = −i sinθdθ
dt + j cos θdθ
dt = eθ
dθ
dt ,
so
(8.10)
ds
dt = ˙rer + r ˙θeθ + ˙zez.
By diﬀerentiating again with respect to t and using (8.8) to ﬁnd (d/dt)(eθ), we can
ﬁnd the acceleration d2s/dt2 in cylindrical coordinates (Problem 2).
General Curvilinear Coordinates
In general, let x1, x2, x3 be the set of vari-
ables or coordinates we are considering (for example, in cylindrical coordinates,
x1 = r, x2 = θ, x3 = z). Then the three sets of coordinate surfaces are x1 =
const., x2 = const., x3 = const. The three coordinate surfaces through a given
point intersect in three coordinate lines.
Example 2.
Given x, y, z as functions of x1, x2, x3, we can ﬁnd ds and the a vectors as
we did for cylindrical coordinates in (8.7) and (8.9).
ds = i dx + j dy + k dz
= i ∂x
∂xn
dxn + j ∂y
∂xn
dxn + k ∂z
∂xn
dxn
= a1 dx1 + a2 dx2 + a3 dx3 = an dxn,
(8.11)
where
(8.12)
an =
∂
∂xn
s = i ∂x
∂xn
+ j ∂y
∂xn
+ k ∂z
∂xn
.
Now deﬁning gij = ai · aj, we can write ds2 = ds · ds in matrix form as follows:
(8.13)
ds2 =
 dx1
dx2
dx3



g11
g12
g13
g21
g22
g23
g31
g32
g33




dx1
dx2
dx3

,

524
Tensor Analysis
Chapter 10
Note that gij is symmetric since the dot product of two vectors is the same in either
order. In simpler form using summation convention (8.13) becomes
(8.14)
ds2 = gij dxi dxj.
We will see later (Section 10) that the gij are the components of a tensor known as
the metric tensor.
If the coordinate system is orthogonal, that is, if the basis vectors (e or a) form
an orthogonal triad, then ds and ds2 can be written in terms of the scale factors as
follows:
ds = e1h1 dx1 + e2h2 dx2 + e3h3 dx3,
(8.15)
ds2 =

dx1
dx2
dx3



h2
1
0
0
0
h2
2
0
0
0
h2
3




dx1
dx2
dx3

.
(8.16)
Also note that the volume element in an orthogonal system is h1h2h3 dx1 dx2 dx3
(volume of a small rectangular parallelepiped with edges h1 dx1, h2 dx2, h3 dx3). For
example, in cylindrical coordinates, the volume element is dr · r dθ · dz = r dr dθ dz.
PROBLEMS, SECTION 8
1.
Find ds2 in spherical coordinates by the method used to obtain (8.5) for cylindrical
coordinates. Use your result to ﬁnd for spherical coordinates, the scale factors, the
vector ds, the volume element, the basis vectors ar, aθ, aφ and the corresponding
unit basis vectors er, eθ, eφ. Write the gij matrix.
2.
Observe that a simpler way to ﬁnd the velocity ds/dt in (8.10) is to divide the
vector ds in (8.6) by dt. Complete the problem to ﬁnd the acceleration in cylindrical
coordinates.
3.
Use the results of Problem 1 to ﬁnd the velocity and acceleration components in
spherical coordinates. Find the velocity in two ways: starting with ds and starting
with s = rer.
4.
In the text and problems so far, we have found the e vectors for various coordinate
systems in terms of i and j (or i, j, k in three dimensions). We can solve these
equations to ﬁnd i and j in terms of the e vectors, and so express a vector given in
rectangular form in terms of the basis vectors of another coordinate system. Carry
out this process to express in cylindrical coordinates the vector V = yi −xj + k.
Hint: Use matrices (as in Chapter 3) to solve the set of equations for i and j.
5.
Using the results of Problem 1, express the vector in Problem 4 in spherical coordi-
nates.
As in Problem 1, ﬁnd ds2, the scale factors, the vector ds, the volume (or area) element,
the a vectors, and the e vectors for each of the following coordinate systems.
6.
Parabolic cylinder coordinates u, v, z:
x = 1
2(u2 −v2),
y = uv,
z = z.
7.
Elliptic cylinder coordinates u, v, z:
x = a cosh u cos v,
y = a sinh u sin v,
z = z.

Section 9
Vector Operators in Orthogonal Curvilinear Coordinates
525
8.
Parabolic coordinates u, v, φ:
x = uv cos φ,
y = uv sin φ,
z = 1
2(u2 −v2).
9.
Bipolar coordinates u, v:
x =
a sinh u
cosh u + cos v ,
y =
a sin v
cosh u + cos v .
10.
Sketch or computer plot the coordinate surfaces in Problems 6 to 9.
Using the expression you have found for ds, and for the e vectors, ﬁnd the velocity and
acceleration components in the coordinate systems indicated.
11.
Parabolic cylinder
12.
Elliptic cylinder
13.
Parabolic
14.
Bipolar
15.
Let x = u + v, y = v. Find ds, the a vectors, and ds2 for the u, v coordinate system
and show that it is not an orthogonal system. Hint: Show that the a vectors are not
orthogonal, and that ds2 contains du dv terms. Write the gij matrix and observe
that it is symmetric but not diagonal. Sketch the lines u = const. and v = const.
and observe that they are not perpendicular to each other.
9. VECTOR OPERATORS IN ORTHOGONAL CURVILINEAR COORDINATES
We have previously (Chapter 6, Sections 6 and 7) deﬁned the gradient (∇u), the
divergence (∇· V), the curl (∇× V), and the Laplacian (∇2u) in rectangular
coordinates x, y, z. Since in many practical problems it is better to use some other
coordinate system (cylindrical or spherical, for example), we need to see how to
express the vector operators in terms of general orthogonal coordinates x1, x2, x3.
(We consider only orthogonal coordinate systems here; see Section 10 for the more
general case.) We shall outline proofs of the formulas; some of the details of the
proofs are left to the problems.
Gradient, ∇u.
In Chapter 6, Section 6, we showed that the directional derivative
du/ds in a given direction is the component of ∇u in that direction.
Example 1.
In cylindrical coordinates, if we go in the r direction (θ and z constant),
then by (8.5) ds = dr. Thus the r component of ∇u is du/ds when ds = dr, that
is, ∂u/∂r. Similarly, the θ component of ∇u is du/ds when ds = r dθ, that is,
(1/r)(∂u/∂θ). Thus ∇u in cylindrical coordinates is
(9.1)
∇u = er
∂u
∂r + eθ
1
r
∂u
∂θ + ez
∂u
∂z .
In general orthogonal coordinates x1, x2, x3, the component of ∇u in the x1
direction (x2 and x3 constant) is du/ds if ds = h1 dx1 [from (8.11)]; that is, the
component of ∇u in the direction e1 is (1/h1)(∂u/∂x1). Similar formulas hold for
the other components and we have
∇u = e1
1
h1
∂u
∂x1
+ e2
1
h2
∂u
∂x2
+ e3
1
h3
∂u
∂x3
=
3

i=1
ei
1
hi
∂u
∂xi
.
(9.2)

526
Tensor Analysis
Chapter 10
Divergence, ∇· V
Let
(9.3)
V = e1V1 + e2V2 + e3V3
be a vector with components V1, V2, V3 in an orthogonal system. We can prove
(Problem 1) that
(9.4)
∇·
 e3
h1h2

= 0,
∇·
 e2
h1h3

= 0,
∇·
 e1
h2h3

= 0.
Let us write (9.3) as
(9.5)
V =
e1
h2h3
(h2h3V1) +
e2
h1h3
(h1h3V2) +
e3
h1h2
(h1h2V3).
We ﬁnd ∇· V by taking the divergence of each term on the right side of (9.5).
Using (7.6) of Chapter 6, namely
(9.6)
∇· (φv) = v · (∇φ) + φ∇· v,
with φ = h2h3V1 and v = e1/h2h3, we ﬁnd that the divergence of the ﬁrst term on
the right side of (9.5) is
(9.7)
∇·

h2h3V1
e1
h2h3

=
e1
h2h3
· ∇(h2h3V1) + h2h3V1∇·
 e1
h2h3

.
By (9.4), the last term in (9.7) is zero. In the ﬁrst term on the right side of (9.7),
the dot product of e1 with ∇(h2h3V1) is the ﬁrst component of ∇(h2h3V1). By
(9.2), this is
1
h1
∂
∂x1
(h2h3V1).
Calculating the divergence of the other terms of (9.5) in a similar way, we get
∇· V =
1
h2h3
1
h1
∂
∂x1
(h2h3V1) +
1
h1h3
1
h2
∂
∂x2
(h1h3V2) +
1
h1h2
1
h3
∂
∂x3
(h1h2V3)
or
(9.8)
∇· V =
1
h1h2h3
 ∂
∂x1
(h2h3V1) +
∂
∂x2
(h1h3V2) +
∂
∂x3
(h1h2V3)

.
Example 2.
In cylindrical coordinates, h1 = 1, h2 = r, h3 = 1. By (9.8), the divergence
in cylindrical coordinates is
∇· V = 1
r
 ∂
∂r (rVr) + ∂
∂θ(Vθ) + ∂
∂z(rVz)

(9.9)
= 1
r
∂
∂r(rVr) + 1
r
∂Vθ
∂θ + ∂Vz
∂z .

Section 9
Vector Operators in Orthogonal Curvilinear Coordinates
527
Laplacian, ∇2u.
Since ∇2u = ∇· ∇u we can ﬁnd ∇2u by combining (9.2) and
(9.8) with V = ∇u. We get
(9.10)
∇2u =
1
h1h2h3
 ∂
∂x1
h2h3
h1
∂u
∂x1

+
∂
∂x2
h1h3
h2
∂u
∂x2

+
∂
∂x3
h1h2
h3
∂u
∂x3

.
Example 3.
In cylindrical coordinates, the Laplacian is then
∇2u = 1
r
 ∂
∂r

r∂u
∂r

+ ∂
∂θ
1
r
∂u
∂θ

+ ∂
∂z

r∂u
∂z

= 1
r
∂
∂r

r∂u
∂r

+ 1
r2
∂2u
∂θ2 + ∂2u
∂z2 .
Curl, ∇× V.
By methods similar to those used in ﬁnding ∇· V we can ﬁnd
∇× V (Problem 2). The result is
∇× V =
1
h1h2h3

h1e1
h2e2
h3e3
∂
∂x1
∂
∂x2
∂
∂x3
h1V1
h2V2
h3V3

(9.11)
=
e1
h2h3
 ∂
∂x2
(h3V3) −
∂
∂x3
(h2V2)

+
e2
h1h3
 ∂
∂x3
(h1V1) −
∂
∂x1
(h3V3)

+
e3
h1h2
 ∂
∂x1
(h2V2) −
∂
∂x2
(h1V1)

Example 4.
In cylindrical coordinates, we ﬁnd
∇× V = 1
r

er
reθ
ez
∂
∂r
∂
∂θ
∂
∂z
Vr
rVθ
Vz

= er
1
r
∂Vz
∂θ −∂Vθ
∂z

+ eθ
∂Vr
∂z −∂Vz
∂r

+ 1
r ez
 ∂
∂r (rVθ) −∂Vr
∂θ

.
PROBLEMS, SECTION 9
1.
Prove (9.4) in the following way. Using (9.2) with u = x1, show that ∇x1 = e1/h1.
Similarly, show that ∇x2 = e2/h2 and ∇x3 = e3/h3. Let e1, e2, e3 in that order
form a right-handed triad (so that e1 × e2 = e3, etc.) and show that ∇x1 × ∇x2 =
e3/(h1h2). Take the divergence of this equation and, using the vector identities (h)
and (b) in the table at the end of Chapter 6, show that ∇· (e3/h1h2) = 0. The
other parts of (9.4) are proved similarly.

528
Tensor Analysis
Chapter 10
2.
Derive the expression (9.11) for curl V in the following way. Show that ∇x1 = e1/h1
and ∇× (∇x1) = ∇× (e1/h1) = 0. Write V in the form
V = e1
h1 (h1V1) + e2
h2 (h2V2) + e3
h3 (h3V3)
and use vector identities from Chapter 6 to complete the derivation.
3.
Using cylindrical coordinates write the Lagrange equations for the motion of a par-
ticle acted on by a force F = −∇V , where V is the potential energy. Divide each
Lagrange equation by the corresponding scale factor so that the components of F
(that is, of −∇V ) appear in the equations. Thus write the equations as the com-
ponent equations of F = ma, and so ﬁnd the components of the acceleration a.
Compare the results with Problem 8.2.
4.
Do Problem 3 in spherical coordinates; compare the results with Problem 8.3.
5.
Write out ∇U, ∇· V, ∇2U, and ∇× V in spherical coordinates.
Do Problem 3 for the coordinate systems indicated in Problems 6 to 9.
Compare the
results with Problems 8.11 to 8.14.
6.
Parabolic cylinder
7.
Elliptic cylinder
8.
Parabolic
9.
Bipolar
Do Problem 5 for the coordinate systems indicated in Problems 10 to 13.
10.
Parabolic cylinder
11.
Elliptic cylinder
12.
Parabolic
13.
Bipolar
In each of the following coordinate systems, ﬁnd the scale factors hu and hv; the basis
vectors eu and ev; the u and v Lagrange equations, and from them the acceleration
components (see Problem 3).
14.
x = u −v,
y = 2√uv.
15.
x = uv,
y = u
√
1 −v2.
Use equations (9.2), (9.8), and (9.11) to evaluate the following expressions
16.
In cylindrical coordinates, ∇· er, ∇· eθ, ∇× er, ∇× eθ.
17.
In spherical coordinates, ∇· er, ∇· eθ, ∇× eθ, ∇× eφ.
18.
In cylindrical coordinates, ∇× k ln r, ∇ln r, ∇· (rer + zez).
19.
In spherical coordinates, ∇× (reθ), ∇(r cos θ), ∇· r.
20.
In cylindrical coordinates, ∇2r, ∇2(1/r), ∇2 ln r.
21.
In spherical coordinates, ∇2r, ∇2(r2), ∇2(1/r2), ∇2eikr cos θ.

Section 10
Non-Cartesian Tensors
529
10. NON-CARTESIAN TENSORS
So far we have considered only the behavior of the rectangular components of tensors
under orthogonal transformations. Now let’s generalize this to include any change
of variables.
Example 1.
In spherical coordinates r, θ, φ,
x = r sin θ cos φ,
y = r sin θ sin φ,
z = r cos θ.
(10.1)
This is not a linear transformation, and we cannot write equations like (2.4) to (2.9)
for the relations between the variables. However, we can write such equations for
the relations between the diﬀerentials of the variables. From (10.1), we ﬁnd the
diﬀerentials dx, dy, dz, in terms of dr, dθ, dφ:
(10.2)


dx
dy
dz

=


sin θ cos φ
r cos θ cos φ
−r sin θ sin φ
sin θ sin φ
r cos θ sin φ
r sin θ cos φ
cos θ
−r sin θ
0




dr
dθ
dφ

.
Example 2.
For general coordinates x1, x2, x3, and x′
1, x′
2, x′
3, if we are given the relations
[like (10.1)] between the two sets of variables, we can write the relations between
the two sets of diﬀerentials as follows:
(10.3)


dx′
1
dx′
2
dx′
3

=









∂x′
1
∂x1
∂x′
1
∂x2
∂x′
1
∂x3
∂x′
2
∂x1
∂x′
2
∂x2
∂x′
2
∂x3
∂x′
3
∂x1
∂x′
3
∂x2
∂x′
3
∂x3











dx1
dx2
dx3

.
More simply, using index notation and summation convention, (10.3) becomes
(10.4)
dx′
i = ∂x′
i
∂xj
dxj.
Compare this with the transformation for the partial derivatives of a function u,
(10.5)
∂u
∂x′
i
= ∂u
∂xj
∂xj
∂x′
i
= ∂xj
∂x′
i
∂u
∂xj
,
and compare both (10.4) and (10.5) with the transformation for a Cartesian vector
(10.6)
V ′
i = aijVj,
(Cartesian).
For Cartesian vectors you can easily verify that
(10.7)
∂x′
i
∂xj
= aij = ∂xj
∂x′
i
,
(Cartesian),
since both the partial derivatives in (10.7) equal the cosine of the angle between the
x′
i and the xj axes (Problem 1). This is not true for general coordinate systems; for
example, in (10.1), ∂x/∂θ ̸= ∂θ/∂x (see Problem 2). Thus in general we have two
possible deﬁnitions of a vector, which become identical for Cartesian vectors.

530
Tensor Analysis
Chapter 10
Contravariant and Covariant Vectors
By deﬁnition, V is a contravariant
vector if its components transform like this:
(10.8)
V ′
i = ∂x′
i
∂xj
Vj,
(contravariant vector),
and V is a covariant vector if its components transform like this:
(10.9)
V ′
i = ∂xj
∂x′
i
Vj,
(covariant vector).
By comparing (10.4) and (10.8), we see that the diﬀerentials of the coordinates are
the components of a contravariant vector. Similarly, by comparing (10.5) and (10.9),
we see that the partial derivatives of a function are the components of a covariant
vector.
Notation
Before we deﬁne tensors in general, we need to discuss a few things
about notation. It is customary to write the indices of contravariant vectors and
tensors as superscripts rather than subscripts.
Be careful not to confuse them
with exponents! (You may ﬁnd the mnemonic “low-co” useful; lower indices are
covariant indices, so, of course, upper indices are contravariant indices.) In this
notation, equation (10.8) for a contravariant vector becomes
(10.10)
V ′i = ∂x′
i
∂xj
V j,
(contravariant vector).
(In fact, to be strictly consistent, since the diﬀerentials are contravariant, we should
write ∂x′i/∂xj. For our purposes this seems unnecessary so we will leave the partial
derivative notation as it is.) Also note that the summation convention now applies
to a pair of indices, one upper and one lower. (An index in the denominator counts
as a lower index and an index in the numerator counts as an upper index.) Note
that this new rule about summation convention applies in (10.9) and (10.10) and
watch for it in future formulas.
Components and basis vectors
You may be wondering how the vectors you
studied in vector analysis (Section 9 and Chapter 6) are related to covariant and
contravariant vectors.
Actually we should speak of covariant and contravariant
components, but the former terminology is customary.
Any vector has various
sets of components relative to various sets of basis vectors. Let’s discuss this for
orthogonal coordinate systems where it is especially simple. Recall that in vector
analysis, we use the unit basis vectors such as i, j, k or er, eθ, eφ; for example, the
vectors ei in Section 9 are all unit vectors. Then the components of a vector V in
vector analysis are the projections ei · V of the vector on the coordinate directions.
To be able to refer to these components, let’s call them the physical components
(they have the right physical dimensions—see Problem 6). We would like to see
the relation between the physical components and the covariant and contravariant
components of a vector, and the relation between the unit basis vectors and the
contravariant and covariant basis vectors.

Section 10
Non-Cartesian Tensors
531
Example 3.
You have learned that, in polar coordinates, the (physical) components of ds
are dr and r dθ. Now (10.4) and (10.10) tell us that the contravariant components
of ds are just dr and dθ (not r dθ). Thus we may guess (correctly) that the con-
travariant components of a vector are the physical components divided by the scale
factors. By considering the components of the gradient (Problem 4), you can show
that the covariant components of a vector are the physical components multiplied
by the scale factors.
Example 4.
In polar coordinates we can write [see equation (8.9)]
(10.11)
ds = er dr + eθ r dθ = ar dr + aθ dθ.
We have written ds in terms of its physical components and the unit ei vectors, and
in terms of its contravariant components and the covariant ai basis vectors. From
(10.11) and from Section 8 we can see that the ai basis vectors are the ei unit vectors
multiplied by the scale factors. Note that the components and the basis vectors used
with them vary in opposite ways so that the scale factors cancel. Similarly we can
write a vector in terms of its covariant components and the contravariant basis
vectors ai which are the unit vectors divided by the scale factors (Problem 5). Note
carefully that what we have just said applies only to orthogonal coordinate systems.
If a coordinate system is not orthogonal, then ai and ai are not in general parallel;
see the discussion just after (10.19).
Deﬁnition of Tensors
Tensors may be covariant of any rank, contravariant of
any rank, or mixed. Here are some sample tensor deﬁnitions; you should be able to
write the corresponding deﬁnitions for tensors of any rank or kind in a similar way
(Problem 7).
T ′
ij = ∂xk
∂x′
i
∂xl
∂x′
j
Tkl
(2nd-rank covariant tensor),
T ′ijk = ∂x′
i
∂xl
∂x′
j
∂xm
∂x′
k
∂xn
T lmn
(3rd-rank contravariant tensor),
(10.12)
T ′ij
k = ∂x′
i
∂xl
∂x′
j
∂xm
∂xn
∂x′
k
T lm
n
(3rd-rank mixed tensor, one covariant
and two contravariant indices).
Kronecker delta
We showed in Section 5 that δij is a 2nd-rank isotropic
Cartesian tensor.
In a general coordinate system, the 2nd-rank tensor which is
equal to 1 if i = j and 0 otherwise in all coordinate systems, is a mixed tensor so
we write it as δi
j. To show that this is correct we write the tensor transformation
equation for δk
l to see that we get δ′i
j.
(10.13)
∂x′
i
∂xk
∂xl
∂x′
j
δk
l = ∂x′
i
∂xk
∂xk
∂x′
j
= ∂x′
i
∂x′
j
= δ′i
j.
Thus we see that δi
j is an isotropic 2nd-rank tensor in general coordinate systems.

532
Tensor Analysis
Chapter 10
Quotient Rule
In Section 3, we discussed the quotient rule for Cartesian tensors.
A similar rule applies in general. To give proofs, we must replace the aij by the
appropriate partial derivatives, noting carefully that summation convention now
applies to a sum over one lower and one upper index.
Example 5.
If we are given TijV j = Ui where V is an arbitrary contravariant vector and
U is a non-zero covariant vector, we want to show that Tij is a 2nd-rank covariant
tensor. We write [compare equations (3.6) to (3.9)]
(10.14)
T ′
αβV ′β = U ′
α = ∂xi
∂x′α
Ui = ∂xi
∂x′α
TijV j = ∂xi
∂x′α
Tij
∂xj
∂x′
β
V ′β.
Set the ﬁrst and last steps equal; then since V ′β is arbitrary, its coeﬃcient = 0 and
we have
T ′
αβ = ∂xi
∂x′α
Tij
∂xj
∂x′
β
which is the transformation equation for a 2nd-rank covariant tensor.
Metric Tensor; Raising and Lowering Indices
Example 6.
From (8.14) we have (with the contravariant dx indices now written as su-
perscripts)
(10.15)
ds2 = gij dxi dxj.
Since ds2 is a scalar, and each dx is a contravariant vector, it follows by the quotient
rule (Problem 8) that gij is a 2nd-rank covariant tensor. It is known as the metric
tensor. If the elements of gij are written as a matrix [see (8.13)], then we deﬁne
gij as the elements of the inverse matrix. We can interpret gijgjk as either the
contracted direct product of two tensors, or as the row times column product of
two matrices which are inverses of each other, that is, a unit matrix. Thus we can
write
(10.16)
gijgjk = δk
i .
Then by (10.13) and the quotient rule, gij is a 2nd-rank contravariant tensor.
Example 7.
If V i is a contravariant vector then Vi = gijV j is a covariant vector (Problem
10). We can also show that gijVj gives back the V i we started with:
(10.17)
gijVj = gijgjkV k = δi
kV k = V i.
This process of ﬁnding the contracted product of a vector (or tensor) with gij
or gij is called raising or lowering indices. The vectors V i and Vi are called the
contravariant and covariant components of the vector V.
In equation (8.12), we deﬁned the covariant basis vectors ai which we use with
contravariant components to write a vector [see (8.11) for example, remembering
that the diﬀerentials are the contravariant components of ds]. The contravariant

Section 10
Non-Cartesian Tensors
533
basis vectors to use with covariant components are given by ai = gijaj. We can
then write a vector in two ways (Problem 11):
(10.18)
V = aiV i = aiVi,
where
 Vi = gijV j,
V i = gijVj,
ai = gijaj,
ai = gijaj.
It is interesting to consider the directions of the vectors ai and ai. We have
deﬁned ai = gijaj but you can show (Problem 12) that ai = ∇xi. Thus we have
ai =
∂
∂xi
s = i ∂x
∂xi
+ j ∂y
∂xi
+ k ∂z
∂xi
,
ai = gijaj = ∇xi = i∂xi
∂x + j∂xi
∂y + k∂xi
∂z .
(10.19)
We see from the displacement vector ds = ai dxi that the basis vectors ai are tan-
gent to the coordinate lines. The vectors ai = ∇xi are orthogonal to the coordinate
surfaces xi = const. (Recall that grad u is orthogonal to u = const.) For orthogonal
coordinates, ai and ai are in the same direction. (For example, in spherical coor-
dinates, ar points in the radial direction, and ar is orthogonal to the sphere r =
const.; these are the same direction.) Thus for orthogonal coordinates, if we nor-
malize each ai, we get the same set of unit basis vectors that we get if we normalize
each ai. However, if the coordinate system is not orthogonal, then at each point we
have two diﬀerent sets of basis vectors ai and ai (see Problems 16 and 17).
Just as we did for vectors, any tensor, say T i
jk, can be written in various diﬀerent
forms by raising and lowering indices to get Tijk, T ijk, T ij
k . These tensors are called
associated tensors. They really all represent the same tensor T, with components
relative to various bases.
Orthogonal coordinate systems
For orthogonal coordinate systems, formulas
involving gij can be written in terms of the scale factors h1, h2, h3 [compare (8.13)
and (8.16)]. Remember that the gij matrix is the inverse of the gij matrix [see
equation (10.16)]. Also let g represent the determinant of the gij matrix. Then you
can show (Problem 13).
(10.20)
gij =

0,
i ̸= j,
h2
i ,
i = j,
gij =



0,
i ̸= j,
1
h2
i
,
i = j,
g = h2
1h2
2h2
3,
√g = h1h2h3
Vector Operators in Tensor Notation
We state without proof the following
tensor expressions for ∇u, ∇· V, and ∇2u. They are correct for any coordinate
system, orthogonal or not. Using (10.20), you can specialize them to orthogonal
coordinate systems and so obtain the expressions given in Section 9. (Problems 14
and 15).
The covariant components of ∇u are ∂u
∂xi
.
(10.21)
∇· V =
1
√g
∂
∂xi
(√g V i), where V i are contravariant components of V.
(10.22)
∇2u =
1
√g
∂
∂xi
√g gij ∂u
∂xj

.
(10.23)

534
Tensor Analysis
Chapter 10
PROBLEMS, SECTION 10
1.
Verify equation (10.7). Hint: Use equations (2.4) to (2.6) and (2.10). For example,
∂y′/∂z = ∂z/∂y′ = n2 = a23.
2.
From (10.1) ﬁnd ∂θ/∂x = (1/r) cos θ cos φ and show that ∂x/∂θ ̸= ∂θ/∂x. Note
carefully that ∂x/∂θ means that r and φ are constant, but ∂θ/∂x means that y and
z are constant. (See Chapter 4, Example 7.6 for further discussion.)
3.
Divide equation (10.4) by dt to show that the velocity v = ds/dt is a contravariant
vector. Note that the contravariant components of the velocity in polar coordinates
are ˙r and ˙θ (not ˙r and r ˙θ which are physical components). As we did in (10.11),
write the velocity v in polar coordinates in terms of the unit e vectors and in terms
of the covariant a vectors. Repeat the problem in spherical coordinates.
4.
What are the physical components of the gradient in polar coordinates? [See (9.1)].
The partial derivatives in (10.5) are the covariant components of ∇u. What rela-
tion do you deduce between physical and covariant components? Answer the same
questions for spherical coordinates, and for an orthogonal coordinate system with
scale factors h1, h2, h3.
5.
Write ∇u in polar coordinates in terms of its physical components and the unit
basis vectors ei, and in terms of its covariant components and the contravariant
basis vectors ai. What is the relation between the contravariant basis vectors and
the unit basis vectors? Hint: Compare equation (10.11) and our discussion of it.
6.
Show that, in polar coordinates, the θ contravariant component of ds is dθ which is
unitless, the θ physical component of ds is r dθ which has units of length, and the θ
covariant component of ds is r2 dθ which has units (length)2.
7.
As in (10.12), write the transformation equations for the following tensors: 2nd-rank
contravariant, 3rd-rank covariant, 4th-rank mixed with 2 covariant and 2 contravari-
ant indices.
8.
Using (10.15) show that gij is a 2nd-rank covariant tensor. Hint: Write the transfor-
mation equation for each dx, and set the scalar ds′2 = ds2 to ﬁnd the transformation
equation for gij.
9.
If U i is a contravariant vector and Vj is a covariant vector, show that U iVj is a
2nd-rank mixed tensor. Hint: Write the transformation equations for U and V and
multiply them.
10.
Show that if V i is a contravariant vector then Vi = gijV j is a covariant vector, and
that if Vi is a covariant vector, then V i = gijVj is a contravariant vector.
11.
In (10.18), show by raising and lowering indices that aiV i = aiVi. Also write (10.18)
for an orthogonal coordinate system with gij and gij written in terms of the scale
factors.
12.
Show that in a general coordinate system with variables x1, x2, x3, the contravariant
basis vectors are given by
ai = ∇xi = i∂xi
∂x + j∂xi
∂y + k∂xi
∂z .
Hint: Write the gradient in terms of its covariant components and the ai basis
vectors to get ∇u = aj∂u/∂xj and let u = xi.
13.
Verify (10.20).

Section 11
Miscellaneous Problems
535
14.
Using equations (10.20) to (10.23), write the gradient, divergence, and Laplacian in
cylindrical coordinates and in spherical coordinates. Change covariant or contravari-
ant components to physical components and compare with the formulas stated in
Chapter 6, Sections 6 and 7.
15.
Do Problem 14 for an orthogonal coordinate system with scale factors h1, h2, h3,
and compare with the Section 9 formulas.
16.
Continue Problem 8.15 to ﬁnd the gij matrix and the contravariant basis vectors.
Check your result by solving the given equations for u and v in terms of x and y,
and ﬁnding the contravariant basis vectors using Problem 12. On your Problem
8.15 sketches of the lines u = const. and v = const., also sketch the covariant and
contravariant basis vectors. Observe that the covariant basis vectors lie along the
lines u = const. and v = const. and the contravariant basis vectors lie along the
normals to these lines.
17.
Repeat Problems 8.15 and 10.16 above for the (u, v) coordinate system if x = 2u−v,
y = u −2v.
18.
Using (10.19), show that ai · ai = δi
j.
11. MISCELLANEOUS PROBLEMS
1.
Show that the transformation equation for a 2nd-rank Cartesian tensor is equivalent
to a similarity transformation. Warning hint: Note that the matrix C in Chapter
3, Section 11, is the inverse of the matrix A we are using in Chapter 10 (compare
r′ = Ar and r = Cr′). Thus a similarity transformation of the matrix T with tensor
components Tij is T′ = ATA−1. Also see “Tensors and Matrices” in Section 3 and
remember that A is orthogonal.
2.
Let e1, e2, e3 be a set of orthogonal unit vectors forming a right-handed system if
taken in cyclic order. Show that the triple scalar product ei · (ej × ek) = ϵijk.
3.
In Chapter 3, Problem 6.6, you are asked to prove some identities among the Pauli
spin matrices (called A, B, C, in that problem). Call the Pauli spin matrices σ1, σ2,
σ3; then show that the identities can be written in the following summation forms:
σkσm = iϵkmnσn + δkm;
σkσmϵkmn = 2iσn.
4.
If E = electric ﬁeld and B = magnetic ﬁeld, is E × B a vector or a pseudovector?
Comment: E × B/µ0 is called the Poynting vector; it points in the direction of
transfer of energy. Does that tell you from the physics whether it is a vector or a
pseudovector?
Do Problems 5 to 8 for the (u, v) coordinate system if x = u(1 −v), y = u
√
2v −v2.
5.
Find ds2, the scale factors, the area element, the vector ds, the unit basis vectors,
and the covariant and contravariant basis vectors.
6.
Use Lagrange’s equations to ﬁnd the u and v acceleration components.
7.
Write ∇U, ∇· V, and ∇2U.
8.
Evaluate ∇· eu, ∇× ev, ∇2 ln u.
9.
If u is a vector specifying the displacement under stress of each point of a deformable
medium, then ∇u is a 2nd-rank Cartesian tensor (see Problem 11) which describes
the strain at each point. Display the components of ∇u as a matrix. Write ∇u as
the sum of a symmetric tensor and an antisymmetric tensor [see (3.5)]. Comment:
The symmetric part of ∇u is called the stress tensor and the antisymmetric part
the rotation tensor.

536
Tensor Analysis
Chapter 10
10.
Show that elements Rij of a rotation matrix are the elements of a Cartesian tensor.
Hints: Could you use the quotient rule? Could you use Problem 1?
11.
Show that the nine quantities Tij = ∂Vi/∂xj (which are the Cartesian components of
∇V where V is a vector) satisfy the transformation equations (2.14) for a Cartesian
2nd-rank tensor. Show that they do not satisfy the general tensor transformation
equations as in (10.12). Hint: Diﬀerentiate (10.9) or (10.10) partially with respect
to, say, x′
k. You should get the expected terms [as in (10.12)] plus some extra terms;
these extraneous terms show that ∂Vi/∂xj is not a tensor under general transfor-
mations. Comment: It is possible to express the components of ∇V correctly in
general coordinate systems by taking into account the variation of the basis vectors
in length and direction.
12.
The square matrix in equation (10.3) is called the Jacobian matrix J; the determi-
nant of this matrix is the Jacobian J = det J which we used in Chapter 5, Section 4
to ﬁnd volume elements in multiple integrals. (Note that as in Chapter 3, J repre-
sents a matrix; J in italics is its determinant.) For the transformation to spherical
coordinates in (10.1) and (10.2) show that J = det J = r2 sin θ. Recall that the
spherical coordinate volume element is r2 sin θ dr dθ dφ. Hint: Find JTJ and note
that det(JTJ) = (det J)2.
13.
In equation (10.13), let the x′ variables be rectangular coordinates x, y, z, and
let x1, x2, x3, be general curvilinear coordinates, orthogonal or not (see end of
Section 8). Show that JTJ is the gij matrix in (8.13) [or in (8.16) for an orthogonal
system].
Thus show that the volume element in a general coordinate system is
dV = √g dx1 dx2 dx3 where g = det(gij), and that for an orthogonal system, this
becomes [by (8.16) or (10.19)], dV = h1h2h3 dx1 dx2 dx3. Hint: To evaluate the
products of partial derivatives in JTJ, observe that the same expressions arise as in
ﬁnding ds2. In fact, from (8.11) and (8.12), you can show that row i times column
j in JTJ is just ai · aj = gij in equations (8.11) to (8.14).

C H A P T E R 11
Special Functions
1. INTRODUCTION
The integrals and series and functions of this chapter arise in a variety of physical
problems. Just as you learn about trigonometric functions, logarithms, etc., and
use them in applied problems, so you should learn something about these special
functions so that you can use them and understand their use as they come up in your
more advanced work. An enormous amount of detail is known about these functions,
and numerous formulas involving them exist and can be looked up in books or found
in your computer program. Our purpose is not to study them intensively, but to
give deﬁnitions and some of the simpler relations and show their use. This should
develop your ability and conﬁdence to cope with more complicated formulas and
many other similar functions and relations that may crop up occasionally in texts
or computer results.
Now you may be thinking that your computer will give you the answers for def-
inite integrals and functions so you really don’t need to bother with this chapter.
If all you want is a numerical approximation, this may be true. However, in theo-
retical work, you often need an exact expression (say in terms of π or
√
3 or ln 2)
and your computer may not give you the form you need.
Example 1.
Suppose you want
 π/2
0
dθ/
√
cos θ. One computer program gives you the
result
√
2 K(1/
√
2) and another gives you 2√π Γ(5/4)/Γ(3/4). In books you ﬁnd
answers 1
2B(1/4, 1/2) and [Γ(1/4)]2/
√
8π. What’s going on here and which is right?
They all are! And when you have studied the formulas in this chapter, you will be
able to show this (Problem 12.21) just as you now recognize that sin2 θ = 1−cos2 θ.
Also in some problems you may want an algebraic approximation for a complicated
expression rather than a numerical answer.
Example 2.
You will ﬁnd in thermal physics the approximation ln N! ∼= N ln N −N; we
will discuss this approximation and its accuracy. (See Problem 11.3).
537

538
Special Functions
Chapter 11
2. THE FACTORIAL FUNCTION
Let us calculate the values of some integrals. For α > 0,
(2.1)
 ∞
0
e−αxdx = −1
αe−αx

∞
0
= 1
α.
Next diﬀerentiate both sides of this equation repeatedly with respect to α (see
Chapter 4, Section 12):
 ∞
0
−xe−αx dx = −1
α2
or
 ∞
0
xe−αx dx = 1
α2 ,
 ∞
0
x2e−αx dx = 2
α3 ,
 ∞
0
x3e−αx dx = 3!
α4 .
or in general
(2.2)
 ∞
0
xne−αx dx =
n!
αn+1 .
Putting α = 1, we get
(2.3)
 ∞
0
xne−x dx = n!,
n = 1, 2, 3, · · · .
Thus we have a deﬁnite integral whose value is n! for positive integral n. We can
use (2.3) to give a meaning to 0!. Putting n = 0 in (2.3), we get
(2.4)
0! =
 ∞
0
e−x dx = −e−x

∞
0
= 1.
(This agrees with our previous deﬁnition of 0! in Chapter 1.)
PROBLEMS, SECTION 2
In Chapter 4, Section 12, do Problems 14 to 17.
3. DEFINITION OF THE GAMMA FUNCTION; RECURSION RELATION
So far n has been a nonnegative integer; it is natural to deﬁne the factorial function
for nonintegral n by the deﬁnite integral (2.3). There is no real objection to the
notation n! for nonintegral n (and we shall occasionally use it), but it is customary to
reserve the factorial notation for integral n and to call the corresponding function
for nonintegral n the gamma (Γ) function. It is also rather common practice to
replace n by the letter p when we do not necessarily mean an integer. Following
these conventions, we deﬁne, for any p > 0
(3.1)
Γ(p) =
 ∞
0
xp−1e−x dx,
p > 0.

Section 3
Deﬁnition of the Gamma Function; Recursion Relation
539
For 0 < p < 1, this is an improper integral because xp−1 becomes inﬁnite at the
lower limit. However, it is a convergent integral for p > 0 (Problem 1). For p ≤0,
the integral diverges and so cannot be used to deﬁne Γ(p); we shall see in Section 4
how to deﬁne Γ(p) when p ≤0. Then from (3.1) and (2.3) we have
Γ(n) =
 ∞
0
xn−1e−x dx = (n −1)!,
Γ(n + 1) =
 ∞
0
xne−x dx = n!.
(3.2)
Thus
Γ(1) = 0! = 1,
Γ(2) = 1! = 1,
Γ(3) = 2! = 2,
Γ(4) = 3! = 6,
· · · ,
with the usual meaning of factorial for positive integral n. The fact that Γ(n) =
(n −1)! and not n! is unfortunate but that’s the notation which is used, so watch
out for it. Replacing p by p + 1 in (3.1), we have
(3.3)
Γ(p + 1) =
 ∞
0
xpe−x dx = p!,
p > −1.
Some authors use the factorial notation p! = Γ(p + 1) even though p is not an
integer; this avoids the nuisance of the p + 1.
Let us integrate (3.3) by parts, calling xp = u, e−xdx = dv; then we get
du = p xp−1 dx,
v = −e−x,
Γ(p + 1) = −xpe−x∞
0 −
 ∞
0
(−e−x)p xp−1 dx
= p
 ∞
0
xp−1e−x dx = pΓ(p).
This equation
(3.4)
Γ(p + 1) = pΓ(p)
is called the recursion relation for the Γ function. It can be used to simplify ex-
pressions involving Γ functions or to write them in a diﬀerent form (much as you
use trigonometric identities).
Example.
By (3.4) we ﬁnd Γ(9/4) = (5/4)Γ(5/4) = (5/4)(1/4)Γ(1/4);
then Γ(1/4) ÷ Γ(9/4) = 16/5.
PROBLEMS, SECTION 3
1.
The integral in (3.1) is improper because of the inﬁnite upper limit and it is also
improper for 0 < p < 1 because xp−1 becomes inﬁnite at the lower limit. However,
the integral is convergent for any p > 0. Prove this.

540
Special Functions
Chapter 11
Use the recursion relation (3.4), and if needed, equation (3.2) to simplify:
2.
Γ(2/3)/Γ(5/3)
3.
Γ(2/3)/Γ(8/3)
4.
Γ(2/5)/Γ(12/5)
5.
Γ(1/2)Γ(4)/Γ(9/2)
6.
Γ(10)/Γ(8)
7.
Γ(4)Γ(3/4)/Γ(7/4)
Express each of the following integrals as a Γ function. By computer, evaluate numerically
both the Γ function and the original integral.
8.
Z ∞
0
x2/3e−x dx
9.
Z ∞
0
e−x4dx Hint: Put x4 = u.
10.
Z ∞
0
x−2/5e−x dx
11.
Z ∞
0
x5e−x2dx Hint: Put x2 = u.
12.
Z ∞
0
xe−x3dx
13.
Z 1
0
x2
„
ln 1
x
«3
dx Hint: Put x = e−u.
14.
Z 1
0
3√
ln x dx
15.
Z ∞
0
x−1/3 e−8x dx
16.
A particle starting from rest at x = 1 moves along the x axis toward the origin.
Its potential energy is V = 1
2m ln x. Write the Lagrange equation and integrate it
to ﬁnd the time required for the particle to reach the origin. Caution: dx/dt < 0.
Answer: Γ( 1
2).
17.
Express as a Γ function
Z 1
0
»
ln
„ 1
x
«–p−1
dx.
Hint: See Problem 13.
4. THE GAMMA FUNCTION OF NEGATIVE NUMBERS
For p ≤0, Γ(p) has not so far been deﬁned. We shall now deﬁne it by the recursion
relation (3.4) solved for Γ(p).
(4.1)
Γ(p) = 1
p Γ(p + 1)
deﬁnes Γ(p) for p < 0.
Example.
Γ(−0.3) =
1
−0.3Γ(0.7),
Γ(−1.3) =
1
(−1.3)(−0.3)Γ(0.7),
and so on. Since Γ(1) = 1, we see that
Γ(p) = Γ(p + 1)
p
→∞
as p →0.
From this and successive use of (4.1) it follows that Γ(p) becomes inﬁnite not only
at zero but also at all the negative integers. In the intervals between the negative
integers, it is alternately positive and negative, negative from 0 to −1, positive from
−1 to −2, and so on, as you can see from computations like those for Γ(−0.3) and
Γ(−1.3) above. See Problems 5.1 and 5.2.

Section 5
Some Important Formulas Involving Gamma Functions
541
5. SOME IMPORTANT FORMULAS INVOLVING GAMMA FUNCTIONS
First we evaluate Γ
 1
2

. By deﬁnition
(5.1)
Γ( 1
2) =
 ∞
0
1
√
t e−t dt.
(Note that it does not matter what letter we use for the dummy variable of in-
tegration in a deﬁnite integral.) Put t = y2 in (5.1); then dt = 2y dy, and (5.1)
becomes
Γ( 1
2) =
 ∞
0
1
y e−y22y dy = 2
 ∞
0
e−y2 dy
or, with x as the dummy integration variable,
(5.2)
Γ( 1
2) = 2
 ∞
0
e−x2 dx.
Multiply these two integrals for Γ( 1
2) together and write the result as a double
integral:

Γ( 1
2)
2 = 4
 ∞
0
 ∞
0
e−(x2+y2)dx dy.
This is an integral over the ﬁrst quadrant; it can be more easily evaluated in polar
coordinates:

Γ( 1
2)
2 = 4
 π/2
0
 ∞
0
e−r2r dr dθ = 4 · π
2 · e−r2
−2

∞
0
= π.
Therefore
(5.3)
Γ( 1
2) = √π.
We state here another important formula involving Γ functions (for proof, see
Chapter 14, Section 7, Example 5):
(5.4)
Γ(p)Γ(1 −p) =
π
sin πp.
Notice that (5.4) also gives Γ
 1
2

= √π if we put p = 1
2.

542
Special Functions
Chapter 11
PROBLEMS, SECTION 5
1.
Using (5.3) with (3.4) and (4.1), ﬁnd Γ(3/2), Γ(−1/2), and Γ(−3/2) in terms of √π.
2.
Without computer or tables, but just using facts you know, sketch a quick rough
graph of the Γ function from −2 to 3. Hint: This is easy; don’t make a big job of
it. From Section 3, you know the values of the Γ function at the positive integers in
terms of factorials. From Problem 1, you can easily ﬁnd and plot the Γ function at
±1/2, ±3/2. (Approximate √π as a little less than 2.) From (4.1) and the discussion
following it, you know that the Γ function tends to plus or minus inﬁnity at 0 and
the negative integers, and you know the intervals where it is positive or negative.
After sketching your graph, make a computer plot of the Γ function from −5 to 5
and compare your sketch.
3.
In Chapter 1, equations (13.5) and (13.6), we deﬁned the binomial coeﬃcients
`p
n
´
where n is a non-negative integer but p may be negative or fractional. Show that
`p
n
´
can be written in terms of Γ functions as
 
p
n
!
=
Γ(p + 1)
n! Γ(p −n + 1).
4.
Prove that, for positive integral n:
Γ(n + 1
2) = 1 · 3 · 5 · · · (2n −1)
2n
√π = (2n)!
4nn!
√π.
5.
Use (5.4) to show that
(a)
Γ( 1
2 −n)Γ( 1
2 + n) = (−1)nπ if n = a positive integer;
(b)
(z!)(−z)! = πz/ sin πz, where z is not necessarily an integer; see comment after
equation (3.3).
6.
Prove that
d
dpΓ(p) =
Z ∞
0
xp−1e−x ln x dx,
dn
dpn Γ(p) =
Z ∞
0
xp−1e−x(ln x)n dx.
7.
In the Table of Laplace Transforms (end of Chapter 8, page 469), verify the Γ
function results for L5 and L6. Also show that L(1/
√
t ) =
p
π/p.
6. BETA FUNCTIONS
The beta function is also deﬁned by a deﬁnite integral:
(6.1)
B(p, q) =
 1
0
xp−1(1 −x)q−1 dx,
p > 0,
q > 0.
There are a number of simple transformations of (6.1) which are useful to know
[see (6.3), (6.4), (6.5)]. It is easy to show that (Problem 1)
(6.2)
B(p, q) = B(q, p).

Section 7
Beta Functions in Terms of Gamma Functions
543
The range of integration in (6.1) can be changed by putting x = y/a; then x = 1
corresponds to y = a, and (6.1) becomes
(6.3)
B(p, q) =
 a
0
y
a
	p−1 
1 −y
a
	q−1 dy
a =
1
ap+q−1
 a
0
yp−1(a −y)q−1 dy.
To obtain the trigonometric form of the beta function, let x = sin2 θ; then
dx = 2 sin θ cos θ dθ,
(1 −x) = 1 −sin2 θ = cos2 θ,
x = 1 corresponds to θ = π/2.
With these substitutions, (6.1) becomes
B(p, q) =
 π/2
0
(sin2 θ)p−1(cos2 θ)q−12 sin θ cos θ dθ
or
(6.4)
B(p, q) = 2
 π/2
0
(sin θ)2p−1(cos θ)2q−1 dθ.
Finally, let x = y/(1 + y) in (6.1); then we get (Problem 2):
(6.5)
B(p, q) =
 ∞
0
yp−1dy
(1 + y)p+q .
PROBLEMS, SECTION 6
1.
Prove that B(p, q) = B(q, p). Hint: Put x = 1 −y in Equation (6.1).
2.
Prove equation (6.5).
3.
Show that for integral n, m,
1/B(n, m) = m
 
n + m −1
n −1
!
= n
 
n + m −1
m −1
!
.
Hint: See Chapter 1, Section 13C, Problem 13.3.
7. BETA FUNCTIONS IN TERMS OF GAMMA FUNCTIONS
Beta functions are easily expressed in terms of Γ functions. We shall show that
(7.1)
B(p, q) = Γ(p)Γ(q)
Γ(p + q) .
Thus we can evaluate a B function in terms of Γ functions (see example below).

544
Special Functions
Chapter 11
To prove (7.1), we start with
Γ(p) =
 ∞
0
tp−1e−t dt
and put t = y2. Then we have
(7.2)
Γ(p) = 2
 ∞
0
y2p−1e−y2 dy.
Similarly (remember that the dummy integration variable can be any letter),
Γ(q) = 2
 ∞
0
x2q−1e−x2 dx.
Next we multiply these two equations together and change to polar coordinates:
Γ(p)Γ(q) = 4
 ∞
0
 ∞
0
x2q−1y2p−1e−(x2+y2)dx dy
= 4
 ∞
0
 π/2
0
(r cos θ)2q−1(r sin θ)2p−1e−r2r dr dθ
= 4
 ∞
0
r2p+2q−1e−r2 dr
 π/2
0
(cos θ)2q−1(sin θ)2p−1dθ.
(7.3)
The r integral in (7.3) is 1
2Γ(p + q) by (7.2). The θ integral in (7.3) is 1
2B(p, q) by
(6.4). Then Γ(p)Γ(q) = 4 · 1
2Γ(p + q) · 1
2B(p, q) and (7.1) follows.
Example.
Find
I =
 ∞
0
x3 dx
(1 + x)5 .
This is (6.5) with (p + q) = 5, p −1 = 3 or p = 4, q = 1. Then I = B(4, 1). By
(7.1), this is
Γ(4)Γ(1)
Γ(5)
= 3!
4! = 1
4.
PROBLEMS, SECTION 7
Express the following integrals as B functions, and then, by (7.1), in terms of Γ functions.
When possible, use Γ function formulas to write an exact answer in terms of π,
√
2, etc.
Compare your answers with computer results and reconcile any discrepancies.
1.
Z 1
0
x4 dx
√
1 −x2
2.
Z π/2
0
p
sin3 x cos x dx
3.
Z 1
0
dx
√
1 −x3
4.
Z 1
0
x2(1 −x2)3/2 dx
5.
Z ∞
0
y2 dy
(1 + y)6
6.
Z ∞
0
y dy
(1 + y3)2
7.
Z π/2
0
dθ
√
sin θ
8.
Z 2
0
x2 dx
√2 −x

Section 8
The Simple Pendulum
545
9.
Prove B(n, n) = B(n, 1
2)/22n−1. Hint: In (6.4), use the identity 2 sin θ cos θ = sin 2θ
and put 2θ = φ. Use this result and (5.3) to derive the duplication formula for Γ
functions:
Γ(2n) =
1
√π 22n−1Γ(n)Γ(n + 1
2).
Check this formula for the case n = 1
4 by using (5.4).
Computer plot the graph of x3 + y3 = 8. Write the integrals for the following quantities
(see Chapter 5 if needed) and evaluate them as B functions.
10.
The ﬁrst quadrant area bounded by the curve.
11.
The centroid of this area.
12.
The volume generated when the area is revolved about the y axis.
13.
The moment of inertia of this volume about its axis.
8. THE SIMPLE PENDULUM
Figure 8.1
A simple pendulum means a mass m suspended by a string (or
weightless rod) of length l so that it can swing in a plane, as shown
in Figure 8.1. The kinetic energy of m is then
(8.1)
T = 1
2mv2 = 1
2m(l ˙θ)2.
If the potential energy is zero when the string is horizontal, then at
angle θ it is
V = −mgl cos θ.
Then the Lagrangian is (see Chapter 9, Section 5)
L = T −V = 1
2ml2 ˙θ2 + mgl cos θ,
and the Lagrange equation of motion is
d
dt(ml2 ˙θ) + mgl sin θ = 0
or
(8.2)
¨θ = −g
l sin θ.
Example 1.
Suppose the pendulum executes such small vibrations that sin θ can be ap-
proximated by θ. Then (8.2) becomes the usual equation for the simple harmonic
motion of a pendulum executing small vibrations, namely
(8.3)
¨θ = −g
l θ.
The solutions of (8.3) are sin ωt and cos ωt where ω = 2πν =

g/l; the period of
the motion is then (see Chapter 7, Problem 2.13, and Chapter 8, Problem 5.34)
(8.4)
T = 1
ν = 2π

l/g.

546
Special Functions
Chapter 11
We now want to replace this approximate solution by one which
is exact even for large θ.
Example 2.
Going back to the diﬀerential equation of motion (8.2), we multiply both
sides of it by ˙θ and integrate, thus obtaining
˙θ¨θ = −g
l sin θ ˙θ
or
˙θ d ˙θ = −g
l sin θ dθ;
1
2
˙θ2 = g
l cos θ + const.
(8.5)
We shall come back to the general solution of this equation when we discuss elliptic
integrals; for now let us ﬁnd the period for 180◦swings (back and forth from −90◦
to +90◦). For this case, ˙θ = 0 when θ = 90◦, so the constant in (8.5) is zero, and
we have (compare Chapter 8, Problem 7.13)
1
2
˙θ2 = g
l cos θ,
dθ
dt =

2g
l
√
cos θ,
dθ
√
cos θ
=

2g
l dt.
From θ = 0 to θ = 90◦is one-quarter of a period; hence the period for 180◦swings
is given by T in the equation
 π/2
0
dθ
√
cos θ
=

2g
l
 T/4
0
dt =

2g
l · T
4 .
Then the period is
(8.6)
T = 4

l
2g
 π/2
0
dθ
√
cos θ
.
We can see by comparing (8.6) with (6.4) that this is a B function.
By computer or tables we ﬁnd that T ∼= 7.42

l/g (see Problem 1
and Problem 12.21). We can ﬁnd the period for only this one special
case (180◦swings) by B functions; the general case gives an elliptic
integral (Section 12).
PROBLEMS, SECTION 8
1.
Complete the pendulum problem to ﬁnd the period for 180◦swings as a multiple of
p
l/g [that is, evaluate the integral in (8.6)].
2.
Suppose that a car with a door open at right angles (θ = 90◦) starts up and ac-
celerates at a constant rate a = 1 mph/sec. The diﬀerential equation for θ(t) is
¨θ = −A sin θ where A = 3a/2w for a uniform door of width w. If w = 3.5 ft, ﬁnd
how long it takes for the door to close.
3.
The ﬁgure is part of a cycloid with parametric equa-
tions
x = a(θ + sin θ),
y = a(1 −cos θ).
(The graph shown is like Figure 4.4 of Chapter 9
with the origin shifted to P2.) Show that the time

Section 9
The Error Function
547
for a particle to slide without friction along the curve from (x1, y1) to the origin is
given by
t =
ra
g
Z y1
0
dy
p
y(y1 −y)
.
Hint: Show that the arc length element is ds =
p
2a/y dy. Evaluate the integral to
show that the time is independent of the starting height y1.
9. THE ERROR FUNCTION
You will meet this function in probability theory (Chapter 15, Section 8), and
consequently in statistical mechanics and other applications of probability theory.
You have probably heard of “grading on a curve.” The “curve” means the bell-
shaped graph of y = e−x2 (see Problem 1); the error function is the area under part
of this curve. We deﬁne the error function as
(9.1)
erf(x) =
2
√π
 x
0
e−t2 dt.
Although this is the usual deﬁnition of erf(x), there are other closely related inte-
grals which are used and sometimes referred to as the error function. Consequently,
you need to look carefully at the deﬁnition in the reference you are using (text,
tables, computer). Here are some integrals you may ﬁnd and their relation to (9.1)
(see Problem 2).
The standard normal or Gaussian cumulative distribution function Φ(x) [see
Chapter 15, equation (8.5)]:
Φ(x) =
1
√
2π
 x
−∞
e−t2/2 dt = 1
2 + 1
2 erf(x/
√
2 ),
(9.2a)
Φ(x) −1
2 =
1
√
2π
 x
0
e−t2/2 dt = 1
2 erf(x/
√
2 ).
(9.2b)
The complementary error function:
erfc(x) =
2
√π
 ∞
x
e−t2 dt = 1 −erf(x),
(9.3a)
erfc
 x
√
2

=

2
π
 ∞
x
e−t2/2 dt.
(9.3b)
We can also use (9.2) to write erf(x) in terms of the standard normal cumulative
distribution function [Chapter 15, equation (8.5)].
(9.4)
erf(x) = 2Φ(x
√
2 ) −1.

548
Special Functions
Chapter 11
We next consider several useful facts about the error function. You can easily
prove that the error function is odd; that is, erf(−x) = −erf(x) (Problem 3). We
show that erf(∞) = 1 as follows:
(9.5)
erf(∞) =
2
√π
 ∞
0
e−t2dt =
2
√π
1
2Γ( 1
2) =
2
√π
1
2
√π = 1
by (5.2) and (5.3). For very small values of x, erf(x) can be approximated by ex-
panding e−t2 in a power series and integrating term by term. We get
erf(x) =
2
√π
 x
0
e−t2dt =
2
√π
 x
0

1 −t2 + t4
2! −· · ·

dt
=
2
√π

x −x3
3 +
x5
5 · 2! −· · ·

.
(9.6)
[Use this when |x| ≪1. Compare (10.4).]
For large x, say x > 3, erf(x) diﬀers from erf(∞) = 1 [see (9.5)] by less than
10−4 (and of course even less for larger x).
We are then usually interested in
1 −erf(x) = erfc(x). This is best approximated by an asymptotic series; we shall
discuss such expansions in Section 10.
The function erﬁ(x), called the imaginary error function, is similar to the error
function but with a positive exponential. We deﬁne
(9.7)
erﬁ(x) =
2
√π
 x
0
et2 dt.
You can show (Problem 5) that erf(ix) = i erﬁ(x).
The Fresnel integrals (Chapter 1, Section 15) are related to the error function
(Problem 6). Also see Section 10, Problem 3 for other relations involving error
functions.
PROBLEMS, SECTION 9
1.
Sketch or computer plot a graph of the function y = e−x2.
2.
Verify equations (9.2), (9.3), and (9.4). Hint: In (9.2a), you want to write Φ(x)
in terms of an error function. Make the change of variable t = u
√
2 in the Φ(x)
integral. Warning: Don’t forget to adjust the limits; when t = x, u = x/
√
2.
3.
Prove that erf(x) is an odd function of x. Hint: Put t = −s in (9.1).
4.
Show that
Z ∞
−∞
e−y2/2 dy =
√
2π
(a)
by using (9.5) and (9.2a);
(b)
by reducing it to a Γ function and using (5.3).
5.
Replace x by ix in (9.1) and let t = iu to show that erf(ix) = i erﬁ(x), where erﬁ(x)
is deﬁned in (9.7).

Section 10
Asymptotic Series
549
6.
Assuming that x is real, show the following relation between the error function and
the Fresnel integrals.
erf
„1 −i
√
2
x
«
= (1 −i)
r
2
π
Z x
0
(cos u2 + i sin u2) du.
Hint: In (9.1), make the change of variables t = 1 −i
√
2
u.
10. ASYMPTOTIC SERIES
Since you have spent some time learning to test series for convergence, it may
surprise you to learn that there are divergent series which can be of practical use.
We can show this best by an example.
Example 1.
From (9.3a)
(10.1)
erfc(x) = 1 −erf(x) =
2
√π
 ∞
x
e−t2 dt.
We are going to expand the integral in (10.1) in a series of inverse powers of x. To
do this we write
(10.2)
e−t2 = 1
t te−t2 = 1
t
d
dt

−1
2e−t2
and integrate by parts as follows:
 ∞
x
e−t2 dt =
 ∞
x
1
t
d
dt

−1
2e−t2
dt
= 1
t

−1
2e−t2
∞
x
−
 ∞
x

−1
2e−t2 
−1
t2

dt
= 1
2xe−x2 −1
2
 ∞
x
1
t2 e−t2 dt.
(10.3)
Now in the last integral in (10.3), write (1/t2)e−t2 = (1/t3)(d/dt)(−1
2e−t2), and
again integrate by parts:
 ∞
x
1
t2 e−t2 dt =
 ∞
x
d
dt

−1
2e−t2
dt
= 1
t3

−1
2e−t2
∞
x
−
 ∞
x

−1
2e−t2 
−3
t4

dt
=
1
2x3 e−x2 −3
2
 ∞
x
1
t4 e−t2 dt.
Continue this process, and substitute (10.3) and the following steps into (10.1) to
get (Problem 1)
(10.4)
erfc(x) = 1 −erf(x) ∼e−x2
x√π

1 −
1
2x2 +
1 · 3
(2x2)2 −1 · 3 · 5
(2x2)3 + · · ·

.
[Use this when |x| ≫1. Compare (9.6).]

550
Special Functions
Chapter 11
(We shall explain the exact meaning of the symbol ∼shortly.) This series diverges
for every x because of the factors in the numerator. However, suppose we stop after
a few terms and keep the integral at the end so that we have an exact equation. If
we stop after the second term, we have
(10.5)
erfc(x) = e−x2
x√π

1 −
1
2x2

+
3
2√π
 ∞
x
t−4e−t2 dt.
There is no approximation here. This is not an inﬁnite series so there is no question
of convergence. However, we shall show that the integral at the end is negligible
for large enough x; this will then make it possible for us to use the rest of (10.5)
[that is, the ﬁrst two terms of (10.4)] as a good approximation for erfc(x) for large
x. This is the meaning of an asymptotic series. As an inﬁnite series it may diverge,
but we do not use the inﬁnite series. Instead, using an exact equation [like (10.5)
for this example], we show that the ﬁrst few terms which we do use give a good
approximation if x is large.
Example 2.
Now let’s look at the integral in (10.5); we want to estimate its size for large
x. The t in the integrand takes values from x to ∞; therefore t ≥x or 1/x ≥1/t
for all values of t from x to ∞. Let us write the integral as
 ∞
x
t−4e−t2 dt =
 ∞
x
1
t5

te−t2	
dt.
We increase the value of this integral if we replace 1/t5 by 1/x5 since 1/x ≥1/t.
Thus
 ∞
x
t−4e−t2 dt <
 ∞
x
1
x5

te−t2	
dt = 1
x5
 ∞
x
te−t2 dt
= 1
x5

−1
2e−t2
∞
x
= e−x2
2x5 .
When we stop in (10.5) with the term in e−x2/x3, the error is of the order of
e−x2/x5, which becomes much smaller than e−x2/x3 as x increases. Thus we have
shown that two terms of (10.4) give a good approximation for erfc(x) when x ≫1.
A similar result can be shown for an approximation using any number of terms of
the asymptotic series (10.4) with the error depending on the “left-over” integral and
the value of x.
We can make the above discussion more precise. For (10.4), we have seen that
if we stop after the term in x−3e−x2, the error is of the order of x−5e−x2. Then the
ratio of the error to the last term kept (namely x−5e−x2 ÷ x−3e−x2 = x−2) tends
to zero as x tends to inﬁnity, that is, the approximation becomes increasingly good
for larger x as we have said. The “error” in an asymptotic expansion means in
general the diﬀerence between the function being expanded and a partial sum (ﬁrst
N terms) of the series. A series is called an asymptotic expansion (about ∞) of a
function f(x) if, for each ﬁxed N, the ratio of the error to the last (nonzero) term

Section 10
Asymptotic Series
551
kept, tends to zero as x →∞. In symbols
f(x) ∼
∞

n=0
φn(x)

read
∞

n=0
φn(x) is an asymptotic expansion of f(x)

(10.6)
if for each ﬁxed N
f(x) −
N

n=0
φn(x)
 ÷ φN(x) →0
as x →∞.
Frequently, the terms of an asymptotic series (about ∞) are inverse powers of x. [We
could write (10.4) this way by multiplying through by ex2.] Then (10.6) becomes
f(x) ∼
∞

n=0
an
xn
if for each ﬁxed N
(10.7)
f(x) −
N

n=0
an
xn
 · xN →0
as x →∞.
We can also have asymptotic series about the origin (or any point—compare Taylor
series). We say that
f(x) ∼
∞

n=0
anxn
if for each ﬁxed N
(10.8)
f(x) −
N

n=0
anxn
 ÷ xN →0
as x →0.
Although we have discussed the particularly interesting case of divergent asymp-
totic series, it is not necessary for such series to diverge. Note that to test a series
for convergence, we ﬁx x and let n tend to inﬁnity; to see if a series is asymptotic,
we ﬁx n and let x tend to a limit. A given series may meet both tests, or only one
or the other (or neither).
PROBLEMS, SECTION 10
1.
Carry through the algebra to get equation (10.4).
2.
The integral
R ∞
x tp−1e−t dt = Γ(p, x) is called an incomplete Γ function. [Note that
if x = 0, this integral is Γ(p).] By repeated integration by parts, ﬁnd several terms
of the asymptotic series for Γ(p, x).
3.
Express the complementary error function erfc(x) as an incomplete Γ function (see
Problem 2) and use your result in Problem 2 to obtain (again) the asymptotic
expansion of erfc(x) as in (10.4).

552
Special Functions
Chapter 11
4.
En(x) =
Z ∞
1
e−xt
tn
dt, n = 0, 1, 2, · · ·, and Ei(x) =
Z x
−∞
et
t dt, and other similar
integrals are called exponential integrals. By making appropriate changes of variable,
show that
(a) E1(x) =
Z ∞
x
e−t
t
dt
(b) Ei(x) = −
Z ∞
−x
e−t
t
dt
(c) E1(x) = −Ei(−x)
(d)
Z x
0
e1/t
t
dt = E1(−1/x)
(Caution: Various notations are used; check carefully the notation in references you
are using.)
5.
(a)
Express E1(x) as an incomplete Γ function.
(b)
Find the asymptotic series for E1(x).
6.
The logarithmic integral is li(x) =
Z x
0
dt
ln t. Express as exponential integrals
(a) li(x)
(b) li(ex)
(c)
Z x
0
dt
ln(1/t)
7.
Computer plot graphs of
(a)
En(x) for n = 0 to 10 and x = 0 to 2;
(b)
E1(x) and Ei(x) for x = 0 to 2;
(c)
the sine integral Si(x) =
Z x
0
sin t
t
dt and the cosine integral Ci(x) = −
Z ∞
x
cos t
t
dt
for x = 0 to 4π.
11. STIRLING’S FORMULA
Formulas involving n! or Γ(p) are not convenient to simplify algebraically or to
diﬀerentiate. Here is an approximate formula for the factorial or Γ function known
as Stirling’s formula which can be used to simplify formulas involving factorials:
(11.1) n! ∼nne−n√
2πn
or
Γ(p + 1) ∼ppe−p
2πp.
Stirling’s formula
The sign ∼(read “is asymptotic to”) means that the ratio of the two sides
n!
nne−n√
2πn
tends to 1 as n →∞. Thus we get better approximations to n! as n becomes large.
Actually the absolute error (diﬀerence between the Stirling approximation and the
correct value) increases, but the relative error (ratio of the error to the value of n!)
tends to zero as n increases. To get some idea of how this formula arises, we outline
what could, with a little more detail, be a derivation of it. (For more detail, consult
advanced calculus books.) Start with
(11.2)
Γ(p + 1) = p ! =
 ∞
0
xpe−x dx =
 ∞
0
ep ln x−x dx.
Substitute a new variable y such that
x = p + y√p.

Section 11
Stirling’s Formula
553
Then
dx = √p dy,
x = 0 corresponds to y = −√p,
and (11.2) becomes
(11.3)
p ! =
 ∞
−√p
ep ln(p+y√p )−p−y√p√p dy.
For large p, the logarithm can be expanded in the following power series:
(11.4)
ln(p + y√p ) = ln p + ln

1 + y
√p

= ln p + y
√p −y2
2p + · · · .
Substituting (11.4) into (11.3), we get
p ! ∼
 ∞
−√p
ep ln p+y√p−(y2/2)−p−y√p√p dy
= ep ln p−p√p
 ∞
−√p
e−y2/2 dy
= ppe−p√p
 ∞
−∞
e−y2/2 dy −
 −√p
−∞
e−y2/2 dy

.
The ﬁrst integral is easily shown to be
√
2π (Problem 9.4). The second integral
tends to zero as p →∞, and we have
p! ∼ppe−p
2πp
which is (11.1). With more work, it is possible to ﬁnd an asymptotic expansion for
Γ(p + 1):
(11.5)
Γ(p + 1) = p! = ppe−p
2πp

1 +
1
12p +
1
288p2 + · · ·

.
This is another example of an asymptotic series which is divergent as an inﬁnite
series; however, the ﬁrst term alone (Stirling’s formula) is a good approximation
when p is large, and the second term can be used to estimate the relative error
(Problem 1).
PROBLEMS, SECTION 11
1.
Use the term 1/(12p) in (11.5) to show that the error in Stirling’s formula (11.1) is
< 10% for p > 1; < 1% for p > 10; < 0.1% for p > 100; < 0.01% for p > 1000.
2.
(a)
To see the results in Problem 1 graphically, computer plot the percentage error
in Stirling’s formula as a function of p for values of p from 1 to 1000. Make
separate plots, say for p = 1 to 10, 10 to 100, 100 to 1000, to make it easier to
read values from your plots.
(b)
Repeat part (a) for the percentage error in (11.5) using two terms of the asymp-
totic series, that is, Stirling’s formula times [1 + 1/(12p)].

554
Special Functions
Chapter 11
3.
In statistical mechanics, we frequently use the approximation ln N! = N ln N −N,
where N is of the order of Avogadro’s number.
Write out ln N! using Stirling’s
formula, compute the approximate value of each term for N = 1023, and so justify
this commonly used approximation.
4.
Use Stirling’s formula to evaluate lim
n→∞
(2n)! √n
22n(n!)2 .
5.
Use Stirling’s formula to evaluate lim
n→∞
Γ(n + 3
2)
√n Γ(n + 1).
6.
Use equations (3.4) and (11.5) to show that Γ(p) ∼ppe−pp
2π/p
“
1 +
1
12p + · · ·
”
.
7.
The function ψ(p) =
d
dp ln Γ(p) is called the digamma function, and the polygamma
functions are deﬁned by ψn(p) =
dn
dpn ψ(p). [Warning: Some authors deﬁne ψ(p) as
d
dp ln p! =
d
dp ln Γ(p + 1).]
(a)
Show that ψ(p + 1) = ψ(p) + 1
p. Hint: See (3.4).
(b)
Use Problem 6 to obtain ψ(p) ∼ln p −
1
2p −
1
12p2 · · ·.
8.
Sketch or computer plot a graph of y = ln x for x > 0. Show that ln n! is between the
values of the integrals
R n+1
2
ln x dx and
R n
1 ln x dx. (Hint: ln n! = ln 1+ln 2+ln 3+· · ·
is the sum of the areas of rectangles of width 1 and height up to the ln x curve at
x = 1, 2, 3, · · ·.) By considering the values of the two integrals for very large n as
in Problem 3, show that ln n! = n ln n −n approximately for large n.
9.
The following expression occurs in statistical mechanics:
P =
n!
(np + u)! (nq −u)!pnp+uqnq−u.
Use Stirling’s formula to show that
1
P ∼xnpxynqyp
2πnpqxy,
where x = 1 + u
np, y = 1 −u
nq , and p + q = 1. Hint: Show that
(np)np+u(nq)nq−u = nnpnp+uqnq−u
and divide numerator and denominator of P by this expression.
10.
Use Stirling’s formula to ﬁnd limn→∞(n!)1/n/n.
12. ELLIPTIC INTEGRALS AND FUNCTIONS
This is another collection of integrals and related functions which may arise in ap-
plied problems and as computer answers (see problems). We shall merely summarize
the basic deﬁnitions and properties—there are whole books on the subject—and you
may ﬁnd useful formulas and information in your computer program and in reference
books and tables.

Section 12
Elliptic Integrals and Functions
555
Legendre Forms
The Legendre forms of the elliptic integrals of the ﬁrst and
second kinds are:
(12.1)
F(φ, k) =
 φ
0
dθ

1 −k2 sin2 θ
,
0 ≤k ≤1,
E(φ, k) =
 φ
0

1 −k2 sin2 θ dθ,
0 ≤k ≤1.
There is also an elliptic integral of the third kind which occurs less frequently. In
(12.1), φ is called the amplitude and k is called the modulus of the elliptic integral.
Jacobi Forms
If we put t = sin θ, x = sin φ in the Legendre forms (12.1), we
obtain the Jacobi forms of the elliptic integrals of the ﬁrst and second kind:
t = sin θ,
dt = cos θ dθ
or
dθ =
dt
cos θ =
dt
√
1 −t2 .
The limits θ = 0 to φ become t = 0 to x.
Then
(12.2)
F(φ, k) =
 φ
0
dθ

1 −k2 sin2 θ
=
 x
0
dt
√
1 −t2 √
1 −k2t2
E(φ, k) =
 φ
0

1 −k2 sin2 θ dθ =
 x
0
√
1 −k2t2
√
1 −t2
dt.
Complete Elliptic Integrals
The complete elliptic integrals of the ﬁrst and
second kind are the values of F and E when φ = π/2 or x = sin φ = 1:
(12.3)
K or K(k) = F
π
2 , k
	
=
 π/2
0
dθ

1 −k2 sin2 θ
=
 1
0
dt
√
1 −t2 √
1 −k2t2 ,
E or E(k) = E
π
2 , k
	
=
 π/2
0

1 −k2 sin2 θ dθ =
 1
0
√
1 −k2t2
√
1 −t2
dt.
Warning: The notation used for elliptic integrals is not uniform. Most references
use F and E, but you may ﬁnd φ replaced by x = sin φ, and instead of k you may
ﬁnd m = k2, or sin−1 k. Also (φ, k) may be written as (k, φ), and other variations
exist. So check carefully the notation of any book or computer program you are
using and reconcile the results with the notation used here.
Example 1.
 π/3
0

1 −(1/2) sin2 θ dθ = E(φ, k) = E(π/3, 1/
√
2 ) in our notation. Other
books or computer programs might give: E(φ, m) = E(π/3, 1/2), or E(x, k) =
E(
√
3/2, 1/
√
2 ) or E(φ, sin−1 k) = E(π/3, π/4), etc. Of course, all of them will
give the same numerical approximation 0.964951.
Many integrals can be written in the form of one of the integrals in (12.2).

556
Special Functions
Chapter 11
Example2.
 π/3
0

16 −8 sin2 θ dθ becomes 4 times the integral in Example 1 if we divide
out a factor of 4 to get 4
 π/3
0

1 −(1/2) sin2 θ dθ.
Example 3.
 2/5
0
dt
√
1 −t2 √
1 −4t2 = F(φ, k) = F(sin−1 2
5, 2) in the notation of (12.2),
except that we have previously required k < 1, and here k = 2. However, we can
put this integral in the standard form with k < 1 by making the change of variable
4t2 = r2, or r = 2t. Substituting this into the given integral gives
 4/5
0
dr/2

1 −r2/4
√
1 −r2
which, by (12.2), is 1
2F(φ, k) = 1
2F(sin−1 4
5, 1
2). (See Problem 24.)
It is sometimes useful to note that the integrands in elliptic integrals are all
functions of sin2 θ and so are even functions of θ. Thus an elliptic integral from
−φ1 to φ2 (φ1 and φ2 both positive) is equal to the integral from 0 to φ1 plus the
integral from 0 to φ2 and we have
 φ2
−φ1

1 −k2 sin2 θ dθ = E(φ1, k) + E(φ2, k)
and a similar formula for F(φ, k). Also we may note that a function of sin2 θ has
period π and is symmetric about θ = nπ + π/2 (look at a graph of sin2 θ). Thus,
using the complete elliptic integrals in (12.3), we can write (Problem 2)
(12.4)
F(nπ ± φ, k) = 2nK ± F(φ, k),
E(nπ ± φ, k) = 2nE ± E(φ, k).
Since k2 sin2 θ < 1 (for k2 < 1), we get convergent inﬁnite series for elliptic
integrals by expanding their integrands using the binomial theorem, and then inte-
grating term by term (Problem 1). For small k these series converge rapidly and
provide a good method for approximating elliptic integrals when k ≪1.
Here are some examples where elliptic integrals occur.
Example 4.
Find the arc length of an ellipse.
This is the problem that gave elliptic
integrals their name. We write the equation of the ellipse in the parametric form
x = a sin θ,
y = b cos θ,
for the case a > b. (If b > a, use the form x = a cos θ, y = b sin θ; see Problem 15.)
Then for a > b, we have
ds2 = dx2 + dy2 = (a2 cos2 θ + b2 sin2 θ) dθ2.
Since a2 −b2 > 0, we can write

ds =
 
a2 −(a2 −b2) sin2 θ dθ = a
 
1 −a2 −b2
a2
sin2 θ dθ.

Section 12
Elliptic Integrals and Functions
557
This is an elliptic integral of the second kind where k2 = (a2 −b2)/a2 = e2 (e is the
eccentricity of the ellipse in analytic geometry). If we want the complete circumfer-
ence, θ goes from 0 to 2π, and the answer is 4aE(π/2, k) = 4aE(k). For a smaller
arc, we use the appropriate limits φ1 and φ2 and obtain E(φ2, k) −E(φ1, k). For
any given ellipse (that is, given a and b), we can ﬁnd the numerical value of the
desired arc length from computer or tables.
Example 5.
Let a pendulum swing through large angles. We had in Section 8
(12.5)
˙θ2 = 2g
l cos θ + const.,
and we considered 180◦swings, that is of amplitude 90◦. Now we want to consider
swings of any amplitude, say α; then ˙θ = 0 when θ = α, and (12.5) becomes
(12.6)
˙θ2 = 2g
l (cos θ −cos α).
Integrating (12.6), we get
(12.7)
 α
0
dθ
√
cos θ −cos α =

2g
l
Tα
4 ,
where Tα is the period for swings from −α to +α and back. This integral can be
written as an elliptic integral; its value (Problem 17) is
(12.8)
√
2 K

sin α
2
	
.
Then (12.7) gives for the period
Tα = 4

l
2g
√
2 K

sin α
2
	
= 4

l
g K

sin α
2
	
.
For α not too large (say α < 90◦, 1
2α < 45◦, so that sin2(α/2) < 1
2), we can get a
good approximation to Tα by series (Problem 1):
(12.9)
Tα = 4

l
g
π
2

1 +
1
2
2
sin2 α
2 +
1 · 3
2 · 4
2
sin4 α
2 + · · ·

.
For α small enough so that sin α/2 can be approximated by α/2, we can write
(12.10)
Tα = 2π

l
g

1 + α2
16 + · · ·

.
For very small α, we get the familiar formula for simple harmonic motion, T =
2π

l/g independent of α. For somewhat larger α, say α = 1
2 radian (about 30◦),
we get
(12.11)
Tα=1/2 = 2π

l
g

1 + 1
64 + · · ·

.
This would mean that a pendulum started at 30◦would get exactly out of phase
with one of very small amplitude in about 32 periods.
For another physics problem giving rise to an elliptic integral, see Am. J. Phys. 55,
763 (1987).

558
Special Functions
Chapter 11
Elliptic Functions
Recall that
u =
 x
0
dt
√
1 −t2 = sin−1 x
deﬁnes u as a function of x, or x as a function of u; in fact x = sin u. In a similar
way, u = F(φ, k) in (12.2) deﬁnes u as a function of φ (or of x = sin φ) or it deﬁnes
x or φ as functions of u (we are assuming k ﬁxed). We write
(12.12)
u =
 x
0
dt
√
1 −t2 √
1 −k2t2 = sn−1 x.
or x = sn u. The function sn u (read ess-en of u) is an elliptic function.
Since
x = sin φ, we have
(12.13)
x = sn u = sin φ.
There are other elliptic functions, related to snu; you will notice [in (12.14)] that
they have some resemblance to the trigonometric functions. We deﬁne
(12.14)
cn u = cos φ =

1 −sin2 φ =

1 −sn2 u =

1 −x2,
dn u = dφ
du =
1
du/dφ =

1 −k2 sin2 φ =

1 −k2 sn2 u =

1 −k2x2.
[The value of du/dφ is found from u = F(φ, k) in (12.2).] There are many formulas
relating these functions—for example, addition formulas, integrals, derivatives, etc.
These can be looked up or, in some cases, easily worked out. For example, since
sn u = sin φ, we have
d
du(sn u) = d
du(sin φ) = cos φdφ
du = cn u dn u.
For a physical problem using elliptic functions, see Am. J. Phys. 68, 888–895 (2000).
PROBLEMS, SECTION 12
1.
Expand the integrands of K and E [see (12.3)] in power series in k2 sin2 θ (assuming
small k), and integrate term by term to ﬁnd power series approximations for the
complete elliptic integrals K and E.
2.
Use a graph of sin2 θ and the text discussion just before (12.4) to verify the equations
(12.4). Note that the area under the sin2 θ graph from 0 to π/2 and the area from
π/2 to π are mirror images of each other, and this will be true also for any function
of sin2 θ.
3.
Computer plot graphs of K(k) and E(k) in (12.3) for k from 0 to 1. Also plot 3D
graphs of F(φ, k) and E(φ, k) in (12.1) for k from 0 to 1 and φ from 0 to π/2 and
also from 0 to 2π. Warning: Be sure you understand the notation used by your
computer program; see text discussion just after (12.3) and Example 1.

Section 12
Elliptic Integrals and Functions
559
In Problems 4 to 13, identify each of the integrals as an elliptic integral (see Examples 1
and 2). Learn the notation of your computer program (see Problem 3) and then evaluate
the integral by computer.
4.
Z 1
0
dt
√
1 −t2 p
1 −t2/4
5.
Z π/2
0
r
1 −1
9 sin2 θ dθ
6.
Z π/3
0
dθ
p
9 −sin2 θ
7.
Z 5π/4
0
p
25 −sin2 θ dθ
8.
Z √
3/2
0
√
49 −4t2
√
1 −t2
dt
9.
Z 1/2
−1/2
dt
√
1 −t2 √
4 −3t2
10.
Z π/4
0
dθ
p
4 −sin2 θ
11.
Z 3π/8
−π/2
dθ
q
1 −
9
10 sin2 θ
12.
Z 1/2
0
√
100 −t2
√
1 −t2
dt
13.
Z 3/4
−1/2
√
9 −4t2
√
1 −t2 dt
14.
Find the circumference of the ellipse 4x2 + 9y2 = 36.
15.
Find the length of arc of the ellipse x2 + (y2/4) = 1 between (0, 2) and ( 1
2,
√
3 ).
(Note that here b > a; see Example 4.)
16.
Find the arc length of one arch of y = sin x.
17.
Write the integral in equation (12.7) as an elliptic integral and show that (12.8)
gives its value. Hints: Write cos θ = 1−2 sin2(θ/2) and a similar equation for cos α.
Then make the change of variable x = sin(θ/2)/ sin(α/2).
18.
Computer plot graphs of sn u, cn u, and dn u, for several values of k, say, for example,
k = 1/4, 1/2, 3/4, 0.9, 0.99. Also plot 3D graphs of sn, cn, and dn as functions of
u and k.
19.
If u = ln(sec φ + tan φ), then φ is a function of u called the Gudermannian of u,
φ = gd u. Prove that:
u = ln tan
„π
4 + φ
2
«
,
tan gd u = sinh u,
sin gd u = tanh u,
d
du gd u = sech u.
20.
Show that for k = 0:
u = F(φ, 0) = φ,
sn u = sin u,
cn u = cos u,
dn u = 1;
and for k = 1:
u = F(φ, 1) = ln(sec φ + tan φ)
or
φ = gd u
(Problem 19),
sn u = tanh u,
cn u = dn u = sech u.
21.
Show that the four answers given in Section 1 for
R π/2
0
dθ/
√
cos θ are all correct.
Hints: For the beta function result, use (6.4). Then get the gamma function results
by using (7.1) and the various Γ function formulas. For the elliptic integral, use the
hint of Problem 17 with α = π/2.

560
Special Functions
Chapter 11
22.
In the pendulum problem, θ = α sin
p
g/l t is an approximate solution when the
amplitude α is small enough for the motion to be considered simple harmonic. Show
that the corresponding exact solution when α is not small is
sin θ
2 = sin α
2 sn
r
g
l t
where k = sin(α/2) is the modulus of the elliptic function. Show that this reduces
to the simple harmonic motion solution for small amplitude α.
23.
A uniform solid sphere of density 1
2 is ﬂoating in water. (Compare Chapter 8, Prob-
lem 5.37.) It is pushed down just under water and released. Write the diﬀerential
equation of motion (neglecting friction) and solve it to obtain the period in terms of
K(5−1/2). Show that this period is approximately 1.16 times the period for small
oscillations.
24.
Sometimes you may ﬁnd the notation F(φ, k) in (12.2) used when k > 1. Allowing
this notation, show that 1
3F(sin−1 3
5, 4
3) = 1
4F(sin−1 4
5, 3
4). Hints: Using the Jacobi
form of F in (12.2), write the integral which is equal to
1
3F(sin−1 3
5, 4
3).
Follow
Example 3 to make a change of variable, write the corresponding integral, and
verify that it is equal to 1
4F(sin−1 4
5, 3
4).
25.
As in Problem 24, show that 1
2F(sin−1
4
15, 5
2) = 1
5F(sin−1 2
3, 2
5).
13. MISCELLANEOUS PROBLEMS
1.
Show that
Z ∞
0
ym dy
(1 + y)n+1 =
1
(n −m)C(n, m)
for positive integral m and n, n > m, where C(n, m) =
` n
m
´
.
2.
Show that B(m, n)B(m + n, k) = B(n, k)B(n + k, m).
3.
Use Stirling’s formula to show that
lim
n→∞nxB(x, n) = Γ(x).
4.
Verify the asymptotic series
Z ∞
0
e−t dt
(1 + xt) ∼
X
(−1)nn! xn
[see equation (10.8)]. Hint: Integrate by parts repeatedly, integrating e−t dt and
diﬀerentiating the powers of (1 + xt)−1.
5.
Use gamma and beta function formulas to show that
Z ∞
0
dx
(1 + x)√x = π.
6.
Generalize Problem 5 to show that
Z ∞
0
dx
(1 + x)xp =
π
sin πp,
0 < p < 1.
Identify each of the following integrals or expressions as one of the functions of this chapter.
Check your work by evaluating both your answer and the original problem by computer.
Be sure you understand your computer program’s notation.
7.
Z ∞
0
x3e−x dx
8.
Z 1
0
e−x2 dx
9.
Z 1
0
r
4 −3x2
1 −x2 dx

Section 13
Miscellaneous Problems
561
10.
Z 3π/4
−π/4
dφ
p
1 + cos2 φ
11.
Z 3/5
0
dt
√
1 −t2 √
16 −25t2
12.
Z π/2
0
dx
p
2 −sin2 x
13.
d
du(cn u)
14.
Z ∞
1
e−x2/2 dx
15.
Z ∞
0
x5/2e−x dx
16.
Z ∞
−∞
e−x2 dx
17.
Z π/2
0
p
sin3 θ cos5 θ dθ
18.
Z ∞
0
e−x dx
x1/4
19.
Z ∞
5
e−x2 dx
20.
Z π/2
0
(cos x)5/2 dx
21.
Z 5
0
x−1/3(5 −x)10/3 dx
22.
Z 7π/8
0
p
4 −sin2 x dx
23.
Find an expression for the exact value of Γ(55.5) in terms of double factorials (!!),
powers of 2 and √π. For !!, see Chapter 1, Section 13C, Example 2.
24.
Using your result in Problem 23 and equation (5.4), ﬁnd an expression for the exact
value of Γ(−54.5).
25.
As in problems 23 and 24, ﬁnd expressions for the exact values of Γ(28.5) and
Γ(−27.5).

C H A P T E R 12
Series Solutions of Differential
Equations; Legendre, Bessel,
Hermite, and Laguerre Functions
1. INTRODUCTION
By now you are well aware that physical problems in many ﬁelds lead to diﬀerential
equations to be solved. In Chapter 13, we will discuss a variety of physical prob-
lems which lead to partial diﬀerential equations. To solve them, we will need the
solutions of some ordinary diﬀerential equations which cannot be solved in terms
of elementary functions. So in this chapter we will learn about these equations and
their solutions. However, if you would prefer to see some of the physics before you
study the math, and if you’ve studied Chapters 7 and 8, you could ﬁrst do Sections 1
to 4 of Chapter 13, and then come back to Chapter 12 to learn the material needed
for the rest of Chapter 13. (See the Preface.)
Now you may be thinking that your computer will give you the solutions of these
diﬀerential equations so you don’t need to study this. What your computer may
give you is the name of a function. What you need to know is something about the
function: graphs; formulas for derivatives and integrals; formulas that correspond to
trigonometric identities for sine and cosine functions; and other useful information
so that you can work with these named functions which occur often in applications.
This is what we will discuss in this chapter.
The diﬀerential equations we are going to solve are linear, like the equations
of Chapter 8, Section 5, but with coeﬃcients which are functions of x instead of
constants, that is, of the form y′′ + f(x)y′ + g(x)y = 0. A method of solving such
equations which we will ﬁnd useful is to assume an inﬁnite series solution.
Example 1.
We illustrate the method of series solution by solving the following simple
equation (which you can easily solve by elementary methods also!):
(1.1)
y′ = 2xy.
562

Section 1
Introduction
563
We assume a solution of this diﬀerential equation in the form of a power series,
namely
(1.2)
y = a0 + a1x + a2x2 + a3x3 + · · · + anxn + · · ·
=
∞

n=0
anxn,
where the a’s are to be found. Diﬀerentiating (1.2) term by term, we get
(1.3)
y′ = a1 + 2a2x + 3a3x2 + · · · + nanxn−1 + · · ·
=
∞

n=1
nanxn−1.
We substitute (1.2) and (1.3) into the diﬀerential equation (1.1); we then have two
power series equal to each other. Now the original diﬀerential equation is to be
satisﬁed for all values of x, that is, y′ and 2xy are to be the same function of x.
Since a given function has only one series expansion in powers of x (see Chapter 1,
Section 11), the two series must be identical, that is, the coeﬃcients of corresponding
powers of x must be equal. We get the following set of equations for the a’s:
(1.4)
a1 = 0,
a2 = a0,
a3 = 2
3a1 = 0,
a4 = 1
2a0,
or in general:
(1.5)
nan = 2an−2,
an =

0,
odd n,
2
nan−2,
even n.
Putting n = 2m (since only even terms appear in this series), we get
(1.6)
a2m =
2
2ma2m−2 = 1
ma2m−2 = 1
m
1
m −1a2m−4 = · · · = 1
m!a0.
Substituting these values of the coeﬃcients into the assumed solution (1.2) gives
the solution
(1.7)
y = a0 + a0x2 + 1
2!a0x4 + · · · + 1
m!a0x2m + · · ·
= a0
∞

m=0
x2m
m! .
Example 2.
Compare this with the solution by an elementary method (in this case,
separation of variables):
dy
y = 2x dx,
ln y = x2 + ln c,
y = cex2.
Expanding this in a series of powers of x2, we get:
y = c

1 + x2 + x4
2! + · · ·

= c
∞

n=0
x2n
n!
which, with c = a0, is the same as the series solution (1.7).

564
Series Solutions of Differential Equations
Chapter 12
You cannot always expect to ﬁnd the closed form of a power series solution
(that is, an elementary function for which your series solution is the power series
expansion), but in simple cases you may recognize it. Of course, in that case, the
problem could have been done without series; the real need for series is in problems
for which there is no closed form in terms of elementary functions. Also you should
realize that not all solutions have series expansions in powers of x, for example, ln x
or 1/x2. All we can say is that if there is a solution which can be represented by a
convergent power series this method will ﬁnd it. We shall discuss later (Section 21)
some theorems which tell us when we can expect to ﬁnd such a solution.
In the following sections we consider some diﬀerential equations which occur
frequently in applied problems and which are usually solved by series methods.
PROBLEMS, SECTION 1
Solve the following diﬀerential equations by series and also by an elementary method
and verify that your solutions agree. Note that the goal of these problems is not to
get the answer (that’s easy by computer or by hand) but to become familiar with
the method of series solutions which we will be using later. Check your results by
computer.
1.
xy′ = xy + y
2.
y′ = 3x2y
3.
xy′ = y
4.
y′′ = −4y
5.
y′′ = y
6.
y′′ −2y′ + y = 0
7.
x2y′′ −3xy′ + 3y = 0
8.
(x2 + 2x)y′′ −2(x + 1)y′ + 2y = 0
9.
(x2 + 1)y′′ −2xy′ + 2y = 0
10.
y′′ −4xy′ + (4x2 −2)y = 0
2. LEGENDRE’S EQUATION
The Legendre diﬀerential equation is
(2.1)
(1 −x2)y′′ −2xy′ + l(l + 1)y = 0,
where l is a constant. This equation arises in the solution of partial diﬀerential equa-
tions in spherical coordinates (see Problem 10.2 and Chapter 13, Section 7) and so
in problems in mechanics, quantum mechanics, electromagnetic theory, heat, etc.,
with spherical symmetry. Also see an application in Section 5.
Although the most useful solutions of this equation are polynomials (called the
Legendre polynomials), one way to ﬁnd them is to assume a series solution of the
diﬀerential equation, and show that the series terminates after a ﬁnite number of
terms. [There are other ways of ﬁnding the Legendre polynomials; see Sections 4
and 5, and Chapter 3, Section 14, Example 6.] We assume the series solution (1.2)
for y and diﬀerentiate it term by term twice to get y′ and y′′:
(2.2)





y = a0 + a1x + a2x2 + a3x3 + a4x4 + · · · + anxn + · · · ,
y′ = a1 + 2a2x + 3a3x2 + 4a4x3 + · · · + nanxn−1 + · · · ,
y′′ = 2a2 + 6a3x + 12a4x2 + 20a5x3 + · · · + n(n −1)anxn−2 + · · · .

Section 2
Legendre’s Equation
565
We substitute (2.2) into (2.1) and collect the coeﬃcients of the various powers of x;
it is convenient to tabulate them as follows:
const.
x
x2
x3
· · ·
xn
· · ·
y′′
2a2
6a3
12a4
20a5
(n + 2)(n + 1)an+2
−x2y′′
−2a2
−6a3
−n(n −1)an
−2xy′
−2a1
−4a2
−6a3
−2nan
l(l + 1)y
l(l + 1)a0
l(l + 1)a1
l(l + 1)a2
l(l + 1)a3
l(l + 1)an
Next we set the total coeﬃcient of each power of x equal to zero [because, as
discussed in Section 1, y must satisfy (2.1) identically]. For the ﬁrst few powers of
x we get
(2.3)
2a2 + l(l + 1)a0 = 0
or
a2 = −l(l + 1)
2
a0;
6a3 + (l2 + l −2)a1 = 0
or
a3 = −(l −1)(l + 2)
6
a1;
12a4 + (l2 + l −6)a2 = 0
or
a4 = −(l −2)(l + 3)
12
a2
= l(l + 1)(l −2)(l + 3)
4!
a0;
and from the xn coeﬃcient we get
(2.4)
(n + 2)(n + 1)an+2 + (l2 + l −n2 −n)an = 0.
The coeﬃcient of an in (2.4) can be factored to give
(2.5)
l2 −n2 + l −n = (l + n)(l −n) + (l −n) = (l −n)(l + n + 1).
Then we can write a general formula for an+2 in terms of an. This formula (2.6)
includes the formulas (2.3) for a2, a3, and a4, and makes it possible for us to ﬁnd
any even coeﬃcient as a multiple of a0, and any odd coeﬃcient as a multiple of a1.
Solving (2.4) for an+2 and using (2.5), we have
(2.6)
an+2 = −(l −n)(l + n + 1)
(n + 2)(n + 1)
an.
The general solution of (2.1) is then a sum of two series containing (as the solu-
tion of a second-order diﬀerential equation should) two constants a0 and a1 to be
determined by the given initial conditions:
y = a0
	
1 −l(l + 1)
2!
x2 + l(l + 1)(l −2)(l + 3)
4!
x4 −· · ·

+ a1
	
x −(l −1)(l + 2)
3!
x3 + (l −1)(l + 2)(l −3)(l + 4)
5!
x5 −· · ·

.
(2.7)
From equation (2.6) you can see by the ratio test that these series converge for
x2 < 1. It can be shown that, in general, they do not converge for x2 = 1.

566
Series Solutions of Differential Equations
Chapter 12
Example.
Consider the a1 series for l = 0. If x2 = 1, this series is 1 + 1
3 + 1
5 + · · · , which
is divergent by the integral test (Chapter 1, Section 6B). Now in many applications
x is the cosine of an angle θ, and l is a (nonnegative) integer. We want a solution
which converges for all θ, that is, a solution which converges at x = ±1 as well
as for |x| < 1. We can always ﬁnd one (but not two) such solutions when l is an
integer; let us see how.
Legendre Polynomials
We have seen that for l = 0 the a1 series in (2.7) di-
verges. But look at the a0 series; it gives just y = a0 for l = 0 since all the rest of
the terms contain the factor l. If l = 1, the a0 series is divergent at x2 = 1, but the
a1 series stops with y = a1x [since all the rest of the terms in the a1 series contain
the factor (l −1)]. For any integral l, one series terminates giving a polynomial
solution; the other series is divergent at x2 = 1. (Negative integral values of l would
simply give solutions already obtained for positive l’s; for example, l = −2 gives
the polynomial solution y = a1x which is the same as the l = 1 solution. Conse-
quently, it is customary to restrict l to nonnegative values.) Thus we obtain a set of
polynomial solutions of the Legendre equation, one for each nonnegative integral l.
Each solution contains an arbitrary constant factor (a0 or a1); for l = 0, y = a0; for
l = 1, y = a1x, and so on. If the value of a0 or a1 in each polynomial is selected so
that y = 1 when x = 1, the resulting polynomials are called Legendre Polynomials,
written Pl(x). From (2.6) and (2.7) and the requirement Pl(1) = 1, we ﬁnd the
following expressions for the ﬁrst few Legendre polynomials:
(2.8)
P0(x) = 1,
P1(x) = x,
P2(x) = 1
2(3x2 −1).
Finding a few more Legendre polynomials by this method and other methods will
be left to the problems. Although Pl(x) for any integral l may be found by this
method, simpler ways of obtaining the Legendre polynomials for larger l will be
outlined in Sections 4 and 5. Of course, if you just want the formula for a particular
Pl, you can ﬁnd it by computer or in reference books.
Eigenvalue Problems
In ﬁnding the Legendre polynomials as solutions of Leg-
endre’s equation (2.1), we have solved an eigenvalue problem.
(See Chapter 3,
Sections 11 and 12.) Recall that in an eigenvalue problem we are given an equation
or a set of equations containing a parameter, and we want solutions that satisfy
some special requirement; in order to obtain such solutions we must choose partic-
ular values (called eigenvalues) for the parameter in the problem. In ﬁnding the
Legendre polynomials, we asked for series solutions of Legendre’s equation (2.1)
which converged at x = ±1. We saw that we could obtain such solutions if the
parameter took on any integral value. The values of l, namely 0, 1, 2, · · · , are
called eigenvalues (or characteristic values); the corresponding solutions Pl(x) are
called eigenfunctions (or characteristic functions).
Note the parallel between the eigenvalue-eigenvector problems of Chapter 3 and
the eigenvalue-eigenfunction problems of this chapter. Recall that in Chapter 3, we
wrote an eigenvalue equation as Mr = λr where M was a matrix operator which
operated on the eigenvector r to produce a multiple of r. The Legendre equation
is of the form f(D)y(x) = l(l + 1)y(x) where f(D) is a diﬀerential operator which

Section 3
Leibniz’ Rule for Differentiating Products
567
operates on the eigenfunction y(x) to produce a multiple of y(x). See Section 22
and Chapter 13 for further examples of diﬀerential equations whose solutions are
eigenfunctions.
The Legendre polynomials are also called Legendre functions of the ﬁrst kind.
The second solution for each l, which is an inﬁnite series (convergent for x2 < 1),
is called a Legendre function of the second kind and is denoted by Ql(x) (See
Problem 4.) The functions Ql(x) are not used as frequently as the polynomials
Pl(x).
For fractional l both solutions are inﬁnite series; these again occur less
frequently in applications.
PROBLEMS, SECTION 2
1.
Using (2.6) and (2.7) and the requirement that Pl(l) = 1, ﬁnd P2(x), P3(x), and
P4(x). Check your results by computer.
2.
Show that Pl(−1) = (−1)l. Hint:
When is Pl(x) an even function and when is it
an odd function?
3.
Computer plot graphs of Pl(x) for l = 0, 1, 2, 3, 4, and x from −1 to 1.
4.
Use the method of reduction of order [Chapter 8, Section 7(e)] and the known
solution Pl(x) of Legendre’s equation to ﬁnd the second solution Ql(x) (in terms of
an integral). Evaluate the integral for the cases l = 0 and l = 1 to ﬁnd Q0 and Q1.
Note the divergence of the logarithms at x = ±1. Expand the logarithms in Q0 to
get the divergent series mentioned above [a1 series in (2.7) with l = 0, x2 = 1].
3. LEIBNIZ’ RULE FOR DIFFERENTIATING PRODUCTS
Let us digress for a moment to discuss a very useful formula called Leibniz rule
for ﬁnding a high order derivative of a product. We shall ﬁrst illustrate this by a
numerical example. We could, of course, do a numerical problem by computer, but
our purpose is to understand the general formula which we will need in derivations.
Also, when you know Leibniz rule, you may ﬁnd in simple numerical cases that you
can write down the answer for a high order derivative of a product faster than you
can type the problem into the computer (see Problems 2 to 5).
Example.
Find (d 9/dx9)(x sin x).
Leibniz rule says that the answer is
(3.1)
x d 9
dx9 (sin x) + 9 d
dx(x) d8
dx8 (sin x) + 9 · 8
2!
d2
dx2 (x) d7
dx7 (sin x) + · · · .
This should remind you of a binomial expansion
(a + b)9 = a0b9 + 9ab8 + 9 · 8
2! a2b7 + · · · .
The coeﬃcients in (3.1) are, in fact, binomial coeﬃcients, and the sum of the orders
of the two derivatives in each term is 9. (You may ﬁnd the second hint in Problem 6
useful in understanding and remembering this.) Now if it happens, as here, that
the derivatives of one factor become zero after the ﬁrst few, the rule saves much
work. In (3.1), (d2/dx2)(x) = 0 and all higher derivatives of x are zero so we get
d 9
dx9 (x sin x) = x d 9
dx9 (sin x) + 9 d8
dx8 (sin x) = x cos x + 9 sin x.

568
Series Solutions of Differential Equations
Chapter 12
PROBLEMS, SECTION 3
1.
By Leibniz’ rule, write the formula for (dn/dxn)(uv).
Use Problem 1 to ﬁnd the following derivatives.
2.
(d10/dx10)(xex)
3.
(d6/dx6)(x2 sin x)
4.
d25/dx25)(x cos x)
5.
d100/dx100)(x2e−x)
6.
Verify Problem 1. Hints: One method is to use mathematical induction. Another
method is to write
d
dx(uv) = D(uv) = (Du + Dv)(uv),
where Du acts only on u and Dv acts only on v, that is, Du(uv) means v(du/dx),
etc. Then
dn
dxn (uv) = (Du + Dv)n(uv).
Expand (Du +Dv)n by the binomial theorem and interpret the terms to get Leibniz’
rule.
4. RODRIGUES’ FORMULA
We have obtained the Legendre polynomials as solutions of Legendre’s equation
when l is an integer; there are other ways of obtaining them. We shall prove that
Rodrigues’ formula
(4.1)
Pl(x) =
1
21l!
d l
dxl (x2 −1)l
gives correctly the Legendre polynomials Pl(x). There are two parts to the proof.
First we show that if
(4.2)
v = (x2 −1)l,
then d lv/dxl is a solution of Legendre’s equation; then we show that Pl(1) = 1 in
(4.1). To prove the ﬁrst part, ﬁnd dv/dx in (4.2) and multiply it by x2 −1:
(4.3)
(x2 −1)dv
dx = (x2 −1)l(x2 −1)l−1 · 2x = 2lxv.
Diﬀerentiate (4.3) l + 1 times by Leibniz’ rule:
(x2 −1)d l+2v
dxl+2 + (l + 1)(2x)d l+1v
dxl+1 + (l + 1)l
2!
· 2 · d lv
dxl
= 2lxd l+1v
dxl+1 + 2l(l + 1)d lv
dxl .
(4.4)
Simplifying (4.4), we get (Problem 1)
(4.5)
(1 −x2)
d lv
dxl
′′
−2x
d lv
dxl
′
+ l(l + 1)d lv
dxl = 0.

Section 5
Generating Function for Legendre Polynomials
569
This is just Legendre’s equation (2.1) with y = d lv/dxl; thus we see that d lv/dxl =
(d l/dxl)(x2 −1)l is a solution of Legendre’s equation as we claimed. It is a poly-
nomial of degree l, and since we have previously called the polynomial solution of
degree l the Legendre polynomial Pl(x), this must be it with the possible exception
of the numerical factor which must give Pl(1) = 1. A simple method of showing
that Pl(1) = 1 for the functions Pl(x) in (4.1) is outlined in Problem 2.
PROBLEMS, SECTION 4
1.
Verify equations (4.4) and (4.5).
2.
Show that Pl(1) = 1, with Pl(x) given by (4.1), in the following way. Factor (x2−1)l
into (x + 1)l(x −1)1 and diﬀerentiate the product l times by Leibniz’ rule. Without
writing out very many terms you should see that every term but one contains the
factor x −1 and so becomes zero when x = 1. Use this to evaluate Pl(x) in (4.1)
when x = 1 to get Pl(1) = 1.
3.
Find P0(x), P1(x), P2(x), P3(x), and P4(x) from Rodrigues’ formula (4.1). Check
your results by computer.
4.
Show that
R 1
−1 xmPl(x) dx = 0 if m < l. Hint: Use Rodrigues’ formula (4.1) and
integrate repeatedly by parts, diﬀerentiating the power of x and integrating the
derivative each time.
5. GENERATING FUNCTION FOR LEGENDRE POLYNOMIALS
The expression
(5.1)
Φ(x, h) = (1 −2xh + h2)−1/2,
|h| < 1,
is called the generating function for Legendre polynomials. We shall show that
(5.2)
Φ(x, h) = P0(x) + hP1(x) + h2P2(x) + · · · =
∞

l=0
hlPl(x),
where the functions Pl(x) are the Legendre polynomials. (For discussion of conver-
gence of the series, see Chapter 14, Problem 2.43.) Let us ﬁrst verify a few terms
of (5.2). For simplicity put 2xh −h2 = y into (5.1), expand (1 −y)−1/2 in powers
of y, then substitute back y = 2xh −h2 and collect powers of h to get
(5.3)
Φ = (1 −y)−1/2 = 1 + 1
2y +
1
2 · 3
2
2! y2 + · · ·
= 1 + 1
2(2xh −h2) + 3
8(2xh −h2)2 + · · ·
= 1 + xh −1
2h2 + 3
8(4x2h2 −4xh3 + h4) + · · ·
= 1 + xh + h2( 3
2x2 −1
2) + · · ·
= P0(x) + hP1(x) + h2P2(x) + · · · .

570
Series Solutions of Differential Equations
Chapter 12
This is not a proof that the functions called Pl(x) in (5.2) are really Legendre
polynomials, but merely a veriﬁcation of the ﬁrst few terms. To prove in general
that the polynomials called Pl(x) in (5.2) are Legendre polynomials we must show
that they satisfy Legendre’s equation and that they have the property Pl(1) = 1.
The latter is easy to prove; putting x = 1 in (5.1) and (5.2), we get
(5.4)
Φ(1, h) = (1 −2h + h2)−1/2 =
1
1 −h = 1 + h + h2 + · · ·
≡P0(1) + P1(1)h + P2(1)h2 + · · · .
Since this is an identity in h, the functions Pl(x) in (5.2) have the property Pl(1) = 1.
To show that they satisfy Legendre’s equation, we shall use the following identity
which can be veriﬁed from (5.1) by straightforward diﬀerentiation and some algebra
(Problem 2):
(5.5)
(1 −x2)∂2Φ
∂x2 −2x∂Φ
∂x + h ∂2
∂h2 (hΦ) = 0.
Substituting the series (5.2) for Φ into (5.5), we get
(5.6)
(1 −x2)
∞

l=0
hlP ′′
l (x) −2x
∞

l=0
hlP ′
l (x) +
∞

l=0
l(l + 1)hlPl(x) = 0.
This is an identity in h, so the coeﬃcient of each power of h must be zero. Setting
the coeﬃcient of hl equal to zero, we get
(5.7)
(1 −x2)P ′′
l (x) −2xP ′
l (x) + l(l + 1)Pl(x) = 0.
This is Legendre’s equation, so we have proved that the functions Pl(x) in (5.2)
satisfy it as claimed.
Recursion Relations
The generating function is useful in deriving the recursion
relations (also called recurrence relations) for Legendre polynomials. These recur-
sion relations are identities in x and are used (as trigonometric identities are) to
simplify work and to help in proofs and derivations. Some examples of recursion
relations are:
(5.8)
(a)
lPl(x) = (2l −1)xPl−1(x) −(l −1)Pl−2(x),
(b)
xP ′
l (x) −P ′
l−1(x) = lPl(x),
(c)
P ′
l (x) −xP ′
l−1(x) = lPl−1(x),
(d)
(1 −x2)P ′
l (x) = lPl−1(x) −lxPl(x),
(e)
(2l + 1)Pl(x) = P ′
l+1(x) −P ′
l−1(x),
(f)
(1 −x2)P ′
l−1(x) = lxPl−1(x) −lPl(x).
We shall now derive (5.8a); the problems outline derivations of the other equations.
From (5.1) we get
(5.9)
∂Φ
∂h = −1
2(1 −2xh + h2)−3/2(−2x + 2h);
(1 −2xh + h2)∂Φ
∂h = (x −h)Φ.

Section 5
Generating Function for Legendre Polynomials
571
Substituting the series (5.2) and its derivative with respect to h into (5.9), we get
(1 −2xh + h2)
∞

l=1
lhl−1Pl(x) = (x −h)
∞

l=0
hlPl(x).
This is an identity in h so we equate coeﬃcients of hl−1. Carefully adjusting indices
so that we select the term in hl−1 each time, we ﬁnd
(5.10)
lPl(x) −2x(l −1)Pl−1(x) + (l −2)Pl−2(x) = xPl−1(x) −Pl−2(x)
which simpliﬁes to (5.8a).
The recursion relation (5.8a) gives the simplest way
of ﬁnding any Legendre polynomial when we know the Legendre polynomials for
smaller l (Problem 3).
Expansion of a Potential
The generating function is useful in problems involv-
ing the potential associated with any inverse square force. Recall that the gravi-
tational force between two point masses separated by a distance d is proportional
to 1/d2 and the associated potential energy is proportional to 1/d. Similarly, the
electrostatic force between two electric charges a distance d apart is proportional
to 1/d2 and the associated electrostatic potential energy is proportional to 1/d.
Example 1.
In either case we can write the potential as
(5.11)
V = K
d ,
Figure 5.1
where K is an appropriate constant. In Figure 5.1, let the two masses (or charges)
be at the heads of vectors r and R.
Then, by the law of cosines, the distance
between them is
(5.12)
d = |R −r|
=

R2 −2Rr cos θ + r2
= R

1 −2 r
R cos θ +
 r
R
2
and the gravitational or electric potential is
(5.13)
V = K
R
	
1 −2r
R cos θ +
 r
R
2
−1/2
.
For |r| < |R|, we make the change of variables
(5.14)
h = r
R,
x = cos θ.
(Note: x is not a coordinate but just a new variable standing for cos θ.) Then in
terms of the generating function Φ in (5.1) we have
(5.15)
d = R

1 −2hx + h2
V = K
R (1 −2hx + h2)−1/2 = K
R Φ.

572
Series Solutions of Differential Equations
Chapter 12
Using (5.2), we can write the potential V as an inﬁnite series
(5.16)
V = K
R
∞

l=0
hlPl(x)
or in terms of r and θ [using (5.14)]
(5.17)
V = K
R
∞

l=0
rlPl(cos θ)
Rl
= K
∞

l=0
rlPl(cos θ)
Rl+1
.
In many applications the distance |R| is much larger than |r|. Then the terms of
the series (5.17) decrease rapidly in magnitude because of the factor (r/R)l, and
the potential can be approximated by using only a few terms in the series.
We can make (5.17) more general and useful by considering the following prob-
lem. (We shall discuss the electrical case for deﬁniteness—the gravitational case
could be discussed in parallel fashion.)
Example2.
Suppose there are a large number of charges qi at points ri. The electrostatic
potential Vi at the point R due to the charge qi at ri means the electrostatic
potential energy of a pair of charges, namely, a unit charge at R and the charge
qi at ri; this is given by (5.11) and (5.12), or by (5.17), with r = ri, θ = θi, and
K = qi · 1 · K′, where K′ is a numerical constant depending on the choice of units:
(5.18)
Vi = K′qi
∞

l=0
rl
iPl(cos θi)
Rl+1
.
The total potential V at R due to all the charges qi is then a sum over i of all the
series (5.18), namely
(5.19)
V =

i
Vi = K′ 
i
qi
∞

l=0
rl
iPl(cos θi)
Rl+1
= K′
∞

l=0

i qirl
iPl(cos θi)
Rl+1
.
Example 3.
If, instead of a set of discrete charges, we have a continuous charge distribu-
tion, then the sum over i becomes an integral, namely
(5.20)

rlPl(cos θ) dq
or

rlPl(cos θ)ρ dτ,
where ρ is the charge density, and the integral is over the space occupied by the
charge distribution. Then (5.19) becomes
(5.21)
V = K′ 
l
1
Rl+1

rlPl(cos θ)ρ dτ.
The terms of the series (5.21) can be interpreted physically. The l = 0 term is
(5.22)
1
R

ρ dτ = 1
R · (total charge).
Thus if R is large enough compared to all the ri or all the values of r at points
of the charge distribution, we can approximate the potential of the distribution as

Section 5
Generating Function for Legendre Polynomials
573
that of a single charge at the origin of magnitude equal to the total charge of the
distribution. The l = 1 term of the series (5.21) is
(5.23)
1
R2

r cos θ ρ dτ.
Figure 5.2
To interpret this recall that the electric dipole moment of a pair
of charges +q and −q a distance d apart (as in Figure 5.2) is
deﬁned as the vector qd, where d is the vector from −q to +q.
Since the vector qd is equal to q(r1 −r2) = qr1 −qr2, we often
call qr1 and −qr2 the dipole moments of +q and −q about O;
then the total dipole moment due to the two charges is just the
sum of the two moments. Suppose we calculate the dipole moment about O of all
the charges qi; this is the vector sum 
i qiri cos θi, since θi is the angle between R
and ri. In the case of a continuous charge distribution this sum becomes
(5.24)

r cos θ ρ dτ.
Thus we see from (5.23) and (5.24) that the second term of the series (5.21) is
1/R2 times the component in the R direction of the dipole moment of the charge
distribution. If you consider the fact that the ﬁrst term of (5.21) involves the total
charge (a scalar, that is, a tensor of rank zero) and the second term involves the
dipole moment (a vector, that is, a tensor of rank one), it may not surprise you
to learn that the third term involves a 2nd-rank tensor known as the quadrupole
moment of the charge distribution, the fourth term involves a 3rd-rank tensor known
as the octopole moment, etc. (See Problem 15 for more detail.)
Example 4.
Given a charge or mass distribution, the moments of various ranks and the
terms in (5.21) can be computed. The opposite process is often of great interest
in applied problems.
Consider a satellite circling the earth; it is moving in the
gravitational ﬁeld of the earth’s mass. If the mass distribution of the earth were
spherically symmetric, then only the ﬁrst term would appear in the series for the
gravitational potential [this series would be (5.21) with ρ a mass density instead
of a charge density]. But since the earth is not a perfect sphere (equatorial bulge,
etc.), other terms are present in (5.21) and the corresponding forces aﬀect the
motion of satellites. From accurate measurements of the satellite orbits, it is now
possible to calculate many terms of the series (5.21). Similarly, in the electrical case,
experimental measurements give us information about the distribution of electric
charge inside atoms and nuclei; our discussion here and equation (5.21) provide
the basis for the interpretation of such measurements, and the terminology used in
discussing them.
PROBLEMS, SECTION 5
1.
Find P3(x) by getting one more term in the generating function expansion (5.3).
2.
Verify (5.5) using (5.1).
3.
Use the recursion relation (5.8a) and the values of P0(x) and P1(x) to ﬁnd P2(x),
P3(x), P4(x), P5(x), and P6(x). [After you have found P3(x), use it to ﬁnd P4(x),
and so on for the higher order polynomials.]

574
Series Solutions of Differential Equations
Chapter 12
4.
Show from (5.1) that
(x −h)∂Φ
∂x = h∂Φ
∂h .
Substitute the series (5.2) for Φ, and so prove the recursion relation (5.8b).
5.
Diﬀerentiate the recursion relation (5.8a) and use the recursion relation (5.8b) with
l replaced by l −1 to prove the recursion relation (5.8c).
6.
From (5.8b) and (5.8c), obtain (5.8d) and (5.8f).
Then diﬀerentiate (5.8d) with
respect to x and eliminate P ′
l−1(x) using (5.8b). Your result should be the Legendre
equation. The derivation of Problems 4 to 6 constitutes an alternative proof [to that
of equations (5.5) to (5.7)] that the functions Pl(x) in (5.2) are Legendre polynomials.
7.
Write (5.8c) with l replaced by l + 1 and use it to eliminate the xP ′
l (x) term in
(5.8b). You should get (5.8e).
Express each of the following polynomials as linear combinations of Legendre polynomials.
Hint: Start with the highest power of x and work down in ﬁnding the correct combination.
8.
5 −2x
9.
3x2 + x −1
10.
x4
11.
x −x3
12.
7x4 −3x + 1
13.
x5
14.
Show that any polynomial of degree n can be written as a linear combination of
Legendre polynomials with l ≤n.
15.
Expand the potential V = K/d in (5.11) in the following way in order to see how
the terms depend on the tensors mentioned above. In Figure 5.1 let R have the
coordinates X, Y , Z and r have coordinates x, y, z. [Note: The coordinate x here
is not the x in (5.14).] Then
V = K
d = K[(X −x)2 + (Y −y)2 + (Z −z)2]−1/2.
Consider X, Y , Z as constants and expand V (x, y, z) in a three variable power series
about the origin. (See Chapter 4, Section 2, for discussion of two-variable power
series and generalize the method.) You should ﬁnd
V =K
R + K
R2
„X
R x + · · ·
«
+ K
R3
»„3
2
X2
R2 −1
2
«
x2 + · · · + 3
2
X
R
Y
R 2xy + · · ·
–
+ · · ·
and similar terms in y, z, y2, xz, and so on. Now letting r = ri and K = K′qi
for a charge distribution as in (5.18), and summing (or integrating) over the charge
distribution, show that: the ﬁrst term is just (K′/R) · total charge; the next group
of terms (in x, y, z) involve the three components of the electric dipole moment; the
sum of these terms is (K′/R2)·component of the dipole moment in the R direction;
the next group (quadratic terms) involve six quantities of the form
ZZZ
x2ρ dτ
and similar y, z integrals,
ZZZ
2xyρ dτ
and similar xz, yz integrals.
If we split the 2xy term into xy and yx (and similarly for the 2xz and 2yz terms), we
have the nine components of a 2nd-rank tensor called the quadrupole moment. Use
the “direct product” method of Chapter 10, Section 2 to show that it is a 2nd-rank

Section 6
Complete Sets of Orthogonal Functions
575
tensor. (Remember from Chapter 10 that, by deﬁnition, x, y, z are the components
of a vector, that is, a 1st-rank tensor.) Just as two charges +q and −q form an
electric dipole, so four charges like this
s
-
s+
s
+
s- form an electric quadrupole and the
quadratic terms in the V series give the potential of such a charge conﬁguration.
Again using Chapter 10, Section 2, show that the third-order terms in x, y, z form
a 3rd-rank tensor; this is known as the octopole moment. It can be represented
physically by two quadrupoles side by side just as the quadrupole above was formed
by two dipoles side by side.
6. COMPLETE SETS OF ORTHOGONAL FUNCTIONS
Orthogonal functions
Two vectors A and B are orthogonal (perpendicular) if
their scalar product is zero, that is, if
(6.1)

i
AiBi = 0.
[See Chapter 3, equations (4.12) and (10.3).] Recall from Chapter 3, Section 14,
that we can think of functions as elements of a vector space. Then by analogy with
(6.1) we say that two functions A(x) and B(x) are orthogonal on (a, b) if
(6.2)
 b
a
A(x)B(x) dx = 0.
If the functions A(x) and B(x) are complex, the deﬁnition of orthogonality is [see
Chapter 3, equation (14.3)]
A(x) and B(x) are orthogonal on (a, b) if
(6.3)
 b
a
A∗(x)B(x) dx = 0,
where A∗(x) is the complex conjugate of A(x) (see Problem 1).
Since (6.3) is identical with (6.2) if A(x) and B(x) are real, we can take (6.3) as
the general deﬁnition of orthogonality of A(x) and B(x) on (a, b).
If we have a whole set of functions An(x) where n = 1, 2, 3, · · ·, and
(6.4)
 b
a
A∗
n(x)Am(x) dx =

0
if m ̸= n,
const. ̸= 0
if m = n,
we call the functions An(x) a set of orthogonal functions. We have already used
such sets of functions in Fourier series. Recall that [Chapter 7, equation (5.2)]
(6.5)
 π
−π
sin nx sin mx dx =

0
if m ̸= n,
π
if m = n ̸= 0.
Thus sin nx is a set of orthogonal functions on (−π, π), or in fact on any other
interval of length 2π. Similarly, the functions cos nx are orthogonal on (−π, π).

576
Series Solutions of Differential Equations
Chapter 12
Also the whole set consisting of sin nx and cos nx is a set of orthogonal functions
on (−π, π) since
 π
−π
sin nx cos mx dx = 0
for any n and m.
We have used complex functions also, namely the set einx. For this set the orthog-
onality property is given by (6.4), namely
(6.6)
 π
−π
(einx)∗eimx dx =
 π
−π
e−inxeimx dx =

0
if m ̸= n,
2π
if m = n.
Recall that sin nx and cos nx (or einx) were the functions used in a Fourier se-
ries expansion on (−π, π). You should now realize that it was the orthogonality
property that we used in getting the coeﬃcients. When we multiplied the equation
f(x) = ∞
m=−∞cmeimx by e−inx and integrated, the integrals of all the terms in
the series except the cn term were zero by the orthogonality property (6.6). There
are many other sets of orthogonal functions besides the trigonometric or exponential
ones. Just as we used the sine-cosine or exponential set to expand a function in a
Fourier series, so we can expand a function in a series using other sets of orthogonal
functions. We shall show this for the functions Pl(x) after we prove that they are
orthogonal.
Complete sets
There is another important point to consider when we want to
expand a function in terms of a set of orthogonal functions. Again let us consider
the vector analogy. We write vectors in terms of their components and the basis
vectors i, j, k.
In two dimensions we need only two basis vectors, say i and j.
But if we tried to write three-dimensional vectors in terms of just i and j, there
would be some vectors we could not represent; we say that (in three dimensions)
i and j are not a complete set of basis vectors. A simple way of expressing this
(which generalizes to n dimensions) is to say that there is another vector (namely
k) which is orthogonal to both i and j. Thus we deﬁne a set of orthogonal basis
vectors as complete if there is no other vector orthogonal to all of them (in the
space of the number of dimensions we are considering). By analogy, we deﬁne a set
of orthogonal functions as complete on a given interval if there is no other function
orthogonal to all of them on that interval. Now it is easy to see that there are
some vectors in three dimensions which cannot be represented using only i and
j . Similarly, there are functions which cannot be represented by a series using an
incomplete set of orthogonal functions. We have discussed one example of this in
Fourier series (Chapter 7, Section 11). If we are trying to represent a sound wave
by a Fourier series, we must not leave out any of the harmonics; that is, the set of
functions sin nx, cos nx on (−π, π) would not be complete if we left out some of the
values of n. As another example, the set of functions sin nx is an orthogonal set
on (−π, π). However, it is not complete; to have a complete set we must include
also the functions cos nx, and you should recall that this is what we did in Fourier
series. On the other hand, sin nx is a complete set on (0, π); we used this fact when
we started with a function given on (0, π), deﬁned it on (−π, 0) to make it odd,
and then expanded it in a sine series. Similarly, cos nx is a complete set on (0, π).
In this chapter, we are particularly interested in the fact (which we state without
proof) that the Legendre polynomials are a complete set on (−1, 1).

Section 7
Orthogonality of the Legendre Polynomials
577
PROBLEMS, SECTION 6
1.
Show that if
R b
a A∗(x)B(x)dx = 0 [see (6.3)], then
R b
a A(x)B∗(x) dx = 0, and vice
versa.
2.
Show that the functions einπx/l, n = 0, ±1, ±2, · · · , are a set of orthogonal functions
on (−l, l).
3.
Show that the functions x2 and sin x are orthogonal on (−1, 1). Hint: See Chapter 7,
Section 9.
4.
Show that the functions f(x) and g(x) are orthogonal on (−a, a) if f(x) is even and
g(x) is odd. (See Problem 3.)
5.
Evaluate
R 1
−1 P0(x)P2(x) dx to show that these functions are orthogonal on (−1, 1).
6.
Show in two ways that Pl(x) and P ′
l (x) are orthogonal on (−1, 1). Hint: See Prob-
lem 4 and Problem 4.4.
7.
Show that the set of functions sin nx is not a complete set on (−π, π) by trying to
expand the function f(x) = 1 on (−π, π) in terms of them.
8.
Show that the functions cos (n + 1
2)x, n = 0, 1, 2, · · · , are orthogonal on (0, π). Ex-
pand the function f(x) = 1 on (0, π) in terms of them. (Is it a complete set? See
Chapter 7, end of Section 11.)
9.
Show in two ways that
R 1
−1 P2n+1(x) dx = 0.
7. ORTHOGONALITY OF THE LEGENDRE POLYNOMIALS
We are going to show that the Legendre polynomials are a set of orthogonal functions
on (−1, 1), that is, that
(7.1)
 1
−1
Pl(x)Pm(x) dx = 0
unless l = m.
To prove this we rewrite the Legendre diﬀerential equation (2.1) in the form
(7.2)
d
dx[(1 −x2)P ′
l (x)] + l(l + 1)Pl(x) = 0.
Write (7.2) for Pl(x) and for Pm(x); multiply the Pl(x) equation by Pm(x), and the
Pm(x) equation by Pl(x) and subtract to get
Pm(x) d
dx[(1 −x2)P ′
l (x)] −Pl(x) d
dx[(1 −x2)P ′
m(x)]
+ [l(l + 1) −m(m + 1)]Pm(x)Pl(x) = 0.
(7.3)
The ﬁrst two terms of (7.3) can be written as
(7.4)
d
dx[(1 −x2)(PmP ′
l −PlP ′
m)]
where, for simplicity, we have used Pl = Pl(x), and so forth.
Integrating (7.3)
between −1 and 1 and using (7.4), we get
(7.5)
(1 −x2)(PmP ′
l −PlP ′
m)
1
−1 + [l(l + 1) −m(m + 1)]
 1
−1
Pm(x)Pl(x) dx = 0.

578
Series Solutions of Differential Equations
Chapter 12
The integrated term is zero because (1 −x2) = 0 at x = ±1, and Pm(x) and Pl(x)
are ﬁnite. The bracket in front of the integral is not zero unless m = l. Therefore
the integral must be zero for l ̸= m and we have (7.1).
The method we have used here is a standard one which can be used for many
other sets of orthogonal functions to prove the orthogonality property by using the
diﬀerential equation satisﬁed by the functions. (See Problems 1 and 2; also see
Section 19 and Problems 10.3, 22.7, 22.16, 22.24, 23.24b, and 23.25.)
Recall (Section 5, Problems 8 to 14) that we can write any polynomial of degree
n as a linear combination of Legendre polynomials of degree ≤n. Thus, by (7.1),
any polynomial of degree < l is orthogonal to Pl(x):
(7.6)
 1
−1
Pl(x) · (any polynomial of degree < l) dx = 0.
PROBLEMS, SECTION 7
1.
By a method similar to that we used to show that the Pl’s are an orthogonal set
of functions on (−1, 1), show that the solutions of y′′
n = −n2yn are an orthogonal
set on (−π, π). Hint: You should know what functions the solutions yn are; do not
use the functions themselves, but you may use their values and the values of their
derivatives at −π and π to evaluate the integrated part of your equation.
2.
Following the method in (7.2) to (7.5), show that the solutions of the diﬀerential
equation
(1 −x2)y′′ −2xy′ + [l(l + 1) −(1 −x2)−1]y = 0
are a set of orthogonal functions on (−1, 1).
3.
Use Problem 4.4 to show that
R 1
−1 Pm(x)Pl(x) dx = 0 if m < l. Comment: This
amounts to a diﬀerent proof of orthogonality—via Rodrigues’ formula instead of the
diﬀerential equation.
4.
Use equation (7.6) to show that
R 1
−1 Pl(x)P ′
l−1(x) dx = 0. Hint: What is the degree
of P ′
l−1(x)? Also show that
R 1
−1 P ′
l (x)Pl+1(x) dx = 0.
5.
Show that
R 1
−1 Pl(x) dx = 0, l > 0. Hint: Consider
R 1
−1 Pl(x)P0(x) dx.
6.
Show that P1(x) is orthogonal to [Pl(x)]2 on (−1, 1). Hint: See Problem 6.4.
8. NORMALIZATION OF THE LEGENDRE POLYNOMIALS
If we take the scalar product of a vector with itself, A · A = A2, we get the square
of the length (or norm) of the vector. If we divide A by its length, we get a unit
vector. In Chapter 3, Section 14 we showed that we can think of functions as the
vectors of a vector space and we deﬁned the norm N of a function A(x) on (a, b)
by [see Chapter 3, equation (14.2)]
 b
a
A∗(x)A(x) dx =
 b
a
|A(x)|2 dx = N 2.
We also say that the function N −1A(x) is normalized; like a unit vector, a normal-
ized function has norm = 1. The factor N −1 is called the normalization factor. For

Section 8
Normalization of the Legendre Polynomials
579
example,
 π
0 sin2 nx dx = π/2. Then the norm of sin nx on (0, π) is

π/2, and the
functions

2/π sin nx have norm 1 on (0, π), that is, they are normalized. A set of
normalized orthogonal functions is called orthonormal. For example,

2/π sin nx
is an orthonormal set on (0, π).
Such a set of orthonormal functions may remind us of i, j, k; like these unit
vectors, the functions are orthogonal and have norm = 1.
If the elements of a
vector space are functions, we can then use a (complete) orthonormal subset of the
functions as the basis vectors of the space. We think of expanding other functions
in terms of them (by analogy with writing a three-dimensional vector in terms of
i, j, k). For example, suppose we have expanded a given function f(x) on (0, π) in
a Fourier sine series:
f(x) =

Bn

2
π sin nx.
We call f(x) a vector with components Bn in terms of the basis vectors

2/π sin nx.
Thus, in quantum mechanics, we often refer to a function which describes the state
of a physical system as either a state function or a state vector. Just as we can
write a three-dimensional vector in terms of i, j, k, or in terms of another basis, say
er, eθ, eφ, so we can expand a given f(x) in terms of another orthonormal set of
functions and ﬁnd its components relative to this new basis. In Section 9, we shall
see how to expand functions in Legendre series.
Just as we needed the norm of sin nx in Fourier series, so we shall need the norm
of Pl(x) in expanding functions in Legendre series. We shall prove that
(8.1)
 1
−1
[Pl(x)]2 dx =
2
2l + 1.
Then the functions

(2l + 1)/2 Pl(x) are an orthonormal set of functions on (−1, 1).
To prove (8.1), we use the recursion relation (5.8b), namely,
(8.2)
lPl(x) = xP ′
l (x) −P ′
l−1(x).
Multiply (8.2) by Pl(x) and integrate to get
(8.3)
l
 1
−1
[Pl(x)]2 dx =
 1
−1
xPl(x)P ′
l (x) dx −
 1
−1
Pl(x)P ′
l−1(x) dx.
The last integral is zero by Problem 7.4. To evaluate the middle integral in (8.3),
we integrate by parts:
 1
−1
xPl(x)P ′
l (x) dx = x
2 [Pl(x)]2
1
−1 −1
2
 1
−1
[Pl(x)]2 dx
= 1 −1
2
 1
−1
[Pl(x)]2 dx
(see Problem 2.2). Then (8.3) gives
l
 1
−1
[Pl(x)]2 dx = 1 −1
2
 1
−1
[Pl(x)]2 dx

580
Series Solutions of Differential Equations
Chapter 12
which simpliﬁes to (8.1). We can combine (7.1) and (8.1) to write
(8.4)
 1
−1
Pl(x)Pm(x) dx =
2
2l + 1 δlm.
PROBLEMS, SECTION 8
Find the norm of each of the following functions on the given interval and state the
normalized function.
1.
cos nx
on (0, π)
2.
P2(x)
on (−1, 1)
3.
xe−x/2
on (0, ∞)
4.
e−x2/2
on (−∞, ∞)
5.
xe−x2/2
on (0, ∞)
Hint: See Chapter 4, Section 12.
6.
Give another proof of (8.1) as follows. Multiply (5.8e) by Pl(x) and integrate from
−1 to 1. To evaluate the middle term, integrate by parts. Then use Problem 7.4.
7.
Using (8.1), write the ﬁrst four normalized Legendre polynomials and compare with
the answers we found by a diﬀerent method in Chapter 3, Section 14, Example 6.
9. LEGENDRE SERIES
Since the Legendre polynomials form a complete orthogonal set on (−1, 1), we can
expand functions in Legendre series just as we expanded functions in Fourier series.
Example 1.
Expand in a Legendre series the function f(x) given by
(9.1)
f(x) =

0,
−1 < x < 0,
1,
0 < x < 1,
Figure 9.1
(see Figure 9.1). We put
(9.2)
f(x) =
∞

l=0
clPl(x).
Our problem is to ﬁnd the coeﬃcients cl. We do this by a method parallel to the one
we used in ﬁnding the formulas for the coeﬃcients in a Fourier series. We multiply
both sides of (9.2) by Pm(x) and integrate from −1 to 1. Because the Legendre
polynomials are orthogonal, all the integrals on the right are zero except the one
containing cm, and we can evaluate it by (8.1). Thus we get
(9.3)
 1
−1
f(x)Pm(x) dx =
∞

l=0
cl
 1
−1
Pl(x)Pm(x) dx = cm ·
2
2m + 1.

Section 9
Legendre Series
581
Using this result in our example (9.1), we ﬁnd
 1
−1
f(x)P0(x) dx = c0
 1
−1
[P0(x)]2 dx
or
 1
0
dx = c0 · 2,
c0 = 1
2;
 1
−1
f(x)P1(x) dx = c1
 1
−1
[P1(x)]2 dx
or
 1
0
x dx = c1 · 2
3,
c1 = 3
4;
 1
−1
f(x)P2(x) dx = c2
 1
−1
[P2(x)]2 dx
or
 1
0
( 3
2x2 −1
2) dx = c2 · 2
5,
c2 = 0.
Continuing in this way we ﬁnd for the function given in (9.1)
(9.4)
f(x) = 1
2P0(x) + 3
4P1(x) −7
16P3(x) + 11
32P5(x) + · · · .
It is unnecessary for f(x) to be continuous as it must be for expansion in a
Maclaurin series. Just as for Fourier series, the Dirichlet conditions (see Chapter 7,
Section 6) are a convenient set of suﬃcient conditions for a function f(x) to be
expandable in a Legendre series. If f(x) satisﬁes the Dirichlet conditions on (−1, 1),
then at points inside (−1, 1) (not necessarily at the endpoints), the Legendre series
converges to f(x) anywhere f(x) is continuous and converges to the midpoint of
the jump at discontinuities.
Example 2.
Here is an interesting fact about Legendre series. Sometimes we want to ﬁt
a given curve as closely as possible by a polynomial of a given degree, say a cubic.
The criterion of “Least Squares” is often used to determine the best ﬁt. This means
that if, say, we want to ﬁt a given f(x) on (−1, 1) by a cubic, we ﬁnd the coeﬃcients
a, b, c, d so that
(9.5)
 1
−1
[f(x) −(ax3 + bx2 + cx + d)]2 dx
is as small as possible. Then
(9.6)
f(x) ∼= ax3 + bx2 + cx + d
is called the best approximation (by a cubic) in the least squares sense. It can
be proved that an expansion (as far as the desired degree of the polynomial ap-
proximation) in Legendre polynomials gives this best least squares approximation
(Problem 16).
PROBLEMS, SECTION 9
Expand the following functions in Legendre series.
1.
f(x) =
(
−1,
−1 < x < 0
1,
0 < x < 1
2.
f(x) =
(
0,
−1 < x < 0
x,
0 < x < 1
3.
f(x) = P ′
3(x)
4.
f(x) = arc sin x
5.

582
Series Solutions of Differential Equations
Chapter 12
6.
f(x) =
(
0
on (−1, 0)
`
ln 1
x
´2
on (0, 1)
Hint: See Chapter 11, Section 3, Problem 13.
7.
f(x) =
(
0
on (−1, 0)
√1 −x
on (0, 1)
Hint: See Chapter 11, Sections 6 and 7.
8.
Hint: Solve the recursion relation (5.8e) for Pl(x) and show that
Z 1
a
Pl(x) dx =
1
2l + 1[Pl−1(a) −Pl+1(a)].
9.
f(x) = P ′
n(x).
Hint: For l ≥n,
R 1
−1 P ′
n(x)Pl(x) dx = 0 (Why?); for l < n, integrate
by parts.
Expand each of the following polynomials in a Legendre series. You should get the same
results that you got by a diﬀerent method in the corresponding problems in Section 5.
10.
3x2 + x −1
11.
7x4 −3x + 1
12.
x −x3
Find the best (in the least squares sense) second-degree polynomial approximation to each
of the given functions over the interval −1 < x < 1. (See Problem 16.)
13.
x4
14.
|x|
15.
cos πx
16.
Prove the least squares approximation property of Legendre polynomials [see (9.5)
and (9.6)] as follows. Let f(x) be the given function to be approximated. Let the
functions pl(x) be the normalized Legendre polynomials, that is,
pl(x) =
r
2l + 1
2
Pl(x)
so that
Z 1
−1
[pl(x)]2 dx = 1.
Show that the Legendre series for f(x) as far as the p2(x) term is
f(x) = c0p0(x) + c1p1(x) + c2p2(x)
with
cl =
Z 1
−1
f(x)pl(x) dx.
Write the quadratic polynomial satisfying the least squares condition as b0p0(x) +
b1p1(x) + b2p2(x) (by Problem 5.14 any quadratic polynomial can be written in this
form). The problem is to ﬁnd b0, b1, b2 so that
I =
Z 1
−1
[f(x) −(b0p0(x) + b1p1(x) + b2p2(x))]2 dx
is a minimum. Square the bracket and write I as a sum of integrals of the individual
terms. Show that some of the integrals are zero by orthogonality, some are 1 because
the pl’s are normalized, and others are equal to the coeﬃcients cl. Add and subtract
c2
0 + c2
1 + c2
2 and show that
I =
Z 1
−1
[f 2(x) + (b0 −c0)2 + (b1 −c1)2 + (b2 −c2)2 −c2
0 −c2
1 −c2
2] dx.
Now determine the values of the b’s to make I as small as possible. (Hint: The
smallest value the square of a real number can have is zero.) Generalize the proof
to polynomials of degree n.

Section 10
The Associated Legendre Functions
583
10. THE ASSOCIATED LEGENDRE FUNCTIONS
A diﬀerential equation closely related to the Legendre equation is
(10.1)
(1 −x2)y′′ −2xy′ +
	
l(l + 1) −
m2
1 −x2

y = 0
with m2 ≤l2. We could solve this equation by series; however, it is more useful
to know how the solutions are related to Legendre polynomials, so we shall simply
verify the known solution. First we substitute
(10.2)
y = (1 −x2)m/2u
into (10.1) and obtain (Problem 1)
(10.3)
(1 −x2)u′′ −2(m + 1)xu′ + [l(l + 1) −m(m + 1)]u = 0.
For m = 0, this is Legendre’s equation with solutions Pl(x). Diﬀerentiate (10.3),
obtaining (Problem 1)
(10.4)
(1 −x2)(u′)′′ −2[(m + 1) + 1]x(u′)′ + [l(l + 1) −(m + 1)(m + 2)]u′ = 0.
But this is just (10.3) with u′ in place of u, and (m + 1) in place of m. In other
words, if Pl(x) is a solution of (10.3) with m = 0, P ′
l (x) is a solution of (10.3) with
m = 1, P ′′
l (x) is a solution with m = 2, and in general for integral m, 0 ≤m ≤l,
(dm/dxm)Pl(x) is a solution of (10.3). Then
(10.5)
y = (1 −x2)m/2 dm
dxm Pl(x)
is a solution of (10.1). The functions in (10.5) are called associated Legendre func-
tions are are denoted by
(10.6)
P m
l (x) = (1 −x2)m/2 dm
dxm Pl(x)
Associated Legendre functions
[Some authors include a factor (−1)m in the deﬁnition of P m
l (x).]
A negative value for m in (10.1) does not change m2, so a solution of (10.1)
for positive m is also a solution for the corresponding negative m.
Thus many
references deﬁne P m
l (x) for −l ≤m ≤l as equal to P |m|
l
(x). Alternatively, we may
use Rodrigues’ formula (4.1) for Pl(x) in (10.6) to get
(10.7)
P m
l (x) =
1
2ll!(1 −x2)m/2 d l+m
dxl+m (x2 −1)l.
It can be shown that (10.7) is a solution of (10.1) for either positive or nega-
tive m; however P −m
l
(x) and P m
l (x) are then proportional rather than equal (see
Problem 8).

584
Series Solutions of Differential Equations
Chapter 12
For each m, the functions P m
l (x) are a set of orthogonal functions on (−1, 1)
(Problem 3). The normalization constants can be evaluated; for the deﬁnition (10.7)
we ﬁnd (Problem 10)
(10.8)
 1
−1
[P m
l (x)]2 dx =
2
2l + 1
(l + m)!
(l −m)!.
The associated Legendre functions arise in many of the same problems in which
Legendre polynomials appear (see the ﬁrst paragraph of Section 2); in fact, the
Legendre polynomials are just the special case of the functions P m
l (x) when m = 0.
PROBLEMS, SECTION 10
1.
Verify equations (10.3) and (10.4).
2.
The equation for the associated Legendre functions (and for Legendre functions
when m = 0) usually arises in the form (see, for example, Chapter 13, Section 7)
1
sin θ
d
dθ
„
sin θ dy
dθ
«
+
»
l(l + 1) −
m2
sin2 θ
–
y = 0.
Make the change of variable x = cos θ, and obtain (10.1).
3.
Show that the functions P m
l (x) for each m are a set of orthogonal functions on
(-1,1), that is, show that
Z 1
−1
P m
l (x)P m
n (x) dx = 0,
l ̸= n.
Hint: Use the diﬀerential equations (10.1) and follow the method of Section 7.
Substitute the Pl(x) you found in Problems 4.3 or 5.3 into equation (10.6) to ﬁnd P m
l (x);
then let x = cos θ to evaluate:
4.
P 1
1 (cos θ)
5.
P 1
4 (cos θ)
6.
P 2
3 (cos θ)
7.
Show that
d l−m
dxl−m (x2 −1)l = (l −m)!
(l + m)!(x2 −1)m d l+m
dxl+m (x2 −1)l.
Hint: Write (x2 −1)l = (x −1)l(x + 1)l and ﬁnd the derivatives by Leibniz’ rule.
8.
Write (10.7) with m replaced by −m; then use Problem 7 to show that
P −m
l
(x) = (−1)m (l −m)!
(l + m)!P m
l (x).
Comment: This shows that (10.7) is a solution of (10.1) when m is negative.
9.
Use Problem 7 to show that
P m
l (x) = (−1)m (l + m)!
(l −m)!
(1 −x2)−m/2
2ll!
d l−m
dxl−m (x2 −1)l.
10.
Derive (10.8) as follows: Multiply together the two formulas for P m
l (x) given in
(10.7) and Problem 9. Then integrate by parts repeatedly lowering the l+m deriva-
tive and raising the l −m derivative until both are l derivatives. Then use (8.1).

Section 11
Generalized Power Series or the Method of Frobenius
585
11. GENERALIZED POWER SERIES OR THE METHOD OF FROBENIUS
It may happen that the solution of a diﬀerential equation is not a power series
∞
n=0 anxn but may either
(a) contain some negative powers of x, for example,
y = cos x
x2
= 1
x2 −1
2! + x2
4! −· · ·
or
(b) have a fractional power of x as a factor, for example,
y = √x sin x = x1/2

x −x3
3! + · · ·

.
Both these cases (and others—see Section 21) are covered by a series of the form
(11.1)
y = xs
∞

n=0
anxn =
∞

n=0
anxn+s,
where s is a number to be found to ﬁt the problem; it may be either positive or
negative and it may be a fraction. (In fact, it may even be complex, but we shall
not consider this case.) Since a0xs is to be the ﬁrst term of the series, we assume
that a0 is not zero. The series (11.1) is called a generalized power series. We shall
consider some diﬀerential equations which can be solved by assuming a series of
the form (11.1); this way of solving diﬀerential equations is called the method of
Frobenius.
Example 1.
As an illustration of this method we solve the equation
(11.2)
x2y′′ + 4xy′ + (x2 + 2)y = 0.
From (11.1) we have
(11.3)
y = a0xs + a1xs+1 + a2xs+2 + · · · =
∞

n=0
anxn+s,
y′ = sa0xs−1 + (s + 1)a1xs + (s + 2)a2xs+1 + · · ·
=
∞

n=0
(n + s)anxn+s−1,
y′′ = s(s −1)a0xs−2 + (s + 1)sa1xs−1 + (s + 2)(s + 1)a2xs + · · ·
=
∞

n=0
(n + s)(n + s −1)anxn+s−2.
We substitute (11.3) into (11.2) and set up a table of powers of x as we did for the
Legendre equation:
xs
xs+1
xs+2
· · ·
xn+s
x2y′′
s(s −1)a0
(s + 1)sa1
(s + 2)(s + 1)a2
(n + s)(n + s −1)an
4xy′
4sa0
4(s + 1)a1
2(s + 2)a2
4(n + s)an
x2y
a0
an−2
2y
2a0
2a1
2a2
2an

586
Series Solutions of Differential Equations
Chapter 12
The total coeﬃcient of each power of x must be zero. From the coeﬃcient of xs we
get (s2 + 3s + 2)a0 = 0, or since a0 ̸= 0 by hypothesis,
(11.4)
s2 + 3s + 2 = 0.
This equation for s is called the indicial equation. We solve it and ﬁnd
s = −2,
s = −1.
From here on we solve two separate problems, one when s = −2, and another when
s = −1; a linear combination of the two solutions so obtained is then the general
solution just as A sin x + B cos x is the general solution of y′′ + y = 0.
Example 2.
For s = −1, the coeﬃcient of xs+1 in the table gives a1 = 0. From the
xs+2 column on, we can use the general formula given by the last column. Notice,
however, that the ﬁrst two columns in the table do not contain the an−2 term, so
you must be careful about using the general term at ﬁrst (Problems 13 and 14).
From the general column with s = −1, we have
an[(n −1)(n + 2) + 2] = −an−2
or
an =
−an−2
n(n + 1)
for n ≥2.
Since a1 = 0, this gives all odd a’s equal to zero. For even a’s:
(11.5)
a2 = −a0
3! ,
a4 = a0
5! ,
a6 = −a0
7! ,
· · · .
Then one solution of (11.2) is
(11.6)
y = a0x−1 −a0
3! x + a0
5! x3 −· · ·
= a0x−2

x −x3
3! + x5
5! −· · ·

= a0 sin x
x2
.
The other solution, when s = −2, will be left to Problem 1.
PROBLEMS, SECTION 11
1.
Finish the solution of equation (11.2) when s = −2. Write your solution in closed
form as in (11.6). To avoid confusion with the an values we found when s = −1, you
may want to call the coeﬃcients in your series a′
n or bn; however, this is not essential
as long as you realize that there are two separate problems, one when s = −1 and
one when s = −2, and each series has its own coeﬃcients.
Solve the following diﬀerential equations by the method of Frobenius (generalized power
series). Remember that the point of doing these problems is to learn about the method
(which we will use later), not just to ﬁnd a solution. You may recognize some series [as
we did in (11.6)] or you can check your series by expanding a computer answer.
2.
x2y′′ + xy′ −9y = 0
3.
x2y′′ + 2xy′ −6y = 0
4.
x2y′′ −6y = 0
5.
2xy′′ + y′ + 2y = 0
6.
3xy′′ + (3x + 1)y′ + y = 0
7.
x2y′′ −(x2 + 2)y = 0
8.
x2y′′ + 2x2y′ −2y = 0
9.
xy′′ −y′ + 9x5y = 0
10.
2xy′′ −y′ + 2y = 0
11.
36x2y′′ + (5 −9x2)y = 0

Section 12
Bessel’s Equation
587
12.
3xy′′ −2(3x −1)y′ + (3x −2)y = 0
Consider each of the following problems as illustrations showing that, in a power series
solution, we must be cautious about using the general recursion relation between the
coeﬃcients for the ﬁrst few terms of the series.
13.
Solve y′′ + y′/x2 = 0 by power series to ﬁnd the relation
an+1 = −n(n −1)
n + 1
an.
If, without thinking carefully, we test the series P∞
n=0 anxn for convergence by the
ratio test, we ﬁnd
lim
n→∞
|an+1xn+1|
|anxn|
= ∞.
(Show this.)
Thus we might conclude that the series diverges and that there is no power series
solution of this equation. Show why this is wrong, and that the power series solution
is y = const.
14.
Solve y′′ = −y by the Frobenius method. You should ﬁnd that the roots of the
indicial equation are s = 0 and s = 1. The value s = 0 leads to the solutions cos x
and sin x as you would expect. For s = 1, call the series y = P∞
n=0 bnxn+1, and ﬁnd
the relation
bn+2 = −
bn
(n + 3)(n + 2).
Show that the b0 series obtained from this relation is just sin x, but that the b1 series
is not a solution of the diﬀerential equation. What is wrong?
12. BESSEL’S EQUATION
Like Legendre’s equation, Bessel’s equation is another of the “named” equations
which have been studied extensively. There are whole books on Bessel functions,
and you will ﬁnd numerous formulas, graphs, and numerical values available in
your computer program and in reference tables. You can think of Bessel functions
as being something like damped sines and cosines. In fact, if you had ﬁrst learned
about sin nx and cos nx as power series solutions of y′′ = −n2y instead of in ele-
mentary trigonometry, you would not feel that Bessel functions were appreciably
more diﬃcult or strange than trigonometric functions. Like sines and cosines, Bessel
functions are solutions of a diﬀerential equation; they can be represented by power
series, their graphs can be drawn, and many formulas involving them (compare
trigonometric identities) are known. Of special interest to science students is the
fact that they occur in many applications. The following list of some of the prob-
lems in which they arise will give you an idea of the great range of topics which
may involve Bessel functions: problems in electricity, heat, hydrodynamics, elas-
ticity, wave motion, quantum mechanics, etc., involving cylindrical symmetry (for
this reason Bessel functions are sometimes called cylinder functions); the motion
of a pendulum whose length increases steadily; the small oscillations of a ﬂexible
chain; railway transition curves; the stability of a vertical wire or beam; Fresnel
integrals in optics; the current distribution in a conductor; Fourier series for the arc
of a circle. We shall discuss some of these applications later (see Section 18, and
Chapter 13, Sections 5 and 6).

588
Series Solutions of Differential Equations
Chapter 12
Bessel’s equation in the usual standard form is
(12.1)
x2y′′ + xy′ + (x2 −p2)y = 0,
where p is a constant (not necessarily an integer) called the order of the Bessel func-
tion y which is the solution of (12.1). You can easily verify that x(xy′)′ = x2y′′+xy′,
so we can write (12.1) in the simpler form
(12.2)
x(xy′)′ + (x2 −p2)y = 0.
We ﬁnd a generalized power series for (12.2) in the same way that we solved (11.2).
[In fact, (11.2) is a form of Bessel’s equation! See Problems 16.1 and 17.1.] Writing
only the general terms in the series for y and the derivatives we need in (12.2), we
have
(12.3)
y =
∞

n=0
anxn+s
y′ =
∞

n=0
an(n + s)xn+s−1
xy′ =
∞

n=0
an(n + s)xn+s
(xy′)′ =
∞

n=0
an(n + s)2xn+s−1
x(xy′)′ =
∞

n=0
an(n + s)2xn+s
We substitute (12.3) into (12.2) and tabulate the coeﬃcients of powers of x:
xs
xs+1
xs+2
· · ·
xs+n
x(xy′)′
s2a0
(1 + s)2a1
(2 + s)2a2
(n + s)2an
x2y
a0
an−2
−p2y
−p2a0
−p2a1
−p2a2
−p2an
The coeﬃcient of xs gives the indicial equation and the values of s:
s2 −p2 = 0,
s = ±p.
The coeﬃcient of xs+1 gives a1 = 0. The coeﬃcient of xs+2 gives a2 in terms of a0,
etc., but we may as well write the general formula from the last column at this
point. We get
[(n + s)2 −p2]an + an−2 = 0
or
(12.4)
an = −
an−2
(n + s)2 −p2 .

Section 12
Bessel’s Equation
589
First we shall ﬁnd the coeﬃcients for the case s = p. From (12.4) we have
(12.5)
an = −
an−2
(n + p)2 −p2 = −
an−2
n2 + 2np = −
an−2
n(n + 2p).
Since a1 = 0, all odd a’s are zero. For even a’s it is convenient to replace n by 2n;
then from (12.5) we have
(12.6)
a2n = −
a2n−2
2n(2n + 2p) = −
a2n−2
22n(n + p).
The formulas for the coeﬃcients can be simpliﬁed by the use of the Γ function
notation (Chapter 11, Sections 2 to 5) as you can see by examining (12.7) below.
Recall that Γ(p + 1) = pΓ(p) for any p, so,
Γ(p + 2) = (p + 1)Γ(p + 1),
Γ(p + 3) = (p + 2)Γ(p + 2) = (p + 2)(p + 1)Γ(p + 1),
and so on. Then from (12.6) we ﬁnd
(12.7)
a2 = −
a0
22(1 + p) = −a0Γ(1 + p)
22Γ(2 + p),
a4 = −
a2
23(2 + p) =
a0
2!24(1 + p)(2 + p) = a0Γ(1 + p)
2!24Γ(3 + p),
a6 = −
a4
3!2(3 + p) = −
a0
3!26(1 + p)(2 + p)(3 + p)
= −a0Γ(1 + p)
3!26Γ(4 + p),
and so on. Then the series solution (for the s = p case) is
(12.8)
y = a0xpΓ(1 + p)
	
1
Γ(1 + p) −
1
Γ(2 + p)
x
2
2
+
1
2!Γ(3 + p)
x
2
4
−
1
3!Γ(4 + p)
x
2
6
+ · · ·

= a02p x
2
p
Γ(1 + p)
	
1
Γ(1)Γ(1 + p) −
1
Γ(2)Γ(2 + p)
x
2
2
+
1
Γ(3)Γ(3 + p)
x
2
4
−
1
Γ(4)Γ(4 + p)
x
2
6
+ · · ·

.
We have inserted Γ(1) and Γ(2) (which are both equal to 1) in the ﬁrst two terms
and written xp = 2p(x/2)p to make the series appear more systematic. If we take
a0 =
1
2pΓ(1 + p)
or
1
2pp!,
then y is called the Bessel function of the ﬁrst kind of order p, and written Jp(x).

590
Series Solutions of Differential Equations
Chapter 12
(12.9)
Jp(x) =
1
Γ(1)Γ(1 + p)
x
2
p
−
1
Γ(2)Γ(2 + p)
x
2
2+p
+
1
Γ(3)Γ(3 + p)
x
2
4+p
−
1
Γ(4)Γ(4 + p)
x
2
6+p
+ · · ·
=
∞

n=0
(−1)n
Γ(n + 1)Γ(n + 1 + p)
x
2
2n+p
.
PROBLEMS, SECTION 12
1.
Show by the ratio test that the inﬁnite series (12.9) for Jp(x) converges for all x.
Use (12.9) to show that:
2.
J2(x) = (2/x)J1(x) −J0(x)
3.
J1(x) + J3(x) = (4/x)J2(x)
4.
(d/dx)J0(x) = −J1(x)
5.
(d/dx)[xJ1(x)] = xJ0(x)
6.
J0(x) −J2(x) = 2(d/dx)J1(x)
7.
lim
x→0 J1(x)/x = 1
2
8.
lim
x→0 x−3/2J3/2(x) = 3−1p
2/π
Hint:
See Chapter 11, equations (3.4) and (5.3).
9.
p
πx/2 J1/2(x) = sin x
13. THE SECOND SOLUTION OF BESSEL’S EQUATION
We have found just one of the two solutions of Bessel’s equation, that is, the one
when s = p; we must next ﬁnd the solution when s = −p. It is unnecessary to
go through the details again; we can just replace p by −p in (12.9). In fact, the
solution when s = −p is usually written J−p. From (12.9) we have
(13.1)
J−p(x) =
∞

n=0
(−1)n
Γ(n + 1)Γ(n −p + 1)
x
2
2n−p
If p is not an integer, Jp(x) is a series starting with xp and J−p is a series starting
with x−p.
Then Jp(x) and J−p(x) are two independent solutions and a linear
combination of them is a general solution. But if p is an integer, then the ﬁrst few
terms in J−p are zero because Γ(n −p + 1) in the denominator is Γ of a negative
integer, which is inﬁnite. You can show (Problem 2) that J−p(x) starts with the
term xp (for integral p) just as Jp(x) does, and that
(13.2)
J−p(x) = (−1)pJp(x)
for integral p;
thus J−p(x) is not an independent solution when p is an integer. The second solution
in this case is not a Frobenius series (11.1) but contains a logarithm. Jp(x) is ﬁnite
at the origin, but the second solution is inﬁnite and so is useful only in applications
involving regions not containing the origin.
Although J−p(x) is a satisfactory second solution when p is not an integer, it is
customary to use a linear combination of Jp(x) and J−p(x) as the second solution.

Section 14
Graphs and Zeros of Bessel Functions
591
This is much as if sin x and (2 sin x −3 cosx) were used as the two solutions of
y′′ + y = 0 instead of sin x and cos x.
Remember that the general solution of
this diﬀerential equation is a linear combination of sin x and cos x with arbitrary
coeﬃcients. But A sin x+B(2 sin x−3 cos x) is just as good a linear combination as
c1 sin x + c2 cos x. Similarly, any combination of Jp(x) and J−p(x) is a satisfactory
second solution of Bessel’s equation. The combination which is used is called either
the Neumann or the Weber function and is denoted by either Np or Yp:
(13.3)
Np(x) = Yp(x) = cos(πp)Jp(x) −J−p(x)
sin πp
.
For integral p this expression is an indeterminate form 0/0. However, for any x ̸= 0
it has a limit (as p tends to an integral value) which gives a second solution. This is
why the special form (13.3) is used; it is valid for any p. Np or Yp are called Bessel
functions of the second kind. The general solution of Bessel’s equation (12.1) or
(12.2) may then be written as
(13.4)
y = AJp(x) + BNp(x),
where A and B are arbitrary constants.
PROBLEMS, SECTION 13
1.
Using equations (12.9) and (13.1), write out the ﬁrst few terms of J0(x), J1(x),
J−1(x), J2(x), J−2(x). Show that J−1(x) = −J1(x) and J−2(x) = J2(x).
2.
Show that, in general for integral n, J−n(x) = (−1)nJn(x), and Jn(−x) = (−1)nJn(x).
Use equations (12.9) and (13.1) to show that:
3.
p
πx/2 J−1/2(x) = cos x
4.
J3/2(x) = x−1J1/2(x) −J−1/2(x).
5.
Using equation (13.3), show that N1/2(x) = −J−1/2(x); that N3/2(x) = J−3/2(x).
6.
Show from (13.3) that N(2n+1)/2(x) = (−1)n+1J−(2n+1)/2(x).
14. GRAPHS AND ZEROS OF BESSEL FUNCTIONS
You can ﬁnd the values of Bessel functions both from your computer program and
in reference books, and you can use your computer to plot graphs of Bessel functions
(see problems). Except for J0(x), all the Jp’s start at the origin behaving like xp
and then oscillate something like sin x but with decreasing amplitude. J0(x) is equal
to 1 at x = 0 and so looks something like a damped cosine. All the N’s are ±∞at
the origin, but away from it they also oscillate with decreasing amplitude.
The values of x for which sin x = 0 (called the zeros for sin x) do not need to be
computed because they are just x = nπ for n = 0, 1, 2, · · ·. The zeros of the Bessel
functions, however, do not occur at regular intervals; they have to be computed
numerically. You can ﬁnd their values by computer or in tables. It is worth noticing
that the diﬀerence between two successive zeros becomes approximately π (as it is
for sin x and cos x) when x is large. You can see this from graphs of the functions or
from tables of the zeros, or from the approximate formulas for the Bessel functions
when x is large. (See Section 20).

592
Series Solutions of Differential Equations
Chapter 12
PROBLEMS, SECTION 14
1.
By computer, plot graphs of Jp(x) for p = 0, 1, 2, 3, and x from 0 to 15.
2.
From the graphs in Problem 1, read approximate values of the ﬁrst three zeros of
each of the functions. Then, by computer, ﬁnd more accurate values of the zeros.
3.
By computer, plot N0(x) for x from 0 to 15, and Np(x) for p = 1, 2, 3, and x from
1 to 15.
4.
From the graphs in Problem 3, read approximate values of the ﬁrst three zeros of
each of the functions, and then ﬁnd more accurate values by computer.
5.
By computer, plot √x J1/2(x) for x from 0 to 4π. Do you recognize the curve? See
Problem 12.9.
6.
By computer, ﬁnd 30 zeros of J0 and note that the spacing between consecutive
zeros is tending to π.
15. RECURSION RELATIONS
The following useful relations hold among Bessel functions and their derivatives.
Although we state them and outline proofs for Jp(x), they also hold for Np(x).
d
dx[xpJp(x)] = xpJp−1(x),
(15.1)
d
dx[x−pJp(x)] = −x−pJp+1(x),
(15.2)
Jp−1(x) + Jp+1(x) = 2p
x Jp(x),
(15.3)
Jp−1(x) −Jp+1(x) = 2J′
p(x),
(15.4)
J′
p(x) = −p
xJp(x) + Jp−1(x) = p
xJp(x) −Jp+1(x).
(15.5)
To prove (15.1), ﬁrst multiply (12.9) by xp and diﬀerentiate to get
d
dx[xpJp(x)] = d
dx
∞

n=0
(−1)n
Γ(n + 1)Γ(n + 1 + p)
x2n+2p
22n+p
=
∞

n=0
(−1)n(2n + 2p)
Γ(n + 1)Γ(n + 1 + p)
x2n+2p−1
22n+p
.
Use the fact that Γ(n+1+p) = (n+p)Γ(n+p), and cancel the factors 2 and (n+p)
to get
d
dx[xpJp(x)] =
∞

n=0
(−1)n
Γ(n + 1)Γ(n + p)
x2x+2p−1
22n+p−1 .
Divide by xp and compare with (12.9); this gives
1
xp
d
dx[xpJp(x)] =
∞

n=0
(−1)n
Γ(n + 1)Γ(n + p)
x
2
2n+p−1
= Jp−1(x),
since this series is just (12.9) with p replaced by p −1. Proofs of the other relations
are outlined in Problems 1 to 3.

Section 16
Differential Equations with Bessel Function Solutions
593
PROBLEMS, SECTION 15
1.
Prove equation (15.2) by a method similar to the one used above to prove (15.1).
2.
Solve equations (15.1) and (15.2) for Jp+1(x) and Jp−1(x). Add and subtract these
two equations to get (15.3) and (15.4).
3.
Carry out the diﬀerentiation in equations (15.1) and (15.2) to get (15.5).
4.
Use equations (15.1) to (15.5) to do Problems 12.2 to 12.6.
5.
Using equations (15.4) and (15.5), show that J0(x) = J2(x) at every maximum or
minimum of J1(x), and J0(x) = −J2(x) = J′
1(x) at every positive zero of J1(x).
Computer plot J0(x), J1(x), and J2(x) on the same axes, and verify that these
results are true.
6.
As in Problem 5, show that Jp−1(x) = Jp+1(x) at every maximum or minimum of
Jp(x), and Jp−1(x) = −Jp+1(x) = J′
p(x) at every positive zero of Jp(x). Computer
plot, say, J2, J3, and J4 on the same axes, (or any other set of three consecutive J’s
or three consecutive N’s) and check to see that the results are true.
7.
(a)
Using (15.2), show that
Z ∞
0
J1(x) dx = −J0(x)|∞
0 = 1.
(b)
Use L23 of the Laplace Transform Table (page 469) to
show that
R ∞
0
J0(t) dt = 1. (Also see Problem 23.29.)
8.
From equation (15.4), show that
Z ∞
0
J1(x) dx =
Z ∞
0
J3(x) dx = · · · =
Z ∞
0
J2n+1(x) dx,
and
Z ∞
0
J0(x) dx =
Z ∞
0
J2(x) dx = · · · =
Z ∞
0
J2n(x) dx.
Then, by Problem 7, show that
Z ∞
0
Jn(x) dx = 1
for all integral n.
9.
Use L23 and L32 of the Laplace Transform Table (page 469) to
evaluate
R ∞
0
tJ0(2t)e−t dt.
16. DIFFERENTIAL EQUATIONS WITH BESSEL FUNCTION SOLUTIONS
Many diﬀerential equations occur in practice that are not of the standard form
(12.1) but whose solutions can be written in terms of Bessel functions. It can be
shown (Problem 13) that the diﬀerential equation
(16.1)
y′′ + 1 −2a
x
y′ +
	
(bcxc−1)2 + a2 −p2c2
x2

y = 0
has the solution
(16.2)
y = xaZp(bxc),

594
Series Solutions of Differential Equations
Chapter 12
where Z stands for J or N or any linear combination of them, and a, b, c, p are
constants. To see how to use this, let us “solve” the diﬀerential equation
(16.3)
y′′ + 9xy = 0.
If (16.3) is of the type (16.1), then we must have
1 −2a = 0,
(bc)2 = 9,
2(c −1) = 1,
a2 −p2c2 = 0.
From these equations we ﬁnd
a = 1
2,
c = 3
2,
b = 2,
p = a
c = 1
3.
Then the solution of (16.3) is
(16.4)
y = x1/2Z1/3(2x3/2).
This means that the general solution of (16.3) is
y = x1/2[AJ1/3(2x3/2) + BN1/3(2x3/2)],
where A and B are arbitrary constants.
It is useful to write the diﬀerential equation whose solutions are Jp(Kx) and
Np(Kx), where K is a constant. We substitute Kx for x in (12.2). Then x(dy/dx)
becomes Kx[dy/d(Kx)] = x(dy/dx) and similarly, x(xy′)′ is unchanged. Thus the
only change in (12.2) is to replace x2 −p2 by K2x2 −p2 and we have:
(16.5)
x(xy′)′ + (K2x2 −p2)y = 0
has solutions Jp(Kx) and Np(Kx).
PROBLEMS, SECTION 16
Find the solutions of the following diﬀerential equations in terms of Bessel functions by
using equations (16.1) and (16.2).
1.
Equation (11.2)
2.
y′′ + 4x2y = 0
3.
xy′′ + 2y′ + 4y = 0
4.
3xy′′ + 2y′ + 12y = 0
5.
y′′ −1
xy′ +
„
4 + 1
x2
«
y = 0
6.
4xy′′ + y = 0
7.
xy′′ + 3y′ + x3y = 0
8.
y′′ + xy = 0
9.
3xy′′ + y′ + 12y = 0
10.
xy′′ −y′ + 9x2y = 0
11.
xy′′ + 5y′ + xy = 0
12.
4xy′′ + 2y′ + y = 0
13.
Verify by direct substitution that the text solution of equation (16.3) and your
solutions in the problems above are correct. Also prove in general that the solution
(16.2) given for (16.1) is correct. Hint:
These are exercises in partial diﬀerentiation.
To verify the solution (16.4) of (16.3), we would change variables from x, y to say
z, u where
y = x1/2u,
u = J1/3(z),
z = 2x3/2,
and show that if x, y satisfy (16.3), then u, z satisfy (12.1), that is,
z2 d2u
dz2 + z du
dz + (z2 −1
9)u = 0.

Section 17
Other Kinds of Bessel Functions
595
Use (16.5) to write the solutions of the following problems. Remember that
x(xy′)′ = x2y′′ + xy′.
14.
x2y′′ + xy′ + (4x2 −9)y = 0
15.
x(xy′)′ + (25x2 −4)y = 0
16.
x2y′′ + xy′ + (16x2 −1)y = 0
17.
xy′′ + y′ + 9xy = 0
17. OTHER KINDS OF BESSEL FUNCTIONS
We have discussed Jp(x) and Np(x) which are called Bessel functions of the ﬁrst
and second kinds, respectively. Since Bessel’s equation is of second order, there
are, of course, only two independent solutions. However, there are a number of
related functions which are also called Bessel functions. Here again there is a close
analogy to sines and cosines. We may think of cos x and sin x as the solutions of
y′′ + y = 0. But cos x ± i sin x are also solutions which we usually write as e±ix. If
we replace x by ix, we get the functions ex, e−x, cosh x, sinh x, which are solutions
of y′′ −y = 0. We list a number of Bessel functions which are frequently used and
their trigonometric analogues:
Hankel Functions or Bessel Functions of the Third Kind
(17.1)
H(1)
p (x) = Jp(x) + iNp(x),
H(2)
p (x) = Jp(x) −iNp(x).
(Compare e±ix = cos x ± i sin x.)
Modiﬁed or Hyperbolic Bessel Functions
The solutions of
(17.2)
x2y′′ + xy′ −(x2 + p2)y = 0
are, by (16.1) Zp(ix). (Compare this with the standard Bessel equation and by
analogy consider the relation between y′′ + y = 0 and y′′ −y = 0.)
The two
independent solutions of (17.2) which are ordinarily used are
(17.3)
Ip(x) = i−pJp(ix),
Kp(x) = π
2 ip+1H(1)
p (ix).
These should be compared with sinh x = −i sin(ix) and cosh x = cos(ix); because
of the analogy, I and K are called hyperbolic Bessel functions. The i factors are
adjusted to make I and K real for real x.

596
Series Solutions of Differential Equations
Chapter 12
Spherical Bessel Functions
If p = (2n + 1)/2 = n + 1
2, n an integer, then
Jp(x) and Np(x) are called Bessel functions of half-odd integral order; they can be
expressed in terms of sin x, cos x, and powers of x. The spherical Bessel functions
are closely related to them as you can see from the formulas (17.4) below. Spherical
Bessel functions arise in a variety of vibration problems especially when spheri-
cal coordinates are used. We deﬁne the spherical Bessel functions jn(x), yn(x),
h(1)
n (x), h(2)
n (x), for n = 0, 1, 2, · · ·, and state their values in terms of elementary
functions (see Problems 2 and 3). For the use of these functions, see Chapter 13,
Problems 7.15, 7.16, 7.19, and 10.20.
(17.4)
jn(x) =
 π
2x J(2n+1)/2(x) = xn

−1
x
d
dx
n sin x
x

,
yn(x) =
 π
2x Y(2n+1)/2(x) = −xn

−1
x
d
dx
n cos x
x

,
h(1)
n
= jn(x) + iyn(x),
h(2)
n
= jn(x) −iyn(x).
The Kelvin Functions
A standard method of solving vibration problems is to as-
sume a solution involving eiωt; the resulting equation may contain imaginary terms.
As an example, the following equation arises in the problem of the distribution of
alternating current in wires (skin eﬀect) (Relton, p. 177):
(17.5)
y′′ + 1
xy′ −iy = 0.
The solution of this equation is (Problem 8a)
(17.6)
y = Z0(i3/2x).
This is complex, and it is customary to separate it into its real and imaginary parts,
called (for Z = J) ber and bei; these stand for Bessel-real and Bessel-imaginary.
We deﬁne the ber, bei, ker, kei functions by
(17.7)
J0(i3/2x) = ber x + i bei x,
K0(i1/2x) = ker x + i kei x.
There are also similar functions for n ̸= 0. These functions occur in problems in
heat ﬂow and in the theory of viscous ﬂuids, as well in electrical engineering.
The Airy Functions
The Airy diﬀerential equation is
(17.8)
y′′ −xy = 0.
By Section 16, the solutions are (Problem 8b)
(17.9)
√x Z1/3( 2
3ix3/2),

Section 17
Other Kinds of Bessel Functions
597
so by (17.3) they can be written in terms of I1/3 and K1/3. The Airy functions are
deﬁned as
(17.10)
Ai(x) = 1
π
x
3 K1/3

2
3x3/2
,
Bi(x) =
x
3

I−1/3

2
3x3/2
+ I1/3

2
3x3/2
.
For negative x, Ai and Bi can be expressed in terms of J1/3 and N1/3, or the Hankel
functions (17.1) of order 1/3. Airy functions are of use in electrodynamics and
quantum mechanics.
PROBLEMS, SECTION 17
1.
Write the solutions of Problem 16.1 as spherical Bessel functions using the deﬁnitions
(17.4) of jn(x) and yn(x) in terms of J(2n+1)/2(x) and Y(2n+1)/2(x). Then, using
(17.4), obtain the solutions in terms of sin x and cos x. Compare with the answers
in equation (11.6) and Problem 11.1.
2.
From Problem 12.9, J1/2(x) =
p
2/πx sin x.
Use (15.2) to obtain J3/2(x) and
J5/2(x). Substitute your results for the J’s into (17.4) to verify the formulas stated
for j0, j1, and j2 in terms of sin x and cos x.
3.
From Problems 13.3 and 13.5, Y1/2(x) = −
p
2/πx cos x. As in Problem 2, obtain
Y3/2 and Y5/2 and verify the formulas (17.4) for y0, y1, and y2 in terms of sin x and
cos x.
4.
Using (17.3) and the results stated in Problems 2 and 3 for J1/2 and Y1/2 (= N1/2),
show that
I1/2(x) =
r
2
πx sinh x,
and
K1/2(x) =
r
π
2x e−x.
5.
Show from (17.4) that h(1)
n (x) = −ixn
„
−1
x
d
dx
«n „eix
x
«
.
6.
Using (16.1) and (17.4) show that the spherical Bessel functions satisfy the diﬀer-
ential equation
x2y′′ + 2xy′ + [x2 −n(n + 1)]y = 0.
7.
(a)
Solve the diﬀerential equation xy′′ = y using (16.1), and then express the
answer in terms of a function Ip by (17.3).
(b)
As in (a), ﬁnd a solution of of y′′ −x4y = 0.
8.
Using (16.1) and (16.2), verify that
(a)
the solution of (17.5) is (17.6);
(b)
the solution of (17.8) is (17.9).
9.
Using (17.3) and (15.1) to (15.5), ﬁnd the recursion relations for Ip(x). In particular,
show that I′
0 = I1.
10.
Computer plot
(a)
I0(x), I1(x), I2(x), from x = 0 to 2.
(b)
K0(x), K1(x), K2(x), from x = 0.1 to 2.
(c)
Ai(x) from x = −10 to 10.

598
Series Solutions of Differential Equations
Chapter 12
(d)
Bi(x) from x = −10 to 1.
11.
From (17.4), show that h(1)
0 (ix) = −e−x/x.
Use the Section 15 recursion relations and (17.4) to obtain the following recursion relations
for spherical Bessel functions. We have written them for jn, but they are valid for yn and
for the hn’s.
12.
jn−1(x) + jn+1(x) = (2n + 1)jn(x)/x 13.
(d/dx)jn(x) = njn(x)/x −jn+1(x)
14.
(d/dx)jn(x) = jn−1(x) −(n + 1)jn(x)/x
15.
(d/dx)[xn+1jn(x)] = xn+1jn−1(x)
16.
(d/dx)[x−njn(x)] = −x−njn+1(x)
18. THE LENGTHENING PENDULUM
As an example of the use of Bessel functions we consider the following problem.
Suppose that a simple pendulum (see Chapter 11, Section 8) has the length l of
its string increased at a steady rate (for example, a weight swaying as it is lowered
by a crane). (This problem was considered as early as 1707; see L. LeCornu, Acta
Mathematica 19 (1895), 201–249.
Also see Relton, and Problem 8.)
Find the
equation of motion and the solution for small oscillations.
From Chapter 11, Section 8, we have the equation of motion
(18.1)
d
dt(ml2 ˙θ) + mgl sin θ = 0.
Let the length of the string at time t be
(18.2)
l = l0 + vt,
and change from t to l as the independent variable. For small oscillations, we may
replace sin θ by θ. Then (18.1) becomes (Problem 1):
(18.3)
ld2θ
dl2 + 2dθ
dl + g
v2 θ = 0.
(This equation could also describe the damped vibration of a variable mass, or an
RLC circuit with variable L.)
We solve (18.3) by comparing it with the standard equation (16.1) to get (Prob-
lem 2)
(18.4)
θ = l−1/2Z1(bl1/2)
where b = 2g1/2/v.
To simplify the notation, let
(18.5)
u = b l1/2 = (2g1/2/v)l1/2.
The general solution of (18.3) is then
(18.6)
θ = Au−1J1(u) + Bu−1N1(u).
We can ﬁnd dθ/du from (18.6) using (15.2):
(18.7)
dθ
du = −[Au−1J2(u) + Bu−1N2(u)].

Section 18
The Lengthening Pendulum
599
The constants A and B must be found from the starting conditions just as they
are for the ordinary simple pendulum with constant l. For example, in the ordinary
case, if θ = θ0 and ˙θ = 0 at t = 0, then the general solution θ = A cos ωt + B sin ωt
becomes just θ = θ0 cos ωt.
For the lengthening pendulum, let’s take the same
simple initial conditions, namely θ = θ0 and ˙θ = 0 at t = 0.
For these initial
conditions, we ﬁnd (after some calculations—see Problems 3 to 6)
(18.8)
A = −πu2
0
2
θ0N2(u0),
B = πu2
0
2
θ0J2(u0).
The solution has a particularly simple form if we adjust the constants v and l0 so
that
(18.9)
u0 = 2(gl0)1/2/v
is a zero of J2(u).
Then B = 0 and the second term of (18.6) is zero, so we have
(18.10)
θ = Au−1J1(u) = Cl−1/2J1(b l1/2),
where (Problem 7)
(18.11)
b = 2g1/2
v
= u0
l1/2
0
,
C = θ0l1/2
0
J1(u0).
For this simple case, ˙θ is a multiple of J2(u) (Problem 8); thus θ = 0 corresponds
to zeros of J1(u) and ˙θ = 0 corresponds to zeros of J2(u). A “quarter” period
corresponds to the time from θ = 0 to ˙θ = 0, or ˙θ = 0 to θ = 0. These quarter
periods can be found from the zeros of J1(u) and J2(u) (Problem 8).
PROBLEMS, SECTION 18
1.
Verify equation (18.3). Hint: From equation (18.2), dl = v dt, so
d
dt = v d
dl.
2.
Solve equation (18.3) to get equation (18.4).
3.
Prove
Jp(x)J′
−p(x) −J−p(x)J′
p(x) = −2
πx sin pπ
as follows: Write Bessel’s equation (12.1) with y = Jp and with y = J−p; multiply
the Jp equation by J−p and the J−p equation by Jp and subtract to get
d
dx[x(JpJ′
−p −J−pJ′
p)] = 0.
Then JpJ′
−p −J−pJ′
p = c/x. To ﬁnd c, use equation (12.9) for each of the four
functions and pick out the 1/x terms in the products. Then use equation (5.4) of
Chapter 11.
4.
Using equation (13.3) and Problem 3, show that
Jp(x)N ′
p(x) −J′
p(x)Np(x) = J′
p(x)J−p(x) −Jp(x)J′
−p(x)
sin pπ
= 2
πx.

600
Series Solutions of Differential Equations
Chapter 12
5.
Use the recursion relations of Section 15 (for N’s as well as for J’s) and Problem 4
to show that
Jn(x)Nn+1(x) −Jn+1(x)Nn(x) = −2
πx.
Hint: Do it ﬁrst for n = 0; then use the result in proving the n = 1 case, and so on.
6.
For the initial conditions θ = θ0, ˙θ = 0, show that the constants A and B in
equations (18.6) and (18.7) are as given in (18.8). Hints: Show that dθ/du = 0 if
˙θ = 0. In equations (18.6) and (18.7), set θ = θ0 and dθ/du = 0 when u = u0 and
solve for A and B. Then use the formula in Problem 5 to simplify your results to
get equation (18.8).
7.
Verify the values of b and C given in equation (18.11). Note that C can be found in
two ways: (1) in equation (18.10), u = bl1/2, so Au−1 = (A/b)l−1/2, C = A/b. Use
Problem 5 to simplify this. (2) Set θ = θ0, u = u0, l = l0 in equation (18.10) and
solve for C.
8.
Find
˙θ = dθ
dt = dθ
du
du
dl
dl
dt
either from equations (18.10) and (15.2) or from equation (18.7) with B = 0. Thus
show that θ = 0 when J1(u) = 0 and ˙θ = 0 when J2(u) = 0.
Show that the
successive (variable) quarter periods of the lengthening pendulum are (v/4g)(r2
2−r2
1)
or (v/4g)(r2
1 −r2
2), where r1 and r2 are successive zeros of J1 and J2. Use a computer
or tables to ﬁnd the needed zeros and calculate several quarter periods (as multiples
of v/(4g)). Observe that an inward swing takes longer than either the preceding or
the following outward swing. [This result is proved by Ll. G. Chambers, Proceedings
of the Edinburgh Mathematical Society (2) 12, 17–18 (1960).]
9.
Consider the “shortening pendulum” problem. Follow the method in the text but
with l = l0 −vt. Does the θ amplitude of the vibration increase or decrease as the
pendulum shortens? Restate the result of Problem 8 about quarter periods for this
case.
10.
The diﬀerential equation for transverse vibrations of a string whose density increases
linearly from one end to the other is
y′′ + (Ax + B)y = 0, where A and B are
constants. Find the general solution of this equation in terms of Bessel functions.
Hint: Make the change of variable Ax + B = Au.
11.
A straight wire clamped vertically at its lower end stands vertically if it is short, but
bends under its own weight if it is long. It can be shown that the greatest length
for vertical equilibrium is l, where kl3/2 is the ﬁrst zero of J−1/3 and
k =
4
3r2
r
ρg
πY ,
r = radius of the wire, ρ = linear density, g = acceleration of gravity, Y = Young’s
modulus. Find l for a steel wire of radius 1 mm; for a lead wire of the same radius.

Section 19
Orthogonality of Bessel Functions
601
19. ORTHOGONALITY OF BESSEL FUNCTIONS
You may expect here that we are going to prove that two Jp’s for diﬀerent p values
are orthogonal. However, this is not what we are going to do—as a matter of fact
it isn’t true! To see what we are going to prove, look at the following comparison
between Bessel functions and sines and cosines.
(19.1)
Two functions: sin x and cos x.
Two functions for each p:
Jp(x) and Np(x).
Consider just sin x.
Consider just Jp(x) for one
value of p.
At the zeros of sin x, namely,
x = nπ,
sin x = 0.
At the zeros of Jp(x), say
x = α, β, · · · ,
Jp(x) = 0.
At x = 1,
sin nπx = 0.
At x = 1,
Jp(αx) = 0,
Jp(βx) = 0, · · ·.
The diﬀerential equation satisﬁed
by y = sin nπx is
y′′ + (nπ)2y = 0.
The diﬀerential equation satisﬁed
by y = Jp(αx) is [see (16.5)]
x(xy′)′ + (α2x2 −p2)y = 0.
(In comparing the diﬀerential equations remember that p is a ﬁxed
constant. The correspondence is between the zeros of sin x, namely
nπ, and the zeros of Jp(x), namely, α, β, etc.)
We have proved (Chapter 7):
 1
0
sin nπx sin mπx dx = 0
for n ̸= m.
We shall prove:
 1
0
xJp(αx)Jp(βx) dx = 0
for α ̸= β.
By (16.5), the diﬀerential equation satisﬁed by Jp(αx) is
(19.2)
x(xy′)′ + (α2x2 −p2)y = 0
and the diﬀerential equation satisﬁed by Jp(βx) is
(19.3)
x(xy′)′ + (β2x2 −p2)y = 0.
Let us for simplicity call Jp(αx) = u and Jp(βx) = v; then (19.2) and (19.3) become
(19.4)
x(xu′)′ + (α2x2 −p2)u = 0,
x(xv′)′ + (β2x2 −p2)v = 0.
We are going to use equations (19.4) to prove the last equation in (19.1) by a
method parallel to that used in proving the orthogonality of Legendre polynomials
(Section 7). Multiply the ﬁrst equation of (19.4) by v, the second by u, subtract
the two equations and cancel an x to get
(19.5)
v(xu′)′ −u(xv′)′ + (α2 −β2)xuv = 0.
The ﬁrst two terms of (19.5) are equal to
(19.6)
d
dx(vxu′ −uxv′).

602
Series Solutions of Differential Equations
Chapter 12
Using (19.6) and integrating (19.5), we get
(19.7)
(vxu′ −uxv′)

1
0
+ (α2 −β2)
 1
0
xuv dx = 0.
At the lower limit the integrated term is zero because x = 0 and u, v, u′, v′ are
ﬁnite. To evaluate the integrated term at the upper limit, recall that u = Jp(αx),
v = Jp(βx); then at x = 1, u = Jp(α) = 0, v = Jp(β) = 0 since α and β are zeros
of Jp. The integrated term is therefore zero at the upper limit also. Thus (19.7)
becomes
(19.8)
(α2 −β2)
 1
0
xuv dx = 0
or
(19.9)
(α2 −β2)
 1
0
xJp(αx)Jp(βx) dx = 0.
If α ̸= β, that is, if α and β are diﬀerent zeros of Jp, the integral must be zero.
If α = β, the integral is not zero; it can be evaluated, but we shall just state the
answer (see Problem 1):
(19.10)
 1
0
xJp(αx)Jp(βx) dx =

0
if α ̸= β,
1
2J2
p+1(α) = 1
2J2
p−1(α) = 1
2J′
p
2(α)
if α = β,
where α and β are zeros of Jp(x).
[You can see that the three answers for the case α = β are equal by equations (15.3)
to (15.5), remembering that α is a zero of Jp.]
We can state (19.10) in words in two diﬀerent ways; if αn, n = 1, 2, 3, · · ·, are
the zeros of Jp(x), then we say either that
(a) the functions √xJp(αnx) are orthogonal on (0, 1);
or that
(b) the functions Jp(αnx) are orthogonal on (0, 1) with respect to the weight
function x.
You may meet other sets of functions which are orthogonal with respect to a
weight function. (See, for example, Section 22.) In general, we say that yn(x) is a
set of orthogonal functions on (x1, x2) with respect to the weight function w(x) if
 x2
x1
yn(x)ym(x)w(x) dx = 0
for
n ̸= m.
The fact that the Bessel functions Jp(αnx) obey (19.10) makes it possible to
expand a given function in a series of Bessel functions much as we expand functions
in Fourier series and Legendre series. We shall do this later (Chapter 13) when we
need it in a physical example.
Just as we generalized Fourier series to an interval (0, l), here we can generalize
(19.10) to an interval (0, a). In (19.10), let x = r/a. Then the limits are x = r/a =
0 to 1, that is, r = 0 to a. The integral in (19.10) becomes
 a
0
(r/a)Jp(αr/a)Jp(βr/a) d(r/a) = 1
a2
 a
0
rJp(αr/a)Jp(βr/a) dr.

Section 20
Orthogonality of Bessel Functions
603
Thus we have
(19.11)
 a
0
rJp(αr/a)Jp(βr/a) dr
=

0
if α ̸= β,
a2
2 J2
p+1(α) = a2
2 J2
p−1(α) = a2
2 J′
p
2(α)
if α = β.
PROBLEMS, SECTION 19
1.
Prove equation (19.10) in the following way. First note that (19.2) and (19.3) and
therefore (19.7) hold whether α and β are zeros of Jp(x) or not. Let α be a zero,
but let β be just any number. From (19.7) show that then
Z 1
0
xuv dx = Jp(β)αJ′
p(α)
β2 −α2
.
Now let β →α and evaluate the indeterminate form by L’Hˆopital’s rule (that is,
diﬀerentiate numerator and denominator with respect to β and let β →α). Hence
ﬁnd
Z 1
0
xuv dx = 1
2J′
p
2(α)
for α = β, that is, for u = v = Jp(αx) as in (19.10). Use equations (15.3) to (15.5)
to show that the other two expressions given in (19.10) are equivalent.
2.
Given that
J3/2(x) =
r
2
πx
„sin x
x
−cos x
«
,
use (19.10) to evaluate
Z 1
0
„sin αx
αx
−cos αx
«2
dx
where α is a root of the equation tan x = x.
3.
Use (17.4) and (19.10) to write the orthogonality condition and the normalization
integral for the spherical Bessel functions jn(x).
4.
Deﬁne Jp(z) for complex z by the power series (12.9) with x replaced by z. (By
Problem 12.1, the series converges for all z.) Show by (19.10) that all the zeros of
Jp(z) are real. Hint: Suppose α and β in (19.10) were a complex conjugate pair;
show that then the integrand would be positive so the integral could not be zero.
5.
We obtained (19.10) for Jp(x), p ≥0. It is, however, valid for p > −1, that is for
Np(x), 0 ≤p < 1. The diﬃculty in the proof occurs just after (19.7); we said that
u, v, u′, v′ are ﬁnite at x = 0 which is not true for Np(x). However, the negative
powers of x cancel if p < 1. Show this for p = 1
2 by using two terms of the power
series (12.9) or (13.1) for the function N1/2(x) = −J−1/2(x) [see (13.3)].
6.
By Problem 5,
R 1
0 xN1/2(αx)N1/2(βx) dx = 0 if α and β are diﬀerent zeros of
N1/2(x). Using (17.4), ﬁnd N1/2(x) in terms of cos x and so ﬁnd the zeros of N1/2(x).
Show that the functions cos(n + 1
2)πx are an orthogonal set on (0, 1). Use (19.10)
to ﬁnd the normalization constant. (Compare Problem 6.8.)

604
Series Solutions of Differential Equations
Chapter 12
20. APPROXIMATE FORMULAS FOR BESSEL FUNCTIONS
There are often cases in which it is useful to have an approximate formula giving
the behavior of a Bessel function when x is near zero or when x is very large. We
list some of these formulas here for reference. The symbol O(xn) is read “terms of
the order of xn or less,” and means that the error in the given approximation is less
than a constant times xn; thus O(1) means bounded terms. Note that p ≥0.
Function
Small x
Large x (asymptotic formulas)
Jp(x)
1
Γ(p + 1)
x
2
p
+ O(xp+2)

2
πx cos

x −2p + 1
4
π

+ O(x−3/2)
Np(x)











p = 0
2
π ln x + O(1)
p > 0
−Γ(p)
π
 2
x
p
+





O(xp),
p < 1
O(x ln 1
x),
p = 1
O(x2−p),
p > 1

2
πx sin

x −2p + 1
4
π

+ O(x−3/2)
H(1) or (2)
p
(x)
Like ±iNp(x)

2
πx e±i[x−(2p+1)π/4] + O(x−3/2)
Ip(x)
Like Jp(x)
1
√
2πx ex + O
ex
x

Kp(x)
Like −π
2 Np(x)
 π
2x e−x + O
e−x
x

jn(x)
xn
(2n + 1)!! + O(xn+2)
1
x sin

x −nπ
2

+ O(x−2)
yn(x)
−(2n −1)!!
xn+1
+ O(x1−n)
−1
x cos

x −nπ
2

+ O(x−2)
Note: (2n+1)!! means 1·3·5·7 · · ·(2n+1) = (2n + 1)!
2nn!
. See Chapter 1, Section 13C.
PROBLEMS, SECTION 20
Use the table above to evaluate the following limits:
1.
lim
x→0 J4(x)/[J2(x)]2
2.
lim
x→∞I3(x)/I5(x)
3.
lim
x→0 N0(x2)/ ln(x)
4.
lim
x→0 Jp(x)/Np(x)
5.
lim
x→∞xIp(x)Kp(x)
6.
lim
x→0 xjn(x)yn(x)
Use the table above and the deﬁnitions in Section 17 to ﬁnd approximate formulas for
large x for:
7.
h(1)
n (x)
8.
h(2)
n (x)
9.
h(1)
n (ix)
10.
h(2)
n (ix)

Section 21
Series Solutions; Fuchs’s Theorem
605
To study the approximations in the table, computer plot on the same axes the given
function together with its small x approximation and its asymptotic approximation. Use
an interval large enough to show the asymptotic approximation agreeing with the function
for large x. If the small x approximation is not clear, plot it alone with the function over
a small interval.
11.
J1(x)
12.
J2(x)
13.
J3(x)
14.
N2(x)
15.
N3(x)
16.
j1(x)
17.
j2(x)
18.
y2(x)
19.
Computer plot on the same axes several Ip(x) functions together with their com-
mon asymptotic approximation. Then computer plot each function with its small x
approximation.
20.
As in Problem 19, study the Kp(x) functions. It is interesting to note (see Prob-
lem 17.4) that K1/2(x) is equal to the asymptotic approximation.
21. SERIES SOLUTIONS; FUCHS’S THEOREM
We have discussed two examples of diﬀerential equations solvable by the Frobenius
method (Legendre and Bessel equations). There are many other “named” equations
and the corresponding “named” functions which are their solutions. (See a few
more examples in Section 22.) All of them have much in common with our two
examples and you should not hesitate to look them up and use them without a
formal introduction when you run into them on your computer or in a text or
reference book. You may discover any or all of the following things about such a
new (to you) set of functions: that they are the set of solutions of a diﬀerential
equation with one or more parameters (like the p in Bessel’s equation); that the
values of the functions, their derivatives, their zeros, and many formulas involving
them are available in references (tables and computer); that they have orthogonality
properties, perhaps with respect to a weight function, and consequently (suitably
restricted) functions can be expanded in series of them; that there is a generating
function for the set of functions; that there are physical problems whose solutions
involve the functions, often in the solution of a partial diﬀerential equation; etc.
Now you may wonder whether all diﬀerential equations can be solved by the
Frobenius method. A general theorem due to Fuchs tells when this method will
work; we shall state it for second-order diﬀerential equations which are the most
important ones in applications. Write the diﬀerential equation as
(21.1)
y′′ + f(x)y′ + g(x)y = 0.
If xf(x) and x2g(x) are expandable in convergent power series ∞
n=0 anxn, we say
that the diﬀerential equation (21.1) is regular (or has a nonessential singularity) at
the origin. Let us call these the Fuchsian conditions. Fuchs’s theorem says that
these conditions are necessary and suﬃcient for the general solution of (21.1) to
consist of either
(1) two Frobenius series, or
(2) one solution S1(x) which is a Frobenius series, and a second solution which
is S1(x) ln x + S2(x) where S2(x) is another Frobenius series.

606
Series Solutions of Differential Equations
Chapter 12
Case (2) occurs only when the roots of the indicial equation are equal or diﬀer
by an integer, and not always then. [See, for example, equation (11.2) and Problems
11.1 to 11.4, and 11.7 to 11.9.] Note the necessary condition: If the Fuchsian condi-
tions are not met, we cannot ﬁnd the general solution by the method of generalized
power series (see Problems 11 to 13). However, the equations most commonly found
in applications do meet these conditions.
If the ﬁrst Frobenius series S1(x) happens to break oﬀ, or you can easily write
its sum in closed form, then the method of “reduction of order” [Chapter 8, Sec-
tion 7(e)] gives a way of ﬁnding the second solution without using inﬁnite series
(see Problems 1 to 4). However, note that our main interest in series solutions is
not to solve diﬀerential equations this way in general, but to study sets of functions
(like Legendre polynomials and Bessel functions) which are solutions of diﬀerential
equations that occur in applications. So the purpose in using series to solve a few
simple diﬀerential equations (for which there are easier methods) is to learn how and
when the series method works—to watch Fuchs’s theorem in action (see problems).
PROBLEMS, SECTION 21
For Problems 1 to 4, ﬁnd one (simple) solution of each diﬀerential equation by series, and
then ﬁnd the second solution by the “reduction of order” method, Chapter 8, Section 7(e).
1.
(x2 + 1)y′′ −xy′ + y = 0
2.
x2y′′ + (x + 1)y′ −y = 0
3.
x2y′′ + x2y′ −2y = 0
4.
(x −1)y′′ −xy′ + y = 0
Solve the diﬀerential equations in Problems 5 to 10 by the Frobenius method; observe
that you get only one solution. (Note, also, that the two values of s are equal or diﬀer
by an integer, and in the latter case the larger s gives the one solution.) Show that the
conditions of Fuchs’s theorem are satisﬁed. Knowing that the second solution is ln x times
the solution you have, plus another Frobenius series, ﬁnd the second solution.
5.
x(x + 1)y′′ −(x −1)y′ + y = 0
6.
4x2(x + 1)y′′ −4x2y′ + (3x + 1)y = 0
7.
x(x −1)2y′′ −2y = 0
8.
xy′′ + xy′ −2y = 0
9.
x2y′′ + (x2 −3x)y′ + (4 −2x)y = 0
10.
x2(x−1)y′′−x(5x−4)y′+(9x−6)y = 0
11.
For the diﬀerential equation in Problem 2, verify that it does not satisfy the Fuchsian
conditions, and that your second solution cannot be expanded in a Frobenius series.
12.
Verify that the diﬀerential equation x4y′′ + y = 0 is not Fuchsian; that it has the
two independent solutions x sin(1/x) and x cos(1/x); and that these solutions are
not expandable in Frobenius series.
13.
Verify that the the diﬀerential equation in Problem 11.13 is not Fuchsian. Solve
it by separation of variables to ﬁnd the obvious solution y = const. and a second
solution in the form of an integral. Show that the second solution is not expandable
in a Frobenius series.

Section 22
Hermite Functions; Laguerre Functions; Ladder Operators
607
22. HERMITE FUNCTIONS; LAGUERRE FUNCTIONS; LADDER OPERATORS
In this section, we shall outline some of the important formulas for two more sets of
named functions. Both Hermite and Laguerre functions are of interest in quantum
mechanics where they arise as solutions of eigenvalue problems (see Problem 27,
and Chapter 13, Problems 7.20 to 7.22). We shall also consider an operator method
which is a useful alternative to series solution for some diﬀerential equations.
Hermite Functions
The diﬀerential equation for Hermite functions is
(22.1)
y′′
n −x2yn = −(2n + 1)yn,
n = 0, 1, 2, · · · .
This equation can be solved by power series (Problem 5), but here we shall consider
an operator method which is particularly eﬃcient for this equation. Let’s use the
operator D to mean d/dx; then (see Problem 5.31 of Chapter 8)
(22.2)
(D −x)(D + x)y =
 d
dx −x

(y′ + xy) = y′′ −x2y + y,
and similarly
(D + x)(D −x)y = y′′ −x2y −y.
Using (22.2), we can write (22.1) in two ways:
(D −x)(D + x)yn = −2nyn
or
(22.3)
(D + x)(D −x)yn = −2(n + 1)yn.
(22.4)
Now let us operate on (22.3) with (D + x) and on (22.4) with (D −x), and change
n to m for later convenience:
(D + x)(D −x)[(D + x)ym] = −2m[(D + x)ym],
(22.5)
(D −x)(D + x)[(D −x)ym] = −2(m + 1)[(D −x)ym].
(22.6)
(The brackets have been inserted to clarify our next step.)
Now compare (22.3) and (22.6); if yn = [(D−x)ym] and n = m+1, the equations
are identical. We write
(22.7)
ym+1 = (D −x)ym
and we see that, given a solution ym of (22.1) for one value of n, namely n = m, we
can ﬁnd a solution when n = m + 1 by applying the “raising operator” (D −x) to
ym. Similarly, from (22.4) and (22.5), we ﬁnd that (Problem 1)
(22.8)
ym−1 = (D + x)ym.
We may call (D + x) a “lowering operator”; these operators are called creation and
annihilation operators in quantum theory. Operators of this kind (see Problems 29,
30, and 23.27 for other examples) are called ladder operators since, like the rungs
of a ladder, they enable us to go up or down in a set of functions.
Now if n = 0, we ﬁnd a solution of (22.3) [and therefore of (22.1)] by requiring
(22.9)
(D + x)y0 = 0.

608
Series Solutions of Differential Equations
Chapter 12
We solve this equation (Problem 2) to get
(22.10)
y0 = e−x2/2.
Then, by (22.7), yn = (D −x)ne−x2/2. These are the Hermite functions; they can
be written in the simpler form yn = ex2/2(dn/dxn)e−x2 (Problem 3):
(22.11)
yn = (D −x)ne−x2/2
or
yn = ex2/2(dn/dxn)e−x2.
Hermite functions
If we multiply (22.11) by (−1)nex2/2, we obtain the Hermite polynomials; the fol-
lowing equation may be called a Rodrigues formula for them:
(22.12)
Hn(x) = (−1)nex2 dn
dxn e−x2.
Hermite polynomials
We ﬁnd (Problems 4 and 5):
(22.13)
H0(x) = 1,
H1(x) = 2x,
H2(x) = 4x2 −2.
The Hermite polynomials satisfy the diﬀerential equation (Problem 6):
(22.14)
y′′ −2xy′ + 2ny = 0.
Hermite equation
Using the diﬀerential equation, we can prove (Problem 7) that the Hermite poly-
nomials are orthogonal on (−∞, ∞) with respect to the weight function e−x2. The
normalization integral can be evaluated (Problem 10). Thus we have:
(22.15)
 ∞
−∞
e−x2Hn(x)Hm(x) dx =

0,
n ̸= m,
√π 2nn!
n = m.

Section 22
Hermite Functions; Laguerre Functions; Ladder Operators
609
The generating function for the Hermite polynomials is (Problem 8):
(22.16)
Φ(x, h) = e2xh−h2 =
∞

n=0
Hn(x)hn
n! .
The generating function can be used to derive recursion relations for the Hermite
polynomials. Two useful relations are (Problem 9):
(22.17)
(a)
H′
n(x) = 2nHn−1(x),
(b)
Hn+1(x) = 2xHn(x) −2nHn−1(x).
Laguerre functions
The Laguerre polynomials may be deﬁned by a Rodrigues
formula:
(22.18)
Ln(x) = 1
n!ex dn
dxn (xne−x).
Carrying out the diﬀerentiation (Problem 12), we ﬁnd:
(22.19)
Ln(x) = 1 −nx + n(n −1)
2!
x2
2! −n(n −1)(n −2)
3!
x3
3! + · · · + (−1)nxn
n!
=
n

m=0
(−1)m
n
m
xm
m! .
Laguerre polynomials
The symbol
 n
m

is a binomial coeﬃcient (see Chapter 1, Section 13C). Some au-
thors omit the 1/n! in (22.18); then the series in (22.19) is multiplied by n!. It
is convenient to note that the series in (22.19) is like the binomial expansion of
(1 −x)n except that each power of x, say xm, is divided by an extra m!. We ﬁnd
(Problem 13):
(22.20)
L0(x) = 1,
L1(x) = 1 −x,
L2(x) = 1 −2x + x2/2.
The Laguerre polynomials are solutions of the diﬀerential equation (Problems 14
and 15):
(22.21)
xy′′ + (1 −x)y′ + ny = 0,
y = Ln(x).

610
Series Solutions of Differential Equations
Chapter 12
Using the diﬀerential equation, we can prove (Problem 16) that the Laguerre
polynomials are orthogonal on (0, ∞) with respect to the weight function e−x. In
fact, we ﬁnd (Problem 19) that, with the deﬁnition (22.18), the functions e−x/2Ln(x)
are an orthonormal set on (0, ∞).
(22.22)
 ∞
0
e−xLn(x)Lk(x) dx = δnk =

0,
n ̸= k,
1,
n = k.
The generating function for the Laguerre polynomials is (Problem 17):
(22.23)
Φ(x, h) = e−xh/(1−h)
1 −h
=
∞

n=0
Ln(x)hn.
Using it, we can derive recursion relations; some examples are (Problem 18):
(22.24)
(a)
L′
n+1(x) −L′
n(x) + Ln(x) = 0,
(b)
(n + 1)Ln+1(x) −(2n + 1 −x)Ln(x) + nLn−1(x) = 0,
(c)
xL′
n(x) −nLn(x) + nLn−1(x) = 0.
Warning: These formulas will be diﬀerent if the factor 1/n! is omitted in the deﬁ-
nition (22.18), so check the notation of any reference you are using (computer, text,
tables).
Derivatives of the Laguerre polynomials are called associated Laguerre polyno-
mials; they may be found by diﬀerentiating (22.18), (22.19), or (22.20) (Problem 20).
We deﬁne:
(22.25)
Lk
n(x) = (−1)k dk
dxk Ln+k(x).
Associated Laguerre polynomials
Warning: The notation in various references may be confusing; some authors deﬁne
Lk
n(x) as (dk/dxk)Ln(x) [compare our deﬁnition in (22.25)], so read carefully the
deﬁnition in the reference you are using. For example, associated Laguerre poly-
nomials are used in the theory of the hydrogen atom in quantum mechanics. In
various references you will ﬁnd them denoted by L2l+1
n−l−1(x) and by L2l+1
n+l (x); both
these notations mean (except for sign) (d2l+1/dx2l+1)Ln+l(x). (See Problems 26
to 28.)
By diﬀerentiating the Laguerre equation (22.21), we ﬁnd the diﬀerential equation
satisﬁed by the polynomials Lk
n(x) (Problem 21):
(22.26)
xy′′ + (k + 1 −x)y′ + ny = 0,
y = Lk
n(x).

Section 22
Hermite Functions; Laguerre Functions; Ladder Operators
611
The polynomials Lk
n(x) may also be found from the Rodrigues formula (Prob-
lem 22):
(22.27)
Lk
n(x) = x−kex
n!
dn
dxn (xn+ke−x).
Note that in this form k does not have to be an integer; in fact, (22.27) is used to
deﬁne Lk
n(x) for any k > −1.
Recursion relations for the polynomials Lk
n(x) may be found by diﬀerentiating
recursion relations for the Laguerre polynomials. Some examples are (Problem 23):
(22.28)
(a)
(n + 1)Lk
n+1(x) −(2n + k + 1 −x)Lk
n(x) + (n + k)Lk
n−1(x) = 0,
(b)
x d
dxLk
n(x) −nLk
n(x) + (n + k)Lk
n−1(x) = 0.
Using the diﬀerential equation (22.26), we can show (Problem 24) that the func-
tions Lk
n(x) are orthogonal on (0, ∞) with respect to the weight function xke−x.
We ﬁnd (Problem 25):
(22.29)
 ∞
0
xke−xLk
n(x)Lk
m(x) dx =

0,
m ̸= n,
(n+k)!
n!
,
m = n.
The normalization integral needed in the theory of the hydrogen atom is not (22.29),
but instead has the factor xk+1. We ﬁnd (see Problems 25 to 27):
(22.30)
 ∞
0
xk+1e−x[Lk
n(x)]2 dx = (2n + k + 1)(n + k)!
n!
.
Again warning: The formulas (22.28), (22.29), and (22.30) will be diﬀerent in ref-
erences which omit the 1/n! in (22.18) and/or use a diﬀerent deﬁnition of Lk
n(x) in
(22.25).
PROBLEMS, SECTION 22
1.
Verify equations (22.2), (22.3), (22.4), and (22.8).
2.
Solve (22.9) to get (22.10). If needed, see Chapter 8, Section 2.
3.
Show that ex2/2D[e−x2/2f(x)] = (D −x)f(x). Now set
f(x) = (D −x)g(x) = ex2/2D[e−x2/2g(x)]
to get
(D −x)2g(x) = ex2/2D2[e−x2/2g(x)].
Continue this process to show that
(D −x)nF(x) = ex2/2Dn[e−x2/2F(x)]
for any F(x). Then let F(x) = e−x2/2 to get (22.11).

612
Series Solutions of Differential Equations
Chapter 12
4.
Using (22.12) ﬁnd the Hermite polynomials given in (22.13). Then use (22.17b) to
ﬁnd H3(x) and H4(x).
5.
By power series, solve the Hermite diﬀerential equation
y′′ −2xy′ + 2py = 0
You should ﬁnd an a0 series and an a1 series as for the Legendre equation in Section 2.
Show that the a0 series terminates when p is an even integer, and the a1 series
terminates when p is an odd integer. Thus for each integer n, the diﬀerential equation
(22.14) has one polynomial solution of degree n. These polynomials with a0 or a1
chosen so that the highest order term is (2x)n are the Hermite polynomials. Find
H0(x), H1(x), and H2(x).
Observe that you have solved an eigenvalue problem
(see end of Section 2), namely to ﬁnd values of p for which the given diﬀerential
equation has polynomial solutions, and then to ﬁnd the corresponding solutions
(eigenfunctions).
6.
Substitute yn = e−x2/2Hn(x) into (22.1) to show that the diﬀerential equation
satisﬁed by Hn(x) is (22.14).
7.
Prove that the functions Hn(x) are orthogonal on (−∞, ∞) with respect to the
weight function e−x2. Hint: Write the diﬀerential equation (22.14) as
ex2 d
dx(e−x2y′) + 2ny = 0,
and see Sections 7 and 19.
8.
In the generating function (22.16), expand the exponential in a power series and
collect powers of h to obtain the ﬁrst few Hermite polynomials. Verify the identity
∂2Φ
∂x2 −2x∂Φ
∂x + 2h∂Φ
∂h = 0.
Substitute the series in (22.16) into this identity to prove that the functions Hn(x)
in (22.16) satisfy equation (22.14). Verify that the highest term in Hn(x) in (22.16)
is (2x)n.
[You have then proved that the functions called Hn(x) are really the
Hermite polynomials since, by Problem 5, (22.14) has just one polynomial solution
of degree n.]
9.
Use the generating function to prove the recursion relations in (22.17). Hint for (a):
Diﬀerentiate (22.16) with respect to x and equate coeﬃcients of hn. Hint for (b):
Diﬀerentiate (22.16) with respect to h and equate coeﬃcients of hn.
10.
Evaluate the normalization integral in (22.15).
Hint: Use (22.12) for one of the
Hn(x) factors, integrate by parts, and use (22.17a); then use your result repeatedly.
11.
Show that we have solved the following eigenvalue problem (see Problem 5 and end
of Section 2): Given the diﬀerential equation y′′ + (ϵ −x2)y = 0 [compare equation
(22.1)]. ﬁnd the possible values of ϵ (eigenvalues) such that the solutions y(x) of the
given diﬀerential equation tend to zero as x →±∞; for these values of ϵ, ﬁnd the
eigenfunctions y(x). What is ϵ, and what are the eigenfunctions?
12.
Using Leibniz’ rule (Section 3), carry out the diﬀerentiation in (22.18) to obtain
(22.19).
13.
Using (22.19), verify (22.20) and also ﬁnd L3(x) and L4(x).
14.
Show that y = Ln(x) given in (22.18) satisﬁes (22.21). Hint: Follow a method similar
to that used in Section 4. Let v = xne−x and show that xv′ = (n−x)v. Diﬀerentiate
this last equation (n + 1) times by Leibniz’ rule, and use dnv/dxn = n! e−xLn(x)
from (22.18).

Section 22
Hermite Functions; Laguerre Functions; Ladder Operators
613
15.
Solve the Laguerre diﬀerential equation
xy′′ + (1 −x)y′ + py = 0
by power series. Show that the a0 series terminates if p is an integer. Thus for each
integer n, the diﬀerential equation (22.21) has one solution which is a polynomial
of degree n. These polynomials with a0 = 1 are the Laguerre polynomials Ln(x).
Find L0(x), L1(x), L2(x), and L3(x).
(This is an eigenvalue problem—compare
Problem 5 and Section 2.)
16.
Prove that the functions Ln(x) are orthogonal on (0, ∞) with respect to the weight
function e−x. Hint: Write the diﬀerential equation (22.21) as
ex d
dx(xe−xy′) + ny = 0,
and see Sections 7 and 19.
17.
In (22.23), write the series for the exponential and collect powers of h to verify the
ﬁrst few terms of the series. Verify the identity
x∂2Φ
∂x2 + (1 −x)∂Φ
∂x + h∂Φ
∂h = 0.
Substitute the series in (22.23) into this identity to show that the functions Ln(x)
in (22.23) satisfy Laguerre’s equation (22.21). Verify that the constant term is 1 by
putting x = 0 in the generating function. [You have then proved that the functions
called Ln(x) in (22.23) are really Laguerre polynomials since, by Problem 15, (22.21)
has just one polynomial solution of degree n.]
18.
Verify the recursion relations (22.24) as follows:
(a)
Diﬀerentiate (22.23) with respect to x to get hΦ = (h −1)(∂Φ/∂x); equate
coeﬃcients of hn+1.
(b)
Diﬀerentiate (22.23) with respect to h to get (1 −h)2(∂Φ/∂h) = (1 −h −x)Φ;
equate coeﬃcients of hn.
(c)
Combine (a) and (b) to get x(∂Φ/∂x) + hΦ −h(1 −h)∂Φ/∂h = 0. Substitute
the series for Φ and equate coeﬃcients of hn.
19.
Evaluate the normalization integral in (22.22).
Hint: Use (22.18) for one of the
Ln(x) factors; integrate by parts n times. Use (22.19) to ﬁnd (dn/dxn)Ln(x) and
Chapter 11, Section 3, to evaluate
R ∞
0
xne−x dx.
20.
Using (22.25), (22.20), and Problem 13, ﬁnd Lk
n(x) for n = 0, 1, 2, and k = 1, 2.
21.
Verify that the polynomials Lk
n(x) in (22.25) satisfy (22.26). Hint: Write (22.21)
with n replaced by n + k and diﬀerentiate k times by Leibniz’ rule.
22.
Verify that the polynomials given by (22.27) are the same as the Lk
n(x) deﬁned in
(22.25). Hints: Show that the functions in (22.27) satisfy (22.26) as follows. Let
v = e−xxn+k and show that xv′ = (n+k−x)v. (Compare Problem 14.) Diﬀerentiate
this equation n + 1 times by Leibniz’ rule, and use dnv/dxn = n! e−xxkLk
n(x) from
(22.27). Also show that the coeﬃcient of xn in both (22.25) and (22.27) is (−1)n/n!
[Thus, assuming that (22.26) for one k has only one polynomial solution of degree
n (which can be shown by series solution), (22.27) gives the same polynomials as
(22.25) for integral k.]

614
Series Solutions of Differential Equations
Chapter 12
23.
Verify the recursion relation relations (22.28) as follows:
(a)
In (22.24b), replace n by n + k and diﬀerentiate k times by Leibniz’ rule; in
(22.24a), replace k by n + k and diﬀerentiate k −1 times. Subtract k times
the second result from the ﬁrst.
(b)
In (22.24c), replace n by n + k and diﬀerentiate k times.
24.
Show that the functions Lk
n(x) are orthogonal on (0, ∞) with respect to the weight
function xke−x. Hint: Write the diﬀerential equation (22.26) as
x−kex d
dx(xk+1e−xy′) + ny = 0
and see Sections 7 and 19.
25.
Evaluate the normalization integrals (22.29) and (22.30).
Hints: Use (22.27) for
one of the Lk
n(x) factors in (22.29); integrate by parts n times. Use (22.25) and
then (22.19) to evaluate dn/dxnLk
n(x). Compare Problem 19. To evaluate (22.30),
multiply (22.28a) by xke−x and integrate; use (22.29) both for m ̸= n and m = n.
26.
Solve the following eigenvalue problem (see end of Section 2 and Problem 11): Given
the diﬀerential equation
y′′ +
„λ
x −1
4 −l(l + 1)
x2
«
y = 0
where l is an integer ≥0, ﬁnd values of λ such that y →0 as x →∞, and ﬁnd
the corresponding eigenfunctions. Hint: let y = xl+1e−x/2v(x), and show that v(x)
satisﬁes the diﬀerential equation
xv′′ + (2l + 2 −x)v′ + (λ −l −1)v = 0.
Compare (22.26) to show that if λ is an integer > l, there is a polynomial solution
v(x) = L2l+1
λ−l−1(x).
27.
The functions which are of interest in the theory of the hydrogen atom are
fn(x) = xl+1e−x/2nL2l+1
n−l−1
“x
n
”
where n and l are integers with 0 ≤l ≤n −1. (Note that here k = 2l + 1, and we
have replaced n by n −l −1; in this problem L3
2 , say, means l = 1, n = 4.) For
l = 1, show that
f2(x) = x2e−x/4,
f3(x) = x2e−x/6 “
4 −x
3
”
,
f4(x) = x2e−x/8
„
10 −5x
4 + x2
32
«
.
Hint: Find the polynomials L3
0, L3
1, L3
2 as in Problem 20 (with k = 3) and then
replace x by x/n.
The functions fn(x) are very diﬀerent from those in (22.29)
since x/n changes from one function to the next. However, it can be shown (Prob-
lem 23.25) that for one ﬁxed l, the set of functions fn(x), n ≥l + 1, is an orthogonal
set on (0, ∞).
Verify this for these three functions.
Hint:
The integrals are Γ
functions—see Chapter 11, Section 3.
28.
Repeat Problem 27 for l = 0, n = 1, 2, 3.
29.
Show that Rp = p
x −D and Lp = p
x + D where D = d/dx, are raising and lowering
operators for Bessel functions, that is, show that RpJp(x) = Jp+1(x) and LpJp(x) =
Jp−1(x). Hint: Use equations (15.5). Note that these operators depend on p as
well as x, so they are not as simple as the Hermite function raising and lowering
operators (22.7) and (22.8). If you want to operate, say, on Jp+1, you must change p
in R or L to p+1, etc. Making this adjustment, show that the equations LRJp = Jp
and RLJp = Jp both give Bessel’s equation.
30.
Find raising and lowering operators (see Problem 29) for spherical Bessel functions.
Hint: See problems 17.15 and 17.16.

Section 23
Miscellaneous Problems
615
23. MISCELLANEOUS PROBLEMS
1.
Use the generating function (5.1) to ﬁnd the normalizing factor for Legendre poly-
nomials. Hint: Square equation (5.2) with Φ as in (5.1) and integrate from −1 to 1.
Expand the integral of Φ2 (after integrating) in powers of h and equate coeﬃcients.
2.
Use the generating function to show that
P2n+1(0) = 0
and
P2n(0) =
 
−1/2
n
!
= (−1)n(2n −1)!!
2nn!
;
Hints: Expand (5.1) for x = 0 in powers of h and equate coeﬃcients of powers of h
in (5.2). See Chapter 1, Section 13C.
3.
Use (5.8e) to show that
R 1
0 Pl(x) dx = [Pl−1(0) −Pl+1(0)]/(2l + 1). Then use the
result of Problem 2 and Chapter 1, Section 13C to show that
Z 1
0
P2n(x) dx = 0, n > 0,
and
Z 1
0
P2n+1(x) dx = (−1)n(2n −1)!!
2n+1(n + 1)!
=
 
1/2
n + 1
!
.
4.
Obtain the binomial coeﬃcient result in Problem 3 directly by integrating the gen-
erating function from 0 to 1 and expanding the result in powers of h. Equate the
coeﬃcients of hl in the identity obtained by integrating (5.2) from 0 to 1, and use
Chapter 1, Section 13C.
5.
Show that Pn
0 (2l + 1)Pl(x) = P ′
n(x) + P ′
n+1(x). Hint: Use mathematical induction
as follows:
(a)
Verify the formula for n = 0.
(b)
Assuming that the formula is true for l = n −1, show [using (5.8e)] that it is
true for l = n.
6.
Using (10.6), (5.8), and Problem 2, evaluate P 1
2n+1(0).
7.
Show that, for l > 0,
R b
a Pl(x) dx = 0 if a and b are any two maximum or minimum
points of Pl(x), or ±1. Hint: Integrate (7.2).
8.
Show that (2l + 1)(x2 −1)P ′
l (x) = l(l + 1)[Pl+1(x)−Pl−1(x)]. Hint: Integrate (5.8e)
and (7.2) and combine the results. Thus show that Pl+1(x) = Pl−1(x) at maximum
and minimum points of Pl(x) and at ±1.
9.
Evaluate
R 1
−1 xPl(x)Pn(x) dx, n ≤l. Hint: Write (5.8a) with l replaced by l + 1,
multiply by Pn(x) and integrate.
Use the recursion relations of Section 15 (and, as needed, Sections 12, 13, 17, and 20) to
verify the formulas in Problems 10 to 14.
10.
Z ∞
0
x−pJp+1(x) dx =
1
2pΓ(1 + p).
11.
Z ∞
0
x−njn+1(x) dx =
1
(2n + 1)!!.
12.
d
dxKp(x) = −1
2[Kp−1(x) + Kp+1(x)].
13.
d
dxjn(x) = [njn−1(x) −(n + 1)jn+1(x)]/(2n + 1).
14.
Z
x3J0(x) dx = x3J1(x) −2x2J2(x).

616
Series Solutions of Differential Equations
Chapter 12
15.
Use the result of Problem 18.4 and equations (17.4) to show that
jn(x)y′
n(x) −yn(x)j′
n(x) = 1
x2 .
Then use Problem 17.14 (for y’s as well as j’s) to show that
jn(x)yn−1(x) −yn(x)jn−1(x) = 1
x2 .
16.
Use (15.2) repeatedly to show that
J1(x) = x
„
−1
x
d
dx
«
J0(x),
J2(x) = x2
„
−1
x
d
dx
«2
J0(x),
and, in general,
Jn(x) = xn
„
−1
x
d
dx
«n
J0(x).
17.
Let α be the ﬁrst positive zero of J1(x) and let βn be the zeros of J0(x). In terms
of α and βn, ﬁnd the values of x at the maximum and minimum points of the
function y = xJ1(αx). By computer or tables, ﬁnd the needed zeros and compute
the coordinates of the maximum and minimum points on the graph of y(x) for x
between 0 and 5. Computer plot y from x = 0 to 5 and compare your computed
maximum and minimum points with what the plot shows.
18.
(a)
Make the change of variables z = ex in the diﬀerential equation y′′ + e2xy = 0,
and so ﬁnd a solution of the diﬀerential equation in terms of Bessel functions.
(b)
Make the change of variables z = ex2/2 in the diﬀerential equation xy′′ −y′ +
x3(ex2 −p2)y = 0, and solve the equation in terms of Bessel functions.
19.
(a)
The generating function for Bessel functions of integral order p = n is
Φ(x, h) = e(1/2)x(h−h−1) =
∞
X
n=−∞
hnJn(x).
By expanding the exponential in powers of x(h −h−1) show that the n = 0
term is J0(x) as claimed.
(b)
Show that
x2 ∂2Φ
∂x2 + x∂Φ
∂x + x2Φ −
„
h ∂
∂h
«2
Φ = 0.
Use this result and Φ(x, h) = P∞
n=−∞hnJn(x) to show that the functions Jn(x)
satisfy Bessel’s equation. By considering the terms in hn in the expansion of
e(1/2)x(h−h−1) in part (a), show that the coeﬃcient of hn is a series starting
with the term (1/n!)(x/2)n. (You have then proved that the functions called
Jn(x) in the expansion of Φ(x, h) are indeed the Bessel functions of integral
order previously deﬁned by (12.9) and (13.1) with p = n.)

Section 23
Miscellaneous Problems
617
20.
In the generating function equation of Problem 19, put h = eiθ and separate real
and imaginary parts to derive the equations
cos(x sin θ) = J0(x) + 2J2(x) cos 2θ + 2J4(x) cos 4θ + · · ·
= J0(x) + 2
∞
X
n=1
J2n(x) cos 2nθ,
sin(x sin θ) = 2[J1(x) sin θ + J3(x) sin 3θ + · · · ]
= 2
∞
X
n=0
J2n+1(x) sin(2n + 1)θ.
These are Fourier series with Bessel functions as coeﬃcients. (In fact the Jn’s for
integral n are often called Bessel coeﬃcients because they occur in many series like
these.)
Use the formulas for the coeﬃcients in a Fourier series to ﬁnd integrals
representing Jn for even n and for odd n. Show that these results can be combined
to give
Jn(x) = 1
π
Z π
0
cos(nθ −x sin θ) dθ
for all integral n. These series and integrals are of interest in astronomy and in the
theory of frequency modulated waves.
21.
In the generating function equation, Problem 19, put x = iy and h = −ik and show
that
e(1/2)y(k+k−1) =
∞
X
n=−∞
knIn(y).
22.
In the cos(x sin θ) series of Problem 20, let θ = 0, and then let θ = π/2, and add the
results to show that (recall Problem 13.2)
∞
X
n=−∞
J4n(x) = 1
2(1 + cos x).
23.
Solve by power series (1 −x2)y′′ −xy′ + n2y = 0.
The polynomial solutions of
this equation with coeﬃcients determined to make y(1) = 1 are called Chebyshev
polynomials Tn(x). Find T0, T1, and T2.
24.
(a)
The following diﬀerential equation is often called a Sturm-Liouville equation:
d
dx[A(x)y′] + [λB(x) + C(x)]y = 0
(λ is a constant parameter). This equation includes many of the diﬀerential
equations of mathematical physics as special cases. Show that the following
equations can be written in the Sturm-Liouville form: the Legendre equation
(7.2); Bessel’s equation (19.2) for a ﬁxed p, that is, with the parameter λ
corresponding to α2; the simple harmonic motion equation y′′ = −n2y; the
Hermite equation (22.14); the Laguerre equations (22.21) and (22.26).
(b)
By following the methods of the orthogonality proofs in Sections 7 and 19, show
that if y1 and y2 are two solutions of the Sturm-Liouville equation (correspond-
ing to the two values λ1 and λ2 of the parameter λ), then y1 and y2 are orthogo-
nal on (a, b) with respect to the weight function B(x) if A(x)(y′
1y2−y′
2y1)|b
a = 0.
25.
In Problem 22.26, replace x by x/n in the y diﬀerential equation and set λ = n
to show that the diﬀerential equation satisﬁed by the functions fn(x) in Prob-
lem 22.27 is
y′′ +
„ 1
x −
1
4n2 −l(l + 1)
x2
«
y = 0.
Hence show by Problem 24 that the functions fn(x) are orthogonal on (0, ∞).

618
Series Solutions of Differential Equations
Chapter 12
26.
Verify Bauer’s formula eixw = P∞
0 (2l+1)iljl(x)Pl(w) as follows. Write the integral
for the coeﬃcients cl in the Legendre series for eixw = P clPl(w). You want to show
that cl(x) = (2l + 1)iljl(x).
First show that y = cl(x) satisﬁes the diﬀerential
equation (Problem 17.6) for spherical Bessel functions. Hints: Diﬀerentiate with
respect to x under the integral sign to ﬁnd y′ and y′′; substitute into the left side
of the diﬀerential equation.
Now integrate by parts with respect to w to show
that the integrand is zero because Pl(w) satisﬁes Legendre’s equation. Thus cl(x)
must be a linear combination of jl(x) and nl(x). Now consider the cl(x) integral
for small x; expand eiwx in series and evaluate the lowest term (which is xl since
R 1
−1 wnPl(w) dw = 0 for n < l). Compare with the approximate formulas for j1(x)
and nl(x) in Section 20.
27.
Show that R = lx −(1 −x2)D and L = lx + (1 −x2)D, where D = d/dx, are raising
and lowering operators for Legendre polynomials [compare Hermite functions, (22.1)
to (22.11) and Bessel functions, Problems 22.29 and 22.30]. More precisely, show
that RPl−1(x) = lPl(x) and LPl(x) = lPl−1(x). Hint: Use equations (5.8d) and
(5.8f). Note that, unlike the raising and lowering operators for Hermite functions,
here R and L depend on l as well as x, so you must be careful about indices. The L
operator operates on Pl, but the R operator as given operates on Pl−1 to produce
lPl. [If you prefer, you could replace l by l + 1 to rewrite R as (l + 1)x −(1 −x2)D;
then it operates on Pl to produce (l + 1)Pl+1.] Assuming that all Pl(1) = 1, solve
LP0(x) = 0 to ﬁnd P0(x) = 1, and then use raising operators to ﬁnd P1(x) and
P2(x).
28.
Show that the functions J0(t) and J0(π −t) are orthogonal on (0, π). Hints: See
the Laplace transform table (page 469), L23 and L24 with g = h = J0. What is the
inverse transform of (p2 + a2)−1?
29.
Show that the Fourier cosine transform (Chapter 7, Section 12) of J0(x) is
8
>
<
>
:
r
2
π
1
√
1 −α2 ,
0 ≤α < 1,
0,
α > 1.
Hence show that
R ∞
0
J0(x) dx = 1. Hints: Show that the integral in Problem 20
gives J0(x) = (2/π)
R π/2
0
cos(x sin θ) dθ. (Replace θ by π−θ in the π/2 to π integral.)
Let sin θ = α to ﬁnd J0 as a cosine transform; write the inverse transform. Now let
α = 0.
30.
Use the results of Chapter 7, Problems 12.18 and 13.19 to evaluate
R ∞
0 [j1(α)]2 dα.

C H A P T E R 13
Partial Differential Equations
1. INTRODUCTION
Many of the problems of mathematical physics involve the solution of partial dif-
ferential equations. The same partial diﬀerential equation may apply to a variety
of physical problems; thus the mathematical methods which you will learn in this
chapter apply to many more problems than those we shall discuss in the illustrative
examples. Let us outline the partial diﬀerential equations we shall consider, and
the kinds of physical problems which lead to each of them.
Laplace’s equation
∇2u = 0
(1.1)
The function u may be the gravitational potential in a region containing no mass,
the electrostatic potential in a charge-free region, the steady-state temperature (that
is, temperature not changing with time) in a region containing no sources of heat,
or the velocity potential for an incompressible ﬂuid with no vortices and no sources
or sinks.
Poisson’s equation
∇2u = f(x, y, z)
(1.2)
The function u may represent the same physical quantities listed for Laplace’s
equation, but in a region containing mass, electric charge, or sources of heat or
ﬂuid, respectively, for the various cases. The function f(x, y, z) is called the source
density; for example, in electricity it is proportional to the density of the electric
charge.
The diﬀusion or heat ﬂow equation
∇2u = 1
α2
∂u
∂t
(1.3)
Here u may be the non-steady-state temperature (that is, temperature varying
with time) in a region with no heat sources; or it may be the concentration of a
diﬀusing substance (for example, a chemical, or particles such as neutrons). The
quantity α2 is a constant known as the diﬀusivity.
Wave equation
∇2u = 1
v2
∂2u
∂t2
(1.4)
619

620
Partial Differential Equations
Chapter 13
Here u may represent the displacement from equilibrium of a vibrating string
or membrane or (in acoustics) of the vibrating medium (gas, liquid, or solid); in
electricity u may be the current or potential along a transmission line; or u may
be a component of E or B in an electromagnetic wave (light, radio waves, etc.).
The quantity v is the speed of propagation of the waves; for example, for light in
a vacuum it is c, the speed of light, and for sound waves it is the speed at which
sound travels in the medium under consideration. The operator ∇2 −1
c2 ∂2
∂t2 is called
the d’Alembertian.
Helmholtz equation
∇2F + k2F = 0
(1.5)
As you will see later, the function F here represents the space part (that is, the
time-independent part) of the solution of either the diﬀusion or the wave equation.
Schr¨odinger equation
−¯h2
2m∇2Ψ + V Ψ = i¯h ∂
∂tΨ
(1.6)
This is the wave equation of quantum mechanics. In this equation, ¯h is Planck’s
constant divided by 2π, m is the mass of a particle, i = √−1, and V is the potential
energy of the particle. The wave function Ψ is complex, and its absolute square is
proportional to the position probability of the particle.
We shall be principally concerned with the solution of these equations rather
than their derivation. If you like, you could say that it is true experimentally that
the physical quantities mentioned above satisfy the given equations. However, it is
also true that the equations can be derived from somewhat simpler experimental
assumptions.
Let us indicate brieﬂy an example of how this can be done.
In
Chapter 6, Sections 10 and 11, we considered the ﬂow of a ﬂuid.
We showed
(Chapter 6, Problem 10.15) that ∇· v = 0 for an incompressible ﬂuid in a region
containing no sources or sinks. If it is also true that there are no vortices (that is, the
ﬂow is irrotational), then curl v = 0, and v can be written as the gradient of a scalar
function: v = ∇u. Combining these two equations, we have ∇· ∇u = ∇2u = 0.
The function u is called the velocity potential and we see that (under the given
conditions) it satisﬁes Laplace’s equation as we claimed. A few more examples of
such derivations are outlined in the problems.
In the following sections, we shall consider a number of physical problems to
illustrate the very useful method of solving partial diﬀerential equations known as
separation of variables (no relation to the same term used in ordinary diﬀerential
equations, Chapter 8).
In Sections 2 to 4, we consider problems in rectangular
coordinates leading to Fourier series solutions—problems similar to those solved by
Fourier. In later sections, we consider use of other coordinate systems (cylindrical,
spherical) leading to solutions using Legendre or Bessel series.
PROBLEMS, SECTION 1
1.
Assume from electrostatics the equations ∇· E = ρ/ϵ0 and E = −∇φ (E = electric
ﬁeld, ρ = charge density, ϵ0 = constant, φ = electrostatic potential). Show that the
electrostatic potential satisﬁes Laplace’s equation (1.1) in a charge-free region and
satisﬁes Poisson’s equation (1.2) in a region of charge density ρ.
2.
(a)
Show that the expression u = sin (x −vt) describing a sinusoidal wave (see
Chapter 7, Figure 2.3), satisﬁes the wave equation (1.4). Show that, in general,

Section 2
Laplace’s Equation; Steady-State Temperature in a Rectangular Plate
621
u = f(x −vt) and u = f(x + vt) satisfy the wave equation, where f is any
function with a second derivative. This is the d’Alembert solution of the wave
equation. (See Chapter 4, Section 11, Example 1.) The function f(x −vt)
represents a wave moving in the positive x direction and f(x + vt) represents
a wave moving in the opposite direction.
(b)
Show that u(r, t) = (1/r)f(r −vt) and u(r, t) = (1/r)f(r + vt) satisfy the wave
equation in spherical coordinates. [Use the ﬁrst term of (7.1) for ∇2u since
here u is independent of θ and φ.] These functions represent spherical waves
spreading out from the origin or converging on the origin.
3.
Assume from electrodynamics the following equations which are valid in free space.
(They are called Maxwell’s equations.)
∇· E = 0
∇· B = 0
∇× E = −∂B
∂t
∇× B = 1
c2
∂E
∂t
where E and B are the electric and magnetic ﬁelds, and c is the speed of light in a
vacuum. From them show that any component of E or B satisﬁes the wave equation
(1.4) with v = c.
4.
Obtain the heat ﬂow equation (1.3) as follows: The quantity of heat Q ﬂowing across
a surface is proportional to the normal component of the (negative) temperature
gradient, (−∇T )·n. Compare Chapter 6, equation (10.4), and apply the discussion
of ﬂow of water given there to the ﬂow of heat. Thus show that the rate of gain
of heat per unit volume per unit time is proportional to ∇· ∇T. But ∂T/∂t is
proportional to this gain in heat; thus show that T satisﬁes (1.3).
2. LAPLACE’S EQUATION; STEADY-STATE
TEMPERATURE IN A RECTANGULAR PLATE
We want to solve the following problem: A long rectangular metal plate has its two
long sides and the far end at 0◦and the base at 100◦(Figure 2.1). The width of
the plate is 10 cm. Find the steady-state temperature distribution inside the plate.
(This problem is mathematically identical to the problem of ﬁnding the electrostatic
potential in the region 0 < x < 10, y > 0, if the given temperatures are replaced by
potentials—see, for example, Jackson, 3rd edition, p.73)
Figure 2.1
To simplify the problem, we shall assume at ﬁrst
that the plate is so long compared to its width that
we may make the mathematical approximation that
it extends to inﬁnity in the y direction. It is then
called a semi-inﬁnite plate. This is a good approxi-
mation if we are interested in temperatures not too
near the far end.
The temperature T satisﬁes Laplace’s equation
inside the plate where there are no sources of heat,
that is,
(2.1)
∇2T = 0
or
∂2T
∂x2 + ∂2T
∂y2 = 0
We have written ∇2 in rectangular coordinates
because the boundary of the plate is rectangular

622
Partial Differential Equations
Chapter 13
and we have omitted the z term because the plate is in two dimensions. To solve
this equation, we are going to try a solution of the form
(2.2)
T (x, y) = X(x)Y (y),
where, as indicated, X is a function only of x, and Y is a function only of y.
Immediately you may raise the question: But how do we know that the solution is
of this form? The answer is that it is not! However, as you will see, once we have
solutions of the form (2.2) we can combine them to get the solution we want. [Note
that a sum of solutions of (2.1) is a solution of (2.1).] Substituting (2.2) into (2.1),
we have
(2.3)
Y d2X
dx2 + X d2Y
dy2 = 0.
(Ordinary instead of partial derivatives are now correct since X depends only on x,
and y depends only on y.) Divide (2.3) by XY to get
(2.4)
1
X
d2X
dx2 + 1
Y
d2Y
dy2 = 0.
The next step is really the key to the process of separation of variables. We are
going to say that each of the terms in (2.4) is a constant because the ﬁrst term is
a function of x alone and the second term is a function of y alone. Why is this
correct? Recall that when we say u = sin t is a solution of ¨u = −u, we mean that
if we substitute u = sin t into the diﬀerential equation, we get an identity (¨u = −u
becomes −sin t = −sin t), which is true for all values of t. Although we speak of an
equation, when we substitute the solution into a diﬀerential equation, we have an
identity in the independent variable. (We made use of this fact in series solutions
of diﬀerential equations in Chapter 12, Sections 1 and 2.) In (2.1) to (2.4) we have
two independent variables, x and y. Saying that (2.2) is a solution of (2.1) means
that (2.4) is an identity in the two independent variables x and y [recall that (2.4)
was obtained by substituting (2.2) into (2.1)]. In other words, if (2.2) is a solution
of (2.1), then (2.4) must be true for any and all values of the two independent
variables x and y. Since X is a function only of x and Y of y, the ﬁrst term of
(2.4) is a function only of x and the second term is a function only of y. Suppose
we substitute a particular x into the ﬁrst term; that term is then some numerical
constant. To have (2.4) satisﬁed, the second term must be minus the same constant.
While x remains ﬁxed, let y vary (remember that x and y are independent). We
have said that (2.4) is an identity; it is then true for our ﬁxed x and any y. Thus
the second term remains constant as y varies. Similarly, if we ﬁx y and let x vary,
we see that the ﬁrst term of (2.4) is a constant. To say this more concisely, the
equation f(x) = g(y), with x and y independent variables, is an identity only if
both functions are the same constant; this is the basis of the process of separation
of variables. From (2.4) we then write
(2.5)
1
X
d2X
dx2 = −1
Y
d2Y
dy2 = const. = −k2,
k ≥0,
or
X′′ = −k2X
and
Y ′′ = k2Y.
The constant k2 is called the separation constant. The solutions of (2.5) are
(2.6)
X =

sin kx,
cos kx,
Y =

eky,
e−ky,

Section 2
Laplace’s Equation; Steady-State Temperature in a Rectangular Plate
623
and the solutions of (2.1) [of the form (2.2)] are
(2.7)
T = XY =

eky
e−ky
  sin kx
cos kx

.
None of the four solutions in (2.7) satisﬁes the given boundary temperatures. What
we must do now is to take a combination of the solutions (2.7), with the constant
k properly selected, which will satisfy the given boundary conditions. [Any linear
combination of solutions of (2.1) is a solution of (2.1) because the diﬀerential equa-
tion (2.1) is linear; see Chapter 3, Section 7, and Chapter 8, Sections 1 and 6.] We
ﬁrst discard the solutions containing eky since we are given T →0 as y →∞. (We
are assuming k > 0; see Problem 5.) Next we discard solutions containing cos kx
since T = 0 when x = 0. This leaves us just e−ky sin kx, but the value of k is
still to be determined. When x = 10, we are to have T = 0; this will be true if
sin (10k) = 0, that is, if k = nπ/10 for n = 1, 2, · · · . Thus for any integral n, the
solution
(2.8)
T = e−nπy/10 sin nπx
10
satisﬁes the given boundary conditions on the three T = 0 sides.
Finally, we must have T = 100 when y = 0; this condition is not satisﬁed by
(2.8) for any n. But a linear combination of solutions like (2.8) is a solution of (2.1);
let us try to ﬁnd such a combination which does satisfy T = 100 when y = 0. In
order to allow all possible n’s we write an inﬁnite series for T , namely
(2.9)
T =
∞

n=1
bne−nπy/10 sin nπx
10 .
For y = 0, we must have T = 100; from (2.9) with y = 0 we get
(2.10)
Ty=0 =
∞

n=1
bn sin nπx
10 = 100.
But this is just the Fourier sine series (Chapter 7, Section 9) for f(x) = 100 with
l = 10. We can ﬁnd the coeﬃcients bn, as we did in Chapter 7; we get
(2.11)
bn = 2
l
 l
0
f(x) sin nπx
l
dx = 2
10
 10
0
100 sin nπx
10 dx =

400
nπ ,
odd n,
0,
even n.
Then (2.9) becomes
(2.12)
T = 400
π

e−πy/10 sin πx
10 + 1
3e−3πy/10 sin 3πx
10 + · · ·

.
Equation (2.12) can be used for computation if πy/10 is not too small since then
the series converges rapidly. (See also Problem 6.) For example, at x = 5 (central
line of the plate) and y = 5, we ﬁnd
(2.13)
T = 400
π

e−π/2 sin π
2 + 1
3e−3π/2 sin 3π
2 + · · ·

≃26.1◦.

624
Partial Differential Equations
Chapter 13
To see how the temperature varies with x and y over a rectangle, you can computer
plot a 3-dimensional graph of several terms of T (x, y) in (2.12). Or you can make
a 2-dimensional contour plot which shows the isothermals (curves of constant T ).
If the temperature on the bottom edge is any function f(x) instead of 100◦(with
the other three sides at 0◦as before), we can do the problem by the same method.
We have only to expand the given f(x) in a Fourier sine series and substitute the
coeﬃcients into (2.9).
Next, let us consider a ﬁnite plate of height 30 cm with the top edge at T = 0◦,
and other dimensions and temperatures as in Figure 2.1. We no longer have any
reason to discard the eky solution since y does not become inﬁnite. We now replace
e−ky by a linear combination ae−ky + beky which is zero when y = 30. The most
convenient way to do this is to use the combination
(2.14)
1
2ek(30−y) −1
2e−k(30−y)
(that is, let a =
1
2e30k and b = −1
2e−30k).
Then, when y = 30, (2.14) gives
e0 −e0 = 0 as we wanted. Now (2.14) is just sinh k(30 −y) (see Chapter 2, Section
12), so for the ﬁnite plate, we can write the solution as [compare (2.9)]
(2.15)
T =
∞

n=1
Bn sinh nπ
10 (30 −y) sin nπx
10 .
Each term of this series is zero on the three T = 0 sides of the plate. When y = 0,
we want T = 100:
(2.16)
Ty=0 = 100 =
∞

n=1
Bn sinh (3nπ) sin nπx
10 =
∞

n=1
bn sin nπx
10
where bn = Bn sinh 3nπ or Bn = bn/ sinh 3nπ.
We ﬁnd bn, solve for Bn and
substitute into (2.15) to get the temperature distribution in the ﬁnite plate:
(2.17)
T =

odd n
400
nπ sinh 3nπ sinh nπ
10 (30 −y) sin nπx
10 .
In (2.12) and (2.17) we have found functions T (x, y) satisfying both (2.1) and
all the given boundary conditions.
For a bounded region with given boundary
temperatures, it is an experimental fact (and it can also be shown mathematically—
see Problem 16 and Chapter 14, Problem 11.38) that there is only one T (x, y)
satisfying Laplace’s equation and the given boundary conditions. Thus (2.17) is the
desired solution for the rectangular plate. It can also be shown that there is only
one solution for the semi-inﬁnite plate provided T →0 at ∞; thus (2.12) is the
solution for that case.
It may have occurred to you to wonder why we took the constant in (2.5) to be
−k2 and what would happen if we took +k2 instead. As far as getting solutions of
the diﬀerential equation is concerned it would be perfectly correct to use +k2; we
would get instead of (2.7):
(2.18)
T = XY =

ekx
e−kx
  sin ky
cos ky

.
[We are assuming that k is real; an imaginary k in (2.18) would simply give combi-
nations of the solutions (2.7) over again. Also see Problem 5.] The solutions (2.18)

Section 2
Laplace’s Equation; Steady-State Temperature in a Rectangular Plate
625
would not be of any use for the semi-inﬁnite plate problem since none of them tends
to zero as y →∞, and a linear combination of ekx and e−kx cannot be zero both at
x = 0 and at x = 10. However, if we had considered a semi-inﬁnite plate with its
long sides parallel to the x axis instead of the y axis, and T = 100◦along the short
end on the y axis, the solutions (2.18) would have been the ones needed. Or, for
the ﬁnite plate, if the 100◦side were along the y axis, then we would want (2.18).
Figure 2.2
Finally, let us see how to ﬁnd the temperature distribution in a
plate if two adjacent sides are held at 100◦and the other two at 0◦
(or, in general, if any values are given for the four sides). We can
ﬁnd the solution to this problem by a combination of the results
we have already obtained. Let us call the sides of the rectangular
plate A, B, C, D (Figure 2.2). If sides A, B, and C are held at 0◦,
and D at 100◦, we can ﬁnd the temperature distribution by the
same method we used in ﬁnding (2.17) if we take the x axis along
D. Next suppose that for the same plate (Figure 2.2) sides A, B,
and D are held at 0◦and C at 100◦. This is the same kind of problem over again,
but this time we want to use the solutions (2.18). [Or to shorten the work, we could
write the solution like (2.17) with the x axis taken along C and then interchange
x and y in the result to agree with Figure 2.2.] Having obtained the two solutions
(one for C at 100◦and one for D at 100◦), let us add these two answers. The
result is a solution of the diﬀerential equation (2.1) (linearity: the sum of any two
solutions is a solution). The temperatures on the boundary (as well as inside) are
the sums of the temperatures in the two solutions we added, that is, 0◦on A, 0◦on
B, 0◦+ 100◦on C, and 100◦+ 0◦on D. These are the given boundary conditions
we wanted to satisfy. Thus the sum of the solutions of two simple problems gives
the answer to the more complicated one (see Problems 11 to 13).
Before solving more problems, let us stop for a moment to summarize this pro-
cess of separation of variables which is basically the same for all the partial diﬀer-
ential equations we shall discuss. We ﬁrst assume a solution which is a product
of functions of the independent variables [like (2.2)], and separate the partial dif-
ferential equation into several ordinary diﬀerential equations [like (2.5)]. We solve
these ordinary diﬀerential equations; the solutions may be exponential functions,
trigonometric functions, powers (positive or negative), Bessel functions, Legendre
polynomials, etc. Any linear combination of these solutions, with any values of the
separation constants, is a solution of the partial diﬀerential equation. The problem
is to determine both the values of the separation constants and the correct linear
combination to ﬁt the given boundary or initial conditions.
The problem of ﬁnding the solution of a given diﬀerential equation subject to
given boundary conditions is called a boundary value problem. Such problems often
lead to eigenvalue problems. Recall (Chapter 3, Section 11, and Chapter 12, end of
Section 2) that in an eigenvalue (or characteristic value) problem, there is a param-
eter whose values are to be selected so that the solutions of the problem meet some
given requirements. The separation constants we have been using are just such
parameters; their values are determined by demanding that the solutions satisfy
some of the boundary conditions. [For example, we found k = nπ/10 just before
(2.8) by requiring that T = 0 when x = 10.] The resulting values of the separation
constants are called eigenvalues and the solutions of the diﬀerential equation [for
example (2.8)] corresponding to the eigenvalues are called eigenfunctions. It may
also happen that in addition to the separation constants there is a parameter in the

626
Partial Differential Equations
Chapter 13
original partial diﬀerential equation [for example, E in the Schr¨odinger equation
(1.6)]. Again the possible values of this parameter (for which the equation has solu-
tions meeting speciﬁed requirements) are called eigenvalues, and the corresponding
solutions are called eigenfunctions.
Having found the eigenfunctions, the next step is to expand the given function
(boundary or initial conditions) in terms of them. [See, for example (2.10) and
(2.16) and many examples in later sections.] As we have discussed (see Chapter 7,
Section 8, and Chapter 12, Section 6), the eigenfunctions are a set of basis functions
for this expansion. Thus we select the functions [for example e−ky sin kx in (2.7)]
and values of the separation constants (eigenvalues) to ﬁt the given boundary (or
initial) conditions; this determines the basis functions for a problem.
PROBLEMS, SECTION 2
After you ﬁnd the series solution of a problem, make computer plots of your results
as discussed just after equation (2.13).
1.
Find the steady-state temperature distribution for the semi-inﬁnite plate problem
if the temperature of the bottom edge is T = f(x) = x (in degrees; that is, the
temperature at x cm is x degrees), the temperature of the other sides is 0◦, and the
width of the plate is 10 cm.
Answer:
T = 20
π
∞
X
n=1
(−1)n+1
n
e−nπy/10 sin (nπx/10).
2.
Solve the semi-inﬁnite plate problem if the bottom edge of width 20 is held at
T =
(
0◦,
0 < x < 10,
100◦,
10 < x < 20,
and the other sides are at 0◦.
3.
Solve the semi-inﬁnite plate problem if the bottom edge of width π is held at
T = cos x and the other sides are at 0◦.
Answer:
T = 4
π
X
even n
n
n2 −1e−ny sin nx.
4.
Solve the semi-inﬁnite plate problem if the bottom edge of width 30 is held at
T =
(
x,
0 < x < 15,
30 −x,
15 < x < 30,
and the other sides are at 0◦.
5.
Show that the solutions of (2.5) can also be written as
X =
(
eikx,
e−ikx,
Y =
(
sinh ky,
cosh ky.
Also show that these solutions are equivalent to (2.7) if k is real and equivalent
to (2.18) if k is pure imaginary.
(See Chapter 2, Section 12.)
Also show that
X = sin k(x −a), Y = sinh k(y −b) are solutions of (2.5).

Section 2
Laplace’s Equation; Steady-State Temperature in a Rectangular Plate
627
6.
Show that the series in (2.12) can be summed to get
T = 200
π arc tan
„ sin (πx/10)
sinh (πy/10)
«
(with the arc tangent in radians). Use this formula to check the value T = 26.1◦
at x = y = 5. Hints for summing the series: Use sin (nπx/10) = Im einπx/10 to
write the series as Im P
odd n zn/n. (What is z?) Compare this with the series for
ln[(1 + z)/(1 −z)] (see Chapter 1, Problem 13.17). Then use (13.5) of Chapter 2.
7.
Solve Problem 3 if the plate is cut oﬀat height 1 and the temperature at y = 1 is
held at 0◦.
Answer:
T = 4
π
X
even n
n
(n2 −1) sinh n sinh n(1 −y) sin nx.
8.
Find the steady-state temperature distribution in a rectangular plate 30 cm by 40 cm
given that the temperature is 0◦along the two long sides and along one short end;
the other short end along the x axis has temperature
T =
(
100◦,
0 < x < 10,
0◦,
10 < x < 30.
9.
Solve Problem 2 if the plate is cut oﬀat height 10 and the temperature of the top
edge is 0◦.
10.
Find the steady-state temperature distribution in a metal plate 10 cm square if one
side is held at 100◦and the other three sides at 0◦. Find the temperature at the
center of the plate.
Answer:
T =
X
odd n
400
nπ sinh nπ sinh nπ
10 (10 −y) sin nπx
10 ,
T (5, 5) ≃25◦.
11.
Find the steady-state temperature distribution in the plate of Problem 10 if two
adjacent sides are at 100◦and the other two at 0◦.
Hint: Use your solution of
Problem 10. You should not have to do any calculation—just write down the answer!
12.
Find the temperature distribution in a rectangular plate 10 cm by 30 cm if two
adjacent sides are held at 100◦and the other two sides at 0◦.
13.
Find the steady-state temperature distribution in a rectangular plate covering the
area 0 < x < 10, 0 < y < 20, if the two adjacent sides along the axes are held at
temperatures T = x and T = y and the other two sides at 0◦.
14.
In the rectangular plate problem, we have so far had the temperature speciﬁed all
around the boundary.
We could, instead, have some edges insulated.
The heat
ﬂow across an edge is proportional to ∂T/∂n, where n is a variable in the direction
normal to the edge (see normal derivatives, Chapter 6, Section 6). For example,
the heat ﬂow across an edge lying along the x axis is proportional to ∂T/∂y. Since
the heat ﬂow across an insulated edge is zero, we must have not T, but a partial
derivative of T, equal to zero on an insulated boundary. Use this fact to ﬁnd the
steady-state temperature distribution in a semi-inﬁnite plate of width 10 cm if the
two long sides are insulated, the far end (at ∞as in Figure 2.1) is at 0◦, and the
bottom edge is at T = f(x) = x −5.
Note that you used T →0 as y →∞only to discard the solutions e+ky; it would
be just as satisfactory to say that T does not become inﬁnite as y →∞. Actually,

628
Partial Differential Equations
Chapter 13
the temperature (assumed ﬁnite) as y →∞in this problem is determined by the
given temperature at y = 0. Let T = f(x) = x at y = 0, repeat your calculations
above to ﬁnd the temperature distribution, and ﬁnd the value of T for large y. Don’t
forget the k = 0 term in the series!
15.
Consider a ﬁnite plate, 10 cm by 30 cm, with two insulated sides, one end at 0◦and
the other at a given temperature T = f(x). Try f(x) = 100◦; f(x) = x. You should
convince yourself that this problem cannot be done using just the solutions (2.7).
To see what is wrong, go back to the diﬀerential equations (2.5) and solve them
if k = 0. You should ﬁnd solutions x, y, xy and constant [the constant is already
contained in (2.7) for k = 0, but the other three solutions are not]. Now go back
over each of the problems we have done so far and see why we could ignore these
k = 0 solutions; then including the k = 0 solutions, ﬁnish the problem of the ﬁnite
plate with insulated sides.
For the case f(x) = x, the answer is:
T = 1
6(30 −y) −40
π2
X
odd n
1
n2 sinh 3nπ sinh nπ
10 (30 −y) cos nπx
10 .
16.
Show that there is only one function u which takes given values on the (closed)
boundary of a region and satisﬁes Laplace’s equation ∇2u = 0 in the interior of
the region. Hints: Suppose u1 and u2 are both solutions with the same boundary
conditions so that U = u1 −u2 = 0 on the boundary.
In Green’s ﬁrst identity
(Chapter 6, Problem 10.16), let φ = Ψ = U to show that ∇U ≡0. Thus show
U ≡0 everywhere inside the region.
3. THE DIFFUSION OR HEAT FLOW EQUATION; THE SCHR ¨ODINGER EQUATION
The heat ﬂow equation is
(3.1)
∇2u = 1
α2
∂u
∂t ,
where u is the temperature and α2 is a constant characteristic of the material
through which heat is ﬂowing. It is worthwhile to do ﬁrst a partial separation of
(3.1) into a space equation and a time equation; the space equation in more than
one dimension then must be further separated into ordinary diﬀerential equations
in x and y, or x, y, and z, or r, θ, φ, etc. We assume a solution of (3.1) of the form
(3.2)
u = F(x, y, z)T (t).
(Note the change in meaning of T ; we have previously used it for temperature; here
u is temperature and T is the time-dependent factor in u.) Substitute (3.2) into
(3.1); we get
(3.3)
T ∇2F = 1
α2 F dT
dt .
Next divide (3.3) by FT to get
(3.4)
1
F ∇2F = 1
α2
1
T
dT
dt .

Section 3
The Diffusion or Heat Flow Equation; The Schr¨odinger Equation
629
The left side of this identity is a function only of the space variables x, y, z, and the
right side is a function only of time. Therefore both sides are the same constant
and we can write
(3.5)
1
F ∇2F = −k2
or
∇2F + k2F = 0
and
1
α2
1
T
dT
dt = −k2
or
dT
dt = −k2α2T.
The time equation can be integrated to give
(3.6)
T = e−k2α2t.
We can see a physical reason here for choosing the separation constant (−k2) to be
negative. As t increases, the temperature of a body might decrease to zero as in
(3.6), but it could not increase to inﬁnity as it would if we had used +k2 in (3.5)
and (3.6). The space equation in (3.5) is the Helmholtz equation (1.5) as promised.
You will ﬁnd (Problem 10) that the space part of the wave equation is also the
Helmholtz equation.
Example 1.
Figure 3.1
Let us now consider the ﬂow of heat through a slab
of thickness l (for example, the wall of a refrigerator). We
shall assume that the faces of the slab are so large that we
may neglect any end eﬀects and assume that heat ﬂows only
in the x direction (Figure 3.1). This problem is then iden-
tical to the problem of heat ﬂow in a bar of length l with
insulated sides, because in both cases the heat ﬂow is just in
the x direction. Suppose the slab has initially a steady-state
temperature distribution with the x = 0 wall at 0◦and the
x = l wall at 100◦. From t = 0 on, let the x = l wall (as
well as the x = 0 wall) be held at 0◦. We want to ﬁnd the
temperature at any x (in the slab) at any later time.
First, we ﬁnd the initial steady-state temperature distribution. You probably
already know that this is linear, but it is interesting to see this from our equations.
The initial steady-state temperature u0 satisﬁes Laplace’s equation, which in this
one-dimensional case is d2u0/dx2 = 0. The solution of this equation is u0 = ax + b,
where a and b are constants which must be found to ﬁt the given conditions. Since
u0 = 0 at x = 0 and u0 = 100 at x = l, we have
(3.7)
u0 = 100
l x.
From t = 0 on, u satisﬁes the heat ﬂow equation (3.1). We have already sep-
arated this; the solutions are (3.2) where T (t) is given by (3.6) and F(x) satisﬁes
the ﬁrst of equations (3.5), namely
(3.8)
∇2F + k2F = 0
or
d2F
dx2 + k2F = 0.
(For this one-dimensional problem, F is a function only of x.) The solutions of (3.8)
are
(3.9)
F(x) =

sin kx,
cos kx,

630
Partial Differential Equations
Chapter 13
and the solutions (3.2) are
(3.10)
u =

e−k2α2t sin kx
e−k2α2t cos kx
We discard the cos kx solution for this problem because we are given u = 0 at x = 0.
Also we want u = 0 at x = l; this will be true if sin kl = 0, that is, kl = nπ, or
k = nπ/l (eigenvalues). Our basis functions (eigenfunctions) are then
(3.11)
u = e−(nπα/l)2t sin nπx
l
and the solution of our problem will be the series
(3.12)
u =
∞

n=1
bne−(nπα/l)2t sin nπx
l
.
At t = 0, we want u = u0 as in (3.7), that is,
(3.13)
u =
∞

n=1
bn sin nπx
l
= u0 = 100
l x.
This means ﬁnding the Fourier sine series for (100/l)x on (0, l); the result (from
Problem 1) for the coeﬃcients is
(3.14)
bn = 100
l
2l
π
1
n(−1)n−1 = 200
π
(−1)n−1
n
.
Then we get the ﬁnal solution by substituting (3.14) into (3.12); this gives
(3.15)
u = 200
π
∞

n=1
(−1)n−1
n
e−(nπα/l)2t sin nπx
l
.
Example 2.
We can now do some variations of this problem. Suppose the ﬁnal temper-
atures of the faces are given as two diﬀerent constant values diﬀerent from zero.
Then, as for the initial steady state, the ﬁnal steady state is a linear function of
distance. The series (3.12) tends to a ﬁnal steady state of zero; to obtain a solution
tending to some other ﬁnal steady state, we add to (3.12) the linear function uf
representing the correct ﬁnal steady state. Thus we write instead of of (3.12)
(3.16)
u =
∞

n=1
bne−(nπα/l)2t sin nπx
l
+ uf.
Then for t = 0, the equation corresponding to (3.13) is
(3.17)
u0 =
∞

n=1
bn sin nπx
l
+ uf

Section 3
The Diffusion or Heat Flow Equation; The Schr¨odinger Equation
631
or
(3.18)
u0 −uf =
∞

n=1
bn sin nπx
l
.
Thus when uf ̸= 0, it is u0−uf rather than u0 which must be expanded in a Fourier
series.
Insulated boundaries
So far we have had the boundary temperatures given.
We could, instead, have the faces insulated; then no heat ﬂows in or out of the
body. This will be true if the normal derivative ∂u/∂n (see Problem 2.14) of the
temperature is zero at the boundary. (When the boundary values of u are given,
the problem is called a Dirichlet problem; when the boundary values of the normal
derivative ∂u/∂n are given, the problem is called a Neumann problem.) For the one-
dimensional case we have considered, we replace the condition u = 0 at x = 0 and
l by the condition ∂u/∂x = 0 at x = 0 and l if the faces are insulated. This means
that the useful solution in (3.10) is now the one containing cos kx; note carefully
that we must include the constant term (corresponding to k = 0). See Problem 7.
The Schr¨odinger Equation
Compare equations (1.3) and (1.6). If V = 0 in
(1.6), the two equations have the same form (a ∇2 term and a ﬁrst partial with
respect to t). For future reference (see problems, Section 7), let’s ﬁrst separate
variables in the general equation (1.6). We assume [compare (3.2)]
(3.19)
Ψ = ψ(x, y, z)T (t).
Substitute (3.19) into (1.6) and divide by Ψ to get
(3.20)
−¯h2
2m
1
ψ ∇2ψ + V = i¯h 1
T
dT
dt = E
where E is the separation constant [compare (3.5)]. (In quantum mechanics, E has
the meaning of energy of the particle.) Then integrating the time equation gives
(compare 3.6)
(3.21)
T = e−iEt/¯h
and the space equation (called the time-independent Schr¨odinger equation) is
(3.22)
−¯h2
2m∇2ψ + V ψ = Eψ.
Time-independent Schr¨odinger equation
For the one-dimensional problems that we consider in this section, and with
V = 0, we have
(3.23)
−¯h2
2m
d2ψ
dx2 = Eψ
or
d2ψ
dx2 + 2mE
¯h2 ψ = 0
which is (3.8) with k2 = 2mE
¯h2 . Thus the solutions of (3.23) are the same as in (3.9)
and the corresponding Ψ solutions are
(3.24)
Ψ = ψ(x)T (t) =

sin kx
cos kx

e−iEt/¯h.

632
Partial Differential Equations
Chapter 13
Example 3.
The “particle in a box” problem in quantum mechanics requires the solution
of the Schr¨odinger equation with V = 0 on (0, l) and Ψ = 0 at the endpoints x = 0
and x = l for all t. (The wave function Ψ then describes a particle trapped between
0 and l.) As in the heat ﬂow problem, Ψ = 0 at x = 0 requires the sine solutions
in (3.24) and Ψ = 0 at x = l requires k = nπ/l. Since k2 = 2mE/¯h2, we ﬁnd
E =
¯h2
2m
n2π2
l2
which we will call En. (The meaning of this equation in quantum
mechanics is that the energy of a particle trapped between 0 and l can have only a
discrete set of values called eigenvalues. We say that the energy is quantized.) The
basis functions for this problem are then the eigenfunctions
(3.25)
Ψn = sin nπx
l
e−iEnt/¯h,
and we write Ψ(x, t) as a linear combination of them.
(3.26)
Ψ(x, t) =
∞

n=1
bn sin nπx
l
e−iEnt/¯h,
(compare (3.12) for the heat ﬂow problem). If the initial state Ψ(x, 0) is the same
function as in (3.7), the bn coeﬃcients are the same as in (3.14), so we have
(3.27)
Ψ(x, t) = 200
π
∞

n=1
(−1)n−1
n
sin nπx
l
e−iEnt/¯h.
See Problems 11 and 12; also see Problems 6.6 to 6.8, and 7.17 to 7.22.
PROBLEMS, SECTION 3
As in Section 2, make computer plots of your results.
1.
Verify the coeﬃcients in equation (3.14).
2.
A bar 10 cm long with insulated sides is initially at 100◦. Starting at t = 0, the
ends are held at 0◦. Find the temperature distribution in the bar at time t.
Answer:
u = 400
π
X
odd n
1
ne−(nπα/10)2t sin nπx
10 .
3.
In the initial steady state of an inﬁnite slab of thickness l, the face x = 0 is at 0◦
and the face x = l is at 100◦. From t = 0 on, the x = 0 face is held at 100◦and the
x = l face at 0◦. Find the temperature distribution at time t.
Answer:
u = 100 −100x
l
−400
π
X
even n
1
ne−(nπα/l)2t sin nπx
l
.
4.
At t = 0, two ﬂat slabs each 5 cm thick, one at 0◦and one at 20◦, are stacked
together, and then the surfaces are kept at 0◦. Find the temperature as a function
of x and t for t > 0.
5.
Two slabs, each 1 inch thick, each have one surface at 0◦and the other surface at
100◦. At t = 0, they are stacked with their 100◦faces together and then the outside
surfaces are held at 100◦. Find u(x, t) for t > 0.
6.
Show that the following problem is easily solved using (3.15): The ends of a bar
are initially at 20◦and 150◦; at t = 0 the 150◦end is changed to 50◦. Find the
time-dependent temperature distribution.

Section 4
The Wave Equation; the Vibrating String
633
7.
A bar of length l with insulated sides has its ends also insulated from time t = 0 on.
Initially the temperature is u = x, where x is the distance from one end. Determine
the temperature distribution inside the bar at time t. Hints and comments: See the
discussion above and also Problem 2.14. Show that the k = 0 solutions are x and
constant (time independent). Note that here (unlike Problem 2.15) you do not need
the extra solution (namely x) for k = 0 since the ﬁnal steady state is a constant
and this is included in the solutions (3.10). Also note that we did need the k = 0
solutions in the discussion following (3.15) but were able to simplify the work by
observing that these linear solutions simply give the ﬁnal steady state.
Answer:
u = l
2 −4l
π2
X
odd n
1
n2 cos nπx
l
e−(nπα/l)2t.
8.
A bar of length 2 is initially at 0◦. From t = 0 on, the x = 0 end is held at 0◦and
the x = 2 end at 100◦. Find the time-dependent temperature distribution.
9.
Solve Problem 8 if, for t > 0, the x = 0 end of the bar is insulated and the x = 2
end is held at 100◦. See Problem 7 above, and Chapter 7, end of Section 11.
10.
Separate the wave equation (1.4) into a space equation and a time equation as we did
the heat ﬂow equation, and show that the space equation is the Helmholtz equation
for this case also.
11.
Solve the “particle in a box” problem to ﬁnd Ψ(x, t) if Ψ(x, 0) = 1 on (0, π). What
is En? The function of interest here which you should plot is |Ψ(x, t)|2.
12.
Do Problem 11 if Ψ(x, 0) = sin2 πx on (0, 1).
4. THE WAVE EQUATION; THE VIBRATING STRING
Let a string (for example, a piano or violin string) be stretched tightly and its ends
fastened to supports at x = 0 and x = l. When the string is vibrating, its vertical
displacement y from its equilibrium position along the x axis depends on x and t.
We assume that the displacement y is always very small and that the slope ∂y/∂x
of the string at any point at any time is small. In other words, we assume that
the string never gets very far away from its stretched equilibrium position; in fact,
we do not distinguish between the length of the string and the distance between
the supports, although it is clear that the string must stretch a little as it vibrates
out of its equilibrium position. Under these assumptions, the displacement y(x, t)
satisﬁes the (one-dimensional) wave equation
(4.1)
∂2y
∂x2 = 1
v2
∂2y
∂t2 .
The constant v depends on the tension and the linear density of the string; it is
called the wave velocity because it is the velocity with which a disturbance at one
point of the string would travel along the string. To separate the variables, we
substitute
(4.2)
y = X(x)T (t)
into (4.1) and get (Problem 3.10)
1
X
d2X
dx2 = 1
v2
1
T
d2T
dt2 = −k2,

634
Partial Differential Equations
Chapter 13
or
X′′ + k2X = 0,
(4.3)
¨T + k2v2T = 0.
We can see from the physical problem why we use a negative separation constant
here; the solutions are to describe vibrations which are represented by sines and
cosines, not by real exponentials. Of course, if we tried using +k2 with k real,
we would also discover mathematically that we could not satisfy the boundary
conditions.
Recall the following notation used in discussing wave phenomena (see Chapter 7,
Problem 2.17):
ν = frequency (sec−1)
λ = wavelength
v = λν
ω = 2πν = angular frequency (radians)
k = 2π
λ = 2πν
v
= ω
v = wave number
The solutions of the two equations in (4.3) are
(4.4)
X =

sin kx,
cos kx,
T =

sin kvt = sin ωt,
cos kvt = cos ωt,
and so the solutions (4.2) for y are are
(4.5)
y =
 sin kx
cos kx
  sin ωt
cos ωt

where ω = kv.
Since the string is fastened at x = 0 and x = l, we must have y = 0 for these values
of x and all t. This means that we want only the sin kx factors in (4.5), and also
we select k so that sin kl = 0 or k = nπ/l. The solutions then become
(4.6)
y =





sin nπx
l
sin nπvt
l
,
sin nπx
l
cos nπvt
l
.
Figure 4.1
The particular combination of solu-
tions (4.6) that we should take to solve
a given problem depends on the initial
conditions.
For example, suppose the
string is started vibrating by plucking
(that is, pulling it aside a small distance
h at the center and letting go). Then
we are given the shape of the string at t = 0, namely y0 = f(x) as in Figure
4.1, and also the fact that the velocity ∂y/∂t of points on the string is zero at
t = 0. (Do not confuse ∂y/∂t with the wave velocity v; there is no relation between

Section 4
The Wave Equation; the Vibrating String
635
them.) In (4.6) we must then discard the term containing sin (nπvt/l) since its time
derivative is not zero when t = 0. Thus the basis functions for this problem are
sin (nπx/l) cos (nπvt/l) and we write the solution in the form
(4.7)
y =
∞

n=1
bn sin nπx
l
cos nπvt
l
.
The coeﬃcients bn are to be determined so that at t = 0 we have y0 = f(x), that
is,
(4.8)
y0 =
∞

n=1
bn sin nπx
l
= f(x).
As in previous problems, we ﬁnd the coeﬃcients in the Fourier sine series for the
given f(x) and substitute them into (4.7). The result is (Problem 1)
(4.9)
y = 8h
π2

sin πx
l cos πvt
l
−1
9 sin 3πx
l
cos 3πvt
l
+ . . .

.
Another way to start the string vibrating is to hit it (a piano string, for example).
In this case the initial conditions would be y = 0 at t = 0, with the velocity ∂y/∂t
at t = 0 given as a function of x (that is, the velocity of each point of the string
is given at t = 0). This time we discard in (4.6) the term containing cos (nπvt/l)
because it is not zero at t = 0. Then, for this problem, the basis functions are
sin (nπx/l) sin (nπvt/l) and the solution is of the form
(4.10)
y =
∞

n=1
Bn sin nπx
l
sin nπvt
l
.
Here the coeﬃcients must be determined so that
(4.11)
∂y
∂t

t=0
=
∞

n1
Bn
nπv
l
sin nπx
l
=
∞

n=1
bn sin nπx
l
= V (x),
that is, V (x), the given initial velocity, must be expanded in a Fourier sine series
(see Problems 5 to 8).
Suppose the string is vibrating in such a way that, instead of an inﬁnite series
for y, we have just one of the solutions (4.6), say
(4.12)
y = sin nπx
l
sin nπvt
l
for some one value of n. The largest value of sin (nπvt/l), for any t, is 1, and the
shape of the string then is
(4.13)
y = sin nπx
l
.
Graphs of (4.13) are sketched in Figure 4.2 for n = 1, 2, 3, 4. (The graphs are ex-
aggerated! Remember that the displacements are actually very small.) Consider

636
Partial Differential Equations
Chapter 13
Figure 4.2
a point x on the string; for this point sin (nπx/l) is some number, say A. Then the
displacement of this point at time t is [from (4.12)]
(4.14)
y = A sin nπvt
l
.
As time passes, this point of the string oscillates up and down with frequency νn
given by ωn = nπv/l = 2πνn or νn = nv/(2l); the amplitude of the oscillation at
this point is A = sin (nπx/l) (see Figure 4.2). Other points of the string oscillate
with diﬀerent amplitudes but the same frequency.
This is the frequency of the
musical note which the string is producing. (See Chapter 7, Section 10.) If n = 1
(see Figure 4.2), the frequency is v/(2l); in music this tone is called the fundamental
or ﬁrst harmonic. If n = 2, the frequency is just twice that of the fundamental; this
tone is called the ﬁrst overtone or the second harmonic; etc. All the frequencies
which this string can produce are multiples of the fundamental. These frequencies
are called the characteristic frequencies of the string. (They are proportional to the
characteristic values or eigenvalues, k = nπ/l.) The corresponding ways in which
the string may vibrate producing a pure tone of just one frequency [that is, with y
given by (4.12) for one value of n] are called the normal modes of vibration. The
ﬁrst four normal modes are indicated in Figure 4.2. Any vibration is a combination
of these normal modes [for example, (4.9) or (4.10)]. The solution (4.12) (for one
n) describing one normal mode, is a characteristic function or eigenfunction.
The waves in Figure 4.2 are called standing waves. The d’Alembert solution
of the wave equation (see Problem 1.2) represents traveling waves. Suppose we
combine two traveling waves moving in opposite directions as follows:
(4.15)
cos k(x −vt) −cos k(x + vt) = 2 sin kx sin kvt
(by a trigonometry formula). This is one of the solutions (4.5) so we see that this
combination of two traveling waves produces a standing wave. Suppose these two
traveling waves are moving along a string which is fastened at x = 0 and at x = l.
First consider the wave cos k(x + vt) which is moving in the negative x direction
toward x = 0. When it reaches x = 0, it will be reﬂected, and the combination of
the incident and reﬂected waves must equal zero at x = 0 for all t. We see that
this is true in (4.15), so the wave cos k(x −vt) is the reﬂection of −cosk(x + vt).
Now consider cos k(x −vt) traveling toward x = l. When it reaches x = l and is
reﬂected, we can verify (Problem 10) that, if k = nπ/l, then the reﬂection at x = l
is −cos nπ
l (x + vt). We can think of a wave traveling back and forth between x = 0

Section 4
The Wave Equation; the Vibrating String
637
and x = l, being reﬂected at each end. The net result as we see from (4.15) is a
standing wave.
So far we have been considering problems in which a string is pinned at both
ends. We could, instead, have a “free” end; this means free to move up and down
along x = 0 or x = l, say by allowing the end to slide along a frictionless track.
The mathematical condition for this is ∂y/∂x = 0 at the free end (compare the
condition for an insulated face in Section 3). If the x = 0 end is free, we choose
the solution containing cos kx (since
∂
∂x cos kx = −k sin kx = 0 at x = 0). Then, if
the string is pinned at x = l, we want cos kl = 0, so kl = (n + 1
2)π. Thus the basis
functions when the x = 0 end is free, the x = l end is pinned, and the initial string
velocity is zero, are
(4.16)
y = cos

n + 1
2

πx
l
cos

n + 1
2

πvt
l
.
For a discussion of these functions, see Chapter 7, Section 11 and Problem 11.11.
PROBLEMS, SECTION 4
As in Sections 2 and 3, use a computer to plot your answers.
1.
Complete the plucked string problem to get equation (4.9).
2.
A string of length l has a zero initial velocity
and a displacement y0(x) as shown. (This ini-
tial displacement might be caused by stopping
the string at the center and plucking half of it.)
Find the displacement as a function of x and t.
Answer:
y = 8h
π2
∞
X
n=1
Bn sin nπx
l
cos nπvt
l
, where Bn = (2 sin nπ/4 −sin nπ/2)/n2.
3.
Solve Problem 2 if the initial
displacement is:
4.
Solve Problem 2 if the initial
displacement is:
5.
A string of length l is initially stretched straight; its
ends are ﬁxed for all t. At time t = 0, its points are
given the velocity V (x) = (∂y/∂t)t=0 as indicated
in the diagram (for example, by hitting the string).
Determine the shape of the string at time t, that is,
ﬁnd the displacement y as a function of x and t in the form of a series similar to
(4.9). Warning: What basis functions do you need here?
Answer:
y = 8hl
π3v
„
sin πx
l sin πvt
l
−1
33 sin 3πx
l
sin 3πvt
l
+ 1
53 sin 5πx
l
sin 5πvt
l
−· · ·
«
.

638
Partial Differential Equations
Chapter 13
6.
Do Problem 5 if the initial velocity V (x) = (∂y/∂t)t=0 is as shown.
Answer:
y = 4hl
π2v
„
sin πw
l
sin πx
l sin πvt
l
−1
9 sin 3πw
l
sin 3πx
l
sin 3πvt
l
+ · · ·
«
.
7.
Solve Problem 5 if the initial velocity is:
8.
Solve Problem 5 if the initial velocity is
V (x) =
(
sin 2πx/l,
0 < x < l/2,
0,
l/2 < x < l.
9.
In each of the Problems 1 to 8, ﬁnd the frequency of the most important harmonic.
10.
Verify that, if k = nπ
l , then the sum of the two traveling waves in equation (4.15) is
zero at x = l, for all t.
11.
Verify (4.16) and ﬁnd a similar formula for a string pinned at x = 0 and free at
x = l. Solve Problems 2, 3, and 4, for a string with a free end (a) at x = 0; (b) at
x = l.
12.
In Sections 2, 3, 4, we have solved a number of physics problems which led to
the expansion of a given f(x) in a Fourier sine series. Look at (2.9) and (2.25),
temperature in a plate; (3.12), heat ﬂow; (3.26), wave function for a particle in a
box; (4.7) and (4.10), displacement of a vibrating string plucked or struck. If we
have expanded a given f(x) in a Fourier sine series on (0, l), we can immediately
write the corresponding solutions for these six diﬀerent physics problems on the same
interval. Do this for f(x) = x −x2 on (0, 1), that is with l = 1. Make computer
plots of your results.
13.
Do Problem 12 for f(x) = 1 −cos 2x on (0, π).
14.
Do Problem 12 for f(x) = x −x3 on (0, 1).
5. STEADY-STATE TEMPERATURE IN A CYLINDER
Figure 5.1
Consider the following problem. Find the steady-state
temperature distribution u in a semi-inﬁnite solid cylin-
der (Figure 5.1) of radius a if the base is held at 100◦
and the curved sides at 0◦.
This sounds very much
like the problem of the temperature distribution in a
semi-inﬁnite plate. However, it is not convenient here
to use the solutions in rectangular coordinates, because
the boundary condition u = 0 is given for r = a rather
than for constant values of x or y. The natural vari-
ables for this problem are the cylindrical coordinates
r, θ, z. The temperature u inside the cylinder satisﬁes
Laplace’s equation since there are no sources of heat
there.

Section 5
Steady-state Temperature in a Cylinder
639
Laplace’s equation in cylindrical coordinates is (see Chapter 10, Section 9)
(5.1)
∇2u = 1
r
∂
∂r

r∂u
∂r

+ 1
r2
∂2u
∂θ2 + ∂2u
∂z2 = 0.
To separate the variables, we assume a solution of the form
(5.2)
u = R(r)Θ(θ)Z(z).
Substitute (5.2) into (5.1) and divide by RΘZ to get
(5.3)
1
R
1
r
d
dr

rdR
dr

+ 1
Θ
1
r2
d2Θ
dθ2 + 1
Z
d2Z
dz2 = 0.
The last term is a function only of z, while the other two terms do not contain z.
Therefore the last term is a constant and the sum of the ﬁrst two terms is minus
the same constant. Notice that neither of the ﬁrst two terms is constant alone since
both contain r.
In order to say that a term is constant, we must be sure that:
(a) it is a function of only one variable, and
(b) that variable does not appear elsewhere in the equation.
Thus we have
(5.4)
1
Z
d2Z
dz2 = K2,
Z =

eKz,
e−Kz.
Since we want the temperature u to tend to zero as z tends to inﬁnity, we call the
separation constant +K2 (K > 0) and then use only the e−Kz solution. Next write
(5.3) with the last term replaced by K2—see (5.4).
1
R
1
r
d
dr

rdR
dr

+ 1
Θ
1
r2
d2Θ
dθ2 + K2 = 0.
We can separate the variables by multiplying by r2.
(5.5)
r
R
d
dr

rdR
dr

+ 1
Θ
d2Θ
dθ2 + K2r2 = 0.
In (5.5) the second term is a function of θ only, and the other terms are independent
of θ. Thus we have
(5.6)
1
Θ
d2Θ
dθ2 = −n2,
Θ =

sin nθ,
cos nθ.
Here we must use −n2 as the separation constant and then require n to be an
integer for the following reason. When we locate a point using polar coordinates,
we can choose the angle as θ or as θ + 2mπ where m is any integer. But regardless
of the value of m, there is one physical point and one temperature there. The
mathematical formula for the temperature at the point must give the same value at

640
Partial Differential Equations
Chapter 13
θ as at θ+2mπ, that is, the temperature must be a periodic function of θ with period
2π. This is true only if the Θ solutions are sines and cosines instead of exponentials
(hence the negative separation constant) and the constant n is an integer (to give
period 2π). The solutions of (5.6) when n = 0 are θ and constant. Since θ is not
periodic, we can use only the constant solution which is already contained in the
cos nθ solution when n = 0.
Finally, the r equation is
r
R
d
dr

rdR
dr

−n2 + K2r2 = 0
or
(5.7)
r d
dr

rdR
dr

+

K2r2 −n2
R = 0.
This is a Bessel equation with solutions Jn(Kr) and Nn(Kr) [see Chapter 12,
equation (16.5)]. Since the base of the cylinder contains the origin, we can use only
the Jn and not the Nn solutions since Nn becomes inﬁnite at the origin. Hence we
have
(5.8)
R(r) = Jn(Kr).
We can ﬁnd the possible values of K from the condition that the temperature is
zero on the curved surface of the cylinder. Thus u = 0 when r = a (for all θ and
z) or R(r) = 0 when r = a. So from (5.8) we see that Jn(Ka) = 0, that is, the
possible values of Ka are the zeros of Jn. If we deﬁne k = Ka, or K = k/a, then
(5.9)
R(r) = Jn(kr/a)
and
Z(z) = e−kz/a.
Thus the solutions for u are
(5.10)
u =

Jn(kr/a) sin nθ e−kz/a,
Jn(kr/a) cos nθ e−kz/a,
where k is a zero of Jn.
For our problem, the base of the cylinder is held at a constant temperature of
100◦. If we turn the cylinder through any angle the boundary conditions are not
changed; thus the solution does not depend on the angle θ. This means that we use
cos nθ with n = 0 in (5.10). The possible values of k are the zeros of J0; call these
zeros km, where m = 1, 2, 3, · · ·. Thus we have the basis functions for the problem
and write the solution in terms of them:
(5.11)
u =
∞

m=1
cmJ0(kmr/a)e−kmz/a.
When z = 0, we want u = 100, that is,
(5.12)
uz=0 =
∞

m=1
cmJ0(kmr/a) = 100.

Section 5
Steady-state Temperature in a Cylinder
641
This should remind you of a Fourier series; here we want to expand 100 in a series
of Bessel functions instead of a series of sines or cosines. We proved [see Chapter
12, equation (19.11)] that the functions J0(kmr/a) are orthogonal on (0, a) with
respect to the weight function r. We can then ﬁnd the coeﬃcients cm in (5.12) by
the same method used in ﬁnding the coeﬃcients in a Fourier sine or cosine series.
(In fact, series like (5.12) are often called Fourier-Bessel series.) Multiply (5.12)
by rJ0(kµr/a), µ = 1, 2, 3, · · ·, and integrate term by term from r = 0 to r = a.
Because of the orthogonality [see Chapter 12, equation (19.11)], all terms of the
series drop out except the term with m = µ, and we have
(5.13)
cµ
 a
0
r [J0(kµr/a)]2 dr =
 a
0
100rJ0(kµr/a) dr.
For each value of µ = 1, 2, 3, · · ·, equation (5.13) gives one of the coeﬃcients in
(5.11) and (5.12); thus any cm in (5.11) is given by (5.13) with µ replaced by m.
We need to evaluate the integrals in (5.13). Equation (19.11) of Chapter 12
gives (for p = 0, α = β = km)
(5.14)
 a
0
r [J0(kmr/a)]2 dr = a2
2 J2
1(km).
By equation (15.1) of Chapter 12
d
dx [xJ1(x)] = xJ0(x).
If we put x = kmr/a in this formula, we get
a
km
d
dr [(kmr/a)J1(kmr/a)] = (kmr/a)J0(kmr/a).
Cancelling one km/a factor and integrating from 0 to a, we have
(5.15)
 a
0
rJ0(kmr/a) dr =
a
km
rJ1(kmr/a)

a
0
= a2
km
J1(km).
Now we write (5.13) for cm, substitute the values of the integrals from (5.14) and
(5.15), and solve for cm. The result is
(5.16)
cm = 100a2J1(km)
km
·
2
a2J2
1(km) =
200
kmJ1(km).
The solution of our problem is now (5.11) with the values of cm given by (5.16).
The numerical value of the temperature at any point can be found by computing a
few terms of the series (Problem 1). The values of the zeros and of the Bessel func-
tions can be found either from your computer or from tables. Warning: Remember
that km is a zero of J0, not of J1.
Suppose the given temperature of the base of the cylinder is more complicated
than just a constant value, say f(r, θ), some function of r and θ. Down to (5.10)
we proceed as before. But now the series solution is more complicated than (5.11)
since we must include all Jn’s instead of just J0. We need a double subscript on the
numbers k which are the zeros of the Bessel functions; by kmn we shall mean the

642
Partial Differential Equations
Chapter 13
mth positive zero of Jn, where n = 0, 1, 2, · · · and m = 1, 2, 3, · · ·. The temperature
u is a double inﬁnite series, summed over the indices m, n of all zeros of all the Jn’s:
(5.17)
u =
∞

m=1
∞

n=0
Jn(kmnr/a)(Amn cos nθ + Bmn sin nθ)e−kmnz/a.
At z = 0, we want u = f(r, θ). Thus we write
(5.18)
uz=0 =
∞

m=1
∞

n=0
Jn(kmnr/a)(Amn cos nθ + Bmn sin nθ) = f(r, θ).
To determine the coeﬃcients Amn, multiply this equation by Jν(kµνr/a) cos νθ and
integrate over the whole base of the cylinder, (0 to 2π for θ, 0 to a for r). Because
of the orthogonality of the functions sin nθ and cos nθ on (0, 2π), all the Bmn terms
drop out, and only the Amn terms for n = ν remain. Because of the orthogonality
of the functions Jn(kmnr/a) (one n, all m), only the one term Aµν remains. Thus
we have
(5.19)
 a
0
 2π
0
f(r, θ)Jν(kµνr/a) cos νθ r dr dθ
= Aµν
 a
0
 2π
0
J2
ν (kµνr/a) cos2 νθ r dr dθ = Aµν · a2
2 J2
ν+1(kµν) · π.
[The r integral is given by (19.11) of Chapter 12, and the θ integral by Chapter 7,
Section 4]. Notice how the weight function r in the Bessel function integral arises
here as part of the polar coordinate area element. Similarly, we can ﬁnd
(5.20)
Bµν =
2
πa2J2
ν+1(kµν)
 a
0
 2π
0
f(r, θ)Jν(kµνr/a) sin νθ r dr dθ.
By substituting the values of the A and B coeﬃcients from (5.19) and (5.20) into
(5.17), we ﬁnd the solution to the problem.
PROBLEMS, SECTION 5
1.
(a)
Compute numerically the coeﬃcients (5.16) of the ﬁrst three terms of the series
(5.11) for the steady-state temperature in a solid semi-inﬁnite cylinder when
u = 0 at r = 1, and u = 100 at z = 0. Find u at r = 1
2, z = 1.
(b)
In part (a), if u = 0 at r = 10 and u = 100 at z = 0, ﬁnd u at r = 5, z = 10.
What is the relation between parts (a) and (b)? Hint: Suppose in part (a) that
the length units for r and z are centimeters. Consider the identical physics
problem but with distances measured in millimeters, and compare part (b).
Note that in equation (5.10), r/a and z/a are just measurements as multiples
of the radius a.
2.
(a)
Find the steady-state temperature distribution in a solid semi-inﬁnite cylinder
if the boundary temperatures are u = 0 at r = 1 and u = y = r sin θ at z = 0.
Hints: In (5.10) you want the solution containing sin θ; therefore you want
the functions J1. You will need to integrate r2J1; follow the text method of
integrating rJ0 just before (5.15).

Section 5
Steady-state Temperature in a Cylinder
643
(b)
Do part (a) if the cylinder radius is r = a.
Answer:
u =
∞
X
m=1
2a
kmJ2(km)J1(kmr/a)e−kmz/a sin θ,
km = zeros of J1.
If a = 2, ﬁnd u when r = 1, z = 1, θ = π/2.
3.
(a)
Find the steady-state temperature distribution in a solid cylinder of height 10
and radius 1 if the top and curved surface are held at 0◦and the base at 100◦.
Hint: See Section 2.
(b)
Generalize part (a) to a cylinder of height H and radius a.
4.
A ﬂat circular plate of radius a is initially at temperature 100◦. From time t = 0 on,
the circumference of the plate is held at 0◦. Find the time-dependent temperature
distribution u(r, θ, t). Hint: Separate variables in equation (3.1) in polar coordinates.
5.
Do Problem 4 if the initial temperature distribution is u(r, θ, t = 0) = 100r sin θ.
6.
Consider Problem 4 if the initial temperature distribution is given as some function
f(r, θ). The solution is, in general, a double inﬁnite series similar to (5.17). Find
formulas for the coeﬃcients in the series.
7.
Find the steady-state temperature distribution in a solid cylinder of height 20 and
radius 3 if the ﬂat ends are held at 0◦and the curved surface at 100◦. Hints: Use
−K2 in (5.4). Also see Chapter 12, Sections 17 and 20.
8.
Water at 100◦is ﬂowing through a long pipe of radius 1 rapidly enough so that we
may assume that the temperature is 100◦at all points. At t = 0, the water is turned
oﬀand the surface of the pipe is maintained at 40◦from then on (neglect the wall
thickness of the pipe). Find the temperature distribution in the water as a function
of r and t. Note that you need only consider a cross section of the pipe.
Answer:
u = 40 +
∞
X
m=1
120
kmJ1(km)J0(kmr)e−(αkm)2t,
where J0(km) = 0.
9.
Find the steady-state distribution of temperature in a cube of side 10 if the tem-
perature is 100◦on the face z = 0 and 0◦on the other ﬁve faces. Hint: Separate
Laplace’s equation in three dimensions in rectangular coordinates, and follow the
methods of Section 2. You will want to expand 100 in the double Fourier series
∞
X
n=1
∞
X
m=1
anm sin nπx
l
sin mπy
l
.
The coeﬃcients anm are determined by using the orthogonality of the functions
sin (nπx/l) sin (mπy/l) over the square, that is,
Z l
0
Z l
0
sin nπx
l
sin mπy
l
sin pπx
l
sin qπy
l
dx dy = 0
unless
(
n = p,
m = q.
10.
A cube is originally at 100◦. From t = 0 on, the faces are held at 0◦. Find the
time-dependent temperature distribution.
Hint: This problem leads to a triple
Fourier series; see the double Fourier series in Problem 9 and generalize it to three
dimensions.

644
Partial Differential Equations
Chapter 13
11.
The following two R(r) equations arise in various separation of variables problems
in polar, cylindrical, or spherical coordinates:
r d
dr
„
r dR
dr
«
= n2R,
d
dr
„
r2 dR
dr
«
= l(l + 1)R.
There are various ways of solving them: They are a standard kind of equation (often
called Euler or Cauchy equations—see Chapter 8, Section 7d); you could use power
series methods; given the fact that the solutions are just powers of r, it is easy to
ﬁnd the powers. Choose any method you like, and solve the two equations for future
reference. Consider the case n = 0 separately. Is this necessary for l = 0?
12.
Separate Laplace’s equation in two dimensions in polar coordinates
[equation (5.1) without the z term] and solve the r and θ equations.
(See Problem 11.) Remember that for the θ equation, only periodic
solutions are of interest. Use your results to solve the problem of the
steady-state temperature in a circular plate if the upper semicircular
boundary is held at 100◦and the lower at 0◦.
Comment: Another physical problem whose mathematical solution is identical
with this temperature problem is this: Find the electrostatic potential inside a
capacitor formed by two half-cylinders, insulated from each other and maintained
at potentials 0 and 100.
Answer:
u = 50 + 200
π
X
odd n
“ r
a
”n sin nθ
n
.
13.
Find the steady-state distribution of temperature in the sector
of a circular plate of radius 10 and angle π/4 if the temperature
is maintained at 0◦along the radii and at 100◦along the curved
edge. Hint: See Problem 12.
14.
Find the steady state temperature distribution in a circular annulus
(shaded area) of inner radius 1 and outer radius 2 if the inner circle
is held at 0◦and the outer circle has half its circumference at 0◦
and half at 100◦. Hint: Don’t forget the r solutions corresponding
to k = 0.
15.
Solve Problem 14 if the temperatures of the two circles are interchanged.
6. VIBRATION OF A CIRCULAR MEMBRANE
A circular membrane (for example, a drumhead) is attached to a rigid support along
its circumference. Find the characteristic vibration frequencies and the correspond-
ing normal modes of vibration.
Take the (x, y) plane to be the plane of the circular support and take the origin
at its center. Let z(x, y, t) be the displacement of the membrane from the (x, y)
plane. Then z satisﬁes the wave equation
(6.1)
∇2z = 1
v2
∂2z
∂t2 .
Putting
(6.2)
z = F(x, y)T (t),

Section 6
Vibration of a Circular Membrane
645
we separate (6.1) into a space equation (Helmholtz) and a time equation (see Prob-
lem 3.10 and Section 3). We get the two equations
(6.3)
∇2F + K2F = 0
and
¨T + K2v2T = 0.
Because the membrane is circular we write ∇2 in polar coordinates (see Chapter 10,
Section 9); then the F equation is
(6.4)
1
r
∂
∂r

r∂F
∂r

+ 1
r2
∂2F
∂θ2 + K2F = 0.
When we put
(6.5)
F = R(r)Θ(θ),
(6.4) becomes (5.5), and the separated equations and their solutions are just (5.6),
(5.7), and (5.8). The solutions of the time equation (6.3) are sinKvt and cos Kvt.
Thus the solutions for z are z = R(r)Θ(θ)T (t), where R(r) = Jn(Kr), Θ(θ) =
{sin nθ, cos nθ} and T (t) = {sin Kvt, cos Kvt}. Just as in Section 5, n must be an
integer. To ﬁnd possible values of K, we use the fact that the membrane is attached
to a rigid frame at r = a, so we must have z = 0 at r = a for all values of θ and t.
Thus Jn(Ka) = 0 so the possible values of Ka are the zeros of Jn. As in Section 5,
let k = Ka, that is, K = k/a. Then the possible values of k for each Jn are kmn,
the zeros of Jn. We can now write the solutions for z as
(6.6)
z = Jn(kr/a)
 sin nθ
cos nθ
  sin kvt/a
coskvt/a

.
For a given initial displacement or velocity of the membrane, we could ﬁnd z as
a double series as we found (5.17) in the cylinder temperature problem. However,
here we shall do something diﬀerent, namely investigate the separate normal modes
of vibration and their frequencies. Recall that for the vibrating string (Section 4),
each n gives a diﬀerent frequency and a corresponding normal mode of vibration
(Figure 4.2).
The frequencies of the string are ν = nv/(2l); all frequencies are
integral multiples of the frequency ν1 = v/(2l) of the fundamental. For the circular
membrane, the frequencies are [from (6.6)]
ν = ω
2π = kv
2πa.
The possible values of k are the zeros kmn of the Bessel functions. Each value of
kmn gives a frequency νmn = kmnv/(2πa), so we have a doubly inﬁnite set of char-
acteristic frequencies and the corresponding normal modes of vibration. All these
frequencies are diﬀerent, and they are not integral multiples of the fundamental as
is true for the string. This is why a drum is less musical than a violin. From your
computer or tables you can ﬁnd several kmn values (Problem 2) and ﬁnd the fre-
quencies as (nonintegral) multiples of the fundamental (which corresponds to k10,
the ﬁrst zero of J0). Let us sketch a few graphs (Figure 6.1) of the normal vibration
modes corresponding to those in Figure 4.2 for the string, and write the correspond-
ing formulas (eigenfunctions) for the displacement z given in (6.6). (For simplicity,
we have used just the cos nθ cos kvt/a solutions in Figure 6.1.) In the fundamental
mode of vibration corresponding to k10, the membrane vibrates as a whole. In the

646
Partial Differential Equations
Chapter 13
Figure 6.1
k20 mode, it vibrates in two parts as shown, the + part vibrating up while the
−part vibrates down, and vice versa, with the circle between them at rest. We
can show that there is such a circle (called a nodal line) and ﬁnd its radius. Since
k20 > k10, the circle r = ak10/k20 is a circle of radius less than a. Hence it is a circle
on the membrane. For this value of r, J0(k20r/a) = J0(k20k10/k20)) = J0(k10) = 0,
so points on this circle are at rest. For the k11 mode, cos θ = 0 when θ = ±π/2 and
is positive or negative as shown. Continuing in this way you can sketch any normal
mode (Problem 1).
It is diﬃcult experimentally to obtain pure normal modes of a vibrating object.
However, a complicated vibration will have nodal lines of some kind and it is easy
to observe these. Fine sand sprinkled on the vibrating object will collect along the
nodal lines (where there is no vibration) so that you can see them clearly—but
see Am. J. Phys. 72, 1345–1346, (2004). [For experimental work on the vibrating
circular membrane, see Am. J. Phys. 35, 1029–1031, (1967); Am. J. Phys. 40,
186–188, (1972); Am. J. Phys. 59, 376–377, (1991). Also see Problem 1(b).]
PROBLEMS, SECTION 6
1.
(a)
Continue Figure 6.1 to show the fundamental modes of vibration of a circular
membrane for n = 0, 1, 2, and m = 1, 2, 3. As in Figure 6.1, write the formula
for the displacement z under each sketch.
(b)
Use a computer to set up animations of the various modes of vibration of a
circular membrane. [This has been discussed in a number of places. See, for
example, Am. J. Phys. 67, 534–537, (1999).]
2.
Find, from computer or tables, the ﬁrst three zeros kmn of each of the Bessel func-
tions J0, J1, J2, and J3. Find the ﬁrst six frequencies of a vibrating circular mem-
brane as (non-integral) multiples of the fundamental frequency.
3.
Separate the wave equation in two-dimensional rectangular coordinates x, y. Con-
sider a rectangular membrane as shown, rigidly attached to supports along its sides.

Section 7
Steady-state Temperature in a Sphere
647
Show that its characteristic frequencies are
νnm = (v/2)
p
(n/a)2 + (m/b)2,
where n and m are positive integers, and sketch the normal
modes of vibration corresponding to the ﬁrst few frequen-
cies. That is, indicate the nodal lines as we did for the
circular membrane in Figure 6.1 and Problem 1.
Next suppose the membrane is square.
Show that in this case there may be
two or more normal modes of vibration corresponding to a single frequency. (Hint
for one example: 72 + 11 = 12 + 72 = 52 + 52.) This is an example of what is
called degeneracy; we say that there is degeneracy when several diﬀerent solutions
of the wave equation (eigenfunctions) correspond to the same frequency (eigenvalue).
Sketch several normal modes giving rise to the same frequency. Comment: Compare
Chapter 3, Section 11, where an eigenvalue of a matrix is called degenerate if several
eigenvectors correspond to it.
4.
Find the characteristic frequencies for sound vibration in a rectangular box (say
a room) of sides a, b, c. Hint: Separate the wave equation in three dimensions in
rectangular coordinates. This problem is like Problem 3 but for three dimensions
instead of two. Discuss degeneracy (see Problem 3).
5.
A square membrane of side l is distorted into the shape
f(x, y) = xy(l −x)(l −y)
and released. Express its shape at subsequent times as an inﬁnite series. Hint: Use
a double Fourier series as in Problem 5.9.
6.
Let V = 0 in the Schr¨odinger equation (3.22) and separate variables in 2-dimensional
rectangular coordinates. Solve the problem of a particle in a 2-dimensional square
box, 0 < x < l, 0 < y < l. This means to ﬁnd solutions of the Schr¨odinger equation
which are 0 for x = 0, x = l, y = 0, y = l, that is, on the boundary of the box, and
to ﬁnd the corresponding energy eigenvalues. Comments: If we extend the idea of
a “particle in a box” (see Section 3, Example 3) to two or three dimensions, the
box in 2D might be a square (as in this problem) or a circle (Problem 8); in 3D
it might be a cube (Problem 7.17) or a sphere (Problem 7.19). In all cases, the
mathematical problem is to ﬁnd solutions of the Schr¨odinger equation with V = 0
inside the box and Ψ = 0 on the boundary of the box, and to ﬁnd the corresponding
energy eigenvalues. In quantum mechanics, Ψ describes a particle trapped inside the
box and the energy eigenvalues are the possible values of the energy of the particle.
7.
In your Problem 6 solutions, ﬁnd some examples of degeneracy. (See Problem 3.
Degeneracy means that several eigenfunctions correspond to the same energy eigen-
value.)
8.
Do Problem 6 in polar coordinates to ﬁnd the eigenfunctions and energy eigenvalues
of a particle in a circular box r < a. You want Ψ = 0 when r = a.
7. STEADY-STATE TEMPERATURE IN A SPHERE
Find the steady-state temperature inside a sphere of radius a when the surface of
the upper half is held at 100◦and the surface of the lower half at 0◦.
Inside the sphere, the temperature u satisﬁes Laplace’s equation. In spherical
coordinates this is (see Chapter 10, Section 9)
(7.1)
∇2u = 1
r2
∂
∂r

r2 ∂u
∂r

+
1
r2 sin θ
∂
∂θ

sin θ∂u
∂θ

+
1
r2 sin2 θ
∂2u
∂φ2 = 0.

648
Partial Differential Equations
Chapter 13
We separate this equation following our standard procedure. Substitute
(7.2)
u = R(r)Θ(θ)Φ(φ)
into (7.1) and multiply by r2/RΘΦ to get
(7.3)
1
R
d
dr

r2 dR
dr

+ 1
Θ
1
sin θ
d
dθ

sin θdΘ
dθ

+ 1
Φ
1
sin2 θ
d2Φ
dφ2 = 0.
If we multiply (7.3) by sin2 θ, the last term becomes a function of φ only and the
other terms do not contain φ. Thus we obtain the φ equation and its solutions:
(7.4)
1
Φ
d2Φ
dφ2 = −m2,
Φ =

sin mφ,
cos mφ.
The separation constant must be negative and m an integer to make Φ a periodic
function of φ [see the discussion after (5.6)].
Equation (7.3) can now be written as
(7.5)
1
R
d
dr

r2 dR
dr

+ 1
Θ
1
sin θ
d
dθ

sin θdΘ
dθ

−
m2
sin2 θ = 0.
The ﬁrst term is a function of r and the last two terms are functions of θ, so we
have two equations
1
R
d
dr

r2 dR
dr

= k,
(7.6)
1
sin θ
d
dθ

sin θdΘ
dθ

−
m2
sin2 θΘ + kΘ = 0.
(7.7)
If you compare (7.7) with the equation of Problem 10.2 in Chapter 12, you will
see that (7.7) is the equation for the associated Legendre functions if k = l(l + 1).
Recall that l must be an integer in order for the solution of Legendre’s equation to
be ﬁnite at x = cos θ = ±1, that is, at θ = 0 or π; the same statement is true for
the equation for the associated Legendre functions. The corresponding result for
(7.7) is that k must be a product of two successive integers; it is then convenient
to replace k by l(l + 1), where l is an integer. The solutions of (7.7) are then the
associated Legendre functions (see Problem 10.2, Chapter 12)
(7.8)
Θ = P m
l (cos θ).
In (7.6), we put k = l(l + 1); you can then easily verify (Problem 5.11) that the
solutions of (7.6) are
(7.9)
R =

rl,
r−l−1.
Since we are interested in the interior of the sphere, we discard the solutions r−l−1
because they become inﬁnite at the origin. If we were discussing a problem (say
about water ﬂow or electrostatic potential) outside the sphere, we would use the
r−l−1 solutions and discard the solutions rl because they become inﬁnite at inﬁnity.

Section 7
Steady-state Temperature in a Sphere
649
The basis functions for our problem are then
(7.10)
u = rlP m
l (cos θ)

sin mφ,
cos mφ.
[The functions P m
l (cos θ) sin mφ and P m
l (cos θ) cos mφ are called spherical harmon-
icsand are often denoted by Y m
l (θ, φ); also see Problem 16.] If the surface tem-
perature at r = a were given as a function of θ and φ, we would have a double
series (summed on l and m). For the given surface temperatures in our problem
(100◦on the top hemisphere and 0◦on the lower hemisphere), the temperature is
independent of φ; thus in (7.10) we must have m = 0, cosmφ = 1. The solutions
(7.10) then reduce to rlPl(cos θ). We write the solution of the problem as a series
of these basis functions:
(7.11)
u =
∞

l=0
clrlPl(cos θ).
We determine the coeﬃcients cl by using the given temperatures when r = a; that
is, we must have
(7.12)
ur=a =
∞

l=0
clalPl(cos θ)
=
 100,
0 < θ < π
2 ,
that is,
0 < cos θ < 1,
0,
π
2 < θ < π,
that is,
−1 < cos θ < 0,
or, with x = cos θ,
ur=a =
∞

l=0
clalPl(x) = 100f(x)
(7.13)
where
f(x) =

0,
−1 < x < 0,
1,
0 < x < 1.
(Note that here x just stands for cos θ and is not the coordinate x.) In Section 9 of
Chapter 12, we expanded this f(x) in a series of Legendre polynomials and obtained:
(7.14)
f(x) = 1
2P0(x) + 3
4P1(x) −7
16P3(x) + 11
32P5(x) + . . . .
The coeﬃcients cl in (7.13) are just these coeﬃcients times 100/al. Substituting
the c’s into (7.11), we get the ﬁnal solution:
(7.15)
u = 100

1
2P0(cos θ) + 3
4
r
aP1(cos θ) −7
16
 r
a
3 P3(cos θ)
+ 11
32
 r
a
5 P5(cos θ) + . . .

.

650
Partial Differential Equations
Chapter 13
We can do variations of this problem. Notice that we have not even mentioned
so far what temperature scale we are using (Celsius, Fahrenheit, absolute, etc.).
This is a very easy adjustment to make once we have a solution in any one scale.
To see why, observe that if u is a solution of Laplace’s equation ∇2u = 0 or of the
heat ﬂow equation ∇2u = (1/α2)(∂u/∂t), then u + C and Cu are also solutions for
any constant C. If we add, say, 50◦to the solution (7.15), we have the temperature
distribution inside a sphere with the top half of the surface at 150◦and the lower half
at 50◦. If we multiply the solution (7.15) by 2, we ﬁnd the temperature distribution
with given surface temperatures of 200◦and 0◦, and so on.
The temperature of the equatorial plane θ = π/2 or cos θ = 0 as given by equa-
tions (7.11) to (7.15) is halfway between the top and bottom surface temperatures,
because Legendre series, like Fourier series, converge to the midpoint of a jump in
the function which was expanded to get the series. To solve the problem of the
temperature in a hemisphere given the temperatures of the curved surface and of
the equatorial plane, we need only imagine the lower hemisphere in place and at
the proper temperature to give the desired average on the equatorial plane. When
the temperature of the equatorial plane is 0◦, this amounts to deﬁning the function
f(x) in (7.13) on (−1, 0) to make it an odd function.
PROBLEMS, SECTION 7
Find the steady-state temperature distribution inside a sphere of radius 1 when the
surface temperatures are as given in Problems 1 to 10.
1.
35 cos4 θ
2.
cos θ −cos3 θ
3.
cos θ −3 sin2 θ
4.
5 cos3 θ −3 sin2 θ
5.
|cos θ|
6.
π/2−θ.
See Chapter 12, Problem 9.4.
7.
cos θ,
0 < θ < π/2,
that is, upper hemisphere,
0,
π/2 < θ < π,
that is, lower hemisphere.
8.
100◦,
0 < θ < π/3,
0◦,
otherwise.
Hint: See Problem 9.8 of Chapter 12.
9.
3 sin θ cos θ sin φ.
Hint: See equation (7.10) and Chapter 12, equation (10.6).
10.
sin2 θ cos θ cos 2φ −cos θ.
(See Problem 9.)
11.
Find the steady-state temperature distribution inside a hemisphere if the spherical
surface is held at 100◦and the equatorial plane at 0◦. Hint: See the last paragraph
of this section above.
12.
Do Problem 11 if the curved surface is held at cos2 θ and the equatorial plane at
zero. Careful: The answer does not involve P2; read the last sentence of this section.
13.
Find the electrostatic potential outside a conducting sphere of radius a placed in
an originally uniform electric ﬁeld, and maintained at zero potential.
Hint: Let
the original ﬁeld E be in the negative z direction so that E = −E0k. Then since
E = −∇Φ, where Φ is the potential, we have Φ = E0z = E0r cos θ (Verify this!)
for the original potential. You then want a solution of Laplace’s equation ∇2u = 0
which is zero at r = a and becomes u ∼Φ for large r (that is, far away from the

Section 7
Steady-state Temperature in a Sphere
651
sphere). Select the solutions of Laplace’s equation in spherical coordinates which
have the right θ and φ dependence (there are just two such solutions) and ﬁnd the
combination which reduces to zero for r = a.
14.
Find the steady-state temperature distribution in a spherical shell of inner radius
1 and outer radius 2 if the inner surface is held at 0◦and the outer surface has its
upper half at 100◦and its lower half at 0◦. Hint: r = 0 is not in the region of
interest, so the solutions r−l−1 in (7.9) should be included. Replace clrl in (7.11)
by (clrl + blr−l−1).
15.
A sphere initially at 0◦has its surface kept at 100◦from t = 0 on (for example, a
frozen potato in boiling water!). Find the time-dependent temperature distribution.
Hint: Subtract 100◦from all temperatures and solve the problem; then add the 100◦
to the answer. Can you justify this procedure? Show that the Legendre function
required for this problem is P0 and the r solution is (1/√r)J1/2 or j0 [see (17.4) in
Chapter 12]. Since spherical Bessel functions can be expressed in terms of elementary
functions, the series in this problem can be thought of as either a Bessel series or a
Fourier series. Show that the results are identical.
16.
Separate the wave equation in spherical coordinates, and show that the θ, φ solutions
are the spherical harmonics Y m
l (θ, φ) =P m
l (cos θ)e±imφ and the r solutions are the
spherical Bessel functions jl(kr) and yl(kr) [Chapter 12, equations (17.4)].
17.
Do Problem 6.6 in 3 dimensional rectangular coordinates. That is, solve the “particle
in a box” problem for a cube.
18.
Separate the time-independent Schr¨odinger equation (3.22) in spherical coordinates
assuming that V = V (r) is independent of θ and φ. (If V depends only on r, then
we are dealing with central forces, for example, electrostatic or gravitational forces.)
Hints: You may ﬁnd it helpful to replace the mass m in the Schr¨odinger equation
by M when you are working in spherical coordinates to avoid confusion with the
letter m in the spherical harmonics (7.10). Follow the separation of (7.1) but with
the extra term [V (r) −E]Ψ. Show that the θ, φ solutions are spherical harmonics
as in (7.10) and Problem 16. Show that the r equation with k = l(l + 1) is [compare
(7.6)]
1
R
d
dr
„
r2 dR
dr
«
−2Mr2
¯h2
[V (r) −E) = l(l + 1).
19.
Find the eigenfunctions and energy eigenvalues for a “particle in a spherical box”
r < a. Hints: See Problem 6.6. Write the R equation from Problem 18 with V = 0,
and compare Chapter 12, Problem 17.6, with y = R, x = βr where β =
p
2ME/¯h2,
and n = l.
20.
Write the Schr¨odinger equation (3.22) if ψ is a function of x, and V =
1
2mω2x2
(this is a one-dimensional harmonic oscillator). Find the solutions ψn(x) and the
energy eigenvalues En. Hints: In Chapter 12, equation (22.1) and the ﬁrst equation
in (22.11), replace x by αx where α =
p
mω/¯h. (Don’t forget appropriate factors
of α for the x’s in the denominators of D = d/dx and ψ′′ = d2ψ/dx2.) Compare
your results for equation (22.1) with the Schr¨odinger equation you wrote above to
see that they are identical if En = (n + 1
2)¯hω. Write the solutions ψn(x) of the
Schr¨odinger equation using Chapter 12, equations (22.11) and (22.12).
21.
Separate the Schr¨odinger equation (3.22) in rectangular coordinates in 3 dimensions
assuming that V = 1
2mω2(x2+y2+z2). (This is a 3-dimensional harmonic oscillator).
Observe that each of the separated equations is of the form of the one-dimensional
oscillator equation in Problem 20. Thus write the solutions ψn(x, y, z) for the 3-
dimensional problem, where n = nx + ny + nz. Find the energy eigenvalues En and
their degree of degeneracy (see Problem 6.7 and Chapter 15, Problem 4.21).

652
Partial Differential Equations
Chapter 13
22.
Find the energy eigenvalues and eigenfunctions for the hydrogen atom. The potential
energy is V (r) = −e2/r in Gaussian units, where e is the charge of the electron and r
is in spherical coordinates. Since V is a function of r only, you know from Problem 18
that the eigenfunctions are R(r) times the spherical harmonics Y m
l (θ, φ), so you only
have to ﬁnd R(r). Substitute V (r) into the R equation in Problem 18 and make the
following simpliﬁcations: Let x = 2r/α, y = rR; show that then
r = αx/2,
R(r) = 2
αxy(x),
d
dr = 2
α
d
dx,
d
dr
„
r2 dR
dr
«
= 2
αxy′′.
Let α2 = −2ME/¯h2 (note that for a bound state, E is negative, so α2 is positive)
and λ = Me2α/¯h2, to get the ﬁrst equation in Problem 22.26 of Chapter 12. Do
this problem to ﬁnd y(x), and the result that λ is an integer, say n. [Caution: not
the same n as in equation (22.26)]. Hence ﬁnd the possible values of α (these are
the radii of the Bohr orbits), and the energy eigenvalues. You should have found α
proportional to n; let α = na, where a is the value of α when n = 1, that is, the
radius of the ﬁrst Bohr orbit. Write the solutions R(r) by substituting back y = rR,
and x = 2r/(na), and ﬁnd En from α.
8. POISSON’S EQUATION
We are going to derive Poisson’s equation (1.2) for a simple problem whose answer
we know in advance. Using our known solution, we shall be able to see a method
of solving more diﬃcult problems.
Recall from Chapter 6, Section 8, that the gravitational ﬁeld is conservative,
that is, curl F = 0, and there is a potential function V such that F = −∇V . If
we consider the gravitational ﬁeld at a point P due to a point mass m a distance r
away, we have
(8.1)
V = −Gm
r
and
F = −Gm
r2 u
where u is a unit vector along r toward P.
It is straightforward to show that
div F = 0 and V satisﬁes Laplace’s equation (Problem 1), that is,
(8.2)
∇· F = −∇· ∇V = −∇2V = 0.
Now suppose there are many masses mi at distances ri from P.
The total
potential at P is the sum of the potentials due to the individual mi, that is,
V =

i
Vi = −

i
Gmi
ri
and the total gravitational ﬁeld at P is the vector sum of the ﬁelds Fi, that is,
F = −

i
∇Vi = −∇V.
Note that we are taking it for granted that none of the masses mi are at P, that is,
that no ri is zero. Since
∇· Fi = −∇2Vi = 0,

Section 8
Poisson’s Equation
653
we have also
∇· F = −∇2V = 0.
Figure 8.1
Instead of a number of masses mi, we can
consider a continuous distribution of mass
inside a volume τ (Figure 8.1). Let ρ be the
mass density of the distribution; then the
mass in an element dτ is ρ dτ. The gravita-
tional potential at P due to this mass ρdτ is
−(Gρ/r) dτ. Then the total gravitational po-
tential at P due to the whole mass distribution
is the triple integral over the volume τ:
(8.3)
V = −

volume τ
Gρ dτ
r
.
As before, the contribution to V at P due to each bit of mass satisﬁes Laplace’s
equation and therefore V satisﬁes Laplace’s equation. Also the total ﬁeld F at P is
the vector sum of the ﬁelds due to the elements of mass, and as before we have
∇· F = −∇2V = 0.
Again note that we are implicitly assuming that none of the mass distribution
coincides with P, that is, that r ̸= 0, which means that point P is not a point of
the region τ.
Figure 8.2
Now let us investigate what happens if P is a point of τ. Can we ﬁnd V from (8.3)
and does V satisfy Laplace’s equation? Let S be a small sphere of radius a about
P; imagine all the mass removed from inside S (Figure 8.2). Then our previous dis-
cussion holds at points inside S since
these points are not in the mass distri-
bution. If F′ and V ′ are the new ﬁeld
and potential (with the matter inside
S removed), then ∇· F′ = −∇2V ′ = 0
at points inside S. Now restore the mass
inside S; let F and V represent the ﬁeld
and potential due to the whole distri-
bution and let FS and VS represent the
ﬁeld and potential due to just the mass
inside S.
Then F = F′ + FS and at
points inside S
(8.4)
∇· F = ∇· F′ + ∇· FS = ∇· FS
since ∇· F′ = 0 inside S.
By the divergence theorem (see Figure 8.2 and Chapter 6, Section 10)
(8.5)

volume of S
∇· FS dτ =

surface of S
FS · n dσ.
If we let the radius a of S tend to zero, the density ρ of matter inside S tends to
its value at P; thus for small a, S contains a total mass M approximately equal to

654
Partial Differential Equations
Chapter 13
4
3πa3ρ, where ρ is evaluated at P. The gravitational ﬁeld at the surface of S due
to this mass is of magnitude
Fs = GM
a2
= G4
3πaρ
directed toward P. Thus in (8.5), FS · n = −4
3Gπaρ because FS and n are antipar-
allel. Since FS is constant over the surface S, the right-hand side of (8.5) is FS · n
times the area of the sphere. The left-hand side is, for small a, approximately the
value of ∇· FS at P times the volume of S. Then we have
(∇· FS)(4
3πa3) = (−4
3Gπaρ)(4πa2)
or
(8.6)
∇· FS = −4πGρ
at P.
Since
∇· FS = ∇· F = −∇· ∇V = −∇2V,
we have
(8.7)
∇2V = 4πGρ.
This is Poisson’s equation; we see that the gravitational potential in a region con-
taining matter satisﬁes Poisson’s equation as claimed in (1.2). Note that if ρ = 0,
(8.7) becomes (8.2) as it should.
Next we must consider whether our formula (8.3) for V is valid when P is a
point of the mass distribution. The integral appears to diverge at r = 0, but this
is not really so as we see most easily by using spherical coordinates. Then (8.3)
becomes
V = −

volume τ
Gρ
r r2 sin θ dr dθ dφ
and we see that there is no trouble when r = 0. Thus (8.3) is valid in general and
gives a solution for (8.7).
Using the notation of (1.2) for Poisson’s equation [that is, replacing 4πGρ by f
and V by u in (8.7) and (8.3)] we can write
(8.8)
u = −1
4π
 f dτ
r
is a solution of
∇2u = f.
In the more detailed notation needed when we use this solution in a problem, (8.8)
becomes (see Figure 8.3):
(8.9)
u(x, y, z) = −1
4π

f(x′, y′, z′)

(x −x′)2 + (y −y′)2 + (z −z′)2 dx′ dy′ dz′
is a solution of
∇2u(x, y, z) = f(x, y, z)

Section 8
Poisson’s Equation
655
Figure 8.3
In (8.9) and Figure 8.3, the point (x, y, z) is the
point at which we are calculating the potential u;
the point (x′, y′, z′) is a point in the mass distri-
bution over which we integrate; r in (8.8) is the
distance between these two points and is written
out in full in (8.9).
Equations (8.8) or (8.9) actually give a very
special solution of Poisson’s equation. Recall that
it is customary to take the zero point for gravita-
tional (and electrostatic) potential energy at inﬁn-
ity, and this is what we have done. Thus (8.8) or (8.9) gives a solution of Poisson’s
equation which tends to zero at inﬁnity. In another problem this may not be what
we want. For example, suppose we have an electrostatic charge distribution near
a grounded plane. The electrostatic potential satisﬁes Poisson’s equation, but here
we want a solution which is zero on the grounded plane rather than at inﬁnity. To
see how we might ﬁnd such a solution, observe that if u is a solution of Poisson’s
equation, and w is any solution of Laplace’s equation (∇2w = 0), then
(8.10)
∇2(u + w) = ∇2u + ∇2w = ∇2u = f;
thus u + w is a solution of Poisson’s equation. Then we can add to the solution
(8.9) any solution of Laplace’s equation; the combination must be adjusted to ﬁt
the given boundary conditions just as we have done in the problems in previous
paragraphs.
Example 1.
Let us do the following simple problem to illustrate this process. In Figure
8.4, a point charge q at (0, 0, a) is outside a grounded sphere of radius R and center
FIgure 8.4
at the origin. Our problem is to ﬁnd the electrostatic potential V at points outside
the sphere.
The potential V and the charge density ρ are related by Poisson’s
equation
(8.11)
∇2V = −4πρ
(in Gaussian units).
The potential at (x, y, z) due to a given charge distribution ρ is given by (8.8) or

656
Partial Differential Equations
Chapter 13
(8.9) with f = −4πρ:
(8.12)
V (x, y, z) = −1
4π

−4πρ(x′, y′, z′)

(x −x′)2 + (y −y′)2 + (z −z′)2 dx′ dy′ dz′.
For a given space-charge distribution, we would next evaluate this integral. For the
single point charge q, we have (x′, y′, z′) = (0, 0, a) and we replace  ρ dx′ dy′ dz′
(which is simply the total charge) by q to obtain
(8.13)
V =
q

x2 + y2 + (z −a)2 .
[We could, of course, simply have written down (8.13) without using (8.8); (8.13) is
just the electrostatic formula corresponding to the gravitational formula (8.1) with
which we started.]
Now we want to add to (8.13) a solution of Laplace’s equation such that the
combination is zero on the given sphere (Figure 8.4). It will be convenient to change
to spherical coordinates and to use solutions of Laplace’s equation in spherical
coordinates. [Note a change in the meaning of r from now on. We have been using
r to mean the distance from q at (x′, y′, z′) to (x, y, z); from now on we want to
use it to mean the distance from (0, 0, 0) to (x, y, z). See, for example, Figures 8.3
and 8.4.] Writing Vq for V in (8.13) (to distinguish it from our ﬁnal answer which
will be a sum of Vq and a solution of Laplace’s equation) and changing to spherical
coordinates, we get
(8.14)
Vq =
q
√
r2 −2ar cos θ + a2 .
The solutions of Laplace’s equation in spherical coordinates are (Section 7):
(8.15)

rl
r−l−1

P m
l (cos θ)

sin mφ
cos mφ

.
Since we are interested in the region outside the sphere, we want r solutions which
do not become inﬁnite at inﬁnity; thus we use r−l−1 and discard the rl solutions.
Because the physical problem is symmetric about the z axis, we look for solutions
independent of φ; that is, we choose m = 0, cos mφ = 1. Then the basis functions
for our problem are r−l−1Pl(cos θ) and we try to ﬁnd a solution of the form
(8.16)
V = Vq +

l
clr−l−1Pl(cos θ).
We must satisfy the boundary condition V = 0 when r = R. This gives
(8.17)
Vr=R =
q
√
R2 −2aR cos θ + a2 +

l
clR−l−1Pl(cos θ) = 0.
Thus we want to expand Vq in a Legendre series. Since Vq is essentially the gener-
ating function for Legendre polynomials, this is very easy. Comparing (8.17) and
the formulas of Chapter 12, Section 5 [(5.1) and (5.2), or more simply, (5.12) and
(5.17)], we ﬁnd
(8.18)
q
√
R2 −2aR cos θ + a2 = q

l
RlPl(cos θ)
al+1
.

Section 8
Poisson’s Equation
657
Thus the coeﬃcients cl in (8.17) are given by
(8.19)
clR−l−1 = −qRl
al+1
or
cl = −qR2l+1
al+1 .
Substituting (8.19) into (8.16), we obtain the ﬁnal solution for V :
(8.20)
V =
q
√
r2 −2ar cos θ + a2 −q

l
R2l+1r−l−1Pl(cos θ)
al+1
.
Since the second term in (8.20) is of the same general form as (8.18), we can
simplify (8.20) by summing the series to get (Problem 2)
(8.21)
V =
q
√
r2 −2ar cos θ + a2 −
(R/a)q

r2 + (R2/a)2 −2r(R2/a) cos θ
.
Formula (8.21) has a very interesting physical interpretation. The second term is
the potential of a charge −(R/a)q at the point (0, 0, R2/a); thus we could replace the
grounded sphere by this charge and have the same potential for r > R. This result
can be shown also by elementary analytic geometry and is known as the “method
of images.” For problems with simple geometry (involving planes, spheres, circular
cylinders), it may oﬀer a simpler method of solution than the one we have discussed;
however, our purpose was to illustrate the more general method.
Use of Green Functions
In Chapter 8, Section 12, we used Green functions
to solve ordinary diﬀerential equations with a nonzero right-hand side. Here we
consider the use of Green functions to solve a corresponding partial diﬀerential
equation in three dimensions, namely Poisson’s equation
(8.22)
∇2u = f(r) = f(x, y, z).
Suppose that we have a solution of Poisson’s equation when the right hand side is
a 3-dimensional δ function (see Chapter 8, Sections 11 and 12):
(8.23)
∇2G(r, r′) = δ(r −r′) = δ(x −x′)δ(y −y′)δ(z −z′).
The three-dimensional δ function has the property that
(8.24)

f(x′, y′, z′)δ(r −r′) dτ ′ = f(x, y, z)
if the volume of integration includes the point (x, y, z) (and the integral is zero
otherwise). Recall that the right-hand side of Poisson’s equation is proportional to
the mass density or the charge density. The volume integral of the density gives the
total mass or total charge. Since

δ(r −r′) dτ ′ = 1, the right-hand side of (8.23)
corresponds to a point mass or point charge. That is, the Green function in (8.23)
is the potential due to a point source. Just as we showed in Chapter 8, Section 12,
that (12.4) is a solution of (12.1), we ﬁnd here that a solution of (8.22) is given by
(see Problem 6)
(8.25)
u(r) =

G(r, r′)f(r′) dτ ′.

658
Partial Differential Equations
Chapter 13
In equation (8.9) we found that a solution of (8.22) is
(8.26)
u(r) = −1
4π

f(r′)
|r −r′| dτ ′.
Comparing (8.25) and (8.26), we conclude that a solution of (8.23) is
(8.27)
G(r, r′) = −
1
4π|r −r′|.
Now (8.26) and (8.27) give solutions which are zero at inﬁnity; usually we want
solutions which are zero on some given surface (for example, zero electrostatic po-
tential on a grounded sphere or plane). In order to obtain such a solution, we add
to (8.27) a solution F(r, r′) of Laplace’s equation chosen so that the new Green
function
(8.28)
G(r, r′) = −
1
4π|r −r′| + F(r, r′)
satisﬁes the desired zero boundary conditions. Then (8.25) with G(r, r′) as in (8.28)
gives a solution of (8.22) which is zero of the boundary. For example, in equation
(8.21), V is the potential outside the grounded sphere r = R due to a point charge
at r = a > R. Rewriting that result in our present notation gives the Green function
(8.28) which satisﬁes (8.23) and is zero on the sphere r = R, namely (Problem 7)
(8.29)
G(r, r′) = −
1
4π|r −r′| +
R/r′
4π|r −R2r′/r′2|.
(Also see Problems 8 and 9.)
PROBLEMS, SECTION 8
1.
Show that the gravitational potential V = −Gm/r satisﬁes Laplace’s equation, that
is, show that ∇2(1/r) = 0 where r2 = x2 + y2 + z2, r ̸= 0.
2.
Using the formulas of Chapter 12, Section 5, sum the series in (8.20) to get (8.21).
3.
Do the problem in Example 1 for the case of a charge q inside a grounded sphere
to obtain the potential V inside the sphere. Sum the series solution and state the
image method of solving this problem.
4.
Do the two-dimensional analogue of the problem in Example 1. A “point charge”
in a plane means physically a uniform charge along an inﬁnite line perpendicular to
the plane; a “circle” means an inﬁnitely long circular cylinder perpendicular to the
plane. However, since all cross sections of the parallel line and cylinder are the same,
the problem is a two-dimensional one. Hint: The potential must satisfy Laplace’s
equation in charge-free regions.
What are the solutions of the two-dimensional
Laplace equation?
5.
Find the method of images for problem 4.
6.
Substitute (8.25) into (8.22) and use (8.23) and (8.24) to show that (8.25) is a
solution of (8.22).
7.
Verify that the Green function in (8.29) is zero when r = R. Also verify that the
point at which the second term becomes inﬁnite is inside the sphere, so outside the
sphere this term satisﬁes Laplace’s equation as required. Thus write a triple integral
for the solution of (8.22) for r > R which is zero on the sphere r = R.

Section 9
Integral Transform Solutions of Partial Differential Equations
659
8.
Show that the Green function (8.28) which is zero on the plane z = 0 is
G(r, r′) = −1
4π
ˆ
(x −x′)2 + (y −y′)2 + (z −z′)2˜−1/2
+ 1
4π
ˆ
(x −x′)2 + (y −y′)2 + (z + z′)2˜−1/2 .
Hence write a triple integral for the solution of (8.22) for z > 0 which is zero for
z = 0.
9.
Show that our results can be extended to ﬁnd the following solution of (8.22) which
satisﬁes given nonzero boundary conditions:
u(r) =
ZZZ
G(r, r′)f(r′) dτ ′ +
ZZ
u(r′)∂G(r, r′)
∂n′
dσ′
where G(r, r′) is the Green function (8.28) which is zero on the surface σ, and
∂G/∂n′ = ∇G · n′ is the normal derivative of G (see Chapter 6, Section 6). Hints:
In Green’s second identity (Chapter 6, Problem 10.16) let φ = u(r) and ψ = G(r, r′),
and use (8.22) and (8.23) to ﬁnd ∇2φ and ∇2ψ. Comment: Although we derived the
divergence theorem and so Green’s identities only for bounded regions in Chapter 6,
they are valid for unbounded regions if the functions involved tend to zero suﬃciently
rapidly.
9. INTEGRAL TRANSFORM SOLUTIONS OF PARTIAL DIFFERENTIAL EQUATIONS
Laplace Transform Solutions
We have seen (Chapter 8, Section 9) that tak-
ing the Laplace transform of an ordinary diﬀerential equation converts it into an
algebraic equation. Taking the Laplace transform of a partial diﬀerential equation
reduces the number of independent variables by one, and so converts a two-variable
partial diﬀerential equation into an ordinary diﬀerential equation. To illustrate this,
we solve the following problem.
Example 1.
A semi-inﬁnite bar (extending from x = 0 to x = ∞), with insulated sides, is
initially at the uniform temperature u = 0◦. At t = 0, the end at x = 0 is brought
to u = 100◦and held there. Find the temperature distribution in the bar as a
function of x and t.
The diﬀerential equation satisﬁed by u is
(9.1)
∂2u
∂x2 = 1
α2
∂u
∂t .
We are going to take the t Laplace transform of (9.1); the variable x will just be a
parameter in this process. Let U be the Laplace transform of u, that is,
(9.2)
U(x, p) =
 ∞
0
u(x, t)e−pt dt.
By Chapter 8, equation (9.1) we have
L
∂u
∂t

= pU −ut=0 = pU
since u = 0 when t = 0. Also
L
∂2u
∂x2

= ∂2
∂x2 L(u) = ∂2U
∂x2

660
Partial Differential Equations
Chapter 13
(remember that x is just a parameter here; we are taking a t Laplace transform).
The transform of (9.1) is then
(9.3)
∂2U
∂x2 = 1
α2 pU.
Now if we think of p as a constant and x as the variable, this is an ordinary diﬀer-
ential equation for U as a function of x. Its solutions are
(9.4)
U =

e(√p/α)x,
e−(√p/α)x.
To ﬁnd the correct combination of these solutions to ﬁt our problem, we need the
Laplace transforms of the boundary conditions on u since these give the conditions
on U. Using L1 (see Laplace Transform Table, page 469) to ﬁnd the transforms,
we have
(9.5)
u = 100
at
x = 0,
U = L(100) = 100
p
at
x = 0;
u →0
as
x →∞,
U →L(0) = 0
as
x →∞.
Since U →0 as x →∞, we see that we must use the solution e−(√p/α)x from (9.4)
and discard the positive exponential solution. We determine the constant multiple
of this solution which ﬁts our problem from the condition that U = 100/p at x = 0.
Thus we ﬁnd that the U solution satisfying the given boundary conditions is
(9.6)
U = 100
p e−(√p/α)x.
We ﬁnd u by looking up the inverse transform of (9.6); it is, by L22
(9.7)
u = 100

1 −erf
x
2α
√
t

and this is the solution of the problem.
Fourier Transform Solutions
In the examples in Sections 2, 3 and 4, we ex-
panded a given function in a Fourier series. This was possible because the function
was to be represented by a series over a ﬁnite interval. We could then take that
interval as the period for the Fourier series. If we are dealing with a function which
is given over an inﬁnite interval (and not periodic), then instead of representing it
by a Fourier series we represent it by a Fourier integral (Chapter 7, Section 12).
Let us do this for a speciﬁc problem.
Example 2.
An inﬁnite metal plate (Figure 9.1) covering the ﬁrst quadrant has the edge
along the y axis held at 0◦, and the edge along the x axis held at
(9.8)
u(x, 0) =

100◦,
0 < x < 1,
0◦,
x > 1.
Find the steady-state temperature distribution as a function of x and y.

Section 9
Integral Transform Solutions of Partial Differential Equations
661
Figure 9.1
The diﬀerential equation and its solutions are the
same as in the semi-inﬁnite plate problem dis-
cussed in Section 2, equations (2.1), (2.6), and
(2.7). As in that problem, we assume u →0 as
y →∞, and use only the e−ky terms. Since u = 0
when x = 0, we use only the sine solutions. The
basis functions we want are then u = e−ky sin kx.
We do not have any requirement here which de-
termines k as we did in Section 2. We must then
allow all k’s and try to ﬁnd a solution in the form
of an integral over k. Instead of coeﬃcients bn in a series, we have a coeﬃcient
function B(k) to determine. Remember that k > 0 since e−ky must tend to zero as
y →∞. Thus we try to ﬁnd a solution of the form
(9.9)
u(x, y) =
 ∞
0
B(k)e−ky sin kx dk.
When y = 0, we have
(9.10)
u(x, 0) =
 ∞
0
B(k) sin kx dk.
This is the ﬁrst of equations (12.14) in Chapter 7, if we identify k with α, u(x, 0)
with fs(x), and B(k) with

2/πgs(α). Thus the given temperature on the x axis
is a Fourier sine transform of the desired coeﬃcient function, so B(k) can be found
as the inverse transform. Using the second of equations (12.14) in Chapter 7, we
get
(9.11)
B(k) =

2
π gs(k) = 2
π
 ∞
0
fs(x) sin kx dx = 2
π
 ∞
0
u(x, 0) sin kx dx.
For the given u(x, 0) in (9.8), we ﬁnd
(9.12)
B(k) = 2
π
 1
0
100 sin kx dx = −200
π
cos kx
k

1
0
= 200
πk (1 −cos k).
Finding B(k) corresponds to evaluating the coeﬃcients in a Fourier series. Substi-
tuting (9.12) into (9.9), we get the solution to our problem in the form of an integral
instead of a series:
(9.13)
u(x, y) = 200
π
 ∞
0
1 −cos k
k
e−ky sin kx dk.
An integral can, of course, be evaluated numerically just as a convergent series
can be approximated by calculating a few terms. However, (9.13) can be integrated;
a convenient way to do it is to recognize that it is a Laplace transform of f(k) =
[(1 −cos k) sin kx]/k, where x is just a parameter and y corresponds to p and k to
t. From L19 and L20
(9.14)
u(x, y) = 200
π

arc tan x
y −1
2 arc tan x + 1
y
−1
2 arc tan x −1
y

.
This can also be written in polar coordinates as (Problem 1)
(9.15)
u = 100
π
π
2 −arc tan r2 −cos 2θ
sin 2θ
	
.

662
Partial Differential Equations
Chapter 13
PROBLEMS, SECTION 9
1.
Verify that (9.15) follows from (9.14). Hint: Use the formulas for tan (α ± β), tan 2α,
etc., to condense (9.14) and then change to polar coordinates. You may ﬁnd
u = 100
π
arc tan
sin 2θ
r2 −cos 2θ .
Show that if you use principal values of the arc tangent, this formula does not give
the correct boundary conditions on the x axis, whereas (9.15) does.
2.
A metal plate covering the ﬁrst quadrant has the edge which is along the y axis
insulated and the edge which is along the x axis held at
u(x, 0) =
(
100(2 −x),
for 0 < x < 2,
0,
for x > 2.
Find the steady-state temperature distribution as a function of x and y.
Hint:
Follow the procedure of Example 2, but use a cosine transform (because ∂u/∂x = 0
for x = 0). Leave your answer as an integral like (9.13).
3.
Consider the heat ﬂow problem of Section 3. Solve this by Laplace transforms (with
respect to t) by starting as in Example 1. You should get
∂2U
∂x2 −p
α2 U = −100
α2l x
and U(0, p) = U(l, p) = 0.
Solve this diﬀerential equation to get
U(x, p) = −100 sinh (p1/2/α)x
p sinh (p1/2/α)l
+ 100
pl x.
Assume the following expansion, and ﬁnd u by looking up the inverse Laplace trans-
forms of the individual terms of U:
sinh (p1/2/α)x
p sinh (p1/2/α)l = x
pl−2
π
»
sin (πx/l)
p + (π2α2/l2) −
sin (2πx/l)
2[p + (4π2α2/l2)] +
sin (3πx/l)
3[p + (9π2α2/l2)] · · ·
–
.
Your answer should be (3.15).
4.
A semi-inﬁnite bar is initially at temperature 100◦for 0 < x < 1, and 0◦for x > 1.
Starting at t = 0, the end x = 0 is maintained at 0◦and the sides are insulated.
Find the temperature in the bar at time t, as follows.
Separate variables in the
heat ﬂow equation and get elementary solutions e−α2k2t sin kx and e−α2k2t cos kx.
Discard the cosines since u = 0 at x = 0. Look for a solution
u(x, t) =
Z ∞
0
B(k)e−α2k2t sin kx dk.
and proceed as in Example 2. Leave your answer as an integral.
5.
A long wire occupying the x axis is initially at rest. The end x = 0 is oscillated up
and down so that
y(0, t) = 2 sin 3t,
t > 0.
Find the displacement y(x, t). The initial and boundary conditions are y(0, t) =
2 sin 3t, y(x, 0) = 0, ∂y/∂t|t=0 = 0. Take Laplace transforms of these conditions
and of the wave equation with respect to t as in Example 1. Solve the resulting
diﬀerential equation to get
Y (x, p) = 6e−(p/v)x
p2 + 9
.

Section 10
Miscellaneous Problems
663
Use L3 and L28 to ﬁnd
y(x, t) =
(
2 sin 3
`
t −x
v
´
,
x < vt,
0,
x > vt.
6.
Continue the problem of Example 2 in the following way: Instead of using the
explicit form of B(k) from (9.12), leave it as an integral and write (9.13) in the form
u(x, y) = 200
π
Z ∞
0
e−ky sin kx dk
Z 1
0
sin kt dt.
Change the order of integration and evaluate the integral with respect to k ﬁrst.
(Hint: Write the product of sines as a diﬀerence of cosines.) Now do the t integration
and get (9.14).
7.
Continue with Problem 4 as in Problem 6.
10. MISCELLANEOUS PROBLEMS
1.
Find the steady-state temperature distribution in a rectangular plate covering the
area 0 < x < 1, 0 < y < 2, if T = 0 for x = 0, x = 1, y = 2, and T = 1−x for y = 0.
2.
Solve Problem 1 if T = 0 for x = 0, x = 1, y = 0, and T = 1 −x for y = 2. Hint:
Use sinh ky as the y solution; then T = 0 when y = 0 as required.
3.
Solve Problem 1 if the sides x = 0 and x = 1 are insulated (see Problems 2.14 and
2.15), and T = 0 for y = 2, T = 1 −x for y = 0.
4.
Find the steady-state temperature distribution in a plate with the boundary tem-
peratures T = 30◦for x = 0 and y = 3; T = 20◦for y = 0 and x = 5. Hint:
Subtract 20◦from all temperatures and solve the problem; then add 20◦. (Also see
Problem 2.)
5.
A bar of length l is initially at 0◦. From t = 0 on, the ends are held at 20◦. Find
u(x, t) for t > 0.
6.
Do Problem 5 if the x = 0 end is insulated and the x = l end held at 20◦for t > 0.
(See Problem 3.9.)
7.
Solve Problem 2 if the sides x = 0 and x = 1 are insulated.
8.
A slab of thickness 10 cm has its two faces at 10◦and 20◦. At t = 0, the face
temperatures are interchanged. Find u(x, t) for t > 0.
9.
A string of length l has initial displacement y0 = x(l −x). Find the displacement as
a function of x and t.
10.
Solve Problem 5.7 if half the curved surface of the cylinder is held at 100◦and the
other half at −100◦with the ends at 0◦.
11.
The series in Problem 5.12 can be summed (see Problem 2.6). Show that
u = 50 + 100
π arc tan 2ar sin θ
a2 −r2 .
12.
A plate in the shape of a quarter circle has boundary temper-
atures as shown. Find the interior steady-state temperature
u(r, θ). (See Problem 5.12.)

664
Partial Differential Equations
Chapter 13
13.
Sum the series in Problem 12 to get
u = 200
π
arc tan 2a2r2 sin 2θ
a4 −r4
.
Hint: See Problem 2.6.
14.
A long cylinder has been cut into quarter cylinders which are insulated from each
other; alternate quarter cylinders are held at potentials +100 and −100. Find the
electrostatic potential inside the cylinder. Hints: Do you see a relation to Problem
12 above? Also see Problem 5.12.
15.
Repeat Problems 12 and 13 for a plate in the shape of a circular sector of angle 30◦
and radius 10 if the boundary temperatures are 0◦on the straight sides and 100◦
on the circular arc. Can you then state and solve a problem like 14?
16.
Consider the normal modes of vibration for a square membrane of side π (see Prob-
lem 6.3). Sketch the 2, 1 and 1, 2 modes. Show that the line y = x is a nodal line for
the combination sin x sin 2y −sin 2x sin y of these two modes. Thus ﬁnd a vibration
frequency of a membrane in the shape of a 45◦right triangle.
17.
Sketch some of the normal modes of vibration for a semicircular drumhead and
ﬁnd the characteristic vibration frequencies as multiples of the fundamental for the
corresponding circular drumhead.
18.
Repeat Problem 17 for a membrane in the shape of a circular sector of angle 60◦.
19.
A long conducting cylinder is placed parallel to the z axis in an originally uniform
electric ﬁeld in the negative x direction. The cylinder is held at zero potential. Find
the potential in the region outside the cylinder. Hints: See Problem 7.13. You want
solutions of Laplace’s equation in polar coordinates (Problem 5.12).
20.
Use Problem 7.16 to ﬁnd the characteristic vibration frequencies of sound in a spher-
ical cavity.
21.
The surface temperature of a sphere of radius 1 is held at u = sin2 θ + cos3 θ. Find
the interior temperature u(r, θ, φ).
22.
Find the interior temperature in a hemisphere if the curved surface is held at u =
cos θ and the equatorial plane at u = 1.
23.
Find the steady-state temperature in the region between two spheres r = 1 and
r = 2 if the surface of the outer sphere has its upper half held at 100◦and its lower
half at −100◦and these temperatures are reversed for the inner sphere. Hint: See
Problem 7.14. Here you will need to ﬁnd two Legendre series (when r = 1 and when
r = 2) and solve for al and bl.
24.
Find the general solution for the steady-state temperature in Figure 2.2 if the bound-
ary temperatures are the constants T = A, T = B, etc., on the four sides, and the
rectangle covers the area 0 < x < a, 0 < y < b. Hints: You can subtract, say, A
from all four temperatures, solve the problem, and then add A back again. Thus
a solution with one side at T = 0 and the other three at given temperatures solves
the general problem. You have previously solved problems (Section 2) with temper-
atures C and D given. For B, see Problem 2.
25.
The Klein-Gordon equation is ∇2u = (1/v2)∂2u/∂t2 + λ2u.
This equation is of
interest in quantum mechanics, but it also has a simpler application. It describes, for
example, the vibration of a stretched string which is embedded in an elastic medium.
Separate the one-dimensional Klein-Gordon equation and ﬁnd the characteristic
frequencies of such a string.
Answer:
νn = v
2
p
(n/l)2 + (λ/π)2.

Section 10
Miscellaneous Problems
665
26.
Find the characteristic frequencies of a circular membrane which satisﬁes the Klein-
Gordon equation (Problem 25). Hint: Separate the equation in two dimensions in
polar coordinates.
27.
Do Problem 26 for a rectangular membrane.
28.
Find the steady-state temperature in a semi-inﬁnite plate covering the region x > 0,
0 ≤y ≤1, if the edges along the x axis and y axis are insulated (see Problem 2.14)
and the top edge is held at
u(x, 1) =
(
100◦,
0 < x < 1,
0◦,
x > 1.
Hint: Look for a solution as a Fourier integral. Leave your answer as an integral
(just as we usually give answers as series.)

C H A P T E R 14
Functions of a
Complex Variable
1. INTRODUCTION
Figure 1.1
In Chapter 2 we discussed plotting com-
plex numbers z = x + iy in the complex
plane (see Figure 1.1) and ﬁnding values
of the elementary functions of z such as
roots, trigonometric functions, logarithms,
etc. Now we want to discuss the calculus of
functions of z, diﬀerentiation, integration,
power series, etc. As you know from such
topics as diﬀerential equations, Fourier se-
ries and integrals, mechanics, electricity,
etc., it is often very convenient to use complex expressions. The basic facts and
theorems about functions of a complex variable not only simplify many calculations
but often lead to a better understanding of a problem and consequently to a more
eﬃcient method of solution. We are going to state some of the basic deﬁnitions and
theorems of the subject (omitting the longer proofs), and show some of their uses.
As in Chapter 2, the value of a function of z for a given z is a complex number.
Example.
Consider a simple function of z, namely f(z) = z2. We may write
f(z) = z2 = (x + iy)2 = x2 −y2 + 2ixy = u(x, y) + iv(x, y),
where u(x, y) = x2 −y2 and v(x, y) = 2xy.
In Chapter 2, we observed that a complex number z = x+iy is equivalent to a pair
of real numbers x, y. Here we see that a function of z is equivalent to a pair of real
functions, u(x, y) and v(x, y), of the real variables x and y. In general, we write
(1.1)
f(z) = f(x + iy) = u(x, y) + iv(x, y),
666

Section 2
Analytic Functions
667
where it is understood that u and v are real functions of the real variables x and y.
Recall that functions are customarily single-valued, that is, f(z) has just one
(complex) value for each z. Does this mean that we cannot deﬁne a function by a
formula such as ln z or arc tan z? By Chapter 2, we have
ln z = ln |z| + i(θ + 2nπ),
where tan θ = y/x. For each z, ln z has an inﬁnite set of values. But if θ is allowed a
range of only 2π , then ln z has one value for each z and this single-valued function is
called a branch of ln z. Thus in using formulas such as √z, ln z, arc tan z, to deﬁne
functions, we always discuss a single branch at a time so that we have a single-
valued function. (As a matter of terminology, however, you should know that the
whole collection of branches is sometimes called a “multiple-valued function.”)
PROBLEMS, SECTION 1
Find the real and imaginary parts u(x, y) and v(x, y) of the following functions.
1.
z3
2.
z
3.
¯z
4.
|z|
5.
Re z
6.
ez
7.
cosh z
8.
sin z
9.
1
z
10.
2z + 3
z + 2
11.
2z −i
iz + 2
12.
z
z2 + 1
13.
ln |z|
14.
z2¯z
15.
ez
16.
z2 −¯z2
17.
cos ¯z
18.
√z
19.
ln z
(Use 0 < θ < 2π.)
20.
(1 + 2i)z2 + (i −1)z + 3
21.
eiz
(Careful:
cos z and sin z are not u and v.)
2. ANALYTIC FUNCTIONS
Deﬁnition
The derivative of f(z) is deﬁned (just as it is for a function of a real
variable) by the equation
(2.1)
f ′(z) = df
dz = lim
∆z→0
∆f
∆z ,
where ∆f = f(z + ∆z) −f(z) and ∆z = ∆x + i∆y.
Deﬁnition:
A function f(z) is analytic (or regular or holomorphic or mono-
genic) in a region∗of the complex plane if it has a (unique) derivative at every
point of the region. The statement “f(z) is analytic at a point z = a” means
that f(z) has a derivative at every point inside some small circle about z = a.
∗Isolated points and curves are not regions; a region must be two-dimensional.

668
Functions of a Complex Variable
Chapter 14
Let us consider what it means for f(z) to have a derivative. First think about
a function f(x) of a real variable x; it is possible for the limit of ∆f/∆x to have
two values at a point x0, as shown in Figure 2.1—one value when we approach x0
from the left and a diﬀerent value when we approach x0 from the right. When we
say that f(x) has a derivative at x = x0, we mean that these two values are equal.
However, for a function f(z) of a complex variable z, there are an inﬁnite number
of ways we can approach a point z0; a few ways are shown in Figure 2.2. When we
say that f(z) has a derivative at z = z0, we mean that f ′(z) [as deﬁned by (2.1)]
has the same value no matter how we approach z0. This is an amazingly stringent
requirement and we might well wonder whether there are any analytic functions.
On the other hand, it is hard to imagine making any progress in calculus unless we
can ﬁnd derivatives!
Figure 2.1
Figure 2.2
Let us immediately reassure ourselves that there are analytic functions by using
the deﬁnition (2.1) to ﬁnd the derivatives of some simple functions.
Example 1.
Show that (d/dz)(z2) = 2z. By (2.1) we have
d
dz (z2) = lim
∆z→0
(z + ∆z)2 −z2
∆z
= lim
∆z→0
z2 + 2z∆z + (∆z)2 −z2
∆z
= lim
∆z→0(2z + ∆z) = 2z.
We see that the result is independent of how ∆z tends to zero; thus z2 is an analytic
function. By the same method it follows that (d/dz)(zn) = nzn−1 if n is a positive
integer (Problem 30).
Observe that the deﬁnition (2.1) of a derivative is of exactly the same form as the
corresponding deﬁnition for a function of a real variable. Because of this similarity,
many familiar formulas can be proved by the same methods used in the real case, as
we have just discovered in diﬀerentiating z2. You can easily show (Problems 25 to
28) that derivatives of sums, products, and quotients follow the familiar rules and
that the chain rule holds [if f = f(g) and g = g(z), then df/dz = (df/dg)(dg/dz)].
Then derivatives of rational functions of z follow the familiar real-variable formulas.
If we assume the deﬁnitions and theorems of Chapters 1 and 2, we can see that the
derivatives of the other elementary functions also follow the familiar formulas; for
example, (d/dz)(sin z) = cos z, etc. (Problems 29 to 33).
Now you may be wondering what is new here since all our results so far seem to
be just the same as for functions of a real variable. The reason for this is that we
have been discussing only functions f(z) that have derivatives. Comparing Figures
2.1 and 2.2, we pointed out the essential diﬀerence between ﬁnding (d/dx)f(x)

Section 2
Analytic Functions
669
and ﬁnding (d/dz)f(z), namely that there are an inﬁnite number of ways we can
approach z0 in Figure 2.2.
Example 2.
Find (d/dz)(|z|2). Note that |x|2 = x2, and its derivative is 2x. If |z|2 has a
derivative, it is given by (2.1), that is, by
lim
∆z→0 = lim
∆z→0
|z + ∆z|2 −|z|2
∆z
.
The numerator of this fraction is always real (because absolute values are real—
recall |z| =

x2 + y2 = r.) Consider the denominator ∆z = ∆x + i∆y. As we
approach z0 in Figure 2.2 (that is, let ∆z →0), ∆z has diﬀerent values depending
on our method of approach. For example, if we come in along a horizontal line,
then ∆y = 0 and ∆z = ∆x; along a vertical line ∆x = 0 so ∆z = i∆y, and along
other directions ∆z is some complex number; in general, ∆z is neither real nor pure
imaginary. Since the numerator of ∆f/∆z is real and the denominator may be real
or imaginary (in general, complex), we see that lim∆z→0 ∆f/∆z has diﬀerent values
for diﬀerent directions of approach to z0, that is, |z|2 is not analytic.
Now we have seen examples of both analytic and nonanalytic functions, but we
still do not know how to tell whether a function has a derivative [except to appeal
to (2.1)]. The following theorems answer this question.
Theorem I
(which we shall prove). If f(z) = u(x, y) + iv(x, y) is analytic in a
region, then in that region
(2.2)
∂u
∂x = ∂v
∂y ,
∂v
∂x = −∂u
∂y .
These equations are called the Cauchy-Riemann conditions.
Proof.
Remembering that f = f(z), where z = x + iy, we ﬁnd by the rules of
partial diﬀerentiation (see Problem 28 and also Chapter 4)
(2.3)
∂f
∂x = df
dz
∂z
∂x = df
dz · 1,
∂f
∂y = df
dz
∂z
∂y = df
dz · i.
Since f = u(x, y) + iv(x, y) by (1.1), we also have
(2.4)
∂f
∂x = ∂u
∂x + i ∂v
∂x
and
∂f
∂y = ∂u
∂y + i ∂v
∂y.
Notice that if f has a derivative with respect to z, then it also has partial derivatives
with respect to x and y by (2.3). Since a complex function has a derivative with
respect to a real variable if and only if its real and imaginary parts do [see (1.1)], then
by (2.4) u and v also have partial derivatives with respect to x and y. Combining
(2.3) and (2.4) we have
df
dz = ∂f
∂x = ∂u
∂x + i∂v
∂x
and
df
dz = 1
i
∂f
∂y = 1
i
∂u
∂y + i∂v
∂y

= ∂v
∂y −i∂u
∂y .

670
Functions of a Complex Variable
Chapter 14
Since we assumed that df/dz exists and is unique (this is what analytic means),
these two expressions for df/dz must be equal. Taking real and imaginary parts,
we get the Cauchy-Riemann equations (2.2).
Theorem II
(which we state without proof). If u(x, y) and v(x, y) and their
partial derivatives with respect to x and y are continuous and satisfy the Cauchy-
Riemann conditions in a region, then f(z) is analytic at all points inside the region
(not necessarily on the boundary).
Although we shall not prove this (see texts on complex variables), we can make
it plausible by showing that it is true when we approach z0 along any straight line.
Example 3.
Find df/dz assuming that we approach z0 along a straight line of slope m,
and show that df/dz does not depend on m if u and v satisfy (2.2). The equation
of the straight line of slope m through the point z0 = x0 + iy0 is
y −y0 = m(x −x0)
and along this line we have dy/dx = m. Then we ﬁnd
df
dz = du + i dv
dx + i dy =
∂u
∂x dx + ∂u
∂y dy + i
∂v
∂x dx + ∂v
∂y dy

dx + i dy
=
∂u
∂x + ∂u
∂y m + i
∂v
∂x + ∂v
∂y m

1 + im
.
Using the Cauchy-Riemann equations (2.2), we get
df
dz =
∂u
∂x −∂v
∂x m + i
∂v
∂x + ∂u
∂x m

1 + im
=
∂u
∂x(1 + im) + i ∂v
∂x(1 + im)
1 + im
= ∂u
∂x + i ∂v
∂x.
Thus df/dz has the same value for approach along any straight line. The theorem
states that it also has the same value for approach along any curve.
Some deﬁnitions:
A regular point of f(z) is a point at which f(z) is analytic.
A singular point or singularity of f(z) is a point at which f(z) is not analytic.
It is called an isolated singular point if f(z) is analytic everywhere else inside
some small circle about the singular point.

Section 2
Analytic Functions
671
Theorem III
(which we state without proof). If f(z) is analytic in a region
(R in Figure 2.3), then it has derivatives of all orders at points inside the region
and can be expanded in a Taylor series about any point z0 inside the region.
The power series converges inside the circle about z0 that extends to the nearest
singular point (C in Figure 2.3).
Figure 2.3
Notice again what a strong condition it is on f(z) to say that it has a derivative.
It is quite possible for a function of a real variable f(x) to have a ﬁrst derivative
but not higher derivatives. But if f(z) has a ﬁrst derivative with respect to z, then
it has derivatives of all orders, and all these derivatives are analytic functions.
This theorem also explains a fact about power series which may have puzzled
you. The function f(x) = 1/(1 + x2) does not have anything peculiar about its
behavior at x = ±1. Yet if we expand it in a power series
(2.5)
1
1 + x2 = 1 −x2 + x4 −x6 + · · ·
we see that the series converges only for |x| < 1. We can see why this happens if
we consider instead
(2.6)
f(z) =
1
1 + z2 = 1 −z2 + z4 −z6 + · · · .
Figure 2.4
When z = ±i, f(z) and its derivatives become inﬁnite; that
is, f(z) is not analytic in any region containing z = ±i. The
point z0 of the theorem is the origin and the circle C (bound-
ing the disk of convergence of the series) passes through the
nearest singular points ±i (Figure 2.4). Since a power series
in z always converges inside its disk of convergence and di-
verges outside (Chapter 2, Problem 6.14), we see that (2.5)
[which is (2.6) for y = 0] converges for |x| < 1 and diverges for
|x| > 1. This simple example shows an important reason for
studying functions of a complex variable; our study of f(z) gives us insights about
the corresponding f(x). Formulas involving not only the elementary functions but
also Γ functions, Bessel functions, and many others are more easily derived and
understood by considering them as functions of z.
A function φ(x, y) which satisﬁes Laplace’s equation in two dimensions, namely,
∇2φ = ∂2φ/dx2 + ∂2φ/∂y2, is called a harmonic function. A great many physical
problems lead to Laplace’s equation, and consequently we are very much interested
in ﬁnding solutions of it. (See Section 10 and Chapter 13.) The following theorem

672
Functions of a Complex Variable
Chapter 14
should then give you a clue as to one reason why the theory of functions of a complex
variable is important in applications.
Theorem IV.
Part 1 (to be proved in Problem 44). If f(z) = u+iv is analytic
in a region, then u and v satisfy Laplace’s equation in the region (that is, u and v
are harmonic functions).
Part 2 (which we state without proof).
Any function u (or v) satisfying
Laplace’s equation in a simply-connected region, is the real or imaginary part of
an analytic function f(z).
Thus we can ﬁnd solutions of Laplace’s equation simply by taking the real or
imaginary parts of an analytic function of z. It is also often possible, starting with
a simple function which satisﬁes Laplace’s equation, to ﬁnd the explicit function
f(z) of which it is, say, the real part.
Example 4.
Consider the function u(x, y) = x2 −y2. We ﬁnd that
∇2u = ∂2u
∂x2 + ∂2u
∂y2 = 2 −2 = 0,
that is, u satisﬁes Laplace’s equation (or u is a harmonic function). Let us ﬁnd the
function v(x, y) such that u+iv is an analytic function of z. By the Cauchy-Riemann
equations
∂v
∂y = ∂u
∂x = 2x.
Integrating partially with respect to y, we get
v(x, y) = 2xy + g(x),
where g(x) is a function of x to be found. Diﬀerentiating partially with respect to
x and again using the Cauchy-Riemann equations, we have
∂v
∂x = 2y + g′(x) = −∂u
∂y = 2y.
Thus we ﬁnd
g′(x) = 0,
or
g = const.
Then
f(z) = u + iv = x2 −y2 + 2ixy + const. = z2 + const.
The pair of functions u, v are called conjugate harmonic functions. (Also see Prob-
lem 64.)
PROBLEMS, SECTION 2
1 to 21. Use the Cauchy-Riemann conditions to ﬁnd out whether the functions in Problems
1.1 to 1.21 are analytic. Similarly, ﬁnd out whether the following functions are analytic.
22.
y + ix
23.
x −iy
x2 + y2
24.
y −ix
x2 + y2

Section 2
Analytic Functions
673
Using the deﬁnition (2.1) of (d/dz)f(z), show that the following familiar formulas hold.
Hint: Use the same methods as for functions of a real variable.
25.
d
dz [Af(z) + Bg(z)] = A df
dz + B dg
dz .
26.
d
dz [f(z)g(z)] = f(z)dg
dz + g(z) df
dz .
27.
d
dz
„f(z)
g(z)
«
= gf ′ −fg′
g2
,
g(z) ̸= 0.
28.
d
dz f[g(z)] = df
dg
dg
dz . (See hint below.)
Problem 28 is the chain rule for the derivative of a function of a function. Hint: Assume
that df/dg and dg/dz exist, and write equations like (3.5) of Chapter 4 for ∆f and ∆g;
substitute ∆g into ∆f, divide by ∆z, and take limits.
29.
d
dz (z3) = 3z2.
30.
d
dz (zn) = nzn−1.
31.
d
dz ln z = 1
z ,
z ̸= 0.
Hint: Expand ln
„
1 + ∆z
z
«
in series.
32.
Using the deﬁnition of ez by its power series [(8.1) of Chapter 2], and the theorem
(Chapters 1 and 2) that power series may be diﬀerentiated term by term (within
the disk of convergence), and the result of Problem 30, show that (d/dz)(ez) = ez.
33.
Using the deﬁnitions of sin z and cos z [Chapter 2, equation (11.4)], ﬁnd their deriva-
tives. Then using Problem 27, ﬁnd (d/dz)(cot z), z ̸= nπ.
Using series you know from Chapter 1, write the power series (about the origin) of the
following functions. Use Theorem III to ﬁnd the disk of convergence of each series. What
you are looking for is the point (anywhere in the complex plane) nearest the origin, at
which the function does not have a derivative. Then the disk of convergence has center at
the origin and extends to that point. The series converges inside the disk.
34.
ln(1 −z)
35.
cos z
36.
p
1 + z2
37.
tanh z
38.
1
2i + z
39.
z
z2 + 9
40.
(1 −z)−1
41.
eiz
42.
sinh z
43.
In Chapter 12, equations (5.1) and (5.2), we expanded the function φ(x, h) in a series
of powers of h. Use Theorem III (see instructions for Problems 34 to 42 above) to
show that the series for φ(x, h) converges for |h| < 1 and −1 ≤x ≤1. Here h is
the variable and x is a parameter; you should ﬁnd the (complex) value of h which
makes Φ inﬁnite, and show that the absolute value of this complex number is 1
(independent of x when x2 ≤1). This proves that the series for real h converges for
|h| < 1.
44.
Prove Theorem IV, Part 1. Hint: Recall the equality of the second cross partial
derivatives; see Chapter 4, end of Section1.
45.
Let f(z) = u+iv be an analytic function, and let F be the vector F = vi+uj. Show
that the equations div F = 0 and curl F = 0 are equivalent to the Cauchy-Riemann
equations.
46.
Find the Cauchy-Riemann equations in polar coordinates. Hint: Write z = reiθ and
f(z) = u(r, θ) + iv(r, θ). Follow the method of equations (2.3) and (2.4).
47.
Using your results in Problem 46 and the method of Problem 44, show that u
and v satisfy Laplace’s equation in polar coordinates (see Chapter 10, Section 9) if
f(z) = u + iv is analytic.

674
Functions of a Complex Variable
Chapter 14
Using polar coordinates (Problem 46), ﬁnd out whether the following functions satisfy the
Cauchy-Riemann equations.
48.
√z
49.
|z|
50.
ln z
51.
zn
52.
|z|2
53.
|z|1/2eiθ/2
Show that the following functions are harmonic, that is, that they satisfy Laplace’s equa-
tion, and ﬁnd for each a function f(z) of which the given function is the real part. Show
that the function v(x, y) (which you ﬁnd) also satisﬁes Laplace’s equation.
54.
y
55.
3x2y −y3
56.
xy
57.
x + y
58.
cosh y cos x
59.
ex cos y
60.
ln(x2 + y2)
61.
x
x2 + y2
62.
e−y sin x
63.
y
(1 −x)2 + y2
64.
It can be shown that, if u(x, y) is a harmonic function which is deﬁned at z0 =
x0 + iy0, then an analytic function of which u(x, y) is the real part is given by
f(z) = 2u
“z + ¯z0
2
, z −¯z0
2i
”
+ const.
[See Struble, Quart. Appl. Math., 37 (1979), 79-81.] Use this formula to ﬁnd f(z)
in Problems 54 to 63. Hint: If u(0, 0) is deﬁned, take z0 = 0.
3. CONTOUR INTEGRALS
Theorem V
Cauchy’s theorem (see discussion below). Let C be a simple†
closed curve with a continuously turning tangent except possibly at a ﬁnite num-
ber of points (that is, we allow a ﬁnite number of corners, but otherwise the curve
must be “smooth”). If f(z) is analytic on and inside C, then
(3.1)

around C
f(z) dz = 0.
(This is a line integral as in vector analysis; it is called a contour integral in the
theory of complex variables.)
Proof.
We shall prove Cauchy’s theorem assuming that f ′(z) is continuous. (With
more eﬀort it is possible to prove it without this assumption, and then show that if
f ′(z) exists in a region, it is, in fact, continuous there. See also Theorem III which
we stated without proof; it is usually proved using the results of Cauchy’s theorem.)

C
f(z) dz =

C
(u + iv)(dx + i dy)
(3.2)
=

C
(u dx −v dy) + i

C
(v dx + u dy).
†A simple curve is one which does not cross itself.

Section 3
Contour Integrals
675
Green’s theorem in the plane (Chapter 6, Section 9) says that if P(x, y), Q(x, y),
and their partial derivatives are continuous in a simply-connected region R, then
(3.3)

C
P dx + Q dy =

area
inside C
∂Q
∂x −∂P
∂y

dx dy,
where C is a simple closed curve lying entirely in R. The curve C is traversed in a
direction so that the area inclosed is always to the left; the area integral is over the
area inside C. Applying (3.3) to the ﬁrst integral in (3.2), we get
(3.4)

C
(u dx −v dy) =

area
inside C

−∂v
∂x −∂u
∂y

dx dy.
Since we are assuming that f ′(z) is continuous, then u and v and their derivatives
are continuous; by the Cauchy-Riemann equations the integrand on the right of
(3.4) is zero at every point of the area of integration, so the integral is equal to zero.
In the same way the second integral in (3.2) is zero; thus (3.1) is proved.
Theorem VI
Cauchy’s integral formula (which we shall prove). If f(z) is
analytic on and inside a simple closed curve C, the value of f(z) at a point z = a
inside C is given by the following contour integral along C:
f(a) =
1
2πi

f(z)
z −adz.
Proof. Let a be a ﬁxed point inside the simple closed
curve C and consider the function
(3.5)
φ(z) = f(z)
z −a,
Figure 3.1
where f(z) is analytic on and inside C. Let C′ be a
small circle (inside C) with center at a and radius ρ.
Make a cut between C and C′ along AB (Figure 3.1);
two cuts are shown to make the picture clear, but later
we shall make them coincide.
We are now going to
integrate along the path shown in Figure 3.1 (in the
direction shown by the arrows) from A, around C, to
B, around C′, and back to A. Notice that the area between the curves C and C′
is always to the left of the path of integration and is inclosed by it. In this area
between C and C′, the function φ(z) is analytic; we have cut out a small disk about
the point z = a at which φ(z) is not analytic. Cauchy’s theorem then applies to the
integral along the combined path consisting of C counterclockwise, C′ clockwise,
and the two cuts. The two integrals, in opposite directions along the cuts, cancel
when the cuts are made to coincide. Thus we have
(3.6)

C counter-
clockwise
φ(z) dz +

C′ clockwise
φ(z) dz = 0
or

C
φ(z) dz =

C′ φ(z) dz
where both are counterclockwise.

676
Functions of a Complex Variable
Chapter 14
Along the circle C′, z = a + ρeiθ, dz = ρieiθ dθ, and (3.6) becomes
(3.7)

C
φ(z) dz =

C′ φ(z) dz =

C′
f(z)
z −a dz
=
 2π
0
f(z)
ρeiθ ρieiθ dθ =
 2π
0
f(z)i dθ.
Since our calculation is valid for any (suﬃciently small) value of ρ, we shall let
ρ →0 (that is, z →a) to simplify the formula. Because f(z) is continuous at z = a
(it is analytic inside C), limz→a f(z) = f(a). Then (3.7) becomes
(3.8)

C
φ(z) dz =

C
f(z)
z −a dz =
 2π
0
f(z)i dθ =
 2π
0
f(a)i dθ = 2πif(a)
or
(3.9)
f(a) =
1
2πi

C
f(z)
z −a dz,
a inside C.
This is Cauchy’s integral formula. Note carefully that the point a is inside
C; if a were outside C, then φ(z) would be analytic everywhere inside C and the
integral would be zero by Cauchy’s theorem. A useful way to look at (3.9) is this:
If the values of f(z) are given on the boundary of a region (curve C), then (3.9)
gives the value of f(z) at any point a inside C. With this interpretation you will
ﬁnd Cauchy’s integral formula written with a replaced by z, and z replaced by
some diﬀerent dummy integration variable, say w:
(3.10)
f(z) =
1
2πi

C
f(w)
w −z dw,
z inside C.
For some important uses of this theorem, see Problems 11.3 and 11.36 to 11.38.
PROBLEMS, SECTION 3
Evaluate the following line integrals in the complex plane by direct integration, that is, as
in Chapter 6, Section 8, not using theorems from this chapter. (If you see that a theorem
applies, use it to check your result.)
1.
R i+1
i
z dz along a straight line parallel to the x axis.
2.
R 1+i
0
(z2 −z) dz
(a)
along the line y = x;
(b)
along the indicated broken line.
3.
H
C z2 dz along the indicated paths:

Section 3
Contour Integrals
677
4.
R
dz/(1 −z2) along the whole positive imaginary axis, that is, the y axis; this is
frequently written as
R i∞
0
dz/(1 −z2).
5.
R
e−z along the positive part of the line y = π; this is frequently written as
R ∞+iπ
iπ
e−z dz.
6.
R i
1 z dz along the indicated paths:
7.
Z
dz
8i + z2 along the line y = x from 0 to ∞.
8.
Z 2π+i∞
2π
e2iz dz
9.
Z ∞+2i
1+2i
dz
(x −2i)2
10.
Z 2+i∞
2
zeiz dz
11.
Evaluate
H
C(¯z −3) dz where C is the indicated closed curve along the
ﬁrst quadrant part of the circle |z| = 2, and the indicated parts of the
x and y axes. Hint: Don’t try to use Cauchy’s theorem! (Why not?
Further hint: See Problem 2.3.)
12.
R 1+2i
0
|z|2 dz along the indicated paths:
13.
In Chapter 6, Section 11, we showed that a necessary condition for
R b
a F · dr to be
independent of the path of integration, that is, for
H
C F · dr around a simple closed
curve C to be zero, was curl F = 0, or in two dimensions, ∂Fy/∂x = ∂Fx/∂y. By
considering (3.2), show that the corresponding condition for
H
C f(z) dz to be zero is
that the Cauchy-Riemann conditions hold.
14.
In ﬁnding complex Fourier series in Chapter 7, we showed that
Z 2π
0
einxe−imx dx = 0,
n ̸= m.
Show this by applying Cauchy’s theorem to
I
C
zn−m−1 dz,
n > m,
where C is the circle |z| = 1. (Note that although we take n > m to make zn−m−1
analytic at z = 0, an identical proof using zm−n−1 with n < m completes the proof
for all n ̸= m.)
15.
If f(z) is analytic on and inside the circle |z| = 1, show that
R 2π
0
eiθf(eiθ) dθ = 0.
16.
If f(z) is analytic in the disk |z| ≤2, evaluate
R 2π
0
e2iθf(eiθ) dθ.
Use Cauchy’s theorem or integral formula to evaluate the integrals in Problems 17 to 20.
17.
I
C
sin z dz
2z −π where C is the circle (a) |z| = 1,
(b) |z| = 2.
18.
I
C
sin 2z dz
6z −π
where C is the circle |z| = 3.

678
Functions of a Complex Variable
Chapter 14
19.
I
e3z dz
z −ln 2 if C is the square with vertices ±1 ± i.
20.
I
C
cosh z dz
2 ln 2 −z if C is the circle (a) |z| = 1,
(b) |z| = 2.
21.
Diﬀerentiate Cauchy’s formula (3.9) or (3.10) to get
f ′(z) =
1
2πi
I
C
f(w) dw
(w −z)2
or
f ′(a) =
1
2πi
I
C
f(z) dz
(z −a)2 .
By diﬀerentiating n times, obtain
f (n)(z) = n!
2πi
I
C
f(w) dw
(w −z)n+1
or
f (n)(a) = n!
2πi
I
C
f(z) dz
(z −a)n+1 .
Use Problem 21 to evaluate the following integrals.
22.
I
C
sin 2z dz
(6z −π)3 where C is the circle |z| = 3.
23.
I
C
e3z dz
(z −ln 2)4 where C is the square in Problem 19.
24.
I
C
cosh z dz
(2 ln 2 −z)5 where C is the circle |z| = 2.
4. LAURENT SERIES
Theorem VII
Laurent’s theorem [equation (4.1)] (which we shall state with-
out proof). Let C1 and C2 be two circles with center at z0. Let f(z) be analytic
in the region R between the circles. Then f(z) can be expanded in a series of the
form
(4.1)
f(z) = a0 + a1(z −z0) + a2(z −z0)2 + · · · +
b1
z −z0
+
b2
(z −z0)2 + · · ·
convergent in R. Such a series is called a Laurent series. The “b” series in (4.1)
is called the principal part of the Laurent series.
Example 1.
Consider the Laurent series
(4.2)
f(z) = 1 + z
2 + z2
4 + z3
8 + · · · +
z
2
n
+ · · ·
+ 2
z + 4
 1
z2 −1
z3 + · · · + (−1)n
zn
+ · · ·

.
Let us see where this series converges. First consider the series of positive powers;
by the ratio test (see Chapters 1 and 2), this series converges for |z/2| < 1, that
is, for |z| < 2. Similarly, the series of negative powers converges for |1/z| < 1, that
is, |z| > 1. Then both series converge (and so the Laurent series converges) for |z|
between 1 and 2, that is, in a ring between two circles of radii 1 and 2.
We expect this result in general. The “a” series is a power series, and a power
series converges inside some circle (say C2 in Figure 4.1). The “b” series is a series

Section 4
Laurent Series
679
of inverse powers of z, and so converges for |1/z| < some constant; thus the “b”
series converges outside some circle (say C1 in Figure 4.1). Then a Laurent series
converges between two circles (if it converges at all). (Note that the inner circle
may be a point and the outer circle may have inﬁnite radius).
Figure 4.1
Figure 4.2
The formulas for the coeﬃcients in (4.1) are (Problem 5.2)
(4.3)
an =
1
2πi

C
f(z) dz
(z −z0)n+1 ,
bn =
1
2πi

C
f(z) dz
(z −z0)−n+1 ,
where C is any simple closed curve surrounding z0 and lying in R. However, this is
not usually the easiest way to ﬁnd a Laurent series. Like power series about a point,
the Laurent series (about z0) for a function in a given annular ring (about z0) where
the function is analytic, is unique, and we can ﬁnd it by any method we choose.
(See examples below.) Warning:
If f(z) has several isolated singularities (Figure
4.2), there are several annular rings, R1, R2, · · · , in which f(z) is analytic; then
there are several diﬀerent Laurent series for f(z), one for each ring. The Laurent
series which we usually want is the one that converges near z0. If you have any
doubt about the ring of convergence of a Laurent series, you can ﬁnd out by testing
the “a” series and the “b” series separately.
Example 2.
The function from which we obtained (4.2) was
(4.4)
f(z) =
12
z(2 −z)(1 + z).
This function has three singular points, at z = 0, z = 2, and z = −1. Thus there
are two circles C1 and C2 about z0 = 0 in Figure 4.2, and three Laurent series about
z0 = 0, one series valid in each of the three regions R1 (0 < |z| < 1), R2(1 < |z| < 2),
and R3(|z| > 2). To ﬁnd these series we ﬁrst write f(z) in the following form using
partial fractions (Problem 2):
(4.5)
f(z) = 4
z

1
1 + z +
1
2 −z

.

680
Functions of a Complex Variable
Chapter 14
Now, for 0 < |z| < 1, we expand each of the fractions in the parenthesis in (4.5) in
powers of z. This gives (Problem 2):
(4.6)
f(z) = −3 + 9z/2 −15z2/4 + 33z3/8 + · · · + 6/z.
This is the Laurent series for f(z) which is valid in the region 0 < |z| < 1. To
obtain the series valid in the region |z| > 2, we write the fractions in (4.5) as
(4.7)
1
1 + z = 1
z
1
1 + 1/z,
1
2 −z = −1
z
1
1 −2/z
and expand each fraction in powers of 1/z. This gives the Laurent series valid for
|z| > 2 (problem 2):
(4.8)
f(z) = −(12/z3)(1 + 1/z + 3/z2 + 5/z3 + 11/z4 + · · · ).
Finally, to obtain (4.2), we expand the fraction 1/(2 −z) in powers of z, and the
fraction 1/(1 + z) in powers of 1/z; this gives a Laurent series which converges for
1 < |z | < 2. Thus the Laurent series (4.6), (4.2) and (4.8) all represent f(z) in
(4.4), but in three diﬀerent regions.
Let z0 in Figure 4.2 be either a regular point or an isolated singular point and
assume that there are no other singular points inside C1. Let f(z) be expanded
in the Laurent series about z0 which converges inside C1 (except possibly at z0);
we say that we have expanded f(z) in the Laurent series which converges near z0.
Then we have the following deﬁnitions.
Deﬁnitions:
If all the b’s are zero, f(z) is analytic at z = z0, and we call z0 a regular point.
(See Problem 4.1)
If bn ̸= 0, but all the b’s after bn are zero, f(z) is said to have a pole of order n
at z = z0. If n = 1, we say that f(z) has a simple pole.
If there are an inﬁnite number of b’s diﬀerent from zero, f(z) has an essential
singularity at z = z0.
The coeﬃcient b1 of 1/(z −z0) is called the residue of f(z) at z = z0.
Example 3.
(a)
ez = 1 + z + z2
2! + z3
3! + · · ·
is analytic at z = 0; the residue of ez at z = 0 is 0.
(b)
ez
z3 = 1
z3 + 1
z2 + 1
2!z + 1
3! + · · ·
has a pole of order 3 at z = 0; the residue of ez
z3 at z = 0 is 1
2!.

Section 4
Laurent Series
681
(c)
e1/z = 1 + 1
z +
1
2!z2 + · · ·
has an essential singularity at z = 0; the residue of e1/z at z = 0 is 1.
Most of the functions we shall consider will be analytic except for poles—such
functions are called meromorphic functions. If f(z) has a pole at z = z0, then
|f(z)| →∞as z →z0. A three-dimensional graph with |f(z)| plotted vertically
over a horizontal complex plane would look like a tapered pole near z = z0. We can
often see that a function has a pole and ﬁnd the order of the pole without ﬁnding
the Laurent series.
Example 4.
(a)
z + 3
z2(z −1)3(z + 1)
has a pole of order 2 at z = 0, a pole of order 3 at z = 1, and a simple pole at
z = −1.
(b)
sin2 z
z3
has a simple pole at z = 0.
To see that these results are correct, consider ﬁnding the Laurent series for f(z) =
g(z)/(z −z0)n. We write g(z) = a0 + a1(z −z0) + · · · ; then the Laurent series for
f(z) starts with the term (z −z0)−n unless a0 = 0, that is unless g(z0) = 0. Then
the order of the pole of f(z) is n unless some factors cancel. In Example 4b, the
sin z series starts with z, so sin2 z has a factor z2; thus (sin2 z)/z3 has a simple pole
at z = 0.
PROBLEMS, SECTION 4
1.
Show that the sum of a power series which converges inside a circle C is an analytic
function inside C. Hint: See Chapter 2, Section 7, and Chapter 1, Section 11, and
the deﬁnition of an analytic function.
2.
Show that equation (4.4) can be written as (4.5). Then expand each of the fractions
in the parenthesis in (4.5) in powers of z and in powers of 1/z [see equation (4.7)]
and combine the series to obtain (4.6), (4.8), and (4.2).
For each of the following functions ﬁnd the ﬁrst few terms of each of the Laurent series
about the origin, that is, one series for each annular ring between singular points. Find
the residue of each function at the origin. (Warning: To ﬁnd the residue, you must use
the Laurent series which converges near the origin.) Hints: See Problem 2. Use partial
fractions as in equations (4.5) and (4.7). Expand a term 1/(z −a) in powers of z to get a
series convergent for |z| < a, and in powers of 1/z to get a series convergent for |z| > a.
3.
1
z(z −1)(z −2)
4.
1
z(z −1)(z −2)2
5.
z −1
z3(z −2)
6.
1
z2(1 + z)2
7.
2 −z
1 −z2
8.
30
(1 + z)(z −2)(3 + z)

682
Functions of a Complex Variable
Chapter 14
For each of the following functions, say whether the indicated point is regular, an essential
singularity, or a pole, and if a pole of what order it is.
9.
(a)
sin z
z
,
z = 0
(b)
cos z
z3 ,
z = 0
(c)
z3 −1
(z −1)3 ,
z = 1
(d)
ez
z −1,
z = 1
10.
(a)
ez −1
z2 + 4,
z = 2i
(b) tan2 z,
z = π/2
(c)
1 −cos z
z4
,
z = 0
(d) cos
„
π
z −π
«
,
z = π
11.
(a)
ez −1 −z
z2
,
z = 0
(b)
sin z
z3 ,
z = 0
(c)
z2 −1
(z −1)2 ,
z = 1
(d)
cos z
(z −π/2)4 ,
z = π/2
12.
(a)
sin z −z
z6
,
z = 0
(b)
z2 −1
(z2 + 1)2 ,
z = i
(c) ze1/z,
z = 0
(d) Γ(z),
z = 0
[See Chapter 11, equation (4.1)]
5. THE RESIDUE THEOREM
Let z0 be an isolated singular point of f(z). We are going to ﬁnd the value of

C f(z) dz around a simple closed curve C surrounding z0 but inclosing no other
singularities. Let f(z) be expanded in the Laurent series (4.1) about z = z0 that
converges near z = z0. By Cauchy’s theorem (V), the integral of the “a” series is
zero since this part is analytic. To evaluate the integrals of the terms in the “b”
series in (4.1), we replace the integrals around C by integrals around a circle C′ with
center at z0 and radius ρ as in (3.6), (3.7), and Figure 3.1. Along C′, z = z0 + ρeiθ;
calculating the integral of the b1 term in (4.1), we ﬁnd
(5.1)

C
b1dz
(z −z0) = b1
 2π
0
ρieiθ dθ
ρeiθ
= 2πib1.
It is straightforward to show (Problem 1) that the integrals of all the other bn terms
are zero. Then

C f(z) dz = 2πib1, or since b1 is called the residue of f(z) at z = z0,
we can say

C
f(z) dz = 2πi · residue of f(z) at the singular point inside C.
The only term of the Laurent series which has survived the integration process is
the b1 term; you can see the reason for the term “residue.” If there are several
isolated singularities inside C, say at z0, z1, z2, · · · , we draw small circles about
each as shown in Figure 5.1 so that f(z) is analytic in the region between C and the
circles. Then, introducing cuts as in Figure 3.1, we ﬁnd that the integral around
C counterclockwise, plus the integrals around the circles clockwise, is zero (since the

Section 6
Methods of Finding Residues
683
Figure 5.1
integrals along the cuts cancel), or the integral along C is the sum of the integrals
around the circles (all counterclockwise). But by (5.1), the integral around each
circle is 2πi times the residue of f(z) at the singular point inside. Thus we have
the residue theorem:
(5.2)

C
f(z) dz = 2πi · sum of the residues of f(z) inside C,
where the integral around C is in the counterclockwise direction.
The residue theorem is useful in evaluating many deﬁnite integrals; we shall
consider this in Section 7. But ﬁrst, in Section 6, we need to develop some techniques
for ﬁnding residues.
PROBLEMS, SECTION 5
1.
If C is a circle of radius ρ about z0, show that
I
C
dz
(z −z0)n = 2πi
if n = 1,
but for any other integral value of n, positive or negative, the integral is zero. Hint:
Use the fact that z = z0 + ρeiθ on C.
2.
Verify the formulas (4.3) for the coeﬃcients in a Laurent series. Hint: To get an,
divide equation (4.1) by (z −z0)n+1 and use the results of Problem 1 to evaluate
the integrals of the terms of the series. Use a similar method to ﬁnd bn.
3.
Obtain Cauchy’s integral formula (3.9) from the residue theorem (5.2).
6. METHODS OF FINDING RESIDUES
A. Laurent Series
If it is easy to write down the Laurent series for f(z) about
z = z0 that is valid near z0, then the residue is just the coeﬃcient b1 of the term
1/(z −z0). Caution: Be sure you have the expansion about z = z0; the series you
have memorized for ez, sin z, etc., are expansions about z = 0 and so can be used
only for ﬁnding residues at the origin (see Section 4, Example 3). Here is another

684
Functions of a Complex Variable
Chapter 14
example: Given f(z) = ez/(z −1), ﬁnd the residue, R(1), of f(z) at z = 1. We
want to expand ez in powers of z −1; we write
ez
z −1 = e · ez−1
z −1
=
e
z −1
	
1 + (z −1) + (z −1)2
2!
+ · · ·

=
e
z −1 + e + · · · .
Then the residue is the coeﬃcient of 1/(z −1), that is, R(1) = e.
B. Simple Pole
If f(z) has a simple pole at z = z0, we ﬁnd the residue by
multiplying f(z) by (z −z0) and evaluating the result at z = z0 (Problem 10).
Example 1.
Find R(−1
2) and R(5) for
f(z) =
z
(2z + 1)(5 −z).
Multiply f(z) by (z + 1
2), [Caution: not by (2z + 1)], and evaluate the result at
z = −1
2. We ﬁnd
(z + 1
2)f(z) = (z + 1
2)
z
(2z + 1)(5 −z) =
z
2(5 −z),
R(−1
2) =
−1
2
2(5 + 1
2) = −1
22.
Similarly,
(z −5)f(z) = (z −5)
z
(2z + 1)(5 −z) = −
z
2z + 1,
R(5) = −5
11.
Example 2.
Find R(0) for f(z) = (cos z)/z. Since zf(z) = cos z, we have
R(0) = (cos z)z=0 = cos 0 = 1.
To use this method, we may in some problems have to evaluate an indeterminate
form, so in general we write
(6.1)
R(z0) = lim
z→z0(z −z0)f(z)
when z0 is a simple pole.
Example 3.
Find the residue of cot z at z = 0. By (6.1)
R(0) = lim
z→0
z cos z
sin z
= cos 0 · lim
z→0
z
sin z = 1 · 1 = 1.
If, as often happens, f(z) can be written as g(z)/h(z), where g(z) is analytic
and not zero at z0 and h(z0) = 0, then (6.1) becomes
R(z0) = lim
z→z0
(z −z0)g(z)
h(z)
= g(z0) lim
z→z0
z −z0
h(z) = g(z0) lim
z→z0
1
h′(z) = g(z0)
h′(z0)

Section 6
Methods of Finding Residues
685
by L’Hˆopital’s rule or the deﬁnition of h′(z) (Problem 11).
Thus we have
(6.2)
R(z0) = g(z0)
h′(z0)
if





f(z) = g(z)/h(z), and
g(z0) = ﬁnite const. ̸= 0, and
h(z0) = 0, h′(z0) ̸= 0.
Often (6.2) gives the most convenient way of ﬁnding the residue at a simple pole.
Example 4.
Find the residue of (sin z)/(1 −z4) at z = i. By (6.2) we have
R(i) = sin z
−4z3

z=i
= sin i
−4i3 = e−1 −e
(2i)(4i) = 1
8(e −e−1) = 1
4 sinh 1.
Now you may ask how you know, without ﬁnding the Laurent series, that a
function has a simple pole. Perhaps the simplest answer is that if the limit obtained
using (6.1) is some constant (not 0 or ∞), then f(z) does have a simple pole and the
constant is the residue. [If the limit = 0, the function is analytic and the residue
= 0; if the limit is inﬁnite, the pole is of higher order.] However, you can often
recognize the order of a pole in advance. [See end of Section 4 for the simple case
in which (z −z0)n is a factor of the denominator.] Suppose f(z) is written in the
form g(z)/h(z), where g(z) and h(z) are analytic. Then you can think of g(z) and
h(z) as power series in (z −z0). If the denominator has the factor (z −z0) to one
higher power than the numerator, then f(z) has a simple pole at z0. For example,
z cot2 z = z cos2 z
sin2 z
= z(1 −z2/2 + · · · )2
(z −z3/3! + · · · )2 = z(1 + · · · )
z2(1 + · · · )
has a simple pole at z = 0. By the same method we can see whether a function has
a pole of any order
C. Multiple Poles
When f(z) has a pole of order n, we can use the following
method of ﬁnding residues.
Multiply f(z) by (z −z0)m, where m is an integer greater than or equal to the
order n of the pole, diﬀerentiate the result m −1 times, divide by (m −1)!, and
evaluate the resulting expression at z = z0.
It is easy to prove that this rule is correct (Problem 12) by using the Laurent
series (4.1) for f(z) and showing that the result of the outlined process is b1.

686
Functions of a Complex Variable
Chapter 14
Example 5.
Find the residue of f(z) = (z sin z)/(z −π)3 at z = π.
We take m = 3 to eliminate the denominator before diﬀerentiating; this is an
allowed choice for m because the order of the pole of f(z) at π is not greater than
3 since z sin z is ﬁnite at π. (The pole is actually of order 2, but we do not need
this fact.) Then following the rule stated, we get
R(π) = 1
2!
d2
dz2 (z sin z)

z=π
= 1
2[−z sin z + 2 cosz]z=π = −1.
(To compute the derivative quickly, use Leibniz’ rule for diﬀerentiating a product;
see Chapter 12, Section 3.)
Much of this work can be done by computer. However, remember that the point
of doing these problems is to gain skill in using the ideas and techniques of complex
variable theory. So a good study method is to do the problems as outlined above
and then check your results by computer.
PROBLEMS, SECTION 6
Find the Laurent series for the following functions about the indicated points; hence ﬁnd
the residue of the function at the point.
(Be sure you have the Laurent series which
converges near the point.)
1.
1
z(z + 1), z = 0
2.
1
z(z −1), z = 1
3.
sin z
z4 , z = 0
4.
cosh z
z2
, z = 0
5.
ez
z2 −1, z = 1
6.
sin 1
z , z = 0
7.
sin πz
4z2 −1, z = 1
2
8.
1 + cos z
(z −π)2 , z = π
9.
1
z2 −5z + 6, z = 2
10.
Show that rule B is correct by applying it to (4.1).
11.
Derive (6.2) by using the limit deﬁnition of the derivative h′(z0) instead of using
L’Hˆopital’s rule. Remember that h(z0) = 0 because we are assuming that f(z) has
a simple pole at z0.
12.
Prove rule C for ﬁnding the residue at a multiple pole, by applying it to (4.1). Note
that the rule is valid for n = 1 (simple pole) although we seldom use it for that case.
13.
Prove rule C by using (3.9). Hints: If f(z) has a pole of order n at z = a, then
f(z) = g(z)/(z −a)n with g(z) analytic at z = a. By (3.9)
Z
C
g(z)
(z −a) dz = 2πig(a)
with C a contour inclosing a but no other singularities. Diﬀerentiate this equation
(n −1) times with respect to a. (Or, use Problem 3.21.)
Find the residues of the following functions at the indicated points.
Try to select the
easiest of the methods outlined above. Check your results by computer.
14.
1
(3z + 2)(2 −z) at z = −2
3; at z = 2
15.
1
(1 −2z)(5z −4) at z = 1
2; at z = 4
5
16.
z −2
z(1 −z) at z = 0; at z = 1
17.
z + 2
4z2 −1 at z = 1
2; at z = −1
2

Section 7
Evaluation of Deﬁnite Integrals by Use of the Residue Theorem
687
18.
z + 2
z2 + 9 at z = 3i
19.
sin2 z
2z −π at z = π/2
20.
z
1 −z4 at z = i
21.
z2
z4 + 16 at z =
√
2(1 + i)
22.
e2z
1 + ez at z = iπ
23.
eiz
9z2 + 4 at z = 2i
3
24.
1 −cos 2z
z3
at z = 0
25.
e2z −1
z2
at z = 0
26.
e2πiz
1 −z3 at z = e2πi/3
27.
cos z
1 −2 sin z at z = π/6
28.
z + 2
(z2 + 9)(z2 + 1) at z = 3i
29.
e2z
4 cosh z −5 at z = ln 2
30.
cosh z −1
z7
at z = 0
31.
e3z −3z −1
z4
at z = 0
32.
eiz
(z2 + 4)2 at z = 2i
33.
1 + cos z
(π −z)3 at z = π
34.
z −2
z2(1 −2z)2 at z = 0 and at z = 1
2
35.
z
(z2 + 1)2 at z = i
14′ to 35′ Use the residue theorem to evaluate the contour integrals of each of the functions
in Problems 14 to 35 around a circle of radius 3
2 and center at the origin. Check carefully
to see which singular points are inside the circle. You may use your results in the previous
problems as far as they go, but you may have to compute some more residues.
36.
For complex z, Jp(z) can be deﬁned by the series (12.9) in Chapter 12. Use this
deﬁnition to ﬁnd the Laurent series about z = 0 for z−3J0(z). Find the residue of
the function at z = 0.
37.
The gamma function Γ(z) is analytic except for poles at z = x = 0, −1, −2, −3 · · ·
(all the negative integers). Find the residues at these poles. Hints: See Example 1
above and Chapter 11, Equation (4.1).
7. EVALUATION OF DEFINITE INTEGRALS BY USE OF THE RESIDUE THEOREM
We are going to use (5.2) and the techniques of Section 6 to evaluate several diﬀerent
types of deﬁnite integrals. The methods are best shown by examples.
Example 1.
Find I =
 2π
0
dθ
5 + 4 cos θ.
Figure 7.1
If we make the change of variable z = eiθ, then as
θ goes from 0 to 2π, z traverses the unit circle |z| = 1
(Figure 7.1) in the counterclockwise direction, and
we have a contour integral. We shall evaluate this
integral by the residue theorem. If z = eiθ, we have
dz = ieiθ dθ = iz dθ
or
dθ = 1
iz dz,
cos θ = eiθ + e−iθ
2
= z + 1
z
2
.

688
Functions of a Complex Variable
Chapter 14
Making these substitutions in I, we get
I =

C
1
iz dz
5 + 2(z + 1/z) = 1
i

C
dz
5z + 2z2 + 2
= 1
i

C
dz
(2z + 1)(z + 2),
where C is the unit circle. The integrand has poles at z = −1
2 and z = −2; only
z = −1
2 is inside the contour C. The residue of 1/[(2z + 1)(z + 2)] at z = −1
2 is
R(−1
2) =
lim
z→−1/2(z + 1
2) ·
1
(2z + 1)(z + 2) =
1
2(z + 2)

z=−1/2
= 1
3.
Then by the residue theorem
I = 1
i 2πiR(−1
2) = 2π · 1
3 = 2π
3 .
This method can be used to evaluate the integral of any rational function of
sin θ and cos θ between 0 and 2π, provided the denominator is never zero for any
value of θ. You can also ﬁnd an integral from 0 to π if the integrand is even, since
the integral from 0 to 2π of an even periodic function is twice the integral from 0
to π of the same function. (See Chapter 7, Section 9 for discussion of even and odd
functions.)
Example 2.
Evaluate I =
 ∞
−∞
dx
1 + x2 .
Here we could easily ﬁnd the indeﬁnite integral and so evaluate I by elemen-
tary methods. However, we shall do this simple problem by contour integration to
illustrate a method which is useful for more complicated problems.
Figure 7.2
This time we are not going to make a change of variable in I. We are going to
start with a diﬀerent integral and show how
to ﬁnd I from it. We consider

C
dz
1 + z2 ,
where C is the closed boundary of the semi-
circle shown in Figure 7.2. For any ρ > 1, the
semicircle incloses the singular point z = i
and no others; the residue of the integrand at
z = i is
R(i) = lim
z→i(z −i)
1
(z −i)(z + i) = 1
2i.
Then the value of the contour integral is 2πi(1/2i) = π. Let us write the integral
in two parts: (1) an integral along the x axis from −ρ to ρ; for this part z = x; (2)
an integral along the semicircle, where z = ρeiθ. Then we have
(7.1)

C
dz
1 + z2 =
 ρ
−ρ
dx
1 + x2 +
 π
0
ρieiθ dθ
1 + ρ2e2iθ .

Section 7
Evaluation of Deﬁnite Integrals by Use of the Residue Theorem
689
We know that the value of the contour integral is π no matter how large ρ becomes
since there are no other singular points besides z = i in the upper half-plane. Let
ρ →∞; then the second integral on the right in (7.1) tends to zero since the
numerator contains ρ and the denominator ρ2. Thus the ﬁrst term on the right
tends to π (the value of the contour integral) as ρ →∞, and we have
I =
 ∞
−∞
dx
1 + x2 = π.
This method can be used to evaluate any integral of the form
 ∞
−∞
P(x)
Q(x) dx
if P(x) and Q(x) are polynomials with the degree of Q at least two greater than
the degree of P, and if Q(z) has no real zeros (that is, zeros on the x axis). If the
integrand P(x)/Q(x) is an even function, then we can also ﬁnd the integral from 0
to ∞.
Example 3.
Evaluate I =
 ∞
0
cos x dx
1 + x2 .
We consider the contour integral

C
eiz dz
1 + z2 ,
where C is the same semicircular contour as in Example 2.
The singular point
inclosed is again z = i, and the residue there is
lim
z→i(z −i)
eiz
(z −i)(z + i) = e−1
2i = 1
2ie.
The value of the contour integral is 2πi(1/2ie) = π/e. As in Example 2 we write
the contour integral as a sum of two integrals:
(7.2)

C
eiz dz
1 + z2 =
 ρ
−ρ
eix dx
1 + x2 +

along upper half
of z = ρeiθ
eiz dz
1 + z2 .
As before, we want to show that the second integral on the right of (7.2) tends to
zero as ρ →∞. This integral is the same as the corresponding integral in (7.1)
except for the eiz factor. Now
|eiz| = |eix−y| = |eix||e−y| = e−y ≤1
since y ≥0 on the contour we are considering. Since |eiz| ≤1, this factor does not
change the proof given in Example 2 that the integral along the semicircle tends to
zero as the radius ρ →∞. We have then
 ∞
−∞
eix
1 + x2 dx = π
e ,

690
Functions of a Complex Variable
Chapter 14
or taking the real part of both sides of this equation,
 ∞
−∞
cos x dx
1 + x2 = π
e .
Since the integrand (cos x)/(1 + x2) is an even function, the integral from 0 to ∞
is half the integral from −∞to ∞. Hence we have
I =
 ∞
0
cos x dx
1 + x2 = π
2e.
Observe that the same proof would work if we replaced eiz by eimz (m > 0) in
the above integrals. At the point where we said e−y ≤1 (since y ≥0) we would
then want e−my ≤1 for y ≥0, which is true if m > 0. [For m < 0, we could use a
semicircle in the lower half-plane (y < 0); then we would have emy ≤1 for y ≤0.
This is an unnecessary complication, however, in evaluating integrals containing
sin mx or cos mx since we can then choose m to be positive.] Although we have
assumed here that (as in Example 2) Q(x) is of degree at least 2 higher than P(x),
a more detailed proof (see books on complex variables) shows that degree at least
one higher is enough to make the integral
 P(z)
Q(z)eimz dz
around the semicircle tend to zero as ρ →∞. Thus
 ∞
−∞
P(x)
Q(x)eimx dx = 2πi · sum of the residues of P(z)
Q(z)eimz
in the upper half-plane if all the following requirements are met:
1. P(x) and Q(x) are polynomials, and
2. Q(x) has no real zeros, and
3. the degree of Q(x) is at least 1 greater than the degree of P(x), and m > 0.
By taking real and imaginary parts, we then ﬁnd the integrals
 ∞
−∞
P(x)
Q(x) cos mx dx,
 ∞
−∞
P(x)
Q(x) sin mx dx.
Example 4.
Evaluate
 ∞
−∞
sin x
x
dx.
Here we remove the restriction of Examples 2 and 3 that Q(x) has no real zeros.
As in Example 3, we consider
 eiz
z dz.
To avoid the singular point at z = 0, we integrate around the contour shown in
Figure 7.3. We then let the radius r shrink to zero so that in eﬀect we are integrat-
ing straight through the simple pole at the origin. We are going to show (later in this

Section 7
Evaluation of Deﬁnite Integrals by Use of the Residue Theorem
691
Figure 7.3
section and Problem 21) that the net result of inte-
grating in the counterclockwise direction around a
closed contour which passes straight‡ through one
or more simple poles is 2πi · (sum of the residues at
interior points plus one-half the sum of the residues
at the simple poles on the boundary). (Warning:
this rule does not hold in general for a multiple pole
on a boundary.) You might expect this result. If a
pole is inside a contour, it contributes 2πi· residue, to the integral; if it is outside,
it contributes nothing; if it is on the straight line boundary, its contribution is just
halfway between zero and 2πi· residue. [See Am. J. Phys. 52, 276 (1984).] Using
this fact, and observing that, as in Example 3, the integral along the large semicircle
tends to zero as R tends to inﬁnity, we have
 ∞
−∞
eix
x dx = 2πi · 1
2

residue of eiz
z
at z = 0

= 2πi · 1
2 · 1 = iπ.
Taking the imaginary parts of both sides, we get
 ∞
−∞
sin x
x
dx = π.
To show more carefully that our result is correct, let us return to the contour of
Figure 7.3. Since eiz/z is analytic inside this contour, the integral around the whole
contour is zero. As we have said, the integral along C tends to zero as R →∞by
the theorem at the end of Example 3. Along the small semicircle C′, we have
z = reiθ,
dz = reiθidθ,
dz
z = idθ,

C′
eiz dz
z
=

C′ eizidθ.
As r →0, z →0, eiz →1, and the integral (along C′ in the direction indicated in
Figure 7.3) tends to
 0
π
i dθ = −iπ.
Then we have as R →∞, and r →0,
 ∞
−∞
eix
x dx −iπ = 0
or
 ∞
−∞
eix
x dx = iπ
as before.
Taking real and imaginary parts of this equation (and using Euler’s
formula eix = cos x + i sin x), we get
 ∞
−∞
cos x
x
dx = 0,
 ∞
−∞
sin x
x
dx = π.
‡By “straight” we mean that the contour curve has a tangent at the pole, that is, it does not
turn a corner there.

692
Functions of a Complex Variable
Chapter 14
Since (sin x)/x is an even function, we have
 ∞
0
sin x
x
dx = 1
2
 ∞
−∞
sin x
x
dx = π
2 .
[For another way of evaluating this integral, see Chapter 7, equation (12.19).]
Principal value
Now consider the cosine integral.
 ∞
0
cos x
x
dx
is a divergent integral since the integrand (cos x)/x is approximately 1/x near x = 0.
The value zero which we found for I =
 ∞
−∞(cos x)/x dx is called the principal value
(or Cauchy principal value) of I. To see what this means, consider a simpler integral,
namely
 5
0
dx
x −3.
The integrand becomes inﬁnite at x = 3, and both
 3
0 dx/(x −3) and
 5
3 dx/(x −3)
are divergent. Suppose we cut out a small symmetric interval about x = 3, and
integrate from 0 to 3 −r and from 3 + r to 5. We ﬁnd
 3−r
0
dx
x −3 = ln |x −3|

3−r
0
= ln r −ln 3,
 5
3+r
dx
x −3 = ln 2 −ln r.
The sum of these two integrals is
ln 2 −ln 3 = ln 2
3;
this sum is independent of r. Thus, if we let r →0, we get the result ln 2
3 which is
called the principal value of
 5
0
dx
x −3

often written PV
 5
0
dx
x −3 = ln 2
3

.
The terms ln r and −ln r have been allowed to cancel each other; graphically an
inﬁnite area above the x axis and a corresponding inﬁnite area below the x axis have
been canceled. In computing the contour integral we integrated along the x axis
from −∞up to −r, and from +r to +∞, and then let r →0; this is just the process
we described for ﬁnding principal values, so the result we found for the improper
integral
 ∞
−∞(cos x)/x dx, namely zero, was the principal value of this integral.
Example 5.
Evaluate
 ∞
0
rp−1
1 + r dr,
0 < p < 1,
and use the result to prove (5.4) of Chapter 11.

Section 7
Evaluation of Deﬁnite Integrals by Use of the Residue Theorem
693
We ﬁrst ﬁnd
(7.3)

zp−1
1 + z dz,
0 < p < 1,
around C in Figure 7.4.
Before we can evaluate this integral, we must ask what zp−1 means, since for each z
there may be more than one value of zp−1. (See discussion of branches at the end of
Section 1.) For example, consider the case p = 1
2; then zp−1 = z−1/2. Recall from
Chapter 2, Section 10, that there are two square roots of any complex number. At
a point where θ = π/4, say, we have
z = reiπ/4,
z−1/2 = r−1/2e−iπ/8.
But if θ increases by 2π (we think of following a circle around the origin and back
to our starting point), we have
z = rei(π/4+2π),
z−1/2 = r−1/2e−i(π/8+π) = −r−1/2e−iπ/8.
Similarly, for any starting point (with r ̸= 0), we ﬁnd that z−1/2 or zp−1 comes
back to a diﬀerent value (diﬀerent branch) when θ increases by 2π and we return
to our starting point. If we want to use the formula zp−1 to deﬁne a (single-valued)
function, we must decide on some interval of length 2π for θ (that is, we must
select one branch of zp−1). Let us agree to restrict θ to the values of 0 to 2π in
evaluating the contour integral (7.3). We may imagine an artiﬁcial barrier or cut
(which we agree not to cross) along the positive x axis; this is called a branch cut.
(See Example 3, Section 9.) A point which we cannot encircle (on an arbitrarily
small circle) without crossing a branch cut (thus changing to another branch) is
called a branch point; the origin is a branch point here.
Figure 7.4
In Figure 7.4, then, θ = 0 along AB (upper side
of the positive x axis); when we follow C around to
DE, θ increases by 2π, so θ = 2π on the lower side of
the positive x axis. Note that the contour in Figure
7.4 never takes us outside the 0 to 2π interval, so the
factor zp−1 in (7.3) is a single-valued function. The
integrand in (7.3), namely zp−1/(1 + z), is now an
analytic function inside the closed curve C in Figure
7.4 except for the pole at z = −1 = eiπ. The residue
there is (eiπ)p−1 = −eiπp. Then we have
(7.4)

C
zp−1
1 + z dz = −2πieiπp,
0 < p < 1.
Along either of the two circles in Figure 7.4 we have z = reiθ and the integral is
 rp−1ei(p−1)θ
1 + reiθ
rieiθ dθ = i

rpeipθ
1 + reiθ dθ.
This integral tends to zero if r →0 or if r →∞.
(Verify this; note that the
denominator is approximately 1 for small r, and approximately reiθ for large r.)
Thus the integrals along the circular parts of the contour tend to zero as the little
circle shrinks to a point and the large circle expands indeﬁnitely. We are left with

694
Functions of a Complex Variable
Chapter 14
the two integrals along the positive x axis with AB now extending from 0 to ∞and
DE from ∞to 0. Along AB we agreed to have θ = 0, so z = rei·0 = r, and this
integral is
 ∞
r=0
rp−1
1 + r dr.
Along DE, we have θ = 2π, so z = re2πi and this integral is
 0
r=∞
(re2πi)p−1
1 + re2πi e2πi dr = −
 ∞
0
rp−1e2πip
1 + r
dr.
Adding the AB and DE integrals, we get
(1 −e2πip)
 ∞
0
rp−1
1 + r dr = −2πieiπp
by (7.4). Then the desired integral is
(7.5)
 ∞
0
rp−1
1 + r dr = −2πieiπp
1 −e2πip =
π · 2i
eiπp −e−iπp =
π
sin πp.
Let us use (7.5) to obtain (5.4) of Chapter 11. Putting q = 1 −p in (6.5) and
(7.1) of Chapter 11, we have
B(p, 1 −p) =
 ∞
0
yp−1
1 + y dy
and
B(p, 1 −p) = Γ(p)Γ(1 −p)
Γ(1) = 1.
(7.6)
Combining (7.5) and (7.6) gives (5.4) of Chapter 11, namely
Γ(p)Γ(1 −p) = B(p, 1 −p) =
 ∞
0
yp−1
1 + y dy =
π
sin πp.
Argument Principle
Since w = f(z) is a complex number for each z, we can
write w = ReiΘ (just as we write z = reiθ) where R = |w| and Θ is the angle of w
[or we could call it the angle of f(z)]. As z changes, w = f(z) also changes and so
R and Θ vary as we go from point to point in the complex (x, y) plane. We want
to show that
(a) if f(z) is analytic on and inside a simple closed curve C and f(z) ̸= 0 on C,
then the number of zeros of f(z) inside C is equal to (1/2π)· (change in the angle
of f(z) as we traverse the curve C);
(b) if f(z) has a ﬁnite number of poles inside C, but otherwise meets the re-
quirements stated,§ then the change in the angle of f(z) around C is equal to (2π)·
(the number of zeros minus the number of poles).
(Just as we say that a quadratic equation with equal roots has two equal roots,
so here we mean that a zero of order n counts as n zeros and a pole of order n
counts as n poles.)
To show (a) and (b) we consider

C
f ′(z)
f(z) dz.
§A function which is analytic except for poles is called meromorphic.

Section 7
Evaluation of Deﬁnite Integrals by Use of the Residue Theorem
695
By the residue theorem, the integral is equal to 2πi·(sum of the residues at singu-
larities inside C). It is straightforward to show (Problem 42) that the residue of
F(z) = f ′(z)/f(z) at a zero of f(z) of order n is n, and the residue of F(z) at a
pole of f(z) of order p is −p. Then if N is the number of zeros and P the number
of poles of f(z) inside C, the integral is 2πi(N −P). Now by direct integration, we
have
(7.7)

C
f ′(z)
f(z) dz = ln f(z)

C = ln ReiΘ
C = Ln R

C + iΘ

C,
where R = |f(z)| and Θ is the angle of f(z). Recall from Chapter 2, Section 13, that
Ln R means the ordinary real logarithm (to the base e) of the positive number R,
and is single-valued; ln f(z) is multiple-valued because Θ is multiple-valued. Then
if we integrate from a point A on C all the way around the curve and back to A,
Ln R has the same value at A both at the beginning and at the end, so the term
Ln R|C is Ln R at A minus Ln R at A; this is zero. The same result may not be
true for Θ; that is, the angle may have changed as we go from point A all the way
around C and back to A. (Think, for example, of the angle of z as we go from z = 1
around the unit circle and back to z = 1; the angle of z has increased from 0 to
2π.) Collecting our results, we have
N −P =
1
2πi

C
f ′(z)
f(z) dz =
1
2πiiΘC
(7.8)
= 1
2π · (change in the angle of f(z) around C),
where N is the number of zeros and P the number of poles of f(z) inside C, with
poles of order n counted as n poles and similarly for zeros of order n. Equation
(7.8) is known as the argument principle (recall from Chapter 2 that argument
means angle).
This principle is often used to ﬁnd out how many zeros (or poles) a given func-
tion has in a given region. (Locating the zeros of a function has important appli-
cations to determining the stability of linear systems such as electric circuits and
servomechanisms.
Example 6.
Let us show that f(z) = z3 + 4z + 1 has exactly one zero in the ﬁrst
Figure 7.5
quadrant.
The closed curve C in (7.8) is, for this problem, the contour OPQ
in Figure 7.5, where PQ is a large quarter circle. We ﬁrst observe that on the x
axis, x3 + 4x + 1 > 0 for x > 0, and on the y axis, (iy)3 + 4iy + 1 ̸= 0 for any
y (since its real part, namely 1, ̸= 0).
Then f(z) ̸= 0 on
OP or OQ. Also f(z) ̸= 0 on PQ if we choose a circle large
enough to inclose all zeros. We now want to ﬁnd the change
in the angle Θ of f(z) = ReiΘ as we go around C. Along
OP, z = x; then f(z) = f(x) is real and so Θ = 0. Along
PQ, z = reiθ, with r constant and very large. For very large
r, the z3 term in f(z) far outweighs the other terms, and we
have f(z) ∼= z3 = r3e3iθ. As θ goes from 0 to π/2 along PQ,

696
Functions of a Complex Variable
Chapter 14
Θ = 3θ goes from 0 to 3π/2. On QO, z = iy, f(z) = −iy3 + 4iy + 1; then
tan Θ = imaginary part of f(z)
real part of f(z)
= 4y −y3
1
.
For very large y (that is, at Q), we had Θ ∼= 3π/2 (for y = ∞, we would have
tan θ = −∞, and Θ would be exactly 3π/2). Now as y decreases along QO, the
value of tan Θ = 4y −y3 decreases in magnitude but remains negative until it
becomes 0 at y = 2. This means that Θ changes from 3π/2 to 2π. Between y = 2
and y = 0, the tangent becomes positive, but then decreases to zero again without
becoming inﬁnite. This means that the angle Θ increases beyond 2π but not as far
as 2π+π/2, and then decreases again to 2π. Thus the total change in Θ around C is
2π, and by (7.8), the number of zeros of f(z) in the ﬁrst quadrant is (1/2π)·2π = 1.
If we realize that (for a polynomial with real coeﬃcients) the zeros oﬀthe real axis
always occur in conjugate pairs, we see that there must also be one zero for z in
the fourth quadrant, and the third zero must be on the negative x axis.
Bromwich integral (Inverse Laplace Transform)
In Chapter 8 (Section 8ﬀ),
we found inverse Laplace transforms from a table (pages 469–471), or by computer,
but we had no general formula for the inverse transform. By analogy with Fourier
transforms (Chapter 7, Section 12), where we have similar integrals for the direct
and inverse transforms, we might reasonably wonder whether an inverse Laplace
transform could be given by an integral. To discuss this, we repeat here for conve-
nience the deﬁnitions of Laplace and Fourier transforms.
(7.9)
L(f) =
 ∞
0
f(t)e−ptdt = F(p)
f(x) =
 ∞
−∞
g(α)eiαxdα
g(α) = 1
2π
 ∞
−∞
f(x)e−iαxdx
(7.10)
If we compare the Laplace transform (7.9) with the Fourier transform [g(α) in
(7.10)], we observe that if p were imaginary, the integrals would be almost the
same. This suggests that we should consider complex p, and that the integral we
want for the inverse Laplace transform might be an integral in the complex p plane
(that is, a contour integral). Let’s investigate this idea.
In the deﬁnition (7.9) of the Laplace transform of f(t), let p be complex, say
p = z = x+iy. (Note that this possibility has already been considered in Chapter 8.)
Then (7.9) becomes
(7.11)
F(p) = F(z) = F(x + iy) =
 ∞
0
e−ptf(t) dt
=
 ∞
0
e−(x+iy)tf(t) dt =
 ∞
0
e−xtf(t)e−iyt dt,
x = Re p > k.
[Recall (Chapter 8, Section 8) that we must have some restriction on Re p to make
the integral converge at inﬁnity.
The restriction depends on what the function
f(t) is, but is always of the form Re p > k, for some real k, as you can see in

Section 7
Evaluation of Deﬁnite Integrals by Use of the Residue Theorem
697
the table of Laplace transforms, pages 469–471.] Now (7.11) is of the form of a
Fourier transform. To see this, compare (7.11) with (7.10) making the following
correspondences: e−iyt dt corresponds to e−iαx dx, that is, y corresponds to α and
t to x [the x in (7.11) is just a constant parameter in this discussion]; the function
(7.12)
φ(t) =

e−xtf(t),
t > 0,
0,
t < 0,
corresponds to f(x) in (7.10) and F(p) = F(x+iy) corresponds to g(α); and ﬁnally,
we recall that the 1/(2π) factor may be in either integral in (7.10). Then assuming
that φ(t) satisﬁes the required conditions for a function to have a Fourier transform
[see Chapter 7, Section 12: Dirichlet conditions, and
 ∞
−∞|φ(t)| dt ﬁnite], we can
write the inverse transform to get
(7.13)
φ(t) = 1
2π
 ∞
−∞
F(x + iy)eiyt dy.
Using the deﬁnition (7.12) of φ(t), we ﬁnd
(7.14)
f(t) = ext · 1
2π
 ∞
−∞
F(x + iy)eiyt dy = 1
2π
 ∞
−∞
F(x + iy)e(x+iy)t dy
for t > 0. Since x is constant, say x = c, we have dz = d(x + iy) = i dy, and we can
write (7.14) as
(7.15)
f(t) =
1
2πi
 c+i∞
c−i∞
F(z)ezt dz,
t > 0,
where the notation means (see Problem 3.4) that we integrate along a vertical line
x = c in the z plane. [This can be any vertical line on which x = c > k as required
by the restriction on Re p in (7.11).] The integral (7.15) for the inverse Laplace
transform is known as the Bromwich integral.
We would like to use contour integration and the residue theorem to evaluate
f(t) in (7.15) for a given F(p) [which we call F(z) since we consider complex p].
In Examples 2 and 3, we have evaluated integrals along a straight line (the x axis)
by considering the contour made up of the x axis and a large semicircle inclosing
the upper half plane. If we rotate this contour 90◦, we have a contour consisting of
a vertical straight line and a semicircle inclosing a left half-plane (that is, the area
to the left of x = c). Let’s use this contour to evaluate (7.15). We restrict F(z) to
be of the form P(z)/Q(z) with P(z) and Q(z) polynomials, and Q(z) of degree at
least one higher than P(z) (compare the conditions in Example 3). Then it can be
shown that, as in Examples 2 and 3, the integral along the semicircle tends to zero
as the radius tends to inﬁnity. Thus the integral along the straight line is equal to
2πi times the sum of the residues of F(z)ezt at its poles, or, cancelling the factor
2πi in (7.15),
(7.16)
f(t) = sum of residues of F(z)ezt at all poles.
We must include all poles in (7.16); to see this we can argue as follows. We know
that (7.15) is true for any value of c > k. Suppose we use a value of c which is

698
Functions of a Complex Variable
Chapter 14
large enough so that all poles lie to the left of x = c; then we know that our answer
is correct. Turning the argument around, we can say that since we would get a
diﬀerent answer if we did not take x = c to the right of all poles, we must integrate
along a vertical line such that all poles of F(z)ezt are included in the contour to
the left of the line.
Example 7.
Find the inverse transform of F(p) =
5
(p + 2)(p2 + 1).
We ﬁrst ﬁnd the poles of F(z)ezt and factor the denominator to get
F(z)ezt =
5ezt
(z + 2)(z + i)(z −i).
Evaluating the residues at the three simple poles (Section 6, method B), we ﬁnd
residue at z = −2
is
5e−2t
5
= e−2t
residue at z = i
is
5eit
(2 + i)(2i)
residue at z = −i
is
5e−it
(2 −i)(−2i)
Then by (7.16) we have
f(t) = e−2t + 5eit(2 −i) −5e−it(2 + i)
(2 + i)(2 −i)(2i)
= e−2t + 2 sin t −cos t.
Dispersion relations
Consider

f(z)
z −a dz around the upper half plane as in
Problem 21. Let a be real. Let f(z) be analytic for y ≥0, and →0 rapidly enough
at ∞so that the integral around the semicircle in the upper half plane →0 as the
radius of the semicircle →∞. Then by Example 4 and Problem (21b) we get
(7.17)
PV
 ∞
−∞
f(x)
x −a dx = iπf(a).
Now we write f(x) = u(x) + iv(x), and take real and imaginary parts of (7.17):
(7.18)
PV
 ∞
−∞
u(x)
x −a dx = −πv(a),
PV
 ∞
−∞
v(x)
x −a dx = πu(a).
These (and similar integrals relating the real and imaginary parts of a function
satisfying the given conditions) are called dispersion relations. From them, you can
ﬁnd the Kramers-Kronig relations (see Problem 66) named for the two people who
developed similar relations involving the complex index of refraction for light. (Light
traveling through a material medium is both refracted and absorbed. The real part
of the complex index of refraction is related to refraction and the imaginary part
to absorption.) These formulas have widespread applications, to optics, electricity,
solid state, elementary particle theory, quantum mechanics, etc.
The integrals in (7.18) are called Hilbert transforms, and (7.18) may be stated
in the form: u(x) and v(x) are Hilbert transforms of each other. Compare Fourier

Section 7
Evaluation of Deﬁnite Integrals by Use of the Residue Theorem
699
transforms (Chapter 7, Section 12), or a Laplace transform and the corresponding
Bromwich integral. In each case two functions have the property that each is given
by an integral involving the other. This is what an integral transform means, and
there are other integral transforms which you may discover in tables or computer.
PROBLEMS, SECTION 7
The values of the following integrals are known and can be found in integral tables or by
computer. Your goal in evaluating them is to learn about contour integration by applying
the methods discussed in the examples above. Then check your answers by computer.
1.
Z 2π
0
dθ
13 + 5 sin θ
2.
Z 2π
0
dθ
5 −3 cos θ
3.
Z 2π
0
dθ
5 −4 sin θ
4.
Z 2π
0
sin2 θ dθ
5 + 3 cos θ
5.
Z π
0
dθ
1 −2r cos θ + r2
(0 ≤r < 1)
6.
Z π
0
dθ
(2 + cos θ)2
7.
Z 2π
0
cos 2θ dθ
5 + 4 cos θ
8.
Z π
0
sin2 θ dθ
13 −12 cos θ
9.
Z 2π
0
dθ
1 + sin θ cos α
(α = const.)
10.
Z ∞
−∞
dx
x2 + 4x + 5
11.
Z ∞
0
dx
(4x2 + 1)3
12.
Z ∞
0
x2 dx
x4 + 16
13.
Z ∞
0
x2 dx
(x2 + 4)(x2 + 9)
14.
Z ∞
−∞
sin x dx
x2 + 4x + 5
15.
Z ∞
0
cos 2x dx
9x2 + 4
16.
Z ∞
0
x sin x dx
9x2 + 4
17.
Z ∞
−∞
x sin x dx
x2 + 4x + 5
18.
Z ∞
0
cos πx dx
1 + x2 + x4
19.
Z ∞
0
cos 2x dx
(4x2 + 9)2
20.
Z ∞
0
cos x dx
(1 + 9x2)2
21.
In Example 4 we stated a rule for evaluating a contour integral when the contour
passes through simple poles. We proved that the result was correct for
PV
Z
Γ
eiz
z dz
around the contour Γ shown here.
(a) By following the same method (integrating around C′ of Figure 7.3 and letting
r →0) show that the result is correct if we replace eiz by any f(z) which is analytic
at z = 0.
(b) Repeat the proof in (a) for
PV
Z
Γ
f(z)
(z −a) dz,
a real
(that is, a pole on the x axis), with f(z) analytic at z = a.

700
Functions of a Complex Variable
Chapter 14
Using the rule of Example 4 (also see problem 21), evaluate the following integrals. Find
principal values if necessary.
22.
Z ∞
−∞
dx
(x −1)(x2 + 1)
23.
Z ∞
−∞
dx
(x2 + 4)(2 −x)
24.
Z ∞
−∞
x sin πx
1 −x2 dx
25.
Z ∞
0
x sin x
9x2 −π2 dx
26.
Z ∞
−∞
x dx
(x −1)4 −1
27.
Z ∞
0
cos πx
1 −4x2 dx
28.
Z ∞
0
dx
1 −x4
29.
Z ∞
0
sin ax
x
dx
30.
(a)
By the method of Example 2 evaluate
Z ∞
0
dx
1 + x4 .
(b)
Evaluate the same integral by using tables or computer to get the indeﬁnite
integral; unless you are very careful you may get zero. Explain why.
(c)
Make the change of variables u = x4 in the integral in (a) and evaluate the u
integral using (7.5).
31.
Use the method of Problem 30(c) to evaluate
Z ∞
0
dx
1 + x6 .
32.
Use the method of Problem 30(c) and the contour and method of Example 5 to
evaluate
Z ∞
0
dx
(1 + x4)2 .
Evaluate the following integrals by the method of Example 5.
33.
Z ∞
0
√x dx
1 + x2
34.
Z ∞
0
√x dx
(1 + x)2
35.
Z ∞
0
x1/3 dx
(1 + x)(2 + x)
36.
Z ∞
0
ln x
x3/4(1 + x) dx
37.
(a)
Show that
Z ∞
−∞
epx
1 + ex dx =
π
sin πp
for 0 < p < 1. Hint: Find
R
epz dz/(1 + ez) around the rectangular contour
shown. Show that the integrals along the vertical sides tend to zero as A →∞.
Note that the integral along the upper side is a multiple of the integral along
the x axis.
(b)
Make the change of variable y = ex in the x integral of part (a), and using
(6.5) of Chapter 11, show that this integral is the beta function, B(p, 1 −p).
Then using (7.1) of Chapter 11, show that Γ(p)Γ(1 −p) = π/ sin πp.

Section 7
Evaluation of Deﬁnite Integrals by Use of the Residue Theorem
701
38.
Using the same contour and method as in Problem 37a evaluate
Z ∞
−∞
epx
1 −ex dx,
0 < p < 1.
Hint: The only diﬀerence between this problem and Problem 37a is that you now
have two simple poles on the contour instead of a pole inside.
Use the rule of
Example 4.
39.
Evaluate
Z ∞
−∞
e2πx/3
cosh πx dx.
Hint: Use a rectangle as in Problem 37a but of height 1 instead of 2π. Note that
there is a pole at i/2.
40.
Evaluate
Z ∞
0
x dx
sinh x.
Hint: First ﬁnd the −∞to ∞integral. Use a rectangle of height π and note the
simple pole at iπ on the contour.
41.
The Fresnel integrals,
R u
0 sin u2 du and
R u
0 cos u2 du, are important in optics. For
the case of inﬁnite upper limits, evaluate these integrals as follows:
Make the
change of variable x = u2; to evaluate the resulting
integrals, ﬁnd
H
z−1/2eiz dz around the contour shown.
Let r →0 and R →∞and show that the integrals
along these quarter-circles tend to zero. Recognize the
integral along the y axis as a Γ function and so eval-
uate it. Hence evaluate the integral along the x axis;
the real and imaginary parts of this integral are the
integrals you are trying to ﬁnd.
42.
If F(z) = f ′(z)/f(z),
(a)
show that the residue of F(z) at an nth order zero of f(z), is n. Hint: If f(z)
has a zero of order n at z = a, then
f(z) = an(z −a)n + an+1(z −a)n+1 + · · · .
(b)
Also show that the residue of F(z) at a pole of order p of f(z), is −p. Hint:
See the deﬁnition of a pole of order p at the end of Section 4.
43.
By using theorem (7.8), show that z3 + z2 + 9 = 0 has exactly one root in the ﬁrst
quadrant. Hence show that it has one root in the fourth quadrant and one on the
negative real axis. Hint: See Example 6.
44.
The fundamental theorem of algebra says that every equation of the form f(z) =
anzn + an−1zn−1 + · · · + a0 = 0, an ̸= 0, n ≥1, has at least one root. From this it
follows that an nth degree equation has n roots. Prove this by using the argument
principle. Hint: Follow the increase in the angle of f(z) around a very large circle
z = reiθ; for suﬃciently large r, all roots are inclosed, and f(z) is approximately
anzn.
As in Problem 43 ﬁnd out in which quadrants the roots of the following equations lie:
45.
z3 + z2 + z + 4 = 0
46.
z3 + 3z2 + 4z + 2 = 0
47.
z3 + 4z2 + 12 = 0
48.
z4 −z3 + 6z2 −3z + 5 = 0

702
Functions of a Complex Variable
Chapter 14
49.
z4 −4z3 + 11z2 −14z + 10 = 0
50.
z4 + z3 + 4z2 + 2z + 3 = 0
51.
Use (7.8) to evaluate
I
C
f ′(z)
f(z) dz,
where
f(z) = z3(z + 1)2 sin z
(z2 + 1)2(z −3),
around the circle |z| = 2; around |z| = 1
2.
52.
Use (7.8) to evaluate
I
z3 dz
1 + 2z4 around |z| = 1.
53.
Use (7.8) to evaluate
I
z3 + 4z
z4 + 8z2 + 16 dz around the circle |z −2i| = 2.
54.
Use (7.8) to evaluate
I
C
sec2(z/4) dz
1 −tan(z/4),
where C is the rectangle formed by the lines y = ±1, x = ± 5
2π.
Find the inverse Laplace transform of the following functions by using (7.16).
55.
p3
p4 + 4
Hint: Use (6.2).
56.
1
p4 −1
57.
p + 1
p(p2 + 1)
58.
p3
p4 −16
59.
3p2
p3 + 8
60.
1
p2(p + 1)
61.
p5
p6 −64
62.
(p −1)2
p(p + 1)2
63.
p
p4 −1
64.
p2
(p2 −1)(p2 −4)
65.
p
(p + 1)(p2 + 4)
66.
In equation (7.18), let u(x) be an even function and v(x) be an odd function.
(a)
If f(x) = u(x)+iv(x), show that these conditions are equivalent to the equation
f∗(x) = f(−x).
(b)
Show that
πu(a) = PV
Z ∞
0
2xv(x)
x2 −a2 dx,
πv(a) = −PV
Z ∞
0
2au(x)
x2 −a2 dx.
These are the Kramers-Kronig relations. Hint: To ﬁnd u(a), write the integral for u(a)
in (7.18) as an integral from −∞to 0 plus an integral from 0 to ∞. Then in the −∞to
0 integral, replace x by −x to get an integral from 0 to ∞, and use v(−x) = −v(x). Add
the two 0 to ∞integrals and simplify. Similarly ﬁnd v(a).
8. THE POINT AT INFINITY; RESIDUES AT INFINITY
It is often useful to think of the complex plane as corresponding to the surface of
a sphere in the following way. In Figure 8.1, the sphere is tangent to the plane at
the origin O. Let O be the south pole of the sphere, and N be the north pole of
the sphere. If a line through N intersects the sphere at P and the plane at Q, we
say that the point P on the sphere and the point Q on the plane are correspond-
ing points. Then we have a one-to-one correspondence between points on the sphere

Section 8
The Point at Inﬁnity; Residues at Inﬁnity
703
Figure 8.1
(except N) and points of the plane (at
ﬁnite distances from O). Imagine point
Q moving farther and farther out away
from O; then P moves nearer and nearer
to N.
If z = x + iy is the complex
coordinate of Q, then as Q moves out
farther and farther from O, we would
say z →∞. It is customary to say that
the point N corresponds to the point at
inﬁnity in the complex plane. Observe
that straight lines through the origin in
the plane correspond to meridians of the sphere. The meridians all pass through
both the north pole and the south pole. Corresponding to this, straight lines through
the origin in the complex plane pass through the point at inﬁnity. Circles in the
complex plane with center at O correspond to parallels of latitude on the sphere.
This mapping of the complex plane onto a sphere (or the mapping of the sphere
onto a tangent plane) is called a stereographic projection.
To investigate the behavior of a function at inﬁnity, we replace z by 1/z and
consider how the new function behaves at the origin. We then say that inﬁnity is
a regular point, a pole, etc., of the original function, depending on what the new
function does at the origin. For example, consider z2 at inﬁnity; 1/z2 has a pole of
order 2 at the origin, so z2 has a pole of order 2 at inﬁnity. Or consider e1/z; since
ez is analytic at z = 0, e1/z is analytic at ∞.
Next we want to see how to ﬁnd the residue of a function at ∞. To do this, we
want to replace z by 1/z and work around the origin. In order to keep our notation
straight, let us use two variables, namely Z which takes on values near ∞, and
z = 1/Z which takes on values near 0. The residue of a function at ∞is deﬁned so
that the residue theorem holds, that is
(8.1)

C
f(Z) dZ = 2πi · (residue of f(Z) at Z = ∞)
if C is a closed path around the point at ∞but inclosing no other singular points.
Now what does it mean to integrate “around ∞”? Recall that we have agreed to
traverse contours so that the area inclosed always lies to our left. The area we wish
to “inclose” is the area “around ∞”; if C is a circle, this area would lie outside
the circle in our usual terminology. Figure 8.1 may clarify this. Imagine a small
circle about the north pole; the area inside this circle (that is, the area including
N) corresponds to points in the plane which are outside a large circle C. We must
go around C in the clockwise direction in order to have the area “around ∞” to
our left. Note that if Z = ReiΘ, then in going clockwise around C, we are going in
the direction of decreasing Θ. Let us make the following change of variable in the
integral (8.1):
Z = 1
z ,
dZ = −1
z2 dz.
If Z = ReiΘ traverses a circle C of radius R in the direction of decreasing Θ,
then z = 1/Z = (1/R)e−iΘ = reiθ traverses a circle C′ of radius r = 1/R in the
counterclockwise direction (that is, θ = −Θ increases as Θ decreases). Thus (8.1)

704
Functions of a Complex Variable
Chapter 14
becomes
(8.2)

C′ −1
z2 f
1
z

dz = 2πi · residue of f(Z) at Z = ∞.
The integral in (8.2) is an integral about the origin and so can be evaluated by
calculating the residue of (−1/z2)f(1/z) at the origin. (There are no other singular
points of f(1/z) inside C′ because we assumed that there were no singular points
of f(Z) outside C except perhaps ∞.) Thus we have
(8.3)
(residue of f(Z) at Z = ∞) = −

residue of 1
z2 f
1
z

at z = 0

and we can use the methods we already know for computing residues at the origin.
Note that a function may be analytic at ∞and still have a residue there.
Example.
f(Z) = 1/Z is analytic at ∞because z is analytic at the origin. But the
residue of f(Z) = 1/Z at Z = ∞is
−

residue of 1
z2 · z at z = 0

= −1.
PROBLEMS, SECTION 8
1.
Let f(z) be expanded in the Laurent series that is valid for all z outside some circle,
that is, |z| > M (see Section 4). This series is called the Laurent series “about
inﬁnity.” Show that the result of integrating the Laurent series term by term around
a very large circle (of radius > M) in the positive direction, is 2πib1 (just as in the
original proof of the residue theorem in Section 5). Remember that the integral
“around ∞” is taken in the negative direction, and is equal to 2πi·(residue at ∞).
Conclude that R(∞) = −b1. Caution: In using this method of computing R(∞),
be sure you have the Laurent series that converges for all suﬃciently large z.
2.
(a)
Show that if f(z) tends to a ﬁnite limit as z tends to inﬁnity, then the residue
of f(z) at inﬁnity is limz→∞z2f ′(z).
(b)
Also show that if f(z) tends to zero as z tends to inﬁnity, then the residue of
f(z) at inﬁnity is −limz→∞zf(z).
Find out whether inﬁnity is a regular point, an essential singularity, or a pole (and if a
pole, of what order) for each of the following functions. Using Problem 1, or Problem 2,
or (8.3), ﬁnd the residue of each function at inﬁnity. Check your results by computer.
3.
z
z2 + 1
4.
2z + 3
(z + 2)2
5.
sin 1
z
6.
z2 + 5
z
7.
4z3 + 2z + 3
z2
8.
z2 + 2
3z2
9.
z2 −1
z2 + 1
10.
1 + z
1 −z
11.
tan 1
z
12.
ln z + 1
z −1
13.
Give another proof of the fundamental theorem of algebra (see Problem 7.44) as
follows. Let I =
H
f ′(z)/f(z) dz about inﬁnity, that is, in the negative direction
around a very large circle C. Use the argument principle (7.8), and also evaluate
I by ﬁnding the residue of f ′(z)/f(z) at inﬁnity; thus show that f(z) has n zeros
inside C.

Section 9
Mapping
705
Evaluate the following integrals by computing residues at inﬁnity. Check your answers by
computing residues at all the ﬁnite poles. (It is understood that
H
means in the positive
direction.)
14.
I 1 −z2
1 + z2
dz
z
around |z| = 2.
15.
I
z2 dz
(2z + 1)(z2 + 9)
around |z| = 5.
16.
Observe that in Problems 14 and 15 the sum of the residues at ﬁnite points plus the
residue at inﬁnity is zero. Prove that this is always true for a function which has a
ﬁnite number of singularities.
9. MAPPING
We often ﬁnd it useful to sketch a graph of a given function y = f(x) of a real
variable x. Imagine trying to make a similar sketch for a function w = f(z) of a
complex variable z. We need a plane to plot values of z and another plane to plot
values of w = f(z), that is, we need a four-dimensional space. Lacking this, we
must resort to a diﬀerent method. Imagine trying to “graph” y = f(x) using only
two straight lines, but not a plane. A “graph” of y = x2 might look like Figure 9.1.
Given a point on the x axis, we can locate a corresponding point y = f(x) on the y
axis and label the two points with the same letter to indicate this correspondence.
(Note that to ﬁnish our “graph,” we really need a second positive y axis to hold the
y points corresponding to negative values of x.)
Figure 9.1
Now consider a similar method of representing a function of a complex variable
w = f(z). We use a z plane and a w plane; a given point in the z plane (that is, a
value of z) determines a corresponding value of w, that is, a point in the w plane.
The pair of points, one z and one w, are called images of each other. Although
we could label pairs of corresponding z and w points (as we did corresponding x
and y points in Figure 9.1), it is usually more interesting to sketch corresponding
curves or regions in the two planes. The correspondence between a point (or curve
or region) in the z plane, and the image point (or curve or region) in the w plane,
is called a mapping or a transformation.
Example 1.
Consider the function w = i + zeiπ/4, and let us map the grid of coordinate
lines x = const., y = const. (z plane in Figure 9.2) into the w plane. You may
be able to see at once that this transformation amounts to a rotation of the grid
through an angle of π/4 (since zeiπ/4 = rei(θ+π/4)) plus a translation i (the image
of z = 0 is w = i), giving the result shown in the w plane in Figure 9.2. Alternatively,

706
Functions of a Complex Variable
Chapter 14
Figure 9.2
we can compute u and v as follows:
w = i + zeiπ/4 = i + (x + iy)

cos π
4 + i sin π
4

= i + (x + iy)
1 + i
√
2

= x −y
√
2
+ i

1 + x + y
√
2

.
Since w = u + iv, we have
(9.1)
u = x −y
√
2 ,
v = 1 + x + y
√
2 .
Then (eliminating x and y in turn), we have
(9.2)
u −v = −1 −y
√
2,
u + v = 1 + x
√
2.
The image of the x axis (y = 0) is, from the ﬁrst equation in (9.2), u −v = −1; the
image of the y axis (x = 0) is, from the second equation in (9.2), u+v = 1. Plotting
these lines in the w plane, and also plotting the images of x = ±
√
2, x = ±2
√
2,
y = ±
√
2, y = ±2
√
2 [using the equations (9.2)], we get Figure 9.2. (Verify that
the shaded squares are images of each other.)
If the elimination [to get (9.2)] is not easy, we can use equations (9.1) directly.
Suppose that we want the image of y = 0. With y = 0, equations (9.1) become
u = x/
√
2, v = 1+x/
√
2; these are a pair of parametric equations for a curve in the
(u, v) plane, with x as the parameter. Similarly, to ﬁnd the image of x = const.,
we substitute the value of x into (9.1); we then have a pair of parametric equations
with y as the parameter.
Note that we could just as easily have found the images in the z plane of the lines
u = const., and v = const. For example, letting u = 0 in (9.1), we get x −y = 0;
the image of the v axis (u = 0) is the 45◦line in the (x, y) plane. (We might have
guessed that going back to the z plane would involve a rotation through −45◦.) In
any given problem, we may start with simple curves (or regions) in either the z
plane or the w plane, and ﬁnd their images in the other plane.

Section 9
Mapping
707
Example 2.
Let us map the coordinate grid u = const., v = const., into the z plane by
the function w = z2. We have
w = z2 = (x + iy)2 = x2 −y2 + 2ixy,
u = x2 −y2,
v = 2xy.
(9.3)
Then the images of u = const. are hyperbolas x2 −y2 = const., and the images of
v = const. are also hyperbolas xy = const. (Figure 9.3). Alternatively, we could
map the lines x = const., y = const. into the w plane (Problem 1); this gives two
sets of parabolas in the (u, v) plane. Accurate graphs can be obtained by computer.
Figure 9.3
Example 3.
Let us consider still another useful way of discussing the mapping by w = z2.
Using polar coordinates, we have
(9.4)
z = reiθ,
w = z2 = r2e2iθ.
Consider the region inside the circle r = 1 in the (x, y) plane. If r = 1 in (9.4), we
have z = eiθ, w = e2iθ. The angle of w is twice the angle of z; thus the ﬁrst-quadrant
part of the area inside the circle r = 1 in the z plane maps into a semicircular area
in the w plane as indicated by the shading in Figure 9.4. The second quadrant of
the z plane disk (θ between π/2 and π) maps into the lower half of the disk in the
w plane (angle of w between π and 2π) as indicated. We have now used up the
whole area of the disk in the w plane and only half of the z plane disk. (Compare
Figure 9.1 and the comment about a second y axis.) In order to have a one-to-one
correspondence between points in the z plane and their images in the w plane, we
draw a second w plane (w plane II in Figure 9.4) to contain the images of points in
the lower half of the z plane. (Convince yourself that the two lower quarter-disks in
the z plane and their images in w plane II are correctly indicated by the shading.)
We agree that as we reach the angle 2π in w plane I, we go over to w plane II,
and as we reach the angle 4π in w plane II, we go back to w plane I. The two w
planes joined in this way are called a Riemann surface; each plane is called a sheet
of the Riemann surface. Note that the line along which the sheets of the Riemann
surface are joined (positive real axis here) is a branch cut, and the origin is a branch
point (see Example 5, Section 7). Here the branch cut and Riemann surface are in

708
Functions of a Complex Variable
Chapter 14
Figure 9.4
the w plane because z = √w has two branches; for w = √z, the Riemann surface
would be in the z plane (as in Section 7). It is not necessary to take the branch
cut along the positive x axis; we can select any 2π interval for one branch of √w,
for example from −π to π instead of 0 to 2π. A Riemann surface may have many
sheets; for example for w = z5, there are 5 sheets, and for w = ln z, there are an
inﬁnite number. For more detail, see complex variables texts.
Conformal Mapping
We have been discussing mappings or transformations. We
used the term transformation in Chapters 3 and 10, meaning a change of variables or
a change of coordinate system or a change of basis; let us see the connection between
the two discussions. In Chapter 10 we used only one plane [the (x, y) plane]; we
located a point in the (x, y) plane by giving its rectangular coordinates (x, y), or
its polar coordinates (r, θ), or some other coordinates (u, v). In polar coordinates,
the circles r = const., and the rays θ = const., were sketched in the (x, y) plane.
Similarly, for any coordinate system (u, v) (in Chapter 10, see Section 8 and the
Section 8 problems), we sketched the curves u = const., v = const., in the (x, y)
plane. In the complex variable language we are now using, this amounts to mapping
the w plane lines u = const., v = const., into the z plane. In Chapter 10 we were
particularly interested in transformations to orthogonal curvilinear coordinates. Let
us see that any analytic function w = f(z) = u + iv gives us a transformation to an
orthogonal coordinate system (u, v). We have
(9.5)
dz = dx + idy,
dw = du + idv,
|dz|2 = dx2 + dy2,
|dw|2 = du2 + dv2.
Then the square of the arc length element in the (x, y) plane is
(9.6)
ds2 = dx2 + dy2 = |dz|2 =

dz
dw

2
|dw|2 =

dz
dw

2
(du2 + dv2).
Since there is no du dv term in ds2, the (u, v) coordinate system is orthogonal
(Chapter 10, Section 8). By this we mean that if we obtain u(x, y) and v(x, y) from

Section 9
Mapping
709
f(z) = u + iv and plot the curves u(x, y) = const., v(x, y) = const. in the (x, y)
plane, we have two sets of mutually orthogonal curves. These are the coordinate
curves for the (u, v) coordinate systems as in Chapter 10. If we solve the equations
u = u(x, y), v = v(x, y) for x and y in terms of u and v, we have the transformation
equations from the variables x, y to the variables u, v as in Problems 8.6 to 8.9 of
Chapter 10, and by (9.6) we know that the coordinate system (u, v) is an orthogonal
system [if f(z) is analytic]. We see an example of this in Figure 9.3 (two orthogonal
sets of hyperbolas). Note from (9.6) that the two scale factors in a (u, v) coordinate
system obtained this way are equal.
Figure 9.5
Although we used only one plane in Chapter 10, for complex variables we ﬁnd
it useful to consider both the z plane [that is the (x, y) plane] and the w plane
[that is, the (u, v) plane]. In the (x, y) plane, the arc length element ds is given
by ds2 = dx2 + dy2. Similarly, in the (u, v) plane, the arc length element (which
we shall call dS) is given by dS2 = du2 + dv2.
From (9.5) we see that ds =
|dz| and dS = |dw|.
Then the ratio of
dS to ds is |dw/dz|. Consider a point z
(and its image w) at which w(z) is analytic
and dw/dz is not zero. If we stay near z,
the value of dw/dz is almost constant, and
the ratio dS/ds is nearly constant. This
says that if we consider a small area in
the z plane (ABCD in Figure 9.5) and its
image (A′B′C′D′ in Figure 9.5) in the w
plane, then
(9.7)
A′B′
AB = B′C′
BC = C′D′
CD = D′A′
DA = dS
ds =

dw
dz
 ,
that is, the two small areas are similar ﬁgures (since corresponding sides are propor-
tional). Because of this property of any mapping by an analytic function, we call the
mapping or transformation conformal (same form or shape). Corresponding angles
are equal (A = A′, etc.) and the net result of the transformation is to magnify (or
minify) and rotate each inﬁnitesimal area. Note that the conformal property is a
local one; since the value of dw/dz changes from point to point, each tiny bit of a
ﬁgure is magniﬁed and rotated by a diﬀerent amount, and so a large ﬁgure will not
have the same shape after mapping. Also note that we do not have conformality
in the neighborhood of a point where dw/dz = 0; for example, in Figure 9.4 a tiny
quarter-circle about the origin in the z plane maps into a tiny semicircle in the w
plane.
PROBLEMS, SECTION 9
In these problems you should be able to make rough sketches by hand, but for accurate
graphs use a computer.
1.
Solve equations (9.3) for x and y in terms of u and v. Use your equations to sketch
the images in the w plane of the z plane lines x = const. (for several values of x)
and similarly of y = const.

710
Functions of a Complex Variable
Chapter 14
For each of the following functions w = f(z) = u + iv, ﬁnd u and v as functions of x
and y. Sketch the graphs in the (x, y) plane of the images of u = const. and v = const.
for several values of u and several values of v as was done for w = z2 in Figure 9.3. The
curves u = const. should be orthogonal to the curves v = const.
2.
w = z + 1
2i
3.
w = 1
z
4.
w = ez
5.
w = z −i
z + i
6.
w = √z. Hint: This is equivalent to w2 = z; ﬁnd x and y in terms of u and v and
then solve the pair of equations for u and v in terms of x and y. Note that this is
really the same problem as Problem 1 with the z and w planes interchanged.
7.
w = sin z
8.
w = cosh z
Describe the Riemann surface for
9.
w = z3
10.
w = √z
11.
w = ln z
12.
If w = f(z) = u(x, y) + iv(x, y), f(z) analytic, deﬁnes a transformation from the
variables x, y to the variables u, v, show that the Jacobian of the transformation
(Chapter 5, Section 4) is ∂(u, v)/∂(x, y) = |f′(z)|2. Hint: To simplify the deter-
minant, use the Cauchy-Riemann equations and the equations (Section 2) used in
obtaining them.
13.
Verify the matrix equation
„du
dv
«
= J
„dx
dy
«
,
where J is a matrix whose determinant is the Jacobian in Problem 12. Multiply the
matrix equation by its transpose and use Problem 12 to obtain dS/ds = |dw/dz| as
in (9.7).
14.
We have discussed the fact that a conformal transformation magniﬁes and rotates
an inﬁnitesimal geometrical ﬁgure. We showed that |dw/dz| is the magniﬁcation
factor. Show that the angle of dw/dz is the rotation angle. Hint:
Consider the
rotation and magniﬁcation of an arc dz = dx + idy (of length ds and angle arc tan
dy/dx) which is required to obtain the image of dz, namely dw.
15.
Compare the directional derivative dφ/ds (Chapter 6, Section 6) at a point and
in the direction given by dz in the z plane, and the directional derivative dφ/dS
in the direction in the w plane given by the image dw of dz.
Hence show that
the rate of change of T in a given direction in the z plane is proportional to the
corresponding rate of change of T in the image direction in the w plane.
(See
Section 10, Example 2.) Show that the proportionality constant is |dw/dz|. Hint:
See equations (9.6) and (9.7).
10. SOME APPLICATIONS OF CONFORMAL MAPPING
Many diﬀerent physical problems require solution of Laplace’s equation. We are
going to show how to solve a few such problems by conformal mapping. Much of
this work can be done by computer. But before you can use the computer, you
need to know the basic theory behind the use of conformal mapping. Our purpose
in this section is to learn this background. First we consider a very simple problem
for which we know the answer from elementary physics.

Section 10
Some Applications of Conformal Mapping
711
Figure 10.1
Example 1.
In Figure 10.1, the shaded area in the (u, v) plane represents a rectangular
plate. The ends and faces of the plate are insulated, the bottom edge is held at
temperature T = 0◦, and the top edge at T = 100◦. Then we know from elementary
physics that the temperature increases linearly from the bottom edge (v = 0) to the
top edge (v = π), that is, T = (100/π)v at any point of the plate. Let us also derive
this answer by a more advanced method. It is known from the theory of heat that
the temperature T of a body satisﬁes Laplace’s equation in regions where there is no
source of heat. (See Chapter 13, Section 2.) In our problem we want a solution of
Laplace’s equation which satisﬁes the boundary conditions, that is, T = 100◦when
v = π, T = 0◦when v = 0, and ∂T/∂u = 0 on the ends (see Chapter 13, Problem
2.14). You should verify that T = 100v/π satisﬁes ∂2T/∂u2 + ∂2T/∂v2 = 0, and
satisﬁes all the boundary conditions. Also note that an easy way to know that v
satisﬁes Laplace’s equation is to observe that it is the imaginary part of w = u +iv,
and use Theorem IV of Section 2 which says that the real and imaginary parts of
an analytic function of a complex variable satisfy Laplace’s equation.
Now let us use our results to solve a harder problem.
Example 2.
Consider the mapping of the rectangle in the w plane into the z plane by the
function w = ln z (Figure 10.1, z plane). We have
w = ln z = ln(reiθ) = ln r + iθ = u + iv,
u = ln r,
v = θ.
(10.1)
Then v = 0 maps into θ = 0, that is, the positive x axis; v = π maps into θ = π, that
is, the negative x axis (z plane, Figure 10.1). The insulated end of the rectangle
at u = 0 maps into ln r = 0 or r = 1; the left-hand end of the rectangle maps into
a small semicircle about the origin which we can think of as a bit of insulation at
the origin separating the 0◦and 100◦parts of the x axis. (If the left-hand end of
the rectangle is at u = −∞, we have ln r = −∞, r = 0, and the image is just the
origin; for ﬁnite negative u, the image is a semicircle with r < 1.) We can now solve
the problem indicated by the picture in the z plane of Figure 10.1. A semicircular
plate has its faces and its curved boundary insulated, and has half its ﬂat boundary
at 0◦and the other half at 100◦(with a bit of insulation at the center).
Find
the temperature T at any point of the plate. To solve this problem we need only
transform our solution in the (u, v) plane to the variables x, y by using (10.1). Thus
we ﬁnd
(10.2)
T = 100
π V = 100
π θ = 100
π arc tan y
x,
0 ≤θ ≤π.

712
Functions of a Complex Variable
Chapter 14
It is not hard to justify our method; we need to show that our solution satisﬁes
Laplace’s equation and that it satisﬁes the boundary conditions. It is straightfor-
ward to show (Problem 1) that if a function φ(u, v) satisﬁes Laplace’s equation
∂2φ/∂u2 + ∂2φ/∂v2 = 0, then the function of x and y obtained by substituting
u = u(x, y), v = v(x, y) in φ satisﬁes Laplace’s equation in x and y, where u and
v are the real and imaginary parts of an analytic function w = f(z). Thus we
know that (10.2) satisﬁes Laplace’s equation (or in this case you can easily verify
the fact directly). We must also know that the transformed T satisﬁes the bound-
ary conditions; this is where conformal mapping is so useful. Observe in Figure
10.1 that we had a transformation which took the boundaries of a simple region
(a rectangle) for which we knew the solution of the temperature problem, into the
boundaries of a more complicated region for which we wanted the solution. This is
the basic method of conformal mapping—to transform from a simple region where
you know the answer to a given problem, to the region in which you want the so-
lution. The temperature at any (x, y) point is the same as the temperature at the
(u, v) image point, since we obtain the temperature as a function of x and y by
the same substitution u = u(x, y), v = v(x, y) that we use to obtain image points.
Thus the temperatures on the boundaries of the transformed region are the same
as the temperatures on the corresponding boundaries of the simpler (u, v) region.
Similarly, isothermals (curves of constant temperature) transform into isothermals;
in this problem the (u, v) isothermals are the lines v = const., and so the (x, y)
isothermals are θ = const. You can show that the rate of change of T in a direction
perpendicular to a boundary in the (u, v) plane is proportional to the corresponding
rate of change of T in a direction perpendicular to the image boundary in the (x, y)
plane (Problem 9.15). Thus insulated boundaries (across which the rate of change
of T is zero) map into insulated boundaries. The lines (or curves) perpendicular to
the isothermals give the direction of ﬂow of heat; in Figure 10.1 heat ﬂows along
the lines u = const. in the w plane, and along the circles r = const. (which are the
images of u = const.) in the z plane.
Using the same mapping function w = ln z, we can solve a number of other
physics problems. Observe ﬁrst that if we think of Figure 10.1 as representing a cross
section of a three-dimensional problem (with all parallel cross sections identical),
then (10.2) gives the solution of the three-dimensional problem also. In Figure 10.1
the (u, v) diagram would be the cross section of a slab with faces at T = 100◦and
T = 0◦and all other surfaces insulated (or extending to inﬁnity); the (x, y) diagram
would similarly represent half a cylinder. Now let us do a three-dimensional problem
in electrostatics.
Figure 10.2
Example3.
In Figure 10.2 the (u, v) diagram represents (the cross section of) two inﬁnite
parallel plates, one at potential V = 0 volts and one at potential V = 100 volts. The
(x, y) diagram represents (the cross section of) one plane with its right-hand half

Section 10
Some Applications of Conformal Mapping
713
at potential V = 0 volts and its left-hand half at V = 100 volts. From electricity
we know that the electrostatic potential V satisﬁes Laplace’s equation in regions
where there is no free charge (see Chapter 13, Section 1). You should convince
yourself that the mapping by (10.1) gives the result shown in Figure 10.2, and that
the potential is given by
V = 100
π v = 100
π θ = 100
π arc tan y
x,
0 ≤θ ≤π
as in (10.2). The equipotentials (V = const.) in the (x, y) plane are the lines θ =
const. Recall that the electric ﬁeld is given by E = −∇V , and that the gradient of
V is perpendicular to V = const. (Chapter 6, Section 6). Then the direction of the
electric ﬁeld at any point is perpendicular to the equipotential through that point.
Thus if we sketch the curves r = const. which are perpendicular to the equipotentials
θ = const., then the tangent to a circle at a point gives the direction of the electric
ﬁeld E at that point.
Note the correspondence between the isothermals of the
temperature problem and the equipotentials here, and between the lines of electric
ﬂux (curves tangent to E) and the lines or curves along which heat ﬂows.
We can also solve problems in hydrodynamics (see Chapter 6, Section 10) by
conformal mapping.
We consider a two-dimensional ﬂow of water by which we
mean either that we think of the water as ﬂowing in a thin sheet over the (x, y)
[or (u, v)] plane, or if it has depth, the ﬂow is the same in all planes parallel to
the (x, y) [or (u, v)] plane. Although it is convenient to talk about water, what we
actually require is an irrotational ﬂow (see Chapter 6, Section 11) of a nonviscous
incompressible ﬂuid. For then (see Problem 2) the velocity V of the liquid is given
by V = ∇Φ, where Φ (called the velocity potential) satisﬁes Laplace’s equation.
Water approximately meets these requirements.
Figure 10.3
Example 4.
Figure 10.3 shows two ﬂow patterns related by the same transformation we
have used in the heat problem and the electrostatics problem, namely w = ln z. In
the w plane of Figure 10.3, we picture water ﬂowing in the u direction at constant
speed V0 down a channel between v = 0 and v = 2π. (Note that v is the imaginary
part of w = u + iv and has nothing to do with velocity.) The velocity potential
is Φ = V0u; for then the velocity, V = ∇Φ, has components ∂Φ/∂u = V0 in the
u direction and ∂Φ/∂v = 0 in the v direction as we have assumed. The function
Φ+iΨ = V0w = V0(u+iv) is called the complex potential; the function Ψ (conjugate
to Φ; see Section 2) is called the stream function. The lines Ψ = const. (that is,

714
Functions of a Complex Variable
Chapter 14
v = const. in the w plane) are the lines along which the water ﬂows and are called
streamlines. Observe that the lines Φ = const. and the lines Ψ = const. are mutually
perpendicular sets of lines. The water ﬂows across lines of constant Φ and along
streamlines (constant Ψ); boundaries of the channel (v = 0 and v = 2π) must then
be streamlines. The water comes from the left (Figure 10.3, w plane) and goes oﬀ
to the right; we say that there is a source at the left and a sink at the right.
Now consider the mapping of the w plane ﬂow of Figure 10.3 into the z plane
by the function w = ln z. The complex potential is
Φ + iΨ = V0w = V0 ln z = V0(ln r + iθ).
The streamlines are Ψ = const., or θ = const., that is, radial lines; the curves Φ =
const. are circles r = const. and are perpendicular to the streamlines. The velocity
is given by
V = ∇Φ = V0∇(ln r) = V0

er
∂
∂r + eθ
1
r
∂
∂θ

ln r = er
V0
r .
What we are describing, then, is the ﬂow of water from a source at the origin out
along radial lines. Since the same amount of water crosses a small circle (about the
origin) or a large one, the velocity of the water decreases with r as we have found
(|V| = V0/r).
We can obtain another ﬂow pattern from any given one by interchanging the
equipotentials and the streamlines. In Figure 10.3, z plane, this new ﬂow would have
the circles r = const. as streamlines and would correspond to a whirlpool motion
of the water about the origin (called a vortex). There are still other applications
of this diagram. The circles r = const. give the direction of the magnetic ﬁeld
about a long current-carrying wire perpendicular to the (x, y) plane and passing
through the origin. The radial lines θ = const. give the direction of the electric
ﬁeld about a similar long wire with a static charge on it. The radial lines give the
direction of heat ﬂow from a small hot object at the origin, and the circles r = const.
are then the isothermals. By starting with problems like these to which we know
the answers and using various conformal transformations, we can solve many other
physics problems involving ﬂuid ﬂow, electricity, heat, and so on. Some examples
are outlined in the problems and you will ﬁnd many more in books on complex
variables.
Example 5.
Let us consider one somewhat more complicated example of the use of con-
formal mapping. We shall be able to solve two interesting physics problems in this
example: (1) to ﬁnd the ﬂow pattern for water ﬂowing out of the end of a straight
channel into the open, and (2) to ﬁnd the edge eﬀect (fringing) at the ends of a
parallel-plate capacitor.
We consider the mapping function
z = w + ew = u + iv + eueiv = u + iv + eu(cos v + i sin v),
x = u + eu cos v,
y = v + eu sin v.
(10.3)
In Figure 10.4, w plane, we picture a parallel ﬂow of water at constant velocity in
the region between the lines DEF and GHI; this is just like the ﬂow of Figure 10.3,

Section 10
Some Applications of Conformal Mapping
715
Figure 10.4
w plane. Now let us map the w plane streamlines into the z plane using (10.3). On
the u axis, v = 0; putting v = 0 in (10.3), we ﬁnd y = 0, and x = u + eu. Thus
the u axis maps into the x axis (y = 0) with u = −∞corresponding to x = −∞,
u = 0 corresponding to x = 1, and u = +∞corresponding to x = +∞as shown
in Figure 10.4 (line ABC maps into A′B′C′). Now on DEF, v = π; substituting
v = π into (10.3), we ﬁnd y = π, x = u + eu cos π = u −eu. However, the image
of v = π is not the entire line y = π. To see this consider x = u −eu. We ﬁnd the
maximum value of x for dx/du = 1 −eu = 0, d2x/du2 = −eu < 0. These equations
are satisﬁed for u = 0, x = −1. The point E (u = 0, v = π) maps into the point
E′ (x = −1, y = π). Thus DE in the w plane maps into the part of the line y = π
in the z plane up to x = −1 with u = −∞corresponding to x = −∞and u = 0
corresponding to x = −1. To see how to map EF, we realize that x has its largest
value at u = 0 and so decreases as u increases; for very large positive u, x = u −eu
is negative and of large absolute value since eu ≫u. Thus the positive part of
v = π (EF) maps into the same line segment (y = π, x ≤−1) that we obtained
for the mapping of the negative part (DE), but this time the line segment (E′F ′,
z plane) is traversed backward. It is as if the line y = π were broken at x = −1
and bent back upon itself through an angle of 180◦. By a parallel discussion of
the line GHI, we ﬁnd that it maps as shown in Figure 10.4 into G′H′I′. Other
streamlines in the w plane are given by v = const. for any v between −π and π. If
we substitute v = const. into the x and y equations in (10.3), we have parametric
equations (with u as the parameter) for the streamlines in the z plane. For any value
of v, these streamlines can be plotted in the z plane: some of them are shown by
the solid curves in Figure 10.5. Think of D′E′ and G′H′ as boundaries of a channel
(in the z plane) down which water ﬂows coming from x = −∞. The boundaries
stop at x = −1 and the water ﬂows out of the channel spreading over the whole
plane, including spreading back along the outsides (E′F ′ and H′I′) of the channel
boundaries. This is correct according to our mapping, for the boundary streamline
DEF mapped into the broken-and-folded-back line D′E′F ′, and similarly for GHI
to G′H′I′.
For the electrical application, let DEF and GHI represent (the cross section
of) a large parallel plate capacitor. Then the lines v = const. are the equipotentials
and the lines u = const. give the direction of the electric ﬁeld E. The image in the
z plane represents (a cross section of) the end of a parallel plate capacitor. The
images of the equipotentials v = const. are the equipotentials in the z plane (same
as the streamlines, shown as solid curves in Figure 10.5). The images of the lines
u = const. (shown as dotted curves in Figure 10.5) give the direction of the electric
ﬁeld at the end of a parallel-plate capacitor. Well inside the plates the E lines are
vertical, but at the end they bulge out; this eﬀect is known as fringing.

716
Functions of a Complex Variable
Chapter 14
Figure 10.5
PROBLEMS, SECTION 10
1.
Prove the theorem stated just after (10.2) as follows. Let φ(u, v) be a harmonic
function (that is, φ satisﬁes ∂2φ/∂u2 + ∂2φ/∂v2 = 0). Show that there is then an
analytic function g(w) = φ(u, v) + iψ(u, v) (see Section 2). Let w = f(z) = u + iv
be another analytic function (this is the mapping function). Show that the function
h(z) = g(f(z)) is analytic. Hint: Show that h(z) has a derivative. (How do you ﬁnd
the derivative of a function of a function, for example, ln sin z?) Then (by Section 2)
the real part of h(z) is harmonic. Show that this real part is φ(u(x, y), v(x, y)).
2.
A ﬂuid ﬂow is called irrotational if ∇×V = 0 where V = velocity of ﬂuid (Chapter 6,
Section 11); then V = ∇Φ. Use Problem 10.15 of Chapter 6 to show that if the
ﬂuid is incompressible, the Φ satisﬁes Laplace’s equation. (Caution: In Chapter 6,
we used V = vρ, with v = velocity; here V = velocity.)
3.
Assuming from electricity the equations ∇·D = ρ, E = −∇V , D = ϵE (ϵ = const.),
show that in regions where the free charge density ρ is zero, V satisﬁes Laplace’s
equation.
4.
Let a ﬂat plate in the shape of a quarter-circle, as
shown, have its faces and curved boundary insulated,
and its two straight edges held at 0◦and 100◦. Find
the temperature distribution T(x, y) in the plate, and
the equations of the isothermals. Hint: Use the map-
ping function w = ln z as in Figure 10.1; what w plane
line maps into the y axis?
5.
Consider a capacitor made of two very large perpendicular plates. (Let the positive
x and y axes in the diagram of Problem 4 represent a cross section of the capacitor.)
Let one plate (x axis) be held at potential V = 0, and the other plate (y axis) be
held at potential V = 100 volts. Find the potential V (x, y) for x > 0, y > 0, and
the equations of the equipotentials. Hint: This problem is mathematically the same
as Problem 4.

Section 10
Some Applications of Conformal Mapping
717
6.
Let the ﬁgure represent (the cross section of) a hot cylinder (say T = 100◦) lying
on a cold plane (say T = 0◦).
(Separate the two by a bit of insulation.)
Find
the temperature in the shaded region. Alternatively, let the cylinder and the plane
be held at two diﬀerent electric potentials (with insulation
between), and ﬁnd the electric potential in the shaded region.
Find and sketch some of the isothermals (equipotentials) and
some of the curves (perpendicular to the isothermals) along
which heat ﬂows (lines of ﬂux for the electric case). Hint:
Use the mapping function w = 1/z, and consider the image
of the w plane region between v = 0 and v = −1.
7.
Use the mapping function w = z2 to ﬁnd the streamlines for the ﬂow of water
around the inside of a right-angle boundary.
Find the velocity potential Φ, the
stream function Ψ, and the velocity V = ∇Φ.
8.
Observe that the magnitude of the velocity in Problem 7 can be obtained from
V = V0|dw/dz|. Show that this result holds in general as follows. Let w = f(z) be
an analytic mapping function such that the lines v = const. map into the streamlines
of the ﬂow you want to consider in the z plane. Then
V0w = V0(u + iv) = Φ(x, y) + iΨ(x, y).
Show that
V0 dw
dz = ∂Φ
∂x −i∂Φ
∂y = Vx −iVy
(this expression is called the complex velocity). Hence show that V = V0|dw/dz|.
9.
Find and sketch the streamlines for the ﬂow of water over a semicircular hump (say
a half-buried log at the bottom of a stream) as shown.
Hint: Use the mapping
function w = z + z−1. Show that the u axis maps into the contour ABCDE with
the correspondence shown.
10.
Find and sketch the streamlines for the indicated ﬂow of water inside a
rectangular boundary. Hint: Consider w = sin z; map the u axis into the
boundary of the rectangle.
11.
For w = ln[(z + 1)/(z −1)], show that the images of u = const. and v = const. are
two orthogonal sets of circles. Find centers and radii of ﬁve or six circles of each set
and sketch them. Include the circle with center at the origin.
Use the results of Problem 11 to solve the following
physics problems.
12.
The ﬁgure represents the cross section of a long
cylinder (assume it inﬁnitely long) cut in half,
with the top half and the bottom half insulated

718
Functions of a Complex Variable
Chapter 14
from each other. Let the surface of the top half be held at temperature T = 30◦and
the surface of the bottom half at T = 10◦. Find the temperature T(x, y) inside the
cylinder. Hint: Show that the line v = π/2 maps into the lower half of the circle
|z| = 1, and the line v = 3π/2 maps into the upper half of the circle.
13.
Let the ﬁgure in Problem 12 represent (the cross section of) a capacitor with the
lower half at potential V1 and the upper half at potential V2. Find the potential
V (x, y) between the plates (that is, inside the circle).
Hint: This is almost like
Problem 12. Observe that in the text and in Problem 12, the w-plane temperature
is of the form Av, with A constant; here you need the potential of the form Av + B,
A and B constants.
14.
In the ﬁgure in Problem 12, let z = −1 be a source and z = +1 a sink, and let the
water ﬂow inside the circular boundary. Find Φ, Ψ, and V. Sketch the streamlines.
15.
In Problem 14, the streamlines were the images of v = const. Consider the ﬂow
(over the whole plane, that is, with no boundaries) with streamlines u = const.
This ﬂow may be described as two vortices rotating in opposite directions. Sketch
a number of streamlines indicating the direction of the velocity with arrows. Since
a boundary is a streamline, a ﬂow is not disturbed by inserting a boundary along
a streamline. Insert two circular boundaries corresponding to u = a and u = −a.
Show that the velocity through the narrow neck (say at z = 0) is greater than the
velocity elsewhere (say at z = i). You can simplify your calculation of the velocity
by showing that the result in Problem 8 holds here also.
16.
Two long parallel cylinders form a capacitor. (Let their cross sections be the images
of u = a and u = −a.) If they are held at potentials V0 and −V0, ﬁnd the potential
V (x, y) at points between them. given that the charge (per unit length) on a cylinder
is q = V0/(2a), show that the capacitance (per unit length), that is, q/(2V0), is
given by 1/(4 cosh−1 d/(2r)), where d is the distance between the centers of the two
cylinders, and their radii are r.
17.
Other problems to consider using the mapping function of Problem 11: (a) a capac-
itor consisting of two long cylinders one inside the other, but not concentric; (b) the
magnetic ﬁeld in a plane perpendicular to two long parallel wires carrying equal but
opposite currents; (c) the electric ﬁeld in a plane perpendicular to two long parallel
wires, one charged positive and the other negative; (d) other ﬂow problems obtained
by inserting boundaries along streamlines.
11. MISCELLANEOUS PROBLEMS
In Problems 1 and 2, verify that the given function is harmonic, and ﬁnd a function f(z) of
which it is the real part. Hint: Use Problem 2.64. For Problem 2, see Chapter 2, Section
17, Problem 19.
1.
ln
p
(1 + x)2 + y2
2.
arc tan
y
x + 1
3.
Liouville’s theorem: Suppose f(z) is analytic for all z (except ∞), and bounded
[that is, |f(z)| ≤M for all z and some M]. Prove that f(z) is a constant. Hints: If
f ′(z) = 0, then f(z) = const. To show this, write f ′(z) as in Problem 3.21 where C
is a circle of radius R and center z, that is, w = z +Reiθ. Show that |f ′(z)| ≤M/R,
and let R →∞.
4.
Use Liouville’s theorem (Problem 3) to prove the fundamental theorem of algebra
(see Problem 7.44). Hint: Let P(z) be a polynomial of degree ≥1; then f(z) =
1/P(z) is a bounded analytic function in a region not containing any zeros of P(z).
Disprove the assumption that P(z) has no zeros anywhere.

Section 11
Miscellaneous Problems
719
In Problems 5 to 8, ﬁnd the residues of the given function at all poles. Take z = reiθ,
0 ≤θ < 2π.
5.
z1/3
1 + z2
6.
√z
1 + 8z3
7.
ln z
1 + z2
8.
ln z
(2z −1)2
In Problems 9 to 10, use Laurent series to ﬁnd the residues of the given functions at the
origin.
9.
sin z2
z7
10.
ln(1 −z)
sin2 z
11.
Find the Laurent series of f(z) = ez/(1 −z) for |z| < 1 and |z| > 1.
Hints:
For |z| < 1, multiply two power series; you should ﬁnd f(z) = P∞
n=0 anzn with
an = Pn
k=0 1/k!. For |z| > 1, use (4.3) where C is a circle |z| = a with a > 1.
Evaluate the integrals by ﬁnding residues at 1 and 0.
You should ﬁnd f(z) =
P∞
n=0 anzn + P∞
n=1 bnz−n where all bn = −e and an = −e + Pn
k=0 1/k!.
12.
Let f(z) be the branch of
√
z2 −1 which is positive for large positive real values
of z. Expand the square root in powers of 1/z to obtain the Laurent series of f(z)
about ∞. Thus by Problem 8.1 ﬁnd the residue of f(z) at ∞. Check your result by
using equation (8.2).
In Problems 13 and 14, ﬁnd the residues at the given points.
13.
(a)
cos z
(2z −π)4
at
π
2
(b)
2z2 + 3z
z −1
at
∞
(c)
z3
1 + 32z5
at
z = −1
2
(d) csc(2z −3)
at
z = 3
2
14.
(a)
ln(1 + 2z)
z2
at
0
(b)
1
z sin(2z + 5)
at
∞
(c)
z3
4z4 + 1
at
1
2(1 + i)
(d)
z sin 2z
(z + π)2
at
−π
In Problem 15 to 20, evaluate the integrals by contour integration.
15.
Z π
0
cos θ dθ
5 −4 cos θ
16.
Z 2π
0
sin θ dθ
5 + 3 sin θ
17.
Z ∞
0
cos x dx
(4x2 + 1)(x2 + 9)
18.
Z ∞
0
x sin(πx/2)
x4 + 4
dx
19.
PV
Z ∞
−∞
sin x dx
(3x −π)(x2 + π2)
20.
PV
Z ∞
−∞
cos x dx
x(1 −x)(x2 + 1)
Verify the formulas in Problem 21 to 27 by contour integration or as indicated. Assume
a > 0, m > 0.
21.
Z 2π
0
dθ
a + b sin θ =
Z 2π
0
dθ
a + b cos θ =
2π
√
a2 −b2 ,
|b| < a
22.
Z 2π
0
dθ
(a + b sin θ)2 =
Z 2π
0
dθ
(a + b cos θ)2 =
2πa
(a2 −b2)3/2 ,
|b| < a
Hint: You can do this directly by contour integration, but it is easier to diﬀerentiate
Problem 21 with respect to a.
23.
Z 2π
0
sin θ dθ
a + b sin θ =
Z 2π
0
cos θ dθ
a + b cos θ = 2π
b
„
1 −
a
√
a2 −b2
«
,
|b| < a

720
Functions of a Complex Variable
Chapter 14
24.
Z ∞
0
cos mx dx
x2 + a2
= π
2ae−ma
25.
PV
Z ∞
0
cos mx dx
x2 −a2
= −π
2a sin ma
26.
Z ∞
0
x sin mx dx
x2 + a2
= π
2 e−ma
27.
PV
Z ∞
0
x sin mx dx
x2 −a2
= π
2 cos ma
Hint for Problems 26 and 27: Diﬀerentiate Problems 24 and 25 with respect to m.
28.
Evaluate
Z ∞
0
√x ln x dx
(1 + x)2
by using the contour of Figure 7.4.
Hint: Along DE, z = re2πi so ln z = ln r + 2πi.
29.
Evaluate
Z ∞
0
(ln x)2
1 + x2 dx by using the contour of Figure 7.3. Comment: Note that
your work also shows that
Z ∞
0
ln x
1 + x2 dx = 0.
30.
Show that
PV
Z ∞
0
cos(ln x)
x2 + 1 dx =
π
2 cosh(π/2)
by integrating ei ln z/(z2 −1) around a contour like Figure 7.3 but rotated 90◦clock-
wise so the straight side is along the y axis.
As in Section 7, ﬁnd out how many roots the equations in Problem 31 to 34 have in each
quadrant.
31.
z4 + 3z + 5 = 0
32.
z3 + 2z2 + 5z + 6 = 0
33.
z6 + z3 + 9z + 64 = 0
(no real roots)
34.
z8 + 5z3 + 3z + 4 = 0
(2 negative real roots)
35.
Show that the Cauchy-Riemann equations [see (2.2) and Problem 2.46] in a general
orthogonal curvilinear coordinate system [see Chapter 10, Sections 8 and 9] are
1
h1
∂u
∂x1 = 1
h2
∂v
∂x2 ,
1
h1
∂v
∂x1 = −1
h2
∂u
∂x2
where, as in Chapter 10, the variables are x1, x2 and the scale factors are h1, h2.
Hint: Consider the directional derivatives (Chapter 6, Section 6) in two perpendic-
ular directions. (Compare Problem 2.46.) Also show that u and v satisfy Laplace’s
equation, Chapter 10, equation (9.10) (drop the x3 term and set h3 = 1).
36.
Show that a harmonic function u(x, y) is equal at every point a to its average value
on any circle centered at a [and lying in the region where f(z) = u(x, y) + iv(x, y)
is analytic]. Hint: In (3.9), let z = a + reiθ (that is, C is a circle with center at
a), and show that the average value of f(z) on the circle is f(a) (see Chapter 7,
Section 4 for discussion of the average of a function). Take real and imaginary parts
of f(a) = [u(x, y) + iv(x, y)]z=a.
37.
A (nonconstant) harmonic function takes its maximum value and its minimum value
on the boundary of any region (not at an interior point). Thus, for example, the
electrostatic potential V in a region containing no free charge takes on its largest
and smallest values on the boundary of the region; similarly, the temperature T of a
body containing no sources of heat takes its largest and smallest values on the surface
of the body. Prove this fact (for two-dimensional regions) as follows: Suppose that
it is claimed that u(x, y) takes its maximum value at some interior point a; this
means that, at all points of some small disk about a, the values of u(x, y) are no
larger than at a. Show by Problem 36 that such a claim leads to a contradiction
(unless u = const.). Similarly prove that u(x, y) cannot take its minimum value at
an interior point.

Section 11
Miscellaneous Problems
721
38.
Show that a Dirichlet problem (see Chapter 13, Section 3) for Laplace’s equation in
a ﬁnite region has a unique solution; that is, two solutions u1 and u2 with the same
boundary values are identical. Hint: Consider u2 −u1 and use Problem 37. [Also
see Chapter 13, discussion following equation (2.17).]
39.
Use the following sequence of mappings to ﬁnd the steady state temperature T(x, y)
in the semi-inﬁnite strip y ≥0, 0 ≤x ≤π if T(x, 0) = 100◦, T(0, y) = T(π, y) = 0,
and T(x, y) →0 as y →∞. (See Chapter 13, Section 2 and Problem 2.6.)
(a)
Use w = (z′ −1)/(z′ + 1) to map the half plane v ≥0 on the upper half plane
y′ > 0, with the positive u axis corresponding to the two rays x′ > 1 and
x′ < −1, and the negative u axis corresponding to the interval −1 ≤x ≤1 of
the x′ axis.
(b)
Use z′ = −cos z to map the half-strip 0 < x < π, y > 0 on the z′ half plane
described in (a). The interval −1 ≤x′ < 1, y′ = 0 corresponds to the base
0 < x < π, y = 0 of the strip.
Comments: The temperature problem in the (u, v) plane is like the problems shown
in the z plane of Figures 10.1 and 10.2, and so is given by T = (100/π) arc tan(v/u).
In the z plane you will ﬁnd
T(x, y) = 100
π
arc tan
2 sin x sinh y
sinh2 y −sin2 x.
Put tan α = sin x
sinh y and use the formula for tan 2α to get
T(x, y) = 200
π
arc tan sin x
sinh y .
Note that this is the same answer as in Chapter 13, Problem 2.6, if we replace 10
by π.
40.
Use L13 of the Laplace transform table to ﬁnd the Laplace transform of sin at sinh at.
Verify your result by ﬁnding its inverse transform using the Bromwich integral.
41.
Evaluate by contour integration
Z ∞
0
cos2(απ/2)
(1 −α2)2 dα.
Hint: cos2(απ/2) = (1 + cos απ)/2. Evaluate
I
1 + eiπz
(z −1)2(z + 1)2 dz
around the upper half plane; note that the poles are actually simple poles (see
Section 7, Example 4).

C H A P T E R 15
Probability and Statistics
1. INTRODUCTION
The theory of probability has many applications in the physical sciences. It is of
basic importance in quantum mechanics where results may be expressed in terms
of probabilities (see Chapter 13, Schr¨odinger equation). It is needed whenever we
are dealing with large numbers of particles or variables where it is impossible or
impractical to have complete information about each one, such as in kinetic theory
and statistical mechanics and a great variety of engineering problems. Statistics is
the part of probability theory which deals with the interpretation of sets of data.
You need statistical terms and methods every time you make a set of laboratory
measurements. In this chapter, we shall discuss some of the basic ideas of probability
and statistics which are most useful in applications.
The word “probably” is frequently used in everyday life.
We say “The test
will probably be hard,” “It will probably snow today,” “We will probably win this
game,” and so on. Such statements always imply a state of partial ignorance about
the outcome of some event; we do not say “probably” about something whose
outcome we know. The theory of probability tries to express more precisely just
what our state of ignorance is. We say that the probability of getting a head in
one toss of a coin is 1
2, and similarly for a tail. We mean by this that there are two
possible outcomes of the experiment (if we do not consider the possibility of the
coin’s standing on edge) and that we have no reason to expect one outcome more
than the other; therefore we assign equal probabilities to the two possible outcomes.
(See end of Section 2 for further discussion of this.)
Consider the following problem. You and I each toss a coin and look at our
own coins but not each other’s.
The question is “What is the probability that
both coins show heads?” Suppose you see that your coin shows tails; you say that
the probability that both coins are heads is zero because you know that yours is
tails. On the other hand, suppose I see that my coin is heads; then I say that the
probability of both heads is 1
2 because I don’t know whether your coin shows heads
or tails. Now suppose neither of us looks at either coin, but a third person looks
at both coins and gives us the information that at least one is heads. Without this
722

Section 1
Introduction
723
information, there are four possibilities, namely
(1.1)
hh
tt
th
ht
to each of which we would ordinarily assign the probability 1
4 (see end of Section 2,
and Section 3). The information “at least one head” rules out tt, but gives no new
information about the other three cases. Since hh, th, ht were equally likely before,
we still consider them equally likely and say that the probability of hh is 1
3.
Notice in the above discussion that the answer to a probability problem depends
on the state of knowledge (or ignorance) of the person giving the answer. Notice
also that in order to ﬁnd the probability of an event, we consider all the diﬀerent
equally likely outcomes which are possible according to our information. We say
that these are mutually exclusive (for example, if a coin is heads it cannot be tails),
collectively exhaustive (we must consider all possibilities), and equally likely (we
have no information which makes us expect one result more than another so we
assume the same probability for each one of the set of outcomes).
Let us now
formalize this notion of probability as a deﬁnition (also see Section 2).
(1.2)
If there are several equally likely, mutually exclusive, and collec-
tively exhaustive outcomes of an experiment, the probability of an
event E is
p = number of outcomes favorable to E
total number of outcomes
.
Example 1.
Find the probability that a single card drawn from a shuﬄed deck of cards
will be either a diamond or a king (or both).
There are 52 diﬀerent possible outcomes of the drawing; since the deck is shuﬄed,
we assume all cards equally likely. Of the 52 cards, 16 are favorable (13 diamonds
and the 3 other kings); therefore by (1.2) the desired probability is 16
52 =
4
13.
Example 2.
A three-digit number (that is, a number from 100–999) is selected “at ran-
dom.” (“At random” means that we assume all numbers to have the same proba-
bility of being selected.) What is the probability that all three digits are the same?
There are 900 three-digit numbers; 9 of them (namely 111, 222, · · · , 999) have
all three digits the same. Hence the desired probability is
9
900 =
1
100.
PROBLEMS, SECTION 1
1.
If you select a three-digit number at random, what is the probability that the units
digit is 7? What is the probability that the hundreds digit is 7?
2.
Three coins are tossed; what is the probability that two are heads and one tails?
That the ﬁrst two are heads and the third tails? If at least two are heads, what is
the probability that all are heads?
3.
In a box there are 2 white, 3 black, and 4 red balls. If a ball is drawn at random,
what is the probability that it is black? That it is not red?

724
Probability and Statistics
Chapter 15
4.
A single card is drawn at random from a shuﬄed deck. What is the probability that
it is red? That it is the ace of hearts? That it is either a three or a ﬁve? That it is
either an ace or red or both?
5.
Given a family of two children (assume boys and girls equally likely, that is, proba-
bility 1/2 for each), what is the probability that both are boys? That at least one
is a girl? Given that at least one is a girl, what is the probability that both are
girls? Given that the ﬁrst two are girls, what is the probability that an expected
third child will be a boy?
6.
A trick deck of cards is printed with the hearts and diamonds black, and the spades
and clubs red. A card is chosen at random from this deck (after it is shuﬄed). Find
the probability that it is either a red card or the queen of hearts. That it is either
a red face card or a club. That it is either a red ace or a diamond.
7.
A letter is selected at random from the alphabet. What is the probability that it is
one of the letters in the word “probability?” What is the probability that it occurs
in the ﬁrst half of the alphabet? What is the probability that it is a letter after x?
8.
An integer N is chosen at random with 1 ≤N ≤100. What is the probability that
N is divisible by 11? That N > 90? That N ≤3? That N is a perfect square?
9.
You are trying to ﬁnd instrument A in a laboratory. Unfortunately, someone has
put both instruments A and another kind (which we shall call B) away in identical
unmarked boxes mixed at random on a shelf. You know that the laboratory has
3 A’s and 7 B’s. If you take down one box, what is the probability that you get
an A? If it is a B and you put it on the table and take down another box, what is
the probability that you get an A this time?
10.
A shopping mall has four entrances, one on the North, one on the South, and two
on the East. If you enter at random, shop and then exit at random, what is the
probability that you enter and exit on the same side of the mall?
2. SAMPLE SPACE
It is frequently convenient to make a list of the possible outcomes of an experiment
[as we did in (1.1)]. Such a set of all possible mutually exclusive outcomes is called a
sample space; each individual outcome is called a point of the sample space. There
are many diﬀerent sample spaces for any given problem. For example, instead of
(1.1), we could say that a set of all mutually exclusive outcomes of two tosses of a
coin is
(2.1)
2 heads,
1 head,
no heads.
Still another sample space for the same problem is
(2.2)
no heads,
at least 1 head.
(Can you list some more examples?) On the other hand, the set of outcomes
2 heads,
at least 1 head,
exactly 1 tail.
cannot be used as a sample space, because these outcomes are not mutually exclu-
sive. “At least 1 head” includes “2 heads” and also includes “exactly 1 tail” (which
means also “exactly 1 head”).

Section 2
Sample Space
725
In order to use a sample space to solve problems, we need to have the probabil-
ities corresponding to the diﬀerent points in the sample space. We usually assign
probability 1/4 to each of the outcomes listed in (1.1). (See end of Section 2 and Sec-
tion 3.) We call such a list of equally likely outcomes a uniform sample space. Now
suppose the outcomes are not equally likely. Satisfy yourself that the probabilities
associated with the points of (2.1) and (2.2) are as follows.
For (2.1):
2h
1h
no h
1
4
1
2
1
4
and for (2.2):
no h
at least 1 h
1
4
3
4
The sample spaces (2.1) and (2.2) with diﬀerent probabilities associated with dif-
ferent points are called nonuniform sample spaces. For some problems, there may
be both uniform and nonuniform sample spaces; for example, (1.1) is a uniform
sample space, and (2.1) and (2.2) are nonuniform sample spaces for a toss of two
coins. But sometimes there is no uniform sample space; for example, consider a
weighted coin which has a probability 1
3 for heads and 2
3 for tails. In such cases,
we cannot use the deﬁnition (1.2) of probability, and we need the following more
general deﬁnition.
Deﬁnition of Probability.
Given any sample space (uniform or not) and the
probabilities associated with the points, we ﬁnd the probability of an event by
adding the probabilities associated with all the sample points favorable to the
event.
For a given nonuniform sample space, we must use this deﬁnition since (1.2)
does not apply. If the given sample space is uniform, or if there is an underlying
uniform sample space [for example, (1.1) is the uniform space underlying (2.1) and
(2.2)], then this deﬁnition is consistent with the deﬁnition (1.2) by equally likely
cases (Problems 15 and 16), and we may use either deﬁnition. As an example, let
us ﬁnd from (2.1) the probability of at least one head; this is the probability of one
head plus the probability of two heads or 1
2 + 1
4 = 3
4. We get the same result from
the uniform sample space (1.1) using either (1.2) or the deﬁnition above.
If we can easily construct several sample spaces for a given problem, we must
choose an appropriate one for the question we want to answer. Suppose we ask the
question: In two tosses of a coin, what is the probability that both are heads? From
either (1.1) or (2.1) we ﬁnd the answer 1
4; (2.2) is not an appropriate sample space
to use in answering this question. (Why not?) To ﬁnd the probability of both tails,
we could use any of the three listed sample spaces, and to ﬁnd the probability that
the ﬁrst toss gave a head and the second a tail, we could use only (1.1) since the
other sample spaces do not give enough information. Let us now consider some less
trivial examples.
Example1.
A coin is tossed three times. A uniform sample space for this problem contains
eight points,
(2.3)
hhh
hth
ttt
tht
hht
thh
tth
htt
and we attach probability 1
8 to each. Now let us use this sample space to answer
some questions.

726
Probability and Statistics
Chapter 15
What is the probability of at least two tails in succession? By actual count, we
see that there are three such cases, so the probability is 3
8.
What is the probability that two consecutive coins fall the same? Again by
actual count, this is true in six cases, so the probability is 6
8 or 3
4.
If we know that there was at least one tail, what is the probability of all tails?
The point hhh is now ruled out; we have a new sample space consisting of seven
points. Since the new information (at least one tail) tells us nothing new about
these seven outcomes, we consider them equally probable, each with probability 1
7.
Thus the probability of all tails when all heads is ruled out is 1
7.
(See problems 11 and 12 for further discussion of this example.)
Example 2.
Let two dice be thrown; the ﬁrst die can show any number from 1 to 6 and
similarly for the second die. Then there are 36 possible outcomes or points in a
uniform sample space for this problem; with each point we associate the probability
1
36. We can indicate a 3 on the ﬁrst die and a 2 on the second die by the symbol
3,2. Then the sample space is as shown in (2.4). (Ignore the circling of some points
and the letters a and b right now; they are for use in the problems below.)
(2.4)
6,1
6,2
6,3
6,4
6,5
6,6
5,1
5,2
5,3
5,4
5,5
5,6
4,1
4,2
4,3
4,4
4,5
4,6
3,1
3,2
3,3
3,4
3,5
3,6
2,1
2,2
2,3
2,4
2,5
2,6
1,1
1,2
1,3
1,4
1,5
1,6
a
b


J
J
J
J


J
J
J
J
Let us now ask some questions and use the sample space (2.4) to answer them.
(a) What is the probability that the sum of the numbers on the dice will be 5?
The sample space points circled and marked a in (2.4) give all the cases for which
the sum is 5. There are four of these sample points; therefore the probability that
the sum is 5 is
4
36 or 1
9.
(b) What is the probability that the sum on the dice is divisible by 5? This
means a sum of 5 or 10; the four points circled and marked a in (2.4) correspond to
a sum of 5, and the three points circled and marked b correspond to a sum of 10.
Thus there are seven points in the sample space corresponding to a sum divisible
by 5, so the probability of a sum divisible by 5 is
7
36 (7 favorable cases out of 36
possible cases, or 7 times the probability
1
36 of each of the favorable sample points).
(c) Set up a sample space in which the points correspond to the possible sums of
the two numbers on the dice, and ﬁnd the probabilities associated with the points
of this nonuniform sample space. The possible sums range from 2 (that is, 1 + 1)
to 12 (that is, 6 + 6). From (2.4) we see that the points corresponding to any given
sum lie on a diagonal (parallel to the diagonal elements marked a or b). There is
one point corresponding to the sum 2; there are two points giving the sum 3, three

Section 2
Sample Space
727
points for sum 4, etc. Thus we have:
(2.5)
Sample Space
2
3
4
5
6
7
8
9
10
11
12
Associated
probabilities
1
36
2
36
3
36
4
36
5
36
6
36
5
36
4
36
3
36
2
36
1
36
(d) What is the most probable sum in a toss of two dice? Although we can
answer this from the sample space (2.4) (Try it!), it is easier from (2.5). We see
that the sum 7 has the largest probability, namely
6
36 = 1
6.
(e) What is the probability that the sum on the dice is greater than or equal
to 9? Using (2.5), we add the probabilities associated with the sums 9, 10, 11,
and 12. Thus the desired probability is
4
36 + 3
36 + 2
36 + 1
36 = 10
36 = 5
18.
So far we have been talking as if it were perfectly obvious and unquestionable
that heads and tails are equally likely in the toss of a coin. If you have felt skeptical
about this, you are perfectly right. It is not obvious; it is not even necessarily
true, as a bent or weighted coin would show. We must distinguish here between
the mathematical theory of probability and its application to a problem about
the physical world. Mathematical probability (like all of mathematics) starts with
a set of assumptions and shows that if the assumptions are true, then various
results follow. The basic assumptions in a mathematical probability problem are
the probabilities associated with the points of the sample space. Thus in a coin
tossing problem, we assume that for each toss the probability of heads and the
probability of tails are both 1
2, and then we show that the probability of both heads
in two tosses is 1
4. (See Section 3.) The question of whether the assumptions are
correct is not a mathematical one. Here we must ask what physical problem we
are trying to solve.
If we are dealing with a weighted coin, and if we know or
can somehow estimate experimentally the probability p of heads (and so 1 −p of
tails), then the mathematical theory starts with these values instead of 1
2, 1
2. In the
absence of any information as to whether heads or tails is more likely, we often make
the “natural” or “intuitive” assumption that the probabilities are both 1
2. The only
possible answer to the question of whether this is correct or not lies in experiment.
If the results predicted on the basis of our assumptions agree with experiment,
then the assumptions are good; otherwise we must revise the assumptions. (See
Section 4, Example 5.)
In this chapter we shall consider mainly the mathematical methods of calcu-
lating the probabilities of complicated happenings if we are given the probabilities
associated with the points of the sample space. For simplicity, we shall often assume
these probabilities to be the “natural” ones; the mathematical theory we develop
applies, however, if we replace these “natural” probabilities ( 1
2, 1
2 in the coin toss
problem, etc.) by any set of non-negative fractions whose sum is 1.
PROBLEMS, SECTION 2
1 to 10.
Set up an appropriate sample space for each of Problems 1.1 to 1.10 and use it
to solve the problem. Use either a uniform or nonuniform sample space or try both.
11.
Set up several nonuniform sample spaces for the problem of three tosses of a coin
(Example 1, above).

728
Probability and Statistics
Chapter 15
12.
Use the sample space of Example 1 above, or one or more of your sample spaces in
Problem 11, to answer the following questions.
(a)
If there were more heads than tails, what is the probability of one tail?
(b)
If two heads did not appear in succession, what is the probability of all tails?
(c)
If the coins did not all fall alike, what is the probability that two in succession
were alike?
(d)
If Nt = number of tails and Nh = number of heads, what is the probability
that |Nh −Nt| = 1?
(e)
If there was at least one head, what is the probability of exactly two heads?
13.
A student claims in Problem 1.5 that if one child is a girl, the probability that
both are girls is
1
2.
Use appropriate sample spaces to show what is wrong with
the following argument: It doesn’t matter whether the girl is the older child or the
younger; in either case the probability is 1
2 that the other child is a girl.
14.
Two dice are thrown. Use the sample space (2.4) to answer the following questions.
(a)
What is the probability of being able to form a two-digit number greater than
33 with the two numbers on the dice? (Note that the sample point 1, 4 yields
the two-digit number 41 which is greater than 33, etc.)
(b)
Repeat part (a) for the probability of being able to form a two-digit number
greater than or equal to 42.
(c)
Can you ﬁnd a two-digit number (or numbers) such that the probability of
being able to form a larger number is the same as the probability of being able
to form a smaller number? [See note, part (a).]
15.
Use both the sample space (2.4) and the sample space (2.5) to answer the following
questions about a toss of two dice.
(a)
What is the probability that the sum is ≥4?
(b)
What is the probability that the sum is even?
(c)
What is the probability that the sum is divisible by 3?
(d)
If the sum is odd, what is the probability that it is equal to 7?
(e)
What is the probability that the product of the numbers on the two dice is 12?
16.
Given an nonuniform sample space and the probabilities associated with the points,
we deﬁned the probability of an event A as the sum of the probabilities associated
with the sample points favorable to A. [You used this deﬁnition in Problem 15 with
the sample space (2.5).] Show that this deﬁnition is consistent with the deﬁnition
by equally likely cases if there is also a uniform sample space for the problem (as
there was in Problem 15). Hint: Let the uniform sample space have N points each
with the probability N−1. Let the nonuniform sample space have n < N points,
the ﬁrst point corresponding to N1 points of the uniform space, the second to N2
points, etc. What is
N1 + N2 + · · · + Nn?
What are p1, p2, . . . , the probabilities associated with the ﬁrst, second, etc., points
of the nonuniform space? What is p1 + p2 + · · · + pn? Now consider an event for
which several points, say i, j, k, of the nonuniform sample space are favorable. Then
using the nonuniform sample space, we have, by deﬁnition of the probability p of
the event, p = pi + pj + pk. Write this in terms of the N’s and show that the result
is the same as that obtained by equally likely cases using the uniform space. Refer
to Problem 15 as a speciﬁc example if you need to.

Section 3
Probability Theorems
729
17.
Two dice are thrown. Given the information that the number on the ﬁrst die is
even, and the number on the second is < 4, set up an appropriate sample space and
answer the following questions.
(a)
What are the possible sums and their probabilities?
(b)
What is the most probable sum?
(c)
What is the probability that the sum is even?
18.
Are the following correct nonuniform sample spaces for a throw of two dice?
If
so, ﬁnd the probabilities of the given sample points. If not show what is wrong.
Suggestion: Copy sample space (2.4) and circle on it the regions corresponding to
the points of the proposed nonuniform spaces.
(a)
First die shows an even number.
First die shows an odd number.
(b)
Sum of two numbers on dice is even.
First die is even and second odd.
First die is odd and second even.
(c)
First die shows a number ≤3.
At least one die shows a number > 3.
19.
Consider the set of all permutations of the numbers 1, 2, 3. If you select a permuta-
tion at random, what is the probability that the number 2 is in the middle position?
In the ﬁrst position? Do your answers suggest a simple way of answering the same
questions for the set of all permutations of the numbers 1 to 7?
3. PROBABILITY THEOREMS
It is not always easy to make direct use of our deﬁnitions to calculate probabilities.
Deﬁnition (1.2) asks us to ﬁnd a uniform sample space for a problem, that is, a
set of all possible equally likely, mutually exclusive outcomes of an experiment, and
then determine how many of these are favorable to a given event. The deﬁnition in
Section 2 similarly requires a sample space, that is, a list of the possible outcomes
and their probabilities. Such lists may be prohibitively long; we want to consider
some theorems which will shorten our work.
Suppose there are 5 black balls and 10 white balls in a box; we draw one ball
“at random” (this means we are assuming that each ball has probability
1
15 of being
drawn), and then without replacing the ﬁrst ball, we draw another. Let us ask
for the probability that the ﬁrst ball is white and the second one is black. The
probability of drawing a white ball the ﬁrst time is 10
15 (10 of the 15 balls are white).
The probability of then drawing a black ball is
5
14 since there are 14 balls left and
5 of them are black. We are going to show that the probability of drawing ﬁrst a
white ball and then (without replacement) a black is the product 10
15 · 5
14. We reason
in the following way, using a uniform sample space. Imagine that the balls are
numbered 1 to 15. The symbol 5,3 will mean that ball 5 was drawn the ﬁrst time
and ball 3 the second time. In such pairs of two (diﬀerent) numbers representing
a drawing of two balls in succession, there are 15 choices for the ﬁrst number and
14 for the second (the ﬁrst ball was not replaced). Thus the uniform sample space
representing all possible drawings consists of a rectangular array of symbols (like
5,3) with 15 columns (for the 15 diﬀerent choices for the ﬁrst number) and 14 rows
(for the 14 choices for the second number). Thus there are 15 · 14 points in the
sample space. [See also (4.1)]. How many of these sample points correspond to

730
Probability and Statistics
Chapter 15
drawing ﬁrst a white ball and then a black ball? Ten numbers correspond to white
balls and the other ﬁve to black balls. Thus to obtain a sample point corresponding
to drawing ﬁrst a white and then a black ball, we can choose the ﬁrst number in
10 ways and then the second number in 5 ways, and so choose the sample point in
10 · 5 ways; that is, there are 10 · 5 sample points favorable to the desired drawing.
Then by the deﬁnition (1.2), the desired probability is (10 · 5)/(15 · 14) as claimed.
Let us state in general the theorem we have just illustrated. We are interested
in two successive events A and B. Let P(A) be the probability that A will happen,
P(AB) be the probability that both A and B will happen, and PA(B) be the
probability that B will happen if know that A has happened. Then
(3.1)
P(AB) = P(A) · PA(B)
Figure 3.1
or in words, the probability of the compound event “A and B” is the product of
the probability that A will happen times the probability that B will happen if A
does. Using the idea of a uniform sample space, we can prove (3.1) by following
the method in the ball drawing problem. Let N be the total number of sample
points in a uniform sample space, N(A) and N(B) be the numbers of sample points
corresponding to the events A and B respectively, and N(AB) be the number
of sample points corresponding to the compound event A and B. It is useful to
picture the sample space geometrically (Figure 3.1) as an array of N points [compare
with sample space (2.4)]. We can then circle all points which correspond to A’s
happening and mark this region A; it contains N(A) points. Similarly, we can circle
the N(B) points which correspond to B’s happening and call this region B. The
overlapping region we call AB; it is part of
both A and B and contains N(AB) points
which correspond to the compound event
A and B. Then by the deﬁnition (1.2):
P(AB) = N(AB)
N
,
P(A) = N(A)
N
,
(3.2)
PA(B) = N(AB)
N(A) .
Perhaps this last formula for PA(B) needs some discussion. Recall from Sec-
tion 2, Example 1, the uniform sample space (2.3) for three tosses of a coin. To
ﬁnd the probability of all tails given that there was at least one tail, we reduced
our sample space to seven points (eliminating hhh). We then assumed that the
seven points of the new sample space had the same relative probability as before
the deletion of the point hhh; thus each of the seven points had probability
1
7.
(This is no more and no less “obvious” than the original assumption that the eight
points had equal probability; it is an additional assumption which we make in the
absence of any information to the contrary; see end of Section 2.) Now let us look
at the third equation of (3.2). N(A) is the number of sample points corresponding
to event A; the N points in the original sample apace all had the same probability

Section 3
Probability Theorems
731
so we now assume that when we cross oﬀall the points corresponding to A’s not
happening, the remaining N(A) points also have equal probability. Thus we have a
new uniform sample space consisting of N(A) points. N(AB) of these N(A) points
correspond to the event B (assuming A). Thus by (1.2), the probability of “B if A”
is N(AB)/N(A). From the three equations (3.2), we then have (3.1). In a similar
way we can show that
(3.3)
P(BA) = P(B) · PB(A) = P(AB)
(see Problem 1). [We have proved (3.1) assuming a uniform sample space. This
assumption is not necessary; (3.1) is true whether or not we can construct a uniform
sample space; see Problem 2.]
Suppose, now, in our example of 5 black and 10 white balls in a box, we draw a
ball and replace it and then draw a second ball. The probability of a black ball on
the second drawing is then
5
15 = 1
3; this is exactly the same result we would get if
we had not drawn and replaced the ﬁrst ball. In the notation of the last paragraph
(3.4)
P(B) = PA(B),
A and B independent.
When (3.4) is true, we say that the event B is independent of event A and (3.1)
becomes
(3.5)
P(AB) = P(A) · P(B),
A and B independent.
Because of the symmetry of (3.5), we may simply say that A and B are independent
if (3.5) is true. (Also see Problem 7.)
Example 1.
(a) In three tosses of a coin, what is the probability that all three are heads?
We found p = 1
8 for this problem in Section 2 by seeing that one sample point out of
eight corresponds to all heads. Now we can do the problem more simply by saying
that the probability of heads on each toss is 1
2, the tosses are independent, and
therefore
p = 1
2 · 1
2 · 1
2 = 1
8.
(b) If we should want the probability of all heads when a coin is tossed ten times,
the sample space would be unwieldy; instead of using the sample space, we can say
that since the tosses are independent, the desired probability is p = ( 1
2)10.
(c) To ﬁnd the probability of at least one tail in ten tosses, we see that this event
corresponds to all the rest of the sample space except the “all heads” point. Since
the sum of the probabilities of all the sample points is 1, the desired probability is
1 −( 1
2)10.
In Figure 3.1 or Figure 3.2 the region AB corresponds to the happening of both
A and B. The whole region consisting of points in A or B or both corresponds to
the happening of either A or B or both. We write P(AB) for the probability that
both A and B occur. We shall write P(A + B) for the probability that either or
both occur. Then we can prove that

732
Probability and Statistics
Chapter 15
Figure 3.2
Figure 3.3
(3.6)
P(A + B) = P(A) + P(B) −P(AB).
To see why this is true, consider Figure 3.2. To ﬁnd P(A+B) we add the probabil-
ities of all the sample points in the region consisting of A or B or both. But if we
add P(A) and P(B), we have included the probabilities of all the sample points in
AB twice [once in P(A) and once in P(B)]. Thus we must subtract P(AB), which
is the sum of the probabilities of all the sample points in AB. This is just what
(3.6) says.
If the sample space diagram is like the one in Figure 3.3, so that P(AB) = 0,
we say that A and B are mutually exclusive. Then (3.6) becomes
(3.7)
P(A + B) = P(A) + P(B),
A and B mutually exclusive.
Example2.
Two students are working separately on the same problem. If the ﬁrst student
has probability 1
2 of solving it and the second student has probability 3
4 of solving
it, what is the probability that at least one of them solves it?
Let A be the event “ﬁrst student succeeds,” and B be the event “second student
succeeds.”
Then P(AB) =
1
2 · 3
4 =
3
8 (assume A and B independent since the
students work separately). Then by (3.6) the probability that one or the other or
both students solve the problem is
P(A + B) = 1
2 + 3
4 −3
8 = 7
8.
Conditional Probability; Bayes’ Formula
If we are asked for the probability
of event B assuming that event A occurs [that is, PA(B)], it is often useful to ﬁnd
it from (3.1):
(3.8)
PA(B) = P(AB)
P(A) .
Equation (3.8) is called Bayes’ formula. In any conditional probability problem to
which the answer is not immediately obvious, you should consider whether you
can easily ﬁnd P(A) and P(AB); if so, the conditional probability PA(B) is given
by (3.8).

Section 3
Probability Theorems
733
Example 3.
A preliminary test is customarily given to the students at the beginning of a
certain course. The following data are accumulated after several years:
(a) 95% of the students pass the course, 5% fail.
(b) 96% of the students who pass the course also passed the preliminary test.
(c) 25% of the students who fail the course passed the preliminary test.
What is the probability that a student who has failed the preliminary test will pass
the course?
Figure 3.4
Let A be the event “fails preliminary test” and B be the event “Passes course.”
The probability we want is then PA(B) in (3.8), so we need P(AB) and P(A).
P(AB) is the probability that the student both fails the preliminary test and passes
the course; this is P(AB) = (0.95)(0.04) = 0.038. (See Figure 3.4; 95% of the
students passed the course and of these 4% had failed the preliminary test.) We
also want P(A), the probability that a students fails the preliminary test; this
event corresponds to the shaded area in Figure 3.4. Thus P(A) is the sum of the
probabilities of the two events “passes course after failing test,” “fails course after
failing test.” Then
P(A) = (0.095)(0.04) + (0.05)(0.75) = 0.0755
(See Figure 3.4; of the 95% of students who passed the course, 4% failed the prelimi-
nary test; of the 5% of the students who failed the course, 75% failed the preliminary
test since we are given that 25% passed.) By (3.8) we have
PA(B) = P(AB)
P(A)
= 0.038
0.0755 = 50%,
that is, half of the students who fail the preliminary test succeed in passing the
course.
Note that in Figure 3.4, the shaded area corresponds to event A (fails preliminary
test). We are interested in event B (passes course) given event A. Thus instead
of the original sample space (whole rectangle in Figure 3.4) we consider a smaller
sample space (shaded area in Figure 3.4). We then want to know what part of this
sample space corresponds to event B (passes course). This fraction is P(AB)/P(A)
which we computed.

734
Probability and Statistics
Chapter 15
PROBLEMS, SECTION 3
1.
(a)
Set up a sample space for the 5 black and 10 white balls in a box discussed
above assuming the ﬁrst ball is not replaced. Suggestions: Number the balls,
say 1 to 5 for black and 6 to 15 for white. Then the sample points form an
array something like (2.4), but the point 3,3 for example is not allowed. (Why?
What other points are not allowed?) You might ﬁnd it helpful to write the
numbers for black balls and the numbers for white balls in diﬀerent colors.
(b)
Let A be the event “ﬁrst ball is white” and B be the event “second ball is
black.” Circle the region of your sample space containing points favorable to
A and mark this region A. Similarly, circle and mark region B. Count the
number of sample points in A and in B; these are N(A) and N(B). The region
AB is the region inside both A and B; the number of points in this region is
N(AB). Use the numbers you have found to verify (3.2) and (3.1). Also ﬁnd
P(B) and PB(A) and verify (3.3) numerically.
(c)
Use Figure 3.1 and the ideas of part (b) to prove (3.3) in general.
2.
Prove (3.1) for a nonuniform sample space. Hints: Remember that the probability
of an event is the sum of the probabilities of the sample points favorable to it. Using
Figure 3.1, let the points in A but not in AB have probabilities p1, p2, . . . , pn, the
points in AB have probabilities pn+1, pn+2, . . . , pn+k, and the points in B but not
in AB have probabilities pn+k+1, pn+k+2, . . . , pn+k+l. Find each of the probabilities
in (3.1) in terms of the p’s and show that you then have an identity.
3.
What is the probability of getting the sequence hhhttt in six tosses of a coin? If you
know the ﬁrst three are heads, what is the probability that the last three are tails?
4.
(a)
A weighted coin has probability of 2
3 of showing heads and 1
3 of showing tails.
Find the probabilities of hh, ht, th and tt in two tosses of the coin. Set up
the sample space and the associated probabilities. Do the probabilities add to
1 as they should? What is the probability of at least one head? What is the
probability of two heads if you know there was at least one head?
(b)
For the coin in (a), set up the sample space for three tosses, ﬁnd the associated
probabilities, and use it to answer the questions in Problem 2.12.
5.
What is the probability that a number n, 1 ≤n ≤99, is divisible by both 6 and 10?
By either 6 or 10 or both?
6.
A card is selected from a shuﬄed deck. What is the probability that it is either a
king or a club? That it is both a king and a club?
7.
(a)
Note that (3.4) assumes P(A) ̸= 0 since PA(B) is meaningless if P(A) = 0.
Assuming both P(A) ̸= 0 and P(B) ̸= 0, show that if (3.4) is true, then
P(A) = PB(A); that is if B is independent of A, then A is independent of B.
If either P(A) or P(B) is zero, then we use (3.5) to deﬁne independence.
(b)
When is an event E independent of itself? When is E independent of “not E”?
8.
Show that
P(A + B + C) = P(A) + P(B) + P(C) −P(AB) −P(AC) −P(BC) + P(ABC).
Hint: Start with Figure 3.2 and sketch in a region C overlapping some of the points
of each of the regions A, B, and AB.
9.
Two cards are drawn at random from a shuﬄed deck and laid aside without being
examined. Then a third card is drawn. Show that the probability that the third
card is a spade is 1
4 just as it was for the ﬁrst card. Hint: Consider all the (mutually
exclusive) possibilities (two discarded cards spades, third card spade or not spade,
etc.).

Section 3
Probability Theorems
735
10.
(a)
Three typed letters and their envelopes are piled on a desk. If someone puts the
letters into the envelopes at random (one letter in each), what is the probability
that each letter gets into its own envelope? Call the envelopes A, B, C, and the
corresponding letters a, b, c, and set up the sample space. Note that “a in C,
b in B, c in A” is one point in the sample space.
(b)
What is the probability that at least one letter gets into its own envelope?
Hint: What is the probability that no letter gets into its own envelope?
(c)
Let A mean that a got into envelope A, and so on. Find the probability P(A)
that a got into A.
Find P(B) and P(C).
Find the probability P(A + B)
that either a or b or both got into their correct envelopes, and the probability
P(AB) that both got into their correct envelopes. Verify equation (3.6).
11.
In paying a bill by mail, you want to put your check and the bill (with a return
address printed on it) into a window envelope so that the address shows right side
up and is not blocked by the check. If you put check and bill at random into the
envelope, what is the probability that the address shows correctly?
12.
(a)
A loaded die has probabilities
1
21,
2
21,
3
21,
4
21,
5
21,
6
21, of showing 1, 2, 3, 4, 5, 6.
What is the probability of throwing two 3’s in succession?
(b)
What is the probability of throwing a 4 the ﬁrst time and not a 4 the second
time with a die loaded as in (a)?
(c)
If two dice loaded as in (a) are thrown, and we know that the sum of the
numbers on the faces is greater than or equal to 10, what is the probability
that both are 5’s?
(d)
How many times must we throw a die loaded as in (a) to have probability
greater than 1
2 of getting an ace?
(e)
A die, loaded as in (a), is thrown twice.
What is the probability that the
number on the die is even the ﬁrst time > 4 the second time?
13.
(a)
A candy vending machine is out of order. The probability that you get a candy
bar (with or without return of your money) is 1
2, the probability that you get
your money back (with or without candy) is 1
3, and the probability that you
get both the candy and your money back is
1
12. What is the probability that you
get nothing at all? Suggestion: Sketch a geometric diagram similar to Figure
3.1, indicate regions representing the various possibilities and their probabili-
ties; then set up a four-point sample space and the associated probabilities of
the points.
(b)
Suppose you try again to get a candy bar as in part (a). Set up the 16-point
sample space corresponding to the possible results of your two attempts to
buy a candy bar, and ﬁnd the probability that you get two candy bars (and
no money back); that you get no candy and lose your money both times; that
you just get your money back both times.
14.
A basketball player succeeds in making a basket 3 tries out of 4. How many tries
are necessary in order to have probability > 0.99 of at least one basket?
15.
Use Bayes’ formula (3.8) to repeat these simple problems previously done by using
a reduced sample space.
(a)
In a family of two children, what is the probability that both are girls if at
least one is a girl?
(b)
What is the probability of all heads in three tosses of a coin if you know that
at least one is a head?

736
Probability and Statistics
Chapter 15
16.
Suppose you have 3 nickels and 4 dimes in your right pocket and 2 nickels and a
quarter in your left pocket. You pick a pocket at random and from it select a coin
at random. If it is a nickel, what is the probability that it came from your right
pocket?
17.
(a)
There are 3 red and 5 black balls in one box and 6 red and 4 white balls in
another. If you pick a box at random, and then pick a ball from it at random,
what is the probability that it is red? Black? White? That it is either red or
white?
(b)
Suppose the ﬁrst ball selected is red and is not replaced before a second ball
is drawn. What is the probability that the second ball is red also?
(c)
If both balls are red, what is the probability that they both came from the
same box?
18.
Two cards are drawn at random from a shuﬄed deck.
(a)
What is the probability that at least one is a heart?
(b)
If you know that at least one is a heart, what is the probability that both are
hearts?
19.
Suppose it is known that 1% of the population have a certain kind of cancer. It is
also known that a test for this kind of cancer is positive in 99% of the people who
have it but is also positive in 2% of the people who do not have it. What is the
probability that a person who tests positive has cancer of this type?
20.
Some transistors of two diﬀerent kinds (call them N and P) are stored in two boxes.
You know that there are 6 N’s in one box and that 2 N’s and 3 P’s got mixed in
the other box, but you don’t know which box is which. You select a box and a
transistor from it at random and ﬁnd that it is an N; what is the probability that
it came from the box with the 6 N’s? From the other box? If another transistor is
picked from the same box as the ﬁrst, what is the probability that it is also an N?
21.
Two people are taking turns tossing a pair of coins; the ﬁrst person to toss two alike
wins. What are the probabilities of winning for the ﬁrst player and for the second
player? Hint: Although there are an inﬁnite number of possibilities here (win on
ﬁrst turn, second turn, third turn, etc.), the sum of the probabilities is a geometric
series which can be summed; see Chapter 1 if necessary.
22.
Repeat Problem 21 if the players toss a pair of dice trying to get a double (that is,
both dice showing the same number).
23.
A thick coin has probability 3
7 of falling heads, 3
7 of falling tails, and 1
7 of standing on
edge. Show that if it is tossed repeatedly it has probability 1 of eventually standing
on edge.
4. METHODS OF COUNTING
Let us digress for a bit to review some ideas and formulas we need in computing
probabilities in more complicated problems.
Let us ask how many two-digit numbers have either 5 or 7 for the tens digit and
either 3, 4, or 6 for the units digit. The answer becomes obvious if we arrange the
possible numbers in a rectangle
53
54
56
73
74
76

Section 4
Methods of Counting
737
with two rows corresponding to the two choices of the tens digit and three columns
corresponding to the three choices of the units digit. This is an example of the
fundamental principle of counting:
(4.1)
If one thing can be done N1 ways, and after that a second thing
can be done in N2 ways, the two things can be done in succession
in that order in N1 · N2 ways. This can be extended to doing any
number of things one after the other, the ﬁrst N1 ways, the second
N2 ways, the third N3 ways, etc. Then the total number of ways
to perform the succession of acts is the product N1N2N3 · · · .
Now consider a set of n things lined up in a row; we ask how many ways we
can arrange (permute) them. This result is called the number of permutations of n
things n at a time, and is denoted by nPn or P(n, n) or P n
n . To ﬁnd this number,
we think of seating n people in a row of n chairs. We can place anyone in the
ﬁrst chair, that is, we have n possible ways of ﬁlling the ﬁrst chair. Once we have
selected someone for the ﬁrst chair, there are (n −1) choices left for the second
chair, then (n −2) choices for the third chair, and so on. Thus by the fundamental
principle, there are n(n −1)(n −2) · · · 2 · 1 = n! ways of arranging the n people in
the row of n chairs. The number of permutations of n things n at a time is
(4.2)
P(n, n) = n!.
Next suppose there are n people but only r < n chairs and we ask how many
ways we can select groups of r people and seat them in the r chairs. The result is
called the number of permutations of n things r at a time and is denoted by nPr
or P(n, r) or P n
r . Arguing as before, we ﬁnd that there are n ways to ﬁll the ﬁrst
chair, (n −1) ways to ﬁll the second chair, (n −2) ways for the third [note that we
could write (n −2) as (n −3 + 1)], etc., and ﬁnally (n −r + 1) ways of ﬁlling chair
r. Thus we have for the number of permutations of n things r at a time
P(n, r) = n(n −1)(n −2) · · · (n −r + 1).
By multiplying and dividing by (n −r)! we can write this as
(4.3)
P(n, r) = n(n −1)(n −2) · · · (n −r + 1)(n −r)!
(n −r)! =
n!
(n −r)!.
So far we have been talking about arranging things in a deﬁnite order. Suppose,
instead that we ask how many committees of r people can be chosen from a group of
n people (n ≥r). Here the order of the people in the committee is not considered;
the committee made up of people A, B, C, is the same as the committee made up
of people B, A, C. We call the number of such committees of r people which we
can select from n people, the number of combinations or selections of n things r
at a time, and denote this number by nCr or C(n, r) or
n
r

. To ﬁnd C(n, r), we
go back to the problem of selecting r people from a group of n and seating them
in r chairs; we found that the number of ways of doing this is P(n, r) as given in

738
Probability and Statistics
Chapter 15
(4.3). We can perform this job by ﬁrst selecting r people from the total n and then
arranging the r people in r chairs. The selection of r people can be done in C(n, r)
ways (this is the number we are trying to ﬁnd), and after r people are selected, they
can be arranged in r chairs in P(r, r) ways by (4.2). By the fundamental principle
(4.1), the total number of ways P(n, r) of selecting and seating r people out of n is
the product C(n, r) · P(r, r). Thus we have
(4.4)
P(n, r) = C(n, r) · P(r, r).
We can solve this equation to ﬁnd the value C(n, r) which we wanted. Substituting
the values of P(n, r) and P(r, r) from (4.3) and (4.2) into (4.4) and solving for
C(n, r), we ﬁnd for the number of combinations of n things r at a time
(4.5)
C(n, r) = P(n, r)
P(r, r) =
n!
(n −r)!r! =
n
r

.
Each time we select r people to be seated, we leave n −r people without chairs.
Then there are exactly the same number of combinations of n things n−r at a time
as there are combinations of n things r at a time. Hence we write
(4.6)
C(n, n −r) = C(n, r) =
n!
(n −r)!r!.
We can also obtain (4.6) from (4.5) by replacing r by (n −r).
Example 1.
A club consists of 50 members. In how many ways can a president, vice-
president, secretary, and treasurer be chosen? In how many ways can a committee
of 4 members be chosen?
In the selection of oﬃcers, we must not only select 4 people, but decide which one
is president, etc.; we could think of seating the 4 people in chairs labeled president,
vice-president, etc. Thus the number of ways of selecting the oﬃcers is
P(50, 4) =
50!
(50 −4)! = 50!
46! = 50 · 49 · 48 · 47.
The committee members, however, are all equivalent (we are neglecting the pos-
sibility that one is named chairman), so the number of ways of selecting committees
of 4 people is
C(50, 4) = 50!
46!4! = 50 · 49 · 48 · 47
24
.
Example 2.
Find the coeﬃcient of x8 in the binomial expansion of (1 + x)15.
Think of multiplying out
(1 + x)(1 + x)(1 + x) · · · (1 + x),
(with 15 factors).
We obtain a term in x8 each time we multiply 1’s from seven of the parentheses by
x’s from eight of the parentheses. The number of ways of selecting 8 parentheses
out of 15 is
C(15, 8) = 15!
8!7!.

Section 4
Methods of Counting
739
This is the desired coeﬃcient of x8.
Generalizing this example, we see that in the expansion of (a+b)n, the coeﬃcient
of an−rbr is C(n, r), usually written
n
r

when used in connection with a binomial
expansion (see Chapter 1, Section 13C). Thus the expressions C(n, r) are just the
binomial coeﬃcients, and we can write
(4.7)
(a + b)n =
n

r=0
n
r

an−rbr.
Example 3.
A basic problem in statistical mechanics is this: Given N balls, and n boxes,
in how many ways can the balls be put into the boxes so that there will be given
numbers of balls in the boxes, say N1 balls in the ﬁrst box, N2 balls in the second
box, N3 in the third, · · · , Nn in the nth, and what is the probability that this
given distribution will occur when the balls are put into the boxes? In statistical
mechanics the “balls” may be molecules, electrons, photons, etc., and each “box”
corresponds to a small range of values of position and momentum of a particle. We
can state many other problems in this same language of putting balls into boxes.
For example, in tossing a coin, we can equate heads with box 1, and tails with
box 2; in tossing a die, there are six “boxes.” In putting letters into envelopes, the
letters are the balls, and the envelopes are the boxes. In dealing cards, the cards
are the balls and the players who receive them are the boxes. In an alpha scattering
experiment, the alpha particles are the balls, and the boxes are elements of area
on the detecting screen which the particles hit after they are scattered. (Also see
Problems 14 and 21 and Feller, pp. 10–11.)
Let us do a special case of this problem in which we have 15 balls and 6 boxes,
and the numbers of balls we are to put into the various boxes are:
Number of balls:
3
1
4
2
3
2
In box number:
1
2
3
4
5
6
We ﬁrst ask how many ways we can select 3 balls to go in the ﬁrst box from the
15 balls; this is C(15, 3).
(Note that the order of the balls in the boxes is not
considered; this is like the committee problem in Example 1.) Now we have 12 balls
left, of which we are to select 1 for box 2; we can do this in C(12, 1) ways. We can
then select the 4 balls for box 3 from the remaining 11 balls in C(11, 4) ways, the
2 balls for box 4 in C(7, 2) ways, the 3 balls for box 5 in C(5, 3) ways, and ﬁnally the
balls for box 6 in C(2, 2) ways (verify that this is 1). By the fundamental principle,
the total number of ways of putting the required numbers of balls into the boxes is
C(15, 3) · C(12, 1) · C(11, 4) · C(7, 2) · C(5, 3) · C(2, 2)
=
15!
3! · 12! ·
12!
1! · 11! ·
11!
4! · 7! ·
7!
2! · 5! ·
5!
3! · 2! ·
2!
2! · 0!
=
15!
3! · 1! · 4! · 2! · 3! · 2!.
(Remember from Chapters 1 and 11 that 0! = 1.)
Next we want the probability of this particular distribution. Let us assume that
the balls are distributed “at random” into the boxes; by this we mean that a ball
has the same probability (namely 1
6) of being put into any one box as into any other
box. We can put the ﬁrst ball into any one of the 6 boxes, the second ball into any

740
Probability and Statistics
Chapter 15
one of the 6 boxes, and so on. Thus by the fundamental principle, the total number
of ways of distributing the 15 balls into the 6 boxes is 6 · 6 · 6 · 6 · · · 6 = 615 and we
are assuming that these distributions are equally probable. Then the probability
that, when 15 balls are distributed “at random” into 6 boxes, there will be 3 balls
in box 1, 1 in box 2, etc., as given, is, by (1.2) (favorable cases ÷ total)
15!
3! · 1! · 4! · 2! · 3! · 2! ÷ 615.
Example 4.
In Example 3, we assumed that the 615 possible distributions of 15 balls into
6 boxes were equally likely. This seems very reasonable if we think of putting the
balls into the boxes by tossing a die for each ball; if the die shows 1 we put the ball
into box 1, etc. However, we can think of situations to which this method and result
do not apply. For example, suppose we are putting letters into envelopes or seating
people in chairs; then we may reasonably require only one letter per envelope, not
more than one person per chair, that is, one ball (or none) per box. Consider the
problem of seating 4 people in 6 chairs, that is of putting 4 balls into 6 boxes. If we
number the chairs from 1 to 6 and let each person choose a chair by tossing a die,
we may have two or more people choosing the same chair. The result 64 (which the
method of Example 3 gives for the problem of 4 balls in 6 boxes) then does not apply
to this problem. However, let us consider the uniform sample space of 64 points and
select from it the points corresponding to our restriction (one ball or none per box).
The new sample space contains C(6, 4) · 4! points (number of ways of selecting the
4 chairs to be occupied times the number of ways of then arranging 4 people in 4
chairs). Since these points were equally probable in the original (uniform) sample
space, we still consider them equally probable. Now let us ask for the probability
that the ﬁrst two chairs are vacant when the 4 people are seated. The number of
sample points corresponding to this event is 4! (the number of ways of arranging
the 4 people in the last 4 chairs). Thus the desired probability is
4!
C(6, 4) · 4! =
1
C(6, 4).
We can now see an easier way of doing problems of this kind. The factor 4!,
which canceled in the probability calculation, was the number of rearrangements of
the 4 people among the 4 occupied chairs. Since this is the same for any given set
of 4 chairs, we can lump together all the sample points corresponding to each given
set of 4 chairs, and have a smaller (still uniform) sample space of C(6, 4) points.
Each point now corresponds to a given set of 4 occupied chairs; the quantity C(6, 4)
is just the number of ways of picking 4 occupied chairs out of 6. The probability
that the ﬁrst two chairs are vacant when 4 people are seated is 1/C(6, 4) since there
is only one way to select 4 occupied chairs leaving the ﬁrst two chairs vacant.
Another useful way of looking at this problem is to consider a set of 4 identical
balls to be put into 6 boxes. Since the balls are identical, the 4! arrangements
of the 4 balls in 4 given boxes all look alike. We can say that there are C(6, 4)
distinguishable arrangements of the 4 identical balls in 6 boxes (one ball or none
per box). Since all these arrangements are equally probable, the probability of any
one arrangement (say the ﬁrst two boxes empty) is 1/C(6, 4) as we found previously.

Section 4
Methods of Counting
741
Example 5.
In Example 4 we found the same answer for the probability that two partic-
ular boxes were empty whether or not we considered the balls distinguishable. This
was true because the allowed distinguishable arrangements were equally probable.
Without the restriction of one ball or none per box, all distinguishable arrangements
are not equally probable according to the methods of Examples 3 and 4. For exam-
ple, the probability of all balls in box 1 is 1/64; compare this with the probability
of no balls in the ﬁrst 2 boxes and one ball in each of the other 4 boxes, which is
4!÷64 =
1
54. We see that the concentrated arrangements (all or several balls in one
box) are less probable than the more uniform arrangements.
Now we are going to try to imagine a situation in which all distinguishable ar-
rangements are equally probable. Suppose the 6 boxes are benches in a waiting room
and the 4 balls are people who are going to come in and sit on the benches. Then
if the people are friends, there will be a certain tendency for them to sit together
and the probabilities we have been calculating will not apply—the probabilities of
the concentrated arrangements will increase. Consider the following mathematical
model. (This is a modiﬁcation of P´olya’s urn model.) We have 6 boxes labeled 1
to 6, and 4 balls. From 6 cards labeled 1 to 6 we draw one at random and place a
ball in the box numbered the same as the card drawn. We then replace the card and
also add another card of the same number so that there are now 7 cards, two with
the number ﬁrst drawn. We now select a card at random from these 7, put a ball
in the corresponding box and again replace the card adding a duplicate to make
8 cards. We repeat this process two more times (until all balls are distributed).
Then the probability that all balls are in box 1 is 1
6 · 2
7 · 3
8 · 4
9. The probability
of one ball in each of the ﬁrst 4 boxes is 1
6 · 1
7 · 1
8 · 1
9 · 4! (here 1
6 · 1
7 · 1
8 · 1
9 is the
probability that the ﬁrst ball is in box 1, the second in box 2, etc.; we must add to
this the probability that the ﬁrst ball is in box 3, the second in box 1, etc.; there
are 4! such possibilities all giving one ball in each of the ﬁrst 4 boxes). We see that
the distributions “all balls in box 1” and “one ball in each of the ﬁrst 4 boxes” are
equally probable. Further calculation (Problem 20) shows that all distinguishable
arrangements are equally probable.
To ﬁnd the number of distinguishable arrangements, consider the following pic-
ture of the 4 balls in the 6 boxes.
|
o
|
|
o o
|
|
o
|
|
Box number:
1
2
3
4
5
6
Number of balls:
1
0
2
0
1
0
The lines mean the sides of the boxes and the circles are the balls; note that it
requires 7 lines to picture the 6 boxes. This picture shows one of many possible
arrangements of the 4 balls in 6 boxes. In any such picture there must be a line at
the beginning and at the end, but the rest of the lines (5 of them) and the 4 circles
can be arranged in any order. You should convince yourself that every arrangement
of the balls in the boxes can be so pictured. Then the number of such distinguishable
arrangements is just the number of ways we can select 4 positions for the 4 circles
out of 9 positions for the 5 lines and 4 circles. Thus there are C(9, 4) equally likely
arrangements in this problem.
We see then that putting balls in boxes is not quite as simple as we thought; we
must say how we propose to distribute them and even before that we must think
what practical problem we are trying to solve; this is what determines the sample
space and the probabilities to be associated with the sample points. Unfortunately,

742
Probability and Statistics
Chapter 15
it may not always be clear what the sample space probabilities should be; then the
best we can do is to try various assumptions. In statistical mechanics it is found that
certain particles (for example, the molecules of a gas) are correctly described if we
assume that they behave like the balls of Example 3 (all 615 arrangements equally
likely); we then say that they obey Maxwell-Boltzmann statistics. Other particles
(for example, electrons) behave like the people to be seated in Example 4 (one
particle or none per box); we say that such particles obey Fermi-Dirac statistics.
Finally some particles (for example, photons) act something like the friends who
want to sit near each other (all distinguishable arrangements of identical particles
are equally likely); we say that these particles obey Bose-Einstein statistics. For
the problem of 4 particles in 6 boxes, there are then 64 equally likely arrangements
for Maxwell-Boltzmann particles, C(6, 4) for Fermi-Dirac particles, and C(9, 4) for
Bose-Einstein particles. (See Problems 15 to 20.)
PROBLEMS, SECTION 4
1.
(a)
There are 10 chairs in a row and 8 people to be seated. In how many ways can
this be done?
(b)
There are 10 questions on a test and you are to do 8 of them. In how many
ways can you choose them?
(c)
In part (a) what is the probability that the ﬁrst two chairs in the row are
vacant?
(d)
In part (b), what is the probability that you omit the ﬁrst two problems in the
test?
(e)
Explain why the answer to parts (a) and (b) are diﬀerent, but the answers to
(c) and (d) are the same.
2.
In the expansion of (a + b)n (see Example 2), let a = b = 1, and interpret the terms
of the expansion to show that the total number of combinations of n things taken
1, 2, 3, · · · , n at a time, is 2n −1.
3.
A bank allows one person to have only one savings account insured to $100,000.
However, a larger family may have accounts for each individual, and also accounts
in the names of any 2 people, any 3 and so on. How many accounts are possible for
a family of 2? Of 3? Of 5? Of n? Hint: See Problem 2.
4.
Five cards are dealt from a shuﬄed deck. What is the probability that they are all
of the same suit? That they are all diamond? That they are all face cards? That
the ﬁve cards are a sequence in the same suit (for example, 3, 4, 5, 6, 7 of hearts)?
5.
A bit (meaning binary digit) is 0 or 1.
An ordered array of eight bits (such as
01101001) is a byte. How many diﬀerent bytes are there? If you select a byte at
random, what is the probability that you select 11000010? What is the probability
that you select a byte containing three 1’s and ﬁve 0’s?
6.
A so-called 7-way lamp has three 60-watt bulbs which may be turned on one or two
or all three at a time, and a large bulb which may be turned to 100 watts, 200 watts
or 300 watts. How many diﬀerent light intensities can the lamp be set to give if the
completely oﬀposition is not included? (The answer is not 7.)
7.
What is the probability that the 2 and 3 of clubs are next to each other in a shuﬄed
deck?
Hint:
Imagine the two cards accidentally stuck together and shuﬄed as
one card.

Section 4
Methods of Counting
743
8.
Two cards are drawn from a shuﬄed deck. What is the probability that both are
aces? If you know that at least one is an ace, what is the probability that both are
aces? If you know that one is the ace of spades, what is the probability that both
are aces?
9.
Two cards are drawn from a shuﬄed deck. What is the probability that both are
red? If at least one is red, what is the probability that both are red? If at least one
is a red ace, what is the probability that both are red? If exactly one is a red ace,
what is the probability that both are red?
10.
What is the probability that you and a friend have diﬀerent birthdays? (For sim-
plicity, let a year have 365 days.) What is the probability that three people have
three diﬀerent birthdays? Show that the probability that n people have n diﬀerent
birthdays is
p =
„
1 −
1
365
« „
1 −
2
365
« „
1 −
3
365
«
· · ·
„
1 −n −1
365
«
.
Estimate this for n ≪365 by calculating ln p [recall that ln(1+x) is approximately x
for x ≪1]. Find the smallest (integral) n for which p < 1
2. Hence, show that for a
group of 23 people or more, the probability is greater than 1
2 that two of them have
the same birthday. (Try it with a group of friends or a list of people such as the
presidents of the United States.)
11.
The following game was being played on a busy street: Observe the last two digits
on each license plate. What is the probability of observing at least two cars with
the same last two digits among the ﬁrst 5 cars? 10 cars? 15 cars? How many cars
must you observe in order for the probability to be greater than 1
2 of observing two
with the same last two digits?
12.
Consider Problem 10 for diﬀerent months of birth. What is the smallest number of
people for which the probability is greater than 1
2 that two of them were born in the
same month?
13.
Generalize Example 3 to show that the number of ways of putting N balls in n boxes
with N1 in box 1, N2 in box 2, etc., is
„
N!
N1! · N2! · N3! · · · Nn!
«
.
14.
(a)
Find the probability that in two tosses of a coin, one is heads and one tails.
That in six tosses of a die, all six of the faces show up. That in 12 tosses of
a 12-sided die, all 12 faces show up. That in n tosses of an n-sided die, all n
faces show up.
(b)
The last problem in part (a) is equivalent to ﬁnding the probability that, when
n balls are distributed at random into n boxes, each box contains exactly one
ball. Show that for large n, this is approximately e−n√
2πn.
15.
Set up the uniform sample spaces for the problem of putting 2 particles in 3 boxes:
for Maxwell-Boltzmann particles, for Fermi-Dirac particles, and for Bose-Einstein
particles. See Example 5. (You should ﬁnd 9 sample points for MB, 3 for FD, and
6 for BE.)
16.
Do Problem 15 for 2 particles in 2 boxes. Using the model discussed in Example 5,
ﬁnd the probability of each of the three sample points in the Bose-Einstein case.
(You should ﬁnd that each has probability 1
3, that is, they are equally probable.)
17.
Find the number of ways of putting 2 particles in 4 boxes according to the three
kinds of statistics.

744
Probability and Statistics
Chapter 15
18.
Find the number of ways of putting 3 particles in 5 boxes according to the three
kinds of statistics.
19.
(a)
Following the methods of Examples 3, 4, and 5, show that the number of
equally likely ways of putting N particles in n boxes, n > N, is nN for Maxwell-
Boltzmann particles, C(n, N) for Fermi-Dirac particles, and C(n −1 + N, N)
for Bose-Einstein particles.
(b)
Show that if n is much larger than N (think , for example, of n = 106, N = 10),
then both the Bose-Einstein and the Fermi-Dirac results in part (a) contain
products of N numbers, each number approximately equal to n. Thus show
that for n ≫N, both the BE and the FD results are approximately equal to
nN/N!, which is 1/N! times the MB result.
20.
(a)
In Example 5, a mathematical model is discussed which claims to give a dis-
tribution of identical balls into boxes in such a way that all distinguishable
arrangements are equally probable (Bose-Einstein statistics).
Prove this by
showing that the probability of a distribution of N balls into n boxes (accord-
ing to this model) with N1 balls in the ﬁrst box, N2 in the second, · · · , Nn in
the nth, is 1/C(n−1+N, N) for any set of numbers Ni such that Pn
i=1 Ni = N.
(b)
Show that the model in (a) leads to Maxwell-Boltzmann statistics if the drawn
card is replaced (but no extra card added) and to Fermi-Dirac statistics if the
drawn card is not replaced. Hint: Calculate in each case the number of possible
arrangements of the balls in the boxes. First do the problem of 4 particles in
6 boxes as in the example, and then do N particles in n boxes (n > N) to get
the results in Problem 19.
21.
The following problem arises in quantum mechanics (see Chapter 13, Problem 7.21).
Find the number of ordered triples of nonnegative integers a, b, c whose sum a+b+c
is a given positive integer n. (For example, if n = 2, we could have (a, b, c) = (2, 0, 0)
or (0, 2, 0) or (0, 0, 2) or (0, 1, 1) or (1, 0, 1) or (1, 1, 0).) Hint: Show that this
is the same as the number of distinguishable distributions of n identical balls in 3
boxes, and follow the method of the diagram in Example 5.
22.
Suppose 13 people want to schedule a regular meeting one evening a week. What
is the probability that there is an evening when everyone is free if each person is
already busy one evening a week?
23.
Do Problem 22 if one person is busy 3 evenings, one is busy 2 evenings, two are each
busy one evening, and the rest are free every evening.
5. RANDOM VARIABLES
In the problem of tossing two dice (Example 2, Section 2), we may be more interested
in the value of the sum of the numbers on the two dice than we are in the individual
numbers. Let us call this sum x; then for each point of the sample space in (2.4), x
has a value. For example, for the point 2,1, we have x = 2+1 = 3; for the point 6,2,
we have x = 8, etc. Such a variable, x, which has a deﬁnite value for each sample
point, is called a random variable. We can easily construct many more examples
of random variables for the sample space (2.4); here are a few (Can you construct

Section 5
Random Variables
745
some more?):
x = number on ﬁrst die minus number on second;
x = number on second die;
x = probability p associated with the sample point;
x =

1 if the sum is 7 or 11,
0 otherwise.
For each of these random variables x, we could set up a table listing all the sample
points in (2.4) and, next to each sample point, the corresponding value of x. This
table may remind you of the tables of values we could use in plotting the graph
of a function.
In analytical geometry or in a physics problem, knowing x as a
function of t means that for any given t we can ﬁnd the corresponding value of x.
In probability the sample point corresponds to the independent variable t; given
the sample point, we can ﬁnd the corresponding value of the random variable x if
we are given a description of x (for example, x = the sum of numbers on dice). The
“description” corresponds to the formula x(t) that we use in plotting a graph in
analytic geometry. Thus we may say that a random variable x is a function deﬁned
on a sample space.
Probability Functions
Let us consider further the random variable x = “sum
of numbers on dice” for a toss of two dice [sample space (2.4)]. We note that there
are several sample points for which x = 5, namely the points marked a in (2.4).
Similarly, there are several sample points for most of the other values of x. It is then
convenient to lump together all the sample points corresponding to a given value
of x, and consider a new sample space in which each point corresponds to one value
of x; this is the sample space (2.5). The probability associated with each point
of the new sample space is obtained as in Section 2, by adding the probabilities
associated with all the points in the original sample space corresponding to the
particular value of x. Each value of x, say xi, has a probability pi of occurrence;
we may write pi = f(xi) = probability that x = xi, and call the function f(x) the
probability function for the random variable x. In (2.5) we have listed on the ﬁrst
line the values of x and on the second line the values of f(x). [In this problem, x
and f(x) take on only a ﬁnite number of discrete values; in some later problems
they will take on a continuous set of values.] We could also exhibit these values
graphically (Figure 5.1).
Figure 5.1

746
Probability and Statistics
Chapter 15
Now that we have the table of values (2.5) or the graph (Figure 5.1) to describe
the random variable x and its probability function f(x), we can dispense with the
original sample space (2.4). But since we used (2.4) in deﬁning what is meant by
a random variable, let us now give another deﬁnition using (2.5) or Figure 5.1. We
can say that x is a random variable if it takes various values xi with probabilities
pi = f(xi). This deﬁnition may explain the name random variable; x is called a
variable since it takes various values. A random (or stochastic) process is one whose
outcome is not known in advance. The way the two dice fall is such an unknown
outcome, so the value of x is unknown in advance, and we call x a random variable.
You may note that at ﬁrst we thought of x as a dependent variable or function
with the sample point as the independent variable. Although we didn’t say much
about it, there was also a value of the probability p attached to each sample point,
that is p and x were both functions of the sample point. In the last paragraph, we
have thought of x as an independent variable with p as a function of x. This is
quite analogous to having both x and p given as functions of t and eliminating t
to obtain p as a function of x. We have here eliminated the sample point from
the forefront of our discussion in order to consider directly the probability function
p = f(x).
Example 1.
Let x = number of heads when three coins are tossed. The uniform sample
space is (2.3) and we could write the value of x for each sample point in (2.3).
Instead, let us go immediately to a table of x and p = f(x). [Can you verify this
table by using (2.3), or otherwise?]
(5.1)
x
0
1
2
3
p = f(x)
1
8
3
8
3
8
1
8
Other terms used for the probability function p = f(x) are: probability density
function, frequency function, or probability distribution (caution: not distribution
function, which means the cumulative distribution as we will discuss later; see Fig-
ure 5.2). The origins of these terms will become clearer as we go on (Sections 6
and 7) but we can get some idea of the terms frequency and distribution from (5.1).
Suppose we toss three coins repeatedly; we might reasonably expect to get three
heads in about 1
8 of the tosses, two heads in about 3
8 of the tosses, etc. That is,
each value of p = f(x) is proportional to the frequency of occurrence of that value
of x—hence the term frequency function (see also Section 7). Again in (5.1), imag-
ine four boxes labeled x = 0, 1, 2, 3, and put a marble into the appropriate box for
each toss of three coins. Then p = f(x) indicates approximately how the marbles
are distributed into the boxes after many tosses—hence the term distribution.
Mean Value; Standard Deviation
The probability function f(x) of a ran-
dom variable x gives us detailed information about it, but for many purposes we
want a simpler description. Suppose, for example, that x represents experimental
measurements of the length of a rod, and that we have a large number N of mea-
surements xi. We might reasonably take pi = f(xi) proportional to the number of
times Ni we obtained the value xi, that is pi = Ni/N. We are especially interested
in two numbers, namely a mean or average value of all our measurements, and some
number which indicates how widely the original set of values spreads out about that
average. Let us deﬁne two such quantities which are customarily used to describe a
random variable. To calculate the average of a set of N numbers, we add them and

Section 5
Random Variables
747
divide by N. Instead of adding the large number of measurements, we can multiply
each measurement by the number of times it occurs and add the results. This gives
for the average of the measurements, the value
1
N ·

i
Nixi =

i
pixi.
By analogy with this calculation, we now deﬁne the average or mean value µ of a
random variable x whose probability function is f(x) by the equation
(5.2)
µ = average of x =

i
xipi =

i
xif(xi).
To obtain a measure of the spread or dispersion of our measurements, we might
ﬁrst list how much each measurement diﬀers from the average.
Some of these
deviations are positive and some are negative; if we average them, we get zero
(Problem 10). Instead, let us square each deviation and average the squares. We
deﬁne the variance of a random variable x by the equation
(5.3)
Var(x) =

i
(xi −µ)2f(xi).
(The variance is sometimes called the dispersion.) If nearly all the measurements xi
are very close to µ, then Var(x) is small; if the measurements are widely spread,
Var(x) is large. Thus we have a number which indicates the spread of the mea-
surements; this is what we wanted. The square root of Var(x), called the standard
deviation of x, is often used instead of Var(x):
(5.4)
σx = standard deviation of x =

Var(x).
Example 2.
For the data in (5.1) we can compute:
By (5.2), µ = average of x = 0 · 1
8 + 1 · 3
8 + 2 · 3
8 + 3 · 1
8 = 12
8 = 3
2.
By (5.3), Var(x) =

0 −3
2
2 · 1
8 +

1 −3
2
2 · 3
8 +

2 −3
2
2 · 3
8 +

3 −3
2
2 · 1
8
= 9
4 · 1
8 + 1
4 · 3
8 + 1
4 · 3
8 + 9
4 · 1
8 = 3
4.
By (5.4), σx = standard deviation of x =

Var(x) = 1
2
√
3.
The mean or average value of a random variable x is also called its expectation
or its expected value or (especially in quantum mechanics) its expectation value.
Instead of µ, the symbols x or E(x) or ⟨x⟩may be used to denote the mean value
of x.

748
Probability and Statistics
Chapter 15
(5.5)
x = E(x) = ⟨x⟩= µ =

i
xif(xi).
The term expectation comes from games of chance.
Example 3.
Suppose you will be paid $5 if a die shows a 5, $2 if it shows a 2 or a 3,
and nothing otherwise. Let x represent your gain in playing the game. Then the
possible values of x and the corresponding probabilities are x = 5 with p = 1
6, x = 2
with p = 1
3, and x = 0 with p = 1
2. We ﬁnd for the average or expectation of x:
E(x) =

xipi = $5 · 1
6 + $2 · 1
3 + $0 · 1
2 = $1.50.
If you play the game many times, this is a reasonable estimate of your average gain
per game; this is what your expectation means. It is also a reasonable amount to
pay as a fee for each game you play. The term expected value (which means the same
as expectation or average) may be somewhat confusing and misleading if you try to
interpret “expected” in an everyday sense. Note that the expected value ($1.50) of x
is not one of the possible values of x, so you cannot ever “expect” to have x = $1.50.
If you think of expected value as a technical term meaning the same as average,
then there is no diﬃculty. Of course, in some cases, it makes reasonable sense with
its everyday meaning; for example, if a coin is tossed n times, the expected number
of heads is n/2 (Problem 11) and it is true that we may reasonably “expect” a fair
approximation to this result (see Section 7).
Cumulative Distribution Functions
So far we have been using the probability
function f(x) which gives the probability pi = f(xi) that x is exactly xi. In some
problems we may be more interested in the probability that x is less than some
particular value. For example, in an election we would like to know the probability
that less than half the votes would be cast for the opposing candidate, that is, that
our candidate would win. In an experiment on radioactivity, we would like to know
the probability that the background radiation always remains below a certain level.
Given the probability function f(x), we can obtain the probability that x is less
than or equal to a certain value xi by adding all the probabilities of values of x less
than or equal to xi. For example, consider the sum of the numbers on two dice; the
probability function p = f(x) is plotted in Figure 5.1. The probability that x is,
say, less than or equal to 4 is the sum of the probabilities that x is 2 or 3 or 4, that
is,
1
36 +
2
36 +
3
36 = 1
6. Similarly, we could ﬁnd the probability that x is less than
or equal to any given number. The resulting function of x is plotted in Figure 5.2.
Such a function F(x) is called a cumulative distribution function; we can write
(5.6)
F(xi) = (probability that x ≤xi) =

xj≤xi
f(xj).
Note carefully that, although the probability function f(x) may be referred to as a
probability distribution, the term distribution function means the cumulative distri-
bution F(x).

Section 5
Random Variables
749
Figure 5.2
PROBLEMS, SECTION 5
Set up sample spaces for Problems 1 to 7 and list next to each sample point the value of
the indicated random variable x, and the probability associated with the sample point.
Make a table of the diﬀerent values xi of x and the corresponding probabilities pi = f(xi).
Compute the mean, the variance, and the standard deviation for x. Find and plot the
cumulative distribution function F(x).
1.
Three coins are tossed; x = number of heads minus number of tails.
2.
Two dice are thrown; x = sum of the numbers on the dice.
3.
A coin is tossed repeatedly; x = number of the toss at which a head ﬁrst appears.
4.
Suppose that Martian dice are 4-sided (tetrahedra) with points labeled 1 to 4. When
a pair of these dice is tossed, let x be the product of the two numbers at the tops of
the dice if the product is odd; otherwise x = 0.
5.
A random variable x takes the values 0, 1, 2, 3, with probabilities
5
12, 1
3,
1
12, 1
6.
6.
A card is drawn from a shuﬄed deck. Let x = 10 if it is an ace or a face card;
x = −1 if it is a 2; and x = 0 otherwise.
7.
A weighted coin with probability p of coming down heads is tossed three times; x =
number of heads minus number of tails.
8.
Would you pay $10 per throw of two dice if you were to receive a number of dollars
equal to the product of the numbers on the dice? Hint: What is your expectation?
If it is more than $10, then the game would be favorable for you.
9.
Show that the expectation of the sum of two random variables deﬁned over the
same sample space is the sum of the expectations. Hint: Let p1, p2, · · · , pn be the
probabilities associated with the n sample points; let x1, x2, · · · , xn, and y1, y2,
· · · , yn, be the values of the random variables x and y for the n sample points. Write
out E(x), E(y), and E(x + y).
10.
Let µ be the average of the random variable x. Then the quantities (xi −µ) are the
deviations of x from its average. Show that the average of these deviations is zero.
Hint: Remember that the sum of all the pi must equal 1.
11.
Show that the expected number of heads in a single toss of a coin is 1
2. Show in two
ways that the expected number of heads in two tosses of a coin is 1:
(a)
Let x = number of heads in two tosses and ﬁnd x.
(b)
Let x = number of heads in toss 1 and y = number of heads in toss 2; ﬁnd the
average of x + y by Problem 9. Use this method to show that the expected
number of heads in n tosses of a coin is 1
2n.

750
Probability and Statistics
Chapter 15
12.
Use Problem 9 to ﬁnd the expected value of the sum of the numbers on the dice in
Problem 2.
13.
Show that adding a constant K to a random variable increases the average by K
but does not change the variance. Show that multiplying a random variable by K
multiplies both the average and the standard deviation by K.
14.
As in Problem 11, show that the expected number of 5’s in n tosses of a die is n/6.
15.
Use Problem 9 to ﬁnd x in Problem 7.
16.
Show that σ2 = E(x2) −µ2. Hint: Write the deﬁnition of σ2 from (5.3) and (5.4)
and use Problems 9 and 13.
17.
Use Problem 16 to ﬁnd σ in Problems 2, 6, and 7.
6. CONTINUOUS DISTRIBUTIONS
In Section 5, we discussed random variables x which took a discrete set of values xi.
It is not hard to think of cases in which a random variable takes a continuous set
of values.
Example 1.
Consider a particle moving back and forth along the x axis from x = 0 to
x = l, rebounding elastically at the turning points so that its speed is constant.
(This could be a simple-minded model of an alpha particle in a radioactive nucleus,
or of a gas molecule bouncing back and forth between the walls of a container.) Let
the position x of the particle be the random variable; then x takes a continuous set
of values from x = 0 to x = l. Now suppose that, following Section 5, we ask for
the probability that the particle is at a particular point x; this probability must be
the same, say k, for all points (because the speed is constant). In Section 5, with a
ﬁnite number of points, we would say k = 1/N. In the continuous case, there are
an inﬁnite number of points so we would ﬁnd k = 0, that is, the probability that
the particle is at a given point) must be zero. But this is not a very useful result.
Let us instead divide (0, l) into small intervals dx; since the particle has constant
speed, the time it spends in each dx is proportional to the length of dx. In fact,
since the particle spends the fraction (dx)/l of its time in a given interval dx, the
probability of ﬁnding it in dx is just (dx)/l.
Figure 6.1

Section 6
Continuous Distributions
751
Comparison of Discrete and Continuous Probability Functions
To see
how to deﬁne a probability function for the continuous case and to correlate this
discussion with the discrete case, let us return for a moment to Figure 5.1. There
we plotted a vertical distance to represent the probability p = f(x) of each value
of x. Instead of a dot (as in Figure 5.1) to indicate p for each x, let us now draw a
horizontal line segment of length 1 centered on each dot, as in Figure 6.1. Then the
area under the horizontal line segment at a particular xi is f(xi) · 1 = f(xi) = pi
(since the length of each horizontal line segment is 1), and we could use this area
instead of the ordinate as a measure of the probability. Such a graph is called a
histogram.
Example 2.
Now let us apply this area idea to Example 1. Consider Figure 6.2. We have
plotted the function
f(x) =
 1/l,
0 < x < l,
0,
x < 0
and
x > l.
Figure 6.2
If we consider any interval x to x+dx
on (0, l), the area under the curve f(x) =
1/l for this interval is (1/l) dx or f(x) dx,
and this is just the probability that the
particle is in this interval.
The proba-
bility that the particle is in some longer
subinterval of (0, l), say (a, b), is (b −a)/l
or
 b
a f(x) dx, that is, the area under the
curve from a to b. If the interval (a, b) is
outside (0, l), then
 b
a f(x) dx = 0 since f(x) is zero, and again this is the correct
value of the probability of ﬁnding the particle on the given interval.
When f(x) is constant over an interval (as in Figure 6.2), we say that x is
uniformly distributed on that interval. Let us consider an example in which f(x)
is not constant.
Example3.
This time suppose the particle of Example 1 is sliding up and down an inclined
plane (no friction) rebounding elastically (no energy loss) against a spring at the
bottom and reaching zero speed at height y = h (Figure 6.3). The total energy,
namely 1
2mv2 + mgy is constant and equal to mgh since v = 0 at y = h. Thus we
have
(6.1)
v2 = 2
m(mgh −mgy) = 2g(h −y).
The probability of ﬁnding the particle within an interval dy at a given height y
is proportional to the time dt spent in that interval. From v = ds/dt, we have
dt = (ds)/v; from Figure 6.3, we ﬁnd ds = (dy) csc α. Combining these with (6.1)
we have
dt = ds
v =
(dy) csc α
√2g√h −y
Since the probability f(y) dy of ﬁnding the particle in the interval dy at height y
is proportional to dt, we can drop the constant factor (csc α)/√2g, and say that

752
Probability and Statistics
Chapter 15
Figure 6.3
f(y) dy is proportional to dy/√h −y. In order to ﬁnd f(y), we must multiply by a
constant factor which makes the total probability
 h
0 f(y) dy equal to 1 since this is
the probability that the particle is somewhere. You can easily verify that
f(y) dy =
1
2
√
h
dy
√h −y
or
f(y) =
1
2

h(h −y)
A graph of f(y) is plotted in Figure 6.4. Note that although f(y) becomes inﬁnite
at y = h, the area under the f(y) curve for any interval is ﬁnite; this area represents
the probability that the particle is in that height interval.
Figure 6.4
We can now extend the deﬁnitions of mean (expectation), variance, standard
deviation, and cumulative distribution function to the continuous case. Let f(x) be
a probability density function; remember that
 ∞
−∞f(x) dx = 1 just as 	n
i=1 pi = 1.
The average of a random variable x with probability density function f(x) is
(6.2)
µ = x = E(x) = ⟨x⟩=

 ∞
−∞
xf(x) dx.
(In writing the limits −∞, ∞here, we assume that f(x) is deﬁned to be zero on
intervals where the probability is zero.) Note that (6.2) is a natural extension of

Section 6
Continuous Distributions
753
the sum in (5.5). Having found the mean of x, we now deﬁne the variance as in
Section 5 as the average of (x −µ)2, that is,
(6.3)
Var(x) =

 ∞
−∞
(x −µ)2f(x) dx = σ2
x.
As before, the standard deviation σx is the square root of the variance. Finally,
the cumulative distribution function F(x) gives for each x the probability that the
random variable is less than or equal to that x. But this probability is just the area
under the f(x) curve from −∞up to the point x. Also, of course, the integral of
f(x) from −∞to ∞must = 1 since that is the total probability for all values of x.
Thus we have
(6.4)
F(x) =

 x
−∞
f(u) du,

 ∞
−∞
f(x) dx = F(∞) = 1.
Example 4.
For the problem in Example 3, we ﬁnd:
By (6.2), µy =

 h
0
yf(y) dy =
1
2
√
h

 h
0
y
1
√h −y dy = 2
3h.
By (6.3), Var(y) =

 h
0
(y −µy)2f(y) dy =

 h
0

y −2
3h
2
1
√h −y dy = 4h2
45 ,
so standard deviation σy =

Var(y) = 2h/
√
45.
By (6.4), cumulative distribution function F(y) =

 y
0
f(u) du
=
1
2
√
h

 y
0
du
√
h −u.
Why “density function”?
In Section 5, we mentioned that the probability func-
tion f(x) is often called the probability density. We can now explain why. Con-
sider (6.2). If f(x) represents the density (mass per unit length) of a thin rod, then
the center of mass of the rod is given by [see Chapter 5, (3.3)]
(6.5)
x =

xf(x) dx
 
f(x) dx,
where the integrals are over the length of the rod, or from −∞to ∞as in (6.2)
with f(x) = 0 outside the rod. But in (6.2),

f(x) dx is the total probability that
x has some value, and so this integral is equal to 1. Then (6.5) and (6.2) are really
the same; we see that it is reasonable to call f(x) a density, and also that the mean
of x corresponds to the center of mass of a linear mass distribution of density f(x).
In a similar way, we can interpret (6.3) as giving the moment of inertia of the mass
distribution about the center of mass (see Chapter 5, Section 3).

754
Probability and Statistics
Chapter 15
Joint Distributions
We can easily generalize the ideas and formulas above to
two (or more) dimensions. Suppose we have two random variables x and y; we
deﬁne their joint probability density function f(x, y) so that f(xi, yj) dx dy is the
probability that the point (x, y) is in an element of area dx dy at x = xi, y = yj.
Then the probability that the point (x, y) is in a given region of the (x, y) plane, is
the integral of f(x, y) over that area. The average or expected values of x and y,
the variances and standard deviations of x and y, and the covariance of x, y (see
Problems 13 to 16) are given by
(6.6)
x =

 ∞
−∞

 ∞
−∞
xf(x, y) dx dy,
y =

 ∞
−∞

 ∞
−∞
yf(x, y) dx dy,
Var(x) =

 ∞
−∞

 ∞
−∞
(x −x)2f(x, y) dx dy = σ2
x,
Var(y) =

 ∞
−∞

 ∞
−∞
(y −y)2f(x, y) dx dy = σ2
y,
Cov(x, y) =

 ∞
−∞

 ∞
−∞
(x −x)(y −y)f(x, y) dx dy.
You should see that these are generalizations of (6.2) and (6.3); that (6.6) can be
interpreted as giving the coordinates of the center of mass and the moments of
inertia of a two-dimensional mass distribution; and that similar formulas can be
written for three (or more) random variables (that is, in three or more dimensions).
Also note that the formulas in (6.6) could be written in terms of polar coordinates
(see Problems 6 to 9).
We have discussed a number of probability distributions both discrete and con-
tinuous, and you will ﬁnd others in the problems. We will discuss three very impor-
tant named distributions (binomial, normal, and Poisson) in the following sections.
Learning about these and related graphs, formulas, and terminology should make
it possible for you to cope with any of the many other named distributions you ﬁnd
in texts, reference books, and computer programs.
PROBLEMS, SECTION 6
1.
(a)
Find the probability density function f(x) for the position x of a particle
which is executing simple harmonic motion on (−a, a) along the x axis. (See
Chapter 7, Section 2, for a discussion of simple harmonic motion.) Hint: The
value of x at time t is x = a cos ωt. Find the velocity dx/dt; then the probability
of ﬁnding the particle in a given dx is proportional to the time it spends there
which is inversely proportional to its speed there. Don’t forget that the total
probability of ﬁnding the particle somewhere must be 1.
(b)
Sketch the probability density function f(x) found in part (a) and also the
cumulative distribution function F(x) [see equation (6.4)].
(c)
Find the average and the standard deviation of x in part (a).
2.
It is shown in the kinetic theory of gases that the probability for the distance a
molecule travels between collisions to be between x and x + dx, is proportional to
e−x/λ dx, where λ is a constant. Show that the average distance between collisions
(called the “mean free path”) is λ. Find the probability of a free path of length ≥2λ.

Section 6
Continuous Distributions
755
3.
A ball is thrown straight up and falls straight back down.
Find the probability
density function f(h) so that f(h) dh is the probability of ﬁnding it between height
h and h + dh. Hint: Look at Example 3.
4.
In Problem 1 we found the probability density function for a classical harmonic
oscillator. In quantum mechanics, the probability density function for a harmonic
oscillator (in the ground state) is proportional to e−α2x2, where α is a constant and
x takes values from −∞to ∞. Find f(x) and the average and standard deviation
of x. (In quantum mechanics, the standard deviation of x is called the uncertainty
in position and is written ∆x.)
5.
The probability for a radioactive particle to decay between time t and time t + dt is
proportional to e−λt. Find the density function f(t) and the cumulative distribution
function F(t). Find the expected lifetime (called the mean life) of the radioactive
particle. Compare the mean life and the so-called “half life” which is deﬁned as the
value of t when e−λt = 1/2.
6.
A circular garden bed of radius 1 m is to be planted so that N seeds are uniformly
distributed over the circular area. Then we can talk about the number n of seeds in
some particular area A, or we can call n/N the probability for any one particular
seed to be in the area A.
Find the probability F(r) that a seed (that is, some
particular seed) is within r of the center. (Hint: What is F(1)?) Find f(r) dr, the
probability for a seed to be between r and r + dr from the center. Find r and σ.
7.
(a)
Repeat Problem 6 where the “circular” area is now on the curved surface of the
earth, say all points at distance s from Chicago (measured along a great circle
on the earth’s surface) with s ≤πR/3 where R = radius of the earth. The
seeds could be replaced by, say, radioactive fallout particles (assuming these to
be uniformly distributed over the surface of the earth). Find F(s) and f(s).
(b)
Also ﬁnd F(s) and f(s) if s ≤1 ≪R (say s ≤1 mile where R = 4000 miles).
Do your answers then reduce to those in Problem 6?
8.
Given that a particle is inside a sphere of radius 1, and that it has equal probabilities
of being found in any two volume elements of the same size, ﬁnd the cumulative
distribution function F(r) for the spherical coordinate r, and from it ﬁnd the density
function f(r). Hint: F(r) is the probability that the particle is inside a sphere of
radius r. Find r and σ.
9.
A hydrogen atom consists of a proton and an electron. According to the Bohr theory,
the electron revolves about the proton in a circle of radius a (a = 5 · 10−9cm for
the ground state). According to quantum mechanics, the electron may be at any
distance r (from 0 to ∞) from the proton; for the ground state, the probability that
the electron is in a volume element dV , at a distance r to r + dr from the proton,
is proportional to e−2r/adV , where a is the Bohr radius.
Write dV in spherical
coordinates (see Chapter 5, Section 4) and ﬁnd the density function f(r) so that
f(r) dr is the probability that the electron is at a distance between r and r + dr
from the proton. (Remember that the probability for the electron to be somewhere
must be 1.) Computer plot f(r) and show that its maximum value is at r = a; we
then say that the most probable value of r is a. Also show that the average value
of r−1 is a−1.
10.
Do Problem 5.10 for a continuous distribution.
11.
Do Problem 5.13 for a continuous distribution.
12.
Do Problem 5.16 for a continuous distribution.
13.
Given a joint distribution function f(x, y) as in (6.6), show that E(x + y) = E(x) +
E(y) and Var(x + y) = Var(x) + Var(y) + 2 Cov(x, y).

756
Probability and Statistics
Chapter 15
14.
Recall that two events A and B are called independent if p(AB) = p(A)p(B). Sim-
ilarly two random variables x and y are called independent if the joint probability
function f(x, y) = g(x)h(y). Show that if x and y are independent, then the expec-
tation or average of xy is E(xy) = E(x)E(y) = µxµy.
15.
Show that the covariance of two independent (see Problem 14) random variables is
zero, and so by Problem 13, the variance of the sum of two independent random
variables is equal to the sum of their variances.
16.
By Problem 15, if x and y are independent, then Cov(x, y) = 0.
The converse
is not always true, that is, if Cov(x, y) = 0, it is not necessarily true that the
joint distribution function is of the form f(x, y) = g(x)h(y). For example, suppose
f(x, y) = (3y2 + cos x)/4 on the rectangle −π/2 < x < π/2, −1 < y < 1, and
f(x, y) = 0 elsewhere. Show that Cov(x, y) = 0, but x and y are not independent,
that is, f(x, y) is not of the form g(x)h(y). Can you construct some more examples?
7. BINOMIAL DISTRIBUTION
Example 1.
Let a coin be tossed 5 times; what is the probability of exactly 3 heads out of
the 5 tosses? We can represent any sequence of 5 tosses by a symbol such as thhth.
The probability of this particular sequence (or any other particular sequence) is
( 1
2)5 since the tosses are independent (see Example 1 of Section 3). The number of
such sequences containing 3 heads and 2 tails is the number of ways we can select 3
positions out of 5 for heads (or 2 for tails), namely C(5, 3). Hence, the probability
of exactly 3 heads in 5 tosses of a coin is C(5, 3)( 1
2)5. Suppose a coin is tossed
repeatedly, say n times; let x be the number of heads in the n tosses. We want to
ﬁnd the probability density function p = f(x) which gives the probability of exactly
x heads in n tosses. By generalizing the case of 3 heads in 5 tosses, we see that
(7.1)
f(x) = C(n, x)( 1
2)n
Example 2.
Let us do a similar problem with a die, asking this time for the probability of
exactly 3 aces in 5 tosses of the die. If A means ace and N not ace, the probability
of a particular sequence such as ANNAA is 1
6 · 5
6 · 5
6 · 1
6 · 1
6 since the probability of
A is 1
6, the probability of N is 5
6, and the tosses are independent. The number of
such sequences containing 3 A’s and 2 N’s is C(5, 3); thus the probability of exactly
3 aces in 5 tosses of a die is C(5, 3)( 1
6)3( 5
6)2. Generalizing this, we ﬁnd that the
probability of exactly x aces in n tosses of a die is
(7.2)
f(x) = C(n, x)( 1
6)x( 5
6)n−x.
Bernoulli Trials
In the two examples we have just done, we have been concerned
with repeated independent trials, each trial having two possible outcomes (h or t,
A or N) of given probability. There are many examples of such problems; let’s
consider a few. A manufactured item is good or defective; given the probability
of a defect we want the probability of x defectives out of n items. An archer has
probability p of hitting a target; we ask for the probability of x hits out of n tries.
Each atom of a radioactive substance has probability p of emitting an alpha particle
during the next minute; we are to ﬁnd the probability that x alpha particles will be
emitted in the next minute from the n atoms in the sample. A particle moves back
and forth along the x axis in unit jumps; it has, at each step, equal probabilities of

Section 7
Binomial Distribution
757
Figure 7.1
Figure 7.2
Figure 7.3
jumping forward or backward. (This motion is called a random walk; it can be used
as a model of a diﬀusion process.) We want to know the probability that, after n
jumps, the particle is at a distance
d = number x of positive jumps −number (n −x) of negative jumps,
from its starting point; this probability is the probability of x positive jumps out of
a total of n jumps.
In all these problems, something is tried repeatedly. At each trial there are two
possible outcomes of probabilities p (usually called the probability of “success”) and
Figure 7.4
Figure 7.5

758
Probability and Statistics
Chapter 15
q = 1 −p (where q = probability of “failure”). Such repeated independent trials
with constant probabilities p and q are called Bernoulli trials.
Binomial Probability Functions
Let us generalize (7.1) and (7.2) to obtain a
formula which applies to any similar problem, namely the probability f(x) of exactly
x successes in n Bernoulli trials. Reasoning as we did to obtain (7.1) and (7.2), we
ﬁnd that
(7.3)
f(x) = C(n, x)pxqn−x.
We might also ask for the probability of not more than x successes in n trials. This
is the sum of the probabilities of 0, 1, 2, · · · , x successes, that is, it is the cumula-
tive distribution function F(x) for the random variable x whose probability density
function is (7.3) [see (5.6)]. We can write
(7.4)
F(x) = f(0) + f(1) + · · · + f(x)
= C(n, 0)p0qn + C(n, 1)p1qn−1 + · · · + C(n, x)pxqn−x
=
x

u=0
C(n, u)puqn−u =
x

u=0
n
u

puqn−u.
Observe that (7.3) is one term of the binomial expansion of (p + q)n and (7.4)
is a sum of several terms of this expansion (see Section 4, Example 2). For this
reason, the functions f(x) in (7.1), (7.2), or (7.3) are called binomial probability (or
density) functions or binomial distributions, and the function F(x) in (7.4) is called
a binomial cumulative distribution function.
We shall ﬁnd it very useful to computer plot graphs of the binomial density
function f(x) for various values of p and n. (See Figures 7.1 to 7.5 and Problems 1
to 8.) Instead of a point at y = f(x) for each x, we plot a horizontal line segment of
length 1 centered on each x as in Figure 6.1; the probabilities are then represented
by areas under the broken line, rather than by ordinates. From Figures 7.1 to 7.3
and similar graphs, we can draw a number of conclusions. The most probable value
of x [corresponding to the largest value of f(x)] is approximately x = np (Problems
10 and 11); for example for p = 1
2, the most probable value of x is 1
2n for even n;
for odd n, there are two consecutive values of x, namely 1
2(n ± 1), for which the
probability is largest. The graphs for p = 1
2 are symmetric about x = 1
2n. For
p ̸= 1
2, the curve is asymmetric, favoring small x values for small p and large x
values for large p. As n increases, the graph of f(x) becomes wider and ﬂatter (the
total area under the graph must remain 1). The probability of the most probable
value of x decreases with n. For example, the most probable number of heads in
8 tosses of a coin is 4 with probability 0.27; the most probable number of heads
in 20 tosses is 10 with probability 0.17; for 106 tosses, the probability of exactly
500,000 heads is less than 10−3.
Let us redraw Figures 7.1 and 7.2 plotting nf(x) against the relative number of
successes x/n (Figures 7.4 and 7.5). Since this change of scale (ordinate times n,
abscissa divided by n) leaves the area unchanged, we can still use the area to
represent probability. Note that now the curves become narrower and taller as n

Section 7
Binomial Distribution
759
increases. This means that values of the ratio x/n tend to cluster about their most
probable value, namely np/n = p. For example, if we toss a coin repeatedly, the
diﬀerence “number of heads −1
2 number of tosses” is apt to be large and to increase
with n (Figures 7.1 and 7.2), but the ratio “number of heads ÷ number of tosses”
is apt to be closer and closer to 1
2 as n increases (Figures 7.4 and 7.5). It is for this
reason that we can use experimentally determined values of x/n as a reasonable
estimate of p.
Chebyshev’s Inequality
This is a simple but very general result which we will
ﬁnd useful. We consider a random variable x with probability function f(x), and
let µ be the mean value and σ the standard deviation of x. We are going to prove
that if we select any number t, the probability that x diﬀers from its mean value µ
by more than t, is less than σ2/t2. This means that x is unlikely to diﬀer from µ
by more than a few standard deviations; for example, if t is twice the standard
deviation σ, we ﬁnd that the probability for x to diﬀer from µ by more than 2σ is
less than σ2/t2 = σ2/(2σ)2 = 1
4. The proof is simple. By deﬁnition of σ, we have
σ2 =

(x −µ)2f(x)
where the sum is over all x. Then if we sum just over the values of x for which
|x −µ| ≥t, we get less than σ2:
(7.5)
σ2 >

|x−µ|≥t
(x −µ)2f(x).
If we replace each x −µ by the number t in (7.5), the sum is decreased, so we have
(7.6)
σ2 >

|x−µ|≥t
t2f(x) = t2

|x−µ|≥t
f(x)
or

|x−µ|≥t
f(x) < σ2
t2 .
But 	
|x−µ|≥t f(x) is just the sum of all probabilities of x values which diﬀer from µ
by more than t, and (7.6) says that this probability is less than σ2/t2, as we claimed.
Laws of Large Numbers
Statements and proofs which make more precise our
general comments about the eﬀect of large n are known as laws of large numbers.
Let us state and prove one such law. We apply Chebyshev’s inequality to a ran-
dom variable whose probability function is the binomial distribution (7.3). From
Problems 9 and 13 we have µ = np and σ = √npq. Then by Chebyshev’s inequality,
(7.7)
(probability of |x −np| ≥t)
is less than
npq/t2.
Let us choose the arbitrary value of t in (7.7) proportional to n, that is, t = nϵ
where ϵ is now arbitrary. Then (7.7) becomes
(7.8)
(probability of |x −np| ≥nϵ)
is less than
npq/n2ϵ2,
or, when we divide the ﬁrst inequality by n,
(7.9)

probability of
x
n −p
 ≥ϵ

is less than
pq
nϵ2 .

760
Probability and Statistics
Chapter 15
Recall that x/n is the relative number of successes; we intuitively expect x/n to be
near p for large n. Now (7.9) says that, if ϵ is any small number, the probability is
less than pq/(nϵ2) for x/n to diﬀer from p by ϵ; that is, as n tends to inﬁnity, this
probability tends to zero. (Note, however, that x/n need not tend to p.) This is
one form of the law of large numbers and it justiﬁes our intuitive ideas.
PROBLEMS, SECTION 7
For the values of n indicated in Problems 1 to 4:
(a) Write the probability density function f(x) for the probability of x heads in n tosses
of a coin and computer plot a graph of f(x) as in Figures 7.1 and 7.2. Also computer
plot a graph of the corresponding cumulative distribution function F(x).
(b) Computer plot a graph of nf(x) as a function of x/n as in Figures 7.4 and 7.5.
(c) Use your graphs and other calculations if necessary to answer these questions: What
is the probability of exactly 7 heads? Of at most 7 heads? [Hint: Consider F(x).] Of
at least 7 heads? What is the most probable number of heads? The expected number
of heads?
1.
n = 7
2.
n = 12
3.
n = 15
4.
n = 18
5.
Write the formula for the binomial density function f(x) for the case n = 6, p = 1/6,
representing the probability of, say, x aces in 6 throws of a die. Computer plot f(x)
as in Figure (7.3). Also plot the cumulative distribution function F(x). What is
the probability of at least 2 aces out of 6 tosses of a die? Hint: Can you read the
probability of at most one ace from one of your graphs?
For the given values of n and p in Problems 6 to 8, computer plot graphs of the binomial
density function for the probability of x successes in n Bernoulli trials with probability p
of success.
6.
n = 6, p = 5/6 (Compare Problem 5)
7.
n = 50, p = 1/5
8.
n = 50, p = 4/5
9.
Use the second method of Problem 5.11 to show that the expected number of suc-
cesses in n Bernoulli trials with probability p of success is x = np. Hint: What is
the expected number of successes in one trial?
10.
Show that the most probable number of heads in n tosses of a coin is 1
2n for even n
[that is, f(x) in (7.1) has its largest value for x = n/2] and that for odd n, there
are two equal “largest” values of f(x), namely for x = 1
2(n + 1) and x = 1
2(n −1).
Hint: Simplify the fraction f(x + 1)/f(x), and then ﬁnd the values of x for which
it is greater than 1 [that is, f(x + 1) > f(x)], and less than or equal to 1 [that is,
f(x + 1) ≤f(x)]. Remember that x must be an integer.
11.
Use the method of Problem 10 to show that for the binomial distribution (7.3), the
most probable value of x is approximately np (actually within 1 of this value).
12.
Let x = number of heads in one toss of a coin. What are the possible values of x and
their probabilities? What is µx? Hence show that Var(x) = [average of (x −µx)2]
= 1
4, so the standard deviation is 1
2. Now use the result from Problem 6.15 “variance
of a sum of independent random variables = sum of their variances” to show that if
x = number of heads in n tosses of a coin, Var(x) = 1
4n and the standard deviation
σx = 1
2
√n.
13.
Generalize Problem 12 to show that for the general binomial distribution (7.3),
Var(x) = npq, and σ = √npq.

Section 8
The Normal or Gaussian Distribution
761
8. THE NORMAL OR GAUSSIAN DISTRIBUTION
The graph of the normal or Gaussian distribution is the bell-shaped curve you may
know as the normal error curve (Figure 8.1). The normal distribution is used a
great deal because, as we shall see, it is not only of interest in itself (see Problems
2 and 3), but also other distributions become almost normal when n (the number
of trials or measurements) becomes large (see Figures 8.2 and 8.3).
The probability density function f(x) and the cumulative distribution function
F(x) for the normal or Gaussian distribution are given by
(8.1)
f(x) =
1
σ
√
2π e−(x−µ)2/(2σ2),
F(x) =
1
σ
√
2π

 x
−∞
e−(t−µ)2/(2σ2) dt.
Normal distribution
It is straightforward to show (Problem 1) that if x is a random variable with prob-
ability density f(x) in (8.1), then the mean of x is µ and the standard deviation
is σ. Also we can show that the integral of f(x) from −∞to ∞is equal to 1 as it
must be for a probability function. Then the probability that a normally distributed
random variable x lies between x1 and x2 is the area under the f(x) curve between
x1 and x2 which is
(8.2)
F(x2) −F(x1) = probability that x1 ≤x ≤x2.
Figure 8.1
A normal density function graph (Figure 8.1) has its peak at x = µ and is
symmetric with respect to the line x = µ. Since the area from −∞to ∞is 1, the
area from −∞to µ is 1
2 (that is, F(µ) = 1
2), and similarly the area from µ to ∞is 1
2.
A change in µ merely translates the graph with no change in shape. An increase in
σ widens and ﬂattens the graph so that the area remains 1, and similarly a decrease
in σ makes the graph taller and narrower. (Problems 4 to 6). The area from µ −σ
to µ + σ is 0.6827, that is, the probability that x diﬀers from its mean value by
1 standard deviation or less, is just over 68%. The probability that |x −µ| ≤2σ

762
Probability and Statistics
Chapter 15
is over 95% and the probability that |x −µ| ≤3σ is over 99.7%. Note that these
probabilities are independent of the values of µ and σ (Problem 7).
Normal Approximation to the Binomial Distribution
As an example of
approximating another distribution by a normal distribution, let’s consider the bi-
nomial distribution (7.3). For large n and large np, we can use Stirling’s formula
(Chapter 11, Section 11) to approximate the factorials in C(n, x) in (7.3) and make
other approximations to ﬁnd
(8.3)
f(x) = C(n, x)pxqn−x ∼
1
√2πnpq e−(x−np)2/(2npq).
Figure 8.2
Binomial distribution for n = 8
n = 8
n = 8, p = 1
2
p = 1
2
p = 1
2,
and the normal approximation.
The sign ∼means (as in Chapter 11, Section 11) that the ratio of the exact binomial
distribution (7.3) and the right-hand side of (8.3) tends to 1 as n →∞. An outline
of a derivation of (8.3) is given in Problem 8, but you may be more impressed by
doing some computer plotting of graphs like Figures 8.2 and 8.3 (Problems 9 and 10).
Although we have said that equation (8.3) gives an approximation valid for large n,
the agreement is quite good even for fairly small values of n. Figure 8.2 shows this
for the case n = 8. The binomial distribution f(x) is deﬁned only for integral x;
you should compare the values of f(x) with the values of the approximating normal
curve at integral values of x. When n is very large (Figure 8.3), a graph of the exact
binomial distribution is very close to the normal approximation (Problem 9).
Figure 8.3
Binomial distribution for n = 100
n = 100
n = 100, p = 1
2
p = 1
2
p = 1
2.
In (8.3), the left-hand side is the exact binomial distribution and the right-
hand side is a normal distribution with µ = np and σ = √npq as we see by
comparing (8.3) and (8.1). Recall from Problems 7.9 and 7.13 that the mean value

Section 8
The Normal or Gaussian Distribution
763
µ and standard deviation σ for a random variable whose probability function is the
binomial distribution (7.3) are also µ = np and σ = √npq.
For the binomial distribution and its normal approximation,
µ = np,
σ = √npq .
(8.4)
We can expect this in general; whatever the µ and σ are for a given distribution,
the normal approximation will have the same µ and σ.
Example 1.
Find the probability of exactly 52 heads in 100 tosses of a coin using the
binomial distribution and using the normal approximation.
See Figure (8.3) which is a plot of the binomial probability density function with
n = 100, p = 1
2. We ﬁnd by computer for x = 52, binomial f(52) = 0.07353, which
you could also read approximately from Figure (8.3).
For the normal approximation, we ﬁnd from (8.4), µ = np = 100 · 1
2 = 50,
σ = √npq =

100 · 1
2 · 1
2 = 5. Then for the normal approximation with µ = 50,
σ = 5, we ﬁnd by computer for x = 52, normal f(52) = 0.07365.
Example 2.
Find the probability P(45, 55) of between 45 and 55 heads in 100 tosses of a
coin, that is 45 ≤x ≤55.
As in Example 1, for the binomial distribution we have n = 100, p = 1
2. The
cumulative binomial distribution function F(x) in (7.4) gives P(45, 55) as a sum of
terms; we want the sum of the 11 terms with x = 45, 46, · · ·55. By computer, we
can ﬁnd F(55), the binomial cumulative distribution function with x = 55, which is
the probability of 55 heads or less, and then ﬁnd and subtract F(44), the probability
of 44 heads or less. Thus we ﬁnd P(45, 55) = binomial F(55) −binomial F(44) =
0.72875.
For the normal approximation, we ﬁnd by computer from (8.2), P(45, 55) =
normal F(55) −normal F(45) = 0.68269. We can get a better approximation by
integrating from 44.5 to 55.5; this corresponds more closely to the appropriate area
under the exact binomial graph in Figure 8.3 by including the whole steps at x = 45
and x = 55. This gives P(44.5, 55.5) = normal F(55.5)−normal F(44.5) = 0.72867.
Standard Normal Distribution
This is just the normal distribution in (8.1)
for the special case µ = 0 and σ = 1. The density function is often denoted by φ(z),
and the corresponding cumulative distribution function by Φ(z):
φ(z) =
1
√
2π e−z2/2,
Φ(z) =
1
√
2π

 z
−∞
e−u2/2 du.
Standard normal distribution
(8.5)
The cumulative distribution function Φ(z) is related to the error function (see Chap-
ter 11, Section 9).

764
Probability and Statistics
Chapter 15
It is sometimes convenient to write the functions in (8.1) in terms of φ(z) and
Φ(z). We can do this by making the change of variables z = (x −µ)/σ. The result
is (Problem 21)
f(x) = 1
σ φ(z),
F(x) = Φ(z),
where z = (x −µ)
σ
.
(8.6)
The functions φ(z) and Φ(z) [or sometimes Φ(z) −1
2] are tabulated so you can use
either tables or computer to do problems.
Example 3.
Find the number r such that the area under the normal distribution curve
y = f(x) from µ −r to µ + r is equal to 1/2.
Look at Figure 8.1 and recall that the area from −∞to ∞is 1 and that the
graph is symmetric about x = µ. Then the integral from −∞to µ −r and the
integral from µ + r to ∞are equal to each other and so each is equal to 1/4. Thus
the integral from −∞to µ + r must be 3/4, that is F(µ + r) = 3/4. By (8.6) this
is Φ(z) = 3/4 where z = (µ + r −µ)/σ = r/σ. By computer or tables we ﬁnd that
if Φ(z) = 3/4, then z = 0.6745. Thus r = 0.6745σ.
Example 4.
You have taken a test (academic like the SAT, or medical like a bone density
test) and a report gives your z-score as 1.14. What percent of your peers scored
higher than you?
If we call the actual test scores x, and their average is µ and standard deviation σ,
then the term z-score means the value of z = (x−µ)/σ as in (8.6). (In words, the z-
score is the diﬀerence between x and its average, measured in units of the standard
deviation.) Now we want the area 1 −F(x) = 1 −Φ(z) by (8.6). By computer (or
tables) we ﬁnd Φ(1.14) = 0.87; then 1 −0.87 = 0.13, so 13% of your peers scored
higher than you. If your z-score is negative, then you are below average—bad if
it’s a physics test, good if it’s your cholesterol! For example, if z = −0.25, then
Φ(z) = 0.40, so 60% of your peers scored higher than you.
Example 5.
Suppose that boxes of a certain kind of cereal have an average weight of 16
ounces and it is known that 70% of the boxes weigh within 1 ounce of the average.
What is the probability that the box you buy weighs less than 14 ounces?
If x represents the weight of a box, then we are given that the probability of
15 < x < 17 is 0.7. Assuming a normal distribution, the area under the f(x) curve
up to x = µ = 16 is 1
2 and the area from x = 16 to x = 17 is half of 0.7 (by symmetry;
see Figure 8.1). Thus F(17) = 0.5 + 0.35 = 0.85. We want to ﬁnd the probability
that x < 14; this is F(14). Using (8.6), x = 17 gives z = (17 −16)/σ = 1/σ, and
similarly x = 14 gives z = −2/σ. So we are given Φ(1/σ) = 0.85, and we want
to ﬁnd Φ(−2/σ). By computer (or tables) we ﬁnd that if Φ(1/σ) = 0.85, then
1/σ = 1.0364, so 2/σ = 2.0728, and Φ(−2/σ) = 0.019. So there is almost a 2%
chance that we would get a box weighing less than 14 ounces.
Note that in Examples 4 and 5 we assumed a normal distribution with no obvious
justiﬁcation. It is a very interesting and useful fact that such an assumption is

Section 8
The Normal or Gaussian Distribution
765
reasonable if the number of measurements is very large. We will discuss this further
at the end of Section 10.
PROBLEMS, SECTION 8
1.
Verify that for a random variable x with normal density function f(x) as in (8.1),
the mean value of x is µ , the standard deviation is σ, and the integral of f(x) from
−∞to ∞is 1 as it must be for a probability function. Hint: Write and evaluate
the integrals
R ∞
−∞f(x) dx,
R ∞
−∞xf(x) dx,
R ∞
−∞(x −µ)2f(x) dx. See equations (6.2),
(6.3), and (6.4).
2.
Do Problem 6.4 by comparing e−ax2 with f(x) in (8.1).
3.
The probability density function for the x component of the velocity of a molecule
of an ideal gas is proportional to e−mv2/(2kT ) where v is the x component of the
velocity, m is the mass of the molecule, T is the temperature of the gas and k is
the Boltzmann constant. By comparing this with (8.1), ﬁnd the mean and standard
deviation of v, and write the probability density function f(v).
4.
Computer plot on the same axes the normal probability density functions with µ = 0,
σ = 1, and with µ = 3, σ = 1 to note that they are identical except for a translation.
5.
Computer plot on the same axes the normal density functions with µ = 0 and σ = 1,
2, and 5. Label each curve with its σ.
6.
Do Problem 5 for σ = 1
6, 1
3, 1.
7.
By computer ﬁnd the value of the normal cumulative distribution function at µ+ σ,
µ + 2σ, µ + 3σ, and satisfy yourself that these are independent of your choices for
µ and σ. Find the probabilities that x is within 1, 2, or 3 standard deviations of
its mean value µ to verify the results stated in the paragraph following (8.2). Hint:
See Figure (8.1). The probability that x is within 1 standard deviation of its mean
value is the area from µ−σ to µ+σ; this is twice the area from µ to µ+σ. Subtract
1
2 (that is the area from −∞to µ) from your value of F(µ + σ) and then double the
result.
8.
Carry through the following details of a derivation of (8.3). Start with (7.3); we want
an approximation to (7.3) for large n. First approximate the factorials in C(n, x)
by Stirling’s formula (Chapter 11, Section 11) and simplify to get
f(x) ∼
„np
x
«x„
nq
n −x
«n−xr
n
2πx(n −x).
Show that if δ = x−np, then x = np+δ and n−x = nq−δ. Make these substitutions
for x and n −x in the approximate f(x). To evaluate the ﬁrst two factors in f(x)
(ignore the square root for now): Take the logarithm of the ﬁrst two factors; show
that
ln np
x = −ln
„
1 + δ
np
«
and a similar formula for ln[nq/(n −x)]; expand the logarithms in a series of powers
of δ/(np), collect terms and simplify to get
ln
„np
x
«x„ nq
n −x
«n−x
∼−δ2
2npq
„
1 + powers of δ
n
«
.
Hence
„np
x
«x„
nq
n −x
«n−x
∼e−δ2/(2npq)

766
Probability and Statistics
Chapter 15
for large n. [We really want δ/n small, that is, x near enough to its average value np
so that δ/n = (x −np)/n is small. This means that our approximation is valid for
the central part of the graph (see Figures 7.1 to 7.3) around x = np where f(x) is
large. Since f(x) is negligibly small anyway for x far from np, we ignore the fact
that our approximation may not be good there. For more detail on this point, see
Feller, p. 192]. Returning to the square root factor in f(x), approximate x by np
and n −x by nq (assuming δ ≪np or nq) and obtain (8.3).
9.
Computer plot a graph like Figure 8.3 of the binomial distribution with n = 1000,
p = 1
2, and observe that you have practically the corresponding normal approxima-
tion.
10.
Computer plot graphs like Figure 8.2 but with p ̸= 1
2 to see that as n increases, the
normal approximation becomes good (at least in the region around x = µ where
the probabilities are large) even though the binomial graph is not symmetric (see
Figure 7.3).
As in Examples 1 and 2, use (a) the binomial distribution; (b) the corresponding normal
approximation, to ﬁnd the probabilities of each of the following:
11.
Exactly 50 heads in 100 tosses of a coin.
12.
Exactly 120 aces in 720 tosses of a die.
13.
Between 100 and 140 aces in 720 tosses of a die.
14.
Between 499,000 and 501,000 heads in 106 tosses of a coin.
15.
Exactly 195 tails in 400 tosses of a coin.
16.
Between 195 and 205 tails in 400 tosses of a coin.
17.
Exactly 31 4’s in 180 tosses of a die.
18.
Between 29 and 33 4’s in 180 tosses of a die.
19.
Exactly 21 successes in 100 Bernoulli trials with probability 1
5 of success.
20.
Between 17 and 21 successes in 100 Bernoulli trials with probability 1
5 of success.
21.
Verify equations (8.6). Hints: In F(x), let u = (t −µ)/σ; note that dt = σdu. What
is u when t = −∞? When t = x? Remember that by deﬁnition z = (x −µ)/σ.
22.
Using (8.6), do Problem 7.
23.
Using (8.6), ﬁnd h such that 90% of the area under a normal f(x) lies between µ−h
and µ + h. Repeat for 95%. Hint: See Example 3.
24.
Write out a proof of Chebyshev’s inequality (see end of Section 7) for the case of a
continuous probability function f(x).
25.
An instructor who grades “on the curve” computes the mean and standard deviation
of the grades, and then, assuming a normal distribution with this µ and σ, sets the
border lines between the grades at: C from µ −1
2σ to µ + 1
2σ, B from µ + 1
2σ to
µ + 3
2σ, A from µ + 3
2σ up, etc. Find the percentages of the students receiving
the various grades. Where should the border lines be set to give the percentages:
A and F, 10%; B and D, 20%; C, 40%?

Section 9
The Poisson Distribution
767
9. THE POISSON DISTRIBUTION
The Poisson distribution is useful in a variety of problems in which the probability
of some occurrence is small and constant. (See Example 1 and Problems 3 to 9.) It
is also a good approximation to the binomial distribution when p is so small that
np is small even though n is large (see Example 2).
Let’s derive the Poisson distribution by considering the following experiment.
Suppose we observe and count the number of particles emitted per unit time by a
radioactive substance. We assume that our period of observation is much less than
the half-life of the substance, so that the average counting rate does not decrease
during the experiment. Then the probability that one particle is emitted during a
small time interval ∆t is µ∆t, µ =const., if ∆t is short enough so that the probability
of two particles during ∆t is negligible. We want to ﬁnd the probability Pn(t) of
observing exactly n counts during a time interval t. The probability Pn(t + ∆t) is
the probability of observing n counts in the time interval t + ∆t. For n > 0, this is
the sum of the probabilities of the two mutually exclusive events, “n particles in t,
none in ∆t” and “(n −1) particles in t, one in ∆t”; in symbols,
(9.1)
Pn(t + ∆t) = Pn(t)P0(∆t) + Pn−1(t)P1(∆t).
Now P1(∆t) is the probability of one particle in ∆t; this, by assumption, is µ∆t.
Then the probability of no particles in ∆t is 1 −P1(∆t) = 1 −µ∆t. Substituting
these values into (9.1), we get
(9.2)
Pn(t + ∆t) = Pn(t)(1 −µ∆t) + Pn−1(t)µ∆t,
or,
(9.3)
Pn(t + ∆t) −Pn(t)
∆t
= µPn−1(t) −µPn(t).
Letting ∆t →0, we have
(9.4)
dPn(t)
dt
= µPn−1(t) −µPn(t).
For n = 0, (9.1) simpliﬁes since the only possible event is “no particles in t, no
particles in ∆t,” and (9.4) becomes, for n = 0,
(9.5)
dP0(t)
dt
= −µP0(t).
Then, since P0(0) = “probability that no particle is emitted during a zero time
interval” = 1, integration of (9.5) gives
(9.6)
P0 = e−µt.
Substituting (9.6) into (9.4) with n = 1 gives a diﬀerential equation for P1(t); its
solution (Problem 1) is P1(t) = µte−µt. Solving (9.4) successively (Problem 1) for
P2, P3, · · · , Pn, we obtain
(9.7)
Pn(t) = (µt)n
n!
e−µt.

768
Probability and Statistics
Chapter 15
Putting t = 1, we get for the probability of exactly n counts per unit time
(9.8)
Pn = µn
n! e−µ.
Poisson distribution
The probability density function (9.8) is called the Poisson distribution or the Pois-
son probability density function. You can show (Problem 2) that for the random
variable n, the mean (that is the average number of counts per unit time) is µ, and
the variance is also µ so the standard deviation is √µ.
Example 1.
The number of particles emitted each minute by a radioactive source is
recorded for a period of 10 hours; a total of 1800 counts are registered. During
how many 1-minute intervals should we expect to observe no particles; exactly one;
etc.?
The average number of counts per minute is 1800/(10·60) = 3 counts per minute;
this is the value of µ. Then by (9.8), the probability of n counts per minute is
Pn = 3n
n! e−3.
A graph of this probability function is shown in Figure 9.1. For n = 0, we ﬁnd
P0 = e−3 = 0.05; then we should expect to observe no particles in about 5% of
the 600 1-minute intervals, that is, during 30 1-minute intervals. Similarly we could
compute the expected number of 1-minute intervals during which 1, 2, · · · , particles
would be observed.
Figure 9.1
Poisson distribution µ = 3
µ = 3
µ = 3.
Poisson Approximation of the Binomial Distribution
In Section 8, we dis-
cussed the fact that the binomial distribution can be approximated by the normal
distribution for large n and large np. If p is very small so that np is very much less
than n (say, for example, p = 10−3, n = 2000, np = 2), the normal approximation
is not good. In this case you can show (Problem 10) that the Poisson distribution
gives a good approximation to the binomial distribution (7.3), that is, that

Section 9
The Poisson Distribution
769
(9.9)
C(n, x)pxqn−x ∼(np)xe−np
x!
,
Large n, small p.
[The exact meaning of (9.9) is that, for any ﬁxed x, the ratio of the two sides ap-
proaches 1 as n →∞and p →0 with np remaining constant.]
Example 2.
If 1500 people each select a number at random between 1 and 500, what is
the probability that 2 people selected the number 29?
The answer is given by the binomial distribution (7.3) with n = 1500, p = 1/500,
x = 2. This is
C(n, x)pxqn−x = 1500!
2!1498!
 1
500
2499
500
998
= 0.2241.
(Or from your computer: the binomial probability density function with n = 1500,
p = 1/500, x = 2, is 0.2241 to four decimal places.). A simpler formula from (9.9) is
the Poisson approximation with µ = np = 3, x = 2, namely µxe−x/x! = 32e−2/2! =
0.2240.
(Or from your computer, the Poisson probability density function with
µ = 3, x = 2, is 0.2240 to four decimal places.) It is interesting to computer plot on
the same axes the binomial distribution with n = 1500, p = 1/500, and the Poisson
distribution with µ = 3 as in Figure 9.1 to discover that they are almost identical
(Problem 12).
Approximations by the Normal Distribution
We have commented that many
distributions can be approximated by the normal distribution when n and µ = np
are both large, and have shown this for the binomial distribution in (8.1). The
Poisson distribution when µ is large is also fairly well approximated by the normal
distribution as in (9.10).
(9.10)
µxe−µ
x!
∼=
1
√2πµe−(x−µ)2/(2µ),
µ large.
Note that the normal distribution in (9.10) has the same mean and variance as the
Poisson distribution it is approximating (see Problem 2 for the Poisson mean and
variance). It is useful to computer plot on the same axes graphs of the Poisson
distribution and their normal approximations (Problem 13).
PROBLEMS, SECTION 9
1.
Solve the sequence of diﬀerential equations (9.4) for successive n values [as started
in (9.5) and (9.6)] to obtain (9.7).
2.
Show that the average value of a random variable n whose probability function is
the Poisson distribution (9.8) is the number µ in (9.8). Also show that the standard
deviation of the random variable is √µ.
Hint:
Write the inﬁnite series for ex,
diﬀerentiate it and multiply by x to get xex = P(nxn/n!); put x = µ. To ﬁnd σ2
diﬀerentiate the xex series again, etc.

770
Probability and Statistics
Chapter 15
3.
In an alpha-particle counting experiment the number of alpha particles is recorded
each minute for 50 hours.
The total number of particles is 6000.
In how many
1-minute intervals would you expect no particles? Exactly n particles, for n = 1, 2,
3, 4, 5? Plot the Poisson distribution.
4.
Suppose you receive an average of 4 phone calls per day. What is the probability
that on a given day you receive no phone calls? Just one call? Exactly 4 calls?
5.
Suppose that you have 5 exams during the 5 days of exam week. Find the probability
that on a given day you have no exams; just 1 exam; 2 exams; 3 exams.
6.
If you receive, on the average, 5 email messages per day, in how many days out
of a 365-day year would you expect to receive exactly 5 messages? Fewer than 5?
Exactly 10? More than 10? Just 1? None at all?
7.
In a club with 500 members, what is the probability that exactly two people have
birthdays on July 4?
8.
If there are 100 misprints in a magazine of 40 pages, on how many pages would you
expect to ﬁnd no misprints? Two misprints? Five misprints?
9.
If there are, on the average, 7 defects in a new car, what is the probability that your
new car has only 2 defects? That it has 6 or 7? That it has more than 10?
10.
Derive equation (9.9) as follows: In C(n, x), show that n!/(n −x)! ∼nx for ﬁxed x
and large n [write n!/(n −x)! as a product of x factors, divide by nx, and show that
the limit is 1 as n →∞]. Then write qn−x = (1 −p)n−x as (1 −p)n(1 −p)−x =
(1 −np/n)n(1 −p)−x; evaluate the limit of the ﬁrst factor as n →∞, np ﬁxed; the
limit of the second factor as p →0 is 1. Collect your results to obtain equation (9.9).
11.
Suppose 520 people each have a shuﬄed deck of cards and draw one card from
the deck. What is the probability that exactly 13 of the 520 cards will be aces of
spades? Write the binomial formula and approximate it. Which is best, the normal
or the Poisson approximation? Although you only need values at one x to answer
the question, you might like to computer plot on the same axes graphs of the three
distributions for the given n and p.
12.
Computer plot on the same axes graphs of the binomial distribution in Example 2
and the Poisson and normal approximations.
13.
Computer plot on the same axes a graph of the Poisson distribution and the corre-
sponding normal approximation for the cases µ = 1, 5, 10, 20, 30.
10. STATISTICS AND EXPERIMENTAL MEASUREMENTS
Statistics uses probability theory to consider sets of data and draw reasonable con-
clusions from them. So far in this chapter, we have been discussing problems for
which we could write down a density function formula (normal, Poisson, etc.).
Suppose that, instead, we have only a table of data, say a set of laboratory mea-
surements of some physical quantity. Presumably, if we spent more time, we could
enlarge this table of data as much as we liked. We can then imagine an inﬁnite
set of measurements of which we have only a sample. The inﬁnite set is called the
parent population or universe. What we would really like to know is the probability
function for the parent population, or at least the average value µ (often thought of
as the “true” value of the quantity being measured) and the standard deviation σ of
the parent population. We must content ourselves with the best estimates we can
make of these quantities using our available sample, that is, the set of measurements
which we have made.

Section 10
Statistics and Experimental Measurements
771
Estimate of Population Average
As a quick estimate of µ we might take the
median of our measurements xi (a value such that there are equal numbers of larger
and smaller measurements), or the mode (the measurement we obtained the most
times, that is the most probable measurement). The most frequently used estimate
of µ is, however, the arithmetic mean (or average) of the measurements, that is the
sample mean x = (1/n) 	n
i=1 xi. Thus we have
(10.1)
Estimate of population mean is µ ≃x = (1/n)
n

i=1
xi.
For a large set of measurements we can justify this choice as follows (also see Prob-
lem 1). Assuming that the parent population for our measurements has probability
density function f(x) with expected value µ and standard deviation σ, it is easy
to show (Problem 2) that the expected value of x is µ and the standard deviation
of x is σ/√n. Now Chebyshev’s inequality (end of Section 7) says that a random
variable is unlikely to diﬀer from its expected value by more than a few standard
deviations. For our problem this says that x is unlikely to diﬀer from µ by more
than a few multiples of σ/√n, which becomes small as n increases. Thus x becomes
an increasingly good estimate of µ as we increase the number n of measurements.
Note that this just says mathematically what you would assume from experience,
that the average of a large number of measurements is more likely to be accurate
than the average of a small number. For example, two measurements might both
be too large, but it’s unlikely that 20 would all be too large.
Estimate of Population Variance
Our ﬁrst guess for an estimate of σ2 might
be s2 = (1/n) 	n
i=1(xi −x)2, but we would be wrong. To see what is reasonable, we
ﬁnd the expected value of s2 assuming that our measurements are from a population
with mean µ and variance σ2. The result is (Problem 3), E(s2) = [(n −1)/n]σ2.
We conclude that a reasonable estimate of σ2 is
n
n−1s2.
(10.2)
Estimate of population variance is σ2 ≃
1
n −1
n

i=1
(xi −x)2.
(Caution: The term “sample variance” is used in various references—texts, refer-
ence books, computer programs—to mean either our s2 or our estimate of σ2, so
check the deﬁnition carefully in any reference you use. We shall avoid using the
term.)
The quantity σ which we have just estimated is the standard deviation for the
parent population whose probability function we call f(x). Consider just a single
measurement x. The function f(x) (if we knew it) would give us the probabilities of
the diﬀerent possible values of x, the population mean µ would tell us approximately
the value we are apt to ﬁnd for x, and the standard deviation σ would tell us
roughly the spread of x values about µ. Since σ tells us something about a single
measurement, it is often called the standard deviation of a single measurement.

772
Probability and Statistics
Chapter 15
Standard Deviation of the Mean; Standard Error
Instead of a single mea-
surement, let us consider x, the average (mean) of a set of n measurements. (The
mean, x, will be what we will use or report as the result of an experiment.) Just as
we originally imagined obtaining the probability function f(x) by making a large
number of single measurements, so we can imagine obtaining a probability function
g(x) by making a large number of sets of n measurements with each set giving us
a value of x. The function g(x) (if we knew it) would give us the probability of
diﬀerent values of x. We have seen (Problem 2) that Var(x) = σ2/n, so the standard
deviation of the mean (that is, of x) is
(10.3)
σm =

Var(x) = σ
√n.
The quantity σm is also called the standard error; it gives us an estimate of the
spread of values of x about µ. We see that the new probability function g(x) must
be much more peaked than f(x) about the value µ because the standard deviation
σ/√n is much smaller than σ. Collecting formulas (10.2) and (10.3), we have
(10.4)
σm ∼=
	n
i=1(xi −x)2
n(n −1)
Example 1.
To illustrate our discussion, let’s consider the following set of measurements:
{7.2, 7.1, 6.7, 7.0, 6.8, 7.0, 6.9, 7.4, 7.0, 6.9}. [Note that, to show methods but
minimize computation, we consider unrealistically small sets of measurements.]
From (10.1) we ﬁnd
µ ≃x = 1
10
10

i=1
xi = 70
10 = 7.0.
From (10.2) we ﬁnd
σ2 ≃1
9
10

i=1
(xi −7)2 = 0.36
9
= 0.04, σ ≃0.2.
From (10.4), the standard error is
σm ≃

0.36
10 · 9 = 0.0632.
Combination of Measurements
We have discussed how we can use a set of
measurements xi to estimate µ (the population average) by x (the sample average)
and to estimate the standard error σmx =

Var(x) [equation (10.4)]. Now suppose
we have done this for two quantities, x and y, and we want to use a known formula
w = w(x, y) to estimate a value for w and the standard error in w. First we consider
the simple example w = x + y. Then, by Problem 6.13,
(10.5)
E(w) = E(x) + E(y) = µx + µy
where µx and µy are population averages. As discussed above, we estimate µx
and µy by x and y and conclude that a reasonable estimate of w is
(10.6)
w = x + y.

Section 10
Statistics and Experimental Measurements
773
Now let us assume that x and y are independently measured quantities. Then by
Problem 6.15,
Var(w) = Var(x) + Var(y) = σ2
mx + σ2
my,
σmw =

σ2mx + σ2my.
(10.7)
Next consider the case w = 4 −2x + 3y. As in equations (10.5) and (10.6), we
ﬁnd w = 4 −2x + 3y. Now by Problem 5.13, we have Var(x + K) = Var(x), and
Var(Kx) = K2 Var(x), where K is a constant. Thus,
Var(w) = Var(4 −2x + 3y) = Var(−2x + 3y)
(10.8)
= (−2)2 Var(x) + (3)2 Var(y) = 4σ2
mx + 9σ2
my,
σmw =

4σ2mx + 9σ2my.
(10.9)
We can now see how to ﬁnd w and σmw for any function w(x, y) which can
be approximated by the linear terms of its Taylor series about the point (µx, µy),
namely (see Chapter 4, Section 2)
(10.10)
w(x, y) ∼= w(µx, µy) +
∂w
∂x

(x −µx) +
∂w
∂y

(y −µy)
where the partial derivatives are evaluated at x = µx, y = µy, and so are constants.
[Practically speaking, this means that the ﬁrst partial derivatives should not be
near zero—we can’t expect good results near a maximum or minimum of w—and
the higher derivatives should not be large, that is, w should be “smooth” near the
point (µx, µy).] Assuming (10.10), and remembering that w(µx, µy) and the partial
derivatives are constants, we ﬁnd
E[w(x, y)] ∼= w(µx, µy) +
∂w
∂x

[E(x) −µx] +
∂w
∂y

[E(y) −µy]
(10.11)
= w(µx, µy).
Since we have agreed to estimate µx and µy by x and y, we conclude that a reason-
able estimate of w is
(10.12)
w = w(x, y).
(This may look obvious, but see Problem 7.)
Then, putting x = x, y = y in (10.10) and remembering the comment just before
(10.11), we ﬁnd as in (10.8)
Var(w) = Var[w(x, y)]
= Var

w(µx, µy) +
∂w
∂x

(x −µx) +
∂w
∂y

(y −µy)

=
∂w
∂x
2
σ2
mx +
∂w
∂y
2
σ2
my,
σmw =
∂w
∂x
2
σ2mx +
∂w
∂y
2
σ2my.
(10.13)
We can use (10.12) and (10.13) to estimate the value of a given function w of two
measured quantities x and y and to ﬁnd the standard error in w.

774
Probability and Statistics
Chapter 15
Example 2.
From Example 1 we have x = 7 and σmx = 0.0632. Suppose we have also
found from measurements that y = 5 and σmy = 0.0591. If w = x/y, ﬁnd w and
σmw. From (10.12) we have w = x/y = 7/5 = 1.4. From (10.13) we ﬁnd
σmw =
1
y
2
σ2mx +
−x
y2
2
σ2my =
1
5
2
(0.0632)2 +
−7
25
2
(0.0591)2
= 0.0208.
Central Limit Theorem
So far we have not assumed any special form (such
as normal, etc.) for the density function f(x) of the parent population, so that
our results for computation of approximate values of µ, σ, and σm from a set of
measurements apply whether or not the parent distribution is normal. (And, in
fact, it may not be; for example, Poisson distributions are quite common.) You
will ﬁnd, however, that most discussions of experimental errors are based on an
assumed normal distribution. Let us discuss the justiﬁcation for this. We have
seen above that we can think of the sample average x as a random variable with
average µ and standard deviation σ/√n. We have said that we might think of a
density function g(x) for x and that it would be more strongly peaked about µ than
the density function f(x) for a single measurement, but we have not said anything
so far about the form of g(x). There is a basic theorem in probability (which we
shall quote without proof) which gives us some information about the probability
function for x.
The central limit theorem says that no matter what the parent
probability function f(x) is (provided µ and σ exist), the probability function for
x is approximately the normal distribution with standard deviation σ/√n if n is
large.
Conﬁdence Intervals, Probable Error
If we assume that the probability func-
tion for x is normal (a reasonable assumption if n is large), then we can give a more
speciﬁc meaning to σm (standard deviation of the mean) than our vague statement
that it gives us an estimate of the spread of x values about µ. Since the probability
for a normally distributed random variable to have values between µ −σ and µ + σ
is 0.6827 (see Section 8 and Problem 8.7), we can say that the probability is about
68% for a measurement of x to lie between µ −σm and µ + σm. This interval is
called the 68% conﬁdence interval. Similarly we can ﬁnd an interval µ ± r such
that the probability is 1
2 that a new measurement would fall in this interval (and
so also the probability is 1
2 that it would fall outside!), that is, a 50% conﬁdence
interval. From Section 8, Example 3, this is r = 0.6745σm. The number r is called
the probable error. When we have found σm as in Examples 1 and 2, we just have
to multiply it by 0.6745 to ﬁnd the corresponding probable error. Similarly we can
ﬁnd the error corresponding to other choices of conﬁdence interval (see Problem 4).
PROBLEMS, SECTION 10
1.
Let m1, m2, · · · , mn be a set of measurements, and deﬁne the values of xi by x1 =
m1 −a, x2 = m2 −a, · · · , xn = mn −a, where a is some number (as yet unspeciﬁed,
but the same for all xi). Show that in order to minimize Pn
i=1 x2
i , we should choose
a = (1/n) Pn
i=1 mi. Hint: Diﬀerentiate Pn
i=1 x2
i with respect to a. You have shown
that the arithmetic mean is the “best” average in the least squares sense, that is,
that if the sum of the squares of the deviations of the measurements from their

Section 10
Statistics and Experimental Measurements
775
“average” is a minimum, the “average” is the arithmetic mean (rather than, say, the
median or mode).
2.
Let x1, x2, · · · , xn be independent random variables, each with density function f(x),
expected value µ, and variance σ2. Deﬁne the sample mean by x = Pn
i=1 xi. Show
that E(x) = µ, and Var(x) = σ2/n. (See Problems 5.9, 5.13, and 6.15.)
3.
Deﬁne s by the equation s2 = (1/n) Pn
i=1(xi −x)2. Show that the expected value
of s2 is [(n −1)/n]σ2. Hints: Write
(xi −x)2 = [(xi −µ) −(x −µ)]2
= (xi −µ)2 −2(xi −µ)(x −µ) + (x −µ)2.
Find the average value of the ﬁrst term from the deﬁnition of σ2 and the average
value of the third term from Problem 2. To ﬁnd the average value of the middle
term write
(x −µ) =
„x1 + x2 + · · · + xn
n
−µ
«
= 1
n[(x1 −µ) + (x2 −µ) + · · · + (xn −µ)].
Show by Problem 6.14 that
E[(xi −µ)(xj −µ)] = E(xi −µ)E(xj −µ) = 0
for i ̸= j,
and evaluate E[(xi −µ)2] (same as the ﬁrst term). Collect terms to ﬁnd
E(s2) = n −1
n
σ2.
4.
Assuming a normal distribution, ﬁnd the limits µ ± h for a 90% conﬁdence interval;
for a 95% conﬁdence interval; for a 99% conﬁdence interval. What percent conﬁdence
interval is µ ± 1.3σ?
Hints: See Section 8, Example 3, and Problems 8.7, 8.22,
and 8.23.
5.
Show that if w = xy or w = x/y, then (10.14) gives the convenient formula for
relative error
rw
w =
s„rx
x
«2
+
„ry
y
«2
.
6.
By expanding w(x, y, z) in a three-variable power series similar to (10.10), show that
rw =
s„∂w
∂x
«2
r2x +
„∂w
∂y
«2
r2y +
„∂w
∂z
«2
r2z.
7.
Equation (10.12) is only an approximation (but usually satisfactory). Show, how-
ever, that if you keep the second order terms in (10.10), then
w = w(x, y) + 1
2
„∂2w
∂x2
«
σ2
x + 1
2
„∂2w
∂y2
«
σ2
y.
8.
The following measurements of x and y have been made.
x : 5.1, 4.9, 5.0, 5.2, 4.9, 5.0, 4.8, 5.1
y : 1.03, 1.05, 0.96, 1.00, 1.02, 0.95, 0.99, 1.01, 1.00, 0.99
Find the mean value and the probable error of x, y, x + y, xy, x3 sin y, and ln x.
Hint: See Examples 1 and 2 and the last paragraph of this section.

776
Probability and Statistics
Chapter 15
9.
Given the measurements
x : 98, 101, 102, 100, 99
y : 21.2, 20.8, 18.1, 20.3, 19.6, 20.4, 19.5, 20.1
ﬁnd the mean value and probable error of x −y, x/y, x2y3, and y ln x.
10.
Given the measurements
x : 5.8, 6.1, 6.4, 5.9, 5.7, 6.2, 5.9
y : 2.7, 3.0, 2.9, 3.3, 3.1
ﬁnd the mean value and probable error of 2x −y, y2 −x, ey, and x/y2.
11. MISCELLANEOUS PROBLEMS
1.
(a)
Suppose you have two quarters and a dime in your left pocket and two dimes
and three quarters in your right pocket. You select a pocket at random and
from it a coin at random. What is the probability that it is a dime?
(b)
Let x be the amount of money you select. Find E(x).
(c)
Suppose you selected a dime in (a). What is the probability that it came from
your right pocket?
(d)
Suppose you do not replace the dime, but select another coin which is also
a dime. What is the probability that this second coin came from your right
pocket?
2.
(a)
Suppose that Martian dice are regular tetrahedra with vertices labeled 1 to 4.
Two such dice are tossed and the sum of the numbers showing is even. Let x
be this sum. Set up the sample space for x and the associated probabilities.
(b)
Find E(x) and σx.
(c)
Find the probability of exactly ﬁfteen 2’s in 48 tosses of a Martian die using
the binomial distribution.
(d)
Approximate (c) using the normal distribution.
(e)
Approximate (c) using the Poisson distribution.
3.
There are 3 red and 2 white balls in one box and 4 red and 5 white in the second
box. You select a box at random and from it pick a ball at random. If the ball is
red, what is the probability that it came from the second box?
4.
If 4 letters are put at random into 4 envelopes, what is the probability that at least
one letter gets into the correct envelope?
5.
Two decks of cards are “matched,” that is, the order of the cards in the decks is
compared by turning the cards over one by one from the two decks simultaneously;
a “match” means that the two cards are identical. Show that the probability of at
least one match is nearly 1 −1/e.
6.
Find the number of ways of putting 2 particles in 5 boxes according to the diﬀerent
kinds of statistics.
7.
Suppose a coin is tossed three times. Let x be a random variable whose value is 1 if
the number of heads is divisible by 3, and 0 otherwise. Set up the sample space for
x and the associated probabilities. Find x and σ.

Section 11
Miscellaneous Problems
777
8.
(a)
A weighted coin has probability
2
3 of coming up heads and probability
1
3 of
coming up tails. The coin is tossed twice. Let x = number of heads. Set up
the sample space for x and the associated probabilities.
(b)
Find x and σ.
(c)
If in (a) you know that there was at least one tail, what is the probability that
both were tails?
9.
(a)
One box contains one die and another box contains two dice. You select a box
at random and take out and toss whatever is in it (that is, toss both dice if you
have picked box 2). Let x = number of 3’s showing. Set up the sample space
and associated probabilities for x.
(b)
What is the probability of at least one 3?
(c)
If at least one 3 turns up, what is the probability that you picked the ﬁrst box?
(d)
Find x and σ.
Do Problems 10 to 12 using both the binomial distribution and the normal approximation.
10.
A true coin is tossed 104 times.
(a)
Find the probability of getting exactly 5000 heads.
(b)
Find the probability of between 4900 and 5075 heads.
11.
A die is thrown 720 times.
(a)
Find the probability that 3 comes up exactly 125 times.
(b)
Find the probability that 3 comes up between 115 and 130 times.
12.
Consider a biased coin with probability 1/3 of heads and 2/3 of tails and suppose
it is tossed 450 times.
(a)
Find the probability of getting exactly 320 tails.
(b)
Find the probability of getting between 300 and 320 tails.
13.
A radioactive source emits 1800 α particles during an observation lasting 10 hours.
In how many one minute intervals do you expect no α’s? 5α’s?
14.
Suppose a 200-page book has, on the average, one misprint every 10 pages. On
about how many pages would you expect to ﬁnd 2 misprints?
In Problems 15 and 16, ﬁnd the binomial probability for the given problem, and then
compare the normal and the Poisson approximations.
15.
Out of 1095 people, what is the probability that exactly 2 were born on Jan. 1?
Assume 365 days in a year.
16.
Find the probability of x successes in 100 Bernoulli trials with probability p = 1/5
of success (a) if x = 25; (b) if x = 21.
17.
Given the measurements
x : 2.3, 2.1, 1.8, 1.7, 2.1
y : 1.0, 1.1, 0.9
ﬁnd the mean value and the probable error for x −y, xy, and x/y3.
18.
Given the measurements
x : 5.7, 4.5, 4.8, 5.1, 4.9
y : 61.5, 60.1, 59.7, 60.3, 58.4
ﬁnd the mean value and the probable error for x + y, y/x, and x2.


References
This list includes the details of references cited in the text, plus a few other books
you might ﬁnd useful.
Abramowitz, Milton, and Irene A. Stegun, editors, Handbook of Mathematical Func-
tions With Formulas, Graphs, and Mathematical Tables, National Bureau of
Standards, Applied Mathematics Series, 55, U. S. Government Printing Of-
ﬁce, Washington, D. C., 1964.
Arfken, George B., and Hans J. Weber, Mathematical Methods for Physicists, Aca-
demic Press, ﬁfth edition, 2001.
Boyce, William E., and Richard C. DiPrima, Introduction to Diﬀerential Equations,
Wiley, 1970.
Butkov, Eugene, Mathematical Physics, Addison-Wesley, 1968.
Callen, Herbert B., Thermodynamics and an Introduction to Thermostatistics, Wi-
ley, second edition, 1985.
Cantrell, C. D., Modern Mathematical Methods for Physicists and Engineers, Cam-
bridge University Press, 2000.
Chow, Tai L., Mathematical Methods for Physicists: A Concise Introduction, Cam-
bridge University Press, 2000.
Courant, Richard, and Herbert Robbins, What Is Mathematics?, Oxford University
Press, second edition revised by Ian Stewart, 1996.
CRC Standard Mathematical Tables, CRC Press, any recent edition.
Feller, William, An Introduction to Probability Theory and Its Applications, Wiley,
second edition, 1966.
Folland, G. B., Fourier analysis and its applications, Brooks/Cole, 1992.
Goldstein, Herbert, Charles P. Poole, and John L. Safko, Classical Mechanics, Ad-
dison Wesley, third edition, 2002.
Griﬃths, David J., Introduction to Electrodynamics, Prentice Hall, third edition,
1999.
Griﬃths, David J., Introduction to Quantum Mechanics, Prentice Hall, second edi-
tion, 2004.
Hassani, Sadri, Mathematical Methods: For Students of Physics and Related Fields,
Springer, 2000.
Jackson, John David, Classical Electrodynamics, Wiley, third edition, 1999.
779

780
References
Jahnke, E., and F. Emde, Tables of Higher Functions, McGraw-Hill, sixth edition
revised by Friedrich L¨osch, 1960.
Jeﬀreys, Harold, Cartesian Tensors, Cambridge University Press, 1965 reprint.
Jordan, D. W., and Peter Smith, Mathematical Techniques: An Introduction for the
Engineering, Physical, and Mathematical Sciences, Oxford University Press,
third edition, 2002.
Kittel, Charles, Elementary Statistical Physics, Dover edition, 2004.
Kreyszig, Erwin, Advanced Engineering Mathematics, Wiley, eighth edition, 1999.
Lighthill, M. J., Introduction to Fourier Analysis and Generalised Functions, Cam-
bridge University Press, 1958.
Lyons, Louis, All You Wanted To Know About Mathematics but Were Afraid To
Ask: Mathematics for Science Students, two volumes, Cambridge University
Press, 1995–1998.
Mathews, Jon, and R. L. Walker, Mathematical Methods of Physics, Benjamin,
second edition, 1970.
McQuarrie, Donald A., Mathematical Methods for Scientists and Engineers, Uni-
versity Science Books, 2003.
Morse, Philip M., and Herman Feshbach, Methods of Theoretical Physics, McGraw-
Hill, 1953.
NBS Tables. See Abramowitz and Stegun.
Parratt, Lyman G., Probability and Experimental Errors in Science, Dover edition,
1971.
Relton, F. E., Applied Bessel Functions, Dover edition, 1965.
Riley, K. F., M. P. Hobson, and S. J. Bence, Mathematical Methods for Physics and
Engineering: A Comprehensive Guide, Cambridge University Press, second
edition, 2002.
Schey, H. M., Div, Grad, Curl, and All That: An Informal Text on Vector Calculus,
Norton, fourth edition, 2004.
Snieder, Roel, A Guided Tour of Mathematical Methods for the Physical Sciences,
Cambridge University Press, second edition, 2004.
Strang, Gilbert, Linear Algebra and Its Applications, Harcourt, Brace, Jovanovich,
third edition, 1988.
Weinstock, Robert, Calculus of Variations, with Applications to Physics and Engi-
neering, Dover edition, 1974.
Weisstein, Eric W., CRC Concise Encyclopedia of Mathematics, Chapman & Hall
/CRC, second edition, 2003.
Woan, Graham, Cambridge Handbook of Physics Formulas, Cambridge University
Press, reprinted 2003 with corrections.
Young, Hugh D., Statistical Treatment of Experimental Data, McGraw-Hill, 1962.

Answers to
Selected Problems
Chapter 1
1.1
0.0173 yd; 0.104 yd (compared to a total of 5 yd)
1.3
5
9
1.5
7
12
1.9
6
7
1.11
19
28
1.15
1
2.1
1
2.4
∞
2.7
e2
2.9
1
4.2
an =
1
5n−1 →0; Sn = 5
4

1 −1
5n

→5
4; Rn =
1
4 · 5n−1 →0
4.4
an = 1
3n →0; Sn = 1
2

1 −1
3n

→1
2; Rn =
1
2 · 3n →0
4.6
an =
1
n(n + 1) →0; Sn = 1 −
1
n + 1 →1; Rn =
1
n + 1 →0
5.2
Test further
5.4
D
5.5
D
5.6
Test further
5.8
Test further
5.9
D
6.5 b D
6.7
D
6.9
C
6.10
C
6.14
D
6.18
D
6.20
C
6.22
C
6.23
D
6.24
D
6.26
C
6.29
D
6.31
D
6.32
D
6.35
C
6.36
D
7.1
C
7.2
D
7.4
C
7.6
D
7.8
C
9.2
D
9.3
C
9.7
D
9.8
C
9.9
D
9.10
D
9.12
C
9.13
C
9.15
D
9.16
C
9.20
C
9.21
C
9.22
(b) D
10.1
|x| < 1
10.3
|x| ≤1
10.4
|x| ≤
√
2
10.5
All x
10.9
|x| < 1
10.10 |x| ≤1
10.11 −5 ≤x < 5
10.13 −1 < x ≤1
10.15 −1 < x < 5
10.17 −2 < x ≤0
10.18 −3
4 ≤x ≤−1
4
10.20 All x
10.21 0 ≤x ≤1
10.22 No x
10.24 |x| < 1
2
√
5
10.25 nπ −π
6 < x < nπ + π
6
781

782
Answers to Selected Problems
Chapter 2
13.4
−1/2
0

= 1;
−1/2
n

= (−1)n(2n −1)!!
(2n)!!
13.6
∞
0
1/2
n

xn+1 (see Example 2)
13.8
∞
0
−1/2
n

(−x2)n (see Problem 13.4)
13.11
∞

0
(−1)nxn
(2n + 1)!
13.14
∞

0
x2n+1
2n + 1
13.15
∞

0
−1/2
n

(−1)n x2n+1
2n + 1
13.17 2

odd n
xn
n
13.21 x2 + 2x4/3 + 17x6/45 · · ·
13.22 1 + 2x + 5x2/2 + 8x3/3 + 65x4/24 · · ·
13.25 1 −x + x2/3 −x4/45 · · ·
13.27 1 + x + x2/2 −x4/8 −x5/15 · · ·
13.28 x −x2/2 + x3/6 −x5/12 · · ·
13.29 1 + x/2 −3x2/8 + 17x3/48 · · ·
13.34 x −x2 + x3 −13x4/12 + 5x5/4 · · ·
13.35 1 + x2/3! + 7x4/(3 · 5!) + 31x6/(3 · 7!) · · ·
13.41 e3[1 + (x −3) + (x −3)2/2! + (x −3)3/3! · · ·]
13.44 5 + (x −25)/10 −(x −25)2/103 + (x −25)3/(5 × 104) · · ·
14.8
For x < 0, error < 0.001; for x > 0, error < 0.002.
15.1
−x4/24 −x5/30 · · · ∼= −3.376 × 10−16
15.3
x5/15 −2x7/45 · · · ∼= 6.667 × 10−17
15.6
12
15.8
1/2
15.10 −1
15.12 1/3
15.14 t −t3
3 , error < 10−6
15.17 cos(π/2) = 0
15.19
√
2
15.20 (b) 5e
15.21 (b) 0.937548
15.22 (b) 1.202057
15.23 (a) 1/2
(c) 1/3
15.24 (a) −π
(d) 0
(f) 0
15.27 (a) 1 −v
c = 1.3 × 10−5, or v = 0.999987c
(d) 1 −v
c = 1.3 × 10−11
15.28 mc2 + 1
2mv2
15.29 (b) F
W = x
l + x3
2l3 + 3x5
8l5 · · ·
15.30 (b) T = 1
2
F
θ

1 + θ2
6 + 7 θ4
360 · · ·

15.31 (a) ﬁnite
(b) inﬁnite
16.6
C
16.7
D
16.9
−1 ≤x < 1
16.10 −4 < x < 4
16.13 −5 < x ≤1
16.15 −x2/6 −x4/180 −x6/2835 · · ·
16.16 1 −x/2 + 3x2/8 −11x3/48 + 19x4/128 · · ·
16.19 −(x −π) + (x −π)3/3! −(x −π)5/5! · · ·
16.20 2 + x −8
12
−(x −8)2
25 · 32
+ 5(x −8)3
28 · 34
· · ·
16.26 −1/3
16.28 1
16.31 (b) 2.66 × 1086 terms. For N = 15, 1.6905 < S < 1.6952

Chapter 2
Answers to Selected Problems
783
Chapter 2
x
y
r
θ
4.1
1
1
√
2
π/4
See Fig. 5.1
4.2
−1
1
√
2
3π/4
See Fig. 9.6
4.3
1
−
√
3
2
−π/3
4.5
0
2
2
π/2
See Fig. 5.2
4.7
−1
0
1
π
See Fig. 9.2
4.9
−2
2
2
√
2
3π/4
4.11
√
3
1
2
π/6
See Fig. 9.1
4.14
√
2
√
2
2
π/4
4.15
−1
0
1
−π or π
See Fig. 9.2
4.17
1
−1
√
2
−π/4
See Fig. 9.5
4.20
−2.39
−6.58
7
−110◦
= −1.92 radians
5.2
−1/2
−1/2
1/
√
2
−3π/4 or 5π/4
5.4
0
2
2
π/2
5.6
−1
0
1
π
5.8
1.6
−2.7
3.14
−59.3◦
5.10
−25/17
19/17

58/17
142.8◦
5.12
2.65
1.41
3
28◦
5.14
1.27
−2.5
2.8
−1.1 radians = −63◦
5.16
1.53
−1.29
2
−40◦
5.17
−7.35
−10.9
13.1
−124◦
5.18
−0.94
−0.36
1
201◦or −159◦
5.19
(2 + 3i)/13; (x −yi)/(x2 + y2)
5.21
(1 + i)/6; (x + 1 −yi)/[(x + 1)2 + y2]
5.23
(−6 −3i)/5; (1 −x2 −y2 + 2yi)/[(1 −x)2 + y2]
5.26
1
5.30
3/2
5.31
1
5.32
169
5.34
1
5.35
x = −4, y = 3
5.36
x = −1/2, y = 3
5.39
x = y = any real number
5.42
x = −1/7, y = −10/7
5.43
(x, y) = (0, 0), or (1, 1), or (−1, 1)
5.45
x = 0, any real y; or y = 0, any real x
5.46
y = −x
5.48
x = 36/13, y = 2/13
5.49
y = 0, x = 1/2
5.53
Circle (Find center and radius)
5.55
Straight line (What is its equation?)
5.56
Part of a straight line (Describe it.)
5.57
Hyperbola (What is its equation?)
5.60
Circle (Find center and radius)
5.62
Ellipse (Find its equation; where are the foci?)
5.63
Two straight lines (What lines?)
5.68
v = 2, a = 4
6.2
D
6.3
C
6.4
D
6.5
D
6.10
C
6.12
C

784
Answers to Selected Problems
Chapter 2
7.1
All z
7.3
All z
7.6
|z| < 1/3
7.7
All z
7.10
|z| < 1
7.12
|z| < 4
7.14
|z −2i| < 1
7.16
|z + (i −3)| < 1/
√
2
8.3
See Problem 17.30
9.3
−9i
9.4
−e(1 + i
√
3)/2
9.6
1
9.7
3e2
9.8
−
√
3 + i
9.10
−2
9.11
−1 −i
9.13
−4 + 4i
9.14
64
9.17
−(1 + i)/4
9.19
16
9.20
i
9.21
1
9.24
4i
9.26
(1 + i
√
3)/2
9.29
1
9.32
3e2
9.34
4/e
9.35
21
9.38
1/
√
2
10.3
±1, ± i
10.4
±2, ± 2i
10.7
±
√
2, ± i
√
2, ± 1 ± i
10.9
1, 0.309 ± 0.951i, −0.809 ± 0.588i
10.16 ±i, (±
√
3 ± i)/2
10.17 −1, 0.809 ± 0.588i, −0.309 ± 0.951i
10.18 ±(1 + i)/
√
2
10.21 ±(
√
3 + i)
10.22 r =
√
2, θ = 45◦+ 120◦n: 1 + i, −1.366 + 0.366i, 0.366 −1.366i
10.24 ±(
√
3 + i)/2, ± (1 −i
√
3)/2, ± (0.259 + 0966i), ± (0.966 −0.259i)
10.25 0.758(1 + i), −0.487 + 0.955i, −1.059 −0.168i, −0.168 −1.059i,
0.955 −0.487i
11.3
3(1 −i)/
√
2
11.5
1 + i
11.8
−41/9
11.9
4i/3
12.25 sin x cosh y −i cosx sinh y,

sin2 x + sinh2 y
12.26 cosh 2 cos 3 −i sinh 2 sin 3 = −3.72 −0.51i, 3.76
12.28 tanh 1 = 0.762
12.30 −i
12.32 −4i/3
12.33 i tanh 1 = 0.762i
12.35 −cosh 2 = −3.76
14.2
−iπ/2 or 3iπ/2
14.3
Ln 2 + iπ/6
14.5
Ln 2 + 5iπ/4
14.6
−iπ/4 or 7iπ/4
14.8
−1, (1 ± i
√
3)/2
14.10 e−π2/4
14.11 cos(Ln 2) + i sin(Ln 2) = 0.769 + 0.639i
14.14 0.3198i −0.2657
14.15 e−π sinh 1 = 0.0249
14.18 −1
14.20 1
14.23 eπ/2 = 4.81
15.2
π/2 + nπ + (i Ln 3)/2
15.3
i(±π/3 + 2nπ)
15.4
i(2nπ + π/6), i(2nπ + 5π/6)
15.5
±[π/2 + 2nπ −i Ln(3 +
√
8)]
15.8
π/2 + 2nπ ± i Ln 3
15.9
i(π/3 + nπ)
15.12 i(2nπ ± π/6)
15.14 2nπ + i Ln 2, (2n + 1)π −i Ln 2
15.15 nπ + 3π/8 + (i/4) Ln 2
16.3
|z| =
√
2; motion around a circle of radius
√
2, at constant speed v =
√
2,
constant acceleration a =
√
2.

Chapter 3
Answers to Selected Problems
785
16.5
v = |z1 −z2|; a = 0
16.6
(a) Series: 3 −2i; parallel: 5 + i
(b) Series: 2(1 + i
√
3 ); parallel: i
√
3
16.8
[R −i(ωCR2 + ω3L2C −ωL)]/[(ωCR)2 + (ω2LC −1)2]; this simpliﬁes to
L/(RC) at resonance.
16.9
(b) ω = 1/
√
LC
16.12 (1 + r4 −2r2 cos θ)−1
17.2
(
√
3 + i)/2
17.4
i cosh 1 = 1.54i
17.6
−e−π2 = −5.17 × 10−5
17.7
eπ/2 = 4.81
17.9
π/2 ± 2nπ
17.11 i
17.13 x = 0, y = 4
17.15 |z| < 1/e
17.26 1
17.27 (c) e−2(x−t)2
17.28 1 + (a2 + b2)2(2ab)−2 sinh2 b
17.30 ex cos x = ∞
n=0

2n/2xn/n!

cos nπ/4
ex sin x = ∞
n=0

2n/2xn/n!

sin nπ/4
Chapter 3
2.4

1
0
−1
2
1
2
0
1
0
1

,
x = 1
2(z + 1), y = 1
2.8


1
−1
0
−11
0
0
1
7
0
0
0
0

,
x = y −11, z = 7
2.9


1
0
1
0
0
1
−1
0
0
0
0
1

,
inconsistent, no solution
2.12


1
0
0
−2
0
1
0
1
0
0
1
1

,
x = −2, y = 1, z = 1
2.17
R = 2
3.1
−11
3.5
−544
3.12
16
3.16
A = −(K + ik)/(K −ik), |A| = 1
4.12
arc cos(−1/
√
2) = 3π/4
4.14
(a) arc cos(1/3) = 70.5◦
4.14
(c) arc cos

2/3 = 35.3◦
4.15
(b) 8i −4j + 8k
4.18
2i −8j −3k
4.19
i + j + k
4.22
Law of cosines
4.24
A2B2
5.1
r = (2i −3j) + (4i + 3j)t
[Note that 2i −3j may be replaced by any point
on the line; 4i + 3j may be replaced by any vector along the line. Thus, for
example, r = 6i −(8i + 6j)t is just as good an answer, and similarly for all
such problems.]
5.4
r = i + (2i + j)t
5.6
(x −1)/1 = (y + 1)/(−2) = (z + 5)/2, or r = i −j −5k + (i −2j + 2k)t
5.8
x/3 = (z −4)/(−5), y = −2; or r = −2j + 4k + (3i −5k)t
5.9
x = −1, z = 7; or r = −i + 7 k + j t

786
Answers to Selected Problems
Chapter 3
5.11
(x −4)/1 = (z −3)/(−2), y = −1; or r = 4i −j + 3k + (i −2k)t
5.12
(x −5)/5 = (y + 4)/(−2) = (z −2)/1; or r = 5i −4j + 2k + (5i −2j + k)t
5.14
36x −3y −22z = 23
5.16
5x −2y + z = 35
5.18
x + 6y + 7z + 5 = 0
5.20
x −4y −z + 5 = 0
5.21
cos θ = 25/(7
√
30 ) = 0.652, θ = 49.3◦
5.22
cos θ = 2/
√
6, θ = 35.3◦
5.24
r = 2i + j + (j + 2k)t, d = 2

6/5
5.25
r = i −2j + (4i + 9j −k)t, d =

3
√
3

/7
5.29
2/
√
6
5.31
5/7
5.33

43/15
5.34

11/10
5.36
3
5.38
arc cos

21/22 = 12.3◦
5.39
Intersect at (3, 2, 0); cos θ = 5/
√
60, θ = 49.8◦
5.42
1/
√
5
5.43
20/
√
21
5.45
d =
√
2, t = −1
6.2
AB =
 −2
−2
1
2

,
BA =
 −6
17
−2
6

,
A + B =

1
−1
−1
5

,
A −B =

3
−9
−1
1

,
A2 =

9
−25
−5
14

,
B2 =
 1
4
0
4

,
5A =

10
−25
−5
15

,
3B =

−3
12
0
6

,
det(5A) = 52 det A for a 2×2 matrix
6.4
You should have found BA, C2, CB, C3, C2B, and CBA; all others are
meaningless.
C2B =


32
12
53
7
−13
−9

,
CBA =


36
46
14
−36
40
22
1
91
−8
−2
1
−29


6.13

5/3
−3
−1
2

6.15
−1
2


4
5
8
−2
−2
−2
2
3
4


6.19
A−1 = 1
7

1
2
−3
1

,
(x, y) = (5, 0)
6.22
A−1 = 1
12


4
4
0
−7
−1
3
1
−5
3

,
(x, y, z) = (1, −1, 2)
6.30
sin kA = A sin k =

0
sin k
sin k
0

,
cos kA = I cosk =
 cos k
0
0
cos k

,
ekA =
 cosh k
sinh k
sinh k
cosh k

,
eikA =
 cos k
i sin k
i sin k
cos k

7.1
Not linear
7.4
Linear
7.6
Not linear
7.8
Not linear
7.11
Not linear
7.12
Linear
7.14
Not linear
7.15
Linear
7.22
D = 1,
rotation θ = −45◦
7.24
D = −1,
reﬂection line x + y = 0
7.26
D = −1,
reﬂection line x = 2y
7.30
R =


0
−1
0
1
0
0
0
0
1

,
S =


1
0
0
0
0
−1
0
1
0

,
R is a 90◦rotation about the z axis, S is a 90◦rotation about the x axis.
7.32
180◦rotation about i −k
7.35
Reﬂection through the (x, y) plane and 90◦rotation about the z axis.

Chapter 3
Answers to Selected Problems
787
8.1
In terms of basis u = 1
9(9, 0, 7), v = 1
9(0, −9, 13), the vectors are: u −4v,
5u −2v, 2u + v, 3u + 6v.
8.3
Basis i, j, k
8.6
V = 3A −B
8.19
x = y = z = w = 0
8.20
x = −z, y = z
8.23
For λ = 3, x = 2y; for λ = 8, x = −2y
8.25
For λ = 2: x = 0, y = −3z; for λ = −3: x = −5y, z = 3y;
for λ = 4: z = 3y, x = 2y
8.26
r = (3, 1, 0) + (−1, 1, 1)z
9.4
A† =


0
i
3
−2i
2
0
−1
0
0

,
A−1 = 1
6


0
0
2
0
3
i
−6
6i
−2


9.14
CTBAT,
C−1M−1C,
H
10.1
(b) d = 8
10.2
The number of basis vectors given is the dimension of the space. We list one
possible basis; other bases consist of the same number of independent linear
combinations of the vectors given.
(b) (1, 0, 0, 5, 0, 1), (0, 1, 0, 0, 6, 4), (0, 0, 1, 0, −3, 0)
10.3
(a) Label the vectors A, B, C, D. Then cos(A, B) = 1/
√
15,
cos(A, C) =
√
2/3, cos(B, D) =

17/690.
10.4
(b) e1 = (0, 0, 0, 1), e2 = (1, 0, 0, 0), e3 = (0, 1, 1, 0)/
√
2
10.5
(b) ∥A∥= 7, ∥B∥=
√
60,
|Inner product of A and B| =
√
5
11.5
θ = 1.1 = 63.4◦
11.11

x
y

= 1
5

1
3
−1
2
 
x′
y′

, not orthogonal
In the following answers, for each eigenvalue, the components of a corresponding
eigenvector are listed in parentheses.
11.12
4
(1, 1)
−1
(3, −2)
11.15
1
(0, 0, 1)
−1
(1, −1, 0)
5
(1, 1, 0)
11.18
4
(2, 1, 3)
2
(0, −3, 1)
−3
(5, −1, −3)
11.20
3
(0, −1, 2)
4
(1, 2, 1)
−2
(−5, 2, 1)
11.22
−4
(−4, 1, 1)
5
(1, 2, 2)
−2
(0, −1, 1)
11.23
18
(2, 2, −1)
9
(1, −1, 0)
9
(1, 1, 4)
The two eigenvectors corresponding to the eigenvalue 9
may be any two vectors orthogonal to (2, 2, −1) and or-
thogonal to each other.
11.26
4
(1, 1, 1)
1
(1, −1, 0)
1
(1, 1, −2)
11.27 D =
3
0
0
1

, C =
1
√
2
 1
1
−1
1

11.29 D =
11
0
0
1

, C =
1
√
5
1
−2
2
1

11.31 D =
5
0
0
1

, C =
1
√
2
1
−1
1
1

11.41 λ = 1, 3;
U =
1
√
2
1
i
i
1


788
Answers to Selected Problems
Chapter 3
11.44 λ = 3, −7;
U =
1
5
√
2

5
−3 −4i
3 −4i
5

11.52 60◦rotation about −i
√
2 + k and reﬂection through the plane z = x
√
2
11.53 180◦rotation about i + j + k
11.56 45◦rotation about j −k
11.58 M10 = 1
5

1 + 4 · 610
2 −2 · 610
2 −2 · 610
4 + 610

11.59 eM = e3
 cosh 1
−sinh 1
−sinh 1
cosh 1

12.2
3x′2 −2y′2 = 24
12.3
10x′2 = 35
12.6
3x′2 +
√
3 y′2 −
√
3 z′2 = 12
12.15 y = 2x with ω =

3k/m; x = −2y with ω =

8k/m
12.17 x = −2y with ω =

2k/m; 3x = 2y with ω =

2k/(3m)
12.19 y = −x with ω =

3k/m; y = 2x with ω =

3k/(2m)
12.22 y = −x with ω =

2k/m; y = 3x with ω =

2k/(3m)
13.6
The cyclic group
13.11 The four matrices of the symmetry group of the rectangle are:
I =

1
0
0
1

, P =

−1
0
0
1

,

1
0
0
−1

= −P,

−1
0
0
−1

= −I
This group is isomorphic to the 4’s group.
13.21 SO(2) is Abelian; SO(3) is not Abelian.
14.3
x, cos x, x cos x, ex cos x
14.5
1, x + x3, x2, x4, x5
14.6
Not a vector space
14.8
1, x2, x4, x6
15.3
(a) (x −4)/1 = (y + 1)/(−2) = (z −2)/(−2); or r = (4, −1, 2) + (1, −2, −2)t
(b) x −5y + 3z = 0
(c) 5/7
(d) 5
√
2/3 = 2.36
(e) arc sin 19/21 = 64.8◦
15.5
(a) y = 7, (x −2)/3 = (z + 1)/4; or r = (2, 7, −1) + (3, 0, 4)t
(b) x −4y −9z = 0
(c) arc sin( 33
70
√
2 ) = 41.8◦
(d) 12/
√
98 = 1.21
(e)
√
29 /5 = 1.08
15.7
You should have found all except ATBT, BAT, ABC, ABTC, B−1C, and
CBT, which are meaningless.
BTAC =


2
2
1 −3i
1
−1 −5i
−1

,
C−1A =
0
−i
1
−1

15.9
1
f = (n −1)
 1
R1
−1
R2
+ (n −1)d
nR1R2

15.13 Area = 1
2
−−→
PQ × −→
PR
 = 7/2
15.14 x′′ = −x, y′′ = −y,
180◦rotation
15.15 x′′ = −y, y′′ = x; 90◦rotation of vectors or −90◦rotation of axes
15.18
1
(1, 1)
−2
(0, 1)
15.20
1
(1, 1)
9
(1, −1)
15.22
1
(1, 0, 1)
4
(0, 1, 0)
5
(1, 0, −1)
15.24
2
(0, 4, 3)
7
(5, −3, 4)
−3
(5, 3, −4)
15.27 3x′2 −y′2 −5z′2 = 15, d =
√
5
15.29 3x′2 + 6y′2 −4z′2 = 54, d = 3

Chapter 4
Answers to Selected Problems
789
Chapter 4
1.1
∂u/∂x = 2xy2/(x2 + y2)2, ∂u/∂y = −2x2y/(x2 + y2)2
1.3
∂z/∂u = u/(u2 + v2 + w2)
1.4
At (0, 0), both = 0; at (−2/3, 2/3), both = −4
1.7
2x
1.9
2x(1 + 2 tan2 θ)
1.11
2y
1.13
4r2 tan θ
1.15
r2 sin 2θ
1.17
4r
1.19
0
1.21
−4x csc2 θ
1.23
2r sin 2θ
1.8′
−2r4/x3
1.10′ 2y + 4y3/x2
1.12′ 2y sec2 θ
1.14′ 2y2 sec2 θ tan θ
1.16′ 2r tan2 θ
1.18′ −2ry4/(r2 −y2)2
1.20′ 4x(tan θ sec2 θ)(tan2 θ + sec2 θ)
1.22′ −8r3/x3
1.24′ −8y3/x3
2.1
y + y3/6 −x2y/2 + x4y/24 −x2y3/12 + y5/120 · · ·
2.3
x −x2/2 −xy + x3/3 + x2y/2 + xy2 · · ·
2.5
1 + xy/2 −x2y2/8 + x3y3/16 −5x4y4/128 · · ·
2.8
ex cos y = 1 + x + (x2 −y2)/2 + (x3 −3xy2)/6 · · ·
4.2
2.5 × 10−13
4.4
12.2
4.6
9%
4.8
5%
4.10
4.28 nt
4.11
3.95
4.15
8 × 1023
5.1
e−y sinh t + z sin t
5.3
2r(q2 −p2)
5.7
(1 −2b −e2a) cos(a −b)
6.2
y′ = 1, y′′ = 0
6.3
y′ = 4(ln 2 −1)/(2 ln 2 −1)
6.5
2x + 11y −24 = 0
6.6
1800/113
6.10
x + y = 0
6.11
y′′ = 4
7.1
dx/dy = z −y + tan(y + z), d2x/dy2 = 1
2 sec3(y + z) + 1
2 sec(y + z) −2
7.4
∂w/∂u = −2(rv + s)w, ∂w/∂v = −2(ru + 2s)w
7.7
(∂y/∂θ)r = x, (∂y/∂θ)x = r2/x, (∂θ/∂y)x = x/r2
7.8
∂x/∂s = −19/13, ∂x/∂t = −21/13, ∂y/∂s = 24/13, ∂y/∂t = 6/13
7.10
∂x/∂s = 1/6, ∂x/∂t = 13/6, ∂y/∂s = 7/6, ∂y/∂t = −11/6
7.13
(∂p/∂q)m = −p/q, (∂p/∂q)a = 1/(a cosp −1),
(∂p/∂q)b = 1 −b sin q, (∂b/∂a)p = (sin p)(b sin q −1)/ cosq,
(∂a/∂q)m = [q + p(a cos p −1)]/(q sin p)
7.15
(∂x/∂u)v = (2yv2 −x2)/(2yv + 2xu), (∂x/∂u)y = (x2u + y2v)/(y2 −2xu2)
7.17
(∂p/∂s)t = −9/7, (∂p/∂s)q = 3/2
7.19
(∂x/∂z)s = 7/2, (∂x/∂z)r = 4, (∂x/∂z)y = 3
8.3
(−1, 2) is a minimum point
8.4
(−1, −2) is a saddle point
8.8
θ = π/3; bend up 8 cm on each side
8.9
l = w = 2h
8.11
θ = 30◦, x = y
√
3 = z/2
8.13
(4/3, 5/3)
8.16
m = 5/2, b = 1/3
9.2
r : l : s =
√
5 : (1 +
√
5 ) : 3
9.4
4/
√
3 by 6/
√
3 by 10/
√
3
9.6
V = 1/3
9.8
(8/13, 12/13)
9.12
Let legs of right triangle be a and b, height of prism = h; then a = b,
h = (2 −
√
2 )a.

790
Answers to Selected Problems
Chapter 5
10.2
4, 2
10.4
d = 1
10.6
d = 2
10.7
1
2
√
11
10.10 (a) max T = 1
2, min T = −1
2
(b) max T = 1, min T = −1
2
(c) max T = 1, min T = −1
2
10.12 Largest sum = 180◦
Smallest sum = 3 arc cos(1/
√
3)
= 164.2◦
10.13 Largest sum = 3 arc sin(1/
√
3) = 105.8◦, smallest sum = 90◦
11.1
z = f(y + 2x) + g(y + 3x)
11.6
d2y/dz2 + dy/dz −5y = 0
11.11 H = p ˙q −L
12.1
1
2x−1/2 sin x
12.3
dz/dx = −sin(cos x) tan x −sin(sin x) cot x
12.4
1
2 sin 2
12.7
(∂u/∂x)y = −e4, (∂u/∂y)x = e4/ ln 2, (∂y/∂x)u = ln 2
12.10 dy/dx = (ex −1)/x
12.12 (2x + 1)/ ln(x + x2) −2/ ln(2x)
12.14 π/(4y3)
13.2
(a) and (b) d = 4/
√
13
13.4
−csc θ cot θ
13.5
−6x, 2x2 tan θ sec2 θ, 4x tan θ sec2 θ
13.9
dz/dt = 1 + (t/z)(2 −x −y), z ̸= 0
13.10 [x ln x −(y2/x)]xy where x = r cos θ, y = r sin θ
13.13 −1
13.14 (∂w/∂x)y = (∂f/∂x)s, t + 2(∂f/∂s)x, t + 2(∂f/∂t)x, s = f1 + 2f2 + 2f3
13.18

26/3
13.21 T (2) = 4, T (5) = −5
13.23 t cot t
13.25 −ex/x
13.29 dt = 3.9
Chapter 5
2.1
3
2.3
4
2.5
1
4e2 −5
12 2.7
5/3
2.9
6
2.11
36
2.13
7/4
2.15
3/2
2.17
1
2 ln 2
2.19
32
2.21
131/6
2.23
9/8
2.25
3/2
2.27
32/5
2.29
2
2.31
6
2.33
16/3
2.36
1/6
2.37
7/6
2.39
70
2.41
5
2.43
9/2
2.45
46k/15
2.47
16/3
2.49
1/3
3.2
(b) Ml2/12
(c) Ml2/3
3.3
(a) M = 140
(b) ¯x = 130/21
(c) Im = 6.92M
(d) I = 150M/7
3.5
(a) Ma2/3
(b) Ma2/12
(c) 2Ma2/3
3.7
(a) M = 9
(b) (¯x, ¯y) = (2, 4/3)
(c) Ix = 2M, Iy = 9M/2
(d) Im = 13M/18
3.9
(a) 1/6
(b) (1/4, 1/4, 1/4)
(c) M = 1/24, ¯z = 2/5
3.11
(a) M = (5
√
5 −1)/6 = 1.7
(b) ¯x = 0, ¯y = (313 + 15
√
5 )/620 = 0.56
3.14
V = 2π2a2b, A = 4π2ab, where a = radius of revolving circle, and b =
distance to axis from center of this circle.
3.15
For area, (¯x, ¯y) = (0, 4
3r/π), for arc, (¯x, ¯y) = (0, 2r/π)

Chapter 6
Answers to Selected Problems
791
3.18
s = [3
√
2 + ln(1 +
√
2 )]/2
3.20
13π/3
3.21
s¯x = [51
√
2 −ln(1 +
√
2 )]/32, s¯y = 13/6, s as in Problem 3.18
3.23
(149/130, 0, 0)
3.25
I/M has the same numerical value as ¯x in Problem 3.21
3.26
2M/3
3.27
149M/130
3.29
2
3.30
32/5
4.1
(b) ¯x = ¯y = 4
3a/π
(c) I = Ma2/4
(e) ¯x = ¯y = 2a/π
4.2
(c) ¯y = 4
3a/π
(d) Ix = Ma2/4, Iy = 5Ma2/4, Iz = 3Ma2/2
(e) ¯y = 2a/π
(f) ¯x = 6a/5, Ix = 48Ma2/175, Iy = 288Ma2/175, Iz = 48Ma2/25
(g) A = ( 2
3π −1
2
√
3 )a2
4.4
(b) (0, 0, a/2)
(c) 2Ma2/3
(e) (0, 0, 3a/8)
4.5
7π/3
4.11
12π
4.12
(c) M = (16ρ/9)(3π −4) = 9.64ρ
I = (128ρ/152)(15π −26) = 12.02ρ = 1.25M
4.14
π(1 −e−1)/4
4.16
u2 + v2
4.19
π/4
4.22
12(1 + 36π2)1/2
4.24
ρGπa/2
4.26
(a) 7
5Ma2
4.27
2πah (where h = distance between parallel planes)
5.1
9
5π
√
30
5.3
π(373/2 −1)/6
5.5
8π for each nappe
5.6
4
5.8
3
16
√
6 + 9
16 ln(
√
2 +
√
3 )
5.9
π
√
2
5.12
M = 1
6
√
3, (¯x, ¯y, ¯z) = ( 1
2, 1
4, 1
4)
5.14
M = 1
2π −4
3
5.16
¯x = 0, ¯y = 1, ¯z = [32/(9π)]

2/5 = 0.716
6.2
45(2 +
√
2 )/112
6.3
15π/8
6.4
(a) 1
2MR2
(b) 3
2MR2
6.6
(a) (4π −3
√
3 )/6
6.7
(8π −3
√
3 )(4π −3
√
3 )−1M
6.8
(b) 27/20
6.10
(a) (¯x, ¯y) = (π/2, π/8)
6.10
(c) 3M/8
6.12
(abc)2/6
6.14
16a3/3
6.15
Ix =
8
15Ma2, Iy =
7
15Ma2
6.16
¯x = ¯y = 2a/5
6.18
(0, 0, 5h/6)
6.19
Ix = Iy = 20Mh2/21, Iz = 10Mh2/21, Im = 65Mh2/252
6.21
πGρh(2 −
√
2 )
6.24
(0, 0, 2c/3)
6.26
1
2 sinh 1
6.27
e2 −e −1
Chapter 6
3.1
(A · B)C = 6C, (A × B) · C = A · (B × C) = −8,
A × (B × C) = −4(i + 2k)
3.3
−5
3.6
v = (2/
√
6 )(A × B) = (2/
√
6 )(i −7j −3k),
r × F = (A −C) × B = 3i + 3j −k,
n · (r × F) = [(A −C) × B] · C/|C| = 8/
√
26
3.7
(a) 11i + 3j −13k,
(b) 3,
(c) 17

792
Answers to Selected Problems
Chapter 6
3.9
−9i −23j + k, 1/
√
21
3.15
u1 · u = −u3 · u, n1u1 × u = n2u2 × u
3.17
a = (ω · r)ω −ω2r; for r ⊥ω, a = −ω2r, |a| = v2/r.
3.19
(a) 16i −2j −5k
(b) 8/
√
6
3.20
(b) 12
4.2
(a) t = 2
(b) v = 4i −2j + 6k, |v| = 2
√
14
(c) (x −4)/4 = (y + 4)/(−2) = (z −8)/6, 2x −y + 3z = 36
4.5
|dr/dt| =
√
2; |d2r/dt2| = 1; path is a helix.
4.8
dr/dt = er(dr/dt) + eθ(r dθ/dt);
d2r/dt2 = er[d2r/dt2 −r(dθ/dt)2] + eθ[r d2θ/dt2 + 2(dr/dt)(dθ/dt)]
6.2
−i
6.4
πe/(3
√
5 )
6.6
6x + 8y −z = 25, (x −3)/6 = (y −4)/8 = (z −25)/(−1)
6.9
(a) 2i −2j −k
(b) 5/
√
6
(c) r = (1, 1, 1) + (2, −2, −1)t
6.12
(a) 2
√
5, −2i + j
(b) 3i + 2j
(c)
√
10
6.14
(b) Down, at the rate 11
√
2
6.17
er
6.19
j
7.1
∇· r = 3, ∇× r = 0
7.2
∇· r = 2, ∇× r = 0
7.4
∇· V = 0, ∇× V = −(i + j + k)
7.6
∇· V = 5xy, ∇× V = ixz −jyz + k(y2 −x2)
7.7
∇· V = 0, ∇× V = ix −jy −kx cos y
7.10
0
7.11
−(x2 + y2)/(x2 −y2)3/2
7.13
2xy
7.14
0
7.16
2(x2 + y2 + z2)−1
7.19
2/r
8.1
−11/3
8.2
(a) −4π
(b) −16
(c) −8
8.3
(a) 5/3
(b) 1
(c) 2/3
8.4
(a) 3
(b) 8/3
8.7
(b) 0
(d) 2π
8.8
yz −x
8.9
3xy −x3yz −z2
8.11
−y sin2 x
8.14
−arc sinxy
8.18
(a) π + π2/2
(b) π2/2
9.2
40
9.4
−3/2
9.7
πab
9.8
24π
9.10
−20
9.11
2
10.2
3
10.4
36π
10.5
4π · 52
10.7
48π
10.9
16π
10.12 φ =





0,
r ≤R1;
(k/2πϵ0) ln(R1/r),
R1 ≤r ≤R2;
(k/2πϵ0) ln(R1/R2),
r ≥R2.
11.2
2ab2
11.3
0
11.4
−12
11.5
36
11.6
45π
11.7
0
11.10 −6π
11.12 18π
11.15 −2π
√
2
11.18 A = (xz −yz2 −y2/2)i + (x2/2 −x2z + yz2/2 −yz)j + ∇u, any u
11.20 A = i sin zx + j cos zx + kezy + ∇u, any u

Chapter 7
Answers to Selected Problems
793
12.1
(sin θ cos θ)C
12.7
(a) 9i + 5j −3k
(b) 29/3
12.9
24
12.11 (a) grad φ = −3yi −3xj + 2zk
(b) −
√
3
(c) 2x + y −2z + 2 = 0, r = (1, 2, 3) + (2, 1, −2)t
12.13 (a) 6i −j −4k
(b) 53−1/2(6i −j −4k)
(c) same as (a)
(d) 531/2
(e) 531/2
12.18 Not conservative
(a) 1/2
(b) 4/3
12.21 4
12.23 192π
12.25 −18π
12.27 4
12.29 10
12.31 29/3
Chapter 7
Amplitude
Period
Frequency
Velocity
Amplitude
2.2
2
π/2
2/π
8
2.3
1/2
2
1/2
π/2
2.6
s = 6 cos(π/8) sin(2t)
6 cos(π/8)
= 5.54
π
1/π
12 cos(π/8)
= 11.1
2.8
2
4π
1/(4π)
1
2.10
4
π
1/π
8
2.11
q
3
1/60
60
I
360π
1/60
60
2.13
A = maximum value of θ, ω =

g/l
2.16
t ∼= 4.91 ∼= 281◦
2.19
A = 1, T = 4, f = 1/4, v = 1/4, λ = 1
2.21
y = 20 sin 1
2π(x −6t), ∂y/∂t = −60π cos 1
2π(x −6t)
2.23
y = sin 880π((x/350) −t)
2.25
y = 10 sin[π(x −3 · 108t)/250]
3.6
sin(2x + 1
3π)
4.5
π−1 + 1
2
4.6
2/π
4.8
0
4.11
1/2
4.14
(a) 2π/3
(b) π
4.15
(a) 3/2
x →
−2π
−π
−π/2
0
π/2
π
2π
6.2
1/2
0
0
1/2
1/2
0
1/2
6.4
−1
0
−1
−1
0
0
−1
6.6
1/2
1/2
1/2
1/2
1/2
1/2
1/2
6.8
1
1
1 −1
2π
1
1 + 1
2π
1
1
6.10
π
0
π/2
π
π/2
0
π

794
Answers to Selected Problems
Chapter 7
7.1
f(x) = 1
2 + i
π
∞

−∞
odd n
1
neinx
7.2
f(x) = 1
4 + 1
2π

(1 −i)eix + (1 + i)e−ix −i(e2ix −e−2ix)
−1 + i
3
e3ix −1 −i
3
e−3ix + 1 −i
5
e5ix + 1 + i
5
e−5ix · · ·

7.7
f(x) = π
4 −
∞

−∞
odd n
 1
n2π + i
2n

einx +
∞

−∞
even n̸=0
i
2neinx
7.11
f(x) = 1
π + eix −e−ix
4i
−1
π
∞

−∞
even n̸=0
einx
n2 −1
8.2
f(x) = 1
4 + 1
π

cos πx
l −1
3 cos 3πx
l
+ 1
5 cos 5πx
l
· · ·

+ 1
π

sin πx
l + 2
2 sin 2πx
l
+ 1
3 sin 3πx
l
+ 1
5 sin 5πx
l
+ 2
6 sin 6πx
l
· · ·

8.6
f(x) = 1
2 + 4
π
 1
n sin nπx
l
(n = 2, 6, 10, · · · )
8.11
(a) f(x) = π2
3 + 4
∞

1
(−1)n
n2
cos nx
(b) f(x) = 4π2
3
+ 2
∞

−∞
 1
n2 + iπ
n

einx,
n ̸= 0
8.14
(a) f(x) = 8
π
∞

1
n(−1)n+1
4n2 −1 sin 2nπx
(b) f(x) = 2
π −4
π
∞

1
cos 2nπx
4n2 −1 = −2
π
∞

−∞
1
4n2 −1e2inπx
8.19
f(x) = 1
8 −1
π2
∞

odd n=1
1
n2 cos 2nπx + 1
2π
∞

1
(−1)n+1
n
sin 2nπx
8.20
f(x) = 2
3 −
9
8π2

cos 2πx
3
+ 1
22 cos 4πx
3
+ 1
42 cos 8πx
3
+ · · ·

−

3
√
3
8π2 + 1
π

sin 2πx
3
+

3
√
3
32π2 −1
2π

sin 4πx
3
−1
3π sin 6πx
3
−

3
√
3
128π2 + 1
4π

sin 8πx
3
· · ·
9.2
(a) 1
2 ln |1 −x2| + 1
2 ln |(1 −x)/(1 + x)|
9.5
f(x) = 4
π
∞

odd n=1
1
n sin nx

Chapter 7
Answers to Selected Problems
795
9.19
fc(x) = fp(x) = 2
π −4
π
∞

1
(−1)n cos 2nx
4n2 −1
fs(x) = 2
π

sin x + sin 3x + 1
3 sin 5x + 1
3 sin 7x + 1
5 sin 9x + 1
5 sin 11x · · ·

9.20
fc(x) = 1
3 + 4
π2
∞

1
(−1)n
n2
cos nπx
fs(x) = 2
π
∞

1
(−1)n+1
n
sin nπx −8
π3
∞

odd n=1
1
n3 sin nπx
fp(x) = 1
3 + 1
π2
∞

1
1
n2 cos 2nπx −1
π
∞

1
1
n sin 2nπx
9.22
fc(x) = 15 −20
π

cos πx
20 −1
3 cos 3πx
20 + 1
5 cos 5πx
20 · · ·

fs(x) = 20
π

3 sin πx
20 −2
2 sin 2πx
20 + 3
3 sin 3πx
20 + 3
5 sin 5πx
20 −2
6 sin 6πx
20 · · ·

fp(x) = 15 −20
π
∞

odd n=1
1
n sin nπx
10
9.23
f(x, 0) = 8h
π2

sin πx
l −1
32 sin 3πx
l
+ 1
52 sin 5πx
l
· · ·

10.1
Relative intensities = 1 : 0 : 0 : 0 :
1
25 : 0 :
1
49 : 0 : 0 : 0
10.3
Relative intensities = 1 : 25 : 1
9 : 0 :
1
25 : 25
9 :
1
49 : 0 :
1
81 : 1
10.5
I(t) = 5
π

1 −2
∞

even n=2
1
n2 −1 cos 120nπt

+ 5
2 sin 120πt
10.6
V (t) = 50 −400
π2
∞

odd n=1
1
n2 cos 120nπt
10.7
I(t) = −20
π
∞

1
(−1)n
n
sin 120nπt
10.10 V (t) = 75 −200
π2
∞

odd n=1
1
n2 cos 120nπt −100
π
∞

1
1
n sin 120nπt
Relative intensities = 1.4 : 0.25 : 0.12 : 0.06 : 0.04
11.5
π2/8
11.7
π2/6
11.9
π2
16 −1
2
12.2
fs(x) = 2
π
 ∞
0
1 −cos α
α
sin αx dα
12.4
f(x) =
 ∞
−∞
sin απ −sin(απ/2)
απ
eiαx dα
12.6
f(x) =
 ∞
−∞
sin α −α cos α
iπα2
eiαx dα
12.8
f(x) =
 ∞
−∞
(iα + 1)e−iα −1
2πα2
eiαx dα

796
Answers to Selected Problems
Chapter 8
12.10 f(x) = 2
 ∞
−∞
αa −sin αa
iπα2
eiαx dα
12.11 f(x) = 1
π
 ∞
−∞
cos(απ/2)
1 −α2
eiαx dα
12.13 fc(x) = 2
π
 ∞
0
sin απ −sin(απ/2)
α
cos αx dα
12.16 fc(x) = 2
π
 ∞
0
cos(απ/2)
1 −α2
cos αx dα
12.18 fs(x) = 2
π
 ∞
0
sin α −α cos α
α2
sin αx dα
12.19 fs(x) = 4
π
 ∞
0
αa −sin αa
α2
sin αx dα
12.21 g(α) = σ(2π)−1/2e−α2σ2/2
12.25 (a) f(x) = 1
2π
 ∞
−∞
1 + e−iαπ
1 −α2
eiαx dα
12.28 (a) fc(x) = 4
π
 ∞
0
cos 3α sin α
α
cos αx dα
(b) fs(x) = 4
π
 ∞
0
sin 3α sin α
α
sin αx dα
12.30 (a) fc(x) = 1
π
 ∞
0
1 −cos 2α
α2
cos αx dα
(b) fs(x) = 1
π
 ∞
0
2α −sin 2α
α2
sin αx dα
13.7
f(x) = π
2 −4
π
∞

1
odd n
1
n2 cos nx
13.8
(b) 1
13.10 (d) −1, −1/2, −2, −1
13.14 (a) f(x) = 1
3 + 4
π2
∞

1
cos nπx
n2
(b) π4/90
13.15 −π/4
13.23 π2/8
Chapter 8
1.5
x = −Aω−2 sin ωt + v0t + x0
1.7
x = (c/F)[(m2c2 + F 2t2)1/2 −mc]
2.2
(1 −x2)1/2 + (1 −y2)1/2 = C, C =
√
3
2.3
ln y = A(csc x −cot x), A =
√
3
2.6
2y2 + 1 = A(x2 −1)2, A = 1
2.7
y2 = 8 + eK−x2, K = 1
2.9
yey = aex, a = 1
2.13
y ≡1, y ≡−1, x ≡1, x ≡−1
2.19
(a) I/I0 = e−0.5 = 0.6 for s = 50 ft
Half value thickness = (ln 2)/µ = 69.3 ft
(b) Half life T = (ln 2)/λ
2.20
(c) τ = RC, τ = L/R. Corresponding quantities are a, λ = (ln 2)/T , µ, 1/τ.
2.22
N = N0eKt −(R/K)(eKt −1) where N0 = number of bacteria at t = 0,
KN = rate of increase, R = removal rate.
2.23
T = 100[1 −(ln r)/(ln 2)]

Chapter 8
Answers to Selected Problems
797
2.26
(a) k = weight divided by terminal speed
(b) t = g−1 · (terminal speed) · (ln 100); typical terminal speeds are 0.02 to
0.1 cm/sec, so t is of the order of 10−4 sec.
2.27
t = 10(ln 5
13)/(ln 3
13) = 6.6 min
2.29
t = 100 ln 9
4 = 81.1 min
2.31
ay = bx
2.33
x2 + ny2 = C
2.35
x(y −1) = C
3.1
y = 1
2ex + Ce−x
3.3
y = ( 1
2x2 + C)e−x2
3.6
y = (x + C)/(x +
√
x2 + 1 )
3.8
y = 1
2 ln x + C/ ln x
3.9
y(1 −x2)1/2 = x2 + C
3.11
y = 2(sin x −1) + Ce−sin x
3.13
x = 1
2ey + Ce−y
3.14
x = y2/3 + Cy−1/3
3.15
S = (107/2)[(1 + 3t/104) + (1 + 3t/104)−1/3], where S = number of pounds
of salt, and t is in hours.
3.17
I = Ae−t/(RC) −V0ωC(sin ωt −ωRC cos ωt)/(1 + ω2R2C2)
3.21
Nn = c1e−λ1t + c2e−λ2t + · · · where
c1 =
λ1λ2 · · · λn−1N0
(λ2 −λ1)(λ3 −λ1) . . . (λn −λ1), c2 =
λ1λ2 · · · λn−1N0
(λ1 −λ2)(λ3 −λ2) · · · (λn −λ2),
etc. (all λ’s diﬀerent)
3.22
y = x + 1 + Kex
4.1
y1/3 = x −3 + Ce−x/3
4.4
x2e3y + ex −1
3y3 = C
4.5
x2 −y2 + 2x(y + 1) = C
4.7
x = y(ln x + C)
4.9
y2 = Ce−x2/y2
4.11
tan 1
2(x + y) = x + C
4.13
y2 = −sin2 x + C sin4 x
4.16
y2 = C(C ± 2x)
4.18
x2 + (y −k)2 = k2
4.19
r = Ae−θ, r = Beθ
5.1
y = Aex + Be−2x
5.3
y = Ae3ix + Be−3ix or other forms
as in (5.24)
5.5
y = (Ax + B)ex
5.7
y = Ae3x + Be2x
5.9
y = Ae2x sin(3x + γ)
5.11
y = (A + Bx)e−3x/2
5.20
y = Ae−x + Beix
5.22
y = Aex + Be−3x + Ce−5x
5.24
y = Ae−x + Bex/2 sin( 1
2x
√
3 + γ) 5.26
y = Ae5x + (Bx + C)e−x
5.28
y = ex(A sin x + B cos x) + e−x(C sin x + D cos x)
5.29
y = (A + Bx)e−x + Ce2x + De−2x + E sin(2x + γ)
5.35
T = 2π

R/g ∼= 85 min.
6.1
y = Ae2x + Be−2x −5
2
6.3
y = Aex + Be−2x + 1
4e2x
6.5
y = Aeix + Be−ix + ex
6.7
y = Ae−x + Be2x + xe2x
6.9
y = (Ax + B + x2)e−x
6.11
y = e−x(A sin 3x + B cos 3x) + 8 sin 4x −6 cos4x
6.13
y = (Ax + B)ex −sin x
6.15
y = e−6x/5[A sin(8x/5) + B cos(8x/5)] −5 cos2x
6.17
y = A sin 4x + B cos 4x + 2x sin 4x
6.18
y = e−x(A sin 4x + B cos 4x) + 2e−4x cos 5x
6.20
y = Ae−2x sin(2x + γ) + 4e−x/2 sin(5x/2)
6.22
y = A + Be−x/2 + x2 −4x
6.24
y = (A + Bx + 2x3)e3x
6.26
y = A sin x + B cos x −2x2 cos x + 2x sin x
6.33
y = A sin(x + γ) + x3 −6x −1 + x sin x + (3 −2x)ex

798
Answers to Selected Problems
Chapter 8
6.34
y = Ae3x + Be2x + ex + x
6.37
y = (A + Bx)ex + 2x2ex + (3 −x)e2x + x + 1
6.41
y = e−x(A cos x + B sin x) + 1
4π
+
∞

odd n=1
[4(n2 −2) cos nx −8n sin nx]/[πn2(n2 + 4)]
7.1
(a) y ≡5
(b) y = 2/(x + 1)
(c) y = tan( π
4 −x
2 ) = sec x −tan x
(d) y = 2 tanh x
7.4
x2 + (y −b)2 = a2, or y = C
7.11
x = (1 −3t)1/3
7.12
t =
 x
1 u2(1 −u4)−1/2 du
7.16
(a) y = Ax + Bx−3
7.16
(c) y = (A + B ln x)/x3
7.18
y = Ax + Bx−1 + 1
2

x + x−1
ln x
7.20
y = x2(A + B ln x) + x2(ln x)3
7.22
y = A cos ln x + B sin ln x + x
7.25
x−1 −1
7.27
x3ex
7.29
xe1/x
8.8
e−2t −te−2t
8.10
1
3et sin 3t + 2et cos 3t
8.12
3 cosh 5t + 2 sinh 5t
8.21
2b(p + a)/[(p + a)2 + b2]2
8.23
y = te−2t(cos t −sin t)
8.25
e−pπ/2/(p2 + 1)
9.3
y = e−2t(4t + 1
2t2)
9.4
y = cos t + 1
2(sin t −t cost)
9.7
y = 1 −e2t
9.9
y = (t + 2) sin 4t
9.11
y = te2t
9.12
y = 1
2(t2e−t + 3et −e−t)
9.13
y = sinh 2t
9.17
y = 2
9.19
y = e2t
9.21
y = e3t + 2e−2t sin t
9.23
y = sin t + 2 cost −2e−t cos 2t
9.25
y = (3 + t)e−2t sin t
9.27

y = t + 1
4(1 −e4t)
z = 1
3 + e4t
9.28

y = t cost −1
z = cos t + t sin t
9.30

y = t −sin 2t
z = cos 2t
9.32

y = sin 2t
z = cos 2t −1
9.36
arc tan(2/3)
9.38
4/5
9.40
1
9.42
π/4
10.3
1
2t sinh t
10.5
[b(b −a)te−bt + a(e−bt −e−at)]/(b −a)2
10.7
(a cosh bt −b sinh bt −ae−at)/(a2 −b2)
10.9
(2t2 −2t + 1 −e−2t)/4
10.12 (b2 −a2)−1(b−2 cos bt −a−2 cos at) + a−2b−2
10.13
1
2(e−t + sin t −cos t)
10.15
1
14e3t + 1
35e−4t −1
10et
10.17 y =

(cosh at −1)/a2,
t > 0
0,
t < 0
11.7
y =

(t −t0)e−(t−t0),
t > t0
0,
t < t0

Chapter 9
Answers to Selected Problems
799
11.9
y =

1
3e−(t−t0) sin 3(t −t0),
t > t0
0,
t < t0
11.11 y =

1
2[sinh(t −t0) −sin(t −t0)],
t > t0
0,
t < t0
11.13 (b) 3δ(x + 5) −4δ(x −10)
11.15 (b) 0
(d) cosh 1
11.21 (b) φ(|a|)/(2|a|)
(c) 1/2
11.23 (a) δ(x + 5)δ(y −5)δ(z), δ(r −5
√
2 )δ(θ −3π
4 )δ(z)/r,
δ(r −5
√
2 )δ(θ −π
2 )δ(φ −3π
4 )/(r sin θ)
(c) δ(x + 2)δ(y)δ(z −2
√
3 ), δ(r −2)δ(θ −π)δ(z −2
√
3 )/r,
δ(r −4)δ(θ −π
6 )δ(φ −π)/(r sin θ)
11.25 (c) G′′(x) = δ(x) + 5δ′(x)
12.2
y = (sin ωt −ωt cosωt)/(2ω2)
12.7
y = [a(cosh at −e−t) −sinh at]/[a(a2 −1)]
12.11 y = −1
3 sin 2x
12.13 y =

x −
√
2 sin x,
x < π/4
1
2π −x −
√
2 cos x,
x > π/4
12.16 y = −x ln x −x −x(ln x)2/2
12.18 y = x2/2 + x4/6
13.1
y = −1
3x−2 + Cx
13.3
y = A + Be−x sin(x + γ)
13.5
x2 + y2 −y sin2 x = C
13.7
3x2y3 + 1 = Ax3
13.8
y = x(A + B ln x) + 1
2x(ln x)2
13.10 u −ln u + ln v + v−1 = C
13.13 y = Ae−2x sin(x + γ) + e3x
13.15 y = (A + Bx)e2x + 3x2e2x
13.18 x = (y + C)e−sin y
13.20 y = Aex sin(2x + γ) + x + 2
5 + ex(1 −x cos 2x)
13.22 y = (A + Bx)e2x + C sin(3x + γ)
13.24 y2 = ax2 + b
13.26 y = x2 + x
13.28 y2 + 4(x −1)2 = 9
13.30 y = g/3, v = 7g/12, a = 5g/12
13.32 1:23 p.m.
13.33 In both (a) and (b), the temperature of the mixture at time t is given by the
formula Ta(1 −e−kt) + (n + n′)−1(nT0 + n′T ′
0)e−kt.
13.38
1
2 ln[(a2 + p2)/p2]
13.41
1
4(tanh 1 −sech2 1) = 0.0854
13.43 (sin at + at cosat)/(2a)
13.46 For e−x: gs(α) = (2/π)1/2α/(1 + α2), gc(α) = (2/π)1/2/(1 + α2)
13.47 y = A sin t + B cos t + sin t ln(sec t + tan t) −1
Chapter 9
2.1
Parabola
2.2
Circle
2.3
ax = sinh(ay + b)
2.6
x + a = 4
3(y1/2 −2b)(b + y1/2)1/2
3.1
dx/dy = C/

y3 −C2
3.3
x4y′2 = C2(1 + x2y′2)3
3.6
x = ay3/2 −1
2y2 + b
3.7
y = K sinh(x + C)
3.9
cot θ = A cos(φ −α)
3.12
(x −a)2 + y2 = C2

800
Answers to Selected Problems
Chapter 10
3.15
r cos(θ + α) = C or, in rectangular coordinates,
the straight line x cos α −y sin α = C
3.18
See Problem 3.9
4.6
Cycloid
5.2





m(¨r −r ˙θ2) = −∂V/∂r
m(r¨θ + 2 ˙r ˙θ) = −(1/r)(∂V/∂θ)
m¨z = −∂V/∂z
Comment: These equations are in the
form ma = F; recall from Chapter 6,
equation (6.7), the polar coordinate
form for F = −∇V .
5.4
l¨θ + g sin θ = 0
5.6

a¨θ −a sin θ cos θ ˙φ2 −g sin θ = 0
(d/dt)(sin2 θ ˙φ) = 0
5.8
L = 1
2m(2 ˙r2 + r2 ˙θ2) −mgr
2¨r −r ˙θ2 + g = 0, (d/dt)(r2 ˙θ) = 0
5.11
L = 1
2(m + Ia−2) ˙z2 −mgz
(ma2 + I)¨z + mga2 = 0
5.12
L = 1
2m( ˙r2 + r2 ˙θ2) −
 1
2k(r −r0)2 −mgr cos θ

¨r −r ˙θ2 + k
m(r −r0) −g cos θ = 0,
(d/dt)(r2 ˙θ) + gr sin θ = 0
5.14
L = M ˙x2 + Mgx sin α,
2M ¨x −Mg sin α = 0
5.16
L = 1
2m(l + aθ)2 ˙θ2 −mg[a sin θ −(l + aθ) cos θ]
(l + aθ)¨θ + a ˙θ2 + g sin θ = 0
5.19
x = y with ω =

g/l ;
x = −y with ω =

3g/l
5.21
2¨θ + ¨φ cos(θ −φ) + ˙φ2 sin(θ −φ) + 2g
l sin θ = 0
¨φ + ¨θ cos(θ −φ) −˙θ2 sin(θ −φ) + g
l sin φ = 0
5.23
φ = 2θ with ω =

2g/(3l);
φ = −2θ with ω =

2g/l
6.1
Catenary
6.3
Circular cylinder
6.5
Circle
8.4
dr/dθ = Kr
√
r4 −K2
8.6
(x −a)2 + (y + 1)2 = C2
8.8
Intersection of r = 1 + cos θ with z = a + b sin(θ/2)
8.10
Intersection of y = x2 with az = b[2x
√
4x2 + 1 + sinh−1 2x] + c
8.12
ey cos(x −a) = K
8.16
Hyperbola: r2 cos(2θ + α) = K or (x2 −y2) cos α −2xy sin α = K
8.17
K ln r = cosh(Kθ + C)
8.18
Parabola: (x −y −C)2 = 4K2(x + y −K2)
8.20
m(¨r −r ˙θ2) + Kr−2 = 0, r2 ˙θ = const.
8.22
r−1m(r2¨θ + 2r ˙r ˙θ −r2 sin θ cos θ ˙φ2) = −r−1(∂V/∂θ) = Fθ = maθ,
aθ = r¨θ + 2 ˙r ˙θ −r sin θ cos θ ˙φ2
8.27
dr/dθ = r

K2(1 + λr)2 −1
Chapter 10
4.6
I =

9
0 −3
0
6
0
−3
0
9

; principal moments: (6, 6, 12); principal axes along the vec-
tors (1, 0, −1) and any two orthogonal vectors in the plane z = x, say (0, 1, 0)
and (1, 0, 1).
5.6
(a) 3
(c) 2
(e) −1

Chapter 10
Answers to Selected Problems
801
6.15
(c) vector
8.1
hr = 1,
hθ = r,
hφ = r sin θ
ds = er dr + eθ r dθ + eφ r sin θ dφ
dV = r2 sin θ dr dθ dφ
ar = i sin θ cos φ + j sin θ sin φ + k cos θ = er
aθ = ir cos θ cos φ + j r cos θ sin φ −kr sin θ = reθ
aφ = −ir sin θ sin φ + j r sin θ cos φ = r sin θ eφ
8.3
ds/dt = er ˙r + eθ r ˙θ + eφ r sin θ ˙φ
d2s/dt2 = er(¨r −r ˙θ2 −r sin2 θ ˙φ2)
+ eθ(r¨θ + 2 ˙r ˙θ −r sin θ cos θ ˙φ2)
+ eφ(r sin θ ¨φ + 2r cos θ ˙θ ˙φ + 2 sin θ ˙r ˙φ)
8.5
V = er cos θ −eθ sin θ −eφ r sin θ
8.6
hu = hv = (u2 + v2)1/2,
hz = 1
ds = (u2 + v2)1/2(eu du + ev dv) + ez dz
dV = (u2 + v2) du dv dz
au = iu + jv = (u2 + v2)1/2eu
av = −iv + ju = (u2 + v2)1/2ev
az = k = ez
8.9
hu = hv = a(cosh u + cos v)−1
ds = a(cosh u + cos v)−1(eu du + ev dv)
dA = a2(cosh u + cos v)−2 du dv
au = (h2
u/a)[i(1 + cos v cosh u) −j sin v sinh u] = hueu
av = (h2
v/a)[i sinh u sin v + j(1 + cos v cosh u)] = hvev
8.11
ds/dt = (u2 + v2)1/2(eu ˙u + ev ˙v) + ez ˙z
d2s/dt2 = eu(u2 + v2)−1/2[(u2 + v2)¨u + u( ˙u2 −˙v2) + 2v ˙u ˙v]
+ ev(u2 + v2)−1/2[(u2 + v2)¨v + v(˙v2 −˙u2) + 2u ˙u˙v] + ez¨z
8.14
ds/dt = a(cosh u + cos v)−1(eu ˙u + ev ˙v)
d2s/dt2 = eua(cosh u + cos v)−2[(cosh u + cos v)¨u + (˙v2 −˙u2) sinh u + 2 ˙u˙v sin v]
+ eva(cosh u + cos v)−2[(cosh u + cos v)¨v + (˙v2 −˙u2) sin v −2 ˙u˙v sinh u]
9.10
Let h = hu = hv = (u2 + v2)1/2 represent the u and v scale factors.
∇U = h−1

eu
∂U
∂u + ev
∂U
∂v

+ k∂U
∂z
∇· V = h−2
 ∂
∂u(hVu) + ∂
∂v (hVv)

+ ∂Vz
∂z
∇2U = h−2
∂2U
∂u2 + ∂2U
∂v2

+ ∂2U
∂z2
∇× V =

h−1 ∂Vz
∂v −∂Vv
∂z

eu +
∂Vu
∂z −h−1 ∂Vz
∂u

ev + h−2
 ∂
∂u(hVv) −∂
∂v(hVu)

ez

802
Answers to Selected Problems
Chapter 12
9.13
Same as 9.10 if h = a(cosh u+cosv)−1 and terms involving either z derivatives
or Vz are omitted. Note, however, that ∇× V has only a z component if
V = euVu + evVv where Vu and Vv are functions of u and v.
9.15
hu = 1, hv = u/
√
1 −v2
eu = iv + j
√
1 −v2, ev = i
√
1 −v2 −jv
m[¨u −u ˙v2/(1 −v2)] = −∂V/∂u = Fu
m[(u¨v + 2 ˙u˙v)/(1 −v2)1/2 + uv ˙v2/(1 −v2)3/2] = −h−1
v ∂V/∂v = Fv
9.16
r−1,
0,
0,
r−1ez
9.19
2eφ,
er cos θ −eθ sin θ,
3
9.21
2r−1,
6,
2r−4,
−k2eikr cos θ
Chapter 11
3.3
9/10
3.7
8
3.9
Γ(5/4)
3.11
1
3.14
−Γ(4/3)
3.17
Γ(p)
7.1
1
2B( 5
2, 1
2) = 3π/16
7.3
1
3B( 1
3, 1
2)
7.5
B(3, 3) = 1/30
7.7
1
2B( 1
4, 1
2)
7.11
2B( 2
3, 4
3)/B( 1
3, 4
3)
7.13
Iy/M = 8B( 4
3, 4
3)/B( 5
3, 1
3)
8.1
B( 1
2, 1
4)

2l/g = 7.4163

l/g
(Compare 2π

l/g )
8.3
t = π

a/g
10.2
Γ(p, x) ∼xp−1e−x[1 + (p −1)x−1 + (p −1)(p −2)x−2 · · · ]
10.5
(a) E1(x) = Γ(0, x)
10.6
(b) Ei(x)
11.5
1
12.1
K = F(π/2, k) = (π/2){1 + ( 1
2)2k2 + [(1 · 3)/(2 · 4)]2k4 · · · }
E = E(π/2, k) = (π/2){1 −( 1
2)2k2 −[1/(2 · 4)]2 · 3k4
−[(1 · 3)/(2 · 4 · 6)]2 · 5k6 · · · }
Caution: For the following answers, see the warning about elliptic integral notation
just after equations (12.3) and in Example 1.
12.5
E(1/3) ∼= 1.526
12.6
1
3F( π
3 , 1
3) ∼= 0.355
12.7
5E( 5π
4 , 1
5) ∼= 19.46
12.10
1
2F( π
4 , 1
2) ∼= 0.402
12.11 F( 3π
8 ,
3
√
10) + K(
3
√
10) ∼= 4.097
12.13 3E( π
6 , 2
3) + 3E(arc sin 3
4, 2
3) ∼= 3.96
12.16 2
√
2 E(1/
√
2 ) ∼= 3.820
12.23 T = 8

a
5g K(1/
√
5 ); for small vibrations, T ∼= 2π

2a
3g
13.8
1
2
√π erf(1)
13.10
√
2 K(1/
√
2 ) ∼= 2.622
13.11
1
5F(arc sin 3
4, 4
5) ∼= 0.1834
13.13 −sn u dn u
13.15 Γ(7/2) = 15√π/8
13.17
1
2B( 5
4, 7
4) = 3π
√
2/64
13.19
1
2
√π erfc 5
13.21 54B( 2
3, 13
3 ) = ( 5
3)5( 14π
√
3 )
13.24 −255√π/109!!

Chapter 12
Answers to Selected Problems
803
Chapter 12
1.2
y = a0ex3
1.3
y = a1x
1.7
y = Ax + Bx3
1.9
y = a0(1 −x2) + a1x
2.4
Q0 = 1
2 ln 1+x
1−x, Q1 = x
2 ln 1+x
1−x −1
3.3
(30 −x2) sin x + 12x cosx
3.5
(x2 −200x + 9900)e−x
5.3
P0(x) = 1
P1(x) = x
P2(x) = (3x2 −1)/2
P3(x) = (5x3 −3x)/2
P4(x) = (35x4 −30x2 + 3)/8
P5(x) = (63x5 −70x3 + 15x)/8
P6(x) = (231x6 −315x4 + 105x2 −5)/16
5.9
2P2 + P1
5.11
2
5(P1 −P3)
5.12
8
5P4 + 4P2 −3P1 + 12
5 P0
8.2
N =

2
5,

5
2 P2(x)
8.4
N = π1/4,
π−1/4e−x2/2
9.1
3
2P1 −7
8P3 + 11
16P5 · · ·
9.4
1
8π(3P1 + 7
16P3 + 11
64P5 · · · )
9.6
P0 + 3
8P1 −20
9 P2 · · ·
9.8
1
2(1 −a)P0 + 3
4(1 −a2)P1 + 5
4a(1 −a2)P2 + 7
16(1 −a2)(5a2 −1)P3 · · ·
9.11
8
5P4 + 4P2 −3P1 + 12
5 P0
9.12
2
5(P1 −P3)
9.14
1
2P0 + 5
8P2 =
3
16(5x2 + 1)
10.5
1
2(sin θ)(35 cos3 θ −15 cosθ)
11.2
y = Ax−3 + Bx3
11.4
y = Ax−2 + Bx3
11.6
y = Ae−x + Bx2/3[1 −3x/5 + (3x)2/(5 · 8) −(3x)3/(5 · 8 · 11) + · · · ]
11.8
y = A(x−1 −1) + Bx2(1 −x + 3x2/5 −4x3/15 + 2x4/21 + · · · )
11.10 y = A[1 + 2x −(2x)2/2! + (2x)3/(3 · 3!) −(2x)4/(3 · 5 · 4!) + · · · ]
+ Bx3/2[1 −2x/5 + (2x)2/(5 · 7 · 2!) −(2x)3/(5 · 7 · 9 · 3!) + · · · ]
11.11 y = Ax1/6[1 + 3x2/25 + 32x4/(5 · 210) + · · · ]
+ Bx−1/6[x + 3x3/26 + 32x5/(7 · 211) + · · · ]
16.1
y = x−3/2Z1/2(x)
16.3
y = x−1/2Z1(4x1/2)
16.5
y = xZ0(2x)
16.7
y = x−1Z1/2(x2/2)
16.9
y = x1/3Z2/3(4√x )
16.11 y = x−2Z2(x)
16.15 y = Z2(5x)
16.17 y = Z0(3x)
17.7
(a) y = x1/2I1(2x1/2). Note that the factor i does not need to be included,
since any multiple of y is a solution.
18.11 1.7 m for steel.
20.1
1/6
20.3
4/π
20.5
1/2
20.7
h(1)
n (x) ∼x−1ei[x−(n+1)π/2]
20.9
h(1)
n (ix) ∼−i−nx−1e−x

804
Answers to Selected Problems
Chapter 13
21.1
y = Ax + B

x sinh−1 x −
√
x2 + 1

21.2
y = A(1 + x) + Bxe1/x
21.5
y = A(x −1) + B[(x −1) ln x −4]
21.7
y = A
x
1−x + B[
x
1−x ln x + 1+x
2 ]
21.8
y = A(x2 + 2x) + B[(x2 + 2x) ln x + 1 + 5x −x3/6 + x4/72 + · · · ]
22.4
H0(x) = 1
H1(x) = 2x
H2(x) = 4x2 −2
H3(x) = 8x3 −12x
H4(x) = 16x4 −48x2 + 12
H5(x) = 32x5 −160x3 + 120x
22.13 L0(x) = 1
L1(x) = 1 −x
L2(x) = 1
2(2 −4x + x2)
L3(x) = 1
6(6 −18x + 9x2 −x3)
L4(x) =
1
24(24 −96x + 72x2 −16x3 + x4)
L5(x) =
1
120(120 −600x + 600x2 −200x3 + 25x4 −x5)
Note: The factor 1/n! is omitted in most quantum mechanics books but is
included as here in most reference books.
Chapter 13
2.12
T =

odd n
400
nπ sinh 3nπ sinh nπ
10 (30 −y) sin nπx
10
+

odd n
400
nπ sinh(nπ/3) sinh nπ
30 (10 −x) sin nπy
30
2.14
For f(x) = x −5: T = −40
π2

odd n
1
n2 cos nπx
10 e−nπy/10
For f(x) = x: add 5 to the answer just given.
3.9
u = 100 −400
π
∞

n=0
(−1)n
2n + 1 e−[(2n+1)πα/4]2t cos
2n + 1
4
πx

3.11
En = n2¯h2/(2m); Ψ(x, t) = 4
π

odd n
sin nx
n
e−iEnt/¯h
4.8
y = 4l
π2v
1
3 sin πx
l sin πvt
l
+ π
16 sin 2πx
l
sin 2πvt
l
−
∞

n=3
sin nπ/2
n(n2 −4) sin nπx
l
sin nπvt
l

4.9
Problem 2: n = 2, ν = v/l
Problem 3: n = 3, ν = 3
2v/l and n = 4, ν = 2v/l have nearly equal intensity.
Problem 5: n = 1, ν = 1
2v/l
5.1
(a) u ∼= 9.76
5.4
u = 200
∞

m=1
1
kmJ1(km)J0(kmr/a)e−(kmα/a)2t,
km = zeros of J0

Chapter 13
Answers to Selected Problems
805
5.10
u = 6400
π3

odd n

odd m

odd p
1
nmp sin nπx
l
sin mπy
l
sin pπz
l e−(απ/l)2(n2+m2+p2)t
5.11
R = rn, r−n, n ̸= 0; R = ln r, const., n = 0.
R = rl, r−l−1.
5.13
u = 400
π

odd n
1
n
 r
10
4n
sin 4nθ
5.14
u = 50 ln r
ln 2
+ 200
π

odd n
rn −r−n
n(2n −2−n) sin nθ
6.5
z = 64l4
π6

odd m

odd n
1
n3m3 sin nπx
l
sin mπy
l
cos πv(m2 + n2)1/2t
l
6.8
Ψmn = Jn(kmnr)
 sin nθ
cos nθ

e−iEmnt/¯h, Emn = ¯h2k2
mn
2ma2
7.2
u = 2
5rP1(cos θ) −2
5r3P3(cos θ)
7.5
u = 1
2P0(cos θ) + 5
8r2P2(cos θ) −3
16r4P4(cos θ) · · ·
7.6
u = 1
8π[3rP1(cos θ) + 7
16r3P3(cos θ) + 11
64r5P5(cos θ) · · · ]
7.8
u = 25[P0(cos θ) + 9
4rP1(cos θ) + 15
8 r2P2(cos θ) + 21
64r3P3(cos θ) · · · ]
7.10
u =
1
15r3P 2
3 (cos θ) cos 2φ −rP1(cos θ)
7.12
u = 3
4rP1(cos θ) + 7
24r3P3(cos θ) −11
192r5P5(cos θ) · · ·
7.13
u = E0(r −a3/r2)P1(cos θ)
7.15
u = 100 + 200a
πr
∞

1
(−1)n
n
sin nπr
a
e−(αnπ/a)2t
= 100 + 200
∞

1
(−1)nj0(nπr/a)e−(αnπ/a)2t
7.19
Ψ(r, θ, φ) = jl(βr)P m
l (cos θ)e±imφe−iEt/¯h, where
β =

2ME/¯h2 ,
βa = zeros ofjl,
E =
¯h2
2Ma2 ( zeros of jl)2
7.20
ψn(x) = e−α2x2/2Hn(αx),
α =

mω/¯h
7.21
Degree of degeneracy of En is C(n + 2, n) = (n + 2)(n + 1)/2, n = 0 to ∞.
7.22
Ψ(r, θ, φ) = R(r)Y m
l (θ, φ), R(r) = rle−r/(na)L2l+1
n−l−1
 2r
na

, En = −Me4
2¯h2n2
8.4
Let K = line charge per unit length. Then
V = −K ln(r2 + a2 −2ra cos θ) + K ln a2 −K ln R2
+ K ln[r2 + (R2/a)2 −2(R2/a)r cos θ]
8.5
K at (a, 0), −K at (R2/a, 0)
9.2
u = 200π−1  ∞
0
k−2(1 −cos 2k)e−ky cos kx dk
9.7
u(x, t) = 100 erf[x/(2αt1/2)] −50 erf[(x −1)/(2αt1/2)] −50 erf[(x + 1)/(2αt1/2)]
10.3
T = 1
4(2 −y) + 4
π2

odd n
1
n2 sinh 2nπ sinh nπ(2 −y) cos nπx

806
Answers to Selected Problems
Chapter 14
10.4
T = 20 + 40
π

odd n
1
n sinh(3nπ/5) sinh nπy
5
sin nπx
5
+ 40
π

odd n
1
n sinh(5nπ/3) sinh nπ(5 −x)
3
sin nπy
3
10.6
u = 20 −80
π
∞

0
(−1)n
2n + 1e−[(2n+1)πα/(2l)]2t cos
2n + 1
2l
πx

10.8
u = 20 −x −40
π

even n
1
n e−(nπα/10)2t sin nπx
10
10.10 u = 1600
π2

odd n

odd m
1
nmIn(3mπ/20)In
mπr
20

sin nθ sin mπz
20
10.16 v
√
5/(2π)
10.18 νmn, n = 3, 6, · · · ; the lowest frequencies are:
ν13 = 2.65 ν10, ν23 = 4.06 ν10, ν16 = 4.13 ν10, ν33 = 5.4 ν10
10.20 ν = vλ l/(2πa) where λ l = zeros of j l, a = radius of sphere,
v = speed of sound
10.22 u = 1 −1
2rP1(cos θ) + 7
8r3P3(cos θ) −11
16r5P5(cos θ) · · ·
10.26 ν = [v/(2π)][(kmn/a)2 + λ2]1/2 where kmn is a zero of Jn
Chapter 14
1.1
u = x3 −3xy2, v = 3x2y −y3
1.3
u = x, v = −y
1.4
u = (x2 + y2)1/2, v = 0
1.7
u = cosy cosh x, v = sin y sinh x
1.9
u = x/(x2 + y2), v = −y/(x2 + y2)
1.11
u = 3x/[x2 + (y −2)2], v = (−2x2 −2y2 + 5y −2)/[x2 + (y −2)2]
1.13
u = ln(x2 + y2)1/2, v = 0
1.17
u = cosx cosh y, v = sin x sinh y
1.18
u = ±2−1/2[(x2 + y2)1/2 + x]1/2, v = ±2−1/2[(x2 + y2)1/2 −x]1/2,
where the ± signs are chosen so that uv has the sign of y.
1.19
u = ln(x2 + y2)1/2, v = arc tan(y/x)
[The angle is in the quadrant of the point (x, y).]
In 2.1–2.23, A = analytic, N = not analytic
2.1
A
2.3
N
2.4
N
2.7
A
2.9
A, z ̸= 0
2.11
A, z ̸= 2i
2.13
N
2.17
N
2.18
A, z ̸= 0
2.19
A, z ̸= 0
2.23
A, z ̸= 0
2.34
−z −1
2z2 −1
3z3 · · · , |z| < 1
2.38
−1
2i + 1
4z + 1
8iz2 −1
16z3 · · · , |z| < 2
2.42
z + z3/3! + z5/5! · · ·, all z
2.48
Yes, z ̸= 0
2.52
No
2.53
Yes, z ̸= 0
2.54
−iz
2.56
−iz2/2
2.59
ez
2.60
2 ln z
2.63
−i/(1 −z)
3.1
1
2 + i
3.3
0
3.5
−1
3.7
π(1 −i)/8
3.9
1
3.12
(a) 5
3(1 + 2i)
3.17
(a) 0
(b) iπ
3.19
16iπ
3.23
72iπ
4.4
For 0 < |z| < 1: −1
4z−1 −1
2 −11
16z −13
16z2 · · · ; R(0) = −1
4
For 1 < |z| < 2: · · · + z−3 + z−2 + 3
4z−1 + 1
2 + 5
16z + 3
16z2 · · ·
For |z| > 2: z−4 + 5z−5 + 17z−6 + 49z−7 · · ·

Chapter 14
Answers to Selected Problems
807
4.6
For 0 < |z| < 1: z−2 −2z−1 + 3 −4z + 5z2 · · · ; R(0) = −2
For |z| > 1: z−4 −2z−5 + 3z−6 · · ·
4.8
For |z| < 1: −5 + 25
6 z −175
36 z2 · · · ; R(0) = 0
For 1 < |z| < 2: −5(· · · + z−3 −z−2 + z−1 + 1
6z + 1
36z2 +
7
216z3 · · · )
For 2 < |z| < 3: · · · + 3z−3 + 9z−2 −3z−1 + 1 −1
3z + 1
9z2 −1
27z3 · · ·
For |z| > 3: 30(z−3 −2z−4 + 9z−5 · · · )
4.9
(a) Regular
(b) Pole of order 3
4.10
(b) Pole of order 2
(d) Essential singularity
4.11
(c) Simple pole
(d) Pole of order 3
4.12
(b) Pole of order 2
(d) Pole of order 1
6.1
z−1 −1 + z −z2 · · · ; R = 1
6.3
z−3 −z−1/3! + z/5! · · ·; R = −1
6
6.5
1
2e[(z −1)−1 + 1
2 + 1
4(z −1) · · · ]; R = 1
2e
6.7
1
4[(z −1
2)−1 −1 + (1 −π2/2)(z −1
2) · · · ]; R = 1
4
6.9
−[(z −2)−1 + 1 + (z −2) + (z −2)2 · · · ]; R = −1
6.14
R(−2/3) = 1/8, R(2) = −1/8
6.16
R(0) = −2, R(1) = 1
6.18
R(3i) = 1
2 −1
3i
6.19
R(π/2) = 1/2
6.21
R[
√
2 (1 + i)] =
√
2 (1 −i)/16
6.22
R(iπ) = −1
6.27
R(π/6) = −1/2
6.28
R(3i) = −1
16 + 1
24i
6.31
R(0) = 9/2
6.33
R(π) = −1/2
6.35
R(i) = 0
6.14′ πi/4
6.16′ −2πi
6.18′ 0
6.19′ 0
6.27′ −πi
6.28′ πi/4
6.31′ 9πi
6.33′ 0
6.35′ 0
7.1
π/6
7.3
2π/3
7.5
π/(1 −r2)
7.7
π/6
7.9
2π/| sin α|
7.11
3π/32
7.13
π/10
7.15
πe−4/3/12
7.17
(π/e)(cos 2 + 2 sin 2)
7.19
πe−3/54
7.23
π/8
7.24
π
7.26
−π/2
7.28
π/4
7.30
π/(2
√
2 )
7.32
3
16π
√
2
7.33
π
√
2/2
7.36
−π2√
2
7.39
2
7.41
(2π)1/2/4
7.45
One negative real, one each in quadrants I and IV
7.48
Two each in quadrants I and IV
7.50
Two each in quadrants II and III
7.52
πi
7.54
8πi
7.55
cosh t cos t
7.57
1 + sin t −cos t
7.60
t + e−t −1
7.61

cosh 2t + 2 cosh t cos t
√
3

/3
7.63
(cosh t −cos t)/2
7.65
(cos 2t + 2 sin 2t −e−t)/5
8.3
Regular, R = −1
8.5
Regular, R = −1
8.7
Simple pole, R = −2
8.9
Regular, R = 0
8.11
Regular, R = −1
8.14
−2πi

808
Answers to Selected Problems
Chapter 15
9.3
u = x/(x2 + y2), v = −y/(x2 + y2)
9.4
u = ex cos y, v = ex sin y
9.7
u = sin x cosh y, v = cos x sinh y
10.6
T = 100y/(x2 + y2); isothermals y/(x2 + y2) = const.;
ﬂow lines x/(x2 + y2) = const.
10.9
Streamlines y −y/(x2 + y2) = const.
10.12 T = (20/π) arc tan[2y/(1 −x2 −y2)], arc tan between π/2 and 3π/2
10.14 Φ = 1
2V0 ln{[(x + 1)2 + y2]/[(x −1)2 + y2]}
Ψ = V0 arc tan{2y/[1 −x2 −y2]}, arc tan between π/2 and 3π/2
Vx = 2V0(1 −x2 + y2)/[(1 −x2 + y2)2 + 4x2y2],
Vy = −4V0xy/[(1 −x2 + y2)2 + 4x2y2]
11.2
−i ln(1 + z)
11.5
R(i) = 1
4(1 −i
√
3 ), R(−i) = −1
2
11.8
R(1/2) = 1/2
11.10 −1
11.12 1/2
11.14 (a) 2
(b) −sin 5
(c) 1/16
(d) −2π
11.16 −π/6
11.18
1
4πe−π/2
11.20
1
2π(e−1 + sin 1)
11.29 π3/8. Caution: −π3/8 is wrong.
11.32 One negative real, one each in quadrants II and III
11.34 Two each in quadrants I and IV, one each in II and III
11.41 π2/8
Chapter 15
1.2
3/8, 1/8, 1/4
1.5
1/4, 3/4, 1/3, 1/2
1.6
27/52, 16/52, 15/52
1.8
9/100, 1/10, 3/100, 1/10
2.12
(a) 3/4
(b) 1/5
(c) 2/3
(d) 3/4
(e) 3/7
2.14
(a) 3/4
(b) 25/36
(c) 37, 38, 39, 40
2.17
(a) 3 to 9 with p(5) = p(7) = 2/9; others, p = 1/9.
(c) 1/3
3.4
(a) 8/9, 1/2
(b) 3/5, 1/11, 2/3, 2/3, 6/13
3.5
1/33, 2/9
3.12
(a) 1/49
(b) 68/441
(c) 25/169
(d) 15 times
(e) 44/147
3.14
n > 3.3, so 4 tries are needed.
3.16
9/23
3.17
(a) 39/80, 5/16, 1/5, 11/16
(b) 374/819
(c) 185/374
3.20
5/7, 2/7, 11/14
3.21
2/3, 1/3
4.1
(a) P(10, 8)
(b) C(10, 8)
(c) 1/45
4.4
1.98 × 10−3, 4.95 × 10−4, 3.05 × 10−4, 1.39 × 10−5
4.7
1/26
4.8
1/221, 1/33, 1/17
4.11
0.097, 0.37, 0.67; 13
4.17
MB: 16,
FD: 6,
BE: 10
5.1
µ = 0, σ =
√
3
5.3
µ = 2, σ =
√
2
5.5
µ = 1, σ =

7/6
5.7
µ = 3(2p −1), σ = 2

3p(1 −p)
6.1
(c) ¯x = 0, σ = 2−1/2a
6.4
¯x = 0, σ = (21/2α)−1
6.5
f(t) = λe−λt, F(t) = 1 −e−λt, ¯t = 1/λ, half life = ¯t ln 2

Chapter 15
Answers to Selected Problems
809
6.7
(a) F(s) = 2[1 −cos(s/R)], f(s) = (2/R) sin(s/R)
(b) F(s) = [1 −cos(s/R)]/[1 −cos(1/R)] ∼= s2,
f(s) = R−1[1 −cos(1/R)]−1 sin(s/R) ∼= 2s
n
Exactly
7 h
At most
7 h
At least
7 h
Most probable
number of h
Expected
number of h
7.1
7
0.0078
1
0.0078
3 or 4
7/2
7.2
12
0.193
0.806
0.387
6
6
In the following answers, the ﬁrst number is the binomial result and the second
number is the normal approximation using whole steps at the ends as in Example 2.
8.12
0.03987, 0.03989
8.14
0.9546, 0.9546
8.17
0.0770, 0.0782
8.18
0.372, 0.376
8.20
0.462, 0.455
9.3
Number of particles
0
1
2
3
4
5
Number of intervals
406
812
812
541
271
108
9.5
P0 = 0.37, P1 = 0.37, P2 = 0.18, P3 = 0.06
9.8
3, 10, 3
9.11
Normal: 0.08, Poisson: 0.0729, (binomial: 0.0732)
10.8
¯x = 5, ¯y = 1, sx = 0.122, sy = 0.029,
σx = 0.131, σy = 0.030, σmx = 0.046, σmy = 0.0095,
rx = 0.031, ry = 0.0064,
x + y = 6 with r = 0.03, xy = 5 with r = 0.04,
x3 sin y = 105 with r = 2.00, ln x = 1.61 with r = 0.006
10.10 ¯x = 6 with r = 0.062, ¯y = 3 with r = 0.067,
ey = 20 with r = 1.3, x/y2 = 0.67 with r = 0.03
11.3
20/47
11.7
¯x = 1/4, σ =
√
3/4
11.9
(d) ¯x = 1/4, σ =
√
31/12
11.13 30, 60
11.17 ¯x = 2 with r = 0.073, ¯y = 1 with r = 0.039, x −y = 1 with r = 0.08,
xy = 2 with r = 0.11, x/y3 = 2 with r = 0.25


Index
Abelian group, 175
absolutely convergent series, 10, 56
absolute value of complex number, 49, 53
acceleration, 286
of car, 33
centripetal, 83, 487
in circular motion, 283
complex, 56
in any coordinate system, 523
Coriolis, 487
in cylindrical coordinates, 523
of gravity, 392
in polar coordinates, 487
a-c circuit, See electric circuits
active transformation, 127
adding (subtracting)
complex numbers, 51
matrices, 115
mod N, 174, 178
rows (columns) of a determinant, 91
series, 19, 23
tensors, 504
vectors, 97–98
adjoint, 137
air pressure in a sound wave, 345, 372
Airy functions, 596
alternating current. See electric current
alternating series, 17, 34
Ampere’s law, 329
amplitude:
of a complex number, 49
of an elliptic integral, 555
of a sinusoidal function, 341
of vibration, 341
AM radio signal, 347
analytic at a point, 667
analytic at inﬁnity, 703–704
analytic geometry using vectors, 106
angle:
of a complex number, 49
in n dimensions, 143, 145
between planes, 112
solid, 320
between vectors, 102
angular frequency, 80
angular momentum, 289 (Problem 9)
angular velocity, 278, 515
annihilation operators, 607
annular ring, 679
antisymmetric matrix, 138
antisymmetric tensor, 503, 509
applications to physics problems. See
individual topics
approximation(s):
by asymptotic series, 549 ﬀ, 552
for Bessel functions, 604
using diﬀerentials, 196–199
of integral, 198
“least squares”, 214 (Problem 16),
581, 774 (Problem 1)
of ln N!, 537
by normal distribution, 762, 769
using series, 33, 38 (Problems 40 ﬀ)
arc length, 250, 266, 521
in cylindrical coordinates, 260, 521
of ellipse, 556
metric tensor, 524
in orthogonal systems, 521
in polar coordinates, 259, 266, 521
in rectangular coordinates, 250
in spherical coordinates, 261. See
also 523–524
vector element, 319
arc tan series, 30
area, 249. See also surface
under a curve, 249
element on a sphere, 261
element on a surface, 271
as measure of probability, 751
of parallelogram, 279
811

812
INDEX
in polar coordinates, 258
sec γ method, 271
of surface of revolution, 254
Argand diagram, 48
argument of a complex number, 49
argument principle, 694
ﬁnding zeros, 695
arithmetic mean, 771
arrow representing a rotation, 497
arrow representing a vector, 96
associated Legendre functions, 583
associated tensors, 533
associative law
for matrix multiplication, 139
for vector addition, 97
asymptotic series, 549 ﬀ
audio frequency, 347
augmented matrix, 85
auxiliary equation, 409 ﬀ
average value. See also mean value
of a function, 347 ﬀ
of products of sines and cosines, 351
of sin2 x and cos2 x, 349
axes
along eigenvector directions, 151
principal, 162
real and imaginary, 48
rotation of, 126, 127, 498
axial vector, 515
left-handed coordinate system, 515
in physics formulas, 517
right-hand rule, 515
bacteria, growth of, 1, 399
balls in boxes, 739 ﬀ
distinguishable and indistinguishable,
741
identical, 740
basic interval in Fourier series, 350, 360
basis, 143 ﬀ
change of, 127, 708
orthonormal, 145
basis functions, 357
completeness relation, 375
complete set of, 375–377
basis vectors. See also basis functions;
unit basis vectors
complete set of, 576
covariant and contravariant, 530
in curvilinear coordinates, 522
in general coordinates, 533
i, j, k, 100
Bauer’s formula, 618
Bayes’ formula, 732
beam carrying load, 496
Bernoulli equation, 404, 431
Bernoulli trials, 756
Bessel coeﬃcients, 617
Bessel functions, 587 ﬀ
Airy functions, 596
applications, 587
approximate formulas, 604
asymptotic formulas, 604
ber, bei, ker, kei, 596
diﬀerential equations, 588, 593, 594
ﬁrst kind, 589, 595
generating function, 616
graphs, 591
Hankel functions, 595
hyperbolic, 595
integrals involving, 617
Kelvin functions, 596
modiﬁed, 595
Neumann function, 591
normalization of, 602–603
order, 589
orthogonality, 601 ﬀ
recursion relations, 592
second kind, 591, 595
second solution, 590
series of, 640 ﬀ
spherical, 596
third kind, 595
Weber function, 591
zeros, 591
Bessel’s inequality, 376
beta functions, 542 ﬀ
in terms of gamma functions, 543
integrals, 542, 543
binomial coeﬃcients, 28 ﬀ, 192, 567,
609, 739
binomial distribution, 756 ﬀ
mean value and standard deviation, 763
normal approximation, 762
Poisson approximation, 768
binomial series, 28 ﬀ. See also bino-
mial coeﬃcients
binomial theorem, 28 ﬀ

INDEX
813
bipolar coordinates, 525 ﬀ
birthdays, 743
books, pile of, 44
Bose-Einstein statistics, 742
bouncing ball, 1
boundary conditions, 393, 625, 631,
634, 711
boundary point problems, 223 ﬀ
boundary value problems, 625, 711
bounded function, 356
brachistochrone, 473, 482, 484
branch, branch cut, branch point, 693
Bromwich integral, 696
butterﬂy net, 328
calculator. See also computer
degree and radian mode, 49, 52
calculus of variations, Chapter 9
brachistochrone, 473, 482, 484
Euler equation, 474, 477
Fermat’s principle, 473, 484
geodesics, 472 ﬀ
isoperimetric problems, 491
Lagrange’s equations, 485 ﬀ
soap ﬁlm, 473, 480
variational notation, 493
Caley-Hamilton theorem, 161, 187
capacitor, 323
fringing at edge of, 714–716
car, acceleration of, 33
carrier wave, 347
Cartesian tensors, 498, 500
Cartesian vectors, 499
catenary, 480
Cauchy diﬀerential equation, 434
Cauchy principal value, 692
Cauchy-Riemann conditions, 669 ﬀ,
673-674, 720
Cauchy’s integral formula, 675
Cauchy’s theorem, 674
center of mass, 251 ﬀ
central limit theorem, 774
centripetal acceleration, 487
centroid, 251 ﬀ
chain rule, 199 ﬀ, 203 ﬀ
in matrix form, 205
chain suspended, 467, 473
change of basis, 127, 708.
See also
change of variables
linear transformations, 125
in n dimensions, 143
orthogonal transformations, 126
change of variables, 228 ﬀ. See also
change of basis
in a diﬀerential equation, 228, 406,
431, 434
general transformations, 529
in integrals, 258 ﬀ
rectangular to cylindrical, 260
rectangular to polar, 258
rectangular to spherical, 261
rotation, 127, 498
character (group), 175
characteristic equation for a diﬀeren-
tial equation, 409
characteristic equation of a matrix, 148
characteristic frequencies, 165–166, 636,
644
characteristic functions, 566, 625. See
also eigenvalue problems
characteristic modes of vibration, 166,
636, 645
characteristic values, 148 ﬀ. See also
eigenvalue problems
characteristic vectors, 148 ﬀ
Chebyshev’s inequality, 759
circuit. See electric circuits
circular membrane, 644 ﬀ
circulation, 325 ﬀ
class (group) 175
cn u, 558
coeﬃcients
in Bessel series, 641-642
binomial, 28 ﬀ, 192, 567, 609, 739
determinant of, 93, 148
in Fourier series, 350
in Legendre series, 580–581
in Maclaurin series, 24
matrix of, 84
in Taylor series, 24
in two-variable power series, 191
undetermined, 421
cofactor, 90
coin, weighted, 727
coldest points of a plate, 224
collectively exhaustive, 723
color, 346, 378
column matrix, 114

814
INDEX
columns. See determinants or matrices
column vector, 114
combinations of measurements, 772 ﬀ
combinations or selections, 737 ﬀ
commutative law
for scalar multiplication, 101
for vector addition, 97
not for vector multiplication, 103
commutator, 117, 122, 141
comparison test, 10
special, 15
complementary error function, 547
complementary function, 417
complete elliptic integrals, 555
complete set of basis functions, 375–377
complete set of basis vectors, 576
complex acceleration, 56
complex conjugate, 50, 52
of a matrix, 137
roots of auxiliary equation, 411
complex eigenvalues, 156
complex equations, 54 ﬀ
complex Euclidean space, 146
complex exponentials, 60 ﬀ
in diﬀerential equations, 420
in evaluating integrals, 351
complex Fourier series, 358 ﬀ
complex impedance, 78
complex inﬁnite series, 56 ﬀ, 678 ﬀ.
See also series; power series
complex numbers, Chapter 2
absolute value, 49, 53
angle, 49
combining, 51, 60, 63
conjugate, 50, 52, 53
deﬁnition, 46
elementary functions of, 60 ﬀ
imaginary part, 47
laws of exponents for, 60
modulus, 49
plotting, 48, 666
polar form, 48, 50 ﬀ
real part, 47, 49
rectangular form, 48, 51
complex plane, 47 ﬀ, 666 ﬀ
complex potential, 713
complex powers and roots, 73
complex power series, 58, 678
complex variable, functions of,
Chapter 14
complex velocity, 56, 717
components, 82, 96
scalar and vector, 100
of a tensor, 496 ﬀ, 499 ﬀ
of a vector, 100 ﬀ, 497
compound interest, 3
computer, See also calculator
comments about use, xii, 3, 36, 63,
93, 196, 241, 402, 408, 537, 562,
699 (see also instructions and
comments in problem sets)
examples of use, 31, 66, 249, 357,
393–394, 397, 605, 624, 646, 762,
768 (see also individual prob-
lem sets)
conditionally convergent series, 18
conditional probability, 732
conﬁdence interval, 774
conformable matrices, 116
conformal mapping, 708 ﬀ
applications, 710 ﬀ
conic section, principal axes, 162
conjugate element, 175
conjugate harmonic functions, 672
conjugate of a complex number, 50,
52, 53
conjugate of a matrix, 137
conservation of energy, 433
conservative ﬁeld, conservative force,
302 ﬀ, 325, 330 ﬀ
constraints, 214, 488
continuity, equation of, 317
continuous distributions, 750–751
contour integrals, 674, 676–678
for inverse Laplace transform, 696
problems, 699 ﬀ
by residues, 687 ﬀ
contour lines, 290
contour map, 295
contraction of a tensor, 502 ﬀ
contravariant vector or tensor, 530 ﬀ
convergence, 3, 6–7
absolute, 10
conditional, 18
disk of, 58
of Fourier series, 356
of inﬁnite series, 2, 7, 9 ﬀ

INDEX
815
interval of, 20
of Legendre series, 580
of power series, 2, 7, 9 ﬀ, 20
radius of, 58
of a series to a function, 23
tests for, 10 ﬀ
convolution, 444, 446, 447, 471
cooling, Newton’s law of, 400
coordinate lines, 522
coordinates
bipolar, 525 ﬀ
curvilinear, 521 ﬀ
cylindrical, 260, 521, 525 ﬀ(see also
cylindrical coordinates)
elliptic cylinder, 524 ﬀ
general, 523, 525, 529, 531
orthogonal, 525, 533
in n dimensions, 143
non-orthogonal, 533
parabolic, 525 ﬀ
parabolic cylinder, 524 ﬀ
polar, 258 ﬀ(see also polar coordi-
nates)
spherical, 261 ﬀ, 529 (see also spher-
ical coordinates)
and variables, 258
coordinate surfaces, 522
coordinate transformations, Chapters
3 and 10. See also transforma-
tions; linear transformations;
orthogonal transformation;
rotation
Coriolis acceleration, 487
correspondence principle, 197
cosh z, 70
cosine
of angle between vectors, 102
of angles between axes, 164
of complex number, 67
Fourier series, 366
Fourier transform, 382
hyperbolic, 70
inverse, 74
power series for, 26, 69
cos nθ as a determinant, 96
Coulomb’s law, 304, 320
counting, fundamental principle of,
737
coupled pendulums, 490
covariant vector or tensor, 530 ﬀ
Cramer’s rule, 93–94
creation operators, 607
critically damped motion, 413
cross product, 103 ﬀ, 276
in tensor form, 516
cumulative distribution function, 748
curl, 296
and angular velocity, 325
and conservative ﬁelds, 302 ﬀ, 324,
331 ﬀ
in orthogonal coordinates, 527
and Stokes’ theorem, 313, 324, 327 ﬀ
in tensor notation, 511
curvature, 435
curve
arc length of, 250, 266, 521 (see also
arc length)
integral along, 299
simple, 330, 674
smooth, 674
tangent line to, 203
curve ﬁtting, 214, 581
curvilinear coordinates, 521. See also
orthogonal curvilinear coordi-
nates
cyclic group, 172
cycloid, 482, 483, 546
cylinder functions, 587. See also Bessel
functions
cylindrical coordinates, 260
arc length element, 266
curl, 527
div, 298, 526
grad, 294, 525
Laplace’s equation, 639
Laplacian, 298, 527
scale factors and unit basis vectors,
522
velocity and acceleration, 523
volume element, 260, 261, 524
damped motion, 413–414
damping, critical, 413
d-c generator voltage, 374
decay constant, 39, 395, 402
deﬁnite integrals. See integrals
deformation of elastic membrane, 148
degeneracy, 152, 647

816
INDEX
degenerate subspace, 153
degree mode, 49
degrees and radians, 49
∇(del), 296
δ (delta, variation), 493
δ function (Dirac delta function), 449 ﬀ
deﬁnition, 452
derivatives of, 454
distribution (generalized function),
450
formulas involving, 455
Fourier transform of, 454
generalized function identities, 455
generalized functions, 450
impulse, 449
Laplace transform of, 453
operator equations, 456, 457
physical applications, 450, 454, 457
in 2 or 3 dimensions, 456
unit impulse, 449
δ (Kronecker delta), 138–139, 508 ﬀ
use in formulas, 510 ﬀ
in general coordinates, 531
inertia tensor, 505, 519
isotropic tensor, 509
DeMoivre’s theorem, 64
density
mass, 246 ﬀ, 250
probability, 753 (see also probabil-
ity functions)
source and sink, 714
dependent equations, 87
dependent functions, 133
dependent variable
diﬀerential of, 193
in Euler equation, 479
missing in diﬀerential equation, 430
derivatives. See also diﬀerentiation
using diﬀerentials, 201
directional, 290 ﬀ, 710 (Problem 15)
of functions of z, 668
of integrals (Leibniz’ rule), 233 ﬀ
normal, 293
partial, 189 (see also partial diﬀer-
entiation)
of products (Leibniz’ rule), 567
of vectors, 285
determinant(s), 89 ﬀ
of coeﬃcients, 93, 148
cofactors, 90
evaluating, 89–90
formula using ϵijk, 509
Laplace development, 90 ﬀ
of a matrix, 89
minor, 89
order of, 80
product of, 118
secular, 148
useful facts about, 91
Wronskian, 133, 136 (Problem 16)
diagonalization of matrices, 148 ﬀ
applications, 162 ﬀ
Hermitian, 153
simultaneous, 158
symmetric, 154
diﬀerential equations.
See ordinary
diﬀerential equations; partial dif-
ferential equations
diﬀerential operators, 409, 415–416,
566
diﬀerentials, 193
approximate calculations using,
196 ﬀ
change of variables using, 228 ﬀ
exact, 305, 331
ﬁnding derivatives using, 200
of independent and dependent vari-
ables, 193
principal part, 194
relation between, in two coordinate
systems, 529
tangent approximation, 193
total, 193, 194
diﬀerentiation. See also derivatives
chain rule for, 199 ﬀ, 203 ﬀ
of Fourier series, 369
implicit, 201, 202 ﬀ, 215
of integrals, 233 ﬀ
partial, 188 ﬀ(see also partial dif-
ferentiation)
of power series, 23
of vectors, 285 ﬀ
diﬀraction, Fresnel, 37
diﬀusion equation, 297, 619, 628 ﬀ.
See also heat ﬂow
diﬀusivity, 619
dimension of a vector space, 144
dipole moment, 574

INDEX
817
Dirac delta function. See δ function
directional derivative, 290 ﬀ, 710
direction cosines, 164, 498
direction ﬁeld, 393, 394
direct product, 501
Dirichlet conditions, 356 ﬀ
Fourier integrals, 379
Fourier series, 356, 362
Legendre series, 581
Dirichlet problem, 631
discriminant, 46
disk of convergence, 58
dispersion relations, 698
dispersion, variance, 747
displacement vector, 286, 498
distance
minimum, 214, 216, 221–222, 225
between points, 143
point to line, 110–111
point to plane, 110
between skew lines, 111
distinguishable arrangements, 741
distribution functions, 748
distribution(s)
binomial, 756
continuous, 750, 751
discrete, 750, 751
generalized function, 450
joint, 754
normal, 761
Poisson, 767
distributive law, 102, 104
divergence, 296
in cylindrical coordinates, 298, 526
in orthogonal coordinates, 526
physical meaning, 316
in tensor notation, 533
divergence theorem, 318 ﬀ
and Gauss’s law, 318, 320
use of, 319
divergent series, 6 ﬀ
dividing
complex numbers, 51, 63
series, 23, 27–28, 59
dn u, 558
dot meaning d/dt, 165
dot product, 101, 276
double factorial, 29
double integrals, 242 ﬀ
double pendulum, 490
drumhead, vibrating, 644 ﬀ
dual tensors, 512
dummy index, 502
dummy variable, 380, 541
earth, gravitational potential of, 484
eccentricity, 557
eﬀective value of current, 348
eigenfunctions. See eigenvalue prob-
lems
eigenplane, 153
eigenvalue problems, 135, 148 ﬀ
boundary value problems, 625
diﬀerential equations, 566
linear equations, 135
matrices, 148 ﬀ
partial diﬀerential equations,
625–626, 630, 632, 636
eigenvalues, 148 ﬀ.
See also eigen-
value problems
complex, 156
real, 154
eigenvectors, 148 ﬀ.
See also eigen-
value problems
Einstein summation convention, 502 ﬀ
elastic medium:
deformed membrane, 148
string in, 665
electric charge, 18, 304, 317, 320–322
problems, 289, 323, 336
electric circuits, 77, 390–391
complex impedance of, 77
diﬀerential equation for, 391, 414, 444
impulse applied to, 450 ﬀ
electric current, 329–330, 344.
See
also electric circuits
distribution in wire (skin eﬀect), 596
root-mean-square, 348
electric-dipole moment, 573–575
electric ﬁeld, 304–305, 317, 320–322,
712–713, 714 ﬀ
problems, 295, 308, 323, 716
electric oscillations, 340, 426 ﬀ, 444
electric quadrupole moment, 573–575
electric resistance, 197
electromagnetic force, 285, 289, 336
electromagnetic theory, 329
electron, 42, 394, 467

818
INDEX
electrostatic potential, 304
of charge distribution, 492, 573 ﬀ,
652–655
by conformal mapping, 711 ﬀ
Legendre expansion of, 571 ﬀ,
574 (Problem 15)
maximum on boundary, 720
by method of images, 657
multipole expansion of, 571–573
of point charge outside grounded sphere,
655 ﬀ, 657–658
Poisson’s equation for, 652 ﬀ
zero at inﬁnity, 655
elementary functions, 60
of complex numbers, 60
derivatives of, 60, 61
power series for, 26
elementary row operations, 86
elements
arc length, 250, 259, 266–267, 521 ﬀ
area, 244 ﬀ, 250, 258, 267, 271
cylindrical coordinates, 260–261, 264, 266
of a determinant, 89
of a group, 172
mass, 251
of a matrix, 89
polar coordinates, 258–259, 266, 521
spherical coordinates, 261, 264–266, 524
surface area, 255, 270 ﬀ, 317
volume, 243, 246, 253, 260 ﬀ, 524
ellipse, 163
arc length, 556
principal axes of, 163
ellipsoid, box inscribed in, 218 ﬀ
elliptic cylinder coordinates, 524 ﬀ
elliptic functions, 558
elliptic integrals, 555
endpoint and boundary point prob-
lems, 223 ﬀ
energy
conservation of, 433
of harmonic oscillator, 342, 348, 545
kinetic, 342, 348, 433, 485, 545
problems, 488–491, 545
of a particle, 433
potential, 303, 433, 485
in a sound wave, 373
equally likely, 723
equation(s). See also individual equa-
tions
auxiliary, 409 ﬀ
characteristic
for diﬀerential equation, 409
for matrix, 148
complex, 54 ﬀ
of continuity, 317
diﬀerential, Chapters 8, 12, 13
homogeneous algebraic, 134 ﬀ
inconsistent, 86, 87
indicial, 586
linear algebraic, 82 ﬀ
of lines and planes, 106 ﬀ
of normal line, 109, 293
partial diﬀerential, Chapter 13
of surfaces of revolution, 257(Prob-
lem 16)
of tangent line, 203
of tangent plane, 293
equator, 239
equipotentials, 290
erfc, 549 ﬀ
erﬁ, 548
error
in alternating series, 34
in asymptotic series, 550-551
probable, 774
relative, 197, 775
in series computation, 34
standard, 722
error function, 547
errors, combination of, 772 ﬀ
escape velocity, 435
essential singularity, 680
Euclidean space, 142 ﬀ
complex, 146 ﬀ
Euler (Cauchy) diﬀerential equation,
434
Euler (Lagrange) equation, 474, 477 ﬀ
Euler’s formula, 61
Euler’s theorem on homogeneous
functions, 238
evaluating integrals, 243 ﬀ, 687 ﬀ
even functions, 364
events, 723
compound, 730
independent, 731
mutually exclusive, 723

INDEX
819
exact diﬀerential, 305, 331
exact diﬀerential equations, 405
expectation, expected value, 747
experimental measurements, 770 ﬀ
exponential Fourier series, 358 ﬀ
exponential function, 60, 419
complex, 67, 420 ﬀ, 428–429
exponential integral, 552
exponential series, 26, 61
exponential shift, 424
exponents, laws for complex numbers, 73
extremal, 474, 475
factorial, 4, 538
factor, integrating, 401, 405
double, 29
function, 4, 538
gamma function, 538
Stirling’s formula, 552
zero factorial, 4, 538
falling body, 392, 400
falling book, 506
Faltung, 446
family of curves, 395–396
Fermat’s principle, 473, 484
Fermi-Dirac statistics, 742
ﬁelds, 290
conservative, 302, 330, 332
electric (see) electric ﬁelds
gravitational (see) gravitational force
irrotational, 332
lamellar, 332
magnetic, 329, 335, 714
scalar, 290, 303 ﬀ, 332
solenoidal, 332
tensor, 520
vector, 290, 325, 332, 520
velocity, 290, 314
ﬁlter, 430
ﬁnite groups, 172
ﬁrst integral
of a diﬀerential equation, 433
of the Euler equation 479
Florida, highest point, 223
ﬂow of water, 317, 325
circulation, 326
by conformal mapping, 713 ﬀ
equation of continuity, 317
irrotational, 713
out of channel, 714 ﬀ
sources and sinks, 714 ﬀ
ﬂuid ﬂow, 325. See also ﬂow of water
ﬂuid, incompressible, 324
ﬂux, 316
force
conservative, 303 ﬀ, 325
electromagnetic, 329
electrostatic, 304
friction, 302
gravitational (see) gravitational force
impulsive, 449
inverse square, 304, 320, 468, 571, 652
moment of, 277
periodic, 427
forced vibrations, 417 ﬀ, 426ﬀ
forcing function. See forced vibrations
Fourier-Bessel series, 641
Fourier coeﬃcients, 350 ﬀ
Fourier integrals, 378 ﬀ. See also Fourier
transforms
Fourier integral theorem, 379
Fourier series, Chapter 7
applications in physics, 345, 372 ﬀ,
428 ﬀ, 623 ﬀ, 629–638
complex form, 358 ﬀ
convergence, 356
cosine series, 366
diﬀerentiating, 369
Dirichlet conditions, 355–358
double, 643
even and odd functions, 364 ﬀ
exponential, 358 ﬀ
in ordinary diﬀerential equations, 428
Parseval’s theorem, 375
in partial diﬀerential equations, Chap-
ter 13, Sections 1–4
period 2l, 360 ﬀ
period 2π, 350 ﬀ
sine-cosine form, 350 ﬀ
sine series, 366
triple, 643
Fourier transform(s), 378 ﬀ
applications of, 454
convolution, 447
cosine, 382
of delta function, 454
Dirichlet conditions, 379
exponential, 379

820
INDEX
factor 1/(2π), 381
and Fourier series, 378
Parseval’s theorem, 383
partial diﬀerential equations, solu-
tions to, 660–662
sine, 381
4’s group, 172
free vibrations, 80, 417
frequencies, characteristic, 165, 636,
644
frequency, 343
angular, 80, 344
continuous, 378
of damped vibrations, 413, 414
of light, 346, 378
modulation, 617
natural undamped, 427
resonance, 427
in a sound wave, 345, 373
frequency function, 746. See also prob-
ability function
Fresnel integrals, 37, 549 (Problem 6),
701 (Problem 41)
friction, 302, 412
fringing at edge of capacitor, 714–716
Frobenius method, 585 ﬀ, 605
Fuch’s theorem, 605
functions
analytic, 667 ﬀ
associated Legendre, 583, 648
average value of, 347 ﬀ
Bessel, 587 ﬀ(see also Bessel func-
tions)
beta, 542 ﬀ
bounded, 356
characteristic, 566, 625 (see also eigen-
value problems)
complementary, 417
of a complex variable, Chapters 2
and 14
conjugate harmonic, 672
cumulative distribution, 748
delta, 449 ﬀ
dependent and independent, 133
discontinuous, 224, 346
elementary, 60, 668
elliptic, 558
error, 547, 763
complementary, 547
even, 364
exponential, 60, 419
factorial, 4, 538
forcing, 417, 426, 444, 449
gamma, 538 ﬀ, 694
generalized, 450
harmonic, 671 ﬀ(see also Laplace’s
equation)
Hermite, 607 ﬀ
holomorphic, 667
homogeneous, 238, 406, 407 (Prob-
lem 21)
hyperbolic, 70
Kelvin, 596
Laguerre, 609
Legendre, 564 ﬀ
ln, 72, 667
of a matrix, 121
meromorphic, 681
monogenic, 667
multiple-valued, 667
Neumann, 591
normalized, 578 ﬀ, 584
not having a derivative, 669
odd, 364
orthogonal, 575 ﬀ
complete sets of, 575
orthonormal, 579
periodic, 343
probability, 745 ﬀ
rational, 60
regular, 667
of several variables, Chapter 4 (see
also partial diﬀerentiation)
sinusoidal, 341
transfer, 444
fundamental, 345
fundamental principle of counting, 737
fundamental theorem of algebra, 701
g, gij, gij, 533
gamma function, 538ﬀ
asymptotic series for, 553
in Bessel function formulas, 589
deﬁnition: for p > 0, 538;
for p ≤0, 540
incomplete, 551 (Problem 2)
recursion relation, 538, 539
Stirling’s formula, 552

INDEX
821
Gaussian distribution, 547
Gauss’s law, 318, 320
Gauss’s theorem, 318
gd u, 559
general coordinate systems, 529 ﬀ
generalized function, 450
generalized power series, 585
general solution of a diﬀerential equa-
tion, 392, 402, 410, 411, 418
generating function:
Bessel functions, 616
Hermite polynomials, 609
Laguerre polynomials, 610
Legendre polynomials, 569
geodesics, 472 ﬀ
on a cone, 481
in a plane, 477
geometrical meaning of:
complex equations, 54, 55
covariant and contravariant vectors,
530
diﬀerentials, 193
linear transformations, 126 ﬀ
real equations, 188
total diﬀerentials, 194
geometric progression, geometric se-
ries, 1
Gibb’s phenomenon, 357
gradient, 290 ﬀ, 294, 525
normal to surface, 293
in orthogonal coordinates, 525
in polar coordinates, 294, 525
in tensor notation, 533
grading “on a curve”, 766
Gram-Schmidt method, 145–146, 182–
183
graphical representation of
complex equations, 55
complex numbers, 45
functions, 188
roots of a complex number, 65 ﬀ
gravitational ﬁeld. See gravitational
force
gravitational force, 302 ﬀ, 392, 571 ﬀ
problems, 308, 416, 435, 467,
489–90, 494
gravitational potential, 290, 330. See
also potential
inside earth, 308, 484
outside earth, 308
Green functions, 461, 657
response to unit impulse, 461
solution of ordinary diﬀerential equa-
tions, 462 ﬀ
solution of partial diﬀerential equa-
tions, 657–658
variation of parameters, 464, 465
Green’s theorem in the plane, 675 ﬀ
Green’s theorems, 324
grid of curves or surfaces, 258, 261
group(s), 172 ﬀ
Abelian, 175
character, 175
class, 175
closure, 175
conjugate element, 175
cyclic, 172
deﬁnition, 172
element, 172
ﬁnite, 172 ﬀ
4’s group, 172
inﬁnite, 176
isomorphic, 174
multiplication table, 173 ﬀ
order, 173
product, 172, 173
representation, 172
dimension of, 176
irreducible, 176
matrix, 175
subgroup, 173
symmetry group:
of equilateral triangle, 174
of rectangle, 178 (Problem 11)
of square, 178 (Problem 10)
unit element, 172
growth of bacteria, 1, 399
Gudermannian, 559
half-life, 399
half-value thickness, 399
Hamiltonian, 233
Hamilton’s principle, 485
hanging chain, 473
Hankel functions, 595
harmonic analysis, 345
harmonic functions, 671, 720. See also
Laplace’s equation

822
INDEX
harmonic oscillator. See simple har-
monic motion
harmonics, 373
harmonic series, 11, 12
alternating, 17 ﬀ
heat ﬂow, 291, 619, 621 (Problem 4),
628 ﬀ
in a bar or slab, 629, 659
across a boundary, 627–631
conformal mapping solution, 711 ﬀ
diﬀerential equation, 390 (see also
partial diﬀerential equations)
Laplace transform solution, 659–660
partial diﬀerential equation, 619, 628 ﬀ
separation of variables solution, 628
temperature gradient, 293, 295
Helmholtz equation, 620, 629, 645
Hermite functions, 607 ﬀ
diﬀerential equation, 607
ladder (raising and lowering) oper-
ators, 607
Hermite polynomials, 608
diﬀerential equation, 608
generating function, 609
normalization, 608
orthogonality, 608
table of, 804
Hermitian adjoint, 137
Hermitian conjugate, 137
Hermitian matrix, 138
higher derivatives by implicit diﬀeren-
tiation, 202
highest point in Florida, 223
high ﬁdelity, 346
Hilbert transform, 698
histogram, 751
holomorphic function, 667
homogeneous algebraic equations, 134
homogeneous diﬀerential equations, 406,
408 ﬀ
homogeneous functions, 238, 406,
407 (Problem 21)
Hooke’s law, 519
hoop, 490
horizon, distance to, 43
hottest points of a plate, 224
hydrodynamics, 713. See also ﬂow of
water
hydrogen atom, 614 (Problems 27, 28),
652 (Problem 22)
hyperbolic Bessel functions, 595
hyperbolic functions, 70
identities, 71
inverse, 74
integrals leading to, 75
i, 46 ﬀ
identities. See also recursion relations
Bessel, 592
Legendre, 570
trigonometric, 69, 71
vector, 339
identity matrix, 118
images in conformal mapping, 705
images, method of, 657
imaginary axis, 48
imaginary numbers, Chapter 2
imaginary part of a complex number,
47
impedance, complex, 78
implicit diﬀerentiation, 201, 202 ﬀ, 215
improper rotation, 514
impulse, unit impulse, 449
incomplete gamma function, 551
incompressible ﬂuid, 324
inconsistent equations, 86, 87
indeﬁnite integrals, 241 ﬀ
independent events, 731
independent random variables, 756
independent variable
change of, 431, 434
missing, in diﬀerential equation, 431
diﬀerential of, 193
in Euler equation, 480
in maximum, minimum problems, 212
in partial diﬀerentiation, 207
independent vectors, 132
indeterminate forms, 38
index, dummy, 502
index notation, 138
index of refraction, 474, 478
indicial equation, 586
inertia, moment of, 252 ﬀ, 505. See
also moment of inertia
inertia tensor, 505 ﬀ, 519
extended body, 506
matrix, 507

INDEX
823
point mass, 506
principal axes, 507
inﬁnite group, 176
inﬁnite series, Chapter 1. See also
series; power series; Fourier
series; Legendre series
complex, 56
inﬁnity, 702 ﬀ
asymptotic series about, 549–551
residues at, 703
inhomogeneous linear diﬀerential equa-
tion, 417
initial conditions, 393
inner product, 100
insulated boundary, 631
integral representations of functions
analytic, 676
Bessel, 617
beta, 542
error, 549
gamma, 538
integrals
arc length, 250
area, 242, 249
around inﬁnity, 703
beta function, 542
Bromwich, 696
change of variables in, 258 ﬀ
contour, 674 ﬀ, 676–678, 687 ﬀ, 696
in cylindrical coordinates, 260 ﬀ
diﬀerentiating, 233
divergence theorem, 318
double, 242 ﬀ, 249 ﬀ, 262, 270
elliptic, 555
error function, 547
evaluated by contour
integration, 687 ﬀ
evaluated in terms of inverse hyper-
bolic functions, 75
evaluated using complex exponen-
tials, 69, 351
evaluated using series, 37, 548
evaluating, 243 ﬀ, 687 ﬀ
Fourier, 378
Fresnel, 37, 549 (Problem 6), 701
(Problem 41)
gamma function, 538
improper, 539
indeﬁnite, 241 ﬀ
iterated, 243 ﬀ
as “limit of sum”, 249
limits on, 243 ﬀ
line, 299
mass, 246, 250
moment of inertia, 252, 259, 264 ﬀ
in polar coordinates, 258 ﬀ
of power series, 23, 37
principal value of, 692
by residues, 687 ﬀ
setting up, 242, 253
in spherical coordinates, 260 ﬀ
Stokes’ theorem, 328
surface, 253, 270 ﬀ
through a simple pole, 691
triple, 242 ﬀ
volume, 242 ﬀ
volume and surface of revolution,
252 ﬀ
integral test, 11 ﬀ
integral transforms, 378 ﬀ, 437 ﬀ
Fourier, 378 (see also Fourier trans-
forms)
Hilbert, 698
Laplace, 437 ﬀ(also see Laplace trans-
forms)
integrating factor, 401, 405
integration. See integrals
intensity of a sound wave, 376
interior maxima and minima, 223 ﬀ
interval of convergence, 20
invariant, 500
inverse exponential shift, 424
inverse Fourier transform (Bromwich
integral), 696
inverse hyperbolic functions, 74
integrals expressed in terms of, 75
inverse Laplace transforms, 440
by contour integration (Bromwich
integral), 696
of a product (convolution), 445 ﬀ
using the table, 440 ﬀ
inverse matrix, 119, 137
inverse of a product of matrices, 140
inverse operators, 424
inverse square force, 304, 320, 571,
652
inverse trigonometric functions, 74
invertible matrix, 119

824
INDEX
irrotational ﬁeld, 325
isolated singular point, 670
isoperimetric problems, 491
isothermals, 290, 295, 712
isotropic tensors, 509
Kronecker delta, 509
Levi-Civita tensor, 510
product of, 510
j, 49
Jacobian, 261 ﬀ, 283, 536 (Problem
12), 710 (Problems 12, 13)
Jacobi forms of elliptic integrals, 555
Jacobi identity, 141, 284, 514
joint probability, 754
Kelvin functions, 596
Kepler’s second law, 495
kinetic energy, 342, 348, 433, 485, 545.
See also energy
kinetic theory applications, 237, 239
kite, 116
Klein-Gordon equation, 665
Kronecker δ, 138–139, 508 ﬀ
in general coordinates, 531
ladder (raising and lowering) opera-
tors, 607, 614 (Problems 29, 30)
Lagrange multipliers, 214, 216 ﬀ, 491
Lagrange’s equations, 485 ﬀ
in polar coordinates, 486
in spherical coordinates, 487
Lagrange’s identity, 106, 284, 514
Lagrangian, 485 ﬀ, 545
Laguerre functions, Laguerre polyno-
mials, 609 ﬀ
associated, 610
generating function, 610
list of, 804
recursion relations, 610, 611
Rodrigues’ formula, 609,
lamellar ﬁeld, 332
lamina, 248, 256
Laplace development, 90 ﬀ
Laplace’s equation, 297, 619, 621 ﬀ,
638 ﬀ, 648 ﬀ, 711
conformal mapping solutions, 711 ﬀ
in cylindrical coordinates, 527, 639
electrostatic potential problems, 712
ﬂuid ﬂow problems, 713
Fourier transform solution, 660 ﬀ
gravitational potential, 652
in one dimension, 629
in orthogonal coordinates, 527
in polar coordinates, 229
separation of variables, 622
in spherical coordinates, 298, 527,
648
temperature problems, 621 ﬀ, 711,
712
in tensor notation, 533
in two dimensions, 671
Laplace transforms, 437 ﬀ
convolution, 444 ﬀ
of delta functions, 453
of derivatives, 440
evaluating integrals using, 442
ﬁnding, 437 ﬀ
inverse, 440 ﬀ, 444, 696 (see also
inverse Laplace transform)
solving ordinary diﬀerential equa-
tions by, 440 ﬀ
solving partial diﬀerential equations
by, 659
table of, 469–471
Laplacian, 297. See also Laplace’s equa-
tion
Laurent series, 678 ﬀ
Laurent’s theorem, 678
law of large numbers, 759
law of reﬂection, 474
“least squares,” 214 (Problem 16), 581,
774 (Problem 1)
left-handed system, 515
Legendre equation, 564. See also Leg-
endre polynomials
Legendre forms of elliptic integrals, 555
Legendre functions, 564 ﬀ. See also
Legendre polynomials
associated, 583
ﬁrst and second kinds, 567
Legendre polynomials, 566 ﬀ
applications, 571 ﬀ, 581, 648 ﬀ, 656–
657
generating function, 569
by Gram Schmidt method, 182–183
list of, 803
normalization, 578 ﬀ
orthogonality, 577

INDEX
825
raising and lowering operators, 607,
618
recursion relations, 570
Rodrigues’ formula, 568
Legendre series, 580 ﬀ, 649
Legendre transformation, 231,
233 (Problems 10 to 13)
Leibniz’ rule:
for diﬀerentiating integrals, 233 ﬀ
for diﬀerentiating products, 567
lengthening pendulum, 598
length of arc. See arc length
length of a vector, 96
lenses, 198
level lines, 290
level surfaces, 290
lever problem, 277
Levi-Civita symbol ϵijk, 508 ﬀ, 515
in determinant formula, 509
isotropic tensor, 510
products of, 510
L’Hˆopital’s rule, 38, 685
light. See also optics applications
absorption, 399
color, 346, 378
continuous spectrum, 378
frequency, 346, 378
parabolic mirror, 407
pulse, 382
scattering, 389
waves, 346, 378
limits on an integral, 243 ﬀ
line(s)
distance between skew, 111
distance from point to, 110–111
equations of, 106 ﬀ
parametric, 108
symmetric, 107–108
normal, 109, 293
perpendicular to plane, 109
tangent to curve, 203
linear absorption coeﬃcient, 399
linear algebra, Chapter 3
linear algebraic equations, 82 ﬀ. See
also determinants; matrices;
matrix
Cramer’s rule, 93–94
homogeneous, 134
matrix solution of, 119–120
solution in vector form, 134
standard form, 84
linear combination, 124
linear dependence, 132
linear diﬀerential equations, 401, 408,
417. See also diﬀerential
equations
linear functions, 124
linearly independent functions, 133
linearly independent vectors, 144
linear operators, 124, 425, 438
linear space. See linear vector space
linear transformations, 125. See also
transformations; orthogonal
transformations
deformation of membrane, 148 ﬀ
eigenvectors of, 148 ﬀ
matrix of, 125, 148
orthogonal, 126
linear triatomic molecule, 167 ﬀ
linear vector space, 143 ﬀ, 179 ﬀ
basis, 143 ﬀ(also see) basis
complex Euclidean, 146 ﬀ
deﬁnition, 142, 179
dimension, 144
Euclidean, 142 ﬀ
examples, 143 ﬀ, 180–181
function space, 180, 414–415 (Prob-
lems 13 to 18)
general, 179
Gram-Schmidt process, 145, 182–183
inﬁnite dimensional, 183
inner product, 144, 146, 181
inner product space, 181
norm, 144, 146, 181
orthogonality, 144, 146, 181
orthonormal basis, 145, 182
Schwarz inequality, 145, 146, 182
span, 143
subspace, 143
line element, 521. See also arc length
line integrals, 299 ﬀ
lines of force, 396
Liouville’s theorem, 718
ln, 72. See also Logarithm
Logarithm(s):
to base e, 72
branch of, 693
of complex numbers, 72

826
INDEX
and inverse hyperbolic functions, 74
of negative numbers, 72
series for, 26
Lorenz equations, 96
loudness, 373
lowering and raising operators (ladder
operators), 607, 614, 618
lowering and raising tensor indices, 532
loxodrome, 269
Maclaurin series, 24 ﬀ. See also series;
power series
magnetic ﬁeld, 329, 714
magnitude of a vector, 96
main diagonal, 118
mapping
functions of z, 705 ﬀ, 710
of the plane, 125 ﬀ
mass, center of, 251 ﬀ
matrices, Chapter 3. See also matrix
addition of, 115
commutator of, 117
conformable, 116
and determinants compared, 115
elementary row operations, 86
equal, 86, 114
inverse of product of, 140
multiplication of, 115, 116
operations on, 114 ﬀ
row reduction, 83 ﬀ
similar, 150
table of special, 137–138
transpose of product of, 139
and vectors or tensors, 114, 503
matrix, Chapter 3, 83ﬀ. See also matrices
adjoint, 137
anti-Hermitian, 138
anti-symmetric, 138
augmented, 85
block diagonalized, 176
characteristic equation of, 148
of coeﬃcients, 84
column, 114
dagger, 137
determinant of, 89
diagonalizing, 148 ﬀ
eigenvalues of, 148 ﬀ
of eigenvectors, 150
equations, 114
functions of, 121
Hermitian, 137, 138
Hermitian conjugate, 137
identity, 118
index notation, 84, 116, 138 ﬀ
inverse, 119, 137
invertible, 119
multiplication by a number, 114
normal, 138
null, 117
operators, 125
orthogonal, 126, 127, 138
power of, 121
pure imaginary, 138
rank of, 86, 94
real, 138
reﬂection, 128 ﬀ, 155 ﬀ
rotation, 120, 127, 129, 155 ﬀ
row, 114
singular, 119
skew-symmetric, 138
special, 137
symmetric, 138
trace of, 140
of a transformation, 125, 148
transpose conjugate of, 137
transpose of, 84, 137
unit, 118
unitary, 138, 154
zero, 117
maxima and minima, 211 ﬀ
boundary point or endpoint prob-
lems, 223 ﬀ
in calculus of variations, 472 ﬀ
with constraints, 214
of harmonic functions, 720
interior, 224 ﬀ
using Lagrange multipliers, 214 ﬀ
second derivative tests, 213 (prob-
lems 1, 2)
Maxwell-Boltzmann statistics, 742
Maxwell equations, 330, 621 (Problem 3)
mean free path, 754
mean value. of See also average value
a product of random variables,
756 (Problem 14)
a random variable, 746,752,763,768
a set of measurements, 771 ﬀ

INDEX
827
a sum of random variables, 749 (Prob-
lem 9)
mean value theorem, 195
measurements, 770 ﬀ
mechanics applications. See accelera-
tion; energy; motion of a par-
ticle; velocity
median, 771
medians of triangle, 98
membrane, deformation of, 148
membrane, vibration of, 644 ﬀ
meromorphic function, 681
method of Frobenius, 585 ﬀ, 605
method of images, 657
method of undetermined coeﬃcients, 421
methods of counting, 736
metric tensor, 524, 532
in orthogonal coordinates, 533
raising and lowering indices, 532
minimum distance:
calculus methods, 214, 216
calculus of variations, 472 ﬀ
Lagrange multipliers, 217–218, 221–222
vector methods, 109–111, 238 (Problem 2)
minimum surface of revolution, 479
minor of a determinant, 89
mirror, 407
mixed second partial derivatives, 189
not necessarily equal, 190
reciprocity relations, 190, 231, 306
mixed tensor, 531
mobile, 44
mode, 771
mode of vibration, 165, 636, 645–646
modern physics. See also quantum mechanics
charge distribution in atoms, 573
hydrogen atom, 614 (Problems 27,
28), 652 (Problem 22)
Millikan oil drop experiment, 400
radioactive decay, 39, 395, 399,
402–403, 755, 768
relativity, 42, 394
waves, 342 (see also waves)
modiﬁed Bessel functions, 595
mod N, 174, 178
modulus of a complex number, 49
modulus of an elliptic integral, 555
Moebius strip, 327
moment, 277
of a charge or mass distribution, 573
electric dipole, 573–575
ﬁrst, 277
of a force, 277
of inertia, 252, 265, 277, 505 (see
also inertia tensor)
problems, 255-257, 267–270,
273–275, 508, 520
quadrupole, 573–575
second, 277
monogenic function, 667
mothball, 394
motion of a particle, 4 (Problem 16),
286. See also acceleration; force;
Lagrange’s equations
in a circle, 283
complex notation, 56, 76, 80, 340–341
damped, 413
forced, 426
under gravity, 392
problems, 308, 400, 435, 486
in polar coordinates, 487
probability function for, 750–753
reduced mass, 197
simple harmonic, 80
problems, 344, 416, 754, 489–490
multiple integrals, Chapter 5
multiple pole, 680
multiple-valued function, 667
multiplication (mod N), 178
multiplication tables for groups, 173 ﬀ
multiplying. See product
music. See sound waves
mutually exclusive, 723
nappe of a cone, 263
natural frequency, 414, 427
natural logarithm, 72. See also Logarithm
n-dimensional space, 143 ﬀ
negative of a vector, 97
Neumann function, 591
Neumann problem, 631
Newton’s law of cooling, 400
Newton’s second law, 80, 289, 390,
394, 485
Newton’s third law, 285
nodal line, 646
nonanalytic function, 669
non-Cartesian tensors, 529 ﬀ, 531

828
INDEX
noncommutative operations, 103, 117, 132
nonconservative ﬁeld, 302, 306
nonlinear diﬀerential equation, 392, 396
non-uniform sample space, 725
norm, 96
normal cumulative distribution, 547
normal derivative, 293
normal distribution, 547, 761, 769
normal error curve, 761
normal frequencies, 166
normalization of
Bessel functions, 602–603
Hermite polynomials, 608
Laguerre polynomials, 610, 611
Legendre polynomials, 578 ﬀ
normal line, 109, 293
normal matrix, 138
normal modes of vibration, 165
normal (perpendicular), 109
normal vector to a plane, 109
normal vector to a surface, 220, 271, 293
null matrix, 117
number of poles and zeros, 694
octopole moment, 573, 575
odd functions, 364
Ohm’s law, 78
one-sided surface, 327
operators See diﬀerential operators; lin-
ear operators; vector operators
optics applications, 79. See also light
combining light waves, 79
Fermat’s principle, 473, 484
Fresnel integrals, 37, 549 (Problem 6),
701 (Problem 41)
law of reﬂection, 474
lenses, 198
multiple reﬂections, 79
scattering, 389
Snell’s law, 474
orbits, 468
order:
of a Bessel function, 589
of a determinant, 80
of a diﬀerential equation, 391
of eigenvalues in a diagonal matrix,
152
of a group, 173
of placing electric charges, 18–19
of a pole, 680
of a tensor, 496
of terms in a series, 18
ordinary diﬀerential equations, Chap-
ters 8 and 12. See also partial
diﬀerential equations
associated Legendre, 583
auxiliary equation, 409 ﬀ
Bernoulli, 404, 431
Bessel, 588, 593, 594
boundary conditions, 393
change of variables in, 406
complementary function, 417
damped motion, 413
dependent variable missing, 430
Euler (Cauchy), 434
Euler (Lagrange), 485 ﬀ
exact, 405
exponential right-hand side, 419
family of solutions, 395–396
ﬁrst integrals, 433
forced vibrations, 417 ﬀ, 426 ﬀ
Fourier series solutions, 428
free vibrations, 412, 417
Fuchs’s theorem, 605
generalized power series solution, 585
general solution of, 392, 395, 401,
410, 411, 418
Green functions for, 461
Hermite, 607, 608
homogeneous, 406, 408 ﬀ
independent variable missing, 431
inhomogeneous, 408
initial conditions, 393
integrating factors, 401, 405
Laguerre, 609 ﬀ
Laplace transform solution, 440 ﬀ
Legendre, 564
linear, 391
linear ﬁrst-order, 401 ﬀ
linear second-order, 408 ﬀ, 417 ﬀ
method of undetermined coeﬃcients,
421
nonhomogeneous, 408
nonlinear, 391, 392, 396 ﬀ,
order, 391
particular solution, 392 ﬀ, 397, 415 ﬀ
(see also particular solution)

INDEX
829
reduction of order, 434, 567 (Prob-
lem 4), 606 (Problems 1–4)
regular, 605
second solution, 606
separable, 395 ﬀ
series solutions, Chapter 12
simultaneous, Laplace transform so-
lution, 441
slope ﬁeld, 393, 394
solution of, 391,
Sturm-Liouville, 617
variation of parameters, 464
y′ missing, 430
orthogonal curvilinear coordinates, 521 ﬀ,
708
arc length element, 521
basis vectors, 522
scale factors, 522
vector operators in, 525
velocity, 524
volume element, 524
orthogonal functions, 575
orthogonality
of Bessel functions, 601 ﬀ
of functions in Fourier series, 351,
601
of Hermite polynomials, 608
of Laguerre polynomials, 610, 611
of Legendre polynomials, 577
proof using diﬀerential equation, 577
of solutions of a Sturm-Liouville equa-
tion, 617
of vectors in 3 dimensional space,
102
of vectors in n dimensional space,
144
with respect to weight function, 602
orthogonal matrix, 126, 127, 138
orthogonal similarity transformation.
See orthogonal transformation
orthogonal trajectories, 396
orthogonal transformation, 126 ﬀSee
also rotation; reﬂection
by an analytic function, 708
diagonalizing a symmetric matrix
by, 149 ﬀ
matrix, 127
in n dimensions, 143
to normal modes of vibration, 165
to principal axes, 162
similarity, 150
in 3 dimensions, 155
orthogonal (perpendicular) vectors,
105, 144
orthonormal
basis, 145
functions, 579
oscillating series, 7
oscillator, oscillatory motion. See vi-
brations
oscillatory (underdamped) motion, 414
outer product, 501
out of phase, 79
overdamped motion, 413
overtones, 345, 373
paddle wheel probe, 325
parabolic coordinates, 525
parabolic cylinder coordinates, 524
parabolic mirror, 407
parallel axis theorem, 255
parallelogram, 186
parallelogram law, 97
parallel vectors, 102
parameters, variation of, 464
parametric equations
circle, 301
curve, 301
cycloid, 483 ﬀ
ellipse, 556
line, 108
parent population, 770 ﬀ
Parseval’s theorem, 375
partial derivatives, Chapter 4.
See
also partial diﬀerentiation
cross partials, 190
of functions of (x, y) or (r, θ), 189
in matrix notation, 200
in thermodynamics, 190, 231
partial diﬀerential equations, Chapter 13
change of variables in, 228 ﬀ
derivations of 620–621
Fourier series solutions, Chapter 13,
Sections 1–4
Green function solutions, 657–658
heat ﬂow or diﬀusion equation, 619,
628 ﬀ, 659
Helmholtz equation, 620, 629, 645

830
INDEX
Laplace’s equation, 619, 621, 638,
648 (see also Laplace’s equation)
Poisson’s equation, 619, 652 ﬀ, 657
Schr¨odinger equation, 620, 628, 631–
632, 651 (Problems 18, 20–22)
solution by Fourier transforms, 660 ﬀ
solution by Laplace transforms, 659 ﬀ
solution by separation of variables,
622, 625, 628, 639, 645, 648
wave equation, 297, 620, 633 ﬀ, 644 ﬀ
partial diﬀerentiation, Chapter 4. See
also partial derivatives
chain rule, 199 ﬀ, 203 ﬀ
change of variables, 228 ﬀ
derivatives not reciprocals, 208
diﬀerentials, 193
implicit, 202
of integrals, 233 ﬀ
Lagrange multipliers, 216 ﬀ
maximum and minimum problems, 211 ﬀ
mixed second derivatives, 189–190
notation, 189–190
total diﬀerential, 193 ﬀ
two-variable power series, 191 ﬀ
partial fractions, 451
partial sum of a series, 7
particular solution, 392ﬀ, 397
complex exponentials, 420
exponential right-hand side, 419 ﬀ
by inspection, 418
principle of superposition, 425, 428
undetermined coeﬃcients, 421
passive transformation, 127
Pauli spin matrices, 122
pendulum(s), 38, 344, 545
coupled, 490
double, 491
energy of, 545
large vibrations of, 557
lengthening, 598
period of, 343, 545–546, 557
seconds, 343
shortening, 600
simple, 38, 344, 545
small vibrations of, 38, 344, 545
spherical, 489
period
of a Fourier series, 350 ﬀ, 360 ﬀ
of a function, 343
of lengthening pendulum, 599
of simple harmonic motion, 341
of simple pendulum, 38, 344, 545
periodic function, 340, 343, 345
permutation, even, odd, 509
permutations, 737
permutation symbol (Levi-Civita),
508 ﬀ
perpendicular axis theorem, 252
perpendicular (orthogonal) vectors, 105
phase of a complex number, 49
phase space, 143
plane
complex, 47 ﬀ
distance from point to, 110
equations of, 108 ﬀ
perpendicular to a vector, 109
tangent to a surface, 293
through 4 points, 136 (Problem 21)
through 3 points, 109
planet, 468
plate, conducting, 322
plate, hottest and coldest points of, 224
plate, temperature in, 621, 661
plotting
complex numbers, 48 ﬀ, 62
graphs of complex equations, 54 ﬀ
roots of complex numbers, 64 ﬀ
point
boundary, 223 ﬀ
at inﬁnity, 702
of inﬂection, 212, 472
maximum, minimum, 211 ﬀ
in n-dimensional space, 143
saddle, 212
of sample space, 724 ﬀ
and vector r, 142
Poisson distribution, 767 ﬀ
approximated by normal distribu-
tion, 769
mean and standard deviation, 768
Poisson’s equation, 619, 652 ﬀ, 657
Poisson’s summation formula, 389
polar coordinates. See also orthogo-
nal coordinates
acceleration in, 487
arc length element, 259, 266, 521
area element, 258
change of variables to, 229, 258

INDEX
831
complex numbers in, 48, 50 ﬀ
div, 298
Euler equation, 478
grad, 294, 525
integrals in, 258 ﬀ
Lagrange’s equations in, 486
Laplacian, 298
partial derivatives, 189, 208
scale factors, 522
unit basis vectors, 288, 522
polar form of a complex number, 48, 61
polar vector, 515
in physics formulas, 517
pole(s)
on contour, 691
at inﬁnity, 703
number in a region, 694
of order 2, 681
of order n, 680
residues at, 684 ﬀ
simple, 680 ﬀ
Polya’s urn model, 741
polynomial approximation, 581
polynomials
Hermite, 608
Laguerre, 609 ﬀ
Legendre, 566 ﬀ(see also Legendre
polynomials)
Legendre polynomials, as combina-
tions of, 574
population average and variance, 771
position vector, 286
potential
complex, 713
by conformal mapping, 712–713
electrostatic, 304, 712, 713 (see also
electrostatic potential)
gravitational, 290, 303 ﬀ, 484,
Legendre expansion of, 571 ﬀ
multipole expansion of, 571–573
Poisson’s equation for, 652 ﬀ
scalar, 303 ﬀ
vector, 332
velocity, 303, 713
zero at inﬁnity, 304–305
potential energy, 303, 433, 485
power of a matrix, 121
power series. See also series
absolutely convergent, 10, 19, 58
adding, 19, 23, 59
alternating series test, 17
in annular ring, 679
binomial, 28
combining, 23, 26 ﬀ, 59
comparison test, 10
complex, 56 ﬀ
computation, 3, 36 ﬀ, 41 ﬀ
using computer, 31
conditionally convergent, 18
convergence of, 6 ﬀ, 20 ﬀ, 58
diﬀerentiating, 23, 59
disk of convergence, 58, 671
divergence of, 6 ﬀ
dividing, 27 ﬀ, 59
expanding functions in, 23 ﬀ
functions having no power series, 33
generalized, 585 ﬀ
general term, 4
integral test, 11 ﬀ
integrating, 23, 30, 59
interval of convergence, 20
Maclaurin, 24 ﬀ
multiplying, 23, 26, 59
numerical computation using, 36
preliminary test, 9
ratio test, 13, 14
rearranging terms, 18
remainder of, 7, 13
sequence, 1, 5
solution of diﬀerential equations, Chap-
ter 12. See also diﬀerential equa-
tions
substitution of one in another, 23, 29
Taylor, 24, 30, 213, 671
theorems about, 23
two-variable, 191
uniqueness of, 23, 59, 191
powers of a matrix, 121
powers of complex numbers, 63
Poynting vector, 535
preliminary test, 9
principal angle of a complex number, 50
principal axes and moments of
inertia, 506 ﬀ
principal axes of a conic section, 162
principal part of ∆z, 195
principal part of Laurent series, 678
principal value of

832
INDEX
arc tan, 50
an integral, 692
ln z, 72
principle of superposition, 425, 428
probability, Chapter 15
applications, 722
of compound events, 730
conditional, 732
cumulative distribution, 748
deﬁnition, 723, 725
density, 753 ﬀ(see also probability
functions)
distribution, 748
distribution function, 748
experimental measurements, 770 ﬀ
functions, 745, 748
binomial, 756 ﬀ
continuous, 750 ﬀ
normal (Gaussian), 761 ﬀ
Poisson, 767 ﬀ
of independent events, 731
mathematical, 727
mean value, 746,752,763,768
natural or intuitive, 727
random variables, 744, 747
sample space, 724 ﬀ
standard deviation, 747,753,763,768
theorems, 729
variance, dispersion, 747, 753
probable error, 774
product
of complex numbers, 62 ﬀ
cross, 103 ﬀ, 276
derivative of, 567
of determinants, 118
dot, 101, 102, 276
inner, 100
of matrices, 115, 116
scalar, 101, 276
of series, 23, 26, 191
vector, 103, 276
of vectors, 276
progression, geometric, 1
projections of a vector, 101
proper rotation, 514
p-series test, 13
pseudovector, pseudotensor, 514
axial vector, 515
cross product, 516
pup tent, 212
pure imaginary, 47
pure tone, 345
quadratic formula, 46
quadratures, 433
quadric surface, principal axes of, 163–164
quadrilateral, 100
quadrupole moment, 573
quantum mechanics applications
complex numbers, 81
correspondence principle, 197
Dirac delta function, 454
Fourier transforms, 386
Hermite and Laguerre functions, 607–614
hydrogen atom, 614 (Problems 27,
28), 652 (Problem 22)
Klein-Gordon equation, 665
ladder operators, 607 ﬀ, 614 (Prob-
lems 29, 30)
Pauli spin matrices, 122
Schr¨odinger equation, 620, 628, 631–
632, 651 (Problems 18, 20–22)
simple harmonic oscillator, 651
(Problem 21)
spherical harmonics, 649, 651
(Problem 16)
statistics, 739 ﬀ
problems, 744
sums of integers, 651 (Problem 21),
744 (Problem 21)
quotient. See dividing
quotient rule for tensors, 504, 532
radian mode, 49
radians and degrees, 49, 52
radioactive decay, 39, 395, 399, 402–
403, 755
and Poisson distribution, 768
radio-frequency, 347
radio waves, 343, 347
radius of convergence, 58
raindrop, 467
raising and lowering operators, ladder
operators, 607, 614, 618
raising and lowering tensor indices, 532
ramp function, 374
random variables, 744, 747
random walk, 757

INDEX
833
rank of a matrix, 86, 94
rank (order) of a tensor, 496
rational functions, 60
ratio test, 13–14
real axis, 48
real part of a complex number, 47, 49
rearranging terms of a series, 18
reciprocals in diﬀerentiation, 208
reciprocity relations, 190, 231, 306
rectangular form of a complex
number, 48, 51
rectiﬁed half-wave, 374
recurrence. See recursion relations
recursion relations:
Bessel functions, 592
gamma function, 538–539
Hermite polynomials, 609
Legendre polynomials, 570
reduced mass, 197
reduction of order in a diﬀerential
equation, 434, 606
reﬂection matrix, 128 ﬀ, 155 ﬀ
reﬂection of axes, 126, 128 ﬀ, 156 ﬀ
reﬂection of light, 285, 474
refraction, 474
region, 667
simply connected, 330
regular diﬀerential equation, 605
regular function, 667
regular point, 680
relative error, 197, 775
relative intensity of harmonics, 373
relativity, 42, 394
relaxation oscillator, 387
remainder, 7, 13
residues
at inﬁnity, 703
using Laurent series, 683
at a multiple pole, 685
at a simple pole, 684
residue theorem, 682
evaluating integrals using, 687 ﬀ
resistance of a wire, 197
resonance, 427
response to unit impulse, 449, 459
resultant, 446
rhombus, 106
rhumb line, 269
Riccati, 408
Riemann surface, 707, 708
right-handed system, 515
right-hand rule, 515
RLC circuit. See electric circuits
rocket, 467
Rodrigues’ formula, 568
Hermite polynomials, 608
Laguerre polynomials, 609
Legendre polynomials, 568
root-mean-square, 348
roots of auxiliary equation, 409–414
roots of complex numbers, 65, 66
rotation(s)
angle, 127, 129, 151
axes rotated, 127
in the complex plane, 77 (Problem 1),
131 (Problem 19)
equations, 127, 151
improper, 514
matrix, 120, 127, 129, 155 ﬀ
in n dimensions, 143
non-commuting, 132
not a vector, 497
to principal axes, 162–164
proper, 514
of a rigid body, 497, 505 ﬀ
tensor, 535 (problem 9)
in three dimensions, 129, 155 ﬀ
in two dimensions, 127, 151
of a vector, 127
vector rotated, 127
rot v, rotation v, 325
row matrix, 114
row operations, 86
row reduction, 83 ﬀ
row vector, 114
saddle point, 212
sample average, 771
sample space, 724 ﬀ
sawtooth voltage, 346, 374
scalar, 82, 496
ﬁeld, 290
operator, 296
potential, 303 ﬀ, 332 (see also
potential)
product, 101, 276
projection, 101
triple product, 278

834
INDEX
scale factors and basis vectors, 522
Schr¨odinger equation, 620, 628, 631–
632, 651 (Problems 18, 20–22)
particle in a box, 632
time independent, 631
Schwarz inequality
in complex Euclidean space, 146
in Euclidean space, 145
sec γ method, 271
second derivative tests for maximum,
minimum, 213 (Problem 2)
second-rank tensor:
Cartesian, 500
contravariant, 532
covariant, 531
mixed, 531
skew-symmetric, 503
symmetric, 503
seconds pendulum, 343
secular determinant 148
seesaw, 277
selections (combinations), 737
separable diﬀerential equations, 395
separation constant, 622
integral valued, 639, 645, 648
sign of, 624, 629, 634, 639, 648
zero value of, 628, 644
separation of variables:
ordinary diﬀerential equations, 395
partial diﬀerential equations, 622,
633, 639
sequence 1, 5, 8
series, Chapters 1, 2, 7, 11, 12. See
also individual series
absolutely convergent, 10, 19, 58
adding, 19, 23, 59
alternating, 17, 34
alternating harmonic, 17, 18, 21, 37
approximations, 33 ﬀ, 38 ﬀ, 545, 548
asymptotic, 549 ﬀ, 552
Bessel, 640 ﬀ, 645 ﬀ(see also Bessel
functions)
binomial, 28
complex, 56 ﬀ, 673, 678 ﬀ
computation with, 3, 36, 41 ﬀ, 548–
549, 624 ﬀ
conditionally convergent, 18
convergent, 6, 20, 58 (see also
convergence)
divergent, 6 ﬀ
dividing, 23, 27, 59
Fourier, Chapter 7 (see also Fourier
series)
geometric, 1 ﬀ
harmonic, 11, 12
inﬁnite, Chapter 1
Laurent, 678 ﬀ
Legendre, 580, 649 (see also
Legendre series)
Maclaurin, 24 ﬀ
multiplying, 23, 26, 191
oscillating, 7
partial sum of, 7
of positive terms, 10
power, Chapter 1 (see also
power series)
rearranging terms in, 18
remainder of, 7, 13, 33
for alternating series, 34
solutions of diﬀerential equations,
428, 562 ﬀ
summing, 37
sum of, 2, 7, 18
Taylor, 24, 30, 671
useful facts about, 19
series solutions of diﬀerential equations,
Chapter 12
Bessel 588, 593, 594
Hermite, 607 ﬀ
Laguerre, 609 ﬀ
Legendre, 564 ﬀ
sgn x, 460
shear forces in stress tensor, 496
sheet of Riemann surface, 708
shifting theorems, 439, 468
SHM. See simple harmonic motion,
340 ﬀ
shortening pendulum, 600
shortest distance along a surface, see
geodesics
shortest time. See brachistochrone
side bands, 347
Sierpi´nski gasket, 3
similarity transformation, 150 ﬀ
orthogonal, 150 ﬀ, 154
unitary, 154
similar matrices, 150
simple curve, 674

INDEX
835
simple harmonic motion, 38, 80, 340 ﬀ,
412. See also pendulum
problems, 344, 416, 489–490, 754
simple pendulum. See pendulum
simple pole, 680
simply connected region, 330
simultaneous diagonalization of ma-
trices, 158
simultaneous diﬀerential equations, 441
sine
of complex number, 68
Fourier series, 366
Fourier transform, 381
hyperbolic, 70
inverse, 74 ﬀ
power series for, 26, 69
single-valued function, 356, 667
singularity, 670
singular matrix, 119
singular point, 670
singular solution, 397
sinh z, 70
sink, sink density, 316, 714
sinusoidal functions, 341
skew lines, 111
skew-symmetric matrix, 138
skew-symmetric tensor, 503
skin eﬀect, 596
slant height, 255
slope of a curve, 202–203
Snell’s law, 474
sn u, 558
soap ﬁlm, 473, 480
solenoidal ﬁeld, 332
solid angle, 320
solid of revolution, 253
sound waves, 345, 372, 378
air pressure in, 345, 372
energy in, 373
frequency: continuous, 378; funda-
mental, 345, 373; overtones, 345, 373
harmonics, 345, 373
intensity of, 373
pure tone, 345
vibrating drum, 644
vibrating string, 633 ﬀ
source, source density, 714
space, 142 ﬀ. See linear vector space
span, 143
special comparison test, 15
speciﬁc heats, 211 (Problem 28)
spectrum, continuous, 378
sphere and complex plane, 703
spherical Bessel functions, 596
spherical coordinates, 261.
See also
orthogonal coordinates
acceleration, 523
arc length element, 266
curl, 527
div, 298, 526
grad, 294, 525
Laplace’s equation, 648
Laplacian, 298
scale factors and unit basis vectors,
523
velocity, 266, 523
volume element, 261, 263, 524
spherical harmonics, 649
spherical pendulum, 489
spring constant, 80
square of a vector, 101
square wave, 353
stability of a vertical wire, 600
standard deviation
for binomial and normal distribu-
tions, 763
of the mean, 772
for Poisson distribution, 768
of a random variable, 747, 753
of a single measurement, 771
of sum, product, etc., 772 ﬀ
standard error, 722
standard normal distribution, 763, 764
star ∗meaning complex conjugate, 50
star ∗meaning convolution, 446
statics problems, 42–43
stationary point, 472 ﬀ
statistical mechanics applications, 554,
739 ﬀ
Bose-Einstein, Fermi-Dirac, Maxwell-
Boltzmann statistics, 742
problems, 743–744
statistics, 770 ﬀ
central limit theorem, 774
combination of measurements,
772 ﬀ
conﬁdence interval, probable
error, 774

836
INDEX
and experimental measurements,
770 ﬀ
population mean and variance,
771
standard deviation of the mean 772
steady state, 426
steady state temperature
in a cylinder, 638 ﬀ
in a ﬁnite plate, 625
insulated boundaries, 631
insulated edges, 627 (Problem 14)
problems, 626 ﬀ
in a semi-inﬁnite rectangular plate, 621
in a sphere, 648 ﬀ
stereographic projection, 703
Stirling’s formula, 552
error in, 553
in statistical mechanics, 554
stochastic process, 746
Stokes’ theorem, 313, 324 ﬀ, 327 ﬀ
and Amp`ere’s law, 329
strain, strain tensor, 519
stream function, 713
streamlines, 325, 714. See also ﬂow of
water
stress tensor, 496, 519, 520
stretch, 152
string, vibrating. See vibrating string
Sturm-Liouville equation, 617
subgroup, 173
subscripts
on D, 568
on ∆, 298
in partial diﬀerentiation, 189–190, 205
in tensor notation, 502 ﬀ, 530
on vectors, 97 ﬀ
subspace, 143 ﬀ
substituting one series in another, 29
subtraction of vectors, 98
summation convention, 502 ﬀ
summation sign, 4
summing numerical series:
by computer, 41, 44, 45
using Fourier series, 358, 377
power series of a function, 37
sum of
alternating harmonic series, 37
complex numbers, 51
conditionally convergent series, 18
geometric progression, 2
inﬁnite series, 2, 7, 10 ﬀ, 37
matrices, 115
power series, 23
two series, 18, 23
vectors, 97
superposition principle, 425
superscripts, 530
surface
area, 271 (see also area)
distance to, 216
integral, 270 ﬀ
level, 290, 293
of minimum area, 479
normal to, 220, 271, 293, 317, 327
one-sided and two-sided, 327
of revolution, 254, 479
tangent plane to, 194, 293
symmetric
equations of line, 107–108
matrix, 138
tensor, 503
symmetry groups, 174, 178
systems of masses and springs, 165–172
tables
approximate formulas for Bessel
functions, 604
Laplace transforms, 469–471
matrices, 137–138
orthogonal polynomials:
Hermite and Laguerre, 804
Legendre, 803
vector identities, 339
tangent approximation, 193
tangent line, 203
tangent plane, 293
tangent, series for, 28
Taylor series, 24, 30, 671.
See also
power series
temperature:
in a bar, 629 ﬀ, 659
on boundary, 720
in a cylinder, 638 ﬀ
gradient, 292–293
in a half cylinder, 712
in a hemisphere, 650
maximum and minimum in a plate,
224–225

INDEX
837
in a plate, 621, 625
scale, 650
in a semicircular plate, 711
in a sphere, 648 ﬀ
tensor product. See direct product
tensor(s), Chapter 10
angular momentum, 505 ﬀ
antisymmetric, 503
applications of, 505, 518 ﬀ
associated, 533
Cartesian, 498 ﬀ
combining, 504
components and basis vectors, 530
contraction, 502 ﬀ
contravariant, 530
covariant, 530
cross product, 516
deﬁnition, 499
direct product, 501
dual, 512
electric dipole, quadrupole,
574 (Problem 15)
ﬁeld, 520
in general coordinates, 531
inertia, 505 ﬀ
isotropic, 509
Kronecker δ, 508 ﬀ
Levi-Civita symbol, 508 ﬀ
and matrices, 503
metric, 524, 532
non-Cartesian, 529 ﬀ
notation, 502
order (see rank)
pseudo-vectors, pseudo-tensors, 514 ﬀ
quotient rule, 504, 532
raising and lowering tensor indices, 532
rank, 496
rotation, 535 (Problem 9)
2nd-rank, 496, 501, 506
strain, 519
stress, 496, 519
summation convention, 502
symmetric, 503
vector identities, 511
vector operators, 525
and vectors, 496 ﬀ
tent, 212
term-by-term addition of series, 19, 23
terminal speed, 400
thermodynamics, 190, 211. See also
heat ﬂow
Legendre transformation, 231, 233
reciprocity relations, 190, 231, 306
speciﬁc heats, 211
time constant, 399
torque about a line, 277
torque about a point, 281
torus, 257
total diﬀerentials, 193 ﬀ
tower
of books, 44
circular, 43
trace, 140
and group character, 176
of a product of matrices, 140
of a rotation matrix, 157
transfer function, 444
transformations. See also linear trans-
formations; rotation
active, 127
conformal mapping, 705 ﬀ
general, 520
Jacobian of, 261 ﬀ, 283, 536 (Prob-
lem 12), 710 (Problems 12, 13)
Legendre, 231, 233
linear, 125
orthogonal, 126 ﬀ
passive, 127
similarity, 150
transforms, integral, 378 ﬀ, 437 ﬀ
Fourier, 378 ﬀ(see also Fourier
transforms)
Hilbert, 437
Laplace, 437 ﬀ(see also Laplace trans-
forms)
transients, 426
translation or shifting theorems, 439
transpose of a matrix, 84, 137
transpose of product of matrices, 139
trapezoid, 100
triangle inequality, 148
trigonometric functions
of complex numbers, 67 ﬀ
identities, 69, 70
integrals of, 349, 351
inverse of, 74
series for, 23 ﬀ
triple integrals, 242 ﬀ

838
INDEX
triple scalar product, 278
triple vector product, 280
trivial solution, 134
true vector (polar vector), 515
tuning fork, 345
two-sided surface, 327
two-variable power series, 191
unbounded region, 659
underdamped motion, 413, 414
undetermined coeﬃcients, 421
undetermined multipliers, 216
uniformly distributed, 751
uniform sample space, 725
unitary
matrix, 138
similarity transformation, 154
transformation, 154
unit basis vectors, 100, 144, 288, 522.
See also basis vectors
cross product, 104,
in curvilinear coordinates, 522
in cylindrical coordinates, 522
derivatives, 288, 523
dot product, 102
in general curvilinear coordinates, 523
in polar coordinates, 288
unit circle, 687
unit eigenvectors, 149, 164
unit element of a group, 172
unit impulse, 449
unit matrix, 118
unit step, 470
unit vector, 98. See also unit basis
vectors
in polar coordinates, 287, 288
universe, 770
variables. See also change of variables;
coordinates; dependent variable;
independent variable
complex, Chapters 2 and 14
dummy, 380, 541
random, 744, 747
variance, 747, 753, 763, 771. See also
standard deviation
variational notation, 493
variation of parameters, 464
varied curves, 475
vector coordinate, 286
vector ﬁeld, 289 ﬀ, 332, 393, 394
vector identities, table 339
polar, cylindrical, spherical, 298
proved in tensor form, 511
vector integral theorems, 325
vector operators, 296 ﬀ, 525 ﬀ
curl, 296, 324, 511, 527
in curvilinear coordinates, 525 ﬀ
in cylindrical coordinates, 525 ﬀ
divergence, 296, 314, 526
gradient, 290 ﬀ, 525
Laplacian, 297, 298, 527
in tensor notation, 533
vector potential, 332, 336 (Problem 3)
vector product, 276
not commutative, 103
of parallel vectors, 103
triple, 280
vectors, Chapters 3, 6 and 10
acceleration, 286
complex, 56
addition of, 97
angle between, 102
associated, 533
associative law for addition, 97
axial, 515
basis, 287 (see also basis vectors)
Cartesian, 498 ﬀ
characteristic, 148 ﬀ
column, 114
commutative law for addition, 97
components, 82, 97, 100, 114, 497,
530
covariant and contravariant, 530
cross product, 103 ﬀ, 276, 516
deﬁnition, 82, 497
derivatives of, 285 ﬀ
displacement, 286
dot product, 101, 102, 276
length, 96
linearly independent, 132
magnitude, 96
in matrix notation, 114
multiplication of, 100 ﬀ
in n dimensions, 143
negative of, 97
norm of, 96
notation, 96

INDEX
839
orthogonal, 144
parallel, 102
perpendicular, 102
polar, 515
in polar coordinates, 287, 288
position, 286
products of, 276
pseudo-, 514
row, 114
scalar product, 276
subtraction of, 98
transformation law, 498
triple products of, 278 ﬀ, 511, 516
unit, 100 (see also unit basis vec-
tors)
zero, 98
vector space. See linear vector space
velocity
amplitude, 343
angular, 278, 324, 340
complex, 56, 717
in cylindrical coordinates, 523
of electrons, 42
of escape, 435
of light, 474
in orthogonal coordinates, 524
potential, 303, 620, 713
in spherical coordinates, 266
vector, 286
wave, 342, 620, 634
vibrating string, 633 ﬀ
characteristic frequencies, 636
in elastic medium, 665
with free end, 637
Green function solution, 462
plucked, 634
standing waves, 636
struck, 635
of variable density, 600
vibrations. See also pendulum; sound
waves; waves; vibrating string
characteristic frequencies, 636
of circular membrane (drum), 644 ﬀ
damped, 413–414
electrical, 340, 426 ﬀ, 444
forced, 417 ﬀ, 426 ﬀ
free, 80, 417
due to impulse, 449
of lengthening pendulum, 598
normal modes, 645, 646
of pendulum, 38, 344, 545 ﬀ, 557
period of, 341
resonance, 427
simple harmonic, 38, 341, 412
problems, 344, 416
in a sound wave, 345, 373
steady state, 426
of string, 633
tuning fork, 345
violin, 645
voltage, 346, 353, 378
volume, 242 ﬀ
element, 253, 261, 524
ﬁnding by integration, 242, 253
integral, 253 ﬀ, 318
of revolution, 253
vortex, 714
water ﬂow, 325, 713-714.
See also
ﬂow of water
water waves, 342
wave equation, 297, 620, 633 ﬀ, 644 ﬀ
for vibrating drum, 644
for vibrating string, 633 ﬀ
wavelength, 342
wave number, 634
waves, 342, 620, 634
light, 346, 378
notation, 344 (Problem 17)
radio, 343
sound, 345, 372
velocity of, 342, 620, 634
Weber function, 591
weighted coin, 727, 734
weight function, 602
wire, vertical stability of, 600
work, 277
independent of the path, 303
Wronskian, 133, 136 (Problem 16)
yo-yo, 489
zero factorial, 4
zero matrix, 117
zero-rank tensor, 496
zeros of Bessel functions, 591
zeros of f(z), 694
zeta (ζ) function, 41
z-score, 764

