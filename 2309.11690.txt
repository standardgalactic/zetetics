EXPLOSIVE GROWTH FROM AI AUTOMATION: A REVIEW OF THE
ARGUMENTS
Ege Erdil
Epoch
Tamay Besiroglu
Epoch, MIT FutureTech
ABSTRACT
We examine whether substantial AI automation could accelerate global economic growth by about an order of
magnitude, akin to the economic growth effects of the Industrial Revolution. We identify three primary drivers
for such growth: 1) the scalability of an AI labor force restoring a regime of increasing returns to scale, 2)
the rapid expansion of an AI labor force, and 3) a massive increase in output from rapid automation occurring
over a brief period of time. Against this backdrop, we evaluate nine counterarguments, including regulatory
hurdles, production bottlenecks, alignment issues, and the pace of automation. We tentatively assess these
arguments, finding most are unlikely deciders. We conclude that explosive growth seems plausible with AI
capable of broadly substituting for human labor, but high confidence in this claim seems currently unwarranted.
Key questions remain about the intensity of regulatory responses to AI, physical bottlenecks in production, the
economic value of superhuman abilities, and the rate at which AI automation could occur.
Contents
1
Introduction
2
2
Arguments in favor of the explosive growth hypothesis
3
2.1
Increasing returns to scale in production gives rise to explosive growth . . . . . . . . . . . . . . . . .
3
2.2
The stock of digital workers could grow fast . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.3
AI automation could have massive transitory effects . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
3
Arguments against the explosive growth hypothesis
9
3.1
Regulations can slow down the economic impact of AI . . . . . . . . . . . . . . . . . . . . . . . . .
9
3.2
Output is bottlenecked by other non-accumulable factors of production . . . . . . . . . . . . . . . . .
10
3.3
Technological progress and task automation by AI will be slow . . . . . . . . . . . . . . . . . . . . .
12
3.4
Alignment difficulties could reduce the economic impact of AI . . . . . . . . . . . . . . . . . . . . .
13
3.5
R&D may be harder than expected . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
3.6
AI automation will fail to show up in the productivity statistics . . . . . . . . . . . . . . . . . . . . .
14
3.7
Human preferences for human-produced goods will bottleneck growth . . . . . . . . . . . . . . . . .
15
3.8
Previous technological revolutions did not lead to growth acceleration . . . . . . . . . . . . . . . . .
17
3.9
Fundamental physical limits restrict economic growth . . . . . . . . . . . . . . . . . . . . . . . . . .
17
4
Discussion
18
4.1
Open questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
We thank Jaime Sevilla, Tom Davidson, Carl Shulman, Anson Ho, Matthew Barnett, Neil Thompson, Sam Manning, and Amelia
Michael for helpful feedback and Maria de la Lama for the illustrations. We are grateful to Open Philanthropy for support for this
project.
arXiv:2309.11690v2  [econ.GN]  1 Oct 2023

1
Introduction
Artificial intelligence (AI) possesses enormous potential to transform the economy by automating a large share of
tasks performed by human labor. There has been growing interest in the possibility that advanced artificial intelligence
(AI) systems could drive explosive economic growth, meaning growth an order of magnitude faster than current rates.
(Davidson 2021) AI could rekindle the increasing returns dynamics that have historically led to super-exponential
growth. This report aims to build on Davidson’s analysis by providing a comprehensive assessment of the key arguments
for why AI that can meaningfully substitute for human labor may or may not produce an acceleration of economic
growth by as much as we understand the Industrial Revolution as having done, a factor of ten or more.
The idea of AI’s potential to automate many or even all tasks presently undertaken by labor has drawn considerable
interest from economists. Various mechanisms, through which this transformation may or may not happen, have been
proposed (for a review, see Trammell and Korinek 2020). While current scholarship provides valuable qualitative
insights and intuitions about the limitations of accelerated economic growth due to AI (e.g. Aghion, B. F. Jones, and
C. I. Jones 2018), our work aims to extend this foundation by offering a more detailed quantitative analysis. We
focus on identifying the specific conditions under which significant growth accelerations may or may not occur. For
example, arguments involving economic bottlenecks, including so-called ‘Baumol effects’ that are invoked to suggest
accelerations might be unlikely, often permit substantial level-effects from AI automation—effects which could easily
produce accelerated growth if automation were to take place in a sufficiently short period of time. Our approach attempts
to dig into the precise quantitative ranges of growth rates that might blocked by such previously identified mechanisms.
Large transitory 
effects of AI automation
The stock of
digital workers
could grow fast
Increasing returns 
to scale in production
S t r o n g e r *
W e a k e r
*Our assessment
We take stock of some of the key arguments as to why or why not we might
expect explosive growth from AI—growth an order of magnitude greater
than is typical in today’s frontier economies. We spell out these arguments
in detail and tentatively assess their force. We focus on providing a quan-
titative basis to key arguments (such as arguments involving bottlenecks
to automation, preferences for human-produced outputs, technical and reg-
ulatory difficulties in automation, among others) to better understand the
plausible range of growth rates.
We describe three related arguments in favor of explosive growth that rest
on the idea that the development of AI offers an accumulable substitute
to human labor—the first relying on increasing returns to scale due to
technological progress, the second based on fast expansions on the amount
of total effective labor force (including AI) and the third from transitory
growth effects due to rapid automation.
The bulk of this work analyzes arguments against explosive growth from
AI, which we articulate and tentatively assess (see Figure 1). Overall, our
assessment highlights four themes:
Growth theory models predict explosive growth. Growth theory models
often predict explosive growth by default when AI is able to substitute
for human labor on most or all tasks in the economy. These predictions
are quantitatively robust under various modeling assumptions, such as
whether we assume increasing returns to scale or constant returns to scale
and whether or not we consider delays to investment, if realistic parameter
values are used.
Regulation could restrict AI-driven growth. Regulation of AI and various restraints (arising from political economy,
or risk-related concerns) could be sufficient to keep growth from increasing by an order of magnitude. However, such
paths generally require lasting global coordination and potentially exerting control over many distributed actors, which
might be infeasible given both the strengths of relevant incentives to develop and deploy advanced AI and the falling
costs of AI training stemming from algorithmic and hardware technology advances.
Many arguments against explosive growth lack quantitative specificity or are otherwise weak. There are numerous
arguments against explosive growth from AI that falter in providing quantitative specifics. For instance, some posit
that fundamental physical limits or non-accumulable factors of production will rapidly bottleneck growth post AI
automation, yet they fall short in quantitatively bounding the growth accelerations permitted by such constraints in a
compelling manner. Other objections, such as that humans might strongly disprefer consuming AI-produced goods or
services, may also fail to thoroughly take seriously “good AI" that is actually able to flexibly substituting for human
labor across a wide range of tasks.
2

It is difficult to rule out explosive growth from AI, but that this should happen is far from certain. We think that
the odds of widespread automation and subsequent explosive growth by the end of this century are about even. Yet, high
confidence in this claim seems unwarranted, given numerous plausible counterarguments and the fact that the prediction
of explosive growth involves the extrapolation of models beyond the regime in which they have been observed to work.
Growth is 
bottlenecked 
by other factors
AI won’t show up 
in the productivity
 statistics
Prior innovations 
had modest
effects
Fundamental 
physical limits
Preferences for 
human-produced 
goods
R&D may be much 
harder than expected
Alignment 
difficulties
Automation could 
be slow
Regulations slow 
down the economic 
impact of AI
S t r o n g e r *
W e a k e r
*Our assessment
In this work, we will refer to “explosive
growth" as growth an order of magnitude
greater than what is typical in today’s fron-
tier economies. Specifically, we define this
as annual real gross world product (GWP) ex-
ceeding 130% of its maximum value over all
previous years. This definition is consistent
with prior definitions (e.g. Davidson 2021),
and it precludes scenarios in which the level
of GWP crashes (due to, e.g., some disaster)
and then recovers quickly. Moreover, by eco-
nomic output, we refer to the measured output
figures produced by relevant statistical agen-
cies operating in at least as favorable mea-
surement conditions as those today in frontier
economies, i.e. incorporating new product
varieties and adequate sampling intervals, etc.
at least as adequately as the Bureau of Labor
Statistics (BLS), Office of National Statistics
(ONS), and so on.
We analyze a dozen key arguments for and
against explosive growth from AI capable of
substantially automating economically valu-
able tasks. Each argument is first summarized
concisely before a deeper examination aims
to give a quantitative sense of how it might
permit or rule out certain growth rates. After
thoroughly assessing each argument, we evaluate its importance in assessing the probability of AI-induced explosive
growth. To ground our quantitative estimates, appendices provide relevant economic growth models and data. We offer
calibrated probability estimates for each argument being decisive in determining if explosive growth occurs. These
judgments are based on a defined likelihood scale that we introduce in Appendix A.
It is worth noting a few key limitations upfront. This work is perhaps not very balanced in two ways. Firstly, we
searched perhaps more thoroughly for reasons why substantial growth accelerations could not happen compared to
arguments in favor. As a result, it contains a much larger treatment of all the ways in which explosive growth could
not happen, relative to the ways in which it could. The fact that many such counterarguments are featured in our work
might then inadvertently give the impression that there are many more plausible ways for the overall hypothesis to fail
than to succeed. On the other hand, we have become more partial towards the idea that explosive growth looks highly
plausible, likely more so than informal polls suggest economists are. Partly in light of this, our evaluation of some
counterarguments may come across as succinct, reflecting our updated perspective on their relative merit.
2
Arguments in favor of the explosive growth hypothesis
In this section, we delve into three reasons to expect explosive economic growth driven by the advent of artificial general
intelligence (AGI). Firstly, we demonstrate that increasing returns to scale in semi-endogenous growth models generally
produces explosive growth when labor is accumulable (in the sense that the stock can be increased by reinvestment
of production). Secondly, we extend our analysis to exogenous growth models, highlighting how explosive growth
can emerge even without increasing returns to scale and while considering current hardware prices. Thirdly we argue
substantial automation happening in a brief window in time could raise the level of output sufficiently high to give rise
to explosive growth. All throughout, we emphasize that the rapid expansion of the total labor force, which encompasses
human and AI workers, likely leads to explosive growth.
2.1
Increasing returns to scale in production gives rise to explosive growth
One argument for explosive growth from AI invokes the increasing-returns production implied by standard R&D-based
growth models. In such models, when AI suitably substitutes for human labor, all factors of production become
3

“accumulable" so that these can be increased through investment. Notably, this gives rise to a feedback mechanism
where greater output gives rise to an increase in inputs that give rise to a greater-than-proportional increase in output.
Hence, such models generically predict super-exponential growth conditional on AI that suitably substitutes for human
labor. The striking feature of endogenous growth models to produce explosive growth was previously pointed out, by
among others, Trammell and Korinek 2020.
If AI offers a suitable substitute for human labor, standard R&D-based growth models with increasing returns to scale
predict super-exponential growth as long as the diminishing returns to R&D are not very steep. Consider a generalized
version of R&D-based growth model, which— due to the nonrivalry of ideas—gives rise to increasing returns:
Y (A, K) = AKβ
(1)
where A represents total factor productivity and K is the stock of capital (machines, computers, etc.). Capital
accumulates in line with dedicated investment, as does total factor productivity. However, total factor productivity
investment have diminishing marginal returns as ideas get “harder to find" (as is well-documented in, for example,
Bloom et al. 2020). Formally:
1
A
dA
dt ∝A−ϕIλ
A
(2)
Standardly, motivated by the so-called “replication argument", we might suppose that β = 1. However, this assumption
is not at all needed for our conclusion. Indeed, β < 1 still produces increasing returns to scale as long as the returns to
idea-production diminish sufficiently slowly.
In particular, we show that as long as λ/ϕ + β > 1, the economy exhibits increasing returns, which implies that such
an economy will grow hyperbolically, i.e. as described by the differential equation dY
dt ∼Y c, where c is the returns to
scale parameter (which is > 1 whenever λ/ϕ + β > 1).
Bloom et al. 2020, which provides us perhaps with the best estimates of the extent to which ideas get “harder to find",
we find that hyperbolic growth occurs with values of β as low as 0.68. Hence, while standard economic arguments
suggest we might expect β ≈1, with highly conservative assumptions, hyperbolic growth with AI is predicted by
R&D-based growth models. This point has been noted elsewhere, notably by Davidson 2021: avoiding increasing
returns to scale is difficult to avoid even when ideas get “harder to find" over time. Indeed, this outcome is consistent
with fairly conservative assumption on there being decreasing returns on inputs to final goods production.
Why might we take the conclusions from these models seriously? R&D-based growth models, and in particular, the
semi-endogenous version, offer adequate explanations of recent and distant economic history, as has been noted in
the literature. As such, the fact that it robustly predicts explosive growth from AI that suitably substitutes for human
labor should be considered a relatively strong argument. Although obtaining high-quality empirical evidence to decide
between competing growth theories remains challenging, the semi-endogenous account predicting explosive growth
performs relatively well (see Table 1).
Prediction
Explanation and References
Economic growth accel-
eration under Malthusian
conditions
An acceleration of economic growth when the size of the population is limited by the available
technology (see also Kremer 1993). This prediction is in line with the observed acceleration over
recorded economic history, such as that of Bolt and Van Zanden 2020. While there is reasonable
debate about how closely models that predict gradual economic acceleration fit distant economic
data, and the extent to which such data is reliable (see, e.g. Garfinkel 2020; Roodman 2020), this
model arguably captures key dynamics of the data.
Non-increasing growth in
global output
Non-increasing growth in global output in the mid-20th century concurrent with the observed
slowing rates of population growth in middle and high-income countries (C. I. Jones 2022). The
model predicts that slowing rates of population growth produce slowing rates of output growth, all
things equal, and therefore does a decent job accounting for the general pattern of 20th-century
growth. There is furthermore evidence that the semi-endogenous growth model fits recent empirical
data on output, multifactor productivity, research intensity better than other models (see, e.g. Kruse-
Andersen 2017; Herzer 2022).
Maximum observed rate
of long-term economic
growth
The maximum observed rate of long-term economic growth should be on the order of the maximum
rate of population growth.1 Semi-endogenous growth theory predicts that growth in output should
be close to the rates of population growth (see Appendix C), and should therefore be on the order of
3% per year, which is consistent with historical data.
Table 1: Summary of key predictions from the semi-endogenous growth theory with corresponding explanations and references.
4

There are alternative accounts of economic history that put more weight on culture and institutions compared to
scale effects from population, capital, and ideas. We agree that these factors matter, but think they are best viewed
as corrections on top of the semi-endogenous model. For instance, just as culture and institutions influenced which
countries were the first to undergo the Industrial Revolution, we also believe that they will influence which countries
will be the first ones to start experiencing explosive growth.
Nevertheless, it might still be appropriate to put some weight on such alternative explanations and appropriately be less
confident that simply scaling the labor force will lead to explosive growth. However, the basic picture here still seems
persuasive to us even if for some reason we believe this is not a good account of what happened in economic history,
and so we still think this argument is strong in the absence of more specific critiques.
Semi-endogenous growth theory offers a comprehensive framework for understanding historical trends and patterns of
economic growth. Although obtaining high-quality empirical evidence on growth theories remains challenging, the
semi-endogenous account predicting explosive growth from AI systems that provide suitable substitutes for human labor
presents moderately strong evidence supporting the explosive growth hypothesis. There is a possibility that current
growth rates are shaped by additional bottlenecks beyond the fact that the current labor-stock is non-accumulable or
that new bottlenecks may emerge shortly after AI substitutes for human labor. The exact nature of such a bottleneck
remains uncertain, which warrants a cautious approach when evaluating future growth prospects (for a more in-depth
discussion on this topic, see Section 3.2).
2.2
The stock of digital workers could grow fast
The stock of AI systems that substitute for human workers could grow very fast once such systems have become
technically feasible, which by itself could potentially expand output massively. Relaxing our earlier assumption of
increasing returns to scale, we can show that even a simple exogenous growth model predicts explosive growth from
AI because the stock of AI systems performing tasks that human labor previously did could grow sufficiently rapidly.
Consider an exogenous growth model without technological progress:
Y (t) = AL(t)αK(t)1−α,
Here L refers to workers: either digital workers in the form of AI systems or human workers. With the development of
AI that presents a suitable substitute for human labor, we can suppose that the stocks of labor and capital grow as a
result of investment:
dL(t)
dt
= sfY (t)/¯c −δLL, dK(t)
dt
= s(1 −f)Y (t) −δKK,
(3)
where f is the fraction of investment channelled towards AI, s is the saving rate of the economy. ¯c denote the average
dollar-costs (on compute and electricity) of building an AI system that performs the same amount of work as a human
laborer. δL, δK are the depreciation rates for the effective labor and capital stocks, respectively. Assuming that A is
constant, some algebra (see Appendix D) combined with the parametric assumptions presented in Table 2.2 reveals that
the steady-state rate of growth in this model exceeds 30% per year if
¯c ≤s10/7 · 150, 000 $/worker.
(4)
Parameter
Value
Value of US capital stock
$70T
US Labor Force
165M
α
0.7
δL, δK
≪30%
Table 2: Summary of key parameters and their values. δL, δK denote the depreciation rates for effective labor and capital stocks,
respectively.
Hence if the cost of running an AI that substitutes for a human worker (¯c whose units are $/worker) is sufficiently low,
exogenous growth models predict that the effective labor stock should grow sufficiently fast to give rise to explosive
growth. A similar argument to the effect that a rapidly expanding “digital workforce" can result in massive expansions
in output has previously been made by Karnofsky 2021.
We can provide a rough estimate of AGI runtime costs by relying on estimates of the cost of computation and the
estimated cost of running the human brain. Right now, machine learning hardware costs around 2 × 1018 FLOP/($ ·
year),2 and Carlsmith 2020 provides a best-guess estimate of 1015 FLOP/s ≈3 × 1022 FLOP/year for the rate
2The current flagship datacenter GPU, the H100, can perform around 4000 TeraFLOP/s in half-precision, and costs around
$30,000. Conservatively assuming this is ran at 40% utilization for three years with a $30,000 energy bill, this amounts to
≈2e18 FLOP/($ · year).
5

of computation done by the human brain. Combining these two estimates suggests a value of around ¯c = 1.5 ×
104 $/worker. In our model, this is consistent with explosive growth if
(1.5 × 104) ≤s10/7 · (1.5 × 105)
(5)
0.1 ≤s10/7
(6)
0.2 ≤s.
(7)
In other words, this would hold if savings rates are in line with saving rates that have been historically observed in
Western countries and significantly lower than saving rates that have been observed in East Asian countries such as
Japan, China, and Singapore. In addition, saving could be higher under AI-driven growth, given that AI could increase
the productivity of capital investments, and result in concentrating wealth to those with a high propensity to save
(Trammell and Korinek 2020).
Overall, this calculation suggests even if we very conservatively assume that hardware technology stops improving,
that we operate in a constant-returns to scale regime, and that AIs are only as productive as the average worker in the
US, explosive growth is still a plausible outcome of labor becoming accumulable if our AGI software can match the
performance of the human brain.
It should be noted that we assume that the depreciation rates of the stock of compute and capital (δK and δL) are
assumed to be neglible compared to the growth rate (see table 2). If we were to relax this assumption then we need
precise estimates of these numbers and in general need higher saving rates. However, even with depreciation rates
∼30%/year, we only need to double the savings rate to s = 0.4 to still get explosive growth, which has historically
been observed in e.g. East Asian countries.
Moreover, we might need to account for the cost of robotic systems in addition to the computational costs of running
the software. While state-of-the-art industrial robotic systems are currently, for e.g. spot welding, are on the order of
$100k per unit (Sirkin, Zinser, and Rose 2015), it is difficult to predict how much this would add to the cost basis, ¯c.
This is because there could be substantial reductions in prices as we proceed along a learning curve as robotics usage
expands (Korus 2019).
While the model above is only a toy model, it nevertheless illustrates the key importance of the parameter ¯c or something
else fulfilling the same role for any endogenous growth model involving AI-driven automation.
The preceding analysis relies on a static calculation that does not account for potential price effects. In other words, it
overlooks how demand could influence the price of computation. Additionally, the model’s conclusions rest heavily on
estimates of the computational requirements of the human brain, which are marked by considerable uncertainty. If we
were to consider the higher-end estimates of the computation costs of running the human brain in Carlsmith 2020 of
1e16 FLOP/s, explosive growth looks unlikely with current prices.
Remarkably, this result holds even if we assume that there are delays to investment, in the sense that “realized
investment" is an exponential moving average of past inputs to investment. In other words, we model investment to
move more gradually, thereby avoiding short and perhaps unrealistic bursts of capital accumulation and output growth
(see Appendix E).
However, it is important to note that hardware prices are expected to decrease considerably over time, with a current
halving time of roughly 2.5 years (Hobbhahn and Besiroglu 2022). This indicates that the cost of running a human-
equivalent AI is likely to become more affordable in the future. Therefore, the argument presented in the analysis
becomes more persuasive if one anticipates that AGI will take around 10 to 20 years to develop, a period during which
computer hardware could become one or two orders of magnitude more cost-effective. This dynamic could potentially
amplify the economic growth impact of labor substitution by AI. In addition to this, it’s also plausible that ¯c is lower
because AIs could be more capable than humans at runtime compute parity. Here are a few reasons why we might
expect this to be the case:
1. A single AI system trained only once can be deployed in many different settings in the economy given a
sufficient runtime compute budget, while this is impossible to do for humans. In other words, it’s much easier
to copy AI systems than it is to copy humans.
This has many beneficial effects. It allows us to amortize the cost of training large systems over a vast number
of runtime instances, something impossible to do with human lifetime learning. In addition, it means we can
pick the best-performing systems at a given runtime compute level and simply copy those, instead of sampling
from a wide distribution of conscientiousness, intelligence, communication skills, etc. that we must do when
the labor force is made up of humans.
6

2. Software progress on AI capabilities might not stop at human levels. Indeed, there’s no particularly good
reason to suppose that human brains are optimal from the point of view of converting runtime compute into
capabilities, given that humans are evidence that previous species were not optimal. Even one or two orders of
magnitude of decrease in ¯c from software progress would strengthen the argument in this section considerably.
An important criticism of this argument is that scaling GWP along the intensive margin and the extensive margin might
be meaningfully different. For instance, it might very well be true that doubling the world population over a sufficiently
long period of time leads to a doubling in gross world product, but without this increase in population leading to faster
technological progress, per capita income would stay the same. If we do not count the consumption of AIs as part of
GWP in our model, then our thesis is that increasing the number of AIs will lead to higher per capita consumption
among humans, and perhaps it is more difficult to get explosive growth this way without being able to scale the quality
of the services in the economy.
We think there is some kernel of truth in this argument, and we expect it to make explosive growth significantly more
difficult in worlds where AI-driven automation is unable to meaningfully accelerate R&D, but some scaling along the
intensive margin is possible even without technological advances. There are already substantial differences in personal
income across the world, and even within rich countries. In most countries, simply raising the average standard of living
in the country to the standards enjoyed by the wealthiest residents would lead to orders of magnitude increase in gross
domestic product, and we know that if resource constraints are sufficiently loose, doing this requires no new technology.
Resource constraints could of course pose obstacles, but those are no more binding when we’re talking about an increase
along the intensive margin than they are when the increase happens along the extensive margin instead.
Even without the assumption of increasing returns to scale, standard economic growth models predict substantial
acceleration in economic growth rates if we assume substitutes for human labor at realistic costs in the model. While
we do not strongly endorse the conclusions of this calculation due to the many simplifications we make throughout, we
think the argument still provides evidence that explosive growth is more likely than we might think, as it occurs even in
the absence of endogenous technological progress and hardware efficiency growth.
2.3
AI automation could have massive transitory effects
In growth theory, there is an important qualitative distinction between growth effects and level effects (Lucas Jr 1988).
A growth effect is assumed to be either permanent or last for a long time (e.g. changes to the steady state or balanced
growth path), while a level effect is a one-time, transitory increase in the level of economic output that does not translate
into higher growth in the future.
It might be the case that even if AI fails to lead to a long-term growth effect, there might still be a level effect from
human-level artificial intelligence being deployed throughout the economy, and a change in the level of gross world
product that happens over a sufficiently short window of time could lead to transitory growth rates that clear the
threshold of “explosive growth".
To quantify these effects, consider a toy model in which output is produced by a CES production function over a unit
continuum of tasks:
Y = A
Z 1
0
Iρ
i di
1/ρ
(8)
where A > 0 is a measure of productivity. We will not be explicit about what the inputs Ii represent for the sake of
generality, but we assume that there is some total stock of inputs I available in the economy that can be allocated across
different tasks. Moreover, ρ < 0 so that tasks are complements, thereby giving rise to ‘bottlenecks’ in production: the
larger negative values of ρ, the more severe the bottlenecks.
Let f denote the fraction of tasks that cannot be cheaply automated. We show that when f is relatively large (e.g. 10%),
the level effect from AI automation is very substantial, even despite substantial bottlenecks in production. Given that
there is some total stock of inputs I available in the economy that can be allocated across different tasks, we have the
constraint:
Z 1
0
Ii di = I, ∀i Ii ≥0
(9)
When ρ < 0 so that the tasks are complements, Y is optimized when Ii = I for all i and therefore Y = AI.
To see the impact of automation, let’s suppose that for some 0 ≤f ≤1, a fraction 1 −f of tasks are “cheaply
automated". In practice, this is likely to mean that we get many orders of magnitude more inputs on these tasks after the
automation than before. When complementarity effects are strong (so when ρ ≪0) we can approximate by assuming
infinite input on automated tasks instead, as this simplifies the calculation without making much of a difference to the
7

2.00
1.75
1.50
1.25
1.00
0.75
0.50
0.25
Substitution parameter, 
10x
100x
1Kx
10Kx
100Kx
Increase in output from automation
 
Proportion tasks that 
 cannot be automated
5%
10%
25%
Figure 1: Level effects of partial AI automation for various different values the substitution parameter ρ of the CES aggregator
function.
final result. In this case, our optimization problem becomes
Y = A
 Z f
0
Iρ
i di
!1/ρ
, subject to
Z f
0
Ii di = I, ∀i Ii ≥0.
(10)
This problem, as before, is solved by setting the inputs of all tasks equal to each other: Ii = I/f for all i. In this case,
we get that Y = AIf (1−ρ)/ρ, so GWP is higher by a factor of f (1−ρ)/ρ. Figure 1 contains the values of this function
evaluated at some plausible values of f and ρ.
Indeed, the level effects from partial AI automation is substantial, even when the assumptions are relatively pessimistic.
For instance, Knoblach, Roessler, and Zwerschke 2020 looks at the elasticity of substitution between capital and labor
in the US economy and finds a plausible range from 0.45 to 0.87, which corresponds to values of ρ = (σ −1)/σ
ranging from −1.2 to −0.14. ρ = −2 is perhaps below the standard range that is considered plausible, implying
stronger complementarities between tasks than we currently believe exist between capital and labor.
Overall, even if the other arguments fail to go through and we cannot even attain AI that perfectly substitutes for humans
across all tasks, there’s still room for explosive growth if AI can automate e.g. 90% of tasks in the economy and it can
do so in a period of less than 10 years. We can relax these assumptions even further if we do not make the pessimistic
assumption of ρ = −2.
The argument we present above can fail to hold for many different reasons:
1. The approximation that AI will be infinitely productive on automated tasks makes the numbers look more
impressive than they should when ρ, f are close to zero. For instance, if we believe AI will only ever contribute
nine times the input intensity on any automated task, the most we can get out of AI automation is an order of
magnitude increase in gross world product, even assuming full automation.
Indeed, if we rely on our estimates of the computational cost of running the human brain from Section 2.2.,
we can estimate that all the computing hardware available in the world today can perhaps run 100 million
simulated workers at most. If that’s the best we can do, human-level AI software will fall far short of increasing
input intensities at all, let alone setting them to infinity. In the future, this can be overcome by manufacturing
more chips, improving hardware efficiency, etc. but these are out of the scope of this argument.
2. We do not have good information about what value for f should be considered plausible. In a world where full
automation is attained, we can turn our model into a coarse approximation and interpret f as the fraction of
tasks where running human-equivalent AIs is comparable to or more expensive than employing humans to
perform the same tasks, but there’s no obvious reason within the framework of this argument why this quantity
should be e.g. less than 25%. Our previous calculations based on the cost of human brains are suggestive
that this number should be small, but conditional on the increasing returns to scale and digital worker cost
arguments failing, we might not want to put substantial weight on this argument either.
3. Even if the argument gives us correct values for the factor increase in GWP we should expect, this increase
can simply drag out over a sufficiently long period of time such that we do not get an explosive rate of growth
8

at any point. We address some objections which argue for such a possibility Section 3, but our responses are
not decisive and we have to concede that long delays are indeed possible.
This argument suggests that explosive growth remains possible even if AI does not result in full automation and even if
humans continue to occupy roles in the economy that bottleneck production. As such, it’s a “worst case argument"
which leads us to put some probability on explosive growth even in such worlds. However, we consider it to be on
shakier ground than the other arguments we present for explosive growth, and recommend against taking this argument
too seriously in worlds where our other arguments for explosive growth have failed.
3
Arguments against the explosive growth hypothesis
In this section, we provide accounts of arguments against AI-driven explosive growth. For each, we assess their
plausibility and, where possible, attempt to estimate the permitted growth rates the argument implies. While several of
the arguments initially seem concerning, upon closer analysis most do not appear decisive. However, a few remain
non-trivial objections that could plausibly reduce the probability of explosive growth, especially in conjunction. We
examine each argument in turn and aim to draw tentative conclusions about their effects on the likelihood of explosive
growth.
3.1
Regulations can slow down the economic impact of AI
This objection states that the training or deployment of AI systems will be sufficiently impeded by regulation to
reduce the economic growth effects of AI. The possibility of the growth effects from AI automation being curtailed
by regulation features, for example, in B. Jones 2021; Yudkowsky 2021; Garfinkel 2021. Presumably, there are many
reasons this might happen: generic fear or reluctance regarding powerful new technologies, concerns about privacy
or intellectual property leading to a shortage of training data, unwillingness to let AI systems perform tasks that can
be automated without human supervision due to concerns about legal liabilities, etc. Such regulations may very well
be appropriate and prudent, and their negative growth effects could plausibly be outweighed by other considerations
around safety and social welfare. The basic argument, though, is that even if AI would indeed produce explosive growth
if this were allowed to happen by governments or relevant international bodies, this possibility may not be realized due
to dedicated efforts coordinating to slow this process down.
Within the deep learning paradigm that has been dominant in AI research over the past decade, what seems to matter most
for the performance of AI systems are the number of examples they see during training and the number of parameters
they have – which is in turn dictated by the amount of compute developers have at their disposal. Quantitative support
for this statement is provided by the growing literature on scaling laws, which describe the performance of a deep
learning model in terms of a few macroscopic properties of the model such as the parameter count and the training
dataset size. For more on this in the context of large language models, see Kaplan et al. 2020 and Hoffmann et al. 2022.
In light of this, the regulation objection looks more plausible than it did a decade ago because it seems that AI
development will be largely driven by access to vast amounts of data and computation. The large physical footprint
of the computation capacity required for training and deploying advanced AI would likely make the process easier to
regulate, and intellectual property laws can be a significant impediment to the data scaling part of the equation if they
were to be interpreted in a manner unfavorable to AI labs. So we do not think we can rule out this scenario as it stands,
especially if in the future there are large and visible alignment failures of AI systems that scare people into action.
However, there are effects pushing in the opposite direction. Insofar as being in possession of better AI systems
becomes a matter of national security, we can expect any coordination by governments across the world to slow down AI
development to be imperfect. Furthermore, the scale of the potential economic value that AGI can create is enormous:
it’s orders of magnitude beyond any other recent innovation we can think of, mainly because of its credible potential to
restore the historical trajectory of accelerating growth. These factors create strong incentives for governments to allow
the widespread deployment of AGI systems.
We also have to consider algorithmic progress and improving hardware efficiency. While scaling laws give a good
description of the performance of ML systems at a particular level of algorithmic efficiency, over time we develop better
software and this means we need fewer resources to achieve the same level of performance. Hernandez and Brown 2020
estimates the pace of algorithmic efficiency improvements in computer vision as one doubling every 16 months and
Erdil and Besiroglu 2022 estimates one doubling every 9 months, though with wide confidence intervals. If these rates
of progress are at least within the right ballpark and hold up across many orders of magnitude of progress, eventually
AGI systems could become quite cheap to train.
In addition, the falling price of computation over time due to hardware efficiency progress means this represents an
increasingly smaller fraction of global spending on computation. To keep up with these two effects, increasingly strict
regimes of surveillance could eventually be required. The theoretical lower bound on the resource needs of AGI set by
9

the human brain should loom large in our thoughts here: the existence of the human brain means that in principle we do
not need more energy or data than is used by a human to achieve human-level performance, and tracking every human
born in the world would require a surveillance regime the likes of which we have never seen so far. We think the first
AGI systems will require substantially more computation and data than the human brain does, but over time there’s no
reason why these costs should not fall to the level of the human brain or even further below.
In light of the above discussion, we think our baseline scenario here for AI regulation should be more like nuclear arms
control and less like the regulation of nuclear energy: coordination on nuclear arms control does happen, but it is quite
imperfect and hasn’t stopped nuclear proliferation from taking place. This is because we think the incentives for AI
adoption are more similar to the incentives for nuclear proliferation than the incentives for using nuclear energy, as the
economic value that would be unlocked by AGI is far greater and this also has the potential to directly translate into
overwhelming military advantage against adversaries.
Here are some concrete ways in which regulation could be used to slow down the economic impact of AI:
1. Place restrictions or otherwise impose additional costs on large training runs, similar to the restrictions that
now exist on nuclear power. The large resource footprint of training runs past the 1027 FLOP scale or so
should make these enforceable for some time.
2. Prohibit the use of AI for certain economic activities. For instance, laws could be created or interpreted to
bar the use of AI in courtrooms or at hospitals without adequate human supervision. This would introduce an
artificial bottleneck that would stop AI from fully automating some tasks.
3. Use intellectual property laws to prevent the use of certain kinds of data for the training of AI systems. A
sufficiently expansive interpretation of existing intellectual property legislation could prevent AI from being
usefully monetized, reducing the incentive for private actors to invest resources into developing better AI
systems.
While implementing such regulations may hinder the development or deployment of AI, the feasibility of enacting
and enforcing them remains uncertain. Firstly, it is unclear whether such policies can reliably remain enforced over a
sufficiently large, possibly global, jurisdiction for multiple decades or longer. The potential value of AI deployment
could be immense, with the prospect of increasing output by several orders of magnitude. Consequently, this would
likely create formidable disincentives for imposing restrictions, as well as powerful incentives for eliminating or
bypassing any existing constraints. Secondly, the difficulties with enforcing such restrictions might become large as
software improvements bring the capital costs of AI training down. Over time, enforcing such restrictions will require
increasingly ubiquitous global surveillance.
The historical record of regulating technologies that could boost output tenfold is sparse because few, if any, such
technologies have previously been developed. Perhaps the closest possible analogs are a cluster of agricultural
technologies that were introduced during the Neolithic Revolution or the manufacturing technologies that contributed to
the Industrial Revolution (the steam engine, the spinning jenny, cotton gin). While England attempted to forestall the
diffusion of some key Industrial Revolution technologies by prohibiting the emigration of skilled workers and the export
of machinery, these protectionist policies proved largely ineffective (Jeremy 1977). From the 1780s to 1840s, skilled
workers, machines, and blueprints were frequently smuggled out of the country despite the bans, and by the 1840s, with
industrialization advancing rapidly, the policies were seen as futile and repealed (Ibid.). In summary, England failed to
meaningfully slow the international diffusion of its industrial technologies. The experience highlights the challenges of
restricting technologies that offer major economic gains.
As far as we can tell, there is no compelling evidence to suggest that technologies involved in prior shocks to production
technologies could have been effectively regulated with the effect of not just delaying such shocks but also substantially
dampening their growth effects.
Overall, we conclude that regulating the training and deployment of AI may delay its economic impact, but there is no
compelling reason to be confident that its development and application would be sufficiently prolonged to maintain
historical economic growth rates for an extended period of several decades. We do not rule out the possibility, but we
would judge it to be unlikely that regulation of the training and deployment of AI will block explosive growth.
3.2
Output is bottlenecked by other non-accumulable factors of production
The endogenous growth theory argument for explosive growth from the Section 2.1 only implies that we should expect
constant returns to scale on all physically embodied inputs jointly. Labor and capital are physically embodied inputs,
but they might not be the only important ones: other inputs such as energy or land could be just as important, and if
they cannot be accumulated through better technology, perhaps this means AGI-driven growth can get short-circuited
by its dependence on these non-accumulable factors before reaching the threshold of “explosive growth". In addition,
10

just like population, there might be intrinsic timescales that block currently accumulable inputs such as physical capital
from being accumulated arbitrarily quickly. If true, this could be a strong objection against the explosive growth view.
Some version of this argument is certainly sound: there must eventually be some resource constraints that prevent
output from growing arbitrarily large. The important question about this argument is not whether it holds eventually,
but whether it holds quickly enough to preclude explosive growth.
We estimate that the diminishing returns structure on idea production implied by Bloom et al. 2020 means that we need
the returns to scale on accumulable inputs to be at least around d ≈0.68 for explosive growth to occur (see Appendix B).
Theoretically, we have reason to believe that d = 1 (i.e. we have constant returns to scale) if we consider all physically
embodied inputs. However, not all such inputs may be accumulable: as a naive example, if empty space becomes a
valuable resource, then regardless of how much output we invest the speed at which we can grow our access to space
might be bounded by the speed of light. There’s no a priori argument which can settle the question of the returns to
scale on accumulable inputs, and we must also consider the possibility that there might be strong complementarity
between presently accumulable inputs such as capital and non-accumulable inputs such as land or empty space. We
must examine the argument in greater detail to make a judgment about its strength.
The outside view consideration is that economic growth has accelerated by many orders of magnitude in the past: indeed,
this is the empirical regularity for which the semi-endogenous growth theory provides an explanation. Factors which
bottleneck this acceleration do not seem commonplace. We might look at the 1.5 order of magnitude increase in growth
rates since the agricultural era as evidence that new bottlenecking factors such as population growth appear at a rate of
roughly once every 1.5 orders of magnitude of acceleration, suggesting a probability of ∼1 −1/(1 + 1/1.5) = 40%
using the time-invariant version of Laplace’s rule from Sevilla and Erdil 2022 that one such bottleneck appears before
world economic growth accelerates by one order of magnitude.
When we get down to specifics, the most plausible bottlenecking factors that we can think of are land, energy and
capital. On the energy front; on average, 4.4e16W hit the Earth (National Aeronautics and Space Administration 2005),
while global yearly energy consumption is about 4e13W (Ritchie, Roser, and Rosado 2022), suggesting that energy
consumption could expand by 3 orders of magnitude. Similarly, only around 1.5m km2 out of the Earth’s 100m km2 of
habitable land is urban and built-up land, which suggests that there are around 2 orders of magnitude of land that could
be urbanized or built-up. Even if these are strong constraints that cannot be overcome, considering just these constraints,
we have at least 2 orders of magnitude of room to scale up gross world product. If we assume no improvements in
efficiency, so that resource consumption needs to be scaled up proportionally to output, such constraints would still
permit explosive growth if the transition to full automation took 20 years or less. Clearly, then such constraints do not
block growth accelerations at least when AI automation occurs swiftly.
We examine the prospect that some form of physical capital could end up being a bottlenecking factor quantitatively
and come to the conclusion that for the argument to block explosive growth, we need adjustments in investment to be
significantly slower than the growth rate of the broader economy (see Appendix E). In particular, if we can double the
worldwide stock of physical capital at a rate of 30%/year, there’s no reason to suppose that explosive growth would be
prevented due to investment delays or adjustment costs.
The assessment of the likelihood of physical capital becoming a bottlenecking factor, therefore, comes down to the
quantitative question of how long we can expect fundamental delays to investment to be. The experience of Chinese
catch-up growth shows that sustained growth rates on the order of 10%/year and one-time growth rates on the order of
15%/year have precedent in economic history. To reach the threshold of explosive growth, we only need a doubling
of this final rate of increase in a world where AI will also be capable of assisting with the process of capital stock
adjustment, which does not seem sufficiently far out of distribution for us to seriously doubt its feasibility.
Overall, the inside view here seems somewhat ambiguous and it’s difficult to know in which direction we should update
given the above paragraph. The fact that the joint returns to scale on labor and capital right now seem to be well over
the threshold of d = 0.68 required for explosive growth is reasonably good evidence that we should expect at least
some period of growth acceleration after full automation, but this period might be short and it might stop before we
actually reach 30%/year in gross world product growth rates.
Still, we think the threshold of 0.68 might be really low, much lower than where existing empirical evidence places it
(e.g. Kariel and Savagar 2022; Basu and Fernald 1997). In addition, even in a world where this objection is valid, the
argument from accumulating digital workers from Section 2.2 could still produce explosive growth for some time as a
consequence of the transition from human labor to AI labor. As a consequence, our estimate of the probability that this
objection blocks explosive growth is substantially smaller than the naive outside view figure of 40%.
11

Our final conclusion is that this argument is plausible on the outside view and the inside view evidence makes the
argument seem somewhat less compelling, though is by no means sufficient to rule it out. Our final judgment is that it’s
unlikely this objection blocks explosive growth.
3.3
Technological progress and task automation by AI will be slow
This argument posits that the requirements for automating different tasks in the economy span a wide range in
computation, data or both. As these resources can only be accumulated in a gradual fashion, it will take a long time to
get from the point where AI starts to have a large economic impact by automating tasks that are the easiest to automate
to the point where AI is able to fully automate the economy, and this long waiting period will spread out the economic
impact sufficiently that we end up not observing explosive growth.
The effect of this argument is similar to the argument from regulation, but the underlying driver is different. Here, the
reason is a physical property of AI systems as such, and not a property of how human civilization will react to the
prospect of full automation of the world economy by AI. In both cases, however, there is some force that causes the
large impact of full automation to be spread out over a long period of time, and this is what precludes explosive growth.
This objection rests on an empirical claim about the relative difficulty and resource requirements of automating different
tasks in the economy, specifically that the distribution of the amount of computation, data, etc. required to use AI
to automate different tasks in the economy is wide and/or fat-tailed. In other words, we need some tasks to be easy
and automated early on, and some tasks to be very difficult and to take many orders of magnitude more resources to
automate.
If this objection holds, it could indeed be why explosive growth does not occur: a 4 order of magnitude (4 OOM
hereafter) increase in gross world product spread out evenly over 80 years would not produce explosive growth, for
instance. A specific plausible story here is that “physically embodied" tasks such as general-purpose robotics will be
quite difficult to automate – solving them will require large amounts of computation, data, and researcher effort. This is
50%
60%
70%
80%
90%
100%
Fraction of tasks automated
0%
10%
20%
30%
40%
Growth in output per 1 p.p.
increase in automation
Substitution
parameter
=
5.0
=
2.0
=
1.0
=
0.5
Figure 2: The distribution of growth effects from automation on gross world product across difference values of the substitution
parameter ρ. The figure illustrates how output growth becomes increasingly back-loaded as ρ becomes more negative, indicating
stronger complementarity effects. For instance, ρ = −5 corresponds to an elasticity of substitution of σ = 1/6 (extremely strong
complementarity), and ρ = −0.5 corresponds to σ = 2/3 (moderately complementarity). All scenarios assume a 100x total level
effect from full automation.
among the more compelling reasons why we might not get explosive growth. However, on the inside view, it still seems
rather unlikely to be correct. There are two main reasons for this:
1. Slow deployments and automation require large gaps in compute and data requirements between the point
where AI starts to accelerate economic growth and the point AI is able to fully automate the world economy.
However, inside-view investigations into AI (such as Cotra 2020; Davidson 2023) do not usually support such
large gaps.
The largest plausible gap in training computation between AI starting to have a noticeable macroeconomic
impact and full automation that has been suggested in such inside-view investigations is around 10 orders of
magnitude, and even this gap would be crossed fairly quickly if we add up the effects of hardware scaling,
improving hardware and software efficiency, etc. It’s implausible that we could get a delay that’s as long as 80
years, and delays on the order of 30-40 years seem like the slowest that takeoff could end up being.
12

2. Even if the delay period is much longer than 40 years, in a straightforward constant elasticity of substitution
(CES) world, where tasks performed in the economy are gross complements so that automated ‘outputs’ are
imperfect substitutes for non-automated ‘outputs’, the final tasks to get automated are substantially more
valuable than earlier tasks. This means that a constant rate of task automation (say, automate 1% of tasks
that humans can do in the year 2020 every year) leads to initially slow growth that becomes extremely fast
towards the end, as can be seen in Figure 2. This intuition seems compelling: the final tasks to get automated
remove the final bottlenecks in production, so if we believe full automation is actually possible it’s difficult to
construct a scenario in which we do not get explosive growth here.
While we consider this objection unlikely to be correct, it’s internally coherent and more compelling compared to most
of the other objections. We expect it to be unlikely that this objection blocks explosive growth.
3.4
Alignment difficulties could reduce the economic impact of AI
If AI alignment—the challenge of steering artificial intelligence (AI) systems to behave according to intended goals and
avoid unintended harmful behaviors—turns out to be so difficult that it’s hard to get AI systems to reliably do what
we want in real-world deployment, then aside from these systems being regulated more strictly, it could also simply
not be in the private interest of any actor to deploy such systems at large scale. The capabilities of an AI system may
seem impressive in the lab, but if private actors are unable to confidently align these systems to accomplish the tasks
they want done safely, it’s hard to foresee such unaligned AI generating major economic impact before these alignment
problems are solved.
It might also be challenging for AI systems to be deployed to perform certain tasks without human supervision. For
instance, as outlined in Ji et al. 2023, a common alignment problem of modern large language models is their tendency
to hallucinate facts that are wrong: when asked to provide references for a claim they have made, they will often respond
with references formatted according to the proper guidelines but referring to papers that do not exist. If the tendency for
models to hallucinate facts cannot be entirely fixed, it might be necessary for a human in the loop to be present in any
application where strict agreement with facts is highly important, which would mean there are limits to how far poorly
aligned AI systems are able to automate such tasks.
There are many other paths to alignment problems leading to AI performing below the economic potential we might
attribute to it based strictly on capabilities. As another example, if humans are concerned about misaligned AI systems
having too much agency, they might deliberately try to engineer AI systems to be less independent in their decision-
making than humans. This would then require humans to play critical decision-making roles in the economy, and then
human decision-making capabilities could end up being a bottleneck in the way of explosive growth.
While the motivation behind the alignment difficulty argument is quite different from the other arguments we consider,
formally its effects are likely going to be equivalent to limiting the fraction of tasks AIs are able to perform in the
economy. For instance, if humans must occupy key decision-making roles in the economy, this means that effectively
these tasks cannot be automated from an economic point of view. The effect of some tasks requiring human supervision
to perform is similar.
This means our quantitative basis for assessing the above argument should be similar to what we outline in Section
2.3. If we think misalignment is likely to be so bad that e.g. f = 25% of tasks are likely to remain unautomated, and
the elasticity of substitution across tasks σ ≈1/3, then it’s quite plausible that this argument blocks explosive growth.
However, as discussed in the aforementioned section; 25% is a large fraction of the tasks in the economy, and σ ≈1/3
is a high degree of complementarity across tasks. As before, we consider both of these parameter choices to be rather
unfavorable, but the alignment difficulty argument pushes us to think that perhaps a 25% lower bound on the fraction of
unautomated tasks in the economy is not as implausible as it might seem.
It is rather unclear what probability distribution is implied by this argument over the parameter f of tasks that AIs won’t
be able to automate “early on". However, it seems likely to us that this distribution puts significant probability mass on
values that are rather small and would block explosive growth even with moderate values of σ, with potentially long
delays in the R&D process that would push this fraction down, echoing the arguments from the Section 3.2. Overall,
our assessment is that this argument is most likely not going to block explosive growth, but its influence cannot be ruled
out, especially in worlds where σ turns out to be smaller than we expect.
Overall, our conclusion is that alignment difficulties are unlikely to block explosive growth. Furthermore, this argument
is in a family of arguments whose plausibility is correlated with one another due to the confounding influence of the
elasticity of substitution parameter σ, and therefore it’s important to take care when aggregating the probabilities: the
disjunction of these arguments is less likely than would be implied if we simply treated them as independent events and
blithely multiplied their individual probabilities of not being blockers to get a final answer.
13

3.5
R&D may be harder than expected
One argument for why we might not see explosive growth is that R&D may be simply too hard. More precisely, the idea
production function for total factor productivity (TFP) may have such unfavorable diminishing returns that it blocks the
whole model from exhibiting explosive growth. As we have shown in Section 3.4, to make this work, the rate of the
returns to R&D and the returns to scale in economic production jointly need to be small enough so that the the feedback
between economic inputs and output is too decoupled to give rise to accelerating growth. If we take existing estimates
of the returns to R&D in for US TFP, from Bloom et al. 2020, this argument works if the homogeneity of the production
function for other non-idea outputs is no greater than d = 0.68.
We unfortunately do not have much evidence to evaluate how plausible the premise of this objection is. Although we
have estimates related to d for the advanced economies today, it is unclear how much these should inform us about the
returns to scale in economies that are possibly bottlenecked by other factors of production. It is also appropriate to put
some probability mass on the possibility that present estimates of the returns to R&D are too aggressive, or that returns
might fall over time as we make more progress in R&D. However, even if we assume the premise that returns to R&D
are less favorable than present estimates suggest, this argument isn’t sufficient to rule out explosive growth because of
the argument based on the cost of computation we advance in the Section 2.2. Indeed, even in a world with exogenous
technological progress and diminishing returns to scale on labor, explosive growth still remains a plausible outcome.
Because of the uncertainty about the premises of this argument and that it does not seem easy for this effect to block
explosive growth even if the premises of the argument are assumed to be valid, this argument seems rather weak. We
accordingly estimate a low probability that this argument is a decisive blocker. In light of the above assessment, we
conclude that it is very unlikely that unexpected difficulties in R&D that result in stagnating TFP growth will end up
blocking explosive growth.
3.6
AI automation will fail to show up in the productivity statistics
Even if substantial AI automation causes explosive growth in some intuitive sense, it is possible that economic
measurement will be flawed in some respects and fail to capture a possible growth acceleration. Therefore, we could
end up seeing a world of rapid economic transformation in which GDP growth statistics nevertheless fall far short of the
threshold of 30%/year we set for explosive growth.
There are at least two related arguments for why substantial AI automation will fail to show up in productivity. The first
is that economic output will be inaccurately measured and that this measurement error will result in a downward bias in
the estimated rate of economic growth. The second related objection is that there are well-known issues with measured
growth in economic output failing to capture growth in consumer surplus, so even if the measurement of output was
highly reliable, estimated economic growth would fall short of growth in consumer surplus. The second objection also
contends that consumer surplus is, in some sense, the more important metric.
The first argument that economic growth will be imperfectly measured and suffer attenuation bias is indeed plausible.
There are many reasons why this might happen, such as:
• Lag in incorporating new product varieties: Official economic agencies often fail to promptly incorporate new
types of products into their metrics. For instance, the advent of electric vehicles took years to be accurately
reflected in GDP calculations.
• Inadequate sampling intervals: Current sampling intervals may be too long to capture short bursts of rapid
economic growth.
• Random measurement errors: Factors like imperfect quality adjustments introduce random errors into growth
estimates. Such error could introduce attenuation bias into the estimates of growth.
The first of these is in part the reason why the productivity effects in IT have been relatively meager (see, e.g.
Brynjolfsson 1993), and the same measurement issues might similarly result in the underestimation of the effects of
AI. On the other hand, the existing literature on the accuracy of GDP estimates suggests that these are not usually
statistically biased. For example, the difference between preliminary estimates and later estimates derived from the
comprehensive economic census tend not to be systematically different, at least in G7 countries (York and Atkinson
1997) or in the US (Landefeld, Seskin, and Fraumeni 2008; Mankiw and Shapiro 1986). Moreover, using data from six
comprehensive revisions—in 2009, 2003, 1999, 1995, 1991, and 1985, Fixler, Greenaway-McGrevy, and Grimm 2011
finds that the size of BEA revisions of advance GDP estimates are not correlated much at all with preliminary GDP
estimates. This suggests that historical growth accelerations are not likely to be systematically underestimated, at least
in the United States.
14

This leaves us with conflicting insights regarding the economic implications of AI. On one hand, GDP estimates in
leading economies have generally proven to be unbiased and reliable. On the other hand, the economic contributions of
past technological innovations like IT have been historically under-reported due to measurement issues.
However, as discussed in Sections 2 and go on to discuss in 3.8, the economic impact of a technology that can widely
substitute for human labor could far exceed that of past technological innovations like IT. Given this, it is reasonable
to expect that statistical agencies, operating under conditions at least as favorable as today’s, will more accurately
estimate the economic gains from AI, akin to how they track overall GDP. Relevant agencies might adapt to a faster
rate of change. In an AI-automation world, agencies could face pressures to ensure that tracking and monitoring are
commensurate with the pace of change. Their budgets are likely to expand in line broadly with the size of the economy,
and relevant technologies used for monitoring with the sophistication of extant technology.
We think this argument is somewhat implausible, mostly because it relies strongly on the notion that output measurements
will make predictable and large errors that we can anticipate but competent statistical agencies will predictably fail to
address. Even with limited knowledge of these agencies’ operations, we find the assumption hard to believe.
A weaker version in which we do not claim to predict the sign of the error in advance is somewhat more convincing. In
light of this objection, one’s expectations of growth rates under AI automation should be more spread out. The net effect
of this is depends on one’s expectations of growth rates from AI automation: if one were confident in explosive growth,
one should shade their probability estimates in light of additional noise. On the other hand, if one were confident that
explosive growth would not occur, one should assign a greater credence to statistical agencies reporting 30% growth
rates. In the end, we consider it unlikely that GDP measurements will make errors sufficiently large and systematic for
their measures to not show explosive growth occurring.
The second argument is based on the recognition that there are well-known issues with measured growth in economic
output failing to capture growth in consumer surplus, as the former fails to capture the value of ‘free’ IT goods, such as
Wikipedia, Google search, OpenCourseWare, and so on. Perhaps, an AI-driven economy will produce a relatively larger
share of goods that fail to show up on the usual output accounting.
Existing attempts to estimate the contributions from ‘free’ goods find the contribution of is relatively small, contributing
roughly no more than one-tenth, in proportional terms, to GDP growth numbers. For example, Nakamura, Samuels, and
Soloveichik 2017 estimate that including ‘free’ content would raise U.S. GDP growth by about 0.03 percentage points
per year from 1995 to 2014. Relative to the average GDP growth rate of 2.5% over that period, this would represent a
very small margin of error. Other attempts at similar accounting of the contributions from ‘free’ content like Facebook
likely find slightly larger contributions (e.g. Brynjolfsson et al. 2019), but similarly suggest that this added growth adds
on the order of tens of basis points to GDP growth, at least in the United States.
In addition, even if such errors did come to pass, at some level, we do not care about productivity statistics in any
fundamental sense. They are simply a useful proxy for what we wish to discuss, and if they fail to be a good proxy in
the future, that does not necessarily mean our thesis about explosive growth is mistaken or that we shouldn’t take action
to prepare for a world in which explosive growth will occur. We find it exceptionally unlikely that this argument blocks
explosive growth in a sense that we would care about, as opposed to e.g. being a measurement artifact.
3.7
Human preferences for human-produced goods will bottleneck growth
Humans may have a preference for human providers over AI counterparts even in economically significant service
industries. Even if AI is physically capable of doing any task as well as a human can or better, there might be some
tasks that are valued by humans only when they are performed by other humans. For example, we today have computer
programs that can play chess better than any human player can, but top human chess players can still make money by
winning tournaments. The fact that a tournament of computers would have a better quality of play is not important
because part of what people want to watch is for humans to be playing the game.
Humans might prefer to interact with human therapists, teachers, or other service providers that involve high symbolic
value and expression of identity (Granulo, Fuchs, and Puntoni 2021). Although AI systems may one day replicate
some social abilities of humans, people currently tend to prefer human interaction for certain services. If such
intrinsic preferences apply to a sufficient range of tasks, full automation might be impossible simply because of human
preferences and not because of any physical fact about what AIs can or cannot do. This would limit gross world product
as long as humans remain the ultimate consumers in the world economy and therefore the prices of goods and services
are set according to their marginal utility.
This objection could in principle work assuming that all prices in the economy are set by humans, but there are two
main problems with it.
1. While there might be good reasons to care about what happens to gross world product, we’re fundamentally
more interested in questions about the ability to manipulate the physical world to get desirable outcomes.
15

Importantly, scenarios in which AI poses a significant military risk or reshapes the physical environment
around us in some substantial way can still be “explosive" in character even if humans are setting the prices
of goods and services and therefore GWP ends up being bottlenecked by human preferences of one sort or
another.
2. Even on the argument’s own terms, the parameter values needed to make this story work seem quite implausible.
The first problem is relatively straightforward, so we focus on the second problem here. Suppose that consumer utility
is some monotone transformation of the CES aggregator
U =
Z 1
0
cρ
i di
1/ρ
,
ρ = σ −1
σ
,
ρ < 0
(11)
over individual consumer goods ci. If markets clear in some underlying model such that goods prices are proportional
to marginal utility, GDP growth would be given by
dY
Y
=
R 1
0 pidci di
R 1
0 pici di
=
R 1
0 Uidci di
R 1
0 Uici di
, where Ui = ∂U
∂ci
= cρ−1
i
U 1−ρ,
(12)
so that the expression for GDP growth simplifies to
dY
Y
=
R 1
0 cρ−1
i
dci di
R 1
0 cρ
i di
= 1
ρ
dU ρ
U ρ = dU
U .
(13)
This equation is solved by Y ∝U. Therefore, for this particular specification, GDP perfectly tracks consumer utility,
and we can reason about GDP growth by using the growth of U as a proxy for it.
If a fraction f of tasks can only be done by humans by definition, and initially the ci are all equal, then setting the
output tasks that cannot be done by humans to infinity should raise U by at least a factor f 1/ρ, and this factor would
increase if we could explicitly take human labor reallocation from automated tasks to human-only tasks into account - if
the technology converting human labor to output on individual tasks is constant returns to scale, for instance, then we
can get this up to f (1−ρ)/ρ.
This is just the same expression that we dealt with in the Section 2.3. We present a range of parameter values to analyze
the plausibility of the argument here in Table 3:
ρ = −0.2
ρ = −0.4
ρ = −2
f = 5%
6.4 × 107
3.6 × 104
89
f = 10%
106
3.2 × 103
32
f = 25%
4.1 × 103
128
8
Table 3: A table showing the scale-up factors we can get in GDP for various different values of the fraction of tasks that cannot be
automated by AI, f; and the substitution parameter ρ of the CES aggregator function.
The value ρ = −2 corresponds to an elasticity of substitution σ = 1/3, which is conservative. Even under the
pessimistic assumptions of f = 25% and ρ = −2, AGI should produce at least ≈1 OOM increase in gross world
product. If this happens in less than a decade, it would be sufficient to produce explosive growth.
We think this scenario is pessimistic because both parameter values seem unreasonable. We think f = 5% to f = 10%
are more realistic values for the fraction of current economic tasks humans would only value if they were done by
humans, and σ = 0.7 is a more realistic value for the elasticity of substitution in the human utility function. Combining
these means we should expect around 3 −4 OOM increase in GDP as a result of AGI even if we accept the argument
that some tasks will not get automated as a result of human preferences for those tasks to be done by humans. This is,
as mentioned previously, more than enough to produce explosive growth for an extended period of time.
As a reference point, note that 3 −4 OOM likely matches how much gross world product has increased since the
Industrial Revolution, and plenty of this came from increased task automation. So arguments based on intrinsic human
preferences for some tasks being performed by humans seem like they would have made poor predictions if we had
relied upon them in the past, and accordingly, we should be skeptical of them today as well.
We think that this argument will have some effect on economic growth, but do not consider it important for three main
reasons:
16

1. It’s not clear if all prices in the economy will actually be set by humans. If AIs can own property and are
able to make consumption decisions as well, then gross world product would also take their preferences into
account, and these preferences may not come with intrinsic demands that certain tasks must be performed by
humans to be valuable.
2. Quantitatively, the magnitude of the complementarity in the utility function and the mass of tasks that humans
wish to be intrinsically done by other humans have to be quite large for this argument to block explosive
growth.
3. Even if explosive growth in gross world product is blocked, this does not necessarily mean that explosive
growth is blocked in other physical variables that we might care about. These might include energy use,
military strength, computer chip production, etc.
For all of these reasons, we consider this argument to be rather weak and do not think it should lead us to update our
credence in explosive growth conditional on AGI downwards by a substantial amount. We consider it very unlikely
that this argument blocks explosive growth.
3.8
Previous technological revolutions did not lead to growth acceleration
We have seen many other technological innovations in the past that changed how we live our lives: computers, electricity,
cars, airplanes, etc. Nevertheless, while these technologies allowed the trend growth rate of around 2% per year per
person in the US and other developed economies to continue, they didn’t lead to any noticeable growth acceleration. If
this is the relevant reference class for evaluating the plausibility of AI-driven explosive growth, we ought to assign a
low prior chance to the possibility of explosive growth driven by AI.
Our view is that this argument is sound in general and gives us some uninformative prior over whether any new
technology is likely to lead to explosive growth. The probability of this happening for a generic technology is, indeed,
quite small: for instance, while fusion reactors would no doubt be economically valuable, we do not expect them to
lead to explosive growth even if they became viable and cost-effective. However, the evidence that AI that can match
human performance on most or all economic tasks is likely to lead to explosive growth is strong enough to overcome
this general argument.
The key reason is that almost every model in endogenous growth theory makes the prediction that AI that’s capable
of automating most or all economic tasks humans can perform at low cost (e.g. cost of human subsistence) has a
substantial chance of leading to explosive growth. For some models, this prediction is robust to parameter choices;
while in others it’s sensitive, but in either case we cannot rule out the possibility. For example, Section 2.1 predict
explosive growth robustly conditional on full automation from AI, while, as we show in Section 2.2, constant returns to
scale models make this prediction for a substantial fraction of plausible parameter values.
There is no comparable situation with most other technologies, and the reason is the important role played by labor in
growth economics. Labor is unique in that it’s an input that’s both a key driver of economic production and growth and
cannot be increased by reinvestment of economic output the same way capital, compute, energy etc. production can be.
In other words, labor is non-accumulable, while other factors of production that are of comparable importance to labor
are accumulable.
This means the potential economic benefits of a technology that can turn labor into an accumulable input are enormous:
we turn the currently most important factor of production from something that is difficult to scale to something that is
easy to scale. If we also assume that the cost of producing or maintaining this stock of accumulable labor inputs is not
prohibitively expensive, almost all conventional growth models will predict explosive growth in this situation.
While the generic argument outlined in this section is convincing about most technologies, we believe that in the
specific case of AI that’s capable of substituting for human workers, we have enough evidence to overcome the low
prior that such an argument would assign to explosive growth conditional on AI. As a result, if the other objections
to our argument (regulations, other bottlenecks, slow speed of automation, etc.) do not apply, we think this generic
argument does not have any additional force. For this reason, we think it’s very unlikely that this argument blocks
explosive growth.
3.9
Fundamental physical limits restrict economic growth
There might be fundamental physical limits to how much we can produce with a given amount of resources, or how
quickly we can scale up production from current levels, regardless of how good our technology is. This objection
may, for example, be found in (Aghion, B. F. Jones, and C. I. Jones 2018). If these limits are sufficiently tight, they
might prevent explosive growth. Some examples of such limits include the speed of light, conservation of energy, the
Landauer limit for irreversible computing, the Bekenstein bound for energy density, Bremermann’s limit for reversible
computing, Carnot’s theorem, etc.
17

In principle, this argument is valid: there will be fundamental physical limits that block economic growth at some point.
Many, if not all, of the bounds listed above will be relevant in constraining growth in the far future. However, we find
the argument unconvincing insofar as it’s meant to apply to explosive growth caused by AGI this century, because we’re
simply too far from the relevant fundamental physical limits for the constraints imposed by them to be binding.
For instance, humans use around 0.01% of the energy flux incident on Earth for production and consumption, and doing
1040 FLOP/year of computation on Earth alone seems feasible based only on fundamental physical limits, which at
the cost of ∼1023 FLOP/year/person estimated in Carlsmith 2020 for running the human brain would be sufficient to
simulate 1017 virtual workers. This would be equivalent to scaling up the world population by 7 orders of magnitude.
Even if every worker needs to be provided with amenities that match the current per capita energy consumption on the
planet, there’s still room for a scaling up of 3 to 4 orders of magnitude.
We simply cannot come up with any plausible scenario in which economic growth is blocked early on as a result of a
fundamental physical limit, as opposed to e.g. limitations of our engineering capabilities. As a result, we think this
argument is rather weak. We think the chance that this argument blocks explosive growth conditional on AGI is small
and conclude that it is very unlikely to block explosive growth.
4
Discussion
Having gone through the above arguments for and against explosive growth, we think that explosive growth is plausible,
both conditional on the deployment of AGI and purely unconditionally, by the end of this century. We didn’t make
the case for the unconditional view in this post, but it’s based on our view that AGI deployment this century seems
plausible based on estimates of how much resources would be needed for the creation of an AGI system and how much
we can expect effective investment into AI to get scaled up by the end of this century. This case is made in greater
detail elsewhere, e.g. Cotra 2020, Davidson 2023 and Barnett and Besiroglu 2023. We do not reproduce the detailed
arguments here and direct the interested reader to these more comprehensive sources.
Due to the numerous arguments against this conclusion that we’ve discussed here and the prediction of explosive growth
involving the extrapolation of models beyond the regime in which they have been observed to work, we think high
confidence in explosive growth is unwarranted. However, we think low confidence is also unwarranted, especially
conditional on the arrival of AGI. This is especially true as the distinct arguments are correlated with each other, so
their disjunction is less likely than we might otherwise infer under an independence assumption.
We think the most plausible confounder that would induce such a correlation is the "overall level of problem-solving
capabilities" of many human-level or superhuman intelligences running in parallel for long durations of subjective time.
The more powerful intelligence turns out to be in general, the more easily we will be able to find ways to get around
bottlenecks, and so conditional on one bottleneck not being serious, the likelihood of others being serious goes down as
well.
To formally illustrate the point about correlations, we can compute:
P
 n
[
i=1
Ai
!
= 1 −P
 n
\
i=1
Ac
i
!
= 1 −P(Ac
1)
n
Y
i=2
P(Ac
i|Ac
1, . . . , Ac
i−1),
where the superscript c denotes taking complements and A1, . . . , An are n events on a probability space. When the
arguments are correlated with each other, P(Ac
i|Ac
1, . . . , Ac
i−1) > P(Ac
i), so the product is larger than it would be were
the events jointly independent, and the probability of the disjunction is accordingly smaller.
There are other confounding influences as well. For instance, many of the arguments that function through the channel
of ruling out the economic equivalent of full automation rely on the elasticity of substitution parameter σ being small,
and many of them require it to be smaller than values often reported in the literature for the elasticity of substitution
between capital and labor e.g. in the US economy, for instance in Knoblach, Roessler, and Zwerschke 2020. This
influence similarly lowers the probability of the disjunction of all arguments that depend on this key parameter.
After taking both the individual strength of the arguments and their overall correlation structure into account, we end up
thinking that credences of less than 20% for explosive growth conditional on AI that can do most or all tasks in the
economy are unreasonably low. We estimate P(explosive growth this century | AGI this century) about as likely as
not.
4.1
Open questions
There are several important questions that would make us more or less confident in explosive growth. Below is a
non-exhaustive list of these questions:
18

1. Are there competing theories of economic history that are similarly plausible to the semi-endogenous growth
story? What do these alternative theories have to say about the deployment of AGI?
2. How does the value-add of a technology affect the strength of regulation of coordination preventing its deploy-
ment? Do regulatory-induced delays follow a power law with respect to the value of relevant technologies?
Is there strong evidence that innovations whose value is on the order of a ten times increase in the GDP of
frontier economies are often blocked for a long time, i.e. many decades?
3. How expensive will it be to build robotic systems for AGIs with adequate motor control to do most or all
embodied economic tasks humans are able to perform? Will robotics costs be of the same order of magnitude
as compute costs, lower or higher? Note that economies of scale are likely to be quite important here, so
looking at present robotics costs could be misleading.
4. Are early AI alignment failures going to make the deployment of otherwise capable AI systems by private
actors unprofitable? While it’s often assumed that misaligned AI would be deceptive and do what you want
early on before it is sufficiently capable, leading to a situation in which actors who care about safety have to
pay an “alignment tax", in our view this position is not supported by strong enough evidence for us to simply
take it for granted.
If AI becomes so unsafe that deployment is in expected value sufficiently costly even from a private actor’s
point of view, then slowing AI down becomes a matter of self-interest and not of global coordination, which is
important for assessing the likelihood of large slowdowns actually occurring.
5. In our analysis, we consider both land and energy as physical factors which could bottleneck production. In
both cases, we find that fundamental physical limits are at least some orders of magnitude away from our
current use of these factors. Is this analysis flawed? If not, are there other factors that we have neglected which
could similarly bottleneck output and prevent explosive growth?
6. What is the economic value of superhuman intelligence? To make this question quantitative in one way (though
certainly not the only way), how much more economically valuable would a human be if they had a brain
that was ten times larger or faster, and how much more overhead in energy and other costs would this incur
in humans? How favorable is this scaling relationship once we take both economic benefits and costs into
account?
For instance, a rough intuition here could be that a brain twice as large is roughly four times as economically
valuable, though this kind of scaling could be quite naive for many reasons.
All of these questions, if answered, could affect our views considerably. For instance, if superhuman intelligence is
extremely powerful, then our credence in explosive growth this century should go up, as substantial expansions in our
compute stock may not be needed for explosive growth. Some of these questions seem quite difficult to answer, while
other questions seem amenable to progress. For instance, an in-depth investigation into the economics of robotics could
plausibly answer (3), and a review of economic history from a quantitative lens could shed some light on (2).
19

Appendix
Appendix A: Likelihood scale
To communicate our uncertainty appropriately, use the following likelihood scale in our assessment of the likelihood of
explosive growth from AI occurring or being undercut by any of the obstacles discussed.
Term
Likelihood of outcome
Virtually certain
>99% probability
Very likely
90%-99% probability
Likely
66%-90% probability
About as likely as not
33%-66% probability
Unlikely
10%-33% probability
Very unlikely
1%-10% probability
Exceptionally unlikely
0%-1% probability
Table 4: Likelihood scale.
Appendix B: Semi-endogenous growth models and idea production
This appendix contains some technical details on the high-level argument laid out in the increasing returns to scale
section.
First, let’s see at a high level why we should expect hyperbolic growth to occur when accumulable inputs have increasing
returns to scale in the production function.
Suppose that Y : (R≥0)n →R≥0 is a production function mapping factor inputs (f1, f2, . . . , fn) (which might be
labor, capital, etc.) to economic output Y . If all of these inputs are strictly accumulable, in the sense that they can
be increased proportionally by reinvestment of output Y , then if we assume a fraction of output αk is invested in the
accumulation of input fk, these quantities will satisfy the differential equations
dfk
dt = αkY
For technical reasons that will become apparent soon, we want to choose the saving rates αk such that the factor
ratios fi/fj are held constant. This is equivalent to choosing αi ∝fi, so if the overall saving rate of our economy is
0 < α < 1, we’ll have
αi = α · fi
P
j fj
Using the chain rule on the production function Y gives
dY
dt =
n
X
k=1
∂Y
∂fk
dfk
dt =
n
X
k=1
∂Y
∂fk
αkY
and a substitution of the above expression for αi to this expression yields
dY
dt = α ×
n
X
k=1
∂Y
∂fk
fkY
P
j fj
Now, we bring in the assumption that Y has increasing returns to scale. Suppose that Y is homogeneous of degree
d > 1, so that it satisfies the homogeneity identity
Y (rf1, rf2, . . . , rfn) = rdY (f1, f2, . . . , fn)
for all nonnegative real numbers r. Since we assume factor ratios are held constant, our factor vector will always be of
the form (rh1, rh2, . . . , rhn) for some real number r and our initial factor endowments h1, h2, . . . , hn. Since Y ∝rd
by the above identity and P
i fi ∝r by assumption, in particular we deduce that P
i fi ∝Y 1/d. Substituting into the
above relation for dY/dt gives
dY
dt ∝Y 1−1/d
n
X
k=1
∂Y
∂fk
fk
20

Finally, suppose we differentiate the homogeneity identity for Y with respect to r at r = 1, holding factor inputs fixed.
This gives the relation
n
X
k=1
fk
∂Y
∂fk
= d × Y
Using this relation as the final ingredient, we get that Y satisfies a differential equation
dY
dt ∝Y 2−1/d
exactly as claimed in the increasing returns to scale section. When Y has increasing returns to scale, so that the
homogeneity degree d > 1, Y exhibits hyperbolic growth and diverges in finite time. We also see why a transition in
which a particular input shifts from being accumulable to not being accumulable can lower d and as a result shift us
from a superexponential to a subexponential growth regime.
One important detail here is that the saving rule we chose for our economy, that αk ∝fk, is not necessarily optimal.
However, the fact that some saving rule can achieve hyperbolic growth is a sufficient condition for the economy to
exhibit hyperbolic growth in the absence of severe market failures, so this is not an important issue.
Diminishing returns in factor production
This simple story is complicated when we consider more general laws of motion for the factors of production fi. Bloom
et al. 2020 considers a general accumulation relationship
1
f
df
dt ∝f −ϕIλ
where f denotes factor stock and I denotes investment into increasing this factor. In this formalism, the quantity
r = λ/ϕ (sometimes called the returns on factor investment) is of crucial importance, as it determines the relationship
between the growth rate of I and the growth rate of f in an exponential growth equilibrium.
It turns out we can generalize the above argument to the case where each factor follows an individual law of motion
1
fi
dfi
dt ∝f −ϕi
i
Iλi
i
but our result ends up being not quite as sharp. If we assume as before that factor ratios must stay constant, it follows
that we must have
f −ϕi
i
Iλi
i
∝f −ϕj
j
Iλj
j
for all i, j. It straightforwardly follows that we must have Ii ∝f ϕi/λi
i
= f 1/ri
i
where ri = λi/ϕi is defined as above,
and the budget constraint P
i Ii = αY once again gives
Ii = αY ×
f 1/ri
i
P
i f 1/ri
i
As before, differentiating Y and using the chain rule gives us
dY
dt = α ×
n
X
k=1
fk
∂Y
∂fk
Y
P
j f 1/rj
j
The problem is that when the rj are different and the ratios between the different fj are fixed by assumption, the
denominator here will be dominated by the factor with the least favorable returns to investment. In other words, the best
we can do is to bound the denominator from above using the relation
X
j
f 1/rj
j
= O(Y 1/(d min{r1,r2,...,rn}))
Denoting rmin = min{r1, r2, . . . , rn}, we can obtain a lower bound on the growth of Y :
dY
dt >up to a constant Y 2−1/(drmin)
As before, this is merely a sufficient condition, not a necessary one. However, if we make no further structural
assumptions about Y , this bound is the best we can do: assuming that Y is a Leontief production function, for instance,
gives a concrete case in which we must keep factor endowments proportional to each other, so this worst-case bound
21

ends up being tight. To relax this worst-case bound, it’s necessary for the factors to not be perfect complements to each
other.
It’s also necessary to relax this bound if we hope to get explosive growth out of the argument. In Bloom et al.
2020’s formalism, the returns to idea production are by assumption equal to 1 (without loss of generality), so if
accumulable inputs also have constant returns to scale we will have d = 2. In such a situation, we’ll get explosive
growth unconditionally if rideas > 1/2. However, Bloom et al. 2020 estimates rideas ≈0.32 for the whole US economy,
so this weak sufficient condition alone is insufficient to deduce we will have explosive growth once labor becomes
accumulable.
Focusing on idea production
Fortunately for us, the above calculation is in fact too general, at least from the point of view of Bloom et al. 2020.
This is because in their model, ideas enter the production function as a constant multiplier, meaning that we can narrow
down the production function of the economy to a more specific form
Y (A, f1, . . . , fn) = AYf(f1, f2, . . . , fn)
where A represents total factor productivity and f1, . . . , fn are accumulable factors as before. Yf is also assumed to be
homogeneous of degree d. We have the laws of motion
dfi
dt = Ii
1
A
dA
dt ∝A−ϕIλ
A
We now assume that we follow the previous investment allocation rule for Yf, so the ratios between the accumulable
factors fi are preserved, but unlike in the diminishing returns in factor production section we exclude A from the set
of factors among which ratios must be preserved. Instead, we assume that a share αA of GDP is invested into idea
research, and a share αf is invested in aggregate into accumulable factors. Treating these as constants, this yields
1
Y
dY
dt = 1
A
dA
dt + 1
Yf
dYf
dt >up to a constant A−ϕY λ + Y Y −1/d
f
= A−ϕY λ + A1/dY 1−1/d
Now, let x = 1/(1 + dϕ). Note that 0 < x ≤1. Our idea is to simplify the expression using the weighted
arithmetic-geometric mean inequality
xa + (1 −x)b ≥axb1−x
using x as our relative weight between the two terms, which holds whenever a, b are both positive and 0 ≤x ≤1. So
we write
1
Y
dY
dt >up to a constant A−ϕY λ + A1/dY 1−1/d > xA−ϕY λ + (1 −x)A1/dY 1−1/d
and use the weighted arithmetic-geometric mean inequality mentioned above to obtain
1
Y
dY
dt >up to a constant A−ϕx+(1−x)/dY λx+(1−1/d)(1−x)
By our choice of the value of x, the exponent of A is equal to zero, so it drops out of the expression altogether.
Substituting x = 1/(1 + dϕ) in the exponent of Y , we can simplify the right hand side to obtain
1
Y
dY
dt >up to a constant Y (r+d−1)/(ϕ−1+d)
As the denominator of the exponent is always positive, it follows that Y exhibits hyperbolic growth and diverges in
finite time whenever r + d > 1. It’s easy to see that there’s also an equilibrium where Y grows exponentially when
r + d = 1, so this condition is both necessary and sufficient for explosive growth in this model.
As we mentioned earlier, the data from Bloom et al. 2020 suggests r ≈0.32, which means that the returns to scale on
accumulable inputs can be as small as d ≈0.68 while still leaving open the possibility of explosive growth.
Appendix C: Bounds on human population growth might explain limits of historical growth
Human population growth is likely bounded from above by biological constraints on human reproduction. That is, L
cannot grow faster than some rate ¯n. If so, semi-endogenous growth theory predicts a bound on economic growth that
of a similar order as n. To see this, consider a semi-endogenous growth model described by the following equations:
Y (t) = A(t)
 K(t)
α (1 −αl)L(t)
1−α
(14)
˙A(t) = αlL(t)γA(t)ϕ
(15)
˙K(t) = sY (t) −δK(t)
(16)
˙L(t) = nL(t).
(17)
22

That is, we consider a simple semi-endogenous growth model with Hicks-neutral technical change, constant savings
rate, and with scientists split between final goods production and R&D. Solving the steady-state growth rates, we get
that:
ga =
γ
1 −ϕn, gk = n
γ + (1 −ϕ)(1 −α)
(1 −ϕ)(1 −α)

.
The steady-state rate of growth is thus:
gy = n

αγ + (1 −ϕ)(1 −α)
(1 −ϕ)(1 −α)
+
γ
1 −ϕ(1 −α)

.
Hence, gy is proportional to n. For instance, if we follow the meta-analyses from Sequeira and Neves 2020 and Neves
and Sequeira 2018 and adopt ϕ = 0.8, and γ = 0.2, and as is standard, assume α = 0.3, then gy ≈1.5n. Hence,
semi-endogenous growth theory predicts that growth is capped at some rate that is, in some sense, quite close to the
maximum rate of n.
Assuming human reproduction is such that the average woman would have no more than 10 offspring who survive to
adulthood throughout her reproductive years, semi-endogenous growth theory predicts that the economic growth rate is
bounded from above to high single-digit or low double-digit percentages. This suggests that semi-endogenous growth
theory correctly predicts the maximum rate of output growth that we have observed so far.
Appendix D: Explosive growth from growth in stock of digital workers
Consider an exogenous growth model with technological progress, where investment is split between compute and
other capital:
Y (t) = AL(t)αK(t)1−α,
the stocks of effective labor and capital grow as a result of investment:
dL(t)
dt
= sfY (t)/¯c −δLL, dK(t)
dt
= s(1 −f)Y (t) −δKK
(18)
where f is the fraction of investment channelled towards AI, s is the saving rate of the economy, and ¯c the average
cost of running a human-equivalent AI. δL, δK are the depreciation rates for the effective labor and capital stocks,
respectively. Assuming that A is constant, some algebra reveals that:3
gy = As
"
α
K(t)
L(t)
1−α f
¯c + (1 −α)
K(t)
L(t)
−α
(1 −f)
#
−αδL −(1 −α)δK
(19)
Along a balanced growth path, the ratio L/K should be equal to f/(1 −f) · 1/¯c. Substituting this into the expression
for gy and optimizing over f to find the value that leads to the highest growth rate in the long run gives f = α, so we
can assume that after labor becomes accumulable, in the long run we will have L/K ≈α/(1 −α) · 1/¯c.
Substituting into (2) would then lead to
gy = As 1
¯cα Bα −αδL −(1 −α)δK, Bα =
"
α2
1 −α
α
1−α
+ (1 −α)2

α
1 −α
α#
(20)
We can also get an estimate for the value of A for a frontier economy. The total capital stock of the US economy was
estimated in 2019 to be around 70 trillion USD in 2017 prices. Furthermore, the number of employed people in the US
in 2019 was around 180 million: there were 150 million nonfarm employees according to FRED, and the same page
states that nonfarm employment makes up for around 80% of the employees that contribute to gross domestic product.
Finally, US real GDP was around 19 trillion 2012 USD, or 20 trillion 2017 USD, in the year 2019.
Combining all of this information and assuming α = 0.7 gives us the equation
2 × 1013 $/year = A × (1.8 × 108 workers)0.7 × (7 × 1013 $)0.3
Solving for A yields
A ≈2337 $0.7workers−0.7year−1
We can now put all of this together to compute the growth rate we should expect post-AGI. If we make the simplification
that δL, δK ≪gy, we can approximate the solution by
gy ≈A(t)s¯c−0.7 0.7 · (0.3/0.7)0.3 · 0.7 + 0.3 · (0.3/0.7)−0.7 · 0.3

(21)
≈2337 × s¯c−0.7 × 0.54
(22)
≈1262 × s¯c−0.7
(23)
3The depreciation rate sets the timescale over which the hardware is useful: it’s ∼1/δL.
23

where the units of the final answer will be year inverse. Explosive growth requires gy ≥0.3, suggesting the bound
s¯c−0.7 ≥0.3/1262 ≈2.38 × 10−4
or, cast slightly differently,
¯c ≤s10/7 · (1.5 × 105) $/worker
Appendix E: Robustness to investment delays
Here, we show that our earlier results are robust even if we assume that there are delays to investment, in the sense that “realized
investment" is an exponential moving average of past inputs to investment. Formally, with a “forgetting rate" of η > 0, such a model
would look like
dK
dt = I
(24)
dI
dt = η(sY −I)
(25)
Y = AK
(26)
Here, s is a constant factor saving parameter as above, A is a multiplier with dimensions of frequency that converts the capital stock
(which has dimensions of dollars) into GDP (which has dimensions of dollars per unit time), and η is a parameter with dimensions of
frequency that controls how responsive realized investment I is to changes in savings sY .
As we shall see, 1/η is the “characteristic time scale" of investment delays in this model. Specifically, log(2)/η is the number of
months for investment to move halfway between I and sY.
This is a straightforward system of differential equations and the asymptotic growth rate will be determined by the positive eigenvalue
of the associated matrix
A =

0
1
Asη
−η

The characteristic polynomial of this matrix is det(tI −A) = t2 + ηt −Asη, which has positive root
λ = −η +
p
η2 + 4Asη
2
= η × −1 +
p
1 + 4As/η
2
When η = ∞so that adjustment is instant, the steady state growth rate should be As. Indeed, this is true in the limit, as can be seen
from the first order approximation √1 + ε = 1 + ε/2 + O(ε2).
Quantitatively, the deviation from this limit is insignificant unless η ≪4As. The order of magnitude here is dominated by A as s
is a dimensionless saving rate parameter and 4 is a constant, so roughly speaking this expression is comparing the two frequency
parameters A and η. In the calculation from the previous section, the constant that corresponds to A is 2/3 years−1, so this means
that we won’t see a substantial impact of delays to investment on the growth rate of the economy unless η ≪2/3 years−1 or
1/η ≫18 months.
The most likely values for 1/η, which is the “characteristic time scale" of investment delays in this model, are probably on the order
of a few years. Therefore this simple calculation predicts a constant factor effect of investment delays on the growth rate of the
economy after full automation. Indeed, if we assume η = As, this constant factor is
√
5 −1
2
= 1
ϕ ≈0.618 . . .
which is the reciprocal of the golden ratio, meaning that the growth rate is reduced to roughly 60% of what we would have predicted
it to be in the naive model not taking these adjustment costs into account. Overall, we think the uncertainty this adds to the calculation
is much smaller than the uncertainty already present from our estimates of A and s, so this effect looks like it can be safely ignored,
perhaps at the expense of choosing other model parameters a bit more conservatively.
References
Aghion, Philippe, Benjamin F Jones, and Charles I Jones (2018). “Artificial intelligence and economic growth”. In: The
economics of artificial intelligence: An agenda. University of Chicago Press, pp. 237–282.
Barnett, Matthew and Tamay Besiroglu (2023). The Direct Approach. Accessed: 2023-5-16. URL: https://epochai.
org/blog/the-direct-approach.
Basu, Susanto and John G Fernald (1997). “Returns to scale in US production: Estimates and implications”. In: Journal
of political economy 105.2, pp. 249–283.
Bloom, Nicholas et al. (Apr. 2020). “Are Ideas Getting Harder to Find?” In: American Economic Review 110.4, pp. 1104–
44. DOI: 10.1257/aer.20180338. URL: https://www.aeaweb.org/articles?id=10.1257/aer.20180338.
Bolt, Jutta and Jan Luiten Van Zanden (2020). “Maddison style estimates of the evolution of the world economy. A new
2020 update”. In: Maddison-Project Working Paper WP-15, University of Groningen, Groningen, The Netherlands.
24

Brynjolfsson, Erik (1993). “The productivity paradox of information technology”. In: Communications of the ACM
36.12, pp. 66–77.
Brynjolfsson, Erik et al. (2019). GDP-B: Accounting for the value of new and free goods in the digital economy.
Tech. rep. National Bureau of Economic Research.
Carlsmith, Joseph (2020). How Much Computational Power Does It Take to Match the Human Brain? Tech. rep. Open
Philanthropy.
Cotra, Ajeya (July 2020). Forecasting TAI with biological anchors Part 1: Overview, conceptual foundations, and
runtime computation. Accessed on 30 April 2023.
Davidson, Tom (2021). “Could advanced AI drive explosive economic growth”. In: Open Philanthropy.
– (2023). What a compute-centric framework says about takeoff speeds.
Erdil, Ege and Tamay Besiroglu (2022). “Algorithmic progress in computer vision”. In: arXiv preprint
arXiv:2212.05153.
Fixler, Dennis J, Ryan Greenaway-McGrevy, and Bruce T Grimm (2011). “Revisions to GDP, GDI, and their major
components”. In: Survey of Current Business 91.7, pp. 9–31.
Garfinkel, Ben (Sept. 2020). Does Economic History Point Toward a Singularity? Accessed: 2023-05-10. URL: https:
//docs.google.com/document/d/1wcEPEb2mnZ9mtGlkv8lEtScUw1k_dI0akbuu1ltb0gM/edit#heading=
h.q55yx84q5kfe.
– (2021). Review of "Could Advanced AI Drive Explosive Economic Growth?" URL: https://docs.google.com/
document/d/1bPxxrIroD5Ya_9mgnFoE3dj_OGXfKgpuoh1Y6tFuQZo/edit#heading=h.nqnhvf79zc2j.
Granulo, Armin, Christoph Fuchs, and Stefano Puntoni (2021). “Preference for human (vs. robotic) labor is stronger in
symbolic consumption contexts”. In: Journal of Consumer Psychology 31.1, pp. 72–80.
Hernandez, Danny and Tom B Brown (2020). “Measuring the algorithmic efficiency of neural networks”. In: arXiv
preprint arXiv:2005.04305.
Herzer, Dierk (2022). “Semi-endogenous versus Schumpeterian growth models: a critical review of the literature and
new evidence”. In: Review of Economics 73.1, pp. 1–55.
Hobbhahn, Marius and Tamay Besiroglu (2022). Trends in GPU price-performance. Accessed: 2023-5-12. URL:
https://epochai.org/blog/trends-in-gpu-price-performance.
Hoffmann, Jordan et al. (2022). “Training compute-optimal large language models”. In: arXiv preprint
arXiv:2203.15556.
Jeremy, David J (1977). “Damming the flood: British government efforts to check the outflow of technicians and
machinery, 1780–1843”. In: Business History Review 51.1, pp. 1–34.
Ji, Ziwei et al. (2023). “Survey of hallucination in natural language generation”. In: ACM Computing Surveys 55.12,
pp. 1–38.
Jones,
Ben
(2021).
Comments
on
“Could
Advanced
AI
Drive
Explosive
Economic
Growth?”
Google Docs. Reviewer comments.
URL:
https : / / docs . google . com / document / d /
1jP9Bb6J6BXH5v6EshsPF2NE1GiWatPxUUrK9wDEpTqA/edit#.
Jones, Charles I (2022). “The past and future of economic growth: A semi-endogenous perspective”. In: Annual Review
of Economics 14, pp. 125–152.
Kaplan, Jared et al. (2020). “Scaling laws for neural language models”. In: arXiv preprint arXiv:2001.08361.
Kariel, Joel and Anthony Savagar (2022). “Returns to Scale and Productivity”. In.
Karnofsky, Holden (2021). The Duplicator: Instant Cloning Would Make the World Economy Explode. Accessed: Sep
15, 2023. URL: https://www.cold-takes.com/the-duplicator/ (visited on 09/15/2023).
Knoblach, Michael, Martin Roessler, and Patrick Zwerschke (2020). “The elasticity of substitution between capital
and labour in the US economy: A meta-regression analysis”. In: Oxford Bulletin of Economics and Statistics 82.1,
pp. 62–82.
Korus, Sam (2019). “Industrial Robot Cost Declines Should Trigger Tipping Points in Demand”. In: ARK Invest Articles.
Accessed: 30 August 2023. URL: https://ark-invest.com/articles/analyst-research/industrial-
robot-cost-declines/.
Kremer, Michael (1993). “Population growth and technological change: One million BC to 1990”. In: The quarterly
journal of economics 108.3, pp. 681–716.
Kruse-Andersen, Peter (2017). “Testing R&D-Based Endogenous Growth Models”. In: Available at SSRN 2947528.
Landefeld, J Steven, Eugene P Seskin, and Barbara M Fraumeni (2008). “Taking the pulse of the economy: Measuring
GDP”. In: Journal of Economic Perspectives 22.2, pp. 193–216.
Lucas Jr, Robert E (1988). “On the mechanics of economic development”. In: Journal of monetary economics 22.1,
pp. 3–42.
Mankiw, N Gregory and Matthew D Shapiro (1986). News or noise? An analysis of GNP revisions.
Nakamura, Leonard I, Jon Samuels, and Rachel H Soloveichik (2017). “Measuring the’Free’Digital Economy within
the GDP and productivity accounts”. In.
25

National Aeronautics and Space Administration (2005). The Balance of Power in the Earth-Sun System. Available
at www.nasa.gov. URL: https://eospso.nasa.gov/sites/default/files/publications/NASA-Facts-
EnergyBalance.pdf.
Neves, Pedro Cunha and Tiago Neves Sequeira (2018). “Spillovers in the production of knowledge: A meta-regression
analysis”. In: Research Policy 47.4, pp. 750–767.
Ritchie,
Hannah,
Max
Roser,
and
Pablo
Rosado
(2022).
“Energy”.
In:
Our
World
in
Data.
https://ourworldindata.org/energy.
Roodman, David (2020). On the probability distribution of long-term changes in the growth rate of the global economy:
An outside view.
Sequeira, Tiago Neves and Pedro Cunha Neves (2020). “Stepping on toes in the production of knowledge: A meta-
regression analysis”. In: Applied Economics 52.3, pp. 260–274.
Sevilla, Jaime and Ege Erdil (2022). A time-invariant version of Laplace’s rule. Accessed: 2023-5-9. URL: https:
//epochai.org/blog/a-time-invariant-version-of-laplace-s-rule.
Sirkin, Harold L., Michael Zinser, and Justin Ryan Rose (2015). The Robotics Revolution: The Next Great Leap in
Manufacturing.
Trammell, Philip and Anton Korinek (2020). “Economic growth under transformative AI”. In: Global Priorities Institute,
September.
York, Robert C and Paul Atkinson (1997). “The reliability of quarterly national accounts in seven major countries: A
user’s perspective”. In: Journal of Economic and Social Measurement 23.4, pp. 239–262.
Yudkowsky, Eliezer (2021). Yudkowsky and Christiano discuss "Takeoff Speeds". 72 min read, 176 comments, Published
on 22nd Nov 2021, Crossposted from the AI Alignment Forum. URL: https://www.lesswrong.com/posts/
vwLxd6hhFvPbvKmBH/yudkowsky-and-christiano-discuss-takeoff-speeds.
26

