86    COMMUNICATIONS OF THE ACM   |  FEBRUARY 2019  |  VOL. 62  |  NO. 2
review articles
A FUNDAMENTAL TECHNIQUE in reasoning about programs 
is the use of logical assertions to describe properties of 
program states. Turing used assertions to argue about 
the correctness of a particular program in 1949,40 and 
they were incorporated into general formal systems for 
program proving starting with the work of Floyd21 and 
Hoare22 in the 1960s. Hoare logic, which separation 
logic builds upon, is a formal system for proving 
specifications of the form 
where the precondition and postcondition are 
vassertions describing properties of the input and 
output states. For example,
can serve as a specification of an imperative program 
that computes the factorial of the value held in variable x 
and places it in y.
Hoare logic and related systems worked very well for 
programs manipulating simple primitive data types 
such as for integers or strings, but proofs became more 
complex when dealing with structured data containing 
embedded pointers. One of the found-
ing papers of separation logic summa-
rized the problem as follows.32
"The main difficulty is not one of find-
ing an in-principle adequate axiomatiza-
tion of pointer operations; rather there 
is a mismatch between simple intu-
itions about the way that pointer opera-
tions work and the complexity of their 
axiomatic treatments. … when there is 
aliasing, arising from several pointers to 
a given cell, an alteration to a cell may af-
fect the values of many syntactically un-
related expressions."
Bornat provided a good description 
of the struggles in reasoning about mu-
table data structures up to 2000.6
In joint work with John Reynolds and 
others we developed separation logic 
(SL) to address the fundamental prob-
lem of reasoning about programs that 
mutate data structures. From a special 
logic for heaps, it gradually evolved into 
a general theory for modular reasoning 
about concurrent as well as sequential 
programs. Efforts by many research-
ers established that the logic provides a 
basis for efficient proof search in auto-
matic and semi-automatic proof tools, 
for example, giving rise to the Infer static 
analyzer, a tool that is in deployment at 
Facebook where it catches thousands 
of bugs per month before code reaches 
production in products used daily by 
over one billion people.
Separation logic is an extension of 
Hoare logic, which employs novel logi-
cal operators, most importantly the sep-
arating conjunction * (pronounced “and 
Separation 
Logic
DOI:10.1145/3211968
Separation logic is a key development in 
formal reasoning about programs, opening up 
new lines of attack on longstanding problems.
BY PETER O’HEARN
 key insights
˽
˽ Separation logic supports in-place 
updating of facts as we reason, in a way 
that mirrors in-place update of memory 
during execution, and this leads to logical 
proofs about imperative programs that 
match computational intuition.
˽
˽ Separation logic supports scalable 
reasoning by using an inference rule 
(the frame rule) that allows a proof to be 
localized to the resources that a program 
component accesses (its footprint).
˽
˽ Concurrent separation logic shows  
that modular reasoning about threads 
that share storage and other resources  
is possible.

FEBRUARY 2019  |  VOL. 62  |  NO. 2  |  COMMUNICATIONS OF THE ACM    87
IMAGE BY ANNA GARMATIY 
separately”) when writing assertions. 
For example, we might write:
as a specification of code that wires to-
gether two memory locations into a cyclic 
linked list. Here x  v says that pointer 
variable x holds the address of a memory 
location where v is stored (or more brief-
ly, x points to v), and a command of the 
form [x] = v updates the location referred 
to by x so that its contents becomes v′. 
The use of * rather than the usual Bool-
ean conjunction ∧ ensures x and y are not 
aliases—distinct names for the same lo-
cation—so that we have a two-element 
cyclic list in the postcondition. A central 
principle is that a command that mu-
tates a single location affects only one 
*-conjunct: operational in-place update 
is mirrored in the logic, addressing the 
key difficulty where “an alteration to a 
cell may affect the values of many syntac-
tically unrelated expressions.”
Reynolds was the first to describe a 
program logic including the separating 
conjunction; he defined an intuitionis-
tic (constructive) logic with *,37 building 
on earlier ideas of Burstall.10 O’Hearn, 
and Ishtiaq26 realized the assertion lan-
guage could be seen as an instance of the 
resource logic BI of O’Hearn and Pym;31 
they independently discovered the same 
intuitionistic logic as Reynolds, and 
also saw that a more powerful Boolean 
(nonconstructive) variant was possible 
in which one could reason about explicit 
memory management (Reynolds had as-
sumed garbage collection). They also in-
troduced the separating implication –*.

88    COMMUNICATIONS OF THE ACM   |  FEBRUARY 2019  |  VOL. 62  |  NO. 2
review articles
proposed a concurrent separation logic 
(CSL). CSL showed efficient reasoning 
about threads that share access to stor-
age, proofs that mirrored design prin-
ciples espoused by Dijkstra at the birth 
of concurrent programming.16 The cor-
rectness of CSL’s proof rules (its ‘sound-
ness’) turned out to be a formidable 
problem, solved eventually by Brookes. 
Brookes and O’Hearn were awarded 
the 2016 Gödel prize for their papers on 
CSL,8,30 the significance of which was 
summed up as follows:
"For the last 30 years experts have 
regarded pointer manipulation as an 
unsolved challenge for program verifica-
tion and shared-memory concurrency as 
an even greater challenge. Now, thanks 
to CSL, both of these problems have 
been elegantly and efficiently solved; 
and they have the same solution." 
	
—2016 Gödel Prize citationa
It is worth remarking that the first 
part of this citation, about pointer ma-
nipulation, applies to sequential and 
not just concurrent SL.
After the early papers, research on SL 
expanded rapidly. Starting from a spe-
cial logic for heaps SL has evolved into 
a general theory for modular reasoning. 
Non-standard models of SL based on an 
abstract model theory due to Pym pro-
vided many potential avenues for wider 
application, and Gardner and others 
realized that there exist non-standard 
models that support modular reason-
ing about intertwined structures as if 
they were separate. SL has even been 
applied to interfering processes using 
fine-grained concurrency, a situation far 
removed from the original intuitions of 
the logic.
SL is the basis of numerous auto-
mated proof tools, and it has been used 
in significant verification efforts. It has 
been used to provide the first verifica-
tion of a crash-proof file system,14 and 
to provide the first verification of a com-
mercial, preemptive OS microkernel.41 
These verification efforts are semi-
automatic, done by a human together 
with a proof assistant (in these cases, 
the Coq proof assistant). SL has also 
been used in static program analysis, 
where weaker properties than full cor-
rectness are targeted but with higher 
automation, so that the tool can scale 
better both in the sizes of codebases 
a	 https://bit.ly/2ywwlpp
SL for sequential programs reached 
maturity in a further paper of O’Hearn, 
Reynolds and Yang.32 In that work 
O’Hearn proposed the following prin-
ciple of local reasoning, both as a way to 
describe what was special about SL and 
as a guiding principle for development 
of reasoning methods.
"To understand how a program 
works, it should be possible for reason-
ing and specification to be confined to 
the cells that the program actually ac-
cesses. The value of any other cell will 
automatically remain unchanged."
A proof rule—the frame rule—al-
lowed to infer that cells remain un-
changed when they are not mentioned 
in a precondition. The frame rule was 
named in homage to the frame problem 
from artificial intelligence, which con-
cerns axiomatizing state changes with-
out enumerating all of the things that do 
not change. The frame rule is the key to 
scalable reasoning in SL.
Reynolds’ influential survey article 
summarized the early developments 
up to 2002.38 At the end of this early pe-
riod, O’Hearn circulated a note that 
Figure 1. Picture semantics.
x
y
x
y
x
y
x = 10
y = 42
10
decomposes into
and
separately
42
42
10
x = 10
y = 42
10
42
x = 10
y = 42
42
10
(
(
)
)
Figure 2. Mathematical semantics.

FEBRUARY 2019  |  VOL. 62  |  NO. 2  |  COMMUNICATIONS OF THE ACM    89
review articles
covered and the number of program-
mers served. Static analysis with SL has 
matured to the point where it has been 
applied industrially in the Facebook 
Infer program analyzer, an open source 
tool used at Facebook, Mozilla, Spotify, 
Amazon Web Services, and other com-
panies (www.fbinfer.com).
The purpose of this article is to de-
scribe the basic ideas of SL as well as 
these and other developments.
Separating Conjunction 
and Implication
Mathematical semantics has been 
critical to the discovery and further SL 
development, but many of the main 
points can be gleaned from “picture 
semantics.” Consider the first picture 
in Figure 1. We read the formula at 
the top of this figure as “x points to 
y and separately y points to x.” Go-
ing down the middle of the diagram 
is a line that represents a heap par-
titioning: a separating conjunction 
asks for a partitioning that divides 
the heap into parts, heaplets, satisfy-
ing its two conjuncts. At the bottom 
of the first picture is an example of 
a concrete memory description that 
corresponds to the diagram. There, 
x and y have values 10 and 42 (in the 
“environment,” or “register bank”), 
and 10 and 42 are themselves loca-
tions with the indicated contents (in 
the “heaplet,” or even “RAM”).
The indicated separating con-
junction here is true of the pictured 
memory because the parts satisfy the 
conjuncts, as indicated in the second 
picture. The meaning of “x points to 
y and yet to nothing” is precisely dis-
ambiguated in the RAM description 
below the diagram: x and y denote val-
ues (10 and 42), x’s value is an allocat-
ed memory address which contains 
y’s value, but y’s value is not allocated. 
The separating conjunction splits the 
heap/RAM, but it does not split the as-
sociation of variables to values.
Generally speaking, the separating 
conjunction P * Q is true of a heap if it 
can be split into two heaplets, one of 
which makes P true and the other of 
which makes Q true. A distinction be-
tween * and Boolean conjunction ∧ is 
that P * P ≠ P where P ∧ P = P. In particu-
lar, x  v * x  v is always false: there is 
no way to divide any heap in such a way 
that a cell x goes to both partitions.
* is often used with linked struc-
tures. If list (x, y) describes an acyclic 
linked list running from x to y, then we 
can describes a structure with a list seg-
ment, followed by a single pointer, fol-
lowed by a further list running up to 0 
(null), as follows: 
x
t
y
This is the kind of structure you 
might need to consider when deleting 
an element from a list, or inserting one 
into it.
There is a further connective, the sep-
arating implication or “magic wand.” 
P –* Q says that whenever the current 
heaplet is extended with a separate 
heaplet satisfying P, the resulting com-
bined heaplet will satisfy Q. For exam-
ple, (x  –) * ((x  3) –* Q) says that x is 
allocated in the current heap, and that if 
you mutate its contents to 3 then Q will 
hold. This describes the “weakest pre-
condition” for the mutation [x] = 3 with 
postcondition Q.26
Finally, there is an assertion emp 
which says “the heaplet is empty,” emp 
is the unit of *, so that P = emp * P = P * 
emp. Also, –* and * fit together is a way 
similarly to how implication ⇒ and con-
junction ∧ do in standard logic. For ex-
ample, the entailment
A * (A –* B)  B
(where  reads “entails”) is a SL relative 
of “modus ponens.”
Although we will concentrate on the 
informal picture semantics in this ar-
ticle, for the theoretically inclined we 
have included a glimpse of the formal 
semantics in Figure 2.
Rules for Program Proof
Figure 3 contains a selection of proof 
rules of SL. The rules are divided into 
axioms for basic mutation commands 
(the “small axioms”) and inference 
rules for modular reasoning. An infer-
ence rule says “if you can derive what 
is above the line, then so can you what 
is below,” and the axioms are deriv-
able true statements that are given. 
The small axioms are for a program-
ming language with load and store 
instructions similar to an assembly 
language. If we vary the programming 
language the small axioms change. 
The concurrency rule uses a composi-
tion operator || for running two pro-
cesses in parallel, derived from Dijks-
tra’s parbegin/parend.16
The first small axiom just says that if 
x points to something beforehand, then 
it points to v afterward, and it says this 
for a small portion of the state in which x 
is the only active cell.
Figure 3. Separation logic proof system (a selection).

90    COMMUNICATIONS OF THE ACM   |  FEBRUARY 2019  |  VOL. 62  |  NO. 2
review articles
for the second step of the code to wire up 
a cyclic linked list described at the start 
of the paper.
The ultimate theoretical support for 
the small axioms came from a complete-
ness theorem in Yang’s Ph.D. thesis.42 
He showed the small axioms and frame 
rule and several other inference rules 
(particularly Hoare’s rules for strength-
ening preconditions and weakening 
postconditions, and a rule for existential 
quantifiers) can be used to derive all true 
Hoare triples for these statements.
Locality properties of program be-
havior, and their connection to logic,13,44 
are critical for these results:
"An assertion talks about a heaplet 
rather than the global heap, and a spec 
{P} C {Q} says that if C is given a heaplet 
satisfying P then it will never try to ac-
cess heap outside of P (other than cells 
allocated during execution) and it will 
deliver a heaplet satisfying Q if it termi-
nates.2"
In-place reasoning as with the two-
element cyclic list has been applied to 
many imperative programs. As an ex-
ample, consider the insertion of a node 
y into a linked list after position x. We 
can do this in two steps: first we swing 
x’s pointer so it points to y, and then we 
swing y to point to z (the node after x).
Here, in the precondition for each 
step we write the frame in red; it is the 
blue that is updated in place. The reader 
can see how, using the small axiom for 
free together with the frame rule, we 
could reason about the converse case of 
removing an element from a list.
This example generalizes to many 
other list and tree algorithms: inser-
tion, deletion, reversal, and so on. The 
SL proofs resemble the box-and-pointer 
arguments that have long been used 
informally in describing data structure 
mutation.
These ideas extend to concurrent 
programs; for example, the second rule 
instance in Figure 4 uses the concurren-
cy rule to reasons about our two-element 
cyclic list, but wired up concurrently 
rather than sequentially. The * in the 
precondition in this instance ensures 
that x and y are not aliases, so there is no 
data race in the parallel program.
The second axiom says that if x points 
to v and we read x into y, then y will have 
value v. Here, we distinguish between 
the value in a variable or register (x and 
y) and the r-value in a heap cell whose l-
value is the value held in x. The second 
axiom assumes that x does not appear 
in syntactic expression v (see O’Hearn et 
al.32 for a precise description of this and 
other variable side conditions).
The allocation axiom says: If you start 
with no heap, then you end with a heap 
of size 1. Conversely the De-Allocation 
axiom starts with a hap of size 1 and 
ends with the empty heap. The Appli-
cation axiom assumes that allocation 
always succeeds. To model a case where 
allocation might fail we could use a dis-
junctive postcondition, like x  – ∨ x == 
0; this is what tools such as SpaceInvad-
er and Infer, discussed later, do for mal-
loc() in C.
The small axioms are so named be-
cause each mentions a small amount 
of memory: a single memory cell. When 
people first see the axioms they can 
come as a shock: aren’t they too sim-
ple? Previous approaches had complex 
descriptions accounting for the effect 
of mutations on global properties of 
graph-like structures.6
In actuality, there is a sense in which 
the small axioms capture all that is 
needed to know about the statements 
they describe. In intuitive terms, we can 
say that imperative computation pro-
ceeds by in-place update, where these 
primitive statements update or access a 
single memory cell at a time; describing 
what happens to only that cell should be 
enough. The small axioms are thus an 
extreme illustration of the principle of 
local reasoning.
The frame rule in Figure 3 provides 
logical support for this intuition. It al-
lows us to extend reasoning from one 
to multiple cells; so the seeming restric-
tion to one cell in the small axioms is not 
a restriction at all, but rather a pleasantly 
succinct description. For instance, if we 
choose x  y as our frame then the first 
instance in Figure 4 gives the reasoning 
Figure 4. Frame and concurrency examples.
Figure 5. deletetree example.
root
r
l
x
y

FEBRUARY 2019  |  VOL. 62  |  NO. 2  |  COMMUNICATIONS OF THE ACM    91
review articles
The concurrency rule is the main rule 
of CSL. In applying CSL to languages 
with dynamic thread creation instead 
of parbegin/-parend different rules are 
needed, but the basic point that sepa-
ration allows independent reasoning 
about processes carries over.
SL’s concurrency rule took inspira-
tion from the “disjoint concurrency 
rule” of Hoare.23 Hoare’s rule used ∧ in 
place of * together with side conditions 
to rule out interference.b * allows us to 
extend its applicability to pointer struc-
tures. But even without pointers, the 
CSL rule is more powerful. Indeed, upon 
seeing CSL
Hoare immediately exclaimed to the 
author: “We can prove parallel quick-
sort!” A direct proof can be given using 
* to recognize and unite disjoint array 
partitions.30
Frames, Footprints,  
and Local Reasoning
The previous section describes how the 
separating conjunction leads to simple 
proofs of the individual steps of heap 
mutations, and how the frame rule em-
beds reasoning about small chunks of 
memory within larger memories. Here, 
the rules' more fundamental role as a ba-
sis for scalable reasoning is explained.
I illustrate by reasoning about a re-
cursive program for deleting the nodes 
in a binary tree. Consider the C program 
in (1) of Figure 5. This program satis-
fies the specification in (2) of the figure, 
where the tree predicate says that its ar-
gument points to a binary tree in mem-
ory. The predicate is defined recursively 
in (3), with a diagram below depicting 
what is described by the else part of the 
definition. Note that here we are using a 
“points-to” predicate root  [l : x, r : y] 
for describing records with l and r fields.
The use of emp in the if branch of 
the definition means that tree(r) is true 
of a heaplet that contains all and only 
the cells in the tree; there are no ad-
ditional cells. Thus, the specification 
of deletetree(r) does not mention 
nodes not in in the tree. This is analo-
gous to what we did with the small axi-
oms for basic statements in Figure 3, 
b	 There are variable conditions in some pre-
sentations of SL, that can technically be done 
away with eliminated by using a version of * 
that separates variables as well as heap.34 This 
article glosses over this issue.
and is a typical pattern in SL reasoning: 
“small specifications” are used which 
mention only the cells touched by the 
program component (its footprint).
The critical part of the proof of the 
program is presented in (4), where the 
precondition at the beginning is ob-
tained by unwinding the recursive defi-
nition using the if condition root ! = 0. 
The proof steps then follow the intuitive 
description of the algorithm: the first 
recursive call deletes the left subtree, 
the second call deletes the right sub-
tree, and the final statement deletes the 
root node. In the pictured reasoning, 
the overall specification of the proce-
dure is applied as an induction hypoth-
esis at each call site, together with the 
Frame Rule for showing that the parts 
not touched by recursive calls are left 
unchanged. For instance, the asser-
tions for the second recursive call are 
an instance of the Frame Rule with the 
triple {tree(right)} deletetree(right)
{emp} as the premise.
The simplicity of this proof comes 
about because of the principle of local 
reasoning. The frame rule allows in-
place reasoning for larger-scale opera-
tions (entire procedures) than individual 
heap mutations. And it allows the speci-
fication to concentrate on the footprint 
of a procedure instead of the global state. 
Put contrapositively, the deletetree 
procedure could not be verified without 
the frame rule, unless we were to compli-
cate the initial specification by including 
some representation of frame axioms 
(saying what does not change) to enable 
the proofs at the recursive call sites.
This reasoning uses a tree predicate 
suitable for reasoning about mem-
ory safety; it mentions that we have a 
tree, but not what data it holds. For 
functional correctness reasoning, it 
is typical to use inductive predicates 
that connect memory structures to 
mathematical entities. In place of tree 
(root) we could have a predicate tree (τ, 
root) that says root points to an area of 
memory representing the mathemati-
cal binary tree τ, where a mathemati-
cal tree is either empty or an atom or 
a pair of trees. We could then specify 
a procedure for copying a tree using a 
postcondition of the form
that says we have two structures in mem-
ory representing the same mathemati-
cal tree. An assertion like this would tell 
us that we could mutate one of the trees 
without affecting the other (at which 
point they would cease to represent the 
same tree).
For data structures without much 
sharing, such as variations on lists and 
trees, reasoning in SL is reminiscent 
of reasoning about purely functional 
programs: you unroll an inductive defi-
nition, then mutate, then roll it back 
up. Inductive definitions using * and 
mutation go well together. The first SL 
proof to address complex sharing was 
done by Yang in his Ph.D. thesis, where 
he provided a verification of the classic 
Schorr-Waite graph-marking algorithm. 
The algorithm works by reversing links 
during search, and then restoring them 
later: A space-saving representation of 
the stack of a recursive algorithm. Part 
of the main invariant in Yang’s proof is
–*
*
capturing the idea that if you replace 
the list of marked nodes by a restored 
list, then you get a spanning tree. Yang’s 
proof reflected the intuition that the al-
gorithm works by a series of local sur-
geries that mutate small parts of the 
structure: The proof decomposed into 
verifications of the surgeries, and ways 
of combining them.
The idiomatic use of –* in assertions 
of the form A * (B –*  C) to describe gen-
eralized update was elevated to a general 
principle in work of Hobor and Villard.25 
They give proofs of a number of pro-
grams with significant sharing, includ-
ing graphs, dags, overlaid structures (for 
example, a list overlaying a tree), and 
culminating in the copying algorithm in 
Cheney’s garbage collector.
Many papers on SL have avoided –*, 
often on the grounds that it complicates 
automation and is only needed for pro-
grams with significant sharing. How-
ever, –* is recently making something of 
a comeback. For example, it is used rou-
tinely as a basic tool in the Iris higher-
order logic.29
Concurrency, Ownership,  
and Separation
The concurrency rule in Figure 3 says: 
To prove a parallel composition we give 
each process a separate piece of state, 
and separately combine the postcon-

92    COMMUNICATIONS OF THE ACM   |  FEBRUARY 2019  |  VOL. 62  |  NO. 2
review articles
Reynolds), in 2004, proved the theorem, 
which justified the logic.
Abstraction and  
the Fiction of Separation
There was considerable work on extend-
ing SL after those early papers. Some of it 
concentrated on different programming 
paradigms, such as object-oriented pro-
gramming or scripting languages, or 
on additional programming primitives 
such as message passing, reentrant lock 
and fork/join concurrency. Besides ex-
tensions to cover an ever-greater variety 
of programming, two conceptual devel-
opments opened major new directions.
˲
˲ In his Ph.D. thesis, Parkinson 
showed how abstract predicates (predi-
cate variables) fit together nearly with * 
in the description of classes and other 
stateful data abstractions.33
˲
˲ Gardner and others emphasized a 
concept of fictional separation, where 
strong separation properties could be 
assumed of data abstractions, even for 
implementations relying on sharing.
These ideas were first described in 
a sequential setting. Dinsdale-Young, 
Gardner and Wheelhouse described 
an implementation of a module of se-
quences in terms of linked lists and not-
ed a mismatch: at the abstract level an 
operation might affect a small part of a 
sequence, where at the implementation 
level its footprint could involve the en-
tire list; conversely, locality can increase 
with abstraction.19 Meanwhile, Parkin-
son initially targeted a sequential subset 
of Java. Subsequent work showed how 
abstract predicates could be understood 
using higher-order versions of SL.5
While they could be expressed in a 
sequential setting, the ideas took flight 
when transported to concurrency. The 
CAP logic18 combined insights on ab-
stract predicates and fiction, along 
with those of CSL, to reason about data 
abstractions with interference in their 
implementations. The views theory17 
provided a foundation where separa-
tion does not appear in the normal exe-
cution semantics of programs, but only 
in an abstraction of it. Views showed 
that a simple version of CSL can embed 
many other techniques including even 
the classic rely-guarantee method;27 
this is surprising because rely-guaran-
tee was invented for reasoning about 
interference, almost the opposite of 
the basis of original SL.
ditions for each process. The rule sup-
ports completely independent reason-
ing about processes. This rule can be 
used to provide straightforward proofs 
of processes that don’t share access to 
storage. We mentioned parallel quick-
sort earlier, and deletetree() pro-
vides another illustration: we can run 
the two recursive calls in parallel rather 
than sequentially, as presented in the 
proof outline (1) in Figure 6.
In work on CSL, proof outlines are 
often presented in a spatial fashion like 
this: this outline shows the premises of 
the concurrency rule in the left and right 
Hoare triples, the overall precondition 
(the pre1 * pre2) at the beginning, and 
the post at the end.
While this reasoning is simple, if CSL 
had only been able to reason about dis-
joint concurrency, where there is no inter-
process interaction, then it would have 
rightly been considered rather restrictive. 
An important early example done with CSL 
was a pointer-transferring buffer, where 
one thread allocates a pointer and puts it 
into a buffer while the other thread reads it 
out and frees it. Crucially, not only is the 
pointer deemed to transfer from one pro-
cess to another, but the “knowledge that it 
is allocated” transfers with the proof. The 
proof establishing absence of memory er-
rors is shown in (2) of Figure 6. A way to 
implement the buffer code for put and 
get is to use locks to synchronize access to 
a shared variable and a Boolean to signal 
when the buffer is full. We will not delve 
into the subproofs of buffer operations 
here—for that, consult O’Hearn30—but 
we want to talk about a shift in perspec-
tive on the meanings of logical assertions 
that the proof (2) led to.
Notice the assertion emp after the 
put(x) statement in the left process. 
We could not prove a mutation were 
we to place it there, because emp is not 
a sufficient precondition for any muta-
tion; that is fortunate as such a muta-
tion could lead to a race condition. But 
it is not the case that we know the glob-
al heap is empty, because the pointer 
x could still persist. Rather, the knowl-
edge that it points to something has 
been forgotten, transferred to the sec-
ond process where it materializes as  
y  –. A reading of assertions began 
to form based on the “right to deref-
erence” or “ownership” (taken as syn-
onymous with right to dereference). 
On this reading emp says “I don’t have 
permission to dereference any heap,” 
or “I own nothing,” rather than “the 
heap is empty.” Similarly, x  – says “I 
own x” (where “I” is the process from 
which the assertion is made).
The ownership transfer example 
made it clear that quite a few concur-
rent programs would have much sim-
pler proofs than before. Modular proofs 
were provided of semaphore programs, 
of a toy memory manager, and programs 
with interacting resources. It seemed as 
if the proofs mirrored design principles 
used to simplify reasoning about con-
current processes, such as in Dijkstra’s 
idea of loosely connected processes:
“[A]part from the (rare) moments of 
explicit intercommunication, the indi-
vidual processes are to be regarded as 
completely independent of each other.”16
However, the very feature that gave 
rise to the unexpected power, ownership 
transfer, made soundness (whether the 
rules prove only true statements) non-
obvious. O’Hearn worked on soundness 
during 2001 and 2002, without success. 
In May of 2002 he turned to Brookes who 
eventually (with important input from 
Figure 6. Concurrency proofs.

FEBRUARY 2019  |  VOL. 62  |  NO. 2  |  COMMUNICATIONS OF THE ACM    93
review articles
Today, advanced logics are often for-
mulated as variations on the theme of 
“higher-order concurrent separation 
logic.” One of these, Verifiable C, is the 
foundation of Appel’s Verified Software 
Toolchain,1 and includes an expressive 
higher-order logic supporting recursive 
predicates. Iris29 encompasses reason-
ing about fine-grained concurrency and 
even relaxed memory, based on differ-
ent instantiations of a single generic 
model. Iris has been used to provide 
a foundation of the type system of the 
Rust programming language,28 which 
is very natural when you consider that 
ownership transfer is one of the central 
ideas in Rust.
Technically, these works are based on 
“non-standard models” of SL, different 
from the heaplet model but instances of 
Pym’s resource semantics as in Figure 
2; see Pym et al.36 There are many such 
models, including ones incorporating 
read and other permissions,7 auxiliary 
state,39 time,39 protocols,29 and others. 
Abstract SL13 showed how general pro-
gram logic could be defined based on 
these models, and the works just men-
tioned and others showed that some of 
them had surprising ramifications.
Fictional 
separation 
and 
views 
worked to reimagine fundamental con-
cepts. The programs being proven go 
beyond the loosely connected processes 
that CSL was originally designed for. 
Significant new theoretical insights and 
soundness arguments were needed to 
justify the program-proof rules support-
ing the fine-grained concurrency exam-
ples.17 This led to a flowering of interest 
and new ideas which is still in progress. 
A recent survey on CSL provides many 
more references in addition to those 
mentioned here.9
Directions in  
Mechanized Reasoning
SL spawned new approaches to verifi-
cation tools. In order to provide a taste 
of where the field has gone, we present 
a sampling of practical achievements; 
that is, we focus on the end points rath-
er than the (important) advancements 
along the way that helped get there. 
Further references to the literature, in-
cluding discussion on intermediate ad-
vances, may be found in the appendix 
(https://bit.ly/2CQD9CU).
Mostly automatic verification. Small-
foot,2 from Calcagno, Berdine, and 
O’Hearn, was the first SL verification 
tool. Given procedure pre/post specs, 
loop invariants and invariants governing 
lock usage, Smallfoot attempts to con-
struct a proof. For the pointer-transfer-
ring buffer, given a buffer invariant and 
pre/post specs for put and get it can 
verify memory safety and race freedom.
Smallfoot used a decidable fragment 
of SL dubbed “symbolic heap,” formu-
lae of the form B ∧ H where H is a sepa-
rating conjunction of heap facts and B 
is a Boolean assertion over non-heap 
data. The format was chosen to make 
in-place symbolic execution efficient. 
Smallfoot’s heap facts were restricted 
to points-to assertions, linked lists and 
trees. Subsequent works extended sym-
bolic heaps in numerous directions, 
covering more inductive definitions as 
well as arrays and arithmetic; see appen-
dix (https://bit.ly/2CQD9CU).
Some of the most substantial auto-
matic verifications done with SL have 
been carried out with the VeriFast tool of 
Jacobs and colleagues. VeriFast employs 
a symbolic execution engine like Small-
foot, but integrates a dedicated SL theo-
rem prover with a classical SMT solver 
for non-heap data. A paper reports on 
the verification of several industrial case 
studies, including Java Card programs 
and device drivers written in C;35 see Ver-
iFast’s GitHub site for these and many 
other 
examples 
(https://github.com/
verifast/verifast).
Interactive verification. In an auto-
matic verifier like Smallfoot, the proof 
construction is automatic, given the 
pre/post annotations plus invariants. 
In interactive verification the human 
helps guide the proof search, com-
monly using a proof assistant such 
as Coq, HOL4, or Isabelle. Interactive 
verification can often prove stronger 
properties than automatic verifiers, 
but the cost is higher.
Interactive verifiers have been used 
to prove small, intricate algorithms. A 
recent paper reports on the verification 
of low-level concurrent algorithms in-
cluding a CAS-lock, a ticketed lock, a GC 
allocator, and a non-blocking stack.39 An 
emphasis is placed on reusability; for in-
stance, the stack uses the GC allocator, 
which in turn uses a lock, but the stack 
uses the spec of the allocator and the 
allocator uses the spec rather than the 
implementation of a lock.
The verifiable C logic1 has been 
used to prove crypto code. For example, 
OpenSSL’s HMAC authentication code, 
comprising 134 lines of C, was proven 
using 2,832 lines of Coq.4
A larger example is the FSCQ file sys-
tem.14 The code and the proof are both 
done in Coq, taking up 31k lines of 
proof+code. This compares to 3k lines of 
C for a related unverified file system. Al-
though the initial effort, which included 
development of a program logic frame-
work in Coq, took several person years, 
experiments show incremental, lower 
cost when modifying code+proof.
A commercial example concerns 
key modules of a preemptive OS ker-
nel, the μC/OS-II.41 Modules verified 
include the scheduler, interrupt han-
dlers, and message queues. 1.3k lines 
of C were proven using 216k lines of 
Coq. It took four person years to de-
velop the framework, one-person year 
to prove the first module, and then the 
remaining modules, around 900 lines 
of C, took six person-months.
Automatic program analysis. With a 
verification-oriented program analysis 
the annotations that a human would 
supply to a mostly automatic verifier 
like Smallfoot—invariants and pre/post 
specs—are inferred. A tool will be able 
to prove weaker properties when the hu-
man is not supplying annotations, but 
can more easily be deployed broadly to 
many programmers.
Program analysis with SL has re-
ceived a great deal of attention. At first, 
analysis was formulated for simple 
linked lists,20 and progressively re-
searchers moved on to more involved 
data structures. A practical high point 
in this line of work was the verification 
of pointer safety in Linux and Win-
dows device drivers up to 10k LOC by 
the SpaceInvader program analyzer.43 
SpaceInvader was an academic tool; 
its sibling, SLAyer,3 developed in par-
allel at Microsoft, was used internally 
to find 10s of memory safety errors in 
Windows device drivers. SpaceInvader 
and SLAyer were able to analyze com-
plex, linear data structures: for exam-
ple, oneWindows driver manipulated 
five-cyclic doubly linked lists sharing a 
common header node, three of which 
had acyclic sublists.
Like much research in verification-
oriented program analysis these tech-
niques worked in a whole-program 
fashion: you start from main() or 

94    COMMUNICATIONS OF THE ACM   |  FEBRUARY 2019  |  VOL. 62  |  NO. 2
review articles
sis not infrequently finds more general 
specifications than a top-down analysis 
that dives into procedures at call sites; 
finding general specs is important for 
both scalability and precision.
The main bi-abduction paper12 
contributed proof techniques and al-
gorithms for abduction, and a novel 
compositional algorithm for generat-
ing pre/post specs of program compo-
nents. Experimental results scaled to 
hundreds of thousands of lines, and a 
part of Linux of 3M lines. This form of 
analysis finds preconditions support-
ing safety proofs of clusters of proce-
dures as well as indicating potential 
bugs where proofs failed.
This work led to the program proof 
startup Monoidics, founded by Calc-
agno, Distefano and O’Hearn in 2009. 
Monoidics developed and marketed the 
Infer tool, based on the abductive tech-
nique. Monoidics was acquired by Face-
book in 2013 at which point Calcagno, 
Distefano, and O’Hearn moved to Face-
book with the Monoidics engineering 
team (www.fbinfer.com).
The compositional nature of In-
fer turned out to be a remarkable fit 
for Facebook’s software development 
process.11 A codebase with millions 
of lines is altered thousands of times 
per day in “code diffs” submitted by 
the programmers. Instead of doing 
a whole-program analysis for each 
diff, Infer analyzes changes (the diffs) 
compositionally, and reports regres-
sions as a bot participating in the in-
ternal code review process. Using bi-
abduction, the frame rule picks off (an 
approximation of) just enough state 
to analyze a diff, instead of consider-
ing the entire global program state. 
The way that compositional analysis 
supports incremental diff analysis is 
even more important than the ability 
to scale; a linear-time analysis operat-
ing on the whole program would usu-
ally be too slow for this deployment 
model. Indeed, Infer has evolved from 
a standalone SL-based analyzer to a 
general framework for compositional 
analyses 
(http://fbinfer.com/docs/
checkers.html and appendix; https://
bit.ly/2CQD9CU).
Conclusion
Some time during 2001, while sitting 
together in his back garden, Reynolds 
turned to me and exclaimed: “The 
other entry points and explore the pro-
gram graph, perhaps visiting proce-
dure bodies multiple times. This can 
be expensive. While accurate analysis 
of 10k LOC can be a leading research 
achievement, 10k is tiny compared to 
software found in the wild. A single 
company can have tens of millions of 
lines of code. Progress toward big code 
called for a radical departure.
Bi-Abduction and Facebook Infer
In 2008 Calcagno asked: What is the main 
obstacle blocking application of SpaceIn-
vader and similar tools to programs in the 
millions of LOC? O’Hearn answered: The 
need for the human to supply precondi-
tions. He proposed that a “truly modu-
lar” analysis based on local reasoning 
could accept a program component with 
no human annotations, and generate 
a pre/post spec where the precondition 
approximates the footprint. The analysis 
would then “stitch” these specifications 
together to obtain results for larger pro-
gram parts. The analysis would be com-
positional, in that a spec for a procedure 
could be obtained without knowing its 
callers, and the hypothesis was that it 
would scale because procedures could be 
visited independently. This implied giv-
ing up on whole-program analysis.
Calcagno, O’Hearn, Distefano and 
Yang set to work on realizing a truly 
modular analysis. Yang developed a 
scheme based on gleaning information 
from failed proofs to discover a foot-
print. Distefano made a breakthrough 
on the stitching issue for the modular 
analysis that involved a new inference 
problem:
Bi-abduction: given A and B, find 
?frame and ?anti-frame such that
where  is read ‘entails’ or ‘implies.’ 
The inference of ?frame (the leftover 
part in A but not B) was present in 
Smallfoot, and is used in many tools. 
The ?anti-frame part (the missing bit 
needed to establish B), is abduction, 
or inference of hypotheses, an infer-
ence problem identified by the philos-
opher Charles Peirce in his conceptu-
al analysis of the scientific method. As 
a simple example,
can be solved with 
With bi-abduction we can automate 
the local reasoning idea by abducing 
assertions that describe preconditions, 
and using frame inference to keep speci-
fications small. Let us illustrate with the 
program we started the paper with. We 
begin symbolic execution with nothing 
in the precondition, and we ask a bi-
abduction question, using the current 
state emp as the A part of the bi-abduc-
tion query and the pre of the small axi-
om for [x] = y as B.
Now, we move the abduced anti-frame 
to the overall precondition, we take 
one step of symbolic execution using 
the small axiom for Pointer Write from 
Figure 2, we install the post of the small 
axiom as the pre of the next instruction, 
and we continue.
The formula y  – in the bi-abduc-
tion query is the precondition of the 
small axiom for the pointer write [y] = x: 
we abduce it as the anti-frame, and add 
it to the overall precondition. The frame 
rule tells us that the inferred frame x  
y is unaltered by [y] = x, when it is sepa-
rately conjoined with y  –, and this 
with the small axiom gives us our overall 
postcondition in
So, starting from specifications for 
primitive statements, we can infer both 
a precondition and a postcondition for 
a compound statement by repeated ap-
plications of bi-abduction and the frame 
rule. This facility leads to a high degree 
of automation. Also, note that the pre-
condition here is more general than the 
one at the start of the paper, because it 
does not mention 0. Bi-abductive analy-

FEBRUARY 2019  |  VOL. 62  |  NO. 2  |  COMMUNICATIONS OF THE ACM    95
review articles
logic is nice, but it’s the model that’s 
really important.” My own prejudice 
for semantics made me agree imme-
diately. We were both beguiled by the 
fact that this funky species of logic 
could be described using down-to-
earth computer science concepts like 
RAMs and access bits.
What happened later came as a sur-
prise. The specific heap/RAM model 
gave way in importance to a more gen-
eral class of nonstandard models based 
on fictional rather than down-to-earth 
separation. And the logic itself, particu-
larly its proof theory, turned out to be ex-
tremely useful in automatic verification, 
leading to many novel research tools 
and eventually to Facebook Infer.
Still, I expect that in the long run it 
will be the spirit rather than the letter of 
SL that is more significant. Concepts of 
frames, footprints, and separation as a 
basis for modular reasoning seem to be 
of fundamental importance, indepen-
dently of the syntax used to describe 
them. Indeed, one of the more impor-
tant directions I see for further work is 
in theoretical foundations that get at 
the essence of scalable, modular rea-
soning in as formalism-independent 
a way as possible. Theoretical synthe-
sis would be extremely useful for three 
reasons: To make it easier for people 
to understand what has been achieved 
by each new idea; to provide a simpler 
jumping-off point for future work than 
the union of the many specific advanc-
es; and, to suggest new, unexplored 
avenues. Hoare has been advancing 
an abstract, algebraic theory related to 
CSL, which has components covering 
semantics, proof theory, and testing,24 
and work along these lines is well worth 
exploring further. 
 Other relevant reference points are 
works on general versions of SL,13,17 
abstract interpretation,15 and work on 
“separation without SL” discussed in 
the appendix (https://bit.ly/2CQD9CU). 
Semantic fundamentals would be cru-
cial to an adequate general foundation, 
but I stress that proof theoretic and es-
pecially algorithmic aspects addressing 
the central problem of scale should be 
covered as well.
In conclusion, scalable reasoning 
about code has come a long way since 
the birth of SL around the turn of the  
millennium, but it seems to me that 
much more is possible both in funda-
mental understanding and in mecha-
nized techniques that help program-
mers in their daily work. I hope that 
scientists and engineers will continue to 
innovate on the fascinating problems in 
this area.
Acknowledgments. This article is 
dedicated to the memory of John C. 
Reynolds (1935–2013). Our work to-
gether at the formative stage of sepa-
ration logic was incredibly intense, 
exciting, and huge fun. I am fortunate 
to have worked so closely with such 
a brilliantly insightful scientist, who 
was also a valued friend.
I thank my many other collabo-
rators in the development of this 
research, particularly David Pym, 
Hongseok Yang, Richard Bornat, Cris-
tiano Calcagno, Josh Berdine, Dino 
Distefano, Steve Brookes, Matthew 
Parkinson, Philippa Gardner, and 
Tony Hoare. Finally, thanks to my col-
leagues at Facebook for our work to-
gether and for teaching me about ap-
plying logic in the real world.	
References
1.	 Appel, A.W. Program Logics for Certified Compilers. 
Cambridge University Press, U.K., 2014.
2.	 Berdine, J. Calcagno, C. and O’Hearn, P.W. Smallfoot: 
Modular automatic assertion checking with separation 
logic. LNCS FMCO 4111 (2005) 115–137, 2005.
3.	 Berdine, J., Cook, B. and Ishtiaq, S. SLAyer: Memory 
safety for systems-level code. In Proceedings of CAV, 
2011, 178–183.
4.	 Beringer, L., Petcher, A., Ye, K.Q. and Appel, A.W. Verified 
correctness and security of OpenSSL HMAC. In 
Proceedings of 24th USENIX Security Symposium, 2015, 
207–221.
5.	 Biering, B., Birkedal, L. and Torp-Smith, N. BI-
hyperdoctrines, higher-order separation logic, and 
abstraction. ACM TOPLAS 29, 4 (2007).
6.	 Bornat, R. Proving pointer programs in Hoare logic. 
LNCS MPC 1837 (2000) 102–126.
7.	
Bornat, R., Calcagno, C., O’Hearn, P.W. and Parkinson, 
M.J. Permission accounting in separation logic. In 
Proceedings of POPL, 2005, 259–270.
8.	 Brookes, S. A semantics for concurrent separation logic. 
Theor. Comput. Sci., 375, 1–3 (2007), 227–270.
9.	 Brookes, S. and O’Hearn, P.W. Concurrent separation 
logic. SIGLOG News 3, 3 (2016), 47–65.
10.	 Burstall, R.M. Some techniques for proving correctness 
of programs which alter data structures. Machine 
Intelligence 7, 1 (1972), 23–50.
11.	 Calcagno, C. et al. Moving fast with software verification. 
In Proceedings of NASA Formal Methods Symposium, 
2015, 3–11.
12.	 Calcagno, C., Distefano, D., O’Hearn, P.W. and Yang, H. 
Compositional shape analysis by means of bi-abduction. 
J. ACM 58, 6 (2011), 26. Preliminary version in 
Proceedings of POPL’09.
13.	 Calcagno, C., O’Hearn, P.W. and Yang, H. Local action and 
abstract separation logic. LICS, 2007, 366–378.
14.	 Chen, H., Ziegler, F., Chajed, T., Chlipala, A., Kaashoek, 
M.F. and Zeldovich, N. Using Crash Hoare logic for 
certifying the FSCQ file system. In Proceedings of 
SOSP, pages 18–37, 2015.
15.	 Cousot, P. and Cousot, R. Abstract interpretation: A 
unified lattice model for static analysis of programs 
by construction or approximation of fixpoints. In 
Proceedings of POPL, 1977, 238–252.
16.	 Dijkstra, E.W. Cooperating sequential processes. 
Programming Languages, Academic Press, 1968, 
43–112.
17.	 Dinsdale-Young, T., Birkedal, L., Gardner, P., Parkinson, 
M.J. and Yang, H. Views: Compositional reasoning for 
concurrent programs. In Proceedings of POPL, 2013, 
287–300.
18.	 Dinsdale-Young, T., Dodds, M., Gardner, M., Parkinson, 
M.J. and Vafeiadis, V. Concurrent abstract predicates. In 
Proceedings of ECOOP, 2010, 504–528.
19.	 Dinsdale-Young, T., Gardner, P. and Wheelhouse, M.J. 
Abstraction and refinement for local reasoning. In 
Proceedings of VSTTE, 2010, 199–215.
20.	 Distefano, D., O’Hearn, P.W. and Yang, H. A local shape 
analysis based on separation logic. In Proceedings of 
TACAS, 2006, 287–302.
21.	 Floyd, R.W. Assigning meanings to programs. In 
Proceedings of the Symposium on Applied Mathematics. 
J.T. Schwartz, ed. AMS, 1967, 19–32.
22.	 Hoare, C.A.R. An axiomatic basis for computer 
programming. Commun. ACM 12, 10 (1969), 576–580.
23.	Hoare, C.A.R. Towards a theory of parallel 
programming. Operati  ng Systems Techniques. 
Academic Press, 1972.
24.	 Hoare, T., Möller, B., Struth, G. and Wehrman, I. 
Concurrent Kleene algebra and its foundations. J. Log. 
Algebr. Program 80, 6 (2011), 266–296.
25.	 Hobor, A. and Villard, J. The ramifications of sharing 
in data structures. In Proceedings of 40th POPL, 2013, 
523–536.
26.	 Ishtiaq, S.S. and O’Hearn, P.W. BI as an assertion 
language for mutable data structures. In Proceedings of 
POPL, 2001, 14–26.
27.	 Jones, C.B. Specification and design of (parallel) 
programs. In Proceedings of IFIP Congress, 1983, 
321–332.
28.	 Jung , R. Jourdan, J.-H., Krebbers, R. and Dreyer. 
D. RustBelt: Securing the foundations of the Rust 
programming language. In Proceedings of PACMPL, 
2018.
29.	 Krebbers, R., Jung, R., Bizjak, A., Jourdan, J-H, Dreyer, D. 
and Birkedal, L. The essence of higher-order concurrent 
separation logic. In Proceedings of ESOP, 2017, 
696–723.
30.	 O’Hearn, P.W. Resources, concurrency, and local 
reasoning. Theor. Comput. Sci. 375, 1-3 (2007), 271–307.
31.	 O’Hearn, P.W and Pym, D.J. The logic of bunched 
implications. Bulletin of Symbolic Logic 5, 2 (1999), 
215–244.
32.	 O’Hearn, P.W., Reynolds, J.C. and Yang, H. Local 
reasoning about programs that alter data structures. In 
Proceedings of CSL, 2001, 1–19.
33.	 Parkinson. M.J. Local reasoning for Java. Ph.D. thesis. 
University of Cambridge, U.K., 2005.
34.	 Parkinson, M.J., Bornat, R. and Calcagno, C. Variables 
as resource in Hoare logics. In Proceedings of 21st LIC, 
2006, 137–146.
35.	 Philippaerts, P., Mühlberg, J.T., Penninckx, W., Smans, 
J., Jacobs, B. and Piessens, F. Software verification with 
verifast: Industrial case studies. Sci. Comput. Program. 
82 (2014), 77–97.
36.	 Pym, D., O’Hearn, P. and Yang, H. Possible worlds and 
resources: The semantics of BI. Theoret. Comp. Sci. 315, 
1 (2004), 257–305.
37.	 Reynolds, J,C. Intuitionistic reasoning about shared 
mutable data structure. Millennial Perspectives in 
Computer Science, Cornerstones of Computing. Palgrave 
Macmillan, 2000.
38.	 Reynolds, J.C. Separation logic: A logic for shared 
mutable data structures. LICS, 2002, 55–74.
39.	 Sergey, I., Nanevski, A. and Banerjee, A. Mechanized 
verification of fine-grained concurrent programs. In 
Proceedings of 36th PLDI, 2015, 77–87.
40.	Turing, A.M. Checking a large routine. Report of a 
Conference on High-Speed Automatic Calculating 
Machines. Univ. Math. Lab., Cambridge, U.K., 1949, 
67–69.
41.	 Xu, F., Fu, M., Feng, X., Zhang, X., Zhang, H. and Li, Z. 
A practical verification framework for preemptive OS 
kernels. In Proceedings of CAV, 2016.
42.	 Yang, H. Local Reasoning for Stateful Programs. Ph.D. 
thesis. University of Illinois, 2001.
43.	 Yang, H., Lee, O., Berdine, J., Calcagno, C., Cook, B., 
Distefano, D. and O’Hearn, P.W. Scalable shape analysis 
for systems code. In Proceedings of CAV, 2008, 
385–398.
44.	Yang, H. and O’Hearn, P.W. A semantic basis for local 
reasoning. In Proceedings of FoSSaCS, 2002, 402–416.
Peter O’Hearn (p.ohearn@ucl.ac.uk) is a research 
scientist at Facebook and professor of computer science 
at University College London, U.K.
© 2019 ACM 0001-0782/19/2 $15.00

