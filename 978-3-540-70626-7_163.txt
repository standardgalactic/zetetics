Quantum Entropy
543
Q
10. J. S. Schwinger: On Quantum Electrodynamics and the Magnetic Moment of the Electron.
Phys. Rev. 73, 416 (1948)
11. R. P. Feynman: The Theory of Positrons. Phys. Rev. 76, 749 (1949)
12. R. P. Feynman: Space-Time Approach to Quantum Electrodynamics. Phys. Rev. 76, 769 (1949)
13. F. J. Dyson: The Radiation Theories of Tomonaga, Schwinger, and Feynman. Phys. Rev. 75,
486 (1949)
14. F. J. Dyson: The S Matrix in Quantum Electrodynamics. Phys. Rev. 75, 1736 (1949)
15. B. Odom, D. Hanneke, B. D’Urso, and G. Gabrielse: New Measurement of the Electron Mag-
netic Moment Using a One-Electron Quantum Cyclotron. Phys. Rev. Lett. 97, 030801 (2006)
16. G. Gabrielse, D. Hanneke, T. Kinoshita, M. Nio and B. Odom: New Determination of the Fine
Structure Constant from the Electron g Value and QED. Phys. Rev. Lett. 97, 030802 (2006)
Secondary Literature
17. S. S. Schweber: QED and the Men Who Made It, Dyson, Feynman, Schwinger, and Tomonaga
(Princeton University Press, New Jersey 1994)
18. J. Mehra and K. A. Milton: Climbing the Mountain, The Scientiﬁc Biography of Julian
Schwinger (Oxford University Press, Oxford 2000)
19. J. Mehra: The Beat of a Different Drum, The Life and Science of Richard Feynman (Oxford
University Press, Oxford 1994)
Quantum Entropy
Dominik Janzing
The von Neumann entropy of a quantum system with density operator ρ is given
by [2]
S(ρ) := −tr(ρ log ρ).
(1)
Let
ρ =

j∈I
pj|ψj⟩⟨ψj |
(2)
be a decomposition of ρ into mutually orthogonal pure states where I is a countable,
but possibly inﬁnite, index set. Then we obtain
S(ρ) = H(p),
(3)
where
H(p) := −

j∈I
pj log pj

544
Quantum Entropy
is the Shannon entropy [5] of the probability distribution given by (pj)j∈I. This is
exactly the uncertainty of the measurement results when an observable is measured
that has |ψj⟩⟨ψj | as its spectral projections [6]. For an arbitrary non-degenerate
observable with spectral projections |φj⟩⟨φj| the probabilities of the measurement
outcomes are given by
qj := ⟨φj|ρ|φj⟩,
and satisfy H(q) ⩾H(p). Von Neumann entropy is conserved under unitary trans-
formations U since they preserve the eigenvalues. This is in particular true for the
dynamical evolution Ut of a closed physical system [7] induced by its Hamilto-
nian H:
ρt := UtρU†
t = e−iHtρ eiHt .
However, in many-particle systems with non-trivial interactions, such a formal con-
servation of entropy is only of limited practical relevance. This is because there
may be no feasible non-degenerate measurement for which the uncertainty of
measurement results attains S(ρt) even though such a measurement may have ex-
isted for the initial state ρ. In a many-particle system, observables with spectral
projections Ut|ψj⟩⟨ψj |U†
t could correspond to an arbitrarily complex measurement
procedure. This can happen, for instance, if the dynamics Ut creates sophisticated
quantum correlations between the particles ( correlations in quantum mechanics).
For every feasible measurement the system then would behave like a system with
higher entropy and we observe entropy increase on the phenomenological level.
Apart from such a “practical view”, it has been argued that complexity aspects
are also relevant from the fundamental point of view: Zurek [3] deﬁnes the physical
entropy of a classical system as the sum of the Shannon entropy (formalizing the
missing knowledge about the state) and the algorithmic information content (algo-
rithmic randomness, i.e. the Kolmogorov complexity) present in the available data
about the system. Mora et al. [4] describes a quantum generalization of Kolmogorov
complexity and discusses also its thermodynamical relevance.
The interpretation of von Neumann entropy deserves further attention. Equations
(2) and (3) may, at ﬁrst glance, suggest the interpretation that one of the pure states
|ψj⟩is present and S(ρ) quantiﬁes the missing knowledge about which one is the
true one. However, this ignores ﬁrst that the decomposition of ρ into pure states is in
general not unique and, second, that ρ can also be the state of a subsystem of a pure
entangled state ( entropy of entanglement). The scenario below shows that S(ρ)
has nevertheless an information theoretic meaning in the sense that it quantiﬁes the
resources required to transmit a quantum state in the same way as Shannon entropy
quantiﬁes the resources required to transmit a classical message.
To sketch this analogy, we assume a sender uses k different symbols 1, . . . , k to
transmit a classical message. If the symbol j is chosen with probability pj and the
total message consists of n symbols we expect that the number nj of occurrences of
j satisfy for large n
nj
n ≈pj
i.e.

j
nj
n lognj
n ≈

j
pj logpj.
(4)

Quantum Entropy
545
Q
Using a precise version of (4), right, coding theory (see [5] for details) deﬁnes the
set of typical sequences and shows that the numbers N(n) of such sequences satisfy
1
n log N(n) →H(p) .
(5)
The deﬁnition of typical sequences is chosen such that the probability for obtaining
an untypical one tends to zero for n →∞. In this limit, the same message can thus
be encoded into H(p) bits per symbol (provided that all logarithms are deﬁned
with respect to the basis 2). One can also show that H(p) bits per copy are really
necessary.
Now we consider a scenario where the sender transmits the quantum state |ψj⟩
with probability pj. A message of length n is then given by a quantum state
|ψ⟩:= |ψj1⟩⊗|ψj2⟩⊗· · · ⊗|ψjn⟩.
If all states |ψj⟩are mutually orthogonal, the above arguments suggest that we can
restrict the attention to typical states |ψ⟩, i.e. those whose numbers nj of occur-
rences of the states |ψj⟩satisfy condition (4), right. They span a  Hilbert space of
dimension N(n) satisfying again the asymptotical condition (5).
However, the more interesting case is when the sender uses non-orthogonal sig-
nal states. From the point of view of an observer who does not know which one of
the states |ψj⟩has been chosen, the sender emits the density operator
ρ =
k

j=1
pj|ψj⟩⟨ψj|.
The density operator for n signal states is then given by
ρ⊗n.
Let ρ = k
i=1 qi|φi⟩⟨φi| be a decomposition of ρ into mutually orthogonal states.
Even though the pure states |φj⟩do not have any direct intuitive meaning since this
set can be completely disjoint from the set of signal states, it turns out that they
are useful for an mathematical analysis of the resource requirements: The density
operator ρ⊗n can be written as a mixture of states of the form
|φ⟩= |φi1⟩⊗|φi2⟩⊗· · · ⊗|φin⟩.
In analogy to the arguments above, we consider only those states φ for which the
sequence of indices is typical. They span a subspace whose dimensions N(n) satisfy
the asymptotical condition (5) with H(q) instead of H(p).
This shows that the number of quantum bits required per copy is asymptoti-
cally given by H(q) = S(ρ) and not by H(p). In other words, the entropy of the
probability measure determining the choice of the signal states is not relevant. In-
stead, the quantum entropy of the corresponding mixture determines the required
resources [1] even though the eigenstates of the mixture do not have any direct
physical interpretation.

546
Quantum Eraser
Literature
1. B. Schumacher: Quantum coding. Phys. Rev. A 51(4), 2738–2747 (1995)
2. M. Nielsen and I. Chuang: Quantum Information and Computation. (Cambridge University
Press, Cambridge 2000)
3. W. Zurek: Algorithmic randomness and physical entropy. Phys. Rev. A 40, 4731–4751 (1989)
4. C. Mora, H. Briegel, and B. Kraus: Quantum Kolmogorov complexity and its applications.
arXiv.org:quant-ph/0610109.
5. T. Cover and J. Thomas: Elements of Information Theory. (Wiley, New York 1991)
6. R. Omnes: The Interpretation of Quantum Mechanics. (Princeton University Press, Princeton
1994)
7. J. Jauch: Foundations of Quantum Mechanics. (Addison Wesley, New York 1968)
Quantum Eraser
Basil James Hiley
To understand the notion of a quantum eraser we need ﬁrst to consider the inter-
ference produced when light falls on a pair of slits. As long as we think of light
as being a wave phenomenon, there is no problem in understanding how the phase
difference between the wave arriving at a point on the screen from one slit and the
wave arriving from the second slit gives rise to the interference effects.
The problem arises when we learn that the wave consists of photons ( light
quantum), a problem that becomes more acute when the incident beam consists only
of a few photons arriving per second. If the photon is a localised packet of energy
then the question as to which slit the photon passed through becomes inevitable.
This question becomes even more pertinent when one realises that particles like
 electrons, neutrons and even atoms produce exactly the same interference patterns
using pairs of slits of the appropriate size.
The obvious way to explore this situation further is to see if we can set up some
form of experiment to ﬁnd through which slit each particle actually passes. In this
way we might be able to understand how the interference pattern arises. Unfortu-
nately what we ﬁnd is that for all experiments that give a deﬁnite answer for each
particle, the interference pattern disappears. This means that once we know which
way the particle goes, we lose the interference pattern. Alternatively if we have no
means of knowing which way the particles go, then we get a sharp interference
pattern. This phenomenon is known as  ‘wave-particle’ duality.
One of the earlier ways of explaining the loss of interference was to argue that
any attempt to determine which way the particle went would induce a series of
random phase changes in the beam. These phase changes arise because in order to
‘see’ where the particle is, some form of scattering would have to be used. It is this
scattering that produces the random phase changes which would clearly destroy the
interference pattern [1].

