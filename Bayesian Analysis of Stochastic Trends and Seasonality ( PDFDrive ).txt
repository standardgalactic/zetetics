BAYESIAN ANALYSIS OF STOCHASTIC
TRENDS AND SEASONALITY
Freie wissenschaftliche Arbeit
zur Erlangung des akademischen Grades
"Dr. rer. pol."
vorgelegt bei
Professor Dr. Susanne R√§ssler
Lehrstuhl f√ºr Statistik und √ñkonometrie
Wirtschafts- und Sozialwissenschaftliche Fakult√§t
Otto-Friedrich-Universit√§t Bamberg
von
Diplom Sozialwirt Alexander Vosseler
12. September 2013

Promotionsvermerk:
Erstgutachterin: Prof. Dr. Susanne R√§ssler
Zweitgutachter: Prof. Dr. Ingo Klein
Datum der Disputation: 18.02.2014

Contents
List of tables
IV
List of Ô¨Ågures
VI
List of notations
VIII
1. Introduction
1.1. Summary and structure of the thesis . . . . . . . . . . . . . . . . . . . .
1
1.2. Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
Part A: Analysis of nonseasonal time series
2. Bayesian model selection for unit root testing with multiple breaks
2.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
2.2. Bayesian unit root testing with multiple breaks
. . . . . . . . . . . . . .
11
2.2.1.
Model and deÔ¨Ånitions
. . . . . . . . . . . . . . . . . . . . . . .
11
2.2.2.
Likelihood and prior speciÔ¨Åcations . . . . . . . . . . . . . . . . .
14
2.3. Stochastic model selection via MCMC . . . . . . . . . . . . . . . . . . .
15
2.4. Monte Carlo evidence: MCMC based model selection . . . . . . . . . . .
20
2.5. Testing the unit root null hypothesis
. . . . . . . . . . . . . . . . . . . .
25
2.6. Power comparison of unit root testing procedures . . . . . . . . . . . . .
29
2.7. Empirical application using OECD data . . . . . . . . . . . . . . . . . .
31
2.8. Summary and conclusion . . . . . . . . . . . . . . . . . . . . . . . . . .
36
I

Part B: Analysis of seasonal time series
3. Some concepts related to seasonal time series
3.1. Stochastic seasonality and seasonal integration
. . . . . . . . . . . . . .
39
3.2. Periodic processes and periodic integration
. . . . . . . . . . . . . . . .
43
3.3. Two classical testing approaches for a periodic unit root . . . . . . . . . .
49
4. Bayesian analysis of periodic unit roots with a break
4.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
4.2. Model and deÔ¨Ånitions . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
4.3. Bayesian testing for a periodic unit root
. . . . . . . . . . . . . . . . . .
57
4.4. Monte Carlo evidence: periodic unit root tests . . . . . . . . . . . . . . .
64
4.5. Empirical application to monthly unemployment data . . . . . . . . . . .
71
4.6. Summary and concluding remarks . . . . . . . . . . . . . . . . . . . . .
74
5. Forecasting seasonal time series.
A Bayesian model averaging ap-
proach
5.1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
5.2. Periodic autoregressive models with one break . . . . . . . . . . . . . . .
79
5.2.1.
SpeciÔ¨Åcation of prior distributions . . . . . . . . . . . . . . . . .
80
5.2.2.
Model augmentation for prediction
. . . . . . . . . . . . . . . .
82
5.3. Markov chain Monte Carlo approach . . . . . . . . . . . . . . . . . . . .
85
5.4. Monte Carlo analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
5.4.1.
A Bayesian sign test for comparing predictive accuracy . . . . . .
90
5.4.2.
Simulation evidence
. . . . . . . . . . . . . . . . . . . . . . . .
94
5.5. Forecasting German monthly unemployment data . . . . . . . . . . . . . 100
5.6. Concluding remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
6. Final summary and discussion
107
Appendices
124
A.
Tables - chapter 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
B.
Tables - chapter 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
C.
Tables - chapter 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
D.
Figures - chapter 2
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
II

E.
Figures - chapter 4
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
F.
Figures - chapter 5
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164
G.
Technical details - chapter 4
. . . . . . . . . . . . . . . . . . . . . . . . 182
G.1.
Preliminaries - posterior analysis . . . . . . . . . . . . . . . . . . 182
G.2.
Derivation of the posterior density of B1 . . . . . . . . . . . . . . 192
G.3.
Derivation of the posterior density of œÜs . . . . . . . . . . . . . . 197
G.4.
Derivation of the marginal posterior of Œ∏
. . . . . . . . . . . . . 197
G.5.
Derivation of the marginal posterior of Q
. . . . . . . . . . . . . 198
G.6.
Some comments on the prior distribution
. . . . . . . . . . . . . 201
H.
Technical details - chapter 5
. . . . . . . . . . . . . . . . . . . . . . . . 203
H.1.
Derivation of the posterior predictive distribution of eyK . . . . . . 203
III

List of Tables
2.1.
Posterior probability of a unit root as a function of T and Œ∏ . . . . . . . . . . .
31
4.1.
Posterior model probabilities
. . . . . . . . . . . . . . . . . . . . . . . . .
69
5.1.
Test results - Design 1 / DGP: PAR(1) . . . . . . . . . . . . . . . . . . . . .
97
5.2.
Test results - Design 2 / DGP: PIAR(1)
. . . . . . . . . . . . . . . . . . . .
98
5.3.
Test results - Design 3 / DGP: SAR(1) . . . . . . . . . . . . . . . . . . . . .
99
5.4.
Test results - Design 4 / DGP: SARMA(1,0) √ó(1,1) . . . . . . . . . . . . . . 100
A.1. Posterior probabilities of the number of structural breaks . . . . . . . . . . . . 125
A.2. Posterior probabilities of the autoregressive lag order . . . . . . . . . . . . . . 126
A.3. Bayesian break date estimates . . . . . . . . . . . . . . . . . . . . . . . . . 127
A.4. Classical Bai and Perron (2003) break date estimates . . . . . . . . . . . . . . 128
A.5. Posterior point estimates bŒ∏ and half lives under different priors . . . . . . . . . 129
A.6. Posterior probabilities of a unit root and tail probabilities . . . . . . . . . . . . 130
B.1. Testing for no periodicity . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
B.2. Posterior probabilities of the number of breaks and the break dates . . . . . . . 132
B.3. Bayesian and classical test results for a periodic unit root . . . . . . . . . . . . 133
B.4. Results of (non)seasonal unit root tests . . . . . . . . . . . . . . . . . . . . . 134
B.5. 95% HPD intervals of the œÜs coefÔ¨Åcients . . . . . . . . . . . . . . . . . . . . 135
B.6. 95% HPD intervals of the œÜs coefÔ¨Åcients (Cont.) . . . . . . . . . . . . . . . . 136
C.1. Testing for no periodicity . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
C.2. Evaluation of 12-months ahead forecasts . . . . . . . . . . . . . . . . . . . . 138
C.3. Evaluation of 12-months ahead forecasts (Cont.) . . . . . . . . . . . . . . . . 139
C.4. Bayesian one-year ahead forecasts (1) . . . . . . . . . . . . . . . . . . . . . 140
C.5. Bayesian one-year ahead forecasts (2) . . . . . . . . . . . . . . . . . . . . . 141
C.6. Bayesian one-year ahead forecasts (3) . . . . . . . . . . . . . . . . . . . . . 142
C.7. Bayesian one-year ahead forecasts (4) . . . . . . . . . . . . . . . . . . . . . 143
IV

C.8. Bayesian one-year ahead forecasts (5) . . . . . . . . . . . . . . . . . . . . . 144
C.9. Bayesian one-year ahead forecasts (6) . . . . . . . . . . . . . . . . . . . . . 145
C.10.Bayesian one-year ahead forecasts (7) . . . . . . . . . . . . . . . . . . . . . 146
C.11.Bayesian one-year ahead forecasts (8) . . . . . . . . . . . . . . . . . . . . . 147
C.12.Bayesian one-year ahead forecasts (9) . . . . . . . . . . . . . . . . . . . . . 148
V

List of Figures
2.1.
No-break design 1: trajectory of an AR(2) process together with the posteriors of the lag
order and of the sum of AR coefÔ¨Åcients Œ∏. . . . . . . . . . . . . . . . . . . . . .
21
2.2.
No-break design 2: trajectory of an AR(6) process with drift and trend together with the
posteriors of the lag order and of the sum of AR coefÔ¨Åcients Œ∏.
. . . . . . . . . . .
22
2.3.
No-break design 3: trajectory of an AR(12) process together with the posterior distribu-
tions of the lag order and the number of breaks.
. . . . . . . . . . . . . . . . . .
22
2.4.
Break design 1: trajectory of a stationary AR(1) with four breaks in level and trend
(dashed lines for true break dates) together with the posterior distributions of the lag
order, the number of breaks and the break dates ki given the MAP estimate of m. . . . .
23
2.5.
Break design 2: trajectory of a Random Walk with two drift breaks (dashed lines for
true break dates) together with the posterior distributions of the lag order, the number of
breaks and the break dates ki given the MAP estimate of m. . . . . . . . . . . . . .
24
2.6.
Break design 3: trajectory of a stationary ARMA(2,1) with one level break (dashed line
for true break date) together with the posterior distributions of the lag order, the number
of breaks and the break dates ki given the MAP estimate of m. . . . . . . . . . . . .
25
2.7.
Prior distributions for the long run coefÔ¨Åcient Œ∏ for T = 200.
. . . . . . . . . . . .
27
2.8.
Risk functions for Œ¥ under different prior distributions. . . . . . . . . . . . . . . .
29
2.9.
Power functions of classical and Bayesian unit root tests without structural breaks. . . .
30
3.1.
Complex unit circle with seasonal unit roots for S = 4. . . . . . . . . . . . . . . .
40
3.2.
Theoretical spectral densities of quarterly (non)stationary (S)AR(1) processes. . . . . .
42
4.1.
Power functions of the Bayesian t-test and the BF-test for quarterly periodic data (T = 150) 65
4.2.
AR(1) trajectory together with S(P)ACF and estimated power spectrum for T = 100 . .
67
4.3.
Comparison of power functions for quarterly nonperiodic data (T = 100) . . . . . . .
67
4.4.
Power functions of the BMA F- and t-test for PAR(1) processes with(out) a break (T = 100). 69
4.5.
Power functions of the F-test for PAR(1) processes with(out) a break. . . . . . . . . .
70
5.1.
(Cumulated) PMSEs for 2-years ahead forecasts (Design 1 and 2). . . . . . . . . . .
96
VI

5.2.
(Cumulated) PMSEs for 2-years ahead forecasts (Design 3 and 4). . . . . . . . . . .
99
D.1. Series Australia: posterior densities for the break dates and the long run coefÔ¨Åcient.
. . 149
D.2. Series Belgium: posterior densities for the break dates and the long run coefÔ¨Åcient. . . . 150
D.3. Series Canada: posterior densities for the break dates and the long run coefÔ¨Åcient. . . . 150
D.4. Series Denmark: posterior densities for the break dates and the long run coefÔ¨Åcient.
. . 151
D.5. Series Finland: posterior densities for the break dates and the long run coefÔ¨Åcient. . . . 151
D.6. Series France: posterior densities for the break dates and the long run coefÔ¨Åcient.
. . . 152
D.7. Series Germany: posterior densities for the break dates and the long run coefÔ¨Åcient.
. . 152
D.8. Series Greece: posterior densities for the break dates and the long run coefÔ¨Åcient.
. . . 153
D.9. Series Ireland: posterior densities for the break dates and the long run coefÔ¨Åcient.
. . . 153
D.10.Series Italy: posterior densities for the break dates and the long run coefÔ¨Åcient.
. . . . 154
D.11.Series Japan: posterior densities for the break dates and the long run coefÔ¨Åcient. . . . . 154
D.12.Series Netherlands: posterior densities for the break dates and the long run coefÔ¨Åcient. . 155
D.13.Series Norway: posterior densities for the break dates and the long run coefÔ¨Åcient. . . . 155
D.14.Series Spain: posterior densities for the break dates and the long run coefÔ¨Åcient. . . . . 156
D.15.Series Sweden: posterior densities for the break dates and the long run coefÔ¨Åcient. . . . 156
D.16.Series UK: posterior densities for the break dates and the long run coefÔ¨Åcient. . . . . . 157
D.17.Series US: posterior densities for the break dates and the long run coefÔ¨Åcient. . . . . . 157
D.18.Helicopter tour Germany: joint posterior mass function of break number and lags. . . . 158
D.19.Helicopter tour Germany (2): joint posterior mass function of break number and lags.
. 158
E.20. Bayesian p-values of recursive F-tests of non-periodicity: Australia and Belgium.
. . . 159
E.21. Bayesian p-values of recursive F-tests of non-periodicity: Canada and Denmark. . . . . 159
E.22. Bayesian p-values of recursive F-tests of non-periodicity: Finland and France. . . . . . 160
E.23. Bayesian p-values of recursive F-tests of non-periodicity: Germany and Greece. . . . . 160
E.24. Bayesian p-values of recursive F-tests of non-periodicity: Ireland and Italy. . . . . . . 161
E.25. Bayesian p-values of recursive F-tests of non-periodicity: Japan and Netherlands.
. . . 161
E.26. Bayesian p-values of recursive F-tests of non-periodicity: Norway and Spain. . . . . . 162
E.27. Bayesian p-values of recursive F-tests of non-periodicity: Sweden and Great Britain. . . 162
E.28. Bayesian p-values of recursive F-tests of non-periodicity: USA. . . . . . . . . . . . 163
F.29. Used prior distributions for the Bayesian sign test. . . . . . . . . . . . . . . . . . 164
F.30. Posterior probability of H1 as a function of x for T = 8. . . . . . . . . . . . . . . . 164
F.31. Posterior probability of H1 as a function of x for T = 60. . . . . . . . . . . . . . . 165
VII

F.32. Series East-Germany (01/1991-02/2013) with S(P)ACF and periodogram. . . . . . . . 166
F.33. Series West-Germany (01/1991-02/2013) with S(P)ACF and periodogram.
. . . . . . 166
F.34. Series Baden-Wuerttemberg (01/1991-02/2013) with S(P)ACF and periodogram.
. . . 167
F.35. Series Bavaria (01/1991-02/2013) with S(P)ACF and periodogram. . . . . . . . . . . 167
F.36. Series Berlin (01/1991-02/2013) with S(P)ACF and periodogram.
. . . . . . . . . . 168
F.37. Series Brandenburg (01/1991-02/2013) with S(P)ACF and periodogram.
. . . . . . . 168
F.38. Series Bremen (01/1991-02/2013) with S(P)ACF and periodogram. . . . . . . . . . . 169
F.39. Series Hamburg (01/1991-02/2013) with S(P)ACF and periodogram. . . . . . . . . . 169
F.40. Series Hesse (01/1991-02/2013) with S(P)ACF and periodogram.
. . . . . . . . . . 170
F.41. Series Lower Saxony (01/1991-02/2013) with S(P)ACF and periodogram. . . . . . . . 170
F.42. Series Mecklenburg-Western Pom. (01/1991-02/2013) with S(P)ACF and periodogram. . 171
F.43. Series North Rhine-Westphalia (01/1991-02/2013) with S(P)ACF and periodogram. . . 171
F.44. Series Rhineland-Palatinate (01/1991-02/2013) with S(P)ACF and periodogram. . . . . 172
F.45. Series Saarland (01/1991-02/2013) with S(P)ACF and periodogram. . . . . . . . . . 172
F.46. Series Saxony (01/1991-02/2013) with S(P)ACF and periodogram. . . . . . . . . . . 173
F.47. Series Saxony-Anhalt (01/1991-02/2013) with S(P)ACF and periodogram.
. . . . . . 173
F.48. Series Schleswig-Holstein (01/1991-02/2013) with S(P)ACF and periodogram.
. . . . 174
F.49. Series Thuringia (01/1991-02/2013) with S(P)ACF and periodogram. . . . . . . . . . 174
F.50. Seasonal boxplots: West- and East-Germany.
. . . . . . . . . . . . . . . . . . . 175
F.51. Seasonal boxplots: Baden-Wuerttemberg and Bavaria.
. . . . . . . . . . . . . . . 175
F.52. Seasonal boxplots: Berlin and Brandenburg. . . . . . . . . . . . . . . . . . . . . 176
F.53. Seasonal boxplots: Bremen and Hamburg. . . . . . . . . . . . . . . . . . . . . . 176
F.54. Seasonal boxplots: Hesse and Lower Saxony.
. . . . . . . . . . . . . . . . . . . 177
F.55. Seasonal boxplots: Mecklenburg-Western Pomerania and North Rhine-Westphalia. . . . 177
F.56. Seasonal boxplots: Rhineland-Palatinate and Saarland. . . . . . . . . . . . . . . . 178
F.57. Seasonal boxplots: Saxony and Saxony-Anhalt.
. . . . . . . . . . . . . . . . . . 178
F.58. Seasonal boxplots: Schleswig-Holstein and Thuringia. . . . . . . . . . . . . . . . 179
F.59. One-year ahead forecasts of the unemployment rates of West-Germany.
. . . . . . . 180
F.60. Model averaged posterior predictive densities of West-Germany (1). . . . . . . . . . 180
F.61. Model averaged posterior predictive densities of West-Germany (2). . . . . . . . . . 181
F.62. Model averaged posterior predictive densities of West-Germany (3). . . . . . . . . . 181
VIII

List of notations
I. General symbols
=
equals
‚àù
proportional to
‚â°
equals by deÔ¨Ånition
‚áí
implies
‚áî
is equivalent to
‚âà
approximately equal to
‚àº
is distributed as
‚àà
element of
‚àÄ
for all
‚àÉ
exists
‚äÇ
subset of
S
union
T
intersection
‚àß
conjunction (‚Äôand‚Äô)
‚à®
disjunction (‚Äôor‚Äô)
mod
modulo operator
‚åäx‚åã
Ô¨Çoor(x) - function
‚àë
summation sign
‚àè
product sign
7‚Üí
maps to
‚Üí
converges to, approaches
d‚Üí
weakly converges, converges in distribution
‚àÜs
s-th differencing operator
lim
limes
min
minimum
max
maximum
sin
sine function
cos
cosine function
exp
exponential function
ln
natural logarithm
log
logarithm to base 10
IX

sign
sign function
Œì
gamma function
det
determinant
X‚àí1
inverse matrix
X‚Ä≤
transposed matrix
Œπ
unit vector
Id
identity matrix of dimension d
dim(X)
dimension of matrix X
x
arithmetic mean of x
Med(x)
median of x
bŒ∏
estimator of Œ∏
1(.)
indicator function
Ds,t
seasonal dummy variable
L
lag operator
E
expectation
Var
variance
Cov
covariance
se
standard error
f (X)
marginal probability density or mass function of X
f (X|Y)
conditional probability density or mass function of X given Y = y
f (X,Y)
joint probability density or mass function of X and Y
F(X)
cumulative probability density or mass function of X
|J|
Jacobian determinant
I(Œ∏)
Fisher information with respect to Œ∏
C
normalizing constant
|z|
absolute value or modulus of a complex number
R
real numbers
Rm
m-dimensional Euclidean space
C
complex numbers
N
positive integers
Z
integers
D
decision (or action) space
M
model space
X

II. Probability distributions and stochastic processes
Be(Œ±,Œ≤)
Beta distribution
B(n, p)
Binomial distribution
œá2
(k)
Chi-squared distribution
G(Œ±,Œ≤)
Gamma distribution
G2(ŒΩ,s)
Gamma-2 distribution
IG2(ŒΩ,s)
Inverse Gamma-2 distribution
L(¬µ,b)
Laplace (or ‚ÄôDouble exponential‚Äô) distribution
Mk(n; p1,..., pk)
Multinomial distribution
F(ŒΩ1,ŒΩ2)
Fisher‚Äôs F-distribution
N(¬µ,œÉ2)
Univariate Normal distribution
Nd(¬µ,œÉ2)
Multivariate Normal distribution
Td(Œ∏, Œ£,ŒΩ)
Multivariate Student-t distribution
U(a,b)
Continuous uniform distribution
{yt}‚àû
t=‚àí‚àû
Stochastic process
AR(p)
Autoregressive process of order p
MA(q)
Moving average process of order q
ARMA(p,q)
Autoregressive moving average process of order (p,q)
SARMA(P,Q) √ó(p,q)
Seasonal ARMA process of order (P,Q) and (p,q)
SETAR(p)
Self-exiting threshold autoregressive model of order p
PAR(p)
Periodic autoregressive process of order p
PMA(q)
Periodic moving average process of order q
PARMA(p,q)
Periodic autoregressive moving average process of order (p,q)
I(d)
Integrated of order d (process)
SI(1)
Seasonally integrated of order one (process)
PI(1)
Periodically integrated of order one (process)
ARI(1)
Integrated AR(1) process
PARI
PAR process for an integrated series
PIAR
Periodically integrated AR process
VAR(P)
Vector autoregressive process of order P
W(r)
(Standard) Wiener process
WN(0,œÉ2)
White noise process
XI

III. Abbreviations
ADF
Augmented Dickey-Fuller
AIC
Akaike‚Äôs information criterion
BF
Bayes factor or Boswijk-Franses
BIC
Bayesian information criterion
BL
Broemeling-Land
BMA
Bayesian model averaging
BPAR
Bayesian periodic autoregressive
DGP
Data generating process
HEGY
Hylleberg-Engle-Granger-Yoo
HPD
Highest posterior density
IAB
Institute for Employment Research
iid
Independently identically distributed
IN
Independently normally distributed
LR
Likelihood ratio
MAP
Maximum a posteriori
MAPE
Mean absolute percentage error
MAD
Mean absolute deviation
MC
Monte Carlo
MCMC
Markov chain Monte Carlo
MH
Metropolis-Hastings
ML
Maximum Likelihood
NAIRU
Non-accelerating inÔ¨Çation rate of unemployment
(N)SC
(No) structural change
OECD
Organisation for economic cooperation and development
OLS
Ordinary least squares
pdf
Probability density function
PEL
Posterior expected loss
PMEANS
Periodic means
(P)MSE
(Predictive) mean squared error
pmf
Probability mass function
RSS
Residual sum of squares
S(P)ACF
Sample (partial) autocorrelation function
WSR
Wilcoxon Signed Rank
XII

Introduction
1.1. Summary and structure of the thesis
This doctoral thesis consists of two main parts, which are devoted to the analysis of non-
seasonal and seasonal time series data, respectively. These two parts are then further sub-
divided according to three research articles, where in the Ô¨Årst of these articles, presented
in chapter 2, a fully Bayesian approach to model selection in testing regressions for a non-
seasonal unit root with multiple structural breaks is proposed. In the second part of the
thesis the focus is on testing and forecasting of seasonal time series data. Since the reader
might not be so familiar with some of the unit root concepts used in the second research
article presented in chapter 4, the most important concepts related to nonstationarity in
seasonal time series models are introduced as a preliminary in chapter 3. In the second
paper, Bayesian testing approaches for different kinds of unit roots within the class of
periodic autoregressive (PAR) models with a possible mean break are proposed. Further,
since all these approaches assume seasonality of quite general form also two Bayesian
pretests for periodic variation in the mean of a process are considered, respectively. The
third article, presented in chapter 5, is devoted to the prediction of quarterly and monthly
time series. Here a model averaging approach for Bayesian PAR models of unknown
order, number of breaks and break dates is proposed in order to improve forecasting accu-
racy. Moreover the joint posterior predictive distribution for multistep ahead forecasts is
analyzed and a sampling approach to obtain the marginal predictive distributions is pre-
sented. In order to compare the predictive ability of the presented forecasting model with
those of other models, a Bayesian sign test is introduced.
In each of the three presented articles an extensive Monte Carlo study is conducted to
analyze the statistical methods for different data generating processes. Further in the em-
pirical sections of the Ô¨Årst two papers (see chapters 2 and 4) the proposed unit root testing
1

procedures are used to answer the question if there is empirical evidence for unemploy-
ment persistence or hysteresis in 17 OECD countries after a labor market shock. In the
empirical application of chapter 5 the suggested prediction approach is applied to forecast
the unadjusted monthly unemployment rates of the 16 German federal states and of East-
and West-Germany. Finally, in chapter 6 the major contributions and results of this thesis
are summarized and a short discussion with potential future research is given.
Before proceeding a brief motivation with regard to the focus of this thesis, namely testing
the unit root hypothesis and in particular the chosen Bayesian frame of reference, will be
given. The aim here is not to provide a general discussion of Bayesian and classical (or
frequentist) statistics per se, but to motivate the use of Bayesian methods for the analysis
and prediction of time series data. A review of the various arguments for and against
the use of the Bayesian paradigm in statistical inference can be found in many excellent
textbooks as for example Berger (1980) or Robert (2007), and the references therein.
1.2. Motivation
In the economic and econometric literature the unit root hypothesis has gained much inter-
est since the seminal paper of Nelson and Plosser (1982). Among the economic theories
for which (non)stationarity of the considered dynamic system has important implications
are the permanent income theory (cf. Hall (1978)), the business cycle theory (cf. King
et al. (1988)) or the insider-outsider theory and the theory of unemployment hysteresis
in labor market research (cf. Blanchard and Summers (1986), Blanchard and Summers
(1987)). The latter provides the theoretical background for the empirical analyses pre-
sented in chapters 2 and 4.
In the nineties there was a heated controversy in the literature on classical and Bayesian
unit root testing and in particular on the appropriate prior distribution, starting with Sims
(1988). The main contributions to this debate are summarized in a special issue of the
Journal of Applied Econometrics (1991, volume 6, number 4). A summary of the many
arguments put forward by the involved authors can be found in Maddala and Kim (1998),
chapter 8, Bauwens et al. (1999), chapter 6, also Uhlig (1994). One of the most striking
points of the Bayesian advocates is, that, in contrast to classical theory, Bayesian inference
2

in dynamic models is largely unaffected by the presence of a unit root, see Sims (1988),
Sims and Uhlig (1991). As a simple comparison of classical and Bayesian unit root
inference consider the following AR(1) model:1
yt = œÜyt‚àí1 + Œµt , y0 = 0, Œµt
i.i.d.
‚àºN(0,œÉ2)
(1.1)
with ordinary least squares estimator bœÜ = ‚àëT
t=1 ytyt‚àí1/‚àëT
t=1 y2
t‚àí1.
It can be shown that the asymptotic distribution of bœÜ has a discontinuity at œÜ = 1 and thus
is not the usual Gaussian distribution as in the stationary case (see Hamilton (1994), p.475
ff., for details). Kadane et al. (1996) summarize the asymptotic behavior of bœÜ, conditional
on the considered subset of the parameter space of œÜ, as
(bœÜ ‚àíœÜ)/
s
T
‚àë
t=1
y2
t‚àí1
d‚Üí
Ô£±
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£≤
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£≥
N(0,1)
, for œÜ < 1
0.5W(1)2‚àí1
(
R 1
0 W(r)2dr)1/2
, for œÜ = 1
T1(0,1, ŒΩ = 1)
, for œÜ > 1
(1.2)
where d‚Üídenotes convergence in distribution as T tends to inÔ¨Ånity, T1(.) is the univariate
standard Student-t density with ŒΩ = 1 degree of freedom, i.e. a Cauchy distribution, and
W(r) denotes a standard Wiener process with r ‚àà[0,1], cf. Banerjee et al. (1993).
From (1.2) it can be seen that the asymptotic sampling distribution f (bœÜ|œÜ) is symmetric
around zero in the stationary and the explosive case, but is asymmetric, more precisely
skewed to the left, in the presence of a unit root. Moreover, adding a constant or a trend
to the model complicates the resulting asymptotic distribution in a non-trivial way, see
Hamilton (1994) for details. Since conditional on initial values an AR model can be
treated as an ordinary linear regression model all the analytical results of the conjugate
normal regression case can be utilized in a Bayesian framework. For example, assuming a
Normal-Inverse-Gamma-2 prior on the unknown quantities œÜ and œÉ2 in (1.1) the marginal
posterior distribution f (œÜ|yT,...,y1,y0) equals a univariate Student-t density or a univari-
ate normal density when œÉ2 = 1, i.e. known, see Raiffa and Schlaifer (2000), chapter 13,
also Zellner (1971), chapter 7.2 It is important to note that the latter is true irrespective
1In order to keep the notation simple I will not discriminate between a random variable and its realization
in the following.
2Another useful analytical result can be utilized by assuming prior independence of both parameters and
3

of the sample size T, nonstationarity of the data generating process or the inclusion of
deterministic components. Another appealing feature of choosing a Bayesian framework
is that one does not only get a point or an interval estimate of the quantity of interest, e.g.
a break date or the number of breaks, but a whole distribution, viz. the posterior distribu-
tion which, for a given data set, is a sound way to capture the uncertainty with regard to
any further inference.
Sims and Uhlig (1991) compute the joint posterior distribution of œÜ and bœÜ under a Ô¨Çat
prior using Monte Carlo methods and examine the behavior of the conditional densities
f (bœÜ|œÜ = 1) and f (œÜ|bœÜ = 1) to compare the Bayesian and the classical approach to unit
root testing. They conclude that classical methods based on the resulting asymmetric
small sample distribution f (bœÜ|œÜ = 1) of the OLS estimator can be misleading by assign-
ing too much density to large œÜ values, see ibid. for details. Although hypothesis testing
can also be considered as a point estimation problem (cf. Robert (2007), chapter 5), unit
root testing is a striking example where it is not possible to recover classical results by us-
ing a Ô¨Çat prior, see Bauwens et al. (1999). Moreover the results of classical and Bayesian
unit root tests can differ considerably. Since the unit root hypothesis is a point hypothesis
it is highly controversial to test for this in a Bayesian framework. In the continuous case,
this implies comparing a parameter interval receiving positive probability mass under the
alternative H1 : œÜ < 1 with a singleton of zero probability mass under the null hypothesis
H0 : œÜ = 1, see equation (1.1). An extreme illustration of the conÔ¨Çicting outcomes of fre-
quentist and Bayesian testing of a point null, namely rejecting the null almost surely with
an arbitrarily low p-value, while on the other hand obtaining a posterior probability of H0
close to one when the sample size increases, is called the ‚ÄôJeffreys-Lindley‚Äôs paradox‚Äô,
see Berger (1980), p.156, also Shafer (1982) for details. Besides the appropriate choice
of the prior, which becomes less inÔ¨Çuential when more information is available, the cho-
sen parametrization of the testing regression can play a pivotal role for the performance
of the test. In frequentist unit root testing the distribution theory becomes much more
involved when structural breaks in the model parameters are allowed, cf. Maddala and
Kim (1998) for an overview. Then for testing purposes two additional kinds of unknown
entities have to be selected, viz. the number of breaks and the corresponding break dates.
In a Bayesian context estimation of both entities can be accomplished simultaneously by
then using a Student-t prior on œÜ and an Inverse-Gamma-2 prior on the variance of the error term, see
Dreze (1977), Richard and Tompa (1980).
4

using Monte Carlo techniques, as will be shown in chapter 2, where this task becomes
much more challenging when using classical methods, cf. Bai and Perron (1998), Bai and
Perron (2003). Another useful approach presented in chapter 4, which avoids the selection
of a single testing regression is to use model averaging techniques. It is exactly for these
reasons why a comparison of classical and Bayesian unit root testing procedures can bring
new insights into the analysis of nonstationarity when different Bayesian approaches to
this model uncertainty problem are considered.
Finally, also with regard to the prediction of future values, yT+k, k ‚â•1, Bayesian meth-
ods can provide an interesting alternative to existing frequentist time series methods. In
chapter 5 a model averaging prediction approach for seasonal time series models with
possible breaks is presented. This requires the computation of a mixture of density func-
tions, where in a Bayesian framework the mixture weights are the posterior probabilities
of the different candidate models Mi. In general, model averaging demands the predeÔ¨Åni-
tion of a set of candidate models, M = {M1,...,MI}, where each element Mi represents a
certain (non)nested model speciÔ¨Åcation, which can be indicated by the introduction of a
model index Œ≥ ‚àà{1,...,I}, see Raftery et al. (1997).3 Although there also exist frequentist
model averaging approaches that obtain the required model weights as the solutions of an
optimization problem (cf. Hansen (2007)), the majority of the existing literature assumes
a Bayesian frame of reference. One reason for this is that here it is natural to consider
the model indicator Œ≥ as an additional random parameter with assigned prior probability
in order to express model uncertainty. Then model averaging implies ‚Äôintegrating out‚Äô
this nuisance parameter by averaging over the support of Œ≥, using the posterior model
probabilities as weights. It is interesting to note that the frequentist estimators of the
model weights can also be obtained by applying a Laplace approximation (see Tierney
and Kadane (1986), Tierney et al. (1989)) to the joint posterior density as in Raftery
(1995), p.130 ff. In this case the posterior probability mass function of model Mi can be
expressed as a function of the Bayesian information criterion (BIC) (see Schwarz (1978)):
f (Mi| y) ‚âàexp(‚àí1/2¬∑BICi)/
I
‚àë
j=1
exp(‚àí1/2¬∑BICj)
which is also one of the sampling estimates for the weights used by Hansen (2007) within
3In this respect a model selection problem can also be perceived as a point estimation problem, namely that
of the model indicator Œ≥, see Robert (2007), p.342.
5

a classical context.
After this motivation on the topic and the Bayesian framework has been given, next an
approach to test for a nonseasonal unit root in the case of multiple structural breaks is
presented.
6

Analysis of nonseasonal time series
7

Bayesian model selection for unit
root testing with multiple breaks
2.1. Introduction
There has been a growing literature to unit root testing in economic time series over the
last three decades starting with the seminal papers of Dickey and Fuller (1979) and Nelson
and Plosser (1982). As stressed by many authors the misspeciÔ¨Åcation of the considered
test regressions can lead to substantially biased inferences in the class of autoregressive
integrated moving average (ARIMA) models, see Banerjee et al. (1993), Stock (1994),
Maddala and Kim (1998) for discussions. The speciÔ¨Åcation regards on the one hand the
structure of the stochastic component, i.e. the autoregressive and/or moving average lag
orders (see Hall (1994), Ng and Perron (2001)) and on the other hand the speciÔ¨Åcation
of the deterministic components like the inclusion of time trends, the number of possi-
ble structural breaks and also the timing of these breaks, see Perron (1989), Christiano
(1992), Vogelsang and Perron (1992), inter alia. In the Bayesian unit root literature a
heated controversy was devoted to the adequate prior use, model speciÔ¨Åcation issues and
the proper modeling of initial conditions, see e.g. Sims (1988), Phillips (1991b), Uhlig
(1994), inter alia, and Bauwens et al. (1999) for an overview. In contrast to the classical
literature there are only a few approaches to account for structural breaks when testing
for stochastic trends, see e.g. Zivot and Phillips (1994), Koop and Steel (1994), DeJong
(1996), Marriott and Newbold (2000). Most of these works treat the model order, in
particular the lag order and/or the number of breaks as Ô¨Åxed quantities. In general, the
process of model selection induces uncertainty with respect to any subsequent analysis
and thus should be captured in order to improve statistical inference. Although there exist
many classical approaches to model selection in dynamic models with structural breaks,
8

which are mainly based on information criteria, a different approach is chosen here using
a Bayesian framework.
In the following a stochastic model selection approach is presented, which can be used to
determine the optimal speciÔ¨Åcation for unit root testing in the case of multiple structural
breaks. In a nutshell, the proposed sampling scheme can be regarded as an extension of
the approach presented in Wang and Zivot (2000) by estimating the number of structural
breaks, the associated break dates as well as the number of autoregressive lags simulta-
neously with all other unknown model parameters. This is accomplished by the intro-
duction of two discrete valued state variables that indicate certain model combinations
in the space of candidate models. Since the joint distribution of all unknown parameters
is of varying dimension, i.e. depends on the speciÔ¨Åc model complexity, usual sampling
techniques to generate random draws from this distribution, like Gibbs sampling, can not
be applied without further modiÔ¨Åcations. For this purpose a Ô¨Çexible Markov chain Monte
Carlo (MCMC) approach is introduced, which enables to jump between parameter spaces
of differing dimensionality. The performance of this method is demonstrated on the ba-
sis of several Monte Carlo (MC) experiments which indicate great reliability in Ô¨Ånding
the true values of the data generating process (DGP). Using Bayesian methods for model
selection in structural break models has the advantage that most of these methods are
technically simpler than their classical counterparts, allow for Ô¨Ånite-sample inferences
that are optimal given the framework, and also allow for nonnested model comparisons
(see Wang and Zivot (2000)). Furthermore with regard to unit root testing a Bayesian
model framework is appealing, because unlike in classical approaches inference stays the
same here for trending and nontrending data (see Sims and Uhlig (1991)). So far many
approaches to model selection in time series models have been proposed in the Bayesian
literature. Among the works that mainly focus on lag order determination are Huerta and
West (1999), Vermaak et al. (2004), Ehlers and Brooks (2004), Philippe (2006), inter alia.
Many of the existing works that deal with the detection of change points treat the selection
of the number of breaks as a successive problem, which is solved by using information
criteria or Bayes factors, but do not treat the number of change points together with the
number of lags as additional model parameters explicitly in their sampling schemes, see
for example Chib (1998), Wang and Zivot (2000), Koop and Potter (2004).
Therefore the present work aims to provide contributions in the following directions: a
9

stochastic model selection approach for multiple structural breaks models is proposed,
where the autoregressive lag order, the break dates and also the number of breaks can be
estimated simultaneously with all other model parameters. As a result the joint posterior
distribution of these model indicators is obtained, which can be used for further inference.
Moreover the model selection approach presented below focuses on the application in unit
root testing problems and the use of Augmented-Dickey-Fuller-type regressions (see Said
and Dickey (1984)) and thus provides an alternative to classical model selection strategies
used in this context. Unlike in standard autoregressive models alternative Bayesian model
selection approaches to lag order determination, as for example the stochastic search vari-
able selection method of George et al. (1993) can be cumbersome to apply here, because
of the special structure of such test regressions. Besides model determination a second
focus lies on testing for a (zero frequency) unit root when there are multiple structural
breaks in the deterministic components of the process. This is done by computing the
posterior probability of a unit root under several prior distributions, which is then used
to construct a Bayesian test. The proposed Bayesian unit root test is then compared with
several classical unit root tests by means of simulated power functions. Monte Carlo ex-
periments indicate a clear superiority of the Bayes test in terms of power especially in
moderate and small samples, i.e. when the asymptotic distribution theory underlying the
classical tests is not valid anymore.
In an empirical application, the unemployment rates of 17 OECD countries for the years
1960 to 2010 are analyzed to answer the question if there is persistent behavior after a
labor market shock. The majority of empirical works to test for persistence effects in
European unemployment rates has been done by using classical methods. Most of these
works apply univariate tests without structural breaks and can not reject the unit root
null hypothesis, see Mitchell (1993), Roed (1996) also Hassler and Wolters (2009). For
the US the results are mostly reverse and therefore no high degree of persistence has
been found in the unemployment rates, see Nelson and Plosser (1982), Blanchard et al.
(1992) also Roed (1996). It is by now well recognized that not allowing for structural
breaks in the test regression can bias the results toward a unit root. Therefore a second
group of studies uses methods that allow for (multiple) structural breaks. Not surprisingly
the results of these studies show a clearer tendency against a unit root, see Arestis and
Biefang-Frissancho Mariscal (1999), Papell et al. (2000), Papell and Prodan (2004) and
also Pascalau (2007). So far only few authors used Bayesian methods to analyze the
10

trend characteristics of unemployment rates, exceptions are Summers (2004), Mikhail
et al. (2006) and Berger and Everaert (2008). Since the time span of the data covers
the Ô¨Årst Ô¨Ånancial crisis of the year 2008 it is also possible to capture the impact of this
event. Thereby, besides the main statistical focus, the present work also aims to provide
some new empirical evidence to the question if certain OECD countries are more likely
then others to recover to their natural rate of unemployment after an exogenous shock
or if such an event has a permanent impact on a country‚Äôs long run unemployment rate.
As a benchmark the Bayesian estimates of the break numbers and the break points are
compared with the estimates from an application of the classical methods of Bai and
Perron (2003). To gain further insights into the countries‚Äô convergence properties and also
in order to control for uncertainty induced through the model selection step the estimated
model posterior distribution is used to compute the model averaged half life of a shock
for each OECD country.
This chapter is structured as follows: in section 2.2 the statistical model is presented
and in section 2.3 the MCMC sampling algorithm is introduced and its performance is
analyzed in section 2.4. Then in section 2.5 the Bayesian testing approach for a unit root
with multiple structural breaks is presented. Further, in section 2.6, the sensitivity of the
test results with regard to the assumed prior distributions is analyzed and the Bayesian
unit root test is compared with some classical unit root tests. In section 2.7 the presented
methods are applied to annual OECD unemployment rates and section 2.8 concludes.
2.2. Bayesian unit root testing with multiple
breaks
2.2.1. Model and denitions
In the following it is assumed that the series of interest yt can be described by an autore-
gressive process of order p together with some deterministic components, i.e.
Ap(L)¬∑yt = ¬µ + Œ≤ ¬∑t + ut with ut
i.i.d.
‚àºN(0,œÉ2) , t = 1,...,T
(2.1)
11

where the intercept ¬µ and slope Œ≤ are the coefÔ¨Åcients of the deterministic trend function
and Ap(L) is deÔ¨Åned in terms of the lag operator xt‚àíj ‚â°L j ¬∑xt , j ‚ààZ, i.e.
Ap(L) ‚â°1‚àíœÜ1L‚àíœÜ2L2 ‚àí...‚àíœÜpLp
(2.2)
The main focus here is to investigate if the autoregressive lag polynomial Ap(L) can
be factorized according to Ap‚àí1(L) ¬∑ (1 ‚àíL), where in this case yt is said to exhibit a
(nonseasonal) unit root, i.e. Ap(1) = 0. To test for a root at the zero spectral frequency it
is convenient to rewrite the above polynomial as
Ap(L) = (1‚àíŒ∏L) ‚àíA‚ãÜ
p‚àí1(L) ¬∑(1‚àíL)
(2.3)
with Œ∏ = ‚àëp
s=1 œÜs the long-run impact coefÔ¨Åcient. The polynomial A‚ãÜ
p‚àí1(L) = œà1 ¬∑ L +
... + œàp‚àí1 ¬∑ Lp‚àí1 is assumed to have all roots outside the complex unit circle with the
coefÔ¨Åcients œàj = ‚àí‚àëp
s= j+1 œÜs , j = 1...p‚àí1, measuring transient dynamics (see Hamilton
(1994), p.517). Substituting (2.3) into (2.1) then leads to
yt = ¬µ + Œ≤ ¬∑t + Œ∏ ¬∑yt‚àí1 +
p‚àí1
‚àë
j=1
œà j ¬∑ ‚àÜyt‚àíj + ut with ut
i.i.d.
‚àºN(0,œÉ2)
(2.4)
This is an Augmented Dickey-Fuller (ADF) regression for testing the unit root hypothesis
H0 : Œ∏ = 1, which implies that (at least) one of the p characteristic roots z j ‚ààC of Ap(z)
has modulus equal to unity (see Said and Dickey (1984), also Nelson and Plosser (1982)).
On the other hand the (trend)stationary alternative H1 : |Œ∏| < 1 implies that all roots are
strictly outside the unit circle. Hence the relevant parameter region for this testing prob-
lem is Œ∏ ‚àà[0;1]. In order to allow for multiple structural breaks in the DGP the above
regression is now extended to (cf. Perron and Vogelsang (1992)):
yt =
m+1
‚àë
i=1
1{ki‚àí1‚â§t<ki}(Œ±i +Œ≤i ¬∑t)+Œ∏ ¬∑yt‚àí1 +
p‚àí1
‚àë
j=1
œàj ¬∑‚àÜyt‚àíj +ut , ut
i.i.d.
‚àºN(0,œÉ2) (2.5)
where ki denotes the i-th break date with 1 < k1 < ... < km ‚â§T and 1{A} denotes an
indicator variable that equals 1 if the statement A is true and 0 otherwise. Note that the
effect of an intervention is modeled here as a step function at date t = ki, which is typically
used to represent an instantaneous impact on the level of a series yt. Setting k0 = 1 and
12

km+1 = T + 1 for the lower and upper margins, respectively, the T observations can be
separated into m + 1 regimes, see ?. In contrast to the latter authors I treat the number
of structural breaks m = 0,1,...,mmax and also the autoregressive lag order p = 1,..., pmax
as unknown model indicators stacked together in a vector Œ≥ ‚â°(p,m)‚Ä≤ which has to be
estimated.
The above ADF-type multiple structural breaks model can be written more compactly
in matrix form, where it is convenient to separate the vector of model parameters Œª Œ≥ ‚â°
(B‚Ä≤
Œ≥,œÉ2,k‚Ä≤
Œ≥)‚Ä≤ of dimension h(Œ≥) = 3 ¬∑ (m + 1) + p in the ‚Äôdrift-and-trend‚Äô case and of
h(Œ≥) = 2¬∑(m+1)+ p in the ‚Äôdrift-only‚Äô case from the vector of model indicators denoted
by Œ≥. The model in (2.5) can then be expressed in the usual linear regression form1
y = XŒ≥BŒ≥ + u
(2.6)
with y = (yp+1,...,yT)‚Ä≤, the Ô¨Årst p observations y0 = (y1,...,yp)‚Ä≤ used as initial values,
u = (up+1,...,uT)‚Ä≤ the vector of innovations and the matrix XŒ≥ = [xp+1,...,xT]‚Ä≤ with row
vectors
xt ‚â°[1{k0‚â§t<k1} ,..., 1{km‚â§t<km+1}, 1{k0‚â§t<k1} ¬∑t ,..., 1{km‚â§t<km+1} ¬∑t,
yt‚àí1, ‚àÜyt‚àí1,...,‚àÜyt‚àíp+1]
of dimension d(Œ≥) = m+1+ p in the ‚Äôdrift-only‚Äô case or dimension 2¬∑(m+1)+ p in the
‚Äôdrift-and-trend‚Äô case.2 The vector of all unknown quantities is thus (B‚Ä≤
Œ≥,œÉ2,k‚Ä≤
Œ≥,Œ≥‚Ä≤)‚Ä≤ with
BŒ≥ = (Œ±1,...,Œ±m+1,Œ≤1,...,Œ≤m+1,Œ∏,œà1,...,œàp‚àí1)‚Ä≤ the vector of regimewise regression
coefÔ¨Åcients and kŒ≥ = (k1,...,km)‚Ä≤ the vector of break dates.3
1Technically speaking the XŒ≥ matrix is of course also dependent on the realizations in kŒ≥. In this sense the
parameters in kŒ≥, i.e. the break dates, could also be considered as further model indicators.
2For notational brevity I will write d = d(p,m) and h = h(p,m) and also for example d‚ãÜ= d(p‚ãÜ,m) in the
sequel.
3Since this is a conditional likelihood approach, rather than an exact (cf. Bauwens et al. (1999), p.135),
the Ô¨Årst p observations of the series get lost due to lagging and so the Ô¨Årst break can not be detected until
t = p+ 2. This is the reason why kŒ≥ is also dependent on the lag order.
13

2.2.2. Likelihood and prior specications
Utilizing the Ô¨Årst p observations as initial values y0 yields the conditional data density,
which when viewed as a function of the parameters is the approximate likelihood function
f (y|Œª Œ≥,Œ≥;y0) ‚àùœÉ‚àí(T‚àíp) ¬∑exp

‚àí1
2œÉ2(y‚àíXŒ≥BŒ≥)‚Ä≤ ¬∑(y‚àíXŒ≥BŒ≥)

(2.7)
Due to the introduction of the model indicators and the break dates this is a mixture
of discrete and continuous distributions. But given values for kŒ≥, p and m, this is the
kernel of the Normal-Inverse-Gamma-2 distribution.4 For the unknown quantities I use
the following prior distributions:
f (BŒ≥|œÉ2) = Nd(B0, œÉ2 ¬∑M‚àí1)
(2.8a)
f (œÉ2) = IG2(a,b) ,
a,b > 0
(2.8b)
f (p,m ;T) ‚àùT ‚àídŒ≥
2 ,
p ‚ààN, m ‚ààN0
(2.8c)
f (ki|ki‚àí1) ‚àù1
, if ki ‚àà]ki‚àí1 ; ki+1[ and 0 otherwise , i = 1...m+ 1
(2.8d)
f (kŒ≥) =
m+1
‚àè
i=1
f (ki|ki‚àí1) with k0 = p+ 1 and km+1 = T + 1
(2.8e)
The priors in (2.8a) and (2.8b) are the conjugate prior distributions for a Normal linear re-
gression model, namely a multivariate Normal distribution with mean vector B0 ‚ààRd and
M a positive deÔ¨Ånite symmetric d √ó d matrix5 and the Inverse-Gamma-2 (IG2) density
with scale and shape parameters b and a, respectively. The assumptions (2.8d) and (2.8e)
express lack of prior knowledge with respect to the break dates. As it can be observed
from (2.8c) the two random variables m and p are assumed as stochastically indepen-
dent of each other, for example in the ‚Äôdrift-and-trend‚Äô-case the prior can be factorized
as f (Œ≥) = f (p) ¬∑ f (m) = T ‚àíp
2 ¬∑ T ‚àí(m+1). This is a strictly decreasing function in p and
m, which implies that higher lag orders and/or number of breaks are considered to be
4Strictly speaking one could also condition on the upper bounds pmax and mmax, respectively, in the follow-
ing. However in order not to overload the notation this conditioning is omitted.
5Here I choose M = Id/100 and B0 = 0, respectively, to express a lack of knowledge with respect to the
prior location and scaling of B0.
14

less likely, given a sample of size T. Furthermore it is a data-dependent6 and informative
prior in the sense that more complex, i.e. higher parameterized models are assigned a
lower prior weight compared to less complex models and thus serves as a penalty factor
in the acceptance ratios below.7 The above priors together with the likelihood function in
(2.7) lead to the following Bayesian hierarchy:
f (Œª Œ≥,Œ≥|y,y0) ‚àùf (y|Œª Œ≥,Œ≥;y0)¬∑ f (BŒ≥|œÉ2,kŒ≥,Œ≥) ¬∑ f (œÉ2|kŒ≥, Œ≥) ¬∑ f (kŒ≥|Œ≥)¬∑ f (Œ≥)
(2.9)
which is equal the joint posterior density of the parameters up to a normalizing constant.
Before presenting an MCMC algorithm to generate random draws from the joint poste-
rior distribution (2.9) for ADF-type models of varying dimension, I will Ô¨Årst sketch the
general idea of the underlying stochastic model selection scheme. In the following the
conditioning on y0 will be dropped for notational convenience.
2.3. Stochastic model selection via MCMC
The main task in model determination is to Ô¨Ånd a single parametrization which describes
the data best with respect to goodness of Ô¨Åt criteria. In Bayesian statistics this Ô¨Åt is
measured in probabilistic terms by means of the posterior probability of a certain model
Mi. In accordance with the model selection literature the parameter and the model space
are distinguished in the following, where the former can be viewed as embedded in the
latter, that is each model Mi is represented as a point in the space of candidate models.
In the sequel a sampling scheme to conduct jumps between parameter spaces of varying
dimensionality is proposed, that is to make moves within the model space. For the model
in (2.5) let M = {M1,M2,...} be a countable set of candidate models each of which is
associated with a likelihood function f (y|Œª Œ≥,Œ≥), with unknown parameter vector Œª Œ≥ ‚àà
ŒõŒ≥ = Rd √ó R+ √ó Nmmax
[p+2; T‚àí1] and a vector of model indicators Œ≥ ‚ààŒì = N[1; pmax] √ó
N[0; mmax]. For example, consider M1 and M2 to be two models indicated by Œ≥1 = (p1,m1)‚Ä≤
and Œ≥2 = (p2,m2)‚Ä≤ of dimensions h1 and h2 within the set of candidate models Œì. Then
for each of these two models three types of model moves can be distinguished when
6This can be considered as an empirical Bayes approach, see Casella (1985).
7Note that this prior trades off the reduction in the residual variance against the inclusion of additional
(regimewise) regressors in the spirit of information criteria, cf. Schwarz (1978).
15

moving from one state Œ≥1 to another state Œ≥2. The possible transitions are called ‚ÄôBirth‚Äô
(i.e. upward), ‚ÄôDeath‚Äô (i.e. downward) and ‚ÄôLife‚Äô moves, where the Ô¨Årst two are between-
model moves and the latter are within-model moves. For example in the case of a ‚Äôp-
Birth‚Äô move the Markov chain would jump from Œ≥1 to Œ≥2 with p2 > p1, and for the ‚ÄôDeath‚Äô
move vice versa. The same applies of course to jumps in the m-dimension. As the name
suggests ‚ÄôLife‚Äô moves leave the dimension with respect to p and m unchanged, i.e. p2 =
p1 and m2 = m1.
The present approach is most similar to that of Troughton and Godsill (1997a), who
propose a sampling scheme for a lag order selection in autoregressive models, see also
Godsill (2001), Ehlers and Brooks (2002). In accordance to the cited works I generate
new values Œª 2 as a full vector directly in the h2-dimensional parameter space leaving the
current value of the error variance œÉ2 unchanged.8 Conducting ‚Äôbetween‚Äô model moves,
i.e. ‚ÄôBirth‚Äô and ‚ÄôDeath‚Äô moves, with respect to the number of breaks m‚ãÜand/or the number
of lags p‚ãÜis accomplished by Metropolis-Hastings (MH) steps (see Hastings (1970), Chib
and Greenberg (1995)) with acceptance probabilities of a candidate move Œ≥‚ãÜ= (p,m‚ãÜ)‚Ä≤
or Œ≥‚ãÜ= (p‚ãÜ,m)‚Ä≤ depending on the context:
Œ±(Œ≥, Œ≥‚ãÜ) = min

1, f (BŒ≥‚ãÜ,Œ≥‚ãÜ,kŒ≥‚ãÜ|œÉ2,y)
f (BŒ≥,Œ≥,kŒ≥|œÉ2,y) ¬∑ œÄ(Œ≥‚ãÜ, Œ≥)
œÄ(Œ≥, Œ≥‚ãÜ) ¬∑ q(uŒ≥|uŒ≥‚ãÜ)
q(uŒ≥‚ãÜ|uŒ≥)

(2.10)
Here f (.) denotes the target density, œÄ(.) the proposal density for a model move accord-
ing to Œ≥‚ãÜand q(.) a proposal density to draw a vector of model parameters uŒ≥‚ãÜunder
the candidate model. Conducting ‚ÄôLife‚Äô moves is done by leaving the components in Œ≥
unchanged and updating the remaining model parameters via Gibbs sampling steps (see
Casella and George (1992)). This hybrid strategy to sample from the joint posterior dis-
tribution in (2.9) then proceeds as outlined in algorithm (1).
8This is the ‚Äôfull parameter vector proposal‚Äô approach of (Troughton and Godsill, 1997a, p.5). The same
approach is used by (Ehlers and Brooks, 2002, p.23) for their ‚Äôclass B moves‚Äô.
16

Algorithm 1 : Hybrid sampler
Step 1: Set the iteration counter on j = 1 and initialize Œª (0)
Œ≥ , p(0),m(0) randomly or de-
terministically.
Step 2: Propose a candidate for the lag order p‚ãÜfrom a proposal density œÄ:
‚Ä¢ if p‚ãÜ> pmax: set p‚ãÜ= pmax,
‚Ä¢ if p‚ãÜ< pmin: set p‚ãÜ= pmin,
‚Ä¢ otherwise accept the candidate move p‚ãÜwith probability:
Œ±1(p, p‚ãÜ) = min
(
1,
f (y| p‚ãÜ,m,k(p‚ãÜ,m))
f (y| p,m,k(p,m)) ¬∑ œÄ(p‚ãÜ, p)
œÄ(p, p‚ãÜ) ¬∑ f (p‚ãÜ)
f (p)
)
(2.11)
‚Ä¢ Set p( j) = p‚ãÜ( j) if accepted, otherwise p( j) = p( j‚àí1)
Step 3: Propose a new number of structural breaks m‚ãÜsimilar to step 2:
‚Ä¢ if m‚ãÜ> mmax: set m‚ãÜ= mmax,
‚Ä¢ if m‚ãÜ< mmin: set m‚ãÜ= mmin,
‚Ä¢ otherwise accept the candidate move m‚ãÜwith probability:
Œ±2(m, m‚ãÜ) = min
(
1,
f (y| m‚ãÜ, p,k(p,m‚ãÜ))
f (y| m, p,k(p,m)) ¬∑ œÄ(m‚ãÜ,m)
œÄ(m,m‚ãÜ) ¬∑ f (m‚ãÜ)
f (m)
)
(2.12)
‚Ä¢ Set m( j) = m‚ãÜ( j) if accepted, otherwise m( j) = m( j‚àí1)
Step 4: Draw the i-th break date ki from the full conditional multinomial posterior dis-
tribution f (k( j)
i
| k( j‚àí1)
i‚àí1
, k( j‚àí1)
i+1 , p( j), m( j), B( j‚àí1)
Œ≥
, œÉ2( j‚àí1), y) on the sample
space ]k( j)
i‚àí1, k( j)
i+1[ , i = 1,...,m
Step 5: Draw a random vector B( j)
Œ≥
from the full conditional multivariate normal
posterior distribution f (B( j)
Œ≥ | k( j), p( j), m( j), œÉ2( j‚àí1), y).
Step 6: Draw œÉ2( j) from the full conditional inverse gamma posterior distribution
f (œÉ2( j)| B( j)
Œ≥ , k( j), p( j), m( j), y).
Step 7: Set j = j + 1, return to step 2.
17

As a proposal density œÄ(.) for the respective model moves I use a discretized Laplacian
density (see Johnson and Kotz (1970)) centered over the current model as proposed by
Godsill (2001), Ehlers and Brooks (2004) among others. Since this is a Random Walk
proposal most moves are conducted in the neighborhood of the current model and thus
most jumps will be small. However occasionally large jumps are also conducted and this
ensures nice mixing and convergence properties of the corresponding Markov chains of
m and p.9 For example, in the case of a jump from state p to p‚ãÜI choose a Laplacian
density of the form
œÄ(p, p‚ãÜ) = 1
2œÑ exp

‚àí|p‚ãÜ‚àíp|
œÑ

,
œÑ ‚â•0 , p‚ãÜ‚àà[1, pmax]
(2.13)
with mean p and variance 2œÑ2. The same strategy is used in order to model jumps in the
‚Äôm‚Äô- dimension. To achieve the expressions of the MH acceptance ratios in (2.11) and
(2.12) I use the full conditional posterior distribution of the vector of regression coefÔ¨Å-
cients (see step 5) as a proposal density:10
uŒ≥‚ãÜ‚àºq(uŒ≥‚ãÜ| kŒ≥‚ãÜ,Œ≥‚ãÜ,uŒ≥, œÉ2; y) = Nd‚ãÜ(¬µŒ≥‚ãÜ, Œ£Œ≥‚ãÜ)
(2.14a)
with ¬µŒ≥‚ãÜ= œÉ‚àí2 ¬∑ Œ£Œ≥‚ãÜ¬∑X‚Ä≤Œ≥‚ãÜ¬∑y ,
(2.14b)
Œ£Œ≥‚ãÜ= œÉ2 ¬∑(X‚Ä≤Œ≥‚ãÜXŒ≥‚ãÜ+ M)‚àí1
(2.14c)
and d‚ãÜthe dimension of the proposed candidate vector. For example Ehlers and Brooks
(2002) show by applying their ‚Äôsecond order method‚Äô that this constitutes an efÔ¨Åcient
proposal, see also Troughton and Godsill (1997b), Dellaportas et al. (2002) among others.
Instead of drawing new values uŒ≥‚ãÜfrom the proposal density in (2.14a) and substituting
it together with the likelihood and the priors into equation (2.10), which could lead to
numerical problems in the computation, I follow Troughton and Godsill (1997b) here by
applying the ‚ÄôCandidate‚Äôs identity‚Äô of Besag (1989) to the present context, namely11
f (y|Œ≥,kŒ≥,œÉ2) = f (y|Œ≥,kŒ≥,BŒ≥,œÉ2)¬∑ f (BŒ≥|Œ≥,kŒ≥,œÉ2)
f (BŒ≥|Œ≥,kŒ≥,œÉ2,y)
(2.15)
9Note that for œÑ ‚Üí‚àûthe result is the uniform proposal for p‚ãÜ‚àà[1, pmax].
10This approach is sometimes called ‚ÄôIndependent Reversible Jump MCMC sampler‚Äô, see Lopes (2006).
11This is the ‚Äôbasic marginal likelihood identity‚Äô used in Chib (1995).
18

so that the density in (2.14a) can equivalently be written as
q(uŒ≥‚ãÜ|uŒ≥) = f (y|Œ≥‚ãÜ,kŒ≥‚ãÜ,BŒ≥‚ãÜ,œÉ2) ¬∑ f (BŒ≥‚ãÜ|Œ≥‚ãÜ,kŒ≥‚ãÜ,œÉ2)
f (y|Œ≥‚ãÜ,kŒ≥‚ãÜ,œÉ2)
(2.16)
Now substituting expression (2.16) into (2.10) and integrating out œÉ2 in both the numer-
ator and the denominator analytically, the acceptance ratio simpliÔ¨Åes to:
Œ±(Œ≥,Œ≥‚ãÜ) = min

1, f (y|Œ≥‚ãÜ,kŒ≥‚ãÜ)
f (y|Œ≥,kŒ≥) ¬∑ f (Œ≥‚ãÜ,kŒ≥‚ãÜ)
f (Œ≥,kŒ≥) ¬∑ œÄ(Œ≥‚ãÜ,Œ≥)
œÄ(Œ≥,Œ≥‚ãÜ)

(2.17)
The above acceptance probability thus reduces to the posterior odds ratio in favor of a
model with Œ≥‚ãÜand kŒ≥‚ãÜ. Given the prior assumptions (2.8c) - (2.8e) the expression in (2.17)
is proportional to the ratio of the marginalized (model-speciÔ¨Åc) likelihoods times the ratio
of the jump probabilities.12 The model likelihoods in (2.17) have the form of multivariate
Student-t densities, TT‚àíp(¬µ = XŒ≥B0, P = (IT‚àíp + XŒ≥M‚àí1X‚Ä≤Œ≥)‚àí1/b, ŒΩ = a), with a
degrees of freedom (see appendix G for details), which are given by
f (y|Œ≥,kŒ≥) = C ¬∑
"
1+ (y‚àíXŒ≥B0)‚Ä≤ ¬∑
 IT‚àíp + XŒ≥M‚àí1X‚Ä≤Œ≥
‚àí1
b
¬∑(y‚àíXŒ≥B0)
#‚àíT‚àíp+a
2
(2.18)
with normalizing constant
C ‚â°œÄ‚àíT‚àíp
2 ¬∑
IT‚àíp + XŒ≥M‚àí1X‚Ä≤Œ≥
‚àí1
2 ¬∑b
a
2 ¬∑

Œì
T ‚àíp+ a
2

/Œì
a
2

(2.19)
Furthermore in step 5 of the sampling scheme above the random vectors BŒ≥ are drawn
from a multivariate normal distribution with mean vector ¬µŒ≥ = œÉ‚àí2 ¬∑ Œ£Œ≥ ¬∑ X‚Ä≤Œ≥ ¬∑ y and co-
variance matrix Œ£Œ≥ = œÉ2 ¬∑(M+ X‚Ä≤Œ≥XŒ≥)‚àí1. The IG(a‚ãÜ,b‚ãÜ) posterior distribution of step 6
has shape parameter a‚ãÜ‚â°a+ T
2 and scale parameter b‚ãÜ‚â°b+ 1
2(y‚àíXŒ≥BŒ≥)‚Ä≤ ¬∑(y‚àíXŒ≥BŒ≥).
Before turning to the empirical analysis of OECD unemployment rates, it is useful to
evaluate the performance of the outlined sampling algorithm for model selection and also
the power of the Bayesian unit root test.
12A similar result is stated by Dellaportas et al. (2002) in context of their ‚ÄôMetropolised Carlin and Chib‚Äô
approach when using the posterior distribution for each model Mi as a pseudo-prior, see Dellaportas et al.
(2002), p.30 for details.
19

2.4. Monte Carlo evidence: MCMC based model
selection
With the stochastic model selection procedure presented in the last section, the (condi-
tional) posterior distributions of the parameters p, m and kŒ≥ can be approximated. These
can then be used for further analysis. For example, Koop and Potter (1999) point out,
that in a Bayesian approach no single model has to capture the true DGP, instead we can
weight features of interest (as the long run coefÔ¨Åcient Œ∏ in the present context) from dif-
ferent models by their respective posterior model probabilities. Working with such model
averaged quantities is particularly attractive in disciplines like economics where theoret-
ical considerations do not always suggest which model speciÔ¨Åcation is best. In contrary
to classical methods where the induced uncertainty of the model selection step can not be
fully captured through the statistical measures, the underlying Bayesian approach allows
a probabilistic representation of this uncertainty through the shape (e.g. multimodality,
platykurtosis) of the corresponding posterior distributions. To get an impression of the
sampler‚Äôs performance, especially with regard to model selection, trajectories of mod-
erate lengths (T = 200) are simulated for three ARMA(p,q)-processes without breaks
and also three processes with breaks. Then the above sampler is run for 10000 iterations
omitting the Ô¨Årst 1000 random draws due to burn-in. The scale parameter of the Lapla-
cian jump proposal (2.13) and the maximum number of lags are chosen to be œÑ = 5 and
pmax = 15, respectively. The DGPs considered here are as follows:
‚Ä¢ No-break design 1: yt = 0.8yt‚àí1 ‚àí0.35yt‚àí2 + Œµt
‚Ä¢ No-break design 2: yt = 0.2+ 0.1¬∑t + 0.5yt‚àí1 + 0.2yt‚àí2 ‚àí0.3yt‚àí3 + 0.5yt‚àí4
‚àí0.3yt‚àí5 ‚àí0.21yt‚àí6 + Œµt
‚Ä¢ No-break design 3: yt = 0.7yt‚àí1 + 0.12yt‚àí2 + 0.22yt‚àí3 ‚àí0.15yt‚àí4 ‚àí0.5yt‚àí5+
0.4yt‚àí6‚àí0.35yt‚àí7+0.23yt‚àí8+0.21yt‚àí9‚àí0.4yt‚àí10+0.2yt‚àí11‚àí0.2yt‚àí12+Œµt
each with Œµt
i.i.d.
‚àºN(0,œÉ = 0.25).
Since in the above three examples interest primary is on the identiÔ¨Åcation of the true lag
order, the number of structural breaks is Ô¨Åxed at m = 0 with the exception of simulation
20

design 3, where a maximum number of mmax = 5 breaks is allowed. Figures 2.1-2.3 show
simulated trajectories together with the resulting posterior distributions of the lag order
p|(m = 0), the long run coefÔ¨Åcient Œ∏|( [
pMAP, m = 0), and in case of design 3 also of
the posterior of the number of breaks m, where [
pMAP denotes the maximum a posteriori
(MAP) estimate of p.13
As is evident from the three examples, the sampler generates
Time
0
50
100
150
200
‚àí3
‚àí2
‚àí1
0
1
2
3
Simulated AR(2) data
1
3
5
7
9
11
13
15
Number of AR lags 'p'
Posterior probability function
0.0
0.1
0.2
0.3
0.4
0.5
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0
2
4
6
8
(p = 2)
q
density
Posterior density functions of q
Figure 2.1.: No-break design 1: trajectory of an AR(2) process together with the posteriors of the lag
order and of the sum of AR coefÔ¨Åcients Œ∏.
unimodal distributions with modes equal to the true parameter values so that the MAP
estimator yields consistent results. Next I simulate three series with breaks in the level
and/or trend of the process. The data are generated according to
‚Ä¢ Break design 1: yt = at + bt ¬∑t + 0.55yt‚àí1 + 0.35Œµt , Œµt ‚àºN(0,1)
with regime speciÔ¨Åc trend parameters at = Œ±1 = 1 , bt = Œ≤1 = 0.01 for 1 ‚â§t ‚â§33 , at =
Œ±2 = ‚àí0.2 , bt = Œ≤2 = 0.01 for 33 < t ‚â§82 , at = Œ±3 = 0.5 , bt = Œ≤3 = 0.015 for 82 < t ‚â§
121 , at = Œ±4 = 1.6 , bt = Œ≤4 = 0.02 for 121 <t ‚â§151, and at = Œ±5 = 0.4 , bt = Œ≤5 = 0.02
for 151 < t ‚â§200, so that the vector of break dates is k = (33,82,121,151)‚Ä≤.
13This point estimator is also called the generalized maximum likelihood estimator, see DeGroot (1970),
p.236.
21

Time
0
50
100
150
200
0
5
10
15
20
Simulated AR(6) data
1
2
3
4
5
6
7
8
Number of AR lags 'p'
Posterior probability function
0.0
0.2
0.4
0.6
0.8
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0
2
4
6
(p = 6)
q
density
Posterior density functions of q
Figure 2.2.: No-break design 2: trajectory of an AR(6) process with drift and trend together with the
posteriors of the lag order and of the sum of AR coefÔ¨Åcients Œ∏.
Time
0
50
100
150
200
‚àí6
‚àí4
‚àí2
0
2
4
6
Simulated AR(12) data
0
1
2
3
4
5
Number of breaks 'm'
0.0
0.2
0.4
0.6
0.8
Posterior probability function
1
3
5
7
9
11
13
15
Number of AR lags 'p'
Posterior probability function
0.0
0.1
0.2
0.3
0.4
0.5
Figure 2.3.: No-break design 3: trajectory of an AR(12) process together with the posterior distributions
of the lag order and the number of breaks.
22

‚Ä¢ Break design 2: yt = at + yt‚àí1 + 0.55Œµt , Œµt ‚àºN(0,1)
with regime speciÔ¨Åc trend parameters at = Œ±1 = 0.15 for 1 ‚â§t ‚â§33 , at = Œ±2 = 0.75 for
33 < t ‚â§151 , and at = Œ±3 = 0.1 for 151 < t ‚â§200, so that the vector of break dates is
k = (33,151)‚Ä≤.
‚Ä¢ Break design 3: yt = at +bt ¬∑t +0.95yt‚àí1‚àí0.35yt‚àí2 +0.3Œµt‚àí1 +Œµt , Œµt ‚àºN(0,0.1)
with regime speciÔ¨Åc trend parameters at = Œ±1 = 0.12 , bt = Œ≤1 = ‚àí0.01 for 1 ‚â§t ‚â§121 ,
and at = Œ±2 = 0.3 , bt = Œ≤2 = ‚àí0.009 for 121 < t ‚â§200, with the single break date
k1 = 121.
Figures 2.4-2.6 show the simulated paths together with the posterior distributions of p,
m and kŒ≥.
From Ô¨Ågure 2.4 we observe that the lag order and the number of breaks are
0
2
4
6
8
10
0
50
100
150
200
Time
Probability
Time
Probability
Time
Probability
Time
Probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distributions of ki
0
1
2
3
4
5
6
7
8
9
Number of breaks 'm'
0.0
0.1
0.2
0.3
0.4
0.5
Posterior probability function
1
2
3
4
5
6
7
8
9
10
Number of AR lags 'p'
Posterior probability function
0.0
0.1
0.2
0.3
0.4
Figure 2.4.: Break design 1: trajectory of a stationary AR(1) with four breaks in level and trend (dashed
lines for true break dates) together with the posterior distributions of the lag order, the number
of breaks and the break dates ki given the MAP estimate of m.
chosen correctly with p = 1 and m = 4. The corresponding four posterior distributions
of the break dates are all concentrated around a single mass point which coincides with
23

0
20
40
60
80
100
0
50
100
150
200
Time
Probability
Time
Probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distributions of ki
0
1
2
3
4
5
6
7
8
9
Number of breaks 'm'
0.0
0.1
0.2
0.3
0.4
Posterior probability function
1
2
3
4
5
6
7
8
9
10
Number of AR lags 'p'
Posterior probability function
0.0
0.1
0.2
0.3
0.4
Figure 2.5.: Break design 2: trajectory of a Random Walk with two drift breaks (dashed lines for true
break dates) together with the posterior distributions of the lag order, the number of breaks
and the break dates ki given the MAP estimate of m.
the respective true break date.14 In design 2 the DGP is speciÔ¨Åed to give an impression
of how the model selection procedure performs in the context of nonstationary processes
with structural breaks. Therefore a Random Walk with two drift breaks is simulated for
T = 200. Even in this case the two break points can be identiÔ¨Åed relatively precisely,
although the posterior distribution of k1 shows more variation compared to that of k2. The
distributions of m and p have the expected modes at the parameter values of the DGP,
i.e. m = 2 and p = 1. The third series allows the investigation of more general ARMA
processes. Figure 2.6 depicts the selection results when the data are generated by an
ARMA(2,1)-process with one level break. The selection of the AR order and the number
of structural breaks are not appreciably inÔ¨Çuenced by the addition of extra noise due to an
MA(1)-component in this case. In summary, the results of the MC experiments indicate
favorable performance of the proposed MCMC approach in Ô¨Ånding the true parameter
values of the DGP. Before turning now to the real data analysis the chosen Bayesian unit
14The lack of variation in the posterior distributions of the ki‚Äòs are due to the choice of the scale parameter
in the Inverse-Gamma prior for œÉ2 with b = 0.001 (see equation (2.8b)).
24

‚àí4
‚àí3
‚àí2
‚àí1
0
0
50
100
150
200
Time
Probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distributions of ki
0
1
2
3
4
5
6
7
8
9
Number of breaks 'm'
0.0
0.1
0.2
0.3
0.4
0.5
0.6
Posterior probability function
1
2
3
4
5
6
7
8
9
10
Number of AR lags 'p'
Posterior probability function
0.0
0.1
0.2
0.3
0.4
0.5
Figure 2.6.: Break design 3: trajectory of a stationary ARMA(2,1) with one level break (dashed line
for true break date) together with the posterior distributions of the lag order, the number of
breaks and the break dates ki given the MAP estimate of m.
root testing approach is introduced.
2.5. Testing the unit root null hypothesis
The Bayesian key device for unit root testing, using the structural breaks model in (2.5),
is the likelihood function f (y|Œ∏,Œ≥,kŒ≥) with Œ∏ ‚ààŒò = [0;1]. Let the parameter set Œò be
partitioned into Œò0 = {1} and Œò1 = Œò\{1}. For testing the sharp null hypothesis of a unit
root H0 : Œ∏ ‚ààŒò0 against the alternative of a covariance stationary process H1 : Œ∏ ‚ààŒò1
it is natural to compare the corresponding posterior mass of these two disjoint sets and
to reject the null if P(Œò1|y) > 0.5, see Robert (2007), p.225 for details.15 The above
pair of hypotheses is also the starting point for many other authors to test for a unit root,
see Maddala and Kim (1998) and Bauwens et al. (1999) for overviews concerning other
15Note that in classical terminology 1‚àíP(Œò0|y) plays the role of a test statistic, as a function of the sample.
25

Bayesian approaches to unit root testing. In order to give the unit root null more ‚Äôweight‚Äô,
a mixed prior density as in Kadane et al. (1996) is used that assigns a positive prior prob-
ability œÄ0 ‚â°f (Œ∏|H0) > 0 to the singleton Œò0 and uses a continuous density f (Œ∏|H1) with
weight 1 ‚àíœÄ0 elsewhere, cf. Berger and Delampady (1987), Berger and Sellke (1987)
for details. Note that by assuming a continuous prior on Œò = Œò0
SŒò1 the simple unit
root hypothesis would always be rejected, since Œò0 has zero Lebesgue measure.16 Given
values for Œ≥ and kŒ≥ the posterior probability of H0 can be expressed as a function of the
conditional Bayes factor (BF) in favor of the null hypothesis.17 The posterior probability
of Œ∏0 = 1 is then obtained analogously to the unconditional case (see Berger and Delam-
pady (1987), also DeGroot (1970), p.238) as
P(H0|Œ≥,kŒ≥;y) =
f (y|Œ∏0,Œ≥,kŒ≥) ¬∑œÄ0
œÄ0 ¬∑ f (y|Œ∏0,Œ≥,kŒ≥) + (1‚àíœÄ0)¬∑ f (y|H1,Œ≥,kŒ≥)
(2.20a)
=

1+ 1‚àíœÄ0
œÄ0
¬∑ 1
BF
‚àí1
(2.20b)
with BF = f (y|Œ∏0,Œ≥,kŒ≥)
f (y|H1,Œ≥,kŒ≥)
(2.20c)
and f (y|H1,Œ≥,kŒ≥) =
Z
Œò1
f (y|Œ∏,Œ≥,kŒ≥)¬∑ f (Œ∏|H1) ¬∑dŒ∏
(2.20d)
where the posterior probability of the null, given in (2.20), is abbreviated by P0 henceforth.
To utilize the results from the above sections in order to derive the likelihood function
of Œ∏|(Œ≥,kŒ≥) simply deÔ¨Åne B‚àíŒ∏ = BŒ≥\{Œ∏} to be the vector of regression coefÔ¨Åcients
without the long run coefÔ¨Åcient Œ∏ and y(Œ∏) ‚â°y ‚àíŒ∏y‚àí1 a linear function in Œ∏ with
y = (yp+1,...,yT)‚Ä≤ and y‚àí1 = (yp,...,yT‚àí1)‚Ä≤. Then the conditional likelihood of Œ∏ given
Œ≥ and kŒ≥ is obtained by integrating out all other parameters B‚àíŒ∏ and œÉ2 from (2.7) and
therefore the derivation of f (y(Œ∏)|Œ≥,kŒ≥) is the same as for f (y|Œ≥,kŒ≥). Looking at the
16As point hypotheses can be perceived as approximations to interval hypotheses, the probability œÄ0 can be
thought of as the mass that would have been assigned to the (more realistic) interval hypothesis H0 : Œ∏ ‚àà
[Œ∏0 ‚àíc, Œ∏0 + c] , c > 0, see Berger (1980), p.150, also Robert (2007), p.230.
17Strictly speaking, this is not a real Bayes factor, because the involved likelihood expressions are not the
marginal likelihoods as in the deÔ¨Ånition of a Bayes factor (see Kass and Raftery (1995)), since they are
still conditional on Œ≥ and kŒ≥, i.e. a particular candidate model.
26

integrand of (2.20d) the Ô¨Årst of these two densities is then given by
f (y|Œ∏,Œ≥,kŒ≥) ‚àù|S|‚àí1
2 ¬∑

b+ (y‚àíŒ∏y‚àí1)‚Ä≤ ¬∑S‚àí1 ¬∑(y‚àíŒ∏y‚àí1)
	‚àí(T‚àíp+a)/2
(2.21a)
with S ‚â°

IT‚àíp + XŒ≥M‚àí1X‚Ä≤
Œ≥

(2.21b)
As a prior density f (Œ∏), with Œ∏ ‚ààŒò, for the computation of (2.20d) I use three different
distributions, namely a conjugate normal prior, as for example advocated by Uhlig (1994),
a simple Ô¨Çat prior as a benchmark and the approximate Jeffreys prior as proposed by
Phillips (1991b), see also Zivot and Phillips (1994), which has the form
fJ(Œ∏;T) =
Ô£±
Ô£¥
Ô£≤
Ô£¥
Ô£≥

1
1‚àíŒ∏2
h
T ‚àí1‚àíŒ∏2T
1‚àíŒ∏2
i1/2
, for Œ∏ Ã∏= 1

T(T‚àí1)
2
1/2
, for Œ∏ = 1,
(2.22)
Figure 2.7 depicts the shapes of these priors, which allocate relatively similar weight over
the stationary region up to, say Œ∏ < 0.8. To check the sensitivity of the inferential results
0.2
0.4
0.6
0.8
1.0
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
q
density
Flat
N(1, T)
Jeffreys
Figure 2.7.: Prior distributions for the long run coefÔ¨Åcient Œ∏ for T = 200.
concerning the above prior speciÔ¨Åcations I compute the corresponding risk functions un-
der squared error loss using the no-break model in (2.4), i.e. with Œ≥ = (p,0)‚Ä≤ and kŒ≥ = 0‚Ä≤:
27

R(Œ¥(y),Œ∏0) =
Z
RT‚àíp[Œ¥(y)‚àíŒ∏0]2 ¬∑ f (y|Œ∏0,Œ≥,kŒ≥) ¬∑dy
(2.23a)
‚âÉ1
N
N
‚àë
i=1
[Œ¥(yi) ‚àíŒ∏0]2
(2.23b)
with Œ¥(yi) ‚â°E(Œ∏|Œ≥,kŒ≥; yi),
(2.23c)
where the vector yi , i = 1...N denotes a draw from f (y|Œ∏0,Œ≥,kŒ≥) of dimension T ‚àíp.
The risk functions are computed as in Bauwens et al. (1999), chapter 6, for the no-break
model (2.4). Here I deÔ¨Åne a grid of values for Œ∏ ‚àà[0.1;1.1] and then generate a trajectory
{yt}T=200
t=1
from yt = 0.5+Œ∏yt‚àí1 +0.5Œµt‚àí1 +Œµt, Œµt ‚àºIN(0,1). Next the conditional pos-
terior expectation18 of Œ∏ for the ADF-model in (2.4) without a time trend is computed,
given a lag order of p = ‚åäT
1
3‚åã, with ‚åäx‚åãthe largest integer not greater than x. Repeating
this for i = 1...1500 and then taking the sample average with respect to the N squared
loss functions in the approximation of (2.23) Ô¨Ånally yields the frequentistic risk of the
Bayes estimator (2.23c) under the respective prior.19 Figure 2.8 shows the risk functions
under the three considered prior distributions. As most of the test decisions in this chapter
are based upon the normal prior, a sensitivity analysis of the point estimation is conducted
using different location/scale speciÔ¨Åcations. To compare the impact of the location param-
eter on the point estimation of Œ∏, I choose a normal prior centered over a Random Walk
and also a normal prior with mean ¬µŒ∏ = 0, which is thus not informative with respect to
the long run impact coefÔ¨Åcient Œ∏. The prior information gets more accentuated when rep-
resented by densities of moderate dispersion, like for example œÉ2
Œ∏ = 0.04, and becomes
less inÔ¨Çuential when considering Ô¨Çat densities using for example œÉ2
Œ∏ = 40. Consequently
the point estimation under the N(1,0.2) prior performs best when approaching the null
constraint Œ∏ = 1. However, for short time series, e.g. T < 50,20 this can be problematic
since the prior weighting then dominates the likelihood and so the posterior will be shifted
18The one-dimensional integration for the posterior expectation in (2.23c) is computed numerically via
Simpson‚Äôs rule on 31 points over a grid of values Œ∏ ‚àà[0.1;1.1] as in Bauwens et al. (1999), p.178. For
the computations all priors are normalized to integrate to one, i.e. to be proper densities.
19Note that the posterior Bayes estimator (2.23c) minimizes the Bayes risk, or equivalently the posterior
expected loss, under a squared loss function for a given prior.
20This situation is frequently encountered when working with annual data, for example most of the OECD
series used in the empirical analysis (see section 2.7) have lengths between T = 25 and T = 45.
28

0.2
0.4
0.6
0.8
0.02
0.04
0.06
0.08
q
R(d, q)
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
Flat
Jeffreys
N(1, 0.2)
N(1, 40)
N(0, 40)
Figure 2.8.: Risk functions for Œ¥ under different prior distributions.
towards a Random Walk. For this reason I use a data-dependent N(1,
‚àö
T) prior, which is
rather Ô¨Çat and hence does not put so much weight on the unit root constraint.
2.6. Power comparison of unit root testing
procedures
To compare the above Bayesian testing procedure under various prior distributions with
some commonly used classical unit root tests, I compute the power functions Œ≤T(Œ∏) for
the Augmented Dickey Fuller (ADF)-test (Dickey and Fuller (1979)), the Phillips and
Perron (1988) (PP)-test and also the Elliot et al. (1996) (ERS)-test.21 The rejection prob-
abilities of the null hypothesis under a speciÔ¨Åc model are approximated by the average
number of rejections, i.e.
P(‚ÄôReject H0‚Äô|Œ∏0,Œ≥,kŒ≥,y) ‚âà1
N
N
‚àë
i=1
1{BF<1}
(2.24)
21These are readily available in the R package urca, see www.r-project.org.
29

where 1{.} is the indicator function and BF denotes the (model-speciÔ¨Åc) Bayes factor in
favor of H0 as given in (2.20c).22
For the computation I simulate ARMA(1,1) trajectories for different sample sizes accord-
ing to yt = Œ∏yt‚àí1 + 0.55Œµt‚àí1 + Œµt, Œµt ‚àºIN(0,1) over a grid Œ∏ ‚àà[0;1.1] of 100 points
and for each of these parameter values I calculate the posterior probability P0 using the
above priors. Further the above three classical unit root tests are applied for a nominal
signiÔ¨Åcance level of 5%. This is repeated M = 5000 times and at each run the rejections
are counted to approximate the above probabilities in (2.24). As can be seen from Ô¨Ågure
2.9(a) the PP test is clearly dominated by the two other tests. On the other hand, the
ADF test is strictly dominated by the Bayes test (regardless of the prior) as Ô¨Ågure 2.9(b)
illustrates. The addressed dominance of the Bayes test gets more accentuated when the
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
q
Rejection probability
llllll
l llllll
l l l l l l l lll
l l l l l l l l l l l ll
l l
l l
l
l
l
l
l l
l
l
l
l
l
l
l
l
l
l
l
l
l
l l
l l l l ll
l l l l l l l l l l l llll
l
ADF‚àíTest
PP‚àíTest
ERS‚àíTest
(H0)
(a) Classical
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
q
Rejection probability
ADF‚àíTest
BF (Conjugate)
BF (Jeffreys)
(b) Classical vs. Bayesian
Figure 2.9.: Power functions of classical and Bayesian unit root tests without structural breaks.
sample size T increases.23 This can be seen from the results of table 2.1, where the pos-
terior probability of a unit root is shown for different sample sizes T and Œ∏-values in the
DGP. The results suggest that the Bayes test outlined above forms a consistent test in the
sense that the power function Œ≤T(Œ∏) ‚Üí1 as T ‚Üí‚àû, for Œ∏ ‚ààŒò1, which is equivalent to
P0 ‚Üí0 as T ‚Üí‚àû, for Œ∏ ‚ààŒò1.
22An equivalent decision rule in terms of the null posterior probability P0 would be to reject the null hy-
pothesis, if 1‚àíP0 > 0.5. Note that the null probability P0 in (2.20) is an increasing function of the Bayes
factor.
23The results are obtained using the conjugate normal distribution. For the other priors similar results are
produced.
30

Table 2.1.: Posterior probability of a unit root as a function of T and Œ∏
T
Œ∏ = 0.75
Œ∏ = 0.8
Œ∏ = 0.85
Œ∏ = 0.9
Œ∏ = 0.95
Œ∏ = 1.0
20
0.2575
0.3087
0.3443
0.4082
0.4881
0.6521
50
0.1686
0.2403
0.3109
0.4243
0.6034
0.8917
100
0.0722
0.1358
0.2102
0.3645
0.6038
0.9898
150
0.0240
0.0496
0.1382
0.3115
0.6074
0.9998
200
0.0065
0.0194
0.0709
0.2219
0.5472
0.9999
250
0.0016
0.0072
0.0272
0.1416
0.5278
1.0000
Overall the normal prior provides slightly better results than the (‚Äôobjective‚Äô) Jeffreys prior
of Phillips (1991b), see Ô¨Ågure 2.9(b), with respect to power and also with respect to fre-
quentistic risk when taking the posterior mean as a point estimator. Looking at the power
functions there seems no evidence against using the Jeffreys prior for testing, although
experience shows that this prior is likely to produce bimodalities when approaching the
nonstationarity region. To draw my conclusions the conjugate normal prior is used in the
following empirical section and the Jeffreys prior is computed for reasons of comparison.
2.7. Empirical application using OECD data
Next the above two-stage procedure is utilized to test for possible unemployment persis-
tence among 17 OECD countries. The data set consists of annual unemployment rates
observed within the time interval from 1960 to 2010.24 The high level of unemploy-
ment in countries of the European union compared to other countries of the OECD has
been an object of investigation for many years. In the economic literature in principal
there are two theoretical explanations for this phenomenon: the non-accelerating inÔ¨Çation
rate of unemployment (NAIRU) and unemployment hysteresis. The former theory im-
plies the unemployment rate to follow a trend stationary process, i.e. after an exogenous
shock the rate will recover to its long run equilibrium. By contrast, hysteresis implies
that temporary shocks have permanent effects on the level of unemployment and thus the
24The data was extracted from OECD online sources. The reported unemployment rates were computed as
the ratio of the number of unemployed persons and the number of persons in the labour force, where the
latter is deÔ¨Åned as the sum of employed and unemployed persons.
31

underlying stochastic process has a unit root. This ‚Äôunit root hysteresis‚Äô deÔ¨Ånition is the
most common in the literature on the stochastic properties of unemployment rates (see
also Blanchard and Summers (1986)). Persistence can now be regarded as a special case
of the NAIRU concept in the sense that the unemployment rate in fact follows a station-
ary process but also has a stochastic component that is nearly integrated of order one,
for example with the sum of autoregressive coefÔ¨Åcients being very close to one (‚ÄôQuasi
Random Walk‚Äô). Structuralist theories of unemployment as described in Phelps (1994)
consider the natural rate of unemployment, as implied by the NAIRU, to be a function of
different macroeconomic variables like the oil price, stock prices or the world real rate of
interest (see Layard et al. (1991)). If the unemployment rate reaches its equilibrium path
after a shock but this path is now higher (lower) than before, then the unemployment rates
can be regarded as being generated by a trend stationary process with breaks. To test for
possible unit root hysteresis in the OECD unemployment rates the corresponding poste-
rior probabilities P0, for œÄ0 = 0.5 are computed (see expression (2.20b)). In addition, the
Bayesian tail probabilities P(Œ∏ ‚â•0.975| bŒ≥, bk, y) to test for stochastic nonstationarity, as
in Phillips (1991b), Summers (2004), are calculated.
Before proceeding with the analysis of the OECD unemployment rates one general note
concerning the unit root testing of limited variables is in order. Because unemployment
rates are bounded between zero and one they cannot be generated by a Random Walk pro-
cess, because such a process would (at least theoretically) cross every boundary almost
surely as the sample size increases. Since under the unit root hypothesis the data are pos-
tulated to be generated by a Random Walk, which is a special case of an I(1) process,25
namely linear with (symmetric and nontruncated) normal innovations, the above test re-
gression would be inappropriate to describe the DGP (see also Koop and Potter (1999)).
Cavaliere (2005a) points out that this neglect makes the interpretation of unit root tests
controversial. He argues that given the researcher has rejected the I(1) hypothesis, it is not
clear if this rejection is due to the presence of I(d) dynamics, |d| < 1, or due to the existing
range constraints that have not been considered. In the present context of unemployment
hysteresis this question is important, especially since the Random Walk hypothesis is
usually rejected when applied to limited time series, e.g. unemployment rates or nominal
interest rates, while it is not rejected in the majority of empirical applications to unlimited
time series (see Cavaliere (2005a) for details). There are now two obvious ways to handle
25Here I(d) means integrated of order d, see Banerjee et al. (1993).
32

this problem, namely either to change the test regression (2.5) in order to be able to han-
dle truncated distributions or to make a change of variables that transforms the (double)
truncated distribution of yt to a nontruncated distribution f (y‚ãÜ
t ) ¬∑ 1R(y‚ãÜ
t ). Here I choose
the latter route. Following Wallis (1987), the unemployment rates yt are transformed by
means of the logistic transformation f : yt 7‚Üíy‚ãÜ
t = ln( yt
1‚àíyt ), i.e. [0;1] 7‚ÜíR.
Then the
hybrid sampler for the model in (2.5) without a time trend26 is run to get estimates for
the number of structural breaks, the number of lags and the corresponding break dates.
As the sampler operates on both the parameter and the model space we get a sample
{Œ≥l, l = 1,...,L} for the model indicators, where Œ≥ denotes a certain (p,m)-combination
in the Œì = N[1; pmax] √ó N[0; mmax] space. Thus the posterior probabilities f (Œ≥|y) can be
estimated by (cf. Lopes (2006), p.3):
bf (Œ≥|y) = 1
L
L
‚àë
l=1
1{Œ≥=Œ≥l}
(2.25)
In order to account for any uncertainty induced through the model selection step the
model probabilities in (2.25) are used as weights to compute a model average bŒ∏M over
all considered submodels M = {M1,...,MK}. Utilizing the Bayes estimates bŒ∏ under the
different priors and also the model averaged estimate bŒ∏M one can compute the half life
HL ‚â°ln(0.5)/ln(bŒ∏) as a measure of persistence (or convergence) for each of the OECD
series. In the present context, the half life means the expected number of years for an un-
employment shock to decay by 50%. To have a classical benchmark I apply the original
ADF test without a break and calculate the half life using the resulting point estimate of
Œ∏. Due to the relatively short series and also for reasons of comparison I allow for a max-
imum number of Ô¨Åve level breaks and also for a maximum number of Ô¨Åve lags. As can
be seen from the results shown in table A.1 (see appendix A) for each of the 17 OECD
countries at least two structural breaks are identiÔ¨Åed. In table A.2 the posterior proba-
bilities of the number of lags together with the selected lags according to the AIC and
BIC information criteria are reported.27 The results indicate that for the OECD data one
and two autoregressive lags have the highest posterior probabilities. With regard to the
26This speciÔ¨Åcation is chosen mainly for reasons of comparison with the empirical results of other authors,
in particular the results of Papell et al. (2000) and Summers (2004), where the latter author chooses a
Bayesian frame of reference.
27For the models with break(s) these were calculated using the respective posterior estimates of break points
from the MCMC output.
33

lag selection, BIC and an inspection of the sample partial autocorrelation function yield
identical values in about 71% and 77% of all considered cases compared to the MCMC
approach.28 For the number of breaks there is an accordance with BIC in about 41% of all
cases (see table A.1). Next the Bayesian results for the determination of the break num-
bers and also the break dates are compared with those obtained from an application of the
methods described in Bai and Perron (2003).29 A comparison of table A.3 with table A.4
reveals, that for about 41% of all countries there is an accordance of the selected number
of breaks and that the corresponding change points are comparable in location for most
of the countries. Summing up, the Bayesian model selection approach suggests slightly
more parsimonious, i.e. less complex models than its classical competitors, although the
results of the lag order selection are very similar.
Note that the data also cover events of possible structural changes like the two oil crises
of 1973 and 1979 as well as more recent events like the (Ô¨Årst) Ô¨Ånancial crisis of 2008.
From A.3 it can be observed that the years 1973 and 1979 are identiÔ¨Åed as shocks to
the national labor markets at least for some countries in the OECD. The impacts of these
shocks appear with a lag of one or two years so that the posterior distributions of the
break dates of Australia, Canada, Germany, Netherlands and the US have modes at the
dates 1974, 1980 and 1981. The year(s) of the Ô¨Ånancial crisis 2008/9 are identiÔ¨Åed as
break dates mainly for the European countries, viz. for Denmark, Greece, Ireland, Spain,
Sweden and for the UK. Among the Non-European countries only Japan and the US
show level shifts for the year 2008. One obvious feature in the results is that for some
of the series there is much uncertainty concerning the identiÔ¨Åcation of the break points.
Looking for example at Germany (see Ô¨Ågure D.7 in appendix D) the sampling results
suggest two breaks, one with mode at 1980, which can be associated with the second
oil crisis of 1979 and the other at 1990, i.e. the year of the German reuniÔ¨Åcation. But
there are also two almost equally likely break dates, namely the years 1992 and 1995,
which suggests multimodality of the posterior distribution of the second change point.
Furthermore there is a trade off between choosing a third break, which could then result
in three unimodal posterior distributions and the use of just two breaks but with some
uncertainty in determining the right timing. This feature can also be recognized when
28For AIC the matches are much lower (30%).
29These are readily available in the R package strucchange. To provide best possible comparability with
the Bayesian results the minimum fraction of observations between two adjacent breaks is set equal to the
smallest possible value depending on the sample size, mostly h = 0.1, see Bai and Perron (2003), p.7.
34

looking at the joint posterior mass function of the number of breaks and the number of
lags, depicted in Ô¨Ågure D.18. When undertaking a ‚ÄôHelicopter tour‚Äô around the posterior
surface it can be observed, that a second mode of this model posterior distribution is at
(p,m) = (1,4), see Ô¨Ågure D.19.30 Having determined the most likely model speciÔ¨Åcation
the Bayesian approach of section 2.5 is used to test for a unit root. Besides the posterior
probabilities of a unit root, also the classical p-values of the ADF test are calculated along
with their Bayesian analogues, the posterior tail probabilities of the nonstationary region,
i.e. of Œ∏ ‚â•1. For the latter I use a N(1,
‚àö
T) prior and the approximate Jeffreys prior
of Phillips (1991b). Table A.6 shows the results of the unit root tests. From there it can
be observed that the only country, which is likely to exhibit unit root behavior is Greece
with posterior probabilities of 84% and 93%, depending on the prior speciÔ¨Åcation. Note
that one arrives at the same conclusion when consulting the Bayesian ‚Äôp-values‚Äô in order
to test the hypothesis of nonstationarity, which are both larger than the usual signiÔ¨Åcance
levels. When looking at the lower posterior density plot of Greece in Ô¨Ågure D.8 the impact
of the Jeffreys prior on the posterior shape can be seen, namely that it puts more weight
on the explosive region of Œ∏, compared to a normal prior. In contrast to the classical
ADF test, the null is rejected for almost all of the analyzed countries using the Bayes
test.31 Comparing the posterior means under a normal prior with the corresponding model
averaged point estimates (see table A.5) it can be recognized that for most of the countries
both estimates are quite close to each other. This fact is also reÔ¨Çected in the corresponding
risk functions presented in section 2.5. Interestingly from the model averaged half lives
it can be observed, that when controlling for possible uncertainty induced through the
model selection step, Greece does not have the longest half life with about three years, as
would be expected given the unit root results. In fact Spain and Japan both have longer
half lives with 5.42 and 5.32 years, respectively. The overall OECD country averages are
(standard deviations in brackets): HLNorm = 3.11 (3.64) years, HLM = 2.04 (1.47) years
and HLADF = 4.73 (2.72) years.
In sum, the empirical results neither suggest unit root hysteresis nor pronounced persis-
tence of the annual unemployment rates for the majority of the OECD countries. The em-
pirical Ô¨Åndings are also in accordance with those of other authors, as for example Papell
30The Ô¨Ågures were constructed as in Klein (2008).
31This can be attributed to the lack of power of the ADF test in small samples and that it does not control
for structural breaks.
35

et al. (2000) and Summers (2004), who Ô¨Ånd no overall evidence of hysteresis or marked
persistence in the unemployment rates of these countries. In the light of economic the-
ory this supports the perception that unemployment rates are best described as transitory
Ô¨Çuctuations around an equilibrium path. Thus the results support structural theories of
unemployment which imply that unemployment rates follow a (trend)stationary process
with possible shifting behavior due to changes in structural factors.
2.8. Summary and conclusion
Most of the existing approaches for model selection in the class of ARMA models with
multiple structural breaks are based on information criteria. However these can be difÔ¨Åcult
to implement when the number of autoregressive lags, the number of breaks, and the as-
sociated break dates are unknown and have to be estimated simultaneously. Furthermore,
most of the classical approaches do not capture the possible uncertainty induced through
a model selection step. In contrast, the presented sampling based method provides the
researcher not only with point estimates for the unknown model indicators but with the
whole joint posterior probability distribution of these quantities. Using this distribution
model averaged point estimates of all quantities of interest can be computed. With the
proposed Bayesian approach it is possible to select the most likely model speciÔ¨Åcation
for unit root testing in the case of multiple breaks. This is accomplished by using a mixed
MCMC sampling strategy, which enables to switch between parameter spaces of different
dimensions. The presented simulation results indicate that the sampler performs well in
Ô¨Ånding the true parameter values of the underlying data generating process. In a next step
the posterior probability of a unit root is computed using different prior distributions to
construct a Bayesian unit root test. The Bayes test is compared with three classical unit
root tests in terms of test power and shows clear superiority especially in small samples.
In an empirical application, the unemployment rates of 17 OECD countries are analyzed
with respect to possible unemployment hysteresis. The results indicate that the only coun-
try with high posterior probabilities for unit root hysteresis is Greece, whereas Japan and
Spain show slightly increased levels of persistence. However, by applying model av-
eraging techniques, it is found, that although Greece still shows an increased level of
persistence after a shock compared to the OECD average, Spain and Japan both exhibit
36

higher levels of persistence than Greece. Overall the empirical analysis suggests that the
majority of the OECD unemployment rates are likely to follow a trend stationary process
with possible level shifts, which is also implied by structuralist theories of employment.
Next attention will be drawn to higher frequency data, namely to quarterly and monthly
time series data. In contrast to the aggregate case with annual data of the last chapter here
different forms of stochastic trends can appear, where each of these forms is associated
with a speciÔ¨Åc frequency of the power spectrum (cf. BloomÔ¨Åeld (2000), chapter 9). Be-
fore introducing some Bayesian approaches to test for a periodic and a seasonal unit root
in chapter 4, Ô¨Årst some general characteristics related to seasonal time series are reviewed
together with two selected frequentist unit root testing procedures as a preliminary.
37

Analysis of seasonal time series
38

Concepts related to seasonal time
series
3.1. Stochastic seasonality and seasonal
integration
Consider a univariate time series yt, t = 1...T, for s = 1...S seasons, which is observed
during N = ‚åäT/S‚åãyears, where ‚åäx‚åãdenotes the greatest integer part of x. Let the obser-
vations be generated by an autoregressive process of order p (‚ÄôAR(p)‚Äô):
œÜp(L)¬∑yt = ¬µ + Œµt
(3.1)
where ¬µ is an intercept term and œÜp(L) = 1‚àíœÜ1L‚àí...‚àíœÜpLp is a polynomial in the lag
operator of order p, and the Œµt are generated by a white noise process, i.e. are uncorrelated
with zero mean and constant variance œÉ2 (cf. Spanos (1999), p.443), henceforth Œµt ‚àº
WN(0,œÉ2).
If the above polynomial œÜp(L) can be factorized as œÜp(L) = œÜ‚ãÜ
p‚àíS(L)¬∑(1‚àíLS), the series
yt is said to be seasonally integrated (see Ghysels and Osborn (2001), p.43). For example,
in the case of quarterly data, i.e. S = 4, the Ô¨Ålter (1 ‚àíL4) can be factorized as (1 ‚àíL) ¬∑
(1 + L) ¬∑ (1 + i) ¬∑ (1 ‚àíi), with i ‚â°‚àö‚àí1 the imaginary part of a complex number. That
is, the process yt has four unit roots, which are illustrated in Ô¨Ågure 3.1 (cf. Hylleberg
et al. (1990)), and are given by a real-valued nonseasonal unit root and three seasonal unit
roots, viz. one real-valued and a conjugate pair of complex-valued roots.
To get the idea of a seasonal unit root consider the following seasonal AR process of order
39

‚àí1.0
‚àí0.5
0.0
0.5
1.0
‚àí1.0
‚àí0.5
0.0
0.5
1.0
Re
Im
z = cos(w) + i sin(w)
l
R = 1
cos(w)
sin(w)
w
z = (1, w)
z3 = (1, p 2)
z4 = (1, -p 2)
z2 = (1, p)
z1 = (1, 0)
l
l
l
l
l
Seasonal unit roots
Figure 3.1.: Complex unit circle with seasonal unit roots for S = 4.
one for S seasons (‚ÄôSAR(1)‚Äô):
yt = œÜyt‚àíS + Œµt ,
Œµt ‚àºWN(0,œÉ2)
(3.2)
with characteristic polynomial œÜS(z) ‚â°1‚àíœÜzS , z ‚ààC.
A study of the properties of a stochastic process can be conducted on the frequency do-
main by analyzing its spectral density (or power spectrum), cf. BloomÔ¨Åeld (2000), Priest-
ley (2004). Therefore the spectral density of the process (3.2) is considered next in more
detail. Assuming weak stationarity of the SAR(1) process in (3.2) the corresponding
MA(‚àû) representation is given by
yt = œà(z) ¬∑Œµt
, where œà(z) ‚â°

1‚àíœÜzS‚àí1
, z ‚ààC
(3.3)
Recall that any complex number can be expressed as z = R ¬∑ [cos(œâ) + i ¬∑ sin(œâ)] =
R ¬∑ exp(iœâ), with angle œâ ‚àà[0,œÄ] in radian and R ‚â°|z| the modulus of z. Furthermore
the autocovariance-generating function of this stochastic process is given by gy(z) = œÉ2
Œµ ¬∑
œà(z) ¬∑ œà(z‚àí1) and is linked to the spectral density via sy(œâ) = gy(z)/2œÄ (see Hamilton
40

(1994), chapter 6 for details), which, in the general case of S seasons (assuming R = 1),
is given by
sy(œâ) = œÉ2
Œµ
2œÄ ¬∑

1‚àíœÜzS‚àí1
¬∑

1‚àíœÜz‚àíS‚àí1
(3.4a)
= œÉ2
Œµ
2œÄ ¬∑(1‚àíœÜ ¬∑exp(S¬∑iœâ))‚àí1 ¬∑(1‚àíœÜ ¬∑exp(‚àíS¬∑iœâ))‚àí1
(3.4b)
= œÉ2
Œµ
2œÄ ¬∑|1‚àíœÜ ¬∑exp(S¬∑iœâ)|‚àí2 = œÉ2
Œµ
2œÄ ¬∑
 1+ œÜ2 ‚àí2œÜ ¬∑cos(S¬∑œâ)
‚àí1
(3.4c)
utilizing the fact that |œà (z)|2 = œà (z) ¬∑œà (z), with z ‚â°exp(‚àíiœâ) the complex conjugate
number of z (cf. Hamilton (1994), Appendix A.2).
Next the spectral densities of four autoregressive processes of the form (3.2) are com-
pared. In Ô¨Ågure 3.2 the power spectrum of a stationary nonseasonal (or annual) AR(1)
process, i.e. with S = 1 and |œÜ| ‚â™1 (see upper left panel), a nonseasonal integrated
AR(1) process (‚ÄôARI(1)‚Äô), i.e. with S = 1 and œÜ = 1 (see upper right panel), a station-
ary quarterly SAR(1), i.e. with S = 4 and |œÜ| ‚â™1 (see lower left panel), whose spectral
density is given in (3.4), and Ô¨Ånally the power spectrum of a seasonally integrated AR(1)
process (‚ÄôSI(1)‚Äô), with S = 4 and œÜ = 1 (see lower right panel), are depicted.1
What can be observed from the upper and lower right spectra in Ô¨Ågure 3.2, is that in case
of an ARI(1) and SI(1) process, i.e. a (non)seasonal Random Walk, the spectrum gets
more concentrated around the frequencies associated with the four unit roots of 1‚àíz4 =
(1 ‚àíz) ¬∑ (1 + z) ¬∑ (1 + z2). These are shown in Ô¨Ågure 3.1 and are given by z1 = 1 (=
cos(0) + i ¬∑ sin(0)), z2 = ‚àí1 (= cos(œÄ) + i ¬∑ sin(œÄ)) and the complex conjugate pair
z3/4 = ¬±i (= cos(¬±œÄ
2 ) + i ¬∑ sin(¬±œÄ
2 )). Here z1 is the nonseasonal unit root, which is
associated with the zero spectral frequency and is denoted by z1 = (R = 1,œâ = 0) in
Ô¨Ågure 3.1. z2 is the real semiannual unit root, associated with frequency œÄ, implying that
in the frequency domain yt has a component that gives rise to a half-cycle every period,
or a full cycle every two periods. Last the complex pair z3/4 are the seasonal unit roots,
which are associated with the œâ = ¬±œÄ
2 spectral frequencies, that is the associated unit
root process contains a full cycle every four periods, see Ô¨Ågure 3.1.2
1The SI(1) process is also called a seasonal Random Walk, see Ghysels and Osborn (2001).
2However both cycles are indistinguishable in the frequency domain, that is they are aliases, because they
both correspond to four-period cycles, see Ghysels and Osborn (2001), p.22, BloomÔ¨Åeld (2000), p.21.
41

0 : 2p
Spectral density AR(1)
0.12
0.16
0.20
0.24
0
p 3
p
4p 3
2p
0 : p
Spectral density ARI(1)
0
5
10
15
0
p 6
p 2
5p 6
p
0 : p
Spectral density SAR(1)
0.12
0.16
0.20
0.24
0
p 4
p 2
3p 4
p
0 : p
Spectral density SI(1)
0
5
10
15
0
p 4
p 2
3p 4
p
Figure 3.2.: Theoretical spectral densities of quarterly (non)stationary (S)AR(1) processes.
Analogously in the monthly case, the characteristic polynomial 1‚àíz12 can be factorized
according to one real nonseasonal unit root, and 11 seasonal unit roots, viz. one real
and Ô¨Åve complex conjugate pairs of unit roots (see Beaulieu and Miron (1993) for de-
tails). Seasonal unit roots correspond with stochastic trends at the seasonal frequencies
and therefore allow for strongly changing seasonality. In this respect, it should be noticed
that a seasonal Random Walk implies S separate nonseasonal (annual) Random Walk pro-
cesses, one relating to each season (see Dickey et al. (1984)). To see this, note that the
above SAR(1) process could alternatively be expressed as
ys,n = œÜys,n‚àí1 + Œµs,n , where Œµt = Œµs,n
(3.5)
with s = 1...S seasons and n = 1...N years (see Pagano (1978), Tiao and Grupe (1980),
Ghysels et al. (2006)).
As noted by Ghysels and Osborn (2001), p.26, this form is useful in emphasizing that the
autoregressive relationship for ys,n in season s relates to the same season in the preceding
year. Solving the stochastic difference equation in (3.5) by substituting for lagged y on
42

the right-hand side, assuming ys,0 = 0, ‚àÄs, and setting œÜ = 1, yields
ys,n =
n‚àí1
‚àë
j=0
Œµs,n‚àíj
(3.6)
Hence each process ys,n ,s = 1...S, is driven only by shocks relating to the speciÔ¨Åc sea-
son s, see Ghysels and Osborn (2001) for details. The implication of S separate annual
Random Walks has been the basis for a large amount of testing procedures for seasonal
unit roots starting with the work of Dickey et al. (1984), Osborn et al. (1988), Hylleberg
et al. (1990), Franses (1991), inter alia. See Ghysels and Osborn (2001) for a survey of
the related literature.
3.2. Periodic processes and periodic integration
One potential drawback of time series models like the SAR model in (3.2) is that seasonal
movements are assumed to be constant over the year. Although changing seasonality
can simply be modeled in a deterministic fashion, for instance by replacing the intercept
¬µ in (3.2) by seasonally varying intercepts ¬µs, s = 1...S, the dynamics of yt are still
assumed to be constant over time. A more Ô¨Çexible class of linear models are so called
Periodic Autoregressive Moving Average (‚ÄôPARMA‚Äô) models which can be considered
as a seasonally varying generalization of the class of ARMA models (Box et al. (2008)).
PARMA models have the general form (see Ghysels and Osborn (2001), p.140):
œÜs(L) ¬∑ys,n = ¬µs + Œ∏s(L)¬∑Œµs,n , s = 1...S and n = 1...N,
(3.7)
where œÜs(L) = 1‚àíœÜs1(L)‚àí...‚àíœÜsp(Lp) and Œ∏s(L) = 1‚àíŒ∏s1(L)‚àí...‚àíŒ∏sq(Lq) are the
seasonally varying autoregressive and moving average lag polynomials, respectively, and
Œµs,n is an i.i.d. process over both season and year, i.e. E(Œµs,nŒµk, j) = 0 unless s = k and n =
j. Furthermore heteroscedasticity over the seasons is often permitted, so that E(Œµ2
s,n) =
œÉ2
s . Pioneering works related to PAR(MA) models go back to Gladyshev (1961), Pagano
(1978), Troutman (1979), Tiao and Grupe (1980), inter alia, see also Franses and Paap
(2006).
43

A widely used member of this class, which will be used in the next to chapters, is a
periodic autoregressive model of order p = maxs{ps}, denoted ‚ÄôPAR(p)‚Äô:
ys,n = ¬µs + œÜs1 ¬∑ys‚àí1,n + ...+ œÜsp ¬∑ys‚àíp,n + Œµs,n
, for s = 1...S
(3.8)
which can also be expressed more explicitly as in Boswijk and Franses (1996), Franses
and Koop (1997):
yt =
S
‚àë
s=1
¬µs ¬∑Ds,t +
S
‚àë
s=1
œÜs1 ¬∑Ds,t ¬∑yt‚àí1 + ...+
S
‚àë
s=1
œÜsp ¬∑Ds,t ¬∑yt‚àíp + Œµt
(3.9)
with dummy variable Ds,t = 1, if st = s, with st ‚â°1 + (t ‚àí1)mod S, for s = 1...S, and
0 otherwise. Here st denotes the season in which observation t falls, assuming that y1 is
observed in season 1 for simplicity.
For example, with monthly data an observation yt at date t = 14 is observed in season
s14 = 1 + (14‚àí1)mod 12 = 2, that is in February of year n. The year n in which obser-
vation yt = ys,n falls can be obtained as nt = 1 + int[(t ‚àí1)/S], where ‚Äôint‚Äô denotes the
integer part, i.e. for example n14 = 1 + int[13/12] = 2, see Ghysels and Osborn (2001),
p.6.
Dropping the constants ¬µs in (3.8) for the moment, note that the PAR(p) model is a special
case of
yt = œÜ1,t ¬∑yt‚àí1 + ...+ œÜp,t ¬∑yt‚àíp + Œµt , t = 1...T
(3.10)
which is usually called a random-coefÔ¨Åcient autoregression of order p (cf. Franses and
Paap (2006), p.7). Assuming œÜst = œÜt, with st = 1 + (t ‚àí1)mod S, then yields a PAR(p)
model. Furthermore the PAR(p) model itself encompasses the nonperiodic AR(p) model
yt = œÜ1 ¬∑yt‚àí1 + ...+ œÜp ¬∑yt‚àíp + Œµt , t = 1...T
(3.11)
by assuming œÜs = œÜ, ‚àÄs.
One important aspect of periodic processes like (3.7) is that they are nonstationary by con-
struction, because their autocorrelation function and hence their spectral density varies
with the season (see Troutman (1979), p.222 for more details). This latter observation
44

suggests an alternative model representation for an analysis of stationarity, unit roots and
stochastic trends. These issues are analyzed most conveniently in a multivariate model
framework, see Franses (1994), Boswijk and Franses (1996), also L√ºtkepohl (2007),
p.591.
The idea is to stack the seasonal observations ys,n in the annual sequence of (S√ó1) vectors
Yn = (y1,n,...,yS,n)‚Ä≤, where ys,n = yS¬∑(n‚àí1)+s is the observation in season s of year n, for
n = 1...N. This was Ô¨Årst proposed by Gladyshev (1961) and adapted by many others in
the sequel, see Franses (2003), Franses and Paap (2006) for an overview.
For illustration purposes, I will write out the univariate model in (3.8) for the simplest
case with p = 1 and S = 4, that is a quarterly PAR(1) process, here explicitly:
y1,n
=
¬µ1 + œÜ11 ¬∑y4,n‚àí1 + Œµ1,n
y2,n
=
¬µ2 + œÜ21 ¬∑y1,n + Œµ2,n
y3,n
=
¬µ3 + œÜ31 ¬∑y2,n + Œµ3,n
y4,n
=
¬µ4 + œÜ41 ¬∑y3,n + Œµ4,n
as ys,n = yS+s,n‚àí1, for s ‚â§0.
Following Boswijk and Franses (1996) the above system of equations can be written as a
multivariate model of Yn:
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
1
0
0
0
‚àíœÜ21
1
0
0
0
‚àíœÜ31
1
0
0
0
‚àíœÜ41
1
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
y1,n
y2,n
y3,n
y4,n
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
=
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
¬µ1
¬µ2
¬µ3
¬µ4
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
+
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
0
0
0
œÜ11
0
0
0
0
0
0
0
0
0
0
0
0
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
y1,n‚àí1
y2,n‚àí1
y3,n‚àí1
y4,n‚àí1
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
+
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
Œµ1,n
Œµ2,n
Œµ3,n
Œµ4,n
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
45

or more compactly in matrix notation
Œ¶0 ¬∑Yn = ¬µ + Œ¶1 ¬∑Yn‚àí1 + En ,
n = 1...N
(3.12)
where the annual lag operator LSYn ‚â°Yn‚àí1 is similarly deÔ¨Åned as the usual one-period
lag operator L ¬∑ ys,n ‚â°ys‚àí1,n and ¬µ = (¬µ1,...,¬µS)‚Ä≤ is a vector of constants and En =
(E1,n,...,ES,n)‚Ä≤ follows an S-dimensional Gaussian vector white noise process with Es,n =
ŒµS¬∑(n‚àí1)+s, respectively. In general, Œ¶0 and Œ¶k, k = 1...P, are S√óS coefÔ¨Åcient matrices
with elements
Œ¶0[i, j] =
Ô£±
Ô£¥
Ô£¥
Ô£≤
Ô£¥
Ô£¥
Ô£≥
1 ,
if i = j
0 ,
if j > i
‚àíœÜi‚àíj,i ,
if i > j
Œ¶k[i, j] = œÜi‚àíj+S¬∑k,i
(3.13)
for i = 1...S, j = 1...S. Here the maximum lag order equals P = 1+ ‚åä(p‚àí1)/S‚åã, see
Franses and Paap (2006), p.32, Ghysels and Osborn (2001), p.145 f. for details.
Now, in contrast with the univariate form in (3.8) and (3.9), respectively, the multivariate
form has constant parameters, which is thus a useful representation to test for the presence
of unit roots (see Franses (1994)). Equation (3.12) can Ô¨Ånally be expressed as a vector
autoregressive process of order P (‚ÄôVAR(P)‚Äô) in terms of a matrix polynomial Œ¶(L) =
Œ¶0 ‚àíŒ¶1LS ‚àí...‚àíŒ¶PLPS (here: with P = 1):
Œ¶(L) ¬∑Yn = ¬µ + En
(3.14)
The vector system in (3.14) is stable, iff the roots z of the characteristic polynomial
det(Œ¶0 ‚àíŒ¶1 ¬∑zS ‚àí...‚àíŒ¶P ¬∑zPS) = 0,
(3.15)
are outside the complex unit circle (see Hamilton (1994), p.259). In case of a PAR(1)
process the determinant in (3.15) equals
det(Œ¶0 ‚àíŒ¶1 ¬∑zS) = 1‚àí(œÜ11œÜ21œÜ31œÜ41 ¬∑...¬∑œÜS1)¬∑zS = 0
(3.16)
From equation (3.16) it can be seen, that the characteristic polynomial has all solutions
46

outside the unit circle, iff
|œÜ11 ¬∑...¬∑œÜS1| < 1
(3.17)
It should be noticed that the condition |œÜs1| < 1, ‚àÄs, is sufÔ¨Åcient but not necessary for the
stationarity condition in (3.17) to hold. For this reason, a stationary PAR(1) process can
exhibit one or more individual |œÜs1| ‚â•1. If œÜ11 ¬∑ ... ¬∑ œÜS1 = 1, the system of Yn has one
unit root and the univariate process ys,n is said to be periodically integrated (see Franses
(1994), p.135). For higher order PAR processes the nonlinear parameter restrictions for
stationarity become more complicated. For example, in case of a quarterly PAR(2) pro-
cess (Boswijk et al. (1995), Franses (1994), p.98) this can be easily veriÔ¨Åed to be
œÜ22œÜ31œÜ41 + œÜ22œÜ42 + œÜ12œÜ21œÜ31 + œÜ12œÜ32 + œÜ11œÜ21œÜ31œÜ41+
œÜ11œÜ21œÜ42 + œÜ11œÜ41œÜ32 ‚àíœÜ12œÜ22œÜ32œÜ42 = 1
(3.18)
Since the Bayesian tests presented in the next chapter are constructed for PAR processes
of order one, the subsequent discussion mainly focuses on these processes. The concept
of Ô¨Årst-order periodic integration (PI) can now be formalized according to Ghysels and
Osborn (2001), p.155, as follows:
DeÔ¨Ånition 1. A nonstationary periodic process ys,,n is said to be periodically integrated
of order 1 if there exist quasi-differences Dsys,n ‚â°ys,n ‚àíœÜs1ys‚àí1,n, with ‚àèS
s=1 œÜs1 = 1 and
not all œÜs1 = 1, such that the VAR representation for the quasi-differences is stationary
and invertible.
The above deÔ¨Ånition was introduced by Osborn et al. (1988) and is an example of the
time-varying parameter deÔ¨Ånition as given in Granger (1986). It can also be considered
as a generalization of the (non)seasonal unit root concept within the class of SARMA
models. Following Ghysels and Osborn (2001), p.152, in a PAR context, Ô¨Årst-order unit
root nonstationarity arises when the characteristic polynomial in (3.15) contains either
the seasonal factor 1 ‚àíLS or the nonseasonal factor 1 ‚àíL, with all other roots having
modulus greater than one. Ghysels and Osborn (2001) distinguish three different types of
integration that can induce Ô¨Årst-order unit root nonstationarity:
‚Ä¢ yt ‚àºI(1): When each periodic autoregressive polynomial œÜs(L) contains the com-
mon factor ‚àÜ1 = (1 ‚àíL), but the VAR representation for ‚àÜ1ys,n is a stationary
47

process. This case corresponds to a zero frequency unit root.
‚Ä¢ yt ‚àºSI(1) : When each periodic autoregressive polynomial œÜs(L) contains the com-
mon factor ‚àÜS = (1 ‚àíLS), but the VAR representation for ‚àÜSys,n is a stationary
process. This type of integration is discussed in section 3.1.
‚Ä¢ yt ‚àºPI(1) : When the characteristic polynomial det(Œ¶(L)) contains the factor
‚àÜS = (1‚àíLS), see also equation (3.14), but (1‚àíLS) is not common to each poly-
nomial œÜs(L), s = 1...S, with the VAR for ‚àÜSys,n being stationary.
The Ô¨Årst two types of integration are the nonseasonal and the seasonal unit root(s) con-
sidered in the ARMA and SARMA framework, respectively (see Box et al. (2008)). The
third case is a speciÔ¨Åc type, that can arise only in a PARMA context. The deÔ¨Ånition
of periodic integration indicates that periodic integration nests the nonseasonal (1 ‚àíL),
and also the seasonal (1 + L) Ô¨Ålter, which correspond to the zero and the œÄ-frequency,
respectively (see section 3.1 above). For a PAR(1) model this suggests that one should
Ô¨Årst check the nonlinear restriction œÜ1 ¬∑ ... ¬∑ œÜS in (3.17) and then test for œÜs = 1,‚àÄs, and
œÜs = ‚àí1,‚àÄs, see Boswijk and Franses (1996). That is, once it has been established that
the periodic unit root null hypothesis
H0 : œÜ1 ¬∑...¬∑œÜS = 1
vs.
H1 : |œÜ1 ¬∑...¬∑œÜS| < 1
(3.19)
cannot be rejected, the next step is to test whether the hypotheses
H0 : œÜs = 1 , for s = 1...S‚àí1
vs.
H1 : œÜs Ã∏= 1 , ‚àÉs
(3.20a)
H0 : œÜs = ‚àí1 , for s = 1...S‚àí1
vs.
H1 : œÜs Ã∏= ‚àí1 , ‚àÉs
(3.20b)
are valid, which also implies that either œÜS = 1 or œÜS = ‚àí1, given ‚àèS
s=1 œÜs = 1.
Both hypotheses (3.20) postulate that there is no periodic variation in the autoregressive
coefÔ¨Åcients, but that the data is generated by a (non)seasonal Random Walk process.
Boswijk and Franses (1996) prove that the corresponding null distributions for a test of
(3.20a) and (3.20b) asymptotically follow a œá2
(3)- distribution (see Boswijk and Franses
(1996), Theorem 2, p.232). When the null in (3.20a) is not rejected the PAR process
is said to contain a nonseasonal (i.e. annual) unit root. In the terminology of Franses
(2003), p.133, the null in (3.20a) results in a PAR process for an I(1) series, which he
48

abbreviates as ‚ÄôPARI‚Äô. However when the null in (3.20b) is not rejected, it is said that the
PAR process contains a real-valued seasonal unit root, corresponding to a half-year cycle
(see Ghysels and Osborn (2001)). In case that the hypotheses in (3.20a) and (3.20b) are
both not rejected the PAR model is called a periodically integrated AR model (‚ÄôPIAR‚Äô),
see Franses (2003).
3.3. Two classical testing approaches for a
periodic unit root
In this section two classical testing approaches for a single periodic unit root are outlined.
The Ô¨Årst one is based on the vector representation of a PAR process and proceeds within
a cointegration framework (Engle and Granger (1987), Johansen (1988)), whereas the
second is based on the univariate model representation and will be used as a classical
competitor in the next section. More details on periodic unit root and cointegration testing
can be found in Franses (2003), Franses and Paap (2006).
The possibility of analyzing periodic unit roots in a cointegration framework stems from
the fact that periodic integration must imply cointegration of the nonstationary series ys,n
with the seasonally varying differencing Ô¨Ålters as the stationary linear combinations (see
also deÔ¨Ånition 1). Moreover the number of unit roots is linked to the number of cointe-
gration relations between the elements of Yn, see Franses and Paap (2006), p.85.
Premultiplying equation (3.12) with Œ¶‚àí1
0
yields:
Yn
=
Œ¶‚àí1
0 ¬µ + Œ¶‚àí1
0 Œ¶1 ¬∑Yn‚àí1 + Œ¶‚àí1
0 En
(3.21)
49

with3
Œ¶‚àí1
0 Œ¶1
=
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
0
0
0
œÜ11
0
0
0
œÜ11œÜ21
0
0
0
œÜ11œÜ21œÜ31
0
0
0
œÜ11œÜ21œÜ31œÜ41
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
(3.22)
By subtracting Yn‚àí1 on both sides the model in (3.21) can be written in vector error cor-
rection form (cf. L√ºtkepohl (2007), p.248) as
‚àÜ1Yn
=
Œ¶‚àí1
0 ¬µ + (Œ¶‚àí1
0 Œ¶1 ‚àíI4) ¬∑Yn‚àí1 + Œ¶‚àí1
0 En
(3.23a)
=
¬µ‚ãÜ+ Œ† ¬∑Yn‚àí1 + E‚ãÜ
n
(3.23b)
where ‚àÜ1 is the Ô¨Årst-differencing Ô¨Ålter for the annual vector series, that is 1‚àíLS operates
on the annual data Yn (see Franses and Paap (2006), p.65). Hence ‚àÜ1Yn corresponds to
‚àÜ4yt for S = 4, or in general to ‚àÜSyt. Of primary interest is the matrix Œ†, which is relevant
for the analysis of longrun equilibria among the elements of Yn:
Œ† ‚â°Œ¶‚àí1
0 Œ¶1 ‚àíI4
=
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
‚àí1
0
0
œÜ11
0
‚àí1
0
œÜ11œÜ21
0
0
‚àí1
œÜ11œÜ21œÜ31
0
0
0
œÜ11œÜ21œÜ31œÜ41 ‚àí1
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
(3.24)
The matrix Œ† contains information on the cointegration relations between the S elements
in Yn. It can be written as Œ† = Œ≥ ¬∑œÜ‚Ä≤ with loading matrix Œ≥ and œÜ the matrix of cointegra-
tion vectors both of dimension 4√ór, see Franses and Paap (2006), p.64. When there are
r stationary linear combinations between the ys,n, the matrix Œ† has rank r with 0 < r < 4.
3This can easily be veriÔ¨Åed by direct calculation of Œ¶‚àí1
0 , for example via Gauss-Jordan elimination.
50

In the present case, the cointegration space can be spanned, for example, by
œÜ‚Ä≤
=
Ô£´
Ô£¨
Ô£¨
Ô£≠
‚àíœÜ21
1
0
0
0
‚àíœÜ31
1
0
0
0
‚àíœÜ41
1
Ô£∂
Ô£∑
Ô£∑
Ô£∏
(3.25)
When the rank r of the matrix Œ† in (3.23b) is r = 0, and hence there are no cointegration
relations between the elements of Yn, this implies that the 1‚àíLS Ô¨Ålter for ys,n is appropri-
ate. The Yn process is stationary when r equals 4. When œÜ11œÜ21œÜ31œÜ41 = 1 the rank of Œ†
equals r = 3, and this implies three cointegrating relationships between the ys,n subseries.
Thus the three stationary linear combinations are: (y2,n ‚àíœÜ21y1,n), (y3,n ‚àíœÜ31y2,n) and
(y4,n ‚àíœÜ41y3,n), which correspond to three quasi-differences (see deÔ¨Ånition 1). Note that
the fourth stationary variable (y1,n ‚àíœÜ11y4,n‚àí1) is implied by the other three, and thus is
not linearly independent.4 In other words, in case of a single real unit root,5 there ex-
ist S ‚àí1 linear combinations (1 ‚àíœÜs1L) ¬∑ ys,n, that transform the series yt to a stationary
process, see Franses (2003), p.128, for details. Since a test for the rank of the matrix
Œ† can also be considered as a test for a periodic unit root, Franses (1994) proposes to
use the likelihood-based cointegration test developed in Johansen (1988). However as
can be seen from equation (3.23a) the cointegration approach by Franses (1994) is highly
parameterized6 compared to the univariate approach considered next.
Boswijk and Franses (1996) propose an alternative testing strategy using the univariate
model representation in (3.9) as a starting point (see also Boswijk and Franses (1995)).
For the ease of reference and also because this classical test is compared with one of the
Bayes tests presented in the next chapter, I will brieÔ¨Çy outline the basic testing strategy of
the Boswijk and Franses (1996) test.7
In the simplest case of a quarterly PAR(1) process without deterministic terms the authors
4This can be checked by inserting the Ô¨Årst and third of the above linear combinations into the second,
imposing the unit root restriction via œÜ1 = 1/(œÜ2 ¬∑œÜ3 ¬∑œÜ4), and solving for y1,n.
5For the case of multiple unit roots, see Franses and Paap (2006), p.67.
6Here an unrestricted S√óS matrix of coefÔ¨Åcients has to be estimated.
7This test has been implemented in R by the author.
51

consider estimating the following unrestricted regression under the alternative H1:
yt =
4
‚àë
s=1
œÜsDs,tyt‚àí1 + Œµt
(3.26)
Assuming independently normally distributed errors Œµt, the maximum likelihood (ML)
estimators of the œÜs are given by the least squares estimators. Under H0 the following
restricted regression is estimated:
yt = œÜ1D1,tyt‚àí1 + œÜ2D2,tyt‚àí1 + œÜ3D3,tyt‚àí1 + (œÜ1œÜ2œÜ3)‚àí1D4,tyt‚àí1 + Œµt
(3.27)
The authors consider maximizing the restricted log-likelihood via non-linear least squares
(see ibid., p.229). A likelihood ratio test statistic can be constructed as
LR ‚â°T ¬∑ln(RSS0/RSS1)
where RSS0 and RSS1 denote the residual sums of squares from the regressions under H0
and H1, respectively.
A one-sided test may then be constructed from the studentized statistic:
LRœÑ = sign(bœÅ ‚àí1) ¬∑
‚àö
LR
(3.28)
Boswijk and Franses (1996), Theorem 1, p.230, show that the statistic in (3.28) has the
following asymptotic distribution under the null hypothesis:
LRœÑ
d‚Üí
Z 1
0 W(r)2dr
‚àí1
2 Z 1
0 W(r) ¬∑dW(r)
(3.29)
where W(r) is a standard Wiener process and d‚Üídenotes convergence in distribution.
This statistic has the same asymptotic null distribution as Fuller‚Äôs œÑ statistic for a nonpe-
riodic AR model without drift and trend and thus the tabulated critical values in Fuller
(1996) can be used.
In the next chapter an alternative Bayesian testing approach for a periodic unit root in the
presence of a structural break at unknown time is presented.
52

Bayesian analysis of periodic unit
roots with a break
4.1. Introduction
Periodic autoregressive models have been applied to economic time series as an alterna-
tive to constant parameter models like seasonal autoregressive moving average models
or seasonal means models, see Osborn et al. (1988), Osborn and Smith (1989), Franses
(1995), Franses and Koop (1997) among others. PAR processes can for example arise
when modeling seasonal decisions of consumers (Osborn et al. (1988)), whereas Hansen
and Sargent (1993) suggest that they arise from seasonal technology. In the literature such
changing seasonal variation in the data has often been modeled in a deterministic fashion,
e.g. through the inclusion of seasonal dummy variables or so called seasonally integrated
autoregressive models. However, empirical studies have found evidence for periodic vari-
ation in many macroeconomic series. For example, Franses (1995) Ô¨Ånds in a business
cycle analysis of quarterly US unemployment rates that seasonal Ô¨Çuctuations are not con-
stant across two business cycle stages and further that shocks to the unemployment rate
are transitory in expansion and persistent in recession periods. Ooms and Franses (1997)
show that quarterly unadjusted OECD unemployment rates of Germany and the US can
best be described by a PAR process with a unit root. Within a periodic error-correction
framework Birchenhall et al. (1989) provide empirical Ô¨Åndings that the long-run income
elasticity of consumption and its rate of adjustment to equilibrium both vary seasonally.
They take this as evidence in favor of the hypothesis that consumers have seasonal pref-
erences and also seasonally varying degrees of habit persistence. In such a case, in order
to remove any stochastic trend, the applied differencing Ô¨Ålter has to vary with the season,
too. Consequently, this leads to the concept of periodic (co)integration (see Osborn et al.
53

(1988)) which can be perceived as a time-varying generalization of the concept of seasonal
(co)integration, see Hylleberg et al. (1990), Beaulieu and Miron (1993), Franses (1994)
and Ghysels and Osborn (2001), Franses (2003) for overviews. Different approaches have
been proposed to test for periodic integration in economic time series, see Franses (1994),
Boswijk et al. (1995), Boswijk and Franses (1996), Franses and Koop (1997), inter alia.
However nearly all of these proceed within a classical (or frequentist) framework. By
contrast there is a vast literature on Bayesian hypothesis testing for a (non-periodic) zero
frequency unit root, see Sims (1988), Phillips (1991b), Sims and Uhlig (1991), Schotman
and van Dijk (1991), inter alia, and the related subsequent discussion on these works, also
Maddala and Kim (1998) for an overview. For a Bayesian adaption of the Hylleberg et al.
(1990) (HEGY) model framework to test for seasonal unit roots, see Franses et al. (1997).
One exception is the paper of Franses and Koop (1997), who present a Bayesian frame-
work to test for different kinds of unit roots, namely (non)seasonal unit roots at the zero
and œÄ-spectral frequency (cf. Ghysels and Osborn (2001)) but most importantly for peri-
odic unit roots. For the latter they propose a sampling based as well as an analytical, i.e.
non-sampling based, testing strategy, whereas for (non)seasonal unit roots they suggest an
approximate Bayesian test based on highest posterior density (HPD) regions. Their tests
assume one structural break at unknown time and are thus conditional on the occurrence
of a break. The authors Ô¨Ånd widespread evidence for (non)periodic integration using data
of nine major UK macroeconomic time series. Franses and Koop (1997) then apply their
methods to a large set of quarterly UK macroeconomic time series and Ô¨Ånd great evidence
in favor of periodic integration of order one.
The subsequent analysis aims to extend the work of Franses and Koop (1997) in several
directions. First, the approach presented here allows to capture the uncertainty induced
by conditioning on a structural break model and therefore assigning zero prior probability
to models without a break. This is achieved by using a mixture of discrete and continu-
ous posterior distributions for unit root testing, where the discrete parts are given by the
posterior probabilities of a model with and without a structural break. Thus the presented
approach essentially consists of averaging over the discrete space of candidate models
by using Bayesian model averaging (BMA) techniques (cf. Raftery et al. (1997)). This
BMA strategy is pursued in order test for periodic unit roots and also to test for zero and
œÄ-frequency unit roots. For the latter two cases a Bayesian F-test is proposed. All pre-
sented tests allow a shift to occur in the seasonal means and/or time trends and are applied
54

to both quarterly and monthly data. To illustrate the performance of the proposed tests,
the results of Monte Carlo experiments are presented. In contrast to the existing literature
on periodic unit root testing, the Bayesian tests are compared to classical competitors in
terms of test power. The results suggest that the Bayes test for a periodic unit root has
favorable power also in small samples, whereas the Bayesian F-test for a (non)seasonal
unit root has less power in small samples. Overall the Bayes tests outperform their classi-
cal competitors, especially in short time series. In an empirical application the proposed
unit root tests are Ô¨Ånally used to test for periodic integration of order one in monthly
unadjusted OECD unemployment rates.
In the economic literature most studies do not consider seasonal forms of non-stationarity
in the data but instead work with seasonally adjusted data. The effect of working with
seasonally adjusted data on the results of unit root tests has been an object of investiga-
tion in the literature. Ghysels and Perron (1993) show that when the data are generated
by a stationary ARMA process there is a positive asymptotic upward bias induced by
an application of the X-11 Ô¨Ålter.1 Thus one can expect unit root tests performed with
Ô¨Åltered data to be less powerful against stationary alternatives, because asymptotically
the sample estimate of the AR coefÔ¨Åcient for such data is greater than for unÔ¨Åltered data
(see Ghysels (1990)). The empirical results presented in this chapter suggest, that the
majority of the analyzed monthly OECD unemployment rates are in fact generated by a
nonperiodic unit root process. The presence of periodic variation in the data is further
analyzed by a Bayesian test for parameter-constancy. The latter shows that there is not
much evidence for stochastic periodicity in the unemployment series. In the light of eco-
nomic theory, favoring a nonperiodic unit root process in order to describe most of the
considered OECD unemployment series can be interpreted as supporting the hypothesis
of unemployment hysteresis, namely that labor market shocks have a long-run impact on
the level of unemployment, see for example Blanchard and Summers (1986).
The rest of this chapter is organized as follows: in section 4.2 the model is introduced and
in section 4.3 the proposed Bayesian testing procedures are presented. Then in section
4.4 the results of Monte Carlo experiments to study the power properties of the tests are
described. In section 4.5 the results of an empirical application to OECD unemployment
data are discussed and section 4.6 summarizes the main Ô¨Åndings and concludes.
1For a review of seasonal adjustment methods see Ghysels and Osborn (2001).
55

4.2. Model and denitions
In the following the focus is on PAR models with at most one structural break in the
deterministic component(s) at an unknown point in time. Similar models have been used
for example in Franses and Koop (1997) and Franses (2003). In case of a structural break
in the periodic intercepts and slopes the model has the following general form
yt = (
S
‚àë
s=1
ps
‚àë
i=1
œÜi,s ¬∑Ds,t ¬∑yt‚àíi) + Œªt + Œµt ,
Œµt
i.i.d.
‚àºN(0,œÉ2
s )
(4.1a)
Œªt =
S
‚àë
s=1
 (¬µs + Œ±s ¬∑œÑt) ¬∑Ds,t + (¬µ‚ãÜ
s + Œ±‚ãÜ
s ¬∑œÑt) ¬∑D‚ãÜ
s,t

(4.1b)
with t = 1,...,T observations and s = 1,...,S seasons.
Let st = 1 + [(t ‚àí1)mod S] denote the season of observation t (see section 3.2), and let
TB ‚àà]ps + Œ∫, T ‚àíŒ∫] be the unknown break point, where Œ∫ denotes the Ô¨Årst and last
ten percent of observations in the sample, which are truncated in order to avoid possible
endpoint problems. Then the seasonal dummy variables in (4.1) are given by Ds,t =
1, if st = s ‚àßt ‚â§TB, otherwise 0, and D‚ãÜ
s,t = 1, if st = s ‚àßt > TB, and 0 otherwise.
Last, œÑt in (4.1b) denotes the value of the linear time trend at time t. In the case of
no structural break Œ±‚ãÜ
s and ¬µ‚ãÜ
s equal zero for all seasons. In the following, ps = 1 and
œÉ2 = œÉ2
s ,‚àÄs, is assumed, i.e. a homogeneous autoregressive lag order of one and no
seasonal heteroscedasticity.
The periodic autoregressive structural break model in (4.1) can be expressed more conve-
niently in matrix form. For this purpose deÔ¨Åne the following expressions:
y0
p√ó1
‚â°
[ y1, y2, ... , yp ]‚Ä≤
y
T‚àíp√ó1
‚â°
[ yp+1, yp+2, ... , yT ]‚Ä≤
y(s)
‚àí1
‚â°
[ Ds,p+1 ¬∑yp, Ds,p+2 ¬∑yp+1, ... ,Ds,T ¬∑yT‚àí1 ]‚Ä≤
...
y(s)
‚àíp
‚â°
[ Ds,p+1 ¬∑y1, Ds,p+2 ¬∑y2, ... ,Ds,T ¬∑yT‚àíp ]‚Ä≤
56

and
X
T‚àíp √ó p¬∑S
‚â°
[ y(1)
‚àí1, ... ,y(S)
‚àí1 , y(1)
‚àí2, ... ,y(S)
‚àí2 , ... , y(1)
‚àíp, ... ,y(S)
‚àíp ]‚Ä≤
Œµ
T‚àíp √ó 1
‚â°
[ Œµp+1, Œµp+2, ... ,ŒµT ]‚Ä≤
Z
T‚àíp √ó 4¬∑S
‚â°
[ (D1, ...,DS)(T‚àíp√óS) , (D‚ãÜ
1, ..., D‚ãÜ
S)(T‚àíp√óS) ,
(D1,p+1 ¬∑œÑp+1, ...,D1,T ¬∑œÑT)‚Ä≤ , ... ,(DS,p+1 ¬∑œÑp+1, ...,DS,T ¬∑œÑT)‚Ä≤ ,
(D‚ãÜ
1,p+1 ¬∑œÑp+1, ...,D‚ãÜ
1,T ¬∑œÑT)‚Ä≤ , ... ,(D‚ãÜ
S,p+1 ¬∑œÑp+1, ...,D‚ãÜ
S,T ¬∑œÑT)‚Ä≤ ]
œÜ
p¬∑S√ó1
‚â°
[ (œÜ1,1, œÜ1,2, ... ,œÜ1,S)
|
{z
}
‚â°œÜ‚Ä≤
1
, ... ,(œÜp,1, œÜp,2, ... ,œÜp,S)
|
{z
}
‚â°œÜ‚Ä≤p
]‚Ä≤
Œ¥
4¬∑S √ó 1
‚â°
[
‚â°¬µ
z
}|
{
¬µ1, ..., ¬µS ,
‚â°¬µ‚ãÜ
z
}|
{
¬µ‚ãÜ
1, ...,¬µ‚ãÜ
S ,
‚â°Œ±
z
}|
{
Œ±1,..., Œ±S ,
‚â°Œ±‚ãÜ
z
}|
{
Œ±‚ãÜ
1, ...,Œ±‚ãÜ
S ]‚Ä≤
Therefore the model in (4.1) can Ô¨Ånally be written in more compact form:2
y
=
X¬∑œÜ + Z¬∑Œ¥ + Œµ =

X ... Z

T‚àíp √ó (4+p)¬∑S
¬∑
 
œÜ
Œ¥
!
(4+p)¬∑S √ó 1
+ Œµ = eX¬∑B+ Œµ
(4.2)
where in the following d ‚â°(4+ p) ¬∑S.
4.3. Bayesian testing for a periodic unit root
In order to draw inference from a Bayesian PAR model (BPAR) some prior information
with regard to the unknown parameters has to be speciÔ¨Åed. In contrast to Franses and
Koop (1997) I do not assume an informative prior for the regression parameters and the
innovation variance, but assume the elements of B and logœÉ2 as independently and uni-
formly distributed, to express prior ignorance with respect to these quantities (cf. Zellner
2In anticipation of the analysis in the next chapter, the model is stated here for a general lag order p.
57

(1971), p.66).3 To express also a lack of prior knowledge with respect to the unknown
break date a discrete uniform prior over the set of possible break dates is chosen. These
assumptions lead to the following prior distributions:
f (B,œÉ2) ‚àùœÉ‚àí2 , with œÉ2 > 0 , B ‚ààR
(4.3a)
f (TB| m = 1, p = 1) =
1
T ‚àí1‚àí2Œ∫ ¬∑1(Œ∫+1<TB‚â§T‚àíŒ∫)
(4.3b)
where 1(.) denotes an indicator function.
By an application of the Bayes Theorem the joint posterior density function of all un-
known quantities, under a structural change model, is given by4
f (B,œÉ2,TB| m = 1, y) = f (y| B,œÉ2,TB, m = 1) ¬∑ f (B, œÉ2| TB, m = 1)¬∑ f (TB| m = 1)
f (y| m = 1)
(4.4)
where m denotes the unknown number of structural breaks, restricted to m ‚àà{0,1}.
In the subsequent analysis interest focuses on testing the following hypotheses:
HA : œÜs = 1
against
|œÜs| < 1 , for s = 1...S
(4.5a)
HB : œÜ1 ¬∑...¬∑œÜS = 1
against
|œÜ1 ¬∑...¬∑œÜS| < 1
(4.5b)
HC : œÜ1 = ... = œÜS = 1
against
œÜs Ã∏= 1 , ‚àÉs
(4.5c)
HD : œÜ1 = ... = œÜS = ‚àí1
against
œÜs Ã∏= ‚àí1 , ‚àÉs
(4.5d)
where in the following œÅ ‚â°‚àèS
s=1 œÜs.
Testing the null hypothesis HA, i.e. a Random Walk in season s, requires the computation
of the marginal posterior density of œÜs,‚àÄs, whereas testing the hypothesis HB, i.e. the
presence of a periodic unit root, requires the derivation of the marginal posterior of the
nonlinear parameter restriction in (4.5b). If HB can not be rejected, the process is called
periodically integrated of order one, abbreviated by yt ‚àºPI(1) (see Ghysels and Osborn
(2001) for details). Last, the two hypotheses in H(C)D are useful for the analysis of a
3It turned out that the empirical results presented in section 4.5 are largely unaffected by this choice.
4In the following conditioning on eX and p = 1 is omitted.
58

(non)seasonal unit root, which implies that the series is (seasonally) integrated of order
one, i.e. yt ‚àºI(1) and yt ‚àºSI(1). That is under HC and HD it is postulated that the
series is generated by a zero and œÄ-frequency unit root process, respectively. Note that
both HC and HD are nested within HB. If the restriction in HB could not be rejected
and a subsequent test shows that either of the nonperiodic unit root null hypotheses HC
and HD can not be rejected, too, such a process is called a PAR process for an I(1)
series (‚ÄôPARI‚Äô). By contrast, if HC and HD could be rejected, but not HB, then the process
is called a periodically integrated AR process (‚ÄôPIAR‚Äô), see section 3.2. Whereas the
required densities for HA and HC(D) can be stated analytically (see appendix G for details),
the analysis of HB is more complex due to the nonlinearity of the null constraint. In order
to circumvent any computationally intensive techniques, like Markov chain Monte Carlo
techniques, Franses and Koop (1997) propose to linearize the restriction œÅ = œÜ1 ¬∑...¬∑œÜS =
1 in HB by taking logs and noting that log(1 + x) ‚âàx for small x.5 As pointed out by
the authors and also according to own experience, the œÜs-coefÔ¨Åcients are close to one in
practice, so this should yield a good approximation. The periodic unit root constraint in
HB can therefore be approximated by the following linear restriction
H0 : œÜ1 + ...+ œÜS = S
against
|œÜ1 + ...+ œÜS| < S
(4.6)
where Œ∏ ‚â°‚àëS
s=1 œÜs is written henceforth.
A second approach to test the hypothesis HB is to generate random draws from the poste-
rior distribution of the vector of PAR coefÔ¨Åcients œÜ, which follows a multivariate Student-t
distribution with ŒΩ = T ‚àí1 ‚àíd degrees of freedom (see appendix G.2), say M = 10000
times, and then compute the product œÅ for each draw. After utilizing kernel density esti-
mates in order to approximate the posterior ordinates, mean and variance can be computed
as well as the 95%-HPD region by using one-dimensional numerical integration.6 Then a
test of HB can be conducted by rejecting the null hypothesis, if the null restriction œÅ = 1
lies outside the HPD region. In the empirical analysis of section 4.5, this testing strategy
is used for comparison with the approximate approach of testing the linear restriction in
(4.6).
In accordance with Franses and Koop (1997), I allow for a single break in the deterministic
5This follows from a Ô¨Årst order Taylor series expansion of log(1+ x) around zero.
6Here for example Simpson‚Äôs rule could be used, cf. Bauwens et al. (1999), p.69.
59

components, but in contrast to the latter authors, I additionally allow a break to occur in
the seasonal time trend so that abrupt changes in the trending behavior of the series can
also be captured. Thus, given the lag order and the speciÔ¨Åcation of deterministics, the set
of candidate models, M , contains only two elements Mi, namely a structural change (SC)
model (m = 1) and a no-structural change (NSC) model (m = 0).7 The key ingredients
for BMA techniques are the model posterior probabilities (see Raftery et al. (1997)):
f (Mj|y) =
f (y|Mj) ¬∑ f (Mj)
‚àëK
i=1 f (y|Mi) ¬∑ f (Mi)
(4.7)
with f (Mi) the prior probability of model Mi, which are chosen as f (Mi) = 1/K, for ‚àÄi,
and K = 2. The prior predictive density under the SC model is given by
f (y| m = 1) =
T‚àíŒ∫
‚àë
TB=Œ∫+2
Z
R+
Z
Rd f (y|B,œÉ2,TB, m = 1) ¬∑
f (B, œÉ2|TB, m = 1) ¬∑ f (TB| m = 1) ¬∑dB¬∑dœÉ2
(4.8)
where f (TB| m = 1) is given in (4.3b) and B denotes the vector of regression parameters.
Note that the inner two integrations can be solved analytically. As pointed out by Raftery
et al. (1997) all probabilities are implicitly conditional on M , i.e. the set of considered
models. In order to construct tests for the above hypotheses, the model speciÔ¨Åc posterior
density functions are required. For the analysis of HA we need the marginal8 posterior
distribution of œÜs, s = 1...S, which can be computed as
f (œÜs| y) =
"
T‚àíŒ∫
‚àë
TB=Œ∫+2
f (œÜs| TB, m = 1, y) ¬∑ f (TB| m = 1,y)
#
¬∑ f (m = 1| y)
+ f (œÜs| m = 0, y) ¬∑ f (m = 0| y)
(4.9)
7Of course in the present context another model indicator could be a binary variable, indicating the inclusion
of a time trend (or any other exogenous regressor). Such variable selection issues are however not further
pursued here, although they would be relatively straightforward to implement, see for example George
et al. (1993).
8In this context marginalization refers to the predeÔ¨Åned model space.
60

Note that the posterior weight for the NSC model used in (4.9) can be calculated as
f (m = 0 | y) ‚àù
eX‚Ä≤eX

‚àí1
2 ¬∑

ŒΩ ¬∑s2‚àíŒΩ
2
(4.10)
with ŒΩ = T ‚àí1‚àíd and s2 the usual sampling estimate of the innovation variance.9
Moreover f (m = 1| y) is proportional to (4.8). The posterior distribution f (œÜs|TB, m =
1, y), s = 1...S, has the form of a univariate Student-t density with ŒΩ = T ‚àí1 ‚àíd de-
grees of freedom (see appendix G.3 for details). Thus the distribution in (4.9) is a model
weighted mixture of t-densities. Here d1 and d2, with d = d1 +d2, denote the dimensions
of the following subvectors:
B ‚â°

B1‚Ä≤ ... B2‚Ä≤
‚Ä≤
=

œÜs
1√ó1
... (œÜ‚Ä≤
‚àís , Œ¥ ‚Ä≤)
‚Ä≤
(4.11)
In appendix G.4 it is shown that the posterior distribution of the linear form Œ∏, under
model Mi, follows a univariate Student-t distribution with ŒΩ = T ‚àí1‚àíd degrees of free-
dom, mean bŒ∏ = Œπ‚Ä≤ ¬∑ bœÜ and variance ŒΩs2 ¬∑ cJ/(ŒΩ ‚àí2), where cJ = Œπ‚Ä≤(eX11 ‚àíeX12 ¬∑ eX‚àí1
22 ¬∑
eX21)‚àí1Œπ. The marginal posterior f (Œ∏| y) is then obtained in the same way as f (œÜs|y) in
(4.9), and therefore is a model weighted mixture of t-densities.
Let the support of Œ∏ be Œò = [0, S] in the following. The posterior probability of the null
hypothesis (4.6), i.e. of the singleton Œò0 = {Œ∏0}, is obtained as in Berger and Delampady
(1987), Berger and Sellke (1987), namely by using a mixed prior density, which assigns
positive prior probability mass œÄ0 to Œò0,10 and uses a continuous density f1(Œ∏), with prior
9This follows from the results of appendix G, by letting B0 and M in (6.35) go to zero.
10Here œÄ0 = 0.5 is used.
61

weight 1‚àíœÄ0, on the complementary parameter set Œò1 = {Œ∏ : 0 ‚â§Œ∏ < S}:11
P(H0| y) =

1+ 1‚àíœÄ0
œÄ0
¬∑ f (y| Œò1)
f (y| Œ∏0)
‚àí1
(4.12a)
with f (y| Œò1) =
Z
Œò1
f (y| Œ∏)¬∑ f1(Œ∏)¬∑dŒ∏
(4.12b)
where the integral in (4.12b) is computed by Simpson‚Äôs rule (cf. Bauwens et al. (1999),
p.69).
Under a ‚Äô0-1‚Äô loss function then an optimal Bayesian decision rule œï(y) is given by (see
Robert (2007), proposition 5.2.2, p.225.):
œï(y) =
(
0 ,
if P(H0|y) ‚â•0.5
1 ,
otherwise
(4.13)
where 1 means rejection of the null hypothesis and P(H0|y) denotes the posterior prob-
ability of the latter, which is abbreviated by P0 henceforth. Further, since the decision
rule (4.13) is based on a Student-t posterior density it is called the ‚ÄôBayesian t-test‚Äô in the
following, in order to discriminate it from the F-test introduced next.
Consider testing the linear hypotheses RœÜ = r in (4.5c) and (4.5d), with R a J √óS matrix
of zeros and ones and r a J-vector of constants. In the present context, the identity matrix
can be used for R and thus J = S. Franses and Koop (1997) propose an approximate Wald-
type test of HC, where they approximate the multivariate Student-t posterior distribution
of œÜ by a Normal distribution. Consequently HC can be tested using the inner product
of standardized normal random variables, which follows a œá2
(S)- distribution (see ibid.,
p.515). However the authors focus in their analysis on quarterly models where there are
usually much more degrees of freedom available than in the case of more parameter-
intensive monthly PAR models. Since for monthly time series of moderate length, i.e.
T = 100‚àí150, such an approximation can be problematic, implying ŒΩ = T ‚àíp‚àíd < 100
11Note that in this approach the sets Œò0 and Œò1 are treated in a different way, since otherwise Œò0 would
have zero Lebesgue measure. Instead of changing the nature of Œò0, by assigning positive probability
mass to it, Pereira et al. (2008) pursue a different strategy by looking for the ‚Äôtangential set‚Äô, T, of points
having posterior density values higher than any in Œò0. Then H0 would not be rejected if the posterior
probability of T, the Bayesian evidence value against H0, is small, see Pereira and Stern (1999), Pereira
et al. (2008) for details.
62

degrees of freedom, with d = (4 + p) ¬∑ S, an exact Bayesian F-test is used instead. For
this purpose deÔ¨Åne the following standardized inner product:
Q(r| Mi, y) ‚â°
h
R(œÜ ‚àíbœÜ)
i‚Ä≤
¬∑
h
R(eX11 ‚àíeX12 ¬∑ eX‚àí1
22 ¬∑ eX21)‚àí1R‚Ä≤i‚àí1
¬∑
h
R(œÜ ‚àíbœÜ)
i
/(S¬∑s2)
= (r‚àíRbœÜ)‚Ä≤ ¬∑
h
R(eX11 ‚àíeX12 ¬∑ eX‚àí1
22 ¬∑ eX21)‚àí1R‚Ä≤i‚àí1
¬∑(r‚àíRbœÜ)/(S¬∑s2)
(4.14)
In appendix G.5 it is shown that the quadratic form follows an F(ŒΩ1 = S, ŒΩ2 = T ‚àí1‚àíd)
posterior distribution, with S and T ‚àí1 ‚àíd degrees of freedom. A simple decision rule
based on Bayesian ‚Äôp-values‚Äô, pv, for testing the linear hypotheses HC and HD, with RœÜ =
r0 = ¬±1, respectively, is to reject the null, whenever
pv(r0| Mi, y) ‚â°1‚àíPF(Q(r0| Mi, y))
(4.15)
is smaller than a nominal level of signiÔ¨Åcance, where PF(.) denotes the cumulative distri-
bution function of the F(ŒΩ1 = S, ŒΩ2 = T ‚àí1‚àíd) posterior distribution.
Since for a selected null hypothesis, i.e. for r0 = ¬±1, the quadratic form Q(r0, TB| m =
1, y) under a structural break model is only a function of the integer-valued break date
TB, the model averaged quadratic form, denoted by QBMA, can be obtained from
QBMA(r0| y) = Q(r0| m = 0, y) ¬∑ f (m = 0 | y)+
"
T‚àíŒ∫
‚àë
TB=Œ∫+2
Q(r0,TB| m = 1, y) ¬∑ f (TB| m = 1, y)
#
¬∑ f (m = 1| y)
(4.16)
with f (m| y) the posterior probability mass function of a break occurrence with normal-
izing constant given by
f (y) =
1
‚àë
m=0
T‚àíŒ∫
‚àë
TB=Œ∫+2
f (y |m, TB) ¬∑ f (TB| m) ¬∑ f (m)
(4.17)
In order to compute the corresponding posterior tail probabilities, the marginalized poste-
rior cumulative distribution function of Q is required. For this purpose, the model speciÔ¨Åc
63

F(ŒΩ1 = S, ŒΩ2 = T ‚àí1‚àíd) posterior ordinates are averaged over the two candidate mod-
els, i.e.
f (Q| y) = f (Q | m = 0, y) ¬∑ f (m = 0 | y) +
"
T‚àíŒ∫
‚àë
TB=Œ∫+2
f (Q | m = 1, TB, y) ¬∑ f (TB| m = 1, y)
#
¬∑ f (m = 1| y)
(4.18)
The corresponding Bayesian p-values, i.e. the right tail probabilities of (4.18), and highest
posterior density regions can then be obtained by numerical integration.
4.4. Monte Carlo evidence: periodic unit root tests
In this section the results of several Monte Carlo (MC) experiments to study the perfor-
mances of the Bayes tests of HB and H(C)D, i.e. of a periodic and a real (non)seasonal unit
root, are presented. For a test of HB, or its linear approximation in (4.6), the Bayesian
t-test in (4.13) is used, where in (4.12a) the conditional or the model averaged posterior
distribution of the linear form Œ∏ is utilized. For a test of the hypothesis H(C)D the Bayesian
F-test, using the conditional p-value (4.15) or the corresponding model averaged p-value
on the basis of (4.18), is computed. In the following simulation study, Ô¨Årst the power
properties of the conditional tests are compared to those of classical competitors. Then
also some simulation evidence concerning the model averaged versions of the Bayes tests
is presented.
In the Ô¨Årst simulation experiment the Bayesian t-test of HB, given a PAR(1) model without
a break, is compared with a classical competitor, namely the test of Boswijk and Franses
(1996) (abbreviated ‚ÄôBF‚Äô, see section 3.3 for some details) in terms of test power. For
this purpose, trajectories of the following quarterly PAR(1) process without a break are
generated:
yt =
4
‚àë
s=1
Ds,t ¬∑(¬µs + œÜs ¬∑yt‚àí1) + Œµt , Œµt
i.i.d.
‚àºN(0,1) , t = 1...150
(4.19)
with seasonal intercepts ¬µs = 1, ‚àÄs.
In order to estimate the empirical power functions for a given sample size, I generate
64

trajectories for each (œÜ1,œÜ2,œÜ3,œÜ4)‚Ä≤- combination in the [0.8,1.1]4-space. Here for each
œÜs, s = 1...4, a grid of six values is used, which results in 64 = 1296 parameter constella-
tions. The rejection probabilities of the null hypothesis are approximated by the average
number of rejections, i.e.
f (‚ÄôReject H0‚Äô| œÅ0, y) ‚âà1
N
N
‚àë
i=1
1(P0<0.5)
(4.20)
where 1(.) denotes an indicator function, N is the number of replications, and œÅ0 denotes
a particular value of this parameter.
Note that (œÜ1,œÜ2,œÜ3,œÜ4) 7‚ÜíœÅ = œÜ1 ¬∑ œÜ2 ¬∑ œÜ3 ¬∑ œÜ4 is not a bijection and thus different œÜs-
combinations can lead to the same œÅ values and hence to similarly persistent processes.
For this reason, if there are any ties in the sequence of œÅ‚Äôs at a value œÅ0, the associated
rejection frequencies are averaged and this average is taken as the value of the power
function at œÅ0.12 In Ô¨Ågure 4.1 the resulting power function for N = 100 replications and
a sample size of T = 150 is shown.13 It is evident that with the exception of seven œÅ-
0.5
0.6
0.7
0.8
0.9
1.0
0.0
0.2
0.4
0.6
0.8
1.0
r = f1f2f3f4
Rejection probability
l
ll
l
l
l
l
l l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l l
l
l
l
l
l
l
l
l l
llll
ll
l
l
l
l
l
l
l
l
ll
l
l l
l
l
ll
ll
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ll
l
l
l
ll
l
l
l l l
l
ll
l
l
l
l
l
l
l
l
l
l
ll
l
ll
llll
l
llll
l
H0
l
Bayes test
Classical BF test
Figure 4.1.: Power functions of the Bayesian t-test and the BF-test for quarterly periodic data (T = 150)
12Franses (1995) considers a similar MC experiment to analyze the empirical power properties of the BF-
test and some other related tests. However the author only simulates two speciÔ¨Åc data generating pro-
cesses in order to compute the empirical sizes and powers of the tests. In contrast, computation of the
whole power function allows to draw a more comprehensive picture of the test characteristics.
13Similar power functions are obtained using larger sample sizes T.
65

values, the Bayes test outperforms the classical BF-test in terms of power. This is most
pronounced if œÅ lies in the stationary parameter region. When approaching the null, i.e.
œÅ ‚Üí1, both procedures perform almost equally in terms of power.
In the second MC experiment the power function of the Bayesian F-test of the hypothesis
HD, i.e. a seasonal (biannual) unit root, is simulated.14 As a classical competitor the
test of Hylleberg et al. (1990) (HEGY) for a (real-valued) seasonal unit root at the œÄ-
frequency is chosen. The HEGY testing approach uses a t-statistic to test the point null of
a real seasonal unit root against a left-sided alternative (see ibid., also Ghysels and Osborn
(2001), p.60, for details). For the subsequent results the Ô¨Ånite sample critical values in
Hylleberg et al. (1990), p.226, have been utilized.15
For the computations of the power functions N = 200 trajectories of the following simple
AR(1) process without a break are generated:
yt = ¬µ + œÜyt‚àí1 + Œµt , Œµt
i.i.d.
‚àºN(0,1) , t = 1...100
(4.21)
with ‚àí1 ‚â§œÜ < 0 with ¬µ = 0.
Figure 4.2 shows a realization of the process (4.21) under the null HD, i.e. for œÜ = ‚àí1, to-
gether with the sample (partial) autocorrelation function (S(P)ACF) and the periodogram.
Note that for œÜ = ‚àí1 the system in (4.21) implies a ‚Äôbounce back‚Äô and hence exhibits
a half-cycle every period. This oscillating behavior induced by an alternating sign can
also be observed when solving the stochastic difference equation for yt recursively, which
yields16
yt =
Ô£±
Ô£≤
Ô£≥
‚àíy0 + ¬µ + ‚àët‚àí1
j=0(‚àí1) j ¬∑Œµt‚àíj
, for t odd
y0 + ‚àët‚àí1
j=0(‚àí1) j ¬∑Œµt‚àíj
, for t even
(4.22)
From Ô¨Ågure 4.2 it is obvious that most of the variation in yt can be attributed to the
biannual frequency œÄ since the periodogram has its maximum at two observations.17 As
14The simulation results for a nonseasonal unit root (HC) are nearly identical and are therefore omitted to
save space.
15All classical tests are conducted on a 5% nominal level of signiÔ¨Åcance.
16Note that the intercept does not translate into a linear time trend here as in the case of a nonseasonal
Random Walk process.
17The periodogram is computed only over the range of [0, S/2] observations, because of the aliasing effect,
cf. BloomÔ¨Åeld (2000).
66

Time
5
10
15
20
25
‚àí4
‚àí2
0
2
4
6
0
1
2
3
4
5
‚àí0.5
0.0
0.5
1.0
Lag
ACF
1
2
3
4
5
‚àí0.8
‚àí0.4
0.0
0.2
Lag
Partial ACF
0.0
0.5
1.0
1.5
2.0
0.01
0.10
1.00
10.00
frequency
spectrum
bandwidth = 0.0115
Figure 4.2.: AR(1) trajectory together with S(P)ACF and estimated power spectrum for T = 100
‚àí1.0
‚àí0.8
‚àí0.6
‚àí0.4
‚àí0.2
0.0
0.2
0.4
0.6
0.8
1.0
f4
Rejection probability
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
H0
l
Bayesian F test
Classical HEGY test
Figure 4.3.: Comparison of power functions for quarterly nonperiodic data (T = 100)
can be seen from Ô¨Ågure 4.3 the Bayesian F-test for a unit root at the œÄ-frequency, given
a PAR(1) model without a break, outperforms the classical HEGY test in terms of power.
The increasing rejection frequencies of the F-test for œÜ < ‚àí1 are due to its two-sided
67

alternative region, whereas the HEGY t-test has a one-sided alternative.18 Observing
the actual sizes of the Bayesian and classical procedure reveals that the former exhibits
a rejection frequency of 3.5% under the null, whereas the latter test with 5.5% almost
exactly follows its nominal signiÔ¨Åcance level.
Summing up, the two Bayesian unit root tests for a PAR(1) model without a break perform
favorable in terms of power when compared to classical competitors. Since the previous
results have been obtained for a given model speciÔ¨Åcation Mi, next also some simulation
evidence for the model averaged versions of the two Bayes tests is presented. These are
used to test the hypothesis HC, i.e. of a nonseasonal unit root. With regard to the empirical
analysis in the next section, the subsequent simulation experiments are conducted using
monthly data (S = 12). As a DGP, a nonperiodic AR(1) process with a break in the
seasonal intercepts at TB = T/2 and without a break is used, where the process with a
break has the following form:
yt =
12
‚àë
s=1
(¬µsDs,t + ¬µ‚ãÜ
s D‚ãÜ
s,t) + œÜ ¬∑yt‚àí1 + Œµt , Œµt
i.i.d.
‚àºN(0,1) , t = 1...T
(4.23)
with ¬µs = 1.5, ¬µ‚ãÜ
s = 0.2,‚àÄs, and the dummy variables Ds,t and D‚ãÜ
s,t are deÔ¨Åned as in section
4.2. In case of no structural break ¬µ‚ãÜ
s = 0,‚àÄs.
For the simulation of the power functions a grid of œÜ-values, with œÜ ‚àà[0.4,1.05], is
used.19 In order to examine the small sample performance of the two Bayes tests, trajec-
tories of length T = 100 are generated from (4.23). This is repeated N = 100 times and
the rejection probabilities are then approximated by the average rejection frequencies. In
Ô¨Ågures 4.4(a) and 4.4(b) the power functions of the two tests are shown for a DGP with
and without a structural break.
From there it is evident that the BMA F-test exhibits quite distinct test properties com-
pared to the BMA t-test in this simulation experiment. The latter test has favorable power
in case of a break and also in case of no break. In particular, the F-test shows an overrejec-
tion (with ‚âà20%) under the null hypothesis HC, i.e. an increased type 1 error, in contrary
to the t-test (with ‚âà0%). The results of other simulation experiments, which are omitted
here to save space, indicate that these overrejections can be attributed to a biased estima-
18As a consequence rejection of yt ‚àºSI(1) does not necessarily imply stationarity.
19In order to save computing time the power functions are approximated at seven œÜ-values.
68

0.4
0.5
0.6
0.7
0.8
0.9
1.0
0.0
0.2
0.4
0.6
0.8
1.0
fs
Rejection probability
l
l
l
l
l
l
l
H0
l
BMA F‚àítest
BMA t‚àítest
(a) With break
0.4
0.5
0.6
0.7
0.8
0.9
1.0
0.0
0.2
0.4
0.6
0.8
1.0
fs
Rejection probability
l
l
l
l
l
l
l
H0
l
BMA F‚àítest
BMA t‚àítest
(b) Without break
Figure 4.4.: Power functions of the BMA F- and t-test for PAR(1) processes with(out) a break (T = 100).
tion of the model probabilities, f (Mi|y), in small samples. This bias mainly depends on
the size of the innovation variance œÉ2 and to some extent also on the speciÔ¨Åcation of the
deterministics in the DGP. To get an impression of this small sample bias, table 4.1 shows
the estimated posterior probabilities for the DGP in (4.23) with m = 1 and m = 0, i.e.
with and without a break.
Table 4.1.: Posterior model probabilities
DGP
No Break (T = 100)
Break (T = 100)
No Break (T = 300)
œÜ
m = 0
m = 1
m = 0
m = 1
m = 0
m = 1
0.40
0.34
0.66
0.19
0.81
0.72
0.28
0.60
0.27
0.73
0.17
0.83
0.77
0.23
0.70
0.38
0.72
0.14
0.86
0.79
0.21
0.80
0.38
0.72
0.15
0.85
0.80
0.20
0.90
0.26
0.74
0.08
0.92
0.75
0.25
0.95
0.24
0.76
0.04
0.96
0.71
0.29
1.00
0.01
0.99
0.01
0.99
0.46
0.54
From table 4.1 it can be observed that the estimated posterior probabilities of m = 0 are
biased towards a model with break when the sample size is small (T = 100), but this bias
69

is reduced when the sample size increases (T = 300).20 What can also be recognized from
the results is that for œÜ ‚Üí1, a process without a break resembles a process with a break,
and thus it becomes harder to discriminate between both. In order to analyze the effect
of the estimated model weights on the outcome of the BMA F-test, the power function is
simulated for the same DGPs as above (see (4.23)), but now a conditional F-test, given
the true model speciÔ¨Åcation, is used. In Ô¨Ågures 4.5(a) and 4.5(b) the resulting power
functions for T = 100 and T = 200 are shown. The Ô¨Ågures suggest that the conditional
0.2
0.4
0.6
0.8
1.0
0.2
0.4
0.6
0.8
1.0
f
Rejection probability
No Break
Break
(a) For T = 100
0.2
0.4
0.6
0.8
1.0
0.2
0.4
0.6
0.8
1.0
f
Rejection probability
No Break
Break
(b) For T = 200
Figure 4.5.: Power functions of the F-test for PAR(1) processes with(out) a break.
Bayesian F-test has favorable power and size properties and that its power increases with
the sample size.
To sum up, the model averaged Bayesian t-test shows favorable power and size properties
compared to classical competitors, and is less affected by a (possibly) biased estimation
of the model weights in small samples. In contrast, the BMA F-test can have serious size
problems in the case of short time series. The latter Ô¨Ånding should be kept in mind when
interpreting the results of the subsequent empirical analysis.
20For larger sample sizes this effect becomes even more pronounced.
70

4.5. Empirical application to monthly
unemployment data
In this section the unit root tests presented above are applied to answer the question, if
there is persistent behavior in the unemployment rates of selected OECD countries. Here
the harmonized monthly unemployment rates21 of 17 OECD countries from January 1999
to March 2012 (T = 159) are used.22 The high level of unemployment in countries of the
European union compared to other countries of the OECD has been an object of inves-
tigation for many years. In the economic literature in principal there are two theoretical
explanations of this phenomenon: the non-accelerating inÔ¨Çation rate of unemployment
(NAIRU) and unemployment hysteresis. The former theory implies the unemployment
rate to follow a trend stationary process, i.e. after an exogenous shock the rate will re-
cover to its long run equilibrium. By contrast hysteresis implies that temporary shocks
have permanent effects on the level of unemployment and thus the underlying stochastic
process has a unit root. This ‚Äôunit root hysteresis‚Äô deÔ¨Ånition is the most common in the
literature on the stochastic properties of unemployment rates (cf. Blanchard and Sum-
mers (1986)). Persistence can be regarded as a special case of the NAIRU concept in the
sense that the unemployment rate follows a stationary process but also has a stochastic
component that is nearly integrated of order one, for example in the present case with the
product of autoregressive coefÔ¨Åcients being close to one (‚ÄôQuasi Random Walk‚Äô).
As a preliminary step of the empirical analysis diagnostic tests are applied to check for the
presence of periodic variation in the level of the series. Here I follow a similar strategy as
used in Boswijk and Franses (1996), p.231, within a classical context. Therefore, Ô¨Årst a
Bayesian PAR(1) model with seasonal intercepts and without a break is estimated, using
the respective posterior means as point estimates and then the null of no periodicity, i.e.
H0 : œÜs = œÜ, ‚àÄs, is tested against the alternative of periodicity H1 : œÜs Ã∏= œÜ, ‚àÉs. This test can
readily be conducted by using the conditional Bayesian F-test23 for the linear hypothesis
21All series are analyzed in logarithmic form.
22The harmonized unemployment rates give the numbers of unemployed persons as a percentage of the
labor force. The labor force consists of employees, the self-employed, unpaid family workers and the
unemployed. The used data set was extracted from OECD sources, see www.oecd.org.
23Note that in a similar manner one could also construct a Bayes test in order to test for periodicity in the
variance of the series, i.e. for seasonal heteroscedasticity, see Franses and Paap (2006), p.40 for a classical
approach.
71

R ¬∑ œÜ = 0 introduced above, with R = [IS‚àí1 , ‚àíŒπ] an S ‚àí1 √ó S matrix of contrasts, IS‚àí1
the identity matrix, and Œπ an S‚àí1 vector of ones. Hence a Bayesian F-test of H0, denoted
FPAR, can be based on an F(ŒΩ1 = S ‚àí1, ŒΩ2 = T ‚àí1 ‚àíd) distribution when S seasonal
intercepts are included in the model, see also Franses (2003), p.104, and Boswijk and
Franses (1996) for a similar result using a classical framework.
Table B.1 (see appendix B) shows the results for the FPAR-test together with the corre-
sponding ‚ÄôBayesian p-values‚Äô. The results indicate that, even by assuming a liberal sig-
niÔ¨Åcance level of 10%, for only 6 out of 17 countries the null of no periodic variation can
be rejected. According to this test there seems to be not much evidence for periodicity in
the OECD unemployment series. In order to check the robustness of the results, I pursue
a strategy similar to the classical approach in Franses (2003), p.116, by using a recursive
testing strategy. Therefore, the Bayesian FPAR-test is computed for rolling subsamples of
the original data. The corresponding F-tests when one year of data is added and removed
successively are called a Bayesian forward and backward recursive FPAR-test, respec-
tively. Figures E.20 to E.28 (see appendix E) show the evolution of the corresponding
Bayesian p-values. Note that for the forward recursive tests the Ô¨Årst time window reaches
from 1/1999 to 12/2002 and the Ô¨Ånal window from 1/1999 to 3/2012, i.e. the whole
time period. In contrast, for the backward recursive tests the Ô¨Årst time window is from
1/1999 to 3/2012, where the last window includes the period from 1/2008 to 3/2012. The
plots indicate that for most countries the sequence of F-tests exhibits some time windows
where there seems to be signiÔ¨Åcant periodicity in the estimated coefÔ¨Åcients on the 5%
signiÔ¨Åcance level with the exception of France, Japan, Norway, Spain and the US.24 On
the grounds of these results the application of a Ô¨Çexible PAR model seems justiÔ¨Åable.
Note that there is some analytical as well as empirical evidence (cf. Franses (2003)) for
starting with a PAR model, which includes the possibility of having S ‚àí1 seasonal unit
roots as well as the zero frequency unit root, instead of Ô¨Årst transforming the data, e.g. by
applying a seasonally differencing Ô¨Ålter ‚àÜS, since this already assumes a certain number
of unit roots.
In table B.3 the test results for a periodic unit root are shown for each OECD country.
In the second column of table B.3 the deterministic model speciÔ¨Åcation is indicated. The
inclusion of seasonal intercepts (‚ÄôDrift‚Äô) or the inclusion of seasonal intercepts together
24In these Ô¨Åve cases a more parsimonious SARMA model could also be Ô¨Åtted.
72

with a seasonal time trend (‚ÄôBoth‚Äô) is suggested on the grounds of visual inspection of
the data. In columns three and four of table B.3 the posterior probabilities, P0, of H0 :
Œ∏ = ‚àë12
s=1 œÜs = 12, using a PAR model with a break and using the BMA version of the
t-test are given, respectively. Columns Ô¨Åve and six show the posterior means and the HPD
regions of œÅ = ‚àè12
s=1 œÜs, given the structural change model with the break date set equal
to the posterior mode T MAP
B
of f (TB| m = 1, p = 1,y).25 The posterior modes are given
in table B.2. In table B.3 it can be seen that for 10 out of 17 of the OECD countries
the null hypothesis of a periodic unit root can not be rejected on the basis of the BMA
posterior probabilities (P0). Among the four countries having the highest probabilities
are Greece, Ireland, Spain and the UK. Almost the same conclusions can be drawn when
using the HPD regions of œÅ. Here for 11 countries the null constraint (4.5b) lies within
the 95%-HPD region, which implies that for these countries the null can not be rejected
when assuming a 5% level of signiÔ¨Åcance.26 The last column also shows the empirical
results from an application of the classical BF test. It is obvious that with the exception of
Finland the null can not be rejected. This Ô¨Ånding can be attributed to the relatively lower
power of the test in small samples as noted in section 4.4, and also to the fact that the test
does not control for a possible structural break.
Given the results of the periodic unit root tests, I test for a possible unit root at the zero
and œÄ-frequency using the model averaged F-test. The results are shown in table B.4 and
suggest that for most of the series for which the hypothesis of a periodic unit root could
not be rejected also the null of a nonseasonal unit root can not be rejected, namely for
France, Germany, Norway, UK and the US. For Belgium, Canada and the series of Japan
the null of a zero frequency unit root can not be rejected when assuming the usual levels
of signiÔ¨Åcance. For the latter two also a relatively high posterior probability of a periodic
unit root can be seen from table B.3 although these probabilities are still below 50%.27
With the exception of Belgium the Ô¨Åndings of table B.4 are in accordance with those in
table B.3 and imply that the unemployment series of the mentioned countries are best
described by a PARI process, i.e. a PAR process for an I(1) series.
25That is, Ô¨Årst the estimate of the break date is computed and then the sampling approach of section 4.3 is
applied, conditional on the estimated break date.
26Note that for Japan the upper bound is only 1.01.
27For Belgium the Ô¨Åndings are not clear. However given the above MC evidence, i.e. that for short series
the F-test exhibits lower power than the test based on P0, it seems justiÔ¨Åable to draw the inferences using
only the latter approach. Then it could be concluded that the series of Belgium is (trend)stationary.
73

The test results are also supported when analyzing each period separately by means of
the HPD regions of the œÜs-coefÔ¨Åcients given in tables B.5 and B.6, respectively.28 An
examination of these tables reveals widespread evidence for hypothesis HA : œÜs = 1, i.e.
a Random Walk in season s (see (4.5a)), since most series yield posterior densities of œÜs
that include the null restriction in their 95% conÔ¨Ådence regions. Finally, as can be seen
from the results of the œÄ-frequency unit root tests (see table B.4), there seems to be no
evidence for seasonal integration in the data.
Summing up, indication of a periodic unit root has been found for the unemployment rates
of Denmark, Greece, Ireland, Netherlands and Spain, which means that these series are
driven by a PIAR process, i.e. a periodically integrated AR process. Note that a periodic
unit root implies that the dynamic response of the unemployment rate to a shock also
depends on the season. Furthermore, for the series of Canada, France, Germany, Norway,
UK and the US the results suggest the existence of a nonseasonal unit root (‚ÄôPARI‚Äô). For
Japan there seems to be some evidence for a stochastic trend, too. For the remaining
series, i.e. those of Australia, Finland, Italy and Sweden no evidence for a (non)periodic
unit root is found. Hence it can be concluded that most of the unadjusted monthly OECD
unemployment rates are most likely (in terms of posterior probability) driven by a unit
root process. More precisely, the empirical results suggest that this process is in most
of the cases associated with a nonseasonal, i.e. zero frequency unit root, which is also
in accordance with the estimates of the spectral densities of the series. This suggests
that the corresponding time series should be modeled by taking (non)periodic Ô¨Årst order
differences (see Ghysels and Osborn (2001), p.153). In the light of economic theory, this
supports theories of unemployment hysteresis, which imply that labor market shocks have
a permanent impact on the level of unemployment.
4.6. Summary and concluding remarks
In this chapter Bayesian testing strategies to test for a periodic unit root with a possible
break at an unknown point in time have been presented. On these grounds also an exact
Bayesian F-test has been proposed in order to test for a unit root at the zero and the œÄ-
28The HPD regions are computed on basis of the model averaged Student-t posterior densities of the œÜs
coefÔ¨Åcients.
74

spectral frequency. All tests have been based on model averaging techniques so that it
is possible to combine evidence from a model with and without a structural break. The
results of simulation experiments to study the performance of the tests indicate that the
model averaged Bayesian F-tests for a zero and a œÄ-frequency unit root can have low
power and increased size in small samples. This feature has been attributed to a small
sample bias of the estimated model posterior probabilities, i.e. the weights of the BMA
tests. In contrast, the test for a periodic unit root has shown to be less sensitive with respect
to the sample size and had better power properties throughout all conducted simulation
experiments. In practice the true data generating process is usually unknown and hence
conditioning on the true parametrization is not possible. Here one either has to select a
particular speciÔ¨Åcation for the analysis or has to resort to model averaging techniques.
With the latter approach it is possible to capture the uncertainty induced through a model
selection step.
In an empirical application these methods have been used to test for unemployment hys-
teresis effects in the monthly unadjusted unemployment rates series of 17 OECD coun-
tries. The results show that in fact most of the analyzed unemployment rates exhibit unit
root behavior. Among the four countries having the highest posterior probabilities of a pe-
riodic unit root are Greece, Ireland, Spain and the UK. Moreover many of these series are
driven by a nonperiodic stochastic trend, which is implied by a zero frequency unit root.
This is also in accordance with a conducted Bayesian pretest for periodicity, which has
shown that there is not much periodic variation in the unemployment series. Moreover no
evidence for (real-valued) seasonal unit roots has been found. With regard to further infer-
ence, e.g. prediction of future data, these empirical Ô¨Åndings suggest that the seasonality
in the monthly OECD unemployment data should in most cases be modeled by seasonal
nonperiodic models, after having applied the relevant differencing Ô¨Ålters. In the light of
economic theory this suggests that there is evidence for unemployment hysteresis in the
respective countries, which implies that labor market shocks have a permanent impact on
the level of unemployment. In future research the Bayesian periodic unit root test could
be extended to allow for heterogeneity in the lag orders ps and the residual variances œÉ2
s .
Another interesting branch of future work would be to extend the above testing procedure
in order to capture also skewness and leptokurtic behavior in the data.
In the next chapter the focus will be on forecasting seasonal time series data. For this
75

purpose, a Bayesian prediction approach based on model averaging will be presented in
the following.
76

Forecasting seasonal time series.
A Bayesian model averaging
approach
5.1. Introduction
Many time series used in economic research exhibit some form of stochastic or determin-
istic seasonality. There are two principal ways to deal with such sort of variation, i.e. to
adjust the data or to model the variation explicitly using seasonal time series models. In
this chapter the latter strategy is pursued with a focus on the prediction of future data. In
the nonseasonal time series literature a large number of alternative models has been pro-
posed for this task, see Ghysels and Osborn (2001), Ghysels et al. (2006) for overviews.
A distinguishing feature of seasonal time series models is the way in which seasonal-
ity is represented. The latter can be modeled to be constant over the different seasons,
s = 1...S, i.e. quarters, months and so on. Another possibility is to allow for seasonal
heterogeneity or periodicity in the stochastic and/or deterministic parts of the data gener-
ating process. As noted by Osborn and Smith (1989) many empirical applications give no
reason for assuming the model parameters to be constant over the seasons, beyond par-
simony and convention. The class of periodic autoregressive moving average (PARMA)
models provides a Ô¨Çexible alternative to other seasonal linear time series models, like sea-
sonal autoregressive moving average (SARMA) models, by allowing the coefÔ¨Åcients to
vary with the seasons, see Ghysels and Osborn (2001), Franses and Paap (2006). In most
economic applications periodic models are assumed to take an autoregressive form and
are known as periodic autoregressive (PAR) models. The latter can be useful in capturing
economic situations where agents show distinct characteristics over the seasons, such as
77

seasonally varying utilities of consumption, see for example Osborn et al. (1988). Im-
portant contributions to the research on PARMA models have been made by Gladyshev
(1961), Pagano (1978), Tiao and Grupe (1980), Vecchia (1985), Osborn (1991), Franses
(1994), Boswijk and Franses (1996), inter alia.
Nearly all works on PARMA models use a classical frame of reference with the exception
of Andel (1983) and Franses and Koop (1997) who choose a Bayesian framework. The
latter authors present a Bayesian approach for prediction and unit root testing in PAR(p)
models. In the subsequent analysis the forecasting approach of Franses and Koop (1997)
is extended in several directions. First, the authors treat the autoregressive lag order p as
Ô¨Åxed and known. In contrast, I treat the lag order as a discrete random variable to which
a prior probability mass is assigned. Because the required number of autoregressive coef-
Ô¨Åcients is in general p¬∑S, lag order selection may be more crucial in the context of PAR
models than in constant-parameter AR models, see also Ghysels et al. (2006). Second,
Franses and Koop (1997) allow for the possibility of one structural break in the seasonal
intercepts at unknown time and then average out this nuisance parameter. In the subse-
quent analysis I allow for one structural break in the seasonal intercepts and/or seasonal
time trends, but treat the occurrence of a break, or the number of breaks m = 0,1, as an
additional random parameter. Then the autoregressive lag order and the number of struc-
tural breaks are used as model indicators in order to identify different candidate models,
Mi, in the model space. Most importantly, instead of resorting to a model selection ap-
proach by picking out a single model for inference, as for example in Franses and Koop
(1997), a prediction approach for PAR models with an unknown number of lags and an
unknown number of structural breaks based on model averaging is presented.
There is a growing literature concerned with model averaging. Seminal contributions
to Bayesian model averaging are Madigan and Raftery (1994), Draper (1995), Raftery
et al. (1997), and for a review of the literature Hoeting et al. (1999), Raftery and Zheng
(2003). Some econometric BMA applications include Fernandez and Steel (2001), Hong
and Preston (2012), inter alia. See for example Hjort and Claeskens (2003), Hansen
(2007) for frequentist approaches and additional references. As argued by some authors
(cf. Raftery et al. (1996)) model selection procedures ignore the uncertainty induced
through a model selection step and thus underestimate uncertainty about the quantities of
interest, as for example future observations. Hence accounting for model uncertainty by
78

using a model averaging approach may improve out-of-sample predictive accuracy. With
regard to forecasting this seems to be a natural approach to capture model uncertainty by
including all models Mi under consideration into a (super) model.
Further, in appendix H it is shown that the joint posterior predictive distribution of a PAR
model is given by the product of Student-t densities, viz. the one-step ahead posterior
predictive distributions given the preceding forecasts. Since no analytical expressions for
the required marginal posterior predictive distributions of the yT+k, k = 1...K, exist, and
further since the possibility of a structural break at an unknown point in time introduces
an additional nuisance parameter, which can not be integrated out analytically, a Markov
chain Monte Carlo approach based on data augmentation (see Tanner and Wong (1987))
is presented. By using the model posterior probabilities as weights in order to capture un-
certainty a model averaged posterior predictive distribution is computed to forecast future
data. The empirical results presented in this chapter indicate that the BMA prediction
approach is able to improve forecasting accuracy when compared to a model selection
approach.
After having introduced the Bayesian PAR (BPAR) model in section 5.2 the Gibbs sam-
pling algorithm for parameter estimation and sampling future values is presented in sec-
tion 5.3. In order to examine the forecasting performance under different data generating
processes the results of a simulation study are given in section 5.4. Here also a Bayesian
test is introduced in order to compare the predictive ability of different forecasting models.
In section 5.5 an empirical application of the proposed prediction approach is presented.
Here the monthly unemployment rates of the 16 federal states of Germany and of East-
and West-Germany are predicted 12-months ahead. Finally, section 5.6 then summarizes
the results and concludes.
5.2. Periodic autoregressive models with one break
In the following I focus on PAR models with at most one structural break in the deter-
ministic component(s) at an unknown point in time. Similar models have been used for
example in Franses and Koop (1997) and Franses (2003). In case of a structural break in
the periodic intercepts and time trends the model has the following general form, which
79

is reproduced here from section 4.2 for the ease of reference:
yt = (
S
‚àë
s=1
ps
‚àë
i=1
œÜi,s ¬∑Ds,t ¬∑yt‚àíi) + Œªt + Œµt , Œµt
i.i.d.
‚àºN(0,œÉ2
s )
(5.1a)
Œªt =
S
‚àë
s=1
 (¬µs + Œ±s ¬∑œÑt) ¬∑Ds,t + (¬µ‚ãÜ
s + Œ±‚ãÜ
s ¬∑œÑt) ¬∑D‚ãÜ
s,t

(5.1b)
with t = 1,...,T observations and s = 1,...,S seasons.
As in the analysis of section 4.2, let st = 1 + [(t ‚àí1)mod S] denote the season of ob-
servation t, and let TB ‚àà]ps + Œ∫, T ‚àíŒ∫] be the unknown break point, where Œ∫ denotes
the Ô¨Årst and last ten percent of observations in the sample, which are truncated in or-
der to avoid possible endpoint problems in the identiÔ¨Åcation of TB. Then the seasonal
dummy variables in (5.1) are given by Ds,t = 1, if st = s ‚àßt ‚â§TB, otherwise 0, and
D‚ãÜ
s,t = 1, if st = s ‚àßt > TB, and 0 otherwise. Last, œÑt in (5.1b) denotes the value of the
linear time trend at time t. Further it is assumed that p = ps and œÉ2 = œÉ2
s , ‚àÄs, i.e. a homo-
geneous autoregressive lag order across the seasons and no seasonal heteroscedasticity.
The above periodic autoregressive structural break model can be expressed more conve-
niently in matrix form (see section 4.2 for deÔ¨Ånitions):
y
=
X¬∑œÜ + Z¬∑Œ¥ + Œµ =

X ... Z

T‚àíp √ó (4+p)¬∑S
¬∑
 
œÜ
Œ¥
!
(4+p)¬∑S √ó 1
+ Œµ = eX¬∑B+ Œµ
(5.2)
where in the following d ‚â°(4+ p) ¬∑S.
In order to draw any inference within a Bayesian framework, the speciÔ¨Åcation of prior
distributions for the unknown parameters is required. These are introduced in the next
section.
5.2.1. Specication of prior distributions
Within a Bayesian frame of reference a priori knowledge with respect to the quantities of
interest can be imposed. For the analysis below I assume a conjugate normal prior for the
80

regression coefÔ¨Åcients and express prior ignorance with respect to all other parameters,
i.e.
f (B | œÉ2) = Nd(B0 , œÉ2V)
(5.3a)
f (œÉ2) ‚àù1/œÉ2 , with œÉ2 > 0
(5.3b)
f (TB) ‚àù
1
T ‚àíp‚àí2Œ∫ , with Œ∫ + p < TB ‚â§T ‚àíŒ∫
(5.3c)
with prior hyperparameters B0 = (œÜ‚Ä≤
0, Œ¥ ‚Ä≤
0)‚Ä≤ and V. For the covariance matrix of the re-
gression coefÔ¨Åcients
V =
 
c1 ¬∑Id1
0
0
c2 ¬∑Id2
!
(5.4)
is chosen, where c1 and c2 are Ô¨Åxed scalars and Id j, j = 1,2, denote identity matrices
of dimensions conformable with the matrices X and Z in (5.2), cf. Franses and Koop
(1997).1 Further Œ¥0 = 0 is imposed to express ignorance with respect to the prior means
of the seasonal dummy and trend coefÔ¨Åcients. For the prior means of the autoregressive
parameters œÜ0 = Œπ is assumed, with Œπ a vector of ones, since experience shows that in
many practical applications of PAR models the estimated autoregressive coefÔ¨Åcients are
close to one. A similar observation has been made by other authors, cf. Franses and
Koop (1997). However it should be noticed that for long time series this prior constraint
is dominated by the sample information.
Let mmax and pmax denote the maximum number of structural breaks and the maximum
number of autoregressive lags, respectively. In the subsequent analysis the number of
breaks, which for simplicity is restricted to m = {0,1}, and the number of autoregressive
lags are used as model indicators in order to identify different candidate models, Mi =
(p,m).2 Thus the discrete space of possible models, denoted by Œì in the following, is
given by the cartesian product Œì = {1,..., pmax} √ó {0,1}. In order to express ignorance
with respect to the model complexity, i.e. the size of the model, I use the following joint
1In the empirical analysis below c1 and c2 in (5.4) are both set equal to 100 in order to express lack of prior
knowledge with regard to the variation of the regression coefÔ¨Åcients.
2In principle, the break location, TB, could also be included in the deÔ¨Ånition of Mi. Instead it is treated as a
nuisance parameter here and is averaged out.
81

prior distribution for the model indicators
f (Mi) ‚àù1/#Œì
(5.5)
where #Œì denotes the cardinality of the set Œì.
One could argue that imposing a Ô¨Çat prior over the space of admissible models is in fact
informative, since more complex models are assigned the same prior weight as simpler
models and thus one should use a prior that assigns less weight to more complex models,
see for example Phillips (1991b), Phillips (1991a) for a discussion of this issue in the
context of unit root testing. However for the analysis below I restrict the model space to
mmax = 1 and pmax = 12, which implies putting zero prior weight to more complex model
combinations. Note that pmax = 12 implies considering also annual lag structures.
As a speciÔ¨Åc model Mi can be identiÔ¨Åed by its (p,m)-combination, and a corresponding
break date in case of m = 1, I condition on Mi in the following to indicate inference
under a particular model speciÔ¨Åcation. Combining the above prior distributions with the
likelihood function according to Bayes‚Äô Theorem, it is straightforward to show that the
joint posterior density function of all unknown quantities, given the break date TB, has the
form of a Normal-Inverse-Gamma-2 distribution, see Bauwens et al. (1999). However,
when not conditioning on the discrete-valued break point, the joint posterior becomes a
mixture of discrete and continuous densities. Of course this case only arises when m = 1.
5.2.2. Model augmentation for prediction
The main objective in a Bayesian approach to forecasting is to derive the predictive den-
sity function, f (eyK|y), which does not depend on the unknown parameters, and contains
all information about the unobserved (‚Äômissing‚Äô) future values in eyK, given knowledge of
the past observations y (see Zellner (1971), Judge et al. (1985)). In order to predict future
values yT+k, k = 1...K, I deÔ¨Åne a K-vector of eyK-values and their corresponding lags for
82

s = 1...S and k = 1...K:
eyK
‚â°
[ yT+1 ,...,yT+K ]‚Ä≤
eŒµK
‚â°
[ ŒµT+1 ,...,ŒµT+K ]‚Ä≤
ey(s)
K‚àí1
‚â°
[ Ds,T+1 ¬∑yT, Ds,T+2 ¬∑yT+1, ... ,Ds,T+K ¬∑yT+K‚àí1 ]‚Ä≤
...
ey(s)
K‚àíp
‚â°
[ Ds,T+1 ¬∑yT+1‚àíp, Ds,T+2 ¬∑yT+2‚àíp, ... ,Ds,T+K ¬∑yT+K‚àíp ]‚Ä≤
XK
‚â°
[ ey(1)
K‚àí1, ... ,ey(1)
K‚àíp, ..., ey(12)
K‚àí1, ... ,ey(12)
K‚àíp ]
ZK
‚â°
[ DK, D‚ãÜ
K, DK ¬∑œÑK , D‚ãÜ
K ¬∑œÑK ]
Finally, stacking all stochastic and deterministic future components as
f
WK
K √ó (4+p)¬∑S
‚â°
[ XK
... ZK ]
(5.6)
yields the following prediction equations
eyK
=
f
WK ¬∑B+eŒµK , eŒµK
i.i.d.
‚àºNK(0, œÉ2IK)
(5.7)
where it is assumed that future observations are generated by a similar process as the
observed data.
The joint probability density function (pdf) of all unknown quantities, given the data, can
be factorized as follows:3
3In the following the Ô¨Årst p observations are used as initial values y0. Thus I work with the approximate
instead of the exact likelihood function, see Bauwens et al. (1999), p.134 f. The conditioning on y0 is
suppressed subsequently.
83

f (eyK,B,œÉ2,TB| Mi, eX, f
WK, y) = f (B,œÉ2,TB| Mi, eX, y) ¬∑ f (eyK| Mi,B,œÉ2,TB,f
WK, y)
‚àùf (B| œÉ2,TB, Mi)¬∑ f (œÉ2) ¬∑ f (TB| Mi) ¬∑
f (y| Mi,B,œÉ2,TB, eX)¬∑ f (eyK| Mi, B,œÉ2,TB,f
WK, y)
(5.8)
Henceforth conditioning on eX and f
WK is omitted. As already noted, the major task here is
to obtain the marginal predictive posterior distributions f (yT+k| Mi, y) for conducting k-
step ahead forecasts, k = 1...K. Let for convenience be Œæ k ‚â°(B‚Ä≤, œÉ2, TB, eyK \{ yT+k})‚Ä≤ ‚àà
Œû, with Œû = Rd √ó R+ √ó N]Œ∫+p; T‚àíŒ∫] √ó RK‚àí1. Then the posterior predictive density of
the scalar random variable yT+k, k = 1...K, under Mi, is obtained by integrating out all
other parameters Œæ k from the joint posterior (see Geweke and Whiteman (2006)):4
f (yT+k | Mi, y)
=
Z
Œû f (Œæ k| Mi, y)¬∑ f (yT+k | Œæ k, Mi, y) ¬∑dŒæ k
(5.9)
As a point estimator of the unknown future value yT+k, k = 1...K, the posterior predic-
tive mean of (5.9), E(yT+k| Mi, y), is chosen. At this point it should be noted that the
joint posterior predictive density of a periodic autoregressive model is not the standard
K-variate Student-t density as in the case of a normal (nonrecursive) linear regression
model, discussed in Zellner (1971), p.73, also Judge et al. (1985), p.123. This has been
emphasized by Broemeling and Land (1984) for the case of a nonperiodic autoregressive
model of order p. Moreover, the latter authors establish that for K ‚â•1 the joint poste-
rior predictive density is given by the product of K univariate t-densities, viz. a marginal
for yT+1 and K ‚àí1 conditional t-densities. In appendix H it is shown that this fact also
applies to the more general case of periodic autoregressive models of order p. Further
the marginal posterior predictive densities (5.9) are not known analytically for K > 1 (see
Broemeling and Land (1984), p.1319, Koop et al. (1995), Bauwens et al. (1999), p.138).
This essentially follows from the fact that the joint posterior predictive density of eyK, after
integrating out all other parameters, is not a multivariate Student-t density (see Broemel-
4In case of the discrete break date TB the corresponding integration is in fact a summation.
84

ing and Land (1984), p.1319). Since allowing for a structural break at an unknown point
in time introduces an additional nuisance parameter in the likelihood function, which can
not be integrated out analytically, an MCMC approach in order to obtain these densities
and also to get point estimates for the unknown parameters is presented in the following.
5.3. Markov chain Monte Carlo approach
Generating multistep forecasts by means of Markov chain Monte Carlo techniques al-
lows to directly exploit the structure of the recursive prediction equations (5.7). In the
following a Gibbs sampler for generating random draws from (5.8) and for obtaining the
predictive densities in (5.9) is presented. Since the future values yT+k are treated as la-
tent variables (or missing data), the subsequent MCMC algorithm can be perceived as a
data augmentation approach, see Tanner and Wong (1987). The basic sampling scheme is
outlined in the following.
85

Algorithm 2 : Data augmentation
Step 1: Set iterations on j = 1 and initialize T (0)
B
,B(0),œÉ2(0),ey(0)
K
randomly or
deterministically.
Step 2: Draw a new break date T ( j)
B
from a multinomial posterior distribution
f (T ( j)
B
| B( j‚àí1),œÉ2( j‚àí1), ey( j‚àí1)
K
, Mi, y) on the sample space TB ‚àà]Œ∫ + p, T ‚àíŒ∫]
Step 3: Draw a new random vector B( j) from a multivariate normal posterior
distribution f (B( j) | T ( j)
B ,œÉ2( j‚àí1), ey( j‚àí1)
K
, Mi, y)
Step 4: If stationarity should be imposed, accept a candidate draw œÜ ( j) in B( j),
if |det(Œ¶0 ‚àíŒ¶1 ¬∑z)| > œâ for z = 1 , œâ > 0, otherwise return to step 3
Step 5: Draw new œÉ2( j) from an inverse gamma posterior distribution
f (œÉ2( j) | T ( j)
B , B( j), ey( j‚àí1)
K
, Mi, y)
Step 6: Draw a new yT+k( j) from a univariate normal posterior distribution
f (y( j)
T+k | œÉ2( j), T ( j)
B , B( j), ey( j‚àí1)
K
\{yT+k}, Mi, y) , k=1...K
Step 7: Compute the marginal posterior predictive densities
f (y(g)
T+k | Mi, y) ‚âÉ1
J ‚àëJ
j=1 f (y(g)
T+k | Œæ ( j)
k , Mi, y) , k = 1...K, g = 1...G
Step 8: Set j = j + 1, return to step 2.
with j = 1,...,J Gibbs runs and Œæ ( j)
k
‚â°(B‚Ä≤( j), œÉ2( j), TB( j), ey( j)
K \{yT+k})‚Ä≤.
The sampling scheme shows how to draw from the joint posterior distribution (5.8). In
step 1, initial values for the Markov chain have to be chosen, where for B and œÉ2, the
corresponding least squares estimates could be used; for the break date TB an initial
value can be drawn from the uniform prior distribution and the unknown future val-
ues, yT+k, k = 1...K, could be initialized with the sample mean of y. In step 2, gen-
erate a new break date from a full conditional multinomial posterior distribution M(n =
86

T ‚àíp‚àí2Œ∫; Œ∏p+Œ∫+1,...,Œ∏T‚àíŒ∫) with n classes and class probabilities given by
Œ∏t =
exp
n
‚àí1
2œÉ2(yt ‚àíext ¬∑B)2o
‚àëT‚àíŒ∫
t=p+1+Œ∫ exp
n
‚àí1
2œÉ2(yt ‚àíext ¬∑B)2
o
, for t = p+ Œ∫ + 1,...,T ‚àíŒ∫
where ext and yt denote the t-th row of the matrix eX and the t-th element of the vector y,
respectively.
Then in the next step, given a new break date TB, a new candidate vector B is generated
from a full conditional multivariate normal distribution with mean vector ¬µB = R‚àí1(eX‚Ä≤ ¬∑
y + V‚àí1B0 + f
W‚Ä≤
K ¬∑eyK) and covariance matrix Œ£B = œÉ2 ¬∑ R‚àí1, where R ‚â°V‚àí1 + eX‚Ä≤eX +
f
W‚Ä≤
Kf
WK. It is important to note here that since the matrix eX and also some parts of the
matrix f
WK depend on the unknown break point through their deterministic components,
these matrices have to be updated accordingly after having drawn a new break date in
sampling step 2.
Next in step 5, the innovation variance œÉ2 is updated by drawing from a full conditional
IG2(a‚ãÜ,b‚ãÜ) density, given all other parameters, with shape parameter a‚ãÜ= T ‚àíp + d +
K + 2 and scale parameter b‚ãÜ= (y ‚àíeX ¬∑ B)‚Ä≤ ¬∑ (yK ‚àíeX ¬∑ B) + (eyK ‚àíf
WK ¬∑ B)‚Ä≤ ¬∑ (ey ‚àíf
WK ¬∑
B)+(B‚àíB0)‚Ä≤V‚àí1(B‚àíB0). After having drawn a new value for the innovation variance,
a new trajectory {yT+1,...,yT+K} is generated. Therefore, in step 6, new candidates for the
unknown future values yT+k, k = 1...K, are successively drawn from the K full conditional
univariate normal distributions, with mean e¬µk = W(k) ¬∑B, and variance œÉ2 given from step
5, where W(k) denotes the k-th row of the matrix f
WK.
In order to facilitate the integrations in (5.9) additional Monte Carlo integration steps, for
k = 1...K, using the Gibbs sampling draws Œæ ( j)
k , j = 1...J, are conducted. For this purpose
Ô¨Årst deÔ¨Åne a grid of {y(g)
T+k, g = 1...G} values over the support of yT+k, for k = 1...K. Then
the posterior ordinates can be approximated as in step 7 above, see Chib (1995). Note that
the marginalized posterior ordinates are needed for the subsequent model averaging.
Next consider a Ô¨Ånite set of candidate models M = {M1, ...,MI}. As already noted, each
candidate model Mi is associated with a vector of model indicators (p,m). Attaching prior
probability mass, f (Mi), to each candidate model we can average over the model space
87

as (see Hong and Preston (2012)):
f (yT+k| y)
=
I
‚àë
i=1
f (yT+k | Mi, y) ¬∑ f (Mi| y) , k = 1...K
(5.10)
with (5.10) being approximated on the same grid of y(g)
T+k values, g = 1...G, as used in
sampling algorithm 2.
Further if one wants to impose stationarity on the PAR(p) model in (5.2), the posterior
draws of the subvector œÜ in B can be constrained by using an additional accept-reject
step in step 4. Note, that although PAR models are nonstationary by construction,5 a
stationarity condition can be stated by using a multivariate model representation as in
Tiao and Grupe (1980). By writing the univariate PAR(p) model (5.2) as an S-dimensional
vector autoregressive model of order P (‚ÄôVAR(P)‚Äô), with P = 1+ ‚åä(p‚àí1)/S‚åã, the usual
stability condition of VAR models in terms of the characteristic polynomial with roots z,
can be used (see section 3.2, also Hamilton (1994), p.259, for details). By restricting the
lag order to pmax = S in the following, the stationarity condition of a VAR(1) model is
given by
det(Œ¶0 ‚àíŒ¶1 ¬∑zS) Ã∏= 0
for |z| ‚â§1
(5.11)
see section 3.2 for the deÔ¨Ånition of the Œ¶ matrices.
Since for a unit root process, i.e. with z = 1, the determinant in step 4 will be close to
zero in practice, an arbitrarily small value œâ > 0, e.g. œâ = 0.05 can be chosen here as a
benchmark value.
The major focus of the presented forecasting approach lies on the model averaged predic-
tive distributions in (5.10). It can be shown that the means of these mixture distributions
minimize the prediction mean squared error and are in this sense optimal, see Raftery and
Zheng (2003), Theorem 4, p.5. In order to compute the BMA predictive distributions in
(5.10) the posterior probability of model Mi, i = 1...I, is needed, which can be obtained
5This can easily be checked from the Ô¨Årst two moments of a PAR process, see Ghysels and Osborn (2001),
Franses and Paap (2006) for details.
88

from Bayes‚Äô Theorem:
f (Mi| y)
=
f (y| Mi) ¬∑ f (Mi)/ f (y)
(5.12)
In case of a structural change model, i.e. with Mi = (pi, mi = 1), the Ô¨Årst expression in
(5.12) is the marginal likelihood under model Mi:
f (y| Mi) =
T‚àíŒ∫
‚àë
TB=p+Œ∫+1
Z
...
Z
f (y| B,œÉ2,TB, Mi) ¬∑ f (B, œÉ2,TB| Mi) ¬∑dB¬∑dœÉ2
(5.13)
and the normalizing constant in (5.12) is equal to
f (y)
=
I
‚àë
i=1
f (Mi) ¬∑ f (y| Mi)
(5.14)
Note that all d + 1 integrals in (5.13) can be solved analytically due to the conjugate
framework. In case of a model without a structural break, i.e. with Mi = (pi, mi = 0),
the summation over all possible change points in (5.13) can of course be omitted and
the marginal likelihood, under model Mi, then has the well-known form of a multivariate
Student-t density of dimension T ‚àíp, see Judge et al. (1985), p.128, also Hamilton (1994),
p.368.
5.4. Monte Carlo analysis
Next the results of four Monte Carlo (MC) experiments are presented in order to compare
the forecasting performance of a conditional BPAR model with other candidate forecast-
ing models. In order to save computing time the computations are conducted for a speciÔ¨Åc
model Mi and are in this sense conditional. To infer if the reported differences in predic-
tive accuracy are also statistically signiÔ¨Åcant, a simple Bayesian test is presented. The
simulated out-of-sample forecasts of the BPAR model are compared to a nonseasonal AR
model, a seasonal AR (SAR) model (see Box et al. (2008), Ghysels and Osborn (2001))
89

and a seasonal (or periodic) means model (abbreviated by ‚ÄôPMEANS‚Äô in the following).6
A nonseasonal AR model is chosen, because PAR models can be perceived as seasonally
varying generalizations of AR models. In this sense an AR model serves as a benchmark
with constant parameters. Similarly, a PMEANS model serves as a benchmark for the
case of deterministic seasonality in the following, cf. Osborn and Smith (1989).
The comparison of forecasting models is usually done on the basis of a risk function
(see Diebold and Mariano (1995), Inoue and Kilian (2006), also Geweke and Whiteman
(2006), p.20). The most prominent measures of forecasting accuracy in this context are
the prediction mean squared error (PMSE), assuming a quadratic loss structure, and the
mean absolute percentage error (MAPE),7 assuming an absolute valued loss function, see
Meese and Rogoff (1983), Stock and Watson (1999), among others, for applications. As
a Bayesian forecasting rule the posterior predictive expectation, byT+k ‚â°E(yT+k| Mi, y),
is used in the following. When expressed as a function of the forecasting horizon the
(cumulated) PMSE and MAPE of a simulated out-of-sample K-step ahead forecast are
given by
PMSE(K)
=
K
‚àë
k=1
E (byt+k ‚àíyT+k)2
(5.15a)
MAPE(K)
=
K
‚àë
k=1
E (|(byt+k ‚àíyT+k)/yT+k|)
(5.15b)
Here yT+k is the actual realization of the process at time T + k, the k-step ahead forecast
is denoted by byT+k, and the expectation is taken with respect to y.
5.4.1. A Bayesian sign test for comparing predictive accuracy
To be able to test if the realized loss differences measured by a loss function g(yt,byt),
e.g. a quadratic loss function g(yt,byt) = (byt ‚àíyt)2, are also statistically signiÔ¨Åcant some
authors propose tests to evaluate predictive accuracy, cf. Diebold and Mariano (1995),
Giacomini and White (2006), Clark and West (2007). To be consistent here, a Bayesian
6Here the variable of interest is simply regressed on a set of S dummy variables Ds,t, which equal one if
observation t is associated with season s.
7Note that the MAPE for a speciÔ¨Åc horizon k does not depend on the scale or dimension.
90

analogue to the sign test proposed in Diebold and Mariano (1995) is introduced. For this
test the latter authors report favorable power and size properties on the basis of MC ex-
periments. Furthermore this test is applicable not only in case of quadratic loss structures,
but also to non-quadratic and relative loss functions as assumed for the calculation of the
MAPE in (5.15) and thus matches the requirements here. Given a realized sequence of
loss-differentials, dt ‚â°[g(bŒµit) ‚àíg(bŒµjt)], under forecasting model i, j = 1...3, with predic-
tion error bŒµit = yt ‚àíbyit under model i, a test for comparing predictive accuracy can be
constructed on the signs of a sequence of loss-differentials {dt}T
t=1, with 1(dt>0)(dt) = 1
in case of a positive sign, and 0 otherwise. Therefore the null hypothesis of a zero median
loss-differential, i.e.
H0 : Med(g(bŒµit)‚àíg(bŒµjt)) = 0
(5.16)
can be tested, which implies P(g(bŒµit) > g(bŒµ jt)) = P(g(bŒµit) < g(bŒµ jt)) or equivalently
P(1(dt>0)(dt) = 1) = 0.5, see Diebold and Mariano (1995).8
A Bayesian analogue can be constructed by assuming that each observation 1(dt>0)(dt),
t = 1...T, is generated according to a Bernoulli distribution with unknown (‚Äôsuccess‚Äô)
probability for a positive loss-differential sign, œÄ ‚â°P(1(dt>0)(dt) = 1), and that œÄ has
a Beta prior density, œÄ ‚àºBe(Œ±, Œ≤), with prior mean equal to Œ±/(Œ± + Œ≤). Let x ‚â°
‚àëT
t=1 1(dt>0)(dt) denote the number of positive signs in the sequence,9 which is a sufÔ¨Å-
cient statistic for œÄ, therefore conditioning on x instead of the data does not change the
validity of the subsequent probability statements, see Monahan and Boos (1992), p.272.
By conjugation it immediately follows that the posterior density of œÄ, that is the proba-
bility for a positive loss-differential sign, also behaves according to a Beta distribution,
i.e. œÄ|x ‚àºBe(Œ± +x; Œ≤ +T ‚àíx), with posterior mean equal to (Œ± +x)/(Œ± +Œ≤ +T). Of
course the null could also be tested against more informative alternatives like H1 : œÄ > 0.5,
which postulates the dominance of model j over model i in dt ‚â°[g(bŒµit)‚àíg(bŒµjt)], and vice
versa.10
8Note that the sign test presumes i.i.d. observations, an assumption that needs to be checked in practice.
9This is the S2-test statistic of Diebold and Mariano (1995), p.255, which follows a Binomial distribution
with parameters T and œÄ = 0.5 under the null hypothesis.
10A more elaborated Bayesian approach for the analysis of regression errors is presented by Zellner (1975)
(see also Chaloner and Brant (1988) for a similar approach), which has been adopted by Lubrano (2001)
in order to test for ARCH(1) effects and non-linearities in time series.
91

Note that in the subsequent computations of the multistep ahead forecasts, the considered
prediction horizons are at most two years. Thus we have to deal with quite short loss-
differential sequences.11 For this reason the hyperparameters of the Beta prior have to
be chosen with some care, see Robert (2007), p.124. Therefore four different parame-
terizations of the Beta prior are stated next, which will be used throughout the following
simulation study in order to check the robustness of the posterior results with respect to
the prior speciÔ¨Åcation.
If prior ignorance with respect to the unknown probability œÄ should be expressed, nonin-
formative priors can be chosen. Here, for example, Haldane‚Äôs prior f (œÄ) ‚àù[œÄ ¬∑(1‚àíœÄ)]‚àí1
can be used, which appears to be the limit of an unnormalized Beta prior when Œ± and Œ≤
go to zero.12 The latter choice then leads to a Be(x, T ‚àíx) posterior distribution with
mean x/T, which is also the maximum likelihood estimator of œÄ. Another popular non-
informative prior is the Jeffreys prior f (œÄ) ‚àù
p
I(œÄ), with I(œÄ) the Fisher information,
which in the present case can be shown to be f (œÄ) ‚àù[œÄ ¬∑ (1‚àíœÄ)]‚àí1/2, i.e. proportional
to a Be(0.5,0.5) density. The third prior, used in the following, is the ‚ÄôBayes‚Äô or ‚ÄôBayes-
Laplace‚Äô prior, f (œÄ) = Be(1,1), which assigns a density of one to each value of œÄ, cf.
Berger (1980), p.89, Robert (2007), p.127. These priors are shown in Ô¨Ågure F.29 of ap-
pendix F. As can be observed from Ô¨Ågure F.29, Jeffreys‚Äô and Haldane‚Äôs prior both assign
the largest density values to the end points zero and one. However, since we are interested
in testing H0 : œÄ = 0.5, this could lead to an increase in the type I or type II error of the test
and therefore in addition a more informative Be(1.01,1.01) prior is used (see the lower
right panel in Ô¨Ågure F.29), which gives more weight to moderate œÄ values.13 Note that
the null restriction is imposed a priori by choosing Œ± = Œ≤, which implies a prior mean of
œÄ equal to 0.5. Now an optimal Bayesian decision rule œï(x) under a ‚Äô0-1‚Äô loss function
(see Robert (2007), proposition 5.2.2, p.225.) is given by
œï(x) =
(
0 ,
if P(H0|x) ‚â•0.5
1 ,
otherwise
(5.17)
11For example, in the MC experiments presented below, 2-years ahead forecasts using quarterly data are
conducted and thus T = 8, whereas in the empirical application of section 5.5, 1-year ahead forecasts
using monthly data are considered and thus the length of the realized loss-differential sequences is T = 12.
12Here for all computations Œ± = Œ≤ = 10‚àí10 is used.
13Note that in general according to the Bernstein von Mises theorem the posterior distribution for an un-
known quantity is effectively independent of the prior distribution once the amount of information sup-
plied by the data is large enough, see van der Vaart (1998), p.140.
92

where 1 means rejection of the null hypothesis and P(H0|x) denotes the posterior proba-
bility of the latter.
Since the hypothesis of interest is a precise hypothesis, i.e. with zero prior probabil-
ity mass, the continuous Beta prior has to be modiÔ¨Åed in order to assign positive prior
probability mass to the singleton under H0 (see Berger and Sellke (1987), Berger and De-
lampady (1987), also Pereira and Stern (1999) for a different approach). Therefore the
following mixed prior is utilized
f (œÄ) = œâ0 ¬∑1H0(œÄ) + (1‚àíœâ0) ¬∑ f1(œÄ) ,
(5.18)
with œâ0 > 0, 1H0(œÄ) an indicator function and f1(œÄ) one of the priors discussed above.14
By an application of Bayes‚Äô Theorem using the mixed prior in (5.18) the posterior proba-
bility of the null hypothesis can be calculated as
P(H0|x) =
f (x|œÄ0)¬∑œâ0
R 1
0 f (x|œÄ) f (œÄ)dœÄ
=
f (x|œÄ0) ¬∑œâ0
œâ0 ¬∑ f (x|œÄ0) + (1‚àíœÄ0) ¬∑m1(x)
(5.19a)
with m1(x) =
Z
{œÄ:œÄÃ∏=0.5} f (x|œÄ) ¬∑ f1(œÄ)¬∑dœÄ
(5.19b)
In order to check the performance of the Bayes test in (5.17) the posterior probability
P(H1|x) = 1 ‚àíP(H0|x) is computed for each of the four Beta priors. To examine fur-
ther the inÔ¨Çuence of the sample size T on the subsequent posterior results, P(H1|x) is
calculated for a sequence of x ‚àà{0,...,T} values, assuming T = 8 and T = 60.
For a given sample size T the posterior probability P(H1|x) can be represented as a func-
tion in x, or x/T, i.e. p(x0) ‚â°P(H1|x = x0;T), for x0 = 0,...,T. Under H0 : œÄ0 = 0.5
we would expect that, for given T, the posterior probability of H1 would decrease when
x
T ‚ÜíœÄ0 and increase otherwise. The results shown in Ô¨Ågures F.30 and F.31 (see appendix
F) conÔ¨Årm that this is the case for most of the considered priors. The Ô¨Ågures suggest that,
with the exception of the results under Haldane‚Äôs prior, all speciÔ¨Åcations yield quite com-
parable results. Moreover even for sequences of length T = 60 the posterior probabilities
of H1 using Haldane‚Äôs prior are still equal to 0 within a large subset of the domain of p(x),
which would lead us to favor the null even for extreme, i.e. very small (or large) numbers
14Here œâ0 = 0.5 is chosen.
93

of positive signs, x, implying a large type II error. Therefore, in the applications below all
conclusions are drawn on the basis of one of the other three posteriors.
As pointed out by Diebold and Mariano (1995) comparing the predictive accuracy of
different models constitutes a multiple hypotheses testing problem. In the frequentist
case the overall size of the test, Œ±‚ãÜ, has to be adjusted by a Bonferonni correction, Œ±‚ãÜ/n,
where n denotes the number of tests. However the Bayesian sign test has not been derived
under the assumption of a Ô¨Åxed type I error, as in a Neyman-Pearson testing framework,
hence another strategy is pursued in the following. Note that in the subsequent analysis
interest mainly centers on testing joint hypotheses of the form
H0 : œÄ1,2 = œÄ1,3 = 0.5
(5.20)
given that model 1 has exhibited the lowest relative loss among, for example, three com-
peting models.
Here œÄi, j denotes the parameter of interest in a pairwise comparison of the models i and
j, respectively. Hence Ô¨Årst the model with the lowest PMSE is detected (‚ÄôModel 1‚Äô) and
then (5.20) is tested accordingly. This a union-intersection testing problem (see Casella
and Berger (2002), p.380) and therefore (5.20) is rejected, if any of the single hypotheses
H0,Œ≥ : œÄŒ≥ = 0.5, with Œ≥ ‚àà{(1,2),(1,3)}, is rejected using the decision rule (5.17). This
testing strategy is pursued to evaluate the results of the following MC experiments and
also the empirical results of the next section.
5.4.2. Simulation evidence
For the subsequent simulation study four Monte Carlo experiments using different data
generating processes (DGP) are conducted. Here the predictive performances of seasonal
models in 2-years ahead forecasts are examined using quarterly data. In order to reduce
computing times, the BPAR predictions are conducted using the conditional posterior
predictive densities, i.e. given values for the autoregressive lag order p and the number
of breaks m, instead of the model averaged predictive densities. Further, because the
posterior expectation is used as a Bayesian forecasting rule, I focus on the PMSE in the
analysis. The corresponding MAPE values are reported for reasons of comparison.
94

In the Ô¨Årst two experiments the predictive accuracies of the considered models are exam-
ined, when the DGP is a stationary PAR(1) and a periodically integrated AR(1) (abbre-
viated by ‚ÄôPIAR(1)‚Äô) process, respectively. Here the forecasting accuracy of a PAR(1)
model is compared with those of an AR(1) model, both having seasonally varying inter-
cepts, and with those of a deterministic PMEANS model. In the third and fourth sim-
ulation design the forecasting performances of a SAR(1) and a SARMA(1,0) √ó (1,1)
process both with seasonally varying intercepts are analyzed, given that the data are gen-
erated by a nonperiodic stochastic process. In the latter two experiments the forecasting
models are: a PAR(4) model, a quarterly SAR(1) and a SARMA(1,0)√ó(1,1) model, re-
spectively, all three having periodically varying intercepts, and Ô¨Ånally a PMEANS model.
Note, that all considered PAR and (S)ARMA models encompass the PMEANS model.
In the Ô¨Årst simulation experiment (‚Äôdesign 1‚Äô) trajectories are generated from a stationary,
quarterly PAR(1) process without a break:
yt =
4
‚àë
s=1
Ds,t ¬∑(¬µs + œÜs ¬∑yt‚àí1 + ut) , ut
i.i.d.
‚àºN(0,1) , t = 1...T
(5.21)
with œÜ = (0.85, 0.67, 0.92, 1.1)‚Ä≤ and ¬µ = (0.85, 0.95, 0.92, 1)‚Ä≤.
For the second experiment (‚Äôdesign 2‚Äô) the same parametrization as in design 1 is used, but
a periodic unit root is imposed by setting œÜ4 = 1/(œÜ1 ¬∑œÜ2 ¬∑œÜ3), see Osborn et al. (1988),
Boswijk et al. (1995), Franses and Paap (2006) for details on periodic integration. Note,
that for œÜ1,œÜ2 and œÜ3 values close to one, which is often the case in practice, this kind of
integration coincides with a (nonseasonal) unit root at the zero spectral frequency.
For all simulations T = 800 draws from the respective processes are generated, discarding
the Ô¨Årst 500 draws due to burn-in and then the remaining T = 300 draws are used to
conduct k-step ahead forecasts for k = 1,...,8.15 This procedure is repeated N = 100
times in order to approximate the expectations in (5.15). For each of the 100 trajectories
the above sampling algorithm is run 5500 times, discarding the Ô¨Årst 500 draws, and then
the respective posterior predictive means of yT+k, k = 1...K are calculated.16 For the
classical forecasts of the (S)AR model and the PMEANS model the Kalman Ô¨Ålter and the
15All initial values are chosen to be Ô¨Åxed and equal to zero.
16The MC integration steps to obtain the marginal posterior predictive distributions of the yT+k, k = 1...8,
are conducted on a grid of 100 points.
95

least squares projections are used, respectively.
In Ô¨Ågure 5.1 the (cumulated) PMSEs for each of the three models are shown for de-
sign 1 (left panel) and design 2 (right panel). As can be recognized from the left panel
2
3
4
5
6
7
8
5
10
15
20
Quarters
PMSE
DGP: PAR(1)
PAR(1)
AR(1)
PMEANS
2
3
4
5
6
7
8
0
10
20
30
Quarters
PMSE
DGP: PIAR(1)
PAR(1)
AR(1)
PMEANS
Figure 5.1.: (Cumulated) PMSEs for 2-years ahead forecasts (Design 1 and 2).
the PAR(1) model slightly dominates the AR(1) model and clearly beats the PMEANS
model for each considered forecasting period. The associated average PMSEs (with av-
erage MAPEs in parentheses) of the three models are 1.73 (0.20) for the PAR(1) model,
1.76 (0.21) for the AR(1) model and 1.94 (0.23) for the PMEANS model. To check if
the median loss-differentials are signiÔ¨Åcantly different from zero the Bayesian sign test
is applied using the prior distributions discussed in section 5.4.1. Further the classical
sign test and the classical Wilcoxon-Signed Rank (WSR) test as proposed in Diebold and
Mariano (1995), are applied here for reasons of comparison with the Bayesian testing
results.17 Table 5.1 shows that the median loss-differentials of the PAR-AR and AR-
PMEANS comparisons are not signiÔ¨Åcantly different from zero according to the Bayesian
sign tests and also according to the classical tests shown in the last two columns of table
5.1. For the latter two tests a 10% nominal level of signiÔ¨Åcance is assumed due to the
short loss-sequences (T = 12).18 In contrast, the PAR-PMEANS differentials are always
17Where it is shown in Diebold and Mariano (1995) that the latter test has slightly more power in small
samples than the former.
18For each loss differential series a Runs test for randomness is conducted, where rejection of the null of
96

signiÔ¨Åcant. However the classical sign test indicates the weakest evidence against the null,
which could be a consequence of its lack of power as reported by Diebold and Mariano
(1995). Looking at the results of the Bayes tests we recognize a similar behavior of the
test in terms of power as described in section 5.4.1, i.e. that the results under the three
prior distributions are quite comparable if not identical.19
Further the joint hypothesis H0 : œÄ1,2 = œÄ1,3 = 0.5 is tested, i.e. a multiple comparison of
models is conducted, see Berry and Hochberg (1999). Following the strategy outlined in
section 5.4.1, the overall null is rejected if at least one of the single tests rejects the null.
According to the results of simulation experiment 1 it can be concluded that in case of
a stationary PAR(1) process, the three models differ signiÔ¨Åcantly in terms of forecasting
accuracy. However there is no signiÔ¨Åcant deterioration in accuracy when using a more
parsimonious AR model instead of a PAR model.20
Table 5.1.: Test results - Design 1 / DGP: PAR(1)
Comparisons
Jeffreys‚Äô
Bayes‚Äô
Be(1.01,1.01)
Sign test (pv.)
WSR test (pv.)
1-2
0.7852
0.7110
0.7110
1.0000
0.3125
1-3
0.2298
0.2195
0.2195
0.0703
0.0546
2-3
0.5638
0.4961
0.4961
0.2891
0.1094
‚Äô1‚Äô: PAR(1), ‚Äô2‚Äô: AR(1), ‚Äô3‚Äô: PMEANS, ‚Äôpv.‚Äô: p-value
Next we turn our attention to the results of simulation experiment 2 in which the forecast-
ing performances in case of nonstationary PAR(1) data are analyzed. From the right panel
of Ô¨Ågure 5.1 it can be recognized that in case of PIAR(1) data, the PAR(1) model clearly
dominates the other two competitors. Note that the PMEANS model can not be seen in
Ô¨Ågure 5.1 due to very large PMSE values. The associated average PMSEs (and MAPEs)
of the three models in this case are: 2.18 (0.42) for the PAR(1) model, 2.47 (0.42) for the
AR(1) model and 9.58 (1.48) for the PMEANS model.
In table 5.2 the test results for comparing predictive accuracy are summarized. All loss-
‚Äôrandomness‚Äô would be problematic with regard to the iid-assumption of the used tests, see Diebold and
Mariano (1995). Here no further evidence for nonrandomness of the sequences has been found.
19Under Haldane‚Äôs prior all posterior probabilities are equal to one.
20Similar results have been obtained for other parameterizations of the DGP in (5.21) and also for a periodic
moving average process of order one as DGP. The average PMSEs in the latter case are 1.22 for a PAR(1)
model, 1.23 for an AR(1) model and 1.26 for a PMEANS model.
97

differentials of the pairwise comparisons are signiÔ¨Åcant.21 Hence the results suggest, that
in contrast to the results of design 1, there is a signiÔ¨Åcant deterioration in forecasting
accuracy when incorrectly using a nonperiodic AR model or a deterministic PMEANS
model in the case of periodic nonstationarity.
Table 5.2.: Test results - Design 2 / DGP: PIAR(1)
Comparisons
Jeffreys‚Äô
Bayes‚Äô
Be(1.01,1.01)
Sign test (pv.)
WSR test (pv.)
1-2
0.0195
0.0339
0.0342
0.0078
0.0078
1-3
0.0195
0.0339
0.0342
0.0078
0.0078
2-3
0.0195
0.0339
0.0342
0.0078
0.0078
‚Äô1‚Äô: PAR(1), ‚Äô2‚Äô: AR(1), ‚Äô3‚Äô: PMEANS, ‚Äôpv.‚Äô: p-value
In simulation design 3 trajectories are generated according to a quarterly SAR(1) process
in order to simulate also annual lag structures. Finally, with regard to the empirical anal-
ysis of the next section also more general dynamics, given by a SARMA(1,0) √ó (1,1)
process, are simulated in design 4. In design 3 and 4 the nonperiodic SAR(MA) models
are identically speciÔ¨Åed as the respective DGPs and compared with a PAR(4) model and
a PMEANS model. The stochastic process used in design 4 is parameterized as follows:
yt =
4
‚àë
s=1
¬µsDs,t + œÜ1yt‚àí1 + œÜ4yt‚àí4 + ut ‚àíŒ∏4ut‚àí4 , ut
i.i.d.
‚àºN(0,1)
(5.22)
with œÜ1 = 0.35, œÜ4 = 0.45, Œ∏4 = 0.35 and ¬µs = 0.5, ‚àÄs, where for simulation design 3 the
same speciÔ¨Åcation is chosen except that œÜ1 and Œ∏4 are set equal to zero.
For the simulation experiments 3 and 4 the corresponding PMSEs are shown in Ô¨Ågure
5.2. From there it can be observed that in case of quarterly data, generated by a constant-
parameter SAR(1) process, a PAR(4) predicts the data almost equally well as the (true)
SAR(1) model. The PMSEs (MAPEs) of experiment 3 are 1.22 (0.81) for the PAR(4)
model, 1.21 (0.83) for the SAR(1) model, and 1.35 (0.93) for the PMEANS model. Table
5.3 summarizes the test results. The test Ô¨Åndings are similar to those of design 1, namely
that there is no signiÔ¨Åcant deterioration in predictive accuracy when estimating a PAR(4)
model instead of the (correct) quarterly SAR(1) model. However estimating a purely
21The corresponding results under Haldane‚Äôs prior are 0.0077 for all three comparisons.
98

2
3
4
5
6
7
8
2
4
6
8
10
12
Quarters
PMSE
DGP: SAR(1)
PAR(4)
SAR(1)
PMEANS
2
3
4
5
6
7
8
2
4
6
8
10
12
Quarters
PMSE
DGP:
 SARMA(1,0)*(1,1)
PAR(4)
SARMA
PMEANS
Figure 5.2.: (Cumulated) PMSEs for 2-years ahead forecasts (Design 3 and 4).
Table 5.3.: Test results - Design 3 / DGP: SAR(1)
Comparisons
Jeffreys‚Äô
Bayes‚Äô
Be(1.01,1.01)
Sign test (pv.)
WSR test (pv.)
1-2
0.5638
0.4961
0.4953
0.2890
0.1953
1-3
0.0195
0.0339
0.0343
0.0078
0.0078
2-3
0.0195
0.0339
0.0343
0.0078
0.0078
‚Äô1‚Äô: PAR(4), ‚Äô2‚Äô: SAR(1), ‚Äô3‚Äô: PMEANS, ‚Äôpv.‚Äô: p-value
deterministic model and thus neglecting the stochastic structure of the data results in a
signiÔ¨Åcant loss in accuracy, which would lead to a rejection of the overall null of predictive
concordance of the three models. Finally, from the right panel of Ô¨Ågure 5.2, it can be
recognized that if the data are generated by a quarterly SARMA(1,0) √ó (1,1) process,
a PAR(4) model produces slightly higher mean squared losses than the true SARMA
model. However the median loss differences between the PAR and the SARMA model
are not signiÔ¨Åcant. The corresponding average PMSEs (MAPEs) of this experiment are
1.29 (2.24) for the PAR model, 1.26 (2.09) for the SARMA model and 1.64 (3.25) for the
PMEANS model.
In sum, both a PAR model and a constant-parameter SAR(MA) model perform similarly
in terms of squared error loss. Both clearly outperform a deterministic PMEANS model
99

Table 5.4.: Test results - Design 4 / DGP: SARMA(1,0) √ó(1,1)
Comparisons
Jeffreys‚Äô
Bayes‚Äô
Be(1.01,1.01)
Sign test (pv.)
WSR test (pv.)
1-2
0.5638
0.4961
0.4953
0.2890
0.2500
1-3
0.0195
0.0339
0.0343
0.0078
0.0078
2-3
0.0195
0.0339
0.0343
0.0078
0.0078
‚Äô1‚Äô: PAR(4), ‚Äô2‚Äô: SARMA(1,0) √ó(1,1), ‚Äô3‚Äô: PMEANS, ‚Äôpv.‚Äô: p-value
when the data exhibit stochastic seasonality. In the context of periodically integrated data
a PAR model provides signiÔ¨Åcantly more accurate forecasts than its competitors. So far,
this suggests the usefulness of the proposed periodic forecasting model even in the case
of nonperiodic data.
In the next section the model averaged PAR (BMA-PAR) model with a possible break is
used to predict monthly unadjusted unemployment rates of Germany.
5.5. Forecasting German monthly unemployment
data
Next the simulated out-of-sample forecasts using the three candidate models of the last
section are conducted to evaluate the accuracy in predicting monthly unemployment rates
of the 16 German federal states and of East- and West-Germany. Furthermore the pre-
dictive performance of a BPAR model, using the model averaged predictive distribution
in (5.10) for prediction, is compared to a BPAR model using the conditional predictive
distribution (5.9), where Mi is obtained through a model selection step. Finally the BMA-
PAR model is used to conduct 12-months ahead out-of-sample forecasts of these series.
In brief, for the German monthly unemployment rates the empirical results show that the
BPAR model outperforms a SARMA and a PMEANS model in terms of squared and ab-
solute error loss. Furthermore, the subsequent Ô¨Åndings suggest superiority of the BMA
approach over a (conditional) model selection approach and are thus in accordance with
the theoretical results in the literature, cf. Raftery and Zheng (2003).
The data set consists of monthly unadjusted unemployment rates of the 16 federal states
100

of Germany as well as the aggregated series for West and East Germany for the sample
period 01/1991 to 02/2013. As in the simulation exercises of the last section the Bayesian
forecasting results are compared to a seasonal AR model and seasonal (or periodic) means
model. The untransformed series together with their sample (partial) autocorrelation func-
tions and spectral densities are depicted in Ô¨Ågures F.32-F.49 (see appendix F). From there
it can be observed that most of the series exhibit strong autocorrelation, which for some
series declines periodically, or shows up seasonally varying swings. Further, when look-
ing at the periodograms in the lower right panels, it can be recognized that for most series
a great amount of variation can be attributed to the zero spectral frequency, which indi-
cates the existence of a nonseasonal stochastic trend component. Also for many of the
series we observe clear peaks in the spectral density around monthly frequencies, which
in addition suggests the existence of a seasonal component. Due to these results and the
results of unreported unit root tests, the original series are transformed by applying Ô¨Årst
differences. In order to get a clearer picture of the seasonal variation in the data, the
monthly boxplots for each country given in Ô¨Ågures F.50-F.58 are examined (see appendix
F). From a visual inspection of the boxplots it can be concluded that most of the con-
ditional, i.e. monthly, sampling distributions are relatively homogenous, which would
advocate the use of constant-parameter models. As counterexamples the series of Lower
Saxony and of Bavaria can be considered.
In order to check the data for the presence of periodic forms of serial dependency of order
one, the Bayesian forward and backward recursive F-tests for no periodicity, introduced
in section 4.5, are applied. For an ease of reference these procedures are restated in
the following.22 First estimate an unrestricted PAR(1) model with seasonal intercepts,
using the respective posterior means23 as point estimates and then use these estimates to
test the null of no periodicity, i.e. H0 : œÜs = œÜ,‚àÄs, against the alternative of periodicity
H1 : œÜs Ã∏= œÜ,‚àÉs. Note that the null hypothesis implies a nonperiodic AR(1) model, whereas
under the alternative a PAR(1) model is assumed. The null can equivalently be tested by
considering H0 : R¬∑œÜ = 0, with R = [IS‚àí1, ‚àíŒπ] an (S‚àí1)√óS matrix of linear contrasts,
IS‚àí1 the identity matrix and Œπ an (S ‚àí1)-vector of ones, where d = dim(B). Given
normality of the innovations and the prior assumptions stated in section 5.2.1, a Bayesian
test can be conducted based on an F(ŒΩ1 = S ‚àí1, ŒΩ2 = T ‚àíp‚àíd) posterior distribution,
22See also Boswijk and Franses (1996) for a similar strategy within a classical framework.
23These can be obtained analytically.
101

see appendix G.5 for details. To check the robustness of the results a recursive testing
procedure is adopted, using the Bayesian F-test, denoted by FPAR, for rolling subsamples
of the original data. The F-test when one year of data is added and removed successively
is then called a Bayesian forward and backward recursive FPAR test, respectively. Note
that for the forward recursive test the Ô¨Årst time window reaches from 1/1991 to 12/1994
and the Ô¨Ånal window from 1/1991 to 2/2013, i.e. the whole time period. In contrast, for
the backward recursive test the Ô¨Årst time window is from 1/1991 to 2/2013, where the last
window includes the period from 1/2009 to 2/2013. The corresponding test results for
each region are shown in table C.1. The null of no periodicity is rejected in the majority
of cases. In contrast to the descriptive results from the boxplots, these Ô¨Åndings suggest
the appropriateness of a periodic model for the prediction of German unemployment data.
In the MCMC algorithm used to generate the forecasts of the model averaged BPAR(p)
model the admissible parameter region of the model indicators are restricted to mmax =
1 and pmax = 12, where the latter is chosen in order to capture also annual dynamics.
Analogously to the BPAR models, one structural break in the deterministic components of
the SARMA and the periodic means model is allowed. The identiÔ¨Åcation of the break date
is accomplished by computing the Bayesian information criterion (BIC) (see Schwarz
(1978)) for all possible break points omitting the Ô¨Årst and last ten percent of the sample
in order to preclude possible end point problems, and then the minimizing date is used as
a change point.
What becomes evident from a Ô¨Årst visual inspection of the original series (see Ô¨Ågures
F.32-F.49) is an instantaneous increase in the level of most of the series around the year
2005. This shift is a consequence of the so called ‚ÄôHartz IV‚Äô labor market reform, which
took effect by January 2005.24 A Ô¨Åxed step-dummy variable in order to control for this
event is not used here, because the considered models only allow for one structural break
and it could be possible, and in fact this has been the case for some series, that there
is another date that is associated with a lower information criterion. However for the
majority of the federal states the date 01/2005 minimizes the BIC and hence is taken as
the Ô¨Ånal break date. The order speciÔ¨Åcation of the SARMA(p, q) √ó (P, Q)12 model
24This reform brought together the former unemployment beneÔ¨Åts for long term unemployed (‚ÄôArbeit-
slosenhilfe‚Äô) and the former welfare beneÔ¨Åts (‚ÄôSozialhilfe‚Äô). That is, since January 2005 these two groups
have both been considered as ‚Äôunemployed‚Äô. This simple change in ‚Äômeasurement‚Äô of the unemployment
rate induced the instantaneous level shift for most of the series.
102

is conducted by computing the BIC for all possible model combinations (p, q, P, Q),
where pmax = qmax = Pmax = Qmax = 2 is chosen in order to obtain more parsimonious
speciÔ¨Åcations. For the SARMA model speciÔ¨Åcations the usual iterative three-stage strat-
egy: identiÔ¨Åcation, estimation, diagnostic checking is employed. Estimation is done by
conditional maximum likelihood and the multistep forecasts are conducted by using the
Kalman Ô¨Ålter.
In table C.2 and C.3 (see appendix C) the average PMSEs and MAPEs of the 1-year
ahead in-sample predictions are reported. For the computations the last 12 observations
are saved for comparison and the preceding observations are then used to calculate the
forecasts for each model. The results support the PAR model in terms of forecasting ac-
curacy. More precisely, for 9 (10) out of the 18 series the BMA-PAR model has the lowest
average loss in terms of the PMSE (MAPE). In only 4 (4) out of the 18 series the more par-
simonious SARMA model is superior, whereas the deterministic periodic means model in
only 4 (3) cases provides more accurate forecasts with respect to the PMSE (MAPE) than
the other forecasting models. In order to check if the loss-differentials are signiÔ¨Åcantly
different from each other, the Bayesian sign test of section 5.4.1 with a Be(1.01,1.01)
prior is used. Here for each of the 18 series pairwise comparisons using the Bayesian sign
test are conducted. Given model 1 has exhibited the lowest average loss, the overall null
H0 : œÄ1,2 = œÄ1,3 = œÄ1,4 = 0.5 is rejected, if at least one of the three pairwise comparisons
is rejected. In advance a Runs test for randomness and also a Box-Ljung test for serial
correlation of order one are applied. Here for most of the considered loss-differential
sequences the iid-assumption of the sign test is invalidated. For this reason, the strategy
outlined in Diebold and Mariano (1995), p.255, is adopted, namely to partition the loss-
differential sequence of two models i and j into k subsequences {di j,1,di j,1+k,di j,1+2k,...},
{di j,2,dij,2+k,dij,2+2k,...},...,{dij,k,di j,2k,di j,3k,...} and then to conduct the sign test on
each of these subsequences. In the present case of four competing models, H0 : œÄi j = 0.5
is rejected if any of the three (sub-) tests could reject the null. In the case of serial de-
pendence of order (k‚àí1) these ‚Äôthinned out‚Äô subsequences should not exhibit any further
serial correlation. For the German unemployment data k = 2 has shown to be sufÔ¨Åcient
to achieve this goal.
As already emphasized at the beginning of this section, interest centers here on capturing
the effect of model averaging on the forecasting accuracy compared to a model selection
103

strategy. Therefore, in the last columns of tables C.2 and C.3, also the PMSE and MAPE
values of a conditional BPAR model, which is selected by using BIC, are shown.25 From
the tables it can be observed that for 6 (6) out of the 18 series a conditional BPAR model
is superior, however only if the model averaged BPAR model is not considered.26 When
the BMA-PAR model is also taken as a competitor, the model selected BPAR model
has only in 1 (1) out of the 18 cases the (statistically signiÔ¨Åcant) lowest average loss
compared to the other three forecasting models. Hence this Ô¨Ånding is in accordance with
the theoretical results stated in the BMA literature, cf. Raftery and Zheng (2003), namely
that BMA point estimates minimize the predictive MSE.
Finally, the BMA-PAR model is used to conduct 12-months ahead out-of-sample predic-
tions for the period 03/2013 - 02/2014. In appendix C the BMA posterior means of yT+k,
for k = 1...12, together with the corresponding Bayesian standard errors and the 95%
HPD prediction error intervals are shown (see tables C.4-C.12). For illustration purposes,
the original unemployment series of West-Germany together with the predicted values
(denoted by ‚ÄôeyT+k‚Äô) is shown in Ô¨Ågure F.59. What can be seen from the Ô¨Ågure is that the
predicted values as well as the HPD intervals favorably render the seasonal variation in
the data. Furthermore in Ô¨Ågures F.60-F.62 the underlying model averaged marginal poste-
rior predictive densities of yT+k, k = 1...12, for West-Germany are depicted, where these
densities are computed on a grid of {y(g)
T+k, g = 1...100} values. For the prediction Ô¨Årst
differences are applied to the original series in order to remove any (stochastic or deter-
ministic) trends, and then the predicted values are transformed back to levels. It should
be noted, that for nearly all federal states the corresponding model posterior probability
mass function, f (Mi|y), assigns decreasing posterior weight to models with higher lag
orders, with or without a structural break.27 This is in accordance with the results of other
authors, see Osborn and Smith (1989), Franses and Koop (1997), inter alia, and also with
own experience, namely that PAR models of low order often provide a good Ô¨Åt to many
economic data sets.
25In this context, note the following useful approximate relationship between the BIC and the posterior
probability mass function of model Mi: f (Mi| data) ‚âàexp(‚àí1/2 BICi)/‚àëI
j=1 exp(‚àí1/2 BICj), which
can be derived by applying a Laplace approximation (see Tierney and Kadane (1986), Tierney et al.
(1989)) to the joint posterior density.
26Most of these six loss-differences are however not statistically signiÔ¨Åcant.
27The results for the 18 series are omitted here.
104

5.6. Concluding remarks
A Bayesian forecasting approach for the class of periodic autoregressive models has been
presented. Since the model admits one structural break in the process mean at an unknown
point in time, this introduces an additional nuisance parameter in the posterior distribu-
tion, which can not be integrated out analytically. Therefore an MCMC approach, based
on data augmentation, is proposed in order to sample from the joint posterior predictive
density, under a speciÔ¨Åc model. Where the latter can be characterized by the number
of autoregressive lags and the number of structural breaks. In order to capture possi-
ble uncertainty induced through a model selection step, a model averaging approach for
prediction has been presented. Instead of working with conditional, i.e. model-speciÔ¨Åc,
predictive distributions, the model posterior probability mass function has been utilized to
obtain model averaged posterior predictive densities. Where the posterior means of these
mixture distributions have been used as point forecasts of the unknown future values.
In a Monte Carlo study, Bayesian PAR models have been compared with SARMA and
seasonal means models in terms of forecasting accuracy. In particular, the simulation
results lend support to the use of PAR models in the case of periodic unit roots. In or-
der to test if two competing forecasting models differ signiÔ¨Åcantly with respect to their
predictive accuracy, a Bayesian sign test has been proposed. In an empirical application
the model averaged BPAR model has been used to forecast monthly unemployment rates
of the 16 federal states of Germany and of East- and West-Germany for one year ahead.
In simulated-out-of-sample forecasts the BMA-PAR model has clearly outperformed a
SARMA and a periodic means model. In addition, a comparison of the forecasting accu-
racy of the BMA-PAR model and a model-selected BPAR model has demonstrated how
model averaging can improve predictive accuracy.
Overall the results suggest that periodic autoregressive models provide a Ô¨Çexible alter-
native to commonly used seasonal models like SARMA and seasonal means models,
particularly in the case of periodic unit roots, i.e. when seasonality might change over
time. Moreover it has been demonstrated that combining evidence from different fore-
casting models by means of a mixture posterior predictive distribution helps to improve
forecasting accuracy. However here the predeÔ¨Ånition of the model space, i.e. the choice
of pmax and mmax, might be crucial. One drawback of PAR(MA) models is their great
105

number of parameters, which gets more inÔ¨Çated when choosing a model averaging ap-
proach. For future work the above model speciÔ¨Åcation could be made more parsimonious
by allowing for heterogenous autoregressive lag orders ps, s = 1...S. Further, by treating
each individual lag Ds,t ¬∑ yt‚àíi, s = 1...S, i = 1..ps, as a variable whose inclusion is con-
trolled, for example by a stochastic search variable selection approach (cf. George et al.
(1993), So et al. (2006), Chen et al. (2011)), the number of parameters could substan-
tially be reduced. Since the inclusion of irrelevant lags introduces additional noise into
the forecasting process (cf. Clark and West (2007)), this approach might not only reduce
the number of parameters but also increase the forecasting accuracy.
106

6. Final summary and discussion
This dissertation presents new evidence on the use of Bayesian methods for unit root test-
ing and forecasting of (non)seasonal time series data. In the context of nonseasonal data
(see chapter 2), a Bayesian unit root testing approach for the case of multiple structural
breaks is presented. Here the number of structural breaks, their location, and also the
number of autoregressive lags in the test regression are treated as random variables. The
Bayes test proceeds by Ô¨Årst identifying the most likely model, and then unit root infer-
ence is drawn conditional on this model speciÔ¨Åcation. For the model selection a mixed
MCMC sampling approach is proposed, which allows to jump between parameter spaces
of varying dimension. As a sensitivity check with respect to the prior choice, the frequen-
tist risk functions for the posterior Bayes estimator of the long-run impact coefÔ¨Åcient,
are simulated using different prior speciÔ¨Åcations. With the presented model selection
approach it is possible to identify the most likely candidate model through the approx-
imated joint posterior distribution of the number of autoregressive lags and the number
of structural breaks. This distribution captures the uncertainty induced by picking out
a particular model for inference and can further be utilized to compute model averaged
point estimates of the parameters of interest, e.g. the half lives of a shock. The results of
an empirical application, using annual unemployment rates of 17 OECD countries, indi-
cate that the only country with high posterior probability for unemployment hysteresis is
Greece, whereas Japan and Spain show slightly increased levels of persistence. Overall
the empirical analysis suggests that the majority of the considered OECD unemployment
rates are likely to follow a trend stationary process with possible level shifts.
In the second part of the thesis the focus is on unit root testing and forecasting of seasonal
time series data. Since in practice often time series of higher than annual frequency are
used, seasonal forms of nonstationarity can occur, and thus testing procedures for seasonal
unit roots are required. In this regard, a Ô¨Çexible class of seasonal time series models, able
107

to capture changing seasonality, is the class of periodic autoregressive models. In chapter
4, a Bayesian testing strategy to test for a periodic unit root with a possible mean break
at an unknown point in time is presented. For this test the posterior density of the prod-
uct of periodic autoregressive coefÔ¨Åcients is required. Here an approximation, based on
a Ô¨Årst order Taylor series expansion, and a direct sampling approach, based on the joint
posterior density of the PAR coefÔ¨Åcients, are presented. Further the marginal posterior
densities of the PAR(1) coefÔ¨Åcients, œÜs, s = 1...S, are derived and used to test the hypoth-
esis of a Random Walk in season s. In addition, in order to test for a real-valued seasonal
and a nonseasonal unit root, a Bayesian F-test is proposed. All unit root tests presented in
chapter 4 are based on model averaging techniques so that it is possible to combine evi-
dence from different models, here: a PAR(1) model with and without a structural break.
As a pretest a Bayesian recursive F-test to test for the presence of periodic variation of
order one in the data is proposed. In an empirical analysis these methods are applied to
test for unemployment hysteresis in the monthly unadjusted unemployment rates of the
17 OECD countries used in the empirical section of chapter 2. The results show that most
of the monthly unemployment rates exhibit unit root behavior. Among the four countries
having the highest posterior probabilities of a periodic unit root are Greece, Ireland, Spain
and the UK. Moreover many of these series are driven by a nonperiodic stochastic trend,
which is implied by a zero frequency unit root.
In contrast to the results of chapter 2, the empirical results of chapter 4 suggest the pres-
ence of a stochastic trend in the OECD unemployment rates. However it should be noted
that although the same countries have been considered, the analysis of chapter 4 has been
performed with monthly data, whereas in chapter 2 yearly data have been used. More
importantly, the statistical models in both chapters are quite different, since in chapter 2
nonperiodic autoregressive models of possibly high order and multiple breaks have been
considered, whereas in chapter 4 periodic autoregressive models of order one with at
most one break have been used. In this respect, there is a trade-off often experienced
in practice between allowing for a (possibly large) number of structural breaks and the
unit-root-evidence found in the data. In other words, by allowing for breaks in the de-
terministic part of a stochastic process some of the sample variation is captured by the
additional deterministic terms and thus the variation attributed to the stochastic part of the
process is reduced.
108

In chapter 5, a novel Bayesian forecasting approach for the class of periodic autoregres-
sive models is presented. For this class the joint posterior predictive distribution of the
multistep ahead forecasts is derived. Similar to the testing approach of chapter 2, the
periodic forecasting model in chapter 5 treats the number of autoregressive lags, the oc-
currence of a break and the corresponding break date as unknown random parameters.
However, instead of working with conditional, i.e. model-speciÔ¨Åc, predictive distribu-
tions, the model posterior probability distribution is utilized to obtain model averaged
posterior predictive densities. The posterior means of these mixture distributions are
used as point forecasts of the unknown future values. In an empirical application, using
monthly unadjusted unemployment rates of the 16 federal states of Germany and of East-
and West-Germany, it is demonstrated that model averaging helps to improve forecasting
accuracy compared to a conditional approach. To test if two forecasting models differ
signiÔ¨Åcantly with respect to their predictive accuracy, a Bayesian sign test, using several
prior speciÔ¨Åcations as a sensitivity check, is proposed. Since the model admits one struc-
tural break at an unknown point in time, this introduces an additional nuisance parameter
in the joint posterior distribution which can not be integrated out analytically. Therefore
an MCMC approach, based on data augmentation, is proposed in order to sample from
the joint posterior predictive density, under a speciÔ¨Åc model.
In each of the three articles the presented Bayesian methods have been compared with
classical competitors using simulated and real data.
Overall the results suggest that
Bayesian methods may often provide useful alternatives to classical methods, as for ex-
ample in the case of unit root testing with an unknown number of structural breaks and
associated break dates. This may particularly be the case when some regularity conditions
under which the classical tests are derived become invalid, e.g. due to short time series,
whereas Bayesian probability statements stay the same irrespective of the sample size.
For example, under a Ô¨Çat prior the marginal posterior distribution of the long-run impact
coefÔ¨Åcient in an Augmented Dickey-Fuller regression is a Student-t density, irrespective
of the sample size. Moreover, as discussed in section 1.2, this distribution stays the same
for stationary and also nonstationary data. By using a Bayesian frame of reference it is
straightforward to assign positive prior probabilities to the members of a predeÔ¨Åned set of
candidate models and then to obtain the (approximate) model posterior probability distri-
bution. The latter can then be used for model selection or model averaging. With regard to
the prediction of future data, using monthly unemployment data of Germany, it is shown
109

that model averaging can improve forecasting accuracy.
In a Bayesian framework the inÔ¨Çuence of the prior distribution becomes more pronounced
in small samples and thus problems of prior elicitation have to be taken more seriously.
Throughout this dissertation normally distributed innovations have been assumed in or-
der to utilize some analytical results based on conjugate prior distributions. This might
be restrictive for many types of data, as for example Ô¨Ånancial data, which exhibit some
well known stylized facts like heavy tails, leptokurtosis and volatility clustering. Another
critical assumption concerns the functional form of the considered models, namely the
linearity, and also the assumed form of the structural breaks. In this thesis only breaks
in the process mean have been allowed. However controlling for breaks in the variance
may also be important in the context of unit root testing (cf. Kim et al. (2002), Cavaliere
(2005b)).
One route for future work is to focus on Bayesian unit root testing in nongaussian, nonlin-
ear time series models. Here the multi-regime heteroscedastic SETAR(1) model presented
in So et al. (2006) and used in Chen et al. (2012) in order to test for local nonstationarity
could be extended to capture higher order dynamics in the mean equation. Moreover the
presented methods could be extended to allow for variance breaks at unknown points in
time and their effects on the outcomes of Bayesian unit root tests could be examined. In
this dissertation point hypotheses have been tested by using a mixed prior distribution,
which assigns a positive prior probability to the singleton under the null (cf. Berger and
Delampady (1987)). As a robustness check of the presented results, the Full Bayesian
SigniÔ¨Åcance Test introduced by Pereira and Stern (1999) (see also Pereira et al. (2008))
for testing precise hypotheses could be used.
Acknowledgements:
The author would like to thank Cathy W.S. Chen (Feng Chia University, Taiwan), Uwe Blien (Institute for
Employment Research (IAB) and University of Bamberg), Enzo Weber (IAB and University of Regens-
burg), Stefan Fuchs (IAB), and Christian Assmann (University of Bamberg) for many helpful comments.
110

Bibliography
Andel, J. (1983), ‚ÄúStatistical Analysis of Periodic Autoregression,‚Äù Aplikace matematiky,
28(5), 364‚Äì385.
Arestis, P., and Biefang-Frissancho Mariscal, I. (1999), ‚ÄúUnit Roots and structural breaks
in OECD unemployment,‚Äù Economic Letters, 65, 149‚Äì156.
Bai, J., and Perron, P. (1998), ‚ÄúEstimating and Testing Linear Models with Multiple Struc-
tural Changes,‚Äù Econometrica, 66(1), 47‚Äì78.
Bai, J., and Perron, P. (2003), ‚ÄúComputation and analysis of multiple structural change
models,‚Äù Journal of Applied Econometrics, 18(1), 1‚Äì22.
Banerjee, A., Dolado, J., Galbraith, J. W., and Hendry, D. F. (1993), Co-Integration,
Error-Correction and the Econometric Analysis of Non-Stationary Data, Oxford: Ox-
ford University Press.
Bauwens, L., Lubrano, M., and Richard, J. F. (1999), Bayesian Inference in Dynamic
Econometric Models, 1. edn, Oxford: Oxford University Press.
Beaulieu, J., and Miron, J. (1993), ‚ÄúSeasonal unit roots in aggregate U.S. data,‚Äù Journal
of Econometrics, 54, 305‚Äì328.
Berger, J. O. (1980), Statistical Decision Theory and Bayesian Analysis, 2. edn, New
York: Springer.
Berger, J. O., and Delampady, M. (1987), ‚ÄúTesting precise hypotheses,‚Äù Statistical Sci-
ence, 2(3), 317‚Äì335.
111

Berger, J. O., and Sellke, T. (1987), ‚ÄúTesting a point null hypothesis: the irreconcil-
ability of P values and evidence,‚Äù Journal of the American Statistical Association,
82(397), 112‚Äì122.
Berger, T., and Everaert, G. (2008), ‚ÄúUnemployment Persistence and the Nairu: A
Bayesian Approach,‚Äù Scottish Journal of Political Economy, 55(3), 281‚Äì299.
Berry, D., and Hochberg, Y. (1999), ‚ÄúBayesian perspectives on multiple comparisons,‚Äù
Journal of Statistical Planning and Inference, 82(1), 215‚Äì227.
Besag, J. (1989), ‚ÄúA Candidate‚Äôs Formula: A Curious Result in Bayesian Prediction,‚Äù
Biometrika, 76(1), 183.
Birchenhall, C. R., Bladen-Hovell, R., Chui, A., Osborn, D. R., and Smith, J. (1989), ‚ÄúA
Seasonal Model of Consumption,‚Äù The Economic Journal, 99(397), 837‚Äì843.
Blanchard, O. J., Katz, L. F., Hall, R. E., and Eichengreen, B. (1992), ‚ÄúRegional Evolu-
tions,‚Äù Brookings Papers on Economic Activity, (1), 1‚Äì75.
Blanchard, O. J., and Summers, L. H. (1986), ‚ÄúHysteresis and the European Unemploy-
ment Problem,‚Äù NBER Macroeconomics Annual, 1, 15‚Äì78.
Blanchard, O. J., and Summers, L. H. (1987), ‚ÄúHysteresis in Unemployment,‚Äù European
Economic Review, 31, 288‚Äì295.
BloomÔ¨Åeld, P. (2000), Fourier Analysis of Time Series, 2. edn, New York: Wiley & Sons.
Boswijk, H., and Franses, P. H. (1995), ‚ÄúTesting for periodic integration,‚Äù Economics
Letters, 48, 241‚Äì248.
Boswijk, H., and Franses, P. H. (1996), ‚ÄúUnit roots in periodic autoregressions,‚Äù Journal
of Time Series Analysis, 17(3), 221‚Äì245.
Boswijk, H., Franses, P. H., and Haldrup, N. (1995), ‚ÄúMultiple unit roots in periodic
autoregression,‚Äù Journal of Econometrics, 80, 167‚Äì193.
Box, G. E. P., Jenkins, G. M., and Reinsel, G. C. (2008), Time Series Analysis Forecasting
and Control, 4 edn, New Jersey: Wiley.
112

Broemeling, L., and Land, M. (1984), ‚ÄúOn forecasting with univariate autoregressive
processes: A Bayesian approach,‚Äù Communications in Statistics - Theory and Methods,
13(11), 1305‚Äì1320.
Casella, G. (1985), ‚ÄúAn Introduction to Empirical Bayes Data Analysis,‚Äù The American
Statistician, 39(2), 83‚Äì87.
Casella, G., and Berger, R. L. (2002), Statistical Inference, 2. edn, PaciÔ¨Åc Grove:
Duxbury.
Casella, G., and George, E. I. (1992), ‚ÄúExplaining the Gibbs Sampler,‚Äù The American
Statistician, 46(3), 167‚Äì174.
Cavaliere, G. (2005a), ‚ÄúLimited Time Series with a Unit Root,‚Äù Econometric Theory,
21(5), 907‚Äì945.
Cavaliere, G. (2005b), ‚ÄúUnit Root Tests under Time-Varying Variances,‚Äù Econometric
Reviews, 23(3), 259‚Äì292.
Chaloner, K., and Brant, R. (1988), ‚ÄúA Bayesian approach to outlier detection and residual
analysis,‚Äù Biometrika, 75, 651‚Äì659.
Chen, C., Chen, S., and Lee, S. (2012), ‚ÄúBayesian unit root test in double threshold
heteroskedastic models,‚Äù Computational Economics, 35(4), 1‚Äì18.
Chen, C., Liu, F., and Gerlach, R. (2011), ‚ÄúBayesian subset selection for threshold au-
toregressive moving-average models,‚Äù Computational Statistics, 26, 1‚Äì30.
Chib, S. (1995), ‚ÄúMarginal Likelihood from the Gibbs Output,‚Äù Journal of the American
Statistical Association, 90(432), 1313‚Äì1321.
Chib, S. (1998), ‚ÄúEstimation and comparison of multiple change-point models,‚Äù Journal
of Econometrics, 86, 221‚Äì241.
Chib, S., and Greenberg, E. (1995), ‚ÄúUnderstanding the Metropolis-Hastings Algorithm,‚Äù
The American Statistician, 49(4), 327‚Äì335.
Chipman, H., George, E. I., and McCulloch, R. E. (2001), ‚ÄúThe Practical Implementation
of Bayesian Model Selection,‚Äù IMS Lecture Notes - Monograph Series, 38.
113

Christiano, L. J. (1992), ‚ÄúSearching for a Break in GNP,‚Äù Journal of Business Economics
and Statistics, 10, 237‚Äì250.
Clark, T., and West, K. (2007), ‚ÄúApproximately normal tests for equal predictive accuracy
in nested models,‚Äù Journal of Econometrics, 138, 291‚Äì311.
DeGroot, M. H. (1970), Optimal Statistical Decisions, 1. edn, New York: Wiley and Sons.
DeJong, D. N. (1996), ‚ÄúA Bayesian Search for Structural Breaks in US GNP,‚Äù in Advances
in Econometrics: Bayesian Methods Applied to Time Series Analysis, ed. T. Fomby,
Vol. B, Greenwich and Conn.: JAI Press.
Dellaportas, P., Forster, J. J., and Ntzoufras, I. (2002), ‚ÄúOn Bayesian model and variable
selection using MCMC,‚Äù Statistics and Computing, 12(1), 27‚Äì36.
Dickey, D. A., and Fuller, W. A. (1979), ‚ÄúDistribution of the Estimates for Autoregres-
sive Time Series with a Unit Root,‚Äù Journal of the American Statistical Association,
(74), 427‚Äì431.
Dickey, D. A., Hasza, D. P., and Fuller, W. A. (1984), ‚ÄúTesting for Unit Roots in Seasonal
Time Series,‚Äù Journal of the American Statistical Association, 79(386), 355‚Äì367.
Diebold, F. X., and Mariano, R. (1995), ‚ÄúComparing Predictive Accuracy,‚Äù Journal of
Business and Economic Statistics, 15(3), 253‚Äì263.
Draper, D. (1995), ‚ÄúAssessment and propagation of model uncertainty,‚Äù Journal of Royal
Statistical Society, Series B, 57(1), 45‚Äì70.
Dreze, J. H. (1977), ‚ÄúBayesian regression analysis using poly-t densities,‚Äù Journal of
Econometrics, 6(3), 329‚Äì354.
Ehlers, R. S., and Brooks, S. P. (2002), ‚ÄúEfÔ¨Åcient Construction of Reversible Jump
MCMC Proposals for Autoregressive Time Series Models,‚Äù Working Paper, .
Ehlers, R. S., and Brooks, S. P. (2004), ‚ÄúBayesian Analysis of Order Uncertainty in
ARIMA Models,‚Äù Technical Report, .
Elliot, G., Rothenberg, T., and Stock, J. H. (1996), ‚ÄúEfÔ¨Åcient Tests for an Autoregressive
Unit Root,‚Äù Econometrica, 64, 813‚Äì836.
114

Engle, R. F., and Granger, C. W. J. (1987), ‚ÄúCo-Integration and Error Correction: Repre-
sentation, Estimation, and Testing,‚Äù Econometrica, 55(2), 251‚Äì276.
Fernandez, C. L., and Steel, M. (2001), ‚ÄúBenchmark priors for Bayesian model averag-
ing,‚Äù Journal of Econometrics, 100, 381‚Äì427.
Franses, P. H. (1991), ‚ÄúSeasonality, non-stationarity and the forecasting of monthly time
series,‚Äù International Journal of Forecasting, 7, 199‚Äì208.
Franses, P. H. (1994), ‚ÄúA multivariate approach to modeling univariate seasoanl time
series,‚Äù Journal of Econometrics, 63, 133‚Äì151.
Franses, P. H. (1995), ‚ÄúQuarterly US unemployment: Cycles, seasons and asymmetries,‚Äù
Empirical Economics, 20(4), 717‚Äì725.
Franses, P. H. (2003), Periodicity and stochastic trends in economic time series, 2. edn,
New York: Oxford University Press.
Franses, P. H., Hoek, H., and Paap, R. (1997), ‚ÄúBayesian analysis of seasonal unit roots
and seasonal mean shifts,‚Äù Journal of Econometrics, 78, 359‚Äì380.
Franses, P. H., and Koop, G. (1997), ‚ÄúA Bayesian Analysis of Periodic Integration,‚Äù Jour-
nal of Forecasting, 16, 509‚Äì532.
Franses, P. H., and Paap, R. (2006), Periodic Time Series Models, 2. edn, New York:
Oxford University Press.
Fuller, W. A. (1996), Introduction to statistical time series, 2. edn, New York: Wiley.
Garcia-Donato, G., and Martinez-Beneito, M. (2012), ‚ÄúOn sampling strategies in
Bayesian variable selection problems with large model spaces (forthcoming),‚Äù Jour-
nal of the Royal Statistical Society, .
Gelman, A., Carlin, J. B., Stern, H. S., and Rubin, D. B. (1995), Bayesian Data Analysis,
1. edn, London: Chapman & Hall.
George, E. I., McCulloch, and R.E. (1993), ‚ÄúVariable Selection Via Gibbs Sampling,‚Äù
Journal of the American Statistical Association, 88(423), 881‚Äì889.
115

Geweke, J., and Whiteman, C. H. (2006), ‚ÄúBayesian Forecasting,‚Äù Handbook of Economic
Forecasting, 1, 3‚Äì80.
Ghysels, E. (1990), ‚ÄúUnit root tests and the statistical pitfalls of seasonal adjustment: The
case of U.S. postwar Real Gross National Product,‚Äù Journal of Business and Economic
Statistics, 8(2), 145‚Äì152.
Ghysels, E., and Osborn, D. R. (2001), The Econometric Analysis of Seasonal Time Series,
1. edn, Cambridge: Cambridge University Press.
Ghysels, E., Osborn, D., and Rodrigues, P. (2006), Forecasting Seasonal Time Series,
Vol. 1 of Handbook of Economic Forecasting, Amsterdam: Elsevier.
Ghysels, E., and Perron, P. (1993), ‚ÄúThe effect of seasonal adjustment Ô¨Ålters on tests for
a unit root,‚Äù Journal of Econometrics, 55, 57‚Äì98.
Giacomini, R., and White, H. (2006), ‚ÄúTests of Conditional Predictive Ability,‚Äù Econo-
metrica, 74, 1545‚Äì1578.
Gladyshev, E. (1961), ‚ÄúPeriodically correlated random sequences,‚Äù Soviet Mathematics,
2, 385‚Äì388.
Godsill, S. J. (2001), ‚ÄúOn the Relationship Between Markov Chain Monte Carlo Meth-
ods for Model Uncertainty,‚Äù Journal of Computational and Graphical Statistics,
10(2), 230‚Äì248.
Granger, C. W. J. (1986), ‚ÄúDevelopments in the study of cointegrated economic vari-
ables,‚Äù Oxford Bulletin of Economics and Statistics, 48(3), 213‚Äì228.
Greene, W. H. (2003), Econometric Analysis, 5. edn, New Jersey: Prentice Hall.
Hall, A. (1994), ‚ÄúTesting for a Unit Root in Time Series with Pretest Data-Based Model
Selection,‚Äù Journal of Business and Economic Statistics, 12, 461‚Äì470.
Hall, R. (1978), ‚ÄúStochastic implication of the cycle-permanent income hypothesis: the-
ory and evidence,‚Äù Journal of Political Economy, 86, 971‚Äì987.
Hamilton, J. D. (1994), Time Series Analysis, 1. edn, New York: Cambridge University
Press.
116

Hansen, B. E. (2007), ‚ÄúLeast Squares Model Averaging,‚Äù Econometrica, 75(4), 1175‚Äì
1189.
Hansen, L., and Sargent, T. (1993), ‚ÄúSeasonality and Approximation Errors in Rational
Expectations Models,‚Äù Journal of Econometrics, 55, 21‚Äì56.
Hassler, U., and Wolters, J. (2009), ‚ÄúHysteresis in Unemployment Rates? A Comparison
between Germany and the US,‚Äù in Jahrb√ºcher f√ºr National√∂konomie und Statistik, ed.
P. Winker, Vol. 229, Stuttgart: Lucius.
Hastings, W. K. (1970), ‚ÄúMonte Carlo sampling methods using Markov chains and their
applications,‚Äù Biometrika, 57(1), 97‚Äì109.
Hjort, N., and Claeskens, G. (2003), ‚ÄúFrequentist Model Average Estimators,‚Äù Journal of
the American Statistical Association, 98, 879‚Äì899.
Hoeting, J., Madigan, D., Raftery, A. E., and Volinsky, C. (1999), ‚ÄúBayesian model aver-
aging: A tutorial,‚Äù Statistical Science, 14, 382‚Äì417.
Hong, H., and Preston, B. (2012), ‚ÄúBayesian averaging, prediction and nonnested model
selection,‚Äù Journal of Econometrics, 167, 358‚Äì369.
Huerta, G., and West, M. (1999), ‚ÄúBayesian inference on periodicities and component
spectral structure in time series,‚Äù Journal of Time Series Analysis, 20(4), 401‚Äì416.
Hylleberg, S., Engle, R. F., Granger, C. W. J., and Yoo, B. S. (1990), ‚ÄúSeasonal Integration
and Cointegration,‚Äù Journal of Econometrics, 44, 215‚Äì238.
Inoue, A., and Kilian, L. (2006), ‚ÄúOn the selection of forecasting models,‚Äù Journal of
Econometrics, (130), 273‚Äì306.
Johansen, S. (1988), ‚ÄúStatistical analysis of cointegration vectors,‚Äù Journal of Economic
Dynamics and Control, 12(2), 231‚Äì254.
Johnson, N., and Kotz, S. (1970), Continuous Univariate Distributions 2, 1. edn, New
Jersey: John Wiley & Sons, Inc.
Judge, G., GrifÔ¨Åths, W., Hill, R., L√ºtkepohl, H., and Lee, T. (1985), The Theory and
Practice of Econometrics, 2. edn, New York: John Wiley & Sons, Inc.
117

Kadane, J. B., Chan, N. H., and Wolfson, L. J. (1996), ‚ÄúPriors for unit root models,‚Äù
Journal of Econometrics, 75(1), 99‚Äì111.
Kass, R. E., and Raftery, A. E. (1995), ‚ÄúBayes Factors,‚Äù Journal of the American Statisti-
cal Association, 90(430), 773‚Äì795.
Kendall, M. G., and Stuart, A. (1969), The Advanced Theory of Statistics - Distribution
Theory, Vol. 1, 3. edn, London: Charles GrifÔ¨Ån and Company Limited.
Kim, T. H., Leybourne, S., and Newbold, P. (2002), ‚ÄúUnit root tests with a break in
innovation variance,‚Äù Journal of Econometrics, 109(2), 365‚Äì387.
King, R., Plosser, C., and Rebelo, S. (1988), ‚ÄúProduction, growth and business cycles: I.
The basic neoclassical model,‚Äù Journal of Monetary Economics, 21, 195‚Äì232.
Klein, I. (2008), ‚ÄúSome R graphics for bivariate distributions,‚Äù Discussion Paper - Uni-
versity of Nuremberg, (83).
Koop, G., Oseiwalski, J., and Steel, M. F. J. (1995), ‚ÄúBayesian long-run prediction in time
series models,‚Äù Journal of Econometrics, 69, 61‚Äì80.
Koop, G., and Potter, S. (1999), ‚ÄúDynamic Asymmetries in U.S. Unemployment,‚Äù Journal
of Business & Economic Statistics, 3(17), 298‚Äì312.
Koop, G., and Potter, S. (2004), ‚ÄúForecasting and estimating multiple change-point
models with an unknown number of change points,‚Äù Review of Economic Studies,
74(3), 763‚Äì789.
Koop, G., and Steel, M. F. J. (1994), ‚ÄúA Decision-Theoretic Analysis of the Unit-Root
Hypothesis using Mixtures of Elliptical Models,‚Äù Journal of Business and Economic
Statistics, 12, 95‚Äì107.
Layard, R., Nickell, S., and Jackman, R. (1991), Unemployment: macroeconomic perfor-
mance and the labour market, 1. edn, Oxford: Oxford University Press.
Liang, F., Paulo, R., Molina, G., Clyde, M., and Berger, J. (2008), ‚ÄúMixtures of g-
Priors for Bayesian Variable Selection,‚Äù Journal of the American Statistical Associ-
ation, 103(481), 410‚Äì423.
118

Lopes, H. F. (2006), ‚ÄúA note on Reversible Jump Markov Chain Monte Carlo,‚Äù Discussion
Paper, .
Lubrano, M. (2001), ‚ÄúSmooth Transition Garch Models:
a Bayesian Perspective,‚Äù
Recherches Economiques de Louvain / Louvain Economic Review, 67(3), 257‚Äì287.
L√ºtkepohl, H. (2007), New Introduction to Multiple Time Series Analysis, 2. edn, Berlin:
Springer.
Maddala, G. S., and Kim, I. M. (1998), Unit Roots, Cointegration and Structural Change,
6. edn, New York: Oxford University Press.
Madigan, D., and Raftery, A. E. (1994), ‚ÄúModel selection and accounting for model uncer-
tainty in graphical models using Occam‚Äôs window,‚Äù Journal of the American Statistical
Association, 89(428).
Marin, J. M., and Robert, C. P. (2010), Bayesian Core, 1. edn, New York: Springer.
Marriott, J., and Newbold, P. (2000), ‚ÄúThe strength of evidence for unit autoregres-
sive roots and structural breaks: A Bayesian perspective,‚Äù Journal of Econometrics,
98(1), 1‚Äì25.
Meese, R., and Rogoff, K. (1983), ‚ÄúEmpirical exchange rate models of the seventies. Do
they Ô¨Åt out of sample?,‚Äù Journal of International Economics, (14), 3‚Äì24.
Mikhail, O., Eberwein, C., and Handa, J. (2006), ‚ÄúEstimating persistence in Canadian un-
employment: evidence from a Bayesian ARFIMA,‚Äù Applied Economics, 38(15), 1809‚Äì
1819.
Mitchell, W. F. (1993), ‚ÄúTesting for unit roots and persistence in OECD unemployment
rates,‚Äù Applied Economics, 25(12), 1489‚Äì1501.
Monahan, J., and Boos, D. (1992), ‚ÄúProper likelihoods for Bayesian analysis,‚Äù
Biometrika, 79(2), 271‚Äì278.
Nelson, C. R., and Plosser, C. I. (1982), ‚ÄúTrends and Random Walks in Macroeconomic
Time Series,‚Äù Journal of Monetary Economics, 10, 139‚Äì162.
119

Ng, S., and Perron, P. (2001), ‚ÄúLag length selection and the construction of unit root tests
with good size and power,‚Äù Econometrica, 69(6), 1519‚Äì1554.
Ooms, M., and Franses, P. H. (1997), ‚ÄúOn periodic correlations between estimated sea-
sonal and nonseasonal components in German and U.S. unemployment,‚Äù Journal of
Business and Economic Statistics, 15(4), 470‚Äì481.
Osborn, D. R. (1991), ‚ÄúThe Implications of Periodically Varying CoefÔ¨Åcients for Seasonal
Time-Series Processes,‚Äù Journal of Econometrics, 48, 373‚Äì384.
Osborn, D. R., Chui, A., Smith, J., and Birchenhall, C. R. (1988), ‚ÄúSeasonality and the
Order of Integration for Consumption,‚Äù Oxford Bulletin of Economics and Statistics,
50, 361‚Äì377.
Osborn, D. R., and Smith, J. (1989), ‚ÄúThe Performance of Periodic Autoregressive Mod-
els in Forecasting Seasonal U.K. Consumption,‚Äù Journal of Business and Economic
Statistics, 7(1), 117‚Äì128.
Pagano, M. (1978), ‚ÄúOn periodic and multiple autoregressions,‚Äù The Annals of Statistics,
6(6), 1310‚Äì1317.
Papell, D. H., Murray, C. J., and Ghiblawi, H. (2000), ‚ÄúThe Structure of Unemployment,‚Äù
Review of Economics and Statistics, 82, 309‚Äì315.
Papell, D. H., and Prodan, R. (2004), ‚ÄúThe Uncertain Unit Root in U.S. Real GDP: Ev-
idence with Restricted and Unrestricted Structural Change,‚Äù Journal of Money, Credit
and Banking, 36(3), 423‚Äì427.
Pascalau, R. (2007), ‚ÄúUnit Root Tests with Smooth Breaks: An Application to the Nelson-
Plosser Data Set,‚Äù Working Paper, .
Pereira, C., and Stern, J. (1999), ‚ÄúEvidence and credibility: full Bayesian signiÔ¨Åcance test
for precise hypotheses.,‚Äù Entropy, 1, 69‚Äì80.
Pereira, C., Stern, J., and Wechsler, S. (2008), ‚ÄúCan a SigniÔ¨Åcance Test be genuinely
Bayesian?,‚Äù Bayesian Analysis, 3, 79‚Äì100.
Perron, P. (1989), ‚ÄúThe great crash, the oil price shock and the unit root hypothesis.,‚Äù
Econometrica, 57, 1361‚Äì1401.
120

Perron, P., and Vogelsang, T. J. (1992), ‚ÄúNonstationarity and Level Shifts with an Ap-
plication to Purchasing Power Parity,‚Äù Journal of Business and Economic Statistics,
10, 301‚Äì320.
Phelps, E. S. (1994), Structural Slumps: The Modern Equilibrium Theory of Unemploy-
ment, Interest and Assests, Cambridge: Harvard University Press.
Philippe, A. (2006), ‚ÄúBayesian analysis of autoregressive moving average processes with
unknown orders,‚Äù Computational Statistics & Data Analysis, 51(3), 1904‚Äì1923.
Phillips, P. C. B. (1991a), ‚ÄúBayesian Routes and Unit Roots: De Rebus Prioribus Semper
Est Disputandum,‚Äù Journal of Applied Econometrics, 6(4), 435‚Äì473.
Phillips, P. C. B. (1991b), ‚ÄúTo Criticize the Critics: An Objective Bayesian Analysis of
Stochastic Trends,‚Äù Journal of Applied Econometrics, 6(4), 333‚Äì364.
Phillips, P. C. B., and Perron, P. (1988), ‚ÄúTesting for a Unit Root in Time Series Regres-
sion,‚Äù Biometrika, 88(75), 335‚Äì346.
Poole, D. (2006), Linear Algebra. A Modern Introduction, 2. edn, Belmont: Thomson
Brooks/Cole.
Priestley, M. (2004), Spectral Analysis and Time Series, Probability and Mathematical
Statistics, 2. edn, London: Elsevier.
Raftery, A. E. (1995), ‚ÄúBayesian Model Selection in Social Research,‚Äù Sociological
Methodology, 25, 111‚Äì163.
Raftery, A. E., Madigan, D., and Hoeting, J. (1997), ‚ÄúBayesian Model Averaging for
Linear Regression Models,‚Äù Journal of the American Statistical Association, 92, 179‚Äì
191.
Raftery, A. E., and Zheng, Y. (2003), ‚ÄúPerformance of Bayesian Model Averaging,‚Äù Jour-
nal of the American Statistical Association, 98, 931‚Äì938.
Raftery, A., Madigan, D., and Volinsky, C. (1996), ‚ÄúAccounting for model uncertainty
in survival analysis improves predictive performance (with discussion),‚Äù in Bayesian
Statistics, eds. J. Berger, J. Bernardo, A. Dawid, D. Lindley, and A. Smith, Vol. 5,
London: Oxford University Press, pp. 323‚Äì349.
121

Raiffa, H., and Schlaifer, R. (2000), Applied Statistical Decision Theory, 1. edn, New
York: Wiley and Sons.
Richard, J., and Tompa, H. (1980), ‚ÄúOn the evaluation of Poly-t density functions,‚Äù Jour-
nal of Econometrics, 12, 335‚Äì351.
Robert, C. P. (2007), The Bayesian Choice, 1. edn, New York: Springer.
Roed, K. (1996), ‚ÄúUnemployment Hysteresis - Macro Evidence from 16 OECD Coun-
tries,‚Äù Empirical Economics, 21, 589‚Äì600.
Said, S. E., and Dickey, D. A. (1984), ‚ÄúTesting for Unit Roots in autoregressive moving
average models of unknown order,‚Äù Biometrika, 71(3), 599‚Äì607.
Schotman, P., and van Dijk, H. K. (1991), ‚ÄúOn Bayesian Routes to Unit Roots,‚Äù Journal
of Applied Econometrics, 6(4), 387‚Äì401.
Schwarz, G. (1978), ‚ÄúEstimating the dimension of a model,‚Äù The Annals of Statistics,
6(2), 461‚Äì464.
Shafer, G. (1982), ‚ÄúLindley‚Äôs paradox,‚Äù Journal of the American Statistical Association,
77(378), 325‚Äì334.
Sims, C. A. (1988), ‚ÄúBayesian Skepticism on Unit Root Econometrics,‚Äù Journal of Eco-
nomic Dynamics and Control, 12, 436‚Äì474.
Sims, C. A., and Uhlig, H. (1991), ‚ÄúUnderstanding Unit Rooters: A Helicopter Tour,‚Äù
Econometrica, 59(6), 1591‚Äì1599.
So, M., Chen, C., and Liu, F. (2006), ‚ÄúBest subset selection of autoregressive models
with exogenous variables and generalized autoregressive conditional heteroscedasticity
errors,‚Äù Journal of the Royal Statistical Society: Series C, 55, 201‚Äì224.
Spanos, A. (1999), Probability Theory and Statistical Inference, 1. edn, Cambridge: Cam-
bridge University Press.
Stock, J. H. (1994), ‚ÄúDeciding between I(1) and I(0),‚Äù Journal of Econometrics, 63, 105‚Äì
131.
122

Stock, J. H., and Watson, M. W. (1999), ‚ÄúForecasting inÔ¨Çation,‚Äù Journal of Monetary
Economics, 44(2), 293‚Äì335.
Summers, P. M. (2004), ‚ÄúBayesian Evidence on the Structure of Unemployment,‚Äù Eco-
nomics Letters, 83, 299‚Äì306.
Tanner, M., and Wong, W. (1987), ‚ÄúThe Calculation of Posterior Distributions by Data
Augmentation,‚Äù Journal of the American Statistical Association, 82(398), 528‚Äì540.
Tiao, G. C., and Grupe, M. (1980), ‚ÄúHidden periodic autoregressive-moving average mod-
els in time series data,‚Äù Biometrika, 67(2), 365‚Äì373.
Tierney, L., and Kadane, J. B. (1986), ‚ÄúAccurate Approximations for Posterior Moments
and Marginal Densities,‚Äù Journal of the American Statistical Association, 81(393), 82‚Äì
86.
Tierney, L., Kass, R., and Kadane, J. (1989), ‚ÄúFully Exponential Laplace Approximations
to Expectations and Variances of Nonpositive Functions,‚Äù Journal of the American Sta-
tistical Association, 84(407), 710‚Äì716.
Troughton, P. T., and Godsill, S. J. (1997a), ‚ÄúBayesian Model Selection for Time Series
using Markov Chain Monte Carlo,‚Äù Technical Report, pp. 3733‚Äì3736.
Troughton, P. T., and Godsill, S. J. (1997b), ‚ÄúA Reversible Jump Sampler for Autore-
gressive Time Series, Employing Full Conditionals to Achieve EfÔ¨Åcient Model Space
Moves,‚Äù Technical Report, pp. 1‚Äì13.
Troutman, B. (1979), ‚ÄúResults in Periodic Autoregression,‚Äù Biometrika, 66(2), 219‚Äì228.
Uhlig, H. (1994), ‚ÄúWhat Macroeconomists should know about unit roots - A bayesian
perspective,‚Äù Econometric Theory, 10, 645‚Äì671.
van der Vaart, A. (1998), Asymptotic Statistics, Cambridge: Cambridge University Press.
Vecchia, A. (1985), ‚ÄúMaximum Likelihood Estimation for Periodic Autoregressive Mov-
ing Average Models,‚Äù Technometrics, 27(4), 375‚Äì384.
Vermaak, J., Andrieu, C., Doucet, A., and Godsill, S. J. (2004), ‚ÄúReversible Jump Markov
Chain Monte Carlo Strategies for Bayesian Model Selection in Autoregressive Pro-
cesses,‚Äù Journal of Time Series Analysis, 25(6), 785‚Äì809.
123

Vogelsang, T. J., and Perron, P. (1992), ‚ÄúNonstationarity and Level Shifts with an Ap-
plication to Purchasing Power Parity,‚Äù Journal of Business and Economic Statistics,
10(3), 301‚Äì320.
Wallis, K. (1987), ‚ÄúTime Series Analysis of bounded economic variables,‚Äù Journal of
Time Series Analysis, 8(1), 115‚Äì123.
Wang, J., and Zivot, E. (2000), ‚ÄúA Bayesian Time Series Model of Multiple Structural
Changes in Level, Trend, and Variance,‚Äù Journal of Business and Economic Statistics,
18(3), 374‚Äì386.
Zellner, A. (1971), Introduction to Bayesian Inference in Econometrics, 1. edn, New York:
Wiley and Sons.
Zellner, A. (1975), ‚ÄúBayesian Analysis of Regression Error Terms,‚Äù Journal of the Amer-
ican Statistical Association, 70(349), 138‚Äì144.
Zellner, A. (1986), ‚ÄúOn assessing prior distributions and Bayesian regression analysis
with g-prior distributions,‚Äù in Bayesian Inference and Decision Techniques: Essays
in Honor of Bruno de Finietti, eds. P. K. Goel, and A. Zellner, Amsterdam: North-
Holland, pp. 233‚Äì243.
Zellner, A., and Siow, A. (1980), ‚ÄúPosterior Odds Ratios for Selected Regression Hy-
potheses,‚Äù in Bayesian Statistics, eds. J. M. Bernardo, M. H. DeGroot, D. V. Lindley,
and A. F. M. Smith, Valencia: University Press, pp. 583‚Äì603.
Zivot, E., and Phillips, P. C. B. (1994), ‚ÄúA Bayesian Analysis of Trend Determination of
Economic Time Series,‚Äù Econometric Reviews, 13(3), 291‚Äì336.
124

A. Tables - chapter 2
Table A.1.: Posterior probabilities of the number of structural breaks
Number of breaks
Country
Years
0
1
2
3
4
5
AIC
BIC
Australia
1966-2010
0.194
0.077
0.117
0.238
0.254
0.120
4
4
Belgium
1983-2010
0.047
0.214
0.136
0.173
0.308
0.122
4
4
Canada
1976-2010
0.098
0.165
0.136
0.178
0.266
0.158
5
3
Denmark
1983-2010
0.091
0.050
0.124
0.254
0.325
0.156
5
4
Finland
1963-2010
0.051
0.041
0.360
0.217
0.221
0.111
5
4
France
1983-2010
0.062
0.043
0.405
0.254
0.171
0.066
5
4
Germany
1970-2010
0.188
0.109
0.259
0.241
0.142
0.062
4
3
Greece
1983-2010
0.061
0.143
0.203
0.255
0.239
0.101
4
4
Ireland
1983-2010
0.096
0.037
0.145
0.305
0.286
0.132
5
5
Italy
1970-2010
0.018
0.035
0.191
0.416
0.260
0.080
3
3
Japan
1968-2010
0.041
0.115
0.187
0.425
0.055
0.181
4
5
Netherlands
1971-2010
0.086
0.037
0.367
0.239
0.171
0.101
4
3
Norway
1972-2010
0.121
0.070
0.234
0.258
0.219
0.100
4
4
Spain
1972-2010
0.039
0.089
0.144
0.244
0.316
0.168
4
4
Sweden
1963-2010
0.034
0.070
0.167
0.366
0.218
0.145
4
3
UK
1984-2010
0.053
0.086
0.090
0.211
0.355
0.206
4
5
US
1960-2010
0.155
0.117
0.106
0.300
0.232
0.090
4
3
‚ÄôAIC‚Äô and ‚ÄôBIC‚Äô: Akaike‚Äôs and Schwarz‚Äôs information criterion.
125

Table A.2.: Posterior probabilities of the autoregressive lag order
Number of lags
Country
1
2
3
4
5
AIC
BIC
PACF
Australia
0.816
0.081
0.031
0.019
0.054
2
2
1
Belgium
0.699
0.128
0.047
0.027
0.099
1
1
2
Canada
0.196
0.323
0.194
0.188
0.099
1
2
2
Denmark
0.809
0.044
0.031
0.032
0.084
5
1
1
Finland
0.151
0.368
0.207
0.069
0.205
3
2
2
France
0.825
0.069
0.030
0.017
0.059
2
1
1
Germany
0.158
0.421
0.172
0.103
0.147
4
2
1
Greece
0.769
0.052
0.032
0.028
0.119
5
1
1
Ireland
0.719
0.084
0.046
0.025
0.126
1
1
1
Italy
0.835
0.041
0.027
0.022
0.075
1
1
1
Japan
0.719
0.076
0.045
0.026
0.134
4
1
1
Netherlands
0.201
0.422
0.201
0.071
0.105
5
2
2
Norway
0.474
0.238
0.097
0.066
0.126
2
2
2
Spain
0.094
0.319
0.235
0.237
0.116
2
2
2
Sweden
0.631
0.144
0.072
0.043
0.110
3
2
2
UK
0.663
0.070
0.080
0.077
0.111
5
1
1
US
0.612
0.195
0.071
0.035
0.087
2
2
2
‚ÄôAIC‚Äô, ‚ÄôBIC‚Äô and ‚ÄôPACF‚Äô: Akaike‚Äôs and Schwarz‚Äôs information criterion and
the (sample) partial autocorrelation function.
126

Table A.3.: Bayesian break date estimates
Break dates
Country
T
1st
2nd
3rd
4th
5th
Australia
45
1974
1981
1990
1993
-
Belgium
28
1988
1992
1999
2001
-
Canada
35
1981
1985
1990
1997
-
Denmark
28
1988
1993
2005
2008
-
Finland
48
1990
1993
-
-
-
France
28
1992
1999
-
-
-
Germany
41
1980
1990
-
-
-
Greece
28
1992
1999
2008
-
-
Ireland
28
1994
2008
2009
-
-
Italy
41
1976
1982
1999
-
-
Japan
43
1992
2002
2008
-
-
Netherlands
40
1980
1983
-
-
-
Norway
39
1987
1993
2005
-
-
Spain
39
1991
1993
2007
2009
-
Sweden
48
1991
1997
2008
-
-
UK
27
1987
1990
1993
2008
-
US
51
1974
1983
2008
-
-
Maximum a-posteriori (MAP) point estimator of TB used.
127

Table A.4.: Classical Bai and Perron (2003) break date estimates
Break dates
Country
T
1st
2nd
3rd
4th
5th
Australia
45
1974
1981
1990
1998
-
Belgium
28
1988
1993
1999
2001
-
Canada
35
1981
1986
1991
1997
-
Denmark
28
1985
1988
1993
1996
2008
Finland
48
1975
1991
1998
-
-
France
28
1992
1999
-
-
-
Germany
41
1975
1981
1992
-
-
Greece
28
1992
1997
2000
2005
2008
Ireland
28
1994
1998
2006
-
-
Italy
41
1976
1983
2001
-
-
Japan
43
1974
1992
1998
2004
-
Netherlands
40
1981
1987
1996
-
-
Norway
39
1981
1988
1996
2005
-
Spain
39
1978
1981
1992
1998
2007
Sweden
48
1991
1998
-
-
-
UK
27
1987
1991
1994
1997
2008
US
51
1974
1986
2006
-
-
128

Table A.5.: Posterior point estimates bŒ∏ and half lives under different priors
Country
bŒ∏Jef f
bŒ∏Norm
bŒ∏M
HLNorm
HLM
HLADF
Australia
0.59
0.59
0.65
1.30
1.63
5.05
Belgium
0.36
0.36
0.43
0.67
0.83
1.36
Canada
0.51
0.51
0.43
1.03
0.82
2.21
Denmark
0.60
0.60
0.61
1.35
1.41
2.89
Finland
0.77
0.76
0.78
2.58
2.78
6.58
France
0.33
0.32
0.36
0.61
0.67
3.14
Germany
0.72
0.71
0.70
2.05
1.94
2.64
Greece
1.07
0.96
0.81
15.43
3.33
2.92
Ireland
0.80
0.80
0.65
3.02
1.61
5.87
Italy
0.43
0.43
0.44
0.82
0.85
4.73
Japan
0.89
0.88
0.88
5.60
5.32
12.44
Netherlands
0.88
0.87
0.79
5.11
2.93
4.83
Norway
0.60
0.60
0.47
1.34
0.93
5.84
Spain
0.91
0.90
0.88
6.58
5.42
7.06
Sweden
0.62
0.61
0.61
1.41
1.41
7.49
UK
0.76
0.76
0.64
2.48
1.54
3.15
US
0.64
0.63
0.56
1.50
1.20
2.25
‚ÄôJeff‚Äô: Jeffreys prior, ‚ÄôNorm‚Äô: Normal prior, ‚ÄôM‚Äô: Model averaged,
‚ÄôADF‚Äô: Classical ADF test.
129

Table A.6.: Posterior probabilities of a unit root and tail probabilities
P(Œ∏ = 1|bŒ≥,bk,y)
P(Œ∏ ‚â•0.975|bŒ≥,bk,y)
P(T ‚â§tad f |Œ∏ = 1)
Country
Normal
Jeffreys
Normal
Jeffreys
ADF test
Australia
0.00
0.00
0.00
0.00
0.92
Belgium
0.00
0.00
0.00
0.00
0.39
Canada
0.00
0.00
0.00
0.00
0.22
Denmark
0.00
0.00
0.00
0.00
0.43
Finland
0.01
0.01
0.00
0.00
0.55
France
0.00
0.00
0.00
0.00
0.60
Germany
0.00
0.00
0.00
0.00
0.47
Greece
0.84
0.93
0.45
0.81
0.33
Ireland
0.03
0.03
0.00
0.01
0.97
Italy
0.00
0.00
0.00
0.00
0.74
Japan
0.25
0.25
0.02
0.05
0.35
Netherlands
0.19
0.19
0.02
0.03
0.33
Norway
0.00
0.00
0.00
0.00
0.57
Spain
0.05
0.05
0.01
0.01
0.48
Sweden
0.00
0.00
0.00
0.00
0.32
UK
0.01
0.01
0.00
0.00
0.57
US
0.00
0.00
0.00
0.00
0.43
130

B. Tables - chapter 4
Table B.1.: Testing for no periodicity
Country
FPAR - stat.
p - val.
Australia
0.90
0.54
Belgium
0.96
0.48
Canada
1.16
0.32
Denmark
2.07
0.03
Finland
0.51
0.90
France
0.67
0.77
Germany
1.71
0.08
Greece
3.62
0.00
Ireland
0.67
0.77
Italy
7.90
0.00
Japan
1.01
0.44
Netherlands
1.73
0.07
Norway
0.86
0.58
Spain
1.16
0.32
Sweden
2.02
0.03
UK
1.07
0.39
US
0.54
0.87
‚ÄôFPAR‚Äô: F-statistic to test the null of no periodicity,
i.e. H0 : œÜs = œÜS, for s = 1...S‚àí1.
131

Table B.2.: Posterior probabilities of the number of breaks and the break dates
Number of breaks
Number of breaks
Country
f (m = 0|y)
f (m = 1|y)
T MAP
B
BIC (m = 0)
BIC (m = 1)
Australia
0.57
0.43
2009(1)
-2.72
-2.35
Belgium
0.99
0.01
2001(7)
-2.12
-1.79
Canada
0.99
0.01
2008(12)
-2.31
-1.93
Denmark
0.99
0.01
2008(11)
-2.65
-2.35
Finland
0.38
0.62
2009(1)
-0.75
-0.41
France
1.00
0.00
2005(3)
-3.19
-2.94
Germany
0.01
0.99
2006(12)
-2.35
-2.08
Greece
0.03
0.97
2010(8)
-0.62
-0.25
Ireland
0.00
1.00
2008(4)
-2.31
-2.06
Italy
0.00
1.00
2003(11)
-1.13
-0.82
Japan
1.00
0.00
2011(1)
-3.08
-2.71
Netherlands
0.99
0.01
2005(7)
-3.25
-2.93
Norway
1.00
0.00
2006(5)
-3.51
-3.18
Spain
0.00
1.00
2008(3)
-1.85
-1.64
Sweden
0.87
0.13
2000(12)
-1.06
-0.76
UK
0.99
0.01
2008(4)
-3.69
-3.36
US
0.99
0.01
2009(5)
-2.64
-2.29
‚Äôf ()‚Äô: Posterior probability of a model with(out) break. ‚ÄôBIC‚Äô: Bayesian information criterion.
‚ÄôTB‚Äô: Maximum a-posteriori (MAP) point estimate of the break date.
132

Table B.3.: Bayesian and classical test results for a periodic unit root
Country
Determ.
P0 cond.
P0 BMA
Post. mean œÅ
œÅ - 95% HPD
œÑBF - stat.
Australia
Both
0.47
0.43
0.20
[0.02 ; 0.64]
-1.73
Belgium
Drift
0.23
0.18
0.36
[0.17 ; 0.66]
-2.37
Canada
Both
0.52
0.47
0.40
[0.15 ; 0.85]
-2.37
Denmark
Drift
0.86
0.78
1.09
[0.84 ; 1.40]
0.67
Finland
Both
0.01
0.00
0.15
[0.02 ; 0.40]
-3.66
France
Drift
0.72
0.58
0.74
[0.54 ; 1.01]
-1.90
Germany
Drift
0.82
0.86
0.84
[0.71 ; 1.00]
0.46
Greece
Drift
0.94
0.95
0.70
[0.33 ; 1.23]
1.97
Ireland
Drift
0.99
0.99
1.16
[1.04 ; 1.28]
2.87
Italy
Drift
0.25
0.33
0.47
[0.23 ; 0.80]
-2.53
Japan
Drift
0.33
0.32
0.60
[0.31 ; 1.01]
-1.85
Netherlands
Both
0.80
0.79
0.90
[0.66 ; 1.19]
-0.83
Norway
Drift
0.66
0.62
0.79
[0.55 ; 1.13]
-1.37
Spain
Drift
0.99
0.99
1.23
[1.09 ; 1.38]
3.76
Sweden
Drift
0.15
0.14
0.37
[0.13 ; 0.81]
-2.56
UK
Drift
0.98
0.98
1.13
[0.95 ; 1.35]
1.55
US
Drift
0.88
0.86
0.96
[0.79 ; 1.15]
-0.48
Notations: ‚ÄôDeterm.‚Äô denotes the deterministic speciÔ¨Åcation of the seasonal components included in the
model, i.e. periodic drifts, trends or both. ‚ÄôP0 cond.‚Äô: denotes the posterior probability of the periodic unit
root null (conditional on a certain model). ‚ÄôP0 BMA‚Äô: denotes the BMA result of the posterior probability
of the periodic unit root null (given the MAP estimate T MAP
B
for the break point). ‚ÄôœÅ - 95% HPD‚Äô: denotes
the HPD interval of the sampled œÅ-values. ‚ÄôœÑBF-stat.‚Äô: denotes the œÑ test statistic of the classical Boswijk
and Franses (1996) test with -2.86 the 5% critical value.
133

Table B.4.: Results of (non)seasonal unit root tests
Country
F - stat. (+1)
F - stat. (-1)
p - val. (+1)
p - val. (-1)
Australia
1.99
373.62
0.03
0.00
Belgium
1.30
512.10
0.22
0.00
Canada
1.28
807.19
0.23
0.00
Denmark
1.94
2759.99
0.04
0.00
Finland
4.44
43.62
0.00
0.00
France
0.93
1512.57
0.51
0.00
Germany
1.57
2030.56
0.11
0.00
Greece
4.20
541.72
0.00
0.00
Ireland
2.06
6929.18
0.03
0.00
Italy
4.58
490.83
0.00
0.00
Japan
1.17
570.45
0.30
0.00
Netherlands
1.64
2485.01
0.09
0.00
Norway
0.93
1394.06
0.51
0.00
Spain
1.95
9594.88
0.04
0.00
Sweden
2.36
280.79
0.01
0.00
UK
1.14
6094.98
0.33
0.00
US
0.52
5861.31
0.89
0.00
The reported F-statistics and corresponding p-values are obtained from BMA versions
of the tests. ‚Äô+1‚Äô and ‚Äô-1‚Äô denote the tests for a unit root at the zero and œÄ-frequency, respectively.
134

Table B.5.: 95% HPD intervals of the œÜs coefÔ¨Åcients
Country
œÜ1
œÜ2
œÜ3
œÜ4
œÜ5
œÜ6
Australia
[0.77; 1.32]
[0.73; 1.23]
[0.47; 1.14]
[0.65; 1.01]
[0.82; 1.29]
[0.77; 1.19]
Belgium
[0.81; 1.23]
[0.91; 1.26]
[0.83; 1.15]
[0.76; 1.08]
[0.80; 1.14]
[0.69; 1.04]
Canada
[0.86; 1.17]
[0.84; 1.13]
[0.91; 1.18]
[0.83; 1.10]
[0.93; 1.20]
[0.73; 0.98]
Denmark
[1.04; 1.21]
[0.87; 1.03]
[0.97; 1.13]
[0.88; 1.05]
[0.88; 1.06]
[0.93; 1.10]
Finland
[0.55; 1.30]
[0.40; 1.15]
[0.35; 1.10]
[0.45; 1.25]
[0.30; 1.00]
[0.20; 0.95]
France
[0.92; 1.15]
[0.89; 1.08]
[0.86; 1.06]
[0.82; 1.03]
[0.83; 1.04]
[0.84; 1.07]
Germany
[0.81; 0.99]
[0.97; 1.17]
[0.95; 1.13]
[0.93; 1.14]
[0.93; 1.13]
[0.86; 1.06]
Greece
[0.85; 1.10]
[0.86; 1.21]
[0.65; 1.09]
[0.84; 1.22]
[1.04; 1.35]
[0.71; 1.01]
Ireland
[0.75; 1.15]
[0.75; 1.10]
[0.75; 1.05]
[0.80; 1.00]
[0.85; 1.05]
[0.90; 1.05]
Italy
[0.55; 1.00]
[0.95; 1.35]
[0.95; 1.30]
[0.70; 1.05]
[0.55; 0.95]
[0.80; 1.25]
Japan
[0.73; 1.09]
[0.67; 1.06]
[0.97; 1.36]
[0.89; 1.22]
[0.87; 1.18]
[0.84; 1.14]
Netherl.
[0.98; 1.16]
[0.92; 1.08]
[0.96; 1.12]
[0.84; 1.00]
[0.89; 1.06]
[0.93; 1.10]
Norway
[0.83; 1.06]
[0.83; 1.06]
[0.88; 1.12]
[0.91; 1.15]
[0.90; 1.13]
[0.88; 1.10]
Spain
[0.90; 1.12]
[0.90; 1.06]
[0.88; 1.06]
[0.88; 1.02]
[0.92; 1.02]
[0.92; 1.04]
Sweden
[0.56; 1.04]
[0.64; 1.16]
[0.64; 1.14]
[0.90; 1.36]
[0.72; 1.16]
[0.66; 1.12]
UK
[0.97; 1.09]
[0.98; 1.12]
[0.92; 1.04]
[0.96; 1.09]
[0.97; 1.09]
[0.94; 1.07]
US
[0.95; 1.08]
[0.93; 1.05]
[0.94; 1.06]
[0.89; 1.02]
[0.95; 1.08]
[0.95; 1.08]
All HPD regions were computed using the respective model averaged posteriors of the œÜs coefÔ¨Åcients.
135

Table B.6.: 95% HPD intervals of the œÜs coefÔ¨Åcients (Cont.)
Country
œÜ7
œÜ8
œÜ9
œÜ10
œÜ11
œÜ12
Australia
[0.73; 1.14]
[0.83; 1.24]
[0.81; 1.18]
[0.80; 1.17]
[0.62; 0.98]
[0.71; 1.12]
Belgium
[0.73; 1.11]
[0.77; 1.13]
[0.72; 1.09]
[0.53; 0.92]
[0.74; 1.20]
[0.80; 1.25]
Canada
[0.86; 1.14]
[0.84; 1.12]
[0.70; 0.98]
[0.83; 1.16]
[0.75; 1.07]
[0.84; 1.17]
Denmark
[0.83; 1.01]
[0.91; 1.09]
[0.96; 1.14]
[0.95; 1.12]
[0.93; 1.10]
[0.92; 1.08]
Finland
[0.51; 1.25]
[0.40; 1.15]
[0.15; 0.95]
[0.50; 1.35]
[0.40; 1.25]
[0.25; 1.10]
France
[0.83; 1.07]
[0.92; 1.16]
[0.81; 1.04]
[0.87; 1.12]
[0.92; 1.16]
[0.84; 1.07]
Germany
[0.87; 1.06]
[0.95; 1.15]
[0.99; 1.18]
[0.94; 1.12]
[0.86; 1.03]
[0.86; 1.04]
Greece
[0.89; 1.22]
[1.02; 1.34]
[0.76; 1.02]
[0.94; 1.25]
[1.05; 1.37]
[0.77; 1.04]
Ireland
[0.90; 1.10]
[0.90; 1.05]
[0.90; 1.00]
[0.90; 1.05]
[0.90; 1.05]
[0.90; 1.10]
Italy
[0.75; 1.25]
[0.60; 0.90]
[0.25; 1.15]
[0.70; 1.20]
[0.70; 1.15]
[0.75; 1.20]
Japan
[0.79; 1.09]
[0.74; 1.04]
[0.82; 1.14]
[0.71; 1.02]
[0.79; 1.13]
[0.71; 1.06]
Netherl.
[0.80; 0.97]
[0.93; 1.11]
[0.91; 1.09]
[0.92; 1.09]
[0.93; 1.11]
[0.88; 1.06]
Norway
[0.94; 1.16]
[0.90; 1.11]
[0.77; 0.98]
[0.83; 1.06]
[0.88; 1.12]
[0.87; 1.10]
Spain
[0.94; 1.06]
[0.94; 1.04]
[0.96; 1.06]
[0.90; 1.04]
[0.91; 1.04]
[0.86; 1.06]
Sweden
[0.38; 0.90]
[0.66; 1.18]
[0.68; 1.22]
[0.62; 1.12]
[0.52; 1.04]
[0.88; 1.36]
UK
[0.92; 1.04]
[0.94; 1.07]
[0.97; 1.10]
[0.93; 1.05]
[0.91; 1.03]
[0.97; 1.10]
US
[0.92; 1.05]
[0.94; 1.07]
[0.92; 1.05]
[0.93; 1.06]
[0.91; 1.04]
[0.96; 1.09]
All HPD regions were computed using the respective model averaged posteriors of the œÜs coefÔ¨Åcients.
136

C. Tables - chapter 5
Table C.1.: Testing for no periodicity
Series
FPAR - stat.
p - val.
East-Germany
2.69
0.00
West-Germany
2.34
0.00
Baden-Wuerttemberg
0.93
0.51
Bavaria
6.22
0.00
Berlin
1.17
0.31
Brandenburg
1.79
0.06
Bremen
0.48
0.91
Hamburg
0.38
0.96
Hesse
2.48
0.01
Lower Saxony
2.93
0.00
Mecklenburg-Western Pomerania
2.15
0.02
North Rhine-Westphalia
1.76
0.06
Rhineland-Palatinate
2.64
0.00
Saarland
1.97
0.03
Saxony
2.89
0.00
Saxony-Anhalt
2.72
0.00
Schleswig-Holstein
2.11
0.02
Thuringia
2.03
0.03
‚ÄôFPAR‚Äô: F-statistic to test the null of no periodicity,
i.e. H0 : œÜs = œÜS, for s = 1...S‚àí1.
137

Table C.2.: Evaluation of 12-months ahead forecasts
BMA-PAR
SARMA(p, q) √ó(P, Q)12
PMEANS
BPAR
Series
PMSE
PMSE
Model order
PMSE
PMSE
East-Germany
0.3238
0.2932
(2, 0) √ó(2, 0)
0.2497
0.2586
West-Germany
0.1995‚ãÜ
0.3173
(2, 0) √ó(1, 0)
0.3547
0.3207
Baden-Wuerttemberg
0.2205
0.2451
(2, 1) √ó(1, 0)
0.1883
0.1370‚ãÜ
Bavaria
0.3035‚ãÜ
0.4067
(1, 1) √ó(2, 0)
0.7351
0.3958
Berlin
0.3835
0.3652‚ãÜ
(1, 1) √ó(1, 0)
0.7728
0.3982
Brandenburg
0.2021
0.3349
(1, 1) √ó(2, 0)
0.2514
0.3336
Bremen
0.2833‚ãÜ
0.4024
(2, 0) √ó(1, 0)
0.3497
0.3367
Hamburg
0.0965‚ãÜ
0.2436
(1, 1) √ó(1, 0)
0.1393
0.1484
Hesse
0.2897
0.3830
(1, 1) √ó(1, 0)
0.2217‚ãÜ
0.2537
Lower Saxony
0.2826‚ãÜ
0.4021
(1, 1) √ó(1, 0)
0.3944
0.3934
Mecklenburg-Western Pom.
0.2348
0.1408‚ãÜ
(1, 1) √ó(1, 0)
0.5287
0.3998
North Rhine-Westphalia
0.3141‚ãÜ
0.3758
(1, 1) √ó(1, 0)
0.3611
0.3557
Rhineland-Palatinate
0.1034‚ãÜ
0.4190
(1, 1) √ó(1, 1)
0.4069
0.4026
Saarland
0.6974
0.6813
(1, 1) √ó(1, 0)
0.5794‚ãÜ
0.5906
Saxony
0.2835
0.5534
(1, 1) √ó(2, 0)
0.2822‚ãÜ
0.3013
Saxony-Anhalt
0.4367
0.2162‚ãÜ
(1, 0) √ó(2, 0)
0.2446
0.2591
Schleswig-Holstein
0.1282
0.1165‚ãÜ
(2, 0) √ó(1, 0)
0.2021
0.2117
Thuringia
0.4691‚ãÜ
0.7103
(1, 0) √ó(2, 1)
0.6316
0.6545
‚ÄôPMSE‚Äô: Predictive Mean Squared Error , ‚Äô‚ãÜ‚Äô: signiÔ¨Åcant
138

Table C.3.: Evaluation of 12-months ahead forecasts (Cont.)
BMA-PAR
SARMA(p, q) √ó(P, Q)12
PMEANS
BPAR
Series
MAPE
MAPE
Model order
MAPE
MAPE
East-Germany
0.0203
0.0220
(2, 0) √ó(2, 0)
0.0153
0.0180
West-Germany
0.0229‚ãÜ
0.0452
(2, 0) √ó(1, 0)
0.0510
0.0454
Baden-Wuerttemberg
0.0427
0.0461
(2, 1) √ó(1, 0)
0.0379
0.0248‚ãÜ
Bavaria
0.0648‚ãÜ
0.0784
(1, 1) √ó(2, 0)
0.1683
0.0877
Berlin
0.0240
0.0239‚ãÜ
(1, 1) √ó(1, 0)
0.0498
0.0251
Brandenburg
0.0121
0.0266
(1, 1) √ó(2, 0)
0.0133
0.0183
Bremen
0.0149‚ãÜ
0.0305
(2, 0) √ó(1, 0)
0.0259
0.0232
Hamburg
0.0088‚ãÜ
0.0259
(1, 1) √ó(1, 0)
0.0140
0.0151
Hesse
0.0429
0.0574
(1, 1) √ó(1, 0)
0.0330‚ãÜ
0.0379
Lower Saxony
0.0312‚ãÜ
0.0517
(1, 1) √ó(1, 0)
0.0480
0.0479
Mecklenburg-Western Pom.
0.0149
0.0077‚ãÜ
(1, 1) √ó(1, 0)
0.0377
0.0271
North Rhine-Westphalia
0.0337‚ãÜ
0.0407
(1, 1) √ó(1, 0)
0.0392
0.0385
Rhineland-Palatinate
0.0139‚ãÜ
0.0692
(1, 1) √ó(1, 1)
0.0652
0.0635
Saarland
0.0816
0.0809
(1, 1) √ó(1, 0)
0.0683‚ãÜ
0.0702
Saxony
0.0176
0.0486
(1, 1) √ó(2, 0)
0.0209
0.0228
Saxony-Anhalt
0.0299
0.0159‚ãÜ
(1, 0) √ó(2, 0)
0.0166
0.0179
Schleswig-Holstein
0.0149
0.0132‚ãÜ
(2, 0) √ó(1, 0)
0.0241
0.0249
Thuringia
0.0456‚ãÜ
0.0691
(1, 0) √ó(2, 1)
0.0630
0.0655
‚ÄôMAPE‚Äô: Mean Absolute Percentage Error, ‚Äô‚ãÜ‚Äô: signiÔ¨Åcant
139

Table C.4.: Bayesian one-year ahead forecasts (1)
East Germany
West Germany
Dates
BMA (s.e.)
95% - HPD
BMA (s.e.)
95% - HPD
2013(3)
12.49 (0.29)
[11.92; 13.10]
6.99 (0.20)
[6.61; 7.39]
2013(4)
11.92 (0.32)
[11.25; 12.54]
6.79 (0.23)
[6.35; 7.27]
2013(5)
11.34 (0.40)
[10.52; 12.15]
6.49 (0.22)
[6.06; 6.95]
2013(6)
11.02 (0.42)
[10.18; 11.89]
6.38 (0.22)
[5.94; 6.85]
2013(7)
11.36 (0.49)
[10.34; 12.39]
6.61 (0.28)
[6.06; 7.16]
2013(8)
11.23 (0.33)
[10.57; 11.90]
6.62 (0.27)
[6.11; 7.17]
2013(9)
10.78 (0.43)
[9.91; 11.66]
6.38 (0.32)
[5.73; 7.03]
2013(10)
10.47 (0.43)
[9.62; 11.33]
6.30 (0.44)
[5.44; 7.21]
2013(11)
10.50 (0.40)
[9.68; 11.31]
6.36 (0.44)
[5.46; 7.29]
2013(12)
11.11 (0.68)
[9.71; 12.48]
6.64 (0.52)
[5.56; 7.74]
2014(1)
12.89 (0.72)
[11.42; 14.35]
7.37 (0.52)
[6.19; 8.45]
2014(2)
13.05 (0.47)
[12.10; 14.00]
7.44 (0.49)
[6.39; 8.59]
‚ÄôBMA‚Äô: Mean of model averaged posterior predictive density, standard error in brackets.
‚ÄôHPD‚Äô: Highest posterior density region.
140

Table C.5.: Bayesian one-year ahead forecasts (2)
Baden-Wuerttemberg
Bavaria
Dates
BMA (s.e.)
95% - HPD
BMA (s.e.)
95% - HPD
2013(3)
4.66 (0.19)
[4.29; 5.03]
4.89 (0.26)
[4.37; 5.38]
2013(4)
4.53 (0.22)
[4.11; 4.96]
4.49 (0.28)
[3.96; 5.08]
2013(5)
4.30 (0.22)
[3.87; 4.72]
4.08 (0.27)
[3.58; 4.64]
2013(6)
4.18 (0.27)
[3.64; 4.73]
3.94 (0.27)
[3.42; 4.49]
2013(7)
4.34 (0.32)
[3.70; 4.99]
4.05 (0.32)
[3.43; 4.69]
2013(8)
4.47 (0.27)
[3.92; 5.02]
4.27 (0.28)
[3.73; 4.83]
2013(9)
4.26 (0.26)
[3.74; 4.79]
4.08 (0.34)
[3.38; 4.78]
2013(10)
4.16 (0.34)
[3.49; 4.85]
3.98 (0.45)
[3.13; 4.94]
2013(11)
4.16 (0.36)
[3.43; 4.93]
4.11 (0.51)
[3.10; 5.21]
2013(12)
4.30 (0.36)
[3.56; 5.04]
4.56 (0.77)
[2.95; 6.22]
2014(1)
4.71 (0.34)
[3.95; 5.37]
5.60 (0.73)
[3.92; 7.04]
2014(2)
4.71 (0.37)
[3.93; 5.51]
5.62 (0.52)
[4.59; 6.85]
‚ÄôBMA‚Äô: Mean of model averaged posterior predictive density, standard error in brackets.
‚ÄôHPD‚Äô: Highest posterior density region.
141

Table C.6.: Bayesian one-year ahead forecasts (3)
Berlin
Brandenburg
Dates
BMA (s.e.)
95% - HPD
BMA (s.e.)
95% - HPD
2013(3)
14.17 (0.27)
[13.62; 14.71]
11.80 (0.33)
[11.16; 12.49]
2013(4)
14.05 (0.31)
[13.44; 14.66]
11.24 (0.40)
[10.42; 12.04]
2013(5)
13.62 (0.30)
[12.99; 14.21]
10.56 (0.41)
[9.73; 11.39]
2013(6)
13.30 (0.38)
[12.50; 14.02]
10.37 (0.50)
[9.38; 11.36]
2013(7)
13.57 (0.31)
[12.95; 14.19]
10.79 (0.53)
[9.71; 11.90]
2013(8)
13.51 (0.31)
[12.89; 14.13]
10.57 (0.39)
[9.77; 11.35]
2013(9)
13.12 (0.38)
[12.34; 13.85]
10.11 (0.44)
[9.23; 11.01]
2013(10)
12.89 (0.41)
[12.08; 13.70]
9.88 (0.44)
[9.01; 10.75]
2013(11)
12.75 (0.41)
[11.89; 13.56]
9.91 (0.42)
[9.06; 10.76]
2013(12)
12.98 (0.41)
[12.17; 13.79]
10.61 (0.80)
[9.01; 12.24]
2014(1)
14.01 (0.74)
[12.41; 15.61]
12.42 (0.71)
[11.01; 13.88]
2014(2)
14.05 (0.35)
[13.33; 14.72]
12.59 (0.46)
[11.64; 13.54]
‚ÄôBMA‚Äô: Mean of model averaged posterior predictive density, standard error in brackets.
‚ÄôHPD‚Äô: Highest posterior density region.
142

Table C.7.: Bayesian one-year ahead forecasts (4)
Bremen
Hamburg
Dates
BMA (s.e.)
95% - HPD
BMA (s.e.)
95% - HPD
2013(3)
12.69 (0.41)
[11.91; 13.53]
8.65 (0.37)
[7.92; 9.71]
2013(4)
12.67 (0.50)
[11.67; 13.65]
8.61 (0.49)
[7.63; 9.69]
2013(5)
12.36 (0.45)
[11.45; 13.24]
8.39 (0.48)
[7.57; 9.79]
2013(6)
12.23 (0.48)
[11.24; 13.15]
8.26 (0.37)
[7.55; 9.21]
2013(7)
12.51 (0.49)
[11.54; 13.48]
8.49 (0.42)
[7.68; 9.71]
2013(8)
12.43 (0.56)
[11.30; 13.57]
8.39 (0.42)
[7.55; 9.62]
2013(9)
12.10 (0.62)
[10.88; 13.39]
8.19 (0.36)
[7.54; 9.07]
2013(10)
12.02 (0.67)
[10.72; 13.50]
8.09 (0.39)
[7.21; 8.86]
2013(11)
11.93 (0.65)
[10.64; 13.31]
8.03 (0.44)
[7.14; 9.25]
2013(12)
12.09 (0.74)
[10.62; 13.68]
8.15 (0.49)
[7.07; 9.20]
2014(1)
13.06 (1.39)
[10.51; 16.68]
8.72 (0.41)
[7.79; 9.58]
2014(2)
13.16 (0.70)
[11.71; 14.71]
8.70 (0.36)
[7.94; 9.46]
‚ÄôBMA‚Äô: Mean of model averaged posterior predictive density, standard error in brackets.
‚ÄôHPD‚Äô: Highest posterior density region.
143

Table C.8.: Bayesian one-year ahead forecasts (5)
Hesse
Lower Saxony
Dates
BMA (s.e.)
95% - HPD
BMA (s.e.)
95% - HPD
2013(3)
6.77 (0.19)
[6.39; 7.16]
7.58 (0.25)
[6.94; 7.96]
2013(4)
6.66 (0.22)
[6.22; 7.09]
7.25 (0.30)
[6.51; 7.69]
2013(5)
6.37 (0.21)
[5.96; 6.78]
6.79 (0.28)
[6.07; 7.20]
2013(6)
6.28 (0.22)
[5.85; 6.71]
6.71 (0.35)
[5.80; 7.21]
2013(7)
6.53 (0.26)
[6.02; 7.04]
7.00 (0.29)
[6.26; 7.39]
2013(8)
6.44 (0.23)
[5.98; 6.91]
6.86 (0.31)
[6.16; 7.38]
2013(9)
6.18 (0.28)
[5.61; 6.74]
6.55 (0.33)
[5.73; 7.06]
2013(10)
6.12 (0.35)
[5.39; 6.83]
6.45 (0.37)
[5.52; 7.04]
2013(11)
6.08 (0.32)
[5.41; 6.72]
7.54 (0.41)
[5.51; 7.21]
2013(12)
6.28 (0.37)
[5.49; 7.02]
6.95 (0.60)
[5.43; 7.94]
2014(1)
6.89 (0.42)
[6.01; 7.78]
7.81 (0.72)
[5.94; 9.04]
2014(2)
6.96 (0.36)
[6.26; 7.75]
7.84 (0.45)
[6.59; 8.49]
‚ÄôBMA‚Äô: Mean of model averaged posterior predictive density, standard error in brackets.
‚ÄôHPD‚Äô: Highest posterior density region.
144

Table C.9.: Bayesian one-year ahead forecasts (6)
Mecklenburg-Western Pomerania
North Rhine-Westphalia
Dates
BMA (s.e.)
95% - HPD
BMA (s.e.)
95% - HPD
2013(3)
14.37 (0.36)
[13.66; 15.08]
9.24 (0.19)
[8.87; 9.61]
2013(4)
13.42 (0.41)
[12.62; 14.26]
9.10 (0.21)
[8.69; 9.51]
2013(5)
12.49 (0.43)
[11.63; 13.36]
8.87 (0.21)
[8.46; 9.28]
2013(6)
11.89 (0.47)
[10.93; 12.84]
8.79 (0.21)
[8.38; 9.20]
2013(7)
12.10 (0.54)
[11.06; 13.20]
9.04 (0.27)
[8.51; 9.59]
2013(8)
12.60 (0.52)
[11.49; 13.71]
8.94 (0.25)
[8.45; 9.46]
2013(9)
11.44 (0.50)
[10.41; 12.41]
8.70 (0.27)
[8.27; 9.25]
2013(10)
11.21 (0.47)
[10.24; 12.15]
8.64 (0.31)
[8.03; 9.25]
2013(11)
11.65 (0.43)
[10.78; 12.52]
8.63 (0.33)
[7.96; 9.28]
2013(12)
12.53 (0.60)
[11.31 ; 13.73]
8.51 (0.39)
[8.00; 9.62]
2014(1)
14.51 (0.90)
[12.69; 16.39]
9.36 (0.39)
[8.56; 10.16]
2014(2)
14.68 (0.55)
[13.54; 15.78]
9.49 (0.55)
[8.39; 10.67]
‚ÄôBMA‚Äô: Mean of model averaged posterior predictive density, standard error in brackets.
‚ÄôHPD‚Äô: Highest posterior density region.
145

Table C.10.: Bayesian one-year ahead forecasts (7)
Rhineland-Palatinate
Saarland
Dates
BMA (s.e.)
95% - HPD
BMA (s.e.)
95% - HPD
2013(3)
6.26 (0.26)
[5.73; 6.71]
8.09 (0.23)
[7.64; 8.53]
2013(4)
5.99 (0.30)
[5.35; 6.55]
7.92 (0.29)
[7.35; 8.50]
2013(5)
5.65 (0.27)
[5.11; 6.17]
7.64 (0.24)
[7.17; 8.12]
2013(6)
5.54 (0.30)
[5.00; 6.12]
7.54 (0.25)
[7.04; 8.03]
2013(7)
6.79 (0.32)
[5.16; 6.44]
7.79 (0.32)
[7.15; 8.44]
2013(8)
5.69 (0.33)
[5.03; 6.36]
7.71 (0.33)
[7.07; 8.35]
2013(9)
5.40 (0.37)
[4.66; 6.17]
7.41 (0.27)
[6.88; 7.96]
2013(10)
5.32 (0.43)
[4.48; 6.32]
7.28 (0.35)
[6.56; 7.98]
2013(11)
5.38 (0.48)
[4.39; 6.41]
7.28 (0.31)
[6.65; 7.90]
2013(12)
5.74 (0.56)
[4.54; 6.89]
7.50 (0.41)
[6.66; 8.35]
2014(1)
6.47 (0.52)
[5.27; 7.58]
8.10 (0.41)
[7.20; 8.92]
2014(2)
6.47 (0.44)
[5.56; 7.41]
8.13 (0.46)
[7.15; 9.09]
‚ÄôBMA‚Äô: Mean of model averaged posterior predictive density, standard error in brackets.
‚ÄôHPD‚Äô: Highest posterior density region.
146

Table C.11.: Bayesian one-year ahead forecasts (8)
Saxony
Saxony-Anhalt
Dates
BMA (s.e.)
95% - HPD
BMA (s.e.)
95% - HPD
2013(3)
11.56 (0.36)
[10.82; 12.28]
13.15 (0.35)
[12.44; 13.84]
2013(4)
10.90 (0.38)
[10.10; 11.65]
12.55 (0.39)
[11.78; 13.32]
2013(5)
10.26 (0.45)
[9.35; 11.20]
11.98 (0.44)
[11.10; 12.88]
2013(6)
9.80 (0.50)
[8.76; 10.78]
11.59 (0.49)
[10.58; 12.61]
2013(7)
10.10 (0.63)
[8.85; 11.43]
11.91 (0.52)
[10.92; 12.99]
2013(8)
10.00 (0.40)
[9.19; 10.78]
11.69 (0.39)
[10.91; 12.49]
2013(9)
9.50 (0.50)
[8.49; 10.51]
11.08 (0.46)
[10.15; 12.02]
2013(10)
9.09 (0.46)
[8.17; 10.02]
10.57 (0.54)
[9.47; 11.66]
2013(11)
9.12 (0.41)
[8.31; 9.94]
10.53 (0.41)
[9.70; 11.35]
2013(12)
9.77 (0.76)
[8.26; 11.30]
11.19 (0.81)
[9.58; 12.81]
2014(1)
11.55 (0.83)
[9.90; 13.33]
13.14 (0.68)
[11.82; 14.51]
2014(2)
11.77 (0.57)
[10.56; 12.92]
13.26 (0.47)
[12.31; 14.17]
‚ÄôBMA‚Äô: Mean of model averaged posterior predictive density, standard error in brackets.
‚ÄôHPD‚Äô: Highest posterior density region.
147

Table C.12.: Bayesian one-year ahead forecasts (9)
Schleswig-Holstein
Thuringia
Dates
BMA (s.e.)
95% - HPD
BMA (s.e.)
95% - HPD
2013(3)
8.04 (0.23)
[7.58; 8.49]
9.78 (0.40)
[8.99; 10.60]
2013(4)
7.54 (0.28)
[6.98; 8.11]
9.00 (0.44)
[8.11; 9.88]
2013(5)
7.07 (0.25)
[6.58; 7.58]
8.38 (0.49)
[7.39; 9.36]
2013(6)
6.90 (0.33)
[6.23; 7.54]
7.89 (0.56)
[6.77; 9.04]
2013(7)
7.15 (0.26)
[6.61; 7.68]
8.28 (0.57)
[7.19; 9.51]
2013(8)
7.05 (0.29)
[6.48; 7.65]
8.19 (0.41)
[7.32; 9.04]
2013(9)
6.75 (0.34)
[6.06; 7.43]
7.64 (0.47)
[6.67; 8.59]
2013(10)
6.69 (0.40)
[5.86; 7.51]
7.26 (0.58)
[6.07; 8.45]
2013(11)
6.93 (0.47)
[5.95; 7.87]
7.28 (0.51)
[6.25; 8.32]
2013(12)
7.32 (0.52)
[6.26; 8.36]
8.07 (0.95)
[6.17; 9.95]
2014(1)
8.14 (0.80)
[6.38; 9.87]
9.95 (1.22)
[7.71; 12.41]
2014(2)
8.18 (0.41)
[7.32; 9.02]
10.10 (0.62)
[8.79; 11.37]
‚ÄôBMA‚Äô: Mean of model averaged posterior predictive density, standard error in brackets.
‚ÄôHPD‚Äô: Highest posterior density region.
148

D. Figures - chapter 2
‚àí5.5
‚àí4.0
‚àí2.5
1970
1980
1990
2000
2010
Time
probability
Time
probability
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 4 break date(s)
0.2
0.4
0.6
0.8
0
1
2
3
4
5
(p = 2)
density
Marginal posterior densities 'Australia'
Normal
Jeffreys
Figure D.1.: Series Australia: posterior densities for the break dates and the long run coefÔ¨Åcient.
149

‚àí3.0
‚àí2.6
‚àí2.2
1985
1990
1995
2000
2005
2010
Time
probability
Time
probability
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 4 break date(s)
0.2
0.3
0.4
0.5
0.6
0.7
1
2
3
4
5
(p = 1)
density
Marginal posterior densities 'Belgium'
Normal
Jeffreys
Figure D.2.: Series Belgium: posterior densities for the break dates and the long run coefÔ¨Åcient.
‚àí3.5
‚àí3.0
‚àí2.5
‚àí2.0
1975
1980
1985
1990
1995
2000
2005
2010
Time
probability
Time
probability
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 4 break date(s)
0.2
0.4
0.6
0.8
1.0
0
1
2
3
4
(p = 2)
density
Marginal posterior densities 'Canada'
Normal
Jeffreys
Figure D.3.: Series Canada: posterior densities for the break dates and the long run coefÔ¨Åcient.
150

‚àí3.5
‚àí3.0
‚àí2.5
1985
1990
1995
2000
2005
2010
Time
probability
Time
probability
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 4 break date(s)
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
1
2
3
4
5
6
(p = 1)
density
Marginal posterior densities 'Denmark'
Normal
Jeffreys
Figure D.4.: Series Denmark: posterior densities for the break dates and the long run coefÔ¨Åcient.
‚àí4.5
‚àí3.5
‚àí2.5
1970
1980
1990
2000
2010
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 2 break date(s)
0.5
0.6
0.7
0.8
0.9
1.0
0
2
4
6
8
(p = 2)
density
Marginal posterior densities 'Finland'
Normal
Jeffreys
Figure D.5.: Series Finland: posterior densities for the break dates and the long run coefÔ¨Åcient.
151

‚àí2.8
‚àí2.4
‚àí2.0
1985
1990
1995
2000
2005
2010
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 2 break date(s)
0.1
0.2
0.3
0.4
0.5
0.6
0.7
1
2
3
4
(p = 1)
density
Marginal posterior densities 'France'
Normal
Jeffreys
Figure D.6.: Series France: posterior densities for the break dates and the long run coefÔ¨Åcient.
‚àí5
‚àí4
‚àí3
‚àí2
1970
1980
1990
2000
2010
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 2 break date(s)
0.5
0.6
0.7
0.8
0.9
1.0
0
2
4
6
8
(p = 2)
density
Marginal posterior densities 'Germany'
Normal
Jeffreys
Figure D.7.: Series Germany: posterior densities for the break dates and the long run coefÔ¨Åcient.
152

‚àí2.8
‚àí2.4
‚àí2.0
1985
1990
1995
2000
2005
2010
Time
probability
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 3 break date(s)
0.6
0.7
0.8
0.9
1.0
1.1
0
1
2
3
4
5
(p = 1)
density
Marginal posterior densities 'Greece'
Normal
Jeffreys
Figure D.8.: Series Greece: posterior densities for the break dates and the long run coefÔ¨Åcient.
‚àí3.5
‚àí2.5
‚àí1.5
1985
1990
1995
2000
2005
2010
Time
probability
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 3 break date(s)
0.5
0.6
0.7
0.8
0.9
1.0
0
2
4
6
(p = 1)
density
Marginal posterior densities 'Ireland'
Normal
Jeffreys
Figure D.9.: Series Ireland: posterior densities for the break dates and the long run coefÔ¨Åcient.
153

‚àí3.5
‚àí2.5
1970
1980
1990
2000
2010
Time
probability
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 3 break date(s)
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0
1
2
3
4
5
6
(p = 1)
density
Marginal posterior densities 'Italy'
Normal
Jeffreys
Figure D.10.: Series Italy: posterior densities for the break dates and the long run coefÔ¨Åcient.
‚àí5.0
‚àí4.0
‚àí3.0
1970
1980
1990
2000
2010
Time
probability
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 3 break date(s)
0.6
0.7
0.8
0.9
1.0
1.1
0
2
4
6
8
10
(p = 1)
density
Marginal posterior densities 'Japan'
Normal
Jeffreys
Figure D.11.: Series Japan: posterior densities for the break dates and the long run coefÔ¨Åcient.
154

‚àí4.5
‚àí3.5
‚àí2.5
1970
1980
1990
2000
2010
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 2 break date(s)
0.5
0.6
0.7
0.8
0.9
1.0
0
2
4
6
8
10
(p = 2)
density
Marginal posterior densities 'Netherlands'
Normal
Jeffreys
Figure D.12.: Series Netherlands: posterior densities for the break dates and the long run coefÔ¨Åcient.
‚àí4.5
‚àí3.5
1980
1990
2000
2010
Time
probability
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 3 break date(s)
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
1
2
3
4
5
(p = 1)
density
Marginal posterior densities 'Norway'
Normal
Jeffreys
Figure D.13.: Series Norway: posterior densities for the break dates and the long run coefÔ¨Åcient.
155

‚àí5
‚àí4
‚àí3
‚àí2
1980
1990
2000
2010
Time
probability
Time
probability
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 4 break date(s)
0.75
0.80
0.85
0.90
0.95
1.00
1.05
0
5
10
15
(p = 2)
density
Marginal posterior densities 'Spain'
Normal
Jeffreys
Figure D.14.: Series Spain: posterior densities for the break dates and the long run coefÔ¨Åcient.
‚àí4.5
‚àí3.5
‚àí2.5
1970
1980
1990
2000
2010
Time
probability
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 3 break date(s)
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
0
1
2
3
4
5
(p = 1)
density
Marginal posterior densities 'Sweden'
Normal
Jeffreys
Figure D.15.: Series Sweden: posterior densities for the break dates and the long run coefÔ¨Åcient.
156

‚àí3.2
‚àí2.6
‚àí2.0
1985
1990
1995
2000
2005
2010
Time
probability
Time
probability
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 4 break date(s)
0.5
0.6
0.7
0.8
0.9
1.0
0
2
4
6
8
(p = 1)
density
Marginal posterior densities 'United Kingdom'
Normal
Jeffreys
Figure D.16.: Series UK: posterior densities for the break dates and the long run coefÔ¨Åcient.
‚àí3.6
‚àí3.0
‚àí2.4
1960
1970
1980
1990
2000
2010
Time
probability
Time
probability
Time
probability
0.0
0.2
0.4
0.6
0.8
1.0
Posterior probability distribution(s) of 3 break date(s)
0.2
0.4
0.6
0.8
1.0
0
1
2
3
4
5
(p = 1)
density
Marginal posterior densities 'United States'
Normal
Jeffreys
Figure D.17.: Series US: posterior densities for the break dates and the long run coefÔ¨Åcient.
157

breaks 'm'
0
1
2
3
4
5
6
lags 'p'
1
2
3
4
5
6
probability
0.00
0.05
0.10
0.15
Figure D.18.: Helicopter tour Germany: joint posterior mass function of break number and lags.
breaks 'm'
0
1
2
3
4
5
6
lags 'p'
1
2
3
4
5
6
probability
0.00
0.05
0.10
0.15
Figure D.19.: Helicopter tour Germany (2): joint posterior mass function of break number and lags.
158

E. Figures - chapter 4
l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
Nom. level
(a) Australia
l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
Nom. level
(b) Belgium
Figure E.20.: Bayesian p-values of recursive F-tests of non-periodicity: Australia and Belgium.
l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
Nom. level
(a) Canada
l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
ll
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
(b) Denmark
Figure E.21.: Bayesian p-values of recursive F-tests of non-periodicity: Canada and Denmark.
159

l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
(a) Finland
l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
Nom. level
(b) France
Figure E.22.: Bayesian p-values of recursive F-tests of non-periodicity: Finland and France.
l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
(a) Germany
l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
(b) Greece
Figure E.23.: Bayesian p-values of recursive F-tests of non-periodicity: Germany and Greece.
160

l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
Nom. level
(a) Ireland
l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
(b) Italy
Figure E.24.: Bayesian p-values of recursive F-tests of non-periodicity: Ireland and Italy.
l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
Nom. level
(a) Japan
l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
Nom. level
(b) Netherlands
Figure E.25.: Bayesian p-values of recursive F-tests of non-periodicity: Japan and Netherlands.
161

l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
Nom. level
(a) Norway
l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
Nom. level
(b) Spain
Figure E.26.: Bayesian p-values of recursive F-tests of non-periodicity: Norway and Spain.
l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
(a) Sweden
l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
Nom. level
(b) Great Britain
Figure E.27.: Bayesian p-values of recursive F-tests of non-periodicity: Sweden and Great Britain.
162

l
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Forward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
l
Nom. level
l
l
l
l
l
l
l
l
l
l
2
4
6
8
10
0.0
0.4
0.8
Backward rolling windows
p‚àívalue
l
l
l
l
l
l
l
l
l
l
Nom. level
Figure E.28.: Bayesian p-values of recursive F-tests of non-periodicity: USA.
163

F. Figures - chapter 5
0.0
0.2
0.4
0.6
0.8
1.0
0.6
1.0
1.4
1.8
Jeffreys' prior
p
density
0.0
0.2
0.4
0.6
0.8
1.0
0.6
0.8
1.0
1.2
1.4
Bayes' prior
p
density
0.0
0.2
0.4
0.6
0.8
1.0
5.0e‚àí10
1.5e‚àí09
Haldane's prior
p
density
0.0
0.2
0.4
0.6
0.8
1.0
0.985
0.995
1.005
Beta(1.01,1.01) prior
p
density
Figure F.29.: Used prior distributions for the Bayesian sign test.
0.2
0.4
0.6
0.8
1.0
0.2
0.4
0.6
0.8
1.0
with Jeffreys' prior
x/T
probability
0.2
0.4
0.6
0.8
1.0
0.3
0.4
0.5
0.6
0.7
0.8
0.9
with Bayes' prior
x/T
probability
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
with Haldane's prior
x/T
probability
0.2
0.4
0.6
0.8
1.0
0.3
0.4
0.5
0.6
0.7
0.8
0.9
with Beta(1.01,1.01) prior
x/T
probability
Figure F.30.: Posterior probability of H1 as a function of x for T = 8.
164

0.0
0.2
0.4
0.6
0.8
1.0
0.2
0.4
0.6
0.8
1.0
with Jeffreys' prior
x/T
probability
0.0
0.2
0.4
0.6
0.8
1.0
0.2
0.4
0.6
0.8
1.0
with Bayes' prior
x/T
probability
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
with Haldane's prior
x/T
probability
0.0
0.2
0.4
0.6
0.8
1.0
0.2
0.4
0.6
0.8
1.0
with Beta(1.01,1.01) prior
x/T
probability
Figure F.31.: Posterior probability of H1 as a function of x for T = 60.
165

Time
%
1995
2000
2005
2010
10
14
18
22
0
10
20
30
40
50
60
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
0
10
20
30
40
50
60
‚àí0.2
0.2
0.6
1.0
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí05
1e‚àí01
frequency
spectrum
Figure F.32.: Series East-Germany (01/1991-02/2013) with S(P)ACF and periodogram.
Time
%
1995
2000
2005
2010
6
7
8
9
10
11
12
0
10
20
30
40
50
60
‚àí0.2
0.2
0.6
1.0
Lag
ACF
0
10
20
30
40
50
60
‚àí0.4
0.0
0.4
0.8
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí05
1e‚àí03
1e‚àí01
1e+01
frequency
spectrum
Figure F.33.: Series West-Germany (01/1991-02/2013) with S(P)ACF and periodogram.
166

Time
%
1995
2000
2005
2010
4
5
6
7
8
9
0
10
20
30
40
50
60
‚àí0.2
0.2
0.6
1.0
Lag
ACF
0
10
20
30
40
50
60
‚àí0.4
0.0
0.4
0.8
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí05
1e‚àí03
1e‚àí01
frequency
spectrum
Figure F.34.: Series Baden-Wuerttemberg (01/1991-02/2013) with S(P)ACF and periodogram.
Time
%
1995
2000
2005
2010
4
5
6
7
8
9
10
0
10
20
30
40
50
60
‚àí0.2
0.2
0.6
1.0
Lag
ACF
0
10
20
30
40
50
60
‚àí0.5
0.0
0.5
1.0
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí05
1e‚àí03
1e‚àí01
1e+01
frequency
spectrum
Figure F.35.: Series Bavaria (01/1991-02/2013) with S(P)ACF and periodogram.
167

Time
%
1995
2000
2005
2010
10
12
14
16
18
20
22
0
10
20
30
40
50
60
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
0
10
20
30
40
50
60
‚àí0.2
0.2
0.4
0.6
0.8
1.0
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí04
1e‚àí02
1e+00
frequency
spectrum
Figure F.36.: Series Berlin (01/1991-02/2013) with S(P)ACF and periodogram.
Time
%
1995
2000
2005
2010
8
10
14
18
22
0
10
20
30
40
50
60
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
0
10
20
30
40
50
60
‚àí0.2
0.2
0.6
1.0
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí05
1e‚àí03
1e‚àí01
1e+01
frequency
spectrum
Figure F.37.: Series Brandenburg (01/1991-02/2013) with S(P)ACF and periodogram.
168

Time
%
1995
2000
2005
2010
10
12
14
16
18
20
0
10
20
30
40
50
60
‚àí0.2
0.2
0.6
1.0
Lag
ACF
0
10
20
30
40
50
60
‚àí0.2
0.2
0.6
1.0
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí04
1e‚àí02
1e+00
frequency
spectrum
Figure F.38.: Series Bremen (01/1991-02/2013) with S(P)ACF and periodogram.
Time
%
1995
2000
2005
2010
8
9
10
11
12
13
14
0
10
20
30
40
50
60
‚àí0.4
0.0
0.4
0.8
Lag
ACF
0
10
20
30
40
50
60
‚àí0.4
0.0
0.4
0.8
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí05
1e‚àí03
1e‚àí01
1e+01
frequency
spectrum
Figure F.39.: Series Hamburg (01/1991-02/2013) with S(P)ACF and periodogram.
169

Time
%
1995
2000
2005
2010
5
6
7
8
9
10
11
0
10
20
30
40
50
60
‚àí0.4
0.0
0.4
0.8
Lag
ACF
0
10
20
30
40
50
60
‚àí0.4
0.0
0.4
0.8
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí05
1e‚àí03
1e‚àí01
1e+01
frequency
spectrum
Figure F.40.: Series Hesse (01/1991-02/2013) with S(P)ACF and periodogram.
Time
%
1995
2000
2005
2010
7
8
9
10
12
14
0
10
20
30
40
50
60
‚àí0.2
0.2
0.6
1.0
Lag
ACF
0
10
20
30
40
50
60
‚àí0.4
0.0
0.4
0.8
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí06
1e‚àí04
1e‚àí02
1e+00
frequency
spectrum
Figure F.41.: Series Lower Saxony (01/1991-02/2013) with S(P)ACF and periodogram.
170

Time
%
1995
2000
2005
2010
15
20
25
0
10
20
30
40
50
60
0.0
0.2
0.4
0.6
0.8
Lag
ACF
0
10
20
30
40
50
60
‚àí0.4
0.0
0.4
0.8
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí05
1e‚àí03
1e‚àí01
1e+01
frequency
spectrum
Figure F.42.: Series Mecklenburg-Western Pom. (01/1991-02/2013) with S(P)ACF and periodogram.
Time
%
1995
2000
2005
2010
8
9
10
11
12
13
14
0
10
20
30
40
50
60
‚àí0.4
0.0
0.4
0.8
Lag
ACF
0
10
20
30
40
50
60
‚àí0.4
0.0
0.4
0.8
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí05
1e‚àí03
1e‚àí01
1e+01
frequency
spectrum
Figure F.43.: Series North Rhine-Westphalia (01/1991-02/2013) with S(P)ACF and periodogram.
171

Time
%
1995
2000
2005
2010
5
6
7
8
9
10
11
0
10
20
30
40
50
60
‚àí0.2
0.2
0.6
1.0
Lag
ACF
0
10
20
30
40
50
60
‚àí0.4
0.0
0.4
0.8
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí05
1e‚àí03
1e‚àí01
1e+01
frequency
spectrum
Figure F.44.: Series Rhineland-Palatinate (01/1991-02/2013) with S(P)ACF and periodogram.
Time
%
1995
2000
2005
2010
8
10
12
14
0
10
20
30
40
50
60
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
0
10
20
30
40
50
60
‚àí0.4
0.0
0.4
0.8
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí05
1e‚àí03
1e‚àí01
frequency
spectrum
Figure F.45.: Series Saarland (01/1991-02/2013) with S(P)ACF and periodogram.
172

Time
%
1995
2000
2005
2010
8
10
14
18
22
0
10
20
30
40
50
60
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
0
10
20
30
40
50
60
‚àí0.2
0.2
0.6
1.0
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí06
1e‚àí02
1e+02
frequency
spectrum
Figure F.46.: Series Saxony (01/1991-02/2013) with S(P)ACF and periodogram.
Time
%
1995
2000
2005
2010
10
15
20
25
0
10
20
30
40
50
60
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
0
10
20
30
40
50
60
‚àí0.2
0.2
0.4
0.6
0.8
1.0
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí04
1e‚àí02
1e+00
1e+02
frequency
spectrum
Figure F.47.: Series Saxony-Anhalt (01/1991-02/2013) with S(P)ACF and periodogram.
173

Time
%
1995
2000
2005
2010
8
10
12
14
0
10
20
30
40
50
60
‚àí0.2
0.2
0.6
1.0
Lag
ACF
0
10
20
30
40
50
60
‚àí0.5
0.0
0.5
1.0
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí05
1e‚àí03
1e‚àí01
1e+01
frequency
spectrum
Figure F.48.: Series Schleswig-Holstein (01/1991-02/2013) with S(P)ACF and periodogram.
Time
%
1995
2000
2005
2010
10
15
20
0
10
20
30
40
50
60
0.0
0.2
0.4
0.6
0.8
Lag
ACF
0
10
20
30
40
50
60
‚àí0.2
0.2
0.6
Lag
Partial ACF
0
1
2
3
4
5
6
1e‚àí04
1e‚àí02
1e+00
frequency
spectrum
Figure F.49.: Series Thuringia (01/1991-02/2013) with S(P)ACF and periodogram.
174

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
6
7
8
9
10
11
12
yt
(a) West-Germany
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
10
12
14
16
18
20
22
yt
(b) East-Germany
Figure F.50.: Seasonal boxplots: West- and East-Germany.
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
4
5
6
7
8
9
yt
(a) Baden-Wuerttemberg
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
4
5
6
7
8
9
10
yt
(b) Bavaria
Figure F.51.: Seasonal boxplots: Baden-Wuerttemberg and Bavaria.
175

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
10
12
14
16
18
20
22
yt
(a) Berlin
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
8
10
12
14
16
18
20
22
yt
(b) Brandenburg
Figure F.52.: Seasonal boxplots: Berlin and Brandenburg.
l
l
l
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
10
12
14
16
18
20
yt
(a) Bremen
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
8
9
10
11
12
13
14
yt
(b) Hamburg
Figure F.53.: Seasonal boxplots: Bremen and Hamburg.
176

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
5
6
7
8
9
10
11
yt
(a) Hesse
l
l
l
l
l
l
lll
l
l
l
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
‚àí1.0
‚àí0.5
0.0
0.5
1.0
1.5
2.0
2.5
yt
(b) Lower Saxony
Figure F.54.: Seasonal boxplots: Hesse and Lower Saxony.
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
15
20
25
yt
(a) Mecklenburg-Western Pomerania
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
8
9
10
11
12
13
14
yt
(b) North Rhine-Westphalia
Figure F.55.: Seasonal boxplots: Mecklenburg-Western Pomerania and North Rhine-Westphalia.
177

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
5
6
7
8
9
10
11
yt
(a) Rhineland-Palatinate
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
8
10
12
14
yt
(b) Saarland
Figure F.56.: Seasonal boxplots: Rhineland-Palatinate and Saarland.
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
8
10
12
14
16
18
20
22
yt
(a) Saxony
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
10
15
20
25
yt
(b) Saxony-Anhalt
Figure F.57.: Seasonal boxplots: Saxony and Saxony-Anhalt.
178

Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
8
10
12
14
yt
(a) Schleswig-Holstein
Jan
Feb
Mar
Apr
May
Jun
Jul
Aug
Sep
Oct
Nov
Dec
10
15
20
yt
(b) Thuringia
Figure F.58.: Seasonal boxplots: Schleswig-Holstein and Thuringia.
179

Time
in %
1995
2000
2005
2010
2015
6
7
8
9
10
11
12
yt
y~
T+k
95% HPD
Figure F.59.: One-year ahead forecasts of the unemployment rates of West-Germany.
‚àí1
0
1
2
0.0
0.5
1.0
1.5
2.0
Dy~
t+1
density
95% HPD
‚àí1
0
1
2
0.0
0.5
1.0
1.5
Dy~
t+2
density
95% HPD
‚àí1
0
1
2
0.0
0.5
1.0
1.5
Dy~
t+3
density
95% HPD
‚àí1
0
1
2
0.0
0.5
1.0
1.5
Dy~
t+4
density
95% HPD
Figure F.60.: Model averaged posterior predictive densities of West-Germany (1).
180

‚àí1
0
1
2
0.0
0.5
1.0
1.5
Dy~
t+5
density
95% HPD
‚àí1
0
1
2
0.0
0.5
1.0
1.5
Dy~
t+6
density
95% HPD
‚àí1
0
1
2
0.0
0.5
1.0
1.5
Dy~
t+7
density
95% HPD
‚àí1
0
1
2
0.0
0.2
0.4
0.6
0.8
1.0
Dy~
t+8
density
95% HPD
Figure F.61.: Model averaged posterior predictive densities of West-Germany (2).
‚àí1
0
1
2
0.0
0.2
0.4
0.6
0.8
1.0
Dy~
t+9
density
95% HPD
‚àí1
0
1
2
0.0
0.2
0.4
0.6
0.8
Dy~
t+10
density
95% HPD
‚àí1
0
1
2
0.0
0.2
0.4
0.6
0.8
1.0
Dy~
t+11
density
95% HPD
‚àí1
0
1
2
0.0
0.2
0.4
0.6
0.8
1.0
1.2
Dy~
t+12
density
95% HPD
Figure F.62.: Model averaged posterior predictive densities of West-Germany (3).
181

G. Technical details - chapter 4
In the following the derivations of the distributions, used in chapter 4, are outlined. For
this purpose, in section G.1, some basic expressions required in the subsequent sections
are derived. Then in section G.2 and section G.3 the posterior density of the subvector
B1 and œÜs are established, respectively, where in section G.4 the posterior distribution of
the linear form Œ∏ is derived. Finally, in section G.5 some details on the derivation of
the posterior density of the quadratic form Q, used for the Bayesian F-test, are outlined.
To provide more general posterior results a conjugate Normal-Inverse-Gamma-2 (NIG2)
prior for (B, œÉ2) will be used. Note that a diffuse prior as in chapter 4 can easily be
obtained as a special case of a NIG2 prior, where the latter also serves as a starting point
for other conjugate priors, e.g. Zellner‚Äôs g-prior (see Zellner (1986)). In section G.6 some
additional details on these prior issues will be given.
G.1. Preliminaries - posterior analysis
By an application of the Bayes Theorem the joint probability density function of all model
parameters and the data can be factorized according to
f (B,œÉ2,y| Mi)
=
f (y| B, œÉ2, Mi) ¬∑ f (B, œÉ2| Mi)
(6.1)
=
f (B,œÉ2| y, Mi) ¬∑ f (y| Mi)
(6.2)
where Mi is a model indicator for a particular model in the discrete model space M =
{M1,...,MK}. To express ignorance with respect to M , f (Mi) = 1/K is chosen. Uti-
lizing the above assumptions about the data and the parameters, and applying a variance
182

decomposition to the quadratic form in the likelihood function in (6.1) leads to
f (B,œÉ2,y| Mi) = C‚àí1
N (œÉ2IT‚àíp ; T ‚àíp) ¬∑exp

‚àí1
2œÉ2[ŒΩs2 + (B‚àíbB)‚Ä≤ ¬∑ eX‚Ä≤eX¬∑(B‚àíbB)]

¬∑
C‚àí1
N (œÉ2M‚àí1; d) ¬∑exp

‚àí1
2œÉ2[(B‚àíB0)‚Ä≤ ¬∑M¬∑(B‚àíB0)]

¬∑
C‚àí1
g
a
2, 2
b

¬∑(œÉ2)‚àía+2
2 ¬∑exp

‚àíb
2œÉ2

(6.3)
with d ‚â°dim(B). Further let CN(Œ£ ; k) = (2œÄ)
k
2 ¬∑|Œ£|
1
2 and Cg(a,b) = Œì(a) ¬∑ba , a,b >
0 be the normalizing constant of the Normal and the Gamma distribution, respectively.
Here the Ô¨Årst argument of CN(;) denotes the covariance matrix and the second argument
denotes the dimension of the respective random vector (see Bauwens et al. (1999), p.293).
Let bB be the least squares estimator of B and ŒΩs2 ‚â°(y‚àíeXbB)‚Ä≤ ¬∑ (y‚àíeXbB) the sum of
squared residuals, with ŒΩ = T ‚àíp‚àíd degrees of freedom.
Writing this together yields
= (2œÄ)‚àíT‚àíp+d+a
2
¬∑(œÉ2)‚àí
‚â°a‚ãÜ
z
}|
{
T ‚àíp+ d + a+2
2
¬∑|M|
1
2 ¬∑
b
a
2
Œì(a
2)¬∑2
a
2
¬∑exp
Ô£±
Ô£¥
Ô£≤
Ô£¥
Ô£≥
‚àí1
2œÉ2[b+ ŒΩs2 + (B‚àíbB)‚Ä≤ ¬∑ eX‚Ä≤eX¬∑(B‚àíbB) + (B‚àíB0)‚Ä≤ ¬∑M¬∑(B‚àíB0)
|
{z
}
‚â°b‚ãÜ
]
Ô£º
Ô£¥
Ô£Ω
Ô£¥
Ô£æ
(6.4)
which has the form of a NIG2 distribution, see Bauwens et al. (1999), p.302.
First it is to show, that b‚ãÜin (6.4) can be written as b‚ãÜ= b + ŒΩs2 + QF(B0) + QF(B),
183

with
¬µB ‚â°(eX‚Ä≤eX+ M)‚àí1 ¬∑(eX‚Ä≤eXbB+ MB0)
(6.5a)
H ‚â°eX‚Ä≤eX+ M
(6.5b)
Œ¥ ‚â°(B‚àí¬µB)
(6.5c)
QF(B) ‚â°Œ¥ ‚Ä≤ ¬∑H¬∑Œ¥
(6.5d)
QF(B0) ‚â°(B0 ‚àíbB)‚Ä≤ ¬∑[M‚àí1 + (eX‚Ä≤eX)‚àí1]‚àí1 ¬∑(B0 ‚àíbB)
(6.5e)
Next the derivation of the quadratic forms in (6.5d) and (6.5e) is outlined. The quadratic
form in (6.5d) can be obtained by completing the square for B in:
(B‚àíbB)‚Ä≤ ¬∑ eX‚Ä≤eX¬∑(B‚àíbB) + (B‚àíB0)‚Ä≤M(B‚àíB0)
(6.6a)
= B‚Ä≤ ¬∑H¬∑B‚àí2B‚Ä≤ ¬∑(eX‚Ä≤y+ MB0) + bB‚Ä≤eX‚Ä≤eXbB+ B‚Ä≤
0MB0
(6.6b)
Apply a Cholesky decomposition to the positive deÔ¨Ånite matrix H in (6.5b) as H = L¬∑L‚Ä≤
with L the resulting lower triangular matrix. Then by deÔ¨Åning A ‚â°L‚Ä≤ ¬∑B ‚áîB = (L‚Ä≤)‚àí1 ¬∑
A, equation (6.6) can equivalently be expressed as
= A‚Ä≤A‚àí2¬∑A‚Ä≤ ¬∑L‚àí1 ¬∑(eX‚Ä≤y+ MB0)
|
{z
}
‚â°¬µA
+ y‚Ä≤ ¬∑Px ¬∑y+ B‚Ä≤
0MB0
(6.7a)
= (A‚àí¬µA)‚Ä≤ ¬∑(A‚àí¬µA) ‚àí¬µ‚Ä≤
A ¬∑ ¬µA + y‚Ä≤Pxy+ B‚Ä≤
0MB0
(6.7b)
with Px ‚â°eX¬∑(eX‚Ä≤eX)‚àí1 ¬∑ eX‚Ä≤ the usual linear projection matrix.1 Writing out the last equa-
tion explicitly this results in
=

B‚àíH‚àí1[eX‚Ä≤y+ MB0]
‚Ä≤
¬∑H¬∑

B‚àíH‚àí1[eX‚Ä≤y+ MB0]

|
{z
}
‚â°QF(B) = Œ¥ ‚Ä≤¬∑H¬∑Œ¥
‚àí(MB0 + eX‚Ä≤y)‚Ä≤H‚àí1(MB0 + eX‚Ä≤y) + y‚Ä≤Pxy+ B0‚Ä≤MB0
(6.8)
Next construct QF(B0) in a similar fashion. For this reason, Ô¨Årst notice that by utilizing
1Note that due to possible singularities in the eX‚Ä≤eX matrix the Moore-Penrose pseudoinverse is used through-
out, see Poole (2006), p.611, for details.
184

(6.8) together with the above deÔ¨Ånition of Px, equation (6.6) can be written as
(B‚àíbB)‚Ä≤eX‚Ä≤eX(B‚àíbB) + (B‚àíB0)‚Ä≤M(B‚àíB0)
= QF(B) ‚àí(eX‚Ä≤eXbB+ MB0)‚Ä≤H‚àí1(eX‚Ä≤eXbB+ MB0) + bB‚Ä≤eX‚Ä≤eXbB+ B‚Ä≤
0MB0
(6.9)
Now multiplying out the second term in equation (6.9) yields:
(eX‚Ä≤eXbB+ MB0)‚Ä≤(M+ eX‚Ä≤eX)‚àí1(eX‚Ä≤eXbB+ MB0)
= B‚Ä≤
0M‚Ä≤(M+ eX‚Ä≤eX)‚àí1MB0 + 2B‚Ä≤0M‚Ä≤(M+ eX‚Ä≤eX)‚àí1eX‚Ä≤eXbB
+ bB‚Ä≤eX‚Ä≤eX(M+ eX‚Ä≤eX)‚àí1eX‚Ä≤eXbB
(6.10)
Next utilize the Woodbury matrix identity (cf. L√ºtkepohl (2007), p.660):2
(M+ eX‚Ä≤eX)‚àí1 = M‚àí1 ‚àíM‚àí1(M‚àí1 + (eX‚Ä≤eX)‚àí1)‚àí1M‚àí1
(6.11a)
= (eX‚Ä≤eX)‚àí1 ‚àí(eX‚Ä≤eX)‚àí1(M‚àí1 + (eX‚Ä≤eX)‚àí1)‚àí1(eX‚Ä≤eX)‚àí1
(6.11b)
Substituting the Ô¨Årst identity (6.11a) in the Ô¨Årst and second summand of (6.10) and the
second identity (6.11b) in the last summand of (6.10), respectively, yields after some
algebra:
= B‚Ä≤
0MB0 ‚àíB‚Ä≤
0(M‚àí1 + (eX‚Ä≤eX)‚àí1)‚àí1B0
+ 2bB‚Ä≤MB0 ‚àí2 bB‚Ä≤(M‚àí1 + (eX‚Ä≤eX)‚àí1)‚àí1(eX‚Ä≤eX)‚àí1MB0
+ bB‚Ä≤eX‚Ä≤eXbB‚àíbB‚Ä≤(M‚àí1 + (eX‚Ä≤eX)‚àí1)‚àí1bB
(6.12)
For convenience let K ‚â°(M‚àí1 +(eX‚Ä≤eX)‚àí1)‚àí1 and multiply the second identity in (6.11b)
by eX‚Ä≤eX:
eX‚Ä≤eX(M+ eX‚Ä≤eX)‚àí1 = I‚àíK(eX‚Ä≤eX)‚àí1
(6.13)
2In more general form this matrix identity can be stated as (A+ U¬∑C¬∑V)‚àí1 = A‚àí1 ‚àíA‚àí1 ¬∑U¬∑(C‚àí1 + V¬∑
A‚àí1 ¬∑U)‚àí1 ¬∑V¬∑A‚àí1, with A,U,C and V matrices of conformable dimension. Where the identities (6.11)
can then be deduced by appropriate deÔ¨Ånitions of these matrices.
185

Then the third and fourth summands in (6.12) are equivalently expressed as
2bB‚Ä≤MB0 ‚àí2 bB‚Ä≤(M‚àí1 + (eX‚Ä≤eX)‚àí1)‚àí1(eX‚Ä≤eX)‚àí1MB0
= 2bB‚Ä≤[I‚àíK(eX‚Ä≤eX)‚àí1]MB0
(6.14)
or, by using (6.13),
= 2bB‚Ä≤ ¬∑ eX‚Ä≤eX(M+ eX‚Ä≤eX)‚àí1M¬∑B0
(6.15)
Note that the middle matrix factor term in equation (6.15) can be written as
eX‚Ä≤eX(M+ eX‚Ä≤eX)‚àí1M =
h
M‚àí1(M+ eX‚Ä≤eX)(eX‚Ä≤eX)‚àí1i‚àí1
(6.16a)
=

M‚àí1 + (eX‚Ä≤eX)‚àí1‚àí1
|
{z
}
= K
(6.16b)
by multiplying out the right-hand side of equation (6.16a).
After utilizing the matrix identities (6.11), (6.13), (6.16) and some lengthy algebra, which
is omitted here in order to save space, the left hand side of (6.10) can Ô¨Ånally be written as
(MB0 + eX‚Ä≤eXbB)‚Ä≤(M+ eX‚Ä≤eX)‚àí1(MB0 + eX‚Ä≤eXbB)
(6.17a)
= B‚Ä≤
0MB0 + bB‚Ä≤eX‚Ä≤eXbB‚àíB‚Ä≤
0KB0 + 2bB‚Ä≤KB0 ‚àíbB‚Ä≤KbB
(6.17b)
= B‚Ä≤
0MB0 + bB‚Ä≤eX‚Ä≤eXbB‚àí(B0 ‚àíbB)‚Ä≤(M‚àí1 + (eX‚Ä≤eX)‚àí1)‚àí1(B0 ‚àíbB)
|
{z
}
‚â°QF(B0)
(6.17c)
= B‚Ä≤
0MB0 + bB‚Ä≤eX‚Ä≤eXbB‚àí(B0 ‚àíbB)‚Ä≤eX‚Ä≤eX(M+ eX‚Ä≤eX)‚àí1M(B0 ‚àíbB)
(6.17d)
where the last equation follows from (6.16). Note that for the representation of diffuse
prior information, i.e. with a precision of M ‚Üí0, as in the case of a Ô¨Çat prior, this implies
QF(B0) ‚Üí0.
After substituting (6.17c) in (6.9), the left-hand side of (6.9) equals
(B‚àíbB)‚Ä≤(eX‚Ä≤eX)(B‚àíbB) + (B‚àíB0)‚Ä≤M(B‚àíB0) = QF(B) + QF(B0)
(6.18)
186

and thus the exponent in (6.4) becomes b‚ãÜ= b+ŒΩs2 +QF(B0)+QF(B) as stated above.
Next, 1.) the marginal likelihood (or prior predictive distribution) under model Mi, 2.)
the conditional posterior density of a subvector of B as well as 3.) the marginal posterior
density of œÉ2 under model Mi are derived.
For this purpose consider the following partitioning of Œ¥ in (6.5c) above:
Œ¥1
d1 √ó 1
‚â°(B1 ‚àí¬µ1B) = E1
d1 √ó d
¬∑(B‚àí¬µB)
(6.19a)
Œ¥2
d2 √ó 1
‚â°(B2 ‚àí¬µ2B) = E2
d2 √ó d
¬∑(B‚àí¬µB)
(6.19b)
Œ¥
d √ó 1 ‚â°

Œ¥1
‚Ä≤ ... Œ¥2
‚Ä≤
‚Ä≤
(6.19c)
with d = d1 + d2 and E1 ‚â°(Id1
... 0d2) and E2 ‚â°(0d1
... Id2) two transformation matrices
that eliminate the lower d2 and d1 components of the vector ¬µB (see (6.5)), respectively.
Further partition the matrix H in (6.5b) conformably as follows:
H
=
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
H11
d1 √ó d1
|
H12
d1 √ó d2
‚àí‚àí‚àí‚àí‚àí
‚àí‚àí‚àí‚àí‚àí
H21
d2 √ó d1
|
H22
d2 √ó d2
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
(6.20)
Using the above deÔ¨Ånitions the quadratic form in (6.8) can be expressed as
QF(B) = Œ¥ ‚Ä≤ ¬∑H¬∑Œ¥ =

Œ¥1
‚Ä≤ ... Œ¥2
‚Ä≤

¬∑
 
H11
H12
H21
H22
!
¬∑
 
Œ¥1
Œ¥2
!
(6.21a)
Multiplying out this expression then leads to
= Œ¥1
‚Ä≤ ¬∑H11 ¬∑Œ¥1 + 2¬∑Œ¥1
‚Ä≤ ¬∑H12 ¬∑Œ¥2 + Œ¥2
‚Ä≤ ¬∑H22 ¬∑Œ¥2
(6.22a)
Let H22 = LL‚Ä≤ with L again the lower triangular matrix from a Cholesky decomposition
and deÔ¨Åne Œ¥ ‚ãÜ
2 ‚â°L‚Ä≤¬∑Œ¥2 ‚áîŒ¥2 = (L‚Ä≤)‚àí1¬∑Œ¥ ‚ãÜ
2 . Then after completing the square with respect
187

to Œ¥2 we have:
= (Œ¥2 + ¬µ2)‚Ä≤ ¬∑H22 ¬∑(Œ¥2 + ¬µ2)
|
{z
}
‚â°QF(Œ¥2)
‚àí¬µ‚Ä≤
2 ¬∑H22 ¬∑ ¬µ2 + Œ¥ ‚Ä≤
1 ¬∑H11 ¬∑Œ¥1
(6.23a)
= QF(Œ¥2) + Œ¥ ‚Ä≤
1 ¬∑(H11 ‚àíH12H‚àí1
22 H21) ¬∑Œ¥1
|
{z
}
‚â°QF(Œ¥1)
(6.23b)
with ¬µ2 ‚â°H‚àí1
22 ¬∑H21 ¬∑Œ¥1.
Utilizing the above expressions the joint density in (6.4) can be expressed as
f (B, œÉ2,y| Mi) = (2œÄ)‚àía‚ãÜ
2 ¬∑(œÉ2)‚àía‚ãÜ
2 ¬∑|M|
1
2 ¬∑
b
a
2
Œì(a
2) ¬∑2
a
2 ¬∑exp

‚àíQF(Œ¥1)
2œÉ2

¬∑exp

‚àí1
2œÉ2[b+ ŒΩs2 + QF(B0) + QF(Œ¥2)]

(6.24)
Next integrate out Œ¥2 from (6.24), since in the next section we want to draw our attention
to the analysis of the subvector Œ¥1:
f (Œ¥1, œÉ2,y| Mi) = (2œÄ)‚àía‚ãÜ
2 ¬∑(œÉ2)‚àía‚ãÜ
2 ¬∑|M|
1
2 ¬∑
b
a
2
Œì(a
2) ¬∑2
a
2 ¬∑exp

‚àíQF(Œ¥1)
2œÉ2

¬∑exp

‚àí1
2œÉ2[b+ ŒΩs2 + QF(B0)]

¬∑CN2 ¬∑
Z
Rd2 C‚àí1
N2 ¬∑exp

‚àíQF(Œ¥2)
2œÉ2

¬∑dŒ¥ 2
(6.25)
188

where CN2(Œ£2; d2) = (2œÄ)
d2
2 ¬∑|Œ£2|
1
2 and Œ£2 = œÉ2 ¬∑H‚àí1
22 .
= (2œÄ)‚àíT‚àíp
2 ¬∑(2œÄ)‚àíd1
2 ¬∑(œÉ2)‚àí
‚â°a‚ãÜ‚ãÜ
z
}|
{
T ‚àíp+ a+2
2
¬∑(œÉ2)‚àíd1
2 ¬∑|M|
1
2 ¬∑
b
a
2
Œì(a
2)¬∑2
a
2 ¬∑|H22|‚àí1
2
¬∑exp

‚àíQF(Œ¥1)
2œÉ2

¬∑exp{‚àí1
2œÉ2[b+ ŒΩs2 + QF(B0)
|
{z
}
‚â°b‚ãÜ‚ãÜ
]}
= (2œÄ)‚àíT‚àíp
2 ¬∑(2œÄ)‚àíd1
2 ¬∑(œÉ2)‚àíd1
2 ¬∑|M|
1
2 ¬∑
b
a
2
Œì(a
2)¬∑2
a
2 ¬∑|H22|‚àí1
2 ¬∑exp

‚àíQF(Œ¥1)
2œÉ2

¬∑Cg
a‚ãÜ‚ãÜ
2 ; 2
b‚ãÜ‚ãÜ

¬∑C‚àí1
g
a‚ãÜ‚ãÜ
2 ; 2
b‚ãÜ‚ãÜ

¬∑(œÉ2)‚àía‚ãÜ‚ãÜ+2
2
¬∑exp

‚àíb‚ãÜ‚ãÜ
2œÉ2

|
{z
}
= IG2(a‚ãÜ‚ãÜ, b‚ãÜ‚ãÜ) density
= (2œÄ)‚àíT‚àíp
2 ¬∑(2œÄ)‚àíd1
2 ¬∑(œÉ2)‚àíd1
2 ¬∑|M|
1
2 ¬∑
b
a
2
Œì(a
2)¬∑2
a
2 ¬∑|H22|‚àí1
2
¬∑Cg
a‚ãÜ‚ãÜ
2 ; 2
b‚ãÜ‚ãÜ

¬∑IG2 ¬∑CN1(Œ£1; d1) ¬∑C‚àí1
N1 (Œ£1; d1) ¬∑exp

‚àíQF(Œ¥1)
2œÉ2

|
{z
}
= Nd1(¬µ1B , Œ£1) density
(6.26)
with a‚ãÜ‚ãÜ= T ‚àíp+a and b‚ãÜ‚ãÜ= b+ŒΩs2+QF(B0) and normalizing constantsCg

a‚ãÜ‚ãÜ
2 ; 2
b‚ãÜ‚ãÜ

,
CN1(Œ£1; d1) as deÔ¨Åned above.
Hence, given a model speciÔ¨Åcation Mi and a value for œÉ2, the random vector Œ¥ 1, or
equivalently B1, follows a d1-dimensional normal posterior distribution with Ô¨Årst and
second moments ¬µ1B (see (6.19)) and
Œ£1 = œÉ2 ¬∑(H11 ‚àíH12H‚àí1
22 H21)‚àí1 ,
(6.27)
respectively, and the conditional posterior density of œÉ2, under model Mi, is of the IG2 (a‚ãÜ‚ãÜ; b‚ãÜ‚ãÜ)
189

form. By using (6.27) the last line of (6.26) becomes
= (2œÄ)‚àíT‚àíp
2 ¬∑|M|
1
2 ¬∑|H22|‚àí1
2 ¬∑
(H11 ‚àíH12H‚àí1
22 H21)

‚àí1
2
|
{z
}
= |H|‚àí1
2
¬∑C‚àí1
g
a
2; 2
b

¬∑Cg
a‚ãÜ‚ãÜ
2 ; 2
b‚ãÜ‚ãÜ

¬∑
Nd1 ¬∑IG2
|
{z
}
= NIG2 density
(6.28)
where the fact is utilized that |H| = |H22| ¬∑ |H11 ‚àíH12H‚àí1
22 H21|, cf. Greene (2003), Ap-
pendix A.5.2, p.823.
Next rewrite the product of determinants in (6.28) as follows:
|H|‚àí1
2 ¬∑|M|
1
2 =
eX‚Ä≤eX+ M

‚àí1
2 ¬∑
M‚àí1‚àí1
2
(6.29a)
=
Id + eX‚Ä≤eX¬∑M‚àí1
‚àí1
2
(6.29b)
From Sylvester‚Äôs determinant theorem it is known that for any two matrices
A
d√óT‚àíp and
B
T‚àíp√ód the following identity holds:
|Id + AB| =
IT‚àíp + BA

and thus equation (6.29b) can equivalently be written as
Id + eX‚Ä≤eX¬∑M‚àí1
‚àí1
2 =
IT‚àíp + eXM‚àí1eX‚Ä≤
‚àí1
2
(6.30)
Hence equation (6.28) becomes
f (B1, œÉ2,y| Mi) = (2œÄ)‚àíT‚àíp
2 ¬∑
IT‚àíp + eXM‚àí1eX‚Ä≤
‚àí1
2 ¬∑
C‚àí1
g
a
2; 2
b

¬∑Cg
a‚ãÜ‚ãÜ
2 ; 2
b‚ãÜ‚ãÜ

¬∑NIG2
(6.31)
190

or
= (2œÄ)‚àíT‚àíp
2 ¬∑
IT‚àíp + eXM‚àí1eX‚Ä≤
‚àí1
2 ¬∑
b
a
2
Œì(a
2)¬∑2
a
2 ¬∑ Œì(a‚ãÜ‚ãÜ
2 )¬∑2
T‚àíp+a
2
[b‚ãÜ‚ãÜ]
a‚ãÜ‚ãÜ
2
¬∑ NIG2
(6.32a)
=
Œì(a‚ãÜ‚ãÜ
2 )
œÄ( T‚àíp
2 ) ¬∑ Œì(a
2)
¬∑b
a
2 ¬∑
IT‚àíp + eXM‚àí1eX‚Ä≤
‚àí1
2 ¬∑

b+ ŒΩs2 + QF(B0)
‚àía‚ãÜ‚ãÜ
2
¬∑ NIG2
(6.32b)
Now let QF(y) ‚â°ŒΩs2 + QF(B0) and note the following identities:
QF(y) = (y‚àíeXbB)‚Ä≤ ¬∑(y‚àíeXbB) + (B0 ‚àíbB)‚Ä≤ ¬∑

M‚àí1 + (eX‚Ä≤eX)‚àí1‚àí1
¬∑(B0 ‚àíbB)
= (y‚àíeXbB)‚Ä≤ ¬∑(y‚àíeXbB) + (B0 ‚àíbB)‚Ä≤ ¬∑ eX‚Ä≤eX(M+ eX‚Ä≤eX)‚àí1M¬∑(B0 ‚àíbB)
= (y‚àíeXB0)‚Ä≤ ¬∑(IT‚àíp + eXM‚àí1eX‚Ä≤)‚àí1 ¬∑(y‚àíeXB0)
= (y‚àíeXB0)‚Ä≤ ¬∑(IT‚àíp ‚àíeX(M+ eX‚Ä≤eX)‚àí1eX‚Ä≤) ¬∑(y‚àíeXB0)
(6.33)
where the Ô¨Årst equality follows by using equation (6.17c) and the second equality follows
from (6.16). The last but one equality can be obtained after some lengthy algebra, essen-
tially by completing the square with respect to y, see Hamilton (1994), Appendix 12.A.,
p.368, for more details, and the last identity follows from an application of the Woodbury
matrix identity, see footnote 2 on page 185 above.
Hence the joint probability density in (6.32b) can be written as
f (B1, œÉ2, y| Mi) =
Œì(T‚àíp+a
2
)
œÄ( T‚àíp
2 ) ¬∑ Œì(a
2)
¬∑b‚àíT‚àíp
2 ¬∑
IT‚àíp + eXM‚àí1eX‚Ä≤
‚àí1
2
¬∑[ 1+ QF(y)/b ]‚àíT‚àíp+a
2
¬∑ NIG2
= f (y| Mi) ¬∑ f (B1| œÉ2, Mi, y) ¬∑ f (œÉ2| Mi, y)
(6.34)
From (6.34) it can be observed that, under model Mi, the conditional posterior distribu-
tion of B1, given œÉ2, is a multivariate Normal density with Ô¨Årst and second moments ¬µ1B
and Œ£1, respectively, and the marginal posterior distribution of œÉ2 is of the IG2 (a‚ãÜ‚ãÜ; b‚ãÜ‚ãÜ)
191

form, with mean E(œÉ2| Mi, y) = a‚ãÜ‚ãÜ/(b‚ãÜ‚ãÜ‚àí2), for b‚ãÜ‚ãÜ> 2, and varianceVar(œÉ2|Mi, y) =
2
b‚ãÜ‚ãÜ‚àí4 ¬∑[E(œÉ2| Mi, y)]2, for b‚ãÜ‚ãÜ> 4, see Bauwens et al. (1999), p.292.
Moreover from (6.34) it can be recognized that the joint data density, f (y| Mi), under
model Mi, is given by
f (y| Mi) =
Œì(T‚àíp+a
2
)
œÄ( T‚àíp
2 ) ¬∑ Œì(a
2)
¬∑b‚àíT‚àíp
2 ¬∑|P|‚àí1
2 ¬∑[ 1+ QF(y)/b ]‚àíT‚àíp+a
2
= C‚àí1
t
(P; a; T ‚àíp) ¬∑
h
1+ (y‚àíeXB0)‚Ä≤ (b¬∑P)‚àí1(y‚àíeXB0)
i‚àíT‚àíp+a
2
(6.35)
with P ‚â°IT‚àíp + eXM‚àí1eX‚Ä≤ and
Ct (P; a; T ‚àíp) =

Œì
a
2

/Œì
T ‚àíp+ a
2

¬∑œÄ
T‚àíp
2 ¬∑|b¬∑P|
1
2
the normalizing constant of a multivariate Student-t density (cf. Bauwens et al. (1999),
p.303).
Hence the sample density (6.35) is a (T ‚àíp)-dimensional multivariate Student-t density
with a degrees of freedom, mean vector eXB0 and scale matrix b¬∑(IT‚àíp + eXM‚àí1eX‚Ä≤), see
also Hamilton (1994), Appendix 12.A., p.368, for a similar result. For given data, (6.35)
is the marginal likelihood function of Mi, and is thus the (unnormalized) probability mass
function of the discrete-valued random vector of model indicators Mi, which is needed for
the construction of posterior model probabilities.
G.2. Derivation of the posterior density of B1
Next the (model speciÔ¨Åc) marginal posterior density f (B1|Mi, y) will be derived. For this
purpose the Ô¨Årst equation in (6.26) of section G.1 is utilized, which will be restated here
192

for the ease of reference:
f (Œ¥1, œÉ2,y| Mi) = (2œÄ)‚àíT‚àíp+d1
2
¬∑(œÉ2)‚àí
‚â°ea
z }| {
d1 + a‚ãÜ‚ãÜ+2
2
¬∑|M|
1
2 ¬∑
b
a
2
Œì(a
2) ¬∑2
a
2 ¬∑
|H22|‚àí1
2 ¬∑exp{‚àí1
2œÉ2[b‚ãÜ‚ãÜ+ QF(Œ¥1)
|
{z
}
‚â°eb
]}
(6.36)
with ea = d1 + a‚ãÜ‚ãÜand eb = b‚ãÜ‚ãÜ+ QF(Œ¥1), and QF(Œ¥1) = Œ¥ ‚Ä≤
1 ¬∑(H11 ‚àíH12H‚àí1
22 H21)¬∑Œ¥1.
Also recall from above that a‚ãÜ‚ãÜ= T ‚àíp+a and b‚ãÜ‚ãÜ= b+ŒΩs2 +QF(B0) = b+QF(y),
with QF(y) = (y‚àíeXB0)‚Ä≤ ¬∑(IT‚àíp + eXM‚àí1eX‚Ä≤)‚àí1 ¬∑(y‚àíeXB0).
Next integrate (6.36) with respect to œÉ2 by using the properties of the IG2 density:
f (Œ¥1, y| Mi) = (2œÄ)‚àíT‚àíp+d1
2
¬∑
b
a
2
Œì(a
2) ¬∑2
a
2 ¬∑|H22|‚àí1
2 ¬∑|M|
1
2 ¬∑Cg
ea
2; 2
eb

¬∑
Z
R+ C‚àí1
g
ea
2; 2
eb

¬∑(œÉ2)‚àíea+2
2 ¬∑exp
(
‚àí
eb
2œÉ2
)
¬∑dœÉ2
= (2œÄ)‚àíT‚àíp+d1
2
¬∑
b
a
2
Œì(a
2) ¬∑2
a
2 ¬∑|H22|‚àí1
2 ¬∑|M|
1
2 ¬∑Cg
ea
2; 2
eb

(6.37)
with the normalizing constant of the IG2 density equal to (see Bauwens et al. (1999),
p.292):
Cg
ea
2; 2
eb

= Œì
d1 + a‚ãÜ‚ãÜ
2

¬∑2
d1+a‚ãÜ‚ãÜ
2
¬∑[b‚ãÜ‚ãÜ+ QF(Œ¥1)]‚àíd1+a‚ãÜ‚ãÜ
2
(6.38)
193

Substituting (6.38) in the last equation of (6.37) yields after some rearrangements:
f (Œ¥1, y| Mi) = œÄ‚àíT‚àíp+d1
2
¬∑ b
a
2
Œì(a
2) ¬∑|H22|‚àí1
2 ¬∑|M|
1
2 ¬∑ Œì
d1 + a‚ãÜ‚ãÜ
2

¬∑
(b‚ãÜ‚ãÜ)‚àíd1+a‚ãÜ‚ãÜ
2
¬∑[1+ QF(Œ¥1)/b‚ãÜ‚ãÜ]‚àíd1+a‚ãÜ‚ãÜ
2
= œÄ‚àíT‚àíp+d1
2
¬∑ b
a
2
Œì(a
2) ¬∑|H22|‚àí1
2 ¬∑|M|
1
2 ¬∑ Œì
d1 + a‚ãÜ‚ãÜ
2

¬∑
[b+ QF(y)]‚àíd1+a‚ãÜ‚ãÜ
2
¬∑[1+ Œ¥ ‚Ä≤
1 ¬∑P1 ¬∑Œ¥1]‚àíd1+a‚ãÜ‚ãÜ
2
(6.39)
with P1 ‚â°(H11 ‚àíH12H‚àí1
22 H21)/b‚ãÜ‚ãÜ.
= œÄ‚àíT‚àíp+d1
2
¬∑ b
a
2
Œì(a
2) ¬∑|H22|‚àí1
2 ¬∑|M|
1
2 ¬∑ Œì
d1 + a‚ãÜ‚ãÜ
2

¬∑
[b+ QF(y)]‚àíd1+a‚ãÜ‚ãÜ
2
¬∑C‚àí1
t
(P1, a‚ãÜ‚ãÜ; d1) ¬∑[1+ Œ¥ ‚Ä≤
1 ¬∑P1 ¬∑Œ¥1 ]‚àíd1+a‚ãÜ‚ãÜ
2
|
{z
}
=Td1(¬µ1B, P1, a‚ãÜ‚ãÜ)
¬∑Ct(P1, a‚ãÜ‚ãÜ; d1)
= œÄ‚àíT‚àíp+d1
2
¬∑ b
a
2
Œì(a
2) ¬∑|H22|‚àí1
2 ¬∑|M|
1
2 ¬∑ Œì
d1 + a‚ãÜ‚ãÜ
2

¬∑Td1(¬µ1B, P1, a‚ãÜ‚ãÜ) ¬∑b‚àíd1+a‚ãÜ‚ãÜ
2
¬∑
h
1+ (y‚àíeXB0)‚Ä≤ ¬∑Py ¬∑(y‚àíeXB0)
i‚àíd1+a‚ãÜ‚ãÜ
2
¬∑Ct(P1, a‚ãÜ‚ãÜ; d1)
(6.40)
with Py ‚â°
h
b¬∑(IT‚àíp + eXM‚àí1eX‚Ä≤)
i‚àí1
and Ct(P1, a‚ãÜ‚ãÜ; d1) the normalizing constant of the
d1-dimensional Student-t density, Td1(¬µ1B, P1, a‚ãÜ‚ãÜ), with mean ¬µ1B, scale matrix P1 and
a‚ãÜ‚ãÜdegrees of freedom (see Bauwens et al. (1999), Appendix A.2).
For a p-dimensional t-density with scale matrix P and ŒΩ degrees of freedom this normal-
izing constant has the general form:
Ct(P, ŒΩ; p) =

Œì
ŒΩ
2

/Œì
ŒΩ + p
2

¬∑œÄ
1
2 p ¬∑|P|‚àí1
2
(6.41)
194

which is stated here for the ease of reference, ibid., p.303.
Using this (6.40) becomes
f (Œ¥1, y| Mi) = œÄ‚àíT‚àíp
2 ¬∑b‚àíT‚àíp+d1
2
¬∑ Œì(a‚ãÜ‚ãÜ
2 )
Œì(a
2) ¬∑|P1|‚àí1
2 ¬∑|H22|‚àí1
2 ¬∑|M|
1
2 ¬∑Td1¬∑
h
1+ (y‚àíeXB0)‚Ä≤ ¬∑Py ¬∑(y‚àíeXB0)
i‚àíd1
2 ¬∑Ct(Py, a; T ‚àíp)
C‚àí1
t
(Py, a; T ‚àíp)¬∑
h
1+ (y‚àíeXB0)‚Ä≤ ¬∑Py ¬∑(y‚àíeXB0)
i‚àía‚ãÜ‚ãÜ
2
|
{z
}
=TT‚àíp(eXB0, Py, a)
= b‚àíT‚àíp+d1
2
¬∑|P1|‚àí1
2 ¬∑
Py
‚àí1
2 ¬∑|H22|‚àí1
2 ¬∑|M|
1
2 ¬∑
h
1+ (y‚àíeXB0)‚Ä≤ ¬∑Py ¬∑(y‚àíeXB0)
i‚àíd1
2 ¬∑Td1 ¬∑TT‚àíp
(6.42)
Now consider the product of determinants in (6.42) in some more detail:
|P1|‚àí1
2 ¬∑|H22|‚àí1
2 ¬∑|M|
1
2 ¬∑
Py
‚àí1
2
=

H11 ‚àíH12H‚àí1
22 H21
b‚ãÜ‚ãÜ

‚àí1
2
¬∑|H22|‚àí1
2 ¬∑|M|
1
2 ¬∑
b‚àí1 ¬∑(IT‚àíp + eXM‚àí1eX‚Ä≤)‚àí1
‚àí1
2
= (b‚ãÜ‚ãÜ)
d1
2 ¬∑|H22|‚àí1
2 ¬∑
H11 ‚àíH12H‚àí1
22 H21

‚àí1
2 ¬∑|M|
1
2 ¬∑b
T‚àíp
2 ¬∑
IT‚àíp + eXM‚àí1eX‚Ä≤
1
2
= (b+ QF(y))
d1
2 ¬∑|H|‚àí1
2 ¬∑|M|
1
2 ¬∑b
T‚àíp
2 ¬∑
IT‚àíp + eXM‚àí1eX‚Ä≤
1
2
(6.43)
utilizing again the fact that |H| = |H22| ¬∑ |H11 ‚àíH12H‚àí1
22 H21|, cf. Greene (2003), Ap-
pendix A.5.2, p.823, in the last line. Furthermore from (6.29) and (6.30) it is already
known that |H|‚àí1
2 ¬∑|M|
1
2 = |IT‚àíp + eXM‚àí1eX‚Ä≤|‚àí1
2.
195

Hence the last equation in (6.43) Ô¨Ånally simpliÔ¨Åes to
|P1|‚àí1
2 ¬∑|H22|‚àí1
2 ¬∑|M|
1
2 ¬∑
Py
‚àí1
2 = (b+ QF(y))
d1
2 ¬∑b
T‚àíp
2
= (1+ QF(y)/b)
d1
2 ¬∑b
T‚àíp+d1
2
(6.44)
Substituting the last result (6.44) into (6.42) Ô¨Ånally gives
f (Œ¥1, y| Mi) = f (Œ¥1| y, Mi) ¬∑ f (y| Mi) = Td1 ¬∑TT‚àíp
(6.45)
That is the joint density f (Œ¥1, y| Mi) equals the product of two multivariate Student-t
densities.
Hence, given the data, the marginal posterior density under model Mi is proportional to
f (B1| Mi, y) ‚àù
"
1+ (B1 ‚àí¬µ1B)‚Ä≤ ¬∑
 H11 ‚àíH12 ¬∑H22‚àí1 ¬∑H21

b‚ãÜ‚ãÜ
¬∑(B1 ‚àí¬µ1B)
#‚àía‚ãÜ‚ãÜ+d1
2
(6.46)
which is the kernel of a d1-dimensional Student-t density with a‚ãÜ‚ãÜ= T ‚àíp+a degrees of
freedom.
In chapter 4, the vector B1 corresponds to the vector of PAR coefÔ¨Åcients œÜ. Under the
Jeffreys prior, used in chapter 4, this kernel then becomes (see also section G.6 for details):
f (œÜ| Mi, y) ‚àù
"
1+ (œÜ ‚àíbœÜ)‚Ä≤ ¬∑
 H11 ‚àíH12 ¬∑H22‚àí1 ¬∑H21

ŒΩs2
¬∑(œÜ ‚àíbœÜ)
#‚àíT‚àíp‚àíd2
2
(6.47)
since T ‚àíp‚àíd + d1 = T ‚àíp‚àíd2 (see Zellner (1971), p.69, for a similar expression).
196

G.3. Derivation of the posterior density of œÜs
The derivation of the (model speciÔ¨Åc) marginal posterior density of œÜs proceeds along the
lines of section G.2, except that now one has to partition
B = [B1‚Ä≤ ... B2‚Ä≤]‚Ä≤ =

œÜs
1√ó1
... œÜ‚Ä≤
‚àís , Œ¥ ‚Ä≤
‚Ä≤
(6.48a)
This leads to
f (œÜs| Mi, y) ‚àù
Ô£Æ
Ô£ØÔ£∞1+ (œÜs ‚àíbœÜs)2 ¬∑(H11 ‚àíH12 ¬∑H‚àí1
22 ¬∑H21)/b‚ãÜ‚ãÜ
|
{z
}
‚â°(h11)‚àí1
Ô£π
Ô£∫Ô£ª
‚àía‚ãÜ‚ãÜ+1
2
‚àù
"
1+ (œÜs ‚àíbœÜs)2
h11
#‚àía‚ãÜ‚ãÜ+1
2
(6.49)
which has the form of a univariate Student-t density with a‚ãÜ‚ãÜdegrees of freedom, location
parameter bœÜs and scale parameter h11,where H11 denotes the scalar (1,1)-element of the
matrix H in (6.20).
G.4. Derivation of the marginal posterior of Œ∏
Next the derivation of the marginal posterior of Œ∏, i.e. the linear approximation of the
product of periodic autoregressive coefÔ¨Åcients is outlined. First deÔ¨Åne Œ∏ ‚â°Œπ‚Ä≤ ¬∑ œÜ, with
Œπ‚Ä≤
1√óS = (1,...,1). From section G.1 we know that the conditional posterior distribution of
the subvector B1, or more precisely œÜ, given œÉ2, follows a multivariate Normal distribu-
tion Nd1(¬µ1B, Œ£1), with mean ¬µ1B, see (6.19), and covariance matrix Œ£1, see (6.27).
Given these results, it is straightforward to check that, conditional on œÉ2 and a model
speciÔ¨Åcation Mi, the linear form Œ∏ follows a univariate Normal posterior distribution with
Ô¨Årst and second moments, under a NIG2 prior, given by
E(Œ∏| œÉ2, Mi, y) = Œπ‚Ä≤ ¬∑ ¬µ1B
(6.50a)
Var(Œ∏| œÉ2, Mi, y) = œÉ2 ¬∑Œπ‚Ä≤ ¬∑
 H11 ‚àíH12 ¬∑H22‚àí1 ¬∑H21
‚àí1 ¬∑Œπ
|
{z
}
‚â°c
(6.50b)
197

and, under a Jeffreys prior, given by
E(Œ∏| œÉ2, Mi, y) = Œπ‚Ä≤ ¬∑ bœÜ
(6.51a)
Var(Œ∏| œÉ2, Mi, y) = œÉ2 ¬∑Œπ‚Ä≤ ¬∑(eX11 ‚àíeX12 ¬∑ eX‚àí1
22 ¬∑ eX21)‚àí1 ¬∑Œπ
|
{z
}
‚â°cJ
(6.51b)
The marginal posterior distribution of the linear form Œ∏, under model Mi, can be obtained
by integrating the joint posterior
f (Œ∏,œÉ2| Mi, y) = f (Œ∏| œÉ2, Mi, y)¬∑ f (œÉ2| Mi, y)
with respect to œÉ2, using properties of the IG2 distribution, which yields3
f (Œ∏| Mi, y) =
Œì

a‚ãÜ‚ãÜ+1
2

Œì
 a‚ãÜ‚ãÜ
2

¬∑‚àöœÄ ¬∑(b‚ãÜ‚ãÜ¬∑c)‚àí1
2 ¬∑

1+ (Œ∏ ‚àíŒπ‚Ä≤ ¬∑ ¬µ1B)2
b‚ãÜ‚ãÜ¬∑c
‚àía‚ãÜ‚ãÜ+1
2
(6.52)
which is a univariate Student-t density with a‚ãÜ‚ãÜdegrees of freedom, mean Œπ‚Ä≤ ¬∑ ¬µ1B and
variance b‚ãÜ‚ãÜ¬∑c/(a‚ãÜ‚ãÜ‚àí2), see Bauwens et al. (1999), Appendix A.1.4, p.294.
Whereas under a Jeffreys prior, omitting for convenience all terms independent of Œ∏, this
simpliÔ¨Åes to
f (Œ∏| Mi, y) ‚àù
"
1+ (Œ∏ ‚àíbŒ∏)2
ŒΩs2 ¬∑cJ
#‚àíT‚àíp‚àíd+1
2
(6.53)
which is the kernel of a univariate t-density with T ‚àíp‚àíd degrees of freedom, mean bŒ∏ =
Œπ‚Ä≤ ¬∑ bœÜ, i.e. the ordinary least squares estimate of Œ∏, and variance ŒΩs2 ¬∑cJ/(T ‚àíp‚àíd ‚àí2),
see Zellner (1971), p.70, for a similar expression.
G.5. Derivation of the marginal posterior of Q
Next consider the linear form RœÜ = r, with R a J √ó S matrix of linear contrasts and r
a J-vector of constants, where J = S in the following. Utilizing some deÔ¨Ånitions and
arguments used in the derivation of the posterior of Œ∏, it is known that under a NIG2 prior
3Details are omitted to save space.
198

f (œÜ| œÉ2, Mi, y) = Nd1(¬µ1B, Œ£1). Hence, conditional on the data and all other parameters,
it follows that
RœÜ| œÉ2, Mi ,y ‚àºNS(R¬∑ ¬µ1B , œÉ2 ¬∑R(H11 ‚àíH12 ¬∑H‚àí1
22 ¬∑H21)‚àí1R‚Ä≤
|
{z
}
‚â°‚Ñ¶
)
(6.54)
or under a Jeffreys prior:
RœÜ| œÉ2, Mi ,y ‚àºNS(R¬∑ bœÜ, œÉ2 ¬∑R(eX11 ‚àíeX12 ¬∑ eX‚àí1
22 ¬∑ eX21)‚àí1R‚Ä≤)
Further it is known, using (6.54), that the quadratic form
Z ‚â°[R(œÜ ‚àí¬µ1B)]‚Ä≤ ¬∑ ‚Ñ¶‚àí1 ¬∑[R(œÜ ‚àí¬µ1B)]
(6.55)
is œá2
(S)- distributed with S degrees of freedom, cf. Kendall and Stuart (1969), chapter 15.
Following Hamilton (1994), p.369, I make the simple change of variables
Q ‚â°Z ¬∑œÉ2 ¬∑a‚ãÜ‚ãÜ/(S¬∑b‚ãÜ‚ãÜ)
(6.56)
with Jacobian equal to
S¬∑b‚ãÜ‚ãÜ/(œÉ2 ¬∑a‚ãÜ‚ãÜ)
.
Since Z|œÉ2,y ‚àºœá2
(S), or equivalently Z|œÉ2,y ‚àºG(S
2, 2), it is easy to show that Q|œÉ2,y
follows a Gamma-2 distribution, G2
 S, d ¬∑b‚ãÜ‚ãÜ/(œÉ2 ¬∑a‚ãÜ‚ãÜ)

, given all other parameters and
the data.4 The posterior f (Q| Mi, y) can then be obtained by integrating the joint posterior
distribution
f (Q, œÉ2| Mi, y) = f (Q| œÉ2, Mi, y) ¬∑ f (œÉ2| Mi, y)
(6.57)
with respect to œÉ2, using properties of the IG2 density, where as above f (œÉ2| Mi, y) =
IG2(a‚ãÜ‚ãÜ, b‚ãÜ‚ãÜ).
After some algebra, which is omitted here to save space (see Hamilton (1994), Appendix
12.A, p.370, for some details) it can be shown that the marginal posterior distribution
of the quadratic form Q in (6.56), under model Mi, follows an F-distribution with S and
4Note that if X ‚àºG2(ŒΩ,s) ‚áîX ‚àºG( ŒΩ
2 , 2
s ), see Bauwens et al. (1999), A.15, for details.
199

a‚ãÜ‚ãÜ= T ‚àíp+ a degrees of freedom, i.e.
Q| Mi,y ‚àºF(ŒΩ1 = S, ŒΩ2 = a‚ãÜ‚ãÜ)
Whereas under a Jeffreys prior, i.e. if (b, M) ‚Üí0 and a ‚Üí‚àíd, then Q| Mi,y ‚àºF(ŒΩ1 =
S, ŒΩ2 = T ‚àíp‚àíd), which therefore yields the same result as within a classical framework.
200

G.6. Some comments on the prior distribution
As already mentioned brieÔ¨Çy at the very beginning of this appendix the assumed (non-
informative) Jeffreys prior of chapter 4 can be obtained as a special case of the natural
conjugate NIG2 prior (see (6.3) above). Recall that the kernels of the multivariate Normal
and the IG2 density, respectively, are given by
k(B| œÉ2) = œÉ‚àíd exp

‚àí1
2œÉ2(B‚àíB0)‚Ä≤M(B‚àíB0)

(6.58a)
k(œÉ2) = œÉ‚àí(a+2) ¬∑exp

‚àíb
2œÉ2

(6.58b)
By letting the scale matrix M and the shape parameter b both go to zero, we Ô¨Ånd the
noninformative priors by computing the limits of the respective kernels (not the limit
of the densities which are trivially equal to zero through their respective normalizing
constants). Letting M ‚Üí0, which corresponds to a zero precision, the kernel in (6.58a)
becomes
k(B| œÉ2) = œÉ‚àíd
(6.59)
In addition, letting b ‚Üí0 the kernel of the IG2 prior in (6.58b) becomes
k(œÉ2) = œÉ‚àí(a+2)
(6.60)
which has different interpretations depending on the choice for the parameter a, see
Bauwens et al. (1999), p.114, for a discussion. Obviously from (6.59) and (6.60) the
kernel of the joint diffuse prior is equal to
k(B, œÉ2) = œÉ‚àí(a+d+2)
(6.61)
Now by letting a ‚Üí‚àíd, Jeffreys‚Äô prior can be obtained, see ibid.:
k(B, œÉ2) = œÉ‚àí2
(6.62)
As already mentioned in the previous sections G.2-G.5 the corresponding posterior ex-
pressions under a noninformative Jeffreys prior can be easily obtained by letting the IG2
201

hyperparameters: b ‚Üí0, in b‚ãÜ‚ãÜ, and a ‚Üí‚àíd, in a‚ãÜ‚ãÜ, and letting M ‚Üí0 for the precision
of B.
Another prior speciÔ¨Åcation, used in an earlier version of the paper presented in chap-
ter 4, is Zellner‚Äôs g-prior (Zellner (1986)), which has become quite popular because of
its analytical convenience, cf. Zellner and Siow (1980), Chipman et al. (2001), Liang
et al. (2008), Garcia-Donato and Martinez-Beneito (2012), among others. Zellner‚Äôs g-
prior allows the experimenter to introduce information about the location parameter of
a regression, but to bypass the most difÔ¨Åcult part of the prior speciÔ¨Åcation, namely the
speciÔ¨Åcation of the prior correlation structure. This structure is data-dependent and thus
Ô¨Åxed in Zellner‚Äôs approach as (see Judge et al. (1985), Marin and Robert (2010))
B| œÉ2, eX ‚àºNd(B0, g¬∑œÉ2(eX‚Ä≤eX)‚àí1)
and
f (œÉ2| eX) ‚àùœÉ‚àí2
(6.63)
All the posterior results of the previous sections could easily be adapted for the case of a
g-prior simply by substituting M = g‚àí1 ¬∑(eX‚Ä≤eX). For example, the marginal likelihood in
(6.35), under model Mi, then becomes
f (y| Mi) =
Œì(T‚àíp+a
2
)
œÄ( T‚àíp
2 ) ¬∑ Œì(a
2)
¬∑b‚àíT‚àíp
2 ¬∑(g+ 1)‚àíd
2 ¬∑[ 1+ QF(y)/b ]‚àíT‚àíp+a
2
with
QF(y) = (y‚àíeXB0)‚Ä≤

IT‚àíp ‚àí
g
g+ 1
eX¬∑(eX‚Ä≤eX)‚àí1 ¬∑ eX‚Ä≤

¬∑(y‚àíeXB0)
However one potential drawback with this approach is that it introduces the additional
unknown hyperparameter g, which has to be integrated out numerically. Furthermore
assuming a g-prior did not yield better results in the empirical application presented in
chapter 4 compared to the results using a Jeffreys prior.
202

H. Technical details - chapter 5
H.1. Derivation of the posterior predictive distribution of eyK
In the following it will be shown that the results in Broemeling and Land (1984), stated
for a nonperiodic AR(p) model, also apply to the more general case of a periodic AR(p)
model of the form (5.1) as in section 5.2.5 The subsequent results apply to the case of a
model without a structural break or with a break at known date TB.
The joint probability density function (pdf) of B, œÉ2, eyK, given the data y and a particular
model speciÔ¨Åcation Mi, can be factorized as (cf. Zellner (1971), p.72):
f (eyK,B,œÉ2| Mi, eX, f
WK, y) = f (B,œÉ2| Mi, eX, y) ¬∑ f (eyK| Mi, B, œÉ2,f
WK, y) (6.64)
In the subsequent conditioning on eX and Mi will be omitted in order to simplify the no-
tation. It is important to keep in mind that the matrix f
WK contains deterministic future
values, but more importantly, also lagged future values yT+K‚àíp, for p = 1...pmax, when
a K-step ahead forecast is considered. In the following it will be useful to partition the
vector of unknown future observations according to
eyK =
 
eyK‚àí1
yT+K
!
(6.65)
where eyK‚àí1 is a subvector of dimension K ‚àí1 and yT+K the unknown future value at
t = T + K.
Further partition the right-hand side variables of the prediction equation (5.7) (see section
5.2.2, p.82), contained in the matrix f
WK, conformably to (6.65):
f
WK =
 f
WK‚àí1
W(K)
!
(6.66)
with f
WK‚àí1 a submatrix of dimension K ‚àí1 √ó d and W(K) a vector of dimension 1 √ó d
which is just the K-th row of the matrix f
WK.
5Note that a nonperiodic AR model is a special case of a periodic AR model, namely for œÜs = œÜ, ‚àÄs.
203

Note that for K = 1, ey1 = yT+1 and f
W1 = W(1). The main results are summarized in the
following proposition, which generalizes Theorem 1, in Broemeling and Land (1984), to
the periodic case.
Proposition 1. If {yt : t = 1...T} is a trajectory of a Gaussian PAR(p) process with un-
known parameters B = (œÜ‚Ä≤, Œ¥ ‚Ä≤)‚Ä≤ ‚ààRd and œÉ2 ‚ààR+, where the vector y contains the
last T ‚àíp observations and y0 contains the Ô¨Årst p observations, and if unknown future
values {yT+k : k = 1...K}, contained in the vector eyK, are generated by the same pro-
cess as the observations, and eX‚Ä≤eX and f
W‚Ä≤
Kf
WK are symmetric positive deÔ¨Ånite matrices,
and the joint prior distribution of (B, œÉ2) is of the Normal-Inverse-Gamma-2 form with
parameters B0 ‚ààRd, V a symmetric positive deÔ¨Ånite scale matrix and a,b > 0, then the
posterior predictive distribution of eyK given y and y0, can be expressed as the product
K univariate predictive densities, namely the marginal density of yT+1, the conditional
predictive density of yT+2 given yT+1 and so on, where these densities have the following
form:6
‚Ä¢ If K = 1, the predictive density of yT+1 is a Student-t density with ŒΩ‚ãÜ= T ‚àíp + a
degrees of freedom, mean
E(yT+1| y) = D‚àí1
1 ¬∑E1
(6.67)
and variance
Var(yT+1| y) = F1 ‚àíE‚Ä≤
1 ¬∑D‚àí1
1 ¬∑E1
(ŒΩ‚ãÜ‚àí2)¬∑D1
(6.68)
where
D1 = 1‚àíW(1) ¬∑R‚àí1 ¬∑W ‚Ä≤
(1)
E1 = W(1) ¬∑R‚àí1 ¬∑F1
F1 = S‚àíy2
T+1 ‚àíF‚Ä≤
1 ¬∑R‚àí1 ¬∑F1
(6.69)
6Conditioning on y0 and eX is omitted.
204

with
R = V‚àí1 + eX‚Ä≤ ¬∑ eX+ f
W‚Ä≤
K ¬∑f
WK
(6.70a)
S = y‚Ä≤ ¬∑y+ey‚Ä≤
K ¬∑eyK + B‚Ä≤
0 ¬∑V‚àí1 ¬∑B0 + b
(6.70b)
F1 = V‚àí1B0 + eX‚Ä≤y
(6.70c)
‚Ä¢ In general, if K > 1, the conditional predictive density of yT+K given f
WK (see (5.6)
in section 5.2.2, p.82) is a Student-t density with ŒΩ‚ãÜ= T ‚àíp+a+K ‚àí1 degrees of
freedom, mean
E(yT+K| f
WK, y) = D‚àí1
K ¬∑EK
(6.71)
and variance
Var(yT+K| f
WK, y) = FK ‚àíE‚Ä≤
K ¬∑D‚àí1
K ¬∑EK
(ŒΩ‚ãÜ‚àí2) ¬∑DK
(6.72)
where
DK = 1‚àíW(K) ¬∑R‚àí1 ¬∑W ‚Ä≤
(K)
EK = W(K) ¬∑R‚àí1 ¬∑

F1 + f
W‚Ä≤
K‚àí1 ¬∑eyK‚àí1

FK = S‚àíy2
T+K ‚àí

F1 + f
W‚Ä≤
K‚àí1 ¬∑eyK‚àí1
‚Ä≤
R‚àí1 
F1 + f
W‚Ä≤
K‚àí1 ¬∑eyK‚àí1

(6.73)
Proof:
Writing out (6.64) more explicitly (omitting the normalizing constants for convenience)
the kernel of this joint pdf is given by
f (eyK,B, œÉ2 | Mi, y)
‚àù(œÉ2)‚àíT‚àíp
2 ¬∑exp

‚àí1
2œÉ2(y‚àíeX¬∑B)‚Ä≤ ¬∑(y‚àíeX¬∑B)

¬∑(œÉ2)‚àía+2
2 ¬∑exp

‚àíb
2œÉ2

¬∑
(œÉ2)‚àíd
2 ¬∑exp

‚àí1
2œÉ2(B‚àíB0)‚Ä≤ ¬∑V‚àí1 ¬∑(B‚àíB0)

¬∑
(œÉ2)‚àíK
2 ¬∑exp

‚àí1
2œÉ2(eyK ‚àíf
WK ¬∑B)‚Ä≤ ¬∑(eyK ‚àíf
WK ¬∑B)

205

(6.74)
with d = (4+ p) ¬∑S (= dim(B)).
First consider only the exponent of (6.74), which is equal to
(y‚àíeX¬∑B)‚Ä≤ ¬∑(y‚àíeX¬∑B) + (eyK ‚àíf
WK ¬∑B)‚Ä≤ ¬∑(eyK ‚àíf
WK ¬∑B)
+ (B‚àíB0)‚Ä≤ ¬∑V‚àí1 ¬∑(B‚àíB0) + b
(6.75)
Next complete the square with respect to the vector B. By using the matrix R given in
(6.70a), the exponent (6.75) can be expressed more compactly as
= B‚Ä≤ ¬∑R¬∑B‚àí2¬∑B‚Ä≤(eX‚Ä≤y+ V‚àí1B0 + f
W‚Ä≤
K ¬∑eyK
|
{z
}
‚â°F
) + y‚Ä≤y+ey‚Ä≤
KeyK + B‚Ä≤
0V‚àí1B0 + b
|
{z
}
‚â°S, see (6.70b)
(6.76)
Applying a Cholesky decomposition to the matrix R = LL‚Ä≤, with L the corresponding
lower triangular matrix, and deÔ¨Åning eB ‚â°L‚Ä≤B ‚áîB = (L‚Ä≤)‚àí1eB, then after completing
the square with respect to eB, equation (6.76) can be written as
= (eB‚àíL‚àí1 ¬∑F)‚Ä≤ ¬∑(eB‚àíL‚àí1 ¬∑F) ‚àíF‚Ä≤ ¬∑R‚àí1 ¬∑F+ S
(6.77)
and by substituting eB = L‚Ä≤B and some algebra, (6.77) is seen to be
= (B‚àíR‚àí1 ¬∑F)‚Ä≤ ¬∑R¬∑(B‚àíR‚àí1 ¬∑F) + S‚àíF‚Ä≤ ¬∑R‚àí1 ¬∑F
(6.78)
where in the following the quadratic form in B is denoted by QF(B).
Plugging (6.78) into the exponent of the joint pdf (6.74) the latter becomes
f (eyK, B, œÉ2 | y) ‚àù(œÉ2)‚àíT‚àíp+K+d+a+2
2
¬∑exp

‚àí1
2œÉ2[ QF(B) + S‚àíF‚Ä≤ ¬∑R‚àí1 ¬∑F ]

(6.79)
206

Now integrate out B from (6.79) using properties of the multivariate Normal density
f (eyK, œÉ2 | y) ‚àù
Z
Rd |R|
1
2 ¬∑(œÉ2)‚àíd
2 ¬∑exp

‚àí1
2œÉ2 ¬∑QF(B)

¬∑dB
¬∑|R|‚àí1
2 ¬∑(œÉ2)‚àíT‚àíp+K+a+2
2
¬∑exp

‚àí1
2œÉ2[ S‚àíF‚Ä≤ ¬∑R‚àí1 ¬∑F ]

(6.80)
and write b‚ãÜ‚â°S‚àíF‚Ä≤ ¬∑R‚àí1 ¬∑F henceforth.
Next integrate out œÉ2 from (6.80) by using the properties of the IG2 density:
f (eyK | y) ‚àù|R|‚àí1
2 ¬∑Cg
Z
R+ C‚àí1
g
¬∑(œÉ2)‚àía‚ãÜ+2
2
¬∑exp

‚àíb‚ãÜ
2œÉ2

¬∑dœÉ2
(6.81)
with a‚ãÜ‚â°T ‚àíp+K +a and Cg(a‚ãÜ
2 ;
2
b‚ãÜ) the normalizing constant of the Gamma-2 distri-
bution, see Bauwens et al. (1999), p.292.
In the following the main task is to obtain the posterior predictive distribution of eyK under
model Mi. By subsuming all terms independent of eyK into the proportionality sign the
expression in (6.81) is proportional to
f (eyK | y) ‚àù| R |‚àí1
2 ¬∑(b‚ãÜ)‚àía‚ãÜ
2
= | R |‚àí1
2 ¬∑ ( S‚àíF‚Ä≤ ¬∑R‚àí1 ¬∑F )‚àía‚ãÜ
2
(6.82)
Furthermore by proceeding as in Zellner (1971), p.72 f., we can express the last factor of
(6.82) in terms of quadratic forms, by completing the square with respect to eyK, y and B0,
which after some algebra7 Ô¨Ånally results in
f (eyK | y) ‚àù| R |‚àí1
2 ¬∑ [ QF(B0) + QF(y) + QF(eyK) ]‚àía‚ãÜ
2
(6.83a)
= | R |‚àí1
2 ¬∑c‚àía‚ãÜ
2 ¬∑ [ 1+ QF(eyK)/c ]‚àía‚ãÜ
2
(6.83b)
with QF(.) the respective quadratic forms and c ‚â°QF(y) + QF(B0).
7Details are omitted here in order to save space, cf. ibid.
207

For an ease of reference QF(eyK) is stated here explicitly without a proof:
QF(eyK) =

eyK ‚àíf
WK ¬∑ bŒ≤B
‚Ä≤
¬∑E‚ãÜ¬∑

eyK ‚àíf
WK ¬∑ bŒ≤B

(6.84)
with scale matrix8
E‚ãÜ‚â°IK ‚àíf
WK ¬∑R‚àí1 ¬∑f
W‚Ä≤
K
(6.85a)
=

IK + f
WK ¬∑(V‚àí1 + eX‚Ä≤eX)‚àí1 ¬∑f
W‚Ä≤
K
‚àí1
(6.85b)
and
bŒ≤B ‚â°

V‚àí1 + eX‚Ä≤eX
‚àí1
¬∑

V‚àí1B0 + eX‚Ä≤y

(6.86)
the usual Bayes estimate of B under quadratic loss, cf. Bauwens et al. (1999), p.58.9
At Ô¨Årst sight the expression in (6.83b) resembles that given in Zellner (1971), p.73, which
has the form of a multivariate t-density (see also Bauwens et al. (1999), Theorem 2.25,
p.61). However when examining (6.83b) in some more detail we recognize that the matrix
R = V‚àí1 + eX‚Ä≤eX + f
W‚Ä≤
Kf
WK, and hence the determinant, depends on lagged future values
yt, t ‚â§T + K ‚àí1, through the matrix f
WK. As a consequence the last factor in (6.83b)
is not the kernel of a multivariate t-density, since a subset of the values in f
WK contains
lagged future values of yt. Hence the posterior predictive distribution of a PAR model
is not a multivariate t-density as in the case of a standard (non-autoregressive) linear
regression model, see for example Judge et al. (1985), p.122, Gelman et al. (1995), p.239,
among others.
Next the posterior predictive distribution f (eyk| y) is examined in more detail. As noted
by Broemeling and Land (1984), p.1309 (henceforth abbreviated by ‚ÄôBL‚Äô), for the case of
a nonperiodic AR(p) model, and as can also be seen from (6.82), the Bayesian predictive
8The last equation (6.85b) follows from an application of the Woodbury matrix identity by setting A =
IK, U = f
WK, V = f
W‚Ä≤
K and C = (V‚àí1 + eX‚Ä≤eX)‚àí1 in (A+ U¬∑C¬∑V)‚àí1, see footnote 2 on page 185 of
section G.1.
9A similar expression as that in (6.84) can be found in Bauwens et al. (1999), Theorem 2.25, p.61., using
(6.85b), or in Zellner (1971), p.73, when using a joint diffuse prior for B and œÉ2.
208

distribution of eyK, for K ‚â•1, can be factorized according to:
f (eyK | y) = g1(eyK‚àí1, y) ¬∑g2(eyK , y) ,
eyK ‚ààRK
(6.87)
with
g1(eyK‚àí1, y) ‚àù| R |‚àí1
2
(6.88a)
g2(eyK , y) ‚àù( S‚àíF‚Ä≤ ¬∑R‚àí1 ¬∑F )‚àíT‚àíp+K+a
2
(6.88b)
For the sake of clarity consider next the matrix f
WK in more detail. Note that this matrix
consists of two submatrices, see (5.6) in chapter 5. Below only the Ô¨Årst of these two
submatrices, namely XK, is indicated here for s = 1,2 explicitly. This matrix is given by
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
D1,T+1 ¬∑yT
...
D1,T+1 ¬∑yT+1‚àíp
D2,T+1 ¬∑yT
...
D2,T+1 ¬∑yT+1‚àíp
...
D1,T+2 ¬∑yT+1
...
D1,T+2 ¬∑yT+2‚àíp
D2,T+2 ¬∑yT+1
...
D2,T+2 ¬∑yT+2‚àíp
...
D1,T+3 ¬∑yT+2
...
D1,T+3 ¬∑yT+3‚àíp
D2,T+3 ¬∑yT+2
...
D2,T+3 ¬∑yT+3‚àíp
...
...
...
...
...
D1,T+K ¬∑yT+K‚àí1
...
D1,T+K ¬∑yT+K‚àíp
D2,T+K ¬∑yT+K‚àí1
...
D2,T+K ¬∑yT+K‚àíp
...
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
with dimension K √ó d and Ds,t equals one if observation t falls in season s, and equals
zero otherwise.10
For K = 1 and a sample y, the Ô¨Årst term g1(ey0, y) in (6.87) does not depend on yT+1 since
f
W1 contains only yt-terms with t < T + 1, and g2(ey1, y) only depends on ey1 = yT+1,
given y. Note that if K = 1, then eyK‚àí1 = ey0 = 0 and f
WK = W(K), since f
WK‚àí1 = 0, see
expressions (6.65) and (6.66). Hence the marginal posterior predictive pdf for a one-step
ahead forecast is
f (yT+1| y) ‚àùg2(yT+1, y)
(6.89)
and will be shown to have the form of a univariate Student-t density. In this case, g2
equals the kernel and g1 equals the normalizing constant of a univariate t-density.
For K = 2, the Ô¨Årst term g1(ey1, y) does not depend on yT+2, since both ey1 and f
W2 contain
10Where the subsequent discussion follows that in Broemeling and Land (1984) for the nonperiodic case.
209

only yt-terms with t < T + 2, and the second term, g2(ey2, y), depends on both yT+1
and yT+2 through ey2. Hence for given values y1,...,yT,yT+1, the conditional posterior
predictive distribution of a two-step ahead forecast, f (yT+2| yT+1, y), is g2(ey2, y), which
will be seen to have the form of a conditional t-density. Since the joint posterior predictive
pdf for K = 2 can be factorized as
f (ey2| y) = f (yT+2| yT+1, y) ¬∑ f (yT+1| y)
(6.90)
it follows that this joint pdf is given by the product of two univariate t-densities (a marginal
and a conditional).
In general, for K ‚â•2 the Ô¨Årst term g1(eyK‚àí1, y) in (6.87) does not depend on yT+K
since eyK‚àí1 and f
WK contain only yt-terms with t ‚â§T + K ‚àí1, and g2(eyK, y) depends
on yT+1,...,yT+K through eyK. Hence for given values eyK‚àí1 and y, the conditional poste-
rior predictive pdf for a K-step ahead forecast, f (yT+K| f
WK, y), is equal to g2(eyK, y),
which will be shown below to be proportional to a t-density kernel. Since the joint poste-
rior predictive pdf for K ‚â•1 can be factorized as
f (eyK| y) =
K
‚àè
k=1
f (yT+k| eyk‚àí1, y) , with ey0 = 0
(6.91)
it follows that the posterior predictive pdf of eyK can be expressed as the product of K
univariate t-densities, viz. a marginal t-density for yT+1 and K ‚àí1 conditional t-densities.
However the crucial point here is that this pdf is not the standard K-variate Student-t
density, as in Zellner (1971), p.73, for the case of a (nonautoregressive) linear regression
model. The same result has been established by Broemeling and Land (1984) for the
nonperiodic case.
Next it will be shown that for K = 1 the marginal posterior predictive density of yT+1 is
a Student-t density with T ‚àíp + a degrees of freedom and that for K > 1 the posterior
predictive density of yT+K, given f
WK, is a conditional Student-t density with T ‚àíp+a+
K ‚àí1 degrees of freedom.
210

First write out the second term of (6.82) explicitly:
S‚àíF‚Ä≤ ¬∑R‚àí1 ¬∑F = y‚Ä≤y+ey‚Ä≤
K ¬∑eyK + B‚Ä≤
0V‚àí1B0
‚àí(eX‚Ä≤y+ V‚àí1B0 + f
W‚Ä≤
K ¬∑eyK)‚Ä≤ ¬∑(V‚àí1 + eX‚Ä≤eX+ f
W‚Ä≤
Kf
WK)‚àí1 ¬∑(eX‚Ä≤y+ V‚àí1B0 + f
W‚Ä≤
K ¬∑eyK)
(6.92)
and use some notation to simplify the subsequent algebra
S‚àíF‚Ä≤ ¬∑R‚àí1 ¬∑F
=
‚â°S1
z
}|
{
B‚Ä≤
0V‚àí1B0 +
‚â°S2
z}|{
y‚Ä≤y +
‚â°S3
z }| {
ey‚Ä≤
K ¬∑eyK
‚àí(
‚â°F1
z
}|
{
V‚àí1B0 + eX‚Ä≤y+
‚â°F2
z }| {
f
W‚Ä≤
K ¬∑eyK)‚Ä≤ ¬∑(V‚àí1 + eX‚Ä≤eX+ f
W‚Ä≤
Kf
WK)‚àí1 ¬∑(F1 + F2)
= ey‚Ä≤
K ¬∑eyK ‚àí
h
f
W‚Ä≤
K ¬∑eyK + F1
i‚Ä≤
¬∑R‚àí1 ¬∑
h
f
W‚Ä≤
K ¬∑eyK + F1
i
+ S1 + S2
= ey‚Ä≤
K ¬∑[IK ‚àíf
WKR‚àí1f
W‚Ä≤
K]
|
{z
}
‚â°H
K√óK
¬∑eyK ‚àí2¬∑ey‚Ä≤
K ¬∑f
WKR‚àí1F1
|
{z
}
‚â°D
K√ó1
+ S1 + S2 ‚àíF1R‚àí1F1
|
{z
}
‚â°const
(6.93)
Next complete the square with respect to yT+K, i.e. the K-th element in the vector eyK (see
(6.65)). Further partition the matrix H in (6.93) as follows:
H
=
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£≠
H11
K‚àí1 √ó K‚àí1
|
H12
K‚àí1 √ó 1
‚àí‚àí‚àí‚àí‚àí
‚àí‚àí‚àí‚àí‚àí
H21
1 √ó K‚àí1
|
H22
1 √ó 1
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∏
(6.94)
and also the vector D, deÔ¨Åned in the last line of (6.93):
D =
Ô£´
Ô£≠DK‚àí1
D(K)
Ô£∂
Ô£∏=
Ô£´
Ô£≠
f
WK‚àí1 ¬∑R‚àí1 ¬∑F1
W(K) ¬∑R‚àí1 ¬∑F1
Ô£∂
Ô£∏
(6.95)
with DK‚àí1 a vector of dimension K ‚àí1 and D(K) the K-th element of D.
211

Using these expressions the last equation in (6.93) can be written more compactly as
= ( ey‚Ä≤
K‚àí1 , yT+K )¬∑
Ô£´
Ô£≠H11
H12
H21
H22
Ô£∂
Ô£∏¬∑
Ô£´
Ô£≠eyK‚àí1
yT+K
Ô£∂
Ô£∏‚àí2¬∑( ey‚Ä≤
K‚àí1 , yT+K )¬∑
Ô£´
Ô£≠DK‚àí1
D(K)
Ô£∂
Ô£∏+ const
(6.96)
Multiplying out (6.96) and completing the square with respect to yT+K yields
S‚àíF‚Ä≤ ¬∑R‚àí1 ¬∑F
= H22 ¬∑
‚â°QF(yT+K)
z
}|
{
h
yT+K ‚àíH‚àí1
22 ¬∑(D(K) ‚àíH21 ¬∑eyK‚àí1)
i2
‚àíH‚àí1
22 ¬∑
h
D(K) ‚àíH21 ¬∑eyK‚àí1
i2
+ ey‚Ä≤
K‚àí1H11eyK‚àí1 ‚àí2¬∑ey‚Ä≤
K‚àí1DK‚àí1 + const
|
{z
}
‚â°q
= H22 ¬∑QF(yT+K)‚àíH‚àí1
22 ¬∑
h
D(K) ‚àíH21 ¬∑eyK‚àí1
i2
+ q
(6.97)
To get explicit expressions for the mean and variance of yT+K recall from (6.93) that the
matrix H is given by
H = IK ‚àíf
WKR‚àí1f
W‚Ä≤
K
= IK ‚àí
Ô£´
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£¨
Ô£≠
‚â°V11
z
}|
{
f
WK‚àí1R‚àí1f
W‚Ä≤
K‚àí1
|
‚â°V12
z
}|
{
f
WK‚àí1R‚àí1W ‚Ä≤
(K)
‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí
‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí
W(K)R‚àí1f
W‚Ä≤
K‚àí1
|
{z
}
‚â°V21
|
W(K)R‚àí1W ‚Ä≤
(K)
|
{z
}
‚â°V22
Ô£∂
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∏
=
Ô£´
Ô£¨
Ô£¨
Ô£≠
IK‚àí1 ‚àíV11
|
‚àíV12
‚àí‚àí‚àí‚àí‚àí
‚àí‚àí‚àí‚àí‚àí
‚àíV21
|
1‚àíV22
Ô£∂
Ô£∑
Ô£∑
Ô£∏
(6.98)
From QF(yT+K) in (6.97) the conditional posterior expectation of yT+K can be seen to
212

equal
E(yT+K| f
WK, y) = H‚àí1
22 ¬∑(D(K) ‚àíH21 ¬∑eyK‚àí1)
(6.99)
or by inserting the expressions of the second equation of (6.98):
=

1‚àíW(K) ¬∑R‚àí1 ¬∑W ‚Ä≤
(K)
‚àí1
¬∑

D(K) +W(K) ¬∑R‚àí1 ¬∑f
W‚Ä≤
K‚àí1 ¬∑eyK‚àí1

(6.100)
From the deÔ¨Ånition of D(K) in (6.95), the conditional expectation in (6.100) can be written
as
E(yT+K| f
WK, y)
=

1‚àíW(K) ¬∑R‚àí1 ¬∑W ‚Ä≤
(K)
‚àí1
¬∑W(K) ¬∑R‚àí1 ¬∑

F1 + f
W‚Ä≤
K‚àí1 ¬∑eyK‚àí1

(6.101)
verifying (6.71) of proposition 1, see BL, p.1310 (26), for a similar expression.
To derive the conditional posterior variance of yT+K, stated in (6.72), Ô¨Årst write out the
last equation of (6.97), utilizing
q = ey‚Ä≤
K‚àí1 ¬∑H11 ¬∑eyK‚àí1 ‚àí2¬∑ey‚Ä≤
K‚àí1DK‚àí1 + S1 + S2 ‚àíF‚Ä≤
1R‚àí1F1
together with the deÔ¨Ånitions of (6.98) to yield
S‚àíF‚Ä≤ ¬∑R‚àí1 ¬∑F = H22 ¬∑QF(yT+K)
‚àíH‚àí1
22 ¬∑

D(K) +W(K)R‚àí1f
W‚Ä≤
K‚àí1 ¬∑eyK‚àí1
2
+ey‚Ä≤
K‚àí1 ¬∑(IK‚àí1 ‚àíV11) ¬∑eyK‚àí1
‚àí2¬∑ey‚Ä≤
K‚àí1DK‚àí1 + S1 + S2 ‚àíF‚Ä≤
1R‚àí1F1
(6.102)
For an ease of comparison with the results in BL deÔ¨Åne:
EK
‚â°D(K) +W(K) ¬∑R‚àí1 ¬∑f
W‚Ä≤
K‚àí1 ¬∑eyK‚àí1
(6.103)
= W(K) ¬∑R‚àí1 ¬∑

F1 + f
W‚Ä≤
K‚àí1 ¬∑eyK‚àí1

(6.104)
where the last line follows from the deÔ¨Ånition of D(K), see (6.95).
213

Then (6.102) can be written as
S‚àíF‚Ä≤ ¬∑R‚àí1 ¬∑F = H22 ¬∑QF(yT+K) ‚àíE‚Ä≤
K ¬∑H‚àí1
22 ¬∑EK + S‚àíy2
T+K
‚àíF‚Ä≤
1R‚àí1F1 ‚àíey‚Ä≤
K‚àí1 ¬∑V11 ¬∑eyK‚àí1 ‚àí2¬∑ey‚Ä≤
K‚àí1 ¬∑DK‚àí1
(6.105)
by utilizing the fact that S1 +S2 = S‚àíS3 = S‚àíeyK‚àí1 ¬∑eyK‚àí1 ‚àíy2
T+K, see equation (6.93).
Further by using the deÔ¨Ånitions of DK‚àí1 and V11, given in (6.95) and (6.98), equation
(6.105) becomes
= H22 ¬∑QF(yT+K) ‚àíE‚Ä≤
K ¬∑H‚àí1
22 ¬∑EK + S‚àíy2
T+K ‚àí[ ey‚Ä≤
K‚àí1 ¬∑f
WK‚àí1
|
{z
}
‚â°C‚Ä≤
¬∑R‚àí1 ¬∑f
W‚Ä≤
K‚àí1 ¬∑eyK‚àí1
+ 2¬∑ey‚Ä≤
K‚àí1 ¬∑f
WK‚àí1 ¬∑R‚àí1F1 + F‚Ä≤
1R‚àí1F1 ]
= H22 ¬∑QF(yT+K) ‚àíE‚Ä≤
K ¬∑H‚àí1
22 ¬∑EK + S‚àíy2
T+K ‚àí

C‚Ä≤R‚àí1C+ 2¬∑C‚Ä≤ ¬∑R‚àí1F1 + F‚Ä≤
1R‚àí1F1

= H22 ¬∑QF(yT+K) ‚àíE‚Ä≤
K ¬∑H‚àí1
22 ¬∑EK + S‚àíy2
T+K ‚àí( C+ F1)‚Ä≤ ¬∑R‚àí1 ¬∑( C+ F1)
|
{z
}
‚â°FK
(6.106)
Note that since H22 corresponds to DK in (6.73) of proposition 1, H22 = DK is used in
the following. By using the last equation of (6.106) the posterior predictive distribution
in (6.82) can be written as:
f (eyK| y) = g1(eyK‚àí1, y)¬∑g2(eyK, y)
‚àù|R|‚àí1
2 ¬∑

FK ‚àíE‚Ä≤
K ¬∑D‚àí1
K ¬∑EK + DK ¬∑QF(yT+K)
‚àía‚ãÜ
2
= |R|‚àí1
2 ¬∑
 FK ‚àíE‚Ä≤
K ¬∑D‚àí1
K ¬∑EK
‚àía‚ãÜ
2 ¬∑
"
1+
 
DK
FK ‚àíE‚Ä≤
K ¬∑D‚àí1
K ¬∑EK
!
¬∑QF(yT+K)
#‚àíŒΩ‚ãÜ+1
2
(6.107)
with ŒΩ‚ãÜ‚â°T ‚àíp + a + K ‚àí1 and QF(yT+K) =

yT+K ‚àíE(yT+K| f
WK, y)
2
, where the
expectation is given in (6.101).
214

First from (6.107) it can be observed that the last factor is the kernel of the proposed
conditional Student-t density of yT+K with ŒΩ‚ãÜposterior degrees of freedom, given eyK‚àí1 =
(yT+1,...,yT+K‚àí1)‚Ä≤, future deterministic values and the data y, contained in the matrix
f
WK. From the expressions in (6.73) of proposition 1 it can be seen that the Ô¨Årst two factors
in the last line of (6.107) do not depend on yT+K, but only on eyK‚àí1. With regard to the
conditional Student-t density of yT+K, for K > 1, this means that given eyK‚àí1 the Ô¨Årst two
factors can be subsumed into the normalizing constant of f (yT+K| f
WK, y). Hence, given
eyK‚àí1, for K > 1 the factor g2 in (6.107) is equal to a conditional Student-t density with
ŒΩ‚ãÜposterior degrees of freedom. From (6.107) the variance of the conditional predictive
pdf of yT+K (see Bauwens et al. (1999), A.35, p.294) is given by:
Var(yT+K| f
WK, y) = FK ‚àíE‚Ä≤
K ¬∑D‚àí1
K ¬∑EK
(ŒΩ‚ãÜ‚àí2)¬∑DK
(6.108)
verifying (6.72) of proposition 1.11
To obtain the conditional posterior predictive density of yT+K‚àí1 given values eyK‚àí2 =
(yT+1,...,yT+K‚àí2)‚Ä≤ and y, complete the square with respect to yT+K‚àí1 in the second factor
of (6.107), which then can be shown to have the form of a univariate conditional t-density,
and so on.
The expressions of the Ô¨Årst two moments for K = 1, proposed in (6.67) and (6.68) above,
can be obtained from (6.101) and (6.108), respectively, by noting that for K = 1, eyK‚àí1 = 0
and f
WK‚àí1 = 0, and thus eyK = yT+1 and f
WK = W(1), where W(1) only depends on the
observed data y. To obtain the corresponding expressions under the diffuse prior for œÉ2,
used in section 5.2.1, the hyperparameters of the IG2 prior have to be chosen according
to a ‚Üí‚àíd and b ‚Üí0.
‚ñ°
11Note that the precision of yT+K is equal to Var(yT+K| f
WK, y)‚àí1 in (6.108), see BL, p.1311 (27), for a
similar result.
215

