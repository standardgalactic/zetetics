CODE LISTINGS AND FIGURES

CHAPTER 1
Figure 1.1. Arti×cial intelligence, machine learning, and deep learning
Figure 1.2. Machine learning: a new programming paradigm
Figure 1.3. Some sample data
Figure 1.4. Coordinate change

Figure 1.5. A deep neural network for digit classi×cation
Figure 1.6. Deep representations learned by a digit-classi×cation model
Figure 1.7. A neural network is parameterized by its weights.

Figure 1.8. A loss function measures the quality of the network’s output.
Figure 1.9. The loss score is used as a feedback signal to adjust the weights.

Figure 1.10. A decision boundary
Figure 1.11. A decision tree: the parameters that are learned are the questions about
the data. A question could be, for instance, “Is coef×cient 2 in the data greater than
3.5?”

CHAPTER 2
Figure 2.1. MNIST sample digits
Listing 2.1. Loading the MNIST dataset in Keras
1
2
from keras.datasets import mnist 
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
1
2
3
4
5
6
>>> train_images.shape 
(60000, 28, 28) 
>>> len(train_labels) 
60000 
>>> train_labels 
array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)
1
2
3
4
5
6
>>> test_images.shape 
(10000, 28, 28) 
>>> len(test_labels) 
10000 
>>> test_labels 
array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)
Listing 2.2. The network architecture
1
2
3
4
5
6
from keras import models 
from keras import layers 
 
network = models.Sequential() 
network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,))) 
network.add(layers.Dense(10, activation='softmax'))

Listing 2.3. The compilation step
1
2
3
network.compile(optimizer='rmsprop', 
                loss='categorical_crossentropy', 
                metrics=['accuracy'])
Listing 2.4. Preparing the image data
1
2
3
4
5
train_images = train_images.reshape((60000, 28 * 28)) 
train_images = train_images.astype('float32') / 255 
 
test_images = test_images.reshape((10000, 28 * 28)) 
test_images = test_images.astype('float32') / 255
Listing 2.5. Preparing the labels
1
2
3
4
from keras.utils import to_categorical 
 
train_labels = to_categorical(train_labels) 
test_labels = to_categorical(test_labels)
1
2
3
4
5
>>> network.fit(train_images, train_labels, epochs=5, batch_size=128) 
Epoch 1/5 
60000/60000 [==============================] - 9s - loss: 0.2524 - acc: 0.9273 
Epoch 2/5 
51328/60000 [========================>.....] - ETA: 1s - loss: 0.1035 - acc: 0.9692
1
2
3
>>> test_loss, test_acc = network.evaluate(test_images, test_labels) 
>>> print('test_acc:', test_acc) 
test_acc: 0.9785
1
2
3
>>> import numpy as np 
>>> x = np.array(12) 
>>> x 

4
5
6
array(12) 
>>> x.ndim 
0
1
2
>>> x.ndim 
1
1
2
3
4
5
>>> x = np.array([[5, 78, 2, 34, 0], 
                  [6, 79, 3, 35, 1], 
                  [7, 80, 4, 36, 2]]) 
>>> x.ndim 
2
1
2
3
4
5
6
7
8
9
10
11
>>> x = np.array([[[5, 78, 2, 34, 0], 
                   [6, 79, 3, 35, 1], 
                   [7, 80, 4, 36, 2]], 
                  [[5, 78, 2, 34, 0], 
                   [6, 79, 3, 35, 1], 
                   [7, 80, 4, 36, 2]], 
                  [[5, 78, 2, 34, 0], 
                   [6, 79, 3, 35, 1], 
                   [7, 80, 4, 36, 2]]]) 
>>> x.ndim 
3
1
2
from keras.datasets import mnist 
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
1
2
>>> print(train_images.ndim) 
3

Figure 2.2. The fourth sample in our dataset
1
2
>>> print(train_images.shape) 
(60000, 28, 28)
1
2
>>> print(train_images.dtype) 
uint8
Listing 2.6. Displaying the fourth digit
1
2
3
4
5
digit = train_images[4] 
 
import matplotlib.pyplot as plt 
plt.imshow(digit, cmap=plt.cm.binary) 
plt.show()
1
2
3
>>> my_slice = train_images[10:100] 
>>> print(my_slice.shape) 
(90, 28, 28)
1
2
3
4
5
>>> my_slice = train_images[10:100, :, :] 
>>> my_slice.shape 
(90, 28, 28) 
>>> my_slice = train_images[10:100, 0:28, 0:28] 
1
2

Figure 2.3. A 3D timeseries data tensor
Figure 2.4. A 4D image data tensor (channels-×rst convention)
6 >>> my_slice.shape 
(90, 28, 28)
1 my_slice = train_images[:, 14:, 14:]
1 my_slice = train_images[:, 7:-7, 7:-7]
1 batch = train_images[:128]
1 batch = train_images[128:256]
1 batch = train_images[128 * n:128 * (n + 1)]

1 keras.layers.Dense(512, activation='relu')
1 output = relu(dot(W, input) + b)
1
2
3
4
5
6
7
8
def naive_relu(x): 
    assert len(x.shape) == 2 
 
    x = x.copy() 
    for i in range(x.shape[0]): 
        for j in range(x.shape[1]): 
            x[i, j] = max(x[i, j], 0) 
    return x
1
2
1
2
3
4
5
6
7
8
9
def naive_add(x, y): 
    assert len(x.shape) == 2 
    assert x.shape == y.shape 
 
    x = x.copy() 
    for i in range(x.shape[0]): 
        for j in range(x.shape[1]): 
            x[i, j] += y[i, j] 
    return x
1
2

1
2
3
4
5
import numpy as np 
 
z = x + y 
 
z = np.maximum(z, 0.)
1
2
1
2
3
4
5
6
7
8
9
10
def naive_add_matrix_and_vector(x, y): 
    assert len(x.shape) == 2 
    assert len(y.shape) == 1 
    assert x.shape[1] == y.shape[0] 
 
    x = x.copy() 
    for i in range(x.shape[0]): 
        for j in range(x.shape[1]): 
            x[i, j] += y[j] 
    return x
1
2
3
1
2
3
4
5
6
import numpy as np 
 
x = np.random.random((64, 3, 32, 10)) 
y = np.random.random((32, 10)) 
 
z = np.maximum(x, y)
1
2
3
1
2
import numpy as np 
z = np.dot(x, y)
1 z = x . y
def naive_vector_dot(x, y): 
   assert len(x.shape) == 1 
   assert len(y.shape) == 1 
   assert x.shape[0] == y.shape[0] 
   z = 0. 
   for i in range(x.shape[0]): 
       z += x[i] * y[i] 

Figure 2.5. Matrix dot-product box diagram
   return z 
 
#1 - x and y are Numpy vectors.
1
2
3
4
5
6
7
8
9
10
11
12
import numpy as np 
 
def naive_matrix_vector_dot(x, y): 
    assert len(x.shape) == 2 
    assert len(y.shape) == 1 
    assert x.shape[1] == y.shape[0] 
 
    z = np.zeros(x.shape[0]) 
    for i in range(x.shape[0]): 
        for j in range(x.shape[1]): 
            z[i] += x[i, j] * y[j] 
    return z
1
2
3
4
1
2
3
4
5
def naive_matrix_vector_dot(x, y): 
    z = np.zeros(x.shape[0]) 
    for i in range(x.shape[0]): 
        z[i] = naive_vector_dot(x[i, :], y) 
    return z
def naive_matrix_dot(x, y): 
   assert len(x.shape) == 2 
   assert len(y.shape) == 2 
   assert x.shape[1] == y.shape[0] 
   z = np.zeros((x.shape[0], y.shape[1])) 
   for i in range(x.shape[0]): 
       for j in range(y.shape[1]): 
           row_x = x[i, :] 
           column_y = y[:, j] 
           z[i, j] = naive_vector_dot(row_x, column_y) 
   return z

1
2
(a, b, c, d) . (d,) -> (a, b, c) 
(a, b, c, d) . (d, e) -> (a, b, c, e)
1 train_images = train_images.reshape((60000, 28 * 28))
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
>>> x = np.array([[0., 1.], 
                 [2., 3.], 
                 [4., 5.]]) 
>>> print(x.shape) 
(3, 2) 
 
>>> x = x.reshape((6, 1)) 
>>> x 
array([[ 0.], 
       [ 1.], 
       [ 2.], 
       [ 3.], 
       [ 4.], 
       [ 5.]]) 
 
 >>> x = x.reshape((2, 3)) 
 >>> x 
 array([[ 0.,  1.,  2.], 
        [ 3.,  4.,  5.]])
1
2
3
>>> x = np.zeros((300, 20)) 
 
>>> x = np.transpose(x) 
1

Figure 2.6. A point in a 2D space
Figure 2.7. A point in a 2D space pictured as an arrow
Figure 2.8. Geometric interpretation of the sum of two vectors
4
5
6
 
>>> print(x.shape) 
(20, 300)
1 A = [0.5, 1]

Figure 2.9. Uncrumpling a complicated manifold of data
Figure 2.10. Derivative of f  in p
1 output = relu(dot(W, input) + b)
1 f(x + epsilon_x) = y + epsilon_y
1 f(x + epsilon_x) = y + a * epsilon_x

Figure 2.11. SGD down a 1D loss curve (one learnable parameter)
Figure 2.12. Gradient descent down a 2D loss surface (two learnable parameters)
Figure 2.13. A local minimum and a global minimum
1
2
y_pred = dot(W, x) 
loss_value = loss(y_pred, y)
1 loss_value = f(W)

past_velocity = 0. 
momentum = 0.1 
while loss > 0.01: 
   w, loss, gradient = get_current_parameters() 
   velocity = past_velocity * momentum + learning_rate * gradient 
   w = w + momentum * velocity - learning_rate * gradient 
   past_velocity = velocity 
   update_parameter(w)
1 f(W1, W2, W3) = a(W1, b(W2, c(W3)))
(train_images, train_labels), (test_images, test_labels) = mnist.load_data() 
train_images = train_images.reshape((60000, 28 * 28)) 
train_images = train_images.astype('float32') / 255 
test_images = test_images.reshape((10000, 28 * 28)) 
test_images = test_images.astype('float32') / 255
network = models.Sequential() 
network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,))) 
network.add(layers.Dense(10, activation='softmax'))
network.compile(optimizer='rmsprop', 
               loss='categorical_crossentropy', 
               metrics=['accuracy'])

1 network.fit(train_images, train_labels, epochs=5, batch_size=128)

CHAPTER 3
Figure 3.1. Relationship between the network, layers, loss function, and optimizer
Figure 3.2. Google web search interest for different deep-learning frameworks over
time
1
2
3
from keras import layers 
 
layer = layers.Dense(32, input_shape=(784,))
1
1
2
3
4
5
6
from keras import models 
from keras import layers 
 
model = models.Sequential() 
model.add(layers.Dense(32, input_shape=(784,))) 
model.add(layers.Dense(32))

Figure 3.3. The deep-learning software and hardware stack
1
2
3
4
5
6
from keras import models 
from keras import layers 
 
model = models.Sequential() 
model.add(layers.Dense(32, activation='relu', input_shape=(784,))) 
model.add(layers.Dense(10, activation='softmax'))
1
2
3
4
5
input_tensor = layers.Input(shape=(784,)) 
x = layers.Dense(32, activation='relu')(input_tensor) 
output_tensor = layers.Dense(10, activation='softmax')(x) 
 
model = models.Model(inputs=input_tensor, outputs=output_tensor)
1
2
3
from keras import optimizers 
 
model.compile(optimizer=optimizers.RMSprop(lr=0.001), 

4
5
              loss='mse', 
              metrics=['accuracy'])
1 model.fit(input_tensor, target_tensor, batch_size=128, epochs=10)
Listing 3.1. Loading the IMDB dataset
1
2
3
4
from keras.datasets import imdb 
 
(train_data, train_labels), (test_data, test_labels) = imdb.load_data( 
    num_words=10000)
1
2
3
4
5
>>> train_data[0] 
[1, 14, 22, 16, ... 178, 32] 
 
>>> train_labels[0] 
1
1
2
>>> max([max(sequence) for sequence in train_data]) 
9999
1
2
3
4
5
word_index = imdb.get_word_index() 
reverse_word_index = dict( 
    [(value, key) for (key, value) in word_index.items()]) 
decoded_review = ' '.join( 
    [reverse_word_index.get(i - 3, '?') for i in train_data[0]])
1
2
3
Listing 3.2. Encoding the integer sequences into a binary matrix
1
2
3
import numpy as np 
 
def vectorize_sequences(sequences, dimension=10000): 

Figure 3.4. The recti×ed linear unit function
4
5
6
7
8
9
10
    results = np.zeros((len(sequences), dimension)) 
    for i, sequence in enumerate(sequences): 
        results[i, sequence] = 1. 
    return results 
 
x_train = vectorize_sequences(train_data) 
x_test = vectorize_sequences(test_data)
1
2
3
4
1
2
>>> x_train[0] 
array([ 0.,  1.,  1., ...,  0.,  0.,  0.])
1
2
y_train = np.asarray(train_labels).astype('float32') 
y_test = np.asarray(test_labels).astype('float32')
1 output = relu(dot(W, input) + b)

Figure 3.5. The sigmoid function
Figure 3.6. The three-layer network

WHAT ARE ACTIVATION FUNCTIONS, AND WHY ARE THEY
NECESSARY?
Without an activation function like relu  (also called a non-linearity),
the Dense  layer would consist of two linear operations—a dot
product and an addition:
So the layer could only learn linear transformations (a}ne
transformations) of the input data: the hypothesis space of the layer
would be the set of all possible linear transformations of the input data
into a 16-dimensional space. Such a hypothesis space is too restricted
and wouldn’t benet from multiple layers of representations, because
a deep stack of linear layers would still implement a linear operation:
adding more layers wouldn’t extend the hypothesis space.
Listing 3.3. The model de×nition
1
2
3
4
5
6
7
from keras import models 
from keras import layers 
 
model = models.Sequential() 
model.add(layers.Dense(16, activation='relu', input_shape=(10000,))) 
model.add(layers.Dense(16, activation='relu')) 
model.add(layers.Dense(1, activation='sigmoid'))
1 output = dot(W, input) + b

In order to get access to a much richer hypothesis space that would
benet from deep representations, you need a non-linearity, or
activation function. relu  is the most popular activation function in
deep learning, but there are many other candidates, which all come
with similarly strange names: prelu , elu , and so on.
Listing 3.4. Compiling the model
1
2
3
model.compile(optimizer='rmsprop', 
              loss='binary_crossentropy', 
              metrics=['accuracy'])
Listing 3.5. Con×guring the optimizer
1
2
3
4
5
from keras import optimizers 
 
model.compile(optimizer=optimizers.RMSprop(lr=0.001), 
              loss='binary_crossentropy', 
              metrics=['accuracy'])
Listing 3.6. Using custom losses and metrics
1
2
3
4
5
6
from keras import losses 
from keras import metrics 
 
model.compile(optimizer=optimizers.RMSprop(lr=0.001), 
              loss=losses.binary_crossentropy, 
              metrics=[metrics.binary_accuracy])
Listing 3.7. Setting aside a validation set
1
2
3
4
x_val = x_train[:10000] 
partial_x_train = x_train[10000:] 
y_val = y_train[:10000] 
partial_y_train = y_train[10000:]
Listing 3.8. Training your model

Figure 3.7. Training and validation loss
Figure 3.8. Training and validation accuracy
1
2
3
4
5
6
7
8
9
model.compile(optimizer='rmsprop', 
              loss='binary_crossentropy', 
              metrics=['acc']) 
 
history = model.fit(partial_x_train, 
                    partial_y_train, 
                    epochs=20, 
                    batch_size=512, 
                    validation_data=(x_val, y_val))
1
2
3
>>> history_dict = history.history 
>>> history_dict.keys() 
[u'acc', u'loss', u'val_acc', u'val_loss']

Listing 3.9. Plotting the training and validation loss
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
import matplotlib.pyplot as plt 
 
history_dict = history.history 
loss_values = history_dict['loss'] 
val_loss_values = history_dict['val_loss'] 
 
epochs = range(1, len(acc) + 1) 
 
plt.plot(epochs, loss_values, 'bo', label='Training loss') 
plt.plot(epochs, val_loss_values, 'b', label='Validation loss') 
plt.title('Training and validation loss') 
plt.xlabel('Epochs') 
plt.ylabel('Loss') 
plt.legend() 
 
plt.show()
1
2
Listing 3.10. Plotting the training and validation accuracy
1
2
3
4
5
6
7
8
9
10
11
12
plt.clf() 
acc_values = history_dict['acc'] 
val_acc_values = history_dict['val_acc'] 
 
plt.plot(epochs, acc, 'bo', label='Training acc') 
plt.plot(epochs, val_acc, 'b', label='Validation acc') 
plt.title('Training and validation accuracy') 
plt.xlabel('Epochs') 
plt.ylabel('Loss') 
plt.legend() 
 
plt.show()
1

Listing 3.11. Retraining a model from scratch
1
2
3
4
5
6
7
8
9
10
11
model = models.Sequential() 
model.add(layers.Dense(16, activation='relu', input_shape=(10000,))) 
model.add(layers.Dense(16, activation='relu')) 
model.add(layers.Dense(1, activation='sigmoid')) 
 
model.compile(optimizer='rmsprop', 
              loss='binary_crossentropy', 
              metrics=['accuracy']) 
 
model.fit(x_train, y_train, epochs=4, batch_size=512) 
results = model.evaluate(x_test, y_test)
1
2
>>> results 
[0.2929924130630493, 0.88327999999999995]
1
2
3
4
5
6
7
8
>>> model.predict(x_test) 
array([[ 0.98006207] 
       [ 0.99758697] 
       [ 0.99975556] 
       ..., 
       [ 0.82167041] 
       [ 0.02885115] 
       [ 0.65371346]], dtype=float32)
Listing 3.12. Loading the Reuters dataset
1
2
3
4
from keras.datasets import reuters 
 
(train_data, train_labels), (test_data, test_labels) = reuters.load_data( 
    num_words=10000)
1
2
3
4
>>> len(train_data) 
8982 
>>> len(test_data) 
2246

1
2
3
>>> train_data[10] 
[1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 
3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]
Listing 3.13. Decoding newswires back to text
1
2
3
4
word_index = reuters.get_word_index() 
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) 
decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in 
    train_data[0]])
1
1
2
>>> train_labels[10] 
3
Listing 3.14. Encoding the data
1
2
3
4
5
6
7
8
9
10
import numpy as np 
 
def vectorize_sequences(sequences, dimension=10000): 
    results = np.zeros((len(sequences), dimension)) 
    for i, sequence in enumerate(sequences): 
        results[i, sequence] = 1. 
    return results 
 
x_train = vectorize_sequences(train_data) 
x_test = vectorize_sequences(test_data)
1
2
1
2
3
4
5
6
7
8
def to_one_hot(labels, dimension=46): 
    results = np.zeros((len(labels), dimension)) 
    for i, label in enumerate(labels): 
        results[i, label] = 1. 
    return results 
 
one_hot_train_labels = to_one_hot(train_labels) 
one_hot_test_labels = to_one_hot(test_labels)
1
2

1
2
3
4
from keras.utils.np_utils import to_categorical 
 
one_hot_train_labels = to_categorical(train_labels) 
one_hot_test_labels = to_categorical(test_labels)
Listing 3.15. Model de×nition
1
2
3
4
5
6
7
from keras import models 
from keras import layers 
 
model = models.Sequential() 
model.add(layers.Dense(64, activation='relu', input_shape=(10000,))) 
model.add(layers.Dense(64, activation='relu')) 
model.add(layers.Dense(46, activation='softmax'))
Listing 3.16. Compiling the model
1
2
3
model.compile(optimizer='rmsprop', 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])
Listing 3.17. Setting aside a validation set
1
2
3
4
5
x_val = x_train[:1000] 
partial_x_train = x_train[1000:] 
 
y_val = one_hot_train_labels[:1000] 
partial_y_train = one_hot_train_labels[1000:]
Listing 3.18. Training the model
1
2
3
4
5
history = model.fit(partial_x_train, 
                    partial_y_train, 
                    epochs=20, 
                    batch_size=512, 
                    validation_data=(x_val, y_val))

Figure 3.9. Training and validation loss
Figure 3.10. Training and validation accuracy
Listing 3.19. Plotting the training and validation loss
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
import matplotlib.pyplot as plt 
 
loss = history.history['loss'] 
val_loss = history.history['val_loss'] 
 
epochs = range(1, len(loss) + 1) 
 
plt.plot(epochs, loss, 'bo', label='Training loss') 
plt.plot(epochs, val_loss, 'b', label='Validation loss') 
plt.title('Training and validation loss') 
plt.xlabel('Epochs') 
plt.ylabel('Loss') 
plt.legend() 
 
plt.show()

Listing 3.20. Plotting the training and validation accuracy
1
2
3
4
5
6
7
8
9
10
11
12
13
plt.clf() 
 
acc = history.history['acc'] 
val_acc = history.history['val_acc'] 
 
plt.plot(epochs, acc, 'bo', label='Training acc') 
plt.plot(epochs, val_acc, 'b', label='Validation acc') 
plt.title('Training and validation accuracy') 
plt.xlabel('Epochs') 
plt.ylabel('Loss') 
plt.legend() 
 
plt.show()
1
Listing 3.21. Retraining a model from scratch
1
2
3
4
5
6
7
8
9
10
11
12
13
14
model = models.Sequential() 
model.add(layers.Dense(64, activation='relu', input_shape=(10000,))) 
model.add(layers.Dense(64, activation='relu')) 
model.add(layers.Dense(46, activation='softmax')) 
 
model.compile(optimizer='rmsprop', 
              loss='categorical_crossentropy', 
              metrics=['accuracy']) 
model.fit(partial_x_train, 
          partial_y_train, 
          epochs=9, 
          batch_size=512, 
          validation_data=(x_val, y_val)) 
results = model.evaluate(x_test, one_hot_test_labels)
1
2
>>> results 
[0.9565213431445807, 0.79697239536954589]
1
2
3
4
5
6
>>> import copy 
>>> test_labels_copy = copy.copy(test_labels) 
>>> np.random.shuffle(test_labels_copy) 
>>> hits_array = np.array(test_labels) == np.array(test_labels_copy) 
>>> float(np.sum(hits_array)) / len(test_labels) 
0.18655387355298308

Listing 3.22. Generating predictions for new data
1 predictions = model.predict(x_test)
1
2
>>> predictions[0].shape 
(46,)
1
2
>>> np.sum(predictions[0]) 
1.0
1
2
>>> np.argmax(predictions[0]) 
4
1
2
y_train = np.array(train_labels) 
y_test = np.array(test_labels)
1
2
3
model.compile(optimizer='rmsprop', 
              loss='sparse_categorical_crossentropy', 
              metrics=['acc'])
Listing 3.23. A model with an information bottleneck
1
2
3
4
5
6
7
8
9
model = models.Sequential() 
model.add(layers.Dense(64, activation='relu', input_shape=(10000,))) 
model.add(layers.Dense(4, activation='relu')) 
model.add(layers.Dense(46, activation='softmax')) 
 
model.compile(optimizer='rmsprop', 
              loss='categorical_crossentropy', 
              metrics=['accuracy']) 
model.fit(partial_x_train, 

10
11
12
13
          partial_y_train, 
          epochs=20, 
          batch_size=128, 
          validation_data=(x_val, y_val))
Listing 3.24. Loading the Boston housing dataset
1
2
3
4
from keras.datasets import boston_housing 
 
(train_data, train_targets), (test_data, test_targets) = 
boston_housing.load_data()
1
2
3
4
>>> train_data.shape 
(404, 13) 
>>> test_data.shape 
(102, 13)
1
2
>>> train_targets 
[ 15.2,  42.3,  50. ...  19.4,  19.4,  29.1]
Listing 3.25. Normalizing the data
1
2
3
4
5
6
7
mean = train_data.mean(axis=0) 
train_data -= mean 
std = train_data.std(axis=0) 
train_data /= std 
 
test_data -= mean 
test_data /= std
Listing 3.26. Model de×nition
1
2
3
4
5
6
from keras import models 
from keras import layers 
 
def build_model(): 
    model = models.Sequential() 
    model.add(layers.Dense(64, activation='relu', 
1

Figure 3.11. 3-fold cross-validation
7
8
9
10
11
                           input_shape=(train_data.shape[1],))) 
    model.add(layers.Dense(64, activation='relu')) 
    model.add(layers.Dense(1)) 
    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) 
    return model
Listing 3.27. K-fold validation
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
import numpy as np 
 
k = 4 
num_val_samples = len(train_data) // k 
num_epochs = 100 
all_scores = [] 
for i in range(k): 
    print('processing fold #', i) 
    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples] 
    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples] 
 
    partial_train_data = np.concatenate( 
        [train_data[:i * num_val_samples], 
         train_data[(i + 1) * num_val_samples:]], 
        axis=0) 
    partial_train_targets = np.concatenate( 
        [train_targets[:i * num_val_samples], 
         train_targets[(i + 1) * num_val_samples:]], 
        axis=0) 
 
    model = build_model() 
    model.fit(partial_train_data, partial_train_targets, 
              epochs=num_epochs, batch_size=1, verbose=0) 
    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0) 
    all_scores.append(val_mae)
1
2
3
4
5
1
2
>>> all_scores 
[2.588258957792037, 3.1289568449719116, 3.1856116051248984, 3.0763342615401386] 

Figure 3.12. Validation MAE by epoch
3
4
>>> np.mean(all_scores) 
2.9947904173572462
Listing 3.28. Saving the validation logs at each fold
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
num_epochs = 500 
all_mae_histories = [] 
for i in range(k): 
    print('processing fold #', i) 
    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples] 
    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples] 
    partial_train_data = np.concatenate( 
        [train_data[:i * num_val_samples], 
         train_data[(i + 1) * num_val_samples:]], 
        axis=0) 
    partial_train_targets = np.concatenate( 
        [train_targets[:i * num_val_samples], 
         train_targets[(i + 1) * num_val_samples:]], 
        axis=0) 
 
    model = build_model() 
    history = model.fit(partial_train_data, partial_train_targets, 
                        validation_data=(val_data, val_targets), 
                        epochs=num_epochs, batch_size=1, verbose=0) 
    mae_history = history.history['val_mean_absolute_error'] 
    all_mae_histories.append(mae_history)
1
2
3
4
Listing 3.29. Building the history of successive mean K-fold validation scores
1
2
average_mae_history = [ 
    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]

Figure 3.13. Validation MAE by epoch, excluding the ×rst 10 data points
Listing 3.30. Plotting validation scores
1
2
3
4
5
6
import matplotlib.pyplot as plt 
 
plt.plot(range(1, len(average_mae_history) + 1), average_mae_history) 
plt.xlabel('Epochs') 
plt.ylabel('Validation MAE') 
plt.show()
Listing 3.31. Plotting validation scores, excluding the ×rst 10 data points
1
2
3
4
5
6
def smooth_curve(points, factor=0.9): 
  smoothed_points = [] 
  for point in points: 
    if smoothed_points: 
      previous = smoothed_points[-1] 
      smoothed_points.append(previous * factor + point * (1 - factor)) 

7
8
9
10
11
12
13
14
15
16
    else: 
      smoothed_points.append(point) 
  return smoothed_points 
 
smooth_mae_history = smooth_curve(average_mae_history[10:]) 
 
plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history) 
plt.xlabel('Epochs') 
plt.ylabel('Validation MAE') 
plt.show()
Listing 3.32. Training the ×nal model
1
2
3
4
model = build_model() 
model.fit(train_data, train_targets, 
          epochs=80, batch_size=16, verbose=0) 
test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)
1
2
1
2
>>> test_mae_score 
2.5532484335057877

CHAPTER 4
Figure 4.1. Simple hold-out validation split
Figure 4.2. Three-fold validation
Listing 4.1. Hold-out validation
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
num_validation_samples = 10000 
 
np.random.shuffle(data) 
 
validation_data = data[:num_validation_samples] 
data = data[num_validation_samples:] 
 
training_data = data[:] 
 
model = get_model() 
model.train(training_data) 
validation_score = model.evaluate(validation_data) 
 
# At this point you can tune your model, 
# retrain it, evaluate it, tune it again... 
 
model = get_model() 
model.train(np.concatenate([training_data, 
                            validation_data])) 
test_score = model.evaluate(test_data)
1
2
3
4
5

Figure 4.3. Feature engineering for reading the time on a clock
Listing 4.2. K-fold cross-validation
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
k = 4 
num_validation_samples = len(data) // k 
 
np.random.shuffle(data) 
 
validation_scores = [] 
for fold in range(k): 
    validation_data = data[num_validation_samples * fold: 
     num_validation_samples * (fold + 1)] 
    training_data = data[:num_validation_samples * fold] + 
     data[num_validation_samples * (fold + 1):] 
    model = get_model() 
    model.train(training_data) 
    validation_score = model.evaluate(validation_data) 
    validation_scores.append(validation_score) 
 
validation_score = np.average(validation_scores) 
 
model = get_model() 
model.train(data) 
test_score = model.evaluate(test_data)
1
2
3
4
5
1
2
x -= x.mean(axis=0) 
x /= x.std(axis=0)
1

Figure 4.4. Effect of model capacity on validation loss: trying a smaller model
Listing 4.3. Original model
1
2
3
4
5
6
7
from keras import models 
from keras import layers 
 
model = models.Sequential() 
model.add(layers.Dense(16, activation='relu', input_shape=(10000,))) 
model.add(layers.Dense(16, activation='relu')) 
model.add(layers.Dense(1, activation='sigmoid'))
Listing 4.4. Version of the model with lower capacity
1
2
3
4
model = models.Sequential() 
model.add(layers.Dense(4, activation='relu', input_shape=(10000,))) 
model.add(layers.Dense(4, activation='relu')) 
model.add(layers.Dense(1, activation='sigmoid'))

Figure 4.5. Effect of model capacity on validation loss: trying a bigger model
Figure 4.6. Effect of model capacity on training loss: trying a bigger model
Listing 4.5. Version of the model with higher capacity
1
2
3
4
model = models.Sequential() 
model.add(layers.Dense(512, activation='relu', input_shape=(10000,))) 
model.add(layers.Dense(512, activation='relu')) 
model.add(layers.Dense(1, activation='sigmoid'))

Figure 4.7. Effect of L2 weight regularization on validation loss
Listing 4.6. Adding L2 weight regularization to the model
1
2
3
4
5
6
7
8
from keras import regularizers 
 
model = models.Sequential() 
model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), 
                       activation='relu', input_shape=(10000,))) 
model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), 
                       activation='relu')) 
model.add(layers.Dense(1, activation='sigmoid'))
Listing 4.7. Different weight regularizers available in Keras
1
2
3
4
from keras import regularizers 
 
regularizers.l1(0.001) 
1

Figure 4.8. Dropout applied to an activation matrix at training time, with rescaling
happening during training. At test time, the activation matrix is unchanged.
5  
regularizers.l1_l2(l1=0.001, l2=0.001)
2
1 layer_output *= np.random.randint(0, high=2, size=layer_output.shape)
1
1 layer_output *= 0.5
1
1
2
layer_output *= np.random.randint(0, high=2, size=layer_output.shape) 
layer_output /= 0.5
1
2
1 model.add(layers.Dropout(0.5))
Listing 4.8. Adding dropout to the IMDB network
1
2
3
4
5
6
model = models.Sequential() 
model.add(layers.Dense(16, activation='relu', input_shape=(10000,))) 
model.add(layers.Dropout(0.5)) 
model.add(layers.Dense(16, activation='relu')) 
model.add(layers.Dropout(0.5)) 
model.add(layers.Dense(1, activation='sigmoid'))

Figure 4.9. Effect of dropout on validation loss
Table 4.1. Choosing the right last-layer activation and loss function for your model
(view table ×gure)
Problem type
Last-layer activation
Loss function
Binary classication
sigmoid
binary_crossentropy
Multiclass, single-label
classication
softmax
categorical_crossentropy
Multiclass, multilabel
classication
sigmoid
binary_crossentropy
Regression to arbitrary
values
None
mse
Regression to values
between 0 and 1
sigmoid
mse or binary_crossentropy

CHAPTER 5
Listing 5.1. Instantiating a small convnet
1
2
3
4
5
6
7
8
9
from keras import layers 
from keras import models 
 
model = models.Sequential() 
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) 
model.add(layers.MaxPooling2D((2, 2))) 
model.add(layers.Conv2D(64, (3, 3), activation='relu')) 
model.add(layers.MaxPooling2D((2, 2))) 
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
>>> model.summary() 
________________________________________________________________ 
Layer (type)                     Output Shape          Param # 
================================================================ 
conv2d_1 (Conv2D)                (None, 26, 26, 32)    320 
________________________________________________________________ 
maxpooling2d_1 (MaxPooling2D)    (None, 13, 13, 32)    0 
________________________________________________________________ 
conv2d_2 (Conv2D)                (None, 11, 11, 64)    18496 
________________________________________________________________ 
maxpooling2d_2 (MaxPooling2D)    (None, 5, 5, 64)      0 
________________________________________________________________ 
conv2d_3 (Conv2D)                (None, 3, 3, 64)      36928 
================================================================ 
Total params: 55,744 
Trainable params: 55,744 
Non-trainable params: 0
Listing 5.2. Adding a classi×er on top of the convnet
1
2
3
model.add(layers.Flatten()) 
model.add(layers.Dense(64, activation='relu')) 
model.add(layers.Dense(10, activation='softmax'))
1
2
3
4
5
>>> model.summary() 
Layer (type)                     Output Shape          Param # 
================================================================ 
conv2d_1 (Conv2D)                (None, 26, 26, 32)    320 
________________________________________________________________ 

Figure 5.1. Images can be broken into local patterns such as edges, textures, and so on.
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
maxpooling2d_1 (MaxPooling2D)    (None, 13, 13, 32)    0 
________________________________________________________________ 
conv2d_2 (Conv2D)                (None, 11, 11, 64)    18496 
________________________________________________________________ 
maxpooling2d_2 (MaxPooling2D)    (None, 5, 5, 64)      0 
________________________________________________________________ 
conv2d_3 (Conv2D)                (None, 3, 3, 64)      36928 
________________________________________________________________ 
flatten_1 (Flatten)              (None, 576)           0 
________________________________________________________________ 
dense_1 (Dense)                  (None, 64)            36928 
________________________________________________________________ 
dense_2 (Dense)                  (None, 10)            650 
================================================================ 
Total params: 93,322 
Trainable params: 93,322 
Non-trainable params: 0
Listing 5.3. Training the convnet on MNIST images
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
from keras.datasets import mnist 
from keras.utils import to_categorical 
 
(train_images, train_labels), (test_images, test_labels) = mnist.load_data() 
train_images = train_images.reshape((60000, 28, 28, 1)) 
train_images = train_images.astype('float32') / 255 
 
test_images = test_images.reshape((10000, 28, 28, 1)) 
test_images = test_images.astype('float32') / 255 
 
train_labels = to_categorical(train_labels) 
test_labels = to_categorical(test_labels) 
 
model.compile(optimizer='rmsprop', 
              loss='categorical_crossentropy', 
              metrics=['accuracy']) 
model.fit(train_images, train_labels, epochs=5, batch_size=64)
1
2
3
>>> test_loss, test_acc = model.evaluate(test_images, test_labels) 
>>> test_acc 
0.99080000000000001

Figure 5.2. The visual world forms a spatial hierarchy of visual modules: hyperlocal
edges combine into local objects such as eyes or ears, which combine into high-level
concepts such as “cat.”
Figure 5.3. The concept of a response map: a 2D map of the presence of a pattern at
different locations in an input

Figure 5.4. How convolution works
Figure 5.5. Valid locations of 3 × 3 patches in a 5 × 5 input feature map
Figure 5.6. Padding a 5 × 5 input in order to be able to extract 25 3 × 3 patches

Figure 5.7. 3 × 3 convolution patches with 2 × 2 strides
1
2
3
4
5
model_no_max_pool = models.Sequential() 
model_no_max_pool.add(layers.Conv2D(32, (3, 3), activation='relu', 
                      input_shape=(28, 28, 1))) 
model_no_max_pool.add(layers.Conv2D(64, (3, 3), activation='relu')) 
model_no_max_pool.add(layers.Conv2D(64, (3, 3), activation='relu'))
1
2
3
4
5
6
7
8
9
10
11
12
13
>>> model_no_max_pool.summary() 
Layer (type)                     Output Shape          Param # 
================================================================ 
conv2d_4 (Conv2D)                (None, 26, 26, 32)    320 
________________________________________________________________ 
conv2d_5 (Conv2D)                (None, 24, 24, 64)    18496 
________________________________________________________________ 
conv2d_6 (Conv2D)                (None, 22, 22, 64)    36928 
================================================================ 
Total params: 55,744 
Trainable params: 55,744 
Non-trainable params: 0

Figure 5.8. Samples from the Dogs vs. Cats dataset. Sizes weren’t modi×ed: the samples
are heterogeneous in size, appearance, and so on.
Listing 5.4. Copying images to training, validation, and test directories
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
import os, shutil 
 
original_dataset_dir = '/Users/fchollet/Downloads/kaggle_original_data' 
 
base_dir = '/Users/fchollet/Downloads/cats_and_dogs_small' 
os.mkdir(base_dir) 
 
train_dir = os.path.join(base_dir, 'train') 
os.mkdir(train_dir) 
validation_dir = os.path.join(base_dir, 'validation') 
os.mkdir(validation_dir) 
test_dir = os.path.join(base_dir, 'test') 
os.mkdir(test_dir) 
 
train_cats_dir = os.path.join(train_dir, 'cats') 
os.mkdir(train_cats_dir) 
 
train_dogs_dir = os.path.join(train_dir, 'dogs') 
os.mkdir(train_dogs_dir) 
 
validation_cats_dir = os.path.join(validation_dir, 'cats') 
os.mkdir(validation_cats_dir) 
 
validation_dogs_dir = os.path.join(validation_dir, 'dogs') 
os.mkdir(validation_dogs_dir) 
 
test_cats_dir = os.path.join(test_dir, 'cats') 
os.mkdir(test_cats_dir) 
 
test_dogs_dir = os.path.join(test_dir, 'dogs') 
os.mkdir(test_dogs_dir) 
 
fnames = ['cat.{}.jpg'.format(i) for i in range(1000)] 
for fname in fnames: 
    src = os.path.join(original_dataset_dir, fname) 
    dst = os.path.join(train_cats_dir, fname) 
    shutil.copyfile(src, dst) 
 
1
2
3
4
5
6
7
8
9
10

39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)] 
for fname in fnames: 
    src = os.path.join(original_dataset_dir, fname) 
    dst = os.path.join(validation_cats_dir, fname) 
    shutil.copyfile(src, dst) 
 
fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)] 
for fname in fnames: 
    src = os.path.join(original_dataset_dir, fname) 
    dst = os.path.join(test_cats_dir, fname) 
    shutil.copyfile(src, dst) 
 
fnames = ['dog.{}.jpg'.format(i) for i in range(1000)] 
for fname in fnames: 
    src = os.path.join(original_dataset_dir, fname) 
    dst = os.path.join(train_dogs_dir, fname) 
    shutil.copyfile(src, dst) 
fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)] 
for fname in fnames: 
    src = os.path.join(original_dataset_dir, fname) 
    dst = os.path.join(validation_dogs_dir, fname) 
    shutil.copyfile(src, dst) 
 
fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)] 
for fname in fnames: 
    src = os.path.join(original_dataset_dir, fname) 
    dst = os.path.join(test_dogs_dir, fname) 
    shutil.copyfile(src, dst)
11
12
13
14
15
1
2
3
4
5
6
7
8
9
10
11
12
>>> print('total training cat images:', len(os.listdir(train_cats_dir))) 
total training cat images: 1000 
>>> print('total training dog images:', len(os.listdir(train_dogs_dir))) 
total training dog images: 1000 
>>> print('total validation cat images:', len(os.listdir(validation_cats_dir))) 
total validation cat images: 500 
>>> print('total validation dog images:', len(os.listdir(validation_dogs_dir))) 
total validation dog images: 500 
>>> print('total test cat images:', len(os.listdir(test_cats_dir))) 
total test cat images: 500 
>>> print('total test dog images:', len(os.listdir(test_dogs_dir))) 
total test dog images: 500
Listing 5.5. Instantiating a small convnet for dogs vs. cats classi×cation
1
2
3
4
5
6
7
8
9
10
11
12
13
from keras import layers 
from keras import models 
 
model = models.Sequential() 
model.add(layers.Conv2D(32, (3, 3), activation='relu', 
                        input_shape=(150, 150, 3))) 
model.add(layers.MaxPooling2D((2, 2))) 
model.add(layers.Conv2D(64, (3, 3), activation='relu')) 
model.add(layers.MaxPooling2D((2, 2))) 
model.add(layers.Conv2D(128, (3, 3), activation='relu')) 
model.add(layers.MaxPooling2D((2, 2))) 
model.add(layers.Conv2D(128, (3, 3), activation='relu')) 
model.add(layers.MaxPooling2D((2, 2))) 

14
15
16
model.add(layers.Flatten()) 
model.add(layers.Dense(512, activation='relu')) 
model.add(layers.Dense(1, activation='sigmoid'))
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
>>> model.summary() 
Layer (type)                     Output Shape          Param # 
================================================================ 
conv2d_1 (Conv2D)                (None, 148, 148, 32)  896 
________________________________________________________________ 
maxpooling2d_1 (MaxPooling2D)    (None, 74, 74, 32)    0 
________________________________________________________________ 
conv2d_2 (Conv2D)                (None, 72, 72, 64)    18496 
________________________________________________________________ 
maxpooling2d_2 (MaxPooling2D)    (None, 36, 36, 64)    0 
________________________________________________________________ 
conv2d_3 (Conv2D)                (None, 34, 34, 128)   73856 
________________________________________________________________ 
maxpooling2d_3 (MaxPooling2D)    (None, 17, 17, 128)   0 
________________________________________________________________ 
conv2d_4 (Conv2D)                (None, 15, 15, 128)   147584 
________________________________________________________________ 
maxpooling2d_4 (MaxPooling2D)    (None, 7, 7, 128)     0 
________________________________________________________________ 
flatten_1 (Flatten)              (None, 6272)          0 
________________________________________________________________ 
dense_1 (Dense)                  (None, 512)           3211776 
________________________________________________________________ 
dense_2 (Dense)                  (None, 1)             513 
================================================================ 
Total params: 3,453,121 
Trainable params: 3,453,121 
Non-trainable params: 0
Listing 5.6. Con×guring the model for training
1
2
3
4
5
from keras import optimizers 
 
model.compile(loss='binary_crossentropy', 
              optimizer=optimizers.RMSprop(lr=1e-4), 
              metrics=['acc'])
Listing 5.7. Using ImageDataGenerator to read images from directories
1
2
3
4
5
6
7
from keras.preprocessing.image import ImageDataGenerator 
 
train_datagen = ImageDataGenerator(rescale=1./255) 
test_datagen = ImageDataGenerator(rescale=1./255) 
 
train_generator = train_datagen.flow_from_directory( 
        train_dir, 
1
2

UNDERSTANDING PYTHON GENERATORS
A Python generator is an object that acts as an iterator: it’s an object
you can use with the for  ...  in  operator. Generators are built
using the yield  operator.
Here is an example of a generator that yields integers:
It prints this:
8
9
10
11
12
13
14
15
16
        target_size=(150, 150) 
        batch_size=20, 
        class_mode='binary') 
 
validation_generator = test_datagen.flow_from_directory( 
        validation_dir, 
        target_size=(150, 150), 
        batch_size=20, 
        class_mode='binary')
3
4
1
2
3
4
5
6
7
8
9
10
def generator(): 
    i = 0 
    while True: 
        i += 1 
        yield i 
 
for item in generator(): 
    print(item) 
    if item > 4: 
        break
1 1 2 3 4 5
1
2
3
4
5
6
>>> for data_batch, labels_batch in train_generator: 
>>>     print('data batch shape:', data_batch.shape) 
>>>     print('labels batch shape:', labels_batch.shape) 
>>>     break 
data batch shape: (20, 150, 150, 3) 
labels batch shape: (20,)

Figure 5.9. Training and validation accuracy
Figure 5.10. Training and validation loss
Listing 5.8. Fitting the model using a batch generator
1
2
3
4
5
6
history = model.fit_generator( 
      train_generator, 
      steps_per_epoch=100, 
      epochs=30, 
      validation_data=validation_generator, 
      validation_steps=50)
Listing 5.9. Saving the model
1 model.save('cats_and_dogs_small_1.h5')

Listing 5.10. Displaying curves of loss and accuracy during training
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
import matplotlib.pyplot as plt 
 
acc = history.history['acc'] 
val_acc = history.history['val_acc'] 
loss = history.history['loss'] 
val_loss = history.history['val_loss'] 
 
epochs = range(1, len(acc) + 1) 
 
plt.plot(epochs, acc, 'bo', label='Training acc') 
plt.plot(epochs, val_acc, 'b', label='Validation acc') 
plt.title('Training and validation accuracy') 
plt.legend() 
 
plt.figure() 
 
plt.plot(epochs, loss, 'bo', label='Training loss') 
plt.plot(epochs, val_loss, 'b', label='Validation loss') 
plt.title('Training and validation loss') 
plt.legend() 
 
plt.show()
Listing 5.11. Setting up a data augmentation con×guration via ImageDataGenerator
1
2
3
4
5
6
7
8
datagen = ImageDataGenerator( 
      rotation_range=40, 
      width_shift_range=0.2, 
      height_shift_range=0.2, 
      shear_range=0.2, 
      zoom_range=0.2, 
      horizontal_flip=True, 
      fill_mode='nearest')

Figure 5.11. Generation of cat pictures via random data augmentation
Listing 5.12. Displaying some randomly augmented training images
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
from keras.preprocessing import image 
 
fnames = [os.path.join(train_cats_dir, fname) for 
     fname in os.listdir(train_cats_dir)] 
 
img_path = fnames[3] 
 
img = image.load_img(img_path, target_size=(150, 150)) 
 
x = image.img_to_array(img) 
x = x.reshape((1,) + x.shape) 
 
i = 0 
for batch in datagen.flow(x, batch_size=1): 
    plt.figure(i) 
    imgplot = plt.imshow(image.array_to_img(batch[0])) 
    i += 1 
    if i % 4 == 0: 
        break 
 
plt.show()
1
2
3
4
5
6
Listing 5.13. De×ning a new convnet that includes dropout

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
model = models.Sequential() 
model.add(layers.Conv2D(32, (3, 3), activation='relu', 
                        input_shape=(150, 150, 3))) 
model.add(layers.MaxPooling2D((2, 2))) 
model.add(layers.Conv2D(64, (3, 3), activation='relu')) 
model.add(layers.MaxPooling2D((2, 2))) 
model.add(layers.Conv2D(128, (3, 3), activation='relu')) 
model.add(layers.MaxPooling2D((2, 2))) 
model.add(layers.Conv2D(128, (3, 3), activation='relu')) 
model.add(layers.MaxPooling2D((2, 2))) 
model.add(layers.Flatten()) 
model.add(layers.Dropout(0.5)) 
model.add(layers.Dense(512, activation='relu')) 
model.add(layers.Dense(1, activation='sigmoid')) 
 
model.compile(loss='binary_crossentropy', 
              optimizer=optimizers.RMSprop(lr=1e-4), 
              metrics=['acc'])
Listing 5.14. Training the convnet using data-augmentation generators
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
train_datagen = ImageDataGenerator( 
    rescale=1./255, 
    rotation_range=40, 
    width_shift_range=0.2, 
    height_shift_range=0.2, 
    shear_range=0.2, 
    zoom_range=0.2, 
    horizontal_flip=True,) 
 
test_datagen = ImageDataGenerator(rescale=1./255) 
 
train_generator = train_datagen.flow_from_directory( 
        train_dir, 
        target_size=(150, 150), 
        batch_size=32, 
        class_mode='binary') 
 
validation_generator = test_datagen.flow_from_directory( 
        validation_dir, 
        target_size=(150, 150), 
        batch_size=32, 
        class_mode='binary') 
 
history = model.fit_generator( 
      train_generator, 
      steps_per_epoch=100, 
      epochs=100, 
      validation_data=validation_generator, 
      validation_steps=50)
1
2
3
4
Listing 5.15. Saving the model
1 model.save('cats_and_dogs_small_2.h5')

Figure 5.12. Training and validation accuracy with data augmentation
Figure 5.13. Training and validation loss with data augmentation
Figure 5.14. Swapping classi×ers while keeping the same convolutional base

Listing 5.16. Instantiating the VGG16 convolutional base
1
2
3
4
5
from keras.applications import VGG16 
 
conv_base = VGG16(weights='imagenet', 
                  include_top=False, 
                  input_shape=(150, 150, 3))
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
>>> conv_base.summary() 
Layer (type)                     Output Shape          Param # 
================================================================ 
input_1 (InputLayer)             (None, 150, 150, 3)   0 
________________________________________________________________ 
block1_conv1 (Convolution2D)     (None, 150, 150, 64)  1792 
________________________________________________________________ 
block1_conv2 (Convolution2D)     (None, 150, 150, 64)  36928 
________________________________________________________________ 
block1_pool (MaxPooling2D)       (None, 75, 75, 64)    0 
________________________________________________________________ 
block2_conv1 (Convolution2D)     (None, 75, 75, 128)   73856 
________________________________________________________________ 
block2_conv2 (Convolution2D)     (None, 75, 75, 128)   147584 
________________________________________________________________ 
block2_pool (MaxPooling2D)       (None, 37, 37, 128)   0 
________________________________________________________________ 
block3_conv1 (Convolution2D)     (None, 37, 37, 256)   295168 
________________________________________________________________ 
block3_conv2 (Convolution2D)     (None, 37, 37, 256)   590080 
________________________________________________________________ 
block3_conv3 (Convolution2D)     (None, 37, 37, 256)   590080 
________________________________________________________________ 
block3_pool (MaxPooling2D)       (None, 18, 18, 256)   0 
________________________________________________________________ 
block4_conv1 (Convolution2D)     (None, 18, 18, 512)   1180160 
________________________________________________________________ 
block4_conv2 (Convolution2D)     (None, 18, 18, 512)   2359808 

30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
________________________________________________________________ 
block4_conv3 (Convolution2D)     (None, 18, 18, 512)   2359808 
________________________________________________________________ 
block4_pool (MaxPooling2D)       (None, 9, 9, 512)     0 
________________________________________________________________ 
block5_conv1 (Convolution2D)     (None, 9, 9, 512)     2359808 
________________________________________________________________ 
block5_conv2 (Convolution2D)     (None, 9, 9, 512)     2359808 
________________________________________________________________ 
block5_conv3 (Convolution2D)     (None, 9, 9, 512)     2359808 
________________________________________________________________ 
block5_pool (MaxPooling2D)       (None, 4, 4, 512)     0 
================================================================ 
Total params: 14,714,688 
Trainable params: 14,714,688 
Non-trainable params: 0
Listing 5.17. Extracting features using the pretrained convolutional base
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
import os 
import numpy as np 
from keras.preprocessing.image import ImageDataGenerator 
 
base_dir = '/Users/fchollet/Downloads/cats_and_dogs_small' 
train_dir = os.path.join(base_dir, 'train') 
validation_dir = os.path.join(base_dir, 'validation') 
test_dir = os.path.join(base_dir, 'test') 
 
datagen = ImageDataGenerator(rescale=1./255) 
batch_size = 20 
 
def extract_features(directory, sample_count): 
    features = np.zeros(shape=(sample_count, 4, 4, 512)) 
    labels = np.zeros(shape=(sample_count)) 
    generator = datagen.flow_from_directory( 
        directory, 
        target_size=(150, 150), 
        batch_size=batch_size, 
        class_mode='binary') 
    i = 0 
    for inputs_batch, labels_batch in generator: 
        features_batch = conv_base.predict(inputs_batch) 
        features[i * batch_size : (i + 1) * batch_size] = features_batch 
        labels[i * batch_size : (i + 1) * batch_size] = labels_batch 
        i += 1 
        if i * batch_size >= sample_count: 
            break 
    return features, labels 
 
train_features, train_labels = extract_features(train_dir, 2000) 
validation_features, validation_labels = extract_features(validation_dir, 1000) 
test_features, test_labels = extract_features(test_dir, 1000)
1
1
2
3
train_features = np.reshape(train_features, (2000, 4 * 4 * 512)) 
validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512)) 
test_features = np.reshape(test_features, (1000, 4 * 4 * 512))

Figure 5.15. Training and validation accuracy for simple feature extraction
Figure 5.16. Training and validation loss for simple feature extraction
Listing 5.18. De×ning and training the densely connected classi×er
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
from keras import models 
from keras import layers 
from keras import optimizers 
 
model = models.Sequential() 
model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512)) 
model.add(layers.Dropout(0.5)) 
model.add(layers.Dense(1, activation='sigmoid')) 
 
model.compile(optimizer=optimizers.RMSprop(lr=2e-5), 
              loss='binary_crossentropy', 
              metrics=['acc']) 
 
history = model.fit(train_features, train_labels, 
                    epochs=30, 
                    batch_size=20, 
                    validation_data=(validation_features, validation_labels))

Listing 5.19. Plotting the results
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
import matplotlib.pyplot as plt 
 
acc = history.history['acc'] 
val_acc = history.history['val_acc'] 
loss = history.history['loss'] 
val_loss = history.history['val_loss'] 
 
epochs = range(1, len(acc) + 1) 
 
plt.plot(epochs, acc, 'bo', label='Training acc') 
plt.plot(epochs, val_acc, 'b', label='Validation acc') 
plt.title('Training and validation accuracy') 
plt.legend() 
 
plt.figure() 
 
plt.plot(epochs, loss, 'bo', label='Training loss') 
plt.plot(epochs, val_loss, 'b', label='Validation loss') 
plt.title('Training and validation loss') 
plt.legend() 
 
plt.show()
Listing 5.20. Adding a densely connected classi×er on top of the convolutional base
1
2
3
4
5
6
7
8
from keras import models 
from keras import layers 
 
model = models.Sequential() 
model.add(conv_base) 
model.add(layers.Flatten()) 
model.add(layers.Dense(256, activation='relu')) 
model.add(layers.Dense(1, activation='sigmoid'))

1
2
3
4
5
6
7
8
9
10
11
12
13
14
>>> model.summary() 
Layer (type)                     Output Shape          Param # 
================================================================ 
vgg16 (Model)                    (None, 4, 4, 512)     14714688 
________________________________________________________________ 
flatten_1 (Flatten)              (None, 8192)          0 
________________________________________________________________ 
dense_1 (Dense)                  (None, 256)           2097408 
________________________________________________________________ 
dense_2 (Dense)                  (None, 1)             257 
================================================================ 
Total params: 16,812,353 
Trainable params: 16,812,353 
Non-trainable params: 0
1
2
3
4
5
6
7
>>> print('This is the number of trainable weights ' 
         'before freezing the conv base:', len(model.trainable_weights)) 
This is the number of trainable weights before freezing the conv base: 30 
>>> conv_base.trainable = False 
>>> print('This is the number of trainable weights ' 
          'after freezing the conv base:', len(model.trainable_weights)) 
This is the number of trainable weights after freezing the conv base: 4
Listing 5.21. Training the model end to end with a frozen convolutional base
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
from keras.preprocessing.image import ImageDataGenerator 
from keras import optimizers 
 
train_datagen = ImageDataGenerator( 
      rescale=1./255, 
      rotation_range=40, 
      width_shift_range=0.2, 
      height_shift_range=0.2, 
      shear_range=0.2, 
      zoom_range=0.2, 
      horizontal_flip=True, 
      fill_mode='nearest') 
 
test_datagen = ImageDataGenerator(rescale=1./255) 
 
train_generator = train_datagen.flow_from_directory( 
        train_dir, 
        target_size=(150, 150), 
        batch_size=20, 
        class_mode='binary') 
 
validation_generator = test_datagen.flow_from_directory( 
        validation_dir, 
        target_size=(150, 150), 
        batch_size=20, 
        class_mode='binary') 
 
model.compile(loss='binary_crossentropy', 
              optimizer=optimizers.RMSprop(lr=2e-5), 
              metrics=['acc']) 
 
1
2
3
4

Figure 5.17. Training and validation accuracy for feature extraction with data
augmentation
Figure 5.18. Training and validation loss for feature extraction with data augmentation
Figure 5.19. Fine-tuning the last convolutional block of the VGG16 network
32
33
34
35
36
37
history = model.fit_generator( 
      train_generator, 
      steps_per_epoch=100, 
      epochs=30, 
      validation_data=validation_generator, 
      validation_steps=50)

1
2
3
4
5
6
7
8
9
10
>>> conv_base.summary() 
Layer (type)                     Output Shape          Param # 
================================================================ 
input_1 (InputLayer)             (None, 150, 150, 3)   0 
________________________________________________________________ 
block1_conv1 (Convolution2D)     (None, 150, 150, 64)  1792 
________________________________________________________________ 
block1_conv2 (Convolution2D)     (None, 150, 150, 64)  36928 
________________________________________________________________ 
block1_pool (MaxPooling2D)       (None, 75, 75, 64)    0 

11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
________________________________________________________________ 
block2_conv1 (Convolution2D)     (None, 75, 75, 128)   73856 
________________________________________________________________ 
block2_conv2 (Convolution2D)     (None, 75, 75, 128)   147584 
________________________________________________________________ 
block2_pool (MaxPooling2D)       (None, 37, 37, 128)   0 
________________________________________________________________ 
block3_conv1 (Convolution2D)     (None, 37, 37, 256)   295168 
________________________________________________________________ 
block3_conv2 (Convolution2D)     (None, 37, 37, 256)   590080 
________________________________________________________________ 
block3_conv3 (Convolution2D)     (None, 37, 37, 256)   590080 
________________________________________________________________ 
block3_pool (MaxPooling2D)       (None, 18, 18, 256)   0 
________________________________________________________________ 
block4_conv1 (Convolution2D)     (None, 18, 18, 512)   1180160 
________________________________________________________________ 
block4_conv2 (Convolution2D)     (None, 18, 18, 512)   2359808 
________________________________________________________________ 
block4_conv3 (Convolution2D)     (None, 18, 18, 512)   2359808 
________________________________________________________________ 
block4_pool (MaxPooling2D)       (None, 9, 9, 512)     0 
________________________________________________________________ 
block5_conv1 (Convolution2D)     (None, 9, 9, 512)     2359808 
________________________________________________________________ 
block5_conv2 (Convolution2D)     (None, 9, 9, 512)     2359808 
________________________________________________________________ 
block5_conv3 (Convolution2D)     (None, 9, 9, 512)     2359808 
________________________________________________________________ 
block5_pool (MaxPooling2D)       (None, 4, 4, 512)     0 
================================================================ 
Total params: 14714688
Listing 5.22. Freezing all layers up to a speci×c one
1
2
3
4
5
6
7
8
9
10
conv_base.trainable = True 
 
set_trainable = False 
for layer in conv_base.layers: 
    if layer.name == 'block5_conv1': 
        set_trainable = True 
    if set_trainable: 
        layer.trainable = True 
    else: 
        layer.trainable = False
Listing 5.23. Fine-tuning the model
1
2
3
4
5
6
7
8
model.compile(loss='binary_crossentropy', 
              optimizer=optimizers.RMSprop(lr=1e-5), 
              metrics=['acc']) 
 
history = model.fit_generator( 
      train_generator, 
      steps_per_epoch=100, 
      epochs=100, 

Figure 5.20. Training and validation accuracy for ×ne-tuning
Figure 5.21. Training and validation loss for ×ne-tuning
Figure 5.22. Smoothed curves for training and validation accuracy for ×ne-tuning
9
10
      validation_data=validation_generator, 
      validation_steps=50)

Figure 5.23. Smoothed curves for training and validation loss for ×ne-tuning
Listing 5.24. Smoothing the plots
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
def smooth_curve(points, factor=0.8): 
  smoothed_points = [] 
  for point in points: 
    if smoothed_points: 
      previous = smoothed_points[-1] 
      smoothed_points.append(previous * factor + point * (1 - factor)) 
    else: 
      smoothed_points.append(point) 
  return smoothed_points 
 
plt.plot(epochs, 
         smooth_curve(acc), 'bo', label='Smoothed training acc') 
plt.plot(epochs, 
         smooth_curve(val_acc), 'b', label='Smoothed validation acc') 
plt.title('Training and validation accuracy') 
plt.legend() 
 
plt.figure() 
 
plt.plot(epochs, 
         smooth_curve(loss), 'bo', label='Smoothed training loss') 

22
23
24
25
26
27
plt.plot(epochs, 
         smooth_curve(val_loss), 'b', label='Smoothed validation loss') 
plt.title('Training and validation loss') 
plt.legend() 
 
plt.show()
1
2
3
4
5
6
7
8
test_generator = test_datagen.flow_from_directory( 
        test_dir, 
        target_size=(150, 150), 
        batch_size=20, 
        class_mode='binary') 
 
test_loss, test_acc = model.evaluate_generator(test_generator, steps=50) 
print('test acc:', test_acc)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
>>> from keras.models import load_model 
>>> model = load_model('cats_and_dogs_small_2.h5') 
>>> model.summary()  <1> As a reminder. 
________________________________________________________________ 
Layer (type)                     Output Shape          Param # 
================================================================ 
conv2d_5 (Conv2D)                (None, 148, 148, 32)  896 
________________________________________________________________ 
maxpooling2d_5 (MaxPooling2D)    (None, 74, 74, 32)    0 
________________________________________________________________ 
conv2d_6 (Conv2D)                (None, 72, 72, 64)    18496 
________________________________________________________________ 
maxpooling2d_6 (MaxPooling2D)    (None, 36, 36, 64)    0 
________________________________________________________________ 
conv2d_7 (Conv2D)                (None, 34, 34, 128)   73856 
________________________________________________________________ 
maxpooling2d_7 (MaxPooling2D)    (None, 17, 17, 128)   0 
________________________________________________________________ 
conv2d_8 (Conv2D)                (None, 15, 15, 128)   147584 
________________________________________________________________ 
maxpooling2d_8 (MaxPooling2D)    (None, 7, 7, 128)     0 
________________________________________________________________ 
flatten_2 (Flatten)              (None, 6272)          0 
________________________________________________________________ 
dropout_1 (Dropout)              (None, 6272)          0 
________________________________________________________________ 
dense_3 (Dense)                  (None, 512)           3211776 
________________________________________________________________ 
dense_4 (Dense)                  (None, 1)             513 
================================================================ 
Total params: 3,453,121 
Trainable params: 3,453,121 
Non-trainable params: 0

Figure 5.24. The test cat picture
Listing 5.25. Preprocessing a single image
1
2
3
4
5
6
7
8
9
10
11
12
img_path = '/Users/fchollet/Downloads/cats_and_dogs_small/test/cats/cat.1700.jpg' 
 
from keras.preprocessing import image 
import numpy as np 
 
img = image.load_img(img_path, target_size=(150, 150)) 
img_tensor = image.img_to_array(img) 
img_tensor = np.expand_dims(img_tensor, axis=0) 
img_tensor /= 255. 
 
<1> Its shape is (1, 150, 150, 3) 
print(img_tensor.shape)
1
2
Listing 5.26. Displaying the test picture
1
2
3
4
import matplotlib.pyplot as plt 
 
plt.imshow(img_tensor[0]) 
plt.show()
Listing 5.27. Instantiating a model from an input tensor and a list of output tensors
1
2
3
4
from keras import models 
 
layer_outputs = [layer.output for layer in model.layers[:8]] 
activation_model = models.Model(inputs=model.input, outputs=layer_outputs)
1
2

Figure 5.25. Fourth channel of the activation of the ×rst layer on the test cat picture
Figure 5.26. Seventh channel of the activation of the ×rst layer on the test cat picture
Listing 5.28. Running the model in predict mode
1 activations = activation_model.predict(img_tensor)
1
1
2
3
>>> first_layer_activation = activations[0] 
>>> print(first_layer_activation.shape) 
(1, 148, 148, 32)
Listing 5.29. Visualizing the fourth channel
1
2
3
import matplotlib.pyplot as plt 
 
plt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')

Figure 5.27. Every channel of every layer activation on the test cat picture
Listing 5.30. Visualizing the seventh channel
1 plt.matshow(first_layer_activation[0, :, :, 7], cmap='viridis')

Listing 5.31. Visualizing every channel in every intermediate activation
1
2
3
4
5
6
7
8
9
10
layer_names = [] 
for layer in model.layers[:8]: 
    layer_names.append(layer.name) 
 
images_per_row = 16 
 
for layer_name, layer_activation in zip(layer_names, activations): 
    n_features = layer_activation.shape[-1] 
 
    size = layer_activation.shape[1] 
1
2
3
4

Figure 5.28. Left: attempts to draw a bicycle from memory. Right: what a schematic
bicycle should look like.
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
 
    n_cols = n_features // images_per_row 
    display_grid = np.zeros((size * n_cols, images_per_row * size)) 
 
    for col in range(n_cols): 
        for row in range(images_per_row): 
            channel_image = layer_activation[0, 
                                             :, :, 
                                             col * images_per_row + row] 
            channel_image -= channel_image.mean() 
            channel_image /= channel_image.std() 
            channel_image *= 64 
            channel_image += 128 
            channel_image = np.clip(channel_image, 0, 255).astype('uint8') 
            display_grid[col * size : (col + 1) * size, 
                         row * size : (row + 1) * size] = channel_image 
 
    scale = 1. / size 
    plt.figure(figsize=(scale * display_grid.shape[1], 
                        scale * display_grid.shape[0])) 
    plt.title(layer_name) 
    plt.grid(False) 
    plt.imshow(display_grid, aspect='auto', cmap='viridis')
5
6
7
8
Listing 5.32. De×ning the loss tensor for ×lter visualization
1
2
3
4
5
6
7
8
9
10
11
from keras.applications import VGG16 
from keras import backend as K 
 
model = VGG16(weights='imagenet', 
              include_top=False) 
 
layer_name = 'block3_conv1' 
filter_index = 0 
 
layer_output = model.get_layer(layer_name).output 
loss = K.mean(layer_output[:, :, :, filter_index])

Listing 5.33. Obtaining the gradient of the loss with regard to the input
1 grads = K.gradients(loss, model.input)[0]
1
Listing 5.34. Gradient-normalization trick
1 grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)
1
Listing 5.35. Fetching Numpy output values given Numpy input values
1
2
3
4
iterate = K.function([model.input], [loss, grads]) 
 
import numpy as np 
loss_value, grads_value = iterate([np.zeros((1, 150, 150, 3))])
Listing 5.36. Loss maximization via stochastic gradient descent
1
2
3
4
5
6
7
input_img_data = np.random.random((1, 150, 150, 3)) * 20 + 128. 
 
step = 1. 
for i in range(40): 
    loss_value, grads_value = iterate([input_img_data]) 
 
    input_img_data += grads_value * step
1
2
3
4
5
Listing 5.37. Utility function to convert a tensor into a valid image
1
2
3
4
5
6
7
8
9
10
11
def deprocess_image(x): 
    x -= x.mean() 
    x /= (x.std() + 1e-5) 
    x *= 0.1 
 
    x += 0.5 
    x = np.clip(x, 0, 1) 
 
    x *= 255 
    x = np.clip(x, 0, 255).astype('uint8') 
    return x
1
2
3

Figure 5.29. Pattern that the zeroth channel in layer block3_conv1  responds to
maximally
Figure 5.30. Filter patterns for layer block1_conv1
Listing 5.38. Function to generate ×lter visualizations
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
def generate_pattern(layer_name, filter_index, size=150): 
    layer_output = model.get_layer(layer_name).output 
    loss = K.mean(layer_output[:, :, :, filter_index]) 
 
    grads = K.gradients(loss, model.input)[0] 
 
    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5) 
 
    iterate = K.function([model.input], [loss, grads]) 
 
    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128. 
 
    step = 1. 
    for i in range(40): 
        loss_value, grads_value = iterate([input_img_data]) 
        input_img_data += grads_value * step 
 
    img = input_img_data[0] 
    return deprocess_image(img)
1
2
3
4
5
6
1 >>> plt.imshow(generate_pattern('block3_conv1', 0))

Figure 5.31. Filter patterns for layer block2_conv1
Figure 5.32. Filter patterns for layer block3_conv1

Figure 5.33. Filter patterns for layer block4_conv1
Listing 5.39. Generating a grid of all ×lter response patterns in a layer
1
2
3
4
5
6
7
8
layer_name = 'block1_conv1' 
size = 64 
margin = 5 
 
results = np.zeros((8 * size + 7 * margin, 8 * size + 7 * margin, 3)) 
 
for i in range(8): 
    for j in range(8): 
1
2
3

Figure 5.34. Test picture of African elephants
9
10
11
12
13
14
15
16
17
18
19
        filter_img = generate_pattern(layer_name, i + (j * 8), size=size) 
 
        horizontal_start = i * size + i * margin 
        horizontal_end = horizontal_start + size 
        vertical_start = j * size + j * margin 
        vertical_end = vertical_start + size 
        results[horizontal_start: horizontal_end, 
                vertical_start: vertical_end, :] = filter_img 
 
plt.figure(figsize=(20, 20)) 
plt.imshow(results)
4
5
6
Listing 5.40. Loading the VGG16 network with pretrained weights
1
2
3
from keras.applications.vgg16 import VGG16 
 
model = VGG16(weights='imagenet')
1
Listing 5.41. Preprocessing an input image for VGG16
1
2
3
4
5
6
7
8
9
10
11
12
13
from keras.preprocessing import image 
from keras.applications.vgg16 import preprocess_input, decode_predictions 
import numpy as np 
 
img_path = '/Users/fchollet/Downloads/creative_commons_elephant.jpg' 
 
img = image.load_img(img_path, target_size=(224, 224)) 
 
x = image.img_to_array(img) 
 
x = np.expand_dims(x, axis=0) 
 
x = preprocess_input(x)
1
2
3
4
5

Figure 5.35. African elephant class activation heatmap over the test picture
1
2
3
4
5
>>> preds = model.predict(x) 
>>> print('Predicted:', decode_predictions(preds, top=3)[0]) 
Predicted:', [(u'n02504458', u'African_elephant', 0.92546833), 
(u'n01871265', u'tusker', 0.070257246), 
(u'n02504013', u'Indian_elephant', 0.0042589349)]
1
2
>>> np.argmax(preds[0]) 
386
Listing 5.42. Setting up the Grad-CAM algorithm
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
african_e66lephant_output = model.output[:, 386] 
 
last_conv_layer = model.get_layer('block5_conv3') 
 
grads = K.gradients(african_elephant_output, last_conv_layer.output)[0] 
 
pooled_grads = K.mean(grads, axis=(0, 1, 2)) 
 
iterate = K.function([model.input], 
                     [pooled_grads, last_conv_layer.output[0]]) 
 
pooled_grads_value, conv_layer_output_value = iterate([x]) 
 
for i in range(512): 
    conv_layer_output_value[:, :, i] *= pooled_grads_value[i] 
 
heatmap = np.mean(conv_layer_output_value, axis=-1)
1
2
3
4
5
6
7
8

Figure 5.36. Superimposing the class activation heatmap on the original picture
Listing 5.43. Heatmap post-processing
1
2
3
heatmap = np.maximum(heatmap, 0) 
heatmap /= np.max(heatmap) 
plt.matshow(heatmap)
Listing 5.44. Superimposing the heatmap with the original picture
1
2
3
4
5
6
7
8
import cv2 
 
img = cv2.imread(img_path) 
 
heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0])) 
 
heatmap = np.uint8(255 * heatmap) 
 
1
2
3

9
10
11
12
13
heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET) 
 
superimposed_img = heatmap * 0.4 + img 
 
cv2.imwrite('/Users/fchollet/Downloads/elephant_cam.jpg', superimposed_img)
4
5
6

CHAPTER 6
Figure 6.1. From text to tokens to vectors
UNDERSTANDING N-GRAMS AND BAG-OF-WORDS
Word n-grams are groups of N (or fewer) consecutive words that you
can extract from a sentence. The same concept may also be applied to
characters instead of words.
Here’s a simple example. Consider the sentence “The cat sat on the
mat.” It may be decomposed into the following set of 2-grams:
It may also be decomposed into the following set of 3-grams:
1
2
{"The", "The cat", "cat", "cat sat", "sat", 
  "sat on", "on", "on the", "the", "the mat", "mat"}
1
2
3
{"The", "The cat", "cat", "cat sat", "The cat sat", 
  "sat", "sat on", "on", "cat sat on", "on the", "the", 
  "sat on the", "the mat", "mat", "on the mat"}

Such a set is called a bag-of-2-grams or bag-of-3-grams, respectively.
The term bag here refers to the fact that you’re dealing with a set of
tokens rather than a list or sequence: the tokens have no specic
order. This family of tokenization methods is called bag-of-words.
Because bag-of-words isn’t an order-preserving tokenization method
(the tokens generated are understood as a set, not a sequence, and the
general structure of the sentences is lost), it tends to be used in
shallow language-processing models rather than in deep-learning
models. Extracting n-grams is a form of feature engineering, and deep
learning does away with this kind of rigid, brittle approach, replacing it
with hierarchical feature learning. One-dimensional convnets and
recurrent neural networks, introduced later in this chapter, are capable
of learning representations for groups of words and characters without
being explicitly told about the existence of such groups, by looking at
continuous word or character sequences. For this reason, we won’t
cover n-grams any further in this book. But do keep in mind that
they’re a powerful, unavoidable feature-engineering tool when using
lightweight, shallow text-processing models such as logistic
regression and random forests.
Listing 6.1. Word-level one-hot encoding (toy example)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
import numpy as np 
 
samples = ['The cat sat on the mat.', 'The dog ate my homework.'] 
 
token_index = {} 
for sample in samples: 
    for word in sample.split(): 
        if word not in token_index: 
            token_index[word] = len(token_index) + 1 
 
max_length = 10 
 
results = np.zeros(shape=(len(samples), 
                          max_length, 
                          max(token_index.values()) + 1)) 
for i, sample in enumerate(samples): 
    for j, word in list(enumerate(sample.split()))[:max_length]: 
        index = token_index.get(word) 
        results[i, j, index] = 1.
1
2
3
4
5
6
Listing 6.2. Character-level one-hot encoding (toy example)
1
2
3
import string 
 
samples = ['The cat sat on the mat.', 'The dog ate my homework.'] 

Figure 6.2. Whereas word representations obtained from one-hot encoding or hashing
are sparse, high-dimensional, and hardcoded, word embeddings are dense, relatively
lowdimensional, and learned from data.
4
5
6
7
8
9
10
11
12
characters = string.printable                                           1 
token_index = dict(zip(range(1, len(characters) + 1), characters)) 
 
max_length = 50 
results = np.zeros((len(samples), max_length, max(token_index.keys()) + 1)) 
for i, sample in enumerate(samples): 
    for j, character in enumerate(sample): 
        index = token_index.get(character) 
        results[i, j, index] = 1.
Listing 6.3. Using Keras for word-level one-hot encoding
1
2
3
4
5
6
7
8
9
10
11
12
13
from keras.preprocessing.text import Tokenizer 
 
samples = ['The cat sat on the mat.', 'The dog ate my homework.'] 
 
tokenizer = Tokenizer(num_words=1000) 
tokenizer.fit_on_texts(samples) 
 
sequences = tokenizer.texts_to_sequences(samples) 
 
one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary') 
 
word_index = tokenizer.word_index 
print('Found %s unique tokens.' % len(word_index))
1
2
3
4
5
Listing 6.4. Word-level one-hot encoding with hashing trick (toy example)
1
2
3
4
5
6
7
8
9
10
samples = ['The cat sat on the mat.', 'The dog ate my homework.'] 
 
dimensionality = 1000 
max_length = 10 
 
results = np.zeros((len(samples), max_length, dimensionality)) 
for i, sample in enumerate(samples): 
    for j, word in list(enumerate(sample.split()))[:max_length]: 
        index = abs(hash(word)) % dimensionality 
        results[i, j, index] = 1.
1
2

Figure 6.3. A toy example of a word-embedding space
Figure 6.4. The embedding  layer
Listing 6.5. Instantiating an Embedding layer
1
2
3
from keras.layers import Embedding 
 
embedding_layer = Embedding(1000, 64)
1
Listing 6.6. Loading the IMDB data for use with an Embedding layer
1
2
3
4
5
6
from keras.datasets import imdb 
from keras import preprocessing 
 
max_features = 10000 
maxlen = 20 
 
1
2

7
8
9
10
11
(x_train, y_train), (x_test, y_test) = imdb.load_data( 
    num_words=max_features) 
 
x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen 
x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)
3
4
Listing 6.7. Using an Embedding layer and classi×er on the IMDB data
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
from keras.models import Sequential 
from keras.layers import Flatten, Dense 
 
model = Sequential() 
model.add(Embedding(10000, 8, input_length=maxlen)) 
 
model.add(Flatten()) 
 
model.add(Dense(1, activation='sigmoid')) 
model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc']) 
model.summary() 
 
history = model.fit(x_train, y_train, 
                    epochs=10, 
                    batch_size=32, 
                    validation_split=0.2)
1
2
3
Listing 6.8. Processing the labels of the raw IMDB data
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
import os 
 
imdb_dir = '/Users/fchollet/Downloads/aclImdb' 
train_dir = os.path.join(imdb_dir, 'train') 
 
labels = [] 
texts = [] 
 
for label_type in ['neg', 'pos']: 
    dir_name = os.path.join(train_dir, label_type) 
    for fname in os.listdir(dir_name): 
        if fname[-4:] == '.txt': 
            f = open(os.path.join(dir_name, fname)) 
            texts.append(f.read()) 
            f.close() 
            if label_type == 'neg': 
                labels.append(0) 
            else: 
                labels.append(1)
Listing 6.9. Tokenizing the text of the raw IMDB data

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
from keras.preprocessing.text import Tokenizer 
from keras.preprocessing.sequence import pad_sequences 
import numpy as np 
 
maxlen = 100 
training_samples = 200 
validation_samples = 10000 
max_words = 10000 
 
tokenizer = Tokenizer(num_words=max_words) 
tokenizer.fit_on_texts(texts) 
sequences = tokenizer.texts_to_sequences(texts) 
 
word_index = tokenizer.word_index 
print('Found %s unique tokens.' % len(word_index)) 
 
data = pad_sequences(sequences, maxlen=maxlen) 
 
labels = np.asarray(labels) 
print('Shape of data tensor:', data.shape) 
print('Shape of label tensor:', labels.shape) 
 
indices = np.arange(data.shape[0]) 
np.random.shuffle(indices) 
data = data[indices] 
labels = labels[indices] 
 
x_train = data[:training_samples] 
y_train = labels[:training_samples] 
x_val = data[training_samples: training_samples + validation_samples] 
y_val = labels[training_samples: training_samples + validation_samples]
1
2
3
4
5
Listing 6.10. Parsing the GloVe word-embeddings ×le
1
2
3
4
5
6
7
8
9
10
11
12
glove_dir = '/Users/fchollet/Downloads/glove.6B' 
 
embeddings_index = {} 
f = open(os.path.join(glove_dir, 'glove.6B.100d.txt')) 
for line in f: 
    values = line.split() 
    word = values[0] 
    coefs = np.asarray(values[1:], dtype='float32') 
    embeddings_index[word] = coefs 
f.close() 
 
print('Found %s word vectors.' % len(embeddings_index))
Listing 6.11. Preparing the GloVe word-embeddings matrix
1
2
3
4
5
6
7
8
embedding_dim = 100 
 
embedding_matrix = np.zeros((max_words, embedding_dim)) 
for word, i in word_index.items(): 
    if i < max_words: 
        embedding_vector = embeddings_index.get(word) 
        if embedding_vector is not None: 
            embedding_matrix[i] = embedding_vector
1

Figure 6.5. Training and validation loss when using pretrained word embeddings
Listing 6.12. Model de×nition
1
2
3
4
5
6
7
8
9
from keras.models import Sequential 
from keras.layers import Embedding, Flatten, Dense 
 
model = Sequential() 
model.add(Embedding(max_words, embedding_dim, input_length=maxlen)) 
model.add(Flatten()) 
model.add(Dense(32, activation='relu')) 
model.add(Dense(1, activation='sigmoid')) 
model.summary()
Listing 6.13. Loading pretrained word embeddings into the Embedding  layer
1
2
model.layers[0].set_weights([embedding_matrix]) 
model.layers[0].trainable = False
Listing 6.14. Training and evaluation
1
2
3
4
5
6
7
8
model.compile(optimizer='rmsprop', 
              loss='binary_crossentropy', 
              metrics=['acc']) 
history = model.fit(x_train, y_train, 
                    epochs=10, 
                    batch_size=32, 
                    validation_data=(x_val, y_val)) 
model.save_weights('pre_trained_glove_model.h5')

Figure 6.6. Training and validation accuracy when using pretrained word embeddings
Listing 6.15. Plotting the results
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
import matplotlib.pyplot as plt 
 
acc = history.history['acc'] 
val_acc = history.history['val_acc'] 
loss = history.history['loss'] 
val_loss = history.history['val_loss'] 
 
epochs = range(1, len(acc) + 1) 
 
plt.plot(epochs, acc, 'bo', label='Training acc') 
plt.plot(epochs, val_acc, 'b', label='Validation acc') 
plt.title('Training and validation accuracy') 
plt.legend() 
 
plt.figure() 
 
plt.plot(epochs, loss, 'bo', label='Training loss') 
plt.plot(epochs, val_loss, 'b', label='Validation loss') 
plt.title('Training and validation loss') 
plt.legend() 
 
plt.show()

Figure 6.7. Training and validation loss without using pretrained word embeddings
Figure 6.8. Training and validation accuracy without using pretrained word embeddings
Listing 6.16. Training the same model without pretrained word embeddings
1
2
3
4
5
6
7
8
9
10
11
12
13
14
from keras.models import Sequential 
from keras.layers import Embedding, Flatten, Dense 
 
model = Sequential() 
model.add(Embedding(max_words, embedding_dim, input_length=maxlen)) 
model.add(Flatten()) 
model.add(Dense(32, activation='relu')) 
model.add(Dense(1, activation='sigmoid')) 
model.summary() 
 
model.compile(optimizer='rmsprop', 
              loss='binary_crossentropy', 
              metrics=['acc']) 
history = model.fit(x_train, y_train, 

Figure 6.9. A recurrent network: a network with a loop
15
16
17
                    epochs=10, 
                    batch_size=32, 
                    validation_data=(x_val, y_val))
Listing 6.17. Tokenizing the data of the test set
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
test_dir = os.path.join(imdb_dir, 'test') 
 
labels = [] 
texts = [] 
 
for label_type in ['neg', 'pos']: 
    dir_name = os.path.join(test_dir, label_type) 
    for fname in sorted(os.listdir(dir_name)): 
        if fname[-4:] == '.txt': 
            f = open(os.path.join(dir_name, fname)) 
            texts.append(f.read()) 
            f.close() 
            if label_type == 'neg': 
                labels.append(0) 
            else: 
                labels.append(1) 
 
sequences = tokenizer.texts_to_sequences(texts) 
x_test = pad_sequences(sequences, maxlen=maxlen) 
y_test = np.asarray(labels)
Listing 6.18. Evaluating the model on the test set
1
2
model.load_weights('pre_trained_glove_model.h5') 
model.evaluate(x_test, y_test)
Listing 6.19. Pseudocode RNN
1
2
state_t = 0 
for input_t in input_sequence: 
1
2

Figure 6.10. A simple RNN, unrolled over time
3
4
    output_t = f(input_t, state_t) 
    state_t = output_t
3
Listing 6.20. More detailed pseudocode for the RNN
1
2
3
4
state_t = 0 
for input_t in input_sequence: 
    output_t = activation(dot(W, input_t) + dot(U, state_t) + b) 
    state_t = output_t
Listing 6.21. Numpy implementation of a simple RNN
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
import numpy as np 
 
timesteps = 100 
input_features = 32 
output_features = 64 
 
inputs = np.random.random((timesteps, input_features)) 
 
state_t = np.zeros((output_features,)) 
 
W = np.random.random((output_features, input_features)) 
U = np.random.random((output_features, output_features)) 
b = np.random.random((output_features,)) 
 
successive_outputs = [] 
for input_t in inputs: 
    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b) 
 
    successive_outputs.append(output_t) 
 
    state_t = output_t 
 
final_output_sequence = np.concatenate(successive_outputs, axis=0)
1
2
3
4
5
6
7
8
9
10
11
1 output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)

1 from keras.layers import SimpleRNN
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
>>> from keras.models import Sequential 
>>> from keras.layers import Embedding, SimpleRNN 
>>> model = Sequential() 
>>> model.add(Embedding(10000, 32)) 
>>> model.add(SimpleRNN(32)) 
>>> model.summary() 
________________________________________________________________ 
Layer (type)                     Output Shape          Param # 
================================================================ 
embedding_22 (Embedding)         (None, None, 32)      320000 
________________________________________________________________ 
simplernn_10 (SimpleRNN)         (None, 32)            2080 
================================================================ 
Total params: 322,080 
Trainable params: 322,080 
Non-trainable params: 0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
>>> model = Sequential() 
>>> model.add(Embedding(10000, 32)) 
>>> model.add(SimpleRNN(32, return_sequences=True)) 
>>> model.summary() 
________________________________________________________________ 
Layer (type)                     Output Shape          Param # 
================================================================ 
embedding_23 (Embedding)         (None, None, 32)      320000 
________________________________________________________________ 
simplernn_11 (SimpleRNN)         (None, None, 32)      2080 
================================================================ 
Total params: 322,080 
Trainable params: 322,080 
Non-trainable params: 0

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
>>> model = Sequential() 
>>> model.add(Embedding(10000, 32)) 
>>> model.add(SimpleRNN(32, return_sequences=True)) 
>>> model.add(SimpleRNN(32, return_sequences=True)) 
>>> model.add(SimpleRNN(32, return_sequences=True)) 
>>> model.add(SimpleRNN(32)) 
>>> model.summary() 
________________________________________________________________ 
Layer (type)                     Output Shape          Param # 
================================================================ 
embedding_24 (Embedding)         (None, None, 32)      320000 
________________________________________________________________ 
simplernn_12 (SimpleRNN)         (None, None, 32)      2080 
________________________________________________________________ 
simplernn_13 (SimpleRNN)         (None, None, 32)      2080 
________________________________________________________________ 
simplernn_14 (SimpleRNN)         (None, None, 32)      2080 
________________________________________________________________ 
simplernn_15 (SimpleRNN)         (None, 32)            2080 
================================================================ 
Total params: 328,320 
Trainable params: 328,320 
Non-trainable params: 0
1
Listing 6.22. Preparing the IMDB data
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
from keras.datasets import imdb 
from keras.preprocessing import sequence 
 
max_features = 10000 
maxlen = 500 
batch_size = 32 
 
print('Loading data...') 
(input_train, y_train), (input_test, y_test) = imdb.load_data( 
     num_words=max_features) 
print(len(input_train), 'train sequences') 
print(len(input_test), 'test sequences') 
 
print('Pad sequences (samples x time)') 
input_train = sequence.pad_sequences(input_train, maxlen=maxlen) 
input_test = sequence.pad_sequences(input_test, maxlen=maxlen) 
print('input_train shape:', input_train.shape) 
print('input_test shape:', input_test.shape)
1
2
Listing 6.23. Training the model with Embedding  and SimpleRNN  layers
1
2
3
4
5
6
7
8
9
from keras.layers import Dense 
 
model = Sequential() 
model.add(Embedding(max_features, 32)) 
model.add(SimpleRNN(32)) 
model.add(Dense(1, activation='sigmoid')) 
 
model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc']) 
history = model.fit(input_train, y_train, 

Figure 6.11. Training and validation loss on IMDB with simplernn
Figure 6.12. Training and validation accuracy on IMDB with simplernn
10
11
12
                    epochs=10, 
                    batch_size=128, 
                    validation_split=0.2)
Listing 6.24. Plotting results
1
2
3
4
5
6
7
8
9
import matplotlib.pyplot as plt 
 
acc = history.history['acc'] 
val_acc = history.history['val_acc'] 
loss = history.history['loss'] 
val_loss = history.history['val_loss'] 
 
epochs = range(1, len(acc) + 1) 
 

Figure 6.13. The starting point of an lstm  layer: a simplernn
Figure 6.14. Going from a simplernn  to an lstm : adding a carry track
10
11
12
13
14
15
16
17
18
19
20
21
22
plt.plot(epochs, acc, 'bo', label='Training acc') 
plt.plot(epochs, val_acc, 'b', label='Validation acc') 
plt.title('Training and validation accuracy') 
plt.legend() 
 
plt.figure() 
 
plt.plot(epochs, loss, 'bo', label='Training loss') 
plt.plot(epochs, val_loss, 'b', label='Validation loss') 
plt.title('Training and validation loss') 
plt.legend() 
 
plt.show()
1 y = activation(dot(state_t, U) + dot(input_t, W) + b)

Figure 6.15. Anatomy of an lstm
Figure 6.16. Training and validation loss on IMDB with LSTM
Listing 6.25. Pseudocode details of the LSTM architecture (1/2)
1
2
3
4
5
output_t = activation(dot(state_t, Uo) + dot(input_t, Wo) + dot(C_t, Vo) + bo) 
 
i_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi) 
f_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bf) 
k_t = activation(dot(state_t, Uk) + dot(input_t, Wk) + bk)
Listing 6.26. Pseudocode details of the LSTM architecture (2/2)
1 c_t+1 = i_t * k_t + c_t * f_t

Figure 6.17. Training and validation accuracy on IMDB with LSTM
Listing 6.27. Using the LSTM  layer in Keras
1
2
3
4
5
6
7
8
9
10
11
12
13
14
from keras.layers import LSTM 
 
model = Sequential() 
model.add(Embedding(max_features, 32)) 
model.add(LSTM(32)) 
model.add(Dense(1, activation='sigmoid')) 
 
model.compile(optimizer='rmsprop', 
              loss='binary_crossentropy', 
              metrics=['acc']) 
history = model.fit(input_train, y_train, 
                    epochs=10, 
                    batch_size=128, 
                    validation_split=0.2)
1
2
3
4
5
cd ~/Downloads 
mkdir jena_climate 
cd jena_climate 
wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip 
unzip jena_climate_2009_2016.csv.zip
Listing 6.28. Inspecting the data of the Jena weather dataset
1
2
3
4
5
6
7
8
import os 
 
data_dir = '/users/fchollet/Downloads/jena_climate' 
fname = os.path.join(data_dir, 'jena_climate_2009_2016.csv') 
 
f = open(fname) 
data = f.read() 
f.close() 

Figure 6.18. Temperature over the full temporal range of the dataset (°C)
9
10
11
12
13
14
15
 
lines = data.split('\n') 
header = lines[0].split(',') 
lines = lines[1:] 
 
print(header) 
print(len(lines))
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
["Date Time", 
 "p (mbar)", 
 "T (degC)", 
 "Tpot (K)", 
 "Tdew (degC)", 
 "rh (%)", 
 "VPmax (mbar)", 
 "VPact (mbar)", 
 "VPdef (mbar)", 
 "sh (g/kg)", 
 "H2OC (mmol/mol)", 
 "rho (g/m**3)", 
 "wv (m/s)", 
 "max. wv (m/s)", 
 "wd (deg)"]
Listing 6.29. Parsing the data
1
2
3
4
5
6
import numpy as np 
 
float_data = np.zeros((len(lines), len(header) - 1)) 
for i, line in enumerate(lines): 
    values = [float(x) for x in line.split(',')[1:]] 
    float_data[i, :] = values

Figure 6.19. Temperature over the ×rst 10 days of the dataset (°C)
Listing 6.30. Plotting the temperature timeseries
1
2
3
4
from matplotlib import pyplot as plt 
 
temp = float_data[:, 1]  <1> temperature (in degrees Celsius) 
plt.plot(range(len(temp)), temp)
Listing 6.31. Plotting the ×rst 10 days of the temperature timeseries
1 plt.plot(range(1440), temp[:1440])

Listing 6.32. Normalizing the data
1
2
3
4
mean = float_data[:200000].mean(axis=0) 
float_data -= mean 
std = float_data[:200000].std(axis=0) 
float_data /= std
Listing 6.33. Generator yielding timeseries samples and their targets
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
def generator(data, lookback, delay, min_index, max_index, 
              shuffle=False, batch_size=128, step=6): 
    if max_index is None: 
        max_index = len(data) - delay - 1 
    i = min_index + lookback 
    while 1: 
        if shuffle: 
            rows = np.random.randint( 
                min_index + lookback, max_index, size=batch_size) 
        else: 
            if i + batch_size >= max_index: 
                i = min_index + lookback 
            rows = np.arange(i, min(i + batch_size, max_index)) 
            i += len(rows) 
 
        samples = np.zeros((len(rows), 
                           lookback // step, 
                           data.shape[-1])) 
        targets = np.zeros((len(rows),)) 
        for j, row in enumerate(rows): 
            indices = range(rows[j] - lookback, rows[j], step) 
            samples[j] = data[indices] 
            targets[j] = data[rows[j] + delay][1] 
        yield samples, targets
Listing 6.34. Preparing the training, validation, and test generators
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
lookback = 1440 
step = 6 
delay = 144 
batch_size = 128 
train_gen = generator(float_data, 
                      lookback=lookback, 
                      delay=delay, 
                      min_index=0, 
                      max_index=200000, 
                      shuffle=True, 
                      step=step, 
                      batch_size=batch_size) 
val_gen = generator(float_data, 
                    lookback=lookback, 
                    delay=delay, 
                    min_index=200001, 
                    max_index=300000, 
                    step=step, 
                    batch_size=batch_size) 

20
21
22
23
24
25
26
27
28
29
30
test_gen = generator(float_data, 
                     lookback=lookback, 
                     delay=delay, 
                     min_index=300001, 
                     max_index=None, 
                     step=step, 
                     batch_size=batch_size) 
 
val_steps = (300000 - 200001 - lookback) 
 
test_steps = (len(float_data) - 300001 - lookback)
1
2
1 np.mean(np.abs(preds - targets))
Listing 6.35. Computing the common-sense baseline MAE
1
2
3
4
5
6
7
8
9
10
def evaluate_naive_method(): 
    batch_maes = [] 
    for step in range(val_steps): 
        samples, targets = next(val_gen) 
        preds = samples[:, -1, 1] 
        mae = np.mean(np.abs(preds - targets)) 
        batch_maes.append(mae) 
    print(np.mean(batch_maes)) 
 
evaluate_naive_method()
Listing 6.36. Converting the MAE back to a Celsius error
1 celsius_mae = 0.29 * std[1]
Listing 6.37. Training and evaluating a densely connected model
1
2
3
4
5
6
7
8
9
10
11
from keras.models import Sequential 
from keras import layers 
from keras.optimizers import RMSprop 
 
model = Sequential() 
model.add(layers.Flatten(input_shape=(lookback // step, float_data.shape[-1]))) 
model.add(layers.Dense(32, activation='relu')) 
model.add(layers.Dense(1)) 
model.compile(optimizer=RMSprop(), loss='mae') 
history = model.fit_generator(train_gen, 
                              steps_per_epoch=500, 

Figure 6.20. Training and validation loss on the Jena temperature-forecasting task with
a simple, densely connected network
12
13
14
                              epochs=20, 
                              validation_data=val_gen, 
                              validation_steps=val_steps)
Listing 6.38. Plotting results
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
import matplotlib.pyplot as plt 
 
loss = history.history['loss'] 
val_loss = history.history['val_loss'] 
 
epochs = range(1, len(loss) + 1) 
 
plt.figure() 
 
plt.plot(epochs, loss, 'bo', label='Training loss') 
plt.plot(epochs, val_loss, 'b', label='Validation loss') 
plt.title('Training and validation loss') 
plt.legend() 
 
plt.show()
Listing 6.39. Training and evaluating a GRU-based model
1
2
3
4
5
6
7
from keras.models import Sequential 
from keras import layers 
from keras.optimizers import RMSprop 
 
model = Sequential() 
model.add(layers.GRU(32, input_shape=(None, float_data.shape[-1]))) 
model.add(layers.Dense(1)) 

Figure 6.21. Training and validation loss on the Jena temperature-forecasting task with
a GRU
Figure 6.22. Training and validation loss on the Jena temperature-forecasting task with
a dropout-regularized GRU
8
9
10
11
12
13
14
 
model.compile(optimizer=RMSprop(), loss='mae') 
history = model.fit_generator(train_gen, 
                              steps_per_epoch=500, 
                              epochs=20, 
                              validation_data=val_gen, 
                              validation_steps=val_steps)
Listing 6.40. Training and evaluating a dropout-regularized GRU-based model
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
from keras.models import Sequential 
from keras import layers 
from keras.optimizers import RMSprop 
 
model = Sequential() 
model.add(layers.GRU(32, 
                     dropout=0.2, 
                     recurrent_dropout=0.2, 
                     input_shape=(None, float_data.shape[-1]))) 
model.add(layers.Dense(1)) 
 
model.compile(optimizer=RMSprop(), loss='mae') 
history = model.fit_generator(train_gen, 
                              steps_per_epoch=500, 
                              epochs=40, 
                              validation_data=val_gen, 
                              validation_steps=val_steps)

Figure 6.23. Training and validation loss on the Jena temperature-forecasting task with
a stacked GRU network
Listing 6.41. Training and evaluating a dropout-regularized, stacked GRU model
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
from keras.models import Sequential 
from keras import layers 
from keras.optimizers import RMSprop 
 
model = Sequential() 
model.add(layers.GRU(32, 
                     dropout=0.1, 
                     recurrent_dropout=0.5, 
                     return_sequences=True, 
                     input_shape=(None, float_data.shape[-1]))) 
model.add(layers.GRU(64, activation='relu', 
                     dropout=0.1, 
                     recurrent_dropout=0.5)) 
model.add(layers.Dense(1)) 
 
model.compile(optimizer=RMSprop(), loss='mae') 
history = model.fit_generator(train_gen, 
                              steps_per_epoch=500, 
                              epochs=40, 
                              validation_data=val_gen, 
                              validation_steps=val_steps)

Figure 6.24. Training and validation loss on the Jena temperature-forecasting task with
a GRU trained on reversed sequences
Listing 6.42. Training and evaluating an LSTM using reversed sequences
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
from keras.datasets import imdb 
from keras.preprocessing import sequence 
from keras import layers 
from keras.models import Sequential 
 
max_features = 10000 
maxlen = 500 
 
(x_train, y_train), (x_test, y_test) = imdb.load_data( 
    num_words=max_features) 
 
x_train = [x[::-1] for x in x_train] 
x_test = [x[::-1] for x in x_test] 
 
x_train = sequence.pad_sequences(x_train, maxlen=maxlen) 
x_test = sequence.pad_sequences(x_test, maxlen=maxlen) 
 
model = Sequential() 
model.add(layers.Embedding(max_features, 128)) 
model.add(layers.LSTM(32)) 
1
2
3
4
5

Figure 6.25. How a bidirectional RNN layer works
21
22
23
24
25
26
27
28
29
model.add(layers.Dense(1, activation='sigmoid')) 
 
model.compile(optimizer='rmsprop', 
              loss='binary_crossentropy', 
              metrics=['acc']) 
history = model.fit(x_train, y_train, 
                    epochs=10, 
                    batch_size=128, 
                    validation_split=0.2)
Listing 6.43. Training and evaluating a bidirectional LSTM
1
2
3
4
5
6
7
8
9
10
model = Sequential() 
model.add(layers.Embedding(max_features, 32)) 
model.add(layers.Bidirectional(layers.LSTM(32))) 
model.add(layers.Dense(1, activation='sigmoid')) 
 
model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc']) 
history = model.fit(x_train, y_train, 
                    epochs=10, 
                    batch_size=128, 
                    validation_split=0.2)
Listing 6.44. Training a bidirectional GRU
1
2
3
4
5
6
7
8
9
10
11
from keras.models import Sequential 
from keras import layers 
from keras.optimizers import RMSprop 
 
model = Sequential() 
model.add(layers.Bidirectional( 
    layers.GRU(32), input_shape=(None, float_data.shape[-1]))) 
model.add(layers.Dense(1)) 
 
model.compile(optimizer=RMSprop(), loss='mae') 
history = model.fit_generator(train_gen, 

Figure 6.26. How 1D convolution works: each output timestep is obtained from a
temporal patch in the input sequence.
12
13
14
15
                              steps_per_epoch=500, 
                              epochs=40, 
                              validation_data=val_gen, 
                              validation_steps=val_steps)
Listing 6.45. Preparing the IMDB data
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
from keras.datasets import imdb 
from keras.preprocessing import sequence 
 
max_features = 10000 
max_len = 500 
 
print('Loading data...') 
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features) 
print(len(x_train), 'train sequences') 
print(len(x_test), 'test sequences') 
 
print('Pad sequences (samples x time)') 
x_train = sequence.pad_sequences(x_train, maxlen=max_len) 
x_test = sequence.pad_sequences(x_test, maxlen=max_len) 
print('x_train shape:', x_train.shape) 
print('x_test shape:', x_test.shape)
Listing 6.46. Training and evaluating a simple 1D convnet on the IMDB data
1
2
3
from keras.models import Sequential 
from keras import layers 
from keras.optimizers import RMSprop 

Figure 6.27. Training and validation loss on IMDB with a simple 1D convnet
Figure 6.28. Training and validation accuracy on IMDB with a simple 1D convnet
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
 
model = Sequential() 
model.add(layers.Embedding(max_features, 128, input_length=max_len)) 
model.add(layers.Conv1D(32, 7, activation='relu')) 
model.add(layers.MaxPooling1D(5)) 
model.add(layers.Conv1D(32, 7, activation='relu')) 
model.add(layers.GlobalMaxPooling1D()) 
model.add(layers.Dense(1)) 
 
model.summary() 
 
model.compile(optimizer=RMSprop(lr=1e-4), 
              loss='binary_crossentropy', 
              metrics=['acc']) 
history = model.fit(x_train, y_train, 
                    epochs=10, 
                    batch_size=128, 
                    validation_split=0.2)

Figure 6.29. Training and validation loss on the Jena temperature-forecasting task with
a simple 1D convnet
Figure 6.30. Combining a 1D convnet and an RNN for processing long sequences
Listing 6.47. Training and evaluating a simple 1D convnet on the Jena data
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
from keras.models import Sequential 
from keras import layers 
from keras.optimizers import RMSprop 
 
model = Sequential() 
model.add(layers.Conv1D(32, 5, activation='relu', 
                        input_shape=(None, float_data.shape[-1]))) 
model.add(layers.MaxPooling1D(3)) 
model.add(layers.Conv1D(32, 5, activation='relu')) 
model.add(layers.MaxPooling1D(3)) 
model.add(layers.Conv1D(32, 5, activation='relu')) 
model.add(layers.GlobalMaxPooling1D()) 
model.add(layers.Dense(1)) 
 
model.compile(optimizer=RMSprop(), loss='mae') 
history = model.fit_generator(train_gen, 
                              steps_per_epoch=500, 
                              epochs=20, 
                              validation_data=val_gen, 
                              validation_steps=val_steps)

Figure 6.31. Training and validation loss on the Jena temperature-forecasting task with
a 1D convnet followed by a gru
Listing 6.48. Preparing higher-resolution data generators for the Jena dataset
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
step = 3 
lookback = 720 
delay = 144 
 
train_gen = generator(float_data, 
                      lookback=lookback, 
                      delay=delay, 
                      min_index=0, 
                      max_index=200000, 
                      shuffle=True, 
                      step=step) 
val_gen = generator(float_data, 
                    lookback=lookback, 
                    delay=delay, 
                    min_index=200001, 
                    max_index=300000, 
                    step=step) 
test_gen = generator(float_data, 
                     lookback=lookback, 
                     delay=delay, 
                     min_index=300001, 
                     max_index=None, 
                     step=step) 
val_steps = (300000 - 200001 - lookback) // 128 
test_steps = (len(float_data) - 300001 - lookback) // 128
1
2

Listing 6.49. Model combining a 1D convolutional base and a GRU  layer
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
from keras.models import Sequential 
from keras import layers 
from keras.optimizers import RMSprop 
 
model = Sequential() 
model.add(layers.Conv1D(32, 5, activation='relu', 
                        input_shape=(None, float_data.shape[-1]))) 
model.add(layers.MaxPooling1D(3)) 
model.add(layers.Conv1D(32, 5, activation='relu')) 
model.add(layers.GRU(32, dropout=0.1, recurrent_dropout=0.5)) 
model.add(layers.Dense(1)) 
 
model.summary() 
 
model.compile(optimizer=RMSprop(), loss='mae') 
history = model.fit_generator(train_gen, 
                              steps_per_epoch=500, 
                              epochs=20, 
                              validation_data=val_gen, 
                              validation_steps=val_steps)

CHAPTER 7
Figure 7.1. A sequential  model: a linear stack of layers
Figure 7.2. A multi-input model
Figure 7.3. A multi-output (or multihead) model
Figure 7.4. An Inception module: a subgraph of layers with several parallel
convolutional branches

Figure 7.5. A residual connection: reinjection of prior information downstream via
feature-map addition
1
2
3
4
5
6
from keras import Input, layers 
 
input_tensor = Input(shape=(32,)) 
dense = layers.Dense(32, activation='relu') 
 
output_tensor = dense(input_tensor)
1
2
3
1
2
3
4
5
6
7
8
9
10
11
from keras.models import Sequential, Model 
from keras import layers 
from keras import Input 
 
seq_model = Sequential() 
seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,))) 
seq_model.add(layers.Dense(32, activation='relu')) 
seq_model.add(layers.Dense(10, activation='softmax')) 
 
input_tensor = Input(shape=(64,)) 
x = layers.Dense(32, activation='relu')(input_tensor) 
1
2

Figure 7.6. A question-answering model
12
13
14
15
16
17
x = layers.Dense(32, activation='relu')(x) 
output_tensor = layers.Dense(10, activation='softmax')(x) 
 
model = Model(input_tensor, output_tensor) 
 
model.summary()
3
4
1
2
3
4
5
6
7
8
9
10
11
12
13
14
_________________________________________________________________ 
Layer (type)                 Output Shape              Param # 
================================================================= 
input_1 (InputLayer)         (None, 64)                0 
_________________________________________________________________ 
dense_1 (Dense)              (None, 32)                2080 
_________________________________________________________________ 
dense_2 (Dense)              (None, 32)                1056 
_________________________________________________________________ 
dense_3 (Dense)              (None, 10)                330 
================================================================= 
Total params: 3,466 
Trainable params: 3,466 
Non-trainable params: 0
1
2
3
4
5
>>> unrelated_input = Input(shape=(32,)) 
>>> bad_model = model = Model(unrelated_input, output_tensor) 
RuntimeError: Graph disconnected: cannot 
obtain value for tensor 
Tensor("input_1:0", shape=(?, 64), dtype=float32) at layer "input_1".
1
2
3
4
5
6
7
8
model.compile(optimizer='rmsprop', loss='categorical_crossentropy') 
import numpy as np 
x_train = np.random.random((1000, 64)) 
y_train = np.random.random((1000, 10)) 
 
model.fit(x_train, y_train, epochs=10, batch_size=128) 
 
score = model.evaluate(x_train, y_train)
1
2
3
4

Listing 7.1. Functional API implementation of a two-input question-answering model
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
from keras.models import Model 
from keras import layers 
from keras import Input 
 
text_vocabulary_size = 10000 
question_vocabulary_size = 10000 
answer_vocabulary_size = 500 
 
text_input = Input(shape=(None,), dtype='int32', name='text') 
 
embedded_text = layers.Embedding( 
    64, text_vocabulary_size)(text_input) 
 
encoded_text = layers.LSTM(32)(embedded_text) 
 
question_input = Input(shape=(None,), 
                       dtype='int32', 
                       name='question') 
 
embedded_question = layers.Embedding( 
    32, question_vocabulary_size)(question_input) 
encoded_question = layers.LSTM(16)(embedded_question) 
 
concatenated = layers.concatenate([encoded_text, encoded_question], 
                                  axis=-1) 
 
answer = layers.Dense(answer_vocabulary_size, 
                      activation='softmax')(concatenated) 
 
model = Model([text_input, question_input], answer) 
model.compile(optimizer='rmsprop', 
              loss='categorical_crossentropy', 
              metrics=['acc'])
1
2
3
4
5
6
7
Listing 7.2. Feeding data to a multi-input model
1
2
3
import numpy as np 
 
num_samples = 1000 

Figure 7.7. A social media model with three heads
4
5
6
7
8
9
10
11
12
13
14
15
16
max_length = 100 
 
text = np.random.randint(1, text_vocabulary_size, 
                         size=(num_samples, max_length)) 
question = np.random.randint(1, question_vocabulary_size, 
                             size=(num_samples, max_length)) 
answers = np.random.randint(0, 1, 
                            size=(num_samples, answer_vocabulary_size)) 
 
model.fit([text, question], answers, epochs=10, batch_size=128) 
 
model.fit({'text': text, 'question': question}, answers, 
          epochs=10, batch_size=128)
1
2
3
4
Listing 7.3. Functional API implementation of a three-output model
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
from keras import layers 
from keras import Input 
from keras.models import Model 
vocabulary_size = 50000 
num_income_groups = 10 
 
posts_input = Input(shape=(None,), dtype='int32', name='posts') 
embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input) 
x = layers.Conv1D(128, 5, activation='relu')(embedded_posts) 
x = layers.MaxPooling1D(5)(x) 
x = layers.Conv1D(256, 5, activation='relu')(x) 
x = layers.Conv1D(256, 5, activation='relu')(x) 
x = layers.MaxPooling1D(5)(x) 
x = layers.Conv1D(256, 5, activation='relu')(x) 
x = layers.Conv1D(256, 5, activation='relu')(x) 
x = layers.GlobalMaxPooling1D()(x) 
x = layers.Dense(128, activation='relu')(x) 
 
age_prediction = layers.Dense(1, name='age')(x) 
income_prediction = layers.Dense(num_income_groups, 
                                 activation='softmax', 
                                 name='income')(x) 
gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x) 
 
model = Model(posts_input, 
              [age_prediction, income_prediction, gender_prediction])
1

Figure 7.8. An Inception module
Listing 7.4. Compilation options of a multi-output model: multiple losses
1
2
3
4
5
6
7
model.compile(optimizer='rmsprop', 
              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy']) 
 
model.compile(optimizer='rmsprop', 
              loss={'age': 'mse', 
                    'income': 'categorical_crossentropy', 
                    'gender': 'binary_crossentropy'})
1
Listing 7.5. Compilation options of a multi-output model: loss weighting
1
2
3
4
5
6
7
8
9
10
11
model.compile(optimizer='rmsprop', 
              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'], 
              loss_weights=[0.25, 1., 10.]) 
 
model.compile(optimizer='rmsprop', 
              loss={'age': 'mse', 
                    'income': 'categorical_crossentropy', 
                    'gender': 'binary_crossentropy'}, 
              loss_weights={'age': 0.25, 
                            'income': 1., 
                            'gender': 10.})
1
Listing 7.6. Feeding data to a multi-output model
1
2
3
4
5
6
7
model.fit(posts, [age_targets, income_targets, gender_targets], 
          epochs=10, batch_size=64) 
 
model.fit(posts, {'age': age_targets, 
                  'income': income_targets, 
                  'gender': gender_targets}, 
          epochs=10, batch_size=64)
1
2

1
2
3
4
5
6
7
8
9
10
11
12
13
14
from keras import layers 
branch_a = layers.Conv2D(128, 1, 
                         activation='relu', strides=2)(x) 
branch_b = layers.Conv2D(128, 1, activation='relu')(x) 
branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b) 
 
branch_c = layers.AveragePooling2D(3, strides=2)(x) 
branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c) 
 
branch_d = layers.Conv2D(128, 1, activation='relu')(x) 
branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d) 
branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d) 
output = layers.concatenate( 
    [branch_a, branch_b, branch_c, branch_d], axis=-1)
1
2
3
4
1
2
3
4
5
6
7
8
from keras import layers 
 
x = ... 
y = layers.Conv2D(128, 3, activation='relu', padding='same')(x) 
y = layers.Conv2D(128, 3, activation='relu', padding='same')(y) 
y = layers.Conv2D(128, 3, activation='relu', padding='same')(y) 
 
y = layers.add([y, x])
1
2
1
2
3
4
5
6
7
8
9
10
from keras import layers 
 
x = ... 
y = layers.Conv2D(128, 3, activation='relu', padding='same')(x) 
y = layers.Conv2D(128, 3, activation='relu', padding='same')(y) 
y = layers.MaxPooling2D(2, strides=2)(y) 
 
residual = layers.Conv2D(128, 1, strides=2, padding='same')(x) 
 
y = layers.add([y, residual])
1
2

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
from keras import layers 
from keras import Input 
from keras.models import Model 
 
lstm = layers.LSTM(32) 
left_input = Input(shape=(None, 128)) 
left_output = lstm(left_input) 
 
right_input = Input(shape=(None, 128)) 
right_output = lstm(right_input) 
 
merged = layers.concatenate([left_output, right_output], axis=-1) 
predictions = layers.Dense(1, activation='sigmoid')(merged) 
 
model = Model([left_input, right_input], predictions) 
model.fit([left_data, right_data], targets)
1
2
3
4
5
1 y = model(x)
1 y1, y2 = model([x1, x2])
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
from keras import layers 
from keras import applications 
from keras import Input 
 
xception_base = applications.Xception(weights=None, 
                                      include_top=False) 
 
left_input = Input(shape=(250, 250, 3)) 
right_input = Input(shape=(250, 250, 3)) 
 
left_features = xception_base(left_input) 
right_input = xception_base(right_input) 
 
merged_features = layers.concatenate( 
    [left_features, right_input], axis=-1)
1
2
3
4

1
2
3
4
5
keras.callbacks.ModelCheckpoint 
keras.callbacks.EarlyStopping 
keras.callbacks.LearningRateScheduler 
keras.callbacks.ReduceLROnPlateau 
keras.callbacks.CSVLogger
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
import keras 
 
callbacks_list = [ 
    keras.callbacks.EarlyStopping( 
        monitor='acc', 
        patience=1, 
    ), 
    keras.callbacks.ModelCheckpoint( 
        filepath='my_model.h5', 
        monitor='val_loss', 
        save_best_only=True, 
    ) 
] 
 
model.compile(optimizer='rmsprop', 
              loss='binary_crossentropy', 
              metrics=['acc']) 
 
model.fit(x, y, 
          epochs=10, 
          batch_size=32, 
          callbacks=callbacks_list, 
          validation_data=(x_val, y_val))
1
2
3
4
5
6
7
8
9
1
2
3
4
5
6
7
8
9
10
11
12
13
callbacks_list = [ 
    keras.callbacks.ReduceLROnPlateau( 
        monitor='val_loss' 
        factor=0.1, 
        patience=10, 
    ) 
] 
 
model.fit(x, y, 
          epochs=10, 
          batch_size=32, 
          callbacks=callbacks_list, 
          validation_data=(x_val, y_val))
1
2
3
4
1
2
3
4
5
6
on_epoch_begin 
on_epoch_end 
 
on_batch_begin 
on_batch_end 
 
1
2
3
4

Figure 7.9. The loop of progress
7
8
on_train_begin 
on_train_end
5
6
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
import keras 
import numpy as np 
 
class ActivationLogger(keras.callbacks.Callback): 
 
    def set_model(self, model): 
        self.model = model 
        layer_outputs = [layer.output for layer in model.layers] 
        self.activations_model = keras.models.Model(model.input, 
                                                    layer_outputs) 
 
    def on_epoch_end(self, epoch, logs=None): 
        if self.validation_data is None: 
            raise RuntimeError('Requires validation_data.') 
 
        validation_sample = self.validation_data[0][0:1] 
        activations = self.activations_model.predict(validation_sample) 
        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'w') 
        np.savez(f, activations) 
        f.close()
1
2
3
4
Listing 7.7. Text-classi×cation model to use with TensorBoard
1
2
3
4
5
6
7
8
9
10
11
12
13
14
import keras 
from keras import layers 
from keras.datasets import imdb 
from keras.preprocessing import sequence 
 
max_features = 2000 
max_len = 500 
 
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features) 
x_train = sequence.pad_sequences(x_train, maxlen=max_len) 
x_test = sequence.pad_sequences(x_test, maxlen=max_len) 
 
model = keras.models.Sequential() 
model.add(layers.Embedding(max_features, 128, 
1
2

Figure 7.10. TensorBoard: metrics monitoring
15
16
17
18
19
20
21
22
23
24
25
                           input_length=max_len, 
                           name='embed')) 
model.add(layers.Conv1D(32, 7, activation='relu')) 
model.add(layers.MaxPooling1D(5)) 
model.add(layers.Conv1D(32, 7, activation='relu')) 
model.add(layers.GlobalMaxPooling1D()) 
model.add(layers.Dense(1)) 
model.summary() 
model.compile(optimizer='rmsprop', 
              loss='binary_crossentropy', 
              metrics=['acc'])
Listing 7.9. Training the model with a TensorBoard callback
1
2
3
4
5
6
7
8
9
10
11
12
callbacks = [ 
    keras.callbacks.TensorBoard( 
        log_dir='my_log_dir', 
        histogram_freq=1, 
        embeddings_freq=1, 
    ) 
] 
history = model.fit(x_train, y_train, 
                    epochs=20, 
                    batch_size=128, 
                    validation_split=0.2, 
                    callbacks=callbacks)
1
2
3
1 $ tensorboard --logdir=my_log_dir

Figure 7.11. TensorBoard: activation histograms
Figure 7.12. TensorBoard: interactive 3D word-embedding visualization

Figure 7.13. TensorBoard: TensorFlow graph visualization
1
2
3
from keras.utils import plot_model 
 
plot_model(model, to_file='model.png')

Figure 7.14. A model plot as a graph of layers, generated with plot_model
Figure 7.15. A model plot with shape information
1
2
3
from keras.utils import plot_model 
 
plot_model(model, show_shapes=True, to_file='model.png')

Figure 7.16. Depthwise separable convolution: a depthwise convolution followed by a
pointwise convolution
1 normalized_data = (data - np.mean(data, axis=...)) / np.std(data, axis=...)
1
2
3
4
5
conv_model.add(layers.Conv2D(32, 3, activation='relu')) 
conv_model.add(layers.BatchNormalization()) 
 
dense_model.add(layers.Dense(32, activation='relu')) 
dense_model.add(layers.BatchNormalization())
1
2

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
from keras.models import Sequential, Model 
from keras import layers 
 
height = 64 
width = 64 
channels = 3 
num_classes = 10 
 
model = Sequential() 
model.add(layers.SeparableConv2D(32, 3, 
                                 activation='relu', 
                                 input_shape=(height, width, channels,))) 
model.add(layers.SeparableConv2D(64, 3, activation='relu')) 
model.add(layers.MaxPooling2D(2)) 
 
model.add(layers.SeparableConv2D(64, 3, activation='relu')) 
model.add(layers.SeparableConv2D(128, 3, activation='relu')) 
model.add(layers.MaxPooling2D(2)) 
 
model.add(layers.SeparableConv2D(64, 3, activation='relu')) 
model.add(layers.SeparableConv2D(128, 3, activation='relu')) 
model.add(layers.GlobalAveragePooling2D()) 
 
model.add(layers.Dense(32, activation='relu')) 
model.add(layers.Dense(num_classes, activation='softmax')) 
 
model.compile(optimizer='rmsprop', loss='categorical_crossentropy')
1
2
3
4
5
6
preds_a = model_a.predict(x_val) 
preds_b = model_b.predict(x_val) 
preds_c = model_c.predict(x_val) 
preds_d = model_d.predict(x_val) 
 
final_preds = 0.25 * (preds_a + preds_b + preds_c + preds_d)
1
2

1
2
3
4
5
6
preds_a = model_a.predict(x_val) 
preds_b = model_b.predict(x_val) 
preds_c = model_c.predict(x_val) 
preds_d = model_d.predict(x_val) 
 
final_preds = 0.5 * preds_a + 0.25 * preds_b + 0.1 * preds_c + 0.15 * preds_d
1

CHAPTER 8
Figure 8.1. The process of character-by-character text generation using a language
model
Figure 8.2. Different reweightings of one probability distribution. Low temperature =
more deterministic, high temperature = more random.
Listing 8.1. Reweighting a probability distribution to a different temperature
1
2
3
4
5
6
import numpy as np 
 
def reweight_distribution(original_distribution, temperature=0.5): 
    distribution = np.log(original_distribution) / temperature 
    distribution = np.exp(distribution) 
    return distribution / np.sum(distribution)
1
2

Listing 8.2. Downloading and parsing the initial text ×le
1
2
3
4
5
6
7
8
import keras 
import numpy as np 
 
path = keras.utils.get_file( 
    'nietzsche.txt', 
    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt') 
text = open(path).read().lower() 
print('Corpus length:', len(text))
Listing 8.3. Vectorizing sequences of characters
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
maxlen = 60 
step = 3 
 
sentences = [] 
 
next_chars = [] 
 
for i in range(0, len(text) - maxlen, step): 
    sentences.append(text[i: i + maxlen]) 
    next_chars.append(text[i + maxlen]) 
 
print('Number of sequences:', len(sentences)) 
 
chars = sorted(list(set(text))) 
print('Unique characters:', len(chars)) 
char_indices = dict((char, chars.index(char)) for char in chars) 
 
print('Vectorization...') 
x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool) 
y = np.zeros((len(sentences), len(chars)), dtype=np.bool) 
for i, sentence in enumerate(sentences): 
    for t, char in enumerate(sentence): 
        x[i, t, char_indices[char]] = 1 
    y[i, char_indices[next_chars[i]]] = 1
1
2
3
4
5
6
7

Listing 8.4. Single-layer LSTM model for next-character prediction
1
2
3
4
5
from keras import layers 
 
model = keras.models.Sequential() 
model.add(layers.LSTM(128, input_shape=(maxlen, len(chars)))) 
model.add(layers.Dense(len(chars), activation='softmax'))
Listing 8.5. Model compilation con×guration
1
2
optimizer = keras.optimizers.RMSprop(lr=0.01) 
model.compile(loss='categorical_crossentropy', optimizer=optimizer)
Listing 8.6. Function to sample the next character given the model’s predictions
1
2
3
4
5
6
7
def sample(preds, temperature=1.0): 
    preds = np.asarray(preds).astype('float64') 
    preds = np.log(preds) / temperature 
    exp_preds = np.exp(preds) 
    preds = exp_preds / np.sum(exp_preds) 
    probas = np.random.multinomial(1, preds, 1) 
    return np.argmax(probas)
Listing 8.7. Text-generation loop
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
import random 
import sys 
 
for epoch in range(1, 60): 
    print('epoch', epoch) 
    model.fit(x, y, batch_size=128, epochs=1) 
    start_index = random.randint(0, len(text) - maxlen - 1) 
    generated_text = text[start_index: start_index + maxlen] 
    print('--- Generating with seed: "' + generated_text + '"') 
    for temperature in [0.2, 0.5, 1.0, 1.2]: 
        print('------ temperature:', temperature) 
        sys.stdout.write(generated_text) 
 
        for i in range(400): 
            sampled = np.zeros((1, maxlen, len(chars))) 
            for t, char in enumerate(generated_text): 
                sampled[0, t, char_indices[char]] = 1. 
 
1
2
3
4
5
6

19
20
21
22
23
24
25
26
            preds = model.predict(sampled, verbose=0)[0] 
            next_index = sample(preds, temperature) 
            next_char = chars[next_index] 
 
            generated_text += next_char 
            generated_text = generated_text[1:] 
 
            sys.stdout.write(next_char)
7
1
2
3
4
5
6
7
new faculty, and the jubilation reached its climax when kant and such a man 
in the same time the spirit of the surely and the such the such 
as a man is the sunligh and subject the present to the superiority of the 
special pain the most man and strange the subjection of the 
special conscience the special and nature and such men the subjection of the 
special men, the most surely the subjection of the special 
intellect of the subjection of the same things and
1
2
3
4
5
6
7
new faculty, and the jubilation reached its climax when kant in the eterned 
and such man as it's also become himself the condition of the 
experience of off the basis the superiory and the special morty of the 
strength, in the langus, as which the same time life and "even who 
discless the mankind, with a subject and fact all you have to be the stand 
and lave no comes a troveration of the man and surely the 
conscience the superiority, and when one must be w
1
2
3
4
5
6
7
8
new faculty, and the jubilation reached its climax when kant, as a 
periliting of manner to all definites and transpects it it so 
hicable and ont him artiar resull 
too such as if ever the proping to makes as cnecience. to been juden, 
all every could coldiciousnike hother aw passife, the plies like 
which might thiod was account, indifferent germin, that everythery 
certain destrution, intellect into the deteriorablen origin of moralian, 
and a lessority o
1
2
3
4
5
6
7
cheerfulness, friendliness and kindness of a heart are the sense of the 
spirit is a man with the sense of the sense of the world of the 
self-end and self-concerning the subjection of the strengthorixes--the 
subjection of the subjection of the subjection of the 
self-concerning the feelings in the superiority in the subjection of the 
subjection of the spirit isn't to be a man of the sense of the 
subjection and said to the strength of the sense of the

Figure 8.3. Example of a DeepDream output image
1
2
3
4
5
6
7
cheerfulness, friendliness and kindness of a heart are the part of the soul 
who have been the art of the philosophers, and which the one 
won't say, which is it the higher the and with religion of the frences. 
the life of the spirit among the most continuess of the 
strengther of the sense the conscience of men of precisely before enough 
presumption, and can mankind, and something the conceptions, the 
subjection of the sense and suffering and the
1
2
3
4
5
6
7
8
9
cheerfulness, friendliness and kindness of a heart are spiritual by the 
ciuture for the 
entalled is, he astraged, or errors to our you idstood--and it needs, 
to think by spars to whole the amvives of the newoatly, prefectly 
raals! it was 
name, for example but voludd atu-especity"--or rank onee, or even all 
"solett increessic of the world and 
implussional tragedy experience, transf, or insiderar,--must hast 
if desires of the strubction is be stronges
Listing 8.8. Loading the pretrained Inception V3 model
1
2
3
4
from keras.applications import inception_v3 
from keras import backend as K 
 
K.set_learning_phase(0) 
1

5
6
7
 
model = inception_v3.InceptionV3(weights='imagenet', 
                                 include_top=False)
2
Listing 8.9. Setting up the DeepDream con×guration
1
2
3
4
5
6
layer_contributions = { 
    'mixed2': 0.2, 
    'mixed3': 3., 
    'mixed4': 2., 
    'mixed5': 1.5, 
}
1
Listing 8.10. De×ning the loss to be maximized
1
2
3
4
5
6
7
8
9
layer_dict = dict([(layer.name, layer) for layer in model.layers]) 
 
loss = K.variable(0.) 
for layer_name in layer_contributions: 
    coeff = layer_contributions[layer_name] 
    activation = layer_dict[layer_name].output 
 
    scaling = K.prod(K.cast(K.shape(activation), 'float32')) 
    loss += coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling
1
2
3
4
Listing 8.11. Gradient-ascent process
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
dream = model.input 
 
grads = K.gradients(loss, dream)[0] 
 
grads /= K.maximum(K.mean(K.abs(grads)), 1e-7) 
 
outputs = [loss, grads] 
fetch_loss_and_grads = K.function([dream], outputs) 
 
def eval_loss_and_grads(x): 
    outs = fetch_loss_and_grads([x]) 
    loss_value = outs[0] 
    grad_values = outs[1] 
    return loss_value, grad_values 
 
def gradient_ascent(x, iterations, step, max_loss=None): 
    for i in range(iterations): 
        loss_value, grad_values = eval_loss_and_grads(x) 
        if max_loss is not None and loss_value > max_loss: 
            break 
        print('...Loss value at', i, ':', loss_value) 
        x += step * grad_values 
    return x
1
2
3
4
5

Figure 8.4. The DeepDream process: successive scales of spatial processing (octaves)
and detail reinjection upon upscaling
Listing 8.12. Running gradient ascent over different successive scales
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
import numpy as np 
''' Playing with these hyperparameters will let you achieve new effects. ''' 
step = 0.01 
num_octave = 3 
octave_scale = 1.4 
iterations = 20 
max_loss = 10. 
base_image_path = '...' 
img = preprocess_image(base_image_path) 
original_shape = img.shape[1:3] 
successive_shapes = [original_shape] 
for i in range(1, num_octave): 
    shape = tuple([int(dim / (octave_scale ** i))  
        for dim in original_shape]) 
    successive_shapes.append(shape) 
successive_shapes = successive_shapes[::-1] 
original_img = np.copy(img) 
shrunk_original_img = resize_img(img, successive_shapes[0])  
for shape in successive_shapes: 
    print('Processing image shape', shape) 
    img = resize_img(img, shape) 
    img = gradient_ascent(img, 
                          iterations=iterations, 
                          step=step, 
                          max_loss=max_loss) 
    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape) 
    same_size_original = resize_img(original_img, shape) 
    lost_detail = same_size_original - upscaled_shrunk_original_img 
    img += lost_detail 
    shrunk_original_img = resize_img(original_img, shape) 
    save_img(img, fname='dream_at_scale_' + str(shape) + '.png') 
save_img(img, fname='final_dream.png')
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17

Figure 8.5. Running the DeepDream code on an example image
Figure 8.6. Trying a range of DeepDream con×gurations on an example image
Listing 8.13. Auxiliary functions
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
import scipy 
from keras.preprocessing import image 
 
def resize_img(img, size): 
    img = np.copy(img) 
    factors = (1, 
               float(size[0]) / img.shape[1], 
               float(size[1]) / img.shape[2], 
               1) 
    return scipy.ndimage.zoom(img, factors, order=1) 
 
def save_img(img, fname): 
    pil_img = deprocess_image(np.copy(img)) 
    scipy.misc.imsave(fname, pil_img) 
 
def preprocess_image(image_path): 
    img = image.load_img(image_path) 
    img = image.img_to_array(img) 
    img = np.expand_dims(img, axis=0) 
    img = inception_v3.preprocess_input(img) 
    return img 
 
def deprocess_image(x): 
    if K.image_data_format() == 'channels_first': 
        x = x.reshape((3, x.shape[2], x.shape[3])) 
        x = x.transpose((1, 2, 0)) 
    else: 
        x = x.reshape((x.shape[1], x.shape[2], 3)) 
    x /= 2. 
    x += 0.5 
    x *= 255. 
    x = np.clip(x, 0, 255).astype('uint8') 
    return x
1
2
3

Figure 8.7. A style transfer example
1
2
loss = distance(style(reference_image) - style(generated_image)) + 
       distance(content(original_image) - content(generated_image))
Listing 8.14. De×ning initial variables
1
2
3
4
5
6
7
from keras.preprocessing.image import load_img, img_to_array 
 
target_image_path = 'img/portrait.jpg' 
style_reference_image_path = 'img/transfer_style_reference.jpg' 
 
width, height = load_img(target_image_path).size 
1
2
3

8 img_height = 400 
img_width = int(width * img_height / height)
Listing 8.15. Auxiliary functions
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
import numpy as np 
from keras.applications import vgg19 
 
def preprocess_image(image_path): 
    img = load_img(image_path, target_size=(img_height, img_width)) 
    img = img_to_array(img) 
    img = np.expand_dims(img, axis=0) 
    img = vgg19.preprocess_input(img) 
    return img 
 
def deprocess_image(x): 
    x[:, :, 0] += 103.939 
    x[:, :, 1] += 116.779 
    x[:, :, 2] += 123.68 
    x = x[:, :, ::-1] 
    x = np.clip(x, 0, 255).astype('uint8') 
    return x
1
2
Listing 8.16. Loading the pretrained VGG19 network and applying it to the three images
1
2
3
4
5
6
7
8
9
10
11
12
13
14
from keras import backend as K 
 
target_image = K.constant(preprocess_image(target_image_path)) 
style_reference_image = K.constant(preprocess_image(style_reference_image_path)) 
combination_image = K.placeholder((1, img_height, img_width, 3)) 
 
input_tensor = K.concatenate([target_image, 
                              style_reference_image, 
                              combination_image], axis=0) 
 
model = vgg19.VGG19(input_tensor=input_tensor, 
                    weights='imagenet', 
                    include_top=False) 
print('Model loaded.')
1
2
3
Listing 8.17. Content loss
1
2
def content_loss(base, combination): 
    return K.sum(K.square(combination - base))

Listing 8.18. Style loss
1
2
3
4
5
6
7
8
9
10
11
def gram_matrix(x): 
    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1))) 
    gram = K.dot(features, K.transpose(features)) 
    return gram 
 
def style_loss(style, combination): 
    S = gram_matrix(style) 
    C = gram_matrix(combination) 
    channels = 3 
    size = img_height * img_width 
    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))
Listing 8.19. Total variation loss
1
2
3
4
5
6
7
8
def total_variation_loss(x): 
    a = K.square( 
        x[:, :img_height - 1, :img_width - 1, :] - 
        x[:, 1:, :img_width - 1, :]) 
    b = K.square( 
        x[:, :img_height - 1, :img_width - 1, :] - 
        x[:, :img_height - 1, 1:, :]) 
    return K.sum(K.pow(a + b, 1.25))
Listing 8.20. De×ning the ×nal loss that you’ll minimize
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
outputs_dict = dict([(layer.name, layer.output) for layer in model.layers]) 
content_layer = 'block5_conv2' 
style_layers = ['block1_conv1', 
                'block2_conv1', 
                'block3_conv1', 
                'block4_conv1', 
                'block5_conv1'] 
total_variation_weight = 1e-4 
style_weight = 1. 
content_weight = 0.025 
 
loss = K.variable(0.) 
layer_features = outputs_dict[content_layer] 
target_image_features = layer_features[0, :, :, :] 
combination_features = layer_features[2, :, :, :] 
loss += content_weight * content_loss(target_image_features, 
                                      combination_features) 
for layer_name in style_layers: 
    layer_features = outputs_dict[layer_name] 
    style_reference_features = layer_features[1, :, :, :] 
    combination_features = layer_features[2, :, :, :] 
    sl = style_loss(style_reference_features, combination_features) 
    loss += (style_weight / len(style_layers)) * sl 
 
loss += total_variation_weight * total_variation_loss(combination_image)
1
2
3
4
5
6
7
8

Listing 8.21. Setting up the gradient-descent process
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
grads = K.gradients(loss, combination_image)[0] 
 
fetch_loss_and_grads = K.function([combination_image], [loss, grads]) 
 
class Evaluator(object): 
 
    def __init__(self): 
        self.loss_value = None 
        self.grads_values = None 
 
    def loss(self, x): 
        assert self.loss_value is None 
        x = x.reshape((1, img_height, img_width, 3)) 
        outs = fetch_loss_and_grads([x]) 
        loss_value = outs[0] 
        grad_values = outs[1].flatten().astype('float64') 
        self.loss_value = loss_value 
        self.grad_values = grad_values 
        return self.loss_value 
 
    def grads(self, x): 
        assert self.loss_value is not None 
        grad_values = np.copy(self.grad_values) 
        self.loss_value = None 
        self.grad_values = None 
        return grad_values 
 
evaluator = Evaluator()
1
2
3
Listing 8.22. Style-transfer loop
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
from scipy.optimize import fmin_l_bfgs_b 
from scipy.misc import imsave 
import time 
 
result_prefix = 'my_result' 
iterations = 20 
 
x = preprocess_image(target_image_path) 
x = x.flatten() 
for i in range(iterations): 
    print('Start of iteration', i) 
    start_time = time.time() 
    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, 
                                     x, 
                                     fprime=evaluator.grads, 
                                     maxfun=20) 
    print('Current loss value:', min_val) 
    img = x.copy().reshape((img_height, img_width, 3)) 
    img = deprocess_image(img) 
    fname = result_prefix + '_at_iteration_%d.png' % i 
    imsave(fname, img) 
    print('Image saved as', fname) 
    end_time = time.time() 
    print('Iteration %d completed in %ds' % (i, end_time - start_time))
1
2
3
4

Figure 8.8. Some example results
Figure 8.9. Learning a latent vector space of images, and using it to sample new images

Figure 8.10. A continuous space of faces generated by Tom White using VAEs
Figure 8.11. The smile vector

Figure 8.12. An autoencoder: mapping an input x  to a compressed representation and
then decoding it back as x'
Figure 8.13. A VAE maps an image to two vectors, z_mean  and z_log_sigma ,
which de×ne a probability distribution over the latent space, used to sample a latent
point to decode.
1
2
3
4
5
6
7
z_mean, z_log_variance = encoder(input_img) 
 
z = z_mean + exp(z_log_variance) * epsilon 
 
reconstructed_img = decoder(z) 
 
model = Model(input_img, reconstructed_img)
1
2
3
4
Listing 8.23. VAE encoder network
1
2
3
4
5
6
7
8
9
10
11
12
13
import keras 
from keras import layers 
from keras import backend as K 
from keras.models import Model 
import numpy as np 
 
img_shape = (28, 28, 1) 
batch_size = 16 
latent_dim = 2 
 
input_img = keras.Input(shape=img_shape) 
 
x = layers.Conv2D(32, 3, 
1

14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
                  padding='same', activation='relu')(input_img) 
x = layers.Conv2D(64, 3, 
                  padding='same', activation='relu', 
                  strides=(2, 2))(x) 
x = layers.Conv2D(64, 3, 
                  padding='same', activation='relu')(x) 
x = layers.Conv2D(64, 3, 
                  padding='same', activation='relu')(x) 
shape_before_flattening = K.int_shape(x) 
 
x = layers.Flatten()(x) 
x = layers.Dense(32, activation='relu')(x) 
 
z_mean = layers.Dense(latent_dim)(x) 
z_log_var = layers.Dense(latent_dim)(x)
2
Listing 8.24. Latent-space-sampling function
1
2
3
4
5
6
7
def sampling(args): 
    z_mean, z_log_var = args 
    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), 
                              mean=0., stddev=1.) 
    return z_mean + K.exp(z_log_var) * epsilon 
 
z = layers.Lambda(sampling)([z_mean, z_log_var])
Listing 8.25. VAE decoder network, mapping latent space points to images
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
decoder_input = layers.Input(K.int_shape(z)[1:]) 
 
x = layers.Dense(np.prod(shape_before_flattening[1:]), 
                 activation='relu')(decoder_input) 
 
x = layers.Reshape(shape_before_flattening[1:])(x) 
x = layers.Conv2DTranspose(32, 3, 
                           padding='same', 
                           activation='relu', 
                           strides=(2, 2))(x) 
x = layers.Conv2D(1, 3, 
                  padding='same', 
                  activation='sigmoid')(x) 
 
decoder = Model(decoder_input, x) 
 
z_decoded = decoder(z)
1
2
3
4
5
6
Listing 8.26. Custom layer used to compute the VAE loss
1
2
class CustomVariationalLayer(keras.layers.Layer): 
 

3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
    def vae_loss(self, x, z_decoded): 
        x = K.flatten(x) 
        z_decoded = K.flatten(z_decoded) 
        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded) 
        kl_loss = -5e-4 * K.mean( 
            1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1) 
        return K.mean(xent_loss + kl_loss) 
 
    def call(self, inputs): 
        x = inputs[0] 
        z_decoded = inputs[1] 
        loss = self.vae_loss(x, z_decoded) 
        self.add_loss(loss, inputs=inputs) 
        return x 
 
y = CustomVariationalLayer()([input_img, z_decoded])
1
2
3
Listing 8.27. Training the VAE
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
from keras.datasets import mnist 
 
vae = Model(input_img, y) 
vae.compile(optimizer='rmsprop', loss=None) 
vae.summary() 
 
(x_train, _), (x_test, y_test) = mnist.load_data() 
 
x_train = x_train.astype('float32') / 255. 
x_train = x_train.reshape(x_train.shape + (1,)) 
x_test = x_test.astype('float32') / 255. 
x_test = x_test.reshape(x_test.shape + (1,)) 
 
vae.fit(x=x_train, y=None, 
        shuffle=True, 
        epochs=10, 
        batch_size=batch_size, 
        validation_data=(x_test, None))
Listing 8.28. Sampling a grid of points from the 2D latent space and decoding them to
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
import matplotlib.pyplot as plt 
from scipy.stats import norm 
 
n = 15 
digit_size = 28 
figure = np.zeros((digit_size * n, digit_size * n)) 
grid_x = norm.ppf(np.linspace(0.05, 0.95, n)) 
grid_y = norm.ppf(np.linspace(0.05, 0.95, n)) 
 
for i, yi in enumerate(grid_x): 
    for j, xi in enumerate(grid_y): 
        z_sample = np.array([[xi, yi]]) 
        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2) 
        x_decoded = decoder.predict(z_sample, batch_size=batch_size) 
        digit = x_decoded[0].reshape(digit_size, digit_size) 
        figure[i * digit_size: (i + 1) * digit_size, 
               j * digit_size: (j + 1) * digit_size] = digit 
1
2
3
4
5

Figure 8.14. Grid of digits decoded from the latent space
Figure 8.15. A generator transforms random latent vectors into images, and a
discriminator seeks to tell real images from generated ones. The generator is trained to
fool the discriminator.
Figure 8.16. Latent space dwellers. Images generated by Mike Tyka using a multistaged
GAN trained on a dataset of faces (www.miketyka.com).
18
19
20
21
 
plt.figure(figsize=(10, 10)) 
plt.imshow(figure, cmap='Greys_r') 
plt.show()

Figure 8.17. Checkerboard artifacts caused by mismatching strides and kernel sizes,
resulting in unequal pixel-space coverage: one of the many gotchas of GANs
Listing 8.29. GAN generator network
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
import keras 
from keras import layers 
import numpy as np 
 
latent_dim = 32 
height = 32 
width = 32 
channels = 3 
 
generator_input = keras.Input(shape=(latent_dim,)) 
 
x = layers.Dense(128 * 16 * 16)(generator_input) 
x = layers.LeakyReLU()(x) 
x = layers.Reshape((16, 16, 128))(x) 
 
x = layers.Conv2D(256, 5, padding='same')(x) 
x = layers.LeakyReLU()(x) 
 
x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x) 
x = layers.LeakyReLU()(x) 
 
x = layers.Conv2D(256, 5, padding='same')(x) 
x = layers.LeakyReLU()(x) 
x = layers.Conv2D(256, 5, padding='same')(x) 
x = layers.LeakyReLU()(x) 
 
x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x) 
generator = keras.models.Model(generator_input, x)                   #3 
generator.summary()
1
2
3
3
4

Listing 8.30. The GAN discriminator network
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
discriminator_input = layers.Input(shape=(height, width, channels)) 
x = layers.Conv2D(128, 3)(discriminator_input) 
x = layers.LeakyReLU()(x) 
x = layers.Conv2D(128, 4, strides=2)(x) 
x = layers.LeakyReLU()(x) 
x = layers.Conv2D(128, 4, strides=2)(x) 
x = layers.LeakyReLU()(x) 
x = layers.Conv2D(128, 4, strides=2)(x) 
x = layers.LeakyReLU()(x) 
x = layers.Flatten()(x) 
 
x = layers.Dropout(0.4)(x) 
 
x = layers.Dense(1, activation='sigmoid')(x) 
 
discriminator = keras.models.Model(discriminator_input, x) 
discriminator.summary() 
 
discriminator_optimizer = keras.optimizers.RMSprop( 
    lr=0.0008, 
    clipvalue=1.0, 
    decay=1e-8) 
discriminator.compile(optimizer=discriminator_optimizer, 
                     loss='binary_crossentropy')
1
2
3
4
5
Listing 8.31. Adversarial network
1
2
3
4
5
6
7
8
discriminator.trainable = False 
 
gan_input = keras.Input(shape=(latent_dim,)) 
gan_output = discriminator(generator(gan_input)) 
gan = keras.models.Model(gan_input, gan_output) 
 
gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8) 
gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')
1
Listing 8.32. Implementing GAN training
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
import os 
from keras.preprocessing import image 
 
(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data() 
 
x_train = x_train[y_train.flatten() == 6] 
 
x_train = x_train.reshape( 
    (x_train.shape[0],) + 
    (height, width, channels)).astype('float32') / 255. 
 
iterations = 10000 
batch_size = 20 
save_dir = 'your_dir' 
 
1
2
3
4

Figure 8.18. Play the discriminator: in each row, two images were dreamed up by the
GAN, and one image comes from the training set. Can you tell them apart? (Answers:
the real images in each column are middle, top, bottom, middle.)
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
start = 0 
for step in range(iterations): 
    random_latent_vectors = np.random.normal(size=(batch_size, 
                                            latent_dim)) 
 
    generated_images = generator.predict(random_latent_vectors) 
 
    stop = start + batch_size 
    real_images = x_train[start: stop] 
    combined_images = np.concatenate([generated_images, real_images]) 
 
    labels = np.concatenate([np.ones((batch_size, 1)), 
                             np.zeros((batch_size, 1))]) 
    labels += 0.05 * np.random.random(labels.shape) 
 
    d_loss = discriminator.train_on_batch(combined_images, labels) 
 
    random_latent_vectors = np.random.normal(size=(batch_size, 
                                            latent_dim)) 
 
    misleading_targets = np.zeros((batch_size, 1)) 
 
    a_loss = gan.train_on_batch(random_latent_vectors, 
                                misleading_targets) 
 
    start += batch_size 
    if start > len(x_train) - batch_size: 
      start = 0 
    if step % 100 == 0: 
        gan.save_weights('gan.h5') 
 
        print('discriminator loss:', d_loss) 
        print('adversarial loss:', a_loss) 
 
        img = image.array_to_img(generated_images[0] * 255., scale=False) 
        img.save(os.path.join(save_dir, 
                      'generated_frog' + str(step) + '.png')) 
 
        img = image.array_to_img(real_images[0] * 255., scale=False) 
        img.save(os.path.join(save_dir, 
                      'real_frog' + str(step) + '.png'))
5
6
7
8
9
10
11
12
13
14
15
16
17
18


CHAPTER 9
1
2
3
4
5
6
7
8
9
from keras import models 
from keras import layers 
 
model = models.Sequential() 
model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,))) 
model.add(layers.Dense(32, activation='relu')) 
model.add(layers.Dense(1, activation='sigmoid')) 
 
model.compile(optimizer='rmsprop', loss='binary_crossentropy')
1
2
3
4
5
6
model = models.Sequential() 
model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,))) 
model.add(layers.Dense(32, activation='relu')) 
model.add(layers.Dense(num_classes, activation='softmax')) 
 
model.compile(optimizer='rmsprop', loss='categorical_crossentropy')
1
2
3
4
5
6
model = models.Sequential() 
model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,))) 
model.add(layers.Dense(32, activation='relu')) 
model.add(layers.Dense(num_classes, activation='sigmoid')) 
 
model.compile(optimizer='rmsprop', loss='binary_crossentropy')
1
2
3
4
5
6
model = models.Sequential() 
model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,))) 
model.add(layers.Dense(32, activation='relu')) 
model.add(layers.Dense(num_values)) 
 
model.compile(optimizer='rmsprop', loss='mse')
1
2
3
4
model = models.Sequential() 
model.add(layers.SeparableConv2D(32, 3, activation='relu', 
                                  input_shape=(height, width, channels))) 
model.add(layers.SeparableConv2D(64, 3, activation='relu')) 

Figure 9.1. Failure of an image-captioning system based on deep learning
5
6
7
8
9
10
11
12
13
14
15
16
17
18
model.add(layers.MaxPooling2D(2)) 
 
model.add(layers.SeparableConv2D(64, 3, activation='relu')) 
model.add(layers.SeparableConv2D(128, 3, activation='relu')) 
model.add(layers.MaxPooling2D(2)) 
 
model.add(layers.SeparableConv2D(64, 3, activation='relu')) 
model.add(layers.SeparableConv2D(128, 3, activation='relu')) 
model.add(layers.GlobalAveragePooling2D()) 
 
model.add(layers.Dense(32, activation='relu')) 
model.add(layers.Dense(num_classes, activation='softmax')) 
 
model.compile(optimizer='rmsprop', loss='categorical_crossentropy')
1
2
3
4
5
model = models.Sequential() 
model.add(layers.LSTM(32, input_shape=(num_timesteps, num_features))) 
model.add(layers.Dense(num_classes, activation='sigmoid')) 
 
50model.compile(optimizer='rmsprop', loss='binary_crossentropy')
1
2
3
4
5
6
7
8
model = models.Sequential() 
model.add(layers.LSTM(32, return_sequences=True, 
               input_shape=(num_timesteps, num_features))) 
model.add(layers.LSTM(32, return_sequences=True)) 
model.add(layers.LSTM(32)) 
model.add(layers.Dense(num_classes, activation='sigmoid')) 
 
model.compile(optimizer='rmsprop', loss='binary_crossentropy')

Figure 9.2. An adversarial example: imperceptible changes in an image can upend a
model’s classi×cation of the image.
Figure 9.3. Current machine-learning models: like a dim image in a mirror
Figure 9.4. Local generalization vs. extreme generalization

Figure 9.5. A learned program relying on both geometric primitives (pattern
recognition, intuition) and algorithmic primitives (reasoning, search, memory)
Figure 9.6. A meta-learner capable of quickly developing task-speci×c models using
reusable primitives (both algorithmic and geometric), thus achieving extreme
generalization

