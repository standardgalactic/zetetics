A free energy principle for generic quantum
systems
Chris Fieldsaâˆ—, Karl Fristonb, James F. Glazebrookc,d and Michael Levine
a 23 Rue des Lavandi`eres, 11160 Caunes Minervois, FRANCE
b Wellcome Centre for Human Neuroimaging, University College London,
London, WC1N 3AR, UK
c Department of Mathematics and Computer Science,
Eastern Illinois University, Charleston, IL 61920 USA
d Adjunct Faculty, Department of Mathematics,
University of Illinois at Urbana-Champaign, Urbana, IL 61801 USA
e Allen Discovery Center at Tufts University, Medford, MA 02155 USA
January 3, 2022
Abstract
The Free Energy Principle (FEP) states that under suitable conditions of weak coupling,
random dynamical systems with suï¬ƒcient degrees of freedom will behave so as to min-
imize an upper bound, formalized as a variational free energy, on surprisal (a.k.a., self-
information). This upper bound can be read as a Bayesian prediction error. Equivalently,
its negative is a lower bound on Bayesian model evidence (a.k.a., marginal likelihood). In
short, certain random dynamical systems evince a kind of self-evidencing. Here, we re-
formulate the FEP in the formal setting of spacetime-background free, scale-free quantum
information theory. We show how generic quantum systems can be regarded as observers,
which with the standard freedom of choice assumption become agents capable of assigning
semantics to observational outcomes. We show how such agents minimize Bayesian predic-
tion error in environments characterized by uncertainty, insuï¬ƒcient learning, and quantum
contextuality. We show that in its quantum-theoretic formulation, the FEP is asymptot-
ically equivalent to the Principle of Unitarity.
Based on these results, we suggest that
biological systems employ quantum coherence as a computational resource and â€“ implicitly
â€“ as a communication resource. We summarize a number of problems for future research,
âˆ—Corresponding author at: 23 Rue des Lavandi`eres, 11160 Caunes Minervois, FRANCE; E-mail address:
ï¬eldsres@gmail.com
1
arXiv:2112.15242v1  [quant-ph]  30 Dec 2021

particularly involving the resources required for classical communication and for detecting
and responding to quantum context switches.
Contents
1
Introduction
3
2
Physical interaction as information exchange
5
2.1
What is â€œquantumâ€? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
2.2
Unitarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
2.3
Separability and holographic encoding
. . . . . . . . . . . . . . . . . . . . .
7
2.4
Reference frames
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
2.5
Symmetry breaking, decoherence, and agency
. . . . . . . . . . . . . . . . .
12
2.6
Channel theory of QRFs . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
3
Repeated measurements and system identiï¬cation
20
3.1
Memory, time, and coarse-graining
. . . . . . . . . . . . . . . . . . . . . . .
20
3.2
Learning and generative models . . . . . . . . . . . . . . . . . . . . . . . . .
24
3.3
Identifying and measuring systems embedded in E . . . . . . . . . . . . . . .
25
3.4
Noncommutativity and context-switching . . . . . . . . . . . . . . . . . . . .
28
4
FEP for generic quantum systems
30
4.1
Deï¬ning VFE for quantum systems . . . . . . . . . . . . . . . . . . . . . . .
30
4.2
Sources of VFE for quantum systems . . . . . . . . . . . . . . . . . . . . . .
31
4.3
Asymptotic behavior of the FEP
. . . . . . . . . . . . . . . . . . . . . . . .
34
5
Discussion
37
5.1
High-level overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
5.2
Summary of results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
5.3
Applications to biological cognition . . . . . . . . . . . . . . . . . . . . . . .
40
5.4
Predictions and open questions
. . . . . . . . . . . . . . . . . . . . . . . . .
42
2

1
Introduction
Since its introduction as a theory of brain function [1, 2, 3, 4], the variational Free Energy
Principle (FEP) has been extended into an explanatory framework for living systems at all
scales [5, 6, 7, 8, 9], and shown to characterize, in its most general form, all random dy-
namical systems that remain measurable, and hence identiï¬able as persistent and separable
entities, over macroscopic times [10]. To summarize, it is shown in [10] that any system that
has a non-equilibrium steady state (NESS) solution to its density dynamics i) possesses an
internal dynamics that is conditionally independent of the dynamics of its environment, and
ii) will continuously â€œself-evidenceâ€ by returning its state to (the vicinity of) its NESS. The
FEP is the statement that any measurable, i.e. bounded and macroscopically persistent,
system will behave so as to satisfy these requirements. Self-organization, the FEP tells
us, is not a rare, special case, but a ubiquitous feature of physical systems with suï¬ƒcient
dynamical stability to be called â€œthings.â€ All â€œthings,â€ in particular, self-organize Markov
blankets (MBs; see [11] for an informal review) comprising â€œsensoryâ€ states that encode
incoming information and thus mediate the inï¬‚uence of external states on internal states,
and â€œactiveâ€ states that encode outgoing information and thus mediate the inï¬‚uence of
internal states on external states. This partitioning of â€œthingsâ€ into internal and MB states
means that every â€œthingâ€ can be construed as a certain kind of â€œparticleâ€ â€“ a particle that
is in open exchange with external states via its MB. In short, the MB of any such â€œparticleâ€
underwrites conditional independence between its internal states and the external states of
its environment by localizing and thereby restricting information exchange; hence, the MB
can be viewed as separating internal from external states, while mediating their exchange.
As noted in [10], generalizing the FEP to characterize the behavior of all â€œthingsâ€ substan-
tialy weakens the traditional distinction between â€œcognitionâ€ and merely â€œphysicalâ€ dynam-
ics, and hence weakens the even deeper, pretheoretical [12] distinction between â€œagentsâ€ and
mere â€œobjectsâ€ [13]. Treating physical interaction as information exchange â€“ â€œobservationâ€
of the environment followed by â€œactionâ€ upon it â€“ redescribes the â€œmechanicalâ€ process
of returning to the NESS â€“ as a random global (a.k.a., pullback) attractor â€“ in terms of
inference. This can be read as â€œactive inferenceâ€ [4, 5, 6, 10] in which the existential in-
tegrity of the MB, and hence of the â€œselfâ€ â€“ â€œworldâ€ distinction [14], can be maintained
in the face of environmental ï¬‚uctuations by changing internal states (via sensory states:
c.f., perception) or changing external states (via active states: c.f., action). It refocuses the
discussion, in other words, from abstract trajectories (or ï¬‚ows) in state space to the MB
itself as a concrete locus of â€œidentityâ€ in the form of persistent measurability, and hence of
â€œself-evidencingâ€ via active inference to maintain that identity.
The idea that all physical systems, including the environment at large, can be considered
â€œobserversâ€ that also act on their surroundings to â€œprepareâ€ them for subsequent obser-
vations has become commonplace in quantum theory, largely replacing the â€œwave-function
collapseâ€ postulate of traditional quantum mechanics [15] with interaction-induced deco-
herence (i.e., dissipation of quantum coherence) as the generator of classical information
3

[16, 17, 18, 19, 20].1 Indeed while quantum theory was originally developed â€“ and is still
widely regarded â€“ as a theory speciï¬cally applicable at the atomic scale and below, since
the pioneering work of Wheeler [24], Feynman [25], and Deutsch [26], it has, over the past
few decades, been reformulated as a scale-free information theory [27, 28, 29, 30, 31, 32] and
is increasingly viewed as a theory of the process of observation itself [33, 34, 35, 36, 37, 38].
This newer understanding of quantum theory ï¬ts comfortably with the generalization of
the FEP, and hence of self-evidencing and active inference, to all â€œthingsâ€ as outlined in
[10], and with the general view of observation under uncertainty as inference.
In what follows, we take the natural next step from [10], formulating the FEP as a generic
principle of quantum information theory. We show, in particular, that the FEP emerges
naturally in any setting in which an â€œagentâ€ or â€œparticleâ€ deploys quantum reference frames
(QRFs), namely, physical systems that give observational outcomes an operational seman-
tics [39, 40], to identify and characterize the states of other systems in its environment.
This reformulation removes two central assumptions of the formulation in terms of random
dynamical systems employed in [10]: the assumption of a spacetime embedding (or â€œback-
groundâ€ in quantum-theoretic language) and the assumption of â€œobjectiveâ€ or observer-
independent randomness. It further reveals a deep relationship between the ideas of local
ergodicity and system identiï¬ability, and hence the idea of â€œthingnessâ€ highlighted in [10],
and the quantum-theoretic idea of separability, i.e., the absence of quantum entanglement,
between physical systems.
Any quantum system that can be distinguished from its environment over time can, there-
fore, be regarded as self-organizing and self-evidencing as described in [10]. We then show
that when the FEP is taken to an asymptotic limit, it drives systems away from separabil-
ity towards entanglement, and hence towards a supraclassical statistical coupling between
each â€œthingâ€ and its environment â€“ between the observer and the observed. In this, the
FEP reproduces the Principle of Unitary, i.e. the Principle of Conservation of Information,
which similarly drives all interacting systems asymptotically toward entanglement. Hence
the FEP is, in an important sense, an alternative statement of the Principle of Unitarity,
the most fundamental principle of quantum theory. It therefore applies to a much broader
array of systems than would fall under an intuitive idea of â€œthingness,â€ e.g. to quantum
ï¬elds, and applies in principle from the Planck scale to cosmological scales. Formulating
the FEP as a generic principle of quantum information theory thus substantially expands
the range of systems to which â€œcognitiveâ€ or information-processing concepts reasonably
apply.
We begin by reviewing in Â§2 the basic principles of quantum theory from an information-
1Variants of quantum theory that postulate a physical collapse mechanism also invoke interaction, e.g.
with gravity or a â€œnoiseâ€ ï¬eld, to generate classicality; see [21] for review. We will not discuss here the
question of â€œinterpretationsâ€ of quantum theory; see [22] for a thorough review and [23] for a more recent
taxonomy highlighting fundamental assumptions. Both decoherence and entanglement, in particular, have
diï¬€erent physical meanings in diï¬€erent interpretations, although their mathematical representations and
observable eï¬€ects are interpretation-independent. Our general approach can be viewed as replacing the
â€œmeasurement problemâ€ â€“ that such interpretations are designed to solve â€“ with an explicit, quantum-
informational theory of measurement. This theory is, we show, just the theory of the FEP.
4

theoretic perspective, limiting the formalism to focus on the physical meaning of the theory.
Using the category-theoretic [41, 42] formalism of Channel Theory â€“ developed by Barwise
and Seligman [43] to formalize the operational semantics of natural languages â€“ we develop
a generic formal representation of QRFs and show how the noncommutativity of QRFs
induces quantum contextuality [44, 45], a nonclassical eï¬€ect demonstrating the presence of
entanglement between distinct physical degrees of freedom. We develop in Â§3 a generic,
formal description of how one quantum system identiï¬es another quantum system as a
persistent entity â€“ a â€œthingâ€ â€“ and measures, records, and compares its states by deploying
speciï¬c sequences of QRFs. This identiï¬cation and measurement process depends critically
on breaking thermodynamic symmetries, and therefore on system-speciï¬c ï¬‚ows of energy.
These sections together provide a representation of generic quantum systems as observers,
or in the language of Gell-Mann and Hartle [46] â€œinformation gathering and using systemsâ€
(IGUSs), that is free of scale and spacetime embedding (i.e. â€œbackgroundâ€) dependent as-
sumptions. It also treats all probabilities as observer-relative. We then show in Â§4 how the
FEP emerges in this setting and analyze its asymptotic behavior; in particular, we consider
how the FEP addresses the fundamental problem posed by quantum context switches. We
conclude in Â§5 by discussing the relevance of these results to a scale-independent under-
standing of biological systems as â€œparticlesâ€ that interact with other â€œparticles,â€ whether
these are other organisms, â€œobjects,â€ or an undiï¬€erentiated environment. We consider in
particular the circumstances in which this â€œparticleâ€ nature can break down, and suggest
that well-designed experiments may be expected to detect quantum context switches or vio-
lations of the Bell [47] or Leggett-Garg [48] inequalities, any of which indicate entanglement,
by macroscopic biological systems under ordinary conditions.
2
Physical interaction as information exchange
2.1
What is â€œquantumâ€?
When physical interaction is viewed as information exchange, why it is â€œquantumâ€ becomes
obvious: the fundamental quantum of information is one bit, one unit of entropy, that
one system exchanges with another. One bit, one quantum of information, is the answer
to one yes/no question. Planckâ€™s quantum of action â„is then naturally regarded as the
action (energy Â· time) required to obtain one bit via any physical interaction. The energy
required to irreversibly obtain one bit, i.e., to receive and irreversibly record one bit, is given
by Landauerâ€™s Principle as ln 2 kBT, with kB Boltzmannâ€™s constant and T temperature
[49, 50, 51]. The (minimum) time to irreversibly obtain one bit is then â„/ ln 2 kBT, roughly
30 fs at 310 K. For comparison, the thermal dissipation time (in 3d space) due to time-
energy uncertainty is Ï€â„/2 ln 2 kBT [52], roughly 50 fs at 310 K. These values deï¬ne a
minimal timescale for biologically-relevant, irreversible information processing, roughly the
timescale of molecular-bond vibrational modes [53] and an order of magnitude shorter than
photon-capture timescales [54].
5

Viewing all physical interaction as information exchange â€“ and the bit as the fundamental
â€œquantumâ€ of information â€“ has the immediate consequence that interaction discretizes
the state spaces of all observable degrees of freedom. Given a set of mutually-commuting,
binary-valued observables, i.e., quantum operators implementing yes/no questions as de-
scribed below, a discrete state space for any observed system is constructed by assigning
a basis vector to each possible outcome (yes or no, +1 or -1) for each observable. These
are ï¬nite-dimensional Hilbert spaces. While Hilbert spaces with either ï¬nite or inï¬nite
dimension are introduced ad hoc in traditional quantum mechanics [15], ï¬nite-dimensional
Hilbert spaces emerge naturally from the process of observation in the information theory.
As Fuchs puts it, inï¬nite dimensional Hilbert spaces are, from an information perspective,
merely a â€œuseful artiï¬ceâ€ permitting computation with diï¬€erential equations [55]. Hence
in what follows, all Hilbert space dimensions will be ï¬nite dimensional.
2.2
Unitarity
The fundamental axiom of quantum theory is unitarity, again introduced ad hoc in tradi-
tional treatments. If U is an isolated system, its time propagator is a unitary operator:
PU = eâˆ’(Ä±/â„)HUt,
(1)
where HU is the â€œinternalâ€ Hamiltonian (i.e. energy) operator satisfying the SchrÂ¨odinger
equation:
Ä±â„(âˆ‚/âˆ‚t)|U(t)âŸ©= HU|U(t)âŸ©,
(2)
where |U(t)âŸ©is the time-dependent state of U. When HU and hence PU are time-invariant,
solutions have the form:
|U(t)âŸ©= eâˆ’Ä±Ï•t|U(0)âŸ©,
(3)
where |U(0)âŸ©is an initial (t = 0) state. This Eq. (3) describes a phase rotation by Ï•
per unit time t in the Hilbert space HU; the initial state |U(0)âŸ©is preserved â€œup toâ€ this
phase rotation. The dimension d = dim(HU) is the number of basis vectors of HU and is, by
deï¬nition, the quantity (in bits) of observable information encoded by the state |U(0)âŸ©. The
number d is clearly invariant under the phase rotation given by Eq. (3); hence the phase
rotation is not an observable. Unitary evolution as deï¬ned by Eq. (1) is, therefore, simply
evolution over time that conserves observable information. Hence, the fundamental axiom
of quantum theory is not ad hoc at all: it is the Principle that observable information, like
energy, is neither created nor destroyed by physical processes.
The appearance of the â€œimaginaryâ€ unit Ä± in Eq. (1) - (3) and the use of Hilbert spaces
over the complex ï¬eld C are standard in quantum theory but are often considered a mere
convenience; compelling arguments for their necessity have only been developed recently
[56, 57]. They can, however, be given a straightforward interpretation: they emphasize
6

that the phase rotation implemented by PU is not an observable dynamics and that the
â€œexternalâ€ time t in these equations is not an observable, clock-referenced time.2 Indeed,
no classical information â€“ no observational outcome â€“ has yet been obtained in the setting
deï¬ned by Eq.
(1) - (3).
Characterizing observation as a process generating classical
outcomes as a result requires an additional assumption of separability as outlined below.
2.3
Separability and holographic encoding
Let U be an isolated system as above, and let U = AB be a bipartite decomposition of U,
i.e. the Hilbert space HU = HA âŠ—HB. At a ï¬xed time t, any such bipartite decomposition
can be characterized by an entanglement entropy:
S(|ABâŸ©) = âˆ’
X
i
|Î±i|2 log2(|Î±i|2),
(4)
where the coeï¬ƒcients Î±i are the Schmidt coeï¬ƒcients given by:
|ABâŸ©=
m
X
i
Î±i|uiâŸ©A|viâŸ©B,
(5)
where the label B is assigned so that m = dim(HB) â‰¤dim(HA) and the |uiâŸ©A and |viâŸ©B are
orthonormal states of A and B respectively. The entanglement entropy S(|ABâŸ©) is a mutual
information measure that detects quantum correlation or â€œcoherenceâ€ between A and B.
If S(|ABâŸ©) = 0, the joint state factors as |ABâŸ©= |AâŸ©|BâŸ©and hence is separable; otherwise
the joint state is entangled. Separable states are also called decoherent; entangled states are
coherent. Heuristically, a joint state |ABâŸ©is separable if the individual states |AâŸ©and |BâŸ©
can be determined by independent measurements. If |ABâŸ©is entangled, interactions with A
and B, including measurements, are no longer independent; this lack of independence can
be detected [47] and is the empirical basis for demonstrating entanglement [60] as discussed
in Â§5.4 below.
Extending Eq. (4) to all times and all bipartite decompositions of U gives a representation
of the time-dependent entanglement structure of U. As t â†’âˆthe unitary dynamics of
Eq. (1) will drive U toward maximal entanglement, i.e. S(|ABâŸ©) â†’dim(HB) for every
bipartite decomposition U = AB; where, here again, B is taken to be the smaller of the two
systems. At maximum entanglement, the joint-state evolution can be considered a simple
rotation as in Eq. (3).
Given a decomposition U = AB, the Hamiltonian can be decomposed as HU = HA +
HB +HAB, where HAB represents the A-B interaction. Provided HAB is weak compared to
2Imagine, for an example, listening to a constant tone that has no beginning or end. Writing time as
Ä±t with t real allows Minkowski spacetime to be given a Galilean (++++) metric. See [58] for a discussion
of Ä± as a shorthand for converting classical to quantum observables, and [59] for a more intuitive view of
â€œrotation by Ä±â€ as a formal operation.
7

the internal interactions HA and HB and the time period of interest is short compared to
timescale in which PU drives the joint system to maximal entanglement, A and B can be
considered at least approximately separable, i.e. S(|ABâŸ©) â‰ˆ0 so |ABâŸ©â‰ˆ|AâŸ©|BâŸ©. In this
case, |AâŸ©and |BâŸ©can be considered individually well-deï¬ned, and bases can be chosen for
A and B so that:
HAB = Î²kkBT k
N
X
i
Î±k
i M k
i ,
(6)
where k =
A or B, the M k
i are N Hermitian operators with eigenvalues in {âˆ’1, 1},
the Î±k
i âˆˆ[0, 1] are such that PN
i Î±k
i = 1, and Î²k â‰¥ln 2 is an inverse measure of kâ€™s
thermodynamic eï¬ƒciency that depends on the internal dynamics Hk [37, 38, 61, 62]. For
ï¬xed k, the operators M k
i clearly must commute, i.e. [M k
i , M k
j ] = M k
i M k
j âˆ’M k
j M k
i = 0
for all i, j; hence HAB is swap-symmetric under the permutation group SN for each k. The
thermodynamic factor Î²kkBT k in Eq. (6) assures compliance with Landauerâ€™s Principle,
i.e., assures that the per-bit free-energy cost of classical bit erasure is paid on each cycle
(see [37, 38] for discussion). As U = AB is by assumption isolated, conservation of energy
requires Î²AT A = Î²BT B. As discussed in [13], Eq. (6) can be written in ordinary narrative
form as:
Physical Interaction = (Thermodynamics) Â· (Yes/No questions).
This formulation emphasizes what quantum theory is about: the process of obtaining in-
formation. Obtaining information from B requires, in particular, that A acts on B by
asking questions. As Wheeler [63] puts it, â€œNo question? No Answer!â€ All inference in this
framework is active inference; Eq. (6) does not allow â€œpassive perceptionâ€ to be a physical
process.
In contrast to classical theories of information transfer, in which physical tokens encoding
bits are transmitted between observers at diï¬€erent locations, Eq. (6) involves no assump-
tions about spacetime, objects, or motions. It is strictly topological: given separability, it
identiï¬es a boundary B between A and B at which HAB is deï¬ned. This boundary is the
â€œchannelâ€ via which A and B exchange strings of bits, ordered by the order of the operators
M k
i in Eq. (6). Each of these bit strings encodes one eigenvalue of HAB; as HAB has units
of energy, these eigenvalues are measures of the energy Î²kkBT k exchanged between A and
B during each cycle of interaction. Any time variation of HAB is, therefore, time variation
of the energy exchanged and can be written:
HAB(t) = Î²k(t)kBT k
N
X
i
Î±k
i (t)M k
i ,
(7)
where Î±k
i (t) and Î²k(t) are subject to the conditions on Î±k
i and Î²k given above. As noted for
Eq. (1) - (3) above, the time t in Eq. (7) is not an observable, clock-referenced time. We
8

will for simplicity consider HAB to be t-invariant; this is eï¬€ectively an adiabatic assumption.
An observer-speciï¬c, measurable time will be introduced in Â§3.1 below.
Boundaries such as B that function as information channels are, when embedded in space-
time and constrained by general covariance,3 holographic screens that limit communication
between the regions they separate to the bits that they encode [64, 65, 66, 67]. Interactions
between separable systems, i.e. interactions of the form given by Eq. (6) or (7) can, with-
out loss of generality, be regarded as deï¬ned at such holographic screens [38, 62, 68]. The
operators M k
i can, in this case, be regarded as â€œpreparationâ€ and â€œmeasurementâ€ operators
that alternately write and read bit values encoded on B. The SN swap symmetry of the
M k
i for each k means that the bits can be prepared, and then measured, in any order and
hence independently, provided preparation precedes measurement for each bit (such swaps
change the â€œzero pointâ€ of the energy scale and are undetectable). The screen B is, as
is any holographic screen, an ancillary construct, not â€œpart ofâ€ either A or B. It can be
physically realized as an ancillary array of noninteracting qubits (quantum bits) with which
A and B interact as illustrated in Fig. 1.
3Eï¬€ectively, this is a requirement for consistency with both Special and General Relativity.
9

Figure 1: A holographic screen B separating systems A and B with an interaction HAB
given by Eq. (6) can be realized by an ancillary array of noninteracting qubits that are
alternately prepared by A (B) and then measured by B (A). Qubits are depicted as Bloch
spheres [27]. There is no requirement that A and B share preparation and measurement
bases, i.e. QRFs. Adapted from [38] Fig. 1, CC-BY license.
The holographic screen B has an obvious interpretation in the language of the FEP and
active inference: it implements the MB separating A from B [69]. â€œActiveâ€ and â€œsensoryâ€
states of the MB correspond to preparation and measurement implemented by the M k
i ; as
the interaction HAB is perfectly symmetrical, Aâ€™s actions are Bâ€™s sensations and vice-versa.
As bit strings on B encode energy eigenvalues, what either A or B â€œsensesâ€ is energy.
The assumption of separability plays, in this setting, the role played by the assumption
of measurability in [10]: it guarantees that systems A and B have well-deï¬ned individual
states. These states are at informational equilibrium; A and B exchange bits one-for-one.
They are not, however, at thermal equilibrium, T A = T B unless their thermodynamic
eï¬ƒciencies Î²A = Î²B. Hence, when sampled and averaged over macroscopic times, the pure
states |AâŸ©and |BâŸ©become (mixed) NESS densities ÏA and ÏB.
2.4
Reference frames
The isolation of U = AB assures that the Aâˆ’B channel is free of classical, environmentally-
induced noise. The preparation and measurement operations M A
i and M B
i
that A and B
10

use to communicate, however, are deï¬ned with respect to and hence depend on the bases
|uiâŸ©and |viâŸ©of the Hilbert spaces HA and HB respectively. In the qubit realization shown in
Fig. 1, the M A
i and M B
i are z-spin operators and so depend on the â€œchoicesâ€ of z axis zA and
zB. Provided A and B are separable, and assuming that there are no â€œsuperdeterministâ€ a
priori correlations, zA and zB are uncorrelated; this is the â€œfree choiceâ€ assumption. Free
choice is often claimed to be essential to science as a practice [70, 71]; if it characterizes any
bounded system, consistency with quantum theory and special relativity together requires
that it must characterize all such systems [72]. Free choice of a basis introduces quantum
â€œnoiseâ€ that is indistinguishable, observationally, from classical noise. Suppose B encodes
| â†‘âŸ©on qubit q, using zB to deï¬ne the â€œupâ€ direction. If zA = zB, Aâ€™s measured state
|qâŸ©A = | â†‘âŸ©, i.e. Aâ€™s probability PA(| â†‘âŸ©) = 1. If, however, zA is chosen perpendicular to zB,
|qâŸ©A = (| â†‘âŸ©âˆ’| â†“âŸ©)/
âˆš
2 and PA(| â†‘âŸ©) = PA(| â†“âŸ©) = 0.5.
The z axis in Fig. 1 is a reference frame; free choice of the z axis generalizes to free choice
of the reference frame for encoding each qubit on B. While in classical physics, reference
frames are typically thought of as fully-speciï¬able abstractions, in quantum theory reference
frames must be considered physical systems â€“ QRFs â€“ that encode unmeasurable quantum
phase information. A QRF cannot, therefore, be fully speciï¬ed by any ï¬nite bit string; it
is â€œnonfungibleâ€ in the terminology of [40]. In the setting of Fig. 1, the z axis deployed
by a A (B) determines how A (B) prepares and then measures the states of the qubits
composing B. We can, in particular, consider A to be isolated from B during the time
interval â€œbetweenâ€ preparation and measurement steps, an interval shorter than the natural
timescale of the interaction HAB. During such a short interval, we abuse the notation only
slightly by writing:
Pk : |BâŸ©meas 7â†’|BâŸ©prep
(8)
where k = A or B, i.e. by thinking of the internal propagators PA and PB, and hence
the dynamics HA and HB, as computing the next preparation of the qubits on B from
their most recent measured state. The idea of â€œcomputationâ€ â€“ or more properly, of the
physical system A (B) implementing a computation â€“ is the standard notion, reviewed in
[73]: in brief, we can say a system A implements a computation of a function F if an
â€œinterpretationâ€ map IF exists such that the diagram:
âŸ¨bitsâŸ©i
F
/ âŸ¨bitsâŸ©i+1
|BâŸ©i
IF
O
PA
/ |BâŸ©i+1
IF
O
(9)
commutes, i.e. F IF = IFPA for every â€œstepâ€ i â†’i + 1, where here âŸ¨bitsâŸ©is a ï¬nite bit
string and i â†’i + 1 generalizes meas â†’prep in Eq. (8). A QRF, e.g. a z axis as in Fig.
1, implemented by PA eï¬€ectively â€œchoosesâ€ the computational basis that renders the string
âŸ¨bitsâŸ©well-deï¬ned. This is the same choice of basis that renders the M A
i
well-deï¬ned in
Eq. (6). Hence, we can identify the interpretation map IF with the QRF that renders the
11

function F well-deï¬ned; to simplify the notation, we will use boldface F to label the QRF
itself. The choice of QRF F and hence of computational basis is functional or semantic, not
physical; both HA and HAB are invariant under changes of basis for HA. It is worth noting
explicitly that the choice of F is not encoded on B and is not observationally accessible to
B. Indeed, the general question of whether an arbitrary system A implements a QRF F is
Turing undecidable by Riceâ€™s theorem [74]; see [38] for discussion.
As illustrated by the z axes in Fig. 1, the role of any QRF in a measurement setting is to
assure that measured values of some degree of freedom can be compared with each other
and hence given an operational meaning [75]. Meter sticks, clocks, gyroscopes, and the
Earth with its gravitational and magnetic ï¬elds serve this function, and are commonplace
laboratory QRFs. As described in detail in Â§3.3 below, recognizing an external object, such
as a meter stick, as a QRF and using it as such requires that the observer in question
already implements a QRF for the relevant degree of freedom: an observer with no â€œinter-
nalâ€ ability to measure and compare lengths, for example, would ï¬nd a meter stick useless.
All QRFs can, therefore, be considered internal functional components of, or computations
implemented by, larger systems that allow measurements of, and assign operational seman-
tics to, one or more degrees of freedom external to the implementing system [61]. Shared
operational semantics across observers requires shared QRFs. The nonfungibility of QRFs
renders the question of QRF sharing in general Turing undecidable, again by Riceâ€™s theorem
[38], a result consistent with the general undecidability of language sharing [76].
2.5
Symmetry breaking, decoherence, and agency
We will be interested in what follows in quantum systems, considered to be observers, that
deploy one or more distinct QRFs to measure particular subsets of the bits encoded on
their boundaries/MBs, and that record the values of these bits to a memory that persists
for at least one measurement cycle and hence allows comparisons of the values obtained in
at least two sequential measurements. Such systems eï¬€ectively decompose the holographic
screen B into three disjoint sectors that we will label E the observed environment, F
the unobserved environment, and Y the memory sector, respectively. Equivalently, they
eï¬€ectively decompose the set M k
i of operators into three disjoint subsets (dropping the
redundant index k) M E
i , M F
j , and M Y
l , respectively, with:
X =def dom({M X
i })
(10)
for each sector X. Assuming free choice of basis as above, this decomposition into sectors
can be regarded as freely chosen. Note that as B is the only locus of classical information in
the current formalism, any persistent classical memory must be a sector on B as discussed
in [13].
The assignment of operators to speciï¬c sectors breaks the SN swap symmetry of B [38].
As with choice of QRF, this is a functional or semantic symmetry breaking, not a physical
symmetry breaking; the assignment of bits on B to distinct sectors by HA has no eï¬€ect
12

on the deï¬nition of HAB given by Eq. (6). Holding HAB ï¬xed, we can vary the internal
interaction HA, and hence the implementation of QRFs as computations, so as to either
satisfy SN symmetry or break it. Note that varying HA in this way is equivalent to varying
HU âˆ’HB; such variation is undetectable at the boundary B. This insensitivity of B to
variation in the internal or joint dynamics of A and B is the core physical meaning of the
holographic principle [64, 65, 66, 67].
Breaking the SN swap symmetry on B renders the sector states |EâŸ©, |FâŸ©, and |Y âŸ©, each of
which corresponds to an encoded bit string, separable and hence mutually decoherent [38].
As emphasized in [77, 78, 79, 80, 81, 82] among others, decoherence is always observer-
relative, even when the â€œobserverâ€ is an ambient environment. Hence decoherence due to
swap-symmetry breaking is decoherence relative to A; the change-of-basis invariance of HAB
renders Aâ€™s sector boundaries undetectable by B. Given free choice of QRFs, moreover,
Bâ€™s sector boundaries, if any, may be diï¬€erent from Aâ€™s. Mismatched sector boundaries
between A and B generate apparent â€œhidden variablesâ€ and hence variational free energy
[4, 5, 6, 10] as discussed in Â§4.2 below. For the present purposes, what is important is that
deploying a QRF sensitive to only some degrees of freedom of B (i.e. sensitive to only some
bit values encoded on B) breaks the swap symmetry on B and creates a decoherent sector
as deï¬ned by Eq. (10).
Breaking the swap symmetry on B allows diï¬€erent sectors to have diï¬€erent thermodynamic
eï¬ƒciences, i.e. breaking swap symmetry allows breaking thermodynamic symmetry. This
can be made evident by rewriting Eq. (6) for A in terms of sectors X as:
HAB =
X
X
Î²XkBT A X
iâˆˆiX
Î±A
i M A
i ,
(11)
where iX is the set of indices of operators M A
i assigned to sector X. Note that this sym-
metry breaking does not change the total energy exchanged (i.e. the eigenvalue of HAB),
it only allocates the energy diï¬€erently to diï¬€erent sectors. This allows sectors to perform
diï¬€erent thermodynamic roles; in particular, it allows the unobserved environment sector
F to serve as a source of free energy to â€“ and a sink of waste heat from â€“ the observed
environment sector E and the memory sector Y [37, 38].
The bits encoded on F are,
therefore, noninformative to A and are traced (eï¬€ectively, marginalised and averaged) over
when deï¬ning information-bearing states of A. Mathematically, this trace operation can
be viewed as implementing decoherence as discussed in [16, 17, 18, 19, 20], i.e., as imple-
menting the sector boundary of F. Assigning this thermodynamic function to F enables
thermodynamically-expensive classical information processing of bits encoded on E and Y ,
including maintaining the stability of bit values written to Y as discussed in Â§3.1 below. It
therefore allows E and Y to have distinct semantics.
Free choice of a decomposition of B into sectors with diï¬€erent QRF-induced semantics is
indicative of agency. Hence, we can deï¬ne:
Deï¬nition 1. A (nontrivial) agent is a system A with an internal dynamics HA that breaks
the SN swap symmetry of its boundary/MB B.
13

We can consider a system with a swap-symmetric boundary as shown in Fig. 1 a trivial
agent. Trivial agents correspond to â€œinertâ€ systems with functionally-insigniï¬cant internal
states, and hence no internal information-processing capacity, as discussed in [10].
All
nontrivial agents are â€œcognitiveâ€ systems that engage in active inference.
Before proceeding to further characterize these sectors or to consider the imposition of ad-
ditional structure on E by further QRFs, we brieï¬‚y review below the speciï¬cation of QRFs
using the generic formalism of Channel Theory [43]. This formalism will enable characteri-
zation of the asymptotic behavior of the FEP and of context-switching as a mechanism for
minimizing FEP as discussed below in Â§4.3 below.
2.6
Channel theory of QRFs
Channel Theory [43] is an application of the category theory of Chu spaces, spaces of
semantic relations exempliï¬ed by object â€“ attribute tables [83, 84, 85]. Indeed Channel
Theory can be regarded as deï¬ning a category Chan that is isomorphic to the category
Chu(Set, K) (for short, Chu) of Chu spaces. While conceptually simple, Channel Theory
is surprisingly rich, providing both a natural representation of conditional probabilities
and formal criteria for operator commutativity and quantum contextuality [86, 87] (for a
logico-philosophical perspective on the properties of semantic coherence in Chan, see e.g.
[88]). Furthermore, it provides an implementation-independent formal language for writing
functional speciï¬cations of QRFs as computations.
The central idea of Channel Theory is that of a â€œclassiï¬erâ€ that relates tokens in some
language to types in that language. We can deï¬ne a classiï¬er as an object in Chan as
follows:
Deï¬nition 2. A classiï¬er A is a triple âŸ¨Tok(A), Typ(A), |=AâŸ©where Tok(A) is a set of
â€œtokensâ€, Typ(A) is a set of â€œtypesâ€, and |=A is a â€œclassiï¬cationâ€ relating tokens to types.
The classiï¬cation |=A can, in general, be valued in any set K without assumed structure
(as is the case for Chu spaces); for simplicity, we will consider only binary classiï¬cations.
Morphisms in Chan, called â€œinfomorphismsâ€ between these objects are then given by the
following:
Deï¬nition 3. Given two classiï¬ers A = âŸ¨Tok(A), Typ(A), |=AâŸ©and B = âŸ¨Tok(B), Typ(B), |=B
âŸ©, an infomorphism f : A â†’B is a pair of maps âˆ’â†’f : Tok(B) â†’Tok(A) and â†âˆ’f : Typ(A) â†’
Typ(B) such that âˆ€b âˆˆTok(B) and âˆ€a âˆˆTyp(A), âˆ’â†’f (b) |=A a if and only if b |=B
â†âˆ’f (a).
This last deï¬nition can be represented schematically as the requirement that the following
diagram commutes:
Typ(A)
âˆ’
â†’
f / Typ(B)
|=B
Tok(A)
|=A
Tok(B)
â†
âˆ’
f
o
(12)
14

An infomorphism f : A â†’B is, eï¬€ectively, a map relating the semantic constraints imposed
by the classiï¬cation |=A to those imposed by |=B.
We are, in practice, interested in collections of infomorphisms than construct complex
semantic constraints out of simple ones; these will allow us to specify QRFs as hierarchies
of semantic constraints. Given a ï¬nite collection Ai of classiï¬ers, we can represent this
construction process as a ï¬nite, commuting cocone diagram (CCD) depicting a ï¬‚ow of
infomorphisms sending inputs to a core Câ€² that is the category-theoretic colimit of the
underlying classiï¬ers, i.e., is the apex of the maximally general diagram of this form over
the Ai, if a unique such maximum exists:
Câ€²
A1
f1
8
g12
/ A2
f2
O
g23
/ . . . Ak
fk
g
(13)
The cocone core Câ€² is itself a classiï¬er that encodes, via the incoming infomorphisms fi,
the conjunction of the semantic constraints imposed by the Ai.
There is a dual construction to this CCD, namely a commuting ï¬nite cone diagram (CD)
of infomorphisms on the same classiï¬ers, where all arrows are reversed. In this case the
core of the (dual) channel is the category-theoretic limit of all possible downward-going
structure-preserving maps to the classiï¬ers Ai. Hence, we can deï¬ne the central idea of a
ï¬nite, commuting cone-cocone diagram (CCCD) as consisting of both a cone and a cocone
on a single ï¬nite set of classiï¬ers Ai linked by infomorphisms as depicted below:
Câ€²
A1
f1
6
g12
g21
/ A2
o
f2
O
g23
g32
/ . . . Ak
o
fk
i
Dâ€²
h1
h
h2
O
hk
5
(14)
If the cores Câ€² = Dâ€², we can also represent the CCCD as:
A1
g12
g21
/ A2
o
g23
g32
/ . . . Ak
o
Câ€²
h1
h
h2
O
hk
5
A1
f1
6
g12
g21
/ A2
o
f2
O
g23
g32
/ . . . Ak
o
fk
i
(15)
This diagram is naturally interpreted as reconstructing the semantics of the Ai via the
â€œcombinedâ€ representation Câ€². Generalizing Diagram (15) by letting Câ€² be the limit of a
15

smaller set of classiï¬ers Aâ€²
1, . . . Aâ€²
j, j < k, we can write:
Aâ€²
1
gâ€²
12
gâ€²
21
/ Aâ€²
2
o
gâ€²
23
gâ€²
32
/ . . . Aâ€²
j
o
Câ€²
hâ€²
1
h
hâ€²
2
O
hâ€²
j
5
A1
f1
6
g12
g21
/ A2
o
f2
O
g23
g32
/ . . . Ak
o
fk
i
(16)
Diagram (16) provides a natural representation of coarse-graining the semantics of Ai via
Câ€² into a compressed representation Aâ€²
i. We will employ this generalization in Â§3.1 below
to specify the writing of coarse-grained records of observational outcomes to the memory
sector Y .
Diagrams such as (13) â€“ (16) can be generalized into hierarchical networks by adding
intermediate layers of classiï¬ers and appropriate maps; when this is done, they clearly
resemble artiï¬cial neural networks (ANNs), and in the â€œbowtieâ€ form of Diagrams (15)
and (16), variational autoencoders (VAEs) [86].
The core Câ€² in (15) and (16) can be
viewed as both an â€œanswerâ€ computed by the fi from inputs to the Ai and, dually, as an
â€œinstructionâ€ propagated by the hi (or in Diagram (16), the hâ€²
i), to drive outputs from the
Ai (or in Diagram (16), the Aâ€²
i). Such dual input/output behavior is exactly the behavior
of a QRF. We can, therefore, represent any QRF as a CCCD â€œattachedâ€ to a subset of
measurement operators M A
k , . . . M A
n by maps that identify the binary eigenvalues of the
M A
i with binary inputs to the Ai as illustrated in Fig. 2.
16

Figure 2: Attaching a CCCD to a subset of measurement operators M A
k , . . . M A
n by iden-
tifying the binary eigenvalues of the M A
i
with binary inputs to the Ai. Only the CCD
direction arrows are shown for simplicity; adding equivalent but reversed arrows completes
the CCCD. The CCCD speciï¬es a function computed by the internal dynamics PA, i.e. a
QRF deployed by A. Adapted from [38] Fig. 3; CC-BY license.
Thus far we have considered binary CCCDs, corresponding to Boolean ANNs or VAEs or to
QRFs imposing Boolean constraints. Mapping a CCCD to an arbitrary ANN or VAE that
computes some function of interest F just requires assigning probabilities, i.e. â€œweightsâ€
to the infomorphisms in a way that respects the Kolmogorov axioms [86, 87]. We can then
treat the computed function F from network inputs to network outputs as an arbitrary
probabilistic QRF, or as suggested by Diagram (16), a pair of coupled QRFs that process
some â€œsensoryâ€ signal received by the Ai and write the result to a lower-dimensional and
17

hence coarse-grained â€œmemoryâ€ via the Aâ€²
i. A QRF so deï¬ned is naturally interpreted as
performing hierarchical Bayesian inference [86, 87]; see [89, 90] for applications to human
cognition.
To assign probabilities to infomorphisms, it is convenient to add the structure of a â€œlocal
logicâ€ L(A) relating subsets of tokens and types to each classiï¬er A [43]. To do this, we
deï¬ne an â€œimplicationâ€ relation between subsets of types:
Deï¬nition 4. Two subsets M, N âŠ†Typ(A) are related by a sequent M |=A N if âˆ€x âˆˆ
Tok(A), x |=A M â‡’x |=A N.
Via the sequent relation, the local logic L(A) eï¬€ectively arranges the types of A into a
hierarchy; any classiï¬er can be extended to a local logic in this way by adding types as
needed. Considering all classiï¬ers to be extended to local logics, Diagrams (13) â€“ (16) can
be considered diagrams of local logics by requiring each of the infomorphisms to be a â€œlogic
infomorphismâ€ that preserves the sequent structure. In general, given an information ï¬‚ow
channel:
âˆ’â†’AÎ±âˆ’1 âˆ’â†’AÎ± âˆ’â†’AÎ±+1 âˆ’â†’Â· Â· Â·
(17)
the semantic content can be extended by postulating local logics LÎ± = L(AÎ±) generated by
the corresponding classiï¬ers AÎ± (assumed, in principle, to be in relationship to a (regular)
theory associated to the individual AÎ±, as speciï¬ed in [43, Ch 9] (cf. [91]) and reviewed in
[87, Appendix A]), so to obtain a ï¬‚ow of logic infomorphisms:
Â· Â· Â· âˆ’â†’LÎ±âˆ’1 âˆ’â†’LÎ± âˆ’â†’LÎ±+1 âˆ’â†’Â· Â· Â·
(18)
which we can take to comprise comprise a CCD as in Eq. (13). Logic infomorphisms are,
eï¬€ectively, embeddings of type hierarchies; Diagrams (15) and (16) can be viewed as em-
beddings into a â€œtop-levelâ€ type hierarchy Câ€² that assigns an overall semantics to its inputs,
followed by encodings of this top-level hierarchy into some componential representation.
The local logic L(A) deï¬ned above is Boolean.
To extend the type hierarchy deï¬ned
by L(A) to a hierarchical Bayesian inference, we extend L(A) to a probabilistic logic by
relaxing the sequent relation to require only that if x |=A M, there is some probability
P(N|M) that x |=A N. We can then write:
M |=P
A N =def P(M|N)
(19)
and construct (extended, probabilistic) logic infomorphisms as above, requiring that they
preserve the conditional probabilities P(M|N) for all subsets M, N at each level of the
hierarchy.4
Traversing upwards in the hierarchy then imposes multiple conditioning on
each â€œlow-levelâ€ probability distribution; traversing downwards sequentially unpacks this
conditioning.
In fundamental Bayesian terms, M above can be regarded as a previous
event, whether observed or conjectured, and N as a currently observed datum, in which
4As pointed out in [93], it is instructive to see that Eq. (19) reveals how a conditional probability can
be used for interpreting the logical implication â€œâ‡’â€ as discussed in [96].
18

case P(M) becomes the prior, and P(N) the evidence, that together generate a prediction.
Given the likelihood P(N|M) as the conditional obtained from weakening the sequent via
Eq. (19), Bayesâ€™ theorem speciï¬es this conditional as the posterior:
P(M|N) = P(N|M)P(M)
P(N)
.
(20)
A brief example illustrates these principles as follows: consider arbitrary classiï¬ers A(a)
1 , . . . , A(e)
5
in some part of an information channel where (as in [87]) the classiï¬ers correspond to events
a, b, c, d, e, respectively, together with logic infomorphisms f13, . . . , f45 between them, in
which the sequents are relaxed to conditional probabilities via Eq. (19):
A(a)
1
f13
}
f14
!
A(b)
2
f24
}
A(c)
3
A(d)
4
f45

A(e)
5
(21)
Following e.g. [92], this particular channel then generates a joint probability distribution
given by:
p(abcde) = p(a)p(b)p(c|a)p(d|ab)p(e|d).
(22)
Putting these details within the framework of the above diagrams, a portion of a typical
CCD computing a hierarchical Bayesian inference from a set of (posterior) observations Ai
to an outcome Câ€² has the form:
Câ€²
A1
p10(Â·|Â·)
8
p12(Â·|Â·)
/ A2
p20(Â·|Â·)
O
p23(Â·|Â·)
/ . . . Ak
pk0(Â·|Â·)
g
(23)
In this formal setting, the diagram commutativity of Diagrams (13) â€“ (16), with probabilities
added as in Diagram (23) above, enforces Bayesian coherence: the probability associated
with any arrow U â†’V must equal the product of the probabilities associated with the
arrows on any other directed path from U to V.5
Any pair of subsets of the Ai have,
therefore, a well-deï¬ned joint probability distribution. As shown in [87], the converse is
also true. Letting A1, A2 . . . B and B, C1, . . . Ck be ï¬nite sets of classiï¬ers, we can state the
following [87, Thm. 7.1]:
5Probability spaces and conditional distributions can also be deï¬ned directly for Chu spaces as exhibited
in [87, Exs. 2.4, 2.5]. See [94] for an alternative representation of Bayesian inference and derivation of the
FEP using monodial categories and an operational formalism closely related to those employed in categorical
quantum theory [95].
19

Theorem 1. A well-deï¬ned joint probability distribution exists over subsets A1, A2 . . . B
and B, C1, . . . Ck of classiï¬ers if and only if the following diagram commutes:
C
C1
Ï†
7
C2
Ïˆ
g
A1
f1
8
/ A2
f2
O
/ . . . B
fB
g
gB
7
/ C1
g2
O
/ . . . Ck
gk
g
(24)
that is, if and only if there exist logic infomorphisms Ï†, Ïˆ and a classiï¬er C such that the
above diagram is a CCD.
Proof. See [87]. The key observation is that Ï† and/or Ïˆ can only fail to exist if the joint
probability distribution fails to exist.
The use of overlapping subsets of classiï¬ers in Theorem 1 mirrors the use of mutually-
noncommuting subsets of mutually-commuting observables in the canonical deï¬nition of
quantum contextuality [44, 45] and its extension to a purely statistical criterion of incom-
patibility between measurement contexts [97, 98]. How the deployment of overlapping but
mutually-noncommuting subsets of QRFs implements context-switching between pairs of
complementary observables â€“ such as position and momentum â€“ is discussed in Â§3.4 be-
low. How the FEP can drive context-switching as a component of active inference is then
discussed in Â§4.3 below.
Viewing commutativity â€“ and hence Bayesian coherence â€“ as fundamental to the deï¬nition
of measurement, and hence also to the deï¬nition of preparation or action on the environment
generally, suggests that the Born rule, i.e. that if a state:
|XâŸ©=
X
i
Î±i|xiâŸ©,
(25)
the probability of obtaining |xiâŸ©as an observational outcome is:
P(|xiâŸ©= |Î±i|2,
(26)
is a prescription for coherently assigning amplitudes Î±i to components |xiâŸ©, consistent with
the position advocated in [33, 35].
3
Repeated measurements and system identiï¬cation
3.1
Memory, time, and coarse-graining
The idea that a system must possess a (quasi-) NESS solution to its density dynamics â€“ and
hence be restricted to trajectories in its classical conï¬guration space that do not diverge
20

exponentially over time â€“ in order to be observable as a â€œthingâ€, immediately raises the
issues of time as measurable duration and of memory as persistent over measurable time.
As the simplest case, consider the NESS density ÏE of the observed environment sector E
of some agent A. The agent A can only detect changes in ÏE and employ them as bases
for inferences and actions if A can write time-ordered records [ÏE(tA)] to, and subsequently
read them from, the memory sector Y . Here tA is an A-speciï¬c time coordinate that must
be constructed. Persistence of the memory record [ÏE(tA)] between writing and reading
requires that it be â€œprotectedâ€ from environmental noise, i.e. from ongoing events in E;
hence if |Y âŸ©is the state encoding [ÏE(tA)], |Y âŸ©must vary only slowly under the action of HB.
In the notation of Eq. (6), â€œprotectionâ€ occurs if the coeï¬ƒcients Î±B
i of operators M B
i acting
on qubits within Y all have small magnitudes. We can, therefore, distinguish two classes
of actions by A on its boundary/MB B. Actions on E are â€œquestionsâ€ in Wheelerâ€™s [63]
sense; they provoke informative responses from B that can be used to develop a generative
model of HB as discussed below. Actions on Y are recordings that must remain relatively
stable to be useful. Stability of the memory sector Y against HB is a critical resource for
any system A capable of responding to environmental state changes, and hence of any A
capable of active inference. Heuristically, this is clearly evinced in active vision, where we
actively palpate the world, every 250 ms or so, to update our working memory Y ; i.e.,
update our (Bayesian) beliefs about the observed environment E.
The Second Law tells us that protecting any state against noise requires the expenditure
of free energy. Hence, any agent A is faced with a fundamental thermodynamic tradeoï¬€:
maintaining the stability of Y requires free energy sourced from the unobserved (traced over)
environmental sector F. For ï¬xed HAB, and hence ï¬xed B, expanding F to obtain more
free energy for Y requires shrinking E, i.e. â€œseeingâ€ less of the environment. The alternative
is to coarse-grain Y either in time or in space, i.e. in bit-string length. Which horn of this
thermodynamic trilemma a given system takes is determined by the QRFs it implements.
Classical manifestation of this trade-oï¬€are seen in many guises. For example, the intimate
relationship between the eï¬ƒciency of information transfer aï¬€orded by compression â€“ as
seen in minimum message length formulations of variational free energy [99, 100] â€“ through
to the minimisation of statistical complexity aï¬€orded by coarse-graining and quantisation
[101].
The simplest memory-write process is illustrated in cartoon form in Fig. 3. A state |EâŸ©, a
bit string of length dim(E), is constructed from one-bit operators M E
i
by a QRF E. It is
then written to the memory Y by a QRF Y, with free energy sourced from the remainder
of B, i.e.
from the unobserved sector F.
In the simplest case, the memory capacity
dim(Y ) = n dim(E) + log2 n where n is the number of distinguishable records. The log2 n
labels that allow records to be distinguished can, without loss of generality, be considered
to be an integer sequence of clock ticks i â†’i + 1, starting from i = 1. Hence, any memory
with more than one-record capacity deï¬nes a clock Gij, which we will see below must, in
general, be a groupoid operator [37].6 This clock is an internal time QRF that deï¬nes the
6Recall that a groupoid is a category in which the objects and arrows each comprise a set (as for a â€˜smallâ€™
category), and every arrow is invertible [102, 103]. A groupoid generalizes the group concept in so far that
21

time coordinate tA.
Figure 3: Cartoon illustration of QRFs required to write a readable memory of an observed
environmental state |EâŸ©. The QRFs E and Y read the state from E and write it to Y
respectively. The clock Gij is a time QRF that deï¬nes the time coordinate tA.
The thermodynamic trade-oï¬€faced by A is between dim(E), dim(Y ), and the sampling
time of states |EâŸ©, which determines the length of one clock tick and hence of one unit of tA.
As mentioned earlier, the minimum timescale for biological systems is set by the thermal
dissipation time to roughly 50 fs. Practical biological clocks run much more slowly; a clock
based on Gamma-band neural activity in mammalian cortex, for example, has a sampling
time of 10 â€“ 20 ms. The recorded record, in this case, is a sample from or average over
a time ensemble < |EâŸ©> of measured states, i.e., is a record [ÏE] of a coarse-grained
density. This record can be further compressed to achieve dim([ÏE]) < dim(E) and hence
dim(Y ) < n Â· dim(E) + log2 n.
With these QRFs, the memory read-compare-write cycle can be represented as in Fig. 4.
The classical record [ÏE(i)] written in the previous cycle is read by Y at â€œexternalâ€ (i.e. Eq.
(1) or (7)) time t. It is compared to the current measured state |E(t)âŸ©and a new record
[ÏE(j)] is written by Y at t+âˆ†t. This read-compare-write cycle advances the internal clock
Gij by one tick i â†’j. All QRFs together with the comparison function are implemented by
the former can admit â€œmultiple identitiesâ€ (the objects).
22

the internal dynamics PA. Formally, we can think of PA as a weighted sum of â€œall possible
pathsâ€ from the boundary state |B(t)âŸ©to the boundary state |B(t + âˆ†t)âŸ©as in Eq. (8)
[104]; see [105] for discussion.
Figure 4: Cartoon illustration of one memory read-compare-write cycle deï¬ning one tick
i â†’j of the internal clock Gij and requiring an interval âˆ†t of â€œexternalâ€ time t. All QRFs
and the comparison function are implemented by the quantum dynamics PA (block arrow).
Fig. 4 explicitly illustrates an important distinction between classical and quantum repre-
sentations of dynamics and hence between classical and quantum formulations of the FEP.
Classical physics assumes a spacetime embedding; hence the MB of any topologically-
connected system can be associated with a spatial boundary that follows a smooth space-
time trajectory. â€œInternalâ€ states of the system and the â€œinternalâ€ dynamics that operates
on those states to maintain a NESS are spatially localized inside this boundary, and are,
in particular, not exposed on the boundary. The current, quantum setting makes, in con-
trast, no assumptions about spacetime embedding as emphasized earlier. The boundary
B represents a Hilbert-space decomposition, not a â€œphysicalâ€ spacetime decomposition.
As B is the only locus of classical information, â€œinternalâ€ classical states, including all
classical memory records, are exposed on B. The assumption that these exposed states
are â€œprotectedâ€ from HB corresponds to the classical assumption of â€œself-evidencingâ€: that
maintaining the integrity of the MB as a spatial boundary enables the maintenance of the
NESS and vice-versa [10].
23

The true internal state of a quantum system A is the state |AâŸ©that remains independently
well-deï¬ned provided the joint state |ABâŸ©remains separable, i.e. provided the interaction
HAB can be written as Eq. (6). This internal state is â€œprotectedâ€ from HB by deï¬ni-
tion. Hence for quantum systems, â€œself-evidencingâ€ is logically equivalent to separability.
Classical memories are at risk of environmental perturbation, unless suï¬ƒcient free energy
is devoted to maintaining them. Quantum â€œmemoriesâ€ are encoded by the dynamics PA
and are at risk of environmental perturbation only if separability breaks down, i.e. if |ABâŸ©
becomes entangled.
With this non-spatial understanding of the â€œinternalâ€ states of a quantum system A with a
classical memory, both the quantum |A(t)âŸ©â†’|A(t+âˆ†t)âŸ©and the classical [ÏE(i)] â†’[ÏE(j)]
loops are internal to A. Hence, the (classical) integrated information Î¦(A) > 0 as deï¬ned in
Integrated Information Theory (IIT) [106], rendering A â€œconsciousâ€ and hence an â€œagentâ€
in the framework of IIT. Hence the notion of agency in IIT is consistent with that of
Deï¬nition 1.
3.2
Learning and generative models
Learning a generative model allowing predictions of the future behavior of E is straightfor-
ward in this setting. The prediction problem can be represented as follows:
[ÏE(1)], [ÏE(2)], . . . [ÏE(k âˆ’1)]
|
{z
}
Prior
, [ÏE(k)]
| {z }
Posterior
â†’[ÏE(k + 1)],
|
{z
}
Prediction
(27)
where [ÏE(1)], [ÏE(2)], . . . [ÏE(k âˆ’1)] are previous memory records, [ÏE(k)] is the current
record, and [ÏE(k + 1)] is the not-yet-obtained next record. The prior data can be re-
represented in three progressively more sophisticated ways:
1. As a probability distribution over the set of possible records, a discrete set of no more
than 2dim(E) elements.
2. As a probability distribution over the set of pairs ([ÏE(i)], [ÏE(i + 1)]) and hence as a
discrete Markov process.
3. As a map from probability distributions on records 1, 2, . . . i to probability distribu-
tions on records 1, 2, . . . i + 1 and hence as a discrete Markov kernel.
Representing the prior data by a discrete Markov kernel provides the greatest data com-
pression, at the cost of more sophisticated processing by PA.
The process of updating a Markov kernel MA
E(i) representing Aâ€™s prior data for E can be
formalized as:
L : (MA
E(i), [ÏE(i)]) 7â†’MA
E(i + 1),
(28)
24

where L is an operator of the form (function, data) â†’functionâ€², i.e. a learning operator.
Hence any system A that stores prior information using a data structure more space-eï¬ƒcient
than an explicit linked list can be considered to be learning.
As the records [ÏE(i)] are just bit strings and Bayesian coherence is guaranteed by the com-
mutativity of the operators composing the QRF Y, the sequence [ÏE(1)], [ÏE(2)], . . . [ÏE(k)]
can be represented by a â€œtrueâ€ Markov kernel ME(k) satisfying the following commutativity
constraint:
ÏE(i)
ME / ÏE(i + 1)
|B(t)âŸ©
E
O
PU/ |B(t + âˆ†t)âŸ©
E
O
(29)
where as before one â€œtickâ€ of tA corresponds to âˆ†t externally and the notation |BâŸ©indicates
the state of the qubit array encoded on B. At step k in Aâ€™s acquisition of state information
about E, therefore, Aâ€™s prediction error ErE for E is:
ErE(k) = d(MA
E(k), ME(k)),
(30)
where the d is the metric distance on Markov kernels. This deï¬nition is independent of L
and hence of the sources of Aâ€™s prediction errors.
3.3
Identifying and measuring systems embedded in E
We have so far considered only observers A that measure the states of their observed en-
vironments E without decomposing E into â€œsystemsâ€ that have their own speciï¬c states.
Such undiï¬€erentiated measurements of E plausibly characterize all biological systems that
interact with their environments primarily biochemically, instead of mechanically [107].
A bacterium measuring an ambient salt concentration, for example, does not assign the
concentration value to a speciï¬c object within the environment [13]. Animals as diverse
as arthropods, cephalopods, and vertebrates, however, detect and track the states of spe-
ciï¬c external â€œparticlesâ€ or objects, often other animals. In terms of theoretical biology,
this ability is either ancient, arising at least by the Cambrian explosion, or results from
convergent evolution in multiple distinct lineages.
The question of how an observer A distinguishes a system S from the environment ËœE, in
which S is embedded, is central to classical cybernetics [108, 109] and, under the rubric of
object persistence, to cognitive and developmental psychology [110, 111]. Here, ËœE indicates
the remainder of E when S is removed, i.e.
E = S ËœE.
While the question of how an
observer distinguishes an external system from its surrounding environment, prior to â€“ and
as a precondition for â€“ measuring some state of interest, is often neglected by physicists, it
imposes signiï¬cant thermodynamic and computational requirements on observers [112].
25

Distinguishing a system from its environment requires measurement, so it is naturally
formulated in the language of QRFs.
To set up some notation, we will consider any distinct, identiï¬ed system S to comprise two
components, S = PR, where P is the â€œpointerâ€ component that indicates some state |PâŸ©
(or density ÏP of time-averaged samples of |PâŸ©) of interest and R is a â€œreferenceâ€ component
that by maintaining a constant state |RâŸ©(or constant density ÏR of time-averaged samples
of |RâŸ©) allows S to be re-identiï¬ed while |PâŸ©varies. Identifying a laboratory apparatus by
monitoring a time-invariant reference state provides an example; see Fig. 5.
Figure 5: Identifying a system S requires identifying some proper component R that main-
tains a constant state |RâŸ©(or density of time-averaged samples ÏR) as the â€œpointerâ€ state
|PâŸ©(or density of time-averaged samples ÏP) of interest varies. Adapted from [37] Fig. 2,
CC-BY license.
Following the reasoning above, decomposing E into disjoint components E = PR ËœE is
deï¬ning subsets of operators {M E
i } = {M P
j } âŠ”{M R
k } âŠ”{M ËœE
l } where âŠ”indicates disjoint
union. We can then deï¬ne several QRFs:
26

P : P = dom({M P
j }) â†’|PâŸ©,
R : R = dom({M R
k }) â†’|RâŸ©,
ËœE : ËœE = dom({M
ËœE
l }) â†’| ËœEâŸ©,
(31)
with corresponding memory records [ÏP(i)], [ÏR(i)], and [Ï ËœE(i)]. As QRFs that prepare as
well as measure their assigned sectors of B, these QRFs P, R, and ËœE can be represented as
CCCDs with the symmetric form of Diagram (15). The processing pathway from a given
sector X to its associated memory record [ÏX] can, assuming a coarse-grained memory,
be represented as a CCCD with the asymmetric form of Diagram (16); the memory-read
to preparation of X pathway has the opposite asymmetry. Note that identiï¬ability of S
requires [ÏR(i)] = [ÏR(j)] for all i, j. Forgetting what someone looks like, for example, can
lead to re-identiï¬cation failure.
Measurements of P, R, and ËœE are of no use unless they are recorded. As above, Markov
kernels provide the most eï¬ƒcient data structure. The kernel MA
R must be constant to enable
system identiï¬cation. By analogy with Eq. (28), these kernels can be associated with a
learning operators LP, LR, and L ËœE; where there is no requirement that these employ the
same learning algorithm. The â€œtrueâ€ Markov kernel ME(i) can similarly be decomposed
into components, each of which must satisfy the commutativity constraint expressed by
Diagram (29):
ÏP
MP (i)/ ÏP(i + 1)
ÏR(i)
MR / ÏR(i + 1)
Ï ËœE(i)
ME / Ï ËœE(i + 1)
|B(t)âŸ©
P
O
PU/ |B(t + âˆ†t)âŸ©
P
O
|B(t)âŸ©
R
O
PU/ |B(t + âˆ†t)âŸ©
R
O
|B(t)âŸ©
ËœE
O
PU/ |B(t + âˆ†t)âŸ©
ËœE
O
(32)
Hence prediction errors for P, R, and ËœE can be deï¬ned as in Eq. (30). Failing to correctly
predict ÏR results in system-identiï¬cation failure and renders concurrent observations of ÏP
meaningless.
The â€œsystemsâ€ P, R, and ËœE are, clearly, just subsets of outcomes obtained by measuring
the qubits on Aâ€™s boundary/MB B; their states are, therefore, determined by the actions
of Bâ€™s encoding operators M B
i . As [M B
i , M B
j ] = 0 for all i, j by deï¬nition, R, P, and ËœE
must all be mutually separable and hence mutually decoherent; equivalently, R, P, and ËœE
must all mutually commute. Hence, A can regard R, P, and ËœE as â€œthingsâ€ with distinct
identities and states as required by [10]. It bears emphasis, however, that no spacetime
background has been assumed in writing Eq. (6), in deï¬ning B, or in deï¬ning any of the
sectors R, P, or ËœE. The â€œthingsâ€ R, P, and ËœE are not, therefore, observer-independent
in any sense, although observers deploying similar QRFs and able to communicate (i.e.
deploying QRFs that enable mutual recognition and communication) may agree as to their
27

states [35, 36].
The present formalism is, therefore, â€œsystem-freeâ€ in the sense of [34]
and hence represents measurements using external apparatus as fully device-independent.
While device independence is implied whenever an MB is invoked [11], classical formula-
tions of measurement interactions â€“ indeed, of perception generally â€“ tend nonetheless to
assume diï¬€erentiated external objects a priori, as Einsteinâ€™s famous insistence that the
Moon is there when no one is looking exempliï¬es [113]; see [114, 115, 116] for examples
from perceptual psychophysics. Evolutionary considerations argue against any assumption
of a priori objects or even Galilean invariances of motion [117, 118], consistent with the
background-independent approach taken here.
3.4
Noncommutativity and context-switching
As emphasized by Bohr almost 100 years ago [119], a ï¬nite quantum of action â„partitions
the set of all possible quantum measurement operators into a set of â€œcomplementaryâ€ non-
commuting pairs, the most well-known being position Ë†x and momentum Ë†p. These operators,
as well as all other operators acting on â€œsystemsâ€ with associated spacetime coordinates,
correspond in the current background-free framework to QRFs acting on sectors of B, i.e.,
on subsets of qubits as described above. Hence, noncommuting operators correspond to
noncommuting QRFs, as formalized by Theorem 1.
Two QRFs U and V can fail to commute only if the underlying measurement operators fail
to commute. However, as noted previously, any set of operators M k
i appearing in Eq. (6)
must all mutually commute. Switching between noncommuting QRFs U and V, therefore,
entails switching between a mutually-commuting operator set M A
i , of which the M U
j are a
subset, and a complementary mutually-commuting operator set OA
i , of which the OV
j are a
subset, where for at least some i, j, [M U
i , OV
j ] Ì¸= 0. This switch implements a basis rotation
on HAB, leaving its dimension N and its eigenvalues, the binary representations of which
are the bit strings encodable on B, both unchanged while replacing the amplitudes Î±A
i with
amplitudes Î»A
i so that Eq. (6) now reads, for A:
HAB = Î²AkBT A
N
X
i
Î»A
i OA
i .
(33)
In practice, we will be primarily interested in partial basis rotations in which the M A
i and
the OA
i substantially overlap, e.g. maintaining ï¬xed sectors F, ËœE and R while switching
between complementary pointer sectors as discussed below. Note that such basis rotations
have no eï¬€ect on B or its operators, so are undetectable, in principle, by B.
An observer A capable of switching between noncommuting QRFs must, to maintain an
operable memory, implement a clock that is invariant under basis rotations on HAB. If
measurements made at clock ticks i and j do not commute, however, the corresponding
clock operations will not commute; in particular Gij â—¦Gji Ì¸= Gji â—¦Gij where â—¦is operator
composition. It is for this reason that the Gij form a groupoid, and not a group [37]. From
a more practical perspective, noncommutativity forces tA to be unidirectional, and hence
28

memory records to be encoded irreversibly with an accompanying expenditure of free energy.
The internal clock Gij thus deï¬nes tA as an entropic time, consistent with the analysis in
[120]. Any observer A, therefore, observes a unidirectional ï¬‚ow of information from B and
of dissipated heat to B; hence any observer A conï¬rms the Second Law with respect to
its internal time tA. As A and B are completely symmetric by Eq. (6), B also conï¬rms
the Second Law with respect to tB, showing that the Second Law is observer-relative and
independent of the â€œexternalâ€ time t, consistent with the analysis in [121].
Switching between noncommuting QRFs while holding other QRFs constant, e.g., switch-
ing between interference (position) and which-path (momentum) measurements on an
interferometer identiï¬ed by a ï¬xed reference sector R, is switching between mutually-
noncommuting but overlapping sets of mutually-commuting operators as described in The-
orem 1 and is a canonical quantum context switch [44, 45]. Pointer-state observables are,
in particular, observables in context as deï¬ned in [87]: the state |PâŸ©of any pointer sector P
is measured in the context of the separable joint state |RâŸ©| ËœEâŸ©|FâŸ©, where the component |FâŸ©
is unobserved by deï¬nition. By Theorem 1, two sets of pointer operators M U
j and OV
j as
above, that deï¬ne alternative pointer sectors U and V by Eq. (10), are mutually-commuting
and hence co-deployable if and only if maps Ï† and Ïˆ exist such that the diagram:
C
C1
Ï†
7
C2
Ïˆ
g
U
f1
O
/ R ËœEF
g1
f
g2
8
/ V
f2
O
(34)
commutes. Here, we have replaced the explicit operators in Diagram (24) by their corre-
sponding sectors to simplify the notation. We can equally well interpret UF and V F as
contexts for the observation of sectors R and ËœE: in this case switching between U and
V â€”with the unobserved sector F held ï¬xed yields consistent probability distributions if
and only if Diagram (34) commutes.
If Diagram (34) fails to commute, then pointer-state observables are said to be non-co-
deployable. Non-commutativity of the CCD in (34) had been speciï¬ed in [87, Th. 7.1] in
terms of non-existence of a consistently deï¬nable joint probability distribution of condi-
tionals, such as for Diagram (23). This non-co-deployability of observables thus amounts
to occurrence of intrinsic (quantum) contextuality in relationship to (34).7
We will see in Â§4.2 below that context switching increases variational free energy (VFE)
by generating Bayesianâ€œprediction errorsâ€; hence context-switching makes minimizing VFE
7As recalled in e.g. [122, Â§3], â€˜non-commutativityâ€™ is at the very heart of contextuality, as ï¬rst formulated
by von Neumann in terms of non-commutativity of self-adjoint operators representing measurement, with
the impossibility of simultaneously measuring the eigenvalues corresponding to non-commuting operators.
In summarizing the principal results of ensuing hidden variables theory, Mermin [123] demonstrated the
impossibility of ï¬nding a joint probability distribution for all possible observables.
29

and hence complying with the FEP more diï¬ƒcult. Deploying noncommuting QRFs against
a ï¬xed background can, however, lead to radically better generative models, as the history
of technological applications of quantum theory attests. Hence, context-switching poses
a fundamental challenge to any classical formulation of the FEP, and a fundamental ex-
planadum for a quantum formulation.
4
FEP for generic quantum systems
4.1
Deï¬ning VFE for quantum systems
The FEP is a variational or least-action principle: it states that a system enclosed by an MB,
and therefore having internal states that are conditionally independent of its environment,
will evolve in a way that tends to minimize a VFE that is an upper bound on surprisal.
Formally, the VFE F(Ï€), where Ï€ is a â€œparticularâ€ state Ï€ = (b, Âµ) comprising MB (b) and
internal (Âµ) components, can be written [10, Eq. 8.4],
F(Ï€) â‰œ
I(Ï€)
|{z}
Surprisal
+ DKL[QÂµ(Î·) âˆ¥P(Î·|b)]
|
{z
}
Divergence
â‰¥I(Ï€).
(35)
This functional as an upper bound on surprisal I(Ï€) = âˆ’log P(Ï€) because the Kullback-
Leibler divergence (DKL) term is always non-negative. This KL divergence is between the
density over external states Î·, given the MB state b, and a variational density QÂµ(Î·) over
external states parameterised by the internal state Âµ. If we view the internal state Âµ as
encoding a posterior over the external state Î·, minimizing VFE is, eï¬€ectively, minimizing a
prediction error, under a generative model supplied by the NESS density. In this treatment,
the NESS density becomes a probabilistic speciï¬cation of the relationship between external
or environmental states and particular (i.e. â€œselfâ€) states.
In the notation developed in Â§2 and 3 above, we can write the surprisal for a quantum
system A in its most general form as:
IA(t) = âˆ’P(|B(t)âŸ©| |A(t)âŸ©)
(36)
and the corresponding evidence bound as:
DKL[Q|B(t)âŸ©(|B(t)âŸ©) âˆ¥P(|B(t)âŸ©| |B(t)âŸ©].
(37)
In the current setting, however, these expressions have little direct utility, as our eï¬€ec-
tive starting point, Eq. (6), constrains neither |A(t)âŸ©nor |B(t)âŸ©. Indeed, from a strict
formal perspective, neither Eq. (36) nor Eq. (37) is well-deï¬ned in the current setting.
The full boundary/MB state |B(t)âŸ©is, moreover, not an observable for A (or B), as the
thermodynamic-resource sector F remains unobservable by deï¬nition. We have, however,
30

already derived in Â§3.2 a representation of Aâ€™s prediction error, Eq. (30), which we repro-
duce here for reference:
ErE(k) = d(MA
E(k), ME(k)).
(38)
In this expression, the timestep k counts Aâ€™s internal clock time tA and the kernels MA
E
and ME are derived from observables and therefore constrained by the theory. The kernel
ME(k) represents the observable behavior of B, as localized to the sector E, up to tA = k.
The kernel MA
E(k) is Aâ€™s generative model of the action of the unknown dynamics PB(t) on
B, also as localized to E. Hence ErE(k) represents Aâ€™s total reducible uncertainty about
B at tA = k. It is, therefore, an upper bound on surprisal analogous, in the current setting,
to F(Ï€).
The operators M E
i
referenced by Eq. (30), i.e. (38) must, clearly, all be co-deployable. In
practice, however, E is as discussed above subject to context switches of the form UR ËœE â†’
V R ËœE whenever A switches between noncommuting pointer QRFs U and V and hence non-
co-deployable operators M U
i
and M V
i . Hence ErE is only well-deï¬ned in the absence of
context switches; in the presence of context switches the generalized uncertainty relation:
âˆ†uâˆ†v â‰¥â„/2
(39)
for pointer outcomes u and v can generate divergent uncertainties. Hence in practice, any
system A is faced with separately minimizing:
ErX(k) = d(MA
X(k), MX(k)).
(40)
for each sector X deï¬ned by a QRF X. We can, therefore, formulate the FEP for generic
quantum systems, taking context-switching into account, as:
FEP: A generic quantum system A will act so as to minimize ErX for each
deployable QRF X.
A trivial agent can be viewed as executing a trivial QRF, i.e. as only exercising choice of
basis for writing to and reading from B as a whole, and so satisï¬es the FEP trivially.
4.2
Sources of VFE for quantum systems
As noted in the Introduction, there is no source of objective randomness in the current
formalism. Indeed, an observer A can be regarded as certain of the states | ËœEâŸ©, |RâŸ©, |PâŸ©,
and |Y âŸ©of the observable sectors of B at every (external) time t. Uncertainty and prediction
error â€“ and hence, VFE â€“ is generated in the current formalism by Aâ€™s in-principle ignorance
of both the state |BâŸ©and the dynamics PB of its interaction partner B. As the bits A reads
from B are written by PB, Aâ€™s ability to predict the future states of its observable sectors,
31

and hence to minimize ErX for each sector X via Eq. (40), depends on its ability to predict
the behavior of PB locally on each observable sector. As the thermodynamic sector F is
not observed, direct predictions on F are not possible; the local behavior of PB on F can at
best be predicted from its local behavior elsewhere. An animal, for example, must employ
its available senses â€“ hence its observable sectors â€“ to predict the nutritional value of food.
The option space governing Aâ€™s ability to locally predict PB is summarized in Fig. 6. What
is important for A is not the dynamic complexity or even the dimension of PB, both of
which are unobservable in principle, but rather the dynamic complexity of the action of
PB on B (the dimension of this action is, clearly, just the dimension of B). Here, the
weak-interaction limit that allows separability between A and B is signiï¬cant: HAB (and
hence B) must have signiï¬cantly lower dimension that HB (and hence PB) if the weak
interaction limit to is hold. The simplest case is shown in Fig. 6, Panel a), in which the
system B is a trivial agent deploying no QRFs other that the choice of basis for interactions
with B. The action of PB is, in this case, limited to choice of basis, e.g., to rotating the z
axis zB in Fig. 1. As discussed in Â§2.4, basis rotation by B generates quantum noise in the
communication channel deï¬ned by HAB that is indistinguishable by A from classical noise.
Hence, the trivial agent B in Fig. 6, Panel a) â€œlooks likeâ€ a noise source to A. Emission
of Hawking radiation from a black hole (BH) provides perhaps the most pure example of
such a noise source; while the dimension â€œinsideâ€ the BH can be arbitrarily large (see e.g.
[67, Fig. 19]), the internal dynamics are uncoupled from the classical information encoded
on the horizon and hence have no classical computational power. As will be discussed in
Â§4.3 below, a â€œsmallâ€ trivial agent will be driven by the FEP toward entanglement with
the larger system A.
32

Figure 6: Four options for Aâ€™s ability to predict the local behavior of PB on an observable
sector XA. a) A trivial agent deploying no QRFs beyond choice of basis for interacting with
B appears as a noise source to A. b) B encodes a sector XB that contains XA; the bits on
XB but outside XA encode â€œnonlocal hidden variablesâ€ for A. c) The sectors XA and XB
overlap; the areas of non-overlap become noise sources. d) If XA = XB, VFE is generated
by insuï¬ƒcient learning.
The more interesting parts of Aâ€™s option space for prediction are shown in Fig. 6, Panel
b), c), and d), in which B is nontrivial. If B is nontrivial, it deploys at least one QRF XB
acting on a sector XB. As discussed in Â§2.5, Bâ€™s sectors must be mutually decoherent, so
the action of PB on XB is independent of its action elsewhere; it is this independence that
makes prediction possible. If XB does not overlap any observable sector for A, however, B
will appear trivial, i.e. as a noise source, to A. Hence, the interesting cases are the ones in
which Aâ€™s and Bâ€™s observable sectors overlap; this is the case, intuitively, in which A and
B can â€œsee each otherâ€ and hence interact in the ordinary, nontechnical sense of that term.
In Fig. 6, Panel b), Bâ€™s sector XB fully contains XA. As noted above in connection with Eq.
(31), all measure â€“ prepare QRFs X are symmetric, i.e codom(X) = dom(X). Preparation
33

by B of the bits in XA will, therefore, in general depend on bits outside of XA but within
XB, i.e. on bits with the remainder XB \XA. The values of these bits are â€œnonlocal hidden
variablesâ€ [45] from Aâ€™s perspective; they aï¬€ect what is observed on sector XA without
being local to, i.e., contained within, XA. Indeed, such bits may be within F and hence
unobservable in principle by A. Changes in the values of these nonlocal hidden variables
are, eï¬€ectively, context changes as deï¬ned in [97, 98]; probability distributions P(XA|Î¶)
and P(XA|Î¾) for distinct hidden-variable states Î¶ and Î¾ may be diï¬€erent. The â€œcontext-
blindâ€ distribution P(XA) can, in this case, fail to be well-deï¬ned over time. Such failures
manifest as violations of Leggett-Garg inequalities [48], i.e. as â€œquantum hysteresisâ€ eï¬€ects
due to nonlocal (i.e. outside of XA) and possibly unobservable causes. In the language of
artiï¬cial intelligence or robotics, they appear as failures to solve the Frame Problem [87],
the problem of predicting what will not change as the result of an action [124]. If XA is
a reference sector for A, Frame Problem solution failures on XA can result in failures of
object re-identiï¬cation [125].
A situation in which XA fully contains XB presents similar issues to that in Fig. 6, Panel b),
except here the â€œhidden variablesâ€ are in XA \ XB and hence are accessible to A. The bits
in XA \ XB nonetheless contribute VFE â€“ eï¬€ectively, noise â€“ to XA that is unconstrained
by XB. If XA and XB overlap with remainders, as in Fig. 6, Panel c), a similar noise
contribution to XA (or on Bâ€™s side, to XB) results. The ï¬nal possibility is, clearly, that
in which XA = XB as shown in Fig. 6, Panel d). Here, the source of VFE is not noise,
but rather diï¬€erences in the computations implemented by the QRFs XA and XB. Such
diï¬€erences correspond, in the notation of Â§2.6, to diï¬€erences in the structures of the CCCDs
implementing XA and XB, e.g. diï¬€erences in the â€œconnection weightsâ€ if these are thought
of as ANNs or VAEs. They correspond, in other words, to learning failures, e.g. due to
insuï¬ƒcient training-set representativeness, as Eq. (28) renders obvious. We can, therefore,
represent the overall situation for any observer A as:
VFE = Noise + Insuï¬ƒcient Learning
(41)
consistently with Eq. (35) above. Here â€œnoiseâ€ includes VFE generated by unobserved
context changes (Leggett-Garg violations or Frame Problem solution failures) as well as
â€œclassicalâ€ noise.
4.3
Asymptotic behavior of the FEP
Having seen how VFE is generated, we can now ask how it is minimized: how, in other
words, an agent acts in accordance with the FEP. As discussed in the Introduction, the FEP
in its classical form is eï¬€ectively the statement that any system with suï¬ƒcient stability to
be a â€œthingâ€ â€“ i.e. a system with a [quasi-] NESS density â€“ will act so as to preserve its
â€œthingnessâ€ by maintaining the integrity of its MB and hence the integrity of its â€œselfâ€ as
distinct from its surroundings. Comparing Eq. (35) and (41), it becomes clear what this
amounts to: a system â€œself evidencesâ€ by behaving in a way that minimizes noise while
improving learning. This, as is well known, induces a trade-oï¬€: learning requires seeking
34

uncertainty in order to minimize it. As emphasized in [126], successful learning requires
a focus on learnable tasks and avoidance of unlearnable tasks. Hence, minimizing VFE
is removing all removable noise. It does not, in practice, lead to perfect predictability of
future MB states, but to best feasible predictability of future MB states. In classical FEP
formulations, this becomes clearly evident in the form of a functional called expected free
energy (EFE); namely, VFE expected under a posterior predictive density that is condi-
tioned on action. In this setting, the most probable actions are those that minimise EFE
and thereby resolve uncertainty or maximise information gain (a.k.a., intrinsic motivation
or epistemic aï¬€ordance). In short, novelty-seeking is an emergent property of anyâ€œthingâ€,
under the FEP.
We can, however, ask in the current framework how the FEP behaves asymptotically, i.e.,
what are the consequences for A as, in the notation of Eq. (40), ErX(k) â†’0 as k â†’âˆ
for all observable sectors X. This clearly involves implementing a learning operator LX
for each sector X that is capable of asymptotically-perfect learning: let us assume this is
the case. What remains given Eq. (41) is noise, including noise due to observed context
switches. Only one mechanism for removing noise is available: that shown in Fig. 6, Panel
d). Hence we can conclude:
The FEP asymptotically drives alignment of QRFs across B.
It drives any observer A, in particular, to match any context switches by its interaction
partner B in order to maintain QRF alignment. Let us now consider, therefore, a situation
in which all QRFs deployed by A and B are aligned as in Fig. 6 d), and in which all of Aâ€™s
QRFs have learned the local behavior of PB on their sectors perfectly. The local behavior
of PB on some shared sector X is determined by Bâ€™s QRF XB. This QRF XB is, however,
a quantum computation; as such, it encodes nonfungible â€“ not ï¬nitely classically encodable
â€“ information as shown in [40]. The future behavior of XB can, therefore, only be perfectly
predicted by XB itself, that is:
ErX â†’0 â‡’XA = XB
(42)
If A and B are separable, the consequent in Eq. (42) violates the no-cloning theorem [127]:
it demands that the internal quantum state |B|X(t)âŸ©, the time (external t) evolution of
which implements XB, be replicated exactly in A. Hence, if Eq. (42) holds, A and B
cannot be separable. Therefore we have:
If AB is isolated, the FEP asymptotically drives the joint state |ABâŸ©to entan-
glement.
The claim that isolated systems are driven to entanglement is familiar from our initial
discussion of bipartite interactions in Â§2.3: all isolated systems are driven to entanglement
by unitary evolution.
Separability is a special case, an approximation that holds only
under conditions of weak interactions and short observation times. Hence, we can, ï¬nally,
conclude:
35

The FEP is, asymptotically, the Principle of Unitarity.
The FEP is, in other words, asymptotically equivalent to the ï¬rst axiom of quantum theory.
Any quantum system, therefore, must behave in accord with the FEP; doing so is simply
approaching entanglement with its environment as required by the Principle of Unitarity.
The FEP is therefore, consistent with the results obtained in [10], a fundamental, generic
physical principle. Conversely, the Principle of Unitarity â€“ the principle that observable
information is conserved â€“ can now be seen as a fundamental principle of cognitive science.
As an example of the FEP in action, let us return to the situation in which a â€œsmallâ€ trivial
system B interacts with a larger, nontrivial system A considered above. The only freedom
B has in this case is freedom of basis choice for reading and writing from B. From Bâ€™s
perspective, any basis choice that is misaligned with Aâ€™s basis choice generates noise. The
FEP will, therefore, drive B to align its choice of basis â€“ z axis in Fig. 1 â€“ with that of A.
This basis alignment, however, leaves B entangled with A. This is not surprising. When a
photon, for example, interacts with an atom, it is completely absorbed and loses its identity
as a â€œthingâ€; its state becomes irreversibly entangled with that of the atom with which it
interacts.
We can develop this result more formally as follows, noticing that a preparation operation
by BX followed by a measurement operation by AX can be described by a CCCD in the
form of Diagram (14), with the classiï¬ers Ai identiï¬ed with the bits comprising sector X
that are prepared and then measured. The question of asymptotic behavior is then the
question of whether this CCCD is symmetric, i.e. whether the cores Câ€² = Dâ€² in Diagram
(14). We approach this by considering the Markov kernels MA
X and MX, the diï¬€erence
between which deï¬nes the error ErX (via Eq. (40)) that the FEP asymptotically sends to
zero.
As shown in [128, p.17], following [129, Â§4], every category C whose arrows form a set
K embeds fully as a subcategory into Chu.
There is, therefore, an induced mapping
F : C âˆ’â†’Chu realizing F(C) as an embedded subcategory of Chu that consists of some
objects of the latter, together with all of the arrows between them (for background on such
embeddings, see e.g. [41, 42]).
Now we recall the direct association between Markov kernels and conditional probabilities,
and apply the above embedding to the category P of conditional probabilities, following
mainly [130, 131] (cf. [132, 133]). Objects of P consist of countably generated measurable
spaces (X, Î£X), and arrows of P between two such objects, having the form:
M : (X, Î£X) âˆ’â†’(Y, Î£Y).
(43)
These arrows are Markov kernels assigning to each x âˆˆX, and each measurable set Q âˆˆÎ£Y,
the probability of Q given x, denoted here by M(Q|x), whenever deï¬ned. We can also write
this as pM(Q, |x), the (regular) conditional probability determined by the arrow M, â€˜regularâ€™
in so far that M is conditioned on points rather than on measurable sets in Î£X. As arrows
given by Eq. (43) specify a Markov process, they comprise a semigroup, and therefore a
36

set. Hence, we obtain a full embedding P âˆ’â†’Chu, where the (arrow) set K is identiï¬ed
with a set of conditional probabilities K = {pM(S, |x)} âŠ†[0, 1].8 Using the fact that Chu
and the Channel Theory category Chan are isomorphic categories with respect to their
respective objects and arrows, we can summarize as follows:
Proposition 1. The category P embeds fully into Chan with classiï¬cation âŠ©A realized by
the conditional probability pM(Â·|Â·) (the Chu space valuation/satisfaction relation) whenever
this is deï¬ned.
Without loss of generality, we can assume the CCD in Diagram (23) to be a diagram in this
embedded subcategory (for a survey of probability spaces and Bayesian belief networks in
terms of the categories Chu and Chan, see [87, Â§2]).
We can now proceed to consider the asymptotic behavior of the FEP, in particular the
conditions under which |MX âˆ’MA
X| â†’0 for an arbitrary system A and sector X (with
QRF X), in the setting where A interacts with some B and the joint system AB is iso-
lated. To make sense of the formal diï¬€erence MA âˆ’MB, that is, to make sense of the
diï¬€erence between two arrows in P, we can use the metric distance on Markov kernels
as in Eq. (30). This distance is then manifestly the diï¬€erence between the conditional
probabilities pMA(Â·|Â·) âˆ’pMB(Â·|Â·), in the way the corresponding Markov kernels determine
these as described above. As discussed previously, this is a diï¬€erence in the (conditional)
probabilities of observable behavior in sectors. Thus, |MA âˆ’MB| â†’0 is interpreted as the
metric distance d(MA, MB) â†’0 in the asymptotic limit.
With the labeling by A, B, let us return to (23) which we adopt to provide two separate
CCDs as speciï¬ed by (23) denoted by CCDA and CCDB. The asymptotic limit â†’0 of the
metric distance of the kernels determining the diï¬€erence of the conditionals (hence â†’0 in
the asymptotic limit) provides the sense in which the diagrams CCDA and CCDB, along
with their respective colimits colim(Câ€²
A) and colim(Câ€²
B), can be identiï¬ed in this limit (or
in the notation of Diagram (14), the cores Câ€² and Dâ€² as required above become identical).
5
Discussion
5.1
High-level overview
While much of the foregoing has been technical, it is conceptually straightforward. To
brieï¬‚y review, the classical FEP as developed in [10] considers the joint environment-
agent system as a random dynamical system that possesses an attracting set. By placing
particular constraints on the coupling among systemic states (e.g., with sparse coupling
in ï¬‚ow operators or stochastic diï¬€erential equations), one can partition the joint state
space into external, internal and blanket (MB) states.
In turn, the blanket states are
8In a similar way, Abramsky in [134] shows that the Dirac-von Neumann formulation of quantum
mechanics can be conveniently represented in the category Chu.
37

partitioned into sensory states that mediate the inï¬‚uence of external states on internal
states and active states that mediate the inï¬‚uence of internal states on external states.
Crucially, this particular partition imposes conditional independence between internal and
external states, given the blanket states. The ï¬nal move in the classical FEP is to induce a
variational density QÂµ(Î·) over external states that is parameterised by internal states. It is
then fairly straightforward to show that the expected ï¬‚ow of internal (and active) states can
be expressed as a gradient ï¬‚ow on a variational free energy. This free energy is eï¬€ectively
the divergence between the variational density encoded by internal states and the density
over external states conditioned on the blanket states. This licences an interpretation of
internal and active states in terms of active inference, or a Bayesian mechanics, in which
their expected ï¬‚ow can be read as perception and action, respectively. In other words, active
inference is a process of Bayesian belief updating that incorporates active exploration of
the environment.
Reformulating the FEP within quantum information theory allows us to drop the assump-
tion of an observer-independent spacetime background characterized by (continuous) frames
of reference that can be speciï¬ed to inï¬nite precision, and also to drop the assumption of
randomness. In the quantum formulation, the blanket states are implemented by a holo-
graphic screen separating the interacting systems A and B. The screen is the (topological)
locus of the interaction HAB; â€œsensoryâ€ and â€œactiveâ€ states of the classical MB become
incoming and outgoing encodings of bits on the screen. The interaction is symmetrical
across the screen: the reciprocal exchange between â€œinternalâ€ A and â€œexternalâ€ B systems
takes the form of answers and questions (formulated as Hermitian operators M k
i ), where
questions correspond to classical action (mediated by active states) and answers correspond
to classical perception (mediated by sensory states). There is, crucially, no assumption that
A and B share preparation and measurement bases; basis mismatches between A and B
generate quantum noise that is â€œperceivedâ€ as classical noise.
An â€œagentâ€ in the quantum formalism is a system that deploys quantum reference frames
â€“ eï¬€ectively, concepts that identify persistent objects and their time-varying states â€“ when
interacting with its environment.
Deploying distinct QRFs breaks the thermodynamic
symmetry of the screen for each agent, redirecting energy ï¬‚ows within each agent to fund
processing and recording memory records of some bits while others â€“ those in the â€œthermo-
dynamicâ€ sector F â€“ remain necessarily unobserved. Thus the quantum formalism explicitly
enforces a distinction that the classical formalism leaves implicit: that between observed
and unobserved parts of the environment. Mismatches between QRFs deployed by two
interacting agents generate noise and prediction errors, including incorrect Frame Problem
solutions and failures to correctly re-identify objects.
In the classical setting, agents â€œself-evidenceâ€ by maintaining their nonequilibrium steady-
states or, equivalently, the integrity of their MBs. From a mathematical point of view, this
is maintaining their identities (in the sense of being independently well-deï¬ned) as systems.
In the quantum setting, being independently well-deï¬ned is being separable from â€“ not
entangled with â€“ the environment; hence â€œself-evidencingâ€ is maintaining separability. The
FEP identiï¬es self-evidencing with the minimization of Bayesian prediction error: toâ€œbeâ€
38

is to be capable of successful predictions; sometimes described as â€œpredicting yourself into
existenceâ€. Minimizing prediction error is, in the quantum setting, minimizing the diï¬€erence
between two Markov kernels. As in the classical setting, noise and errors due to insuï¬ƒcient
learning must both be minimized, a process that requires trade-oï¬€s between the two.
The classical and quantum formulations of the FEP diï¬€er in their asymptotic behavior,
i.e., as total prediction error is driven toward zero. A classical â€œperfect predictorâ€ achieves
maximal classical correlation and hence maximal behavioral synchrony with its environ-
ment; it becomes a â€œperfect regulatorâ€ in the sense of the good regulator theorem [135].
In a quantum setting, perfect prediction entails shared QRFs between interaction partners
and hence entanglement; a quantum â€œperfect regulatorâ€ becomes indistinguishable from
the environment it is predicting. While this diï¬€erence in asymptotic behaviors is a formal,
mathematical outcome, it can be traced to a diï¬€erence in fundamental assumptions. The
classical formalism assumes a spacetime background, and hence can rely on separation in
space to distinguish between systems. The quantum formalism is background free: space
is simply an observable, represented by a QRF that a system may or may not deploy. It
can, therefore, play no â€œonticâ€ role in maintaining distinctions between systems. This re-
ï¬‚ects the general role of (â€œphysicalâ€ 3d) space in quantum ï¬eld theories: space is there to
enforce separability (see [68] for a general discussion of this point from a gauge-theoretic
perspective).
Both classical and quantum formulations of the FEP engender a fundamental form of
epistemic solipsism, in the sense that the coupling between internal and external systems
precludes the states of one from ever â€œknowingâ€ the states of the other. While this seems
counter-intuitive, it is a straightforward consequence of the use of vector spaces to rep-
resent physical states. Vector-space product operators â€“ the classical Cartesian product
or the Hilbert-space tensor product â€“ are by deï¬nition associative (equivalently, dynamic
operators such as Hamiltonians are additive); product decompositions are, therefore, un-
detectable across decompositional boundaries in any vector space [136]. This sense of epis-
temic solipsism does not, as Fuchs emphasizes [55], in any way suggest ontic or metaphysical
solipsism. Both classical and quantum formulations of the FEP â€“ indeed, any theory of
measurement or observation â€“ requires two interacting systems, observer and observed. The
idea of a metaphysically solipsist theory of observation is self-contradictory.
5.2
Summary of results
We have obtained three results in this paper:
1. Given the standard free-choice assumption, the intuitive idea of an â€œagentâ€ or IGUS
can be fully formulated within background-independent, scale-free quantum informa-
tion theory.
2. The FEP can be given a quantum-theoretic formulation that renders it applicable to
generic quantum systems.
39

3. When formulated as a generic principle of quantum information theory, the FEP is
asymptotically equivalent to the Principle of Unitarity.
Result 1) places the long-standing practice of treating generic quantum systems as â€œob-
serversâ€ on a ï¬rm theoretical foundation. It allows a formal speciï¬cation, in the language
of QRFs, of exactly what systems a given observer is capable of recognizing and what states
of those systems it is capable of measuring. Such speciï¬cations require no â€œonticâ€ assump-
tions of observer-independent systems; hence they are compliant with a device-independent
theoretical strategy. Result 1) also provides a formal deï¬nition of an â€œagentâ€ in the con-
text of the free-choice assumption, and provides a generic language â€“ the category-theoretic
language of Channel Theory â€“ for specifying the semantics assigned by an agent to an
observational outcome. Finally, Result 1) shows how semantics arise from thermodynamic
symmetry breaking on a holographic screen, and provides a formal mechanism for quanti-
fying energy ï¬‚ows that enable classical computation and classical memory encoding.
Result 2) extends the range of applicability of the FEP to generic quantum systems inde-
pendently of spacetime background or scale-dependent assumptions. Quantum ï¬elds, black
holes, and other spatially-distributed or topologically-deï¬ned systems can, therefore, be
regarded as Bayesian observers and, if free choice is assumed, as Bayesian agents. Result
2) therefore makes clear the sense in which generic quantum systems can be regarded as
â€œusersâ€ of quantum information theory, as proposed under the rubric of QBism [33, 35, 55].
Indeed Result 2) renders QBism a consequence of quantum information theory, not an
interpretation.
Result 3) shows that the FEP is compliant with the Principle of Unitarity and, conversely,
that unitary evolution is compliant with the FEP. It allows us, in particular, to understand
quantum context-switching as both a source of prediction errors and a strategy for reducing
prediction errors. Result 3) also allows us to view separability as a resource for classical
communication and computation that is analogous to entanglement as a resource for quan-
tum communication and computation. Hence, it allows us to consider trade-oï¬€s between
these resources by systems that maintain approximate separability while also employing
shared entanglement. Such systems have been studied in the abstract, and can potentially
exceed the computational power of Turing machines (e.g. can solve the Halting problem as
shown in [137]). Result 3) suggests that (some) biological systems may have this capability,
as discussed further in Â§5.4 below.
5.3
Applications to biological cognition
In addition to the results listed above, the current framework has a variety of more speciï¬-
cally biological consequences, some of which have been discussed already in [13]. It predicts,
for example, that moving in ordinary 3d space does not require a QRF for Euclidean space
and hence, does not require an experience of space. From a classical perspective, this is
certainly true; as evidenced e.g. by place and grid cells in mammalian brains [138, 139, 140]
that appear to encode a coarse-grained representation of location, head-direction etc., in
40

various frames of reference. This coarse graining endorses another prediction; namely, that
actionable classical encodings are coarse-grained. Any system that encodes information
irreversibly is, therefore, faced with a choice that its computational architecture must re-
solve: the trade-oï¬€between preserving information in memory and losing information due
to coarse graining. On a classical FEP account, this coarse graining is mandated by the
minimization of VFE, which can be expressed as complexity minus accuracy. Classically,
complexity corresponds to the KL divergence between posterior and prior beliefs as in Eq.
(35).
This relative entropy clearly depends upon the degree of discretisation or coarse
graining aï¬€orded by the dimensionality of internal states. Eï¬€ectively, this KL divergence
scores the computational and thermodynamic cost of belief updating that is mitigated by
coarse graining or, in quantum terms, devoting memory resources to the results computed
by only some QRFs, possibly in a context-sensitive fashion [141].
The ubiquity of context-dependent eï¬€ects leads to another prediction: living systems in
complex environments will evolve context and attention switching systems. On a classical
view, this entails the identiï¬cation of context (cf. the role of pointers) in a hierarchical
generative model, where high level states contextualise the processing of lower level states.
This immediately introduces the notion of MBs or holographic screens in the joint space of
an agentâ€™s internal states, i.e. a notion of modularity supported by shared memory. This
is gracefully accommodated by the channel theory of QRFs as developed in Â§2.6.9 Indeed,
much work in the classical ï¬eld of active inference rests upon optimising the hierarchical
structure of deep generative models, via various free energy minimizing processes [143,
144, 145, 146]. This is especially true for generative models of navigation and language
[147, 148, 149] that are almost universally based upon quantisation or discretisation of state
spaces. The attendant Boolean logic that arises from the imposition of Boolean constraints
by QRFs may have important practical applications, as demonstrated by recent work in
active vision and scene construction [150] that rests upon a generative model of the sensory
(visual) consequences of visually foraging a scene with multiple objects. Active inference
in this context can be seen as an inversion of a generative model that maps from causes
(external objects), to consequences (sensory states) (cf. [116]).
The inversion of generative models for active vision is extremely diï¬ƒcult and ill-posed due to
its computational complexity. These models have to accommodate all the natural physical
laws of motion and optics (e.g., occlusion). The inversion of these models corresponds to
the measurement operators that mediate belief updating. In a classical setting, this can
be massively ï¬nessed by coarse graining the problem and applying Boolean operators. For
example, if one object is near and another object is far, an agent will see the near object.
Quantising or coarse graining the internal (i.e. generative) model along these lines reduces
the likelihood mapping to a set of relatively simple Boolean operators that could be cast as
measurement operators in a quantum-theoretic context. At present, when these operators
are encoded on standard classical computers for simulation, they are eï¬€ectively implemented
with enormous tensors. Reading and writing these tensors into working memory dwarfs
9See [90] for an explicit application to global-workspace theory and [142] for a more ambitious synthesis
of active inference, a global workspace, and IIT.
41

the actual compute time and renders active vision schemes of this sort computationally
and thermodynamically ineï¬ƒcient. One might imagine that a combination of quantum
computing [25, 27] and neuromorphic engineering [151, 152] may be able to parallel the
eï¬ƒciency of human vision.
There are, in addition, certain technical problems that are resolved in moving from a
classical to a quantum FEP formulation of active inference that go beyond a commitment
to unitary processes and binary measurement operators. These include problems entailed
by assuming reference frames that can be speciï¬ed to inï¬nite precision. In formalising
the asymptotic behaviour of belief updating in the absence of random ï¬‚uctuations in the
classical formalism, for example, one has to deal with diï¬€erential entropies that are ill-
deï¬ned for very precise conditional densities, e.g. Dirac Delta functions. One workaround
is to use Jaynesâ€™ limiting density of discrete points (LDDP) [153], which brings us back to
where we started, namely ï¬nite dimensional Hilbert spaces and discrete state spaces.
Finally, from a more philosophical perspective, the framework presented here is consistent
with [13, 14, 154] in supporting a panpsychist perspective on questions of agency, sentience,
and cognition. As our Deï¬nition 1 of agency illustrates, traditional binary categorizations
of entities into those having agency, sentience, and cognition and those lacking them are
replaced here by continua of â€œinterestingnessâ€ along these dimensions. Deï¬nition 1 assumes
free choice, in particular of measurement basis. The Conway-Kochen theorem [72] states
that if any physical system is assumed to have free choice, then all physical systems must
be assumed to have free choice.
â€œFree choiceâ€ in this case means behavior that is not
determined by (cannot be fully predicted given) the events in the systemâ€™s past lightcone.
Determination of behavior by events in the past lightcone is local determinism; such local
determinism is fundamentally inconsistent with the global determinism implied by unitarity
[155]. Hence what is interesting is the extent of choice. As emphasized in [10], interesting
choices are implemented by internal processes.
An electron, for example, has internal
states â€“ its charge and mass are not states of its MB â€“ but they are invariant, and so
do not implement choices. The internal states of rocks are not invariants â€“ changes in
water content or radioactive decay can occur â€“ but they do not, in general, implement
interesting choices from our human perspective.
Interesting choices require interesting
sensations and actions, and hence signiï¬cant internal energy ï¬‚ows as discussed above. They
require diï¬€erential use of thermodynamic resources to deploy multiple QRFs that probe the
observable environment in diï¬€erent ways. Systems, including organisms, clearly do this to
diï¬€erent extents; even among humans, the extent of variation is striking. Consonant with
a broadly-construed enactivism [156, 157, 158, 159], we view such active exploration of the
environment â€“ hence, active inference â€“ as indicating cognition and intelligence.
5.4
Predictions and open questions
The results obtained here suggest that the ï¬eld of quantum biology is far larger than has so
far been explored; indeed they suggest that all biological systems are properly considered
quantum systems and can be expected to employ quantum coherence as an information
42

processing resource. This suggestion is of course not novel, having been explored by many
authors from philosophical, theoretical, and increasingly over the past two decades, empiri-
cal perspectives [160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174]. We
have, however, shown here that it follows from general principles: quantum systems with
suï¬ƒciently complex internal information ï¬‚ows can be expected to exhibit active inference,
and hence to behave like organisms. Indeed, quantum systems that do not display evident
intelligence â€“ quantum systems that are trivial agents â€“ become an unusual special case.
Conversely, the results obtained here suggest that the concepts of active inference, agency,
Bayesian satisï¬cing, and cognition are applicable to generic quantum systems, and hence
to physical systems across the board. This turns the traditional question of the emergence
of intentionality [175, 176, 177] on its head: by making agency a generic expectation, it
makes the â€œmerely physicalâ€ the special case demanding explanation. It thus suggests that
the traditional division between agency and mechanism is a hindrance, not a help, in the
task of understanding the natural world.
We make, in particular, the following predictions:
1. The internal, molecular-scale dynamics of both prokaryotic and eukaryotic cells im-
plement quantum information processing, i.e., make essential use of quantum coher-
ence as a computational and memory resource. This is consistent with recent results
showing that the free energy budgets of biological systems across known phylogeny are
orders of magnitude short of the resources required for purely classical computation
at the molecular scale [178].
2. Interacting biological systems trade oï¬€separability against entanglement and hence
classical against quantum communication. Interactions between biological systems
from the molecular scale upwards can be expected to display quantum contextuality
and violations of the Bell and Leggett-Garg inequalities.
These predictions remain largely untested, both for reasons of technical diï¬ƒculty and due
to a still-pervasive traditional view of macroscopic systems as ontically classical. The mech-
anistic role of entanglement â€“ even in relatively well-established systems such as light har-
vesting â€“ remains subject to considerable debate [172, 173, 174]. Quantum context switch-
ing has been detected in human subjects [179, 180], but whether it is properly considered
â€œquantumâ€ or merely â€œquantum-likeâ€ remains open to question [181].10 Neither Bell nor
Leggett-Garg inequality violations have been conclusively demonstrated with biological sys-
tems.
Setting technical diï¬ƒculties aside, we suggest that coherence eï¬€ects in biological settings
may be systematically overlooked due to being dismissed as â€œnoiseâ€ or â€œrandom coinci-
dence.â€ Thermal noise in biological settings is well characterized; general environmental
variation, including eï¬€ects of signaling by other cells or organisms, is less straightforwardly
10Such â€œquantum-likeâ€ contextuality is claimed for a certain case of gene expression in [182] where
conï¬‚icting probabilities (quantum vs. classical) do not give rise to a consistently deï¬nable joint distribution,
so suggesting a variant of Kolmogorov contextuality.
43

modeled or controlled. Experimental designs that explicitly test for coherence eï¬€ects will,
we expect, be required to test the above predictions. Focused theoretical support for such
designs is therefore necessary.
Interactions involving multiple agents remain an open theoretical as well as experimental-
design problem. In the bipartite setting employed for the technical analysis above, every
agent interacts with its entire surrounding, whether the bits transferred by this interaction
are observed and processed or not (i.e. whether they are included in sector E or F). This
does not change in a multi-party setting; each agent still interacts with its entire surround,
identifying other agents (or not) via speciï¬c QRFs. The ubiquitous assumption that inter-
agent communication is classical, made in domains as disparate as cell-cell interaction and
human natural language use, becomes problematic in this setting. As discussed in Â§4.3,
shared QRFs are required for fully-shared, counterfactual-supporting semantics, but they
induce entanglement (see also the discussion of this point in [38]). The extent of shared
semantics is not readily observable in living systems. In a fully classical setting, generalised
synchronisation (a.k.a., synchronisation of chaos) emerges when two free energy minimising
â€˜partnersâ€™ observe each other [183].
â€œPerfect predictionâ€ of the partnerâ€™s behavior may
result, driven by classical learning of a shared generative model, implicitly resolving the
hermeneutics problem in the communication context [184, 185]. Recognizing a particular
communication partner, in this case, requires invoking a particular generative model, the
correct model to predict that partnerâ€™s behavior [186]. Such classical synchronization is not,
however, robust against perturbation; altering one agentâ€™s model does not â€œautomaticallyâ€
alter the other, as would be expected if the models, i.e. the QRFs implemented by the two
agents were entangled. Both theoretical and experimental characterization of relevant QRFs
will be required to assess the extent to which classical communication can be considered
purely classical, and detemine where and how quantum coherence contributes to in-practice
successful shared semantics.
Darwinian evolution can be viewed as a process of variation and selection of QRFs, and
hence as an instance of the multiple-agents problem in which semantics is only partially
shared. Evolution can be given a natural description in the framework of the classical FEP
[5, 187, 188, 189]. Variation and selection have been advanced as a model of decoherence
under the rubric of quantum Darwinism [18, 190]; see [191] for a discussion from the per-
spective of universal Darwinism. The selection mechanism invoked by quantum Darwinism,
however, assumes QRF sharing by multiple agents [192]; see [38, 62] for discussion. While
the present results allow any evolutionary system coupled to a larger environment to be
viewed as a Bayesian agent implementing active inference, a fully-satisfactory account of
variation and selection within a quantum framework remains to be developed.
Additional theoretical work is also needed to understand the relationships among the many
distinct models of quantum contextuality that have been put forward, often with the use
of quite diï¬€erent formal tools (e.g. [193, 194, 195, 196]). The question of â€œcontextâ€ is
deeply tied up with that of what is to be regarded as the â€œenvironmentâ€ or â€œsurroundingâ€
of any given system. This is a particularly critical question at the cellular level, where
multiple signaling modalities with diï¬€erent spatial ranges and temporal characteristics are
44

present. Models that explicitly characterize the â€œspacesâ€ in which cells and multicellular
systems operate â€“ e.g. the space of potential morphologies, or that of potential messages
from interaction partners â€“ and that consider constraining eï¬€ects of one space on another
both within and between scales will be needed to understand the roles of context, and of
context switching, in biological systems.
In closing, we hope that we have shown to readers familiar with the FEP and the active
inference framework that quantum eï¬€ects are worth considering both theoretically and in
experimental design. For readers not familiar with the classical FEP but literate in quantum
theory (or vice versa), we hope this paper has gone some way to contextualizing your QRFs
in sense-making via Markov blankets and their underlying holographic screens.
Conï¬‚ict of Interest Statement
The authors declare that the research was conducted in the absence of any commercial or
ï¬nancial relationships that could be construed as a potential conï¬‚ict of interest.
Funding
The work of C.F. is supported in part by the Emerald Gate Foundation. K.J.F. is sup-
ported by funding for the Wellcome Centre for Human Neuroimaging (Ref: 205103/Z/16/Z)
and the Canada-UK Artiï¬cial Intelligence Initiative (Ref: ES/T01279X/1). M.L. gratefully
acknowledges support by the Guy Foundation Family Trust (103733-00001), the John Tem-
pleton Foundation (62212), and the Elisabeth Giauque Trust.
References
[1] Friston KJ. A theory of cortical responses. Philos Trans R Soc Lond B, Biol Sci
2005;360:815â€“36.
[2] Friston KJ, Kilner J, Harrison L. A free energy principle for the brain. J Physiol Paris
2006;100:70â€“87.
[3] Friston KJ, Stephan KE. Free-energy and the brain. Synthese 2007;159:417â€“58.
[4] Friston KJ. The free-energy principle:
a uniï¬ed brain theory?
Nat Rev Neurosci
2010;11:127â€“38.
[5] Friston KJ. Life as we know it. J R Soc Interface 2013;10:20130475.
[6] Friston KJ, FitzGerald T, Rigoli F, Schwartenbeck P, Pezzulo G. Active inference: a
process theory. Neural Comput 2017;29:1â€“49.
45

[7] Ramstead MJ, Badcock PB, Friston KJ. Answering SchrÂ¨odingerâ€™s question: a free-
energy formulation. Phys Life Rev 2018;24:1â€“16.
[8] Ramstead MJ, Constant A, Badcock PB, Friston KJ. Variational ecology and the physics
of sentient systems. Phys Life Rev 2019;31:188â€“205.
[9] Kuchling F, Friston K, Georgiev G, Levin M. Morphogenesis as Bayesian inference:
A variational approach to pattern formation and control in complex biological systems.
Phys Life Rev 2020;33:88â€“108
[10] Friston K. A free-energy principle for a particular physics. Preprint arXiv:1906.10184
(2019).
[11] Clark A. How to knit your own Markov blanket: Resisting the Second Law with meta-
morphic minds. In: Metzinger T, Wiese W (eds), Philosophy and Predictive Processing:
3. Frankfurt am Main: MIND Group, 2017.
[12] Scholl BJ, Tremoulet PD. Perceptual causality and animacy. Trends Cogn Sci
2000;4:299â€“309.
[13] Fields C, Glazebrook JF, Levin M. Minimal physicalism as a scale-free substrate for
cognition and consciousness. Neurosci Cons 2021;7:niab013.
[14] Levin M. Life, death, and self: fundamental questions of primitive cognition viewed
through the lens of body plasticity and synthetic organisms. Biochem Biophys Res Comm
2020;564:114â€“133.
[15] Von Neumann J. The Mathematical Foundations of Quantum Mechanics. Princeton,
NJ: Princeton University Press, 1955.
[16] Omn`es R. Consistent interpretations of quantum mechanics. Rev Mod Phys
1992;64:339â€“382.
[17] Zurek WH. Decoherence, einselection and the existential interpretation (the rough
guide). Phil Trans R Soc A 1998;356:1793â€“1821.
[18] Zurek WH. Decoherence, einselection, and the quantum origins of the classical. Rev
Mod Phys 2003;75;715â€“775.
[19] Schlosshauer M. Decoherence, the measurement problem, and interpretations of quan-
tum mechanics. Rev Mod Phys 2003;76:1267â€“1305.
[20] Schlosshauer M. Decohenece and the Quantum to Classical Transition. Springer,
Berlin, 2007.
[21] Bassi A, Lochan K, Satin S, Singh TJ, Ulbricht H. Models of wave-function collapse,
underlying theories, and experimental tests. Rev Mod Phys 2013;85:471â€“527.
46

[22] Landsman NP. Between classical and quantum. In: Butterï¬eld J, Earman J. (eds.),
HandBook of the Philosophy of Science: Philosophy of Physics. Elsevier, Amsterdam,
Netherlands, 2007, pp. 417â€“553.
[23] Cabello A. Interpretations of quantum theory:
A map of madness. Preprint
arXiv:1509.04711v1, 2015.
[24] Wheeler JA. Law without law. In: Wheeler JA, Zurek W (eds), Quantum Theory and
Measurement. Princeton, NJ: Princeton University Press, 1983, pp. 182â€“213.
[25] Feynman RP. Simulating physics with computers. Int J Theor Phys 1982;21:467â€“488.
[26] Deutsch D. Quantum theory, the Church-Turing principle and the universal quantum
computer. Proc R Soc A 1985;400: 97â€“117.
[27] Nielsen MA, Chuang IL. Quantum Computation and Quantum Information. New York:
Cambridge University Press, 2000.
[28] Hardy L. Quantum theory from ï¬ve reasonable axioms. Preprint arxiv:quant-
ph/0101012v4 (2001).
[29] Fuchs CA. Quantum mechanics as quantum information, mostly. J Mod Opt
2003;50:987â€“1023.
[30] Brassard G. Is information the key? Nat Phys 2005;1:2â€“4.
[31] Chiribella G, Dâ€™Ariano GM, Perinotti P. Informational derivation of quantum theory.
Phys Rev A 2011;84:012311.
[32] Masanes L, MÂ¨uller MP. A derivation of quantum theory from physical requirements.
New J Phys 2011:13;063001.
[33] Fuchs C, Schack R. Quantum Bayesian coherence. Rev Mod Phys 2013;85:1693â€“1715.
[34] Grinbaum A. How device-independent approaches change the meaning of physical the-
ory. Stud Hist Phil Mod Phys 2017;58:22â€“30.
[35] Mermin
ND.
Making
better
sense
of
quantum
mechanics.
Rep
Prog
Phys
2018;82:012002.
[36] MÂ¨uller MP. Law without law: from observer states to physics via algorithmic informa-
tion theory. Quantum 2020;4:301.
[37] Fields C, Glazebrook JF. Representing measurement as a thermodynamic symmetry
breaking. Symmetry 2020;12:810.
[38] Fields C, Glazebrook JF, Marcian`o A. Reference frame induced symmetry breaking on
holographic screens. Symmetry 2021;13:408.
47

[39] Aharonov Y, Kaufherr T. Quantum frames of reference. Phys Rev D 1984;30:368â€“385.
[40] Bartlett SD, Rudolph T, Spekkens RW. Reference frames, super-selection rules, and
quantum information. Rev Mod Phys 2007;79:555â€“609.
[41] AdÂ´amek J, Herrlich H, Strecker GE. Abstract and Concrete Categories: The Joy of
Cats. New York: Wiley, 2004. Available at http://katmat.math.uni-bremen.de/acc (Ac-
cessed May 26, 2019)
[42] Awodey S. Category Theory. (Oxford Logic Guides, 62). Oxford, UK: Oxford Univer-
sity Press, 2010.
[43] Barwise J, Seligman J, Information Flow: The Logic of Distributed Systems (Cam-
bridge Tracts in Theoretical Computer Science, 44). Cambridge, UK: Cambridge Univer-
sity Press, 1997.
[44] Kochen S, Specker EP. The problem of hidden variables in quantum mechanics. J Math
Mech 1967;17:59â€“87.
[45] Mermin D. Hidden variables and the two theorems of John Bell. Rev Mod Phys
1993;65:803â€“815.
[46] Gell-Mann M, Hartle JB. Quantum mechanics in the light of quantum cosmology. In
Zurek W (ed) Complexity, Entropy, and the Physics of Information. Boca Raton, FL:
CRC Press, 1989; pp. 425â€“458.
[47] Bell JS. On the Einstein-Podolsky-Rosen paradox. Physics 1964;1:195â€“200
[48] Emary
C,
Lambert
N,
Nori
F.
Leggett-Garg
inequalities.
Rep
Prog
Phys
2013;77:016001.
[49] Landauer R. Irreversibility and heat generation in the computing process. IBM J Res
Devel 1961;5:183â€“195.
[50] Landauer R. Information is a physical entity. Physica A 1999;263:63â€“67.
[51] Bennett CH. The thermodynamics of computation. Int J Theor Phys 1982;21:905â€“940.
[52] Lloyd S. Ultimate physical limits to computation. Nature 2000;406:1047â€“1054.
[53] Zweir MC, Chong LT. Reaching biological timescales with all-atom molecular dynamics
simulations. Curr Opin Pharmacol 2010;10:745â€“752.
[54] Wang Q, Schoenlein RW, Peteanu LA, Mathies RA, Shank CV. Vibrationally coherent
photochemistry in the femtosecond primary event of vision. Science 1994;266:422â€“424.
[55] Fuchs C. QBism, the Perimeter of quantum Bayesianism. Preprint arXiv:1003.5209,
2010.
48

[56] Moretti V, Oppio M. Quantum theory in real Hilbert space: How the complex Hilbert
space structure emerges from PoincarÂ´e symmetry. Rev Math Phys 2017;29:17500021.
[57] Renou M-O, Trillo D, Weilenmann M, Thinh LP, Tavakoli A, Gisin N, AcÂ´Ä±n A,
NavascuÂ´es M. Quantum physics needs complex numbers. Preprint arXiv:2101.10873,
2021.
[58] Baez JC. Getting to the bottom of Noetherâ€™s theorem. Preprint arXiv:2006.14741,
2020.
[59] Kauï¬€man
LH.
Eigenforms
and
quantum
physics.
Cybernet
Human
Knowing
2011;18:111â€“121.
[60] Aspect A, Grangier P, Roger G. Experimental realization of the Einstein-Posolsky-
Rosen gedankenexperiment:
A new violation of Bellâ€™s inequalities. Phys Rev Lett
1982;49:91â€“94.
[61] Fields C, Marcian`o A. Sharing nonfungible information requires shared nonfungible
information. Quant Rep 2019;1: 252â€“259.
[62] Fields C, Marcian`o A. Holographic screens are classical information channels. Quant
Rep 2019;2;326â€“336.
[63] Wheeler JA. Information, physics, quantum: The search for links. In Zurek W (ed)
Complexity, Entropy, and the Physics of Information. Boca Raton, FL: CRC Press, 1989;
pp. 3â€“28.
[64] â€™t Hooft G. Dimensional reduction in quantum gravity. In Ali A, Ellis J, Randjbar-
Daemi S. (eds) Salamfestschrift. Singapore: World Scientiï¬c, 1993, pp. 284â€“296.
[65] Susskind L. The world as a hologram. J Math Phys 1995;36:6377â€“6396.
[66] Bousso R. The holographic principle. Rev Mod Phys 2002;74:825â€“874.
[67] Almheiri A, Hartman T, Maldacena J, Shaghoulian E, Tajdini A. The entropy of
Hawking radiation. Rev Mod Phys 2021;93:035002.
[68] Addazi A, Chen P, Fabrocini F, Fields C, Greco E, Lulli M, Marcian`o A, Pasechnik
R. Generalized holographic principle, gauge invariance and the emergence of gravity `a la
Wilczek. Front Astron Space Sci 2021;8:563450.
[69] Fields C, Marcian`o A. Markov blankets are general physical interaction surfaces. Phys
Life Rev 2020;33:109â€“111.
[70] Bohr N. Atomic Physics and Human Knowledge. New York: Wiley, 1958.
[71] Gisin N. Non-realism: Deep thought or a soft option? Found Phys 2012;42:80â€“85.
[72] Conway JH, Kochen S. The strong free will theorem. Notices AMS 2009;56(2):226â€“232.
49

[73] Horsman C, Stepney S, Wagner RC, Kendon V. When does a physical system compute?
Proc R Soc A 2014;470:20140182.
[74] Rice HG. Classes of recursively enumerable sets and their decision problems. Trans
Am Math Soc 1953;74:358â€“366.
[75] Fields C, Levin M. How do living systems create meaning? Philosophies 2020;5:36.
[76] Quive WVO. Word and Object. Cambridge, MA: MIT Press, 1960.
[77] Zanardi, P. Virtual quantum subsystems. Phys Rev Lett 2001;87:077901.
[78] Zanardi P, Lidar DA, Lloyd S. Quantum tensor product structures are observable-
induced. Phys Rev Lett 2004;92:060402.
[79] DugiÂ´c M, JekniÂ´c J. What is â€œsystemâ€: Some decoherence-theory arguments. Int J
Theor Phys 2006;45:2249â€“2259.
[80] DugiÂ´c M, JekniÂ´c-DugiÂ´c J. What is â€œsystemâ€: The information-theoretic arguments.
Int J Theor Phys 2008;47:805â€“813.
[81] De la Torre AC, Goyeneche D, Leitao L. Entanglement for all quantum states. Eur J
Phys 2010;31:325â€“332.
[82] Harshman NL, Ranade KS. Observables can be tailored to change the entanglement
of any pure state. Phys Rev A 2011;84:012303.
[83] Barr M. *-Autonomous Categories, with an Appendix by Po Hsiang Chu (Lecture
Notes in Mathematics 752). Springer: Berlin, Germany, 1979.
[84] Pratt V. Chu spaces. In School on Category Theory and Applications (Coimbra 1999);
Volume 21 of Textos Math. SÂ´er. B. University of Coimbra: Coimbra, Portugal, 1999, pp.
39â€“100.
[85] Pratt V. Chu spaces from the representational viewpoint. Ann Pure Appl Logic
1999;96:319â€“333.
[86] Fields C, Glazebrook JF. A mosaic of Chu spaces and Channel Theory I: Category-
theoretic concepts and tools. J Expt Theor Artif Intell 2019;31:177â€“213.
[87] Fields C, Glazebrook JF. Information ï¬‚ow in context-dependent hierarchical Bayesian
inference. J Expt Theor Artif Intell 2021; in press (doi: 10.1080/0952813X.2020.1836034).
[88] Collier J. Information, causation and computation. In G. D. Crnkovic and M. Burgin
(eds.) Information and Computation: Essays on Scientiï¬c and Philosophical Foundations
of Information and Computation (World Scientiï¬c Series in Information Studies Vol 2).
World Scientiï¬c Press. Hackensack, NJ, 2011, pp. 89-105.
50

[89] Fields C, Glazebrook JF. A mosaic of Chu spaces and Channel Theory II: Appli-
cations to object identiï¬cation and mereological complexity. J Expt Theor Artif Intell
2019;31:237â€“265.
[90] Fields C, Glazebrook JF. Do Process-1 simulations generate the epistemic feelings that
drive Process-2 decision making? Cogn Proc 2020;21:533â€“553.
[91] Barwise
J.
Information
and
impossibilities.
Notre
Dame
J
Formal
Logic
1997;38(4):488â€“515.
[92] Cherniak E. Bayesian networks without tears. AI Mag 1991;12(4):50â€“63.
[93] Allwein, G. A qualititative framework for Shannon Information theories. In NSPW
â€™04: Proceedings of 2004 Workshop on New Security Paradigms (Nova Scotia, Canada,
September 20-23, 2004). New York: ACM, 2004, pp. 23â€“31.
[94] St. Clere Smithe T. Compositional active inference I: Bayesian lenses, statistical games.
Preprint arXiv:2109.04461 [math.ST], 2021.
[95] Coecke B. Quantum picturalism. Contemp Phys 2010;51:59â€“83.
[96] Adams EW. A Primer of Probabilistic Logic. Chicago: University of Chicago Press,
1998.
[97] Dzhafarov EN, Cervantes VH, Kujala JV. Contextuality in canonical systems of ran-
dom variables. Phil Trans R Soc A 2017;375:20160389.
[98] Dzharfarov EN, Kon M. On universality of classical probability with contextually la-
beled random variables. J Math Psych 2018;85:17â€“24.
[99] MacKay DJC, Peto LCB. A hierarchical Dirichlet language model. Nat Lang Engin
1995;1,289â€“308.
[100] Wallace CS, Dowe, DL. Minimum message length and Kolmogorov complexity. Com-
puter J 1999;42:270â€“283.
[101] Smith R, Schwartenbeck P, Parr T, Friston KJ. An active inference approach to mod-
eling structure learning: Concept learning as an example case. Front Comput Neurosci
2020;14:41.
[102] Weinstein A. Groupoids: Unifying internal and external symmetry. Notices Am Math
Soc 1996;43:744â€“752.
[103] Brown R. Topology and Groupoids. www.groupoids.org.uk, Deganwy, UK, 2006.
[104] Deutsch D. The structure of the multiverse. Proc R Soc A 2002;458:2911â€“2923.
51

[105] Marcian`o, A.; Chen, D.; Fabrocini, F.; Fields, C.; Greco, E.; Gresnigt, N.; Jinklub,
K.; Lulli, M., Terzidis, K.; Zappala, E. Deep neural networks as the semi-classical limit
of quantum neural networks. Preprint arXiv:2007.00142v2 [cond-mat.diss-nn].
[106] Oizumi M, Albantakis L, Tononi G. From the phenomenology to the mechanisms of
consciousness: Integrated Information Theory 3.0. PLoS Comp Biol 2014;10:e1003588.
[107] Robbins RJ, Krishtalka L, Wooley JC. Advances in biodiversity: Metagenomics and
the unveiling of biological dark matter. Stand Genom Sci 2016:11:69.
[108] Ashby WR. Introduction to Cybernetics. Chapman and Hall, London, UK, 1956.
[109] Moore EF. Gedankenexperiments on sequential machines. In Shannon CW, McCarthy
J (eds) Autonoma Studies. Princeton University Press, Princeton, NJ, USA, 1956, pp.
129â€“155.
[110] Scholl BJ. Object persistence in philosophy and psychology. Mind Lang 2007;22:563â€“
591.
[111] Fields C. The very same thing: Extending the object token concept to incorporate
causal constraints on individual identity. Adv Cognit Psychol 2012;8:234â€“247.
[112] Fields C. Some consequences of the thermodynamic cost of system identiï¬cation.
Entropy 2018;20:797.
[113] Pais A. Einstein and the quantum theory. Rev Mod Phys 1979;51:863â€“914.
[114] Marr D. Vision. Freeman, San Francisco, CA, 1982.
[115] Palmer S. Vision Science: Photons to Phenomenology. MIT Press, Cambridge, MA,
1999.
[116] Pizlo Z. Perception viewed as an inverse problem. Vis Res 2001;41:3145â€“3161.
[117] Prakash C, Fields C, Hoï¬€man DD, Prentner R, Singh M. Fact, ï¬ction, and ï¬tness.
Entropy 2020;22:514.
[118] Prakash C, Stephens KD, Hoï¬€man DD, Prentner R, Singh M, Fields C. Fitness beats
truth in the evolution of perception. Acta Biotheor 2021;69: 319â€“341.
[119] Bohr N. The quantum postulate and the recent development of atomic theory. Nature
1928;121:580â€“590.
[120] Di Biagio A, Don`a P, Rovelli C. The arrow of time in operational formulations of
quantum theory. Quantum 2021;5;520.
[121] Tegmark M. How unitary cosmology generalizes thermodynamics and solves the in-
ï¬‚ationary entropy problem. Phys Rev D 2012;85:123517.
52

[122] Sulis W. Contextuality in neurobehavioural and collective intelligence systems. Quan-
tum Reports 2021;3: 592â€“614.
[123] Mermin D. Simpliï¬ed uniï¬ed form for the major no-hidden variables theorem. Phys
Rev Lett 1990; 65: 3373â€“3376.
[124] McCarthy J, Hayes PJ. Some philosophical problems from the standpoint of artiï¬cial
intelligence. In Michie D, Meltzer, B. (eds.) Machine intelligence, Vol. 4). Edinburgh
University Press, Edinburgh, 1969, pp. 463â€“502.
[125] Fields C. How humans solve the frame problem. J Expt Theor Artif Intell 2013;25:441â€“
456.
[126] Gottlieb J, Lopes M, Oudeyer P-Y. Motivated cognition: Neural and computational
mechanisms of curiosity, attention, and intrinsic motivation. In: Kim S-Y, Reeve J,
Bong M. (Eds) Recent Developments in Neuroscience Research on Human Motivation
(Advances in Motivation and Achievement, Vol. 19), Emerald Group Publishing Limited,
Bingley, UK, 2016, pp. 149â€“172.
[127] Wooters WK, Zurek WH. A single quantum cannot be cloned. Nature 1982;299:802â€“
803.
[128] Pratt V. Types as Processes, via Chu spaces. Elect Notes Theor Comp Sci 1997;7:227â€“
247.
[129] Pratt V. Broadening the denotational semantics of linear logic. Elect Notes Theor
Comp Sci 1996;3: 155â€“166.
[130] Culbertson J, Sturtz K. Bayesian machine learning via category theory. Preprint
arXiv:1312.1445v1[math.CT], 2013.
[131] Culbertson J, Sturtz K. A categorical foundation for Bayesian probability. Appl Cat-
egor Struct 2014;22(4): 647â€“662.
[132] Giry M. A categorical approach to probability theory. In: Banaschewski B. (ed)
Categorical Aspects of Topology and Analysis. (Lecture Notes in Mathematics, vol 915).
Springer, Berlin, 1982, pp. 68â€“85.
[133] Lawvere WF. The category of probabilistic mappings. Unpublished seminar notes,
(1962) available at https://ncatlab.org/nlab/ï¬les/lawvereprobability196.pdf (Accessed
10 Dec 2021).
[134] Abramsky S. Big toy models: Representing physical systems as Chu spaces. Synthese
2012;186:697â€“718.
[135] Conant RC, Ashby WR. Every good regulator of a system must be a model of that
system. Int J Syst Sci 1970;1(2):89â€“97.
53

[136] Fields C. Building the observer into the system: Toward a realistic description of
human interaction with the world. Systems 2016;4:32.
[137] Ji Z, Natarajan A, Vidick T, Wright J, Yuen H. MIP* = RE. Comms ACM
2021;64(11):131â€“138.
[138] Moser MB., Rowland DC, Moser EI. Place cells, grid cells, and memory. Cold Spring
Harbor Perspect Biol 2015;7:a021808.
[139] Stachenfeld KL, Botvinick MM, Gershman SJ. The hippocampus as a predictive map.
Nat Neurosci 2017;20:1643â€“1653.
[140] Whittington JC, Muller TH, Mark S, Chen G, Barry C, Burgess N, Behrens TE. The
Tolman-Eichenbaum Machine: Unifying space and relational memory through generali-
sation in the hippocampal formation. Preprint bioRxiv:770495, 2019.
[141] Lloyd K, Leslie DS. Context-dependent decision-making: A simple Bayesian model.
J R Soc Interface 2013;10:20130069.
[142] Safron A. An Integrated World Modeling Theory (IWMT) of consciousness: Combin-
ing integrated information and global neuronal workspace theories with the Free Energy
Principle and active inference framework; Toward solving the Hard Problem and charac-
terizing agentic causation. Front Artif Intell 2020;3:30.
[143] Davis MH, Johnsrude IS. Hierarchical processing in spoken language comprehension.
J Neurosci 2003;23:3423â€“3431.
[144] George D, Hawkins J. Towards a mathematical theory of cortical micro-circuits. PLoS
Comput Biol 2009;5:e1000532.
[145] Friston KJ, Lin M, Frith CD, Pezzulo G, Hobson JA, Ondobaka S. Active inference,
curiosity and insight. Neural Comput 2017;29:2633â€“2683.
[146] Friston KJ., Rosch, R, Parr T, Price C, Bowman H. Deep temporal models and active
inference. Neurosci Biobehav Rev 2017;77:388â€“402.
[147] MacKay DJ. Free-energy minimisation algorithm for decoding and cryptoanalysis.
Electron Lett 1995;31:445â€“447.
[148] Teh YW, Jordan MI, Beal MJ, Blei DM. Hierarchical Dirichlet processes. J Am Statist
Assoc2006;101:1566â€“1581.
[149] Friston KJ, Parr T, Yuï¬k Y, Sajid N, Price CJ, Holmes E. Generative models, lin-
guistic communication and active inference. Neurosci Biobehav Rev 2020;118:42â€“64.
[150] Parr T, Friston KJ. The active construction of the visual world. Neuropsychologia
2017;104:92â€“101.
54

[151] Mead C. Neuromorphic electronic systems. Proc IEEE 1990;78:1629â€“1636.
[152] Tang J, Yuan F, Shen X, Wang Z, Rao M, He Y, Sun Y, Li X, Zhang W, Li Y,
Gao B, Qian H, Bi G, Song S, Yang J, Wu H. Bridging biological and artiï¬cial neural
networks with emerging neuromorphic devices: Fundamentals, progress, and challenges.
Adv Mater 2019;31:1902761.
[153] Jaynes ET. Information Theory and Statistical Mechanics. Phys Rev (Series II)
1957;106:620â€“630.
[154] Friston KJ, Wiese W, Hobson JA. Sentience and the origins of consciousness: From
Cartesian duality to Markovian monism. Entropy 2020;22:516.
[155] Fields C. A whole box of Pandoras: Systems, boundaries and free will in quantum
theory. J Expt Theor Artif Intell 2013;25:291â€“302.
[156] Maturana H, Varela FJ. Autopoiesis and Cognition: The Realization of the Living.
Boston Stud Phil Sci 42. D. Reidel, Dordrecht, 1980.
[157] Varela F, Thompson E, Rosch, E. The Embodied Mind: Cognitive Science and Human
Experience. MIT Press, Cambridsge, MA, 1991.
[158] Anderson ML. Embodied cognition: A ï¬eld guide. Artif Intell 2003;149:91â€“130.
[159] Froese T, Ziemke T. Enactive artiï¬cial intelligence: Investigating the systemic orga-
nization of life and mind. Artif Intell 2009;173:466â€“500.
[160] SchrÂ¨odinger E. What Is Life?. Cambridge University Press, Cambridge, UK, 1944.
[161] Wigner EP. Remarks on the mind-body question. In: Good IJ (ed.), The Scientist
Speculates. London: Heinemann, 1961, pp. 284â€“302.
[162] Penrose R. The Emperorâ€™s New Mind. Oxford University Press, Oxford, 1989.
[163] Hameroï¬€S, Penrose R. Orchestrated reduction of quantum coherence in brain mi-
crotubules: A model for consciousness. Math. Comput. Simul. 1996;40:453â€“480.
[164] Tegmark M. Importance of quantum decoherence in brain processes. Phys. Rev. E
2000;61:4194â€“4206.
[165] Davies PCW. Does quantum mechanics play a non-trivial role in life? BioSystems
2004;78:69â€“79.
[166] Hameroï¬€S, Tuszynski, J. Quantum states in proteins and protein assemblies: The
essence of life?
In: Abbott D, Bezrukov SM, Der A, SÂ´anchez A. (eds) Fluctuations
and Noise in Biological, Biophysical, and Biomedical Systems II SPIE, Bellingham, WA,
2004, pp. 27â€“41.
55

[167] Arndt M, Juï¬€mann T, Vedral V, Quantum physics meets biology. HFSP J 2009;3:386â€“
400.
[168] Lambert N, Chen Y-N, Cheng Y-C, Li C-M, Chen G-Y, Nori F. Quantum biology.
Nat. Phys. 2012;9:10â€“18.
[169] Melkikh AV, Khrennikov A. Nontrivial quantum and quantum-like eï¬€ects in biosys-
tems: Unsolved questions and paradoxes. Prog. Biophys. Mol. Biol. 2015;119:137â€“161.
[170] Brookes JC. Quantum eï¬€ects in biology: Golden rule in enzymes, olfaction, photo-
synthesis and magnetodetection. Proc. R. Soc. A 2017;473:20160822.
[171] McFadden J, Al-Khalili J. The origins of quantum biology. Proc. R. Soc. A
2018;474:20180674.
[172] Marais A, Adams B, Ringsmuth AK, Ferretti M, Gruber MJ, Hendrikx R, et al. The
future of quantum biology. J. R. Soc. Interface 2018;15:20180640.
[173] Cao J, Cogdell RJ, Coker DF, Duan H-G, KleinekathÂ¨ofer U, Jansen TLC, et al.
Quantum biology revisited. Sci. Adv. 2020;6:eaaz4888.
[174] Kim Y, Bertagna F, Dâ€™Souza EM, Heyes DJ, Johannissen LO, Nery ET. Quantum
biology: An update and perspective. Quant Rep 2021;3:1â€“48.
[175] Polanyi M. Lifeâ€™s irreducible structure. Science 1968;160:1308â€“1312.
[176] Rosen R. On information and complexity. In Casti JL, Karlqvist A. (eds) Complexity,
Language, and Life: Mathematical Approaches. Springer, Berlin, 1986; pp. 174â€“196.
[177] Ellis GFR. Physics, complexity, and causality. Nature 2005;435:743.
[178] Fields C, Levin M. Metabolic limits on classical information processing by biological
cells. BioSystems 2021;209:104513.
[179] Cervantes VH, Dzhafarov EN. Snow Queen is evil and beautiful: Experimental evi-
dence for probabilistic contextuality in human choices. Decision 2018;5(3):193â€“204.
[180] Basieva I, Cervantes VH, Dzhafarov EN, Khrennikov A. True contextuality beats
directs inï¬‚uences in human decision making. J Expt Psychol General 2019;148:1925â€“
1937.
[181] Khrennikov A. Quantum-like modeling of cognition. Front Phys 2015;3:77.
[182] Basieva I, Khrennikov A, Ohya M, Yamato O. Quantum-like interference eï¬€ect in
gene expression: glucose-lactose destructive interference. Syst Synth Biol 2011;5:59â€“68.
[183] Friston K, Frith C. A Duet for one. Conscious Cogn 2015;36:390â€“405.
56

[184] Frith C, Wentzer T. Neural Hermeneutics. In Kaldis B. (ed) Encyclopedia of Phi-
losophy and the Social Sciences. SAGE Publications, Thousand Oaks, CA, 2013, pp.
657â€“659.
[185] Friston KJ, Frith CD. Active inference, communication and hermeneutics. Cortex
2015;68:129â€“143.
[186] Isomura T, Parr T, Friston K. Bayesian ï¬ltering with multiple internal models: To-
ward a theory of social intelligence. Neural Comput 2019;31:2390â€“2431.
[187] Campbell JO. Universal Darwinism as a process of Bayesian inference. Front Syst
Neurosci 2016;10:49.
[188] Fields C, Levin M. Integrating evolutionary and developmental thinking into a scale-
free biology. BioEssays 2020;42:1900228.
[189] Fields C, Levin M. Does evolution have a target morphology? Organisms 2020;4:57â€“
76.
[190] Zurek WH. Quantum Darwinism. Nature Physics 2009;5:181â€“188.
[191] Campbell JO. Quantum Darwinism as a Darwinian process. Preprint arXiv:1001.0745
[physics.gen-ph], 2010.
[192] Fields C. Quantum Darwinism requires an extra-theoretical assumption of encoding
redundancy. Int J Theor Phys 2010;49:2523â€“2527.
[193] Abramsky S, Brandenburger, A. The sheaf-theoretic structure of non-locality and
contextuality. New J Phys 2011;13:113036.
[194] Abramsky S, Hardy L. Logical Bell inequalities. Phys Rev A 2012; 85(6):062114.
[195] Popescu S. Non-locality beyond quantum mechanics. Nat Phys 2014;10:264â€“270.
[196] Adlam
E.
Contextuality,
ï¬ne-tuning
and
teleological
explanation.
Preprint
arXiv:2110.15898v1[quant-ph], 2021.
57

