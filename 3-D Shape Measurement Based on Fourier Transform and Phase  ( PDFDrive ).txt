 
   
SSStttooonnnyyy   BBBrrrooooookkk   UUUnnniiivvveeerrrsssiiitttyyy   
 
 
 
 
 
 
 
   
   
   
   
   
The official electronic file of this thesis or dissertation is maintained by the University 
Libraries on behalf of The Graduate School at Stony Brook University. 
   
   
©
©©   A
AAllllll   R
RRiiiggghhhtttsss   R
RReeessseeerrrvvveeeddd   bbbyyy   A
AAuuuttthhhooorrr...   

 
   
SSStttooonnnyyy   BBBrrrooooookkk   UUUnnniiivvveeerrrsssiiitttyyy   
 
 
 
 
 
 
 
   
   
   
   
   
The official electronic file of this thesis or dissertation is maintained by the University 
Libraries on behalf of The Graduate School at Stony Brook University. 
   
   
©
©©   A
AAllllll   R
RRiiiggghhhtttsss   R
RReeessseeerrrvvveeeddd   bbbyyy   A
AAuuuttthhhooorrr...   

3-D Shape Measurement Based on
Fourier Transform and Phase Shifting
Method
A Dissertation Presented
by
Hong Guo
to
The Graduate School
in Partial Fulﬁllment of the Requirements
for the Degree of
Doctor of Philosophy
in
Mechanical Engineering
Stony Brook University
December 2009

Stony Brook University
The Graduate School
Hong Guo
We, the dissertation committee for the above candidate for the Doctor of
Philosophy degree, hereby recommend acceptance of this dissertation.
Dr. Peisen S. Huang – Dissertation Advisor
Professor, Department of Mechanical Engineering
Dr. Fu-pen Chiang – Chairperson of Defense
Professor, Department of Mechanical Engineering
Dr. Yu Zhou
Assistant Professor, Department of Mechanical Engineering
Dr. Hong Qin
Professor of Computer Science,
Department of Computer Science of Stony Brook University
This dissertation is accepted by the Graduate School.
Lawrence Martin
Dean of the Graduate School
ii

Abstract of the Dissertation
3-D Shape Measurement Based on Fourier
Transform and Phase Shifting Method
by
Hong Guo
Doctor of Philosophy
in
Mechanical Engineering
Stony Brook University
2009
Phase shifting method and the Fourier transform method are both
fringe analysis methods. This dissertation research focuses on uti-
lizing these two methods to extract 3-D shape information encoded
in fringe patterns obtained from digital fringe projection tech-
nique and shadow moir´e technique respectively. A modiﬁed Fourier
transform method is developed for real-time 3-D shape measure-
ment of dynamic objects based on the digital fringe projection
technique. A phase shifting scheme is developed for the shadow
moir´e technique in eﬀort to improve its resolution and accuracy.
A novel face recognition method is proposed, which employs phase
shifting method and the Fourier transform method to obtain an
eﬃcient spectral representation of 3-D face.
Digital fringe projection technique is a full-ﬁeld, high-resolution,
and high-speed 3-D shape measurement method. Real-time fringe
pattern acquisition, processing, and 3-D display by use of 3-step
phase shifting method has been previously achieved on a high-
speed digital fringe projection system. However, measurement of
iii

fast moving or changing objects remains diﬃcult in that at least
three fringe patterns taken over time are required. Although the
Fourier transform method only needs one frame of fringe pattern,
the measurement quality is limited when objects with complex
shapes are measured. In this research, a modiﬁed Fourier method
is proposed, which aims at measuring dynamic objects with com-
plex shapes.
The basic idea is to acquire a ﬂat image in addi-
tion to a fringe image, which provides necessary information for
overcoming the shortcomings of the conventional Fourier trans-
form method.
Two fringe projection schemes are proposed and
compared. The experimental results demonstrated that the pro-
posed method can be used for real-time 3-D shape measurement
of complex shapes, and improved measurement quality over 3-step
phase shifting method is achieved.
Shadow moir´e is a traditional full-ﬁeld optical 3-D shape measure-
ment technique. By combining phase shifting method with shadow
moir´e technique, the resolution of the measurement can be greatly
improved.
Various phase shifting schemes have been previously
proposed. However, none of them provides exact close-form phase
solution for the phase shifting shadow moir´e. In this research, we
provide an elegant exact solution for phase shifting shadow moir´e.
Four phase-shifted fringe patterns are obtained by translating the
grating vertically in equal steps. The Carr´e algorithm is applied
to the phase-shifted fringe patterns to obtain an exact close-form
phase solution. Simulation and experimental results veriﬁed the
proposed method.
Face recognition is an intuitive and promising human biometrics
method. 2-D and 3-D face recognition methods have been exten-
sively studied. However, the performance of 2-D methods is greatly
inﬂuenced by facial texture and illumination variations. 3-D meth-
ods require reconstruction of the 3-D face geometry which results
in high computation and storage expenses. In this research, a face
recognition method is proposed, which employs a spectral represen-
tation of 3-D face to perform face recognition without 3-D recon-
struction. A high-speed digital fringe projection system captures
three phase-shifted fringe patterns of a face. 3-step phase shifting
method and the Fourier transform method are applied to face fringe
patterns to remove facial texture and illumination variations and
extract spectra related to the 3-D shape of the face. The eigenface
algorithm is employed to analyze the face spectra database and
iv

recognize the identity of the unknown face. The experimental and
simulation results demonstrated promising recognition rates with
reduced computation and storage expenses.
v

Dedicated to My Family

Contents
List of Figures
x
List of Tables
xiii
Acknowledgements
xiv
1 Introduction
1
1.1
Overview of 3-D Shape Measurement Technology
. . . . . . .
2
1.1.1
Laser triangulation . . . . . . . . . . . . . . . . . . . .
2
1.1.2
Time-of-ﬂight . . . . . . . . . . . . . . . . . . . . . . .
2
1.1.3
Stereo vision . . . . . . . . . . . . . . . . . . . . . . . .
3
1.1.4
Coded pattern projection . . . . . . . . . . . . . . . . .
3
1.1.5
Interferometry . . . . . . . . . . . . . . . . . . . . . . .
4
1.1.6
Moir´e method . . . . . . . . . . . . . . . . . . . . . . .
4
1.1.7
Digital fringe projection
. . . . . . . . . . . . . . . . .
5
1.2
Motivation and Objective
. . . . . . . . . . . . . . . . . . . .
7
1.2.1
3-D shape measurement of dynamic objects
. . . . . .
7
1.2.2
Phase shifting shadow moir´e . . . . . . . . . . . . . . .
8
1.2.3
3-D human face recognition
. . . . . . . . . . . . . . .
8
1.2.4
Research objectives . . . . . . . . . . . . . . . . . . . .
9
1.3
Dissertation Structure
. . . . . . . . . . . . . . . . . . . . . .
10
2 Modiﬁed Fourier Transform Method for Real-time
3-D Shape Measurement
12
2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
2.1.1
Principle of the Fourier transformed method . . . . . .
13
2.1.2
Related work
. . . . . . . . . . . . . . . . . . . . . . .
16
2.2
Modiﬁed Fourier Transform Method . . . . . . . . . . . . . . .
18
2.2.1
Flat pattern + fringe pattern
. . . . . . . . . . . . . .
19
2.2.2
Three phase-shifted fringe patterns . . . . . . . . . . .
19
2.2.3
Binary mask generation
. . . . . . . . . . . . . . . . .
23
vii

2.2.4
Spectral leakage reduction . . . . . . . . . . . . . . . .
23
2.3
Phase Unwrapping
. . . . . . . . . . . . . . . . . . . . . . . .
25
2.3.1
Quality index . . . . . . . . . . . . . . . . . . . . . . .
27
2.3.2
Quality-guided path following . . . . . . . . . . . . . .
28
2.4
Absolute Phase Retrieval . . . . . . . . . . . . . . . . . . . . .
32
2.4.1
Marker detection . . . . . . . . . . . . . . . . . . . . .
32
2.4.2
Marker removal . . . . . . . . . . . . . . . . . . . . . .
34
2.5
3-D Reconstruction . . . . . . . . . . . . . . . . . . . . . . . .
35
2.6
Software Implementation . . . . . . . . . . . . . . . . . . . . .
36
2.7
Experimental Results . . . . . . . . . . . . . . . . . . . . . . .
36
2.7.1
Projector grayscale calibration . . . . . . . . . . . . . .
37
2.7.2
Measurement of still object with complex shape . . . .
39
2.7.3
Measurement of moving object and changing face sequence 40
2.8
Summary
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
3 Phase Shifting Shadow Moir´e by use of Carr´e Algo-
rithm
44
3.1
Introduction to Phase Shifting Shadow Moir´e Technique
. . .
44
3.1.1
Principle of shadow moir´e technique . . . . . . . . . . .
44
3.1.2
Phase shifting algorithms for fringe analysis
. . . . . .
47
3.2
Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
3.3
Grating Pattern Removal . . . . . . . . . . . . . . . . . . . . .
49
3.4
Phase Shifting Scheme and Carr´e Algorithm . . . . . . . . . .
52
3.4.1
Phase shifting scheme
. . . . . . . . . . . . . . . . . .
52
3.4.2
Carr´e algorithm . . . . . . . . . . . . . . . . . . . . . .
53
3.4.3
Phase unwrapping
. . . . . . . . . . . . . . . . . . . .
54
3.5
3-D Reconstruction . . . . . . . . . . . . . . . . . . . . . . . .
54
3.6
Simulation Results
. . . . . . . . . . . . . . . . . . . . . . . .
55
3.7
Experimental Results . . . . . . . . . . . . . . . . . . . . . . .
59
3.8
Summary
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
4 Face Recognition Based on Fringe Pattern Analysis 65
4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . .
65
4.2
Background and Related Work . . . . . . . . . . . . . . . . . .
66
4.3
Principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
4.3.1
Digital fringe projection system . . . . . . . . . . . . .
68
4.3.2
Texture and illumination removal . . . . . . . . . . . .
68
4.3.3
Fourier spectra of fringe image . . . . . . . . . . . . . .
71
4.4
Face Image Normalization . . . . . . . . . . . . . . . . . . . .
73
4.5
Principal Component Analysis of the Fourier Spectra . . . . .
74
4.6
Experiments and Simulation . . . . . . . . . . . . . . . . . . .
74
viii

4.6.1
Experiments . . . . . . . . . . . . . . . . . . . . . . . .
74
4.6.2
Simulation on FRGC2.0 database . . . . . . . . . . . .
78
4.7
Summary
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
5 Conclusions and Future Work
85
5.1
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . .
85
5.2
Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
Bibliography
90
ix

List of Figures
1.1
System diagram of a DLP projectior.
. . . . . . . . . . . . .
6
1.2
System diagram of the high-speed digital fringe projection sys-
tem.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2.1
Fourier spectra |G(fx, y)|.
. . . . . . . . . . . . . . . . . . . .
14
2.2
Phase-to-coordinate conversion in the conventional Fourier trans-
form method. . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
2.3
Fourier spectrum . . . . . . . . . . . . . . . . . . . . . . . . .
18
2.4
Schematic system diagram for the modiﬁed Fourier transform.
19
2.5
Flat+fringe pattern projection. (a)Fringe image; (b)Flat im-
age; (c)Spectrum of 320th row with the ﬂat image subtracted;
(d)Spectrum of 320th row of the fringe image. . . . . . . . . .
20
2.6
Schematic diagram for the modiﬁed Fourier transform using 3
fringe images. . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
2.7
Three phase-shifted pattern projection. (a)-(c)Fringe images;
(d)Spectrum of 320th row with the ﬂat image subtracted; (e)Spectrum
of 320th row of the second fringe image.
. . . . . . . . . . . .
22
2.8
Binary mask generation. (a) Histogram of the ﬂat image; (b)
Binary mask.
. . . . . . . . . . . . . . . . . . . . . . . . . . .
24
2.9
Window function.
(a)Hamming window; (b)Windowed sinu-
soidal fringe pattern. . . . . . . . . . . . . . . . . . . . . . . .
24
2.10 Windowing eﬀect on the results of MFTM. (a)-(c) 3-D images
of a white plane cardboard aﬀected by windowing; (d)-(e)Cross
sections at the same row from (a)-(c). . . . . . . . . . . . . . .
26
2.11 Flood-ﬁll algorithm.
. . . . . . . . . . . . . . . . . . . . . . .
29
2.12 Phase unwrapping result of a model. (a) Fringe image. (b) Flat
image. (c) Wrapped phase map. (d) Visibility map. . . . . . .
30
2.13 Quality-guided phase unwrapping process.
(a) Intermediate
step 1. (b) Intermediate step 2. (c) Intermediate step 3. (d)
Final result. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
x

2.14 Markers and template. (a) Marker embedded in the fringe pat-
tern; (b) Marker embedded in the ﬂat pattern; (c) Template. .
33
2.15 Marker detection and removal example. (a) Fringe image; (b)Flat
image; (c) Template matching result; (d)Marker removal result.
33
2.16 Marker detection example for the 3 phase-shifted fringe pat-
terns. (a) One of three fringe images; (b)Flat image; (c) Visi-
bility map; (d)Template matching result. . . . . . . . . . . . .
34
2.17 Coordinate systems used for 3-D reconstruction. . . . . . . . .
35
2.18 Software interface.
. . . . . . . . . . . . . . . . . . . . . . . .
37
2.19 Projector grayscale error compensation. (a) Before compensa-
tion; (b) After compensation.
. . . . . . . . . . . . . . . . . .
38
2.20 3-D measurement results of a free-form part. (a) Flat+fringe
pattern scheme; (b) Three phase-shifted fringe pattern scheme;
(c) Conventional FTM method; (d) Zoom-in view of (a); (e)
Zoom-in view of (b); (f) Zoom-in view (c). . . . . . . . . . . .
39
2.21 A moving cylinder. (a) 3-step phase shifting; (b) MFTM with
ﬂat+fringe patterns; (c) MFTM with 3 phase-shifted fringe pat-
terns; (d)-(e)Error on the cross sections of (a)-(c) in the middle
of the cylinder along X direction.
. . . . . . . . . . . . . . . .
41
2.22 Facial expression sequences. (a) Result from the proposed method.
(b) Result from the 3-step phase shifting method. . . . . . . .
42
3.1
Schematic setup of shadow moir´e.
. . . . . . . . . . . . . . .
45
3.2
Shadow moir´e pattern on a sphere.
. . . . . . . . . . . . . . .
46
3.3
Remove grating pattern from the shadow moir´e pattern. Grat-
ing horizontal translations: (a) 0◦; (b) 120◦; (c) 240◦; (d) Grat-
ing removal result.
. . . . . . . . . . . . . . . . . . . . . . . .
51
3.4
Schematic setup of the proposed phase shifting shadow moir´e
method. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
3.5
Coordinate systems in shadow moir´e setup. . . . . . . . . . . .
55
3.6
Shadow moir´e patterns. (a) Input 3-D model; Grating horizon-
tal translations: (b) 0◦; (c) 120◦; (d) 240◦. . . . . . . . . . . .
56
3.7
Phase-shifted moire patterns with grating pattern removed. (a)-
(d) Four phase-shifted fringe patterns.
. . . . . . . . . . . . .
57
3.8
Simulation results. (a) Wrapped phase map; (b) Phase shift
distribution α/2 (rad); (c) Unwrapped phase map (rad).
. . .
58
3.9
3-D surface obtained by the proposed phase shifting shadow
moir´e method . . . . . . . . . . . . . . . . . . . . . . . . . . .
60
3.10 Phase-shifted moir´e patterns of a NIST calibration block. . . .
61
xi

3.11 Measurement results of a NIST calibration block. (a) Wrapped
phase map (rad); (b) Unwrapped phase map (rad); (c) Height
map (µm). . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
3.12 Phase-shifted moir´e patterns of a lens.
. . . . . . . . . . . . .
63
3.13 Measurement results of a lens. (a) Wrapped phase map (rad);
(b) Unwrapped phase map (rad); (c) Height map (µm). . . . .
64
4.1
System diagram of the digital fringe projection system. . . . .
69
4.2
Skin texture and illumination removal.
(a)-(c) three phase-
shifted fringe patterns; (d) fringe pattern with skin texture and
background illumination removed. . . . . . . . . . . . . . . . .
71
4.3
Fourier spectra (|G(fx, y)|) of the processed fringe pattern.
.
72
4.4
Fourier spectra of Fig. 4.8(c)
. . . . . . . . . . . . . . . . . .
72
4.5
Face fringe pattern normalized.(a)Detected face area; (b)Cropped
fringe pattern; (c)Filtered Fourier spectra. . . . . . . . . . . .
73
4.6
Face recognition process by use of PCA.
. . . . . . . . . . . .
75
4.7
Illumination and texture removal result of a face with makeup.
76
4.8
Illumination and texture removal result of a face with diﬀerent
background illumination. . . . . . . . . . . . . . . . . . . . . .
77
4.9
Sample face fringe patterns and spetra. . . . . . . . . . . . . .
79
4.10 FRGC2.0 face database. (a) 2-D image; (b) 3-D image; (c) 3-D
image with virtually projected fringe pattern.
. . . . . . . . .
80
4.11 Normalized 3-D faces with fringe virtually projected fringe pat-
tern. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
4.12 Normalized 2-D intensity images from FRGC2.0 database.
. .
83
4.13 Face recognition results with diﬀerent number of top eigenfaces.
84
5.1
Shadow moir´e patterns produced by the SEM.(a) SE detector
image; (b) BSE detector image. . . . . . . . . . . . . . . . . .
88
xii

List of Tables
4.1
Recognition results with diﬀerent number of training spectra or
images. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
xiii

Acknowledgements
First of all, I would like to express my deepest gratitude to my advisor Pro-
fessor Peisen Huang. This dissertation research could not be accomplished
without his contributions of time and ideas. I beneﬁted so much from his
encouragements, guidance and help.
I am grateful to my committee members, Professor Fu-pen Chiang, Pro-
fessor Yu Zhou, and Professor Hong Qin, for their precious time on reviewing
and providing valuable feedbacks on this dissertation. I also thank Professor
Qiaode Ge and Professor Goldie Negat for their valuable time on reviewing
my dissertation proposal.
I would like to thank my colleague Mr. Xu Han in the Optical Metrology
Laboratory for his help in my research. I also would like to thank former lab
members Dr. Song Zhang, Dr. Jiahui Pan, Dr. Qingying Hu for their valuable
advice and help.
My thanks also goes to Professor Goldie Negat and Dr. Zhe Zhang. It
was a pleasure for me to work together them on the robotic search and rescue
project. I would like to thank my colleague in ME department, Gunes Uzer,
for his help on SEM operation.
My study at Stony Brook was enjoyable due to my friends Wenfei Liu, Yi
Ding, Xiao Yun, Jian Yao, and Wei Zhao.
And last but not least, I thank my wife Yanxiao Zhao, my parents, and
my brother. Their love and support carried me through the tough times in my
PhD study.

Chapter 1
Introduction
Optical 3-D shape measurement technology plays an important role in manu-
facturing, medicare, biometrics, and entertainment industry, due to the non-
contact nature of the measurement. Among various techniques, the structured
light method has salient advantages of high-resolution, full-ﬁeld measurement
and fast data acquisition. In this dissertation research, two structured light
3-D shape measurement methods, namely digital fringe projection and shadow
moir´e, are studied. This research focuses on eﬀectively generating fringe pat-
terns and accurately extracting 3-D shape information from the fringe patterns
obtained from digital fringe projection and shadow moir´e technique respec-
tively.
Digital fringe projection is a high-resolution, full-ﬁeld, high-speed 3-D
shape measurement technique, which is especially suitable for measuring free-
form surfaces with high resolution.
A novel fringe projection and analysis
method is proposed for measuring the 3-D shape of moving or changing ob-
jects in real-time by use of a digital fringe projection technique. As an ap-
plication of the digital fringe projection technique, a human face recognition
method based on the digital fringe projection and fringe analysis is proposed,
in which a spectral representation of the 3-D face is obtained by analyzing the
face fringe patterns by the Fourier transform method and the phase shifting
method. Shadow moir´e technique is a traditional high-accuracy optical 3-D
shape measurement technique. A phase shifting scheme is proposed for the
shadow moir´e setup to improve the measurement accuracy.
This chapter gives an overview of optical 3-D shape measurement technol-
ogy and explains the motivation and objectives of this dissertation research.
The rest of this chapter is organized as follows. Current optical 3-D shape
measurement techniques related to this research are brieﬂy reviewed in Sec.1.1.
The motivation and objectives are given in Sec.1.2. The structure of this dis-
sertation is outlined in Sec.1.3.
1

1.1
Overview of 3-D Shape Measurement Tech-
nology
With the fast development of computer and optical components in the past
two decades, the optical 3-D shape measurement technology has achieved great
improvements in terms of accuracy, speed and measurement range. Several
widely employed optical 3-D shape measurement techniques are summarized
as follows.
1.1.1
Laser triangulation
Laser triangulation technique utilizes the triangle formed by the laser light
source, the laser spot on the object surface, and the image of the spot on the
receiving sensor to acquire range information [1, 2]. The distance between
the light source and the receiving sensor is calibrated. The direction of the
incident laser beam is known. The beam is incident on a diﬀusely scattering
surface and the light spot on the surface forms an image on the sensor. Based
on the position of the image on the sensor, the angle between the incident
and reﬂected laser beam can be calculated. The distance between the light
source and the object surface can be calculated employing trigonometry. The
principle of triangulation measurement has been widely used in other optical
dimensional measurement techniques.
The laser light source can be a single point source or a linear source. Lin-
ear source laser scanners have larger ﬁeld of view, usually in the order of 20
to 30 degree. Point source laser scanners have better depth resolution and
immunity to ambient light. The measurement range of commercialized laser
triangulation systems is 40-650 mm. The accuracy can reach 10 µm [3]. How-
ever, complicated scanning system is required in order to achieve full ﬁeld
measurement. The measurement speed is rather low for laser scanning.
1.1.2
Time-of-ﬂight
Time-of-ﬂight technique detects the time of a laser pulse traveled to the object
surface and reﬂected back to the receiving sensor. Based on the speed of the
light and the recorded time, the distance between the object and the sensor can
be calculated. The technique demands high time resolution electronics, usually
an avalanche photodiode. Besides timing laser pulse, diﬀerent methods have
been developed for the time-of-ﬂight systems, such as amplitude modulation
and frequency modulation methods.
The 3-D surface is scanned point by
point. The accuracy is in the order of 1 mm [4, 5]. Time-of-ﬂight technique
2

is suitable for measuring large scale objects (e.g. airplane) and conducting
landscape survey (e.g. building and plant).
1.1.3
Stereo vision
Stereo vision technique reconstructs 3-D geometry of an object using a pair
of 2-D images captured from two diﬀerent points of view [6]. In both im-
ages, pixel correspondences, which are the pixels that belong to the same 3-D
points, are detected by image correlation techniques. The intrinsic and ex-
trinsic parameters of the cameras are obtained by camera calibration. With
the pixel correspondences and camera parameters, the 3-D coordinates of the
3-D points can be calculated based on the projective geometry [7]. Multiple
images captured by one camera from diﬀerent perspectives can also be used for
camera calibration and 3-D geometry reconstruction [8]. As a passive optical
technique, no light pattern projection is required and the setup of stereo vision
technique is simple.
Due to the limited features that can be used for building pixel correspon-
dence in the image pair, the resolution of the technique is usually much lower
than that of the 2-D image. Although with the help of epipolar geometry,
building pixel correspondences is the bottle neck of the speed performance of
stereo vision technique. In order to assist building robust pixel correspon-
dences, eﬀorts such as mounting bright markers on the surface of the object
are made [9]. Illumination, surface condition, object geometry, and camera
calibration determine the measurement accuracy [10]. The accuracy of the
technique could achieve 0.1 mm [11].
1.1.4
Coded pattern projection
Coded pattern projection techniques facilitate the building of pixel correspon-
dences by projecting a single pattern or a set of light patterns onto the ob-
jects [12, 13]. The conﬁgurations of one camera and a projector or a pair of
cameras and a projector are employed. The pixels in the pattern have their
codewords. The camera captures the deformed pattern from an oﬀset angle.
The captured pattern is analyzed and the codewords are recognized, so that
pixels on the pattern can ﬁnd their correspondences located in the projected
pattern or in another camera image.
There are diﬀerent coding strategies, i.e. how to assign codewords to the
pixels. Color coding utilizes diﬀerent colors to code the pixels [14, 15]. Binary
coding only uses two illumination levels, which are 0 and 1. Every pixel has
a unique codeword formed by the combination of 0s and 1s [16, 17]. N-ary
coding reduces the large number of patterns to be projected by the binary
3

coding by increasing the coding basis [18, 19]. Intensity ratio coding is based
on linear changing gray levels [20, 21]. There are also hybrid techniques such
as color N-ary Gray code [22].
For coded pattern projection techniques, the larger number of pixels that
must be coded, the more complicated the coding is. Therefore pixel-by-pixel
resolution for coded pattern projection is diﬃcult to achieve especially for
high-resolution images.
1.1.5
Interferometry
Interferometric techniques are usually employed for measuring simple object
surface with high accuracy requirement, such as optical components. Most
interferometers use laser as the light source.
The laser beam is split into
two beams and sent into diﬀerent propagation paths. Then the beams are
superposed on the object’s surface to generate interference patterns, usually
fringe patterns. The fringe patterns are analyzed by phase shifting methods
or Fourier transform methods to obtain the phase map of the fringe pattern,
which is related to surface topography [23, 24]. The surface proﬁle is recon-
structed by using the geometry of the setup and the phase map.
Widely
used interferometers includes: Fizeau interferometer, Twyman-Green interfer-
ometer, Mach-Zehnder interferometer, and Michelson interferometer [25, 26].
White-light interferometer that utilizes broad bandwidth light source is also
used for optical metrology [27]. The accuracy of the interferometry measure-
ment systems can achieve 1/1000 of a fringe [5]. Various fringe pattern analysis
methods are developed to improve the resolution and accuracy of optical in-
terferometry systems, especially phase shifting methods [28].
1.1.6
Moir´e method
Moir´e method acquires the contour of the object surface by the interference of
two grating patterns, a reference grating pattern and the deformed reference
grating pattern [26, 29, 30, 31]. Moir´e method includes two kinds of techniques:
shadow moir´e and projection moir´e. Shadow moir´e uses a single grating placed
over the object [32, 33]. A camera and a point light source are mounted over
the grating. The grating produces a shadow that is cast on the object and
deformed by the 3-D surface topography. When the object is viewed through
the grating from a direction diﬀerent from the light source, the moir´e pattern
is observed as a result of the interference of the shadow of the grating and
the grating itself. Projection moir´e technique projects the grating onto the
object surface, and then observes the object through a second grating from
a diﬀerent point of view [34, 35, 36]. The distorted grating pattern on the
4

object surface interfere with the second grating to generate moir´e pattern.
The distance between the object and the gratings could be much larger than
that of the shadow moir´e setup.
The moir´e pattern obtained from both techniques contains 3-D surface
topography information. Analyzing the moir´e pattern by the phase shifting
method to obtain the phase map is a common practice.
The height map
between the grating and the object surface can be determined by using the
phase map and the geometry of the setup. The typical measurement range of
the phase shifting moir´e method is from 1 mm to 0.5 m with the resolution
at 1/10 to 1/100 of a fringe [5]. Moir´e method is utilized for full-ﬁeld non-
contact 3-D shape measurement in industry. Compared with interferometry,
the measurement range is larger and the optical setup is simpler.
1.1.7
Digital fringe projection
Digital fringe projection technique utilizes a liquid crystal display (LCD) pro-
jector or a digital light processing (DLP) projector to project single or multiple
sinusoidal fringe patterns onto a diﬀuse object surface [5]. The fringe pattern
is distorted by the 3-D shape of the surface. A camera mounted on an oﬀset
angle captures the deformed fringe patterns. The deformed fringe patterns
are analyzed by the phase shifting or the Fourier transform method to obtain
the phase map. The phase map along with the calibration parameters of the
camera and projector are employed to calculate the 3-D shape of the surface.
Digital fringe projection is a fast and ﬂexible full-ﬁeld 3-D shape measure-
ment technique. Phase shifts of the fringe patterns can be accurately intro-
duced into the fringe pattern without mechanical errors. Other parameters
can also be easily changed to satisfy the measurement requirements. High-
speed digital fringe projection system based on the digital micromirror device
(DMD) technology has been built [37]. Fig. 1.1 shows the principle of DLP
display technology. DMD is an array of micro mirrors mounted on hinges that
are individually controlled by the computer [38]. The grayscale of each pixel is
controlled by adjusting the time that each micro mirror stays at “on” position.
Color images are displayed by projecting the contents of color channels (R, G,
B) sequentially at a high image refreshing rate.
In the digital fringe projection system, the phase-shifted fringe patterns
are encoded in three color channels (R, G, B) and projected onto the object
surface sequentially at a frequency of 180 Hz. The projector works at the
black-and-white (B/W) mode. Therefore, the projected fringe patterns are all
in grayscale. The synchronized B/W camera captures the fringe images. The
3-D shape measurement result is generated by analyzing the captured fringe
patterns. Fig. 1.2 shows the system diagram of the high-speed digital fringe
5

Figure 1.1: System diagram of a DLP projectior.
projection system.
Fringe analysis is an important task for the digital fringe projection tech-
nique.
The fringe patterns are analyzed by phase shifting method or the
Fourier transform method. Phase shifting method needs at least three phase-
shifted fringe patterns to obtain the phase map [39].
The averaging eﬀect
of the phase shifting method makes the method robust to noises and back-
ground illumination variation. Also, solving phase map pixel by pixel renders
phase shifting method the ability to handle complex shapes. Because multiple
fringe patterns are needed, phase shifting method was considered less ideal for
measuring moving or changing objects.
The Fourier transform method only needs a single fringe pattern in order
to obtain the 3-D shape [40]. Therefore, Fourier transform method can be
used for 3-D shape measurement of moving objects or dynamic processes. The
disadvantage of the Fourier transform method is that the measurement quality
for object with complex shapes is limited due to the problems of processing
fringe pattern in spatial frequency domain, such as spectrum overlapping and
spectral leakage.
Compared with the coded pattern projection technique, the main advan-
tage of the digital fringe projection technique is pixel-by-pixel 3-D resolution.
Meanwhile, the fringe analysis process is fully automatic and robust to noises.
6

R
G
B
PC
DLP
Projector
B/W
Camera
RGB
Fringe
R
G
B
Object
I1
I2
I3
3-D
Result
Figure 1.2: System diagram of the high-speed digital fringe projection system.
1.2
Motivation and Objective
1.2.1
3-D shape measurement of dynamic objects
Full-ﬁeld high-resolution 3-D shape measurement has many applications, such
as medical imaging, motion capture, online inspection and biometrics. In most
of the above applications, moving or changing objects are involved and real-
time data processing is required, therefore real-time 3-D shape measurement
of moving or changing objects is of great research value.
Digital fringe projection technique is suitable for this task due to its high-
speed fringe projection capability. Although real-time 3-D shape measurement
system has been implemented on the digital fringe projection system using 3-
step phase shifting method, the object movement during the acquisition of
a sequence (a least three) fringe images causes measurement errors. On the
other hand, the Fourier transform method only needs one fringe pattern, but
its measurement results of objects with complex shapes are not satisfactory.
3-D shape measurement of moving or changing objects is a challenging task.
One way to improve the 3-D measurement result of fast moving or chang-
ing objects is to further increase the fringe pattern projection and acquisition
speed, which mostly relies on the improvement of the hardware systems of pro-
7

jector and camera. Currently, as further increasing the pattern projection and
capture speed meets the hardware bottleneck, improvement on the software
side seems more practical. Developing a modiﬁed Fourier transform method
to improve its ability of measuring complicated shapes can provide a solution
for measuring moving or changing objects. This research can substantially im-
prove the measurement results based on the current digital fringe projection
hardware systems.
1.2.2
Phase shifting shadow moir´e
Shadow moir´e for 3-D shape measurement has been extensively studied since
1970’s. By using phase shifting method to analyzing shadow moir´e patterns,
the phase calculation achieved automation, and the resolution has been greatly
improved. However, generating phase-shifted moir´e patterns with the shadow
moir´e optical setup is not an easy task, especially when the phase shifting
algorithm employed demands uniform phase shift across the ﬁeld of view.
During the past two decades, various procedures have been proposed in
eﬀort to introduce phase shifts into a shadow moir´e setup. Mauvoisin et al.
studied the methods that could possibly produce phase shifts, which include:
changing the grating period, changing the distance between the light source
and camera, changing the distance between the grating plane and camera-light
source plane, changing the distance between object and the grating plane[32].
Their works showed that exact uniform phase shifts across the ﬁeld of view
is theoretically impossible due to the nonlinear nature of the height-phase
relation. Therefore, typical phase shifting algorithms fail to produce accurate
results.
Various techniques that introduce approximate uniform phase shifts in the
ﬁeld of view have been proposed. However, no exact close-form phase solution
has been provided by these techniques. In this research, we aim to develop a
phase shifting scheme for the shadow moir´e method to provide exact close-form
phase solution, in order to improve the measurement accuracy.
1.2.3
3-D human face recognition
During the past decade, human face recognition has been attracting more and
more researchers because of the growing demands from security surveillance,
law enforcement, information control, and entertainment industry [41, 42].
Face recognition is an intuitive biometrics.
Face image acquisition require
less subject cooperation and awareness to collect than those of ﬁngerprints,
irises, voice or signature. Based on the underlying face data, face recognition
methods can be divided into two groups, 2-D methods and 3-D methods [43].
8

The performance of 2-D face recognition methods are greatly inﬂuenced by the
illumination and facial skin texture variations. 3-D methods are not aﬀected
by illumination and texture variations, but the 3-D reconstruction of the facial
geometry is not computationally eﬃcient and the size of the 3-D data is huge.
We seek a more eﬃcient facial representation that can utilize the underly-
ing 3-D face geometry without reconstructing the 3-D coordinates. Since the
digital fringe projection technique for 3-D shape measurement extracts the
3-D information by analyzing the deformed fringe patterns, it is possible to
directly make use of the 3-D face information for recognition purpose by fringe
analysis. The background illumination and surface texture can be solved from
phase-shifted fringe patterns by the phase shifting method. The Fourier trans-
form method extracts the 3-D shape related spectra in the spatial frequency
domain. In this research we propose to employ a spectral face representation
acquired by fringe analysis for face recognition.
1.2.4
Research objectives
The objectives of this dissertation research are listed as follows:
• Develop pattern projection schemes for the modiﬁed Fourier transform
method.
• Develop an eﬀective phase unwrapping method for the modiﬁed Fourier
transform method.
• Develop absolute phase retrieval techniques for the modiﬁed Fourier
transform method.
• Implement the modiﬁed Fourier transform method on the digital fringe
projection system to achieve real-time 3-D shape measurement of moving
or changing objects.
• Develop a phase shifting shadow moir´e method to provide exact close-
form phase solution.
• Verify the proposed phase shifting shadow moir´e method by simulation
and experiments
• Develop a face recognition method based on the digital fringe projection
technique and fringe analysis.
• Design experiments and simulation to evaluate the face recognition method’s
performance.
9

1.3
Dissertation Structure
This dissertation includes ﬁve chapters. Chapter 1 is the introduction. The
background, motivation, and the objectives of this dissertation are introduced.
Chapter 2 presents the proposed modiﬁed Fourier transform method for
real-time 3-D shape measurement. The method adopts the hardware system
of a previously built high-speed digital fringe projection system. Two pattern
projection schemes are proposed in order to prevent the spectrum overlap.
Both of the pattern projection schemes produce a ﬂat image that does not
contain fringe pattern. A binary mask is generated based on the grayscale
histogram of the ﬂat image. The windowing technique is applied to reduce
spectral leakage. The phase map is calculated. A phase unwrapping method
is proposed for the modiﬁed Fourier transform method which utilizes the fringe
visibility as a quality index to guide the path-following unwrapping algorithm.
Two absolute phase map retrieval methods are designed for the pattern projec-
tion schemes respectively. The 3-D reconstruction process is brieﬂy introduced,
in which the 3-D coordinates are computed based on the absolute phase map.
Experiments demonstrated the real-time 3-D shape measurement results of
face sequences while the subjects are speaking. Improvements over the 3-step
phase shifting method are observed in the results.
Chapter 3 introduces a phase shifting shadow moir´e technique based on
the Carr´e algorithm. First, the recent research work related to phase shifting
shadow moir´e is reviewed. The principle of the shadow moir´e technique is
introduced. Then, the phase shifting scheme is proposed to obtain four phase-
shifted moir´e patterns. A grating pattern removal method is described. After
removing the unwanted grating pattern, the Carr´e algorithm is applied to the
phase-shifted moir´e patterns to obtain the exact close-form phase solution. A
simulation is designed using MatLab. The proposed method is veriﬁed by the
simulation program. Experimental results of a NIST calibration block and a
lens also demonstrated satisfactory measurement results.
Chapter 4 proposes a face recognition method based on digital fringe pro-
jection. Digital fringe projection technique has been successfully employed in
Chapter 2 for real-time high-resolution 3-D shape measurement. This chapter
presents a novel 3-D face recognition method that directly utilizes 2-D images
generated by a structured light system without reconstructing the 3-D geom-
etry. First the related research work is reviewed. Then the fringe pattern
projection scheme is brieﬂy introduced. Three phase-shifted sinusoidal fringe
patterns are sequentially projected onto the subject’s face.
The distorted
fringe patterns are captured by the camera and analyzed by the phase shift-
ing method to remove texture and illumination. The resultant fringe pattern
is transformed into frequency domain, where the spectra related to the 3-D
10

facial geometry are ﬁltered out. The eigenface algorithm is applied to the face
spectra to perform the recognition. In order to evaluate the proposed method,
experiments are carried out using the digital fringe projection system. In order
to compare the proposed method with the baseline 2-D method, a simulation
is designed by use of the Face Recognition Grand Challenge 2.0 (FRGC2.0)
face database. In the simulation, the fringe pattern is virtually projected on
the 3-D face. Both the simulation results showed promising recognition rate.
Chapter 5 summarizes this dissertation research and outlines the future
research work.
11

Chapter 2
Modiﬁed Fourier Transform Method for Real-time 3-D
Shape Measurement
With the fast development of camera and projector technologies, the digital
fringe projection technique for 3-D shape measurement is now capable of high-
speed and high-resolution measurement. As successful as it has been proved
on measuring still or slow-moving objects, the digital fringe projection systems
utilizing phase shifting methods can only produce less satisfactory results when
handling fast moving or changing objects. The main limitation for the phase
shifting method is that a series of fringe patterns (at least three) taken in
sequence are required. This chapter proposes a modiﬁed Fourier transform
method for real-time 3-D shape measurement. The method is implemented on
the digital fringe projection system introduced in the previous chapter. The
proposed method greatly improved measurement results on moving or chang-
ing objects compared with 3-step phase shifting method, while maintaining
high measurement speed and resolution.
This chapter is organized as follows. Section 2.1 introduces the conven-
tional Fourier transform method for 3-D shape measurement and brieﬂy re-
views recent related research work. Section 2.2 presents the fringe projection
schemes of the modiﬁed Fourier transform method. Section 2.3 presents the
quality-guided phase unwrapping method. Section 2.4 introduces the absolute
phase map retrieval. Section 2.7 shows the experimental results. Section 2.8
summarizes this chapter.
2.1
Introduction
The Fourier transform method (FTM) for 3-D shape measurement, which is
also referred to as Fourier transform proﬁlometry (FTP), is a widely used full-
ﬁeld optical method for 3-D shape measurement [26, 44]. FTM was originally
developed for the analysis of simple fringe patterns generated by interferome-
12

try [40]. Later, it was successfully applied to 3-D shape measurement [45, 46].
Conventional FTM only needs one frame of fringe pattern to obtain the phase
map. Therefore it is much less sensitive to motion, compared to the phase
shifting methods, such as 3-step method, 4-step method, or Carr´e algorithm,
which needs multiple (at least 3) fringe patterns. However, the shortcomings of
the FTM prevent it from directly being applied in the digital fringe projection
system for real-time 3-D shape measurement. To facilitate further discussion
of those shortcomings, the principle of the conventional FTM for 3-D shape
measurement is brieﬂy reviewed as follows.
2.1.1
Principle of the Fourier transformed method
A sinusoidal fringe pattern can be expressed as follows,
g(x, y) = a(x, y) + b(x, y) cos[2πf0x + φ(x, y)] ,
(2.1)
where φ(x, y) is the phase that contains the shape information, a(x, y) relates
to the background illumination, b(x, y) represents the local amplitude of the
cosine function and relates to the surface reﬂectivity. f0 is the carrier frequency.
Applying Euler’s formula to Eq. 2.1,
g(x, y) = a(x, y) + c(x, y)ei2πf0x + c∗(x, y)e−i2πf0x ,
(2.2)
where
c(x, y) = 1/2b(x, y)eiφ(x,y) ,
(2.3)
and ∗denotes a complex conjugate. By taking 1-D Fourier transform with
respect to x, Eq. 2.2 gives
G(fx, y) = A(fx, y) + C(fx −f0, y) + C∗(fx + f0, y) ,
(2.4)
where A(fx, y) and C(fx −f0, y) are the 1-D Fourier transforms of a(x, y)
and c(x, y) respectively. Assume φ(x, y), a(x, y), and b(x, y) vary very slowly
compared to the carrier frequency f0. The three terms in Eq. 2.4 are separated
in the spatial frequency domain. The Fourier spectra are shown in Fig. 2.3. A
properly designed ﬁlter is applied to isolate the C(fx−f0, y) term. Then C(fx−
f0, y) is taken inverse Fourier transform. The phase φ(x, y) can be extracted
by computing the logarithm of c(x, y), and then isolating the imaginary part.
φ(x, y) = Im [log[c(x, y)]] = Im
·
log
·1
2b(x, y)
¸
+ iφ(x, y)
¸
,
(2.5)
13

Figure 2.1: Fourier spectra |G(fx, y)|.
The phase thus obtained is wrapped in the range of −π to π. To remove the
2π discontinuity, a phase unwrapping process can be applied. The unwrapped
phase map is a continuous phase map. A reference plane is utilized to retrieve
the 3-D shape based on the geometry of the optical setup [45]. This reference
phase map is subtracted from the unwrapped phase map. The resulting phase
map ∆φ(x, y) is converted to coordinates according to the geometric setup
shown by Fig. 2.2. The height of the surface point D(i, j) is DB. Since DB is
much smaller than the distance between the system and the object in practice,
the height of of point D(x, y) is calculated by the following equation,
Z(i, j) = DB ≈l
dAC = pl
2πdφAC = Kz∆φ(i, j) ,
(2.6)
where l is the distance between the reference plane and the line connecting the
optical centers of DMD and CCD, and d is the distance between the above two
centers. p is the fringe pitch of the reference plane. K is a calibrated constant.
∆φ(i, j) is the phase value at point D(i, j). The X and Y coordinates are
calculated by use of two calibrated constants Kx and Ky.
X(i, j) = Kxi ,
(2.7)
Y (i, j) = Kyj .
(2.8)
Conventional FTM’s salient advantage is that only one frame of fringe image
is needed. It is ideal for 3-D shape measurement of fast moving or chang-
ing objects. However, the Fourier transform method has the following limita-
tions that aﬀect the measurement quality when measuring object with complex
14

P 
Object   D 
I 
l 
DMD 
CCD 
Reference plane  
d 
B 
A 
C  O 
Figure 2.2: Phase-to-coordinate conversion in the conventional Fourier trans-
form method.
shapes, such as steep slopes and holes.
First, spectral overlapping. The overlapping of the background terms and
the terms containing phase information occurs in the spatial frequency do-
main when measuring complex 3-D shapes [44]. Steep slopes will dramatically
change the carrier frequency from the camera’s point of view. The spectra
around the carrier frequency sometimes overlap with the spectra around the
zero frequency.
Second, spectral leakage.
Discrete Fourier transform (DFT) will gener-
ate spectral leakage when discontinuity occurs at the ends of the signal [47].
The length of the sinusoidal fringe pattern is ﬁnite. The 1-D discrete Fourier
transform assumes the fringe pattern is a part of an inﬁnite repetitive fringe
pattern. Therefore, if the two ends of the fringe pattern can not be connected
smoothly, sharp discontinuities will generate broad band frequency compo-
nents and spread over the spectrum. Also, edges of the holes and shadows in
the fringe pattern are discontinuities that causes spectral leakage. The spectral
leakage produces phase errors.
Third, robustness of phase unwrapping. The only fringe pattern used by
the conventional FTM is usually corrupted by noises. Therefore, unwrapping
process is diﬃcult due to lack of reliable information that could be used to
guide the phase unwrapping process.
15

Fourth, the accuracy of the 3-D coordinate reconstruction. The conven-
tional FTM used a reference plane and assuming small surface height variation
from the reference plane and approximation is used in the phase-to-height con-
version, as shown in Eq. 2.5. The coordinate conversion model is not suitable
for applications requiring large height measurement range. Also, the lens dis-
tortions of the camera and projector were not considered in the coordinate cal-
culation. Accurate phase-to-coordinate conversion requires the absolute phase
map retrieval to be used with the more sophisticated camera and projector
calibration model.
2.1.2
Related work
In order to improve the conventional FTM, diﬀerent fringe projection schemes
were studied [48, 49, 50]. Chen et al. proposed to use a bicolor fringe pattern to
obtain two recorded fringe patterns with a 180◦phase shift to each other [48].
The unwanted background term is removed by subtracting one of the fringe
patterns from the other. The zero frequency terms in the spatial frequency are
eliminated; and as a result, the spectrum overlapping is prevented. Also, the
noise level is reduced in the resulting high contrast fringe pattern. The main
disadvantage is that the object surface color signiﬁcantly aﬀect the accuracy in
that the color pattern is employed. Yue et al. proposed a novel technique that
uses a fringe pattern modulated from two 180◦phase-shifted gray level fringe
pattern [49]. The modulated fringe pattern is ﬁrst projected onto the object,
then the recorded deformed fringe pattern is demodulated into two 180◦phase
shifted fringe patterns. Finally the unwanted zero frequency components are
removed. The disadvantage of this technique is that the two phase-shifted
fringe patterns are decoded by ﬁltering in the frequency domain, and then
by inverse Fourier transform. Thus the ﬁnal recovered phase is obtained by
two times of fast Fourier transform (FFT) and inverse fast Fourier transform
(IFFT), which are not only computationally expensive but also degrades the
accuracy. In this research, more eﬀective fringe pattern projection schemes for
Fourier transform method are proposed.
Phase unwrapping is a common yet diﬃcult task for fringe analysis meth-
ods, especially when noises and geometric discontinuities exist in the phase
map. Various phase unwrapping techniques have been proposed to solve the
phase unwrapping problems in various applications [51].
Branch cut algo-
rithms connect nearby residues by branch cuts and unwrap the phase map by
integrating the phase diﬀerence around the branch cuts [52, 53, 54]. Quality-
guided algorithms ﬁrst generate a quality map that indicates the goodness
of the phase, and then unwrap the pixels with good quality ﬁrst [55, 56, 57].
Minimum discontinuity approach identiﬁes the loops of discontinuities and add
16

appropriate multiples of 2π to the pixels in the loops [58]. Minimum Lp-norm
method and weighted least-squares method minimize the wrapped phase diﬀer-
ence between the wrapped phase map and the unwrapped phase map [59, 60].
Temporal phase unwrapping method utilizes a series of fringe patterns with
changing pitches to accomplish phase unwrapping [61]. Depending on the ap-
plications, every algorithm has its own advantages and disadvantages. The
phase unwrapping algorithm needs to be selected based on the requirements
of the system and the characteristic of the wrapped phase map.
As to the phase unwrapping problem speciﬁc to the Fourier transform
method, Takeda et al. proposed to use frequency-multiplex fringe pattern to
improve the phase unwrapping process [46]. Burton et al. proposed multi-
channel Fourier fringe analysis to aid the unwrapping process [62]. Those two
techniques need more than one fringe patterns to be projected onto the object,
and the same number of wrapped phase maps need to be calculated. This is
computationally expensive because FFT and inverse FFT operations are re-
peatedly used for each fringe pattern. Zappa and Busca compared eight of
the above-mentioned phase unwrapping algorithms used for unwrapping the
phase map generated by the Fourier transform method for 3-D shape measure-
ment [63]. Among them, the quality-guided algorithm achieved a better result
with reasonable execution time. Phase unwrapping method proposed by Su
et al. used data modulation of the recorded fringe pattern as a quality index
to guide the unwrapping process [62]. The data modulation is deﬁned as the
peak-to-peak amplitude of the sinusoidal fringe pattern, which is closely related
to the local reﬂectivity of the object surface. The algorithm achieved satis-
factory unwrapping results. In this research, we will develop quality-guided
phase unwrapping algorithm for the proposed fringe projection schemes.
The 3-D reconstruction in the previously proposed Fourier transform meth-
ods utilized a reference plane [48, 49]. Hu and Harding’s recent work showed
speciﬁcally that the phase shifting method with the absolute phase map con-
cept was signiﬁcantly more accurate than the Fourier transform method with
the reference plane approach [64]. The drawbacks of the phase-to-coordinate
conversion algorithm using the reference plane include: (1) The optical system
setup is complicated and requires high accuracy calibration. (2) The conver-
sion of coordinates is only accurate when the measured surface is very close
to the reference plane. (3) The algorithm itself cannot take the camera and
projector lenses distortion into account.
17

2.2
Modiﬁed Fourier Transform Method
We seek to utilize additional information to solve the existing problems of
the conventional FTM. The inﬂuence of the background illumination can be
removed if we could obtain image that exactly describes the background illu-
mination of the fringe pattern:
g0(x, y) = a(x, y) ,
(2.9)
where a(x, y) is the same term in Eq. 2.1 representing the background illumina-
tion. Subtracting Eq. 2.9 from the captured sinusoidal fringe image expressed
in Eq. 2.1, and then performing the 1-D Fourier transform with respect to x,
we have
G′(fx, y) = C(fx −f0, y) + C∗(fx + f0, y) .
(2.10)
With the background illumination removed, the zero frequency terms are
out of the equation before the Fourier transform, and the overlapping in the
frequency domain can be prevented or at least alleviated. The magnitude of
the Fourier spectra are shown in Fig. 2.3.
Figure 2.3: Fourier spectrum
We propose to obtain the background illumination term by taking advan-
tage of previously developed high-speed digital fringe projection system. The
working principle of the system has been introduced in Chapter 1. The sys-
tem consists of a digital video projector based on digital micro-mirror device
(DMD) and a high-speed black-and-white (B/W) camera.
Three diﬀerent
fringe patterns can be encoded in three color channels (R, G, and B), and the
fringe patterns are captured sequentially at a frequency of 90 frame/second or
18

higher. There is great ﬂexibility of designing fringe pattern for each color chan-
nel. Based on this fringe projections system, two fringe projection schemes are
proposed. The ﬁrst one directly projects one ﬂat pattern and a fringe pattern.
The other one projects three phase-shifted fringe patterns. The details of the
two schemes are introduced as follows.
2.2.1
Flat pattern + fringe pattern
 
Phase Map
FFT
and
IFFT
 
Unwrapping
and 3-D
reconstruction
3-D Image
 
 
Fringe image
R channel
Flat Image
G channel
Subtract
Binary
Mask
Figure 2.4: Schematic system diagram for the modiﬁed Fourier transform.
In the ﬁrst scheme, a ﬂat pattern and a sinusoidal fringe pattern are em-
ployed.
The schematic diagram of the method is shown in Fig. 2.4.
Flat
pattern means a uniform grayscale pattern whose intensity value is the aver-
age of the sinusoidal fringe pattern. A fringe pattern and a ﬂat pattern are
encoded in the color channels (R, G and B). When the fringe and ﬂat patterns
are projected onto the object, the synchronized camera captures the fringe
image g0(x, y) and ﬂat image g(x, y) sequentially.
2.2.2
Three phase-shifted fringe patterns
In the second scheme, the system projects three phase-shifted fringe patterns
with 2π/3 phase shift between neighboring fringe pattern. Averaging three
captured fringe images can generate a ﬂat image. Three phase-shifted fringe
patterns are expressed as follows.
p1(x, y) = ap + bp cos
·
2πf0x −2π
3
¸
,
(2.11)
p2(x, y) = ap + bp cos [2πf0x] ,
(2.12)
p3(x, y) = ap + bp cos
·
2πf0x + 2π
3
¸
,
(2.13)
19

(a)
(b)
−250
−200
−150
−100
−50
0
50
100
150
200
250
0
500
1000
1500
2000
2500
3000
3500
4000
Frequency
||G’||
(c)
−250
−200
−150
−100
−50
0
50
100
150
200
250
0
0.5
1
1.5
2
2.5
x 10
4
Frequency
||G’||
(d)
Figure 2.5:
Flat+fringe pattern projection. (a)Fringe image; (b)Flat image;
(c)Spectrum of 320th row with the ﬂat image subtracted; (d)Spectrum of 320th
row of the fringe image.
20

 
 
 
 
 
0o
120o
240o
Flat Image
Phase map
Averaging
Subtract
Binary
Mask
FFT and
IFFT
fringe
image
 
Unwrapping
and 3-D
reconstruction
3-D Image
Figure 2.6: Schematic diagram for the modiﬁed Fourier transform using 3
fringe images.
where ap is the bias and bp is the amplitude of the fringe pattern. The fringe
patterns represented by Eq. 2.11 ∼Eq. 2.13 are encoded into three color
channels of a DLP projector and projected onto the object. The captured
fringe images have the following forms,
g1(x, y) = a(x, y) + b(x, y) cos
·
2πf0x + φ(x, y) −2π
3
¸
,
(2.14)
g2(x, y) = a(x, y) + b(x, y) cos [2πf0x + φ(x, y)] ,
(2.15)
g3(x, y) = a(x, y) + b(x, y) cos
·
2πf0x + φ(x, y) + 2π
3
¸
,
(2.16)
where φ(x, y) is the phase that contains the shape information, a(x, y) repre-
sents the background illumination, b(x, y) is related to the surface reﬂectivity,
and f0 is the carrier frequency of the fringe pattern. The background term is
solved by averaging the three fringe patterns,
a(x, y) = g1(x, y) + g2(x, y) + g3(x, y)
3
.
(2.17)
The background a(x, y) is the ﬂat image of the object without the fringe pat-
tern. In every three consecutive captured fringe images g1(x, y), g2(x, y),g3(x, y),
21

the background is calculated and subtracted from g2(x, y). Then the Fourier
transform is followed to obtain the phase map.
(a)
(b)
(c)
250
−200
−150
−100
−50
0
50
100
150
200
250
0
200
400
600
800
1000
1200
1400
1600
1800
2000
Frequency
||G’||
(d)
250
−200
−150
−100
−50
0
50
100
150
200
250
0
2000
4000
6000
8000
10000
12000
14000
16000
18000
Frequency
||G’||
(e)
Figure 2.7:
Three phase-shifted pattern projection.
(a)-(c)Fringe images;
(d)Spectrum of 320th row with the ﬂat image subtracted; (e)Spectrum of
320th row of the second fringe image.
Comparing the two fringe projection schemes, the “ﬂat+fringe” scheme
needs less patterns. Therefore it is more suitable for measuring fast moving or
changing objects. However, the disadvantages include (1) The grayscale of the
ﬂat pattern needs to be calibrated in order to compensate for the grayscale
error of the projector.
(2) The system needs to diﬀerentiate the captured
fringe image from the ﬂat image. The advantages of using three phase-shifted
fringe patterns to generate the ﬂat image include: (1) No grayscale calibration
is needed. (2) The averaging eﬀect helps to reduce random intensity noises.
(3) The order of the phase-shifted fringe pattern does not aﬀect the phase
calculation. Any three consecutive fringe patterns can be used to generate
the ﬂat image.
The disadvantage is that three fringe patterns are needed
22

to calculate one 3-D image.
It needs more time to capture fringe images
and defects caused by motion are more likely to occur. Therefore, ﬂat+fringe
pattern projection is preferred when measuring fast moving objects. For slowly
moving or changing objects, three phase-shifted pattern projection scheme can
achieve better results.
2.2.3
Binary mask generation
In order to reduce the spectrum leakage, various of “windows” can be applied
to the data. Shadows and holes need to be detected in the fringe patterns
before the windows can be applied. The shadows and holes are detected in
the ﬂat image based on an intensity threshold. The object was put in front
of a black background when capturing the images. Shadows and holes appear
to be the dark areas in the captured ﬂat image. The intensity threshold is
generated based on the grayscale histogram of the ﬂat image. In the histogram,
the intensity value corresponding to the valley between the two peaks formed
by the foreground and background is selected as the intensity threshold. For
diﬀerent surfaces such as, plastic workpiece and human face, new thresholds
need to be determined by this process. A binary mask is generated based on
the threshold to indicate the shadows and holes. Fig. 2.2.3 shows the histogram
and the binary mask for the free-form workpiece used in previous examples.
Windows will be applied based on the boundaries marked by the binary mask.
1-D forward and inverse FFT will be performed within each continuous valid
fringe pattern area indicated by the binary mask. Thus the computation time
is greatly reduced.
2.2.4
Spectral leakage reduction
For an undistorted sinusoidal fringe pattern with a constant carrier frequency
f0, there should be only one non-zero frequency component f0 in the corre-
sponding spatial frequency spectrum. However, when using FFT to transform
such a sinusoidal fringe pattern with non-integer number of periods into spa-
tial frequency domain, the spectrum will spread to all frequency components
instead of concentrated on the carrier frequency of the fringe pattern. This
is known as spectral leakage. The spectral leakage will decrease the signal to
noise ratio in that it causes a given spectral component to contain not only
its own signal energy, but also the energy from the rest of the spectrum. In
FTM for 3-D shape measurement, the phase term is obtained by forward and
inverse FFT. Spectral leakage in FFT will introduce phase errors.
An eﬀective means to reduce spectral leakage is to modulate the amplitude
of the signal to make the signal ﬁt into one period, which is called windowing.
23

(a)
(b)
Figure 2.8:
Binary mask generation. (a) Histogram of the ﬂat image; (b)
Binary mask.
0
50
100
150
200
250
300
350
400
450
500
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Hamming Window
(a)
0
50
100
150
200
250
300
350
400
450
500
0
20
40
60
80
100
120
140
160
Windowed Sinusoidal Fringe Pattern
(b)
Figure 2.9: Window function. (a)Hamming window; (b)Windowed sinusoidal
fringe pattern.
24

A window function is multiplied with the data to achieve windwoing. In order
to reduce spectral leakage, various windows can be applied to the signal data
before performing FFT [47]. Both ends of a 1-D signal are compressed to
a value near zero to make sure they are approximately continuous. Some of
the widely used windows are Hamming window, Hanning window, Blackman
window, and Kaiser window. Berryman et al. studied the eﬀectiveness of the
windowing functions on the FTM [65]. The research shows that the windowing
can improve the measurement quality when the fringe pattern is not dense and
noise level is low. The disadvantage of the windowing is that windowing func-
tions compress the data close to both ends are close to zero. The compression
of amplitude degrades the quality of the phase values in those areas. Fig. 2.9
shows the windowing of a sinusoidal fringe pattern. The period of the fringe
pattern is 20 pixel/cycle.
Extension of the boundaries of the fringe pattern has been proved eﬀective
on reducing error [66]. In this research, in order to reduce spectral leakage
while preserving measurement qulaity, the data is extended at both ends with
zeroes, before a 1-D Hamming window is applied.
After the inverse FFT,
the extended data are discarded. A white plane cardboard is employed to
demonstrate the spectral leakage reduction by windowing. Three phase-shifted
fringe patterns projected onto the cardboard are captured.
The period of
the fringe pattern is 20 pixel/cycle. The 3-D measurement results are shown
in Fig. 2.10. When no window function is applied, spectral leakage causes
“ripples” on the plane, especially on both edges. When Hamming window is
applied without extending the boundary of the fringe pattern, the ripple error
is reduced. When both boundaries in the X direction are extended by 10%
of the width of the plane before applying the Hamming window, the ripple
error is further reduced. Fig. 2.10(d) - Fig. 2.10(f) show the cross sections of
the measurement results. A ﬁtted straight line is shown in the cross section
plot. The root mean square (RMS) error of the data against the ﬁtted line
is calculated. The measurement result without windowing has an RMS error
of 0.5537 mm. Windowing the fringe pattern directly reduced the ripples but
errors on the borders are still high (RMS=0.6539 mm). Windowing with the
extension of the boundaries generates a much lower error (RMS=0.3402 mm).
2.3
Phase Unwrapping
The wrapped phase maps obtained by the above methods are in the range
of −π to π. The process of removing the 2π discontinuities is called phase
unwrapping. The phase unwrapping process is important for acquiring the
accurate 3-D shape of the object.
25

(a)
(b)
(c)
−50
0
50
100
150
200
250
−50
−48
−46
−44
−42
−40
−38
−36
−34
−32
−30
X(mm)
Z(mm)
Measured Data
Fitted Data
(d)
−50
0
50
100
150
200
250
−50
−48
−46
−44
−42
−40
−38
−36
−34
−32
−30
X(mm)
Z(mm)
Measured Data
Fitted Data
(e)
−50
0
50
100
150
200
250
−50
−48
−46
−44
−42
−40
−38
−36
−34
−32
−30
X(mm)
Z(mm)
Measured Data
Fitted Data
(f)
Figure 2.10: Windowing eﬀect on the results of MFTM. (a)-(c) 3-D images of
a white plane cardboard aﬀected by windowing; (d)-(e)Cross sections at the
same row from (a)-(c).
26

Phase unwrapping for the phase map produced by FTM is a diﬃcult task
when noise level is high and less information is available, compared to phase
shifting methods. Meanwhile, the real-time 3-D reconstruction requires high
processing speed. The quality-guided can produce robust unwrapping results
with reasonable speed for high-speed applications. In this section, a quality-
guided unwrapping algorithm using fringe visibility as quality index is pro-
posed for the modiﬁed FTM. First, two quality indexes are introduced. Then,
the path following algorithm is introduced. The unwrapping results are shown
at the end of this section.
2.3.1
Quality index
Quality index plays an important role in quality-guided path following algo-
rithms. It is the information recovered from the wrapped phase map or from
the fringe images, which can be used to determine the goodness of the phase
quality. In this research, phase gradient and fringe visibility are employed to
assist the quality-guided phase unwrapping process and their results compared.
Phase Gradient
Phase gradient is calculated from the wrapped phase map. It is deﬁned as
follows.
∆(i, j) =
q
(∆x
i,j)2 + (∆y
x,y)2 ,
(2.18)
where,
∆x
i,j = W{φ(i + 1, j) −φ(i, j)} ,
(2.19)
∆y
i,j = W{φ(i, j + 1) −φ(i, j)} ,
(2.20)
Here W{} is a wrapping operator, φ(i, j) is the wrapped phase map, and
∆x
i,j and ∆y
i,j are the wrapped phase diﬀerence in the horizontal and vertical
directions. Phase gradient is a quality measure that indicates the variation of
the phase in both X and Y direction. It has been successfully used as a quality
index for phase unwrapping in the phase shifting method [67]. Low phase
gradient value indicates high phase quality. For the Fourier transform method,
higher carrier fringe frequency helps to preserve details in the 3-D measurement
result. Unfortunately, when the pitch of the fringe pattern is small (high carrier
frequency), the phase variation is large in the areas even without geometric
discontinuities. In the modiﬁed Fourier transform method, a higher carrier
frequency is preferred because it allows for ﬁner details of an object to be
measured.
As a result, the ability of phase gradient for classifying phase
quality is greatly limited. The resulting high phase gradient in the wrapped
27

phase map poses a problem for the quality-guided unwrapping algorithm using
only phase gradient as the quality index to distinguish noises.
In the proposed method, phase gradient is employed in the preprocessing
step. A threshold of phase gradient is set to eliminate pixels with abnormally
high phase gradient values.
Visibility
Visibility is a measure of the contrast of the fringe pattern. Its value is in
the range of [0, 1] with 0 indicating zero visibility of the fringes. In a digital
fringe projection system, geometric discontinuities typically create shadow ar-
eas because of the oﬀset angle between the light source and the camera. Low
visibility value means low signal-to-noise ratio, which usually implies poor
phase quality [68]. In colored surface areas, although the modulation value
of the pixel is low, the phase quality can be good if contrast is high enough.
Visibility map has better discrimination power than modulation map in such
cases. The visibility map of the sinusoidal fringe pattern is expressed as
γ(x, y) = b(x, y)
a(x, y) ,
(2.21)
where a(x, y) and b(x, y) have the same meanings as those in Eq. 2.1. The vis-
ibility map is diﬃcult to obtain in the conventional Fourier transform method.
In the proposed modiﬁed Fourier transform method, the visibility map can be
calculated by using the ﬂat image as a(x, y). Based on Eq. 2.10,
b(x, y) = 2|C(fx −f0, y)| ,
(2.22)
In this research, visibility map and phase gradient map are employed as the
quality maps to guide the unwrapping process.
2.3.2
Quality-guided path following
A masking operation is performed before the unwrapping process begins. First,
an intensity threshold is generated to identify areas with shadows and holes
based on the grayscale values of the ﬂat image, and to exclude pixels with
intensity values close to zero. The threshold is chosen based on the intensity
histogram of the ﬂat image. Then, the phase gradient map is calculated based
on Eq. 2.18-Eq. 2.20 and a threshold is selected to eliminate pixels with higher
phase gradient values than the threshold. Also, a threshold of visibility is set
to eliminate pixels with poor phase quality from the unwrapping process.
28

The quality-guided path-following phase unwrapping process is performed
using the ﬂood-ﬁll algorithm [57]. The visibility map is employed as the qual-
ity map.
The algorithm utilizes an adjoin list to store sorted pixels to be
unwrapped. In our method, the adjoin list is formed by N queues, which are
corresponding to N quality levels. Phase unwrapping is an iterative process.
Our quality-guided phase unwrapping process is illustrated in Fig. 2.11. At the
3
4
5
6
7
6
2
1
5
3
1
3
5
6
2
4
5
6
7
6
5
3
5
6
9
4
6
1
3
4
2
1
4
Starting piont
Unwrapped pixel
Pixel in the
adjoin list
Current pixel
Figure 2.11: Flood-ﬁll algorithm.
beginning of the process, a starting pixel close to the image center is selected,
whose quality is over a pre-set threshold, and is marked as “unwrapped” Then
the four neighboring pixels of the starting pixel are examined. If they are not
masked out, then they are pushed into queues corresponding to their quality
values. In the next step, queues are checked from high quality to low quality.
If the queue of highest quality pixels is not empty, a pixel is popped out, and
its phase value is unwrapped by use of Eq. 2.23 or Eq. 2.24, depending on the
relative position with the unwrapped neighboring pixel:
ϕ(i, j) = ϕ(i −1, j) + ∆x
i,j ,
(2.23)
ϕ(i, j) = ϕ(i, j −1) + ∆y
i,j ,
(2.24)
where ϕ(i, j) is the unwrapped phase and ∆x
i,j and ∆y
i,j are the wrapped phase
diﬀerence along the X and Y directions respectively. Once this is done, the
pixel is then marked as ”unwrapped”. Its four neighboring pixels are then
examined in the same way. The process continues until all the queues are
empty.
The proposed phase unwrapping method for modiﬁed FTM is tested using
a plaster sculpture with complex shape. The fringe and ﬂat images at a reso-
lution of 532×500 pixels. Each pair of images has two identical fringe images
and one ﬂat image. The ﬂat pattern’s intensity is calibrated to compensate for
the grayscale error of the projector, so that the captured ﬂat image represents
the average intensity of the fringe image. Fig. 2.12 shows the fringe image and
29

(a)
(b)
(c)
(d)
Figure 2.12: Phase unwrapping result of a model. (a) Fringe image. (b) Flat
image. (c) Wrapped phase map. (d) Visibility map.
the ﬂat image. The fringe pattern used in the experiment has a pitch of 9 pix-
els/fringe. The surface of the statue is white. The visibility variation is caused
mainly by the surface shape. In the visibility map shown in Fig. 2.12(d), low
visibility values are seen in the areas of shadows or geometric discontinuities.
In Fig. 2.13, the four intermediate steps in the quality-guided unwrapping
process are shown. The unwrapping process starts from a pixel close to the
center of the image. Pixels with high phase quality are unwrapped ﬁrst. The
ﬂood-ﬁll algorithm successfully grows the unwrapped region until it has com-
pletely unwrapped the phase map, as shown in Fig. 2.13(d).
30

(a)
(b)
(c)
(d)
Figure 2.13: Quality-guided phase unwrapping process. (a) Intermediate step
1. (b) Intermediate step 2. (c) Intermediate step 3. (d) Final result.
31

2.4
Absolute Phase Retrieval
The resulting continuous phase map is a relative phase map φ(x, y), whose
value depends on the starting point of the unwrapping process. An absolute
phase map is required by the 3-D reconstruction process. The phase value
distribution in an absolute phase map does not depend on the start point of
the unwrapping process. The phase values in the absolute phase map can
be used to build the correspondence between the projector and the camera
pixels. Based on the correspondence, the 3-D coordinates can be calculated
by triangulation.
The absolute phase map retrieval is achieved by embedding markers in
the projected patterns and then detected its positions in the captured images.
For the “ﬂat+fringe” fringe projection scheme, two cross-shaped markers with
distinguishable grayscale patterns are embedded in the ﬂat pattern and the
fringe pattern. For the three phase-shifted fringe pattern projection scheme,
three cross-shaped markers with diﬀerent visibility patterns are embedded into
three fringe patterns.
2.4.1
Marker detection
Flat pattern + fringe pattern
The embedded markers are shown in Fig. 2.14(a) and Fig. 2.14(b). The in-
tensity distribution on the marker in the fringe pattern is uniform and the
intensity value is that of the ﬂat pattern.
The captured marker intensity
distribution is the same as that expressed as in Eq. 2.9. In the ﬂat image,
the intensity on the marker is sinusoidal with a π phase diﬀerence with the
fringe pattern. The captured marker intensity distribution in the ﬂat image is
expressed as,
gm(x, y) = a(x, y) + b(x, y) cos[2πf0x + φ(x, y) + π] ,
(2.25)
The marker is detected in the ﬂat image by use of a template that has the
same intensity distribution with the fringe marker. The template is shown
in Fig. 2.14(c). The template matching is performed. For each location, the
squared intensity diﬀerences between each pixel on the template and the pixel
on the captured ﬂat image are summed up. The center of the marker is located
by minimizing the sum of the squared intensity diﬀerence.
The marker is
designed to be projected onto a ﬂat area on the object in order to reduce
detection error. Fig. 2.15 shows a marker detection result of a workpiece. The
template matching result is normalized into the grayscale intensity interval of
[0, 255] for visualization purpose. Each pixel in the image represents the sum
32

(a)
(b)
(c)
Figure 2.14:
Markers and template.
(a) Marker embedded in the fringe
pattern; (b) Marker embedded in the ﬂat pattern; (c) Template.
of the squared diﬀerence at that point. The marker’s center is successfully
detected in this example.
(a)
(b)
(c)
(d)
Figure 2.15: Marker detection and removal example. (a) Fringe image; (b)Flat
image; (c) Template matching result; (d)Marker removal result.
Three phase-shifted fringe pattern
The three phase-shifted fringe patterns expressed in Eq. 2.14∼Eq. 2.16 have
the same visibility map as deﬁned in Eq. 2.21. A one-pixel wide cross-shaped
marker is embedded in the same position in three fringe patterns. The marker
is visible in the visibility map, because the visibility values on the marker are
set to be lower than other pixels. The marker’s position is detected in the
visibility map by template matching in the visibility map. A marker detection
example is shown in Fig. 2.16. The location of the marker in the fringe pattern
to be projected is known and ﬁxed in the patterns to be projected. According
to the principle of epipolar geometry [6], the marker’s locations in the captured
images for diﬀerent object distances form a straight trajectory if lens distortion
is ignored. Therefore, the search area is set to be a narrow strip centered at
33

(a)
(b)
(c)
(d)
Figure 2.16: Marker detection example for the 3 phase-shifted fringe patterns.
(a) One of three fringe images; (b)Flat image; (c) Visibility map; (d)Template
matching result.
the calibrated marker trajectory. With this approach, the search time and
error rate are signiﬁcantly reduced.
The absolute phase map retrieval relies on the detection of the location
of the marker’s center. Assume the relative phase of the center pixel of the
marker is φ0, and the absolute phase value of that pixel is 0. The absolute
phase map Φ(x, y) is given by
Φ(x, y) = ϕ(x, y) −ϕ0 .
(2.26)
2.4.2
Marker removal
When subtracting Eq. 2.9 from Eq. 2.1, the result only contains the sinusoidal
term. Therefore, the marker is completely removed during the subtraction of
the ﬂat image from the fringe image. Because the two markers are on the
same position in the images, the blurring eﬀect on both markers cancel each
other completely. Therefore, the marker removal does not aﬀect the phase
extraction. A marker removal example for the “ﬂat+fringe” pattern scheme is
shown in Fig. 2.15(d).
For the three phase-shifted fringe pattern scheme, the width of the marker
arm is one or two pixel in the captured fringe image. Therefore, the marker is
left in the fringe image and it is removed in the ﬁnal 3-D result by interpolating
the 3-D surface in the marker area.
The absolute phase map builds a constraint between the camera pixels and
projector pixels. With this correspondence and projector and camera calibra-
tion parameters, an absolute phase map is converted in to 3-D coordinates.
This process is called phase-to-coordinate conversion or 3-D reconstruction.
34

Figure 2.17: Coordinate systems used for 3-D reconstruction.
2.5
3-D Reconstruction
In Fig. 2.17, an arbitrary pixel (uc, vc) on the CCD has an absolute phase value
Φ1. The corresponding pixel on the DMD can be found on a line up = Φ1,
on which all the pixels have the same absolute phase Φ1. This pixel corre-
spondence allows the sophisticated camera and projector calibration model
to be applied to obtain accurate 3-D coordinate reconstruction results [69].
The coordinate systems used for the 3-D reconstruction is shown in Fig. 2.17.
The camera camera (CCD) and projector (DMD) coordinate systems are
{oc; xc, yc, zc}, and {op; xp, yp, zp} respectively. The camera image pixel co-
ordinate system and projector image pixel coordinate system are {oc
0; uc, vc}
and {op
0; up, vp} respectively. The world coordinate is {ow; xw, yw, zw}.
An arbitrary point on P the object surface has the homogeneous coor-
dinate {xw, yw, zw, 1}T.
The camera image of P is Ic = {uc, vc, 1}T.
The
corresponding pixel projector on the projector side is Ip = {up, vp, 1}T. The
camera and projector are calibrated separately [70]. Ac and [Rc, T c] are the
intrinsic and extrinsic parameters for the camera respectively. Ap and [Rp, T p]
35

are the intrinsic and extrinsic parameters for the projector respectively. Ap-
plying the pinhole model to the camera and projector, we have the following
two equations.
scIc = Ac[Rc, T c]P ,
(2.27)
spIp = Ap[Rp, T p]P ,
(2.28)
where sc, sp are the scaling factors for the camera and projector respectively.
Observing Eq. 2.27 and Eq. 2.28, we have 7 unknowns, namely (xw, yw, zw),
up, vp, sc, sp, and 6 equations.
From the absolute phase constraint, we can
obtain another equation:
up = f(Φ(uc, vc)) ,
(2.29)
where function f takes the absolute phase value as input and returns a pixel
index, which represents a line on the DMD with the same absolute phase value.
Solving Eq. 2.27, Eq. 2.28, and Eq. 2.29 simultaneously, the 3-D coordinates
of P in the world coordinate system (xw, yw, zw) can be solved.
2.6
Software Implementation
A C++ program is created to implement the proposed MFTM and to provide
a graphic user interface (GUI). A snapshot of the GUI of the program is
shown in Fig. 2.18.
The program implements multiple document interface
(MDI). It can display the 3-D measurement result in real time, while display
3-D snapshots in multiple windows.
Other implemented functions include:
record a sequence of fringe images, oﬀ-line processing a sequence of fringe
images, export 3-D point cloud into ASCII format ﬁles, save 3-D snapshots,
and modifying the projected fringe pattern. Multi-threaded programming is
employed to implement the real-time 3-D display.
The FFT operations used in the program is implemented by FFTW li-
brary [71]. FFTW is a C subroutine library for discrete Fourier transform
(DFT). The FFT functions in the library can perform 1-D or 2-D FFT of
arbitrary input size.
2.7
Experimental Results
The proposed modiﬁed FTM has been implemented on the digital fringe pro-
jection system introduced in Chapter 1. The fringe pattern and the ﬂat pat-
tern are sequentially projected by a digital-light-processing (DLP) projector
working in black-and-white (B/W) mode. The fringe and ﬂat patterns are
respectively encoded into RGB channels of the DLP projector. A B/W cam-
36

Figure 2.18: Software interface.
era synchronized with the projector’s projection timing continuously captures
fringe pattern images. Captured ﬂat images and fringe images are diﬀerenti-
ate by comparing the intensity diﬀerences of two pixels separate by half fringe
cycle. The camera and projector are calibrated respectively using a nonlinear
calibration method [69].
2.7.1
Projector grayscale calibration
For the ﬂat+fringe pattern projection scheme, the grayscale of the projector
needs to be calibrated. Theoretically, if the sinusoidal fringe pattern varies
in the range of [0, 255], the intensity of the uniform grayscale pattern should
be set to 127 or 128 in order to obtain a ﬂat image that could approximately
cancel the zero order terms in the frequency domain. In other words, the mean
intensity value of the captured ﬂat image should be approximately equal to
that of the fringe image. However, due to the diﬀerence between the two color
channels of the projector and the nonlinearity of the projector’s output, the
digital video projector used in our experiment has a small diﬀerence between
the two mean values.
The projector’s grayscale output error needs to be
compensated in order to make the ﬂat image represent the zero frequency
terms.
The following measures are taken to compensate the projector’s grayscale
37

0
20
40
60
80
100
120
140
160
180
200
50
100
150
200
250
grayscale
Cross sections of the flat image and fringe image
0
20
40
60
80
100
120
140
160
180
200
−60
−40
−20
0
20
40
60
pixel
grayscale
Cross section of the fringe image after subtracting the flat image
mean
(a)
0
20
40
60
80
100
120
140
160
180
200
50
100
150
200
250
grayscale
Cross sections of the flat image and fringe image
0
20
40
60
80
100
120
140
160
180
200
−60
−40
−20
0
20
40
60
pixel
grayscale
Cross section of the fringe image after subtracting the flat image
mean
(b)
Figure 2.19: Projector grayscale error compensation. (a) Before compensation;
(b) After compensation.
error. A white plane board is used. The plane board ﬁlls the camera’s ﬁeld
of view. First, adjust the projector’s bias and contrast until the nonlinearity
response between the intensity input and output is minimized. Then, adjust
the ﬂat pattern’s intensity until the diﬀerence between the mean intensity
value of the captured ﬂat image and that of the captured fringe image is
minimized. The fringe pattern and the ﬂat pattern are projected onto the
white board sequentially. The initial intensity value of the ﬂat pattern is set
to 128. A single row of pixels with the length of 15 cycles is taken from the
same location of the fringe image and and the ﬂat image respectively. The
mean intensity values are calculated. Adjust the intensity of the ﬂat pattern
based on the previous result to reduce the diﬀerence.
In order to lower the inﬂuence of the background noise and electronic noise,
the average of 10 sets of fringe and ﬂat images are used. Repeat the above
process until the two mean values are close enough. The grayscale compen-
sation result is shown in Fig. 2.19. In Fig. 2.19(a), the upper part shows the
cross sections of the ﬂat image and the fringe image. The lower part shows the
cross section of the fringe image after subtracting the ﬂat image, in which the
dashed line indicates the mean value before compensation. The diﬀerence of
mean values is 4.20 when the intensity of the ﬂat pattern is 128. Fig. 2.19(b)
shows the same cross sections after compensation.
The mean value of the
fringe image after subtracting ﬂat image is reduced to 0.14 after adjust the
intensity of the ﬂat pattern to 126.
38

(a)
(b)
(c)
(d)
(e)
(f)
Figure 2.20:
3-D measurement results of a free-form part. (a) Flat+fringe
pattern scheme; (b) Three phase-shifted fringe pattern scheme; (c) Conven-
tional FTM method; (d) Zoom-in view of (a); (e) Zoom-in view of (b); (f)
Zoom-in view (c).
2.7.2
Measurement of still object with complex shape
In order to compare the proposed MFTM with the conventional FTM, the 3-D
shape of the free-form workpiece is measured by use of both fringe projection
schemes. Fig. 2.20 shows the 3-D measurement results by use of the ﬂat+fringe
pattern scheme, three phase-shifted scheme, and conventional FTM.
Notice that there are slopes on both sides of the part. The zoom-in views of
the result from the conventional FTM by use of the same fringe pattern shows
the defects caused by the spectrum overlapping and spectrum leakage. Both
MFTM fringe projection schemes show signiﬁcant improvement. Detailed fea-
tures are preserved in the 3-D results.
39

2.7.3
Measurement of moving object and changing face
sequence
In order to evaluate the performance of the proposed method, the 3-D shape
of a moving plaster cylinder is captured by use of the 3-step phase shifting
method and MFTM respectively. The cylinder is moving in the horizontal
direction at approximately 0.5m/s. The results are shown in Fig. 2.21.
The defects caused by motion are examined on cross sections of the 3-D
results. Each cross section is a row in the middle of the along the horizontal
direction. The cross sections are ﬁtted into arcs, and the root mean square
(RMS) errors on the cross sections are calculated. The diﬀerence between the
measured data and the ﬁtted data are plotted in Fig. 2.21. The RMS error of
3-step phase shifting method 0.1896 mm. RMS error of ﬂat+fringe patterns
0.0394 mm. RMS error of 3 phase-shifted fringe patterns 0.0477 mm. There
is no texture on the cylinder. The ripple-like defects in the results from phase
shifting method and MFTM by use of three fringe patterns are caused by the
motion. During the capture of 3 fringe patterns, the movement of the cylinder
causes misalignment of the fringe pixels, and therefore phase error occurs.
Fig. 2.22 shows two facial expression sequences measured by the proposed
method and 3-step phase shifting method respectively.
Two sequences are
captured by the same fringe projection system.
The camera resolution is
640×480 pixels. The face occupies about 1/3 of total image pixels. The subject
is speaking with a normal speed. The proposed modiﬁed Fourier transform
method achieved 3-D frame rate of 25 frame/sec.
Obvious improvements can be observed in the MFTM result. Because there
are only two patterns needed for the proposed method, the defects caused by
the motion around the mouth area are reduced, compared to the ripple-like
defects in the result from 3-step phase shifting method. Also, the periodic
vertical lines, which are caused by projector intensity errors, do not appear in
the MFTM result. The periodic noise is ﬁltered out in the frequency domain.
Our experimental results show that for the worst case, that is when all
image pixels are occupied, the 3-D frame rate achieved 13 frame/second for
the camera with resolution of 532×500 pixels. The computer used to obtain
the result is Dell Precision 690.
The bottleneck for further improving the
frame rate is the computational load of FFT. With more advanced fast FFT
algorithm and hardware computing power, the frame rate could be further
improved.
40

(a)
(b)
(c)
0
50
100
150
200
250
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
X(mm)
Error(mm)
(d)
0
50
100
150
200
250
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
X(mm)
Error(mm)
(e)
0
50
100
150
200
250
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
X(mm)
Error(mm)
(f)
Figure 2.21:
A moving cylinder. (a) 3-step phase shifting; (b) MFTM with
ﬂat+fringe patterns; (c) MFTM with 3 phase-shifted fringe patterns; (d)-
(e)Error on the cross sections of (a)-(c) in the middle of the cylinder along X
direction.
41

(a)
(b)
Figure 2.22:
Facial expression sequences.
(a) Result from the proposed
method. (b) Result from the 3-step phase shifting method.
42

2.8
Summary
This chapter has proposed a modiﬁed Fourier transform method for real-time
3-D shape measurement. Two fringe projection schemes are proposed to pre-
vent the spectrum overlapping and facilitate the absolute phase retrieval. The
forward and inverse 1-D FFT are performed within the areas indicated by
the binary mask. The computational load is reduced, and the spectral leak-
age is alleviated by ﬁrst extending then windowing the data. The proposed
method is implemented on a high-speed digital fringe projection system. The
experimental results showed that the proposed method produced better mea-
surement results when measuring object with complex shapes than the con-
ventional Fourier transform method. The system demonstrated substantial
improvement on measuring moving and changing objects compared to phase
shifting method.
43

Chapter 3
Phase Shifting Shadow Moir´e by use of Carr´e Algorithm
In this chapter, a novel phase-shifting shadow moir´e technique is proposed.
The proposed technique has the potential of signiﬁcantly improving the mea-
surement accuracy and extends the measurement range. The phase shifts are
generated by translating the grating in equal steps in the direction perpen-
dicular to the grating plane. Nonuniform phase shifts in the ﬁeld of view are
generated. The Carr´e algorithm is utilized to process the resulting fringe pat-
terns. The method provides a close form exact solution of the phase map for
the ﬁrst time.
In this chapter, Section 3.1 introduces the principle of shadow moir´e tech-
nique, and several phase shifting algorithms for fringe pattern analysis. Sec-
tion 3.2 reviews previous related research work of combining the phase shifting
method with shadow moir´e technique. Section 3.3 explains the grating removal
method. Section 3.4 proposes a novel phase-shifting shadow moir´e method.
Section 3.5 describes the phase-to-coordinate conversion. Section 3.6 presents
the simulation results. Section 3.7 shows the experimental results. Section 3.8
draws the conclusion.
3.1
Introduction to Phase Shifting Shadow Moir´e
Technique
3.1.1
Principle of shadow moir´e technique
Moir´e pattern is a beat pattern that appears, for example, when one looks
through two identical straight line gratings rotated by a small angle to each
other.
The moir´e method for 3-D shape measurement utilizes an optical setup
to generate a grating pattern that is projected onto the 3-D surface. When
a camera observes the 3-D surface from a diﬀerent perspective through an-
44

other grating, a moir´e pattern is observed as the result of superposing of the
straight grating and the deformed grating pattern on the surface. Combined
with the optical geometry, the moir´e pattern can be analyzed to retrieve 3-D
information.
Shadow moir´e and projection moir´e are two techniques to generate moir´e
patterns. The application of moir´e method to optical shop testing and surface
topography has a long history [30, 31]. Shadow moir´e has been extensively
studied since 1970’s, because it has wide applications due to its simple setup
and high accuracy. Shadow moir´e uses a grating placed above the object. The
optical setup is shown in Fig. 3.1. The light source and the camera are at
the same distance to the grating plane. When the camera looks though the
grating, the shadow of the grating cast onto the object geometrically interferes
with the grating itself, and the moir´e pattern is observed. The light source
does not have to be coherent. The grating can be either binary or sinusoidal
pattern. The image captured by the camera is a shadow moir´e pattern.
Light Source
Camera
Object
Grating
d
l
h(x,y)
p
P(x,y)
Figure 3.1: Schematic setup of shadow moir´e.
Fig. 3.2 shows a shadow moir´e pattern generated by computer simulation,
in which the grating has sinusoidal intensity distribution and the object is a
sphere. The moir´e pattern includes the sinusoidal grating pattern itself and
the fringe pattern generated by the moir´e eﬀect. The fringe pattern contains
45

useful topography information while the grating pattern is unwanted. After
removal of the grating pattern, the fringe pattern can be analyzed by phase
shifting or the Fourier transform method.
Figure 3.2: Shadow moir´e pattern on a sphere.
The 3-D shape of the sphere in Fig. 3.2 can be obtained by ﬁrst calculating
the phase map of the moir´e pattern in Fig. 3.1. In Fig. 3.2 the fringe contours
contain useful geometric information of the object’s surface, while the high
frequency grating pattern is useless and is considered as noises. The removal
of the unwanted grating patterns will be introduced in Section 3.3. After the
unwanted grating pattern being removed, the fringe contour pattern can be
expressed as,
I(x, y) = I′(x, y) + I′′(x, y) cos[φ(x, y)] ,
(3.1)
where,
φ(x, y) =
2πdh(x, y)
p[l + h(x, y)] .
(3.2)
In Eq. 3.1, φ(x, y) is the phase term, I(x, y) is the measured intensity,
I′(x, y) is the background intensity, and I′′(x, y) is the intensity modulation.
In Eq. 3.2, p is the pitch of the sinusoidal grating, d is the distance between
light source and the camera, l is the distance from the grating plane to the
46

light source or camera, and h(x, y) is the surface height measured from the
grating plane. The surface height can be solved from Eq. 3.2 pixel by pixel.
Note that the phase-height relation is nonlinear.
In order to solve for the height, phase map have to be retrieved ﬁrst. Among
the fringe analysis methods, the phase shifting method is usually employed to
obtain the phase map.
By combining phase shifting method with shadow
moir´e, the measurement resolution and accuracy can be greatly improved.
3.1.2
Phase shifting algorithms for fringe analysis
Given a series of phase-shifted fringe patterns, phase shifting algorithms can
be used to solve the phase. In order to illustrate the concept of phase-shifting
algorithm, several widely phase shifting algorithms are introduced as follows:
3-step algorithm, 4-step algorithm, 5-step algorithm, and Carr´e algorithm [68,
72].
3-step algorithm is a typical phase shifting algorithm, which handles uni-
form phase shifts across the whole ﬁeld of measurement. In 3-step algorithm,
three recorded fringe patterns are expressed as
I1(x, y) = I′(x, y) + I′′(x, y) cos[φ(x, y) + α1] ,
(3.3)
I2(x, y) = I′(x, y) + I′′(x, y) cos[φ(x, y) + α2] ,
(3.4)
I3(x, y) = I′(x, y) + I′′(x, y) cos[φ(x, y) + α3] ,
(3.5)
where αi = −2π/3, 0, 2π/3 are the phase shifts. By solving Eq. 3.3-Eq. 3.5
simultaneously, we have the phase at each pixel,
φ(x, y) = tan−1
µ√
3
I1 −I3
2I2 −I1 −I3
¶
.
(3.6)
In 4-step algorithm, four fringe patterns (I1, I2, I3, and I4) are recorded [28,
73]. The phase shifts are αi = 0, π/2, π, 3π/2 . The phase term is calculated
as
φ(x, y) = tan−1
µ
I4 −I2
I1 −I1 −I3
¶
.
(3.7)
In 5-step algorithm, ﬁve fringe patterns (I1, I2, I3, I4, and I5) are recorded.
The phase shifts are αi = −π, −π/2, 0, π/2, π [74, 75].
The phase term is
calculated as
φ(x, y) = tan−1
µ
7(I2 −I4)
−4I1 + I2 + 6I3 + I4 −4I5
¶
.
(3.8)
47

The Carr´e algorithm needs four frames of fringe patterns with constant
phase shifts for the same pixel between neighboring frames [76]. The phase
shift can be unknown. To solve the phase term, assume the phase shift αi =
−3α/2, −α/2, α/2, 3α/2. the phase and phase shift can be solved as
φ(x, y) = tan−1
p
[(I1 −I4) + (I2 −I3)] [3(I2 −I3) −(I1 −I4)]
(I2 + I3) −(I1 + I4)
,
(3.9)
α = 2 tan−1
Ãs
3(I2 −I3) −(I1 −I4)
(I2 −I3) + (I1 −I4)
!
.
(3.10)
3.2
Related Work
During the past two decades, various techniques have been proposed to im-
plement the phase shifting method for shadow moir´e technique. Most of the
previous works employed phase shifting algorithms that require uniform phase
shifts across the ﬁeld, such as the 4-step algorithm. However, for every pixel
in the ﬁeld of view, if the surface height value h(x, y) is not constant, uniform
phase shifts in the ﬁeld of view cannot be obtained by changing any parame-
ter in Eq. 3.2. In that case, the n-step phase shifting algorithms will generate
phase error theoretically. However, approximate uniform phase shifts in the
ﬁeld of view can be achieved in practice.
Dirckx et al. [77] proposed a phase shifting shadow moir´e method by trans-
lating the object in the direction perpendicular to the grating plane. The as-
sumption in the method is that with small translation steps, the phase shifts
across the whole ﬁeld-of-view are approximately uniform.
Yoshizawa and Tomisawa [33] proposed a phase shifting shadow moir´e tech-
nique, in which the light source is translated in the direction parallel to the
grating plane and grating is shifted perpendicularly to its own plane, in order
to create uniform phase-shifts across the ﬁeld. The results showed that the
phase shifts are approximately uniform within certain fringe orders.
Xie et al. [78] proposed a phase shifting shadow moir´e scheme by rotating
the grating to obtain variation in grating pitch in the observer’s point of view.
However, the underling assumption was that the measurement range was much
less than the distance between the observer and the grating plane ( h(x, y) ≪l
in Fig. 3.1).
Jin et al. [79] proposed to ﬁrst move the grating vertically and then rotate it.
It was still an approximate method and the measurement range was restricted
by the pitch of the grating and the rotation angle.
The results of the above-mentioned methods showed improved accuracy.
48

However, the results have inherent measurement error because the phase shift-
ing algorithms employed all assume uniform phase-shifts across the ﬁeld. Mau-
voisin et al. [32] studied possible methods that could produce phase shifts in
a shadow moir´e setup, which included: changing period of the grating, trans-
lating the grating, translating the object, changing the distance between the
light source and camera. Their work showed that the uniform phase shifts
across the whole ﬁeld of view for a shadow moir´e setup was impossible due
to the nonlinearity nature of the height-phase relation, as can be seen later
in Eq. 3.2. However, if assuming the depth of measurement to be much less
than the distance h between the camera and the grating plane, the phase shifts
introduced by object translation perpendicular to the grating plane was shown
to be almost uniform.
Degrieck et al. [80] proposed a digital implementation of the phase shifting
shadow moir´e that took into account the non-linearity of height-phase relation.
The phase shift is produced by calculating a reference grating image iteratively.
The calculation is expensive and depends on an initial guess of the height value.
Until now, no exact close-form solution of height has been proposed for
phase shifting shadow moir´e method.
3.3
Grating Pattern Removal
Allen and Meadows [81] had shown that translating the grating horizontally
in four positions, where neighboring positions are separated by one quarter of
the grating period, could remove the unwanted patterns without changing the
useful fringe patterns. The proposed technique removes the unwanted grating
patterns by translating the grating in its own plane two times. The grating is
translated one third of the pitch each time. Suppose the intensity modulation
of the grating T1(x) is given by
T1(x) = 1
2 + 1
2 sin 2πx
p
.
(3.11)
The intensity of the moir´e pattern observed by the camera is
Ig1(x, y) = I0
·1
2 + 1
2 sin
2πxl
p(l + h(x, y))
¸ ·1
2 + 1
2 sin 2π
p
µxl + dh(x, y)
l + h(x, y)
¶¸
,
(3.12)
where I0 is the background illumination intensity. Let
θ0 =
2πxl
p(l + h(x, y)) .
(3.13)
49

Based on Eq. 3.13, Eq. 3.12 could be rewritten as
Ig1(x, y) = I0
4 [1 + sin θ0] [1 + sin(φ(x, y) + θ0)] .
(3.14)
When translating the grating by p/3, intensity modulation of the grating and
the moir´e pattern intensity are
T2(x) = 1
2 + 1
2 sin
µ2πx
p
+ 2π
3
¶
.
(3.15)
After applying the new grating modulation, the moir´e pattern observed by the
camera is rewritten as
Ig2(x, y) = I0
4
·
1 + sin
µ
θ0 + 2π
3
¶¸ ·
1 + sin(φ(x, y) + θ0 + 2π
3 )
¸
.
(3.16)
Further translating the grating for the third time by p/3, intensity modulation
of the grating and the moir´e pattern intensity are
T3(x) = 1
2 + 1
2 sin
µ2πx
p
+ 4π
3
¶
.
(3.17)
Ig3(x, y) = I0
4
·
1 + sin
µ
θ0 + 4π
3
¶¸ ·
1 + sin(φ(x, y) + θ0 + 4π
3 )
¸
.
(3.18)
Averaging the three moir´e patterns Ig1, Ig2, Ig3, we have
I(x, y) = I0
4
µ
1 + 1
2 cos φ(x, y)
¶
.
(3.19)
In Eq. 3.19, the unwanted grating pattern is removed, and only the fringe
pattern related to the object surface shape is retained.
Fig. 3.3 shows the grating removal result of a moire pattern generated by
simulation. The object is a sphere. The grating has sinusoidal intensity mod-
ulation distribution. When the grating is translated one third of the grating
pitch in the horizontal direction, the grating pattern is shifted 120◦in the
moir´e pattern, while the moir´e pattern (contour pattern) is unchanged. Three
moir´e patterns are shown in Fig. 3.3(a)-Fig. 3.3(c). After averaging the three
images, the grating removal result is shown in Fig. 3.3(d).
50

(a)
(b)
(c)
(d)
Figure 3.3: Remove grating pattern from the shadow moir´e pattern. Grating
horizontal translations: (a) 0◦; (b) 120◦; (c) 240◦; (d) Grating removal result.
51

3.4
Phase Shifting Scheme and Carr´e Algo-
rithm
The Carr´e algorithm only requires uniform phase shifts for each individual
pixel between frames. Carr´e algorithm was originally developed to eliminate
the need of knowing the exact amount of phase shift in the calculation of the
phase map. As long as the phase shift is ﬁxed at each pixel, the phase term
can be accurately calculated. Thus it eﬀectively removes the requirement for
uniform phase shift across the ﬁeld. Previous analysis suggests the possibility
that the Carr´e algorithm could be utilized to provide an exact close-form
solution of the phase in a shadow moir´e setup.
3.4.1
Phase shifting scheme
In the proposed phase shifting scheme for shadow moir´e technique, the phase
shift is introduced by vertical translation of the grating in equal steps. The
schematic diagram of the optical setup is shown in Fig. 3.4. Arrow 1 and
2 indicate the vertical and horizontal grating translation directions. Arrow
Light Source
Camera
Object
Grating
d
l
h(x,y)
P(x,y)
1
2
x
p
o
Figure 3.4: Schematic setup of the proposed phase shifting shadow moir´e
method.
52

1 indicates the direction of horizontal grating translation, which is for the
purpose of removing unwanted grating pattern.
The intensity modulation
of the grating in Fig. 3.4 is sinusoidal.
Two horizontal translation of the
grating with one third of the pitch each time generates three moir´e patterns
with grating the pattern.
Based on the grating pattern removal technique
introduced in Section 3.3, averaging those three moir´e pattern can remove the
unwanted grating pattern.
Arrow 2 indicates the horizontal grating translation direction. Translating
the grating in the direction perpendicular to the grating plane in equal steps
generates uniform phase shifts for each pixel. Suppose there are four diﬀerent
moir´e patterns generated at diﬀerent vertical grating positions (relative to
the light source or the camera) li, i = 1, 2, 3, 4. The phase shift between two
neighboring patterns is expressed as
α(x, y) =
2πdli+1
p [li+1 + hi+1(x, y)] −
2πdli
p [li + hi] .
(3.20)
3.4.2
Carr´e algorithm
According to Fig. 3.4, for arbitrary point P(x, y), we have
li+1 + hi+1(x, y) = li + hi(x, y) .
(3.21)
Therefore Eq. 3.20 can be simpliﬁed as
α(x, y) = 2πd(li+1 −li)
p [li + hi(x, y)] .
(3.22)
Let the step of the vertical grating translation to be ∆l. Then li = l, l+∆l, l+
2∆l, l + 3∆l(i = 1, 2, 3, 4). The phase shift can be rewrite in the form of
α(x, y) =
2πd∆li
p [l + h(x, y)] .
(3.23)
In this way, the unform phase shifts for each point are introduced. Applying
Carr´e algorithm to the phase-shifted moir´e patterns, the phase term and phase
shift are solved by Eq. 3.9 and Eq. 3.10 respectively.
The proposed phase shifting scheme only involves vertical and horizontal
translation of the grating. The phase shifts need not to be accurate as long as
they are equal. The exact solution of the phase map can be obtained.
53

3.4.3
Phase unwrapping
The phase values obtained from Eq. 3.9 are wrapped in the range of [−π, π].
Phase unwrapping has to be performed before the height map can be retrieved.
The quality-guided path following unwrapping algorithm introduced in Sec-
tion 2.3.2 is employed here again, in which the phase gradient is selected as
the quality index.
The pixels are put in a queue according to the phase gradient from low to
high. The one with the smallest gradient is unwrapped ﬁrst and put into the
solution array. And its four neighbors’ phase gradients are computed, ranked,
and put into the queue. Then, the top pixel in the queue is unwrapped. The
unwrapping process in this way until the queue is empty. At the end of the
process, the remaining pixels are in the completely isolated areas, caused by
shadow or holes. The successful unwrapping process produces a continuous
phase map, which is ready to be converted into coordinates.
3.5
3-D Reconstruction
The 3-D surface is reconstructed based on the phase map and the geometry of
the shadow moir´e setup. The surface height can be determined from Eq. 3.2
and Eq. 3.9 as follows,
h(x, y) =
plφ(x, y)
2πd −pφ(x, y) .
(3.24)
In order to reconstruct the object’s 3-D surface, the X and Y coordinate
also need to be calculated.
The coordinate systems used in phase shifting
shadow moir´e is shown in Fig. 3.5. Oc is the optical center of the camera
lens. oc, xc, yc, zc is the coordinate system on the imaging plane of the camera.
ow, xw, yw, zw is the world coordinate system.
f is the focal length of the
camera. Oc, oc and ow are collinear. An arbitrary point on the object surface
P(x, y) has an image on the imaging plane p(xc, yc). Based on geometry of
similar triangles, the X and Y coordinate of P are:
x = xc(l + h(x, y))
f
.
(3.25)
y = yc(l + h(x, y))
f
.
(3.26)
54

Light Source
Imaging
Plane
Object
Grating
Plane
d
l
h(xc, yc)
P(x, y)
p(xc, yc)
Oc
xc
yc
yw
xw
oc
ow
zw
f
Camera
Figure 3.5: Coordinate systems in shadow moir´e setup.
3.6
Simulation Results
The principle of the proposed phase shifting shadow moir´e technique is veriﬁed
by a simulation program using MATLAB. The input 3-D model is obtained
by the digital fringe projection system introduced in Section 1.1.7. The 3-D
image is shown in Fig. 3.6.
The MATLAB simulation program assumes the 3-D model has a diﬀuse
reﬂection surface and uniform reﬂectivity. The light source is a point source
and the camera has ideal pinhole imaging model. The grating has sinusoidal
intensity modulation. We have the shadow moir´e patterns shown in Fig. 3.6(b)
- Fig. 3.6(d). They are obtained by translating the grating horizontally two
times. By averaging three patterns, the unwanted grating pattern is removed.
Image without grating pattern is shown in the ﬁrst picture of Fig. 3.7.
Then, vertically translate the grating in three steps and repeat the above
grating removal procedure at each step. We have four phase shifted fringe
patterns shown in Fig. 3.7.
The Carr´e algorithm is applied to the four phase-shifted fringe patterns.
The wrapped phase map φ(x, y), unwrapped phase map and phase shift map
α(x, y) are obtained, as shown in Fig. 3.8.
Although Carr´e algorithm does not require the phase shifts to be known,
55

(a)
(b)
(c)
(d)
Figure 3.6: Shadow moir´e patterns. (a) Input 3-D model; Grating horizontal
translations: (b) 0◦; (c) 120◦; (d) 240◦
.
56

(a)
(b)
(c)
(d)
Figure 3.7: Phase-shifted moire patterns with grating pattern removed. (a)-(d)
Four phase-shifted fringe patterns.
57

(a)
(b)
(c)
Figure 3.8: Simulation results. (a) Wrapped phase map; (b) Phase shift dis-
tribution α/2 (rad); (c) Unwrapped phase map (rad).
58

a range of phase shift is preferred for minimizing the phase error. Theoret-
ically, the phase term can be calculated for any phase shift step by Eq. 3.9.
However, when systematic error and random error occur in the fringe images,
[(I1 −I4) + (I2 −I3)] [3(I2 −I3) −(I1 −I4)] could be a negative number and
result in complex phase value.
Carefully selected phase shift steps can reduce the risk of complex phase
value when systematic and random errors are inevitable.
The relation be-
tween phase error and phase shift step has been studied in previous litera-
ture [82, 83, 84]. Phase error of phase shifting shadow moir´e is generated by
systematic phase shift error, systematic intensity error, and random intensity
error.
Phase shift steps between 90◦-120◦have been proved to reduce the
inﬂuence of systematic and random errors.
In the proposed phase shifting scheme for the shadow moir´e setup, each
pixel’s phase shift step is determined by the height value of that pixel. Most
pixels should have phase shift steps in the range of 90◦-120◦. Fig. 3.8(b) shows
the α/2 value distribution (phase shift step of the Carr´e algorithm is α).
With the unwrapped phase map, the 3-D reconstruction is performed. The
3-D image is shown in Fig. 3.9. The 3-D shape of the input model is accurately
reconstructed. The simulation successfully veriﬁed the proposed phase shifting
shadow moir´e method.
3.7
Experimental Results
Experiments were conducted on a NIST (National Institute of Standards and
Technology) calibration block and a concave lens respectively. The grating
employed is dense enough (100 lines/inch), so that the grating pattern is not
visible in the moir´e pattern. d and l in Eq. 3.24 are both 787.4 mm. The
vertical grating translation step is 69.6 µm. Four phase-shifted moir´e patterns
were obtained, which are shown in Fig. 3.10 and Fig. 3.12 respectively.
The vertical translation step of the grating and the height of the objects
are very small compared to l. Therefore, according to Eq. 3.23, the phase
shift variation across the ﬁeld of view is relatively small. The phase shifts in
both experiments are about 90◦in the ﬁeld of view. The wrapped phase maps,
unwrapped phase map, and reconstructed 3-D surfaces of the calibration block
and the concave lens are obtained are shown in Fig. 3.11 and Fig. 3.13. The
NIST calibration block is 2 inch square. The height of the step on the block is
calibrated as 209.04 µm. The calculated step height by the proposed method
is 205.78 µm. The error is 3.26µm.
59

Figure 3.9: 3-D surface obtained by the proposed phase shifting shadow moir´e
method
60

(a)
(b)
(c)
(d)
Figure 3.10: Phase-shifted moir´e patterns of a NIST calibration block.
3.8
Summary
Due to the nonlinearity relation between the phase and geometry parameters
of the optical setup, it has been diﬃcult to apply phase shifting method in the
shadow moir´e technique for 3-D shape measurement. In this paper, a phase
shifting shadow moir´e method is proposed to provide a simple phase shifting
scheme and an exact close form solution for the phase map. In our proposed
method, the grating is translated in equal steps in the direction perpendicular
to the grating plane to introduce phase shifts. It is demonstrated that the
phase shifts are uniform for each pixel, while they are nonuniform across the
ﬁeld of view. The proposed method takes advantage of the Carr´e algorithm’s
ability of handling nonuniform phase shifts across the ﬁeld to provide an exact
close-form 3-D shape measurement result for the shadow moir´e setup. The
phase value at each point is determined by the Carr´e algorithm. The proposed
method is successfully veriﬁed by computer simulation and the experimental
results.
61

(a)
(b)
(c)
Figure 3.11: Measurement results of a NIST calibration block. (a) Wrapped
phase map (rad); (b) Unwrapped phase map (rad); (c) Height map (µm).
62

(a)
(b)
(c)
(d)
Figure 3.12: Phase-shifted moir´e patterns of a lens.
63

(a)
(b)
(c)
Figure 3.13: Measurement results of a lens. (a) Wrapped phase map (rad);
(b) Unwrapped phase map (rad); (c) Height map (µm).
64

Chapter 4
Face Recognition Based on Fringe Pattern Analysis
This chapter introduces a novel face recognition method that takes advantage
of the 3-D information of the face without reconstructing the 3-D coordinates.
Two fringe pattern analysis methods, namely phase shifting method and the
Fourier transform method, are employed. Three phase-shifted fringe images
are analyzed and the background illumination and texture are removed. The
resulting fringe pattern contains only 3-D facial geometry related information.
Fourier transform is applied to the resulting fringe pattern and the ﬁltered
Fourier spectrum of the resulting fringe pattern is generated. Principal compo-
nent analysis (PCA) is applied to the face spectra to perform face recognition.
The proposed method is robust to background illumination and skin texture
variation and has reduced computation and storage expenses compared to 3-D
face recognition algorithms.
4.1
Introduction
Human beings recognize faces not long after they were born. However, face
recognition has never been an easy task for machines. In recent years, human
face recognition has been attracting more and more researchers because of
its wide applications in security surveillance, law enforcement, information
control, and entertainment [43].
Compared with other human biometrics,
collecting face images requires less subject cooperation and awareness than
those of ﬁngerprints, irises, voice or signature.
Face recognition techniques based on 2-D intensity images have been ex-
tensively studied [41, 85, 86, 87, 88].
The recognition performance of 2-D
techniques signiﬁcantly relies on the consistency of the illumination and the
skin texture for the same person. The cause of facial skin texture variation
can be facial makeup, tanning, or aging. The illumination variation is caused
by diﬀerent lighting conditions, such as outdoor, indoor, or controlled lighting
65

environments. Even in an indoor controlled lighting environment, diﬀerent
cameras or the same camera with changed settings can produce face images
with considerable intensity variations. Although preprocessing such as his-
togram equalization is usually performed, maintaining intensity consistency is
diﬃcult for 2-D face recognition techniques. The inﬂuence of skin texture and
illumination variation can be eliminated by use of 3-D face data [89, 90, 91, 92].
Facial 3-D geometry is represented in the form of point cloud, proﬁles, or mesh.
However, apart from the computational complexity of 3-D recognition algo-
rithms, the reconstruction and storage expenses of the 3-D surface geometry
are high.
In this chapter, a face recognition method based on fringe pattern analy-
sis is proposed, which directly utilizes 2-D images generated by a structured
light system without reconstructing the 3-D geometry. A high-speed digital
fringe projection system is employed to project three phase-shifted sinusoidal
fringe patterns onto the subject’s face. First, the face fringe patterns are an-
alyzed by the phase shifting method to generate one fringe pattern without
any texture or background illumination. Then, the resultant fringe patterns
are transformed into the spatial frequency domain. The spectra related to the
3-D facial geometry are extracted. Finally, the eigenface algorithm is applied
to the face spectra to perform face recognition. The advantages of the pro-
posed method include immunity to skin texture and background illumination
variations; and the reduced computation and storage expenses compared to
3-D face recognition algorithms.
This chapter is organized as follows.
In Section 4.2, the digital fringe
projection technique is brieﬂy introduced and the related work is reviewed.
Section 4.3 presents digital fringe projections system and the proposed face
fringe pattern analysis method. Section 4.4 describes the face normalization.
Section 4.5 introduces the eigenface algorithm employed for to accomplish the
recognition task. Section 4.6 shows the experimental and simulation results.
The conclusion is drawn in Section 4.7.
4.2
Background and Related Work
The digital fringe projection technique has been studied as a structured light
method for 3-D shape measurement of freeform surfaces. A digital video pro-
jector sequentially projects phase-shifted sinusoidal fringe patterns onto the
object surface. When observed from a diﬀerent perspective by the camera,
the fringe pattern is distorted by the 3-D shape of the object. The captured
fringe image contains 3-D shape of the object along with the surface reﬂectance
and background illumination. The phase term in the sinusoidal function is
66

directly related to the 3-D shape information. Therefore, phase shifting or
the Fourier transform method is applied to solve the phase map of the sinu-
soidal fringe pattern [68]. The 3-D reconstruction process includes three steps.
First, the phase map is unwrapped to remove the 2π ambiguities [51]. Then
the unwrapped phase map is used to solve the correspondence between the
camera pixels and the projector pixels [70, 93]. With the intrinsic and extrin-
sic calibration parameters of the camera and projector, 3-D coordinates are
reconstructed for each pixel [70]. The virtues of the digital fringe projection
technique include non-contact, fast and high-resolution measurement.
The digital fringe projection technique has been successfully employed for
3-D face data acquisition [94, 95]. Much research has been done to utilize
the 3-D face data obtained from various other structured light techniques for
face recognition, such as laser scanning [96, 97], binary stripe pattern projec-
tion [98, 99], and rainbow camera [100]. Comparatively little research work has
been done about utilizing the 3-D information encoded in the 2-D image cap-
tured by a structured light system without reconstructing the 3-D geometry.
Andrade et al. proposed a electronic-optical 3-D face recognition system that
matches the moir´e patterns by use of optical technqiues [101]. The unknown
subject’s face is structurally illuminated and a moir´e pattern is observed, which
encodes the 3-D information of the face. The known reference moir´e pattern
is mixed with the unknown one and processed by the electronic-optical sys-
tem. The recognition decision is made based on the output of the matching.
Esteve-Taboada et al.
proposed a 3-D object recognition method that ex-
amines the correlation of the grating patterns[102]. The method projects a
grating pattern onto the object surface and records the distorted grating pat-
tern. The distorted grating pattern and a reference pattern is processed by
a modiﬁed joint transform correlation (JTC) technique to achieve 3-D object
recognition. Both methods demonstrated fast recognition speed by directly
utilizing 3-D information in the 2-D images. However, the disadvantages of
the above techniques are that the hardware system is complicated and the one
by one recognition process is not suitable for large database.
In this research, we propose to utilize the 3-D information encoded in the
fringe patterns by use of the fringe analysis methods without going through
the 3-D reconstruction process. Phase shifting method solves the phase map
from a series of sequentially captured fringe patterns with known phase shifts.
The background illumination and texture terms of the fringe pattern can be
explicitly solved. Therefore, one of the advantages of phase shifting method is
the robustness to illumination and texture variations. The Fourier transform
method takes on a diﬀerent perspective on how to solve the phase map. The
fringe pattern is transformed into the spatial frequency domain, where the
67

phase terms is modulated by the surface reﬂectivity and are separated from
the background illumination by the fringe frequency. The phase terms are
extracted by ﬁltering and then taken inverse Fourier transform. The phase
map is the imaginary part of the result. Only a single fringe pattern is needed
by the Fourier transform method.
The drawback of the Fourier transform
method is that the background illumination and surface texture severely aﬀect
the resulting phase map. For the purpose of face recognition, combining both
fringe analysis methods provides a means to represent the the 3-D face in the
spatial frequency domain without the inﬂuence of the background illumination
and texture variations.
4.3
Principle
4.3.1
Digital fringe projection system
The digital fringe projection system utilized in this research has been intro-
duced in Chapter 1. It consists of a digital video projector and a black-and-
white (B/W) camera. The schematic system diagram is shown in Fig. 4.1. The
projector is based on the digital light processing (DLP) technology. The pro-
jected pattern is formed on a digital-micromirror-device (DMD). Three phase-
shifted sinusoidal fringe patterns are generated by computer and encoded in
the red, green, and blue (RGB) color channels of a color image. Based on the
working principle of DMD, the contents of the three color channels are pro-
jected sequentially at a high frequency (180 Hz). Because the projector works
in B/W mode, three fringe patterns are sequentially projected onto the sub-
ject’s face. The camera, which is synchronized with the projector, captures the
fringe pattern from an oﬀset angle at a speed of 90 frames/second. The data
acquisition time for a set of 3 phase-shifted fringe pattern is 33 ms. Therefore,
subjects do not have to sit still for several seconds for the data acquisition.
4.3.2
Texture and illumination removal
Three-step phase shifting method is employed to analyze the fringe patterns.
Three phase-shifted sinusoidal fringe patterns could be written in the following
forms:
IR(x, y) = 255[1 + cos(2πf0x −2π/3)] ,
(4.1)
IG(x, y) = 255[1 + cos(2πf0x)] ,
(4.2)
IB(x, y) = 255[1 + cos(2πf0x + 2π/3)] ,
(4.3)
68

R
G
B
PC
DLP
Projector
B/W
Camera
RGB
Fringe
R
G
B
Face
Figure 4.1: System diagram of the digital fringe projection system.
69

in which, x and y are the pixel indexes, f0 is the frequency of the sinusoidal
pattern, and the phase shift is 2π/3.
The three deformed fringe patterns
captured by the synchronized camera are expressed as:
I1(x, y) = I′(x, y) + I′′(x, y) cos[2πf0x + φ(x, y) −2π/3] ,
(4.4)
I2(x, y) = I′(x, y) + I′′(x, y) cos[2πf0x + φ(x, y)] ,
(4.5)
I3(x, y) = I′(x, y) + I′′(x, y) cos[2πf0x + φ(x, y) + 2π/3] ,
(4.6)
where I′(x, y) represents the background illumination or ambient light illumi-
nation. I′′(x, y) relates to the facial skin texture reﬂectivity. φ(x, y) is the
phase information that contains the 3-D facial geometry. We could solve the
background illumination and facial texture by solving Eq. 4.4, Eq. 4.5 and
Eq. 4.6 simultaneously,
I′(x, y) = I1 + I2 + I3
3
,
(4.7)
I′′(x, y) =
p
3(I1 −I3)2 + (2I2 −I1 −I3)2
3
.
(4.8)
The texture and illumination can be removed from one of the fringe image
I2(x, y), resulting in a fringe image If(x, y),
If(x, y) = I2(x, y) −I′(x, y)
I′′(x, y)
= cos[2πf0x + φ(x, y)] .
(4.9)
The result in Eq. 4.9 is an image that only contains the 3-D face proﬁles. The
intensity values of the pixels are in the range of [−1, 1]. To visualize the result,
it is normalized into the grayscale range of [0, 255] in Eq. 4.10.
Ifn(x, y) = 255
2 {1 + cos[2πf0x + φ(x, y)]} .
(4.10)
When the surface reﬂectivity is too low (e.g. shadow, black hair or beard),
I′′(x, y) will be too close to zero. A threshold is set for I′′(x, y) to prevent
Eq. 4.9 from generating unstable result. Fig. 4.2 shows the phase-shifted fringe
patterns and the fringe pattern after texture and illumination removal. The
resulting fringe pattern contains only the distorted fringe lines which represents
the 3-D geometry related information. The skin texture is completely removed.
The grayscale intensity of the pixels on eyes, hair and eyebrows are set to zero
by the reﬂectivity threshold.
70

(a)
(b)
(c)
(d)
Figure 4.2: Skin texture and illumination removal. (a)-(c) three phase-shifted
fringe patterns; (d) fringe pattern with skin texture and background illumina-
tion removed.
4.3.3
Fourier spectra of fringe image
The fringe pattern shown in Fig. 4.2(d) can not be directly used for face
recognition in that the resultant pattern’s horizontal position shifts between
diﬀerent images of the same subject. For example, the nose tip may appear
in the dark part of the fringe in one image while in the bright part in another
image of the same person.
The 3-D shape information encoded in a distorted fringe pattern can be
extracted in the spatial frequency domain [40]. This principle has been adopted
by the Fourier transform methods for optical 3-D shape measurement. Here,
we utilize this principle to obtain the 3-D face information in the form of
Fourier spectra, which can be further processed by existing pattern recognition
algorithms. Applying Euler’s formula, Eq. 4.9 can be rewritten in the following
form:
If(x, y) = c(x, y)ei2πf0x + c∗(x, y)e−i2πf0x ,
(4.11)
where c(x, y) = 1/2eiφ(x,y) . Taking 1-D Fourier transform of Eq. 4.11 with
respect to x, we have
G(fx, y) = C∗(f + f0, y) + C(f −f0, y) .
(4.12)
The Fourier spectra and the band-pass ﬁlter are shown in Fig. 4.3. The spec-
tra containing the phase term φ(x, y) concentrate around the carrier frequency
(f0, −f0), and are symmetrical in the frequency domain. Either of the con-
jugate terms C∗(f + f0, y) or C(f −f0, y) can be employed. Fig. 4.4 is the
frequency spectrum of the fringe image shown in Fig. 4.2(d). In order to re-
duce the data size for further computation, the spectra around f0 is extracted
71

f
C*(f+f0, y)
C(f-f0, y)
f0
f0
(0, y)
H(f-f0, y)
Figure 4.3: Fourier spectra (|G(fx, y)|) of the processed fringe pattern.
Figure 4.4: Fourier spectra of Fig. 4.8(c)
by a band-pass ﬁlter. Theoretically, there should be no zero frequency compo-
nent in the spatial frequency domain since the background illumination term
I′(x, y) has been removed. However, zero frequency components exist as a
result of the low reﬂectivity areas ﬁlled with zeros, especially the non-face
background in the image. Therefore, a band-pass ﬁlter is necessary. Because
only half of the spectra is enough to represent the 3-D face information, the
data size is greatly reduced.
72

4.4
Face Image Normalization
A 2-D face image without fringe can be obtained by averaging three phase-
shifted fringe patterns in Eq. 4.4∼Eq. 4.6. The centers of eyes, mouth and the
face area are detected in the face image by using the Viola-Jones method [103].
Based on the eye centers and the face area detected, the fringe patterns are
cropped to keep only the face area aligned by the eye positions. The nor-
malization is applied to the face fringe pattern shown in Fig. 4.2. Face area
detection result is shown in Fig. 4.5(a). The 1-D Fourier transform is per-
formed on Fig. 4.5(b). The ﬁltered Fourier spectra are shown in Fig. 4.5. The
size of the Fourier spectra shown is a 336 × 50 array, which is much smaller
than the original 2-D fringe image’s size 532 × 500 pixels.
(a)
(b)
(c)
Figure 4.5: Face fringe pattern normalized.(a)Detected face area; (b)Cropped
fringe pattern; (c)Filtered Fourier spectra.
73

4.5
Principal Component Analysis of the Fourier
Spectra
Among the face recognition algorithms, principal component analysis (PCA),
also known as “eigenfaces”, has been extensively studied and widely used as
a baseline algorithm [85, 104]. In this paper, eigenface algorithm is applied
to the Fourier spectra of the normalized face fringe patterns to accomplish
the recognition task. The face spectra obtained from the previous Section is
saved as data ﬁles, and is sent to the algorithm as inputs. The proposed face
recognition process is illustrated in Fig. 4.6.
Eigenface algorithm takes the face spectra gallery as a high-dimension vec-
tor space. Each image is represented by a vector X of length N. The training
set of M face spectra form a N × M matrix Φ.
The eigen vectors of the
covariance matrix of Φ are called the eigenfaces. The eigenfaces are ranked
according to their corresponding eigenvalues in descending order. Top eigen-
faces, which are the most representative features of the gallery, are chosen to
form a subspace. When an unknown face is presented, it is projected onto the
eigenfaces, and a set of coordinates are generated. The distances between the
coordinates of the unknown face and those of the known persons are calculated.
The nearest neighbor is considered as the unknown face’s identity.
There are several distance metrics available for the nearest neighbor search
such as Euclidean distance, Cityblock distance, and Mahalanobis distance.
The Mahalanobis distance is selected as a distance measure. Every dimension
in the subspace is weighted by the corresponding eigen value. Compared with
Euclidean distance, the advantage of Mahalanobis distance is that no eigenface
would dominate the result, and the contribution of each eigenface is balanced
and comparable.
4.6
Experiments and Simulation
4.6.1
Experiments
Fringe images used in the experiments are captured by the digital fringe pro-
jection system introduced in Section 4.3.1. The resolution of the B/W camera
is 532×500 pixels. The projector projects three phase-shifted sinusoidal fringe
patterns with the resolution of 1024×768 pixels. The pitch of the projected
fringe pattern is 9 pixels/cycle.
In the ﬁrst experiment, a face’s fringe images are captured in diﬀerent
conditions to verify the proposed texture and illumination removal method.
First, makeup (white powder) is applied onto the cheeks of the subject. One
74

Training
fringe
images
Unknown
fringe
images
Texture &
illumination
removal
Fourier
transform
Filtering
Eigenface
generation
Projection
onto
eigenfaces
Nearest
neighbor
classifer
Training
spectra
Unknown spectra
Face
detection &
normalization
Recognition
result
Figure 4.6: Face recognition process by use of PCA.
set of fringe images with makeup is captured. Another set of fringe images
of the same face without makeup are captured for comparison. The fringe
images, averaged ﬂat images, and the texture removal results are shown in
Fig. 4.7. The texture variation caused by the makeup is completely removed
in Fig. 4.7(c) and Fig. 4.7(f).
Then, two sets of face fringe images are captured with diﬀerent background
illumination, which result in grayscale intensity variation in the ﬂat images.
Fig. 4.8(a) is one of three phase-shifted fringe images captured with normal
background illumination. Fig.4.8(b) is generated by averaging three phase-
shifted fringe images. Fig. 4.8(c) is the texture and illumination removal re-
sult. Fig. 4.8(d) is one of the fringe images captured with less background
illumination. The average grayscale intensity of the generated ﬂat image in
Fig. 4.8(e) is 78.8% of that of Fig. 4.8(b). The grayscale variation in the ﬂat
images is eliminated in the texture and illumination removal results from the
above two sets of fringe images.
The second experiment is to evaluate the recognition performance of the
proposed method. 165 sets of phase-shifted face fringe patterns were taken
from 44 subjects. Subjects were asked to sit at a ﬁxed distance to the fringe
projection system. Expressions were avoided during the image capture. At
least three sets of fringe patterns for each subject were captured. Face spec-
trum images are generated from the normalized fringe patterns. Sample face
fringe patterns and spectrum images are shown in Fig. 4.9. From the total
165 face spectrum images, 132 are used to form a training set, 3 spectrum
75

(a)
(b)
(c)
(d)
(e)
(f)
Figure 4.7: Illumination and texture removal result of a face with makeup.
76

(a)
(b)
(c)
(d)
(e)
(f)
Figure 4.8: Illumination and texture removal result of a face with diﬀerent
background illumination.
77

images for each person. Top 25 eigenvectors are employed in the eigenface
algorithm. The other 33 face spectrum images are used to test the algorithm.
The recognition rate is 90.91%. The experimental results indicate that the
time for generating a spectrum images is approximately 60% of the time for
generating a 3-D face point cloud. The size of the spectrum image is only 10%
of the size of the 3-D face point cloud generated from the same fringe patterns.
Flat grayscale images of the subjects are also generated by averaging three
fringe patterns. The same PCA algorithm is applied to the corresponding ﬂat
grayscale images, and the recognition rate is 87.87%.
The spectrum representation of ﬂat grayscale face image has been shown
to be able to eﬀectively reduce data size [105]. The Fourier spectra of the ﬂat
grayscale images can be obtained by applying 2D Fourier transform and extract
the low frequency band. The same PCa algorithm is applied to the Fourier
spectra of the ﬂat grayscale images, and the recognition rate is 93.94%. These
preliminary experimental results demonstrated that the proposed method can
achieve satisfactory face recognition rate compared with the methods using
grayscale images. There is no illumination or skin texture variation in the
grayscale images, in that the images of the same subject were captured by our
fringe projection system in one session under similar illumination conditions.
4.6.2
Simulation on FRGC2.0 database
The fringe projection process can be simulated by virtual fringe projection on
computer, if 3-D face models are available. By use of simulation, we can utilize
existing 3D face databases to evaluate the proposed method. Most 3D face
databases have corresponding 2D grayscale face images with illumination or
certain degree of skin texture variation, in that face images are captured over
multiple sessions. The face database of Face Recognition Grand Challenge 2.0
(FRGC2.0) is employed in our simulation [42]. FRGC2.0 provides the 3-D
point clouds along with corresponding 2-D intensity images for each person.
The 2-D face images in FRGC2.0 are taken with diﬀerent indoor illumination
conditions. The resolution of both 2-D and 3-D face images are 640×480 pixels.
Samples of 2-D and 3-D faces are shown in Fig. 4.10(a) and Fig. 4.10(b).
In the simulation program, phase-shifted sinusoidal fringe patterns are vir-
tually projected onto the 3-D face surface to simulate the digital fringe pro-
jection system. The virtual projection is enabled by the projective texture
technique [106]. The 3-D face mesh generation and virtual fringe projection
are implemented using Open Graphic Library (OpenGL) [106]. A sample 3-D
face with virtually projected sinusoidal fringe pattern is shown in Fig. 4.10(c).
There is no texture variation on the 3-D faces in the database. However, that
will not aﬀect the eﬀectiveness of the simulation, since the texture and illu-
78

(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
(i)
(j)
(k)
(l)
Figure 4.9: Sample face fringe patterns and spetra.
79

(a)
(b)
(c)
Figure 4.10: FRGC2.0 face database. (a) 2-D image; (b) 3-D image; (c) 3-D
image with virtually projected fringe pattern.
80

mination removal result has been successfully veriﬁed by the experiment in
Section 4.6.1.
There are 228 3-D faces of 39 subjects are employed in the the simulation.
Face images with exaggerated expressions are excluded. Pose normalization
of the 3-D faces is necessary to remove the inﬂuence of out-of-plane rotation.
The face area and eye and mouth positions are detected in the 2-D intensity
images. The corresponding 3-D points are found and used to normalize the
pose and scale.
Fig. 4.11 shows some samples of the fringe images in the
gallery.
The face area is also detected in the 2-D face image and the 3-D points
outside of the face area is discarded. Then the phase-shifted fringe patterns
are projected onto the normalized 3-D face. The deformed fringe patterns are
recorded. Fourier spectra are obtained by applying the proposed method. The
2-D intensity images are also based on the detected features. The scale varia-
tion and in-plane-rotation are eliminated by measuring the pixels between eye
centers and aligning the line connecting eye centers to the horizontal direction.
Histogram equalization is applied to perform illumination normalization.
The proposed method’s face recognition performance is compared with
the eigenface algorithm using 2-D intensity images. 4 face spectra of each
person are used for training. 72 unknown face spectra are used for testing.
The same amount of corresponding 2-D intensity images are employed for
training and testing. Fig. 4.13 shows that the proposed method achieved a
better performance than the eigenface algorithm using 2-D intensity images,
when varied number of top eigenfaces are adopted. The result also shows that
performances of both methods increase until 30 top eigenfaces are used (ap-
proximately 20% of total eigenfaces), which is consistent with the performance
analysis in Ref. [104]. When the number of training spectra and 2-D images
are varied, the recognition results are shown in Table. 4.1. In both simulation
results, the proposed method demonstrated improved recognition performance
compared to the eigenface algorithm using 2-D intensity images.
4.7
Summary
We proposed a novel 3-D face recognition method based on the digital fringe
projection technique. A high-speed digital fringe projection system projects
phase-shifted sinusoidal fringe patterns and captures the deformed fringe pat-
terns of a human face. Two fringe analysis methods are employed. The phase
shifting method is used to eliminate the background illumination and facial
skin texture variations. The Fourier transform method is applied to generate
a Fourier spectra, which represents the 3-D shape of the face. The eigenface
81

(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
(i)
Figure 4.11: Normalized 3-D faces with fringe virtually projected fringe pat-
tern.
82

(a)
(b)
(c)
(d)
(e)
(f)
Figure 4.12: Normalized 2-D intensity images from FRGC2.0 database.
Table 4.1: Recognition results with diﬀerent number of training spectra or
images.
Input
Training set
Train/person
Eigenfaces
Tests
Recog. rate
Spectra
78
2
16
72
80.6%
117
3
23
72
84.7%
156
4
30
72
91.7%
2-D Images
78
2
16
72
73.6%
117
3
23
72
76.4%
156
4
30
72
86.1%
83

Figure 4.13: Face recognition results with diﬀerent number of top eigenfaces.
algorithm takes the face spectra as inputs and performs face recognition. The
proposed method obtained a spectral representation of the 3-D face without re-
constructing the 3-D face geometry. The experimental and simulation results
demonstrated satisfactory recognition results and the advantage of reduced
storage space and computation load compared to 3-D point clouds.
84

Chapter 5
Conclusions and Future Work
This chapter concludes this dissertation by summarizing the contributions of
this research and discuss possible extensions of this research work in the future.
5.1
Conclusions
This research work developed two 3-D shape measurement techniques and a
face recognition method. Fringe analysis methods, Fourier transform method
and phase shifting method, played a central role in this research work. The
main contributions are summarized as follows:
1. Developed a modiﬁed Fourier method for 3-D shape measure-
ment of dynamic objects
A modiﬁed Fourier transform method (MFTM) for 3-D shape measure-
ment is developed. The conventional Fourier transform method is im-
proved by acquiring an additional ﬂat image. Based on this idea, two
fringe projection schemes are proposed. One scheme directly project a
uniform grayscale pattern in addition to the fringe pattern. The other
scheme projects three phase-shifted fringe patterns. While both schemes
alleviate the spectra overlapping by subtracting a ﬂat image from the
fringe image, the former scheme is more suitable for measuring fast
moving or changing objects and the latter scheme handles objects with
complex shapes better. Spectral leakage reduction is achieved by ﬁrst
extending and then windowing the data before FFT. A binary mask is
generated based on the grayscale distribution of the ﬂat image to mask
out background and thus to reduce the computation time.
A path-
following phase unwrapping algorithm is developed by using the fringe
visibility as an quality index. Absolute phase retrieval techniques are
developed for both fringe projection schemes.
85

Preliminary experimental result of a free-form workpiece shows that the
MFTM has improved performance on measuring objects with complex
shapes. A moving cylinder and a face sequence with the subject speaking
are captured to demonstrate the MFTM’s ability to measure moving
or changing object. The MFTM achieved real-time image acquisition,
processing, and 3-D display on a high-speed digital fringe projection
system. The proposed method has potential applications such as 3-D lip
tracking, facial expression capture and online 3-D inspection.
2. Developed a phase shifting technique for shadow moir´e
A phase shifting shadow moir´e technique by use of the Carr´e algorithm
is developed. The phase shifting is achieved by translating the grating
in vertical direction in equal steps to obtain four phase-shifted fringe
patterns. The phase shifts in the ﬁeld of view of the camera are not
uniform, while the phase shifts between neighboring grating movements
for each pixel are uniform. Carr´e algorithm is applied to solve the phase
map. The grating pattern removal and phase shift step selection are also
discussed. The proposed method provides an exact close-form solution
for surface height for the ﬁrst time. The simulation and experimental re-
sults veriﬁed the principle and demonstrated a satisfactory measurement
results.
3. Developed a face recognition method based on fringe pattern
analysis
A novel 3-D face recognition method based on the digital fringe projec-
tion and analysis is developed. A high-speed digital fringe projection
system projects three phase-shifted sinusoidal fringe patterns onto a hu-
man face and captures the deformed fringe patterns. Two fringe analy-
sis methods, namely the Fourier transform and phase shifting method,
are employed. The phase shifting method is used to eliminate the back-
ground illumination and facial skin texture variations. The Fourier trans-
form method is applied to generate a spectrum, which represents the 3-D
shape of the face. The eigenface algorithm takes the face spectra as in-
puts and performs face recognition. The proposed method obtained a
spectral representation of the 3-D face without reconstructing the 3-D
face geometry. The experimental and simulation results demonstrated
satisfactory recognition results compared to 2-D intensity image based
technique, and the advantage of reduced storage space and computation
load compared to 3-D point clouds.
86

5.2
Future Work
Further research of this dissertation research is recommended to include:
1. Automatic ﬁltering the Fourier spectrum For the MFTM, the ex-
traction of the 3-D shape related terms in the spatial frequency domain
is achieved by a band-pass ﬁlter. For objects with simple shape, the
width and position of the band-pass ﬁlter need not to be varied, in that
the 3-D shape related terms are well concentrated around the carrier
frequency. However, when complex shapes are measured, the carrier fre-
quency will be shifted towards or away from zero frequency. Right now
the width and position of the band-pass ﬁlter needs to be adjusted based
on the overall shape of the spectrum of the object. The ﬁltering aﬀects
the phase quality. In the future, an automatic ﬁlter adjustment needs
be developed in order to achieve better measurement results for diﬀerent
objects without frequently adjusting the ﬁlter.
2. Multiple marker detection and removal for absolute phase re-
trieval
The 3-D reconstruction in the MFTM is based on the retrieval of the
absolute phase map, which is built by detecting a embedded marker in
the fringe pattern. The robustness of the marker detection can be further
improved by employing multiple markers. When a single marker is used,
it has to be projected on a relatively ﬂat area to insure the accuracy of
marker center detection. If no ﬂat areas are available, the accuracy of
the absolute phase map is degraded. Multiple markers provide a possible
means to solve the problem. When multiple markers are projected, the
chance one of them being projected on a relatively ﬂat area is greatly
enhanced.
The epipolar geometry can be utilized to help detect the
markers. The potential diﬃculty is that how to determine which marker
detection result can be adopted. A strategy needs to be developed to
evaluate the marker detection results.
3. Application of the phase shifting shadow moir´e method to 3-D
shape measurement by using a SEM
Scanning electron microscope (SEM) is a widely used nanometer level 2-
D image acquisition tool. The shadow moir´e technique can be employed
in the SEM setup. Shadow moir´e pattern has been successfully observed
by placing a grating on top of a small steel ball. Fig. 5.1 shows the moire
pattern captured by the back scattered electron (BSE) detector and sec-
ondary electron (SE) detector respectively. Introducing phase shifts in a
87

SEM setup is diﬃcult. Therefore, the complicated approximate uniform
phase shifting schemes are not applicable. Our proposed phase shifting
method is simple and easy to implement in a SEM shadow moire setup.
The standard SEM stage can serve as a phase shifter. In the future,
special grating made needs to be manufactured in order to implement
the proposed phase shifting shadow moir´e method using a SEM.
(a)
(b)
Figure 5.1: Shadow moir´e patterns produced by the SEM.(a) SE detector
image; (b) BSE detector image.
4. Real-time face recognition based on the digital fringe projection
system
Real-time face image acquisition, processing, and recognition has great
application potential. A high-speed fringe projection system is utilized in
Chapter 4. The phase-shifted face fringe images are captured at a frame
rate of 30 sets/second. In order to achieve real-time face recognition, the
face spectra need be obtained in real-time, and a spectral face database
has to be built and eﬃciently managed. Also, the eigenface algorithm
needs to be implemented to connect with the face acquisition system and
the database.The fringe projection system employed in this research is
able to reconstruct 3-D face geometry in real-time. Fringe patterns can
be virtually project onto the 3-D face. Due to the pose normalization
requirement, the whole frontal face should be captured. Currently more
than one shot are needed to obtain a whole frontal face. However, the
symmetry of human face can be utilized. The lost part of the face due
to occlusion or shadow can be inferred from the available part of the 3-D
88

face. In this way, the inﬂuence of pose variation can be eliminated. The
proposed method can build or extend the spectral face database based
on existing 3-D database, by using virtual fringe projection technique.
89

Bibliography
[1] D. K. MacKinnon, V. Aitken, and F. Blais. A comparison of precision
and accuracy in triangulation laser range. Proc. IEEE Canadian Con-
ference on Electrical & Computer Engineering, pages 832–837, 2006.
[2] Z. Ji and M. C. Leu. Design of optical triangulation devices. Opt. Laser
Technology, 21(5):335–338, 1989.
[3] F. Blais. Review of 20 years of range sensor development. J. Electron.
Imaging, 13(1):231–240, 2004.
[4] John S. Massa, Gerald S. Buller, Andrew C. Walker, Sergio Cova,
Manikam Umasuthan, and Andrew M. Wallace. Time of ﬂight optical
ranging system based on time-correlated single-photo counting. Appl.
Opt., 37(31):7298–7304, 1998.
[5] F. Chen, G. M. Brown, and M Song. Overview of three-dimensional
shape measurement using optical method. Opt. Eng., 39(1):10–22, 2000.
[6] D. A. Forsyth and J. Ponce.
Computer vision: a modern approach.
Prentice-Hall, Upper Saddle River, New Jersey, 2002.
[7] R. Hartley and A. Zisserman. Multiple view geometry in computer vision.
Cambridge University Press, 2000.
[8] Thomas Luhmann, Stuart Robson, Stephen Kyle, and Ian Harleyr).
Close Range Photogrammetry: Principles, Techniques and Applications.
Whittles Publishing, 2006.
[9] Ronald D. Rogus, Robin L. Stern, and Hideo D. Kubo. Accuracy of
a photogrammetry-based patient positioning and monitoring system for
radiation therapy. Med. Phys., 26(5):721–728, 1999.
[10] J. J. Aguilar, F. Torres, and M. A. Lope. Stereo vision for 3D measure-
ment: accuracy analysis, calibration and industrial applications. Mea-
surement, 18(4):193–200, 1996.
90

[11] S. Malassiotis and M. G. Strintzis. Stereo vision system for precision
dimensional inspection of 3D holes. Machine Vision and Applications,
15(2):101–113, 2003.
[12] Joaquim Salvi, Jordi Pages, and Joan Batlle. Pattern codiﬁcation strate-
gies in structured light systems.
Pattern Recognition, 37(4):827–849,
2004.
[13] Joan Batlle, El Mustapha Mouaddib, and Joaquim Salvi.
Recent
progress in coded structured light as a technique to solve the correspon-
dence problem: A survey. Pattern Recognition, 31(7):963–982, 1998.
[14] Batlle J. Salvi, J. and E. Mouaddib. A robust-coded pattern projection
for dynamic 3d scene measurement.
Pattern Recognition Letters, 19:
1055–1065, 1998.
[15] Z. J. Geng. Rainbow 3-d camera: New concept of high-speed three vision
system. Opt. Eng., 35:376–383, 1996.
[16] J. L. Posdamer and M. D. Altschuler. Surface measurement by space-
encoded projected beam systems. Computer Graphics and Image Pro-
cessing, 18(1):1–17, 1982.
[17] S. Inokuchi, K. Sato, and F. Matsuda. Range imaging system for 3-
d ojbect recognition. IEEE Proc. of the International Conference on
Pattern Recognition, pages 806–808, 1984.
[18] E. Horn and N. Kiryati. Toward optimal structured light patterns. Image
and Vision Computing, 17(2):87–89, 1999.
[19] Kiryati N. Caspi, D. and J. Shamir. Range imaging with adaptive color
structured light. IEEE Trans. on Pattern Analysis and Machine Intelli-
gence, 20(5):470–480, May 1998.
[20] B. Carrihill and R. Hummel. Experiments with the intensity ratio depth
sensor. Computer Vision, Graphics and Image Processing, 32:337–358,
1985.
[21] Gilia Chazan and Nahum Kiryati. Pyramidal intensity-ratio depth sen-
sor. Technical Report No. 121, Israel Institute of Technology, Technion,
Haifa, Israel, Oct. 1995.
[22] Jianhui Pan, Peisen Huang, Song Zhang, and Fu-Pen Chiang. Color n-
ary gray code for 3-d shape measurement. In Proc. 12th Int’l Conference
on Experimental Mechanics, 2004.
91

[23] K Creath. Phase-shifting interferometry techniques. Pogress in Optics
XXVI, 26:357–373, 1988.
[24] K. A. Haines and B. P. Hildebrand. Contour generation by wavefront
construction. Phys. Lett., 19:10–11, 1965.
[25] K. J. G˚asvik, editor.
Optical Metrology.
John Wiley & Sons, third
edition, 2002.
[26] D. Malacara, editor. Optical Shop Testing. John Wiley & Sons, second
edition, 1992.
[27] Joanna Schmit and Artur Olszak. High-precision shape measurement by
white-light interferometry with real-time scanner error correction. Appl.
Opt., 41(28):5943–5950, 2002.
[28] J. C. Wyant. Interferometric optical metrology: basic system and prin-
ciples. Laser Focus, page 65:1, 1982.
[29] D. M. Meadows, W. O. Johnson, and J. B. Allen. Generation of surface
contours by moir´e patterns. Appl. Opt., 9:942–947, 1970.
[30] H. Takasaki. Moir´e topography. Appl. Opt., 9(6):1467–1472, 1970.
[31] F. P. Chiang. Moir´e methods of strain analysis. In A. S. Kobayashi,
editor, Manual on Experimental Stress Analysis, pages 51–69, Brookﬁeld
Center, CT, 1983. Soc. for Exp. Stress Anal.
[32] G. Mauvoisin, F. Bremand, and A Lagarde. Three-dimensional shape
reconstruction by phase-shifting shadow moir´e. Appl. Opt., 33(11):2163–
2169, 1994.
[33] T. Yoshizawa and T. Tomisawa. Shadow moir´e topography by means of
the phase-shift method. Opt. Eng., 32(7):1668–1674, 1993.
[34] M. Halioua, R. S. Krishnamurthy, H. Liu, and F. P. Chiang. Projection
moir´e with moving gratings for automated 3-d topography. Appl. Opt.,
22(6):850–855, 1983.
[35] Y. Choi and S. Kim. Phase-shifting grating projection moir´e topography.
Opt. Eng., 37(3):1005–1010, 1998.
[36] J. A. N. Buytaert and J. J. J. Dirckx. Moir´e proﬁlometry using liquid
crystals for projection and demodulation. Optics Express, 16(1):179–193,
2008.
92

[37] P. S. Huang, C. Zhang, and F. P. Chiang. High-speed 3-d shape mea-
surement based on digital fringe projection. Opt. Eng., 42(1):163–168,
2003.
[38] D. Doherty and G. Hewlett.
Pulse width modulation control in dlp
projectors. Texas Instruments Technical Journal, 15:115121, 1998.
[39] D. Malacara, editor. Optical Shop Testing. John Wiley and Songs, NY,
1992.
[40] M. Takeda, H. Ina, and S. Kobayashi.
Fourier-transform method of
fringe-pattern analysis for computer-based topography and interferome-
try. J. Opt. Soc. Am., 72:156–160, 1981.
[41] W. Y. Zhao, R. Chellappa, A. Rosenfeld, and P.J. Phillips. Face recog-
nition: A literature survey. ACM Computing Surveys, 35(4):399–458,
2003.
[42] P. J. Phillips, Todd Scruggs, Kevin W. Bowyer, Jin Chang, Kevin Hoﬀ-
man, Joe Marques, Jaesik Min, and William Worek. Overview of the face
recognition grand challenge. volume 1 of IEEE Computer Society Con-
ference on Computer Vision and Pattern Recognition(CVPR05), pages
947–954, 2005.
[43] Andrea F. Abate, Michele Nappi, Daniel Riccio, and Gabriele Sabatino.
2d and 3d face recognition: A survey. Pattern Recognition Letters, 28
(14):1885–1906, 2007.
[44] X. Su and W. Chen. Fourier transform proﬁlometry: a review. Optics
and Lasers in Engineering, 35:263–284, 2001.
[45] M. Takeda and K. Mutoh. Fourier transform proﬁlometry for the auto-
matic measurement of 3-d object shapes. Applied Optics, 22(24):3977–
3982, 1983.
[46] M. Takeda,
M. Kinoshita Q. Gu,
H. Takai,
and Y. Takahashi.
Frequency-multiplex Fourier-transform proﬁlometry:
a single-shot
three-dimensional shape measurement of objects with large height dis-
continuities and/or surface isolations. Applied Optics, 36(22):5347–5354,
1997.
[47] F. J. Harris.
On the use of windows for harmonic analysis with the
discrete Fourier transform. volume 66 of Proc. IEEE, pages 51–83, 1978.
93

[48] W. Chen, X. Su, Y. Cao, and L. Xian.
Improving fourier transform
proﬁlometry based on bicolor fringe pattern. Opt. Eng., 43(1):192–198,
2004.
[49] H. Yue, X. Su, and Y. Liu. Fourier transform proﬁlometry based on
composite structured light pattern. Optics and Laser Technology, 39:
1170–1175, 2007.
[50] K. Qian. Two-dimensional windowed fourier transform for fringe pat-
tern analysis: principles, applications and implementations. Optics and
Lasers in Engineering, 45:304–317, 2007.
[51] Dennis C. Ghiglia and Mark D. Pritt. Two-Dimensional Phase Unwrap-
ping: Theory, Algorithms, and Software.
John Wiley and Sons, Inc,
1998.
[52] R. M. Goldstein, H. A. Zebker, and C. L. Werner. Satellite radar inter-
ferometry: two-dimensional phase unwrapping. Radio Sci., 23:713–720,
1988.
[53] J. M. Huntley. Noise-immune phase unwrapping algorithm. Appl. Opt.,
28:3268–3270, 1989.
[54] T. J. Flynn. Consistent 2-d phase unwrapping guided by a quality map.
Proc. IGARSS’96, pages 2057–2059, Lincoln, NE, 1996.
[55] D. J. Bone. Fourier fringe analysis: the two-dimensional phase unwrap-
ping problem. Appl. Opt., 30:3627–3632, 1991.
[56] Y. Xu and C. Ai. Simple and eﬀective phase unwrapping technique.
volume 2003 of Proc. SPIE, pages 254–263, 1993.
[57] A. Asundi and Z. Wensen. Fast phase-unwrapping algorithm based on
a gray-scale mask and ﬂood ﬁll. Appl. Opt., 37:5416–5420, 1998.
[58] T. J. Flynn.
Two-dimensional phase unwrapping with minimum
weighted discontinuity. J. Opt. Soc. Am., 14:2692–2701, 1997.
[59] D. C. Ghiglia and L. A. Romero. Minimum lp-norm two-dimensional
phase unwrapping. J. Opt. Soc. Am. A, 13:1999–2013, 1996.
[60] J.-J. Chyou, S.-J. Chen, and Y.-K. Chen. Two-dimensional phase un-
wrapping with a multichannel least-mean-square algorithm. Appl. Opt.,
43:5655–5661, 2004.
94

[61] J. M. Huntley and H. O. Saldner. Temporal phase-unwrapping algorithm
for automated interferogram analysis. Appl. Opt., 32:3047–3052, 1993.
[62] David R. Burton and Michael J. Lalor. Multichannel fourier fringe anal-
ysis as an aid to automatic phase unwrapping. Appl. Opt., 33(14):2939–
2948, 1994.
[63] E. Zappa and G. Busca. Comparison of eight unwrapping algorithms
applied to fourier-transform proﬁlometry. Optics and Lasers in Engi-
neering, 46:106–116, 2007.
[64] Q. Hu and K. G. Harding. Conversion from phase map to coordinate:
Comparison among spatial carrier, fourier transform, and phase shifting
methods. Optics and Lasers in Engineering, 45:342–348, 2007.
[65] James Cubillo Fiona Berrymana, Paul Pynsent. The eﬀect of windowing
in Fourier transform proﬁlometry applied to noisy images. Optics and
Lasers in Engineering, 41:815825, 2004.
[66] D. J. Bone, H.-A. Bachor, and R. J. Sandeman. Fringe-pattern analysis
using a 2-d Fourier transform. Applied Optics, 25(10):1653–1660, 1986.
[67] X. Han. On Improving the Accuracy of a Real-time 3-D Shape Measure-
ment System. Stony Brook University, Stony Brook, 2006.
[68] Kjell J. G˚asvik.
Optical Metrology.
John Wiley and Sons, Inc, 3rd
edition, 2002.
[69] P. S. Huang and X. Han. On improving the accuracy of structured light
systems. In P. S. Huang, editor, Two- and Three-Dimensional Methods
for Inspection and Metrology IV, volume 6382 of Proc. SPIE, 2006.
[70] S. Zhang and P. S. Huang. Novel method for structured light system
calibration. Opt. Eng., 45(8):083601–1–8, 2006.
[71] M. Frigo and S.G. Johnson. The design and implementation of FFTW
3. Proceedings of the IEEE, 93(2):216–231, 2005.
[72] Daniel Malacara, editor. Optical Shop Testing. John Wiley and Songs,
NY, 1992.
[73] Johannes Schwider, Oliver R. Falkenstoerfer, Horst Schreiber, Andreas
Zoeller, and Norbert Streibl. New compensating four-phase algorithm
for phase-shift interferometry. Opt. Eng., 32(8):1883–1885, 1993.
95

[74] P. Hariharan, B. F. Oreb, and T. Eiju. Digital phase-shifting interfer-
ometry: a simple error-compensating phase calculation algorithm. Appl.
Opt., 26:25042506, 1987.
[75] J. Schwider, R. Burow, K.-E. Elssner, J. Grzanna, R. Spolaczyk, and
K. Merkel. Digital wave-front measuring interferometry: some system-
atic error sources. Opt. Eng., 22:3421 3432, 1983.
[76] P. Carr´e. Installation et utilisation du comparateur photoelectrique et
interferentiel du bureau international des poids de mesures. Metrologia,
2:13, 1966.
[77] J. J. J. Dirckx, W. F. Decraemer, and G. Dielis. Phase shift method
based on object translation for full ﬁeld automatic 3-d surface recon-
struction from moir´e topograms. Appl. Opt., 26(7):1164–1169, 1988.
[78] X. Xie, J. T. Atkinson, M. J. Lalor, and D. R. Burton.
Three-map
absolute moir´e contouring. Appl. Opt., 35(35):6990–6995, 1996.
[79] L. Jin, Y. Kodera, T. Yoshizawa, and Y. Otani. Shadow moir´e pro-
ﬁlometry using the phase-shifting method. Opt. Eng., 39(8):2119–2123,
2000.
[80] J. Degrieck, W. V. Paepegem, and P. Boone.
Application of digital
phase-shift shadow moir´e to micro deformation measurements of curved
surfaces. Optics and Lasers in Engineering, 36:29–40, 2001.
[81] J. B. Allen and D. M. Meadows. Removal of unwanted patterns from
moir´e contour maps by grid translation techniques. Appl. Opt., 10:210–
212, 1971.
[82] Q. Kemao, S. Fangjun, and W. Xiaoping. Determination of the best
phase step of the Carr´e algorithm in phase shifting interferometry. Mea-
surement Science and Technology, 11(8):1220–3, 2000.
[83] J. van Wingerden, H.J. Frankena, and C. Smorenburg. Linear approxi-
mation for measurement errors in phase shifting interferometry. Applied
Optics, 30(19):2718–2729, 1991.
[84] K. Creath. Phase-measurement interferometry techniques. Progress in
optics, 26:349–393, 1988.
[85] M. Turk and A. Pentland. Eigenfaces for recognition. J. Cognitive Neu-
roscience, 3(1):71–86, 1991.
96

[86] V. I. Belhumeur, J. P. Hespanha, and D. J. Kriegman.
Eigenfaces
vs.ﬁsherfaces: recognition using class speciﬁc linear projection. IEEE-
Trans. Patt. Anal. Mach. Intell., 19(7):711–720, 1997.
[87] D. L. SWETS and J. WENG. Using discriminant eigenfeatures for image
retrieval. IEEE Trans. Patt. Anal. Mach. Intell., 18(8):831–836, 1996.
[88] Kyong I. Chang, Kevin W. Bowyer, and Patrick J. Flynn. Using discrim-
inant eigenfeatures for image retrieval. IEEE Trans. Patt. Anal. Mach.
Intell., 27(4):619–624, 2005.
[89] Kevin W. Bowyer, Kyong Chang, and Patrick Flynn. A survey of ap-
proaches and challenges in 3D and multi-modal 3D + 2D face recogni-
tion. Computer Vision and Image Understanding, 101(1):1–15, 2006.
[90] Xiaoguang Lu, Dirk Colbry, and Anil K. Jain. Three-dimensional model
based face recognition. Proc. International Conference on Pattern Recog-
nition, pages 362–366, 2004.
[91] S. Malassiotis and M.G. Strintzis. Pose and illumination compensation
for 3d face recognition. volume 1 of International Conference on Image
Processing, pages 91–94, 2004.
[92] Bernard Achermann, Xiaoyi Jiang, and Horst Bunke. Face recognition
using range images. Proc. International Conference on Virtual Systems
and MultiMedia, page 129, 1997.
[93] Hong Guo and Peisen S. Huang. Absolute phase technique for the fourier
transform method. Optical Engineering, 48(4):043609, 2009.
[94] A.C. Zimmermann, A.A. Gon¸calves Jr, and J.M. Barreto. A 3D Object
Extraction and Recognition Method. In IEEE-Sixth International Con-
ference on Control, Automation, Robotics and Vision-ICARV. Citeseer,
2000.
[95] Yang Wang, Mohit Gupta, Song Zhang, Sen Wang, Xianfeng Gu, Dim-
itris Samaras, and Peisen Huang. High resolution tracking of non-rigid
motion of densely sampled 3D data using harmonic maps. Int. J. Com-
put. Vis., 76:283300, 2009.
[96] Xiaoguang Lu, Dirk Colbry, and Anil K. Jain. Three-dimensional model
based face recognition. Pattern Recognition, International Conference
on, 1:362–366, 2004. ISSN 1051-4651.
97

[97] P. Flynn K. Chang, K. Bowyer. Face recognition using 2D and 3D facial
data. Multimodal User Authentication Workshop, page 2532, December
2003.
[98] Chris Boehnen and Patrick Flynn. Accuracy of 3d scanning technolo-
gies in a face scanning scenario. In 3DIM ’05: Proceedings of the Fifth
International Conference on 3-D Digital Imaging and Modeling, pages
310–317, Washington, DC, USA, 2005. IEEE Computer Society. ISBN
0-7695-2327-7.
[99] C. Beumier and M. Acheroy. Automatic 3D face authentication. Image
and Vision Computing, 18(4):315–321, 2000.
[100] Chiraz BenAbdelkadera and Paul A. Griﬃn. Comparing and combining
depth and texture cues for face recognition. Image and Vision Comput-
ing, 23:339–352, 2005.
[101] R. A. Andrade, B. S. Gilbert, D. W. Dawson, C. Hart, S. P. Kozaitis, and
J. H. Blatt. Real-time optically processed face recognition system based
on arbitrary moir´e contours. Optical Engineering, 35(9):2534–2540, 1996.
[102] J. J. Esteve-Taboada, D. Mas, and J. Garc´ıa. Three-dimensional object
recognition by fourier transform proﬁlometry. Applied Optics, 38(22):
4760–4765, 1999.
[103] P. Viola and M. Jones. Robust real-time object detection. Intl. J. Com-
puter Vision, 57(2):137–154, 2002.
[104] Hyeonjoon Moon and P. J. Phillips. Computational and performance
aspects of pca-based face-recognition algorithms. Perception, 30:303–
321, 2001.
[105] H. Abdi F. Yang and A. Monopoli. Development of a fast panoramic
mosaicking and recognition system. Opt. Eng., 44(8):087005–1–10, 2005.
[106] Cass
Everitt.
Projective
texture
mapping,
2001.
http://www.nvidia.com/developer.
98

