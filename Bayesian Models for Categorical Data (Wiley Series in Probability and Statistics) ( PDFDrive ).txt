
Bayesian Models for Categorical Data

WILEY SERIES IN PROBABILITY AND STATISTICS
Established by WALTER A. SHEWHART and SAMUEL S. WILKS
Editors: David J. Balding, Peter Bloomﬁeld, Noel A. C. Cressie,
Nicholas I. Fisher, Iain M. Johnstone, J. B. Kadane, Geert Molenberghs,
Louise M. Ryan, David W. Scott, Adrian F. M. Smith, Jozef L. Teugels;
Editors Emeriti: Vic Barnett, J. Stuart Hunter, David G. Kendall
A complete list of the titles in this series appears at the end of this volume.

Bayesian Models for
Categorical Data
PETER CONGDON
Queen Mary, University of London, UK
Chichester  New York  Weinheim  Brisbane  Singapore  Toronto

Copyright # 2005
John Wiley & Sons Ltd, The Atrium, Southern Gate, Chichester,
West Sussex PO19 8SQ, England
Telephone
(+44) 1243 779777
Email (for orders and customer service enquiries): cs-books@wiley.co.uk
Visit our Home Page on www.wiley.com
All Rights Reserved. No part of this publication may be reproduced, stored in a retrieval system
or transmitted in any form or by any means, electronic, mechanical, photocopying, recording,
scanning or otherwise, except under the terms of the Copyright, Designs and Patents Act 1988
or under the terms of a licence issued by the Copyright Licensing Agency Ltd, 90 Tottenham
Court Road, London W1T 4LP, UK, without the permission in writing of the Publisher.
Requests to the Publisher should be addressed to the Permissions Department, John Wiley
& Sons Ltd, The Atrium, Southern Gate, Chichester, West Sussex PO19 8SQ, England, or
emailed to permreq@wiley.co.uk, or faxed to (+44) 1243 770620.
Designations used by companies to distinguish their products are often claimed as trademarks.
All brand names and product names used in this book are trade names, service marks, trademarks
or registered trademarks of their respective owners. The publisher is not associated with any product
or vendor mentioned in this book.
This publication is designed to provide accurate and authoritative information in regard to the
subject matter covered. It is sold on the understanding that the Publisher is not engaged in rendering
professional services. If professional advice or other expert assistance is required, the services
of a competent professional should be sought.
Other Wiley Editorial Ofﬁces
John Wiley & Sons Inc., 111 River Street, Hoboken, NJ 07030, USA
Jossey-Bass, 989 Market Street, San Francisco, CA 94103-1741, USA
Wiley-VCH Verlag GmbH, Boschstr. 12, D-69469 Weinheim, Germany
John Wiley & Sons Australia Ltd, 33 Park Road, Milton, Queensland 4064, Australia
John Wiley & Sons (Asia) Pte Ltd, 2 Clementi Loop # 02-01, Jin Xing Distripark, Singapore 129809
John Wiley & Sons Canada Ltd, 22 Worcester Road, Etobicoke, Ontario, Canada M9W 1L1
Wiley also publishes its books in a variety of electronic formats. Some content that appears in
print may not be available in electronic books.
Library of Congress Cataloging-in-Publication Data
Congdon, P.
Bayesian models for categorical data/Peter Congdon.
p. cm. – (Wiley series in probability and statistics)
Includes bibliographical references and index.
ISBN 0-470-09237-8 (cloth : alk. paper)
1. Bayesian statistical decision theory. 2. Monte Carlo method. 3. Markov processes.
4. Multivariate analysis. I. Title. II. Series.
QA279.5.C6495 2005
519.5’42–dc22
2005005158
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
ISBN-13 978-0-470-09237-8 (HB)
ISBN-10 0-470-09237-8 (HB)
Typeset in 11/13pt Times by Thomson Press (India) Limited, New Delhi, India.
Printed and bound in Great Britain by Antony Rowe Ltd, Chippenham, Wiltshire
This book is printed on acid-free paper responsibly manufactured from sustainable forestry
in which at least two trees are planted for each one used for paper production.

Contents
Preface
xi
Chapter 1
Principles of Bayesian Inference
1
1.1
Bayesian updating
1
1.2
MCMC techniques
2
1.3
The basis for MCMC
4
1.4
MCMC sampling algorithms
6
1.5
MCMC convergence
10
1.6
Competing models
12
1.7
Setting priors
12
1.8
The normal linear model and generalized
linear models
13
1.9
Data augmentation
17
1.10
Identiﬁability
19
1.11
Robustness and sensitivity
21
1.12
Chapter themes
23
References
23
Chapter 2
Model Comparison and Choice
29
2.1
Introduction: formal methods, predictive
methods and penalized deviance criteria
29
2.2
Formal Bayes model choice
30
2.3
Marginal likelihood and Bayes factor
approximations
32
2.4
Predictive model choice and checking
35
2.5
Posterior predictive checks
37
2.6
Out-of-sample cross-validation
39
2.7
Penalized deviances from a Bayes perspective
41
2.8
Multimodel perspectives via parallel sampling
42
2.9
Model probability estimates from parallel sampling
46
2.10
Worked example
49
References
50

Chapter 3
Regression for Metric Outcomes
55
3.1
Introduction: priors for the linear regression model
55
3.2
Regression model choice and averaging based
on predictor selection
59
3.3
Robust regression methods: models for outliers
67
3.4
Robust regression methods: models for skewness and
heteroscedasticity
71
3.5
Robustness via discrete mixture models
75
3.5.1
Complete data representation
76
3.5.2
Identiﬁcation issues
77
3.5.3
Dirichlet process mixture models
79
3.6
Non-linear regression effects via splines and
other basis functions
82
3.6.1
Penalized random effects for spline coefﬁcients 85
3.6.2
Basis function regression
86
3.6.3
Special spline functions
87
3.7
Dynamic linear models and their application in
non-parametric regression
95
3.7.1
Some common forms of DLM
96
3.7.2
Robust errors
97
3.7.3
General additive models
98
3.7.4
Alternative smoothness priors
100
Exercises
105
References
106
Chapter 4
Models for Binary and Count Outcomes
113
4.1
Introduction: discrete model likelihoods vs.
data augmentation
113
4.1.1
Count data
114
4.1.2
Binomial and binary data
117
4.2
Estimation by data augmentation: the
Albert–Chib method
121
4.2.1
Other augmented data methods
122
4.3
Model assessment: outlier detection and model checks
125
4.3.1
Model assessment: predictive model selection
and checks
126
4.4
Predictor selection in binary and count regression
130
4.5
Contingency tables
133
4.6
Semi-parametric and general additive models
for binomial and count responses
140
4.6.1
Robust and adaptive non-parametric regression
143
4.6.2
Other approaches to non-linearity
144
Exercises
149
References
150
vi
CONTENTS

Chapter 5
Further Questions in Binomial and Count Regression
155
5.1
Generalizing the Poisson and binomial:
overdispersion and robustness
155
5.2
Continuous mixture models
157
5.2.1
Modiﬁed exponential families
161
5.3
Discrete mixtures
163
5.4
Hurdle and zero-inﬂated models
167
5.5
Modelling the link function
171
5.5.1
Discrete (DPP mixture)
172
5.5.2
Parametric link transformations
173
5.5.3
Beta mixture on cumulative densities
174
5.6
Multivariate outcomes
177
5.6.1
The factor analysis approach
179
5.6.2
Speciﬁc modelling of marginal and
odds ratios
180
5.6.3
Multivariate Poisson data
182
Exercises
189
References
192
Chapter 6
Random Effect and Latent Variable Models for
Multicategory Outcomes
197
6.1
Multicategory data: level of observation and relations
between categories
197
6.2
Multinomial models for individual data:
modelling choices
198
6.3
Multinomial models for aggregated data: modelling
contingency tables
202
6.3.1
Conditional contingency tables:
histogram smoothing and multinomial
logit via Poisson regression
203
6.4
The multinomial probit
210
6.5
Non-linear predictor effects
213
6.6
Heterogeneity via the mixed logit
216
6.7
Aggregate multicategory data: the multinomial–
Dirichlet model and extensions
219
6.8
Multinomial extra variation
221
6.8.1
Uncertainty in Dirichlet parameters
223
6.9
Latent class analysis
226
Exercises
230
References
231
Chapter 7
Ordinal Regression
235
7.1
Aspects and assumptions of ordinal data models
235
7.2
Latent scale and data augmentation
236
CONTENTS
vii

7.3
Assessing model assumptions: non-parametric
ordinal regression and assessing ordinality
243
7.4
Location-scale ordinal regression
247
7.5
Structural interpretations with aggregated ordinal data
251
7.6
Log-linear models for contingency tables with
ordered categories
255
7.7
Multivariate ordered outcomes
258
Exercises
263
References
264
Chapter 8
Discrete Spatial Data
267
8.1
Introduction
267
8.2
Univariate responses: the mixed ICAR
model and extensions
268
8.3
Spatial robustness
273
8.4
Multivariate spatial priors
275
8.5
Varying predictor effect models
279
Exercises
285
References
286
Chapter 9
Time Series Models for Discrete Variables
289
9.1
Introduction: time dependence in observations and
latent data
289
9.2
Observation-driven dependence
291
9.2.1
Binary data and Markov
Chain models
293
9.2.2
Observation-driven models for individual
multicategory data
297
9.2.3
Time series of aggregate multinomial data
298
9.3
Parameter-driven dependence via DLMs
300
9.3.1
Measurement error models
302
9.3.2
Conjugate updating
304
9.4
Parameter-driven dependence via autocorrelated
error models
309
9.5
Integer autoregressive models
311
9.6
Hidden Markov models
313
Exercises
315
References
317
Chapter 10
Hierarchical and Panel Data Models
321
10.1
Introduction: clustered data and general
linear mixed models
321
10.2
Hierarchical models for metric outcomes
322
viii
CONTENTS

10.3
Hierarchical generalized linear models
324
10.3.1
Augmented data sampling for
hierarchical GLMs
328
10.4
Random effects for crossed factors
333
10.5
The general linear mixed model for panel data
336
10.5.1
Time dependence
338
10.5.2
Longitudinal categorical data
340
10.6
Conjugate panel models
346
10.7
Growth curve analysis
350
10.8
Multivariate panel data
352
10.9
Robustness in panel and clustered data analysis
358
10.10 APC and spatio-temporal models
362
10.11 Space–time and spatial APC models
364
Exercises
371
References
374
Chapter 11
Missing-Data Models
379
11.1
Introduction: types of missing data
379
11.2
Density mechanisms for missing data
381
11.3
Auxiliary variables
385
11.4
Predictors with missing values
387
11.5
Multiple imputation
391
11.6
Several responses with missing values
395
11.7
Non-ignorable non-response models for
survey tabulations
397
11.7.1
The differential non-response model
398
11.7.2
Alternative parameterizations of the
differential non-response model
401
11.7.3
Ecological inference: imputing missing
interior data in R  C tables
403
11.7.4
Cross-tabulations with missing
data on any factor
407
11.8
Recent developments
409
Exercises
410
References
412
Index
415
CONTENTS
ix


Preface
This book continues the themes in my two earlier Wiley books in seeking
to make modern Bayesian methods accessible via a practically oriented
exposition, with statistical computing and applied data analysis at the
forefront. As before, I have focused on the WINBUGS package, which
has now reached a wide degree of acceptance in application to the ever
expanding corpus of methodological work and applications based on
Monte Carlo Markov Chain techniques. I hope that the applied focus will
help students and researchers alike, including those with primary dis-
ciplinary interests outside statistics (e.g. psychology, geography and
epidemiology). Nevertheless a wide range of simple or more advanced
modelling techniques are discussed and I hope the approach is also
helpful for courses in Bayesian data analysis and statistical computing. I
have sought to review recent Bayesian methodology for categorical
outcomes (binary, count and multinomial data) but my take on this will
obviously emphasize some themes more than others: particular aspects
that I have focused on include non-parametric and non-linear regression
models, model choice, time series and spatio-temporal models. Missing
data models are also considered. As with my earlier Wiley books, a set of
worked examples with documented code forms part of the book’s
presentation and can be downloaded from the publisher’s website ftp://
www.wiley.co.uk/pub/books/congdon, the WINBUGS site or STATLIB.
Peter Congdon


CHAPTER 1
Principles of Bayesian
Inference
1.1
BAYESIAN UPDATING
Bayesian inference differs from classical inference in treating parameters
as random variables and using the data to update prior knowledge about
parameters and functionals of those parameters. We are also likely to
need model predictions and these are provided as part of the updating
process. Prior knowledge about parameters and updated (or posterior)
knowledge about them, as well as implications for functionals and
predictions, are expressed in terms of densities. One of the beneﬁts of
modern Monte Carlo Markov Chain (MCMC) sampling methods (e.g.
Chib and Greenberg, 1995; Tierney, 1994; Gelfand and Smith, 1990;
Gilks et al., 1996a; Smith and Roberts, 1993) is the ease with which full
marginal densities of parameters may be obtained. In a regression model
the parameters would be regression coefﬁcients and possible variance
parameters, and functionals of parameters might include elasticities (in
econometrics) or effective dose (in biometrics).
The new Bayesian sampling-based estimation techniques obtain sam-
ples from the posterior density, either of parameters themselves, or
functionals of parameters. They improve considerably on multiple
integration or analytical approximation methods that are infeasible with
large numbers of parameters. Nevertheless many issues remain in the
application of sampling-based techniques, such as obtaining convergence,
and choice of efﬁcient sampling method. There are also more general
Bayesian Models for Categorical Data
P. Congdon
# 2005 John Wiley & Sons, Ltd

problems in Bayesian methods such as choice of priors (and possible
sensitivity of inferences to alternative choices).
The basis for Bayesian inference may be derived from simple prob-
ability theory. Thus the conditional probability theorem for events A and
B is that
PrðAjBÞ ¼ PrðA; BÞ=PrðBÞ ¼ PrðBjAÞPrðAÞ=PrðBÞ
Replacing B by observations y, A by a parameter set  and probabilities
by densities results in the relation
pðjyÞ ¼ pð; yÞ=pðyÞ ¼ pðyjÞpðÞ=pðyÞ
ð1:1Þ
where pðyjÞ is the likelihood of y under a model and pðÞ is the prior
density, or the density of  before y is observed. This density expresses
accumulated knowledge about , or, viewed another way, the degree of
uncertainty about . It may also include working model assumptions (e.g.
assumptions about the nature of error structures); for example, one model
might assume uncorrelated errors over time or space and another model
assume correlated errors.
Classical analysis via maximum likelihood focuses on the likelihood
pðyjÞ without introducing a prior, whereas fully Bayesian analysis
updates the prior information about  with the information contained in
the data. The denominator pðyÞ ¼
Ð
pðyjÞpðÞd in (1.1) deﬁnes the
‘marginal likelihood’ or ‘prior predictive density’ of the data and may be
set to be an unknown constant c. So posterior inferences about  under
(1.1) can be equivalently stated in the relation
pðjyÞ ¼ pð yjÞpðÞ=c
or
pðjyÞ / pð yjÞpðÞ
This can be stated as ‘posterior is proportional to likelihood times prior’.
1.2
MCMC TECHNIQUES
The basis of modern Bayesian inference regarding pðjyÞ is the use of
iterative MCMC methods that involve repeated sampling from the
posterior distribution, using long, possibly multiple, chains of parameter
samples. One is then interested in posterior summaries of parameters or
functionals from the MCMC output in the form of expectations, densities
or probabilities. These summaries typically include posterior means and
2
PRINCIPLES OF BAYESIAN INFERENCE

variances of the parameters themselves, or of functions  ¼ ðÞ of the
parameters, which analytically are
EðkjyÞ ¼
ð
kpðjyÞd
ð1:2Þ
VarðkjyÞ ¼
ð
2
kpðjyÞd  ½EðkjyÞ2
¼ Eð2
kjyÞ  ½EðkjyÞ2
ð1:3Þ
E½ðÞjy ¼
ð
ðÞpðjyÞd
Var½ðÞjy ¼
ð
2pðjyÞd  ½EðjyÞ2
¼ Eð2jyÞ  ½EðjyÞ2
Often the major interest is in marginal densities of the parameters
themselves. Let the model dimension be d, so that  ¼ ð1; . . . ; dÞ.
Then the marginal density of the jth parameter j is obtained by
integrating out all other parameters
pðjjyÞ ¼
ð
pðjyÞd1d2 . . . j1jþ1 . . . d
The predictive density for new or replicate data useful in model checking
and comparison is
pðynewjyÞ ¼
ð
pðynew; jyÞd ¼
ð
pðynewjy; ÞpðjyÞd
Posterior probabilities might relate to the probability that j exceeds a
threshold b, and involve integrals of the form
Prðj > bjyÞ ¼
ð1
b
pðjjyÞdj
ð1:4Þ
Such expectations, densities or probabilities may be obtained analytically
for conjugate analyses, such as a binomial likelihood where the prob-
ability has a beta prior. Results can be obtained under asymptotic
approximations (Bernardo and Smith, 1994), similar to those used in
classical statistics, or by analytic approximations (e.g. Laplace) based on
expanding the relevant integral (Kass et al., 1988). Such approximations
tend to be less good for posteriors that are not approximately normal or
where there is multimodality. An alternative strategy facilitated by
contemporary computer technology is to use sampling-based approxima-
tions based on the Monte Carlo principle. One such sampling method is
MCMC TECHNIQUES
3

importance sampling (Geweke, 1989; McFadden, 1989), and other
precursors of modern Bayesian sampling include data augmentation for
Bayes inference in missing-data problems (Tanner and Wong, 1987).
1.3
THE BASIS FOR MCMC
The canonical Monte Carlo method assumes a sample of independent d-
dimensional simulations uð1Þ; uð2Þ; . . . ; uðTÞ from a target density ðuÞ
whereby E½gðuÞ ¼
Ð
gðuÞðuÞdu is estimated as
gT ¼
X
T
t¼1
gðuðtÞÞ
With probability 1, gT tends to E½gðuÞ as T ! 1. However, indepen-
dent sampling from the posterior density pðjyÞ is not feasible in general.
It is valid, however, to use dependent samples ðtÞ provided the sampling
satisfactorily covers the support of pðjyÞ (Gilks et al., 1996b). In order to
sample approximately from pðjyÞ, MCMC methods generate pseudoran-
dom-dependent draws via Markov chains. Speciﬁcally let ð0Þ; ð1Þ; . . . be
a sequence of random variables. Then pðð0Þ; ð1Þ; . . . ; ðTÞÞ is a Markov
chain if
pððtÞjð0Þ; ð1Þ; . . . ; ðt1ÞÞ ¼ pððtÞjðt1ÞÞ
so that only the preceding state is relevant to the future state. Suppose ðtÞ
is deﬁned on a discrete state space S ¼ fs1; s2; . . .g; generalisation to
continuous state spaces is described by Tierney (1996). Assume
pððtÞjðt1ÞÞ is deﬁned by a constant one-step transition matrix
Qi; j ¼ PrððtÞ ¼ sjjðt1Þ ¼ siÞ
with t-step transition matrix Qi; jðtÞ ¼ PrððtÞ ¼ sjjð0Þ ¼ siÞ. Sampling
from a constant one-step Markov chain converges to a stationary
distribution ðÞ ¼ pðjyÞ if additional requirements1 on the chain are
satisﬁed (irreducibility, aperiodicity and positive recurrence) – see
Roberts (1996, p 46) and Norris (1997). Sampling chains meeting these
1Suppose a chain is deﬁned on a space S. A chain is irreducible if for any pair of states ðsi; sjÞ 2 S
there is a non-zero probability that the chain can move from si to sj in a ﬁnite number of steps. A state
is positive recurrent if the number of steps the chain needs to revisit the state has a ﬁnite mean. If all
the states in a chain are positive recurrent then the chain itself is positive recurrent. A state has period
k if it can only be revisited after a number of steps that is a multiple of k. Otherwise the state is
aperiodic. If all its states are aperiodic then the chain itself is aperiodic. Positive recurrence and
aperiodicity together constitute ergodicity.
4
PRINCIPLES OF BAYESIAN INFERENCE

requirements have a unique stationary distribution limt!1 Qi; jðtÞ ¼ ð jÞ
satisfying the full balance condition ðjÞ ¼ P
i ðiÞQi; j. Many Markov
chain methods are additionally reversible, meaning ðiÞQi; j ¼ ðjÞQj;i.
With this type of sampling mechanism, the ergodic average gT tends to
E½gðuÞ with probability 1 as T ! 1 despite dependent sampling.
Remaining practical questions include establishing an MCMC sampling
scheme and establishing that convergence to a steady state has been
obtained for practical purposes (Cowles and Carlin, 1996).
Estimates of quantities such as (1.2) and (1.3) are routinely obtained
from sampling output along with 2.5% and 97.5% percentiles that
provide credible intervals for the value of the parameter. A full posterior
density estimate may be derived also (e.g. by kernel smoothing of the
MCMC output of a parameter). For ðÞ its posterior mean is obtained
by calculating ðtÞ at every MCMC iteration from the sampled values
ðtÞ. The theoretical justiﬁcation for this is provided by the MCMC
version of the law of large numbers (Tierney, 1994), namely that
X
T
t ¼ 1
ððtÞÞ=T ! E½ðÞ
provided that the expectation of ðÞ under ðÞ ¼ pðjyÞ, denoted
E½ðÞ, exists.
The probability (1.4) would be estimated by the proportion of iterations
where ðtÞ
j
exceeded b, namely PT
t¼1 1ððtÞ
j
> bÞ=T, where 1ðAÞ is an
indicator function which takes value 1 when A is true, 0 otherwise. Thus
one might in a disease mapping application wish to obtain the probability
that an area’s smoothed relative mortality risk k exceeds zero, and so
count iterations where this condition holds, avoiding the need to evaluate
the integral
Prðk > 0Þ ¼
ð1
0
pðkjyÞdk
This principle extends to empirical estimates of the distribution function,
FðÞ of parameters or functions of parameters. Thus the estimated
probability that  < d for values of d within the support of  is
^FðdÞ ¼
X
T
t¼1
1ððtÞ  dÞ=T
The sampling output also often includes predictive replicates yðtÞ
new that
can be used in posterior predictive checks to assess whether a model’s
predictions are consistent with the observed data. Predictive replicates
THE BASIS FOR MCMC
5

are obtained by sampling ðtÞ and then sampling ynew from the
likelihood model pðynewjðtÞÞ. The posterior predictive density can
also be used for model choice and residual analysis (Gelfand, 1996,
sections 9.4–9.6).
1.4
MCMC SAMPLING ALGORITHMS
The Metropolis–Hastings (M–H) algorithm is the baseline for MCMC
sampling schemes and is based on a binary transition kernel. Following
Hastings (1970), the chain is updated from ðtÞ to  with probability
ðjðtÞÞ ¼ min 1; pðjyÞfððtÞjÞ
pððtÞjyÞfðjðtÞÞ


ð1:5Þ
with transition kernel ðjðtÞÞfðjðtÞÞ, where f is known as a proposal
or jumping density (Chib and Greenberg, 1995). If the proposed update is
rejected the next state is the same as the current state. The algorithm
works most successfully when the proposal density matches, at least
approximately, the shape of the target density pðjyÞ. The rate at which a
proposal generated by f is accepted (the acceptance rate) depends on how
close  is to ðtÞ, and this depends on the variance 2 assumed in the
proposal density. For a normal proposal density a higher acceptance rate
follows from reducing 2, but with the risk that the posterior density will
take longer to explore. Performance also tends to be improved if
parameters are transformed to take the full range of positive and negative
values ð1; 1Þ so lessening the occurrence of skewed parameter
densities.
If the proposal density is symmetric, with fðjðtÞÞ ¼ fððtÞjÞ, then
the Hastings algorithm reduces to an algorithm used by Metropolis et al.
(1953) for indirect simulation of energy distributions, whereby
ðjðtÞÞ ¼ min 1; pðjyÞ
pððtÞjyÞ


ð1:6Þ
A particular symmetric density in which fðjðtÞÞ ¼ fðjðtÞ  jÞ leads
to the random walk Metropolis (Gelman et al., 1996). While it is possible
for the proposal density to relate to the entire parameter set, it is often
computationally simpler to divide  into blocks or components, and use
componentwise updating, where updating is used in a generic sense
allowing for possible non-acceptance of proposed values.
6
PRINCIPLES OF BAYESIAN INFERENCE

Thus let ½j ¼ ð1; 2; . . . ; j1; jþ1; . . . ; dÞ denote the parameter set
omitting j and ðtÞ
j
be the value of j after iteration t. At step j of iteration
t þ 1 the preceding j  1 parameters are already updated via the M–H
algorithm while jþ1; . . . ; d are still at their iteration t values (Chib and
Greenberg, 1995). Let the vector of partially updated parameters be
denoted
ðt;tþ1Þ
½j
¼ ððtþ1Þ
1
; ðtþ1Þ
2
; . . . ; ðtþ1Þ
j1 ; ðtÞ
jþ1; . . . ; ðtÞ
d Þ
The proposed value 
j for ðtþ1Þ
j
is generated from the jth proposal
density, denoted fð
j jðtÞ
j ; ðt;tþ1Þ
½j
Þ. Also governing the acceptance of a
proposal are full conditional densities pððtÞ
j jðt;tþ1Þ
½j
Þ specifying the
density of j conditional on other parameters ½j. The candidate 
j is
accepted with probability
ððtÞ
j ; ðt;tþ1Þ
½j
; 
j Þ ¼ min 1;
pð
j jðt;tþ1Þ
½j
Þ fððtÞ
j j
j ; ðt;tþ1Þ
½j
Þ
pððtÞ
j jðt;tþ1Þ
½j
Þ fð
j jððtÞ
j ; ðt;tþ1Þ
½j
Þ
2
4
3
5
The Gibbs sampler (Gelfand and Smith, 1990; Gilks et al., 1996a; Casella
and George, 1992) is a special componentwise M–H algorithm whereby
the proposal density for updating j is the full conditional pð
j j½jÞ so that
proposals are accepted with probability 1. This sampler was originally
developed by Geman and Geman (1984) for Bayesian image reconstruc-
tion, with its full potential for simulating marginal distributions by
repeated draws recognised by Gelfand and Smith (1990). The Gibbs
sampler involves parameter-by-parameter updating which when com-
pleted forms the transition from ðtÞ to ðtþ1Þ:
1.
ðtþ1Þ
1
 f1ð1jðtÞ
2 ; ðtÞ
3 ; . . . ; ðtÞ
d Þ;
2.
ðtþ1Þ
2
 f2ð2jðtþ1Þ
1
; ðtÞ
3 ; . . . ; ðtÞ
d Þ;



d.
ðtþ1Þ
d
 fdðdjðtþ1Þ
1
; ðtþ1Þ
3
; . . . ; ðtþ1Þ
d1 Þ.
Repeated sampling from M–H samplers such as the Gibbs sampler
generates an autocorrelated sequence of numbers that, subject to reg-
ularity conditions (ergodicity etc.), eventually ‘forgets’ the starting values
ð0Þ ¼ ðð0Þ
1 ; ð0Þ
2 ; . . . ; ð0Þ
d Þ used to initialize the chain and converges to a
stationary sampling distribution pðjyÞ.
MCMC SAMPLING ALGORITHMS
7

The full conditional densities may be obtained from the joint density
pð; yÞ ¼ pðyjÞpðÞ and in many cases reduce to standard densities
(normal, exponential, gamma, etc.) from which sampling is straightfor-
ward. Full conditional densities can be obtained by abstracting out from
the full model density (likelihood times prior) those elements including j
and treating other components as constants (Gilks, 1996). Consider a
conjugate model for Poisson count data yi with means i that are
themselves gamma distributed; this is a model appropriate for over-
dispersed count data with actual variability VarðyÞ exceeding that under
the Poisson model. Suppose i  Gað; Þ, namely
fðij; Þ ¼ 1
i
expðiÞ=ðÞ
and further that   EðaÞ, and   Gðb; cÞ, where a, b and c are preset
constants; this prior structure is used by George et al. (1993). So the
posterior density of  ¼ ð1; . . . ; n; ; Þ given y is proportional to
eðaÞb1eðcÞ Y
n
i¼1
expðiÞyi
i
 Y
n
i¼1
1
i
expðiÞ

½=ðÞn
where all constants (such as the denominator Q yi! in the Poisson
likelihood) are combined in the proportionality constant. It is apparent
that the conditional densities of i and  are Gaðyi þ ;  þ 1Þ and
Gaðb þ n; c þ P iÞ respectively. The full conditional density of  is
fðjy; ; 
Þ / expðaÞ½=ðÞn
 Y
n
i¼1
i
1
This density is non-standard but log-concave and cannot be sampled
directly (as can the gamma densities for i and ). However, adaptive
rejection sampling (Gilks and Wild, 1992) may be used.
As examples of how M–H sampling might be carried out in practice,
consider a Poisson density with unknown mean  and data y ¼
ðy1; . . . ; ynÞ. One possible reference prior for  is pðÞ ¼ 1= so the
posterior density on  can be written
pðjyÞ /
Y
n
i¼1
½expðÞyi=
Suppose  is transformed to  ¼ logðÞ. Then the posterior in  includes
a Jacobian adjustment, @=@ ¼ expðÞ ¼ m, which cancels with pðÞ,
and so
pðjyÞ /
Y
n
i¼1
expðe þ yiÞ ¼ exp ne þ
X
n
i¼1
yi
 
!
8
PRINCIPLES OF BAYESIAN INFERENCE

If the prior is placed directly on  rather than , e.g.   Nða; bÞ where a
and b are known, a Jacobian adjustment is not needed. Then
pðjyÞ / exp ne þ
X
n
i¼1
yi
 
!
exp ð  aÞ2
2b
"
#
In either case one might use a symmetric normal proposal density to
generate potential new values  via (1.6). This density is centred on t
with variance 2
p that might be set at a default such as 2
p ¼ 1 and
increased or reduced in order to obtain better acceptance rates. Alter-
natively it might be based on VarðÞ from a maximum likelihood (ML)
analysis but with variance increased, namely 2
p ¼ K VarðMLÞ, K > 1.
If the variance is too low, acceptance rates will be high but the chain
will mix slowly (i.e. move slowly through the parameter space) and
converge slowly to pðjyÞ. If the variance is too large, the acceptance rate
will be low because the proposed new parameter values will have low
values of the ratios pðjyÞ=pðtjyÞ. For example, if the required accep-
tance rate is  (e.g.  ¼ 0:45), then one might run the sampler for a
certain number N of iterations and compare the actual number of
proposals accepted N1 with required number N2 ¼ N and revise the
scale according as N1  N2 or N1 > N2. If N1  N2,
p;new ¼ p;old=ð2  N1=N2Þ
while if N1 > N2,
p;new ¼ p;old=½2  ðN  N1Þ=ðN  N2Þ
Multiparameter updating will involve a multivariate density such as a
multivariate normal with dispersion matrix p. For example, consider the
mean  and standard deviation  in a univariate Student t density with
known degrees of freedom 	. Taking
pð; Þ ¼ 1=
as one among several possible reference priors, the posterior density is
pð; jyÞ / 1

Y
n
i¼1
1 þ ðyi  Þ2
	2
"
#ð	þ1Þ=2
Transforming to  ¼ log , the Jacobian is @=@ ¼  and the posterior
density in  and  is
pð; jyÞ / 1
e
Y
n
i¼1
1 þ ðyi  Þ2
	e2
"
#ð	þ1Þ=2
MCMC SAMPLING ALGORITHMS
9

This is the comparator density in (1.5) or (1.6), with a possible proposal
density, when  ¼ log , being a bivariate normal centred at ððtÞ; ðtÞÞ.
1.5
MCMC CONVERGENCE
There are many unresolved questions around the assessment of conver-
gence of MCMC sampling procedures (Cowles and Carlin, 1996). It is
generally accepted to be preferable to use two or more parallel chains
with diverse starting values to ensure full coverage of the sample space of
the parameters, and so diminish the chance that the sampling will become
trapped in a small part of the space (Gelman and Rubin, 1992; Gelman,
1996). Single long runs may be adequate for straightforward problems, or
as a preliminary to obtain inputs to multiple chains. Convergence for
multiple chains may be assessed using Gelman–Rubin scale reduction
factors that compare variation in the sampled parameter values within and
between chains. Parameter samples from poorly identiﬁed models will
show wide divergence in the sample paths between different chains and
the variability of sampled parameter values between chains will con-
siderably exceed the variability within any one chain. To measure
variability of samples ðtÞ
j
within the jth chain ðj ¼ 1; . . . ; JÞ deﬁne
Vj ¼
X
sþT
t¼sþ1
ððtÞ
j
 jÞ2=ðT  1Þ
over T iterations after an initial burn-in of s iterations. Ideally the burn-in
period is a short initial set of samples where the effect of the initial
parameter values tails off; during the burn-in the parameter trace plots
will show clear monotonic trends as they reach the region of the posterior.
Convergence is therefore assessed from iterations s þ 1 to s þ T.
Variability within chains VW is then the average of the Vj. Between-
chain variance is measured by
VB ¼
T
J  1
X
J
j¼1
ðj  Þ2
where  is the average of the j. The scale reduction factor (SRF)
compares a pooled estimator of VarðÞ, given by VP ¼ VB=T þ
TVW=ðT  1Þ, with the within-sample estimate VW. Speciﬁcally the
SRF is ðVP=VWÞ0:5 with values under 1.2 indicating convergence.
Parameter samples obtained by MCMC methods are correlated, which
means extra samples are needed to convey the same information.
10
PRINCIPLES OF BAYESIAN INFERENCE

Additionally, as in any iterative estimation, there may be a delay in
seeking the region of the posterior density where the modal value is
located. The extent of correlation, and the convergence towards the modal
region, will depend on a number of factors including the form of
parameterization, the sample size, the complexity of the model and the
form of sampling (e.g. block or univariate sampling of parameters).
A more recently proposed convergence statistic is that due to Brooks
and Gelman (1998) and known as the Brooks–Gelman–Rubin (BGR)
statistic. This is a ratio of parameter interval lengths, where for chain j the
length of the 100ð1  Þ% interval for parameter  is obtained, i.e. the
gap between 0.5 and ð1  0:5Þ points from T simulated values. This
provides J within-chain interval lengths, with mean IU. For the pooled
output of TJ samples, the same 100ð1  Þ% interval IP is also obtained.
Then the ratio IP=IU should converge to one if there is convergent mixing
over different chains.
Analysis of sequences of samples from an MCMC chain amounts to an
application of time series methods, in regard to problems such as
assessing stationarity in an autocorrelated sequence. Autocorrelation at
lags 1, 2 and so on may be assessed from the full set of sampled values
ðtÞ, ðtþ1Þ, ðtþ2Þ; . . . , or from subsamples K steps apart, ðtÞ, ðtþKÞ,
ðtþ2KÞ; . . . , etc. If the chains are mixing satisfactorily then the auto-
correlations in the one-step apart iterates ðtÞ will fade to zero as the lag
increases (e.g. at lag 10 or 20). Non-vanishing autocorrelations at high
lags mean that less information about the posterior distribution is
provided by each iterate and a higher sample size T is necessary to
cover the parameter space. Slow convergence will show in trace plots that
wander, and that exhibit short-term trends rather than ﬂuctuating rapidly
around a stable mean.
Problems of convergence in MCMC sampling may reﬂect problems in
model identiﬁability due to overﬁtting or redundant parameters. Running
multiple chains often assists in diagnosing poor identiﬁability of models.
This is illustrated most clearly when identiﬁability constraints are missing
from a model, such as in discrete mixture models that are subject to ‘label
switching’ during MCMC updating (Fru¨hwirth-Schnatter, 2001). One
chain may have a different ‘label’ to others so that obtaining a G–R
statistic for some parameters is not sensible. Choice of diffuse priors
tends to increase the chance of poorly identiﬁed models, especially in
complex hierarchical models or small samples (Gelfand and Sahu, 1999).
Elicitation of more informative priors or application of parameter con-
straints may assist identiﬁcation and convergence. Correlation between
parameters within the parameter set  ¼ ð1; 2; . . . ; dÞ tends to delay
MCMC CONVERGENCE
11

convergence and increase the dependence between successive iterations.
Reparameterisation to reduce correlation – such as centring predictor
variables in regression – usually improves convergence (Gelfand et al.,
1995; Zuur et al., 2002).
1.6
COMPETING MODELS
Generally there are several possible competing models for the data,
differing in likelihood or prior speciﬁcations. It is necessary either to
choose between them, or to have some way of averaging inferences over
them in terms of their relative probability or likelihood. From the
conditional probability rule one can obtain posterior model probabilities.
Let Mj be one among several possible alternative models fM1; . . . ; MJÞ.
Then with B ¼ y and A ¼ Mj, we have that
pðMjjyÞ ¼ pðyjMjÞpðMjÞ=pðyÞ
where the denominator is equivalent to P
k pðyjMkÞpðMkÞ. The formal
Bayes model choice is based on posterior model probabilities pðMjjyÞ and
associated quantities, such as the Bayes factor Bjk ¼ pðyjMjÞ=pðyjMkÞ
comparing models j and k. This and other methods for comparing and
checking models are considered in Chapter 2.
1.7
SETTING PRIORS
Priors may be chosen to encapsulate existing knowledge (e.g. based on
results or parameter estimates from historical data) or to impart relatively
little information in relation to that provided by the data. In the latter
category are ‘reference priors’ that are constructed automatically without
needing to choose tuning parameters. The latter are also sometimes
known as objective priors (e.g. Casella and Moreno, 2002), whereas
priors based to some degree on existing knowledge are known as
subjective or elicited priors (Garthwaite et al., 2004). While objective
priors have the beneﬁt of being ‘off the shelf’ and of ‘letting the data
speak for themselves’, they may also create problems in sampling-based
estimation. Improper priors, for example, may lead to an improper joint
posterior distribution even when all the full conditional posteriors are
proper (Casella and George, 1992; Hobert and Casella, 1996).
In practice other principles may guide prior speciﬁcation: for example,
formal model choice (section 1.6 and Chapter 2) may be adversely
affected by using diffuse or just proper priors. Complex models for
12
PRINCIPLES OF BAYESIAN INFERENCE

relatively small samples may require relatively informative priors in order
to be identiﬁable from the data. Conjugate priors in which the posterior
has the same form as the prior have advantages in tractability, and also in
interpretation, since the prior can be interpreted in terms of a prior sample
size or as pseudo data.
In many applications involving small or modest sample sizes posterior
inferences about parameters or functionals of parameters may be affected
by the prior used. Formal model choice via the Bayes factor may remain
sensitive to prior speciﬁcation for all sample sizes. In fact, the Bayes
factor B21 for model 2 vs. model 1 (where model 2 is more parameter-
ized) tends to zero as the sample size n increases. Also when model 2
contains an additional parameter and the diffuseness of the prior on that
parameter is increased, B21 tends to zero (Bartlett, 1957; Lindley, 1957).
On the other hand, problems with Bayes factor stability may be
overstated. Although the Bayes factor may change with a change in the
prior, it is pertinent to ask whether the ranking of the leading models
changes when the prior is changed in reasonable ways. Possible alter-
natives to the formal Bayes factor include Bayes factors using minimal
training samples from y ¼ ðy1; . . . ; ynÞ to provide proper priors, examples
being the fractional Bayes factor (O’Hagan, 1995) and the intrinsic Bayes
factor (Berger and Pericchi, 1996a; 1996b).
A good principle for any application is to carry out a sensitivity
analysis with a variety of prior speciﬁcations. This is especially so for
parameters that are known to have sensitivity implications, e.g. the
variances in hierarchical random effects models, or where the model is
only weakly identiﬁed (e.g. see Chapter 8). A practical procedure implicit
in the WINBUGS package and with some support in the literature (e.g.
Besag et al., 1995) is the use of just proper, minimally informative priors.
However, some argue that improper or just proper priors can be avoided
by some subject matter reasoning. Thus Kadane and Lazar (2003, p 281)
state that ‘if statisticians were to think about the reality underlying the
parameter, they should always be able to describe it reasonably well using
a prior distribution’.
1.8
THE NORMAL LINEAR MODEL AND
GENERALIZED LINEAR MODELS
In this book the focus is on discrete outcome models pðyjÞ that
generalize the tools used for continuous data, e.g. regression models,
time series models and panel analysis. Such generalization usually starts
THE NORMAL LINEAR MODEL AND GENERALIZED LINEAR MODELS
13

with non-hierarchical linear regression. The mainstay of regression
modelling for continuous data is the normal linear model whereby a
response variable yi, measured for subjects i ¼ 1; . . . ; n, is related linearly
to
regressor
variables
(or
predictors)
xi1; . . . ; xip.
Assuming
that
predictors are measured without error, model discrepancies or measure-
ment errors in the yi are expressed via errors " ¼ ð"1; . . . ; "nÞ assumed
to beindependently normally distributed with a common variance 2.
Thus
yi ¼ 0 þ 1xi1 þ 2xi2 þ    þ pxip þ "i
"i  Nð0; 2Þ
Equivalently
Y ¼ X þ "
where Y is an n  1 column vector,  ¼ ð0; . . . ; pÞ0 is a ðp þ 1Þ  1
column vector of regression parameters and X is an n  ðp þ 1Þ matrix of
predictor variables including an intercept xi0 ¼ 1. Letting 
i ¼ 0þ
1xi1 þ 2xi2 þ . . . þ pxip ¼ Xi, where Xi is the ith row of X, the
normal linear model may also be written in the form
yi  Nð
i; 2Þ
However, for discrete responses (e.g. binary or count data) the
distribution of yi will not usually be normal. Also, to ensure that
predictions ^yi are of the same form as yi itself (e.g. if yi is binary it is
necessary that ^yi be between 0 and 1), the mean i of the dependent
variable may need to be a transformation of the linear predictor 
i rather
than equalling it. In the class of generalized linear models (Nelder and
Wedderburn, 1972), yi may follow one of a wide set of distributions
within the linear exponential family instead of being assumed normal.
Thus
yi  pðyiji; Þ
lði; jyÞ ¼ log½pðyiji;  ¼ ½yii  bðiÞ=aiðÞ þ cðyi; Þ
ð1:7Þ
where a, b and c are known functions that deﬁne the particular distribu-
tion, i ¼ hð
iÞ ¼ hðXiÞ are unknown location parameters, and the scale
parameter  and hence aiðÞ may be known or unknown. Canonical
14
PRINCIPLES OF BAYESIAN INFERENCE

models are where i ¼ 
i. By using the relations Eð@l=@Þ ¼ 0 and
Eð@2l=@2Þ þ Eð@l=@Þ2 ¼ 0, one may show that EðyiÞ ¼ b0ðiÞ and
VarðyiÞ ¼ aiðÞb00ðiÞ.
To ensure predictions of the right form, a transform or link function
gðiÞ is usually needed to link the mean i ¼ EðyiÞ to the regression term
in the predictors Xi. So assuming a linear regression term, one obtains
gðiÞ ¼ Xi ¼ 
i
with the inverse link being
i ¼ g1ðXiÞ ¼ g1ð
iÞ
Different types of link may be used for any particular distribution (e.g. for
the binomial distribution, commonly used links are the logit, probit or
extreme value). The normal linear model with an identity link is in fact a
special case of the linear exponential family, in which i ¼ i ¼ Xi,
and the relevant functions are aiðÞ ¼ 2, bðiÞ ¼ 2
i =2, cðyi; Þ ¼
0:5½y2
i =2 þ logð22Þ.
The Poisson with log link between 
i and i
leads to i ¼
logðiÞ ¼ Xi,
with
relevant
functions
being
aiðÞ ¼ 1,
bðiÞ ¼
expðiÞ, cðyi; Þ ¼  log yi!. Thus
yi  PoðyijiÞ
where
PoðyijÞ ¼ exp½yi logðiÞ  i  log yi!
The variance ¼ mean relation of the Poisson is obtained by differentiating
bðiÞ. For the binomial with mean i and ni subjects at risk in the ith
group or trial the likelihood may be written as
ni
yi


½i=ð1  iÞyið1  iÞni
This
is
obtained
from
the
exponential
family
with
i ¼ Xi ¼
log½i=ð1  iÞ, aiðÞ ¼ 1, bðiÞ ¼ ni log½1 þ exp ðiÞ, and
cðyi; Þ ¼ log
ni
yi


Thus the logit function is the canonical link between i and 
i ¼ i.
Random variation in subject means (i in the Poisson, i in the
binomial) may be introduced. If modelled in the regression link, this
might take the form
gðiÞ ¼ Xi þ i
THE NORMAL LINEAR MODEL AND GENERALIZED LINEAR MODELS
15

where i might be normal, or a mixture of normals. Alternatively
conjugate mixing may be considered, as when Poisson means i are
assumed to be gamma distributed over subjects, and when binomial
probabilities are taken to be beta distributed (Nelder and Lee, 2000). The
motivations for such extensions often lie in heterogeneity greater than
expected under the standard exponential family models or to obtain
improved estimates of varying means for subjects that allow ‘pooling of
strength’.
Random
variation
between
subjects
may
be
unstructured
and
exchangeable (the features of the density are unaffected by permutation
of the subject identiﬁers). However, structured variation is likely for
observations arranged in space or time (e.g. spatially correlated variation
if the observation units are areas). Consider the mixed model in spatial
epidemiology (Besag et al., 1991) for Poisson distributed event totals yi
with means i ¼ iEi, where Ei are expected events and i are relative
disease risks (see Chapter 8). Then
logðiÞ ¼ Xi þ i1 þ i2
ð1:8Þ
where i1 and i2 are white–noise and spatial errors respectively.2 The
impact of unstructured random effects i1 is to pool strength over all
areas towards the overall mean. With structured errors, the conﬁguration
of areas affects the nature of the pooling of strength: smoothing is
towards local rather than global averages.
Classical ML analysis of models following particular forms of the
exponential family density (1.7) involves Newton–Raphson iteration or
iteratively reweighted least squares, and usually relies on asymptotic
normality to provide parameter densities or hypothesis tests. However,
the asymptotic approximations may not hold for small or moderate
sample sizes or for non-linear models (e.g. see Zellner and Rossi,
1984). Inferences based on asymptotic normality of the ML parameters
can be affected, perhaps distorted, by choice of parameterization, by
sample size, by the form of regression (non-linear vs. linear) and so on.
An illustration by Pastor-Barriuso et al. (2003) is for a logit model
subject to a change point in the impact of regressors. Bayesian analysis of
discrete data follows the generalized linear model (GLM) structure but is
not constrained to asymptotic normality to obtain posterior inferences.
2Ei denotes the expected deaths, taking account of the size of the population exposed to risk and its
age structure but assuming a standard death rate schedule (e.g. national death rates).
16
PRINCIPLES OF BAYESIAN INFERENCE

Other distributions for discrete data not encompassed by (1.7) may
sometimes be obtained as a special form of GLM providing certain
parameters are ﬁxed. Thus the negative binomial with dispersion
parameter 1=r is often appropriate when count data are overdispersed.
This has form
yi  NBði; rÞ
NBði; rÞ ¼
ðyi þ rÞ
ðrÞðyi þ 1Þ
r
i þ r

r
yi
i þ r

yi
EðyiÞ ¼ i ¼ expðXiÞ
VarðyiÞ ¼ i þ 2
i =r
If r is ﬁxed, then the negative binomial can be expressed in the linear
exponential form (see McCullagh and Nelder, 1989, chapter 11).
The GLM framework also extends to cases where subjects are clustered
(e.g. in ﬁrms, schools) or are measured repeatedly, sometimes known as
general
linear
mixed
models
(GLMMs).
For
clustered
data,
let
i ¼ 1; . . . ; I denote the level 1 units (clusters) and j ¼ 1; . . . ; Ji denote
the level 1 units (observations) nested within each cluster. Then random
effects may be deﬁned at both cluster and observation level. Let Wij be a
predictor of dimension r and ij be a vector random effect at observation
level, so that for yij Poisson or binomial with means 	ij and link g
gð	ijÞ ¼ Xij þ Ziji þ Wijij
Bayesian analysis of clustered GLMMs is exempliﬁed by applications in
longitudinal data (Chib and Carlin, 1999) and health services research
(Normand et al., 1997; Daniels and Gatsonis, 1999).
1.9
DATA AUGMENTATION
Data augmentation via latent or auxiliary variables is a strategy used to
convert the likelihood to a form (such as the normal linear regression) for
which simple Gibbs sampling can be used. For example, data augmenta-
tion is used to ensure conjugacy of prior and likelihood such that the
posterior takes a standard form (Damien et al., 1999; van Dyk and Meng,
2001; van Dyk, 2002). It is used to simplify sampling in discrete mixture
models (Chapter 5), and also forms the basis for missing-data models
(Chapter 11). Bayesian developments in factor analysis and item response
DATA AUGMENTATION
17

analysis can also be cast in terms of augmented data for the factor scores
(Aitkin and Aitkin, 2005).
Consider for example a binary regression for responses yi ¼ 1 or 0 with
logit link to regressors xi. Suppose a mixture of regression components is
proposed (e.g. distinct regression models for a small number of
subpopulations, j ¼ 1; . . . ; J as in market segmentation studies), with
prior probabilities j that subject i belongs to a group j. In practice the
group indicators Di 2 ð1; . . . ; JÞ are unknown but are considered as
augmented data to be sampled at each iteration in an MCMC chain. So
conditional on Di
yijDi ¼ j  BernðijÞ
gðijÞ ¼ xij
where g is typically the probit or logit link. Given a set of sampled
D ¼ ðD1; . . . ; DnÞ the likelihood in yi has the form
Lij ¼ yi
ijð1  ijÞð1yiÞ
and the total likelihood is
Y
n
i¼1
X
J
j¼1
jLij
The full conditionals for binary and count regression in such situations
have been presented by several authors (e.g. Robert, 1996) but are not
necessarily of standard form; this necessitates the M–H algorithm or
adaptive rejection sampling for the regression parameters j.
Instead a further augmentation produces Gibbs sampling throughout
and also provides continuous quantities Wi with substantive relevance
(e.g. consumer utilities). These are the unobserved responses in a linear
regression
Wi ¼ xij þ ui
ð1:9Þ
with ui  Nð0; 2Þ. For equivalence to a probit link, such augmentation is
unproblematic. The Wi are generated by truncated sampling according to
whether yi ¼ 1 or 0 as
WijDi ¼ j;
j  Nðxij; 2ÞIð0; Þ
yi ¼ 1
WijDi ¼ j;
j  Nðxij; 2ÞIð ; 0Þ
yi ¼ 0
18
PRINCIPLES OF BAYESIAN INFERENCE

The form of the information provided by y does not allow all the
regression parameters for the metric model to be identiﬁed unless the
variance 2 is ﬁxed, typically 2 ¼ 1.
A logit link is consistent with a heavier tail density for the underlying
Wi, and here augmentation relies on the close approximation to a logit
link by a Student t density. Speciﬁcally the Wi are taken to be Student t
with eight degrees of freedom (Albert and Chib, 1993) and scale
2 ¼ 2:49. In terms of the linear regression (1.9), the ui are now Student
t errors, and following Andrews and Mallows (1974), the Student t with 	
degrees of freedom is obtainable by mixing the scale in a normal density,
i.e. ui  Nð0; 2=iÞ, with i  Ga(0.5	, 0.5	).
The latent metric scale may be envisaged to result from an underlying
comparison of scales depending on the application (e.g. patient severity
in the medical application, consumer utility in the economic application)
with value Ui1 for subject i if the response is yes and Ui0 if the response is
no. Deﬁne Wi ¼ Ui1  Ui0; then according as yi ¼ 1 or 0 the metric scale
has values Wi 	 0 or Wi < 0. Modelling on the latent scale with W rather
than with the original (e.g. Bernoulli) likelihood will entail no loss of
information provided pðjW; YÞ ¼ pðjWÞ. One can see that this holds
for the example just cited since fWi 	 0; Wi < 0g is equivalent to
fyi ¼ 1; yi ¼ 0g. The sampling for the metric scale model will then
consist of sampling from conditional densities pðjjW; ½jÞ and pðWjY; Þ
where ½j consists of all regression model parameters apart from j. The
form of the conditional pðWjY; Þ, namely estimating proxy metric scale
data corresponding to the actual discrete data, follows from the density
assumed for u (see Chapters 4 et seq).
1.10
IDENTIFIABILITY
Devices such as data augmentation, together with other features of
MCMC sampling–based estimation, facilitate the ﬁtting of highly com-
plex models. However, highly parameterized models raise questions
about practical identiﬁcation of the model’s assumed structure with the
data at hand, for instance in hierarchical random effects models (e.g.
Gelfand and Sahu, 1999; Vines et al., 1996), and in speciﬁc applications
in phylogeny (Rannala, 2002) and factor analysis (Fokoue, 2004).
Model identiﬁability has several possible meanings: it may relate to the
ability to estimate the entirety of the parameters postulated by the model.
It may also relate to the fact that several distinct models have closely
similar ﬁts to the same data; or it may relate to certain parameters in a
IDENTIFIABILITY
19

model that cannot be effectively updated by the data. Among relevant
factors are the size of sample, the complexity of the model, and the level
of information provided by the prior. Also relevant is the type of model:
for example, the parameters of non-linear regressions and random effects
models are more subject to identiﬁcation problems than those of linear
regression.
The ﬁrst sort of situation occurs in multiple random effects models
where the level of several random effects is confounded with the
intercept. In a model with a single random effect as in two–way analysis
of variance, one might combine the random effect and the intercept, so
that
yij ¼  þ i þ eij
where the i have prior mean zero, is replaced by
yij ¼ i þ eij
where i have mean . Another possibility is a centring operation at each
MCMC iteration, or a constraint such as 1 ¼ 0 or 1 ¼ 2. Identiﬁa-
bility is compromised by random effects priors that do not specify an
average level (e.g. i  Nð0; Þ) but instead how successive values are
related, e.g. in a ﬁrst-order random walk with i  Nði1; Þ. Identiﬁa-
bility is also complicated in some types of models over space or time
when there are several random effects; in spatial applications involving
the mixed model of Besag et al. (1991) the identiﬁability problems focus
on separating structured and unstructured errors since only their sum is
identiﬁed. In disease models with age and time as dimensions an
additional cohort effect may be identiﬁed and constraints on random
effects have to be imposed to ensure identiﬁcation.
Similar ﬁts from models with different substantive implications may
occur suggesting perhaps a model averaging strategy (see Hoeting, 1999;
also Chapter 2). Structural equation models provide examples when
statistical ﬁt is similar but the character of the model might differ
substantially, e.g. in one model factors are uncorrelated and in another
they are correlated, but similar ﬁts are obtained (Muthen, 2003). Formal
observational equivalence has been deﬁned by econometricians: two
models that generate identical outcomes are observationally equivalent
and data alone cannot distinguish between them (Hendry et al., 2001).
An example of the third kind occurs in the setting of higher stage priors
(which, suitably applied, has value for assessing sensitivity of inferences
to priors). For example, the inverse variance  ¼ 2 in a linear regres-
sion with errors u may be assigned a gamma prior Gað1; 2Þ and 1 and
20
PRINCIPLES OF BAYESIAN INFERENCE

2 are typically taken as known (e.g. 1 ¼ 2 ¼ 0:001). However, they
can be extra parameters, e.g. 1  ExpðÞ, 2  ExpðÞ. If  is preset
then the data may effectively update the priors on 1 and 2, but if  itself
is taken as unknown3 the data are unlikely to identify 1, 2 and .
1.11
ROBUSTNESS AND SENSITIVITY
Model comparison is subject to sensitivity when inferences about para-
meters  are affected by choice of sampling model or choice of prior
(Geweke, 1998), and especially when standard assumptions (e.g. normal-
ity of errors, unimodal densities) are questionable. Model elaborations
better to reﬂect data features may involve robust alternatives in the prior
or in the likelihood components of a model, or in both (Weiss et al., 1998;
Carlin, 1992).
If alternative models have close ﬁt but differ in their implications then
one strategy is model averaging rather than trying to choose one model as
best (Chapter 2). Another strategy is to recognize that inferences are not
certain and report the results of a sensitivity analysis using perturbations
in likelihood or prior assumptions. Non-parametric classes of prior that
may provide greater robustness in the face of prior uncertainty have been
suggested, such as density ratio priors (DeRobertis and Hartigan, 1981),
Dirichlet process priors (Ferguson, 1973; Dey et al., 1998), and
"-contamination classes (Berger, 1994) where
pðÞ ¼ ð1  "ÞpbðÞ þ "
 2 Z
where pbðÞ is the base prior, " is the postulated error in the base prior,
and Z is the class of contaminations considered.
3Consider a Poisson regression where the error u represents overdispersion in relation to the Poisson
assumption that variance ¼ mean. To illustrate, 100 points were generated from a model
yi  PoðiÞ
logðiÞ ¼ 2 þ xi þ ui
xi  Uð1; 1Þ
ui  Nð0; 2Þ
(see Program 1.1 Simulated Overdispersed Poisson). The ﬁrst prior on  ¼ 1=VarðuÞ using preset
parameters ð1 ¼ 1; 2 ¼ 0:001Þ produces a posterior mean (standard deviation),  ¼ 0:56ð0:10Þ.
Taking 1  EðÞ, 2  EðÞ with  ¼ 1 also gives a well-identiﬁed model with  ¼ 0:54ð0:10Þ,
1 ¼ 0:97ð0:69Þ, 2 ¼ 1:29ð1:00Þ. However, taking  as additional unknown with an E(1) prior leads
to poorly identiﬁed 1 and 2, with inﬂated standard deviations.
ROBUSTNESS AND SENSITIVITY
21

Inference sensitivity tends to be related to factors such as sample size
or features of the data: inferences for small samples or samples with
multiple modes or unusual cases are more sensitive to changes in prior
settings. Hence diagnostics for outliers and other checks comparing
model predictions to the data (see Chapter 2 on posterior predictive
checks) are important in assessing robustness. Often a heavier tailed
sampling density pðyjÞ or heavier tailed priors pðÞ such as t	 (	 under
ﬁve) for means or regression coefﬁcients instead of normal priors reduce
the impact of outliers (Angers, 1992). A univariate or multivariate
Student t density instead of a normal sampling model pðyjÞ provides
outlier weights if the scale mixture version of the t density is used (West,
1984); this of course adds to the parameter count of the model. Other
generalizations of standard densities allow for skewness (Branco and
Dey, 2001; Azzalini and Capitanio, 1999). Discrete mixture models also
provide great ﬂexibility in modelling unusual densities or clusters of
unusual cases (Roberts, 1996). Overdispersed alternatives to standard
discrete densities (e.g. negative binomial instead of Poisson) can also be
seen as robustiﬁed versions of these densities (Gelman et al., 2003).
Sensitivity to prior assumptions also depends on the type of parameter
under consideration. For example, ﬁxed effect regression parameters are
typically less problematic than hyperparameters governing random
effects models. A further type of sensitivity is when inferences are
affected by the type of population model, whether parametric random
effects or non-parametric mixtures. The latter are often proposed as a way
of avoiding parametric assumptions (Ishwaran, 2000).
Much analysis has occurred in relation to the speciﬁcation of variances
for random effects in hierarchical models. In applications of the spatial
mixed model, non-informative gamma Ga(", ") priors (with " small such
as " ¼ 0:001) on the inverse variances compound the identiﬁability
problems inherent in separating structured and unstructured variance
components. A Ga(0.001, 0.001) prior on  ¼ 2 is incompatible with
small levels of variation and priors such as Ga(0.5,0.0005) (Wakeﬁeld
and Morris, 1999) or Ga(0.1, 0.1) (MacNab, 2003) have been suggested
instead; these priors are compatible with stronger prior belief in the
possibility of small variability.
Gelman (2005) points out problems with this form of prior in multi-
level models with repetitions j ¼ 1; . . . ; ni within clusters i ¼ 1 . . . I, e.g.
yij  Nð þ i; 2Þ
where the cluster effects i are often assumed normal with mean 0 and
variance 2
. The choice 1=2
  Gað"; "Þ with " ¼ 0:001 can be proble-
matic when I is small. Gelman instead recommends a uniform prior, e.g.
22
PRINCIPLES OF BAYESIAN INFERENCE

U(0, 100) on the standard deviation , or a half Student t prior, where 
is the absolute value of a draw from a Student t with mean 0, known scale
and small degrees of freedom (e.g. 	 ¼ 1 for a half Cauchy).
1.12
CHAPTER THEMES
In the following chapters the themes mentioned above will recur within
an overriding focus on categorical data models. Chapter 2 considers in
detail the question of model comparison, checking and choice. Increas-
ingly model averaging rather than choice is being emphasized and this is
in practice what happens in regression selection models whether for
metric data (Chapter 3), or for count and binomial data (Chapter 4).
Chapters 3, 4 and 5 also consider issues such as robust alternatives to the
standard densities such as the Poisson and binomial, e.g. non-parametric
regression modelling from a Bayesian perspective, the modelling of
overdispersion and the accommodation of outliers or population sub-
groups. Chapter 6 considers multinomial data generalizations of common
links such as the multinomial logit and probit models, while Chapter 7
concerns ordinal data models. Chapter 8 considers a particular form of
discrete data analysis, namely spatial data modelling, where issues of
both robustness and parameter identiﬁcation ﬁgure large. Chapters 9 and
10 consider respectively time series analysis for categorical data and
clustered data (multilevel and panel models). With clustered data,
correlation over time periods or within clusters becomes an issue.
Chapter 11 considers possible models for missing categorical data from
a Bayesian perspective.
REFERENCES
Aitkin, M. and Aitkin, I. (2005) Bayesian inference for factor scores. In Con-
temporary Advances in Psychometrics. Erlbaum (in press).
Albert, J. and Chib, S. (1993) Bayesian analysis of binary and polychotomous
response data. Journal of the American Statistical Association, 88, 669–679.
Andrews, D. and Mallows, C. (1974) Scale mixtures of normal distributions.
Journal of the Royal Statistical. Society, Series B, 36, 99–102.
Angers, J.-F. (1992) Use of Student-t prior for the estimation of normal means: a
computational approach. In Bayesian Statistics 4, Bernardo, J., Berger, J.,
Dawid, A. and Smith, A. (eds). Clarendon Press: Oxford, 567–575.
Azzalini, A. and Capitanio, A. (1999) Statistical applications of the multivariate
skew-normal distribution. Journal of the Royal Statistical Society, Series B, 61,
579–602.
REFERENCES
23

Bartlett, M. (1957) A comment on D. V. Lindley’s statistical paradox. Biometrika,
44, 533–534.
Berger, J. (1994) An overview of robust Bayesian analysis. Test, 3, 5–
124.
Berger, J. and Pericchi, L. (1996a) The intrinsic Bayes factor for model
selection and prediction. Journal of the American Statistical Association,
91, 109–122.
Berger, J. and Pericchi, L. (1996b) The intrinsic Bayes factor for linear models. In
Bayesian Statistics 5, Bernardo, J., Berger, J., Dawid, A. and Smith, A. (eds.).
Clarendon Press: Oxford, 23–42.
Bernardo, J. and Smith, A. (1994) Bayesian Theory. Chichester John Wiley & Sons.
Besag, J. York, J. and Mollie´, A. (1991) Bayesian image restoration with two
applications in spatial statistics. Annals of the Institute of Statistics and
Mathematics, 43, 1–59.
Besag, J., Green, P., Higdon, D. and Mengersen, K. (1995) Bayesian computation
and stochastic systems. Statistical Science, 10, 3–66.
Branco, M. and Dey, D. (2001) A general class of multivariate skew-elliptical
distributions. Journal of Multivariate Analysis, 79, 99–113.
Brooks, S. and Gelman, A. (1998) Alternative methods for monitoring conver-
gence of iterative simulations. Journal of Computational and Graphical
Statistics, 7, 434–455.
Carlin, B. (1992) State space modeling of non-standard actuarial time series.
Insurance Mathematics and Economics, 11, 209–222.
Casella, G. and George, E. (1992) Explaining the Gibbs sampler. American
Statistician, 46, 167–174.
Casella, G. and Moreno, E. (2002) Objective Bayesian variable selection. Dept. of
Statistics, University of Florida.
Chib, S. and Carlin, B. (1999) On MCMC sampling in hierarchical longitudinal
models. Statistics and Computing, 9, 17–26.
Chib S. and Greenberg, E. (1995) Understanding the Metropolis-Hastings algo-
rithm. American Statistician, 49, 327–335.
Cowles, M. and Carlin, B. (1996) Markov Chain Monte Carlo convergence
diagnostics: a comparative review. Journal of the American Statistical Asso-
ciation, 91, 883–904.
Damien, P., Wakeﬁeld, J. and Walker, S. (1999) Gibbs sampling for Bayesian
non-conjugate and hierarchical models by using auxiliary variables. Journal
of the Royal Statistical Society, Series B, 61, 331–344.
Daniels, M. and Gatsonis, C. (1999) Hierarchical generalized linear models in the
analysis of variations in health care utilization. Journal of the American
Statistical Association, 94, 29–42.
DeRobertis, L. and Hartigan, J. (1981) Bayesian inference using intervals of
measures. Annals of Statistics, 9, 235–244.
Dey, D., Muller, P. and Sinha, D. (eds) (1998) Practical Nonparametric and
Semiparametric Bayesian Statistics. Springer: New York.
24
PRINCIPLES OF BAYESIAN INFERENCE

Ferguson, T. (1973) A Bayesian analysis of some nonparametric problems.
Annals of Statistics, 1, 209–230.
Fokoue, E. (2004) Stochastic determination of the intrinsic structure in Bayesian
factor analysis. Technical Report #2004-17, Statistical and Applied Mathe-
matical Sciences Institute.
Fru¨hwirth-Schnatter, S. (2001) MCMC estimation of classical and dynamic
switching and mixture models. Journal of the American Statistical Associa-
tion, 96, 194–209.
Garthwaite, P., Kadane, J. and O’Hagan, A. (2004) Elicitation. Journal of the
American Statistical Association, to appear.
Gelfand, A. (1996) Model determination using sampling-based methods. In
Markov Chain Monte Carlo in Practice, Gilks, W., Richardson, S. and
Spiegelhalter, D. (eds). Chapman and Hall: London, 145–162.
Gelfand, A. and Sahu, S. (1999) Identiﬁability, improper priors, and Gibbs
sampling for generalized linear models. Journal of the American Statistical
Association, 94, 247–253.
Gelfand, A. and Smith, A. (1990) Sampling-based approaches to calculating
marginal densities. Journal of the American Statistical Association, 85, 398–409.
Gelfand, A., Sahu, S. and Carlin, B. (1995) Efﬁcient parameterization for normal
linear mixed models. Biometrika, 82, 479–488.
Gelman, A. (1996) Inference and monitoring convergence. In Markov Chain
Monte Carlo in Practice, Gilks, W., Richardson, S. and Spiegelhalter, D. (eds).
Chapman and Hall: London, 131–143.
Gelman, A. (2005) Analysis of variance: why it is more important than ever (with
discussion). Annals of Statistics, to appear.
Gelman, A. and Rubin, D. (1992) Inference from iterative simulation using
multiple sequences. Statistical Science, 7, 457–511.
Gelman, A., Roberts, G. and Gilks, W. (1996) Efﬁcient Metropolis jumping rules.
In Bayesian Statistics 5, Bernardo, J., Berger, J., Dawid, A. and Smith, A. (eds).
Oxford University Press: Oxford, 599–607.
Gelman, A., Carlin, J., Stern, H. and Rubin, D. (2003) Bayesian Data Analysis,
2nd Edition. Boca Raton, FL: CRC Press.
Geman, S. and Geman, D. (1984) Stochastic relaxation, Gibbs distributions, and
the Bayesian restoration of images. Transactions on Pattern Analysis and
Machine Intelligence, 6, 721–741.
George, E., Makov, U., and Smith, A. (1993) Conjugate likelihood distributions.
Scandinavian Journal of Statistics, 20, 147–156.
Geweke, J. (1989) Bayesian inference in econometrics models using Monte Carlo
integration. Econometrica, 57, 1317–1340.
Geweke, J. (1998) Simulation methods for model criticism and robustness analysis.
In Bayesian Statistics 6, Bernardo, J. (ed.). Oxford University Press: Oxford.
Gilks, W. (1996) Full conditional distributions. In Markov Chain Monte Carlo in
Practice, Gilks, W., Richardson, S. and Spiegelhalter, D. (eds). Chapman and
Hall: London, 75–88.
REFERENCES
25

Gilks, W. and Wild, P. (1992) Adaptive rejection sampling for Gibbs sampling.
Applied Statistics, 41, 337–348.
Gilks, W., Richardson, S. and Spiegelhalter, D. (eds) (1996a) Markov Chain
Monte Carlo in Practice. Chapman and Hall: London.
Gilks, W., Richardson, S. and Spiegelhalter, D. (1996b) Introducing Markov
chain Monte Carlo. In Markov Chain Monte Carlo in Practice, Gilks, W.,
Richardson, S. and Spiegelhalter, D. (eds). Chapman and Hall: London, 1–20.
Hastings, W. (1970) Monte Carlo sampling methods using Markov chains and
their applications. Biometrika, 57, 97–109.
Hendry, D., Lu, M. and Mizon, G. (2001) Model identiﬁcation and non-unique
structure. Nufﬁeld College, Oxford Working Paper Series 2002-W10.
Hobert, J. and Casella, G. (1996) The effect of improper priors on Gibbs sampling
in hierarchical linear mixed models. Journal of the American Statistical
Association, 91, 1461–1473.
Hoeting, J., Madigan, D., Raftery, A. and Volinsky, C. (1999) Bayesian model
averaging: a tutorial. Statistical Science, 14, 382–401.
Ishwaran, H. (2000) Inference for the random effects in Bayesian generalized
linear mixed models. ASA Proceedings of the Bayesian Statistical Science
Section, 1–10.
Kadane, J. and Lazar, N. (2003) Methods and criteria for model selection. Journal
of the American Statistical Association, 99, 279–290.
Kass, R., Tierney, L. and Kadane, J. (1988) Asymptotics in Bayesian computa-
tion. In Bayesian Statistics 3, Bernardo, J., DeGroot, M., Lindley, D. and
Smith, A. (eds). Oxford University Press: Oxford, 261–278.
Lindley, D. (1957) A statistical paradox. Biometrika, 44, 187–192.
MacNab, Y. (2003) Hierarchical Bayesian modeling of spatially correlated health
service outcome and utilization rates. Biometrics, 59, 305–316.
McCullagh, P. and Nelder, J. (1989) Generalized Linear Models, 2nd Edition.
Chapman and Hall: London.
McFadden, D. (1989) A method of simulated moments for estimation of discrete
response models without numerical integration. Econometrica, 7, 995–1026.
Metropolis, N., Rosenbluth, A., Rosenbluth, M., Teller, A. and Teller, E. (1953)
Equations of state calculations by fast computing machines. Journal of
Chemical Physics, 21, 1087–1092.
Muthen, B. (2003) Statistical and substantive checking in growth mixture
modeling. Psychological Methods, 8, 369–377.
Nelder, J. and Lee, Y. (2000) Two ways of modelling overdispersion in non-
normal data. Applied Statistics, 49, 591–598.
Nelder, J. and Wedderburn, R. (1972) Generalized linear models. Journal of the
Royal Statistical Society, Series A, 135, 370–384.
Normand, S., Glickman, M. and Gatsonis, C. (1997) Statistical methods for
proﬁling providers of medical care: issues and applications. Journal of the
American Statistical Association, 92, 803–814.
Norris, J. (1997) Markov Chains. Cambridge University Press: Cambridge.
26
PRINCIPLES OF BAYESIAN INFERENCE

O’Hagan, A. (1995) Fractional Bayes factors for model comparison. Journal of
the Royal Statistical Society, 57B, 99–138.
Pastor-Barriuso, R., Guallar, E. and Coresh, J. (2003) Transition models for
change-point estimation in logistic regression. Statistics in Medicine, 22,
1141–1162.
Rannala, B. (2002) Identiﬁability of parameters in MCMC Bayesian inference of
phylogeny. Systematic Biology, 51, 754–760.
Robert, C. (1996) Mixtures of distributions: inference and estimation. In Markov
Chain Monte Carlo in Practice, Gilks, W., Richardson, S. and Spiegelhalter, D.
(eds). Chapman and Hall: London, 441–464.
Roberts, C. (1996) Markov chain concepts related to sampling algorithms. In
Markov Chain Monte Carlo in Practice, Gilks, W., Richardson, S. and
Spiegelhalter, D, (eds). Chapman and Hall: London, 45–59.
Smith, A. and Roberts, G. (1993) Bayesian computation via the Gibbs sampler
and related Markov chain Monte Carlo methods. Journal of the Royal
Statistical Society, Series B, 55, 3–23.
Tanner, M. and Wong, W. (1987) The calculation of posterior distributions by data
augmentation (with discussion). Journal of the American Statistical Associa-
tion, 82, 528–550.
Tierney, L. (1994) Markov chains for exploring posterior distributions. Annals of
Statistics, 22, 1701–1762.
Tierney, L. (1996) Introduction to general state-space Markov chain theory. In
Markov Chain Monte Carlo in Practice, Gilks, W., Richardson, S. and
Spiegelhalter, D. (eds). Chapman and Hall: London, 59–74.
van Dyk, D. (2002) Hierarchical models, data augmentation, and MCMC. In
Statistical Challenges in Modern Astronomy III, Babu, G. and Feigelson, E.
(eds). Springer: New York, 41–56.
van Dyk, D. and Meng, X. (2001) The art of data augmentation. Journal of
Computational and Graphical Statistics, 10, 1–111.
Vines, S., Gilks, W. and Wild, P. (1996) Fitting Bayesian multiple random effects
models. Statistics and Computing, 6, 337–346.
Wakeﬁeld, J. and Morris, S. (1999) Spatial dependence and error-in-variables in
environmental epidemiology. In Bayesian Statistics 6, Bernardo, J., Berger, J.,
Dawid A. and Smith A. (eds). Clarendon Press: Oxford, 657–684.
Weiss, R., Cho, M. and Yanuzzi, M. (1998) On Bayesian calculations for mixture
likelihoods and priors. Dept. of Biostatistics, UCLA School of Public Health.
West, M. (1984) Outlier models and prior distributions in Bayesian linear
regression. Journal of the Royal Statistical Society, Series B, 46, 431–439.
Zellner, A. and Rossi, P. (1984) Bayesian analysis of dichotomous quantal
response models. Journal of Econometrics, 25, 365–393.
Zuur, G., Garthwaite, P., and Fryer, R. (2002) Practical use of MCMC methods:
lessons from a case study. Biometrical Journal, 44, 433–455.
REFERENCES
27


CHAPTER 2
Model Comparison
and Choice
2.1
INTRODUCTION: FORMAL METHODS, PREDICTIVE
METHODS AND PENALIZED DEVIANCE CRITERIA
A range of methods have been proposed for model choice and diagnosis
based on Bayesian principles. For instance, among the questions that
regression model choice might include are choice between subsets of
regressor variables, whether response and regressor variables should be
transformed, and whether a linear sum of regression effects should be used
or various non-linear forms including general additive models (Chapters 3
and 4). The error structure, or more generally the speciﬁcations of pos-
sibly multiple random effects (e.g. see Chapters 6 and 10), is an additional
question. One may wish to assess the gains from adopting heavy-tailed
densities instead of the default normal errors assumption of multiple
linear regression (West, 1984), or whether to adopt error forms adapted to
the possibility of a small number of outlier points (Vernardinelli and
Wasserman, 1991).
For models j ¼ 1; . . . ; J, let m be a multinomial model indicator, and j
be the parameters under each model. Then formal Bayesian model
assessment (sections 2.2–2.3) is based on prior model probabilities
P(m ¼ j) and posterior model probabilities P(m ¼ jjY) after observing
data. Instead of choosing one model as best, the goal may be to allow for
model uncertainty by model averaging (Hoeting et al., 1999). Problems
with the formal choice method occur with diffuse or improper priors
P(jjm ¼ j); for example, if the prior is improper then so is P(Yjm ¼ j )
(Gelfand and Dey, 1994). A variety of Bayesian predictive approaches to
Bayesian Models for Categorical Data
P. Congdon
# 2005 John Wiley & Sons, Ltd

model choice and diagnosis (sections 2.4–2.5) shift the focus onto
observables away from parameters (Geisser and Eddy, 1979) and seek
to alleviate the impact of factors such as speciﬁcation of priors. In
particular, repeated sampling of replicate data Zj from each model’s
parameters provides estimates of the posterior predictive densities
PðZjjY; m ¼ jÞ ¼
ð
PðZjjY; j; m ¼ jÞPðjjY; m ¼ jÞdj
and model choice may be based on comparing such ‘predictive replicates’
with the observations (Laud and Ibrahim, 1995). Predictive methods may
also be used in a variety of model checks, with posterior predictive
checks (Gelman et al., 1995) the simplest to apply, though more
sophisticated predictive check methods have been suggested that are
less conservative.
Analogies to classical methods are illustrated by formal out-of-sample
validation methods (section 2.6); for example, this may involve leaving
some of the data out of the analysis (the ‘validation sample’) and making
predictions of the validation data from a model using only the remain-
ing data (the ‘training sample’). Similarly, Bayesian methods for estimat-
ing parametric complexity lead to penalized deviance measures similar to
those in classical methods (section 2.7). Of relevance both to formal
choice based on posterior model probabilities and to deviance penaliza-
tion are methods based on parallel sampling (sections 2.8–2.9), as
discussed by Congdon (2005a, 2005b, 2005d).
2.2
FORMAL BAYES MODEL CHOICE
Formal Bayesian model assessment is based on updating prior model
probabilities Pðm ¼ jÞ to posterior model probabilities Pðm ¼ jjYÞ after
observing the data. Thus if J models are being compared,
Pðm ¼ jjYÞ ¼ ½Pðm ¼ jÞPðYjm ¼ jÞ=
X
J
j¼1
½Pðm ¼ jÞPðYjm ¼ jÞ
ð2:1Þ
Evaluation of (2.1) involves multidimensional integration over each j,
Pðm ¼ jjYÞ ¼ Pðm ¼ jÞ
ð
PðYjjÞPðjÞ dj=
X
J
j¼1
½Pðm ¼ jÞ

ð
PðYjjÞPðjÞ dj
30
MODEL COMPARISON AND CHOICE

The marginal likelihoods in (2.1)
PðYjm ¼ jÞ ¼
ð
PðYjjÞPðjÞ dj
give the probability of the data conditional on model j and are often
difﬁcult to estimate. Approximation methods for P(Yjm ¼ j) include
those presented by Gelfand and Dey (1994), Newton and Raftery
(1994) and Chib (1995) (section 2.3). The Bayes factor is used for
comparing one model against another under the formal approach and is
the ratio of marginal likelihoods
B12 ¼ PðYjm ¼ 1Þ=PðYjm ¼ 2Þ
From (2.1) it can be seen that the Bayes factor converts the ratio of prior
model probabilities Pðm ¼ 2Þ=Pðm ¼ 1Þ to the posterior ratio of such
probabilities
Pðm ¼ 2jYÞ=Pðm ¼ 1jYÞ
Often equal prior model probabilities, namely P(m ¼ jÞ ¼ 1=J, are
assumed. However, if alternate models are being compared in an MCMC
analysis (rather than single models being estimated one at a time) one
may use the prior model probabilities to penalize more complex models.
Assuming equal prior model probabilities, the Bayes factor is used for
model choice under the formal approach. While there are no preset values
at which one model can be chosen as correct, values of log10(B12) above 2
decisively support model 1 (Jeffreys, 1961; Kass and Raftery, 1995).
Values between 0.5 and 2 provide weaker support for model 1 and values
in 0–0.5 are inconclusive. Taking loge(B12) instead, values above 3 are
conclusive in support of model 1.
Whereas data analysis is often based on selecting a single best model
and making inference as if that model were true, such an approach neg-
lects uncertainty about the model itself, as expressed in the posterior model
probabilities P(m ¼ jjY) (Hoeting et al., 1999; Draper, 1995; Wasserman,
2000). Consider a quantity (j; Y) possibly depending on both the data
and the parameters of each model j ¼ 1; . . . ; J, though it might just be a
function of the parameters. Averaging over each model’s posterior den-
sity (j; Y) on this quantity implies the model averaged estimate
E½ð; YÞ ¼
X
j
Pðm ¼ jjYÞðjjYÞ
ð2:2Þ
Assuming a single model true means that uncertainty about such quanti-
ties can be understated. Moreover, several studies have shown better pre-
dictive performance via model averaging as opposed to choosing a single
FORMAL BAYES MODEL CHOICE
31

model (Fernandez et al., 2001; Hoeting et al., 2002); formal reasons for
this are mentioned by Raftery et al. (1997).
2.3
MARGINAL LIKELIHOOD AND BAYES FACTOR
APPROXIMATIONS
The formal model choice process has a probabilistic basis, but the
evaluation of marginal likelihoods may become unstable when vague
(non-informative) priors P(j) are used on parameters. Arguably this is
not a problem with the formal model approach so much as with adopting
ﬂat priors that are not Bayesian in spirit (e.g. see the discussion in Kadane
and Lazar, 2004, p 281). Several approximations to the marginal like-
lihood and hence to the Bayes factor have been suggested. Analytic
approximations include the Laplace approximation (Tierney and Kadane,
1986). Thus using the Laplace method for integrals one can show for a
model of dimension d that
log½PðYÞ 
 0:5d logð2Þ þ 0:5 log jGj þ log½PðYjÞPðÞ
where
(a)  might be a componentwise vector of posterior means, the max-
imum likelihood estimate of , or the multivariate median (Lewis and
Raftery, 1997).
(b) P() is the set of prior densities evaluated at P(), providing what is
known as the prior ordinate.
(c) G is minus the inverse of the Hessian matrix @2hð; yÞ=ð@ @0Þ of
hð; yÞ ¼ log½PðYjÞPðÞ evaluated at . Asymptotically this equals
the posterior covariance matrix, and can be estimated by the covar-
iance between parameter samples from MCMC output, though more
robust estimators are available (Rousseeuw, 1985).
As another example of an approximation using MCMC output, consider
the relation (with the conditioning on model m omitted)
1 ¼
ð
gðÞ d ¼
ð
gðÞ PðYÞPðjYÞ
PðYjÞPðÞ d
Since P(Y) is a constant one can move it to the left hand side, so that the
marginal likelihood is given by
PðYÞ ¼
ð
gðÞ
PðYjÞPðÞ PðjYÞ d

1
ð2:3aÞ
32
MODEL COMPARISON AND CHOICE

Gelfand and Dey (1994) recommend that g be an importance density
approximation for the posterior P(jY), such as a multivariate normal,
derived as a moment estimator1 from a run of sample values of the
components of , namely ðtÞ
1 ; ðtÞ
2 ; . . . ; ðtÞ
d . Once this estimated density is
obtained the probability gðtÞ under the importance density of each
individual sampled parameter ðtÞ can be evaluated (so sampled values
far from the average of the density will have a low probability under g).
The values of gðtÞ; LðtÞ ¼ PðYjðtÞÞ, and ðtÞ ¼ PððtÞÞ, namely the impor-
tance density, likelihood and prior ordinate, are evaluated at each of the
sampled values ðtÞ. From (2.3a), the marginal likelihood is then approxi-
mated by
^PðYÞ ¼ 1= T1 X
t
gðtÞ=fLðtÞðtÞg
"
#
¼ T=
X
t
gðtÞ=fLðtÞðtÞg
"
#
ð2:3bÞ
Note that if g is taken as the prior P(), one obtains the harmonic mean of
the likelihoods as an estimator for P(Y), namely
^PðYÞ ¼ T=
X
t
f1=PðYjðtÞÞg
"
#
ð2:4Þ
Newton and Raftery (1994) propose methods of stabilizing this estimator
which will be affected by the degree of informativeness in the prior.
Another approach to derive Bayes factors from MCMC output was
developed by Chib (1995) and is based on approximating the marginal
likelihood via a restatement of (1.1). Thus consider
PðYÞ ¼ PðYjÞPðÞ=PðjYÞ
or equivalently
log½PðYÞ ¼ log½PðYjÞ þ log½PðÞ  log½PðjYÞ
at a high density point for  such as the posterior mean . The likelihood
and prior ordinate at  are usually readily obtained and the problem lies in
estimating P(jY). While approximation methods for the posterior den-
1For example, if d ¼ 2 and the samples of parameters 1 and 2 were approximately normal then a
bivariate normal density g might be estimated with mean f1; 2g given by sample averages from a
long MCMC run and covariance matrix  estimated from the sample standard deviations and
correlations.
MARGINAL LIKELIHOOD AND BAYES FACTOR APPROXIMATIONS
33

sities P(jY) might be used, such as the Gelfand–Dey approach, Chib
(1995) presents a method for estimating this ordinate in terms of a
marginal/conditional decomposition of the blocks of  used in the
MCMC estimation procedure. For example, if  ¼ ð1; 2) are the blocks
with which the MCMC sampling is conducted, the posterior ordinate is
expressed as pð1jyÞpð2jy; 1Þ. The ﬁrst ordinate in this decomposition
is estimated from the output of the full run whereas the second ordinate is
available directly. When there are the three blocks, the ﬁrst ordinate is
estimated as above, but the second ordinate, pð2jy; 1) is estimated from
the output of a subsidiary MCMC simulation with blocks 2 and 3 free
but block 1 held ﬁxed. The conditional density of the third block given
the ﬁrst two blocks is found directly. This method, which works in this
manner for any number of blocks, will be illustrated for binary responses
in Chapter 4.
Some approximation methods to formal Bayesian model choice pro-
duce posterior model probabilities or Bayes factors without seeking to
produce marginal likelihoods. For example, path sampling (Gelman and
Meng, 1998; Song and Lee, 2002) involves constructing a path to link
two models being compared. Instead of approximating the marginal
likelihood of each model the goal is to estimate the Bayes factor as a
ratio of normalizing constants. Denote the alternative models as m ¼ 0
and m ¼ 1. From the relation
PðjYÞ ¼ PðY; Þ=PðYÞ
where PðY; Þ ¼ PðYjÞP(), one may obtain for a metric variable s
PðjY; sÞ ¼ PðY; jsÞ=PðYjsÞ
ð2:5Þ
In particular, deﬁne s as a path parameter s 2 ½0; 1 linking the two
models. For example, suppose the alternative models were
Model 0 :
yi ¼  þ xi1 þ "i
ð2:6Þ
Model 1 :
yi ¼  þ wi2 þ "i
ð2:7Þ
The models m ¼ 0 and m ¼ 1 at s ¼ 0 and s ¼ 1 are linked by the models
m ¼ s (s taking values between 0 and 1) deﬁned by
Model s :
yi ¼  þ ð1  sÞxi1 þ swi2 þ "i
ð2:8Þ
Let ZðsÞ ¼ PðYjm ¼ sÞ, and in particular Zð1Þ ¼ PðYjm ¼ 1Þ and
Zð0Þ ¼ PðYjm ¼ 0Þ. Taking logarithms in (2.5) gives
log½PðjY; sÞ ¼ log½PðY; jsÞ  log½ZðsÞ
34
MODEL COMPARISON AND CHOICE

and differentiating gives
d
ds log½ZðsÞ ¼
ð
1
ZðsÞ
d
ds PðY; jsÞ d ¼ E d
ds log PðY; jsÞ


where the expectation is with respect to PðjY; sÞ. If the prior density P()
is independent of s, then
d
ds log½PðY; jsÞ ¼ d
ds log½PðYj; sÞ
Denote
Rð; sÞ ¼ d
ds log½PðYj; sÞ
Then the logarithm of the Bayes factor is obtained as
log B10 ¼ log½Zð1Þ=Zð0Þ ¼
ð1
0
Rð; uÞ du
Notionally s is continuous between 0 and 1, but to estimate the integral in
practice, deﬁne an ordered grid between 0 and 1, s0 ¼ 0; s1 < s2 <
s3 < . . . < sG < sGþ1 ¼ 1. Then by the trapezoid rule
log ^B10 ¼ 0:5
X
G
j¼0
½Rjþ1 þ Rj½sjþ1  sj
where Rj ¼ PT
t¼1 RððtÞ; sjÞ=T is an average over T iterations from an
MCMC chain of parameters (t) sampled from P(jY; sj). In the above
linear regression example
log½PðYj; sÞ ¼ 0:5½logð2Þ þ n logð2Þ
 0:5
X
n
i¼1
½yi    ð1  sÞ1xi  s2wi2=2
and
Rð; sÞ ¼ 
X
n
i¼1
½yi    ð1  sÞ1xi  s2wi½1xi  2wi=2
2.4
PREDICTIVE MODEL CHOICE AND CHECKING
Another set of model choice and diagnostic procedures is based on
adapting the classical principle of predictive cross-validation. This
approach reﬂects a belief that model choice should be based on accurate
PREDICTIVE MODEL CHOICE AND CHECKING
35

predictions within and/or beyond the sample, with Geisser and Eddy
(1979), Laud and Ibrahim (1995) and Gelfand and Ghosh (1998) being
among those providing a Bayesian basis for predictive model selection.
Thus suppose the posterior for a parameter m under model m and
observations fyi; i ¼ 1; . . . ; ng is given by
PðmjYÞ / PðmÞPðYjmÞ
In choice of predictor applications, with Xm as the predictor set in model
m, m in a normal linear regression might be a vector of regression
coefﬁcients and a conditional variance, m ¼ ðm; Þ, and in a Poisson or
binomial regression simply a vector of regression coefﬁcients. Let

im ¼ Ximm, and g be the relevant link function to model means im.
To assess the suitability of the model one may sample replicate data
Zm ¼ ðz1m; . . . ; znmÞ from the same model assumed to produce Y. These
are drawn from the posterior predictive density
PðZmjYÞ ¼
ð
PðZm; mjYÞ dm
¼
ð
PðZmjY; mÞPðmjYÞdm
¼
ð
PðZmjmÞPðmjYÞ dm
ð2:9Þ
Predictions Zm may be used both in model selection and in predictive
checks (Gelman et al., 1995). In practice, predictions Z are obtained by
repeated sampling from P ZðtÞ
m jðtÞ
m


; for example, zi  Nðim; mÞ in a
linear regression with im ¼ 
im, or zim  PoiðimÞ in a log-link Poisson
regression with log(imÞ ¼ 
im.
Bayesian model selection or diagnostics may be based on predictions
based on comparing the ‘new data’ Z with the observations. For example,
Laud and Ibrahim (1995) and Meyer and Laud (2002) propose as a basis
for model choice minimization of the criterion
Cm ¼ E½cðZm; YÞjY ¼
X
n
i¼1
fVarðzimÞ þ ½yi  EðzimÞ2g
ð2:10Þ
where cðZm; YÞ is the predictive error sum of squares under model m
cðZm; YÞ ¼ ðZm  YÞ0ðZm  YÞ
The criterion (2.10) can be obtained from the posterior means and vari-
ances of sampled zðtÞ
im or from the posterior average of Pn
i¼1ðzðtÞ
im  yiÞ2.
Meyer and Laud (2002) suggest a forward selection algorithm based on
36
MODEL COMPARISON AND CHOICE

this criterion, or more speciﬁcally its square root C0:5
m . Carlin and Louis
(1996) and Buck and Sahu (2000) propose analogous criteria appropriate
to both metric and discrete outcomes. Thus the expected predictive devi-
ance (EPD) is
Dm ¼ E½dðZm; YÞjY
ð2:11Þ
where dðZm; YÞ is the relevant deviance. For Y Poisson, for example,
dðZm; YÞ ¼ 2
X
n
i¼1
fyi logðyi=zimÞ  ðyi  zimÞg
Buck and Sahu (2000) propose the loss function
UðZm; YÞ ¼ 2
X
n
i¼1
yim logðyim=zimÞ
with an expectation (over the posterior predictive density) that can be
written as the sum of the usual likelihood ratio statistic and a complexity
penalty.
The predictive loss criteria of Gelfand and Ghosh (1998), Ibrahim et al.
(2001) and others allow varying trade-offs in the balance between bias in
predictions and their precision. Then for k positive, one possible criterion
has the form
PrLmðkÞ ¼
X
n
i¼1
VarðzimÞ þ
k
k þ 1


½yi  EðzimÞ2


ð2:12Þ
This criterion would be compared between models at selected values of k,
typical values being k ¼ 1; k ¼ 10 and k ¼ 10 000. Higher values of k
imply a greater stress on accuracy in predictions (i.e. bias) and less stress
on precision. Laud and Ibrahim (1995), Ibrahim et al. (2001) and others
have considered calibration of such measures, i.e. expressing the uncer-
tainty of Cm, Dm or PrLmðkÞ in a variance measure. Then one might move
on to make probabilistic statements that model k is inferior to the best
ﬁtting model j with a certain probability based on fCk; Cj; sjg where
sj ¼ ½VarðCjÞ0:5. An alternative approach to assessing uncertainty in
predictive criteria is considered by Congdon (2005a); see section 2.8.
2.5
POSTERIOR PREDICTIVE CHECKS
Gelman et al. (1995) propose a diagnostic procedure known as a posterior
predictive checking using predictive replicates Z. Various forms of
checking function may be calculated for both new data and actual
POSTERIOR PREDICTIVE CHECKS
37

observations to assess whether the model satisfactorily reproduces certain
important aspects of the actual data. Thus such checks go beyond bias
and precision.
For example, if continuous data are skewed, or count data are over-
dispersed, then the model should reproduce such features in the replicates
Z which are sampled from the model. Suppose CðY; Þ is the observed
criterion (e.g. a ratio of observed variance to mean, or a skewness mea-
sure). Let the same criterion based on new data be denoted CðZ; Þ. A
reference distribution is obtained from the joint distribution of Z and ,
PRðZ; Þ ¼ PðZjÞPðjYÞ
and the actual value obtained by sampling set against this distribution.
In practice, at each iteration CðZðtÞ; ðtÞÞ and CðY; ðtÞÞ are obtained and
the proportion of iterations where CðZðtÞ; ðtÞÞ exceeds the other is also
obtained, namely
^Pc ¼
X
T
t¼1
1ðCðZðtÞ; ðtÞÞÞ > CðY; ðtÞÞ=T
ð2:13Þ
Sometimes CðY; ðtÞÞ may in fact not depend on ðtÞ but represent a ﬁxed
aspect of the observations (e.g. the proportion of zero counts in a Poisson
regression application). So it does not need to be sampled at each
iteration, though CðZðtÞ; ðtÞÞ still does.
Values of ^Pc near 0 or 1 (above 0.9 or below 0.1) indicate discrepancy
between the observations and the model. Values relatively close to 0.5
mean that the actual data and the new data sampled from the model are
closely comparable in terms of the feature that the checking function
summarises. Reviews of the posterior predictive check procedure argue
that it makes double use of the data and suggest that it may be conser-
vative as a test (Bayarri and Berger, 2000), since the observations yi can
have a strong inﬂuence on the replicate zi. Sinharay and Stern (2003)
present simulations showing that posterior predictive checking may not
detect departures from normality in random effects models; they consider
the educational testing data also analysed by Gelman et al. (1995).
Marshall and Spiegelhalter (2003) develop on Gelman et al. (1996) by
suggesting a mixed predictive scheme where the model for im includes
random effects. Thus one ﬁrst simulates new random effects, and then
simulates predictions based on the sampled random effects. For example,
in the disease mapping model of (1.8) with means i ¼ iEi, and
log(iÞ ¼ Xi þ i1 þ i2,
replicates
i1;new
and
i2;new
would
be
sampled and replicate disease counts Z would be sampled using means
i;new ¼ expðXi þ i1;new þ i2;newÞ, whereas usually replicates Z are
38
MODEL COMPARISON AND CHOICE

sampled from means i ¼ expðXi þ i1 þ i2Þ. This procedure consi-
derably reduces the conservatism of posterior predictive checks (and
other predictive assessments).
2.6
OUT-OF-SAMPLE CROSS-VALIDATION
Cross-validation is more explicit when predictions of a subset Ys of the
observed data Y are made from parameters estimated using only the
remaining part of the data, namely the complement of Ys, denoted Y½s
(Gelfand and Dey, 1994). The data on which the model is estimated are
often called the training data or training set and the data whose ﬁt to the
model is to be assessed the prediction or validation set (e.g. Raftery et al.,
1997, p 185).
An example of such methods is in time series analysis where observ-
ations y1; . . . ; yT are available, but only part of the history, say fy1; . . . ;
yT  mg, is used to predict the remainder of the series fyT  m þ 1; . . . ; yTg.
Cross-validatory predictions may, like those of new data, be based on
repeated sampling from the posterior of  in an MCMC sampling chain
and have the form
PðYsjY½sÞ ¼
ð
PðYsj; Y½sÞPðjY½sÞ d
Even if the prior for  is improper, this predictive density is proper
because the posterior based on using Y½s to estimate , namely PðjY½sÞ, is
proper (Gelfand, 1996). By contrast, the formal Bayes factor is not
deﬁned for improper priors.
If Ys  yi consists of just one observation, with Y½i denoting the
remaining n  1 cases, then the density
PðyijY½iÞ ¼ PðYÞ=PðyiÞ ¼
ð
Pðyij; Y½iÞPðjY½iÞ d
ð2:14Þ
is known as the conditional predictive ordinate (CPO) for case i (Geisser
and Eddy, 1979). A Monte Carlo estimate of the CPO obtained without
actually omitting case i from the estimation is provided by the harmonic
mean of the likelihoods for case i (e.g. Sinha et al., 2003):
CPOi ¼ T=
 X
t
f1=PðyijðtÞÞg

ð2:15Þ
Thus the full cross-validation based on N separate estimations (the ﬁrst
omitting case 1, the second omitting case 2, etc.) may be approximated
by a single estimation run based on the full sample. The CPO values may
OUT-OF-SAMPLE CROSS-VALIDATION
39

be scaled (dividing by their maximum) and low values for particular
observations (e.g. under 0.01) will then show outlying observations where
the model is not ﬁtting well (Weiss, 1994). If there are no scaled CPOs
under say 0.01 then a relatively good ﬁt to all data points is suggested.
The range in scaled CPOs is useful as an indicator of a good ﬁtting model
(Congdon, 2005c).
An improved estimate of the CPO may be obtained by weighted
resampling from PðjYÞ (Smith and Gelfand, 1992). Thus samples ðtÞ
from P(jY) can be converted to samples from P(jY½i) by resampling the
ðtÞ with weights
wðtÞ
i
¼ HðyijðtÞÞ=
X
i
HðyijðtÞÞ
where HðyijðtÞÞ ¼ 1=PðyijðtÞÞ, i.e. the inverse likelihoods of case i at
iteration t. Once  has been resampled, a sample of replicate data Y can
be obtained. From (2.14), PðyijY½iÞ ¼
Ð
Pðyij; Y½iÞPðjY½iÞ d, so if ðtÞ

is sampled from PðjY½iÞ and if replicate data are obtained as
yðtÞ
i  PðyijðtÞ
 ), then the marginal density of yi is PðyijY½iÞ. Note that
both estimation techniques, the simple one via (2.15) or the resampling
one, become difﬁcult when individual cases have low likelihoods (e.g. log
likelihoods of 10 or 20).
One may obtain a range of summary measures of the closeness of ﬁt
between the observed yi and the predictions made via (2.14). Gelfand
et al. (1992) propose discrepancy functions for comparing the observa-
tions with predictions from PðyijY½iÞ. Among the simplest is the cross-
validation residual (Carlin and Louis, 2000, p 205)
½yi  EðyijY½iÞ=½VarðyijY½iÞ0:5
The posterior mean EðyijY½iÞ ¼
Ð
EðyijÞPðjY½iÞ d may be approxi-
mated by sampling new data Zi and setting EðyijY½iÞ ¼ EðZijYÞ. Similarly
Var(yijY½i) may be estimated by the posterior variance of Zi or by
sampling Z2
i and setting Var(yijY½iÞ 
 EðZ2
i jYÞ ½EðZijYÞ2.
As discussed by Gelfand (1996), cross-validation based on single case
omission provides an alternative to formal marginal likelihood estima-
tion. Thus if yi consists of only one observation and the remaining n  1
observations are used to estimate , then a proxy for the marginal
likelihood PðYÞ, known as the pseudo marginal likelihood, is deﬁned
by the product of these terms
PsML ¼ ^PðYÞ ¼
Y
n
i¼1
PðyijY½iÞ
ð2:16Þ
40
MODEL COMPARISON AND CHOICE

with PðyijY½iÞ estimated as in (2.15), or via resampling. The ratio of P1ðyÞ
and P2ðyÞ for two models 1 and 2 is sometimes known as the pseudo
Bayes factor (PsBF), though a Jeffreys’ type scale for these is not
available. An estimate of the log pseudo marginal likelihood in (2.16)
is obtained by totalling over the log CPOs as estimated by (2.15).
Model assessment by cross-validation includes comparison of models
via random splitting of data sets, e.g. k-fold validation (Kuo and Peng,
1999). Here the data are split into a small number of groups (e.g. k ¼ 5)
of roughly equal size and cross-validation is applied k times by leaving
out the kth group and using the k  1 remaining groups as the training
data.
2.7
PENALIZED DEVIANCES FROM A BAYES PERSPECTIVE
Several model choice techniques proposed for use in Bayesian analy-
sis include features of classical model assessment, such as penalizing
excess complexity and the requirement for accurate out-of-sample pre-
dictions (or cross-validation). The resulting criteria for model selection
may be known as informal if they do not produce a model probability
P(m ¼ jjY) conditional on the data. As an example of a Bayesian adapt-
ation of frequentist model choice by comparing penalized deviances,
Spiegelhalter et al. (2002) propose an estimate for the effective total
number of parameters or model dimension, denoted de. This total is gene-
rally less than the nominal number of parameters dn in complex hierarchi-
cal random effects models where there is no way to count parameters, and
where the number of effects being ﬁtted may exceed the number of
observations.
For instance, under the mixed model in spatial epidemiology with
p regressors (equation 1.8), the nominal number of parameters is
dn ¼ ðp þ 1Þ þ 2n þ 2, allowing for the n parameters in each of i1
and i2. However, such sets of parameters are not independent of each
other because they are generated from a joint density and their effective
dimension is lower. Let LðtÞ ¼ log½PðYjðtÞÞ denote the log likelihood
obtained at the tth iteration in a long sampling chain, and DðtÞ ¼ 2LðtÞ
be the deviance. Another deﬁnition of the deviance is provided by
McCullagh and Nelder (1989) and involves comparing the model and
saturated likelihoods (this is termed the GLM deviance below): both
deﬁnitions may be used to derive the effective parameters.
Then de may be approximated by the difference between the expected
deviance EðDjy; Þ, given by the mean DD of the sampled deviances DðtÞ,
PENALIZED DEVIANCES FROM A BAYES PERSPECTIVE
41

and the deviance DðjyÞ at the posterior mean  of the parameters. The
latter deviance may also be estimated at the posterior means, e.g.
i ¼ iEi in the model of (1.8), and this estimate may be denoted
DðjyÞ.
The analogue of the classical Akaike information criterion (AIC) is
then either
DðjyÞ þ 2de
ð2:17aÞ
or
DðjyÞ þ 2de
ð2:17bÞ
and termed the deviance information criterion (DIC) by Spiegelhalter
et al. (2002). DðjyÞ may be more easily obtainable than DðjyÞ in certain
complex (e.g. discrete mixture) models.
Another effective parameter estimate relies on the asymptotic chi-
square distribution of DðjyÞ  DðminjYÞ where min is the value of 
minimizing the deviance for a given model (Gelman et al., 2003). Then
from the properties of the chi-square density, d
e ¼ 0:5 VarðDðtÞÞ. Both
effective parameter estimates in practice include aspects of a model such
as the precision of its parameters and predictions.
2.8
MULTIMODEL PERSPECTIVES VIA PARALLEL
SAMPLING
As in Congdon (2005a), consider data Y ¼ ðy1; . . . ; ynÞ and a set of
potential models j ¼ 1; . . . ; J of dimensions d ¼ ðd1; d2; . . . ; dJÞ, with
parameter sets  ¼ ð1; 2; . . . ; J), prior model probabilities P(m ¼ j),
and priors on parameters P(jjm ¼ j). Likelihood and prior speciﬁcation
is independent between models.
The log-likelihood under model j is log[P(YjjÞ ¼ LðjjY), with
deviance obtained as DðjjYÞ ¼ 2LðjjYÞ or as DðjjYÞ ¼ 2½Lðjj
YÞ  LðYjYÞ.
Consider
the
output
from
sampling
stream
ðtÞ ¼
ððtÞ
1 ; . . . ; ðtÞ
j ; . . . ; ðtÞ
j Þ of length T. This may be obtained from parallel
or sequential sampling. As noted above, posterior means of the log
likelihood or deviance (respectively Lj ¼ PT
t¼1 LððtÞ
j jYÞ=T and Dj) have
been suggested as measures of model performance by Spiegelhalter et al.
(2002) and Dempster (1997). One might also use deviances or log
likelihoods with a penalty for dimension; for instance, take the AIC of
model j as AICj ¼ Dj þ 2dj, or the BIC (Bayesian Information Criterion)
of model j as BICj ¼ Dj þ dj logðnÞ. An alternative might be to penalize
the deviance at the posterior parameter mean (namely, DðjÞ), or posterior
42
MODEL COMPARISON AND CHOICE

mode. Sometimes inferences are based on maximum a posteriori estima-
tion maximizing the joint density of parameters, data and model (the ‘full
model likelihood’ for short), namely
Fj ¼ PðY; j; m ¼ jÞ ¼ PðYjjÞPðjjm ¼ jÞPðm ¼ jÞ
Consider a ﬁt criterion such as the difference in AIC between models j
and k,
AICjk ¼ AICj  AICk
where AICj ¼ Dj þ dj, or equivalently the penalized likelihood ratio or
evidence ratio (Burnham and Anderson, 2002)
Ejk ¼ ðLj=LkÞ expðdk=djÞ
ð2:18Þ
Similarly relevant to model comparisons are Akaike or AIC weights
(Brooks, 2002) obtained by comparing AICj to the minimum AIC for
model m, giving differences AICj ¼ AICj  AICm. These are rescaled
to give weights
!j ¼ expð0:5AICjÞ=
X
m
½expð0:5AICmÞ
ð2:19Þ
One may also consider likelihood weights, based on comparison with the
highest log-likelihood model m; deﬁning Lj ¼ Lj  Lm, likelihood
weights are obtained as
j ¼ expðLjÞ=
X
m
½expðLmÞ
ð2:20Þ
Another option, based on Schwartz (1978), are BIC weights (Wintle
et al., 2003). Comparison with the minimum BIC model m, gives
BICj ¼ BICj  BICm, and weights
j ¼ expð0:5BICjÞ=
X
m
½expð0:5BICmÞ
ð2:21Þ
Analysing parallel output (or pooled output from models run separately)
enables analysis of the densities of intermodel ﬁt criteria, or of associated
model weights. Posterior averages and densities of such criteria are
obtained and the densities may be used as evidence of support for
models. Monte Carlo estimates of formal model probabilities P(m ¼
jjY) are also obtainable using samples of the iteration-speciﬁc model
probabilities P½m ¼ jjY; ðtÞ (see section 2.9). Iteration-speciﬁc values of
model weights or model probabilities provide a basis for model averaging
that takes into account both model and parameter uncertainty; this
approach constrasts with that of Hoeting et al. (1999) who base model
MULTIMODEL PERSPECTIVES VIA PARALLEL SAMPLING
43

averaging on posterior means and variances of parameters in different
models.
From a parallel sampling analysis one may consider posterior prob-
abilities that model j provide better predictions than model k (perhaps
after adjusting for parameter complexity). Thus the JðJ  1Þ predictive
comparison probabilities
Qðj; kÞ ¼ Pr½DðZj; YÞ < DðZk; YÞ
ð2:22Þ
provide evidence on the relative predictive success of models j and k. For
example, if
Pr½DðZj; YÞ < DðZk; YÞ > 0:5
and dj < dk also (i.e. model j has a higher probability of providing better
predictions and also has a lower dimension), this would be evidence,
using Occam’s razor, in support of model j. One may also consider
the probabilities that model j provides the best predictions among all
models:
BðnewÞ
j
¼ Pr½DðZj; YÞ < DðZk; YÞ; all k 6¼ j
ð2:23aÞ
or
BðnewÞ
j
¼ Pr½CðZj; YÞ < CðZk; YÞ; all k 6¼ j
ð2:23bÞ
estimated by the proportion of iterations where
DðZðtÞ
j ; YÞ < DðZðtÞ
k ; YÞ; all k 6¼ j
Optimality may also be deﬁned in terms of the model with the best
likelihood or penalized likelihood criterion; for example,
BðAICÞ
j
¼ Pr½AICðj; YÞ < AICðk; YÞ; all k 6¼ j
ð2:24Þ
estimated by the proportion of iterations where
LððtÞ
j jyÞ þ 2pj < LðZðtÞ
k ; yÞ þ 2pk;
8k 6¼ j
As mentioned above, a problem in model selection is in random effects
models where the model dimension is unknown. One can, however,
substitute an effective parameter count into conventional ﬁt criteria such
as the AIC and BIC. Using the effective parameter count proposed by
Spiegelhalter et al. (2002) leads to a strategy for model choice based on
minimum DICj where
DICj ¼ DðjÞ þ 2dej
44
MODEL COMPARISON AND CHOICE

This still leaves a problem when DIC differences are small. In an attempt
to describe what differences in AIC or DIC count as signiﬁcant, ‘rules of
thumb’ options such as
DICjk ¼ DICj  DICk > 4
(Spiegelhalter et al., 2002) or AICjk > 10 (Anderson et al., 2000), have
been suggested.
If estimates of dej and dek are obtained from a preliminary run, then
parallel sampling enables one to obtain the density of the DICjk in a
subsequent run, and hence an informed decision to be made about signi-
ﬁcant differences in DIC or AIC. We take the iteration-speciﬁc equivalent
of the DIC to be DððtÞ
j Þ þ dej, and obtaining a density for DICjk then
involves repeated sampling of
ðtÞ
jk ¼ DððtÞ
j Þ  DððtÞ
k Þ þ ðdej  dekÞ
ð2:25Þ
In fact, some analytic results are available to deﬁne the densities of
intermodel ﬁt statistics. Gelman et al. (2003) mention another estimate of
effective parameters, based on the asymptotic distribution of the deviance
difference between j and the value 
j providing the minimum deviance;
thus
Cj ¼ DðjÞ  Dð
j Þ  2ðdejÞ
ð2:26Þ
Since the variance of a chi-square variable is twice the degrees of
freedom, one may obtain an effective parameter estimate dej as half the
variance of a stream of sampled deviances
dej ¼ 0:5 Var½DðtÞ
j 
It follows that the difference Cj  Ck between models is distributed as
a difference of chi-square variables 2(dejÞ and 2(dekÞ, so if ðtÞ
jk ¼
DððtÞ
j Þ  DððtÞ
k Þ, then
0:5 Var½ðtÞ
jk  
 dej þ dek
So the variance of the deviance difference ðtÞ
jk
measures the ‘total
complexity’ of models being compared. Since the DIC is the posterior
mean of the deviance plus dej (which is viewed as an unknown constant or
perhaps a constant subject to small Monte Carlo variation), the difference
in DICs is obtained as the posterior mean of ðtÞ
jk ¼ ðtÞ
jk þ ðdej  dekÞ.
The variance of ðtÞ
jk and ðtÞ
jk may not exactly equal 2ðdej þ dekÞ, since in
repeated sampling of models in parallel it will be necessary to adjust for
correlation rjk between the series of sampled values DðtÞ
j
and DðtÞ
k , though
MULTIMODEL PERSPECTIVES VIA PARALLEL SAMPLING
45

this correlation tends to diminish as longer sampling chains are taken.
Also, since it is a random correlation between two series and not an
autocorrelation, it is generally small (e.g. between 0.05 and 0.05). The
actual variance of ðtÞ
jk will be
Var½ðtÞ
jk  ¼ 2ðdej þ dek  wjkÞ
where wjk is the covariance between series, so that the variance of the
DIC difference is obtained as
Var½DICjk ¼ Var½ðtÞ
jk   2wjk
ð2:27Þ
Consider also a stream of comparison measures on the log-likelihood
scale such as the log-likelihood ratio ðtÞ
jk or the log of evidence ratio
"ðtÞ
jk ¼ log½EðtÞ
jk 
ð2:28Þ
From above it follows that
2Varð"ðtÞ
jk Þ ¼ 2VarððtÞ
jk Þ 
 dej þ dek  wjk
ð2:29Þ
That is, the variance of the log evidence ratio, as obtained by repeated
sampling involving comparison of two models, is also a measure of total
complexity.
2.9
MODEL PROBABILITY ESTIMATES FROM
PARALLEL SAMPLING
Suppose from parallel sampling, or less conveniently from pooling output
from separate sequential sampling, that one obtains parameter samples
for all J models. The collected output at iterations t ¼ 1; . . . ; T is
fð1Þ; . . . ; ðTÞg where ðtÞ ¼ ððtÞ
1 ; . . . ; ðtÞ
J Þ. Using such output, one may
obtain estimates of P(m ¼ jjY) of the posterior model probabilities, and
hence estimated Bayes factors Bjk from the relation
Pðm¼jjYÞ=Pðm¼kjYÞ ¼ ½PðYjm¼jÞ=PðYjm¼kÞ½Pðm¼jÞ=Pðm¼kÞ
¼ Bjk½Pðm ¼ jÞ=Pðm ¼ kÞ
Averaging over the posterior P(jY) of  ¼ ð1; 2; . . . ; JÞ one may
obtain P(m ¼ jjY) as
Pðm ¼ jjYÞ ¼
ð
Pðm ¼ j; jYÞ d ¼
ð
Pðm ¼ jjY; ÞPðjYÞ d
46
MODEL COMPARISON AND CHOICE

A Monte Carlo estimate ^Pðm ¼ jjYÞ of Pðm ¼ jjYÞ is therefore provided
by
^Pðm ¼ jjYÞ ¼
X
T
t¼1
Pðm ¼ jjY; ðtÞÞ=T
ð2:30Þ
Consider the numerator in the following re-expression of P(m ¼ jjY; Þ:
Pðm ¼ jjY; Þ ¼ PðY; ; m ¼ jÞ=PðY; Þ
¼ PðY; ; m ¼ jÞ=
X
k
PðY; ; m ¼ kÞ
ð2:31Þ
namely
PðY; ; m ¼ jÞ ¼ PðYj; m ¼ jÞPð; m ¼ jÞ ¼ PðYj; m ¼ jÞ
 Pðjm ¼ jÞPðm ¼ jÞ
The ﬁrst component is the likelihood when m ¼ j, and reduces to
lj ¼ lðjjYÞ ¼ PðYjj; m ¼ jÞ
(cf. Carlin and Chib, 1995). Also assume
Pðkjm ¼ jÞ ¼ 1
ðk 6¼ jÞ
ð2:32Þ
This is reasonable in terms of a subjective prior view since model j 6¼ k is
not meant to provide information about different values of k.
The cross-model priors P(kjm ¼ j) are also termed pseudo-priors by
Carlin and Chib (1995), but their role in this case is not strictly as priors
but as linking densities in a product space search algorithm – see also
Godsill (2001) on pseudo-priors in the metropolized version of the Carlin–
Chib algorithm. However, Carlin and Chib argue that pseudo-priors can
be set arbitrarily and so the choice (2.32) can be seen as consistent with
this while also simplifying model probability calculations.
Thus with (2.32)
Pðjm ¼ jÞ ¼
Y
J
k¼1
Pðkjm ¼ jÞ ¼ Pðjjm ¼ jÞ
and (2.31) becomes
Pðm ¼ jjY; Þ ¼ ljPðjjm ¼ jÞPðm ¼ jÞ=
X
J
k¼1
lkPðkjm ¼ kÞPðm ¼ kÞ
"
#
¼ Fj=
X
J
k¼1
Fk
MODEL PROBABILITY ESTIMATES FROM
47

where Fj ¼ PðY; j; m ¼ jÞ. Note that the same simpliﬁcation follows
from assuming that the cross-model priors are equal without actually
specifying them, i.e. that Pðk1jm ¼ j1Þ ¼ Pðk2jm ¼ j2Þ for all k1 6¼
j1; k2 6¼ j2.
Except possibly for small samples, Rj ¼ log Fj is the quantity that is
monitored in practice. Let m be the model with the maximum RðtÞ
j
at a
particular iteration, and deﬁne RðtÞ
j
¼ RðtÞ
j
 RðtÞ
m. Then
wðtÞ
j
¼ expð0:5RðtÞ
j Þ=
X
k
½expð0:5RðtÞ
k Þ
ð2:33Þ
is an estimator of Pðm ¼ jjY; ðtÞÞ at iteration t. The averages
wj ¼
X
t
wðtÞ
j =T
ð2:34Þ
may be used to approximate posterior model probabilities. The wj are
termed Bayesian model weights, and are Bayesian in the sense that they
clearly incorporate prior information on j into model choice and
averaging, whereas for criteria such as the AIC this is not directly
apparent (Kadane and Lazar, 2004). Another estimator for model choice
is provided by considering the differences Rj between Rj and max(Rj)
and then calculating
expðRjÞ=
X
k
½expðRkÞ
Model performance is also summarized by differences jk ¼ Rj  Rk in
the posterior averages of the log total model likelihoods. For example, if
the 95% interval of fðtÞ
jk ; t ¼ 1; . . . ; Tg is conﬁned to positive values this
would support model j.
Consider the iteration-speciﬁc average of a functional of parameters
and data (ðtÞ
j ; Y) obtained by using weights wðtÞ
j , namely
wððtÞ; YÞ ¼
X
j
wðtÞ
j ððtÞ
j ; YÞ
Then the posterior mean E[wððtÞ; YÞjY, as estimated by P
t w
ððtÞ; YÞ=T, provides a model averaged estimate of (; Y) that takes
account of both model and parameter uncertainty. A particular applica-
tion is illustrated by regression selection. Deﬁne inclusion weights ðtÞ
r for
regressor xr at iteration t based on totalling wðtÞ
k over those models k that
include xr. Then a density for r is obtained by averaging over iterations,
while the posterior mean E(rjy) may be used to form particular kinds of
48
MODEL COMPARISON AND CHOICE

model.
The
regression
model
deﬁned
by
those
predictors
with
E(rjyÞ > 0:5 is sometimes known as the median probability model
(Barbieri and Berger, 2004).
2.10
WORKED EXAMPLE
As a simple demonstration of the calculation in (2.34), consider the 2  2
factorial study (patient frailty and treatment) with a binomial mortality
response, undertaken by Dellaportas et al. (2002) and Green (2003). All
ﬁve possible models are considered, namely mean only, mean þ frailty,
mean þ treatment,
mean þ frailty þ treatment
and
mean þ frailty þ
treatment þ frailty * treatment. Priors are as in Dellaportas et al. The
posterior model probabilities from the last 45 000 of a 50 000 iteration two-
chain run are (0.008, 0.507, 0.017, 0.405, 0.063). These are close to those
reported by existing studies (Green, 2003; Dellaportas et al., 2002) using
RJMCMC or the metropolized version of the Carlin–Chib algorithm.
The code in WINBUGS is
model {for (i in 1:N) {# J=5 models with differing predictors
logit(p [i,1])<-b1 [1]
logit(p [i,2])<-b2 [1]+b2 [2]*equals(frai [i],1)
logit(p [i,3])<-b3 [1]+b3 [2]*equals(trt [i],1)
logit(p [i,4])<-b4 [1]+b4 [2]*equals(frai [i],1)+b4 [3]*equals(trt [i],1)
logit(p [i,5]) <-b5[1]+b5 [2]*equals(frai [i],1)+b5 [3]*equals(trt [i],1)
+b5 [4]*equals(frai [i],1)*equals(trt [i],1)
for (j in 1:J) {Y [i,j] <- y [i]; Y [i,j]  dbin(p [i,j],n [i])
LL [i,j] <-logfact(n [i])-logfact(n [i]-y [i])-
logfact(y [i])+y [i]*log(p [i,j])+(n [i]-y [i])*log(1-p [i,j])}}
# priors and prior ordinates
for (j in 1:d [1]) {b1 [j]dnorm(B0 [j],P [j]); Pr [j,1]<- 0.5*log(P [j]/6.28)-
0.5*P [j]*pow(b1 [j]-B0 [j],2)}
for (j in 1:d [2]) {b2 [j] dnorm(B0 [j],P [j]); Pr [j,2] <- 0.5*log(P [j]/6.28)-
0.5*P [j]*pow(b2 [j]-B0 [j],2)}
for (j in 1:d [3]) {b3 [j] dnorm(B0 [j],P [j]); Pr [j,3]<-0.5*log(P [j]/6.28)-
0.5*P [j]*pow(b3 [j]-B0 [j],2)}
for (j in 1:d [4]) {b4 [j] dnorm(B0 [j],P [j]); Pr [j,4]<-0.5*log(P [j]/6.28)-
0.5*P [j]*pow(b4 [j]-B0 [j],2)}
for (j in 1:d [5]) {b5 [j] dnorm(B0 [j],P [j]); Pr [j,5]<-0.5*log(P [j]/6.28)-
0.5*P [j]*pow(b5 [j]-B0 [j],2)}
# scaled likelihoods and model probabilities at each iteration
for (j in 1:J) {L [j]<-sum(LL [,j])+sum(Pr [1:d [j],j])+log(PriorMod [j]
WORKED EXAMPLE
49

# underﬂow protection for disparate model likelihoods
SL [j]<- max(L [j]-maxL,-700); expSL [j]<- exp(SL [j])
# model probabilities at iteration t
w [j]<- expSL [j]/sum(expSL [])}
# maximum of model likelihoods
maxL <- ranked(L [],J)}
The data are as follows:
list(PriorMod=c(0.2,0.2,0.2,0.2,0.2),d=c(1,2,2,3,4),N=4,J=5,P=c(0.125,
0.125,0.125,0.125,0.125),B0=c(0,0,0,0,0),y=c(15,22,5,7),n=c(21,26,20,
12),frai=c(1,1,0,0),trt=c(1,0,1,0))
Initial values for one chain are provided by the list
list(b1=c(0), b2=c(0,0), b3=c(0,0), b4=c(0,0,0), b5=c(0, 0, 0, 0))
with those for the other chain generated from the priors.
REFERENCES
Anderson, D., Burnham, K. and Thompson, W. (2000) Null hypothesis testing:
problems, prevalence, and an alternative. Journal of Wildlife Management, 64,
912–923.
Barbieri, M. and Berger, J. (2004) Optimal predictive model selection. Annals of
Statististics, 32, 870–897.
Bayarri, M. and Berger, J. (2000) P-values for composite null models. Journal of
the American Statistical Association, 95, 1127–1142.
Brooks, S. (2002) Discussion to Spiegelhalter et al Journal of the Royal Statistical
Society, 64B, 616–618.
Buck, C. and Sahu, S. (2000) Bayesian models for relative archaeological
chronology building. Applied Statistics, 49, 423–444.
Burnham, K. and Anderson, D. (2002) Model Selection and Multimodel Infer-
ence: A Practical Information-theoretic Approach 2nd Edition. Springs:
New York.
Carlin, B. and Chib, S. (1995) Bayesian model choice via Markov chain
Monte Carlo methods. Journal of the Royal Statistical Society, Series B,
57, 473–484.
50
MODEL COMPARISON AND CHOICE

Carlin, B. and Louis, T. (1996) Bayes and Empirical Bayes Methods for Data
Analysis. Chapman and Hall: London.
Carlin, B. and Louis, T. (2000) Bayes and Empirical Bayes Methods for Data
Analysis, 2nd Edition. Chapman and Hall: London.
Chib, S. (1995) Marginal likelihood from the Gibbs output. Journal of the
American Statistical Association, 90, 1313–1321.
Congdon, P. (2005a) Bayesian predictive model comparison via parallel sam-
pling. Computational Statistics and Data Analysis, 48, 735–753.
Congdon, P. (2005b) Bayesian model choice based on Monte Carlo estimates of
posterior model probabilities. Computational Statistics and Data Analysis (in
press).
Congdon, P. (2005c) A model for nonparametric spatially varying regression
effects. Computational Statistics and Data Analysis (in press).
Congdon, P. (2005d) Bayesian model comparison via parallel model output.
Journal of Statistical Computation and Simulation, 75 (in press).
Dellaportas, P., Forster, J. and Ntzoufras, I. (2002) On Bayesian model and
variable selection using MCMC. Statistics and Computing, 12, 27–36.
Dempster, A. (1997) The direct use of likelihood for signiﬁcance testing.
Statistics and Computing, 7, 247–252.
Draper, D. (1995) Assessment and propagation of model uncertainty. Journal of
the Royal Statistical Society, Series B 57, 45–97.
Fernandez, C., Ley, E. and Steel, M. (2001) Model uncertainty in cross-country
growth regressions. Journal of Applied Econometrics, 16, 563–576.
Geisser, S. and Eddy, W. (1979) A predictive approach to model selection.
Journal of the American Statistical Association, 74, 153–160.
Gelfand, A. (1996) Model determination using sampling based methods. Chapter 9
in Markov Chain Monte Carlo in Practice, Gilks, W., Richardson, S. and
Spieglehalter, D. (eds). Chapman and Hall: London/CRC Press: Boca Raton, FL.
Gelfand, A. and Dey, D. (1994) Bayesian model choice: asymptotics and
exact calculations. Journal of the Royal Statistical Society, Series B, 56,
501–514.
Gelfand, A. and Ghosh, S. (1998) Model choice: a minimum posterior predictive
loss approach. Biometrika, 85, 1–11.
Gelfand, A., Dey, D. and Chang, H. (1992) Model determination using predictive
distributions with implementation via sampling based methods (with discus-
sion). In Bayesian Statistics 4, Bernardo J. et al (eds). Oxford University Press:
Oxford, 147–167.
Gelman, A. and Meng, X.-L. (1998) Simulating normalizing constants: from
importance sampling to bridge sampling to path sampling. Statistical Science,
13, 163–185.
Gelman, A., Carlin, J., Stern, H. and Rubin, D. (1995) Bayesian Data Analysis,
Chapman and Hall: London.
Gelman, A., Meng, X.-L. and Stern, H. (1996) Posterior predictive assessment of
model ﬁtness via realized discrepancies. Statistica Sinica, 6, 733–807.
REFERENCES
51

Gelman, A., Carlin, J., Stern, H. and Rubin, D. (2003) Bayesian Data Analysis,
2nd Edition. CRC Press: Boca Raton, FL.
Godsill, S. (2001) On the relationship between Markov chain Monte Carlo for
model uncertainty. Journal of Computational and Graphical Statistics, 10,
230–248.
Green, P. (2003) Trans-dimensional Markov chain Monte Carlo. In Highly
Structured Stochastic Systems, Green, P., Hjort, N. and Richardson, S.
(eds). Oxford University Press: Oxford, 179–198.
Hoeting, J., Madigan, D., Raftery, A. and Volinsky, C. (1999) Bayesian model
averaging: a tutorial. Statistical Science, 14, 382–401.
Hoeting, J., Raftery, A. and Madigan, D. (2002) A method for simultaneous
variable and transformation selection in linear regression. Journal of Compu-
tational and Graphical Statistics, 11, 485–507.
Ibrahim, J., Chen, M. and Sinha, D. (2001) Criterion-based methods for Bayesian
model assessment. Statistica Sinica, 11, 419–443.
Jeffreys, A. (1961) The Theory of Probability, 2nd Edition. Cambridge: Cambridge
University Press.
Kadane, J. and Lazar, N. (2004) Methods and criteria for model selection. Journal
of the American Statistical Association, 99, 279–290.
Kass, R. and Raftery, A. (1995) Bayes factors. Journal of the American Statistical
Association, 90, 773–795.
Kuo, L. and Peng, F. (1999) A mixture model approach to the analysis of survival
data. In Generalized Linear Models: A Bayesian Perspective, Dey, K., Ghosh,
S. and Mallick, B. (eds). Marcel Dekker: New York.
Laud, P. and Ibrahim, J. (1995) Predictive model selection. Journal of the Royal
Statistical Society, Series B, 57, 247–262.
Lewis, S. and Raftery, A. (1997) Estimating Bayes factors via posterior simulation
with the Laplace-Metropolis estimator. Journal of the American Statistical
Association, 92, 648–655.
Marshall, E. and Spiegelhalter, D. (2003) Approximate cross-validatory predic-
tive checks in disease mapping models. Statistics in Medicine, 22, 1649–1660.
McCullagh, P. and Nelder, J. (1989) Generalized Linear Models, 2nd Edition.
Chapman and Hall: London.
Meyer, M. and Laud, P. (2002) Predictive variable selection in generalized linear
models. Journal of the American Statistical Association, 97, 859–871.
Newton, M. and Raftery, A. (1994) Approximate Bayesian inference by the
weighted likelihood bootstrap. Journal of the Royal Statistical Society, Series
B, 56, 3–48.
Raftery, A., Madigan, D. and Hoeting, J. (1997) Bayesian model averaging for
regression models. Journal of the American Statistical Association, 92, 179–
191.
Rousseeuw, P. (1985) Multivariate estimators with high breakdown point. In
Mathematical Statistics and its Applications (vol. B), Grossmann, W., Pﬂug,
G., Vincze, I. and Wertz, W. (eds). Dordrecht: Reidel, 283–297.
52
MODEL COMPARISON AND CHOICE

Schwartz, G. (1978) Estimating the dimension of a model. Annals of Statistics, 6,
461–464.
Sinha, D., Patra, K. and Dey, D. (2003) Modelling accelerated life test data by
using a Bayesian approach. Applied Statistics, 52, 249–259.
Sinharay, S. and Stern, H. (2003) Posterior predictive model checking in hier-
archical models. Journal of Statistical Planning and Inference, 11, 209–221.
Smith, A. and Gelfand, A. (1992) Bayesian statistics without tears: a sampling-
resampling perspective. American Statistician, 46, 84–88.
Song, X. and Lee, S. (2002) A Bayesian model selection method with applica-
tions. Computational Statistics and Data Analysis, 40, 539–557.
Spiegelhalter, D., Best, N., Carlin, B. and van der Linde, A. (2002) Bayesian
measures of model complexity and ﬁt. Journal of the Royal Statistical Society,
Series B, 64, 583–639.
Tierney, L. and Kadane, J. (1986) Accurate approximations for posterior moments
and marginal densities. Journal of the American Statistical Association, 81,
82–86.
Trevisani, M. and Gelfand, A. (2003) Inequalities between expected marginal
log likelihoods with implications for likelihood-based model comparison.
Canadian Journal of Statistics, 31, 239–250.
Vernardinelli, I. and Wasserman, L. (1991) Bayesian analysis of outlier problems
using the Gibbs sampler. Statistics and Computing, 1, 105–117.
Wasserman, L. (2000) Bayesian model selection and model averaging. Journal of
Mathematical Psychology, 44, 92–107.
Weiss, R. (1994) Pediatric pain, predictive inference and sensitivity analysis.
Evaluation Review, 18, 651–678.
West, M. (1984) Outlier models and prior distributions in Bayesian
linear regression. Journal of the Royal Statistical Society, Series B, 46,
431–439.
Wintle, B., McCarthy, M., Volinsky, C. and Kavanagh, R. (2003) The use of
Bayesian model averaging to better represent uncertainty in ecological models.
Conservation Biology, 17, 1579–1590.
REFERENCES
53


CHAPTER 3
Regression for Metric
Outcomes
3.1
INTRODUCTION: PRIORS FOR THE LINEAR
REGRESSION MODEL
Regression models seek to quantify the relationship between two or more
variables, with the simplest framework assuming a one-way dependence
between a response or dependent variable y and one or more independent
variables. The latter are taken to be observed without error. Then
conditional on X of dimension p, the normal linear regression model
assumes
yi  Nði; 2Þ
i ¼ 0 þ 1xi1 þ 2xi2 þ    þ pxip
or equivalently
yi ¼ 0 þ 1xi1 þ 2xi2 þ    þ pxip þ "i
"i  Nð0; 2Þ
ð3:1Þ
The function predicting y is linear in X, and the conditional variance
VðyijXiÞ ¼ Vð"iÞ is constant regardless of the values of yi, Xi ¼ ðxi1; xi2;
. . . ; xipg or other information. Analytic results may be obtained for
the posterior densities of the parameters of the normal linear model
without needing to involve MCMC sampling. These often involve
reference priors, such as a uniform prior on f; log g where  ¼
Bayesian Models for Categorical Data
P. Congdon
# 2005 John Wiley & Sons, Ltd

ð0; 1; . . . ; pg. Equivalently (Lee, 1997; Gelman et al., 2003) this prior
may be expressed
pð; 2Þ / 2
under which the conditional posterior for  is
j2; y; X  Nð ~; 2ðX0XÞ1Þ
with ~ ¼ ðX0XÞ1X0y, the usual ordinary least squares estimate. The
conditional posterior for  ¼ 2 is a gamma density1
j; y; X  Ga 0:5ðn  p  1Þ; 0:5
X
e2
i
	

where ei is the estimated error, ei ¼ yi  Xi ¼ yi  i.
Prior interdependence between  and 2 of the form pð; 2Þ ¼
pðj2Þpð2Þ may be expressed in the conjugate multivariate normal
prior of dimension p þ 1 with prior mean m and covariance 2V. Among
options proposed for V are V ¼ gðX0XÞ1 where g is taken large to
guarantee that the prior contains relatively little information as compared
with that in the data; for example, g between 10 and 100 (Smith and
Kohn, 1996) or g ¼ maxð½ p þ 12; nÞ as in Fernandez et al. (2001a,
2001b). The prior on the precision  ¼ 2 is taken as   Gaða; bÞ.
There is debate about the appropriate values for fa; bg or whether the
prior should be set on some transformation of , such as a uniform prior
on logðÞ or  (Gelman et al., 2003), in which case conjugacy no longer
applies. Independent priors on  and 2 as in pð; 2Þ ¼ pðÞpð2Þ, such
as   Npþ1ðB0; T1
0 Þ and   Gaða; bÞ lead to a posterior density
pðj2; y; XÞ with variance  ¼ ðT0 þ X0XÞ1 and mean ðT0B0 þ
X0yÞ.
Another approach to specifying priors in the normal linear model (and
other types of general linear model) is to set them in such a way that the
Bayes factor will be fairly insensitive to changes in the prior. As noted in
Chapter 2, the Bayes factor is the formal method of Bayesian model
choice but may be sensitive to prior speciﬁcation, especially to alternative
diffuse priors. Raftery et al. (1996) propose proper priors for GLM
regression models, based on the data, that are relatively ﬂat over a range
1 The WINBUGS code for this model when p ¼ 1 (i.e. intercept and one predictor) is
model {for (i in 1:n) {y[i]  dnorm(mu[i],tau);
e[i] <- y[i]mu[i];
mu[i] <- a + b*(x[i]-mean(x[]))}
A1 <- 0.5*(n  p  1);
A2 <- 0.5*inprod(e[],e[])
a  dﬂat()
b  dﬂat()
tau  dgamma(A1,A2)
sig2 <- 1/tau}
56
REGRESSION FOR METRIC OUTCOMES

of plausible range of values for j; see also Hoeting et al. (2002). Their
approach is related to the g priors of Zellner (1986) that are used in
Fernandez et al. (2001b). Thus the priors on each j are independent,
with 0  Nð ~0; s2
yÞ and j  Nð0; 2=s2
j Þ ð j ¼ 1; . . . ; pÞ, where s2
y is the
observed variance of Y and s2
j the variance of Xj. The prior on  has the
form   Gað0:5	; 0:5	Þ with expected precision 1/. Raftery et al.
establish default values  ¼ 0:28, 	 ¼ 2:58 and  ¼ 2:85.
The model in (3.1) is appropriate if the assumptions of linearity, normal
errors and constant variance hold, at least approximately. It also assumes
the effect of predictors is the same across all subjects. In practice
departures such as outlier points, non-linear effects of predictors, non-
constant error variances or heavier tailed errors than normal will suggest
modiﬁed models. Another scenario is when regression effects differ
between subjects or subsets of subjects (local regression effects), suggest-
ing perhaps a discrete regression mixture. Even in the linear model there
may be collinearity between predictors such that a parsimonious model is
required that selects only a subset of the available predictors. Because of
the wide variety of possible model features, as well as alternative priors,
selection among models becomes necessary.
Example 3.1
Radiata pines
Here we consider linear model selection
using Bayes factors. Carlin and Chib (1995) and others have investigated
prediction of Y, strength of radiata pines ðn ¼ 42Þ, using either
x ¼ density or w ¼ adjusted density in a simple linear regression (3.1).
So under M1, p ¼ 1 with x as predictor and under M2, p ¼ 1 with w as
predictor, and the models are linear regressions
M1
yi ¼ 1 þ 1xi þ "i1
M2
yi ¼ 2 þ 2wi þ "i2
with "ik  Nð0; 1=kÞ. Carlin and Chib obtain a Bayes factor of 4420 in
favour of M2 by allowing jumps between these models and using pseudo-
priors on 2 when model 1 is selected (and vice versa) so that MCMC
conditions are satisﬁed – see Congdon (2001, section 10.4).
Here the ﬁrst code in Program 3.1 is used to obtain the pseudo marginal
likelihood (2.16). N(3000, 106) priors are assumed for f1; 2g, N(185,
104) priors for f1; 2g, and Ga(1, 0.0000111) priors for f1; 2g
(essentially the same priors as used by Carlin and Chib and in several
other analyses of these data). A two-chain run of 10 000 iterations is
taken with default initial values in one run and values from a pilot run in
the other. This provides (with convergence at under 500 iterations in both
INTRODUCTION
57

models) pseudo marginal likelihoods of 306.9 and 298.1 on models 1
and 2.
This leads to a log (to base e) of the pseudo Bayes factor of 8.84 (see
section 3.3.1). Spreadsheet3_1.xls shows calculation of this likelihood for
M1 and a suggested exercise is to obtain it for M2. One may note that the
scaled CPO for observation 41 under M1 is 0.01, as Y is overpredicted;
under M2 the scaled CPO for this observation is 0.26, and so is no longer
an outlier.
The path sampling method described in Chapter 2 is applied with 41
equally spaced points between 0 and 1 (s0 ¼ 0, s1 ¼ 0:025, etc., to
s40 ¼ 1) and is then applied using code B in Program 3.1. Applying this
requires one to set a prior on 41 values of , 1, 2 and  in the path
model speciﬁed in (2.8). This gives logðBFÞ ¼ 8:51. So model 2 is
conclusively preferred again.
A Monte Carlo parallel sampling approach is then applied using the
approximate model probabilities in (2.30)–(2.31). Prior model probabil-
ities PðM1Þ ¼ 0:9995 and PðM2Þ ¼ 0:0005 are assumed to compensate
for the low support for model 1. Convergence in the separate models is
reached early (at under 1000 iterations) in a two-chain run of 20 000
iterations for each model, and with divergent starting values on 1 and 2
where k ¼ ðk; k; kÞ. With T ¼ 19 000, average weights w1 and w2 are
obtained as 0.34 and 0.66. Taking account of the unequal prior model
probabilities, the estimated Bayes factor is 3880 and logðBFÞ ¼ 8:26.
The WINBUGS code for this analysis is as follows:
model {# Centre Predictors
for (i in 1:42) { cx[i] <- X[i]-mean(X[]); cw[i] <- W[i]-mean(W[])
# repeat data for two models
for (j in 1:2) {Y[i,j] <- y[i]}}
# sampling model
for (i in 1:42) { for (j in 1:2) {Y[i,j]  dnorm(mu[i,j],tau[j])
# log LKD contribution
LL[i,j] <- -0.5*tau[j]*pow(y[i]-mu[i,j],2) + 0.5*log(tau[j]/6.2832) }
# means for M1 and M2
mu[i,1] <- a[1] + b[1]*cx[i];
mu[i,2] <- a[2] + b[2]*cw[i]}
# scaled likelihoods and model probabilities w[k] at each iteration
for (k in 1:2) { L[k] <- sum(LL[,k])+sum(logPrior[1:3,k])+log(Prior-
Mod[k])
SL[k] <- max(L[k]-maxL,-700)
expSL[k] <- exp(SL[k]);
# model weights
w[k] <- expSL[k]/sum(expSL[])}
# maximum of model likelihoods
maxL <- ranked(L[],2)
# priors
58
REGRESSION FOR METRIC OUTCOMES

for (j in 1:2) {a [j]  dnorm(M [1],T [1]); b [j]  dnorm(M [2],T[2]); tau[j]
 dgamma(r,m)
# prior ordinates
logPrior[1,j] <- 0.5*log(T[1]/6.28)-0.5*T[1]*pow(a[j]-M [1],2)
logPrior[2,j] <- 0.5*log(T[2]/6.28)-0.5*T[2]*pow(b [j]-M [2],2)
logPrior[3,j] <- log(pow(tau[j],r-1)*exp(-m*tau[j])*
pow(m,r))-loggam(r)}}
Initial values are given in the list vectors:
list(a=c(0,0),b=c(0,0),tauc(1,1))
list(a=c(3000,3000),b=c(200,200),tau=c(0.001,0.001))
3.2
REGRESSION MODEL CHOICE AND AVERAGING
BASED ON PREDICTOR SELECTION
While approaches based on the penalized ﬁt (e.g. Burnham and Anderson,
2002), or on predictions (e.g. Laud and Ibrahim, 1995), or on marginal
likelihood approximations have been applied to regression model selec-
tion, more directed methods have been proposed for particular model
choice questions occurring in regression. Variable selection is indicated
when predictors X1; X2; . . . ; Xp are highly correlated (approximately
collinear) and a subset of predictors is required in order to obtain a
precisely identiﬁed model. With correlated predictors, coefﬁcients on
particular Xj in a model including all predictors may be reduced to
‘insigniﬁcance’ (a 95% interval straddling the null zero value), or take
signs opposite to what is expected on substantive grounds.
The simplest choice schemes specify priors on binary indicators
j; j ¼ 1; . . . ; p relating to the inclusion ðj ¼ 1Þ or exclusion ðj ¼ 0Þ
of the jth predictor. Thus the linear regression model becomes
yi ¼ 0 þ 11xi1 þ 22xi2 þ    þ ppxip þ "i
ð3:2Þ
The prior probability j ¼ Pðj ¼ 1Þ may be preset. Typically, the value
j ¼ 0:5 is assumed, ensuring equal probabilities for the 2p possible
models (assuming the intercept is included by default). Gibbs sampling is
based on the conditionals
j; Y; 2;
2j; Y;
jj½j; 
where ½j ¼ f1; . . . ; j1; jþ1; . . . ; pg. From a long run the marginal
posterior probabilities that j ¼ 1 (i.e. that Xj be included) are obtained.
Also obtained are posterior probabilities on each of the J ¼ 2p regression
models. This approach assumes a common prior for 2 and 0 even
though these parameters would in fact differ across the J models if each
were ﬁtted separately.
REGRESSION MODEL CHOICE AND AVERAGING
59

Speciﬁcally, a run of T samples will visit a particular model at iteration
t as deﬁned by that subset of fðtÞ
1 ; . . . ; ðtÞ
p g which are ones. The
probability that j 6¼ 0 is then obtained as 1=T times the number of
iterations where j ¼ 1 or equivalently as the number of models visited
that contain Xj. If models M1; . . . ; MJ are visited T1; . . . ; TJ times, where
T ¼ P
j Tj, then posterior model probabilities are estimated as
PðMjjYÞ ¼ Tj=T
Fernandez et al. (2001b) and Koop (2003, chapter 11) compare the
posterior model inferences under variable selection with formal Bayes
factor methodology.
An equivalent procedure selects the model from a multinomial prob-
ability vector with equal prior probabilities 1=2p, where model 1 might be
the intercept only, model 2 a model with X1 only, model 3 a model with
X2 only and so on till the ﬁnal model MJ including all predictors. A
particular form of model selection used when p is large is the MC3
algorithm of Madigan and York (1995). Under this a Metropolis step is
used under which the chain moves from the current model Mc to new
model Mn with probability
p ¼ minf1; ½PðYjMnÞPðMnÞ=½PðYjMcÞPðMcÞg
where PðYjMnÞ is the marginal likelihood of model n. The chain remains
at Mc with probability 1  p. To reduce the range of new models Mn
may be conﬁned to models with one fewer or one more predictor than
Mc.
If the object is to choose the best model then a second run might be
conﬁned to those predictors Xj with posterior probabilities j greater than
0.5. If the object is rather to allow for model uncertainty (i.e. to estimate
parameters under a model averaging perspective) then the focus is
on the products j ¼ jj in (3.2). MCMC sampling will average over
iterations when j ¼ 0 as well as iterations where a model including Xj is
chosen. For example, if the posterior density estimates of j have 95%
intervals straddling zero, this would indicate that Xj is not important in
predicting Y.
Selection may be extended to multiparameter coefﬁcients where the
number of selection indicators k is less than the number of predictors.
For example, in log-linear regression for cross-classiﬁed counts yijk
(i ¼ 1; . . . ; I; j ¼ 1; . . . ; J; k ¼ 1; . . . ; K), there would typically be a
single inclusion indicator for the totality of ðI  1ÞðJ  1Þ parameters
u12ðijÞ describing second-order interactions. One might also apply this
60
REGRESSION FOR METRIC OUTCOMES

idea to standard linear regression for metric y with a single  applying to
the inclusion of a subset of predictors (e.g. for p ¼ 5, 1 ¼ 1 if fX1; X3g
are to be included and 2 ¼ 1 if fX2; X4; X5g are to be included). In this
case prior probabilities j would be (0.4, 0.6) because the subsets are of
different size. One might also extend the selection approach to sets of
random effects (e.g.  ¼ 1 if random three-way effects u123ðijkÞ are to be
included in a log-linear model for counts yijk).
George and McCullough (1993, 1997) develop a stochastic search
variable selection (SSVS) method based on a mixture prior
PðjjjÞ ¼ jPðjjj ¼ 1Þ þ ð1  jÞPðjjj ¼ 0Þ
whereby j has a vague prior centred at zero when j ¼ 1. However, when
j ¼ 0 is selected, the prior is centred at zero (or some other value close to
zero) with high precision. For instance, taking a univariate normal prior
for jjj ¼ 1
jjj ¼ 1  Nð0; V1jÞ
one might assume that V1j is large (leading to a diffuse prior) but multiply
V1j by a small (near zero) constant cj, V0j ¼ cjV1j such that the prior
jjj ¼ 0  Nð0; V0jÞ
is closely constrained around zero. cj should be chosen so that the range
of j under Pðjjj ¼ 0Þ is conﬁned to substantively insigniﬁcant values.
Ntzoufras (1999) recommends applying an ‘automatic scaling’ for all j
(e.g. cj ¼ c ¼ 0:01), possibly with calibration of c to assist the chain to
move better between models.
In the approaches of Kuo and Mallick (1998) and Smith and Kohn
(1996) the selection indicators j and coefﬁcients j are independent
rather than being governed by mixture priors as in the SVSS approach,
such that j ¼ 0 if j ¼ 0, and j ¼ 1 if j 6¼ 0. Kuo and Mallick suggest
independent normal priors on the j, though not overly diffuse, e.g.
j  Nð0; jÞ where 0:4  j  16. The prior on  may also be speciﬁed
as a form of g prior as Npþ1ð0; g2ðXXÞ1Þ where g is a known constant.
In the linear regression model (3.2) let X be the predictor matrix
corresponding to those j selected as 1, and set
SðÞ ¼ Y0Y  ½g=ð1 þ gÞY0XðXXÞ1XY
ð3:3Þ
The conditional probability for j given all other indicators ½j under this
prior is then
Pðjj½j; YÞ / j
j ð1  jÞ1jð1 þ gÞp=2SðÞ  0:5n
ð3:4Þ
REGRESSION MODEL CHOICE AND AVERAGING
61

and the conditional probabilities Pðj ¼ 1j½j; YÞ are obtained by setting
j ¼ 1 in (3.4) and normalizing.
Finally the parallel sampling approach (see section 2.7) may be used in
forward selection. Consider a normal linear regression with p potential
predictors apart from the intercept. An algorithm based on parallel
sampling of models (see Example 3.3) may be stated as follows:
1. To obtain the ﬁrst predictor to be entered into the model, select from
J ¼ p þ 1 parallel models deﬁned by
yi ¼ j þ jxij þ eij
eij  Nð0; jÞ;
j ¼ 1; . . . ; p
yi ¼ pþ1 þ ei;pþ1
ei;pþ1  Nð0; pþ1Þ
Obtain the weights (2.19)–(2.21) and (2.33), the comparison prob-
abilities (2.22) and the best model indicator Bj as in (2.23) or (2.24). If
model j1  p with predictor xij1 is preferred according to these criteria
go to step 2, while if model M ¼ p þ 1 is preferred then stop. Thus if
Qðp þ 1; jÞ > 0:5 for all j < p þ 1, stopping is justiﬁed because a
lower dimension model has a probability over 0.5 of giving better
predictions than all competing higher dimension models.
2. Select from J ¼ p parallel models, with the ﬁrst p  1 models being
yi ¼ j þ jxij1 þ jxik þ eij
eij  Nð0; jÞ
where j ¼ 1; . . . ; p  1 as k varies between 1 and p excluding k ¼ j1.
The lower dimension model is
yi ¼ p þ pxij1 þ eip
eip  Nð0; pÞ
If model jðj  p  1Þ is selected via predictive criteria with predictor
xij2 go to 3, or if model p is selected then stop.
3. Select from J ¼ p  1 parallel models, with p  2 new models
yi ¼ j þ 1jxij1 þ 2jxij2 þ jxik þ eij
eij  Nð0; jÞ
where k 6¼ fj1; j2g. Model p  1 is
yi ¼ p1 þ 1;p1xij1 þ 2;p1xij2 þ ei;p1
ei;p1  Nð0; pÞ
Then select model jðj  p  2Þ and extra predictor j3 via the criteria
used in step 1, or if model p  1 is selected then stop. This process
continues until the majority of weights are higher for model J, and
QðJ; kÞ exceeds 0.5 for k < J.
There may be a conﬂict between choice based on likelihood weights
(which are not penalized by a parameter count) and the other weights
62
REGRESSION FOR METRIC OUTCOMES

which are so penalized. The AIC weights may also tend to select more
heavily parameterized models than BIC weights and model probability
weights (2.33). The latter may tend (like the formal Bayes factor) to
select relatively simple models.
Example 3.2
Electricity usage
Chatterjee et al. (1995, p 292) present
data on electricity usage (y ¼ log kilowatt-hours) by month for a house in
Westchester, New York. The predictor variables are powers of average
monthly Fahrenheit temperature. The choice is between combinations of
a linear term in temperature ðX1Þ, a quadratic term ðX2Þ and a cubic term
ðX3Þ. These three variables are standardized. Note that X1 and X2 are
highly correlated (0.993) and X1 is correlated slightly less with X3 (0.975).
Fit is assessed by the predictive criteria (2.10) and (2.12), by posterior
model probabilities from parallel model sampling, and by indicator/
model selection as in section 3.2. The eight models being compared
are f1g, f1 þ X1g, f1 þ X2g, f1 þ X3g, f1 þ X1 þ X2g, f1 þ X2 þ X3g,
f1 þ X1 þ X3g and f1 þ X1 þ X2 þ X3g. The precisions in the normal
priors for the coefﬁcients on X1 to X3 are 10 000, while the prior for the
intercept is set at N(43, 10 000) where 43 is the OLS intercept in
fX0; X1; X2; X3g. The criterion (2.10), which is equivalent to (2.12)
when k is very large, prefers model 5, namely f1 þ X1 þ X2g. The
three lowest values of the criterion, respectively 10 098, 10 213 and
10 224, are for model 5, model 7 and model 8. Taking k ¼ 1 in (2.12) still
leaves model 5 rated as the best model.
The approximate posterior model probabilities from parallel model
sampling (section 2.8) are for models 5, 7 and 8, namely 0.45, 0.43 and
0.002, so the model with p ¼ 3 receives much less weight. This is based
on two chains of 10 000 iterations and a 1000 burn-in. Note that whereas
the coefﬁcients on powers of temperature in both 5 and 7 are well
identiﬁed, the coefﬁcients 2 and 3 in model 8 are less well identiﬁed.
There is also a probability of 0.10 on the two-predictor model 6, namely
1 þ X2 þ X3.
With binary selection indicators on the j as in (3.2) the respective
probabilities on models 5 to 8 are 0.488, 0.056, 0.278 and 0.178. The
models corresponding to various combinations of j ¼ 1 are obtained by
deﬁning a binary model indicator mj (i.e. mj ¼ 1 when model j is
selected)
mj ¼ Ið1 ¼ Aj1ÞIð2 ¼ Aj2ÞIð3 ¼ Aj3Þ
where Ajk is one when model j includes variable k. The direct
model selection approach, selecting j as a categorical variable from a
REGRESSION MODEL CHOICE AND AVERAGING
63

multinomial vector with prior probabilities 1/16, yields similar probabil-
ities on models 5 to 8 of 0.477, 0.071, 0.268 and 0.183.
Example 3.3
Malnutrition in cystic ﬁbrosis
Altman (1991) and
Everitt and Rabe-Hesketh (2001) consider n ¼ 25 observations on con-
tinuous measures of malnutrition in cystic ﬁbrosis patients. There are
nine possible predictors apart from xi0 ¼ 1, i ¼ 1; . . . ; n (see Table 3.1).
Table 3.1
Predicting malnutrition in cystic ﬁbrosis patients
y
x1
x2
x3
x4
x5
x6
x7
x8
x9
Age
Sex
Height
Weight
BMP
FEV
RV
FRC
TLC
95
7
0
109
13.1
68
32
258
183
137
85
7
1
112
12.9
65
19
449
245
134
100
8
0
124
14.1
64
22
441
268
147
85
8
1
125
16.2
67
41
234
146
124
95
8
0
127
21.5
93
52
202
131
104
80
9
0
130
17.5
68
44
308
155
118
65
11
1
139
30.7
89
28
305
179
119
110
12
1
150
28.4
69
18
369
198
103
70
12
0
146
25.1
67
24
312
194
128
95
13
1
155
31.5
68
23
413
225
136
110
13
0
156
39.9
89
39
206
142
95
90
14
1
153
42.1
90
26
253
191
121
100
14
0
160
45.6
93
45
174
139
108
80
15
1
158
51.2
93
45
158
124
90
134
16
1
160
35.9
66
31
302
133
101
134
17
1
153
34.8
70
29
204
118
120
165
17
0
174
44.7
70
49
187
104
103
120
17
1
176
60.1
92
29
188
129
130
130
17
0
171
43.6
69
38
172
130
103
85
19
1
156
37.2
72
21
216
119
81
85
19
0
174
54.6
86
37
184
118
101
160
20
0
178
64
86
34
225
148
135
165
23
0
180
73.8
97
57
171
108
98
95
23
0
175
51.1
71
33
224
131
112
195
23
0
179
71.5
95
52
225
127
101
Sex: ¼ 0 for males
BMP Basic Metabolic Panel
FEV Forced Expiratory Volume
RV Residual Volume
FRC Functional Residual Capacity
TLC Total Lung Capacity
64
REGRESSION FOR METRIC OUTCOMES

Non-informative N(0, 104) priors are adopted on the regression coefﬁ-
cients in a normal errors linear regression, with all continuous predictors
being centred. Selection is based on likelihood, AIC, BIC and Bayesian
model weights (2.19), (2.21) and (2.33), the predictive comparison
probability QðJ; kÞ, k < J, and the best model indicator Bj in (2.24).
These are compared with the posterior average C0:5
m in (2.10), as used by
Laud and Ibrahim (1995). The model with weight, BMP, FEV and RV is
selected by classical backward and forward selection methods (Everitt
and Rabe-Hesketh, 2001, p 194).
At the ﬁrst selection stage ðJ ¼ 10Þ, nine models containing just one
predictor and an intercept (e.g. model 9 is 1 þ X9) are compared with
each other and to a tenth model containing just an intercept. A two-chain
run of 10 000 iterations shows that all criteria prefer the model 1 þ X4.
At the second stage ðJ ¼ 9Þ there are eight new models all containing
an intercept and X4, with the extra variable being just one of the
eight
remaining
predictors.
So
models
1
to
8
are
1 þ X4 þ Xj
( j ¼ 1; 2; 3; 5; 6; 7; 8; 9) and model 9 is 1 þ X4. The predictive
probability estimates fQð9; kÞ; k ¼ 1; 8g obtained at this stage (Table
3.2) show that ﬁve higher dimension models appear to provide no gain
over 1 þ X4 and are overparameterized. The likelihood and AIC prefer
1 þ X4 þ X5, i.e. BMP combined with weight, while the BIC weights and
Bayes model probability estimates prefer the lower dimension model
1 þ X4 and would not proceed further.
If another stage with J ¼ 8 is pursued, there are seven new models
including new predictors in addition to X4 and X5. Only one model
1 þ X4 þ X5 þ X6 improves on 1 þ X4 þ X5 according to the probabilities
QðJ; kÞ, where J ¼ 8. Hence the selected model involves x6 ¼ FEV,
x5 ¼ BMP
and
x4 ¼ weight.
In
fact
the
more
complex
model
1 þ X4 þ X5 þ X6 is preferred by the BIC weight though (2.31) still
prefers the lower dimension model.
As an illustration of the approximation (2.29) we monitor "8k and ﬁnd
the variances to range between 4.66 and 5.02, or combined complexity
9.3 to 10. This is slightly higher than the nominal total of 9, though the
approximation may be affected by the small sample.
At the fourth stage ðJ ¼ 7Þ the lower dimension seventh model
1 þ X4 þ X5 þ X6 is preferred by the BIC weight and model probability
estimate. The AIC weight is indecisive between 1 þ X4 þ X5 þ X6 and
1 þ X4 þ X5 þ X6 þ X7, while the likelihood weight and predictive cri-
teria prefer the larger model. This is consistent with the choice via
classical forward selection. The ﬁfth stage shows QðJ; kÞ > 0:5 where
model J is 1 þ X4 þ X5 þ X6 þ X7, so selection stops by all criteria.
REGRESSION MODEL CHOICE AND AVERAGING
65

Table 3.2
Cystic ﬁbrosis data, forward selection diagnostics
Stage Model
Model weights
C1=2
B
Likel’d
AIC
BIC
BMW Q(J; k)
1
1. 1 þ X1
188.5
0.258
0.287
0.286
0.285
0.245
0.146
2. 1 þ X2
227.9
0
0.003
0.003
0.003
0.001
0.460
3. 1 þ X3
190.7
0.143
0.223
0.222
0.221
0.196
0.160
4. 1 þ X4
184.5
0.599
0.452
0.451
0.449
0.372
0.125
5. 1 þ X5
231.5
0
0.002
0.002
0.002
0.002
0.485
6. 1 þ X6
213.9
0
0.017
0.017
0.017
0.013
0.322
7. 1 þ X7
226.9
0
0.004
0.004
0.004
0.001
0.444
8. 1 þ X8
217.7
0
0.011
0.010
0.010
0.003
0.357
9. 1 þ X9
235.9
0
0.001
0.001
0.001
0.001
0.522
10. 1
234.0
0
0.001
0.004
0.007
0.165
2
1. 1 þ X4 þ X1
186.9
0.020
0.076
0.068
0.059
0.009
0.529
2. 1 þ X4 þ X2
183.9
0.073
0.120
0.102
0.089
0.012
0.497
3. 1 þ X4 þ X3
187.0
0.013
0.069
0.065
0.057
0.009
0.529
4. 1 þ X4 þ X5
177.2
0.413
0.270
0.233
0.206
0.021
0.413
5. 1 þ X4 þ X6
183.4
0.105
0.140
0.118
0.103
0.017
0.484
6. 1 þ X4 þ X7
185.9
0.024
0.080
0.075
0.065
0.010
0.513
7. 1 þ X4 þ X8
188.3
0.012
0.069
0.060
0.052
0.007
0.529
8. 1 þ X4 þ X9
185.6
0.025
0.082
0.073
0.064
0.010
0.520
9. 1 þ X4
184.5
0.315
0.094
0.206
0.305
0.906
3
1. 1 þ X4 þ X5 þ X1
178.9
0.029
0.087
0.076
0.067
0.008
0.525
2. 1 þ X4 þ X5 þ X2
176.9
0.077
0.117
0.103
0.091
0.015
0.509
3. 1 þ X4 þ X5 þ X3
181
0.044
0.078
0.069
0.061
0.008
0.539
4. 1 þ X4 þ X5 þ X6
164.1
0.611
0.438
0.400
0.365
0.076
0.382
5. 1 þ X4 þ X5 þ X7
181.6
0.010
0.061
0.053
0.046
0.009
0.538
6. 1 þ X4 þ X5 þ X8
180.2
0.020
0.064
0.056
0.049
0.008
0.538
7. 1 þ X4 þ X5 þ X9
179.1
0.010
0.068
0.060
0.053
0.012
0.535
8. 1 þ X4 þ X5
177.2
0.200
0.088
0.184
0.268
0.864
0.520
4
1. 1 þ X4 þ X5 þ X6 þ X1
164.8
0.084
0.124
0.108
0.095
0.012
0.506
2. 1 þ X4 þ X5 þ X6 þ X2
168.6
0.027
0.078
0.067
0.059
0.010
0.545
3. 1 þ X4 þ X5 þ X6 þ X3
166.5
0.058
0.100
0.087
0.076
0.010
0.526
4. 1 þ X4 þ X5 þ X6 þ X7
158.4
0.272
0.250
0.221
0.196
0.057
0.432
5. 1 þ X4 þ X5 þ X6 þ X8
161.3
0.145
0.171
0.149
0.132
0.034
0.467
6. 1 þ X4 þ X5 þ X6 þ X9
162.2
0.134
0.162
0.141
0.125
0.033
0.475
7. 1 þ X4 þ X5 þ X6
164.1
0.280
0.115
0.227
0.318
0.845
5
1. 1 þ X1 þ X4 þ X5 þ X6 þ X7
160.8
0.119
0.165
0.136
0.115
0.018
0.525
2. 1 þ X2 þ X4 þ X5 þ X6 þ X7
162.3
0.083
0.139
0.114
0.097
0.018
0.540
3. 1 þ X3 þ X4 þ X5 þ X6 þ X7
159.6
0.122
0.170
0.140
0.119
0.018
0.512
4. 1 þ X4 þ X5 þ X6 þ X7 þ X8
162.1
0.093
0.143
0.118
0.100
0.019
0.535
5. 1 þ X4 þ X5 þ X6 þ X7 þ X9
160.2
0.134
0.179
0.147
0.126
0.024
0.516
6. 1 þ X4 þ X5 þ X6 þ X7
158.4
0.449
0.204
0.345
0.443
0.902
66
REGRESSION FOR METRIC OUTCOMES

3.3
ROBUST REGRESSION METHODS: MODELS
FOR OUTLIERS
As discussed in Chapter 1, many data sets present complex features that
militate against the application of a single parametric density, such as a
normal or any other density for continuous data (e.g. lognormal, gamma,
exponential) serving to summarize adequately all the data. Observations
may show multimodality, or contain outlier points, either isolated or
clustered (Justel and Pena, 2001). In a regression model where variability
in yi is related to predictors xi, multimodality will often have a
substantive equivalent, e.g. heterogeneity over subpopulations which
have different regression relationships. Thus different models may hold
in subsets of the data, so increasing the uncertainty in predicting new
observations on the basis of the sampled observations.
Bayesian methods for robust regression fall into two broad sets of
procedures. Outlier diagnostic methods seek a central model and control
for the potentially distorting effect on estimates of that model of outlying
or inﬂuential observations with a low probability of being generated by it.
Model extension methods seek to model more directly the source of
aberrant observations, for instance by adopting a discrete mixture or by
replacing a single normal density by a scale mixture (i.e. an error
distribution with heavier tails). Preliminary detection of aberrant or
inﬂuential points may be undertaken with criteria (e.g. CPOs) considered
in section 2.4. Thus for normal linear regression with n observations and
p predictors, and under ﬂat priors, Pettit (1990) shows that the conditional
predictive ordinate is proportional to the standardized residual test for
detecting outliers. Thus
Pðyijy½iÞ /
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  hi
p
1 þ
1 þ r2
i
n  p  1


=s½i
where s2
½i is the residual variance when observation i is excluded, hi is the
leverage
of
observation
i,
namely
the
ith
diagonal
element
of
H ¼ XðX0XÞ1X0, and ri is the studentized residual
ri ¼ ðyi  XiÞ=½
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1  hi
p
=s½i
Observations with large studentized residuals will have a small CPO and
be detected as outliers, while observations with high leverage will also
have small conditional predictive ordinates, regardless of whether they
are outliers, since then hi tends to one.
The diagnostic approach is illustrated by a contaminated normal
regression model, in which each observation is a potential outlier with
ROBUST REGRESSION METHODS: OUTLIERS
67

a low probability ! and outliers have shifted location and or variances
(Verdinelli and Wasserman, 1991). A shifted location model means the
density of y is then
fðyij; 2; !; AÞ ¼ ð1  !Þðyij; 2Þ þ !ðyij þ Ai; 2Þ
where  is the normal density, and A ¼ ðA1; . . . ; AnÞ is the shift in
location for an outlier. An inﬂated variance model is
fðyij; 2; !; Þ ¼ ð1  !Þðyij; 2Þ þ !ðyij; 2Þ
where  > 0. Often  is preset, say at 5 or 10, since ! and  may be
difﬁcult to identify if both are unknowns. Computation and inferences are
aided by adding latent variables i  Bernð!Þ so that the location shift
model becomes
yij; 2; !; A  Nð þ iAi; 2Þ
If regressors are included then the shifted location model is
yij2; ; !; A  ð1  !ÞNðyijXi; 2Þ þ !NðyijXi þ Ai; 2Þ:
Model extension methods to mitigate against the impact of outliers or
inﬂuential points on the central model include: (a) adopting heavier tail
densities than the normal for the error distribution by scale mixing; and
(b) discrete regression mixtures (section 3.7).
The scale mixture of Andrews and Mallows (1974) augments the data
in such a way as to produce an analysis equivalent to assuming Student t
errors. Thus
yi  Nði; 2=iÞ
ð3:5Þ
where i  Gað0:5	; 0:5	Þ. This is equivalent to assuming regression
errors in (3.1) following the Student t density with 	 degrees of freedom.
Other mixture densities may be used (West, 1987). If i  Expð0:5Þ, i.e.
an exponential density with mean 2, then the regression errors in (3.1)
have a double-exponential density, another heavy-tailed alternative to the
normal. Low values of i for particular points (in relation to the average
for all points) suggest observations that are only included in the model by
inﬂating the observation-speciﬁc variance Vi ¼ 2=i (West, 1984) and so
suggest these points are outliers or not adequately represented by the model.
While 	 in the Student t option may be preset – for example, 	 ¼ 4 is a
robust option considered by Gelman et al. (1995, p 352) – a prior may
also be adopted. Geweke (1993) points out problems with adopting
diffuse priors for 	. Possibilities are discrete priors (Knorr-Held, 1999)
with maximum possible 	 equivalent to a de facto normal density (e.g.
68
REGRESSION FOR METRIC OUTCOMES

	 ¼ 100) or an exponential density such as 	  Eð0:1Þ as proposed by
Fernandez and Steel (1998a) or Sahu et al. (2003). Example 3.4 considers
the efﬁcacy of such priors in recovering Student t parameters when data
are generated under known parameters.
Example 3.4
Simulated regression with Student t errors
To illus-
trate the operation of possible priors for the Student t scale mixture model
100 observations are generated from the model
yi  Nði; 2=iÞ
i ¼ 2 þ 0:5xi
i  Gað5; 5Þ
where the xi are N(0,1) variates and 2 ¼ 0:2; this is equivalent to a linear
regression with Student t errors and 	 ¼ 10 degrees of freedom. The goal
is to re-estimate the model parameters ð0; 1; 2; 	Þ with the sampled
yi and xi. The i generated as above range from 0.16 to 2.3 with variance
0.17.
We consider three possible priors for 	. The ﬁrst is a discrete prior over
81 possible values f2k; k ¼ 1; 0:9; 0:8; . . . ; 6:9; 7g (Knorr-Held,
1999). The second is an exponential prior for 	/2 with parameter ,
which is in turn obtained as the inverse of a parameter !, uniformly
distributed between 0 and 2. The third is an exponential prior with 
preset at 0.2 (equivalent to a mean on 	/2 of 5).
Under the discrete prior, a two-chain run of 2500 iterations (convergent
from 1500) shows 	 overestimated at 49 and the variance of the i
understated at 0.08, whereas 2 is overstated at 0.26. Under the expo-
nential prior with underlying uniform prior on ! ¼ 1=, the 	 and 2
parameters are more accurately reproduced, with respective means in a
two-chain run of 2500 iterations of 10.6 and 0.23. The variance of the i
stands at 0.20, closer to the actual 0.17, and the posterior means for
f0; 1g are 1.92 (s.d. ¼ 0.05) and 0.42 (0.05). Under the exponential
prior with  preset at 0.1, the variance of the i is understated at 0.07 and
the degrees of freedom overestimated at 38.
Example 3.5
Puromycin experiment
To illustrate the use of scale
mixing within a normal errors model as in (3.5), consider the non-linear
regression model used by Carlin and Polson (1991) for data from an
experiment in biochemical kinetics. The response is an enzymatic
reaction (in counts/min2) predicted as a function
i ¼  þ xi=ð þ xiÞ
ROBUST REGRESSION METHODS: OUTLIERS
69

of a substrate concentration (in ppm). The enzyme has been treated with
puromycin. The mixtures considered are a Student t with 2 degrees of
freedom, equivalent to normal scale mixing with i  Gað1; 1Þ, and a
double exponential (DE), namely scale mixing with i  Expð0:5Þ. One
goal of the analysis is prediction at an unobserved x value, namely
x ¼ 0:5. To summarize model ﬁt, the DIC and mean absolute deviation
(MAD) between yi and i are used.
The double exponential has a DIC of 90 and an MAD of 92.5, with a
possible discrepancy for observation 2 with Y ¼ 47 but  ¼ 62. This
point has the lowest i, namely 1.16, against an average of 2. The
prediction at x ¼ 0:5 has mean 188 with a 95% interval (169,205). The
Student t mixture again points up observation 2, with i ¼ 0:7 (against an
average of 1) and with 2 ¼ 61. This model has a worse DIC and MAD
(respectively 93.7 and 95) than the double exponential.
Both the DIC and MAD may understate the impact on ﬁt of the
imprecision of parameter estimates under the double exponential. For
example, Carlin and Polson (1991) adopt a different model choice
method: they include a model node in their analysis and obtain a higher
posterior probability Pðm ¼ 1jyÞ ¼ 0:73 for the Student t as against
Pðm ¼ 2jyÞ ¼ 0:27 for the double exponential.
Here the second half of a two-chain run of 100 000 iterations using the
parallel sampling approach with diverse starting values for both models
gives posterior probabilities of 0.68 on the Student t mixture and 0.32 on
the DE mixture – far from conclusive. Following Carlin and Polson
(1991), one might be interested in parameter averaging (or averaging
some other quantity, not itself a parameter) over the alternative models.
Thus consider the average of  over the Student t and DE models using
iteration-by-iteration weights (2.31a). The densities of the two parameters
and their average are summarized in Table 3.3.
It can be seen that the averaged parameter has greater precision (in
terms of a narrower 95% interval) than the parameters from either model,
with mean closer to the estimate from the Student t model. In many cases,
though, model averaging may lead to greater uncertainty (less precision)
Table 3.3
Averages of 
Mean
2.5%
Median
97.5%
1
193.9
160.2
192.0
237.0
2
195.4
157.9
192.7
249.7
 (average over models)
194.5
163.7
193.0
233.3
70
REGRESSION FOR METRIC OUTCOMES

as compared with estimates from a single model (Hoeting et al., 2002,
p 499).
3.4
ROBUST REGRESSION METHODS: MODELS FOR
SKEWNESS AND HETEROSCEDASTICITY
Robust regression may also consider questions such as non-constant
variance and non-normality due to skewness as well as, or instead of,
heavier tailed error densities. Often these problems are interrelated, and
solutions to them may be combined with other procedures: for example,
predictor selection as in Hoeting et al. (2002) and Smith and Kohn
(1996), or with model selection as in Laud and Ibrahim (1995).
A well-known method for skew responses or predictors involves a
skew-minimising transformation such as the Box–Cox transform
yðÞ ¼ ðy  1Þ=
for  6¼ 0, and yð0Þ ¼ logðyÞ for  ¼ 0 (e.g. Pericchi, 1981; Hinkley and
Runger, 1984; Weiss, 1994). If the analysis includes transforming the
response then a discrete grid of  values may be assumed (e.g.  ¼ 1,
0.5, 0.5 and 1), as in Hoeting et al. (2002) and Smith and Kohn (1996).
Hoeting et al. (2002) also consider a change point transformation on
predictors, under which there is no change in the expectation of y above
or below a certain level of X. Skewness may also be tackled by adopting
ﬂexible asymmetric densities, such as the gamma density. For example,
one may assume
Yi  Gað
; 
=iÞ
where logðiÞ ¼ Xi (McCullagh and Nelder, 1989). Modiﬁcations of the
normal and Student t densities have also been suggested. Sahu et al.
(2003) introduce an extra random effect i (with known scale as for a
latent trait in factor analysis) into the regression mean. This extra effect is
constrained to be positive. Thus a skewed normal model is
yi ¼ Xi þ i þ "i
i ¼ 1; . . . ; N
ð3:6Þ
where "i  Nð0; 2Þ,
i  Nð0; 1ÞIð0Þ
and  is a loading that is positive when there is right skew in the data and
negative when there is left skew. Equivalently
Yi  Nði; 2Þ
i ¼ Xi þ i
ð3:7Þ
ROBUST REGRESSION METHODS: SKEWNESS & HETEROSCEDASTICITY
71

A positive density such as the gamma might also be used for i, e.g.
i ¼ 
i  1
ð3:8Þ
where 
i  Gað1; 1Þ as this accommodates additional non-normality.
Introducing such effects may induce excess parameterization and an
option is to assume a Dirichlet process prior (DPP) (section 3.5.3) with a
maximum number of say N/10 or N/20 clusters for the skew effects.
Fernandez and Steel (1998b) consider methods to address both skew-
ness and fat tails together. Thus the baseline variance 2 (or precision
 ¼ 2) is scaled differentially according to whether the residual
"i ¼ yi  i ¼ yi  Xi is negative or positive. For positive residuals
the variance is scaled by a positive factor 1/2, while for negative
residuals the scaling is by 2. So when there is positive skewness in
the errors ", values of  > 1 are selected. By contrast,  ¼ 1 corresponds
to a symmetric density, and values of  under 1 to negative skewness.
This model for skewness can be combined with a scale mixture form of
the Student t density to allow for both skewness and heavy tails.
A frequently occurring form of heteroscedasticity is when the variance
of the residuals increases with the size of the ﬁtted values. As for
skewness, one solution to this involves transformation of the response,
such as square root or log. Direct modelling of changes in the variance
VðyjXÞ between observations is also possible (Boscardin and Gelman,
1996). Among possible schemes for such heteroscedasticity, consider
yi ¼ Xi þ "i ¼ i þ wi"i
where "i  Nð0; 1Þ. Then if the variance of the residuals increases with
the ﬁtted values one might set
wi ¼ expðiÞ
wi ¼ i
j
j
or
wi ¼ ð0 þ 22
i Þ0:5
Alternatively, if heteroscedasticity is related to predictors (Aitkin, 1987;
Cepeda and Gamerman, 2000) consider
yi ¼ i þ "i
where "i  Nð0; 
iÞ and let logð
iÞ ¼ Zi where Zi are additional pre-
dictors (or include some of the Xi). If the heteroscedasticity is related to
one predictor (e.g. Xi1) then one could set logð
iÞ ¼ 0 þ 1Xi1. Homo-
scedasticity would be shown by values of 1 not clearly differing from
zero.
72
REGRESSION FOR METRIC OUTCOMES

Dynamic linear (state-space) priors of various types for volatility in
regression errors have been proposed, especially for time series but with
relevance to other types of regression. For example, if the data are
arranged in ascending order of y then with i ¼ logðiÞ, an RW(1) prior
would take i  Nði1; Þ. A penalized spline method for heterosce-
dasticity is proposed by Ruppert et al. (2003) and illustrated below.
Example 3.6
Cherry Wood
Aitkin (1987) considers n ¼ 31 observa-
tions on the volume V of usable wood in cherry trees, in terms of the tree
heights H and diameters D. The actual model transforms V to reduce
skewness and heteroscedasticity, i.e.
V1=3
i
¼ 0 þ 1Hi þ 2Di þ "i
where "i  Nð0; 2Þ. However, examination of the residuals from this
model (model 1) suggests that their variation increases with height.
Therefore an alternative model (model 2) is heteroscedastic "i  Nð0;
expð0 þ 1Hi þ 2DiÞÞ. The criterion (2.12) shows that this model has
worse
ﬁt,
with
PrL2ð1Þ ¼ 0:40
and
PrL2ð1000Þ ¼ 0:49,
whereas
PrL1ð1Þ ¼ 0:33 and PrL1ð1000Þ ¼ 0:42. (Results are based on the second
half of a two-chain run of 100 000 iterations.) The coefﬁcients 1 and 2
are not well identiﬁed, i.e. 0.104 (with s.d. ¼ 0.076) and 0.036 (0.133)
from the second half of a two-chain run of 100 000 iterations.
The residual plots from both models 1 and 2 show the residuals most
widely scattered at middle values of i ¼ 0 þ 1Hi þ 2Di with their
dispersion tapering off for larger and smaller . Therefore one might
try, as model 3, taking logðwiÞ ¼ ð0 þ 1i þ 22
i Þ. This yields
PrL3ð1Þ ¼ 0:35 and PrL2ð1000Þ ¼ 0:45, with posterior means (s.d.) for
1 and 2 of 14.7 (5.5) and 2.1 (0.9).
Example 3.7
Student interview data
To illustrate alternative models
for skew data, this example follows Sahu et al. (2003) in considering
scores of 584 students on a non-academic skills rating scale. The data
suggest some negative skew (Figure 3.1). Relevant predictors are three
dummy indicators for gender–ethnicity. Thus X1 ¼ 1 for white male (0
otherwise), X2 ¼ 1 for non-white male (0 otherwise), X3 ¼ 1 for non-
white female (0 otherwise), so the reference category with average score
given by the intercept is white females. The ﬁt of the different models is
assessed by sampling new data and obtaining total predictive errors
squared, as in (2.10), as well as by the DIC, deﬁned as minus twice the
log likelihood. Sahu et al. (2003) cite a DIC of 2751 for the conventional
normal model.
ROBUST REGRESSION METHODS: SKEWNESS & HETEROSCEDASTICITY
73

For the skew normal a two-chain run of 10 000 iterations (convergent at
under 1000) shows a predictive criterion of 2125 and reduced DIC of
2697, obtained as 2D  Dð; Þ where  ¼ 1=2. The probability that 
in (3.6) is negative is obtained as 0.88; the parameter itself has a
positively skewed density. The j are all negative (with means 0.63,
0.88 and 1.05, and 95% intervals conﬁned to negative values)
indicating that the highest non-academic scores are for white female
student interviewees.
The alternative gamma prior for i
in (3.8) gives
D ¼ 2536,
Dð; Þ ¼ 2379 and a DIC of 2688; the predictive criterion is 1965.
The low ﬁrst observation Y1 ¼ 14 is predicted better under this option.
The method of Fernandez and Steel (1998b) gives
D ¼ 2739,
Dð; Þ ¼ 2733:3 and a DIC of 2745, slightly better than the usual
normal regression. However, the predictive criterion (2.10) worsens to
3760. The scaling parameter  is estimated as 0.91 with 95% interval
(0.85,0.98).
These data provide an illustration of a DPP prior (see section 3.7) as
there is repetition in both the predictor variables and the responses. So
instead of assuming n ¼ 584 random effects, one may assume clustering
Figure 3.1
Observed student ratings
74
REGRESSION FOR METRIC OUTCOMES

of students into a smaller total of random effects, such that many students
with the same or similar response/predictors have the same effect.
Accordingly replace the individual level prior for the skew normal, i.e.

i  Gað1; 1Þ, with i ¼ 
i  1 ði ¼ 1; . . . ; nÞ by assuming
Gi  CatðpÞ
where the probability vector p ¼ ðp1; . . . ; pKÞ governs allocation to one
of K ¼ 30 possible clusters. The K cluster effects follow
k ¼ 
k  1;

k  Gað1; 1Þ
and the sequence of pk follows (3.10). Then at a particular iteration,
having sampled k and Gi, one sets i ¼ Gi. Instead of n ¼ 584 random
effects there are a maximum of K cluster effects (not all the clusters need
to be chosen). A two-chain run of 5000 iterations (convergent from 1000)
shows an average of 21 clusters (with mean Dirichlet concentration
parameter 5.2), and a more clearly negative  in (3.21) with a 95%
interval ð2:9; 0:3Þ. This model produces D ¼ 2590, Dð; Þ ¼ 2502
and a DIC of 2678, so there appears to be a beneﬁt from reducing the
parameterization of the i.
3.5
ROBUSTNESS VIA DISCRETE MIXTURE MODELS
Finite mixture models provide a way to model complex observed
structures, approximating the sampling density by a mixture of K latent
subpopulations
fðyiÞ ¼
X
K
j¼1
jfjðyijjÞ;
i ¼ 1; . . . ; n
ð3:9Þ
where fjðjjÞ is a given parametric density such as the normal. At least
one parameter component of the density will vary over subpopulations:
for example, a mixture of normals might have a common variance
2
j ¼ 2, but would then necessarily have varying means. In the absence
of covariates there would be K different means j to estimate, and several
Bayesian model selection analyses focus on the optimal number of
subgroups in such situations (Richardson and Green, 1997). Applications
without predictors are usually seen as providing a smoothing of the mean
of each data value towards a value consistent with the full set of
observations.
Using the Gibbs sampler in discrete mixture estimation involves
augmenting the data with allocation indicators, and this means one can
ROBUSTNESS VIA DISCRETE MIXTURE MODELS
75

express the likelihood of the model in terms of ‘complete data’. It may be
necessary to use parameter constraints for identiﬁability (e.g. the prior on
the means of components is ordered) and even without constrained priors,
some information will be needed in the priors – improper priors lead to
undeﬁned posterior densities (Robert, 1996).
The most ﬂexible procedures for ﬁnite mixture models allow switches
in the number of subgroups K at each iteration, as in the reversible jump
algorithm (e.g. Hurn et al., 2003). This will produce a posterior density of
the number of subgroups K, such that one can derive a Bayes factor on
(say) a three-group mixture as against a two group mixture. A very
similar consequence follows the application of a truncated Dirichlet
process (see below), in that the density of non-empty clusters will
indicate the appropriate number of subpopulations.
In
regression
applications
with
predictors
Xi ¼ ðxi1; xi2; . . . ; xipÞ
together with an intercept, means may differ over subjects according to
their membership probabilities of groups with differing regression para-
meters j ¼ fj1; . . . ; jpÞ; j ¼ 1; . . . ; K. Regression model selection
may be applied to assess whether a particular regression parameter
(e.g. for xik) is equal over all subgroups jk ¼ k; j ¼ 1; . . . ; K, or within
subsets of the full set of groups (e.g. 1k ¼ 2k, but jk unequal for j > 2).
As illustrated by Dayton and Macready (1988), the unknown allocation
indicators Gi 2 ð1; . . . ; KÞ may also be modelled as functions of covari-
ates wi ¼ ðwi1; . . . ; wiqÞ such that the multinomial probabilities are
deﬁned by parameters
ij ¼ expðjwiÞ=
X
k
expðkwiÞ
3.5.1
Complete data representation
As mentioned by Diebolt and Robert (1994) and Dempster et al. (1977) a
ﬁnite mixture can be expressed in terms of the original data fyi; Xig and
augmented data consisting of the unknown categories Gi of group
membership. Gi may be equivalently stated in terms of binary indicators:
dij ¼ 1 when subject i is in group j and dij ¼ 0 otherwise. The likelihood
of the complete (observed and augmented) data fyi; Xi; Gig is
Y
J
j¼1
Y
n
i¼1
dij
j ½ fjðyijxijÞdij
The allocation of subjects to groups at each iteration as well as the
sampled values of the group parameters determine the complete data
likelihood, which may be monitored as one index of model ﬁt.
76
REGRESSION FOR METRIC OUTCOMES

In estimation via repeated sampling the indicators dij may switch
between subgroups (dðtÞ
ij ¼ 1 if subject i is allocated to component j at
iteration t). This can reﬂect both uncertainty about which group subject i
belongs to and an identiﬁcation problem known as ‘label switching’ (see
section 3.5.2). The complete data likelihood is unaffected by label
switching (as are some functions of the parameters such as means for
each observation).
By contrast to random effects models, the number of parameters will be
known in ﬁnite mixture models so that AIC measures may be obtained.
For DPP models the effective parameters may be estimated by comparing
the deviance at the mean DðjyÞ with the mean deviance or by counting
the number of non-empty clusters.
The complete data representation means that a mixture model can be
represented hierarchically, and such representations facilitate estimation
via repeated sampling. The highest level speciﬁes priors on the mixture
density parameters j, which in turn drive the densities for the latent class
indicators
Gi  gðGijjÞ
and the likelihood is
yi  fðyijj; dijÞ
The posterior probabilities of group membership for each subject, i.e.
ij ¼ Prðdij ¼ 1Þ, have the form
ij ¼ j fjðyijjÞ=
X
k
k fkðyijkÞ
Gibbs sampling in a ﬁnite mixture model includes the augmented data dij
as parameters and updates them according to
Gi  Categoricði1; i2; . . . ; iKÞ
If Tj ¼ P
i dij subjects are allocated to group j at iteration t and a prior
mass on group j is set at tj then the subpopulation proportions are updated
according to a Dirichlet
  DðT1 þ t1; T2 þ t2 ; . . . ; TK þ tKÞ
3.5.2
Identification issues
Repeated sampling of latent class mixture models where labelling is
relevant to inference (e.g. ﬁnite mixture models) may be problematic in
ROBUSTNESS VIA DISCRETE MIXTURE MODELS
77

terms of obtaining well-identiﬁed solutions. Setting K too large will mean
the solution is only identiﬁable with an informative prior that supplies an
adequate prior sample size for all subgroups. There is also a possibility
that ‘label switching’ will occur in MCMC estimation of ﬁnite mixture
models. If two or more chains are run with an unconstrained prior, there
is a strong chance that one chain will adopt a different labelling to the
other(s), even though within chains there is no label switching. This will
show in trace plots where (say) 1 in chain 1 is a high mean group, but in
chain 2 1 is a low mean group and they will never converge.
If an unconstrained prior with K groups is used, then the parameter
space has K! subspaces corresponding to possible ways of relabelling the
states. To avoid this one may ‘pin down’ the analysis by selected
parameter restrictions: for example, specifying that one mixture prob-
ability is always greater than another. Alternatively one or more density
or regression parameters might be subject to a constraint (e.g. for a
normal mixture one might specify a priori that 1 > 2 > . . . > K, or
alternatively that variances are ordered). A particular form of constraint
may be more or less appropriate to a particular data set. Exploratory
procedures have been proposed (Fru¨hwirth-Schnatter, 2001) to assess
whether a particular form of constraint will distort the solution more than
another. If in fact the subgroup means (say) are well separated then a
prior constraint to that effect will have little distorting effect on ﬁnal
parameter estimates. A constraint such as 1 > 2 > . . . > K may be
needed for the effective operation of ﬂexible mixture schemes that allow
for K to be stochastic, as in applications of the reversible jump method
(Richardson et al., 2002).
Another option (Celeux et al., 2000) applies clustering or other
procedures to the MCMC output from an unconstrained prior. This
involves ﬁrst selecting a relatively short run of MCMC iterations (say
T ¼ 100 iterations) where there is no label switching. The means
jk ¼ P
t jkt=T on parameters of type k in group j are then obtained
from this sample. For a normal mixture there will be three types of
parameters j ¼ fj; j; 2
j g and for K groups there will be 3K para-
meters. The initial run of sampled parameter values provides a reference
labelling (any one arbitrarily selected labelling among the K! possible). It
also enables deﬁnition of means of f; ; 2g under alternative (non-
reference) labelling schemes. In a subsequent run of R iterations where
label switching might occur, iteration r is assigned to that scheme that is
closest to it in distance terms and a relabelling is applied if there has been
a switch away from the reference scheme. The means under the schemes
are recalculated at each iteration T þ r (see Celeux et al., 2000, p 965).
78
REGRESSION FOR METRIC OUTCOMES

3.5.3
Dirichlet process mixture models
A ﬂexible mixture modelling structure is based on various forms of
Dirichlet prior process, which in applications may involve truncation at a
large number of potential groups or clusters K to which individual
observations i may belong. Ishwaran and James (2002) consider the use
of the truncated Dirichlet process to approximate a formal Dirichlet
process where the number of clusters is in theory inﬁnite.2 Unlike ﬁnite
mixture analysis, which requires that all component subpopulations
contain at least one sample member to be identiﬁed, the DPP model
allows empty clusters. DPP mixture models deﬁne a baseline prior H0
from which potential values for j are drawn.
While more than n clusters are possible, in practice a smaller number
K  n of potential clusters may be envisaged in any application (e.g.
K ¼ 10 or K ¼ 20). So j ¼ 1; . . . ; K values of j will be drawn from
H0 and the most appropriate value for case i among the candidate values
f1; 2; . . . ; Kg is selected using a categorical prior for the subpopula-
tion indicator Gi. In a normal mixture application without predictors the
DPP might be applied to selecting the means j most appropriate to each
subject, and one might take H0 to be a normal density N(0, V) with preset
large variance (e.g. V ¼ 1000) or V an additional unknown.
Then Gi ¼ j if group j is appropriate for subject i and
Gi  Categoricalð pÞ
where p ¼ ðp1; . . . ; pKÞ: The prior for the category probabilities p is
deﬁned by a ‘stick-breaking’ procedure. Let r1; r2; . . . ; rK1 be a
sequence of Beta(1,) random variables (with rK ¼ 1)
r1; r2; . . . ; rK1  Betað1; Þ
and set
p1 ¼ r1
p2 ¼ r2ð1  r1Þ
p3 ¼ r3ð1  r2Þð1  r1Þ
..
.
pM ¼ rKð1  rK1Þð1  rK2Þ    ð1  r1Þ
ð3:10Þ
2 If the sample size is n and truncation at K clusters is assumed then the marginal density for a
normal mixture obtained under the truncated Dirichlet process can be compared with that under the
inﬁnite random measure of Ferguson (1973). The discrepancy in terms of an L1 error bound is
approximately 4n exp½ðK  1Þ=.
ROBUSTNESS VIA DISCRETE MIXTURE MODELS
79

The number K of non-empty clusters (between 1 and K) depends in
practice on the so-called concentration parameter , which may be preset
or itself assigned a prior. Other names for  include mass parameter and
precision parameter.
Typical values of  (if it is preset) are between 1 and 5. Smaller values
of  lead to solutions (when the data have no predictors) resembling a
ﬁnite mixture model with a few subgroups, while large  leads to a
smoother appearance. Ishwaran and James (2002) suggest a gamma
Ga(
1; 
2) prior for , with its updating taking place according to the
conditional
fðjÞ  Ga K þ 
1  1; 
2 
X
K1
k¼1
logð1  rkÞ
 
!
Let Tk be the number of subjects for whom Gi ¼ k. Then the conditional
for rk (which deﬁnes the cluster probabilities pkÞ is
rk  Beta 1 þ Tk;  þ
X
K
j¼kþ1
Tk
 
!
A predictive density for a future observation ynew can be obtained by
sampling (at each iteration) as follows: Gnew  Categoricalð pÞ and then
ynew  fðyjGnewÞ. This provides a way of plotting the implied predictive
density.
Example 3.8
Galaxy data
These data relate to N ¼ 82 velocities of
galaxies in the Corona Borealis region. Different analyses have suggested
different numbers of components K in a discrete normal mixture for such
data. With K given the mixture density is denoted
fðYjjK; jK; jKÞ ¼
X
K
j¼1
jKðYijjK; jKÞ
Thus for K ¼ 2 the parameters are f12; 12; 12; 22; 22; 22g while for
K ¼ 3 the parameters are f13; 13; 13; 23; 23; 23; 33; 33; 33g. Four
models with K ¼ 2; 3, 4 and 5 respectively are compared with priors
jK  N(20, 25) on the component means, while Dirichlet priors with
K-vector components of 1 are used for jK. The precisions 1=jK are taken
to be Ga(1, 0.001).
The method of parallel sampling (section 2.8) is used to assess the
posterior probabilities of the different mixture densities. The prior
adopted on jK means that model weights are unaffected by relabelling
80
REGRESSION FOR METRIC OUTCOMES

of parameters at a particular iteration. So it is not necessary to apply
parameter constraints in order to obtain the optimal K. As well as the
total model ﬁt criteria, the estimated means for individual cases are
unaffected by relabelling. These are obtained at iteration t as
GðtÞ
iK
where GðtÞ
iK is a latent observation-speciﬁc index variable with values
between 1 and K. Hence one might average the predicted means of
selected cases (e.g. the minimum and maximum y) in order to assess how
well the different mixture models are representing these extreme points
and also to obtain a model averaged mean for these observations at a
particular iteration. For example, assuming ranked data yn 	 yn1 	
. . . 	 y1, the maximum value yn is predicted at iteration t as
ðtÞ
n ¼ wðtÞ
1 GðtÞ
n2 þ wðtÞ
2 GðtÞ
n3 þ wðtÞ
3 GðtÞ
n4 þ wðtÞ
4 GðtÞ
n5
There are J ¼ 4 models comparing K ¼ 2; 3; 4 and 5 groups. A two-chain
run of 5000 iterations (with a 1000 burn-in) and prior model probabilities
Pðm ¼ jÞ ¼ 1=4
gives
w1 ¼ 0:0005,
w2 ¼ 0:907,
w3 ¼ 0:084
and
w4 ¼ 0:008, so the K ¼ 3 model is preferred, though not overwhel-
mingly, and different priors might affect the choice. Carlin and Chib
(1995) compare K ¼ 3 and K ¼ 4 and obtain PðK ¼ 3jyÞ as 0.64;
Moreno
and
Lisco
(2003)
compare
K ¼ 1; 2; 3; 4; 5
and
obtain
PðK ¼ 3jYÞ ¼ 0:84, PðK ¼ 4jYÞ ¼ 0:1599 with negligible weights on
the other values of K. The maximum observed velocity (in thousands) is
y82 ¼ 34:28 and under models 1 to 4 this observation has means 21.9,
31.75, 31.8 and 31.9 respectively. So the model with K ¼ 3 adequately
represents the maximum observation. (Of course other model checks may
be carried out in addition.) The model averaged 82 (with 95% credible
interval) is 31.77 (29.3, 34.1).
A DPP model is then applied with a cluster upper limit K ¼ 20 and
the values f
1; 
2g ¼ ð2; 4Þ for the prior on , as assumed by Escobar
and West (1995) in their analysis of these data. Note that more diffuse
priors, such as f
1; 
2g ¼ ð0:1; 0:1Þ, will lead to larger numbers of non-
empty clusters being identiﬁed. Let Kj; y be the number of distinct y values
(number of non-empty clusters). Then a two-chain run of 5000 iterations
shows nine as the modal number of clusters (see Table 3.4), considerably
higher than implied by the standard non-parametric mixture approach.
The mean for 82 is now 33.1, a more accurate estimate but at the cost
of heavier parameterization. The predictive density for a new observation
shows the greater heterogeneity implied by this model (Figure 3.2).
ROBUSTNESS VIA DISCRETE MIXTURE MODELS
81

3.6
NON-LINEAR REGRESSION EFFECTS VIA SPLINES
AND OTHER BASIS FUNCTIONS
The linear model of (3.1), namely
yi ¼ 0 þ 1xi1 þ 2xi2 þ    þ pxip þ "i
assumes a known form (an additive linear impact of the predictors) with
the main issue being the identiﬁcation of signiﬁcant predictors given the a
priori assumption of linearity. If one or more of the predictors, say xik, has
a non-linear impact on y then known regression forms (e.g. polynomial
regression or the Box–Cox transform in section 3.4) are also available.
However, while sometimes non-linear functions may be based on subject
Table 3.4
Posterior probabilities for number of distinct y values (non-empty
clusters)
k
6
7
8
9
10
11
12
>12
Pr(K ¼ k)
0.033
0.108
0.186
0.219
0.180
0.134
0.079
0.061
Figure 3.2
Predictive density for new y
82
REGRESSION FOR METRIC OUTCOMES

matter knowledge, there is often little knowledge concerning an appro-
priate non-linear function.
One may instead simply assume that the regression surface for xik is
smooth but try to estimate its unknown non-linear form. This approach,
known as non-parametric regression, estimates a function that adapts to
the underlying true form. Methods for modelling yi as a general non-
linear function of one or more predictors mostly assume linear combina-
tions of basis functions BðxikÞ of predictors. Examples of basis functions
are truncated polynomial or spline functions (Friedman and Silverman,
1989) or more recent models discussed by Denison et al. (2002), such as
multivariate linear splines, wavelets and multivariate adaptive regression
splines.
Assume a single predictor with values ordered
x1 < x2 <    < xn
and let the mean of y be represented as a function of x, with a random
error representing residual effects
yi ¼ 0 þ BðxiÞ þ "i
Assume also one or more predictors wi1; wi2; . . . ; wim have a conventional
linear effect; then a semi-parametric model is obtained. For example, a
single w predictor and an adaptive regression in a single x give
yi ¼ 0 þ 1wi þ BðxiÞ þ "i
Spline functions to approximate Bi ¼ BðxiÞ include quadratic and cubic
splines, i.e. piecewise quadratic or cubic polynomials that interpolate
(x) at K selected knot points t1; t2; . . . ; tK within the range of the
variable x, such that minðxiÞ < t1 < t2 < . . . < tK < maxðxiÞ. A cubic
regression spline for metric y and with homoscedastic normal errors has
typical form
yi  Nði; 2Þ
i ¼ 0 þ BðxiÞ
BðxiÞ ¼ 1xi þ 2x2
i þ 3x3
i þ
X
K
k¼1
1ðxi  tkÞkðxi  tkÞ3
where 1ðxi  tkÞ is one if xi exceeds the kth knot tk, and zero otherwise.
An alternative notation with the same meaning is
BðxiÞ ¼ 1xi þ 2x2
i þ 3x3
i þ
X
K
k¼1
kðxi  tkÞ3
þ
ð3:11Þ
NON-LINEAR REGRESSION EFFECTS
83

where ðxi  tkÞþ ¼ maxð0; xi  tkÞ. Sometimes the terms 1xi, 2x2
i ; 3x3
i
are omitted, so that i ¼ 0 þ BðxiÞ with
BðxiÞ ¼
X
K
k¼1
kðxi  tkÞ3
þ
ð3:12Þ
Denison et al. (2002, p 74) discuss issues around prior speciﬁcation in
(3.11) which are resolved in a two-sided cubic spline model
BðxiÞ ¼
X
K
k¼1
kðxi  tkÞ3
þ þ
X
2K
k¼Kþ1
kðtk  xiÞ3
þ
There is no certainty on how many knot points to include or where to
locate them. More knots are needed in regions where BðxÞ is changing
rapidly (Eubank, 1988). Sometimes subject knowledge may be relevant in
placing knots where a change in the shape of the curve is expected:
human mortality shows a ‘bathtub’ shape with minimum mortality around
age 10. Using too few knots or poorly sited knots means the approxima-
tion to the true curve BðxÞ will be degraded. By contrast, a spline using
too many knots will be imprecise.
Knots may be based on selecting among the existing x values (e.g.
Friedman and Silverman, 1989), might be equally spaced within the
range [min(x), max(x)] as in Biller (2000), or be taken as unknowns.
Another approach is based on ‘smoothing splines’ whereby there is a
knot, or potential knot, at each distinct value of xi so that the number of
knots may equal the sample size. For n large, selection is required so that
K  n. For example, Ruppert et al. (2003) suggest a maximum of
K ¼ 35 or 40.
Starting with a relatively large number of candidate knot locations,
regression selection may be used to select signiﬁcant knot points (Smith
and Kohn, 1996; Smith et al., 2001). Smith and Kohn (1996) suggest
indicator variables 1k (for 1; . . . ; 3 in the polynomial part of the cubic
spline (3.11) and 2k (for the k ¼ 1; . . . ; K spline coefﬁcients k) such
that if, at a particular iteration, the indicator variables are zero (one) then
the corresponding predictor is excluded (included).
Alternatively, under a free knot approach, the knots can take any values
within the range [min(x),max(x)] and are not tied to selecting from the
observations (e.g. Denison et al., 1998a). Note that for a known number
of knots, a prior on knots with free location speciﬁes their ordering and
84
REGRESSION FOR METRIC OUTCOMES

might take the form
t1  Nð0; VÞIðminðxÞ; t2Þ
t2  Nð0; VÞIðt1; t3Þ
...
tK  Nð0; VÞIðtK1; maxðxÞÞ
ð3:13Þ
where V is known (e.g. V ¼ 1000) or an extra parameter. Biller (2000)
and Denison et al. (1998a) use reversible jump MCMC to allow switch-
ing between models with different numbers and sitings of free knots.
Denison et al. (1998a) make the simpliﬁcation of calculating  and 
coefﬁcients by standard least squares formulae rather than the full
Bayesian prior/posterior updating procedure.
3.6.1
Penalized random effects for spline coefficients
Berry et al. (2002) and Ruppert et al. (2003) avoid regression selection
among ﬁxed effects k by using penalizing random effects priors on the 
coefﬁcients. These may link the variance 2
 of the k to Var("Þ ¼ 2 and
so induce varying degrees of constraint on the k. Under this approach a
linear spline is often appropriate except for highly non-linear regression
effects, though it may involve increasing K till a satisfactory ﬁt is obtained.
Let nu be the number of distinct x values. Ruppert et al. (2003, 126)
recommend K ¼ minð35; nu=4Þ, though values such as K ¼ 80 may
occasionally be needed, for n sufﬁciently large. The knots might
correspond to percentiles in the observed x (Berry et al., 2002): for example,
tk sited at the percentile k=ðK þ 1Þ. For example, if K ¼ 19 then the knots
are located at every ﬁfth percentile of x. Then a spline of degree q is
yi ¼ 0 þ 1xi þ    þ pxq
i þ
X
K
k¼1
kðxi  tkÞq
þþ þ "i
ð3:14Þ
where k  N(0, 2
) and q ¼ 1 gives a linear spline. The full condi-
tionals on 1=2
 and 1=2 are
1=2
  Ga a1 þ 0:5K; b1 þ 0:5
X
K
k¼1
2
k
 
!
1=2  Ga a2 þ 0:5n; b2 þ 0:5
X
n
i¼1
"2
i
 
!
NON-LINEAR REGRESSION EFFECTS
85

where 1=2
  Gaða1; b1Þ; 1=2  Gaða2; b2Þ are the priors on the preci-
sions. This approach may be extended to modelling heteroscedasticity
and so provide a ‘spatially adaptive’ non-linear smooth. Thus let
"i  Nð0; 2
i ); then a non-constant variance would involve an additional
spline model
logð2
i Þ ¼ ’0 þ ’1xi þ    þ ’qxq
i þ    þ
X
M
k¼1
kðxi  tkÞq
þ
ð3:15Þ
Usually M < K (see Ruppert and Carroll, 2000).
3.6.2
Basis function regression
As noted above, one may replace the conceptual framework of the linear
regression model
yi ¼ 0 þ 1xi1 þ 2xi2 þ    þ pxip þ "i
by a more general class of basis function models (Denison et al., 2002)
with
yi ¼ 0 þ
X
M
m
X
Km
k
mkBmkðXiÞ þ "i
where each BmkðXiÞ is a function of one or more xij; j ¼ 1; . . . ; p. In
matrix terms
Y ¼ 10 þ B þ "
where Y, 1 and " are n  1;  is L  1 where L ¼ PM
m Km, and B is n  L
with
B ¼
B11ðX1Þ
  
BMKMðX1Þ
..
.
..
.
..
.
B11ðXnÞ
  
BMKMðXnÞ
2
64
3
75
For example, if p ¼ 1 with Xi ¼ xi then the truncated power splines can
be written, following the simpliﬁed (3.12), as
yi ¼ 0 þ
X
K
k
kðxi  tkÞq
þ þ "i
86
REGRESSION FOR METRIC OUTCOMES

Setting q ¼ 1 gives a truncated linear spline and q ¼ 3 the truncated
cubic spline. A similar model with more than one predictor might allow
differing numbers of knots and degrees between predictors, but still
limited to univariate splines in each. Thus
yi ¼ 0 þ B1ðxi1Þ þ B2ðxi2Þ þ    þ BpðxipÞ þ "i
¼ 0 þ
X
K1
k
k1ðxi1  tk1Þq1
þ þ
X
K2
k
k2ðxi2  tk2Þq2
þ
þ    þ
X
K2
k
kpðxip  tk2Þq2
þ þ "i
ð3:16Þ
with M ¼ p and L ¼ K1 þ K2 þ    þ Kp.
3.6.3
Special spline functions
Special spline forms have been proposed to deal with possible interac-
tions between variables or reduce ill-conditioning in regression problems.
To allow for interactions between predictors in such spline functions, one
may consider products such as
Bkðxi1; xi2Þ ¼ ½xi1  tk1q1
þ½xi2  tk2q2
þ
for knots k1 ¼ 1; . . . ; K1 and k2 ¼ 1; . . . ; K2. With a linear form
ðq1 ¼ q2 ¼ 1Þ such products ﬁgure in the Bayesian MARS approach
(Denison et al., 1998b):
Bkðxi1; xi2Þ ¼ ½xi1  tk1þ½xi2  tk2þ
ð3:17Þ
A two-sided spline form allows one or both terms in the above example to
be of the form ½t  xþ rather than ½x  tþ, for instance
Bkðxi1; xi2Þ ¼ ½xi1  tk1q1
þ½tk2  xi2q2
þ
Alternatively one may write a typical term ðx  t0Þþ in a truncated
univariate linear spline as a dot product ½ð1; xÞ ðt0; 1Þþ. This suggests
the multivariate generalization (Holmes and Mallick, 2001)
Bðxi1; xi2; . . . ; xipÞ ¼ ½ð1; x1; x2; x3; . . . ; Þðt0; t1; t2; t3; . . .Þþ
Without loss of generality, the minus sign may be omitted from t0,
giving
Bðxi1; xi2; . . . ; xipÞ ¼
t0 þ
X
p
j
tjxij
 
!
þ
ð3:18Þ
NON-LINEAR REGRESSION EFFECTS
87

So, in addition to ‘main effect splines’ as in (3.16) one might have
p
2


interaction splines of order 2, as deﬁned by (3.18). For example, if p ¼ 3,
then there are three second-order interaction splines
B1ðxi1; xi2Þ ¼ ðt10 þ t11xi1 þ t12xi2Þþ
B2ðxi1; xi3Þ ¼ ðt20 þ t21Xi1 þ t23xi3Þþ
B3ðxi2; xi3Þ ¼ ðt30 þ t31xi2 þ t33xi3Þþ
Then M ¼ 6 since there are three main effect splines in this example and
three second-order splines. Holmes and Mallick (2001) and Denison et al.
(2002) consider a framework allowing jumps between interactions of
order 1, 2 and higher, so that main effect splines are nested within
interaction splines. A full model for p ¼ 3 might take the form
yi ¼ 0 þ 1B1ðxi1; xi2Þ þ 2B2ðxi1; xi3Þ þ 3B3ðxi2; xi3Þ þ 4B4ðx1iÞ
þ 5B5ðx2iÞ þ 6B6ðx3iÞ þ "i
raising identiﬁcation issues3 involving the  and t coefﬁcients.
One possible problem with truncated power splines such as (3.11) is
that they may be ill-conditioned in terms of the regression model, with
the normal equations difﬁcult to solve (Eubank, 1988). Specialized
versions of cubic splines such as natural cubic splines have been
suggested; natural splines reduce to straight lines when x is below the
smallest knot or above the largest, namely tK. An alternative basis less
prone to ill-conditioning is provided by B splines. Consider a B spline of
degree D, with K interior knots and deﬁne m ¼ D þ 1, and boundary
3 Holmes and Mallick (2001) suggest sampling tkj (for j > 0) from a G(1,1) density and then
normalizing by dividing each tkj by the sum of squared tkj involved in the spline. For example, in B1
one obtains
t
11 ¼ t11=½t2
11 þ t2
12
t
12 ¼ t12=½t2
11 þ t2
12
The tk0 coefﬁcients are obtained by sampling from a uniform (discrete) density over all n subjects,
Let Jk be the number of tkjðj > 0Þ coefﬁcients in spline k, e.g. in B1, B2 and B3; Jk is 2. Also let Wkj
denote the predictors included in the kth spline, e.g. in B1ðX1Þ, W11 ¼ 1 and W12 ¼ 2. With
probability 1=n, tk0 takes the one among f1; . . . ; ng of the subject-speciﬁc sums

X
Jk
j
XiWkjtkj
This device ensures that the plane for basis k passes through at least one observed data point.
88
REGRESSION FOR METRIC OUTCOMES

points a  minðxÞ, b 	 maxðxÞ. Then 2m additional knots are required
with
tD ¼ tD  1 ¼    ¼ t0 ¼ a
tKþ1 ¼    ¼ tKþm ¼ b
The B spline has to be evaluated at the observed points between a and b,
and may be deﬁned by the recursion (see De Boor, 1978; MacNab and
Dean, 2001)
BjiðxÞ ¼ ðx  tjÞBj;i1ðxÞ=ðtjþi1  tjÞ þ ðtjþi  xÞBjþ1;iðxÞ=ðtjþi  tjþ1Þ;
j ¼ D; . . . ; k; i ¼ 1; . . . ; m
ð3:19Þ
In this recursion any term of the two on the right involving division by
tjþi1  tj when tjþi1 ¼ tj (or by tjþi  tjþ1 when tjþi ¼ tjþ1) is deﬁned as
zero. The initial terms Bj1ðxÞ in the recursion are simply indicators
deﬁning a partition of the x values.
For example, for a cubic ðD ¼ 3Þ B spline with K ¼ 2 knots there are
three non-zero initial indicator functions
B01ðxÞ ¼ 1
if x 2 ða; t1Þ;
0 otherwise
B11ðxÞ ¼ 1
if x 2 ðt1; t2Þ;
0 otherwise
B21ðxÞ ¼ 1
if x 2 ðt2; bÞ;
0 otherwise
All other Bj1ðxÞ functions are zero, namely B3;1ðxÞ, B2;1ðxÞ and
B1;1ðxÞ. There are four non-zero functions Bj;2ðxÞ deﬁned by the
recursion (3.19) with j ¼ 1; . . . ; 2. For example,
B1;2ðxÞ ¼ ðt1  xÞB01ðxÞ=ðt1  aÞ ¼ ðt1  xÞ=ðt1  aÞ
There are ﬁve non-zero functions Bj3ðxÞ, j ¼ 2; . . . ; 2 and m þ K ¼ 6
non-zero polynomial functions Bj4ðxÞ (with j ¼ 3; 2; . . . ; 2) that
deﬁne the basis. The smooth at an observed value x is deﬁned as
SðxiÞ ¼
X
mþK
j¼1
jBjm;mðxiÞ
where j are parameters to be determined.
Example 3.9
Titanium and heat
Eubank (1988, p 395) presents data
on a property of titanium as a function of heat. An optimal ﬁve-knot
solution is known to be at the heat values (836, 876.4, 898.1, 916.3,
973.9) with these points representing the hump in y for values of x
between 800 and 1000. Among ways to ﬁt a smooth to these data might
be truncated polynomial or B splines with regression selection among
NON-LINEAR REGRESSION EFFECTS
89

knots at equally spaces in the range of x; for example, ten equally spaced
points over 785 to 1055.
Here a knot total K ¼ 5 is initially assumed (model A), and unknown
knot locations with prior as in (3.13), with parameters {, } derived by
conventional least squares formulae (cf. Denison et al., 1998a). With
early convergence in a two-chain run the estimates in Table 3.5 are
obtained by pooling over iterations 1000–1500, and a close ﬁt is obtained.
The total error sum of squares (between Yi and the posterior means ^Si
of the Si) is 0.0075.
A complete Bayesian analysis with both unknown knot locations and
with parameters {, } subject to posterior updating is more computa-
tionally intensive and may pose identiﬁability issues. McCullagh and
Nelder (1989, p 380) note such problems in non-linear models involving
sums of exponentials. Here a fully Bayes implementation of this option
includes predictor selection as in Smith and Kohn (1996), since an
analysis without such selection suggested 1  3 to be effectively
zero. Priors on the knots were based on the ﬁrst model, though with
downweighted precision (prior variance of 20). The prior for the intercept
is based on that of Raftery et al. (1996). The last 50 000 iterations of a
two-chain run of 250 000 iterations show an error sum of squares 0.045,
inﬂated by the uncertainty introduced by making predictor effects
additional unknowns (see Figure 3.3). The posterior means (and s.d.) of
the knots are 829.5 (1.4), 867.8 (2.2), 906.1 (1), 917.4 (0.6) and 986.6
(4.5).
Finally two models taking the knots known at the optimal values (of
model A) are applied. These are truncated cubic spline and a B spline (see
Example3_9.xls for derivation of the spline coefﬁcients). Predictor
selection is not used. The B spline gives an error sum of squares of
0.035 and the truncated cubic spline one of 0.01.
Depending on the focus of interest one might for a simpliﬁed analysis
apply the model A approach, with either truncated polynomial or B
Table 3.5
Posterior knot densities, K ¼ 5
Mean
S.d.
2.5%
97.5%
835.2
2.5
830.4
840.0
878.4
2.7
874.2
884.1
895.4
4.3
887.1
902.2
917.8
3.1
911.6
923.4
973.3
4.9
964.2
982.7
90
REGRESSION FOR METRIC OUTCOMES

splines, for a few alternative numbers of knots (e.g. K ¼ 4, K ¼ 5,
K ¼ 6). Then model C can be applied with the knots assumed known
(at their posterior means from model A).
Example 3.10
Vitamin in turnip green
Draper and Smith (1966)
present data (Table 3.6) from a study concerning vitamin B2 content in
turnip green in relation to three predictors. These are X1, radiation
in relative gram calories per minute in the preceding half-day (divided
by 100), X2, the average soil moisture tension (divided by 100), and
X3, the Fahrenheit temperature (divided by 100). They refer to an earlier
model
chosen
by
Anderson
and
Bancroft
(1959)
of
the
form
yi ¼ 0 þ 1xi1 þ 2xi2 þ 3xi3 þ 4xi1xi2 þ "i.
Here we ﬁrst ﬁt (models A and B in Program 3.10) a normal linear
regression with binary selection (see section 3.2) and with predictors
fX1; X2; X3; X1X2; X1X3; X2X3g calculated after centring X1  X3. The
results suggest that only X2 merits inclusion and all other main effects
and all interactions are not needed, though the interaction between X1 and
X2 has the highest posterior probability of inclusion. The coefﬁcient for
X2 has mean 78 and 95% interval ð96; 60Þ, and the deviance of a
model with only X2 as predictor is 48.5, with predictive error sum of
squares 71. This is obtained (see section 2.4) by sampling new data Zi and
comparing it with the observations.
0.5
0.7
0.9
1.1
1.3
1.5
1.7
1.9
2.1
2.3
575
675
775
875
975
1075
Actual
Fitted
Figure 3.3
Titanium and heat
NON-LINEAR REGRESSION EFFECTS
91

A multivariate linear spline (MLS) analysis with binary selection among
the six basis functions for fX1; X2; X3; X1X2; X1X3; X2X3g is then
applied (model C in Program 3.10). The results of this analysis replicate
the ﬁndings based on the standard linear model, since only the basis for
X2 has a posterior probability of inclusion (namely, 0.97) exceeding the
prior probability of 0.5. However, the interactions X1X2 and X2X3 have
the second and third highest posterior probabilities, around 0.52 and 0.42.
These probabilities are considerably higher than under the linear model.
It is possible to rerun the model only with the signiﬁcant effects (as in
model D in Program 3.10). From the viewpoint of obtaining predictions
Table 3.6
Turnip green data
Obs.
X1
X2
X3
Y
X1  X2
1
1.76
0.07
7.8
110.4
0.123
2
1.55
0.07
8.9
102.8
0.109
3
2.73
0.07
8.9
101
0.191
4
2.73
0.07
7.2
108.4
0.191
5
2.56
0.07
8.4
100.7
0.179
6
2.8
0.07
8.7
100.3
0.196
7
2.8
0.07
7.4
102
0.196
8
1.84
0.07
8.7
93.7
0.129
9
2.16
0.07
8.8
98.9
0.151
10
1.98
0.02
7.6
96.6
0.040
11
0.59
0.02
6.5
99.4
0.012
12
0.8
0.02
6.7
96.2
0.016
13
0.8
0.02
6.2
99
0.016
14
1.05
0.02
7
88.4
0.021
15
1.8
0.02
7.3
75.3
0.036
16
1.8
0.02
6.5
92
0.036
17
1.77
0.02
7.6
82.4
0.035
18
2.3
0.02
8.2
77.1
0.046
19
2.03
0.474
7.6
74
0.962
20
1.91
0.474
8.3
65.7
0.905
21
1.91
0.474
8.2
56.8
0.905
22
1.91
0.474
6.9
62.1
0.905
23
0.76
0.474
7.4
61
0.360
24
2.13
0.474
7.6
53.2
1.010
25
2.13
0.474
6.9
59.4
1.010
26
1.51
0.474
7.5
58.7
0.716
27
2.05
0.474
7.6
58
0.972
92
REGRESSION FOR METRIC OUTCOMES

of y that reﬂect model uncertainty, a form of model averaging results
from allowing all possible basis functions to be relevant, as in model C
(Denison et al., 2002, p 56; Smith and Kohn, 1996). A two-chain run of
10 000 iterations (convergent by 1000) of model C shows 2.75 as the
average number of basis functions retained, with mean deviance as 46.9
and predictive error sum of squares of 59.3. The latter criterion is more
favourable to the MLS model than a deviance comparison.
Finally model E applies a MARS model involving single knot terms in
X1, X2 and X3 and spline products for fX1; X2g and fX2; X3g as in (3.17):
yi ¼ 0 þ 1½xi1  t1þ þ 2½xi2  t2þ þ 3½xi3  t3þ
þ 4½xi1  t4þ½xi2  t5þ þ 5½xi2  t6þ½xi3  t7þ þ "i
This gives a mean deviance and predictive error sum of squares similar to
that for model C, namely 47.4 and 62.6. The coefﬁcient 2 is clearly
signiﬁcant as we would expect from previous analysis, while the knot
estimate t2 ¼ 0:1 essentially separates observations 1–18 from observa-
tions 19–27.
Example 3.11
Penalized spline for light detection and ranging
Ruppert et al. (2003) consider 221 observations on reﬂection of light
from lasers in order to measure mercury in the atmosphere (Figure 3.4).
The independent variable is the distance travelled before the light is
reﬂected back and the response is the log of the ratio of received light
−1.0
−0.8
−0.6
−0.4
−0.2
0.0
0.2
375
425
475
525
575
625
675
725
775
Range
Figure 3.4
LIDAR data
NON-LINEAR REGRESSION EFFECTS
93

from two lasers. One has a resonance frequency equal to that of mercury,
the other has an alternate frequency.
The data show clear non-linearity and an increased scatter in the y–x
relationship at higher x. A penalized spline model is applied assuming a
constant conditional variance Var(yjx) (model 1) and then a heterosce-
dastic model (model 2). K ¼ 23 knots are used, located at the 8th, 12th,
16th; . . . ; 96th percentiles. Thus in the ﬁrst model a linear spline for the
regression means is
yi ¼ 0 þ 1xi þ
X
K
k¼1
kðxi  tkÞþ þ "i
where k  Nð0; 2
Þ and "i  Nð0; 2Þ. Ga(0.1, 0.1) priors are assumed
on both precision parameters. In the second model the regression mean is
the same but the variance is non-constant according to
logð1=2
i Þ ¼ ’0 þ ’1xi þ
X
K
k¼1
kðxi  tkÞþ
The ﬁt for both models is assessed using predictions of new data and the
criterion in (2.12) with k ¼ 1 and k ¼ 1000.
For model 1, the second half of a two-chain run of 20 000 iterations
shows PrL1ð1Þ ¼ 2:51 and PrL1ð1000Þ ¼ 3:28. By contrast, model 2
shows PrL1ð1Þ ¼ 2:36, PrL1ð1000Þ ¼ 3:05 and a close ﬁt to the data
(Figure 3.5).
−1.0
−0.8
−0.6
−0.4
−0.2
0.0
0.2
1
21
41
61 81
101
121
141
161
181
201
221
Observation
Log ratio
Data
Smooth
Figure 3.5
LIDAR data smooth via heteroscedastic model
94
REGRESSION FOR METRIC OUTCOMES

3.7
DYNAMIC LINEAR MODELS AND THEIR APPLICATION
IN NON-PARAMETRIC REGRESSION
For univariate or multivariate outcomes a dynamic linear model describes
the evolution of observations yt in terms of unobserved continuous states
t. Such models may apply equally to time or over the space of predictors
arranged in ascending order. For simplicity a time frame is initially
adopted. Thus a dynamic linear model (DLM) consists of an observation
equation specifying the distribution of yt, conditional on the states t, and
a state equation specifying how the states change dynamically (Berliner,
1996; Meyer, 2000). A ﬁrst-order Markov dependence in t leads to a
model such as
ytjt ¼ f1ðt; Þ þ "t
t ¼ f2ðt1; Þ þ !t
where f1 and f2 may be linear or non-linear functions and typically the "t
are normal with variance 2. Linear forms for these two equations are
often used and typically involve a design matrix Ft specifying which
latent states and covariates impact on the outcome, while the state
equation involves a transition matrix Gt for describing how latent state
values at successive times are related. Thus
yt ¼ Ftt þ "t
ð3:20aÞ
t ¼ Gtt1 þ !t
ð3:20bÞ
Suppose yt is multivariate of dimension m and t of dimension d, so that
Ft is m  d and Gt is d  d. Even though yt might be univariate ðm ¼ 1Þ,
t may be of dimension d greater than one. In this case some of the design
matrix elements will be zero.
Unless the analysis conditions on some early observations, initializing
prior assumptions are needed for the initial latent state values. In a ﬁrst-
order Markov scheme for t these would consist of a single parameter 0
which is usually assigned a diffuse prior. The errors "t and !t in (3.20) are
generally taken to be mutually uncorrelated and not correlated with the
initial latent state values.
Different MCMC sampling schemes have been proposed for DLMs
according to the form of outcome. Carlin et al. (1992) suggest a Gibbs
sampling scheme where the states are updated individually based on the
conditional densities of the components pðjtj½jt; ; Y, where  spe-
ciﬁes the observation (co)variances and state (co)variances. More efﬁ-
cient M–H updating schemes (Carter and Kohn, 1994; Fru¨hwirth-
DYNAMIC LINEAR MODELS IN NON-PARAMETRIC REGRESSION
95

Schattner, 1994a; 1994b) involve block updating for the state vector
based on the densities pðtj; YÞ but may reduce modelling ﬂexibility.
Other computational aspects are relevant to the identiﬁability of models
involving state-space priors. For example, priors such as (3.20) do not
usually specify a level for the t series, and so devices such as recentring
at each MCMC iteration, to ensure the effects sum to zero, assist in
convergence. Other options might be to set one or more initial parameters
to zero (Koop, 2003).
3.7.1
Some common forms of DLM
The general form (3.20) may be illustrated by commonly used models for
a univariate outcome. An additive model involving an underlying trend t
ð 1tÞ, a periodic component tð 2tÞ and an uncorrelated error "t is
yt ¼ t þ t þ "t
One possible trend scheme involves a linear trend through time and an
additional unknown series t
t ¼ t1 þ t1 þ !1t
t ¼ t1 þ !2t
where !1t and !2t are uncorrelated over time and independent of each
other. For trend or regression coefﬁcients other commonly used schemes
are the ﬁrst- and second-order random walks, typically taken to be normal
(Fahrmeier and Knorr-Held, 2000). The ﬁrst-order random walk, some-
times denoted RW(1), has the form
t ¼ t1 þ !t
where !t  Nð0; Þ or equivalently t  Nðt1; Þ. The ﬁrst-order
random walk penalizes large discontinuities between successive values,
especially if the prior on  favours relatively small variances. The
second-order random walk, or RW(2) model, has the form
t ¼ 2t1  t2 þ !t
or equivalently t  Nð2t1  t2; Þ. This prior penalizes large
deviations from the linear trend 2t1  t2. As an example of how
Ft and Gt in (3.20) are speciﬁed, consider a model with yt ¼ t þ "t, and
t following an RW(2) prior t  Nð2t1  t2; Þ. Then
t ¼
t
t1


¼
2
1
1
0


t1
t2


þ
!t
0


and yt ¼ ð1; 0Þt þ "t.
96
REGRESSION FOR METRIC OUTCOMES

In the RW(1) and RW(2) models there are respectively one and two
initial values to consider, namely 0 ¼ f0g and 0 ¼ f0; 1g. These
are typically assigned diffuse priors – though see Carlin et al. (1992) and
Berzuini and Larizza (1996) for examples of more informative initial
priors. In the RW(1) model one might take 0  Nð0; V0Þ with V0 large
and known (say V0 ¼ 1000).
While apparently asymmetric these priors may be written in undirected
form. For example, assume normal errors !t and "t
yt ¼ t þ t þ "t
t ¼ t1 þ !t
with precisions  ¼ 1=2 and   ¼ 1=. Then the full conditionals for
t ðt ¼ 2; . . . ; T  1Þ are normal with means
ð ðtþ1 þ t1Þ þ  ytÞð2  þ  Þ1
and variances 1=ð2  þ  Þ, making clear a pooling of strength both
forward and backward in time. The conditional for 1 has mean
ð 2 þ  ytÞð  þ  Þ1, and that for T has mean ð T1 þ  ytÞ
ð  þ  Þ1.
3.7.2
Robust errors
The assumption of normal errors in the dynamic linear model may not be
robust against sudden shifts in the series or outlying observations. One
alternative is a Student t density based on scale mixing (Carter and Kohn,
1994; Knorr-Held, 1999). This may be used in the observation equation,
some or all components of the state equation, or both. For example, under
a scale mixture prior on the trend component of the state equation, an
RW(1) prior for t would become
t ¼ t1 þ !t
!t  Nð0; =tÞ
t  Gð0:5	; 0:5	Þ
and 	 is the degrees of freedom parameter of the Student t density. More
ﬂexibility in the shape of the error density may be achieved by a discrete
mixture (see section 3.5), possibly a two-group mixture with known
mixture probabilities on components (West, 1997). Thus one might have
an observation equation with errors
"t  ð1  ÞNð0; 2Þ þ Nð0; ’2Þ
ð3:21Þ
DYNAMIC LINEAR MODELS IN NON-PARAMETRIC REGRESSION
97

where  ¼ 0:05 or 0.01 and ’ is large (say between 10 and 100) to
accommodate outliers. The probability PrðGt ¼ 2Þ of belonging to the
minority group will be below the prior probability (i.e. below 0.05 if
 ¼ 0:05) for most observations.
3.7.3
General additive models
DLMs have considerable utility in regression applications that modify the
usual assumption of linear predictor effects. Using these priors, adaptive
smoothing functions can explore the form of underlying non-linear
relationships between predictors Xj and outcome y. Predictor effects are
represented by univariate smooth functions in single predictors sðXjÞ,
though two-dimensional smoothing functions (e.g. in latitude and long-
itude) are possible (Bowman and Azzalini, 1997, chapter 8). Generalized
additive models assume that smooth functions combine additively, and
like the non-parametric models considered in section 3.6 they avoid the
usual assumption of a global linear effect applicable to all n observations
and also avoid modelling non-linearity by again assuming non-linear
effects that apply globally. Additive models for metric outcomes may be
extended to generalized additive models (GAMs) for discrete outcomes,
such as binary or count-dependent variables (Chapter 4).
For a metric outcome y1; . . . ; yn assume corresponding values of a
single predictor x1; . . . ; xn ordered such that
x1 < x2 <    < xn
Note that the observations fyt; xtg need not be a time series. The GAM
seeks to represent the mean sðxÞ as a locally smooth function of x as x
varies through its range. The plot of sðxÞ against x is the non-parametric
analogue of the usual linear regression plot.
The observation model error term is typically assumed to be para-
metric (e.g. normal, Student t), though it can also be modelled non-
parametrically, e.g. via a Dirichlet process. The GAM with this single
predictor is then
yt ¼ 0 þ sðxtÞ þ "t
where typically "t  N(0, 2). Let st ¼ sðxtÞ be the smooth function
representing the locally changing impact of x on y as it varies over its
range. A convenient prior might then be provided by normal or Student
random walks in the ﬁrst, second or higher differences of st (Fahrmeier
and Lang, 2001; Koop and Poirier, 2001). Note that centring of the st or
some other constraint (e.g. s1 ¼ 0Þ may be needed for identiﬁability since
otherwise the level of the st is confounded with 0. Because there is only
98
REGRESSION FOR METRIC OUTCOMES

local smoothing, inferences may also be sensitive to priors assumed for
evolution variance 2 and other aspects of the model.
If there is equal spacing then the ﬁrst- and second-order random walk
priors are just
st  Nðst1; 2Þ
ð3:22Þ
st  Nð2st1  st2; 2Þ
ð3:23Þ
For metric responses the parameterization 2 ¼ 2 is often used; smaller
values of  result in a smoother curve. Koop and Poirier (2001) outline a
method for eliciting  based on the cross-validation function
X
n
t¼1
½yt  0  sðxtÞ2
In general regression applications the xt are usually unequally spaced,
and the random walk prior is then modiﬁed to weight each preceding
point differently. The precision of st is reduced the larger the gap between
xt and its predecessor (remembering that the xt are ordered). Suppose
gaps between points are 1 ¼ x2  x1, 2 ¼ x3 x2; . . . ; n1 ¼ xn xn1.
A ﬁrst-order normal random walk would then be
st  Nðst1; t2Þ
ð3:24Þ
and a second-order one would be
st  Nð	t; t2Þ
ð3:25aÞ
where
	t ¼ st1ð1 þ t=t1Þ  st2ðt=t1Þ
ð3:25bÞ
(Fahrmeir and Lang, 2001). Separate, usually ﬁxed effect priors are
assumed for the initial values (e.g. s1 in a ﬁrst-order random walk).
If there are ties in the x variables with only nu distinct x values, denoted
fx
t ; t ¼ 1; . . . ; nug then the above priors would be on the differences

t ¼ x
t  x
t1 in the unique x and it would be necessary to specify a
grouping index Oi (ranging between 1 and nu) for each observation
i ¼ 1; . . . ; n.
If there is more than one predictor then a semi-parametric model might
be adopted with smooth functions sjðxjÞ on a subset j ¼ 1; . . . ; q of p
predictors, with the remainder modelled by assuming global linearity. So
yt ¼ 0 þ s1ðx1tÞ þ s2ðx2tÞ þ    þ sqðxqtÞ þ 1xqþ1;t þ    þ pqxp;t þ "t
If non-parametric functions are estimated by state space methods for
several regressors x1t; x2t; x3t. . ., then an ordering index O1t; O2t;
DYNAMIC LINEAR MODELS IN NON-PARAMETRIC REGRESSION
99

O3t; . . . ; Opt for each of p regressors is necessary. These indices range
between 1 and nu1; nu2; . . . ; nup (rather than between 1 and n) if there are
tied predictor values.
3.7.4
Alternative smoothness priors
Other smoothness priors have been proposed. A scheme analogous to
(3.24) but allowing a choice between RW(1) and RW(2) dependence for
unequally spaced x is proposed by Berzuini and Larizza (1996), i.e.
st  Nðt; VtÞ
where
t ¼ st1½1 þ ðt=t1Þ expðtÞ  st2½ðt=t1Þ expðtÞ
Vt ¼ 2
t 2½1  expð2tÞ
and  > 0. Larger values of , such that exp(t) tends to zero, imply
an approximate RW(1) prior and less smoothness.
In a Fourier series prior (Lenk, 1999) with xt deﬁned on the interval
½a; b, sðxtÞ may be deﬁned by a truncated series
sðxÞ ¼
X
K
k¼1
!k ’kðxÞ
where
’kðxÞ ¼
2
b  a

0:5
cos  k x  a
b  a
	

h
i
In line with local smoothing, the prior for !k assumes decay as k
increases; for instance, in the geometric smoother prior
!k  Nð0; 2 expð kÞÞ
where  > 0 determines the rate of decay of k.
Another approach (Wood and Kohn, 1998; Wahba, 1983) is the state-
space version of spline smoothing. For a spline of order 2m  1,
st ¼ sðxtÞ is generated by a differential equation
dmst
dtm ¼  dWt
dt
ð3:26Þ
with Wt a Weiner process and 2 the evolution variance. The state vector
Vt ¼
st; dst
dt ; d2st
dt2 ; . . . ; dðm1Þst
dtðm1Þ
 
!
100
REGRESSION FOR METRIC OUTCOMES

is then of order m, evolving stochastically according to
Vt ¼ FtVt1 þ ut
ð3:27aÞ
where Ft is an m  m transition matrix and ut is a multivariate error.
Consider m ¼ 2 (corresponding to a cubic spline), then Vt ¼ ðst; dst=dtÞ
is bivariate and the transition matrix is
Ft ¼
1
t
0
1


ð3:27bÞ
where t ¼ xtþ1  xt. When m ¼ 2, the ut are bivariate (e.g. MVN) with
zero mean and covariance 2Ut, where
Ut ¼
3
t =3
2
t =2
2
t =2
t


ð3:27cÞ
As usual there may be grouping in the x values and the prior (3.27) would
be on the number of distinct values nu  n. Each observation would have
a grouping index Ot with values between 1 and nu. The full regression in
x for m ¼ 2 can then be written
y ¼ 0 þ 1x þ sðOtÞ þ "t
Example 3.12
Static expiratory pressure in cystic ﬁbrosis patients
Consider data from Everitt and Rabe-Hesketh (2001) on the maximum
static expiratory pressure (y) for n ¼ 25 cystic ﬁbrosis patients in relation
to four predictors: weight, BMP, FEV and RV (Table 3.7). A GAM is
assumed with the impacts of all these regressors modelled non-parame-
trically via RW(2) priors. The gaps between successive ordered values of
the predictors are unequal so the prior is as in (3.27).
Only one predictor, namely weight, has 25 distinct values, while BMP
has only 16 distinct values so O2t has only 16 values (Table 3.7). The
prior in s2t will have the form
s2t  Nð	2t; 2t2
2Þ
t ¼ 2; 16
where 	2t ¼ s2;t1ð1 þ 2t=2;t1Þ  s2;t2ð2t=2;t1Þ and 22 ¼ 1 (i.e. 65
minus 64), 23 ¼ 1; . . . ; 2;16 ¼ 2 (i.e. 97 minus 95). The priors on
2
j ðj ¼ 1; 4Þ and the measurement error variance 2 are linked via
2
j ¼ 2j
where G(0.1,1) priors on j are adopted favouring lower evolution
variances as compared with 2.
A standard multiple linear regression has a DIC of 234 (see code A).
By contrast a GAM in all four predictors (code B in Program 3.12) has a
DYNAMIC LINEAR MODELS IN NON-PARAMETRIC REGRESSION
101

DIC of 219 with 19 effective parameters. This is on the basis of a two-
chain run of 20 000 iterations, with convergence after 5000. Plots of the
smooths are given in Figures 3.6 to 3.9.
The same model was also ﬁtted using truncated cubic splines in the
four predictors. The predictors are taken in standard form and ﬁve knot
points at f2; 1; 0; 1; 2g are assumed. Without selection on the regres-
sors, there are apparently many non-signiﬁcant coefﬁcients. The smooth
plots, however, resemble those from the GAM. Code D uses the
regression selection method of Smith and Kohn (1996) in a cubic spline
and also produces non-linear smooths with similar characteristics to
the GAM.
Table 3.7
Original values and observation ranks, cystic ﬁbrosis data
Subject Weight BMP
FEV
RV
Order
Order
Order Order
y
(Weight)
(BMP) (FEV) (RV)
1
13.1
68
32
258
2
5
11
16
95
2
12.9
65
19
449
1
2
2
24
85
3
14.1
64
22
441
3
1
4
23
100
4
16.2
67
41
234
4
4
17
14
85
5
21.5
93
52
202
6
14
21
8
95
6
17.5
68
44
308
5
5
18
19
80
7
30.7
89
28
305
9
11
8
18
65
8
28.4
69
18
369
8
6
1
21
110
9
25.1
67
24
312
7
4
6
20
70
10
31.5
68
23
413
10
5
5
22
95
11
39.9
89
39
206
14
11
16
10
110
12
42.1
90
26
253
15
12
7
15
90
13
45.6
93
45
174
18
14
19
4
100
14
51.2
93
45
158
20
14
19
1
80
15
35.9
66
31
302
12
3
10
17
134
16
34.8
70
29
204
11
7
9
9
134
17
44.7
70
49
187
17
7
20
6
165
18
60.1
92
29
188
22
13
9
7
120
19
43.6
69
38
172
16
6
15
3
130
20
37.2
72
21
216
13
9
3
11
85
21
54.6
86
37
184
21
10
14
5
85
22
64
86
34
225
23
10
13
13
160
23
73.8
97
57
171
25
16
22
2
165
24
51.1
71
33
224
19
8
12
12
95
25
71.5
95
52
225
24
15
21
13
195
102
REGRESSION FOR METRIC OUTCOMES

Example 3.13
Electricity use
To illustrate the use of alternative
smoothness priors, speciﬁcally the state-space version of spline regres-
sion in (3.27), consider again the data on electricity use by temperature.
The full gamma conditional for 1/2 is used to update this parameter, with
prior values 
 ¼ ð1; 1Þ. There are 37 distinct temperature values and it is
−50
−30
−10
10
30
50
70
90
110
10
20
30
40
50
60
70
Weight
m(Weight)
Mean
2.5%
97.5%
Figure 3.6
Smooth in weight
−50
−40
−30
−20
−10
0
10
20
30
40
65
70
75
80
85
90
95
BMP
m(BMP)
Mean
2.5%
97.5%
Figure 3.7
Smooth for BMP
DYNAMIC LINEAR MODELS IN NON-PARAMETRIC REGRESSION
103

−60
−40
−20
0
20
40
60
80
18
23
28
33
38
43
48
53
FEV
m(FEV)
Mean
2.5%
97.5%
Figure 3.8
Smooth for FEV
−60
−40
−20
0
20
40
60
155
205
255
305
355
405
RV
m(RV)
Mean
2.5%
97.5%
Figure 3.9
Smooth for RV
104
REGRESSION FOR METRIC OUTCOMES

necessary to supply a group index Oi to each of the 55 cases. Since an
intercept is included it is necessary to centre the 37 smooth effects. Two
chains are run for 10 000 iterations to produce a smooth (Figure 3.10)
showing a sharp fall in use at lower temperatures.
EXERCISES
1. Using model A in Program 3.1 obtain the pseudo marginal likelihood
of M1 (with predictor W ¼ adjusted density) and so derive the pseudo
Bayes factor assuming P(M0Þ ¼ PðM1Þ ¼ 0:5. (This involves monitor-
ing g[] in Program 3.1.) Also obtain the DIC for models M1 and M0 by
monitoring the deviance (Dv in Program 3.1) as well as the model
means and precisions (mu[i] and tau); mu[] can be monitored via
inference/summary in BUGS rather than the full monitoring option.
2. In Example 3.1 try the model M3 : yi ¼ 3 þ 3xi þ 3wi þ "i3 and
assess its ﬁt against M1 and M2 using the pseudo marginal likelihood,
the path sampling method for estimating the Bayes factor, and via the
posterior model probability based on parallel sampling.
3. In Example 3.5 try ﬁtting the puromycin data with a gamma scale
mixture i  Ga(	/2,	/2) where the degrees of freedom are unknown.
Does this improve over the Ga(1,1) option?
−30
−10
10
30
50
20
30
40
50
60
70
80
Temperature
Figure 3.10
Electricity use and temperature
EXERCISES
105

4. In Example 3.6 try a normal scale mixture model rather than a
heteroscedastic model and detect which observations are most ‘out-
lying’ with regard to the model
yi ¼ V1=3
i
¼ 0 þ 1Hi þ 2Di þ "i
Also try an outlier model with variance inﬂation, namely
fðyij; 2; !; Þ ¼ ð1  !Þðyij; 2Þ þ !ðyij; ð1 þ Þ2Þ
where  ¼ 4 and i  Bern(!) where ! ¼ 0:05. Which observation
has the highest posterior average for i.
5. In Example 3.8 try a DPP mixture with f
1; 
2g ¼ ð1; 1Þ and ﬁnd the
modal number of clusters.
6. In Example 3.9 try a truncated cubic and B spline models with ten
equally spaced knots at 800, 825, 850, 875, 900, 925, 950, 975, 1000
and 1025, and with predictor selection applied both to  and 
coefﬁcients. How does the ﬁt obtained compare with that obtained
by using the optimal knots with locations assumed known but with
predictor selection?
7. In Example 3.10 obtain the DIC of the MLS model C with basis
function selection. This requires monitoring the means (m[i] in the
program) and precision  in order to estimate the deviance at the
posterior mean, where the deviance is deﬁned as

X
ðYi  iÞ2  n logðÞ=2
8. In Example 3.13 try ﬁtting the same model but without using an
intercept. This means it is no longer necessary to centre the smooth effects
REFERENCES
Aitkin, M. (1987) Modelling variance heterogeneity in normal regression using
GLIM. Applied Statistics, 36, 332–339.
Altman, D. (1991) Practical Statistics for Medical Research. Chapman and Hall:
London.
Anderson, R. and Bancroft, T. (1959) Statistical Theory in Research. McGraw-
Hill: New York.
Andrews, D. and Mallows, C. (1974) Scale mixtures of normal distributions.
Journal of the Royal Statistical Society, Series B, 36, 99–102.
Berliner, L. (1996) Hierarchical Bayesian time series models. In Maximum
Entropy and Bayesian Methods, Hanson, K. and Silver, R. (eds). Kluwer
Academic: Dordrecht.
106
REGRESSION FOR METRIC OUTCOMES

Berry, S., Carroll, R. and Ruppert, D. (2002) Bayesian smoothing and regression
splines for measurement error problems, Journal of the American Statistical
Association. 97, 160–169.
Berzuini, C. and Larizza, C. (1996) A uniﬁed approach for modelling longitudinal
and failure time data, with application in medical monitoring. IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, 18, 109–123.
Biller, C. (2000) Adaptive Bayesian regression splines in semiparametric general-
ized linear models. Journal of Computational and Graphical Statistics, 9, 122–
140.
Boscardin, W. and Gelman, A. (1996) Bayesian computation for parametric
models of heteroscedasticity in the linear model. In Advances in Econometrics,
Volume 11A, Bayesian Computational Methods and Applications, Hill, R (ed.).
JAI Press: Greenwich, CT.
Bowman, A. and Azzalini, A. (1997) Applied Smoothing Techniques for Data
Analysis. Oxford University Press: New York.
Burnham, K. and Anderson, D. (2002) Model Selection and Multimodel Infer-
ence: A Practical Information-theoretic Approach, 2nd Edition. New York:
Springer.
Carlin, B. and Chib, S (1995) Bayesian model choice via the Markov chain Monte
Carlo methods, Journal of the Royal Statistical Society, Series B, 57, 473–484.
Carlin, B. and Polson, N (1991) Inference for nonconjugate Bayesian models
using the Gibbs sampler. Canadian Journal of Statistics, 19, 399–405.
Carlin, B., Polson, N. and Stoffer, D. (1992) A Monte Carlo approach to
nonnormal and nonlinear state-space modeling. Journal of the American
Statistical Association, 87, 493–500.
Carter, C. and Kohn, R. (1994) On Gibbs sampling for state space models.
Biometrika, 81, 541–553.
Celeux, G. Hurn, M. and Robert, C. (2000) Computational and inferential
difﬁculties with mixture posterior distributions. Journal of the American
Statistical Association, 95, 957–970.
Cepeda, E. and Gamerman, D. (2000) Bayesian modeling of joint regressions for
the mean and covariance matrix. Technical Report 135, Statistical Laboratory
LES-UFRJ.
Chatterjee, S., Handcock, M. and Simonoff, J. (1995) A Casebook for a First
Course in Statistics and Data Analysis. John Wiley & Sons: New York.
Congdon, P. (2001) Bayesian Statistical Modelling. John Wiley & Sons:
Chichester.
Dayton, C. and Macready, G. (1988) Concomitant-variable latent class models.
Journal of the American Statistical Association, 83, 173–178.
De Boor, C. (1978) A Practical Guide to Splines. Springer: Berlin.
Dempster, A., Laird, N. and Rubin, D. (1977) Maximum likelihood from
incomplete data via the EM algorithm. Journal of the Royal Statistical Society,
Series B, 34, 1–38.
REFERENCES
107

Denison, D., Mallick, B. and Smith, A. (1998a) Automatic Bayesian curve ﬁtting.
Journal of Royal Statistical Society, Series B, 60, 333–359.
Denison, D., Mallick, B. and Smith, A. (1998b) Bayesian MARS. Statistics and
Computing, 8, 337–346.
Denison, D., Holmes, C., Mallick, B. and Smith, A. (2002) Bayesian Methods
for
Nonlinear
Classiﬁcation
and
Regression.
John
Wiley
&
Sons:
New York.
Diebolt, J. and Robert, C. (1994) Estimation of ﬁnite mixture distributions
through Bayesian sampling. Journal of the Royal Statistical Society, Series
B, 56, 363–375.
Draper, N. and Smith, H. (1966) Applied Regression Analysis. John Wiley &
Sons: New York.
Escobar, M. and West, M. (1995) Bayesian density estimation and inference using
mixtures. Journal of the American Statistical Association, 90, 577–588.
Eubank, R. (1988) Spline Smoothing and Nonparametric Regression. Marcel
Dekker: New York.
Everitt, B. and Rabe-Hesketh, S. (2001) Analyzing Medical Data Using S-Plus.
Springer: New York.
Fahrmeier, L. and Knorr-Held, L. (2000) Dynamic and semiparametric models. In
Smoothing and Regression: Approaches, Computation and Application,
Schimek, M (ed.). John Wiley & Sons: New York, 513–544.
Fahrmeier, L. and Lang, S. (2001) Bayesian inference for generalized additive
mixed models based on Markov random ﬁeld priors. Journal of the Royal
Statistical Society, Series C, 50, 201–220.
Ferguson, T. (1973) A Bayesian analysis of some nonparametric problems.
Annals of Statistics, 1, 209–230.
Fernandez, C. and Steel, M. (1998a) On the dangers of modelling through
continuous distributions: a Bayesian perspective. In Bayesian Statistics 6,
Bernardo, J., Berger, J., Dawid, A. and Smith, A (eds). Oxford University
Press: Oxford, 1–16.
Fernandez, C. and Steel, M. (1998b) On Bayesian modeling of fat tails and
skewness. Journal of the American Statistical Association, 93, 359–371.
Fernandez, C., Ley, E. and Steel, M. (2001a) Benchmark priors for Bayesian
model averaging. Journal of Econometrics, 100, 381–427.
Fernandez, C., Ley, E. and Steel, M. (2001b) Model uncertainty in cross-country
growth regressions. Journal of Applied Econometrics, 16, 563–576.
Friedman, J. and Silverman, B. (1989) Flexible parsimonious smoothing and
additive modeling. Technometrics, 31, 1–39.
Fru¨hwirth-Schnatter, S. (1994a) Applied state space modelling of non-Gaussian
time series using integration-based Kalman ﬁltering. Statistics and Computing,
4, 259–269.
Fru¨hwirth-Schnatter, S. (1994b) Data augmentation and dynamic linear models.
Journal of Time Series Analysis, 15, 183–202.
108
REGRESSION FOR METRIC OUTCOMES

Fru¨hwirth-Schnatter, S. (2001) MCMC estimation of classical and dynamic
switching and mixture models. Journal of the American Statistical Associa-
tion, 96, 194–209.
Gelman, A., Carlin, J., Stern, H. and Rubin, D. (1995) Bayesian Data Analysis.
Chapman and Hall: London.
Gelman, A., Carlin, J., Stern, H. and Rubin, D. (2003) Bayesian Data Analysis,
2nd Edition. CRC Press: Boca Raton, FL.
George, E. and McCulloch, R. (1993) Variable selection via Gibbs sampling.
Journal of the American Statistical Association, 88, 881–889.
George, E. and McCulloch, R. (1997) Approaches for Bayesian variable selection.
Statistica Sinica, 7, 339–373.
Geweke, J. (1993) Bayesian treatment of the independent Student-t linear model.
Journal of Applied Econometrics, 8S, 19–40.
Hinkley, D. and Runger, G. (1984) The analysis of transformed data. Journal of
the American Statistical Association, 79, 302–319.
Hoeting, J., Raftery, A. and Madigan, D. (2002) Bayesian variable and trans-
formation selection in linear regression. Journal of Computational and
Graphical Statistics, 11, 485–507.
Holmes, C. and Mallick, B. (2001) Bayesian regression with multivariate linear
splines. Journal of the Royal Statistical Society, Series B, 63, 3–17.
Hurn, M., Justel, A. and Robert, C. (2003) Estimating mixtures of regressions.
Journal of Computational and Graphical Statistics, 12, 55–79.
Ishwaran, H. and James, L. (2002) Approximate Dirichlet process computing in
ﬁnite normal mixtures: smoothing and prior information. Journal of Computa-
tional and Graphical Statistics, 11, 508–532.
Justel, A. and Pena, D. (2001) Heterogeneity and model uncertainty in Bayesian
regression models. Dept. of Mathematics, Universidad Autonoma de Madrid.
Knorr-Held, L. (1999) Conditional prior proposals in dynamic models.
Scandinavian Journal of Statistics, 26, 129–144.
Koop, G. (2003) Bayesian Econometrics, John Wiley & Sons: Chichester.
Koop, G. and Poirier, D. (2001) Bayesian variants of some classical semipara-
metric regression techniques. Working Papers, University of California
Irvine – School of Social Sciences.
Kuo, L. and Mallick, B. (1998) Variable selection for regression models. Sankhya
60B, 65–81.
Laud, P. and Ibrahim, J. (1995) Predictive model selection. Journal of the Royal
Statistical Society, Series B, 57, 247–262.
Lee, P. (1997) Bayesian Statistics: An Introduction, 2nd Edition. Arnold: London.
Lenk, P. (1999) Bayesian inference for semiparametric regression using a Fourier
representation. Journal of the Royal Statistical Society, Series B, 61, 863–879.
MacNab, Y. and Dean, C. (2001) Autoregressive spatial smoothing and temporal
spline smoothing for mapping rates. Biometrics, 57, 949–956.
McCullagh, P. and Nelder, J. (1989) Generalized Linear Models, 2nd Edition.
Chapman and Hall: London.
REFERENCES
109

Madigan, D. and York, J. (1995) Bayesian graphical models for discrete data.
International Statistical Review, 63, 215–232.
Meyer, R. (2000) Applied Bayesian data analysis using state-space models. In
Data Analysis: Scientiﬁc Modeling and Practical Applications, Gaul, W.,
Opitz, O. and Schader, M (eds). Springer: New York, 259–271.
Moreno, E. and Lisco, B. (2003) A default Bayesian test for the number of
components in a mixture. Journal of Statistical Planning and Inference, 111,
129–142.
Ntzoufras, I. (1999) Aspects of Bayesian model and variable selection
using MCMC. Dept. of Statistics, Athens University of Economics and
Business.
Pericchi, L. (1981) A Bayesian approach to transformations to Normality.
Biometrika, 68, 35–43.
Pettit, L. (1990) The conditional predictive ordinate for the Normal distribution.
Journal of the Royal Statistical Society, Series B, 52, 175–184.
Raftery, A., Madigan, D. and Hoeting, J. (1996) Bayesian model averaging for
linear regression models. Journal of the American Statistical Association, 92,
179–191.
Richardson, S. and Green, P. (1997) On the Bayesian analysis of mixtures with an
unknown number of components. Journal of the Royal Statistical Society,
Series B, 59, 731–792.
Richardson, S., Viallefont, V. and Green, P. (2002) Bayesian analysis of Poisson
mixtures. Journal of Nonparametric Statistics, 14, 181–202.
Robert, C. (1996) Mixtures of distributions: inference and estimation. In Markov
Chain Monte Carlo in Practice, Gilks, W., Richardson, S. and Spiegelhalter, D.
(eds). Chapman and Hall: London, 441–464.
Ruppert, D. and Carroll, R. (2000) Spatially-adaptive penalties for spline ﬁtting.
Australian & New Zealand Journal of Statistics, 42, 205–223.
Ruppert, D., Wand, M. and Carroll, R. (2003) Semiparametric Regression.
Cambridge University Press: Cambridge.
Sahu, S., Dey, D. and Branco, M. (2003) A new class of multivariate skew
distributions with applications to Bayesian regression models. Canadian
Journal of Statistics, 31, 129–150.
Smith, M. and Kohn, R. (1996) Nonparametric regression using Bayesian variable
selection. Journal of Econometrics, 75, 317–334.
Smith, M., Kohn, R. and Yau, P. (2001) Nonparametric bivariate surface estima-
tion. In Smoothing and Regression: Approaches, Computation and Applica-
tion, Schimek, M. (ed.). John Wiley & Sons: New York, 545–580.
Verdinelli, I. and Wasserman, L. (1991) Bayesian analysis of outlier problems
using the Gibbs sampler. Statistics and Computing, 1, 105–117.
Wahba, G. (1983) Bayesian conﬁdence intervals for the cross-validated smooth-
ing spline. Journal of the Royal Statistical Society, Series B, 45, 133–150.
Weiss, R. (1994) Pediatric pain, predictive inference, and sensitivity analysis.
Evaluation Review, 18, 651–677.
110
REGRESSION FOR METRIC OUTCOMES

West, M. (1984) Outlier models and prior distributions in Bayesian linear
regression. Journal of the Royal Statistical Society, Series B, 46, 431–439.
West, M. (1987) On scale mixtures of normal distributions. Biometrika, 74, 646–
648.
West, M. (1997) Bayesian time series: models and computations for the analysis
of time series in the physical sciences. In Maximum Entropy and Bayesian
Methods 15, (Hanson K. and Silver R. (eds). Kluwer: Dordrecht.
Wood, S. and Kohn, R. (1998) A Bayesian approach to robust nonparametric
binary regression. Journal of the American Statistical Association, 93, 203–
213.
Zellner, A. (1986) On assessing prior distributions and Bayesian regression
analysis with g-prior distributions. In Bayesian Inference and Decision
Techniques, Goel, P. and Zellner, A. (eds). North-Holland: Amsterdam,
233–243.
REFERENCES
111


CHAPTER 4
Models for Binary and
Count Outcomes
4.1
INTRODUCTION: DISCRETE MODEL LIKELIHOODS
VS. DATA AUGMENTATION
A major motivation for the general linear model has been for the analysis
of counts and binary data. Aggregations of binary data provide binomial
data – see Table 4.1 of McCullagh and Nelder (1989) on ways of
presenting binary data. In the analysis of count, binary and binomial
data, classical methods rely especially on maximum likelihood (ML) or
empirical Bayes (EB) techniques applied to densities such as the Poisson,
negative binomial, Bernoulli, binomial and beta–binomial.
A Bayesian approach to binary, binomial and count data may have
advantages when regression coefﬁcients are not necessarily symmetri-
cally (e.g. normally) distributed, and the actual ‘exact’ shape of posterior
distributions of such coefﬁcients can be assessed from repeated sampling
from the posterior. The asymptotic approximations of classical likelihood
methods may be particularly suspect in small samples or in samples with
binary data (Zellner and Rossi, 1984). As usual the Bayes sampling
approach also permits assessment of exact densities of derived statistics
(e.g. functions of odds ratios derived from logit regression coefﬁcients)
(Fahrmeier and Knorr-Held, 2000).
A fully Bayes analysis is facilitated by MCMC methods, though simple
Gibbs sampling is conﬁned to conjugate analysis without regressors. For
binary and Poisson regressions the full conditionals of the regression
parameters are not in closed form, but the likelihood is log-concave and
adaptive rejection sampling (ARS) can be used (Gilks and Wild, 1992).
Bayesian Models for Categorical Data
P. Congdon
# 2005 John Wiley & Sons, Ltd

An alternative is to introduce augmented (e.g. normal) data that underlie
the discrete data, especially in binary regression, so that analysis reduces
to the metric regression in terms of residual analysis and other techniques
discussed in Chapter 3 (Albert and Chib, 1993). Other avenues explored
in recent Bayesian research include modiﬁcations to standard link
functions, and methods for correlated multivariate binary and count
responses.
4.1.1
Count data
To illustrate the fully Bayesian approach in terms of direct likelihood
updating of the prior (which gives similar results to ML or EB methods if
diffuse priors are used), suppose observed counts y ¼ fy1; y2; y3; . . . ; yng
are a sample from a Poisson density with common mean . Suppose also
that the data are not over- or underdispersed (variance greater than the
mean and less than the mean respectively), though moderate departures
from the variance ¼ mean relationship may be allowed. Since  is
positive, the prior for  might be taken as a gamma with parameters 
and , and so mean /. In a simple Poisson analysis with  constant
over subjects,  and  often take preset values (e.g.  ¼  ¼ 0.001
provides a diffuse prior). The Poisson likelihood for y given  is
proportional to
Y
n
i ¼ 1
expðÞyi
"
#
and the posterior in the three parameters {, , }, with {, } as
unknowns, is proportional to
Y
n
i ¼ 1
expðÞyi
"
#
½1 expðÞ=ðÞPð; Þ
where P(,) is the prior for {,}. As a function of  alone, the
posterior is proportional to
Y
n
i ¼ 1
expðÞyi
"
#
1 expðÞ ¼ 
þP
i
;yi1
exp½ð þ nÞ
so the posterior for  is a gamma, namely Ga( þ P
i yi;  þ n). Since
prior and posterior densities have the same form, this provides a
conjugate analysis.
It might not be sensible to assume a common rate. One option assumes
that the varying means i are separate ﬁxed effects, typically with diffuse
114
MODELS FOR BINARY AND COUNT OUTCOMES

gamma priors such as i  Gaða; aÞ where a is small (e.g. a ¼ 0:001) and
taken as known. An alternative is to seek pooling of information over the
units in order to stabilize estimates of unit-level Poisson rates i
especially if event totals in each unit i are small. If a gamma prior for
i is assumed as the pooling density, then  and  are taken as unknown
hyperparameters governing the degree of pooling. The posterior density
is then proportional to
Y
n
i ¼ 1
expðiÞyi
i
"
#
1
i
expðiÞðÞ
and the posterior density for each i is Ga( þ yi;  þ 1). Such mixture
models are considered more extensively in Chapter 5.
Poisson data may be in the form of observed counts in relation to
expected counts Ei, as in disease mapping or hospital mortality applica-
tions (Albert, 1999) or as counts observed for certain exposure times ti
(McCullagh and Nelder, 1989, pp 193–208). So in the disease mapping
case
yi  PoiðiÞ
i ¼ Ei	i
where 	i are unknowns. Where relevant, Ei may be taken as random
(Wakeﬁeld and Best, 1999) but are usually taken as known, with 	i ¼
i=Ei amounting to relative risks of disease. With a Gamma prior
	i  Ga(,), and Ei as known constants, the posterior density is
proportional to
Y
n
i ¼ 1
expðEi	iÞ	yi
i
"
#
	1
i
expð	iÞ=ðÞ
and the posterior density for each 	i is Ga( þ yi;  þ Ei). The posterior
mean of each underlying rate, namely
Eð	ij; Þ ¼ ð þ yiÞ=ð þ EiÞ
may be written
ð1  BiÞyi=Ei þ Bið=Þ
that is, a weighted average of the crude ﬁxed effects estimate and the
prior mean = of the pooling density. The ratio Bi ¼ =ð þ EiÞ
amounts to a shrinkage factor which leads to greater pooling of smoothed
rates E(	i) to the prior mean for smaller expected counts Ei.
INTRODUCTION
115

If covariates xi ¼ ðxi1; . . . ; xipÞ0 are introduced to explain variations
between Poisson rates then a conjugate analysis is no longer possible. As
outlined in Chapter 1, binomial, binary and Poisson regression usually
involves introducing a link to ensure that the Poisson means or binary/
binomial probabilities are appropriately constrained. Thus for count data
assumed to be Poisson with mean i, a link g() is needed to convert the
linear predictor 
i ¼ 0 þ xi onto a positive scale for i. The link most
commonly used is the loge transform, so that
gðiÞ ¼ logeðiÞ ¼ 0 þ xi
since the inverse link g1 ¼ exp is analytically simple. For data with
exposures or expected counts Ei then
i ¼ Ei	i
gð	iÞ ¼ 0 þ xi
or equivalently
gðiÞ ¼ gðEi	iÞ
so that, for example,
logðiÞ ¼ logðEiÞ þ 0 þ xi
ð4:1Þ
Ei is then called an offset (see Example 4.4). A regression model may be
combined with pooling of information via random effects (see Chapter 5).
For example, one may assume yi  Poð	iEiÞ, and a conjugate prior
	i  Gað; =iÞ where i ¼ expðxiÞ. Conditional on  and , the
posterior mean of 	i is ðyi þ Þ=ðEi þ =iÞ. Albert (1999) presents
approximate marginal likelihoods for comparing such a hierarchical
model against the ﬁxed effects alternative deﬁned as  ! 0.
While direct speciﬁcation of priors on coefﬁcients jð j ¼ 1; . . . ; pÞ in
count regression is widely used, several methods have been suggested to
include more directly historic or elicited information. Bedrick et al.
(1996) and others have suggested data augmentation (or conditional
means) priors. For count data this involves eliciting a mean value ijr
at r ¼ 1; . . . ; R values of the jth predictor xij and then including this
information as implicit ‘prior data’ in the form of a gamma density. For a
large number of covariates the mean values might just be elicited for a
given number (e.g. p) of predictor combinations. Suppose p ¼ 1 in (4.1)
and that xi is standardized, so that 0 
 0 when P
i yi ¼ P
i Ei. Taking
R ¼ 2, the relative risk 	 might be elicited as 1.5 for x ¼ 1 but as 0.75
when x ¼ 1. If one were willing to assign ﬁve prior observations to each
of these elicitations then the prior is Ga(7.5, 5) for x ¼ 1 and Ga(3.75, 5)
116
MODELS FOR BINARY AND COUNT OUTCOMES

when x ¼ 1. These priors induce priors on . If there were two
predictors, both standardized and both factors that increase relative
risk, then one might consider just two combinations ðx1; x2Þ ¼
ð1; 1Þ and (1, 1) of the predictors at which to obtain elicitations. In
related work, Meyer and Laud (2002) propose conjugate priors for  in
Poisson regression of the form
gð1; . . . ; pÞ / exp
X
i
0½i0xi  expðxiÞ
(
)
where i0 is an elicited mean and 0 measures strength of belief in the
elicitation.
4.1.2
Binomial and binary data
For binomial data the occurrences of a certain event are counted among
totals at risk n. The stylized version of the binomial refers to numbers of
‘successes’ y in relation to total trials n. Let  denote the average chance
of occurrence of an event or the average success rate. Under the binomial
model the likelihood is
pðyjÞ ¼
n
y


yð1  Þny
or in terms of the unknown parameter
pðyjÞ / yð1  Þny
The conjugate prior density for a common binomial probability is the
beta density with parameters a and b (both positive),   Beða; bÞ, such
that
pðÞ / a1ð1  Þb1
Note that a symmetric prior on  is obtained under the simpliﬁcation
a ¼ b and a ¼ b ¼ 1 reduces to a uniform prior. The posterior density of
 is then also a beta with parameters a þ y and b þ n  y: speciﬁcally
pðjy; nÞ / aþy1ð1  Þbþny1
with mean  ¼ ½a þ y=½a þ b þ n:
Alternatively,
suppose several
binomial observations
are
taken,
fy1; n1g; fy2; n2g; . . . ; fyG; nGg. For example, in Kahn and Raftery
(1996) the ni are total stroke discharges from a set of hospitals
i ¼ 1; . . . ; G and yi are discharges to one type of post-hospital care,
namely skilled nursing facilities. Assume there is a single underlying
INTRODUCTION
117

occurrence rate  across all units. Then with a Be(a; b) prior for , with a
and b known, the posterior density is
  Be a þ
X
G
i¼1
yi; b þ
X
G
i¼1
ni 
X
G
i¼1
yi
 
!
so that the posterior mean is
 ¼
a þ
X
G
i¼1
yi
"
#
= a þ b þ
X
G
i¼1
ni
"
#
ð4:2Þ
A more sensible model for such data might not assume there is a single
underlying rate but varying rates. A ﬁxed effects analysis might take
i  Beða; bÞ with a and b known, such as the uniform prior Be(1, 1).
Alternatively a population of similar or related units (e.g. hospitals)
provides a basis (via exchangeability) for smoothing the unit speciﬁc
rates. In smoothing applications the parameters in the Be(a; b) prior
would usually be taken as unknowns and the full conditionals for the unit-
speciﬁc proportions would be
Beða þ yi; b þ ni  yiÞ
For both binomial and count data, ﬁt is generally measured in terms of the
likelihood or deviance. Bayesian measures of ﬁt (e.g. the DIC) compare
the posterior mean of these measures to their values at the posterior
means of the parameters or at the posterior means of i and i. For
binomial data, the log likelihood for the data given i is
L ¼
X
i
log
ni
yi


þ yi logðiÞ þ ðni  yiÞ logð1  iÞ


Letting pi ¼ yi=ni then the saturated log likelihood is
Ls ¼
X
i
log
ni
yi


þ yi logðpiÞ þ ðni  yiÞ logð1  piÞ


and the GLM deviance (McCullagh and Nelder, 1989) is obtained as
D ¼ 2ðL  LsÞ, namely
D ¼
X
i
yi logðpi=iÞ þ ðni  yiÞ log 1  pi
1  i




The deviance is sometimes also deﬁned as minus twice the likelihood.
Underlying binomial totals ri and ni in aggregated binomial unit data
are binary responses for individuals within clusters (e.g. for the jth patient
118
MODELS FOR BINARY AND COUNT OUTCOMES

in the ith hospital the responses are yij ¼ 1 or yij ¼ 0), and so equivalently
an estimate for a common occurrence rate is
 ¼
a þ
X
G
i¼1
yij
"
#
= a þ b þ
X
G
i¼1
ni
"
#
A disaggregation to the underlying binary outcomes is relevant when the
latent scale approach to binary regression is adopted (section 4.2). For
binary data both deﬁnitions of the deviance, namely as 2L or
2ðL  LsÞ, are problematic as they reduce to functions of the ﬁtted
probabilities i and do not involve the observations yi (Collett, 2003).
Therefore other methods of assessing ﬁt may be needed; for example,
sensitivity and speciﬁcity rates based on the proportions of successes
and failures correctly classiﬁed when new data are sampled from the
model. The DIC method may still be used to assess effective model
dimensions.
When predictors are introduced for binomial or binary data, possible
links must ensure a transformation from 
i ¼ xi on the real line to the 
2 [0, 1] probability scale. The most common links meeting this require-
ment are the logit, probit and complementary log–log links. This raises
questions about which link is most appropriate or whether one might
average over different links (see section 4.3). The probit and logit links
are symmetric about  ¼ 0:5, and the relationship
gðÞ ¼ gð1  Þ
holds for both. By contrast, the complementary log–log link allows
asymmetry by specifying
log½ logð1  iÞ ¼ xi
or equivalently
i ¼ 1  exp½ expðxiÞ
This transform tends to one faster than it tends to zero. One may compare
different links and use the standard model assessment criteria to choose
the best link. Alternatively, ﬂexible and non-parametric link modelling
for binary data has also been considered from a Bayesian perspective
(Chapter 5).
As for count regression, default priors for regression parameters might
be univariate normal j  Nð0; Vj) where Vj are known, or a multivariate
normal prior on ð1; . . . ; pÞ. However, one may also elicit prior
probabilities associated with chosen predictor values. Consider again
the case p ¼ 1, and a standardized predictor. Suppose a prior guess for 
INTRODUCTION
119

when x ¼ 1 was 1 ¼ 0:75 but 2 ¼ 0:25 when x ¼ 1. Assume a prior
sample size (strength of belief in the guess) of m ¼ 5 observations for
both elicitations. Then a conditional means prior (CMP), following
Bedrick et al. (1996), might consist of the two beta densities
Be(im; ½1  imÞ, i.e. Be(3.75, 1.25) when x ¼ 1 and Be(1.25, 3.75)
when x ¼ 1. The Meyer and Laud prior for logistic regression has the
form
gð1; . . . ; pÞ / exp
X
i
0½i0xi  logð1 þ expðxiÞÞ
(
)
where i0 is an elicited probability for  based on the predictor vector xi
and 0 measures the strength of belief in the elicitation.
Special designs may require adaptations of the standard logistic frame-
work. For example, Holford et al. (1978) consider a conditional logistic
model for matched case–control studies in epidemiology. Each case
k ¼ 1; . . . ; K is matched to Mk controls, so the data can be considered
as K strata, each containing 1 þ Mk individuals. Deﬁne yik ¼ 1 for the
case in stratum k and yik ¼ 0 for the Mk controls. The appropriate analysis
takes case–control status yik as Poisson with mean ðikÞ¼ expðk þ xik),
where xik is a vector of risk factors. The k are usually taken as ﬁxed
effects representing the level of the outcome in stratum k after condition-
ing on the risk factors. This method may be extended to situations where
the kth stratum contains Nk cases and Mk controls by conditioning on the
observed predictors in each matched set.
Example 4.1
Binomial clustering, bovine trypanosomiasis
Bo¨hning
(1999) considers prevalence rates of bovine trypanosomiasis in G ¼ 50
Ugandan farms, and the impact of clustering (higher infection rates may
be related to particular herds) on the appropriateness of a pooled rate, as in
(4.2). The total PG
i¼1 yi is 87 and PG
i¼1 ni is 487, so with a Be(1, 1) prior
on the pooled mean rate  the posterior mean will be 88=489 ¼ 0:18 with
standard deviation 0.01735 under the variance formula for the beta
density. If a pooled mean rate  is not appropriate then predictions
(replicate data) ziði ¼ 1; . . . ; GÞ from this model will have a smaller
variance Vz than actually observed, namely Vy ¼ 7:58.
A standard binomial is applied under a 50 000 two-chain run and
new infection totals ziði ¼ 1; . . . ; 50Þ sampled at each iteration. It is seen
that the binomial underpredicts the variance: the 95% interval for Vz is
{1.43, 4.34} with a probability of zero that Vz > Vy. Pooling strength
models for heterogeneity (e.g. discrete mixture models or beta–binomial
120
MODELS FOR BINARY AND COUNT OUTCOMES

models) will therefore provide a better ﬁt and a better check against the
actual dispersion (see Chapter 5).
4.2
ESTIMATION BY DATA AUGMENTATION: THE
ALBERT–CHIB METHOD
Bayesian simulation facilitates the introduction of latent data (‘data
augmentation’) on a different scale to the actual observed data. For
example, for binary data y the latent data w is deﬁned on a metric scale
which yields y ¼ 1 when w 	 0 and y ¼ 0 when w < 0 (Albert and Chib,
1993). The introduction of augmented data may assist in residual analysis
and in multivariate analysis combining data of different types (e.g. a
mixture of binary and ordinal responses). An underlying scale may be
introduced in terms of utilities Ui1 and Ui0 of options 1 and 0 with
Uij ¼ Vij þ "ij ¼ 
j xi þ "ij
wi ¼ Ui1  Ui0
The probability that option 1 is selected is then
Prðyi ¼ 1Þ ¼ Prðwi 	 0Þ ¼ Prð"i0  "i1  Vi1  Vi0Þ
Assume "ij is normal with mean 0 and variance 2 and deﬁne  ¼

1  
0. Then the comparison of utilities leads to a probit link with
Prðyi ¼ 1Þ ¼ ðxi=Þ
It is apparent that  and  cannot be separately identiﬁed and the usual
approach is to set 2 ¼ 1. It is then possible to sample the latent
differences wi.
The augmented data approach to estimating parameters for binary
responses is particularly relevant in regression problems where the values
of predictors in combination with the response provide information on the
latent scale. If yi is one, then a probit link (" normal) means that the latent
response wi is constrained to be positive and sampled from a normal with
mean xi and variance 2 ¼ 1. If yi ¼ 0, wi is sampled from the same
normal density but constrained to be negative (with 0 as a ceiling value).
So
wi  Nðxi; 1ÞIð0; 1Þ
yi ¼ 1
wi  Nðxi; 1ÞIð1; 0Þ
yi ¼ 0
ð4:3Þ
In practice sampling within the interval ð10; 10Þ or ð5; 5Þ for w will be
sufﬁcient (Oh, 1997).
ESTIMATION BY DATA AUGMENTATION
121

Output from this model may be used to illustrate the method of
calculating marginal likelihoods via the relation
log½PðYÞ ¼ log½PðYjÞ þ log½PðÞ  log½PðjYÞ
as proposed by Chib (1995). The likelihoods and prior ordinates at a
high-density point, say the mean , are readily obtained by substituting
the values in  into the likelihood and the prior densities. To estimate
PðjYÞ at  ¼ , and so estimate MðYÞ ¼ log½PðYÞ as
^MðYÞ ¼ log½PðYj Þ þ log½Pð Þ  log½Pð jYÞ
note that
PðjYÞ ¼
ð
PðjY; WÞPðWjYÞ dW
where W is the vector of normally distributed latent data. Assuming a
prior   Npðb; BÞ, the posterior PðjY; WÞ may be estimated (Albert and
Chib, 1993) as
jY; W  Nð ^W; VWÞ
where
^W ¼ ðB1 þ X0XÞ1ðB1b þ X0WÞ
and
VW ¼ ðB1 þ X0XÞ1
Given t ¼ 1; . . . ; T MCMC draws of the latent data vectors WðtÞ, a Monte
Carlo estimator for Pð jYÞ is therefore provided by
^Pð jYÞ ¼
X
T
t ¼ 1
ð j ^ðtÞ
W ; VWÞ
where  is the normal density function.
4.2.1
Other augmented data methods
Several alternatives to the probit may be considered for binary data
generated according to
Prðyi ¼ 1Þ ¼ Prðwi 	 0Þ ¼ Prð"i0  "i1  Vi1  Vi0Þ
The logit link may be sampled directly
wi  logisticðxi; 1ÞIð0; 1Þ
yi ¼ 1
wi  logisticðxi; 1ÞIð1; 0Þ
yi ¼ 0
ð4:4Þ
122
MODELS FOR BINARY AND COUNT OUTCOMES

where the logistic density logistic (,), with mean  and scale parameter
 has the form
fðxÞ ¼  expð½x  Þ=f1 þ expð½x  Þg2
This has variance 2=2 where 2 ¼ 2=3. Note that the standard logistic
density with mean 0 and variance 1 has the form
fðxÞ ¼  expðxÞ=½1 þ expðxÞ2
Alternatively the logit link may be approximated by sampling wi from a
Student t with 8 degrees of freedom (Albert and Chib, 1993). This entails
constrained normal sampling, as for the probit, but with the precision of
one replaced by subject-speciﬁc variances sampled from an inverse
gamma density with shape and index both equal to four. So
wi  Nðxi; 1=iÞIð0; 1Þ
yi ¼ 1
wi  Nðxi; 1=iÞIð1; 0Þ
yi ¼ 0
i  Gað	=2; 	=2Þ
	 ¼ 8
ð4:5Þ
Note that the  coefﬁcients under this approach need to be scaled to
match those obtained from a logistic regression. Other mixtures are
possible, e.g. taking 	 as an unknown amounts to a model for the link
function; see Chapter 5 and Albert and Chib (1993, p 677). Then various
levels of ‘heavy tails’ are possible as 	 varies, with 	 ¼ 1 corresponding
to the Cauchy density.
Wood and Kohn (1998, p 211) and Oh (1997) propose alternative ways
of approximating the logit link by sampling latent w. Following Scott
(2003) an augmented data version of the logit link may also be obtained
by constrained sampling of fwi1; wi2g from exponential densities with
means i1 ¼ 1 and i2 ¼ expðxiÞ. Then if Di ¼ 1 for ‘failure’ and
Di ¼ 2 for ‘success’, and if Di ¼ argminðwi1; wi2Þ, then PrðDi ¼
kjxiÞ / ik as under a logit regression. Another option, suggested by
Harvey (1976), is for a heteroscedastic probit with the variance model
based on predictors Zi, such that for y ¼ 1
wi  Nðxi; 1=iÞIð0; 1Þ
i ¼ expðZiÞ
where Zi excludes the intercept for identiﬁability.
Estimated residuals from data augmented models may be used to assess
outliers or other aspects of poor ﬁt (Albert and Chib, 1995). Thus for the
augmented data probit, the residual
"i ¼ wi  xi
ESTIMATION BY DATA AUGMENTATION
123

is approximately N(0,1) if the model is appropriate, whereas if the
posterior distribution of "i is signiﬁcantly different from N(0,1) then
the model conﬂicts with the observed y. For example, following Chaloner
and Brant (1988) one may monitor the probability
Prðj"ijÞ > 2
ð4:6aÞ
and compare it will its prior value, which is 0.045. For the augmented
data version of the logit as in (4.4), one monitors
Prðj"ij=0:5Þ > 2
ð4:6bÞ
while for the logistic approximation method as in (4.5), one monitors
Prðj"ij0:5
i Þ > 2
ð4:6cÞ
For Poisson data, data augmentation is more complex, especially for
overdispersed data. Oh and Lim (2001) mention that the cdf of a Poisson
variable yi with mean i is closely approximated by
ðA½yi; iÞ ¼ ð3u0:5
i
½ðiuiÞ1=3  1 þ ui=9Þ
where  is the standard normal cdf and ui ¼ 1=½yi þ 1. Deﬁne 
i ¼
logðiÞ ¼ xi; latent variables underlying the Poisson observations
yi ¼ 1; 2; 3; . . . may be obtained by sampling
wi  Nði; 1ÞIðA½yi  1; i þ 
i; A½yi; i þ 
iÞ
For yi ¼ 0 they are obtained as
wi  Nði; 1ÞIð1; A½0; i þ 
iÞ
Further applications of data augmentation for count and binary regres-
sions occur where the response (e.g. a health behaviour or an economic
choice variable) is endogenous with an intervention (e.g. a health
intervention or medical advice), especially if important determinants of
the intervention are unobserved (Jochmann, 2003). Let Di ¼ 1 or 0 be
binary observations according to whether the intervention (‘treatment’) is
taken up by the subject, and Yi be the observed count or binary outcome.
For Yi a count, one may assume
Yi ¼ ð1  DiÞYi0 þ DiYi1
where Yi1 and Yi0 are unobserved count outcomes with means expð
i1)
and expð
i0Þ. Another possibility is to take Yi1 and Yi0 as gamma variables
with the same means. Then assume 
i1  NðXi1; 1Þ, 
i0  NðXi0; 0Þ
124
MODELS FOR BINARY AND COUNT OUTCOMES

and that take-up of the intervention depends on the response, such
that
wi  NðZi þ 0
i0 þ 1
i1; 1ÞIð0; 1Þ
Di ¼ 1
wi  NðZi þ 0
i0 þ 1
i1; 1ÞIð1; 0Þ
Di ¼ 0
where Zi includes one or more factors not among the Xi. An individual-
level treatment effect is provided by Yi1  Yi0.
4.3
MODEL ASSESSMENT: OUTLIER DETECTION
AND MODEL CHECKS
For detecting unusual cases with binary or binomial data, one may also
combine logit or probit links with outlier detection as in Verdinelli and
Wasserman (1991) (see section 3.5). Wood and Kohn (1998) consider a
shifted location version of the Verdinelli and Wasserman (1991) approach
in augmented data sampling of a probit regression. Let outliers be
selected by i  Bern (!) where ! is small, say ! ¼ 0:05. Then with
inﬂated variance  ¼ 10 for outliers
wiji ¼ 1  Nðxi; 10ÞIð0; 1Þ
yi ¼ 1
wiji ¼ 0  Nðxi; 1ÞIð0; 1Þ
yi ¼ 1
wiji ¼ 1  Nðxi; 10ÞIð1; 0Þ
yi ¼ 0
wiji ¼ 0  Nðxi; 1ÞIð1; 0Þ
yi ¼ 0
ð4:7Þ
An alternative interpretation of outliers when the outcome is binary
is that a misclassiﬁcation has occurred (e.g. Copas, 1988). This might
be relevant if y is based on fallible judgement (e.g. y ¼ 1 for positive
diagnosis under a screening tool with low sensitivity). Let Ti be the true
status and ’i be the probability that Ti ¼ 1. Also let !1 be the probability
that a T ¼ 1 is misrecorded as y ¼ 0 and !0 the probability that T ¼ 0 is
misrecorded as y ¼ 1. Then the probabilities of the actually observed yi are
i ¼ Pðyi ¼ 1Þ ¼ Prðyi ¼ 1jTi ¼ 1ÞpðTi ¼ 1Þ
þ Prðyi ¼ 1jTi ¼ 0ÞPrðTi ¼ 0Þ
¼ ð1  !1Þ’i þ !0ð1  ’iÞ
and similarly
1  i ¼ Pðyi ¼ 0Þ ¼ Prðyi ¼ 0jTi ¼ 1ÞpðTi ¼ 1Þ
þ Prðyi ¼ 0jTi ¼ 0ÞPrðTi ¼ 0Þ
¼ !1’i þ ð1  !0Þð1  ’iÞ
MODEL ASSESSMENT
125

Letting !1 ¼ !0 ¼ ! and allowing the chance of misclassiﬁcation to vary
with i  Bern(!) one can re-express i as
i ¼ Pðyi ¼ 1Þ ¼ Pðyi ¼ 1jTi ¼ 1ÞPðTi ¼ 1Þ
þ Prðyi ¼ 1jTi ¼ 0ÞPrðTi ¼ 0Þ
¼ ð1  iÞ’i þ ið1  ’iÞ
ð4:8Þ
and express the logit or probit of ’i as a function of predictors (see
Example 4.3).
4.3.1
Model assessment: predictive model selection and checks
Model selection methods for binary or count responses involve the same
principles, such as predictive cross-validation and choice according to
posterior model probability, as for metric outcomes. Applying predictive
cross-validation involves relevant adaptations based on the form of
deviance appropriate to the response. Thus consider a parameter set
m ¼ fm; mg including regression parameters m. Samples from the
posterior predictive density are obtained by sampling from pðZjmÞ; for
example,
Zim  PoiðimÞ
in
a
log-link
Poisson
regression
with
logðimÞ ¼ 
im ¼ mXm
i .
Then for model selection, Carlin and Louis (1996) propose a deviance
criterion analogous to the Cm criterion of Laud and Ibrahim (1995),
namely
Dm ¼ E½dðZm; yÞ
ð4:9Þ
where dðZm; yÞ is the relevant deviance. For y Poisson, for example,
dðZm; yÞ ¼ 2
X
n
i ¼ 1
½yi logðyi=ZimÞ  ðyi  ZimÞ
Gelfand and Ghosh (1998) propose a deviance criterion based on
extending to discrete outcomes the predictive loss criterion
X
i
’i þ
k
k þ 1

 X
i
ðyi  iÞ2
ð4:10Þ
where i and ’i are respectively the posterior mean and variance of Zi.
Thus let i be the posterior average of the deviance term based on the
sampled new data at iteration t, Zt
i. For example, for Poisson distributed
count data i is the mean of sampled values of dðZiÞ ¼ Zi log Zi  Zi. The
same formula is used for dðiÞ and dðyiÞ. In practice one would use
126
MODELS FOR BINARY AND COUNT OUTCOMES

dðyiÞ ¼ ðyi þ cÞ logðyi þ cÞ  yi and dðZiÞ ¼ ðZi þ cÞ logðZi þ cÞ  Zi to
avoid logarithms of zero. For binomial data with ni cases in trial i,
dðZiÞ ¼ Zi=ni logðZi=niÞ þ ½ðni  ZiÞ=ni log½ðni  ZiÞ=ni
Deﬁne i ¼ ði þ kyiÞ=ð1 þ kÞ; then the Gelfand–Ghosh measure is
2
X
i
½i  dðiÞ þ 2ðk þ 1Þ
X
i
f½dðiÞ þ kyi=½1 þ k  dðiÞg
ð4:11Þ
From both (4.10) and (4.11), it can be seen that small values of k mean
greater stress is put on precision of predictions (so penalizing complex
models which produce less precise predictions), whereas increasing k
puts more stress on accuracy (‘goodness of ﬁt’ per se). The ﬁrst term in both
(4.10) and (4.11) is a penalty term for complexity or imprecise predictions,
and the second is the goodness-of-ﬁt term (measuring bias in predictions
rather than their precision). Meyer and Laud (2002) advocate the measure
X
i
½’i þ ðyi  iÞ2
ð4:12Þ
for yi as count, binomial or binary data as well as metric data.
For model diagnosis using posterior predictive checks (Gelman et al.,
1995), a frequent issue for both binomial and count data is overdispersion
(see Chapter 5) and hence a suitable model will replicate the over-
dispersion present in the data. To assess whether it does so one might
compare the ratio CZ ¼ VarðZÞ=Z based on sampled new data with the
corresponding ratio Hy for the actual data. This check would be done at
each iteration and a satisfactory model will have CZ exceeding Cy about
50% of the time.
Example 4.2
Model selection, logit regression of nodal involvment
These data have been considered in a number of studies with the issue
centred on regressor choice. Congdon (2003) considered Chib’s method
for obtaining a Bayes factor by marginal likelihood approximation,
together with pseudo marginal likelihood estimates and predictive
cross-validation. Here we consider the path sampling method for Bayes
factor approximation and the parallel sampling method for approximating
model probabilities (Chapter 2). The predictors are x1 ¼ log(serum acid
phosphate), x2 ¼ result of X-ray (1 ¼ þve, 0 ¼ ve), x3 ¼ size of
tumour (1 ¼ large, 0 ¼ small) and x4 ¼ pathological grade of tumour
(1 ¼ more serious, 0 ¼ less serious). A binary regression model includ-
ing all four predictors is then yi  BernðiÞ where
i ¼ ð0 þ 1x1i þ    þ 4x4iÞ
MODEL ASSESSMENT
127

or
i ¼ expð0 þ 1x1i þ    þ 4x4iÞ=½1 þ expð0 þ 1x1i þ    þ 4x4iÞ
under probit and logit links respectively. Let M1 denote the full model
(four predictors) and M0 a reduced model excluding x4.
The priors used on the regression coefﬁcients are as in Chib (1995).
With a logit link, the alternative models are
M1 :
logitðiÞ ¼ 0 þ 1x1i þ    þ 4x4i
M0 :
logitðiÞ ¼ 0 þ 1x1i þ    þ 3x3i
and under the path sampling approach for approximating the Bayes
factor, the linking model Ms with s 2 ð0; 1Þ is
Ms :
logitðisÞ ¼ 0 þ 1x1i þ    þ 3x3i þ s4x4i
The log likelihood under Ms is
log Pðyij; sÞ ¼ yi logðisÞ þ ð1  yiÞ logð1  isÞ
where is ¼ expð
isÞ=½1 þ expð
isÞ and 
is ¼ 0 þ 1x1i þ    þ 3x3i þ
s4x4i. So, as in section 2.3,
Rið; sÞ ¼ yi4x4i  4x4i expð
isÞ=½1 þ expð
isÞ
With a grid of 20 intervals the Bayes factor in favour of the smaller model
is 2.44. Increasing the number of intervals does not substantially affect
this estimate.
Under the parallel sampling approach the posterior probability on M0 is
obtained as 0.79 giving a Bayes factor of 3.76 favouring the simpler
model (under equal prior model probabilities). Strictly one should allow
for Monte Carlo variation in the posterior model probability estimates w0
and w1. From a two-chain run of 50 000 iterations the Monte Carlo
standard error of both estimates is 0.00116 and a 95% interval on the
Bayes factor may be obtained by simulation of the ratio of these two
probabilities.
Example 4.3
Latent normal sampling; simulated data
Albert and
Chib (1995) present a small simulated sample (n ¼ 20) of binary data
with a single predictor and discuss the identiﬁcation of outliers. The data
are generated under a logit link, namely
yi  BernðiÞ
logitðiÞ ¼ 0 þ 1xi
with 0 ¼ 0, 1 ¼ 3. With the data thus generated, ﬁrst consider the
standard logit and probit regression. Logit regression yields posterior
128
MODELS FOR BINARY AND COUNT OUTCOMES

means (and standard deviations) 0 ¼ 0:03 (0.6), 1 ¼ 3:55 (1.66), while
probit regression yields 0 ¼ 0:03 (0.34), 1 ¼ 1:99 (0.89). Logit regres-
sion with a prior misclassiﬁcation probability ! ¼ 0:01 and misclassiﬁ-
cation indicators i  Bern(!) as in (4.8) shows cases 4, 9 and 13 to have
posterior probabilities P(i ¼ 1) of 0.11, 0.11 and 0.07 respectively. The
coefﬁcient 1 is inﬂated to around 4.1 (s.d. 2.1) under this model.
Table 4.1 shows the probabilities of outliers under different data
augmentation options. It also contains the scale weights i under (4.5).
Probit regression via augmented data sampling also shows cases 4 and 9
with positive responses (y ¼ 1) but negative x to be possible outliers,
together with case 13 which has y ¼ 0 despite positive x. The posterior
Table 4.1
Outlier detection under data augmentation (DA)
Obs.
y
x
Probability of outlier
————————————————
————————————
Probit
Logit
DA Logit
Logit
Probit
regression
approxi-
approxi-
regression
DA
via
mation
mation
via
with
DA
via
scale
DA
variance
DA
weights
inﬂation
1
0
0.740
0.026
0.030
1.022
0.030
0.037
2
0
0.005
0.048
0.051
0.987
0.059
0.053
3
1
0.337
0.036
0.032
1.025
0.035
0.040
4
1
0.492
0.189
0.180
0.812
0.227
0.155
5
0
0.268
0.030
0.034
1.027
0.038
0.042
6
1
0.187
0.037
0.036
1.016
0.042
0.042
7
0
0.211
0.038
0.035
1.022
0.041
0.044
8
0
0.538
0.030
0.029
1.031
0.032
0.038
9
1
0.490
0.186
0.180
0.811
0.224
0.151
10
0
0.377
0.036
0.032
1.026
0.037
0.040
11
0
0.628
0.029
0.030
1.024
0.030
0.038
12
1
0.198
0.073
0.076
0.936
0.089
0.071
13
0
0.352
0.155
0.140
0.861
0.176
0.123
14
1
0.366
0.033
0.033
1.023
0.036
0.040
15
0
0.751
0.031
0.029
1.021
0.031
0.038
16
1
0.359
0.031
0.032
1.025
0.038
0.041
17
0
0.173
0.039
0.038
1.017
0.043
0.047
18
0
0.156
0.038
0.038
1.018
0.046
0.044
19
0
0.432
0.032
0.029
1.030
0.033
0.040
20
1
0.454
0.030
0.031
1.025
0.035
0.041
MODEL ASSESSMENT
129

outlier probabilities of 0.15 or more compare with prior probabilities of
0.05.
Similar results are obtained under the logistic regression schemes (4.4)
and (4.5). The scale weights under (4.5) also highlight cases 4, 9 and 13.
Probit regression via augmented data sampling with outlier detection in
terms of elevated variance, as in (4.7) with  ¼ 10, yields a slightly lower
outlier probability on case 13.
4.4
PREDICTOR SELECTION IN BINARY AND COUNT
REGRESSION
For regression variable selection in binary or count regression one may
adapt the linear regression method of George and McCulloch (1993) and
George et al. (1996) based on a scale mixture of two normal distributions.
As for a metric response, the prior for a regression coefﬁcient when Xj is
not certain to be included is
jjj  jNð0; c2
j &2
j Þ þ ð1  jÞNð0; &2
j Þ
ð4:13Þ
If j ¼ 1 is chosen at any iteration it corresponds to Xj being included in
the model and j is then distributed as a normal with mean 0 and large
variance c2
j &2
j . If inclusion of Xj is not supported then the prior with a
small default variance, namely Nð0; &2
j Þ, will be selected. cj should be
chosen large enough (and &j small enough) to ensure separation of the two
densities in the mixture. George et al. (1996) recommend taking cj
between 10 and 100, and &j to be based on setting a neighbourhood
ðj; jÞ around zero within which variation in j is unimportant to the
outcome. Once j is obtained, &j ¼ j=2:15 for cj ¼ 10 and &j ¼ j=3:04
for cj ¼ 100 (see George et al., 1996, p 342).
For generalized linear models based on the exponential family density
with natural parameter , one has
fðyijiÞ ¼ exp½yii  bðiÞ þ cðyiÞ
where EðyiÞ ¼ b0ðiÞ. With 0i ¼ xi, the impact on EðyiÞ of a change
xij in xj is
y ¼ Eðy1iÞ  Eðy0iÞ ¼ jb0ð0i þ jxijÞ  b0ð0iÞj
This is approximately equal to b00ð0iÞjxijjjjj where b00() is the
variance of y (George et al., 1996). It is required to obtain j so that
for jjj < j, y is small, i.e. y < " where " is small relative to the
range in y. Thus one option would be to choose j ¼ "=ðb00ð0ÞjxjjÞ, and
xj represents a large change in xj in terms of its dispersion.
130
MODELS FOR BINARY AND COUNT OUTCOMES

Another option is to assess the size that Gj ¼ jjxjj would need to be
to ensure that y < ", and then take j ¼ Gj=jxjj. For example,
EðyÞ ¼ () in a binary regression with probit link, with  the standard
normal cumulative density. Since EðyÞ can vary only between 0 and 1, a
reasonable value for " is 0.01. Assuming 0 ¼ 0 gives ð0Þ ¼ 0:5, then
since (0 þ 0:025Þ ¼ 0:51, one obtains with Gj ¼ 0:025
y ¼ ð0i þ GjÞ  ð0iÞ ¼ 0:01
and so setting j  0:025=jxjj ensures jjxjj is under 0.025. xj might
be the interquartile range of xj or the difference between the ninth and
ﬁrst
decile.
For
a
binary
logit
regression,
EðyÞ ¼ LðÞ ¼
expðÞ=½1 þ expðÞ and with 0 ¼ 0, Lð0Þ ¼ 0:5. Here Lð0:04Þ ¼ 0:51
and one may set j ¼ 0:04=jxjj. For count data, one might take y as "
times
the
range
of
y
and
with
0 ¼ 0,
expð0Þ ¼ 1.
So
then
Gj ¼ lnðy þ 1Þ.
The similar approaches of Smith and Kohn (1996) and Kuo and
Mallick (1998) assume binary indicators 1; . . . ; p on regression para-
meters 1; . . . ; p such that j ¼ 0 if j ¼ 0 and j ¼ 1 if j 6¼ 0. Suppose
the prior on j ¼ Pðj ¼ 1Þ is j ¼ 0:5. Gerlach et al. (2002) describe a
modiﬁcation of the Smith and Kohn (1996) approach (see Chapter 3) such
that for binary data
yi  BernðiÞ
logitðiÞ ¼ zi ¼ Xi þ ei;
with ei  Nð0; Þ
Then S() in (3.3) is deﬁned with z replacing y.
Count or logit regression variable selection may also be based on
separately running all models and considering predictive summaries or
criteria, such as those in (4.9)–(4.12). Meyer and Laud (2002) and Laud
and Ibrahim (1995) propose a prior for the regression coefﬁcients m in
the parameters sets m ¼ fm; mg for models m. These are based on
eliciting prior guesses for im0 (binary or binomial response), or im0
(count
response),
or
possibly
taking
logit(im0Þ ¼  m

Xim,
and
log(im0Þ ¼ 

mXim where 

m is the maximum likelihood estimate
(Meyer and Laud, 2002, p 864). Strength of belief in the mth prior is
represented by the ratio m
0 ¼ nm
0 =n of prior sample sizes nm
0 to the actual
sample size n. For a logistic regression the conjugate prior on the vector
m is
Pðmjm
0 ; m
0 Þ / exp
X
n
i¼1
m
0 ½m
i0Ximm  logð1 þ expðXimmÞÞ
(
)
PREDICTOR SELECTION IN BINARY AND COUNT REGRESSION
131

while for a Poisson regression, the conjugate prior is
Pðmjm
0 ; m
0 Þ / exp
X
n
i¼1
m
0 ½m
i0Ximm  expðXimmÞ
(
)
Choice between predictors may involves comparing 2p models against
one another and selecting that combination of predictor variables that
minimizes predictive criteria such as (4.9). Forward search methods
might also be used in tandem with predictive criteria (see also Congdon,
2005, for a parallel sampling method of forward selection).
Example 4.4
Suicides in English local authorities
In this example
the response is the total male suicides yi in 1989–1993 in 354 English
local authorities. The average suicide count over this ﬁve-year period is
52, with a range from 0 (in the Isles of Scilly) to 409 in Birmingham.
Expected deaths Ei (based on England-wide age-speciﬁc suicide rates in
1991) are used as an offset. There are ten possible predictors, all from the
1991 UK Census. These reﬂect factors such as isolation and social
fragmentation (e.g. high population turnover, one-person households),
social class and deprivation (e.g. percentage of economically active in
classes IV and V, namely semi- and unskilled manual), and the possible
impact of rurality (demonstrated by elevated suicide rates among farm-
ers). The predictors indicative of social fragmentation are X1 ¼ single,
widowed, divorced, X2 ¼ % of population with different address one year
ago, X3 ¼ one-person households, X4 ¼ private renting. The remaining
predictors are X5 ¼ unemployment, X6 ¼ % economically active in
classes IV and V, X7 ¼ agricultural workers, X8 ¼ renting from local
authority/housing association, X9 ¼ population density (divided by 1000)
and X10 ¼ non-white ethnicity.
With the mixture selection prior as in (4.13) above, take D as " times
the range of y so that with " ¼ 0:01,
Gj ¼ lnðy þ 1Þ ¼ lnð5:09Þ ¼ 1:63
Then j ¼ Gj=jxjj; j ¼ 1; . . . ; 10, where jxjj is the difference between
the 90th and 10th percentiles for each predictor. Then with cj ¼ 10,
&j ¼ j=2:15. Here " ¼ 0:01 and 0.05 are compared in terms of ﬁt using
the model averaged Poisson means
yi  PoðEi	iÞ
where the 	i ¼ Xi average over the models deﬁned by which j ¼ 1 at
iteration t. The effect of predictors can be interpreted as measuring
changes in the log relative risk, i.e. in log(	i), using means of j ¼ jj.
132
MODELS FOR BINARY AND COUNT OUTCOMES

To assess predictions the discrepancy criterion (4.12) is used. A two-
chain run of 50 000 iterations (and a 10 000 burn-in) with &j based on
" ¼ 0:01 gives a discrepancy of 50 810. The marginal posterior prob-
abilities Pr(j ¼ 1) are above 0.5 for X3 and X6 only. For example, the
posterior mean of 3 is 0.026, so there is a 27% higher suicide risk in
areas with 30.5% one-person households (the 90th percentile) than in
areas with 21.5% (the 10th percentile). However, the averages of
j ¼ jj are ‘signiﬁcant’ in the sense of having 95% intervals entirely
above or below zero for two other predictors, namely X2 and X9. The
predictors X2, X3 and X6 have positive effects on the suicide rate and the
impact of X9 is negative, perhaps reﬂecting the impact of rurality as a
suicide risk factor.
With &j based on " ¼ 0:05 the discrepancy criterion is lowered slightly
to 50 530. With this option X1 is more apparently signiﬁcant, with 95%
intervals all positive. The predictors X2, X3 and X6 also have positive
effects in terms of the 95% intervals for j, whereas X9 and X5 have
negative effects. Here none of the marginal inclusion probabilities exceed
0.5 so there appear to be a range of plausible models with differing
predictors included in them.
4.5
CONTINGENCY TABLES
A speciﬁc application of Poisson regression is to contingency tables
under which subjects are classiﬁed by a number of categorical factors.
Thus consider subjects r ¼ 1; . . . ; N with observed values C1r, C2r; . . . on
two or more factors. One might analyse such data at individual level,
especially when there are also metric observations xr1, xr2; . . . and a clear
distinction exists between predictors and response(s). However, when the
observations are conﬁned to a few categorical variables (which are
effectively joint responses) an alternative is to analyse counts accumu-
lated over subjects with the same category values. Suppose there are only
two factors i ¼ 1; . . . ; I and j ¼ 1; . . . ; J (i.e. rows and columns of the
table) and with associated counts yij; then y11 þ y12 þ . . . þ y21 þ y22 þ
. . . þ yIJ ¼ N with the total cells in the table being IJ. In general a T-way
contingency table involves T cross-classiﬁed variables. The totals of the
observations over one or more but not all factors (such as the row sums
P
j yij in a two-way table) are known as marginal totals.
There are several possible sampling schemes which can produce a
contingency table. Poisson sampling is relevant when the total of
observations N is random (variants such as negative binomial sampling
CONTINGENCY TABLES
133

will be relevant in overdispersed data). Each cell mean in the contingency
table is then the mean i1i2 ... iT of Poisson distributed counts yi1i2 ... iT. Other
sorts of sampling occur when N is ﬁxed or one or more of the margins are
ﬁxed. When N alone is ﬁxed (e.g. the total sample size in a clinical trial
or questionnaire survey, or a census population total) one obtains multi-
nomial sampling from a total of N with probabilities of being in a cell
deﬁned by categories on the combined factors (see Chapter 6). For
instance, in a two-way table, frequencies yij would be multinomial with
probabilities ij ¼ PrðC1 ¼ i; C2 ¼ jÞ in relation to N ¼ P
i
P
j yij, with
P
i
P
j ij ¼ 1. When the margins on one variable are also ﬁxed, for
instance in stratiﬁed sample designs or when classiﬁers j; k, etc., relate to
subdvisions of populations in units i such as geographic small areas,
hospitals or schools, then product multinomial sampling occurs. An
example is that considered by Leonard and Hsu (1994) where students
in schools i ¼ 1; . . . ; 40 are classiﬁed by grades j ¼ 1; . . . ; 6 on a
mathematics test and the data result from 40 separate multinomial
distributions.
Consider Poisson sampling when N is not ﬁxed. Hierarchical log-linear
models express the counts in terms of main effects and interactions
among the variables, with higher order interactions not being introduced
unless lower order ones are present. The simplest model and one the
subject of several Bayesian studies (e.g. Epstein and Fienberg, 1991;
Albert, 1996; Gunel and Dickey, 1974) is where the variables are
mutually independent with main effects only, whereas substantive interest
is usually in the form of association between the factors (i.e. in departures
from independence). Thus for a two-way table, yij  PoðijÞ, the inde-
pendence model
logðijÞ ¼ u0 þ u1ðiÞ þ u2ðjÞ
ð4:14Þ
is obtained when parameters u12ðijÞ representing interactions between the
factors are absent. The model with interactions
logðijÞ ¼ u0 þ u1ðiÞ þ u2ðjÞ þ u12ðijÞ
ð4:15Þ
is known as a saturated model since the number of possible parameters is
IJ þ I þ J þ 1, exceeding the number of cells in the table. The usual
system of priors to ensure identiﬁability (number of parameters equal to
or less than the number of cells in the table) sets u1ð1Þ ¼ u2ð1Þ ¼ 0, and
also u12ðijÞ ¼ 0 for all classiﬁcation pairs fi; jg where one or more of the
i and j are one. Thus u12ð1jÞ ¼ 0 for all j and u12ði1Þ ¼ 0 for all i.
The remaining parameters may be taken to be independently distributed
ﬁxed effects, with zero means and known large variances, e.g.
134
MODELS FOR BINARY AND COUNT OUTCOMES

u1ð2Þ  Nð0; 1000Þ; . . . ; u1ðIÞ  Nð0; 1000Þ; u2ð2Þ Nð0; 1000Þ; . . . ; u2ðJÞ 
Nð0; 1000Þ; u12ð22Þ  Nð0; 1000Þ; . . . ; u12ðIJÞ  Nð0; 1000Þ.
Possible alternative prior structures include:
1. Two-stage priors where an extra parameter is introduced to model the
goodness of ﬁt of the log-linear model and/or account for over-
dispersion; Albert (1988) describes a two-stage model where the
contingency table results from Poisson sampling and Epstein and
Fienberg (1991) do the same when there is multinomial sampling is
relation to ﬁxed N (see Chapter 6).
2. Random effects rather than ﬁxed effects priors on interaction para-
meters, such as u12ðijÞ in (4.15), that allow a limiting case where the
precision on u12ðijÞ ¼ 0 is so high that the independence model
becomes plausible (Albert, 1996). Random effects priors that include
all the identiﬁable parameters in a log-linear model are discussed by
Knuiman and Speed (1988) and Dellaportas and Forster (1999). These
involve covariance matrices which combine projection matrices for
each parameter set (e.g. interactions between factors 2 and 3 in a
three-way table, or main effects for factor 3) to ensure identiﬁability,
combined with variance parameters which may differ between each
parameter set.
3. Models where the interactions are ‘structured’ for the sake of
parsimony (see Chapter 7). For instance, suppose C1 and C2 are
ordinal and of the same type (parental status and descendant status), so
that one can deﬁne distance as jj  ij and so model the interaction
parameters more parsimoniously as
u12ðijÞ ¼ jj  ij
Despite the reduced parameter count, it is still necessary to set
u1ð1Þ ¼ u2ð1Þ ¼ 0 in order to separate out the row and column effects
from the intercept, but there may be improved precision on derived
parameters (e.g. odds ratios) as a result of a more economical model
(Albert, 1988).
Raftery (1996) proposes a prior for regression coefﬁcients in general
linear models (including contingency table models) and generalizing the
prior for linear regression models in Hoeting et al. (1996). Assuming
standardized covariates, all coefﬁcients j except the intercept are
assigned independent normal priors with mean 0 and common variance.
The prior is then transformed in such a way as to reﬂect the actual
observations (so is a ‘data-dependent’ prior). The method involves
CONTINGENCY TABLES
135

deﬁning a design matrix X which for a contingency table application
would be of dimension N  p where p is the number of independent
(identiﬁable) parameters for the impacts of each level of each categorical
factor or factor interaction. N would be the number of cells (e.g.
I  J  K in a three-way table).
For a regression with p predictors (e.g. a normal linear regression with
continuous predictors as well as a Poisson regression with categorical
predictors)1, the prior for  is derived from a prior for  assuming
standardized predictors (Raftery, 1996, p 256). Let sjð j ¼ 2; . . . ; pÞ
denote standard deviations of predictors in column j of Xnp, and
sy ¼ ½VðyÞ0:5. For preset values of ð ; g
1  Nð0;  2Þ
and
j  Nð0; 2Þ;
j ¼ 2; . . . ; p
Then  ¼ v þ Q, where v1 ¼ y, and vj ¼ 0, j ¼ 2; . . . ; p. Qpp has zero
elements except for diagonal elements ðsy; sy=s2; sy=s3; . . . ; sy=spÞ and
ﬁrst row Q12 ¼ syX2=s2; Q13 ¼ syX3=s3; . . . ; Q1p ¼ syXp=sp. Values
of  should be chosen that have minimal effect on model choice via the
Bayes factor and Raftery recommends a range 1    5, with central
value  ¼ 1:65. For non-metric outcomes in general linear models with
mean i and link g;y and sy are replaced by z and sZ where zi ¼
gðiÞ þ ðyi  iÞ=g0ðiÞ.
Priors such as this may be combined with the variable selection
methodology of George and McCulloch (1993), Kuo and Mallick
(1998), Ntzoufras (1999) and others. Predictor selection for coefﬁcients
in log-linear models usually leads to a situation where the number of
selection indicators m is less than the number of predictors. For example,
in log-linear regression for cross-classiﬁed counts yijkði ¼ 1; . . . ; I; j ¼
1; . . . ; J; k ¼ 1; . . . ; K) there would typically be a single inclusion indi-
cator for the entire set of ðI  1ÞðJ  1Þ parameters u12ðijÞ, one for u13ðikÞ,
one for u23ðjkÞ and another one for u123ðijkÞ. The intercept and main effects
are usually included by default. The priors on m would then reﬂect how
many of the possible models involved each parameter set.
Albert (1996) takes the intercept and main effects as included by
default but second- and higher order interactions subject to selection.
1 For a log-linear regression ‘predictors’ are deﬁned by the level of each categorical factor or their
interactions. For a 2  2  5 log-linear model X would be of dimension 20  20 with columns
corresponding to an intercept, dummy ‘predictors’ for each of the six main effects, nine predictors for
each of the two-way interactions and four for the three-way interactions.
136
MODELS FOR BINARY AND COUNT OUTCOMES

Thus for a two-way table, the independence model (4.14) may be
compared with the model (4.15) including the second-order interaction.
The main effects have standard ﬁxed effects priors with corner constraints
for identiﬁcation. However, for interaction terms an exchangeable normal
prior u12ðijÞ  Nð0; PÞ is assumed with no corner constraints on the u12ðijÞ.
A mixture prior on the inclusion or not of the entire set of interactions can
then be set up using the McCulloch and Rossi (1993) method. Let I be a
binary selection indicator. Then according as I ¼ 1 or 0, the variance P
or the precision P1 is selected to correspond to the independence model
(model 0) or the interaction model (model 1). Model 0 applies as P ! 0,
so when I ¼ 0; u12ðijÞ  Nð0; P0Þ where P0 is small, whereas when
I ¼ 1, u12ðijÞ  Nð0; P1Þ where P1 is large, allowing non-trivial, non-
zero effects to emerge. A robust extension is a scale mixture on the log-
linear model parameters subject to doubts on their inclusion. For a
two-way table and when I ¼ 1
u12ij  Nð0; P=ijÞ
where ij  Ga(0.5	, 0.5	) and 	 is small (under ﬁve).
Example 4.5
Contraceptive use and heart attack risk
Consider a
case–control study of the interdependence between oral contraceptive use
and myocardial infarction among women aged 25–49, classiﬁed into age
bands 25–29, 30–34, 35–39, 40–44 and 45–49 (Raftery, 1996). So the
data are of dimension 2  2  5 arranged as contraceptive use (rows),
infarction (columns) and age (slices) (denoted C, M and A for short); see
Table 4.2.
Consider ﬁrst predictor selection with four binary indicators m
corresponding to interaction effects (CM), (CA), (MA) and (CMA). There
are nine possible models that include intercept and main effects by default:
1. 1 þ C þ M þ A þ CM
2. 1 þ C þ M þ A þ CA
Table 4.2
Oral contraceptive use and myocardial infarction
Control group
Myocardial infarction
age
age
———————
————————————————
———————
——————————————
25–29 30–34 35–39 40–44 45–49
25–29 30–34 35–39 40–44 45–49
Contraceptive
No
224
390
330
362
301
2
12
33
65
93
use
Yes
62
33
26
9
5
4
9
4
6
6
CONTINGENCY TABLES
137

3. 1 þ C þ M þ A þ MA
4. 1 þ C þ M þ A þ CM þ CA
5. 1 þ C þ M þ A þ CM þ MA
6. 1 þ C þ M þ A þ CA þ MA
7. 1 þ C þ M þ A þ CA þ MA þ CM
8. 1 þ C þ M þ A þ CA þ MA þ CM þ CMA
9. 1 þ C þ M þ A
CMA
appears
in
only
one
model,
so
an
appropriate
prior
is
4  Bernð1=9Þ. If CMA is not included then each interaction CM, CA
and MA appears in four of the remaining eight models. Since non-
hierarchical models are not allowed, an appropriate prior for 1; 2; 3 is
j  Bern() where
 ¼ 4 þ 0:5ð1  4Þ
The choice of one or more m ¼ 1 corresponds to one of the nine models
and relative frequencies of selection under MCMC sampling may be
monitored. One may also monitor the relative risk of myocardial infarc-
tion for oral contraceptive users. This is expðu12ð22ÞÞ if CM is included
and expðu12ð22Þ þ u123ð22kÞÞ if CMA is included. Note that model 7
corresponds to age as a confounder (not a risk factor in itself but the
distribution on the true risk factors differs by age), while in model 8 age
is a modiﬁer.
With N(0, 0.1) priors taken on  j, it appears that model 7 is preferred.
The second half of a two-chain run of 100 000 iterations gives a
probability exceeding 0.99 on this model.
Next consider the robust prior model of Raftery (1996), for which in a
contingency table application of dimension 2  2  5 (as in Table 4.2),
the model means are given by
logðijkÞ¼ u0 þ u1ðiÞ þ u2ðjÞ þ u3ðkÞ þ u12ðijÞ þ u13ðikÞ þ u23ðjkÞ þ u123ðijkÞ ¼ X
where the 20 independent parameters (those not set to zero) are 1 ¼ u0,
2 ¼ u1ð2Þ, 3 ¼ u2ð2Þ, 4 ¼ u3ð2Þ, 5 ¼ u3ð3Þ, 6 ¼ u3ð4Þ, 7 ¼ u3ð5Þ,
8 ¼ u12ð22Þ,
9 ¼ u13ð22Þ,
10 ¼ u13ð23Þ,
11 ¼ u13ð24Þ,
12 ¼ u13ð25Þ,
13 ¼ u23ð22Þ, 14 ¼ u23ð23Þ, 15 ¼ u23ð24Þ, 16 ¼ u23ð25Þ, 17 ¼ u123ð222Þ,
18 ¼ u123ð223Þ, 19 ¼ u123ð224Þ and 20 ¼ u123ð225Þ. The design matrix has
rows deﬁned by cell entries fi; j; kg with k changing most rapidly and i
least rapidly. So rows 1; 2; 3; 4; 5; 6; . . . ; 20 are deﬁned for y111, y112, y113,
y114, y115, y121; . . . ; y225. The ﬁrst column relates to 1 and has ones
throughout, the second column relates to 2 and has entries equal to one
for rows 11–20 (where i ¼ 2) and zero elsewhere (see Example4_5.xls).
138
MODELS FOR BINARY AND COUNT OUTCOMES

In fact Raftery considers a simpliﬁed model (where p ¼ 17) under
which the relative risk is constant for ages above and below 34. So
17 ¼ u123ð222Þ for ages k ¼ 3; 4; 5 and 17 ¼ 0 for ages k ¼ 1; 2, though
the full age categorization is retained for lower order effects. Here
predictor selection may be used with an indicator only on the inclusion
of the redeﬁned MCA, denoted MCA2. Thus 1 ¼ 1 if MCA2 is included,
1 ¼ 0 for model 7. A prior probability of 0.9 is assumed for Pr(1 ¼ 1)
and the posterior probability (from the second half of a two-chain run of
25 000 iterations) is 0.767. So the Bayes factor in favour of the simpler
model 7 is 2.7, which is not conclusive. A suggested exercise is to obtain
the relative risk of myocardial infarction for pill users at ages under 34
under models 7 and 8 and hence a model averaged estimate of the relative
risk based on this Bayes factor.
Example 4.6
Thromboembolism data
Case–control data ﬁrst con-
sidered by Worcester (1971) has been used in subsequent model choice
studies, such as Spiegelhalter and Smith (1982) and Pettit and Young
(1990). The data yijk cross-classify thromboembolism and control patients
(i ¼ 1 and 2 respectively) by two risk factors: oral contraceptive user (j ¼
1 for user, j ¼ 2 for non-user) and smoking (k ¼ 1 for smokers, k ¼ 2 for
non-smokers). The data are in Table 4.3.
While a design matrix approach to model speciﬁcation as in Bishop
et al. (1975) is often used, an economical model notation follows
Worcester (1971), with the saturated model (model 1) speciﬁed as
yijk  PoðijkÞ
logðijkÞ ¼ 0 þ i1 þ j2 þ k3 þ ij12 þ ik13 þ jk23 þ ijk123
where  is one only when all the subscripts are one, and is zero otherwise.
Thus
1 ¼ 11 ¼ 111 ¼ 1
Table 4.3
Risks for thromboembolism
Patient type
Smoker
Non-smoker
Totals
contraceptive user
contraceptive user
Yes
No
Yes
No
Thrombolembolism
14
7
12
25
58
Control
2
22
8
84
116
CONTINGENCY TABLES
139

but for all other subscript combinations  = 0. Hence the need to specify
corner constraints is eliminated.
For these data a close ﬁt is obtained with a model omitting 13 and 23
(this forming model 2). Model choice inferences under both methods may
be sensitive to the priors on  given the small sample size. Though
default priors based on minimal experiments have been suggested
(Spiegelhalter and Smith, 1982) one may also draw on substantive
epidemiological knowledge. On a log scale the  parameters amount to
log relative risks (this is strictly an approximation for case–control data).
Relative risks (e.g. of thromboembolism) associated with adverse beha-
vioural risk factors are usually in the range 1–10. A relative risk of 100
amounts to a virtually certain disease inception and allowing the prior on
 to include such high relative risks (i.e. virtually certain of disease or
death given a risk factor) is itself potentially informative. Instead a
normal prior on the j ð j 	 1Þ with mean 2 and variance 0.1 is assumed,
this being equivalent to a mean relative risk of 7 and 95% point above
1000. For the intercept an N(0,1000) prior is assumed.
A two-chain run of 20 000 iterations is taken, with a 1000 burn-in.
With the above prior the Gelfand–Ghosh and DIC criteria both select the
smaller model (see Example4_6.xls for calculations). Under the priors
used, the Bayes factor estimate is B21 ¼ 23:8, quite strongly in favour of
the smaller model with loge B21 ¼ 3:17. The fact that the reduced model
gives a close ﬁt implies that the use of oral contraceptives, particularly
among those who smoke, is a risk for thromboembolism, but for smokers
who do not take the pill there is no excess risk.
4.6
SEMI-PARAMETRIC AND GENERAL ADDITIVE MODELS
FOR BINOMIAL AND COUNT RESPONSES
As for metric outcomes, varying coefﬁcient and general additive models
allow possible non-linearity in the impacts of predictors in binomial,
binary or count regression but without specifying complex algebraic
forms. For instance, suppose yt is a binary outcome with responses
corresponding to ordered values of a regressor xt
x1 < x2 <    < xn
ð4:16Þ
Assuming yt  BernðtÞ, and predictors ðzi1; . . . ; ziq) with a conventional
linear impact on y, a general additive semi-parametric regression model
has the form
g½t ¼ 0 þ sðxtÞ þ z
ð4:17Þ
140
MODELS FOR BINARY AND COUNT OUTCOMES

where g is a link function (e.g. the logit). Let st ¼ sðxtÞ denote the smooth
function representing the possibly non-linear impact of x on y as it varies
over its range. For count data one might take yt  PoðtÞ or yt  NBðtÞ
with
logðtÞ ¼ 0 þ sðxtÞ þ z
For GAMs based on state-space priors, it is common to assume normal or
Student t random walks in the ﬁrst or second (and occasionally higher
order) differences of the st. If there are equal gaps between the successive
x then a ﬁrst-order normal random walk prior is
st  Nðst1; 2Þ
ð4:18Þ
or equivalently
st ¼ st1 þ ut
ð4:19Þ
where ut  Nð0; 2Þ. For greater smoothing, an RW(2) prior may be used
with
st  Nð2st1  st2; 2Þ
ð4:20Þ
or
st ¼ 2st1  st2 þ ut
For binary data, especially in small samples, the smoothing function may
not be well identiﬁed and relatively informative priors on the evolution
variance 2 may be elicited. With unequal gaps t ¼ xtþ1  xt between x
values, a ﬁrst-order normal random walk would then be
st  Nðst1; t2Þ
and a second-order one would be
st  Nð	t; t2Þ
where 	t ¼ st1ð1 þ t=t1Þ  st2ðt=t1Þ.
Since the above priors do not specify a level for st, identiﬁability may
be obtained by recentring at each MCMC iteration, namely
g½t ¼ 0 þ St þ z
where St ¼ st  s. If there is a smooth in just one predictor then an
alternative is to omit the intercept 0 and then the st need not be
recentred. Another option is to set the ﬁrst effect s1 to zero, rather than
a free parameter. Other aspects of identiﬁcation such as standardizing
predictors are also relevant to satisfactory convergence.
MODELS FOR BINOMIAL AND COUNT RESPONSES
141

Other types of prior include the state-space version of a cubic spline,
with bivariate state vector Vt ¼ ðst; dst=dtÞ evolving via
Vt ¼ FtVt1 þ ut
ð4:21Þ
where Ft is a 2  2 transition matrix, namely
Ft ¼
1
t
0
1


The ut are bivariate (e.g. MVN) with zero mean and covariance 2Ut,
where 2 is the smoothing variance and
Ut ¼
3
t =3
2
t =2
2
t =2
t


Sometimes a smooth in x interacts with the effect of another predictor z,
with
g½t ¼ 0 þ ztsðxtÞ
If xt ¼ t denotes time then a dynamic coefﬁcient model is obtained, with
g½t ¼ 0 þ zt1t
Wood and Kohn (1998) consider general additive regression of binary
data using latent continuous data or ‘utilities’, as in Albert and Chib
(1993). So if yt ¼ 1 then the latent response wt is positive, while if
yt ¼ 0; wt is constrained to be negative. Equivalence with a probit link
involves truncated normal sampling of the wt with variance 1 and means
EðwtÞ ¼ t ¼ 0 þ sðxtÞ þ z
ð4:22Þ
As mentioned above, this data augmentation approach may have beneﬁts
in sampling since full conditionals are the same as for metric (e.g.
normal) responses. Residual analysis may also be facilitated.
Spline models based on truncated polynomial or other basis functions
can be used, such as the penalized random effects spline of Ruppert et al.
(2003), with knots kðk ¼ 1; . . . ; KÞ sited at percentiles ðk þ 1Þ=ðK þ 2Þ
of xt. For binary outcomes modelled via data augmentation, a penalized
linear spline would then involve the model
wtjyt ¼ 1  Nðt; 1ÞIð0; Þ
wtjyt ¼ 0  Nðt; 1ÞIð ; 0Þ
with means
t ¼ 0 þ 1xt þ
X
K
k ¼ 1
kðxt  kÞþ
ð4:23Þ
142
MODELS FOR BINARY AND COUNT OUTCOMES

where k  Nð0; 2
Þ. A quadratic spline would have means
t ¼ 0 þ 1xt þ 1x2
t þ
X
K
k ¼ 1
kðxt  Þ2
þ
ð4:24Þ
For count data with yt  PoðtÞ a non-linear effect of a single predictor
might be combined with an error term to allow for overdispersion
(Chapter 5), as in the linear spline model
	t ¼ logðtÞ ¼ 0 þ 1xt þ
X
K
k ¼ 1
kðxt  kÞþ þ "t
With priors 1=2
  Gaða1; b1Þ, 1=2
"  Gaða2; b2Þ, the full conditionals
on 1=2
 and 1=2
" are
1=2
  Ga a1 þ 0:5K; b1 þ 0:5
X
K
k ¼ 1
2
k
 
!
1=2
"  Ga a2 þ 0:5n; b2 þ 0:5
X
n
t ¼ 1
"2
t
 
!
where
"t ¼ 	t  0 þ 1xt þ
X
K
k ¼ 1
kðxt  kÞþ
"
#
4.6.1
Robust and adaptive non-parametric regression
To allow for discontinuities or changes in curvature of the smooth or
smooths on predictors one may assume that the errors ut in (4.19) or
(4.21) come from a discrete mixture density with L components, e.g. an
RW(1) model for univariate ut would become
st  Nðst1; 2
MtÞ
Mt  CategoricalðÞ
where  ¼ ð1; . . . ; LÞ. Usually L is two or three at most. One might also
(Knorr-Held, 1999) assume a scale mixture (equivalent to a t density with
	 degrees of freedom) on the random walk parameters. For example,
st  Nðst1; 2=tÞ
ð4:25Þ
where t  Ga(0.5	, 0.5	).
Alternatively a stochastically evolving variance might be considered
instead of taking 2 constant over time. Thus let 2 ¼ expðhtÞ and let ht
MODELS FOR BINOMIAL AND COUNT RESPONSES
143

itself be an RW(1) or RW(2) series as in (4.18) and (4.20). This provides
a dependent (i.e. time structured) prior in the log variances. Alternatively
the ht might be unstructured over time and be a scale mixture just as in
(4.24). Despite the extra parameterization involved in such ‘spatially
adaptive’ models there may be a gain in ﬁt (e.g. Jerak and Lang, 2003;
Ruppert and Carroll, 2000).
4.6.2
Other approaches to non-linearity
One might also consider approaches analogous to those in section 3.4 for
non-linear predictor impacts on discrete outcomes. However, Kay and
Little (1987) propose an alternative to the Box–Cox transform
xðÞ ¼ ðx  1Þ=
of x when y is binary. Speciﬁcally they view the predictor as a random
variable with density ffjðxÞ; j ¼ 0; 1g according to whether y ¼ 0 or
y ¼ 1 and suppose that
log½ f1ðxÞ=f0ðxÞ ¼ 0 þ hðxÞ
where hðxÞ is a possibly non-linear vector transform of x. They show that
for yi  BernðiÞ, the logit transform is then linear in hðxÞ:
logitðiÞ ¼ 0 þ 1hðxÞ
Depending on the nature of x (e.g. whether its density may be character-
ized as normal, gamma, beta, etc.) they deﬁne the form hðxÞ of x such that
the logistic model obtains; there may be more than one such h transform
variable. For example, if x is gamma then the appropriate hðxÞ transforms
are x and log(x), while if x is beta with values in (0,1) then the appropriate
h variables are log(x) and log(1  x); see Example 4.9. If x is normal then
the appropriate h variables are x and x2.
Example 4.7
Blood cell sedimentation
Everitt and Rabe-Hesketh
(2001) present cubic spline smooth estimates obtained via the backﬁtting
algorithm for a sparse binary outcome, i.e. 6 out of 32 observations with
yt ¼ 1. The responses relate to the rate at which red blood cells (known as
erythrocytes) settle out of suspension in blood plasma, and the response is
one if erythrocyte sedimentation (ES) exceeds 20 mm/h, where values
below this threshold characterize healthy individuals. The probability of a
positive (i.e. morbid) response is related to smooths sðxÞ in two plasma
proteins, ﬁbrinogen ðx1tÞ and gamma-globulin ðx2tÞ, which are recorded
in gm/l.
144
MODELS FOR BINARY AND COUNT OUTCOMES

Here a direct Bernoulli likelihood approach with logit link is used to
obtain smooth functions in the proteins. Because there are ties on both
predictors (i.e. two or more subjects with the same values) the smoothing
prior is speciﬁed in terms of the nu1 ¼ 28 distinct values of ﬁbrinogen and
nu2 ¼ 15 distinct values of gamma-globulin. Further, the values are
unequally spaced, with jt ¼ xj;tþ1  xj;t deﬁning the gaps in the ordered
predictor values xjt. Since there are two predictors (Table 4.4), the data
cannot be uniquely ordered as in (4.16), and it is necessary to record the
Table 4.4
Original data and ranks on predictors
Subject
Fibrinogen ðx1Þ
Gamma ðx2Þ
Rank x1
Rank x2
y
1
2.52
38
12
11
0
2
2.56
31
14
4
0
3
2.19
33
4
6
0
4
2.18
31
3
4
0
5
3.41
37
25
10
0
6
2.46
36
11
9
0
7
3.22
38
22
11
0
8
2.21
37
5
10
0
9
3.15
39
21
12
0
10
2.6
41
15
13
0
11
2.29
36
8
9
0
12
2.35
29
9
2
0
13
5.06
37
28
10
1
14
3.34
32
24
5
1
15
2.38
37
10
10
1
16
3.15
36
21
9
0
17
3.53
46
26
15
1
18
2.68
34
18
7
0
19
2.6
38
15
11
0
20
2.23
37
6
10
0
21
2.88
30
19
3
0
22
2.65
46
16
15
0
23
2.09
44
1
14
1
24
2.28
36
7
9
0
25
2.67
39
17
12
0
26
2.29
31
8
4
0
27
2.15
31
2
4
0
28
2.54
28
13
1
0
29
3.93
32
27
5
1
30
3.34
30
24
3
0
31
2.99
36
20
9
0
32
3.32
35
23
8
0
MODELS FOR BINOMIAL AND COUNT RESPONSES
145

ranks r1t and r2t of the tth subject on each predictor. Then yt  BernðtÞ,
and assuming a logit link without data augmentation, approach (a)
leads to
logit½t ¼ 0 þ 1x1t þ g1ðx1;r1tÞ þ 2x2t þ g2ðx2;r2tÞ
The smoothing prior is as in (4.21) with a Ga(1, 0.01) prior on the
smoothing precision 1/2.
A two-chain run of 10 000 iterations (convergent after 1000) shows that
the total regression effect for ﬁbrinogen, 1x1t þ s1ðx1;r1tÞ, is primarily
linear in shape, though there is increased variability at larger values
(Figure 4.1). The regression effect for gamma-globulin (Figure 4.2)
shows some non-linearity, i.e. an attenuation of the effect at middle
values. Figure 4.2 replicates that in Everitt and Rabe-Hesketh (2001,
p 300).
Example 4.8
Union membership and wages
Berndt (1991) consid-
ers data from the 1985 US Current Population Survey (CPS) on the
relation between union membership and hourly wage rates. Consider a
−4
−2
0
2
4
6
8
10
1.8
2.8
3.8
4.8
5.8
Mean
10%
90%
Figure 4.1
Total impact of ﬁbrinogen
−5
−3
−1
1
3
5
25
30
35
40
45
50
Mean
10%
90%
Figure 4.2
Total impact of gamma-globulin
146
MODELS FOR BINARY AND COUNT OUTCOMES

penalized random effects linear spline, as in (4.23), for the impact of
wages on the binary outcome. A logit regression without data augmenta-
tion is used. K ¼ 19 knots are used, starting with the 5th percentile for
wages and ending with the 95th percentile. (The code in Program 4.8
allows for a quadratic spline instead.) A Ga(0.5, 0.1) prior is assumed for
2
. A two-chain run of 10 000 iterations (convergent from 1000) shows a
clear non-linear effect (Figure 4.3), with the maximum probability
occurring at a wage rate of around $14 per hour.
Example 4.9
Age at menarche
Kay and Little (1987) consider
binomial data on age at menarche in 3918 Warsaw girls, arranged in
25 age groups. Table 4.5 shows that the ages x range between 9.2 and
17.6 and one possible approach (model A) takes
yi  Binðni; iÞ
logitðiÞ ¼ 0 þ 1xðÞ
where xðÞ ¼ ðx  1Þ= ð 6¼ 0Þ, xðÞ ¼ logðxÞ ð ¼ 0Þ. Alternatively,
by transforming x to range between 0 and 1 according to v ¼ ðx  9Þ=18
it is reasonable to regard v as a beta variable. In this case (model B) the
relevant predictors are logðvÞ and log(1  v), and
logitðiÞ ¼ 0 þ 1 logðvÞ þ 2 logð1  vÞ
For model A a uniform prior Uð2; 2Þ is adopted for . Should initial
runs suggest this not to be wide enough an interval, a prior such as
Uð5; 5Þ might be used. The criterion (4.12) under model A is 496 with
0
0.1
0.2
0.3
0.4
0.5
0
10
20
30
Wage rate
prob(union
member)
Prob+SD
Prob-SD
Figure 4.3
Union membership probability and wages per hour
MODELS FOR BINOMIAL AND COUNT RESPONSES
147

ð0; 1Þ ¼ ð91; 55Þ and  ¼ 0:36 with a 95% interval ð0:45;
0:24Þ. Under model B, the same criterion is 472 with improved
predictions at the lowest ages and the highest age; the parameter means
from a two-chain run of 50 000 iterations are ð0; 1; 2Þ ¼ ð2:3; 4:4;
2:3Þ. However, the predictions under model B are less precise and using
(4.10) with k at one or less shows model B with less advantage.
Table 4.5
Age at menarche
Mean
Total
Number
Predictions
age
having
—————————————————
menstruated
Box–Cox model
Log (v) and
log (1  v),
v beta
———————
——————
Z
sd(Z)
Z
sd(Z)
9.21
376
0
0.2
0.47
0.0
0.00
10.21
200
0
1.2
1.09
0.6
0.81
10.58
93
0
1.1
1.07
1.0
1.03
10.83
120
2
2.5
1.57
2.1
1.51
11.08
90
2
3.0
1.75
2.9
1.76
11.33
88
5
4.8
2.18
4.7
2.23
11.58
105
10
8.7
2.89
9.2
3.02
11.83
111
17
13.9
3.63
14.9
3.96
12.08
100
16
18.4
4.06
19.1
4.22
12.33
93
29
24.0
4.47
25.0
4.37
12.58
100
39
34.9
5.00
35.9
5.00
12.83
108
51
48.6
5.47
49.3
5.74
13.08
99
47
54.5
5.15
54.2
5.34
13.33
106
67
68.7
5.20
67.5
5.32
13.58
105
81
76.5
4.75
75.5
4.60
13.83
117
88
93.5
4.51
92.4
4.77
14.08
98
79
83.5
3.66
82.3
3.71
14.33
97
90
86.6
3.12
86.0
3.27
14.58
120
113
110.7
3.06
110.1
3.19
14.83
102
95
96.4
2.37
96.2
2.45
15.08
122
117
117.1
2.20
117.1
2.32
15.33
111
107
107.8
1.84
108.0
1.93
15.58
94
92
92.1
1.39
92.3
1.39
15.83
114
112
112.3
1.32
112.6
1.22
17.58
1049
1049
1047.0
1.43
1049.0
0.44
148
MODELS FOR BINARY AND COUNT OUTCOMES

EXERCISES
1. In Example 4.3 ﬁnd the outlier probabilities under the variance
inﬂation model when the variance for outliers is ﬁve rather than ten.
2. In Example 4.7 use the data augmentation approach equivalent to a
logit link to obtain smooths in the proteins. This means sampling
according to
wt  logisticðt; 1ÞIðAt; BtÞ
t ¼ 0 þ 1x1t þ s1ðx1;r1tÞ þ 2x2t þ s2ðx2;r2tÞ
At ¼ 1; Bt ¼ 0
if yt ¼ 0
At ¼ 0; Bt ¼ 1
if yt ¼ 1
In practice default limits may replace inﬁnities for At, Bt. A logit link
is also achieved (approximately) by sampling the wt from a Student t
with 	 ¼ 8 degrees of freedom, or by scale mixing and normal
sampling, namely
wt  Nðt; 1=tÞIðAt; BtÞ
where the t are drawn from a gamma density G(0.5	, 0.5	). In this
case, do the sampled t suggest any outlying cases?
3. There are potentially non-linear impacts of the predictors used in
Example 4.4. Use the penalized random effects approach, with either
quadratic or linear splines as in (4.23) or (4.24), to investigate possible
non-linearity in the impacts of X1 ¼ population density, X2 ¼ %
economically active in classes IV and V, and X3 ¼ private renting.
To avoid numerical overﬂow under the quadratic spline, dividing the
predictors by 100 is recommended.
4. In Example 4.8 use an augmented data approach with normal
sampling but scale mixing to allow for outliers. Are any apparent?
Let the degrees of freedom of the scale mixture be unknown and so
assess whether a probit or logit link is more suitable.
5. Using the results in Table 4.5 obtain criterion (4.10) for k ¼ 1 and
k ¼ 0:5. Also add code to Program 4.9 in order to obtain criterion
(4.11) for k ¼ 1000, k ¼ 1 and k ¼ 0:5.
6. In Example 4.9 apply the augmented data probit regression model in
(4.4). This means adopting a disaggregated model at the level of each
girl and using the average age in each band as the predictor. Apply the
EXERCISES
149

hðxÞ transforms model along with variance inﬂation as in (4.7) to
check for outliers. Alternatively introduce variance scale factors i as
in (4.3) with degrees of freedom 	 unknown and check for outliers
using the i themselves.
REFERENCES
Albert, J. (1988) Bayesian estimation methods for Poisson means using a
hierarchical log-linear model. In Bayesian Statistics 3, Bernardo, J., DeGroot,
M., Lindley, D. and Smith, A. (eds). Oxford University Press, Oxford, 519–
531.
Albert, J. (1996) Bayesian selection of log-linear models. Canadian Journal of
Statistics, 24, 327–347.
Albert, J. (1999) Criticism of a hierarchical model using Bayes factors. Statistics
in Medicine, 18, 287–305.
Albert, J. and Chib, S. (1993) Bayesian analysis of binary and polychotomous
response data. Journal of the American Statistical Association, 88, 669–679.
Albert, J. and Chib, S. (1995) Bayesian residual analysis for binary response
regression models. Biometrika, 82, 747–759.
Bedrick, E., Christensen, R. and Johnson, W. (1996) A new perspective on priors
for generalized linear models. Journal of the American Statistical Association,
91, 1450–1460.
Berndt, E. (1991) The Practice of Econometrics. Addison-Wesley: Reading, MA.
Bishop, Y., Fienberg, S. and Holland, P. (1975) Discrete Multivariate Analysis:
Theory and Practice. MIT Press: Cambridge, MA.
Bo¨hning, D. (1999) Computer-Assisted Analysis of Mixtures and Applications:
Meta-Analysis, Disease Mapping and others. Chapman and Hall: London/
CRC Press: Boca Raton, FL.
Carlin, B. and Louis, T. (1996) Bayes and Empirical Bayes Methods for Data
Analysis. London: Chapman and Hall.
Chaloner, K. and Brant, R. (1988) A Bayesian approach to outlier detection and
residual analysis. Biometrika, 75, 651–659.
Chib, S. (1995) Marginal likelihood from the Gibbs output. Journal of the
American Statistical Association, 90, 1313–1321.
Collett, D. (2003) Modelling Binary Data, 2nd Edition. Chapman and Hall:
London/CRC Press: Baton Roca, FL.
Congdon, P. (2003) Applied Bayesian Modelling. John Wiley & Sons: Chichester.
Congdon, P. (2005) Bayesian predictive model comparison via parallel sampling,
Computational Statistics and Data Analysis, 48, 735–753.
Copas, J. (1988) Binary regression models for contaminated data. Journal of the
Royal Statistical Society, Series B, 50, 225–265.
150
MODELS FOR BINARY AND COUNT OUTCOMES

Dellaportas, P. and Forster, J. (1999) Markov chain Monte Carlo model determi-
nation in hierarchical and graphical log-linear models. Biometrika, 86, 615–
633.
Epstein, A. and Fienberg, S. (1991) Bayesian estimation in multidimensional
contingency tables. In Computer Science and Statistics: Proceedings of the
Twenty-Third Symposium on the Interface, Keramidas, E (ed.). Interface
Foundation of North America: Fairfax, VA, 37–47.
Everitt, B. and Rabe-Hesketh, S. (2001) Analyzing Medical Data using S-PLUS.
Springer: New York.
Fahrmeier, L. and Knorr-Held, L. (2000) Dynamic and semiparametric models.
In Smoothing and Regression: Approaches, Computation and Application,
Schimek, M. (ed.). John Wiley & Sons: New York, 513–544.
Gelfand, A. and Ghosh, S. (1998) Model choice: A minimum posterior predictive
loss approach. Biometrika, 85, 1–11.
Gelman, A., Carlin, J., Stern, H. and Rubin, D. (1995) Bayesian Data Analysis, 1st
Edition. Chapman and Hall: London.
George, E. and McCulloch, R. (1993) Variable selection via Gibbs sampling,
Journal of the American Statistical Association, 88, 881–889.
George, E., McCulloch, R. and Tsay, R. (1996) Two approaches to Bayesian
model selection with applications. In Bayesian Analysis in Statistics and
Econometrics: Essays in Honor of Arnold Zellner, Berry, D., Chaloner, K.
and Geweke, J. (eds). John Wiley & Sons: New York.
Gerlach, R., Bird, R. and Hall, A. (2002) Bayesian variable selection in logistic
regression: predicting company earnings direction. Australian & New Zealand
Journal of Statistics, 2, 155–168.
Gilks, W. and Wild, P. (1992) Adaptive rejection sampling for Gibbs sampling.
Applied Statistics, 41, 337–348.
Gunel, E. and Dickey, J. (1974) Bayes factors for independence in contingency
tables. Biometrika, 61, 545–557.
Harvey, A. (1976) Estimating regression models with multiplicative heterosce-
dasticity. Econometrica, 44, 461–465.
Hoeting, J., Raftery, A. and Madigan, D. (1996) A method for simultaneous
variable selection and outlier identiﬁcation in linear regression. Computational
Statistics and Data Analysis, 22, 251–270.
Holford, T., White, C. and Kelsey, J. (1978) Multivariate analysis for matched
case-control studies. American Journal of Epidemiology, 107, 245–256.
Jerak, A. and Lang, S. (2003) Locally adaptive function estimation for binary
regression models. Discussion Paper 310, SFB 386, University of Munich.
Jochmann, M. (2003) Semiparametric Bayesian inference for count data treat-
ment models. Department of Economics, University of Konstanz.
Kahn, M. and Raftery, A. (1996) Discharge rates of Medicare stroke patients to
skilled nursing facilities: Bayesian logistic regression with unobserved hetero-
geneity. Journal of the American Statistical Association, 91, 29–41.
REFERENCES
151

Kay, R. and Little, S. (1987) Transformations of the explanatory variables in the
logistic regression model for binary data. Biometrika, 74, 495–501.
Knorr-Held, L.
(1999)
Conditional
prior
proposal
in
dynamic
models.
Scandinavian Journal of Statistics, 26, 129–144.
Knuiman, M. and Speed, T. (1988) Incorporating prior information into the
analysis of contingency tables. Biometrics, 44, 1061–1071.
Kuo, L. and Mallick, B. (1998) Variable selection for regression models. Sankhya,
60B, 65–81.
Laud, P. and Ibrahim, J. (1995) Predictive model selection. Journal of the Royal
Statistical Society, Series B, 57, 247–262.
Leonard, T. and Hsu, J. (1994) The Bayesian analysis of categorical data – a
selective review. In Aspects of Uncertainty: A Tribute to DV Lindley, Freeman,
P. and Smith, A. (eds). John Wiley & Sons: Chichester.
McCullagh, P. and Nelder, J. (1989) Generalized Linear Models, 2nd Edition.
Chapman and Hall: London.
Meyer, M. and Laud, P. (2002) Predictive variable selection in generalized linear
models. Journal of the American Statistical Association, 97, 859–871.
Ntzoufras, I. (1999) Aspects of Bayesian model and variable selection using
MCMC. Department of Statistics, Athens University of Economics and
Business.
Oh, M. (1997) A Gibbs sampling approach to Bayesian analysis of generalized
linear models for binary data. Computational Statistics, 12, 431–445.
Oh, M. and Lim, Y. (2001) Bayesian analysis of time series Poisson data. Journal
of Applied Statistics, 28, 259–271.
Pettit, L. and Young, K. (1990) Measuring the effect of observations on Bayes
factors. Biometrika, 77, 455–466.
Raftery, A. (1996) Approximate Bayes factors and accounting for model uncer-
tainty in generalised linear models. Biometrika, 83, 251–266.
Ruppert, D. and Carroll, R. (2000) Spatially-adaptive penalties for spline ﬁtting.
Australian and New Zealand Journal of Statistics, 42, 205–223.
Ruppert, D., Wand, M. and Carroll, R. (2003) Semiparametric Regression.
Cambridge University Press: Cambridge.
Scott, S. (2003) Data augmentation for the bayesian analysis of multinomial logit
models. Proceedings of the American Statistical Association Section on
Bayesian Statistical Science. American Statistical Association: Alexandria,
VA.
Smith, M. and Kohn, R. (1996) Nonparametric regression using Bayesian variable
selection. Journal of Econometrics, 75, 317–334.
Spiegelhalter, D. and Smith, A. (1982) Bayes factors for linear and log-linear
models with vague prior information. Journal of the Royal Statistical Society,
Series B, 44, 377–387.
Verdinelli, I. and Wasserman, L. (1991) Bayesian analysis of outlier problems
using the Gibbs sampler. Statistics and Computing, 1, 105–117.
152
MODELS FOR BINARY AND COUNT OUTCOMES

Wakeﬁeld, J. and Best, N. (1999) Accounting for inaccuracies in populations
counts and case registration in cancer mapping studies. Journal of the Royal
Statistical Society, Series A, 162, 363–382.
Wood, S. and Kohn, R. (1998) A Bayesian approach to robust nonparametric
binary regression. Journal of the American Statistical Association, 93, 203–
213.
Worcester, J. (1971) The relative odds in the 23 contingency table. American
Journal of Epidemiology, 93, 145–149.
Zellner, A. and Rossi, P. (1984) Bayesian analysis of dichotomous quantal
response models. Journal of Econometrics, 25, 365–393.
REFERENCES
153


CHAPTER 5
Further Questions in
Binomial and Count
Regression
5.1
GENERALIZING THE POISSON AND BINOMIAL:
OVERDISPERSION AND ROBUSTNESS
The Poisson and binomial models assume that the variances of the observ-
ations are known functions of the mean parameters. In practice data of
both types may be more dispersed than these densities assume. Such over-
dispersion of excess heterogeneity may reﬂect a few extreme observa-
tions or multiple modes, clustering of high or low rates, clumped or other
non-random sampling (Efron, 1986), or variation between units of widely
different exposures (e.g. death totals for areas differing widely in popu-
lation size). Alternatively it may be due to unobserved variations between
subjects (or frailties) i that are not represented by the observed
covariates. Without correction for extra variation the precision of the 
parameters will be overstated: their credible intervals will be too narrow
(Cameron and Trivedi, 1998). Extra variation may be partly caused by
poor ﬁt. For example, standard GLM assumptions may also not hold for
the assumed link and a better ﬁt may be obtained with an alternative link.
There may also be heterogeneity in the appropriate link.
For metric data an overdispersed alternative to the univariate or
multivariate normal is the Student t density, which can be obtained by
mixing on the scale parameters (variance or covariance matrix) of the
normal. In the same way, the binomial and Poisson densities may need to
Bayesian Models for Categorical Data
P. Congdon
# 2005 John Wiley & Sons, Ltd

be modiﬁed when the observed variance exceeds the form assumed under
the density, and this involves a mixture distribution on the binomial
probability or the Poisson mean. This may be combined with adoption of
alternative link functions or mixing over links.
Mixture and link generalizations can be seen both as providing greater
robustness in inferences (Gelman et al., 2003) and as providing a density
that is compatible with the data. Another motivation for mixture models
is to pool information over units when event counts for each unit may
vary considerably; by modelling the rates for individual units in terms of
an overall hyperdensity, shrinkage estimates may be obtained for each
unit that smooth towards the average. For example, for death rates by
area, these estimates would be a weighted combination of the population
mean rate and the rate derived by treating each area in isolation (Bo¨hning,
1999). In models with both spatial and unstructured errors pooling
may be to local (neighbourhood) means as well as to the global average
(Chapter 8). Another application is in ‘ecological’ inference (e.g. in
voting applications) when only the marginals of R  C tables are
observed and a model is required for the internal cells (Rosen et al., 2001;
Haneuse and Wakeﬁeld, 2004) – see Chapter 11.
For a set of occurrences/trials data ½fy1; ng; fy2; ng; . . . ; fyg; ng con-
forming to the standard binomial density with common probability  and
Beða; bÞ prior, the posterior mean of y is that of a Beða þ P
i yi; a þ
b þ gnÞ density, with EðjyÞ ¼ ða þ P
i yiÞ=ða þ b þ gnÞ and variance
VðyÞ ¼ nEðjyÞ½1  EðjyÞ. Overdispersion would mean VðyÞ exceeding
nEðjyÞ½1  EðjyÞ. For Poisson count data with prior   Gaðc; dÞ and
observations fy1; . . . ; yng the posterior density is Gaðc þ P
i yi; d þ nÞ
with mean ðc þ P
i yiÞ=ðd þ nÞ and the variance equals this mean. For
data subject to overdispersion the observed variance exceeds the mean. It
is also possible, though less frequent, for data to be underdispersed
relative to the standard Poisson assumption. Similarly in Poisson or
binomial regression it is often found that the conditional variance VðyijxiÞ
exceeds its nominal value under Poisson or binomial sampling. For
Poisson data this means VðyijxiÞ exceeds i ¼ EðyijxiÞ where for instance
i ¼ expðxiÞ.
In many cases data yi are not simply overdispersed but contain too
many zeros to be Poisson or binomial. Such systematic departures from
Poisson or binomial sampling require a different method that explicitly
models the excess frequency of zero observations. Retaining the usual
sampling models, albeit mixed with gamma or beta frailties, will lead to
underprediction of the percentage of zero counts (Hall, 2000; Lambert,
156
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

1992). Models explicitly approaching excess zeros in relation to the
Poisson or binomial models are considered in section 5.4.
5.2
CONTINUOUS MIXTURE MODELS
While other analyses are possible and commonly used in more complex
applications (e.g. general linear mixed models for multilevel and panel
applications), the conjugate mixture distributions are often used in
simple applications, especially in non-regression situations. The conju-
gate model for count data that is often used to account for extra variation
replaces the model yi  PoðiÞ by a model with heterogeneous means
following a gamma density. Thus
yi  PoðiÞ
i  Gað; Þ
Parameterizing the mean of the i as  ¼ =, one obtains EðÞ ¼  and
VðÞ ¼ =2 ¼ 2=. Then
VðyÞ ¼ E½VðyjÞ þ Var½EðyjÞ ¼  þ 2= ¼ ð1 þ =Þ
so that overdispersion applies if  > 0 where  ¼ 1=.
To represent unobserved heterogeneity for count data in a regression
analysis, a multiplicative frailty with log-link would mean
yi  Poð	iÞ
	i ¼ ii ¼ expðXiÞi
Assuming a gamma frailty model i  Gað; Þ, conjugate to the Poisson
density, then
PðyijXi; iÞPðiÞ ¼ fexpðiiÞ½iiyi=yi!gf1
i
expðiÞ=ðÞg
Integrating out i, as in
PðyijXiÞ ¼
ð
PðyijXi; iÞPðiÞdi
leads to a marginal negative binomial density for yi. The identiﬁability
constraint  ¼  is frequently used, the alternative being to exclude an
intercept in Xi. With this constraint VðiÞ ¼ 1= and the negative
binomial NBði; Þ has the form
PðyijXiÞ ¼ ð þ yiÞ=fðÞðyi þ 1Þg

 þ i


i
i þ 

yi
ð5:1Þ
CONTINUOUS MIXTURE MODELS
157

With estimation by repeated sampling it is straightforward to analyse
using either the negative binomial likelihood or the mixed Poisson–
gamma likelihood. Alternative gamma mixtures are possible (Albert,
1999), namely
yi  Poð	iÞ
	i  Gaði; Þ
ð5:2Þ
giving Varð	iÞ ¼ i= and
VðyijXiÞ ¼ i þ i=
Conditional on , the 	i are Gaðyi þ i; 1 þ Þ with mean
ð1  SÞyi þ Si
where S ¼ =ð þ 1Þ is a shrinkage factor. If the observations result
from different exposures Ei with yi  Poð	iEiÞ, then the underlying rates
	ij are Gaðyi þ i; Ei þ Þ with posterior mean
ð1  SiÞyi=Ei þ Sii
where Si ¼ =ð þ EiÞ. Si is the proportion of shrinkage from the crude
unpooled estimate towards the hierarchical model mean i. Larger values
of  mean greater shrinkage, and the non-hierarchical Poisson corre-
sponds to  ! 1. Alternatively
	i  Gð; =iÞ
ð5:3Þ
gives
VðyijXiÞ ¼ i þ 2
i =
and 	ij  Gaðyi þ i; Ei þ =iÞ with mean
ð1  SiÞyi þ Sii
where Si ¼ =ð þ EiiÞ. These are known as the NB1 and NB2 models
respectively (Cameron and Trivedi, 1998). PðyjXÞ as in (5.1) corresponds
to the NB2 form, since Vð	iÞ ¼ 2
i =.
In a generalization of the negative binomial, Winkelmann and
Zimmermann (1995) propose a variance function
VðyijXiÞ ¼ i þ þ1
i
where  > 0 and  	 1. The Poisson is the limiting case when  tends
to zero. This variance function is obtained by
yi  Poð	iÞ
	i  Gð1
i
=; 
i =Þ
ð5:4Þ
158
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

The value  ¼ 0 means the conditional variance is ð1 þ Þi, while
 ¼ 1 gives VðyijXiÞ ¼ i þ 2
i . So this mixture includes the NB1 and
NB2 models and the form (5.4) may be used to decide which is more
appropriate to the data.
A further development in the negative binomial or Poisson–gamma
approach is to let the variance parameter  vary by subjects (e.g. Dey
et al., 1997; Efron, 1986), so that
yi  Poð	iÞ
	i  Gð1=i; 1=½iiÞ
with i ¼ expðXiÞ, and i ¼ expðZiÞ, where Xi and Zi may overlap.
For instance, in count data with varying exposures Ei it may be that
variances depend on Ei, so that
logðiÞ ¼ 0 þ 1Ei
The main alternative to a conjugate frailty is an additive random error
in gðiÞ so that
yi  PoðiÞ
gðiÞ ¼ 0 þ Xi þ "i
ð5:5Þ
where "i may follow a parametric density (e.g. normal or Student t). As
noted by Engel and Keen (1994, p 12) if the log-link is assumed and
"  Nð0; Þ then to a close approximation, VðyijXiÞ ¼ i þ 2
i . To
avoid possible identiﬁability problems with regard to 0 and the average
of "i, one may instead take
gðiÞ ¼ 0i þ Xi
where 0i is randomly distributed.
For occurrences–trials data the conjugate frailty model assumes 
to vary from trial to trial according to a beta density. Thus instead of
yi  Binðni; Þ it is assumed that
yi  Binðni; iÞ
i  Betað1; 2Þ
A reparameterized beta density, setting  ¼ 1 þ 2,  ¼ 1=, is often
preferred since  and  are closer to being orthogonal, so that
i  Betað; ð1  ÞÞ
ð5:6Þ
The variance of yi is then given by
VðyiÞ ¼ niið1  iÞ ni þ 
 þ 1


CONTINUOUS MIXTURE MODELS
159

and the correlation between individual responses within each trial is
1=ð1 þ 1 þ 2Þ ¼ 1=ð1 þ Þ
ð5:7Þ
The beta–binomial is not in the exponential family even for known .
If covariates are available, one may (Kahn and Raftery, 1996) take  to
vary over cases with
gðiÞ ¼ Xi
where g is an appropriate link, such as logitðiÞ ¼ Xi.
The GLMM alternative is to take yi  Binðni; iÞ as above but assume
an additive random error in gðiÞ. For example,
logitðiÞ ¼ Xi þ "i
ð5:8Þ
where "i may follow a parametric density or a non-parametric mixture.
Taking " to be normal gives the logistic normal model (Pierce and Sands,
1975). Engel and Keen (1994) show that, to a close approximation, if
"i  Nð0; Þ and i ¼ nii then
VðyijXiÞ ¼ i 1  i
ni


1 þ i 1  i
ni

 ni  1
ni




Example 5.1
Male suicides in England
To illustrate count overdis-
persion, consider (as in Example 4.4) male suicides yi in 1989–1993
in 354 English local authorities (Example5_1.xls). Four predictors are
used to predict suicide relative risks. These are X1 ¼ single, widowed,
divorced, X2 ¼ one-person households, X3 ¼ % economically active in
classes IV and V, and X4 ¼ population density (divided by 1000). On the
basis of Example 4.4, X2–X4 would be expected to be the most important
of these. However, other aspects of the data need to be considered, e.g.
the adequacy of Poisson regression in modelling the dispersion in the
data. The variance of the yi is 1567 compared with the mean of 52 and the
predictions of an adequate model would reﬂect this overdispersion.
In particular, if zi are samples of new data from the model being
applied, a posterior predictive check for an adequate model would show
overdispersion in the z compatible with that in the y. So one might
compare the ratio of variance with mean between z and y, by calculating
CðtÞ
z
¼ VðzðtÞÞ=zðtÞ
for the sampled z at iteration t and comparing it with Cy ¼ VðyÞ=y ¼
1567=52 ¼ 30:1
160
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

A basic assessment of how far overdispersion is adequately modelled
involves comparing the average of the sampled deviances, namely DðtÞ
where
DðtÞ ¼ 2
X
ðyi þ 0:5Þ log½ðyi þ 0:5Þ=ððtÞ
i
þ 0:5Þ  ðyi  ðtÞ
i Þ
n
o
with the available degrees of freedom, namely n  p or n  pe. On this
basis, a simple Poisson regression (model A), sampling for which conver-
ges from 1000 iterations of a two-chain run of 20 000 iterations, seems
reasonably adequate with D ¼ 526. However, the predictive check shows
an average probability Pc ¼ 0:96 that CðtÞ
z
exceeds Cy, whereas acceptable
bounds for Pc are between 0.10 and 0.90. Predictors fX1–X4g under model
A are ‘signiﬁcant’ in the sense of 95% intervals above zero for X1, X2 and
X3 and below zero for X4. The 95% interval for X1 is from 0.0003 to 0.0082.
For the NB1 Poisson–gamma mixture as in (5.2), a two-chain run of
20 000 iterations (convergent from 10 000) gives an improved deviance
D ¼ 361, and a more compatible predictive check with PðCðtÞ
z
> CyÞ ¼
0:86. The dispersion parameter  is estimated at 0.47. The impact of X1
remains signiﬁcant under this model with 95% interval f0:0004; 0:0024g.
A further improved ﬁt and satisfactory predictive check are achieved by
the generalized gamma mixture (5.4) with D ¼ 337 and PðCðtÞ
z
> CyÞ ¼
0:73. Here  ¼ 1:05 and  ¼ 0:02. Estimates of CPOs under this model
are obtained from (2.15). The 16 areas with scaled CPOs under 0.01
(Table 5.1) may suggest excluded predictors; for example, 3 of the 16 are
coastal resorts with higher suicide rates than predicted under the model,
perhaps reﬂecting the transient populations attracted to such areas.
5.2.1
Modified exponential families
As well as GLMM and conjugate mixture models, more fundamental
extensions of the GLM allow modelling of the variance (and hence over-
dispersion) as well as regression for the mean. Efron (1986) pointed out
the limitation of the binomial variance assumption in which VarðyiÞ is
inversely proportional to the sample size ni, especially when samples of
subjects are subject to clumping. Efron discussed the family of double-
exponential models that include double-binomial and double-Poisson
models. Instead of the standard binomial and Poisson densities that con-
tain only mean parameters, their double versions include mean and vari-
ance parameters i and ’i that may be related to predictors (including
actual sample size in the case of ’i under the binomial). For example, the
double Poisson takes the form
log½Pðyj; ’Þ ¼ cðyÞ þ 0:5 logð’Þ  ’ þ ’y logðe=yÞ
CONTINUOUS MIXTURE MODELS
161

where cðyÞ is a function of y alone. Under the double binomial, the vari-
ance of yi is approximately ið1  iÞ=½ni’i rather than ið1  iÞ=ni.
Efron’s double-binomial analysis of toxoplasmosis data for 34 cities in
El Salvador took the variance function to be a quadratic in the sample
sizes
’i ¼ M=½1 þ expðiÞ
i ¼ 0 þ 1ni þ 2n2
i
It may be noted that modelling of binomial data by Bernoulli disaggre-
gation and then data augmentation, as in (4.3), has a similar impact to
the double exponential if combined with scale mixing as in (4.5). Thus
for i ¼ 1; . . . ; g,
wij  NðXi; 1=iÞIð0; 1Þ
j ¼ 1; yi
wij  NðXi; 1=iÞIð1; 0Þ
j ¼ ni  yi þ 1; ni
Table 5.1
Diagnostics for another areas
Area
Log
Ratio of
^Y
^
SMR
SMR
Crude
Y
Expected
(CPO)
CPO to
(posterior
SMR
(actual
deaths
maximum
mean
deaths)
CPO
of i)
Lambeth
6.39
0.00289
130.0
135.1
151
146
96.2
Shefﬁeld
6.38
0.00294
194.6
94.7
87
179
205.5
Wycombe
6.20
0.00351
62.5
106.1
130
77
58.9
Burnley
6.18
0.00357
42.3
131.2
172
56
32.3
Taunton Deane
6.16
0.00365
43.4
123.6
162
57
35.1
Bedford
6.07
0.00401
60.6
120.2
148
75
50.4
Bournemouth
5.90
0.00473
81.5
135.8
159
96
60.0
Reigate &
5.63
0.00623
48.5
110.5
139
61
43.9
Banstead
Waltham Forest
5.43
0.00757
70.3
88.9
74
58
79.0
Bassetlaw
5.37
0.00808
47.0
119.0
149
59
39.5
Torbay
5.34
0.00829
56.8
131.8
160
69
43.1
Manchester
5.27
0.00889
224.5
143.3
150
235
156.7
Sunderland
5.24
0.00912
95.4
90.3
79
83
105.6
East Riding
5.20
0.00959
97.7
87.6
77
86
111.6
of Yorkshire
Derwentside
5.19
0.00962
31.3
99.1
67
21
31.6
Hastings
5.17
0.00984
39.9
130.1
165
51
30.7
SMR ¼ Standard Mortality Ratio
162
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

where logðiÞ may be modelled as a function of ni. The double expo-
nential also has afﬁnities with the scaled exponential families proposed
by West (1985) and the exponential dispersion models of Jorgensen
(1987). Gelfand and Dalal (1990) and Dey et al., (1997) consider
overdispersed GLMs based on a two-parameter exponential family of
the form
log½Pðyj; Þ ¼ cðyÞ þ y þ TðyÞ  ð; Þ
ð5:9Þ
where the usual exponential family of Chapter 1 occurs when  ¼ 0.
Including a variance function aðÞ in (5.9) and setting ð; 0Þ ¼ bðÞ, the
usual exponential family is
log½Pðyj; Þ ¼ cðy; Þ þ ½y  bðÞ=aðÞ
Often aðÞ ¼ =n and another way of modelling overdispersion is to
take  to vary over subjects according to logðiÞ ¼ Zi (Ganio and
Schafer, 1992) The usual one-parameter family is obtained only for
given i.
5.3
DISCRETE MIXTURES
While continuous mixtures such as the gamma–Poisson and beta–binomial
model have advantages of conjugacy, they are not necessarily always the
most suitable way of modelling overdispersion. Finite mixture models as
discussed in Chapter 3 may have beneﬁt in representing overdispersion
while simultaneously providing robust inferences (see e.g. Aitkin, 1996;
Aitkin, 2001; Hurn et al., 2003). For count data yi without covariates one
might assume a mixture over Poisson or negative binomial densities
Pðyij; Þ ¼
X
J
j¼1
jPoðyijjÞ
Pðyij; ; Þ ¼
X
J
j¼1
jNBðyijj; jÞ
As in Chapter 3 a mixture of Poisson or negative binomial densities can be
formulated as a hierarchical model using the latent variable Gi that
allocates subject i to one of the components. So a Poisson mixture can
be represented as
PðyijGi ¼ jÞ ¼ PoðjÞ
DISCRETE MIXTURES
163

With predictors Xi one might consider mixtures of Poisson regressions
such that
EðyijXiÞ ¼
X
J
j¼1
j expðjXiÞ
ð5:10aÞ
or mixtures of logistic regressions for binary data, with
EðyijXiÞ ¼
X
J
j¼1
jfexpðjXiÞ=½1 þ expðjXiÞg
ð5:10bÞ
A discrete mixture may also be relevant in modelling overdispersion.
Thus for Poisson overdispersion, one might assume
yi  PoðiÞ
gðiÞ ¼ 0 þ 1Xi þ "i ¼ 0i þ 1Xi
where the prior for 0i may follow a ﬁnite mixture of normal densities
with differing means and variances
0i 
X
J
j¼1
jNðBj; jÞ
One might also take discrete mixtures of the conjugate Poisson–gamma
or beta–binomial models (Moore et al., 2001). For example, with bino-
mial data, let
yi  Binðni; iÞ
i 
X
J
j¼1
j Betaðij; ijÞ
ð5:11Þ
A reparameterization of the beta in terms of ij ¼ ijj and ij ¼
ð1  ijÞj facilitates regression modelling (e.g. a logit regression for
predicting ij using predictors Xi). It also permits simple identiﬁability
constraints (e.g. 1 > 2 > . . . > J) when predictors are not used, and
ij ¼ jj, ij ¼ ð1  jÞj.
Another type of mixture strategy involves outlier detection models.
For example, in a conjugate Poisson model, with yi  Poð	iÞ, and
	i  Gað; K=iÞ. The parameter  is a precision parameter (as 
tends to inﬁnity the Poisson is approached). For outlier resistance one
may assume
	i  GaðK; K=iÞ þ ð1  Þ Gað; =iÞ
164
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

where  is small (e.g.  ¼ 0:05) and 0 < K < 1 (e.g. K ¼ 0:25). The ﬁrst
component is ‘precision deﬂated’. In a GLMM Poisson model with
logð	iÞ ¼ i þ ui
one might take
ui  Nð0; KÞ þ ð1  Þ Nð0; Þ
where K > 1 (e.g. K ¼ 5 or K ¼ 10).
Finally, as in Dey and Ravishanker (2000) and Kleinman and Ibrahim
(1998), one may adopt Dirichlet process mixing. Here, for yi  EFðiÞ,
gðiÞ ¼ 0 þ 1Xi þ "i
"i  DPðH0Þ
ð5:12Þ
where  is the concentration parameter and H0 is a base density. H0 is
often taken to be normal with variance  an extra parameter. The preset
concentration parameter, or the prior on it (if not preset), includes beliefs
regarding how close the true density of "i is reﬂected by H0. Low values
of  allow more non-normality (and fewer clusters) than larger values.
The number of potential clusters K under (5.12) may equal n but in
practice may be set at a value such as 10 or 20 ð nÞ to encompass
realistic amounts of possible error clustering. The same prior might be
applied to varying slopes
gðijGi ¼ jÞ ¼ 0 þ 1jXi
where Gi ¼ j is the cluster selected for observation i. In a model with
varying intercepts and slopes, namely
gðijGi ¼ jÞ ¼ 0j þ 1jXi
one might adopt different DPPs for the intercepts and slopes, allowing for
more clustering in one than the other.
Example 5.2
Sole egg hatchings
Lindsey (1975) presents binomial
data on the effects of salinity ðX1Þ and temperature ðX2Þ in an egg hatching
experiment for English sole. Speciﬁcally the observations are the numbers
of eggs hatching yi out of ni total eggs in i ¼ 1; . . . ; 72 tanks. He observed
that extra variation was substantial after allowing for these known inﬂu-
ences. The average deviance for a simple binomial model is over 12 000.
Here two types of mixture analysis are applied: the conjugate beta–
binomial model and a non-parametric mixture.
Under the conjugate mixture approach of (5.6)
yiji  Binðni; iÞ
i  Betaði; ð1  iÞÞ
DISCRETE MIXTURES
165

with the impact of the predictors modelled via
logitðiÞ ¼ Xi
with the prior for  assumed to be a Ga(1, 0.001). A two-chain run of
5000 iterations for this model shows early convergence, with the average
deviance reduced to around 71.9. With 70.3 effective parameters the DIC
is 142.2.  stands at around 2.9, implying a within-cluster correlation,
from (5.7), of 1=ð1 þ 2:9Þ ¼ 0:26. Of the two predictors, only tempera-
ture appears to have a coefﬁcient different from zero, with a 95% interval
(0.17, 0.36).
A non-parametric mixture involves a Dirichlet process with a G(0.01, 0.1)
prior on the Dirichlet concentration parameter , and an N(0, 1) baseline
density assumed for varying intercepts 0j in the model
yi  Binðni; iÞ
logitðiÞ ¼ 0Gi þ xi
An upper limit of 20 clusters for the cluster index Gi is assumed. Conver-
gence is obtained from around 1500 iterations (with centred covariates)
and the deviance averages 87. The average number of clusters is 15.4 and
the mean of  is 8.4. The effective parameter count is slightly smaller
(66) than for the beta–binomial model but the DIC higher at 153. The
interval for 2 is slightly less favourable to high values with a 95%
interval (0.18,0.29).
Example 5.3
Protozoa mortality
Data from Follman and Lambert
(1989) record deaths yi from ni exposed to poison dose xi for g ¼ 8 groups
of protozoa. Thus y ¼ f0; 8; 18; 18; 22; 37; 47; 50g, n ¼{55, 49, 60, 55,
53, 53, 51, 50} with dosages x ¼ f4:7; 4:8; 4:9; 5; 5:1; 5:2; 5:3; 5:4g.
Follman and Lambert try a logistic regression mixture with K ¼ 2 groups
as in (5.10), with varying intercepts but homogeneous effect of dose:
yi  Binðni; iÞ
Gi  Catð1; 2Þ
logitðiÞ ¼ 0;Gi þ 1ðxi  xÞ
Follman and Lambert (1989) obtain a deviance of 21.3 at the maximum
likelihood parameter estimate; see also Agresti (2002, p 546). The irregu-
larity making a robust mixture necessary is the ﬂat mortality rate at
medium doses; a simple binomial regression adequately models overdis-
persion as a predictive check will show.
166
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

Here a two-group regression with varying intercepts and slopes is used,
namely
logitðiÞ ¼ 0;Gi þ 1;Giðxi  xÞ
N(0,10 000) priors are assumed on 0j and 1j with an identiﬁability
constraint 12 > 11 on the slopes, and a Dirichlet D(5, 5) prior on  ¼
ð1; 2Þ. The posterior classiﬁcation rates from a two-chain run of
100 000 iterations are  ¼ ð0:58; 0:42Þ with 0 ¼ ð0:2; 5:2Þ, 1 ¼
ð6:5; 91Þ. Posterior probabilities PðGi ¼ 2Þ are above 0.5 only for the ﬁrst
and last observations. The average deviance is now 10.6, indicating an
improved model.
5.4
HURDLE AND ZERO-INFLATED MODELS
Hurdle and zero-inﬂated models are specialized instances of discrete
mixture models commonly used for count or binomial data with excess
zeros. In the hurdle model non-zero observations (counts of one, two or
more) occur from crossing a threshold or hurdle (Mullahy, 1986). The
probability of crossing this hurdle involves a binary sampling model,
while the sampling of non-zero counts involves a truncated Poisson or
binomial (sampling conﬁned to values of y above zero). Explanatory
variables Xi can be introduced in both parts of the model. In economic
applications, an interpretation in terms of a two-stage decision process
may apply, with the ﬁrst binary stage involving a selection mechanism.
Let f1 and f2 be probability densities appropriate to integer data. For
count observations yi, f1 might be Bernoulli and f2 Poisson or negative
binomial. Then the probabilities of the two stages are given by
Pðyi ¼ 0Þ ¼ f1ð0Þ
Prðyi ¼ jÞ ¼ f½1  f1ð0Þ=½1  f2½0gf2½ j
j > 0
¼ !f2½ j
where ! ¼ ½1  f1ð0Þ=½1  f2½0. The correction factor 1  f2½0 is need-
ed to account for the truncated sampling at stage 2 (i.e. ensure the model
probabilities sum to unity). Note that for count data f1 might also be the
Poisson or negative binomial density truncated at zero (Cameron and
Trivedi, 1998, p 124).
Suppose count observations are arranged so that cases i ¼ 1; . . . ; n1
have zero outcomes, while for i ¼ n1 þ 1; . . . ; n, all responses are
non-zero. Thus if f1 were Bernoulli with f1ð1Þ ¼ i, f1ð0Þ ¼ ð1  iÞ
HURDLE AND ZERO-INFLATED MODELS
167

and f2 Poisson with mean i, with f2½0 ¼ expðiÞ, the likelihood would
be deﬁned by
yi  BernðiÞ i ¼ 1;...;n1
Prðyi ¼ jÞ ¼ ½ð1  iÞ=ð1  expðiÞÞexpðiÞyi
i =yi!
i ¼ n1 þ 1;...;n
i and i may be functions of possibly overlapping covariates Wi and Xi.
Setting f1 ¼ f2 or equivalently ! ¼ 1 reduces to the standard model
(Cameron and Trivedi, 1998). The factor ! can be seen to vary by
obervation. In terms of this factor, the expectation and variance are
(Winkelmann, 2000)
EðyÞ ¼ !
X
1
j¼1
j f2ð jÞ
VðyÞ ¼
X
1
j¼1
j2 f2ð jÞ  !
X
1
j¼1
j f2ð jÞ
"
#2
which reduces to the standard variance-mean relation when ! ¼ 1. The
range 0 < ! < 1 yields overdispersion with excess zeros, while ! > 1
yields underdispersion (subject to the variance being deﬁned) with zeros
less frequent than under the standard Poisson. These properties are
deﬁned at the individual level in terms of means i, such that
VðyijXiÞ ¼ i þ 1  !i
!i
2
i
The larger the ratio of 1  !i to !i the more an observation is contributing
to excess dispersion.
An alternative zero inﬂated Poisson (ZIP) mechanism is proposed by
Lambert (1992) whereby zero observations may occur either by deﬁnition
(e.g. when a manufacturing process is under control) or by a chance
mechanism (when the manufacturing process is producing some defec-
tive items but sometimes yields zero defectives). Let Gi ¼ 1 or 2
according to which latent state or regime is operating. Then
Prðyi ¼ 0Þ ¼ PrðGi ¼ 1Þ þ Pðyi ¼ 0jGi ¼ 2ÞPrðGi ¼ 2Þ
Prðyi ¼ jÞ ¼ Pðyi ¼ jjGi ¼ 2ÞPrðGi ¼ 2Þ
j ¼ 1; 2; . . .
If the probability that Gi ¼ 1 is denoted i then the overall density is
Prðyi ¼ jÞ ¼ ið1  giÞ þ ð1  iÞPðyiÞ
where gi ¼ minðyi; 1Þ and PðyiÞ is a standard density for count data. A
logit model with covariates Wi might be used to model the i. Under a
168
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

Poisson model with mean i ¼ EðyijXiÞ
Pðyi ¼ 0Þ ¼ i þ ð1  iÞ expðiÞ
Pðyi ¼ jÞ ¼ ð1  iÞ expðiÞyi
i =yi!
j ¼ 1; 2; . . .
The variance is then
VðyijXiÞ ¼ ð1  iÞ½i þ i2
i  > ið1  iÞ ¼ EðyijXiÞ
and again the modelling of excess zeros implies overdispersion. The zero
inﬂated model can also be used with PðyÞ as negative binomial in case the
Poisson option does not produce predictions that account both for
overdispersion and excess zeros.
Example 5.4
Major derogatory reports
This example uses data
from Greene (2000) on yi, the number of derogatory credit reports, for
100 subjects in terms of age, dollar income (divided by 10 000), monthly
credit card expenditure (divided by 100) and home ownership vs. renting
(1 for owners). The covariates Wi used to explain the hurdle parameters
i and the ZIP parameters i are age, income and home ownership,
while age, income and expenditure are used in the second-stage truncated
Poisson model. Simple analysis of average expenditure and income by
counts of derogatory reports shows that average expenditure is highest for
zero reports but that average income peaks for y ¼ 2 reports. The second
stage of the hurdle model (applicable only to the 18 subjects with yi > 0)
may be achieved by truncated Poisson sampling,
yi  PoðiÞIð1; Þ
The ﬁt of the hurdle and ZIP models is compared by sampling new data.
The new data z are obtained at each iteration t from the relevant Poisson
density (deﬁned by GðtÞ
i
¼ 1 or 2) for the inﬂated model, and from the
second stage of the hurdle model for all subjects, even those with yi ¼ 0.
The Poisson sampling for z under the hurdle model allows zero counts.
The predictive criterion (2.10) is then used to assess ﬁt.
The coefﬁcients of the ZIP model show that higher income people are
less likely to be in the zero-risk group (those for whom Gi ¼ 1), while the
frequency of reports declines with average expenditure (compare Greene,
2000, p 892). As may be veriﬁed by estimating CPO statistics (see 2.15),
the ﬁt of the hurdle model is worsened by subjects 85 and 91 who, despite
large expenditures, have a derogatory report (Table 5.2). The ZIP model
is much less affected by these subjects, and under criterion (2.10) its ﬁt is
markedly better.
HURDLE AND ZERO-INFLATED MODELS
169

Example 5.5
Recreation trips
To illustrate the use of negative bino-
mial and NB hurdle regression, especially in a setting with excess zeros,
consider the recreation trips data of Cameron and Trivedi (1998). These data
relate to 659 respondents to a survey on boating trips to Lake Somerville,
Texas, during 1980. Of the 659, 50 respondents report ten or more trips
(with a maximum of 88) but 417 respondents report zero trips. Potential
models should reﬂect both overdispersion and the excess zeros.
Predictors include a subjective quality rating ðX1 ¼ SQÞ, a binary index
for involvement in water-skiing at the lake ðX2 ¼ SKIÞ, annual household
income in $1000 ðX3 ¼ INCÞ, and a binary index for season fee payment
ðX4 ¼ FEEÞ. The other predictors are dollar expenditures (TEXP) by
lakes: Conroe ðX5 ¼ TEXP1Þ, Somerville ðX6 ¼ TEXP2Þ and Houston
ðX7 ¼ TEXP3Þ. Cameron and Trivedi consider several mixture models,
including a hurdle version of the negative binomial.
Here a binary model with the above seven predictors is used to model
the ﬁrst stage of the NB hurdle, i.e. the distinction between zero-trip res-
pondents ðdi ¼ 0Þ and those with at least one trip ðdi ¼ 1Þ. Thus
di  BernðiÞ
logitðiÞ ¼ Xi
The second stage is negative binomial with these predictors and with
truncated sampling (conﬁned to values 1 and above). Thus
yi  NBði; ÞIð1; Þ
logðiÞ ¼ Xi
Table 5.2
Derogatory reports
Hurdle selection model
ZIP zero group
Mean
2.5%
97.5%
Mean
2.5%
97.5%
Intercept
3.27
0.92
5.59
5.56
1.44
10.24
Age
0.043
0.110
0.027
0.040
0.128
0.048
Income
0.16
0.49
0.18
1.22
2.56
0.30
Own/rent
0.91
0.36
2.28
0.47
1.28
2.30
Frequency model
Standard Poisson group
Intercept
1.31
0.09
2.73
1.33
0.39
2.70
Age
0.01
0.05
0.03
0.01
0.05
0.04
Income
0.06
0.30
0.16
0.12
0.44
0.10
Expenditure
0.31
0.68
0.01
0.60
1.00
0.29
170
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

A Ga(1, 0.1) prior is set on the  parameter in (5.1). There are only 13
subjects with FEE ¼ 1 and none of them have di ¼ 0. The parameter 4
on FEE is therefore poorly identiﬁed by the data. Cameron and Trivedi
give a maximum likelihood estimate for 4 of 9.4 ðs:e: ¼ 0:6Þ and a
suitably downweighted (e.g. precision reduced by 100) version of this
estimate might be used to provide an informative prior. Hence a prior
4  ð9:4; 36Þ is assumed.
A two-chain run of 100 000 iterations converges after 40 000 iterations.
The results (based on iterations 50 000–100 000) are similar to those
of Cameron and Trivedi (1998, p 214). Among differences are the less
precise estimate of 4, i.e. 8.2 with a 95% interval (2, 15) but a signiﬁcant
parameter 4.  is estimated at 1.64 with a 95% interval (1.31, 2.03).
5.5
MODELLING THE LINK FUNCTION
Under the GLM, a known link function g connects the mean of the
density to a systematic linear regression term. Thus for count data,
yi  PoðiÞ and gðiÞ ¼ Xi where logðiÞ is the canonical link. Binary
regression models assume that yi is related to predictors Xi via
Prðyi ¼ 1jxiÞ ¼ FðXiÞ
with F being the inverse link function. For binary regression the range of
F is within [0,1] and F is therefore typically a known cumulative distri-
bution function. F as the normal cdf is equivalent to the probit link, and
F as the cdf of the standard logistic function corresponds to a logit link,
which is the canonical GLM link. Sometimes standard choices of link
lead to poor ﬁt, and one may instead allow for a choice of the link func-
tion based on the data. Selection of the link usually leads to a form
of model averaging and may be combined with predictor selection
(Ntzoufras et al., 2003).
For example, Basu and Mukhopadhyay (2000) propose normal scale
mixtures in the probit regression model
Prðyi ¼ 1jXiÞ ¼
ð
ðXi=ÞdhðÞ
ð5:13Þ
where h is a discrete mixture such as that formed by a Dirichlet process;
see also Basu and Chib (2003). Newton et al., (1996) also consider non-
parametric estimation of the binary link function by assuming a Dirichlet
process mixture on the mean, with a logistic or normal distribution
function as baseline. Mallick and Gelfand (1994) propose mixture models
MODELLING THE LINK FUNCTION
171

for link functions g, in particular discrete mixtures of beta densities. A
baseline link such as g0ð
iÞ ¼ g0ðXiÞ ¼ expðXiÞ in a Poisson regres-
sion provides the basis for mixture modelling of the cumulative density
function deﬁned by Jð
Þ ¼ agð
Þ=½agð
Þ þ b, where Yi  Poðgð
iÞÞ.
Another approach takes the link as belonging to a parametric class
of link transformations. For binary and binomial data, one- and two-
parameter link families have been suggested by Aranda-Ordaz (1981),
Stukel (1988) and Czado (1994).
5.5.1
Discrete (DPP mixture)
The model in (5.13) may be operationalized by using the Albert and Chib
(1993) data augmentation approach. Letting i denote precisions for sub-
jects i, the scale mixture generalization of the probit is
Wi  NðXi; 1=iÞIðLi; UiÞ
where the i are drawn from a density conﬁned to positive values and with
mean 1 and fLi; Uig are deﬁned by the observed binary yi. A conjugate
density for i is provided by a gamma density, leading to a t density with
	 degrees of freedom (see Chapter 3). Thus
i  Gammað	=2; 	=2Þ
ð5:14Þ
Instead of assuming n distinct values of i (i.e. one for each observation),
Basu and Mukhopadhyay (2000) propose a DPP whereby i values fall
into a relatively small number of clusters (perhaps K ¼ 5 to K ¼ 20
would be a typical number). The baseline density of the DPP would be a
gamma as above, with the degrees of freedom 	 taken as either known or
an extra parameter, and the concentration parameter  of the DPP may
also be taken as known or left as a free parameter.
In many situations, including Example 5.6 below, the data are pre-
sented as binomial but result from repeated binary observations at
covariate level Xi, so the actual observations are repetitions within
clusters, of the form yij, i ¼ 1; . . . ; g, j ¼ 1, ni where ni is the total cluster
size and ri ¼ P yij is the number of ‘successes’ when the covariate has
value Xi. Thus at the lowest dose in Table 5.3 below there are six cases
where yij ¼ 1 and 53 cases where yij ¼ 0. The augmented data sampling
would be at this disaggregated data level but the regression model would
be at the cluster level. So the probit model would involve
Wij  NðXi; 1ÞIðLij; UijÞ
with truncation below or above by zero according as yij were 1 or 0.
172
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

5.5.2
Parametric link transformations
For models where the link belongs to a parametric class of link trans-
formations, let  be the shape parameter of the link density and 
 ¼ X.
Then possible families of densities include
hð
;  Þ ¼ ð1 þ 
 Þ1= 
ð5:15Þ
hð
;  Þ ¼ logð1 þ 
 Þ= 
ð5:16Þ
hð
;  Þ ¼ ½expð
 Þ  1= 
ð5:17Þ
and
hð
;  Þ ¼ ½ð
 þ 1Þ  1= 
ð5:18Þ
Czado (1994) uses the last of these in single parameter link functions
which are appropriate to left and right tails of the link F. In particular,
taking F½hð
;  Þ ¼ ½hð
;  Þ where  is the standard normal cdf, the
option
hð
;  Þ ¼

if

 	 0
½ð
 þ 1Þ  1= 
otherwise

is used the modify the left tail and
hð
;  Þ ¼
½ð
 þ 1Þ  1= 
if

 	 0

otherwise

allows for modiﬁcation of the right tail. Then under either option  ¼ 1
corresponds to the usual probit link. Czado and Raftery (2001) consider
the choice between tail-modiﬁed models using the Bayes factor methods
of Raftery (1996).
As for the Basu–Mukhopadhyay model, augmented data sampling
may be used to apply these modiﬁed link models. With 
i ¼ Xi, a left
modiﬁed tail approach to a probit link would mean sampling
Wi  Nð
i; 1Þ
if 
i 	 0
ð5:19Þ
Wi  Nð½1  
iÞ  1= ; 1Þ
otherwise
ð5:20Þ
with sampling additionally constrained according to whether yi were 1
or 0. For example, if yi ¼ 1 then sampling would be truncated below at
zero and switch between (5.19) and (5.20) according to whether 
i were
positive or negative. It is possible to combine the tail modiﬁcations
(5.15)–(5.18) with scale mixing as in (5.14); see Example 5.7.
MODELLING THE LINK FUNCTION
173

5.5.3
Beta mixture on cumulative densities
A parametric approach is also proposed by Mallick and Gelfand (1994)
and Gelfand and Mallick (1995). The basis of their approach is that a
discrete mixture of beta densities can closely approximate any continuous
density on (0, 1). In particular the modelling of the cumulative density
Jð
Þ ¼ agð
Þ=½agð
Þ þ b
or equivalently the inverse link g with
gð
Þ ¼ bJð
Þ=½a  aJð
Þ
involves a discrete mixture (with K components, with K usually in small
integers) over the cumulative densities associated with beta densities
Betaðc; dÞ. The cumulative densities are
Bð
; c; dÞ ¼ ðc þ dÞ
ðcÞðdÞ
ðJ0ð
Þ
0
uc1ð1  uÞd1du
where J0ð
Þ ¼ ag0ð
Þ=½ag0ð
Þ þ b is the cumulative density function
associated with the baseline inverse link g0. Thus
Jð
Þ ¼
X
k
kBð
; ck; dkÞ
where k are mixture proportions. Mallick and Gelfand (1994) argue that
taking k unknown and fck; dkg known is more tractable than taking
fck; dkg as parameters. Gelfand and Mallick (1995) propose generating ck
and dk by the scheme
ck ¼ k
dk ¼ ðK þ 1  kÞ
in order to provide a set of densities that fully cover (0,1), with  govern-
ing how peaked the beta densities are. Priors on parameters fa; b; Þ might
be considered but defaults such as a ¼ b ¼  ¼ 1 are often sufﬁcient.
Example 5.6
Beetle mortality
Data from Bliss (1935) record the
number of beetles dead after ﬁve hours’ exposure to carbon disulphide
(transformed to log10 dose in Table 5.3).
The standard probit gives a coefﬁcient on the standardized dose vari-
able of 1.34 and mean deviance of 38.3. The predictions of the death rates
are most discrepant at the four lowest doses, with underpredictions at the
two lowest doses and overpredictions at the following two. Various ana-
lyses of the data have suggested alternative links (e.g. complementary
log–log) or a generalized logistic model (Stukel, 1988).
174
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

Here a left tail modiﬁcation was found to give a signiﬁcant gain in ﬁt
(cf. Czado, 1994) with mean deviance reduced to 31.6 (with effective
parameters pe ¼ 2:5). The predictions of the ﬁrst four death rates, i.e.
0.12, 0.19, 0.31 and 0.54, are much improved. The posterior mean of
the link parameter  is close to zero (Figure 5.1) with a 95% interval
(0.67,0.62) from a two-chain run of 10 000 iterations.
The impression from Table 5.3 is that the death rate becomes much
higher for doses over 60, implying a non-constant coefﬁcient on dose. To
assess whether this option provides an alternative way of improving ﬁt
a discrete mixture model is applied for the dose coefﬁcient. Speciﬁcally a
Table 5.3
Flour beetle deaths
Dose
Log10dose
Deaths
Exposed
Death rate (%)
49.1
1.6907
6
59
10.2
53.0
1.7242
13
60
21.7
56.9
1.7552
18
62
29.0
60.8
1.7842
28
56
50.0
64.8
1.8113
52
63
82.5
68.7
1.8369
53
59
89.8
72.6
1.861
61
62
98.4
76.5
1.8839
60
60
100.0
0
1
1.2
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.2
0.4
0.6
0.8
0.3
0.4
0.5
Parameter value
Density
Figure 5.1
Kernel plot, link parameter
MODELLING THE LINK FUNCTION
175

DPP is used with concentration parameter of one and up to eight possible
clusters on the dose coefﬁcient. The average coefﬁcient at each dose level
is monitored and the lowest dose coefﬁcients (around 1.27) are found at
doses 1.691 and 1.724, whereas the highest is 1.44 at dose 1.884. This
model does improve the average deviance (to around 36.8) but not as much
as the left tail modiﬁcation. Comparison with the deviance at the mean
of the parameters shows there are around 3.7 effective parameters.
A quadratic in dose is another option that has been mentioned in the
literature for these data.
Finally, a data augmentation approach is adopted with scale mixing as
in Basu and Mukhopadhyay (2000), and left tail modiﬁcation, as in
Czado (1994). A logit link is used as it is more robust to extreme linear
predictor values. A Dirichlet concentration parameter  of one is assumed
and 	 in (5.14) set at ten. Up to 12 clusters are assumed in line with there
being two possible responses at six doses. The augmented data have
the form Wij where i ¼ 1,6 denotes the dose levels and j ¼ 1; . . . ; ni
denote repetitions at each dose. A two-chain run shows convergence
from around 5000 iterations and an average deviance 35.0 with six
effective parameters. The highest residuals are for those dying at the
lowest dose and for the survivors at 1.837 and 1.861. Evidence for
variation in scales is not pronounced with the lowest precision i being
0.88 for the lone survivor at dose 1.861. Note that the marginal likelihood
and Bayes factors for this type of model can be obtained as in Basu and
Chib (2003).
Example 5.7
Unknown link for simulated Poisson data
To illustrate
the beta mixture modelling of the cumulative density Jð
Þ associated with
the inverse link gð
Þ, consider 20 Poisson observations generated from a
model with 
i ¼ 0 þ 1xi ¼ 2 þ 3xi where the xi are standard normal
variates and gð
Þ ¼ expð
Þ. It is assumed that a ¼ b ¼ 1, but a prior
  Gð1; 1Þ is assumed in the scheme ck ¼ k, dk ¼ ðK þ 1  kÞ where
K ¼ 4. A simple Poisson regression with these simulated data shows
posterior standard deviations on 0 and 1 of 0.66 and 0.5.
The precisions of the priors on these coefﬁcients in the beta mixture
link model then downweight those from the Poisson regression by ten.
A two-chain run of 40 000 iterations for this link mixture model
converges at around 22 500 iterations and the second half of the run
shows  ¼ 1:27 and f0; 1g ¼ f2:1; 3:7g so that the covariate effect is
ampliﬁed. Figure 5.2 shows the relation between the estimated gð
Þ ¼
Jð
Þ=½1  Jð
Þ and the baseline g0ð
Þ ¼ expð
Þ. The EPD for this model
obtained by sampling ‘new data’ from the model (see 2.11) in fact
176
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

improves on that obtained with a simple Poisson regression, i.e. 20.0 vs.
23.5, with closer predictions of the zero observed counts.
5.6
MULTIVARIATE OUTCOMES
For K multivariate outcomes of binary, proportion or count data, similar
themes to those above recur. These include direct modelling of the out-
come as against modelling of the latent continuous scale producing the
outcome, the choice between different links, and the possible necessity to
account for overdispersion on one or more of the outcomes. There are
also choices over how to use random effects to model the correlations
between the outcomes.
Consider the case of K binary outcomes, Yi ¼ fYi1; Yi2; . . . ; YiKg.
Among possible frameworks for such data are:
1. K separate Bernoulli likelihoods (i.e. direct modelling of the out-
comes) with correlations between outcomes modelled in the link
function, for instance by additive multivariate normal errors "ij in
the logit or other link. The correlations between responses are
obtained
from
the
estimated
covariance
matrix

of
"i ¼
ð"i1; "i2; . . . ; "iKÞ.
0.3
0.35
0.4
0.45
0.5
0.55
0.6
0.65
0.7
0.75
0.8
−9
−7
−5
−3
−1
1                   3
η
Ratio
Figure 5.2
Ratio of estimated link to baseline link
MULTIVARIATE OUTCOMES
177

2. A multivariate probit model which may be estimated directly (by
multivariate integration) or by augmenting the data with K underlying
latent continuous values fWi1; Wi2 ; . . . ; WiKg (Chib and Greenberg,
1998). The correlations between responses may be modelled by
assuming a multivariate normal error of dimension K, or scale mix-
tures of multivariate normal errors (e.g. leading to multivariate Stu-
dent t errors). A multivariate logit regression may also be achieved
with suitable mixing strategies (Chen and Dey, 2003; O’Brien and
Dunson, 2004).
3. Either separate Bernoulli likelihoods assumed for each outcome as
in option 1, or separate latent scale sampling of each outcome as in
option 2, but with correlations between outcomes modelled by Q < K
factors.
Under option 1 random effects over subjects or subjects–outcomes may
be modelled parametrically (e.g. MVN for "i), though the parameters of
the covariance matrix may be weakly identiﬁed in small samples. A
possible alternative is a Bernoulli–beta mixture with beta frailties i for
subjects to model the correlation between outcomes. Thus, with a logit
link
yij  BernðijÞ
ij ¼ fexpðjxijÞ=½1 þ expðjxijÞgi
i  Betað; 2Þ
Under the multivariate version of the probit model (option 2) the known
conditional variance of one in the univariate probit, as in (4.2), is replaced
by a correlation matrix R ¼ ½rjk for the density YjX with known diagonal
elements but correlations as free parameters. There will also be outcome-
speciﬁc regression parameter vectors k of dimension p, assuming that a
common regression vector xi ¼ ð1; xi2; xi3; . . . ; xipÞ is used to predict all
outcomes. The probability of a particular pattern yi ¼ fyi1; yi2; . . . ; yiKg
is, with  ¼ f1; . . . ; K; Rg,
ProbðYi ¼ yijÞ ¼
ð
Di1
ð
Di2
. . .
ð
DiK
Kðuj0; RÞdu
with the regions of integration Dik deﬁned according to whether yik ¼ 1
or yik ¼ 0. Thus Dik is between 1 and xik when yik ¼ 0, but between
xik and 1 when yik ¼ 1.
As for the univariate probit, a tractable formulation of the multivariate
probit involves augmenting the data with the latent normal variables
178
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

Wi ¼ fWi1; Wi2; . . . ; WiKg. Then Wi is truncated MVN with mean i ¼
fi1; i2; . . . ; iKg where ik ¼ xik and dispersion (correlation) matrix
R. Sampling of the constituent Wik of Wi is conﬁned to values above zero
when yik ¼ 1 and to values below zero when yik ¼ 0. One may generalize
the multivariate probit models to multivariate t (MVT) or other models
by scale mixing, which amounts to dividing the correlation matrix R by
a weighting factor i
Wi  TNKði; R=iÞ
i  Gað	=2; 	=2Þ
ð5:21Þ
5.6.1
The factor analysis approach
To continue the multivariate binary example, the factor analysis perspec-
tive (option 3), accounting for both the interdependence among the yik
and the different regression effects k on each outcome, might involve
either direct Bernoulli likelihoods or truncated univariate normal sampl-
ing. Under this option Q < K factors Fi1; Fi2; . . . ; FiQ are introduced to
account for the correlations between the observations. As noted by Cox
and Wermuth (2002), choosing latent scale sampling instead of the direct
Bernoulli likelihood involves two levels of latent variables. Thus for the
kth outcome for subject i
Wik  Nðik; 1ÞIðLik; UikÞ
ð5:22Þ
ik ¼ xik þ k1Fi1 þ k2Fi2 þ    þ kQFiQ
ð5:23Þ
where for yik ¼ 0; Uik speciﬁes an upper sampling limit of zero, and for
yik ¼ 1, Lik speciﬁes a lower sampling limit of zero. However, conditional
on the factor scores Fiq, the observations fyikg are usually taken to be
independent. This is the conditional independence assumption, under
which the Fiq account for the correlations between the yik.
Regression and factor loading parameters for the kth variable may be
standardized (Bock and Gibbons, 1996) by dividing by
dk ¼
1 þ
X
Q
m¼1
2
km
 
!0:5
The correlations between the latent scales on different outcomes Wj and
Wk (conditional on x) are then obtained under the factor model as
jk ¼
X
Q
q¼1
jqkq
MULTIVARIATE OUTCOMES
179

where the  are standardized. Note that a factor structure might also
be used with direct sampling of binary items (Bartholomew and Knott,
1999), as in
yik  BernðikÞ
ð5:24Þ
logitðikÞ ¼ xik þ k1Fi1 þ k2Fi2 þ    þ kQFiQ
ð5:25Þ
For multivariate binary responses, identiﬁability requires the factors Fiq
in (5.23) or (5.25) to have mean 0 and variance 1 and to be uncorrelated.
Additional restrictions are also needed on the K  M matrix  of factor
loadings with multiple binary outcomes. These either are equality cons-
traints or involve setting loadings to ﬁxed values; thus for q > k one
might set kq ¼ 1 or kq ¼ 0 (Bartholomew, 1987, chapter 6; Bock and
Gibbons, 1996). So for Q ¼ 2 one might set 12 ¼ 1 or 0. Different ﬁxed
values might be tried (e.g. 12 ¼ 1 instead of 12 ¼ 0) to ﬁnd which is
better supported by the data. If all observed items are anticipated to be
positive measures of an underlying construct, as when K items are all
binary measures of mathematical aptitude in the case Q ¼ 2 (and yik ¼ 1
for greater aptitude), then the setting of a loading such as 12 to one acts
to prevent label switching on the remaining loadings, namely f22;
32; . . . ; K2g.
5.6.2
Specific modelling of marginal and odds ratios
Multivariate binary data may also be analysed in terms of the marginal
outcomes Prðyij ¼ 1Þ, joint pairwise outcomes Prðyij ¼ 1; yik ¼ 1Þ, or
conditional outcomes Prðyij ¼ 1jyik ¼ 1Þ. For larger K this means select-
ing certain aspects of the total likelihood (i.e. the joint density of
y1; . . . ; yK) for consideration. As discussed by Liang et al., (1992), the
joint distribution of a K vector of binary responses y ¼ ðy1; y2; . . . ; yKÞ
can be represented by a saturated log-linear model
log½PðyÞ ¼ u0 þ
X
K
k¼1
ukyk þ
X
K
j<k
ujkyjyk þ    þ u12 : : : Ky1y2 . . . yK
with 2K  1 parameters. These parameters express conditional prob-
abilities, for instance:
uk ¼ logit½Prðyk ¼ 1jyj ¼ 0; j 6¼ kÞ
and
ujk ¼ log½ORðyj; ykjym ¼ 0; m 6¼ j; m 6¼ kÞ
180
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

where the odds ratio (OR) is deﬁned by
ORðyj; ykÞ ¼ ½Prðyj ¼ 1; yk ¼ 1ÞPrðyj ¼ 0; yk ¼ 0Þ=
½Prðyj ¼ 1; yk ¼ 0ÞPrðyj ¼ 0; yk ¼ 1Þ
Usually, more parsimonious models are applied which seek to represent
substantively more important questions, as represented by the marginal
outcomes and pairwise odds ratios, or the impact that positives on yk
ðk 6¼ jÞ have on the occurrence of yj ¼ 1.
For example, if the yik are all positive disease indicators (y ¼ 1 for
disease present), then the conditional probability that yik ¼ 1 may
be related to the number of positive responses on the other outcomes
(Connolly and Liang, 1988). Let Yi½k denote the indicators for subject i
excluding yik, namely fyi1; yi2; . . . ; yi;k1; yi;kþ1; . . . ; yiKg. Then one form
for this type of conditional logistic model speciﬁes
yikjYi½k  BernðikÞ
logitðikÞ ¼ log
1 þ Sk2
1  1 þ ðK  1  SkÞ2


þ kxi
where Sk is the number of indicators in Yi½k which have value 1. The
alternating logistic model of Carey et al., (1993) is somewhat similar with
model means for marginal and joint outcomes
ij ¼ EðyijÞ
	ijk ¼ Eðyij; yikÞ
contributing to a model for the conditional outcome, namely
Prðyij ¼ 1jyik ¼ 1Þ ¼ g1½yik þ logðRijkÞ
where
Rijk ¼ ðij  	ijkÞ=ð1  ij  ik þ 	ijkÞ
McCullagh and Nelder (1989) propose a multivariate logit model in
which marginal and joint associations (pairwise and higher) are modelled
together; see also Glonek and McCullagh (1995) and Liang et al. (1992).
Pairwise associations between binary outcomes are generally stated in
odds ratio form but can be modelled via a multinomial likelihood
(Chapter 6). For example, K ¼ 2 binary responses yi1 and yi2 deﬁne a
multinomial of dimension 4 formed by combining the levels of y1 and y2.
Let 11; 10; 01; 00 be combined response categories (1 ¼ Yes, 0 ¼ No)
with P
i
P
j ij ¼ 1. Independence between the responses may be
assessed via the odds ratio
ð1100Þ=ð1001Þ
MULTIVARIATE OUTCOMES
181

with null value 1, or log odds ratio
log½ð1100Þ=ð1001Þ
with null value 0. Consider the data in aggregate form with n11 being the
number of subjects with y1 ¼ 1, y2 ¼ 1, n10 being the total with
y1 ¼ 1; y2 ¼ 0, and so on. Suppose additionally there is a predictor
with M levels (e.g. grouped drug exposure) with value zm for subtable
njkm with probabilities 11m; 10m; 01m; 00m deﬁning the joint outcomes
in that subtable. Then the multivariate logit model of McCullagh and
Nelder for K ¼ 2 involves marginal logits to predict Pðy1 ¼ 1Þ and
Prðy2 ¼ 1Þ, while to model the odds ratio, a multinomial logit regression
can estimate how joint response changes with the predictor, via
ijm ¼ ijm
 X
j
X
k
jkm
where
11m ¼ expðxm þ xm þ xmÞ
10m ¼ expðxmÞ
01m ¼ expðxmÞ
00m ¼ 1
ð5:26Þ
The predictor vector has the form xm ¼ ð1; zmÞ. Independence within each
subtable of the predictor using odds ratios deﬁned by relations among the
ijm (and ijm) is given by
log½ð11m00mÞ=ð10m01mÞ ¼ log½ð11m00mÞ=ð10m01mÞ ¼ xm
This analysis can also be performed with disaggregated data using the
marginal responses yi1; yi2 and the multinomial variable Di formed by
the joint values of ðyi1; yi2Þ, where Di ¼ 1 if y1 ¼ 1; y2 ¼ 1, Di ¼ 2 if
y1 ¼ 1; y2 ¼ 0, etc.
5.6.3
Multivariate Poisson data
For multivariate count data, option 1 above no longer poses identiﬁability
issues (see Chib and Winkelmann, 2001), and option 3 applies with a
direct likelihood approach (e.g. Poisson or NB). However, the augmented
data approach in option 2 is not applicable. Thus under option 1
yij  PoðijÞ
logðijÞ ¼ jxij þ "ij
182
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

where the multivariate error "i ¼ f"i1; "i2; . . . ; "iKg might follow an
MVN, or a mixture of MVNs, such as
"i  NK

0; P
1

þ ð1  ÞNK

0; P
2

where P
2 ¼  P
1 with scalars  and  possibly both taking preset
values. Other options are a scale mixture of MVNs
"i  NK

0; P =i

with i  Gað	=2; 	=2Þ.
The negative multinomial model (Guo, 1996) may also be relevant to
account for both correlated outcomes and overdispersion. Thus
yij  PoðijÞ
ij ¼ expðjxijÞi
i  Gað1; 2Þ
where 1 ¼ 2 for identiﬁability.
A factor model may also be used to model the correlations between
errors. For both binary and count data an alternative factor model approach
is to the regression component (systematic part) of the model, assuming
that a common set of predictors xi is used across the responses. This is
relevant if the observed responses are indicators of an underlying cons-
truct. Thus with a single factor
yij  PoðijÞ
logðijÞ ¼ 0 þ 1jFi
Fi ¼ xi þ ui
Example 5.10
considers multivariate count data with K ¼ 2 when a
single unobservable construct plausibly underlies both outcomes. If
Q ¼ 2 (with K > 2) then
logðijÞ ¼ 0 þ 1jFi1 þ 2jFi2
Fi1 ¼ 1xi þ ui1
Fi2 ¼ 2xi þ ui2
The number of free factor loadings depends on the assumptions about the
conditional variances Vj ¼ VarðuijÞ of the factor scores Fij, j ¼ 1; . . . ; Q.
If Q ¼ 1, for example, then taking V1 ¼ 1 means 11; . . . ; 1K may be
estimated whereas taking V1 unknown requires one of the 1j to be ﬁxed.
Muthen (1979) proposes this model for binary data when there are
multiple indicators of one or possibly more underlying constructs. His
MULTIVARIATE OUTCOMES
183

analysis focuses on a survey among married women of attitudes to sex
typing. The survey questions yield binary indicators Y1; . . . ; YK of an
underlying construct F ‘the propensity to reject sex typing’ and predictors
xi include length of education and length of time married.
Example 5.8
Pneumoconiosis symptoms
Consider the data analysed
by Bock and Gibbons (1996) on ﬁve binary pneumoconiosis symptom
variables, namely cough (1 ¼ Yes, 0 ¼ No), phlegm, breathlessness,
wheeze and weather-related symptoms. The single covariate is xi2 ¼
age with xi1 ¼ 1. Age takes the values 22.5, 27.5, etc., up to 62.5. Here a
10% sample is obtained from the full set of 29 720 observations.
An initial analysis considers just the ﬁrst two outcomes and takes a
single factor ðQ ¼ 1Þ. The constraint 11  Nð1; 1ÞIð0; Þ is adopted,
i.e. the positive ﬁrst loading of cough on the single factor amounts to
constraining this factor to be a positive morbidity measure. The prior on
21 is taken as N(0, 1) though an N(1, 1) prior as in Johnson and Albert
(1999) is a possibility in line with expectations of a unipolar morbidity
factor. A two-chain run of this model shows early convergence (at around
500 iterations) and gives a steeper age gradient for cough than phlegm,
namely 0.036 ðs:d: ¼ 0:0022Þ as against 0.031 (0.0021). The correlation
between W1 and W2 is obtained as 0.85 – based on posterior means of
standardized loading 11 and 21, which are both 0.92. The DIC is 3955
with 1160 effective parameters.
The bivariate probit is estimated under the assumption of a Uð1; 1Þ
prior for r12 and N(0, 100) priors for kg, where k ¼ 1, 2 for the two
outcomes and g ¼ 1 for the constant and g ¼ 2 for age. With convergence
at around 800 iterations in a 2000-iteration run, the age gradients are
found to be similar to the factor model, though more precisely estimated,
i.e. 0.035 (0.0020) for cough and 0.030 (0.0020) for phlegm. The
correlation r12 is estimated at 0.90. However, the ﬁt measured by DIC
deteriorates to 6253. The DIC is obtained by monitoring the mean of the
multivariate binary deviance and comparing it with the deviance obtained
using posterior averages of ik ¼ k1 þ k2xi2.
Example 5.9
Use of health care
As an illustration of options for
modelling correlations in a bivariate count outcome (Y1, Y2), consider
joint modelling of discrete outcomes relating to demand for medical
care by the elderly in the USA (Munkin and Trivedi, 1999; Chib and
Winkelmann, 2001). The two variables considered, emergency room visits
and number of hospitalizations (EMR and HOSP) for n ¼ 4406 subjects,
are obtained from the National Medical Expenditure Surveys in 1987 and
184
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

1988. These are related to categorical predictors (health status, region,
type of medical insurance, ethnicity, sex, employed or not, difﬁculties
with activities in daily living), a count predictor for illness conditions,
and to three continuous predictors, age (divided by 10), years of educa-
tion, and relative family income.
The predictors are the same for both outcomes, so xij ¼ xi. Both variables
have relatively low means y, namely 0.26 for EMR and 0.30 for HOSP,
and high proportions of zero counts. So one aspect of model checking is
whether this high zero proportion is replicated by the model predictions.
There is also some overdispersion with Vðy1Þ ¼ 0:7 and Vðy2Þ ¼ 0:75.
The ﬁrst model (model A) is the bivariate Poisson lognormal mixture,
with unrestricted dispersion structure, namely
yij  PoðijÞ;
i ¼ 1; . . . ; N; j ¼ 1; K
ð5:27Þ
where K ¼ 2,
logðijÞ ¼ jxi þ "ij
ð5:28Þ
and the "ij are bivariate normal. If the "ij are highly correlated, a one-
factor model might be considered as an alternative. Under this
logðijÞ ¼ jxi þ 1jFi
ð5:29Þ
where Fi  Nð0; FÞ. The variance parameter F may be preset (when
both 1j are unknown) or estimated (if one of the 1j is preset, typically to
one). Since both outcomes may be taken as proxies for an underlying
morbidity construct, a further possible model is
yij  PoðijÞ
logðijÞ ¼ 0 þ 1jFi
Fi ¼ xi þ ui
ð5:30Þ
The applicability of this model would be greater when 1 and 2 in (5.28)
are similar.
A Poisson lognormal model (model A) as in (5.27)–(5.28) has an
average deviance D of 2256 for EMR and 2320 for HOSP with deviances
DðijÞ at models means of 1643 and 1648 (from the second half of a two-
chain run of 5000 iterations). This gives a DIC of 5859 with pe ¼ 1284.
Predictor effects are given in Table 5.4 with a correlation between the
errors "i1 and "i2 of over 0.9. There is some doubt on how well this model
accounts for the excess zeros: in fact the model replicates seem to have
more zeros than are present in the data, since a predictive check
comparing the zero proportion among replicates zij with that among the
yij averages 0.92.
MULTIVARIATE OUTCOMES
185

Table 5.4
Health demand: bivariate Poisson
Mean
S.d.
2.5%
Median
97.5%
Vð"1Þ
2.23
0.55
1.80
2.02
4.11
Covð"1; "2Þ
2.07
0.44
1.71
1.89
3.38
Vð"2Þ
2.37
0.77
1.79
2.02
4.56
Corrð"1; "2Þ
0.92
0.05
0.77
0.93
0.96
EMR visits
Constant
4.050
0.465
4.735
4.014
3.042
Excellent health
0.676
0.219
1.138
0.668
0.282
Poor health
0.626
0.158
0.377
0.610
0.995
Number chronic conditions
0.243
0.030
0.187
0.240
0.307
ADL difﬁculties
0.281
0.180
0.104
0.307
0.572
N East
0.009
0.118
0.253
0.004
0.205
Mid West
0.095
0.128
0.335
0.104
0.172
West
0.149
0.124
0.109
0.151
0.414
Age
0.163
0.070
0.006
0.179
0.244
Black
0.156
0.123
0.085
0.151
0.413
Male
0.090
0.104
0.112
0.092
0.297
Married
0.157
0.135
0.458
0.135
0.057
Years education
0.022
0.016
0.056
0.022
0.007
Family income
0.001
0.016
0.033
0.001
0.030
Employed
0.220
0.132
0.044
0.220
0.473
Private insurance
0.058
0.117
0.155
0.054
0.280
MedicAid
0.199
0.181
0.119
0.197
0.593
Hospitalizations
Constant
5.436
0.355
6.413
5.358
4.916
Excellent health
0.750
0.229
1.222
0.733
0.351
Poor health
0.730
0.249
0.407
0.669
1.419
Number chronic conditions
0.271
0.043
0.172
0.275
0.358
ADL difﬁculties
0.146
0.263
0.533
0.229
0.482
N East
0.005
0.119
0.237
0.003
0.223
Mid West
0.004
0.143
0.297
0.008
0.243
West
0.130
0.127
0.112
0.127
0.402
Age
0.300
0.034
0.239
0.295
0.374
Black
0.085
0.134
0.155
0.072
0.390
Male
0.164
0.094
0.022
0.171
0.332
Married
0.040
0.131
0.349
0.013
0.159
Years education
0.003
0.015
0.033
0.002
0.025
Family income
0.002
0.017
0.033
0.003
0.032
Employed
0.104
0.138
0.186
0.102
0.387
Private insurance
0.198
0.128
0.056
0.200
0.437
MedicAid
0.235
0.186
0.161
0.236
0.610
186
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

It follows from the high correlation that a single factor model for the
errors as in (5.29) is a viable alternative. The variance F is preset at one
so both loadings j are free parameters. These are assigned N(1, 1) priors
with 1 additionally constrained to be positive, with the goal of avoiding
label switching. The label switching problem occurs because Fi may be
either a morbidity effect (with both  positive) or a good health effect
(with both  negative). In fact, the posterior means of the j are both
around 1.28. Although D worsens to 2277 for EMR and 2349 for HOSP,
the gap between D and DðÞ is reduced because the model has reduced
complexity (in fact pe ¼ 1180 with a DIC of 5806). The predictive check
Pc on zero counts is still on the boundary of acceptability, i.e. Pc ¼ 0:89.
Estimates of the model (5.27)–(5.28) show a similarity in the proﬁle of
effects jv, v ¼ 1,17 (see Table 5.4). From this it follows that a one-factor
regression model as in (5.30) might be considered as a further alternative.
The loadings have priors as in the factor error model so one would expect
Fi to be a morbidity index, i.e. an index of patient propensity to make
more EMR and HOSP visits. This model leads to generally similar
inﬂuences of the 17 predictors on the single ‘needs factor’ as were
obtained in the bivariate Poisson model. As for the factor error model, the
ﬁt is slightly improved over model A with a DIC of 5808 and pe ¼ 1157.
The effects on the outcomes (via the factor) of difﬁculties in activities
of daily living (ADL) and of male gender are clariﬁed (Table 5.5).
Table 5.5
Regression effects under factor regression model
Mean
S.d.
2.5%
Median
97.5%
Excellent health
0.553
0.133
0.812
0.550
0.302
Poor health
0.427
0.074
0.286
0.426
0.572
Number chronic conditions
0.215
0.020
0.175
0.215
0.253
ADL difﬁculties
0.317
0.068
0.181
0.318
0.447
N East
0.032
0.074
0.114
0.032
0.177
Mid West
0.066
0.068
0.071
0.067
0.196
West
0.116
0.076
0.038
0.116
0.270
Age
0.110
0.053
0.033
0.102
0.236
Black
0.112
0.085
0.054
0.113
0.278
Male
0.123
0.059
0.006
0.123
0.239
Married
0.063
0.063
0.187
0.062
0.062
Years education
0.005
0.008
0.020
0.005
0.011
Family income
0.002
0.010
0.021
0.001
0.018
Employed
0.106
0.093
0.084
0.108
0.286
Private insurance
0.099
0.073
0.041
0.098
0.242
MedicAid
0.158
0.099
0.038
0.158
0.349
MULTIVARIATE OUTCOMES
187

Both observed variables have similar loadings on the factor. The check on
zero counts is improved with Pc ¼ 0:83. Further model simpliﬁcation,
perhaps via regressor selection to eliminate predictors of marginal
signiﬁcance, might enhance the impacts of those regressors which
distinguish patients with non-zero visits – this would improve this
predictive check further.
Example 5.10
Visual impairment by eye
Liang et al. (1992) consi-
der bivariate binary data for visual impairment (vision less than 20/60)
among 5199 subjects under the State of Maryland driving regulations.
Thus Yi1 ¼ 1 if sight in the left eye is impaired and Yi2 ¼ 1 if there is
impairment in the right eye. They consider the predictors age (in bands
40–50, 50–60, 60–70 and 70þ), race (1 for blacks, 0 for whites) and
education (Table 5.6). Here only age and race are considered and age is
in the form Ai  2:5 where Ai ¼ 1 for persons aged 40–50, Ai ¼ 2 for
persons 50–60, etc. (i.e. age centred at 60 and in units of ten years).
As in section 5.4.2, one may model the marginal models and odds ratio
separately. Here, however, the marginal models 
a ¼ logitðPrðY1 ¼ 1ÞÞ
and 
 b ¼ logitðPrðY2 ¼ 1ÞÞ are assumed to be the same so that 
 ¼

a ¼ 
b is an epidemiological model for visual impairment (VI) regard-
less of eye affected or whether sight is impaired in one or both eyes. Then
following Liang et al., the predictors for the marginal model are age, age
squared, race, and an interaction between age squared and race. Liang
et al., also include an interaction between race and age itself but this
appears to be insigniﬁcant (Liang et al., 1992, Table 4). The model for
the odds ratio, reﬂecting whether VI in one eye is associated with VI
in the other, is
log½ORðY1; Y2Þ ¼ log½ð1100Þ=ð1001Þ ¼ 0 þ 1Race
Here disgaggregated data for the 5199 subjects is used for estimation.
Table 5.6
Visual impairment by age and race
Left Right
Black
Subtotal
White
Sub- Grand
eye
eye
40–50 50–60 60–70 70þ
40–50 50–60 60–70 70þ total total
No
No
729
551
452
307
2039
602
541
752
606
2501 4540
No
Yes
21
23
21
37
102
15
16
37
67
135
237
Yes
No
19
24
22
29
94
11
15
31
60
117
211
Yes
Yes
10
14
28
56
108
4
9
11
79
103
211
Total
779
612
523
429
2343
632
581
831
812
2856 5199
188
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

Liang et al. report in their GEE1 analysis a coefﬁcient 1 of 0.54 with t
ratio 2.2. Here the multinomial logit approach of (5.26) (after a two-chain
run of 10 000 iterations, convergent from 1000) shows 1 to straddle
zero, with mean 0.35 and 95% interval f0:13; 0:81g. The effects of age,
age squared, race (all positive) and of race by age squared (negative) are,
by contrast, all well deﬁned. The coefﬁcients in the marginal model are
higher than reported by Liang et al., (1992), with the race coefﬁcient in

 being 0.6 compared with 0.33.
As one possible model check the proportion of blacks impaired in both
eyes among those over 70 is compared with the proportion among whites
over 70 so impaired. Thus the risk difference based on sampling replicate
data from the multinomial model is compared with the observed risk
difference. The observed rates are 13.05% (56/429) among blacks and
9.73% among whites, giving a difference of 3.32%. The model tends to
underestimate this difference ðPc ¼ 0:05Þ predicting an average differ-
ence of around 1.1%. This suggests that age or an age–race interaction
might be added to the model for the odds ratio. In fact the observed risk
differences between races are similar for the two age bands under 60 and
the two bands over 60, so the interaction model might be quite simple.
EXERCISES
1. In Example 5.1 try the Poisson–lognormal mixture as in (5.5), with
"i  Nð0; 2Þ and also a non-parametric mixture with
yi  PoðiÞ
logðiÞ ¼ xi þ "i
"i  DPð	G0Þ
where G0 is also a normal density with mean 0 and unknown variance,
where 	 is preset at ﬁve, and the maximum number of potential
clusters is 20. How far does either approach modify inferences on the
predictor effects or affect goodness of ﬁt?
2. The toxoplasmosis data used by Efron (1986) and others record
positive cases yi in total samples of size ni in i ¼ 1; . . . ; 34 cities in
El Salvador in relation to rainfall totals xi. Consider the beta-binomial
model
yi  Binðni; piÞ
pi  Beðii; i½1  iÞ
EXERCISES
189

where logitðiÞ ¼ x and logðiÞ ¼ z. Using standardized predictors
Xi ¼ ðxi  xÞ=sx and Ni ¼ ðni  nÞ=sn, consider the model with ﬁxed
variance parameters i ¼  against models allowing them to vary
linearly and quadratically with Ni. Thus the simplest model has
logðiÞ ¼ 0 and the most complex has logðiÞ ¼ 0 þ 1Ni þ 2N2
i .
The model for EðpiÞ in each case is
logitðiÞ ¼ 0 þ 1Xi þ 2X2
i þ 3X3
i
Obtain predictions of yi via replicate sampling zi  Binðni; piÞ, and
assess via a predictive loss criterion such as (2.10) how far their bias
and precision are affected by different variance models.
City
Rainfall
p(MLE)
ni
yi
ni  yi
1
1735
0.5
4
2
2
2
1800
0.6
5
3
2
3
2050
0.292
24
7
17
4
1770
0.545
11
6
5
5
1756
0.167
12
2
10
6
1871
0.438
16
7
9
7
1780
0.615
13
8
5
8
1936
0.3
10
3
7
9
1750
0.25
8
2
6
10
1830
0
1
0
1
11
1920
0
1
0
1
12
1650
0
1
0
1
13
2063
0.561
82
46
36
14
1900
0.3
10
3
7
15
2000
0.2
5
1
4
16
2077
0.368
19
7
12
17
1650
0.5
30
15
15
18
1770
0.611
54
33
21
19
2250
0.727
11
8
3
20
2100
0.692
13
9
4
21
1976
0.167
6
1
5
22
1973
0.3
10
3
7
23
1920
0.5
6
3
3
24
2200
0.182
22
4
18
25
2240
0.444
9
4
5
26
1796
0.532
77
41
36
27
1918
0.535
43
23
20
28
2292
0.622
37
23
14
(Continue)
190
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

3. Fit a DPP mixture with varying intercepts 0j, but uniform slope, namely
yi  Binðni; iÞ
logitðiÞ ¼ 0Gi þ 1xi
to the data in Example 5.3 from Follman and Lambert (1989). For
example, one might try taking the maximum potential clusters as
J ¼ 5, and the Dirichlet concentration parameter as an unknown (e.g.
updated as in section 3.5.3) or preset at  ¼ 5.
4. Fit the Poisson ZIP and hurdle models to the fetal lamb movement
data which contains 182 zeros, 41 ones, 12 twos, 2 threes, 2 fours, and
one seven (Leroux and Puterman, 1992). Thus for the ZIP model the
unknowns are  and  in the mixture model
Prðyi ¼ 0Þ ¼  þ ð1  Þ expðÞ
Prðyi ¼ jÞ ¼ ð1  Þ expðÞyi=yi!
Include a predictive check of the zero counts from the ZIP model.
Note that these data have a time series aspect that is not allowed for in
these mixture models.
5. In Example 5.6 try the scale mixture model but with a right tail rather
than left tail modiﬁcation. How does the ﬁt compare with the left tail
modiﬁcation (as in Model D of Program 5.6) and for which cases does
an improvement/deterioration occur?
6. In Example 5.7 how is the EPD affected by setting  at one rather than
taking it as a free parameter, and taking K ¼ 3 rather than K ¼ 4?
7. In Example 5.8 try one- and two-factor models with all ﬁve outcomes
and compare their ﬁts using DIC or EPD measures. Also try the
bivariate probit model applied to breathlessness and wheeze (Y3 and
Y4) in the data given in the example; compare with the results (based
on 29 720 subjects) given by Bock and Gibbons (1996).
(Continued)
City
Rainfall
p(MLE)
ni
yi
ni  yi
29
1750
1
2
2
0
30
1800
0.8
10
8
2
31
2000
0
1
0
1
32
1620
0.278
18
5
13
33
1890
0.471
51
24
27
34
1834
0.707
75
53
22
EXERCISES
191

8. In Example 5.9 try the negative multinomial model and compare its
ﬁt with the factor model and bivariate Poisson–lognormal model.
9. In Example 5.9 include a predictive check on how far replicate data
from the model reproduces the observed overdispersion. Also apply a
selection procedure on the regressors to assess whether the predictive
check for zero counts is thereby improved.
10. In Example 5.10 add an age–race interaction to the model for the
odds ratio and assess whether the predictive check on both eye VI by
race improves.
REFERENCES
Agresti, A. (2002) Categorical Data Analysis, 2nd edition. John Wiley & Sons:
New York.
Aitkin, M. (1996) A general maximum likelihood analysis of overdispersion in
generalized linear models. Statiststics and Computing, 6, 251–262.
Aitkin, M. (2001) Likelihood and Bayesian analysis of mixtures. Statistical
Modelling, 1, 287–304.
Albert, J. (1999) Criticism of a hierarchical model using Bayes factors. Statistics
in Medicine, 18, 287–305.
Albert, J. and Chib, S. (1993) Bayesian analysis of binary and polychotomous
response data. Journal of the American Statistical Association, 88, 669–679.
Aranda-Ordaz, F. (1981) On two families of transformations to additivity for
binary response data. Biometrika, 68, 357–363.
Bartholomew, D. (1987) Latent Variable Models and Factor Analysis. Charles
Grifﬁn: London.
Bartholomew, D. and Knott, M. (1999) Latent Variable Models and Factor
Analysis, Kendall’s Library of Statistics, 7. Arnold: London.
Basu, S. and Chib, S. (2003) Marginal likelihood and Bayes factors for Dirichlet
process mixture models. Journal of the American Statistical Association, 98,
224–235.
Basu, S. and Mukhopadhyay, S. (2000) Binary response regression with normal
scale mixture links. In Generalized Linear Models: A Bayesian Perspective,
Dey, D., Ghosh, S. and Mallick, B. (eds). Marcel Dekker: New York.
Bliss, C. (1935) The calculation of the dosage-mortality curve. Annals of Applied
Biology, 22.
Bock, R. and Gibbons, R. (1996) High dimensional multivariate probit analysis.
Biometrics, 52, 1183–1194.
Bo¨hning, D. (1999) Computer-Assisted Analysis of Mixtures and Applications:
Meta-Analysis, Disease Mapping and Others. Chapman and Hall: London/
CRC Press: Boca Raton, FL.
192
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

Cameron, C. and Trivedi, P. (1998) Regression Analysis of Count Data, Econo-
metric Society Monograph No. 30, Cambridge University Press: Cambridge.
Carey, V., Zeger, S. and Diggle, P. (1993) Modelling multivariate binary data
with alternating logistic regressions. Biometrika, 80, 517–526.
Chen, M. and Dey, D. (2003) Variable selection for multivariate logistic regres-
sion models. Journal of Statistical Planning and Inference, 111, 37–55.
Chib, S. and Greenberg, E. (1998) Analysis of multivariate probit models.
Biometrika, 85, 347–361.
Chib, S. and Winkelmann, R. (2001) Markov chain Monte Carlo analysis of cor-
related count data. Journal of Business and Economic Statistics, 19, 428–435.
Connolly, M. and Liang, K. (1988) Conditional logistic regression models for
correlated binary data. Biometrika, 75, 501–506.
Cox, D. and Wermuth, N. (2002) On some models for multivariate binary
variables parallel in complexity with the multivariate Gaussian distribution.
Biometrika, 89, 462–469.
Czado, C. (1994) Bayesian inference of binary regression models with parametric
link. Journal of Statistical Planning and Inference, 41, 121–140.
Czado, C. and Raftery, A. (2001) Choosing the link function and accounting for
link uncertainty in generalized linear models using Bayes factors. Discussion
Paper 262, SFB 386, University of Munich.
Dey, D. and Ravishanker, N. (2000) Bayesian approaches for overdispersion in
Generalized Linear Models. In Generalized Linear Models: A Bayesian
Perspective, Dey, D., Ghosh, S. and Mallick, B. (eds). Marcel Dekker:
New York.
Dey, D., Peng, F. and Gelfand, A. (1997) Overdispersed generalized linear
models. Journal of Statistical Planning and Inference, 64, 93–107.
Efron, B. (1986) Double exponential families and their use in generalized linear
regression. Journal of the American Statistical Association, 81, 709–721.
Engel, B. and Keen, A. (1994) A simple approach for the analysis of generalized
linear mixed models. Statistica Neerlandica, 48, 1–22.
Follman, D. and Lambert, D. (1989) Generalizing logistic regression by nonpara-
metric mixing. Journal of the American Statistical Association, 84, 295–300.
Ganio, L. and Schafer, D. (1992) Diagnostics for overdispersion. Journal of the
American Statistical Association, 87, 795–804.
Gelfand, A. and Dalal, S. (1990) A note on overdispersed exponential families.
Biometrika, 77, 55–64.
Gelfand, A. and Mallick, B. (1995) Bayesian analysis of semiparametric propor-
tional hazards models. Biometrics, 51, 843–852.
Gelman A., Carlin J., Stern, H. and Rubin, D. (2003) Bayesian Data Analysis, 2nd
Edition. CRC Press: Boca Raton, FL.
Glonek, G. and McCullagh, P. (1995) Multivariate logistic models. Journal of the
Royal Statistical Society, Series B, 53, 533–546.
Greene, W. (2000) Econometric Analysis, 4th edition, Prentice Hall: Englewood
Cliffs, NJ.
REFERENCES
193

Guo, G. (1996) Negative multinomial regression models for clustered event
counts. Sociological Methodology, 26, 113–132.
Hall, D. (2000) Zero-inﬂated Poisson and binomial regression with random
effects: a case study. Biometrics, 56, 1030–1039.
Haneuse, S. and Wakeﬁeld, J. (2004) Ecological inference incorporating spatial
dependence. Chapter 13 in Ecological Inference: New Methodological Stra-
tegies, King, G., Rosen, O. and Tanner, M. (eds). Cambridge University Press:
Cambridge.
Hurn, M., Justel, A. and Robert, C. (2003) Estimating mixtures of regressions.
Journal of Computational and Graphical Statistics, 12, 1–25.
Johnson, V. and Albert, J. (1999) Ordinal Data Models. Springer: New York.
Jorgensen, B. (1987) Exponential dispersion models. Journal of the Royal
Statistical Society, Series B, 49, 127–162.
Kahn, M. and Raftery, A. (1996) Discharge rates of Medicare stroke patients to
skilled nursing facilities: Bayesian logistic regression with unobserved hetero-
geneity. Journal of the American Statistical Association, 91, 29–41.
Kleinman, K. and Ibrahim, J. (1998) A semiparametric Bayesian approach to the
random effects model. Biometrics, 54, 921–938.
Lambert, D. (1992) Zero-inﬂated Poisson regression, with an application to
defects in manufacturing. Technometrics, 34, 1–14.
Leroux, B. and Puterman, M. (1992) Maximum penalized likelihood estimation
for independent and Markov-dependent Poisson mixtures. Biometrics, 48,
545–558.
Liang, K.-Y., Zeger, S. and Qaqish, B. (1992) Multivariate regression analyses for
categorical data. Journal of the Royal Statistical Society, Series B, 54, 3–40.
Lindsey, J. (1975) Likelihood analysis and test for binary data. Applied Statistics,
24, 1–16.
Mallick, B. and Gelfand, A. (1994) Generalized linear models with unknown link
function. Biometrika, 81, 237–245.
McCullagh, P. and Nelder, J. (1989) Generalized Linear Models, 2nd Edition.
Chapman and Hall: London.
Moore, D., Park, C. and Smith, W. (2001) Exploring extra-binomial variation in
teratology data using continuous mixtures. Biometrics, 57, 490–494.
Mullahy, J. (1986) Speciﬁcation and testing of some modiﬁed count data models.
Journal of Econometrics, 33, 341–365.
Munkin, M. and Trivedi, P. (1999) Simulated maximum likelihood estimation of
multivariate mixed-Poisson regression models, with application. Econometrics
Journal, 2, 29–48.
Muthen, B. (1979) A structural probit model with latent variables. Journal of the
American Statistical Association, 24, 807–811.
Newton, M., Czado, C. and Chappell, R. (1996) Bayesian inference for semi-
parametric binary regression. Journal of the American Statistical Association,
91, 142–153.
194
FURTHER QUESTIONS IN BINOMIAL AND COUNT REGRESSION

Ntzoufras, I., Dellaportas, P. and Forster, J. (2003) Bayesian variable and link
determination for generalised linear models. Journal of Statistical Planning
and Inference, 111, 165–180.
O’Brien, S. and Dunson, D. (2004) Bayesian multivariate logistic regression.
Biometrics, 60, 739–746.
Pierce, D. and Sands, B. (1975) Extra-Bernouilli variation in binary data.
Technical Report No. 46, Dept. of Statistics, Oregon State University.
Raftery, A. (1996) Approximate Bayes factors and accounting for model uncer-
tainty in generalised linear models. Biometrika, 83, 251–266.
Rosen, O., Jiang, W., King, G. and Tanner, M. (2001) Bayesian and frequentist
inference for ecological inference: the RC case. Statistica Neerlandica, 55,
134–156.
Stukel, T. (1988) Generalized logistic models. Journal of the American Statistical
Association, 83, 426–431.
West, M. (1985) Generalised linear models: scale parameters, outlier accom-
modation and prior distributions (with discussion). In Bayesian Statistics 2,
Bernardo, J., DeGroot, M., Lindley, D. and Smith, A. (eds). North-Holland:
Amsterdam.
Winkelmann, R. (2000) Econometric Analysis of Count Data. Springer:
New York.
Winkelmann, R. and Zimmermann, K. (1995) Recent developments in count data
modeling. Journal of Economic Surveys, 9, 1–24.
REFERENCES
195


CHAPTER 6
Random Effect and Latent
Variable Models for
Multicategory Outcomes
6.1
MULTICATEGORY DATA: LEVEL OF OBSERVATION
AND RELATIONS BETWEEN CATEGORIES
Suppose the observed data are polytomous, when for individual data level
one among the elements of the vector yi ¼ ðyi1; yi2; . . . ; yiJÞ takes the
value 1. Equivalently this type of outcome may be represented by a
categorical indicator Di ¼ j if and only if yij ¼ 1. Much survey and
census data regarding attitudes or demographic attributes are of this kind,
as are choice data in econometrics. Usually such data are deﬁned in terms
of mutually exclusive alternatives: if the jth outcome of the J possible
outcomes occurs then yij ¼ 1, and the others are zero (yik ¼ 0 for k 6¼ j).
Aggregated multinomial (or ‘compositional’) data accumulate such
responses over subjects within clusters i and will be in the form
fi ¼ ð fi1; fi2; . . . ; fiJÞ
specifying
counts
in
response
categories
j ¼
1; . . . ; J for clusters i. Such categories may be ranked (e.g. attainment
levels j by individual pupils or schools i) or unranked. This chapter
considers unranked or nominal categorizations, whereas Chapter 7
tackles ordinally ranked multinomial data. In each situation a model is
required for the probabilities ij of choice or allocation j for the ith unit or
individual.
As for binary data the ‘revealed’ choice or allocation may be regarded
as reﬂecting the operation of an underlying latent utility or frailty (Albert
Bayesian Models for Categorical Data
P. Congdon
# 2005 John Wiley & Sons, Ltd

and Chib, 1993; Scott, 2003) and data augmentation at the level of the
individual may be introduced to facilitate estimation of the ij. While a
standard multinomial likelihood, or data augmentation corresponding
indirectly to the standard likelihood, may be appropriate in many cases,
whether for individual or aggregate data, interdependence between
choice categories and other sorts of heterogeneity (leading to multinomial
overdispersion) may need to be considered.
As for binomial and count data, representations of heterogeneity in
choice modelling may be classed as discrete or continuous (Wedel et al.,
1999), with discrete approaches exempliﬁed by ﬁnite mixture models that
may be taken to correspond to subpopulations or market segments (e.g. in
consumer choice modelling). However, the underlying distribution of
preferences or utilities may in fact be continuous, and continuous mixture
models may outperform discrete mixture models in out-of-sample pre-
dictions (Lenk et al., 1996). The conjugate approach for such hetero-
geneity is the multinomial–Dirichlet mixture where the Dirichlet is the
multivariate generalization of the beta density. However, as for binary
logit and Poisson data it is often easier to model random interdependent
choices and heterogeneity within the regression link, as in random effects
MNL models (see section 6.6) (Hensher and Greene, 2001), or via probit
models (Hausman and Wise, 1978).
6.2
MULTINOMIAL MODELS FOR INDIVIDUAL DATA:
MODELLING CHOICES
A number of modelling schemes have been proposed for multiple
category variables observed at individual level, including multinomial
generalizations of the logit and probit models for binary outcomes.
Examples of multicategory modelling include human choice applications,
for instance in transportation (Greene, 2000; Nobile et al., 1997), in
marketing (Rossi and Allenby, 2003), party choice in political science
(Glasgow, 2001) and in occupational and residential mobility. They may
involve unordered or ranked categories between which a choice is made,
and predictors may relate to subject characteristics (e.g. class or income),
attributes of different choices (e.g. price), or be subject-speciﬁc measures
of attractiveness of different choices.
The revealed choice is often taken (e.g. in econometrics) to reﬂect an
underlying latent continuous utility scale. In some applications (e.g.
political afﬁliation or religious belief) a single underlying scale may be
less substantively justiﬁed. Assume a subject chooses the option with the
198
MODELS FOR MULTICATEGORY OUTCOMES

highest utility and that the utility function is written as a sum of an error
term (summarizing unknown inﬂuences) and a systematic component for
the utility of known predictors. Different sorts of model follow according
to the density assumed for the errors: the extreme value distribution of
McFadden (1974) leads to logit models (e.g. the multinomial logit and
categorical logit models discussed below), while a normal error leads to
multiple and categorical probit models (McCulloch and Rossi, 1994).
Other forms for " may be used, such as scale mixtures of multivariate
normals (Chen and Kuo, 2002). Discrete mixtures of normal or other
densities are another possibility.
Predictors of choice or group membership may include social and
demographic characteristics of individuals i, Xi, namely ‘characteristics
of the chooser’ in choice models (Hoffman and Duncan, 1988). However,
they may also be attributes of the different choices j, Aj, or attributes of
choices speciﬁc to individuals Cij (e.g. individual costs attached to
different transport modes). In a choice application the underlying utility
takes the form
Uij ¼ Vij þ "ij ¼ Xij þ Cij þ Aj’ þ "ij
ð6:1Þ
where 
ij ¼ Xij þ Cij þ Aj’ reﬂects the impact of known aspects of
utility measured by Xi, Cij and Ai. What is actually observed is the choice
j which is taken to correspond to a maximum utility decision with
Uij ¼ maxðUi1; Ui2; . . . ; UijÞ, so that
ij ¼ ProbðUij > Ui½ jÞ
with ½ j denoting the set of choices apart from the jth. Subject to
identiﬁability constraints, data augmentation provides a way to simulate
the underlying utilities (Albert and Chib, 1993; McCulloch and Rossi,
1994), and may lead to simpliﬁed sampling by converting the analysis to
normal linear multivariate regression. However, direct estimation using
the multinomial likelihood remains an option.
Different model frameworks are deﬁned according to the type of
regressor variable. If the predictors include only individual characteristics
then what may be termed a pure multinomial logit or probit is appro-
priate, usually with choice-speciﬁc parameters j and with parameters for
a baseline choice category set to zero to avoid model indeterminacy. If
the predictors include attributes Cij of the jth alternative speciﬁc for
individual i, then an appropriate model is the conditional logit or probit
model. With Xi0 ¼ 1 for a constant term included in a 1  p vector Xi of
predictors for subjects i ¼ 1; . . . ; n, and with the last among j ¼ 1; . . . ; J
MULTINOMIAL MODELS FOR INDIVIDUAL DATA
199

categories as baseline or reference, the pure multinomial logit model has
the form
PrðYij ¼ 1Þ ¼ ij ¼ expðXijÞ= 1 þ
X
J1
k¼1
expðXikÞ
"
#
j ¼ 1; . . . ; J  1
ð6:2aÞ
PrðYiJ ¼ 1Þ ¼ iJ ¼ 1= 1 þ
X
J1
k¼1
expðXikÞ
"
#
ð6:2bÞ
where j ¼ ðj0; . . . ; jpÞ0 describes how the subject attributes affect
different choices. The effect of Xim (the mth attribute for subject i) on
the logit of choice j versus choice k is obtained as the contrast jm  km.
An alternative parameterization for identiﬁability is to specify a regres-
sion parameter prior j for j ¼ 1; . . . ; J and then centre the parameters as
c
j ¼ j  , with
ij ¼ expðXic
j Þ=
X
J
k ¼ 1
expðXic
kÞ
ð6:2cÞ
One point to note is that one may deﬁne the variable regression
coefﬁcients in terms of subsets of the choices, rather than all the j
necessarily being different. For example, taking 1m as a free parameter
for predictor m but other km as ﬁxed at zero (for k ¼ 2; . . . ; J  1)
amounts to comparing the impact of a covariate between choice 1 against
all other choices combined. So in the data considered in Example 6.2
below, Greene (2000) compares the impact of household income on travel
by air as against travel by train, car or bus.
By contrast to the multinomial logit model, the conditional logit
considers choice attribute data Cij speciﬁc to individuals, and typically
involves regression coefﬁcients  constant over alternatives j
ij ¼ expðCijÞ=
X
K
k¼1
expðCikÞ
ð6:3Þ
Dividing by the numerator, as in
ij ¼ 1=
X
K
k¼1
expð½Cik  CijÞ
shows that choice probabilities are then determined by differences in
attribute values between alternatives. When equality over categories in
the  coefﬁcients is not assumed, it is necessary to constrain one
category’s parameter to zero (e.g. 
ij ¼ j0 þ C1ijj1 þ C2ijj2, for j ¼
1; . . . ; J  1 and 
ij ¼ 0).
200
MODELS FOR MULTICATEGORY OUTCOMES

With data containing both chooser attributes X and attributes C speciﬁc
to choices and individuals, coefﬁcients on intercepts or chooser attributes
replicate the format in (6.2) but the coefﬁcients for C variables replicate
(6.3). So with a single variable of each type, Xi and Cij; J ¼ 3 choices,
and taking the third category as reference,

i1 ¼ 1 þ Xi1 þ Ci1

i2 ¼ 2 þ Xi2 þ Ci2

i3 ¼ Ci3
ij ¼ expð
ijÞ=
X
K
k¼1
expð
ikÞ
ð6:4Þ
This type of mixed attribute model is generally also called the multi-
nomial logit model or MNL model for short, and this is the terminology
subsequently adopted. However, it is worth being aware of the distinction
sometimes drawn between conditional logit and logit models with
chooser attributes only (e.g. Greene, 2000, section 19.7.1). While any
choice-speciﬁc ﬁxed regression effects (e.g. the intercepts jÞ are set to
zero in the reference category model, note that choice–subject predictors
Cij with constant coefﬁcients over choices are included.
In the multinomial and conditional logit models, the ratio ij=ik, i.e.
the probability of choosing the jth alternative compared with the kth, can
be seen to be independent of the presence or characteristics of other
alternatives. This is known as the independence of irrelevant alternatives
(IIA) assumption or axiom. However, assuming this property may be
inconsistent with observed choice behaviour in that utilities over different
alternatives may be correlated (e.g. there may be sets of similar alter-
natives with similar utilities between which substitution may be made).
One way to correct for clustering is to assume subject or subject–choice
errors in the generalized logit link, leading to mixed logit models or
mixed MNL (MMNL) models (section 6.4).
Another option is the use of multinomial probit models (section 6.4)
since these are not restricted to the IIA axiom. Their estimation by
classical methods is complicated by the need to evaluate multidimen-
sional normal integrals. However, MCMC sampling using data augmen-
tation is relatively easy computationally. Other options to tackle
departures from IIA include nested logit models (e.g. Lahiri and Gao,
2002) which group the choices into subsets such that error variances
differ between subsets.
MULTINOMIAL MODELS FOR INDIVIDUAL DATA
201

6.3
MULTINOMIAL MODELS FOR AGGREGATED DATA:
MODELLING CONTINGENCY TABLES
Strictly, individual choice categorical regression is only necessary when
one or more predictors are continuous. When all predictors are catego-
rical, equivalences with contingency table analysis may be useful to
exploit. As mentioned in Chapter 4, contingency tables (e.g. fij for a two-
way table) can be taken to follow a multinomial distribution if the total
count (e.g. fþþ for a two-way table) is ﬁxed or if row totals are ﬁxed. The
latter case is known as product multinomial sampling since there are I
separate multinomial densities, one for the data in each row, and the total
likelihood is a product over these. Authors such as Lindley (1964) and
Good (1976) set out the Bayesian analysis for I  J two-way tables with
multinomial sampling in relation to the total count fþþ with cell
probabilities ij subject to P
i
P
i ij ¼ 1. This involves a Dirichlet
prior1 on  ¼ ð11; 12; . . . ; IJÞ such that
Pð j Þ /
Y
ij
ij1
ij
The ij can be considered as prior counts for the cell ði; jÞ and the total
þþ as a prior sample size. The posterior is also Dirichlet with elements
yij þ ij and total sample size fþþ þ þþ. Epstein and Fienberg (1991)
consider a proﬁle of ﬁts using an extended prior allowing for varying
strengths
of
belief
in
independence.
Thus
ðf11; f12; . . . ; fIJÞ 
Mðyþþ; 11; 12; . . . ; IJÞ and ð11; 12; . . . ; IJÞ  DirðK; Þ, namely
Pð j K; Þ /
Y
ij

Kij1
ij
A multiple logit model is speciﬁed for ij based on a log-linear model
ij ¼ expð0 þ 1i þ 2jÞ=
X
i
X
j
expð0 þ 1i þ 2jÞ
with constraint
0 ¼  log
X
ij
½expð1i þ 2jÞ
(
)
1 It is worthwhile knowing that a sample (y1; . . . ; yj) from a Dirichlet with parameters ð1; . . . ; jÞ
may be obtained by sampling xj from J independent gamma densities xj  Gaðj; 1) and then setting
yj ¼ xj= P
j x. Alternatively select y1 from a beta density Be(1; þþ  1Þ and xjð j ¼ 2; . . . ; J  1)
from Be(j; PJ
k ¼ jþ1 k). Then
yj ¼
1 
X
j1
k¼i
yk
 
!
xj
ð j ¼ 2; . . . ; J  1Þ
and
yk ¼
1 
X
J1
k¼1
yk
 
!
202
MODELS FOR MULTICATEGORY OUTCOMES

K is preset and taking large values (K ! 1) gives estimates ij
corresponding to independence, whereas K ¼ 0 corresponds to a satu-
rated model with estimated ij close to the observed proportions. Below, a
prior on K is proposed as a way of assessing independence.
Alternatively, as in Leonard and Hsu (1994, p 290), a model can be
framed directly in terms of the multiple logits
ij ¼ expð
ijÞ=
X
i
X
j
expð
ijÞ
where

ij ¼ A
i þ B
j þ AB
ij
ð6:5Þ
subject to the identiﬁcation constraints
X
i
A
i ¼
X
j
B
j ¼
X
i
AB
ij
¼
X
j
AB
ij
¼ 0
Via MCMC sampling one may assess signiﬁcance for omnibus associa-
tion criteria based on models such as (6.5) for I ¼ J ¼ 2
 ¼ log½ð1122Þ=ð1221Þ ¼ 
11 þ 
22  
12  
21
Thus if variables A and B are positively associated then sampled values
ðtÞ will be predominantly positive.
6.3.1
Conditional contingency tables: histogram smoothing and
multinomial logit via Poisson regression
For product multinomial analysis with row totals ﬁxed, the analysis
conditions on known yiþ. So with probabilities ij of variable B taking
values j ¼ 1; . . . ; J given variable A ¼ i, and with P
j ij ¼ 1, the
sampling model is
fij  Mðyiþ; i1; . . . iJÞ
i ¼ 1; . . . ; I
The probabilities deﬁning sampling in each row may be obtained as
ij ¼ jji ¼ PrðB ¼ j j A ¼ iÞ ¼ PrðA ¼ i; B ¼ jÞ=PrðA ¼ iÞ ¼ ij=iþ
with ij obtained by multinomial sampling in relation to yþþ as above.
Gunel and Dickey (1974) show how a two-step prior may be speciﬁed for
product multinomial data, by ﬁrst sampling yiþ from yþþ, and then yij
from yiþ. A product multinomial also applies if column totals are ﬁxed.
However, the Dirichlet has a restricted covariance structure when there
are dependencies between the ‘response’ categories j within rows i. For
example, for I constituencies and J political parties one may expect both
MULTINOMIAL MODELS FOR AGGREGATED DATA
203

negative and positive correlations between ij for different parties. Instead
consider the logit form
ij ¼ expð
ijÞ=
X
k
expð
ikÞ
and assume the parameters of the I multinomial densities under ﬁxed row
totals are exchangeable under a hyperdensity. For example, setting 
i ¼
ð
i1; . . . ; 
ijÞ, with 
iJ ¼ 0 for identiﬁabilty, one may assume

i;1:J1  NJ1ð; Þ
or

i;1:J1  NJ1ð; =iÞ
where the i are positive variables with mean 1. Alternatively one may
take

i  NJð; Þ
where the  parameters include a constraint such as J ¼ 0 for identi-
ﬁcation and the identiﬁed centred means c
j ¼ j  ð j ¼ 1; . . . ; JÞ may
then be obtained.
The raw percentages fij=fiþ, providing estimates of ij based on a
separate row analysis without pooling strength under a hyperdensity, are
likely to show erratic features, whereas prior structures such as the above
both lead to frequency smoothing and provide for a model of interde-
pendencies between categories. This model may also be ﬁtted by Poisson
regression using the fact that the multinomial is equivalent to a Poisson
distribution conditional on a ﬁxed total; this involves deﬁning I ﬁxed
effects predictors i to ensure the row totals are maintained. Thus
fij  PoðijÞ
logðijÞ ¼ i þ ij
where i would typically be assigned vague priors, e.g. i  N(0, 10 000).
Product multinomial sampling may be extended to combinations of
conditioning factors. In particular, when all predictors are categorical, an
MNL model may be ﬁtted by Poisson regression again using the multi-
nomial–Poisson equivalence conditional on a ﬁxed total. Consider four
variables A, B, C and D in categorical form with I, J, K and M levels
respectively. Assume a single multinomial for the contingency table fijkm
such that the joint probabilities PrðA ¼ i; B ¼ j; C ¼ k; D ¼ mÞ ¼ ijkm
sum to one, namely P P P P ijkm ¼ þþþþ ¼ 1.
204
MODELS FOR MULTICATEGORY OUTCOMES

Let D be the dependent variable and A, B and C be predictors. So the
goal is to model conditional probabilities that D is at level m given the
predictors at various combinations of levels,
mjijk ¼ PrðD ¼ m j A ¼ i; B ¼ j; C ¼ kÞ
¼ PrðA ¼ i; B ¼ j; C ¼ k; D ¼ mÞ=PrðA ¼ i; B ¼ j; C ¼ kÞ
¼ ijkm=ijkþ
The distribution of D given ðA ¼ i; B ¼ j; C ¼ kÞ is multinomial with
denominator fijkþ and probabilities mjijk. So via multinomial–Poisson
equivalence this is the same as a Poisson model with ﬁxed marginal totals
fijkþ. The Poisson model would need to include dummy terms for all main
effects and interactions among the predictors, in order to ensure the
marginal totals fijkþ are preserved by the model. However, this reduces to
including a set of IJK ﬁxed effects ijk.
Thus an MNL approach with main effect impacts of the categorical
predictors A, B and C on the response D involves the model
fijkm  PoðijkmÞ
logðijkmÞ ¼ ijk þ m þ im þ jm þ km
ð6:6Þ
where the usual corner constraints apply to the intercept terms (e.g. J
must be set to zero and only 1; . . . ; J1 are free) and to the impacts of
A, B and C. The predicted probabilities are then mjijk ¼ ijkm=fijkþ. The
model may be extended to interactions between predictors, e.g. 
ijm
models an interactive impact of A and B on D.
Example 6.1
Occupational attainment
This example illustrates an
application where the pure multinomial logit model of equation (6.2)
rather than conditional logit of equation (6.3) is relevant: the only
predictors pertaining to the allocation of subjects between a set of ﬁve
occupational categories are subject attributes. The example illustrates
how summaries may be obtained for regression parameter contrasts that
occur in discrete choice models, and how ‘Bayesian signiﬁcance tests’
can be applied to such contrasts. It also considers an alternative Poisson
log-linear regression model that may be applied when predictors are
available in (or converted to) categorical form.
The data are from the 1982 US General Social Survey and also
considered by Long (1997), among others. The occupations are ‘menial’
ð j ¼ 1Þ, blue collar ð j ¼ 2Þ, craft ð j ¼ 3Þ, white collar ð j ¼ 4Þ and
professional ð j ¼ 5Þ. The three predictors are X1 ¼ ethnicity (1 ¼ white,
0 ¼ non-white), X2 ¼ years of education, and X3 ¼ years of work
MULTINOMIAL MODELS FOR AGGREGATED DATA
205

experience. Low-skill manual occupations are taken as the reference
category, so 10 ¼    ¼ 13 ¼ 0 with j0; j1; j2; j3 being the intercept,
ethnicity, education and experience effects for occupations j ¼ 2; . . . ; 5.
This is the corner constraint parameterization.
The IIA property of the MNL without random effects means that the
odds of being in occupation j as against occupation k, namely
Prðyij ¼ 1Þ=Prðyik ¼ 1Þ  PrðDi ¼ jÞ=PrðDi ¼ kÞ
are given by expð½j  kXiÞ, so the contrast j  k deﬁnes the effect of
all covariates Xi on the logit of occupation j versus occupation k. The
effect of covariate Xim (e.g. years of education) on the logit of occupation
j vs. k is jm  km. Sometimes such contrasts may be signiﬁcant (i.e.
positive or negative with a probability exceeding 0.95 or higher), even
when the original coefﬁcients are not signiﬁcantly different from zero. In
particular, one may consider the probabilities
Pr½jm  km > 0
of positive contrasts between choice j and k for predictor m. It may be
noted that maximum likelihood estimation (MLE) shows signiﬁcant
positive effects (t statistics > 1:96) of (a) white ethnicity on the odds
(relative to menial jobs) of being in professional jobs; of (b) education on
being in white-collar and professional jobs; and of (c) experience on
being in professional jobs.
With N(0,10 000) priors on the free parameters and a two-chain run of
20 000 iterations, convergence is obtained from around 5000 iterations.
By contrast to the MLE results, the Bayesian estimation shows more
signiﬁcant coefﬁcients (Table 6.1); for example, white ethnicity is
advantageous for entry to both blue-collar jobs and white-collar jobs as
opposed to menial jobs. It has been noted that maximum likelihood
analysis of logistic models for binary outcomes may have drawbacks with
assessing signiﬁcant predictor effects in small samples (Zellner and
Rossi, 1984) and the present analysis may illustrate similar issues in
multiple logit analysis.
Two of the experience effects are signiﬁcant in the sense that 95%
intervals are entirely positive or negative, though that for white-collar
jobs is on the margin. Some of the experience contrasts j3  k3 are,
however, clearly signiﬁcant. For example, the contrast between 43 and
23 is positive with a probability of 0.98, showing an advantage of
experience in white-collar as against blue-collar jobs.
Examination of the CPOs estimated via (2.15) shows subjects 336 and
295 with the lowest log CPOs (9.1 and 7). These are individuals with
206
MODELS FOR MULTICATEGORY OUTCOMES

under ten years of education but in professional jobs. Low CPOs also
occur for individuals with 16 years of education who are in blue-collar
jobs. Such ﬁndings suggest some heterogeneity in the impact of educa-
tion on occupational allocation.
As will be considered below, discrete mixture models offer one
approach to such heterogeneity. For example, assume
Prðyij ¼ 1 j LiÞ ¼ expðjLixiÞ= 1 þ
X
J
k¼2
expðkLixiÞ
"
#
j > 1
where Li is latent group for subject i and predictor effects jg ¼
ðjg0; . . . ; jgpÞ differ between groups g ¼ 1; . . . ; G. However, in this
application discrete mixture models with G ¼ 2 subpopulations differing
either in all predictor effects jgm; m ¼ 1; 3, or just in the effect of
education jg2 (experience and ethnicity not differing by subpopulation)
did not yield a clearly interpretable pattern. One drawback with these data
is the relative sparsity in terms of measuring the impact of ethnicity (only
28 of 337 subjects are non-white). Other approaches to choice hetero-
geneity (e.g. effects of attributes on allocation varying between subjects)
are considered in section 6.5.
To illustrate the Poisson regression approach to the MNL model
(section 6.3.1), education was grouped into ﬁve categories (under
Table 6.1
Multinomial logit occupational choice (effects relative to menial
jobs); Bayes estimates
Blue collar
Craft
White collar
Professional
Constant (j0)
0.6
0.6
1.4
1.1
2.5%
2.0
0.6
2.8
2.0
97.5%
0.3
1.3
0.5
0.2
White (j1)
1.36
0.63
2.12
2.24
2.5%
0.16
0.34
1.05
1.35
97.5%
2.77
1.88
3.43
3.21
Education (j2)
0.11
0.09
0.37
0.82
2.5%
0.30
0.07
0.16
0.61
97.5%
0.06
0.26
0.59
1.05
Experience (j3)
0.005
0.030
0.037
0.039
2.5%
0.029
0.002
0.000
0.004
97.5%
0.041
0.065
0.077
0.077
MULTINOMIAL MODELS FOR AGGREGATED DATA
207

12 years, 12 years, 13–14 years, 15–16 years and 17 þ years) while
experience was formed into seven bands (under 6 years, 6–10, 11–15,
16–20, 21–25, 26–35, over 35 years). So the joint predictor distribution
has IJK ¼ 2  5  7 ¼ 70 cells and 70 ﬁxed effects ijk as in (6.6) must
be included to ensure equivalence to a multiple logistic. Note that a
multiple logistic using multinomial sampling remains an option and has
the beneﬁt of not involving dummy predictors for each combination of
predictor (which inﬂate the parameter count). The substantive interest
under either approach is in the parameters im, jm and km relating to the
impact of ethnicity, education and experience respectively.
With a Poisson likelihood, the posterior means of the white ethnicity
parameters fimg, namely f22; 23; 24; 25g, are similar to those in
Table 6.1 but less precisely estimated (i.e. wider 95% credible intervals):
1.2 (0.1,2.8), 0.5 (0.7,1.7), 1.8 (0.1,3.9) and 1.95 (0.5, 3.6). The
effects of education suggest some non-linearity: the coefﬁcients j5 for
entry to professional jobs for education levels 2, 3, 4 and 5 are
respectively 1.1 (with a 95% interval from 0.4 to 2.7), 1.8 (0.3,3.3),
5.3 (3.1,8.4) and 10.6 (4.6,17.9). While losing continuity in predictor
values, this approach may be useful to detect non-linearity as part of an
exploratory data analysis. However, the estimates obtained depend on
whatever grouping of the originally continuous variable is used. Example
6.4 considers an alternative approach to the non-linear impact of educa-
tion for these data.
Example 6.2
Exam grade frequencies
Leonard and Hsu (1994)
present totals fij of students allocated to six grades in mathematics for
40 London schools. The frequency smoothing model described in section
6.3.1 is ﬁtted with multinomial sampling conditioning on the school totals
fiþ, and with parameters ij,  and , as in
fij  Mðfiþ; ijÞ
i ¼ 1; . . . ; I
ij ¼ expð
ijÞ=
X
i
X
j
expð
ijÞ

i  NJð; Þ
where the  parameters include a constraint 1 ¼ 0 for identiﬁcation. The
centred means c
j ¼ j  ð j ¼ 1; . . . ; 6Þ may then be obtained.
A Wishart prior on  is adopted with 6 degrees of freedom and
identity scale matrix, and N(0,103) priors on the j. The second half of
208
MODELS FOR MULTICATEGORY OUTCOMES

a two-chain run of 10 000 iterations results in a correlation matrix
R ¼
1
0:71
0:51
0:02
0:40
0:69
0:71
1
0:56
0:14
0:30
0:54
0:51
0:56
1
0:29
0:10
0:36
0:02
0:14
0:29
1
0:24
0:19
0:40
0:30
0:10
0:24
1
0:47
0:69
0:54
0:36
0:19
0:47
1
2
6666664
3
7777775
showing positive correlations for adjacent grades, especially the ﬁrst and
second. The centred means have posterior means (with standard devia-
tions) similar to those cited by Leonard and Hsu, namely 0.47 (0.2),
0.46 (0.1), 0.61 (0.1), 0.61 (0.1), 0.90 (0.17) and 0.31 (0.17). The
smoothing is illustrated by school 22 with the lowest student total (14)
students and f22 ¼ ð2; 3; 6; 3; 0; 0Þ but with posterior mean 22 ¼
ð0:132; 0:239; 0:317; 0:221; 0:039; 0:052Þ.
Using chi-square deviations to measure discrepancies, the more unu-
sual schools in terms of the model are those either with high proportions
in grade 1 or those with high proportions in grades 5 or 6. A predictive
posterior check on model adequacy may be used comparing the usual chi-
square statistic Cð f; ^f) (where ^fij ¼ ijfiþÞ with that based on sampling
replicate data, namely Cð fnew;^fÞ. The value 0.67 so obtained indicates an
adequate model.
Example 6.3
Parental style
Epstein and Fienberg (1991) consider a
two-way table (Table 6.2) relating to parental decision making (author-
itarian vs. democratic) and political afﬁliation (SDS vs. YAF).
They specify N(0.5, 4) priors for both 1i and 2j under the indepen-
dence prior for the Dirichlet means, namely
ij ¼ expð0 þ 1i þ 2jÞ=
X
i
X
j
expð0 þ 1i þ 2jÞ
with constraint
0 ¼  log
X
ij
½expð1i þ 2jÞ
(
)
Table 6.2
Parental style and political afﬁliation
SDS
YAF
All
Authoritarian
29
33
62
Democratic
131
78
209
All
160
111
271
MULTINOMIAL MODELS FOR AGGREGATED DATA
209

They take various values of K and compare the resulting estimates of ij
(see Table 6.3).
Here a prior on K is added, obtained as K ¼ 1=L where L is uniform
between zero and a large number (e.g. 107). A two-chain run of
50 000 iterations (with K converging after 10 000) gives mean K of 254
and median 70. This suggests a model intermediate between the indepen-
dence and saturated models.  is estimated as (0.115, 0.115, 0.475, 0.295).
The DIC is 21.6 with 2.2 effective parameters. A predictive check proba-
bility of 0.41 based on a chi-square calculation for actual and replicate data
suggests that this approach provides an adequate model.
6.4
THE MULTINOMIAL PROBIT
Independence between choices is often not appropriate, as Example 6.2
illustrates. Among the limitations of the MNL forms considered in sec-
tion 6.2 in analysing individual choice data are inﬂexibility in the face of
correlated choices (and substitutability between choices) and heterogeneity
in predictor effects. The multinomial probit (MNP) model seeks especially
to reﬂect interdependent choices, but may be extended to reﬂect hetero-
geneity (Glasgow, 2001). It starts with the random utility model of (6.1) but
involves reframing it to obtain identiﬁability. Thus in a generalization of the
utility comparison underlying dichotomous choice (Chapter 4), the utility for
choice j has systematic and stochastic components according to
Uij ¼ 
ij þ "ij ¼ Xi
j þ Cij þ Aj’ þ "ij
where
yij ¼ 1
if
Uij ¼ maxðUi1; Ui2; . . . ; UiJ).
Since
the
density
y j X; C; A is unchanged by adding a scalar random variable to Uij,
identiﬁability in terms of location requires differencing against the utility
of a reference category, such as the Jth (Geweke et al., 1994). So the
latent utilities which are modelled are differences
Wij ¼ Uij  UiJ;
j ¼ 1; . . . ; J  1
Table 6.3
Contingency table probabilities for different K
K
0
100
200
400
600
1000
2000
1
11
0.107
0.115
0.119
0.125
0.130
0.126
0.135
0.133
12
0.122
0.115
0.110
0.105
0.102
0.098
0.100
0.093
21
0.483
0.474
0.471
0.469
0.468
0.463
0.453
0.459
22
0.288
0.296
0.300
0.301
0.300
0.313
0.312
0.315
210
MODELS FOR MULTICATEGORY OUTCOMES

giving J  1 latent variables. So yij ¼ 1 ð j ¼ 1; . . . ; J  1Þ if both Wij ¼
maxðWi1; Wi2; . . . ; WiJ1Þ and Wij > 0. If the observed choice is J ðyiJ ¼
1Þ then all the Wij are negative. Note that this redeﬁnition entails taking
differences in the predictors Cij and Aj; so for instance the model now
involves differenced predictors cij ¼ Cij  CiJ, j ¼ 1; . . . ; J  1.
The augmented data Wij may be sampled in the same way that the
latent scale is sampled in binary regression except that they will be
correlated (Albert and Chib, 1993, p 673). Under the multinomial probit,
an MVN linear regression with correlated errors (as in Chapter 3) is
assumed for the latent Wij. For example, a regression with both chooser
characteristics and subject-speciﬁc choice measures has the form
Wij ¼ jXi þ cij þ "ij
ð6:7Þ
where
"i  NJ1ð0; Þ
and "i ¼ ð"i1; "i2; . . . ; "i; J1). Unlike the MNL models considered in
section 6.2, the correlation among the choices induced by the error
structure in (6.7) means that the restrictive IIA no longer holds. So one
may assess how far voters view political parties as similar or different
(Glasgow, 2001), or allow for substitution between travel modes
(Daganzo, 1979). Scale mixing may also be used, as in the simple probit
(see equation 4.5) to allow robustness to aberrant observations. Then
"i  NJ1ð0; =iÞ
where i  Ga(	/2,	/2) and 	 is a degrees of freedom parameter
(Linardakis and Dellaportas, 2003).
Despite differencing via Wij ¼ Uij  UiJ, there is still an issue of unique
scale, since multiplying (6.7) through by a constant leaves the likelihood
unchanged. In general one element of  must be preset, leaving ½JðJ  1Þ=
2  1 free parameters (Glasgow, 2001; Albert and Chib, 1993). Setting the
ﬁrst variance term in  to one is the most common strategy, though this
leads to more complex sampling than an unrestricted . Let this ﬁrst
variance term be denoted 11, the variance for "i1, with 1 ¼ 0:5
11 .
McCulloch and Rossi (1994) propose a Gibbs sampling scheme that
involves an unrestricted  but monitors the identiﬁed parameters, such as
the regression parameters, ~j ¼ j=1 and ~ ¼ =1, the scaled covariances
~jk ¼ jk=1
and hence the correlations between the errors. Yu (2000) reports the
success of such a strategy in an application to psychometric rankings.
Specifying a prior on j,  and the unrestricted error covariance matrix
THE MULTINOMIAL PROBIT
211

means that the prior on the identiﬁed parameters is induced. To ascertain
the form of the induced prior might involve simulation using the
observations without actual updating with the response data y. Problems
may occur with informative priors on the unidentiﬁed parameters, though
Nobile (1998) suggests a strategy to improve convergence under the
unrestricted  approach.
Schemes with fully identiﬁed prior for the MNP have also been
proposed (McCulloch et al., 2000; McCulloch and Rossi, 2000; Lahiri
and Gao, 2002). Thus from the properties of the multivariate normal 
may be written as a partitioned matrix
 ¼
11
!
!



ð6:8Þ
where 11 is the variance of "i1, and the J  2 parameters ! deﬁne the
covariance between "i1 and the errors 
i ¼ ð"i2; "i3; . . . ; "i;J1Þ. Then for
sampled "i1, the 
i are NJ2 with covariance  and means (!/11Þ"i1.
Taking 11 ¼ 1 reduces the unknown parameters to a ðJ  2Þ-dimen-
sional ‘regression’ parameter ! and the ðJ  2ÞðJ  1Þ=2 parameters of .
Another method proposed by Chib et al. (1998) also sets 11 ¼ 1 and
uses a prior based on a Choleski decomposition to represent the free
elements in . Thus let
 ¼ HH0
where H is a ðJ  1Þ  ðJ  1Þ lower triangular matrix with h11 ¼ 1.
For example, with J ¼ 3, H would be a 2  2 matrix with ﬁrst row (1 0),
and with second row ðh21; h22Þ, so that 11 ¼ 1; 12 ¼ 21 ¼ h21 and
22 ¼ h2
21 þ h2
22. Letting  ¼ ðh21; log h22; h31; h32; log h33; . .. ; hJ1;1;. .. ;
log hJ1; J1Þpriorsmaybeintheformofunrestrictednormaldensitieson jk.
Heterogeneity in the multinomial probit may be introduced via
Wij ¼ jXi þ cij þ ’iZij þ "ij
where Zij is a vector of predictors the impact of which varies over subjects
according to the subject-level random effect ’i. If Zij contains just the
intercept then a nested error structure is obtained. The parameters of the
MNP, especially its heterogeneous version, may be weakly identiﬁed by
the data. The Wij are unobserved, and if themselves modelled in terms of
random effects such as ’i, weak identiﬁcation is obtained. Even the stan-
dard MNP may yield imprecise inferences about the covariance matrix 
for small data sets. Chib et al. (1998) contrast the possible identiﬁability
problems with the MNP model as against the simple MNL model (without
random effects). Such identiﬁability problems apply to mixed MNL models
212
MODELS FOR MULTICATEGORY OUTCOMES

also (section 6.6) and occur in classical estimation as well as Bayesian
sampling-based estimation (Keane, 1992; Greene, 2000).
It may be noted that latent utilities Wij under the MNL model analogous
to those in (6.6) may be generated by assuming that "ij are sampled from a
type I extreme value density (McFadden, 1974), as opposed to the MVN
error density for the MNP model. Consider the MNL model as
PrðDi ¼ jÞ ¼ ij ¼ ij= 1 þ
X
J1
k¼1
ik
 
!
/ ij
j ¼ 1; . . . ; J  1
PrðDi ¼ JÞ ¼ iJ ¼ 1= 1 þ
X
J1
k¼1
ik
 
!
where, for example, ij ¼ expðjXi þ cijÞ or ij ¼ jXi þ cij þ 
iZij
(for j < J) and iJ ¼ 1 for identiﬁability. Scott (2003) proposed sampling
exponential variables Zij  EðijÞ with Zij ¼ minðZi1; . . . ; ZiJÞ when Di ¼
j. It is necessary to sample ZiJ  Eð1Þ to ensure the scale is deﬁned. If
Di ¼ argminkðZikÞ then PrðDi ¼ jÞ is proportional to ij and so follows
the MNL model.
6.5
NON-LINEAR PREDICTOR EFFECTS
A few authors have considered how to modify MNL or MNP models to
reﬂect non-linear impacts of predictors. For example, Abe (1999) pro-
poses a form of conditional logistic model (see Chapter 4) with each
choice occasion or consumer deﬁning a stratum. Examples of non-linear
effects include a region of price variation within which consumers are
relatively insensitive, whereas once a certain threshold is exceeded sensi-
tivity to price changes is noticed. While polynomials in, say, cost or
income may be used in consumer applications to model non-linearity, a
more ﬂexible approach is provided by non-parametric regression
involving spline or GAM methods. For example, the MNL model
Prðyij ¼ 1Þ ¼ ij ¼ exp ð
ijÞ=
X
J
k¼1
expð
ikÞ
where

ij ¼ jXi þ Cij
j < J

iJ ¼ CiJ
may be replaced by one in which some predictor effects are modelled by
smooth functions. So for j < J one might assume that two attributes Xi1
NON-LINEAR PREDICTOR EFFECTS
213

and Xi2 follow a linear effect, while the impacts of Xi3 and Cij are
modelled as smooth functions. The smooth in the attribute would be
speciﬁc to the choice category j, but not the smooth in Cij, so that

ij ¼ 0j þ 1jxi1 þ 2jxi2 þ S1jðxi3Þ þ S2ðCijÞ
As for other multiple choice models, identiﬁability is an issue if, for
example, subjects at higher levels of X3 are mostly conﬁned to a subset of
the range of choices j ¼ 1; . . . ; J; for instance, higher income consumers
may be conﬁned to a few brands.
Example 6.4
Occupation attainment (continued)
To illustrate non-
linear regression effects in the occupation choice data, let the impact of
experience assume a conventional linear form but that of years of
education be modelled by a penalized random effects quadratic spline
(Ruppert et al., 2003) with
Sðxi3Þ ¼ 1xi3 þ 2x2
i3 þ
X
K
k¼1
kðxi3  tkÞ2
þ
where k  Nð0; 2
Þ and 1/2
 is assigned a Ga(0.1,0.1) prior. K ¼ 6
knots are taken at t ¼ f9:6; 12; 13:6; 14; 16; 16:4g; note that the 20th,
30th, 40th and 50th percentiles of education are all 12 years. This model
yields a slight improvement in average deviance (minus twice the log
likelihood), i.e. 864 versus 871 for the MNL model in Example 6.1.
However, there are 26 effective parameters compared with 16 under the
−8
−3
2
7
12
17
22
27
5
7
9
11
13
15
17
19
21
Years educated
Mean
2.5%
97.5%
Figure 6.1
Smooth education effect for professional jobs
214
MODELS FOR MULTICATEGORY OUTCOMES

linear effects MNL so the DIC is slightly worse at 890. Plots of the effects
of education years on allocation to professional, white-collar and blue-
collar jobs suggest non-linear effects. The posterior means Sðxi3Þ and
their 95% intervals are in Figures 6.1 to 6.3.
−12
−7
−2
3
8
13
18
5
7
9
11
13
15
17
19
21
Years educated
Mean
2.5%
97.5%
Figure 6.2
Smooth education effect for white-collar jobs
−8
−6
−4
−2
0
2
4
6
8
10
5                7
9
11
13
15
17
19
Years educated
Mean
2.5%
97.5%
Figure 6.3
Smooth education effect for blue-collar jobs
NON-LINEAR PREDICTOR EFFECTS
215

6.6
HETEROGENEITY VIA THE MIXED LOGIT
As mentioned above, there may be heterogeneity in the impact of pre-
dictors and interdependent choices, and discrete or continuous mixture
models may be applied to model such effects. The mixed MNL model is an
extension of the MNL model that includes heterogeneity between subjects.
Such heterogeneity may represent variation in tastes and valuations (in
consumer applications) or risk aversion (in mobility applications), or
ambivalence (in voting or attitudinal applications). There may also be
unobserved aspects of utility for alternative choices (Glasgow, 2001).
In the mixed MNL model, heterogeneity is deﬁned in terms of random
effects for certain regression coefﬁcients or for intercepts. Variation in
regression effects between subjects may in theory apply to intercepts and
all predictors, but such a model is likely to strain identiﬁability and
instead heterogeneity is conﬁned to a subset of predictors that may
include the intercept. Consider the MNL with likelihood
yi  Mð1; iÞ
where yi ¼ ðyi1; yi2; . . . ; yiJÞ; i ¼ ði1; i2; . . . ; iJÞ and
ij ¼ expðXij þ CijÞ=
X
K
k¼1
expðXik þ CijÞ
Suppose now that random variability is introduced in one or more
coefﬁcients. For example, this might be in the coefﬁcient m for a
predictor Cmij, such that for subjects i
Uij ¼ 
ij þ !ij ¼ Xij þ C1ij1 þ    þ Cmijim þ    þ !ij
ð6:9aÞ
where the heterogeneity model itself potentially includes systematic as
well as random elements
im ¼ m þ 
mHi þ "im
ð6:9bÞ
The Hi are known subject attributes that may be relevant to explaining
heterogeneity in the coefﬁcients im.
For coefﬁcients that are not choice speciﬁc "im may be a univariate
density. Multivariate densities on " might apply if, say, coefﬁcients m
and k on two of the predictors C were subject to random variation, or if
certain jm were to vary randomly. While normal priors for variability in
the regression deviations im are possible, they may allow infeasibly large
deviations from the average coefﬁcient m and other options may be substan-
tively preferable. For example, Glasgow (2001) considers heterogeneity
in the impact of union membership on voting in the 1992 US presidential
216
MODELS FOR MULTICATEGORY OUTCOMES

election, and suggests triangular densities that are zero beyond end points
½m  a; m þ a and descend linearly to a peak at m.
Consider an example for coefﬁcients that vary over choices (such as the
intercept). Suppose J ¼ 4 and there is heterogeneity (taken to be normal)
in the intercepts; then for j ¼ 1; 3

ij ¼ 0j þ Xij þ Cij þ uij
ð6:10aÞ
where ui ¼ fui1; ui2; ui3g is MVN with mean 0 and covariance matrix ,
while for j ¼ 4

i4 ¼ Ci4
ð6:10bÞ
Note that instead of adopting a full multivariate error model one might
assume Q < J  1 factors and model the correlations between the ui in
terms of factor loadings; this may be more tractable, i.e. less subject to
identiﬁability problems (McFadden and Train, 2002). Thus for Q ¼ 1,
(6.10) becomes

ij ¼ 0j þ Xij þ Cij þ jui
j ¼ 1; 2; 3

i4 ¼ Ci4
where ui has a set scale (e.g. ui  Nð0; 1Þ.
Example 6.5
Travel mode choice
This data set consists of mode
choice observations ( j ¼ 1; . . . ; 4 and respectively air, train, bus, car) for
travel between Sydney and Melbourne. For 210 subjects, there is a single
chooser attribute (household income Xi1) and two choice attributes that
are subject speciﬁc. These are C1ij for generalized cost (GC) of travel
mode j for subject i, derived by considering in-vehicle cost and a wage
measure times time travelled; and C2ij for terminal time (TT), which is
zero for cars by deﬁnition (i.e. C2i4 ¼ 0). Greene (2000) considers a
utility function in which the dependence of air travel choice on household
income is compared with all other modes together, so that

i1 ¼ 01 þ Xi111 þ C1i11 þ C2i12

i2 ¼ 02 þ C1i21 þ C2i22

i3 ¼ 03 þ C1i31 þ C2i32

i4 ¼ C1i41
where 04 ¼ 0 for identiﬁability.2 By contrast, the Chen and Kuo (2002)
model for these data compares the impact of household income for
2 An alternative scheme deﬁnes intercepts 1; 2; 3; 4 for all J ¼ 4 choices but imposes the
constraint P j ¼ 0 (i.e. three effective parameters).
HETEROGENEITY VIA THE MIXED LOGIT
217

air travel against the car option, train against car, and bus against car, so
that

i1 ¼ 01 þ Xi11 þ C1i11 þ C2i12

i2 ¼ 02 þ Xi112 þ C1i21 þ C2i22

i3 ¼ 03 þ Xi113 þ C1i31 þ C2i32

i4 ¼ C1i41
A simple conditional logit model for the latter speciﬁcation, conforming
to the possibly unrealistic IIA assumption, is ﬁtted using Code A in
Program 6.5. A two-chain run, using null start values and values from a
trial run, shows early convergence (at around 500 iterations in a run of
2500). The DIC for this model, with a known total of eight parameters, is
395, and the regression parameter estimates show that lower income
households are signiﬁcantly more likely to choose train travel (mean
11 ¼ 0:059 with s:d: ¼ 0:013Þ. Such households are also more likely
to choose bus travel (with 13 ¼ 0:030, s:d: ¼ 0:014). Increased gen-
eralized cost and terminal time for a mode are associated with reduced
chances
of
selecting
that
mode,
with
1 ¼ 0:011
(0.004)
and
2 ¼ 0:099 (0.011).
Next, two types of mixed logit model are considered. One considers
random intercept variation with the model

i1 ¼ bi1 þ Xi111 þ C1i11 þ C2i12

i2 ¼ bi2 þ Xi112 þ C1i21 þ C2i22

i3 ¼ bi3 þ Xi113 þ C1i31 þ C2i32

i4 ¼ C1i41
where bi ¼ fbi1; bi2; bi3g is taken as MVN with means f01; 02; 03g.
The matrix partition method (equation 6.8) is used to estimate the
covariance among the bij, with bi1  Nð01; 1Þ. To improve identiﬁability,
priors for 0j and 1j are based on the posterior means and standard
deviations of the baseline categorical logit model, but with downweight-
ing of precision by 100. A two-chain run of 50 000 iterations shows
convergence after 25 000 iterations and similar results on the impacts of
the GC and TT variables to the baseline categorical logit model. It also
suggests slightly greater variability in bij for airline passengers, with
1 ¼ 1 against 2 ¼ 0:9 and 3 ¼ 0:7. The DIC suggests that this model
provides no marked gain over the simple conditional logit – the mean
deviance improves (344 vs. 387) but the effective parameter count is
around 53 compared with 8 under the simple model, so the DIC remains
218
MODELS FOR MULTICATEGORY OUTCOMES

around 395. The two ! parameters in (6.8) are not well identiﬁed,
suggesting that bi2 and bi3 could be taken as independent.
By contrast a mixed logit model with varying individual coefﬁcients
on the GC and TT variables, as in (6.9), shows a clear gain in ﬁt.
Independent normal priors are assumed on i1 and i2, speciﬁcally
i1  Nð1; 1) and i2  Nð2; 2Þ. Priors for 1 and 2 are based on
the posterior means and standard deviations of the baseline categorical
logit model, but with downweighting of precision by 100; speciﬁcally
1  Nð0:011; 0:002Þ; 2  ð0:1; 0:01Þ
Gamma Gðaj; 1Þ priors are assumed for 1=j with parameters aj taken to
have an approximately uniform prior, namely aj  Gð1; 0:001Þ.
A two-chain run of 10 000 iterations shows convergence after 5000 itera-
tions and an enhanced central effect for both general cost and terminal time,
with 1 and 2 having respective means 0.043 (s:d: ¼ 0:013) and 0.30
(0.05). Variability in the travel time effect is greater than that in the cost
effect (1 ¼ 0:006 vs. 2 ¼ 0:14). Note that results for this model may be
sensitive to the priors adopted, with less informative priors on j leading to
greater departure from the homogeneous effects logistic. The DIC is consi-
derably reduced compared with the varying intercept model, to around 230.
For the MNP applied to these data, a Cholesky decomposition prior is
used with an N(0,1) prior for the elements of h ¼ ½h21; log h22; h31;
h32; log h33]. A two-chain run of 5000 iterations shows convergence
from 2500 iterations. The DIC improves on the MNL model standing at
295 (with 18 effective parameters). As for the MNL models, lower
income households are more likely to choose train travel (the mean of 12
is 0.035 with s.d. 0.012). However, the income effect on bus travel is no
longer apparent. Again increased generalized cost and terminal time
reduce chances of selecting a mode: thus 1 ¼ 0:0066 (with s:d: ¼
0:002) and 2 ¼ 0:047 (s:d: ¼ 0:008). The largest correlation is 0.45
between air and bus, but is not signiﬁcant in the sense of its 95% interval
being conﬁned to negative values. The standard deviation (square root of
diagonal element of ) for bus is slightly lower (0.79) than for train
(1.17) and air (1 by default).
6.7
AGGREGATE MULTICATEGORY DATA: THE
MULTINOMIAL–DIRICHLET MODEL AND EXTENSIONS
Consider again the problem of analysing aggregated multinomial data
rather than individual choice or allocation data. Often administrative data
AGGREGATE MULTICATEGORY DATA
219

may be in this form for conﬁdentiality reasons, while large-scale national
data (e.g. distributions between income or demographic groups) can only
be analysed by aggregating over individuals. Analysis techniques for
multinomial discrete observations, such as electoral data (votes by party)
or religious afﬁliation data, may overlap with those for purely composi-
tional data (namely vectors of proportions describing the composition of
the whole in terms of J components). Examples of the latter type of data
include composition of river water by source (Soulsby et al., 2003) and
species composition data (Billheimer et al., 2001).
Let fij denote the total counts of observations in units i ¼ 1; . . . ; I
which may belong to one of j ¼ 1; . . . ; J categories, ranked or unranked.
Examples of unranked category data include multiparty electoral data
(Katz and King, 1999), while ranked data examples include job satisfac-
tion category j by income group i (Chen et al., 2000), or housing
satisfaction in survey neighbourhoods (Wilson, 1989). The conjugate
multinomial–Dirichlet model for such data may be inﬂexible in terms of
modelling correlations between categories and may be modiﬁed in
several ways. Possibilities include modelling the Dirichlet hyperpara-
meters (e.g. in terms of predictors or higher stage priors), specifying
mixture densities on transformations of the probabilities ij, or adopting
compositional analysis techniques (e.g. converting J proportions to J  1
odds ratios).
Let Ni ¼ P
j fij denote the total observations for unit i. A baseline
model for the data fi ¼ ffi1; . . . ; fiJÞ assumes they are independent
multinomial distributions of dimension J
fi  MJðNi; iÞ
where the probability parameter vectors i ¼ ði1; . . . ; iJÞ0 model the
relative frequencies in each unit subject to iJ ¼ 1  PJ1
j¼1 ij. The
conjugate model involves Dirichlet priors on each of the I sets of
probabilities. Thus for unit i
Pðfi1; fi2; . . . ; fiJ j iÞ ¼
Ni!
fi1!fi2! . . . fiJ!  fi1
i1  fi2
i2 . . .  fiJ
iJ
i  Dirði1; i2; . . . ; iJÞ
where default values such as ij ¼ 1 or ij ¼ 0 for all i and j are often
used. This will yield a Dirichlet posterior for i with means
Pij ¼ Eðij j fiÞ ¼
ij þ fij
P
jðij þ fijÞ
220
MODELS FOR MULTICATEGORY OUTCOMES

variances Vðij j fiÞ ¼ Pijð1  PijÞ=½1 þ P
jðij þ fijÞ and covariances
Covðij; ik j fiÞ ¼ PijPik=½1 þ P
jðij þ fijÞ.
6.8
MULTINOMIAL EXTRA VARIATION
Often extra variation occurs relative to this baseline model, owing for
instance to clustering of high rates in certain observations i on some of
the J options. Overdispersion may be expressed in terms of a scaled
covariance matrix under a model with predictions of fij given by ij ¼
ijNi. Writing i ¼ diagðijÞ as a J  J diagonal matrix, the covariance
matrix for fi ¼ ðfi1; fi2; . . . ; fiJÞ0 is
E½ð fi  iÞð fi  iÞ0 ¼ i i  i0
i


where  ¼ 1 for multinomial data and  > 1 for overdispersion. The
factor  may be estimated by calculating the usual Pearson chi square
between fij and ij and dividing by the degrees of freedom (McCullagh
and Nelder, 1989, p 175; Mebane and Sekhon, 2004). As noted above, an
alternative view of the multinomial is as the joint density of ffi1; . . . ; fiJg,
given that the total count P
j fij ¼ Ni in cluster i is Poisson, with para-
meters ij ¼ ij=i. Overdispersion will be apparent when VarðNiÞ >
EðNiÞ.
For example, in research on different types of road accident at
different monitoring sites (Bolduc and Bonin, 1998), J ¼ 3 categories
were distinguished according to day of the week (Example 6.6). There
may be subsets of sites with sufﬁciently high weekend rates (both
temporal and spatial clustering may also be involved) such as to
invalidate the multinomial assumptions. In data of this type there
may also be extra variation because some sites have unusually high
overall totals Ni.
In cases such as the latter where Ni is not preset, one might allow
variability in the overall rate i (e.g. using a gamma density to represent
variability in the Poisson rate), and adopt simpliﬁed models for the
multinomial choice or allocation probabilities. For instance, if the
allocation probabilities ij are taken as equal for all sites in the accident
application above, the rate ij for accident type j at site i is modelled as
the product ij.
Whether the Ni are taken as given or themselves taken as stochastic,
there may, however, be heterogeneity over subjects in the allocation
probabilities. One way to model heterogeneity in the ij is in terms of the
MULTINOMIAL EXTRA VARIATION
221

multiple logit link. Thus let 
ij be deﬁned by
ij ¼ expð
ijÞ=
X
k
expð
ikÞ
ð6:11Þ
One might take the 
ij to follow a hyperdensity that aims for ‘global
smoothing’ towards the population-wide proportions j across sites.
Leonard and Hsu (1994) propose an MVN model for the 
ij with mean
 ¼ ð1; 2; . . . ; J) and covariance matrix 
 of dimension J. A sum to
zero constraint on the j is needed for identiﬁcation (see Example 6.6).
Heterogeneity across sites in the ij may also involve expressing the 
ij in
regression terms, using predictors speciﬁc to subject i, choice j, or both.
For example, in the accident analysis example, certain sites may be closer
to weekend sports or entertainment venues, where speciﬁc dates for
events during the year generate extra variation.
A compositional model appropriate for relatively large samples in each
category involves taking logs of percentage ratios to a reference category
(such as the Jth), so that
rij ¼ logðfij=fiJÞ
¼ logðpij=piJÞ
j ¼ 1; . . . ; J  1
where pij ¼ fij= P
j fij. Then the J  1 dimensional data ri ¼ ðri1,
ri2; . . . ; ri;J1Þ are modelled via a multivariate form such as the MVN
or multivariate t (Aitchison, 1986), e.g.
ri  NJ1ði; Þ
where
ij ¼ jXij
and Xij is a vector of predictors speciﬁc to clusters and choices (e.g.
constituencies and parties). The original pij are obtained from
pij ¼ expðrijÞ= 1 þ
X
J1
j¼1
expðrijÞ
"
#
Like the Leonard and Hsu model this allows a ﬂexible covariance struc-
ture between categories, but assumptions (e.g. of multivariate normality)
may not be applicable to real-life data. Katz and King (1999) discuss
sources of non-normality in voting composition data and propose as a
robust alternative an additive logistic Student distribution for rij. This
222
MODELS FOR MULTICATEGORY OUTCOMES

may be attained by scale mixing as well as by formally taking
ri  TJ1ði; ; 	Þ
6.8.1
Uncertainty in Dirichlet parameters
An alternative way to model heterogeneity in the ij is to allow for
uncertainty in Dirichlet hyperparameters  ¼ ð1; 2; . . . ; JÞ rather than
take them as known (e.g. as in an assumption j ¼ 1 for all j). This leads
to the multinomial version of the beta–binomial model for binomial extra
variation. Thus one may assume
fi j i  MJðNi; iÞ
i j   Dirð1; 2; . . . ; JÞ
j  Gðaj; bjÞ
ð6:12Þ
with faj; bjg known. A prior on log(j) might also be used. Posterior
probabilities of higher or lower than average rates j ¼ j= P
j j of each
type of outcome can then be estimated by counting iterations:
Hij ¼ Prðij > jÞ ¼
X
T
t¼1
1ððtÞ
ij > ðtÞ
j Þ=T
ð6:13Þ
The Dirichlet prior on i in (6.12) may be implemented indirectly using a
set of gamma priors (see Gelman et al., 1995, p 482; also Example 6.6).
Thus for sampled values of 1; 2; . . . ; J, sample  ij  Gaðj; 1Þ and
then obtain ij as ij ¼  ij= P
j  ij.
Nandram (1998) proposes the form
j ¼ j
ð6:14Þ
where  ¼ ð1; 2; . . . ; JÞ and P j ¼ 1 represent the population-wide
category proportions. The jth component of j then has prior mean j and
variance
jð  jÞ=½2ð1 þ Þ ¼ jð1  jÞ=ð þ 1Þ
where P j ¼  is the total prior sample size. At the higher stage one
may assume
  DirichletðRÞ
where the components of R ¼ ðR1 . . . RJÞ are taken to be known. The
sample size parameter may take a gamma prior
  Gammaðt1; t2Þ
MULTINOMIAL EXTRA VARIATION
223

where t1 and t2 are taken as known (e.g. t1 ¼ 1; t2 ¼ 0:001Þ. In the
absence of subject matter or elicited knowledge regarding the Rj, a
default such as R1 ¼ R2 ¼    ¼ RJ ¼ 1 may be taken.
One might, subject to identiﬁability, allow variation over observation
units i in the Dirichlet parameters. For example, one might take
i  Dirði1; i2; . . . ; ijÞ
logðijÞ ¼ jxij þ uij
i ¼ 1; . . . ; I; j ¼ 1; . . . ; J  1
and consider multivariate unstructured priors (e.g. MVN) or structured
priors for the uij. For spatial data, structured priors might allow spatial
correlation parameters j for each outcome (Bolduc and Bonin, 1998).
This approach resembles the Leonard–Hu model but retains the multi-
nomial–Dirichlet structure. Alternatively
i  Dirði1; i2; . . . ; iJÞ
ij ¼ expðjxij þ uijÞ= 1 þ
X
J1
j
expðjxij þ uijÞ
"
#
j < J
ij ¼ 1= 1 þ
X
J1
j
expðjxij þ uijÞ
"
#
ð6:15Þ
with  as in (6.14).
Example 6.6
Quebec accident data
Bolduc and Bonin (1998) pre-
sent accident totals for 90 intersection sites in Quebec for 1990–1993.
Three types of accident are deﬁned: accidents on Monday–Wednesday,
accidents on Thursday or Friday, and weekend accidents. We ﬁrst
consider a ﬁxed effects model with no pooling to global proportions or
model for dispersion:
fi j i  MJðNi; iÞ
i j i  Dirði1; i2; . . . ; iJÞ
with ij ¼ 1 preset. This yields a deviance at  ¼ ðÞ of 582 but has 185
parameters (DIC ¼ 953), approximately equal to the number, i.e. 180, of
free proportion parameters i. The predictions from this model are too
overdispersed with Prð2
new > 2
obsÞ ¼ 1, where 2 is the usual Pearson
statistic. A model as in (6.12) with three population-wide proportions to
be
estimated
yields
DevðÞ ¼ 756,
where
 ¼ ð; Þ
and
 ¼
ð0:45; 0:34; 0:21Þ. The parameter count is much reduced and the pena-
lized ﬁt improves despite the poorer ﬁt at  (pe ¼ 31; DIC ¼ 818). The
predictive
checks
from
this
model
are
more
satisfactory
with
224
MODELS FOR MULTICATEGORY OUTCOMES

Prð2
new > 2
obsÞ ¼ 0:22, but suggest the model for heterogeneity could be
improved.
By contrast the multiple logit model (6.11) with MVN effects 
ij
generates more overdispersion than is consistent with the data, with
Prð2
new > 2
obsÞ ¼ 0:88. For this model pe ¼ 83 and DIC ¼ 826. The
correlations obtained from 
 show that accident rates for Monday–
Wednesday and for Thursday–Friday are positively correlated at 0.60
(95% interval 0.10 to 0.92).
The reparameterized Dirichlet model of (6.14) shows a closer consis-
tency with the actual overdispersion with Pr(2
new > 2
obsÞ ¼ 0:36. The
DIC of 809 (pe ¼ 31) shows a parsimonious ﬁt. Using the Hij statistics in
(6.13) one ﬁnds much higher than average weekend accident rates at sites
15 and 22 but low weekend rates at site 9. Finally a model for ij, namely
ij ¼ ij
as in (6.15), is then applied, with a regression using intercepts only
ij ¼ expðc
j Þ=
X
J
j
expðc
j Þ
with ij following the parameterization (6.2c). A two-chain run of 25 000
iterations produces a DIC of 813.5 (pe ¼ 39Þ, a satisfactory check against
the actual overdispersion with Prð2
new > 2
obsÞ ¼ 0:38, and a mean for 
of 77. Ideally, however, such a model would involve predictors or, for
area clusters, a spatial interaction structure.
Example 6.7
Incumbency advantage
Katz and King (1999) consider
data from the 1997 UK election, namely proportions (for 526 English
constituencies) voting Labour, Conservative or Liberal. These are con-
verted to a 526  2 matrix of log odds ratios with the Liberal proportions
as denominator, so that
rij ¼ logðpij=piJÞ
j ¼ 1; . . . ; J  1
where J ¼ 3. The analysis investigates the beneﬁts of incumbency on
voting proportions: x1 and x2 are lagged values from the 1992 election of
the two log odds ratios, while x3 ¼ 1, x4 ¼ 1 and x5 ¼ 1 according as the
Conservative, Labour or Liberal candidate is the incumbent. The regres-
sion parameters are speciﬁc to the Conservative and Labour Parties so
there are 12 regression parameters in all.
Since the log odds ratio data appear heavy tailed relative to the normal,
Katz and King adopt a multivariate t distribution with unknown degrees
of freedom. As a baseline, the ﬁrst analysis here uses an MVN prior. To
MULTINOMIAL EXTRA VARIATION
225

assess how far overdispersion in the data is reproduced, chi-square
statistics over constituencies i and parties j are then calculated comparing
(a) observed voting totals (i ¼ 1; . . . ; 526, j ¼ 1; . . . ; 3) with voting totals
predicted by the model and (b) replicate voting totals (new data sampled
from the model parameters) with the model predictions. A two-chain run
of 1000 iterations shows early convergence. The model appears to
generate predictions that are rather overdispersed relative to the observa-
tions: the posterior predictive check p value is 0.98. The incumbency
effect for Conservative candidates, namely the coefﬁcient of x3 on ri1,
with mean 0.075 (95% interval 0.015 to 0.17), is weaker than that for
Labour candidates. Thus the coefﬁcient of x4 on ri2 has mean 0.13
(0.03, 0.22).
A multivariate T model (MVT) model improves the predictive check
slightly, but suggests scope for other modelling approaches: the p value is
now just under 0.9. One feature of the MVT model is the reduced
incumbency effect for Labour candidates. The mean value of 	, the
degrees of freedom, i.e. 7 with 95% interval (5.4,9.2), supports the need
for a heavy-tailed model.
6.9
LATENT CLASS ANALYSIS
The other major approach to heterogeneity and overdispersed categorical
data involves discrete mixture regression using the observed multinomial
outcomes. This involves modifying the framework of section 5.3 to
multinomial responses. Here we focus on a discrete mixture framework
where the multinomial outcome is not observed. Latent class analysis is a
particular form of discrete mixture model applied where a set of observed
categorical or binary indicators X are taken to be imperfect measures of
an underlying latent category variable G, or possibly of more than one
latent categorization.
There may be a substantive basis for assuming the latent class variable
is categorical, as in staging applications in psychological development
studies. In medical or psychometric settings the X are typically a set of
categorical symptom or diagnosis ratings. In this situation, there is often
no gold standard way of classifying individuals, but instead a number of
observed diagnostic measures subject to misclassiﬁcation, and the goal is
to identify the number of true diseased subjects. Thus in about a third of
evaluation studies of medical diagnostic tests, there is no clear gold
standard or reference test (Sheps and Schechter, 1984). In recent exten-
sions of latent class models it is proposed that a continuous scale be
envisaged underlying the latent category (Uebersax, 1999).
226
MODELS FOR MULTICATEGORY OUTCOMES

The most common model assumes that the interaction between the p
manifest variables is explicable by a smaller set of latent categorical
variables, such that given the level on the latent variable or variables, the
manifest variables are independent (the conditional independence
assumption). The most frequent applications assume either several
(though fewer than p) binary latent categorical variables, or a single
latent variable with several levels.
Assume p binary items are observed and that there is a single latent
variable with C categories (C 	 2) which in a medical application might
be latent diagnosis or morbidity. The parameters of a latent class model in
this setting are the allocation probabilities 1; . . . ; C of belonging to the
different categories of the latent variable, and the item probabilities of a
positive response ic to the ith item (c ¼ 1; . . . ; C; i ¼ 1; . . . ; p) for
someone allocated to the cth category of the latent variable. Suppose
the latent variable has C ¼ 3 categories. Then latent class analysis (LCA)
under conditional independence implies the following:
1 þ 2 þ 3 ¼ 1
Pi ¼ 1i1 þ 2i2 þ 3i3
i ¼ 1; . . . ; p
Pij ¼ 1i1j1 þ 2i2j2 þ 3i3j3
i; j ¼ 1; . . . ; p
Pijk ¼ 1i1j1k1 þ 2i2j2k2 þ 3i3j3k3
i; j; k ¼ 1; . . . ; p
where Pi is the probability of a positive response to item i, Pij is the joint
probability of a positive response to both items i and j, etc.
Example 6.8
Antisocial behaviour
Muthe´n and Muthe´n (2000) pre-
sent a latent class analysis of 17 binary indicators of antisocial behaviour
(ASB) among American youth, using data from the National Long-
itudinal Survey of Youth and administered in 1980. Their analysis relates
to 7326 subjects who provided complete response proﬁles on the 17
items. These items are all ‘positive’ indicators of ASB (whether or not the
behaviour occurred in the previous year) such as ﬁghting (1 ¼ yes), using
drugs (1 ¼ yes) and taking an auto (1 ¼ yes). The Muthe´n and Muthe´n
analysis adopted C ¼ 4 latent classes and shows a large ‘low ASB’ group
(with probability 0.47) with low item probabilities on all items, and a
small minority group (allocation probability 0.09) with high item prob-
abilities on most crimes and ASB. Two minority groups (probabilities
0.18 and 0.28 respectively) are characterized by drug use (but no item
probabilities exceeding 0.5) and by ﬁghting and threatening behaviour.
Here a 10% subsample of the original survey respondents is taken (n ¼
754) and an unconstrained trial run of 1000 iterations (a 100 burn-in) shows a
very similar pattern to that reported by Muthe´n and Muthe´n (Table 6.4).
LATENT CLASS ANALYSIS
227

Table 6.4
Item probabilities and allocation probabilities, trial and ﬁnal
estimates, antisocial behaviour data
Initial estimates
Class 1
Class 2
Class 3
Class 4
Property
0.05
0.30
0.27
0.92
Fighting
0.13
0.65
0.31
0.86
Shoplifting
0.10
0.32
0.51
0.79
Stole (under $50)
0.08
0.24
0.38
0.77
Stole (over $50)
0.01
0.08
0.05
0.47
Use of force
0.02
0.16
0.06
0.27
Threatening behaviour
0.17
0.91
0.44
0.77
Intent to injure
0.00
0.30
0.15
0.46
Took pot
0.29
0.42
0.94
0.90
Took other drug
0.07
0.03
0.56
0.65
Sold pot
0.01
0.02
0.29
0.58
Sold other drug
0.00
0.01
0.03
0.24
Conﬁdence trick
0.14
0.37
0.35
0.61
Took auto
0.03
0.15
0.21
0.43
Broke into building
0.00
0.04
0.09
0.49
Held stolen goods
0.02
0.12
0.15
0.65
Gambling
0.01
0.02
0.03
0.25
Allocation probabilities
0.58
0.16
0.19
0.07
Final estimates (two chains)
Property
0.05
0.30
0.25
0.92
Fighting
0.12
0.64
0.30
0.85
Shoplifting
0.10
0.30
0.49
0.80
Stole (under $50)
0.08
0.24
0.37
0.76
Stole (over $50)
0.01
0.07
0.04
0.46
Use of force
0.02
0.16
0.05
0.26
Threatening behaviour
0.16
0.90
0.43
0.77
Intent to injure
0.00
0.28
0.15
0.45
Took pot
0.29
0.41
0.93
0.90
Took other drug
0.06
0.03
0.55
0.64
Sold pot
0.00
0.02
0.27
0.57
Sold other drug
0.00
0.01
0.03
0.23
Conﬁdence trick
0.14
0.37
0.34
0.61
Took auto
0.03
0.15
0.20
0.42
Broke into building
0.00
0.04
0.09
0.47
Held stolen goods
0.02
0.11
0.14
0.64
Gambling
0.01
0.02
0.03
0.23
Allocation probabilities
0.56
0.17
0.20
0.07
228
MODELS FOR MULTICATEGORY OUTCOMES

However, inferences from an LCA applied to this data set are subject to
identiﬁability issues around consistent labelling of the latent classes
through a large number of iterations. It is possible by chance that a
unique labelling (with no switching) is obtained, typically in a relatively
short single chain. However, in multiple chain sampling it is more than
likely that different labelling schemes will emerge between one chain and
another.
In the present situation the results of Muthe´n and Muthe´n (based on an
EM method) suggest a clear high-probability group (group 1 in Table 6.4)
and a low-probability group (group 4 in Table 6.4), and an identiﬁability
constraint on 1 and 4 is applicable to reproduce this feature, involving
constraints 1 > maxð2; 3Þ and 4 < minð2; 3Þ. However, the two
other groups are similar in relative frequency and are identiﬁable in terms
of their item probability proﬁle, rather than the size of 2 versus 3.
Table 6.4 shows that the third group has a much higher item probability on
cannabis use and so an identiﬁability constraint that 93 > 92 may be
imposed.
The standard Dirichlet may be used for suitably constrained sampling
of the c in this problem but there are other ways. One takes a series of
gamma priors, such as
1  Gð1; 0:001ÞIðh; Þ
h ¼ maxð2; 3Þ
2  Gð1; 0:001ÞIð4; 1Þ
3  Gð1; 0:001ÞIð4; 1Þ
4  Gð1; 0:001Þ Ið; gÞ
g ¼ minð2; 3Þ
and then sets c ¼ c= P
c c. Another approach (the one used here) sets
normal priors on ’c with ’1 ¼ 0, and V assumed known (i.e. V ¼ 1),
’2  Nð0; VÞIð’4; ’1Þ
’3  Nð0; VÞIð’4; ’1Þ
’4  Nð0; VÞIð; ’gÞ
’g ¼ minð’2; ’3Þ
and then takes c ¼ expð’cÞ, and c ¼ c= P
c c.
Unconstrained sampling is used for the second and third groups but an
identiﬁability check, i.e. whether 93 > 92, is applied. This is an alter-
native to a more rigorous cluster analysis procedure such as that of
LATENT CLASS ANALYSIS
229

Celeux et al. (2000), and will be suitable if the constraint holds (i.e. there
is no label switching) within a long sampling run.
In a two-chain run of 5000 iterations we ﬁnd the ﬁrst set of initial
values leads to an opposite labelling of groups 2 and 3 than the second set
of initial values. After the ﬁrst 50 iterations both chains are internally
stable with regard to their labelling schemes (using the check whether
93 > 92 just mentioned). So a consistent labelling over the two chains is
achieved just by relabelling the output from one chain (i.e. relabelling
group 2 to 3 and vice versa). Had there been label switching within either of
the two chains then the full procedure of Celeux et al. would be necessary.
The ﬁnal set of estimates in Table 6.4 shows a ‘low ASB’ group (with
probability 0.56) with low item probabilities on all items, violent and
drug use groups, and a ‘high ASB’ group with probability 0.07.
EXERCISES
1. In Example 6.1 use the data with education and experience grouped
into ﬁve and seven categories (rather than in continuous form) and
estimate the MNL model with data in this form using a multinomial
likelihood as opposed to Poisson log-linear regression. Use the Albert
(1996) method (see section 4.5) to compare this ‘main effects only’
log-linear model with one including interactions between ethnicity and
education subject to a hierarchical mixture prior. How does the ﬁt
compare using the DIC and a predictive loss criterion based on
sampling replicate counts Yijkl (i denotes ethnicity, j denotes education,
k denotes experience, l denotes occupation)?
2. In Example 6.1 apply the exponential sampling model of Scott (2003)
to generate latent data Wij (i subjects, j occupations) underlying the
MNL choice model.
3. Try ﬁtting the analysis in Example 6.2 using a Poisson regression with
dummy ﬁxed effects parameters for schools.
4. In Example 6.2 ﬁt the model via a multinomial likelihood but with
scale mixing, namely
i  NJð; =iÞ
where i  Ga(	/2, 	/2) with 	 unknown. Can outliers be identiﬁed?
5. In Example 6.4 try a cubic penalized spline for the effect of years of
education. Compare its ﬁt with that of a conventional MNL with linear
regression effects for all predictors.
230
MODELS FOR MULTICATEGORY OUTCOMES

6. In Example 6.5 try the random intercept version of the mixed logit
using a factor model (Q ¼ 1). Does this improve in ﬁt over the
baseline conditional logit model?
7. In Example 6.7 try a two-group discrete mixture models
ri  NJ1 iGi; Gi
ð
Þ
where Gi is the latent group for constituency i and both the dispersion
g and the regression model differ by group
ijg ¼ jgXij
Assess how well this model represents overdispersion.
REFERENCES
Abe, M. (1999) A generalized additive model for discrete-choice data. Journal of
Business and Economic Statistics, 17, 271–284.
Aitchison, J. (1986) The Statistical Analysis of Compositional Data. Chapman
and Hall: London.
Albert, J. (1996) Bayesian selection of log-linear models. Canadian Journal of
Statistics, 24, 327–347.
Albert, J. and Chib, S. (1993) Bayesian analysis of binary and polychotomous
response data. Journal of the American Statistical Association, 88, 669–679.
Billheimer, D., Guttorp, P. and Fagan, W. (2001) Statistical interpretation of
species composition. Journal of the American Statistical Association, 96,
1205–1214.
Bolduc, D. and Bonin, S. (1998) Bayesian analysis of road accidents: a general
framework for the multinomial case. Cahiers de Recherche 9802, Universite´
Laval – De´partement d’Economique.
Celeux, G., Hurn, M. and Robert, C. (2000) Computational and inferential
difﬁculties with mixture posterior distributions. Journal of the American
Statistical Association, 95, 957–970.
Chen, M., Ibrahim, J. and Shao, Q. (2000) Monte Carlo Methods in Bayesian
Computation. Springer: New York.
Chen, Z. and Kuo, L. (2002) Discrete choice models based on the scale mixtures
of multivariate Normal distributions. Sankhya, 64B, 192–213.
Chib, S., Greenberg, E. and Chen, Y. (1998) MCMC methods for ﬁtting and
comparing multinomial response models. Economics Working Paper Archive,
Econometrics, No. 9802001, Washington University of St Louis.
Daganzo, C. (1979) Multinomial Probit: The Theory and its Application to
Demand Forecasting. Academic Press: New York.
REFERENCES
231

Epstein, A. and Fienberg, S. (1991) Bayesian estimation in multidimensional
contingency tables. In Computer Science and Statistics: Proceedings of the
Twenty-Third Symposium on the Interface, Keramidas, E (ed), Interface
Foundation of North America: Fairfax, 37–47.
Gelman, A., Carlin, J., Stern, H. and Rubin, D. (1995) Bayesian Data Analysis.
Chapman and Hall: London.
Geweke, J., Keane, M. and Runkle, D. (1994) Alternative computational
approaches to inference in the multinomial probit model. Review of Economics
and Statistics, 76, 609–632.
Glasgow, G. (2001) Mixed logit models for multiparty elections. Political
Analysis, 9, 116–136.
Good, I. (1976) On the application of symmetric Dirichlet distributions and their
mixtures to contingency tables. Annals of Statistics, 4, 1159–1189.
Greene, W. (2000) Econometric Analysis, 4th edition, Prentice Hall: Englewood
Cliff, NJ.
Gunel, E. and Dickey, J. (1974) Bayes factors for independence in contingency
tables. Biometrika, 61, 545–557.
Hausman, J. and Wise, D. (1978) A conditional probit model for qualitative
choice: discrete decisions recognizing interdependence and heterogeneous
preferences. Econometrica, 48, 403–429.
Hensher, D. and Greene, W. (2001). The mixed logit model: the state of practice
and warnings for the unwary. Working Paper, School of Business, The
University of Sydney.
Hoffman, S. and Duncan, G. (1988) A comparison of choice-based multinomial
and nested logit models: the family structure and welfare use decisions of
divorced or separated women. Journal of Human Resources, 23, 550–562.
Katz, J. and King, E. (1999) A statistical model for multiparty electoral data.
American Political Science Review, 93, 15–32.
Keane, M. (1992) A note on identiﬁcation of the multinomial probit model.
Journal of Business and Economic Statistics, 10, 193–200.
Lahiri, K. and Gao, J. (2002) Bayesian analysis of nested logit model by Markov
chain Monte Carlo. Journal of Econometrics, 111, 103–133.
Lenk, P., DeSarbo, W., Green, P. and Young, M. (1996) Hierarchical Bayes
conjoint analysis: recovery of partworth heterogeneity from reduced experi-
mental designs. Marketing Science, 15, 173–191.
Leonard, T. and Hsu, J. (1994) The Bayesian analysis of categorical data – a
selective review. In Aspects of Uncertainty: A Tribute to DV Lindley, Freeman,
P. and Smith, A. (eds). John Wiley & Sons: New York.
Linardakis, M. and Dellaportas, P. (2003) Assessment of Athens’ metro passenger
behaviour via a multi-ranked probit model. Journal of the Royal Statistical
Society Series C, 52, 185–200.
Lindley, D. (1964) The Bayesian analysis of contingency tables. Annals of
Mathematical Statistics, 35, 1622–1643.
232
MODELS FOR MULTICATEGORY OUTCOMES

Long, J. (1997) Regression Models for Categorical and Limited Dependent
Variables. Sage: Thousand Oaks, CA.
McCullagh, P. and Nelder, J. (1989) Generalized Linear Models, 2nd edition.
Chapman and Hall: London.
McCulloch, R. and Rossi, P. (1994) An exact likelihood analysis of the multi-
nomial probit model. Journal of Econometrics, 64, 207–240.
McCulloch, R. and Rossi, P. (2000) Bayesian analysis of the multinomial
probit model. In Simulation-based Inference in Econometrics, Mariano,
R., Schuermann, T. and Weeks, M. (eds). Cambridge University Press:
Cambridge, 158–175.
McCulloch, R., Polson, N. and Rossi, P. (2000) A Bayesian analysis of the
multinomial probit model with fully identiﬁed parameters. Journal of Econo-
metrics, 99, 173–193.
McFadden, D. (1974) Conditional logit analysis of qualitative choice behavior. In
Frontiers in Econometrics, Zarembka, P. (ed.). Academic Press: New York,
105–142.
McFadden, D. and Train, K. (2002) Mixed MNL models for discrete response.
Journal of Applied Econometrics, 15, 447–470.
Mebane, W. and Sekhon, J. (2004) Robust estimation and outlier detection for
overdispersed multinomial models of count data. American Journal of Poli-
tical Science, 48, 391–410.
Muthe´n, B. and Muthe´n, L. (2000) Integrating person-centered and variable-
centered analyses: growth mixture modeling with latent trajectory classes.
Alcoholism, Clinical and Experimental Research, 24, 882–891.
Nandram, B. (1998) A Bayesian analysis of the three-stage hierarchical multi-
nomial model. Journal of Statistical Computation and Simulation, 61, 97–126.
Nobile, A. (1998) A hybrid Markov chain for the Bayesian analysis of the
multinomial probit model. Statistics and Computing, 8, 229–242.
Nobile, A., Bhat, C. and Pas, E. (1997) A random effects multinomial probit
model of car ownership choice. Case Studies in Bayesian Statistics 3, Gatsonis,
C., Hodges, J., Kass, R., McCulloch, R., Rossi, P. and Singpurwalla, N (eds).
Springer: New York, 419–434.
Rossi, P. and Allenby, G. (2003) Bayesian statistics and marketing. Marketing
Science, 22, 304–328.
Ruppert, D., Wand, M. and Carroll, R. (2003) Semiparametric Regression.
Cambridge University Press: Cambridge.
Scott, S. (2003) Data augmentation for the Bayesian analysis of multinomial logit
models. Proceedings of the ASA Section on Bayesian Statistical Science. ASA:
Alexandria, VA.
Sheps, S. and Schechter, M. (1984) The assessment of diagnostic tests. A survey
of current medical research. Journal of the American Medical Association,
252, 2418–2422.
Soulsby, C., Petry, J., Brewer, M., Dunn, S., Ott, B. and Malcolm, I. (2003)
Identifying and assessing uncertainty in hydrological pathways: a novel
REFERENCES
233

approach to end member mixing analysis in a Scottish agricultural catchment.
Journal of Hydrology, 274, 109–128.
Uebersax, J. (1999) Probit latent class analysis with dichotomous or ordered
category measures: conditional independence/dependence models. Applied
Psychological Measurement, 23, 283–297.
Wedel, M., Kamakura, W., Arora, N., Bemmaor, A., Chiang, J., Elrod, T.,
Johnson, R., Lenk, P., Neslin, S. and Poulsen, C. (1999) Discrete and
continuous representation of heterogeneity. Marketing Letters, 10, 217–230.
Wilson, J. (1989) Chi-square tests for overdispersion with multiparameter
estimates. Journal of the Royal Statistical Society, Series C, 38, 441–453.
Yu, P. (2000) Bayesian analysis of order statistics models for ranking data.
Psychometrika, 65, 281–299.
Zellner, A. and Rossi, P. (1984) Bayesian analysis of dichotomous quantal
response models. Journal of Econometrics, 25, 365–393.
234
MODELS FOR MULTICATEGORY OUTCOMES

CHAPTER 7
Ordinal Regression
7.1
ASPECTS AND ASSUMPTIONS OF
ORDINAL DATA MODELS
Data with ordinal dependent variables occur frequently in health surveys
and clinical settings (Cox, 1995), in econometric applications including
studies of income inequality (Chotikapanich and Grifﬁths, 2000), in
psychometric applications (e.g. rating scales) and in social surveys. Let
yi be an ordinal response variable for individuals i ¼ 1; . . . ; n and with
levels 1; 2; . . . ; J. Thus
yi  CategoricalðiÞ
where i ¼ ði1; i2; . . . ; iJÞ is the vector of model probabilities that
subject i will be located at level j. Since the outcome is ranked one may
consider cumulative probabilities conditional on regressors Xi, namely
ijðxiÞ ¼ Prðyi  jjXiÞ ¼ i1ðXiÞ þ i2ðXiÞ þ    þ ijðXiÞ
As for other probabilities ij may then be regressed on predictors via a
link function g ¼ F1 where typical forms of F include the cumulative
standard normal F ¼  or the logistic cdf
FðuÞ ¼ expðuÞ=½1 þ expðuÞ
A cumulative logit model with a linear predictor 
ij speciﬁes
logitðPrðyi  jjXiÞÞ ¼ logitðijðXiÞÞ ¼ j þ jXi ¼ j þ 
ij
ð7:1Þ
The logit and probit links in (7.1) are most common but another option is
the complementary log–log, with
log½ logð1  ijÞ ¼ j þ jxi
Bayesian Models for Categorical Data
P. Congdon
# 2005 John Wiley & Sons, Ltd

A frequent simplifying assumption is that the effect of predictors Xi is
constant across ordered categories j ¼ . If F is logistic and the
predictors are respondent characteristics only, then under this assumption,
the difference in cumulative logits between subjects i and k with
responses both in the jth category is Cij  Ckj where
Cij ¼ logitðijÞ ¼ j þ Xi
ð7:2Þ
The difference Cij  Ckj ¼ ðXi  XkÞ is independent of j, this being
known as the proportional odds property (McCullagh, 1980). By contrast
model (7.1) is a non-proportional model. The proportional odds model
may be estimated by a set of J  1 regressions, with J ¼ 1; 2; . . . ; J  1
Dij ¼ 1
if yi  J
Dij ¼ 0
if yi > J
Dij  BernðijÞ
with F1ðijÞ ¼ j þ Xi and J1 > J2 >    > 1. The most effec-
tive method involves estimating all J  1 regressions in one single all-
encompassing model since  is common to all models. One may apply
(7.1) or (7.2) with a negative sign before the , so that  may be
interpreted in terms of odds that increase with j (Simonoff, 2003, p 436).
If it is not assumed that all the j are equal (e.g. only some covariates
have differing regression coefﬁcients according to j) then a partial
proportional odds model is obtained (e.g. Peterson and Harrell, 1990).
A drawback with allowing j to be level speciﬁc is that the J  1 non-
parallel regression lines may cross when explanatory variables are conti-
nuous; this problem does not occur for categorical explanatory variables
(Gibbons and Hedeker, 2000). Further features of non-proportionality are
considered by Fahrmeier and Tutz (2001, section 3.3) and Ishwaran
(2001). A non-proportional or partial proportional model amounts to
making the thresholds depend on explanatory variables. Thus the partial
proportional model may be framed as
logit½ijðXi; WiÞ ¼ j þ jWi þ Xi
ð7:3Þ
where the Wi are denoted threshold predictor variables and the Xi denoted
(proportional) shift variables.
7.2
LATENT SCALE AND DATA AUGMENTATION
Following McCullagh (1980), the observed response y is often taken to
reﬂect an underlying continuous random variable y with J  1 thresholds
236
ORDINAL REGRESSION

or cut points. In medical diagnosis a latent disease severity is plausible
(Cox, 1995), though in some applications a latent variable may not be
appropriate. Agresti (2002) cites academic gradings (Assistant, Asso-
ciate and Full Professor) as an example where a latent scale seems dubi-
ous. Suppose yi denotes health status category as recorded by a health
survey (with J ¼ 5 levels, namely 1 ¼ very good, 2 ¼ good ; . . . ; 5 ¼
bad) then a latent ill-health on a continuous scale y
i may be envisaged,
deﬁned by cut points
1 ¼ 0 < 1 <    < J1 < J ¼ 1
The observed discrete responses are deﬁned according to the value of the
underlying metric response, with
yi ¼ 1
if  1 < y
i  1
yi ¼ 2
if 1 < y
i  2
yi ¼ 3
if 2 < y
i  3
yi ¼ 4
if 3 < y
i  4
yi ¼ 5
if 4 < y
i  1
If J  1 cut points are free parameters then identiﬁability requires that
the intercept be omitted from the regression term. However, if one of the
cut points is set to a value (e.g. 1 ¼ 0), or two cut points are equated,
then the intercept may be included. For instance, for p predictors and
J  1 free cut points 
ij ¼ j þ 1Xi1 þ 2Xi2 þ    þ pXip excluding an
intercept.
The cumulative odds under the latent response model is based on a cdf
of the form Fðy  
Þ where 
 is a regression mean such as 
 ¼ x
(Hastie and Tibshirani, 1987). The model for the latent continuous
scale y is
y
i  
i þ ei
ð7:4Þ
with the density of ei determined by the form of F. Since
yi ¼ j
if j1 < y  j
then
yi ¼ j
if j1  x < y  x  j  x
So for a proportional cumulative odds model with J  1 free cut points
it is assumed that
yi  CategoricalðiÞ
LATENT SCALE AND DATA AUGMENTATION
237

where i ¼ ði1; i2; . . . ; iJÞ and
i1 ¼ i1
ij ¼ ij  i; j1
j ¼ 2; . . . ; J  1
ij ¼ Prðyi  jÞ ¼ Fðj  
iÞ
j ¼ 1; . . . ; J  1

i ¼ 1Xi1 þ 2Xi2 þ    þ pXip
The probability of the highest rank is iJ ¼ 1  i;J1. If attributes of the
choices Cij and Aj (as in Chapter 6) are added then non-proportionality is
likely to exist.
Adopting a framework with an underlying scale envisaged does not
necessarily require that data augmentation be applied and the y values be
formally sampled. However, following Albert and Chib (1993) and
Johnson and Albert (1999), one may estimate the proportional logit or
probit model by constrained sampling of y. As for binary regression via
data augmentation, the problem is converted to a metric linear regression
with simpliﬁed Gibbs sampling and beneﬁts in terms of residual analysis.
The interval constraints for sampling a particular subject’s y
i are based
on that individual’s observed category (see Example 7.1). Thus if yi ¼ 1,
y would lie between 1 and 1. The cut points are sampled in a way
that takes account of the sampled y. Thus at iteration t
ðtÞ
j
 Nð0; VÞIðLj; UjÞ
j ¼ 1; . . . ; J  1
where V is preset and
Lj ¼ maxðyðtÞ; yi ¼ jÞ
Uj ¼ minðyðtÞ; yi ¼ j þ 1Þ
If F ¼  then ei in (7.4) will be standard normal and truncated normal
sampling of y applies. Scale mixing may be used for greater robustness
allowing an implicit mixing over links. Thus
y  NðX; iÞIðyi1; yiÞ
where i  Gað0:5	; 0:5	Þ and 	 is itself unknown. This includes an
approximation to the logistic (Albert and Chib, 1993). For F logistic,
direct sampling is also possible since the ei follow a standard logistic den-
sity. An asymmetric distribution for the latent variable might be appro-
priate in some applications (e.g. when the response is a grouped survival
time) and a complementary log–log link may be used: the ei then follow a
standard double-exponential density (extreme value) with variance 2=6.
Lang (1999) suggests a procedure for averaging over link functions in
ordinal regression, speciﬁcally mixing over the left-skewed extreme value
238
ORDINAL REGRESSION

(LSEV), the logistic and the right-skewed extreme value (RSEV); see
Example 7.2.
Some drawbacks of the augmented data approach for ordinal data have
been noted in recent papers (Ishwaran, 2000; Parmigiani et al., 2003), for
instance the addition of many extra parameters in large samples. Direct
analysis of the multinomial likelihood may be applied instead but also
has possible disadvantages. For example, there are J  1 residuals for
each multinomial observation under the direct likelihood approach in
contrast to the single residual y
i  Xi from the latent variable approach
(Johnson and Albert, 1999). Other types of residual may be used instead
(e.g. estimates of the conditional predictive ordinate based on average
inverse likelihoods). One may also sample new y
i values in a data
augmentation (DA) approach or new yi in a direct multinomial approach
and assess the resulting concordancy between predicted categorization of
subjects and their actual categories.
Note that identiﬁability under either approach may require informative
priors, e.g. on the j, especially when the numbers observed at each
ordinal category may be small and the data contain relatively little inform-
ation to estimate the cut points precisely. The DA approach may particu-
larly require informative priors for numeric stability as it involves doubly
constrained sampling: on the j themselves and the y
i also. One method
to increase stability is to increase numbers in each response category by
aggregating over outcome categories with sparse response levels. How-
ever, this may affect conclusions about predictors (Murad et al., 2003).
Since the j are expected to be broadly aligned to the discrete responses,
priors with a relatively low variance (e.g. 1 or 10) are justiﬁable. An alter-
native suggested by Ishwaran (2000) is a uniform density
0 ¼ 1  2      J1  U
where U is equal to or less than J. Sometimes the reparameterization of
Fahrmeier and Tutz (2001, section 3.3) is beneﬁcial; assuming 1 ¼ 0
then this parameterization is
2 ¼ expð’2Þ
j ¼ j1 þ
X
j
m¼3
expð’mÞ
ð7:5Þ
where the ’m are unconstrained. In Ishwaran (2000) the partial propor-
tional odds model in (7.3) is accordingly expressed as
logit½ijðXi; WiÞ ¼ Xi þ
X
j
m¼1
expð’m þ MWiÞ
LATENT SCALE AND DATA AUGMENTATION
239

where ’1 ¼ 1 (i.e. 1 ¼ 0) for identiﬁability when 
i ¼ Xi includes
an intercept.
Example 7.1
Statistics grades
Johnson and Albert (1999) present an
example for N ¼ 30 statistics students classiﬁed into ﬁve grades (Fail ¼ 1,
D grade ¼ 2, C grade ¼ 3, B grade ¼ 4, A grade ¼ 5) with predictor X ¼
SATM score. We compare the ﬁt of different links and assess residual
effects under direct sampling of the latent y. For an ordinal probit model
mildly informative priors are assumed for j to assure identiﬁcation. With
an overall intercept 0 retained (and assuming 1 ¼ 0) there are three free
cut points with assumed priors:
2  Nð1; 10ÞIð0; 3Þ
3  Nð2; 10ÞIð2; 4Þ
4  Nð3; 10ÞIð3; Þ
An N(0,10) prior on the effect of the SAT score is assumed for numerical
reasons, though one might alternatively scale the SAT score itself (e.g.
divide the score by 100).
The second half of a two-chain run of 10 000 iterations for the ordinal
probit model shows a coefﬁcient 1 ¼ 0:025 (posterior s:d: ¼ 0:006) on
the centred SAT score, close to the estimate obtained by Johnson and
Albert (1999, p 143). The estimated cut points 1.55, 2.44 and 3.79 com-
pare with their estimates of 1.29, 2.11 and 3.56. Large residuals y  X
(absolutely exceeding 1.96) are obtained for subject 1 (who failed despite
a SATM score of 557) with e1 ¼ 2:47, and subject 30 who got grade A
despite an average SATM score, with e30 ¼ 2:16. One may also sample
new y (without constraint), allocate them to a predicted category based
on their value relative to the cut points and compare the predicted with
the actual category. This leads to a total predictive concordancy (percen-
tage of students correctly classiﬁed) of 34.3. The lowest probability of
predicted category equalling actual category is for subject 1, namely
0.024, while subject 30 has a probability of 0.05.
Logistic and double-exponential densities are adapted as being poten-
tially more robust to sampled values in tails but the same priors as for the
ordinal probit are retained. Sampling from the standard logistic yields a
mean for 1 of 0.042 but with less precision (a posterior standard
deviation of 0.01). The predictive concordancy rises to 39.9%, with
subject 1 again the leading outlier. Outlying subjects are downweighted
and the probability of a correct match for subject 1 is now 0.002. Resi-
duals are now compared with the standard deviation of the standard
240
ORDINAL REGRESSION

logistic, namely =p3; the scaled residual for subject 1 is now 2.59.
Double-exponential sampling gives a very similar performance to the
other two links, with predictive concordancy of 38.3%. The residuals
y  X highlight cases 1 and 30, while the probability of a predictive
match highlights subjects 1, 5 and 30.
Example 7.2
Mental health status
This example considers the Lang
(1999) model and modiﬁcations of it applied to data on mental health
status from Agresti (2002). Health status y has levels 1 ¼ well, 2 ¼ mild
impairment, 3 ¼ moderate impairment and 4 ¼ impaired. It is related to
an X1 ¼ SES (a binary measure of low socio-economic status) and
X2 ¼ LIFE (an adverse life events total including factors such as divorce,
bereavement, etc.).
As noted above, the link is averaged over three options for the cumu-
lative density, Fk, k ¼ 1; 2; 3. Thus F1 for the LSEV distribution is
F1ðtÞ ¼ 1  exp½ expð
Þ
while F3 for the RSEV distribution is
F3ðtÞ ¼ exp½ expð
Þ
with
F2ðtÞ ¼ expðtÞ=½1 þ expð
Þ
and cumulative probabilities ðkÞ
ij
in
F1
k ½ðkÞ
ij  ¼ j þ Xi
are obtained according to link k ¼ 1; . . . ; 3 and response category j ¼
1; . . . ; J  1.
The link mixture is
FðtÞ ¼ 1ðÞF1ðtÞ þ 2ðÞF2ðtÞ þ 3ðÞF3ðtÞ
where probabilities on F1 and F3 depend on a parameter   Nð0; 2
Þ
such that
1ðÞ ¼ exp½ expð3:5 þ 2Þ
3ðÞ ¼ exp½ expð3:5 þ 2Þ
2ðÞ ¼ 1  1ðÞ  3ðÞ
ð7:6Þ
A negative  means the LSEV link form is preferred, and positive 
means RSEV is preferred, while  ¼ 0 means w1ðÞ and w3ðÞ are both
near zero and leads to selection of the logit link. A Dirichlet prior is
LATENT SCALE AND DATA AUGMENTATION
241

another possibility for ð1; 2; 3Þ. Then the model averaged predic-
tions are
ijðxiÞ ¼
X
k
kðÞðkÞ
ij
Alternative models might make the cut points and/or regression effects
speciﬁc to the link (though still proportional within each link) so that
F1
k ½ðkÞ
ij  ¼ 
ijk ¼ jk þ kxi
or take the parameter ’ ¼ 3:5 to differ between link probabilities so that
1ð’1Þ ¼ exp½ expð’1 þ 2Þ
3ð’2Þ ¼ exp½ expð’2 þ 2Þ
A further alternative model considered here averages over four possible
links, namely the three considered by Lang plus the probit. A Dirichlet
mixture is used
  DirchðÞ
where  ¼ ð1; 2; 3; 4Þ and  ¼ ð1; 1; 1; 1Þ. Hence the averaged link is
FðtÞ ¼ 1F1ðtÞ þ 2F2ðtÞ þ 3F3ðtÞ þ 4F4ðtÞ
with
F1ðtÞ ¼ 1  exp½ expð
Þ
F2ðtÞ ¼ expðtÞ=½1 þ expð
Þ
F3ðtÞ ¼ ðtÞ
F4ðtÞ ¼ exp½ expð
Þ
In model A the mixture probabilities are as in (7.6), with a prior  
Nð0; 5Þ, and common cut points and regression effects are assumed.
Initial runs suggested that the interaction in LIFE and SES was not an
important predictor. Results from the second half of a two-chain run of
20 000 iterations for model A show a credible interval for  straddling
zero, i.e. (3.7,4.6). The posterior mean on 2ðÞ of 0.49, compared with
0.30 for 1ðÞ and 0.21 for 3ðÞ, conﬁrms that the simple logit link is
preferred, though there is clearly averaging over the three links. Both life
events and low status are associated negatively with the lowest response
category (being well), and so positively with impairment. The effect of
life events is better deﬁned (95% interval entirely negative, i.e. 0.48
to 0.07) while the effect of SES straddles zero. The DIC is 115.1 and a
‘concordancy index’ (the proportion of subjects correctly classiﬁed into
one of the four grades) averages 0.315.
242
ORDINAL REGRESSION

In a second model (model B), the cut points are allowed to differ
between links, though the regression effects remain common, with
F1
k ½ðkÞ
ij  ¼ 
ijk ¼ jk þ Xi
Priors for the cut points jk are based on the posterior means and standard
deviations of j from model A, with a ten-fold downweighting of preci-
sion. Results from a 20 000-iteration run suggest that the logit cut points
differ from those of the skewed links, i.e. 2 ¼ ð0:5; 2:2; 3:6Þ compared
with 1 ¼ ð0:1; 1:9; 3:9Þ and 3 ¼ ð0:2; 2; 4Þ. One feature of model B
is a more precise effect for SES, with posterior mean 1.1 and a 95%
interval ð2:3; 0:1Þ conﬁned to negative values. The DIC deteriorates
under this model (to 118) but the concordancy index is 0.317.
In model C the Dirichlet mixture on four links is considered (with com-
mon link cut points as in model A). This shows the preference for the logit
with 2 ¼ 0:32 but shows the probit has a weight comparable with the
asymmetric options (3 ¼ 0:21 as against 1 ¼ 0:26 and 4 ¼ 0:21). The
DIC and concordancy index are similar to model A, i.e. 114.9 and 0.316.
7.3
ASSESSING MODEL ASSUMPTIONS: NON-PARAMETRIC
ORDINAL REGRESSION AND ASSESSING ORDINALITY
As for GLMs involving metric, count and binary data, a non-parametric
approach may be used to assess the assumed linear regression form for all
predictors. Often a non-parametric approach will be combined with a
review of the proportional odds assumption (Lee and Wild, 1996).
Assume a latent scale model with cumulative odds
ij ¼ Prðyi  jÞ ¼ Fðj  
ijÞ
j ¼ 1; . . . ; J  1
and link g, and initially assume proportional odds
gðijÞ ¼ j  
i
Then the category-speciﬁc regression means 
i might be modelled semi-
parametrically, e.g. by adopting a single smooth function si ¼ sðXiÞ for one
predictor. Assuming cases are ordered in terms of Xi with remaining predic-
tors zi1; . . . ; ziq modelled by linear effects constant over categories, then

i ¼ sðXiÞ þ 1zi1 þ    þ qziq
A fully non-parametric model (Hastie and Tibshirani, 1987) would take
the form
gðijÞ ¼ j  s1ðXi1Þ  s2ðXi2Þ  s3ðXi3Þ      spðXipÞ
ASSESSING MODEL ASSUMPTIONS
243

Several ways are available to obtain identiﬁability with a smooth in one
predictor. One involves setting both 1 ¼ 0 and the overall intercept 0 to
zero (if the latter step is not taken the mean of the si will be confounded
with it). The si series will then identify the intercept, and sampling on the
si can be unconstrained in the semiparametric model
gðijÞ ¼ j  si  1zi1  2zi2      qziq
Another way to obtain identiﬁability would be to recentre the si at each
iteration (e.g. using the carnormal function in BUGS if random walk priors
are used for si) and then an overall intercept 0 may be included provided
1 ¼ 0. If more than one predictor is modelled non-parametrically by
functions sðkÞ
i
for predictor k, then identiﬁcation would require devices
such as setting sðkÞ
1
¼ 0 for all k, or centring all the sðkÞ
i
at each iteration
(with an overall intercept included if 1 ¼ 0).
To assess proportionality with the impact of a single predictor Xi
modelled non-parametrically, one could assume smooth functions sij ¼
sjðXiÞ differing by category (or possibly subgroupings of the categories).
For example,
gðijÞ ¼ j  sij  1zi1  2zi2      qziq
where the smoothing function for subject i would be determined by that
person’s observed y, i.e. sij ¼ si;yi.
Example 7.3
Attitudes towards working mothers
Long (1997) pre-
sents an analysis of attitudes towards mothers working using the GHS
data aggregated over two survey years (1977 and 1989), with a total of
2293 respondents. The survey asked whether a working mother can
establish as warm and secure relationship with children as a non-working
mother. The response scale was 1 ¼ strongly disagree, 2 ¼ disagree, 3 ¼
agree, 4 ¼ strongly agree. Apart from survey year other predictors are
age in years, gender (1 ¼ male, 0 ¼ female), ethnicity (1 ¼ white, 2 ¼
non-white), occupational prestige and years of education.
We initially ﬁt a proportional cumulative logit model (7.1) with linear
form assumed for the impact of all predictors. A negative sign on  is
used so that regressor effects relate to more favourable views on mothers
working. A two-chain run of 1000 iterations, with one set of initial values
based on Long (1997), converges at under 250 iterations and estimates for
all predictors are signiﬁcant. Positive effects (i.e. favourable to mothers
working) are estimated for 1989 (vs. 1977), greater prestige and more
years of education, while negative views are estimated for males, whites
and older people. The DIC for this model is 6630.
244
ORDINAL REGRESSION

For a proportional semi-parametric model (model B) with a smooth in
age, a second-order random walk is assumed for si ¼ sðAiÞ where ages
are grouped into two-year bands to avoid sparsity, especially when
crossed with the grades of the response in the subsequent model. So
A ¼ 1 for ages 18, 19, A ¼ 2 for ages 20, 21, etc., up to A ¼ 36 for ages
88, 89. The si are centred at each iteration (so that their level is identiﬁed)
and so an intercept 0 can be included, provided 1 ¼ 0. The prior on the
precision s of the si is non-conjugate with s  Gað1; bÞ where b itself is
assigned a Ga(1,0.001) prior. The second half of a two-chain run of 5000
iterations produces a smooth curve which suggests some non-linearity,
namely a plateau effect up to around age 30 and a ‘liberal views’ blip for
people in their seventies (Figure 7.1). The DIC improves to around 6626
under this model.
There is a slight loss in ﬁt compared with model B (a DIC of 6630) in
moving to a non-proportional semi-parametric model (model C) where
the smooths in age are speciﬁc to response category. However, there is
clear evidence of non-proportionality. Here full conditionals for the
standard conjugate gamma priors on the three precision parameters are
used, with convergence apparent from around 3000 iterations in a two-
chain 5000 iteration run. For the category ‘strongly disagree’ the decline
in approval for working mothers stops at older ages (with a plateau effect
past 60). For the less extreme ‘disagree’ category the smooth gets close to
being linear, while for the ‘agree’ response there is a plateau at younger
ages (Figures 7.2 to 7.4).
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
18
28
38
48
58
68
78
88
Age
Figure 7.1
Proportional non-parametric model
ASSESSING MODEL ASSUMPTIONS
245

−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
18
28
38
48
58
68
78
88
Age
Figure 7.2
Strongly disagree by age
−1.2
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
18
28
38
48
58
68
78
88
Age
Figure 7.3
Disagree by age
−1.2
−1
−0.8
− 0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
18
28
38
48
58
68
78
88
Age
Figure 7.4
Agree by age
246
ORDINAL REGRESSION

7.4
LOCATION-SCALE ORDINAL REGRESSION
A generalization of the ordinal regression model models both the location
and scale of the underlying variable y, such that
Prðyi  jjXi; uiÞ ¼ F j  Xi
expðuiÞ


ð7:7Þ
If F ¼  (the cumulative standard normal) then yi ¼ j if j1 < y
i  j
where
y
i ¼ Xi þ Zi expðuiÞ
Zi  Nð0; 1Þ
Thus y
i has mean Xi and variance expð2uiÞ and, if  is positive or
negative, no longer leads to proportional odds. Tosteson and Begg (1988)
consider analysis of diagnostic tests with a single predictor Xi ¼ ui de-
ﬁned to be 0.5 for diseased (positive) subjects and þ0.5 for well sub-
jects. Then 1 describes how variability on the latent scale differs between
well and ill subjects, while 1 measures the predictive accuracy of the
diagnostic test. For 1 given, more accurate tests have larger 1.
Cox (1995) considers a further generalization, but with a logit link,
such that
logit½Prðyi  jjXi; ui; Aij; vjÞ ¼ ij ¼ j  Xi  Aij
expðui þ !vjÞ


ð7:8Þ
where Aij are attributes both of the categories and the subjects and vj are
attributes of the categories. These might be dummy variables identifying
certain categories for certain classes of subjects (e.g. certain categories of
subject i may be more likely to respond for more extreme categories j). If
 6¼ 0, ! 6¼ 0 or  6¼ 0 then a non-proportional model results (Peterson
and Harrell, 1990). Recent Bayesian location-scale models have focused
especially on receiver–operator curves (ROCs) involving models of this
type (e.g. see Peng and Hall, 1996; Ishwaran and Gatsonis, 2000;
Hellmich et al., 1998).
Another application of the location-scale approach illustrates how an
unknown scale may be part of a model allowing estimation of the link,
rather than taking it known (cf. the discrete mixture over three or more
possible links discussed above). Gelfand and Kuo (1991) consider an
unknown link model in the analysis of assay data, where increasing
standardized dosages tk; k ¼ 1; . . . ; K are applied and deaths rk at that
dosage are binomial
rk  Binðnk; pkÞ
LOCATION-SCALE ORDINAL REGRESSION
247

By assumption, the ‘potency’ curve pk ¼ FðtkÞ is increasing as tk
increases (i.e. as the lethality of the dose increases or the strength of
the input in general) and so the sequence of values ðp1; . . . ; pkÞ describes
part of a cumulative density function with boundary values
t0 ¼ 1;
p0 ¼ Fðt0Þ ¼ 0
and
tKþ1 ¼ 1;
pKþ1 ¼ FðtKþ1Þ ¼ 1
Suppose original doses in their original measure scale are T1; . . . ; TK and
the standardized dosages are
tk ¼ ðTk  Þ=
A parametric analysis with a standard link might therefore assume
pk ¼ ðtkÞ
or
pk ¼ expðtkÞ=½1 þ expðtkÞ
However, a non-parametric approach allows uncertainty around such a
central ‘baseline’ link such as Fb ¼  according to a prior sample size
(‘concentration parameter’) M, with the prior on the unknown cdf FðtÞ
then being
FðtÞ  BeðMFbðtÞ; Mð1  FbðtÞÞÞ
Larger values of M imply greater conﬁdence in the suitability of Fb and
greater closeness of the estimated FðtÞ to FbðtÞ. This induces a Dirichlet
prior on the differences
Fðt1Þ  Fðt0Þ ¼ p1  p0 ¼ p1
Fðt2Þ  Fðt1Þ ¼ p2  p1
Fðt3Þ  Fðt2Þ ¼ p3  p2
..
.
FðtKÞ  FðtK1Þ ¼ pK  pK1
FðtKþ1Þ  FðtKÞ ¼ pKþ1  pK ¼ 1  pK
with parameters
k ¼ M½FbðtkÞ  Fbðtk1Þ
Let ^FðtkÞ be the mean potency curve estimate at dosage tk. The expected
potency at an intermediate dosage t to those at which applications are
248
ORDINAL REGRESSION

made is obtainable as
ð½kþ1  =kþ1Þ^FðtkÞ þ ð=kÞ^Fðtkþ1Þ
where
 ¼ M½FbðtÞ  FbðtkÞ
Possible developments on this approach include a prior on the scale ,
and possibly the origin , though this can be set to t to reduce para-
meterization. The scale may also be made a function of covariates as
above. While M can be preset, a prior on M might be used but would need
to be tuned to avoid low values that cause numerical problems in sampl-
ing the Dirichlet. One might also include regression effects both on the
varying impact of the dosage, and on other relevant factors zk such as
measured frailty, soil fertility, etc., of the samples exposed to application
level k. Thus with 
k ¼ 1Tk þ 2zk and  ¼ 
tk ¼ ð1Tk þ 2zk  Þ=
pk ¼ FbðtkÞ
FðtÞ  BeðMFbðtÞ; Mð1  FbðtÞÞ
Example 7.4
Nausea and cisplatin
Cox (1995) presents data on seve-
rity of nausea in two sets of chemotherapy patients, one group ðN1 ¼
161Þ a control group, the other ðN2 ¼ 58Þ in receipt of cisplatin
(Table 7.1). The response is graded 0 to 5 (recoded 1 to 6 in Program 7.4),
namely no nausea (0), intermediate levels of nausea (1, 2, 3, 4) and severe
nausea (5).
Cox considers model (7.7) and extensions drawing partly on Peterson
and Harrell to allow non-proportionality. First ﬁtting model (7.7) with
xi ¼ ui ¼ 1 for the cisplatin group gives 1 ¼ 0:83 ðs:d: ¼ 0:24Þ so that
in fact cisplatin patients experienced more severe nausea (results from a
two-chain run of 2500 iterations that shows convergence at under 500
iterations). The coefﬁcient  is marginally negative with mean 0.15 but
with the 95% interval straddling zero. So there is weak evidence of less
Table 7.1
Nausea by cisplatin group
Severity of Nausea
Total
0
1
2
3
4
5
No cisplatin
43
39
13
22
15
29
161
Cisplatin
7
7
3
12
15
14
58
LOCATION-SCALE ORDINAL REGRESSION
249

variability in y for the cisplatin than the non-cisplatin group. The DIC is
777, and the percentage of patients correctly classiﬁed is 19.3. A second
(proportional odds) model omits ui from (7.7). This raises 1 to around
0.86 and has a DIC of 776.
Peterson and Harrell (1990) introduce a patient–category attribute to
the model just considered, as in (7.8). Thus Aij ¼ 1 for cisplatin patients
in the last severity category but one (note that iJ ¼ 1 and only categories
0, 1, 2, 3, 4 are actually modelled) and Aij ¼ 0 for all other patient-
outcome combinations. This reduces the DIC to around 775.3 but the
percentage of patients correctly classiﬁed is lower than model A, at 19.1.
In contrast to the results presented by Cox (1995) the coefﬁcient 1
straddles zero with mean 0.63 and 95% interval (0.18,1.44).
Cox replaces Aij by a dummy variable common to both patient groups,
so modelling the scale, not the location, in (7.8), i.e. vj ¼ 1 if yi ¼ 4 and
vj ¼ 0 otherwise. This improves the DIC to 769 under an informative
N(0,0.2) prior for !1.
Example 7.5
Cox and Snell assay data
Gelfand and Kuo (1991)
consider data from Cox and Snell (1989) on deaths rk at K ¼ 5 doses
T1 ¼ 0, T2 ¼ 1, T3 ¼ 2, T4 ¼ 3, T5 ¼ 4. The number of subjects at all
levels is nk ¼ 30. The baseline cdf assumed is a cumulative normal 
with mean 2 and variance 0.25. Hence the prior baseline cdf has values
Fbð0Þ ¼ 3:17  105
Fbð1Þ ¼ 0:023
Fbð2Þ ¼ 0:5
Fbð3Þ ¼ 0:977
Fbð4Þ ¼ 0:99997
Gelfand and Kuo consider alternative (preset) values of M, namely M ¼
1, M ¼ 30, M ¼ 100 and M ¼ 200. Taking M ¼ 30 we sample the
Dirichlet using a series of gamma densities to estimate the differences
Sk ¼ pk  pk1, with SKþ1 ¼ 1  pK. The estimated means and standard
deviations for pk ¼ FðtkÞ are then
Fð1Þ ¼ 0:061ð0:035Þ
Fð2Þ ¼ 0:135ð0:038Þ
Fð3Þ ¼ 0:503ð0:060Þ
Fð4Þ ¼ 0:871ð0:038Þ
Fð5Þ ¼ 0:921ð0:035Þ
with a DIC of 29.3.
250
ORDINAL REGRESSION

An extension is to take the scale  as unknown – with Ga(1,0.001)
prior – but M still set at 30. This improves the DIC considerably to 21.5,
with FðtÞ now estimated as 0.086 (0.040), 0.255(0.055), 0.503 (0.058),
0.752 (0.053), 0.901 (0.040) and the estimated scale in Fb standing at
1.56. One may further (model C in Program 7.5) let both the scale and
Dirichlet concentration M be unknowns, with the prior on the latter
assumed to be M  Gað1; 0:1Þ. Results may be sensitive to the priors on
 and M. In fact, this leads to a worsening of the DIC to 26.5, with M
estimated at 3 and the scale now 3.3.
7.5
STRUCTURAL INTERPRETATIONS WITH AGGREGATED
ORDINAL DATA
Most of the model features as considered above (e.g. use of cumulative
probabilities) for individual response data also pertain to aggregated
ordinal data, except that analysis typically takes place via the direct
multinomial likelihood. To adopt the latent variable method where y is
sampled would require disaggregating to the equivalent individual-level
data. The discussion of aggregated ordinal data applications focuses on
structural indices that are functions of the parameters (and possibly data
also) in models relating to health status and to consumer choice.
Suppose aggregated counts fi1; fi2; . . . ; fiJ denote persons in ranked
health categories j ¼ 1; . . . ; J for social or income groups iði ¼ 1; . . . ; IÞ
of size Ni. For monitoring the impact of economic and health policies it
may be important to assess trends in health inequality and this might
involve comparing two or more periods to assess whether health status
contrasts over income groups have narrowed or widened. If the data for
two periods are denoted f1ij and f2ij then one possible model for health
status contrasts in period t is
fti  MultðNti; tiÞ
where ti ¼ ðti1; ti2; . . . ; tiJÞ is the distribution of income groups over
illness categories (good health at low ranks to poor health at high ranks),
with cumulative probabilities
tij ¼ ti1 þ ti2 þ    þ tij
modelled via links such as
logitðtijÞ ¼ tj  ti
or
1ðtijÞ ¼ tj  ti
STRUCTURAL INTERPRETATIONS WITH AGGREGATED ORDINAL DATA
251

The tj are period-speciﬁc cut points and the ti represent the average ill-
health in group i in period t. Survey data (or other sources such as the
Census) may also provide information on the changing distribution of the
population across income or social groups. This additional data may be
modelled as
Nti  MultðNt; ptiÞ
where pti are the proportions in group i in year t. The average morbidity
level in period t is then  t ¼ PG
i¼1 tipti. Note that one might constrain
the effects ti to being monotonic as well as the tj. Social status bands
are usually also ordinal, and a gradient of health over social rankings is
commonly observed.
An inequality index Ct, based on the model parameters such as jt and
it, may be used to gauge whether inequality has changed. This would
involve comparing Ct with Ct1 and counting the proportion of iterations
where Ct > Ct1. Take
rti ¼ pt1 þ pt2 þ    þ 0:5pti
as the relative rank of group i in period t (Kakwani et al., 1997). One may
then derive a ‘concentration index’ as
Ct ¼
X
G
i¼1
ptitirti   t
 
!
= t
ð7:9Þ
This type of discrepancy is deﬁned in Lorenz concentration curves as
twice the area between the horizontal axis (health equality) and a plot of
cumulative ill-health HðsÞ against s, where s is socio-economic status or
income. If HðsÞ lies above the diagonal then inequalities in illness favour
more advantaged social groups. If HðsÞ is taken as piecewise linear then
the index Ct is lower (less positive, more negative) and the more ill-health
is concentrated among the disadvantaged.
As another example of structural inferences consider aggregated
consumer ratings for i ¼ 1; . . . ; I products on ordinal scales with J levels
fij. A multinomial distribution applies to each row of this tabulation, i.e.
across the total ratings for each product. So fi  MultðNi; iÞ, i ¼ 1; . . . ; I
where i ¼ ði1; i2; . . . ; iJÞ is the distribution over consumer ratings.
Allowing for both mean and scale in the underlying ordered utilities as in
section 7.4, one might specify, as in Nandram (1998, p 111),
logitðijÞ ¼ ðj  iÞ= expðiÞ
i ¼ 1; . . . ; I; j ¼ 1; . . . ; J  1
with  and  parameters centred for identiﬁability, and all  parameters
free. Following Nandram (1997) one might be interested in the product
252
ORDINAL REGRESSION

having the highest mean ranking (i.e. highest consumer rating). Speciﬁ-
cally the interest is in the posterior probabilities
q1i ¼ Prði > k; k 6¼ ijyÞ
ð7:10Þ
which may be estimated from the MCMC sampling chain. However, an
alternative perspective on optimal ranking (with analogies to the health
status application above) involves the relative distribution of the ij and
associated ranks. Nandram (1997, p 404) proposes the alternative mean
satisfaction measure
vi ¼
X
j
jij
The best product is then assessed by estimating
q2i ¼ Prð	i > 	k; k 6¼ ijyÞ
ð7:11Þ
Example 7.6
Self-assessed health application
Wagstaff and van
Doorslaer (1994) consider survey data on self-assessed health in the
Netherlands in the late 1980s and early 1990s, with responses on a health
scale with J ¼ 5 categories (j ¼ 1 for health ‘very good’, ‘good’, ‘fair’,
‘sometimes good, sometimes bad’ and j ¼ 5 for bad health). The data are
disaggregated to six income groups; the lowest income group in 1989/
1990 accounts for 25% of household heads and in 1991/1992 for 20%,
while the highest income group accounts for 9% and 12% in the two
periods. Wagstaff and van Doorslaer consider both standard normal and
standard lognormal latent ill-health scales. They obtain evidence of a rise
in health inequality between 1989 and 1990 and 1991 and 1992, using a
concentration curve methodology as just described.
Here we consider the data for the two periods separately using a probit
link. So
fti  MultðNti; tiÞ
tij ¼ ti1 þ ti2 þ    þ tij
1ðtijÞ ¼ tj  ti
The data are arranged so that the lowest category is good health and the
highest is poor health; income groups are arranged from 1 (lowest ) to 6
(highest) (see Table 7.2 for the 1989–1990 data).
t1 is set at zero so all health by income parameters are free; they are
assigned N(0,100) priors. Two-chain runs of 20 000 iterations converge
after 1000 iterations. The concentration index in (7.9) for the second
period is found to be lower than for the ﬁrst, i.e. 0.195 vs. 0.156
STRUCTURAL INTERPRETATIONS WITH AGGREGATED ORDINAL DATA
253

(Table 7.3). The mean health parameters by income band ti reﬂect the
worse health in lower income bands. The gap in mean health in 1991–
1992 between highest and lowest income groups is wider than in 1989–1990.
A suggested exercise is to code the analysis (i.e. pooling the likelihood over
the two periods) such that one can assess the probability that C2 < C1.
Example 7.7
Sensory evaluation, entre´es in army meals
Nandram
(1998) presents data on 12 entre´es in a military ration. The entre´es were
each rated for taste by 36 panelists (a different panel for each entre´e) on a
nine-point hedonic scale. The intention is to assess the best rated entre´e.
The frequencies fij, i ¼ 1; . . . ; 12 and j ¼ 1; . . . ; 9, are analysed by the
location-scale cumulative logit model
logitðijÞ ¼ ðj  iÞ= expðiÞ
Table 7.2
1989–1990 health by income data
Income
Health
V. good
Good
Fair
Mixed
Bad
1 (lowest)
455
1140
420
186
98
2
388
794
225
109
45
3
418
872
202
88
35
4
424
850
158
55
19
5
420
914
110
51
17
6 (highest)
275
490
65
8
8
Table 7.3
Health in the Netherlands
1989–1990
1991–1992
Mean
2.5%
97.5%
Mean
2.5%
97.5%
Concentration index
0.156
0.176
0.137 0.195 0.216 0.174
Mean ill-health by
income group
1
0.935
0.887
0.983
1.032
0.978
1.085
2
0.752
0.694
0.809
0.783
0.723
0.844
3
0.663
0.608
0.720
0.669
0.613
0.724
4
0.539
0.481
0.595
0.554
0.499
0.611
5
0.494
0.438
0.551
0.462
0.411
0.514
6
0.365
0.290
0.443
0.334
0.268
0.401
254
ORDINAL REGRESSION

A two-chain run of 2500 iterations shows early convergence. The post-
erior probabilities (7.10) show entre´e 9 (chicken) as best with q1;9 ¼ 0:47,
followed by the 11th entre´e (ham slices) with q1;11 ¼ 0:20, in turn closely
followed by the ﬁrst entre´e (pork sausage) with q1;1 ¼ 0:19. Under (7.11),
the respective probabilities for these entre´es are q2;9 ¼ 0:28, q2;11 ¼ 0:47
and q2;1 ¼ 0:10.
7.6
LOG-LINEAR MODELS FOR CONTINGENCY TABLES
WITH ORDERED CATEGORIES
In contingency tables one or more of the dimensions may be ordinally rank-
ed. To take this ordering into account one may adopt random walk priors for
the main effects or interactions. For example, for mortality or disease data
recorded by discrete age groups and period, another dimension (the cohort, a
form of ‘interaction’ between age and period) can be derived leading to age–
period–cohort models. Each of these dimensions is ordered and random walk
priors of ﬁrst or second order can be adopted to reﬂect the likely auto-
correlation between successive effects; an order constraint may be applied,
e.g. to age effects, to reﬂect their ordinality (Besag et al., 1995).
Alternatively in the row–column (RC) model for a two-way table yij
(with i ¼ 1; . . . ; I and j ¼ 1; . . . ; J and one or both categorizations
ordered) the priors for the main effects are taken as unordered ﬁxed
effects, but the prior for the interactions incorporates the ordering of the
categories (Goodman, 1979). The usual log-linear or logit linear inter-
action terms u12ij (involving IJ  I  J þ 1 unknowns) are replaced by a
less heavily parameterized multiplicative structure involving row effects,
column effects, or both. The RC model leads to simpler tests of indepen-
dence than in the usual log-linear model for unordered categories.
A simple model with only one unknown parameter when both factors are
ordered is called the linear by linear association model (or constant associa-
tion model). Thus with Poisson sampling yij  PoðijÞ the means are
modelled as
logðijÞ ¼ u0 þ u1i þ u2j þ ij
where i and j are known scores, e.g. i ¼ i and j ¼ j. Alternatively,
for a two-way table with multinomial sampling, let ij be the probabilities
of response in cell ði; jÞ with ijij ¼ 1. So with  ¼ ð11; 12; . . . ; IJÞ,
y  Multðy . . . ; Þ then
ij ¼ expðijÞ=½1 þ expðijÞ;
j ¼ 1; . . . ; J  1
with ij as above.
LOG-LINEAR MODELS FOR CONTINGENCY TABLES
255

If the 95% interval for  straddles zero then independence is supported,
while a 95% interval consistent with  > 0 implies that higher totals yij
occur when i and j increase or decrease together.  < 0 means higher
counts yij occur when i increases but j decreases or vice versa. Under
this model the log odds for any 2  2 subtable is obtained as
logð½ijkm=½imkjÞ ¼ ði  kÞðj  mÞ
so in this sense association is constant across the whole table.
If rows are not ordered but columns are, one might model interactions
u12ij with assigned column scores and unknown row scores, not subject to
an order constraint, so that
u12ij ¼ ji
logðijÞ ¼ u0 þ u1i þ u2j þ ji
with row scores subject to P i ¼ 0 for indentiﬁability (this is a row
effects model). A column effects model has u12ij ¼ ij.
When both factors are ordered, both scores i and j may be taken as
unknown (this is the row  column or RC model) so that
u12ij ¼ ij
The scaling and location of both i and j is arbitrary and for identiﬁa-
bility a zero-sum, unit-length constraint may be imposed, e.g. P j ¼ 0,
P 2
j ¼ 1 and P i ¼ 0, P 2
j ¼ 1. Order constraints may also be applied
to both sets of scores 1  2      I and 1  2      J (Ritov
and Gilula, 1991). Additionally an association parameter may be includ-
ed, namely
logðijÞ ¼ u0 þ u1i þ u2j þ ij
There is also a row þ column (R þ C) model deﬁned by
logðijÞ ¼ u0 þ u1i þ u2j þ s2ji þ s1ij
where i and j are known scores (e.g. i ¼ i, j ¼ j) and the scores s1i
and s2j are constrained to sum to zero and unit length but not constrained
to be monotonic.
Albert (1997) considers how departures from the constant association
model can be accommodated when they are conﬁned to a few cells. Thus
the departures are limited to a small fraction of the total cells. Speciﬁ-
cally, for a two-way table with IJ total cells, the number of outliers might
be a priori set at k ¼ qIJ where q (the fraction of outliers) is small (under
15%). The constant association RC model is therefore extended to the
256
ORDINAL REGRESSION

RC þ INT model
logðijÞ ¼ u0 þ u1i þ u2j þ ij þ eij
where the eij measure departures from the constant association model.
Because only a small proportion of the eij are expected to be non-zero,
binary indicators ij are used to choose between an outlier prior (non-zero
interaction prior)
eij  Nð0; P1
N Þ
and a zero-interaction prior, eij ¼ 0. In practice the zero interaction prior
is eij  Nð0; P1
Z Þ where PZ is large. Typical values for PN and PZ might
be 0.001 and 1000 respectively. The prior on the ij is ij  BernðqÞ
where q is the proportion of outliers assumed known as part of the prior,
so q might be varied to assess sensitivity (e.g. q ¼ 0:05 vs. q ¼ 0:01). The
prior probabilities of 0; 1; 2; . . . outliers are then given by a binomial with
probability of success q and IJ as the binomial denominator.
Example 7.8
Mental health status, constant association model with
outliers
Albert (1997) analyses data on mental health status by parental
socio-economic status (Table 7.4) and originally considered by Goodman
(1979); the health state has I ¼ 4 ordered categories while social status
has J ¼ 6.
The outlier model just outlined is applied with k ¼ 3 as the expected
outlier total so that q ¼ 3=24 ¼ 0:125. So model 1 is the constant asso-
ciation RC model
logðijÞ ¼ u0 þ u1i þ u2j þ ij
with i ¼ i and j ¼ j taken as known. The alternative general depen-
dence model (model 2) is
logðijÞ ¼ u0 þ u1i þ u2j þ ij þ eij
Table 7.4
Mental health by social status
Mental health
Parental status
A
B
C
D
E
F
Well
64
57
57
72
36
21
Mild symptoms
94
94
105
141
97
71
Moderate symptoms
58
54
65
77
54
54
Impaired
46
40
60
94
78
71
LOG-LINEAR MODELS FOR CONTINGENCY TABLES
257

where one or more eij are non-zero. The prior probability of three outliers
is 0.24 by the binomial formula and that of zero outliers (i.e. model 1
applies) is ð0:875Þ24 ¼ 0:04. Setting PN ¼ 0:001 and PZ ¼ 10 000 a
posterior probability of zero outliers of 0.972 is obtained, so the Bayes
factor B12 supporting model 1 is 24, providing strong support for the
constant association model without further interaction parameters. The
parameter  indicates positive association between the factors with a 95%
interval (0.06, 0.12). The DIC for this approach (model A which averages
over models 1 and 2) is 175 ðde ¼ 11Þ.
Model B has an association parameter and unknown row and column
scores; the latter are subject to standardization for identiﬁability and also
constrained to be monotonic. Thus
logðijÞ ¼ u0 þ u1i þ u2j þ ij
with 1  2      I and 1  2      J. This model also shows
a positive association with a 95% interval on  of (0.16,0.31). However
the DIC is now 204.5 with de ¼ 17. So despite assuming known row and
column scores, model A is preferred.
7.7
MULTIVARIATE ORDERED OUTCOMES
Suppose M outcomes are obtained for i ¼ 1; . . . ; n individuals and con-
taining J1; J2; . . . ; JM ordered categories respectively. For simplicity, take
J ¼ J1 ¼ J2 ¼    ¼ JM perhaps by expanding or conﬂating scales to
achieve this simpliﬁcation. Then the observed ranks are denoted yim, i ¼
1; . . . ; N, m ¼ 1; . . . ; M. As above, one may introduce latent variables y
im
and J  1 cut points mj on their range such that
yim ¼ j
if m;j1  y
im < mj
1 < m1      m;J1 < 1
For example, the analogue of the univariate ordinal probit ðF ¼ Þ would
mean the y
im being multivariate normal with mean fB1Xi; B2Xi; ... ; BMXiÞ,
and with a dispersion matrix being a correlation matrix R ¼ ½lm of order
M. As above, the constraint m1 ¼ 0 may be used, leaving J  2 free cut
points and the intercept m0 as a free parameter, so that the regression
parameter vectors are Bm ¼ ðm0; . . . ; mpÞ.
However, a further option has the advantage that the dispersion matrix
is replaced by an unrestricted dispersion matrix. Instead of modelling the
mj directly, Chen et al. (2000) consider transformed cut points mj
conﬁned to the interval (0,1), such that m;J1 ¼ 1 in addition to m1 ¼ 0.
258
ORDINAL REGRESSION

Then
yim ¼ j
if m;j1  w
im < mj
ð7:12Þ
where the redeﬁned latent variables w
im are (for instance) taken as multi-
variate normal with mean for the mth outcome CmXi and an unrestricted
dispersion matrix , such that the ðl; mÞth element of  is given by
lm
pll
pmm. The original regression parameters Bmj for covariates
j ¼ 0; . . . ; p are obtained as
Bmj ¼ Cmp=pmm
and the original cut points as
mj ¼ mj=pmm
including mJ ¼ 1=pmm. So in the redeﬁned analysis there are fewer
cut point parameters, namely MðJ  3Þ, but an unrestricted dispersion
matrix. Other links can be obtained by scale mixing. For example,
O’Brien and Dunson (2004) approximate multivariate logistic sampling
for multiple ordinal variables. Thus truncated sampling of y takes place
from a multivariate normal with observation-speciﬁc scale matrix R=i or
=i where i  Gað0:5	; 0:5	Þ and 	 may be unknown.
As for multivariate binary and count responses, an alternative approach
to modelling correlation between several ordinal variables is to introduce
Q < M factor variables. For independent factors and (standardized) load-
ings mqðm ¼ 1; . . . ; M; q ¼ 1; . . . ; QÞ of variable m on factor q, the cor-
relations lm between the original ordinal variables are represented as
lm ¼ PQ
q¼1 lqmq. Let mij be the cumulative probability of a response j
or lower for response m and respondent i so that
mij ¼ mi1 þ mi2 þ    þ mij
and with logit, probit or other links g and a proportional regression effect
gðmijÞ ¼ mj  
mi
Under a factor approach, the regression function will combine the impact
of known predictors xi and one or more factors so that

mi ¼ BmXi þ m1Fi1 þ m2Fi2 þ    þ mQFiQ
For the mth variable with Jm categories, an intercept will not be included
in Bm if there are Jm  1 free cut points but can be included (since it is
then identiﬁed) when there are Jm  2 unknown cut points. As is usual in
factor analysis applications, the yim are taken to be independent when the
MULTIVARIATE ORDERED OUTCOMES
259

values of the latent variables are known,
fðyijFiÞ ¼
Y
M
m¼1
fðyimjFiÞ
where Fi ¼ ðFi1; . . . ; FiQÞ, yi ¼ ðyi1; . . . ; yiMÞ.
Another possible approach when multivariate items are all taken to
reﬂect the same underlying concept is to regard the observations yim as
repetitions on a single scale, much as in item analysis for binary respon-
ses (Gibbons and Hedeker, 2000). One may then deﬁne a subject effect ui
and assess intrasubject correlation by comparing 2
u to 2
u þ 2
e , where 2
e
is deﬁned by the link used. Assume all M variables have J ordered cate-
gories. Consider a logit link and single predictor Xi, and deﬁne the
dummy variables Dimj ¼ 1 if Yim  j, and Dimj ¼ 0 otherwise. When
regarded as repetitions on a single scale the data can be modelled as
Dimj  BernðimjÞ
m ¼ 1; . . . ; M; j ¼ 1; . . . ; J  1
and assuming proportional odds
logitðimjÞ ¼ j þ 0m þ 1mXi þ ui
ð7:13Þ
where J1 > J2 >    > 1 and a corner constraint is applied to item
intercepts 0m (e.g. 01 ¼ 0) if all J  1 cut points are free parameters.
The comparison with item analysis becomes closer if the variance of the
ui is preset, e.g. ui  Nð0; 1Þ, and loadings j are introduced such that
logitðimjÞ ¼ j þ 0m þ 1mXi þ jui
Example 7.9
London suicides
To illustrate sampling y when there
are M ¼ 2 ordinal responses consider suicide SMRs in 32 London
boroughs for 1989–1993 in terms of quartile ranks, J1 ¼ J2 ¼ 4 (e.g.
male suicide SMRs under 80.7 have rank 1, those between 80.7 and 96
have rank 2, etc.). There is a single predictor, a deprivation score. The cut
point parameterization in (7.12) is used, and the bivariate normal there-
fore has variances f2
1; 2
2g which are not ﬁxed. The bivariate normal is
obtained conditionally; that is, y
i1 is sampled according to cut points 1j
(only one of which is free) from

i1 ¼ 11 þ 12Xi
giving a residual ri1 ¼ y
i1  
i1 and then y
i2 is sampled from

i2 ¼ 21 þ 22Xi þ ri1
Sampling of the cut points requires specifying those observations with
relevant y values that determine the constraints used in their sampling.
260
ORDINAL REGRESSION

Following Spiegelhalter and Marshall (1999) a relatively diffuse prior is
adopted on  ¼ 2=1. The correlation  between the scores y
i1 and y
i2
may be estimated using the posterior means of , 1 and 2. Here we ﬁnd
a stronger effect of deprivation on male suicide 12 ¼ 0:46ð0:12Þ than on
female suicide 22 ¼ 0:39ð0:14Þ and a correlation of 0.90 between the
two latent scores. This conditional speciﬁcation of the bivariate (or higher
order) multivariate normal may have advantages in scale mixing as it
allows different implicit links for each response. Thus scale multipliers
i1, i2, etc., may be sampled from gamma densities with different un-
known degrees of freedom.
Example 7.10
Social attitudes
As an example of the factor analytic
approach consider three ordinal attitude variables from the 2000 General
Social Survey. The analysis is conﬁned to 1665 subjects with complete
responses to all items:
1. Sex relations before marriage: always wrong (1), almost always wrong
(2), wrong only sometimes (3) or not wrong at all (4).
2. Divorce laws: should divorce in this country be easier or more
difﬁcult to obtain than it is now? Easier (1), Stay Same (2), More
Difﬁcult (3).
3. It is sometimes necessary to discipline a child with a good, hard
spanking: Strongly Agree (1), Agree (2), Disagree (3), Strongly
Disagree (4).
A single factor ðQ ¼ 1Þ is taken to underlie associations between these
items and represent the contrast between traditional and libertarian social
attitudes. The known predictor age (in standard units, denoted xi) is also
used. The ﬁrst cut point for each variable is taken as free, so the regres-
sion means ðm ¼ 1; 2; 3Þ have the form

mi ¼ mxi þ mFi
The loading 1 of the ﬁrst question on the factor is constrained to be
positive and since responses to the ﬁrst question are increasing in liber-
tarianism Fi will be a positive measure of libertarianism. Note that res-
ponses to the second question are ascending in traditionalism so 2 will
tend to be negative.
A two-chain run of 2000 iterations shows early convergence with pos-
terior means from iteration 500 to 2000 on the scaled loadings being
 ¼ f0:92; 0:56; 0:39g. Traditional attitudes tend to increase with age,
especially for the ﬁrst two questions, so 1 is negative and 2 is positive.
MULTIVARIATE ORDERED OUTCOMES
261

The highest absolute correlations m1m2 are between variables 1 and 2,
namely 0.51, as against 0.35 between the ﬁrst and third questions,
and 0.21 between questions 2 and 3. Further options might be consi-
dered for these data, such as alternative links and possible scope for a
second factor since the third variable does not seem so well explained.
Example 7.11
NORC sexual attitudes data
Agresti and Lang (1993)
and Gibbons and Hedeker (2000) both consider data from the earlier 1989
General Social Survey on sexual attitudes. Speciﬁcally they consider
M ¼ 3 ordinal responses of 475 subjects (Table 7.5) to three items:
(a) sex relations among early teens (ages 14–16); (b) premarital sex
relations; (c) extramarital sex relations. The J ¼ 4 responses are as
follows: 1 ¼ always wrong, 2 ¼ almost always wrong, 3 ¼ wrong only
sometimes, 4 ¼ not wrong.
First of all consider the proportional model as in (7.13)
Dimj  BernðimjÞ
m ¼ 1; . . . ; 3; j ¼ 1; . . . ; 3
logitðimjÞ ¼ j þ 0m þ ui
With J  1 cut points j as free parameters, and the ﬁrst item intercept
01 (for teen sex) set equal to zero for identiﬁability, the remaining 0m
Table 7.5
Sexual attitudes
Teen
Premarital
Extramarital sex
sex
sex
1
2
3
4
Total
1
1
140
1
0
0
141
2
30
3
1
0
34
3
66
4
2
0
72
4
83
15
10
1
109
2
1
3
1
0
0
4
2
3
1
1
0
5
3
15
8
0
0
23
4
23
8
7
0
38
3
1
1
0
0
0
1
2
2
0
0
0
0
3
3
2
3
1
9
4
13
4
6
0
23
4
1
0
0
0
0
0
2
0
0
0
0
0
3
0
0
1
0
1
4
7
2
2
4
15
262
ORDINAL REGRESSION

are then contrast parameters measuring whether premarital and extra-
marital sex are seen as more or less wrong (in terms of opinions in higher
categories) than teen sex. Convergence in a two-chain run of 2000 iter-
ations is obtained at around 250 iterations. The estimates 02 and 03
of 4.8 and 0.7 show premarital sex is seen as less wrong than teen sex,
but extramarital sex is seen as more wrong. The estimated variance of the
subject effects ui is 10.8 and the intrasubject correlation
2
u=ð2
u þ 2
eÞ
averages 0.76; 2
e ¼ 2=3 is the variance of the standard logistic con-
tinuous variable taken to underlie the observed ordinal response. The DIC
is 2062 with 259 effective parameters.
A non-proportional model takes the item intercepts to vary according
to the level of the underlying scale, namely
logitðimjÞ ¼ j þ 0mj þ ui
This leads to an apparent loss of ﬁt with the DIC rising to 2066. The pro-
portional odds model seems most at doubt for the comparison of extra-
marital and teen sex, with the coefﬁcients 031, 032 and 033 being 0.75
(0.31, 1.18), 0.44 (0.14, 1.04) and 1.70 (0.52, 3.03). However, these
estimates are relatively imprecise being based on low frequencies. One
may also estimate the within-item contrasts (e.g. 033  032) as in Agresti
and Lang (1993).
EXERCISES
1. In Example 7.1 try a scale mixture with y sampled from truncated
normals with unknown degrees of freedom parameter. Does the probit
or logit link get more support?
2. In Example 7.2 try a model with cut points common between the
skewed left and skewed right extreme value links but different cut
points for the logit link (i.e. model B simpliﬁed to have six rather than
nine cut points).
3. In Example 7.3 try a GAM for the impact of age using 15 ﬁve-year age
bands (under 20, 20–24, 25–29, 30–34, . . . , 80–84, 85–89) rather than
the 72 individual ages between 18 and 89. Assess the ﬁt for propor-
tional and non-proportional age GAMs. Also assess whether pro-
portional and non-proportional GAMs for the impact of prestige
improve the model (with age also still a smooth function).
EXERCISES
263

4. In Example 7.5 try N(2, 1) as a baseline density Fb and experi-
ment with unknown M using a discrete prior over selected values
1; 2; 3; 4; . . . ; 20.
5. In Example 7.6 recode the program to pool the likelihood over the
two periods so as to assess the probability that C2 < C1 (i.e. that
health inequality increased).
6. In Example 7.6 compare the ﬁt of logit, probit and complementary
log–log models and apply a procedure to mix over the links.
7. In Example 7.7 apply the cumulative complementary log–log link
rather than the cumulative logit link and assess any changes in ﬁt or
in inferences about the best entre´e.
8. In Example 7.8 (mental health by social status) obtain the Bayes
factor in support of the independence model
logðijÞ ¼ u0 þ u1i þ u2j
and the alternative interaction model is
logðijÞ ¼ u0 þ u1i þ u2j þ eij
when k ¼ 2 interactions eij are a priori expected to be non-zero.
9. In Example 7.8 try the R þ C model and compare its ﬁt to the two
RC models already discussed.
10. In Example 7.9 try scale mixing with 	1 ¼ 	2 ¼ 4 as preset para-
meters, and assess ﬁt against the MVN using the predictive con-
cordancy approach used in Example 7.1.
11. In Example 7.11 obtain the posterior probability that 032 is less than
033 in the non-proportional model.
REFERENCES
Agresti, A. (2002) Categorical Data Analysis, 2nd edition. John Wiley & Sons:
New York.
Agresti, A. and Lang, J. (1993) Quasi-symmetric latent class models, with
application to rater agreement. Biometrics, 49, 131–139.
Albert, J. (1997) Bayesian testing and estimation of association in a two-
way contingency table. Journal of the American Statistical Association, 92,
685–693.
Albert, J. and Chib, S. (1993) Bayesian analysis of binary and polychotomous
response data. Journal of the American Statistical Association, 88, 669–679.
264
ORDINAL REGRESSION

Besag, J., Green, P., Higdon, D. and Mengersen, K. (1995) Bayesian computation
and stochastic systems. Statistical Science, 10, 1–41.
Chen, M., Shao, Q. and Ibrahim, J. (2000) Monte Carlo Methods in Bayesian
Computation. Springer: New York.
Chotikapanich, D. and Grifﬁths, W. (2000) Posterior distributions for the Gini
coefﬁcient using grouped data. Australian and New Zealand Journal of
Statistics, 42, 383–392.
Cox, C. (1995) Location-scale cumulative odds models for ordinal data: a
generalized nonlinear model approach. Statistics in Medicine, 14, 1191–1203.
Cox, D. and Snell, E. (1989) Analysis of Binary Data. Chapman and Hall: London.
Fahrmeier, L. and Tutz, G. (2001) Multivariate statistical modelling based on
generalized linear models. Springer: Berlin.
Gelfand, A. and Kuo, L. (1991) Nonparametric Bayesian bioassay including
ordered polytomous response. Biometrika, 78, 657–666.
Gibbons, R. and Hedeker, D. (2000) Applications of mixed-effect models in
biostatistics. Sankyha, 62B, 70–103.
Goodman, L. (1979) Simple models for the analysis of association in cross-
classiﬁcations having ordered categories. Journal of the American Statistical
Association, 74, 537–552.
Hastie, T. and Tibshirani, R. (1987) Generalized additive models: some applica-
tions. Journal of the American Statistical Association, 82, 371–386.
Hellmich, M., Abrams, K., Jones, D. and Lambert, P. (1998) A Bayesian approach
to a general regression model for ROC curves. Medical Decision Making, 18,
436–443.
Ishwaran, H. (2000) Univariate and multirater ordinal cumulative link regression
with covariate speciﬁc cutpoints. Canadian Journal of Statistics, 28, 715–730.
Ishwaran, H. and Gatsonis, C. (2000) A general class of hierarchical ordinal
regression models with applications to correlated ROC analysis. Canadian
Journal of Statistics, 28, 731–750.
Johnson, V. and Albert, J. (1999) Ordinal Data Modelling, Springer: New York.
Kakwani, N., Wagstaff, A. and van Doorslaer, E. (1997) Socioeconomic inequal-
ities in health: measurement, computation and statistical inference. Journal of
Econometrics, 77, 87–103.
Lang, J. (1999) Bayesian ordinal and binary regression models with a parametric
family of mixture links. Computational Statistics and Data Analysis, 31, 59–87.
Lee, T. and Wild, C. (1996) Vector general additive models. Journal of the Royal
Statistical Society, Series B, 58, 481–493.
Long, J. (1997) Regression Models for Categorical and Limited Dependent
Variables. Sage: Thousand Oaks, CA.
McCullagh, P. (1980) Regression models for ordinal data. Journal of the Royal
Statistical Society, Series B, 42, 109–142.
Murad, H., Fleischman, A., Sadetzki, S., Geyer, O. and Freedman, L. (2003)
Small samples and ordered logistic regression: does it help to collapse
categories of outcome? American Statistician, 57, 1–6.
REFERENCES
265

Nandram, B. (1997) Bayesian inference for the best ordinal multinomial popula-
tion in a taste test. In Case Studies in Bayesian Statistics, 3, Gatsonis, C.,
Hodges, J., Kass, R. and Singpurwall, N. (eds). Springer: New York.
Nandram, B. (1998) A Bayesian analysis of the three stage hierarchical multi-
nomial model. Journal of Statistical Computing and Simulation, 61, 97–126.
O’Brien, S. and Dunson, D. (2004) Bayesian multivariate logistic regression.
Biometrics, 60, 739–746.
Parmigiani, G., Ashih, H., Samsa, G., Duncan, P., Lai, S. and Matchar, D. (2003)
Cross-calibration of stroke disability measures: Bayesian analysis of long-
itudinal ordinal categorical data using negative dependence. Journal of the
American Statistical Association, 98, 273–281.
Peng, F. and Hall, W. (1996) Bayesian analysis of ROC curves using Markov-
chain Monte Carlo methods. Medical Decision Making, 16, 404–411.
Peterson, B. and Harrell, F. (1990) Partial proportional odds models for ordinal
response variables. Applied Statistics, 39, 205–217.
Ritov, Y. and Gilula, Z. (1991) The order-restricted RC model for ordered
contingency tables: estimation and testing for ﬁt. Annals of Statistics, 19,
2090–2101.
Simonoff, J. (2003) Analyzing Categorical Data. Springer: New York.
Spiegelhalter, D. and Marshall, E. (1999) Inference-robust institutional compar-
isons: a case study of school examination results. In Bayesian Statistics 6,
Bernardo, J., Berger, J., Dawid, A. and Smith, A. (eds). Oxford University
Press: Oxford, 613–630.
Tosteson, A. and Begg, C. (1988) A general regression methodology for ROC
curve estimation. Medical Decision Making, 8, 204–215.
Wagstaff, A. and van Doorslaer, E. (1994) Measurement of health inequalities in
the presence of multiple-category morbidity indicators. Health Economics, 3,
281–291.
266
ORDINAL REGRESSION

CHAPTER 8
Discrete Spatial Data
8.1
INTRODUCTION
Discrete data are frequent in ecological studies of social behaviour or
disease outcomes and it is here that many developments of recent
Bayesian methodology have occurred – see Wakeﬁeld et al. (2000), Bailey
(2001) and Pascutto et al. (2000) for reviews of spatial epidemiological
applications. The same issues occur for spatially conﬁgured count or rate
data as considered in Chapters 5 and 6: discrete data for areas often show
greater variability than under Poisson, multinomial or binomial sampling.
Event totals within districts cumulate over individual events that may be
clustered (e.g. within households). Such data are typically also accumu-
lated within discrete administrative areas, so that confounded with vari-
ability between areas due to real substantive inﬂuences, there is also that
due to arbitrary boundaries.
Hence, with mortality or morbidity data overdispersion in the observed
event counts may be to some degree spatially unstructured, but may also
reﬂect spatial correlation in underlying relative risks – that in turn may
reﬂect omitted risk factors (Pascutto et al., 2000; Besag et al., 1991)
straddling arbitrary boundaries. However, the possibly multiple form of
random effects in spatial data raises distinct identiﬁability and parame-
terization issues. For example, certain models may only be identiﬁable by
restricting certain random parameters within the set, or by enforcing identi-
ﬁability during the MCMC run (Carlin and Pe´rez, 2000). In this chapter
the focus is on discrete area analysis (e.g. using health counts for adminis-
trative areas). Recent progress in Bayesian geostatistics (i.e. in conti-
nuous space) has been substantial, exempliﬁed in the book by Banerjee
et al. (2004), and papers by Diggle et al. (1998) and Diggle et al. (2003).
Bayesian Models for Categorical Data
P. Congdon
# 2005 John Wiley & Sons, Ltd

8.2
UNIVARIATE RESPONSES: THE MIXED ICAR
MODEL AND EXTENSIONS
Let yi denote death totals in area i, with expected deaths Ei or populations
at risk Ti. Extra variability is usually modelled via a log-linear or logit-
linear regression as in (5.5). For example,
yi  PoiðEiiÞ
where i is the relative mortality risk. The mixed model of Besag et al.
(1991) has been seminal in terms of wider developments such as spatio-
temporal models and multivariate spatial models. The mixed model
proposes
logðiÞ ¼ Xi þ ui þ si
ð8:1Þ
where the spatially unstructured error ui is typically taken as normal with
constant variance
ui  Nð0; 2
uÞ
One possible joint density for the spatial effects s ¼ ðs1; . . . :; snÞ is in
terms of pairwise differences in errors, and a variance term ’2
s
PðsÞ / exp 0:5’2
s
X
i<j
ðsi  sjÞ2
"
#
An equivalent conditional speciﬁcation is obtained using the properties
of the multivariate normal (Besag and Kooperberg, 1995). Thus, the pre-
ceding joint density implies a conditional prior for area i, conditioning on
the effects sj in remaining areas j 6¼ i that are denoted s½i, namely
Pðsijs½i; 2
s Þ  Nð!i; ViÞ
ð8:2Þ
where !i is a weighted average
!i ¼
X
j
cijsj=
X
j
cij ¼
X
j
wijsj
The conditional variances Vi ¼ 2
s= P
j cij in (8.2) depend on the inter-
action structure represented by cij. Typical forms for cij are (a) binary
adjacency: cij ¼ 1 if areas i and j are neighbours, cij ¼ 0 otherwise (and
cii ¼ 0); and (b) distance decay: cij ¼ expðdijÞ where  > 0 and dij are
distances between the area centres (and cii ¼ 0). From cij the spatial
weights wij are obtained as row standardized interactions wij ¼ cij= P
j cij.
The more neighbours there are (deﬁnition a), or the closer they are
(deﬁnition b), the more precisely is si deﬁned (in terms of lower Vi).
268
DISCRETE SPATIAL DATA

Events yi may be modelled via a logistic linear regression when popu-
lations at risk Ti are small, not just the event totals yi (e.g. MacNab, 2003,
p 306), with yi  BinðTi; iÞ and the mixed model is accordingly
logitðiÞ ¼ Xi þ ui þ si
Aggregate multinomial data yi ¼ fyi1; . . . ; yiJg with J categories (e.g.
deaths by area due to different causes, or votes by constituency to
different parties, or households by census area with different religious
afﬁliations) may also be included in this framework. Thus one might
specify
yi  MJðyiþ; iÞ
ij ¼ expð
ijÞ=
X
k
expð
ikÞ

ij ¼ jXi þ uij þ sij
with a zero-mean multivariate normal model for uij, an identiﬁability
contraint on the j such as 1 ¼ 0 and the sij being spatial errors
constrained to sum to zero over areas and over categories j.
For some purposes (e.g. deﬁning priors for spatio-temporal effects) it
is useful to note that the joint prior for s ¼ ðs1; . . . ; snÞ can be expressed
as a multivariate normal of dimension n with mean 0 and precision
matrix sK, where s ¼ 1=2
s and the structure matrix K is deﬁned as
Kij ¼ cijði 6¼ jÞ, Kii ¼ P
j cij; see Mollie´ (1996), Lagazio et al. (2001)
and Clayton (1996).
The most common assumption in disease mapping is to deﬁne cij by
binary adjacency, so that
!i ¼ si
ð8:3aÞ
Vi ¼ 2
s=Ni
ð8:3bÞ
where si is the average of sj over the Ni neighbours of area i. When
interaction is speciﬁed by adjacency the structure matrix K is deﬁned as
Kij ¼ 1
if areas i and j are neighbours
¼ 0
for non-adjacent areas
¼ Ni
when i ¼ j
ð8:4Þ
This prior is termed the intrinsic conditional autoregression or ICAR
prior and poses identiﬁcation issues since it speciﬁes only differences in
log relative risks, and not the overall level of relative risk. To achieve
identiﬁcation of the si one may centre them at each iteration in an MCMC
run (Gelfand and Sahu, 1996). Other ways of achieving identiﬁcation are
UNIVARIATE RESPONSES
269

to set a single si to a ﬁxed value (e.g. s1 ¼ 0) or to omit the intercept in
the log-linear or log logistic regression.
There are also identiﬁcation issues regarding the separate random
effects in (8.1). Only the sum of ui and si is identiﬁed and the partitioning
of the variance between unstructured and spatial variation may be affect-
ed by prior speciﬁcations. The prior on the variances 2
s and 2
u or their
inverses s and u is especially relevant, e.g. in terms of the appropriate
balance between the two types of variation. Mollie´ (1996, p 372) suggests
using the inverse of the observed variance of the crude relative risks r ¼
1=VarðrÞ where ri ¼ yi=Ei. Thus u  Gaðcr; cÞ and s  Gaðcr=N; cÞ
where N is the average number of neighbours and c is a small constant
(e.g. c ¼ 0:01) that downweights the prior (data-based) information.
Bernardinelli et al. (1995) suggest the marginal standard deviation ’s
of the spatial effects be proportional to the conditional standard deviation
s. One may estimate ’s empirically during an MCMC run as the stan-
dard deviation, sdðsÞ, of the sampled sðtÞ
i
and then it is recommended that
sdðsÞ 
 s=ðN0:5
i
CÞ
with C ¼ 0:7
A neutral prior (with regard to the balance between independence and
spatial clustering) might then set
2
u ¼ 2
s=ðNC2Þ
ð8:5Þ
(see Carlin and Pe´rez, 2000). If preset values fas; bsg are used for the
spatial precision s  Gaðas; bsÞ then default choices such as as ¼ bs ¼
0:001 have been shown to put little mass on small variances, in contrast to
choices such as a ¼ 0:5, b ¼ 0:0005, as reecommended by Kelsall and
Wakeﬁeld (1999).
Some studies (e.g. Gelfand et al., 1998) report that both unstructured
and structured errors, namely ui and si, may not both be necessary in
many applications, and one may consider a reduced model retaining si but
without ui. This deﬁnes a pure spatial ICAR process
gðiÞ ¼ Xi þ si
This simpliﬁcation eliminates one form of identiﬁability issue but it is
still necessary to adopt devices such as centring the si at each iteration.
To obtain propriety and so avoid such devices, a spatial correlation
parameter  may be added (Sun et al., 2000), leading to the ICAR()
model, whereas (8.2) is the ICAR(1) model where  ¼ 1 by default. Thus
Pðsijs½i; ; 2
s Þ  Nð!i; ViÞ
ð8:6Þ
where !i is as above. So under binary adjacency, !i ¼ si in (8.6).
 2 ½0; 1 measures spatial association since the covariance between si
270
DISCRETE SPATIAL DATA

and sj is obtained as
2
s cij=
X
k
cik
X
k
cjk þ 2c2
ij
 
!
Another ICAR prior proposed as avoiding identiﬁability problems with
the mixed model (8.1) is suggested by Leroux et al. (1999) and applied
by MacNab (2003). This has joint form
Pðsj2; Þ  Nnð0; 2R1Þ
where the precision matrix is R ¼ K þ ð1  ÞI, with K an n  n struc-
ture matrix as in (8.4). The corresponding conditional form in the case
of binary adjacency is
Pðsijs½i; 2; Þ  N 
X
ji
sj=Di; 2=Di
 
!
ð8:7Þ
where j  i denotes that j is a neighbour of area i, and Di ¼ 1   þ Ni.
This reduces to an ICAR(1) prior when  ¼ 1 and to unstructured varia-
tion when  ¼ 0, so can be viewed as allowing for both types of variation,
spatially structured or unstructured.
Another spatial prior is based on the ‘multiple members’ model of
Langford et al. (1999) and Browne et al. (2001). Thus underlying
the spatial errors si are unstructured errors v, distinct from u in (8.1),
namely
si ¼
X
n
j¼1
wijvj
ð8:8aÞ
vi  Nð0; 2
vÞ
ð8:8bÞ
where the wij are row standardized spatial interactions. For binary
adjacency, si ¼ N1
i
P
ji vj. This framework has the beneﬁt that ui and
vi may be correlated and also provides one way of modelling multivariate
spatial effects and spatially non-constant predictor effects (section 8.5).
One may also extend it to allow a compromise prior as in (8.7). Thus for
underlying unstructured random effects vi1 and vi2, deﬁne
gðiÞ ¼ Xi þ si
where
si ¼ iN1
i
X
ji
vj1 þ ð1  iÞvi2
and i is a beta mixture, i  Beðk; kÞ, with k known.
UNIVARIATE RESPONSES
271

Example 8.1
Glasgow cancer deaths
This example uses data from
Langford et al. (1999) on cancer deaths in 143 Glasgow postcode sectors,
with a deprivation score (Carstairs index) as the single predictor Xi.
Among other features of these data, overdispersion (s2
y ¼ 160 compared
with y ¼ 22:3) may be noted. Because of this, as well as likely spatial
structuring of mortality, some sort of strategy involving pure hetero-
geneity and spatial correlation is suggested, as in the mixed model of
(8.1). To assess outliers (or areas not well ﬁtted by the model) the usual
CPO diagnostics are obtained as well as the mixed predictive p values
mentioned in Chapter 2 (Marshall and Spiegelhalter, 2003). Thus yi is
compared with the replicate data zi to gauge if it is extreme in terms of
this predictive density, via p values:
Pc ¼ Prðzi < yiÞ þ 0:5 Prðzi ¼ yiÞ
To identify the mixed ICAR(1) model of Besag et al. (1991), with si as
in (8.2), one strategy is to omit the intercept, so that
logðiÞ ¼ logðEiÞ þ Xi þ ui þ si
with predicted deaths in area i being ^Yi ¼ Eii where i is the posterior
mean.
The ﬁrst analysis sets Gað1; 0:01Þ priors on the precisions u ¼ 1=2
u
and s ¼ 1=2
s. To assess the relative importance of clustering vs. unstruc-
tured heterogeneity one can monitor the ratio
Rs ¼ sdðsÞ=½sdðsÞ þ sdðuÞ
where sdðsÞ is based on taking the standard deviation of the sampled si at
any iteration. This shows the two components to be roughly equal in size,
with Rs ¼ 0:47. The mixed model seems to provide an adequate account
of the overdispersion, with the predictive check (comparing the ratios
s2
z=z for data z replicated from the model with the observed ratio) stand-
ing at 0.77.
For estimates of the effective parameter count one may use the DIC
method or the chi-square approximation noted by Gelman et al. (2003,
p 182). The latter tends to show higher effective parameters in complex
random effects models and accordingly d
e ¼ 51:5 under the chi-square
method as against de ¼ 26 under the DIC method ðDIC ¼ 823:4Þ.
Finally, the regressor effect has mean  ¼ 0:025 with a 95% interval
(0.016, 0.034).
Instead one may use the principle in (8.5) to set a higher mean on the
prior precision u than on s. Thus with s  Gað1; 0:01Þ we take u 
Gaðhu; 0:01Þ where hu ¼ 0:72(5.44) with 5.44 being the average N of
272
DISCRETE SPATIAL DATA

neighbours. This reduces d
e to 44.8 and de to 21.6 (DIC ¼ 822.4) and Rs
now stands at 0.49. Relatively poor ﬁts under this model are obtained
for case 18 (Y18 ¼ 13, ^Y18 ¼ 24:4, log CPO ¼ 6:5) and case 49 (Y49 ¼
43, ^Y18 ¼ 30:6, log CPO ¼ 6) and three more areas (47, 82, 88) have
CPOs under 1% of the highest CPO. Mixed predictive checks for this
model (Marshall and Spiegelhalter, 2003) show four areas (42, 49, 82, 88)
with Pc values over 0.95 and ﬁve areas (18, 38, 47, 103, 109) have Pc
values under 0.05. The most extreme points are 18 ðPc ¼ 0:002Þ and 49
ðPc ¼ 0:991Þ.
Model B applies the mixture model (in version 1.3) but with si proper
according to (8.6). This gives a median  of 0.62 and DIC via (2.17b) of
823.5 with de ¼ 24:7. Instead of a mixed model (8.1) one may instead
apply a model which incorporates both clustering and heterogeneity as
extremes. Thus the Leroux et al. (1999) model in (8.7) is applied with
Ga(1,0.01) prior on 2. We ﬁnd  ¼ 0:85 with a relatively wide 95%
interval (0.55, 0.995). This leads to a worse DIC (837.6) with higher
effective parameters (de ¼ 53, d
e ¼ 63) perhaps partly because the
conditional prior for si involves the ratio =ð1   þ NiÞ and hence a
loss of sampling precision. The impact of the predictor is slightly reduced
with  ¼ 0:022.
8.3
SPATIAL ROBUSTNESS
While spatial patterns are often continuous (adjacent areas have similar
patterns) there are circumstances leading to discontinuities in behavioural
or disease patterns over space (e.g. a spatial error model will not be appro-
priate for deprived high-mortality areas surrounded by afﬂuent lower
mortality areas). Greater robustness in the spatial error in (8.1) may be
achieved by a scale mixture of normal densities or by heavier tailed
alternatives such as the double exponential DE or Laplace prior (Besag,
1989)
PðsjÞ / 0:5 exp

0:5
X
i<j
jsi  sjj2

ð8:9Þ
where smaller values of the scaling parameter  imply lower spatial
variability. With binary spatial interaction, the conditional prior is double
exponential with mean !i ¼ si and variance Vi ¼ 2
s=Ni. One may pre-
multiply the average of neighbouring values under this prior as in (8.6)
giving a DE() prior.
Non-parametric mixtures for modelling discontinuities have also been
considered (e.g. Militino et al., 2001; Knorr-Held and Rasser, 2000;
SPATIAL ROBUSTNESS
273

Fernandez and Green, 2002). Lawson and Clark (2002) propose a mixture
of the CAR and heavy-tailed densities for different spatial errors, such as
logðiÞ ¼ Xi þ ui þ isi1 þ ð1  iÞsi2
ð8:10Þ
where si1 is ICAR(1) or ICAR(), si2 might be double exponential and i
is a beta mixture, i  Betaðk1; k2Þ where k1 and k2 are preset for identi-
ﬁability. The same idea may be applied to the mixture model of (8.1) so
that greater emphasis is put on the unstructured error in areas that show
discontinuities with respect to neighbouring areas:
logðiÞ ¼ Xi þ iui þ ð1  iÞsi
ð8:11Þ
One might make the unstructured error follow a Student t model here to
allow for outliers (Pascutto et al., 2000).
Discrete mixture approaches may also be used for robust spatial data
analysis. For instance, one may adapt the prior of (8.8) to be deﬁned by
an underlying non-parametric mixture (Congdon, 2004). Thus the under-
lying vi may be drawn from a discrete mixture with a known number J of
components or, as in a DPP model, with an unknown and stochastically
varying total of components. Under the latter option one might deﬁne
categorical indicators for area i
Di  CategoricalðÞ
where  is of length M (M less than or equal to n), and updated using an
appropriate prior such as the stick breaking prior with concentration
parameter s. Associated with each cluster k is a value Vkðk ¼ 1; . . . ; MÞ
drawn from the baseline prior G0 (that might be normal or Student t).
Then if at a particular iteration DðtÞ
j
¼ k, for areas j 6¼ i, one obtains
sðtÞ
i
¼
X
n
j¼1
wijVDðtÞ
j
ð8:12Þ
One might also model the unstructured error in (8.1) in terms of a discrete
mixture rather than a parametric random effect, e.g. via a standard mix-
ture of normals (see Clayton and Kaldor, 1987) or
ui  DPPðu; G0Þ
where G0 might be a normal density.
Fernandez and Green (2002) propose modelling spatial interaction
effects via the weights in a discrete mixture. Thus
yi 
X
J
j¼1
ij PoðEiijÞ
274
DISCRETE SPATIAL DATA

where ij is a regression mean differing in intercepts or other regression
effects. Thus suppose a ﬁxed number of categories M. Then generate J
sets of n underlying spatially correlated effects qij from a proper density
such as (8.6) or (8.7) (as opposed to the CAR(1) prior). The qij are con-
verted to area-speciﬁc mixture weights ij via
ij ¼ expðqij=Þ= 1 þ
X
J
k¼1
expðqik=Þ
"
#
where  is a positive tuning parameter. As  tends to inﬁnity the ij tend
to 1=J without any spatial patterning, whereas small values of  act to
reduce overshrinkage.
Example 8.2
Robust models for Glasgow data
The analysis in
Example 8.1 revealed some poorly ﬁt cases, raising the possibility that
robust models with special mixture or heavy-tailed density features
might improve ﬁt. Consider, ﬁrst of all, a beta mixture on ICAR and DE
spatial priors together with an unstructured effect. Thus
logðiÞ ¼ Xi þ ui þ isi1 þ ð1  iÞsi2
si1  ICARð1Þ
si2  DEð2Þ
This raises the DIC to 861 (i.e. ﬁt deteriorates) and has de ¼ 82. The ﬁt to
cases 18 and 49 does improve slightly, however, and their CPOs relative
to the maximum CPO rise above 0.01.
If the unstructured error is excluded, then de falls considerably (to
around 12) and the DIC stands at 822.5. However, the CPOs for cases 18
and 49 worsen considerably (log CPOs of 6.5 and 6.25 respectively
against a maximum of 0.1). This suggests a beneﬁt from including an
unstructured error. Hence model C follows (8.11). This leads to a very
similar ﬁt to the mixed spatial error model (DIC ¼ 822.1, de ¼ 17)
without any marked improvement or worsening in the ﬁt to cases 18
and 49.
8.4
MULTIVARIATE SPATIAL PRIORS
Suppose multivariate observations of dimension M are observed for each
area. For example, suppose the responses for n areas consist of multi-
variate counts
fy11; y12; . . . ; y1M; y21; y22; . . . ; y2M; . . . ; yn1; yn2; . . . ; ynMg
MULTIVARIATE SPATIAL PRIORS
275

which might for instance be data on numbers ill and numbers dying from
a particular cause. Let yi ¼ ðyi1; . . . ; yiMÞ0. One might propose models for
the means of yim as follows:
gðimÞ ¼ Xim þ uim þ sim
ð8:13Þ
While independent priors for each sim are feasible, one might suppose
intercorrelation often exists between sik and sim ðk 6¼ mÞ.
One prior allowing for multivariate interdependence for Si ¼ ðsi1;
si2; . . . ; siMÞ0 is proposed by Gelfand and Vounatsou (2003) and gener-
alizes the ICAR() model of Sun et al. (1999). This provides the MCAR
ð; Þ prior where  is a scalar, with
PðSijS½i; ; Þ ¼ NM

X
j
WijSj; =
X
j
cij
 
!
ð8:14Þ
where  is an M  M covariance matrix and Wij ¼ wijIMM. If  is set to
one then identiﬁability requires devices such as centring each of the M
sets of effects at each iteration. Gamerman et al. (2002) also discuss the
MCAR(1,) prior in connection with spatially varying predictor effects
(section 8.5 below).
A generalization of (8.14) to a vector  ¼ ð1; . . . ; MÞ is complicated
by the symmetry requirement for the covariance matrix in the corres-
ponding joint prior, though Gelfand and Vounatsou (2003) suggest a
method of circumventing this. If correlations between the unstructured
effects in (8.13) are required, then Ui ¼ ðui1; ui2; . . . ; uiMÞ may be taken
as multivariate normal of order M.
An alternative way to allow for correlation between spatial errors is
via a spatial common factor model (Congdon, 2004; 2002; Wang and
Wall, 2003). Thus a model with one spatial factor might be
gði1Þ ¼ Xi1 þ ui1 þ 1si
gði2Þ ¼ Xi2 þ ui2 þ 2si
..
.
gðiMÞ ¼ XiM þ uiM þ Msi
ð8:15Þ
where for identiﬁcation one of the m is preset (e.g. 1 ¼ 1) or the
variance of si is ﬁxed. Additionally if a CAR(1) prior is used for si then
sampled values sðtÞ
i
must be centred at each iteration. A constraint such as
1 ¼ 1 assists in the avoidance of label switching, which affects factor
analysis as well as discrete mixtures (Congdon, 2003a).
276
DISCRETE SPATIAL DATA

Example 8.3
Joint life table
This example considers an analysis by
Congdon (2002) concerning mortality and health data drawn from the
1991 Census and from vital statistics returns for 44 small areas in NE
London. Health data relate to the year 1991 and deaths to the ﬁve-year
periods 1988–1992 and 1993–1997. The data are by age x (19 ﬁve-year
bands up to 90þ), gender s, area i and additionally by period t for deaths
only. Populations are denoted Ptixs. Well populations are deﬁned as total
populations minus the long-term ill.
A different model is assumed for ages up to 65 and ages over 65. Speci-
ﬁcally, a shared ICAR(1) spatial effect ’i for ages under 65 reﬂects the
expectation that good health and mortality will be negatively correlated.
It is at these ages that deprivation has the strongest effect on mortality and
that a latent spatial effect (proxying deprivation) is arguably more rele-
vant. So ’i has a preset loading of 1 in the health model and a free
loading ! in the deaths model.
For ﬁve-year age groups x ¼ 1; . . . ; 13 (where x ¼ 13 for ages 60–64),
deaths Ytixs  PoiðPtixstixsÞ and well populations Hixs  BinðPixs; ixsÞ,
the model means are
logðtixsÞ ¼ c11 þ 1t þ m
x;s þ umi þ !’i
logitði;x;sÞ ¼ c21 þ h
x;s þ uhi  ’i:
For higher ages (x ¼ 14 to x ¼ 19) the model is
logðtixsÞ ¼ c12 þ 2t þ m
x;s þ umi
logitði;x;sÞ ¼ c22 þ h
x;s þ uhi:
Of interest as model outputs (structural parameters) are total and healthy
life expectancies and the difference between the two which deﬁnes the
‘disease burden’.
From a two-chain run of 3000 iterations (a 1000 burn-in), Table 8.1
shows the high association (correlation 0.93) between posterior means of
the spatial factor 100 expð’iÞ and actual government index of multiple
deprivation (IMD) scores. The correlation with the Jarman deprivation
score (also used in health need applications) is 0.89. The loading ! has
mean 0.65 with a 95% interval (0.55,0.76), so both morbidity and morta-
lity are reﬂected in the factor score. This example therefore illustrates
how spatial effects may proxy real substantive inﬂuences (cf. Pascutto
et al., 2000).
MULTIVARIATE SPATIAL PRIORS
277

Table 8.1
Spatial factor and deprivation scores
Area
Area
Jarman UPA
Life table common
Index of multiple
number
(ward)
deprivation
spatial effect
deprivation
name
score
(exponentiated and 100)
score
1
Abbey
39.8
149.2
44.91
2
Alibon
17.5
136.6
42.91
3
Cambell
14.5
119.2
38.84
4
Chadwell Heath
6.6
91.2
21.48
5
Eastbrook
4.9
97.7
26.07
6
Eastbury
18.0
119.8
36.47
7
Fanshawe
19.2
129.5
45.34
8
Gascoigne
55.1
170.4
50.29
9
Goresbrook
20.9
131.8
38.96
10
Heath
27.1
119.1
40.93
11
Longbridge
1.3
78.6
17.30
12
Manor
18.5
132.8
43.00
13
Marks Gate
28.9
115.6
42.47
14
Parsloes
14.5
145.9
39.62
15
River
16.4
114.6
33.33
16
Thames
34.3
121.1
40.94
17
Triptons
16.7
129.8
39.33
18
Valence
20.5
143.2
37.92
19
Village
22.4
103.9
41.70
20
Airﬁeld
6.3
94.1
17.81
21
Ardleigh Green
14.2
82.8
6.86
22
Brooklands
7.5
79.7
18.51
23
Chase Cross
8.3
103.9
27.43
24
Collier Row
7.8
95.4
18.31
25
Cranham East
12.9
67.4
10.03
26
Cranham West
25.8
67.6
3.69
27
Elm Park
9.7
82.0
10.47
28
Emerson Park
20.1
69.0
7.05
29
Gidea Park
20.3
58.9
7.02
30
Gooshays
18.5
127.2
36.02
31
Hacton
8.8
82.1
11.82
32
Harold Wood
9.9
83.0
10.16
33
Heath Park
5.0
73.4
10.92
34
Heaton
14.6
142.1
35.04
35
Hilldene
22.5
146.3
42.33
36
Hylands
4.1
73.5
11.77
37
Mawney
2.2
87.6
16.57
38
Oldchurch
10.9
115.9
22.61
39
Rainham
7.3
86.0
17.25
40
Rise Park
13.6
73.2
10.49
41
St. Andrew’s
6.0
69.5
12.06
42
St. Edward’s
3.4
90.9
16.55
43
South Hornchurch
0.3
100.7
26.32
44
Upminster
17.2
64.0
3.27
278
DISCRETE SPATIAL DATA

8.5
VARYING PREDICTOR EFFECT MODELS
Developments in spatial epidemiology in the 1990s focused on variations
between small areas in incidence or mortality and interpreted such varia-
tions as due to unobserved factors which vary smoothly over space. A
spatially correlated ‘error’ term was used to describe such effects. By
contrast, the impact of known predictors was generally assumed homo-
geneous, i.e. not spatially varying. In many applications in both spatial
econometrics and disease mapping it is likely that regression effects
are not in fact constant over a region, and spatially varying regression
coefﬁcients are deﬁned as one form of spatial heterogeneity by Anselin
(2001).
In geographical applications the spatial expansion model and Bayesian
geographically weighted regression (LeSage, 2004) allow for regression
heterogeneity, though have focused on metric responses. By contrast,
developments in the Bayesian epidemiology perspective include
Gamerman et al. (2003) and Congdon (2003b), while Congdon (1997)
describes a spatially varying regression coefﬁcient model for a univariate
Poisson outcome.
One might adopt the MCAR models of section 8.4 to model spatial
regression heterogeneity. Assume all p predictors can have spatially non-
constant effects so that for yi in the exponential family (e.g. Poisson,
binomial) with mean i, one has
gðiÞ ¼ 0 þ Xii
ð8:16Þ
where Xi ¼ ðxi1; xi2; . . . ; xipÞ and i ¼ ði1; i2; . . . ; ipÞ0 is p  1. The
relevant pairwise difference MCAR(1) joint prior has the form
Pðj#Þ / j#j0:5n exp 0:5
X
n
i6¼j
cijði  jÞ0#1ði  jÞ
"
#
ð8:17aÞ
where  ¼ ð1; . . . ; nÞ and # is a dispersion matrix. The conditional
form under binary adjacency is
ij P
; ½i  Np i; P
 =Ni
	

ð8:17bÞ
where P
 is the conditional dispersion matrix, and ð i ¼ i1; . . . ;
ipÞ where ik is the average of jk over the j ¼ 1; . . . ; Ni neighbours
of area i. The overall average effects Bk of predictor k are obtained as the
average of ik.
VARYING PREDICTOR EFFECT MODELS
279

A mixed prior analogous to (8.1) for the i in (8.16), as in
i ¼ s
i þ u
i
where s
i follows (8.17) and u
i  Npð0; P
uÞ is spatially unstructured, is
likely to be difﬁcult to identify. However, robust versions of (8.17) such
as heavier tailed densities may be used if there is irregularity in the
spatially varying regressor effects.
Another approach extends the spatial intercepts method of Leyland
et al. (2000), Browne et al. (2001) and Langford et al. (1999) to obtain
spatially varying regression coefﬁcients for univariate or multivariate
outcomes. For example, consider an M-variate count response ðyi1;
yi2; . . . ; yiMÞ with means ðEi1i1; Ei2i2; . . . ; EiMiMÞ and p predictors.
Then let
logði1Þ ¼ 1 þ i11xi1 þ i21xi2 þ i31xi3 þ    þ ip1xip þ ui1 þ si1
logði2Þ ¼ 2 þ i12xi1 þ i22xi2 þ i32xi3 þ    þ ip2xip þ ui2 þ si2
...
logðiMÞ ¼ M þ i1Mxi1 þ i2Mxi2 þ i3Mxi3 þ    þ ipMxip þ uiM þ siM
ð8:18aÞ
It is possible to adopt separate priors for each of ðp þ 2ÞM possible
effects. However, to allow interdependence between all effects including
the unstructured error, one may assume underlying unstructured errors vi
of dimension ðp þ 2ÞM or possibly lower.
Consider an example with M ¼ 2 and p ¼ 3; then vi ¼ ðvi1; vi2; . . . ;
vi;10Þ is of dimension 10 and linked to the spatial regression coefﬁcients
and varying intercepts as follows:
i11 ¼
X
n
j¼1
wijvj1
i12 ¼
X
n
j¼1
wijvj6
i21 ¼
X
n
j¼1
wijvj2
i22 ¼
X
n
j¼1
wijvj7
i31 ¼
X
n
j¼1
wijvj3
i32 ¼
X
n
j¼1
wijvj8
si1 ¼
X
n
j¼1
wijvj4
si2 ¼
X
n
j¼1
wijvj9
ui1 ¼ vj5
ui2 ¼ vj10
ð8:18bÞ
280
DISCRETE SPATIAL DATA

Then one might take the vi ¼ ðvi1; vi2; . . . ; vi;10Þ to be parametric random
effects, e.g. multivariate normal of order 10 with dispersion matrix P
v
and mean !v ¼ ðB11; B21; B31; 0; 0; B12; B22; B32; 0; 0Þ. Thus the means of
the effects fvi4; vi5; vi9; vi10g underlying the spatial intercepts are zero,
but the remainder are outcome-speciﬁc average effects Bkmðk ¼ 1; . . . ;
3; m ¼ 1; 2Þ of the predictors X1, X2 and X3.
It may be possible to omit intercept variation (if deviations are not
spatially correlated) so that (8.18a) reduces to
logði1Þ ¼ 1 þ i11xi1 þ i21xi2 þ i31xi3 þ    þ ip1xip
logði2Þ ¼ 2 þ i12xi1 þ i22xi2 þ i32xi3 þ    þ ip2xip
..
.
logðiMÞ ¼ M þ i1Mxi1 þ i2Mxi2 þ i3Mxi3 þ    þ ipMxip
ð8:18cÞ
In this case the MVN or MVT prior would be of dimension Mp, and in the
above example
i11 ¼
X
n
j¼1
wijvj1
i12 ¼
X
n
j¼1
wijvj4
i21 ¼
X
n
j¼1
wijvj2
i22 ¼
X
n
j¼1
wijvj5;
i31 ¼
X
n
j¼1
wijvj3
i32 ¼
X
n
j¼1
wijvj6
ð8:18dÞ
While the covariance matrix v in such models may be taken as unstruc-
tured, reduced parameterizations are possible, such as those allowing
correlations between parallel effects (e.g. correlations between vi1 and vi6,
and hence between i11 and i12; between vi2 and vi7 and hence between
i21 and i22, and so on).
A spatial factor approach to spatially varying coefﬁcients also provides
a reduced parameterization. For M outcomes and p predictors vi is of
dimension Mp. A simpliﬁcation is to assume a single factor (or possibly
factors) underlying the spatial effects ikm for predictor k. Thus let Fik be a
VARYING PREDICTOR EFFECT MODELS
281

single such factor, and deﬁne for k ¼ 1; . . . ; p
ik1 ¼ k1
X
n
j¼1
wijFjk
ik2 ¼ k2
X
n
j¼1
wijFjk
...
ikM ¼ kM
X
n
j¼1
wijFjk
ð8:19Þ
Then Fi ¼ ðFi1; . . . ; FipÞ is of dimension p, and might be modelled as
multivariate normal. For identiﬁability the loadings k1ðk ¼ 1; . . . ; pÞ
may be preset (e.g. to one) leaving pðM  1Þ free loadings.
Finally robust spatial regression models based on non-parametric
approaches may be considered. Thus the underlying vi in (8.18c) may
be drawn from a discrete mixture with a known number J of components
or, as in a DPPðG0; Þ model, an unknown and stochastically varying
total of components under a baseline prior G0 and concentration
parameter . Under the latter option deﬁne categorical indicators for
area i,
Di  CategoricalðÞ
where  is of length C (C less than or equal to n), and updated using
an appropriate prior such as the stick breaking prior. Associated with
each cluster c is a value Vc ¼ ðvc1; vc2; . . . ; vc;MpÞðc ¼ 1; . . . ; CÞ drawn
from the baseline prior G0 (that might be multivariate normal or
Student t of dimension Mp). Then if at a particular iteration
t ¼ 1; . . . ; T the selected cluster for area j is cj ¼ DðtÞ
j , one obtains
ikm as a spatially ﬁltered average of vcjh ðh ¼ 1; . . . ; MpÞ. Thus (8.18d)
is replaced by
i11 ¼
X
n
j¼1
wijvcj1
i12 ¼
X
n
j¼1
wijvcj4
i21 ¼
X
n
j¼1
wijvcj2
i22 ¼
X
n
j¼1
wijvcj5
i31 ¼
X
n
j¼1
wijvcj3
i32 ¼
X
n
j¼1
wijvcj6
ð8:20Þ
282
DISCRETE SPATIAL DATA

The means fB11; B21; B31; B12; B22; B32g are obtained by averaging the
ðtÞ
ikm over areas and iterations.
Example 8.4
Varying effect of suicide risk factors
A varying regres-
sion effect model for male and female suicides in 1989–1993 in 354
English local authorities is considered. There are three predictors – a
social fragmentation score, a deprivation score and a rurality score1 – each
of which has a varying predictor effect. Alternative models (A and B) as
in (8.17) and (8.18) are considered as well as a spatial factor model
(model C) as in (8.19). The model under (8.18) is then yim  PoiðEimimÞ
for m ¼ 1; 2 with
logði1Þ ¼ 1 þ i11xi1 þ i21xi2 þ i31xi3
logði2Þ ¼ 2 þ i12xi1 þ i22xi2 þ i32xi3
Under (8.17) the intercepts are omitted for identiﬁability. Fit is assessed
using the DIC and pseudo marginal likelihood (PsML) of Gelfand (1996),
while cross-validatory predictive checks for individual areas are based on
Marshall and Spiegelhalter (2003). Additionally, the Moran I statistic is
calculated from model residuals yim  ^yim to assess whether varying
intercepts uim and sim are required in addition to spatially varying regres-
sion effects. Note that allowing for spatially varying regression may avoid
the need for spatial errors (Fotheringham et al., 2003), in the sense that
model deviations are no longer spatially correlated.
With the prior in (8.17), average predictor effects Bkm are found to be
all signiﬁcantly positive for males, but only social fragmentation has a
clear positive effect on female suicide (Table 8.2). It is also apparent that
the Moran I is not different from zero, so there is no residual spatial
correlation. Mean regression effects under (8.18) are similar but the ﬁt
appears to improve slightly. The correlation between the 354 values of
i11 under model A and under model B is 0.75. For the ﬁve other coefﬁ-
cients (i21 through to i32) the correlations are 0.77, 0.78, 0.80, 0.77 and
0.88. So the spatially varying regression coefﬁcients seem to be reason-
ably stable over the two models. The Moran coefﬁcient is also satisfac-
tory under model B.
The Marshall and Spiegelhalter (2003) diagnostics show more diver-
gencies (P values over 0.975 or under 0.025) for model B than model A,
i.e. 35 vs. 18 in 758 observations (N ¼ 354 male suicide totals, N ¼ 354
1 Social fragmentation combines people not married, population turnover, one-person households and
‘bedsitter’ (private rented) accommodation. Deprivation combines unemployment, social groups IV
and V, no-car households and social renting. Rurality is based on agricultural workers and population
density (negatively weighted).
VARYING PREDICTOR EFFECT MODELS
283

female suicide totals). However a Q–Q plot of the P values for model B
against the 2N order statistics 1=ð2N þ 1Þ of a uniform (0,1) distribution
appears satisfactory (Figure 8.1).
Model C as would be expected has fewer effective parameters and also
does not lead to any major loss in goodness of ﬁt. Both the DIC and
PsML improve slightly. There are again 35 divergent areas as per
Table 8.2
Mean regression effects (spatial regression heterogeneity)
Mean regression effect
2.5%
Median
97.5%
Model A
Male, social fragmentation
0.047
0.085
0.123
Male, deprivation
0.004
0.041
0.079
Male, rurality
0.023
0.061
0.100
Female, social fragmentation
0.084
0.136
0.188
Female, deprivation
0.042
0.005
0.053
Female, rurality
0.070
0.023
0.035
Moran (males)
0.038
0.025
0.090
Moran (females)
0.023
0.033
0.091
DIC
4573
de
295
PsML
2312
Model B
Male, social fragmentation
0.039
0.085
0.131
Male, deprivation
0.015
0.059
0.101
Male, rurality
0.023
0.067
0.111
Female, social fragmentation
0.083
0.148
0.211
Female, deprivation
0.038
0.014
0.071
Female, rurality
0.070
0.007
0.059
Moran (males)
0.041
0.019
0.080
Moran (females)
0.014
0.045
0.103
DIC
4556
de
257
PsML
2303
Model C
Male, social fragmentation
0.059
0.100
0.140
Male, deprivation
0.007
0.048
0.091
Male, rurality
0.022
0.065
0.110
Female, social fragmentation
0.087
0.140
0.199
Female, deprivation
0.002
0.027
0.062
Female, rurality
0.014
0.014
0.051
Moran (males)
0.034
0.022
0.081
Moran (females)
0.064
0.102
0.137
DIC
4547
de
180
PsML
2293
284
DISCRETE SPATIAL DATA

Marshall and Spiegelhalter (2003) and the Q–Q plot is in line with a
uniform distribution. However, the Moran statistic for females is no
longer satisfactory.
EXERCISES
1. In Example 8.1 assess how far the model in (8.7) affects ﬁt to the
extreme areas (e.g. 18, 49) identiﬁed under the mixed ICAR model.
2. In Example 8.2 (model C) try a scale mixture version of the normal for
the unstructured error
ui  Nð0; 1=ðuiÞÞ
with
i  Gað0:5	; 0:5	Þ
(equivalent to Student t with 	 degrees of freedom). Assess changes in
ﬁt to the suspect cases and in overall terms.
Figure 8.1
QQ plot for P values, Model B
EXERCISES
285

3. In Example 8.3 try the common spatial factor model for all ages, not
just ages under 65. First try a single error ’i for all ages and then two
errors ’i1 and ’i2 for ages under and over 65. Under the ﬁrst option
assess how far the correlation between 100 expð’iÞ and the IMD score
changes when the model extends to all ages. Under the second option
assess how far the estimated disease burden by area is affected.
REFERENCES
Anselin, L. (2001) Spatial econometrics. In A Companion to Theoretical Econo-
metrics, B. Baltagi (ed.). Oxford: Basil Blackwell, 310–330.
Bailey, T. (2001) Spatial statistical analysis in health. Cadernos de Saude Publica,
17, 1083–1098.
Banerjee, S., Carlin, B. and Gelfand, A. (2004) Hierarchical Modeling and
Analysis for Spatial Data. Chapman and Hall: London/CRC Press Boca
Raton, FL.
Bernardinelli, L., Clayton, D. and Montomoli, C. (1995) Bayesian estimates of
disease maps: how important are priors? Statistics in Medicine, 14, 2411–2431.
Besag, J. (1989) Towards Bayesian image analysis. Journal of Applied Statistics,
16, 395–407.
Besag, J. and Kooperberg, C. (1995) On conditional and intrinsic autoregression.
Biometrika, 82, 733–746.
Besag, J., York. J. and Mollie´, A. (1991) Bayesian image restoration with two
applications in spatial statistics. Annals of the Institute of Statistics and
Mathematics, 43, 1–59.
Browne, W., Goldstein, H. and Rasbash, J. (2001) Multiple membership multiple
classiﬁcation (MMMC) models. Statistical Modelling, 1, 103–124.
Carlin, B. and Pe´rez, M. (2000) Robust Bayesian analysis in medical and
epidemiological settings. In Robust Bayesian Analysis, Lecture Notes in
Statistics 152, Insua, D. R. and Ruggeri, F. (eds). Springer: New York,
351–372.
Clayton, D. (1996) Generalized linear mixed models. In Markov Chain Monte
Carlo in Practice, Gilks, W., Richardson, S. and Spiegelhalter, D. (eds).
Chapman and Hall: London, 275–301.
Clayton, D. and Kaldor, J. (1987) Empirical Bayes estimates of age-standardized
relative risks for use in disease mapping. Biometrics, 43, 671–681.
Congdon, P. (1997) Bayesian models for the spatial structure of rare health
outcomes: a study of suicide using the BUGS program. Journal of Health and
Place, 3(4), 229–247.
Congdon, P. (2002) A life table approach to small area health need proﬁling.
Statistical Modelling, 2, 1–26.
Congdon, P. (2003a) Applied Bayesian Modelling. John Wiley & Sons:
Chichester.
286
DISCRETE SPATIAL DATA

Congdon, P. (2003b) Modelling spatially varying impacts of socioeconomic
predictors on mortality outcomes. Journal of Geographical Systems, 5,
161–184.
Congdon, P. (2004) A multivariate model for spatio-temporal health outcomes
with an application to suicide mortality. Geographical Analysis, 36, 234–258.
Diggle, P., Moyeed, R. and Tawn, J. (1998) Model based geostatistics. Applied
Statistics, 47, 299–350.
Diggle, P., Ribeiro, P. and Christensen, O. (2003) An introduction to model-based
geostatistics. In Spatial Statistics and Computational Methods, Lecture Notes
in Statistics 173, Møller, J. (ed.). Springer: New York.
Fernandez, C. and Green, P. (2002) Modelling spatially correlated data via
mixtures: a Bayesian approach. Journal of the Royal Statistical Society, Series
B, 64, 805–826.
Fotheringham, A., Charlton, M. and Brunsdon, C. (2003) Geographically
Weighted Regression. John Wiley & Sons: Chichester.
Gamerman, D., Moreira, A. and Rue, H. (2003) Space-varying regression models:
speciﬁcations and simulation. Computational Statistics and Data Analysis, 42,
513–533.
Gelfand, A. (1996) Model determination using sampling-based methods. In
Markov Chain Monte Carlo in Practice, W. Gilks, S. Richardson and D.
Spiegelhalter (eds). Chapman and Hall: London, 145–161.
Gelfand, A. and Sahu, S. (1996) Identiﬁability, propriety, and parameterization
with regard to simulation-based ﬁtting of generalized linear mixed models.
Technical Report 96–36, University of Connecticut, Dept. of Statistics.
Gelfand, A. and Vounatsou, P. (2003) Proper multivariate conditional autore-
gressive models for spatial data analysis. Biostatistics, 4, 11–15.
Gelfand, A., Ghosh, S., Knight, J. and Sirmans, C. (1998) Spatio-temporal
modeling of residential sales markets. Journal of Business & Economic
Statistics, 16, 312–321.
Gelman, A., Carlin, J., Stern, H. and Rubin, D. (2003) Bayesian Data Analysis,
2nd Edition. CRC Press: Boca Raton, FL.
Kelsall, J. and Wakeﬁeld, J. (1999) Discussion of ‘Bayesian models for spatially
correlated disease and exposure data’, by Best, N., Waller, L., Thomas, A.,
Conlon, E. and Arnold R. In Bayesian Statistics 6: Proceedings of the Sixth
Valencia Meeting on Bayesian Statistics, Bernardo, J., Berger, J., Dawid, A.
and Smith, A. (eds). Oxford University Press: Oxford.
Knorr-Held, L. and Rasser, G. (2000) Bayesian detection of clusters and
discontinuities in disease maps. Biometrics, 56, 13–21.
Lagazio, C., Dreassi, E. and Biggeri, A. (2001) A hierarchical Bayesian model for
the analysis of spatio-temporal variation in disease risk. Statistical Modelling,
1, 17–29.
Langford, I., Leyland, A., Rasbash, J. and Goldstein, H. (1999) Multilevel
modelling of the geographical distributions of rare diseases. Journal of the
Royal Statistical Society, Series C, 48, 253–268.
REFERENCES
287

Lawson, A. and Clark, A. (2002) Spatial mixture relative risk models applied to
disease mapping. Statistics in Medicine, 21, 359–370.
Leroux, B., Lei, X. and Breslow, N. (1999) Estimation of disease rates in small
areas: a new mixed model for spatial dependence. In Statistical Models in
Epidemiology, the Environment and Clinical Trials, Halloran, M. and Berry, D.
(eds). Springer: New York, 135–178.
LeSage, J. (2004) A family of geographically weighted regression models. In
Advances in Spatial Econometrics: Methedology Tools and Applications,
Anselin, L., Florax, J. and Rey, S. (eds). Springer: New York.
Leyland, A., Langford, I., Rasbash, J. and Goldstein, H. (2000) Multivariate
spatial models for event data. Statistics in Medicine, 19, 2469–2478.
MacNab, Y. (2003) Bayesian modeling of spatially correlated health service
outcome and utilization rates. Biometrics, 59, 305–315.
Marshall, E. and Spiegelhalter, D. (2003) Approximate cross-validatory predic-
tive checks in disease mapping models. Statistics in Medicine, 22, 1649–1660.
Militino, A., Ugarte, M. and Dean, C. (2001) The use of mixture models for
identifying high risks in disease mapping. Statistics in Medicine, 20, 2035–
2049.
Mollie´, A. (1996) Bayesian mapping of disease. In Markov Chain Monte Carlo in
Practice, Gilks, W., Richardson, S. and Spiegelhalter, D. (eds). Chapman and
Hall: London, 359–379.
Pascutto, C., Wakeﬁeld, J., Best, N., Richardson, S., Bernardinelli, L., Staines, A.
and Elliott, P. (2000) Statistical issues in the analysis of disease mapping data.
Statistics in Medicine, 19, 2493–2519.
Sun, D., Tsutakawa, R. and Speckman, P. (1999) Posterior distribution of
hierarchical models using CAR(1) distributions. Biometrika, 86, 341–350.
Sun, D., Tsutakawa, R., Kim, H. and He, Z. (2000) Spatio-temporal interaction
with disease mapping. Statistics in Medicine, 19, 2015–2035.
Wakeﬁeld, J., Best, N. and Waller, L. (2000) Bayesian approaches to disease
mapping. In Spatial Epidemiology: Methods and Applications, Elliott, P.,
Wakeﬁeld, J., Best, N. and Briggs, D. (eds). Oxford University Press: Oxford,
104–127.
Wang, F. and Wall, M. (2003) Generalized common spatial factor model.
Biostatistics, 4, 569–582.
288
DISCRETE SPATIAL DATA

CHAPTER 9
Time Series Models for
Discrete Variables
9.1
INTRODUCTION: TIME DEPENDENCE
IN OBSERVATIONS AND LATENT DATA
There are a range of possible methods for modelling time series of count,
binary and multinomial variables with considerable overlap between
methods for different types of discrete response. There are some well-
deﬁned classes of models such as integer autoregressive models, hidden
Markov models and transition models for counts with gamma (i.e. conju-
gate) mixing. Alternatively, dependence on past observations or on lagged
predictors may be handled by adapting continuous data methods.
Models with state-space features may be included within the class
of dynamic generalized linear models or DGLMs (West et al., 1985;
Gamerman, 1998). Thus let yt have a conditional density given state t
that belongs to the exponential family
fðytjt; tÞ ¼ exp½fytt  bðtÞg=aðtÞ þ cðyt; tÞ
with expectation t ¼ E½ytjt; t. Then with link g and a p-dimensional
predictor vector Xt including an intercept such that
gðtÞ ¼ tXt
Then as for metric responses one might specify a linear ﬁrst-order updat-
ing scheme
t ¼ Gtt1 þ !t
t ¼ 2; . . . ; T
Bayesian Models for Categorical Data
P. Congdon
# 2005 John Wiley & Sons, Ltd

where !t has mean 0 and p-dimensional covariance matrix W, and the
initial condition !1 has a diffuse prior.
As for continuous outcomes we expect correlations over time in discrete
variables due both to data-driven dependence in an outcome over succes-
sive time points and to dependence in latent variables such as regression
errors. These are sometimes known as observation- and parameter-driven
models respectively (Cox, 1981; Jackman, 1998).
Neglecting correlation from either source (i.e. assuming temporal
independence) may lead to mis-statement of standard errors on regression
coefﬁcients, as Poirier and Ruud (1988) demonstrate for correlated binary
data modelled via a probit link. As with cross-sectional count or binomial
data, there may well be departures from standard variance–mean assump-
tions (e.g. overdispersion or excess zeros) which also need to be allowed
for if regression parameters are to be efﬁciently estimated (Jowaheer and
Sutradhar, 2002).
Various methods allowing for autocorrelation and overdispersion exist,
raising questions of model choice and diagnosis. For example, following
Davis et al. (2000) a general approach might therefore allow both a latent
autoregressive process and lagged dependence in the observations. Model
discrimination procedures would decide whether one or the other or both
were required for a particular data set. As Grunwald et al. (2000) suggest,
there may be a range of diagnostic tests that can be applied within classi-
cal estimation frameworks, e.g. via parametric bootstrap methods as in
Tsay (1992). Analogous procedures in Bayesian estimation via repeated
sampling might involve using the predictive check techniques of Gelman
et al. (1996). For example, if overdispersion exists in the observed count
data such that y ¼ VarðyÞ=y exceeds one, then the model can be checked
in terms of whether it reproduces this observed feature. For samples of
new data z from a model the predictive diagnostic z can be compared
with the observed level of overdispersion, via the check
Pc ¼ E½Prðz > yÞjy
ð9:1Þ
As well as reproducing the observed overdispersion, a satisfactory model
will effectively eliminate error autocorrelations. As in Cameron and
Trivedi (1998, p 228) one might consider autocorrelations in the Pearson
residuals
et ¼ ðyt  tÞ0:5=’t
where ’t ¼ ’ðt;tÞ is the variance function. For example, under a gamma–
Poisson mixture as in (5.1), with yt  PoðttÞ, where t ¼ expðXtÞ and
290
TIME SERIES MODELS FOR DISCRETE VARIABLES

t  Gðt; tÞ, the variance function is t þ 2
t =t. Then the lag k autocor-
relation ðk ¼ 1; . . . ; LÞ is estimated as
^rk ¼
X
T
t¼kþ1
etetk
 X
T
t¼1
e2
t
and is Nð0; 1=TÞ when the true autocorrelations rkð j ¼ 1; . . . ; LÞ are zero.
Equivalently
ﬃﬃﬃﬃ
T
p
^rk is N(0,1) under temporal independence and the
Box–Pierce statistic T PL
k¼1 ^r2
k is 2ðLÞ. To guard against incorrect
standardization (i.e. incorrect speciﬁcation of ’t) alternative diagnostics
are
Rk ¼
X
T
t¼kþ1
etetk

X
T
t¼kþ1
e2
t e2
tk
 
!0:5
which are N(0,1) when rk ¼ 0; k ¼ 1; . . . ; L.
9.2
OBSERVATION-DRIVEN DEPENDENCE
In this section we consider models with a clear dependence on lagged
observational values, while possibly also allowing for data augmentation
or introducing error effects that may also potentially be autocorrelated.
For count data, the data augmentation approach is not commonly used.
Instead direct Poisson sampling is typically used and a straightforward
autoregressive data dependence might involve a log-link and lags in the
log of the dependent variable. To avoid taking logs of zero one might (see
Zeger and Qaqish, 1988) set y
t ¼ yt þ c, where 0 < c < 1, and a lag 1
dependence is then
yt  Poð	tÞ
logð	tÞ ¼  logðy
t1Þ þ xt
ð9:2Þ
A positive  implies 	t is increased as the previous outcome increases,
whereas a negative  means 	t falls as yt1 increases. Such a model might
not remove temporal correlation in the errors yt  	t or standardized
residuals 
t ¼ ðyt  	tÞ=’t where ’t ¼ VarðytjXtÞ. One might therefore
add additional lags to (9.2) as in
logð	tÞ ¼ 1 logðy
t1Þ þ 2 logðy
t2Þ þ    þ m logðy
tmÞ þ Xt
An apparently obvious observation-driven model for count data, namely
logð	tÞ ¼ Xt þ yt1
ð9:3Þ
OBSERVATION-DRIVEN DEPENDENCE
291

is stationary when  ¼ 0 and  < 0, but implies exponential growth in
the series when  > 0. In fact for constant Xt,  is a growth rate, since
logð	tÞ ¼ logð	t1Þ ¼ ðyt1  yt2Þ.
A further option for count data, considered by Grunwald et al. (2000)
and Brandt et al. (2000), is a conditional linear autoregessive CLAR(L)
process up to lag L. In its lag 1 version the CLAR(1) model involves a
lag parameter , a mean parameter t and additional parameters t (e.g
variances for Gaussian data). For example, with yt  Poð	tÞ
	t ¼ tyt1 þ t
ð9:4Þ
where restrictions t > 0 and t > 0 apply. A possible option is t ¼
expðtXtÞ. More generally
	t ¼ tyt1 þ "t
where "t might be gamma distributed with mean t. The lagged observ-
ation dependence might take the form of ‘thinning’ (see section 9.5), with
	t ¼ t  yt1 þ t
The Gaussian AR(1) model ﬁts into this framework by taking t ¼
ð1  Þ and
yt   ¼ ðyt1  Þ þ "t
where "t  Nð0; 2Þ. Whether applied to metric or discrete responses,
this model with t ¼  has an exponential lag decay property such that
corrðyt; ytkÞ ¼ k.
Cai et al. (2001) consider models for count (or ordinal categorical) data
ytþ1 where the regression parameter depends on the previously observed
value yt. Under this functional autoregressive approach, the conditional
probability that ytþ1 ¼ j given ðXtþ1; Xt; . . . ; yt ¼ i; yt1 ¼ k; . . .g might
be speciﬁed as Prðytþ1 ¼ jjyt; yt; Xt; ytÞ. For a Poisson density with q
predictors this leads to
ytþ1  Poið	tþ1Þ
logð	tþ1Þ ¼ yt þ 1;ytx1;tþ1 þ    þ q;ytxq;tþ1 þ ytyt
ð9:5Þ
The impact of yt on ytþ1 is thus expressed indirectly through the inter-
cepts and/or regression coefﬁcients. A high correlation between succes-
sive values will lead to i increasing with i. Though Cai et al. do not use
state-space priors, these may be relevant when there are many different
values of yt ¼ i. Random walks adjusted for unequal differences between
successive values may apply.
In each of these cases modiﬁcations may be necessary to account for
overdispersion, e.g. taking counts yt to be negative binomial rather than
Poisson, or equivalently, or adopting a conjugate mixture, namely
292
TIME SERIES MODELS FOR DISCRETE VARIABLES

gamma–Poisson or beta–binomial. One might also add a normal or other-
wise distributed error in the log or logit link (for count and binomial data
respectively) to represent overdispersion.
9.2.1
Binary data and Markov Chain models
As an example of observation-driven dependence where latent data are
introduced, consider a times series for a binary outcome yt; t ¼ 1; . . . ; T,
where the latent variable Wt is introduced according as yt is 1 or 0,
Wt  Nðt; 1Þ Iðat; btÞ
ð9:6Þ
with at ¼ 1 or 0 (and bt ¼ 0 or 1) according as yt ¼ 0 or 1. Then an
AR(1) dependence on previous responses could be speciﬁed
t ¼ Wt1 þ Xt
where  2 ½1; 1 under stationarity (Beck et al., 2001).
A more extensive model proposed by Heckman (1981) allows lagged
effects on Wt of Wt1, Wt2; . . . , and of the observations yt1; yt2; . . . .
As for cross-sectional data, greater generality in terms of link functions,
and robustness in terms of downweighting outliers, is achieved by scale
mixing, whereby
Wt  Nðt; VtÞ
The differing scales Vt may be deﬁned non-parametrically, allowing for
clustering in the scales, or alternatively drawn from a positive parametric
density (e.g. gamma).
If a direct likelihood model is used for binary data, a logistic model
analogous to (9.3) has a sounder basis for studying Markov chain depen-
dencies. In a ﬁrst-order Markov chain with constant transition prob-
abilities, the move between binary states yt and ytþ1 is governed by the
2  2 matrix
P ¼
p00
p01
p10
p11


where p00 þ p01 ¼ 1, p10 þ p11 ¼ 1 (Cox and Snell, 1989, p 98). Moves
between states separated by K periods are governed by a matrix PK if a
ﬁrst-order Markov chain is appropriate to the observations.
The distribution among states ðtÞ ¼ ð0t; 1tÞ at time t under a ﬁrst-
order Markov chain model is speciﬁed by
ðtÞ ¼ Pt1ð1Þ
As t increases, ðtÞ approaches an equilibrium satisfying
P ¼ 
OBSERVATION-DRIVEN DEPENDENCE
293

with solution Prðyt ¼ 1Þ ¼ 1 ¼ p01=ðp01 þ p10Þ, 0 ¼ 1  1. In the
equilibrium, the joint density of yt1 and yt is
Prðyt1 ¼ j; yt ¼ kÞ ¼ j pjk
and therefore
Eðyt1; ytÞ ¼ 1p11
Covðyt1; ytÞ ¼ 1p11  2
1
and the correlation between successive binary observations is
Corrðyt1; ytÞ ¼ ð1p11  2
1Þ=ð01Þ ¼ p11  p01
In second- and higher order Markov chains the probability of a move to
state 1 or 2 between t and t þ 1 depends not only on the current state but
on preceding states. The dependence is on both the states at t and t  1 in
a second-order chain, on the states at t, t  1 and t  2 in a third- order
chain, and so on. A ﬁrst-order Markov chain stationary through time may
be represented by the model
yt  BernðtÞ
logitðtÞ ¼  þ yt1
ð9:7aÞ
(see e.g. Lindsey, 1993, p 184). Higher order Markov chains will be
appropriate when both higher order lags and interactions between lags in
logit link regression models are signiﬁcant. For example, a second-order
Markov chain implies the model
logitðtÞ ¼  þ 1yt1 þ 2yt2 þ 3yt1yt2
ð9:7bÞ
When covariates Xt are available, the transition probabilities may be
modelled by logistic regression with the regression coefﬁcients speciﬁc to
the previous state, analogous to (9.5). Thus
yt  BernðtÞ
logitðtÞ ¼ ½yt1 þ ½yt1Xt
So
pðtÞ
01 ¼ expð0 þ 0XtÞ=½1 þ expð0 þ 0XtÞ
pðtÞ
00 ¼ 1=½1 þ expð0 þ 0XtÞ
pðtÞ
11 ¼ expð1 þ 1XtÞ=½1 þ expð1 þ 1XtÞ
pðtÞ
10 ¼ 1=½1 þ expð1 þ 1XtÞ
When observations are unequally spaced a continuous time Markov pro-
cess may be used. Let 01 and 10 be the transition intensities between
294
TIME SERIES MODELS FOR DISCRETE VARIABLES

states 0 and 1 and vice versa, with 1 ¼ 01=ð01 þ 10Þ and 0 ¼ 1  1.
Then following Cox and Snell (1989) and Jones (1993), and assuming a
time gap t between observations,
pðtÞ
01 ¼ 1½1  expðf01 þ 10gtÞ
pðtÞ
10 ¼ 0½1  expðf01 þ 10gtÞ
ð9:8aÞ
As t tends to inﬁnity, these probabilities tend to steady-state probabilities
1 and 0 respectively, and the correlation at time gap t is exp½ð01þ
10Þt. Covariates may be introduced by setting
log½01ðtÞ ¼ 0 þ 0Xt
log½10ðtÞ ¼ 1 þ 1Xt
ð9:8bÞ
More general regression structures for binomial and binary time series
include non-parametric modelling as in Hyndman (1999). Thus for binary
data, lags in y are included together with conventional linear effects in
predictors z and smoothed regression effects in predictors x1, x2, etc.:
yt  BernðtÞ
gðtÞ ¼ z þ s1ðx1tÞ þ s2ðx2tÞ þ    þ 1yt1 þ 2yt2 . . .
Following Wood and Kohn (1998) this type of semi-parametric model
may also be based on augmented data sampling, as in (9.6).
Example 9.1
Strikes and output
These data (Kennan, 1985) illus-
trate Poisson time series regression with both lags in the response and
overdispersion. They relate to monthly strikes yt in the USA from January
1968 to December 1976 and their relation to output ﬂuctuations (mea-
sured as the cyclical difference of output from a trend level). A baseline
model is provided by a static Poisson regression without dependence on
previous observed values or autocorrelated errors. Thus
yt  Poið	tÞ
logð	tÞ ¼ 0 þ 1xt
with xt ¼ output. In a two-chain run of 5000 iterations (convergent at
under 500) we obtain the regression t ¼ expð1:65 þ 3:09xtÞ. This model
does not reproduce the observed overdispersion as shown by a predictive
check. It is also subject to signiﬁcant temporal correlations ^r1;^r2; . . . ,
etc., with a Box–Pierce statistic of 54 (for 5 degrees of freedom) based on
the ﬁrst ﬁve ^rk.
Instead consider lagged dependence on shifted values
y
t ¼ yt þ c
ð0 < c < 1Þ
OBSERVATION-DRIVEN DEPENDENCE
295

with the mean taking the form (Zeger and Qaqish, 1988)
logð	tÞ ¼ 0 þ 1xt þ 1 logðy
t1Þ þ 2 logðy
t2Þ þ    þ L logðy
tLÞ
Simply taking this model with L ¼ 1 and c ¼ 0:5 eliminates the problem
of reproducing the overdispersion. Moreover, the Box–Pierce statistic has
posterior mean 7.7 and a comparison with a chi-square variable (with
5 degrees of freedom) shows no signiﬁcant autocorrelation (the prob-
ability that the observed Box–Pierce exceeds the chi-square variable is
0.8). This model has a DIC of 574, with the largest deviance for y37
(9 strikes) following a zero count y36 ¼ 0 in the previous month.
The ﬁt is improved if a negative binomial model with lag 1 in y
t ¼ ytþ
c is assumed. Thus
yt  NBðt; Þ
logðtÞ ¼ 0 þ 1xt þ  logðy
t1Þ
This gives a DIC of 544 and a 95% interval on 1 of (0.5,4.4). However,
the Box–Pierce statistic worsens under this model.
Example 9.2
Rainfall at Madison
Lindsey (1993) considers a binary
time series relating to June days at Madison (Wisconsin) with precipita-
tion recorded ðyt ¼ 1Þ against rain-free days ðyt ¼ 0Þ. The series extends
over 11 consecutive years (1961 to 1971) so there are 330 observations.
The data are treated as one series, though June 1, 1962 will be separated
from June 30, 1961. Assuming a ﬁrst-order Markov chain yields a DIC of
414 and a transition matrix
P ¼
0:72
0:28
0:58
0:42


where the ﬁrst row is for yt1 ¼ 0 and the second row is for yt1 ¼ 1 and
the ﬁrst and second columns are for yt ¼ 0 and yt ¼ 1. So the probability
of rain, given the previous day is rainy, is 0.42.
A second-order Markov chain as in (9.7b) yields the following
probabilities; conditional on the joint pair of states at t  2 and t  1:
States at
State at t
t  2
t  1
0
1
0
0
0.746
0.254
0
1
0.499
0.501
1
0
0.653
0.347
1
1
0.690
0.310
This yields a slight improvement in the DIC to 412.7.
296
TIME SERIES MODELS FOR DISCRETE VARIABLES

Example 9.3
England vs. Scotland internationals
To illustrate the
case of unequally spaced binary data, consider England vs. Scotland inter-
nationals between 1872 and 1987, with yt ¼ 1 if England won. These
occurred annually except for the two wars, so there is a gap of six years
between matches in 1914 and 1920 and of eight years between 1939 and
1947. In all there are 104 observations. A possible predictor of the res-
ponse is whether the match was played in England.
First consider the model in (9.8a) without using the predictor. The ﬁrst
year is modelled as a separate ﬁxed effect. The estimates of 01 and 10
are 1.85 and 2.9 respectively and the steady-state probabilities are 0 ¼
0:61 and 1 ¼ 0:39. There is a low correlation between successive yt,
namely 0.03. The DIC is 142.5. The second model uses the covariate as in
(9.8b). The effects are not pronounced; for example, 1 is marginally
negative (median 0.5 but with a 95% interval from 1.7 to 1.1), so the
probability of England not winning at t given they won at t  1 is lower if
England is playing at home at time t.
9.2.2
Observation-driven models for individual
multicategory data
For categorical data with J > 2 categories, models in lagged observa-
tions analogous to (9.7) involve multiple logit speciﬁcations (Kedem and
Fokianos, 2002). As discussed in Chapter 6, a reference category (e.g. the
ﬁrst or Jth) is usually selected and choices or allocations are then relative
to the reference category. Suppose the data are in dummy indicator form:
Dtj ¼ 1 if observation yt is in the jth of the J categories and so
Dt1 ¼ Dt2 ¼    ¼ Dt; j1 ¼ Dt; jþ1 ¼    ¼ DtJ ¼ 0. Thus
yt  CategoricalðptÞ
or equivalently
Dt  Mð1; ptÞ
where pt ¼ ð pt1; pt2; . . . ; ptJÞ is of dimension J.
If the Jth category is the reference then ‘own’ lags in the same category
and ‘cross’ lags in other categories may be included, as in VAR(L)
models for multivariate continuous data. If lagged dependence extends
beyond the ﬁrst period interactions may occur, as in (9.7b), e.g. on the
products Dt1; j Dt2; j in a lag 2 model. A second-order lag model for the
probabilities ptj would potentially involve J  1 lag 1 main effects, J  1
lag 2 main effects and ðJ  1Þ2 interaction effects. For instance, if
OBSERVATION-DRIVEN DEPENDENCE
297

interaction effects are excluded and a predictor xt is also available, then a
lag 2 model is
ptj ¼ expð
tjÞ
 X
k
expð
tkÞ
ð9:9aÞ
where 
tJ ¼ 0, while for j ¼ 1; . . . ; J  1

tj ¼ j þ jxt þ ½j11Dt1;1 þ    þ j1;J1Dt1;J1
þ ½j21Dt2;1 þ    þ j2;J1Dt2;J1
ð9:9bÞ
The lag coefﬁcients jkm model the impact on category j of the lag k in
category m.
To estimate ﬁrst- or higher order Markov chain models for data with
J > 2 categories, a direct analysis via a multinomial likelihood is indi-
cated. Under stationarity, a ﬁrst-order Markov chain
ðytjyt1 ¼ jÞ  Multð1; pjÞ
where pj ¼ ðpj1; pj2; . . . ; pjJÞ and PJ
k¼1 pjk ¼ 1. Under conjugacy, the
transition probability vector in row j follows a Dirichlet prior. A ﬁrst-
order chain therefore involves JðJ  1Þ free transition probabilities and a
pth order chain involves JpðJ  1Þ.
More parsimonious models have been suggested. The mixture transi-
tion distribution (MTD) model of Raftery (1985) assumes that Lth-order
dependence is expressible as a mixture (speciﬁcally a linear combination)
of separate impacts of each lag. So
Prfyt ¼ k0jyt1 ¼ k1; yt2 ¼ k2; . . . ; ytL ¼ kLg
¼
X
L
j¼1

j Prðyt ¼ k0jytj ¼ kjÞ ¼
X
L
j¼1

jQkjk0
ð9:10Þ
where PJ
k¼1 
k ¼ 1. The J  J transition matrix of probabilities Qkjk0 ¼
Prðyt ¼ k0jytj ¼ kjÞ pools over lags of different order. This model
involves just JðJ  1Þ þ ðL  1Þ parameters, compared with JpðJ  1Þ
in a pth-order Markov chain. The ﬁrst-order MTD model is equivalent to
a Markov chain of order 1.
9.2.3
Time series of aggregate multinomial data
Consider numbers of observations nt > 1 at time t, with yt ¼ ðyt1;
yt2; . . . ; ytJÞ a vector of counts. Then
yt  Multðnt; ptÞ
298
TIME SERIES MODELS FOR DISCRETE VARIABLES

with pt ¼ ðpt1; pt2; . . . ; ptJÞ. One might replace the multinomial logit
model in (9.9) with one involving lags in yt; j. Extra multinomial variation
would mean adding random effects "tj that might be multivariate normal
of order J  1.
Alternatively a conjugate prior, allowing for temporal dependence and
for extra variation, is provided by the Dirichlet. Thus a temporal indepen-
dence prior speciﬁes
pt  Dirðt1; . . . ; tJÞ
and the tj are uncorrelated over time, a standard choice being t1 ¼
t2 ¼    ¼ tJ ¼ 1 for all t. However, the independence prior neglects
that probabilities close in time will be more similar than probabilities
separated by a larger time gap. Gustafson and Walker (2003) propose a
prior penalizing large changes between prior probabilities, namely
pðptj; Þ / Dirð; ; . . . ; Þ exp 
X
T
t¼2
X
J
j¼1
ðptj  pt1;jÞ2=
"
#
Smaller  imply greater smoothing (high autocorrelation) while as  !
1 the independence prior holds. A DGLM approach is used by Cargnoni
et al. (1997), illustrated by a single predictor application with
gðptÞ ¼ 0t þ 1txt
where g might be the multivariate logit as in (9.9), and the category-
speciﬁc intercepts 0t and regression slopes 1t allow for cross-series
pooling of strength via random walk priors such as
0t  NJ1 0;t1; 0


Example 9.4
DNA sequences
To illustrate VAR(L) type and MTD
models for polytomous data consider the ﬁrst 1000 records in the DNA
sequence for the gene BNFR1 of the Epstein–Barr virus. These data
involve J ¼ 4 unordered categories of nucleotide (1 ¼ adenine, 2 ¼
guanine, 3 ¼ cytosine, 4 ¼ thymine) and are obtainable from the data-
bases at the European Molecular Biology Laboratory. They are consi-
dered by Kedem and Fokianos (2002, p 116) with thymine as reference.
They consider models as in (9.9b) without interactions between lags and
ﬁnd that the best model among a range of options up to lag L ¼ 4 in
fDtk;j; j ¼ 1; . . . ; 3g is one involving lags k ¼ 1 and 3 only. Thus for
j ¼ 1; 2; 3

tj ¼ 0j þ ½j11Dt1;1 þ j12Dt1;2 þ j13Dt1;3
þ ½j31Dt3;1 þ j32Dt3;2 þ j33Dt3;3
OBSERVATION-DRIVEN DEPENDENCE
299

There are no predictors, so this particular model involves 21 parameters
(three intercepts, three own lags at lag 1, three own lags at lag 3, six
cross-lags at lag 1 and six cross-lags at lag 3). A two-chain run shows
convergence at around 800 iterations. The deviance at the posterior mean
is 2666.5 (compared with 2663.2 at the maximum likelihood estimate)
giving a DIC of 2687.5.
By comparison the DIC for the lag 1 only model is 2703. Strictly
this means that the model including lag 3 effects is preferred. In fact
both models contain insigniﬁcant coefﬁcients and a variable selection
method may be applied to gain parsimony and obtain a more clearly
identiﬁed model.
A second order mixture transition model as in (9.10) achieves a
comparable DIC with that under a multinomial logit model. In a two-
chain run (convergent after 500 iterations), the average deviance for this
model is 2678, but since there are fewer (13) parameters the DIC is
competitive at 2691. Note that a series of gamma densities is used as the
prior for the elements on each row of Q rather than a Dirichlet prior. The
estimated mixture proportions are 
 ¼ ð0:79; 0:21Þ with transition matrix
Q ¼
0:18
028
0:37
0:17
0:26
0:29
0:21
0:23
0:22
0:33
0:33
0:12
0:13
0:26
0:38
0:23
2
664
3
775
This model was estimated without a constraint on 
1 and 
2, though an
unconstrained run shows that one value is clearly higher and a constraint
could be set accordingly. Higher order models may require a preset con-
straint in order to avoid label switching.
9.3
PARAMETER-DRIVEN DEPENDENCE VIA DLMs
Typical model forms where temporal dependence is modelled by random
effects latent variables include state-space models, particularly dynamic
linear models (DLMs), considered in this section, and autocorrelated
error models (section 9.4).
Random effects evolution of states t (i.e. regression intercepts or
coefﬁcients) is the hallmark of dynamic generalized linear models, where
yt belongs to one of the exponential family of distributions
Fðytjt; tÞ ¼ exp ytt  bðtÞ
aðtÞ
þ cðyt; tÞ


300
TIME SERIES MODELS FOR DISCRETE VARIABLES

where a link function g relates the mean t ¼ EðytjtÞ ¼ b0ðtÞ to a
p-dimensional regressor vector Xt, via gðtÞ ¼ tXt. The regression coefﬁ-
cients follow a Markov transition model
t ¼ Ftt1 þ !t
t ¼ 2; . . . ; T
where Ft are known p  p matrices (Ft ¼ I is a common option) and the
error is often assumed multivariate normal
!t  Npð0; WtÞ
with W ¼ Wt usually taken for identiﬁability (or some other device such
as discounting, as in West and Harrison, 1997). In practice not all the
coefﬁcients need be subject to random evolution.
More extensive models for the means t might involve trend, seasonal
and overdispersion effects, as in the model of Ferreira and Gamerman
(2000) for monthly meningococcal meningitis cases in Rio de Janeiro.
Speciﬁcally this is a dynamic log-linear Poisson model (see also
Fahrmeier and Tutz, 2000)
yt  Poð	tÞ
logð	tÞ ¼ t þ st þ 
t þ txt
with trend and seasonal (month) effects
t ¼ t1 þ !1t
st ¼ ðst1 þ st2 þ    þ st11Þ þ !2t
which have errors
!1t  Nð0; W1Þ
!2t  Nð0; W2Þ
The overdispersion error takes the form

t  Nð0; W3Þ
A dynamic binary time series model involving a trend and a non-
stationary effect of the past response might be deﬁned as
yt  BernðtÞ
logitðtÞ ¼ t þ tyt1
t ¼ t1 þ !1t
t ¼ t1 þ !2t
For multinomial data, a dynamic version of (9.9) might involve taking
random walks in intercepts jt and regression effects jt or making the
PARAMETER-DRIVEN DEPENDENCE VIA DLMs
301

cross-lag effects jkm vary through time. Omitting lagged responses leads
to a dynamic multiple logit model which for a single predictor is
yt  Categorical ðptÞ
ptj ¼ expð
tjÞ
X
j
expð
tjÞ
where 
tJ ¼ 0 and

tj ¼ jt þ jtxt
j ¼ 1; . . . ; J  1
For a DGLM for an ordered categorical response one might set
pt1 ¼ t1
ptj ¼ tj  t;j1
j ¼ 2; . . . ; J  1
tj ¼ Prðyt  jÞ ¼ Fðtj  tXtÞ
j ¼ 1; . . . ; J  1
ptJ ¼ 1  i;J1
where F might be a normal or logistic distribution function and possibly
time-varying cut points on the underlying continuous scale are con-
strained to satisfy
t1 <    < t;J1
Ordinal data time-series varying coefﬁcient regression models for
unequally spaced observations r ¼ 1; . . . ; R at times t1; t2; . . . ; tR are
considered by Kauermann (2000). Thus
tj ¼ Prðyr  jjxr; trÞ ¼ F½jðtrÞ þ ðtrÞXr
where cut points and regression effects may vary over time via state-
space models allowing for varying gaps tr ¼ tr  tr1 between pre-
dictors (Chapter 3).
9.3.1
Measurement error models
If Xt contains only an intercept then the above DGLMs essentially repre-
sent a true state underlying a response measured with error. To exemplify
this latent state approach, Carlin and Polson (1992) examine binary data
for REM sleep in infants with yt ¼ 1 if in REM sleep at minute t, yt
otherwise. They suggest that underlying the observed yt, and similarly the
augmented data Wt as in (9.6), is a ‘true’ sleep state variable t. Assum-
ing a ﬁrst-order random walk in the true state one might have
Wt  Nðt; 1Þ
ð9:11aÞ
t  Nðt1; 2
Þ
ð9:11bÞ
302
TIME SERIES MODELS FOR DISCRETE VARIABLES

with the initial condition 0 a separate ﬁxed effect. An autoregressive
dependence might also be assumed, with
t  Nðt1; 2
Þ
ð9:11cÞ
A similar type of measurement error model retains binomial or Poisson
sampling but assumes autoregressive or random walk dependence in a
state variable deﬁned by the mean parameters (Kitagawa and Gersch,
1996, chapter 13) or by linking transformations of them such as logit or
log transforms. For example, assume a Bernoulli density for the binary
variable yt, with yt  BernðtÞ. Then, as in Cox and Snell (1989), one
may let
logitðtÞ ¼ t
t  Nð þ ðt1  Þ; Þ
Kitagawa and Gersch propose ﬁrst- or second-order random walks in t
(occasionally higher orders may be used). For example, an RW(1) normal
prior has the form
t  Nðt1; Þ
ð9:12Þ
Equivalently
kt  Nð0; Þ
where k ¼ 1 for an RW(1) prior. The same process applies to binomial
data with nt subjects at risk and yt successes, with probability t of
success. An illustration provided by Kitagawa and Gersch involves the
number of occurrences of rainfall over 1 mm in Tokyo in T ¼ 366 observ-
ations. Thus 365 pairs of days and 1 single day are obtained by aggrega-
ting over two years (1983–1984). For example, the ﬁrst observation
combines Jan 1 1983 and Jan 1 1984. So nt ¼ 2 with the exception nt ¼ 1
for 29 February in 1984 – see Exercise 9.3.
For Poisson data the corresponding state-space model would typically
involve the log transform of the Poisson mean, i.e. if
yt  Poð	tÞ
and
logð	tÞ ¼ t
then
kt  Nð0; Þ
PARAMETER-DRIVEN DEPENDENCE VIA DLMs
303

9.3.2
Conjugate updating
Harvey and Fernandes (1989) combine gamma–Poisson or beta–binomial
mixing (as in cross-sectional data) with state-space updating through
time. The observations follow a relevant exponential family density, such
as Poisson, binomial and negative binomial. Changes in the underlying
level or state of the process through times t are governed by sequential
updating based on the observations at times t. The state process follows
the relevant conjugate density (gamma for Poisson, beta for binomial and
negative binomial, and so on). The impact of covariates is generally
assumed ﬁxed. Thus for count data, let
yt  PoðtmtÞ
mt ¼ expðxtÞ
Given preceding observations Dt1 ¼ fyt1; yt2; . . . ; xt1; xt2g, the time-
varying levels t are taken to be gamma, t1jDt1  Gðat1; bt1Þ with
the subsequent period’s prior being
tjDt1  Gðwat1; wbt1Þ
where w  Uð0; 1Þ is a discount factor. Combining the likelihood after
observing Dt and the prior gives, via gamma conjugacy with the Poisson,
a full conditional
tjDt  Gðwat1 þ yt; wbt1 þ mtÞ
To allow for observation-driven lagged impacts, a Poisson autoregressive
model to lag L, or PAR(L) model, is outlined by Brandt and Williams
(2001) drawing on this methodology and that of the CLAR(L) model
in (9.4). Thus
mt ¼
X
L
k¼1
kytk þ expðxtÞ
ð9:13Þ
Another model (the Poisson exponentially weighted moving average
model or PEWMA; Brandt et al., 2000) includes period growth rates in
the model for mt, with
mt ¼ expðrt þ xtÞ
Ord et al. (1993) and Harvey and Fernandes (1989) consider the same
framework for binomial–beta, NB–beta and multinomial–Dirichlet
mixture models. Thus for binomial data yt  Binðnt; tÞ and t  Be
304
TIME SERIES MODELS FOR DISCRETE VARIABLES

ðwct1; wdt1Þ where the process is initialized by vague positive ﬁxed
effects c1 and d1, e.g. c1  Gað1; 0:001Þ, d1  Gað1; 0:001Þ. Then the full
conditional for t is
tjDt  Beðwct1 þ yt; wdt1 þ nt  ytÞ
For multinomial data yt  Mðnt; ptÞ the prior on pt is Dirichlet with para-
meters fwcj;t1; j ¼ 1; . . . ; Jg and the full conditional is
ptjDt  Dirðwc1;t1 þ y1t; wc2;t1 þ y2t; . . . ; wcJ;t1 þ yJtÞ
For the negative binomial
pðytjt; rÞ ¼
r þ yt  1
yt


r
tð1  tÞyt
the expectation is
Eðytjt; rÞ ¼ rð1  tÞ=t
and the conjugate prior for t is beta, as for the binomial. However, to
ensure a constant expectation the prior has the form
t  Beð!at1 þ ð1  !Þ; !bt1Þ
Explanatory variables may be introduced by setting rt ¼ expðXtÞ.
Program 9.5
REM sleep
Carlin and Polson (1992) examine a series
of 120 observations at minute intervals with yt ¼ 1 if an infant is in REM
sleep at minute t, and yt otherwise. In their model the binary data are
augmented by the underlying continuous (normal) variables Wt
Wtj2; yt; t  Nðt; 2Þ Ið0; 1Þ
if yt ¼ 1
 Nðt; 2Þ Ið1; 0Þ
if yt ¼ 0
t  Nðt1; 2Þ
with 0 a separate ﬁxed effect. One goal is to predict the next value in the
series (observation y121 with state 121). Following Carlin and Polson
(1992, p 584) the following priors are assumed:
0  Nð0; 1Þ
1=2  Gað3; 3Þ
1=2  Gað0:5; 0:5Þ
  Nð0:5; 10Þ
A two-chain run of 20 000 iterations in WINBUGS13 (convergent from
under 1000) estimates 2 as 1.2 and  as 0.93 (and a 95% interval 0.82
to 1). The estimated mean for 121 is 2.39 and the probability that y121
is one is estimated as 0.85. Note that the ﬁve preceding observations
(y116 to y120) are all one. Figure 9.1 plots the estimates of t.
PARAMETER-DRIVEN DEPENDENCE VIA DLMs
305

While the preceding model may be identiﬁed with informative priors
on the two variances, identiﬁability is more straightforward by setting
2 ¼ 1. This approach reduces the estimated variance of the states to 0.89
(posterior mean) but the probability that y121 is one remains at 0.85.
Program 9.6
Purse snatchings
Brandt and Williams (2001) analyse
data on purse snatchings in the Hyde Park neighbourhood of Chicago
before and after a crime prevention programme. The data are 71 counts
over 28-day periods from January 1969, with the intervention commenc-
ing at the 42nd period (xt ¼ 0 for t ¼ 1; . . . ; 41 and xt ¼ 1 for t ¼
42; . . . ; 71).
First a CLAR(1)-type model as in (9.13) is adopted with
mt ¼ 1yt1 þ expð0 þ 1xtÞ
with prior 1  Nð0; 1Þ on the intervention effect. Diffuse priors are
adopted on the initial values a1 and b1. A two-chain run of 10 000 iter-
ations (convergent from 2500) shows a negative mean for 1 of 0.36,
with the 95% interval entirely negative (0.69,0.02) in line with an
effective intervention. The lag parameter  has mean 0.72. Using equa-
tion (2.17b) there are around 42 effective parameters and a DIC of 421. A
predictive check on whether new data sampled from the model have a
variance–mean relationship in tune with the observed data suggests that
−5
−4
−3
−2
−1
0
1
2
3
4
5
1      5      9 13 17 21 25 29 33 37 41 45 49 53 57 61 65 69 73 77 81 85 89 93 97 101 105 109 113 117
Minute
Figure 9.1
Latent states for infant REM sleep
306
TIME SERIES MODELS FOR DISCRETE VARIABLES

this aspect of the data is satisfactorily reproduced, with Pc in (9.1) stand-
ing at 0.26.
A standard negative binomial, with
PðytÞ ¼
ðyt þ rÞ
ðyt þ 1ÞðrÞ
r
r þ t

r
t
r þ t

yt
and regression effects included via the CLAR(1) model
t ¼ 1yt1 þ expð0 þ 1xtÞ
give a DIC of 446 and also a satisfactory predictive check (namely 0.39)
in terms of reproducing the observed overdispersion. The coefﬁcient on
1 is still negative but the 95% interval is no longer entirely negative,
namely (0.76,0.01). Under this model ^r1 is estimated as 0.13, and so
temporal autocorrelation at lag 1 does not appear signiﬁcant (
ﬃﬃﬃﬃ
T
p
^r1 is
around 1.1).
Program 9.7
Non-accidental mortality in Birmingham
Smith et al.
(2000) give several alternative analyses of a series of daily deaths yt
(from causes other than accidents) among the over 65s in Birmingham,
Alabama, between August 3, 1985 and December 31, 1988 (a period of
1247 days). They use Poisson regression to relate deaths to minimum
daily temperature (tmin), mean speciﬁc humidity (mnsh) and PM10
readings. Their best model for the meteorological variables involves a
lag 3 term in tmin, lags at 0, 1, 2 and 3 in mnsh, and lags at 0 and 1 in the
square of mnsh. (A lag at 0 means the predictors of yt include contempo-
raneous values of mnsh and mnsh2.) They model the impact of PM10 as a
three-day average, PMMEAN, of the readings on the previous three
days (PM10_1, PM10_2 and PM10_3). They try a simple linear term in
PMMEAN and ﬁnd a coefﬁcient of 0.00098 (s.d. 0.00040). They also try
a seasonally varying impact of PMMEAN and ﬁnd a weaker effect in
summer (June, July, August) than the other seasons.
Here the lag 1 term in the square of mnsh is omitted as it proved non-
signiﬁcant and an intercept varying by year is adopted as there is a slight
upward trend in deaths among the over 65s. To model seasonal effects
(higher deaths in winter months) a monthly seasonal random effect
is used (via an RW(1) model). There are four missing values in the
PMMEAN series and these necessitate modelling of the explanatory
variable by a ﬁrst-order random walk (other interpolation methods might
be used). IG(1,1) priors on the evolutionary variances in both these
random walks are used in the expectation of reasonably smoothly
changing series.
PARAMETER-DRIVEN DEPENDENCE VIA DLMs
307

The most important remaining aspect of the model is representing the
impact of the running PM10 mean, PMMEAN, on the death rate. Model
A follows Smith et al. in using a seasonally varying PM10 effect. For
numerical reasons, PM10 is scaled by 0.01 so the coefﬁcients on it should
be approximately 100 times those cited by Smith et al. The seasonal
effect estimated here peaks in spring and fall and is weaker in the other
seasons. The coefﬁcients with 95% intervals for spring, summer, fall and
winter are respectively 0.147 (0.027, 0.265), 0.023 (0.136, 0.167),
0.141 (0.016, 0.262) and 0.022 (0.115, 0.165). The DIC for this
model is 16 751, which includes a component from the interpolation
model for PM10.
A second model uses a cubic spline with knots at PM10 readings of 80
and 100. These were based on analysing death rates according to grouped
sets of days with PM10 readings in bands 2.5 wide (these being succes-
sively 10–12.49, 12.5–14.99, etc.) with values over 120 constituting the
45th band. Then a seven-period moving average of these 45 bands gives
an impression of the smooth PM10 effect, showing the death rate rising
at higher values. Smith et al. use threshold and general additive models to
demonstrate this non-linear effect. This model has a slightly worse DIC
than model A (at 16 764) but shows the accelerating effect of PM10 on
mortality (Figure 9.2). Figure 9.2 also shows the distorting impact of the
sparse values of PM10 over 120.
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0
20
40
60
80
100
120
140
160
PM10
Death rate
Figure 9.2
Impact of PM10 on death rate
308
TIME SERIES MODELS FOR DISCRETE VARIABLES

9.4
PARAMETER-DRIVEN DEPENDENCE
VIA AUTOCORRELATED ERROR MODELS
Davis et al. (2000) emphasize the importance of detecting autocorrelation
in the regression errors, indicating where present the need for a latent
series with a potentially complex ARMA structure. For simplicity let the
latent series "t be AR(1). Then in a data augmented binary regression
analysis one might have
Wt  Nðt; 1Þ
t ¼ Xt þ "t
"t  Nð"t1; 2
"Þ
with Xt including an intercept. Czado (2001) describes such a model with
yt deﬁned by migraine attacks, and Wt being an unobservable latent
threshold for such an attack. For a count time series one might have (Oh
and Lim, 2001; Chen and Ibrahim, 2000)
yt  Poð	tÞ
logð	tÞ ¼ Xt þ "t
ð9:14aÞ
with
"t ¼ "t1 þ ut
ð9:14bÞ
where j j  1 and ut is an uncorrelated error with variance 2. An alter-
native conjugate model (Zeger, 1988; Davis et al., 2000) has
t ¼ expðXtÞ
t
where 
t is gamma with mean 1. In either case the latent process intro-
duces both autocorrelation and overdispersion in yt, though the auto-
correlation in yt is less than or equal to that in the latent series (Chen and
Ibrahim, 2000).
Oh and Lim (2001) combine this approach with data augmentation (i.e.
introducing latent normal Wt underlying the observations yt), while Chen
and Ibrahim (2000) suggest this model along with methods for formally
incorporating historical data into the prior for f; ; 2
"g. Oh and Lim
mention that the cdf of a Poisson variable yt with mean 	t is closely
approximated by
ðA½yt; 	tÞ ¼ ð3u0:5
t
½ð	tutÞ1=3  1 þ ut=9Þ
PARAMETER-DRIVEN DEPENDENCE VIA ERROR MODELS
309

where  is the standard normal cdf and ut ¼ ½yt þ 11. Deﬁne 
t ¼
logð	tÞ ¼ Xt þ "t as above; then for yt > 0 the latent variables under-
lying the Poisson observations are obtained by sampling
Wt  Nðt; 1Þ IðA½yt  1; 	t þ 
t; A½yt; 	t þ 
tÞ
For yt ¼ 0 they are obtained as
Wt  Nðt; 1ÞIð1; A½0; 	t þ 
tÞ
To include observational lags as well as lags in the latent process one
might adopt the CLAR model structure with lags in ytk and "tk. For
example, with ﬁrst-order lags in both, one obtains
yt  Poð	tÞ
	t ¼ 1yt1 þ expðXt þ "tÞ
"t ¼ 2"t1 þ ut
ð9:15Þ
where 1  Uð1; 1Þ and 2  Uð1; 1Þ. Zeger and Qaqish (1988)
suggest an empirical error model where the error is deﬁned by comparing
the lagged and transformed responses logðy
tkÞ, as in (9.2), with the
regression predictions Xtk. So an AR(1) model analogous to (9.14) is
yt  Poð	tÞ
logð	tÞ ¼ xt þ 1ðlog y
t1  Xt1Þ
This might be combined with lags in the logðy
tkÞ themselves to give a
joint observation–parameter-driven model.
Program 9.8
Purse snatchings (continued)
The purse snatchings data
are reanalysed with models allowing both observational and error lags.
The ﬁrst model uses the transformation of Zeger and Qaqish (1988) so
that
yt  Poð	tÞ
logð	tÞ ¼ 1 log y
t1 þ Xt þ "t
"t ¼ 2"t1 þ ut
Uð1; 1Þ priors are assumed on both correlation parameters. This model
shows 2 to average 0.88 and 1 to be negative (mean 0.23). The
Whistlestop effect disappears completely. The DIC is lower at 406 than
for the model used in Example 9.6, with de ¼ 31.
The second model uses a CLAR(1) model with AR(1) errors in the
exponential component, as in (9.15). The DIC for this model is 418 and
as for the ﬁrst model 2 is strongly signiﬁcant, with mean 0.86 from the
310
TIME SERIES MODELS FOR DISCRETE VARIABLES

second half of a two-chain run of 20 000 iterations. The Whistlestop
intervention coefﬁcient is again not signiﬁcant with a 95% interval
(0.48, 0.68).
9.5
INTEGER AUTOREGRESSIVE MODELS
Integer-valued autoregressive (INAR) models for count observations yt
involve a form of survival of some of the previous counts in the series
together with immigration of new units. An INAR(1) model involving
yt1 only assumes
yt ¼ Rt þ !t
t > 1
with
Rt  Binð; yt1Þ
and !t is a Poisson ‘innovation’ series with mean ð1  Þ. If yt1 is
Poisson with mean , then Rt is Poisson , and yt is Poisson with mean
 (McKenzie, 1986). The initial condition (the prior for the ﬁrst observ-
ation y1) for an INAR(1) model is taken as
y1  PoðÞ
The notation
Rt ¼   yt1
is used to denote binomial thinning, and taking 0 <  < 1 provides a
stationarity constraint. An INAR(2) process involves thinning on yt1 and
yt2 and replacement probabilities, 1 and 2. Then
yt ¼ R1t þ R2t þ !t
where R1t  Binð1; yt1Þ, R2t  Binð2; yt2Þ. The innovation !t is then
Poisson with mean
	
1 
X
2
k¼1
k

. Stationarity for an INAR(p) process is
deﬁned by
X
p
k¼1
k < 1
(Cardinal et al., 1999). The INAR(1) model without covariates implies
yt  Poið	tÞ, where 	t ¼ Eðytjyt1Þ ¼ yt1 þ ð1  Þ (Winkelmann,
2000, p 203).
To allow for overdispersion both !t and y1 may be negative binomial
(McKenzie, 1986). Alternatively, random thinning may be assumed
(Grunwald et al., 2000, p 481); for example, with replacement
INTEGER AUTOREGRESSIVE MODELS
311

probabilities varies over time t according to a beta density with mean 
(Jowaheer and Sutradhar, 2002). Thus
yt ¼ Wt þ !t
Wt  Binðt; yt1Þ
t  Betaðb; bð1  ÞÞ
ð9:16Þ
where the innovations and the ﬁrst observation y1 are Poisson or negative
binomial.
Suppose predictors are available and a regression term such as t ¼
expðXtÞ is introduced. Assuming y1  Poið1Þ then to be fully consis-
tent with the INAR framework such that EðytÞ ¼ t, it is necessary that !t
have mean t ¼ t   t1. For t to be positive in turn requires t to be
constant or monotonically decreasing (Azzalini, 1994), so limiting the
ﬂexible modelling of time-varying predictors. Alternatively, following
Brannas (1995), the innovation term !t may be modelled as Poisson with
mean t and for the ﬁrst observation a pre-series latent observation y0
might be introduced, so that for t ¼ 1; . . . ; T
yt ¼   yt1 þ !t
!t  PoðtÞ
Alternatively or additionally covariates Zt may be introduced into model-
ling the time-varying replacement probabilities t. To ensure 0 < t < 1
a logit or probit link might be used:
logitðtÞ ¼ Zt
INAR models are framed to resemble Gaussian autoregression models
but can be framed in terms of conditional means (Grunwald et al., 2000).
For example, survival and immigration might also be modelled directly in
Poisson or NB means, such that 	t combines thinning (e.g.   yt1) with
an innovation series !t with density conﬁned to positive values (e.g.
Poisson, negative binomial or a gamma). So
yt  Poð	tÞ
t > 1
	t ¼   yt1 þ !t
!t  Poðð1  ÞÞ
y1  PoðÞ
ð9:17Þ
Overdispersion might be introduced by taking !t to be a discrete mixture
with K classes, as in
!t  PoðGtÞ
Gt  Categoricalð1; . . . ; KÞ
312
TIME SERIES MODELS FOR DISCRETE VARIABLES

by random thinning (taking t to vary randomly), or taking the innova-
tions to be gamma distributed, as in
!t  Gaðct; cÞ
ð9:18Þ
with t ¼ expðXtÞ. Discrete innovation series other than Poisson are
considered by McCabe and Martin (2003).
Program 9.9
Purse snatchings (continued)
The purse snatchings
data are reanalysed using an INAR(1) structure in Poisson means. The
ﬁrst model is as in (9.17) without predictors Xt and taking  constant. The
estimated  is 0.42 with  ¼ 13:4. The predictive check on overdispersion
shows this not to be accounted for, with probability as in (9.1) of 0.01 and
the DIC deteriorates to 432, as measured by DðjyÞ þ 2de.
To allow for overdispersion and predictor effects, one option is random
thinning as in (9.16). So
yt  Poð	tÞ
	t ¼ t  yt1 þ !t
t  Betaðb; bð1  ÞÞ
!t  PoðtÞ
t ¼ expð0 þ 1XtÞ
A Be(1,1) prior on  is assumed and a Ga(0.5,0.5) prior on b. A two-chain
run of 10 000 iterations shows convergence from around 2000 iterations.
The 95% interval on 1, namely (0.70,0.04), is conﬁned to negative
values with a posterior average of 0.36;  is estimated as 0.35. The
average deviance is 379 with 44 effective parameters, giving a DIC of
423. The predictive check on predictive vs. actual overdispersion is satis-
factory, around 0.47.
9.6
HIDDEN MARKOV MODELS
Whereas in state-space models the unobserved series driving the observa-
tions is continuous, in hidden Markov models (HMMs) the unobserved
states are discrete; see, for example, Paroli and Spezia (2002) and Leroux
and Puterman (1992). In a ﬁrst-order hidden Markov model (by far the
most commonly used) the unobserved process St is in one of m categories,
with movement between states at successive periods determined by a
stationary one-step transition matrix P ¼ fPijg of order m, namely
Pij ¼ Pr½St ¼ jjSt1 ¼ i
ð9:19Þ
HIDDEN MARKOV MODELS
313

that involves mðm  1Þ unknown probabilities. In a ﬁrst-order model,
there is one initial state S1 which is multinomial with probabilities q ¼
fq1; . . . ; qmg. The distribution among states at time t, ðtÞ ¼ ð1t; . . . ;
mtÞ, is speciﬁed by
ðtÞ ¼ Pt1ð1Þ
As t increases, ðtÞ approaches an equilibrium satisfying
P ¼ 
with solution (for m ¼ 2)
1 ¼ p12=ðp12 þ p21Þ
2 ¼ 1  1
For example, for a ﬁrst-order Poisson HMM with no predictors, there are
m means 1; . . . ; m with
Yt  PoðStÞ
St  CategoricalðPSt1;1:mÞ
t > 2
S1  Categoricalðq1:mÞ
As for other mixture models there are possible questions of label
switching, especially as the number of latent categories m increases,
and identiﬁability constraints on the model parameters are needed. For
example, in a Poisson HMM with no predictors, such a constraint is an
ordering of the Poisson means (Scott, 2002, pp 342–343).
Among developments of such models are the incorporation of additive
errors, possibly with state-dependent variances (de Gunst et al., 2001) or
other state-dependent parameters (e.g. the autocorrelations in AR error
schemes). Thus for a Poisson HMM one might have
yt  Poð	tÞ
	t ¼ St þ "t
"t ¼ St"t1 þ ut
with ut  Nð0; StÞ.
Given the underlying states St the observations yt are usually taken to
be mutually independent. If St is allocated to category k, then yt is
assigned to the kth of the m possible components of a suitable density. For
count data, Poisson components might have different means (Leroux and
Puterman, 1992), while for a negative binomial they might have different
means and overdispersion parameters. Suppose component k of a Poisson
314
TIME SERIES MODELS FOR DISCRETE VARIABLES

HMM has mean k; then the likelihood is deﬁned by the state-dependent
probabilities
tk ¼ Prðyt ¼ yjSt ¼ kÞ ¼ expðkÞy
k=y!
and the marginal distribution of yt is
Prðyt ¼ yÞ ¼
X
k
ktk
For count data, shifting between regimes with different intensities is often
used as a model for overdispersion.
Example 9.10
Purse snatchings (continued)
A two-state Poisson
HMM is applied to these data. Although the average deviance is higher
than for some previous models at 424, the parsimony of the model (with
ﬁve parameters) means that the penalized ﬁt is relatively acceptable. The
means of the two Poisson groups are 21.4 and 9.9, and the probabilities of
belonging to the ﬁrst higher intensity group approach 1 for periods 23–43.
One might try higher numbers of states m and compare the AIC and BIC
of the resulting models with the m¼2 case. Scott (2002) notes that the
BIC for latent Markov models may unduly penalize larger models (i.e.
those with higher m).
EXERCISES
1. In Example 9.1 try a CLAR(1) model with yt  Poið	tÞ
	t ¼ yt1 þ expðxtÞ
with  > 0 and the mixed version
	t ¼ yt1 þ "t
"t  Gað expðxtÞ; Þ. How does ﬁt compare with the models using
the transform y
t ¼ yt þ c? Try also the discrete conditioning model
with mean
logðtþ1Þ ¼ yt1 þ xt
where i has 19 possible values (since yt varies between 0 and 18). A
random state-space prior (e.g. RW(1)) for i is one option.
2. In Example 9.3, try a model with ﬁrst and second lags ðk ¼ 1; 2Þ in the
Poisson and NB models with transformed observations
y
t ¼ yt þ c
ðc ¼ 0:5Þ
How does this affect ﬁt and autocorrelation in the error terms?
EXERCISES
315

3. The following data relate to the Tokyo rainfall data mentioned earlier
and in the code below are modelled via a stationary binomial model.
Consider instead non-stationary RW(1) and RW(2) models (with
normal or other errors) in the logit of the rainfall probability and
assess the gain in ﬁt over the stationary binomial.
model {for (t in 1:59) {y[t]  dbin(p,2)}
for (t in 61:366) {y[t]  dbin(p,2)}
# model for 29th February 1984
y[60]  dbern(p)}
# prior on constant binomial probability
p  dbern(1,1)}
list(y¼c(0,0,1,1,0,1,1,0,0,0,0,0,0,0,1,0,0,1,1,0,1,1,0,0,0,0,0,0,0,0,1,
0,1,0,0,0,0,0,0,0,0,0,1,1,0,0,0,2,1,0,0,0,0,1,1,0,1,0,0,0,
0,1,1,0,0,0,0,0,0,2,0,0,1,1,0,2,1,0,1,1,1,0,1,2,0,0,1,1,1,1,1,
2,0,0,1,1,0,1,2,0,1,1,1,0,0,1,2,1,0,2,1,0,1,0,0,0,0,0,1,0,0,
1,1,0,0,0,1,1,0,0,0,0,0,1,1,1,2,2,0,0,0,0,0,1,1,1,0,0,0,1,0,0,
0,0,0,1,0,1,0,0,0,2,1,1,2,1,0,1,2,2,0,2,2,1,1,1,2,2,2,1,1,0,
0,0,1,0,1,1,1,2,1,0,1,1,0,0,2,1,1,1,1,2,2,0,1,0,0,0,0,1,1,0,0,
0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0,1,2,1,0,0,0,0,0,0,0,1,0,
1,0,0,0,1,0,1,1,1,2,0,0,0,1,2,2,0,1,1,2,2,1,0,1,1,1,1,1,1,0,
0,0,0,0,1,0,0,0,1,0,2,1,1,0,1,1,1,0,2,1,1,1,1,0,0,0,1,0,0,0,0,
0,0,0,0,0,1,1,0,1,1,0,0,0,0,1,1,0,0,1,1,0,0,0,1,0,0,0,0,0,0,
0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,1,0,0,0,0,1,0,0,0,0,0,0,1,1))
4. In Example 9.6 apply a negative binomial–beta mixture with the prior
and parameterization discussed in section 9.3.2.
5. In the analysis of the data in Example 9.7, Smith et al. mention issues
with representing overdispersion and also possible error autocorrela-
tion. Using Example 9.8 as a template, investigate these questions.
6. In Example 9.10 try m ¼ 3 and m ¼ 4 in the Poisson HMM for the
purse snatching data and assess ﬁt against the m ¼ 2 model via the
AIC and BIC.
316
TIME SERIES MODELS FOR DISCRETE VARIABLES

REFERENCES
Azzalini, A. (1994) Logistic regression and other discrete data models for
serially correlated observations. Journal of the Italian Statistical Society, 3,
169–179.
Beck, N., Epstein, D., Jackman, S. and O’Halloran, S. (2001) Alternative models
of dynamics in binary time-series-cross-section models: the example of state
failure. Political Methodology Working Papers – 2001 (http://polmeth.wustl.
edu).
Brandt, P. and Williams, J. (2001) A linear Poisson autoregressive model: the
Poisson AR(p) model. Political Analysis, 9, 164–184.
Brandt, P., Williams, J., Fordham, B. and Pollins, B. (2000) Dynamic models for
persistent event count time series. American Journal of Political Science, 38,
823–843.
Brannas, K. (1995) Explanatory variables in the INAR(1) count data model. Umea
Economic Studies 381.
Cai, Z., Yao, Q. and Zhang, W. (2001) Smoothing for discrete valued time series.
Journal of the Royal Statistical Society, Series B, 63, 357–375.
Cameron, C. and Trivedi, P. (1998) Regression Analysis of Count Data, Econo-
metric Society Monograph No. 30. Cambridge University Press: Cambridge.
Cardinal, M., Roy, R. and Lambert, J. (1999) On the application of integer-valued
time series models for the analysis of disease incidence. Statistics in Medicine,
18, 2025–2039.
Cargnoni, C., Mu¨ller, P. and West, M. (1997) Bayesian forecasting of multinomial
time series through conditionally Gaussian dynamic models. Journal of the
American Statistical Association, 92, 640–647.
Carlin, B. and Polson, N. (1992) Monte Carlo Bayesian methods for discrete
regression models and categorical time series. In Bayesian Statistics 4,
Bernardo, J. et al. (eds). Clarendon Press: Oxford, 577–586.
Chen, M.-H. and Ibrahim, J. (2000) Bayesian predictive inference for time series
count data. Biometrics, 56, 678–685.
Cox, D. (1981) Statistical analysis of time series: some recent developments.
Scandinavian Journal of Statistics, 8, 93–115.
Cox, D. and Snell, E. (1989) Analysis of Binary Data, 2nd Edition, Monographs
on Statistics and Applied Probability, 32. Chapman and Hall: London.
Czado, C. (2001) Individual migraine risk management using binary state space
mixed models. Working Paper, Technische Universita¨t Mu¨nchen, Lehrstuhl fu¨r
Statistik.
Davis, R., Dunsmuir, W. and Wang, Y. (2000) On autocorrelation in a Poisson
regression model. Biometrika, 87, 491–505.
De Gunst, M., Ku¨nsch, H. and Schouten, J. (2001) Statistical analysis of ion
channel data using hidden Markov models with correlated state-dependent
noise and ﬁltering. Journal of the American Statistical Association, 96, 805–
815.
REFERENCES
317

Fahrmeier, L. and Tutz, G. (2000) Multivariate Statistical Modelling Based on
Generalized Linear Models. Springer: Berlin.
Ferreira, M. and Gamerman, D. (2000) Dynamic generalized linear models. In
Generalized Linear Models: A Bayesian Perspective, Dey, D., Ghosh, S. and
Mallick, B. (eds). Marcel Dekker: New York, 57–72.
Gamerman, D. (1998) Markov chain Monte Carlo for dynamic generalised linear
models. Biometrika, 85, 215–227.
Gelman, A., Carlin, J., Stern, H. and Rubin, D. (1996) Bayesian Data Analysis.
Chapman and Hall, London.
Grunwald, G., Hyndman, R., Tedesco, L. and Tweedie, R. (2000) Non-Gaussian
conditional linear AR(1) models. Australian & New Zealand Journal of
Statistics, 42, 479–495.
Gustafson, P. and Walker, L. (2003) An extension of the Dirichlet prior for the
analysis of longitudinal multinomial data. Journal of Applied Statistics, 30,
293–310.
Harvey, A. and Fernandes, C. (1989) Time series models for count or qualitative
observations. Journal of Business and Economic Statistics, 7, 407–417.
Heckman, J. (1981) Statistical models for discrete panel data. In Structural
Analysis of Discrete Data with Econometric Applications, Manski, C. and
McFadden, D. (eds). The MIT Press: Cambridge, MA, 114–178.
Hyndman, R. (1999) Nonparametric additive regression models for binary time
series. Proceedings, 1999 Australasian Meeting of the Econometric Society,
7–9 July 1999, University of Technology, Sydney.
Jackman, S. (1998) Time series models for discrete data: solutions to a problem
with quantitative studies of international conﬂict. Department of Political
Science, Stanford University.
Jones, R. (1993) Longitudinal Data with Serial Correlation: A State-space
Approach. Chapman and Hall: London.
Jowaheer, V. and Sutradhar, B. (2002) Analyzing longitudinal count data with
overdispersion. Biometrika, 89, 389–399.
Kauermann, G. (2000) Modeling longitudinal data with ordinal response by
varying coefﬁcients. Biometrics, 56, 692–698.
Kedem, B. and Fokianos, K. (2002) Regression Models for Time Series Analysis.
John Wiley & Sons: New York.
Kennan, J. (1985) The duration of contract strikes in US manufacturing. Journal
of Econometrics, 28, 5–28.
Kitagawa, G. and Gersch, W. (1996) Smoothness Prior Analysis of Time Series.
Springer: Berlin.
Leroux, B. and Puterman, M. (1992) Maximum penalized likelihood estimation for
independent and Markov-dependent poisson mixtures. Biometrics, 48, 545–558.
Lindsey, J. (1993) Models for Repeated Measurements. Clarendon Press: Oxford.
McCabe, B. and Martin, G. (2003) Coherent Bayesian predictions of low count
time series. Working Paper, Department of Economics and Accounting, School
of Management, University of Liverpool.
318
TIME SERIES MODELS FOR DISCRETE VARIABLES

McKenzie, E. (1986) Autoregressive moving average processes with negative
binomial and geometric marginal distributions. Advances in Applied Proba-
bility, 18, 679–705.
Oh, M. and Lim, Y. (2001) Bayesian analysis of time series Poisson data. Journal
of Applied Statistics, 28, 259–271.
Ord, K., Fernandes, C. and Harvey, A. (1993) Time series models for multivariate
series of count data. In Developments in Time Series Analysis: In Honour of
Maurice B. Priestley, Subba Rao, T. (ed.). Chapman and Hall: London, 295–
309.
Paroli, R. and Spezia, L. (2002) Parameter estimation of Gaussian hidden Markov
models when missing observations occur. Metron, 60, 165–181.
Poirier, D. and Ruud, P. (1988) Probit with dependent observations, Review of
Economic Studies, 55, 593–614.
Raftery, A. (1985) A model for higher-order Markov chains, Journal of the Royal
Statistical Society, Series B, 47, 528–539.
Scott, S. (2002) Bayesian methods for hidden Markov models: recursive comput-
ing in the 21st century. Journal of the American Statistical Association, 97,
337–351.
Smith, R., Davis, J., Sacks, J. and Speckman, P. (2000) Regression models for air
pollution and daily mortality: analysis of data from Birmingham, Alabama.
Environmetrics, 10, 719–745.
Tsay, R. (1992) Model checking via parametric bootstraps in time series analysis.
Applied Statistics, 41, 1–15.
West, M. and Harrison, J. (1997) Bayesian Forecasting and Dynamic Models,
2nd Edition. Springer: New York.
West, M., Harrison, J. and Migon, H. (1985) Dynamic generalised linear models
and Bayesian forecasting. Journal of the American Statistical Association, 80,
73–83.
Winkelmann, R. (2000) Econometric Analysis of Count Data, 3rd Edition.
Springer: Berlin.
Wood, S. and Kohn, R. (1998) A Bayesian approach to robust nonparametric
binary regression. Journal of the American Statistical Association, 93, 203–
213.
Zeger, S. (1988) A regression model for time series of counts. Biometrika, 75,
621–629.
Zeger, S. and Qaqish, B. (1988) Markov regression models for time series: a
quasi-likelihood approach. Biometrics, 44, 1019–1031.
REFERENCES
319


CHAPTER 10
Hierarchical and Panel
Data Models
10.1
INTRODUCTION: CLUSTERED DATA AND GENERAL
LINEAR MIXED MODELS
Multilevel models are appropriate for hierarchically arranged data with
nested sources of variability such as patients within hospitals, progeny
within sires, or pupils within classes, when incorrect inferences may be
drawn if the different sources of variability are not taken into account.
Analysing data in which individuals j are arranged within clusters i
(i ¼ 1; . . . ; n; j ¼ 1; . . . ; Ri) should address the similarity (autocorrela-
tion) between individuals in the same cluster, and also possibly varying
causal impacts of predictors xijk on the outcome yij across clusters. Other
forms of clustered data include panel data (repetitions of observations at
times t for subjects i), with the clusters being the subjects. Repeated data
may also be deﬁned by cross-categorized factors (e.g. treatment combi-
nations, diagnostic tests, product attributes) with the subjects being
patients, quality raters, etc. For longitudinal data it is often appropriate
for the autocorrelation model to be structured in time, using methods such
as those in Chapter 9. If subjects are arranged spatially then both space
and time structuring should be included (section 10.10).
Some of the mechanisms underlying autocorrelation within clusters of
human subjects in hierarchically structured school outcome data are spelt
out by Snijders and Bosker (1999, p 9) such as residence in a similar
neighbourhood, attending the same school, or shared group norms. For
instance, pupil exam results vary partly because of different pupil
abilities, but also because of differences between classes or schools.
Bayesian Models for Categorical Data
P. Congdon
# 2005 John Wiley & Sons, Ltd

Pupils in the same class tend to perform more similarly than pupils in
different classes, and pupils in one school are usually more similar to
each other than to pupils in other schools. The institutional context may
also impact on individual-level attainment processes; for instance, the
slope relating exam performance to ability may be inﬂuenced by class
size or teacher style (Aitkin and Longford, 1986). Similar contextual
effects apply for health and behavioural outcomes, though there is still
much debate about the relative importance of individual-level inﬂuences
and those due to institutional or neighbourhood settings (Goldstein and
Spiegelhalter, 1996).
In longitudinal or panel studies a collection of subjects is observed
through time, so that repeated observations are clustered within subjects.
For instance, a discrete outcome yit may be observed at t ¼ 1; . . . ; Ti
occasions for each of n subjects. While there are many overlaps with
speciﬁcations involving cross-sectional clustered data, there are distinct
issues that may occur, such as the modelling of growth paths through
time, or the addition of lagged values ðyi;t1, yi;t2, etc.) as predictors
of the current response. Just as for clustered data it is likely that
subjects vary in their average levels on the outcome, but they may also
vary in growth rates over time, or in the impact of other time-speciﬁc
predictors.
10.2
HIERARCHICAL MODELS FOR METRIC OUTCOMES
As for cross-sectional data without clustering, the linear model for metric
data forms a baseline for non-metric data or is sometimes of direct
relevance if, say, the Albert–Chib data augmentation method (Albert and
Chib, 1993) via Gibbs sampling is applied. Consider a univariate metric
outcome and a two-level hierarchy and let yi be an Ri  1 vector
yi ¼ ðy1i; y2i; . . . ; yRiiÞ0 with Ri being the number of repetitions within
clusters or subjects i ¼ 1; . . . ; n. Let Xi be an Ri  p matrix of time-
varying
predictors
with
ith
row
Xir ¼ ðxir1; . . . ; xirpÞ,
and
i ¼
fi1; i2; . . . ; ipg0 be a p  1 random regression parameter vector. Also
let 1 be Ri  1. Then a two-level hierarchical model with variation in
intercepts i and in all predictor effects has the form
yi ¼ 1i þ Xii þ "i
ð10:1Þ
The observation level error "i ¼ ð"i1; "i2; . . . ; "iRiÞ0 is most usually taken
to follow a parametric density (e.g. normal) with constant variance
"ir  N(0, 2
"). The cluster-speciﬁc random effects 
i ¼ ði; i1; . . . ; ip)
322
HIERARCHICAL AND PANEL DATA MODELS

may have independent prior densities or be associated in a multivariate
prior density, e.g.

i  Npþ1ðH; Þ
ð10:2Þ
where H ¼ ðA; 1; . . . ; qÞ represents average regression effects. These
population averages typically have diffuse prior densities, e.g. the prior
on the average intercept might be A  Nð0; VÞ where V is a known
large variance. Alternatively variations in 
i might be modelled in terms
of regression on r cluster-level attributes Wi, e.g.

i  Npþ1ðWi’; Þ
where ’ is of dimension r  ðp þ 1Þ.
Often a mixed model (Laird and Ware, 1982) with some regression
parameters ﬁxed over clusters is used, so that
yi ¼ 1 þ Xi þ Zibi þ "i
ð10:3Þ
where Xi is an Ri  p matrix of predictors associated with ﬁxed regression
parameters , and Zi is an Ri  q matrix of predictors the impact of which
on the outcome is expressed by a q  1 vector of random cluster-speciﬁc
effects bi ¼ ðbi1; bi2; . . . ; biqÞ0. If the zik are a subset of f1; xi1; . . . ; xipg
then the bi may be parameterized to represent deviations from the
population average regression parameters. So the total effect of the kth
predictor in cluster i is ik ¼ k þ bik. bi typically takes a parametric
multivariate prior parallel to (10.2), namely
bi  Nqð0; bÞ
ð10:4Þ
Other options are possible: for instance, Zi might include variables not
present in Xi. Non-parametric alternatives to (10.4) are also possible, such
as discrete mixtures. The precision matrix Tb ¼ 1
b
of the predictor
random effects under a multivariate normal prior (10.4) is typically
assigned a Wishart prior Tb  Wð	0; QÞ, though options for greater
ﬂexibility have been proposed (e.g. Boscardin and Weiss, 2004). The
full conditional density of Tb is then a Wishart with shape 	 ¼ 	0 þ n and
scale
Q1 þ
X
n
i¼1
bib
0
i
 
!1
Wakeﬁeld et al. (1994) and Chib and Carlin (1999) note that Gibbs
sampling can be used for all the parameters in this model, since all full
conditionals reduce to standard densities. Despite this there may be a gain
in identiﬁability and convergence in MCMC estimation if overlaps
HIERARCHICAL MODELS FOR METRIC OUTCOMES
323

between the ﬁxed and random effects speciﬁcations are avoided (Chib et
al., 1999). Thus suppose Zi
consists only of X
variables, say
Zi ¼ ðXi1; . . . ; XiqÞ, with randomly varying coefﬁcients that have means
ð1; . . . ; qÞ. To avoid overlaps, the model is reframed so that Xi now
consists only of X
i ¼ ðXi;qþ1; . . . ; XipÞ, and bi in (10.4) now has mean
ð1; . . . ; qÞ.
Heterogeneity in intercepts representing intersubject variations in, say,
average susceptibility or ability that are not captured by measured
covariates is often an issue. In many applications this is the only form
of heterogeneity considered (so q ¼ 1) and the linear mixed model
reduces to
yi ¼ 1 þ Xi þ 1bi þ "i
ð10:5Þ
where bi might a priori be taken as bi  Nð0; 2
bÞ. Under the alternative
parameterization above the intercept is excluded from the ﬁxed effects
and the mean of the ﬁrst random effect assumes the role of the intercept
(Chib and Carlin, 1999). So (10.5) becomes
yi ¼ 1bi þ Xi þ "i
where bi  Nð; 2
bÞ.
The above models may be expressed in a three-stage form which is the
basis for conjugate generalized linear mixed models for discrete out-
comes as discussed by Daniels and Gatsonis (1999). Thus the model of
equation (10.3) may be written
yir  Nðir; 2Þ
where the conditional mean is ir ¼ EðyirjbiÞ ¼  þ Xir þ Zirbi. The
second stage of this model speciﬁes the prior density pðbijbÞ for the
cluster effects bi while the third stage speciﬁes priors on hyperpara-
meters, pðbÞ.
10.3
HIERARCHICAL GENERALIZED LINEAR MODELS
For non-normal data (binary, categorical or count) similarly assume that
the responses yir follow the exponential family density
pðyirjirÞ ¼ expf½yirir   ðirÞ=airðÞ þ cðyir; Þg
The appropriate density (e.g. Poisson) from this family provides the
likelihood for the observations at the ﬁrst stage. Under a conjugate
mixture approach (Daniels and Gatsonis, 1999), the second stage spe-
ciﬁes the conjugate mixing density for ir (e.g. gamma for a Poisson
324
HIERARCHICAL AND PANEL DATA MODELS

likelihood, beta for a binomial likelihood) in terms of a mean ir (e.g.
Poisson mean, binomial probability) and scale parameter i. A mixture on
the ir at the second stage is especially relevant in the case of over-
dispersion. The second stage also speciﬁes how ir is linked to the
regression function 
ir ¼ 
irðXirÞ, e.g.
gðirÞ ¼ Xiri
ð10:6Þ
where the q  1 regression vectors i vary over clusters. The third stage
speciﬁes densities for varying effects between clusters i in terms of
cluster attributes Wi for example,
i  NðWi’; Þ
while the fourth stage speciﬁes priors on hyperparameters.
Thus consider a conjugate Poisson–gamma mixture for repeated count
data. Then one form possible is a multiplicative subject-level frailty
yir  PoiðirÞ
ir  Gðiir; iÞ
where i might be itself assigned a Gamma prior. Then log(irÞ ¼ iXir
and i  NðWi; ). Related model speciﬁcations (Lee and Nelder,
2000) might specify
ir ¼ expðXirÞ	i
where
	i  Gð; Þ
and the precision  of the 	i might be assigned its own prior. If
overdispersion is still unaccounted for then a gamma distributed observa-
tion-level effect 	ir might be introduced, again with mean 1:
ir ¼ expðXirÞ	ir	i
A related model often used to analyse integer item scores (e.g. in
education) is known as the Rasch Poisson count model (van Duijn and
Jansen, 1995) and assumes for subject i and item r
ir ¼ 	iir
where
the
effects
	i  Gaðc; c=mÞ
have
mean
m
and
ir 
Dirðb1; . . . ; bR). In educational applications, the 	i are ability parameters
and the ir are difﬁculty parameters with prior difﬁculties br constant
over subjects. The marginal likelihood here is the product of a negative
binomial for the subject total yiþ ¼ P
r yir (and with parameters c and
s ¼ c=m) and a multinomial for yir conditional on yiþ with parameters
HIERARCHICAL GENERALIZED LINEAR MODELS
325

ir=iþ. So the multinomial is modelling how the total score for an
individual is distributed between individual items. This is also known as
the Dirichlet model in consumer research (Goodhardt et al., 1984).
Generalizations might include making the ability mean m speciﬁc to
pupil groups (e.g. m1; . . . ; mG), or relating an individual-level mean mi to
predictors via log-linear regression.
The alternative to conjugate approaches is the generalized linear mixed
model involving random effects in a log- or logit linear regression term

ir. For example, with yir  PoðirÞ or yir  Binðnir; ir), heterogeneity
in intercepts or slopes across clusters could be modelled via
gðirÞ ¼ Xir þ Zirbi
ð10:7Þ
where
Xir
is
1  p,
Zir ¼ ðzir1; zir2; . . . ; zirq)
is
1  q,
and
bi ¼ ðbi1; . . . ; biqÞ0. This form is often simpler for purposes of modelling
variation between clusters in both slopes and intercepts, e.g. via a
multivariate normal prior
bi  NqðWi’; bÞ
Robust alternatives might involve scale mixing or discrete mixtures. For
example, a scale mixture would specify
bi  NqðWi’; b=iÞ
where i are gamma (leading to multivariate t or Cauchy distributed bi) or
exponential (leading to a double exponential bi). One discrete mixture
option (Weiss et al., 1999) allows for an inﬂated variance (dispersion)
component with
bi  NqðWi’; bÞ þ ð1  ÞNqðWi’; kbÞ
where k ¼ 100, say. As for the metric model above, identiﬁability may be
improved if Xir and Zir are mutually exclusive. So if there were intercept
variation between clusters (and no other form of heterogeneity, so q ¼ 1)
then Zir1 ¼ 1 and bi ¼ bi1 has a non-zero mean which represents the
average intercept. The Xir will not then include an intercept.
Modelling intracluster correlation may remove much extra variation in
the GLMM of (10.7), but, if required, an extra level of variation at the
observation level may be used
gðirÞ ¼ Xir þ Zirbi þ "ir
ð10:8Þ
Such extensions will generally much improve ﬁt as measured by DðjyÞ
or DðjyÞ but may risk overparameterizing the model. Here the prior on
the "ir may need to be sufﬁciently informative to prevent them effectively
modelling the data (Johnson and Albert, 1999).
326
HIERARCHICAL AND PANEL DATA MODELS

The logit linear random effects approach generalizes to clustered
ordinal and multinomial responses with J levels. Let yir 2 1; 2; . . . ; J
be repetitions of categorical variables for individuals or groups. Thus for
an ordinal response with predictors possibly varying over repetitions, one
seeks to model the cumulative probabilities
irj ¼ Prðyir  jjXirÞ
ð10:9aÞ
with probabilities irj ¼ Prðyir ¼ jÞ obtained as
ir1 ¼ ir1
irj ¼ irj  ir;j1
j ¼ 2; . . . ; J  1
irj ¼ Fðj  irÞ
j ¼ 1; . . . ; J  1
irJ ¼ 1  ir;J1
ð10:9bÞ
and J  1 free cut point parameters j. The model for the regression
mean excludes an intercept but may include zero-mean random effects bi,
namely
ir ¼ 1xir1 þ 2xir2 þ    þ pxirp þ bi
or subject-varying coefﬁcients on a q vector of predictors Zir;
ir ¼ 1xir1 þ 2xir2 þ    þ pxirp þ Zirbi
For unordered categorical data with repeated observations (e.g. consumer
choice data with several observations on each household or subject)
alternative estimation methods are considered by Chen and Kuo (2001).
For example, a random subject intercept MNL model for repeated
multinomial choice data with individual speciﬁc attributes Cij (e.g.
Priceij and Qualityij) or attributes varying over repetitions Cijr (e.g.
price by purchase occasion) has the form
irj ¼ Prðyir ¼ jÞ
¼ expðbij þ 1Priceijr þ 2QualityijrÞ=
X
J
k¼1
expðbik þ 1Priceikr
þ 2QualityikrÞ
j ¼ 1; . . . ; J; r ¼ 1; . . . ; R
where for identiﬁability one effect is zero (e.g. biJ ¼ 0) and so
bij; j ¼ 1; . . . ; J  1 might be taken as multivariate effects (e.g. MVN)
of order J  1. Random effects for other predictors can be modelled
similarly: for example, 1 might vary over individuals, choices or both.
The mixed MNL models considered in Chapter 6 are likely to be better
identiﬁed if there are repeated choice observations for each subject.
HIERARCHICAL GENERALIZED LINEAR MODELS
327

10.3.1
Augmented data sampling for hierarchical GLMs
As for non-hierarchical data, models for clustered categorical data
(especially binary or ordinal) may involve augmenting the data by latent
continuous scales. In this case the metric forms of the mixed model
(section 10.2) become relevant. Consider binary data with repetitions r
within clusters i. Assume a latent metric utility y
ir that is given by
y
ir ¼ Xir þ Zirbi þ "ir
ð10:10Þ
When q ¼ 1, (10.10) reduces to a mixed intercept model
y
ir ¼ Xir þ bi þ "ir
ð10:11Þ
The probability of an event is
Prðyir ¼ 1Þ ¼ Prðy
ir > 0Þ ¼ Prð"ir > Xir  ZirbiÞ ¼ 1  FðXir  ZirbiÞ
For F symmetric about zero (e.g. when F is the cdf of an N(0,1) variable)
the last element of this equation equals FðXir þ Zirbi). So in this case
the y
ir are obtainable by truncated normal sampling, constrained to be
negative when the actual binary observation yir ¼ 0, and positive when
yir ¼ 1. As above, robust alternatives may be obtained by scale mixing on
both the model for y
ir and the model for bi. For example, to approximate a
logit link, the y
ir can be sampled from a truncated Student t density with 8
degrees of freedom, and variance 1/0.6342, since a t8 variable is
approximately 0.634 times a logistic variable. The scale mixture version
of the Student t density then facilitates outlier detection and down-
weighting of aberrant cases (see Example 10.3).
Latent scales also apply for clustered ordinal and multinomial data, and
are ﬁttable by the Albert and Chib (1993) approach. For ordinal responses
a generalization of the location-scale model (section 7.4) is provided by
Ishwaran and Gatsonis (2000). Thus for subject i and diagnostic tests r
assume univariate ordered observations yir, underlying variables y and
predictors Xir and Uir such that
Prðyir  jjXirÞ ¼ F j  Xir
expðUirÞ


Then yir ¼ j if j1 < y
ir  j where
y
ir ¼ Xir þ Zir expðUirÞ
Zi  Nð0; RÞ
where R is a correlation matrix, since the variances are not identiﬁed. For
clustered multinomial data, the multinomial probit can be generalized to
328
HIERARCHICAL AND PANEL DATA MODELS

repetitions r. Then yir ¼ j if y
irj ¼ maxðy
ir1; y
ir2; . . . ; y
irJÞ where one
possible model might be
y
irj ¼ Virj þ "irj ¼ Xirj þ Zirbi þ Cij þ Aj þ "irj
where Cij are subject–choice attributes and Aj are choice-speciﬁc attri-
butes. Identiﬁability involves differencing against the utility of a refer-
ence category, such as the Jth (Geweke et al., 1994).
Example 10.1
Cohabitation experience
To illustrate multilevel ana-
lysis with a binary outcome consider data from the 1994 International
Social Survey Program (Snijders and Bosker, 1999, chapter 14). This
relates to whether 2079 Norwegian adults had lived together without
being married. Age and religious adherence (religion ¼ 1 if respondent
attends religious service at least once a month) are the individual
predictors. The experience of cohabitation and other aspects (e.g. the
slope on age or the impact of religion) may differ by region, there being
i ¼ 1; . . . ; 19 regions varying in respondent totals Ri from 235 (Oslo) to
35 (Finmark).
The age effect over all subjects is modelled as a quadratic spline with
knots at ages 30 and 40, namely
SðAgeÞ ¼ 0 þ 1ðAge  20Þ þ 2ðAge  20Þ2
þ 3½ðAge  30Þþ2 þ 4½ðAge  40Þþ2
where for example
ðAge  30Þþ ¼ ðAge  30Þ
if Age > 30
¼ 0
if Age  30
In the ﬁrst model (model A) the intercept varies by region. Thus q ¼ 1
and Zir1 ¼ 1 as in (10.7), so that yir  BernðirÞ,
logitðirÞ ¼ bi þ 1ðAge  20Þ þ 2ðAge  20Þ2
þ 3½ðAge  30Þþ2 þ 4½ðAge  40Þþ2 þ 5Religion
and
bi  Nð0; 2
bÞ
The age effect in region i under this model is
SiðAgeÞ ¼ bi þ 1ðAge  20Þ þ 2ðAge  20Þ2
þ 3½ðAge  30Þþ2 þ 4½ðAge  40Þþ2
HIERARCHICAL GENERALIZED LINEAR MODELS
329

Posterior means on the regression parameters  ¼ ð0; 1; . . . ; 5) are
obtained as (1.18,0.57,0.031,0.025,0.0075,1.92) with the age effect
when bi ¼ 0 reproduced in Figure 10.1. This shows the experience of
cohabitation reaching a maximum at age 30 and declining thereafter.
Region effects bi vary from 1.02 to 1.27. The DIC is 2191 with
de ¼ 13; since there are six ﬁxed effects regression parameters plus the
variance of the bi, the 19 extra random effects have an effective
dimension of 6. As an alternative predictive ﬁt criterion, the proportion
of those with cohabitation experience correctly classiﬁed using ‘new
data’ samples is 0.60 as against 0.69 for those without experience.
A second model adds varying linear age effects over regions with a
multivariate normal prior allowing for covariance between intercepts bi1
and age effects bi2. An identity scale matrix for the Wishart prior on the
inverse covariance matrix is assumed. This model has around 34.5
effective parameters, so adds considerably to complexity. In fact there
is no correlation between the two region effects, so a simpler independent
effects model may be more successful. There does appear to be some
regional variation in the age effects with the posterior mean of the
relevant parameter b22 of the covariance matrix being 0.06, with a 95%
interval (0.03,0.11). The sensitivity under this model improves slightly to
around 0.605 and the DIC falls to 2188.
To illustrate the latent data technique, latent normal y with constant
variance are sampled from a model (model C) with mean given by
(10.11), i.e. varying intercepts only. This involves truncated sampling and
is equivalent to a probit link, g1 ¼ . New latent data are sampled
(without truncation) and their match with the observations assessed. The
Age
−2.5
−1.5
−0.5
0.5
1.5
0
1
2
−2
−1
Log-odds
20
25
30
35
40
45
50
55
60
65
70
Figure 10.1
Impact of age on experience of cohabitation
330
HIERARCHICAL AND PANEL DATA MODELS

sensitivity and speciﬁcity are close to those under the direct likelihood
approach (model A), namely 0.60 and 0.69. By monitoring possible
outliers via Monte Carlo estimates of the CPO, the lowest CPOs are found for
the youngest adults (under 18) with cohabitation experience and for three
religious older adults (over 65) also with such experience.
To assess their impact on regression effects and ﬁt a logit link is
approximated by scale mixing (model D). Thus, following Albert and
Chib (1993),
y
ir  NðXir þ bi; 1=½ir0:6342Þ
where
ir  Gað4; 4Þ
As would be expected, the lowest weights ir (around 0.5) are for older
religious subjects with cohabitation experience; the highest weights
(around 1.2) are for non-religious adults in their thirties with experience.
Under model D, these subjects are less at odds with the model, with their
CPOs accordingly higher than under model C. Under scale mixing the
sensitivity is raised to 0.61 and the speciﬁcity to 0.70, though there are no
impacts on regressor effects (e.g. in terms of their direction and
signiﬁcance). The effective parameter count is now 45, compared with
12 under the uniform variance model, so there is an increase in complex-
ity, though despite this the DIC falls from 2188 to 2179.
Example 10.2
Wine bitterness
A clustered ordinal data analysis
considers rankings of the bitterness of wines by nine rankers on a ﬁve-
point scale from 1 ¼ not bitter to 5 ¼ very bitter (Randall, 1989). Two
wine bottles were randomly selected from products deﬁned ﬁrst by
temperature at pressing, and second by skin contact at pressing. Thus
each ranker rates eight bottles, two from the low-temperature–no contact
category, two from the low-temperature–contact category, two from the
high-temperature–no-contact category, and two from the high-temperature–
contact category. Apart from the inﬂuence of these factors on ratings, it is
necessary to allow for random variation between raters.
Thus the structure of (10.9) above applies to observations r ¼ 1; . . . ; 8
for raters i ¼ 1; . . . ; 9. A model for irj ¼ Prðyir ¼ jÞ under proportional
odds and without rater random effects may be deﬁned as
ir1 ¼ ir1
irj ¼ irj  ir;j1
j ¼ 2; . . . ; J  1
logitðirjÞ ¼ j  ir
j ¼ 1; . . . ; J  1
HIERARCHICAL GENERALIZED LINEAR MODELS
331

with J ¼ 5, four free cut points 1; . . . ; 4, and regression mean
ir ¼ 1Xir1 þ 2Xir2
where Xir1 ¼ 1 for low temperature (¼ 0 otherwise) and Xir2 ¼ 1 for skin
contact (¼ 0 otherwise). The prior (7.5) is adopted for the cut points,
namely
1 ¼ ’1
j ¼ j1 þ
X
j
m¼2
expð’mÞ
with unconstrained ’m. Model B including rater intercept variation has
the form
ir ¼ 1Xir1 þ 2Xir2 þ bi
where the bi are zero-mean random effects, for instance bi  Nð0; 2
b). It
is also possible to allow rater variation in the impacts of the other
predictors. Labelling them as Zir1 and Zir2 (and retaining intercept
variation) this leads to a model
ir ¼ bi1 þ bi2Zir1 þ bi3Zir2
where bi ¼ ðbi1; bi2; bi3Þ might be taken as multivariate normal or student
t and bi1 has a zero mean.
A model without random intercepts gives DIC ¼ 185 and de ¼ 5:9 (a
log likelihood at posterior mean of the parameters of 86.6). The mean
coefﬁcient on low temperature is 2.45 (so less bitter ratings are obtained
for low-temperature pressing) while that on contact is 1.54 (so contact
increases bitterness).
To allow for clustering within raters (i.e. non-independence of
responses yir within raters) a normal random effect bi is added for the
model
ir ¼ 1Xir1 þ 2Xir2 þ bi
Because of the small sample there may be sensitivity in estimating the bi
to alternative priors on 2
b. Assuming
b ¼ 1=2
b  Gað1; 0:01Þ
a two-chain run of 20 000 iterations shows the most bitter ratings to be
provided by rater 1 (b1 ¼ 1:05) and the least bitter by rater 7. Allowing
for such differences improves the DIC to 176.5, with de ¼ 12:1 and log
likelihood at  ¼ ðb; ) of 76. The means on temperature and contact
332
HIERARCHICAL AND PANEL DATA MODELS

are enhanced to 2.75 and 1.72. An alternative prior on b (only one
possible option) takes

 ¼ b=ð1 þ bÞ

  Beð1; 1Þ
This gives a lower DIC of 170 and a wider scatter of rater effects, e.g.
b1 ¼ 1:75, and b7 ¼ 1:77.
10.4
RANDOM EFFECTS FOR CROSSED FACTORS
The most common multilevel structure is when contextual variables are
nested: for example, subjects i ¼ 1; . . . ; Njk at level 1 (e.g. pupils) are
nested within clusters j ¼ 1; . . . ; J at level 2 (schools) that may be further
nested into level 3 aggregates k ¼ 1; . . . ; K (local education agencies);
see, for example, Rasbash and Browne (2001). A random effects model
can be set at each level with random effects at level j explicable by
predictors at level j and k. One may also establish models for hetero-
scedasticity or overdispersion at level 1 with the variance of errors "ijk
depending on characteristics of individuals or their contexts, e.g.
log½Varð"ijkÞ ¼ 0 þ 1Xijk þ 2Wjk.
However, in many situations the context involves overlapping or
crossed rather than nested factors (e.g. when pupil attainment reﬂects
both school and area of residence). Let h ¼ ½jk denote the cross-hatched
factor formed by crossing levels j and k. In some applications the risk
population Nh may not occur in all the combinations of contextual factors
but for the moment deﬁne H ¼ JK to cover all possible combinations.
Rather than let i (for pupil) range from 1 to Nh, deﬁne i to range from 1 to
N where N ¼ P
h Nh. Also let j ¼ j½i denote the pupil’s school, k ¼ k½i
denote the pupil’s area of residence and h ¼ h½i denote the crossed index
jk½i, with h varying from 1 to H. Then for a binary outcome with
yi  BernðiÞ possible models include a random effect h at the crossed
level
logitðiÞ ¼ Xi þ Wj½i þ Zk½i þ 
h½i
or separate random effects u1 and u2 for the two crossed factors
logitðiÞ ¼ Xi þ Wj½i þ Zk½i þ u1j½i þ u2k½i
Sometimes aggregated data may be recorded for cross-hatched factors
without individual information being available. For example, deaths or
hospital referrals may be recorded for area of residence (j) and for the
RANDOM EFFECTS FOR CROSSED FACTORS
333

general practitioner (GP) practice (k) the patient is registered with. Let h
range from 1 to H ¼ JK and let j½h and k½h denote the factors deﬁning
particular levels of the cross-hatched index h ¼ 1; . . . ; H. Let yh be
counts with yh  PoðhEhÞ with Eh being exposed to risk totals (e.g.
populations living in area j and also registered with GP practice k) or
expected events. Then as above there are options for modelling random
effects, such as
logðhÞ ¼ Xh þ Wj½h þ Zk½h þ 
h
ð10:12Þ
where (for example)

h  Nð0; 2
hÞ
This model may also be stated as
logðhÞ ¼ Xh þ 
h
where 
h  Nð	h; 2
h) and 	h ¼ Wj½h þ Zk½h. Another option is separate
random effects u1 and u2 for the two factors
logðhÞ ¼ Xh þ Wj½h þ Zk½h þ u1j½h þ u2k½h
ð10:13Þ
where u1j  Nð0; 2
1) and u2k  Nð0; 2
2). An additional possibility
(Congdon and Best, 2000) is to deﬁne a bivariate effect 
h ¼ ð
h1; 
h2Þ
with dispersion matrix 
 and means
	h1 ¼ Wj½h
	h2 ¼ Zk½h
with
logðhÞ ¼ Xh þ 
h1 þ 
h2

h  N2ð	h; 
Þ
ð10:14Þ
This structure expresses correlations in the overlapping impact of the two
factors and generalizes to more than two factors. If one or more of the
factors were spatially or temporally structured then one may introduce
structured effects into the means. For example,
	h1 ¼ Wj½h þ sj½h
where the sj, j ¼ 1; . . . ; J, are spatially structured. Unstructured effects
speciﬁc to one or more factor may also be included in the means.
Example 10.3
Child respiratory hospitalizations
Child respiratory
illness, including asthma incidence and hospital admissions, has been
increasing in developed societies and there are well-established links with
334
HIERARCHICAL AND PANEL DATA MODELS

socio-economic deprivation in the area of residence, here deﬁned by UK
electoral wards (Payne et al., 1993). GP practices have responsibility for
registered populations that are geographically unrestricted and so will
cross ward boundaries. They are responsible for referring their more ill
patients to hospital, and their referral rate variation may reﬂect differ-
ences in the deprivation levels of their registered population but also the
effectiveness of case management in primary care. So both ward (small
area) and GP practice attributes may inﬂuence variation in counts of
hospitalizations at the crossed factor level.
There are j ¼ 1; . . . ; 44 wards and k ¼ 1; . . . ; 99 practices in a study
considering referrals to hospital for children aged 0–14 years with
respiratory illness during the ﬁve ﬁnancial years from 1 April 1991 to
31 March 1996 (Congdon and Best, 2000). Preliminary analysis of
referral patterns selected combinations of wards and practices which
accounted for the great majority of the at-risk population (for many
combinations there are no children at risk) and h ¼ 1; . . . ; 345 such
combinations were identiﬁed (so H ¼ 345 rather than 44  99).
Ward-level predictors included the Townsend index of neighbourhood
deprivation, and a practice-level deprivation score was derived by assign-
ing each patient afﬁliated to the practice with the Townsend index of their
census enumeration district (which nests within wards), and then aver-
aging over all patients. Other predictors are ward-level population density
(a proxy for urban environment and trafﬁc density), a ward-level measure
of geographic access to hospitals, and an indicator of practice-level
prescribing efﬁciency, i.e. the ratio of net costs of prophylactic asthma
prescriptions to bronchodilator prescribing.
The bivariate normal effects structure in (10.14) is adopted with
a Wishart WðI; 2Þ prior assumed for 1

 . A spatial effect is included
in the mean for wards, 
h1, and an unstructured effect in the mean for 
h2.
So
logðhÞ ¼ Xh þ 
h1 þ 
h2

h  N2ð	h; 
Þ
	h1 ¼ Wj½h þ sj½h
	h2 ¼ Zk½h þ uk½h
A two-chain run of 10 000 iterations converging after 5000 shows a high
negative correlation (around 0.8) between the effects. Of the ﬁve
predictor effects only one is signiﬁcant (ward deprivation with a positive
effect, as expected). Two other regression coefﬁcients have means in
the expected direction but their credible intervals overlap zero, namely
RANDOM EFFECTS FOR CROSSED FACTORS
335

prescribing efﬁciency and practice deprivation. Variation between prac-
tices may in part reﬂect efﬁciency, and so of interest for assessing
‘performance’ are the average ranks of the practice effect uk. For
example, practice 39 has a median rank of 96 (out of 99), and practices
47 and 78 have median ranks of 92.
The average GLM deviance is 347 so the model seems to represent the
dispersion structure accurately; however, de is relatively high at 213
(DIC ¼ 1952) so more parsimonious models may be obtained. The most
aberrant case according to CPO estimates is Y35 ¼ 14 (against an
expectation E35 ¼ 1:8) and with estimated referrals lower at 35 ¼ 8.
10.5
THE GENERAL LINEAR MIXED MODEL
FOR PANEL DATA
Parallel to the hierarchical model for metric data (10.1) is the linear
random effects model for longitudinal metric data,
Yi ¼ 1 þ Xi þ Zibi þ "i
where Yi and "i are Ti  1, Xi is Ti  p (sometimes called a design matrix
if it represents allocation of subjects to treatments or other experimental
groups), and  is a (p  1) vector of regression coefﬁcients modelled as
ﬁxed effects. Zi is a Ti  q matrix of predictors the impacts of which, as
expressed by the q  1 vector bi, vary between subjects.
For simplicity assume Ti ¼ T (all subjects are observed the same
number of times). For categorical data Yi ¼ ðyi1; yi2; . . . ; yiTÞ0 from the
exponential family
pðyitjitÞ ¼ expf½yitit   ðitÞ=aitðÞ þ cðyit; Þg
with link g, it ¼ EðyitjitÞ ¼ d ðitÞ=dit and VarðyitjitÞ ¼ d2 ðitÞ=
d2it. The corresponding model for the mean in a GLMM is
it ¼ g1ð þ Xit þ ZitbiÞ
ð10:15aÞ
The repetition over individuals and times allows for time-speciﬁc
regression effects, so that with more generality
it ¼ g1ð þ Xitt þ ZitbiÞ
ð10:15bÞ
For instance, a longitudinal count regression with GLMM form could
take the form
yitjbi  PoðitÞ
logðitÞ ¼  þ Xitt þ Zitbi
336
HIERARCHICAL AND PANEL DATA MODELS

while a longitudinal logit regression with denominators Nit could be
yitjbi  BinðNit; itÞ
it ¼ expð þ Xitt þ ZitbiÞ=½1 þ expð þ Xitt þ ZitbiÞ
Often q ¼ 1 so that there is only a varying intercept b
i ¼  þ bi, often
called a permanent effect or said to represent permanent heterogeneity.
Thus
it ¼ g1ð þ Xitt þ biÞ
ð10:16Þ
Fixed effects models have been proposed for such permanent subject
parameters on the grounds of robustness, avoiding choosing a particular
density for heterogeneity over subjects or the assumption that individual
effects are uncorrelated with regressors (Hsiao, 1986). However, there are
likely to be beneﬁts in terms of parsimony, identiﬁability and ‘pooling
strength’ by modelling heterogeneity with random effects that refer to a
population-wide probability distribution. This is especially the case when
the number of repetitions Ti is small and ﬁxed effects are not well
identiﬁed. As an example of parametric errors, one may assume
bi  Nqð; bÞ
with  ¼ ð1; . . . ; qÞ0 and 1 ¼ 0. Alternatively, for a random intercept
model with q ¼ 1, bi  Nð0; 2
b). However, scale mixing or non-
parametric error forms may be adopted in the search for greater robust-
ness, while still pooling strength, unlike the ﬁxed effects scheme (Ibrahim
and Kleinman, 1998) – see section 10.6.
Models for longitudinal discrete data will often show overdispersion
that may sometimes be resolved simply by including permanent subject
effects, but may sometimes require additional random variation at unit
(subject-times time) level, namely
it ¼ g1ð þ Xitt þ Zitbi þ "itÞ
ð10:17aÞ
where the "it are possibly normal, scale mixtures of normals, or discrete
mixtures including Dirichlet process priors (Hirano, 1999). The errors "it
are generally unstructured in time but time dependence may be relevant,
especially for larger T. Note, however, that (10.17a) includes a form of
correlation between times. Consider the case q ¼ 1:
it ¼ g1ð þ Xitt þ bi þ "itÞ
ð10:17bÞ
with unstructured errors "it having variance 2
". Letting the total residual
be !it ¼ "it þ bi, then the correlation between !it at different periods is
 ¼ 2
b=ð2
b þ 2
"Þ
ð10:17cÞ
THE GENERAL LINEAR MIXED MODEL FOR PANEL DATA
337

Model checking for models such as (10.17) may consider Monte Carlo
estimates of the CPO either at unit level (based on harmonic means of
likelihoods at unit level) or at subject level (by totalling the pseudo
marginal likelihoods over times for a given individual). Outliers may also
be detected by directly considering estimates of the permanent subject
effects fbi1; bi2; . . . ; biqg and the unit-level effects "it.
If r cluster characteristics Wi ¼ ðW1i; W2i; . . . ; WriÞ0 are thought to
account for heterogeneity in intercepts or slopes over clusters, one may
assume a multivariate regression for cluster effects
bi ¼ Wi’ þ vi
where the ﬁxed effects regression parameter matrix ’ is of order r  q,
and
vi  Nqð0; bÞ
10.5.1
Time dependence
Heterogeneity between subjects, as in (10.16), or between observations as
in (10.17), may operate through an autocorrelated structure in data or
errors. Under augmented data sampling correlation effects may involve
both the observed and augmented data. Suppose as in section 10.3 that for
binary observations yit latent continuous data y
it are obtained by truncated
sampling (Albert and Chib, 1993). Then one might allow for lagged error
effects via
y
it ¼ Xitt þ Zitbi þ 
it

it ¼ 

i;t1 þ uit
representing (say) persistence in the impacts of unmeasured propensities
in choice applications. The uit are unstructured. A random walk prior on

it is also possible, e.g.

it  Nð
i;t1; 2

Þ
True state dependence would involve a lag on yit itself, and both types of
dependence are included in the model
y
it ¼ Xitt þ Zitbi þ YYi;t1 þ 
it

it ¼ 

i;t1 þ uit
Here Y measures the impact of observed choice at t  1 on the current
propensity.
338
HIERARCHICAL AND PANEL DATA MODELS

Alternatively, following Heckman (1981), consider the intercept-only
model as in (10.17b) with uncorrelated unit errors "it,
y
it ¼ Xitt þ bi þ Yyi;t1 þ "it
Then a factor analytic extension to this model achieves time-varying
correlation between disturbances. Let t be time-varying loadings on the
permanent effects, namely
y
it ¼ Xitt þ tbi þ Yyi;t1 þ "it
ð10:18Þ
where for identiﬁability the bi are taken to have known variance (e.g.
bi  N(0,1)), or one of the t is constrained. If
t ¼ 2
t 2
b=½2
t 2
b þ 2
"
then the correlation between total disturbances !it ¼ tbi þ "it at times t
and s is ðtsÞ0:5.
For count data, sampling latent (e.g. normal) data is more problematic
(though see Oh and Lim, 2001). Generalizations of the methods used in
Chapter 8 may be considered to allow autoregression in Poisson or
negative binomial models. For observation-driven dependence, the Zeger
and Qaqish (1988) method sets Vit ¼ yit þ cð0 < c < 1Þ, so a lag 1
dependence would be
yit  PoðitÞ
logðitÞ ¼ V logðVitÞ þ Xitt þ Zitbi
For a positive V, the means it increase with the preceding period’s
count, whereas for negative V the means fall as yi;t1 increases. Such a
model might not remove temporal correlation in residuals, deﬁned, for
example, via (Cantoni, 2004)
rit ¼ ðyit  itÞ=0:5
it
and additional lags in Vit might be added or autoregression in a latent
error 
it introduced, as above. Similarly, an extension of the conditional
linear autoregessive process for count data (Grunwald et al., 2000) would
set
it ¼ yi;t1 þ expðXtt þ ZitbiÞ
A factor analytic model as in (10.18) with time-varying loadings on one
or more bik, k ¼ 1; . . . ; q, could also be used for modelling parameter-
driven autodependence. Thus with q ¼ 1, and the above method for
observation lags,
logðitÞ ¼ tbi þ Xitt þ V logðVitÞ þ "it
Lee and Hwang (2000) and Diggle (1988) consider an AR(1) error
component

ijt
in
three-level
longitudinal
data
with
individuals
THE GENERAL LINEAR MIXED MODEL FOR PANEL DATA
339

j ¼ 1; . . . ; Ni nested within groups i ¼ 1; . . . ; I. Thus with yijt  EFðijtÞ
it is now possible to let  vary over subjects as well as over times, and bij
may vary by both groups and individual. For example,
gðijtÞ ¼ Xijti þ Zijtbij þ 
ijt þ "ijt
where 
ijt are autocorrelated (e.g. AR(1) or AR(p)) and "ijt are unstruc-
tured N(0,2).
While AR(1) or random walk dependence in 
it or 
ijt is the simplest
model for serial correlation, more complex models may be estimated,
especially for larger data sets. As Jones (1993, p 65) points out, many
panel data sets are not long enough to support complicated error
structures. A general form for 
i ¼ ð
i1; . . . ; 
iT) in a two-level model
is a multinormal density of dimension T

i  NTð0; 2CÞ
where 
i ¼ ð
i1; . . . ; 
iTÞ and the form of C ¼ Covð
t; 
ts) reﬂects
possible time dependencies. Thus an AR(1) error structure with correla-
tion  2 ð1; 1Þ gives
C ¼
1

2
3
  
T1

1

2
  
T2
2

1

  
T3
3
2

1
  
T4
...
T1
  
  
  
  
1
2
66666664
3
77777775
Other error structures are possible (e.g. ARMA) or specialized dispersion
structures such as correlation depending only on the time difference t  s
leading to constant parameters along every diagonal
C ¼
1
1
2
3
  
T1
1
1
1
2
  
T2
2
1
1
1
  
T3
3
2
1
1
  
T4
..
.
3
2
1
T1
  
  
  
  
1
2
66666664
3
77777775
10.5.2
Longitudinal categorical data
Longitudinal multinomial and ordinal responses occur often for biometric
or attitudinal studies where observations are classiﬁcations, ordered or
unordered. Such data raise distinct modelling issues. For example, for
340
HIERARCHICAL AND PANEL DATA MODELS

ordinal outcomes (with J levels) thresholds on a continuous scale,
possibly time speciﬁc, may be assumed to underlie observed gradings,
namely 1t, 2t; . . . ; J1;t. Saei and McGilchrist (1998) refer to this as a
time-dependent longitudinal threshold model. As for the three-level panel
model for count or binary data, one may also consider modelling cluster
effects bij speciﬁc to clusters i and categories j. Although it does not
necessarily imply augmented data sampling, consider the observed
responses Y as resulting from latent propensities or abilities Y. Thus
for ordinal data yit ¼ j if
j1;t < y
it < jt
where
y
it ¼ Xitt þ Zitbi þ "ijt
and
"ijt  Nð0; 1Þ
under a probit link. Departures from proportional odds would allow t
and bi to be group speciﬁc, with
y
it ¼ Xitjt þ Zitbij þ "ijt
To ensure identiﬁability one may either omit intercepts from Xit or take
1t ¼ 0. In some panel studies changing thresholds are interpretable as
changes in measurement scales or recording instruments when the focus
is on estimating progress in individual ratings; for example, attempts to
measure whether a mood factor is changing over time would be
complicated by allowing changing scales (Steyer and Partchev, 2000).
A DGLM-based approach applicable to aggregate multinomial and
ordinal data is used by Cargnoni et al. (1997). Here
Yit  Muðnit; pitÞ
where Yit ¼ ðyit1; . . . ; yitJÞ, pit ¼ ðpit1; . . . ; pitJ) and logðpitj=pitJÞ ¼ tjþ
itj, where tj are trend parameters speciﬁc to category j (e.g. national
party afﬁliation trends), and itj are residual trend parameters, represent-
ing area or group differentials from the overall trend. For identiﬁcation
tJ ¼ itJ ¼ 0. The overall trend parameters provide a mechanism for
cross-series pooling of strength. Cargnoni et al. assume both these sets of
parameters to be MVN with an RW(1) form for itj. They also impose the
identiﬁability constraint
Ntj ¼
X
N1
i¼1
itj
THE GENERAL LINEAR MIXED MODEL FOR PANEL DATA
341

In the voting trend by area example below (Example 10.5) it was found
beneﬁcial for out-of-sample forecasting (periods T þ 1 etc.) to add a
constant interaction effect ij in the model for pitj.
Autocorrelation in panel categorical data may also be modelled via
hidden Markov models as in Chapter 9. For example, Bo¨ckenholt (2002)
suggests a random effects model for binary panel choice data based on a
latent two-state Markov chain. Preferences both in the choice and in the
Markov transition behaviour are allowed to vary over individuals. Here
we consider a generalized version of this approach with the yit falling into
one of J categories, and the latent state Lit falling into one of K groups.
Then
PrðLit ¼ kÞ ¼ q½i; Li;t1; k
for t > 1, where
logðqijk=qitKÞ ¼ jk þ jkFi
and for identiﬁcation the subject random effects Fi have known variance,
and additionally jK ¼ jK ¼ 0. Also
Prðyit ¼ jÞ ¼ p½i; Lit; t; j
where
logðpiktj=piktJÞ ¼ 1kj þ 2ij þ 3tj
and 1kJ ¼ 2iJ ¼ 3tJ ¼ 0 for identiﬁcation. The 1kj represent choice
factors that vary according to latent group, and the subject choice random
effects 2ij have dimension J  1. One might as in Bo¨ckenholt (2002)
model the Fi and 2ij via a J-dimensional random effects density. The
ﬁnal element of this model speciﬁes the distribution between latent states
at time 1: for example,
PrðLi1 ¼ jÞ ¼ r½i; k
where
logðrik=riKÞ ¼ Wik
where Wi ¼ ðWi1; . . . ; WiLÞ are ﬁxed attributes of subject i, and K ¼ 0.
Example 10.4
Respiratory symptoms in ohio children
Fitzmaurice
et al. (2003) consider binary data on wheeze symptoms among 537 Ohio
children at ages 7, 8, 9 and 10 in terms of their age ðAtÞ, maternal
smoking status (Mi ¼ 1 for smoking mothers) and an interaction AtMi.
Here we contrast the effectiveness of logit and complementary log–log
links (models 1 and 2 respectively) for these data using predictive criteria
342
HIERARCHICAL AND PANEL DATA MODELS

and model weights under parallel sampling (Congdon, 2005). The
regression models in each case are deﬁned by a single permanent subject
effect bi (i ¼ 1; . . . ; 537) and the three predictors.
To assess predictions using replicate data ynew from the model, sensi-
tivity and speciﬁcity (proportions of wheeze and non-wheeze children
correctly identiﬁed as such) are obtained for each age group by checking
concordance between ynew;i;t and yit. A total measure of predictive
accuracy in each age group is the sum of sensitivity and speciﬁcity
(Youdens index  t) as used by Congdon (2001a) and a 95% interval can
be obtained for the difference  1t   2t in predictive accuracy between
the models. One may also obtain posterior probabilities that model 1
provides better predictions, namely
Prð 1t >  2tÞ
The model weights (2.19)–(2.21), DIC differences DICjk and prob-
ability estimates (2.34) are also obtained.
The DICs under model 1 and 2 suggest that the complementary log–log
link is preferable (DIC1 ¼ 1416 vs. DIC2 ¼ 1403). This preference is
entirely due to complexity differences: model 1 has both a higher average
likelihood and higher likelihood at 1. The effective parameters are
de1 ¼ 248:5 and de2 ¼ 224 (according to the
DIC method) and
de1 ¼ 492 and de2 ¼ 445 according to the approximation (2.26) from
Gelman et al. (2003). The former are used to obtain the density of ðtÞ
12 as
in (2.25). Over the second half of a single chain of 10 000 iterations,
covariation between DIC(ðtÞ
1 ) and DIC(ðtÞ
2 ) is 51. The empirical
variance of ðtÞ
12 of 1975 includes this covariation but after adjustment
Var(DIC12) corresponds to
VarððtÞ
12Þ ¼ VarðDIC12Þ  2Cov½DICððtÞ
1 Þ; DICððtÞ
2 Þ
¼ 2ðde1 þ de2  w12Þ ¼ 2ð492 þ 445 þ 51Þ
Accordingly the difference DIC12 of 13 compares with a standard
deviation of 43 ¼ ð2:492 þ 2:445Þ0:5, suggesting a large element of
model uncertainty remains. The posterior probability that
Pr½DICððtÞ
1 Þ > DICððtÞ
2 Þ
is accordingly far from decisive and is obtained as 0.62. The AIC and
BIC weights include higher penalties for complexity than the DIC. The
result is that the BIC decisively favours model 2 ðw2 ¼ 0:9997Þ. The
Bayesian model weight estimate gives w2 ¼ 0:97, while the Akaike
weight gives w2 ¼ 0:8. Likelihood weights are not penalized for com-
plexity and very slightly favour model 1 ðw1 ¼ 0:55Þ.
THE GENERAL LINEAR MIXED MODEL FOR PANEL DATA
343

Prediction-based model comparisons are also not penalized for com-
plexity - though see Congdon (2005). The probabilities Prð 1t >  2tÞ are
accordingly all around 0.5 and the differences  1t   2t do not seem to
show a marked difference between the models.
Example 10.5
Canadian voting intentions
Gustafson and Walker
(2003) analyse voting intention data for J ¼ 4 major Canadian parties
(excluding Bloq Quebecois) over ten months in 2000 (source: www.ip-
sos-reid.com). March, April and June are omitted as polls were not
conducted, so T ¼ 7. Gustafson and Walker (2003) consider just trends in
the Atlantic provinces. Areas i ¼ 1; . . . ; 5 are considered here, namely
Atlantic provinces, BC, Alberta, Saskatchewan/Manitoba and Ontario
(Table 10.1).
Cargnoni et al. (1997) adopt an arcsin transformation to link the
probabilities itj to the 
itj. Here the multinomial logit approach of
Leonard and Hsu (1994) is adapted to this dynamic model. Additionally
an RW(1) prior for both tj and itj is assumed together with area-speciﬁc
dispersion matrices i for the itj rather than a common  over all areas.
Hence with J ¼ 4, T ¼ 7 and N ¼ 5, the model is
Prðyit ¼ jÞ ¼ pitj
logðpitj=pitJÞ ¼ ij þ tj þ itj
with iJ ¼ tJ ¼ itJ ¼ 0. The priors on the randomly evolving para-
meters are
1j  Nð0; 1000Þ
j ¼ 1; . . . ; J  1
t  NJ1ðt1; TÞ
where t ¼ ðt1; t2; . . . ; t;J1) and
1;t  Nð0; 1000Þ
j ¼ 1; . . . ; J  1
it  NJ1ði;t1; iÞ
i ¼ 1; . . . ; N  1
where it ¼ ðit1; it2; . . . ; it;J1Þ and the dispersion is area speciﬁc. A
Wishart prior with J  1 degrees of freedom and 0.0001 diagonal
elements is assumed for the inverse dispersion matrices. For the interac-
tions it is assumed that
ij  Nð0; 1000Þ
i ¼ 1; . . . ; N  1; j ¼ 1; . . . ; J  1
344
HIERARCHICAL AND PANEL DATA MODELS

Table 10.1
Voting intentions by province and month (excluding undecided)
Conservative
Liberal
New Democratic Alliance
Total
British Columbia
Jan
12
71
24
50
157
Feb
9
74
28
50
161
May
14
78
24
60
176
July
9
65
20
79
173
Aug
13
78
20
96
207
Sept
10
84
12
68
174
Oct
9
68
12
84
173
Alberta
Jan
20
40
11
50
121
Feb
21
37
11
48
117
May
20
36
11
72
139
July
11
24
8
65
109
Aug
16
42
6
86
150
Sept
12
45
6
57
120
Oct
9
38
4
75
126
Saskatchewan/Manitoba
Jan
11
36
25
19
91
Feb
9
42
28
26
104
May
12
43
22
32
110
July
14
26
27
39
105
Aug
8
38
23
39
108
Sept
12
48
17
24
101
Oct
4
43
26
36
109
Ontario
Jan
113
292
56
40
501
Feb
88
287
54
54
483
May
93
259
49
78
479
July
62
261
43
100
466
Aug
65
355
72
134
626
Sept
53
290
47
90
480
Oct
49
248
44
136
477
Atlantic
Jan
34
42
22
5
103
Feb
22
53
22
6
103
May
30
53
13
6
102
July
24
47
25
17
113
Aug
31
70
16
15
132
Sept
21
64
13
13
111
Oct
21
59
16
15
111
THE GENERAL LINEAR MIXED MODEL FOR PANEL DATA
345

The identiﬁability constraints
Ntj ¼
X
N1
i¼1
itj
Nj ¼
X
N1
i¼1
ij
are also imposed. Additionally the variance matrices are scaled to allow
for the unequal spacing of polls.
Following Gustafson and Walker (2003) one question of interest is the
smoothing of ‘wiggles’ in the data such as the May surge in the
Conservative voting intention in the Atlantic provinces. Extrapolation
to future periods is also of interest. For forecasting intentions one period
ahead (November, 2000) the following speciﬁcation is assumed:
pi;Tþ1;j ¼ i;Tþ1;j=
X
k
i;Tþ1;k
logði;Tþ1;jÞ ¼ ij þ Tþ1;j þ iTj
j ¼ 1; . . . ; J  1
i;Tþ1;J ¼ 1
since the itj are estimated rather imprecisely and make forecasting
intervals too wide if they are extrapolated.
A two-chain run of 10 000 iterations (convergent from around 5000
iterations) shows smoothing downwards of the Conservative intention for
May in the Atlantic provinces, and smoothing up of the February
percentage. The forecast for the Atlantic Conservative voting proportion
in November (namely p5;8;1) is close to the October mean of 19.4% but
with a wider 95% credible interval, i.e. (0.115,0.29) compared with
(0.125,0.27) for October.
10.6
CONJUGATE PANEL MODELS
Section 10.5 has considered the GLMM strategies for panel models. By
contrast, conjugate models for modelling both overdispersion and the
permanent effects (e.g. Daniels and Gatsonis, 1999) involve Poisson–
gamma mixing, beta–binomial mixing or multinomial–Dirichlet mixing.
Thus gamma mixing on the underlying mean for count data as in
yit  PoðitÞ
it  Gaðhit; hÞ
logðitÞ ¼ t þ Xitt þ Zitbi
346
HIERARCHICAL AND PANEL DATA MODELS

with h > 0 preset or an extra unknown, leads to an overdispersed Poisson
since
VðyitÞ ¼ it þ it=h
Taking hi to vary between subjects, e.g. by taking hi=ð1 þ hiÞ to be beta
distributed, leads to a subject-speciﬁc variance–mean ratio, while taking
h to vary over times gives a time-speciﬁc variance–mean. Similarly for
binomial data, one might specify
yit  Binðnit; itÞ
it  BeðritMt; ð1  ritÞMtÞ
gðritÞ ¼ t þ Xitt þ Zitbi
where Mt is an extra unknown. The priors on it are independent with
regard to time. An alternative is gamma or beta mixing for the intercept
only (Hausman et al., 1984) so that for a count response
yit  PoðiitÞ
i  Gaðh; hÞ
logðitÞ ¼ t þ Xitt
The variance is then it þ 2
it=h and the variance–mean ratio ð1 þ it=hÞ
increases with it. Another conjugate longitudinal model adapts the
Rasch Poisson count model (Jansen, 1997) and assumes for subject i
and time t
yit  PoðitÞ
it ¼ 	iit
where
	i  Gaðh; h=iÞ
and
it  DirðMi1; . . . ; MiTÞ
The 	i are constant subject effects with i ¼ expðXiÞ possibly a function
of time constant attributes. The it
are subject-speciﬁc occasion
parameters that may be related to time-varying predictors. When not
related to predictors the Mit may be assigned pooling strength priors, or
taken as constant over clusters ðMit ¼ MtÞ to represent population-wide
period intensities. Or they may deﬁne a population-wide growth model, e.g.
logðMtÞ ¼ 0 þ 1t
The marginal likelihood involves a negative binomial for the total count
yiþ ¼ P
t yit and a multinomial for yit conditional on yiþ with parameters
it=iþ.
CONJUGATE PANEL MODELS
347

The impact of predictive or risk factors may modelled at individual
level or via stratiﬁcation. For example, suppose panel data are recorded
for groups of subjects (e.g. deﬁned by several demographic character-
istics) rather than individuals. The data might be for demographic strata
(e.g. age–sex–ethnic subgroups by area) and the event might be divorce,
political participation, etc. For binary events, let gt be the rate at time t
for subgroup g, with ygtjgt  Binðngt; gtÞ, and let prior heterogeneity in
rates fðgtÞ over subpopulations and periods be represented by a beta
mixture. An independence prior on  would allow rates in different
periods to have unrelated priors, e.g. gt  Beðag; bg) where ag and bg
might be preset or extra unknowns. However, if the chance of the event is
varying over time (i.e. there is non-stationarity) and rates in successive
periods are correlated then successive odds ratios may be linked accord-
ing to
½gt=ð1  gtÞ ¼ gt½g1=ð1  g1Þ
where ‘improvement ratios’ gt are positive and
g1  BetaðrgMg; ð1  rgÞMgÞ
where rg is the initial rate for group g and Mg is a prior sample size
(Davies et al., 1982). Equivalently
logitðgtÞ ¼ logðgtÞ þ logitðg;t1Þ
For gt ¼ logðgtÞ one might adopt state-space priors that penalize large
changes, in line with an expectation of smoothly changing event rates.
For Poisson data ygt  Poðgt), with gt  Gaðhgt; hÞ, the improvement
factors would be modelled via relative risks
gt=g1 ¼ gt
For categorical observations (e.g. polling intentions for J political parties)
for g ¼ 1; . . . ; N areas through times t ¼ 1; . . . ; T similar considerations
apply. Let ngt denote the total subjects (e.g. voters surveyed) in area g at
time t. In this case
Ygt  Muðngt; pgtÞ
where Ygt ¼ ðygt1; ygt2; . . . ; ygtJÞ, pgt ¼ ðpgt1; pgt2; . . . ; pgtJÞ. An indepen-
dence prior could be
pgt  Dirðgt1; . . . ; gtJÞ
Often it is assumed that gtj ¼ h for all g; j and t with h known (e.g.
h ¼ 1). However, a time- and area-independent prior neglects that
probabilities within the sequence for area g tend to be more similar to
348
HIERARCHICAL AND PANEL DATA MODELS

each other than probabilities for different areas, and that probabilities
close in time for area g will be more similar than probabilities separated
by a larger time gap. Gustafson and Walker (2003) propose a prior that
downweights large changes between probabilities in successive periods.
Speciﬁcally
fðpgtÞ / Dirð1; 1; . . . ; 1Þ exp 
X
T
t¼2
X
J
j¼1
ðpgtj  pg;t1;jÞ2=
"
#
where smaller values of  imply greater smoothing. As  ! 1 the
independence prior with h ¼ 1 is obtained. One may also adapt the
improvement ratio method such that for j ¼ 1; . . . ; J  1 and t > 1
logitð pgtjÞ ¼ logðgtjÞ þ logitðg;t1;jÞ
while pg1  Dirðg1; . . . ; gJÞ.
Example 10.6
Seizure data
Seizure data in N ¼ 59 epileptic patients,
ﬁrst presented by Thall and Vail (1990), have become one of the classic
panel data sets for both frequentist and Bayesian analysis. Consider the
mixture model described above with yit  PoðitÞ and it ¼ 	iit where
	i  Ga ðh; h=iÞ and it  DirðM1; . . . ; MTÞ. The subject effects 	i
have means in terms of four ﬁxed attributes
i ¼ expðXiÞ ¼ expð0 þ 1Xi1 þ 2Xi2 þ 3Xi3 þ 4Xi4Þ
where X1 ¼ base seizure count, X2 ¼ treatment (binary), X3 ¼ treatment–
base interaction and X4 ¼ age at baseline. The it are subject-speciﬁc
occasion parameters with
it  DirðMi1; . . . ; MiTÞ
and means Mit ¼ Mt that are based on a linear population growth model
with Mt ¼ expð0 þ 1tÞ.
A two-chain run of 5000 iterations shows a signiﬁcant effect of the
treatment in reducing seizures (95% interval from 1.8 to 0.1) and also
a signiﬁcant impact of the logged baseline seizure count (95% interval
from 0.6 to 1.15). Effects of X3 on 	i and of time in the population growth
model are indicative rather than ‘signiﬁcant’: the 95% intervals straddle
zero, though most of the interval for 1 is negative. The DIC is estimated
as 1146 (de ¼ 121). A predictive check based on 2 statistics comparing
actual and replicate data with it is satisfactory (p statistic 0.44).
However, outlier assessment via CPOs shows y25;3 and y39;2 as suspect
at observation level.
CONJUGATE PANEL MODELS
349

10.7
GROWTH CURVE ANALYSIS
One type of panel model where random variation between subjects is a
major feature is growth curve analysis for evolving biological character-
istics or educational attainments. For instance, Gamerman and Smith
(1996) develop a Bayesian version of the linear growth model proposed
by Fearns (1975) in which a metric or discrete outcome yit for subject i at
time t has a mean
gðitÞ ¼ bi1 þ bi2t
where heterogeneous intercepts bi1 and linear growth rates bi2 are
modelled as exchangeable random effects. bi1 and bi2 can be taken as
two sets of independent effects or to follow a bivariate (e.g. BVN)
density: for example, it may be that growth rates are lower for subjects
with higher initial levels (‘negative feedback’), and this correlation is
accommodated by a bivariate density. Greater robustness may be
achieved by a mixture of bivariate normals, or by mixing the covariance
with subject weights (equivalent to multivariate Student t). Factor
analytic or latent growth curve models introduce factor loadings instead
of functions of time (Rovine and Molenaar, 1998), e.g.
gðitÞ ¼ bi1 þ tbi2
where at least one of the t is preset to ensure identiﬁability, e.g. 1 ¼ 1,
with 2 to T being unknown parameters. A submodel may be used to
explain intercepts bi1 or linear growth rates bi2 in terms of ﬁxed attributes
Wi of subjects.
To accommodate excess heterogeneity and/or remaining autocorrela-
tion, one may specify
gðitÞ ¼ bi1 þ bi2t þ "it
A simple independent errors assumption "i  Nð0; 2
"IÞ for "i ¼ ð"i1; . . . ;
"iTÞ may be assessed against alternatives such as "i  NTð0; "Þ, where
" is an unstructured dispersion matrix, or some speciﬁed time depen-
dence (e.g. AR(1) dependence).
A conjugate model for growth curves might also allow for both non-
parallelism and overdispersion (Jansen, 1997). Thus assume a constant
subject effect 	i and a subject–period effect it based on a regression
involving time t, with
it ¼ 	iit
350
HIERARCHICAL AND PANEL DATA MODELS

where 	i  Gaðc; c=miÞ and it  DirðMi1; . . . ; MiTÞ. Subject means mi
might be related to ﬁxed subject predictors Wi via a log-linear model,
while growth paths are taken as non-parallel according to
logðMitÞ ¼ 
0 þ 
1it
A frequent variation involves multilevel panel data when the subjects fall
into a few subgroups g ¼ 1; . . . ; G, such as treatment groups or schools
(Jones, 1993; Muthe´n, 1997). Then the varying slopes and intercepts
would have means speciﬁc to the treatment group and extra variation may
also be group speciﬁc. So for groups g ¼ 1; . . . ; G and subjects i ¼
1; . . . ; ng within groups
gðitgÞ ¼ bi1g þ bi2gt þ "itg
where a regression model for explaining variation in subject parameters
might be
bi1g ¼ 01g þ 11gWi1 þ 21gWi2 þ    þ ui1g
bi2g ¼ 02g þ 12gWi1 þ 22gWi2 þ    þ ui2g
Another variation for growth curve and other panel analysis is for
unequally spaced observation points (Jones and Boadi-Boateng, 1991).
Thus the observations Yi ¼ ðyi1; . . . ; yiniÞ for subject i are observed at
times ti1; ti2; . . . ; tini and the mixed intercept and slope linear growth
model becomes
gðijÞ ¼ bi1 þ bi2tij þ 
i;tij
j ¼ 1; . . . ; ni
A lag 1 autoregressive structure in 
 would then account for time gaps as
in

i;tij ¼ ðtij  ti;j1Þ
i;ti;j1 þ ui;tij
with Varð
Þ ¼ 2
u½1  2ðtij  ti;j1Þ21
Example 10.7
Change in antisocial behaviour
The development of
antisocial behaviour in adolescence has been linked inter alia to aca-
demic failure, home support, child gender and mother’s age. Curran and
Bollen (2001) use data from the US National Longitudinal Study of
Youth to consider this form of growth trajectory. The antisocial behaviour
scale aggregates over mother’s reports on six items (e.g. child cheats or
lies: 0 if not true, 1 if sometimes true, 2 if often true). The total score
ranges from 0 to 12 on four measurement waves, two years apart starting
in 1986, for children aged 6–8 at the ﬁrst wave.
GROWTH CURVE ANALYSIS
351

Although the six subitems are originally ordinal, the total scores are
here taken as binomial from totals of 12. Predictors are W1 for gender (1
for males), and continuous scores for home cognitive support ðW2Þ that
are ﬁxed over waves. The model ﬁtted is
yit  Binð12; itÞ
logitðitÞ ¼ bi1 þ bi2 t
bi1 ¼ 01 þ 11Wi1 þ 21Wi2 þ ui1
bi2 ¼ 02 þ 12Wi1 þ 22Wi2 þ ui2
where ui  N2ð0; bÞ, and b is assigned a Wishart prior with identity
scale matrix and 2 degrees of freedom.
The second half of a two-chain run of 20 000 iterations shows a
signiﬁcant positive effect of male gender on bi1 (with 11 ¼ 0:45) and a
signiﬁcant negative effect of support ðW2Þ on bi2 (with the posterior mean
22 ¼ 0:028 and a 95% interval from 0.055 to 0.005). The correla-
tion between bi1 and bi2 has a negative mean of 0.2, but the 95%
interval (0.48,0.15) straddles zero.
To identify cases not well represented by this model CPO estimates are
obtained at unit level and the log(PsML) estimates totalled over each
subject’s four observations. This shows subjects 137, 78 and 147 with the
smallest log(PsML) values, namely 14.1, 13.6 and 12.9. Subject
137 has an erratic series of values 3, 1, 0 and 7, as does subject 147 with
0, 4, 10 and 7. These patterns are at odds with linear trends. Considering
outlyingness of individual gradients bi2 in relation to the average growth
rate b2 ¼ P bi2=221, subject 200 is identiﬁed with the lowest bi2 (her
trajectory is 3, 0, 0, 0). Subjects 147 and 156 have the highest bi2
(probabilities over 0.995 of exceeding the average), though the growth for
147 is discontinuous. While a non-linear model would be infeasible with
such a short series, it is relevant that the population growth is highest
between periods 1 and 2 (mean 1.84 in period 2 vs. 1.49 in period 1) and
slower thereafter (means 1.88 and 2.07 in the next two periods). It may
therefore be relevant to try to distinguish linear growth pattern subjects
from other more irregular paths.
10.8
MULTIVARIATE PANEL DATA
The above models generalize readily to more than one outcome with
correlations between outcomes modelled via permanent effects or
352
HIERARCHICAL AND PANEL DATA MODELS

possibly observation effects. Thus for outcomes m ¼ 1; . . . ; M over time
yimt  EFðimtÞ a possible structure would be
itm ¼ g1ðtm þ Xittm þ Zitbim þ "itmÞ
where Xit is 1  p, and Zit is 1  q. If unstructured in time, the unit-time–
response errors "it ¼ ð"it1; . . . ; "itMÞ might be MVN, scale mixtures of
MVNs, or discrete mixtures of MVNs. If autoregression is required in the
"itm then a VAR(1) of order M or multivariate random walk would be
relevant. For example, an RW(1) of order M is
"it  NMð"i;t1; T"Þ
The dynamic regression coefﬁcients tm ¼ ðtm1; . . . ; tmpÞ0 might also
adopt multivariate random walk priors; an RW(1) prior with interdepen-
dence between outcomes m is
tm  Npðt1;m; mÞ
The permanent effects bim are likely to be correlated over outcomes
according to a covariance structure of dimension qM. For example,
suppose growth curve analysis for M ¼ 2 correlated responses (e.g.
maths and linguistic scores) was required. Intercepts and slopes vary
over subjects, so q ¼ 2. Then one might specify
gðit1Þ ¼ bi11 þ bi12t þ "it1
gðit2Þ ¼ bi21 þ bi22t þ "it2
Let di1 ¼ bi11; di2 ¼ bi12; di3 ¼ bi21 and di4 ¼ bi22 and assume di 
N4ðd; dÞ where di ¼ ðdi1; di2; di3; di4). Then negative correlations
between di1 and di2 and between di3 and di4 represent negative feedback
within outcomes. By contrast, positive correlations between di2 and di4
may be expected if yit1 and yit2 are both positive measures of ability,
mood, etc. As another example, consider the mixed intercept model
itm ¼ g1ðtm þ Xittm þ bim þ "itmÞ
Here the bi ¼ ðbi1; . . . ; biMÞ are outcome-speciﬁc intercepts and a multi-
variate prior of dimension M would be appropriate for pooling strength
over the outcomes.
Multivariate
longitudinal
data
may
gain
from
factor
analytic
approaches that also pool information. For example, Steyer and Partchev
(2000) consider panel multivariate ordinal data for subjects i, times t,
items m and categories j ¼ 1; . . . ; Jm. Then Yit ¼ ðyit1; . . . ; yitMÞ where
yitm may be in one of Jm ordered categories. Their application relates to
different measures of mood so a common factor it pooling over the
MULTIVARIATE PANEL DATA
353

outcomes and measuring the trend in mood for subject i may be
considered. If the impacts of a treatment were being monitored then it
is sensible to assume constant thresholds, i.e.
mtj ¼ mj ð j ¼ 1; . . . ; Jm  1Þ
on the M ordinal scales. Otherwise changes in measuring instrument are
confounded with treatment impact. So
Prðyitm ¼ jÞ ¼ itmj
where
itm1 ¼ itm1
itmj ¼ itmj  itm;j1
j ¼ 2; . . . ; Jm  1
itmJm ¼ 1  itm;Jm1
logitðitmjÞ ¼ mj  itm
j ¼ 1; . . . ; Jm  1
Regression coefﬁcients tm on ﬁxed attributes Xi may be speciﬁc for
response and time. So the regression mean with (say) p ¼ 2 ﬁxed
predictors is
itm ¼ mit þ 1tmXi1 þ 2mtXi2
Also the scale of it is ﬁxed to allow m to be identiﬁed. One may, for
example, take the it as independently N(0,1) or autocorrelated, as in
it  Nði;t1; 1Þ
Factor analytic approaches may also be used in multivariate growth curve
models which occur often in clinical and educational contexts. For
ordinal outcomes a factor-based regression model would involve cumu-
lative probabilities itmj by subject i, time t, outcome m and ordered
categories j. Then a logit model in itmj might take the following form,
pooling growth rate and intercept information over outcomes:
logitðitmjÞ ¼ mj  1mi1  2mi2t  Xitm
ð10:19Þ
where i ¼ ði1; i2Þ is a bivariate factor effect representing intercepts
and growth rates. The cut points mj are taken as ﬁxed through time. An
alternative structure might be
logitðitmjÞ ¼ mj  im1  im2t  Xitm
where im1 and im2 are (correlated) intercept and slope effects
for outcomes m and some loadings t are preset for identiﬁability
(MacCallum et al., 1997).
354
HIERARCHICAL AND PANEL DATA MODELS

Example 10.8
Health demand
To illustrate multivariate count panel
data consider the health demand data from the German Socioeconomic
Panel for 1984–1994, as analysed by Riphahn et al. (2003). There are two
responses, visits to doctor Y1 and visits to hospital Y2, and histories for
N ¼ 3602 female subjects are considered. The relevant questions were
not asked in 1989–1990 and 1992–1993 so there is a maximum of seven
observations per subject. While 375 subjects appear in all years, many
appear only once. The total of observations for person-years (‘units’) is
13 083. Of interest to Riphahn et al. (2003) were the impacts of insurance
cover after demographic inﬂuences (age, income, occupation) had been
controlled for. Demand might be expected to be higher for those within
the public insurance system (most of the subjects) and also among those
purchasing add-on insurance (only a small minority of subjects).
There are 15 (ﬁxed) predictors in the bivariate Poisson model of
Riphahn et al. (2003) who assume ﬁxed regression coefﬁcients and
permanent effects bim which are uncorrelated between outcomes. Thus
yitm  PoiðitmÞ where
logðitmÞ ¼ m þ Xim þ bim þ "itm
where "it  N2ð0; ") but bim  Nð0; mÞ, m ¼ 1; 2. Following the dis-
cussion above, possible variations on this approach would consider
correlated permanent effects and time-varying regression parameters.
Here we continue to assume ﬁxed regression effects but allow in an
extended model for correlated permanent effects.
The ﬁrst model ﬁtted here ignores the jointness of the outcomes. Thus
all outcome-speciﬁc random effects are independent, with "itm 
Nð0; mÞ and bim  Nð0; mÞ. The resulting DIC is 59 680 (de ¼ 9220).
The four coefﬁcients on insurance status are all positive1 but none have
entirely positive 95% credible intervals; this may partly reﬂect a highly
parameterized regression model, with possible scope for eliminating
regressors (e.g. being married and being employed). The estimated bi1
and bi2 have a correlation of 0.19, although are a priori independent.
A modiﬁed model allows for correlation in both unit and subject
effects. The DIC is reduced slightly to 59 570 (de ¼ 9154), despite the
extra parameterization, though this reduction is unlikely to be ‘signiﬁ-
cant’ in view of the high number of effective parameters in the two
models (Congdon, 2005). The correlation between the pair of permanent
1 Under model A the coefﬁcients 1;15, 1;16, 2;15 and 2;16 have posterior means (s.d.) of 0.09 (0.05),
0.055 (0.08), 0.19 (0.14) and 0.27 (0.22). In model B the corresponding estimates are 0.14 (0.06),
0.05 (0.09), 0.27 (0.14) and 0.24 (0.22).
MULTIVARIATE PANEL DATA
355

effects is 0.40 under bivariate normality. However, there is some positive
skew in the distribution of bi2 (hospital visits) compared with bi1 (doctor
visits) – see Figures 10.2 and 10.3. This suggests use of a heavier tailed
density than the bivariate normal for bi, or one allowing for skewness in
the hospital permanent effects (e.g. see section 3.4). Under this model the
effects of public insurance have a more clearly positive impact on both
types of demand.
Example 10.9
Mood change
Steyer and Partchev (2000) consider a
panel of length T ¼ 3 for M ¼ 3 ordinal mood items, each with Jm ¼ 5
levels on a Lickert scale. The items are positive measures of mood, i.e.
whether the subject feels ‘content’ (zufrieden), ‘good’ (gut) and ‘happy’
(glu¨cklich). Predictors are gender (2 ¼ F,1 ¼ M) and age at ﬁrst observa-
tion.
Two models are considered. The ﬁrst (model A) is a random subject–
time effects model with
logitðitmjÞ ¼ mj  Sit  Xim
Figure 10.2
Permanent effects, hospital visits
356
HIERARCHICAL AND PANEL DATA MODELS

where Xi1 ¼ 1 for females (¼ 0 for males), and Xi2 ¼ age=10. The ﬁrst
cut point is set to zero ðm1 ¼ 0Þ, and since there are no period intercepts,
the means for each period of the subject mood scores Sit can be identiﬁed
and represent mean population mood scores. We ﬁnd from a two-chain
run of 5000 iterations that the average S:2 is highest (4.39) with a 95%
interval (3.93, 4.84) compared with S:1 ¼ 4:15 and S:3 ¼ 4:26. As an
example of a subject with major mood shift, subject 42 has item scores
(5, 5, 5) at time 1 but (2, 2, 3) at time 3 with their score S42;t falling from
9.5 to 2.1. The estimated cut points for the three items are very similar,
while the regression effects show older persons and males to have more
positive mood. The DIC is 9670 with pe ¼ 1275.
The second analysis involves a factor model (model B) as in (10.19).
This model includes intercepts with
logitðitmjÞ ¼ mj  t  mit  Xim
so that for identiﬁability factor scores have set means and scale, namely
it  Nð0; 1Þ. The loadings are constrained to positivity, namely
m  Nð1; 1ÞIð0; Þ
Figure 10.3
Permanent effects, doctor visits
MULTIVARIATE PANEL DATA
357

to ensure consistent labelling. Subject scores comparable with those of
the ﬁrst model are obtained as Sit ¼ t þ it
P
3
m¼1
m.
This model reduces the DIC to 9632 with pe ¼ 1283. The estimated m
and their standard deviations are 2.65 (0.12), 2.59 (0.12) and 2.62 (0.12).
The correlation between the two sets of Sit in models A and B exceeds
0.99. The most aberrant unit-level observation according to estimated
CPOs is subject 123 at time 1 for item 2 (with score 5), whereas the other
two items have scores of 1 recorded at this time.
10.9
ROBUSTNESS IN PANEL AND CLUSTERED
DATA ANALYSIS
Models for hierarchical and clustered data sets are often applied to
relatively small data sets with few replications on each subject, but
involve complex random effects models or autocorrelation structures.
There is therefore potential for overﬁtting or applying parametric struc-
tures not supported by the data. Consider the model
yit  EFðitÞ
gðitÞ ¼ t þ Xitt þ Zitbi þ "it
ð10:20Þ
A multivariate or univariate normal is the default in many studies for the
vector of subject effects bi or for unit-level errors "it. Another option in
the variable intercepts model, albeit potentially heavily parameterized, is
to take the bi as ﬁxed effects.
A model form intermediate between taking the bi to be ﬁxed effects
and taking them to be random and fully parametric involves discrete
mixtures. A ﬂexible discrete mixture model that provides a form of
averaging over different numbers of subgroups is obtained under a DPP.
For example, instead of assuming N distinct bi one may allow J < N as
the maximum number of possible values which in turn allows clustering
into a smaller set of J < J distinct values during estimation. The number
of clusters is stochastic and its posterior density will indicate whether the
assumed maximum J is sufﬁcient. Hirano (1999) discusses non-para-
metric alternatives regarding "it, while Kleinman and Ibrahim (1998a,
1998b) consider DPP modelling of permanent effects.
Greater resistance to discrepant observations might also be gained by
scale mixing over subjects. For example, a gamma scale mixture on
358
HIERARCHICAL AND PANEL DATA MODELS

normal subject effects bi leads to a heavier tailed multivariate Student t
model rather than multivariate normality. With q ¼ 1, this involves
bi  Nð0; 2
b=iÞ
i  Gað	=2; 	=2Þ
where 	 may be another parameter. If combined with latent data sampling
as in section 10.3.1, taking 	 as unknown amounts to averaging over
alternative links.
Chen and Dunson (2003) point out that a parametric option such as the
Wishart for b necessarily assumes heterogeneity in effects and does not
include an option whereby bi ¼ 0 for all i (i.e. a homogeneous effect
ik ¼ k of a predictor across all subjects or clusters). Suppose there are p
predictors (including the intercept) and all are potentially heterogeneous,
namely
gðitÞ ¼ Zitbi þ "it
where bi1 is a variable intercept and bi2, bi3, etc., are variable regression
effects having unknown means. Chen and Dunson suggest taking a
Choleski decomposition of b that involves expressing bi as
bi ¼ ci
where
cik  Nð0; 1Þ
k ¼ 1; . . . ; p
and
 ¼ diagð1; . . . ; pÞ
is a vector of elements k 	 0, and  is a lower triangular matrix with
pðp  1Þ=2 unknowns. Thus jj ¼ 1, jk ¼ 0 for k ¼ 1; . . . ; p  1 and for
j > k, and the remaining terms may be assigned unrestricted normal
priors (e.g. for p ¼ 3 the unknowns would be 1; 2; 3; 21; 31 and 32).
A homogeneous effect in predictors k can be allowed for by introducing a
binary indicator: Ak ¼ 1 if k ¼ 0 (homogeneity) and Ak ¼ 0 if k > 0. If
Ak ¼ 0 the k have priors constrained to be positive, e.g. k  Gaðak; bkÞ.
The prior probability PðAk ¼ 0Þ may be set at 0.5 and if Ak ¼ 0 at a
particular
iteration
one
sets
to
zero
all
elements
kj ¼ jk ¼ 0,
k ¼ 1; . . . ; p. The proportion of iterations where Ak ¼ 1 may be com-
pared via an empirical Bayes factor with the prior proportion, to assess
which predictors have heterogeneous effects across subjects or clusters.
Semi-parametric regression models for longitudinal categorical data
seek to robustify the regression component by allowing for non-linear
effects of one or more metric predictors (Chib and Jeliazkov, 2002). Thus
ROBUSTNESS IN PANEL AND CLUSTERED DATA ANALYSIS
359

instead of the standard GLMM with linear effects of Xit, it may be
assumed that a constant non-linear smooth applies to a time-varying
predictor Uit
gð
itÞ ¼ Xit þ SðUitÞ þ Zitbi þ "it
This might apply in true panel studies where a cohort is followed through
time and behaviours such as fertility or labour participation are monitored
as functions of age Uit. Another option with time-varying Uit or constant
Ui is a time-varying smooth such as
gð
itÞ ¼ Xit þ StðUitÞ þ Zitbi þ "it
An example in spatial epidemiology where this might be relevant is for
sets of areas where the impact of deprivation on area mortality is allowed
both to be non-linear and to change between different periods. A
particular application of semi-parametric modelling is when latent data
are introduced as an alternative to direct binary or multinomial logit or
probit analysis. Thus for binary panel data a probit link is equivalent to
Wit  Nðit; 1ÞIðAit; BitÞ
where Ait ¼ ð1; 0Þ and Bit ¼ ð0; 1Þ according as yit ¼ 0 or 1 and
Wit ¼ Xit þ SðUitÞ þ Zitbi
This type of model raises possible identiﬁcation issues with a latent
response and random effects for both the smooth model and the subject
effects bi.
Example
10.10
Epileptic
seizures
To
illustrate
non-parametric
approaches to assessing the pattern of random effects consider again
the epileptic seizure data of Example (10.6). A bivariate random effect
involves the intercept and the slope over visit time (in weeks). Fixed
predictors are as before: X1 ¼ base seizure count, X2 ¼ treatment (bin-
ary), X3 ¼ treatment–base interaction and X4 ¼ age at baseline. These
data are subject to overdispersion as well as widely differing subject
frailties, so a model such as (10.17a) with both bi and "it modelled
parametrically might be considered. One may also consider non-para-
metric alternatives such as a DPP model whereby the random intercepts
and slopes are taken to fall into a maximum of J  N clusters.
Here we consider a model without subject occasion errors "it but with
random intercepts and slopes ðbi1 and bi2) belonging to a maximum J
clusters, where J is taken as 20. The Dirichlet concentration parameter 
is taken as ﬁve, though it might also be an extra unknown; Kleinman and
360
HIERARCHICAL AND PANEL DATA MODELS

Ibrahim (1998b) assume alternative preset options ( ¼ 1:5 and  ¼
100). The base density is taken to be a bivariate normal with precision
matrix P and dispersion matrix D ¼ P1. Kleinman and Ibrahim assume
a relatively informative Wishart prior on P (drawing on an earlier
parametric GLMM analysis), with 	 ¼ 10 degrees of freedom and a
diagonal scale matrix S, with S11 ¼ S22 ¼ 5. Here we take 	 ¼ 5 and S to
be the identity matrix.
Early convergence is obtained in a two-chain run of 15 000 iterations.
The average number of non-empty clusters, J, is 14, with posterior
density (from 10 000 iterations in one chain) as in Figure 10.4. This total
is intermediate between the values 10.6 (for  ¼ 1:5Þ and 17.7 (for
 ¼ 100) reported by Ibrahim and Kleinman (1998). Under this option
for the random variation of intercepts and slopes, the average slope is
negative, i.e. bb2 ¼ 0:29, but not precisely identiﬁed, with a 95% interval
0.86 to 0.25. Also there is virtually no correlation between intercepts
and slopes ðD12 ¼ 0:01 with a 95% interval 0.41 to 0.34) so they
might be modelled as separate DPP effects with possibly differing
numbers of clusters. Both base and treatment effects are signiﬁcant,
however, with the latter having mean 0.89 and 95% interval (1.89,
0.06); age and the interaction effects are not signiﬁcant.
Figure 10.4
Posterior for number of clusters
ROBUSTNESS IN PANEL AND CLUSTERED DATA ANALYSIS
361

A simpliﬁed model might drop one or both of the interaction and age
effects. Here for illustration the age effect is modelled non-parametrically
using prior (3.25), namely
st  Nðst1½1 þ t=t1  st2½t=t1; t2Þ
There are 22 distinct age values and the smooth uses xt ¼ log(age), with
differences then being t ¼ xt  xt1. With an informative Ga(10,2.5)
prior on 2 a quadratic rather than linear age effect is indicated, with peak
inﬂuence around age 30 (Figure 10.5). The treatment effect loses
signiﬁcance under this model with a 95% interval from 1.59 to 0.22.
The Gelman et al. (2003) complexity measure, mentioned in section 2.1,
shows this model to have lower de (i.e. 113 with D ¼ 395:4) than the
linear age model, which has D ¼ 398:7 and higher de ¼ 134. However,
inferences are likely to be sensitive to the prior on 2 which controls the
trade-off between smoothness and ﬁt (Chib and Jeliazkov, 2002).
10.10
APC AND SPATIO-TEMPORAL MODELS
The age-period model is a particular type of panel model that is
commonly applied to death or disease counts yat by age group a
(a ¼ 1; . . . ; A) and period t (t ¼ 1; . . . ; T). An implicit cohort dimension
is then obtained leading to age–period–cohort (APC) models. The usual
sampling assumptions for what is actually observed, namely the yat, are
Poisson, in relation to person-years or expected events Eat, or binomial in
relation to at-risk populations Nat. Suppose yat  PoðEatatÞ and that
mortality or disease incidence is declining at a similar rate across all age
Figure 10.5
Non-linear age effect
362
HIERARCHICAL AND PANEL DATA MODELS

bands. Then the mortality or disease rate trend lines for different age
groups will be approximately parallel and a proportional model
at ¼ expðaÞ expðtÞ
logðatÞ ¼ a þ t
ð10:21aÞ
will be appropriate. While ﬁxed effects priors for a and t are possible,
autoregressive random walk priors are preferable in terms of pooling
strength between adjacent periods or age categories with similar values
(Berzuini and Clayton, 1994, p 828). Possibilities include RW(1) or
RW(2) models, such as
a  Nða1; Þ
(with 1 assumed a priori as a ﬁxed effect) or
a  Nð2a1  a2; Þ
(with 1 and 2 as ﬁxed effects). Greater robustness to shifts may be
gained by scaled mixing, such as
a  Nða1; =!aÞ
where !a is gamma distributed. The difference a  b is interpreted as
the log of the relative risk for age group a compared with that for age
group b. Since a constant may be added to all the  parameters and
subtracted from all the  parameters, this model is not identiﬁed without
constraints. Identiﬁability in a model such as (10.21a) without a constant
may be gained by devices such as centring the t (or the a), or by setting
one parameter to a ﬁxed value, e.g. 1 ¼ 0. An alternative strategy (see
Besag et al., 1995) does not impose such constraints but monitors only
identiﬁable contrasts such as a  b and t  s. If an intercept is
included as in
logðatÞ ¼  þ a þ t
ð10:21bÞ
then identiﬁability requires two constraints such as setting 1 ¼ 1 ¼ 0
or centring both sets of parameters at each MCMC iteration.
The introduction of both age and time means that the birth cohort can
be obtained as
c ¼ A  a þ t
with maximum C ¼ A  1 þ T. For example, if the T ¼ 4 time periods
were 1983–1987, 1988–1992, 1993–1997, 1998–2002 and A ¼ 18 age
bands were 0–4, 5–9, 10–14; . . . ; 80–84 and 85 þ then the ﬁrst cohort
ðc ¼ 1Þ would be those over 85 in 1983–1987 and the last ðc ¼ 21Þ
would be 0–4 year olds in 1998–2002. Deﬁning cohorts is simplest when
APC AND SPATIO-TEMPORAL MODELS
363

age bands and periods are of the same width, though there are ways to
deﬁne cohorts when widths are unequal (Knorr-Held and Rainer, 2001).
A Poisson age–cohort model is then deﬁned as
yat  PoiðEatatÞ
where
logðatÞ ¼ a þ c
ð10:22Þ
where the cohort effects c represent factors that inﬂuence the mortality
or disease incidence of a particular birth cohort throughout their lives.
Identiﬁability in (10.22) requires centring of the c or devices such as
setting 1 ¼ 0 or 1 ¼ 2.
A
model
including
age,
period
and
cohort
effects
for
data
yat  PoiðEatatÞ then has the form
logðatÞ ¼  þ a þ t þ c
ð10:23Þ
This is an APC model and here identiﬁability can be problematic. It
requires that all three sets of effects be centred or the use of devices such
as 1 ¼ 1 ¼ 1 ¼ 0 to set the level of the three series. Additionally the
relation c ¼ A  a þ t introduces an extra identiﬁability issue and an
extra constraint is needed for full identiﬁcation. Often early cohort effects
are poorly identiﬁed and so one might set 1 ¼ 2 as well as centring all
the effects at each MCMC iteration. Knorr-Held and Rainer (2000)
suggest that RW(1) priors introduce a stochastic constraint that obviates
the requirement for an additional formal constraint. Again a possible
alternative is to summarize the model – and gauge convergence – using
only identiﬁable parameter subsets or contrasts. These include the means
at, projections to new years (Bray, 2002), and contrasts such a  b
and c  d. In all the models (10.21)–(10.23) a zero-mean overdisper-
sion effect may be added, so that (10.23) would become
logðatÞ ¼  þ a þ t þ c þ "atc
ð10:24Þ
10.11
SPACE–TIME AND SPATIAL APC MODELS
Models deﬁned over space and one or more time dimensions have diverse
applications such as meteorology, medical imaging and disease mapping.
In spatial epidemiology they may be used to monitor trends in environ-
mental impacts (e.g. lung disease in relation to sources of airborne
pollution) or trends in small-area inequalities in mortality (Congdon,
2004). Consider an application for areas i and times t, and assume
364
HIERARCHICAL AND PANEL DATA MODELS

Poisson sampling of disease or death counts yit in relation to expected
events Eit. Binomial sampling might also be considered for large event
totals or populations relatively small in relation to event totals; see Knorr-
Held (2000) and Knorr-Held and Besag (1998).
Then one possible framework might include constant spatial and
unstructured effects (‘permanent area effects’), si and ui, as in the
cross-sectional mixed models considered in Chapter 8, combined with
area-speciﬁc growth rates. Thus for yit  PoðEititÞ the mixed model of
Besag et al. (1991) might be extended as follows to include a spatially
varying growth curve:
gðitÞ ¼  þ it þ ui þ si
ð10:25Þ
where the effects i may be unstructured with overall average growth rate
. For spatially clustered trends the i might be assumed to be spatially
dependent (Bernardinelli et al., 1995), e.g. with ICAR() form or
following a robust or non-parametric option, to allow for growth
discontinuities.
In addition the basic evolution through time  t of the mortality or
disease rate (or of a p vector of regression impacts t) may be speciﬁed in
various ways: as independent ﬁxed effects t  Nð0; #Þ with # known
and large, or as random effects such as an RW(1) process with
t  Npðt1; VÞ
or modelled via spline functions as in MacNab and Dean (2001). For
example, with yit  PoðEititÞ, a time-varying intercept and regression
effect model implies
logðitÞ ¼  t þ si þ ui þ it þ Xitt
ð10:26Þ
It is also possible to generalize the regression effect to be spatially as well
as temporally varying, as in
logðitÞ ¼  t þ si þ ui þ it þ Xitit
with spatial dependence at times t and t  1
it  Np
i;t1 þ 1
X
j i
jt þ 2
X
j i
j;t1; V=½2Li þ 1
 
!
where Li is the number of neighbours j of area i.
More general or more heavily parameterized models may be proposed:
for example, time-varying heterogeneity or spatial effects, uit or sit
(Waller et al., 1997; Carlin and Louis, 2000), autocorrelated errors "it
(Congdon, 2001b), or area-speciﬁc growth functions (e.g. polynomials or
SPACE–TIME AND SPATIAL APC MODELS
365

spline functions), iðtÞ. In such models the addition of random effects
may cause identiﬁability problems. Identiﬁability in practice may be
improved by further constraints such as setting one of the ui or si terms to
zero.
Random effects speciﬁc to both area and time may be introduced to
account for excess dispersion in relation to the Poisson or binomial. For
example, Sun et al. (2000) propose a model for Poisson overdispersion
including age as well as time and area dimensions
logðiatÞ ¼ a þ ui þ si þ ði þ aÞt þ "iat
which if age were omitted becomes
logðitÞ ¼ ui þ si þ it þ "it
If the "it is autocorrelated in time, it may be preferable to omit the
unstructured error to improve identiﬁability so that
logðitÞ ¼ si þ it þ "it
with the error deﬁned as
"it ¼ "it1 þ 	it
for time periods t > 1, where 	it  N(0,), while "i1  N(0,/(12).
Congdon (2004) considers age–period or time–period interactions
based on the Carter–Lee model (Carter and Lee, 1992). Considering
age–period interactions, log relative risks for age, area and time take the
form
gðiatÞ ¼ a þ t þ si þ at
with the parameters in the multiplicative function at constrained to
gain identiﬁability. Lee (2000) takes the a as multinomial and t to sum
to zero. The a express variations between age groups in the adherence to
the overall mortality trend represented by the t parameters. If the t are
falling (as mortality declines) then larger a indicate for which age
groups mortality rates are declining most. Space–time interactions might
be modelled via
gðiatÞ ¼ a þ t þ si þ 
tbi
where 
t are multinomial and represent differences between periods in
the extent of spatial clustering deﬁned by the bi (e.g. clustering might be
growing over time). Finally age–area interactions might be modelled via
gðiatÞ ¼ a þ t þ si þ abi
where the a represent age group differences in adherence to the spatial
mortality regime deﬁned by bi. If spatial relative risks bi are higher in
366
HIERARCHICAL AND PANEL DATA MODELS

deprived areas then a would be higher in those age groups (e.g. the
middle-aged and children) where deprivation had the most marked
mortality impact.
MacNab and Dean (2001) allow non-linear trends S ðtÞ in the level of
mortality or disease or in regression impacts SðtÞ via B-spline functions,
though other forms of non-parametric regression could be used. Area–
time interactions (alternatively viewed as area-speciﬁc deviations from
the overall trend) may be modelled by allowing spatially varying
coefﬁcients applied to each term in a B-spline decomposition. Thus a
cubic spline with a single knot would involve four polynomial functions
pjðtÞ, j ¼ 1; . . . ; 4 each of which would be premultiplied by spatial effects
ji for i ¼ 1; . . . ; I areas. The growth curve model in (10.26) with the
effect of two predictors modelled via splines would become
gðitÞ ¼ S ðtÞ þ S1ðtÞX1t þ S2ðtÞX2t þ 1ip1ðtÞ þ 2ip2ðtÞ
þ 3ip3ðtÞ þ 4ip4ðtÞ þ ui þ si
ð10:27Þ
where the smooth overall trend S ðtÞ and smooths in covariates j, namely
SjðtÞ, involve ﬁxed effect parameters. For instance, a cubic spline with a
single knot for S ðtÞ would take the form
S ðtÞ ¼  1q1ðtÞ þ  2q2ðtÞ þ  3q3ðtÞ þ  4q4ðtÞ
where qjðtÞ are polynomial functions.
The greatest generality occurs if the APC model is extended to include
area i. Interactions between cohort and time, and between area and
cohort, may then be relevant. Deﬁne a model with a ‘main effect’ spatial
term si based on spatial adjacency and two sets of interactions as
logðiatÞ ¼  þ si þ a þ t þ c þ ic þ ct
Clayton (1996, p 291) suggests a prior for such interactions based on
multiplying the structure matrices underlying the joint priors in (say)
cohort and area separately. Let the structure matrices of the separate area
and cohort effects be denoted Ks and K. Then the Kronecker product of
these structure matrices Ks ¼ Ks  K deﬁnes the structure matrix for
the joint prior and the structure of the conditional prior on ic can then be
derived. As an example of a structure matrix, an RW(1) prior in cohort
effects has a structure matrix with the form
K½cd ¼
1
if cohorts c and d are adjacent
0
if cohorts c and d are not adjacent
1
if c ¼ d ¼ 1 or c ¼ d ¼ C
2
if c ¼ d ¼ k where k 6¼ 1 and k 6¼ C
8
>
>
<
>
>
:
SPACE–TIME AND SPATIAL APC MODELS
367

while an RW(2) prior has a structure matrix
K ¼
1
2
1
2
5
4
1
4
6
4
1
1
4
6
4
1
..
.
1
4
6
4
1
1
4
6
4
1
1
4
5
2
1
2
1
2
6666666666664
3
7777777777775
From Chapter 8, the prior for s ¼ ðs1; . . . ; sn) based on adjacency is
MVN with precision matrix sKs where
Ks½ij ¼
1
if areas i and j are neighbours
0
for non-adjacent areas
Li
when i ¼ j
8
<
:
and Li is the cardinality of area i (its total number of neighbours). Then an
RW(1) cohort prior crossed with an ICAR(1) spatial main effect has a
conditional form with variance
2
=Li
when c ¼ 1 or c ¼ C
2
=ð2LiÞ
otherwise
and where the mean 	ic for ic is deﬁned by
	i1 ¼ i2 þ
X
j i
j1=Li 
X
j i
j2=Li
	ic ¼ 0:5ði;c1 þ i;cþ1Þ þ
X
j i
jc=Li 
X
j i
j;cþ1 þ
X
j i
j;c1
 
!
=ð2LiÞ
1 < c < C
	iC ¼ i;C1 þ
X
j i
jC=Li 
X
j i
j;C1=Li
Identiﬁability requires that the ic be doubly centred at each iteration
(over both areas for a given cohort c, and over cohorts for a given area i).
Crossed structure matrix priors for area–time, cohort–time, age–time and
age–area interactions are similarly deﬁned.
Example 10.11
Lung cancer in Italian males
Berzuini and Clayton
(1994) analyse trends in lung cancer mortality in Italian males in T ¼ 9
ﬁve-year periods 1944–1948, 1949–1953 through to 1984–1988. The data
have A ¼ 13 age bands (15–19, 20–24 through to 75–79), so there are 23
cohorts, the ﬁrst being those aged 75–79 in 1944–1948 and the last being
368
HIERARCHICAL AND PANEL DATA MODELS

those aged 15–19 in 1984–1988. Figure 10.6 shows the trend in mortality
for the three oldest age groups and only in the last period is there some
evidence of the increase tailing off. Total deaths rose from 5789 in the
ﬁrst period to 97 580 in 1979–1983 and 109 170 in 1984–1988.
The model structure of (10.24) is assumed with second-order random
walk priors for the age, period and cohort effects. Priors on precisions 1/
2 for these effects follow the form adopted by Berzuini and Clayton,
namely
	ð0=Þ2  2ð	Þ
where 0 is a guess at  (initially taken as 2
0 ¼ 0:01 in the application
here) and 	 is the prior degrees of freedom (reﬂecting level of conﬁdence
in the guess); here 	 ¼ 2. Identiﬁability constraints 1 ¼ 1 ¼ 1 ¼
2 ¼ 0 are applied.
A two-chain run of 2500 iterations shows convergence after 1000
iterations with median forecasts (and 50% credible intervals) for total
deaths in 1989–1993 and 1994–1998 of 120 900 (111 500 to 129 800) and
131 200 (108 500 to 154 600). Taking 2
0 ¼ 0:001 leads to virtually the
same median for 1994–1998 but a narrower forecast interval (112 000 to
154 000). Comparable forecasts by Berzuini and Clayton (1994, Table IV)
show medians 104 110 (98 500 to 110 200) and 110 700 (101 200 to
121 900) for 1989–1993 and 1994–1998 respectively.
Example 10.12
Trends in English male suicide
To illustrate trends
in the impact of social factors on suicide mortality, consider male suicide
deaths yit over 15 years between 1986 and 2000 (t ¼ 7; 6; . . . ; 6; 7) in
354 English local authorities. The standard age schedule used to calculate
expected suicide deaths is for England and Wales in 1993. The non-
65−69
70−74
75−79
700
600
500
400
300
200
100
0
1944-
1948
1949-
1953
1954-
1958
1959-
1963
1964-
1968
1969-
1973
1974-
1978
1979-
1983
1984-
1988
Rate per 100000
Figure 10.6
Observed trends in mortality
SPACE–TIME AND SPATIAL APC MODELS
369

constant effects of three census-based indicators, namely social fragmen-
tation ðX1Þ, deprivation ðX2Þ and ethnicity ðX3Þ, are modelled via cubic B
splines with one interior knot at t ¼ 0. A linear growth in area suicide
rates to model area-level deviations from the central trend S ðtÞ is
assumed, with randomly varying and spatially interdependent growth
coefﬁcients i. The total area growth effect at time t is therefore
S ðtÞ þ it. Constant spatial intercept effects, si, are also included. Both
si and i follow ICAR(1) priors. So with yit  PoiðEititÞ
gðitÞ ¼ S ðtÞ þ si þ it þ S1ðtÞX1t þ S2ðtÞX2t þ S3ðtÞX3t
To illustrate the results, Figures 10.7 and 10.8 show the changing
overall intercept S ðtÞ and the changing deprivation effect S2ðtÞ
respectively. The area growth coefﬁcients i vary from 0.06 to 0.037.
2.5%
97.5%
Median
0.2
0.15
0.1
0.05
0
−0.05
−0.1
1986
1991
1996
Year
Figure 10.8
Changing deprivation effect
2.5%
97.5%
Median
1996
1991
1986
0.1
00.5
0
−0.05
−0.1
−0.15
Year
Figure 10.7
Changing interecpt
370
HIERARCHICAL AND PANEL DATA MODELS

Figure 10.9 shows clustering of higher growth in parts of northern and
central southern England.
The DIC is 27 128 with 454 effective parameters. With a relatively
large data set such as this, some observations will not be well ﬁt. The
evidence from Monte Carlo CPO estimates is that poor ﬁt is conﬁned to
outlying observations in the series for each area (time within area
outliers) as opposed to cluster (area) level outliers. The lowest CPO is
for area 65 in year 4 (Bradford in 1989) when a low death count follows a
high count for the preceding year.
EXERCISES
1. In Example 10.1 try out a simple logit regression without varying
region intercepts and compare its ﬁt (e.g. via sensitivity and speciﬁcity
rates estimated using replicate data as against actual data) with the
varying intercepts model. Also consider a simpliﬁed model for varying
Figure 10.9
Spatially verying linear time effects
EXERCISES
371

region intercepts and age effects modelled not as correlated but as
independent random effects.
2. In Example 10.1 try a varying intercept model deﬁned by a two-group
discrete mixture
logitðirÞ ¼ biGi þ 1ðAge  20Þ þ 2ðAge  20Þ2
þ 3½ðAge  30Þþ2 þ 4½ðAge  40Þþ2 þ 5Religion
where Gi is binary and the two sets of effects bij differ in mean and
variance, namely
bi1  Nð01; 1Þ
bi2  Nð02; 2Þ
Either the variances or the intercepts would need to be constrained
(e.g. 01 > 02) to ensure identiﬁability.
3. In Example 10.2 try the full varying regressor effect model. With
Zir1 ¼ 1 for low temperature and Zir2 ¼ 1 for skin contact, the
regression model is
ir ¼ bi1 þ bi2Zir1 þ bi3Zir2
Try ﬁrst taking bi1; bi2 and bi3 as independent random effects and then
as multivariate effects and assess gains in ﬁt and possible identiﬁa-
bility issues. Are the last affected by the prior assumed for bi?
4. In Example 10.3 try a bivariate Student t for 
h (either directly or by
scale mixing) and assess global and individual observation ﬁt against
the BVN option.
5. In Example 10.4 use the latent data (Albert and Chib, 1993) method
and compare (e.g. via parallel sampling) the predictive accuracy of
probit and logit links. The logit link may be approximated by scale
mixing or by using the logistic density to sample the latent continuous
data (see Chapter 4).
6. In Example 10.4 use a complementary log–log link to compare the
model ﬁtted there (i.e. with age–maternal smoking interaction AtMi)
with a model with ZtMi where Zt ¼ 1 for the last three ages and Zt ¼ 0
for children aged 7.
7. In Example 10.5 assess both ﬁt to the observed data and out-of-sample
predictive accuracy (November forecast) of assuming a common
dispersion matrix  for the residual trend parameters itj. Assessing
the out-of-sample accuracy will require the actual November data
from the Ipsos–Reid website.
372
HIERARCHICAL AND PANEL DATA MODELS

8. In Example 10.6 try one of the other conjugate Poisson panel models
outlined in Section 10.6 and compare its ﬁt and implications for
treatment impact with the adapted version of the Rasch Poisson model.
9. In Example 10.7 try a mixture of normals to model the growth rates,
with the effects bi1 modelled as univariate effects independently of
bi2, and bi2 modelled as a mixture of univariate normals (growth rate
subgroups)
bi2  NðBi1; V1Þ þ ð1  ÞNðBi2; V2Þ
Also the regression model in Bi1 and Bi2 should include different
regression effects (i.e. the intercepts and the coefﬁcients on W1 and
W2 vary according to growth rate subgroup). For identiﬁability the
intercepts for Bi1 and Bi2 may be ordered a priori.
10. In Example 10.8 try adding a skew random effect into the model for
hospital visits, namely
logðit2Þ ¼ 2 þ Xi2 þ bi2 þ bi3 þ "it2
where bi3  Nð0; 1ÞIð0; Þ and  is a positive loading, and ascertain
change in model performance.
11. In Example 10.9 try model A with period and item-speciﬁc regression
effects, namely
logitðitmjÞ ¼ mj  Sit  Ximt
and ascertain any gain in ﬁt. Also in model B assess gains in ﬁt from
making it autoregressive, as in
it  Nði;t1; 1Þ
12. In both the models in Example 10.10 try DPP with baseline
univariate normals (rather than bivariate) on bi1 (varying intercepts)
and bi2 (varying time slopes). Allow the DPP to have separate
clustering schemes.
13. In Example 10.12 ﬁt a simpliﬁed model
gðitÞ ¼ S ðtÞ þ si þ Git þ S1ðtÞX1t þ S2ðtÞX2t þ S3ðtÞX3t
where Gi can fall into one of three categories and 1 < 2 < 3 for
identiﬁability. Compare its ﬁt with the spatially varying linear trend
model in terms of the DIC, average deviance, and effective para-
meters as deﬁned by Spiegelhalter et al. (2002) and Gelman et al.
(2003).
EXERCISES
373

REFERENCES
Aitkin, M. and Longford, N. (1986) Statistical modeling issues in school
effectiveness studies. Journal of the Royal Statistical Society, Series A,
149, 1–43.
Albert, J. and Chib, S. (1993) Bayesian analysis of binary and polycho-
tomous response data. Journal of the American Statistical Association, 88,
669–679.
Bernardinelli, L., Clayton, D. and Montomoli, C. (1995) Bayesian estimates of
disease maps: how important are priors? Statistics in Medicine, 14, 2411–2431.
Berzuini, C. and Clayton, D. (1994) Bayesian survival analysis on multiple time
scales. Statistics in Medicine, 13, 823–838.
Besag, J., York, J. and Mollie, A. (1991) Bayesian image restoration with
applications in spatial statistics. Annals of the Institute of Mathematical
Statistics, 43, 1–59.
Besag, J., Green, P., Higdon, D. and Mengersen, K. (1995) Bayesian computation
and stochastic systems. Statistical Science, 10, 3–66.
Bo¨ckenholt, U. (2002) Markov models with random effects for binary panel data.
Methods of Psychological Research Online, Special Issue.
Boscardin, W. and Weiss, R. (2004) Fitting unstructured covariance matrices to
longitudinal data. Working Paper, UCLA Department of Biostatistics.
Bray, I. (2002) Application of Markov chain Monte Carlo methods to projecting
cancer incidence and mortality by APC models. Journal of the Royal Statistics
Society, Series C, 51, 151–164.
Cantoni, E. (2004) A robust approach to longitudinal data analysis. Canadian
Journal of Statistics, 32, 169–180.
Cargnoni, C., Mu¨ller, P. and West, M. (1997) Bayesian forecasting of multinomial
time series through conditionally Gaussian dynamic models. Journal of the
American Statistical Association, 92, 640–647.
Carlin, B. and Louis, T. (2000) Bayes and Empirical Bayes Methods for Data
Analysis, 2nd Edition. Chapman and Hall: London CRC Press: Boca Raton,
FL.
Carter, L. and Lee, R. (1992) Modeling and forecasting US sex differentials in
mortality. International Journal of Forecasting, 8, 393–411.
Chen, Z. and Dunson, D. (2003) A Bayesian approach for assessing heterogeneity
in generalized linear models. Working Paper, National Institute of Environ-
mental Health Sciences.
Chen, Z. and Kuo, L. (2001) A note on the estimation of the multinomial logit
model with random effects. The American Statistician, 55, 89–95.
Chib, S. and Carlin, B. (1999) On MCMC sampling in hierarchical longitudinal
models. Statistics and Computing, 9, 17–26.
Chib, S. and Jeliazkov, I. (2002) Semiparametric hierarchical Bayes analysis of
discrete panel data with state dependence and serial correlation. Working
Papers, Olin School of Business, Washington University in St Louis.
374
HIERARCHICAL AND PANEL DATA MODELS

Chib, S., Greenberg, E. and Winkelmann, R. (1999) Posterior simulation
and Bayes factors in panel count data models. Journal of Econometrics,
86, 33–54.
Clayton, D. (1996) Generalized linear mixed models. In Markov Chain Monte
Carlo in Practice, Gilks, W., Richardson, S. and Spiegelhalter, D. (eds).
Chapman and Hall: London.
Congdon, P. (2001a) Predicting adverse infant health outcomes using routine
screening variables: modelling the impact of interdependent risk factors.
Journal of Applied Statistics, 28, 183–197.
Congdon, P. (2001b) Bayesian models for suicide monitoring. European Journal
of Population, 15, 1–34.
Congdon, P. (2004) Modelling trends and inequality in small area mortality.
Journal of Applied Statistics, 31, 603–622.
Congdon, P. (2005) Bayesian predictive model comparison via parallel sampling.
Computational Statistics and Data Analysis, 48, 735–753.
Congdon, P. and Best, N. (2000) Small area variation in hospital admission rates:
adjusting for referral and provider variation. Journal of the Royal Statistical
Society, Series C, 49, 207–226.
Curran, P. and Bollen, K. (2001) The best of both worlds: combining autore-
gressive and latent curve models. In New Methods for the Analysis of Change,
Collins, L. and Sayer, A. (eds). American Psychological Association:
Washington, DC, 105–136.
Daniels, M. and Gatsonis, C. (1999) Hierarchical generalized linear models in the
analysis of variations in health care utilization. Journal of the American
Statistical Association, 94, 29–42.
Davies, R., Crouchley, R. and Pickles, A. (1982) Modelling the evolution of
heterogeneity in residential mobility. Demography, 19, 291–299.
Diggle, P. (1988) An approach to the analysis of repeated measurements.
Biometrics, 44, 959–971.
Fearns, T. (1975) A Bayesian approach to growth curves. Biometrics, 62,
89–100.
Fitzmaurice, G., Laird, N. and Ware, J. (2003) Applied Longitudinal Analysis.
John Wiley & Sons: New York.
Gamerman, D. and Smith, A. (1996) Bayesian analysis of longitudinal data
studies. In Bayesian Statistics 5, Bernardo, J., Berger, J., Dawid, A. and Smith,
A. (eds). Oxford University Press: Oxford, 587–597.
Gelman, A., Carlin, J., Stern, H. and Rubin, D. (2003) Bayesian Data Analysis,
2nd Edition. CRC Press: Boca Raton, FL.
Geweke, J., Keane, M. and Runkle, D. (1994) Alternative computational
approaches to inference in the multinomial probit model. Review of Economics
and Statistics, 76, 609–632.
Goldstein, H. and Spiegelhalter, D. (1996) League tables and their limitations.
Statistical issues in comparisons of institutional performance. Journal of the
Royal Statistical Society, Series A, 159, 385–443.
REFERENCES
375

Goodhardt, G., Ehrenberg, A. and Chatﬁeld, C. (1984) The Dirichlet: a compre-
hensive model of buying behaviour. Journal of the Royal Statistical Society,
Series A, 147, 621–655.
Grunwald, G., Hyndman, R., Tedesco, L. and Tweedie, R. (2000) Non-Gaussian
conditional linear AR(1) models. Australian & New Zealand Journal of
Statistics, 42, 479–495.
Gustafson, P. and Walker, L. (2003) An extension of the Dirichlet prior for the
analysis of longitudinal multinomial data. Journal of Applied Statistics, 30,
293–310.
Hausman, J., Hall, H. and Griliches, Z. (1984) Econometric models for count data
with an application to the patents-R&D relationship. Econometrica, 52, 909–
938.
Heckman, J. (1981) Statistical models for discrete panel data. In Structural
analysis of discrete data with econometric applications, Manski, C. and
McFadden, D. (eds). The MIT Press: Cambridge, MA, 114–178.
Hirano, K. (1999) A semiparametric model for labor earnings dynamics. In
Practical Nonparametric and Semiparametric Bayesian Statistics, Dey, D.,
Mueller, P. and Sinha, D. (eds). Springer: New York.
Hsiao, C. (1986) Analysis of Panel Data. Cambridge University Press:
Cambridge.
Ibrahim, J. and Kleinman, K. (1998) Semiparametric Bayesian methods for
random effects models. In Practical Nonparametric and Semiparametric
Bayesian Statistics, Dey, D., Mueller, P. and Sinha, D. (eds). Springer:
New York.
Ishwaran, H. and Gatsonis, C. (2000) A general class of hierarchical ordinal
regression models with applications to correlated ROC analysis. Canadian
Journal of Statistics, 28, 731–750.
Jansen, M. (1997) Applications of Rasch’s Poisson counts model to longitudinal
count data. In Applications of Latent Trait and Latent Class Models in the
Social Sciences, Rost, J. and Langeheine, R. (eds). Waxmann Mu¨nster:
New York, 380–389.
Johnson, V. and Albert, J. (1999) Ordinal Data Modeling. Springer: New York.
Jones, R. (1993) Longitudinal Data with Serial Correlation: A State-space
Approach. Chapman and Hall: London.
Jones, R. and Boadi-Boateng, F. (1991) Unequally spaced longitudinal data with
AR(1) serial correlation. Biometrics, 47, 161–175.
Kleinman, K. and Ibrahim, J. (1998a) A semiparametric Bayesian approach to the
random effects model. Biometrics, 54, 921–938.
Kleinman, K. and Ibrahim, J. (1998b) A semi-parametric Bayesian approach to
generalized linear mixed models. Statistics in Medicine, 17, 2579–2596.
Knorr-Held, L. (2000) Bayesian modelling of inseparable space-time variation in
disease risk. Statistics in Medicine, 19, 2555–2567.
Knorr-Held, L. and Besag, J. (1998) Modelling risk from a disease in time and
space. Statistics in Medicine, 17, 2045–2060.
376
HIERARCHICAL AND PANEL DATA MODELS

Knorr-Held, L. and Rainer, E. (2001) Projections of lung cancer mortality in West
Germany: a case study in Bayesian prediction. Biostatistics, 2, 109–129.
Laird, N. and Ware, J. (1982) Random-effects models for longitudinal data.
Biometrics, 38, 963–974.
Lee, J. and Hwang, R. (2000) On estimation and prediction for temporally
correlated longitudinal data. Journal of Statistical Planning and Inference,
87, 87–104.
Lee, R. (2000) The Lee-Carter method for forecasting mortality, with various
extensions and applications. North American Actuarial Journal, 4, 80–93.
Lee, Y. and Nelder, J. (2000) Two ways of modelling overdispersion in non-
normal data. Journal of the Royal Statistical Society, Series C, 49, 591–598.
Leonard, T. and Hsu, J. (1994) The Bayesian analysis of categorical data – a
selective review. In Aspects of Uncertainty: A Tribute to DV Lindley, Freeman,
P. and Smith, A. (eds). John Wiley & Sons: Chichester.
MacCallum, R., Kim, C., Malarkey, W. and Kiecolt-Glaser, J. (1997) Studying
multivariate change using multilevel models and latent curve models. Multi-
variate Behavioral Research, 32, 215–253.
MacNab, Y. and Dean, C. (2001) Autoregressive spatial smoothing and temporal
spline smoothing for mapping rates. Biometrics, 57, 949–956.
Muthe´n, B. (1997) Latent variable modeling of longitudinal and multilevel data.
In Sociological Methodology, Raftery, A (ed.). Blackwell: Boston, MA, 453–
480.
Oh, M. and Lim, Y. (2001) Bayesian analysis of time series Poisson data. Journal
of Applied Statistics, 28, 259–271.
Payne, J., Coy, J., Milner, P. and Patterson, S. (1993) Are deprivation indicators a
proxy for morbidity? A comparison of the prevalence of arthritis, depression,
dyspepsia, obesity and respiratory symptoms with unemployment rates and the
Jarman score. Journal of Public Health Medicine, 15, 161–170.
Randall, J. (1989) The analysis of sensory data by generalized linear models.
Biometrical Journal, 31, 783–791.
Rasbash, J. and Browne, W. (2001) Modelling non-hierarchical structures. In
Multilevel Modelling of Health Statistics, Leyland, A. and Goldstein, H. (eds).
John Wiley & Sons: Chichester, 93–105.
Riphahn, R., Wambach, A. and Million, A. (2003) Incentive effects in the demand
for health care: a bivariate panel count data estimation. Journal of Applied
Econometrics, 18, 387–406.
Rovine, M. and Molenaar, P. (1998) The covariance between level and shape in
the latent growth curve model with estimated basis vector coefﬁcients.
Methods
of
Psychological
Research
Online,
http://www.ppm.ipn.uni-
kiel.de/mpr/issue5.
Saei, A. and McGilchrist, C. (1998) Longitudinal threshold models with random
components. Journal of the Royal Statistical Society, Series D, 47, 365–375.
Snijders, T. and Bosker, R. (1999) Multilevel Analysis: An Introduction to Basic
and Advanced Multilevel Modeling. Sage: London.
REFERENCES
377

Spiegelhalter, D., Best, N., Carlin, B. and van der Linde, A. (2002) Bayesian
measures of model complexity and ﬁt. Journal of the Royal Statistical Society,
Series B, 64, 583–639.
Steyer, R. and Partchev, I. (2000) Latent state-trait modelling with logistic item
response models. In Structural Equation Modeling: Present and future,
Cudeck, R., Du Toit, S. and So¨rbom, D. (eds). Scientiﬁc Software Interna-
tional: Chicago, 481–520.
Sun, D., Tsutakawa, R., Kim, H. and He, Z. (2000) Bayesian analysis of mortality
rates with disease maps. Statistics and Medicine, 19, 2015–2035.
Thall, P. and Vail, S. (1990) Some covariance models for longitudinal count data
with overdispersion. Biometrics, 46, 657–671.
Van Duijn, M. and Jansen, M. (1995) Modeling repeated count data: some
extensions of the Rasch Poisson counts model. Journal of Educational &
Behavioral Statistics, 20, 241–258.
Wakeﬁeld, J., Smith, A., Racine-Poon, A. and Gelfand, A. (1994) Bayesian
analysis of linear and non-linear population models by using the Gibbs
Sampler. Applied Statistics, 43, 201–221.
Waller, L., Carlin, B., Xia, H. and Gelfand, A. (1997) Hierarchical spatio-
temporal mapping of disease rates. Journal of the American Statistical
Association, 92, 607–617.
Weiss, R., Cho, M. and Yanuzzi, M. (1999) On Bayesian calculations for mixture
likelihoods and priors. Statistics in Medicine, 18, 1555–1570.
Zeger, S. and Qaqish, B. (1988) Markov regression models for time series: a
quasi-likelihood approach. Biometrics, 44, 1019–1031.
378
HIERARCHICAL AND PANEL DATA MODELS

CHAPTER 11
Missing-Data Models
11.1
INTRODUCTION: TYPES OF MISSING DATA
Many data sets resulting from surveys or longitudinal investigations (e.g.
clinical follow-up studies) are subject to missing data. Cross-sectional
surveys may be subject to refusal by some subjects to answer certain
questions or items (this is known as item non-response) or be subject to
complete missingness on a subject (unit non-response). Panel studies in
clinical and other applications are subject to intermittently missing res-
ponses or permanent loss from observation (known as attrition) (Ibrahim
et al., 2001a). Let X generically denote dependent or predictor variables.
Permanent loss to observation results in what is known as a monotone form
of missing data since if Xit is observed then Xi;t1, Xi;t2; . . . are necess-
arily observed, while if Xit is missing then Xi;tþ1, Xi;tþ2; . . . are necessarily
also missing. In cross-sectional (e.g. survey) applications monotone non-
response would occur in the context of two items if education (say) was
answered whenever income was, but for some subjects education would
be recorded though income was missing. Panel studies and time series,
such as those in climatology or environmetrics, may be subject to inter-
mittent non-monotone missing data. For example, limitations of measure-
ment instruments mean that values below detection limits are left censored
(Hopke et al., 2001).
Apart from whether missingess is monotone, a further question is
whether the chance of a missing value is related to the value that would
have been observed had response actually happened (Little and Rubin,
1987). Corresponding to whether data Xij on variable j for subject i are
observed or not, one may deﬁne binary indicators which count as part
of the observations. Thus Rij ¼ 1 (for Xij missing) and Rij ¼ 0 (for Xij
Bayesian Models for Categorical Data
P. Congdon
# 2005 John Wiley & Sons, Ltd

observed); if Xijt is time varying then Rijt ¼ 1 (for Xijt missing) and
Rijt ¼ 0 (for Xijt observed). The missingness indicators may be multi-
nomial rather than binary when there is more than one type of missing
data. For example, in the case of multilevel data (e.g. pupils within
schools) the non-response may be at level 1 (pupils) or at level 2 (schools).
If the probability that Xij is missing (i.e. the probability that Rij is one
when there is only one type of missingness) is governed by missingess
at random then ij ¼ PrðRij ¼ 1Þ may depend on values of observed
variables (e.g. observed Yi, or Xik where k 6¼ j) but not on the values of
possibly missing variables including Xij itself. By contrast, when the
chance of non-response is related to the values of missing variables, then
response is called non-ignorable. An example might be when response to
an income question depends on the level of income, or in a panel study if
the chances of dropout were related to treatment allocation or response.
For instance, dropout from clinical intervention studies may be greater
for patients adversely affected by a treatment, or a measure of mood may
be more likely to be missing when the subject is in a poor mood (Ibrahim
et al., 2001a). The parameters of a missingness model may be only
weakly identiﬁed by the data and so sensitivity analysis may be applied
on the parameters of the central model (relating Y to X) according to
alternative parameterizations of the model for R j Y; X (Roy and Lin, 2002).
The opposite possibility is known as missingess completely at random
(MCAR): none of the data collected or missing are relevant to explaining
the chance of missingness; the regression for PrðRijÞ ¼ 1 is independent
of all predictors X and outcomes Y. Only if the MCAR assumption holds
is it valid to use the strategy known as complete case analysis: that is,
excluding from the analysis any observation with missing values.
Where data are missing, whether by missingness at random (MAR) or
non-ignorable mechanisms, the analysis may be set up such that values
for the missing data are sampled at each MCMC iteration. In non-
ignorable models such a sampling scheme is a necessary feature of the
model. However, approximations to such repeated sampling imputation
of missing data may be obtained by a small ﬁnite set of imputations under
the multiple imputation (MI) method (Rubin, 1987; Schafer, 1997). Lett-
ing the missing data be denoted Xmis, and the observed data Xobs, multiple
imputation requires a sample of m values of Xi;mis (for subjects i ¼
1; . . . ; n) from the conditional density pðXmis j XobsÞ. These samples
replace or ‘ﬁll in’ the missing data to make m versions of the complete
data and then standard complete data analysis is applied m times.
Inferences on parameters or derived quantities are obtainable by averag-
ing over the m complete data analyses.
380
MISSING-DATA MODELS

11.2
DENSITY MECHANISMS FOR MISSING DATA
When missingness is at random, Rubin (1976) shows that likelihood-
based inference does not require a model for the missing-data mechanism
(see also Laird, 1988). By contrast, for non-ignorable non-response it is
necessary to set up a model for the response mechanism as well as for the
data themselves. As an example, suppose for a cross-sectional sample
that there is a binary outcome Y, a single binary covariate X, and that Y is
fully observed but X possibly missing. Then set R ¼ 1 if X is missing and
R ¼ 0 if X is observed. One possible approach, known as a selection
model, considers the joint density as
pðY; X; Rj
; ; Þ ¼ pðRjY; X; 
ÞpðYjX; ÞpðXjÞ
ð11:1aÞ
Since X is binary, fðXjÞ reduces for each individual to a Bernoulli
density
Xi  BernðÞ
ð11:1bÞ
and pðYjX; Þ can be modelled using a logit, probit or complementary
log–log link, g:
Yi  BernðY
i Þ
gðY
i Þ ¼ 1 þ 2Xi
ð11:1cÞ
If the chance that X is missing is possibly related to observed values of X,
but not to missing values of X, then the model need go no further and
pðRjY; X; 
Þ need not be speciﬁed. However, if there is non-ignorable
missingness, i.e. if PrðRi ¼ 1Þ is related to Xi;mis as well as Xi;obs, then a
further model stage is required. For instance, one might specify
Ri  BernðR
i Þ
logitðR
i Þ ¼ 
1 þ 
2Yi þ 
3Xi
ð11:1dÞ
where predictor values Xi include imputations under (11.1b). A sensiti-
vity analysis in this simple example might consider whether setting 
3 or

2 to zero affects the  coefﬁcients.
In panel data subject to attrition but not intermittent missing data, non-
ignorable missingness means the chance of a dropout at time t may
be related to the possibly missing value of yit at that time. Ignorable
DENSITY MECHANISMS FOR MISSING DATA
381

missingness by contrast might include impacts of lagged (and observed)
dependent variable values such as yi;t1 on PrðRit ¼ 1Þ but not the
contemporaneous value (Diggle and Kenward, 1994). So non-ignorable
missingness would imply 
2 6¼ 0 in a dropout model such as
Rit  BernðR
itÞ
ð11:2aÞ
logitðR
itÞ ¼ 
1 þ 
2yit þ 
3Xit þ 
4yi;t1
ð11:2bÞ
where yit is an additional unknown imputed under the model when
Rit ¼ 1.
Another possible factoring of the joint density in (11.1a) leads to what
is known as the pattern mixture model approach to incomplete data
(Little, 1993). Let Y be subject to missingness and X be fully observed;
then the model for RY precedes that for Y itself, as in
pðY; X; Rj
; ; Þ ¼ pðYjRY; X; ÞpðRYjX; 
ÞpðXjÞ
ð11:3aÞ
The regression analysis for Y involves both the missingness indicators R
and the substantive inﬂuences X which are the focus of interest, and the
marginal expectation EðYijXiÞ is obtainable by averaging over the pro-
babilities R
i (Horton and Fitzmaurice, 2002). Practical strategies for
pattern mixture modelling involve simplifying identiﬁability constraints
(Molenberghs et al., 2002) such as delimiting a relatively small number
of non-response patterns. For example, for T ¼ 3 observation points in a
panel data problem, the possible sequences are OOO (all three values of
Y observed), OOM, OMO, MOO, OMM, MOM, MMO and MMM. While
it is possible to include the complete non-response pattern MMM given
information on some predictors, they are often ignored in practice
(Hedeker and Gibbons, 1997). Hence one is left with seven response
patterns and the probability pðYjR; X; Þ can be modelled by introducing
an extra categorical predictor Ri for missingness status (with seven
levels). Random effects parameters (e.g. variance or dispersion matrices
for permanent subject effects in GLMMs) can also be distinguished by
subject response category.
If X is not subject to missingness it may be taken as known rather than
random, and the joint density (11.3a) becomes
pðY; X; Rj
; Þ ¼ pðYjR; X; ÞpðRYjW; 
Þ
ð11:3bÞ
382
MISSING-DATA MODELS

One might therefore have a multinomial logit model for R (with seven
categories in the example just quoted) using predictors W that may in-
clude a subset of X, and a main regression for Y in which R is introduced
as a categorical predictor. Alternatively, interpretability may be gained by
simply reducing non-response patterns to a binary index Ri ¼ 1 for
completers (those with the OOO pattern), and Ri ¼ 0 for all non-
completers regardless of pattern (those with one of the OOM, OMO,
MOO, OMM, MOM, MMO patterns). This option makes it easy to
include in the Y regression model interactions X  R between substantive
factors (e.g. treatment status and time) and response status. Another
simpliﬁcation of the response patterns might be a trichotomy distinguish-
ing full response from monotone missingness (OOM and OMM) and
from intermittent nonmonotone missingness (MOM, MOO, OMO and
MMO).
Example 11.1
NIMH schizophrenia collaborative study
As an illus-
tration of a pattern mixture approach consider clinical trial data on 437
patients observed at one or more of seven possible occasions (weeks from
start of study) as in Table 11.1. The outcome yit is ordinal with J ¼ 7
levels of increasing severity. Not all subjects were measured at each time
point. It can be seen that by six weeks there is substantial dropout. A
simple pattern mixture model simply deﬁnes Ri ¼ 1 or 0 according as a
measurement is taken at week 6.
In Hedeker and Gibbons (1997), a GLMM as in Chapter 10 is applied,
with time transformed to the square root of weeks. The predictors Xit are
X1 ¼ treatment status (drug vs. placebo) and X2 ¼ time–treatment interac-
tion, while the random effects predictors are Z1 ¼ intercept and Z2 ¼
time. Then a model ignoring missingness Pðyitj; bi; Xit; ZitÞ can be
Table 11.1
Observed sample totals at each of seven observation points
Weeks from start
Total
of study
sample
0
1
2
3
4
5
6
Drug
327
321
9
287
9
7
265
329
Placebo
107
105
5
87
2
2
70
108
DENSITY MECHANISMS FOR MISSING DATA
383

contrasted with one that takes it into account via the mechanism
Pðyitj; bi; Xit; Zit; RiÞPðRijW; 
Þ as in (11.3b). Hedeker and Gibbon do
not explicitly model PðRijWi; 
Þ, though interactions in the model for yit
achieve this indirectly. The relevant interactions are between dropout
status and treatment, between drop-out and time, and between dropout
and the time–treatment interaction. One might instead have a separate
logit regression of R on treatment status.
With a subject–time ordinal response the relevant multinomial pro-
bability vector is denoted it ¼ ðit1; . . . ; itJÞ and a model ignoring
dropout is
yit  CategoricalðitÞ
itj ¼ itj  it; j1
j ¼ 2; . . . ; J  1
logitðitjÞ ¼ j  ð1Xi1 þ 2Xi2 þ bi1 þ bi2Zi1Þ
where j are cut points on an underlying continuous scale. The random
effects bi ¼ ðbi1; bi2Þ are assumed to be bivariate normal with inverse
covariance P1
b
following a Wishart prior with identity scale matrix.
Because of the varying intercept bi1, it is assumed that 1 ¼ 0.
This is a highly parameterized model and convergence may be slow.
The ﬁrst model (model A ignoring missingness) is run for 20 000 iter-
ations and results from the second half shows no clear ‘main effect’ 1 of
treatment, but a treatment–time effect 2 that is signiﬁcantly negative.
Those on the drug regime decline more rapidly in terms of symptom
severity. Note, though, that all patients seem to show an improvement
over time (the median of the time effects bi2 is 0.52). Intercepts and
random time paths are negatively correlated.
The pattern mixture model (model B) is then ﬁtted with a dropout status
main effect and interactions between dropout and treatment, dropout and
time, and dropout and time  treatment. To aid identiﬁability the covar-
iance matrix P
b from model A is used to set an informative Wishart prior
on the MVN precision matrix for bi.
The DIC ﬁts (Table 11.2) are very similar between the models but the
drug–time interaction is ampliﬁed in model B, with median 2.81 instead
of 1.63. Dropout is more common among those in the treatment group
with higher scores and among those within the treatment group with
worsening symptoms (the dropout–drug–time interaction is positive).
However, dropouts in general, regardless of treatment group, tend to have
lessening symptoms (the dropout  time effect is negative).
384
MISSING-DATA MODELS

11.3
AUXILIARY VARIABLES
Often survey data contain auxiliary information that may provide inform-
ation on (i.e. act as a surrogate for) incompletely observed predictors X or
responses Y (Ibrahim et al., 2001b; Horton and Laird, 2001). Auxiliary
information might be stratiﬁer variables (e.g. area of residence, demo-
graphic variables) available even in the event of complete unit non-
response. Another possibility when a covariate X is expensive to measure
is to obtain a proxy A for all subjects while the gold standard X is col-
lected only for a small subsample. Consider the case of missing data on
one or more predictors X. If the probability of response PrðRi ¼ 1Þ on X is
related to the possibly missing values Xi the complete selection model
likelihood may be factored as
pðRX;Y;A;Xj
;;Þ ¼ pðRXjY;A;X;
ÞpðYjX;A;ÞpðX;AjÞ
ð11:4aÞ
Table 11.2
Parameter estimates in with- and without-dropout models
Parameter
Without dropout
Allowing for dropout
(model A)
(model B)
2.5%
Median
97.5%
2.5%
Median 97.5%
Intercept
7.46
8.15
8.78
7.87
8.57
9.10
Time
0.78
0.52
0.27
0.28
0.03
0.36
2
1.91
2.26
2.61
1.96
2.29
2.64
3
3.46
3.87
4.28
3.52
3.91
4.30
4
5.20
5.68
6.16
5.30
5.73
6.15
5
7.36
7.91
8.50
7.47
7.96
8.43
6
10.79
11.54
12.46
10.95
11.61
12.19
Drug
0.09
0.48
1.00
0.85
0.09
0.79
Drugtime
2.04
1.63
1.33
3.49
2.81
2.14
Dropout
1.44
0.57
0.14
Dropouttime
1.23
0.75
0.36
Dropoutdrug
0.10
0.89
1.94
Dropoutdrugtime
0.75
1.41
2.22
Variance Intercepts
2.61
3.63
5.48
2.38
3.53
4.46
Covariance time and
1.10
0.46
0.04
1.03
0.55
0.10
intercepts
Variance time
0.76
1.17
1.63
0.82
1.17
1.61
DIC
4278
4271
de
521
510
AUXILIARY VARIABLES
385

Simpliﬁcations occur if missingness on X is at random rather than non-
ignorable and if Y is conditionally independent of A given X. If the latter
condition holds then pðYjX; A; Þ ¼ pðYjX; Þ and the auxiliary variable
is not a signiﬁcant predictor of Y when X is given. If additionally
missingness in X depends only on observed data, then the model may
be reduced to
pðRX;Y;A;Xj;Þ ¼ pðY;A;Xj;Þ ¼ pðYjX;ÞpðX;AjÞ
ð11:4bÞ
Note that an alternative factorization if Y and A are not conditionally inde-
pendent is (Horton and Laird, 2001)
pðY; A; Xj; ; Þ ¼ pðAjY; X; ÞpðYjX; ÞpðXjÞ
ð11:4cÞ
where pðXjÞ is usually just a model for the missing covariate(s), with
pðY; A; Xj; ; Þ ¼ pðAjY; X; ÞpðYjX; ÞpðXmisj; XobsÞ
If additionally missingness on X is non-ignorable,
pðRX; Y; A; Xj
; ; ; Þ ¼ pðRXjY; A; X; 
ÞpðAjY; X; Þ
 pðYjX; ÞpðXmisj; XobsÞ
ð11:4dÞ
Example 11.2
Mental health service use
To illustrate the value of
auxiliary data in improving the model for missing X and hence the pre-
diction of Y (which is completely observed) consider data from Horton
and Laird (2001) on a binary measure Y of mental health service use by
2486 children. Predictors include socio-economic variables: gender
(X1 ¼ 1 for boy), age group (X2 ¼ 1 for older age group), ethnicity of
child, namely whether black (X3 ¼ 1 or 0) or Hispanic (X4 ¼ 1 or 0), and
also whether from a single-parent family (X5 ¼ 1 or 0). Also available is
a parental measure of child pathology (the Child Behavior Checklist,
CBCL) and a teacher measure of child pathology (the Teacher Report
Form, TRF). The CBCL is considered an auxiliary variable for the TRF
which is subject to 43% missingness and is considered one of the X vari-
ables ðX6 ¼ TRFÞ. All other X variables and Y are fully observed.
Fitzmaurice et al. (1996) conclude that PrðR ¼ 1Þ for the variable
TRF (R ¼ 1 if TRF is missing, 0 otherwise) is not related to TRF, i.e.
missingess is at random. However, for illustrative purposes we allow, as
in (11.4d), for the possibility of non-ignorable non-response by including
a logit model for R. An informative N(0, 1) prior is assumed for the impact
of TRF on logit[PrðR ¼ 1Þ], in line with a 95% expectation of an odds
ratio between 0.14 and 7. A vague prior leads to lack of identiﬁability.
386
MISSING-DATA MODELS

The remainder of the model uses the factorization as in (11.4c) that
does not necessarily assume conditional independence of Y and A given
X, so that conditional independence can be assessed by whether Y has a
direct effect on A. This is the likelihood assumed here with the additional
component fðRXjY; A; X; 
Þ.
Thus the model has the following components: a model for missingness
on TRF
Ri  Bernð1iÞ
g1ð1iÞ ¼ 
XXobs;i þ 
6TFRi þ 
7CBCLi þ 
8Yi
where 
X ¼ ð
0; . . . ; 
5Þ and Xobs;i ¼ ð1; X1; X2; X3; X4; X5Þ0; a model for
the auxiliary variable CBCL (the parent pathology report)
CBCLi  Bernð2iÞ
g2ð2iÞ ¼ XXobs;i þ 6TFRi þ 7Yi
a model for Y
Yi  Bernð3iÞ
g3ð3iÞ ¼ Xobs;i þ 6TFR
where  ¼ ð0; . . . ; 5Þ; and a model for values taken by the covariate
(teacher’s pathology report) subject to missingness
TRFi  Bernð4iÞ
g4ð4iÞ ¼ Xobs;i
A two-chain run of 5000 iterations (convergent from 1000) shows that
TRF is not a signiﬁcant inﬂuence on PrðRi ¼ 1Þ so the MAR assumption
on TFR is conﬁrmed. The coefﬁcient on TRF in the model for Y has mean
1.32 (s.d. 0.17) which compares closely with the estimate of 1.30
obtained by Horton and Laird (2001, p 39) under their MLA model. A
higher coefﬁcient on TFR is obtained if it is erroneously assumed that Y
and A are conditionally independent. The lack of conditional indepen-
dence is apparent in the impact of Y in the logit model for the auxiliary
variable CBCL, with a coefﬁcient of 1.17 (s.d. 0.13).
11.4
PREDICTORS WITH MISSING VALUES
Consider data without auxiliary variables but with several covariates (as
well as possibly Y also) subject to missing values. The joint density has
the form
pðY; X; RY; RXj
; ; Þ ¼ pðRX; RYjY; X; 
ÞpðYjX; ÞpðXjÞ
PREDICTORS WITH MISSING VALUES
387

with one possible conditional sequence giving
pðY; X; RY; RXj
; ; Þ ¼ pðRYjRX; Y; X; 
YÞ
pðRXjY; X; 
XÞpðYjX; ÞpðXjÞ
Assume for simplicity that only X values are subject to missingness so that
pðY; X; RXj
; ; Þ ¼ pðRXjY; X; 
ÞpðYjX; ÞpðXjÞ
The incompletely observed covariates Xi;mis ¼ ðXi1; . . . ; XimÞ may be cate-
gorical fXi1; . . . ; Xikg and continuous ðXi;kþ1; . . . ; Ximg and there is a
question of specifying both the joint distribution of Xi;mis ¼ fXi1; . . . ;
Ximg and the joint density of the covariate missingness indicators Ri ¼
fRi1; . . . ; Rimg. The fully observed covariates are Xi;obs ¼ fXi;mþ1; . . . ;
Xipg.
Ibrahim et al. (1999) propose the joint density of the covariates subject
to missingness speciﬁed as a series of one-dimensional conditional distri-
butions, so that
pðXi1;...;Ximjg ¼ pðXimjXi;m1;...;Xi1;mg...pðXi2jXi1;2ÞpðXi1j1Þ
ð11:5aÞ
Alternative conditioning sequences may be tried as part of a sensitivity
analysis. Possible approaches for modelling the Ri include a joint log-
linear model for pðRijYi; Xi; 
Þ with Xi ¼ ðXi;mis; Xi;obsÞ as predictors, or
equivalently a multinomial model with all possible classiﬁcations of non-
response as categories (Schafer, 1997, chapter 9). For example, if Xmis
contains two variables then there are four possible combinations of R1
and R2. However, the joint density can also (Ibrahim et al., 1999) be
speciﬁed as a series of conditional distributions
pðRi1; . . . ; Rimj
; Xi; Yig ¼ pðRimjRi;m1; . . . ; Ri1; 
m; Xi; YiÞ
. . . pðRi2jRi1; 
2; Xi; YiÞpðRi1j
1; Xi; YiÞ
ð11:5bÞ
What (11.5a) and (11.5b) mean in practice may be illustrated with the
case of two incompletely observed continuous variables fXi1; Xi2g, Xi3
fully observed (continuous or binary), and two incompletely observed
binary variables Xi4; Xi5. Suppose also that Y is fully observed. Suppose
the joint density
pðXi2jXi1; 2ÞpðXi1j1Þ
is speciﬁed as a series of univariate normals. This is equivalent to a
bivariate normal
pðXi1; Xi2j1; 2Þ
388
MISSING-DATA MODELS

which is the ﬁrst and second lowest stages combined in (11.5a). Condi-
tional on partially missing fXi1; Xi2g and the fully observed Xi3, a binary
regression may be used for 4i ¼ PrðXi4 ¼ 1Þ with
g½4ðXi4jXi1; Xi2; Xi3; 4Þ ¼ 40 þ 41Xi1 þ 42Xi2 þ 43Xi3
Note that it is not necessary to model the distribution of Xi3, since it is
always observed; Xi3 can be conditioned on in the sense that the means
i1 and i2 of Xi1 and Xi2 are functions of Xi3. Finally a regression for Xi5
would be of the form
g½5ðXi5jXi1; Xi2; Xi3; Xi4; 5Þ ¼ 50 þ 51Xi1 þ 52Xi2 þ 53Xi3 þ 54Xi4
Note that other orders of conditioning are possible: one might also start
with pðXi4j1Þ then model pðXi5j2; Xi4Þ then pðXi1jXi5; Xi4; 3Þ, etc. A
sensitivity analysis would assess the impact of alternative sequences on
the  parameters in the regression of Y on X.
For non-ignorable non-response, one allows the probability of mis-
singness, such as PrðRi1 ¼ 1Þ, to depend on missing values of the same
variable ðXi1Þ, other variables subject to missingness ðXi2; Xi4; Xi5Þ, the
response and fully observed covariates, as well as earlier Rik in the condi-
tional sequence. So a full model for the missingness of Xi1 might be
gðPr½Ri1 ¼ 1Þ ¼ 
11 þ 
12Xi1 þ 
13Xi2 þ 
14Xi3 þ 
15Xi4 þ 
16Xi5 þ 
17Yi
ð11:5cÞ
The logit model for Ri2 given Ri1, pðRi2jRi1; 
2Þ, is then
gðPr½Ri2 ¼ 1Þ ¼ 
21 þ 
22Xi1 þ 
23Xi2 þ 
24Xi3 þ 
25Xi4
þ 
26Xi5 þ 
27Yi þ 
28R1i
and so on for PrðRi4 ¼ 1Þ conditional on Ri1 and Ri2, and PrðRi5 ¼ 1Þ
conditional on Ri1, Ri2 and Ri4.
Note, though, that such models may be poorly identiﬁed and that par-
simonious models (and/or informative priors) may be needed for identi-
ﬁability in practice (Fitzmaurice et al., 1996; Ibrahim et al., 2001a,
p 558). The usual predictor selection methods may be used to obtain
parsimonious missingness models containing only signiﬁcant predictors.
Missingness may then be judged random or non-ignorable depending on
which predictors are included in the parsimonious model. For example, if

12 ¼ 
13 ¼ 
15 ¼ 
16 ¼ 0 in the model (11.5c) for Ri1 then missingess
in Xi1 is at random (MAR) since it depends only on fully observed data.
If also 
14 ¼ 
17 ¼ 0 then missingess in Xi1 is completely at random
(MCAR).
PREDICTORS WITH MISSING VALUES
389

Example 11.3
Foreign language attainment
Schafer (1997) presents
data from a cross-sectional study of college achievement in foreign
language (n ¼ 279 subjects). The measure of success Y is an ordinal
ﬁnal grade, GRD, here reduced to a binary variable (1 ¼ grade A, 0
otherwise), since 126 of 232 complete responses on GRD were grade A.
A new instrument for predicting success, the Foreign Language Attitude
Scale or FLAS, is being compared with a well-established instrument, the
Modern Language Aptitude Test (MLAT).
Of the available predictors, three continuous and one binary variable
are used here. As well as the continuous X3 ¼ FLAS, which is completely
observed, the two other partially missing continuous scales are X1 ¼
MLAT (missing for 49 subjects) and college grade point average (X2 ¼
CGPA), missing for 34 subjects. The binary predictor X4 is one if three or
more prior language courses have been taken, and zero for two or less
prior courses (this variable is missing for 11 subjects). We consider a
selection model allowing for non-ignorable response in both X and Y.
As one possible conditional sequence, the ﬁrst stage in the modelling
of the Xi;mis ¼ ðXi1; Xi2; Xi4Þ speciﬁes the means i1 of Xi1 as a function of
the fully observed covariate Xi3. Then the means of Xi2 are modelled
in terms of Xi1 and Xi3, while the logit regression for X4 is in terms of X1,
X2 and X3. Thus
Xi1  Nði1; !1Þ
i2 ¼ 21 þ 22Xi1 þ 23Xi3
i1 ¼ 11 þ 12Xi3
Xi4  Bernði4Þ
Xi2  Nði2; !2Þ
gði4Þ ¼ 41 þ 42Xi1 þ 43Xi2 þ 44Xi3
Y and three of the four covariates, namely fX1; X2; X4g, are subject to
missing values. The conditional sequence assumed for the missingness
indicators in both Y and X is
pðRiYjRi1; Ri2; Ri4; Xi; YiÞpðRi4jRi2; Ri1; Xi; YiÞ
 pðRi2jRi1; Xi; YiÞpðRi1jXi; YiÞ
For example, the most extensive model for missingess on the response,
namely for iY ¼ PrðRiY ¼ 1Þ, is
gYðiYÞ ¼ 
Y1 þ 
Y2Yi þ 
Y3Xi1 þ 
Y4Xi2 þ 
Y5Xi3 þ 
Y6Xi4
þ 
Y7Ri1 þ 
Y8Ri2 þ 
Y9Ri4
while the model for i4 ¼ PrðRi4 ¼ 1Þ is
g4ði4Þ ¼ 
41 þ 
42Yi þ 
43Xi1 þ 
44Xi2 þ 
45Xi3 þ 
46Xi4 þ 
47Ri1 þ 
48Ri2
390
MISSING-DATA MODELS

The coefﬁcients on 
Y2 and 
46 (i.e. where missingness is related to pos-
sibly missing values for the same binary variable) are taken as relatively
informative, namely N(0,1), in order to achieve stable convergence. Even
under these priors, convergence is relatively slow, after around 2000 itera-
tions with two chains, with the coefﬁcients in the model for Ri1 showing
delayed convergence.
Using 3000 more iterations, results for  in the central model (of
ultimate substantive interest) show linguistic success positively related to
both language aptitude scales, FLAS and MLAT, and also to college
grade, but not to number of prior courses. The coefﬁcients and 95% inter-
vals for this model are given in Table 11.3.
Results from the logit regression for PrðRi1 ¼ 1Þ suggest that mis-
singess on X1 ¼ MLAT is informative: missingness is lower as MLAT
increases, the relevant coefﬁcient (eta1[4] in the code) having mean 0.57
and 95% interval (1.45, 0.19). Missingness on X1 is also positively
linked to Y itself. By contrast, missingness on X2 ¼ CGPA is positively
related to X2 and negatively to Y. Missingess on X4 and Y appears to be at
random though the models are evidently overparameterized: there is only
one coefﬁcient (on X1) in the model for PrðRiY ¼ 1Þ that has a 95% inter-
val conﬁned to negative or to positive values.
Accordingly a second analysis includes regressor selection in the model
for PrðRiY ¼ 1Þ. With prior probabilities of regressor inclusion of 0.5, two
variables have posterior probabilities of inclusion above 0.5, namely Y
and X1. A reduced model just including these predictors for RY (and
without predictor selection) still shows X1 as the only signiﬁcant predic-
tor, so the missingness on Y is conﬁrmed as MAR.
11.5
MULTIPLE IMPUTATION
The multiple imputation approach to missing data (see e.g. Faris
et al., 2002; Rubin, 1987) applies whether missingess is ignorable or
Table 11.3
FLAS main model, posterior summary
Mean
S.d.
2.5%
97.5%
1 (constant)
9.0
1.95
13.4
5.6
2 (MLAT)
0.11
0.03
0.05
0.17
3 (CGPA)
1.07
0.45
0.28
2.02
4 (FLAS)
0.034
0.011
0.013
0.059
5 (Prior courses)
0.29
0.31
0.30
0.89
MULTIPLE IMPUTATION
391

non-ignorable, though is most typically applied in conjunction with an
MAR assumption. Suppose X is subject to missingness. Under a MAR
model,
a
small
number
m
of
samples
of
the
missing
data
Xmis;i;j j ¼ 1; . . . ; m; i ¼ 1; . . . ; n, are drawn from the predictive density
PðXmisjXobsÞ ¼
ð
pðXmisjXobs; ÞpðjXobsÞd
After ﬁlling in the missing values m complete data sets are obtained.
These data sets may be analysed by Bayesian or classical methods to
yield separate estimates ð1Þ; . . . ; ðmÞ of the parameters  involved in the
PðYjX; Þ model. The complete data analysis might be a logistic regres-
sion (Y on predictors X) whereas the imputation model might involve
imputation of missing continuous predictors Xmis which ﬁgure among
those in a logistic regression of Y on X ¼ ðXmis; XobsÞ.
In the case of m separate Bayesian analyses, ð1Þ; . . . ; ðmÞ are obtained
as posterior means. Suppose also that the posterior variances of the
kth parameter in each set fð1Þ
k ; . . . ; ðmÞ
k
g are V1k; . . . ; Vmk respectively.
Then a combined estimate of the relevant regression coefﬁcient is simply
the average k over the m analyses. The average within-imputation
variance of k is estimated as
Vk ¼
X
m
j¼1
Vjk=m
while the estimated between-imputation variance is
Bk ¼
X
m
j¼1
ððmÞ
k
 kÞ2=ðm  1Þ
So the estimated total variance of the combined estimate k is
Bkð1 þ 1=mÞ þ Vk
ð11:6Þ
With several continuous X variables, one or more subject to incomplete
observation, a commonly used imputation model is the multivariate nor-
mal under an MAR assumption (Schafer, 1997). This might be used after
suitably transforming some of the original variables to reduce skewness.
With several discrete variables one might use the same principle within
the link function (Aitchison and Ho, 1989); for example, for J count vari-
ables Yij, take
Yij  PoðexpðuijÞÞ
where
ui  NJ u; u
ð
Þ
392
MISSING-DATA MODELS

This type of imputation model may be most appropriate when there is a
relatively small fraction of missing data, and when between-variable cor-
relations outweigh within-variable correlations such as may occur in panel
data. When within-variable correlation is important the imputation
method should include correlation in the observed data or error series
(e.g. autocorrelation in the outcomes Yit in a panel data situation).
A speciﬁc form of multiple imputation is based on the propensity score
approach (Lavori et al., 1995). At its simplest this involves predicting
‘scores’ ei ¼ PrðRi ¼ 1Þ using a logistic regression on fully observed
variables. Suppose Ri ¼ 1 for a subject with X2 missing and Ri ¼ 0 with
X2 observed; suppose also that X1 is fully observed and assists in pre-
dicting PrðRi ¼ 1Þ in a logistic regression.
Then one would stratify subjects on the basis of the scores ei. For
example, split the sample into g ¼ 1; . . . ; G groups according to the
quartiles of ei. Then within each of those G groups suppose there were Rg
respondents and Qg non-respondents. In line with the ‘approximate
Bayesian bootstrap procedure’ of Rubin (1987) one randomly selects
Qg values of X2 (with replacement) from among those Rg subjects with X2
observed. The sampled values are imputed to the non-respondent subjects
in the same propensity score group. This would be repeated in line with
MI principles to provide m copies of the ‘complete’ data.
In panel studies permanent loss of subjects is common (i.e. attrition or
monotone missing data). For example, suppose there are two variables
Xi1t and Xi2t and that waves 1 and 2 are fully observed but at wave 3 some
subjects drop out. Then one might predict ei3 ¼ PrðRi3 ¼ 1Þ using the
fully observed data ðXi1t; Xi2tÞ for t ¼ 1; 2 and impute missing scores for
both predictors (Xi13 and Xi23) according to the propensities ei3. Deﬁne
XC
3m as the complete data resulting from the mth imputation. Then a
regression to predict the missingness scores ei4 ¼ PrðRi4 ¼ 1Þ at wave
4 might be based on the fully observed data at times 1 and 2 combined
with the average ‘complete’ data XC
3 at time 3.
Example 11.4
Attitude to low-tar cigarettes
This example uses data
from Schafer (1999) on answers to the question ‘The new low-tar ciga-
rettes aren’t going to hurt me’ before and after a behavioural intervention;
binary data for 882 subjects form responses y1 (before) and y2 (after).
Data are further classiﬁed by grade 6 vs. grade 8 (see Table 11.4). There
are no completely missing responses (non-response at both waves) but
partial missingness only (wave 1 or wave 2). Effectiveness of the inter-
vention may be gauged by reduction in the percentage agreeing with the
question in the experimental group as compared with the control group.
MULTIPLE IMPUTATION
393

The analysis is carried out for individuals and rather than multiple
imputation (e.g. selecting a small number of sets of inﬁll values for ymis;1
and ymis;2) we use MAR imputation using known grades and intervention
groups, on the basis of repeated MCMC sampling. Let Gi ¼ 1 for experi-
mental group, Gi ¼ 2 for control group and Ci ¼ 1 for grade 6, and
Ci ¼ 2 for grade 8. The model is
yij  BernðijÞ
j ¼ 1; 2
logitði1Þ ¼ 0 þ 1ðCi ¼ 1Þ þ 2ðGi ¼ 1Þ þ 3ðCi ¼ 1; Gi ¼ 1Þ
logitði2Þ ¼ 0 þ 1ðCi ¼ 1Þ þ 2ðGi ¼ 1Þ þ 3ðCi ¼ 1; Gi ¼ 1Þ
where ðAÞ ¼ 1 if A is true. It would also be possible to include yi1 in
the model for i2. A non-ignorable model would include missingness
models pðR1jX; Y1Þ and pðR2jX; Y1; Y2Þ where X ¼ ðC; GÞ. The percen-
tage reductions j for experiment group grades 6 and 8 under the model
used are 0:169 (0.044) and 0:127 (0.045), while for control group
grades 6 and 8 they are 0.046 (0.053) and 0.035 (0.043).
Schafer (1999) takes four sets of multiply imputed data, and bases
inferences on j on the four ‘complete’ data sets, namely Ycomp;1 ¼ ðYobs;
Ymis;1Þ; Ycomp;2 ¼ ðYobs; Ymis;2Þ; Ycomp;3 ¼ ðYobs; Ymis;3Þ and Ycomp;4 ¼ ðYobs;
Table 11.4
Success of behavioral intervention
Experimental group
Agree after
Agree before
Grade 6
Grade 8
N
Y
NA
Total
N
Y
NA
Total
N
61
18
4
83
91
12
9
112
Y
55
70
14
139
35
19
3
57
NA
12
20
0
32
28
9
0
37
Grand total
128
108
18
254
154
40
12
206
Control group
Agree after
Agree before
Grade 6
Grade 8
N
Y
NA
Total
N
Y
NA
Total
N
69
16
7
92
100
23
11
134
Y
13
18
1
32
26
34
0
60
NA
24
12
0
36
37
31
0
68
Grand total
106
46
8
160
163
88
11
262
394
MISSING-DATA MODELS

Ymis;4Þ. The estimated j, obtained by averaging over four complete
data analyses and using (11.6) for estimating combined precision, are
0:173 (0.039), 0:152 (0.039), 0.041 (0.046) and 0.028 (0.040).
11.6
SEVERAL RESPONSES WITH MISSING VALUES
One may envisage adapting the strategies outlined in sections 11.2–11.5
to multivariate or panel responses. For a repeated univariate or multi-
variate response Yit at times t one may extend the non-ignorable model in
(11.2) to include several lags as well as contemporary effects, but such a
model may be subject to collinearity. With multivariate panel responses
Yitm for outcomes m ¼ 1; . . . ; M one conceivably should allow for cross-
lags and cross-contemporary effects between variables. For example, for
M ¼ 3, a non-ignorable missingess model might imply both contem-
porary effects on PrðRitm ¼ 1Þ of each of fYit1; Yit2; Yit3g and lagged
effects of each of fYi;t1;1; Yi;t1;2; Yi;t1;3g giving 21 parameters in addi-
tion to the intercepts.
Alternatively, as in Roy and Lin (2002), one might propose Q < M
more underlying factors fFit1; Fit2; . . . ; FitQg both to model the correla-
tion between the observations Yitm and to include in a less heavily
parameterized missingness model. Thus for metric or discrete outcomes
Yitm from an exponential family density with known scale, and Q ¼ 1,
one may set
Ritm  BernðitmÞ
gRðitmÞ ¼ 
m1 þ 
m2Fit
ð11:7aÞ
Yitm  EFðitmÞ
gYðitmÞ ¼ 0m þ 1mFit þ bim
ð11:7bÞ
where bim are permanent effects in the mth variable and where the factors
are deﬁned in terms of ﬁxed effects applied to a p  1 covariate vector Xit
and random subject effects applied to a q  1 covariate vector Zit. For
example,
Fit ¼ X
0
itt þ Z
0
iti þ vit
ð11:7cÞ
where t is p  1; the i might be multivariate normal of order q. If the Zit
and Xit are coincident then the means of i are zero. For identiﬁability
vit  Nð0; 1Þ and Xit and Zit should not include a constant if there are
already constants in (11.7b).
The missingness model (11.7a) may additionally involve lagged Fit as
well as lagged and contemporary covariates. Note that missingness is
SEVERAL RESPONSES WITH MISSING VALUES
395

likely to be at unit (subject) level, either attrition or intermittent, and
consist of total missingness at a given t for subject i on all responses Yitm.
Thus rather than variable-speciﬁc missingness one may consider a global
missingness indicator Rit ¼ 1 if at wave t subject i drops out or is
missing, and Rit ¼ 0 if the subject stays under observation or is subse-
quently observed. Then a non-ignorable model for it ¼ PrðRit ¼ 1Þ and a
single covariate might be
gRðitÞ ¼ 
0 þ 
1Fit þ 
2Fi;t1 þ 
3Xi;t1
ð11:7dÞ
Example 11.5 considers this approach for intermittent loss to observation
rather than permanent dropout, including intermittent item rather than
unit non-response.
Example 11.5
Diabetic patient biochemical markers
To illustrate
the use of latent (factor) variables in modelling missingness (Roy and
Lin, 2002) consider data from Crowder and Hand (1990, Table 2.1) on the
evolution of two biochemical markers in 27 patients. T ¼ 12 measures
are obtained on cyclic guanosine monophosphate (Y1 ¼ cyclic GMP) and
cyclic adenosine monophosphate (Y2 ¼ cyclic AMP) in the patients.
These are converted to ordinal scales, with J1 ¼ 5 levels on GMP
(under 5, 5–9.99, 10–14.99, 15–19.99, over 20) and J2 ¼ 6 levels on
AMP (under 6, 6–11.99, 12–17.99, 18–23.99, 24–29.99, 30þ). The
patients are classiﬁed into four groups, denoted by subject indicators
Gi, namely 1 ¼ normal control; 2 ¼ control diabetic; 3 ¼ diabetic with
hypertension; 4 ¼ diabetic with postural hypertension.
Missingness in these data is mostly intermittent rather than permanent
(only subjects 10 and 27 ﬁt the ‘lost to follow-up’ description). Also,
while most of this missingness is at subject level (i.e. when Yit1 is missing
so also is Yit2) there are instances of item non-response (e.g. Y19;1;2 is
missing whereas Y19;1;1 is not).
In the ﬁrst model for these data the underlying means of the ordinal
variables, Yitmðm ¼ 1; 2; i ¼ 1; . . . ; 27; t ¼ 1; . . . ; 12Þ, are explained by
the factor scores Fit and constant factor loadings m. So for responses
m ¼ 1; 2 and with itm ¼ ðitm1; . . . ; itmJmÞ
Yitm  CategoricalðitmÞ
itmk ¼ itmk  itm;k1
k ¼ 2; . . . ; Jm  1
logitðitmkÞ ¼ mk  mFit
Fit  Nðit; 1Þ
it ¼ Gi þ i
i  Nð0; 2
Þ
396
MISSING-DATA MODELS

where the  coefﬁcients (for patient group) are subject to a corner cons-
traint and an N(1,1) prior assumed for the second factor loading 2 (cf.
Johnson and Albert, 1999, p 197), with 1 preset as one. The latter cons-
traint improves identiﬁability and convergence, and means that the Fit
describe change at individual level in a latent factor underlying high
scores in both GMP and AMP. Additionally, for identiﬁcation of i the
ﬁrst cut point m1 is set to zero. The missingness mechanism involves
the Fit as follows:
Ritm  BernðitmÞ
logitðitmÞ ¼ 
0m þ 
1mFit
A two-chain run of 5000 iterations (convergent from 500) gives a mean
2 of 0.66 (95% interval from 0.50 to 0.86) so the underlying factor Fit
increases with both Y1 and Y2. The  scores range from 3.2 (subject 19,
who belongs to the lowest category of Y1 and Y2 on most readings) to 5.5
(for subject 26 who records especially high scores on Y2). There is some
evidence that missingness is non-ignorable in that 
11 is biased towards
negative values with mean 0.38 and 95% interval from 0.73 to 0.10:
patients with lower GMP readings tend to have higher rates of missing
data. The DIC is estimated at 1633 with de ¼ 114.
A second model introduces correlated subject–variable intercept effects
bim and time-speciﬁc loadings 2t (with 1t ¼ 1 for identiﬁcation). This
is an example of a permanent subject effect in a multivariate setting (see
section 10.8). Thus
logitðitmkÞ ¼ mk  mtFit  bim
This model considerably improves ﬁt (DIC ¼ 1363) at the cost of a slight
increase in de to 135. Imputations under the two models are similar
(Table 11.5). The coefﬁcient 
11 is still negative but with with mean
0.26 and 95% interval from 0.54 to 0.03.
11.7
NON-IGNORABLE NON-RESPONSE MODELS
FOR SURVEY TABULATIONS
Survey or census tabulations often include large proportions of non-
response. Bayesian models have been proposed for different types of
missing data situation in such tabulations. These include differential
non-response among survey subgroups (Stasny, 1991), partially observed
R  C cross-tabulations (Rosen et al., 2001), and missingness on one or
more factors in a multidimensional tabulation.
NON-IGNORABLE NON-RESPONSE MODELS FOR SURVEY TABULATIONS 397

11.7.1
The differential non-response model
In one scenario, the tabulated outcome is presented for subgroups,
deﬁned possibly by combinations of fully observed categorical variables
such as age group and gender (as in Park and Brown, 1994), or by known
Table 11.5
Diabetic markers, imputations of missing ordinal data
Missing datum
Model 1
Model 2
2.5%
Median
97.5%
Mean
2.5%
97.5%
Y1;9;1
1
2
4
1
2
4
Y1;11;1
1
2
4
1
2
5
Y2;11;1
2
3
5
1
3
5
Y3;11;1
2
3
5
1
3
5
Y4;11;1
2
3
5
1
3
5
Y10;11;1
1
2
4
1
2
4
Y10;12;1
1
2
4
1
2
4
Y12;11;1
1
2
4
1
2
5
Y13;11;1
1
2
3
1
2
4
Y16;1;1
1
1
1
1
1
2
Y23;11;1
1
1
3
1
2
3
Y25;5;1
1
2
3
1
2
3
Y27;11;1
1
1
1
1
1
2
Y27;12;1
1
1
1
1
1
2
Y1;9;2
1
3
6
1
3
5
Y1;11;2
1
3
6
1
3
6
Y2;11;2
2
3
6
2
4
6
Y3;9;2
2
3
6
1
3
5
Y3;11;2
2
3
6
1
3
6
Y4;11;2
1
3
6
1
2
4
Y8;11;2
1
2
4
1
3
5
Y10;11;2
1
3
5
1
3
6
Y10;12;2
1
3
5
1
3
6
Y12;11;2
1
3
6
1
2
4
Y13;11;2
1
3
5
1
3
6
Y14;1;2
1
2
3
1
1
3
Y16;1;2
1
1
3
1
1
3
Y19;1;2
1
1
3
1
1
3
Y23;11;2
1
2
4
1
2
4
Y25;5;2
1
2
5
1
2
4
Y27;11;2
1
1
3
1
1
3
Y27;12;2
1
1
3
1
1
3
398
MISSING-DATA MODELS

survey stratiﬁers such as urban or rural residence (as in Stasny, 1991).
Non-response rates will vary according to subgroup. Under a hierarchical
model one may pool over subgroups via exchangeable priors to improve
both the estimates of probabilities (binomial, multinomial) of the out-
come and the estimated non-response probabilities in separate subgroups.
The form of hierarchical model for the non-response probabilities is
deﬁned by the form of missingess. Taking non-response probabilities to
come from a single distribution, regardless of the possibly missing
outcome, is consonant with missingness at random. By contrast a non-
ignorable missingness model involves allowing differential non-response
according to the category of the outcome (Little and Gelman, 1999).
Suppose that the survey outcome is binary and that the tabulation is in
terms of k ¼ 1; . . . ; K groups deﬁned by observed subject variables or by
survey stratiﬁers. All subjects in subgroup k are taken to have the same
probability pik ¼ pk of the outcome, with prior density for pk a beta
distribution with parameters m1 and m2.
Suppose (following a selection model approach) that the chances of
non-response in group k are affected by the occurrence or otherwise of the
binary survey outcome. Let ik1 ¼ k1 ¼ PrðRik ¼ 1jYik ¼ 1Þ denote the
probability that subject i in group k is a non-respondent given that
he/she is positive on the outcome. The probability that subject i in group
k is a non-responder given that he/she is negative on the outcome is
ik0 ¼ k0 ¼ PrðRik ¼ 1jYik ¼ 0Þ. The total probability of non-response
(i.e. that Rik ¼ 1) involves the possible combinations of outcome PrðYikÞ
and of non-response conditional on outcome:
PrðRik ¼ 1Þ ¼ PrðRik ¼ 1jYik ¼ 1ÞPrðYik ¼ 1Þ
þ PrðRik ¼ 1jYik ¼ 0ÞPrðYik ¼ 0Þ
¼ k1pk þ k0ð1  pkÞ
ð11:8aÞ
For the conditional non-response probabilities one may adopt beta priors
k0  Betað0; 0Þ
k1  Betað1; 1Þ
with a default choice being 0 ¼ 0 ¼ 1 ¼ 1 ¼ 1.
Suppose there are Uk non-respondents in the kth group to the binary
outcome, with likelihood element as in (11.8a). Further suppose there are
Sk respondents with an observed positive outcome ðY ¼ 1Þ and Tk with an
observed negative outcome ðY ¼ 0Þ. The likelihood elements for the
latter two responder groups are respectively
PrðRik ¼ 0jYik ¼ 1ÞPrðYik ¼ 1Þ ¼ ð1  k1Þpk
ð11:8bÞ
NON-IGNORABLE NON-RESPONSE MODELS FOR SURVEY TABULATIONS 399

and
PrðRik ¼ 0jYik ¼ 0ÞPrðYik ¼ 0Þ ¼ ð1  k0Þð1  pkÞ
ð11:8cÞ
So the total likelihood involves terms (11.8a) to (11.8c) – see Stasny
(1991) for an empirical Bayes approach to this model. Congdon (2001)
outlines a fully Bayes approach to this situation and extensive modelling
options are considered by Nandram and Choi (2002a; 2002b). The crime
data used by Stasny are in Table 11.6. The domains are based on urban vs.
rural neighbourhood (U vs. R), city, other incorporated or not corporated
place (C/I/N), and high or low neighbourhood poverty (H/L). Combina-
tions of rural and city are excluded, so that only 10 of the 12 factor combi-
nations actually exist.
The estimates of the outcome probabilities pk may be distorted by dif-
ferential missingness between the groups. To model the total number of
positives on Y one may introduce, as a latent variable, the number Vk
among the total non-responders Uk who are positive on Y, leaving Uk
Vk non-responders who have Y ¼ 0. Then from (11.8a),
Vk  BinðUk; kÞ
ð11:9aÞ
with
k ¼ k1pk=½k0ð1  pkÞ þ k1pk
Table 11.6
National crime survey data
Domain
Responders reporting
Responders
Non-responders
Total
victimization (Sk)
crime free (Tk)
(Uk)
sample
UCL
156
555
104
815
UCH
95
364
73
532
UIL
162
557
101
820
UIH
72
262
36
370
UNL
92
297
79
468
UNH
15
40
9
64
RIL
11
36
7
54
RIH
10
105
20
135
RNL
35
274
32
341
RNH
79
413
64
556
400
MISSING-DATA MODELS

From the expression of the likelihood involving (11.8a)–(11.8c) one may
obtain the full conditional densities of the outcome rate and the condi-
tional response probabilities as
pkjVk; k0; k1  BetaðVk þ Sk þ m1; Tk þ Uk  Vk þ m2Þ
ð11:9bÞ
k1jpk; Vk  BetaðVk þ 1; Sk þ 1Þ
ð11:9cÞ
k0jpk; Vk  BetaðUk  Vk þ 0; Tk þ 0Þ
ð11:9dÞ
The above model is for non-ignorable response. By contrast, under MAR
one takes the missingness probabilities independent of outcome that
k0 ¼ k1 ¼ k. With a Bð; Þ prior on these probabilities their full
conditional density is
kjpk; Vk  BetaðUk þ ; Sk þ Tk þ Þ
When Y is multinomial (with J > 2 categories) rather than binomial, one
may modify the non-ignorable approach so that
pk  DirchðAk1; . . . ; AkJÞ
where pk ¼ ðpk1; . . . ; pkJÞ and Akj ¼ Vkj þ Skj þ mj and non-response pro-
babilities are updated according to
kj  BetaðVkj þ j; Skj þ jÞ
ð11:10aÞ
The stratum-speciﬁc non-respondents who are latent positives on Y are
updated according to
Vk  MultðUk; kÞ
ð11:10bÞ
where Vk ¼ ðVk1; .. . ; VkJÞ, k ¼ ðk1; .. . ;kJÞ and kj ¼ kjpkj= P
j kjpkj.
11.7.2
Alternative parameterizations of the differential
non-response model
Little and Gelman (1999) and Nandram and Choi (2002a) consider repara-
meterizations of the differential non-response model when the outcome is
binary. For groups k ¼ 1; . . . ; K, Little and Gelman (1999) consider the
ratios
Rk ¼ k1=ðk1 þ k0Þ
together with the overall non-response rate
k ¼ ðk0 þ k1Þ=2
so that k1 ¼ 2Rkk, k0 ¼ 2ð1  RkÞk. Thus the parameters fk1; k0; pkg
are replaced by fk; Rk; pkg. Setting a prior on the Rk, for instance a beta with
NON-IGNORABLE NON-RESPONSE MODELS FOR SURVEY TABULATIONS 401

mean 0.5, is consonant with a non-ignorable missingness model. Nandram
and Choi (2002a) adopt a similar model with
k1 ¼ kk0
ð11:11aÞ
though their model is set out in terms of probabilities of response by
group rather than non-response.
To assist in identiﬁcation when the data may contain little information
on conditional non-response, Little and Gelman argue that in most surveys
the Rk should vary less than the pk. They advocate drawing on previous
surveys to assess prior variability in the Rk. Nandram and Choi (2002a)
suggest the uniform shrinkage prior of Albert (1988) for k1 and k0 in
order to stabilize their estimation. They adopt a parameterization of the
beta Beð; Þ in terms of  ¼ ,  ¼ ð1  Þ so that  and  are ortho-
gonalized. Then the full conditional densities for pk and k0 may be para-
meterized as
pkjVk;k0;k1 BetaðVk þSk þ11;Tk þUk Vk þ1ð11ÞÞ ð11:11bÞ
k0jpk;Vk BetaðUk Vk þ22;Tk þ2ð12ÞÞ
ð11:11cÞ
The shrinkage prior is
j ¼ 1=Z0:5
j
 1
where Zj  Uð0; 1Þ, so that values on the boundary of the parameter
space are discouraged. For jðj ¼ 1; 2Þ a Be(1,1) prior is assumed, while
for the scaling factors k in (11.11a) the shrinkage prior is adopted again.
Speciﬁcally a truncated gamma, namely
k  Gað	; 	ÞIð ; 1=i0Þ
is used, to ensure that i1 is bounded above by one.
Example 11.6
National crime survey
Consider the Stasny (1991) data
in Table 11.6. These data show not only varying victmization rates
(among respondents) but non-response differing by stratum, with res-
ponse rates apparently higher in lower crime areas. One therefore seeks
stratum-speciﬁc and global estimates of victimization that adjust for non-
response. There is a subsidiary goal via (11.9b) to pool strength over
domains and stabilize estimates in small domains, such as RIL and UNH.
The empirical Bayes method used by Stasny gives estimates of k0 in
(11.9d) that are constant over domains (k0 ¼ 93:7% for all k), while the
k1 vary slightly from 67.9% to 69.4%; adjusted victimization rates vary
from 16.6% to 30.5%. To be consistent with Stasny (1991) the rates k1
and k0 in Program 11.6 relate to response rather than non-response.
402
MISSING-DATA MODELS

The fully Bayes conditional updating densities in (11.9) show slightly
less smoothing of the victimization rates than under the EB model, with a
range from 14.4% in RIH to 30.5% in UNH. The response rates k0
among the crime free vary from 88% to 94% and among the victimized
from 59% in RIH to 82% in UIH. Figures 11.1 and 11.2 show the rela-
tionships between pk and k1 and between pk and k0 respectively:
Figure 11.2 suggests a negative relationship between pk and k0.
11.7.3
Ecological inference: imputing missing interior data in
R  C tables
Rosen et al. (2001) and King et al. (1999) consider a situation that often
occurs in political science, i.e. inference about the cells of a population
0.87
0.88
0.89
0.9
0.91
0.92
0.93
0.94
0.95
0.1
0.15
0.2
0.25
0.3
0.35
Victim rate
Response rate
Figure 11.2
Response rate among crime free
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
0.1
0.15
0.2
0.25
0.3
0.35
Victim rate
Response rate
Figure 11.1
Response rate among victims
NON-IGNORABLE NON-RESPONSE MODELS FOR SURVEY TABULATIONS 403

cross-tabulation from information on marginal totals. Since the cells
within the cross-tabulations provide more information on individual
behaviour than the marginal totals, they can be seen as relevant to the
ecological inference problem (i.e. of inferring individual behaviour from
aggregate data). The analysis of the binomial case when the marginal
variables have only two categories (e.g. the observations are the marginal
totals of a 2  2 table when there are two variables) shows overlaps with
the differential response model of section 11.7.1. Consider observations
for a set of electoral areas on voting vs. ethnicity as follows: the total
electorate Ei eligible to vote (the grand total in the table), numbers actu-
ally voting Vi vs. those not voting Ei  Vi, and percentages black xi and
white, namely ð1  xiÞ, from census data. Equivalently, numbers of black
and white are Eixi and Eið1  xiÞ. Then the probability of voting i in
area i can be written as
PrðvoteÞ ¼ PrðvotejblackÞPrðblackÞ þ PrðvotejwhiteÞPrðwhiteÞ
or
i ¼ b
i xi þ w
i ð1  xiÞ
where b
i and w
i are unknown probabilities from the underlying 2  2
cross-tabulation. Then the observed data have model
Vi  Binði; EiÞ
while the latent numbers of voting blacks and voting whites are sampled as
Vb
i  Binði; ViÞ
Vw
i  Binð1  i; ViÞ
where i ¼ b
i xi=i. The unknown percentages are updated as
b
i  BetaðVb
i þ ab; Vw
i þ bbÞ
w
i  BetaðVw
i þ aw; Vb
i þ bwÞ
where fab; bb; aw; bwg may themselves be assigned priors. Thus King
et al. (1999, p 72) use E(2) priors for these parameters.
In the more general case each marginal of the table can have more than
two categories. For example, for each of i ¼ 1; . . . ; N electoral regions,
two variables are observed from different sources and cross-tabulation
is not possible. Thus the numbers tic voting for parties c ¼ 1; . . . ; C are
provided by electoral returns, while fractions xir of the voting age popu-
lation who are in social classes or ethnic groups r ¼ 1; . . . ; R are from the
census. The interest is in unobserved quantities such as the proportions
irc of people in social class r and area i who vote for different parties c.
404
MISSING-DATA MODELS

Assume that one or more variables Zij are available for each region that
are relevant to the voting choice (e.g. local unemployment rates). Missing
data for sets of areas may also be explained in part by their spatial struc-
ture in terms of adjacency or area centroids (Haneuse and Wakeﬁeld,
2004). Then the sampling model for the observed data is
ti;1:C  MultðVi; i;1:CÞ
where Vi is the total of voters, and taking the xir as known constants
ic ¼
X
R
r¼1
ircxir
A Dirichlet prior on the irc is assumed with parameters that may involve
a regression on relevant covariates. With one such covariate, the Dirichlet
weights are
ir1 ¼ dr expðr1 þ r1ZiÞ
ir2 ¼ dr expðr2 þ r2ZiÞ
...
ir;C1 ¼ dr expðr;C1 þ r;C1ZiÞ
irC ¼ dr
The parameters dr will typically be assigned gamma or exponential priors.
The work of Haneuse and Wakeﬁeld (2004) focuses on 2  2 tables for
a set of constituencies and on the marginal totals, namely Democrat and
Republican votes (columns) and black vs. white voters (rows). Only the
marginal totals are known (and taken from different sources). Letting xi
be the percentage black in area i, the probability i of voting Republican
can be written
Prðvote RepublicanÞ ¼ Prðvote RepublicanjblackÞPrðblackÞ
þ Prðvote RepublicanjwhiteÞPrðwhiteÞ
or
i ¼ b
i xi þ w
i ð1  xiÞ
where, as above, b
i and w
i are unknown race-speciﬁc probabilities of
voting Republican from the underlying 2  2 cross-tabulation. Haneuse
and Wakeﬁeld follow King et al. (1999) in taking the xi as known
constants (not stochastic); this assists in identiﬁcation of the unknown i
probabilities. They estimate these probabilities using the spatial structure
NON-IGNORABLE NON-RESPONSE MODELS FOR SURVEY TABULATIONS 405

of the areas in a mixed model (see Chapter 8):
logitðw
i Þ ¼ w þ uwi þ swi
logitðb
i Þ ¼ b þ ubi þ sbi
where u are unstructured and s are spatial errors, e.g. si  ICARð1Þ.
Example 11.7
Simulated voting by social class
As an example of
this framework we generate data for N ¼ 150 areas, R ¼ 3 social classes
and C ¼ 3 political parties. This example follows some of the aspects set
out in an example of Rosen et al. (2001) who were interested in assessing
the proportions of different social classes voting for the National Socia-
lists in the 1932 German elections. Speciﬁcally a covariate for each area
is generated as N(0,1) and ‘important covariate’ coefﬁcients rc follow
those in Rosen et al. (2001); their substantive interest was in the effect of
area unemployment Z on the pattern of voting by class.
Total voters Vi are generated from a Poisson–gamma mixture with
mean 10 000. Proportions f0:4; 0:4; 0:2g are assumed to generate the
social class proportions xir, via a Dirichlet with parameters f4; 4; 2g.
To estimate the model from the simulated data we ﬁrst assume dr 
ExpðÞ where  is unknown. An E(1) prior is assumed on , and N(0,10)
priors are assumed for rc and rc. It is necessary to model the Dirichlet
prior on the irc using a series of gamma densities (a Dirichlet on 1:C
with
weights
1; 2 ; . . . ; C
may
be
sampled
by
ﬁrst
taking
yj  Gðj; 1Þ for j ¼ 1 ; . . . ; C and then setting j ¼ yj= P
j
yj). Following
Rosen et al. (2001) the xir are taken as known rather than stochastic.
The second half of a two-chain run of 20 000 iterations reproduces the
parameter values assumed in the simulation (Table 11.7).
Table 11.7
Posterior parameter estimates for simulated voting by social class
Parameter
Assumed value
Posterior mean
Standard deviation
11
0.3
0.51
0.22
12
0.4
0.58
0.14
21
0.5
0.20
0.32
22
0.9
1.09
0.16
31
0.8
1.22
0.21
32
1.4
1.12
0.20
11
1.6
1.50
0.16
12
2.2
2.12
0.17
21
1
0.88
0.21
22
1.6
1.71
0.13
31
1.2
1.14
0.20
32
1.4
0.86
0.16
406
MISSING-DATA MODELS

11.7.4
Cross-tabulations with missing data on any factor
The general situation here is that a cross-tabulation involves K catego-
rical variables Y1; Y2; Y3; . . . ; YK with I1; I2; I3; . . . ; IK levels. Incomplete-
ness at subject level may occur on just one of these, or on one or more in
combination – with the worst case being subjects with complete non-
response on all K variables. Consider for illustration a two-way table with
binary variables Y1 and Y2.
The possible missingness patterns can be summarized as a two-way
table with supplementary margins - see Jansen et al. (2003), Baker et al.
(1992) and Molenberghs et al. (1999). Thus Jansen et al. consider binary
data on treatment side effect and duration of follow-up (Table 11.8).
Let njkr1r2 denote a cross-classiﬁcation both by response category (r1 ¼
1 if Y1 observed, 0 if Y1 missing and r2 ¼ 1 if Y2 observed, 0 if Y2
missing) and by the categories j and k of Y1 and Y2 themselves. Thus
Baker et al. (1992) consider a study on infant birth-weight (low, normal)
and maternal risk Y2 (high, low) with observations (nine counts of mother)
as follows:
a 2  2 table for both variables observed fnjk11g
a 1  2 vector with only maternal risk observed fn:k01g
a 2  1 vector with only child birth-weight observed fnj:10g
a scalar for neither observed fn::00g
In the second case the four underlying ‘complete data’ cells fnjk01g have
to be estimated, in the third case the cells fnjk10g have to be estimated,
and so on.
Table 11.8
Side effects by duration: numbers of subjects in different response
groups
Side
Completely observed
Side effect
Duration observed
Duration
effect
duration
observed
side effect missing
missing
duration
side effect
Below
Above
missing
Below
Above
missing
4 years
4 years
4 years
4 years
Yes
89
13
26
14
No
57
65
49
2
0
NON-IGNORABLE NON-RESPONSE MODELS FOR SURVEY TABULATIONS 407

Following Jansen et al. (2003) the probability jkr1r2 of belonging to
a particular category of the unobserved full data may be speciﬁed as a
selection model
jkr1r2 ¼ qr1r2jjk pjk
ð11:12aÞ
where
pjk ¼ jk=
X
j
X
k
expðjkÞ
ð11:12bÞ
is the model for fY1; Y2g and
qr1r2jjk ¼ exp½jkð1  r1Þ þ jkð1  r2Þ þ ð1  r1Þð1  r2Þ=
½1 þ expðjkÞ þ expðjkÞ þ expðjk þ jk þ Þ
ð11:12cÞ
speciﬁes missingness given Y1 ¼ j and Y2 ¼ k. Thus jk only operates
when r1 ¼ 0, jk only when r2 ¼ 0, etc. When Y1 and Y2 are binary the
probabilities of the observed nine counts are then given by 1111, 1211,
2111, 2211, :101, :201, 1:10, 2:10 and ::00 where for example
::00 ¼ 1100 þ 1200 þ 2100 þ 2200
For identiﬁability, it is necessary to set the jk or jk equal to each other
(e.g. jk ¼ ), or equal either for all j or for all k (e.g. jk ¼ j). Thus
identiﬁable models are as follows:
(1) jk ¼ , jk ¼ 
(2) jk ¼ , jk ¼ j
(3) jk ¼ k; jk ¼ 
(4) jk ¼ , jk ¼ k
(5) jk ¼ j, jk ¼ 
Model (1) represents ignorable missingness since the chance of an observa-
tion missing does not depend on the unobserved level of Y1 or Y2. Models
(2) and (3) mean missingness on one variable is ignorable but missing-
ness on the other variable depends on the outcome of the former. Models
(4) and (5) mean missingness on one variable is ignorable but missing-
ness on the other variable depends on its own outcome.
An alternative parameterization is given by Baker et al. (1992). Thus
a log-linear model for the means jk11 ¼ mjk of the fully observed
subtable is
logðmjkÞ¼0 þ1j þ2k þ3 þ4 þ12jk þ13j þ14j þ23k þ24k þ34
408
MISSING-DATA MODELS

where 1j, 2k and 12jk are conventional log-linear effects but parameters
with subscripts 3 or 4 involve missing data. Thus 3 is the main effect for
Y1 missing, 4 is the main effect for Y2 missing, and 34 is the effect for
both missing. The model for data with Y1 missing has means jk01 ¼
mjkjk where
logðjkÞ ¼ 2½3 þ 13j þ 23k þ 34
The model for data with Y2 missing has means jk10 ¼ mjkjk where
logðjkÞ ¼ 2½4 þ 14j þ 24k þ 34
and the model for data with Y1 and Y2 missing has means jk00 ¼
mjkjkjk where
logðÞ ¼ 434
Priors are placed on jk, jk and , subject to alternative restrictions as
in (1)–(5) above for identiﬁcation.
Example 11.8
Psychiatric study
Consider the data in Table 11.8 and
the selection model speciﬁed by (11.12). Only one option for deﬁning the
missingness model (11.12c) is considered, namely the ignorable missing
model jk ¼ , jk ¼  (Baker et al., 1992, p 646). The data model in
(11.12b) involves three  parameters: one for j ¼ 1; k ¼ 1, one for j ¼
1; k ¼ 2 and one for j ¼ 2; k ¼ 1. Nð0; 1Þ priors are assumed for ,  and
1, 2, 3.
The resulting DIC is 52 with 5.1 parameters, and the model estimates
are summarized in Table 11.9. The negative credible interval for 3
shows lesser side effects for patients at longer durations. Other identiﬁ-
able models are considered by Jansen et al. (2003, Table 3). A sensitivity
analysis would consider alternative missingness models and the impact
on the  parameters.
11.8
RECENT DEVELOPMENTS
The models considered above have focused on true missing data as opposed
to latent variables (e.g. several manifest variables may be an indicator for
a latent class as in the case of diagnosis when there is no gold standard
test). They have in some cases considered simple binary situations (e.g. in
sections 11.7.2 and 11.7.4), though extensions to multinomial and ordinal
situations may be obtained. Furthermore situations where missingness
includes both categorical and metric data have not been discussed – for
RECENT DEVELOPMENTS
409

example, see Schafer (1997) on the general location model. Recent deve-
lopments of the location model are considered by Peng et al. (2003).
Another area where Bayesian extensions are possible is in semi-parametric
modelling of the non-response mechanism (Scharfstein and Irizarry,
2003). Recent book-length treatments of missing data include Allison
(2002), Gelman and Meng (2004) and Little and Rubin (2002).
EXERCISES
1.
In Example 11.1 try a selection model (for non-monotone missing-
ness) rather than a pattern mixture model (see data set C in Program
11.1 with missing data explicit). Relate PrðRitÞ to Yi;t1 and Yit via a
logit regression (Rit ¼ 1 if Y is NA) and assess whether a non-
ignorable model is supported. For example, see equation (11.2b).
Note that a model without random intercepts and slopes (on weeks0.5)
Table 11.9
Ignorable model summary
Node
2.5%
Median
97.5%

4.23
3.57
3.06

1.31
1.04
0.80

0.94
1.72
2.54
n1111
68.88
81.37
95.75
n2111
46.82
58.69
71.40
n1211
7.55
12.94
20.40
n2211
53.36
65.15
78.55
n1110
22.57
28.79
35.92
n2110
15.46
20.71
26.64
n1210
2.54
4.57
7.51
n2210
17.31
23.09
29.46
n1101
1.16
2.30
3.87
n2101
0.83
1.64
2.83
n1201
0.16
0.35
0.73
n2201
0.92
1.82
3.15
n1100
2.46
4.48
7.48
n2100
1.73
3.23
5.45
n1200
0.33
0.70
1.38
n2200
1.96
3.58
6.01
1
0.05
0.22
0.51
2
0.44
0.11
0.23
3
2.20
1.62
1.10
410
MISSING-DATA MODELS

may be simpler to ﬁt. So one may assess whether there is a loss of ﬁt
in making this simpliﬁcation.
2. In Example 11.2 it may not necessarily be that missingness on the
covariate X6 ¼ TRF is related to CBCL and TRF independently but to
discrepancies between the ratings. One reason for missingness of TRF
is that parents refused to give permission for school information to be
obtained (Fitzmaurice et al., 1996, p 104). In the model for PrðRi ¼ 1Þ
where Ri ¼ 1 if TRF is missing, substitute a variable for the difference
between TRF and CBCL to replace the separate effects of these two
predictors and assess whether missingness is non-ignorable on this
basis. Also assess whether missingness is non-ignorable if CBCL is
excluded as a predictor in the logit regression for R.
3. In Example 11.3 compare the inferences on the main substantive
question (the impact on whether GRD=A of FLAS, CGPA, MLAT and
prior courses) as obtained from the models described with those based
on a ‘complete case’ analysis. The latter involves excluding any
subjects with missing (NA) values on any X or on Y.
4. In Example 11.3 replicate the analysis undertaken but with Y treated
as ordinal rather than reduced to binary.
5. In Example 11.4 apply formal multiple imputation based on taking
samples of missing Y1 and Y2 at iterations 1000 and 2000 in a two-
chain run of Program 11.4 (this involves using the state-space com-
mand in WINBUGS). Try estimating the j and their standard errors
from the corresponding four ‘complete’ data sets.
6. In Example 11.4 modify the existing program to allow non-ignorable
missingness by making the probability of response (Rj ¼ 1 if Yj is
observed) depend on the outcome as well as treatment and grade, so
there are two missingness models, pðR1jX; Y1Þ and pðR2jX; Y1; Y2Þ
where X ¼ ðC; GÞ. How does this affect estimates of the j?
7. In Example 11.5 apply the model
logitði1jkÞ ¼ jk  1jFi1
logitðitjkÞ ¼ jk  1jFit  2jFi;t1
t > 1
and compare the imputations with those obtained under the two
models described.
8. In Example 11.5 apply the models already in the program but with the
original continuous response data on Y1 and Y2 (included in the
EXERCISES
411

programs) formed into ordinal variables with more categories (e.g.
eight on both).
9. In Example 11.6 introduce a prior (e.g. E(2)) on the j and j para-
meters in (11.9c) and (11.9d) and assess any impacts on inferences.
10. In Example 11.8 try the missingness model with jk ¼ , jk ¼ k
(i.e. missingness on Y2 depends on its level).
REFERENCES
Aitchison, J. and Ho, C. (1989) The multivariate Poisson-log normal distribution.
Biometrika, 76, 643–651.
Albert, J. (1988) Bayesian estimation of Poisson means using a hierarchical log-
linear model. In Bayesian Statistics 3, Bernardo, J., DeGroot, M., Lindley, D.
and Smith, A. (eds). Oxford University Press: New York, 519–531.
Allison, P. (2002) Missing Data. Sage: Thousand Oaks, CA.
Baker, S., Rosenberger, W. and DerSimonian, R. (1992) Closed form estimates
for missing counts in two-way contingency tables. Statistics in Medicine, 11,
643–657.
Congdon, P. (2001) Bayesian Statistical Modelling. John Wiley & Sons:
Chichester.
Crowder, M. and Hand, D. (1990) Analysis of Repeated Measures. Chapman
and Hall: London.
Diggle, P. and Kenward, M. (1994) Informative drop-out in longitudinal data
analysis. Applied Statistics, 43, 49–93.
Faris, P., Ghali, W., Brant, R., Norris, C., Galbraith, P. and Knudtson, M. (2002)
Multiple imputation versus data enhancement for dealing with missing data
in observational healthcare outcome analyses. Journal of Clinical Epidemio-
logy, 55, 184–191.
Fitzmaurice, G., Laird, N. and Zahner, G. (1996) Multivariate logistic models for
incomplete binary response. Journal of the American Statistical Association,
91, 99–108.
Gelman, A. and Meng, X.-L. (eds) (2004) Bayesian Analysis, Causal Inference,
and Missing Data. John Wiley & Sons: New York.
Haneuse, S. and Wakeﬁeld, J. (2004) Ecological inference incorporating spatial
dependence. Chapter 13 in Ecological Inference: New Methodological Stra-
tegies, King, G., Rosen, O. and Tanner, M. (eds). Cambridge University Press:
Cambridge.
Hedeker, D. and Gibbons, R. (1997) Application of random-effects pattern-
mixture models for missing data in longitudinal studies. Psychological
Methods, 2, 64–78.
412
MISSING-DATA MODELS

Hopke, P., Liu, C. and Rubin, D. (2001) Multiple imputation for multivariate
data with missing and below-threshold measurements: time series concentra-
tions of pollutants in the Arctic. Biometrics, 57, 22–33.
Horton, N. and Fitzmaurice, G. (2002) Maximum likelihood estimation of
bivariate logistic models for incomplete responses with indicators of ignorable
and non-ignorable missingness. Applied Statistics, 51, 281–295.
Horton, N. and Laird, N. (2001) Maximum likelihood analysis of logistic regres-
sion models with incomplete covariate data and auxiliary information.
Biometrics, 57, 34–42.
Ibrahim, J., Lipsitz, S. and Chen, M.-H. (1999) Missing covariates in generalized
linear models when the missing data mechanism is non-ignorable. Journal
of the Royal Statistical Society Series B, 61, 173–190.
Ibrahim, J., Chen, M. and Lipsitz, S. (2001a) Missing responses in generalized
linear mixed models when the missing data mechanism is non-ignorable.
Biometrika, 88, 551–564.
Ibrahim, J., Lipsitz, S. and Horton, N. (2001b) Using auxiliary data for para-
meter estimation with non-ignorably missing outcomes. Applied Statistics, 50,
361–373.
Jansen, I., Molenberghs, G., Aerts, M., Thijs, H. and Van Steen, K. (2003) A local
inﬂuence approach applied to binary data from a psychiatric study. Biometrics,
59, 410–419.
Johnson, V. and Albert, J. (1999) Ordinal Data Modelling. Springer: New York.
King, G., Rosen, O. and Tanner, M. (1999) Binomial-beta hierarchical models
for ecological inference. Sociological Methods and Research, 28, 61–90.
Laird, N. (1988) Missing data in longitudinal studies. Statistics in Medicine, 7,
305–315.
Lavori, P., Dawson, R. and Shera, D. (1995) A multiple imputation strategy for
clinical trials with truncation of patient data. Statistics in Medicine, 14, 1913–
1925.
Little, R. (1993) Pattern-mixture models for multivariate incomplete data. Journal
of the American Statistical Association, 88, 125–134.
Little, R. and Rubin, D. (1987) Statistical Analysis with Missing Data. John Wiley
& Sons: New York.
Little, R. and Rubin, D. (2002) Statistical Analysis with Missing Data, 2nd Edi-
tion. John Wiley & Sons: New York.
Little, T. and Gelman, A. (1999) Modelling differential nonresponse in sample
surveys. Sankhya, B60, 101–126.
Molenberghs, G., Goetghebeur, E., Lipsitz, S. and Kenward, M. (1999) Non-
random missingness in categorical data: strengths and limitations. American
Statistician, 53, 110–118.
Molenberghs, G., Michiels, B., Verbeke, G. and Curran, D. (2002) Strategies to ﬁt
pattern-mixture models. Biostatistics, 3, 245–265.
Nandram, B. and Choi, J. (2002a) A Bayesian analysis of a proportion under non-
ignorable nonresponse. Statistics in Medicine, 21, 1189–212.
REFERENCES
413

Nandram, B. and Choi, J. (2002b) Hierarchical Bayesian nonresponse models for
binary data from small areas with uncertainty about ignorability. Journal of the
American Statistical Association, 97, 381–388.
Park, T. and Brown, M. (1994) Model for categorical data with nonignorable
response. Journal of the American Statistical Associationi, 89, 44–52.
Peng, Y., Little, R. and Raghuanthan, T. (2003) An extended general location
model for causal inference from data subject to noncompliance and missing
values. Working Paper Series, No. 7, University of Michigan, Department of
Biostatistics.
Rosen, O., Jiang, W., King, G. and Tanner, M. (2001) Bayesian and frequentist
inference for ecological inference: the R  C case. Statistica Neerlandica, 55,
134–156.
Roy, J. and Lin, X. (2002) Analysis of multivariate longitudinal outcomes with
non-ignorable dropouts and missing covariates: changes in methadone treat-
ment practices. Journal of the American Statistical Association, 97, 40–52.
Rubin, D. (1976) Comparing regressions when some predictor variables are
missing. Psychometrika, 43, 3–10.
Rubin, D. (1987) Multiple Imputation for the Non-response in Surveys. John
Wiley & Sons: New York.
Schafer, J. (1997) Analysis of Incomplete Multivariate Data. Chapman and Hall:
London.
Schafer, J. (1999) Multiple imputation: a primer. Statistical Methods in Medical
Research, 8, 3–15.
Scharfstein, D. and Irizarry, R. (2003) Generalized additive selection models for
the analysis of studies with potentially non-ignorable missing outcome data.
Biometrics, 59, 601–613.
Stasny, E. (1991) Hierarchical models for the probabilities of a survey classiﬁca-
tion and nonresponse: an example from the National Crime Survey. Journal of
the American Statistical Association, 86, 296–303.
414
MISSING-DATA MODELS

Index
activities of daily living (ADL) 187
adaptive non-parametric regression
143–4
adaptive rejection sampling (ARS) 112
age at menarche 147–8
age–period–cohort (APC) models
362–4
age–period interactions 366
aggregated multicategory data 219–21
aggregated multinomial data 197
models for 202–10
time series of 298–300
aggregated ordinal data, structural
interpretations 251–5
Akaike information criterion (AIC) 42–5,
63, 65, 343
Albert–Chib method 121–5, 322
antisocial behaviour (ASB)
data analysis 227–30
development 351–2
APC model extension 367
ARMA structure 309
association model with outliers 257–8
association parameter 256, 258
attitudes towards working mothers 244
augmented data probit 123–4
augmented data sampling for hierarchical
GLMS 328–33
autocorrelated error models, parameter-
driven dependence via 309–11
autocorrelation 290–1, 321
in panel categorical data 342
autoregressive structure 351
auxiliary variables 385–7
averaging based on predictor selection
59–65
basis function models 86
basis function regression 86–7
Basu–Mukhopadhyay model 173
Bayes factor 12–13, 31, 39–41, 46, 56–7,
127–8, 139
approximation 32–5, 127
logarithm of 35
methods 173
Bayes perspective, penalized deviances
from 41–2
Bayes sampling approach 112
Bayesian epidemiology 279
Bayesian geostatistics 267
Bayesian inference, principles of 1–27
Bayesian Information Criterion (BIC)
42–4, 63, 65, 343
Bayesian measures of ﬁt 118
Bayesian methods for robust
regression 67
Bayesian model weight 48, 65
Bayesian predictive approaches to model
choice and diagnosis 29–30
Bayesian sampling-based estimation
techniques 1
Bayesian signiﬁcance tests 205
Bayesian simulation 121
Bayesian updating 1–2
beetle mortality data 174–6
behavioural intervention 393–5
Bernoulli–beta mixture 178
Bernoulli density 303
Bayesian Models for Categorical Data
P. Congdon
# 2005 John Wiley & Sons, Ltd

Bernoulli disaggregation 162
Bernoulli likelihood 145, 178–9
beta–binomial 160
mixing 304
model 163–4
beta density 117
beta mixture
modelling of cumulative density
associated with inverse link 176
on cumulative densities 174–7
binary adjacency 269, 271, 279
binary data 117–21
analysis 112
augmentation 293–7
binary indicators 184
binary outcome-models 112–53
binary regression, predictor selection
130–3
binary sampling model 167
binary selection 92
binary selection indicators 63
binomial clustering 120–1
binomial data 117–21
binomial density 156
binomial model, generalization 155–7
binomial probability 156
binomial regression 155–95
binomial responses 140–8
binomial sampling 365
biochemical markers, diabetic patients
396–8
bivariate Poisson log-normal mixture 185
bivariate probit 184
blood cell sedimentation 144–6
bovine trypanosomiasis 120–1
Box–Cox transform 71, 144
Box–Pierce statistic 291, 295–6
Brooks–Gelman–Rubin (BGR) statistic 11
BUGS 244
cancer deaths in Glasgow 272–3
robust models for 275
canonical models 14–15
Carlin–Chib algorithm 49
Carter–Lee model 366
case–control studies 120
categorical data models 23
categorical indicator 197
Cauchy density 123
census data 197
cherry trees, usable wood 73
chi-square density 42
chi-square deviations 209
chi-square variable 45
child respiratory hospitalizations 334–6
choice applications 199
Choleski decomposition 359
cisplatin and nausea 249–50
cluster-level attributes 323
cluster-speciﬁc effects 323
cluster-speciﬁc random effects 322–3
clustered data 321–2
clustered multinomial data 328–9
clustered ordinal data analysis, wine
bitterness 331–3
clusters, average number of non-empty 361
cohabitation experience 329–31
comparator density 10
competing models 12
complementary log–log 235
complete data representation 76–7
concentration index 252
concordancy index 243
conditional contingency tables 203–10
conditional density 8, 380
conditional dispersion matrix 279
conditional linear autoregressive (CLAR)
process 292
conditional logit model 200
conditional means prior (CMP) 120
conditional non-response probabilities 399
conditional outcome 181
conditional posterior 56
conditional predictive ordinate (CPO)
39–40, 67, 161, 206–7, 272–3, 331,
336, 338, 349, 352, 358, 371
conditional probability 12, 61–2
conditional probability theorem 2
conditional variance 55, 159
conditioning factors 204
conditioning sequences 388
conjugate analysis 114
conjugate frailty model 159
conjugate multivariate normal prior 56
conjugate panel models 346–9
conjugate Poisson–gamma mixture 325
416
INDEX

conjugate Poisson model 164
conjugate prior 13, 131–2
conjugate prior density 117
conjugate updating 304
contamination classes 21
contingency tables 133–40
modelling 202–10
probabilities for different K 210
with ordered categories, log-linear
models for 255–8
continuous mixture models 157–63
contraceptive use 137–9
convergence 323, 361
count regression 116, 119, 155–95
predictor selection 130–3
count responses 140–8
Cox and Snell assay data 250–1
cross-classiﬁed counts 136
cross-model priors 47
cross-tabulations with missing data
407–9
cross-validation
function 99
out-of-sample 39–41
crossed factors, random effects for 333–6
cumulative density 174
associated with inverse link, beta
mixture modelling of 176
beta mixture on 174–7
cumulative density function 248
cumulative logit model 235
cumulative odds 243
cumulative odds model 237
cumulative probabilities 235
cumulative standard normal 235, 247
cystic ﬁbrosis
malnutrition in 64–6
static expiratory pressure in 101–2
data augmentation 17–19, 112–25, 142,
198, 201, 236–43
outlier detection under 129
degree of uncertainty 2
demographic attributes 197
density mechanisms for missing data
381–4
density of intermodel ﬁt statistics 45
deprivation scores 278
derogatory reports 169–70
deviance criterion 126
deviance information criterion (DIC) 42–6,
70, 74–5, 118–19, 140, 166, 184, 187,
215, 218–19, 224–5, 243–5, 258,
263, 272, 275, 283, 296, 300, 307,
313, 330, 332–3, 343, 349, 357–8,
384
diabetic patients, biochemical markers
396–8
differential non-response model 398–401
alternative parameterizations 401–3
Dirichlet mixture 242
Dirichlet model 326
Dirichlet parameters 166, 224, 360
uncertainty in 223–6
Dirichlet posterior 220
Dirichlet prior 167, 220, 223, 241–2, 405
Dirichlet process prior (DPP) 21, 72, 74,
81, 176, 274, 282, 337, 358, 360–1
discrepancy criterion 133
discrepancy functions 40
discrete mixtures 163–7, 172, 274, 323
estimation 75
models, robustness via 75–81
discrete model likelihoods 112–21
discrete spatial data 267–88
discrete variables, time series models for
289–319
disease mapping 115, 269
model 38
dispersion structure 185
DNA sequences 299–300
double-binomial models 161
double-exponential (DE) 70
double-exponential density 68, 238
double-Poisson models 161
dropout model 382, 384–5
dynamic binary time series model 301
dynamic generalized linear models
(DGLMs) 289, 299, 341
dynamic linear models (DLMs) 95–105
common forms 96–7
normal errors 97
parameter-driven dependence via 300–8
robust errors 97–8
dynamic linear (state-space) priors 73
dynamic log-linear Poisson model 301
INDEX
417

ecological inference 156, 403–6
egg hatching experiment 165–6
electricity use 63–4
and temperature 103–5
empirical Bayes (EB) techniques 112
England vs. Scotland internationals 297
entre´es in army meals, sensory evaluation
254–5
epileptic seizures 360–2
Epstein–Barr virus 299
error structure 29
erythrocyte sedimentation (ES) 144
evolution variance 100
exam grade frequencies 208–9
expected predictive deviance (EPD) 37
exponential family density 130, 324
factor analysis approach 179–80
factor analytic model 339
extension 339
factor model 183, 185, 357
factor regression model, regression effects
under 187
ﬁnite mixture models 75–6, 78
ﬁxed effects analysis 118
foreign language attainment 390–1
Foreign Language Attitude Scale (FLAS)
390–1
formal Bayesian model, approximation
methods 34
formal Bayesian model assessment 30–2
formal model probabilities, Monte Carlo
estimates 43
frequency smoothing 204, 208
galaxy data 80–1
gamma conditional 103
gamma density 56, 116, 123
gamma frailty model 157
gamma mixture 158, 161
gamma–Poisson mixing 290, 304
gamma–Poisson model 163
gamma prior 20, 74, 115, 223, 325
gamma scale mixture 358–9
gamma variables 124
Gelfand–Ghosh criteria 127, 140
Gelman–Rubin scale reduction factors 10
general additive models 140–8
general linear mixed models (GLMMs) 17,
160–1, 165, 321–2, 326, 336–46, 360
generalized additive models (GAMs)
98–102, 213
generalized linear models (GLMs) 13–17,
130, 155
generalized linear models (GLMs)
deviance 41, 118, 336
generalized linear models (GLMs)
extensions 161
generalized linear models (GLMs) link
function 171
generalized linear models (GLMs)
regresson models 56–7
Gibbs sampling 7, 18, 75, 77, 112, 211,
238, 322–3
grouping index 101
growth curve analysis 350–2
health care demand 184–8
health demand data 355–6
heart attack risk 137–9
Hessian matrix 32
heterogeneity 226
in choice modelling 198
in intercepts 324
in multinomial probit 212
modelling 221–2
via mixed logit 216–19
heteroscedastic model 94
heteroscedasticity 72, 86
hidden Markov models (HMMs) 313–15
hierarchical generalized linear models
324–33
hierarchical GLMS, augmented data
sampling for 328–33
hierarchical log-linear models 134
hierarchical models 321–78
for metric outcomes 322–4
random effects in 22
human choice applications 198
hurdle models 167
hurdle regression 170–1
hyperdensity 204
ICAR 269–77, 368
identiﬁability 19–21, 213, 217, 224, 323,
327, 366, 408
418
INDEX

identiﬁability constraint 157, 167, 203, 346
identiﬁability factor scores 357
identiﬁability issues 77–8, 88, 90, 182, 270
ignorable missingness 408
improvement ratios 348
incumbency advantage in election 225–6
independence model 137
independence of irrelevant alternative
(IIA) assumption 201, 218
independent priors 56–7
index of multiple deprivation (IMD) scores
277
individual data, multinomial models for,
modelling choices 198–201
individual multicategory data, observation-
driven models for 297–8
inequality index 252
inference sensitivity 22
integer-valued autoregressive (INAR)
models 311–13
interaction effects 297–8
interaction splines 88
intercepts, heterogeneity in 324
intermittent nonmonotone missingness 383
intrinsic conditional autoregression see
ICAR
inverse link, beta mixture modelling of
cumulative density associated with
176
inverse variance 20
Jacobian adjustment 8–9
Jeffreys’ type scale 41
joint life table 277
kernel plot, link parameter 175
knot locations 84, 90
lagged error effects 338
Laplace approximation 32
Laplace prior 273
latent class analysis 226–30
latent (factor) variables in modelling
missingness 396
latent normal sampling, simulated data
128–30
latent response model 237
latent scale 236–43
model 243
latent variable models for multicategory
outcomes 197–234
least squares formulae 85
left-skewed extreme value (LSEV) 238–9,
241
light detection and ranging (LIDAR),
penalized spline for 93–4
likelihood weights 62
linear regression model, priors for 55–9
link function 15
modelling 171–7
link generalizations 156
link parameter, kernel plot 175
location-scale model 328
location-scale ordinal regression 247–51
log evidence ratio 46
log-likelihood 118
log-likelihood ratio 46
log-linear models for contingency tables
with ordered categories 255–8
log-linear regression 126, 136
log–log links 119
logistic density 123
logistic regression 123, 130–1, 164
logistic regression mixture 166
logit linear random effects 327
logit link 19, 122–3, 128, 145, 178, 247
logit regression 128
of nodal involvement 127–8
logit transform 144
longitudinal categorical data 340–6
Lorenz concentration curves 252
loss function 37
low-tar cigarettes 393–5
lung cancer mortality in Italian males
368–9
main effect splines 88
malnutrition in cystic ﬁbrosis 64–6
marginal density 3
marginal likelihood 31–5, 60, 116, 122,
347
approximation 127
estimation 40
marginal outcomes 180–2
marginal posterior probabilities 59
Markov chain models 293–8
Markov transition model 301
INDEX
419

MARS model 93
matrix partition method 218
maximum likelihood (ML) 2
analysis 16
estimation 206
parameters 16
techniques 112
maximum of model likelihoods 50
mean missingness 408
measurement error models 302–3
median probability model 49
menarche, age at 147–8
mental health service use 386–7
mental health status 241–3
by social status 257–8
metric outcomes
hierarchical models for 322–4
regression models for 55–111
metric scale model 19
Metropolis–Hastings (M–H) algorithm 6
Metropolis–Hastings (M–H) sampling 8
Metropolis–Hastings (M–H) updating
schemes 95
Metropolis step 60
Meyer and Laud prior 120
missing data
cross-tabulations with 407–9
density mechanisms for 381–4
in R  C tables 403–6
models 379–114
recent developments 409–10
problems 4
types 379–80
missing values
predictors with 387–91
responses 395–7
missingness
at random (MAR) 380, 389, 391–2,
394
completely at random (MCAR) 279,
380, 389
ignorable 408
indicators 382
latent (factor) variables in modelling
396
monotone 379, 383
non-ignorable 381–2
missingness model 389–90, 395–6
parameters 380
psychiatric study 409
missingness patterns, side effects 407
missingness status 382
mixed attribute model 201
mixed ICAR model and extensions 268–73
mixed logit
heterogeneity via 216–19
model 201, 218
mixed MNL (MMNL) models 201, 327
mixed model in spatial epidemiology 41
mixture density 80
mixture generalizations 156
mixture prior 61
mixture transition distribution (MTD)
model 298
model averaging strategy 20
model comparison and choice 29–53
formal methods 29
penalized deviance criteria 29
predictive methods 29
sensitivity and robustness 21–3
model extension methods 68
model identiﬁability 19–21
model likelihoods, maximum of 50
model probability 49–50
estimates from parallel
sampling 46–9
Modern Language Aptitude Test (MLAT)
390–1
modiﬁed exponential families 161–3
monotone missingness 379, 383
Monte Carlo Markov Chain (MCMC) 267,
269–70, 363
basis for 4–6
convergence 10–12
estimation 34, 78, 323
methods 112
output 32–3, 78
sampling 1, 34, 39–41, 55, 60, 95, 201,
203, 253, 394
sampling algorithms 6–10
simulation 34
techniques 2–4
Monte Carlo parallel sampling 58
mood change 356–8
Moran I statistic 283
mortality in Birmingham 307–8
420
INDEX

multicategory data, level of observation
and relations between categories
197–8
multicategory outcomes
latent variable models for
197–234
random effect for 197–234
multidimensional integration 30
multilevel models, priors in 22
multimodel perspectives via parallel
sampling 42–6
multinomial densities 204
multinomial–Dirichlet model and
extensions 219–21
multinomial–Dirichlet structure 224
multinomial extra variation 221–6
multinomial logit model (MNL) 201,
204–5, 210–16, 219
Poisson regression approach to 207–8
multinomial logit occupational choice
207
multinomial models
for aggregated data 202–10
for individual data, modelling choices
198–201
multinomial–Poisson equivalence 204–5
multinomial probability vector 384
multinomial probit 210–13, 328–9
heterogeneity in 212
multinomial probit model (MNP) 201, 210,
212–13, 219
multinomial sampling 203
multiparameter coefﬁcients 60
multiparameter updating 9
multiple binary outcomes 180
multiple imputation (MI) method 380,
391–3
multiple logit model 202
multiple logit speciﬁcations 297
multiple random effects 29
models 20
multivariate count data 183
multivariate density 9, 216
multivariate generalization 87
multivariate linear spline analysis 92
multivariate logit model 181–2
multivariate logit regression 178
multivariate longitudinal data 353
multivariate normal (MVN) linear
regression 211
multivariate normal (MVN) model 183,
217–18, 222, 225, 353, 368
multivariate normal (MVN) prior 225–6,
323, 326
multivariate ordered outcomes 258–63
multivariate outcomes 177–89
multivariate panel data 352–8
multivariate Poisson data 182–9
multivariate prior density 323
multivariate probit model 178
multivariate spatial priors 275–7
multivariate T model (MVT) model 226
national crime survey data 400, 402–3
nausea and cisplatin 249–50
Newton–Raphson iteration 16
nodal involvement, logit regression of
127–8
non-ignorable missingness 381–2
non-ignorable non-response models for
survey tabulations 397–409
non-linear predictor effects 213–15
non-linear regression effects via splines
and other basis functions 82–94
non-linearity approaches 144–8
non-parametric approach 248
non-parametric functions 99
non-parametric mixtures 273
non-parametric model 243
non-parametric ordinal regression 243–5
non-proportional model 236, 263
non-proportionality 238
non-zero functions 89
NORC sexual attitudes data 262–3
normal linear model 13–17
observation-driven dependence 291–300
observation-driven models for individual
multicategory data 297–8
observation-speciﬁc variance 68
Occam’s razor 44
occupational attainment 205–8, 214–15
occupational mobility 198
occurrences–trials data 156, 159
odds ratio 180–2, 225
offset 116
INDEX
421

ordinal data models 235–6
ordinal data time-series-varying
coefﬁecient regression models 302
ordinal dependent variables 235
ordinal regression 235–66
ordinal regression model 247
ordinality 243–5
out-of-sample cross-validation 39–41
out-of-sample predictions 41
outlier assessment via CPOs 349
outlier detection
and model checks 125–30
under data augmentation 129
outlier resistance 164
outliers
association model with 257–8
impact of 68
overdispersion 155–7, 161, 164, 183, 221,
226, 267, 290, 301, 311
panel analysis, robustness in 358–62
panel data
autocorrelation in 342
general linear mixed model (GLMM)
for 336–46
models 321–78
panel studies 393
parallel sampling 45, 62, 80, 127–8
model probability estimates from 46–9
multimodel perspectives via 42–6
parameter-driven dependence
via autocorrelated error models 309–11
via DLMs 300–8
parental style and political afﬁliation
209–10
parsimonious missingness models 389
parsimonious models 298, 389
parsimony 135
partial proportional model 236
path sampling method 58, 127–8
pattern mixture model 382, 384
penalized deviances from Bayes
perspective 41–2
penalized likelihood criterion 44
penalized random effects for spline
coefﬁcients 85–6
penalized spline for light detection and
ranging (LIDAR) 93–4
pneumoconiosis symptoms 184
Poisson age–cohort model 364
Poisson data 114–115, 124, 133–4, 157,
204, 255, 292, 365
Poisson exponentially weighted moving
average model (PEWMA) 304
Poisson–gamma likelihood 158
Poisson–gamma mixture 161
Poisson–gamma models 164
Poisson HMM 314–15
Poisson likelihood 114
Poisson log-linear regression model 205
Poisson log-normal model 185
Poisson mean 156
Poisson model 8, 169
generalization 155–7
Poisson overdispersion 164
Poisson rates 116
Poisson regression 21, 117, 132–3, 136,
161, 164, 176–7, 204
approach to MNL model 207–8
Poisson time series regression 295
posterior density 115, 118
posterior knot density 90
posterior mean 118
posterior model probability 12, 60, 126
posterior predictive checks 37–9
posterior predictive density 36
posterior probability 3, 82, 91, 128, 167
predictive cross-validation 35, 126–7
predictive density 3, 80, 82
predictive error sum of squares 36, 93
predictive loss criteria 37, 126
predictive model choice and checking
35–7, 126–30
predictive replicates 37–9
predictor selection
averaging based on 59–65
in binary and count regression 130–3
predictors
regression applications with 76
with missing values 387–91
prior assumptions, sensitivity 22
prior interdependence 56
prior model probabilities 58, 81
prior ordinates 49
prior probability 59, 258
prior structures 135
422
INDEX

prior uncertainty 21
priors 12–13, 49
for linear regression model 55–9
for regression coefﬁcients 135
in multilevel models 22
in normal linear model 56
sensitivity analysis 13
speciﬁcation 116
probit models 172, 198
probit regression 125, 129–30
model 171
product multinomial analysis 203
product multinomial sampling 204
proportional cumulative odds model 237
proportional non-parametric model 245
proportional odds 236, 243
proportional semi-parametric model 245
proposal density 6–7, 9
protozoa mortality 166–7
pseudo Bayes factor (PsBF) 41, 58
pseudo marginal likelihood (PsML) 40,
57–8, 127, 283
pseudo-priors 47
psychiatric study, missingness model 409
pure multinomial logit model 200, 205
puromycin experiment 69–71
purse snatchings in Chicago 306–7,
310–11, 313, 315
Q–Q plot 285
quadratic spline 143
Quebec accident data 224–5
radiata pines 57–9
rainfall data, Madison, Wisconsin 296
random effects 20, 38, 74–5, 116, 135, 178
cluster-speciﬁc 322–3
for crossed factors 333–6
for multicategory outcomes 197–234
in hierarchical models 22
in MNL models 198, 327
in models 44
in spatial data 267
speciﬁc to area and time 366
unstructured 271
random subject intercept MNL model 327
random variation 15–16
random walk 292
ﬁrst- and second-order 99
priors 99, 338
Rasch Poisson count model 347
receiver–operator curves (ROCs) 247
recreation trips data 170–1
reference distribution 38
reference priors 55
regression applications with predictors 76
regression coefﬁcients 200, 354
prior for 135
regression effects under factor regression
model 187
regression errors 68, 73
regression models 13–14, 49
choice of 59–65
for metric outcomes 55–111
relative risks 140
REM sleep 302, 305–6
residential mobility 198
respiratory symptoms in Ohio children
342–4
reversible jump MCMC 85
right-skewed extreme value (RSEV) 239,
241
risk factors 140, 267
robust models for cancer deaths in
Glasgow 275
robust regression 143–4
Bayesian methods for 67
robust regression methods
models for outliers 67–71
models for skewness and
heteroscedasticity 71–5
robust spatial regression models 282
robustness 21–3, 155–7, 238
in clustered panel data analysis 358–62
in panel analysis 358–62
spatial 273–5
via discrete mixture models 75–81
sampling-based techniques 1
SAT score 240
saturated model 134
scale mixture 68, 70, 223
generalization 172
scale weights 130
scaled likelihoods 49–50
scaling parameter 74
INDEX
423

schizophrenia collaborative
study 383–4
second-order interaction splines 88
second-order interactions 60
second-order random walk 245
seizure data in epileptic patients 349
self-assessed health application 253–4
semi-parametric regression
models 140–8
sensitivity 21–3
sensitivity analysis, priors 13
sensory evaluation of entres in army meals
254–5
sexual attitudes data 262–3
shrinkage factor 115, 158
side effects, missingness patterns 407
simulated regression with Student t
errors 69
skewed normal model 71
skills rating scale 73
smoothing variance 142
smoothness priors 100–5
social attitudes 261–2
social classes voting 406
space–time models 364–71
spatial APC models 364–71
spatial data, random effects in 267
spatial epidemiology 279
applications 267
mixed model in 41
spatial expansion model 279
spatial factor 278
approach to spatially varying
coefﬁcients 281
spatial heterogeneity 279
spatial interaction effects 274
spatial regression coefﬁcients 280
spatial robustness 273–5
spatio-temporal models 362–4
special spline functions 87–94
spline coefﬁcients, penalized random
effects for 85–6
spline functions 83
spline models 142
splines and other basis functions, nonlinear
regression effects via 82–94
static expiratory pressure in cystic ﬁbrosis
101–2
statistics student grades 240–1
stochastic search variable selecton (SSVS)
method 61
strikes and output 295–6
structural equation models 20
structured interactions 135
student grades 240–1
student interview data 73–5
Student t density 19, 68, 72, 155
Student t distribution 222–3
Student t errors, simulated regression
with 69
Student t model 359
Student t parameters 69
Student t prior 23
subject-speciﬁc variance–mean ratio 347
subject–time ordinal response 384
suicide
in England 160–1
in English local authorities 132–3
in English males 369–71
in London 260–1
risk factors, varying effect of 283–5
survey tabulations, non-ignorable non-
response models for 397–409
thromboembolism data 139–40
time dependence 338–40
in observations and latent
data 289–91
time–period interactions 366
time series
aggregate multinomial data 298–300
methods 11
models for discrete variables 289–319
time-speciﬁc variance–mean ratio 347
titanium as function of heat 89–91
toxoplasmosis data, double-binomial
analysis 162
transition matrix 142
travel mode choice 217–19
truncated power splines 86
truncated univariate normal
sampling 179
turnip green, vitamin B2 content in 91
two-parameter exponential family 163
two-sided cubic spline model 84
two-stage priors 135
424
INDEX

uniform prior 22–3, 55–6
union membership and wages 146–7
univariate normal prior 61
univariate reponses 268–73
utility function 199
variable selection methodology 136
variance function 158
varying predictor effect models 279–84
visual impairment 188–9
vitamin B2 content in turnip green 91
voting intentions in Canada 344–6
Whistlestop intervention coefﬁcient 311
WINBUGS 13, 49, 58, 305
wine bitterness, clustered ordinal data
analysis 331–3
Wishart prior 208, 323, 384
zero-inﬂated (ZIP) models 167–71
Index compiled by Geoffrey Jones
INDEX
425


WILEY SERIES IN PROBABILITY AND STATISTICS
ESTABLISHED BY WALTER A. SHEWHART AND SAMUEL S. WILKS
Editors
David J. Balding, Peter Bloomﬁeld, Noel A. C. Cressie, Nicholas I. Fisher,
Iain M. Johnstone, J. B. Kadane, Geert Molenberghs, Louise M. Ryan,
David W. Scott, Adrian F. M. Smith, Jozef L. Teugels
Editors Emeriti
Vic Barnett, J. Stuart Hunter, David G. Kendall
The Wiley Series in Probability and Statistics is well established and authoritative. It covers
many topics of current research interest in both pure and applied statistics and probability theory.
Written by leading statisticians and institutions, the titles span both state-of-the-art developments in
the ﬁeld and classical methods.
Reﬂecting the wide range of current research in statistics, the series encompasses applied,
methodological and theoretical statistics, ranging from applications and new techniques made
possible by advances in computerized practice to rigorous treatment of theoretical approaches.
This series provides essential and invaluable reading for all statisticians, whether in academia,
industry, government, or research.
ABRAHAM and LEDOLTER  Statistical Methods for Forecasting
AGRESTI  Analysis of Ordinal Categorical Data
AGRESTI  An Introduction to Categorical Data Analysis
AGRESTI  Categorical Data Analysis, Second Edition
ALTMAN, GILL, and McDONALD  Numerical Issues in Statistical Computing for the Social
Scientist
AMARATUNGA and CABRERA  Exploration and Analysis of DNA Microarray and Protein Array
Data
AND
EL  Mathematics of Chance
ANDERSON  An Introduction to Multivariate Statistical Analysis, Third Edition
*ANDERSON  The Statistical Analysis of Time Series
ANDERSON, AUQUIER, HAUCK, OAKES, VANDAELE, and WEISBERG  Statistical Methods
for Comparative Studies
ANDERSON and LOYNES  The Teaching of Practical Statistics
ARMITAGE and DAVID (editors)  Advances in Biometry
ARNOLD, BALAKRISHNAN, and NAGARAJA  Records
*ARTHANARI and DODGE  Mathematical Programming in Statistics
*BAILEY  The Elements of Stochastic Processes with Applications to the Natural Sciences
BALAKRISHNAN and KOUTRAS  Runs and Scans with Applications
BARNETT  Comparative Statistical Inference, Third Edition
BARNETT  Environmental Statistics: Methods & Applications
BARNETT and LEWIS  Outliers in Statistical Data, Third Edition
BARTOSZYNSKI and NIEWIADOMSKA-BUGAJ  Probability and Statistical Inference
BASILEVSKY  Statistical Factor Analysis and Related Methods: Theory and Applications
BASU and RIGDON  Statistical Methods for the Reliability of Repairable Systems
BATES and WATTS  Nonlinear Regression Analysis and Its Applications
BECHHOFER, SANTNER, and GOLDSMAN  Design and Analysis of Experiments for Statistical
Selection, Screening, and Multiple Comparisons
BELSLEY  Conditioning Diagnostics: Collinearity and Weak Data in Regression
*Now available in a lower priced paperback edition in the Wiley Classics Library.

BELSLEY, KUH, and WELSCH  Regression Diagnostics: Identifying Inﬂuential Data and
Sources of Collinearity
BENDAT and PIERSOL  Random Data: Analysis and Measurement Procedures, Third Edition
BERNARDO and SMITH  Bayesian Theory
BERRY, CHALONER, and GEWEKE  Bayesian Analysis in Statistics and
Econometrics: Essays in Honor of Arnold Zellner
BHAT and MILLER  Elements of Applied Stochastic Processes, Third Edition
BHATTACHARYA and JOHNSON  Statistical Concepts and Methods
BHATTACHARYA and WAYMIRE  Stochastic Processes with Applications
BILLINGSLEY  Convergence of Probability Measures, Second Edition
BILLINGSLEY  Probability and Measure, Third Edition
BIRKES and DODGE  Alternative Methods of Regression
BLISCHKE and MURTHY (editors)  Case Studies in Reliability and Maintenance
BLISCHKE and MURTHY  Reliability: Modeling, Prediction, and Optimization
BLOOMFIELD  Fourier Analysis of Time Series: An Introduction, Second Edition
BOLLEN  Structural Equations with Latent Variables
BOROVKOV  Ergodicity and Stability of Stochastic Processes
BOULEAU  Numerical Methods for Stochastic Processes
BOX  Bayesian Inference in Statistical Analysis
BOX  R. A. Fisher, the Life of a Scientist
BOX and DRAPER  Empirical Model-Building and Response Surfaces
*BOX and DRAPER  Evolutionary Operation: A Statistical Method for Process
Improvement
BOX, HUNTER, and HUNTER  Statistics for Experimenters: An Introduction to
Design, Data Analysis, and Model Building
BOX and LUCEN˜ O  Statistical Control by Monitoring and Feedback Adjustment
BRANDIMARTE  Numerical Methods in Finance: A MATLAB-Based Introduction
BROWN and HOLLANDER  Statistics: A Biomedical Introduction
BRUNNER, DOMHOF, and LANGER  Nonparametric Analysis of Longitudinal Data in
Factorial Experiments
BUCKLEW  Large Deviation Techniques in Decision, Simulation, and Estimation
CAIROLI and DALANG  Sequential Stochastic Optimization
CHAN  Time Series: Applications to Finance
CHATTERJEE and HADI  Sensitivity Analysis in Linear Regression
CHATTERJEE and PRICE  Regression Analysis by Example, Third Edition
CHERNICK  Bootstrap Methods: A Practitioner’s Guide
CHERNICK and FRIIS  Introductory Biostatistics for the Health Sciences
CHILE`S and DELFINER  Geostatistics: Modeling Spatial Uncertainty
CHOW and LIU  Design and Analysis of Clinical Trials: Concepts and Methodologies, Second
Edition
CLARKE and DISNEY  Probability and Random Processes: A First Course with Applications,
Second Edition
*COCHRAN and COX  Experimental Designs, Second Edition
CONGDON  Applied Bayesian Modelling
CONGDON  Bayesian Statistical Modelling
CONGDON  Bayesian Models for Categorical Data
CONOVER  Practical Nonparametric Statistics, Second Edition
COOK  Regression Graphics
COOK and WEISBERG  Applied Regression Including Computing and Graphics
COOK and WEISBERG  An Introduction to Regression Graphics
CORNELL  Experiments with Mixtures, Designs, Models, and the Analysis of Mixture Data,
Third Edition
*Now available in a lower priced paperback edition in the Wiley Classics Library.

COVER and THOMAS  Elements of Information Theory
COX  A Handbook of Introductory Statistical Methods
*COX  Planning of Experiments
CRESSIE  Statistics for Spatial Data, Revised Edition
CSO¨ RGO¨ and HORVA´ TH  Limit Theorems in Change Point Analysis
DANIEL  Applications of Statistics to Industrial Experimentation
DANIEL  Biostatistics: A Foundation for Analysis in the Health Sciences, Sixth Edition
*DANIEL  Fitting Equations to Data: Computer Analysis of Multifactor Data, Second Edition
DASU and JOHNSON  Exploratory Data Mining and Data Cleaning
DAVID and NAGARAJA  Order Statistics, Third Edition
*DEGROOT, FIENBERG, and KADANE  Statistics and the Law
DEL CASTILLO  Statistical Process Adjustment for Quality Control
DENISON, HOLMES, MALLICK, and SMITH  Bayesian Methods for Nonlinear Classiﬁcation
and Regression
DETTE and STUDDEN  The Theory of Canonical Moments with Applications in
Statistics, Probability, and Analysis
DEY and MUKERJEE  Fractional Factorial Plans
DILLON and GOLDSTEIN  Multivariate Analysis: Methods and Applications
DODGE  Alternative Methods of Regression
*DODGE and ROMIG  Sampling Inspection Tables, Second Edition
*DOOB  Stochastic Processes
DOWDY and WEARDEN, and CHILKO  Statistics for Research, Third Edition
DRAPER and SMITH  Applied Regression Analysis, Third Edition
DRYDEN and MARDIA  Statistical Shape Analysis
DUDEWICZ and MISHRA  Modern Mathematical Statistics
DUNN and CLARK  Applied Statistics: Analysis of Variance and Regression, Second Edition
DUNN and CLARK  Basic Statistics: A Primer for the Biomedical Sciences, Third Edition
DUPUIS and ELLIS  A Weak Convergence Approach to the Theory of Large Deviations
EDLER and KITSOS (editors)  Recent Advances in Quantitative Methods in Cancer and Human
Health Risk Assessment
*ELANDT-JOHNSON and JOHNSON  Survival Models and Data Analysis
ENDERS  Applied Econometric Time Series
ETHIER and KURTZ  Markov Processes: Characterization and Convergence
EVANS, HASTINGS, and PEACOCK  Statistical Distributions, Third Edition
FELLER  An Introduction to Probability Theory and Its Applications, Volume I, Third Edition,
Revised; Volume II, Second Edition
FISHER and VAN BELLE  Biostatistics: A Methodology for the Health Sciences
*FLEISS  The Design and Analysis of Clinical Experiments
FLEISS  Statistical Methods for Rates and Proportions, Second Edition
FLEMING and HARRINGTON  Counting Processes and Survival Analysis
FULLER  Introduction to Statistical Time Series, Second Edition
FULLER  Measurement Error Models
GALLANT  Nonlinear Statistical Models
GELMAN and MENG (editors): Applied Bayesian Modeling and Casual Inference from
Incomplete-data Perspectives
GHOSH, MUKHOPADHYAY, and SEN  Sequential Estimation
GIESBRECHT and GUMPERTZ  Planning, Construction, and Statistical Analysis of Comparative
Experiments
GIFI  Nonlinear Multivariate Analysis
GLASSERMAN and YAO  Monotone Structure in Discrete-Event Systems
GNANADESIKAN  Methods for Statistical Data Analysis of Multivariate Observations,
Second Edition
*Now available in a lower priced paperback edition in the Wiley Classics Library.

GOLDSTEIN and LEWIS  Assessment: Problems, Development, and Statistical Issues
GREENWOOD and NIKULIN  A Guide to Chi-Squared Testing
GROSS and HARRIS  Fundamentals of Queueing Theory, Third Edition
*HAHN and SHAPIRO  Statistical Models in Engineering
HAHN and MEEKER  Statistical Intervals: A Guide for Practitioners
HALD  A History of Probability and Statistics and their Applications Before 1750
HALD  A History of Mathematical Statistics from 1750 to 1930
HAMPEL  Robust Statistics: The Approach Based on Inﬂuence Functions
HANNAN and DEISTLER  The Statistical Theory of Linear Systems
HEIBERGER  Computation for the Analysis of Designed Experiments
HEDAYAT and SINHA  Design and Inference in Finite Population Sampling
HELLER  MACSYMA for Statisticians
HINKELMAN and KEMPTHORNE:  Design and Analysis of Experiments, Volume 1:
Introduction to Experimental Design
HOAGLIN, MOSTELLER, and TUKEY  Exploratory Approach to Analysis of Variance
HOAGLIN, MOSTELLER, and TUKEY  Exploring Data Tables, Trends and Shapes
*HOAGLIN, MOSTELLER, and TUKEY  Understanding Robust and Exploratory Data Analysis
HOCHBERG and TAMHANE  Multiple Comparison Procedures
HOCKING  Methods and Applications of Linear Models: Regression and the Analysis of Variance,
Second Edition
HOEL  Introduction to Mathematical Statistics, Fifth Edition
HOGG and KLUGMAN  Loss Distributions
HOLLANDER and WOLFE  Nonparametric Statistical Methods, Second Edition
HOSMER and LEMESHOW  Applied Logistic Regression, Second Edition
HOSMER and LEMESHOW  Applied Survival Analysis: Regression Modeling of
Time to Event Data
HUBER  Robust Statistics
HUBERTY  Applied Discriminant Analysis
HUNT and KENNEDY  Financial Derivatives in Theory and Practice, Revised Edition
HUSKOVA, BERAN, and DUPAC  Collected Works of Jaroslav Hajek—with
Commentary
IMAN and CONOVER  A Modern Approach to Statistics
JACKSON  A User’s Guide to Principle Components
JOHN  Statistical Methods in Engineering and Quality Assurance
JOHNSON  Multivariate Statistical Simulation
JOHNSON and BALAKRISHNAN  Advances in the Theory and Practice of Statistics: A
Volume in Honor of Samuel Kotz
JUDGE, GRIFFITHS, HILL, LU¨ TKEPOHL, and LEE  The Theory and Practice of
Econometrics, Second Edition
JOHNSON and KOTZ  Distributions in Statistics
JOHNSON and KOTZ (editors)  Leading Personalities in Statistical Sciences: From the
Seventeenth Century to the Present
JOHNSON, KOTZ, and BALAKRISHNAN  Continuous Univariate Distributions,
Volume 1, Second Edition
JOHNSON, KOTZ, and BALAKRISHNAN  Continuous Univariate Distributions,
Volume 2, Second Edition
JOHNSON, KOTZ, and BALAKRISHNAN  Discrete Multivariate Distributions
JOHNSON, KOTZ, and KEMP  Univariate Discrete Distributions, Second Edition
JURECˇ KOVA´ and SEN  Robust Statistical Procedures: Asymptotics and Interrelations
JUREK and MASON  Operator-Limit Distributions in Probability Theory
KADANE  Bayesian Methods and Ethics in a Clinical Trial Design
*Now available in a lower priced paperback edition in the Wiley Classics Library.

KADANE and SCHUM  A Probabilistic Analysis of the Sacco and Vanzetti Evidence
KALBFLEISCH and PRENTICE  The Statistical Analysis of Failure Time Data,
Second Edition
KARIYA and KURATA  Generalized Least Squares
KASS and VOS  Geometrical Foundations of Asymptotic Inference
KAUFMAN and ROUSSEEUW  Finding Groups in Data: An Introduction to Cluster Analysis
KEDEM and FOKIANOS  Regression Models for Time Series Analysis
KENDALL, BARDEN, CARNE, and LE  Shape and Shape Theory
KHURI  Advanced Calculus with Applications in Statistics, Second Edition
KHURI, MATHEW, and SINHA  Statistical Tests for Mixed Linear Models
KLEIBER and KOTZ  Statistical Size Distributions in Economics and Actuarial Sciences
KLUGMAN, PANJER, and WILLMOT  Loss Models: From Data to Decisions
KLUGMAN, PANJER, and WILLMOT  Solutions Manual to Accompany Loss Models:
From Data to Decisions
KOTZ, BALAKRISHNAN, and JOHNSON  Continuous Multivariate Distributions,
Volume 1, Second Edition
KOTZ and JOHNSON (editors)  Encyclopedia of Statistical Sciences: Volumes 1 to 9
with Index
KOTZ and JOHNSON (editors)  Encyclopedia of Statistical Sciences: Supplement Volume
KOTZ, READ, and BANKS (editors)  Encyclopedia of Statistical Sciences: Update Volume 1
KOTZ, READ, and BANKS (editors)  Encyclopedia of Statistical Sciences: Update Volume 2
KOVALENKO, KUZNETZOV, and PEGG  Mathematical Theory of Reliability of
Time-Dependent Systems with Practical Applications
LACHIN  Biostatistical Methods: The Assessment of Relative Risks
LAD  Operational Subjective Statistical Methods: A Mathematical, Philosophical, and
Historical Introduction
LAMPERTI  Probability: A Survey of the Mathematical Theory, Second Edition
LANGE, RYAN, BILLARD, BRILLINGER, CONQUEST, and GREENHOUSE 
Case Studies in Biometry
LARSON  Introduction to Probability Theory and Statistical Inference, Third Edition
LAWLESS  Statistical Models and Methods for Lifetime Data, Second Edition
LAWSON  Statistical Methods in Spatial Epidemiology
LE  Applied Categorical Data Analysis
LE  Applied Survival Analysis
LEE and WANG  Statistical Methods for Survival Data Analysis, Third Edition
LEPAGE and BILLARD  Exploring the Limits of Bootstrap
LEYLAND and GOLDSTEIN (editors)  Multilevel Modelling of Health Statistics
LIAO  Statistical Group Comparison
LINDVALL  Lectures on the Coupling Method
LINHART and ZUCCHINI  Model Selection
LITTLE and RUBIN  Statistical Analysis with Missing Data, Second Edition
LLOYD  The Statistical Analysis of Categorical Data
MAGNUS and NEUDECKER  Matrix Differential Calculus with Applications in
Statistics and Econometrics, Revised Edition
MALLER and ZHOU  Survival Analysis with Long Term Survivors
MALLOWS  Design, Data, and Analysis by Some Friends of Cuthbert Daniel
MANN, SCHAFER, and SINGPURWALLA  Methods for Statistical Analysis of
Reliability and Life Data
MANTON, WOODBURY, and TOLLEY  Statistical Applications Using Fuzzy Sets
MARCHETTE  Random Graphs for Statistical Pattern Recognition
MARDIA and JUPP  Directional Statistics
*Now available in a lower priced paperback edition in the Wiley Classics Library.

MASON, GUNST, and HESS  Statistical Design and Analysis of Experiments with
Applications to Engineering and Science, Second Edition
MCCULLOCH and SEARLE  Generalized, Linear, and Mixed Models
MCFADDEN  Management of Data in Clinical Trials
MCLACHLAN  Discriminant Analysis and Statistical Pattern Recognition
MCLACHLAN and KRISHNAN  The EM Algorithm and Extensions
MCLACHLAN and PEEL  Finite Mixture Models
MCNEIL  Epidemiological Research Methods
MEEKER and ESCOBAR  Statistical Methods for Reliability Data
MEERSCHAERT and SCHEFFLER  Limit Distributions for Sums of Independent
Random Vectors: Heavy Tails in Theory and Practice
*MILLER  Survival Analysis, Second Edition
MONTGOMERY, PECK, and VINING  Introduction to Linear Regression Analysis,
Third Edition
MORGENTHALER and TUKEY  Conﬁgural Polysampling: A Route to Practical
Robustness
MUIRHEAD  Aspects of Multivariate Statistical Theory
MURRAY  X-STAT 2.0 Statistical Experimentation, Design Data Analysis, and
Nonlinear Optimization
MURTHY, XIE, and JIANG  Weibull Models
MYERS and MONTGOMERY  Response Surface Methodology: Process and Product
Optimization Using Designed Experiments, Second Edition
MYERS, MONTGOMERY, and VINING  Generalized Linear Models. With
Applications in Engineering and the Sciences
NELSON  Accelerated Testing, Statistical Models, Test Plans, and Data Analyses
NELSON  Applied Life Data Analysis
NEWMAN  Biostatistical Methods in Epidemiology
OCHI  Applied Probability and Stochastic Processes in Engineering and Physical Sciences
OKABE, BOOTS, SUGIHARA, and CHIU  Spatial Tesselations: Concepts and
Applications of Voronoi Diagrams, Second Edition
OLIVER and SMITH  Inﬂuence Diagrams, Belief Nets and Decision Analysis
PALTA  Quantitative Methods in Population Health: Extensions of Ordinary Regressions
PANKRATZ  Forecasting with Dynamic Regression Models
PANKRATZ  Forecasting with Univariate Box-Jenkins Models: Concepts and Cases
*PARZEN  Modern Probability Theory and It’s Applications
PE~NA, TIAO, and TSAY  A Course in Time Series Analysis
PIANTADOSI  Clinical Trials: A Methodologic Perspective
PORT  Theoretical Probability for Applications
POURAHMADI  Foundations of Time Series Analysis and Prediction Theory
PRESS  Bayesian Statistics: Principles, Models, and Applications
PRESS  Subjective and Objective Bayesian Statistics, Second Edition
PRESS and TANUR  The Subjectivity of Scientists and the Bayesian Approach
PUKELSHEIM  Optimal Experimental Design
PURI, VILAPLANA, and WERTZ  New Perspectives in Theoretical and Applied Statistics
PUTERMAN  Markov Decision Processes: Discrete Stochastic Dynamic Programming
*RAO  Linear Statistical Inference and Its Applications, Second Edition
RAUSAND and HØYLAND  System Reliability Theory: Models, Statistical Methods and
Applications, Second Edition
RENCHER  Linear Models in Statistics
RENCHER  Methods of Multivariate Analysis, Second Edition
RENCHER  Multivariate Statistical Inference with Applications
*Now available in a lower priced paperback edition in the Wiley Classics Library.

RIPLEY  Spatial Statistics
RIPLEY  Stochastic Simulation
ROBINSON  Practical Strategies for Experimenting
ROHATGI and SALEH  An Introduction to Probability and Statistics, Second Edition
ROLSKI, SCHMIDLI, SCHMIDT, and TEUGELS  Stochastic Processes for Insurance and Finance
ROSENBERGER and LACHIN  Randomization in Clinical Trials: Theory and Practice
ROSS  Introduction to Probability and Statistics for Engineers and Scientists
ROUSSEEUW and LEROY  Robust Regression and Outlier Detection
RUBIN  Multiple Imputation for Nonresponse in Surveys
RUBINSTEIN  Simulation and the Monte Carlo Method
RUBINSTEIN and MELAMED  Modern Simulation and Modeling
RYAN  Modern Regression Methods
RYAN  Statistical Methods for Quality Improvement, Second Edition
SALTELLI, CHAN, and SCOTT (editors)  Sensitivity Analysis
*SCHEFFE  The Analysis of Variance
SCHIMEK  Smoothing and Regression: Approaches, Computation, and Application
SCHOTT  Matrix Analysis for Statistics
SCHOUTENS  Levy Processes in Finance: Pricing Financial Derivatives
SCHUSS  Theory and Applications of Stochastic Differential Equations
SCOTT  Multivariate Density Estimation: Theory, Practice, and Visualization
*SEARLE  Linear Models
SEARLE  Linear Models for Unbalanced Data
SEARLE  Matrix Algebra Useful for Statistics
SEARLE, CASELLA, and McCULLOCH  Variance Components
SEARLE and WILLETT  Matrix Algebra for Applied Economics
SEBER  Multivariate Observations
SEBER and LEE  Linear Regression Analysis, Second Edition
SEBER and WILD  Nonlinear Regression
SENNOTT  Stochastic Dynamic Programming and the Control of Queueing Systems
*SERFLING  Approximation Theorems of Mathematical Statistics
SHAFER and VOVK  Probability and Finance: Its Only a Game!
SMALL and MCLEISH  Hilbert Space Methods in Probability and Statistical Inference
SRIVASTAVA  Methods of Multivariate Statistics
STAPLETON  Linear Statistical Models
STAUDTE and SHEATHER  Robust Estimation and Testing
STOYAN, KENDALL, and MECKE  Stochastic Geometry and Its Applications,
Second Edition
STOYAN and STOYAN  Fractals, Random Shapes and Point Fields: Methods of
Geometrical Statistics
STYAN  The Collected Papers of T. W. Anderson: 1943–1985
SUTTON, ABRAMS, JONES, SHELDON, and SONG  Methods for Meta-Analysis in
Medical Research
TANAKA  Time Series Analysis: Nonstationary and Noninvertible Distribution Theory
THOMPSON  Empirical Model Building
THOMPSON  Sampling, Second Edition
THOMPSON  Simulation: A Modeler’s Approach
THOMPSON and SEBER  Adaptive Sampling
THOMPSON, WILLIAMS, and FINDLAY  Models for Investors in Real World Markets
TIAO, BISGAARD, HILL, PE~NA, and STIGLER (editors)  Box on Quality and
Discovery: with Design, Control, and Robustness
*Now available in a lower priced paperback edition in the Wiley Classics Library.

TIERNEY  LISP-STAT: An Object-Oriented Environment for Statistical Computing and
Dynamic Graphics
TSAY  Analysis of Financial Time Series
UPTON and FINGLETON  Spatial Data Analysis by Example, Volume II:
Categorical and Directional Data
VAN BELLE  Statistical Rules of Thumb
VESTRUP  The Theory of Measures and Integration
VIDAKOVIC  Statistical Modeling by Wavelets
WEISBERG  Applied Linear Regression, Second Edition
WELSH  Aspects of Statistical Inference
WESTFALL and YOUNG  Resampling-Based Multiple Testing: Examples and
Methods for p-Value Adjustment
WHITTAKER  Graphical Models in Applied Multivariate Statistics
WINKER  Optimization Heuristics in Economics: Applications of Threshold Accepting
WONNACOTT and WONNACOTT  Econometrics, Second Edition
WOODING  Planning Pharmaceutical Clinical Trials: Basic Statistical Principles
WOOLSON and CLARKE  Statistical Methods for the Analysis of Biomedical Data,
Second Edition
WU and HAMADA  Experiments: Planning, Analysis, and Parameter Design Optimization
YANG  The Construction Theory of Denumerable Markov Processes
*ZELLNER  An Introduction to Bayesian Inference in Econometrics
ZELTERMAN  Discrete Distributions: Applications in the Health Sciences
ZHOU, OBUCHOWSKI, and McCLISH  Statistical Methods in Diagnostic Medicine
*Now available in a lower priced paperback edition in the Wiley Classics Library.

