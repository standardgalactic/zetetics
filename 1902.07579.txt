Emulating Human Developmental Stages with Bayesian Neural Networks
Marcel Binz (binz@staff.uni-marburg.de)
Department of Psychology, Theoretical Neuroscience Group
Philipps-Universit¨at Marburg
Dominik Endres (dominik.endres@staff.uni-marburg.de)
Department of Psychology, Theoretical Neuroscience Group
Philipps-Universit¨at Marburg
Abstract
We compare the acquisition of knowledge in humans and ma-
chines. Research from the ﬁeld of developmental psychology
indicates, that human-employed hypothesis are initially guided
by simple rules, before evolving into more complex theories.
This observation is shared across many tasks and domains. We
investigate whether stages of development in artiﬁcial learning
systems are based on the same characteristics. We operational-
ize developmental stages as the size of the data-set, on which
the artiﬁcial system is trained. For our analysis we look at the
developmental progress of Bayesian Neural Networks on three
different data-sets, including occlusion, support and quantity
comparison tasks. We compare the results with prior research
from developmental psychology and ﬁnd agreement between
the family of optimized models and pattern of development
observed in infants and children on all three tasks, indicating
common principles for the acquisition of knowledge.
Keywords: Core knowledge; developmental psychology; in-
tuitive physics; approximate number system; machine learn-
ing, deep learning, variational inference, normative models
Introduction
The theory of core knowledge in developmental psychology
identiﬁes several domains, that build the foundations of
human cognition (Spelke & Kinzler, 2007; Lake, Ullman,
Tenenbaum, & Gershman, 2017). Typically physics, actions,
numbers, space and social interactions are listed among the
core domains. Knowledge in these areas is present starting
from early stages of childhood and serves as the basis
for learning during later life.
Research in developmental
psychology over the past decades equipped us with a solid
understanding about the acquisition of such knowledge.
Different stages of development have been identiﬁed for a
wide range of phenomena. Insights across studies suggest,
that established rules generally start with a simple hypothesis
before becoming more sophisticated over time (Baillargeon,
2002).
We investigate whether current machine learning systems
show generalization behavior reminiscent of human infants
and children at different stages of development.
For this
purpose, we assume that the amount of data available to
the learning algorithm is proportional to human age.
The
class of models we focus on are Bayesian Neural Networks
(BNNs), that are trained through variational inference.
Neural networks have the desirable property of being able
to approximate an arbitrary complex mapping given enough
capacity,
while Bayesian inference captures normative
principles of how to update an initial belief in the light of
new evidence. The speciﬁc choice of variational inference
and neural networks is mainly due to convenience reasons,
and we hypothesize, that many different combinations of
universal function approximators and Bayesian learning
would lead to comparable results.
Our experiments focus on two of the established core
domains: physics and numbers.
We consider two experi-
ments involving intuitive reasoning about the laws of physics
(Baillargeon, 2002) and one examining the approximate
number system, which is responsible for forming fast,
but imprecise, representations of quantities (Halberda &
Feigenson, 2008). In all three cases we observe pattern in our
models, that share similarities with the development progress
during childhood, as we increase the data-set size.
There has been a recent interest in replicating reasoning
capabilities from the core domains in artiﬁcial systems. Prior
work regarding intuitive physics has considered generative
(Battaglia, Hamrick, & Tenenbaum, 2013; Chang, Ullman,
Torralba, & Tenenbaum, 2016) as well as discriminative
models (Lerer, Gross, & Fergus, 2016). Both classes of mod-
els are often able to reach performance levels comparable to
those of adults on speciﬁc tasks. Another core domain, that
has received some attention within the computational mod-
elling community, is the one of intuitive psychology. Here,
for example, Baker, Saxe, and Tenenbaum (2009) suggest to
employ Bayesian inverse planning for inferring mental states
of other agents. In contrast to the aforementioned prior work,
we are interested in the differences between optimal models
for varying data-set sizes and how these differences compare
to observations made in developmental psychology. Existing
work on modelling the development of intuitive physics is
limited to descriptive models, such as list of rules (Siegler &
Chen, 1998) or decision trees (Baillargeon, Li, Ng, & Yuan,
2009). In contrast to this, our approach is based on normative
principles and we ask the question, whether observed stages
emerge naturally in complex artiﬁcial learning systems.
In the next section we provide a short technical overview
of neural networks and variational inference. This is followed
by a description of the three experiments under examination.
For each experiment we outline the given task, the empirical
observations made in the developmental psychology litera-
ture and how we construct an artiﬁcial data-set. We ﬁnally
arXiv:1902.07579v1  [cs.LG]  20 Feb 2019

provide a comparison between the developmental progress of
children at different ages and that of optimized models for
different data-set sizes. We conclude the article with a dis-
cussion of the obtained results and an outlook of the future
interaction between the areas of machine learning and devel-
opmental psychology.
Methods
Deep Learning
Neural networks are parametric function approximators, that
combine linear transformations W and non-linear activation
functions f in alternating fashion:
hl = fl

W⊤
l hl−1

where l ∈{1,...,L}. h0 corresponds to the input x and hL
to an estimate of the target ˆy. Parameters of the model are
commonly updated via gradient descent on a loss function,
usually some form of negative log-likelihood. The power of
neural networks stems from their ability to approximate any
continuous function on a compact subset of Rn.
Variational Inference
The task of learning model parameters W can also be stated
as a Bayesian inference problem:
p(W|D)
|
{z
}
posterior
=
likelihood
z
}|
{
p(y|X,W)
prior
z }| {
p(W)
p(y|X)
| {z }
evidence
(1)
for a given data set D = {(xi,yi)}N
i=1,
with inputs
X = {xi}N
i=1 and targets y = {yi}N
i=1. Bayes’ theorem deﬁnes
how we should update our beliefs as more information
becomes available.
As N →∞the inﬂuence of the prior
vanishes, while for N →0 we can only rely on prior assump-
tions.
In our context we assume that experience (i.e.
N)
increases with age and hence we use an approximation to
Equation 1 with data-sets of varying size to represent agents
of different age.
Equation 1 is in general hard to compute for models of
useful complexity.
Variational inference offers a tractable
approximation to Equation 1 (Hinton & Van Camp, 1993).
Let qφ(W) be a distribution with parameters φ, that approxi-
mates the true posterior p(W|D). Formulating the problem as
a minimization of the Kullback-Leibler (KL) divergence be-
tween qφ(W) and p(W|D) leads to the evidence lower bound
(ELBO):
L(φ) = Eqφ(W) [log p(y|X,W)]−KL(qφ(W)||p(W))
(2)
which can be maximized with respect to φ using standard
optimization techniques.
In order to be able to scale to large data-sets Equation 2 is
often approximated using batches B ⊆D of size M, with the
log-likelihood term being scaled appropriately:
log p(y|X,W) ≈N
M ∑
i∈B
log p(yi|Xi,W)
(3)
Note, that only the ﬁrst term of the ELBO depends on the
data-set size N, while the second term is independent of it.
Hence the divergence term will dominate for small data-sets,
leading to models that closely reﬂect our prior assumptions.
In this work we employ priors, that promote simple functions.
Therefore, our models are able to capture successively more
complex functions with increasing data-set size.
Implementational Details
All models consist of L = 3 layers with hidden layer sizes
|hl| = 256 and ELU activation functions (Clevert, Un-
terthiner, & Hochreiter, 2015), unless otherwise mentioned.
Inputs x correspond to ﬂattened images of the scene and tar-
gets y are dependent on the current task. We place a group
horseshoe prior, which can be viewed as a continuous re-
laxation of a spike-and-slab prior (Mitchell & Beauchamp,
1988), over all parameters:
s ∼C +(0,τ0);
˜zi ∼C +(0,1);
˜wij ∼N (0,1);
wij = ˜wij˜zis
and represent the approximate posterior qφ(W) through a
fully factorized distribution as proposed in (Louizos, Ullrich,
& Welling, 2017). The sparsity hyperparameter of the horse-
shoe prior is ﬁxed to τ0 = 10−5. During training we approxi-
mate the expectation of the log-likelihood term with a single
sample from qφ(W) and make use of the local reparametriza-
tion trick (Kingma, Salimans, & Welling, 2015). Gradient-
based optimization is performed using Adam (Kingma & Ba,
2014) with batches consisting of 64 samples. Results reported
after training correspond to a Monte-Carlo estimate using 100
samples from qφ(W).
Experiments
In this section we present an analysis of the proposed model
on three different tasks adopted from the developmental psy-
chology literature. The ﬁrst two tasks involve reasoning about
physical events (occlusion and support), while the last is con-
cerned with the intuitive representation of quantities.
For
each task we include a summary of empirical observations
made in children, alongside a comparison between these re-
sults and our models. Code for performing all experiments
and generating artiﬁcial data-sets is publicly available1.
Occlusion Events
The ﬁrst task under investigation is concerned with occlu-
sion events.
It is based on an experiment conducted by
1https://github.com/marcelbinz/Developmental
-Stages-of-BNNs

Original Task
Artiﬁcial Data
Results
256
512
1024
2048
4096
8192
0
10
20
30
40
50
60
70
80
Error (%)
2.5 month
3.0 month
3.5 month
baseline
everything removed
bottom removed
top removed
Figure 1: Visualization of the occlusion event experiment. Left: Schematic illustration of the original setup. Figure adopted
from (Baillargeon, 2002). Center: Examples from the artiﬁcial data-set. Right: Performance for models with access to
different amounts of data in the different conditions. Baseline indicates the chance for guessing randomly. Models discover
solutions in order of their difﬁculty (green →blue →red), which is in accordance with observations made in the developmental
psychology literature.
Baillargeon (2002). Each scene consists of a cylinder and a
screen in form of a rectangular plane. During experimental
manipulation the cylinder is moved back and forth behind
the screen, while parts of the screen are removed.
There
are three different experimental conditions, each differing
in which part of the screen is removed (top, bottom or
everything removed). A depiction of the setup is shown in
Figure 1 (left). We are interested in infants’ ability to judge,
whether the cylinder remains visible as it moves behind
the screen, which is measured via violation-of-expectation
methods (Baillargeon, Spelke, & Wasserman, 1985).
In
violation-of-expectation methods gazing times for physically
implausible events are measured. High gazing times for such
events indicate, that children are surprised by the observation,
which is interpreted as a violation of their expectation of
what should have happened.
Empirical evidence indicates, that infants form an initial
concept based on a behind/not-behind distinction starting
from the age of 2.5 months. At this stage they have learned,
that the cylinder remains visible while moving past the
screen, if the entire middle section of the screen is removed.
They do not expect the cylinder to be visible in the other
two conditions. This initial concept is reﬁned during later
stages of development. At the age of three months they also
predict to see parts of the cylinder, if only the bottom part of
the screen is removed. The knowledge of 3.5 months olds
additionally extends to screens with removed top fractions.
Note, that the last condition is more challenging compared
to the other two, as it involves a comparison of heights
between the cylinder and the lower connection of the screen
(if the connection height is lower than the cylinder, the
cylinder will be visible, otherwise it will not be visible).
Baillargeon et al.
conclude from these observations, that
infants start with initially simple rules about the laws of
physics
(behind/not-behind
distinction),
which
become
successively more sophisticated over time (reasoning about
relative heights).
We construct an artiﬁcial version of this task as follows.
Each input x corresponds to a 24 × 24 image with three
channels, containing segregated information about the ﬂoor,
the cylinder and the screen respectively. Input images show
an initial conﬁguration of the scene, in which the cylinder is
located on the left side of the screen. Each target y indicates
the visibility of the cylinder when passing behind the screen,
as it is moved towards the right side of the image. Cylinder
height and position, screen position and size and ﬂoor level
are determined randomly. We generate a training and test
set, each consisting of 10000 data-points. Figure 1 (center)
shows examples for each of the conditions. Both sets include
2000 images for each of the three condition, as well as 4000
baseline images (nothing of the screen is removed).
This
is to ensure, that both y = 0 (cylinder is visible) and y = 1
(cylinder is not visible) are represented in equal fractions, i.e.
the chance of guessing correctly is 50 percent.
We
train
otherwise
identical
models
for
N ∈
{256,512,1024,2048,8192}
until
convergence
and
re-
port results averaged over ten random seeds. The resulting
performances on the artiﬁcial data-set are visualized in
Figure 1 (right). We observe, that the percentage of incorrect
predictions, similar to the developmental progress in infants,
decreases ﬁrst in the easier conditions. The network is able
to predict visibility of the cylinder reliably (with less than ten
percent errors), if the entire middle section of the screen is
removed, for N larger than 512. For N larger than 4096 it is
additionally able to predict the correct targets, if the bottom
part is removed (corresponding to knowledge of a three
months old). This extends to the condition, in which the top

Original Task
Artiﬁcial Data
Results
top
side
amount
prop.
256
512
1024
2048
4096
8192
0
10
20
30
40
50
60
70
80
Error (%)
12.5 month
6.5 month
5.0 month
3.0 month
baseline
proportional
amount
side
top
Figure 2: Visualization of the support event experiment. Left: Schematic illustration of the original setup. Figure adopted from
(Baillargeon, 2002). Center: Examples from the artiﬁcial data-set alongside the name of the corresponding condition. The
left column shows stable conﬁgurations, while those in the right column are unstable. Right: Result from training models with
access to different amounts of data. Baseline indicates the performance for guessing randomly. Models discover solutions to
the easier condition (two upper rows in the left ﬁgure) ﬁrst, and solutions to the harder conditions (two bottom rows in the left
ﬁgure) later. Note the slight increase in number of samples required for learning between the third and forth condition.
part is removed for N = 8192 (corresponding to knowledge
of a 3.5 months old). Hence we conclude, that in this task the
family of BNNs recovers the order of developmental stages
observed in infants.
Support Events
Next we take a closer look at infants’ knowledge of sup-
port events, for which we adopt another experiment of
Baillargeon (2002). In this task a scene consists of a box
and a platform. The box is presented in different positions
relative to the platform and the experimenter measures (via
violation-of-expectation methods), if infants are able to
predict, whether the given conﬁguration is stable or not. Four
different conditions are investigated. In the ﬁrst the box is
positioned either on top of the platform or some distance
away from it. This condition requires a simple contact/no-
contact distinction to make reliable predictions about the
stability of the conﬁguration. The second condition involves
a distinction between different types of contact. Here the box
connects with the platform either on the top (as before) or on
the side. The third condition requires judgments based on the
amount of contact, i.e. the box is only partially positioned on
the platform. The ﬁnal condition adds an additional layer of
complexity, as it involves reasoning about non-rectangular
shapes. The different conditions are summarized in Figure 2
(left).
According to Baillargeon (2002), from three months on-
ward infants knowledge about the stability of a conﬁguration
is captured through a contact/no-contact distinction.
At
this stage they expect the box to be stable if and only if it
touches the platform in some way. This initial hypothesis is
than reﬁned, as they grow older. At the age of around ﬁve
months infants begin to distinguish between different types
of contacts. They realize, that the box will only be stable, if
it positioned above the platform, but not if it touches it on the
side. Starting with an age of 6.5 months they are able to take
into account the center of mass of simple objects (rectangular
boxes) when reasoning about stability. This is extended to
more complex, asymmetrical shapes at an age of roughly
twelve months. As in the occlusion task, infants start with an
initially simple hypothesis of how the laws of physics work,
which is subsequently reﬁned to better ﬁt the observed data.
In our artiﬁcial version of this task inputs x are represented
as 24×24 images with three channels (one for platform, box
and ﬂoor) and targets y are a binary indicator of the stability
of the given conﬁguration. Floor level as well as the size and
position of the platform and the box are randomized. Again
we generate a training set of 10000 samples and an equally
large test set. In both sets 2500 data-points belong to each of
the described conditions. Within each condition the amount
of stable and unstable conﬁgurations is balanced, leading
to a chance of 50 percent for guessing correctly. Example
conﬁgurations are shown in Figure 2 (center).
As before we train otherwise identical models for N ∈
{256,512,1024,2048,8192} until convergence and report re-
sult averaged over ten random seeds. Inspecting Figure 2
(right) we observe, that the family of BNNs ﬁrst discovers
solutions to the easier conditions (those where the box is po-
sitioned fully on the platform or on the side of it). If we in-
crease N to 4096 or more, they are also able to reason reliably
about stability in both of the center of mass conditions. Note,
that the error rate decreases slower, when being exposed to
the more complex, L-shaped objects, although this difference

Original Task
Artiﬁcial Data
Results
10000
15000
20000
25000
30000
Data-set size
1.0
1.5
2.0
2.5
3.0
Weber ratio
0
5
10
15
20
Age
Figure 3: Visualization of the approximate number system experiment. Left: Schematic illustration of the original setup.
Figure adopted from (Halberda & Feigenson, 2008). Center: Examples from the artiﬁcial data-set. This pair corresponds to
a ratio of 6:5. Right: Weber ratios of the experimental data. Red coloring corresponds to estimates from human participants,
while blue coloring corresponds to estimates from optimized BNNs. The progression of Weber ratios follows a Weber-Fechner
Law and is well described through exponential functions in both cases.
is only marginal. We conclude, that the models show pat-
tern similar to the developmental progress of infants, as we
increase the data-set size, akin to the observation from exper-
iment 1, although not as pronounced.
Approximate Number System
Moving away from probing knowledge about physical laws,
we next inspect a different domain:
children’s intuitive
counting abilities (Halberda & Feigenson, 2008). A single
trial consists of two images, each containing between 1 and
10 items, and the goal is to determine quickly, i.e. without
to much deliberation time, which of the two images contains
the larger quantity of items. The display time is adjusted
depending on age, such that it is short enough to prevent
serial counting. Objects within a trial are identical, but are
selected from a set of different objects across trials. Two
conditions either control for average item size or the summed
continuous area. An example trial from the original task is
shown in Figure 3 (left).
Experimental data for this task has been obtained for
three to six years olds, as well as for adults (Halberda &
Feigenson, 2008). Human perception is sensitive to the ratio
between amounts of objects in the two images and not their
difference, i.e. it follows a Weber-Fechner law. Levels of
accuracy are measured for different ratios of objects, ranging
from 1.11 (10:9) to 2.0 (2:1), from which Weber ratios are
estimated.
The Weber ratio is the smallest ratio, where a
participant is able to identify the correct stimulus in more
than 75 percent of the cases. Empirical results indicate, that
the Weber ratio decreases during childhood and our ability
to distinguish similar stimuli improves over time. Prior work
(Halberda & Feigenson, 2008) estimates Weber ratios of
around 1.53 in three years olds, which improves to 1.38 in
four years olds, to 1.23 in ﬁve years olds, to 1.18 in six years
olds and to 1.11 in adults. Overall the decrease of Weber
ratios is well described through an exponential function of
age (see Figure 3, right).
We created an artiﬁcial version of this task, with inputs
x corresponding to two 24 × 24 images.
For simplicity
images contain only rectangular objects and the difference in
quantity within a pair of images is always one. Targets y are
the number of objects in each images and the ﬁnal prediction
is obtained by comparing expected values between the two
estimates. Object sizes are randomly drawn from {1,2,3}
and their position is randomized, such that neighbouring
objects do not overlap. We controlled for an equal expected,
total area between both images as done in the second
condition of the original task.
Both training and test set
contain 6000 samples for each ratio from {10:9, 9:8, 8:7, 7:6,
6:5, 5:4, 4:3, 3:2, 2:1}. Examples are provided in Figure 3
(center).
We train one model for each value from N ∈{4,...,15} ·
2048. Hidden layers have 512 units in this experiment and
we found it helpful to initialize weights for all models from
a pretrained network. For the resulting models we calculate
Weber ratios after estimating accuracy levels of 75 percent
via linear interpolation and visualize the results in Figure 3
(right). We observe an improvement of Weber ratios as the
data-set size N increases and conclude, that our models also
follow a Weber-Fechner law. The resulting progression is
well described through an exponential function2 of data-set
size, a characteristic shared with the curve obtained from hu-
man participants. There is however a small gap between the
overall model performance in the artiﬁcial task and that of hu-
man participants in the original one, even for large data-sets.
Discussion
We investigated the progress of Bayesian Neural Networks
with access to increasingly large data-sets on three different
tasks.
In all three examples we ﬁnd an at least partial
agreement between the development of our artiﬁcial learning
2y = ae−bx+c +d, with x corresponding to data-set size or age.

systems and ﬁndings from the developmental psychology
literature.
However we also observe some considerable
differences. The best performing BNNs in the quantity com-
parison task, for example, do not reach the level of human
adults.
We attribute this effect to difﬁculties for standard
neural networks architectures on relational reasoning tasks
and hypothesize that recent advances in visual relational
reasoning (Santoro et al., 2017) could close this gap.
In
general we interpret our results as additional evidence for
Bayesian theories of cognition and learning (Grifﬁths, Kemp,
& Tenenbaum, 2008).
The discriminative models employed in this work require
large amounts of input-target pairs to obtain the desired
result. Children on the other hand have to operate in a much
more data-efﬁcient manner, as they do not have constant
access to a teacher providing correct targets. One approach
to resolve the question of sources, that children use for
learning, are generative models, which are able to discover
underlying structures without explicitly provided targets.
Whether our results transfer to generative models remains to
be seen. Indeed applying generative models in this context
would enable us to measure performance in artiﬁcial systems
directly via violation-of-expectation methods, as was done
with infants in two of our examples. In the future it would be
natural to extend our work to more realistic settings and apply
different architectures, such as recurrent or convolutional
networks.
We believe there are exciting opportunities for research
on the intersection of machine learning and developmental
psychology. On one hand insights from developmental psy-
chology can provide guidelines of how to build more intelli-
gent, human-like systems. The machine learning framework
on the other hand enables researchers to formulate norma-
tive theories, that can be empirically veriﬁed. We already see
some progress in these areas. Examples include the usage of
violation-of-expectation methods for probing the knowledge
of deep networks (Piloto et al., 2018) or the proposal to se-
lect training curricula for machine learning systems, based on
how children obtain samples (Smith & Slone, 2017).
Acknowledgments
This work was supported by the DFG GRK-RTG 2271
’Breaking Expectations’.
References
Baillargeon, R. (2002). The acquisition of physical knowl-
edge in infancy: A summary in eight lessons. Blackwell
handbook of childhood cognitive development, 1(46-83),
1.
Baillargeon, R., Li, J., Ng, W., & Yuan, S. (2009). An ac-
count of infants physical reasoning. Learning and the in-
fant mind, 66–116.
Baillargeon, R., Spelke, E. S., & Wasserman, S.
(1985).
Object permanence in ﬁve-month-old infants. Cognition,
20(3), 191–208.
Baker, C. L., Saxe, R., & Tenenbaum, J. B. (2009). Action
understanding as inverse planning. Cognition, 113(3), 329–
349.
Battaglia, P. W., Hamrick, J. B., & Tenenbaum, J. B. (2013).
Simulation as an engine of physical scene understand-
ing.
Proceedings of the National Academy of Sciences,
201306572.
Chang, M. B., Ullman, T., Torralba, A., & Tenenbaum, J. B.
(2016). A compositional object-based approach to learning
physical dynamics. arXiv preprint arXiv:1612.00341.
Clevert, D.-A., Unterthiner, T., & Hochreiter, S. (2015). Fast
and accurate deep network learning by exponential linear
units (elus). arXiv preprint arXiv:1511.07289.
Grifﬁths, T. L., Kemp, C., & Tenenbaum, J. B.
(2008).
Bayesian models of cognition.
Halberda, J., & Feigenson, L. (2008). Developmental change
in the acuity of the” number sense”: The approximate num-
ber system in 3-, 4-, 5-, and 6-year-olds and adults. Devel-
opmental psychology, 44(5), 1457.
Hinton, G. E., & Van Camp, D. (1993). Keeping the neural
networks simple by minimizing the description length of
the weights. In Proceedings of the sixth annual conference
on computational learning theory (pp. 5–13).
Kingma, D. P., & Ba, J. (2014). Adam: A method for stochas-
tic optimization. arXiv preprint arXiv:1412.6980.
Kingma, D. P., Salimans, T., & Welling, M. (2015). Vari-
ational dropout and the local reparameterization trick. In
Advances in neural information processing systems (pp.
2575–2583).
Lake, B. M., Ullman, T. D., Tenenbaum, J. B., & Gershman,
S. J. (2017). Building machines that learn and think like
people. Behavioral and Brain Sciences, 40.
Lerer, A., Gross, S., & Fergus, R. (2016). Learning phys-
ical intuition of block towers by example. arXiv preprint
arXiv:1603.01312.
Louizos, C., Ullrich, K., & Welling, M. (2017). Bayesian
compression for deep learning. In Advances in neural in-
formation processing systems (pp. 3288–3298).
Mitchell, T. J., & Beauchamp, J. J. (1988). Bayesian vari-
able selection in linear regression. Journal of the American
Statistical Association, 83(404), 1023–1032.
Piloto, L., Weinstein, A., TB, D., Ahuja, A., Mirza, M.,
Wayne, G., ... Botvinick, M. M. (2018). Probing physics
knowledge using tools from developmental psychology.
Santoro, A., Raposo, D., Barrett, D. G., Malinowski, M., Pas-
canu, R., Battaglia, P., & Lillicrap, T. (2017). A simple neu-
ral network module for relational reasoning. In Advances in
neural information processing systems (pp. 4967–4976).
Siegler, R. S., & Chen, Z. (1998). Developmental differences
in rule learning: A microgenetic analysis. Cognitive psy-
chology, 36(3), 273–310.
Smith, L. B., & Slone, L. K. (2017). A developmental ap-

proach to machine learning?
Frontiers in Psychology, 8,
2124.
Spelke, E. S., & Kinzler, K. D. (2007). Core knowledge.
Developmental science, 10(1), 89–96.

