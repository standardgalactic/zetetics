Agustín Blasco
Bayesian 
Data Analysis 
for Animal 
Scientists
The Basics

Bayesian Data Analysis for Animal Scientists

Agustı´n Blasco
Bayesian Data Analysis for
Animal Scientists
The Basics

Agustı´n Blasco
Institute of Animal Science and Technology
Universitat Polite`cnica de Vale`ncia
Vale`ncia
Spain
ISBN 978-3-319-54273-7
ISBN 978-3-319-54274-4
(eBook)
DOI 10.1007/978-3-319-54274-4
Library of Congress Control Number: 2017945825
# Springer International Publishing AG 2017
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of
the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or
dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt
from the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, express or implied, with respect to the material contained
herein or for any errors or omissions that may have been made. The publisher remains neutral with
regard to jurisdictional claims in published maps and institutional afﬁliations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

To Daniel and Daniel, from whom I have
learnt so much in these matters

Preface
What we now call ‘Bayesian analysis’ was the standard approximation to statistics
in the nineteenth century and the ﬁrst quarter of the twentieth century. For example,
Gauss’s ﬁrst deduction of the least squares method was made by using Bayesian
procedures. A strong reaction against Bayesian methods, led by Ronald Fisher,
Jerzy Neyman and Egon Pearson, took place in the 1920s and 1930s with the result
that Bayesian statistics was replaced by the current ‘frequentist’ methods of P-
values, signiﬁcance tests, conﬁdence intervals and likelihood estimation. The
reasons were in part philosophical and in part practical; often Bayesian procedures
needed to solve complex multidimensional integrals. The philosophical issues were
mainly related to the use of prior information inherent to Bayesian analysis; it
seemed that for most cases, informative priors should be subjective, and moreover,
it was not possible to represent ignorance.
When the computers’ era arrived, the practical problems had a solution using
techniques known as ‘Markov Chain Monte Carlo’ (MCMC), and a new interest in
Bayesian procedures took place. Subjective informative priors were almost aban-
doned, and ‘objective’ priors with little information were used instead, expecting
that having enough data, the priors will not affect the results in practice. It was soon
discovered that some difﬁcult problems in biological sciences, particularly in
genetics, could be approached much easily using Bayesian techniques, and some
problems that had no solution using frequentist statistics could be solved with this
new tool. The geneticists Daniel Gianola and Daniel Sorensen brought in the 1990s
the MCMC procedures to solve animal breeding problems using Bayesian statistics,
and its use started being more and more common. Nowadays, Bayesian techniques
are common in animal breeding, and there is no reason why they should not be
applied in other ﬁelds of animal production.
The objective of this book is to offer the animal production scientist an intro-
duction to this methodology, offering examples of its advantages for analysing
common problems like comparison between treatments, regression or linear mixed
models analyses. Classical statistical tools are often not well understood by practi-
cal scientists. Signiﬁcance tests and P-values are misused so often that in some
ﬁelds of research it has been suggested to eliminate them. I think that Bayesian
procedures give much more intuitive results and provide easy tools, helping practi-
cal scientists to be more accurate when explaining the results of their research.
Substituting stars and ‘n.s.’ by probabilities of obtaining a relevant difference
vii

between treatments helps not only in understanding results but in making further
decisions. Moreover, some difﬁcult problems have a straightforward Bayesian
procedure to be solved that does not need new conceptual tools but the use of the
principles learnt for simpler problems.
This book is based on the lecture notes of an introductory Bayesian course I gave
in Scotland (Edinburgh, Scottish Agricultural College), France (Toulouse, Institut
National de la Recherche Agronomique), Spain (Valencia, Universitat Polite`cnica
de Vale`ncia), the USA (Madison, University of Wisconsin), Uruguay (Montevideo,
Universidad Nacional), Brazil (Botucatu, Universidade Estadual Paulista; Lavras,
Universidade Federal de Lavras) and Italy (Padova, Universita` di Padova). The
book analyses common cases that can be found in animal production using practical
examples and deriving demonstrations to appendices to facilitate reading the
chapters. I have preferred to be more intuitive than rigorous, to help the reader in
his ﬁrst contact with Bayesian inference. The data are almost always considered to
be Normally distributed conditioned to the unknowns, because Normal distribution
is the most common in animal production and all derivations are similar using other
distributions. The book is structured into 10 chapters. The ﬁrst one reviews the
classical statistics concepts stressing the common misinterpretations; quite a few
practical scientists will discover that the techniques they were applying do not mean
what they thought. Chapter 2 offers the Bayesian possibilities for common analyses
like comparisons between treatments; here, the animal production scientists will see
new ways of presenting the results: probability of a difference between treatments
being relevant, minimum guaranteed value with a chosen probability, when can it
be said ‘there is no difference between treatments’ and when ‘we do not know
whether there is a difference or not’, etc. Chapter 3 gives elementary notions about
distribution functions. Chapter 4 introduces MCMC procedures intuitively.
Chapters 5, 6 and 7 analyse the linear model from its simplest form (only the
mean and the error) to the complex multitrait mixed models. Chapter 8 gives some
examples of complex problems that have no straightforward solution under classi-
cal statistics. Chapter 9 deals with all the problems related to prior information, the
main object of criticism of Bayesian statistics in the past. Chapter 10 deals with the
complex problem of model selection from both frequentist and Bayesian points of
view. Although this is a book for practical scientists, not necessarily interested in
the philosophy of Bayesian inference, I thought it would be possible to communi-
cate the philosophical problems that made frequentism and Bayesianism two
irreconcilable options in the view of classical statisticians like Fisher, Jeffreys,
Pearson (father and son), Neyman, Lindley and many others. Following a classical
tradition in Philosophy, I wrote three dialogues between a frequentist statistician
and a Bayesian one, in which they discuss about the problem of using probability as
a degree of belief, the limitations of the classical probability theory, the Bayesian
solution and the difﬁcult problem of induction, i.e. the reasons why we think our
inferences are correct. I took Hylas and Philonous, the characters invented by
Bishop Berkeley in the eighteenth century for his dialogues, assigning the
frequentist role to Hylas and the Bayesian to Philonous, and I also placed the
viii
Preface

dialogues in the eighteenth century, when Bayes published his famous theorem, to
make them entertaining and give some sense of humour to a book dedicated to such
a rather arid matter as statistics.
I have to acknowledge many people who have contributed to this book. First of
all, the colleagues who invited me to give the introductory Bayesian course on
which this book is based; the experience teaching this matter in several countries
and in several languages has been invaluable for trying to be clear and concise in the
explanations of all the statistical concepts and procedures contained in the book. I
am grateful to Jose´ Miguel Bernardo for his suggestions about how a practical
scientist can use the Bayesian credibility intervals for most common problems,
developed in Chap. 2, and to Luis Varona for the intuitive interpretation of how
Gibbs sampling works. I should also be grateful to all the colleagues who have read
the manuscript, corrected my faults and given advice; I am especially grateful to
Manolo Baselga for his detailed reading line by line and also to the colleagues who
reviewed all or part of the book, Miguel Toro, Juan Manuel Serradilla, Quim
Casellas, Luis Varona, Noelia Iba´~nez and Andre´s Legarra, although all the errors
that could be found in the book are my entire responsibility. Finally, I am grateful to
my son Alejandro, educated in British universities, for his thorough English revi-
sion of this book and of course to Concha for her patience and support when I was
engaged dedicating so many weekends to writing the book.
Vale`ncia, Spain
Agustı´n Blasco
Preface
ix

Notation
Colour
To help in identifying the functions used in this book, when necessary, we have
used red colour for the variables and black for the constants or given parameters.
Thus,
f yjμ; σ2


¼
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2πσ2
p
exp  y  μ
ð
Þ2
2σ2
"
#
is the probability density function of a Normal distribution, because the variable is
y, but the conditional
f yjμ; σ2


¼
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2πσ2
p
exp  y  μ
ð
Þ2
2σ2
"
#
is not a Normal but an Inverted Gamma distribution because the variable is σ2. This
also helps in distinguishing a likelihood f(y| θ) from a probability density function
of the data f(y| θ).
Probabilities and Probability Distributions
The letter ‘P’ is used for probabilities; for example, P(a  x  b) means the
probability of x being between a and b.
The letter ‘f’ is used to represent probability density functions; e.g. f(x) can be
the probability density function of a Normal distribution or a binomial distribution.
It is equivalent to the common use of the letter ‘p’ for probability density functions,
but using ‘f’ stresses that it is a function.
We will use the word Normal (with ﬁrst capital letter) for the Gaussian distribu-
tion, to avoid the confusion with the common word ‘normal’.
xi

Scalars, Vectors and Matrixes
Bold small letters are column vectors, e.g. y ¼
1
0
5
2
4
3
5
y0 is a transposed (row) vector, e.g. y0 ¼ [1 0 5]
Bold capital letters are matrixes, e.g. A ¼
1
0
8
6


Symmetric matrixes are usually written only placing the upper triangle, e.g.
G ¼
σ2
a
σac
σak
σ2
c
σck
σ2
k
2
4
3
5
Lower case letters are scalars, e.g. y1 ¼ 7
Greek letters are parameters, e.g. σ2 is a variance.
Proportionality
The sign / means ‘proportional to’. For example, if c and k are constants, the
distribution N(0,1) is
f y
ð Þ ¼
1ﬃﬃﬃﬃﬃ
2π
p
exp y2
2


/ exp y2
2


/ k  exp c
ð Þ  exp y2
2


/ k  exp c  y2
2


Notice that we cannot add constants or multiply the exponent by a constant
if f y
ð Þ / exp y2
ð
Þ, then
f y
ð Þ not proportional to k þ exp y2
ð
Þ
f y
ð Þ not proportional to exp c  y2
ð
Þ
xii
Notation

Contents
1
Do We Understand Classic Statistics? . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Historical Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Test of Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.2.1
The Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.2.2
Common Misinterpretations . . . . . . . . . . . . . . . . . . . .
7
1.3
Standard Errors and Conﬁdence Intervals . . . . . . . . . . . . . . . . .
13
1.3.1
Deﬁnition of Standard Error and Conﬁdence Interval . . .
13
1.3.2
Common Misinterpretations . . . . . . . . . . . . . . . . . . . .
14
1.4
Bias and Risk of an Estimator . . . . . . . . . . . . . . . . . . . . . . . . .
16
1.4.1
Unbiased Estimators . . . . . . . . . . . . . . . . . . . . . . . . .
16
1.4.2
Common Misinterpretations . . . . . . . . . . . . . . . . . . . .
16
1.5
Fixed and Random Effects . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
1.5.1
Deﬁnition of ‘Fixed’ and ‘Random’ Effects . . . . . . . . .
18
1.5.2
Shrinkage of Random Effects Estimates . . . . . . . . . . .
19
1.5.3
Bias, Variance and Risk of an Estimator when the
Effect is Fixed or Random . . . . . . . . . . . . . . . . . . . . .
20
1.5.4
Common Misinterpretations . . . . . . . . . . . . . . . . . . . .
21
1.6
Likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
1.6.1
Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
1.6.2
The Method of Maximum Likelihood . . . . . . . . . . . . .
24
1.6.3
Common Misinterpretations . . . . . . . . . . . . . . . . . . . .
25
Appendix 1.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
Appendix 1.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
Appendix 1.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
Appendix 1.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
2
The Bayesian Choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
2.1
Bayesian Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
2.1.1
The Foundations of Bayesian Inference . . . . . . . . . . . .
33
2.1.2
Bayes Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
2.1.3
Prior Information . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
2.1.4
Probability Density . . . . . . . . . . . . . . . . . . . . . . . . . .
40
xiii

2.2
Features of Bayesian Inference . . . . . . . . . . . . . . . . . . . . . . . .
42
2.2.1
Point Estimates: Mean, Median and Mode . . . . . . . . . .
42
2.2.2
Credibility Intervals . . . . . . . . . . . . . . . . . . . . . . . . . .
44
2.2.3
Marginalisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
2.3
Test of Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
2.3.1
Model Choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
2.3.2
Bayes Factors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
2.3.3
Model Averaging . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
2.4
Common Misinterpretations . . . . . . . . . . . . . . . . . . . . . . . . . .
54
2.5
Bayesian Inference in Practice . . . . . . . . . . . . . . . . . . . . . . . . .
57
2.6
Advantages of Bayesian Inference . . . . . . . . . . . . . . . . . . . . . .
61
Appendix 2.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
Appendix 2.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
Appendix 2.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
3
Posterior Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
3.1
Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
3.2
Probability Density Function . . . . . . . . . . . . . . . . . . . . . . . . . .
68
3.2.1
Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
3.2.2
Transformation of Random Variables . . . . . . . . . . . . .
69
3.3
Features of a Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
3.3.1
Mean . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
3.3.2
Median . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
3.3.3
Mode . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
3.3.4
Credibility Intervals . . . . . . . . . . . . . . . . . . . . . . . . . .
72
3.4
Conditional Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
3.4.1
Bayes Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
3.4.2
Conditional Distribution of the Sample of a Normal
Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
3.4.3
Conditional Posterior Distribution of the Variance of a
Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . .
73
3.4.4
Conditional Posterior Distribution of the Mean of a
Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . .
75
3.5
Marginal Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
76
3.5.1
Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
76
3.5.2
Marginal Posterior Distribution of the Variance of a
Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . .
77
3.5.3
Marginal Posterior Distribution of the Mean of a Normal
Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
78
Appendix 3.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
Appendix 3.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
Appendix 3.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
Appendix 3.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
83
Reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
xiv
Contents

4
MCMC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
85
4.1
Samples of Marginal Posterior Distributions . . . . . . . . . . . . . . .
86
4.1.1
Taking Samples of Marginal Posterior Distributions . . .
86
4.1.2
Making Inferences from Samples of Marginal
Posterior Distributions . . . . . . . . . . . . . . . . . . . . . . . .
87
4.2
Gibbs Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
4.2.1
How It Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
4.2.2
Why It Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
4.2.3
When It Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
4.2.4
Gibbs Sampling Features . . . . . . . . . . . . . . . . . . . . . .
95
4.3
Other MCMC Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
98
4.3.1
Acceptance-Rejection . . . . . . . . . . . . . . . . . . . . . . . . .
98
4.3.2
Metropolis–Hastings . . . . . . . . . . . . . . . . . . . . . . . . .
100
Appendix: Software for MCMC . . . . . . . . . . . . . . . . . . . . . . . . . . . .
101
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
102
5
The Baby Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
103
5.1
The Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
103
5.2
Analytical Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
104
5.2.1
Marginal Posterior Density Function of the Mean
and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
104
5.2.2
Joint Posterior Density Function of the Mean and
Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
105
5.2.3
Inferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
105
5.3
Working with MCMC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
109
5.3.1
The Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
109
5.3.2
Using Flat Priors . . . . . . . . . . . . . . . . . . . . . . . . . . . .
109
5.3.3
Using Vague Informative Priors . . . . . . . . . . . . . . . . .
112
5.3.4
Common Misinterpretations . . . . . . . . . . . . . . . . . . . .
114
Appendix 5.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
115
Appendix 5.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
116
Appendix 5.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
117
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
118
6
The Linear Model: I. The ‘Fixed Effects’ Model . . . . . . . . . . . . . . .
119
6.1
The ‘Fixed Effects’ Model . . . . . . . . . . . . . . . . . . . . . . . . . . .
119
6.1.1
The Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
119
6.1.2
Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
124
6.1.3
Common Misinterpretations . . . . . . . . . . . . . . . . . . . .
125
6.2
Marginal Posterior Distributions via MCMC Using
Flat Priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
127
6.2.1
Joint Posterior Distribution . . . . . . . . . . . . . . . . . . . . .
127
6.2.2
Conditional Distributions . . . . . . . . . . . . . . . . . . . . . .
128
6.2.3
Gibbs Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
129
Contents
xv

6.3
Marginal Posterior Distributions via MCMC Using Vague
Informative Priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
130
6.3.1
Vague Informative Priors . . . . . . . . . . . . . . . . . . . . . .
130
6.3.2
Conditional Distributions . . . . . . . . . . . . . . . . . . . . . .
131
6.4
Least Squares as a Bayesian Estimator . . . . . . . . . . . . . . . . . . .
132
Appendix 6.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
133
Appendix 6.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
134
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
135
7
The Linear Model: II. The ‘Mixed’ Model . . . . . . . . . . . . . . . . . . .
137
7.1
The Mixed Model with Repeated Records . . . . . . . . . . . . . . . .
137
7.1.1
The Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
137
7.1.2
Common Misinterpretations . . . . . . . . . . . . . . . . . . . .
141
7.1.3
Marginal Posterior Distributions via MCMC . . . . . . . .
142
7.1.4
Gibbs Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
144
7.2
The Genetic Animal Model . . . . . . . . . . . . . . . . . . . . . . . . . . .
145
7.2.1
The Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
145
7.2.2
Marginal Posterior Distributions via MCMC . . . . . . . .
150
7.3
Bayesian Interpretation of BLUP and REML . . . . . . . . . . . . . .
154
7.3.1
BLUP in a Frequentist Context . . . . . . . . . . . . . . . . . .
154
7.3.2
BLUP in a Bayesian Context . . . . . . . . . . . . . . . . . . .
156
7.3.3
REML as a Bayesian Estimator . . . . . . . . . . . . . . . . .
158
7.4
The Multitrait Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
158
7.4.1
The Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
158
7.4.2
Data Augmentation . . . . . . . . . . . . . . . . . . . . . . . . . .
160
7.4.3
More Complex Models . . . . . . . . . . . . . . . . . . . . . . . .
163
Appendix 7.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
164
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
165
8
A Scope of the Possibilities of Bayesian Inference + MCMC . . . . . .
167
8.1
Nested Models: Examples in Growth Curves . . . . . . . . . . . . . .
168
8.1.1
The Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
168
8.1.2
Marginal Posterior Distributions . . . . . . . . . . . . . . . . .
171
8.1.3
More Complex Models . . . . . . . . . . . . . . . . . . . . . . . .
173
8.2
Modelling Residuals: Examples in Canalising Selection . . . . . .
174
8.2.1
The Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
175
8.2.2
Marginal Posterior Distributions . . . . . . . . . . . . . . . . .
176
8.2.3
More Complex Models . . . . . . . . . . . . . . . . . . . . . . . .
177
8.3
Modelling Priors: Examples in Genomic Selection . . . . . . . . . .
178
8.3.1
The Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
179
8.3.2
RR-BLUP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
183
8.3.3
Bayes A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
185
8.3.4
Bayes B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
187
8.3.5
Bayes C and Bayes Cπ . . . . . . . . . . . . . . . . . . . . . . . .
188
8.3.6
Bayes L (Bayesian Lasso) . . . . . . . . . . . . . . . . . . . . .
188
8.3.7
Bayesian Alphabet in Practice . . . . . . . . . . . . . . . . . .
189
xvi
Contents

Appendix 8.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
190
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
191
9
Prior Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
193
9.1
Exact Prior Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
193
9.1.1
Prior Information . . . . . . . . . . . . . . . . . . . . . . . . . . . .
193
9.1.2
Posterior Probabilities with Exact Prior Information . . .
195
9.1.3
Inﬂuence of Prior Information in Posterior
Probabilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
197
9.2
Vague Prior Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
198
9.2.1
A Vague Deﬁnition of Vague Prior Information . . . . . .
198
9.2.2
Examples of the Use of Vague Prior Information . . . . .
200
9.3
No Prior Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
203
9.3.1
Flat Priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
204
9.3.2
Jeffreys Prior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
205
9.3.3
Bernardo’s ‘Reference’ Priors . . . . . . . . . . . . . . . . . . .
206
9.4
Improper Priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
207
9.5
The Achilles Heel of Bayesian Inference . . . . . . . . . . . . . . . . .
208
Appendix 9.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
209
Appendix 9.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
210
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
210
10
Model Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
213
10.1
Model Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
213
10.1.1
The Purpose of Model Selection . . . . . . . . . . . . . . . . .
213
10.1.2
Fitting Data vs Predicting New Records . . . . . . . . . . .
217
10.1.3
Common Misinterpretations . . . . . . . . . . . . . . . . . . . .
218
10.2
Hypothesis Tests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
221
10.2.1
Likelihood Ratio Test and Other Frequentist Tests . . . .
221
10.2.2
Bayesian Model Choice . . . . . . . . . . . . . . . . . . . . . . .
223
10.3
The Concept of Information . . . . . . . . . . . . . . . . . . . . . . . . . .
226
10.3.1
Fisher’s Information . . . . . . . . . . . . . . . . . . . . . . . . . .
227
10.3.2
Shannon Information and Entropy . . . . . . . . . . . . . . . .
231
10.3.3
Kullback–Leibler Information . . . . . . . . . . . . . . . . . . .
232
10.4
Model Selection Criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
233
10.4.1
Akaike Information Criterion (AIC) . . . . . . . . . . . . . .
233
10.4.2
Deviance Information Criterion (DIC) . . . . . . . . . . . . .
237
10.4.3
Bayesian Information Criterion (BIC) . . . . . . . . . . . . .
239
10.4.4
Model Choice in Practice . . . . . . . . . . . . . . . . . . . . . .
241
Appendix 10.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
242
Appendix 10.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
243
Appendix 10.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
244
Appendix 10.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
245
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
246
Contents
xvii

Appendix: The Bayesian Perspective—Three New Dialogues Between
Hylas and Philonous . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
247
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
265
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
271
xviii
Contents

Do We Understand Classic Statistics?
1
Without hoping to know whether each separate hypothesis is
true or false, we may search for rules to govern our behaviour
with regard to them, in following which we insure that, in the
long run of experience, we shall not be too often wrong.
Jerzy Neyman and Egon Pearson, 1933
In this chapter, we review the classical statistical concepts and procedures, test of
hypothesis, standard errors and conﬁdence intervals, unbiased estimators, maxi-
mum likelihood, etc., and we examine the most common misunderstandings about
them. We will see the limitations of classical statistics in order to stress the
advantages of using Bayesian procedures in the following chapters.
1.1
Historical Introduction
The Bayesian School was, in practice, founded by the French aristocrat and politi-
cian Marquis Pierre-Simon Laplace via several works published from 1774 to 1812,
and it had a preponderant role in scientiﬁc inference during the nineteenth century
(Hald 1998). A few years before Laplace’s ﬁrst paper on the matter, the same
principle was formalised in a posthumous paper presented at the Royal Society of
London and attributed to a rather obscure priest Revd Thomas Bayes of whom we
know very little; even his supposed portrait is probably false (Bellhouse 2004).
Bayes wrote his essay to refute Hume’s attack to religion found in his essay ‘Of
Miracles’, in which it was argued that miracles had a great improbability in
comparison to the probability that they were not accurately reported (Stigler
2013). Apparently, the principle upon which Bayesian inference is based was
formulated before. Stigler (1983) attributes it to Saunderson (1683–1739), a blind
professor of optics who published a large number of papers on several ﬁelds of
mathematics. Due to the work of Laplace, what we call now Bayesian techniques
were commonly used along the nineteenth and the ﬁrst few decades of the twentieth
# Springer International Publishing AG 2017
A. Blasco, Bayesian Data Analysis for Animal Scientists,
DOI 10.1007/978-3-319-54274-4_1
1

century. For example, the ﬁrst deduction of the least square method made by Gauss
in 1795 (although it was published in 1809) was made using Bayesian theory. At
that time these techniques were known as ‘inverse probability’, because their
objective was to estimate the parameters from the data (i.e. to ﬁnd the probability
of the causes from their effects); direct probability takes place when the probability
distribution originating the data is known, and the probability of a sample is
calculated from it (e.g. throwing a dice). The word ‘Bayesian’ is rather recent
(Fienberg 2006), and it was introduced by Fisher (1950) to stress the precedence in
time (not in importance) of the work of Revd Bayes. As the essay of Bayes was
largely ignored, given that Laplace was not aware about the work of Bayes when
proposing the same principle, the correct name for this school should probably be
‘Laplacian’, or perhaps we should preserve the old and explicit name of ’inverse
probability’. Nevertheless, as it is commonplace today, we will use the name
‘Bayesian’ throughout this book.
Bayesian statistics uses probability to express the uncertainty about the
unknowns that are being estimated. The use of probability is more efﬁcient than
any other method of expressing uncertainty (Ramsey 1931). Unfortunately, to make
it possible, inverse probability needs the knowledge of some prior information. For
example, we know through published literature that in many countries the pig breed
Landrace has a litter size of around 10 piglets. We then perform an experiment to
learn about Spanish Landrace litter size, and a sample of ﬁve sows is evaluated for
litter size in their ﬁrst parity. Let us say an average of six born piglets is observed,
this seems a very unlikely outcome a priori, and we should not put much trust in our
sample. However, it is not entirely clear how to integrate properly the prior
information about Landrace litter size in our analysis. We can pretend we do not
have any prior information and say that all the possible results have the same prior
probability, but this leads to some inconsistencies, as we will see later in Chap. 9.
Laplace became aware of this problem, and in his later works, he examined the
possibility of making inferences based in the distribution of the samples rather than
in the probability of the unknowns, founding in practice the frequentist school
(Hald 1998).
Fisher’s work on the likelihood function in the 1920s and the frequentist work of
Neyman and Pearson in the 1930s eclipsed Bayesian inference, the reason being
that they offered inferences and measured uncertainty about these inferences
without the need of prior information. Fisher developed the properties of the
method of maximum likelihood, a method attributed to him, although Daniel
Bernoulli proposed it as early as 1778 (Kendall 1961) and Johan Heinrich Lambert
in 1760 (Hald 1998). When Fisher discussed this method (Fisher 1935), one of the
discussants of his paper noticed that the statistician and economist of Irish-Catalan
origin Isidro Francis Edgeworth had proposed it in 1908. It is likely that Fisher did
not know of this article when he ﬁrst proposed to use the likelihood in an obscure
paper published in 1912,1 when he was 22 years old, but it is remarkable that Fisher
1The historian of statistics A. Hald (1998) asks himself why such an obscure paper passed the
referee’s report and was ﬁnally published. At that time, Fisher did not use the name of ‘likelihood’.
2
1
Do We Understand Classic Statistics?

never cited in his life any precedent of his work about likelihood. His main
contribution was to determine the statistical properties of the likelihood and to
develop the concept of information based on it. Neyman and Pearson (1933) used
the likelihood ratio as a useful way to perform hypothesis tests. Their theory was
based in considering hypothesis tests as a decision problem, choosing between a
hypothesis and an alternative, a procedure that Fisher disliked. Fisher considered
that when a null hypothesis is not rejected, we cannot assume straight away that this
hypothesis is true, but instead just take this hypothesis as provisional (Fisher 1925,
1935), very much in the same sense as the Popper theory of refutation (Popper
1934). It is interesting to note that Popper’s famous theory of conjectures and
refutations was published independently on Fisher’s one around the same time.
Although some researchers still used Bayesian methods in the 1930s, like the
geologist and statistician Harold Jeffreys did (Jeffreys 1939), the classical Fisher-
Neyman-Pearson school dominated the statistical world until the 1960s, when a
‘revival’ started that has been increasing hitherto. Bayesian statistics had three
problems to be accepted, two main theoretical problems and a practical one. The
ﬁrst theoretical problem was the difﬁculty of integrating prior information. To
overcome this difﬁculty, Ramsey (1931) and De Finetti (1937) proposed separately
and independently to consider probability as a ‘belief’. Prior information should then
be evaluated by experts and the probabilities assigned to different events according to
the experts’ opinion. This procedure can work for a few traits or effects, but it has
serious problems in the multivariate case. The other theoretical problem is how to
represent ‘ignorance’ when there is no prior information or when we would like to
assess the information provided by the data without prior considerations. This second
theoretical problem is still the main difﬁculty for many statisticians to accept
Bayesian theory, and it is nowadays an area of intense research. The third problem
comes from the use of probability for expressing uncertainty, a characteristic of the
Bayesian School. As we will see later, with the exception of very simple inferences,
this leads to multiple integrals that cannot be solved even using approximate
methods. This supposed a big problem for applying Bayesian techniques until the
1990s, when a numerical method was applied in order to ﬁnd practical solutions to all
these integrals. The method, called Markov chain Monte Carlo (MCMC), enabled the
integrals to be solved, contributing to the current rapid development and application
of Bayesian techniques in all ﬁelds of science.
Bayesian methods express the uncertainty using probability density functions
that we will see in Chap. 3. The idea of MCMC is to provide a set of random sample
numbers extracted from a probability density function, instead of using the mathe-
matical expression of this function. The ﬁrst use of random samples from a
probability density function was proposed by the Guinness brewer William Sealy
Gosset, called ‘Student’, in his famous paper in which he presented the t-distribu-
tion (Student 1908). The use of Markov chains to ﬁnd these random samples has its
origins in the work developed in Los Alamos at the end of Second World War, and
it was ﬁrst used by John von Neumann and Stanislav Ulman for solving the problem
of neutron diffusion in ﬁssionable material. The method had its success due to the
appearance of the ﬁrst computer in 1946, the ENIAC, that made the computations
feasible. The name ‘Monte Carlo’ was proposed by Nicholas Metropolis in 1947
1.1
Historical Introduction
3

(Metropolis 1987) using the Monte Carlo roulette as a kind of random sampling.
Metropolis and Ulam (1949) published the ﬁrst paper describing MCMC. Much
later, Geman and Geman (1986) applied this method to an image analysis using a
particularly efﬁcient type of MCMC that they called ‘Gibbs sampling’ because they
were using Gibbs distributions. Gelfand and Smith (1990) introduced this technique
in the statistical world to obtain probability distributions, and Daniel Gianola
(Wang et al. 1994) and Daniel Sorensen (Sorensen et al. 1994) brought these
techniques into the ﬁeld of animal breeding. These techniques present several
numerical problems, and there is a very active area of research in this ﬁeld; Sharon
McGrayne has written a lively and entertaining history of this procedure
(McGrayne 2011). Today, the association of Bayesian inference and MCMC
techniques has produced a dramatic development of the application of Bayesian
methods to practically every ﬁeld of science.
The Bayesian methods have been compared many times with the frequentist
methods. The old criticism to Bayesian methods usually lied in the lack of objec-
tivity because of the use of subjective priors (see, e.g. Barnett 1999). The general-
ised use of what Bayesians call ‘objective priors’, often linked to the use of MCMC
techniques, has changed the focus of the criticism. The reader who is interested in a
critical view of these procedures, even acknowledging their usefulness, can consult
the recent book of Efron and Hastie (2016). A critical comparison in the ﬁeld of
animal breeding has been provided by Blasco (2001). The point of view of the
present book is that Bayesian techniques not only give results that are more
practical for the animal production scientists, but they are easier to understand
than the classical frequentist results. It is rather frequent that the practical scientist
misunderstands the meaning of the frequentist statistical tool that is used. We are
now going to examine these tools and comment frequent misinterpretations.
1.2
Test of Hypothesis
1.2.1
The Procedure
Let us start with a classical problem: we have an experiment in which we want to
test whether there is an effect towards some treatment, for example, we are testing
whether a selected population for growth rate has a higher growth rate than a control
population. What we wish to ﬁnd is the probability of the selected population being
higher than the control one. However, classic statistics does not provide an answer
to this question; classical statistics cannot give the probability of a treatment being
higher than other treatment, which is rather frustrating. The classical procedure is
to start with the hypothesis, called ‘null hypothesis H0’, that there is no difference
between treatments, i.e. that the difference between the means of the selected and
control populations m1  m2 ¼ 0. By repeating the experiment an inﬁnite number of
times,2 we would obtain an inﬁnite number of samples, and we could calculate the
2The frequentist concept of probability, considered as the limit of the frequency of an inﬁnite
number of trials, was mainly developed by Richard von Mises in 1928 (Von Mises 1957), although
there are several precedents of this use (see Howie 2002, for an entertaining history of the
4
1
Do We Understand Classic Statistics?

difference x1  x2 for each repetition between the averages of the samples. If the
null hypothesis is true, these differences will be grouped around zero (Fig. 1.1).
Notice that although there is no difference between selected and control populations
(we assumed m1  m2 ¼ 0), the difference between our samples x1  x2 will never
be exactly zero, and by chance, it can be high. Let us consider the 5% of the highest
differences (shadow area in Fig. 1.1).
We would actually take only one sample. If our sample lied in the shadow area of
Fig. 1.1, we could say that:
1. There is no difference between treatments, and our sample was a very rare
sample that would only occur 5% of the times, maximum, if we repeat the
experiment an inﬁnite number of times.
2. The treatments are different, and if we repeat the experiment an inﬁnite number
of times, the difference between the averages of the samples (x1  x2) would not
be distributed around zero but around an unknown value different from zero.
Neyman and Pearson (1933) suggested that the ‘scientiﬁc behaviour’ should be
to take option 2, acting as if the null hypothesis H0 was wrong. A result of this
behaviour would be that ‘in the long run’ we would be right in almost 95% of the
*
x1 – x2
–
–
x1 – x2
–
–
H0: m1 – m2 =0
m1 – m2
0
95%
Fig. 1.1 Distribution of the
difference between the
averages of conceptually
repeated samples x1  x2, if
H0 is true and there is no
difference between treatments
(m1  m2 ¼ 0). When our
actual difference between
sample averages lies in the
shadow area, we reject H0 and
say that the difference is
‘signiﬁcant’. This is often
represented by a star
controversy between frequentist and Bayesian probability). A discussion about the different
deﬁnitions of probability can be found in Childers (2013). Response to some criticism about the
impossibility of repeating the same experiment can be found in Neyman (1977).
1.2
Test of Hypothesis
5

cases. Notice that this is not the probability of the treatments being different, but the
probability of ﬁnding samples higher than a given value. The relationship between
both concepts is not obvious, but theoretical considerations and simulation
experiments show that the probability of the treatments being different is substan-
tially lower than what its 95% level of rejection seems to provide. For example, a P-
value of 0.05 would not give an evidence of 95% against the null hypothesis, but
only about 70% (Berger and Sellke 1987; Johnson 2013).
We have stated, before making our experiment, the frequency in which we will say
that there are differences between treatments when actually there are not, using a
conventional value of 5%. This is called ‘Type I error’. There is some discussion in the
classical statistical world about what to do when we do not reject the null hypothesis.
In this case we can either say that we do not know whether the two treatments are
different,3 or we can accept that both treatments have the same effect, i.e. that the
difference between treatments is null. Fisher (1925) defended the ﬁrst choice, whereas
Neyman and Pearson (1933) defended the second one stressing that we also have the
possibility of being wrong by saying that there is no difference between treatments
when actually this difference exists (they called it ‘Type II error’).
Often a ‘P-value’ accompanies the result of the test. P-value is the probability of
obtaining a difference between samples x1  x2 equal or higher than the actual
difference found, when there is no difference between populations (m1  m2 ¼ 0)
(Fig. 1.2).4 Notice that P-value is not the probability of both treatments being
different, but the probability of ﬁnding samples of the difference between
x1 – x2
–
–
x1 – x2
–
–
m1 – m2
0
3%
Fig. 1.2 A P-value of 3%
gives the probability of
ﬁnding the current sample
value or a higher value if the
null hypothesis holds
3This attitude to scientiﬁc progress was later exposed in a less technical way by Karl Popper
(1934). Scientists and philosophers attribute to Popper the theory about scientiﬁc progress based in
the refutation of pre-existing theories, whereas accepting the current theory is always provisional.
However, Fisher (1925, 1935) based his testing hypothesis theory in the same principle. I do not
know how far backwards can be traced the original idea, but it is contained at least in the famous
essay “On liberty” of James Stuart Mill (1848).
4Here we use a one tail test for simplicity.
6
1
Do We Understand Classic Statistics?

treatments higher than ours. Nowadays P-values are used associated to signiﬁcance
tests although their rationale for inference is different. P-values were proposed and
used by Fisher as exploratory analyses to examine how much evidence we can get
from our samples.5
A very low P-value gives more evidence of treatments being different than a
higher P-value, but we do not know how much evidence, since they do not measure
the probability of the populations being different. In other words, a P-value of 2%
does not give twice as much evidence as a P-value of 4%. Moreover, the result of
the test is established with the same Type I error, normally a 5%, independently on
the P-value we obtain, because we deﬁne the Type I error before making the
experiment, and the P-value is obtained after the experiment is made. It is important
to realise that the P-value changes if we repeat the experiment; thus, a P-value of
2% does not give a ‘signiﬁcance at the level or threshold 2%’ because this will
change if we repeat the experiment.6 Modern statisticians use P-values to express
the amount of evidence the sample gives, but there is still a considerable amount of
discussion about how is this ‘amount’ measured, and no standard methods have
been hitherto implemented (see Sellke et al. 2001; Bayarri and Berger 2004;
Johnson 2013 for a discussion).
1.2.2
Common Misinterpretations
The error level is the probability of being wrong: It is not. We choose the error
level before making the experiment; thus, a small size or a big size experiment can
have the same error level. After the experiment is performed, we behave (accepting
or rejecting the null hypothesis) as if we had probability ¼ 100% of being right,
hoping to be wrong a small number of times along our career.
The error level is a measure of the percentage of times we will be right: This
is not true. For example, you may accept an error level of a 5% and ﬁnd along your
career that your data was always distributed far away from the limit of the rejection
(Fig. 1.3).
P-value is the probability of the null hypothesis being true, i.e. not having
differences between treatments: This is not true. The P-value gives the probabil-
ity of ﬁnding the current sample value or a higher value, but we are not interested in
how probable it is to ﬁnd our sample value, but in how probable our hypothesis is,
and classic statistic does not have an answer for this question. A conscious statisti-
cian knows what a P-value means, but the problem is that P-values suggest more
evidence to the average researcher than they actually have. For example, Berger
5Neyman and Pearson never used P-values because they are not needed for accepting or rejecting
hypothesis. However, it is noticeable how both Neyman and Pearson signiﬁcance and Fisher P-
values are now blended in modern papers just because now P-values are easy to compute. Often
they create more confusion than help in understanding results.
6Moreover, as Goodman (1993) says, this is like having a student ranking the 15th out of
100 students and report that she is ‘within the top 15th percent’ of the class.
1.2
Test of Hypothesis
7

and Sellke (1987) have noticed that a P-value of 0.05 corresponds to a probability
of 30% of the null hypothesis being true, instead of 5% as the P-value suggests.
Johnson (2013) has showed that, when testing common null hypothesis, about one
quarter of signiﬁcant ﬁndings are false. This means that people interpreting
P-values as the probability of the null hypothesis being true are wrong and fare
away about the real evidence of this. Johnson (2013) recommends the use of
P-values of 0.005 as a new threshold for signiﬁcance.
P-value is a measure of ‘signiﬁcance’: This is not true. A P-value of 2% does not
mean that the difference between treatments is ‘signiﬁcant at a 2%’, because if we
repeat the experiment, we will ﬁnd another P-value. We cannot ﬁx the error level of
our experiment depending on our current result because we drive conclusions not
only from our sample but also from all possible repetitions of the experiment.
Notice that if a P-value is small enough for establishing signiﬁcant differences, if
we repeat the experiment, the new P-value will not necessarily be that small. For
example, consider that the true value m1  m2 is placed at the 5% level (Fig. 1.4).
Then we take a sample and ﬁnd that the difference between treatments obtained
x1  x2 is also placed at the 5% level (this is not a rare supposition, since the
samples should be distributed near the true value). We will say that the difference
between treatments is signiﬁcant. However, when repeating the experiment, as the
new samples will be distributed around the true value m1  m2, half of the samples
will give signiﬁcant differences between treatments (P < 0.05), and half of them
will not (P > 0.05). When repeating the experiment, we have the same probability
of obtaining signiﬁcant differences than not. Thus, a P-value of 5% gives the
impression of having more evidence than what we actually have.7 In practice, we
do not know where the true value is; thus, we do not know whether we are in the
situation of Fig. 1.4 or not.
x1 – x2
–
–
x1 – x2
–
–
H0: m1 – m2 = 0
m1 – m2
0
95%
Fig. 1.3 An error level of 5%
of being wrong when
rejecting the null hypothesis
was accepted, but along his
career, a researcher
discovered that his data
showed a much higher
evidence about the null
hypothesis being wrong
7Notice that this argument is independent of the power of the test. It applies whatever this power is.
8
1
Do We Understand Classic Statistics?

Signiﬁcant difference means that a difference exists: This is not always true.
We may be wrong once every twenty times, on average, if the error level is 5%. The
problem is that when measuring many traits, we may detect a false signiﬁcant
difference once every twenty traits.8 The same problem arises when we are
estimating many effects. It is not infrequent to see pathetic efforts of some authors
trying to justify some second or third order interaction that appears in an analysis
when all the other interactions are not signiﬁcant, without realising that this
interaction can be signiﬁcant purely by chance.
N.S. (non-signiﬁcant difference) means that there is no difference between
treatments: This is usually false. First, in agriculture and biology, treatments are
generally different because they are not going to be exactly equal. Two pig breeds
can differ in growth rate in less than a gram, but this is obviously irrelevant.
Secondly, in well-designed experiments, N.S. appears when the difference between
treatments is irrelevant, but this only happens for the trait for which the experiment
was designed; thus, other traits can have relevant differences between treatments,
but we obtain N.S. from our speciﬁc tests. The safest interpretation of N.S. is ‘we do
not know whether treatments differ or not’; this is Fisher’s interpretation for N.S.
Even if the differences are N.S., we can still observe a ‘tendency’: This
statement is nonsense. If we do not ﬁnd signiﬁcant differences between treatments
A and B, this means that now A is higher than B, but after repeating the experiment,
B can be higher than A. It is rather unfortunate that referees admit expressions like
this, even in competent scientiﬁc journals. Moreover, it often happens that the
N.S. differences are high, nothing that can be described as a ‘tendency’;
N.S. describes my state of ignorance, not the size of the effect.
Our objective is to ﬁnd whether two treatments are different: We are not
interested in ﬁnding whether or not there are differences between treatments,
5%
m1 – m2
x1 – x2
–
–
0
Fig. 1.4 Distribution of the
samples when the true value
is the same as the actual
sample, and the current
sample gives us a P-value of
5%. Notice that when
repeating the experiment, half
of the times, we will obtain
‘non-signiﬁcant’ differences
(P > 0.05). This example is
shown for one-tail test, but the
same applies to two-tail tests
8Once each twenty traits as a maximum if the traits are uncorrelated. If they are correlated, the
frequency of detecting false signiﬁcances is different.
1.2
Test of Hypothesis
9

because they are not going to be exactly equal. Our objective in an experiment is to
ﬁnd relevant differences. How big should a difference be in order to consider it as
relevant should be deﬁned before making the experiment. A relevant value is a
quantity under which differences between treatments have no biological or eco-
nomical meaning. Higher values will be also relevant, but we are interested in the
minimum value that can be considered relevant, because if two treatments differ in
a lower value, we will consider that they are not different for practical purposes,
i.e. for the purpose of our experiment. In classical statistics, the size of the experi-
ment is usually established for ﬁnding a signiﬁcant difference between two
treatments when this difference is considered relevant. The problem then is that
experiments are designed for one trait, but many other traits are often measured;
thus, signiﬁcant differences will not be linked to relevant differences for these other
traits, as we are going to see below.
Signiﬁcant difference means ‘relevant difference’: This is often false. In well-
designed experiments, a signiﬁcant difference will appear just when this difference
is relevant. Thus, if we consider before performing the experiment that 100 g/d is a
relevant difference between two treatments, we will calculate the size of our
experiment in order to ﬁnd a signiﬁcant difference when the difference from the
averages of our samples j x1  x2 j 100 g/d, and we will not ﬁnd a signiﬁcant
difference if it is lower than this. The problem arises when we analyse a trait other
than the one used for deﬁning the size of the experiment; but also in ﬁeld data,
where no experimental design has been made, or in poorly designed experiments. In
these cases, there is no link between the relevance of the difference and its
signiﬁcance. In these cases, we can ﬁnd:
1. Signiﬁcant differences that are completely irrelevant: This case is innocuous;
however, if signiﬁcance is confused with relevance, the author of the paper will
stress this result without reason, since the difference found is irrelevant. We will
always get signiﬁcant differences if the sample is big enough. If the sample is
high, when repeating an experiment many times, the average of the sample will
have a lower dispersion. For example, the average of milk production of the
daughters of a sire having only two daughters can be 4000 kg or 15,000 kg, but
the average of sires with 100 daughters will be much closer to the mean of the
population. Figure 1.5 shows a non-signiﬁcant difference that is signiﬁcant for a
larger sample. Conversely, if we throw away part of our sample, former signiﬁ-
cant differences become non-signiﬁcant. Thus, ‘signiﬁcance’ itself is of little
value; it only indicates whether the sample is big or not.9 This has been noticed
at least since 1938 (Berkson 1938), and it is a classical criticism to frequentist
hypothesis tests (see Johnson 1999 for a review).
9In simulation studies, it is easy to ﬁnd signiﬁcant differences by augmenting the number of
repeated simulations.
10
1
Do We Understand Classic Statistics?

2. Non-signiﬁcant differences that are relevant: This means that the size of the
experiment is not high enough. Sometimes experimental facilities are limited
because of the nature of the experiment, but relevant differences that are
non-signiﬁcant would mean that perhaps there is an important effect of the
treatment or perhaps not, we do not know but it is important to know it, and a
higher sample should be analysed.
3. Non-signiﬁcant differences that are irrelevant, but have high errors: Some-
times the estimated difference between treatments can be, by chance, near zero,
but if the standard error of it is high, the true difference may be much higher and
relevant. This is dangerous, because a small difference accompanied with a ‘N.
S.’ seems to be non-important, but it can be rather relevant indeed. For example,
if a relevant difference between treatments for growth rate is 100 g/d in pigs and
the difference between the selected and control populations is 10 g/d with a
s.e. of 150 g/d, when repeating the experiment, we may ﬁnd a difference higher
than 100 g/d, i.e. we can get a relevant difference. Thus, a small and ‘N.S.’
x1 – x2
–
–
n = 100
n = 10
m1 – m2
Fig. 1.5 Distribution of the
samples for two sample sizes.
‘Non-signiﬁcant’ differences
for n ¼ 10 can be signiﬁcant
for n ¼ 100
1.2
Test of Hypothesis
11

difference should not be interpreted as ‘there is no relevant difference’ unless the
precision of this difference is good enough, i.e. its conﬁdence interval is small.
4. Signiﬁcant differences that are relevant, but have high errors: This may lead
to a dangerous misinterpretation. Imagine that we are comparing two breeds of
rabbits for litter size. We decide that one kit will be enough to consider the
difference between breeds to be relevant. We obtain a signiﬁcant difference of
two kits (we get one ‘star’). However, the conﬁdence interval at a 95% proba-
bility of this estimation goes from 0.1 to 3.9 kits. Thus, we are not sure about
whether the difference between breeds is 2 kits, 0.1 kits, 0.5 kits, 2.7 kits or
whatever other value between 0.1 and 3.9. It may happen that the true difference
is 0.5 kits, which is irrelevant. However, typically, all the discussion of the
results is organised around the two and the ‘star’, saying ‘we found signiﬁcant
and important differences between breeds’, although we do not have this evi-
dence. The same applies when comparing our results with other published
results; typically the standard errors and conﬁdence intervals of both results
are ignored when discussing similarities or dissimilarities.
We always know what a relevant difference is: Actually, for some problems,
we do not know. A panel of experts analyse the aniseed ﬂavour of some meat, and
they ﬁnd differences of three points in a scale of ten points; is this relevant? Which
is the relevant value for enzyme activities? It is difﬁcult sometimes to precise the
relevant value, and in this case, we are completely disoriented when we are
interpreting the tables of results, because in this case we cannot distinguish between
the four cases we have listed before. This is an important problem, because we
cannot conclude anything from an experiment in which we do not know whether the
differences between treatments we ﬁnd are irrelevant or not. In Appendix 1.1, we
propose some practical solutions to this problem.
Tests of hypothesis are always needed in experimental research: For most
biological problems, we do not need any hypothesis test. The answer provided by a
test is rather elementary: Is there a difference between treatments? Yes or
No. However, this is not actually the question for most biological problems. In
fact, we know that the answer to this question is generally Yes, because two
treatments are not going to be exactly equal. The test only adds to our previous
information that one of the treatments is higher than the other one. However, in
most biological problems, our question is whether these treatments differ in more
than a relevant quantity. In order to answer this question, we should estimate the
difference between treatments accompanied by a measurement of our uncertainty.
This is more informative than comparing LS-means only, by showing whether they
are signiﬁcantly different, because as we have seen before, signiﬁcance is not
related to relevance but to sample size. There is a large amount of literature
recommending focusing more in conﬁdence intervals or other quantitative
measurements of uncertainty than in hypothesis tests (see Johnson 1999, or
Lecoutre and Poitevineau 2014, for a recent review on this controversy).
12
1
Do We Understand Classic Statistics?

1.3
Standard Errors and Confidence Intervals
1.3.1
Definition of Standard Error and Confidence Interval
If we take an inﬁnite number of samples, the sample mean (or the difference
between two sample means) will be distributed around the true value we want to
estimate, as shown in Fig. 1.1. The standard deviation of this distribution is called
‘standard error’ (s.e.), to avoid confusion with the standard deviation of the
population. A large standard error means that the sample averages will take very
different values, many of them far away from the true value. As we do not take
inﬁnite samples, just one, a large standard error means that we do not know how
close we are to the true value, but a small standard error means that we are close to
the true value because most of the possible sample averages when repeating the
experiment will be close to this true value.
When the distribution obtained by repeating the experiment is Normal,10 twice
the standard error around the true value will contain approximately 95% of the
samples.11 This permits the construction of the so-called conﬁdence intervals at
95% by establishing the limits within which the true value is expected to be found.
Unfortunately, we do not know the true value; thus, it is not possible to establish
conﬁdence intervals as in Fig. 1.1, and we have to use our estimate instead of the
true value to deﬁne the limits of the conﬁdence interval. Our conﬁdence interval is
approximately (sample average)  2 s.e.12 A consequence of this is that each time
we repeat the experiment, we have a new sample and thus a new conﬁdence
interval. For example, let’s assume we want to estimate the litter size of a pig
breed, and we obtain 10 piglets with a conﬁdence interval CI (95%) ¼ [9, 11]. This
means that if we repeat the experiment, we will get many conﬁdence intervals: [8,
10], [9.5, 11.5], etc., and a 95% of these intervals will contain the true value.
However, we are not going to repeat the experiment an inﬁnite number of times.
What shall we do? In classical statistics, we behave as if our interval would be one
of the intervals containing the true value (see Fig. 1.7). We hope, as a consequence
of our behaviour, to be wrong a maximum of 5% of times along our career.
10Computer programmes (like SAS) ask whether you have checked the Normality of your data, but
Normality of the data is not needed if the sample is large enough (see Chap. 10, Sect. 10.1.3).
Independently of the distribution of the original data, the average of a sample is distributed
Normally, if the simple size is big enough. This is often forgotten, as Fisher often complained
(Fisher 1925).
11The exact value is not twice but 1.96 times.
12For small samples, a t-distribution should be used instead of a Normal distribution, and the
conﬁdence interval is somewhat larger, but this is not important for this discussion.
1.3
Standard Errors and Confidence Intervals
13

1.3.2
Common Misinterpretations
The true value lies between  2 s.e. of the estimate: We do not know whether this
will happen or not. First, the distribution of the samples when repeating the
experiment might not be Normal. This is common when estimating correlation
coefﬁcients, which are close to 1 or to 1; it is nonsense to write a correlation
coefﬁcient as 0.95  0.10. Some techniques (e.g. bootstrap), taking advantage of
the easy computation with modern computers, can show the actual distribution of a
sample. A correlation coefﬁcient sampling distribution may be asymmetric, like in
Fig. 1.6. If we take the most frequent value as our estimate (0.9), the s.e. has little
meaning.
CI (95%) means that the probability of the true value to be contained in the
interval is 95%: This is not true. We say that the true value is contained in the
interval with probability P ¼ 100%, i.e. with total certainty. We utter that our
interval is one of the ‘good ones’ (Fig. 1.7). We may be wrong, but if we behave like
this, we hope to be wrong only 5% of the times as a maximum along our career. As
in the case of the test of hypothesis, we make inferences not only from our sample
but also from the distribution of samples in ideal repetitions of the experiment.
MODE
Correlation coefficient
–1.00
–0.9
–0.8
–0.7
–0.6
Fig. 1.6 Sampling
distribution of a correlation
coefﬁcient. Repeating the
experiment, the samples are
not distributed symmetrically
around the true value
[
]
[
]
[
]
[
]
[
]
[
]
[
]
m
5%
95%
mine is a
good one !
Fig. 1.7 Repeating the
experiment many times, 95%
of the intervals will contain
the true value m. We do not
know whether our interval is
one of these, but we assume
that it is. We hope not to be
wrong too many times along
our career
14
1
Do We Understand Classic Statistics?

The true value should be in the centre of the CI, not in the borders: We do
not know where the true value is. If the CI for differences in litter size is [0.1, 3.9],
the true value may be 0.1, 0.2, 2.0 and 3.9 or some other intermediate value between
the conﬁdence interval limits. In Fig. 1.7 we can see that some intervals have the
true value near one side and others near the centre. We expect to have more
intervals in which the true value is near the centre, but we do not know whether
our interval is one of these.
Conceptual repetition leads to paradoxes: Several paradoxes produced by
drawing conclusions not only from our sample but also from conceptual repetitions
of it have been noticed. The following one can be found, in a slightly different way,
in Berger and Wolpert (1984, pp. 91–92). Imagine we are measuring pH and we
know that the estimates will be Normally distributed around the true value when
repeating the experiment an inﬁnite number of times. We obtain a sample with ﬁve
measurements: 4.1, 4.5, 5, 5.5 and 5.9. We then calculate our CI as 95%. Suddenly,
a colleague tells us that the pH metre was broken, and it does not work if the pH is
higher than 6. Although we did not ﬁnd any measure higher than 6, repeating the
experiment an inﬁnite number of times, we will obtain a truncated distribution of
our samples (Fig. 1.8b). This means that we should change our conﬁdence interval,
since all possible samples higher than 6 would not be recorded. Then another
colleague tells us that the pH metre was repaired before we started our experiment,
and we write a paper changing the CI 95% to the former values. However, our
former colleague insists in that the pH metre was still broken; thus, we change again
our CI. Notice that we are changing our CI even though none of our measurements
lied in the area in which the pH metre was broken. We change our CI not because
we had wrong measures of the pH, but because if we would repeat the experiment
an inﬁnite number of times, this will produce a different distribution of our samples.
As we make inferences not only from our samples but also from conceptual
repetitions of the experiment, our conclusions are different if the pH metre is
broken although all our measurements were correct.
a
b
6
[4.1, 4.5, 5, 5.5, 5.9]
Fig. 1.8 After repeating an
experiment an inﬁnite number
of times, we arrive to
different conclusions,
whether our pH metre works
well (a) or whether it is
broken and does not measure
values higher than 6 (b), even
though all our measurements
were correctly taken
1.3
Standard Errors and Confidence Intervals
15

1.4
Bias and Risk of an Estimator
1.4.1
Unbiased Estimators
In classical statistics, we call error of estimation to the difference between the true
value u and the estimated value bu:
e ¼ u  bu:
We call loss function to the square of the error:
l bu; u
ð
Þ ¼ e2
and we call risk to the mean of the losses13:
R bu; u
ð
Þ ¼ E l bu; u
ð
Þ
½
 ¼ E e2


A good estimator will have a low risk. We can express the risk as
R bu;u
ð
Þ ¼ E e2
ð
Þ ¼ E e2 þ e2  e2
ð
Þ ¼ E e2
ð
Þ þ E e2  e2
ð
Þ ¼ e2 þ var e
ð Þ ¼ Bias2þ
var e
ð Þ, where we deﬁne bias as the mean of the errors e. An unbiased estimator
has a null bias. This property is considered particularly attractive in classical
statistics, because it means that when repeating the experiment an inﬁnite number
of times, the estimates are distributed around the true value like in Fig. 1.1.
Nevertheless, unbiasedness has not always been considered a particularly attractive
property of an estimator; Fisher considered that the property of unbiasedness was
irrelevant due to its lack of invariance to transformations (Fisher 1959,
pp. 142–143), as we will see below.
1.4.2
Common Misinterpretations
A transformation of an unbiased estimator leads to another unbiased estima-
tor: This is normally not true. In general, a transformation of an unbiased estimator
leads to an estimator that is not unbiased anymore. For example, it is frequent to
ﬁnd unbiased estimators for the variance and use them for estimating the standard
deviation by computing their square root. However, the square root of an unbiased
estimator of the variance is not an unbiased estimator of the standard deviation. It
is possible to ﬁnd unbiased estimations of the standard deviation, but they are not
the square root of the unbiased estimator of the variance (see, e.g. Kendall et al.
1994).
13All of this is rather arbitrary and other solutions can be used. For example, we may express the
error as a percentage of the true value, the loss function may be the absolute value of the error
instead of its square, and the risk might be the mode instead of the mean of the loss function, but in
this chapter, we will use the common deﬁnitions.
16
1
Do We Understand Classic Statistics?

Unbiased estimators should be always preferred: Not always. In general, the
best estimates are the ones with lower risk. As the risk is the sum of the bias plus the
variance of the estimator, it may happen that a biased estimator had a lower risk,
being a better estimator than an unbiased estimator (Fig. 1.9).
For example, take the case of the estimation of the variance. We can estimate the
variance as
bσ2 ¼ 1
k
X
n
1
yi  y
ð
Þ2
It can be shown that the bias, variance and risk of this estimator, using the
quadratic loss function we deﬁned before, are
Bias bσ2


¼ σ2  n  1
k
σ2;
var bσ2


¼ 2 n  1
ð
Þ
k2
σ4
Risk bσ2


¼ Bias2 þ var bσ2


¼
σ2  n  1
k
σ2

2
þ 2 n  1
ð
Þ
k2
σ4
Depending on the value of k, we obtain different estimators. To obtain the
estimator of minimum risk, we derive the risk with respect to k, equal to zero,
and obtain a value of k ¼ n + 1. When k ¼ n, we obtain the maximum likelihood
(ML) estimator, and when k ¼ n  1, we obtain the residual (or restricted)
maximum likelihood estimator (REML) (see Blasco 2001). Notice that when
m
Fig. 1.9 An example of
biased estimator (blue) that is
not distributed around the true
value ‘m’, but has lower risk
than an unbiased estimator
(red) that is distributed
around the true value with a
much higher variance
1.4
Bias and Risk of an Estimator
17

k ¼ n  1 the estimator is unbiased, which is one of the reasons of REML users to
prefer this estimator. However, the risk of REML is higher than the risk of ML
because its variance is higher; thus, ML should be preferred or, even better, the
minimum risk estimator.
1.5
Fixed and Random Effects
1.5.1
Definition of ‘Fixed’ and ‘Random’ Effects
Churchill Eisenhart proposed in 1947 a distinction between two types of effects.
The effect of a model was ’ﬁxed’ if we were interested in its particular value and
‘random’ if it could be considered just one of the possible values of a random
variable. Consider, for example, an experiment in which we have 40 sows in four
groups of 10 sows each, and each sow has ﬁve parities. We feed each group with a
different diet, and we are interested in knowing the effect of the diet in the litter size
of the sows. The effect of the diet can be considered as a ‘ﬁxed’ effect, because we
are interested in ﬁnding the food that leads to higher litter sizes, and we consider
that, if repeating the experiment, the effect of each diet on litter size will be the
same. Some sows are more proliﬁc than others are, but we are not interested in the
proliﬁcacy of a particular sow; thus, if the sows have been assigned randomly to
each diet, we consider that each sow effect is a ‘random’ effect. Repeating the
experiment, we would have different sows with different sow effects, but these
effects would not change our inferences about diets because sows are assigned
randomly to each diet.
When repeating an experiment an inﬁnite number of times, a ﬁxed effect has
always the same values, whereas a random effect changes in each repetition of the
experiment. Repeating our experiment, we would always give the same four diets,
but the sows will be different; thus, the effect of the food will be always the same,
but the effect of the sow will randomly change in each repetition. In Fig. 1.10, we
can see how the true value of the effects and their estimates are distributed. When
repeating the experiment, the true value of the ﬁxed effect remains constant, and all
its estimates are distributed around this unique true value. In the case of the random
effect, each repetition of the experiment leads to a new true value; thus, the true
value is not constant, it varies and is distributed around its mean.
Notice that the errors are the difference between true and estimated values in
both cases, but in the case of random effects, they are not the distance between the
estimate and the mean of the estimates, because the true value changes in each
repetition of the experiment. As random values change in each repetition, instead of
‘estimating’ random values, we often say ‘predicting’ random values.
18
1
Do We Understand Classic Statistics?

1.5.2
Shrinkage of Random Effects Estimates
The estimate (the prediction) of a random effect depends on the amount of data
used. Let us take a simple model in which we measure the growth of chicken under
several diets, with a different number of chickens per diet.
If we estimate the effect of a diet as a ﬁxed effect, the effect of a diet will be the
average of the chicken’s growth under this diet:
buF ¼ 1
n
X
yi
However, estimating the diet effect as a random effect, the effect of diet will be:
buR ¼
1
n þ σ2ε
σ2u
X
yi
where σ2
ε is the variance of the residual effects on growth not explained by the diet,
i.e. y ¼ u + ε then σ2
y ¼ σ2
u þ σ2
ε. We will see this different way of estimating ﬁxed
or random effects in Chap. 7.
Notice that when ‘n’ is high, both estimates are similar, but when ‘n’ is small, the
random estimate suffers a ‘shrinking’ and takes a smaller value than when the effect
is considered as ﬁxed. The importance of this shrinking will depend on the number
of data used for estimating the random effect. This is well known by geneticists,
who evaluate animals considering their genetic values as random. An example is
developed in Appendix 1.3.
e
e
u
û4 û1
û
û3
û2
FIXED
RANDOM
e
e
e
u3
u1 u2
û
u
û1
û3
û2
Fig. 1.10 Distribution of the effects and their estimates when repeating the experiment an inﬁnite
number of times. When the effects are ﬁxed, the true value is constant, but when the effect is
random, it changes its value in each repetition. In red, the distribution of the true values. In blue,
the distribution of the estimates
1.5
Fixed and Random Effects
19

As we will see later, the researcher is sometimes faced to the dilemma of
considering an effect as ﬁxed or random, particularly when correcting for noise
effects. If some levels of a noise effect have few data, they will be poorly estimated,
which could affect the results, but if the noise is considered random, this correction
will be small. This is why it is common to consider random an effect with many
levels and few data in each level. The other side of the problem is that the
corrections actually applied in these cases are very small; thus, the decision of
taking an effect as random or ﬁxed is not always clear.
1.5.3
Bias, Variance and Risk of an Estimator when the Effect is
Fixed or Random
In the case of ﬁxed effects, since the true value is constant, u ¼ E(u), when the
estimator is unbiased, the estimates are distributed around the true value. In the case
of random effects, the true value is not constant, and when the estimator is
unbiased, the average of the estimates will be around the average of the true values,
a much less attractive property:14
FIXED:
Bias ¼ E(e) ¼ E(u  ^u) ¼ E(u)  E(^u) ¼ u  E(^u)
RANDOM:
Bias ¼ E(e) ¼ E(u  ^u) ¼ E(u)  E(^u)
The variances of the errors are also different (see Appendix 1.2 for a
demonstration):
FIXED:
var(e) ¼ var(u  ^u) ¼ var(^u)
RANDOM:
var(e) ¼ var(u  ^u) ¼ var(u)  var(^u)
The best estimators are the ones with the lowest risk; in the case of unbiased
estimators, as Bias ¼ 0, the best ones have the lowest error variance. For ﬁxed
effects, as the true value ‘u’ is a constant, var(u) ¼ 0, thus the variance of the error is
the same as the variance of the estimator var(^u), and the best unbiased estimators
are the ones with smallest variance. In the case of random effects, the true values are
not constant, and the variance of the error is the difference between the variances of
the true and estimated values. Thus, in the case of random effects, the best estimator
is the one with a variance as close as possible to the variances of the true values,
because this minimizes the variance of the error. The source of the confusion is that
a good estimator is not the one with small variance, but the one with small error
variance. A good estimator will give values close to the true value in each
14Henderson (1973) has been criticised for calling the property E(u) ¼ E(^u) ‘unbiasedness’, in
order to defend that his popular estimator ‘BLUP’ was unbiased. This property should always
mean that the estimates are distributed around the true value. In the case of random effects, this
means u ¼ E(^u|u), a property that BLUP does not have (see Robinson 1991).
20
1
Do We Understand Classic Statistics?

repetition, the error will be small and the variance of the error will be small. In the
case of ﬁxed effects, this variance of the error is the same as the variance of the
estimator, and in the case of random effects, the variance of the error is small when
the variance of the estimator is close to the variance of the true value.
1.5.4
Common Misinterpretations
An effect is ﬁxed or random due to its nature: This is not always true. In the
example before, we might have considered the four types of foods as random
samples of all different types of food. Thus, when conceptually repeating the
experiment, we would conceptually change the food.15 Conversely, we might
have considered the sow as a ‘ﬁxed’ effect, and we could have estimated it, since
we had ﬁve litters per sow.16 Thus, the effects can be taken as ﬁxed or random
depending on our interests.
We are not interested in the particular value of a random effect: Sometimes
we can be interested in it. A particular case in which it is interesting to consider the
effects as random is the case of predicting genetic values. Using Mendel’s laws, we
know the relationships between relatives; thus, we can use this prior information
when the individual genetic effects are considered random effects. Appendix 1.3
gives an example of this prediction.
Even for random effects to be unbiased is an important property: The
property of unbiasedness is not particularly attractive for random effects, since
when repeating the experiment the true values change as well and the estimates are
not distributed around the true value. We have seen before that, even for ﬁxed
effects, unbiasedness may be considered rather unattractive, since usually it is not
invariant to transformations.
BLUP is the best possible predictor of a genetic random value: Animal
breeding values are commonly estimated (predicted) by BLUP (best linear unbiased
predictor, Henderson 1973). The word ‘best’ is somewhat misleading because it
seems that BLUP is the best possible predictor, but we can have biased predictors
with lower risk than unbiased ones. The reason for searching predictors only among
the unbiased ones is that there are an inﬁnite number of possible biased predictors
with the same risk, depending on their bias and their variance. By adding the
condition of unbiasedness, we ﬁnd a single one, called BLUP, which is not the
best possible predictor, but the best among the unbiased ones. In Chap. 7, Sect.
7.3.2, we will develop BLUP from a Bayesian perspective.
15That is, imagining that we are repeating the experiment, we imagine we change the food.
16Fisher, considered that the classiﬁcation of the effects in ﬁxed and random was worse than
considering all the effects as random, as they were considered before Eisenhart’s proposal (Yates
1990).
1.5
Fixed and Random Effects
21

1.6
Likelihood
1.6.1
Definition
The concept of likelihood and the method of maximum likelihood (ML) were
developed by Fisher between 1912 and 1922, although there are historical
precedents attributed to Bernoulli, Lambert and Edgeworth as we said in the
historical introduction. By 1912, the theory of estimation was in an early state
and the method was practically ignored. However, Fisher (1922) published a paper
in which the properties of the estimators were deﬁned, and he found that this
method produced estimators with good properties, at least asymptotically. The
method was then accepted by the scientiﬁc community and it is now
frequently used.
Consider ﬁnding the average weight of rabbits of a breed at 8 weeks of age. We
take a sample of one rabbit, and its weight is y0 ¼ 1.6 kg. The rabbit can come from
a population Normally distributed with a mean of 1.5 kg or from other population
with a mean of 1.8 kg or from many other possible populations. Figure 1.11 shows
the probability density functions of several possible populations from which this
rabbit can come from, with population means of m1 ¼ 1.50 kg, m2 ¼ 1.60 kg and
m3 ¼ 1.80 kg. Notice that, at the point y0, the probability density of the ﬁrst and
third population f(y0|m1) and f(y0|m3) is lower than the second one f(y0|m2). It looks
very unlikely that a rabbit of 1.6 kg comes from a population with a mean of 1.8 kg.
Therefore, it seems more likely that the rabbit comes from the second population.
All the values f(y0|m1), f(y0|m2), f(y0|m3), etc. are called ‘likelihoods’ and show
how ‘likely’ we would have obtained our sample y0 if the true value of the mean
would have been m1, m2, m3, etc. (Fig. 1.12).
These likelihoods can be represented for each value of the means. They deﬁne a
curve with a maximum in f(y0|m2) (Fig. 1.13). This curve varies with m, and the
sample y0 is a ﬁxed value for all those probability density functions. It is obvious
that the new function deﬁned by these values is not a probability density function,
since each value belongs to a different probability density function.
f(y|m1)
f(y|m2)
f(y|m3)
f(y0|m1)
m1 = 1.5
y0 = 1.6
y0 = 1.6
m2 = 1.6
m3 = 1.8
f(y0|m2)
f(y0|m3)
a
b
c
y0 = 1.6
Fig. 1.11 Three likelihoods for the sample y0 ¼ 1.6: (a) likelihood if the true mean of the
population is 1.5, (b) likelihood if the true mean of the population is 1.6 and (c) likelihood if the
true mean of the population is 1.8
22
1
Do We Understand Classic Statistics?

We have a problem of notation here, because here the variable is ‘m’ instead of
‘y’. Speaking about a family of probability density functions f(y0|m1), f(y0|m2), f(y0|
m3), etc. for a given y0 is the same as speaking about a function L(m|y0) that is not a
probability density function.17 However this notation hides the fact that L(m|y0) is a
f(y|m1)
f(y|m2)
f(y|m3)
m1
y0 = 1.6
m2
m3
x
Fig. 1.12 Three likelihoods
for the sample y0 ¼ 1.6
f(y0|m1)
f(y0|m)
f(y0|m2)
f(y0|m3)
m1
y0 = 1.6
m2
m3
m
Fig. 1.13 Likelihood curve.
It is not a probability because
its values come from different
distributions, but it is a
rational degree of belief. The
notation stresses that the
variable (in red) is m and not
y0, which is a given ﬁxed
sample
17Some classic texts of statistics (Kendall et al. 1994) contribute to the confusion by using the
notation L(y|m) for the likelihood. Moreover, some authors distinguish between ‘given a parame-
ter’ (always ﬁxed) and ‘giving the data’ (which are random variables). They use (y|m) for the ﬁrst
1.6
Likelihood
23

family of probability density functions indexed at a ﬁxed value y ¼ y0. We will use
a new notation, representing the variable in red colour and the constants in black
colour. Then f(y0|m) means a family of probability density functions, in which the
variable is m, that are indexed at a ﬁxed value y0. For example, if these Normal
functions of our example are standardised (s.d. ¼ 1), then the likelihood will be
represented as:
f y0jm
ð
Þ ¼
1ﬃﬃﬃﬃﬃ
2π
p
exp  y0  m
ð
Þ2
2
"
#
¼
1ﬃﬃﬃﬃﬃ
2π
p
exp  1:6  m
ð
Þ2
2
"
#
where the variable is in red colour. We will use ‘f’ exclusively for probability
density functions in a generic way, i.e. f(x) and f(y) may be different functions
(e.g. Normal or Poisson), but they will be always probability density functions.
1.6.2
The Method of Maximum Likelihood
Fisher (1912) proposed to take the value of m that maximised f(y0|m) because from
all the populations deﬁned by f(y0|m1), f(y0|m2), f(y0|m3), etc., this is the one that if
this were the true value, the sample would be most probable. Here the word
probability can lead to some confusion since, as we have seen, these values belong
to different probability density functions, and the likelihood function deﬁned taking
them is not a probability function. Thus, Fisher preferred to use the word likelihood
for all these values.18
Fisher (1912, 1922) not only proposed a method of estimation but also proposed
the likelihood as a degree of belief, different from the probability, but allowing
expressing uncertainty in a similar manner. What Fisher proposed was to use the
whole likelihood curve and not only its maximum, a practice rather unusual
nowadays (Fig. 1.14).19 Today, frequentist statisticians typically use only the
maximum of the curve because it has good properties in repeated sampling.
Repeating the experiment an inﬁnite number of times, the estimator will be
distributed near the true value, with a variance that can also be estimated. However,
all those properties are asymptotic; thus, there is no guarantee about the goodness of
the estimator when samples are small. Besides, the ML estimator is not necessarily
the estimator that minimizes the risk. Nevertheless, the method has an interesting
property, apart from its asymptotic frequentist properties: any reparameterization
leads to the same type of estimator (Appendix 1.4). For example, the ML estimator
of the variance is the square of the ML estimator of the standard deviation, and in
case and (m;y) for the second. Likelihood can be found in textbooks as L(m|y), L(y|m), f(y|m) and L
(m;y).
18Speaking strictly, these quantities are densities of probability. As we will see in Sect. 3.3.1,
probabilities are areas deﬁned by f(y)Δy.
19In this ﬁgure, as in other ﬁgures of the book, we do not draw a known function like a Normal,
Poisson, Inverted gamma, etc., but functions that help to understand the concept proposed.
24
1
Do We Understand Classic Statistics?

general, a function of a ML estimator is a ML estimator as well. This was a key
property for Fisher.
From a practical point of view, the ML estimator is an important tool for the
applied researcher. The frequentist school found a list of properties that good
estimators should have, but there are no rules about how to ﬁnd these estimators.
Maximum likelihood is a way of obtaining estimators with (asymptotically) desir-
able properties. It is also possible to ﬁnd a measurement of precision from the
likelihood function itself. If the likelihood function is sharp, its maximum gives a
more likely value of the parameter than other values near it. Conversely, if the
likelihood function is rather ﬂat, other values of the parameter will be almost as
likely as the one that gives the maximum to the function. This allowed Fisher to
propose interesting concepts like ‘amount of information’ that we will see in
Chap. 10, Sect. 10.3.1, providing a way for estimating (asymptotically) standard
errors. The frequentist school also discovered that the likelihood was useful for
constructing hypothesis tests, since the likelihood ratio between the null and the
alternative hypothesis has good asymptotical frequentist properties. We will come
back to this in Chap. 10, Sect. 10.2.1.
1.6.3
Common Misinterpretations
The method of maximum likelihood ﬁnds the estimate that makes the sample
most probable: This is strictly nonsense, since each sample has its own probability
depending on the true value of the distribution from which it comes. For example, if
the true value of the population of Fig. 1.9 is the case c (mTRUE ¼ m3 ¼ 1.8), our
sample y0 ¼ 1.6 is rather improbable, but its probability is not modiﬁed just because
we use a maximum likelihood method to estimate the true value of m. Therefore,
the method of ML is not the one that makes the sample most probable. This method
provides a value of the parameter that if this were the true value, the sample would
be most probable.20 As Fisher says:
a
b
f(y|m)
Fig. 1.14 Likelihood curve.
Here m can take ‘likely’ the
values ‘a’ or ‘b’; however, the
frequentist school will only
take the maximum at ‘a’
20Some authors say that likelihood maximises the probability of the sample before performing the
experiment. They mean that f(y|m) can be considered a function of both y and m before taking
1.6
Likelihood
25

We deﬁne likelihood as a quantity proportional to the probability that, from a population
having that particular value of ρ, a sample having the observed value r, should be obtained.
Ronald Fisher (1921)
A likelihood four times bigger than other likelihood gives four times more
evidence in favour of the ﬁrst estimate: This is not true. Likelihoods are not
quantities that can be treated as probabilities because each value of the likelihood
comes from a different distribution. Then they do not follow the laws of probability
(e.g. they do not sum up to one, the likelihood of excluding events is not the sum of
their likelihoods, etc.). Therefore, a likelihood four times higher than another one
does not lead to a ‘degree of rational belief’ four times higher. We compare
likelihood with probability in Chap. 9, Sect. 9.1.2. There is an obvious risk of
confounding likelihood and probability, as people working in QTL should know.21
Appendix 1.1
Definition of Relevant Difference
In both classical and Bayesian statistics, it is important to know which difference
between treatments should be considered ‘relevant’. The minimum relevant value
needed to take a decision is usually obtained under economic considerations, for
example, which difference between treatments justiﬁes doing an investment or
changing a diet for another one. In classical design of experiments, a ‘relevant’
value of the difference between treatments is deﬁned in order to ﬁnd a signiﬁcant
difference if this value, or a higher one, is found. However, there are traits like the
results of a sensory panel test, or the enzymatic activities, for which it is difﬁcult to
determine what a minimum relevant difference between treatments is. To ﬁnd
signiﬁcant differences is not a solution to this problem because we know that if
the sample is big enough, we will always ﬁnd signiﬁcant differences.
We can consider that a relevant difference (i.e. a minimum relevant value for this
difference) should be expressed as a proportion of the variability of the trait. Having
one ﬁnger more in a hand is relevant because the variability of this trait is very
small, but to have one hair more in the head is not so relevant (although for some of
us it is becoming relevant with the age). Take an example of pigs from Tribout et al.
(2010): dressing percentage has a very small variability; its mean value is 77.6 but
its standard deviation is only 1.8. If a treatment would increase a carcass yield of
samples, and a value of m can be found that maximises f(y|m) for each given y. Again, it maximises
the density of probability only if m is the true value, and the sentence before performing the
experiment is a clear abuse of the common language.
21Figures of marginal likelihoods, common in papers searching for QTL, are often interpreted as
probabilities. Incidentally, one of the founders of the frequentist theory, Von Mises (1957,
pp. 157–158), accuses Fisher of exposing with great care the differences between likelihood and
probability, just to forget it later and use the word ‘likelihood’ as we use ‘probability’ in common
language.
26
1
Do We Understand Classic Statistics?

one standard deviation, this would suppose a great increment, although 1.8 is only
2% of the mean. Conversely, if litter size in pigs is 14 (see, e.g. Lundgren et al.
2010), 2% of the mean is 0.28 piglets, which is rather irrelevant. If we take a list of
the important traits in animal production, we will see that the economic relevance
appears at a quantity placed between one-half and one-third of the standard devia-
tion of the trait for most of them. Therefore, we can postulate a quantity placed
between one-half and one-third of the standard deviation of the trait for all traits in
which it is not possible to argue economical or biological reasons. This sounds
arbitrary, but it is even more arbitrary to compare treatments without any indication
of the importance of the differences found in the samples. Similar postulates can be
proposed using the variance instead of the standard deviation; for example, it is
common to consider a relevant effect of a QTL (quantitative trait locus) or a gene
from a 10% of the variance, which is approximately one-third of the standard
deviation. These ﬁgures should be considered not as thresholds but as rough
indications of the importance of the effects, in order to help the discussion of the
results obtained in the experiments. Other values for relevance (i.e. for the minimum
relevant value) can be postulated, but if they are not based on economical or
biological considerations, it is convenient to refer them to a fraction of the standard
deviation of the trait.
Another solution, that we will see in Chap. 2, would be to compare ratios of
treatments instead of differences between treatments. It can be said that a treatment
has an effect 10% bigger than the other one, or its effect is a 92% of the other one,
which is more expressive than ﬁnding a difference between treatments of 1.7 points in
a scoring for liver ﬂavour. This can be complex in classical statistics, mainly because
the s.e. of a ratio should be calculated making approximations that do not always work
well,22 but is trivial for Bayesian statistics when combined with MCMC.
Appendix 1.2
We estimate ‘u’ from the data. If ‘u’ and the data ‘y’ are jointly Normally
distributed, their relationship is linear:
u ¼ b y þ e ¼ bu þ e
and cov(^u, e) ¼ 0. In this case,
σ2
u ¼ σ2
bu þ σ2
e
!
σ2
e ¼ σ2
u  σ2
bu
Notice that when the joint distribution is not Normal, cov(^u, e) may be different
from zero, and it should be considered. We assume in our models that the random
effects depend on many factors with small effect each one; if so, we can conclude
22For example, the delta method, commonly used in quantitative genetics to estimate s.e. of ratios,
does not work well for genetic correlations (Visscher 1998).
Appendix 1.2
27

from the ‘central limit theorem’ that random effects are Normally distributed. This
theorem proves that under quite general conditions, the sum of many small inde-
pendent effects tends to the Normal distribution.
Appendix 1.3
Let us estimate the genetic value ‘u’ of a bull as a ﬁxed value or as a random value,
using the average value of milk production of its daughters ‘y’.
The estimate of the genetic value of the bull is, as a ﬁxed effect, buF, and taking
into account that a bull only transmits half of the genetic information to his
daughters:
buF ¼ 2  y
For estimating (predicting) the genetic value as a random effect buR, we will use a
linear prediction using the average production of the daughters:
u ¼ b  y þ e ¼ buR þ e
buR ¼ b  y
where b is a regression coefﬁcient:
b ¼ cov u; y
ð
Þ
var y
ð Þ
½
2
We assume in the example that the daughters come from different dams, i.e. they
are half sibs, as usual when a bull is evaluated. We also know that the only thing in
common that sire and daughters have is that daughters have half of their genetic
information from the father. This is also the only thing in common between
daughters. We know that the covariance between father and daughter and the
covariances between daughters are, respectively:
cov u; y
ð
Þ ¼ cov u; 1
n
X
n
1
yi
 
!
¼ 1
n n  cov u; yi
ð
Þ ¼ 1
2 σ2
u
cov yi; yk
ð
Þ ¼ 1
2  1
2  σ2
u ¼ 1
4 σ2
u
var y
ð Þ ¼ var 1
n
X
n
1
yi
 
!
¼ 1
n2
nσ2
y þ n n  1
ð
Þcov

yi; yk



¼ 1
n
σ2
y þ n  1
ð
Þ1
4σ2
u


28
1
Do We Understand Classic Statistics?

b ¼ cov u; y
ð
Þ
var y
ð Þ
¼
1
2 σ2
u
1
n σ2
y þ n  1
ð
Þ1
4σ2
u

 ¼
n  1
2 σ2
u
σ2
y þ n  1
ð
Þ  1
4 σ2
u
When n ¼ 1 and taking into account that σ2
u  σ2
y
b ¼ 1
2  σ2
u
σ2
y
 1
2
And when n ! 1
b ¼ 2
This means that there is a ‘shrinkage’ when estimating ‘u’ as a random effect,
depending on the number of daughters we have. This is reasonable. If we estimate
the value of a bull only by the average of the daughters, a bull with only one
daughter having by chance a very high value (say 20,000 kg of milk) is
overestimated, but overestimation is much more difﬁcult when the bull has
100 daughters. Thus, bulls with only one daughter can be overestimated, and if
we take as a selection criterion only the value of the current average of a bull’s
daughters, we will select only overestimated bulls with little information. By
evaluating the bull as a random effect, we shrink this value and move it towards
the average of the population according to the amount of daughters the bull has;
thus, a bull having a daughter of 20,000 kg of milk can see its genetic value
estimated as only 12,500 kg. Notice that this is the value of the estimate, which is
different from the accuracy. Of course, a bull with only one daughter will have a
lower accuracy than a bull with 100 daughters, but we are now stating that the
estimate of its genetic value will also be lower.
Appendix 1.4
A transformation of a ML estimator is also a ML estimator of the new parameter.
For example, if we have a ML estimator of the variance, eσ2
ML , the ML of the
standard deviation is bσML ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃ
eσ2
ML
q
. It is intuitively reasonable that when our
sample has maximum probability for a ML estimator,23 it also has maximum
probability for a transformation of it.
To ﬁnd the ML estimator of θ:
∂f yjθ
ð
Þ
∂θ
¼ 0
23Remember, this happens when the estimator takes the true value.
Appendix 1.4
29

If we have a transformed variable, for example, g(θ), to ﬁnd the ML of g(θ) what
we need to solve:
∂f yjg θ
ð Þ
ð
Þ
∂g θ
ð Þ
¼ 0
But notice that:
f yjθ
ð
Þ ¼ f yjg θ
ð Þ
ð
Þ
because if θ is given, all the transformations are also given. Now:
∂f yjθ
ð
Þ
∂θ
¼ ∂f yjg θ
ð Þ
ð
Þ
∂θ
 ∂g θ
ð Þ
∂g θ
ð Þ ¼ ∂f yjg θ
ð Þ
ð
Þ
∂g θ
ð Þ
 ∂g θ
ð Þ
∂θ
¼ 0
As ∂g θ
ð Þ
∂θ
6¼ 0 because θ is not a constant, then:
∂f yjg θ
ð Þ
ð
Þ
∂g θ
ð Þ
¼ 0
and the same value for θ is obtained solving both equations; therefore g bθML


is the
ML estimator of g(θ).
References
Barnett V (1999) Comparative statistical inference. Wiley, Chichester
Bayarri MJ, Berger JO (2004) The interplay of Bayesian and frequentist analysis. Stat Sci
19:58–80
Bellhouse DR (2004) The Reverend Thomas Bayes, FRS: a biography to celebrate the tercente-
nary of his birth. Stat Sci 19:3–43
Berger JO, Sellke T (1987) Testing a point null hypothesis: the irreconcilability of P-values and
evidence. J Amer Stat Assoc 82:112–122
Berger JO, Wolpert RL (1984) The likelihood principle, Institute of Mathematical Statistics.
Lecture Notes—Monograph Series. Purdue University
Berkson J (1938) Some difﬁculties of interpretation encountered in the application of the
chi-squaretest. J Am Stat Assoc 33:526–542
Blasco A (2001) The Bayesian controversy in animal breeding. J Anim Sci 79:2023–2046
Childers T (2013) Philosophy and probability. Oxford University Press, Oxford
de Finetti B (1937) La pre´vision: ses lois logiques, ses sources subjectives. Annales de l’Institut
Henri Poincaire´ 7:1–68. Translated in Kyburg HE, Smokler HE (1964) Studies in subjective
probability. Wiley, New York
Efron B, Hastie T (2016) Computer age statistical inference. Cambridge University Press,
New York
Fienberg SE (2006) When did Bayesian inference become “Bayesian”? Bayesian Anal 1:1–40
Fisher RA (1912) On an absolute criterion for ﬁtting frequency curves. Messenger Math
41:155–160. Reprinted in Stat Sci 1997, 12:39–41
30
1
Do We Understand Classic Statistics?

Fisher R (1921) On the “probable error” of a coefﬁcient of correlation deduced from a small
sample. Metron 1:3–32
Fisher R (1922) On the mathematical foundations of theoretical statistics. Phil Trans A
222:309–368
Fisher R (1925) Statistical methods for research workers. Oliver and Boyd, Edinburgh
Fisher R (1935) The logic of inductive inference. J R Stat Soc 98:39–82
Fisher R (1950) Contributions to mathematical statistics. Wiley, New York
Fisher R (1959) Statistical methods and scientiﬁc inference, 2nd edn. Oliver and Boyd, Edinburgh
Gauss CF (1809) Theoria motus corporum coelestium in sectionibus conicis solem ambientium
(trans: Davis CE, 1963). Dover, New York
Gelfand AE, Smith FM (1990) Sampling-based approaches to calculating marginal densities. J Am
Stat Assoc 85:398–409
Geman S, Geman D (1986) Stochastic relaxation, Gibbs distributions and the Bayesian restoration
of images. IEEE Trans Pattern Anal Mach Intell 6:721–742
Goodman SN (1993) p-values, hypothesis tests and likelihood: implications for epidemiology of a
neglected historical debate. Am J Epidemiol 137:485–496
Hald A (1998) A history of mathematical statistics from 1750 to 1930. Wiley, New York
Henderson CR (1973) Sire evaluation and genetic trends. In: Proc. Anim. Breed. and Genet. Symp.
in honor of Dr. J. L. Lush. Blacksburg, Virginia, pp 10–41
Howie D (2002) Interpreting probability: controversies and developments in the early twentieth
century. Cambridge University Press, New York
Jeffreys H (1939/1961). Theory of probabilities, 1st and 3rd edn. Clarendon Press, Oxford
Johnson DH (1999) The insigniﬁcance of statistical signiﬁcance testing. J Wildl Manag
63:763–772
Johnson
VE
(2013)
Revised
standards
for
statistical
evidence.
Proc
Natl
Acad
Sci
110:9313–19317
Kendall MG (1961) Daniel Bernoulli on maximum likelihood. Biometrika 48:1–8
Kendall M, Stuart A, Ord K (1994) Kendall’s advanced theory of statistics, volume 1: distribution
theory. Arnold, London
Lecoutre B, Poitevineau J (2014) The signiﬁcance test controversy revisited. Springer, New York
Lundgren H, Canario L, Grandinson K, Lundeheim N, Zumbach B, Vangen O, Rydhmer L (2010)
Genetic analysis of reproductive performance in Landrace sows and its correlation to piglet
growth. Livest Sci 128:173–178
McGrayne SB (2011) The theory that would not die. Yale University Press, New Haven, NJ
Metropolis N (1987) The beginning of the Monte Carlo method. Los Alamos Sci 15(Special
Issue):125–130
Metropolis N, Ulam S (1949) The Monte Carlo method. J Am Stat Assoc 44:335–341
Mill JS (1848) On liberty. Reprinted in 2006 by Longman
Neyman J (1977) Frequentist probability and frequentist statistics. Synthese 36:97–131
Neyman J, Pearson E (1933) On the problem of the most efﬁcient test of statistical hypotheses. Phil
Trans R Soc 231A:289–337
Popper K (1934) Logik der Forschung. Springer
Ramsey FP (1931) Truth and probability. In: Braithwaite RB (ed) The foundation of mathematics
and other logical essays. Routledge & Kegan, London
Robinson GK (1991) That BLUP is a good thing: the estimation of random effects. Stat Sci
6:15–51
Sellke T, Bayarri MJ, Berger JO (2001) Calibration of P-values for testing precise null hypotheses.
Am Stat 55:62–71
Sorensen DA, Wang CS, Jensen J, Gianola D (1994) Bayesian analysis of genetic change due to
selection using Gibbs sampling. Genet Sel Evol 26:333–360
Stigler SM (1983) Who discovered Bayes theorem? Am Stat 37:290–296
Stigler SM (2013) The true title of Bayes’s essay. Stat Sci 28(3):283–288
Student (1908) On the probable error of a mean. Biometrika 6:1–25
References
31

Tribout T, Caritez JC, Gruand J, Bouffaud M, Guillouet P, Billon Y, Pe´ry C, Laville E, Bidanel JP
(2010) Estimation of genetic trends in French Large White pigs from 1977 to 1998 for growth
and carcass traits using frozen semen. J Anim Sci 88:2856–2867
Visscher PM (1998) On the sampling variance of intraclass correlations and genetic correlations.
Genetics 149:1605–1614
Von Mises R (1928/1957) Probability statistics and truth. Macmillan Publ. Co., London
Wang CS, Gianola D, Sorensen DA, Jensen J, Christensen A, Rutledge JJ (1994) Response to
selection for litter size in Danish Landrace pigs: a Bayesian analysis. Theor Appl Genet
88:220–230
Yates F (1990) Preface of statistical methods, experimental design, and scientiﬁc inference by
R.A. Fisher. Oxford University Press, Oxford
32
1
Do We Understand Classic Statistics?

The Bayesian Choice
2
If an event can be produced by a number of n different
causes, the probabilities of theses causes given the event
are to each other as the probabilities of the event given the
causes, and the probability of the existence of each of these is
equal to the probability of the event given that cause, divided
by the sum of all the probabilities of the event given each of
these causes.
Pierre Simon, Marquis de Laplace, 1774
In this chapter, we examine the advantages of Bayesian inference using practical
examples. We will see how to use Bayesian credibility intervals for inferences.
We introduce new tools as the probability of relevance or the guaranteed value
at a given probability. We will see the advantages of comparing treatments
using ratios instead of differences. We will learn one of the main advantages of
Bayesian procedures, the possibility of marginalisation. We also will see some
misinterpretations of Bayesian theory and procedures.
2.1
Bayesian Inference
2.1.1
The Foundations of Bayesian Inference
Bayesian inference is based on the use of probability for expressing uncertainty. It
seems more natural to express uncertainty stating that the probability of two
treatments being different is of 98% than acting as if they were different hoping
not to be wrong more than a 95% of times along our career. It looks more natural to
ﬁnd the most probable value of a parameter based on our data than ﬁnding out
which value of this parameter would produce our data with highest probability if it
were the true value. To examine the distribution of a combination of the data if the
experiment was repeated many times is less attractive than examining the probabil-
ity distribution of the parameter we want to estimate. This was recognised by the
# Springer International Publishing AG 2017
A. Blasco, Bayesian Data Analysis for Animal Scientists,
DOI 10.1007/978-3-319-54274-4_2
33

founders of what we now call ‘classical statistics’ (see, for example, K. Pearson
1920; Fisher 1936; E. Pearson 1962). All of them preferred probability statements
to express uncertainty, but they thought it was not possible to construct these
statements. The reason being that we need some prior information for making
probability statements based in our data, and it is not clear how to introduce this
prior information in our analysis or how to express complete lack of information
using probability statements. However, Bayesian statisticians claim they have
found solutions for these problems, and they can indeed make probability
statements about the parameters, making the Bayesian choice more attractive. All
the controversy between both schools is centred in this point: whether the Bayesian
solutions for prior information are valid or not. In this chapter, we will show why
the Bayesian choice is more attractive by showing its possibilities for inference, and
in the following chapters, we will see how to work with Bayesian statistics in
practice. We will delay to Chap. 9 the discussion about prior information.
2.1.2
Bayes Theorem
Bayesian inference is based in what nowadays is known as ‘Bayes theorem’, a
statement about probability universally accepted.
To see how it works, we need to deﬁne ﬁrst conditional probability. Let us take a
collective of men and women, British and Spanish. If we call:
A: to be man
B: to be British
N: total number of individuals
NA: number of men
NB: number of British people
NAB: number of British men
The probability of being at the same time man and British is
P A; B
ð
Þ ¼ NAB
N
However, if we take only British people, the probability of being a man is
P AjB
ð
Þ ¼ NAB
NB
This is read, ‘The probability of being a man, given that this person is British, is the
number of British men divided by the total number of British people’.
34
2
The Bayesian Choice

The relationship between both probabilities is easy to ﬁnd:
P A; B
ð
Þ ¼ NAB
N ¼ NAB
NB
 NB
N ¼ P AjB
ð
Þ  P B
ð Þ
In general, if we express the probability of the joint occurrence of two events
A and B, we have the same expression
P A; B
ð
Þ ¼ P AjB
ð
Þ  P B
ð Þ
where the bar ‘|’ means ‘given’,1 i.e. the probability of the event A is conditioned to
the occurrence of event B. The probability of taking a train at 12:00 to London is the
probability of arriving on time to the train station, given that there is a train to
London at this time, multiplied by the probability of having indeed a train at
this time.
In general, the probability of occurring two events is the probability of the ﬁrst
one given that the other one happened for sure, by the probability of this later event
taking place; thus, we can apply this rule to both events, A and B
P A; B
ð
Þ ¼ P AjB
ð
Þ  P B
ð Þ ¼ P BjA
ð
Þ  P A
ð Þ
directly leading to Bayes theorem:
P AjB
ð
Þ ¼ P BjA
ð
Þ  P A
ð Þ
P B
ð Þ
Imagine we are interested in comparing how a new food affects growth rate in
pigs; we have a control food and a speciﬁc food, and we call C and S the effect of
these foods on growth rate, respectively. We are interested in knowing whether
growth rate is higher or not with this speciﬁc food, i.e. whether S > C or, in other
terms, whether S  C > 0. This will be called ‘event A’, and the data of our random
sample of pigs will be ‘event B’:
A : S  C > 0
the unknown
ð
Þ
B : y
the data sample
ð
Þ
we have, applying Bayes theorem
P S  C > 0jy
ð
Þ ¼ P yjS  C > 0
ð
Þ  P S  C > 0
ð
Þ
P y
ð Þ
1Notice that ‘|’ is a vertical bar, different from ‘/’. The notation was introduced by Jeffreys (1931)
to avoid confusion with the sign of division.
2.1
Bayesian Inference
35

Thus, given our data, we can estimate the probability of the effect of the speciﬁc
food in growth rate being higher than the effect of the control food. In order to make
this inference, we need to know:
P(y| S  C > 0): This probability is based on the distribution of the data for a given
value of the unknowns. This distribution is often known or assumed to be known
from reasonable hypotheses. For example, most biological traits are originated
from many causes each one having a small effect; thus, the central limit theorem
says that data should be Normally distributed, which allows us to calculate this
probability.
P(y) is a constant, the probability of the sample. Our sample is an event, and it has a
probability. Using MCMC techniques, we do not need to calculate it, as we will
see in Chap. 4.
P(S  C > 0) is a probability independent of any set of data. It is interpreted as the
information that we have (before making the experiment) about the difference
S  C being positive. This prior information is needed to complete Bayes
theorem and allow us to make a probability statement. We discuss below the
different options we have for assessing this probability.
An advantage of Bayesian inference is that we have a rule for estimation in all
sorts of circumstances. We know that all problems are reduced to a single pathway:
we should look for a posterior distribution, given the distribution of the data and the
prior distribution.
2.1.3
Prior Information
Prior information is the information about the parameters we want to estimate that
exists before we perform our experiment. Normally, we are not the only people in
the world working on a topic; other colleagues should have performed related
experiments that would provide some prior information about our experiment. If
so, it would be very interesting to blend this information with the information
provided by our data. Scientists always consider prior information, even if they
apply classical statistics; they compare their results with results provided by other
colleagues, as we can see in the ‘Discussion’ section of all papers. Our conclusions
are not only based in our work but also in results obtained in other publications;
thus, a formal integration of all sources of information looks attractive. Unfortu-
nately, it is almost impossible to perform this accurately, with some exceptions. We
will distinguish three scenarios:
When we have exact prior information: In this case, we do not have any
difﬁculty in integrating this prior information, as we will see with detail in Chap. 9.
For example, suppose the colour of the skin in a line of mouse is determined by a
single gene with two alleles (A,a). If a mouse receives the ‘a’ allele from both
parents, its colour is brown (therefore, it is homozygous aa), but if it receives an
allele ‘A’ from one of the parents, his colour is black (in this case it can either be
36
2
The Bayesian Choice

homozygous AA or heterozygous Aa). We try to ﬁnd out whether a black mouse,
son of black heterozygous mates (Aa  Aa), is homozygous (AA) or heterozygous
(Aa) (Fig. 2.1). In order to assess this, we mate this mouse with a brown (aa) mouse.
If we obtain a brown son, we will be certain it is heterozygous, since it has passed an
allele ‘a’ to the son, but if we obtain black offspring, there is still the doubt about
whether our mouse is homozygous AA or heterozygous Aa. We perform the
experiment, and we actually get three offspring of black mice. What is the proba-
bility, given this data, that our black mouse is heterozygous Aa?
Notice that before we perform the experiment, we have prior information due to
our knowledge of Mendel’s law of inheritance. We know that our mouse will
receive an allele ‘A’ or ‘a’ from his father and an allele ‘A’ or ‘a’ from his mother,
but it cannot receive an allele ‘a’ from each one at the same time, because in this
case it would be brown. This means that we have only three possibilities: either it
has received two alleles ‘A’, it received one ‘A’ from the father and an allele ‘a’
from the mother or an ‘a’ from the father and an ‘A’ from the mother. This means
that the prior probability of our mouse to be heterozygous before performing the
experiment is two-thirds, because there are two favourable possibilities in a total of
three. Therefore, the probability of being homozygous AA is one-third because the
sum of probabilities of all events should be 1.
We should blend this prior information with the information provided by the
experiment, in our case having three black offspring when crossing this black
mouse (AA or Aa) with a brown mouse (aa). We will do this in Chap. 9.
When we have vague prior information: In most cases, prior information is not
as ﬁrmly established as in the example before. We have some experiments in the
literature, but even if they look similar and they give their standard errors, we may
not trust them or we may consider that their circumstances were only partially
applicable to our case. However, they may provide information useful to us, but
putting that aside, we always need prior information in order to apply Bayes
theorem. This was not correctly perceived throughout the nineteenth century, and
it was assumed that we could not integrate prior information properly. The ﬁrst
Black
Black
Black
Black
Brown
AA
Aa
aA
??
X
aa
P(AA) = 1/3
P(Aa) = 2/3
Fig. 2.1 Two heterozygous black mice have a black son, which may be homozygous or hetero-
zygous. To test this, the son is crossed with a brown mouse, and their offspring is examined.
Before performing the experiment, we have some prior information due to our knowledge of
Mendel’s law
2.1
Bayesian Inference
37

solution to this problem was provided independently by the philosopher of mathe-
matics Frank Ramsey (1931) and the Italian actuary Bruno de Finetti (1937).2 Their
solution was original but polemic. They sustained that probability, considered as
ratios between events, was not sufﬁcient to describe the use of probability we
do. For example, if we say that it is probable that the Scottish nationalist party
will win next elections, we are not calculating the ratio between favourable and
total number of events. If we say that it is improbable that an earthquake will
destroy Berlin in the next 10 years, we are not applying any ratio between events
either. Both Ramsay and de Finetti proposed that probability describes beliefs. We
assign a number between 0 and 1 to an event, according to our subjective evaluation
of the event. This does not mean that our beliefs are arbitrary; if we are experts on a
subject and we are performing an experiment, we hope to agree with our colleagues
in the evaluation of previous experiments. This deﬁnition also includes other uses
of probability, like the probability of obtaining 6 when throwing a dice. If we have
enough data, our data will overcome the prior opinion we had, and our experiment
would give approximately the same results independently on whether we used our
prior opinion or the prior opinion of our colleagues. Notice that this prior belief is
always based on previous data, not in unfounded guessing or in arbitrary
statements.3
When this solution was proposed, some statisticians were scandalised by the
thought of science becoming something subjective. Kempthorne expresses this
point of view accurately:
The controversy between the frequentist school and the Bayesian school of inference has
huge implications . . . every reporting of any investigation must lead to the investigator’s
making statements of the form: “My probability that a parameter θ of my model lies
between, say, 2.3 and 5.7 is 0.90.”
Oscar Kempthorne (1984)
Here Kempthorne confused subjective with arbitrary. As we said before, several
experts can share the same subjective opinion.4 In ﬁelds in which the expert opinion
is used to make decisions, this did not represent any problem; however, in
2Ramsey and de Finetti formalised probability as a degree of belief, making possible to operate
with it. For early discussions about probability as a degree of belief, see Howie (2002).
3A Bayesian statistician quotes Kant (Robert 1992, p. 336) to justify prior beliefs. Kant looked for
a rational justiﬁcation of the principle of induction in the prior knowledge, but the prior knowledge
of Kant only has its name in common with the Bayesian prior knowledge. Kant says, ‘It is therefore
at least a question requiring closer investigation, and one not to be dismissed at ﬁrst glance,
whether there is any such cognition independent of all experience and even of all impressions of
the senses. One calls such cognitions a priori, and distinguishes them from empirical ones, which
have their sources a posteriori, namely in experience’ (Kant 1781, p. 136). Of course, no Bayesian
scientist would use prior knowledge as something not based in previous experiences. Therefore, it
seems that there is no relationship between Kant’s philosophy and the Bayesian paradigm.
4One of the ﬁrst defenders of probability as degree of belief, William Donkin, said that probability
was ‘not being relative to any individual mind; since, the same information being presupposed, all
minds ought to distribute their belief in the same way’ (Donkin 1851).
38
2
The Bayesian Choice

biological sciences, it is preferred that results are based in current data more than in
our prior beliefs. In this case, data should be enough to avoid dependence on prior
beliefs. For example, Blasco et al. (1998) compared three different prior beliefs to
estimate the heritability of ovulation rate of a pig population of French Landrace.
According to literature, there is a large range of variation of this parameter, the
average being of about 0.4. However, in a former experiment performed 11 years
ago with the same population, the heritability was of 0.11. Then, vague states of
beliefs were tested (Fig. 2.2).
The ﬁrst state of beliefs considered that it was more probable that the true value
of the heritability was around 0.4 and the second that it was more probable around
0.11. A third state of opinion was considered: all of the possible values would have
the same probability. After performing the experiment, all analyses gave the same
results approximately; thus, prior beliefs were irrelevant for the conclusions. In
Chap. 5 we will see how to integrate vague beliefs in the analysis.
It can be argued that when the prior belief is very sharp with respect to the
distribution of the data, it will dominate, and the results will reﬂect our prior belief
instead of what our experiment brings. This is a correct criticism, but it is unrealis-
tic, why should we perform an experiment if we have sharp prior beliefs? If we are
sure about the value of the heritability, no experiment will change our beliefs. For
example, it is known after many experiments that heritability of litter size in pigs
has values between 0.05 and 0.15. This means that our prior belief around these
values is very sharp, and if we perform an experiment, our results will be similar to
our prior opinion, independently of the result of our experiment. However, the same
will happen if we use classical statistics: if we ﬁnd a heritability of 0.90 for litter
size, we will not trust it, and then we will use our prior opinion to disregard our
result and still believe that heritability of litter size is low. Thus, scientists using
classical statistics also use prior beliefs, although in a different manner.
0.2
0.4
0.6
0.8
1
heritability
Prior 1
Prior 2
Prior 3
Fig. 2.2 Three different
priors showing three different
states of belief about the
heritability of ovulation rate
in French Landrace pigs
(from Blasco et al. 1998)
2.1
Bayesian Inference
39

A main problem for deﬁning subjective beliefs arises in the multivariate case. In
this case, we cannot state a prior opinion because human minds cannot imagine
distributions in more than three dimensions. We will deal with this problem in
Chap. 9.
When we do not have any prior information. Describing ignorance: It is
uncommon the lack of prior information, usually somebody else has worked before
in the same subject or in a similar one. Nevertheless, even having prior information,
it may be interesting to know what we will obtain ignoring prior information and
basing our inferences only in our data. Unfortunately, it does not seem possible to
describe ignorance using probability statements. Along the nineteenth century and
the ﬁrst three decades of the twentieth century, it was applied what Keynes (1921)
named the principle of indifference, consisting in assuming that all events had the
same prior probability, i.e. all possible values of the parameters to be estimated
were equally probable before performing the experiment. These priors are called
ﬂat priors because of their shape; prior 3 of Fig. 2.2 is a ﬂat prior. The problem is
that ignorance is not the same as indifference (it is not the same to say ‘I don’t
know’ that ‘I don’t care’). Moreover, this principle leads to paradoxes, as we will
see in Chap. 9. Other alternatives have been proposed: Jeffreys (1961) proposed
priors that are invariant to transformations, and Bernardo (1979) proposed priors
that have minimum information. All these priors are called ‘objective’ or
‘noninformative’ by Bayesian statisticians; however, it should be noted ﬁrst that
all of them are informative (although usually the information they provide is rather
vague) and second that the information they provide is not objective, at least using
the common meaning of this word.5 Nevertheless, the principle of indifference is
widely used because, introducing a very small amount of information, it does not
affect the results unless we have very small samples. In Chap. 10, Sect. 10.3.2, we
will ﬁnd some support to the principle of indifference using information theory. We
will examine the problem of representing ignorance in Chap. 9. Until then, in all
forthcoming chapters, we will ask the reader to admit the use of ﬂat priors, and we
will use them in most examples.
2.1.4
Probability Density
When we make inferences about continuous variables, we have an inﬁnite number
of possible values; thus, we make probability statements as ‘probability of having a
response to selection higher than 10 g/day’ or ‘probability of differences in litter
size being between 1.0 and 1.5’ because the probability of a single point (like
1.4564587534. . . or 10.00000000. . .) is always zero. To make these statements, we
need an auxiliary function f called ‘probability density function’. As we will see in
5Geneticists can ﬁnd this nomenclature particularly annoying; because due to their knowledge of
Mendel’s laws, they have real objective priors. Thus, when they are using prior knowledge of
relationships between relatives, they are not using subjective priors at all.
40
2
The Bayesian Choice

Chap. 3, the probability of S  C being between the values a and b, given our data,
is the area enclosed by the probability density function between both values
(Fig. 2.3).
It is important to notice that we make our inferences, ‘given our data’, which
means that if we have other data set, our inferences can change (Fig. 2.4). For
example, if we have more data, the density function will be sharper. In this case, we
f (S – C | y)
a
b
Fig. 2.3 Probability density function of the difference S  C given the data. In blue,
P(a  S  C  b)
f (S – C | y2)
f (S – C | y1)
a
a
b
c
d
b
Fig. 2.4 (a) Probability density of the difference S  C given the set of data y1. (b) Probability
density of the difference S  C given the set of data y2. In blue, P(a  S  C  b) ¼ 0.95 in both
cases
2.1
Bayesian Inference
41

can make more accurate inferences about the true value S  C; the interval [c, d] of
Fig. 2.4 has the same probability as the interval [a, b], but it is shorter, and the
inference is more precise. Saying ‘the difference in growth rate between speciﬁc
and control feed is between 100 and 200 g/day’ (Fig. 2.4b) is more precise than
saying that this difference is between 50 and 300 g/day (Fig. 2.4a).
In a Bayesian context, our inferences depend on our unique sample, not in how
samples would be distributed if we had a hypothetical large number of them. If we
collected more samples, we would put all of them together and make inferences
conditioned to our new, larger data set. From now, we will not consider this point
again; thus, we will always show inferences ‘given our sample’.
The probability density functions conditioned to the data are called posterior
distributions. The functions of Fig. 2.2 are also probability density functions, but in
this case, they are not conditioned to the data because they express our prior
uncertainty about the parameters to be estimated before doing the experiment,
they are prior distributions. In Chap. 3 we will learn how to formally use these
density functions.
2.2
Features of Bayesian Inference
2.2.1
Point Estimates: Mean, Median and Mode
All information is contained in the posterior probability density function f(S  C|y);
thus, we do not really need a point estimate (i.e. a single estimated value of S  C)
to make inferences. We can derive probabilities from the areas contained in the
density function, as we have done before, establishing the limits for the true value
with a determined probability of our choice. In both, classical and Bayesian
statistics, it looks somewhat strange to say that our estimate is 10, just to immedi-
ately state that we do not know whether its true value is between 9 and 11 or not.
However, if we need a point estimate, for example, to facilitate comparisons with
other authors, we have in a Bayesian context several choices (Fig. 2.5). We can take
the mean, the median or the mode of the posterior distribution as a point estimate
MEAN
0
MEDIAN MODE
f (S – C |y)
Fig. 2.5 Mean, median and
mode of the posterior
distribution of the difference
between speciﬁc and control
feed, given the information
provided by our data
42
2
The Bayesian Choice

and say that the difference between S and C is, say, 160 g/day, 150 g/day or 140 g/
day. Each point estimate has its advantages, and we will discuss them below.
As we have seen in Chap. 1, a good estimator should minimise the RISK of the
estimation, i.e. the mean of the loss function. The problem here is that each point
estimate is based in a different loss function; thus, each one minimises a different
risk. Calling u the unknown and bu its estimate, the risk minimised by each point
estimator is (Appendix 2.1):
RISK minimised
MEAN
Eu bu  u
ð
Þ2
MEDIAN
Eu bu  u
j
j
MODE
RISK ¼ 0 if bu ¼ u, RISK ¼ 1 otherwise
MEAN: It is quite common to use the mean because it minimises the risk that is
more familiar to us. However, the risk function of the mean has two
inconveniences. Firstly, it penalises high errors, since we work with the square of
the error, and it is not clear why should we do this. Secondly, this risk function is not
invariant to transformations, i.e. the risk of u2 is not the square of the risk of u. For
example, if we estimate the variance as the mean of its posterior distribution, and
we do the same with the standard deviation, one estimate is not the square of the
other (the same happens in a frequentist context when estimating parameters by
least squares: a transformation of a least square estimate is not necessarily a least
square estimate itself).
MODE: It is quite popular for two reasons—one reason is that it is the most
probable value and the second one is that, in the era before MCMC, it was easier to
calculate than the other estimates. Unfortunately, mode has a terrible loss function.
To understand what this function means, see the (rather artiﬁcial) distribution
shown in Fig. 2.6, representing the posterior distribution of a correlation coefﬁcient
given our data.
This distribution has a negative mode, but although the most probable value is
negative, the coefﬁcient is probably positive, because the area of probability in the
positive side is much higher. Only if we are right and the true value is exactly the
mode, we will not have losses.
–0.1 0
1
Fig. 2.6 Posterior
probability distribution of a
correlation coefﬁcient given
the data. The mode is
negative, but the coefﬁcient
of correlation is probably
positive
2.2
Features of Bayesian Inference
43

MEDIAN: The true value has a 50% of probability of being higher or lower than
the median. The median has an attractive loss function in which the errors are
considered according to their value (not to their square or any other transformation).
The median has also the interesting property of being invariant to one-to-one
transformations (e.g. if we have ﬁve values and we calculate the square of them,
the median is still in the middle, and the median of the set of squared values is the
square of the former median). A short demonstration is in Appendix 2.2.
Statisticians tend to prefer the median as a point estimator when using posterior
distributions (this should not be confused with the use of the median of a sample
when we want to estimate the population mean; in this case the median is less
accurate than the mean).6
When the amount of data increases, the distributions tend to become Normal (see
Appendix 2.3), and the mean, median and mode tend to become coincident.
Nevertheless, some parameters like the correlation coefﬁcient show asymmetric
distributions, particularly near the limits of the parametric space (near 1 or +1)
even with samples that are not small. The same happens with heritabilities that are
near zero, variances and other parameters. In these cases, it is not trivial to choose
the mean, mode or median as a point estimator.
Notice that Risk has the same deﬁnition as it did in the frequentist case we saw in
Chap. 1, Sect. 1.4.1 (the mean of the loss function), but here the variable is not bu.
Our estimate is a combination of the data, and in a Bayesian context, the data are
ﬁxed; we do not repeat the experiment conceptually in an inﬁnite number of times.
Here the variable is u because we make probability statements about the unknown
value; thus, we use a random variable u that has the same name as the constant
unknown true value. This is a frequent source of confusion (see ‘misinterpretations’
below).
2.2.2
Credibility Intervals
2.2.2.1 Highest Posterior Density Interval
Bayesian inference provides probability intervals. Now, the conﬁdence intervals
(Bayesians prefer to call them credibility intervals) contain the true value with a
probability of 95% or with other probabilities deﬁned by the user. An advantage of
the Bayesian approach, mainly through MCMC procedures that we will see in
Chap. 4, is the possibility of construction of all kinds of intervals easily. This allows
us to ask questions that we could not ask within the classical inference approach.
For example, if we provide the median and the mode and we ask for the precision of
6Please do not confuse the median of the distribution with the median of a sample when we want to
estimate the population mean. In the latter case, the median has less information than the
arithmetic mean (in a frequentist context, a large s.e.), and the mean should be preferred. We
are considering here probability distributions in the continuous case, with an inﬁnite number of
points; we are not using a sampling estimator.
44
2
The Bayesian Choice

our estimation, we can ﬁnd the shortest interval containing the true value with a
95% probability (what is called the highest posterior density interval at 95%,
HPD95%). We like short intervals because this means that the value we are trying
to estimate is between two close values. Notice (and this is important) that this
interval is independent from the estimate we give, and it can be asymmetric around
the mean or the mode (Fig. 2.7a). Of course, we can also obtain the symmetric
interval about the mean or the mode containing 95% of the probability (Fig. 2.7b) if
this is what we wish, although it would be larger. Notice that zero is included in the
symmetric interval in this example, but it is not in the shortest interval. Including
zero is relevant in classical statistics because it is not possible to state whether S is
larger than C or not, it is related to nonsigniﬁcant differences. However, as we will
see below, including zero in the Bayesian conﬁdence interval is irrelevant, because
we have other intervals to determine the probability of the difference S  C being
higher than zero. It may happen, for example, that zero is included in the interval
HPD95% and simultaneously the probability S  C > 0 being 96%.
2.2.2.2 Probability of Being Positive (or Negative)
We can also calculate the probability of the difference between S and C being
higher than 0 (Fig. 2.8a), which is the same as the probability of S being greater than
C. In the case in which S is less than C, we can calculate the probability of S  C
being negative, i.e. the probability of S being less than C (Fig. 2.8b). Notice that this
is not a hypothesis test, since we are not comparing two hypotheses as in Chap. 1,
Sect. 1.2; this is the estimation of the actual probability of S > C (or that of S < C if
the difference is negative). This can be more practical than a test of hypothesis; as
we will argue later, we do not need hypothesis tests for many biological problems.
Notice that we can estimate the probability of S  C being positive or negative, but
we do not estimate the probability of S  C ¼ 0 because this probability is always
zero. We know that S  C is not going to be exactly 0.0000000. . .. Later we will
deﬁne the probability of similitude, for the cases in which S  C is irrelevant.
MODE
MEAN
P = 0.95
f (S – C |y) 
MEAN
P = 0.95
f (S – C |y)
Shortest interval with P = 0.95
Symmetric interval with P = 0.95
a
b
Fig. 2.7 Credibility intervals containing the true value with a probability of 0.95. (a) Shortest
interval (not symmetric around the mean or the mode). (b) Symmetric interval around the mean
2.2
Features of Bayesian Inference
45

2.2.2.3 Guaranteed Value
In some cases, it may be important to know how high this difference is with a
chosen probability, for example, 95%. By calculating the interval [k, +1)
containing 95% of the probability (Fig. 2.9a), we can state that the probability of
S  C being less than this value k is only a 5%, i.e. we can state that S  C takes at
least a value k with a probability of 95% (or the probability we decide to take).
If S is lower than C, we can calculate the interval (1, k] and state that the
probability of S  C being higher than k is only 5% (Fig. 2.9b).7 We call k the
guaranteed value at a determined probability. For many problems, we will be
satisﬁed with a guaranteed value of lower probability, say 80%.8
f (S – C |y)
f (S – C |y)
b
a
0
0
P < 0
P > 0
Fig. 2.8 Credibility intervals. (a) Interval (0, +1) showing the probability of S  C being higher
than zero when S > C. (b) Interval (1, 0) showing the probability of S  C being lower than zero
when S < C
f (S – C |y)
f (S – C |y)
b
a
0
k
k
0
P = 0.95
P = 0.95
Fig. 2.9 Credibility intervals. (a) Interval [k, +1) showing the minimum guaranteed value with a
probability of 95%. (b) Interval (1, k] showing the maximum guaranteed value with a proba-
bility of 95%
7These intervals have the advantage of being invariant to transformations. HPD 95% intervals are
not invariant to transformations, i.e. the HPD 95% interval for the variance is not the square of the
HPD 95% interval for the standard deviation. The same happens with frequentist conﬁdence
intervals.
8This looks smaller than the common use of 95%, but for a guaranteed value, it is not. It is quite
common to discuss results based in a point estimation without looking at the bounds of the
conﬁdence interval. Here a guaranteed provides some safety in the discussion.
46
2
The Bayesian Choice

2.2.2.4 Probability of Relevance
In practice, we are interested not only in ﬁnding whether S is higher than C or not,
but in whether this difference is relevant. S may be higher than C, but this difference
may be irrelevant. A relevant value is what we consider the minimum difference
between S and C having an economical or biological meaning; of course, higher
values are also relevant, but we deﬁne ‘relevant value’ as the minimum relevant
value. Relevant values are deﬁned before performing the experiment and do not
depend on it but on economical or biological considerations (see Chap. 1, Sect.
1.2.2 and Appendix 1.1 for ﬁnding relevant values). In fact, we can deﬁne ‘relevant’
values even if we are not performing any experiment. Relevant values are com-
monly used in experimental design to determine the sample size; in classical
statistics, they are the values of a trait from which differences between treatments
should appear as ‘signiﬁcant’ when calculating the sample size of the experiment.
We can calculate the probability of the difference S  C being relevant, what we
call probability of relevance. For example, if we are measuring lean content in pigs,
we can consider that 1 mm of back fat is a relevant difference between S and
C groups and calculate the probability of S  C being more than 1 mm (Fig. 2.10a).
When S is lower than C, the relevant value is negative, and we calculate the
probability of it being lower than this value (Fig. 2.10b).
2.2.2.5 Probability of Similitude
We can be interested in ﬁnding whether S is different from C. When we mean
‘different’, we mean higher or lower than a relevant value, deﬁned as before: the
minimum value with economical or biological meaning. For most biological
problems, we are certain that S is different from C because they cannot be exactly
equal. When comparing adult weight of beef cattle breeds, we are rather sure that
they will differ at least in one kg, or one g or one mg, but they will never have
exactly the same weight. Nevertheless, if we deﬁne a relevant value of, say 100 kg,
we can obtain the probability of the absolute value of the difference between
these breeds being lower than 100 kg, i.e. the probability of this difference being
f (S – C |y)
b
0
f (S – C |y)
a
0
Relevant
Relevant
P = 0.93
P = 0.93
Fig. 2.10 Credibility intervals. (a) Interval from a relevant quantity to +1, showing the proba-
bility of the difference S  C of being relevant. (b) Intervals from 1 to a relevant quantity,
showing the probability of the difference S  C of being relevant
2.2
Features of Bayesian Inference
47

irrelevant, null for practical purposes. If this probability is high (Fig. 2.11a), we can
say that both breeds are equal for practical purposes.
However, it may happen that our sample is not high enough to establish
conclusions, and we have, for example, a probability of similitude of 21%, a
probability of relevance for S > C of 49% and a probability of relevance for
C > S of 30% (Fig. 2.11b). In this case, we cannot establish any conclusion.
Therefore, using the probability of similitude, we can differentiate between ‘there
is no difference’ (for practical purposes) or ‘I do not know whether there is a
difference or not’. Comparing with the ‘n.s.’ result of a classical test of hypothesis,
‘nonsigniﬁcance’ cannot state that there are no differences between both breeds; we
do not know. As before, the probability of similitude is not a hypothesis test but the
actual probability of the breeds being equal (for our purposes).
We can also apply the concepts of relevance and similarity to parameters; for
example, we can say that a correlation between two variables is zero for us when it
is between 0.1 and 0.1; if so, our decisions concerning these two variables will be
the same as if they were completely independent. If the probability of a correlation
coefﬁcient being between 0.1 and 0.1 is high, we can consider that this coefﬁcient
is null in practice (it will never be exactly 0.00000. . .).
It is important to notice that we are talking about relevant differences, not about
inﬁnitesimal differences. If we try to draw conclusions from ﬁgures like Fig. 2.11
when the relevant quantity is extremely small, we can have problems related to the
prior distribution. Figure 2.11 shows posterior distributions, and they have been
derived using a prior distribution. For most problems, we will have data enough and
we can use vague priors that will be dominated by the data distribution, as we will
see in Chap. 9, but if the area in blue of Fig. 2.11b is extremely small, even in these
cases the prior can have an inﬂuence in the conclusions. Therefore, the probability
of similitude and probabilities for other conﬁdence intervals should be applied for
relevant values, which in practice will never be inﬁnitesimal.
2.2.2.6 Credibility Intervals of Ratios
The use of the probabilities of relevance and similitude, although attractive, has the
problem of deﬁning a relevant difference or a relevant value of a parameter. For
many traits, it is difﬁcult to state what is a relevant difference or a relevant value.
Relevant
Relevant
Relevant
Relevant
P = 0.96
0
0
f (S – C |y)
f (S – C |y)
b
a
P = 0.21
Fig. 2.11 Probability of similitude between S and C. (a) S and C do not differ in practice. (b) We
do not have data enough to determine whether S is higher, lower or similar to C
48
2
The Bayesian Choice

For example, if we measure the effect of a treatment on enzymes activities, it is not
clear which difference in enzyme activity can be considered as ‘relevant’. We have
proposed a procedure for these cases in Appendix 1.1 in Chap. 1, but we have here
another solution. For these cases, we can express our results as ratios instead of
differences. We will make the same inferences as before, but now using the
marginal posterior distribution of the ratio S/C instead of the posterior distribution
of S  C. We can apply all the credibility intervals exposed before, now to the ratio
S/C instead of applying them to the difference S  C. For example, we can calculate
the probability of the treatment S being a 10% higher than the control C for a
particular trait (Fig. 2.12). If S is lower than C, we can be interested in the
probability of the selected population being, for example, lower than a 90% of
the control population (Fig. 2.12b).
We have doubts about what can be a relevant difference for enzyme activities,
but we know what it means that a treatment produces a 10% more of some enzyme
activity. This is possible to do in classical statistics by computing the ratios of least
square means, but on one the hand, the ratio does not have the statistical properties
of least square estimation any more, and on the other hand, obviously, the s.e. of the
ratio is not the ratio of the s.e. If we want the s.e. of the ratio, we should use
approximations using Taylor series, it is not immediate. The use of MCMC
techniques easily provides the posterior distribution of the ratios and all the
conﬁdence intervals.
2.2.3
Marginalisation
One of the main advantages of Bayesian inference is the possibility of
marginalisation. This implies that in a model with several variables and parameters,
we can examine the uncertainty of each variable and parameter one by one, taking
into accounts the errors of estimation of all the other unknowns. Take, for example,
a mixed model: in classical statistics, we estimate the variance components and use
them for the estimation of the ﬁxed effects we have in the model. We use point
estimates of the variances taking their values as true values, with no error. Another
example is the estimation of growth curves or lactation curves: we estimate the
f (S/C | y)
f (S/C | y)
b
a
1.1
1
1
0.9
P = 0.94
P = 0.94
Fig. 2.12 Credibility interval for the ratio of levels of a treatment. (a) The probability of S being
10% higher than C is 0.94. (b) The probability of S being 90% of C is 0.94
2.2
Features of Bayesian Inference
49

curve for each animal, take the curve’s parameters as true values and then apply a
ﬁxed effect or a mixed model to these ‘true’ values estimated with no error. The
same can be said for the estimation of residual food intake and, in general, for any
‘nested’ model in which some parameters are considered as ‘true values’ in order to
apply another statistical mode on them. Classical statistics has no solution for
‘nested’ models, but Bayesian statistics has a solution, easy to apply considering
the MCMC methods that we will see in Chap. 4. This is possible because Bayesian
inference is based in probabilities. Inferences in a Bayesian context are made from
the marginal posterior distribution of an effect or a parameter, having integrated out
all other unknowns, i.e. giving to them all their possible values, multiplying by the
probability of each value and summing up. We will see how it works in a simple
example.
Let us come back to the group of people composed by British and Spanish men
and women. We have made a contract with this group of people, and we should now
pay them. We have the average salary they earn in the following table, in thousands
of euros per year, divided by sex and nationality.9 The percentage of individuals of
each type in our group of people is between brackets.
British
Spanish
Men
36 (40%)
26 (10%)
Women
30 (20%)
20 (30%)
Now we would like to know how much we should pay to the British people and
to the Spanish people, independently on whether they are men or women. We need
to marginalise our data. We see that among British people, 2/3 are men and1/3 are
women,10 so
SalaryforBritish ¼ 36  2
3 þ 30  1
3 ¼ 34
We also see that 1/4 of Spanish people are men and 3/4 are women, so
SalaryforSpanish ¼ 26  1
4 þ 20  3
4 ¼ 21:5
Thus, we have
British
Spanish
34 (60%)
21.5 (40%)
9These are approximate ﬁgures, but near the real ones, according to Eurostat.
10Doing that properly, the proportion of British men is
0:4
0:4þ0:2 and the same holds for the other
proportions.
50
2
The Bayesian Choice

Now instead of two variables, sex and nationality, we have only nationality; we
have integrated out the variable sex that has now disappeared.
In our example about treatments S and C, we do not know the residual variance
of the model y ¼ Treatment + e, which has to be estimated from the data. Suppose
that this residual variance can only take two values, σ2 ¼ 0.5 and σ2 ¼ 1. The
marginal posterior distribution of the difference between treatments will be the sum
of f(S  C given the data and given that σ2 ¼ 0.5) and f(S  C given the data and
given that σ2 ¼ 1) multiplied by the respective probabilities of σ2 taking these
values.
f S  Cjy
ð
Þ ¼ f S  Cjy; σ2 ¼ 0:5


 P σ2 ¼ 0:5


þ f S  Cjy; σ2 ¼ 1


 P σ2 ¼ 1


When σ2 can take all possible values from 0 to 1, instead of summing up, we
calculate the integral of f(S  C| y, σ2) for all possible values of σ2 from 0 to 1.
f S  Cjy
ð
Þ ¼
Z 1
0
f S  C; σ2jy


dσ2 ¼
Z 1
0
f S  Cjy; σ2


f σ2


dσ2
Thus, when we marginalise, we take all possible values of the unknowns, we
multiply by their probability and we sum up. This has two main consequences:
1. We concentrate our efforts of estimation only in the posterior probability of the
unknown of interest. All multivariate problems are converted in a set of univari-
ate problems of estimation.
2. We take into account the uncertainty of all other parameters when we are
estimating the parameter of interest.
2.3
Test of Hypothesis
2.3.1
Model Choice
Sometimes, we face real hypothesis testing, for example, when it should be decided
in court a verdict of ‘guilty’ or ‘innocent’, but as we have stressed before, there is no
need of hypothesis tests for most biological experiments. This has been emphasised
by Gelman et al. (2013), Howson and Urbach (1996) and Robert (1992) among
many others for both, frequentist and Bayesian statistics. Nevertheless, there are
circumstances in which we may need to select one among several statistical models.
For example, when we are trying to eliminate some noise effects of a model that
have too many levels to be tested two by two, or when we have many noise effects
and we would like to know whether we could be freed from them. Even in these
cases, our opinion is that the researcher should know when to add noise effects,
from her biological knowledge of the problem; statistics is a tool, and it cannot
substitute thinking. We will come back on this problem on Chap. 10.
2.3
Test of Hypothesis
51

Now suppose we have two models to be compared, one model has an effect; the
other model does not have this effect. This is known as ‘nested’ model. In the
Bayesian case, we have a wider scope. We can compare models that are not nested.
For example, we can try to ﬁt different growth curves to the data based on different
functions. We can also compare several models simultaneously, based on
different hypotheses. Suppose we have Hypothesis 1, 2, 3. . ., we can calculate
P(H1|y), P(H2|y), P(H3|y), . . . and choose the most probable one. Here we are not
assuming risks at 95% as in frequentist statistics, the probabilities we obtain are the
actual probabilities of these hypotheses, thus if we say that, when comparing two
hypotheses, H1 has a probability of 90% and H2 has a 10%, we can say that H1 is
9 times more probable than H2. Notice that we are giving the probabilities relative
to the hypotheses that are being tested; for example, if we test two hypotheses and
one of them has a probability of 60%, the other one will have a 40%, but if we test a
third hypothesis and it has a 10% probability, the probability of the other two ones is
modiﬁed.
To calculate the probability of each hypothesis, we have to perform
marginalisation as we have seen before. We give all possible values to the
parameters that need to be estimated θ, we multiply by their probability and we
sum up. In the continuous case, we integrate instead of summing. For each
hypothesis H, we have:
P Hjy
ð
Þ ¼
Z
f θ; Hjy
ð
Þdθ
As we will see in Chap. 10, Sect. 10.2.2, these integrals are highly dependent on
the prior information f(θ), which makes Bayesian model choice extremely difﬁcult.
Model choice is a difﬁcult area that is still under development in statistical
science. We have ﬁrst to decide which will be our criterion for preferring a model to
others. Test of hypothesis is only one of the possible ways of model choice. We can
use criteria based in amount of information, or criteria based on probability, or
heuristic criteria that we have derived by simulation or according to our experience.
We can also choose a model based in its predictive properties for new data. In the
last chapter, we will discuss the different approaches to model selection.
2.3.2
Bayes Factors
A common case is to have only two hypotheses to be tested, then
P H1jy
ð
Þ
P H2jy
ð
Þ ¼
P yjH1
ð
ÞP H1
ð
Þ
P y
ð Þ
P yjH2
ð
ÞP H2
ð
Þ
P y
ð Þ
¼ P yjH1
ð
Þ  P H1
ð
Þ
P yjH2
ð
Þ  P H2
ð
Þ ¼ BF  P H1
ð
Þ
P H2
ð
Þ
52
2
The Bayesian Choice

where
BF ¼ P yjH1
ð
Þ
P yjH2
ð
Þ
is called ‘Bayes factor’ (although Bayes never used it, this was actually proposed by
Laplace). In practice most people consider that ‘a priori’ both hypotheses to be
tested have the same probability, then if P(H1) ¼ P(H2) we have
BF ¼ P yjH1
ð
Þ
P yjH2
ð
Þ ¼ P H1jy
ð
Þ
P H2jy
ð
Þ
and we can use Bayes factors to compare the posterior probabilities of two
hypotheses. The main problem with Bayes factors is that the probabilities of the
hypotheses are sensitive to the prior distributions of the unknowns f(θ). Moreover,
if we have complex models, Bayes factors are difﬁcult to calculate. Notice that the
justiﬁcation of the use of Bayes factors in a Bayesian context is that they express the
ratio of posterior probabilities when prior probabilities are the same, they are not
justiﬁed as ‘the support that the hypothesis gives to the observed data’ or other
informal justiﬁcations.
2.3.3
Model Averaging
Another possibility of Bayesian inference is to do model averaging. This interesting
procedure for inferences has no counterpart in frequentist statistics. It consists in
using simultaneously several models for inferences, weighted according to their
posterior probabilities. For example, if we are interested in estimating a parameter θ
that appears in both models and has the same meaning in both models (this is
important!), we can ﬁnd that, given the data, H1 has a probability of 70% and H2 has
of 30%. This is unsatisfactory, because when choosing H1 as the true model and
estimate θ with it, there is still a considerable amount of evidence in favour of H2.
Here we face the problem we saw in Chap. 1 when having insufﬁcient data to
choose one model; our data does not support either model 1 or model 2. In a
classical context, the problem has no solution because the risks are ﬁxed before the
analysis is performed, and they do not represent the probability of the model being
true, as we explained in Chap. 1. In a Bayesian context, we have the actual
probabilities of each model, and we can make inferences from both hypotheses,
weighing each one by its probability.
P θjy
ð
Þ ¼ P θ; H0jy
ð
Þ þ P θ; H1jy
ð
Þ ¼ P θjH0; y
ð
Þ  P H0jy
ð
Þ þ P θjH1; y
ð
Þ  P H1jy
ð
Þ
We should be careful, in that θ should be the same parameter in both models; for
example, the parameters b, k of the logistic growth curve have different meanings
than the same parameters in the Gompertz growth curve.
2.3
Test of Hypothesis
53

2.4
Common Misinterpretations
The main advantage of Bayesian inference is the use of prior information: This
would be true if prior information was easy to integrate in the inference. Unfortu-
nately, this is not the case, and most modern Bayesians do not use prior information
except as a tool that allows them to work with probabilities. The real main
advantage of Bayesian inference is the possibility of working with probabilities,
which allows making inferences about the unknowns based in probabilities and
permits marginalisation.
Bayesian statistics is subjective; thus, researchers ﬁnd what they want:
Sometimes Bayesian statistics can be subjective (when there is vague prior infor-
mation), but subjective does not mean arbitrary, as we have discussed before. It is
true that we can always deﬁne a prior probability that will dominate the results, but
if we really believe in a highly informative prior, why should we perform any
experiment? Subjective priors should always be vague, and data should usually
dominate the results. We have an additional difﬁculty, which is that in multivariate
cases subjective priors are almost impossible to be deﬁned properly (in Chap. 9 we
will come back on this topic).
Bayesian results are a blend of the information provided by the data and by
the prior: This should be the ideal scenario, but as said before, it is difﬁcult to
integrate prior information; thus, modern Bayesians try to minimise the effect of the
prior. They do this using enough data in order to be sure that data will dominate the
results, so that after checking several vague priors or after using minimum infor-
mative priors, the results stay the same.
The posterior of today is the prior of tomorrow: This is usually untrue, at least
in biological and agricultural experiments. When we are analysing a new experi-
ment, other people have been working in the ﬁeld, so our last posterior should be
integrated subjectively with this new information. Moreover, we will normally try
to avoid the effect of any prior by having enough data. We will not normally use our
previous posterior as a new prior.
In Bayesian statistics, the true value is a random variable: We can ﬁnd
statements like ‘in frequentist statistics, the sample is a variable and the true
value is ﬁxed, whereas in Bayesian statistics the sample is ﬁxed, and the true
value is a random variable’. This is nonsense. The true value θTRUE is a constant
that we do not know. We use the random variable θ (which is not the true value) to
make probability statements about this unknown true value θTRUE. Unfortunately,
frequentist statisticians use θ as the true value; thus, this is a source of confusion;
what is worse, some Bayesian statisticians use θ for both the true value and the
variable used to express uncertainty about the true value. Perhaps Bayesian
statisticians should use another way of representing the random variable used
to make statements about the unknown true value, but the common practice is to
use σ2 to represent the random variable used to express uncertainty about the true
value σ2
TRUE.
54
2
The Bayesian Choice

Bayesian statistics ignores what would happen if the experiment were
repeated: We can be interested in which would be the distribution of a Bayesian
estimator if the experiment were repeated. In this case, we are not using frequentist
statistics because our estimator was derived under other basis, but we would like to
know what would happen when repeating our experiment or we would like to
examine the frequentist properties of our estimator. To know what will happen
when repeating an experiment is a sensible question and Bayesian statistics often
examine this.11
Credibility intervals should be symmetric around the mean: This is not
necessary. These intervals do not represent the accuracy of the mean or the
accuracy of the mode but another way of estimating our unknown quantity, interval
estimation instead of point estimation.
Credibility intervals should always contain a 95% probability: The choice of
the 95% was made by Fisher (1925a, p. 46) because approximately two standard
deviations of the Normal function included 95% of its values. Here we are not
working with signiﬁcance levels; thus, we obtain actual probabilities. If we obtain
89% probability, we should ask ourselves whether this uncertainty is enough for the
trait that we are examining. For example, we may never play lottery, but if a
magician told us that if playing tomorrow we would have an 80% probability to
win, we can seriously consider playing. However, if the magician says that if
driving tomorrow we would have a 95% probabilities to survive, we can consider
that the risk is too high and not to drive.
When 0 is included in the credibility interval 95%, there are no signiﬁcant
differences: Firstly, there is no such thing as ‘signiﬁcant differences’ in a Bayesian
context. We do not have signiﬁcance levels, since we can measure the actual
probability of a difference being greater than zero. Secondly, in a frequentist
context, ‘signiﬁcant differences’ is the result of a hypothesis test, and we are not
performing any test by using a credibility interval; the result of a frequentist test is
‘yes’ or ‘no’, but we are here estimating the precision of an unknown. Finally, the
Bayesian answer to assess whether S is greater than C is not to offer an HPD95%
but to calculate the probability of S > C.
We can calculate the probability of S > C and the probability of S < C, but
my interest is which is the probability of S ¼ C, how can I calculate this? It is
not necessary to calculate it if you are working with a continuous variable, as usual
in biology or agriculture. This probability is always zero because there are inﬁnite
numbers in the real line. The question is not correctly formulated. We are not
interested in knowing whether the difference between S and C is 0.0000000000. . .
but in whether if it is lower than a value small enough to consider this difference to
be irrelevant. Then we can ﬁnd probabilities of similitude as in Fig. 2.11.
11This does not mean that Bayesian estimators have good frequentist properties. For example, they
are usually biased due to the prior. However, this does not mean that they are not good estimators,
what happens is that their ‘good properties’ are different.
2.4
Common Misinterpretations
55

We need hypothesis tests for checking whether there is or not an effect: Let
us assume, for example, that there is a sex effect in the comparison of treatments.
We can compare two models for growth rate at a determined age, one with a sex
effect and other model without sex effect, and choose the most probable one.
However, if we chose the model with no sex effect, this does not mean that the
difference between males and females for this trait is zero. As we said before, the
question is not properly formulated. We are not interested in knowing whether the
sex difference is 0.0000000 . . . but if it is lower than a quantity that would be
irrelevant to us. Even when performing a hypothesis test, a negative answer does
not mean that we are sure about the absence of this effect, only that our data is
compatible with the absence of this effect, which is not the same. Moreover, if we
have few data, our sample will always be compatible with the absence of the effect
we are testing; we have seen in Chap. 1 that differences are always signiﬁcant if the
sample is large enough. Because of the difﬁculties of performing tests, that we
mentioned before, in practice, it is much easier and more informative to ﬁnd the
posterior probability of the difference between males and females in order to check
whether this difference is relevant or not. If the probability of similitude between
males and females is high, i.e. if this difference in absolute value has a high
probability of being lower than a relevant value, the sex effect can be ignored.
Bayes factors contain all information provided by the data; thus we can
make inferences with no prior probabilities: Inferences are made in a Bayesian
context from posterior distributions. A ratio of posterior distributions is the product
of a Bayes factor by the ratio of prior probabilities of the hypotheses; thus, it is true
that all information coming from the data is contained in the Bayes factor. The
problem is that we need the prior probabilities to make inferences; we cannot make
inferences without them because in this case we cannot apply Bayes theorem. In a
Bayesian context, when we make inferences from Bayes factors, it is always
assumed that prior probabilities of both hypotheses are the same.
Bayes factors show which hypothesis makes the data more probable: Again,
as in the case of maximum likelihood we discussed in Chap. 1, Bayes factors show
which hypotheses, if it was the true hypothesis and not otherwise, would make the
sample more probable. This is not enough to make inferences because it does not
lead to learning which hypothesis is the most probable one, and this is the only way
for drawing inferences in a Bayesian context. Our interest is not to know which is
the hypothesis that, if it was the true one, will make our data more probable but to
ﬁnd, given our data, which is the most probable hypothesis. In the ﬁrst case, we do
not have any measure of evidence; in the second case, we can compare the
probabilities of both hypotheses.
Bayes factors are equivalent to the maximum likelihood ratio: The maximum
likelihood ratio is a technique that shows how to construct hypothesis tests in the
frequentist world, leading to chi-square distributions that can be used for drawing
rejection areas for nested hypothesis tests. The interpretation is thus completely
different. Moreover, Bayes factors use the average likelihoods, not the likelihoods
at their maximum, which can lead to different results when likelihoods are not
symmetric. Finally, remember that Bayes factors can only be used for inferences
56
2
The Bayesian Choice

when prior probabilities of both hypotheses are the same. When used for inferences,
Bayes factors show ratios of probabilities, a much more informative way of dealing
with uncertainty than likelihood ratio tests.
Bayesian statistics give the same results as likelihood when the prior is ﬂat:
The shape of the function can be the same, but the way of making inferences is
completely different. We have seen that likelihoods cannot be integrated because
they are not probabilities; thus, no credibility intervals can be constructed with the
likelihood function and no marginalisation of the parameters can be made.
Marginal posterior distributions are like maximum likelihood proﬁles: In
classical statistics, for example, in genetics when searching major genes, maximum
likelihood proﬁles are used. They consist in ﬁnding the maximum likelihood esti-
mate for all parameters but one and examine the likelihood curve substituting all
unknowns, with the exception of this one, by their maximum likelihood estimates. In
Fig. 2.13, we represent the likelihood of two parameters θ1 and θ2. The lines should
be taken as level curves in a map; we have two ‘hills’, one higher than the other one.
The objective in classical analysis is to ﬁnd the maximum of this ﬁgure, which
would be the top of the high ‘hill’ forgetting the rest of the hill although it contains
some information of interest. When a maximum likelihood proﬁle is made by
‘cutting’ the hill along the maximum likelihood of one of the parameters in order
to draw a maximum likelihood proﬁle, the smaller ‘hill’ is still forgotten. In the
Bayesian case, if these ‘hills’ represent a posterior distribution of both parameters,
marginalisation will take into account that there is a small ‘hill’ of probability, and
all the values of θ2 in this area will be multiplied by their probability and summed up
in order to construct the marginal posterior distribution of θ1.
2.5
Bayesian Inference in Practice
In this section, we will follow the examples given by Blasco (2005) with small
modiﬁcations. Bayesian inference modiﬁes the approach to the discussion of the
results. Classically, we have point estimation, usually a least square mean, and its
ML
ML
f (y |    ,    )
2
θ
1
θ 
1
θ 
2
θ 
Fig. 2.13 Probability
density of the data for two
parameters. Lines should be
interpreted as level curves of
a map
2.5
Bayesian Inference in Practice
57

standard error, accompanied by a hypothesis test indicating whether there are
differences between treatments according to a signiﬁcance level previously deﬁned.
Then we discuss the results based upon these features. Now, in a Bayesian context,
the procedure is inverted. We should ﬁrst ask which question is relevant for us and
then go to the marginal posterior distribution to ﬁnd an answer.
Example 1 We take an example from Blasco et al. (1994). They were interested in
ﬁnding the differences in percentage of ham from a pig ﬁnal cross using Belgian
Landrace or Duroc as terminal sire. They offer least square means of 25.1  0.2 kg
and 24.5  0.2 kg, respectively, and ﬁnd that they are signiﬁcantly different. Now,
in order to present the Bayesian results, we have estimated the marginal posterior
distribution of the difference between both crosses. Now, we should ask some
questions:
1. What is the difference between both crosses?
We can offer the mean, the mode or the median. Here the marginal distribution is
approximately Normal; thus, the three parameters are approximately the same, and
the answer is coincident with the classical analysis: 0.6 kg.
2. What is the precision of this estimation?
The most common Bayesian answer is the highest posterior density interval
containing a probability of 95%. However, here the marginal posterior distribution
is approximately Normal, and we know that the mean  twice the standard
deviation of the marginal posterior distribution will contain approximately this
probability; therefore, we can give either an interval [0.1 kg, 1.1 kg] or just the
standard deviation of the difference, 0.25 kg.
3. What is the probability of the Belgian Landrace cross being higher than the
Duroc cross?
We do not need a test of hypothesis to answer this question. We can just
calculate how much probability area of the marginal posterior distribution is
positive. We ﬁnd a 99% probability. Please notice that, with a smaller sample, we
could have found a high posterior density interval containing a 95% of probability
of [0.1 kg, 1.3 kg], if, for example, the standard deviation would have been
0.30 kg and still say that the probability of the Belgian Landrace cross being higher
than the Duroc is, say, 96%. This is because one question is the accuracy of the
difference, shown in Fig. 2.7a, and another question is whether there is a difference,
shown in Fig. 2.8a. In this last ﬁgure, we do not need the tail of probability of the
right side of Fig. 2.7a. Using Bayesian inference, we should choose the best way for
answering each question.
58
2
The Bayesian Choice

4. How large can we say is this difference with a probability of 95%?
We calculate the interval [k, +1) (see Fig. 2.9a), and we ﬁnd out that the value
of k is 0.2 kg; thus, we can say that the difference between crosses is at least of
0.2 kg with a probability of 95%; we have a guaranteed value of 0.2 kg at 95%
probability. We could have also estimated a guaranteed value at 80% or at other
probability value; see, for example, Martı´nez-A´ lvaro et al. (2016).
5. Considering that an economical relevant difference between crosses is 0.5 kg,
what is the probability of the difference between crosses being relevant?
We calculate the probability of being higher than 0.5 (Fig. 2.10a), and we ﬁnd
the probability of relevance to be 66%. Thus, we can say that although we consider
that both crosses are different, the probability of this difference being relevant is of
only 66%.
Example 2 We now take a sensory analysis from Herna´ndez et al. (2005). Here a
rabbit population selected for growth rate is compared with a control population,
and sensory properties of meat from the l. dorsi are assessed by a panel test. The
panels test scored from 0 to 5, and the data was divided by the standard deviation of
each panelist in order to avoid a scale effect. In this example, it is difﬁcult to
determine what a relevant difference is, because it is difﬁcult to understand whether
a difference in 0.3 points of liver ﬂavour, for example, is high or not. Thus, instead
of assessing the differences between the selected (S) and control (C) population, the
ratio of the selection and control effects S/C is analysed (see Fig. 2.12). This allows
expressing the superiority of the selected over the control population (or conversely
the superiority of the control over the selected population) in percentage. We will
take the trait liver ﬂavour. The result of the classical analysis is that the least square
means of the selected and control populations are 1.38  0.08 and 1.13  0.08
points, respectively, and they were found to be signiﬁcantly different. These means
and their standard error are rather inexpressive about the effect of selection on meat
quality. Now, the Bayesian analysis answers the following questions:
1. What is the probability of the selected population being higher than the control
population?
We calculate the probability of the ratio being higher than 1. We ﬁnd a 99%
probability; thus, we conclude they are different.
2. How much higher is the liver ﬂavour of the selected population with respect to
the control population?
As in Example 1, we can give the mean, the mode or the median, and all of them
are approximately coincident; we ﬁnd that the liver ﬂavour of the selected popula-
tion is 23% higher than the liver ﬂavour of the control population.
2.5
Bayesian Inference in Practice
59

3. Which is the precision of this estimation?
The 95% high posterior density interval goes from 1.03 to 1.44, which means
that the liver ﬂavour of the selected population is between 3% and 44% higher than
this ﬂavour in the control population with a probability of 95%.
4. How large can we say is this difference with a probability of 95%?
We calculate the guaranteed value, the k of the interval[k, +1), and we ﬁndthat the
value of k for the ratio S/C is 1.06; thus, we can say that selected population is at least
6% higher than control population with a probability of 95%. We can say alternatively
that the probability of selected population being lower than 6% of the control popula-
tion has a probability of only 5%. In practice, lower probabilities are used for
guaranteed values; often 80% is enough (see, for example, Zome~no et al. 2013).
5. Assuming being 10% higher as relevant, what is the probability of the selected
population being 10% higher than the control population?
We calculate the probability of the ratio of being higher than 1.10, and we ﬁnd
this value to be 88%. This means that the probability of the effect of selection on
liver ﬂavour being relevant is 88%. This is not related to signiﬁcance thresholds or
rejection areas; we can state that this is the actual probability.
Example 3 Progesterone participates in the release of mature oocytes, facilitation
of implantation and maintenance of pregnancy. Most progesterone functions are
exerted through its interaction with speciﬁc nuclear progesterone receptor. Peiro´
et al. (2008) analyse a possible association of a PGR gene polymorphism (GG, GA,
AA) with litter size in a rabbit population. They consider that 0.5 kits per litter is a
relevant quantity. The GG genotype had higher litter size than GA genotype; the
difference between genotypes D was relevant and P(D > 0) ¼ 99%. The GA
genotype had similar litter size as the AA genotype (probability of similar-
ity ¼ 96%), which indicates that the genetic determination of this trait is dominant.
Here, the probability of similitude (Fig. 2.11a) means that the area of the posterior
distribution of P(GA-AA | y) included between 0.5 and +0.5 kits was 96%.
Example 4 Hernandez et al. (1998) estimated the correlation between moisture
and fat percentage in hind leg meat of rabbit, obtaining a coefﬁcient of
0.95  0.07. This standard error is not very useful, since the sampling distribution
of the correlation coefﬁcient is not symmetrical (the correlation cannot be lower
than 1; thus, the ‘’ is misleading).12 A Bayesian analysis obtained the marginal
12Using bootstrap techniques, a drawing of the sampling distribution of the correlation coefﬁcient
can be obtained, showing that when repeating many times the experiment, the samples will not be
symmetrical. However, this sampling distribution does not allow making probability statements
about the unknowns but only about the sampling distribution, and it is more complex than the
MCMC procedures used for estimating marginal posterior distributions that we will see in Chap. 4.
60
2
The Bayesian Choice

posterior distribution shown in Fig. 2.14. Here the distribution is asymmetrical;
thus, mode, mean and median are not coincident. A usual choice for a point
estimation is to take the mean (0.93) because it minimises the quadratic risk,
which is conventional, although there are reasons for taking the median, as we said
before. Here the HPD interval at 95% is [1.00, 0.79], not symmetrical around
the mean, and shows better the uncertainty about the correlation than the s.e. of the
classical analysis. The probability of this correlation being negative is almost one.
2.6
Advantages of Bayesian Inference
We will summarise here the advantages of Bayesian inference:
•
We have a measure of uncertainty for both hypothesis tests and credibility
intervals, since we work with probabilities. We do not have ‘prior’ risks.
•
We are not worried about bias (there is no such thing as ‘bias’ in a Bayesian
context).
•
We should not decide whether an effect is ﬁxed or random (all of them are
random); we will consider different prior distributions instead, as we will see in
Chap. 7, Sect. 7.3.2.
•
We work with marginal probabilities, i.e. all multivariate problems are
converted to univariate, and we take into account errors of estimating other
parameters.
•
We have a method for inferences, a path to follow. We know that we should
calculate marginal posterior distributions, and we can express uncertainty in
several ways using them.
–1
–0.9
–0.8
–0.7
–0.6
–0.5
–0.4
Correlation coefficient
Fig. 2.14 Probability
distribution of a correlation
coefﬁcient. Notice that it is
highly asymmetric
2.6
Advantages of Bayesian Inference
61

Appendix 2.1
1. The mean minimises the risk: R ¼ Eu bu  u
ð
Þ2.
We should ﬁnd the value of bu that minimises R
∂R
∂bu ¼ 2  Eu bu  u
ð
Þ ¼ 0
!
Eu u
ð Þ ¼ Eu bu
ð Þ ¼ bu
where Eu bu
ð Þ ¼ bu, because u is not included in bu. The estimate bu is only function of
the data, and we are taking the mean Eu with respect to the values of u.
2. The median minimises the risk: R ¼ Eu bu  u
j
j
The loss function bu  u
j
j can be expressed as
L bu; u
ð
Þ ¼
bu  u
when bu > u
u  bu
when u > bu


The median m is deﬁned (see Chap. 3, Sect. 3.4.2) as
Z
m
1
f x
ð Þdx ¼ 0:50
We should prove now that the median m has a lower risk of the type
R ¼ Eu bu  u
j
j than any other estimator bu.
Assume that bu is the estimator of minimum risk of this type, and consider
without loss of generality that bu > m (an analogous demonstration can be made for
bu < m
).
Consider
now
the
difference
between
the
loss
functions
D ¼ L m; u
ð
Þ  L bu; u
ð
Þ.
m > u, bu > u,
D ¼ m  u  bu  u
ð
Þ ¼ m  bu
m < u, bu < u,
D ¼ u  m  u  bu
ð
Þ ¼ bu  m
m < u, bu > u,
D ¼ u  m  bu  u
ð
Þ ¼ 2u  m  bu < 2bu  m  bu ¼ bu  m
We do not consider the case m > u, bu < u because we have assumed that bu > m.
Thus, we can write
D 
m  bu
when m > u 50% of times; since m is the median
ð
Þ
bu  m
when m < u 50% of times; since m is the median
ð
Þ


62
2
The Bayesian Choice

Eu D
ð Þ ¼ Eu L m; u
ð
Þ  L bu; u
ð
Þ
½

 1
2 m  bu
ð
Þ þ 1
2 bu  m
ð
Þ ¼ 0 ! Eu L m; u
ð
Þ
½
  Eu L bu; u
ð
Þ
½

But as bu is the estimator of minimum risk, m cannot have a lower risk and should be
m ¼ bu; thus, the median is the estimator of minimum risk.
3. The mode minimises the risk: RISK ¼ 0 if bu ¼ u, RISK ¼ 1 otherwise
The demonstration of this requires complex operations that are out of the scope
of this book. The reader interested in it can consult, for example, Leonard and Hsu
(1999) or http://web.uvic.ca/~dgiles/blog/zero_one.pdf.
Appendix 2.2
We know (see Chap. 3, Sect. 3.3.2) that, if y is a function of x,
f y
ð Þ ¼ f x
ð Þ  dx
dy


then
median y
ð Þ !
Z my
1
f y
ð Þdy ¼ 1
2 ¼
Z my
1
f x
ð Þ  dx
dy

dy ¼
Z mx
1
f x
ð Þdx ! median x
ð Þ
Appendix 2.3
If we take a ﬂat prior f(θ) ¼ constant, as we know that x ¼ exp(log x),
f θjy
ð
Þ / f yjθ
ð
Þf θ
ð Þ / f yjθ
ð
Þ / exp log f yjθ
ð
Þ
½

We can develop a Taylor series of log f(θ| y) around the mode m, up till the
second term.
f θjy
ð
Þ / exp
θ  m
ð
Þ ∂log f yjθ
ð
Þ
∂θ


θ¼m
þ 1
2 θ  m
ð
Þ2 ∂2log f yjθ
ð
Þ
∂θ2
"
#
θ¼m
(
)
Since the mode is a maximum, the ﬁrst derivative is null, thus
Appendix 2.3
63

f θjy
ð
Þ / exp
1
2 
θ  m
ð
Þ2
∂2log f yjθ
ð
Þ
∂θ2
h
i1
θ¼m
0
B
@
1
C
A
which is the kernel of a Normal distribution with mean m and variance the inverse
of the second derivative of the log of the density function of the data applied in the
mode of the parameter (we will ﬁnd this expression again when we will introduce
the concept of information in Chap. 10). As the Normal distribution is symmetric,
mode, mean and median is the same.
References
Bernardo JM (1979) Reference posterior distributions for Bayesian inference. J R Stat Soc B
41:113–147
Blasco A (2005) The use of Bayesian statistics in meat quality analyses. Meat Sci 69:115–122
Blasco A, Gou P, Gispert M, Estany J, Soler Q, Diestre A, Tibau J (1994) Comparison of ﬁve types
of pig crosses. I. Growth and Carcass traits. Livest Prod Sci 40:171–178
Blasco A, Sorensen D, Bidanel JP (1998) A Bayesian analysis of genetic parameters and selection
response for litter size components in pigs. Genetics 149:301–306
de Finetti B (1937) La pre´vision: ses lois logiques, ses sources subjectives. Annales de l’Institut
Henri Poincaire´ 7:1–68. Translated in Kyburg HE, Smokler HE (1964) Studies in subjective
probability. Wiley, New York
Donkin WF (1851) On certain questions relating to the theory of probabilities. Philos Mag
1:353–368. 2:55–60
Fisher R (1925) Statistical methods for research workers. Oliver and Boyd, Edinburgh
Fisher R (1936) Uncertain inference. Proc Am Acad Arts Sci 71:245–258
Gelman A, Carlin JB, Stern HS, Dunson DB, Vehtari A, Rubin DB (2013) Bayesian data analysis,
3rd edn. Chapman and Hall, Boca Raton, FL
Herna´ndez P, Guerrero L, Ramı´rez J, Mekkawy W, Pla M, Ari~no B, Iba´~nez N, Blasco A (2005) A
Bayesian approach of the effect of selection for growth rate on sensory meat quality of rabbit.
Meat Sci 69:123–127
Hernandez P, Pla M, Blasco A (1998) Carcass characteristics and meat quality of rabbit lines
selected for different objectives. II. Relationships between meat characteristics. Livest Prod Sci
54:125–131
Howie D (2002) Interpreting probability: controversies and developments in the early twentieth
century. Cambridge University Press, New York
Howson C, Urbach P (1996) Scientiﬁc reasoning. The Bayesian approach. Open Court, Chicago,
IL
Jeffreys H (1931) Scientiﬁc inference. Oxford University Press, Oxford
Jeffreys H (1961) Theory of probabilities, 3rd edn. Clarendon Press, Oxford
Kant E (1781/1998) Critique of pure reason. Reprinted in translation. Cambridge University Press,
Cambridge
Kempthorne O (1984) Revisiting the past and anticipating the future. In: Statistics: an appraisal.
Proc. 50th Anniversary Iowa State Statistical Laboratory. The Iowa State University Press,
Ames, pp 31–52
Keynes JM (1921) A treatise on probability. Macmillan Publ. Co, London
Laplace PS (1774/1986) Memoir on the probabilities of the causes of events (Trad. by Stigler SM).
Stat Sci 1:364–378
Leonard T, Hsu JSJ (1999) Bayesian methods. Cambridge University Press, New York
64
2
The Bayesian Choice

Martı´nez-A´ lvaro M, Herna´ndez P, Blasco A (2016) Divergent selection on intramuscular fat in
rabbits: responses to selection and genetic parameters. J Anim Sci 94:4993–5003
Pearson K (1920) The fundamental problems of practical statistics. Biometrika 13:1–16
Pearson E (1962) Some thoughts on statistical inference. Ann Math Stat 33:394–403
Peiro´ R, Mercha´n M, Santacreu MA, Argente MJ, Garcı´a ML, Folch JM, Blasco A (2008)
Progesterone receptor gene as candidate gene for reproductive traits in rabbits. Genetics
180:1699–1705
Ramsey FP (1931) Truth and probability. In: Braithwaite RB (ed) The foundation of mathematics
and other logical essays. Routledge & Kegan, London
Robert CP (1992) L’Analyse statistique bayesienne. Economica, Paris, France
Zome~no C, Hernandez P, Blasco A (2013) Divergent selection for intramuscular fat content in
rabbits. I Direct response to selection. J Anim Sci 91:4526–4531
References
65

Posterior Distributions
3
If science cannot measure the degree of probability involved,
so much the worse for science. The practical man will stick to
his appreciative methods until it does, or will accept the
results of inverse probability of the Bayes/Laplace brand till
better are forthcoming.
Karl Pearson, 1920
This chapter introduces the tools we will use for Bayesian inference. We have seen in
Chap. 2 that we need a function, called ‘probability density function’, to produce
conﬁdence intervals and point estimates. We have also seen the advantages of
marginalisation. Here we will consider that our data come from a Normal distribution,
and we will show the probability density function of the data. As the Normal
distribution is deﬁned by two parameters, mean and variance, we will develop the
posterior marginal distributions of the mean and the variance given the data, which are
the distributions that we will use for inferences. We will also develop the conditional
distributions of the mean given the variance (and the data) and the variance given the
mean (and the data), because they will be needed for MCMC procedures.
3.1
Notation
From now on, bold type will be used for matrixes and vectors and capital letters for
matrixes. Thus ‘y’ represents a vector, ‘A’ is a matrix and ‘y’ is a scalar. Unknown
parameters will be represented by Greek letters, like μ and σ2.
The letter ‘f’ will always be used for probability density functions.1 The letter
‘P’ will be reserved for probability. The variables will be in red colour. For
example,
1It is common in statistical texts to use ‘p’ instead of ‘f’, but this may create to the reader that is
being introduced in the ﬁeld confusions with the probability.
# Springer International Publishing AG 2017
A. Blasco, Bayesian Data Analysis for Animal Scientists,
DOI 10.1007/978-3-319-54274-4_3
67

f yjσ2


¼
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2πσ2
p
exp  y  μ
ð
Þ2
2σ2
"
#
is a function of σ2, but it is not a function of ‘y’ or a function of μ, which are
considered constants. Thus, in this example, we represent a family of probability
density functions indexed at a constant value y. An example of this is the likelihood,
as we have seen in Chap. 1, Sect. 1.6.1.
The sign / means ‘proportional to’. We will often work with proportional
functions, since it is easier and we can obtain almost exact results from them
using MCMC. For example, if c and k are constants, the distribution N(0, 1) is
f y
ð Þ ¼
1ﬃﬃﬃﬃﬃ
2π
p
exp y2
2


/ exp y2
2


/ k  exp c
ð Þ  exp y2
2


/ k  exp c  y2
2


Thus, we can add or subtract constants from an exponent, or multiply or divide the
function if the constants are not in the exponent. Notice that we cannot add
constants or multiply the exponent by a constant; for example, for
f y
ð Þ / exp y2


we have
f y
ð Þ not proportional to k þ exp y2
ð
Þ
f y
ð Þ not proportional to exp c  y2
ð
Þ ¼ exp y2
ð
Þ
½
c
3.2
Probability Density Function
3.2.1
Definition
We will use an auxiliary function to describe our uncertainty about the unknown
parameters we want to estimate. This is the probability density function, which in
statistical texts is usually abbreviated as p.d.f. In this function, the area under the
curve for an interval [a, b] (Fig. 3.1) is the probability that the true value of the
parameter we estimate falls between the limits deﬁned by this interval.
P a  x  b
ð
Þ ¼
Z
b
a
f x
ð Þdx
Notice that for an arbitrary point x0, the value f(x0) is not a probability. As we
have seen before, probabilities are the areas deﬁned by f(x) between two points. In
Fig. 3.2, we can see that the area of small rectangles of the type f(x0)  Δx is
approximately a probability when Δx is small. These small probabilities are usually
68
3
Posterior Distributions

expressed as f(x) dx. Then, the integral between a and b is like summing up small
rectangles which surface is f(x)  dx, between a and b.
When this interval covers all possible values (1, 1), this probability is 1
P 1  x  1
ð
Þ ¼
Z þ1
1
f x
ð Þdx ¼ 1
3.2.2
Transformation of Random Variables
We know a probability density function f(x), and we want to ﬁnd the probability
density function f(y) of a function y ¼ g(x). Intuitively, the probability area f(x0)  Δx
should be the same as f(y0)  Δy when Δx and Δy are small enough. Thus, we can
write
a
b
Fig. 3.1 Probability density
function. The area in blue
between ‘a’ and ‘b’ is the
probability that the true value
of the parameter falls between
‘a’ and ‘b’
0.2
0.1
–0.1
–0.2
–0.3
–0.4
–0.5
–0.6
0
Intensity of flavour
Fig. 3.2 An example of
probability density function
for the trait ‘intensity of liver
ﬂavour’ of meat. Probabilities
are areas of f(x), for example,
the pink area shows P(x < 0),
and the yellow one P(x > 0).
The small rectangles f(x)  Δx
are approximate probabilities
3.2
Probability Density Function
69

f y
ð Þdy ¼ f x
ð Þdx
but it may happen that when x increases, y decreases, and then
f y
ð Þdy ¼ f x
ð Þdx
Taking both together
f y
ð Þ ¼ f x
ð Þ dx
dy

 ¼ f x
ð Þ dy
dx


1
In Appendix 3.1 we show a more formal demonstration of this. For example, we
have a Normal distribution f(x), and we want to know the distribution of y ¼ exp(x).
f x
ð Þ ¼
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2πσ2
p
exp  x  μ
ð
Þ2
2σ2
"
#
f y
ð Þ ¼ f x
ð Þ  dy
dx


1
¼
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2πσ2
p
exp  x  μ
ð
Þ2
2σ2
"
#

1
exp x
ð Þ
Since x ¼ ln(y), we ﬁnally get
f y
ð Þ ¼
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2πσ2
p
exp  ln y  μ
ð
Þ2
2σ2
"
#

1
exp ln y
ð
Þ ¼
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2πσ2
p
exp  ln y  μ
ð
Þ2
2σ2
"
#
 1
y
Notice that f(x) is deﬁned between 1 and +1, but f(y) is deﬁned between 0 and
+1.
In the multivariate case, we know f(x, y) and we want to know the density f(u, w),
where u and w are functions of (x, y)
u ¼ g x; y
ð
Þ;
w ¼ h x; y
ð
Þ
For example, f(x, y) is a known bivariate distribution, and we would like to know
the density of
x
xþy. This happens, for example, when in genetics we have the
densities of the additive and environmental variance of a trait, and we want to
know the density of the heritability, which is the ratio of the additive and the sum of
both variance components. In this case
u ¼ x;
w ¼
x
x þ y
The corresponding formula for the bivariate case is
f u; w
ð
Þ ¼ f x; y
ð
Þ  Jj j
where |J| is the absolute value of what in mathematics is called the ‘Jacobian’,
70
3
Posterior Distributions

J ¼ determinant of
∂f x
ð Þ
∂u
∂f x
ð Þ
∂w
∂f y
ð Þ
∂u
∂f y
ð Þ
∂w
2
64
3
75
This can be easily generalized for the multivariate case.
3.3
Features of a Distribution
3.3.1
Mean
The expectation or mean of a distribution is
E x
ð Þ ¼
Z 1
1
x  f x
ð Þdx
If we have a function of the random variable
y ¼ g x
ð Þ
We have seen in Sect. 3.3.2 that
f y
ð Þ ¼ f x
ð Þ dx
dy

;
thus, its expectation is
E y
ð Þ ¼
Z 1
1
y  f y
ð Þdy ¼
Z 1
1
g x
ð Þ  f x
ð Þ dx
dy

dy ¼
Z 1
1
g x
ð Þ  f x
ð Þdx
For example, if
y ¼ x2
E y
ð Þ ¼
Z 1
1
y  f y
ð Þdy ¼
Z 1
1
x2  f x
ð Þdx
3.3.2
Median
The median is the value dividing the area deﬁned by the probability density
function of the distribution in two parts, each one with a 50% of probability,
i.e. the median is the value mx that
Z mx
1
f x
ð Þdx ¼ 0:50
3.3
Features of a Distribution
71

3.3.3
Mode
The mode is the maximum of the probability density function of a distribution:
Mode ¼ argmax f x
ð Þ
3.3.4
Credibility Intervals
A credibility interval for a given probability, for example, 90%, is the interval [a, b]
containing 90% of the probability deﬁned by the density function; i.e. any values
‘a’ and ‘b’ for which
Z
b
a
f x
ð Þdx ¼ 0:90
constitute a credibility interval [a, b] at 90%. For example, when performing
inferences about some unknown parameter or about a difference between
treatments θ, an interval [a, b] with 90% probability would mean that the true
value of θ lies between the limits a, b of the interval with a probability of 90%.
Notice that there are inﬁnite credibility intervals at 90% of probability, but they
have different lengths, as we have seen in Chap. 2 (Fig. 2.7), providing different
accuracies about θ. One of these intervals is the shortest one (giving the best
accuracy), and in Bayesian inference, when the density function used is the
posterior density, it is called the highest posterior density interval at 90%
(HPD90%).
3.4
Conditional Distributions
3.4.1
Bayes Theorem
Although f(x) is not a probability, f(x)Δx is indeed a probability (see Fig. 3.2); thus,
we can apply Bayes theorem,
P AjB
ð
Þ ¼ P BjA
ð
Þ  P A
ð Þ
P B
ð Þ
f xjy
ð
ÞΔx ¼ f yjx
ð
ÞΔy  f x
ð ÞΔx
f y
ð ÞΔy
!
f xjy
ð
Þ ¼ f yjx
ð
Þ  f x
ð Þ
f y
ð Þ
Thus, we now have a version of Bayes theorem for probability density functions.
Considering x as the variable and ‘y’ as a given (constant) value,
72
3
Posterior Distributions

f xjy
ð
Þ ¼ f yjx
ð
Þ  f x
ð Þ
f y
ð Þ
which can be expressed proportionally, since f(y) is a constant,
f xjy
ð
Þ / f yjx
ð
Þ  f x
ð Þ
3.4.2
Conditional Distribution of the Sample of a Normal
Distribution
Let us now consider a sample y from a Normal distribution in which y ~ N(1μ, Iσ2)
where 1 is a unity vector (i.e. 10 ¼ [1, 1, 1. . .1]) and the sample components are
uncorrelated. The probability density function of y when we repeat the sampling
inﬁnite times is
f yjμ; σ2
ð
Þ
¼ f y1; y2 . . . ynjμ; σ2
ð
Þ ¼ f y1jμ; σ2
ð
Þ  f y2jμ; σ2
ð
Þ  . . .  f ynjμ; σ2
ð
Þ
¼
Y
n
1
f yijμ; σ2


¼
Y
n
1
1
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2πσ2
p
exp  yi  μ
ð
Þ2
2σ2
"
#
¼
1
ﬃﬃﬃﬃﬃ
2π
p

n σ2
ð
Þn=2exp 
X
n
1
yi  μ
ð
Þ2
2σ2
2
6664
3
7775;
this function is conditioned to the given values of μ and σ2; i.e. for each given value
of the mean and the variance, we have a different posterior density distribution. For
example, for a given mean μ ¼ 5 and variance σ2 ¼ 2, and for a sample of three
elements y0 ¼ [y1, y2, y3], we have, in repeated sampling,
f yjμ; σ2


¼
1
ﬃﬃﬃﬃﬃ
2π
p

3 2
ð Þ3=2 exp  y1  5
ð
Þ2 þ y2  5
ð
Þ2 þ y3  5
ð
Þ2
2  2
"
#
3.4.3
Conditional Posterior Distribution of the Variance of a
Normal Distribution
We can also write the conditional posterior distribution of the variance for a given
sample ‘y’ and a given mean ‘μ’. We do not know f(σ2| μ, y), but we can apply Bayes
theorem, and we obtain
f σ2jμ; y


/ f yjσ2; μ


f σ2


3.4
Conditional Distributions
73

applying the principle of indifference (see Chap. 2, Sect. 2.1.3); we will consider in
this example that a priori all values of the variance have the same probability
density, i.e. f(σ2) ¼ constant. This leads to
f σ2jμ; y


/ f yjσ2; μ


;
but we know the distribution of the data, which we have assumed to be Normal;
thus, we can write the conditional distribution of the variance
f σ2jμ; y


/ f yjσ2; μ


¼
1
ﬃﬃﬃﬃﬃ
2π
p

n σ2
ð
Þn=2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775
Notice that the variable is coloured in red; thus, here the variance is the variable,
and the sample and the mean are given constants. For example, if the mean and the
sample are
μ ¼ 1
y0 ¼ 2; 3; 4
½

for this given mean and this given sample, the p.d.f. of the conditional distribution
of the variance is
f σ2jμ; y


/
1
σ2
ð
Þ3=2 exp  2  1
ð
Þ2 þ 3  1
ð
Þ2 þ 4  1
ð
Þ2
2σ2
"
#
¼
1
σ2
ð
Þ3=2 exp 14
σ2

	
Notice that this is not a Normal distribution. There is a type of distribution called
‘inverted gamma’, that is,
f xjα; β
ð
Þ /
1
xαþ1 exp β
x

	
where ‘α’ and ‘β’ are parameters that determine the shape of the function (see
Fig. 3.3).2 We can see that the conditional distribution of the variance in this
example is of the type ‘inverted gamma’ if we take β ¼ 14, α þ 1 ¼ 3
2. In general,
the conditional distribution of the variance of a Normal distribution is an inverted
gamma with parameters
α ¼ n
2  1;
β ¼ 1
2
X
n
1
yi  μ
ð
Þ2
2This distribution is also called ‘inverse gamma’ or ‘inverted chi square’ distribution.
74
3
Posterior Distributions

3.4.4
Conditional Posterior Distribution of the Mean of a Normal
Distribution
The p.d.f. of the conditional distribution of the mean for a given sample y and a
given variance σ2, applying Bayes theorem, is
f μjσ2; y


/ f yjμ; σ2


f μ
ð Þ
Applying the principle of indifference, we will consider f(μ) ¼ constant. This
leads to
f μjσ2; y


/ f yjμ; σ2


As we know the distribution of the data that we have assumed to be Normal,
f μjσ2; y


/
1
σ2
ð
Þn=2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775
Notice that the variable is coloured in red; thus, here the mean is the variable,
and the data and the variance are given constants. For example, if the variance and
the sample are
σ2 ¼ 9
y0 ¼ 2; 3; 4
½

for this given variance and this given sample, the p.d.f. of the conditional posterior
distribution of the mean is
Fig. 3.3 Different inverted
gamma distributions for
different ‘α’ and ‘β’
parameters
3.4
Conditional Distributions
75

f μjσ2; y
ð
Þ /
1
9
ð Þ3=2exp  2  μ
ð
Þ2 þ 3  μ
ð
Þ2 þ 4  μ
ð
Þ2
2  9
"
#
/ exp  3μ2  18μ þ 29
18

	
This can be transformed into a Normal distribution easily
f μjσ2; y


/ exp 1
2
μ  3
ð
Þ2
9
3
"
#
/
1
ﬃﬃﬃﬃﬃ
2π
p

9
3
 1=2 exp 1
2
μ  3
ð
Þ2
9
3
"
#
which is a Normal distribution with mean 3 (the sample mean) and variance 9 (the
given variance divided by the number of data). Here we have added the constants
needed for the Normal distribution
ﬃﬃﬃﬃﬃ
2π
p

9
3
 1=2


using the advantage of working
with proportionality, as we have seen in Sect. 3.1.
In a general form, we have (Appendix 3.2)
f μjσ2; y


/
1
σ2
ð
Þn=2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775 /
1
ﬃﬃﬃﬃﬃ
2π
p
σ2
n
 1=2 exp  μ  y
ð
Þ2
2 σ2
n
"
#
which is a Normal distribution in which the mean is the sample mean y and the
variance is the given variance σ2 divided by the sample size.
3.5
Marginal Distributions
3.5.1
Definition
We saw in Chap. 2, Sect. 2.2.3 the advantages of marginalisation. When we have a
bivariate probability density f(x, y), a marginal density f(x) is
f x
ð Þ ¼
Z 1
1
f x; y
ð
Þdy ¼
Z 1
1
f xjy
ð
Þf y
ð Þdy
The marginal density f(x) takes the average of all values of ‘y’ for each x, i.e. adds
all values of ‘y’ in f(x| y), multiplied by their probability f(y)dy.
A density can be marginal for one variable and conditional for another one. For
example, a marginal p.d.f. of x with respect to variable y, conditioned in ‘z’, is
shown below
76
3
Posterior Distributions

f xjz
ð
Þ ¼
Z 1
1
f x; yjz
ð
Þdy ¼
Z 1
1
f xjy; z
ð
Þf yjz
ð
Þdy
where ‘y’ has been integrated out and ‘z’ is conditioning the values of ‘x’. Notice
that the variable ‘y’ does not appear in f(x| z) because, for each value of ‘x’, all the
possible values of ‘y’ have been considered, multiplied by their respective proba-
bility and summed up; thus, we do not need to give a value to ‘y’ in order to obtain
f(x| z). However, the conditional variable appears in f(x| z) because for each given
value of ‘z’, we obtain a different value of f(x| z). We will see an example in the next
section.
3.5.2
Marginal Posterior Distribution of the Variance of a Normal
Distribution
The p.d.f. of the marginal posterior distribution of the variance conditioned to the
data is
f σ2jy


¼
Z 1
1
f μ; σ2jy


dμ
Here the mean is integrated out, and the data are conditioning the values of the
variance, which means that we will obtain a different distribution for each sample.
We will call this distribution ‘the marginal distribution of the variance’ as a short
name, because in Bayesian inference, it is implicit that we are always conditioning
in the data. Bayesian inference is always based in the sample, not in conceptual
repetitions of the experiment; the sample is always ‘given’.
We do not know f(μ, σ2| y), but we can ﬁnd it out applying Bayes theorem
because we know the distribution f(y| μ, σ2). If the prior information f(μ, σ2)
is constant because we apply the principle of indifference as before, we will
have
f μ; σ2jy


¼ f yjμ; σ2
ð
Þf μ; σ2
ð
Þ
f y
ð Þ
/ f yjμ; σ2


f μ; σ2


/ f yjμ; σ2


and the marginal p.d.f. is
f σ2jy


¼
Z 1
1
f μ; σ2jy


dμ /
Z 1
1
f yjμ; σ2


dμ
¼
Z 1
1
1
2π
ð
Þn=2 σ2
ð
Þn=2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775dμ
3.5
Marginal Distributions
77

After integration (Appendix 3.3),
f σ2jy


/
1
σ2
ð
Þ
n1
2 exp 
P
n
1
yi  y
ð
Þ2
2σ2
2
664
3
775
which is an Inverted Gamma distribution with parameters α, β
β ¼ 1
2
X
n
1
yi  y
ð
Þ2
α ¼ n  1
2
 1 ¼ n  3
2
For example, if we have the sample
y0 ¼ 2; 3; 4
½

the marginal distribution of the variance is
f σ2jy
ð
Þ /
1
σ2
ð
Þ
31
2 exp  2  2þ3þ4
3

2 þ 3  2þ3þ4
3

2 þ 4  2þ3þ4
3

2
2σ2
"
#
¼ 1
σ2exp  1
σ2

	
Notice that the mean does not appear in the formula. To write the probability
density function of the variance conditioned to the mean and to the data, we should
have the mean and the data. Here we should only provide the data because the mean
has been integrated out.
3.5.3
Marginal Posterior Distribution of the Mean of a Normal
Distribution
The p.d.f. of the marginal posterior distribution of the mean conditioned to the data
is
f μjy
ð
Þ ¼
Z 1
0
f μ; σ2jy


dσ2
Here the variance is integrated out, and the data is conditioning the values of the
mean, which means that we will obtain a different distribution for each sample. We
will call this distribution ‘the marginal distribution of the mean’ as a short name,
because, as we said before, in Bayesian inference it is implicit that we are always
conditioning the data.
78
3
Posterior Distributions

We do not know the function f(μ, σ2| y), but applying Bayes theorem we can ﬁnd
it out, because we know the distribution f(y| μ, σ2).
f μ; σ2jy


¼ f yjμ; σ2
ð
Þf μ; σ2
ð
Þ
f y
ð Þ
/ f yjμ; σ2


f μ; σ2


if we admit the indifference principle to show vague prior information, then we can
take f(μ, σ2) as a constant; thus,
f μ; σ2jy


/ f yjμ; σ2


and the marginal density of the mean is
f μjy
ð
Þ /
Z
f yjμ; σ2


dσ2 ¼
Z 1
0
1
2π
ð
Þn=2 σ2
ð
Þn=2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775dσ2
This integral is solved in Appendix 3.4, and the result is
f μjy
ð
Þ /
1 þ
n
n  1  μ  y
ð
Þ2
s2
"
#n2
2
where
y ¼ 1
n
X
n
1
yi;
s2 ¼
1
n  1
X
n
1
yi  y
ð
Þ2
This is a Student t-distribution with n  1 degrees of freedom, having a mean,
which is the sample mean, and a variance that is the sample quasi-variance; thus
f μjy
ð
Þ / tn1 y; s2


For example, if y0 ¼ [2, 3, 4]
y ¼ 1
3 2 þ 3 þ 4
ð
Þ ¼ 3
s2 ¼
1
3  1
2  3
ð
Þ2 þ 3  3
ð
Þ2 þ 4  3
ð
Þ2
h
i
¼ 1
f μjy
ð
Þ /
1 þ
3
2  1  μ  3
ð
Þ2
1
"
#3
2
3.5
Marginal Distributions
79

Notice that the variance does not appear in the formula. When we wrote the
density of the mean conditioned to the variance and to the data, we had to give the
variance and the data. Here we should only give the data because the variance has
been integrated out.
Appendix 3.1
We deﬁne the cumulative distribution function at the point y0 as
F y0
ð
Þ ¼ P y  y0
ð
Þ ¼
Z y0
1
f y
ð Þdy,
forally0
We know a p.d.f. f(x) and what we want is to ﬁnd the p.d.f. f(y) of a function
y ¼ g x
ð Þ
We will ﬁrst assume that g(x) is a strictly increasing function, as in Fig. 3.4a.
F y0
ð
Þ ¼ P y  y0
ð
Þ ¼ P g x
ð Þ  y0
½

but since g(x) is an increasing function, we know that
g x
ð Þ  y0 ! x  x0
then, we would have
F y0
ð
Þ ¼ P x  x0
ð
Þ ¼ F x0
ð
Þ ! forally0 andx0, F y
ð Þ ¼ F x
ð Þ
Now, from the deﬁnition of the distribution function, we have
y0
x0
x0
y0
g(x)
g(x)
a
b
Fig. 3.4 (a) When g(x) is a monotonous increasing function. (b) When g(x) is a monotonous
decreasing function
80
3
Posterior Distributions

f y
ð Þ ¼ dF y
ð Þ
dy
¼ dF x
ð Þ
dy
¼ dF x
ð Þ
dx
 dx
dy ¼ f x
ð Þ  dx
dy
Now suppose that g(x) is a strictly decreasing function, as in Fig. 3.4b. By the
deﬁnition of distribution function, we would have
F y0
ð
Þ ¼ P y  y0
ð
Þ ¼ P g x
ð Þ  y0
½

but as g(x) is a decreasing function, we know that
g x
ð Þ  y0 ! x  x0
then, we have
F y0
ð
Þ ¼ P x  x0
ð
Þ ¼ 1  P x  x0
ð
Þ ¼ 1  F x0
ð
Þ ! F y
ð Þ ¼ 1  F x
ð Þ
because this applies for every x0. Now, by deﬁnition of density function, we have
f y
ð Þ ¼ dF y
ð Þ
dy
¼ d 1  F x
ð Þ
½

dx
 dx
dy ¼ f x
ð Þ  dx
dy
Finally, putting together both cases, we have
f y
ð Þ ¼ f x
ð Þ  dx
dy

 ¼ f x
ð Þ  dy
dx


1
Appendix 3.2
We consider ﬁrst that the numerator in the exp is
X
n
1
yi  μ
ð
Þ2 ¼
X
n
1
yi  y þ y  μ
ð
Þ2 ¼
X
n
1
yi  y
ð
Þ  μ  y
ð
Þ
½
2
¼
X
n
1
yi  y
ð
Þ2 þ
X
n
1
μ  y
ð
Þ2  2
X
n
1
yi  y
ð
Þ μ  y
ð
Þ
¼
X
n
1
yi  y
ð
Þ2 þ n μ  y
ð
Þ2
because the double product is null
Appendix 3.2
81

X
n
1
yi  y
ð
Þ μ  y
ð
Þ ¼ μ  y
ð
Þ
X
n
1
yi  y
ð
Þ ¼ μ  y
ð
Þ
X
n
1
yi
ð Þ  ny
"
#
¼ μ  y
ð
Þ
X
n
1
yi
ð Þ  n1
n
X
n
1
yi
ð Þ
"
#
¼ 0
Then, substituting in the formula, we have
f μjσ2; y
ð
Þ /
1
σ2
ð
Þn=2 exp 
X
n
1
yi  μ
ð
Þ2
2σ2
2
6664
3
7775
/
1
σ2
ð
Þn=2 exp 
X
n
1
yi  y
ð
Þ2
2σ2
2
6664
3
7775exp  n μ  y
ð
Þ2
2σ2
"
#
/ exp  n μ  y
ð
Þ2
2σ2
"
#
/
1
ﬃﬃﬃﬃﬃ
2π
p
σ2
n
 1=2exp  μ  y
ð
Þ2
2 σ2
n
2
664
3
775
Appendix 3.3
f σ2jy


/
Z 1
1
1
2π
ð
Þn=2 σ2
ð
Þn=2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775dμ
We can place out of the integral everything but μ; thus, considering the factori-
zation of the numerator within the exp that we have made in Appendix 3.2, we can
write
f σ2jy


/
1
σ2
ð
Þn=2 exp 
P
n
1
yi  y
ð
Þ2
2σ2
2
664
3
775
Z 1
1
exp  n yi  μ
ð
Þ2
2σ2
"
#
dμ
We can include within the integral any constant or variable with the exception of
μ; thus, we multiply out of the integral and divide inside the integral by the same
expression and write
82
3
Posterior Distributions

f σ2jy


/
ﬃﬃﬃﬃﬃ
2π
p
σ2
n

 1=2
σ2
ð
Þn=2
exp 
P
n
1
yi  y
ð
Þ2
2σ2
2
664
3
775
Z 1
1
1
ﬃﬃﬃﬃﬃ
2π
p
σ2
n
 1=2 exp  μ  y
ð
Þ2
2 σ2
n
"
#
dμ
The expression inside the integral is a density function (a Normal function) of μ,
and the integral is 1; thus,
f σ2jy


/
1
σ2
ð
Þ
n1
2 exp 
P
n
1
yi  y
ð
Þ2
2σ2
2
664
3
775
Appendix 3.4
f μjy
ð
Þ /
Z 1
0
1
2π
ð
Þn=2 σ2
ð
Þn=2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775dσ2
We can include within the integral any constant or variable with the exception of
σ2; thus, we divide out of the integral and multiply inside the integral by the same
expression and write
f μjy
ð
Þ /
Γ α
ð Þ
P
n
1
yi  μ
ð
Þ2

	n2
2

Z 1
0
1
Γ α
ð Þ
P
n
1
yi  μ
ð
Þ2
2
2
664
3
775
n2
2
σ2

n=2exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775dσ2
Now, if we call x ¼ σ2, the inside part of the integral looks like
f xjα; β
ð
Þ ¼
1
Γ α
ð Þ βαx αþ1
ð
Þexp β
x

	
where
Appendix 3.4
83

β ¼
P
n
1
yi  μ
ð
Þ2
2
;
α ¼ n
2  1 ¼ n  2
2
This results an inverted gamma distribution, and thus the value of the integral is
1. Then, we have
f μjy
ð
Þ /
1
P
n
1
yi  μ
ð
Þ2

	n2
2
This can be transformed according to the factorization of Appendix 3.2
f μjy
ð
Þ /
X
n
1
yi  μ
ð
Þ2
"
# n2
2
¼
X
n
1
yi  y
ð
Þ2 þ n μ  y
ð
Þ2
"
# n2
2
¼
n  1
ð
Þs2 þ n μ  y
ð
Þ2
h
i n2
2
¼ n  1
ð
Þs2 1 þ n μy
ð
Þ2
n1
ð
Þs2
h
i n2
2 / 1 þ
n
n1  μy
ð
Þ2
s2
h
i n2
2
where
y ¼ 1
n
X
n
1
yi;
s2 ¼
1
n  1
X
n
1
yi  y
ð
Þ2
Reference
Pearson K (1920) The fundamental problems of practical statistics. Biometrika 13:1–16
84
3
Posterior Distributions

MCMC
4
Before I had succeeded in solving my problem analytically,
I had endeavoured to do so empirically. The material used
was a correlation table containing the height and left middle
ﬁnger measurements of 3000 criminals, from a paper by
W. R. Macdonell (Biometrika, Vol. I, p. 219). The
measurements were written out on 3000 pieces of cardboard,
which were then very thoroughly shufﬂed and drawn at
random. As each card was drawn its numbers were written
down in a book which thus contains the measurements of
3000 criminals in a random order. Finally each consecutive
set of 4 was taken as a sample—750 in all—and the mean,
standard deviation, and correlation of each sample
determined.
William Searly Gosset (‘Student’), 1908
We introduce in this chapter a numerical method, Markov Chain Monte Carlo
(MCMC), which will allow us to ﬁnd an accurate estimate of the marginal
posterior distributions without the need of solving the integrals required for
marginalisation. The formal justiﬁcation of the MCMC procedure is complex
and out of the scope of this book, but we can intuitively understand how it
works. We will see with some detail the most common MCMC procedure used
in animal production, Gibbs sampling, and we will sketch other common MCMC
procedures. This is an active research area with continuous new developments,
but it is not a part of Bayesian statistics. MCMC is only a numerical tool for
approximating marginal posterior distributions without solving the integrals that
stopped in the past the practical development of Bayesian statistics in many ﬁelds
of knowledge.
# Springer International Publishing AG 2017
A. Blasco, Bayesian Data Analysis for Animal Scientists,
DOI 10.1007/978-3-319-54274-4_4
85

4.1
Samples of Marginal Posterior Distributions
4.1.1
Taking Samples of Marginal Posterior Distributions
We have seen in Chap. 2 that two great advantages of Bayesian inference are
marginalisation and the possibility of calculating probability intervals. Integrals
should be performed for both marginalising and obtaining these intervals. This does
not represent a problem for very simple models, but the difﬁculty increases when
models have several effects and different variance components. These difﬁculties
stopped the progress of Bayesian inference for many years, and often the only
practical solution was to ﬁnd a multivariate mode, renouncing to the possibility of
marginalisation. Even obtaining the precision of these modes was an impossible
task in many circumstances, because it was also necessary to calculate integrals
to ﬁnd credibility intervals. Most of these problems disappeared when a system
of integration based in random sampling of Markov chains was made available.
Using these methods, we do not obtain the posterior marginal distributions, but
just random samples from them. This may look disappointing, but has many
advantages, as we will see soon.
Let us put an example. We need to ﬁnd the marginal posterior distribution of the
difference between the treatments S and C for the meat quality trait ‘ﬂavour
intensity’, given the data, measured by a panel test in a scale from 1 to 5. We are
going to estimate this distribution by obtaining random samples of the marginal
posterior distribution of the treatments given the data. We obtain two lists of
random numbers
f Sjy
ð
Þ : 3:1; 3:3; 4:1; 4:8; 4:9; . . .
½

f Cjy
ð
Þ : 2:4; 2:6; 2:6; 2:6; 2:8; . . .
½

Since both lists are random samples of the marginal posterior distributions of
the effects, the difference sample by sample (i.e. 3.1  2.4 ¼ 0.7, 3.3  2.6 ¼ 0.7,
4.1  2.6 ¼ 1.5, 4.8  2.6 ¼ 2.2, etc.) is a list of numbers that are also a random
sample of the difference between treatments:
f S  Cjy
ð
Þ : 0:7; 0:7; 1:5; 2:2; 2:1; . . .
½

These lists are Markov chains. Since they are formed by random samples, they are
called Monte Carlo, as the famous casino. We can make a histogram with these
numbers and obtain an approximation of the posterior distribution of S  C given
the data y (Fig. 4.1).
From this random sample, it is easy to make Bayesian inferences, as we will see
later. For example, if we want to estimate the mean of this posterior distribution, we
just calculate the average of the chain of numbers sampled from f(S  C | y).
This chain of sampled numbers from the posterior distribution can be as large as
we want; thus, we can estimate the posterior distribution as accurately as we need.
86
4
MCMC

There is a sampling error that depends on the size of the sample, but also on how
correlated the samples are. For example, if we take 500 samples and the correlation
between them is 1, we do not have 500 samples because it is always the same one.
We can calculate the correlation between two consecutive samples of the chain, and
if it is too high, we can just throw away samples and take, for example, one in each
100 samples; this will reduce the correlation between two consecutive samples in
our ﬁnal chain. We can calculate the ‘effective number’ of the chain, i.e. the sample
size of uncorrelated numbers that estimates the posterior distribution with the same
accuracy as with our current chain. It is important to notice that, having many
samples from the chains, we augment the precision of the estimation of the posterior
distribution, but we do not augment the precision of our experiment, which depends
on the number of data we have, i.e. in our data sample size, not in the sample size of
the chain. If the posterior distribution has a large variance, the experiment is
inaccurate, although this variance and other features of the posterior distribution
can be calculated as accurately as we want.
4.1.2
Making Inferences from Samples of Marginal Posterior
Distributions
From a chain of samples, we can make inferences. Let us take the former example,
in which we have a chain of random samples of the posterior distribution for the
difference between the treatments. We now have a chain of 30 samples. Let us order
the chain from the lowest to the highest values
f S  Cjy
ð
Þ : 0:5; 0:4; 0:2; 0:1; 0:1; 0:0; 0:0; 0:1; 0:2; 0:2; 0:2; 0:2; 0:5; 0:6;
½
0:6; 0:7; 0:7; 1:1; 1:1; 1:3; 1:5; 1:8; 1:8; 1:8; 1:8; 2:0; 2:0; 2:1; 2:2; 2:4
0.2
0.1
–0.1
–0.2
–0.3
–0.4
–0.5
–0.6
0
Intensity of flavour
Fig. 4.1 A histogram made
by randomly sampling the
posterior distribution of the
difference between two
treatments f(S  C | y) for
‘intensity of ﬂavour’
4.1
Samples of Marginal Posterior Distributions
87

Now we want to make the following inferences:
1. What is the probability of S being higher than C (Fig. 2.8a of Chap. 2)?
P S > C
ð
Þ ¼ P S  C > 0
ð
Þ
We estimate this probability counting how many samples higher than zero we
have and divide by the total number of samples. We have 23 samples higher than
zero from 30 samples: thus, our estimate is
P S > C
ð
Þ ¼ 23
30 ¼ 0:77
2. What is the probability of the difference between groups being higher than a
relevant value that, before making the experiment, we determine to be 0.5
(Fig. 2.10a of Chap. 2)?
We count how many samples are higher than 0.5. We ﬁnd 17 samples higher
than 0.5. Since we have 30 samples, the probability of the difference between
groups being higher than 0.5 is
P S  C > 0:5
ð
Þ ¼ 17
30 ¼ 0:57
3. What is the probability of the difference between the groups being different from
zero (Fig. 2.11a of Chap. 2)?
Strictly speaking, the probability of being different from zero is 1, since this
difference will never exactly take the value 0.000000. . .; thus, we have to reformu-
late the question. We should deﬁne the minimum value of this difference from
which lower values will be considered, in practice, as null. We have deﬁned
this ‘relevant value’ in Chap. 2. Reformulating the question, the new question
should be:
What is the probability of similitude between the groups?
or
What is the probability of the difference between the groups being irrelevant
(like zero, for practical purposes)?
For clarity, we will use a different relevant value in this example. We decide,
basing our decision in our knowledge of the problem, that a relevant difference will
be any one equal or higher than 0.1. We see that only two samples are lower than
0.1 and higher than 0.1; thus,
88
4
MCMC

P S  C
j
j  Relevant value
ð
Þ ¼ 2
30 ¼ 0:07
4. What is the probability of the difference between groups being between 0.1 and
2.0 (Fig. 2.3 of Chap. 2)?
We have 20 samples between both values (including them); thus,
P 0:1  S  C  2:0
ð
Þ ¼ 20
30 ¼ 0:67
5. What is the guaranteed value with a probability of 70%, i.e. the minimum value
that the difference between treatments can take with a probability of 70%
(Fig. 2.9a of Chap. 2)?
We look for a guaranteed value with a probability of 70%, as deﬁned in Chap. 2.
Let us take the last 70% of the samples of our ordered chain. A 70% of 30 samples
is 21 samples; thus, we take the last 21 samples of the chain. The ﬁrst value of this
set, which is the lowest one as well, is 0.2; thus, we say that the difference between
groups is at least of 0.2 with a probability of 70%; i.e. the guaranteed value with a
probability of 70% is 0.2.
6. What is the lowest maximum value that the difference between groups can take
with a probability of 0.90? (Fig. 2.9b of Chap. 2).
We take the ﬁrst 90% of the samples of our ordered chain. A 90% of 30 samples
are 27 samples; thus, we take the ﬁrst 27 samples, and the highest value of this set
(the last sample) is 2.0. Thus, we say that the difference between groups will be 2.0
as a maximum with a probability of 90%.
7. What is the shortest interval containing a 90% of probability (Fig. 2.7a of
Chap. 2)?
The shortest interval (i.e. the most precise one) is calculated by considering all
possible intervals containing the same probability. Since 90% of 30 samples are
27 samples, such an interval will contain 27 samples. Let us consider all possible
intervals with 27 samples. These intervals are [0.5, 2.0], [0.4, 2.1], [0.2, 2.2].
The ﬁrst interval has a length of 2.5, the second one 2.5, and the third one 2.4; thus,
the shortest interval containing 90% probability is [0.2, 2.2].
8. Give an estimate of the difference between groups (Fig. 2.5 of Chap. 2).
Although it is somewhat illogical to say that this difference has a determined
value, just to immediately say that we are not sure about this value (and give an
4.1
Samples of Marginal Posterior Distributions
89

interval), it is usual to give point estimates of the differences between treatments.1
We have seen that we can give the mean, median or mode of the posterior
distribution. The mean is the average of the chain, and the median the value in
the middle, the value between the sample 15 and 16.
Estimate of the mean and median of the posterior distribution
Mean ¼ 1
30
X
0:2;0:2;0:1;0:1;0:1;0:0;0:0;0:1;0:2;0:2;0:2;0:2;0:5;0:6;
ð
0:6;0:7;0:7;1:1;1:1;1:3;1:5;1:8;1:8;1:8;1:8;2:0;2:0;2:1;2:1;2:2Þ ¼ 0:86
Median ¼ 0:6 þ 0:7
2
¼ 0:65
To estimate the mode, we need to draw the distribution, since we have a ﬁnite
number of samples (e.g. it can happen that by chance we have few samples of the
most probable value).
In this example, mode and median differ, showing that the distribution is
asymmetric. Which estimate should be given is a matter of opinion; we should
just be aware of the advantages and disadvantages, expressed in Chap. 2, Sect.
2.2.1. When working with MCMC chains, statisticians often prefer medians as
point estimates.2 Medians have also the advantage of being robust to outliers; for
example, take a sample of food conversion rate in pigs in which there is an error in
the last data,
2:3; 2:3; 2:3; 2:4; 2:5; 2:5; 24
½
:
The mean of this set is 5.5, but the median is 2.4, much closer to what should be the
real value. Sometimes the chains can sample outliers (particularly when we are
creating new chains from the chains we obtained by MCMC; for example, combin-
ing two chains for having a chain of the ratio, when the denominator is not far from
zero). Medians are robust to these outliers.
1Ronald Fisher was particularly critical with ‘point estimation’. In a rude statement against
Neyman and Pearson, he said that the distinction between point and interval estimation was
made to support the claim of that they made an original contribution, showing great conﬁdence
in the ignorance of students to support this claim (Fisher 1959, p. 143).
2Medians have a larger standard error than means, and this is the reason that means are preferred
when we are taking inferences directly from a data sample. However, here we are calculating
means and medians of large chains; thus, the s.e. of the mean or the median of the chain is
irrelevant since it can be made as small as we want. As we said before, this will not improve the
accuracy of our experiment, but the accuracy of the estimation of our marginal posterior distribu-
tion and its features.
90
4
MCMC

4.2
Gibbs Sampling
4.2.1
How It Works
Now the question is how to obtain samples of marginal posterior distributions. We
will start with a simple example: how to obtain random samples from a joint
posterior distribution f(x, z) that are also sets of samples from the marginal posterior
distributions f(x), f(z). In Chap. 5 we will estimate the marginal posterior
distributions of the mean and the variance of a Normal distribution, in Chaps. 6
and 7 we will estimate marginal posterior distributions of the parameters of linear
models, and in Chap. 8 we will see how to estimate marginal posterior distributions
of a variety of models. A common MCMC technique for obtaining samples from
the marginal posterior distribution is called ‘Gibbs sampling’.3 What we need for
obtaining these samples is:
1. Univariate distributions of each unknown parameter conditioned to the other
unknown parameters; i.e. we need f(x| z) and f(z| x).
2. Functions allowing us to extract random samples from these conditional
distributions.
The ﬁrst step is easy, as we have seen in Chap. 3. The second step is easy if the
conditional distribution has a recognisable form (Normal, Gamma, Poisson, etc.)
for which we have functions allowing us to extract random samples. For example,
to extract random samples from a Normal distribution:
(a)
Take a random sample x between 0 and 1 from a random number generator (all
computers have this).
(b)
Calculate y ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2logx
p
 cos 2πx
ð
Þ.
Then y is a random sample of a N(0, 1).
When we do not have this function because the conditional distribution is not a
known function or we do not have algorithms allowing us to extract random
samples from it, other MCMC techniques can be used, but they are much more
laborious as we will see later.
Once we have several conditional distributions from which we can sample, the
Gibbs sampling mechanism starts as follows (Fig. 4.2):
1. Start with an arbitrary value for z, for example, z ¼ 1.
2. Extract one random sample from the conditional distribution f(x| z ¼ 1). Suppose
this random sample is x ¼ 4.
3Gibbs sampling was proposed by Geman and Geman in 1984. They proposed the name ‘Gibbs
sampling’ for the method because they were using Gibbs distributions in their paper (John Willard
Gibbs was a famous nineteen-century scientists, creator of statistical mechanics, who made key
contributions in thermodynamics).
4.2
Gibbs Sampling
91

3. Extract one random sample from the conditional distribution f(z| x ¼ 4). Suppose
this random sample is z ¼ 5.
4. Extract one random sample from the conditional distribution f(x| z ¼ 5). Suppose
this random sample is x ¼ 2.
5. Extract one random sample from the conditional distribution f(z| x ¼ 4). Suppose
this random sample is z ¼ 6.
6. Continue with the process until obtaining two long chains:
x: 4, 2, . . .
z: 5, 6, . . .
7. Disregard the ﬁrst samples. We will see later how many samples should be
disregarded and why.
8. Consider that the samples not disregarded are samples from the marginal
distributions f(x) and f(z).
4.2.2
Why It Works
Markov Chain Monte Carlo is a complex branch of the mathematics requiring a
considerable effort for developing and understanding the main results. Exposing the
mathematical methodology of these numeric methods is out of the scope of this
book. Nevertheless, we will expose here intuitively the methods we need for our
f(x|z = 1)
z = 1 arbitrary
4
5
2
6
f(z|x = 4)
f(x|z = 5)
f(z|x = 2)
Fig. 4.2 Gibbs sampling
at work
92
4
MCMC

inferences, in order to understand how and why MCMC works. Consider the former
example. Figure 4.3 shows f(x, z) represented as lines of equal probability density
(as level curves in a map).
Take an arbitrary value for z, say z ¼ 1. Sample a random number from the
conditional probability density function f(x| z ¼ 1), which is the probability density
function having all possible values for x but in which all values of z are z ¼ 1. This
function is represented in Fig. 4.3 as the line z ¼ 1; notice that we have more
probability density between ‘a’ and ‘b’ (in green) than in other parts of this line.
Therefore, the number sampled from f(x| z ¼ 1) will be found between ‘a’ and ‘b’
more probably than in other parts of the conditional distribution. Suppose that the
number sampled is x ¼ 4.
Now sample a random number from the conditional density f(z| x ¼ 4). This
distribution is represented in Fig. 4.3 as the line x ¼ 4 that has more density of
probability between ‘c’ and ‘d’ (in blue) than in other parts of this line. Therefore,
the number sampled from f(z| x ¼ 4) will be found between ‘c’ and ‘d’ more
probably than in other parts of the conditional distribution. Suppose that the number
sampled is z ¼ 5.
Now sample a random number from the conditional density f(x| z ¼ 5). This
distribution is represented in Fig. 4.3 as the line z ¼ 5 that has more density of
probability between ‘e’ and ‘f’ (in red) than in other parts of this line. Therefore, the
number sampled from f(x| z ¼ 5) will be found between ‘e’ and ‘f’ more probably
than in other parts of the conditional distribution. Suppose that the number sampled
is x ¼ 2.
f(xÔz = 1)
f(x,z)
z = 1 arbitrary
4
5
2
6
f(zÔx = 4)
z
x
f(xÔz = 5)
f(zÔx = 2)
x = 2
z = 1
z = 5
z = 6
x = 4
e
f
d
a
b
g
h
c
Fig. 4.3 Gibbs sampling. The curves represent lines of equal probability
4.2
Gibbs Sampling
93

Now sample a random number from the conditional density f(z| x ¼ 2). This
distribution is represented in Fig. 4.3 as the line x ¼ 2 that has more density of
probability between ‘g’ and ‘h’ (in yellow) than in other parts of this line. Therefore,
the number sampled from f(z| x ¼ 2) will be found between ‘g’ and ‘h’ more
probably than in other parts of the conditional distribution. Suppose that the number
sampled is z ¼ 6. We will carry on the same procedure until we obtain a chain of
samples of the desired length.
Observe that we have the trend of sampling from the highest areas of probability
more often than from the lowest areas. At the beginning, z ¼ 1 and x ¼ 4 were
points of the posterior distribution, but they were not random extractions; thus, we
were not interested on them. However, after many iterations, we will ﬁnd more
samples in the highest areas of probability than in the lowest areas; thus, we will
ﬁnd random samples from the joint posterior distribution f(x, z) that are also random
samples from the respective marginal posterior distributions f(x), f(z). This explains
why the ﬁrst points sampled should be discarded, and the samples are taken at
random only after several cycles of iteration.
Notice that the conditional probability density functions f(x| z ¼ 1), f(x| z ¼ 5), . . .
are different functions. For example, if x and z were the mean and variance of a
Normal distribution, f(x| variance ¼ 1) is not the same p.d.f. as f(x| variance ¼ 5).
We will see a detailed example in Chap. 5.
4.2.3
When It Works
1. Strictly speaking, it cannot be demonstrated that we are ultimately sampling
from a posterior distribution. A Markov chain must be reducible to converge to a
posterior distribution. Although it can be demonstrated that some chains are not
reducible, there is no general procedure for ensuring reducibility.
2. Even in the case in which the chain is reducible, it is not known when the
sampling from the posterior distribution begins. Even when having a reducible
chain and tests ensuring convergence, the distribution may not be stationary.
Sometimes there are large sequences of sampling that give the impression of
stability, and after many iterations, the chain moves to another area.
The above problems are not trivial, and they occupy a part of the research in MCMC
methods. Practically speaking, what people do is to launch several chains with
different starting values and observe their behaviour. No pathologies are expected
for a large set of problems (e.g. when using multivariate distributions), but some
more complicated models (e.g. threshold models with environmental effects in
which no positives are observed in some level of one of the effects) should be
examined with care. By using several chains, we arrive to an iteration from which
the variability among chains may be attributed to sampling error and thus support
the belief that samples are being drawn from the posterior distribution. There are
some tests to check whether this is the situation (Gelman and Rubin 1992). Another
94
4
MCMC

possibility is to use the same seed and different initial values; in this case, both
chains should converge, and we can establish a minimum difference between chains
to accept the convergence (Johnson 1996). When having only one chain, a common
procedure is to compare the ﬁrst part and the last part of a chain (Geweke 1992).
The animal production researcher, who is usually living in a multivariate Normal
world, should not have any problem with MCMC methods. For more complex
models, good books for Bayesian inference with MCMC are Gelman et al. (2013)
and Carlin and Louis (2008).
It should be noted that the special difﬁculties found when using MCMC methods
for complex problems are similar in the classical statistical world. Finding a global
maximum in multivariate likelihood with several ﬁxed and random effects, out of
the multivariate Normal distribution world, is not often an easy task. Complex
models are difﬁcult to handle under either paradigm. However, MCMC techniques
transform multivariate problems in univariate approaches, and we have seen how
inferences are made using probabilities, having an easier interpretation.
4.2.4
Gibbs Sampling Features
To give an accurate description of the Gibbs sampling procedure used to estimate
the marginal posterior distributions, in a scientiﬁc paper, we can offer:
In the ‘Material and Methods’ section:
1. Number of chains: When using several chains that converge, we have the
psychological perception that no convergence problems were found. We have
no limit for the number of chains; in simple problems, like linear models for
treatment comparison, one chain is enough, but with complex problems, it is
convenient to compute at least two chains. For very complex problems, ten or
more chains should be computed. For example, chains in Fig. 4.4a indicate
that in a complex problem, convergence arrived, but Fig. 4.4b questions
convergence when estimating a genetic correlation.
2. Length of the chains: It is customary to provide the length of the chains in order
to have an idea about the complexity of the problem. Very long chains are
performed when convergence problems were found, or when all the samples
are extremely correlated. For common problems like treatment comparisons,
short chains of some thousands samples are long enough.
3. Burn-in: We have seen in Sect. 3.3.2 that the ﬁrst samples are not taken at
random and should be disregarded. We often consider that the samples are yet
random samples from the joint distribution by visual inspection of the chain. In
many problems, this is not difﬁcult, and in simple problems like treatment
comparison, convergence is raised after few iterations (Fig. 4.5). Although
there are some methods to determine the burn-in (e.g. Raftery and Lewis 1992),
they require the chain to have some properties that we do not know whether it
actually has them; thus, visual inspection is a common method to determine the
burn-in.
4.2
Gibbs Sampling
95

4. Sampling lag: We have seen how we started sampling in a part of the distribu-
tion and how it is not probable to jump to the other side of the posterior
distribution for a new sample; thus, samples are often correlated. If the correla-
tion between two successive samples is very high (say, 0.99), we will need
more samples to obtain the same precision as with less correlated samples. For
example, if the samples are independent, the sample mean has a variance that is
the variance of the distribution divided by the number of samples (σ2/n), but
when the samples are correlated, this variance is higher because the covariances
0.24
0.04
–0.16
–0.36
–0.56
–0.76
–0.96
0.24
0.04
–0.16
–0.36
–0.56
–0.76
–0.96
0
0.4
0.8
1.2
1.6
2
2.4
2.4
2.8
3.2
3.6
4
(X 10000)
0
0.4
0.8
1.2
1.6
2
2.4
2.4
2.8
3.2
3.6
4
(X 10000)
a
b
Fig. 4.4 Several Gibbs sampling chains showing convergence (a) or not (b)
0.9
0.6
0.3
–0.3
–0.6
0
0
1
2
3
4
(X 10000)
Fig. 4.5 Several Gibbs sampling chains showing convergence from the ﬁrst iterations
96
4
MCMC

should also be taken into account. Collecting a high enough number of samples
is not a problem; we can achieve the accuracy we desire, but in order to avoid
collecting an extremely large number of highly correlated samples, consecutive
samples are disregarded. For example, if only one of 100 samples is collected,
this substantially decreases the correlation between two collected consecutive
samples. This is called the ‘lag’ between samples. Nevertheless, in common
analysis like treatment comparisons, no sampling lag is needed.
In tables of results:
5. Convergence tests: When having a positive answer from a convergence test, we
should say, ‘No lack of convergence was detected’, because there is no
guaranty about the convergence. Some authors give the results of the tests. In
common analyses, like treatment comparisons, this is not needed, since con-
vergence is obtained after few iterations.
6. Monte Carlo s.e.: This is the error produced by the size of the sample. As we
said before, it is not the same to estimate the posterior distribution with
500 samples than with 5000 or 50,000, and the samples can be correlated.
This error is calculated using groups of samples and examining the sample
means, or using temporal series techniques. Current software for MCMC gives
the MCse. It can become as small as we want just by taking more samples of the
posterior distribution. We should augment the sampling until this error
becomes irrelevant (e.g. when it is 10 times lower than the standard deviation
of the posterior distribution).
7. Actual sample size: It is the equivalent number of independent samples that will
have the same accuracy as the sample we have. For example, we can have
50,000 highly correlated samples that will lead to the same precision as
35 uncorrelated samples. The actual sample size gives us an idea about the
real sample size we have, since having a high number of highly correlated
samples does not provide much information. As we have said before, in many
analyses, samples will not be highly correlated and actual sample size will not
be commonly offered.
8. Point estimates: Median, mean, mode. When distributions are approximately
symmetrical, we should use one of them. Statisticians normally prefer the
median for reasons explained in this book, but the mean and the mode are
also used.
9. Standard deviation of the posterior distribution: When the distribution is
approximately Normal, it is sufﬁcient to know the s.d. for calculating HPDs;
for example, HPD95% will be approximately twice the standard deviation.
10. Credibility intervals: HPD, guaranteed values [k, +1) or (1, k]. We can give
several intervals in the same paper, for example, guaranteed values for 80 and
95% of probability.
11. Probabilities: Probability of relevance, probability of similarity. We have seen
them in Chap. 2.
4.2
Gibbs Sampling
97

When MCMC started in being used in animal production, all of these requirements
(MCse, several chains, convergence tests, criteria for determining the burning off,
correlation between consecutive samples, effective size of the chains, etc.) were
required before admitting papers for publication. Something similar occurred with
maximum likelihood, for which many technical features of the numerical methods
used to ﬁnd the maximum were required. It is not actually necessary to ask for all
these features because they do not affect the quality of the experiment, and it is
only a matter of computing costs to ﬁnd lower MCse, effective sample size, etc. In
the future, it should occur what happened with the numerical methods used for
maximum likelihood, and all the features mentioned will not probably be required,
since it will be supposed that the researcher have them under control.
4.3
Other MCMC Methods
Not always will we have functions providing us random samples of the condi-
tional distributions. If we do not have these functions, we can apply several
methods. Here we can only outline some of the most commonly used. There is a
whole area of research to ﬁnd methods that are more efﬁcient and to improve the
efﬁciency of the existent ones. The readers interested in MCMC methods can
consult Sorensen and Gianola (2002) or Gelman et al. (2013) for a more detailed
account.
4.3.1
Acceptance-Rejection
The acceptance-rejection method consists in covering the probability density func-
tion f(x), from which we want to take random samples, with a known function g(x)
(not a probability density distribution) of which we know how to take random
samples (Fig. 4.6). By sampling many times and building a histogram, we can
obtain a good representation of g(x). We call g(x) ‘proposal function’ because it is
the function we propose for sampling.
Let us extract a random sample from g(x). Consider that, as in Fig. 4.6,
the random sample x0 gives a value for f(x0) that is 1/2 of the value of g(x0). If
we take many random samples of g(x), and build a histogram, half of them will be
random samples of f(x) as well, but which ones? To decide this, we can throw a
coin: ‘face’ is a random sample of f(x), and ‘tail’ is not. If we do this, after
sampling many times and building a histogram, we will have a good representation
of f(x) at x0.
98
4
MCMC

We will proceed in a similar manner for the following sample, x1, examining the
ratio between f(x1) and g(x1). If this ratio is 1/6, as in Fig. 4.6, we can throw a die
and decide that if we get a ‘1’, the sample is a random sample from f(x); otherwise,
it is not. Again, if we do this, when sampling many times and building a histogram,
we will have a good representation of f(x) at x1.
The general procedure is as follows:
1. Take a random sample x0 from g(x).
2. Sample a number k from the uniform distribution U[0, 1].
3. If k < f x0
ð
Þ
g x0
ð
Þ, accept x0 as a random sample of f(x); otherwise, reject it.
For example, we take a random sample of g(x), and we get x0 ¼ 7. We take a random
sample from U[0, 1], and we get k ¼ 0.3. We evaluate the ratio of functions at x0, and
we obtain f 7
ð Þ
g 7
ð Þ ¼ 0:8 > 0:3; thus, we accept that 7 is a random sample of f(x).
How to ﬁnd a good g(x) is not always easy. We need to be sure it covers f(x);
thus, we need to know the maximum of f(x). Some g(x) functions can be very
inefﬁcient, and most samples can be rejected, which obliges to sample many times;
for example, in Fig. 4.7a we have an inefﬁcient function, x0, which is going to be
rejected most of the times. We see in Fig. 4.7b a better adapted function.
There are methods that search for a new g(x) according to the success we had in
the previous sampling; they are called ‘adaptive acceptance rejection samplings’.
As said before, there is a whole area of research in these topics.
g(x)
f(x)
x0
x1
Fig. 4.6 Acceptance-
rejection MCMC method. f(x)
is the probability density
function from which we want
to take random samples. g(x)
is a function (not a probability
density function) from which
we know how to take random
samples, covering f(x). x0 is a
random sample from g(x) that
may also be a random sample
from f(x)
4.3
Other MCMC Methods
99

4.3.2
Metropolis–Hastings
This method has a rigorous proof based in the theory of Markov chains that can be
found, for example, in Sorensen and Gianola (2002). We will only expose here how
it works.
Our proposal function g(x) is now a probability density function4; thus, it should
integrate to 1. We know how to take samples from g(x). The procedure works as
follows:
1. Take an arbitrary number x0 (Fig. 4.8a).
2. Sample x1 from g(x).
3. If f(x1) > f(x0), accept x1 as a sample of f(x); otherwise, use acceptance-rejection
sampling, as in Fig. 4.6. If x1 is rejected, sample again from g(x) and repeat the
process until you get a sample that is accepted.
4. If x1 is accepted, move the mode of g(x) to x1 as in Fig. 4.8b and sample again x2
from g(x). Check whether f(x2) > f(x1) and proceed as before.
Notice that by accepting x1 when f(x1) > f(x0), we tend to sample more often in
the highest probability areas. We ensure we are sampling in the low probability
areas by the acceptance-rejection method. When sampling enough times and
constructing a histogram, it will reﬂect the shape of f(x).
A key issue of the method is to ﬁnd the right proposal density g(x). It should be
as similar as possible to the function f(x) from which we want to extract samples, in
order to accept as many samples as possible when sampling. If we have a proposal
density as in Fig. 4.8a, we can accept many samples on the left part of f(x) but never
g(x)
g(x)
f(x)
f(x)
x0
x0
a
b
Fig. 4.7 (a) An easy but inefﬁcient accepting-rejection function. (b) A better adapted function
4Although we use the notation f(x) for density functions along this book, we will make an
exception for g(x) in order to maintain the nomenclature used before for proposal functions.
100
4
MCMC

move to the right part of f(x), and therefore we will not estimate f(x) but only a part
of it. There is research on how to ﬁnd efﬁcient proposal densities, and there are
adaptive Metropolis methods that try to change the proposal density along the
sampling process to get more efﬁcient g(x) densities.
Appendix: Software for MCMC
There is software that can be used in several mainframes and in Microsoft Windows
PCs allowing to analyse a large number of statistical models.
BUGS permits to make inferences from a large number of models. It is
programmed in R-programming language, and it allows adding R instructions.
It is not charged by the moment, and it is widely used for Bayesian analyses. It
can be downloaded from https://www.mrc-bsu.cam.ac.uk/software/bugs. For
geneticists, it does not have the possibility of including the relationship matrix,
but recently, Damgaard (2007) showed how to use BUGS for animal models. The
same website links to other similar software developed independently (JAGS,
Stan and NIMBLE).
TM is a Fortran90 software for multiple trait estimations of variance components,
breeding values and ﬁxed effects in threshold, linear and censored linear models
in animal breeding. It has been developed by Luis Varona and Andre´s Legarra,
with the intervention of some other people. It is not charged and can be obtained
from http://genoweb.toulouse.inra.fr/~alegarra/tm_folder/.
Ignacy Mizstal has developed a set of programs under the name BLUPF90,
covering a large amount of different problems, orientated to genetics. They can be
downloaded from http://nce.ads.uga.edu/wiki/doku.php.
a
b
g(x)
g(x)
f(x)
f(x)
x0
x1
x1
x2
Fig. 4.8 A proposal density g(x) from which we know how to take samples and the density
function f(x) from which we need to take random samples. (a) Start sampling. (b) Moving the
proposal density
Appendix: Software for MCMC
101

There are other packages available (LaplacesDemon, etc.) with different
peculiarities that may ﬁt better the needs of the reader.
References
Carlin BP, Louis TA (2008) Bayesian methods for data analysis, 3rd edn. Chapman and Hall, Boca
Raton
Damgaard LH (2007) Technical note: how to use Winbugs to draw inferences in animal models. J
Anim Sci 85:1363–1368
Fisher R (1959) Statistical methods and scientiﬁc inference, 2nd edn. Oliver and Boyd, Edinburgh
Gelman A, Carlin JB, Stern HS, Dunson DB, Vehtari A, Rubin DB (2013) Bayesian data analysis,
3rd edn. Chapman and Hall, Boca Raton, FL
Gelman A, Rubin DB (1992) Inference for iterative simulation using multiple sequences. Stat Sci
7:457–472
Geweke J (1992) Evaluating the accuracy of sampling-based approaches to the calculation of
posterior moments. In: Bernardo JM, Berger JO, Dawid AP, Smith AF (eds) Bayesian statistics
4. Oxford University Press, Oxford
Johnson VE (1996) Studying convergence of Markov chain Monte Carlo algorithms using coupled
sample paths. J Am Stat Assoc 91:154–166
Raftery AE, Lewis SM (1992) How many iterations in the Gibbs sampler? In: Bernardo JM,
Berger JO, Dawid AP, Smith AFM (eds) Bayesian statistics, vol 4. Oxford University Press,
Oxford
Sorensen DA, Gianola D (2002) Likelihood, Bayesian and MCMC methods in quantitative
genetics. Springer, New York
Student (1908) On the probable error of a mean. Biometrika 6:1–25
102
4
MCMC

The Baby Model
5
Essentially, all models are wrong, but some are useful.
George Box and Norman Drapper, 1987, p. 424
In this chapter we will obtain marginal posterior distributions of the unknowns
using the simplest possible model, the one in which data are Normally distributed
and we only have to estimate the mean and variance of the Normal distribution. In
Chaps. 6, 7 and 8, we will see models that are more complex. We will ﬁnd ﬁrst
analytical solutions to understand better the meaning of conditional and marginal
distributions, and we will use Gibbs sampling later. We follow the humorous
suggestion of Daniel Gianola and name the simplest model ‘Baby model’.
5.1
The Model
Our model consists of only a mean plus an error term.
yi ¼ μ þ ei
Throughout the book, we will consider that the data are Normally distributed,
although all procedures and conclusions can be applied to other distributions. The
‘Normal’ distribution was called ‘normal’ because it is the most common one in
nature.1 All errors have mean ‘zero’ and are uncorrelated, and all sampled data
comes from the same distribution. Thus, to describe our model, we will say that
1We will say ‘Normal’ throughout the book to distinguish the density distribution from the
common uses of the word ‘normal’. The term ‘normal’ applied to the density distribution was
proposed independently by various statisticians along the nineteenth century.
# Springer International Publishing AG 2017
A. Blasco, Bayesian Data Analysis for Animal Scientists,
DOI 10.1007/978-3-319-54274-4_5
103

yi  N μ; σ2
ð
Þ
y  N 1μ; Iσ2
ð
Þ
where 10 ¼ [1, 1, 1, ... , 1] and I is the identity matrix. The p.d.f. is
f yjμ; σ2


¼
1
2π
ð
Þ
n
2 σ2
ð
Þ
n
2 exp
X
n
1
 yi  μ
ð
Þ2
2σ2
"
#
as we saw in Sect. 3.4.2 of Chap. 3. Now we have to establish our objectives. What
we want is to estimate the unknowns ‘μ’ and ‘σ2’ that deﬁne the distribution.
5.2
Analytical Solutions
5.2.1
Marginal Posterior Density Function of the Mean
and Variance
We will try to ﬁnd the marginal posterior distributions for each unknown because
this distribution takes into account the uncertainty when estimating the other
parameter, as we have seen in Chaps. 2 and 3. Thus, we should ﬁnd the posterior
distribution for μ after having marginalised it for σ2 and the posterior distribution
for σ2 after having marginalised it for μ. Although both are marginal distributions,
they are conditional to the data, as we have seen in Chap. 3.
f μ j y
ð
Þ ¼
Z 1
0
f μ; σ2jy


dσ2
f σ2 j y


¼
Z 1
1
f μ; σ2jy


dμ
We have derived these distributions by calculating the integrals in Chap. 3,
Sect. 3.5.
f μjy
ð
Þ / tn1 y; s2


This is a ‘Student’ t-distribution with parameters y and s2 and n  1 degrees of
freedom, where
y ¼ 1
n
X
n
1
yi;
s2 ¼
1
n  1
X
n
1
yi  y
ð
Þ2
The other marginal density we look for is
104
5
The Baby Model

f σ2jy


/
1
σ2
ð
Þ
n1
2 exp 
P
n
1
yi  y
ð
Þ2
2σ2
2
664
3
775 / IG α; β
ð
Þ
This is an Inverted Gamma distribution with parameters α, β
α ¼ n  1
2
 1;
β ¼ 1
2
X
n
1
yi  y
ð
Þ2
5.2.2
Joint Posterior Density Function of the Mean and Variance
Using ﬂat priors for the mean and variance,
f μ; σ2jy


¼ f yjμ; σ2
ð
Þf μ; σ2
ð
Þ
f y
ð Þ
/ f yjμ; σ2


f μ; σ2


/ f yjμ; σ2


f μ; σ2jy


/
1
2π
ð
Þ
n
2 σ2
ð
Þ
n
2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775
now both parameters are in red because this is a bivariate distribution.
5.2.3
Inferences
We can draw inferences from the joint or from the marginal posterior distributions.
For example, if we ﬁnd the maximum from the joint posterior distribution, this
would be the most probable value for both parameters μ and σ2 simultaneously.
This is not the most probable value for the mean and the variance when all possible
values of the other parameter have been weighted by their probability and summed
up (i.e. the mode of the marginal posterior distributions of μ and σ2). We will now
show some inferences that have related estimators in the frequentist world.
5.2.3.1 Mode of the Joint Posterior Distribution
To ﬁnd the mode, as it is the maximum value of the posterior distribution, we derive
and equal to zero (Appendix 5.1):
5.2
Analytical Solutions
105

mode f μ; σ2jy


!
∂
∂μ f μ; σ2jy
ð
Þ ¼ 0 ! bμ ¼ 1
n
X
yi ¼ y corresponding to bμML
∂
∂σ2 f μ; σ2jy
ð
Þ ¼ 0 ! bσ2 ¼ 1
n
X
yi  y
ð
Þ2 corresponding to bσ2
ML
8
>
>
<
>
>
:
Thus, the mode of the joint posterior distribution looks like the maximum likeli-
hood (ML) estimates of the variance, although here the interpretation is different.
Here they mean that these estimates are the most probable values of the unknowns μ
and σ2 simultaneously, whereas in a frequentist context, this means that these values
would make our current sample y most probable if they were the true values. The
numeric value of the estimate is the same, but the interpretation is different.
Notice that we will not usually make inferences from joint posterior distributions
because when estimating one of the parameters, we do not take into account the
uncertainty of estimating the other parameter, unless we are interested in simulta-
neous inferences for some reason.
5.2.3.2 Mean, Median and Mode of the Marginal Posterior Distribution
of the Mean
As the marginal posterior distribution of the mean is tn1 y; s2
ð
Þ, the mean, median
and mode are the same, and they are equal to the sample mean. For credibility
intervals, we can consult a table of the tn  1 distribution.
5.2.3.3 Mode of the Marginal Posterior Distribution of the Variance
Deriving the marginal posterior distribution and equating to zero, we obtain
(Appendix 5.3)
mode f σ2jy


! ∂
∂σ2 f σ2jy


¼ 0 !
bσ2 ¼
1
n  1
X
yi  y
ð
Þ2 corresponding to bσ2
REML
Thus, the mode of the joint posterior distribution looks like the residual maxi-
mum likelihood (REML) estimates of the variances, although here the interpreta-
tion is different. Here this estimate is the most probable value of the unknown σ2
when the values of the other unknown μ have been considered, weighted by their
probability and summed up (the mean has been integrated out). In a frequentist
context, we mean that this value would make the sample most probable if this was
the true value, working in a subspace in which there is no μ (see Blasco 2001 for a
more detailed interpretation). The numeric value of the estimate is the same, but the
interpretation is different. Here the use of this estimate seems to be more founded
than in the frequentist case, but notice that the frequentist properties are different
from the Bayesian ones.
106
5
The Baby Model

5.2.3.4 Mean of the Marginal Posterior Distribution of the Variance
To calculate the mean of a distribution is not so simple because we need to calculate
an integral. Because of that, modes were more popular before the MCMC era.
However, the mean has a better loss function than the mode, as we have seen in
Chap. 2, and we may prefer this estimate. By deﬁnition of the mean, we have to
calculate the integral:
mean f σ2jy


¼
Z 1
0
f σ2jy


f σ2


dσ2
In this case, we know that f(σ2| y) is an inverted gamma, with parameters α and β,
that we have seen in Sect. 5.2.2. We can calculate the mean of this distribution if we
know its parameters, and the formula can be found in several books (e.g. see
Bernardo and Smith (1994)). Taking the value of α and β from Sect. 5.2.2, we have
Mean INVERTED GAMMA
½
 ¼
β
α  1 ¼
1
2
P
n
1
yi  μ
ð
Þ2
n3
2  1
¼
1
n  5
X
n
1
yi  μ
ð
Þ2
which does not have an equivalent in the frequentist world. This also gives a smaller
estimate than the mode.
Notice that this estimate does not agree with the frequentist estimate of mini-
mum quadratic risk that we saw in Sect. 1.4.4 of Chap. 1. This estimate had the
same expression but dividing by n þ 1 instead of by n  5. The reason is on one
hand that we are not minimising the same risk; in the frequentist case, the variable is
the estimate bσ2, which is a combination of data, whereas in the Bayesian case, the
variable is the parameter σ2, which is not a data combination. Thus, when calculat-
ing the risk, we integrate in one case on this combination of data and in the other
case the parameter.2
Bayesian RISK ¼ Eu bu  u
ð
Þ2 ¼
Z
bu  u
ð
Þ2f u
ð Þdu
Frequentist RISK ¼ Ey bu  u
ð
Þ2 ¼
Z
bu  u
ð
Þ2f y
ð Þdy
The other reason is that these Bayesian estimates have been derived under the
assumption of ﬂat (constant) prior information. These estimates will be different if
2Remember that the parameter has a true unknown value σ2
TRUE and we use σ2 to express our
uncertainty about σ2
TRUE.
5.2
Analytical Solutions
107

other prior information is used. For example, we will see in Chap. 9 that there are
reasons for taking other prior for the variance:
f σ2


/ 1
σ2
In this case, we have
f σ2jy


/ 1
σ2 
1
σ2
ð
Þ
n1
2 exp 
P
n
1
yi  y
ð
Þ2
2σ2
2
664
3
775 /
1
σ2
ð
Þ
n1
2 þ1 exp 
P
n
1
yi  y
ð
Þ2
2σ2
2
664
3
775
then, calculating the mean as before
Mean INVERTED GAMMA
½
 ¼
β
α  1 ¼
1
2
P
n
1
yi  μ
ð
Þ2
n1
2  1
¼
1
n  3
X
n
1
yi  μ
ð
Þ2
which is different from the former estimate. When the sample is high, all estimates
are similar, but if ‘n’ is low, we will get different results. Prior information may be
important in Bayesian analyses if the samples are very small.
5.2.3.5 Median of the Marginal Posterior Distribution of the Variance
We stressed in Chap. 2 the advantages of the median as an estimator that uses a
reasonable loss function and that it is invariant to transformations. The median m is
the value that
Z
m
0
f σ2jy


f σ2


dσ2 ¼ 0:5
thus, we must calculate the integral.
5.2.3.6 Credibility Intervals between Two Values ‘a’ and ‘b’
The probability that the true value lies between ‘a’ and ‘b’ is
P a  σ2  b


¼
Z
b
a
f σ2jy


f σ2


dσ2;
thus, we must calculate the integral.
108
5
The Baby Model

5.3
Working with MCMC
5.3.1
The Process
The process for estimating marginal posterior densities is:
1. To write the joint posterior distribution of all parameters. To do this, we need:
(a)
The distribution of the data
(b)
The joint prior distributions
We have seen how to write the joint posterior distribution for μ and σ2 in the case of
using ﬂat priors.
2. To write the conditional distributions for each individual parameter, given all
other parameters and the data. We just take the joint posterior distribution, leave
in red colour the parameter of interest and paint in black the other parameters,
which now become constants. In our example, we have two conditional
distributions, one for μ and another one for σ2.
3. To ﬁnd functions allowing us to take random samples from the conditional
distributions. We can ﬁnd these functions in books dedicated to distributions.
If we cannot ﬁnd these functions, we should use alternative sampling methods
like Metropolis, as we have seen in Chap. 4.
4. To generate chains using the Gibbs sampling algorithm. In complex problems,
we can run several chains from different starting points and check convergence
using a test or by visual inspection of the chains. We can also calculate the
Monte Carlo standard error (MCse) and check the correlation between consecu-
tive samples, in order to throw samples if the correlation is high. We will also
discard the ﬁrst part of the chains (the ‘burning off’) until we are sure that the
chain has converged to the posterior distribution. In simple problems such as
linear models with ﬁxed effects for mean comparisons, the chains converge
immediately, the MCse are very low, and the correlation between consecutive
samples is near zero; thus, Normally only one chain is used without discarding
any sample.
5. To make inferences from the samples of the marginal posterior distributions. We
have seen how to make these inferences from chains in Chap. 4.
Now we will put two examples with different prior information
5.3.2
Using Flat Priors
We have written the joint posterior distribution for μ and σ2 in Sect. 5.2.2. Now we
will write the conditionals.
5.3
Working with MCMC
109

f μjy; σ2


/ f yjμ; σ2


/
1
σ2
ð
Þ
n
2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775
f σ2jy; μ


/ f yjσ2; μ


/
1
σ2
ð
Þ
n
2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775
Notice that the formulae are the same, but the variable is in red; thus, the
functions are completely different. As we saw in Chap. 3, Sect. 3.4, the ﬁrst is a
Normal distribution and the second an inverted gamma distribution.
f μjy; σ2


 N
y; σ2
n


f σ2jy; μ


 IG α; β
ð
Þ;
β ¼ 1
2
X
n
1
yi  μ
ð
Þ2;
α ¼ n
2  1
In Chap. 4, Sect. 4.2.1, we have seen that we have a function for random
sampling from Normal distributions, and we also have functions for random
sampling from inverted gamma distributions. We start, for example, with an
arbitrary value for the variance σ2
0, and then we get a sample value of the mean.
We substitute this value in the conditional of the mean, and we get a random value
of the variance. We then substitute it in the conditional distribution of the mean, and
we continue the process (Fig. 5.1).
We will put an example. We have a data vector with four data
y0 ¼ 2; 4; 4; 2
½

s0 arbitrary
2
2
f(m|s2 = s0,y)
f(s2|m = m0,y)
Fig. 5.1 Gibbs sampling
process for the mean and the
variance of the ‘Baby model’
110
5
The Baby Model

Then we calculate
y ¼ 3
n ¼ 4
X
n
1
yi  μ
ð
Þ2 ¼
X
n
1
y2
i


 2μ
X
n
1
yi
ð Þ þ 4μ2 ¼ 40  24  μ þ 4μ2
and we can prepare the ﬁrst conditional distributions
f μjσ2; y


 N
y; σ2
n


¼ N 3; σ2
4


f σ2jμ;y


 Igamma
β ¼ 1
2
X
n
1
yi  μ
ð
Þ2
α ¼ n
2  1
8
>
>
<
>
>
:
¼ Igamma
β ¼ 1
2 40  24  μ þ 4μ2


α ¼ 1
8
<
:
Now we start the Gibbs sampling process by taking an arbitrary value for σ2, for
example,
σ2
0 ¼ 1
Then we substitute this arbitrary value in the ﬁrst conditional distribution, and we
have
f μjσ2; y


 N 3; 1
4


We sample from this distribution using an appropriate function, and we ﬁnd
μ0 ¼ 5:2
Then we substitute this sampled value into the second conditional distribution,
f σ2jμ; y


 Igamma 12; 1
½

Now we sample from this distribution using an appropriate function, and we ﬁnd
σ2
1 ¼ 2
Then we substitute this sampled value in the ﬁrst conditional distribution,
f μjσ2; y


 N 3; 2
4


5.3
Working with MCMC
111

Now we sample from this distribution and we ﬁnd
μ1 ¼ 3
Then we substitute this sampled value in the second conditional distribution and
continue the process. Notice that we sample each time from a different conditional
distribution. The ﬁrst conditional distribution of μ was a Normal with mean ¼ 3 and
variance ¼ 1, but the second time we sampled it was a Normal with the same mean
but with variance ¼ 2. The same happened with the different Inverted Gamma
distributions from which we were sampling.
We obtain two chains. Each of the samples belongs to different conditional
distributions, but after a while, they are also samples from the respective marginal
posterior distributions (Fig. 5.2). After rejecting the samples of the ‘burning
period’, we can use the rest of the samples for inferences as we did in Chap. 4
with the MCMC chains.
5.3.3
Using Vague Informative Priors
As we saw in Chap. 2, and we will see again in Chap. 9 with more detail, vague
informative priors should reﬂect the beliefs of the researcher, beliefs that are
supposed to be shared by the scientiﬁc community to a higher or lesser degree.
They need not to be precise, since very precise informative priors would make
unnecessary to perform the experiment in the ﬁrst place. Many density functions
can express our vague beliefs. For example, we may have an a priori expectation of
obtaining a difference of 100 g of live weight between two treatments for poultry
growth. We believe that it is less probable to obtain 50 g than 150 g. We also believe
that it is rather improbable to obtain 25 g, as improbable as to obtain 175 g of
N
3,
1
4
N
3,
2
4
N
3,
5
4
f(s2|m,y) : [2, 5, 3, 3, 2.6, 2.6, 2.8,...]
f(m|s2,y) : [5.2, 3, 4.6, 4.1, 4.8, 4.9,...]
f(s2|y): [2.6, 2.8,...]
f(m|y): [4.8, 4.9,...]
Igamma(12,1)
Igamma(2,1)
Igamma(7,1)
Fig. 5.2 A Gibbs sampling
process. Samples are obtained
from different conditional
distributions, but after a
‘burning’ in which samples
are rejected, the rest of them
are samples of the marginal
posterior distributions
112
5
The Baby Model

difference between both treatments. These beliefs are symmetrical around the most
probable value, 100 g, and can be approximately represented by a Normal distribu-
tion, but also by a t-distribution or a Cauchy distribution, all of them symmetrical.
We will choose the most convenient distribution in order to facilitate the way of
obtaining the conditional distributions we need for the Gibbs sampling. We will see
below that this will be a Normal distribution. The same can be said about the
variance, but here our beliefs are typically asymmetric because we are using square
measurements. For example, we will not believe that the heritability of growth rate
in beef cattle is going to be 0.8 or 0.9; even if our expectations are around 0.5, we
tend to believe that lower values are more probable than higher values. These
beliefs can be represented by many density functions, but again we will choose
the ones that will facilitate our task of obtaining the conditional distributions we
need for Gibbs sampling. These are called conjugate density distributions. In
Chap. 2, Fig. 2.2 shows an example of different prior beliefs represented by inverted
gamma distributions.
5.3.3.1 Vague Informative Priors for the Variance
Let us take independent prior distributions for μ and σ2, a ﬂat prior for the mean and
an inverted gamma distribution to represent our asymmetric beliefs for the vari-
ance. This function can show very different shapes by changing its parameters α
and β, as we have seen in Chap. 2, Fig. 2.2 and in Chap. 3, Fig. 3.3.
f μ; σ2


¼ f μ
ð Þ  f σ2


/ f σ2


¼
1
σ2
ð
Þαþ1 exp  β
σ2


Then the joint posterior distribution is
f μ; σ2jy


/
1
σ2
ð
Þ
n
2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775 
1
σ2
ð
Þαþ1 exp  β
σ2


and the conditional distribution of σ2 given μ and the data y is
f σ2jy; μ
ð
Þ /
1
σ2
ð
Þ
n
2 exp 
P
n
1 yi  μ
ð
Þ2
2σ2
2
64
3
75 
1
σ2
ð
Þαþ1 exp  β
σ2


/
1
σ2
ð
Þ
n
2þαþ1 exp 
P
n
1 yi  μ
ð
Þ2  2β
2σ2
2
64
3
75 ¼
1
σ2
ð
Þaþ1 exp  b
σ2


which is an inverted gamma with parameters ‘a’ and ‘b’
5.3
Working with MCMC
113

a ¼ n
2 þ α
b ¼ 1
2
X
n
1
yi  μ
ð
Þ2  β
5.3.3.2 Vague Informative Priors for the Mean
Now we use an informative prior for the mean and a ﬂat prior for the variance. As
we said before, our beliefs can be represented by a Normal distribution. Thus, we
can determine the mean and variance of our beliefs, ‘m’ and ‘v2’, respectively. Our
prior will be
f μ; σ2


¼ f μ
ð Þ  f σ2


/ f μ
ð Þ /
1
v2
ð
Þ
1
2 exp  μ  m
ð
Þ2
2v2
"
#
The joint distribution is
f μ; σ2jy


/
1
σ2
ð
Þ
n
2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775 
1
v2
ð
Þ
1
2 exp  μ  m
ð
Þ2
2v2
"
#
and the conditional of μ given σ2 and the data y is
f μjσ2; y


/
1
σ2
ð
Þ
n
2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775 
1
v2
ð
Þ
1
2 exp  μ  m
ð
Þ2
2v2
"
#
After some algebra gymnastics (Appendix 5.3), this becomes a Normal distribution
with parameters w and d2
f μjσ2; y


/ exp 1
2  μ  w
ð
Þ2
d2
"
#
/ N w; d2


The values of w and d2 can be found in Appendix 5.3. This is a Normal distribution
with mean w and variance d2, and we know how to sample from a Normal distribu-
tion. Thus, we can start with the Gibbs sampling mechanism as in Sect. 5.3.1.
5.3.4
Common Misinterpretations
We estimate the parameters ‘by Gibbs sampling’: This is incorrect. Gibbs
sampling is not a method of estimation, but a method of numeric calculus to
114
5
The Baby Model

integrate the joint posterior distribution and ﬁnd the marginal ones. We estimate our
parameters using the mode, median or mean of the marginal posterior distribution,
never ‘by Gibbs sampling’.
The parameters of the inverted gamma distribution are degrees of freedom:
The concept of degrees of freedom was developed by Fisher (1922), who
represented the sample in a space of n-dimensions (see Blasco 2001 for an intuitive
representation of degrees of freedom). This has no relation with what we want. We
manipulate the parameters in order to change the shape of the function, and it is
irrelevant whether these ‘hyperparameters’ are natural numbers or fractions. For
example, Blasco et al. (1998) use fractions for these parameters.
One of the parameters of the inverted gamma distribution represents
credibility, and the other represents the variance of the function: Both
parameters modify the shape of the function in both senses, dispersion and sharp-
ness; therefore, it is incorrect to name one of them as the parameter of credibility.
Both parameters should be manipulated in order to obtain a shape that will show our
beliefs, and it is irrelevant which values they have as far as the shape of the function
represents something similar to our state of beliefs. Often standard deviations or
variances coming from other experiments are used as ‘dispersion parameter’ or
‘window parameter’ of the inverted gamma distribution, but this is only correct
when, after drawing the distribution, we agree in that it actually represents our state
of prior uncertainty.
Appendix 5.1
∂
∂μ f μ; σ2jy


¼ ∂
∂μ
1
2π
ð
Þ
n
2 σ2
ð
Þ
n
2exp 
P
n
1 yi  μ
ð
Þ2
2σ2
2
64
3
75 ¼
¼
1
2π
ð
Þ
n
2 σ2
ð
Þ
n
2 
2P
n
1 yi  μ
ð
Þ
2σ2
 exp 
P
n
1 yi  μ
ð
Þ2
2σ2
2
64
3
75 ¼ 0
X
n
1
yi  bμ
ð
Þ ¼ 0 !
X
n
1
yi  nbμ ¼ 0 ! bμ ¼ 1
n
X
n
1
yi
Appendix 5.1
115

∂
∂σ2 f μ; σ2jy


¼ ∂
∂σ2
1
2π
ð
Þ
n
2 σ2
ð
Þ
n
2 exp 
X
n
1
yi  μ
ð
Þ2
2σ2
2
6664
3
7775
¼
1
2π
ð
Þ
n
2 σ2
ð
Þ
n
2 
X
n
1
yi  μ
ð
Þ2
2 σ2
ð
Þ2
 exp 
X
n
1
yi  μ
ð
Þ2
2σ2
2
6664
3
7775
þ
n
2
2π
ð
Þn=2 σ2
ð
Þ
n
2þ1 exp 
X
n
1
yi  μ
ð
Þ2
2σ2
2
6664
3
7775¼ 0
1
2π
ð
Þ
n
2 σ2
ð
Þ
n
2þ2 
X
n
1
yi  μ
ð
Þ2
2
þ
2 n
2

	
σ2
2 2π
ð
Þ
n
2 σ2
ð
Þ
n
2þ2 ¼ 0
X
n
1
yi  bμ
ð
Þ2  n  bσ2 ¼ 0 ! bσ2 ¼ 1
n
X
n
1
yi  bμ
ð
Þ2
Appendix 5.2
∂
∂σ2 f σ2jy


/ ∂
∂σ2
1
σ2
ð
Þ
n1
2 exp 
P
n
1 yi  y
ð
Þ2
2σ2
2
64
3
75
¼
1
σ2
ð
Þ
n1
2 
P
n
1 yi  y
ð
Þ
2 σ2
ð
Þ2
 exp 
P
n
1 yi  y
ð
Þ2
2σ2
2
64
3
75
þ
 n  1
2
σ2
ð
Þ
n1
2 þ1  exp 
P
n
1 yi  y
ð
Þ2
2σ2
2
64
3
75 ¼ 0
1
σ2
ð
Þ
n1
2 þ2 
P
n
1 yi  y
ð
Þ
2
þ
2  n  1
2


σ2
2 σ2
ð
Þ
n1
2 þ2
¼ 0
116
5
The Baby Model

X
n
1
yi  bμ
ð
Þ2  n  1
ð
Þ  bσ2 ¼ 0 ! bσ2 ¼
1
n  1
X
n
1
yi  bμ
ð
Þ2
Appendix 5.3
f μjσ2; y


/ f yjμ; σ2


f μ
ð Þ /
1
σ2
ð
Þ
n
2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775 
1
v2
ð
Þ
1
2 exp  μ  m
ð
Þ2
2v2
"
#
but we saw in Chap. 3, Appendix 2, that
f yjμ; σ2


/
1
σ2
n
 1
2 exp  μ  y
ð
Þ2
2 σ2
n
"
#
then, substituting, we have
f μjσ2; y
ð
Þ / f yjμ; σ2
ð
Þf μ
ð Þ /
1
σ2
n
 1=2 exp  μ  y
ð
Þ2
2 σ2
n
2
664
3
775 
1
v2
ð
Þ1=2 exp  μ  m
ð
Þ2
2v2
"
#
/
1
σ2
n  v2

1
2 exp  μ  y
ð
Þ2
2 σ2
n
 μ  m
ð
Þ2
2v2
2
664
3
775 / exp 
v2 μ  y
ð
Þ2 þ σ2
n μ  m
ð
Þ2
2 σ2
n v2
2
664
3
775
Now, the exponential can be transformed if we take into account that
v2 μ  y
ð
Þ2 þ σ2
n μ  m
ð
Þ2 ¼
v2 þ σ2
n


μ2  2 v2y þ σ2
n m


μ þ v2y2 þ σ2
n m2
/
v2 þ σ2
n


μ2  2 v2y þ σ2
n m


μ ¼
μ2  2
v2y þ σ2
n m


v2 þ σ2
n

 μ
1
v2 þ σ2
n


calling
Appendix 5.3
117

w ¼
v2y þ σ2
n m

	
v2 þ σ2
n


and substituting in the expression, it becomes
μ2  2wμ
1
v2 þ σ2=n


¼ μ2  2wμ þ w2  w2
1
v2 þ σ2=n


/
μ  w
ð
Þ2
1
v2 þ σ2=n


f μjσ2; y


/ exp  μ  w
ð
Þ2
2
σ2=n
ð
Þv2
σ2=n
ð
Þþv2
2
4
3
5
calling
1
d2 ¼
1
σ2=n þ 1
v2 ¼ σ2=n
ð
Þ þ v2
σ2=n
ð
Þ  v2
we have
f μjσ2; y


/ exp  μ  w
ð
Þ2
2  d2
"
#
/ N w; d2


References
Bernardo JM, Smith FM (1994) Bayesian theory. Wiley, Chichester
Blasco A (2001) The Bayesian controversy in animal breeding. J Anim Sci 79:2023–2046
Blasco A, Sorensen D, Bidanel JP (1998) A Bayesian analysis of genetic parameters and selection
response for litter size components in pigs. Genetics 149:301–306
Box GEP, Draper NR (1987) Empirical model-building and response surfaces. Wiley, New York
Fisher R (1922) On the mathematical foundations of theoretical statistics. Phil Trans A
222:309–368
118
5
The Baby Model

The Linear Model: I. The ‘Fixed Effects’
Model
6
If any quantity has been determined by several direct
observations, made under the same circumstances and with
equal care, the arithmetic mean of the observed values gives
the most probable value.
Carl Friedrich Gauss (1809)
In this chapter, we introduce the linear model, the most common model in
animal production, used for treatment comparisons, regressions and analysis of
variance and covariance. We will see what, in a frequentist context, is known
as ‘ﬁxed effects model.’ We discussed in Chap. 1 the differences between
‘ﬁxed’ and ‘random’ effects in a classical context. In a Bayesian context, all
effects are random because in a Bayesian context, uncertainty is described
using probabilities about the true value of the unknowns; thus, there is no
distinction between ﬁxed models, random models or mixed models. Neverthe-
less, we will use the classical nomenclature of ‘ﬁxed’ and ‘random’, and in
Chap. 7 we will see that in a Bayesian context, both are random effects but
with different prior distributions.
6.1
The ‘Fixed Effects’ Model
6.1.1
The Model
We will describe here the Normal linear model; although other distributions of
the data can be considered, the procedure would be the same. Our model consists
of a set of effects and covariates plus a residual. For example, we are comparing
the effect of two treatments, two diets with different protein content, on the
commercial live weight in rabbits, therefore we include a treatment effect ‘T’ in
# Springer International Publishing AG 2017
A. Blasco, Bayesian Data Analysis for Animal Scientists,
DOI 10.1007/978-3-319-54274-4_6
119

the model. We know that in the ﬁrst parities, the does are still growing, and
rabbits of the ﬁrst parities tend to be smaller; thus, we introduce in the model an
effect of parity with two levels, ﬁrst parity and other parities. We also know that
large litters tend to have lower weight than small litters. We could add an effect
of litter, but litters vary from 4 to 20; thus, we would have many effects to
estimate, some of them with few records, which would lead to inaccurate
estimates. To avoid this, we could group litters by size: 4 to 6, 7 to 9, etc.;
however, we know that weight is directly proportional to litter size; thus, we can
add a covariate so that we only have to estimate the regression coefﬁcient instead
of all the levels of litter size.
The model will be
y ¼ μ þ T þ P þ β  LS þ e
where
y: commercial weight of a rabbit
T: treatment ﬁxed effect
P: parity ﬁxed effect
LS: litter size in which the rabbit was born (covariate)
β: regression coefﬁcient of the covariate
e: random residual effect
The model can be more complex. In general, it is recommended to include
all effects that have biological meaning and can affect the results. We can
consider other effects, but this model will work well as an example. In the
following example, we have two rabbits of the same litter (litter size ¼ 7),
having treatment 1 and coming from the second parity of a doe. Then we have
a rabbit from another litter (litter size ¼ 8), under the second treatment, coming
from the ﬁrst parity, and we have a rabbit from another litter (litter size ¼ 6),
under treatment 1 and parity 1. The same procedure applies to the whole
population.
2120 ¼ μ þ T1 þ P2 þ b  7 þ e1
2130 ¼ μ þ T1 þ P2 þ b  7 þ e2
2020 ¼ μ þ T2 þ P2 þ b  8 þ e3
2350 ¼ μ þ T1 þ P1 þ b  6 þ e4
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
In matrix form,
120
6
The Linear Model: I. The ‘Fixed Effects’ Model

2120
2130
2020
2350
  
2
66664
3
77775
¼
1
1
0
0
1
7
1
1
0
0
1
7
1
0
1
0
1
8
1
1
0
1
0
6
  
  
  
  
  
  
2
66664
3
77775

μ
T1
T2
P1
P2
β
2
6666664
3
7777775
þ
e1
e2
e3
e4
  
2
66664
3
77775
y
¼
X
b
þ
e
where
y is a known vector with the data of the commercial weight of each rabbit.
X is a known matrix (called design matrix) containing 1 and 0 to indicate the
presence or absence of each level of all ﬁxed effects and containing the data of
the covariate (litter size).
b is a vector containing the unknown ﬁxed effects and the covariate. It is common
to refer the ﬁxed effects to a general mean μ so that the sum of the levels of each
effect is zero; in our case
T1 þ T2 ¼ 0
and
P1 þ P2 ¼ 0
We have to express our uncertainty about the ﬁxed effects. We can use ﬂat priors
as we did for the mean in Chap. 5, Sect. 5.3.2, or we can use vague informative
priors as we did for the mean in Sect. 5.3.3. If we use ﬂat priors, all unknowns are ‘a
priori’ uncorrelated (they are constant), and their variances are inﬁnite, since they
vary from 1 to +1; they are not proper probability densities, and they are called
improper priors. Nevertheless, they lead to proper posterior distributions, as we will
see later in Chap. 9, but we often consider that these ﬂat priors have limits in order
to represent proper probabilities, which is expressed as
bi e U ai; di
½

where U means uniform distribution and ‘a’ and ‘d’ are the subjective limits we use
to delimitate the priors for each ﬁxed effect, i.e., each treatment, each parity and the
coefﬁcient of regression on litter size. When using MCMC methods, no speciﬁc
priors are usually given; thus, in practice, the largest and lowest MCMC sample
limits the ﬂat priors.1 Since ﬂat priors have very little information, limits are not
usually important, as we will see in Chap. 9.
1Some software takes the mean of the sample plus minus a large interval, for example, ten standard
deviations, as limits of the uniform distributions. This is formally incorrect, since we should not
take our actual sample as prior information, but it is irrelevant in practice, since this will not affect
the results, as we will see in Chap. 9. Flat priors or proper priors with very large intervals are
innocuous for ﬁxed effects, but can lead to improper posterior distributions in more complex
problems (Hobert and Casella 1996). We will discuss improper priors in Chap. 9.
6.1
The ‘Fixed Effects’ Model
121

If we decide to use vague informative priors, we should express our uncertainty
for each level of each ﬁxed effect and for the regression coefﬁcient of the covariate.
A convenient method, as we saw in Chap. 5, is to represent our beliefs using a
Normal distribution. Since we have several effects and levels, this should be a
multivariate Normal distribution, i.e.,
b j m, Ve N m; V
ð
Þ
However, it is difﬁcult to express multivariate beliefs; we should quantify how
much it would affect the weight and the ﬁrst diet with ﬁrst parity for a determined
regression coefﬁcient in comparison with the second diet with second parity for
another value of the regression coefﬁcient, and so on. The human mind has
difﬁculties in imagining how to quantify their beliefs in more than two or three
dimensions. A practical solution is to consider that all levels of all ﬁxed effects are
uncorrelated and express beliefs only level by level. For example, we can think:
•
Prior for μ: We assume, based in other experiments, that the average of
commercial weight would be around 2200 g with maximum probability,
although it could be around 2000 or around 2400 with the same probability
and around 1600 or around 2800 with much lower probability. Our beliefs can be
represented by a Normal distribution with mean 2200 and s.d. 200; thus μ ~ N
(2200, 2002).
•
Prior for T1: We can assume, based in other published experiments, that the
effect of this treatment should be around 40 g with maximum probability, but it
could be around 30 or around 50 with the same probability, around 20 or
around 60 with less probability, etc. We can construct a histogram of beliefs
and ﬁnd a Normal distribution ﬁtting them approximately, for example, T1 ~ N
(40, 102).
•
Prior for T2, P1, P2, β: They are constructed in the same way.
When constructing the priors in this way, V is a diagonal matrix with different
variances for different effects. Sometimes these subjective Normal distributions are
substituted by Normal distributions with large variances in order to obtain proper
priors with little information. In practice, this is similar to using ﬂat priors.
e is a vector of unknown random effects containing the residuals, and they are
also independently normally distributed, i.e.,
e j σ2
e eN 0; Iσ2
e


σ2
e is the variance of the residuals. We need to deﬁne our prior uncertainty about
the residual variance. We can use a ﬂat prior, as we did in Chap. 5 with the Baby
model (Sect. 5.3.2), or we can use informative priors as in Chap. 5, Sect. 5.3.3. If we
use a ﬂat prior,
σ2
e eU 0; ke
½

122
6
The Linear Model: I. The ‘Fixed Effects’ Model

where ‘ke’ is the subjective maximum value this variance can have. This ensures
that the prior distribution is a proper prior distribution.
If we decide to take a vague prior for the variance, it is convenient to use a
conjugated prior, as we saw in Chap. 5, Sect. 5.3.3, an inverted gamma distribution:
σ2
e eIgamma α; β
½

f σ2
e


¼
1
σ2
e

αþ1 exp  β
σ2
e


where α and β are the parameters of the Inverted Gamma distribution that deﬁne the
shape. We will change them until we ﬁnd a distribution ﬁtting our prior opinion.2 In
a Bayesian context, we can also express uncertainty about the parameters of the
Inverted Gamma distribution (called hyperparameters to distinguish them from the
parameters of the model), or about the bounds of the uniform prior distributions (ai,
di, ke). We could assign prior distributions to these hyperparameters, which will
depend on other hyper-hyperparameters, and so on.
We can write the same model using the distribution of the data
y j b, σ2
e eN Xb; Iσ2
e


which means that the data are Normally distributed, the data have means Xb, and
the only component that is variable is the error; thus, the data have a variance-
covariance matrix Iσ2
e. Now we should specify the priors for b and σ2
e as before.
Strictly speaking, we should have written the distribution of the data as
y j X, b, σ2
e, ΗeN Xb; Iσ2
e


where H is the set of hypothesis that we have assumed when writing the model
(e.g. the hypothesis that the sample has been randomly collected, that there are no
other effects affecting the mean or variance of the data, etc.), but the simpliﬁed
notation we have used is common.
Our objective is to ﬁnd the marginal posterior distributions of all unknowns,
from which we can drive inferences using probability; in our example, our objective
is to ﬁnd
f μjy
ð
Þ, f μ þ T1jy
ð
Þ, f μ þ T2jy
ð
Þ, f μ þ P1jy
ð
Þ, f μ þ P2jy
ð
Þ, f σ2
ejy


2When β ¼ 0 and α ¼  1, this distribution becomes a ﬂat prior. Quite often we can see in the
literature authors saying that they use an inverted gamma with hyperparameters β ¼ 0 and α ¼  1.
This is misleading, since we use inverted gammas to introduce subjective prior information; what
they are actually using is a ﬂat prior.
6.1
The ‘Fixed Effects’ Model
123

or the p.d.f. of the marginal posterior distributions of combinations of effects, for
example,
f T1  T2jy
ð
Þ,
f
μ þ T1
μ þ T2
jy


,
f
T1 þ P1
ð
Þ  T2 þ P2
ð
Þjy
ð
Þ
6.1.2
Example
This example is based on the paper published by Martı´nez-A´ lvaro et al. (2016).
They estimate the difference between two divergent lines of rabbits selected for
intramuscular fat, one for increasing intramuscular fat and the other line for
decreasing it. The intramuscular fat is measured in two rabbits per litter (male
and female), and a full sib is selected based on these data. For example, we will
consider a model with line, season, sex and parity order. We will use the following
table, based in their results, to make some inferences:
High-Low
HPD95%
P
r
Pr
Ps
Intramuscular fat %
0.39
0.33, 0.44
1.00
0.05
1.00
0.00
Meat/bone
0.23
0.04, 0.42
0.99
0.16
0.76
0.24
pH
0.01
0.02, 0.05
0.82
0.03
0.15
0.84
SFA% (saturated fatty acids)
0.12
0.87, 0.60
0.61
0.62
0.09
0.90
PUFA% (polyunsaturated
fatty acids)
10.1
11.5, 8.61
1.00
1.24
1.00
0.00
P: P(High-Low > 0) when High > Low, or P(High-Low < 0) when High < Low.
r: relevant value.
Pr: P(High-Low > r) when High > Low, or P(High-Low < r) when High < Low.
Ps: P(|High-Low|) < r
The authors considered a difference between lines to be relevant when it
was higher than one-third of the standard deviation of the trait (see Chap. 1,
Appendix 1.1). They calculated the probability of relevance Pr and the probability
of similitude Ps (see Chap. 2, Sect. 2.2.2). When the high line has lower values than
the low line, the difference is negative. This is why the probability of similitude is
deﬁned as the probability of the difference between lines in absolute value being
lower than the relevant value r, and the probability of relevance is the probability of
the difference between lines being higher than r when positive or lower than r
when negative. Let us go now to the interpretation of the results.
Intramuscular fat: It has a straightforward interpretation; there is a relevant differ-
ence between lines (Pr ¼ 1) estimated with precision (short HPD95%).
Meat/bone ratio: The high line shows a higher meat/bone ratio than the low line
(P ¼ 0.99). However, the difference has been estimated with low precision
124
6
The Linear Model: I. The ‘Fixed Effects’ Model

(large HPD95% ¼ [0.04, 0.42]). There is low evidence about whether this
difference is relevant (Pr ¼ 0.76); therefore, the difference may be relevant
(r > 0.16) or not (r < 0.16).
pH: We have some evidence about the high line having higher pH than the low line
(P ¼ 0.82), but this difference is not relevant (Pr ¼ 0.15), and we can state that
we have evidence that, in practice, there is no difference between lines
(Ps ¼ 0.84). Here the problem is should we admit probabilities of 0.82 or 0.84
as providing enough evidence? This depends on the goals of the research; quite
often, this evidence would be satisfactory. Please do not confuse these
probabilities with the P-values we have seen in Chap. 1 (Sect. 1.2.1); the
evidence provided by P-values of 0.05 is often lower than this value.
SFA%: We do not have enough evidence to state whether the high line has more
saturated fatty acids than the low line or not (P ¼ 0.62), but since the probability
of similitude is reasonably high (Ps ¼ 0.90), we can state they have, in practice,
the same percentage of saturated fatty acids.
PUFA%: Here, just like in the case of intramuscular fat, we can clearly state that the
high line has lower polyunsaturated fatty acid percentage than the low line
(P ¼ 1.00), that this difference is relevant (Pr ¼ 1) and that it has been accurately
measured (short HPD95%).
6.1.3
Common Misinterpretations
When the data is corrected by a ﬁxed effect, this effect disappears: For example,
after correcting it by season, all data can be considered as belonging to the same
season. This is only an approximate statement. Seasons affect each animal in a
different manner; some animals are more sensitive to seasonal effects than others
are. We estimate the winter effect as an average and correct each single data using
this average (e.g. 34 g); thus, we did not correct for the actual effect affecting each
animal but for an approximated average effect.
We should use all available levels of a ﬁxed effect: For example, if we have six
parities, we should use six parity levels; if we have a seasonal effect, it is better to
use a month effect than a trimester effect. The problem is that some levels can have
few data, be inaccurately estimated and affect the results in which we are interested.
We can combine levels in order to augment the amount of data; for example, we can
consider the levels ‘Parity 1, Parity 2, and Parity 3 and more’ or group the data
every six months as a seasonal effect. In this case, the estimate of the level of the
effect will be more accurate, but the individual correction of each animal will be
worse, because as we said, we do not correct for the actual effect affecting each
animal but for an approximated average effect of the level. If our sample is small,
we should carefully examine how we deﬁne the levels of each ﬁxed effect.
We use a covariate when the factor of correction is continuous: This can
either be the case or not. For example, litter size is not continuous, and we have seen
in the model shown before that litter size can be included as a covariate. On the
6.1
The ‘Fixed Effects’ Model
125

other hand, a continuous effect can be divided in several classes and be considered
as a ﬁxed effect. In the example of Sect. 6.1.2, we could have considered live weight
as a covariate, or we could have divided it in classes, for example, less than 2.0 kg,
2.1 to 2.2 kg, 2.2 to 2.3 kg and more than 2.3 kg. We use a covariate when we know
that there is a close linear relationship between the covariate and the trait analysed,
because in this case we should not estimate several levels but only the regression
coefﬁcient.
We remove an effect from the model when it is not signiﬁcant (n.s.): This
should NOT be done, in general. An effect can be relevant but n.s., simply because
there is no enough data to detect signiﬁcance. We have discussed this in Chap. 1,
Sect. 1.2.2. We should evaluate whether the effect is relevant, but this is not enough.
For example, the differences in sex for intramuscular fat can be almost zero, say
0.01%, but the conﬁdence interval can be so large that we are not sure about
whether this effect is so low or not. We can use the probability of relevance that
we saw in Chap. 2, Sect. 2.2.2, to take a decision about the inclusion or not of an
effect.
When an effect that actually exists is not included, the comparisons are
biased: This is not necessarily true. When the design is completely balanced for this
effect, the estimates for the other effects are the same. Taking the example of Sect.
6.3.1, suppose that there are no differences between lines, but females have more
intramuscular fat, and we have measured more females in the high line than in the
low line. If we do not include the sex effect, we will ﬁnd that the high line has more
intramuscular fat, when actually it has not. However, if we have the same number of
males and females in all lines, seasons and parities (or they are in the same
proportion), we will obtain the same estimates, including or not the sex effect.
The accuracy will be lower because we will ﬁnd a higher residual variance due to
the differences between sexes.3
When we include an effect that is not inﬂuencing the data, the model is
wrong: All models are wrong, but as Box and Draper (1987) said, ‘the practical
question is how wrong do they have to be to not be useful’. If there is no effect and
we include it in the model, the correction should be small, and results should not be
practically affected. Moreover, if there is no sex effect for a trait, for example, we
know that the average of males for this trait in our sample is not going to be the
same exactly as the average of females; thus, we correct for a sampling effect when
including sex in the model. Precision depends on the variance of the residuals and
on the number of effects that are estimated. Including too many effects would
reduce the residual variance improving precision, but on the other side, this will
increase the number of estimates, decreasing precision. If sample size is small, it is
better to check out how the model works with or without an effect before making a
decision. We will come back to all these questions in Chap. 10.
3If the differences between sexes are large, we will have a bimodal distribution, mixed of two
Normal, one for each sex, but discussions about these complexities are out of the scope of
this book.
126
6
The Linear Model: I. The ‘Fixed Effects’ Model

6.2
Marginal Posterior Distributions via MCMC Using Flat
Priors
6.2.1
Joint Posterior Distribution
Our objective is to obtain marginal posterior distributions of all unknowns, as we
said in Sect. 6.1.1. To do this, we ﬁrst need the joint posterior distribution of the
unknowns and then the conditional distributions in order to run the Gibbs sampler.
We need to obtain samples of the joint posterior distribution:
f b; σ2
ejy


We do not know the joint posterior distribution of the unknowns, but we know
the distribution of the data. Applying Bayes theorem, we have
f b; σ2
ejy


/ f yjb; σ2
e


 f b; σ2
e


We can assume that the ﬁxed effects and the residual variance are ‘a priori’
independent.
f b; σ2
e


¼ f b
ð Þ  f σ2
e


If we use ﬂat priors for b and σ2
e, the joint posterior distribution becomes
f b; σ2
ejy


/ f yjb; σ2
e


which is similar to the joint posterior density distribution of the mean and the
variance we saw in Chap. 5, Sect. 5.2.2. Since we know that the data are jointly
normally distributed, we can write the joint posterior distribution taking into
account that all the unknowns are variables (in red) and the data are constants
(in black).4 Let us say that we have a total of ‘n’ records.
f b; σ2
ejy


/ f yjb; σ2
e


/
1
σ2
e

n
2 exp  1
2σ2
e
y  Xb
ð
Þ0 y  Xb
ð
Þ


To obtain MCMC samples of this distribution, we need the conditional
distributions of b and σ2
e, as we saw in Chap. 4. If we know how to take random
samples of these conditional distributions, we can apply the Gibbs sampling
procedure described in Chap. 4; otherwise, we would need to apply alternative
MCMC sampling techniques as acceptance-rejection, Metropolis, etc.
4Remember that the unknowns have an unknown true value, and the variables b, σ2
e are used to
represent the uncertainty about the unknowns (see in ‘common misinterpretations’ in Chap. 2,
Sect. 2.4, the common misinterpretation ‘In Bayesian statistics, the true value is a random
variable’).
6.2
Marginal Posterior Distributions via MCMC Using Flat Priors
127

6.2.2
Conditional Distributions
As we did in Chap. 5, Sect. 5.3.2, to obtain the conditionals, we will draw in black what
is ‘given’ and in red the variable. Applying Bayes theorem with ﬂat priors, we have
f bjy; σ2
e


/ f yjb; σ2
e


/
1
σ2
e

n
2 exp  1
2σ2
e
y  Xb
ð
Þ0 y  Xb
ð
Þ


f σ2
ejy; b


/ f yjσ2
e; b


/
1
σ2
e

n
2 exp  1
2σ2
e
y  Xb
ð
Þ0 y  Xb
ð
Þ


Notice that the formulae are the same, but as the variable is in red, the condi-
tional distributions of the ﬁxed effects and the residual variance are completely
different. We can see in Appendix 6.1 that the conditional distribution of the ﬁxed
effects is a multivariate Normal distribution5
f bjy; σ2
e


eN bb; X0X
ð
Þ1σ2
e
h
i
f bjy; σ2
e


/
1
X0X
ð
Þ1σ2
e


1
2 exp 1
2 
b  bb
	

0
X0X
ð
Þ1σ2
e
h
i1
b  bb
	



where bb has the same form as the minimum least square estimator6
bb ¼ X0X
½
1X0y
and the conditional distribution of σ2
e is an Inverted Gamma distribution, as we have
seen in Chap. 3, Sect. 3.5.4,
f σ2
ejy; b


eIGamma α; β
ð
Þ
with parameters
β ¼ 1
2 y  Xb
ð
Þ0 y  Xb
ð
Þ
α ¼ n
2  1
5We assume here that X0X can be inverted, or that the usual appropriate restrictions have been
introduced to permit its inversion, for example, T1 + T2 ¼ 0 and P1 + P2 ¼ 0 in the example of Sect.
6.1.1.
6We do not say that bb is the minimum least square estimator, but that it has ‘the same form’, to
stress out that we are not estimating anything by least squares. It is interesting to notice that the ﬁrst
proof of the least square method given by Gauss was a Bayesian one (Gauss 1809).
128
6
The Linear Model: I. The ‘Fixed Effects’ Model

6.2.3
Gibbs Sampling
To start the Gibbs sampling process, we need the conditional density distributions
and functions for extracting random samples from them. Now we have the condi-
tional distributions; they are known densities (multivariate Normal and Inverted
Gamma), and there are functions to take random samples from them; therefore, we
can start the Gibbs sampling process as we have seen in Chap. 4 and in the
particular case of the baby model in Chap. 5.
We can start with an arbitrary value for the variance, for example, and then we
can get a random sample of b from the conditional distribution f bjy; σ2
e


; we
directly sample all ﬁxed effects. Then we substitute this sample in the conditional
distribution of the variance f σ2
ejy; b


, and we extract a random sample of σ2
e from
this conditional distribution. Then we substitute this sample of σ2
e in the conditional
distribution f bjy; σ2
e


, and we take a new sample of the ﬁxed effects b, and we
continue the process (Fig. 6.1), as we have seen in Chap. 5 for the ‘Baby model’.
We will obtain a matrix of chains, in which each row is a random sample of the
joint distribution:
μ
T1
T2
P1
P2
β
σ2
e
2110
15
10
45
39
0:21
40235
2056
10
2
87
102
0:12
38118
1998
3
51
12
65
0:15
41520
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
Each column is composed of random samples of the marginal posterior distribution
of each element of b, and the last chain is composed of random samples of the
marginal posterior distribution of σ2
e. Once we have obtained the chains, we can
make all sorts of inferences, as we have seen in Chap. 2 and in the example of Sect.
s 2
0
s 2=
,y)
f(b |
f(     |
s 2 b = b0,y)
arbitrary
s 2
0
Fig. 6.1 Gibbs sampling
process for the ‘ﬁxed effects’
model
6.2
Marginal Posterior Distributions via MCMC Using Flat Priors
129

6.1.2. Notice that common restrictions have been applied, and T1 + T2 ¼ 0 and
P1 + P2 ¼ 0.
In practice, instead of sampling from a multivariate distribution, it is often easier
to sample element by element from univariate distributions, i.e., from
f b1jb2; b3; b4; . . . ; y; σ2
e


f b2jb1; b3; b4; . . . ; y; σ2
e


f b3jb1; b2; b4; . . . ; y; σ2
e


. . .
. . .
f σ2
ejb1; b2; b3; . . . ; y


applying Gibbs sampling in the same way.
6.3
Marginal Posterior Distributions via MCMC Using Vague
Informative Priors
6.3.1
Vague Informative Priors
Our beliefs, as we have seen in Sect. 6.1.1, can be represented by a multivariate
Normal distribution.
b j m, VeN m; V
ð
Þ
f bjm; V
ð
Þ /
1
V
j j
1
2 exp 1
2 b  m
ð
Þ0V1 b  m
ð
Þ


Our asymmetric beliefs for the residual variance can be represented by an
inverted gamma distribution, as we have seen in Chap. 5, Sect. 5.3.3. This function
can show very different shapes by changing its parameters α and β.
σ2
e j α, β  IGamma α; β
ð
Þ
f σ2
ejα; β


¼
1
σ2
e

αþ1 exp  β
σ2
e


We can assume independence between the ﬁxed effect and the residual variance.
In this case, the prior distribution would be
f b; σ2
ejm; V; α; β


¼ f bjm; V
ð
Þ  f σ2
ejα; β


/
1
V
j j
1
2
exp 1
2 b  m
ð
Þ0V1 b  m
ð
Þ



1
σ2
e

αþ1 exp  β
σ2
e


130
6
The Linear Model: I. The ‘Fixed Effects’ Model

We can have other combinations of prior distributions, for example, ﬂat priors
for the ﬁxed effects and Inverted Gamma for the residual variance, or any other
distributions describing our beliefs. We should take into account that these
distributions are going to be used for deriving the conditional distributions needed
for MCMC, and the conditional distributions should be, when possible, recogniz-
able distributions, for which we have functions allowing us to take random samples
from them. Thus, it is convenient to use conjugate distributions with the distribution
of the data. In our examples, we have considered data Normally distributed. We
have taken multivariate Normal distribution for the mean and Inverted Gamma
distribution for the variance, because they lead to recognizable conditional
densities, but when the data is not Normally distributed (e.g. they follow a Binomial
or a Poisson distribution), other appropriate prior distributions that conjugate with
the data distribution can be considered to describe our beliefs.
6.3.2
Conditional Distributions
Applying Bayes theorem, as before, we obtain the conditional distribution of the
ﬁxed effects:
f bjσ2
e; y; m; V; α; β


/ f yjb; σ2
e


f bjm; V
ð
Þf σ2
ejα; β


 /
1
σ2
e

n
2
exp  y  Xb
ð
Þ0 y  Xb
ð
Þ
2σ2
e



1
V
j j
1
2
exp 1
2 b  m
ð
Þ0V1 b  m
ð
Þ



1
σ2
e

αþ1 exp  β
σ2
e


/ exp  y  Xb
ð
Þ0 y  Xb
ð
Þ
2σ2
e
 1
2 b  m
ð
Þ0V1 b  m
ð
Þ


We can see in Appendix 6.2 that this is a multivariate Normal distribution.
The conditional distribution of the residual variance is
f σ2
ejy; b; m; V; α; β


/ f yjb; σ2
e


f bjm; V
ð
Þf σ2
ejα; β


 /
1
σ2
e

n
2
exp  y  Xb
ð
Þ0 y  Xb
ð
Þ
2σ2
e



1
V
j j
1
2
exp 1
2 b  m
ð
Þ0V1 b  m
ð
Þ



1
σ2
e

αþ1 exp  β
σ2
e


/
1
σ2
e

n
2þαþ1 exp  y  Xb
ð
Þ0 y  Xb
ð
Þ þ 2β
2σ2
e


which is an Inverted Gamma distribution with parameters ‘a’ and ‘b’:
6.3
Marginal Posterior Distributions via MCMC Using Vague Informative Priors
131

a ¼ n
2 þ α
b ¼ 1
2 y  Xb
ð
Þ0 y  Xb
ð
Þ þ β
as we have seen in Chap. 3, Sect. 3.5.4.
The conditional distributions are known densities (multivariate Normal and
Inverted Gamma); there are functions allowing extracting random samples from
them, and we can start the Gibbs sampling process as in Sect. 6.2.3.
6.4
Least Squares as a Bayesian Estimator
The least square estimator was developed by Legendre under intuitive bases.
Later,7 Gauss found the ﬁrst statistical justiﬁcation of the method, developing
least squares, ﬁrst as a mode of conditional posterior distribution and later under
frequentist bases. In a Bayesian context, we have seen that, under ﬂat priors,
f bjy; σ2
e


eN bb; X0X
ð
Þ1σ2
e
h
i
In a Normal distribution, the mean, mode and median are the same; thus, the
least square estimator can be interpreted as
bb ¼ X0X
ð
Þ1X0y ¼ mode f bjσ2
e; y


¼ median f bjσ2
e; y


¼ mean f bjσ2
e; y


Notice that this is a distribution conditioned inσ2
e, i.e. for a given value ofσ2
e. In a
Bayesian context, to estimate the ﬁxed effects, we would calculate the marginal
posterior distribution for b, as we have done in Sect. 6.2.3. This distribution takes
into account the error of estimating the variance.
f bjy
ð
Þ ¼
Z
f b; σ2
ejy


dσ2
e ¼
Z
f bjσ2
e; y


f σ2
e


dσ2
e
Here we take into account all possible values of σ2
e and multiply it by their
probabilities, integrating afterwards, as we have seen in Chap. 5, Sect. 5.2.1. Notice
as well that, even if we estimate the ﬁxed effects as the mode, mean and median of
the conditional distribution, in a Bayesian context, we can apply all the conﬁdence
intervals for inference that we saw in Chap. 2.
7Gauss insisted in that he found the method before Legendre, but he did not publish it. See Hald
(1998) for a history of the controversy.
132
6
The Linear Model: I. The ‘Fixed Effects’ Model

Appendix 6.1
We should see that the conditional distribution
f bjy; σ2
e


/
1
σ2
e

n
2 exp  y  Xb
ð
Þ0 y  Xb
ð
Þ
2σ2
e


is a multivariate Normal distribution.
First, consider the following product:
b  bb
	

0
X0X b  bb
	

¼ b0X0Xb  2b0X0Xbb þ bb0X0Xbb
where
bb ¼ X0X
ð
Þ1X0y
!
X0Xbb ¼ X0y
Substituting X0Xbb by X
0y, we have
b  bb
	

0
X0X b  bb
	

¼ b0X0Xb  2b0X0y þ bb0y
Now consider the quantity
y  Xb
ð
Þ0 y  Xb
ð
Þ
¼ y0y  2b0X0y þ b0X0Xb
¼ b0X0Xb  2b0X0y þ bb0y  bb0y þ y0y
Substituting,
y  Xb
ð
Þ0 y  Xb
ð
Þ ¼
b  bb
	

0
X0X b  bb
	

 bb0y þ y0y
We can write the conditional distribution of the ﬁxed effects as
f bjy;σ2
ð
Þ /
1
σ2
e

n
2
exp  y  Xb
ð
Þ0 y  Xb
ð
Þ
2σ2
e


/ exp 
b  bb
	

0
X0X b  bb
	

 bb0y þ y0y
2σ2
e
2
64
3
75 / exp 
b  bb
	

0
X0X b  bb
	

2σ2
e
2
64
3
75
exp bb0y þ y0y
2σ2
e
"
#
/ exp 
b  bb
	

0
X0X b  bb
	

2σ2
e
2
64
3
75
/
1
X0X
ð
Þ1σ2
e


1
2
exp 1
2  b  bb
	

0
X0X
ð
Þ1σ2
e
h
i1
b  bb
	



Appendix 6.1
133

where we have multiplied by
X0X
ð
Þ1σ2
e


1
2, taking this term from the proportional
constant. This is a multivariate Normal distribution with mean bb ¼ X0X
ð
Þ1X0y and
covariance matrix V ¼ X0X
ð
Þ1σ2
e.
Appendix 6.2
We should see that the conditional distribution
f bjσ2
e; y; m; V


/ exp  y  Xb
ð
Þ0 y  Xb
ð
Þ
2σ2
e
 1
2 b  m
ð
Þ0V1 b  m
ð
Þ


/
exp 1
2
b  bb
	

0
X0X σ2
e

1 b  bb
	

þ b  m
ð
Þ0V1 b  m
ð
Þ
h
i


is a multivariate Normal distribution.
This conditional distribution can be written as
f bjσ2
e; y; m; V


/ exp 1
2 b  ~b

0Q1 b  ~b




which is the kernel of a multivariate Normal distribution. Multiplying by |Q|1/2,
taken from the proportional constant as in Appendix 6.1, we have the multivariate
Normal distribution.
First, calling
C1 ¼ X0X σ2
e

1
the exponent in the conditional distribution becomes
b  bb
	

0
C1 b  bb
	

þ b  m
ð
Þ0V1 b  m
ð
Þ
Now let us consider
~b ¼ C1 þ V1

1 Cbb þ V1m
	

which is the result of weighing bb and m by the inverse of their variances, a common
method of averaging different estimators. Let us call
Q1 ¼ C 1 þ V1


Now, let us consider
134
6
The Linear Model: I. The ‘Fixed Effects’ Model

b  ~b

0Q1 b  ~b


¼ b0Q1b  2b0Q1~b þ ~b0Q1~b
¼ b0Q1b  2b0Q1~b þ constant
where the word ‘constant’ means all the rest of the formula that is constant and will
be absorbed later by the sign of proportionality ‘/’. Substituting Q we have
b  ~b

0Q1 b  ~b


¼ b0 C1 þ V1


b  2b0 C1 þ V1


 C1 þ V1

1 C1bb þ V1m
	

þ constant
¼ b0 C1 þ V1


b  2b0 C1bb þ V1m
	

þ constant
The exponent in the conditional distribution can be written as
b  bb
	

0
C1 b  bb
	

þ b  m
ð
Þ0V1 b  m
ð
Þ ¼ b0C1b
2b0C1bb þ b0V1b  2b0V1m þ constant ¼
¼ b0 C1 þ V1


b  2b0 C1bb þ V1m
	

þconstant ¼ b  ~b

0Q1 b  ~b


þ constant
Therefore,
f bjσ2
e; y; m; V


/ exp 1
2 b  ~b

0Q1 b  ~b


þ constant


/ exp 1
2 b  ~b

0Q1 b  ~b




 exp constant
½

 / exp 1
2 b  ~b

0Q1 b  ~b




/
1
Q
j j1
2
exp 1
2 b  ~b

0Q1 b  ~b




References
Box GEP, Draper NR (1987) Empirical model-building and response surfaces. Wiley, New York
Gauss CF (1809) Theoria motus corporum coelestium in sectionibus conicis solem ambientium
(trans: Davis CE, 1963). Dover, New York
Hald A (1998) A history of mathematical statistics from 1750 to 1930. Wiley, New York
Hobert JP, Casella G (1996) The effect of improper priors on Gibbs sampling in hierarchical linear
mixed models. J Am Stat Assoc 436:1461–1473
Martı´nez-A´ lvaro M, Herna´ndez P, Blasco A (2016) Divergent selection on intramuscular fat in
rabbits: responses to selection and genetic parameters. J Anim Sci 94:4993–5003
References
135

The Linear Model: II. The ‘Mixed’ Model
7
In a classical context, a ‘mixed model’ consists of a set of ﬁxed effects and
covariates plus one or more random effects, plus a random error term. In Chap. 1,
Sect. 1.5, we have explained the differences between ﬁxed and random effects in a
frequentist context. However, as we said in Chap. 6, in a Bayesian context, all
effects are random; thus, there is no distinction between ﬁxed models, random
models or mixed models. Nevertheless, we keep the nomenclatures ‘ﬁxed’ and
‘random’ for the effects that are considered so in a frequentist model, because it is
widely extended and it facilitates the understanding of the model. Later we will see
which type of Bayesian random effects are what we call ‘ﬁxed’ effects in the
frequentist school. We will also consider here that the data are Normally distributed,
although other distributions of the data can be considered, and the procedure would
be the same. In this chapter, we examine a common mixed model in animal
production, the model with repeated records and the most widely used mixed
model in genetic evaluation. We end the chapter with an introduction to multitrait
models.
7.1
The Mixed Model with Repeated Records
7.1.1
The Model
Consider an experiment in which we are comparing two treatments for milk
production in dairy cattle. We have repeated records, i.e. we have several lactations
for each cow. Records are taken along several seasons and cow parities, and we
would like to correct for the size of the cow. The model will be:
yijkl ¼ μ þ Si þ Pj þ β  Aijk þ cijk þ eijkl
where
# Springer International Publishing AG 2017
A. Blasco, Bayesian Data Analysis for Animal Scientists,
DOI 10.1007/978-3-319-54274-4_7
137

y: one of the records of milk production from one of the cow’s parities
S: season ﬁxed effect
P: parity ﬁxed effect
A: weight of the cow (covariate)
β: regression coefﬁcient of the covariate
c: common effect for all records of the same cow (random)
e: random residual effect
We assume a seasonal effect; some periods of the year may have a different
temperature, food composition or other events affecting milk production. We also
assume that there is a common parity effect for all cows; for example, we assume
that the ﬁrst parity will have a different milk production than the second or the third
parities, and this effect will be the same for all cows. Since we have a substantial
amount of data in each season and we have many data in each parity, we consider
that these effects will be well estimated; therefore, we consider them as ﬁxed
effects. We will assume that we do not have any prior information on these effects,
thus we will use ﬂat priors as we have said in Chap. 2, Sect. 2.1.3, deriving the
discussion about prior information to Chap. 9.
We assume that there will be an effect along the lactations of the same cow,
differing from cow to cow. This effect is due to genetic differences and also to
different permanent environments from cow to cow; some cows produce more milk
than other cows along lactations due to microenvironment affecting each individ-
ual. Considering this effect as random, we also modify the structure of the residuals,
as we will see below.
In this model, we assume, as in the ﬁxed effects model, that residuals are a priori
Normally distributed and independent, and the common effects are also a priori
Normally distributed and independent; thus, the cows we are using in our experi-
ment are genetically unrelated. We now need priors for the variances if we want to
estimate them from our data. We can use conjugate priors as in Chap. 5 (Sect. 5.3.3)
or consider ﬂat priors as for the ﬁxed effects.
Consider the following example. Cow 1 has three records, cow 2 has two
records, cow 3 has one record, etc.
cow1 :
7520 ¼ μ þ S1 þ P1 þ b  534 þ c1 þ e11
cow1 :
6880 ¼ μ þ S2 þ P2 þ b  534 þ c1 þ e12
cow1 :
6920 ¼ μ þ S3 þ P3 þ b  534 þ c1 þ e13
cow2 :
9801 ¼ μ þ S2 þ P1 þ b  650 þ c2 þ e21
cow2 :
8754 ¼ μ þ S3 þ P2 þ b  650 þ c2 þ e22
cow3 :
5950 ¼ μ þ S1 þ P1 þ b  485 þ c3 þ e31
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
138
7
The Linear Model: II. The ‘Mixed’ Model

In matrix form:
7520
6880
6920
9801
8754
5950

2
66666664
3
77777775
¼
1
1
0
0
1
0
0 534
1
0
1
0
0
1
0 534
1
0
0
1
0
0
1 534
1
0
1
0
1
0
0 650
1
0
0
1
0
1
0 650
1
1
0
0
1
0
0 485
       
2
666666664
3
777777775

μ
S1
S2
S3
P1
P2
P3
b
2
6666666664
3
7777777775
þ
1
0
0 
1
0
0 
1
0
0 
0
1
0 
0
1
0 
0
0
1 
   
2
666666664
3
777777775

c1
c2
c3

2
664
3
775þ
e11
e12
e13
e21
e22
e31

2
6666664
3
7777775
y
¼
X
b
þ
W
c
þ
e
where
y is a known vector with the data of each lactation of all the cows.
X is a known matrix (called design matrix) containing 1 and 0 to indicate the
presence or absence of each level of all ﬁxed effects and containing the data of the
covariate (the cow’s weight).
W is a known matrix (also called design matrix) containing 1 and 0 to indicate
presence or absence of each level of the random effect
b is a vector containing the unknown ﬁxed effects and the covariate, having ﬂat
priors. Although improper ﬂat priors can be used without consequences, we con-
sider that these ﬂat priors have limits, in order to represent proper probabilities. We
have seen in Chap. 6 that this is expressed as
bi  U ai; di
½

where U means uniform distribution and ‘a’ and ‘d’ are the subjective limits we use
to delimitate the priors for each ﬁxed effect, i.e. each season, each parity and the
coefﬁcient of regression on cow’s weight. When using MCMC methods, no speciﬁc
priors are usually given, and we let the largest and lowest MCMC sample to limit
the ﬂat priors. As ﬂat priors have very little information, limits are not important, as
we will see in Chap. 9.
c is a vector of unknown random effects containing the common effect of each
cow through lactations that are independently Normally distributed. We can express
this as
c j σ2
c  N 0; Iσ2
c


σ2
c is the variance of each of the random common effects through lactation that
each cow has. It deﬁnes our prior uncertainty about these effects. We can give this
variance as known from prior experiments or estimate this variance from our data;
in this case, we should give our prior information about the variance. We often
assume that we do not have prior information and we use a ﬂat or a conjugated
prior, as in Chap. 5, Sect. 5.3.3.
7.1
The Mixed Model with Repeated Records
139

σ2
c  U 0; kc
½

where U means uniform distribution and ‘kc’ is the subjective maximum value this
variance can have. As before, many times does the researcher not care about this
limit, and it is deﬁned by the MCMC sampling; we will see in Chap. 9 that these
scarcely informative priors are not going to affect our inferences.
e is a vector of unknown random effects containing the residuals, and they are
independently Normally distributed, i.e.
e j σ2
e  N 0; Iσ2
e


σ2
e is the variance of the residuals. As before, and as we did in Chap. 6, we need to
deﬁne the prior information about the error variance. Using a ﬂat prior with bounds
σ2
e  U 0; ke
½

where ‘ke’ is the subjective maximum value this variance can have and we apply the
same considerations as with the common effects variance.
We also consider that the random effects are uncorrelated between them.
We can write the same model using the distribution of the data:
y j b, c, σ2
e  N Xb þ Wc; Iσ2
e


which means that the data are Normally distributed, and when b and c are ‘given’,
i.e. are ﬁxed constants, the data have a mean Xb + Wc and the only variable
component is the error; thus, the data have a variance Iσ2
e. If we do not ‘give’ c,
the distribution of the data is
y j b, σ2
c, σ2
e  N Xb; W0Wσ2
c þ Iσ2
e


In this expression c has not been ﬁxed, it is a random effect with mean zero, and
since it is random, it contributes to the variance of the data.
Notice that the structure of the data variability has changed from the ﬁxed
effects model. There, all data had the same variance and they were uncorrelated,
var y
ð Þ ¼ Iσ2
e, but now we have that the records of the same cows are correlated
because they share a common effect ‘c’.
cow 1
=
0
0
0
s 2 + s 2
c
s 2
c
s 2
c
s 2
c
s 2
c
s 2
c
s 2
c
e
s 2 + s 2
c
e
s 2 + s 2
c
s 2
c
s 2
c
e
s 2 + s 2
c
e
s 2 + s 2
c
e
s 2 + s 2
c
e
...
0
0
0
...
0
0
0
...
0
...
0
...
0
0
0
0
0
0
0
0
0
0
0
...
...
...
...
...
...
...
...
cow 2
cow 3
var (y) = var
...
y11
y12
y13
y21
y22
y31
140
7
The Linear Model: II. The ‘Mixed’ Model

Our objective is to ﬁnd the marginal posterior distributions of all unknowns:
f μjy
ð
Þ, f S1jy
ð
Þ, f S2jy
ð
Þ, . . . , f P1jy
ð
Þ, f P2jy
ð
Þ, . . . , f bjy
ð
Þ, . . . f c1jy
ð
Þ, f c2jy
ð
Þ, . . . ,
f σ2
cjy


, f σ2
ejy


or any combinations of them, for example:
f P1  P2jy
ð
Þ,
f
S1
S2


,
f
σ2
c
σ2
e
jy


, . . .
And we can calculate the median, mean, mode or conﬁdence intervals of these
distributions as we described in Chap. 2. We will see in Sect. 7.1.3 how to estimate
these marginal distributions using MCMC.
7.1.2
Common Misinterpretations
We consider an effect as random when we are not interested in its value. This is
not necessarily so. We can consider any effect as ﬁxed or random. We saw in
Chap. 1, Sect. 1.5.4, that the effects can be taken as ﬁxed or random according to
our criteria. In the model we have exposed, we have few lactations per cow, thus if
we consider it as ﬁxed, we will have substantially high errors that may inﬂuence our
results. However, when considering this effect as random, the correction will not be
so strong; we have seen in Chap. 1 (Sect. 1.5.2 and Appendix 1.3) that there is a
‘shrinkage’ when estimating random effects, depending on the amount of data we
have in each level of the effect; thus, with little data, the correction is small. When
we have enough data, ﬁxed and random effects are similar. Conceptually, in a
Bayesian framework, we only have random effects; we will see later how what we
consider to be ‘ﬁxed’ is interpreted. In a frequentist context, when repeating the
experiment, the random effects change; for example, the effect of the animal
changes because it is considered in the model as a random animal affecting the
trait randomly. When repeating the experiment, in a frequentist context the ﬁxed
effects, like the effect of diet, are supposed to be the same.
Some effects, like season effect, should always be considered as ﬁxed. As we
have seen in last section, if we have little data by season, we should consider it as
random in order to avoid strong corrections that may be wrongly estimated. This
generates the problem that the corrections will not be strong, and in many cases, it
would be better to examine both models, taking ‘season’ as random or as ﬁxed, and
see which results look more logical. We can also merge several levels of the effect
in order to get more individuals, although the correction will be less accurate, as we
have commented in Chap. 6, Sect. 6.1.3. When having several random effects, we
have the problem of determining the covariances or correlations between them,
unless we can assume that they are independent, which is not always the case.
7.1
The Mixed Model with Repeated Records
141

7.1.3
Marginal Posterior Distributions via MCMC
We will now see how to ﬁnd the marginal posterior distributions of the unknowns
for the repeated records model. We need the conditional distributions to prepare the
Gibbs sampling process. To obtain the conditionals, we ﬁrst need to write the joint
posterior distribution.
7.1.3.1 Joint Posterior Distribution
Using Bayes’ theorem, we have
f b; c; σ2
c; σ2
ejy


/ f yjb; c; σ2
c; σ2
e


 f b; c; σ2
c; σ2
e


Some unknowns are independent ‘a priori’, for example, b and c, where c are
random effects, different on each cow, and b are systematic effects affecting all
cows. We also assume ‘a priori’ independence between the variances and between
ﬁxed effects and variances. What we cannot assume is this independence between
the random effects and their variances, because the variances deﬁne the distribution
of these effects. In this case we know by the theory of probability that P(A, B) ¼ P
(A | B)P(B); thus:
f c; σ2
c


¼ f cjσ2
c


 f σ2
c


Then, the prior density can be written as
f b; c; σ2
c; σ2
e


¼ f b
ð Þ  f cjσ2
c


 f σ2
c


 f σ2
e


We take constant priors for ﬁxed effects and variances; thus:
f b; c; σ2
c; σ2
e


/ f cjσ2
c


Thus, the joint posterior distribution can be written as
f b; c; σ2
c; σ2
ejy


/ f yjb; c; σ2
c; σ2
e


 f cjσ2
c


We know the distribution of the data and the distribution of the random effects
(see Sect. 7.1.1):
y j b, c, σ2
e  N Xb þ Wc; Iσ2
e


c j σ2
c  N 0; Iσ2
c


Thus, we can write the posterior joint distribution taking into account that all the
unknowns are variables (in red) and all data are given (in black). Let us say that we
have a total of ‘n’ records from ‘m’ cows.
142
7
The Linear Model: II. The ‘Mixed’ Model

f yjb; c; σ2
e


/
1
σ2
e

n
2 exp  1
2σ2
e
y  Xb  Wc
ð
Þ0 y  Xb  Wc
ð
Þ


f cjσ2
c


/
1
σ2
c

m
2 exp  1
2σ2
c
c0c


Therefore, the p.d.f. of the joint posterior distribution will be
f b; c; σ2
c; σ2
ejy


/
1
σ2
e

n
2
exp  1
2σ2
e
y  Xb  Wc
ð
Þ0 y  Xb  Wc
ð
Þ



1
σ2
c

m
2
exp  1
2σ2
c
c0c


7.1.3.2 Conditional Distributions
As in Chap. 6, to obtain the conditionals, we will draw in black what is ‘given’ and
in red the variables. Remember that the constants can be often removed using the
sign of proportionality / (see Chap. 3, Sect. 3.1).
1. Conditional posterior distribution of the variances
f σ2
ejb; c; σ2
c; y


/
1
σ2
e

n
2
exp  1
2σ2
e
y  Xb  Wc
ð
Þ0 y  Xb  Wc
ð
Þ



1
σ2
c

m
2
exp  1
2σ2
c
c0c


/
1
σ2
e

n
2
exp  1
2σ2
e
y  Xb  Wc
ð
Þ0 y  Xb  Wc
ð
Þ


This is an inverse gamma distribution (see Chap. 3, Sect. 3.5.4, and Chap. 6),
with parameters:
β ¼ 1
2 y  Xb  Wc
ð
Þ0 y  Xb  Wc
ð
Þ
α ¼ n
2  1
f σ2
cjb; c; σ2
e; y


/
1
σ2
e

n
2
exp  1
2σ2
e
y  Xb  Wc
ð
Þ0 y  Xb  Wc
ð
Þ



1
σ2
c

m
2
exp  1
2σ2
c
c0c


/
1
σ2
c

m
2
exp  1
2σ2
c
c0c


This is also an inverse gamma distribution, with parameters:
7.1
The Mixed Model with Repeated Records
143

β ¼ 1
2c0c
α ¼ m
2  1
2. Conditional posterior distribution of the effects
f b; cjσ2
c; σ2
e; y


/
1
σ2
e

n
2
exp  1
2σ2
e
y  Xb  Wc
ð
Þ0 y  Xb  Wc
ð
Þ



1
σ2
c

m
2
exp  1
2σ2
c
c0c


In Appendix 7.1, it is shown that this distribution can be transformed into a
Normal distribution.
7.1.4
Gibbs Sampling
To work with MCMC-Gibbs sampling we need the conditional distributions of the
unknowns.
f b; cjσ2
c; σ2
e; y


! Multivariate Normal
f σ2
cjb; c; σ2
e; y


! Inverted Gamma
f σ2
ejb; c; σ2
c; y


! Inverted Gamma
After having functions for taking random samples from the conditionals, we can
start with the Gibbs sampling procedure (Fig. 7.1) as we did in Sect. 6.2.1 of
Chap. 6.
f(b,c|
|
|
s 2
c s 2
e , y)
f(s2
c b,c, s2
e , y)
f(s 2
e b,c,s 2
c , y)
,
Fig. 7.1 Gibbs sampling
process for the components of
the univariate mixed model
and the variance components
144
7
The Linear Model: II. The ‘Mixed’ Model

7.2
The Genetic Animal Model
7.2.1
The Model
We can add an individual genetic effect to the model of our former example, to
separate the common effect of each cow in two components, one due to the genetic
effect of the cow and the other one to an environmental common effect acting on the
same cow through all its lactations called ‘permanent effect’. We can consider now
that cows are genetically related
yijkl ¼ μ þ Si þ Pj þ β  Aijk þ uijk þ pijk þ eijkl
where
u: the cow’s genetic effect
p: the cow’s environmental permanent effect
Both effects are random for the reasons explained in the former model in Sect.
7.1.1. It seems that we are not going to be able to separate the genetic and the
permanent environmental effects, since in both cases we have one effect for each
cow, and two different cows will have different effects. However, as we will see
later, we estimate the genetic effect on one cow not only using data of the cow but
also data of all the relatives of this cow. This permits to separate the genetic effect
from the effect that is common to all lactations and obtain the environmental
permanent effect p. Since both are random, in both cases we will have the ‘shrink-
age’ effect depending on the amount of data used to estimate them. The structure of
the errors will be also modiﬁed. The permanent environmental effect will have the
same covariance structure as the common effect ‘c’ we used in the model with
repeated records (Sect. 7.1.1), but the genetic effect will have a different covariance
structure, since relatives share some genetic effects.
Let us put an example. As an average, each genetic value is the average of the
parents’ genetic value
uCOW ¼ 1
2 uSIRE þ 1
2 uDAM þ mCOW
where SIRE and DAM are the parents’ of the cow. Since not all the offspring of the
same sire and dam have the same genetic value, we add an individual genetic
component mCOW that is different for each cow and is uncorrelated with the genetic
values of the sire and the dam (we call it the ‘Mendelian’ component). This term
takes into account the genetic differences between sibs of the same sire and dam.
We will assume that sire and dam are not relatives, so that their genetic effects are
independent. Now take two half sibs, i.e. two cows with the same sire but different
dams
7.2
The Genetic Animal Model
145

uCOW1 ¼ 1
2uSIRE þ 1
2uDAM1 þ mCOW1
uCOW2 ¼ 1
2uSIRE þ 1
2uDAM2 þ mCOW2
They have the same sire genetic effect, but given that the dams are different, they
do not share the dam effect and of course they do not share the individual genetic
effect. If we calculate the covariance between both half sibs, since all covariances
between SIRE, DAM1, DAM2 and individual Mendelian effects are null,
cov uCOW1; uCOW2
ð
Þ ¼ cov 1
2uSIRE; 1
2uSIRE


¼ 1
4 var uSIRE
ð
Þ ¼ 1
4 σ2
u
Since we consider that the genetic effects of sires, dams or individuals all have
the same genetic variance, σ2
u.
If the cows are full sibs, they share the effect of the sire and the effect of the dam
uCOW1 ¼ 1
2uSIRE þ 1
2uDAM þ mCOW1
uCOW2 ¼ 1
2uSIRE þ 1
2uDAM þ mCOW2
then, the covariance between them will be
cov uCOW1; uCOW2
ð
Þ ¼ cov 1
2uSIRE þ 1
2uDAM; 1
2uSIRE þ 1
2uDAM


¼
¼ 1
4var uSIRE
ð
Þ þ 1
4var uDAM
ð
Þ ¼ 1
4σ2
u þ 1
4σ2
u ¼ 1
2σ2
u
Since, as we have said before, sires and dams are not correlated (they are not
relatives) and the variance of sires, dams and individuals is the same, σ2
u.
We can calculate all sort of covariances between relatives, and all of them will
have a coefﬁcient (1/2, 1/4, etc.) multiplying σ2
u. In matrix form, the matrix of
covariances between relatives will be
G ¼ Aσ2
u
where A is a matrix containing all coefﬁcients, and it is called ‘relationship matrix’
or ‘numerator relationship matrix’ because the covariance is the numerator of the
coefﬁcient of correlation. As before, we will use ﬂat priors for the variances of the
genetic effects and the permanent environmental effects.
Let us consider the same example as in Sect. 7.1.1, but now dividing the former
common effect ‘c’ in genetic ‘u’ and permenant environmental effects ‘p’.
146
7
The Linear Model: II. The ‘Mixed’ Model

cow1 :
7520 ¼ μ þ S1 þ P1 þ b  534 þ u1 þ p1 þ e11
cow1 :
6880 ¼ μ þ S2 þ P2 þ b  534 þ u1 þ p1 þ e12
cow1 :
6920 ¼ μ þ S3 þ P3 þ b  534 þ u1 þ p1 þ e13
cow2 :
9801 ¼ μ þ S2 þ P1 þ b  650 þ u2 þ p2 þ e21
cow2 :
8754 ¼ μ þ S3 þ P2 þ b  650 þ u2 þ p2 þ e22
cow3 :
5950 ¼ μ þ S1 þ P1 þ b  485 þ u2 þ p2 þ e31
. . .
. . .
. . . . . . . . . . . . . . . . . . . . . . . . . . .
In matrix form:
y ¼ Xb þ Zu þ Wp þ e
where Xb has the same meaning as before, in the example of Sect. 7.1.1
7520
6880
6920
9801
8754
5950

2
66666664
3
77777775
¼ Xbþ
1
0
0

1
0
0

1
0
0

0
1
0

0
1
0

0
0
1

   
2
666666664
3
777777775

u1
u2
u3

2
664
3
775þ
1
0
0

1
0
0

1
0
0

0
1
0

0
1
0

0
0
1

   
2
666666664
3
777777775

p1
p2
p3

2
664
3
775þ
e11
e12
e13
e21
e22
e31

2
6666664
3
7777775
y
¼ Xbþ
Z
u
þ
W
p
þ
e
where
b is a vector containing the ﬁxed effects and covariate, having ﬂat priors.
bi  U ai; di
½

u is a vector of random effects containing the genetic effects of the cows and also
the genetic effects of the bulls and in general of all animals having no records.1 The
effects are correlated. They are normally distributed with a variance-covariance
matrix that depends on the additive genetic variance σ2
u and the relationship matrix
A. This last matrix has the relationship coefﬁcients between genetic effects. It is a
known matrix, calculated according to the parental relationships between
individuals.
1For animals having no records (e.g. bulls), the matrix Z has columns of zeroes. For example, if we
have two cows with records and one bull related to them, the equations are
y1
y2


¼
1
0
0
0
1
0


u1
u2
u3
2
4
3
5 þ
e1
e2


The genetic value of the bull u3 is estimated using the cows’ data through the relationships
between the bull and the cows. (We have ignored in this small example the ﬁxed effects and the
mean, which of course are taken into account in the general case).
7.2
The Genetic Animal Model
147

u j A, σ2
u  N 0; Aσ2
u


σ2
u is the variance of the random genetic effects. It deﬁnes our prior uncertainty
about these effects. We can give this variance if we have prior information about
these effects, but we can estimate this variance from our data; in this case, we
should give our prior information about the variance. We often assume that we do
not have prior information and we use a conjugated or a ﬂat prior.
σ2
u  U 0; ku
½

p is a vector of random effects containing the common environmental effect of
each cow through lactations that are independently normally distributed. We can
express this as
p j σ2
p  N 0; Iσ2
p

	
σ2
p is the variance of each of the random environmental common effects through
lactation that each cow has. As before, it deﬁnes our prior uncertainty about these
effects, and we often assume that we do not have prior information and we use a
conjugated or a ﬂat prior.
σ2
p  U 0; kp


e is a vector of random effects containing the residuals, and they are also
independently normally distributed, i.e.
e j σ2
e  N 0; Iσ2
e


and, as before, we need to deﬁne the prior information about the error variance, and
we decide to use a conjugated prior or a ﬂat prior with bounds
σ2
e  U 0; ke
½

We consider that all random effects are uncorrelated between them.
As in Sect. 7.1.1, we can express the same using the distribution of the data2
y j b, u, p, σ2
e  N Xb þ Zu þ Wp; Iσ2
e


2Notice that this is a simpliﬁed notation. We should have written
y j X, Z, W, A, b, u, p, σ2
p, σ2
u, σ2
e, Η  N Xb þ Zu þ Wp; Iσ2
e


where Η is the set of hypothesis we had when constructing the model (e.g. the hypothesis that there
has not been a preferential treatment to some cows, etc.). We simplify the notation because X, Z,
W, A are always known and because given u and p we do not need A, σ2
u and σ2
p since in this
distribution the genetic and permanent effects are ‘given’, i.e. they are ﬁxed and do not vary.
148
7
The Linear Model: II. The ‘Mixed’ Model

which means that the data are normally distributed, and when b, u and p are ‘given’,
i.e. are ﬁxed constants, the data have a mean Xb + Zu + Wp, and the only
component that is variable is the error; thus, the data have a variance Iσ2
e. If we
do not ‘give’ u and p, the distribution of the data is taking into account that random
effects are uncorrelated between them
y j A, b, σ2
u, σ2
p, σ2
e  N Xb; Z0AZσ2
u þ W0Wσ2
p þ Iσ2
e

	
In this example, the matrices Z and W look identical, but they are not, because
the matrix Z contains the genetic effects of the bulls, which do not have data. For
example, if u4 , u5 are bulls, we can add columns with zeroes in the matrix Z so that
no data of lactation will be associated to them in the equation (see footnote 1).
Later, these genetic effects of the bulls will be estimated through the relationships
with their relatives. Now, the matrix form will be
7520
6880
6920
9801
8754
5950

2
66666664
3
77777775
¼Xbþ
1
0
0
0
0 
1
0
0
0
0 
1
0
0
0
0 
0
1
0
0
0 
0
1
0
0
0 
0
0
1
0
0 
     
2
666666664
3
777777775

u1
u2
u3
u4
u5

2
666664
3
777775
þ
1
0
0 
1
0
0 
1
0
0 
0
1
0 
0
1
0 
0
0
1 
   
2
666666664
3
777777775

p1
p2
p3

2
664
3
775þ
e11
e12
e13
e21
e22
e31

2
6666664
3
7777775
Our objective is to ﬁnd the marginal posterior distributions of all unknowns:
f μjy
ð
Þ, f S1jy
ð
Þ, f S2jy
ð
Þ, . . . , f P1jy
ð
Þ, f P2jy
ð
Þ, . . . , f u1jy
ð
Þ, f u2jy
ð
Þ, . . . , f σ2
ujy


,
f σ2
pjy

	
, f σ2
ejy


or combinations of them, for example, the heritability, deﬁned as
h2 ¼
σ2
u
σ2
u þ σ2
p
or the response to selection deﬁned as the distribution of the average of the genetic
values at a determined time; for example, if we have a selection experiment with
discrete generations, we can take all the cows of the last generation; otherwise, we
can take the contemporary cows at a determined time, for example, at year 2016.
Let us say that these cows’ genetic values are u80 , u81 , . . . , u99. We can deﬁne the
response to selection as the average of these genetic values:
R ¼ u80 þ u83 þ    þ u99
20
7.2
The Genetic Animal Model
149

Then we can estimate the marginal posterior distributions of these combinations
of unknowns:
f h2jy


;
f Rjy
ð
Þ
Notice that once we have the marginal posterior distributions, we can apply all
the inferences using different conﬁdence intervals that were described in Chap. 2.
For example, we can estimate the minimum guaranteed value of the heritability,
i.e. the k value of the interval [k, 1] with a determined probability, say 80% or 95%;
or the probability that the heritability is higher than a relevant value, say 0.10, or
other value.
Example
Martı´nez-Alvaro et al. (2016) estimated the heritability of intramuscular fat in
rabbit using a mixed model with a genetic random effect and an environmental
common litter effect. They estimated the heritability of intramuscular fat and
offered the following results:
h2
HPD95%
k80%
k95%
Intramuscular fat
0.54
[0.37, 0.71]
0.47
0.40
k: interval [k,1] containing 80% or 95% probability
Although the precision of the estimate was relatively low, with a HPD95% from
0.37 to 0.71, they could provide guaranteed values of 0.47 and 0.40 with
probabilities 80% and 95%, respectively. This means that the authors can guarantee
that the heritability is at least 0.40 with 95% probability, but if less precision can be
allowed, it is guaranteed that the heritability will be at least 0.47 with 80%
probability.
Now we are going to estimate the marginal posterior distributions of all
unknowns by MCMC methods.
7.2.2
Marginal Posterior Distributions via MCMC
As before, in Sect. 7.1.3, we need to write the joint posterior distribution, then
calculate the conditional distributions and then start the Gibbs sampling process.
7.2.2.1 Joint Posterior Distribution
Applying the Bayes’ theorem, we have
f b; u; p; σ2
u; σ2
p; σ2
ejy

	
/ f yjb; u; p; σ2
u; σ2
p; σ2
e

	
 f b; u; p; σ2
u; σ2
p; σ2
e

	
Some unknowns are independent ‘a priori’, for example, u and p, because they
are the genetic and environmental part of a common effect between lactations. We
150
7
The Linear Model: II. The ‘Mixed’ Model

assume independence between b and u.3 We also assume ‘a priori’ independence
between the variances.4 What we cannot assume this independence between the
random effects and their variances, because the variances deﬁne the distribution of
these effects. In this case we know by the theory of probability that P(A, B) ¼ P
(A | B)P(B); thus:
f u; σ2
u


¼ f ujσ2
u


 f σ2
u


f p; σ2
p

	
¼ f pjσ2
p

	
 f σ2
p

	
Then, the prior density can be written as
f b; u; p; σ2
u; σ2
p; σ2
e

	
¼ f b
ð Þ  f ujσ2
u


 f σ2
u


 f pjσ2
p

	
 f σ2
p

	
 f σ2
e


We take constant priors for ﬁxed effects and variances; thus:
f b; u; p; σ2
u; σ2
p; σ2
e

	
/ f ujσ2
u


 f pjσ2
p

	
Thus, the joint posterior distribution can be written as
f b; u; p; σ2
u; σ2
p; σ2
ejy

	
/ f yjb; u; p; σ2
u; σ2
p; σ2
e

	
 f ujσ2
u


 f pjσ2
p

	
We know the distribution of the data and the distribution of the random effects:
y j b, u, p, σ2
e  N Xb þ Zu þ Wp; Iσ2
e


u j A, σ2
u  N 0; Aσ2
u


p j σ2
p  N 0; Iσ2
p

	
Thus, we can write the posterior joint distribution taking into account that all the
unknowns are variables (in red) and the data are given (in black). Let us say that we
have a total of ‘n’ records from ‘m’ cows. We are also evaluating bulls, and we have
3This may not be the case. For example, if we are evaluating several farms, we will include a ‘herd
ﬁxed effect’ in b. It may happen that the better farms have a better environment and at the same
time buy better semen and embryos (they are more expensive); in this case there will be a
correlation between environmental and genetic effects.
4It is less clear the independence between the genetic and environmental variances. Usually the
literature in genetics offers heritabilities, which is a ratio between the genetic variance and the sum
of the genetic and environmental variances; thus, it is not easy to have a subjective opinion on the
genetic variance independent of our opinion about the environmental variance. However it is even
more complicated to assess our opinion about the covariances, thus Bayesian geneticists prefer,
with some exception (Blasco et al. 1998) to consider prior independence, hoping that the data will
dominate the result and this assumption will not have any consequence.
7.2
The Genetic Animal Model
151

young cows with no data; thus, let us say we have a total of ‘q’ animals to be
evaluated:
f yjb; u; p; σ2
e


/
1
σ2
e

n
2 exp  1
2σ2
e
y  Xb  Zu  Wp
ð
Þ0 y  Xb  Zu  Wp
ð
Þ


f ujA; σ2
u


/
1
σ2
u

q
2 exp  1
2σ2
u
u0A1u


f pjσ2
p

	
/
1
σ2
p

	m
2 exp  1
2σ2
p
p0p
"
#
Therefore, the joint posterior distribution will be
f b; u; p; σ2
u; σ2
p; σ2
ejy

	
/
1
σ2
e

n
2
exp  1
2σ2
e
y  Xb  Zu  Wp
ð
Þ0 y  Xb  Zu  Wp
ð
Þ



1
σ2
u

q
2
exp  1
2σ2
u
u0A1u



1
σ2
p

	m
2
exp  1
2σ2
p
p0p
"
#
To obtain the conditionals, we will draw in black what is ‘given’ and in red the
variable. Remember that the constants can be often removed using the sign of
proportionality / (see Chap. 3, Sect. 3.1).
7.2.2.2 Conditional Distributions of the Variances
1. Residual variance5
f σ2
ejb; u; p; σ2
u; σ2
p; y

	
/
1
σ2
e

n
2
exp  1
2σ2
e
y  Xb  Zu  Wp
ð
Þ0 y  Xb  Zu  Wp
ð
Þ



1
σ2
u

q
2
exp  1
2σ2
u
u0A1u



1
σ2
p

	m
2
exp  1
2σ2
p
p0p
"
#
/
1
σ2
e

n
2
exp  1
2σ2
e
y  Xb  Zu  Wp
ð
Þ0 y  Xb  Zu  Wp
ð
Þ


This is an inverse gamma, with parameters:
5Remember that in our simpliﬁed notation, we assume X, Z, W and A are always ‘given’.
152
7
The Linear Model: II. The ‘Mixed’ Model

β ¼ 1
2 y  Xb  Zu  Wp
ð
Þ0 y  Xb  Zu  Wp
ð
Þ
α ¼ n
2  1
2. Genetic variance
f σ2
ujb; u; p; σ2
p; σ2
e; y

	
/
1
σ2
e

n
2
exp  1
2σ2
e
y  Xb  Zu  Wp
ð
Þ0 y  Xb  Zu  Wp
ð
Þ



1
σ2
u

q
2
exp  1
2σ2
u
u0A1u



1
σ2
p

	m
2
exp  1
2σ2
p
p0p
"
#
/
1
σ2
u

q
2
exp  1
2σ2
u
u0A1u


This is also an inverse gamma distribution, with parameters:
β ¼ 1
2u0A1u
α ¼ q
2  1
3. Permanent environmental variance
f σ2
pjb; u; p; σ2
u; σ2
e; y

	
/
1
σ2
e

n
2
exp  1
2σ2
e
y  Xb  Zu  Wp
ð
Þ0 y  Xb  Zu  Wp
ð
Þ



1
σ2
u

q
2
exp  1
2σ2
u
u0A1u



1
σ2
p

	m
2
exp  1
2σ2
p
p0p
"
#
/
1
σ2
p

	m
2
exp  1
2σ2
p
p0p
"
#
This is also an inverse gamma distribution, with parameters:
β ¼ 1
2p0p
α ¼ m
2  1
7.2
The Genetic Animal Model
153

7.2.2.3 Conditional Distributions of the Effects
f b; u; pj; σ2
u; σ2
p; σ2
e; y

	
¼
1
σ2
e

n
2
exp  1
2σ2
e
y  Xb  Zu  Wp
ð
Þ0 y  Xb  Zu  Wp
ð
Þ




1
σ2
u

q
2
exp  1
2σ2
u
u0A1u



1
σ2
p

	m
2
exp  1
2σ2
p
p0p
"
#
This is a multivariate Normal distribution, as in the case of the former model in
Sect. 7.1.3. The way of transforming this expression in a multinormal distribution is
analogous as the procedure exposed in Appendix 7.1 (see Sorensen and Gianola
2002, for details).
7.3
Bayesian Interpretation of BLUP and REML
7.3.1
BLUP in a Frequentist Context
BLUP are the initials of ‘best linear unbiased predictor’, a name that is somewhat
misleading because BLUP is only the best (minimum risk) within the class of the
unbiased ones (see Chap. 1, Sect. 1.5.4). Moreover, BLUP is not unbiased, in the
sense in which this word is used for ﬁxed effects, as we saw in Chap. 1, Sect. 1.5.3.
BLUP is just a linear predictor with some good properties. For a genetic mixed
model:
y ¼ Xb þ Zu þ e
Henderson (1976) discovered that BLUP and the corresponding estimates for the
ﬁxed effects (BLUE, best linear unbiased estimators) could be obtained by solving
the equations:
X0X
X0Z
Z0X
Z0Z þ A1σ2
e
σ2
u
2
4
3
5 bb
bu


¼
X0y
Z0y


These are called the mixed model equations, and they are particularly popular
among animal breeders. They usually have a large number of animals to be
evaluated, and these equations provide an easy method of predicting the breeding
values bu at a low computational cost.
In a frequentist context, there is a distinction between estimation and prediction.
As we have seen in Chap. 1, Sect. 1.5.1, if an effect is ﬁxed, we expect it will take
the same value after repeating the experiment, but when it is random, we will obtain
154
7
The Linear Model: II. The ‘Mixed’ Model

a different value. This is the reason for using the names BLUE and BLUP for b and u,
respectively.
Henderson (1973) explained he derived BLUP and the mixed model equations as
a result of a mistake. He was learning with Jay Lush how to predict genetic values
and was also learning with Alexander Mood6 how to estimate ﬁxed effects. He
thought he was using the maximum likelihood method for the mixed model, which
was not actually true. He presented the method in a local dairy cattle meeting, but
when he realized he was wrong, he did not publish the method (only a summary
appeared in the Journal of Animal Science in 1949). Later, with the help of Shayle
Searle,7 he discovered that the method had good statistical properties, and it became
the most popular method between animal breeders when Henderson (1976) discov-
ered how to calculate A1 directly and at a low computational cost. Even nowadays,
most animal breeding programs are based in BLUP or in modiﬁed versions of
BLUP to include genomic information.
When working with maximum likelihood, we should maximize
f yju
ð
Þ
This cannot be done with random effects because if we ﬁx the value of u, it is not
random any more. Henderson ignored this and treated u as a random effect.
Henderson maximized
f y; u
ð
Þ ¼ f yju
ð
Þ  f u
ð Þ
There is some intuitive logic in this. As we have said, we try to ﬁnd the value of u
that, if true, will lead to a maximum probability of our sample y; thus, it is natural to
multiply by the probability of this value being true. Henderson maximized
φ ¼ f yju
ð
Þ  f u
ð Þ
/ exp 1
2 y  Xb  Zu
ð
Þ0 Iσ2
e

1 y  Xb  Zu
ð
Þ


exp 1
2u0 Aσ2
u

1u


to facilitate this, we will take logarithms, because the maximum of a quantity is at
the same point as the maximum of its logarithm.
log φ ¼
1
2 y  Xb  Zu
ð
Þ0 Iσ2
e

1 y  Xb  Zu
ð
Þ
1
2u0 Aσ2
u

1u þ constant
6Mood is the author of a well-known textbook of statistics, Mood (1950), Mood and Graybill (1963).
7Again, the author of a well-known textbook about linear models (Searle 1971).
7.3
Bayesian Interpretation of BLUP and REML
155

∂
∂b ln φ ¼ σ2
e

1X0 y  Xb  Zu
ð
Þ
∂
∂u ln φ ¼ σ2
e

1Z0 y  Xb  Zu
ð
Þ  Aσ2
u

1u
equating to zero to ﬁnd the maxima, we obtain
X0Xbb þ X0Zbu ¼ X0y
Z0Xbb þ Z0Zbu þ σ2
e Aσ2
u

1bu ¼ Z0y
that in matrix form leads to the mixed model equations:
X0X
X0Z
Z0X
Z0Z þ A1σ2
e
σ2
u
2
4
3
5 bb
bu


¼
X0y
Z0y


This procedure is confusing, since it is not maximum likelihood, and we are
estimating b without applying the same logic to b as to u. Also notice that to solve
the mixed model equations, we need the true value of σ2
u and σ2
e, but we do not know
them; thus, we will never get real BLUP, since the true values of the variance
components will be substituted by our estimations. We only have the hope that, if
we have good estimations of the variance components, we should be close to the
real BLUP. Moreover, in a frequentist context, we do not have any method to
include the error of estimation of the variance components; thus, we will underesti-
mate the standard errors of both ﬁxed and random effects.
7.3.2
BLUP in a Bayesian Context
In a Bayesian context, there are no differences between ﬁxed and random effects;
thus, we do not need mixed models, and we can work with the same model as in
Sect. 6.1.1 of Chap. 6. We assume independence between b and u. We will use vague
informative priors for b as in Chap. 6, Sect. 6.1.1. The model can be written as
y ¼ Xb þ Zu þ e ¼ Wt þ e
where
W ¼ XZ
½
; t0 ¼ b0u0
½

b j mb, S  N mb; S
ð
Þ
u j σ2
u  N 0; Aσ2
u


156
7
The Linear Model: II. The ‘Mixed’ Model

t j m, S, σ2
u  N
mb
0


;
S
0
0
Aσ2
u




e  N 0; Iσ2
e


We call:
m ¼
mb
0


and
V ¼
S
0
0
Aσ2
u


Thus:
y j t, σ2
e  N Wt; Iσ2
e


Now we will ﬁnd the mode of the posterior distribution of t given the data, but
also conditioned to the variance components. Applying Bayes’ theorem, we have
f tjy; V; σ2
e


/ f yjt; V; σ2
e


 f tjV
ð
Þ / exp 1
2 y  Wt
ð
Þ0 Iσ2
e

1 y  Wt
ð
Þ


exp 1
2 t  m
ð
Þ0V1 t  m
ð
Þ


ln f tjy; m; V; σ2
e


¼  1
2σ2
e
y  Wt
ð
Þ0 y  Wt
ð
Þ  1
2 t  m
ð
Þ0V1 t  m
ð
Þ þ constant
∂
∂t ln f tjy; V; σ2
e


¼  1
σ2
e
W0 y  Wt
ð
Þ þ V1 t  m
ð
Þ
equating to zero to ﬁnd the maximum, this leads to
W0Wbt þ σ2
eV1bt ¼ W0y  σ2
eV1m
X Z
½
0 X
Z

 bb
bu
 
þσ2
e
S
0
0 Aσ2
u

1 bb
bu
 
¼
X Z
½
0yσ2
e
S
0
0 Aσ2
u

1 mb
0


X0X þ σ2
eS1
X0Z
Z0X
Z0Z þ σ2
e
σ2
u
A1
2
4
3
5 bb
bu


¼
X0y  σ2
eS1mb
Z0y


These equations are very similar to the mixed model equations. In fact, if S1
¼ 0, they are identical to the mixed model equations. This condition only holds up
if the prior variance of b is inﬁnite; i.e. if we use unbounded ﬂat priors for b.
Therefore, in a Bayesian context, the difference between what in a frequentist
context are called ﬁxed or random effects is only the type of prior they have. A
7.3
Bayesian Interpretation of BLUP and REML
157

‘ﬁxed’ effect in a frequentist context is just a random effect with an unbounded ﬂat
prior in a Bayesian context.
In a Bayesian context, BLUP is the mode of the joint posterior distribution of b
and u, conditioned not only to the data but also to the values of the variance
components, using an unbounded ﬂat prior for b. Notice that in a Bayesian context,
BLUP is not biased or unbiased, since there are no repetitions of the experiment.
We can be interested, even in a Bayesian context, in what will happen in theoretical
new repetitions of the experiment, but our inferences are based only in our sample
and the priors, not in the information of the sampling space.
7.3.3
REML as a Bayesian Estimator
We have seen in Chap. 5, Sect. 5.2.3, that the mode of the marginal posterior
distribution of the variance gives an expression that is the same as the one we obtain
in a frequentist context for the REML estimate. The same happens in the linear
model; the REML estimators of σ2
u and σ2
e are coincident with the mode of the joint
marginal posterior density:
f σ2
u; σ2
ejy


Prior values are assumed to be ﬂat for b and Normal for u, as in the case of BLUP,
and the density can be obtained analytically or by Gibbs sampling as before. Notice
that this is not the best Bayesian solution; we will usually prefer the mean or the
median of each marginal distribution for each variance component:
f σ2
ujy


f σ2
ejy


instead of the mode of the joint distribution of both variance components.
7.4
The Multitrait Model
7.4.1
The Model
When several correlated traits are analysed together, we use a multitrait model. In
its simplest form, we have two traits measured in the same individual, for example,
growth rate and food conversion ratio. We have treatments, for example, different
diets to be compared, and we have noise effects like season for both traits. The
model is
158
7
The Linear Model: II. The ‘Mixed’ Model

y1 ¼ Xb1 þ e1
y2 ¼ Xb2 þ e2
where b1 and b2 are Treaments and environmental effects (season, herd, etc.) and e1
and e2 are the residuals. We assume:
b1
b2


 Uniform bounded
Residuals are correlated. Take individuals A, B, C for traits 1 and 2. Co-variances
between residuals are
cov eA
1; eA
2; eB
1; eB
2; eC
1 ; eC
2 ; . . . jσ2
e1; σ2
e2; σe1e2

	
¼
σ2
e1
σe1e2
0
0
0
0
  
  
σe1e2
σ2
e2
0
0
0
0
  
  
0
0
σ2
e1
σe1e2
0
0
  
  
0
0
σe1e2
σ2
e2
0
0
  
  
0
0
0
0
σ2
e1
σe1e2
  
  
0
0
0
0
σe1e2
σ2
e2
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
2
66666666664
3
77777777775
This can be expressed using what in matrix algebra is known as the Kronecker
product:
cov eA
1; eA
2; eB
1; eB
2; eC
1 ; eC
2 ; . . . jσ2
e1; σ2
e2; σe1e2

	
¼ I  R
where I is the identity matrix and
R ¼
σ2
e1
σe1e2
σe1e2
σ2
e2


Therefore:
e1
e2


SORTED BY INDIVIDUAL
j R  N 0; I  R
ð
Þ
Now we need priors for the variances and covariances. We will take ﬂat priors:
R ¼
σ2
e1
σe1e2
σe1e2
σ2
e2


 Uniform bounded
When vague priors are used, a multinormal distribution is often used for the
priors of b1 and b2, and inverse Wishart distributions (the equivalent to the inverse
Gamma for the multivariate case) are used for R.
7.4
The Multitrait Model
159

Sometimes the models for each trait may be different. For example, when
analysing litter size and growth rate, a dam may have several litters and conse-
quently several records for litter size, but only one data for growth rate. Moreover,
many animals will have one data for growth rate but no data for litter size, because
they were males or they were not selected to be reproductive stock. We will put an
example in which one trait has several records and the other trait only one record:
for example, in dairy cattle we have several records for milk production but only
one record for type traits. This means that we can add an environmental effect that
is common for all lactation records, but we do not have this effect in the type traits
because we only have one record per animal. The multitrait model is now
y1 ¼ X1b1 þ e1
y2 ¼ X2b2 þ Wc þ e2
This model has the great problem that the design matrixes X1 and X2 are different,
and we have an effect in trait 2 that is not in trait 1. If we had a permanent effect in
trait 1, and if the design matrixes would be the same, we could write the model with
both traits as
y ¼ Xb þ Wc þ e
where y, b and c are the data and the effects of both traits.
In the next section, we will see how we can write the multitrait model as if all
design matrices were the same and all traits would have the same effects. This
technique is known as ‘data augmentation’.
7.4.2
Data Augmentation
Data augmentation is a procedure to augment the database ﬁlling the gaps until all
traits have the same design matrixes. Thus, if some traits have several season effects
and one of the traits has only one season effect, new data with several season effects
for this trait are added until it has the same X matrix as the others. If one trait has
only one record, new records are added until we also have a common environmental
effect for this trait. The conditions that these new records added must follow are:
1. The new records are added to ﬁll the gaps until all traits have the same design
matrixes.
2. The new records must not be used for inferences, since they are not real records.
The second condition is important. Inferences are only based on the sample y, the
augmented data must not be used for inferences, and they will not add any
information or modify the result of the analyses.
Let us call z1 and z2 the vectors of augmented data for traits 1 and 2, and let us
call the new data vectors with all data, recorded and augmented:
160
7
The Linear Model: II. The ‘Mixed’ Model

y∗
1 ¼
y1
z1


;
y∗
2 ¼
y2
z2


The new multitrait model is now
y∗
1 ¼ Xb1 þ Wc1 þ e1
y∗
2 ¼ Xb2 þ Wc2 þ e2
which can be written as
y∗¼ Xb þ Wc þ e
Now we should ﬁnd a way to generate the augmented data in a way in which they
allow us to regularize the vectors and matrixes, but they will not be used for
inferences.
Let us call θ all unknowns:
θ ¼ b, c, C, R
where
C ¼
σ2
c1
σc1c2
σc1c2
σ2
c2


is the (co)variance matrix of the permanent effects of both traits, and
R ¼
σ2
e1
σe1e2
σe1e2
σ2
e2


the (co)variance matrix of the residuals.
We should generate the augmented data z that are also unknown and should be
treated as unknowns. As with the other unknowns θ, we should estimate the
posterior distribution conditioned to the data f(z, θ| y). We do not know this distri-
bution, but we know the distribution of the data, and we can apply the Bayes’
theorem:
f z; θjy
ð
Þ / f yjz; θ
ð
Þ  f z; θ
ð
Þ ¼ f yjz; θ
ð
Þ  f zjθ
ð
Þ  f θ
ð Þ
but, according to the laws of probability, we have
f y; zjθ
ð
Þ ¼ f yjz; θ
ð
Þ  f zjθ
ð
Þ
Thus, substituting, we have
f z; θjy
ð
Þ / f y; zjθ
ð
Þ  f θ
ð Þ ¼ f y∗jθ
ð
Þ  f θ
ð Þ
7.4
The Multitrait Model
161

and now we can start with the Gibbs sampling because we know the distribution of
y* and the conditionals, as we have shown in Sect. 7.1.
Notice that the new augmented data z are not used for inferences. We estimate z
and θ from f(z, θ| y), i.e. given only our sample of observed data y. Then we
disregard the augmented data z, which are not useful after estimating θ, and keep
the estimates of the unknowns θ ¼ b , c , C , R, which are the unknowns in which we
are interested.
As before, we will use bounded uniform priors for all unknowns with the
exception of c, which is Normally distributed with zero mean and a covariance
matrix in which the unknowns are in C. The conditionals we need for the Gibbs
sampling are
f zjb; c; C; R; y
ð
Þ
f b; cjC; R; z; y
ð
Þ ¼ f b; cjC; R; y∗
ð
Þ
f Cjb; c; R; z; y
ð
Þ ¼ f Cjb; c; R; y∗
ð
Þ
f Rjb; c; C; z; y
ð
Þ ¼ f Rjb; c; C; y∗
ð
Þ
At the end of the process, we will have chains for all unknowns and for the
augmented data z. We will ignore the augmented data and we will use the chains of
the unknowns for inferences.
We know how to sample from all conditionals (see Sect. 7.1.3), with the
exception of the conditional of the augmented data z. To calculate the conditional
of the augmented data z, we should consider that the joint distribution of the
augmented and the experimental data is a multivariate Normal distribution:
f z; yjb; c; R
ð
Þ ¼ f y∗jb; c; R
ð
Þ  N Xb þ Wc; I  R
ð
Þ
In the multivariate Normal distribution, the conditional distributions are also
Normal. We will put an example about how to calculate the augmented data.
Example
Let us go to the simple example we put in Sect. 7.4.1. We have growth rate and
food conversion ratio. As this second trait is expensive to measure, only some
animals have been measured; thus, we have growth rate for all animals but food
conversion ratio only for some pigs. Let us divide the data of growth rate in two
groups: the ﬁrst group yGR1 are the pigs having both growth rate and food conver-
sion data, and the second group yGR2 are the pigs that only have growth rate data.
We have the food conversion rate data yFC for the animals in which food conversion
has been measured and the augmented data z for the animals in which food
conversion has not been measured.
yGR ¼
yGR1
yGR2


yFC ¼
yFC1
z


162
7
The Linear Model: II. The ‘Mixed’ Model

We will consider in this example that the ﬁxed effects (e.g. season, batch, parity)
are the same for both traits; thus, the design matrixes X1 and X2 are the same for
both traits.
yGR1 ¼ X1bGR þ eGR1
yFC1 ¼ X1bFC þ eFC1
yGR2 ¼ X2bGR þ eGR2
z ¼ X2bFC þ eFC2
We know that yGR and yFC are jointly normally distributed; thus, the conditional
distribution of z is also normally distributed:
z j bGR, bFC, R, yGR, yFC
 N X2bFC þ σeGReFC
σ2
eGR
yGR2  X2bGR
ð
Þ; I σ2
eFC  σ2
eGReFC
σ2
eGR
 
!
"
#
Once we have z, we can complete the vector yFC and apply Gibbs sampling as
shown in Fig. 7.2.
In practice it is easier to sample the residuals and, instead of sampling from
multivariate distributions, to sample from univariate distributions, as we have seen
in Chap. 6, Sect. 6.2.3.
7.4.3
More Complex Models
The models can be more complex; we can introduce genetic effects:
u1
u2


SORTED BY INDIVIDUAL
 N 0; A  G
ð
Þ
G ¼
σ2
u1
σu1u2
σu1u2
σ2
u2


 Uniform bounded
They are solved using the same procedure.
f(z|b,R,y)
f(b|R,z,y)
f(R|b,z,y)
Fig. 7.2 Gibbs sampling
process for the components of
the multitrait model with
augmented data
7.4
The Multitrait Model
163

Appendix 7.1
The model is
y ¼ Xb þ Wc þ e
Let us assume unbounded ﬂat priors for b as we did when we considered BLUP
as a Bayesian estimator in Sect. 7.3.2. In this case, the variance of the ﬁxed effects is
inﬁnite, and its inverse is null.
Let us call
a ¼
b
c


Q ¼ X
W
½

V1 ¼
0
0
0
Iσ2
e
σ2
c
2
4
3
5
The model is now:
y ¼ Qa þ e
The conditional distribution for the effects is
f b; cjσ2
c; σ2
e; y


/
1
σ2
e

n
2
exp  1
2σ2
e
y  Xb  Wc
ð
Þ0 y  Xb  Wc
ð
Þ



1
σ2
c

m
2
exp  1
2σ2
c
c0c


/
exp  1
2σ2
e
y  Xb  Wc
ð
Þ0 y  Xb  Wc
ð
Þ þ σ2
e
σ2
c
c0c




considering that
a0V1a ¼
b0
c0


0
0
0
Iσ2
e
σ2
c
2
4
3
5 b
c


¼ c0cσ2
e
σ2
c
The distribution can be written as
f ajσ2
c; σ2
e; y


/ exp  1
2σ2
e
y  Qa
ð
Þ0 y  Qa
ð
Þ  a0V1a




We have seen in Chap. 6, Sect. 6.3.2, and Appendix 2 in Chap. 6 that this is a
Normal distribution with mean
ba ¼ Q0Q þ V1

1Q0y
and variance
Q0Q þ V1

1
164
7
The Linear Model: II. The ‘Mixed’ Model

References
Blasco A, Sorensen D, Bidanel JP (1998) A Bayesian analysis of genetic parameters and selection
response for litter size components in pigs. Genetics 149:301–306
Henderson CR (1973) Sire evaluation and genetic trends. In: Proc. Anim. Breed. and Genet. Symp.
in honor of Dr. J. L. Lush. Blacksburg, Virginia, pp 10–41
Henderson CR (1976) A simple method for computing the inverse of a numerator relationship
matrix used in prediction of breeding values. Biometrics 32:69
Martı´nez-A´ lvaro M, Herna´ndez P, Blasco A (2016) Divergent selection on intramuscular fat in
rabbits: responses to selection and genetic parameters. J Anim Sci 94:4993–5003
Mood AM (1950) Introduction to the theory of statistics. McGraw-Hill, New York
Mood AM, Graybill FA (1963) Introduction to the theory of statistics. MacGraw Hill, New York
Searle SR (1971) Linear models. Wiley, New York
Sorensen DA, Gianola D (2002) Likelihood, Bayesian and MCMC methods in quantitative
genetics. Springer, New York
References
165

A Scope of the Possibilities of Bayesian
Inference + MCMC
8
Today, Bayesian spam ﬁlters whisk pornographic and
fraudulent e-mail to our computers’ junk bins. When a
ship sinks, the Coast Guard calls on Bayes and locates
shipwrecked survivors who may have ﬂoated at sea for
weeks. Scientists discover how genes are controlled and
regulated. Bayes even wins Nobel Prizes. Online, Bayes’ rule
trawls the web and sells songs and ﬁlms. It has penetrated
computer science, artiﬁcial intelligence, machine learning,
Wall Street, astronomy and physics, Homeland Security,
Microsoft, and Google. It helps computers translate one
language into another, tearing down the world’s millennia-
old Tower of Babel. It has become a metaphor for how our
brains learn and function. Prominent Bayesians even advise
government agencies on energy, education, and research.
Sharon McGrayne, 2011
Bayesian analysis can be applied in all ﬁelds of animal production in which
statistics is needed. We have seen hitherto how useful Bayesian analysis is for the
standard linear model, including mixed models. We have faced common problems
like comparison among treatments, regression and covariates, genetic merit predic-
tion, variance components estimation and so on. Now we will try to see some of the
possibilities of Bayesian analyses in models that are more complex. It is out of the
scope of this book to have an encyclopaedic list of all possible problems that
Bayesian analysis can handle. What we will do, however, is to carry out a close
examination to some difﬁcult problems and outline their Bayesian solution. We
have chosen three examples that have no solution using classical statistics, or for
which the classical solution is not straightforward.
# Springer International Publishing AG 2017
A. Blasco, Bayesian Data Analysis for Animal Scientists,
DOI 10.1007/978-3-319-54274-4_8
167

8.1
Nested Models: Examples in Growth Curves
‘Nested models’ are typical examples of a problem that has no solution, or at least
not a straightforward solution, in classical statistics. We say that a model has nested
factors when we have levels of a factor that are expressed in only one level of
another factor. For example, if we assign ﬁve dams per sire for mating, and each
dam has always been mated with the same sire, we say that dams are nested to sires.
‘Nested models’ is a similar concept. We are going to put an example of a three-
level nested model: the case of growth curves. Similar examples are models with
longitudinal data (lactation curves, for example).
8.1.1
The Model
A growth curve is estimated by taking several weights of the animals along the
time. Growth curves are non-linear; Fig. 8.1 shows a typical growth curve in
mammals.
Growth curves can be described using several equations, but the most common
one in mammals and birds is the Gompertz curve. A model with the Gompertz
curve can be the following one:
yij ¼ ai  exp ci  exp ki tj




þ εij
where
yij: weight of the animal i at the time j (e.g. at week j or month j).
0
50
100
150
200
250
Age (days)
0
1000
2000
3000
4000
5000
Weight (g)
Fig. 8.1 Growth curve of a rabbit. Observed values (solid line) and ﬁtted values (dotted line)
168
8
A Scope of the Possibilities of Bayesian Inference + MCMC

ai , ci , ki: parameters of the Gompertz curve for animal i
εij: residual for the weight of the animal i at the time j
There is a problem for ﬁtting growth curves. At the end of the growth curve, the
animals are much heavier than at the beginning; thus, due to this scale effect,
weights, and consequently residuals, are more variable with time until they stabilise
(Fig. 8.2). Blasco et al. (2003) proposed that this evolution of the residuals can also
be represented by a growth curve; thus, we can represent the evolution of the
standard deviation of the ﬁtting residuals as
σεj ¼ aε  exp cε  exp kε tj




where
σεj is the standard deviation of the ﬁtting residuals by unit of time j (week j, for
example)
aε , cε , kε are the parameters of the Gompertz curve for the standard deviations of
the residuals
0
50
100
150
200
250
Age (days)
0
1000
2000
3000
4000
5000
Weight (g)
Fig. 8.2 Data of weekly weights of a rabbit population
8.1
Nested Models: Examples in Growth Curves
169

Blasco et al. (2003) assume that the ﬁtting residuals are uncorrelated. Another
characteristic of the model is that the number of variances of the ﬁtting residuals
changes with each animal, since not all animals have the same number of data.
Some animals die before ending the weekly measurements. The residual’s variance
matrix is thus a diagonal matrix V in which σ2
εj is in the diagonal and j varies from
individual to individual.
The parameters of the Gompertz growth curve have a biological interpretation.
Parameter ‘a’ is related to adult weight, as can be seen in Fig. 8.3a, which shows
curves in which only the parameter ‘a’ has been modiﬁed. Parameter ‘k’ is related
to the shape of the curve; Fig. 8.3b shows curves in which only the parameter k has
been modiﬁed. Parameter ‘c’ is related to initial conditions; Fig. 8.3c shows curves
in which only parameter c has been modiﬁed.
The traits adult weight, growth rate and initial body weight all are affected by
environmental and genetic effects; therefore, the parameters of the growth curve are
also affected by them. This can be expressed by a model ‘nested’ to the former
model. In matrix form,
a ¼ Xba þ ea
c ¼ Xbc þ ec
k ¼ Xbk þ ek
where
a, c, k are the vectors containing the Gompertz growth curve parameters of all
animals. These vectors should be estimated from the data, as we will see below.
ba , bc , bk are the vectors containing the environmental systematic effects on the
growth curve parameters. For example, there should be a seasonal effect on adult
weight, growth rate and initial body weight; thus, the vectors b contain the effect
of summer and winter on the growth curve parameters.
ea , ec , ek are the residuals at this nested level and should be distinguished from the
ﬁtting residuals εij. For example, for an animal ‘i’, eai represents all factors
affecting adult weight not considered in ba. They are supposed to be caused by
a
b
c
Fig. 8.3 (a) Changes in parameter ‘a’ of the Gompertz growth curve. (b) Changes in parameter
‘k’. (c) Changes in parameter ‘c’
170
8
A Scope of the Possibilities of Bayesian Inference + MCMC

many small independent effects so that we can appeal to the Central Limit
theorem and consider that they are Normally distributed. Adult weight is
correlated with growth rate and with the initial weight; thus, we will consider
that ea , ec , ek are correlated.
ea, ec, ek  N 0; R
ð
Þ
R ¼
σ2
a
σac
σak
σ2
c
σck
σ2
k
2
4
3
5
In this ﬁrst approach, we will consider that individuals are unrelated; thus,
ea
ec
ek
2
4
3
5
SORTED BY INDIVIDUAL
 N 0; I  R
ð
Þ
I  R ¼
R
0
  
0
0
R
  
0
  
  
  
  
0
0
  
R
2
664
3
775
8.1.2
Marginal Posterior Distributions
The model has unknowns that will be estimated by ﬁnding their marginal posterior
distributions, which will also provide us a measure of the uncertainty we have about
their value. The marginal posterior distributions will be estimated by MCMC
methods. The general procedure is the same that we have seen in Chaps. 6 and 7;
we ﬁrst write the joint posterior distribution, and then, we write the conditional
distributions. When we have functions for sampling from the conditional
distributions, we use them in the Gibbs sampler; otherwise, we use Metropolis–
Hastings or other MCMC method, and we generate chains that after some burning
up will become samples of the respective marginal posterior distributions.
8.1.2.1 Joint Posterior Distribution
For simplicity, we will name p the vector of parameters of all animals and pε the
vector of parameters of the ﬁtting residuals growth curve
p0 ¼ a0; c0; k0
½

p0
ε ¼ aε; cε; kε
½

The probability density function of the joint posterior distribution is
8.1
Nested Models: Examples in Growth Curves
171

f p; b; R; pεjy
ð
Þ / f yjp; b; R; pε
ð
Þ  f p; b; R; pε
ð
Þ
We assume independence between the parameters, the residuals and the envi-
ronmental effects. We also assume independence between individual growth curve
parameters p and the parameters pε of the growth curve of the ﬁtting residuals’
standard deviation. Since we need to know the environmental effects and the
residual variances to deﬁne the parameters, the priors of the parameters p are
conditioned to b and R.
f p; b; R; pεjy
ð
Þ / f yjp; b; R; pε
ð
Þ  f pjb; R
ð
Þ  f b
ð Þ  f R
ð Þ  f pε
ð
Þ
This formula can be simpliﬁed, because y|p implies that the parameters p are
‘given’; thus, we do not need b and R to estimate them; therefore, the joint posterior
distribution can be written as
f p; b; R; pεjy
ð
Þ / f yjp; pε
ð
Þ  f pjb; R
ð
Þ  f b
ð Þ  f R
ð Þ  f pε
ð
Þ
Notice that the prior distribution of the parameters is conditioned by the envi-
ronmental effects and the residuals. This prevents outliers, since the parameters are
the sum of the environmental effects b and the residual e of the nested model. They
cannot be too high because they are limited in the case of b by the estimation
obtained with all individuals, and in the case of the residuals because their size is
controlled by their a priori variances. This outlier’s prevention is better in more
complex models, in which data of relatives contribute to the estimation of each
individual’s growth curve parameters.
As in Chaps. 6 and 7, we consider that the data, when all unknowns are given and
only the ﬁtting residual varies, are Normally distributed
f yjp; pε
ð
Þ  N m; V
ð
Þ
where m is the vector of the ﬁtted growth curve at each point; i.e. for an individual
‘i’ at a time ‘j’,
m0 ¼ m11; m12; m13; . . . ; m21; m22; m23; . . .
½

mij ¼ ai  exp ci  exp ki tj




V is the variance–covariance matrix of the ﬁtting residuals described in Sect.
8.1.1. It is a diagonal matrix with the variances σ2
εj in the diagonal, different for each
time ‘j’ according to the data recorded for each individual.
The prior of the nested model, when the unknowns b and R are given and only
the residual e varies, is also assumed to be Normally distributed
f pjb; R
ð
Þ  N Xb; R
ð
Þ
For b, R and pε we can use bounded ﬂat priors.
172
8
A Scope of the Possibilities of Bayesian Inference + MCMC

8.1.2.2 Conditional Distributions
Conditional distributions are derived as we have seen in Chaps. 6 and 7. They were
derived by Blasco et al. (2003), and we will not detail the derivation here. They
found
f pjb; R; pε; y
ð
Þ  Unknown distribution ! Metropolis Hasting
f bjp; R; pε; y
ð
Þ  Normal distribution ! Direct sampling
f Rjp; b; pε; y
ð
Þ  Inverted Whisart distribution ! Direct sampling
f pεjb; R; p; y
ð
Þ  Unknown distribution ! Metropolis Hasting
The MCMC mechanism is implemented as described in Chaps. 6 and 7.
8.1.3
More Complex Models
Models for growth curves can be made more complex; for example, we can
consider that the data have ﬁxed or random environmental effects at the ﬁtting
level, that the ﬁtting residuals εij are correlated, etc. The way of solving the model
will be the same, but the risk of non-convergence of the MCMC chains and the
increase of uncertainty augments with the over-parameterisation. Blasco et al.
(2003) dealt with the case in which the animals are correlated due to genetic
relationships. They considered
a ¼ Xba þ Zua þ ea
c ¼ Xbc þ Zuc þ ec
k ¼ Xbk þ Zuk þ ek
where ua , uc , uk are vectors with the genetic values of the individuals for the
growth curve parameters. As in Chap. 7, Sect. 7.4.3, we will consider that the
genetic effects are all correlated, so that
ua
uc
uk
2
4
3
5
SORTED BY INDIVIDUAL
 N 0; A  G
ð
Þ
where A is the numerator relationship matrix between individuals (see Chap. 7,
Sect. 7.2.1), and
G ¼
σ2
Ga
σGac
σGak
σ2
Gc
σGck
σ2
Gk
2
4
3
5  Uniformbounded
The typical frequentist procedure for estimating the unknowns would be as
follows:
8.1
Nested Models: Examples in Growth Curves
173

•
Fit individual growth curves for each animal using a model in which the variance
of the error is constant, or it is weighed according to some simple law (a linear
law, for example).
•
Take the curve parameters a, b, k of each individual as if they were the true
values (as observed values), and estimate the variance components.
•
Take the variance components as if they were the true ones and estimate the
genetic values.
By doing this, we ignore the errors of estimation at each level; we take the
individual ﬁtted parameters and the variance components as if they were the true
ones. This leads to underestimating the uncertainty when predicting the genetic
values.
Another complication can arise when growth curves are ﬁtted on selected data, a
problem considered by Piles et al. (2003). They put the example of 10,151 rabbits
selected by growth rate for 11 generations, and in the last generation, 137 rabbits
were weekly weighted from weeks 1 to 40 (not all of them arrived to the 40th week
of age). As the data were selected, to avoid the effect of selection on the marginal
posterior distributions of the growth curves, all data used in selection and the whole
relationship matrix should be used in the analysis. We have 10,014 rabbits with
only one weight and 137 with 40 or less weekly weights, and our objective is to
estimate the growth curves of all these 137 rabbits by taking into account the whole
correlated set of data of the 10,151 rabbits. The problem can be solved deriving the
adequate conditional distributions, as Piles et al. (2003) did, or by using data
augmentation as we saw in Chap. 7, Sect. 7.4.2. We can augment the data until
the whole set of 10.151 rabbits have 40 weights, one per week of age, and use
MCMC as we did in Chap. 7. We sample the augmented data to be used in the
procedure ignoring the augmented data at the end and considering only the growth
curve parameters of the 137 individuals of generation 11. The fact that the aug-
mented data are many more than the actual data does not affect the estimation,
because augmented data are not considered for inferences.
8.2
Modelling Residuals: Examples in Canalising Selection
In Chaps. 6 and 7, we assumed that residuals all have the same variance; the models
were ‘homoscedastic’. However, there are several examples in animal production in
which this is not the case; we have seen in Sect. 8.1 how growth curves have
different residual variances, changing with time. Residual variances can be affected
by genetic and environmental factors. For example, pigs more sensitive to stress
and diseases may have more variable litter size from parity to parity than pigs that
are less sensitive to stress and more disease resistant. Garcı´a et al. (2012) have
shown that rabbits selected for higher litter variability were more sensitive to
external agents and to stress than rabbits selected for lower litter size variability.
The effect of stress and diseases are environmental effects for litter size, but can
174
8
A Scope of the Possibilities of Bayesian Inference + MCMC

have a genetic determination that leads to lower litter size in animals suffering these
agents, as shown by Blasco et al. (2017).
8.2.1
The Model
We will put an example of a simple model. Consider a trait like weaning weight in
beef cattle. We only have one record per animal.
yi ¼ μ þ ai þ ei,
ei  N 0; σ2


where
μ is the general mean. A model with ﬁxed effects would have μ + Fj instead.
ai is the genetic effect on the trait weaning weight. These effects are correlated, as in
Chap. 7, Sect. 7.2.1. In matrix form
a j A, σ2
a  N 0; Aσ2
a


where A is the relationship matrix that we saw in Sect. 7.2.1.
ei is the residual for weaning weight. We consider all residuals to be independent;
thus, cov(ei, ej) ¼ 0.
The same model can be written as
yi ¼ μ þ ai þ σ  εi,
εi  N 0; 1
ð
Þ
since
var ei
ð Þ ¼ var σ  εi
ð
Þ ¼ σ2var εi
ð Þ ¼ σ2  1 ¼ σ2
Now we can consider that the residual variance is not constant but has a genetic
determination (Garcı´a et al. 2009). In this case, the standard deviation of each
animal will be different, and we will have a heteroscedastic model
σi ¼ μ∗þ a∗
i
where
μ∗is the general mean of the standard deviation σ. A model with ﬁxed effects
would have μ∗þ F∗
j
instead. The mean and ﬁxed effects on the standard
deviation are different from the ones acting on the weaning weight; this is why
we add the superscript [*].
8.2
Modelling Residuals: Examples in Canalising Selection
175

a∗
i is the genetic effect acting on the standard deviation of the weaning weight. In
matrix form
a∗j A, σ2
a∗ N 0; Aσ2
a∗


where A is the same relationship matrix as for the trait weaning weight.
Notice that both genetic effects can be correlated, so that
G ¼
σ2
a
ρσaσa∗
ρσaσa∗
σ2
a∗


where ρ is the genetic correlation coefﬁcient between weaning weight and its
standard deviation, andσ2
a andσ2
a∗are the correspsonding additive genetic variances.
It can be shown that this model is equivalent to the reaction norm model used by
geneticists (Hill and Mulder 2010).
8.2.2
Marginal Posterior Distributions
We will make inferences about all unknowns from their marginal posterior
distributions. We will use MCMC to estimate these distributions. We proceed as
in Chaps. 6 and 7,
•
writing the joint posterior distribution,
•
writing the conditional distribution for each unknown,
•
identifying when possible the conditional distribution (whether it is Normal,
Inverted gamma or other functions from which we know how to take random
samples)
•
applying MCMC techniques as we saw in these former chapters. If we have a
function to take random samples from a conditional distribution, we will use it;
otherwise, we will use acceptance rejection, Metropolis–Hastings or other
procedures to extract random samples from these conditional distributions.
8.2.2.1 Joint Posterior Distribution
The p.d.f. of the joint posterior density of all unknowns is
f μ; μ∗; a; a∗; σ2
a; σ2
a∗; ρjy


/ f yjμ; μ∗; a; a∗; σ2
a; σ2
a∗; ρ


 f μ; μ∗; a; a∗; σ2
a; σ2
a∗; ρ


Using ﬂat priors for the means and the genetic parameters, and considering that
they are independent,
176
8
A Scope of the Possibilities of Bayesian Inference + MCMC

f μ; μ∗; a; a∗; σ2
a; σ2
a∗; ρjy


/ f yja; a∗; σ2
a; σ2
a∗; ρ


 f a; a∗jσ2
a; σ2
a∗; ρ


This can be simpliﬁed, as in Sect. 8.1.2, because when a and a* are given, we do
not need the genetic parameters. Therefore,
f μ; μ∗; a; a∗; σ2
a; σ2
a∗; ρjy


/ f yja; a∗
ð
Þ  f a; a∗jσ2
a; σ2
a∗; ρ


f(y| a, a∗) and f a; a∗jσ2
a; σ2
a∗; ρ


are multivariate Normal densities, similar to the
ones we saw in Chap. 7, Sect. 7.4.
8.2.2.2 Conditional Posterior Distributions
Now the procedure is the same as in Chap. 7 and in Sect. 8.2.2. We need to sample
from the conditionals of each unknown. These conditionals cannot be identiﬁed,
and we are forced to use other MCMC procedures like Metropolis–Hastings, as
Iba´~nez-Escriche et al. (2008, 2010) did for the trait uterine capacity in rabbits. After
sampling the conditionals, we proceed with the MCMC procedure to estimate the
marginal posterior distributions of all unknowns.
8.2.3
More Complex Models
The model exposed in Sect. 8.2.1 can be more complex. We can add ﬁxed effects, as
said before. In cases in which we have repeated measurements, like litter size or
milk yield, we can add, as in Chap. 7, Sect. 7.2.1, permanent environmental effects
for the trait and for the standard deviation in a similar manner as we did for the
additive effect, and we can also consider that both permanent environmental effects
can be correlated. The theoretical way for ﬁnding the marginal posterior
distributions of the unknowns is the same, but these highly parameterised models
need good designs and large samples to estimate the marginal posterior
distributions.
We can model the variance instead of the standard deviation (Hill and Zhang
2004),
σ2
i ¼ μ∗þ F∗
j þ a∗
i
This model is similar to the former one. Both models require μ∗þ F∗
j þ a∗
i
being positive for all individuals, which might not happen if the additive values or
the ﬁxed effects are high. The advantage is that the genetic effects are easy to be
interpreted, and the heritability of the variance has a straightforward meaning.
SanCristobal et al. (1998) proposed modelling the logarithm of the variance in
order to avoid the possible negative variances
8.2
Modelling Residuals: Examples in Canalising Selection
177

log σ2
i


¼ μ∗þ F∗
j þ a∗
i
Or its equivalent multiplicative form1
σ2
i ¼
exp
μ∗þ F∗
j þ a∗
i
2

	2
¼ e
μ∗
2  e
F∗
j
2  e
a∗
i
2
The inconvenience of this model is that it does not work in the natural scale, and
the heritability in the exponential scale is difﬁcult to interpret. These three models
have been discussed by Garcı´a et al. (2009) and Hill and Mulder (2010).
No matter which model is used, the way of ﬁnding the marginal posterior
distributions is the same. The main problem lies in identifying the conditionals in
order to ﬁnd a function that would allow us to sample from these distributions;
otherwise, we need to use other MCMC procedures and the task is computer time-
consuming, sometimes convergence does not arrive easily, etc.
Care should be taken with these highly parameterised models, because they may
be sensitive to the hypothesis of the model. For example, Yang et al. (2011) showed
that deviations of the Normality of the residuals when using the SanCristobal et al.
(1998) model lead to great changes in the estimates of the genetic parameters,
particularly in the genetic correlation between the trait and its variance.
8.3
Modelling Priors: Examples in Genomic Selection
The rapid development of DNA technologies has allowed having a large number of
markers at low cost. These markers can be associated with many of the genes
controlling the economically interesting traits, even if the effect of each gene is
small. The simplest marker is the Single Nucleotide Polymorphism (SNP), which
marks a place in the genome in which there is variability in a single nucleotide. For
example, at a concrete point of the DNA chain, some animals can have the bases
Guanine (G) or Adenine (A); thus, we have at this position three possible
genotypes, GG, GA, AA. Nowadays, the use of chips with 50,000–80,000 SNPs
in a genome is common, and there are high-density chips with 850,000 SNPs or
more. The cost of genotyping is dramatically decreasing, and we are approaching
the possibility of having a whole sequence at low cost; nevertheless, for genomic
selection within a population, it seems that chips higher than 50,000 SNPs do not
give substantial extra information (see Blasco and Toro 2014 for a historical
review). Current breeding programs are introducing genomic selection as a main
tool in the program (dairy cattle) or as a useful complement (pigs, poultry). The
question for an animal breeder today is not whether to include genomics in their
programs but how to include it to optimise beneﬁts.
1Notice that log σ2
i


¼ log exp
μ∗þF∗
j þa∗
i
2

2
¼ 2 log exp
μ∗þF∗
j þa∗
i
2
¼ μ∗þ F∗
j þ a∗
i
178
8
A Scope of the Possibilities of Bayesian Inference + MCMC

The other use of genomics has been the detection and localisation of genes with
major effects by associating SNPs with productive traits. These genome wide
association studies (GWAS) have been criticised (Blasco and Toro 2014; Bernardo
2016) mainly because most economically important traits are determined by many
genes of small effect each, and when there are major genes, they have already been
localised and selected. Nevertheless, GWAS is widely used in animal production,
plant production and human medicine, and it has been supported despite its
limitations (Visscher et al. 2012).
8.3.1
The Model
Consider that we have 4000 individual records of milk production in dairy cattle
and we genotype each one of the 4000 cows with a chip of 50,000 SNPs. We will
associate these genetic markers with production records of the animals. In this
example, we will consider one record per animal, ignoring ﬁxed effects.
We generate one variable zi per SNP having an arbitrary value indicating
whether the SNP ‘i’ is ‘homozygous’ for one base, ‘heterozygous’ (i.e. has different
bases) or ‘homozygous’ for the other base. Calling ‘M’ and ‘m’ the two positions of
the bases of one SNP, we have for each SNP
SNPi
MiMi
Mimi
mimi
zi
1
0
1
The values 1, 0, 1 are arbitrary and can be substituted by other values (e.g. 2,
1, 0). The coding is additive; it is related to the number of copies of one reference
allele, ‘M’ in this example. This has sometimes some consequences related to the
scale, but both systems work well and both are widely used. The use of capital letter
‘M’ does not mean that we are considering dominance effects, although models that
are more complex can include this possibility (Vitezica et al. 2013).
As we have said, genomics can be used for genomic selection and for detection
of single genes (GWAS). We will examine now both uses.
8.3.1.1 Genomic Selection
We are going to predict the genetic value of each cow by multiple regression on the
variables we have created. We will consider in this simple example that the data are
pre-corrected, and we will use centred data to avoid the mean and make the
formulae simpler. The equation is
y ¼ a1z1 þ a2z2 þ a3z3 þ    þ a50,000z50,000 þ e
where a1 , a2 , a3    a50, 000 are the coefﬁcients of regression and z1 , z2 , z3    z50, 000
the variables associated with each SNP. Our example, in matrix form, is
8.3
Modelling Priors: Examples in Genomic Selection
179

701
550
115
  
  
775
2
6666664
3
7777775
¼ a1
1
1
1
  
  
0
2
6666664
3
7777775
þ a2
0
0
1
  
  
1
2
6666664
3
7777775
þ a3
1
1
0
  
  
1
2
6666664
3
7777775
þ    þ a50,000
0
1
1
  
  
1
2
6666664
3
7777775
þ
e1
e2
e3
  
  
e50,000
2
6666664
3
7777775
y
¼ a1
z1
þ a2
z2
þ a3
z3
þ    þ a50,000 z50,000 þ
e
where
y are the records of milk production, pre-corrected and centred with respect to their
mean
z1 , z2 , z3 , . . . , z50, 000 are the values of variables indicating the presence of one
polymorphism (MM, Mm, mm) for each SNP (usually indicated by 1, 0, 1 or by
2, 1, 0).
a1 , a2 , a3    a50, 000 are the regression coefﬁcients to be estimated.
Notice that these variables z1 , z2 , z3 , . . . , z50, 000 are actually correlated,
because SNPs close to each other are frequently associated in its genetic transmis-
sion. Thus, the alleles M5 and M23, for example, can be found together in a
frequency showing that they are not independent; i.e. freq(M5, M23) 6¼ freq(M5)
freq(M23). Even the SNPs being in different chromosomes, we can still ﬁnd
correlations between the variables z; for example, selection for one trait can affect
genes placed in different chromosomes and consequently SNPs associated with
these genes will be correlated. This phenomenon is called ‘linkage disequilibrium’
because it is more frequent when both SNPs are physically close to each other
although it can occur in SNPs placed in different chromosomes.2
As the variables z1 , z2 , z3 , . . . , z50, 000 are correlated, the coefﬁcients do not
indicate the importance of each SNP. The equation is useful for predicting the
whole genetic value ‘u’ of an animal but not for detecting single genes. The
coefﬁcient of an SNP in a multiple regression is not the same as the coefﬁcient
that can be found when this SNP is ﬁt in isolation. The coefﬁcients of the equation
will change depending on the number of SNPs considered, because the sum of all of
the terms in the multiple regression equation should give the same genetic value ‘u’
of the animal.3 We will see later how to use SNPs for single gene detection.
2‘Linkage disequilibrium’ is an unfortunate name, not only because two genes in different
chromosomes can be correlated (e.g. due to selection) but also because close genes in the same
chromosome can be in equilibrium, i.e. uncorrelated. Alleles A and B of the same chromosome can
be often present together because of linkage, but when recombination takes place, allele ‘A’ will
appear associated with allele ‘b’, and this new association will remain because recombination is
rare. Therefore, over time, even close genes can be in equilibrium.
3These are general features of multiple regression. For example, if we predict the carcass meat
content (MC) of rabbits using hot carcass weight (CW0) and carcass weight 24 h after slaughter
(CW24), we can ﬁnd an equation like MC ¼ 0.44  CW0 + 0.08  CW24. This does not mean that
CW24 is not related to meat content, but that CW0 estimates most of meat content. A separate
180
8
A Scope of the Possibilities of Bayesian Inference + MCMC

This model cannot be solved using traditional least squares methods because it
has more unknowns than data. However, we have seen in Chap. 7, Sect. 7.2.1, that
we can predict the values of all cows and bulls related to them even when only
having one record per cow; i.e. we had more unknowns than data. The reason is that
we use prior information in our prediction; we consider not only the records of the
cows but their relationships. For example, if we have two cows with one record
each and we want to predict the genetic values of the two cows and one bull related
to them,4 we have,
y1
y2


¼
1
0
0
0
1
0


u1
u2
u3
2
4
3
5 þ
e1
e2


y
¼
Z
u
þ
e
If we try to solve the system by least squares, i.e. taking u as a ‘ﬁxed’ effect, we
take a ﬂat prior for u (see Chap. 6, Sect. 6.4). The equations to be solved are
Z0Z bu ¼ Z0y
but the matrix
Z0Z ¼
1
0
0
0
0
1
0
0
0
"
#
cannot be inverted and the system cannot be solved.5 However, if we try to solve the
system taking u as random effect, we take a Normal prior for u with mean zero and
a known variance–covariance matrix G that depends on the relationships between
individuals (see Chap. 7, Sect. 7.2.1). Solving the system as we did in Chap. 7, Sect.
7.3.1, we have
Z0Z þ G1

bu ¼ Z0y
The matrix Z
0Z + G1 can be inverted
Z0Z þ G1 ¼
1 þ g11
g12
g13
g12
g13
1 þ g22
g23
g23
g33
2
4
3
5
where gij is the element ij of the matrix G1.6 Therefore, the system can be solved.
equation will be MC ¼ 0.52  CW0, showing that the coefﬁcient of regression of CW0 is not the
same as the one in the multiple regression equation.
4In this example, we also ignore ﬁxed effects and the mean, taking the data as pre-corrected.
5Alternatively, we can say that it has no unique solution.
6It is common to use superindex for the elements of inverted matrixes instead of subindex.
8.3
Modelling Priors: Examples in Genomic Selection
181

The use of a non-ﬂat prior information has allowed us to invert the matrix. It is
important to notice that this prior information is not subjective, but it is the actual
information we have according to our knowledge of the relationships between
individuals. Now we have to solve a system of equations having 4000 data and
50,000 unknowns; we will try to solve the system by adding prior information.7 The
problem is that we do not have here the same type of actual information based on
relationships that we had for estimating u, and we have to speculate about this
information. This has led to different procedures named Bayes A, B, C, D, L, R, T,
Z, etc., with variants (Cπ, Dπ, D0, D1, D2, D3, RS, TA, TB, etc.); this is what
Gianola et al. (2009) named ‘The Bayesian alphabet’. We will show here some
examples of this ‘alphabet’, to see how Bayesian solutions can be obtained by
modelling the priors.
8.3.1.2 Genome Wide Association Studies (GWAS)
In genomic selection, our objective is to establish a prediction equation as a whole,
not to make inferences for single SNPs. If our objective is to localise single genes
with relevant effect on the trait, we can perform genome wide association analyses
(GWAS), in which we take each SNP in isolation and ﬁt 50,000 individual single
regressions of the data y on each variable zi. If one of the SNPs is correlated with a
causal gene with high effect, the coefﬁcient ai of this SNP will be large. Of course,
several close SNPs highly correlated will give similar high coefﬁcients; thus,
estimating the effects in groups is common (what in the literature are called
‘windows’).
Individually or in ‘windows’, we face a serious statistical problem known as
‘multiple test’, consisting in the appearance of SNPs having large effects by chance.
If we perform 50,000 individual tests for each SNP, many of them will detect some
relevant SNP effects by chance even if the SNP has a null effect.8 This is a difﬁcult
problem, out of the scope of this book, but the models used for GWAS can be the
same as the ones used for genomic selection; thus, we will examine them consider-
ing both uses.
The models that we will examine differ in their prior speciﬁcation. The models
can be more complex, as the ones discussed in Chap. 7, by adding ﬁxed
7This also solves the problem of the high collinearity of the equations. Two close SNPs are usually
highly correlated; thus, the variables z are highly collinear and the matrix Z0Z is difﬁcult or
impossible to invert.
8This problem does not depend on whether we use frequentist or Bayesian statistics; it is an
intrinsic problem of the data and the procedure. Imagine we estimate the mean height of Scots by
taking one random representative sample; we do not have any problem in admitting that the sample
mean is an estimator of the mean population of Scots. Then we take 100 random representative
samples of Scots, and we select the one in which the average of Scots are taller. We can object that
this sample, although random and representative, has been favoured by hazard. Now we take
100 random representative samples of people from several nations of the world: Scots, Catalans,
Kurdish, Corsicans, etc. We know that some samples have been favoured by hazard, but we do not
know which ones. The same happens in the multiple test comparison: some SNPs are favoured by
hazard, but we do not know which ones.
182
8
A Scope of the Possibilities of Bayesian Inference + MCMC

environmental effects or random common permanent effects. We can also add
genetic effects capturing the genetic part that is not explained by the markers,
either an additive part or including dominant effects (Vitezica et al. 2013), but this
will not affect the modelling of priors, and the MCMC procedure for solving all the
models will be the same as the procedure we have seen in Chap. 7.
8.3.2
RR-BLUP
RR-BLUP (‘Ridge Regression’ or ‘Random Regression’ BLUP) was ﬁrst proposed
by Meuwissen et al. (2001), and it is a method widely used in genomic selection.
Let us consider the example of the former section.
y ¼ Za þ e
where
a is a vector with the multiple linear regression coefﬁcients a1 , a2 , a3    a50, 000
to be estimated. It is a random vector with a non-ﬂat prior because we need this
condition for solving the system of equations, as we have seen in Sect. 8.3.1. Here
we will assume that all effects are a priori Normally distributed and have the same
variance. We will also assume that they are a priori uncorrelated.
f ajσ2
a


 N 0; Iσ2
a


In multiple linear regressions, when the variables z1 , z2 , z3 , . . . , z50, 000 are
correlated, the coefﬁcients a1 , a2 , a3    a50, 000 are also correlated. We assume an
a priori independence, because we have two correlated markers (M1, m1) and (M2,
m2), and we do not know in which chromosome is each allele; thus, we do not know
whether M1 is linked to m2 or to M2. Moreover, considering all covariances will
make the problem intractable. After performing the analysis, the coefﬁcients will be
correlated a posteriori.
σ2
a is the a priori variance of the effect of each SNP. It shows our uncertainty
about the value of each effect. We assume:
•
The trait is determined by many genes each one having a small effect.
•
The SNPs effects are (a priori) uncorrelated.
•
We have the same a priori uncertainty for all markers.
•
The whole genetic variance of the trait should be shared among all SNPs; thus,
we can propose, as Meuwissen et al. (2001) did,
σ2
a ¼
σ2
u
50, 000
8.3
Modelling Priors: Examples in Genomic Selection
183

where σ2
u is the genetic variance of the trait that can be estimated independently.
However, the most common proposal for the prior variance is (see Appendix 8.1)
σ2
a ¼
σ2
u
P
50, 000
1
2piqi
where ( pi, qi) are the frequencies of the alleles (Mi, mi) at each SNP.9 This way
of deﬁning the a priori variance means that our uncertainty about the individ-
ual effect of a SNP decreases when the number of SNPs augments, and the
effect is closer to zero, since the mean of each SNP prior distribution is zero.
Notice that both the SNP effect and our uncertainty about it are very small
quantities.
Z is a matrix indicating in the columns which type of SNP (MM, Mm or mm) is in
the position 1, 2,. . .,50,000 for each cow ‘i’.
e is a vector of random effects containing the residuals, and they are assumed
independently Normally distributed; i.e.
e j σ2
e  N 0; Iσ2
e


and we need to deﬁne the prior information for the error variance, for which
we decide to use a conjugated prior or a ﬂat prior with bounds, as in Chaps. 6
and 7.
σ2
e  U 0; ke
½

The procedure for estimating the effects, if we want to use MCMC, is the same
as we saw in Chap. 7, Sect. 7.2, but we can have an analytical solution by solving
the system
Z0Z þ G1

ba ¼
Z0Z þ Iσ2
e
σ2
a


ba ¼ Z0y
because now the matrix
9These should be the frequencies in the base population, before starting any selection process,
although there are evidences that the current frequencies used in the data analysis can give similar
results (Forni et al. 2011). From a strict Bayesian point of view, information from the data should
not be used when deﬁning prior information, but this is a rather common practice in cases in which
it would be difﬁcult to ﬁnd an alternative. This falls among the set of procedures called ‘Empirical
Bayes’, which are not necessarily considered ‘Bayesian’.
184
8
A Scope of the Possibilities of Bayesian Inference + MCMC

Z0Z þ Iσ2
e
σ2
a


can be inverted, since the term σ2
e
σ2a is added to the diagonal of Z0Z.
Adding a term in the diagonal in order to allow inverting this matrix is a classical
statistical procedure called ‘ridge regression’. The similarity of this procedure with
ridge regression methods and with BLUP led to the term ‘ridge regression BLUP’
(RR-BLUP) as it is also known. It is also known as ‘random regression BLUP’
because the coefﬁcients have non-ﬂat priors, which in a frequentist context
corresponds to random effects (see Chap. 7, Sect. 7.3). It can be shown (Habier
et al. 2007; Goddard 2009) that this procedure is equivalent to the use of a
relationship matrix between individuals that takes into account the number of
sites in which relatives share the same genetic type of SNP. For example, we
know that on average full sibs share half of their genomic information, but by
crossing two heterozygotes Aa  Aa we could produce three full sibs AA, AA and
aa. The two ﬁrst full sibs are more similar for this SNP when compared with the
other full sib. Taking into account all SNPs, we can have a more accurate idea about
the real correlation between relatives. This allows being more accurate in the
genetic evaluation that we saw in Chap. 7, Sect. 7.2. This procedure is known as
‘Genomic-BLUP’ (G-BLUP; see for example Clark and Van der Werf 2013).
8.3.3
Bayes A
Bayes A, as called by their authors (Meuwissen et al. 2001), considers that the traits
are genetically determined by many genes with small effects and some genes with
medium or large effects. They modelled this by augmenting the prior uncertainty
about the size of the effect of some SNPs. In G-BLUP, we did not allow any effect
to be large because all of them had a prior distribution with a very small prior
variance σ2
a. Now some SNPs are allowed to have larger effects by having larger
prior variances; i.e. we are not so sure that all SNPs will have a small effect; thus,
we augment our uncertainty about some of them. How many? How big should the
effects be allowed to be? From experiments in animal breeding, we know that some
traits (litter size, for example) have very few genes with large effect, some more
genes with medium effect, some more with less than medium effect, etc.
Meuwissen et al. (2001) model this prior information as follows:
•
Each SNP effect has a different prior variance
f aijσ2
i


 N 0; σ2
i


where all SNP effects ai are, as before, a priori uncorrelated.
•
Most variances should be very small, but some of them can be large, some
medium, some smaller, etc. We can represent this by an inverted gamma
distribution of the type we have seen in Chap. 3, Sect. 3.5.4 (Fig. 8.4). We can
change its shape by modifying its parameters α and β.
8.3
Modelling Priors: Examples in Genomic Selection
185

σ2
i  IG αi; βi
ð
Þ /
1
σ2
i

αiþ1 exp βi
σ2
i


The hyper-parameters αi and βi determine the shape of the prior distribution of
the variance of each SNP effect, showing our state of uncertainty (i.e. our ‘igno-
rance’) about the values of the variances. We could expect that, having a large data
set, our posterior uncertainty about this parameter would be lower. However,
Gianola et al. (2009) have shown that, even having a large amount of data, hyper-
parameters are slightly modiﬁed by the evidence provided by the data, so that we
cannot really learn about the genetic determination of the trait,10 as represented by
the model. The model is ﬂexible, because it produces different shrinkage of the
regression coefﬁcients ai, allowing SNPs with large and medium effects, which are
shrunk in distinct manners, according to their prior variances (Gianola 2013).
It has been shown by Gianola et al. (2009) that this parameterisation is equiva-
lent to assuming that the effects of each SNP are distributed under the same t-
distribution
f aijσ2
a; v


 tv 0; σ2
a


where v is the degrees of freedom, the mean of the t-distribution is zero and the
variance, which is higher or lower depending on the degrees of freedom, is11
Effect size
SNP number
Fig. 8.4 Inverted gamma
distribution showing the
expected size of SNPs effects
10Named nowadays with the somewhat pretentious term ‘genetic architecture’ of the trait.
11Deﬁned for v > 2. When v  2, the distribution has no variance, although it may be still used as
prior distribution.
186
8
A Scope of the Possibilities of Bayesian Inference + MCMC

v
v  2 σ2
a
The t-distributions have ‘thick’ tails (Fig. 8.5), allowing some genes to have
major or medium effects with higher probability than with the Normal distribution.
Bayes A has been used in GWAS, since the objective of these studies is detecting
major genes or genes with medium effect (see, for example, Lo´pez de Maturana
et al. 2014).
8.3.4
Bayes B
We usually assume that the traits are genetically determined by a much lower
number of causal genes than the SNPs we have in a chip, and we also assume that
the causal genes are not uniformly distributed along the whole genome. As SNPs of
our chips are distributed along the whole genome, we assume that most SNPs will
have null or almost null effect on the trait. Meuwissen et al. (2001) suggest that we
can model the prior as we did before with Bayes A, but allowing a percentage of the
SNPs to have a zero effect,
f aijσ2
i


 N 0; σ2
i


σ2
i ¼ 0 with probabilityπ
σ2
i  IG α; β
ð
Þ with probability1  π
where the value of π is given a priori and should be based in our previous
information about the percentage of SNPs that usually have zero value. This is
modelled by using Bernoulli variables δi that take values 0 or 1 with probability π
and 1  π, respectively.
Notice that by assigning a zero value to the a priori variance, we say that we are
sure about the value of the SNP effect (we have no uncertainty), and we also say
that this value is zero because the effects are Normally distributed with zero mean.
Fig. 8.5 Distribution of SNP
effects. Blue line Normal. Red
line t-distribution with
2 degrees of freedom
8.3
Modelling Priors: Examples in Genomic Selection
187

This creates a problem, since different values of π can lead to different results;
therefore, a robustness analysis is sometimes done by trying several π values.
8.3.5
Bayes C and Bayes Cp
Bayes C and the variant Cπ were proposed by Habier et al. (2011). Bayes C is the
same as RR-BLUP, but with the possibility of assigning zero value to some SNP
effects, as in Bayes B
f ajσ2
a


 N 0; Iσ2
a


σ2
a ¼ 0 with probabilityπ
σ2
a  IG α; β
ð
Þ with probability1  π
As in RR-BLUP, it considers that there are no genes with major effects, but it
also considers that a large part of the SNPs may have zero value; i.e. many SNPs do
not affect the trait. As in Bayes B, we should give the value of π, and results are
sensitive to the value we give.
Bayes Cπ is the same as Bayes C, but we decide that it should be the data that
will decide the values of π; thus, we consider π as a random value having a prior
distribution. It is somewhat arbitrary which prior distribution should be used for π,
but it should be a vague prior. Following the principle of indifference, we can give a
uniform (ﬂat) prior to π (we will discuss about this procedure in Chap. 9).
8.3.6
Bayes L (Bayesian Lasso)
The ‘least absolute shrinkage and selection operator’ (LASSO) was proposed by
Tibshirani (1996) for ﬁtting regression equations when some variables were highly
correlated leading to large s.e. Collinearity produces difﬁculties for inverting the
matrix of the equation that gives the least square solution we have seen in Sect.
8.3.1. The classical solutions are the Ridge regression, as in Sect. 8.3.2., or selection
of a smaller set of variables, for example by stepwise regression. The ﬁrst procedure
does not remove variables in the equation setting the coefﬁcients to zero, and the
stepwise regression and other selection methods are sensitive to particularities of
the sample; two different samples can lead to different variables selected, as we will
comment in Chap. 10. For a regression equation, the LASSO consists in shrinking
some coefﬁcients (just like if they were considered random factors) and setting
some of them to zero. It tries to get the advantages of the two procedures
commented before. The LASSO minimises the residual sum of squares, as usual
in regression, with the restriction that the sum of all regression coefﬁcients
(in absolute value) should be lower than a determined quantity ﬁxed by the
188
8
A Scope of the Possibilities of Bayesian Inference + MCMC

researcher. Later, Park and Casella (2008) presented a Bayesian version of the
LASSO and de los Campos et al. (2009) adapted it to genomics. We consider the a
priori distribution of the SNP effects to be
f aijλ
ð
Þ ¼ λ
2 exp λ ai
j j
ð
Þ
We consider, as before, the SNPs to be independent; therefore,
f ajλ
ð
Þ ¼
Y
50, 000
1
f aijλ
ð
Þ ¼
Y
50, 000
1
λ
2 exp λ ai
j j
ð
Þ
The parameter λ determines the ‘sharpness’ of the distribution (Fig. 8.6), and it
can be ﬁxed by the researcher or a prior distribution can be assigned to λ, as we did
with the parameter π of Bayes Cπ, usually a ﬂat prior or a conjugated prior
(a Gamma distribution, for example; see de los Campos et al. 2009).
Once the priors have been deﬁned, the model is solved and the marginal
posterior distributions of all unknowns are derived by Gibbs sampling.
8.3.7
Bayesian Alphabet in Practice
Genomics has been used for predicting the genetic merit of the candidates to
selection and for searching genes with major or medium effects. The success of
one or the other methods largely depends on the true genetic determination of the
trait analysed. If the trait is determined by many genes with small effects,
RR-BLUP or Bayes C are convenient methods for genomic prediction of breeding
values. Even when a trait is determined by many genes, they are not expected to be
uniformly located along the genome; thus, Bayes C should perform even better than
RR-BLUP. Bayes A, Bayes B and Bayes L allow for large gene effects; thus, when
there are such genes they should perform well in genomic prediction of breeding
values and in genomic detection of single genes. Fernando and Garrick (2013) have
noticed that in simulation studies, Bayes A and Bayes B had higher accuracy of
prediction than RR-BLUP, but in real applications, RR-BLUP works just as well as
Bayes A, Bayes B or Bayes C and sometimes even better. This occurs probably
because in practice, even if there are genes with medium-large effects, they are not
in close association with only few markers, but their effect is captured by many
markers. When there are genes with large effects, they can be detected better with
Bayes B, setting to zero a large proportion of SNPs effects. As Bayes B is sensitive
to the π value used, Bayes Cπ permits to avoid robustness analyses about the value
of π, but when the data set is small, π is not accurately determined and there are
problems of convergence; thus, Bayes B or C should be used instead.
Bayes L allows for genes with larger effects than the other methods whereas
shrinking to zero more effectively than other distributions (see Fig. 8.6) and
8.3
Modelling Priors: Examples in Genomic Selection
189

apparently performs better than Bayes A when there are many SNPs with null effect
(de los Campos et al. 2009). It also has a much better convergence than Bayes Cπ
having the same accuracy for predictions (Colombani et al. 2012).
There is a wide amount of studies comparing these Bayesian methods, both with
real and simulated data. The choice of one or other method is determined by several
circumstances: computation facilities when managing large data sets, the need of
reducing the number of SNPs to be considered when the sample is small, the
objective of the work (prediction of genetic value or detecting genes), etc. As
said before, the actual genetic determination of the data, the association of the
genes with the markers, the number of markers considered, etc., will decide the
optimal method to be used.
Appendix 8.1
Fernando et al. (2007) proposed to assign a value to the prior variance of the SNPs
derived from the total genetic variance. Their rationale is as follows: If the SNPs are
not correlated (they are in linkage equilibrium), the total genetic variance σ2
u will be
the sum of the variances contributed by each SNP, since the covariances are null.
Each SNP has a probability ‘p’ of having an allele M and ‘q’ of having an allele m;
thus, the genetic variance contributed by each SNP is the variance of a binomial
distribution, 2pqa2. If we have k SNPs, the total variance will be
σ2
u ¼
X
k
1
2piqia2
i
Now consider
Fig. 8.6 Bayesian Lasso
distribution (in red) compared
with the Normal distribution
(in blue)
190
8
A Scope of the Possibilities of Bayesian Inference + MCMC

1
k
X
k
1
a2
i ¼ 1
k
X
k
1
ai  0
ð
Þ2 ¼ σ2
a
cov 2piqi; a2
i


¼ 1
k
X
k
1
2piqia2
i 
1
k
X
k
1
2piqi
 
!
1
k
X
k
1
a2
i
 
!
¼ 1
kσ2
u 
1
k
X
k
1
2piqi
 
!
σ2
a
If we assume that the SNP effects are independent of the frequencies, this
covariance is null; therefore,
σ2
a ¼
σ2
u
P
k
1
2piqi
References
Bernardo R (2016) Bandwagons I, too, have known. Theor Appl Genet 129:2323–2332
Blasco A, Martı´nez-A´ lvaro M, Garcı´a ML, Iba´~nez-Escriche N, Argente MJ (2017) Selection for
environmental variance of litter size in rabbits. Genet Sel Evol 49:48
Blasco A, Piles M, Varona L (2003) A Bayesian analysis of the effect of selection for growth rate
on growth curves in rabbits. Genet Sel Evol 35:21–42
Blasco A, Toro MA (2014) A short critical history of the application of genomics to animal
breeding. Livest Sci 166:4–9
Clark SA, van der Werf J (2013) Genomic best linear unbiased prediction (gBLUP) for the
estimation of genomic breeding values. In: Gondro C, van der Werf J, Hayes B (eds)
Genome-wide association studies and genomic prediction. Humana Press, New York
Colombani C, Croiseau P, Fritz S, Guillaume F, Legarra A, Ducrocq V, Robert-Granie´ C (2012) A
comparison of partial leastsquares (PLS) and sparse PLS regressions in genomic selection in
French dairy cattle. J Dairy Sci 95:2120–2131
de los Campos G, Naya H, Gianola D, Crossa J, Legarra A, Manfredi E, Weigel K, Cotes JM
(2009) Predicting quantitative traits with regression models for dense molecular markers and
pedigree. Genetics 182:375–385
Fernando RL, Garrick D (2013) Bayesian methods applied to GWAS. In: Gondro C, van der
Werf J, Hayes B (eds) Genome-wide association studies and genomic prediction. Humana
Press, New York
Fernando RL, Habier D, Stricker C, Dekkers JCM, Totir LR (2007) Genomic selection. Acta Agric
Scand A 57:192–195
Forni S, Aguilar I, Misztal I (2011) Different genomic relationship matrices for single-step
analysis using phenotypic, pedigree and genomic information. Genet Sel Evol 43:1
Garcı´a ML, Argente MJ, Muelas R, Birlanga V, Blasco A (2012) Effect of divergent selection for
residual variance of litter size on health status and welfare. In: 10th World Rabbit Congress,
Sharm El-Sheikh, Egypt, 3–6 September 2012, pp 103106
Garcia M, David I, Garreau H, Ibanez-Escriche N, Mallard J, Masson JP, Pommeret D, Robert-
Granie C, Bodin L (2009) Comparisons of three models for canalising selection or genetic
References
191

robustness. In: 60th annual meeting of European Association for Animal Production. Spain,
Barcelona
Gianola D (2013) Priors in whole-genome regression: the Bayesian alphabet returns. Genetics
194:573–596
Gianola D, de los Campos G, Hil WG, Manfredi E, Fernando RL (2009) Additive genetic
variability and the Bayesian alphabet. Genetics 183:347–363
Goddard M (2009) Genomic selection: prediction of accuracy and maximisation of long term
response. Genetica 136:245–257
Habier D, Fernando RL, Dekkers JCM (2007) The impact of genetic relationship information on
genome-assisted breeding values. Genetics 177:2389–2397
Habier D, Fernando RL, Kizilkaya K, Garrick D (2011) Extension of the Bayesian alphabet for
genomic selection. BMC Bioinformatics 12:186
Hill WG, Mulder HA (2010) Genetic analysis of environmental variation. Genet Res 92:381–395
Hill WG, Zhang XS (2004) Effects on phenotypic variability of directional selection arising
through genetic differences in residual variability. Genet Res 83:121–132 (Erratum 83, 160)
Iba´~nez-Escriche N, Garcia M, Sorensen D (2010) GSEVMv.2: MCMC software to analyze
genetically structured environmental variance models. J Anim Breed Genet 127:249–251
Iba~nez-Escriche N, Sorensen D, Waagepetersen R, Blasco A (2008) Selection for environmental
variation: a statistical analysis and power calculations to detect response. Genetics
180:2209–2226
Lo´pez de Maturana E, Iba~nez-Escriche N, Gonza´lez-Recio O, Marenne G, Mehrban H, Chanok SJ,
Goddard M, Malats N (2014) Next generation modeling in GWAS: a comparison study among
different genetic architectures. Hum Genet 123:1235–1253
McGrayne SB (2011) The theory that would not die. Yale University Press, New Haven, NJ
Meuwissen TH, Hayes BJ, Goddard ME (2001) Prediction of total genetic value using genome-
wide dense marker maps. Genetics 157:1819–1829
Park T, Casella G (2008) The Bayesian LASSO. J Am Stat Assoc 103:681–686
Piles M, Gianola D, Varona L, Blasco A (2003) Bayesian inference about parameters of a
longitudinal trajectory when selection operates on a correlated trait. J Anim Sci 81:2714–2724
SanCristobal M, Elsen JM, Bodin L, Chevalet C (1998) Prediction of the response to a selection for
canalisation of a continuous trait in animal breeding. Genet Sel Evol 30:423–451
Tibshirani R (1996) Regression shrinkage and selection via the LASSO. J R Stat Soc B
58:267–288
Visscher PM, Brown MA, McCarthy MI, Yang J (2012) Five years of GWAS discovery. Am J
Hum Genet 90:7–24
Vitezica ZG, Varona L, Legarra A (2013) On the additive and dominant Variance and covariance
of individuals within the genomic selection scope. Genetics 195:1223–1230
Yang Y, Christensen OF, Sorensen D (2011) Analysis of a genetically structured variance
heterogeneity model using the Box-Cox transformation. Genet Res 93:33–46
192
8
A Scope of the Possibilities of Bayesian Inference + MCMC

Prior Information
9
We were certainly aware that inferences must make use of
prior information, but after some considerable thought and
discussion round these matters we came to the conclusion,
rightly or wrongly, that it was so rarely possible to give sure
numerical values to these entities, that our line of approach
must proceed otherwise
Egon Pearson, 1962
One of the most attractive characteristics of Bayesian theory is the possibility of
integrating prior information in the inferences; thus, we should discuss here why
this is so rarely done, at least in the biological application. Hitherto, we have
assumed that prior distributions were ﬂat or they had a convenient conjugated
form, but we have derived the discussion about prior information to this chapter.
Bayesian inference has been questioned due to the difﬁculty in properly integrating
prior information in the analyses. It has also been stressed the impossibility of
making inferences using probabilities when we have a total prior ignorance. This
chapter is dedicated to discuss these topics, to see how and when Bayesian infer-
ence can use prior information and how we can deal with the problem of not having
any prior information that we would like to consider.
9.1
Exact Prior Information
9.1.1
Prior Information
When there is exact prior information available, there is no discussion about
Bayesian methods and prior information can be integrated using the rules of
probability. The following example is based on an example prepared by Fisher
(1959), who was a notorious anti-Bayesian, but he never objected to the use of prior
probability when clearly established. We have introduced this example in Chap. 2
(Sect. 2.1.3).
# Springer International Publishing AG 2017
A. Blasco, Bayesian Data Analysis for Animal Scientists,
DOI 10.1007/978-3-319-54274-4_9
193

Suppose there is a type of laboratory mouse whose skin colour is controlled by a
single gene with two alleles, ‘A’ and ‘a’, so that when the mouse has two copies of
the recessive allele (aa), its skin is brown, and it is black in the other cases (AA and
Aa). We cross a black and a brown mouse and we obtain two black mice that should
have the alleles (Aa) because they have received the allele ‘a’ from the brown
parent, and the allele of the other parent must be ‘A’; otherwise, they would have
been brown. We now cross both black (Aa) mice, and we have a descent that is
black coloured. This black mouse could have received both ‘A’ alleles from its
parents, and in this case, we would say that it is homozygous (AA), or it could have
received one ‘A’ allele from one parent and one ‘a’ allele from the other parent; in
this case, we would say it is heterozygous (Aa or aA). We are interested in knowing
which type of black mouse it is, homozygous or heterozygous. In order to ﬁnd out,
we must cross this mouse with a brown mouse (aa) and examine the offspring
(Fig. 9.1).
If we get a brown mouse as an offspring, we will know that the mouse is
heterozygous, because the brown mouse has to be (aa) and should have received
an ‘a’ allele from each parent, but if we only get black offspring we still will have
the doubt about whether it is homo- or heterozygous. If we get many black
offspring, it will be unlikely that the mouse is heterozygous, because the ‘a’ allele
should have been transmitted at least to one of its descents. Notice that before
making the experiment we can calculate the probability of obtaining black or brown
offspring. We know that the mouse to be tested cannot be (aa) because otherwise it
would be brown. Thus, it either received both ‘A’ alleles from its mother and father,
and therefore, it is (AA), or an ‘A’ allele from the father and an ‘a’ allele from the
mother to become (Aa), or the opposite, to become (aA). We have three possi-
bilities; thus, the probability of being ‘AA’ is 1/3 and the probabilities of being
heterozygous (‘Aa’ or ‘aA’, both are genetically identical) is 2/3. This is what we
expect before having any data from the experiment. Notice that these expectations
are not merely ‘beliefs’ but quantiﬁed probabilities. Also notice that they come
from our knowledge of the Mendel laws and from the knowledge that our mouse is
the son of two heterozygotes; this prior knowledge is based in previous experience.
Aa
Aa
aa
??
X
X
Black
Black
Black
Brown
P(AA) = 1/3
P(Aa) = 2/3
AA
Aa
aA
Fig. 9.1 Experiment to
determine whether a parent is
homozygous (AA) or
heterozygous (Aa or aA)
194
9
Prior Information

9.1.2
Posterior Probabilities with Exact Prior Information
Now, the experiment is made and we obtain three offspring, all black (Fig. 9.2).
They received for sure an ‘a’ allele from the mother and an ‘A’ allele from our
mouse, but our mouse can still be homozygous (AA) or heterozygous (we will not
make any difference from Aa and aA in the rest of the chapter; since they are
genetically identical, we will use (Aa) for both). Which is the probability of being
each type?
To ﬁnd it out, we will apply the Bayes Theorem. The probability of being
homozygous (AA) given that we have obtained three black offspring is
P AA j y ¼ 3 black
ð
Þ ¼ P y ¼ 3 black j AA
ð
Þ  P AA
ð
Þ
P y ¼ 3 black
ð
Þ
We know that if it is true that our mouse is AA, the probability of obtaining a
black offspring is 1, since the offspring will always have an ‘A’ allele. Thus,
P y ¼ 3 black j AA
ð
Þ ¼ 1
We also know that the prior probability of being AA is 1/3; thus,
P AA
ð
Þ ¼ 0:33
Finally, the probability of the sample is the sum of the probabilities of two
excluding events: having a parent homozygous (AA) or having a parent hetero-
zygous (Aa).
P y ¼ 3 black
ð
Þ ¼ P y ¼ 3 black&AA
ð
Þ þ P y ¼ 3 black&Aa
ð
Þ ¼
¼ P y ¼ 3 black j AA
ð
Þ  P AA
ð
Þ þ P y ¼ 3 black j Aa
ð
Þ  P Aa
ð
Þ
to calculate it we need the prior probability of being heterozygous, which we know
it is:
Aa
Aa
aa
??
X
X
Black
Black
Black
Black
Black
Black
Brown
P(AA) = 1/3
P(Aa) = 2/3
AA
Aa
aA
Fig. 9.2 Experiment to
determine whether a parent is
homozygous (AA) or
heterozygous (Aa or aA).
Results of the experiment
9.1
Exact Prior Information
195

P Aa
ð
Þ ¼ 2
3
and the probability of obtaining our sample if it is true that our mouse is Aa. If our
mouse was Aa, the only way of obtaining a black offspring is if this offspring got its
A allele from him; thus, the probability of obtaining one black offspring would be
1/2. The probability of obtaining three black offspring will be 1/2  1/2  1/2; thus,
P y ¼ 3 black j Aa
ð
Þ ¼
1
2
 3
Now we can calculate the probability of our sample:
P y ¼ 3 black
ð
Þ ¼ P y ¼ 3 black j AA
ð
Þ  P AA
ð
Þ þ P y ¼ 3 black j Aa
ð
Þ  P Aa
ð
Þ ¼
¼
1

1
3
þ
1
2
 3

2
3
¼ 0:42
Then, applying Bayes theorem
P AA j y ¼ 3 black
ð
Þ ¼ P y ¼ 3 black j AA
ð
Þ  P AA
ð
Þ
P y ¼ 3 black
ð
Þ
¼ 1  0:33
0:42
¼ 0:80
The probability of being heterozygous can be calculated again using the Bayes
theorem, or simply
P Aa j y ¼ 3 black
ð
Þ ¼ 1  P AA j y ¼ 3 black
ð
Þ ¼ 1  0:80 ¼ 0:20
Thus, we had a prior probability before obtaining any data, and a probability after
obtaining three black offspring
prior P AA
ð
Þ ¼ 0:33
posterior P AAjy
ð
Þ ¼ 0:80
prior P Aa
ð
Þ ¼ 0:67
posterior P Aajy
ð
Þ ¼ 0:20
before the experiment was performed it was more probable that our mouse was
heterozygous (Aa), but after the experiment it is more probable that it is homo-
zygous (AA).
Notice that the sum of both probabilities is 1
P AAjy
ð
Þ þ P Aajy
ð
Þ ¼ 1:00
Thus, the posterior probabilities give a relative measure of uncertainty (80% and
20%, respectively).
196
9
Prior Information

However, using the maximum likelihood method, we can also give a higher
chance to the homozygous (AA), but we do not have a measure of evidence.
Consider the likelihood of both events; as we have seen before,
If it is true that our mouse is AA, the probability of obtaining a black offspring is 1
P y ¼ 3 black j AA
ð
Þ ¼ 1
If it is true that our mouse is Aa, the probability of obtaining our sample is
P y ¼ 3 black j Aa
ð
Þ ¼
1
2
 3
¼ 0:125
Notice that the sum of the likelihoods is not 1 because they come from different
events
P yjAA
ð
Þ þ P yjAa
ð
Þ ¼ 1:125
Thus, the likelihoods do not provide a measure of uncertainty. Even if we rescale
the likelihood to force the sum to 1, the relative value of the likelihoods still does
not provide a relative measure of their evidence as the probability does.
9.1.3
Influence of Prior Information in Posterior Probabilities
If we had used ﬂat priors, instead of using exact prior information, repeating the
calculus, we will obtain
prior P AA
ð
Þ ¼ 0:50
posterior P AAjy
ð
Þ ¼ 0:89
prior P Aa
ð
Þ ¼ 0:50
posterior P Aajy
ð
Þ ¼ 0:11
we can see that ﬂat prior information had an inﬂuence in the ﬁnal result. We still
favour the homozygous case (AA), but we are overestimating the evidence in
favour of it. When having exact prior information, the correct way to make an
inference is to use this exact prior information.
Suppose now that we have a large amount of information favouring the case
(Aa). Suppose we know that our prior information of being AA is P(AA) ¼ 0.002.
Computing the probabilities again we obtain
prior P AA
ð
Þ ¼ 0:002
posterior P AAjy
ð
Þ ¼ 0:02
prior P Aa
ð
Þ ¼ 0:998
posterior P Aajy
ð
Þ ¼ 0:98
Thus, despite of having evidence from the data in favour of AA, we decide that the
mouse is Aa because prior information dominates, and the posterior distribution
favours Aa. This has been a frequent criticism to Bayesian inference, but one
9.1
Exact Prior Information
197

wonders why an experiment should be performed when the previous evidence is so
strong in favour of Aa.
What could have happened if instead of three black offspring we had obtained
seven black offspring?
Repeating the calculus for y ¼ 7 black, we obtain
prior P AA
ð
Þ ¼ 0:33
posterior P AAjy
ð
Þ ¼ 0:99
prior P Aa
ð
Þ ¼ 0:67
posterior P Aajy
ð
Þ ¼ 0:01
If ﬂat priors were used, we obtain
prior P AA
ð
Þ ¼ 0:50
posterior P AAjy
ð
Þ ¼ 0:99
prior P Aa
ð
Þ ¼ 0:50
posterior P Aajy
ð
Þ ¼ 0:01
In this case, the evidence provided by the data dominates over the prior information.
However, if the prior information is very accurate
prior P AA
ð
Þ ¼ 0:002
posterior P AAjy
ð
Þ ¼ 0:33
prior P Aa
ð
Þ ¼ 0:998
posterior P Aajy
ð
Þ ¼ 0:67
thus having even more data, prior information dominates the ﬁnal result when it is
very accurate, which should not normally be the case. In general, prior information
loses importance with larger samples. For example, if we have n uncorrelated data,
f θjy
ð
Þ / f yjθ
ð
Þf θ
ð Þ ¼ f y1; y2; . . . ; ynjθ
ð
Þf θ
ð Þ ¼ f y1jθ
ð
Þf y2jθ
ð
Þ . . . f ynjθ
ð
Þf θ
ð Þ
taking logarithms
log f θjy
ð
Þ / log f y1jθ
ð
Þ þ log f y2jθ
ð
Þ þ . . . þ log f ynjθ
ð
Þ þ log f θ
ð Þ
we can see that prior information has less and less importance as the amount of
data augments.
9.2
Vague Prior Information
9.2.1
A Vague Definition of Vague Prior Information
It is infrequent to ﬁnd exact prior information. Usually, there is prior information,
but it is not clear how to formalise it in order to describe this information using a
prior distribution. For example, if we are going to estimate the heritability of litter
size of a rabbit breed we know that this heritability has also been estimated in other
breeds, and it has often given values between 0.05 and 0.11. We have a case in
which the estimate was 0.30, but the standard error was high. We also have a high
198
9
Prior Information

realised heritability in an experiment that we have reasons for not taking it too
seriously. A high heritability was also presented in a Congress, but this paper did
not pass the usual peer review ﬁlter and we tend to give less credibility to these
results. Moreover, some of the experiments are performed in situations that are
more similar to our own experiment or with breeds that are closer to ours. It is
obvious that we have prior information, but how can we manage all of this?
One of the disappointments when arriving at Bayesian inference attracted by the
possibility of using prior information is that modern Bayesians tend to avoid the use
of prior information due to the difﬁculties of deﬁning it properly. A solution for
integrating all sources of prior knowledge in a clearly deﬁned prior information was
offered independently in the decade of the 1930s by the British philosopher Frank
Ramsey (1931) and by the Italian mathematician Bruno de Finetti (1937), but the
solution is unsatisfactory in many cases as we will see. They propose that what we
call probability is just a state of beliefs. This deﬁnition has the advantage of
including events like the probability of obtaining a 6 when throwing a dice and
the probability of Scotland becoming an independent republic in this decade. Of
course, in the ﬁrst case we have some mathematical rules that will determine our
beliefs and in the second we do not have these rules, but in both cases we can
express sensible beliefs about the events.
Transforming probability, which looks as an external concept to us, into beliefs,
which look like an arbitrary product of our daily mood, is a step that some scientists
refuse to walk. Nevertheless, there are three aspects to consider:
It should be clear that although beliefs are subjective, this does not mean that
they are arbitrary. Ideally, previous beliefs should be expressed by experts and
there should be a good agreement among experts on how prior information is
evaluated.
Prior beliefs should be vague and contain little information; otherwise, there is
no reason to perform the experiment in the ﬁrst place, as we have seen in Sect. 9.1.3.
In some cases, an experiment may be performed in order to add more accuracy to a
good previous estimation, but this is not normally the case.
When having enough data, prior information loses importance, and different
prior beliefs can give rise to the same result, as we have seen in Sect. 9.1.3.
There is another problem of a different nature. In the case of multivariate
analyses, it is almost impossible to determine a rational state of beliefs. For
example, suppose we are analysing heritabilities and genetic correlations of three
traits. How can we determine our beliefs about the heritability of the ﬁrst trait, when
the second trait has a heritability of 0.2, the correlation between both traits is 0.7,
the heritability of the third trait is 0.1, the correlation between the ﬁrst and the
third traits is 0.3 and the correlation between the second and the third trait is 0.4;
then our beliefs about the heritability of the ﬁrst trait when the heritability of the
second trait is 0.1, . . .etc.? Here we are unable to represent any state of beliefs, even
a vague one.
9.2
Vague Prior Information
199

9.2.2
Examples of the Use of Vague Prior Information
We can describe our prior information using many density functions, but it would
be convenient to propose a density that can be easily combined with the distribution
of the data, what we called a conjugate distribution in Chap. 5 (paragraph 5.3.3).
When we are comparing two means, as in the example in Sect. 5.3.3 of Chap. 5, it is
easy to understand how we can construct a prior density. We compare an a priori
expectation of obtaining a difference of 100 g of live weight between two
treatments for poultry growth. We believe that it is less probable to obtain 50 g,
than 150 g. We also believe that it is rather improbable to obtain 25 g, as improbable
as to obtain 175 g of difference between both treatments. We can draw a diagram
with our beliefs, representing the probabilities we give to these differences. These
beliefs are symmetrical around the most probable value, 100 g, and can be approxi-
mately represented by a Normal distribution. It is not important whether the
representation of our beliefs is very accurate or not, since it should be necessarily
vague; otherwise, we would not perform the experiment, as we have said before.
This is a simple example about how to construct prior beliefs. The reader can ﬁnd
friendly examples about how to construct prior beliefs for simpler problems in Press
(2002). However, it is generally difﬁcult to work with prior information in more
complex problems. To illustrate the difﬁculties of working with vague prior infor-
mation, we will show here two examples of attempts of constructing prior informa-
tion for the variance components in genetic analyses. In the ﬁrst attempt, Blasco
et al. (1998) tried to express the prior information about variance components for
ovulation rate in pigs. As the available information is on heritabilities, they consid-
ered that the phenotypic variance is estimated without error (in genetic experiments,
often performed with a large amount of data, this error is very small) and expressed
their beliefs about additive variances, just as if they were heritabilities.1 The error
variance priors were constructed according to these beliefs. Blasco et al. (1998)
used inverted gamma densities to express the uncertainty about the heritability of
one trait, because they are conjugated priors that can be easily combined with the
distribution of the data, as we have seen in Chap. 5 (Sect. 5.3.3). These functions
depend on two parameters that we have called been α and β in Sect. 3.5.4,
f xjα; β
ð
Þ /
1
xαþ1 exp β
x


The shape of the function changes when changing α and β; thus, the researcher
can try different values for these parameters until she ﬁnds a shape that agrees with
her beliefs. We will now see how Blasco et al. (1998) constructed their prior
densities using inverted chi-square distributions, which are the same as inverted
gamma but with a different parameterisation (Fig. 9.3).
1There are other alternatives, for example, thinking in standardised data to construct prior beliefs
for the additive variance.
200
9
Prior Information

Prior distributions for variance components were built on the basis of information from the
literature. For ovulation rate, most of the published research shows heritabilities of either
0.1 or 0.4, ranging from 0.1 to 0.6 (Blasco et al. 1993). Bidanel et al. (1992) reports an
estimate of heritability of 0.11 with a standard error of 0.02 in a French Large White
population. On the basis of this prior information for ovulation rate, and assuming [without
error] a phenotypic variance of 6.25 (Bidanel et al. 1996), three different sets of prior
distributions reﬂecting different states of knowledge were constructed for the variance
components. In this way, we can study how the use of different prior distributions affects
the conclusions from the experiment. The ﬁrst set is an attempt to ignore prior knowledge
about the additive variance for ovulation rate. This was approximated assuming a uniform
distribution, where the additive variance can take any positive value up to the assumed
value of the phenotypic variance, with equal probability. In set two, the prior distribution of
the additive variance is such that its most probable value is close to 2.5 [corresponding to a
heritability of 0.4], but the opinion about this value is rather vague. Thus, the approximate
prior distribution assigns similar probabilities to different values of the additive variance of
2.5. The last case is state three, which illustrates a situation where a stronger opinion about
the probable distribution of the additive variance is held, a priori, based on the fact that the
breed used in this experiment is the same as in Bidanel et al. (1992). The stronger prior
opinion is reﬂected in a smaller prior standard deviation. Priors describing states two and
three are scaled inverted chi-square distributions. The scaled inverted chi-square distribu-
tion has two parameters, v and S2. These parameters were varied on a trial and error basis
until the desired shape was obtained. Fig. 1 [Fig. 9.3 in this book] illustrates the three prior
densities for the additive variance for ovulation rate.
Blasco et al. (1998)
In the second example, Blasco et al. (2001) make an attempt of drawing prior
information on uterine capacity in rabbits. Here, phenotypic variances are consi-
dered to be estimated with error, and the authors argue about heritabilities using the
transformation that can be found in Sorensen and Gianola (2002).
0.2
Prior 2
Prior 1
Prior 3
0.4
0.6
0.8
1
heritability
Fig. 9.3 Prior densities
showing three different states
of belief about the heritability
of ovulation rate in French
Landrace pigs (from Blasco
et al. 1998)
9.2
Vague Prior Information
201

Attempts were made to choose prior distributions that represent the state of knowledge
available on uterine capacity up to the time the present experiment was initiated. This
knowledge is however extremely limited; the only available information about this trait has
been provided in rabbits by BOLET et al. (1994) and in mice by GION et al. (1990), who
report heritabilities of 0.05 and 0.08 respectively. . . Under this scenario of uncertain prior
information, we decided to consider three possible prior distributions. State 1 considers
proper uniform priors for all variance components. The (open) bounds assumed for the
additive variance, the permanent environmental variance and the residual variance were
(0.0, 2.0), (0.0, 0.7) and (0.0, 10.0), respectively. Uniform priors are used for two reasons:
as an attempt to show prior indifference about the values of the parameters, and to use them
as approximate reference priors in Bayesian analyses. In states 2 and 3, we have assumed
scaled inverse chi-square distributions for the variance components, as proposed by
SORENSEN et al. (1994). The scaled inverse chi-square distribution has 2 parameters, ν
and S2, which deﬁne the shape. In state 2, we assigned the following values to these two
parameters: (6.5, 1.8), (6.5, 0.9) and (30.0, 6.3) for the additive genetic, permanent
environmental and residual variance, respectively. In state 3, the corresponding values of
ν and S2 were (6.5, 0.3), (6.5, 0.2) and (20.0, 10.0). The implied, assumed mean value
for the heritability and repeatability under these priors, . . .[Sorensen and Gianola 2002],
is 0.15 and 0.21, respectively for state 1, 0.48 and 0.72 for state 2, and 0.08 and 0.16 for
state 3.
Blasco et al. (2001)
These are particularly complex examples of constructing prior beliefs, but there
are cases in which it is not feasible to construct prior opinions. In particular, in the
multivariate case, comparisons between several priors should be made with caution.
We often ﬁnd authors who express their multivariate beliefs as inverted Wishart
distributions (the multivariate version of the inverted gamma distributions), chang-
ing the hyper-parameters arbitrarily and saying that ‘since results almost do not
change, this means that we have enough data, and that prior information does not
affect the results’. If we do not know the amount of information we are introducing
when changing priors, then this is nonsense, because we can always ﬁnd a multi-
variate prior sharp enough to dominate the results. There is no clear solution for this
problem. Blasco et al. (2003) use priors considering that, in the univariate case, the
parameter S2 is frequently used to represent the variability of the density distribu-
tion. They generalise to the multivariate case, and take the corresponding parameter
in the Wishart distribution, as similar to a matrix of (co)variances:
We can then compare the two possible states of opinion, and study how the use of the
different prior distributions affects the conclusions from the experiment. We ﬁrst used ﬂat
priors (with limits that guarantee the property of the distribution) for two reasons: to show
indifference about their value and to use them as reference priors, since they are usual in
Bayesian analyses. Since prior opinions are difﬁcult to draw in the multivariate case, we
chose the second prior by substituting a (co)variance matrix of the components in the hyper
parameters SR and SG and using nR ¼ nG ¼ 3, as proposed by Gelman et al. (1995) in order
to have a vague prior information. These last priors are based on the idea that S is a scale-
parameter of the inverted Wishart function, thus using for SR and SG prior covariance
202
9
Prior Information

matrixes with a low value for n, would be a way of expressing prior uncertainty. We
proposed SR and SG from phenotypic covariances obtained from the data of Blasco and
Go´mez (1993).
Blasco et al. (2003)
The reader probably feels that we are far from the beauty initially proposed by
the Bayesian paradigm, in which prior information was integrated with the infor-
mation of the experiment to better assess the current knowledge. Therefore, the
reader should not be surprised when learning that modern Bayesian statisticians
tend to avoid vague prior information, or to use it only as a tool with no particular
meaning. As Bernardo and Smith (1994) say:
The problem of characterizing a ‘non-informative’ or ‘objective’ prior distribution,
representing ‘prior ignorance’, ‘vague prior knowledge’ and ‘letting the data speak for
themselves’ is far more complex that the apparent intuitive immediacy of these words
would suggest. . . ‘vague’ is itself much too vague idea to be useful. There is no “objective”
prior that represents ignorance. . . the reference prior component of the analysis is simply a
mathematical tool.
Bernardo and Smith (1994)
The advantage of using this ‘mathematical tool’ is not anymore the possibility of
introducing prior information in the analysis, but the possibility of still working
with probabilities, with all the advantages that we have seen in Chap. 2 (multiple
conﬁdence intervals, marginalisation, etc.).
9.3
No Prior Information
It sounds quite unrealistic, the assumption of having no prior information. We can
have rather vague prior information, but in Biology it is difﬁcult to sustain that we
have complete lack of information. We can say that we have no information about
the average height of the Scottish people, but we know at least that they are humans;
thus, it is very improbable that their average height is higher than 2 m or lower than
1.5 m. It is also improbable, but less improbable, that their average height is higher
than 1.9 m or lower than 1.6 m. We can construct a vague state of beliefs as before,
only based in our vague information about how humans are. Later, as we have seen,
this vague state of beliefs will not affect our results unless our sample is very small.
However, even in this case, we can be interested in knowing which results we
would obtain if we had no prior information at all; i.e. how would the results look
like if they were based only in our data. The problem is not as easy as it appears, and
several methods to deal with the no-information cases have been proposed. We will
only examine some of them, since using vague prior information will be enough for
most of the problems we have in Biology or Agriculture.
9.3
No Prior Information
203

9.3.1
Flat Priors
As we said in Chap. 2 (Sect. 2.1.3), we can try to represent ignorance as synony-
mous of indifference and say that all possible values of the parameters to be
estimated were equally probable before performing the experiment.2
Since the origins of Bayesian inference (Laplace 1774) and during its develop-
ment in the nineteenth century, Bayesian inference was always performed under the
supposition that prior ignorance was well represented by ﬂat priors.3 Laplace
himself, Gauss, Pearson and others suspected that ﬂat priors did not represent
prior ignorance and moved on to examine the properties of the sampling distribu-
tion. Including actual prior information in the inferences, instead of using ﬂat
priors, was not proposed until the work of Ramsay and de Finetti, quoted before.
It is quite easy to see why ﬂat priors cannot represent ignorance: Suppose we
believe that we do not have any prior information about the heritability of a trait.
If we represent this using a ﬂat prior (Fig. 9.4), the event A ‘the heritability is lower
than 0.5’ has a probability of 50% (blue area). Take now the event B ‘the square of
the heritability is lower than 0.25’. This is exactly the same event4 as event A; thus,
its probability should be the same, also a 50%.
We are just as ignorant about h4 as about h2; thus, if ﬂat priors represent
ignorance, we should also represent the ignorance about h4 with ﬂat priors. How-
ever, if we do this, and we also maintain that P(h4 < 0.25) ¼ 50%, we arrive to an
absurd conclusion: we do not know anything about h2, but we know that h4 is closer
to zero than h2.
To avoid this absurd conclusion, we have to admit that ﬂat priors do not
represent ignorance, but they are informative. The problem is that we do not
know what this prior information really means. However, this information is very
vague and should not cause problems; in most cases that data will dominate and the
Event A ิ h2 < 0.5   
Event B ิ h4 < 0.25  
P(B) = ½    
P(A) = ½   
Uninformative??  
Informative!!  
f(h2)
0
0.5
1
Fig. 9.4 Flat priors are
informative
2Bernard Bosanquet, a nineteenthth-century British logician, quotes a play of Richard Sheridan to
illustrate the principle of indifference, which Bosanquet considers a sophism:
ABSOLUTE—Sure, Sir, this is not very reasonable, to summon my affection for a lady I know
nothing of.
SIR ANTHONY—I am sure, Sir, it is more unreasonable in you to object to a lady you know
nothing of.
3This was known as the “principle of insufﬁcient reason”. Later, the economist J.M. Keynes
named it as “principle of indifference” (Keynes 1921).
4If the reader does not like squares, take half of the heritability or other transformation.
204
9
Prior Information

results will not be practically affected by the prior. Nevertheless, it is a bad practice
to deﬁne ﬂat priors as ‘non-informative priors’.
9.3.2
Jeffreys Prior
Ideally, the estimate of a parameter should be invariant to transformations. It is
somewhat inconvenient having an estimate of the standard deviation (e.g. the mean
of the marginal posterior distribution of the standard deviation) and an estimate of
the variance (e.g. the mean of the marginal posterior distribution of the variance)
and ﬁnd that one it is not the square of the other. It is quite common that the good
properties of estimations are not conserved when transforming the parameter; for
example, take an unbiased least square estimator of a parameter θ; the square root of
θ is a biased estimator, and it is not a ‘least square’ estimator anymore. In the case of
representing prior information, we would like that our prior information was
conserved after transformations; i.e. if we represent vague information about the
standard deviation, we would like the information of the variance to be equally
vague. For example, if the prior information on the standard deviation is
represented by f(σ), the prior information of the variance should be, according to
the transformation rule we exposed in Sect. 3.3.2,
f σ2


¼ f σ
ð Þ dσ2
dσ


1
¼ f σ
ð Þ 2σ
ð
Þ1 ¼ 1
2σ f σ
ð Þ
Harold Jeffreys proposed to use priors that were invariant to transformations, so
that if f(θ) is a Jeffreys prior for θ, then [ f(θ)]2 should be a prior for θ2. For example,
the Jeffreys prior for the standard deviation is
Jeffreys prior f σ
ð Þ / 1
σ
Then, the prior for the variance would be:
f σ2


¼ 1
2σ f σ
ð Þ / 1
2σ  1
σ / 1
σ2
which is the square of the Jeffreys prior for the standard deviation.
The Jeffreys prior of a parameter θ is:
Jeffreys prior f θ
ð Þ /
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Ey
∂log f yjθ
ð
Þ
∂θ

2
s
For example, the Jeffreys prior of the variance is
9.3
No Prior Information
205

f σ2


/
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Ey
∂log f yjσ2
ð
Þ
∂σ2

2
s
/ 1
σ2
The deduction of this prior is in Appendix 9.1. In Appendix 9.2, we show that
these priors are invariant to transformations.
Jeffreys priors are widely used in univariate problems, but they lead to some
paradoxes in multivariate problems.
9.3.3
Bernardo’s ‘Reference’ Priors
If we do not have prior information and we know that all priors are informative, a
sensible solution may be to use priors with minimum information. Bernardo (1979)
proposed to calculate posterior distributions in which the amount of information
provided by the prior is minimal. These priors have the great advantage of being
invariant to reparametrisation.
To build these posterior densities we need:
1. To use some deﬁnition of information. Bernardo proposes the deﬁnition of
Shanon (1948), which we will see in Chap. 10.
2. To deﬁne the amount of information provided by an experiment: this is deﬁned
as the distance between the prior and the posterior information, averaging for all
possible samples.
3. To use some deﬁnition of distance between distributions. Bernardo uses the
Kullback’s divergence between distributions, which is based on Bayesian
arguments. We will see Kullback’s divergence in Chap. 10.
4. To ﬁnd a technically feasible way for solving the problem and deriving the
posterior distributions. This is technically complex, and reference priors are not
easy to derive.
In the multivariate case, we should transform the multivariate problem in
univariate ones taking into account the parameters that are not of interest. This
should be made, for technical reasons, conditionalising the other parameters in
some order. The problem is that the reference prior obtained differs depending on
the order of conditionalisation. This is somewhat uncomfortable, since it would
oblige the scientist to consider several orders of conditionalisation to see how the
results differ, a procedure feasible with few parameters, but not in cases in which
the problems are highly parametrised. For the latter cases, the strategy would be to
use sensible vague informative priors when possible or to nest the problems as we
have seen in Chap. 8, when parameters of growth curves were under environmental
and genetic effects that were distributed Normally with known variances deﬁned
206
9
Prior Information

using conjugated priors with some hyper-parameters. Reference priors would be
calculated only in the last step.
Bernardo’s reference priors are out of the scope of this book. However, Jose´-Miguel
Bernardo has developed in Valencia University a promising area in which the same
‘reference’ idea has been applied to hypothesis tests, credibility intervals and other
areas, creating a ‘reference analysis’ (Bernardo 2005).
9.4
Improper Priors
Some priors are not densities, for example: f(θ) ¼ k, where k is an arbitrary constant;
it is not a density because Rf(θ)dθ ¼ 1. However, improper priors lead to proper
posterior densities when
f y
ð Þ ¼
Z
f yjθ
ð
Þf θ
ð Þdθ < 1
Sometimes they are innocuous and they are not used in the inference, for
example, for one single data
f y
ð Þ  N μ; 1
ð
Þ
f μ
ð Þ ¼ k
f y
ð Þ ¼
R
f yjμ
ð
Þf μ
ð Þdμ ¼
R
f yjμ
ð
Þ  k  dμ ¼ k 
R
f yjμ
ð
Þ  dμ ¼
¼ k R
1ﬃﬃﬃﬃﬃ
2π
p
exp  y  μ
ð
Þ2
2
"
#
dμ ¼ k
Z
1ﬃﬃﬃﬃﬃ
2π
p
exp  μ  y
ð
Þ2
2
"
#
dμ ¼ k
f μjy
ð
Þ ¼ f yjμ
ð
Þf μ
ð Þ
f y
ð Þ
¼ f yjμ
ð
Þ  k
k
¼ f yjμ
ð
Þ
Thus, in this case the posterior density of μ does not take into account the prior.
In general, it is recommended to always use proper priors, to be sure that we
obtain proper posterior densities. When using Gibbs sampling, some densities look
as proper ones, but they may be improper. Although when using MCMC all
densities are, in practice, ‘proper’ ones (we never sample in the inﬁnite); samples
can have very long burning periods and can lead to chains that only apparently have
converged. The recommendation is to use proper priors (bounded priors with
reasonable limits, for example), unless it has been proved that they are innocuous
(Hobert and Casella 1996).
9.4
Improper Priors
207

9.5
The Achilles Heel of Bayesian Inference
Bayesian inference, or Inverse probability, as it was called before, is extremely
attractive because of the use of probabilities and the possibility of integrating prior
information. However, integrating prior information is much more difﬁcult than the
optimistic Bayesians of the ﬁfties thought. We have put an example in which actual
prior information was used, and there are some ﬁelds of knowledge in which
integrating prior information has had success (see McGrayne 2011 for an excellent
and entertaining history lesson of this ‘proper’ Bayesian inference). However, in the
biological and agricultural ﬁelds, in which the model used often has many
parameters to be estimated, and multivariate procedures are frequent, integrating
prior information has been showed to be a challenge beyond the possibilities of the
average researcher. This situation has led to the use of several artefacts, substituting
the proper ‘prior information’ in order to make possible the use of probability.
Some statisticians think that an artefact multiplied by a probability will give an
artefact and not a probability, and consequently, they are reluctant to use Bayesian
inference. There is not a deﬁnitive answer to this problem, and it is a matter of
opinion to use Bayesian or frequentist statistics; both are now widely used and no
paper will be refused by a publisher because it uses one type of statistics or the
other.
Many users of statistics, like the author of this book, are not ‘Bayesians’ or
‘frequentists’ but just people with problems. Statistics is a tool for helping solving
these problems, and users are more interested in the availability of easy solutions
and friendly software than in the background philosophy. I use Bayesian statistics
because I understand probability better than signiﬁcance levels and because it
permits to me to express my results in a clearer way for later discussion. Some
other users prefer Bayesian statistics because there is a route for solving their
problems: make a joint posterior distribution, ﬁnd the conditionals and use
MCMC to ﬁnd the marginal distributions. We behave as if we were working with
real probabilities. This should not be objected by frequentists, who behave as if
their alternative hypothesis was true or their conﬁdence interval contained the true
value. We have seen in Chap. 1 that Neyman and Pearson (1933) justiﬁed
frequentist statistics on the grounds of the right scientiﬁc behaviour. Behaving as
if the probabilities found using ‘innocent priors’ were true probabilities does not
seem to be dangerous, since very little prior information is introduced in the
inference. To acknowledge the true probabilities drives us to the Problem of
Induction, a very difﬁcult problem out of the scope of this book. The Appendix
‘Three new dialogues between Hylas and Filonus’ tries to expose this problem in a
literary form. Virgil, in an agrarian context, exposed our wish for having certainty.
He said.
‘Felix qui potuit rerum cognoscere causas’ (Happy the man that can know the causes of the
things!).
Virgil, Egloga IX, 63
208
9
Prior Information

Appendix 9.1
f σ2


/
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I σ2jy
ð
Þ
p
¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Ey
∂log f yjσ2
ð
Þ
∂σ2

2
s
f yjσ2


¼
1
ﬃﬃﬃﬃﬃ
2π
p

n σ2
ð
Þ
n
2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775
log f yjσ2


¼ k  n
2 logσ2 
P yi  μ
ð
Þ2
2σ2
∂log f yjσ2
ð
Þ
∂σ2
¼  n
2σ2 þ
P yi  μ
ð
Þ2
2 σ2
ð
Þ2
∂2log f yjσ2
ð
Þ
∂σ2
ð
Þ2
¼
n
2 σ2
ð
Þ2  2 P yi  μ
ð
Þ2
2 σ2
ð
Þ3
Ey
∂log f yjσ2
ð
Þ
∂σ2

2
¼ Ey
 ∂2log f yjσ2
ð
Þ
∂σ2
ð
Þ2
 
!
¼ 
n
2 σ2
ð
Þ2 þ
Ey
P yi  μ
ð
Þ2
h
i
σ2
ð
Þ3
Ey
X
n
1
yi  μ
ð
Þ2
"
#
¼ nEy yi  μ
ð
Þ2 ¼ nσ2
Ey
∂log f yjσ2
ð
Þ
∂σ2

2
¼ 
n
2 σ2
ð
Þ2 þ nσ2
σ2
ð
Þ3 ¼ 
n
2 σ2
ð
Þ2 þ
n
σ2
ð
Þ2 ¼
1
σ2
ð
Þ2
n
2

 
/
1
σ2
ð
Þ2
f σ2


/
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I σ2jy
ð
Þ
p
¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
Ey
∂log f yjσ2
ð
Þ
∂σ2

2
s
/
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
1
σ2
ð
Þ2
s
/ 1
σ2
Appendix 9.1
209

Appendix 9.2
If λ ¼ g θ
ð Þ
I λjy
ð
Þ ¼ Ey
∂log f yjλ
ð
Þ
∂λ

2
¼ Ey
∂log f yjg θ
ð Þ
ð
Þ
∂θ
 ∂θ
∂λ

2
¼
∂θ
∂λ

2
Ey
∂log f yjg θ
ð Þ
ð
Þ
∂θ

2
¼
¼
∂θ
∂λ

2
I θjy
ð
Þ
f θ
ð Þ /
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I θjy
ð
Þ
p
f λ
ð Þ /
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I θjy
ð
Þ
p
 ∂θ
∂λ

 ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I θjy
ð
Þ  ∂θ
∂λ


2
s
¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
I λjy
ð
Þ
p
References
Bernardo JM (1979) Reference posterior distributions for Bayesian inference. J R Stat Soc B 41:
113–147
Bernardo JM (2005) Reference analysis. In: Dey DK, Rao CR (eds) Handbook of statistics, vol 25.
Elsevier, Amsterdam, pp 17–90
Bernardo JM, Smith FM (1994) Bayesian theory. Wiley, Chichester
Bidanel JP, Ducos A, Groeneveld E, Gruand J, Lagant H (1992) Genetic variability of components
of litter size in French Large White gilts. 43rd annual meeting of the European Association for
Animal Production, Madrid, September 1992
Bidanel JP, Blasco A, Gogue J, Lagant H (1996) Re´sultats de quatre ge´ne´rations de se´lection pour
le taux d’ovulation et la survie pre´natale chez des porcs de race Large White. Journe´es Rech
Porcine en France. 28:1–8. Janvier 1996. Paris
Blasco A, Go´mez E (1993) A note on growth curves of rabbit lines selected on growth rate or litter
size. Anim Prod 57:332–334
Blasco A, Santacreu MA, Thompson R, Haley C (1993) Estimates of genetic parameters for
ovulation rate, prenatal survival and litter size in rabbits from an elliptical selection experi-
ment. Livestock Prod Sci 34:163–174
Blasco A, Sorensen D, Bidanel JP (1998) A Bayesian analysis of genetic parameters and
selection response for litter size components in pigs. Genetics 149:301–306
Blasco A, Argente MJ, Santacreu MA, Sorensen D, Bidanel JP (2001) Bayesian analysis of
response to selection for uterine capacity in rabbits. J Anim Breed Genet 118:93–100
Blasco A, Piles M, Varona L (2003) A Bayesian analysis of the effect of selection for growth rate on
growth curves in rabbits. Genet Sel Evol 35:21–42
Bolet G, Santacreu MA, Argente MJ, Climent A, Blasco A (1994) Divergent selection for uterine
efﬁciency in unilaterally ovariectomized rabbits. I. Phenotypic and genetic parameters. Proc.
5th World Congress on Genetics Applied to Livestock Production, Guelph, 1994, vol 19,
pp 261–264
210
9
Prior Information

de Finetti B (1937) La pre´vision: ses lois logiques, ses sources subjectives. Annales de l’Institut
Henri Poincaire´ 7:1–68. Translated in Kyburg HE, Smokler HE (1964) Studies in subjective
probability. Wiley, New York
Fisher R (1959) Statistical methods and scientiﬁc inference, 2nd edn. Oliver and Boyd, Edinburgh
Gelman A, Carlin J, Stern HS, Rubin DB (1995) Bayesian data analysis. Chapman and Hall,
London
Gion JM, Clutter AC, Nielsen MK (1990) Alternative methods of selection for litter size in mice: II
response to thirteen generations of selection. J Anim Sci 68:3543–3556
Hobert JP, Casella G (1996) The effect of improper priors on Gibbs sampling in hierarchical linear
mixed models. J Am Stat Assoc 436:1461–1473
Keynes JM (1921) A treatise on probability. Macmillan Publ. Co, London
Laplace PS (1774/1986) Memoir on the probabilities of the causes of events (Trad. by Stigler SM).
Stat Sci 1:364–378
McGrayne SB (2011) The theory that would not die. Yale University Press, New Haven, NJ
Neyman J, Pearson E (1933) On the problem of the most efﬁcient test of statistical hypotheses.
Phil Trans R Soc 231A:289–337
Pearson E (1962) Some thoughts on statistical inference. Ann Math Stat 33:394–403
Press SJ (2002) Subjective and objective Bayesian statistics: principles, models, and applications.
Wiley, New York
Ramsey FP (1931) Truth and probability. In: Braithwaite RB (ed) The foundation of mathematics and
other logical essays. Routledge & Kegan, London
Shanon CE (1948) A mathematical theory of communication. Bell Syst Tech J 27(379–423):
623–656
Sorensen DA, Gianola D (2002) Likelihood, Bayesian and MCMC methods in quantitative genetics.
Springer, New York
Sorensen DA, Wang CS, Jensen J, Gianola D (1994) Bayesian analysis of genetic change due to
selection using Gibbs sampling. Genet Sel Evol 26:333–360
References
211

Model Selection
10
If a particular model does not make biological sense, this is
reason to exclude it from the set of candidate models.
K.P. Burnham and D.V. Anderson, 2002
Model selection and multimodel inference
In Chaps. 6 and 7, before making inferences about parameters of interest
(e.g. before comparing treatments), we wrote a model containing ‘noise’ effects
and effects of interest and we described which was the prior information of these
effects, or in a frequentist context whether they were ‘ﬁxed’ or ‘random’. We have
assumed we know the right model without discussing whether there was a more
appropriate model for our inferences. We can think that a better model could have
been used to get better inferences. We can also think that we have underestimated
our uncertainty, since we have some uncertainty about which is the best model for
our inferences. The ﬁrst problem is the goal of this chapter: how to choose the best
model. The second problem has a difﬁcult solution, since we cannot take into
account all possible models to describe a natural phenomenon.
10.1
Model Selection
10.1.1 The Purpose of Model Selection
We have brieﬂy considered in Chap. 2, Sect. 2.3.3, how, in a Bayesian context, we
can sometimes perform multimodel inference by model averaging, considering
several models and their probabilities, but even in such case we are preselecting
which models will be considered.
Let us put an example. We assume that our data are distributed according to
some distribution (Normal, Poisson, Gamma, etc.) depending on some set of
parameters θ. For example, in Chap. 6, Sect. 6.1, we assumed that our data were
Normally distributed
# Springer International Publishing AG 2017
A. Blasco, Bayesian Data Analysis for Animal Scientists,
DOI 10.1007/978-3-319-54274-4_10
213

y j b, σ2
e e N Xb; Iσ2
e


This is our model. Our purpose in the example we put in Sect. 6.1 was to estimate
the parameters b and σ2
e, where b contained the effects of a treatment and some
‘noise’ effects. However, our purpose may be to determine whether data are better
ﬁtted if we use a different distribution. For example, in Fig. 10.1 we have a
histogram of data of food conversion rate in rabbits. We can try to ﬁt these data
to a Normal distribution y ~ N(μ, σ2) or, as it does not seem to be Normal, to another
distribution, for example an inverted gamma that we have seen in Chap. 5, Sect.
5.2.1, y ~ IG(α, β)
In this case, we have Model 1 with probability density function f1( y) ~ N(μ, σ2)
and Model 2 with probability density function f2( y) ~ IG(α, β). Both models have
different probability density functions and different parameters to ﬁt.
When constructing a model, we should determine ﬁrst how the data are
distributed, given all the unknowns. For example, if we have three diets and we
examine the growth of chicken at commercial weight, we can obtain a Normal
distribution for growth for each diet (Fig. 10.2). This is why we examine the
conditional density function given the unknowns, because in this case, only the
residual varies and we get a single Normal distribution.
In animal production, we can often say that the residuals (i.e. the data, given the
unknowns) are Normally distributed. Even when they are not, we strongly recom-
mend using Normal distributions unless the distribution of the data, given the
unknowns, is far from Normal. The estimation of the parameters is quite robust to
the lack of Normality, particularly for comparisons between treatments, as we will
discuss in Sect. 10.1.3. The Normal distribution has several good properties, and
many software programs are written assuming Normality of the data given the
unknowns. Residuals contain all the effects that act on a trait and are not included in
the model. In animal production, usually residuals depend on many independent
factors with small effects on each one; thus, we can appeal to the Central Limit
0
1
2
3
4
5
Fig. 10.1 Data of food conversion rate in rabbits, with a Normal distribution (in blue) superposed
214
10
Model Selection

Theorem and claim that the residuals are Normally distributed.1 The common
alternative is transforming the data, but biological interpretation in transformed
scales is often difﬁcult, and transformation cannot be done backwards for the
inferences we are interested in. For example, if we are estimating a heritability
and we transform the data taking logarithms, the meaning of h2 is not clear in the
transformed scale; i.e. it is not clear which is the relationship with this heritability
and the expected response to selection; thus, it loses its applicability. Moreover, the
s.e. (or the features of the marginal posterior density) cannot be transformed
backwards; i.e. the s.e. of the heritability is not the antilogarithm of the s.e. of
log (h2). Therefore, transformations should be avoided when possible.
Models have several parameters to be estimated. Part of these parameters are
treatments in which we are genuinely interested, and part of them are ‘noise’ effects
which we would like to be rid of. In the example of Sect. 6.1, our model was
y ¼ μ þ T þ P þ β  LS þ e
where
y: one record of commercial weight of a rabbit
T: treatment ﬁxed effect
-6
-4
-2
0
2
4
6
0.0
0.1
0.2
0.3
0.4
0.5
Fig. 10.2 Distribution of growth rate with three different treatments
1This theorem can be applied in a large variety of circumstances, for example, when the
distributions of the factors are different. The demonstration is complex, and it is out of the
scope of this book.
10.1
Model Selection
215

P: parity ﬁxed effect
LS: litter size in which the rabbit was born (covariate)
β: regression coefﬁcient of the covariate
e: random residual effect
We are interested in the treatment effect, but not in the parity effect or in the
litter size effect. We would like to have had all animals in the same parity and with
the same litter effect, but in the usual conditions of animal production experiments,
this is not possible; thus, we need to ‘correct’ for these effects by including them in
the model. Parity and litter size are called ‘noise’.
A common problem of model selection is to consider whether the data are
affected by some noise effects or not. For example, the parity effect might be
irrelevant and can be removed from the model. It is a frequent practice checking
whether the effects in a model are signiﬁcant or not, based in an F or a t-test, and
remove the effects that are non-signiﬁcant. This is strictly incorrect and should be
avoided. We have seen in Chap. 1, Fig. 1.5, that signiﬁcance is associated with
sample size; thus, by removing non-signiﬁcant effects we can remove effects that
can be substantial although non-signiﬁcant or retain irrelevant signiﬁcant effects.
We have several simple solutions to this problem:
1. We can retain the noise effects independently of whether they are signiﬁcant
or not. For example, when we are estimating carcass lean content in chicken at a
determined age, we can consider that, even if there is no sex effect at this age, we
would like our sample to be corrected so that our average of males and females is
the same. This reduces the residual variance increasing the precision, but at the
same time, as we are estimating more effects, we lose degrees of freedom and
decrease the precision. If we have few data including many effects in the model,
this strategy would not be recommendable, but when having large samples, we
can think of including all biologically sensible effects independently of whether
they are signiﬁcant or not. We can do exploratory analyses to see how the model
behaves, i.e. what we obtain, adding or removing effects, but we should be
careful because we have the risk of adapting the model to our particular sample;
thus, we can ‘overﬁt’ the data. The best simple solution, having enough data, is
to keep the effects biologically sensible.
2. We can estimate the probability of the noise effects being higher or lower
than zero; for example, P(Male effect) > 0 and P(Male effect) < 0, and P
(Female effect) > 0 and P(Female effect) < 0. If these probabilities are very
low, we can consider removing the sex effect.
3. We can estimate the probability of similitude (Chap. 2, Sect. 2.2.2) for
deciding whether a noise effect should be retained. We estimate whether the
noise effects are higher or lower than a relevant value. If the probability of
similitude is high, the effects are zero for practical purposes and can be removed.
We recommend solution 1 when we have enough data. Solutions 2 and 3 cannot
be always applied. For example, when we have year-season effects in dairy cattle,
we have a huge amount of levels; it is not practical to examine them one by one.
Even if we do that, by chance we will ﬁnd some of the levels to be relevant. In these
216
10
Model Selection

cases, we can consider solution 1, or alternatively we can consider model selection
criteria as the ones we will see in Sect. 10.4.
A simple example of model selection is to choose between Model 1 and Model
2 in the following example:
Model 1
y ¼ μ þ T þ β  LS þ e
Model 2
y ¼ μ þ T þ P þ β  LS þ e
we say that Model 1 is nested to Model 2 because all effects of Model 1 are included
in Model 2, and their probability density function is the same. We have considered
here that they only differ in one effect, but Model 2 could have more different
effects from Model 1.
We can use a frequentist technique for model selection and compare their
likelihoods using a likelihood ratio test. We can also use Bayesian techniques
comparing the probability of both models, or we can use criteria based on the
amount of information that the models provide. We will examine all these
possibilities below.
Notice that if we chose Model 1 we are not saying that there is no parity effect.
What we are saying is that our data are compatible with the absence of a parity
effect. It is important to have this in mind, because if we have few data, our data can
be compatible with almost every model.
10.1.2 Fitting Data vs Predicting New Records
The most frequent situation in biological problems is to perform an experiment
expecting that new records will behave just as the records used to ﬁt the data. Thus,
by ﬁtting a model we expect to predict the behaviour of new data. When we decide
that a diet is better than other diets, we expect that this will be repeated when being
applied to other animals different from our sample. However, we have the risk of
overﬁtting the data so that they adjust very well to our sample, but do not, however,
have good predictive capacity. We will put an example.
We would like to ﬁnd a model explaining the growth of some deer we keep in a
natural park. We have the data of a deer represented in Fig. 10.3a (if you are not
happy with a single deer, you can think these points are the average of several deer;
it does not matter for the example). We ﬁt a straight line (Fig. 10.3b), and we ﬁnd
that the coefﬁcient of determination of the model is R2 ¼ 0.95. As this looks
unsatisfactory, we ﬁt a quadratic model (Fig. 10.3c) and obtain R2 ¼ 0.98. We think
that a cubic model will ﬁt better, and when we ﬁt it (Fig. 10.3d), we ﬁnd R2 ¼ 0.99.
We can add more and more parameters until obtaining a perfect ﬁt (Fig 10.3e), but
this is ad hoc to our data, so if we take weights from other deer we will have another
polynomial (Fig. 10.3f), and our good ﬁt will be useless to predict new data.
10.1
Model Selection
217

This shows the dilemma between ﬁtting well the data and obtaining new
predictions. Some of the criteria we will later see penalise models according to
their number of parameters, so that not always the most parameterised model is
selected. This is not a heuristic (i.e. practical) decision, but the result of applying the
logic used to derive the criteria, for example, criteria based on information, as we
will see below.
10.1.3 Common Misinterpretations
The data should be Normally distributed. If they are not, we should transform
the data to obtain a Normal distribution. As we said in Chap. 1, when comparing
50
40
30
20
10
0
0
10
20
30
40
Time
Time
weight
50
40
30
20
10
0
0
10
20
30
40
Time
Weight
R2 = 1
50
40
30
20
10
0
0
10
20
30
40
Time
Weight
Y= b0 + b1x+b2x2
R2 = 0.98
R2 = 0.95
50
40
30
20
10
0
0
10
20
30
40
Time
Weight
R2 = 1
50
40
30
20
10
0
0
10
20
30
40
Weight
Y= b0 + b1x
50
40
30
20
10
0
0
10
20
30
40
Time
Weight
R2 = 0.99
Y= b0 + b1x+b2x2 + b3x3
a
b
c
d
e
f
Fig. 10.3 Different adjustments to growth data. (a) Growth data. (b) Linear adjustment. (c)
Quadratic adjustment. (d) Cubic adjustment. (e) Full adjustment. (f) New data showing a different
full adjustment
218
10
Model Selection

treatments, if we have enough data,2 the distribution of the mean when repeating the
experiment many times is Normal, even if the data are not Normally distributed.3
For example, the distribution of the number of dead piglets at birth in Iberian pig is
clearly non-Normal (Fig. 10.4).
We will take several samples and see how the mean of these samples is
distributed. If we have 100 parities, we compute the average of dead piglets and
we obtain 1.8 piglets. We repeat the experiment and we obtain an average of 0.9; we
repeat and obtain 2.1. All these averages, when repeating the experiment many
times, are Normally distributed although the row data, the number of dead piglets, is
not. Notice that if our sample is very small and, instead of 100 parities, we only
have 1 parity, when repeating the experiment we will reproduce Fig. 10.3, and if we
have few parities per sample, the average may also be non-Normal when repeating
the experiment.
When the simplest model is selected, this indicates that the effects contained
in more complex models are zero. This is incorrect. We can never state that an
effect is exactly zero (i.e. 0.000000. . .); what we can state is that our data are
compatible with the absence of some effects. Notice that when having few data this
may happen often.
A non-signiﬁcant effect should be removed from the model. Signiﬁcance
directly depends on sample size. Even in a well-designed experiment, we are only
linking signiﬁcance with relevance for the treatment effect of one trait (see Chap. 1,
0
0.0
0.2
0.4
0.6
1
2
3
4
5
6
7
8
9
10
11
12
Fig. 10.4 Distribution of the
number of dead piglets at
birth in Iberian pig
2For animal production data, this may be more than 10 or 15 data per treatment, depending on the
variability of the trait.
3This depends, of course, on how far away the data are from Normality and how disperse is the
population, i.e. how large is its variance. However, in animal production and in many biological
problems, the means of the treatments to be compared can be safely assumed to be Normally
distributed even when the data are not.
10.1
Model Selection
219

Sect. 1.2.2). Since non-signiﬁcant effects can be relevant and signiﬁcant ones can
be irrelevant, signiﬁcance should be a criterion for removing effects from a model.
The simplest models should be preferred. Parsimony is attractive because it
often helps in understanding the results, and it also has some aesthetic appeal. The
thirteenth-century philosopher William of Ockham proposed to remove all
hypotheses that were not needed for explaining a phenomenon. In the twentieth
century, Karl Popper supported parsimonious models because they are less ‘ad hoc’
for explaining natural phenomena and can be refuted easily if they are incorrect.4
We can see in Fig. 10.3 that the best models for ﬁtting the data are too ‘ad hoc’, but
we can also see that the simplest models do not ﬁt the data well. However,
parsimony cannot be a criterion itself. We will later see that some model criteria
penalise models with too many parameters (i.e. too ‘ad hoc’), but simplicity derives
from the rationale of the criteria applied. These criteria can be the ability of a model
for predicting new data, the probability of a model of being better than the others,
etc., as we will see later. Parsimony can be a by-product of the criteria used for
model selection. The reader interested in this topic can consult a recent book on
parsimony of the philosopher of science Elliot Sober that includes a long discussion
about parsimony in model selection (Sober 2016).
The coefﬁcient of determination R2 is a good criterion for model selection.
Stepwise regression is an efﬁcient model selection practice. This criterion, the
R2, is not generally recommended independently of whether we are using only
regression or more complex models. The coefﬁcient of determination is
R2 ¼ 1  σ2
e
σ2
y
where σ2
e is the variance of the residuals of the model andσ2
y the variance of the data.
When R2 is high, the model explains the data well, since all the factors inﬂuencing the
data contained in the residual contribute in a small proportion to the variability
observed. However, R2 can be relatively high in cases in which the model is not
well ﬁtted, for example, when scale effects make some data more variable than others.
An extreme example is growth curves, as we have seen in Chap. 8, Sect. 8.1.1; the
adult weight of an animal is much higher than the initial weights; thus, residuals are
higher at the end of the curve and R2 depends much more on the last data. In the case of
stepwise regression, we have the risk of selecting variables that ﬁt special peculiarities
of our current sample, but that would not be selected ﬁtting another sample.
Cross-validation is the best model selection practice. This cannot be general-
ised. Cross-validation is an attractive practice consisting in dividing the sample in
subsamples, ﬁtting a model in one of the subsamples and checking how well the
4Since probability is involved with model selection, as we will see later, Popper’s theory of
refutation does not hold, because it does not include uncertainty. Refuting Popper has been the
preferred occupation of many philosophers since the ﬁrst appearance of his books. See Sober
(2016) for parsimony and Stove (1982) for a general criticism about Popper philosophy of science.
220
10
Model Selection

data of other subsample are predicted by the model. This is intuitively reasonable,
although there are some inconveniences. First, since part of the sample is used for
checking, the actual ﬁtted sample is smaller. It can also happen that some models ﬁt
partially better some data and some models ﬁt better other data; for example, in
non-linear models (lactation curves, growth curves, etc.), some model can ﬁt better
the initial conditions and some models can ﬁt better the ﬁnal ones. For example, Blasco
et al. (2003) found, using cross validation in rabbit growth curves, a certain trend of
overestimating predictions at the beginning of the growth curve and underestimating
them at the end. Finally, cross validation may depend on particular idiosyncrasies of
our sample, and taking another sample the results of cross validation may be different.
10.2
Hypothesis Tests
10.2.1 Likelihood Ratio Test and Other Frequentist Tests
In statistics, the expression ‘testing hypothesis’ is used to compare the absence or
presence of some effect, referring these events as null (H0) or alternative hypothesis
(H1), and this leads to selecting or not the model containing this effect. A common
ﬁrst approach to model selection is to remove from the model the effects that are
non-signiﬁcant. As we have seen in Sect. 10.1.3, this is incorrect and therefore is not
recommended. We have seen in Chap. 1 that the results of frequentist hypothesis tests
like t-test or F-test depend on sample size; thus, more parameterised models are
selected when sample size augments, and irrelevant effects can be selected or relevant
effects discarded based only in their signiﬁcation. Frequentist tests have been widely
criticised, mainly because of their frequent misuse (see Johnson 1999 for a review).
10.2.1.1 Likelihood Ratio Test
A more general way of model selection is to use the likelihood ratio test. We have a
hypothesis H0 in which a probability density function depends on a set of
parameters θ0, and a hypothesis H1 in which the same density function has a larger
set of parameters θ1 in which the former set are included. We test whether some of
the parameters included in θ1 are null. This will lead to select the model with or
without these parameters as a result of the test.
Samuel Wilks (1938) showed that for independent large samples, when both
models were Normally distributed, the ratio LR
LR ¼ 2log
f yjbθ0


f yjbθ1

 ¼ 2logf yjbθ1


 2logf yjbθ0


was distributed, when H0 was the true hypothesis, as aχ2
p1p0 where p0 and p1 are the
number of parameters of θ0 and θ1, respectively, and bθ0, bθ1 their maximum
likelihood estimates. This allows ﬁxing a rejection level, for example 5%, and
saying that when this ratio gives a value higher than the threshold for the rejection
10.2
Hypothesis Tests
221

level, H1 is preferred over H0. There are asymptotic approximations that do not
require the distributions to be Normal (see Sorensen and Gianola 2002,
pp. 166–177, for a detailed discussion).
At this point, we will change the notation in order to stress that we are comparing
not only the presence or absence of an effect, but we are also selecting different
models, and saying that we have ‘n’ nested models to be compared, M1, M2, . . .,
Mm, each one with its own set of parameters θi. The expression
Di ¼ 2logf yjbθi


is often called the ‘Deviance’ of model i.5 For the likelihood ratio test, we compare
‘deviances’ of models that are nested. The likelihood ratio test can be expressed as
LR ¼ D0  D1
Showing that the likelihood ratio test is a difference between the deviances of
both models.
Example
We have two models; in Model 1, all data are Normally independently
distributed all with mean 0 and variance 1, and in Model 2 all data are also
Normally independently distributed all with mean μ and variance 1.
Model 1: y ~ N(0, I); it is a perfectly established model, without parameters,
in which p1 ¼ 0
Model 2: y ~ N(1μ, I), p2 ¼ 1
Notice that Model 1 is nested in Model 2, since μ ¼ 0 is a particular value
of μ. Now we calculate the deviances
D1 ¼ 2logf yjμ ¼ 0
ð
Þ
¼ 2log
1
2π
ð
Þn=2  2 1
2

 X
i
yi  0
ð
Þ2 ¼ nlog2π þ
X
i
yi
ð Þ2
D2 ¼ 2logf yjbμML
ð
Þ ¼ nlog2π þ
X
i
yi  bμML
ð
Þ2
¼ nlog2π þ
X
i
yi  y
ð
Þ2
(continued)
5Formally speaking, the deviance is 2logf yjbθS


 2logf yjbθi


, where bθS corresponds to what is
called the ‘saturated’ model, the model with perfect ﬁt and no error as in Fig. 10.3e and f, but it is
also common to informally call ‘deviance’ to 2logf yjbθi


222
10
Model Selection

D1  D2 ¼
X
i
yi
ð Þ2 
X
i
yi  y
ð
Þ2 ¼
X
i
yi
ð Þ2 
X
i
yi
ð Þ2  ny2
 
!
¼ ny2
When the maximum likelihood estimate of the mean (i.e. the sample mean y)
increases, the difference between deviances increases as well. The difference
between deviances is the likelihood ratio test, and it is distributed as a
chi-square with p1  p2 ¼ 1 degrees of freedom. Choosing a level of signiﬁ-
cance of 5%, we ﬁnd χ1 ¼ 3.84; thus, when D1  D2 ¼ ny2 > 3:84 we will
choose Model 2.
10.2.1.2 Likelihood Ratio Test in Practice
This test has its limitations:
•
It can be only applied to nested models, i.e. to models with the same probability
density function in which the parameters of a model are a subset of the
parameters of the other model.
•
It applies only to independent samples, which is not always the case in animal
production, in which family-related individuals are often used.
•
It only holds for large samples, since the distribution of D1  D2 is χ2
p2p1 only
when n ! 1
•
It is somewhat inconsistent. We expect that when n ! 1 the test should give the
correct answer, but we still can select model 1 or model 2 depending on the result
of the test.
•
It tends to favour hyper-parameterised models, because these models ﬁt the data
better, have sharper likelihoods and have larger maximum likelihoods.
10.2.2 Bayesian Model Choice
In a Bayesian context, we can compare many hypotheses by estimating their
probabilities, as we have seen in Chap. 2. As we said in Sect. 2.3.1, in a Bayesian
context we can test not only nested models but also models with different
parameters and different probability density functions.
As before, we will change the notation of Sect. 2.3.1 in order to stress that we are
comparing not only presence or absence of an effect, but we also selecting different
models, and saying that we have ‘m’ models to be compared, M1, M2, . . ., Mm. In a
Bayesian context, to specify each model we need to specify the probability density
function with its parameters but also the prior probability of the model. Each model
has its own prior probability P(Mi), its own density function fi and its own set of
parameters θi. The probability of each model is, using Bayes theorem,
10.2
Hypothesis Tests
223

P Mijy
ð
Þ ¼ P yjMi
ð
Þ  P Mi
ð
Þ
P y
ð Þ
¼ P yjMi
ð
Þ  P Mi
ð
Þ
P
n
1
P y; Mi
ð
Þ
where the probability of the data P(y) is the sum of the mutually exclusive events of
the data being generated by Model 1, Model 2, . . . Model m.
P y
ð Þ ¼
X
m
1
P y; Mi
ð
Þ ¼
X
m
1
P yjMi
ð
Þ  P Mi
ð
Þ
The rationale of the process is to select the most probable model.
10.2.2.1 Bayes Factors
When comparing models two by two, it is not necessary to calculate P(y), since, as
we saw in Chap. 2, Sect. 2.3.2,
P M1jy
ð
Þ
P M2jy
ð
Þ ¼
P yjM1
ð
ÞP M1
ð
Þ
P y
ð Þ
P yjM2
ð
ÞP M2
ð
Þ
P y
ð Þ
¼ P yjM1
ð
Þ  P M1
ð
Þ
P yjM2
ð
Þ  P M2
ð
Þ ¼ BF P M1
ð
Þ
P M2
ð
Þ
where the ratio
BF ¼ P yjM1
ð
Þ
P yjM2
ð
Þ
is called ‘Bayes factor’. When all models have the same prior probabilities, as it is
frequently assumed,
P M1jy
ð
Þ
P M2jy
ð
Þ ¼ P yjM1
ð
Þ
P yjM2
ð
Þ ¼ BF
Bayes factors are popular because they give the relative probability of a model
with respect to another model, and because they also have an interpretation in
classical statistics. If P(y| M1) > P(y| M2) classical statisticians say that the data are
‘more supported’ by Model 1 than by Model 2. The problem is to understand what
‘support’ means and which are its units. If M1 is the true model, P(y| M1) is the
probability of obtaining our sample y. If M2 is the true model, P(y| M2) is the
probability of obtaining our sample y. However, our interest is not to ﬁnd under
which model, if it was the true model, would our data be more probable; our interest
is to know which model is more probable according to the information provided by
our data. We have discussed in Chap. 1 that we do not extract our samples with
maximum probability; all the discussions we had on likelihood apply here. Because
we do not extract samples with maximum probability, even if Model i has the
maximum value for P(y| Mi) we cannot tell whether this model is the most probable.
Whether we prefer to calculate the probability of each model, or to use the
simpler approach of Bayes factors, we need to calculate the probability of the data
224
10
Model Selection

under each model P(y| Mi). To do this, we have to consider all the possible values of
their parameters, multiply by their probability and sum; i.e. we have to marginalise
these parameters by integrating out them, as we saw in Chaps. 5, 6 and 7.
P yjMi
ð
Þ ¼
Z
f i yjθi
ð
Þ  f θi
ð Þdθi
This integration, which can be a complex multiple integration when we have
many parameters, can be solved by MCMC numerical procedures. Unfortunately,
this probability strongly depends on the priors of the parameters, described by their
probability density functions f(θi). We have seen in Chap. 9, Sect. 9.1.3, that prior
information loses importance when sample size increases. However, here the
situation is different, because we are comparing models using the same sample;
sample size is thus the same for all models. We will put an example to see how prior
can affect the results.
Example
We have two models:
Model 1: y ~ N(μ, 1), f μ
ð Þ ¼ constant with bounds 1; 1
½
 ¼
1
1 1
ð
Þ ¼ 1
2
Model 2: y ~ N(μ, 1), f μ
ð Þ ¼ constant with bounds k; k
½
 ¼
1
k k
ð
Þ ¼ 1
2k
Now we will calculate the Bayes factor
P yjM1
ð
Þ ¼
R 1
1 f yjμ
ð
Þf μ
ð Þdμ ¼
R 1
1 f yjμ
ð
Þ  1
2dμ ¼ 1
2
Z 1
1
f yjμ
ð
Þdμ
P yjM2
ð
Þ ¼
R k
k f yjμ
ð
Þf μ
ð Þdμ ¼
R k
k f yjμ
ð
Þ  1
2kdμ ¼ 1
2k
Z
k
k
f yjμ
ð
Þdμ
BF ¼ P yjM1
ð
Þ
P yjM2
ð
Þ ¼ k 
R 1
1 f yjμ
ð
Þdμ
R k
k f yjμ
ð
Þdμ
Thus, even when using vague priors, the decision on how large the bounds are
affects the result of the Bayes factor. Sorensen and Gianola (2002) give a
more developed example of the same problem.
10.2.2.2 Bayesian Model Choice in Practice
When using Bayesian model choice, we should take into account that:
•
The result is inﬂuenced by the prior probability of each model P(Mi). It is
common to consider, appealing to the principle of indifference, that all models
have the same prior probability, although in the real world this is rarely the case.
10.2
Hypothesis Tests
225

•
The result is also strongly inﬂuenced by the priors used for the parameters of the
model, described by their probability density functions f(θi), which limits its use.
Often, Bayes factors are used exclusively as an approximate way for ranking
models in order to help in model selection.
•
As with likelihood ratio tests, we should use the same set of data y to compare all
models. In Bayesian statistics, our inferences are always conditioned to the data.
•
The probabilities of the models P(Mi) are relative probabilities. If we have two
models, one with a 70% probability, the other one will have a 30% probability,
but if we introduce a third model, the probability of the other two models can
decrease and the three models may have 60%, 20%, 20% probability; thus,
models are compared relatively. We say that the ﬁrst model is three times
more probable than the other ones (0.60/0.20 ¼ 3) only when comparing these
three models.
There are some advantages of Bayesian model comparison:
•
It takes into account the uncertainty about the models, which is out of the
possibilities of non-Bayesian procedures.
•
Comparison between models is based on probability; thus, we have a measure of
the uncertainty associated with each model if we have already solved the
problems associated with the priors.
•
Models do not need to be nested; all types of models can be compared.
•
All parameters are integrated out; thus, Bayesian model comparison does not
necessarily ﬁts the model with higher number of parameters.
The main problem in using Bayesian model comparison is its dependence on the
priors of the parameters of each model. Other inconveniences, as the difﬁculty of
computation, are being solved by the development of MCMC techniques. We will
see later the criterion BIC, an approximation to Bayesian model comparison that
uses vague priors and is less dependent on them.
10.3
The Concept of Information
The concept of ‘amount of information’ was proposed by Ronald Fisher6 in 1925 in
a context of likelihood (Fisher 1925). The rationale is that sharp likelihood curves
have more information than ﬂat ones. It is a useful concept because it can be used
for estimating the standard errors of maximum likelihood estimators. However, the
literature rarely provides the amount of information in scientiﬁc papers, although
6Likelihood and information were previously developed by the Irish-Catalan statistician and
economist Francis Ysidro Edgeworth (1908), but Fisher never recognised this precedent (Hald
1998).
226
10
Model Selection

the mathematical expression of Fisher’s information is widely used in statistics.
More than 20 years later of Fisher’s proposal, Claude Shannon, an electrical
engineer of the Bell Telephone Laboratories, developed a new concept of informa-
tion in the context of the loss of information produced when transmitting a message
through a channel (Shanon 1948). This use of information was not related to
statistics, but it was shown quickly by Solomon Kullback and Richard Leibler
that it could be used to evaluate the amount of information lost when approximating
a probability density function by another probability density function (Kullback and
Leibler 1951). They introduced the concept of ‘divergence’ between functions that
was used later by for model selection.
10.3.1 Fisher’s Information
Fisher’s information is related to the sharpness of the likelihood function. In
Fig. 10.5, we have two likelihood curves of different sharpness; Fig. 10.5b looks
less informative, since a large amounts of values of θ have similar likelihoods. This
means that we have a large amount of possible values of θ that if they were the true
value, our sample would have nearly the same probability.
The sharpness of a curve at a determined point θ0 can be measured by the tangent
of the curve at this point; i.e. by the value of the ﬁrst derivative at this point. This
tangent can be positive or negative; thus, in order to avoid the sign, we can consider
the square of the tangent as a more appropriate measure of the sharpness at the
point θ0.
∂f yjθ
ð
Þ
∂θ

2
θ¼θ0
f(q  y)
f(q  y)
q
q0
q0
q
a
b
Fig. 10.5 Sharpness of likelihoods measured using tangents to the curves
10.3
The Concept of Information
227

This could also be a measure of the amount of information at the point θ0, but for
practical reasons that we will see below, it is more convenient to use the natural
logarithm of this expression
IOBS θ0jy
ð
Þ ¼
∂log f yjθ
ð
Þ
∂θ

2
θ¼θ0
where IOBS(θ0| y) is called the ‘observed information’ at the point θ0 because it
depends on the observed data y.
In a frequentist context, uncertainty is assessed by thinking what would happen
when the experiment is repeated many times; if we repeat the experiment, the
likelihood curves will change and the observed information at the point θ0 will be
different (see Fig. 10.6). Let us take the expectation for all possible samples to
deﬁne the ‘information at the point θ0’.
I θ0jy
ð
Þ ¼ Ey
∂logf yjθ
ð
Þ
∂θ

2
θ¼θ0
where Ey means the expectation for all possible data ‘y’.
It can be shown (Appendix 10.1) that the information function can be written as
I θjy
ð
Þ ¼ Ey
∂logf yjθ
ð
Þ
∂θ

2
¼ Ey
 ∂2logf yjθ
ð
Þ
∂θ2
 
!
q0
q0
q
q
Fig. 10.6 Likelihoods after repeating the experiment, with new data
228
10
Model Selection

The advantage of this new expression is that it permits to deﬁne the information
carried by each data. Let us consider an independent sample
f yjθ
ð
Þ ¼ f y1; y2; . . . ; ynjθ
ð
Þ ¼ f y1jθ
ð
Þ  f y2jθ
ð
Þ . . . f ynjθ
ð
Þ
logf yjθ
ð
Þ ¼ logf y1jθ
ð
Þ þ logf y2jθ
ð
Þ þ . . . þ logf ynjθ
ð
Þ
∂2logf yjθ
ð
Þ
∂θ2
¼ ∂2logf y1jθ
ð
Þ
∂θ2
þ ∂2logf y2jθ
ð
Þ
∂θ2
þ    þ ∂2logf ynjθ
ð
Þ
∂θ2
Now, multiplying by 1 and taking expectations,
Ey
 ∂2logf yjθ
ð
Þ
∂θ2
 
!
¼ Ey
 ∂2logf y1jθ
ð
Þ
∂θ2
 
!
þ Ey
 ∂2logf y2jθ
ð
Þ
∂θ2
 
!
þ   
þ Ey
 ∂2logf ynjθ
ð
Þ
∂θ2
 
!
which shows that the information of an independent sample is the sum of the
information given by each data
I θjy
ð
Þ ¼ I θjy1
ð
Þ þ I θjy2
ð
Þ þ    þ I θjyn
ð
Þ
This is why we preferred to deﬁne the information in a logarithmic scale.
Fisher’s information is popular because, when applied to the maximum likeli-
hood estimate θ0 ¼ bθML, it is the inverse of the variance of the estimator. This
allows us to estimate the s.e. of the maximum likelihood estimators for large
samples7
var bθML



1
I bθMLjy


Often, it is not possible to calculate the Ey; thus, the observed information for
this particular sample is used. Asymptotically, it also converges to the inverse of the
maximum likelihood estimator variance. Thus, for large samples,
var bθML



1
 ∂2logf yjθ
ð
Þ
∂θ2


θ¼bθML
It is easy to generalise this concept for several parameters. For example, if we
have two parameters θ1 and θ2, the information matrix is
7It is obvious that for very large samples nobody is particularly interested in the standard error.
Here, ‘large’ would mean ‘not small’; the problem of how large they should be depends on each
case and no general rules can be applied.
10.3
The Concept of Information
229

I θ1; θ2jy
ð
Þ ¼
 ∂2logf yjθ1; θ2
ð
Þ
∂θ1
ð
Þ2
 ∂2logf yjθ1; θ2
ð
Þ
∂θ1∂θ2
 ∂2logf yjθ1; θ2
ð
Þ
∂θ1∂θ2
 ∂2logf yjθ1; θ2
ð
Þ
∂θ2
ð
Þ2
2
6664
3
7775
Example
Suppose that we have an independent sample Normally distributed
f yjμ; σ2


¼
1
ﬃﬃﬃﬃﬃ
2π
p

n σ2
ð
Þ
n
2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775
The maximum likelihood estimates of the parameters are
bμML ¼ y
bσ2
ML ¼ 1
n
X
yi  y
ð
Þ2 ¼ s2
Now, it is easy to see that deriving f( y| μ, σ2) and substituting μ , σ2 by y, s2,
we get, for large samples,
IOBS bμML; bσ2
MLjy


¼

∂2logf yjμ;σ2
ð
Þ
∂μ
ð
Þ2

∂2logf yjμ;σ2
ð
Þ
∂μ∂σ2

∂2logf yjμ;σ2
ð
Þ
∂μ∂σ2

∂2logf yjμ;σ2
ð
Þ
∂σ2
ð
Þ2
0
B
@
1
C
A
μ ¼ y
σ2 ¼ s2
¼
n
s2
0
0
n2
2s4
0
B
@
1
C
A ¼
1
var bμ
ð Þ
0
0
1
var bσ2
ML
ð
Þ
0
B
B
@
1
C
C
A
which gives, for large samples,
s:e: bμML
ð
Þ ¼ sﬃﬃﬃn
p
s:e: bσ2
ML


¼
ﬃﬃﬃ
2
p
n s2
The exact value of the s.e. of both parameters can be calculated for any
sample size; for example, the exact s.e. for the variance is
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
2 n1
ð
Þ
n2
q
 s2 which
is practically the same for large n, when n  1  n.
230
10
Model Selection

10.3.2 Shannon Information and Entropy
According to Shannon (1948), the deﬁnition of information comes from ﬁve
postulates:
•
Information should be positive: I > 0
•
For events A and B, IA[B > IA and IA[B > IB
•
Information should be additive for independent events:
If P(A\B) ¼ P(A)  P(B) then IA\B ¼ IA + IB
•
For certain events I ¼ 0 (the experiment does not add any information)
•
For impossible events I ¼ 1 (the experiment adds much information)
The ﬁrst two postulates seem reasonable. The third one, the additivity of
information, is questionable; for example, information could be multiplicative;
we can talk about an event increasing information by 15%. The other postulates
are conventions: if I say that tomorrow either it will rain or it will not, my prediction
will be conﬁrmed undoubtedly, but I will not earn any reputation as a meteorologist,
since the amount of information I have given is null. We can reason in the same
way, saying that if an event is very rare, it contains much information; in the limit, if
it is impossible, it has an inﬁnite amount of information.
Shannon (1948) proved that the only function that ﬁts the ﬁve postulates was
I ¼ log PA
ð
Þ
where PA is the probability of the event A and I the amount of information of this
event. You can check the ﬁve postulates: logarithms are always greater than zero, P
(A[B) > P(A), for independent events  log(PA  PB) ¼  log(PA)  log(PB), for
certain events  log(1) ¼ 0 and for impossible events  log(0) ¼  1
In discrete distributions with n events, we can calculate the mean information
contained in the distribution
H ¼ E log P1
ð
Þ  log P2
ð
Þ      log Pn
ð
Þ
½

Shannon called this quantity H ‘entropy’ of the distribution because it has the
same mathematical formula as the entropy in thermodynamics.
Entropy is maximum when all probabilities are the same
P1 ¼ P2 ¼    ¼ Pn ¼ 1
n
which supports the principle of indifference when there is no prior information.
For the continuous case, we can deﬁne the entropy of a probability density
function as
10.3
The Concept of Information
231

H f y
ð Þ
½
 ¼ E logf y
ð Þ
½
 ¼ 
Z
log f y
ð Þ  f y
ð Þdy
For example, if f(y) is uniform between a and b (Fig. 10.7),
f yja; b
ð
Þ ¼
1
b  a
H f yja; b
ð
Þ
½
 ¼ Ey log
1
b  a
	

¼ Ey log b  a
ð
Þ
½

¼
Z
b
a
log b  a
ð
Þ 
1
b  a dy ¼ log b  a
ð
Þ
This seems reasonable: when b  a is a large interval, uncertainty is great, and
entropy is also great. However, entropy is not well deﬁned for the continuous case,
because when b  a < 1 we get negative entropies. This and other inconveniences
(see Bernardo and Smith 1994) have limited the use of entropy to discrete cases, but
the concept has been useful for deﬁning the divergence between probability density
functions as we will see below.
10.3.3 Kullback–Leibler Information
Few years after Shannon’s proposal of information, Kullback and Leibler (1951)
proposed a generalisation of this concept. Suppose we have a probability density
function that is considered the ‘true’ density function and we would like to
approximate it by using another density function. For example, we think that the
true distribution is Normal and we would like to approximate to it by using a
binomial. The Kullback–Leibler discrimination information is the loss of informa-
tion that we have when using a probability density function of a distribution as an
approximation to other distribution; in our example, it will be the loss of informa-
tion when using the Binomial to approximate the Normal. Calling fN(y) the
probability density function of the Normal distribution and fB(y) the probability
density function of the Binomial distribution, the loss of information for using the
Binomial instead of the Normal is
a
b
Fig. 10.7 Constant
probability density function
between (a) and (b)
232
10
Model Selection

I f B
ð
Þ  I f N
ð
Þ ¼ logf B  logf N
ð
Þ ¼ logf N
logf B
The mean of this loss of information is
K f Bjf N
ð
Þ ¼ EN I f B
ð
Þ  I f N
ð
Þ
½
 ¼ EN
logf N y
ð Þ
logf B y
ð Þ


¼
Z 1
1
logf N y
ð Þ
logf B y
ð Þ  f N y
ð Þdy
where we use the notation EN for the expectation in order to stress that we are taking
expectations assuming that the ‘true’ distribution is the Normal one, if we assume
that the Binomial is the ‘true’ distribution and the Normal is an approximation, the
average loss of information is
K f Njf B
ð
Þ ¼ EB I f N
ð
Þ  I f B
ð
Þ
½
 ¼
Z 1
1
logf B y
ð Þ
logf N y
ð Þ  f B y
ð Þdy
which is not the same quantity. By K( fB| fN) we mean the Kullback–Leibler
information given that the ‘true’ distribution is the Normal with probability density
function fN, and by K( fN| fB) we mean that the ‘true’ distribution is the Binomial
with probability density function fB. The Kullback–Leibler information is some-
times called Kullback–Leibler ‘distance’, as intuitively it would be the ‘distance’
between the two distributions; however, as it is not symmetric, it is not a proper
distance (to be a distance it needs to accomplish some conditions; for example, the
distance between A and B should be the same that between B and A). Because of
that, it is also called Kullback–Leibler ‘divergence’.8
When we do not know which is the ‘true’ distribution or the distribution to which
we want to approximate the other one to, it has been proposed to use the average of
both ‘divergences’ or the minimum of them in a Bayesian context of minimum prior
information (Bernardo 2005).
Kullback–Leibler information looks like an entropy or a difference between
entropies; indeed, it has been called a ‘crossed entropy’. It can be safely used, since
it can be proven that this quantity is always positive.
10.4
Model Selection Criteria
10.4.1 Akaike Information Criterion (AIC)
In 1973, Hitoguru Akaike proposed selecting models on the basis of an information
criterion (AIC was originally named ‘An Information Criterion’). We select the
model that has the lowest Kullback–Leibler divergence with the true model.
8Here, it happens as with Fisher’s use of the likelihood that we commented in Chap. 1; after clearly
establishing that it is a divergence and not a distance, many people immediately forget this and use
the Kullback–Leibler information as a distance.
10.4
Model Selection Criteria
233

In frequentist tests, we only have one hypothesis and a nested alternative, but we
can now compare many models that do not need to be nested; for example, we can
ﬁt our data assuming a Normal distribution in a model and a Poisson distribution in
another model. Assume we want to compare models M1, which has a probability
density function f1( y| θ1) with a set of unknown parameters θ1, and M2, which has a
probability density function f2( y| θ2) with unknown parameters θ2. Notice that the
probability density functions can be different and so can the set of parameters. Our
models and parameters are simpliﬁcations of the reality, but we can consider that
the data are generated by an unknown density function. Assume that there is a
TRUE probability density function fT generating the actual data. Of course, we do
not know the true density function; to represent how our data are really generated,
we would need a very large set of parameters and an extremely complex function.9
However, ideally, we could represent the Kullback–Leibler divergence of our
models with the true model.
K f 1jf T
½
 ¼ ET I f 1
ð
Þ  I f T
ð
Þ
½
 ¼ ET logf 1  logf T
ð
Þ
½
 ¼ ET logf T
½
  ET logf 1
½

K f 2jf T
½
 ¼ ET logf T
½
  ET logf 2
½

where ET indicates the expectation under the true model; i.e.
ET logf i yjθi
ð
Þ
½
 ¼
Z
logf i yjθi
ð
Þ  f T y
ð Þdy
The best model will be the one with the smallest divergence. Since the term
ET[log fT] is the same for both models, we can choose the model in which the
second term makes the Kullback–Leibler divergence smaller. When comparing
several models,
K f ijf T
½
 ¼ ET logf T
½
  ET logf i
½
 ¼ C  ET logf i yjθi
ð
Þ
½

where C ¼ ET[log fT] is a constant common to all models. We will select the model
that makes this divergence smallest.
These divergences depend on the true values of the parameters θi for each model
i. We estimate these values by maximum likelihood. When we have obtained the
maximum likelihood estimates for each model, we calculate the estimated
Kullback–Leibler divergence for each model.
9Data in biological problems depend on many factors, most of them unknown. The residuals of the
models represent all the factors that were not considered. With our models, we simplify the
observed reality so that we capture most of the information contained in the data, but we cannot
sustain that one of our models is the “true” one.
234
10
Model Selection

bK ¼ C  ET logf yjbθML


h
i
We have removed the subindex ‘i’ for simplicity, but we have a bKi for each
model Mi, and each model has a different set of parameters estimated by maximum
likelihood bθMLi and can have a different probability density function fi; only the
constant C and the data y are the same for all models.
Notice that the expectations ET are taken considering that our data are generated
by an unknown true model, but we do not know the true probability density function
fT which is needed to calculate this expectation. We can consider that our current
sample can be used as an estimate of this expectation; thus, an estimation of the
Kullback–Leibler divergence can be, for each model,
~K ¼ C  logf yjbθML


Now, we could choose the model with the smallest estimated divergence, but
this estimate is biased. If we repeat the experiment for several samples y, the
average of ~K will not be bK. In Appendix 10.2, we show that the bias is the number
of parameters ‘p’ in the model.
Therefore, an unbiased estimator of bK is
C  logf yjbθML


 p
h
i
We can now compare models with the smallest divergence. In order to make this
criterion more similar to the likelihood ratio test, Akaike suggested multiplying it
by 2 in order to look similar to the likelihood ratio test and proposed his AIC
criterion for model selection. The Akaike Information Criterion for each model is
AIC ¼ 2logf yjbθML


þ 2p
We select the model with the smallest AIC because its probability density
function f( y| θ) has, for large samples, the smallest Kullback–Leibler divergence
with the true density function fT( y).
For small samples, it is recommended (Burnham and Anderson 2002) to use
AICc ¼ 2logf yjbθML


þ 2p
n
n  p  1


where n is the sample size. When n is much larger than p, AIC works well and AICc
is not needed.
10.4
Model Selection Criteria
235

Example
We will put the same example as in the case of the likelihood ratio test in Sect.
10.1.3. We have to choose between two models
Model 1: y ~ N(0, I), it is a model without parameters, in which p1 ¼ 0
Model 2: y ~ N(1μ, I), p2 ¼ 1
AIC1 ¼ 2logf yjμ ¼ 0
ð
Þ þ 2p1
AIC2 ¼ 2logf yjbμ
ð
Þ þ 2p2
We have calculated the ﬁrst terms in Sect. 10.1.3. As p1 ¼ 0 and p2 ¼ 1, we
have
AIC1 ¼ nlog2π þ
X
i
yi
ð Þ2
AIC2 ¼ nlog2π þ
X
i
yi  y
ð
Þ2 þ 2 ¼ nlog2π þ
X
i
yi
ð Þ2  ny2 þ 2
Model 2 will be chosen when AIC2 < AIC1; i.e. when AIC1  AIC2 > 0
AIC1  AIC2 ¼ ny2  2 > 0 ! ny2 > 2
Notice that the result is not the same as when applying the likelihood
ratio test.
AIC in practice
•
We calculate AIC independently for each model, and choose the smallest AIC,
since it minimises the divergence with the true model.
•
AIC has two terms with opposite signs, one depending on how well the model
ﬁts the data and the other one depends on the number of parameters. A model
that will ﬁt the data well because it has many parameters will be penalised and its
AIC will not necessarily be the smallest one.
•
AIC should be calculated for each model using the same data y. Model choice
depends on the data; a new set of data could alter the order of the models.
•
AIC is a criterion for model selection, not a probability. It is useful for selecting a
model among several models; thus, the absolute value of AIC is not important,
but the relative value between models.
•
The absolute value of AIC is irrelevant; it depends on the sample size. The
important value is the difference between models, all compared with the same
sample. Our ﬁnal decision will be to select one model with the smallest value of
AIC, or several models showing small differences of AIC with the best model.
How large should be these differences is somewhat subjective. It has been
suggested that models showing AIC less than 2 points higher than the smallest
AIC model have essentially the same support, and models showing differences
236
10
Model Selection

in AIC with the smallest one greater than 10 points should be discarded
(Burnham and Anderson 2002). For intermediate cases, or models showing
similar support, biological or practical considerations should be taken into
account to select the most appropriate model.
•
AIC is derived estimating the average for all possible samples and values of
bθML ; thus, it should ﬁt well new data that are not observed. It has been shown
that AIC is asymptotically consistent with results of cross validation (Burnham
and Anderson 2002).
•
AIC does not take into account the error of estimation of the parameters bθML nor
the uncertainty associated with the selection of a particular model with a
particular probability density function fi. The consequence is that AIC tends to
overestimate the number of parameters needed (see Kass and Adrian 1995 for a
discussion).
•
AIC is based in a set of assumptions and is derived using several approximations.
In the common version explained here, it requires the models not to have large
divergences with the true one and the samples should be relatively large. AIC
gives an unbiased estimate of the deviance. Unbiased estimates are not neces-
sarily optimal. AIC is, thus, a tool for orientating model choice, not a rule of
thumb to be blindly followed.
10.4.2 Deviance Information Criterion (DIC)
DIC (Deviance Information Criterion) was proposed as a Bayesian model choice
criterion by Spiegelhalter et al. (2002) for complex nested models in which the
number of parameters is not clearly deﬁned, but it can be applied to any model. It is
popular because it is very easy to calculate from MCMC results.
We have seen in Sect. 10.4.1 the Akaike Information Criterion
AIC ¼ 2log f yjbθML


þ 2p
where bθML is the maximum likelihood estimate of θ and p the number of parameters
of the model. In a Bayesian context, instead of the maximum likelihood estimate we
can use the mean of the posterior density10 of θ
θ ¼ Eθ θjy
ð
Þ
Now we propose the Deviance Information Criterion for each model
10We could also use the median or the mode, but the mean has some mathematical advantages in
the development of the formulae.
10.4
Model Selection Criteria
237

DIC ¼ 2log f yjθ


þ 2pD
where pD is the equivalent to the number of parameters in AIC and should be
calculated. In Appendix 10.3, we show that
pD ¼ D  D θ
 
where D is the mean of the deviances and D θ
 
is the deviance of the posterior
mean. In Appendix 10.3, there is the analytical expression for pD and DIC, but it is
very easy to compute it using MCMC, as we will show in the following example.
Example
We will take an example from the Baby model
f yjμ; σ2


¼
1
2πσ2
ð
Þ
n
2 exp 
P
n
1
yi  μ
ð
Þ2
2σ2
2
664
3
775
D μ; σ2jy


¼ 2log f yjμ; σ2


¼ nlog 2π
ð
Þ þ nlogσ2 þ
P
n
1
yi  μ
ð
Þ2
σ2
We have MCMC chains for μ and σ2 with m samples. We compute the
posterior mean for both parameters
μ1
μ2
μ3
  
σ2
1
σ2
2
σ2
3
  

μm
σ2
m
μ ¼ 1=m
ð
Þ P μi
σ2 ¼ 1=m
ð
Þ P σ2
i
We can also compute the deviance for each sample of the MCMC chain
and the mean of all deviances
D1 ¼ D μ1; σ2
1jy


¼ nlog 2π
ð
Þ þ nlogσ2
1 þ
P
n
1
yi  μ1
ð
Þ2
σ2
1
and the same for D2, D3,. . .Dm
D1 D2 D3   
f
Dm
D ¼ 1=m
ð
Þ P Di
We also compute the deviance using the posterior means
(continued)
238
10
Model Selection

D μ; σ2jy


¼ nlog 2π
ð
Þ þ nlogσ2 þ
P
n
1
yi  μ
ð
Þ2
σ2
Now, pD and DIC are calculated directly from the previous results
pD ¼ D  D μ; σ2jy


DIC ¼ D μ; σ2jy


þ 2pD
10.4.3 Bayesian Information Criterion (BIC)
Another criterion is the BIC (Bayesian Information Criterion) developed by Gideon
Schwartz in 1978. It is an approximation to the Bayesian model comparison that we
have seen in Sect. 10.2.2. Bayesian model choice is based in comparing the
posterior probabilities of the models P(Mi| y). When models are compared two by
two, assuming that all models have equal prior probabilities, we use the Bayes
Factors (BF)
BF ¼ P yjM1
ð
Þ
P yjM2
ð
Þ ¼ P M1jy
ð
Þ
P M2jy
ð
Þ
As we have seen in Sect. 10.2.2, Bayes factors are strongly dependent on the
priors of the parameters of each model Mi. We can approximate P( y| Mi) using
vague priors, but as we did with AIC and DIC, we will approximate its natural
logarithm by multiplying by 2 to make it more similar to the likelihood ratio test.
In Appendix 10.4, we show that for each model Mi
2logP yjMi
ð
Þ ¼ 2log
Z
f i yjθi
ð
Þ  f θi
ð Þdθi  2logf i yjbθMLi


þ 2pilog n
ð Þ
where bθMLi is the maximum likelihood estimation of the parameters of model Mi, pi
is the number of parameters of this model and n is the sample size. The reader can
wonder about the prior, but it can be shown that it has been dropped in the
approximation, since the terms involved in the prior are of lower order than the
ones appearing in the formula. Removing the subindex ‘i’ for simplicity as before,
we deﬁne the Bayesian Information Criterion for each model M as
10.4
Model Selection Criteria
239

BIC ¼ 2log f yjbθML


þ 2p  log n
ð Þ
where each model has a different set of estimated parameters bθMLi and can have a
different probability density function fi; the data y and the sample size n are the
same for all models. This criterion looks similar to AIC although it has not been
derived from information criteria. When comparing two models, the ratio of BICs
of the two models is a good approximation to 2log(BF) for large samples. Here, as
with AIC, the model with the smallest BIC is preferred.
The reader may consider surprising to ﬁnd a maximum likelihood estimation
bθML in a Bayesian criterion. We have conserved the nomenclature bθMLto stress the
similarity with AIC, but we could have named it ‘the mode of the joint posterior
density of all parameters with ﬂat priors’ as we did in Chap. 5, Sect. 5.2.3.
Example
We will put the same example as in the case of the likelihood ratio test in Sect.
10.1.3. We have to choose between two models
Model 1: y ~ N(0, I), it is a model without parameters, in which p1 ¼ 0
Model 2: y ~ N(1μ, I), p2 ¼ 1
BIC1 ¼ 2logf yjμ ¼ 0
ð
Þ þ 2p1  log n
ð Þ
BIC2 ¼ 2logf yjbμ
ð
Þ þ 2p2  log n
ð Þ
We have calculated the ﬁrst terms in Sect. 10.1.3. For p1 ¼ 0 and p2 ¼ 1,
we have
BIC1 ¼ nlog2π þ
X
i
yi
ð Þ2
BIC2 ¼ nlog2π þ
X
i
yi y
ð
Þ2 þ2log n
ð Þ ¼ nlog2π þ
X
i
yi
ð Þ2 ny2 þ2log n
ð Þ
Model 2 will be chosen when BIC2 < BIC1, i.e. when BIC1  BIC2 > 0
BIC1  BIC2 ¼ ny2  2  log n
ð Þ > 0
!
n
log n
ð Þ y2 > 2
Notice that the criterion is different from AIC, and we will chose model
1 more frequently because we divide n by log(n).
BIC in practice
•
There are underlying assumptions in BIC. First, as with all Bayes factors, the
prior probabilities of the models P(Mi) are supposed to be the same. Due to the
approximations made, it works well with large samples, particularly when the
number of parameters and ﬁxed effects to be estimated is relatively small when
compared with sample size n.
240
10
Model Selection

•
BIC tends to favour models with fewer parameters than AIC (Kass and Adrian
1995) due to the supplementary penalty of log(n) in the formula.
•
If the true model is among the models to be selected (we can consider that one of
them is a quasi-true one), BIC selects this model when ‘n’ is large (see Sorensen
and Gianola 2002, p. 422), although it has been argued that in this case ‘n’ should
be very large (see Burnham and Anderson 2002, p. 288).
•
BIC does not minimise the Kullback–Leibler divergence with the true model; its
rationale is different; it is an approximation to Bayesian model choice.
•
As with AIC, BIC can be used for non-nested models and comparisons are made
with the same sample.
10.4.4 Model Choice in Practice
It is difﬁcult to give general rules for model selection; it depends on the complexity
of the problem, the number of models to be compared, the actual true state of the
phenomenon that is under study, etc. In animal production, we usually have a
reduced amount of possible models of interest, normally less than 10 or 15 models;
thus, we will not be in the situation of comparing hundreds of models as in some
biological problems. We can give some general advice for model comparison:
•
First, compare only models that are biologically sound. Comparing all possible
models is not only a waste of time, but can by chance lead to select a model
difﬁcult to interpret.
•
Perform exploratory analysis. Many times this is inspiring about which models
should be compared. However, notice that exploratory analysis is only a ﬁrst
approach; we have the risk of overﬁtting if we are trying to include in the model
all peculiarities of our sample that may have been produced by chance.
•
Including or not some noise effects cannot be decided by thumb rules, thus do
not remove effects just because they are non-signiﬁcant. If you have enough
data, you can include all the effects that are biologically sound, independently of
their signiﬁcance. You can also remove effects that are irrelevant, but this should
be always showed by their conﬁdence interval, because they may be relevant
although the actual estimate is not. Finally, you can use model selection criteria
to decide about including or not some effects.
•
Model selection criteria (AIC, BIC, DIC, TIC, etc.) are particularly useful when
you have many models and you want a closer examination of the three or four
more relevant, or when you have models with different distributions. The
common practice of using model selection criteria to choose the best of three
or four models gives too much conﬁdence to these criteria, unless there are
dramatic score differences between models. Approximations made using
Taylor’s expansions are made when developing the criteria (see Appendices 10.2,
3 and 4). Taylor expansions are approximations only locally valid around
the point in which the expansion is made, in this case the estimator being used
10.4
Model Selection Criteria
241

(bθML orθ), which means that the true value should be near the estimator when
Taylor’s expansion is used. The true value is near the estimator when the sample
is large enough.
•
The ﬁnal decision about model selection cannot be a thumb rule after applying a
model’s selection criterion. It should include a discussion about the biological
soundness of the models compared, or the practical use of them. We can select a
model that scores lower than others, based on biological, economical or practical
reasons.
Appendix 10.1
∂log f yjθ
ð
Þ
∂θ
¼
1
f yjθ
ð
Þ
∂f yjθ
ð
Þ
∂θ
!
∂log f yjθ
ð
Þ
∂θ
f yjθ
ð
Þ ¼ ∂f yjθ
ð
Þ
∂θ
E ∂log f yjθ
ð
Þ
∂θ


¼
Z 1
1
∂log f yjθ
ð
Þ
∂θ
f yjθ
ð
Þdy ¼
Z 1
1
∂f yjθ
ð
Þ
∂θ
dy
¼ ∂
∂θ
Z 1
1
f yjθ
ð
Þdy ¼ 0
because
Z 1
1
f yjθ
ð
Þdy ¼ 1
!
∂
∂θ
Z 1
1
f yjθ
ð
Þdy ¼ 0
Taking a second differentiation,
∂
∂θ E ∂log f yjθ
ð
Þ
∂θ


¼ 0
∂
∂θ
E ∂log f yjθ
ð
Þ
∂θ


¼ ∂
∂θ
Z 1
1
∂log f yjθ
ð
Þ
∂θ
f yjθ
ð
Þdy
¼
Z 1
1
∂
∂θ
∂log f yjθ
ð
Þ
∂θ
f yjθ
ð
Þ


dy ¼
¼
Z 1
1
∂2f yjθ
ð
Þ
∂θ2
f yjθ
ð
Þdy þ
Z 1
1
∂log f yjθ
ð
Þ
∂θ
 ∂f yjθ
ð
Þ
∂θ
dy ¼
¼
Z 1
1
∂2f yjθ
ð
Þ
∂θ2
f yjθ
ð
Þdy þ
Z 1
1
∂log f yjθ
ð
Þ
∂θ
 ∂log f yjθ
ð
Þ
∂θ
f yjθ
ð
Þdy
¼ E ∂2f yjθ
ð
Þ
∂θ2
 
!
þ E ∂log f yjθ
ð
Þ
∂θ

2
¼ 0
242
10
Model Selection

Therefore,
E ∂log f yjθ
ð
Þ
∂θ

2
¼ E ∂2f yjθ
ð
Þ
∂θ2
 
!
Appendix 10.2
We can approximate log f( y| θ) by taking a Taylor’s expansion at bθML
log f yjθ
ð
Þ  log f yjbθML


þ
θ  bθML

 ∂log f i yjθ
ð
Þ
∂θ
	

θ¼bθML
þ 1
2 θ  bθML

0 ∂2log f yjθ
ð
Þ
∂θ∂θ0
"
#
θ¼bθML
θ  bθML


But the ﬁrst derivative is null at the maximum, i.e. at the point θ ¼ bθML, thus,
log f yjθ
ð
Þ  log f yjbθML


þ 1
2 θ  bθML

0 ∂2log f yjθ
ð
Þ
∂θ∂θ0
"
#
θ¼bθML
θ  bθML


 log f yjbθML


þ 1
2 θ  bθML

0
IbθML θ  bθML


where IbθMLis Fisher’s observed information matrix.
log f yjθ
ð
Þ  log f yjbθML


 1
2 θ  bθML

0
IbθML θ  bθML


E 2log f yjbθML


h
i
 E 2log f yjθ
ð
Þ
½
  E
θ  bθML

0
IbθML θ  bθML


h
i
The term
θ  bθML

0
IbθML θ  bθML


is a quadratic form. If θ is a multivariate
Normal distribution, or if the sample is large enough allowing f( y| θ) to converge to
a Normal distribution (see Chap. 2, Appendix 2.3), this quadratic form converges
to a χ2
p , where ‘p’ is the number of parameters in θ. Therefore, the expectation of
this quadratic form is
E 2log f yjbθML


h
i
E 2log f yjθ
ð
Þ
½
E
θbθML

0
IbθML θbθML


h
i
¼E χ2
p


¼p
Appendix 10.2
243

Appendix 10.3
Let us take
θ ¼ E θjy
ð
Þ
We will approximate the deviance using a Taylor’s expansion
D θ
ð Þ ¼ 2log f yjθ
ð
Þ  2log f yjθ


þ ∂2log f yjθ
ð
Þ
∂θ
	

θ¼θ
θθ


þ1
2 θθ

0 ∂22log f yjθ
ð
Þ
∂θ∂θ0
"
#
θ¼θ
θθ


Now we will calculate the mean deviance
D ¼ E D θ
ð Þ
½

Taking expectations, and taking into account that
•
E 2  log f yjθ




¼ 2  log f yjθ


because it is a constant,
•
 ∂2log f yjθ
ð
Þ
∂θ
h
i
θ¼θ and  ∂22log f yjθ
ð
Þ
∂θ∂θ0
h
i
θ¼θ are constants because after differentia-
tion we substitute θ by the posterior mean θ.
•
E
 ∂2log f yjθ
ð
Þ
∂θ
h
i
θ¼θ θ  θ


n
o
¼  ∂2log f yjθ
ð
Þ
∂θ
h
i
θ¼θE θ  θ


¼ 0
we can calculate the mean deviance D
D ¼ E D θ
ð Þ
½
  2  log f yjθ


þ E
θ  θ

0  ∂2log f yjθ
ð
Þ
∂θ∂θ0
"
#
θ¼θ
θ  θ


(
)
¼ 2  log f yjθ


þ pD
This second term pD, the ‘effective number of parameters’, is the expectation of a
quadratic form. In general, a quadratic form is a scalar originated by multiplying a
matrix A by a vector x as x0Ax. The expectation of a quadratic form is
E x0Ax
ð
Þ ¼ tr AE xx0
ð
Þ
½

In our case, pD is
244
10
Model Selection

pD
¼ E
θ  θ

0  ∂2log f yjθ
ð
Þ
∂θ∂θ0
"
#
θ¼θ
θ  θ


(
)
¼ tr
 ∂2log f yjθ
ð
Þ
∂θ∂θ0
"
#
θ¼θ
E θ  θ


θ  θ

0
(
)
¼
¼ tr
 ∂2log f yjθ
ð
Þ
∂θ∂θ0
"
#
θ¼θ
V
(
)
where V is the covariance matrix of the posterior density.
Appendix 10.4
We have seen in Appendix 10.2 that
log f yjθ
ð
Þ  log f yjbθML


þ 1
2 θ  bθML

0
IbθML θ  bθML


¼
¼ log f yjbθML


þ log exp 1
2 θ  bθML

0
IbθML θ  bθML


	

¼
¼ log f yjbθML


exp 1
2 θ  bθML

0
IbθML θ  bθML


	



Now, to approximate P(y | M) we will take a vague prior for the parameters; we
will take f(θ) ¼ 1. We will simplify the notation and take bθML ¼ bθ
P yjM
ð
Þ ¼
R
f yjθ
ð
Þ  f θ
ð Þdθ ¼
R
f yjθ
ð
Þdθ  f yjbθ



R
exp 1
2 θ  bθ

0
Ibθ θ  bθ


	

dθ  f yjbθ


 2π
ð
Þp=2 Ibθ


1=2 R
1
2π
ð
Þp=2 Ibθ


1=2 exp 1
2 θ  bθ

0
Ibθ θ  bθ


	

dθ
The integrand is a Normal density function, and the integral of a probability
density function from 1 to 1 is equal to 1; therefore,
log P yjM
ð
Þ  log f yjbθ


 2π
ð
Þp=2 Ibθ


1=2
	

 log f yjbθ


 2π
ð
Þp=2 n
ð Þp=2 1
nIbθ


1=2
"
#
 log f yjbθ


þp
2log2π  p
2log n
ð Þ  1
2log 1
nIbθ


For large samples (n!1),
Appendix 10.4
245

logP yjM
ð
Þ  log f yjbθ


 p
2 log n
ð Þ
2logP yjM
ð
Þ  2log f yjbθ


þ plog n
ð Þ
References
Bernardo JM (2005) Reference analysis. In: Dey DK, Rao CR (eds) Handbook of statistics, vol 25.
Elsevier, Amsterdam, pp 17–90
Bernardo JM, Smith FM (1994) Bayesian theory. Wiley, Chichester
Blasco A, Piles M, Varona L (2003) A Bayesian analysis of the effect of selection for growth rate
on growth curves in rabbits. Genet Sel Evol 35:21–42
Burnham KP, Anderson KR (2002) Model selection and multimodel inference. Springer,
New York
Edgeworth FY (1908) On the probable error of frequency constants. J R Stat Soc 71:381–397,
499–512, 651–678, Addendum in 1908, 72:81–90
Fisher R (1925) Theory of statistical estimation. Proc Camb Philos Soc 22:700–725
Hald A (1998) A history of mathematical statistics from 1750 to 1930. Wiley, New York
Johnson DH (1999) The insigniﬁcance of statistical signiﬁcance testing. J Wildl Manag
63:763–772
Kass RE, Adrian ER (1995) Bayes factors. J Am Stat Assoc 90:773–795
Kullback S, Leibler RA (1951) On information and sufﬁciency. Ann Math Stat 22:79–86
Shanon CE (1948) A mathematical theory of communication. Bell Syst Tech J 27
(379–423):623–656
Sober E (2016) Occam’s razor. Cambridge University Press, Cambridge
Sorensen DA, Gianola D (2002) Likelihood, Bayesian and MCMC methods in quantitative
genetics. Springer, New York
Spiegelhalter DJ, Best NG, Carlin BP, van der Linde A (2002) Bayesian measures of model
complexity and ﬁt. J R Stat Soc B 64:583–639
Stove D (1982) Popper and after: four modern irrationalists. Pergamon, Oxford
Wilks S (1938) The large-sample distribution of the likelihood ratio for testing composite
hypotheses. Ann Math Stat 9:60–62
246
10
Model Selection

Appendix: The Bayesian Perspective—Three
New Dialogues Between Hylas and Philonous
Preliminary Note
The dialogues between Hylas and Philonous were written by the Irish philosopher
Bishop Berkeley (to which a famous University owes its name), at the beginning of
the eighteenth century, in order to explain in an accessible way the philosophical
problems exposed in his book ‘A Treatise concerning the principles of Human
knowledge’. In his dialogues, Philonous expresses his doubts about our ability to
attain real and true knowledge of the world and even about the existence of a world
beyond that which is perceived through sensory impressions. For many years, a
favourite task of philosophers from all schools has been to refute Philonous, but the
arguments of this protagonist of the dialogues are much more difﬁcult to refute than
might appear at ﬁrst glance. Curiously, a refutation of Philonous is offered by Hylas
himself in three other dialogues that the well-known philosopher of science Mario
Bunge wrote to defend inductive methods in science (Bunge 1954). Induction is a
difﬁcult problem in philosophy, and a very important one because it is a key
concept to justify the scientiﬁc activity, as Bertrand Russell stressed (Russell
1912, chapter VI). The problem has not a straightforward solution, and depending
on how it is formulated, it has no solution at all, but due to its importance, several
philosophers have tried to ﬁnd rational bases for induction (see, for example,
Popper 1972, chapter I, and Stove 1986, chapters V to VII). In recent times,
Bayesian inference has been used to justify the principle of induction (Howson
2003), and a growing number of papers deal with the induction problem using
Bayesian techniques. Along this book, we have exposed the Bayesian inference
from a very practical point of view, sacriﬁcing the philosophical issues to useful
procedures, due to the scope of this book. This is appropriate because this is an
introductory book and also because the problem of induction is difﬁcult to expose
and discuss. Nevertheless, I have thought that the reader may be interested in how
classical statistics and Bayesian statistics face this problem. In order to avoid the
difﬁculties of the classical treatises of philosophy, I took the same procedure as
Berkeley and Bunge and prepared three new dialogues between Hylas and
Philonous. I have also placed the dialogues in the eighteenth century, at the time
in which Bayes principle was discovered.
# Springer International Publishing AG 2017
A. Blasco, Bayesian Data Analysis for Animal Scientists,
DOI 10.1007/978-3-319-54274-4
247

In the ﬁrst dialogue, Philonous studies the problem of induction, starting with
one of Hylas’ arguments contained in the third of Bunge’s dialogues, which hardly
seems convincing to him. In Hylas’ opinion induction is possible, for if it were not,
science and technique would not be possible either. Philonous makes him see that
the certainty of his scientiﬁc predictions is impossible, to which Hylas agrees
unwillingly, although he offsets Philonous’ argument quoting that at least our
knowledge of things is probable. Here follows an interjection about what we can
assume is probability, and Philonous, whose name means ‘linked to the mind’,
makes Hylas see that induction is only possible by considering probability as a
degree of personal belief. This surprises Hylas (whose name means ‘linked to
matter’), who thinks that a degree of personal belief is unacceptable to infer
something about Nature, but as the dialogue develops he realises the drawbacks
of considering probability in a way that is external to the investigator. Finally, he
accepts that probability can be deﬁned in the broad sense as this state of belief, but
he is worried about the consequences that might arise for science and the interpre-
tation of the world from transforming a tool, he thought was objective, into a scale
of doubt of a subjective kind. In the second dialogue, Hylas confesses to his friend
Philonous his uneasiness at not being able to escape from subjectivity when
occupied with something so apparently objective as science, and in particular, by
the need to refer to previous opinions about the results we are going to obtain, often
expressed in a vague way. However, Philonous makes him see that it is precisely
this use of previous information, even when it is irrelevant, which allows us to use
probability to determine the uncertainty associated with experiments, something
that is not possible using other theories. In the third dialogue, when it seems as
though all has been concluded, the induction problem solved, Hylas alerts
Philonous to the fact that methods of belief always end up by indirectly assuming
untested hypotheses. Philonous observes that Hylas’ reasons are valid, but also that,
in admitting them, although scientiﬁc activity would still be possible on a rational
basis, he still would not be able to resolve the induction problem. On parting, they
are both worried and promise to meet again to continue investigating the matter.
First Dialogue
HYLAS—Good morning, Philonous! What is the result of your meditations? Now
do you admit that we can perceive more than what our senses reveal to us? Or on the
contrary, do you still think that the material world is unknown to us?
PHILONOUS—I admit it, Hylas, and I also admit that we can conclude that
many years ago events of which no one was conscious took place, that we can build
entities just like irrational numbers, which no one has perceived, and that we have
innate information that does not come from our perceptions. But yesterday you
used, my dear friend, an argument that made me so uncomfortable that I have not
been able to get it out of my mind from the moment we parted. You told me that we
could infer a law of Nature through the induction of a great number of speciﬁc
cases.
248
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .

HYLAS—That is what I believe. How would science work otherwise? How
would it be possible for us to build bridges without uncertainty about whether they
are going to collapse, causing everyone on them to fall, were it not that our
experience showed us the conditions that made them safe? Could you live in the
doubt of whether the sun will shine tomorrow?
PHILONOUS—I understand, Hylas, the difﬁculties implied in denying your
reasoning, but I do not ﬁnd any problem in asserting that the sun may have already
disappeared and that we shall not know it until the few minutes its light takes to
reach us have expired. My faith in the new bridge not collapsing has not prevented
the falling of others, and I can only tell you that if I live without this sort of
preoccupations it is due to the fact that my Nature does not make me think of them,
and I act as if a knew for sure what I don’t know, not even as a probability, and I do
not get upset by thinking the Universe could end today or tomorrow. I do not
understand what rule, according to you, God has created so that upon listing several
particular cases we can make inferences about cases we do not even know about.
HYLAS—I admit, Philonous, that we cannot speak with the certainty of those
who have perfect knowledge of all the facts Nature provides, but you cannot deny
that we can qualify certain events as highly improbable.
PHILONOUS—I do not understand, Hylas, what you mean by the word
‘improbable’. Are you referring to the number of bridges that collapse with respect
to the ones that remain solid?
HYLAS—I ﬁnd your proposal quite shocking, and I think it is inspired mostly by
a game of irony, more than by a discussion that tries to illuminate the darkest
corners of these concepts; but even so I could accept what you say as an expression
of uncertainty regarding the doubt that a bridge will collapse.
PHILONOUS—And how many times has the sun exploded in order for us to be
able to calculate the probability that it will go up in smoke again?
HYLAS—You are joking Philonous, and I beg you to centre our conversation on
concrete examples to which I can give you an answer.
PHILONOUS—Following your reasoning, Hylas, few are the examples of doubt
to which we could apply probability. If we do an experiment to infer something or
other, how can we associate what is probable to the results if we have never seen in
how many cases our predictions have failed?
HYLAS—You can imagine you repeated that experiment an inﬁnite number of
times and that your result is one derived from one of the possible repetitions.
PHILONOUS—You ask for too much imagination, my friend Hylas. I beg you,
please give me an example of your mode of action because I ﬁnd myself a little
disoriented and I do not know how to infer general laws from things I have not
yet seen.
HYLAS—Let us suppose, Philonous, that I toss a coin into the air and I record
the results.
PHILONOUS—I accept the example, Hylas.
HYLAS—After repeating the same experiment several times, half the time you
will have got heads and the other half you will have got tails, to which I can say that
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .
249

we have a 50% probability of getting heads the next time we throw. There you can
see how I infer about things that I have not seen.
PHILONOUS—But if after one thousand repetitions, 60% of the time you got
heads and the other 40% you got tails, what would you say then?
HYLAS—I would without any doubt postulate the fact that the coin is rigged.
PHILONOUS—What would you say if I tossed the coin a million times and it
resulted in heads 55% of the time and in tails the rest of the time?
HYLAS—I would also say the coin is rigged.
PHILONOUS—Then the only possible deﬁnition for a coin is ‘that object which
is thrown in the air and falls on the head’s side approximately half the time’, is that
not right?
HYLAS—I see Philonous that you are accusing me of introducing the deﬁned
into the deﬁnition, but it is not like that. What I am saying is that with my rigged
coin, getting heads 60% of the time and tails 40%, I can deduce what results I may
get in subsequent tosses, so I will then say that the probability of getting tales is only
0.4 if I obstinately continue to use it.
PHILONOUS—I have a feeling we shall reach a poor conclusion, Hylas, but I
would like you to please give me yet another example related to the laws of Nature.
HYLAS—Well now, suppose we are walking about the countryside, let us
imagine that I want to know how much a new-born piglet from Berkshire weighs.
I would get a good number of them, weigh them, and I would infer a general law of
Nature.
PHILONOUS—And how would you know that the real value is not very
different from the one you obtained?
HYLAS—Because if I repeated collecting and weighing the piglets an inﬁnite
number of times, all the values obtained would revolve around the true value.
PHILONOUS—Hylas, you are asking me to make conclusions based not only
on the values you obtained but also on those you could have obtained but did not.
Do you think it is wise and safe to draw conclusions about laws basing yourself on
something that you have not even done?
HYLAS—I draw no conclusions from experiments I have never done, but rather
from those I have done and my knowledge of what would happen if I repeated them.
PHILONOUS—Let us then suppose that you have used scales that can weigh up
to ten kg, and let us suppose that your values are all around one kilo; let us say they
were 0.6, 0.8, 1, 1.2 and 1.4 kg.
HYLAS—I would then conclude that the average weight is 1 kg.
PHILONOUS—But, what would you say if I told you that the scales are broken
and you cannot weigh anything heavier than 1.4 kg?
HYLAS—Then I would have to increase my estimation, because if I had
repeated the experiment many times, I would have got values higher than 1.4 kg
which I would have been unable to detect.
PHILONOUS—But then if our friend Bishop Berkeley were to tell us that he
had ﬁxed the scales without me noticing, what value would you assign to the weight
of our new-born in Hampshire?
HYLAS—Again, without doubt, 1 kg.
250
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .

PHILONOUS—Which means that you are modifying the value of your infer-
ence, not based on facts from your experiment, which never exceeded the value that
was apparently on the broken scales, but rather on the basis of the experiments that
you could have carried out but never did. And do you think that any wise man
should proceed by basing his inference on the imaginary results of experiments that
have never taken place?
HYLAS—I have seen very talented men proceeding in that way, and you cannot
blame anyone if they have been informed by an insuperable error as to what results
they can expect.
PHILONOUS—Let’s set another example: How can you associate probabilities
with facts like, for example: it might rain tomorrow; new worlds may be discov-
ered; the enterprises in which we invest will prosper? How can we know if the
decisions taken at a crucial moment are going to be the right ones?
HYLAS—I have no clue, and I don’t think anybody on this earth has a solution
to that.
PHILONOUS—Consider, Hylas, that we can determine the uncertainty by
expressing our degree of belief that an event will occur, or our opinion about the
value that such a character as the weight of the newly-born piglets will receive.
HYLAS—I do not understand what it is you are proposing, Philonous. Do you
want me to assign values to my beliefs in such a way that they obey the laws of
probability?
PHILONOUS—That is what I pretend, and nothing else. I am sure that before
weighing those piglets you did not believe they could weigh ten kilos, nor even ten
grams. Assign, then, a value to your beliefs and we shall then see the results of the
experiment.
HYLAS—I ﬁnd what you propose highly irregular, Philonous. I may have some
beliefs whilst you have others, and how ever many times we mix them with the
results from an experiment they shall always end up being our personal beliefs,
nothing solid on which to base an inference.
PHILONOUS—I want to make you realise, Hylas, that the experiments are not
so conclusive, at least not usually, as to conﬁrm or refute a theory, or even in many
cases to be able to achieve a precise measurement. And I also remind you that we
submit every result to discussion and to personal interpretations.
HYLAS—But at least we can separate what facts we have from what we
later add.
PHILONOUS. And what attitude would you adopt if the facts told you that the
piglets of your experiment weighed thirty kilos when born? Wouldn’t you at least
be doubtful of the prediction of your scales?
HYLAS—Your question has an implicit answer, but I do not know in what way
that modiﬁes my argument.
PHILONOUS—And what if you were to comment on the weight of the piglets
with the farmers of the region and they were to tell you that they weigh much less
than what has been seen on other occasions, what would you say then?
HYLAS—I do not have an answer for I did not do the experiment, but I suppose
that I would conclude to the fact that the piglets I weighed were ill, or I would reach
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .
251

some similar sort of conclusion that would permit me to explain the anomaly in my
facts.
PHILONOUS—And what if I were to tell you that the information you got from
some of the farmers isn’t reliable, because they are all a bunch of rascals and like to
laugh at city people; or because they are all completely stupid and would not know a
scale any better than their own pigs would?
HYLAS—It is obvious, in that case, that I would give very little credit to their
afﬁrmations, whilst I would do the contrary with those farmers whom I could trust.
PHILONOUS—And wouldn’t you then, my good Hylas, be concluding from
earlier information, subjectively evaluated, and not from your facts?
HYLAS—That’s how I would be doing it, but I still insist that I would then
separate what my opinions are from what I add, meaning the facts that I obtain from
my personal interpretation.
PHILONOUS—I do not understand very clearly what is the purpose of this
separation if you are not going to use it later on. But let us return to my original
argument: if you want to know how very probable your results are, you need to use
some sort of subjective evaluation of that probability.
HYLAS—I have already told you before what I understand to be probability and
how I would evaluate the uncertainty of my experiment, and I have not needed to
recur to my personal world for it, but instead I have talked to you about objective
measures.
PHILONOUS—I see that my criticising your method has made very little
impression. But what would you say if I concluded that your probability is a
particular case of this much bigger one that I propose?
HYLAS—They worry me, Philonous, all these things you tell me, and you must
let me reﬂect upon them, for it is the ﬁrst time I am faced with such a surprising fact
as that probability could be a state of my opinion and not something that remains
detached from me, which is was I have thought up to now.
PHILONOUS—I ﬁnd it more surprising the way you mentally repeat an experi-
ment. And what to say about your probabilities when I apply them to astronomy or
to other events that tomorrow brings.
HYLAS—But it is true that we accept in a more comfortable manner the
difﬁculties in a theory we were taught during our youth, and that we live with
them with the same ease as we do with problems that our relatives cause, consider-
ing them an inevitable product of fate and accepting them with resignation and
patience, whilst we are more intolerant with the difﬁculties that new theories cause,
however much they are going to improve our life and our understanding of the laws
that govern Nature.
PHILONOUS—What you say is exact, Hylas, and I think it would be wise to
leave the discussion here so that your understanding may become accustomed to the
new concepts with which you have challenged it today. Contrary to what
philosophers would have us believe, reason is not a perfect machine that admits
anything new if the syllogism is correct, and I have seen many wise man wondering
around stubborn, ignoring good reasoning, until they were later permitted to change
252
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .

their way of thinking; and even then I am only referring to those cases in which
they did.
Second Dialogue
PHILONOUS—Good Morning Hylas, what has been the result of your reﬂections?
When I left you yesterday you seemed worried and I did not want to bother you
during the evening, engrossed as you were in your meditations. Do you now ﬁnd
Nature a little more intelligible?
HYLAS—Say no more, my friend, for I am making myself ill thinking that I
cannot infer anything real from the world and that all I have are the opinions of the
people I have spoken with! I thought that, if not with the certainty to which every
man aspires, I could at least assert that I observe things that exist and are not a part
of me. I thought that by means of experiment and skill I would be able to deduce the
laws that govern the world, and that way I would also understand more clearly the
Creator’s work and what His means and purposes were. Now I feel dismayed, for I
can only count on the beliefs of my neighbours, without anything outside of each
man to help me explain the causes of things.
PHILONOUS—Hylas, speaking to you tires me (and I beg you, do not feel
offended, for you know I speak to you with the love of a friend), because you
consistently continue to doubt about the reality that surrounds you. Do you think by
chance that your neighbours are demented and they are going to tell you things that
make no sense as soon as they meet you? Do you not see that one thing is that
probability may be subjective and another that it may not be reasonable?
HYLAS—But before I used to believe in the reality of things that I had to
estimate, and I knew a true and immutable value existed around which the data
obtained in my experiments would revolve. Now that value has disappeared, it no
longer exists, I no longer mention it, my afﬁrmations are now about the probability
you get one value or another, whilst the real value has disappeared!
PHILONOUS—It has not disappeared, although you are right when you say that
you no longer mention it. And why would you want to mention something that not
only is unknown, but that you are never going to know about anyway? What is the
use of referring to a value that is not only unknown but also unknowable? Yes, that
value exists, and it continues existing while you speak as I do, and it remains solid
and changeless in the same world as the Hampshire pig, the ideal jug, the young
man and the horses.1 I am simply speaking about the probability of a determined
weight when the pigs are born, and not about what would be this unknowable value.
1This last afﬁrmation refers to a passage in the Phaedo, Plato’s dialogue in which Socrates
establishes the world of ideas where the universals lie and of which the objects of the world are
imperfect copies. The only thing that does not ﬁt the passage is the ideal type of Hampshire pig,
which makes me suspect that this is an apocryphal addition.
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .
253

HYLAS—But earlier on I also wanted to talk about probabilities and you
forbade me.
PHILONOUS—You did not speak to me about the probability of the piglets’
weight being one or another, in light of the sample, but instead you spoke to me
about what probability there was that this sample would take on this or that value.
And if I have to be frank, then I do not understand why you have so much interest in
knowing what the probability of your sample is instead of worrying about the
essence and the core of the problem; meaning what probability there is for the
weight of the new-born piglet to adopt this or that value. And I made you realise,
Hylas, that the only way you can talk about probability being associated with your
facts is by considering previous probability, the one that your observations gener-
ate, and ﬁnally the one that results from combining both.2 Your afﬁrmations cannot
be linked to probability in any other way.
HYLAS—Well, then what value will my predictions have? Do you not realise
that if I gave my opinion a priori a high category, the result would be determined by
that opinion which I have introduced? Do you not see that in this manner I could
communicate to the Royal Society whatever result I wished?
PHILONOUS—I operate on the premise that you are an honest man and that
your previous opinion is not inﬂuenced by your interests. But in any case, Hylas, tell
me, if you are so sure of your previous opinion, why do you want to do this
experiment?
HYLAS—I do not know what it is you are trying to say.
PHILONOUS—What I want to say is that if your previous opinion has a high
probability, there is no reason for you to carry out an experiment, for the only thing
you would get out of it would be to reduce your property without your knowledge
growing or being any different from that which you had before beginning. Only
when your opinion a priori is uncertain is when it is worth looking for evidence in
Nature that corroborates or disproves the ideas that roam around in your head.
HYLAS—It might be that I am interested in conﬁrming something that I am
already very sure of.
PHILONOUS—You contradict yourself, Hylas; if you are already very sure
about it then no experiment on earth can take that security away from you, and if
there is an experiment capable of it, then your previous opinion is not as ﬁrm as you
tried to convince me it was.
HYLAS—I accept what it is you are telling me, but I still have another objection.
If I should only conﬁrm my opinion when it is indistinct, then what do I get out of
that opinion? What is the use of me having a theory that unites previous opinions to
facts, if I am later only going to use it if the previous opinion lacks in value?
2This is a reference to the Bayes theorem, which had not been published at the time in which this
dialogue takes place (it was published posthumously in 1780). However, Stigler (1983) has
pointed out that the theorem in question was known much before, and it was included in a book
published in 1750, in which the author indicates that it is borrowed from ‘an ingenious friend’.
254
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .

PHILONOUS—You are exaggerating, Hylas. It is one thing that previous
opinion dominates and another that it cannot be combined with the one that the
facts give you, for what it is worth. In any case, if this makes you feel uncomfort-
able, I would suggest that you collect as many facts as possible so that the previous
opinion does not have any inﬂuence on your result.
HYLAS—What you propose, Philonous, is not consistent with your approaches.
For, what advantages will I obtain from your ways of procedure if I then have to
ignore my previous opinions? Why all the commotion if I then have to do all that is
possible for my previous opinion not to be taken into account? You speak of the
superior coherence of your system, of its beauty, of its simplicity; and you then
propose that I ignore the principal part on which its beauty it based, that is, the
combination of probabilities pre and post experiment.
PHILONOUS—I am not telling you to abandon these previous probabilities, I’m
only telling you that if you feel insecure about how you should express them and
you prefer to trust the information that your facts give you, then you have a way of
doing it.
HYLAS—I confess to you, Philonous, that this way your system loses a good
part of its charm. I then do not know what I am to gain, if in the end the facts are
going to be the ones who drag me out of my ignorance.
PHILONOUS—Facts are always the ones to drag us out of our ignorance,
whether they be facts that we obtain or facts that were obtained by others before
us. Our opinion a priori should not be partial, unfounded or moved by interest, but
rather it should be such that various wise men could embrace it, within the
uncertainty with which we must necessarily express it.
HYLAS—And isn’t it better to be dragged out of your ignorance by the facts of
your experiment than by that vague idea of probability a priori, which appears to be
nothing more than the blurry outline of an intangible spirit?
PHILONOUS—I insist, Hylas, that probability a priori is necessary to construct
the inference. You cannot say that you choose the most probable hypothesis without
even speaking about it. This is not a perversion of my system but rather an
obligation of the laws of probability.
HYLAS—I can choose the hypothesis which makes my facts more probable, so I
do not need to talk about probabilities a priori.
PHILONOUS—I do not understand what it is you mean by this.
HYLAS—What I’m trying to say is that among two or more alternative
hypotheses, I would choose the one that made it more probable for me to obtain
the facts that I had already obtained.
PHILONOUS—And what are the advantages you see in this procedure? Why do
you think it is more reasonable to choose the hypothesis that makes the facts you are
going to obtain more probable?
HYLAS—I see it as intuitively reasonable. It doesn’t seem adequate to sustain it
was highly improbable that the facts I obtained were going to appear.
PHILONOUS—Hylas, you are not choosing the hypothesis that makes your
sample more probable; you are choosing the hypothesis that if it were right, it
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .
255

would give you the data you obtained with the maximum probability, which is not
the same thing.
HYLAS—I do not see the importance of such a nuance.
PHILONOUS—I shall set an example. Suppose you want to estimate men’s
stature in Scotland, and for this you take the height of just one Scotsman, and his
height is 1.60 metres.
HYLAS—I think your sample is a little lacking, but let us continue. I’d say that
the hypothesis that would make that fact the most probable would be that the
average height of the Scottish was 1.60. If it were like that, then to obtain this
data would be the most probable fact. If the Scottish were dwarfs whose height only
reached a metre, obtaining a Scotsman of 1.60 metres would be highly improbable,
and I don’t know why I should sustain that I obtained a highly improbable fact if the
way I moved was by choosing a man at random.
PHILONOUS—I want to make you realise that you have once again said if it
were like that, which means that in reality you don’t know if it is that value which
makes your fact more probable or not.
HYLAS—I am conscious of this limitation, but even so, I do not understand why
I should sustain that the average height of Scottish men is two metres, or a metre-
ﬁfty.
PHILONOUS—Hylas, the hypothesis that makes your only fact the most prob-
able is that ALL Scottish are 1.60 metres tall. This and no other is the hypothesis
that makes your sample more probable, for sustaining that there are Scottish with a
height different from 1.60 makes it more improbable to ﬁnd a Scottish man of that
stature than if the totality of them are this height.
HYLAS—Are you joking, Philonous? Saying that the Scottish are not men but
rather machines designed by some evil spirit, enemy of delicacy in the arts and the
perfection in music?3 How can you expect me to sustain something so absurd as that
every Scotsman is the same height as his neighbour?
PHILONOUS—And how do you know that the Scottish are men, and that their
stature should vary, and that it is not to be expected to ﬁnd in Nature the uniformity
that can’t be found in other places? You are not, by any chance, using any
information a priori?
HYLAS—And even if it is so, which it obviously is, it only intervenes in my
inference by making me lay aside any absurd hypotheses.
PHILONOUS—Making you discard them, or giving them zero a priori proba-
bility, which is the same thing. It is an extreme example, but it can make you realise
that only by choosing the hypothesis that, if it were right, makes your facts more
probable, it is not sufﬁcient for inference. Only when this hypothesis is considered
by probability a priori can you choose what you really desire; that is, the most
probable hypothesis given the facts you have.
HYLAS—What you say is all right for choosing among conﬂicting hypotheses,
but only once we have established the frame we move within, this meaning that the
3We infer that Hylas is English.
256
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .

Scottish are people and that people’s height varies, and it is as likely to ﬁnd Scottish
people that are taller and others that are shorter than the average, I think I can
choose for the height of the Scottish the value that makes it more probable that I
found my facts and not others.
PHILONOUS—You mean the value that, in the case that this value is the true
one, would make it more likely for you to ﬁnd the data you obtained.
HYLAS—Yes, Philonous, that is what I want to say; you have made me realise
this on various occasions.
PHILONOUS—But then you ﬁnd yourself in the same situation. Imagine that
the Scottish man you found was two metres tall, would it be reasonable to assume
they are giants?
HYLAS—It is very improbable that I were to ﬁnd a value like that picking a
Scottish man at random.
PHILONOUS—That is precisely what I want to make you realise. Your system
has the defect of it only making your sample more probable in the case of the true
value being the one you obtained. To avoid the terrible starting point of your
inference, ‘in the case of’, there is a need to weigh that ‘case’ for its probability,
and only then will we have a sensible inference.
HYLAS—I would agree if, in fact, we were weighing each case for its probabil-
ity, but this is not your procedure, that probability which you are considering is not
really the probability in each case but rather your previous opinion. I do not want
my experiment to be inﬂuenced by my prejudgements to such an extreme. I am
willing to ignore from the outset how tall I expect the Scottish to be, and for me
whatever value that can be imagined has in principle the same probability.
PHILONOUS—I do not ﬁnd that way of acting intelligent, but even so I could
still tell you that thanks to that constant probability that you have marked a priori,
you can talk about how probable it is that the Scottish are or are not two metres tall
on the average.
HYLAS—I do not want absurd conclusions, Philonous. I would say that in this
case a single Scottish man is not enough for my purposes and I need to record a
larger number so as to not depend on my prejudgement.
PHILONOUS—That is why earlier on I was telling you that if you were so
worried about not depending on your previous opinions, you should get hold of as
many facts as possible so the previous opinion does not have any inﬂuence on the
result.
HYLAS—And if I have to ask you once again what it is I have to gain by
considering these previous opinions, when precisely what I am trying to do is to get
rid of them?
PHILONOUS—Well, even though you lose all previous opinions because they
are your facts and not those of others which are going to govern your results, you
gain a lot, Hylas, a lot more than you suspect. Now you can talk about what can be
the probability of the piglets’ weight being this or that value, of what probability
they have of being bigger than the piglets of any other breed; you can say that your
hypothesis A is twice more probable than your hypothesis B but ﬁve times less
probable than hypothesis C; in conclusion, you can express the uncertainty by
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .
257

means of probability and not by means of dark mechanisms that call on the place
occupied by ghostly samples that you never took and will never take.
HYLAS—I understand the advantages your method offers, but I still have some
doubts. What if the correct hypothesis were not to be found among the ones I am
now testing?
PHILONOUS—Hylas, we do not know which one is correct, nor can we know.
HYLAS—I understand you, but how can I assign a probability to other
hypotheses when the most highly probable one is not found among them?
PHILONOUS—Because the probabilities that you are comparing are relative.
You express your belief that one is more probable than the other, but your results do
not make any reference to other possible hypotheses that you have not yet consid-
ered. I see that your tendency to imagine what you don’t do; to take imaginary
samples, I’d say, makes you think that there are an inﬁnite amount of possible
hypotheses that you should consider. No, Hylas, you can only speak about what you
are actually speaking about, not about something you are not. Your comparisons
always refer to the hypotheses which concern you at that very moment, and the
probabilities they have refer to how much more probable one of them is with respect
to the other.
HYLAS—But if I were to consider a new hypothesis, then the probabilities of
the rest would be modiﬁed, isn’t that right?
PHILONOUS—That is so, although I do not know why this disturbs you.
HYLAS—The reason is obvious, Philonous, how is it possible that a hypothesis
has a probability of 60%, and that it turns into 40% once the other alternatives are
considered?
PHILONOUS—Once again you believe, Hylas, that probability is something
external, belonging to things, and not, as we had already agreed, the expression of
your opinion on this or that hypothesis. When you consider new alternatives, it is
logical that your degree of belief regarding the truth of one or another hypothesis is
modiﬁed.
HYLAS—But then I can’t establish my absolute probability, even though it is
subjective, of any hypothesis. When I say that its probability is 60% it is only an
illusion, for in reality my beliefs would be modiﬁed if I had sufﬁcient information,
and I would choose another hypothesis more appropriate to the state of things.
PHILONOUS—I don’t understand what you mean by absolute probability, nor
about not having enough information. That is not the way we behave when we want
to discover the state of Nature. If we had such sufﬁcient information, I can’t see the
reason for doing experiments.
HYLAS—You do not convince me, Philonous, but attribute that to the limits
that God imposed on my knowledge or to the difﬁculty with which things new to us
settle on our spirit. I do not wish to carry on with this problem because I want you to
give me an answer to yet another difﬁculty I have seen in your doctrine. What
happens when we have a complete lack of previous information? If I understand
correctly, whether it be a little or a lot, it is essential if we wish to talk about
probability.
258
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .

PHILONOUS—You put me in an awkward position, Hylas, since I do not know
when you have heard of absolute ignorance with respect to the laws of Nature.
Quite a novel experiment this is! In that case I would recommend that you say that
all previous alternatives have the same probability.
HYLAS—It doesn’t seem to me, Philonous, as if it is the same thing to say that I
do not know something as to say that all the alternatives have the same previous
probability. If I have a bag in which my servant has put black and white balls, not
knowing in what proportion, I do not believe that taking out a white ball or taking
out a black ball has the same probability. That will depend on what the true
proportion is.
PHILONOUS—You are not talking about what the real proportion is, but rather
about your opinion a priori.
HYLAS—Even so I do not see why my opinion a priori should be the one that
considers all probabilities to be equal. This procedure looks more to be indifference
than ignorance.
PHILONOUS—In that case try various previous opinions, and if you have
sufﬁcient facts, then they will not affect the ﬁnal result, which means you rid
yourself of the problem because you know then that the opinions a priori are not
going to inﬂuence your declarations.
HYLAS—I am still left with one doubt, Philonous. When I want to discover
various things at the same time (for example, what the value of this or that character
is, what the relation between the two is) and I apply this to many characteristics of
an animal, how shall I be able to express my previous opinion? My brain is
insufﬁcient for imagining how much a piglet could weigh if the mother had a
small or large litter and at the same time they were fed in a special way, one way or
another, and examining all the variants and relationships among characters, giving
my opinions for each case. This is too greater a demand on me and I am afraid that it
would easily result in contradictions.
PHILONOUS—I understand you Hylas, and in this case I cannot think of any
other means except trying various opinions once again and waiting for the facts to
make them unnecessary.
HYLAS—But in this case I ﬁnd myself incapable of expressing those opinions,
Philonous!. It is not that I refuse to compare various previous opinions, it is that I do
not know how to express them with exactitude.
PHILONOUS—This is a difﬁcult problem, and I can only recommend you do
what you can starting from different bases. For example, on one hand you can
sustain that all the values have the same probability a priori, and on the other you
can establish separately the previous opinions for each character, as if they were
unrelated. You can sustain that the characters are related in a somewhat vague and
more or less arbitrary way. If the results in the end are the same ones, it is difﬁcult to
sustain that the previous opinion had any value, for you started with different bases
to construct each opinion a priori.
HYLAS—Once again I feel your theory loses its charm, Philonous. Although I
admit, and this is how I mean it, that is not just a small advantage that we can still
operate within this world of probabilities to express uncertainty.
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .
259

PHILONOUS—This is also how I see it. And let me show my satisfaction for
having persuaded you of the great compensation we obtain, even though we pay for
it with lack of precision in our procedure.
HYLAS—So then it seems like God did not create a perfect world in which we
could decide without erring in how to behave. But I feel satisﬁed with this,
Philonous, so let us retire now, for the sun is about to set and we are still quite a
walk from our homes.
Third Dialogue
PHILONOUS—Good morning, Hylas. I hope you are feeling better and that you
can enjoy this clean daybreak, so unusual in the hills of Cotswold, and the beauty of
our cathedral lighted by the ﬁrst rays of the sun whose loyalty we have so much
doubted in these last few days.
HYLAS—Good morning, Philonous. I have brought something positive with me
taken from our conversations, and it is the thankfulness to God for allowing the sun
to shine as we expected, in spite of our doubts regarding it. Although I must confess
that it worries me to not be able to know the nature of things as something certain,
but rather as something probable. It is as if reality were seen straining through a
mist, or as if we were blind and needed a guide in order to situate ourselves in the
world that surrounds us.
PHILONOUS—But you must think, Hylas, that that probability is continually
nearing certainty. Once you have carried out your experiment, your state of beliefs
is new and different from the one you had before starting the task. You have less
important doubts and your knowledge is more precise. And that is the state of
opinion that you or others shall use in future experiments, if they feel the need to
better specify their uncertainty.
HYLAS—You mean that with time, I and others more fortunate than myself will
improve our knowledge and extinguish our ignorance little by little. If I understand
you correctly, after each experiment I can make the state of my beliefs more
accurate, and whenever I want to get closer to the truth I will make use of that
new state of beliefs as ‘a priori’ as in the process of inquiry, with which, God
willing, we shall be nearer the truth and the knowledge of the laws that govern
Nature.
PHILONOUS—That is the way I see it, and that is the way we can acquire
general knowledge from the particular facts we examine.
HYLAS—If you are right, you would have resolved the problem of induction,
which has preoccupied so many philosophers for so many centuries.
PHILONOUS—Well, now that we have resolved the problem of induction, let
us take pleasure today in delights nearer our senses and let us save our lucubration
for moments in which melancholy dominates our spirit. There is time for every-
thing, and good days not as many, so I propose, since you have already paciﬁed
your understanding, that we now excite what least depends on it.
260
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .

HYLAS—You are right, but for me to fully enjoy the pleasures that you are
suggesting, the premise that my understanding is paciﬁed must be an accurate one.
PHILONOUS—And is it not so? Or do you feel new doubts with respect to all
the things that we have so much discussed? Do you for any reason think you can be
an impartial judge of what you experience?
HYLAS—Have no fear, Philonous, for all of that is clear to me. What now
worries me is the way in which we have resolved the problem of induction. We
sustain that we can know the probability of an event, or that a variable takes on a
value, given on one hand the facts obtained in the experiment and on the other the
probability derived from our previous experience.
PHILONOUS—That is right, and even though this probability is subjective,
when the number of facts is large enough, your previous opinion must be irrelevant.
HYLAS—But there is still something that doesn’t quite ﬁt in the process. What
would happen if I had obtained the sample incorrectly? What if the facts did not
reﬂect the state of the population correctly? What would happen if they were not
distributed in the way I presumed? What would happen if my previous opinion,
shared by many other scientists, were to differ so greatly from the truth because of
my prejudgements, so common in men, that not even with a reasonably high
number of facts could I offset the mistaken opinion given by the experts?
PHILONOUS—Look, Hylas, you are letting yourself slide down the hill that
leads to scepticism, and from there to solipsism and later to melancholy there is a
short stretch.
HYLAS—Should I, then fool myself and say that I understand what I do not, and
admit that I ﬁnd reasonable what seems to me has faulty foundations?
PHILONOUS—No, no you should not, but neither should you ignore the limits
of human understanding. Probabilities a priori do not exist alone, ﬂoating on the
waves created by seas of opinions. All probability is based on certain hypotheses,
and so is this previous probability. In reality we should call it ‘probability a priori
given a series of hypotheses’, for only with regard to them is this probability
feasible.
HYLAS—But then the result of our inference is not a probability ‘given
experimental evidence’, but a probability ‘given experimental evidence and a
group of attached hypotheses’.
PHILONOUS—That is the way I understand it.
HYLAS—And how do you then say you have resolved the problem of induction,
if you have left it as intact as it was before starting your lucubration? It has
maintained its virginity if I am correct! How can you assert that Science already
has a ﬁrm base if it all depends on the truth of previous hypotheses, and this is a
truth that you are unaware of? How can you justify that your knowledge progresses
if its foundation is as fragile as the clay of the idol’s feet? Or is it that you have some
means of estimating the certainty of the hypotheses that accompany all your
reasoning?
PHILONOUS—Calm down, Hylas, for your own health comes before all else in
the world. I do not know how certain those hypotheses may be. However, if I
suspected that the sample was not taken properly or that the worker who weighed
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .
261

the pigs mixed up the facts, or did it badly out of spite because he had an unsettled
debt with me, then in such cases, I wouldn’t give credit to my results. If I did, it
would be because I was convinced that everything was done in an honest and
reasonable way. And science progresses that way, because I can choose between
rival theories even though they are conditioned by the veracity of those hypotheses,
for in the end the experimental evidence will make me lean towards one theory or
the other.
HYLAS—They seem to me like poor means for reaching such high objectives. If
science should progress on the basis of good faith, of the absence of unavoidable
error, of the correct interpretation of Nature, and of all that your hypotheses contain,
I wouldn’t tell you that I expect quick and constant progress, but rather ups and
downs, false starts and errors that should remain unsolved because we trust in the
fact that we did things correctly.
PHILONOUS—Having a way of discerning which theory we prefer is not a poor
result, although it is true that science is always conditioned by the veracity of those
hypotheses. In reality the sword of Damocles is always present, providing us with
mistaken hypotheses, but once we admit that they are the most reasonable we can
ﬁnd, we can activate our decision mechanism to make our estimations about all we
ﬁnd in Nature more precise, say how probable it is for one character to have this or
that value, and prefer this theory to that one based on how much more probable this
one is to its alternatives.
HYLAS—In how much more probable you think it is, you mean.
PHILONOUS—Of course Hylas, we have already agreed that probability is
nothing other than my state of beliefs.
HYLAS—That’s it, but I have the impression that it is so much our custom to
believe that probability is something objective and that it is outside us that upon
talking about how probable this or that hypothesis is, we will end up believing that
we are truly talking about objective probability and not about the state of our
opinion.
PHILONOUS—And
what
do
you
suggest?
That
scientists
send
their
declarations to the Royal Society using the phrase ‘my probability’? It would be
annoying and it would emphasise the author’s ego, something that a man of science
should always avoid.
HYLAS—Yes, but it wouldn’t give the impression of a detached objectivity.
PHILONOUS—Nor does it intend to. Insisting upon subjectivity would also
give the impression of something arbitrary being done, and we have already agreed
that subjectivity does not in any way imply arbitrariness if the scientist isn’t mad.
And this without taking into account that most of the time the facts dominate that
subjective previous opinion that so disgusts you.
HYLAS—I admit that science can progress, although I doubt that progress can
be so rapid and constant as the application of your principle seems to suggest, but
we have left the induction principle untouched. In reality no experimental evidence
can guarantee us proximity to the truth, for we depend on other hypotheses which
we do not know to be true.
262
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .

PHILONOUS—But you won’t deny that we have established a reasonable
behaviour that can be followed by all those men that are interested in learning
about the laws of Nature.
HYLAS—A behaviour that will produce good results because God won’t allow
it to be any other way, but not because it intrinsically guarantees an approximation
to the truth.
PHILONOUS—Hylas, you are adducing a comparison that could be quite
fortunate. Ethics without God are based on the behaviour that is most beneﬁcial
for the individual and the community. In the same way, scientiﬁc progress without
God would be based on the premise that a scientist’s behaviour will give results
which we consider, under certain hypotheses, to be more probable and better
adjusted to what we already know. In both cases the individual’s behaviour is
determined on uncertain, but experimental, bases.
HYLAS—I do not understand the comparison, Philonous, and I think it is
completely forced. With regard to ethics, I don’t know how you fuse the
individual’s and society’s beneﬁt, when they so often come into conﬂict; and
with regard to science, I can’t see what relation there is between the behaviour of
the scientist and what it is I am asking you: how can you guarantee that experimen-
tal evidence will lead you nearer to the truth?
PHILONOUS—Hylas, If you are so extreme then I shall say no, no I cannot
assure that experimental evidence will lead me nearer to the truth; nor can I assure
that you are here now and that I am not speaking to a ghost or I am immersed in a
dream without knowing it. I do not even know if I can talk appropriately like
myself, since I only have experimental evidence about myself!
HYLAS—I beg you not to feel offended, Philonous, my questions arise from my
perplexity and not from my desire to ridicule your answers. I wanted certainty and I
exchanged it with you for probability, and now I don’t even have the consolation of
reaching probable knowledge. How happy the monks must be, not having to doubt
anything and trusting in God to govern and resolve the course of their lives! Is it that
blind faith that deﬁnitively guides our belief that we know something?
PHILONOUS—Hylas, to begin to discuss something you must at least ﬁrst
assume that your interlocutor is truly present. To add hypotheses to our
experiments, taking for granted they hadn’t been sabotaged, the samples were
taken at random and no neglected risk was introduced, does not seem to me to be
paying a high price for the conclusions at which we will arrive. And if the result
permits you to act upon Nature and beneﬁt from it, if you can build bridges that
don’t collapse, if your crops yield more, if you can cure the ill, all of this indicates
that you cannot be too mistaken.
HYLAS—Yes, but ordinary practice does not require speculative knowledge.
You can believe that you are ill because bad humours take over your blood, and that
you shall recover by taking certain herbs; and if you take the right ones, health shall
return to your body, even though the causes of your illness might not have been the
ones you suspected. Using theories with scarce foundation because they work well
is like making children believe that the bogeyman exists just so they will eat their
soup. An engineer might not need anything more than rules he can keep in his
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .
263

memory, but a scientist is obliged to think in a different way and ask himself the
reasons for things he infers and for the decisions he takes.
PHILONOUS—I do not know if this world is made for you, Hylas, but I think
we have good reasons for behaving the way we do and believing in all that we
believe.
HYLAS—And what is the nature of those good reasons?
PHILONOUS—I couldn’t answer you now, Hylas. The happiness with which I
began the day has vanished, and I see that new matters must be submitted to our
reﬂection.
HYLAS—Then let us go down to the city, and we shall continue to deal with
these things another day. Let us free our bodies from their tensions since we cannot
do the same for our spirit. It has been said that the thinker should be frugal, and that
the intensity of thought always made the great geniuses forget their sustenance. I am
not one of them and I do not encourage you to be either.
PHILONOUS—Let us go then, Hylas, and leave the discussion for tomorrow.
264
Appendix: The Bayesian Perspective—Three New Dialogues Between Hylas. . .

References
Barnett V (1999) Comparative statistical inference. Wiley, Chichester
Bayarri MJ, Berger JO (2004) The interplay of Bayesian and frequentist analysis. Stat Sci
19:58–80
Bellhouse DR (2004) The Reverend Thomas Bayes, FRS: a biography to celebrate the tercente-
nary of his birth. Stat Sci 19:3–43
Berger JO, Sellke T (1987) Testing a point null hypothesis: the irreconcilability of P-values and
evidence. J Amer Stat Assoc 82:112–122
Berger JO, Wolpert RL (1984) The likelihood principle, Institute of Mathematical Statistics.
Lecture Notes—Monograph Series. Purdue University
Berkeley G (1713/1986) Three dialogues between Hylas and Philonous. Oxford University Press,
Oxford
Berkson J (1938) Some difﬁculties of interpretation encountered in the application of the
chi-squaretest. J Am Stat Assoc 33:526–542
Bernardo JM (1979) Reference posterior distributions for Bayesian inference. J R Stat Soc B
41:113–147
Bernardo JM (2005) Reference analysis. In: Dey DK, Rao CR (eds) Handbook of statistics, vol 25.
Elsevier, Amsterdam, pp 17–90
Bernardo JM, Smith FM (1994) Bayesian theory. Wiley, Chichester
Bernardo R (2016) Bandwagons I, too, have known. Theor Appl Genet 129:2323–2332
Bidanel JP, Blasco A, Gogue J, Lagant H (1996) Re´sultats de quatre ge´ne´rations de se´lection pour
le taux d’ovulation et la survie pre´natale chez des porcs de race Large White. Journe´es Rech
Porcine en France. 28:1–8. Janvier 1996. Paris
Bidanel JP, Ducos A, Groeneveld E, Gruand J, Lagant H (1992) Genetic variability of components
of litter size in French Large White gilts. 43rd annual meeting of the European Association for
Animal Production, Madrid, September 1992
Blasco A (2001) The Bayesian controversy in animal breeding. J Anim Sci 79:2023–2046
Blasco A (2005) The use of Bayesian statistics in meat quality analyses. Meat Sci 69:115–122
Blasco A, Argente MJ, Santacreu MA, Sorensen D, Bidanel JP (2001) Bayesian analysis of
response to selection for uterine capacity in rabbits. J Anim Breed Genet 118:93–100
Blasco A, Go´mez E (1993) A note on growth curves of rabbit lines selected on growth rate or litter
size. Anim Prod 57:332–334
Blasco A, Gou P, Gispert M, Estany J, Soler Q, Diestre A, Tibau J (1994) Comparison of ﬁve types
of pig crosses. I. Growth and Carcass traits. Livest Prod Sci 40:171–178
Blasco A, Martı´nez-A´ lvaro M, Garcı´a ML, Iba´~nez-Escriche N, Argente MJ (2017) Selection for
environmental variance of litter size in rabbits. Genet Sel Evol 49:48
Blasco A, Piles M, Varona L (2003) A Bayesian analysis of the effect of selection for growth rate
on growth curves in rabbits. Genet Sel Evol 35:21–42
# Springer International Publishing AG 2017
A. Blasco, Bayesian Data Analysis for Animal Scientists,
DOI 10.1007/978-3-319-54274-4
265

Blasco A, Santacreu MA, Thompson R, Haley C (1993) Estimates of genetic parameters for
ovulation rate, prenatal survival and litter size in rabbits from an elliptical selection experi-
ment. Livestock Prod Sci 34:163–174
Blasco A, Sorensen D, Bidanel JP (1998) A Bayesian analysis of genetic parameters and selection
response for litter size components in pigs. Genetics 149:301–306
Blasco A, Toro MA (2014) A short critical history of the application of genomics to animal
breeding. Livest Sci 166:4–9
Bolet G, Santacreu MA, Argente MJ, Climent A, Blasco A (1994) Divergent selection for uterine
efﬁciency in unilaterally ovariectomized rabbits. I. Phenotypic and genetic parameters. Proc.
5th World Congress on Genetics Applied to Livestock Production, Guelph, 1994, vol 19, pp
261–264
Bosanquet B (1911) Logic or the morphology of knowledge, vol 1, 2nd edn. Oxford University
Press, Oxford, p 354
Box GEP, Draper NR (1987) Empirical model-building and response surfaces. Wiley, New York
Bunge M (1954) New dialogues between Hylas and Philonous. Philos Phenomenol Res
15:192–199
Burnham KP, Anderson KR (2002) Model selection and multimodel inference. Springer,
New York
Carlin BP, Louis TA (2008) Bayesian methods for data analysis, 3rd edn. Chapman and Hall, Boca
Raton
Childers T (2013) Philosophy and probaility. Oxford University Press, Oxford
Clark SA, van der Werf J (2013) Genomic best linear unbiased prediction (gBLUP) for the
estimation of genomic breeding values. In: Gondro C, van der Werf J, Hayes B (eds)
Genome-wide association studies and genomic prediction. Humana Press, New York
Colombani C, Croiseau P, Fritz S, Guillaume F, Legarra A, Ducrocq V, Robert-Granie´ C (2012) A
comparison of partial leastsquares (PLS) and sparse PLS regressions in genomic selection in
French dairy cattle. J Dairy Sci 95:2120–2131
Copleston F (1946) A history of philosophy. Vol V: Hobbes to Hume. Search Press, London
Damgaard LH (2007) Technical note: how to use Winbugs to draw inferences in animal models. J
Anim Sci 85:1363–1368
de Finetti B (1937) La pre´vision: ses lois logiques, ses sources subjectives. Annales de l’Institut
Henri Poincaire´ 7:1–68. Translated in Kyburg HE, Smokler HE (1964) Studies in subjective
probability. Wiley, New York
de los Campos G, Naya H, Gianola D, Crossa J, Legarra A, Manfredi E, Weigel K, Cotes JM
(2009) Predicting quantitative traits with regression models for dense molecular markers and
pedigree. Genetics 182:375–385
Donkin WF (1851) On certain questions relating to the theory of probabilities. Philos Mag
1:353–368. 2:55–60
Edgeworth FY (1908) On the probable error of frequency constants. J R Stat Soc 71:381–397,
499–512, 651–678, Addendum in 1908, 72:81–90
Efron B, Hastie T (2016) Computer age statistical inference. Cambridge University Press,
New York
Eisenhart C (1947) The assumptions underlying the analysis of variance. Biometrics 3:1–21
Fernando RL, Garrick D (2013) Bayesian methods applied to GWAS. In: Gondro C, van der
Werf J, Hayes B (eds) Genome-wide association studies and genomic prediction. Humana
Press, New York
Fernando RL, Habier D, Stricker C, Dekkers JCM, Totir LR (2007) Genomic selection. Acta Agric
Scand A 57:192–195
Fienberg SE (2006) When did Bayesian inference become “Bayesian”? Bayesian Anal 1:1–40
Fisher RA (1912) On an absolute criterion for ﬁtting frequency curves. Messenger Math
41:155–160. Reprinted in Stat Sci 1997, 12:39–41
Fisher R (1921) On the “probable error” of a coefﬁcient of correlation deduced from a small
sample. Metron 1:3–32
Fisher R (1922) On the mathematical foundations of theoretical statistics. Phil Trans A
222:309–368
266
References

Fisher R (1925a) Statistical methods for research workers. Oliver and Boyd, Edinburgh
Fisher R (1925b) Theory of statistical estimation. Proc Camb Philos Soc 22:700–725
Fisher R (1935) The logic of inductive inference. J R Stat Soc 98:39–82
Fisher R (1936) Uncertain inference. Proc Am Acad Arts Sci 71:245–258
Fisher R (1950) Contributions to mathematical statistics. Wiley, New York
Fisher R (1959) Statistical methods and scientiﬁc inference, 2nd edn. Oliver and Boyd, Edinburgh
Forni S, Aguilar I, Misztal I (2011) Different genomic relationship matrices for single-step
analysis using phenotypic, pedigree and genomic information. Genet Sel Evol 43:1
Garcı´a ML, Argente MJ, Muelas R, Birlanga V, Blasco A (2012) Effect of divergent selection for
residual variance of litter size on health status and welfare. In: 10th World Rabbit Congress,
Sharm El-Sheikh, Egypt, 3–6 September 2012, pp 103106
Garcia M, David I, Garreau H, Ibanez-Escriche N, Mallard J, Masson JP, Pommeret D, Robert-
Granie C, Bodin L (2009) Comparisons of three models for canalising selection or genetic
robustness. In: 60th annual meeting of European Association for Animal Production. Spain,
Barcelona
Gauss CF (1809) Theoria motus corporum coelestium in sectionibus conicis solem ambientium
(trans: Davis CE, 1963). Dover, New York
Gelfand AE, Smith FM (1990) Sampling-based approaches to calculating marginal densities. J Am
Stat Assoc 85:398–409
Gelman A, Carlin J, Stern HS, Rubin DB (1995) Bayesian data analysis. Chapman and Hall,
London
Gelman A, Carlin JB, Stern HS, Dunson DB, Vehtari A, Rubin DB (2013) Bayesian data analysis,
3rd edn. Chapman and Hall, Boca Raton, FL
Gelman A, Rubin DB (1992) Inference for iterative simulation using multiple sequences. Stat Sci
7:457–472
Geman S, Geman D (1986) Stochastic relaxation, Gibbs distributions and the Bayesian restoration
of images. IEEE Trans Pattern Anal Mach Intell 6:721–742
Geweke J (1992) Evaluating the accuracy of sampling-based approaches to the calculation of
posterior moments. In: Bernardo JM, Berger JO, Dawid AP, Smith AF (eds) Bayesian statistics
4. Oxford University Press, Oxford
Gianola D (2013) Priors in whole-genome regression: the Bayesian alphabet returns. Genetics
194:573–596
Gianola D, de los Campos G, Hil WG, Manfredi E, Fernando RL (2009) Additive genetic
variability and the Bayesian alphabet. Genetics 183:347–363
Gilks WR, Richardson S, Spiegelhalter DJ (eds) (1996) Markov chain Monte Carlo in practice.
Chapman & Hall, London
Gion JM, Clutter AC, Nielsen MK (1990) Alternative methods of selection for litter size in mice: II
response to thirteen generations of selection. J Anim Sci 68:3543–3556
Goddard M (2009) Genomic selection: prediction of accuracy and maximisation of long term
response. Genetica 136:245–257
Goodman SN (1993) p-values, hypothesis tests and likelihood: implications for epidemiology of a
neglected historical debate. Am J Epidemiol 137:485–496
Habier D, Fernando RL, Dekkers JCM (2007) The impact of genetic relationship information on
genome-assisted breeding values. Genetics 177:2389–2397
Habier D, Fernando RL, Kizilkaya K, Garrick D (2011) Extension of the Bayesian alphabet for
genomic selection. BMC Bioinformatics 12:186
Hald A (1998) A history of mathematical statistics from 1750 to 1930. Wiley, New York
Hastings WK (1970) Monte Carlo sampling methods using Markov chains and their applications.
Biometrika 57:97–109
Henderson CR (1973) Sire evaluation and genetic trends. In: Proc. Anim. Breed. and Genet. Symp.
in honor of Dr. J. L. Lush. Blacksburg, Virginia, pp 10–41
Henderson CR (1976) A simple method for computing the inverse of a numerator relationship
matrix used in prediction of breeding values. Biometrics 32:69
References
267

Herna´ndez P, Guerrero L, Ramı´rez J, Mekkawy W, Pla M, Ari~no B, Iba´~nez N, Blasco A (2005) A
Bayesian approach of the effect of selection for growth rate on sensory meat quality of rabbit.
Meat Sci 69:123–127
Hernandez P, Pla M, Blasco A (1998) Carcass characteristics and meat quality of rabbit lines
selected for different objectives. II. Relationships between meat characteristics. Livest Prod Sci
54:125–131
Hill WG, Mulder HA (2010) Genetic analysis of environmental variation. Genet Res 92:381–395
Hill WG, Zhang XS (2004) Effects on phenotypic variability of directional selection arising
through genetic differences in residual variability. Genet Res 83:121–132 (Erratum 83, 160)
Hobert JP, Casella G (1996) The effect of improper priors on Gibbs sampling in hierarchical linear
mixed models. J Am Stat Assoc 436:1461–1473
Howie D (2002) Interpreting probability: controversies and developments in the early twentieth
century. Cambridge University Press, New York
Howson C (2003) Hume’s problem: induction and the justiﬁcation of belief. Oxford University
Press, Oxford
Howson C, Urbach P (1996) Scientiﬁc reasoning. The Bayesian approach. Open Court, Chicago,
IL
Hume D (1739) An enquiry concerning human understanding. Oxford University Press 1998
Iba´~nez-Escriche N, Garcia M, Sorensen D (2010) GSEVMv.2: MCMC software to analyze
genetically structured environmental variance models. J Anim Breed Genet 127:249–251
Iba~nez-Escriche N, Sorensen D, Waagepetersen R, Blasco A (2008) Selection for environmental
variation: a statistical analysis and power calculations to detect response. Genetics
180:2209–2226
Jeffreys H (1931) Scientiﬁc inference. Oxford University Press, Oxford
Jeffreys H (1939/1961). Theory of probabilities, 1st and 3rd edn. Clarendon Press, Oxford
Johnson VE (1996) Studying convergence of Markov chain Monte Carlo algorithms using coupled
sample paths. J Am Stat Assoc 91:154–166
Johnson DH (1999) The insigniﬁcance of statistical signiﬁcance testing. J Wildl Manag
63:763–772
Johnson
VE
(2013)
Revised
standards
for
statistical
evidence.
Proc
Natl
Acad
Sci
110:9313–19317
Kant E (1781/1998) Critique of pure reason. Reprinted in translation. Cambridge University Press,
Cambridge
Kass RE, Adrian ER (1995) Bayes factors. J Am Stat Assoc 90:773–795
Kempthorne O (1984) Revisiting the past and anticipating the future. In: Statistics: an appraisal.
Proc. 50th anniversary Iowa state statistical laboratory. The Iowa State University Press, Ames,
pp 31–52
Kendall MG (1961) Daniel Bernoulli on maximum likelihood. Biometrika 48:1–8
Kendall M, Stuart A, Ord K (1994) Kendall’s advanced theory of statistics, volume 1: distribution
theory. Arnold, London
Keynes JM (1921) A treatise on probability. Macmillan Publ. Co, London
Kullback S, Leibler RA (1951) On information and sufﬁciency. Ann Math Stat 22:79–86
Laplace PS (1774/1986) Memoir on the probabilities of the causes of events (Trad. by Stigler SM).
Stat Sci 1:364–378
Lecoutre B, Poitevineau J (2014) The signiﬁcance test controversy revisited. Springer, New York
Leonard T, Hsu JSJ (1999) Bayesian methods. Cambridge University Press, New York
Lo´pez de Maturana E, Iba~nez-Escriche N, Gonza´lez-Recio O, Marenne G, Mehrban H, Chanok SJ,
Goddard M, Malats N (2014) Next generation modeling in GWAS: a comparison study among
different genetic architectures. Hum Genet 123:1235–1253
Lundgren H, Canario L, Grandinson K, Lundeheim N, Zumbach B, Vangen O, Rydhmer L (2010)
Genetic analysis of reproductive performance in Landrace sows and its correlation to piglet
growth. Livest Sci 128:173–178
268
References

Martı´nez-A´ lvaro M, Herna´ndez P, Blasco A (2016) Divergent selection on intramuscular fat in
rabbits: responses to selection and genetic parameters. J Anim Sci 94:4993–5003
McGrayne SB (2011) The theory that would not die. Yale University Press, New Haven, NJ
Metropolis N (1987) The beginning of the Monte Carlo method. Los Alamos Sci 15(Special
Issue):125–130
Metropolis N, Rosenbluth AW, Rosenbluth MN, Teller NH, Teller E (1953) Equations of state
calculations by fast computing machines. J Chem Phys 21:1087–1092
Metropolis N, Ulam S (1949) The Monte Carlo method. J Am Stat Assoc 44:335–341
Meuwissen TH, Hayes BJ, Goddard ME (2001) Prediction of total genetic value using genome-
wide dense marker maps. Genetics 157:1819–1829
Mill JS (1848) On liberty. Reprinted in 2006 by Longman
Misztal I, Tsuruta S, Strabel T, Auvray B, Druet T, Lee DH (2002) Blupf90 and related programs
(bgf90). In: 7th world congress on genetics applied to livestock production, pages CD–ROM
Communication N 28–07
Mood AM (1950) Introduction to the theory of statistics. McGraw-Hill, New York
Mood AM, Graybill FA (1963) Introduction to the theory of statistics. MacGraw Hill, New York
Neyman J (1977) Frequentist probability and frequentist statistics. Synthese 36:97–131
Neyman J, Pearson E (1933) On the problem of the most efﬁcient test of statistical hypotheses. Phil
Trans R Soc 231A:289–337
Park T, Casella G (2008) The Bayesian LASSO. J Am Stat Assoc 103:681–686
Pearson K (1920) The fundamental problems of practical statistics. Biometrika 13:1–16
Pearson E (1962) Some thoughts on statistical inference. Ann Math Stat 33:394–403
Peiro´ R, Mercha´n M, Santacreu MA, Argente MJ, Garcı´a ML, Folch JM, Blasco A (2008)
Progesterone receptor gene as candidate gene for reproductive traits in rabbits. Genetics
180:1699–1705
Popper K (1934) Logik der Forschung. Springer
Popper K (1972) Objective knowledge. Oxford University Press
Press SJ (2002) Subjective and objective Bayesian statistics: principles, models, and applications.
Wiley, New York
Raftery AE, Lewis SM (1992) How many iterations in the Gibbs sampler? In: Bernardo JM,
Berger JO, Dawid AP, Smith AFM (eds) Bayesian statistics, vol 4. Oxford University Press,
Oxford
Ramsey FP (1931) Truth and probability. In: Braithwaite RB (ed) The foundation of mathematics
and other logical essays. Routledge & Kegan, London
Robert CP (1992) L’Analyse statistique bayesienne. Economica, Paris, France
Robert C, Casella G (2004) Monte Carlo statistical methods, 2nd edn. Springer-Verlag, New York
Robinson GK (1991) That BLUP is a good thing: the estimation of random effects. Stat Sci
6:15–51
Russell B (1912) The problems of philosophy. Williams and Norgate, London
SanCristobal M, Elsen JM, Bodin L, Chevalet C (1998) Prediction of the response to a selection for
canalisation of a continuous trait in animal breeding. Genet Sel Evol 30:423–451
SanCristobal-Gaudy M, Bodin L, Elsen JM, Chevalet C (2001) Genetic components of litter size
variability in sheep. Genet Sel Evol 33:249–271
Schwartz G (1978) Estimating the dimension of a model. Ann Stat 6:461–464
Sellke T, Bayarri MJ, Berger JO (2001) Calibration of P-values for testing precise null hypotheses.
Am Stat 55:62–71
Shanon CE (1948) A mathematical theory of communication. Bell Syst Tech J 27
(379–423):623–656
Sober E (2016) Occam’s razor. Cambridge University Press, Cambridge
Sorensen DA, Gianola D (2002) Likelihood, Bayesian and MCMC methods in quantitative
genetics. Springer, New York
Sorensen DA, Wang CS, Jensen J, Gianola D (1994) Bayesian analysis of genetic change due to
selection using Gibbs sampling. Genet Sel Evol 26:333–360
References
269

Spiegelhalter DJ, Best NG, Carlin BP, van der Linde A (2002) Bayesian measures of model
complexity and ﬁt. J R Stat Soc B 64:583–639
Stigler SM (1983) Who discovered Bayes theorem? Am Stat 37:290–296
Stigler SM (1986) The history of statistics: the measurement of uncertainty before 1900. Harvard
University Press, Cambridge, MA
Stigler SM (2013) The true title of Bayes’s essay. Stat Sci 28(3):283–288
Stove D (1982) Popper and after: four modern irrationalists. Pergamon, Oxford
Stove D (1986) The rationality of induction. Clarendon Press, Oxford
Student (1908) On the probable error of a mean. Biometrika 6:1–25
Tibshirani R (1996) Regression shrinkage and selection via the LASSO. J R Stat Soc B
58:267–288
Tribout T, Caritez JC, Gruand J, Bouffaud M, Guillouet P, Billon Y, Pe´ry C, Laville E, Bidanel JP
(2010) Estimation of genetic trends in French Large White pigs from 1977 to 1998 for growth
and carcass traits using frozen semen. J Anim Sci 88:2856–2867
Van Tassell CP, Van Vleck LD (1996) Multiple-trait gibbs sampler for animal models: ﬂexible
programs for bayesian and likelihood-based (co)variance component inference. J Anim Sci
74:2586–2597
Visscher PM (1998) On the sampling variance of intraclass correlations and genetic correlations.
Genetics 149:1605–1614
Visscher PM, Brown MA, McCarthy MI, Yang J (2012) Five years of GWAS discovery. Am J
Hum Genet 90:7–24
Vitezica ZG, Varona L, Legarra A (2013) On the additive and dominant Variance and covariance
of individuals within the genomic selection scope. Genetics 195:1223–1230
Vitezica ZG, Varona L, Elsen JM, Misztal I, Herring W, Legarra A (2016) Genomic BLUP
including additive and dominant variation in purebreds and F1 crossbreds, with an application
in pigs. Genet Sel Evol 48:6
Von Mises R (1928/1957) Probability statistics and truth. Macmillan Publ. Co, London
Wang CS, Gianola D, Sorensen DA, Jensen J, Christensen A, Rutledge JJ (1994) Response to
selection for litter size in Danish Landrace pigs: a Bayesian analysis. Theor Appl Genet
88:220–230
Wilks S (1938) The large-sample distribution of the likelihood ratio for testing composite
hypotheses. Ann Math Stat 9:60–62
Yang Y, Christensen OF, Sorensen D (2011) Analysis of a genetically structured variance
heterogeneity model using the Box-Cox transformation. Genet Res 93:33–46
Yates F (1990) Preface of statistical methods, experimental design, and scientiﬁc inference by
R.A. Fisher. Oxford University Press, Oxford
Zome~no C, Hernandez P, Blasco A (2013) Divergent selection for intramuscular fat content in
rabbits. I Direct response to selection. J Anim Sci 91:4526–4531
270
References

Index
A
Acceptance-rejection method, 98–100
Akaike Information Criterion (AIC), 233–237
Animal breeding programs, 155
B
Baby model
credibility intervals, 108
inverted gamma distribution, 105
joint posterior distributions (see Joint
posterior distributions)
mean, 107–108
median, 108
mode, 106, 117–118
student t-distribution, 104
vague informative priors, 112–114
Bayes A, 185–187, 189
Bayes B, 187–189
Bayes C, 188, 189
Bayes Cπ, 188, 189
Bayes factors (BF), 239
model selection, 224–226
test of hypothesis, 52–53, 56–57
Bayes theorem
Bayesian inference, 34–36
conditional distributions, 72–73
posterior distribution, 195–196
prior probability, 223–224
Bayesian inference, 1, 2
advantages, 36, 54, 61
Bayes theorem, 34–36
credibility intervals
guaranteed value, 46, 60
highest posterior density
interval, 44–45, 60
interval estimation, 55
marginalisation, 49–51
positive/negative probability, 45, 46
for ratio of levels, treatment, 48–49
relevance probability, 47
signiﬁcant differences, 55
similitude probability, 47–48, 60
frequentist properties, estimator, 55
Hylas and Philonous beliefs, 247–264
marginal posterior distributions, 57–61
mean, 42, 43, 62
median, 42, 44, 62–63
mode, 42–44, 63
prior information, 209–210
assumption, 203
Bernardo reference prior, 206–207
deﬁnition, 36
exact information (see Exact prior
information)
ﬂat priors, 40, 204–205
improper priors, 207
Jeffreys prior, 205–206
Mendel’s law of inheritance, 37
objective/noninformative priors, 40
principle of indifference, 40
standard errors, 37
state of beliefs, 39
statistics, 208
vague prior information (see Vague
prior information)
probability density, 40–42
random variable, 54
test of hypothesis
Bayes factors, 52–53, 56–57
model averaging, 53
model choice, 51–52
nested model, 52
with/without sex effect, 56
Bayesian Information Criterion
(BIC), 239–241
# Springer International Publishing AG 2017
A. Blasco, Bayesian Data Analysis for Animal Scientists,
DOI 10.1007/978-3-319-54274-4
271

Bayesian least absolute shrinkage and
selection operator (Bayesian
LASSO), 188–190
Bayesian statistics, 2, 3
Belgian Landrace cross, 58–59
Bernardo reference prior, 206–207
Best linear unbiased predictor (BLUP)
animal breeding programs, 155
animal breeding values, 21
in Bayesian context, 156–158
for genetic mixed model, 154
mixed model equations, 154–156
RR-BLUP, 183–185, 190–191
Binomial distribution, 232–233
BLUP. See Best linear unbiased predictor
(BLUP)
C
Canalising selection, residuals modelling
ﬁxed effects, 175
genetic effects, 176
heteroscedastic model, 175
marginal posterior distributions, 176–177
variance, 177
Central limit theorem, 28, 36, 171, 214–215
Conditional distributions
Bayes theorem, 72–73
ﬁxed effects model, 128, 131–135
genetic animal model, 152–154, 164
Gibbs sampling process, 91–92
of mean, 75–76
mixed model, repeated records, 143–144
of sample, 73
of variance, 73–75
Conﬁdence intervals (CI), 13–15
Conjugate density distributions, 113
Credibility intervals
Bayesian inference
guaranteed value, 46
highest posterior density
interval, 44–45, 60
marginalisation, 49–51
positive/negative probability, 45, 46
for ratio of levels, treatment, 48–49
relevance probability, 47
similitude probability, 47–48
posterior distributions, 72
Crossed entropy, 233
Cumulative distribution function, 80–81
D
Data augmentation, 160–163, 174
Density of heritability, 70
Deviance Information Criterion
(DIC), 237–239
Duroc cross, 58–59
E
Error of estimation, 16
Exact prior information
anti-Bayesian, 193
black and brown mouse, 194
posterior probability
ﬂat priors, 197–198
maximum likelihood method, 197
sample of, 195–196
uncertainty, 196
F
Fixed effects model
bias, 20
conditional distributions, 128, 131–135
conﬁdence interval, 126
conjugated prior, 123
continuous effect, 126
covariate, 125–126
distribution of effects, 18, 19
effect of parity, 120
improper priors, 121
intramuscular fat measurement, 124
inverted gamma distribution, 123
least square estimator, 132
marginal posterior distributions
ﬂat priors, 121, 122, 127–130
inferences, 123
vague informative priors, 122, 130–132
multivariate beliefs, 122
probability of relevance, 124
probability of similitude, 124
regression coefﬁcient, 120
residual variance, 126
sampling effect, 126
seasonal effect, 125
treatment effect, 119
true value, 20
unbiased estimators, 20
variance, 20
G
Genetic animal model
conjugated/ﬂat prior, 148
covariance, 146
genetic effect, 145–149
marginal posterior distributions, 149–154
permanent effect, 145
272
Index

prior information, 148
shrinkage effect, 145
variance, 148
Genetic value, 28
Genome wide association studies (GWAS),
182–183
Genomic selection
Bayes A, 185–187, 189
Bayes B, 187–189
Bayes C, 188, 189
Bayes Cπ, 188
Bayes L, 188–190
ﬂat prior, 181
genetic value, 180
GWAS, 182–183
linkage disequilibrium, 180
prior information, 181, 182
RR-BLUP, 183–185, 190–191
SNP, 178–180, 190–191
variance–covariance matrix, 181
Gibbs sampling process, 4
Baby model, 110–112, 114–115
conditional distributions, 91–92
convergence, 95
equal probability density, 93–94
features, 95–98
ﬁxed effects model, 129–130
mixed model, repeated records, 144
sampling error, 94
univariate distributions, 91
Gompertz curve, 168, 170
Growth curves, nested models
data augmentation, 174
ﬁtting residuals, 169, 170, 173
Gompertz curve, 168, 170
marginal posterior distributions, 171–173
relationship matrix, 174
weekly weights data, 169
GWAS. See Genome wide association studies
(GWAS)
H
Highest posterior density interval, 44–45, 60
I
Inverse probability, 2, 208
Inverted gamma distribution, 73–75, 83–84,
105, 115
J
Jeffreys prior, 205–206
Joint posterior distributions
Baby model
ﬂat priors, 109–112
of mean and variance, 105
mode, 105–106, 115–116
conditional distributions, 173
ﬁxed effects model, 127
genetic animal model, 150–152
mixed model, repeated records, 142–143
nested model, growth curves, 171–172
K
Kronecker product, 159
Kullback–Leibler distance, 232–233
Kullback–Leibler divergence, 232–233
L
Likelihood, deﬁnition, 22–24
Linkage disequilibrium phenomenon, 180
M
Marginal posterior distributions
Baby model
credibility intervals, 108
inverted gamma distribution, 105
joint posterior distributions (see Joint
posterior distributions)
mean, 107–108
median, 108
mode, 106, 117–118
student t-distribution, 104
vague informative priors, 112–114
Bayesian inference, 57–61
deﬁnition, 76–77
ﬁxed effects model
ﬂat priors, 121, 122, 127–130
inferences, 123
vague informative priors, 122, 130–132
genetic animal model, 149–154
histogram, 86, 87
inferences
guaranteed value, 89
probability counting, 88
relevant difference, 88–89
shortest interval, 89
MCMC methods
acceptance-rejection method, 98–100
Gibbs sampling, 91–98
Metropolis–Hastings method, 100–101
software, 101–102
mixed model, repeated records
conditional distributions, 143–144
Gibbs sampling, 144
Index
273

Marginal posterior distributions (cont.)
joint posterior distribution, 142–143
nested models, growth curves, 171–173
Normal distribution
of mean, 78–80
of median, 90
random samples, 86
sampling error, 87
of variance, 77–78
Marginalisation, 49–51
Markov chain Monte Carlo (MCMC) methods
acceptance-rejection method, 98–100
Gibbs sampling (see Gibbs sampling
process)
marginal posterior distributions
using ﬂat priors, 121, 122, 127–130
vague informative priors, 122, 130–132
Metropolis–Hastings method, 100–101
mixed model, 139
prior information, 207, 208
software, 101–102
Maximum likelihood (ML) estimator, 24–26,
29–30
MCMC methods. See Markov chain Monte
Carlo (MCMC) methods
MCSE. See Monte Carlo standard error
(MCSE)
Mendel’s law of inheritance, 37
Metropolis–Hastings method, 100–101
Mixed model, repeated records
ﬁxed effect, 141
ﬂat priors, 138, 140
marginal posterior distributions
conditional distributions, 143–144
Gibbs sampling, 144
joint posterior distribution, 142–143
MCMC methods, 139
parity effect, 138
prior information, 139, 140
random effect, 138, 141
season effect, 138, 141
variance, 140
ML estimator. See Maximum likelihood
(ML) estimator
Model selection
AIC, 233–237
BIC, 239–241
DIC, 237–239
differentiation, 242–243
ﬁtting data vs. new records prediction, 217–
218
hypothesis tests
Bayes factors, 224–226
frequentist tests, 221
likelihood ratio test, 221–223
prior probability, 223–224
likelihood curves
entropy, 231–232
Fisher’s information, 227–230
Kullback–Leibler discrimination
information, 232–233
maximum estimators, 226
Shannon information, 231
mean deviance, 244–245
model comparison, 241–242
Normal distribution
animal production, 214–215
coefﬁcient of determination, 220
cross-validation, 220–221
dead piglets, 218–219
food conversion, 214
growth rate, 214–215
noise effects, 215–216
non-Normal, 218–219
non-signiﬁcant effects, 219–220
parameters, 213–214
parsimony, 218, 220
probability density function, 214,
245–246
year-season effects, 216–217
Taylor’s expansion, 243
Monte Carlo standard error (MCSE), 109
Multitrait model
data augmentation, 160–163
ﬂat priors, 159
permanent effect, 160
vague priors, 159
N
Nested models, growth curves
data augmentation, 174
ﬁtting residuals, 169, 170, 173
Gompertz curve, 168, 170
marginal posterior distributions, 171–173
relationship matrix, 174
weekly weights data, 169
Normal distribution, 103
animal production, 214–215
coefﬁcient of determination, 220
cross-validation, 220–221
dead piglets, 218–219
food conversion, 214
growth rate, 214–215
noise effects, 215–216
non-Normal, 218–219
274
Index

non-signiﬁcant effects, 219–220
parameters, 213–214
parsimony, 218, 220
probability density function, 214, 245–246
vague prior information, 200
year-season effects, 216–217
Null hypothesis, 3–5
P
Popper theory of refutation, 3
Posterior distribution
Bayes theorem, 195–196
conditional distributions, 72–76
credibility intervals, 72
cumulative distribution function, 80–81
expectation/mean, 71
ﬂat priors, 197–198
marginal distributions, 76–80
maximum likelihood method, 197
median, 71
mode, 72
notation, 67–68
probability density function, 68–71
uncertainty, 196
Probability density function
auxiliary function, 40
bivariate distribution, 70
deﬁnition, 68
inference, 41–42
for liver ﬂavour intensity of meat, 69
mode selection, 214, 245–246
multivariate case, 70
R
Random effects model, 18–21
Relevance probability, 47
Relevant difference, 26–27
Repeated records, mixed model
ﬁxed effect, 141
ﬂat priors, 138, 140
marginal posterior distributions
conditional distributions, 143–144
Gibbs sampling, 144
joint posterior distribution, 142–143
MCMC methods, 139
parity effect, 138
prior information, 139, 140
random effect, 138, 141
season effect, 138, 141
variance, 140
Residual/restricted maximum likelihood
estimator (REML), 17–18, 158
Ridge regression/random regression BLUP
(RR-BLUP), 183–185, 190–191
S
Similitude probability, 47–48
Single Nucleotide Polymorphism (SNP), 178,
179, 190–191
Standard error, 13
Student t-distribution, 104
T
Test of hypothesis
error level, 7, 8
in experimental research, 12
model selection
Bayes factors, 224–226
frequentist tests, 221
likelihood ratio test, 221–223
prior probability, 223–224
non-signiﬁcant difference, 9, 11–12
null hypothesis, 4–5
P-value, 6–9
relevant value, 10, 12
scientiﬁc behaviour, 5
signiﬁcant difference, 9, 10, 12
Type I error, 6, 7
Type II error, 6
U
Unbiased estimators, 16–18
Univariate distributions, 91
V
Vague prior information
Baby model, 112–114
Bayesian paradigm, 203
conjugate distribution, 200
deﬁnition, 198–199
ﬁxed effects model, 129–130
inverted Wishart distributions, 202–203
MCMC methods, 122, 130–132
Normal distribution, 200
ovulation rate, pigs, 200–201
uterine capacity, rabbits, 201–202
Variance of error, 20–21
Index
275

