ChemCrow: Augmenting large-language models with
chemistry tools
Andres M Bran12∗
Sam Cox3∗
Andrew D. White3
Philippe Schwaller12
1 Laboratory of Artiﬁcial Chemical Intelligence (LIAC), ISIC, EPFL
2National Centre of Competence in Research (NCCR) Catalysis, EPFL
3 Department of Chemical Engineering, University of Rochester
∗Contributed equally.
{andres.marulandabran,philippe.schwaller}@epfl.ch
{samantha.cox,andrew.white}@rochester.edu
Abstract
Large-language models (LLMs) have recently shown strong performance in tasks across
domains, but struggle with chemistry-related problems. Moreover, these models lack
access to external knowledge sources, limiting their usefulness in scientiﬁc applications.
In this study, we introduce ChemCrow, an LLM chemistry agent designed to accomplish
tasks across organic synthesis, drug discovery, and materials design. By integrating
13 expert-designed tools, ChemCrow augments the LLM performance in chemistry,
and new capabilities emerge. Our evaluation, including both LLM and expert human
assessments, demonstrates ChemCrow’s effectiveness in automating a diverse set of
chemical tasks. Surprisingly, we ﬁnd that GPT-4 as an evaluator cannot distinguish
between clearly wrong GPT-4 completions and GPT-4 + ChemCrow performance. There
is a signiﬁcant risk of misuse of tools like ChemCrow and we discuss their potential
harms. Employed responsibly, ChemCrow not only aids expert chemists and lowers
barriers for non-experts, but also fosters scientiﬁc advancement by bridging the gap
between experimental and computational chemistry.
1
Introduction
In the last few years, Language Language Models (LLMs)1–5 have transformed various sectors by au-
tomating natural language tasks. A prime example of this is the introduction of GitHub Copilot in 20216,
which provides proposed code completions based on the context of a ﬁle and open windows that increases
developers’ productivity7. Most recent advances are based on the Transformer architecture8, introduced
for neural machine translation and extended to various natural language processing tasks demonstrating
remarkable few-shot and zero-shot performance2.
Nevertheless, it is crucial to recognize the limitations of LLMs, which often struggle with seemingly
simple tasks like basic mathematics and chemistry operations9. For instance, GPT-410 and GPT-3.511
cannot consistently and accurately multiply 12345*98765 or convert IUPAC names into the corresponding
molecular graph12 These shortcomings can be attributed to the models’ core design, which focuses on
predicting subsequent words. To address these limitations, one viable approach is to augment large
language models with dedicated external tools or plugins, such as a calculator for mathematical operations
or OPSIN13 for IUPAC to structure conversion. These specialized tools provide exact answers, thereby
compensating for the inherent deﬁciencies of LLMs in speciﬁc domains and enhancing their overall
performance and applicability.
Chemistry, as a ﬁeld, has been impacted through expert-designed artiﬁcial intelligence (AI) systems that
tackle speciﬁc problems, such as reaction prediction14–18, retrosynthesis planning19–25, molecular property
prediction26–30, de-novo molecular generation31,32, materials design33,34, and more recently, Bayesian
Preprint. Under review.
arXiv:2304.05376v1  [physics.chem-ph]  11 Apr 2023

Optimization35,36. Due to the nature of their training, it has been shown that code-generating LLMs
do possess some understanding of chemistry12. However, the automation levels achieved in chemistry
remain relatively low compared to other domains, primarily due to its highly experimental and occasionally
artisanal nature, as well as the limited scope and applicability of computational tools, even within their
designated areas37.
Integrating such tools tends to occur within closed environments, such as RXN for Chemistry16,22,38–40 and
AIZynthFinder23,41,42, facilitated by corporate directives that promote integrability and internal usability.
Nevertheless, although most tools are developed by the open-source community or made accessible
through application programming interfaces (API), their integration and interoperability pose considerable
challenges for experimental chemists, thereby preventing the full exploitation of their potential.
Figure 1: Overview. Using a variety of chemistry-related packages and software, a set of tools is created.
These tools and a user prompt are then given to an LLM. The LLM then proceeds through an automatic,
iterative chain-of-thought process, deciding on its path, choice of tools, and inputs before coming to a ﬁnal
answer.
Inspired by successful applications in other ﬁelds9,43,44, we propose an LLM-powered chemistry engine,
ChemCrow, designed to streamline the reasoning process for various common chemical tasks across areas
such as drug and materials design and synthesis. ChemCrow harnesses the power of multiple expert-
designed tools for chemistry and operates by prompting an LLM (GPT-4 in our experiments) with speciﬁc
instructions about the task and the desired format, as shown in Figure 1. The LLM is provided with a list
of tool names, descriptions of their utility, and details about the expected input/output. It is then instructed
to answer a user-given prompt using the tools provided when necessary. The model is guided to follow the
Thought, Action, Action Input, Observation format45, which requires it to reason about the current state of
the task, consider its relevance to the ﬁnal goal, and plan the next steps accordingly. Contemporaneously
with this preprint,46 describes a similar approach of augmenting an LLM with tools for accomplishing
tasks in chemistry that are out of reach of GPT-4 alone. Their focus is speciﬁcally on cloud labs, while
ours is on a large range of tasks and tools.
After the reasoning in the Thought step, the LLM requests a tool (preceded by the keyword "Action") and
the input for this tool (with the keyword "Action Input"). The text generation then pauses, and the program
attempts to execute the requested function using the provided input. The result is returned to the LLM
prepended by the keyword "Observation," and the LLM proceeds to the "Thought" step again.
This workﬂow, previously described in the ReAct45 and MRKL47 papers, effectively combines chain-of-
thought reasoning with tools relevant to the tasks. As a result, the LLM transitions from a hyperconﬁdent
–although typically wrong– information source, to a reasoning engine, namely it observers, reﬂects and acts.
We implemented 13 tools, including web search, literature search, molecule-speciﬁc and reaction-speciﬁc
tools, as shown in Figure 2 and described in Section 6.3. While we recognize the list of tools included is
not exhaustive, it can be easily adapted to new applications by providing the tool, along with a description
of its intended use, all through natural language.
ChemCrow serves as an assistant to expert chemists while simultaneously lowering the entry barrier
for non-experts by offering a simple interface to access accurate chemical knowledge. We analyze the
capabilities of ChemCrow on 12 use cases (see Appendix A.1), including synthesizing a target molecule,
safety controls, and searching for molecules with similar modes of action. However, it is important to
2

Figure 2: ChemCrow’s tool set. The general, molecule, and reaction tools implemented in ChemCrow.
The image in the center was generated using MidJourney.
emphasize that potential risks may arise for non-experts who lack the chemical reasoning to evaluate results
or the proper lab training, as conducting experiments still necessitates thorough laboratory experience.
2
Evaluation and results
In recent years, there has been a surge in the application of machine learning to chemistry, resulting in
a wealth of datasets and benchmarks in the ﬁeld48,49. However, few of these benchmarks concentrate
on assessing LLMs for tasks speciﬁc to chemistry, and given the rapid pace of progress a standardized
evaluation technique has not yet been established, posing a challenge in assessing the approach we
demonstrate here.
To address this issue, we collaborated with expert chemists to develop a set of tasks that test the capabilities
of LLMs in using chemistry-speciﬁc tools and solving problems in the ﬁeld. The selected tasks are executed
by both ChemCrow and GPT-4 (prompted to assume the role of an expert chemist), and these results are
evaluated with a combination of LLM-based and expert human assessments. For the former, we draw
inspiration from the evaluation method described in5,50,51, where the authors use an evaluator LLM that is
instructed to assume the role of a teacher assessing their students. In our case, we adapted the prompt so
that the evaluator LLM only gives a grade based on whether the task is addressed or not, and whether the
overall thought process is –or at least seems– correct. The evaluator is further instructed to highlight the
strengths and weaknesses of each approach. Full results for several tasks are presented in the Appendix
A.1, and one example is given in ﬁgure 3 below, where models are tasked with proposing a synthetic plan
for the drug atorvastatin.
The validity of the responses is limited by the quality of tools, tool usage is limited by reasoning process,
and the reasoning process is evaluated through the LLM evaluator. Therefore, we evaluate the LLM without
tools in terms of correctness by assessing the level of hallucination it produces compared to ChemCrow.
Similarly, we manually report scores between 1 and 10 focusing only on A. whether the response completes
the task and B. how correct the responses are. Aggregate statistics of this are presented in Figure 4.
The results show that ChemCrow vastly outperforms the plain LLM, especially on more complex tasks.
GPT-4 fails systematically to provide factually accurate information (average score of 4.79 versus 9.25
of ChemCrow), where most of the errors in our examples are either providing the wrong molecule name
or SMILES, or predicting the wrong reaction (see Appendix A.1). On the completion score, GPT-4 does
slightly better (6.87) than on facts, although still far below ChemCrow’s level (9.62), showing the efﬁcacy
of ChemCrow at solving chemical tasks.
This type of evaluation also reveals various interesting aspects regarding the chemical knowledge of LLMs,
that were not highlighted by the LLM-powered evaluation. As shown in in Figure 5 (an example output for
task 1), GPT-4 produces an overall wrong synthesis procedure for atorvastatin as it doesn’t lead to the ﬁnal
product. Additionally, some individual reactions make little sense, showing how the model struggles to
address what the current product is (e.g. proposing a Friedel-Crafts acylation while the current product
contains no aromatic rings). In this sense, ChemCrow gets highly ranked in our human evaluation while
3

Figure 3: Task 1. Synthesis Planning of Atorvastatin. Prompt (top) is given to both ChemCrow (left)
and GPT-4 (right), then outputs are given to a separate instance of GPT-4 for evaluation (bottom).
GPT-4 scores low. However, it is remarkable how the overall plan proposed by GPT-4 seems to address
the formation of the β,δ-dihydroxy acid from an early stage. Although failing to explain how to form
the t-butyl ester, GPT-4 also seems to suggest that this is the precursor of the carboxylic acid, which it
4

Figure 4: Score results. The results for each task are evaluated in three ways. On the top row, human
evaluators scored the outputs based on accuracy and completeness of task. Then, the results were evaluated
by an LLM-powered evaluator, based on quality and clarity of thought, as well as completeness (bottom
left). In this evaluation, both models are determined to perform equally. On the bottom right, average
scores are given for each evaluation method, showing that the LLM-powered evaluator scores the two
methods equally, while a large different exists for the human-evaluated correctness.
correctly hydrolyses as the ﬁnal step of the synthesis, in a similar fashion to ChemCrow’s proposal (drawn
from IBM’s RXN4Chemistry40). ChemCrow’s results, on the other hand, are limited by the quality of the
tools provided. The results could be improved by optimizing the underlying synthesis engine, an active
area of research52,53
Note the difference between the two subplots presented in 4, as the LLM evaluator concluded approximately
equivalent results for each method, which may contradict the human-evaluation results. By employing
an LLM-powered evaluator in the role of a teacher, we aimed to assess the performance of our proposed
approach in using chemistry-speciﬁc tools and solving tasks in the ﬁeld, demonstrating the capabilities of
these LLMs. However, an important and unexpected ﬁnding from these results is that GPT-4 is limited
when evaluating task solutions that it, by itself, cannot correctly address. When evaluating the tasks
provided, GPT-4 teacher concluded that the two methods were roughly equivalent on average. However,
the human evaluation showed that the quality of the responses was actually quite different, with the human
evaluation showing how ChemCrow vastly outperforms GPT-4 in chemical tasks. GPT-4 has been recently
presented and used as a self-evaluation method5,50, but these results indicate that when it lacks the required
understanding to answer a prompt, it also lacks information to evaluate the prompt completions and thus
fails to provide a trustworthy assessment, rendering it unusable for the benchmarking of LLM capabilities.
This –to some extent– success of GPT-4 says however little about its synthetic planning capabilities, as
atorvastatin is a well-known molecule with multiple synthetic routes described in the literature54, possibly
meaning that all the apparent knowledge shown here is the result of mere memorization. This hypothesis is
further supported by the success of GPT-4 at designing a synthetic plan for paracetamol (see Appendix
A.1), where the model can accurately describe the acetylation of p-hydroxyaniline as a possible synthetic
route.
5

Figure 5: Human analysis of GPT-4 (left) and ChemCrow’s (right) answer to task 1. GPT-4 provides
an overall wrong synthetic plan and shows a lack of awareness of current progress within the synthetic
campaign. The general plan can be a valuable insight, however it requires intense human interpretation and
might be a mere product of GPT’s memorization.
3
Risks and Mitigation Strategies
The implementation and use of LLM-powered chemistry engines, like ChemCrow, present potential risks
that must be acknowledged and addressed to ensure their safe and responsible application. We discuss the
key risks and propose possible mitigation strategies.
3.1
Dual Usage
As AI technology advances, addressing concerns related to dual usage, the potential for AI to be used for
both positive and negative purposes, becomes increasingly crucial. Previous reports55,56 have demonstrated
6

that technologies intended for beneﬁcial and impactful purposes, such as drug discovery, can be easily
repurposed for harmful applications, such as designing chemical weapons. Researchers have attempted to
align large language models (LLMs) with safety objectives, focusing on restricting potentially dangerous
or harmful information and behaviors. However, these safeguards become fragile when applied to systems
like ChemCrow, where providing tools and straightforward instructions can easily circumvent initial safety
measures. The high potential of ChemCrow, as demonstrated in this paper, can also be directed towards
malicious objectives with relative ease. For instance, a misuse case could involve developing a new
substance with a nerve agent (see Appendix 17). In this scenario, the current version of ChemCrow could
research the mechanism of action (MOA) of cyclosarin, identify similar molecules, modify them, and draft
an email to a custom synthesis company. This process could be further enhanced through more precise
speciﬁcations and prompt engineering. The resulting compound would be novel, and thus, no toxicity or
safety information would be available. Consequently, the custom synthesis company may not reject the
request, as conducting safety trials for all produced substances would be a signiﬁcant burden.
This situation highlights the substantial risks posed by increasingly powerful LLMs. While tools like
ChemCrow can contribute to scientiﬁc advancements, it is essential to implement additional measures to
mitigate potential threats and ensure the responsible development and use of AI technologies.
3.2
Unintended Risks
Safety concerns in laboratory settings, particularly for non-experts who lack proper lab training, present
another risk. Attempting to perform experiments based on the LLM-powered engine’s recommendations
may lead to accidents or hazardous situations. A possible mitigation strategy is to include clear safety
warnings and guidelines within the engine’s output, emphasizing the importance of proper lab training and
supervision. Furthermore, safety checks and expert review systems could be considered for integration,
ensuring that recommendations adhere to established safety standards and protocols.
Inaccurate or incomplete reasoning due to a lack of sufﬁcient chemistry knowledge in the LLM-powered
engine poses a signiﬁcant risk, as it may lead to ﬂawed decision-making or problematic experiment results.
One of the key points of this paper is that the integration of expert-designed tools can help mitigate the
hallucination issues commonly associated with these models, thus reducing the risk of inaccuracy. However,
concerns may still arise when the model is unable to adequately analyze different observations due to a
limited understanding of chemistry concepts, potentially leading to suboptimal outcomes. To address this
issue, developers can focus on improving the quality and breadth of the training data, incorporating more
advanced chemistry knowledge, and reﬁning the LLM’s understanding of complex chemistry concepts.
Additionally, a built-in validation or peer-review system, analog to the RLHF implemented for GPT-3.557,58,
could be incorporated to help ensure the reliability of the engine’s recommendations.
Encouraging users to critically evaluate the information provided by the LLM-powered engine and cross-
reference it with established literature and expert opinions can further mitigate the risk of relying on ﬂawed
reasoning59. By combining these approaches, developers can work towards minimizing the impact of
insufﬁcient chemistry knowledge on the engine’s reasoning process and enhancing the overall effectiveness
of LLM-powered chemistry engines60 like ChemCrow.
Addressing ethical concerns and intellectual property issues is crucial for the responsible development and
use of generative AI models, like ChemCrow61. Clearer guidelines and policies regarding the ownership of
generated chemical structures or materials, as well as the potential misuse of proprietary information, need
to be established. Collaboration with legal and ethical experts, as well as industry stakeholders, can help in
navigating these complex issues and implementing appropriate measures to protect intellectual property
and ensure ethical compliance.
In summary, it is crucial to carefully consider and address the potential risks associated with LLM-powered
chemistry engines, such as ChemCrow, to ensure their safe and responsible application. By integrating
expert-designed tools, the issue of model hallucination can be mitigated, while improving the quality
and breadth of training data can enhance the engine’s understanding of complex chemistry concepts.
Implementing effective mitigation strategies, such as access controls, safety guidelines, and ethical policies,
further contributes to minimizing risks and maximizing the positive impact of these engines on the ﬁeld of
chemistry. As the technology continues to evolve, collaboration and vigilance among developers, users, and
industry stakeholders are essential in identifying and addressing new risks and challenges62,63, fostering
responsible innovation and progress in the domain of LLM-powered chemistry engines.
7

Figure 6: Task 11. GPT-4 evaluator results for GPT-4 and ChemCrow performance on a task requir-
ing information that ChemCrow does not have access to via available tools. This is an example of
how providing tools can open doors to unintended use, leading to potentially dangerous outcomes. Prompt
(top) is given to both ChemCrow (left) and GPT-4 (right), then outputs are given to a separate instance of
GPT-4 for evaluation (bottom).
4
Limitations
A limitation when working with LLMs like GPT-4 is their attempt to generate an answer for any given
input, which can sometimes result in inaccuracies or hallucinations. For example, in ﬁgure 7, which is an
8

extension of ﬁgure 3, ChemCrow was asked to compare the prices of reactants and products, a task which
requires a basic understanding of stoichiometry. Lacking that understanding, it made a mistake by only
considering the price of a commercially available amount of each compound, comparing the sum of the
reactants’ prices to that of the product. This resulted in a chemically unmotivated comparison, as the model
could not compare equal amounts. This example shows the dependency of ChemCrow’s performance upon
the type, quantity, and quality of tools and descriptions provided. Of course, an obvious to address these
limitations is by giving the model more tools to address a given domain. In any case, when using a method
like this, we emphasize the importance of evaluating the output for correctness.
Figure 7: Limitations of ChemCrow. In this example the model is asked to compare the price of buying
the reactants to the price of the target compound (highlighted in red). In the ﬁnal answer, ChemCrow
concludes that it is cheaper to buy atorvastatin. However, due to lack of available tools, this conclusion is
based upon incorrect assumptions and calculations, showing the limitations of ChemCrow.
5
Discussion & Conclusions
We have shown the development of ChemCrow, a novel, LLM-powered method for integrating computa-
tional tools in chemistry. The system works by combining the reasoning power of LLMs with the chemical
expert knowledge from computational tools for chemistry. As has been shown, ChemCrow is capable
of independently solving reasoning tasks in chemistry ranging from a simple loop of drug discovery to
synthesis planning of potentially hazardous substances; showing potential for the development of future
chemical assistants à la ChatGPT. In its current state, the results are limited by the amount and quality of
the tools chosen. However, the space of possibilities is vast, especially as potential tools are not limited to
the chemistry domain, but can include other language-based tools, image processing tools, among many
others. In addition, the selected evaluation tasks are limited and must be built upon to further push the
limits of what these systems can do.
Our evaluation methods showed two different results: in terms of completeness and quality of thought,
the LLM-based evaluation concludes that GPT-4 and ChemCrow perform nearly equivalently; however,
human evaluations (oriented towards the completion and chemical correctness of the solutions) showed
9

that ChemCrow outperforms GPT-4 by a large margin of nearly 4.4/10 points, and 2.75/10 in successful
task completion.
This evaluation is not perfect and could beneﬁt from improved experimental design. One of the weak points
of this type of evaluation method is the inherent lack of reproducibility of individual results, as it is unlikely
that any two instances of an LLM will produce the same output. Another issue arises when assessing
the abilities of systems like GPT: GPT’s results strong sensibility to prompt engineering. To reduce this
potential for bias, we consistently used a single prompt completion from all models and evaluators. Other
limitations in this evaluation technique are the implicit bias in the selection of the tasks and the inherent
limitations of checking claims regarding chemical results. These points introduce new bias from both
techniques: The evaluator LLM method can only provide a reliable score based on the quality of thought
and completeness of response, as it has limited knowledge of chemistry and cannot assess the accuracy
of the solutions. The human evaluation, conducted by the authors, used available tools and chemical
knowledge, with a rubric deﬁned for this particular task. Despite efforts, the nature of the score aggregation
implicitly imposes certain biases. To address this issue, an impartial team of chemists should evaluate the
results in an A/B-experiment fashion. In spite of this, our results demonstrate the ability and potential of
these types of systems to serve as assistants to chemists.
6
Methods
6.1
LLMs
The rise of LLMs in the last years, and their quick advancement, availability, and scaling in the last months,
have opened the door to a wide range of applications and ideas. Usage of LLMs is further overpowered
when used as part of some frameworks designed to exploit their zero-shot reasoning capabilities, as can
be demonstrated by architectures like ReAct45 and MRKL47. These architectures allow combining the
shown success of chain-of-thought64 reasoning with LLMs’ use of tools9. For our experiments, we used
OpenAI’s GPT-410 with a temperature of 0.1.
6.2
LLMs application framework – LangChain
LangChain65 is a comprehensive framework designed to facilitate the development of language model
applications by providing support for various modules, including access to various LLMs, prompts,
document loaders, chains, indexes, agents, memory, and chat functionality. With these modules, LangChain
enables users to create various applications such as chatbots, question answering systems, summarization
tools, and data-augmented generation systems. LangChain not only offers standard interfaces for these
modules but also assists in integrating with external tools, experimenting with different prompts and
models, and evaluating the performance of generative models. In our implementation, we integrate external
tools through LangChain, as LLMs have been shown to perform better with tools9,30,66.
6.3
Tools
Although our implementation uses a limited set of tools, it must be noted that this tool set can very easily
be expanded depending on needs and availability.
The tools used can be classiﬁed into general tools, molecular tools, and chemical reaction tools.
6.3.1
General tools
Web search
The web search tool is designed to provide the language model with the ability to access
relevant information from the web. Utilizing SerpAPI67, the tool queries search engines and compiles a
selection of impressions from the ﬁrst page of Google search results. This allows the model to collect
current and relevant information across a broad range of scientiﬁc subjects. A notable feature of this tool is
its ability to serve as a starting point when the model receives a prompt that it cannot address or is uncertain
about the appropriate tool to use. Integrating this tool enables the language model to efﬁciently expand its
knowledge base, simplify the procedure of solving common scientiﬁc tasks, and verify the precision and
dependability of the information it offers.
Literature search
The literature search tool focuses on extracting relevant information from scientiﬁc
documents such as PDFs or text ﬁles (including raw HTML) to provide accurate and well-grounded
10

answers to questions. This tool utilizes the paper-qa python package (https://github.com/whitead/paper-qa).
By leveraging OpenAI Embeddings68 and FAISS69, a vector database, the tool embeds and searches
through documents efﬁciently. A language model then aids in generating answers based on these embedded
vectors.
The literature search process involves embedding documents and queries into vectors and searching for
the top k passages in the documents. Once these relevant passages have been identiﬁed, the tool creates a
summary of each passage in relation to the query. These summaries are then incorporated into the prompt,
allowing the language model to generate an informed answer. By grounding responses in the existing
scientiﬁc literature, the literature search tool signiﬁcantly enhances the model’s ability to provide reliable
and accurate information for routine scientiﬁc tasks, while also including references to the relevant papers.
6.3.2
Molecule tools
Query to SMILES
This tool is speciﬁcally designed to obtain the SMILES representation of a given
molecule. By taking the name of a molecule as input, it returns the corresponding SMILES string. The
tool allows users to request tasks involving molecular analysis and manipulation, by referencing the
molecule in natural language (e.g. caffeine, novastatine, etc), IUPAC names, etc. Our implementation
queries chem-space70 as a primary source, and upon failure queries Pubchem71 and the IUPAC to SMILES
converter OPSIN72 as a last option.
Obtain price of molecule
The purpose of this tool is to provide information on the purchasability and
commercial cost of a speciﬁc molecule. By taking a molecule as input, it ﬁrst utilizes molbloom73 to
check whether the molecule is available for purchase (in ZINC2074). Then, using chem-space API70, it
returns the cheapest price available on the market, enabling the LLM to make informed decisions about the
affordability and availability of the queried molecule toward the resolution of a given task.
Molecule to CAS
The tool is designed to determine the Chemical Abstracts Service (CAS) number
of a given molecule, using various types of input references such as common names, IUPAC names, or
other identiﬁers. By converting these references into the unique CAS number, it greatly facilitates web
searches and information retrieval for any molecule. The CAS number serves as a precise and universally
recognized chemical identiﬁer, enabling researchers to access relevant data and resources with ease, and
ensuring that they obtain accurate and consistent information about the target molecule75.
Molecular similarity calculator
The primary function of this tool is to evaluate the similarity between
two molecules, utilizing the Tanimoto similarity measure76 based on the ECFP2 molecular ﬁngerprints77
of both input molecules. By taking two molecules as input, it returns a measure of their structural similarity,
which is valuable for assessing the potential of molecular analogs in various applications, such as drug
discovery and chemical research. This tool allows the model to calculate and compare the similarity
between pairs of molecules. The Tanimoto similarity approach provides a robust and reliable comparison
of molecular structures, allowing scientists to make informed decisions when exploring new molecular
candidates or investigating structure-activity relationships.
Molecular modiﬁer
This tool is designed to make alterations to a given molecule by generating a local
chemical space around it using retro and forward synthesis rules. It employs the SynSpace package78,
originally applied in counterfactual explanations for molecular machine learning79. The modiﬁcation
process utilizes 50 robust medchem reactions80, and the retrosynthesis is performed either via PostEra
Manifold16,81 (upon availability of an API key) or by reversing the 50 robust reactions. The purchasable
building blocks come from the Purchasable Mcule supplier building block catalogs82, although customiza-
tion options are available. By taking the SMILES representation of a molecule as input, this tool returns a
single modiﬁed molecule resulting from a small change. This tool gives the model the ability to explore
structurally similar molecules and generate novel molecules. This enables researchers to explore new
molecular structures, derivatives, and ﬁne-tune their molecular candidates for speciﬁc applications, such as
drug discovery and chemical research.
Patent checker
The patent checker tool is designed to verify whether a molecule has been patented or
not, without the need for a web request. It utilizes molbloom73, a C library to check strings against a bloom
ﬁlter, making it an efﬁcient tool to assess compounds against known databases. The primary application of
this tool, which is used in our implementations, is to determine if a molecule can be purchased by checking
11

against the ZINC database of purchasable compounds. By taking a molecule’s SMILES representation as
input, the patent checker tool informs the LLM if a patent exists for that particular molecule, thus helping
it avoid potential intellectual property conﬂicts and determine whether a given compound is novel.
Functional groups ﬁnder
This tool is designed to identify functional groups within a given molecule
by analyzing a list of named SMARTS (SMiles ARbitrary Target Speciﬁcation) patterns. By taking the
SMILES representation of a single molecule as input, the functional group ﬁnder searches for matches
between the molecule’s structure and the predeﬁned SMARTS patterns representing various functional
groups.
Upon identifying these matches, the tool returns a list of functional groups present in the molecule. This
information is essential for understanding the molecule’s reactivity, properties, and potential applications in
various scientiﬁc domains, such as drug discovery, chemical research, and materials science. By providing
a comprehensive overview of a molecule’s functional groups, the LLM can make informed decisions when
designing experiments, synthesizing compounds, or exploring new molecular candidates.
Safety assessment
This comprehensive safety tool combines the functionality of multiple individual
tools to evaluate the hazards and health concerns of a given molecule. By taking a molecule’s name, CAS
number, or SMILES representation as input, the uniﬁed tool provides essential safety information by
leveraging the Globally Harmonized System of Classiﬁcation and Labeling of Chemicals83, human safety
concerns, FDA approval status, and toxicological data. The GHS classiﬁcation and human safety concerns
tools pull data from PubChem71, while the FDA approval and toxicity information comes from the Clintox
dataset49. This tool allows the LLM to evaluate the potential risks and safety measures required when
handling various chemicals, enabling it to assist users in determining proper risk prevention in potential
applications. It facilitates informed decision-making for researchers and practitioners, contributing to the
safety of both people and the environment when working with potentially harmful compounds
6.3.3
Chemical reaction tools
Reaction classiﬁer
This tool, powered by the proprietary software NameRxn from NextMove Software84,
is designed to identify and classify a given chemical reaction based on its internal database of several
hundred named reactions. By taking a reaction SMILES, the tool returns a classiﬁcation code and the
reaction name in natural language. The classiﬁcation code corresponds to a position in the hierarchy
proposed by Carey, Laffan, Thomson, and Williams85. This information is essential for understanding
reaction mechanisms, selecting appropriate catalysts, and optimizing experimental conditions.
Reaction prediction
The reaction prediction tool leverages the RXN4Chemistry API from IBM Re-
search40, which utilizes a transformer model speciﬁcally tailored for predicting chemical reactions and
retrosynthesis paths based on the Molecular Transformer16,22 and provides highly accurate predictions.
This tool takes as input a set of reactants and returns the predicted product, allowing the LLM to have
accurate chemical information that can’t typically be obtained by a simple database query, but that requires
a sort of abstract reasoning chemists are trained to perform. While the API is free to use, registration is
required.
Molecular synthesis planner
This powerful tool also employs the RXN4Chemistry API from IBM
Research16,22,40, utilizing the same Transformer approach for translation tasks as the reaction prediction
tool, but adding search algorithms to handle multi-step synthesis, and an action prediction algorithm
that converts a reaction sequence into actionable steps in machine readable format, including conditions,
additives, and solvents86. To interface with ChemCrow, we added an LLM processing step that converts
these machine-readable actions into natural language. The molecular synthesis planner is designed to
assist the LLM in planning a synthetic route to prepare a desired target molecule. By taking the SMILES
representation of the desired product as input, this tool enables ChemCrow to devise and compare efﬁcient
synthetic pathways toward the target compound.
Acknowledgements
A.M.B. and P.S. acknowledge support from the NCCR Catalysis (grant number 180544), a National
Centre of Competence in Research funded by the Swiss National Science Foundation. S.C. and A.D.W.
acknowledge support from the NSF under grant number 1751471. Research reported in this work was
12

supported by the National Institute of General Medical Sciences of the National Institutes of Health under
award number R35GM137966.
References
[1] Devlin, J.; Chang, M.-W.; Lee, K.; Toutanova, K. Bert: Pre-training of deep bidirectional transformers
for language understanding. arXiv preprint arXiv:1810.04805 2018,
[2] Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.; Dhariwal, P.; Neelakantan, A.; Shyam, P.;
Sastry, G.; Askell, A., et al. Language models are few-shot learners. Advances in neural information
processing systems 2020, 33, 1877–1901.
[3] Bommasani, R.; Hudson, D. A.; Adeli, E.; Altman, R.; Arora, S.; von Arx, S.; Bernstein, M. S.;
Bohg, J.; Bosselut, A.; Brunskill, E., et al. On the opportunities and risks of foundation models. arXiv
preprint arXiv:2108.07258 2021,
[4] Chowdhery, A.; Narang, S.; Devlin, J.; Bosma, M.; Mishra, G.; Roberts, A.; Barham, P.; Chung, H. W.;
Sutton, C.; Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint
arXiv:2204.02311 2022,
[5] Bubeck, S.; Chandrasekaran, V.; Eldan, R.; Gehrke, J.; Horvitz, E.; Kamar, E.; Lee, P.; Lee, Y. T.;
Li, Y.; Lundberg, S., et al. Sparks of artiﬁcial general intelligence: Early experiments with gpt-4.
arXiv preprint arXiv:2303.12712 2023,
[6] GitHub Copilot: Your AI pair programmer. https://copilot.github.com.
[7] Ziegler, A.; Kalliamvakou, E.; Li, X. A.; Rice, A.; Rifkin, D.; Simister, S.; Sittampalam, G.;
Aftandilian, E. Productivity assessment of neural code completion. Proceedings of the 6th ACM
SIGPLAN International Symposium on Machine Programming. 2022; pp 21–29.
[8] Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, Ł.; Polosukhin, I.
Attention is all you need. Advances in neural information processing systems 2017, 30.
[9] Schick, T.; Dwivedi-Yu, J.; Dessì, R.; Raileanu, R.; Lomeli, M.; Zettlemoyer, L.; Cancedda, N.;
Scialom, T. Toolformer: Language models can teach themselves to use tools. arXiv preprint
arXiv:2302.04761 2023,
[10] OpenAI, GPT-4 Technical Report. 2023.
[11] Ouyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright, C.; Mishkin, P.; Zhang, C.; Agarwal, S.;
Slama, K.; Ray, A., et al. Training language models to follow instructions with human feedback.
Advances in Neural Information Processing Systems 2022, 35, 27730–27744.
[12] White, A. D.; Hocky, G. M.; Gandhi, H. A.; Ansari, M.; Cox, S.; Wellawatte, G. P.; Sasmal, S.;
Yang, Z.; Liu, K.; Singh, Y., et al. Assessment of chemistry knowledge in large language models that
generate code. Digital Discovery 2023,
[13] Lowe, D. M.; Corbett, P. T.; Murray-Rust, P.; Glen, R. C. Chemical Name to Structure: OPSIN, an
Open Source Solution. Journal of Chemical Information and Modeling 2011, 51, 739–753, PMID:
21384929.
[14] Coley, C. W.; Barzilay, R.; Jaakkola, T. S.; Green, W. H.; Jensen, K. F. Prediction of organic reaction
outcomes using machine learning. ACS central science 2017, 3, 434–443.
[15] Coley, C. W.; Jin, W.; Rogers, L.; Jamison, T. F.; Jaakkola, T. S.; Green, W. H.; Barzilay, R.;
Jensen, K. F. A graph-convolutional neural network model for the prediction of chemical reactivity.
Chem. Sci. 2019, 10, 370–377.
[16] Schwaller, P.; Laino, T.; Gaudin, T.; Bolgar, P.; Hunter, C. A.; Bekas, C.; Lee, A. A. Molecular
transformer: a model for uncertainty-calibrated chemical reaction prediction. ACS central science
2019, 5, 1572–1583.
13

[17] Pesciullesi, G.; Schwaller, P.; Laino, T.; Reymond, J.-L. Transfer learning enables the molecular
transformer to predict regio-and stereoselective reactions on carbohydrates. Nat. Commun. 2020, 11,
1–8.
[18] Irwin, R.; Dimitriadis, S.; He, J.; Bjerrum, E. J. Chemformer: a pre-trained transformer for computa-
tional chemistry. Machine Learning: Science and Technology 2022, 3, 015022.
[19] Szymku´c, S.; Gajewska, E. P.; Klucznik, T.; Molga, K.; Dittwald, P.; Startek, M.; Bajczyk, M.;
Grzybowski, B. A. Computer-assisted synthetic planning: the end of the beginning. Angew. Chem. -
Int. Ed. 2016, 55, 5904–5937.
[20] Segler, M. H.; Preuss, M.; Waller, M. P. Planning chemical syntheses with deep neural networks and
symbolic AI. Nature 2018, 555, 604–610.
[21] Coley, C. W.; Thomas, D. A.; Lummiss, J. A.; Jaworski, J. N.; Breen, C. P.; Schultz, V.; Hart, T.;
Fishman, J. S.; Rogers, L.; Gao, H., et al. A robotic platform for ﬂow synthesis of organic compounds
informed by AI planning. Science 2019, 365.
[22] Schwaller, P.; Petraglia, R.; Zullo, V.; Nair, V. H.; Haeuselmann, R. A.; Pisoni, R.; Bekas, C.;
Iuliano, A.; Laino, T. Predicting retrosynthetic pathways using transformer-based models and a
hyper-graph exploration strategy. Chemical science 2020, 11, 3316–3325.
[23] Genheden, S.; Thakkar, A.; Chadimová, V.; Reymond, J.-L.; Engkvist, O.; Bjerrum, E. AiZynthFinder:
a fast, robust and ﬂexible open-source software for retrosynthetic planning. J. Cheminf. 2020, 12,
1–9.
[24] Molga, K.; Szymku´c, S.; Grzybowski, B. A. Chemist Ex Machina: Advanced Synthesis Planning by
Computers. Acc. Chem. Res. 2021, 54, 1094–1106.
[25] Schwaller, P.; Vaucher, A. C.; Laplaza, R.; Bunne, C.; Krause, A.; Corminboeuf, C.; Laino, T.
Machine intelligence for chemical reaction space. Wiley Interdisciplinary Reviews: Computational
Molecular Science 2022, 12, e1604.
[26] Mayr, A.; Klambauer, G.; Unterthiner, T.; Hochreiter, S. DeepTox: toxicity prediction using deep
learning. Frontiers in Environmental Science 2016, 3, 80.
[27] Yang, K.; Swanson, K.; Jin, W.; Coley, C.; Eiden, P.; Gao, H.; Guzman-Perez, A.; Hopper, T.;
Kelley, B.; Mathea, M., et al. Analyzing learned molecular representations for property prediction.
Journal of chemical information and modeling 2019, 59, 3370–3388.
[28] Chithrananda, S.; Grand, G.; Ramsundar, B. Chemberta: Large-scale self-supervised pretraining for
molecular property prediction. arXiv preprint arXiv:2010.09885 2020,
[29] van Tilborg, D.; Alenicheva, A.; Grisoni, F. Exposing the limitations of molecular machine learning
with activity cliffs. Journal of Chemical Information and Modeling 2022, 62, 5938–5951.
[30] Jablonka, K. M.; Schwaller, P.; Ortega-Guerrero, A.; Smit, B. Is GPT-3 all you need for low-data
discovery in chemistry? 2023,
[31] Gómez-Bombarelli, R.; Wei, J. N.; Duvenaud, D.; Hernández-Lobato, J. M.; Sánchez-Lengeling, B.;
Sheberla, D.; Aguilera-Iparraguirre, J.; Hirzel, T. D.; Adams, R. P.; Aspuru-Guzik, A. Automatic
Chemical Design Using a Data-Driven Continuous Representation of Molecules. ACS Cent. Sci. 2018,
4, 268–276, PMID: 29532027.
[32] Blaschke, T.; Arús-Pous, J.; Chen, H.; Margreitter, C.; Tyrchan, C.; Engkvist, O.; Papadopoulos, K.;
Patronov, A. REINVENT 2.0: an AI tool for de novo drug design. Journal of chemical information
and modeling 2020, 60, 5918–5922.
[33] Tao, Q.; Xu, P.; Li, M.; Lu, W. Machine learning for perovskite materials design and discovery. npj
Computational Materials 2021, 7, 1–18, Number: 1 Publisher: Nature Publishing Group.
[34] Gómez-Bombarelli, R. et al. Design of efﬁcient molecular organic light-emitting diodes by a high-
throughput virtual screening and experimental approach. Nature Materials 2016, 15, 1120–1127,
Number: 10 Publisher: Nature Publishing Group.
14

[35] Shields, B. J.; Stevens, J.; Li, J.; Parasram, M.; Damani, F.; Alvarado, J. I. M.; Janey, J. M.;
Adams, R. P.; Doyle, A. G. Bayesian reaction optimization as a tool for chemical synthesis. Nature
2021, 590, 89–96.
[36] Torres, J. A. G.; Lau, S. H.; Anchuri, P.; Stevens, J. M.; Tabora, J. E.; Li, J.; Borovika, A.; Adams, R. P.;
Doyle, A. G. A Multi-Objective Active Learning Platform and Web App for Reaction Optimization.
Journal of the American Chemical Society 2022, 144, 19999–20007.
[37] Zhao, Z.-W.; del Cueto, M.; Troisi, A. Limitations of machine learning models when predicting
compounds with completely new chemistries: possible improvements applied to the discovery of new
non-fullerene acceptors. Digital Discovery 2022, 1, 266–276.
[38] Vaucher, A. C.; Schwaller, P.; Geluykens, J.; Nair, V. H.; Iuliano, A.; Laino, T. Inferring experimental
procedures from text-based representations of chemical reactions. Nature communications 2021, 12,
2573.
[39] Schwaller, P.; Probst, D.; Vaucher, A. C.; Nair, V. H.; Kreutter, D.; Laino, T.; Reymond, J.-L. Mapping
the space of chemical reactions using attention-based neural networks. Nature machine intelligence
2021, 3, 144–152.
[40] rxn4Chemistry, rxn4Chemistry. https://github.com/rxn4chemistry/rxn4chemistry, 2020;
Accessed: April 2023.
[41] Thakkar, A.; Kogej, T.; Reymond, J.-L.; Engkvist, O.; Bjerrum, E. J. Datasets and their inﬂuence
on the development of computer assisted synthesis planning tools in the pharmaceutical domain.
Chemical science 2020, 11, 154–168.
[42] Thakkar, A.; Selmi, N.; Reymond, J.-L.; Engkvist, O.; Bjerrum, E. J. “Ring breaker”: neural network
driven synthesis prediction of the ring system chemical space. Journal of medicinal chemistry 2020,
63, 8791–8808.
[43] Yang, Z.; Li, L.; Wang, J.; Lin, K.; Azarnasab, E.; Ahmed, F.; Liu, Z.; Liu, C.; Zeng, M.;
Wang, L. MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action. arXiv preprint
arXiv:2303.11381 2023,
[44] Shen, Y.; Song, K.; Tan, X.; Li, D.; Lu, W.; Zhuang, Y. HuggingGPT: Solving AI Tasks with ChatGPT
and its Friends in HuggingFace. 2023.
[45] Yao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.; Narasimhan, K.; Cao, Y. React: Synergizing reasoning
and acting in language models. arXiv preprint arXiv:2210.03629 2022,
[46] Boiko, D. A.; MacKnight, R.; Gomes, G. Emergent autonomous scientiﬁc research capabilities of
large language models. arXiv preprint 2023,
[47] Karpas, E.; Abend, O.; Belinkov, Y.; Lenz, B.; Lieber, O.; Ratner, N.; Shoham, Y.; Bata, H.;
Levine, Y.; Leyton-Brown, K., et al. MRKL Systems: A modular, neuro-symbolic architecture that
combines large language models, external knowledge sources and discrete reasoning. arXiv preprint
arXiv:2205.00445 2022,
[48] Lowe, D. M. Extraction of chemical structures and reactions from the literature. Ph.D. thesis,
University of Cambridge, 2012.
[49] Wu, Z.; Ramsundar, B.; Feinberg, E. N.; Gomes, J.; Geniesse, C.; Pappu, A. S.; Leswing, K.; Pande, V.
MoleculeNet: a benchmark for molecular machine learning. Chemical science 2018, 9, 513–530.
[50] Liu, Y.; Iter, D.; Xu, Y.; Wang, S.; Xu, R.; Zhu, C. GPTEval: NLG Evaluation using GPT-4 with
Better Human Alignment. arXiv preprint arXiv:2303.16634 2023,
[51] Eloundou, T.; Manning, S.; Mishkin, P.; Rock, D. Gpts are gpts: An early look at the labor market
impact potential of large language models. arXiv preprint arXiv:2303.10130 2023,
[52] Grzybowski, B. A.; Badowski, T.; Molga, K.; Szymku´c, S. Network search algorithms and scoring
functions for advanced-level computerized synthesis planning. WIREs Computational Molecular
Science 2023, 13, e1630.
15

[53] Thakkar, A.; Johansson, S.; Jorner, K.; Buttar, D.; Reymond, J.-L.; Engkvist, O. Artiﬁcial intelligence
and automation in computer aided synthesis planning. Reaction chemistry & engineering 2021, 6,
27–51.
[54] Roth, B. D. In 1 The Discovery and Development of Atorvastatin, A Potent Novel Hypolipidemic
Agent; King, F. D., Oxford, A. W., Reitz, A. B., Dax, S. L., Eds.; Progress in Medicinal Chemistry;
Elsevier, 2002; Vol. 40; pp 1–22, ISSN: 0079-6468.
[55] Urbina, F.; Lentzos, F.; Invernizzi, C.; Ekins, S. Dual use of artiﬁcial-intelligence-powered drug
discovery. Nature Machine Intelligence 2022, 4, 189–191.
[56] Urbina, F.; Lentzos, F.; Invernizzi, C.; Ekins, S. A teachable moment for dual-use. Nature machine
intelligence 2022, 4, 607–607.
[57] Gao, L.; Schulman, J.; Hilton, J. Scaling Laws for Reward Model Overoptimization. arXiv preprint
arXiv:2210.10760 2022,
[58] Radford, A.; Narasimhan, K.; Salimans, T.; Sutskever, I., et al. Improving language understanding by
generative pre-training. 2018,
[59] Li, B.; Qi, P.; Liu, B.; Di, S.; Liu, J.; Pei, J.; Yi, J.; Zhou, B. Trustworthy AI: From Principles to
Practices. ACM Computing Surveys 2021, 55, 1 – 46.
[60] Hocky, G. M.; White, A. D. Natural language processing models that automate programming will
transform chemistry research and teaching. Digital Discovery 2022, 1, 79–83.
[61] Henderson, P.; Li, X.; Jurafsky, D.; Hashimoto, T.; Lemley, M. A.; Liang, P. Foundation Models and
Fair Use. arXiv preprint arXiv:2303.15715 2023,
[62] Askell, A.; Brundage, M.; Hadﬁeld, G. The Role of Cooperation in Responsible AI Development.
2019.
[63] Neufville, R. d.; Baum, S. D. Collective action on artiﬁcial intelligence: A primer and review.
Technology in Society 2021, 66, 101649.
[64] Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Chi, E.; Le, Q.; Zhou, D. Chain of thought prompting
elicits reasoning in large language models. arXiv preprint arXiv:2201.11903 2022,
[65] Chase, H. LangChain. 2022; https://github.com/hwchase17/langchain.
[66] Press, O.; Zhang, M.; Min, S.; Schmidt, L.; Smith, N. A.; Lewis, M. Measuring and Narrowing the
Compositionality Gap in Language Models. arXiv preprint arXiv:2210.03350 2022,
[67] SerpAPI, SerpAPI - Google Search Results API. 2023; https://serpapi.com/.
[68] Neelakantan, A.; Xu, T.; Puri, R.; Radford, A.; Han, J. M.; Tworek, J.; Yuan, Q.; Tezak, N.;
Kim, J. W.; Hallacy, C., et al. Text and code embeddings by contrastive pre-training. arXiv preprint
arXiv:2201.10005 2022,
[69] Johnson, J.; Douze, M.; Jégou, H. Billion-scale similarity search with GPUs. IEEE Transactions on
Big Data 2019, 7, 535–547.
[70] ChemSpace, ChemSpace - Provider of Chemical Building Blocks, Fragment Libraries, and Screening
Compounds. https://chem-space.com/, 2023.
[71] National Center for Biotechnology Information, PubChem. https://pubchem.ncbi.nlm.nih.
gov/, 2023.
[72] Lowe, D. M.; Corbett, P. T.; Murray-Rust, P.; Glen, R. C. Chemical name to structure: OPSIN, an
open source solution. 2011.
[73] White, A. D. molbloom: quick assessment of compound purchasability with bloom ﬁlters. 2022;
https://github.com/whitead/molbloom.
16

[74] Irwin, J. J.; Tang, K. G.; Young, J.; Dandarchuluun, C.; Wong, B. R.; Khurelbaatar, M.; Moroz, Y. S.;
Mayﬁeld, J.; Sayle, R. A. ZINC20—a free ultralarge-scale chemical database for ligand discovery.
Journal of chemical information and modeling 2020, 60, 6065–6073.
[75] Chemical
Abstracts
Service,
CAS
Registry
Number.
https://www.cas.org/content/
cas-registry, Accessed: April 2023.
[76] TT, T. An elementary mathematical theory of classiﬁcation and prediction; 1958.
[77] Rogers, D.; Hahn, M. Extended-connectivity ﬁngerprints. Journal of chemical information and
modeling 2010, 50, 742–754.
[78] White, Andrew D, SynSpace. https://github.com/whitead/synspace, Accessed: April 2023;
GitHub repository.
[79] Wellawatte, G. P.; Seshadri, A.; White, A. D. Model agnostic generation of counterfactual explanations
for molecules. Chemical science 2022, 13, 3697–3705.
[80] MedChemComm.
Accessed:
5
April
2023;
https://www.rsc.org/
journals-books-databases/about-journals/medchemcomm/.
[81] Yang, Q.; Sresht, V.; Bolgar, P.; Hou, X.; Klug-McLeod, J. L.; Butler, C. R., et al. Molecular
transformer uniﬁes reaction prediction and retrosynthesis across pharma chemical space. Chemical
communications 2019, 55, 12152–12155.
[82] Mcule, Purchasable Mcule. https://purchasable.mcule.com/, Accessed: April 2023.
[83] United Nations, Globally Harmonized System of Classiﬁcation and Labeling of Chemicals. https:
//www.unece.org/trans/danger/publi/ghs/ghs_rev07/07files_e.html, 2015; Accessed:
5 April 2023.
[84] NextMove Software, NameRxn. https://www.nextmovesoftware.com/namerxn.html, last ac-
cessed 2020/11/07; Accessed: 5 April 2023.
[85] Carey, J. S.; Laffan, D.; Thomson, C.; Williams, M. T. Analysis of the reactions used for the
preparation of drug candidate molecules. Organic & biomolecular chemistry 2006, 4, 2337–2347.
[86] Vaucher, A. C.; Schwaller, P.; Geluykens, J.; Nair, V. H.; Iuliano, A.; Laino, T. Inferring experimental
procedures from text-based representations of chemical reactions. Nature Communications 2021, 12,
2573, Number: 1 Publisher: Nature Publishing Group.
17

A
Appendix
A.1
Tasks and Evaluation
A.1.1
Task 2 - Propose New Organocatalyst
Figure 8: GPT-4 evaluator results for GPT-4 and ChemCrow performance on a task 2. Prompt (top)
is given to both ChemCrow (left) and GPT-4 (right), then outputs are given to a separate instance of GPT-4
for evaluation (bottom).
18

A.1.2
Task 3 - Explain mechanisms
Figure 9: GPT-4 evaluator results for GPT-4 and ChemCrow performance on task 3. Prompt (top) is
given to both ChemCrow (left) and GPT-4 (right), then outputs are given to a separate instance of GPT-4
for evaluation (bottom).
19

A.1.3
Task 4 - Propose Similar Nontoxic Molecule
Figure 10: GPT-4 evaluator results for GPT-4 and ChemCrow performance on task 4. Prompt (top)
is given to both ChemCrow (left) and GPT-4 (right), then outputs are given to a separate instance of GPT-4
for evaluation (bottom).
20

A.1.4
Task 5 - How to Make Target
Figure 11: GPT-4 evaluator results for GPT-4 and ChemCrow performance on task 5. Prompt (top)
is given to both ChemCrow (left) and GPT-4 (right), then outputs are given to a separate instance of GPT-4
for evaluation (bottom).
21

A.1.5
Task 6 - Compare Catalyst Mechanisms
Figure 12: GPT-4 evaluator results for GPT-4 and ChemCrow performance on task 6. Prompt (top)
is given to both ChemCrow (left) and GPT-4 (right), then outputs are given to a separate instance of GPT-4
for evaluation (bottom).
22

A.1.6
Task 7 - Synthesize Similar Molecule
Figure 13: GPT-4 evaluator results for GPT-4 and ChemCrow performance on task 7. Prompt (top)
is given to both ChemCrow (left) and GPT-4 (right), then outputs are given to a separate instance of GPT-4
for evaluation (bottom).
23

A.1.7
Task 8 - Propose Similar Novel Nontoxic Molecule
Figure 14: GPT-4 evaluator results for GPT-4 and ChemCrow performance on task 8. Prompt (top)
is given to both ChemCrow (left) and GPT-4 (right), then outputs are given to a separate instance of GPT-4
for evaluation (bottom).
24

A.1.8
Task 9 - Predict Success of Reaction
Figure 15: GPT-4 evaluator results for GPT-4 and ChemCrow performance on task 9. Prompt (top)
is given to both ChemCrow (left) and GPT-4 (right), then outputs are given to a separate instance of GPT-4
for evaluation (bottom).
25

A.1.9
Task 10 - Property of Reaction Product
Figure 16: GPT-4 evaluator results for GPT-4 and ChemCrow performance on task 10. Prompt (top)
is given to both ChemCrow (left) and GPT-4 (right), then outputs are given to a separate instance of GPT-4
for evaluation (bottom).
26

A.1.10
Task 12 - Similar mode of action (MOA)
Figure 17: GPT-4 evaluator results for GPT-4 and ChemCrow performance on task 12. This example
has been drawn from the GPT-4 paper10 readteaming on chemistry capabilities. There, the authors provided
some basic tools to the LLM as well. Prompt (top) is given to both ChemCrow (left) and GPT-4 (right),
then outputs are given to a separate instance of GPT-4 for evaluation (bottom).
27

