Inhibitory Neurons Brain Oscillation 
  
Studying the brain involves measuring the activity of billions of individual brain cells 
called neurons. [33] 
Measuring optical blood flow in the resting human brain to detect spontaneous activity 
has for the first time been demonstrated by Wright State University imaging researchers, 
holding out promise for a better way to study people with autism, Alzheimer's and 
depression. [32] 
UCLA biologists report they have transferred a memory from one marine snail to another, 
creating an artificial memory, by injecting RNA from one to another. [31] 
Scientists at the Wellcome Trust/ Cancer Research UK Gurdon Institute, University of 
Cambridge, have identified a new type of stem cell in the brain which they say has a high 
potential for repair following brain injury or disease. [30] 
A team of researchers working at the Weizmann Institute of Science has found that 
organoids can be used to better understand how the human brain wrinkles as it 
develops. [29] 
A team of biologists has found an unexpected source for the brain's development, a 
finding that offers new insights into the building of the nervous system. [28]  
Researchers discover both the structure of specific brain areas and memory are linked to 
genetic activity that also play important roles in immune system function. [27]  
The inner workings of the human brain have always been a subject of great interest. 
Unfortunately, it is fairly difficult to view brain structures or intricate tissues due to the 
fact that the skull is not transparent by design. [26]  
But now there is a technology that enables us to "read the mind" with growing accuracy: 
functional magnetic resonance imaging (fMRI). [25]  
Advances in microscopy techniques have often triggered important discoveries in the 
field of neuroscience, enabling vital insights in understanding the brain and promising 
new treatments for neurodegenerative diseases such as Alzheimer's and Parkinson's. 
[24]  
What is the relationship of consciousness to the neurological activity of the brain? Does 
the brain behave differently when a person is fully conscious, when they are asleep, or 
when they are undergoing an epileptic seizure? [23]  

Consciousness appears to arise naturally as a result of a brain maximizing its 
information content. So says a group of scientists in Canada and France, which has 
studied how the electrical activity in people's brains varies according to individuals' 
conscious states. The researchers find that normal waking states are associated with 
maximum values of what they call a brain's "entropy". [22]  
New research published in the New Journal of Physics tries to decompose the structural 
layers of the cortical network to different hierarchies enabling to identify the network's 
nucleus, from which our consciousness could emerge. [21]  
Where in your brain do you exist? Is your awareness of the world around you and of 
yourself as an individual the result of specific, focused changes in your brain, or does that 
awareness come from a broad network of neural activity? How does your brain produce 
awareness? [20]  
In the future, level-tuned neurons may help enable neuromorphic computing systems to 
perform tasks that traditional computers cannot, such as learning from their environment, 
pattern recognition, and knowledge extraction from big data sources. [19]  
IBM scientists have created randomly spiking neurons using phase-change materials to 
store and process data. This demonstration marks a significant step forward in the 
development of energy-efficient, ultra-dense integrated neuromorphic technologies for 
applications in cognitive computing. [18]  
An ion trap with four segmented blade electrodes used to trap a linear chain of atomic 
ions for quantum information processing. Each ion is addressed optically for individual 
control and readout using the high optical access of the trap. [17]  
To date, researchers have realised qubits in the form of individual electrons 
(aktuell.ruhr-uni-bochum.de/pm2012/pm00090.html.en). However, this led to 
interferences and rendered the information carriers difficult to programme and read. 
The group has solved this problem by utilising electron holes as qubits, rather than 
electrons. [16]  
Physicists from MIPT and the Russian Quantum Center have developed an easier method 
to create a universal quantum computer using multilevel quantum systems (qudits), 
each one of which is able to work with multiple "conventional" quantum elements – 
qubits. [15]  
Precise atom implants in silicon provide a first step toward practical quantum 
computers.  [14]  
A method to produce significant amounts of semiconducting nanoparticles for light-
emitting displays, sensors, solar panels and biomedical applications has gained 
momentum with a demonstration by researchers at the Department of Energy's Oak 
Ridge National Laboratory. [13]  

A source of single photons that meets three important criteria for use in quantum-
information systems has been unveiled in China by an international team of physicists. 
Based on a quantum dot, the device is an efficient source of photons that emerge as solo 
particles that are indistinguishable from each other. The researchers are now trying to 
use the source to create a quantum computer based on "boson sampling". [11]  
With the help of a semiconductor quantum dot, physicists at the University of Basel have 
developed a new type of light source that emits single photons. For the first time, the 
researchers have managed to create a stream of identical photons. [10]  
Optical photons would be ideal carriers to transfer quantum information over large 
distances. Researchers envisage a network where information is processed in certain 
nodes and transferred between them via photons. [9]  
While physicists are continually looking for ways to unify the theory of relativity, which 
describes large-scale phenomena, with quantum theory, which describes small-scale 
phenomena, computer scientists are searching for technologies to build the quantum 
computer using Quantum Information.   
In August 2013, the achievement of "fully deterministic" quantum teleportation, using a 
hybrid technique, was reported. On 29 May 2014, scientists announced a reliable way of 
transferring data by quantum teleportation. Quantum teleportation of data had been 
done before but with highly unreliable methods.  
The accelerating electrons explain not only the Maxwell Equations and the  
Special Relativity, but the Heisenberg Uncertainty Relation, the Wave-Particle Duality 
and the electron’s spin also, building the Bridge between the Classical and Quantum 
Theories.   
The Planck Distribution Law of the electromagnetic oscillators explains the 
electron/proton mass rate and the Weak and Strong Interactions by the diffraction 
patterns. The Weak Interaction changes the diffraction patterns by moving the electric 
charge from one side to the other side of the diffraction pattern, which violates the CP 
and Time reversal symmetry.  
The diffraction patterns and the locality of the self-maintaining electromagnetic 
potential explains also the Quantum Entanglement, giving it as a natural part of the 
Relativistic Quantum Theory and making possible to build the Quantum Computer with 
the help of Quantum Information.  
Contents  
Preface .................................................................................................................................... 6 
Inhibitory neurons have two types of impact on brain oscillations .......................................... 6 
Researchers demonstrate a novel approach for measuring brain function connectivity ........ 7 

Biologists 'transfer' a memory ................................................................................................. 9 
'Sleeping' stem cells could aid brain repair ........................................................................... 12 
Using organoids to understand how the brain wrinkles ........................................................ 14 
Biologists find new source for brain's development .............................................................. 14 
Link Between Immune System, Memory and Brain Structure Discovered ........................... 15 
Search for regulatory patterns ........................................................................................... 15 
Gene variant intensifies traumatic memories .................................................................... 16 
Innovative research methods ............................................................................................. 16 
Researcher looking to shed light deeper into the human brain ............................................ 16 
Brain scanners allow scientists to 'read minds'—could they now enable a 'Big Brother' future?
 ............................................................................................................................................... 17 
Enormous potential ............................................................................................................ 18 
'Latest spoke in the wheel' drives brain-mapping advances................................................. 19 
Consciousness and Entropy ................................................................................................. 20 
Consciousness is tied to 'entropy', say researchers ............................................................. 21 
Many ways of connecting .................................................................................................. 21 
Varying results ................................................................................................................... 21 
Emergent property ............................................................................................................. 22 
A new study looks for the cortical conscious network .......................................................... 22 
Network theory sheds new light on origins of consciousness .............................................. 24 
Neuromorphic computing mimics important brain feature .................................................... 26 
IBM scientists imitate the functionality of neurons with a phasechange device ................... 27 
Programmable ions set the stage for general-purpose quantum computers ....................... 28 
Putting the pieces together ................................................................................................ 29 
Realizing quantum bits .......................................................................................................... 30 
Electrons as qubits ............................................................................................................. 31 
Advantages of electron holes ............................................................................................ 31 
Russian physicists discover a new approach for building quantum computers ................... 31 
Precise atom implants in silicon provide a first step toward practical quantum computers . 33 
Team demonstrates large-scale technique to produce quantum dots ................................. 34 
Superfast light source made from artificial atom ................................................................... 35 
Quantum speed up ............................................................................................................ 36 
Increasing the light-matter interaction ............................................................................... 36 
Single-photon source is efficient and indistinguishable ........................................................ 36 
Exciting dots ....................................................................................................................... 37 

Quantum sandwich ............................................................................................................ 37 
Semiconductor quantum dots as ideal single-photon source ............................................... 38 
Noise in the semiconductor ............................................................................................... 38 
How to Win at Bridge Using Quantum Physics ..................................................................... 38 
Quantum Information............................................................................................................. 39 
Heralded Qubit Transfer ........................................................................................................ 39 
Quantum Teleportation ......................................................................................................... 40 
Quantum Computing ............................................................................................................. 40 
Quantum Entanglement ........................................................................................................ 41 
The Bridge ............................................................................................................................. 41 
Accelerating charges ......................................................................................................... 41 
Relativistic effect ................................................................................................................ 41 
Heisenberg Uncertainty Relation .......................................................................................... 42 
Wave – Particle Duality ......................................................................................................... 42 
Atomic model ......................................................................................................................... 42 
The Relativistic Bridge .......................................................................................................... 42 
The weak interaction ............................................................................................................. 43 
The General Weak Interaction ........................................................................................... 44 
Fermions and Bosons ........................................................................................................... 44 
Van Der Waals force ............................................................................................................. 44 
Electromagnetic inertia and mass ......................................................................................... 45 
Electromagnetic Induction ................................................................................................. 45 
Relativistic change of mass ............................................................................................... 45 
The frequency dependence of mass ................................................................................. 45 
Electron – Proton mass rate .............................................................................................. 45 
Gravity from the point of view of quantum physics ............................................................... 45 
The Gravitational force....................................................................................................... 45 
The Higgs boson ................................................................................................................... 46 
Higgs mechanism and Quantum Gravity .............................................................................. 47 
What is the Spin? ............................................................................................................... 47 
The Graviton ...................................................................................................................... 47 
Conclusions ........................................................................................................................... 48 
References ............................................................................................................................ 48 
 

  
Author: George Rajna  
Preface  
Where in your brain do you exist? Is your awareness of the world around you and of yourself as an 
individual the result of specific, focused changes in your brain, or does that awareness come from a 
broad network of neural activity? How does your brain produce awareness? [20]  
While physicists are continually looking for ways to unify the theory of relativity, which describes 
large-scale phenomena, with quantum theory, which describes small-scale phenomena, computer 
scientists are searching for technologies to build the quantum computer.   
Australian engineers detect in real-time the quantum spin properties of a pair of atoms inside a 
silicon chip, and disclose new method to perform quantum logic operations between two atoms. 
[5] Quantum entanglement is a physical phenomenon that occurs when pairs or groups of particles 
are generated or interact in ways such that the quantum state of each particle cannot be described 
independently – instead, a quantum state may be given for the system as a whole. [4]  
I think that we have a simple bridge between the classical and quantum mechanics by 
understanding the Heisenberg Uncertainty Relations. It makes clear that the particles are not point 
like but have a dx and dp uncertainty.   
  
Inhibitory neurons have two types of impact on brain oscillations  
Studying the brain involves measuring the activity of billions of individual brain cells called neurons. 
Consequently, many brain measurement techniques produce data that is averaged to reflect the 
activity of large populations of these neurons. If all of the neurons are behaving differently, this will 
average out. But, when the behaviour of individual neurons is synchronized, it produces clearly 
visible oscillations. 
Synchronisation is important to understanding how neurons behave, which is particularly relevant 
with regard to brain diseases like Alzheimer's, epilepsy and Parkinson's. Now, a group of 
researchers from the Institute of Computational Physics and Complex Systems at Lanzhou 
University, China, has used a combination of two computer models to study the ways different 
kinds of neurons can impact synchronisation. The study is published in the European Physical 
Journal B. 
To study the effects on synchronisation, the authors examined neurons called inhibitory neurons—
which work to slow down or stop the activity of other neurons. Moreover, they explored the 
likelihood of these inhibitory neurons firing either spontaneously or not at all within the network. 
Using computer models, the researchers then constructed an Izhikevich neural network; they 
also employed a model of neuronal transmission, called the Tsodyks-Uziel-Markram (TUM) model. 

Their findings indicate that inhibitory neurons can have a two-fold impact on oscillatory 
patterns. On the one hand, they can delay the firing of the neurons, which prevents 
synchronisation from happening. On the other, they can facilitate the transition of the oscillatory 
patterns, which is conducive to synchronisation. 
The research is important for increasing our understanding of brain diseases, like stroke, 
Alzheimer's and epilepsy. "The ever-increasing morbidity of brain diseases makes the investigation 
on this topic significant in both psychology and medicine" the authors say. [33] 
 
 
Researchers demonstrate a novel approach for measuring brain 
function connectivity  
Measuring optical blood flow in the resting human brain to detect spontaneous activity has for the 
first time been demonstrated by Wright State University imaging researchers, holding out promise 
for a better way to study people with autism, Alzheimer's and depression. 
Ulas Sunar, associate professor of biomedical, industrial and human factors engineering, and his 
team of researchers have shown that optical blood flow contrast measured by Diffuse Correlation 
Spectroscopy can be used to detect Resting State Functional Connectivity (RSFC) in the brain. 
The research team includes Sunar, who holds the endowed position of the Ohio Research Scholar 
for Medical Imaging at Wright State, and his researchers Chien Poon, Jun Li, Jeremy Kress and Dan 
Rohrbach. 
The team's findings were recently published in one of the top optical journals, the Journal of 
Biophotonics, covering research on the interactions between light and biological materials. The 
work has also been featured in the Biophotonics.World, which serves the worldwide biophotonics 
community as a central access point for the latest news and articles about recent scientific 
developments in academia and industry. 
The team's novel optical approach is based on detecting light scattering from moving blood cells 
and can quantify absolute cerebral blood flow-related contrast. It is a complementary technique to 
widely known functional near infrared spectroscopy that measures blood oxygenation. 
"We are seeing that blood flow shows higher contrast than oxygenation in our neuroimaging 
experiments," said Sunar. "Under neuronal firing brain may ask for more blood flow. That's why 
blood flow is an important parameter for assessing human brain resting state functional 
connectivity. And also the blood flow imaging technique is relatively new. The custom system was 
built here, by my Ph.D. student Chien Poon, and we demonstrated the resting state approach for 
the first time in our field." 
The researchers used blood flow parameter to quantify RSFC in nine healthy adult males as a proof-
of-concept study. The technique showed high connectivity between certain areas of the brain and 
low connectivity between other areas. The results match similar studies performed previously with 
other methods such as functional magnetic resonance imaging (fMRI). 

From left: Dan Rohrbach, Ulas Sunar, Ben Rinehart and Chien Poon in the Sunar Research Group lab 
in the Neuroscience Engineering Collaboration Building. Credit: Wright State University 
"These are exciting results in our field since the study has proven the potential of optical blood flow 
method as a non-invasive mean to assess RSFC in humans," Sunar told Biophotonics.World. 
"Cerebral blood flow is a very important parameter for neuronal disease characterization due to its 
high contrast." 
RSFC studies are a valuable tool for studying people with disorders that can make performing tasks 
difficult. But many people, such as young autistic children, are poor candidates for RSFC assessment 
by fMRI, which requires them to hold still for long intervals inside a confined imaging space with 
loud noise from the magnet. 
Optical imaging is highly suitable for such people because it is fast and can be performed by optical 
probes that can be worn by the patient. The researchers expect that this will ultimately become a 
highly useful tool for non-invasively assessing brain function in young and disabled patients. 
Sunar said the technology could also be used for assessing human performance to understand if a 
task increases cerebral blood flow and neural activity. 

"When a task is performed, what happens to the blood flow in the brain?" he said. "Is there a 
relationship? Is the brain network more connected at the resting state and performing state? These 
are interesting questions to investigate." 
The next step for the research team will be to modify the optical system to enable it to show both 
blood flow and oxygenation. 
"We are working on combining multiple imaging contrasts to get a more complete picture of 
the brain function," Sunar said. "For example, we can quantify cerebral metabolic rate of oxygen 
consumption by combining blood flow and oxygenation measurements. This approach will have a 
high impact in many areas, from neurological disease characterization in clinical settings to 
assessing the human performance relevant to military research." [32] 
 
Biologists 'transfer' a memory 
UCLA biologists report they have transferred a memory from one marine snail to another, creating 
an artificial memory, by injecting RNA from one to another. This research could lead to new ways to 
lessen the trauma of painful memories with RNA and to restore lost memories. 
"I think in the not-too-distant future, we could potentially use RNA to ameliorate the effects of 
Alzheimer's disease or post-traumatic stress disorder," said David Glanzman, senior author of the 
study and a UCLA professor of integrative biology and physiology and of neurobiology. The team's 
research is published May 14 in eNeuro, the online journal of the Society for Neuroscience. 
RNA, or ribonucleic acid, has been widely known as a cellular messenger that makes proteins and 
carries out DNA's instructions to other parts of the cell. It is now understood to have other 
important functions besides protein coding, including regulation of a variety of cellular processes 
involved in development and disease. 
The researchers gave mild electric shocks to the tails of a species of marine snail called Aplysia. The 
snails received five tail shocks, one every 20 minutes, and then five more 24 hours later. The shocks 
enhance the snail's defensive withdrawal reflex, a response it displays for protection from potential 
harm. When the researchers subsequently tapped the snails, they found those that had been given 
the shocks displayed a defensive contraction that lasted an average of 50 seconds, a simple type of 
learning known as "sensitization." Those that had not been given the shocks contracted for only 
about one second. 
The life scientists extracted RNA from the nervous systems of marine snails that received the tail 
shocks the day after the second series of shocks, and also from marine snails that did not receive 
any shocks. Then the RNA from the first (sensitized) group was injected into seven marine snails 
that had not received any shocks, and the RNA from the second group was injected into a control 
group of seven other snails that also had not received any shocks. 

UCLA Professor David Glanzman holding a marine snail. Credit: Christelle Snow/UCLA 
Remarkably, the scientists found that the seven that received the RNA from snails that were given 
the shocks behaved as if they themselves had received the tail shocks: They displayed a defensive 
contraction that lasted an average of about 40 seconds. 
"It's as though we transferred the memory," said Glanzman, who is also a member of UCLA's Brain 
Research Institute. 
As expected, the control group of snails did not display the lengthy contraction. 
Next, the researchers added RNA to Petri dishes containing neurons extracted from different snails 
that did not receive shocks. Some dishes had RNA from marine snails that had been given electric 
tail shocks, and some dishes contained RNA from snails that had not been given shocks. Some of 
the dishes contained sensory neurons, and others contained motor neurons, which in the snail are 
responsible for the reflex. 
When a marine snail is given electric tail shocks, its sensory neurons become more excitable. 
Interestingly, the researchers discovered, adding RNA from the snails that had been given shocks 
also produced increased excitability in sensory neurons in a Petri dish; it did not do so in motor 

neurons. Adding RNA from a marine snail that was not given the tail shocks did not produce this 
increased excitability in sensory neurons. 
David Glanzman holding a marine snail. Credit: Christelle Snow/UCLA 
In the field of neuroscience, it has long been thought that memories are stored in synapses. (Each 
neuron has several thousand synapses.) Glanzman holds a different view, believing that memories 
are stored in the nucleus of neurons. 
"If memories were stored at synapses, there is no way our experiment would have worked," said 
Glanzman, who added that the marine snail is an excellent model for studying the brain and 
memory. 
Scientists know more about the cell biology of this simple form of learning in this animal than any 
other form of learning in any other organism, Glanzman said. The cellular and molecular processes 
seem to be very similar between the marine snail and humans, even though the snail has about 
20,000 neurons in its central nervous system and humans are thought to have about 100 billion. 
In the future, Glanzman said, it is possible that RNA can be used to awaken and restore memories 
that have gone dormant in the early stages of Alzheimer's disease. He and his colleagues published 
research in the journal eLife in 2014 indicating that lost memories can be restored. 

There are many kinds of RNA, and in future research, Glanzman wants to identify the types of RNA 
that can be used to transfer memories. [31] 
  
 
'Sleeping' stem cells could aid brain repair  
Scientists at the Wellcome Trust/ Cancer Research UK Gurdon Institute, University of Cambridge, 
have identified a new type of stem cell in the brain which they say has a high potential for repair 
following brain injury or disease. 
A major goal of regenerative research is to repair the brain efficiently following injury, for example 
due to stroke, Alzheimer's disease or head trauma, disease or ageing. The brain is poor at repairing 
itself; however, it may become possible to improve repair without surgery by targeting 
stem cells residing in patients' brains. Stem cells have the unique capacity to produce all of the 
cells in the brain but are normally kept inactive in a form of cellular 'sleep' known as quiescence. 
Quiescent cells do not proliferate or generate new cells. Thus, any regenerative therapy targeting 
stem cells must first awaken them from quiescence. 
In a study published today in the journal Science, PhD student Leo Otsuki and his supervisor 
Professor Andrea Brand report the discovery in the brain of a new type of quiescent stem cell 
(known as 'G2 quiescent stem cell') with higher regenerative potential than quiescent stem cells 
identified previously. Importantly, G2 quiescent stem cells awaken to make the key types of cell in 
the brain - neurons and glia - much faster than known quiescent stem cells, making them attractive 
targets for therapeutic design. 

 
Stem cells are labelled in red, nuclear membranes in green and DNA in blue. Credit: Andrea 
Brand/Leo Otsuki 
"The brain is not good at repairing itself, but these newly-discovered stem cells suggest there may 
be a way to improve its ability," says Professor Brand. "These stem cells are in a dormant state, but 
once awake, they have the ability to generate key brain cells." 
By studying the fruit fly (Drosophila), the authors identified a gene known as tribbles that 
selectively regulates G2 quiescent stem cells. The DNA of fruit flies has many similarities with that 
of humans, making them a useful model to understand human biology, and 60% of 
human genes associated with disease are also found in Drosophila. The tribbles gene has 
counterparts in the mammalian genome that are expressed in stem cells in the brain. The 
researchers believe that drugs that target tribbles might be one route to awakening G2 quiescent 
stem cells. 
"We've found the gene that directs these cells to become quiescent," adds Otsuki. "The next step is 
to identify potential drug-like molecules that block this gene and awaken a person's stem cells. 
"We believe there may be similar quiescent stem cells in other organs, and this discovery could 
help improve or develop new regenerative medicines." [30] 
 
 

 
Using organoids to understand how the brain wrinkles 
A team of researchers working at the Weizmann Institute of Science has found that organoids can 
be used to better understand how the human brain wrinkles as it develops. In their paper published 
in the journal Nature Physics, the team describes how they used a modified form of organoid 
development to study the development of brain wrinkles. Larry Taber with Washington University 
offers a News & Views piece on the work done by the team in the same journal issue. 
An organoid is an artificially grown mass of cells meant to replicate human or other animal organs. 
They are typically much smaller than the organs they are meant to mimic, but allow researchers a 
unique means of studying how organs develop. In this new effort, the researchers sought to better 
understand the process by which the human brain develops wrinkles. Realizing that the standard 
approach used for creating organoids would not work in such a study, the team tried another 
tactic—they grew stem cells on platform that resulted in a brain organoid that was much thinner 
and rounder than it would naturally grow—and it was also grown on a form surrounding a narrow 
space. The end result, the team reports, was a brain organoid that resembled a pita. This 
configuration allowed the researchers to take images of folds as they developed and to supply 
nutrients to all the cells since blood vessels typically do not develop in organoids. 
In studying the images of the developing organoid, the researchers found that the folds developed 
as expected—opposing forces resulting from growth differences in brain material. In this case, it 
was the cytoskeleton in the organoid's core and the cell nucleus expanding at the organoid's outer 
edges. Uneven expansion between the two causes one or the other to fold as a means of dealing 
with the increase in pressure. 
To learn more about the development of folds, the researchers ran the same experiment again, but 
used stem cells from a patient with smooth brain syndrome, which, as it sounds, is a condition in 
which the brain develops without folds. As expected, the organoid developed very few folds. A 
closer look showed differences in elasticity between the cells in the organoid grown with healthy 
cells and the those with the mutated genes that are behind smooth brain syndrome. [29] 
 
 
 
Biologists find new source for brain's development  
A team of biologists has found an unexpected source for the brain's development, a finding that 
offers new insights into the building of the nervous system.  
The research, which appears in the journal Science, discovered that glia, a collection of non-
neuronal cells that had long been regarded as passive support cells, in fact are vital to nerve-cell 
development in the brain.  
"The results lead us to revise the often neuro-centric view of brain development to now appreciate 
the contributions for non-neuronal cells such as glia," explains Vilaiwan Fernandes, a postdoctoral 
fellow in New York University's Department of Biology and the study's lead author. "Indeed, our 
study found that fundamental questions in brain development with regard to the timing, identity, 

and coordination of nerve cell birth can only be understood when the glial contribution is 
accounted for."  
The brain is made up of two broad cell types, nerve cells or neurons and glia, which are non-nerve 
cells that make up more than half the volume of the brain. Neurobiologists have tended to focus 
on the former because these are the cells that form networks that process information.  
However, given the preponderance of glia in the brain's cellular make-up, the NYU researchers 
hypothesized that they could play a fundamental part in brain development.  
To explore this, they examined the visual system of the fruit fly. The species serves as a powerful 
model organism for this line of study because its visual system, like the one in humans, holds 
repeated mini-circuits that detect and process light over the entire visual field.  
This dynamic is of particular interest to scientists because, as the brain develops, it must 
coordinate the increase of neurons in the retina with other neurons in distant regions of the brain.  
In their study, the NYU researchers found that the coordination of nerve-cell development is 
achieved through a population of glia, which relay cues from the retina to the brain to make cells in 
the brain become nerve cells.  
"By acting as a signaling intermediary, glia exert precise control over not only when and where a 
neuron is born, but also the type of neuron it will develop into," notes NYU Biology Professor 
Claude  
Desplan, the paper's senior author. [28]  
Link Between Immune System, Memory and Brain Structure 
Discovered  
The body’s immune system performs essential functions, such as defending against bacteria and 
cancer cells. However, the human brain is separated from immune cells in the bloodstream by the 
so-called blood-brain barrier. This barrier protects the brain from pathogens and toxins circulating 
in the blood, while also dividing the immune cells of the human body into those that fulfill their 
function in the blood and those that work specifically in the brain. Until recently, it was thought 
that brain function was largely unaffected by the peripheral immune system.  
However, in the past few years, evidence has accumulated to indicate that the blood’s immune 
system could in fact have an impact on the brain. Scientists from the University of Basel’s 
Transfaculty Research Platform Molecular and Cognitive Neurosciences (MCN) have now carried 
out two independent studies that demonstrate that this link between the immune system and 
brain is more significant than previously believed.  
Search for regulatory patterns  
In the first study, the researchers searched for epigenetic profiles, i.e. regulatory patterns, in the 
blood of 533 young, healthy people. In their genome-wide search, they identified an epigenetic 
profile that is strongly correlated with the thickness of the cerebral cortex, in particular in a region 
of the brain that is important for memory functions. This finding was confirmed in an independent 
examination of a further 596 people. It also showed that it is specifically those genes that are 

responsible for the regulation of important immune functions in the blood that explain the link 
between the epigenetic profile and the properties of the brain.  
Gene variant intensifies traumatic memories  
In the second study, the researchers investigated the genomes of healthy participants who 
remembered negative images particularly well or particularly poorly. A variant of the TROVE2 gene, 
whose role in immunological diseases is currently being investigated, was linked to participants’ 
ability to remember a particularly high number of negative images, while their general memory 
remained unaffected.  
This gene variant also led to increased activity in specific regions of the brain that are important for 
the memory of emotional experiences. The researchers also discovered that the gene is linked to 
the strength of traumatic memories in people who have experienced traumatic events.  
The results of the two studies show that both brain structure and memory are linked to the activity 
of genes that also perform important immune regulatory functions in the blood. “Although the 
precise mechanisms behind the links we discovered still need to be clarified, we hope that this will 
ultimately lead to new treatment possibilities,” says Professor Andreas Papassotiropoulos, 
CoDirector of the University of Basel’s MCN research platform. The immune system can be 
precisely affected by certain medications, and such medications could also have a positive effect on 
impaired brain functions.  
Innovative research methods  
These groundbreaking findings were made possible thanks to cutting edge neuroscientific and 
genetic methods at the University of Basel’s MCN research platform. Under the leadership of 
Professor Andreas Papassotiropoulos and Professor Dominique de Quervain, the research platform 
aims to help us better understand human brain functions and to develop new treatments for 
psychiatric disorders. [27]  
Researcher looking to shed light deeper into the human brain  
The inner workings of the human brain have always been a subject of great interest. Unfortunately, 
it is fairly difficult to view brain structures or intricate tissues due to the fact that the skull is not 
transparent by design. The reality is that light scattering is the major obstacle for deep penetration 
into tissue.  
Dr. Vladislav Yakovlev, professor in the Department of Biomedical Engineering at Texas A&M 
University, has been developing a more efficient way of propagating light through an opaque 
medium. Propagation of light refers to the way that light travels from one point to another, in this 
case, through a medium, such as human tissue.  
The new method involves making a minimally invasive hole within the medium, which is smaller in 
diameter than needles that are currently being used within the medical field. The process shows a 
great deal of promise in many uses, including viewing brain structure through the skull and imaging 
blood through skin tissue.  

The technology could even be extended outside the realm of biomedical engineering to develop a 
more efficient way of seeing through fog while driving. This can be accomplished by deploying a 
laser pulse that could be sent through fog and evaporate water. This would allow drivers to have a 
safer experience during hazardous driving conditions and would work exactly as the method used 
in biomedical engineering applications.  
The holes used to pass the light through are a few hundred micrometers in depth and a width of 20 
to 30 microns. A micron is one millionth of a meter, and by comparison a single strand of human 
hair is about 75 microns in diameter. The light is then coupled into the opaque material resulting in 
an increase of magnitude of optical transmission into the material. The material that light is passed 
through is also referred to as the scattering medium.  
The report documenting the work of Yakovlev was recently published in Proceedings of the 
National Academy of Sciences of the United States of America and definitively demonstrated that 
light injected into the scattering medium will remain there for an extended period of time. The 
amount of time that the photons remained was increased by a factor of 100.  
One of the challenges facing researchers is that of optical absorption within tissues. However, 
because the new method is wavelength independent, the wavelength can be specified to perform 
measurements in a specific part of the light spectrum. This approach has the potential to yield 
analytical information about the composition and structure of the medium or tissue. [26]  
Brain scanners allow scientists to 'read minds'—could they now enable 
a 'Big Brother' future?  
Are you lying? Do you have a racial bias? Is your moral compass intact?To find out what you think 
or feel, we usually have to take your word for it. But questionnaires and other explicit measures to 
reveal what's on your mind are imperfect: you may choose to hide your true beliefs or you may not 
even be aware of them.  
But now there is a technology that enables us to "read the mind" with growing accuracy: functional 
magnetic resonance imaging (fMRI). It measures brain activity indirectly by tracking changes in 
blood flow – making it possible for neuroscientists to observe the brain in action. Because the 
technology is safe and effective, fMRI has revolutionised our understanding of the human brain. It 
has shed light on areas important for speech, movement, memory and many other processes.  
More recently, researchers have used fMRI for more elaborate purposes. One of the most 
remarkable studies comes from Jack Gallant's lab at the University of California. His team showed 
movie trailers to their volunteers and managed to reconstruct these video clips based on the 
subjects' brain activity, using a machine learning algorithm.  
In this approach, the computer developed a model based on the subject's brain activity rather than 
being fed a pre-programmed solution by the researchers. The model improved with practice and 
after having access to enough data, it was able to decode brain activity. The reconstructed clips 
were blurry and the experiment involved extended training periods. But for the first time, brain 
activity was decoded well enough to reconstruct such complex stimuli with impressive detail.  

Enormous potential  
So what could fMRI do in the future? This is a topic we explore in our new book Sex, Lies, and Brain 
Scans: How fMRI Reveals What Really Goes on in our Minds. One exciting area is lie detection. 
While early studies were mostly interested in finding the brain areas involved in telling a lie, more 
recent research tried to actually use the technology as a lie detector.  
As a subject in these studies, you would typically have to answer a series of questions. Some of 
your answers would be truthful, some would be lies. The computer model is told which ones are 
which in the beginning so it gets to know your "brain signature of lying" – the specific areas in your 
brain that light up when you lie, but not when you are telling the truth.  
Afterwards, the model has to classify new answers as truth or lies. The typical accuracy reported in 
the literature is around 90%, meaning that nine out of ten times, the computer correctly classified 
answers as lies or truths. This is far better than traditional measures such as the polygraph, which 
is thought to be only about 70% accurate. Some companies have now licensed the lie detection 
algorithms. Their next big goal: getting fMRI-based lie detection admitted as evidence in court.  
They have tried several times now, but the judges have ruled that the technology is not ready for 
the legal setting – 90% accuracy sounds impressive, but would we want to send somebody to 
prison if there is a chance that they are innocent? Even if we can make the technology more 
accurate, fMRI will never be error proof. One particularly problematic topic is the one of false 
memories. The scans can only reflect your beliefs, not necessarily reality. If you falsely believe that 
you have committed a crime, fMRI can only confirm this belief. We might be tempted to see brain 
scans as hard evidence, but they are only as good as your own memories: ultimately flawed.  
Still, this raises some chilling questions about the possibility for a "Big Brother" future where our 
innermost thoughts can be routinely monitored. But for now fMRI cannot be used covertly. You 
cannot walk through an airport scanner and be asked to step into an interrogation room, because 
your thoughts were alarming to the security personnel.  
Undergoing fMRI involves lying still in a big noise tube for long periods of time. The computer 
model needs to get to know you and your characteristic brain activity before it can make any 
deductions. In many studies, this means that subjects were being scanned for hours or in several 
sessions. There's obviously no chance of doing this without your knowledge – or even against your 
will. If you did not want your brain activity to be read, you could simply move in the scanner. Even 
the slightest movements can make fMRI scans useless.  
Although there is no immediate danger of undercover scans, fMRI can still be used unethically. It 
could be used in commercial settings without appropriate guidelines. If academic researchers want 
to start an fMRI study, they need to go through a thorough process, explaining the potential risks 
and benefits to an ethics committee. No such guidelines exist in commercial settings. Companies 
are free to buy fMRI scanners and conduct experiments with any design. They could show you 
traumatising scenes. Or they might uncover thoughts that you wanted to keep to yourself. And if 
your scan shows any medical abnormalities, they are not forced to tell you about it.  
Mapping the brain in great detail enables us to observe sophisticated processes. Researchers are 
beginning to unravel the brain circuits involved in self control and morality. Some of us may want 
to use this knowledge to screen for criminals or detect racial biases. But we must keep in mind that 

fMRI has many limitations. It is not a crystal ball. We might be able to detect an implicit racial bias 
in you, but this cannot predict your behaviour in the real world.  
fMRI has a long way to go before we can use it to fire or incarcerate somebody. But neuroscience is 
a rapidly evolving field. With advances in clever technological and analytical developments such as 
machine learning, fMRI might be ready for these futuristic applications sooner than we think. 
Therefore, we need to have a public discussion about these technologies now. Should we screen 
for terrorists at the airport or hire only teachers and judges who do not show evidence of a racial 
bias? Which applications are useful and beneficial for our society, which ones are a step too far? It 
is time to make up our minds. [25]  
'Latest spoke in the wheel' drives brain-mapping advances  
Advances in microscopy techniques have often triggered important discoveries in the field of 
neuroscience, enabling vital insights in understanding the brain and promising new treatments for 
neurodegenerative diseases such as Alzheimer's and Parkinson's. A special section on 
"Superresolution Microscopy of Neural Structure and Function" in the current issue of the journal 
Neurophotonics, published by SPIE, the international society for optics and photonics, details this 
work in reports on ground-breaking new research and reviews.  
Starting with the Golgi technique at the end of the 19th century, to electron microscopy in the 
1950s, to fluorescent confocal and two-photon microscopy at the close of the 20th century, 
microscopy techniques have driven important breakthroughs in neuroscience, note guest editors 
Valentin Nägerl and Jean-Baptiste Sibarita of the Université de Bordeaux and the CNRS in their 
editorial for the special section.  
"By providing higher spatial and temporal resolutions, as well as more contrast and specificity, 
these ground-breaking techniques have greatly informed our view of how the brain works," the 
editors write.  
Super-resolution fluorescence microscopy "is the latest spoke in the revolutionary wheel," the 
guest editors note. "Recognized with the Nobel Prize in chemistry in 2014 for overcoming the 
diffraction barrier of light microscopy, it unlocks a new potential to upend biological research at 
the molecular level. Ten years after their development in a handful of laboratories, super-
resolution microscopy techniques have caught on like wildfire and are now routinely used in a large 
number of biology labs."  
While super-resolution microscopy is a relative recent addition to the arsenal of tools available for 
neuroscientific research, said Neurophotonics editor-in-chief David Boas of Massachusetts General 
Hospital, Harvard Medical School, "the breadth of impactful applications is growing rapidly. This 
special section provides a snapshot of this growth with a collection of exciting papers illustrating 
the breadth of applications."  
Articles in the section, many of them accessible via open access, help validate and assess new 
techniques by comparing them with more established approaches. Among them:  
In "Filling the gap: adding super-resolution to array tomography for correlated ultrastructural and 
molecular identification of electrical synapses at the C. elegans connectome," Sebastian Matthias 

Markert of the University of Würzburg and co-authors describe a new method to correlate 
molecular information with ultrastructural context. Their aim is to allow researchers to dissect the 
molecular underpinnings of the ultrastructural organization and function of electrical synapses 
precisely and confidently.  
Producing nanoscale maps of protein organization on cell surfaces or within organelles is another 
exciting prospect in super-resolution microscopy. In "Counting numbers of synaptic proteins: 
absolute quantification and single molecule imaging techniques," Angela Patrizio and Christian 
Specht of École Normale Supérieure describe how single-molecule-based microscopy techniques 
offer unparalleled opportunities to study protein content and dynamics in key functional 
compartments.  
An early hallmark of neurodegenerative diseases such as Alzheimer's and Parkinson's is the 
misfolding and self-aggregation of proteins into amyloid structures that are believed to wreak 
havoc on neurons and synapses. In "Probing amyloid protein aggregation with optical super-
resolution methods: from the test tube to models of disease", Clemens Kaminski and Gabriele 
Kaminski Schierle of the University of Cambridge explain the potential of new optical super-
resolution techniques to provide insight on the molecular mechanism of the pathogenic self-
assembly process in vitro and inside cells. [24]  
Consciousness and Entropy  
What is the relationship of consciousness to the neurological activity of the brain? Does the brain 
behave differently when a person is fully conscious, when they are asleep, or when they are 
undergoing an epileptic seizure? A recent study by R. Guevara Erra, D. M. Mateos, R. Wennberg, 
J.L. Perez Velazquez of the University of Toronto, suggests that consciousness if correlated to a 
maximum number of neurological connections. In thermodynamics, this quantity, describing the 
complexity of a system, is entropy. In their paper, published in Physics Letters, they write:  
It has been said that complexity lies between order and disorder. In the case of brain activity, and 
physiology in general, complexity issues are being considered with increased emphasis. We sought 
to identify features of brain organization that are optimal for sensory processing, and that may 
guide the emergence of cognition and consciousness, by analysing neurophysiological recordings in 
conscious and unconscious states. We find a surprisingly simple result: normal wakeful states are 
characterised by the greatest number of possible configurations of interactions between brain 
networks, representing highest entropy values. Therefore, the information content is larger in the 
network associated to conscious states, suggesting that consciousness could be the result of an 
optimization of information processing. These findings encapsulate three main current theories of 
cognition, as discussed in the text, and more specifically the conceptualization of consciousness in 
terms of brain complexity. We hope our study represents the preliminary attempt at finding 
organising principles of brain function that will help to guide in a more formal sense inquiry into 
how consciousness arises from the organization of matter.  
The authors are rightly cautious about the significance of the correlation. Just because A and B are 
correlated, does not mean that A causes B. However the recognition that a phenomenon such as 
entropy may describe consciousness opens a new direction for consciousness research. [23]  

Consciousness is tied to 'entropy', say researchers  
Consciousness appears to arise naturally as a result of a brain maximizing its information content. 
So says a group of scientists in Canada and France, which has studied how the electrical activity in 
people's brains varies according to individuals' conscious states. The researchers find that normal 
waking states are associated with maximum values of what they call a brain's "entropy".  
Statistical mechanics is very good at explaining the macroscopic thermodynamic properties of 
physical systems in terms of the behaviour of those systems' microscopic constituent particles. 
Emboldened by this success, physicists have increasingly been trying to do a similar thing with the 
brain: namely, using statistical mechanics to model networks of neurons. Key to this has been the 
study of synchronization – how the electrical activity of one set of neurons can oscillate in phase 
with that of another set. Synchronization in turn implies that those sets of neurons are physically 
tied to one another, just as oscillating physical systems, such as pendulums, become synchronized 
when they are connected together.  
The latest work stems from the observation that consciousness, or at least the proper functioning 
of brains, is associated not with high or even low degrees of synchronicity between neurons but by 
middling amounts. Jose Luis Perez Velazquez, a biochemist at the University of Toronto, and 
colleagues hypothesized that what is maximized during consciousness is not connectivity itself but 
the number of different ways that a certain degree of connectivity can be achieved.  
Many ways of connecting  
Perez Velazquez's colleague Ramon Guevarra Erra, a physicist at the Paris Descartes University, 
points out that there is only one way to connect each set of neurons in a network with every other 
set, just as there is only one way to have no connections at all. In contrast, he notes, there are 
many different ways that an intermediate medium-sized number of connections can be arranged.  
To put their hypothesis to the test, the researchers used data previously collected by Perez 
Velazquez showing electric- and magnetic-field emissions from the brains of nine people, seven of 
whom suffered from epilepsy. With emissions recorded at dozens of places across the subjects' 
scalps, the researchers analysed every possible pairing of these data "channels" to establish 
whether the emissions in each case were in phase with one another. They added up the number of 
synchronized pairs and plugged that figure along with the total number of all possible pairings into 
a fairly straightforward statistical formula to work out how many different brain configurations 
that level of synchronicity yields. They then took the logarithm of that number to establish the 
brain's entropy.  
The data were analysed in two parts. In one, they compared the emissions from four of the 
epileptic patients when undergoing a seizure and when in a normal "alert" state. In the second, 
they compared emissions from the other five individuals when sleeping and when awake. In both 
cases, the bottom line was the same: subjects' brains display higher entropy, or a higher value of a 
similar quantity known as Lempel–Ziv (LZ) complexity, when in a fully conscious state.  
Varying results  
Guevarra Erra admits that the results are not watertight. Indeed, the LZ complexity of one of the 
four epileptic patients in the first analysis showed no change between seizure and alert states 
(although that person did remain conscious during part of the seizure). In another individual, LZ 

complexity actually increased in the second analysis while that person was asleep. Guevarra Erra 
says that he and his colleagues didn't carry out a statistical analysis of their results in part because 
of the "very heterogeneous" nature of those results. But he nevertheless remains "highly 
confident" that the correlations they have identified are real, particularly, he argues, because they 
were seen in "two very different sets of data".  
Peter McClintock, a physicist who works on nonlinear dynamics at Lancaster University in the UK, 
describes the research as "intriguing" but says that the consciousness–entropy correlation should 
be confirmed using a larger number of subjects. He also suggests investigating "what happens in 
other brain states where consciousness is altered", such as anaesthesia.  
Emergent property  
Perez Velazquez and colleagues argue that consciousness could simply be an "emergent property" 
of a system – the brain – that seeks to maximize information exchange and therefore entropy, 
since doing so aids the survival of the brain's bearer by allowing them to better model their 
environment. On the question of entropy, however, Guevarra Erra is cautious. He says that 
personally he would like to have a better understanding of the physical processes taking place in 
the brain before employing the label "entropy", explaining that Perez Velazquez was keen to use 
the term in their paper. One option, he says, would be to carry out fresh experiments that measure 
thermodynamic quantities in subjects' brains. He notes, for example, that magnetic resonance 
imaging can be used to measure oxygenation, which is directly related to metabolism and 
therefore to the generation of heat.  
Guevarra Erra adds that he would like to extend their investigations beyond the hospital to cover 
more subtle but general cognitive behaviour. The idea would be to monitor a person's changing 
brain activity as they focus on carrying out a specific task, such as discriminating between musical 
tones or trying to find their way round a labyrinth. This, he says, should help to establish whether 
varying "entropy" correlates with degree of awareness as well as simply with the presence or 
absence of consciousness.  
A paper describing the work will be published in Physical Review E and is also available on arXiv. 
[22]  
A new study looks for the cortical conscious network  
New research published in the New Journal of Physics tries to decompose the structural layers of 
the cortical network to different hierarchies enabling to identify the network's nucleus, from which 
our consciousness could emerge.  
The brain is a very complex network, with approximately 100 billion neurons and 100 trillion 
synapses between the neurons. In order to cope with its enormous complexity and to understand 
how brain function eventually creates the conscious mind, science uses advanced mathematical 
tools. Ultimately, scientists want to understand how a global phenomenon such as consciousness 
can emerge from our neuronal network.  
A team of physicists from Bar Ilan University in Israel led by Professor Shlomo Havlin and Professor 
Reuven Cohen used network theory in order to deal with this complexity and to determine how the 

structure of the human cortical network can support complex data integration and conscious 
activity. The gray area of the human cortex, the neuron cell bodies, were scanned with MRI 
imaging and used to form 1000 nodes in the cortical network. The white matter of the human 
cortex, the neuron bundles, were scanned with DTI imaging, forming 15,000 links or edges that 
connected the network's nodes. In the end of this process, their network was an approximation of 
the structure of the human cortex.  
Previous studies have shown that the human cortex is a network with small world properties, 
which means that it has many local structures and some shortcuts from global structures that 
connect faraway areas (similar to the difference between local buses and cross-country trains). The 
cortex also has many hubs, which are nodes that have a high number of links (like central stations), 
that are also strongly interconnected between themselves, making it easy to travel between the 
brain's information highways.  
Nir Lahav, the lead author of the study, says, "In order to examine how the structure of the 
network can support global emerging phenomena like consciousness, we applied a network 
analysis called Kshell decomposition. This analysis takes into account the connectivity profile of 
each node, making it easy to uncover different neighborhoods of connections in the cortical 
network, which we called shells."  
The most connected neighborhood in the network is termed the network's nucleus. Nir says, "In 
the process, we peel off different shells of the network to get the most connected area of the 
network, the nucleus. Until today, scientists were only interested in the network's nucleus, but we 
found that these different shells can hold important information about how the brain integrates 
information from the local levels of each node to the entire global network. For the first time, we 
could build a comprehensive topological model of the cortex."  
This topological model reveals that the network's nucleus includes 20 percent of all nodes and that 
the remaining 80 percent are strongly connected across all of the shells. Interestingly, comparing 
this topology to that of other networks, such as the internet, noticeable differences are apparent. 
For instance, in internet network topology, almost 25 percent of the nodes are isolated, meaning 
they don't connect to any other shells but the nucleus. In the cortical network, however, there are 
hardly any isolated nodes. It seems that the cortex is much more connected and efficient than the 
internet.  
Looking at all the shells of the cortical network, the authors were able to define the network's 
hierarchical structure and essentially model how information flows within the network. The 
structure revealed how shells of low connectivity are nodes that typically perform specific 
functions like face recognition. From there, the data is transferred to higher, more connected shells 
that enable additional data integration. This reveals regions of the executive network and working 
memory. With these areas, researchers can focus on task performance, for example.  
The integrated information then 'travels' to the most connected neighborhood of nodes, the 
nucleus, which spans across several regions of the cortex. According to Nir, "It's an interconnected 
collective which is densely linked with itself and can perform global functions due to its great 
number of global structures, which are widespread across the brain."  

Which global function might the nucleus serve? The authors suggest the answer is no less than 
consciousness itself.  
"The connection between brain activity and consciousness is still a great mystery," says Nir. The 
main hypothesis today is that in order to create conscious activity, the brain must integrate 
relevant information from multiple areas of the network. According to this theory, led by Professor 
Giulio Tononi from the University of Wisconsin, if the level of integrated information crosses a 
certain limit, a new and emergent state is entered—consciousness. This model suggests that 
consciousness depends on both information integration and information segregation. Loosely 
speaking, consciousness is generated by a "central" network structure with a high capacity for 
information integration, with the contribution of sub-networks that contain specific and 
segregated information without being part of the central structure. In other words, certain parts of 
the brain are more involved than others in the conscious complex of the brain, yet other connected 
parts still contribute, working quietly outside the conscious complex.  
The authors demonstrate how the nucleus and the shells satisfy all of the requirements of these 
recent consciousness theories. The shells calculate and contribute to data integration without 
actually being part of the conscious complex, while the nucleus receives relevant information from 
all other hierarchies and integrates it to a unified function using its global interconnected structure.  
The nucleus could thus be this conscious complex, serving as a platform for consciousness to 
emerge from the network activity.  
When the authors examined the different regions that make up the nucleus, they revealed that, 
indeed, these regions have been previously associated with conscious activities. For example, 
structures within the brain's midline, which form the majority of the network's nucleus, were 
found to be associated with the stream of consciousness, and some researchers, like Professor 
Georg Northoff from the University of Ottawa, have suggested that these regions are involved with 
creating our sense of self.  
"Now, we need to use this analysis on the whole brain, and not only on the cortex in order to 
reveal a more exact model of the brain's hierarchy, and later on understand what, exactly, are the 
neuronal dynamics that lead to such global integration and ultimately consciousness." [21]  
Network theory sheds new light on origins of consciousness  
Where in your brain do you exist? Is your awareness of the world around you and of yourself as an 
individual the result of specific, focused changes in your brain, or does that awareness come from a 
broad network of neural activity? How does your brain produce awareness?  
Vanderbilt University researchers took a significant step toward answering these longstanding 
questions with a recent brain imaging study, in which they discovered global changes in how brain 
areas communicate with one another during awareness. Their findings, which were published 
March 9 in the Proceedings of the National Academy of Sciences, challenge previous theories that 
hypothesized much more restricted changes were responsible for producing awareness.  
"Identifying the fingerprints of consciousness in humans would be a significant advancement for 
basic and medical research, let alone its philosophical implications on the underpinnings of the 

human experience," said René Marois, professor and chair of psychology at Vanderbilt University 
and senior author of the study. "Many of the cognitive deficits observed in various neurological 
diseases may ultimately stem from changes in how information is communicated throughout the 
brain."  
Using graph theory, a branch of mathematics concerned with explaining the interactive links 
between members of a complex network, such as social networks or flight routes, the researchers 
aimed to characterize how connections between the various parts of the brain were related to 
awareness.  
"With graph theory, one can ask questions about how efficiently the transportation networks in the 
United States and Europe are connected via transportation hubs like LaGuardia Airport in New 
York," Douglass Godwin, graduate student and lead author on the research, said. "We can ask 
those same questions about brain networks and hubs of neural communication."  
Modern theories of the neural basis of consciousness fall generally into two camps: focal and 
global. Focal theories contend there are specific areas of the brain that are critical for generating 
consciousness, while global theories argue consciousness arises from large-scale brain changes in 
activity. This study applied graph theory analysis to adjudicate between these theories.  
The researchers recruited 24 members of the university community to participate in a functional 
magnetic resonance imaging (fMRI) experiment. While in the fMRI scanner, participants were 
asked to detect a disk that was briefly flashed on a screen. In each trial, participants responded 
whether they were able to detect the target disk and how much confidence they had in their 
answer. Experimenters then compared the results of the high-confidence trials during which the 
target was detected to the trials when it was missed by participants. These were treated as 
"aware" and "unaware" trials, respectively.  
Comparison of aware and unaware trials using conventional fMRI analyses that assess the 
amplitude of brain activity showed a pattern of results typical of similar studies, with only a few 
areas of the brain showing more activity during detection of the target than when participants 
missed seeing it. The present study, however, was interested not simply in what regions might be 
more activated with awareness, but how they communicate with one another.  
Unlike the focal results seen using more conventional analysis methods, the results via this network 
approach pointed toward a different conclusion. No one area or network of areas of the brain 
stood out as particularly more connected during awareness of the target; the whole brain 
appeared to become functionally more connected following reports of awareness.  
"We know there are numerous brain networks that control distinct cognitive functions such as 
attention, language and control, with each node of a network densely interconnected with other 
nodes of the same network, but not with other networks," Marois said. "Consciousness appears to 
break down the modularity of these networks, as we observed a broad increase in functional 
connectivity between these networks with awareness."  
The research suggests that consciousness is likely a product of this widespread communication, and 
that we can only report things that we have seen once they are being represented in the brain in 
this manner. Thus, no one part of the brain is truly the "seat of the soul," as René Descartes once 

wrote in a hypothesis about the pineal gland, but rather, consciousness appears to be an emergent 
property of how information that needs to be acted upon gets propagated throughout the brain.  
"We take for granted how unified our experience of the world is. We don't experience separate 
visual and auditory worlds, it's all integrated into a single conscious experience," Godwin said. "This 
widespread cross-network communication makes sense as a mechanism by which consciousness 
gets integrated into that singular world." [20]  
Neuromorphic computing mimics important brain feature  
When you hear a sound, only some of the neurons in the auditory cortex of your brain are 
activated. This is because every auditory neuron is tuned to a certain range of sound, so that each 
neuron is more sensitive to particular types and levels of sound than others. In a new study, 
researchers have designed a neuromorphic ("brain-inspired") computing system that mimics this 
neural selectivity by using artificial level-tuned neurons that preferentially respond to specific types 
of stimuli.  
In the future, level-tuned neurons may help enable neuromorphic computing systems to perform 
tasks that traditional computers cannot, such as learning from their environment, pattern 
recognition, and knowledge extraction from big data sources.  
The researchers, Angeliki Pantazi et al., at IBM Research-Zurich and École Polytechnique Fédérale 
de Lausanne, both in Switzerland, have published a paper on the new neuromorphic architecture in 
a recent issue of Nanotechnology.  
Like all neuromorphic computing architectures, the proposed system is based on neurons and their 
synapses, which are the junctions where neurons send signals to each other. In this study, the 
researchers physically implemented artificial neurons using phase-change materials. These 
materials have two stable states: a crystalline, low-resistivity state and an amorphous, high-
resistivity state. Just as in traditional computing, the states can be switched by the application of a 
voltage.   
When the neuron's conductance reaches a certain threshold, the neuron fires.  
"We have demonstrated that phase-change-based memristive devices can be used to create 
artificial neurons and synapses to store and process data," coauthor Evangelos Eleftheriou at IBM 
ResearchZurich told Phys.org. "A phase-change neuron uses the phase configuration of the phase-
change material to represent its internal state, the membrane potential. For the phase-change 
synapse, the synaptic weight—which is responsible for the plasticity—is encoded by the 
conductance of the nanodevice."  
In this architecture, each neuron is tuned to a specific range, or level. Neurons receive signals from 
many other neurons, and a level is defined as the cumulative contribution of the sum of these 
incoming signals.  
"We have introduced the biologically inspired architecture of level-tuned neurons that is able to 
distinguish different patterns in an unsupervised way," Eleftheriou said. "This is important for the 
development of ultra-dense, scalable and energy-efficient neuromorphic computing."  

One of the main advantages of these highly selective level-tuned neurons is their improved 
learning ability. In neuromorphic computing, learning occurs through repeated incoming signals, 
which strengthens certain synaptic connections. The researchers showed that level-tuned neurons 
are very good at learning multiple input patterns, even in the presence of input noise.  
"Even a single neuron can be used to detect patterns and to discover correlations in real-time 
streams of event-based data," Eleftheriou said. "Level-tuned neurons increase the capability of a 
single-neuron network for discriminating information when multiple patterns appear at the input. 
Level-tuned neurons, along with the high-speed and low-energy characteristics of their 
phasechange-based implementation, will be particularly useful for various emerging applications, 
such as Internet of Things, that collect and analyze large volumes of sensory information and 
applications to detect patterns in data sources, such as from social media to discover trends, or 
weather data for real-time forecasts, or healthcare data to detect patterns in diseases, etc."  
In the future, the researchers plan to further develop the concept of artificial level-tuned neurons 
in order to design enhanced large-scale neural networks.  
"We will be looking into more complex computational tasks based on artificial spiking neurons and 
their synapses," Eleftheriou said. "We are interested in studying the scaling potential and 
applications of such neuromorphic systems in cognitive computing systems." [19]  
IBM scientists imitate the functionality of neurons with a phasechange 
device  
IBM scientists have created randomly spiking neurons using phase-change materials to store and 
process data. This demonstration marks a significant step forward in the development of 
energyefficient, ultra-dense integrated neuromorphic technologies for applications in cognitive 
computing.  
Inspired by the way the biological brain functions, scientists have theorized for decades that it 
should be possible to imitate the versatile computational capabilities of large populations of 
neurons. However, doing so at densities and with a power budget that would be comparable to 
those seen in biology has been a significant challenge, until now.  
"We have been researching phase-change materials for memory applications for over a decade, 
and our progress in the past 24 months has been remarkable," said IBM Fellow Evangelos 
Eleftheriou. "In this period, we have discovered and published new memory techniques, including 
projected memory, stored 3 bits per cell in phase-change memory for the first time, and now are 
demonstrating the powerful capabilities of phase-change-based artificial neurons, which can 
perform various computational primitives such as data-correlation detection and unsupervised 
learning at high speeds using very little energy."  
The artificial neurons designed by IBM scientists in Zurich consist of phase-change materials, 
including germanium antimony telluride, which exhibit two stable states, an amorphous one 
(without a clearly defined structure) and a crystalline one (with structure). These materials are the 
basis of re-writable Blu-ray discs.   
However, the artificial neurons do not store digital information; they are analog, just like the 
synapses and neurons in our biological brain.  

In the published demonstration, the team applied a series of electrical pulses to the artificial 
neurons, which resulted in the progressive crystallization of the phase-change material, ultimately 
causing the neuron to fire. In neuroscience, this function is known as the integrate-and-fire 
property of biological neurons. This is the foundation for event-based computation and, in 
principle, is similar to how our brain triggers a response when we touch something hot.  
Exploiting this integrate-and-fire property, even a single neuron can be used to detect patterns and 
discover correlations in real-time streams of event-based data.   
For example, in the Internet of Things, sensors can collect and analyze volumes of weather data 
collected at the edge for faster forecasts. The artificial neurons could be used to detect patterns in 
financial transactions to find discrepancies or use data from social media to discover new cultural 
trends in real time. Large populations of these high-speed, low-energy nano-scale neurons could 
also be used in neuromorphic coprocessors with co-located memory and processing units.  
IBM scientists have organized hundreds of artificial neurons into populations and used them to 
represent fast and complex signals. Moreover, the artificial neurons have been shown to sustain 
billions of switching cycles, which would correspond to multiple years of operation at an update 
frequency of 100 Hz. The energy required for each neuron update was less than five picojoule and 
the average power less than 120 microwatts—for comparison, 60 million microwatts power a 60 
watt lightbulb.   
"Populations of stochastic phase-change neurons, combined with other nanoscale computational 
elements such as artificial synapses, could be a key enabler for the creation of a new generation of 
extremely dense neuromorphic computing systems," said Tomas Tuma, a co-author of the paper. 
[18]  
Programmable ions set the stage for general-purpose quantum 
computers  
An ion trap with four segmented blade electrodes used to trap a linear chain of atomic ions for 
quantum information processing. Each ion is addressed optically for individual control and readout 
using the high optical access of the trap.  
Quantum computers promise speedy solutions to some difficult problems, but building large-scale, 
general-purpose quantum devices is a problem fraught with technical challenges.  
To date, many research groups have created small but functional quantum computers. By 
combining a handful of atoms, electrons or superconducting junctions, researchers now regularly 
demonstrate quantum effects and run simple quantum algorithms—small programs dedicated to 
solving particular problems.  
But these laboratory devices are often hard-wired to run one program or limited to fixed patterns 
of interactions between the quantum constituents. Making a quantum computer that can run 
arbitrary algorithms requires the right kind of physical system and a suite of programming tools. 
Atomic ions, confined by fields from nearby electrodes, are among the most promising platforms 
for meeting these needs.  

In a paper published as the cover story in Nature on August 4, researchers working with 
Christopher  
Monroe, a Fellow of the Joint Quantum Institute and the Joint Center for Quantum Information 
and Computer Science at the University of Maryland, introduced the first fully programmable and 
reconfigurable quantum computer module. The new device, dubbed a module because of its 
potential to connect with copies of itself, takes advantage of the unique properties offered by 
trapped ions to run any algorithm on five quantum bits, or qubits—the fundamental unit of 
information in a quantum computer.  
"For any computer to be useful, the user should not be required to know what's inside," Monroe 
says. "Very few people care what their iPhone is actually doing at the physical level. Our 
experiment brings high-quality quantum bits up to a higher level of functionality by allowing them 
to be programmed and reconfigured in software."  
The new module builds on decades of research into trapping and controlling ions. It uses standard 
techniques but also introduces novel methods for control and measurement. This includes 
manipulating many ions at once using an array of tightly-focused laser beams, as well as dedicated 
detection channels that watch for the glow of each ion.  
"These are the kinds of discoveries that the NSF Physics Frontiers Centers program is intended to 
enable," says Jean Cottam Allen, a program director in the National Science Foundation's physics 
division. "This work is at the frontier of quantum computing, and it's helping to lay a foundation 
and bring practical quantum computing closer to being a reality."  
The team tested their module on small instances of three problems that quantum computers are 
known to solve quickly. Having the flexibility to test the module on a variety of problems is a major 
step forward, says Shantanu Debnath, a graduate student at JQI and the paper's lead author. "By 
directly connecting any pair of qubits, we can reconfigure the system to implement any algorithm," 
Debnath says. "While it's just five qubits, we know how to apply the same technique to much 
larger collections."  
At the module's heart, though, is something that's not even quantum: A database stores the best 
shapes for the laser pulses that drive quantum logic gates, the building blocks of quantum 
algorithms. Those shapes are calculated ahead of time using a regular computer, and the module 
uses software to translate an algorithm into the pulses in the database.  
Putting the pieces together  
Every quantum algorithm consists of three basic ingredients. First, the qubits are prepared in a 
particular state; second, they undergo a sequence of quantum logic gates; and last, a quantum 
measurement extracts the algorithm's output.  
The module performs these tasks using different colors of laser light. One color prepares the ions 
using a technique called optical pumping, in which each qubit is illuminated until it sits in the 
proper quantum energy state. The same laser helps read out the quantum state of each atomic ion 
at the end of the process. In between, a separate laser strikes the ions to drive quantum logic 
gates.  

These gates are like the switches and transistors that power ordinary computers. Here, lasers push 
on the ions and couple their internal qubit information to their motion, allowing any two ions in 
the module to interact via their strong electrical repulsion. Two ions from across the chain notice 
each other through this electrical interaction, just as raising and releasing one ball in a Newton's 
cradle transfers energy to the other side.  
The re-configurability of the laser beams is a key advantage, Debnath says. "By reducing an 
algorithm into a series of laser pulses that push on the appropriate ions, we can reconfigure the 
wiring between these qubits from the outside," he says. "It becomes a software problem, and no 
other quantum computing architecture has this flexibility."  
To test the module, the team ran three different quantum algorithms, including a demonstration of 
a Quantum Fourier Transform (QFT), which finds how often a given mathematical function repeats. 
It is a key piece in Shor's quantum factoring algorithm, which would break some of the most 
widelyused security standards on the internet if run on a big enough quantum computer.  
Two of the algorithms ran successfully more than 90% of the time, while the QFT topped out at a 
70% success rate. The team says that this is due to residual errors in the pulse-shaped gates as well 
as systematic errors that accumulate over the course of the computation, neither of which appear 
fundamentally insurmountable.   
They note that the QFT algorithm requires all possible two-qubit gates and should be among the 
most complicated quantum calculations.  
The team believes that eventually more qubits—perhaps as many as 100—could be added to their 
quantum computer module. It is also possible to link separate modules together, either by 
physically moving the ions or by using photons to carry information between them.  
Although the module has only five qubits, its flexibility allows for programming quantum 
algorithms that have never been run before, Debnath says. The researchers are now looking to run 
algorithms on a module with more qubits, including the demonstration of quantum error 
correction routines as part of a project funded by the Intelligence Advanced Research Projects 
Activity. [17]  
Realizing quantum bits  
A research team from Germany, France and Switzerland has realised quantum bits, short qubits, in 
a new form. One day, they might become the information units of quantum computers.  
To date, researchers have realised qubits in the form of individual electrons (aktuell.ruhr-
unibochum.de/pm2012/pm00090.html.en). However, this led to interferences and rendered the 
information carriers difficult to programme and read. The group has solved this problem by 
utilising electron holes as qubits, rather than electrons.  
A report has been published in the journal Nature Materials by a team of researchers from 
RuhrUniversität Bochum, the University of Basel, and Lyon University; among its contributors were 
the two Bochum-based researchers Prof Dr Andreas Wieck and Dr Arne Ludwig from the Chair of 

Applied Solid State Physics. The project was headed by the Swiss researcher Prof Dr Richard 
Warburton.  
Electrons as qubits  
In order to realise qubits in the form of electrons, an electron is locked in a tiny semiconductor 
volume, the so-called quantum dot. The spin turns the electron into a small permanent magnet.  
Researchers are able to manipulate the spin via an external magnetic field and initiate precession. 
The direction of the spin is used to code information.  
The problem: the nuclear spins of the surrounding atoms also generate magnetic fields, which 
distort the external magnetic field in a random, unpredictable manner. This, in turn, interferes with 
programming and reading qubits. Consequently, the team searched for another method. The 
solution: rather than locking individual electrons in the quantum dot, the team removed specific 
electrons. Thus, positively charged vacancies were generated in the electron structure, so-called 
electron holes.  
Advantages of electron holes  
Electron holes have a spin, too. Researchers can manipulate it via the magnetic field in order to 
code information. As the holes are positively charged, they are decoupled from the nuclei of the 
surrounding atoms, which are likewise positively charged. This is why they are virtually immune 
against the interfering forces of the nuclear spin.  
"This is important if we one day want to manufacture reproducible components that are based on 
quantum bits," explains Andreas Wieck. However, this method is only applicable at low 
temperatures, as the holes are more likely to be disturbed by warmth than the electrons.  
At Ruhr-Universität, researchers are able to generate quantum dots of outstanding quality. The 
experiment could be conducted thanks to a structural design developed by Arne Ludwig in Basel 
and subsequently realised at the RUB Department headed by Andreas Wieck. It enabled the 
researcher to apply not just individual electrons to quantum dots, but also electron holes. Sascha 
René Valentin, PhD student from Bochum, utilised the technique for the purpose of the current 
study. [16]  
Russian physicists discover a new approach for building quantum 
computers  
Physicists from MIPT and the Russian Quantum Center have developed an easier method to create 
a universal quantum computer using multilevel quantum systems (qudits), each one of which is 
able to work with multiple "conventional" quantum elements – qubits.  
Professor Vladimir Man'ko, Aleksey Fedorov and Evgeny Kiktenko have published the results of 
their studies of multilevel quantum systems in a series of papers in Physical Review A, Physics 
Letters A, and also Quantum Measurements and Quantum Metrology.  
"In our studies, we demonstrated that correlations similar to those used for quantum information 
technologies in composite quantum systems also occur in non-composite systems – systems which 
we suppose may be easier to work with in certain cases. In our latest paper we proposed a method 

of using entanglement between internal degrees of freedom of a single eight-level system to 
implement the protocol of quantum teleportation, which was previously implemented 
experimentally for a system of three two-level systems," says Vladimir Man'ko.  
Quantum computers, which promise to bring about a revolution in computer technology, could be 
built from elementary processing elements called quantum bits – qubits. While elements of 
classical computers (bits) can only be in two states (logic zero and logic one), qubits are based on 
quantum objects that can be in a coherent superposition of two states, which means that they can 
encode the intermediate states between logic zero and one. When a qubit is measured, the 
outcome is either a zero or a one with a certain probability (determined by the laws of quantum 
mechanics).  
In a quantum computer, the initial condition of a particular problem is written in the initial state 
of the qubit system, then the qubits enter into a special interaction (determined by the specific 
problem). Finally, the user reads the answer to the problem by measuring the final states of the 
quantum bits.  
Quantum computers will be able to solve certain problems that are currently far beyond the reach 
of even the most powerful classical supercomputers. In cryptography, for example, the time 
required for a conventional computer to break the RSA algorithm, which is based on the prime 
factorization of large numbers, would be comparable to the age of the universe. A quantum 
computer, on the other hand, could solve the problem in a matter of minutes.  
However, there is a significant obstacle standing in the way of a quantum revolution – the 
instability of quantum states. Quantum objects that are used to create qubits – ions, electrons, 
Josephson junctions etc. can only maintain a certain quantum state for a very short time. However, 
calculations not only require that qubits maintain their state, but also that they interact with one 
another. Physicists all over the world are trying to extend the lifespan of qubits. Superconducting 
qubits used to "survive" only for a few nanoseconds, but now they can be kept for milliseconds 
before decoherence – which is closer to the time required for calculations.  
In a system with dozens or hundreds of qubits, however, the problem is fundamentally more 
complex.  
Man'ko, Fedorov, and Kiktenko began to look at the problem from the other way around – rather 
than try to maintain the stability of a large qubit system, they tried to increase the dimensions of 
the systems required for calculations. They are investigating the possibility of using qudits rather 
than qubits for calculations. Qudits are quantum objects in which the number of possible states 
(levels) is greater than two (their number is denoted by the letter D). There are qutrits, which have 
three states; ququarts, which have four states, etc. Algorithms are now actively being studied in 
which the use of qudits could prove to be more beneficial than using qubits.  
"A qudit with four or five levels is able to function as a system of two "ordinary" qubits, and eight 
levels is enough to imitate a three-qubit system. At first, we saw this as a mathematical 
equivalence allowing us to obtain new entropic correlations. For example, we obtained the value of 
mutual information (the measure of correlation) between virtual qubits isolated in a state space of 
a single four-level system," says Fedorov.  

He and his colleagues demonstrated that on one qudit with five levels, created using an artificial 
atom, it is possible to perform full quantum computations—in particular, the realization of the 
Deutsch algorithm. This algorithm is designed to test the values of a large number of binary 
variables.  
It can be called the fake coin algorithm: imagine that you have a number of coins, some of which 
are fake – they have the same image on the obverse and reverse sides. To find these coins using 
the "classical method", you have to look at both sides. With the Deutsch algorithm, you "merge" 
the obverse and reverse sides of the coin and you can then see a fake coin by only looking at one 
side.  
The idea of using multilevel systems to emulate multi-qubit processors was proposed earlier in the 
work of Russian physicists from the Kazan Physical-Technical Institute. To run a two-qubit Deutsch 
algorithm, for example, they proposed using a nuclear spin of 3/2 with four different states. In 
recent years, however, experimental progress in creating qudits in superconducting circuits has 
shown that they have a number of advantages.  
However, superconducting circuits require five levels: the last level performs an ancillary role to 
allow for a complete set of all possible quantum operations.  
"We are making significant progress, because in certain physical implementations, it is easier to 
control multilevel qudits than a system of the corresponding number of qubits, and this means that 
we are one step closer to creating a full-fledged quantum computer. Multilevel elements offer 
advantages in other quantum technologies too, such as quantum cryptography," says Fedorov. [15]  
Precise atom implants in silicon provide a first step toward practical 
quantum computers  
Sandia National Laboratories has taken a first step toward creating a practical quantum computer, 
able to handle huge numbers of computations instantaneously.  
  
Here's the recipe:  
A "donor" atom propelled by an ion beam is inserted very precisely in microseconds into an 
industrystandard silicon substrate.  
The donor atom—in this case, antimony (Sb) —carries one more electron (five) than a silicon atom 
(four). Because electrons pair up, the odd Sb electron remains free.  
Instruments monitor the free electron to determine if, under pressure from an electromagnetic 
field, it faces up or down, a property called "spin." Electrons in this role, called qubits, signal "yes" 
or "no" from the subatomic scale, and so act as the information bearers of a quantum computer.  
The ability to precisely place a donor atom in silicon means that it should be possible to insert a 
second donor atom just far enough away, in the "Goldilocks" zone where communication is neither 
lost through distance nor muffled by too-close proximity. Sandia will try to do this later this year, 
said lead researcher Meenakshi Singh, a postdoctoral fellow. Qubits "talking" to each other are the 
basis of quantum computing circuits.  

The successful Sandia first step, reported in Applied Physics Letters, makes use of electromagnetic 
forces provided by a neighboring quantum dot pre-embedded in the silicon. The quantum dot—
itself a tiny sea of electrons—contains a variety of energy levels and operates like a transistor to 
block or pass the qubit.  
If an available dot energy level is compatible with the electron, the transistor gate is effectively 
open and the electron jumps into the dot. If not, the qubit stays put. That action is reported back 
to the surface by a photodiode sensor sensitive to current flows rather than photon movement. 
Because of the multiple "gates" in the quantum dot, many qubits at different energy levels could 
pass through the transistor, or be denied passage, theoretically making possible an extremely wide 
array of information processing.  
"Our method is promising because, since it reads the electron's spin rather than its electrical 
charge, its information is not swallowed by background static and instead remains coherent for a 
relatively long time," Singh said. "Also, we use silicon as our basic material, for which commercial 
fabrication technologies are already developed, rather than employing superconducting 
components that can be expensive."  
A third unique quality of the Sandia method is the precise and rapid placement of donor atoms 
exactly where they should be, placed in microseconds within nanometers of their target, instead of 
a buckshot approach that places qubits only where they statistically average to Goldilocks 
distances.  
While components of this experiment have been demonstrated before, this is the first time all have 
worked together on a single chip, with researchers knowing accurately the vertical and horizontal 
placement of each qubit, instead of mere statistical approximations.  
Sandia researcher and paper author Mike Lilly expects "the Sandia technique will allow fabrication 
of more complicated multi-qubit structures and do so at higher yield than existing donor implant 
approaches."  
Components of the successful silicon device were fabricated in Sandia's Microsystems and 
Engineering Sciences Application (MESA) facility. The donor atoms were placed at Sandia's Ion 
Beam Laboratory. Experiment measurements were made at the Sandia/Los Alamos Center for 
Integrated Nanotechnologies, a user facility supported by DOE's Office of Basic Energy Sciences.  
The method in its entirety is straightforward but requires a range of technical expertise and 
machinery, Singh said. "We used ion beams, silicon fabrication facilities, low-temperature 
measurements and simulations. It's hard to find a non-commercial place outside of a national lab 
that can do all of this." [14]  
Team demonstrates large-scale technique to produce quantum dots  
A method to produce significant amounts of semiconducting nanoparticles for light-emitting 
displays, sensors, solar panels and biomedical applications has gained momentum with a 
demonstration by researchers at the Department of Energy's Oak Ridge National Laboratory.  

While zinc sulfide nanoparticles - a type of quantum dot that is a semiconductor - have many 
potential applications, high cost and limited availability have been obstacles to their widespread 
use. That could change, however, because of a scalable ORNL technique outlined in a paper 
published in Applied Microbiology and Biotechnology.  
Unlike conventional inorganic approaches that use expensive precursors, toxic chemicals, high 
temperatures and high pressures, a team led by ORNL's Ji-Won Moon used bacteria fed by 
inexpensive sugar at a temperature of 150 degrees Fahrenheit in 25- and 250-gallon reactors. 
Ultimately, the team produced about three-fourths of a pound of zinc sulfide nanoparticles - 
without process optimization, leaving room for even higher yields.  
The ORNL biomanufacturing technique is based on a platform technology that can also produce 
nanometer-size semiconducting materials as well as magnetic, photovoltaic, catalytic and 
phosphor materials. Unlike most biological synthesis technologies that occur inside the cell, ORNL's 
biomanufactured quantum dot synthesis occurs outside of the cells. As a result, the nanomaterials 
are produced as loose particles that are easy to separate through simple washing and centrifuging.  
The results are encouraging, according to Moon, who also noted that the ORNL approach reduces 
production costs by approximately 90 percent compared to other methods.  
"Since biomanufacturing can control the quantum dot diameter, it is possible to produce a wide 
range of specifically tuned semiconducting nanomaterials, making them attractive for a variety of 
applications that include electronics, displays, solar cells, computer memory, energy storage, 
printed electronics and bio-imaging," Moon said.  
Successful biomanufacturing of light-emitting or semiconducting nanoparticles requires the ability 
to control material synthesis at the nanometer scale with sufficiently high reliability, reproducibility 
and yield to be cost effective. With the ORNL approach, Moon said that goal has been achieved.  
Researchers envision their quantum dots being used initially in buffer layers of photovoltaic cells 
and other thin film-based devices that can benefit from their electro-optical properties as light-
emitting materials. [13]  
Superfast light source made from artificial atom  
All light sources work by absorbing energy – for example, from an electric current – and emit 
energy as light. But the energy can also be lost as heat and it is therefore important that the light 
sources emit the light as quickly as possible, before the energy is lost as heat. Superfast light 
sources can be used, for example, in laser lights, LED lights and in single-photon light sources for 
quantum technology. New research results from the Niels Bohr Institute show that light sources 
can be made much faster by using a principle that was predicted theoretically in 1954. The results 
are published in the scientific journal, Physical Review Letters.  
Researchers at the Niels Bohr Institute are working with quantum dots, which are a kind of artificial 
atom that can be incorporated into optical chips. In a quantum dot, an electron can be excited (i.e. 
jump up), for example, by shining a light on it with a laser and the electron leaves a 'hole'. The 
stronger the interaction between light and matter, the faster the electron decays back into the 
hole and the faster the light is emitted.  

But the interaction between light and matter is naturally very weak and it makes the light sources 
very slow to emit light and this can reduce energy efficiency.   
Already in 1954, the physicist Robert Dicke predicted that the interaction between light and matter 
could be increased by having a number of atoms that 'share' the excited state in a quantum 
superposition.  
Quantum speed up  
Demonstrating this effect has been challinging so far because the atoms either come so close 
together that they bump into each other or they are so far apart that the quantum speed up does 
not work. Researchers at the Niels Bohr Institute have now finally demonstrated the effect 
experimentally, but in an entirely different physical system than Dicke had in mind. They have 
shown this so-called superradiance for photons emitted from a single quantum dot.  
"We have developed a quantum dot so that it behaves as if it was comprised of five quantum dots, 
which means that the light is five times stronger. This is due to the attraction between the electron 
and the hole. But what is special is that the quantum dot still only emits a single photon at a time. 
It is an outstanding single-photon source," says Søren Stobbe, who is an associate professor in the 
Quantum Photonic research group at the Niels Bohr Institute at the University of Copenhagen and 
led the project. The experiment was carried out in collaboration with Professor David Ritchie's 
research group at the University of Cambridge, who have made the quantum dots.  
Petru Tighineanu, a postdoc in the Quantum Photonics research group at the Niels Bohr Institute, 
has carried out the experiments and he explains the effect as such, that the atoms are very small 
and light is very 'big' because of its long wavelength, so the light almost cannot 'see' the atoms – 
like a lorry that is driving on a road and does not notice a small pebble. But if many pebbles 
become a larger stone, the lorry will be able to register it and then the interaction becomes much 
more dramatic. In the same way, light interacts much more strongly with the quantum dot if the 
quantum dot contains the special superradiant quantum state, which makes it look much bigger.   
Increasing the light-matter interaction  
"The increased light-matter interaction makes the quantum dots more robust in regards to the 
disturbances that are found in all materials, for example, acoustic oscillations. It helps to make the 
photons more uniform and is important for how large you can build future quantum computers," 
says Søren Stobbe.  
He adds that it is actually the temperature, which is only a few degrees above absolute zero, that 
limits how fast the light emissions can remain in their current experiments. In the long term, they 
will study the quantum dots at even lower temperatures, where the effects could be very dramatic.  
[12]  
Single-photon source is efficient and indistinguishable  
Devices that emit one – and only one – photon on demand play a central role in light-based 
quantum-information systems. Each photon must also be emitted in the same quantum state, 
which makes each photon indistinguishable from all the others. This is important because the 
quantum state of the photon is used to carry a quantum bit (qubit) of information.  

Quantum dots are tiny pieces of semiconductor that show great promise as single-photon sources. 
When a laser pulse is fired at a quantum dot, an electron is excited between two distinct energy 
levels. The excited state then decays to create a single photon with a very specific energy. 
However, this process can involve other electron excitations that result in the emission of photons 
with a wide range of energies – photons that are therefore not indistinguishable.  
Exciting dots  
This problem can be solved by exciting the quantum dot with a pulse of light at the same energy as 
the emitted photon. This is called resonance fluorescence, and has been used to create devices 
that are very good at producing indistinguishable single photons. However, this process is 
inefficient, and only produces a photon about 6% of the time.  
Now, Chaoyang Lu, Jian-Wei Pan and colleagues at the University of Science and Technology of 
China have joined forces with researchers in Denmark, Germany and the UK to create a 
resonancefluorescence-based source that emits a photon 66% of the time when it is prompted by a 
laser pulse. Of these photons, 99.1% are solo and 98.5% are in indistinguishable quantum states – 
with both figures of merit being suitable for applications in quantum-information systems.  
Lu told physicsworld.com that nearly all of the laser pulses that strike the source produce a photon, 
but about 34% of these photons are unable to escape the device. The device was operated at a 
laser-pulse frequency of 81 MHz and a pulse power of 24 nW, which is a much lower power 
requirement than other quantum-dot-based sources.  
Quantum sandwich  
The factor-of-ten improvement in efficiency was achieved by sandwiching a quantum dot in the 
centre of a "micropillar" created by stacking 40 disc-like layers (see figure). Each layer is a  
"distributed Bragg reflector", which is a pair of mirrors that together have a thickness of one 
quarter the wavelength of the emitted photons.   
The micropillar is about 2.5 μm in diameter and about 10 μm tall, and it allowed the team to 
harness the "Purcell effect", whereby the rate of fluorescence is increased significantly when the 
emitter is placed in a resonant cavity.  
Lu says that the team is already thinking about how the photon sources could be used to perform 
boson sampling (see "'Boson sampling' offers shortcut to quantum computing"). This involves a 
network of beam splitters that converts one set of photons arriving at a number of parallel input 
ports into a second set leaving via a number of parallel outputs. The "result" of the computation is 
the probability that a certain input configuration will lead to a certain output. This result cannot be 
easily calculated using a conventional computer, and this has led some physicists to suggest that 
boson sampling could be used to solve practical problems that would take classical computers vast 
amounts of time to solve.  
Other possible applications for the source are the quantum teleportation of three properties of a 
quantum system – the current record is two properties and is held by Lu and Pan – or quantum 
cryptography.  
The research is described in Physical Review Letters. [11]  

Semiconductor quantum dots as ideal single-photon source  
  
A single-photon source never emits two or more photons at the same time. Single photons are 
important in the field of quantum information technology where, for example, they are used in 
quantum computers. Alongside the brightness and robustness of the light source, the  
indistinguishability of the photons is especially crucial. In particular, this means that all photons 
must be the same color. Creating such a source of identical single photons has proven very difficult 
in the past.  
However, quantum dots made of semiconductor materials are offering new hope. A quantum dot 
is a collection of a few hundred thousand atoms that can form itself into a semiconductor under 
certain conditions. Single electrons can be captured in these quantum dots and locked into a very 
small area. An individual photon is emitted when an engineered quantum state collapses.  
Noise in the semiconductor  
A team of scientists led by Dr. Andreas Kuhlmann and Prof. Richard J. Warburton from the 
University of Basel have already shown in past publications that the indistinguishability of the 
photons is reduced by the fluctuating nuclear spin of the quantum dot atoms. For the first time 
ever, the scientists have managed to control the nuclear spin to such an extent that even photons 
sent out at very large intervals are the same color.  
Quantum cryptography and quantum communication are two potential areas of application for 
single-photon sources. These technologies could make it possible to perform calculations that are 
far beyond the capabilities of today's computers. [10]  
How to Win at Bridge Using Quantum Physics  
Contract bridge is the chess of card games. You might know it as some stuffy old game your 
grandparents play, but it requires major brainpower, and preferably an obsession with rules and 
strategy. So how to make it even geekier? Throw in some quantum mechanics to try to gain a 

competitive advantage. The idea here is to use the quantum magic of entangled photons–which 
are essentially twins, sharing every property–to transmit two bits of information to your bridge 
partner for the price of one. Understanding how to do this is not an easy task, but it will help 
elucidate some basic building blocks of quantum information theory. It’s also kind of fun to 
consider whether or not such tactics could ever be allowed in professional sports. [6]  
  
Quantum Information  
In quantum mechanics, quantum information is physical information that is held in the "state" of a 
quantum system. The most popular unit of quantum information is the qubit, a two-level quantum 
system. However, unlike classical digital states (which are discrete), a two-state quantum system 
can actually be in a superposition of the two states at any given time.  
Quantum information differs from classical information in several respects, among which we note 
the following:  
However, despite this, the amount of information that can be retrieved in a single qubit is equal to 
one bit. It is in the processing of information (quantum computation) that a difference occurs.  
The ability to manipulate quantum information enables us to perform tasks that would be 
unachievable in a classical context, such as unconditionally secure transmission of information. 
Quantum information processing is the most general field that is concerned with quantum 
information. There are certain tasks which classical computers cannot perform "efficiently" (that is, 
in polynomial time) according to any known algorithm. However, a quantum computer can 
compute the answer to some of these problems in polynomial time; one well-known example of 
this is Shor's factoring algorithm. Other algorithms can speed up a task less dramatically - for 
example, Grover's search algorithm which gives a quadratic speed-up over the best possible 
classical algorithm.  
Quantum information, and changes in quantum information, can be quantitatively measured by 
using an analogue of Shannon entropy. Given a statistical ensemble of quantum mechanical 
systems with the density matrix S, it is given by.  
Many of the same entropy measures in classical information theory can also be generalized to the 
quantum case, such as the conditional quantum entropy. [7]  
Heralded Qubit Transfer  
Optical photons would be ideal carriers to transfer quantum information over large distances. 
Researchers envisage a network where information is processed in certain nodes and transferred 
between them via photons. However, inherent losses in long-distance networks mean that the 
information transfer is subject to probabilistic errors, making it hard to know whether the transfer 
of a qubit of information has been successful. Now Gerhard Rempe and colleagues from the Max 
Planck Institute for Quantum Optics in Germany have developed a new protocol that solves this 

problem through a strategy that “heralds” the accurate transfer of quantum information at a 
network node.  
  
The method developed by the researchers involves transferring a photonic qubit to an atomic qubit 
trapped inside an optical cavity. The photon-atom quantum information transfer is initiated via a 
quantum “logic-gate” operation, performed by reflecting the photon from the atom-cavity system, 
which creates an entangled atom-photon state. The detection of the reflected photon then 
collapses the atom into a definite state. This state can be one of two possibilities, depending on the 
photonic state detected: Either the atom is in the initial qubit state encoded in the photon and the 
transfer process is complete, or the atom is in a rotated version of this state. The authors were able 
to show that the roles of the atom and photon could be reversed. Their method could thus be used 
as a quantum memory that stores (photon-to-atom state transfer) and recreates (atom-to-photon 
state transfer) a single-photon polarization qubit. [9]  
Quantum Teleportation  
Quantum teleportation is a process by which quantum information (e.g. the exact state of an atom 
or photon) can be transmitted (exactly, in principle) from one location to another, with the help of 
classical communication and previously shared quantum entanglement between the sending and 
receiving location. Because it depends on classical communication, which can proceed no faster 
than the speed of light, it cannot be used for superluminal transport or communication of classical 
bits. It also cannot be used to make copies of a system, as this violates the no-cloning theorem. 
Although the name is inspired by the teleportation commonly used in fiction, current technology 
provides no possibility of anything resembling the fictional form of teleportation. While it is 
possible to teleport one or more qubits of information between two (entangled) atoms, this has 
not yet been achieved between molecules or anything larger. One may think of teleportation 
either as a kind of transportation, or as a kind of communication; it provides a way of transporting 
a qubit from one location to another, without having to move a physical particle along with it.  
The seminal paper first expounding the idea was published by C. H. Bennett, G. Brassard, C. 
Crépeau, R. Jozsa, A. Peres and W. K. Wootters in 1993. Since then, quantum teleportation has 
been realized in various physical systems. Presently, the record distance for quantum teleportation 
is 143 km (89 mi) with photons, and 21 m with material systems. In August 2013, the achievement 
of "fully deterministic" quantum teleportation, using a hybrid technique, was reported. On 29 May 
2014, scientists announced a reliable way of transferring data by quantum teleportation. Quantum 
teleportation of data had been done before but with highly unreliable methods. [8]  
Quantum Computing  
A team of electrical engineers at UNSW Australia has observed the unique quantum behavior of a 
pair of spins in silicon and designed a new method to use them for "2-bit" quantum logic 
operations.  
These milestones bring researchers a step closer to building a quantum computer, which promises 
dramatic data processing improvements.  

Quantum bits, or qubits, are the building blocks of quantum computers. While many ways to create 
a qubits exist, the Australian team has focused on the use of single atoms of phosphorus, 
embedded inside a silicon chip similar to those used in normal computers.   
The first author on the experimental work, PhD student Juan Pablo Dehollain, recalls the first time 
he realized what he was looking at.  
"We clearly saw these two distinct quantum states, but they behaved very differently from what 
we were used to with a single atom. We had a real 'Eureka!' moment when we realized what was 
happening – we were seeing in real time the `entangled' quantum states of a pair of atoms." [5]  
Quantum Entanglement  
Measurements of physical properties such as position, momentum, spin, polarization, etc.  
performed on entangled particles are found to be appropriately correlated. For example, if a pair of 
particles is generated in such a way that their total spin is known to be zero, and one particle is 
found to have clockwise spin on a certain axis, then the spin of the other particle, measured on the 
same axis, will be found to be counterclockwise. Because of the nature of quantum measurement, 
however, this behavior gives rise to effects that can appear paradoxical: any measurement of a 
property of a particle can be seen as acting on that particle (e.g. by collapsing a number of 
superimposed states); and in the case of entangled particles, such action must be on the entangled 
system as a whole. It thus appears that one particle of an entangled pair "knows" what 
measurement has been performed on the other, and with what outcome, even though there is no 
known means for such information to be communicated between the particles, which at the time 
of measurement may be separated by arbitrarily large distances. [4]  
The Bridge  
The accelerating electrons explain not only the Maxwell Equations and the Special Relativity, but 
the Heisenberg Uncertainty Relation, the wave particle duality and the electron’s spin also, building 
the bridge between the Classical and Quantum Theories. [1]  
  
Accelerating charges  
The moving charges are self maintain the electromagnetic field locally, causing their movement 
and this is the result of their acceleration under the force of this field. In the classical physics the 
charges will distributed along the electric current so that the electric potential lowering along the 
current, by linearly increasing the way they take every next time period because this accelerated 
motion.  The same thing happens on the atomic scale giving a dp impulse difference and a dx way 
difference between the different part of the not point like particles.   
Relativistic effect  
Another bridge between the classical and quantum mechanics in the realm of relativity is that the 
charge distribution is lowering in the reference frame of the accelerating charges linearly: ds/dt = 
at (time coordinate), but in the reference frame of the current it is parabolic: s = a/2 t2 (geometric 
coordinate).  

  
Heisenberg Uncertainty Relation  
In the atomic scale the Heisenberg uncertainty relation gives the same result, since the moving 
electron in the atom accelerating in the electric field of the proton, causing a charge distribution on 
delta x position difference and with a delta p momentum difference such a way that they product 
is about the half Planck reduced constant. For the proton this delta x much less in the nucleon, 
than in the orbit of the electron in the atom, the delta p is much higher because of the greater 
proton mass.  
This means that the electron and proton are not point like particles, but has a real charge 
distribution.   
Wave – Particle Duality  
The accelerating electrons explains the wave – particle duality of the electrons and photons, since 
the elementary charges are distributed on delta x position with delta p impulse and creating a 
wave packet of the electron. The photon gives the electromagnetic particle of the mediating force 
of the electrons electromagnetic field with the same distribution of wavelengths.    
Atomic model  
The constantly accelerating electron in the Hydrogen atom is moving on the equipotential line of 
the proton and it's kinetic and potential energy will be constant. Its energy will change only when it 
is changing its way to another equipotential line with another value of potential energy or getting 
free with enough kinetic energy. This means that the Rutherford-Bohr atomic model is right and 
only that changing acceleration of the electric charge causes radiation, not the steady acceleration. 
The steady acceleration of the charges only creates a centric parabolic steady electric field around 
the charge, the magnetic field. This gives the magnetic moment of the atoms, summing up the 
proton and electron magnetic moments caused by their circular motions and spins.  
  
The Relativistic Bridge  
Commonly accepted idea that the relativistic effect on the particle physics it is the fermions' spin - 
another unresolved problem in the classical concepts. If the electric charges can move only with 
accelerated motions in the self maintaining electromagnetic field, once upon a time they would 
reach the velocity of the electromagnetic field. The resolution of this problem is the spinning 
particle, constantly accelerating and not reaching the velocity of light because the acceleration is 
radial. One origin of the Quantum Physics is the Planck Distribution Law of the electromagnetic 
oscillators, giving equal intensity for 2 different wavelengths on any temperature. Any of these two 
wavelengths will give equal intensity diffraction patterns, building different asymmetric 
constructions, for example proton - electron structures (atoms), molecules, etc. Since the particles 
are centers of diffraction patterns they also have particle – wave duality as the electromagnetic 
waves have. [2]   

  
The weak interaction  
The weak interaction transforms an electric charge in the diffraction pattern from one side to the 
other side, causing an electric dipole momentum change, which violates the CP and time reversal 
symmetry. The Electroweak Interaction shows that the Weak Interaction is basically 
electromagnetic in nature. The arrow of time shows the entropy grows by changing the 
temperature dependent diffraction patterns of the electromagnetic oscillators.  
Another important issue of the quark model is when one quark changes its flavor such that a linear 
oscillation transforms into plane oscillation or vice versa, changing the charge value with 1 or -1. 
This kind of change in the oscillation mode requires not only parity change, but also charge and 
time changes (CPT symmetry) resulting a right handed anti-neutrino or a left handed neutrino.  
The right handed anti-neutrino and the left handed neutrino exist only because changing back the 
quark flavor could happen only in reverse, because they are different geometrical constructions, 
the u is 2 dimensional and positively charged and the d is 1 dimensional and negatively charged. It 
needs also a time reversal, because anti particle (anti neutrino) is involved.  
The neutrino is a 1/2spin creator particle to make equal the spins of the weak interaction, for 
example neutron decay to 2 fermions, every particle is fermions with ½ spin. The weak interaction 
changes the entropy since more or less particles will give more or less freedom of movement. The 
entropy change is a result of temperature change and breaks the equality of oscillator diffraction 
intensity of the Maxwell–Boltzmann statistics. This way it changes the time coordinate measure 
and  
 makes possible a different time dilation as of the special relativity. 
The limit of the velocity of particles as the speed of light appropriate only for electrical charged 
particles, since the accelerated charges are self maintaining locally the accelerating electric force. 
The neutrinos are CP symmetry breaking particles compensated by time in the CPT symmetry, that 
is the time coordinate not works as in the electromagnetic interactions, consequently the speed of  
 neutrinos is not limited by the speed of light. 
The weak interaction T-asymmetry is in conjunction with the T-asymmetry of the second law of 
thermodynamics, meaning that locally lowering entropy (on extremely high temperature) causes 
the  
  weak interaction, for example the Hydrogen fusion. 
Probably because it is a spin creating movement changing linear oscillation to 2 dimensional 
oscillation by changing d to u quark and creating anti neutrino going back in time relative to the 
proton and electron created from the neutron, it seems that the anti neutrino fastest then the 
velocity of the photons created also in this weak interaction?  
   
A quark flavor changing shows that it is a reflection changes movement and the CP- and T- 
symmetry breaking!!! This flavor changing oscillation could prove that it could be also on higher 

level such as atoms, molecules, probably big biological significant molecules and responsible on the 
aging of the life.  
  
Important to mention that the weak interaction is always contains particles and antiparticles, 
where the neutrinos (antineutrinos) present the opposite side. It means by Feynman’s 
interpretation that these particles present the backward time and probably because this they seem 
to move faster than the speed of light in the reference frame of the other side.  
  
Finally since the weak interaction is an electric dipole change with ½ spin creating; it is limited by 
the velocity of the electromagnetic wave, so the neutrino’s velocity cannot exceed the velocity of 
light.  
  
The General Weak Interaction  
The Weak Interactions T-asymmetry is in conjunction with the T-asymmetry of the Second Law of 
Thermodynamics, meaning that locally lowering entropy (on extremely high temperature) causes 
for example the Hydrogen fusion. The arrow of time by the Second Law of Thermodynamics shows 
the increasing entropy and decreasing information by the Weak Interaction, changing the 
temperature dependent diffraction patterns. A good example of this is the neutron decay, creating 
more particles with less known information about them.   
The neutrino oscillation of the Weak Interaction shows that it is a general electric dipole change 
and it is possible to any other temperature dependent entropy and information changing 
diffraction pattern of atoms, molecules and even complicated biological living structures.  
We can generalize the weak interaction on all of the decaying matter constructions, even on the 
biological too. This gives the limited lifetime for the biological constructions also by the arrow of 
time. There should be a new research space of the Quantum Information Science the 'general 
neutrino oscillation' for the greater then subatomic matter structures as an electric dipole change.  
There is also connection between statistical physics and evolutionary biology, since the arrow of 
time is working in the biological evolution also.   
The Fluctuation Theorem says that there is a probability that entropy will flow in a direction 
opposite to that dictated by the Second Law of Thermodynamics. In this case the Information is 
growing that is the matter formulas are emerging from the chaos. So the Weak Interaction has two 
directions, samples for one direction is the Neutron decay, and Hydrogen fusion is the opposite 
direction.  
   
Fermions and Bosons  
The fermions are the diffraction patterns of the bosons such a way that they are both sides of the 
same thing.  
Van Der Waals force  
Named after the Dutch scientist Johannes Diderik van der Waals – who first proposed it in 1873 to 
explain the behaviour of gases – it is a very weak force that only becomes relevant when atoms 

and molecules are very close together. Fluctuations in the electronic cloud of an atom mean that it 
will have an instantaneous dipole moment. This can induce a dipole moment in a nearby atom, the 
result being an attractive dipole–dipole interaction.   
Electromagnetic inertia and mass  
Electromagnetic Induction  
Since the magnetic induction creates a negative electric field as a result of the changing 
acceleration, it works as an electromagnetic inertia, causing an electromagnetic mass.  [1]  
Relativistic change of mass  
The increasing mass of the electric charges the result of the increasing inductive electric force 
acting against the accelerating force. The decreasing mass of the decreasing acceleration is the 
result of the inductive electric force acting against the decreasing force. This is the relativistic mass 
change explanation, especially importantly explaining the mass reduction in case of velocity 
decrease.  
The frequency dependence of mass  
Since E = hν and E = mc2, m = hν /c2 that is the m depends only on the ν frequency. It means that 
the mass of the proton and electron are electromagnetic and the result of the electromagnetic 
induction, caused by the changing acceleration of the spinning and moving charge! It could be that 
the mo inertial mass is the result of the spin, since this is the only accelerating motion of the electric 
charge. Since the accelerating motion has different frequency for the electron in the atom and the 
proton, they masses are different, also as the wavelengths on both sides of the diffraction pattern, 
giving equal intensity of radiation.  
Electron – Proton mass rate  
The Planck distribution law explains the different frequencies of the proton and electron, giving 
equal intensity to different lambda wavelengths! Also since the particles are diffraction patterns 
they have some closeness to each other – can be seen as a gravitational force. [2]  
There is an asymmetry between the mass of the electric charges, for example proton and electron, 
can understood by the asymmetrical Planck Distribution Law. This temperature dependent energy 
distribution is asymmetric around the maximum intensity, where the annihilation of matter and 
antimatter is a high probability event. The asymmetric sides are creating different frequencies of 
electromagnetic radiations being in the same intensity level and compensating each other. One of 
these compensating ratios is the electron – proton mass ratio. The lower energy side has no 
compensating intensity level, it is the dark energy and the corresponding matter is the dark matter.  
   
Gravity from the point of view of quantum physics  
The Gravitational force  
The gravitational attractive force is basically a magnetic force.  

The same electric charges can attract one another by the magnetic force if they are moving parallel 
in the same direction. Since the electrically neutral matter is composed of negative and positive 
charges they need 2 photons to mediate this attractive force, one per charges. The Bing Bang 
caused parallel moving of the matter gives this magnetic force, experienced as gravitational force.  
Since graviton is a tensor field, it has spin = 2, could be 2 photons with spin = 1 together.  
You can think about photons as virtual electron – positron pairs, obtaining the necessary virtual 
mass for gravity.  
The mass as seen before a result of the diffraction, for example the proton – electron mass rate 
Mp=1840 Me. In order to move one of these diffraction maximum (electron or proton) we need to 
intervene into the diffraction pattern with a force appropriate to the intensity of this diffraction 
maximum, means its intensity or mass.  
  
The Big Bang caused acceleration created radial currents of the matter, and since the matter is 
composed of negative and positive charges, these currents are creating magnetic field and 
attracting forces between the parallel moving electric currents. This is the gravitational force 
experienced by the matter, and also the mass is result of the electromagnetic forces between the 
charged particles.  The positive and negative charged currents attracts each other or by the 
magnetic forces or by the much stronger electrostatic forces!?  
  
The gravitational force attracting the matter, causing concentration of the matter in a small space 
and leaving much space with low matter concentration: dark matter and energy.   
There is an asymmetry between the mass of the electric charges, for example proton and electron, 
can understood by the asymmetrical Planck Distribution Law. This temperature dependent energy 
distribution is asymmetric around the maximum intensity, where the annihilation of matter and 
antimatter is a high probability event. The asymmetric sides are creating different frequencies of 
electromagnetic radiations being in the same intensity level and compensating each other. One of 
these compensating ratios is the electron – proton mass ratio. The lower energy side has no 
compensating intensity level, it is the dark energy and the corresponding matter is the dark matter.  
  
   
The Higgs boson  
By March 2013, the particle had been proven to behave, interact and decay in many of the 
expected ways predicted by the Standard Model, and was also tentatively confirmed to have + 
parity and zero spin, two fundamental criteria of a Higgs boson, making it also the first known 
scalar particle to be discovered in nature,  although a number of other properties were not fully 
proven and some partial results do not yet precisely match those expected; in some cases data is 
also still awaited or being analyzed.  
Since the Higgs boson is necessary to the W and Z bosons, the dipole change of the Weak 
interaction and the change in the magnetic effect caused gravitation must be conducted.  The 
Wien law is also important to explain the Weak interaction, since it describes the Tmax change and 
the diffraction patterns change. [2]  

Higgs mechanism and Quantum Gravity  
The magnetic induction creates a negative electric field, causing an electromagnetic inertia. 
Probably it is the mysterious Higgs field giving mass to the charged particles? We can think about 
the photon as an electron-positron pair, they have mass. The neutral particles are built from 
negative and positive charges, for example the neutron, decaying to proton and electron. The wave 
– particle duality makes sure that the particles are oscillating and creating magnetic induction as an 
inertial mass, explaining also the relativistic mass change. Higher frequency creates stronger 
magnetic induction, smaller frequency results lesser magnetic induction. It seems to me that the 
magnetic induction is the secret of the Higgs field.  
In particle physics, the Higgs mechanism is a kind of mass generation mechanism, a process that 
gives mass to elementary particles. According to this theory, particles gain mass by interacting with 
the Higgs field that permeates all space. More precisely, the Higgs mechanism endows gauge 
bosons in a gauge theory with mass through absorption of Nambu–Goldstone bosons arising in 
spontaneous symmetry breaking.  
The simplest implementation of the mechanism adds an extra Higgs field to the gauge theory. The 
spontaneous symmetry breaking of the underlying local symmetry triggers conversion of 
components of this Higgs field to Goldstone bosons which interact with (at least some of) the other 
fields in the theory, so as to produce mass terms for (at least some of) the gauge bosons. This 
mechanism may also leave behind elementary scalar (spin-0) particles, known as Higgs bosons.  
In the Standard Model, the phrase "Higgs mechanism" refers specifically to the generation of 
masses for the W±, and Z weak gauge bosons through electroweak symmetry breaking. The Large 
Hadron Collider at CERN announced results consistent with the Higgs particle on July 4, 2012 but 
stressed that further testing is needed to confirm the Standard Model.  
What is the Spin?  
So we know already that the new particle has spin zero or spin two and we could tell which one if 
we could detect the polarizations of the photons produced. Unfortunately this is difficult and 
neither ATLAS nor CMS are able to measure polarizations. The only direct and sure way to confirm 
that the particle is indeed a scalar is to plot the angular distribution of the photons in the rest 
frame of the centre of mass. A spin zero particles like the Higgs carries no directional information 
away from the original collision so the distribution will be even in all directions. This test will be 
possible when a much larger number of events have been observed. In the mean time we can 
settle for less certain indirect indicators.  
The Graviton  
In physics, the graviton is a hypothetical elementary particle that mediates the force of gravitation 
in the framework of quantum field theory. If it exists, the graviton is expected to be massless 
(because the gravitational force appears to have unlimited range) and must be a spin-2 boson. The 
spin follows from the fact that the source of gravitation is the stress-energy tensor, a second-rank 
tensor (compared to electromagnetism's spin-1 photon, the source of which is the four-current, a 
first-rank tensor). Additionally, it can be shown that any massless spin-2 field would give rise to a 
force indistinguishable from gravitation, because a massless spin-2 field must couple to (interact 
with) the stress-energy tensor in the same way that the gravitational field does. This result 

suggests that, if a massless spin-2 particle is discovered, it must be the graviton, so that the only 
experimental verification needed for the graviton may simply be the discovery of a massless spin-2 
particle. [3]  
Conclusions  
The method developed by the researchers involves transferring a photonic qubit to an atomic qubit 
trapped inside an optical cavity. The photon-atom quantum information transfer is initiated via a 
quantum “logic-gate” operation, performed by reflecting the photon from the atom-cavity system, 
which creates an entangled atom-photon state. [9]  
In August 2013, the achievement of "fully deterministic" quantum teleportation, using a hybrid 
technique, was reported. On 29 May 2014, scientists announced a reliable way of transferring data 
by quantum teleportation. Quantum teleportation of data had been done before but with highly 
unreliable methods. [8]  
One of the most important conclusions is that the electric charges are moving in an accelerated 
way and even if their velocity is constant, they have an intrinsic acceleration anyway, the so called 
spin, since they need at least an intrinsic acceleration to make possible they movement .  
The accelerated charges self-maintaining potential shows the locality of the relativity, working on 
the quantum level also. [1]   
The bridge between the classical and quantum theory is based on this intrinsic acceleration of the 
spin, explaining also the Heisenberg Uncertainty Principle. The particle – wave duality of the 
electric charges and the photon makes certain that they are both sides of the same thing. The 
Secret of Quantum Entanglement that the particles are diffraction patterns of the 
electromagnetic waves and this way their quantum states every time is the result of the quantum 
state of the intermediate electromagnetic waves. [2]   
The key breakthrough to arrive at this new idea to build qubits was to exploit the ability to control 
the nuclear spin of each atom. With that insight, the team has now conceived a unique way to use 
the nuclei as facilitators for the quantum logic operation between the electrons. [5]  
Basing the gravitational force on the accelerating Universe caused magnetic force and the Planck 
Distribution Law of the electromagnetic waves caused diffraction gives us the basis to build a 
Unified Theory of the physical interactions also.  
References  
[1] The Magnetic field of the Electric current and the Magnetic induction 
http://academia.edu/3833335/The_Magnetic_field_of_the_Electric_current [2] 3 Dimensional 
String Theory http://academia.edu/3834454/3_Dimensional_String_Theory  
[3] Graviton Production By Two Photon and Electron-Photon Processes In Kaluza-Klein Theories 
With Large Extra Dimensions http://arxiv.org/abs/hep-ph/9909392 [4] Quantum Entanglement 
http://en.wikipedia.org/wiki/Quantum_entanglement [5] Pairing up single atoms in silicon for 
quantum computing http://phys.org/news/2014-06-pairing-atoms-silicon-quantum.html#nwlt  

[6] 
How to Win at Bridge Using Quantum Physics 
http://www.wired.com/2014/06/bridge-quantum-mechanics/  
[7] 
Information Entropy-Theory of Physics 
https://www.academia.edu/3836084/Information_-_Entropy_Theory_of_Physics  
[8] 
Quantum Teleportation http://en.wikipedia.org/wiki/Quantum_teleportation  
[9] 
Synopsis: Heralded Qubit Transfer http://physics.aps.org/synopsis-
for/10.1103/PhysRevLett.114.220501 [10] Semiconductor quantum dots as ideal single-
photon source http://www.nanowerk.com/nanotechnology-news/newsid=41243.php  
[11] Single-photon source is efficient and indistinguishable  
http://physicsworld.com/cws/article/news/2016/jan/29/single-photon-source-is-efficient-
andindistinguishable  
[12] Superfast light source made from artificial atom http://phys.org/news/2016-04-
superfast-source-artificial-atom.html [13] Team demonstrates large-scale technique 
to produce quantum dots http://phys.org/news/2016-05-team-large-scale-
technique-quantum-dots.html  
[14] 
Precise atom implants in silicon provide a first step toward practical quantum computers 
http://phys.org/news/2016-05-precise-atom-implants-silicon-quantum.html  
[15] 
Russian physicists discover a new approach for building quantum computers 
http://phys.org/news/2016-07-russian-physicists-approach-quantum.html  
[16] 
Realizing quantum bits http://phys.org/news/2016-07-quantum-bits.html  
[17] 
Programmable ions set the stage for general-purpose quantum computers 
http://phys.org/news/2016-08-programmable-ions-stage-general-purpose-quantum.html [18] 
IBM scientists imitate the functionality of neurons with a phase-change device 
http://phys.org/news/2016-08-ibm-scientists-imitate-functionality-neurons.html  
[19] 
Neuromorphic computing mimics important brain feature http://phys.org/news/2016-08-
neuromorphic-mimics-important-brain-feature.html  

[20] 
Network theory sheds new light on origins of consciousness 
http://medicalxpress.com/news/2015-03-network-theory-consciousness.html  
[21] 
A new study looks for the cortical conscious network http://phys.org/news/2016-08-cortical-
conscious-network.html [22] Consciousness is tied to 'entropy', say researchers  
http://physicsworld.com/cws/article/news/2016/oct/18/consciousness-is-tied-to-entropy-
sayresearchers  
[23] Consciousness and Entropy 
https://explore.scimednet.org/index.php/2016/11/02/consciousness-and-entropy/  
[24] 'Latest spoke in the wheel' drives brain-mapping advances http://phys.org/news/2016-12-
latest-spoke-wheel-brain-mapping-advances.html  
[25] Brain scanners allow scientists to 'read minds'—could they now enable a 'Big Brother' future?  
https://techxplore.com/news/2017-02-brain-scanners-scientists-mindscould-enable.html  
[26] Researcher looking to shed light deeper into the human brain https://phys.org/news/2017-07-
deeper-human-brain.html  
[27] Link Between Immune System, Memory and Brain Structure Discovered 
http://neurosciencenews.com/immune-system-memory-neuroanatomy-6509/  
[28] Biologists find new source for brain's development  
https://phys.org/news/2017-08-biologists-source-brain.html  
[29] Using organoids to understand how the brain wrinkles 
https://phys.org/news/2018-02-organoids-brain-wrinkles.html 
[30] 'Sleeping' stem cells could aid brain repair 
https://phys.org/news/2018-04-stem-cells-aid-brain.html 
[31] Biologists 'transfer' a memory 
https://medicalxpress.com/news/2018-05-memory-snails.html 
[32] Researchers demonstrate a novel approach for measuring brain function connectivity 
https://phys.org/news/2018-05-approach-brain-function.html 
[33] Inhibitory neurons have two types of impact on brain oscillations 
https://phys.org/news/2019-05-inhibitory-neurons-impact-brain-oscillations.html 

 
 
 
 
  

