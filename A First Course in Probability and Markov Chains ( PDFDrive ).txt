

A First Course in Probability
and Markov Chains


A First Course in Probability
and Markov Chains
Giuseppe Modica
and
Laura Poggiolini
University of Firenze, Italy
A John Wiley & Sons, Ltd., Publication

This edition ï¬rst published 2013
Â© 2013 John Wiley & Sons, Ltd
Registered ofï¬ce
John Wiley & Sons Ltd, The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ, United Kingdom
For details of our global editorial ofï¬ces, for customer services and for information about how to apply for
permission to reuse the copyright material in this book please see our website at www.wiley.com.
The right of the author to be identiï¬ed as the author of this work has been asserted in accordance with the
Copyright, Designs and Patents Act 1988.
All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or transmitted,
in any form or by any means, electronic, mechanical, photocopying, recording or otherwise, except as
permitted by the UK Copyright, Designs and Patents Act 1988, without the prior permission of the publisher.
Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may not
be available in electronic books.
Designations used by companies to distinguish their products are often claimed as trademarks. All brand
names and product names used in this book are trade names, service marks, trademarks or registered
trademarks of their respective owners. The publisher is not associated with any product or vendor mentioned
in this book. This publication is designed to provide accurate and authoritative information in regard to the
subject matter covered. It is sold on the understanding that the publisher is not engaged in rendering
professional services. If professional advice or other expert assistance is required, the services of a competent
professional should be sought.
Library of Congress Cataloging-in-Publication Data
Modica, Giuseppe.
A ï¬rst course in probability and Markov chains / Giuseppe Modica and Laura Poggiolini.
pages cm
Summary: â€œA ï¬rst course in Probability and Markov Chains presents an introduction to the basic
elements in statistics and focuses in two main areasâ€ â€“ Provided by publisher.
Includes bibliographical references and index.
ISBN 978-1-119-94487-4 (hardback)
1. Markov processes. I. Poggiolini, Laura. II. Title.
QA274.7.M63 2013
519.2â€²33 â€“ dc23
2012033463
A catalogue record for this book is available from the British Library.
ISBN: 978-1-119-94487-4
Set in 9.5/12pt Times by Laserwords Private Limited, Chennai, India.

Contents
Preface
xi
1
Combinatorics
1
1.1
Binomial coefï¬cients
1
1.1.1
Pascal triangle
1
1.1.2
Some properties of binomial coefï¬cients
2
1.1.3
Generalized binomial coefï¬cients and binomial series
3
1.1.4
Inversion formulas
4
1.1.5
Exercises
6
1.2
Sets, permutations and functions
8
1.2.1
Sets
8
1.2.2
Permutations
8
1.2.3
Multisets
10
1.2.4
Lists and functions
11
1.2.5
Injective functions
12
1.2.6
Monotone increasing functions
12
1.2.7
Monotone nondecreasing functions
13
1.2.8
Surjective functions
14
1.2.9
Exercises
16
1.3
Drawings
16
1.3.1
Ordered drawings
16
1.3.2
Simple drawings
17
1.3.3
Multiplicative property of drawings
17
1.3.4
Exercises
18
1.4
Grouping
19
1.4.1
Collocations of pairwise different objects
19
1.4.2
Collocations of identical objects
22
1.4.3
Multiplicative property
23
1.4.4
Collocations in statistical physics
24
1.4.5
Exercises
24
2
Probability measures
27
2.1
Elementary probability
28
2.1.1
Exercises
29

vi
CONTENTS
2.2
Basic facts
33
2.2.1
Events
34
2.2.2
Probability measures
36
2.2.3
Continuity of measures
37
2.2.4
Integral with respect to a measure
39
2.2.5
Probabilities on ï¬nite and denumerable sets
40
2.2.6
Probabilities on denumerable sets
42
2.2.7
Probabilities on uncountable sets
44
2.2.8
Exercises
46
2.3
Conditional probability
51
2.3.1
Deï¬nition
51
2.3.2
Bayes formula
52
2.3.3
Exercises
54
2.4
Inclusionâ€“exclusion principle
60
2.4.1
Exercises
63
3
Random variables
68
3.1
Random variables
68
3.1.1
Deï¬nitions
69
3.1.2
Expected value
75
3.1.3
Functions of random variables
77
3.1.4
Cavalieri formula
80
3.1.5
Variance
82
3.1.6
Markov and Chebyshev inequalities
82
3.1.7
Variational characterization of the median and of the
expected value
83
3.1.8
Exercises
84
3.2
A few discrete distributions
91
3.2.1
Bernoulli distribution
91
3.2.2
Binomial distribution
91
3.2.3
Hypergeometric distribution
93
3.2.4
Negative binomial distribution
94
3.2.5
Poisson distribution
95
3.2.6
Geometric distribution
98
3.2.7
Exercises
101
3.3
Some absolutely continuous distributions
102
3.3.1
Uniform distribution
102
3.3.2
Normal distribution
104
3.3.3
Exponential distribution
106
3.3.4
Gamma distributions
108
3.3.5
Failure rate
110
3.3.6
Exercises
111
4
Vector valued random variables
113
4.1
Joint distribution
113

CONTENTS
vii
4.1.1
Joint and marginal distributions
114
4.1.2
Exercises
117
4.2
Covariance
120
4.2.1
Random variables with ï¬nite expected value and
variance
120
4.2.2
Correlation coefï¬cient
123
4.2.3
Exercises
123
4.3
Independent random variables
124
4.3.1
Independent events
124
4.3.2
Independent random variables
127
4.3.3
Independence of many random variables
128
4.3.4
Sum of independent random variables
130
4.3.5
Exercises
131
4.4
Sequences of independent random variables
140
4.4.1
Weak law of large numbers
140
4.4.2
Borelâ€“Cantelli lemma
142
4.4.3
Convergences of random variables
143
4.4.4
Strong law of large numbers
146
4.4.5
A few applications of the law of large numbers
152
4.4.6
Central limit theorem
159
4.4.7
Exercises
163
5
Discrete time Markov chains
168
5.1
Stochastic matrices
168
5.1.1
Deï¬nitions
169
5.1.2
Oriented graphs
170
5.1.3
Exercises
172
5.2
Markov chains
173
5.2.1
Stochastic processes
173
5.2.2
Transition matrices
174
5.2.3
Homogeneous processes
174
5.2.4
Markov chains
174
5.2.5
Canonical Markov chains
178
5.2.6
Exercises
181
5.3
Some characteristic parameters
187
5.3.1
Steps for a ï¬rst visit
187
5.3.2
Probability of (at least) r visits
189
5.3.3
Recurrent and transient states
191
5.3.4
Mean ï¬rst passage time
193
5.3.5
Hitting time and hitting probabilities
195
5.3.6
Exercises
198
5.4
Finite stochastic matrices
201
5.4.1
Canonical representation
201
5.4.2
States classiï¬cation
203
5.4.3
Exercises
205

viii
CONTENTS
5.5
Regular stochastic matrices
206
5.5.1
Iterated maps
206
5.5.2
Existence of ï¬xed points
209
5.5.3
Regular stochastic matrices
210
5.5.4
Characteristic parameters
218
5.5.5
Exercises
220
5.6
Ergodic property
222
5.6.1
Number of steps between consecutive visits
222
5.6.2
Ergodic theorem
224
5.6.3
Powers of irreducible stochastic matrices
226
5.6.4
Markov chain Monte Carlo
228
5.7
Renewal theorem
233
5.7.1
Periodicity
233
5.7.2
Renewal theorem
234
5.7.3
Exercises
239
6
An introduction to continuous time Markov chains
241
6.1
Poisson process
241
6.2
Continuous time Markov chains
246
6.2.1
Deï¬nitions
246
6.2.2
Continuous semigroups of stochastic matrices
248
6.2.3
Examples of right-continuous Markov chains
256
6.2.4
Holding times
259
Appendix A Power series
261
A.1
Basic properties
261
A.2
Product of series
263
A.3
Banach space valued power series
264
A.3.2
Exercises
267
Appendix B Measure and integration
270
B.1
Measures
270
B.1.1
Basic properties
270
B.1.2
Construction of measures
272
B.1.3
Exercises
279
B.2
Measurable functions and integration
279
B.2.1
Measurable functions
280
B.2.2
The integral
283
B.2.3
Properties of the integral
284
B.2.4
Cavalieri formula
286
B.2.5
Markov inequality
287
B.2.6
Null sets and the integral
287
B.2.7
Push forward of a measure
289
B.2.8
Exercises
290

CONTENTS
ix
B.3
Product measures and iterated integrals
294
B.3.1
Product measures
294
B.3.2
Reduction formulas
296
B.3.3
Exercises
297
B.4
Convergence theorems
298
B.4.1
Almost everywhere convergence
298
B.4.2
Strong convergence
300
B.4.3
Fatou lemma
301
B.4.4
Dominated convergence theorem
302
B.4.5
Absolute continuity of integrals
305
B.4.6
Differentiation of the integral
305
B.4.7
Weak convergence of measures
308
B.4.8
Exercises
312
Appendix C Systems of linear ordinary differential equations
313
C.1
Cauchy problem
313
C.1.1
Uniqueness
313
C.1.2
Existence
315
C.2
Efï¬cient computation of eQt
317
C.2.1
Similarity methods
317
C.2.2
Putzer method
319
C.3
Continuous semigroups
321
References
324
Index
327


Preface
This book collects topics covered in introductory courses in probability delivered
by the authors at the University of Florence. It aims to introduce the reader to
typical structures of probability with a language appropriate for further advanced
reading. The attention is mainly focused on basic structures.
There is a well established tradition of studies in probability due to the wide
range of possible applications of related concepts and structures in science and
technology. Therefore, an enormous amount of literature on the subject is avail-
able, including treatises, lecture notes, reports, journal papers and web pages. The
list of references at the end of this book is obviously incomplete and includes
only references used directly in writing the following pages. Throughout this
book we adopt the language of measure theory (relevant notions are recalled in
the appendices).
The ï¬rst part of the book deals with basic notions of combinatorics and proba-
bility calculus: counting problems and uniform probability, probability measures,
probability distributions, conditional probability, inclusionâ€“exclusion principle,
random variables, dispersion indexes, independence, and the law of large num-
bers are also discussed. Central limit theorem is presented without proof. Only
a basic knowledge of linear algebra and mathematical analysis is required.
In the second part we discuss, as a ï¬rst example of stochastic processes,
Markov chains with discrete time and discrete states, including the Markov chain
Monte Carlo method, and we introduce Poisson process and continuous time
Markov chains with ï¬nite states. For this part, further notions in mathematical
analysis (summarized in the appendices) are required: the Banach ï¬xed point
theorem, systems of linear ordinary differential equations, powers and power
series of matrices.
We wish to thank all the students who have attended our courses. We also
wish to thank our colleagues Matteo Focardi, Mariano Giaquinta, Paolo Maria
Mariano, Andrea Mennucci, Marco Romito and Enrico Vicario who helped us
with suggestions and comments. Special gratitude goes to Enrico Vicario for
many helpful discussions on the applications.
Our special thanks also go to the editorial staff of Wiley for the excellent
quality of their work.

xii
PREFACE
We have tried to avoid misprints and errors. However, we would be very
grateful to be notiï¬ed of any errors or misprints and would be glad to receive
any criticism or comments. Our e-mail addresses are:
giuseppe.modica@uniï¬.it
laura.poggiolini@uniï¬.it
We will try to keep up an errata corrige at the following web pages:
http://www.dma.unifi.it/âˆ¼modica
http://www.dma.unifi.it/âˆ¼poggiolini
http://www.dmi.unifi.it/âˆ¼modica
http://www.dmi.unifi.it/âˆ¼poggiolini

1
Combinatorics
Combinatorics deals with the cardinality of classes of objects. The ï¬rst example
that jumps to our minds is the computation of how many triplets can be drawn
from 90 different balls. In this chapter and the next we are going to compute the
cardinality of several classes of objects.
1.1
Binomial coefï¬cients
1.1.1
Pascal triangle
Binomial coeffcients are deï¬ned as
n
k

:=
â§
âªâªâ¨
âªâªâ©
1
if k = 0,
0
k > n,
n(n âˆ’1) . . . (n âˆ’k + 1)
k!
if n â‰¥1 and 1 â‰¤k â‰¤n.
Binomial coefï¬cients are usually grouped in an inï¬nite matrix
C := (Cn
k), n, k â‰¥0,
Cn
k :=
n
k

called a Pascal triangle given the triangular arrangement of the nonzero entries,
see Figure 1.1. Here and throughout the book we denote the entries of a matrix
(ï¬nite or inï¬nite) A = (ai
j) where the superscript i and the subscript j mean the
ith row and the jth column, respectively. Notice that the entries of each row of
C are zero if the column index is large enough, Ci
j = 0 âˆ€i, j with j > i â‰¥0. We
also recall the Newton binomial formula,
(1 + z)n =
n
0

+
n
1

z + Â· Â· Â· +
n
n

zn =
n

k=0
n
k

zk =
âˆ

k=0
n
k

zk.
A First Course in Probability and Markov Chains, First Edition. Giuseppe Modica and Laura Poggiolini.
Â© 2013 John Wiley & Sons, Ltd. Published 2013 by John Wiley & Sons, Ltd.

2
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
â›
âœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâ
1
0
0
0
0
0
0
0
0
0
. . .
1
1
0
0
0
0
0
0
0
0
. . .
1
2
1
0
0
0
0
0
0
0
. . .
1
3
3
1
0
0
0
0
0
0
. . .
1
4
6
4
1
0
0
0
0
0
. . .
1
5
10
10
5
1
0
0
0
0
. . .
1
6
15
20
15
6
1
0
0
0
. . .
1
7
21
35
35
21
7
1
0
0
. . .
1
8
28
56
70
56
28
8
1
0
. . .
1
9
36
84
126
126
84
36
9
1
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
Figure 1.1
Pascal matrix of binomial coefï¬cients (Cn
k), k, n â‰¥0.
Thus formula can be proven with an induction argument on n or by means of
Taylor formula.
1.1.2
Some properties of binomial coefï¬cients
Many formulas are known on binomial coefï¬cients. In the following proposition
we collect some of the simplest and most useful ones.
Proposition 1.1 The following hold.
(i)
n
k

=
n!
k!(n âˆ’k)! âˆ€k, n, 0 â‰¤k â‰¤n.
(ii)
n
k

= n
k
n âˆ’1
k âˆ’1

âˆ€k, n, 1 â‰¤k â‰¤n.
(iii) Stifel formula
n
k

=
n âˆ’1
k

+
n âˆ’1
k âˆ’1

âˆ€k, n, 1 â‰¤k â‰¤n.
(iv)
n
j
j
k

=
n
k
n âˆ’k
j âˆ’k

âˆ€k, j, n, 0 â‰¤k â‰¤j â‰¤n.
(v)
n
k

=

n
n âˆ’k

âˆ€k, 0 â‰¤k â‰¤n.
(vi) the map k â†’
n
k

achieves its maximum at k =
 n
2

.
(vii)
n

k=0
n
k

= 2n âˆ€n â‰¥0.
(viii)
n

k=0
(âˆ’1)k
n
k

= Î´0,n =

1
if n = 0,
0
if n Ì¸= 0.
(ix)
n
k

â‰¤2n âˆ€k, n, 0 â‰¤k â‰¤n.

COMBINATORICS
3
Proof. Formulas (i), (ii), (iii), (iv) and (v) directly follow from the deï¬nition.
(vi) is a direct consequence of (v). (vii) and (viii) follow from the Newton
binomial formula n
k=0
n
k

zk = (1 + z)n choosing z = 1 and z = âˆ’1. Finally,
(ix) is a direct consequence of (vii).
Estimate (ix) in Proposition 1.1 can be made more precise. For instance, from
the Stirling asymptotical estimate of the factorial,
n!
nneâˆ’nâˆš
2Ï€n
â†’1
as n â†’âˆ
one gets
(2n)! = 4nn2neâˆ’2nâˆš
4Ï€n (1 + o(1)),
(n!)2 = n2neâˆ’2n2Ï€n (1 + o(1)),
so that
2n
n

=
4n
âˆšÏ€n
1 + o(1)
1 + o(1)
or, equivalently,
2n
n

4n
âˆšÏ€n
â†’1
as n â†’âˆ.
(1.1)
Estimate (1.1) is â€˜accurateâ€™ also for small values of n. For instance, for n = 4,
one has
8
4

= 70 and 44
1
âˆš
Ï€4 â‰ƒ72.2.
1.1.3
Generalized binomial coefï¬cients and binomial series
For Î± âˆˆR we deï¬ne the sequence
Î±
n

of generalized binomial coefï¬cients as
Î±
n

:=
â§
âªâ¨
âªâ©
1
if n = 0,
Î±(Î± âˆ’1)(Î± âˆ’2) Â· Â· Â· (Î± âˆ’n + 1)
n!
if n â‰¥1.
Notice that
Î±
k

Ì¸= 0 âˆ€k if Î± /âˆˆN and
Î±
k

= 0 âˆ€k â‰¥Î± + 1 if Î± âˆˆN. The power
series
âˆ

n=0
Î±
n

zn
(1.2)
is called the binomial series.
Proposition 1.2 (Binomial series) The binomial series converges if |z| < 1 and
âˆ

n=0
Î±
n

zn = (1 + z)Î±
if |z| < 1.

4
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Proof. Since

 Î±
n+1


Î±
n

= |Î± âˆ’n|
|n + 1| â†’1
as n â†’âˆ,
it is well known that
n
|an| â†’1 as well; thus, the radius of the power series in
(1.2) is 1.
Differentiating n times the map z â†’(1 + z)Î±, one gets Dn(1 + z)Î± = Î±(Î± âˆ’
1) Â· Â· Â· (Î± âˆ’n + 1)(1 + z)Î±âˆ’n, so that the series on the left-hand side of (1.2) is
the McLaurin expansion of (1 + z)Î±.
Another proof is the following. Let S(z) := âˆ
n=0
Î±
n

zn, |z| < 1, be the sum
of the binomial series. Differentiating one gets
(1 + z)Sâ€²(z) = Î±S(z),
|z| < 1,
hence

S(z)
(1 + z)Î±
â€²
= (1 + z)Sâ€²(z) âˆ’Î±S(z)
(1 + z)Î±+1
= 0.
Thus there exists c âˆˆR such that S(z) = c (1 + z)Î± if |z| < 1. Finally, c = 1
since S(0) = 1.
Proposition 1.3 Let Î± âˆˆR. The following hold.
(i)
Î±
k

= Î±
k
Î± âˆ’1
k âˆ’1

âˆ€k â‰¥1.
(ii)
Î±
k

=
Î± âˆ’1
k

+
Î± âˆ’1
k âˆ’1

âˆ€k â‰¥1.
(iii)
âˆ’Î±
k

= (âˆ’1)k
Î± + k âˆ’1
k

âˆ€k â‰¥0.
Proof. The proofs of (i) and (ii) are left to the reader. Proving (iii) is a matter
of computation:
âˆ’Î±
k

= âˆ’Î±(âˆ’Î± âˆ’1) Â· Â· Â· (âˆ’Î± âˆ’k + 1)
k!
= (âˆ’1)k Î±(Î± + 1) Â· Â· Â· (Î± + k âˆ’1)
k!
= (âˆ’1)k
Î± + k âˆ’1
k

.
A few negative binomial coefï¬cients are quoted in Figure 1.2.
1.1.4
Inversion formulas
For any N, the matrix CN := (Cn
k), n, k = 0, . . . , N, is lower triangular and
all its diagonal entries are equal to 1. Hence 1 is the only eigenvalue of CN

COMBINATORICS
5
â›
âœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâ
1
0
0
0
0
0
0
0
0
0
. . .
1
âˆ’1
1
âˆ’1
1
âˆ’1
1
âˆ’1
1
âˆ’1
. . .
1
âˆ’2
3
âˆ’4
5
âˆ’6
7
âˆ’8
9
âˆ’10
. . .
1
âˆ’3
6
âˆ’10
15
âˆ’21
28
âˆ’36
45
âˆ’55
. . .
1
âˆ’4
10
âˆ’20
35
âˆ’56
84
âˆ’120
165
âˆ’220
. . .
1
âˆ’5
15
âˆ’35
70
âˆ’126
210
âˆ’330
495
âˆ’715
. . .
1
âˆ’6
21
âˆ’56
126
âˆ’252
462
âˆ’792
1 287
âˆ’2 002
. . .
1
âˆ’7
28
âˆ’84
210
âˆ’462
924
âˆ’1 716
3 003
âˆ’5 005
. . .
1
âˆ’8
36
âˆ’120
330
âˆ’792
1 716
âˆ’3 432
6 435
âˆ’11 440
. . .
1
âˆ’9
45
âˆ’165
495
âˆ’1 287
3 003
âˆ’6 435
12 870
âˆ’24 310
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
Figure 1.2
The coefï¬cients
âˆ’n
k

.
with algebraic multiplicity N. In particular CN is invertible, its inverse is lower
triangular, all its entries are integers and its diagonal entries are equal to 1.
Theorem 1.4 For any n, k = 0, . . . , N, (Câˆ’1
N )n
k = (âˆ’1)n+kn
k

.
Proof. Let B := (Bk
n), Bk
n := (âˆ’1)n+kn
k

so that both B and CNB are lower
triangular, i.e. (CNB)n
k = 0 if 0 â‰¤n < k. Moreover, (iv) and (viii) of Proposition
1.1 yield for any n â‰¥k
(CNB)n
k =
N

j=1
n
j

(âˆ’1)j+k
j
k

=
n

j=k
(âˆ’1)j+k
n
j
j
k

=
n
k

n

j=k
(âˆ’1)j+k
n âˆ’k
j âˆ’k

=
n
k
 nâˆ’k

i=0
(âˆ’1)i
n âˆ’k
i

=
n
k

Î´0,nâˆ’k = Î´n,k.
A few entries of the inverse of the matrix of binomial coefï¬cients are shown
in Figure 1.3. As a consequence of Theorem 1.4 the following inversion formulas
hold.
Corollary 1.5 Two sequences

xn

,

yn

satisfy
yn =
n

k=0
n
k

xk,
âˆ€n â‰¥0
if and only if
xn =
n

k=0
(âˆ’1)n+k
n
k

yk,
âˆ€n â‰¥0.

6
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
â›
âœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâ
1
0
0
0
0
0
0
0
0
0
. . .
âˆ’1
1
0
0
0
0
0
0
0
0
. . .
1
âˆ’2
1
0
0
0
0
0
0
0
. . .
âˆ’1
3
âˆ’3
1
0
0
0
0
0
0
. . .
1
âˆ’4
6
âˆ’4
1
0
0
0
0
0
. . .
âˆ’1
5
âˆ’10
10
âˆ’5
1
0
0
0
0
. . .
1
âˆ’6
15
âˆ’20
15
âˆ’6
1
0
0
0
. . .
âˆ’1
7
âˆ’21
35
âˆ’35
21
âˆ’7
1
0
0
. . .
1
âˆ’8
28
âˆ’56
70
âˆ’56
28
âˆ’8
1
0
. . .
âˆ’1
9
âˆ’36
84
âˆ’126
126
âˆ’84
36
âˆ’9
1
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
Figure 1.3
The inverse of the matrix of binomial coefï¬cients Câˆ’1
N .
Similarly,
Corollary 1.6 Two N-tuples or real numbers

xn

and

yn

satisfy
yn =
N

k=n
k
n

xk,
âˆ€n, 0 â‰¤n â‰¤N,
if and only if
xn =
N

k=n
(âˆ’1)n+k
k
n

yk,
âˆ€n, 0 â‰¤n â‰¤N.
1.1.5
Exercises
Exercise 1.7 Prove Newton binomial formula:
(i) directly, with an induction argument on n;
(ii) applying Taylor expansion formula;
(iii) starting from the formula D((1 + z)n) = n(1 + z)nâˆ’1.
Exercise 1.8 Differentiating the power series, see Appendix A, prove the formulas
in Figure 1.4.
Solution. Differentiating the identity âˆ
k=0 zk =
1
1âˆ’z, |z| < 1, we get for
|z|<1
âˆ

k=0
kzk = z
âˆ

k=0
D(zk) = zD
 âˆ

k=0
zk
= zD

1
1 âˆ’z

=
z
(1 âˆ’z)2 ;

COMBINATORICS
7
Let z âˆˆC, |z| < 1, and n âˆˆZ. We have the followings.
(i)
âˆ

k=0
kzk =
z
(1 âˆ’z)2 ,
(ii)
âˆ

k=0
k2zkâˆ’1 = D

z
(1 âˆ’z)2

=
1 + z
(1 âˆ’z)3 ,
(iii)
âˆ

k=0
n
k

zk = (1 + z)n,
(iv)
âˆ

k=0
k
n
k

zk = nz(1 + z)nâˆ’1,
(v)
âˆ

k=0
k2
n
k

zk = nz(1 + nz)(1 + z)nâˆ’2.
Figure 1.4
The sum of a few series related to the geometric series.
âˆ

k=0
k2zkâˆ’1 =
âˆ

k=0
D(kzk)
= D
 âˆ

k=0
kzk
= D

z
(1 âˆ’z)2

=
1 + z
(1 âˆ’z)3 .
Moreover, for any non-negative integer n, differentiating the identities
âˆ

k=0
n
k

zk = (1 + z)n
and
âˆ

k=0
âˆ’n
k

zk = (1 + z)âˆ’n
for any |z| < 1, we get
âˆ

k=0
k
n
k

zk = z
n

k=0
D
n
k

zk
= zD

n

k=0
n
k

zk
= zD((1 + z)n) = nz(1 + z)nâˆ’1;
âˆ

k=0
k2
n
k

zk = z
n

k=0
D

k
n
k

zk
= zD

n

k=0
n
k

zk
= zD(nz(1 + z)nâˆ’1) = nz(1 + nz)(1 + z)nâˆ’2.

8
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
1.2
Sets, permutations and functions
1.2.1
Sets
We recall that a ï¬nite set A is an unordered collection of pairwise different
objects. For example, the collection A hose objects are 1,2,3 is a ï¬nite set which
we denote as A = {1, 2, 3}; the collection 1,2,2,3 is not a ï¬nite set, and {1, 2, 3}
and {2, 1, 3} are the same set.
If A is a ï¬nite set with n objects (or elements), we may enumerate the
elements of A so that A =

x1, . . . , xn

. Therefore, for counting purposes, we
can assume without loss of generality that A = {1, . . . , n}. The number n is the
cardinality of A, and we write |A| = n.
Proposition 1.9 Let A be a ï¬nite set with n elements, n â‰¥1. There are Cn
k =
n
k

subsets of A with k elements.
Proof. Different proofs can be done. We propose one of them. Let dn,k be
the number of subsets of A with k elements. Obviously, dn,1 = n and dn,n = 1.
For 2 â‰¤k â‰¤n âˆ’1, assume we have n football players and we want to select a
team of k of them, including the captain of the team. We may proceed in the
following way: ï¬rst we choose the team of k-players: dn,k different teams can
be selected. Then, among the team, we select the captain: k different choices are
possible: so there are kdn,k ways to select the team and the captain. However,
we can proceed in another way: ï¬rst we choose the captain among the n players:
there are n different possible choices. Then we choose k âˆ’1 players among the
remaining n âˆ’1 players: there are dnâˆ’1,kâˆ’1 possible choices. Thus
dn,k = n
k dnâˆ’1,kâˆ’1
which by induction, gives
dn,k = n
k
n âˆ’1
k âˆ’1 . . . n âˆ’k + 2
2
dnâˆ’k+1,1
= n
k
n âˆ’1
k âˆ’1 . . . n âˆ’k + 2
2
n âˆ’k + 1
1
=
n
k

.
1.2.2
Permutations
Let N be a ï¬nite set and let n be its cardinality. Without loss of generality,
we can assume N = {1, 2, . . . , n}. A permutation of N is an injective (and thus
one-to-one) mapping Ï€ : N â†’N. Since composing bijective maps yields another
bijective map, the family of permutations of a set N is a group with respect to
the composition of maps; the unit element is the identity map; this group is called
the group of permutations of N. It is denoted as Sn or Pn. Notice that Pn is a
not a commutative group if n â‰¥3.
Each permutation is characterized by its image-word or image-list, i.e. by the
n-tuple (Ï€(1), . . . , Ï€(n)). For instance, the permutation Ï€ âˆˆP6 deï¬ned by

COMBINATORICS
9
Ï€(1) = 2, Ï€(2) = 3, Ï€(3) = 1, Ï€(4) = 4, Ï€(5) = 6 and Ï€(6) = 5 is denoted as

1
2
3
4
5
6
2
3
1
4
6
5

.
or, in brief, with its image-word 231465.
The set of permutations of N = {1 . . . , n} has n! elements,
|Pn| = n!
In fact, the image Ï€(1) of 1 can be chosen among n possible values, then the
image Ï€(2) of 2 can be chosen among n âˆ’1 possible values and so on. Hence
|Pn| = n(n âˆ’1)(n âˆ’2) Â· Â· Â· 3 Â· 2 Â· Â· Â· 1 = n!
1.2.2.1
Derangements
Let Ï€ âˆˆPn be a permutation of N = {1, . . . , n}. A point x âˆˆN is a ï¬xed point
of Ï€ if Ï€(x) = x.
We now compute the cardinality dn of the set Dn of permutations without
ï¬xed points, also called derangements.
Dn :=

Ï€ âˆˆPn
 Ï€(i) Ì¸= i âˆ€i âˆˆN

.
Proposition 1.10 The cardinality of Dn is
dn = n!
n

j=0
(âˆ’1)j 1
j!
âˆ€n â‰¥1.
Proof. If a permutation of N has j ï¬xed points, 0 â‰¤j â‰¤n, then it is
a derangement of the other n âˆ’j points of N. Thus, a permutation with j
ï¬xed points splits as a couple: the set of its ï¬xed points and a derangement
of n âˆ’j points. There are
n
j

different choices for the j ï¬xed points and
dnâˆ’j
derangements of the remaining n âˆ’j
points, so that, the possible
permutations of N with exactly j ï¬xed points are
n
j

dnâˆ’j (where d0 = 1). Thus
|Pn| = n
j=0
n
j

dnâˆ’j âˆ€n â‰¥1, i.e.
n! =
n

j=0
n
j

dnâˆ’j
âˆ€n â‰¥0.
(1.3)
The inversion formula of binomial coefï¬cients, see Corollary 1.5, reads
dn =
n

j=0
(âˆ’1)(n+j)
n
j

j! = n!
n

j=0
(âˆ’1)j
j!
âˆ€n â‰¥0.

10
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
0, 0, 1, 2, 9, 44, 265, 1 854, 14 833, 133 496, 1 334 961, 14 684 570, . . .
Figure 1.5
From the left, the numbers d0, d1, d2, d3, . . . of derangements of
0, 1, 2, 3, . . . points.
Corollary 1.11 The number dn of derangements of n points is the nearest integer
to n!/e.
Proof. The elementary estimate between the exponential and its McLaurin
expansion gives
ex âˆ’
n

j=0
xj
j!
 â‰¤
|x|n+1
(n + 1)!,
âˆ€x â‰¤0;
hence for x = âˆ’1 we get
1
e âˆ’
n

j=0
(âˆ’1)j
j!
 â‰¤
1
(n + 1)!,
so that, from Proposition 1.10 one gets
dn âˆ’n!
e
 = n!

n

j=0
(âˆ’1)j
j!
âˆ’1
e
 â‰¤
n!
(n + 1)! =
1
n + 1 â‰¤1
3
for each n â‰¥2.
Figure 1.5 contains the ï¬rst elements of the sequence {dn}.
1.2.3
Multisets
Another interesting structure is an unordered list of elements taken from a given
set A. This structure is called a multiset on A. More formally, a multiset on a
set A is a couple (A, a) where A is a given set and a : A â†’N âˆª{+âˆ} is the
multiplicity function which counts â€˜how many timesâ€™ an element x âˆˆA appears
in the multiset. Clearly, each set is a multiset where each object has multiplicity
1. We denote as

a2, b2, c5
or a2b2c5 the multiset on A := {a, b, c} where a
and b have multiplicity 2 and c has multiplicity 5. The cardinality of a multiset
(A, a) is 
xâˆˆA a(x) and is denoted by |(A, a)| or #(A, a). For instance, the
cardinality of a2b2c5 is 9.
If B is a subset of A, then B is also the multiset (A, a) on A where
a(x) =
1
if x âˆˆB,
0
if x /âˆˆB.

COMBINATORICS
11
Given two multisets (B, b) and (A, a), we say that (B, b) is included in (A, a)
if B âŠ‚A and b(x) â‰¤a(x) âˆ€x âˆˆB. In this case, (B, b) = (A,b) where
b(x) =

b(x)
if x âˆˆB,
0
if x /âˆˆB.
Proposition 1.12 Let A be a ï¬nite set, |A| = n. Let (A, a) be a multiset on A and
let k be a non-negative integer such that k â‰¤a(x) âˆ€x âˆˆA. The multisets included
in (A, a) with k elements are
n + k âˆ’1
k

.
Proof. Let A = {1, . . . , n}. A multiset S of cardinality k included in (A, a)
contains the element 1 x1 times, the element 2 x2 times, and so on, with x1 +
x2 + Â· Â· Â· + xn = k. Moreover, the n-tuple (x1, . . . , xn) characterizes S. We can
associate to a n-tuple (x1, . . . , xn) the binary sequence
00 . . . 0
  
x1
1 00 . . . 0
  
x2
1 . . . 1 00 . . . 0
  
xnâˆ’1
1 00 . . . 0
  
xn
(1.4)
where the symbol 1 denotes the fact that we are changing the element of A. This
is a binary word of length n + k âˆ’1 with k zeroes.
The correspondence described above is a one-to-one correspondence between
the set of multisets of cardinality k included in (A, a) and the set of binary words
of length n + k âˆ’1 with k zeroes. There are exactly
n + k âˆ’1
k

different words of this kind, so that the claim is proven.
1.2.4
Lists and functions
Given a set A, a list of k objects from the set A or a k-word with symbols in A
is an ordered k-tuple of objects. For instance, if A = {1, 2, 3}, then the 6-tuples
(1,2,3,3,2,1) and (3,2,1,3,2,1) are two different 6-words of objects in A. In these
lists, or words, repetitions are allowed and the order of the objects is taken into
account. Since each element of the list can be chosen independently of the others,
there are n possible choices for each object in the list. Hence, the following holds.
Proposition 1.13 The number of k-lists of objects from a set A of cardinality n is
nk.
A function f : X â†’A is deï¬ned by the value it assumes on each element of
X: if f : {1, . . . , k} â†’A, then f is deï¬ned by the k-list (f (1), f (2), . . . , f (k)),

12
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
which we refer to as the image-list or image-word of f . Conversely, each k-list
(a1, a2, . . . , ak) with symbols from A deï¬nes the function f : {1, . . . , k} â†’A
given by f (i) := ai âˆ€i. If |A| is ï¬nite, |A| = n, we have a one-to-one correspon-
dence between the set Fk
n of maps f : {1, . . . , k} â†’A, and the set of the k-lists
with symbols in A. Therefore, we have the following.
Proposition 1.14 The number of functions in Fk
n is F k
n := |Fk
n| = nk.
1.2.5
Injective functions
We use the symbol Ik
n to denote the set of injective functions f : {1, . . . , k} â†’A,
|A| = n, k â‰¤n. Let I k
n = |Ik
n|. Obviously, I k
n = 0 if k > n. The image-list of an
injective function f âˆˆIk
n is a k-word of pairwise different symbols taken from A
To form any such image-list, one can choose the ï¬rst entry among n elements, the
second entry can be chosen among n âˆ’1 elements, . . ., the kth entry can be cho-
sen among the remaining n âˆ’k + 1 elements of A, so that we have the following.
Proposition 1.15 The cardinality I k
n of Ik
n is
I k
n = |Ik
n| = n(n âˆ’1) Â· Â· Â· Â· Â· (n âˆ’k + 1) = k!
n
k

=
n!
(n âˆ’k)! .
Some of the I k
nâ€™s are in Figure 1.6.
1.2.6
Monotone increasing functions
Let
Ck
n,
k â‰¤n,
be
the
set
of
strictly
monotone
increasing
functions
f : {1, . . . , k} â†’{1, . . . , n}. The image-list of any such function is an ordered
k-tuple of strictly increasingâ€“hence pairwise disjointâ€“elements of {1, . . . , n}.
The k-tuple is thus identiï¬ed by the subset of the elements of {1, . . . , n} appearing
in it, so that we have the following.
â›
âœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâ
1
1
1
1
1
1
1
1
1
1
. . .
0
1
2
3
4
5
6
7
8
9
. . .
0
0
2
6
12
20
30
42
56
72
. . .
0
0
0
6
24
60
120
210
336
504
. . .
0
0
0
0
24
120
360
840
1 680
3 024
. . .
0
0
0
0
0
120
720
2 520
6 720
15 120
. . .
0
0
0
0
0
0
720
5 040
20 160
60 480
. . .
0
0
0
0
0
0
0
5 040
40 320
181 440
. . .
0
0
0
0
0
0
0
0
40 320
362 880
. . .
0
0
0
0
0
0
0
0
0
362 880
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
Figure 1.6
The cardinality I k
n of the set of injective maps Ik
n for n, k â‰¥0.

COMBINATORICS
13
Proposition 1.16 The cardinality Ck
n of Ck
n is
Ck
n := |Ck
n| =
n
k

= Cn
k = (CT )k
n.
1.2.7
Monotone nondecreasing functions
Let Dk
n be the class of monotone nondecreasing functions f : {1, . . . , k} â†’
{1, . . . , n}. The image-list of any such function is a nondecreasing ordered
k-tuple of elements of {1, . . . , n}, so that elements can be repeated. The
functions in Dk
n are as many as the multisets with cardinality k included in
a multiset (A, a), where A = {1, . . . , n} and a(x) â‰¥k âˆ€x âˆˆA. Thus, see
Proposition 1.12, we have the following.
Proposition 1.17 The cardinality Dk
n of Dk
n is
Dk
n := |Dk
n| = |Ck
n+kâˆ’1| =
n + k âˆ’1
k

.
Another proof of Proposition 1.17. Consider the map Ï† : Dk
n â†’Fk
n+kâˆ’1 deï¬ned
by Ï†(f )(i) := f (i) + i âˆ’1 âˆ€i âˆˆ{1, . . . , k}, âˆ€f âˆˆDk
n. Obviously, if f âˆˆDk
n,
then Ï†(f ) is strictly monotone increasing, Ï†(f ) âˆˆCk
n+kâˆ’1. Moreover, the corre-
spondence Ï† : Dk
n â†’Ck
n+kâˆ’1 is one-to-one, thus
Dk
n = |Dk
n| = |Ck
n+kâˆ’1| =
n + k âˆ’1
k

.
Yet another proof of Proposition 1.17. We are now going to deï¬ne a one-to-one
correspondence between a family of multisets and Dk
n. Let (A, a) be a multiset
on A = {1, . . . , n} with a(x) â‰¥k âˆ€k. For any multiset (S, nS) of cardinality k
included in (A, a), let fS : A â†’{0, . . . , k} be the function deï¬ned by
fS(x) :=

yâ‰¤x
nS(y),
i.e. for each x âˆˆA, fS(x) is the sum of the multiplicities nS(y) of all elements
y âˆˆA, y â‰¤x. fS is obviously a nondecreasing function and fS(n) = k. More-
over, it is easy to show that the map
S â†’fS
is a one-to-one correspondence between the family of the multisets included
in (A, a) of cardinality k and the family of monotone nondecreasing func-
tions from {1, . . . , n} to {0, . . . , k} such that f (k) = 1. In turn, there is an
obvious one-to-one correspondence between this class of functions and the class

14
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
of monotone nondecreasing functions from {1, . . . , n âˆ’1} to {0, . . . , k}. Thus,
applying Proposition 1.17 we get
|Dnâˆ’1
k+1| =
k + 1 + (n âˆ’1) âˆ’1
n âˆ’1

=
n + k âˆ’1
k

.
1.2.8
Surjective functions
The computation of the number of surjective functions is more delicate. Let Sk
n
denote the family of surjective functions from {1, . . . , k} onto {1, . . . , n} and let
Sk
n =
â§
âªâ¨
âªâ©
1
if n = k = 0,
0
if n = 0, k > 0
|Sk
n|
if n â‰¥1.
Obviously, Sk
n = |Sk
n| = 0 if k < n. Moreover, if k = n â‰¥1, then a function
f : {1, . . . , n} â†’{1, . . . , n} is surjective if and only if f is injective, so that
Sn
n = |Sk
n| = I n
n = n!
If k > n â‰¥1, then Sk
n Ì¸= âˆ…. Observe that any function is onto on its range.
Thus, for each j = 1, . . . , n, consider the set Aj of functions f : {1, . . . , k} â†’
{1, . . . , n} whose range has cardinality j. We must have
nk = |Fk
n| =
n

j=1
|Aj|.
There are exactly
n
j

subsets of {1, . . . , n} with cardinality j and there are Sk
j
different surjective functions onto each of these sets. Thus, |Aj| =
n
j

Sk
j and
nk =
n

j=1
n
j

Sk
j
âˆ€n â‰¥1.
Since we deï¬ned Sk
0 = 0, we get
nk =
n

j=0
n
j

Sk
j
âˆ€n â‰¥0.
(1.5)
Therefore, applying the inversion formula in Corollary 1.5 we conclude the fol-
lowing.
Proposition 1.18 The cardinality Sk
n of the set Sk
n of surjective functions from
{1, . . . , k} onto {1, . . . , n} is
Sk
n =
n

j=0
(âˆ’1)n+j
n
j

j k =
n

j=0
(âˆ’1)j
n
j

(n âˆ’j)k
âˆ€n, k â‰¥1.

COMBINATORICS
15
We point out that the equality holds also if k â‰¤n so that
1
n!
n

j=0
(âˆ’1)j
n
j

(n âˆ’j)k = 1
n!Sk
n =

1
if k = n,
0
if k < n.
Another useful formula for Sk
n is an inductive one, obtained starting from
Sn
n = n! âˆ€n â‰¥0 and Sk
n = 0 for any k and n with k < n.
Proposition 1.19 We have
â§
âªâ¨
âªâ©
Sk
n = n(Skâˆ’1
n
+ Skâˆ’1
nâˆ’1)
if k â‰¥1, n â‰¥0,
Sn
n = n!,
Sk
0 = 0
if k â‰¥1.
(1.6)
Proof. Assume n â‰¥1 and k â‰¥1 and let f : {1, . . . , k} â†’{1, . . . , n} be a sur-
jective function. Let A âŠ‚Sk
n be the class of functions such that the restriction
f : {1, . . . , k âˆ’1} â†’{1, . . . , n} of f is surjective and let B := Sk
n \ A. The car-
dinality of A is nSkâˆ’1
n
because there are Skâˆ’1
n
surjective maps from {1, . . . , k âˆ’1}
onto {1, . . . , n} and there are n possible choices for f (k). Since the maps on B
have a range of (n âˆ’1) elements, we infer that there are nSkâˆ’1
nâˆ’1 maps of this
kind. In fact, there are
 n
nâˆ’1

= n subsets E of {1, . . . , n} of cardinality n âˆ’1
and there are Skâˆ’1
nâˆ’1 surjective functions from {1, . . . , k âˆ’1} onto E. Therefore,
Sk
n = |A| + |B| = nSkâˆ’1
n
+ nSkâˆ’1
nâˆ’1.
i.e. (1.6).
Some of the Sk
nâ€™s are in Figure 1.7.
â›
âœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâ
0
0
0
0
0
0
0
0
0
. . .
0
1
0
0
0
0
0
0
0
. . .
0
1
2
0
0
0
0
0
0
. . .
0
1
6
6
0
0
0
0
0
. . .
0
1
14
36
24
0
0
0
0
. . .
0
1
30
150
240
120
0
0
0
. . .
0
1
62
540
1 560
1 800
720
0
0
. . .
0
1
126
1 806
8 400
16 800
15 120
5 040
0
. . .
0
1
254
5 796
40 824
126 000
191 520
141 120
40 320
. . .
0
1
510
18 150
186 480
834 120
1 905 120
2 328 480
1 451 520
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
Figure 1.7
The cardinality Sk
n of the set of surjective maps Sk
n for n, k â‰¥0.

16
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
1.2.9
Exercises
Exercise 1.20 How many diagonals are there in a polygon having n edges?
1.3
Drawings
A drawing or selection of k objects from a population of n is the choice of k
elements among the n available ones. We want to compute how many of such
selections are possible. In order to make this computation, it is necessary to be
more precise, both on the composition of the population and on the rules of the
selection as, for instance, if the order of selection is relevant or not. We consider
a few cases:
â€¢ The population is made by pairwise different elements, as in a lottery: in
other words, the population is a set.
â€¢ The population is a multiset (A, a). In this case, we say that we are dealing
with a drawing from A with repetitions.
â€¢ The selected objects may be given an order. In this case we say that we
consider an ordered selection. Unordered selections are also called simple
selections.
Some drawing policies simply boil down to the previous cases:
â€¢ In the lottery game, numbers are drawn one after another, but the order of
drawings is not taken into account: it is a simple selection of objects from
a set.
â€¢ In ordered selections the k-elements are selected one after another and the
order is taken into account.
â€¢ A drawing with replacement, i.e. a drawing from a set where each selected
object is put back into the population before the next drawing is equivalent
to a drawing with repetitions, i.e. to drawing from a multiset where each
element has multiplicity larger than the total number of selected objects.
1.3.1
Ordered drawings
Ordered drawings of k objects from a multiset (A, a) are k-words with symbols
taken from A.
1.3.1.1
Ordered drawings from a set
Each ordered drawing of k objects from a set A is a k-list with symbols in A
that are pairwise different. Thus the number of possible ordered drawings of k
elements from A is the number of k-lists with pairwise different symbols in A.

COMBINATORICS
17
If |A| = n, there are n possible choices for the ï¬rst symbol, n âˆ’1 for the second
and so on, so that there are
n(n âˆ’1) . . . (n âˆ’k + 1)
different k-words with pairwise different symbols.
1.3.1.2
Ordered drawings from a multiset
Let (A, a) be a multiset where |A| = n and let k âˆˆN be less than or equal to
min {a(x) | x âˆˆA}. Each ordered drawing of k elements from (A, a) is a k-list
with symbols in A, where the same symbol may appear more than once. We
have already proven that there are nk possible k-lists of this kind, so that the
following holds.
Proposition 1.21 The number of ordered drawings of k elements from a multiset
(A, a) where k â‰¤min {a(x) | x âˆˆA} is nk.
In particular, the number of ordered drawings with replacement of k elements
from A is nk.
1.3.2
Simple drawings
1.3.2.1
Drawings from a set
The population from which we make the selection is a set A. To draw k objects
from A is equivalent to selecting a subset of k elements of A: we do not distin-
guish selections that contain the same objects with a different ordering.
Proposition 1.22 The number of possible drawings of k elements from a set of
cardinality n is
n
k

.
1.3.2.2
Drawings from a multiset
Let (A, a) be a multiset, |A| = n, and let k â‰¤min {a(x) | x âˆˆA}. Each sequence
S drawn from (A, a) is a sequence of symbols in A where repetitions may occur
and the order of the symbols is not taken into accout, e.g.
FABADABDF = FBFDDAABA
i.e. S is a multiset of k elements included in (A, a) (cf. Proposition 1.17).
Proposition 1.23 The number of simple drawings of k elements from a multiset
(A, a), is
n+kâˆ’1
k

provided k â‰¤min {a(x) | x âˆˆA}.
1.3.3
Multiplicative property of drawings
The previous results on drawings can also be obtained from the following com-
binatorics properties of drawings.

18
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Theorem 1.24 For each non-negative integer k let ak and bk be the numbers of
drawings of k objects from the multisets (A, a) and (B, b) made according to
policies P1 and P2, respectively. If A and B are disjoint, then the number of draw-
ings of k elements from the population obtained by the union of (A, a) and (B, b)
made according to policies P1
and P2
for the drawings from (A, a)
and (B, b), respectively, is
ck =
k

j=0
ajbkâˆ’j.
Proof. A drawing of k objects from the union of the two populations contains,
say, j elements from (A, a) and k âˆ’j elements from (B, b), where j is an
integer, 0 â‰¤j â‰¤k. The j elements drawn from (A, a) can be chosen in aj
different ways, while the n âˆ’j elements drawn from (B, b) can be chosen in
bkâˆ’j different ways and the two choices are independent. Thus,
ck =
k

j=0
ajbkâˆ’j.
A similar result holds for ordered drawings
Theorem 1.25 For each non-negative integer k let ak and bk be the number of
ordered drawings from the multisets (A, a) and (B, b) made according to policies
P1 and P2, respectively. If A and B are disjoint, then the number of ordered
drawings from the population union of (A, a) and (B, b) made according to policy
P1 for the elements of (A, a) and according to policy P2 for elements of (B, b) are
ck =
k

j=0
k
j

ajbkâˆ’j.
Proof. A drawing of k elements from the union of the two populations con-
tains j elements from (A, a) and n âˆ’j elements from (B, b) for some integer
j âˆˆ{0, . . . , k}. The j elements from (A, a) can be chosen in aj different ways,
the k âˆ’j elements drawn from (B, b) can be chosen in bkâˆ’j different ways and
the two chosen groups are independent. Finally, there are
k
j

ways to order such
selections. Thus,
ck =
k

j=0
k
j

ajbkâˆ’j.
1.3.4
Exercises
Exercise 1.26 A committee of 7 people has to be chosen among 11 women and 8
men. In each of the following cases compute how many different committees can
be chosen:

COMBINATORICS
19
â€¢ No constraint is imposed.
â€¢ At least two women and at least one man must be present.
â€¢ There must be more women than men.
â€¢ At least two women and no more than three men must be present.
1.4
Grouping
Many classical counting problems amount to a collocation or grouping problem:
how many different arrangements of k objects in n boxes are there? Putting it
another way, how many different ways of grouping k objects into n groups are
there? Also in this case a deï¬nite answer cannot be given: we must be more
precise both on the population to be arranged, on the rules (or policy) of the
procedure, and on the way the groups are evaluated. For example, one must say
whether the objects to be arranged are pairwise different or not, whether the order
of the objects in each box must be taken into account or not, whether the boxes
are pairwise distinct or not, and if further constraints are imposed. Here we deal
with a few cases, all referring to collocation or grouping in pairwise different
boxes. We consider the formed groups as a list instead of as a set: for instance,
if we start with the objects {1, 2, 3} then the two arrangements in two boxes
({1}, {2, 3}) and ({2, 3}, {1}) are considered to be different.
1.4.1
Collocations of pairwise different objects
Arranging k distinct objects in n pairwise different boxes is the act of
deciding the box in which each object is going to be located. Since both the
objects and the boxes are pairwise distinct, we may identify the objects and the
boxes with the sets {1, . . . , k} and {1, . . . , n}, respectively. Each arrangement
corresponds to a grouping map f : {1, . . . , k} â†’{1, . . . , n} that puts the object
j into the box f (j).
1.4.1.1
No further constraint
In this case the set of possible locations is in a one-to-one correspondence with the
set Fk
n of all maps f : {1, . . . , k} â†’{1, . . . , n}. Therefore, there are nk different
ways to locate k-different objects in n boxes.
A different way to do the computation is the following. Assume i1, . . . , in
objects are placed in the boxes 1, . . . , n, respectively, so that i1 + Â· Â· Â· + in = k.
There are
k
i1

different choices for the elements located in the ï¬rst box,
kâˆ’i1
i2

different choices for the elements in the second box, and so on, so that there are
k âˆ’i1 âˆ’Â· Â· Â· âˆ’inâˆ’1
in


20
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
different choices for the elements in the nth box. Thus the different possible
arrangements are
k
i1
k âˆ’i1
i2

Â· Â· Â·
k âˆ’i1 âˆ’Â· Â· Â· âˆ’inâˆ’1
in

=
=
k!
i1!(k âˆ’i1)!
(k âˆ’i1)!
i2!(k âˆ’i1 âˆ’i2)! Â· Â· Â· =
k!
i1! i2! Â· Â· Â· in!;
(1.7)
the ratio in (1.7) is called the multinomial coefï¬cient and is denoted as

k
i1 i2 Â· Â· Â· in

.
From (1.7) we infer that the possible collocations of k pairwise different objects
in n pairwise different boxes are

i1+Â·Â·Â·+in=k

k
i1 i2 Â· Â· Â· in

where the sum is performed over all the n-tuples i1, . . . , in of non-negative inte-
gers such that i1 + Â· Â· Â· + in = k. Thus, from the two different ways of computing
collocations, we get the equality
nk =

i1+Â·Â·Â·+in=k

k
i1 i2 Â· Â· Â· in

.
1.4.1.2
At least one object in each box
We now want to compute the number of different arrangements with at least one
object in each box. Assuming we have k objects and n boxes, collocations of
this type are in a one-to-one correspondence with the class of surjective maps
Sk
n from {1, . . . , k} onto {1, . . . , n}, thus there are
Sk
n =
n

j=0
(âˆ’1)j
n
j

(n âˆ’j)k
collocations of k pairwise different into n pairwise different boxes that place at
least one object in each box.
Another way to compute the previous number is the following. Assume
i1, . . . , in objects are located in the boxes 1, . . . , n, respectively, with at least
one object in each box, i.e. i1 + Â· Â· Â· + in = k and i1, . . . , in â‰¥1. As in (1.7),
there are

k
i1 i2 Â· Â· Â· in

(1.8)

COMBINATORICS
21
ways to arrange k different objects in n boxes with ij objects in the box j. Thus
the number of arrangements with no empty box is

i1+Â·Â·Â·+in=k
i1,...,inâ‰¥1

k
i1 i2 Â· Â· Â· in

;
here, the sum is performed over all the n-tuples i1, . . . , in with positive compo-
nents with i1 + Â· Â· Â· + in = k. The above two ways of computing the number of
such collocations yield the identity
Sk
n =

i1+Â·Â·Â·+in=k
i1,...,inâ‰¥1

k
i1 i2 Â· Â· Â· in

.
(1.9)
1.4.1.3
At most one object in each box
We now impose a different constraint: each box may contain at most one object.
Assuming we have k objects and n boxes, collocations of this type are in a
one-to-one correspondence with the class of injective grouping maps Ik
n from
{1, . . . , k} onto {1, . . . , n}, thus there are
I k
n = k!
n
k

collocations of this type.
1.4.1.4
Grouping into lists
Here, we want to compute the number of ways of grouping k pairwise different
objects in n pairwise different boxes and pretend that the order of the objects in
each box matters. In other words we want to compute how many different ways
exist to group k objects in a list of n lists of objects. We proceed as follows.
The ï¬rst object can be collocated in one of the n boxes, that is in n different
ways. The second object can be collocated in n + 1 different ways: in fact, it can
be either collocated in each of the n âˆ’1 empty boxes, or it can be collocated
in the same box as the ï¬rst object. In the latter case it can be collocated either
as the ï¬rst or as the second object in that box. So the possible arrangements of
the second object are (n âˆ’1) + 2 = n + 1. The third object can be collocated in
n + 2 ways. In fact, if the ï¬rst two objects are collocated in two different boxes,
then the third object can either be collocated in one of the n âˆ’2 empty boxes
or in two different ways in each of the two nonempty boxes. Thus, there are
(n âˆ’2) + 2 + 2 = n + 2 possible arragements. If the ï¬rst two objects are in the
same box, then the third object can either be collocated in one of the n âˆ’1 empty
boxes or in the nonempty one. In the latter case, it can be collocated in three
different ways: either as the ï¬rst, or between the two objects already present, or

22
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
as the last one. Again, the third object can be collocated in (n âˆ’1) + 3 = n + 2
ways. By an induction argument, we infer that there are n + k âˆ’1 different
arrangements for the kth object. Thus, the number of different ordered locations
of k objects in n boxes is
n(n + 1)(n + 2) . . . (n + k âˆ’1) = k!
n + k âˆ’1
k

.
1.4.2
Collocations of identical objects
We want to compute the number of ways to arrange k identical objects in n
pairwise different boxes. In this case each arrangement is characterized by the
number of elements in each box, that is by the map x : {1, . . . , n} â†’{0, . . . , k}
which counts how many objects are in each box. Obviously, n
s=1 x(s) = k. If
the k objects are copies of the number â€˜0â€™, then each arrangement is identiï¬ed
by the binary sequence
00 . . . 0
  
x(1)
1 00 . . . 0
  
x(2)
1 . . . 1 00 . . . 0
  
x(nâˆ’1)
1 00 . . . 0
  
x(n)
(1.10)
where the number â€˜0â€™ denotes the fact that we are changing box.
1.4.2.1
No further constraint
Let us compute the number of such arrangements with no further constraint.
There is a one-to-one correspondence between such arrangements and the set
of all binary sequences of the type (1.10). Therefore, see Proposition 1.12, the
different collocations of k identical objects in n pairwise different boxes is
n + k âˆ’1
k

.
(1.11)
1.4.2.2
At least one in each box
We add now the constraint that each box must contain at least one object. If
k < n no such arrangement is possible. If k â‰¥n, we then place one object in
each box so that the constraint is satisï¬ed. The remaining k âˆ’n objects can be
now collocated without constraints. Therefore, cf. (1.11), there are
n + (k âˆ’n) âˆ’1
k âˆ’n

=
k âˆ’1
k âˆ’n

=
k âˆ’1
n âˆ’1

ways to arrange k identical objects in n boxes, so that no box remains empty.
1.4.2.3
At most one in each box
We consider arrangements of k identical objects in n pairwise different boxes
that place at most one object into each box. In this case, each arrangement is

COMBINATORICS
23
completely characterized by the subset of ï¬lled boxes. Since we can choose them
in
n
k

different ways, we conclude that the collocations of k identical objects in
n pairwise different boxes with at most one object per box is
n
k

.
1.4.3
Multiplicative property
Combinatorial properties hold for collocations as well as for drawings.
Theorem 1.27 For each non-negative integer k, let ak and bk be the number
of collocations of k pairwise different objects in two sets S1 and S2 of pairwise
different boxes with policies P1 and P2, respectively. If S1 âˆ©S2 = âˆ…, then the dif-
ferent collocations of the k objects in S1 âˆªS2 following policy P1 for collocations
in boxes of S1 and policy P2 for collocations in boxes of S2 is
ck =
k

j=0
k
j

ajbkâˆ’j.
Proof. Let j objects, 0 â‰¤j â‰¤k be collocated in the boxes of the set S1 and
let the other k âˆ’j objects be collocated in the boxes of S2. There are aj different
ways of placing j objects in the boxes of S1 and bkâˆ’j different ways of placing
(k âˆ’j) objects in the boxes of S2. Moreover, there are
k
j

different ways to
choose which objects are collocated in the boxes of S1. Hence,
ck =
k

j=0
k
j

ajbkâˆ’j
âˆ€k â‰¥0.
A similar result holds for the collocations of identical objects.
Theorem 1.28 For each non-negative integer k, let ak and bk be the number of
collocations of k identical objects in two sets S1 and S2 of pairwise different boxes
with policies P1 and P2, respectively. If S1 âˆ©S2 = âˆ…, then the collocations of the k
objects in the boxes of S1 âˆªS2 made according to policy P1 for the collocations in
the boxes of S1 and according to policy P2 for the collocations in the boxes of S2 is
ck =
k

j=0
ajbkâˆ’j.
Proof. Let j objects, 0 â‰¤j â‰¤k be collocated in the boxes of the set S1 and
let the other k âˆ’j objects be collocated in the boxes of S2. There are aj ways of
placing j objects in the boxes of S1 and bkâˆ’j different ways of placing (k âˆ’j)

24
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
objects in the boxes of S2. Since the objects are identical, there is no way to
select which the j objects to be placed in the boxes of S1 are. Then the possible
different collocations are
ck =
k

j=0
ajbkâˆ’j
âˆ€k â‰¥0.
1.4.4
Collocations in statistical physics
In statistical physics, each â€˜particleâ€™ is allowed to be in a certain â€˜stateâ€™; an
â€˜energy levelâ€™ is associated with each state. The total energy of a system of
particles depends on how many particles are in each of the possible states; the
mean value of the energy depends on the probabilities that particles stay in a
certain state. Thus, the number of possible collocations of the particles in the
available states must be evaluated.
1.4.4.1
Maxwell-Boltzmann statistics
This is the case of classical statistical physics: the particles are distinct and no
constraint is imposed on their distribution in different states. The number of
possible collocations of k particles in n states is thus the number of collocations
of k pairwise different objects in n pairwise different boxes, i.e. nk.
1.4.4.2
Boseâ€“Einstein statistics
The particles are indistinguishable and no constraint is imposed on their distri-
bution in different states. Particles with this behaviour are called bosons. The
number of collocations of k particles in n states is then the number of collocations
of k identical objects in n pairwise different boxes, i.e.
n + k âˆ’1
k

=
n + k âˆ’1
n âˆ’1

.
1.4.4.3
Fermiâ€“Dirac statistics
The particles are indistinguishable and each state can be occupied by at most
one particle (Pauli exclusion principle). Particles following this behaviour are
called fermions. Then the collocations of k particles in n states is the number
of possible choices for the states to be occupied, i.e.
n
k

. Obviously, the Pauli
exclusion principle implies n â‰¥k.
1.4.5
Exercises
Exercise 1.29 A group of eight people sits around a table with eight seats. How
many different ways of sitting are there?

COMBINATORICS
25
Exercise 1.30 Compute the number gn,k of subsets of {1 . . . , n} having cardinality
k and that do not contain two consecutive integers.
Solution. There is a one-to-one correspondence between the family of the
subsets of cardinality k and the set of binary n-words given by mapping a
subset A âŠ‚{1, . . . , n} to its characteristic function 1A. Namely, to the subset
A âŠ‚{1, . . . , n} we associate the binary n-word (a1, a2, . . . , an) where ai = 1 if
i âˆˆA and ai = 0 otherwise. Consequently, the family we are considering is in
a one-to-one correspondence with the binary n-words in which there cannot be
two consecutive 1â€™s, in
0001000101000101
Considering the 0â€™s as the sides of a box that contains at most one 1, we have
k 1â€™s and n âˆ’k + 1 boxes with at most one 1 per box. Thus, each collocation
is uniquely detected by the choice of the k nonempty boxes. Thus, see Section
1.4.2, gn,k =
nâˆ’k+1
k

.
Exercise 1.31 A physical system is made by identical particles. The total energy of
the system is 4E0 where E0 is a given positive constant. The possible energy levels
of each particle are k E0, k = 0, 1, 2, 3, 4. How many different conï¬gurations are
possible if;
(i) the kth energy level is made of k2 + 1 states;
(ii) the kth energy level is made of 2(k2 + 1) states;
(iii) the kth energy level is made of k2 + 1 states and two particles cannot occupy
the same state.
Exercise 1.32 For any non-negative integer n â‰¥0, deï¬ne
xn := x(x + 1)(x + 2) Â· Â· Â· (x + n âˆ’1),
xn := x(x âˆ’1)(x âˆ’2) Â· Â· Â· (x âˆ’n + 1).
Prove that
xn = (âˆ’1)n(âˆ’x)n.
(1.12)
[Hint. Take advantage of (iii) of Proposition 1.3.]
Exercise 1.33 n players participate in a single-elimination tennis tournament.
How many matches shall be played?
Exercise 1.34 You are going to place 4 mathematics books, 3 chemistry books
and 2 physics books on a shelf. Compute how many different arrangements are
possible. What if you want to keep books of the same subject together?

26
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Exercise 1.35 A comittee of 4 is to be chosen from a group of 20 people. How
many different choices are there for the roles of president, chairman, secretary,
and treasurer?
Exercise 1.36 How many bytes of N digits exist with more zeroes than ones?
Exercise 1.37 There are 40 cabinet ministers sitting around a circular table. One
seat is reserved for the Prime Minister. In how many ways can the other ministers
seat themselves?
Exercise 1.38 Thirty people meet after a long time and they all shake hands. How
many handshakes are there?
Exercise 1.39 Find the number of solutions to equation x + y + z + w = 15:
(i) in the set of non-negative integers;
(ii) in the set of positive integers;
(iii) in the set of integers such that x > 2, y > âˆ’2, z > 0, w > 3.
Exercise 1.40 Find the number of non-negative integer solutions (x, y, z, t) of
x + y + z + t â‰¤6.

2
Probability measures
The correspondence between Blaise Pascal (1623â€“1662) and Pierre de Fermat
(1601â€“1665) on some matters related to card games suggested by the nobleman
and gambler Chevalier de MÂ´erÂ´e is considered to be the birth of probability. The
ï¬rst treatise, De Ratiociniis in ludo aleae, by Christiaan Huygens (1629â€“1695)
was published in 1647. Other publications followed in the eighteenth century: at
the beginning of the century, the Ars conjectandi by Jacob Bernoulli (1654â€“1705)
and the Doctrine of Chances by Abraham de Moivre (1667â€“1754) were published
in 1713 and 1718, respectively. Then the ThÂ´eorie analytique des probabilitÂ´es by
Pierre-Simon Laplace (1749â€“1827), which appeared in 1812, summarized the
knowledge on probability of the whole century.
The deï¬nition of probability given by Pascal for games of chance is the so-
called classical interpretation: the probability of an event E is the ratio between
the number of successes (the cases in which the event E happens) and the number
of all possible cases:
P(E) := favourable cases
possible cases .
(2.1)
Clearly, the deï¬nition can be criticized: it cannot deï¬ne the probability of those
events for which we do not know a priori the number of successes and it does
not make sense when there are an inï¬nite number of possible cases. Generally
speaking, the deï¬nition does not apply to a multitude of cases which we would
like to speak of in probability terms.
Another deï¬nition, given by Richard von Mises (1883â€“1953), is the frequen-
tist interpretation: the probability of an event is the limit of the frequencies of
successes as the number of trials goes to inï¬nity:
P(E) = lim
nâ†’âˆ
favourable cases among n trials
n
(2.2)
A First Course in Probability and Markov Chains, First Edition. Giuseppe Modica and Laura Poggiolini.
Â© 2013 John Wiley & Sons, Ltd. Published 2013 by John Wiley & Sons, Ltd.

28
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
This deï¬nition can also be easily criticized: how can the limit of a sequence be
computed if the sequence itself is not known? Moreover, the limit may not exist
and in many situations, such as in economics, experiments cannot be repeated.
A further deï¬nition, ï¬rst given by Jacob Bernoulli (1654â€“1705), is the sub-
jectivist interpretation: the probability of an event E is a number p = P(E) that
measures the degree of belief that E may happen, expressed by a coherent indi-
vidual. The â€˜coherenceâ€™ is expressed by the fact that if the individual measures
as p âˆˆ[0, 1] the degree of belief that E happens, then 1 âˆ’p is the degree of
belief that E does not happen.
Another way to describe the subjectivist interpretation is the bet that an indi-
vidual, according to the information in his possession, regards as a fair cost to pay
(to get paid) in order to get (pay) one if the event E happens and in order to get
(pay) nothing if E does not happen. The coherence is in a fair evaluation of the
probability that E happens: the individual may be either the gambler or the book-
maker but the evaluation remains the same. The following example is from [1].
Example 2.1 Betting on horse racing helps to illustrate the subjectivist point of
view. In ï¬xed-odds betting the bookmaker decides a different bet for each horse.
The gambler, if he or she wins, receives the amount a(1 + q) where a is the
money bet and q is the bet. In other words, the gambler pays a to win a(1 + q)
if the horse bet on wins the race and pays a to get no money if the horse bet on
does not win the race.
Let p be the probability that the horse wins the race. Then the ratio between
a and a(1 + q) must be equal to the ratio between p and 1, i.e. p = 1/(1 + q)
or q = 1
p âˆ’1. The game is fair if the sum of the probabilities of all horses in
the race is 1. UNIRE, the public corporation that regulates Italian horse racing,
has ï¬xed an upper bound on the bookmakers bets in order to protect gamblers:
the betting is fair if the sum of the probabilities of the horses is not greater than
1.6, 
i pi â‰¤1.6.
2.1
Elementary probability
In the classic deï¬nition by Pascal, the probability of an event is the ratio between
favourables cases (successes) and possible ones. Let  be the set of all possible
cases and let A âŠ‚ be the subset of favourable cases, then
P(A) = |A|
||
âˆ€A âŠ‚.
Calculus of probabilities thus boils down to a counting problem. In mathematics
nowadays, this probability is known as the uniform distribution on a ï¬nite set.
Example 2.2 In ï¬‚ipping a coin, the possible results are â€˜headsâ€™ or â€˜tailsâ€™. The
set of all possible cases is  = {H, T }. For a fair coin, one has P({T }) =
P({H}) = 0.5, i.e. the uniform probability on a set of two elements.

PROBABILITY MEASURES
29
Example 2.3 When throwing a dice, the possible results are the six faces of the
dice. The set of possible cases is  = {1, 2, 3, 4, 5, 6}. If the dice is fair, then all
the possible results have the same probability 1/6, i.e. the uniform probability
on a set of 6 elements.
Example 2.4 When throwing two dice, the possible results are the couples (i, j),
i, j = 1, . . . , 6, where the ï¬rst and the second components are the result of the
ï¬rst and second dice, respectively. In other words, the set of possible cases is
 := {1, 2, 3, 4, 5, 6}2. If the dice are fair and do not interfere with each other,
then each couple has the same probability, i.e. we have the uniform probability
on a set of 36 elements. For instance, the probability to obtain two sixes or to
obtain (4, 6), that is, 4 on the ï¬rst dice and 6 on the second dice or, to obtain
(6, 4), i.e. 6 on the ï¬rst dice and 4 on the second dice are equal to 1/(36). Notice
that in dice games the outcomes are not ordered, thus the probability to obtain
six on both dices is 1/(36) while the probability of obtaining one 4 and one 6,
i.e. either (4, 6) or (6, 4), is 1/(18).
Example 2.5 Draw a number among ninety available ones. The set of possible
cases is  = {1, 2, . . . , 90}. In a lottery game ï¬ve different numbers are drawn;
the order of the drawing is not taken into account. If the drawing is fair, each
subset of 5 elements of  has the same probability. The set of possible cases is
the family of all the subsets of  with 5 elements, and the probability of each
element of the family is 1/
90
5

.
Example 2.6 We draw 5 numbers among a set of 90 different ones. The order of
the drawing is taken into account, so that the possible cases are all the ordered
lists of ï¬ve pairwise different integers in 1, 2, . . . , 90. Thus the possible cases
are 5!
90
5

= 90!
85!. If the drawing is fair, then any drawn list has the same proba-
bility p = 1/(5!
90
5

) â‰ƒ1.9 Â· 10âˆ’10.
2.1.1
Exercises
Exercise 2.7 In a group of n people, each person writes his or her name on a
card and drops the card in a common urn. Later each person gets one card from
the urn. Compute the probability that one (and only one) person in the group gets
the card with his or her own name. Compute the probability that no one in the
group gets the card with his or her own name.
Exercise 2.8 Five balls are drawn from an urn containing 90 balls labelled from
1 to 90. A player can play each of the following gambles:
â€¢ He or she tries to guess three of the ï¬ve drawn balls.
â€¢ He or she tries to guess four of the ï¬ve drawn balls.
â€¢ He or she tries to guess all ï¬ve drawn balls.
Compute the probability of winning in each of the cases above.

30
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Exercise 2.9 k items of a stock of N objects are subject to testing. If only one item
of the stock is defective, compute the probability that the test detects that item. If
two items are defective, compute the probability that the test identiï¬es at least one
of them and both of them.
Exercise 2.10 (Birthday paradox) A group of n people meets at a party,
n â‰¤365. Assuming that all the years are 365 days long (i.e. 29th February does
not exist) and that childbirth is equiprobable on each day of the year, compute
the probability that the n people at the party are born on n different days of the
year.
Solution. We label the people of the party from 1 to n and compute the number
of favourable cases. Person â€˜1â€™ can be born on any day of the year, person â€˜2â€™ can
be born on any of the other 364 days of the year, person â€˜3â€™ can be born on any of
the other 363 days of the year and so on. Thus the favourable cases are as
many as the collocations of n pairwise distinct objects in 365 pairwise different
boxes with at most one object per box, i.e.
365!
(365 âˆ’n)!.
Let us now compute the number of possible cases. Each person can be born
on any of the 365 days of the year, i.e. the possible cases are as many as the
collocations of n pairwise objects in 365 pairwise different boxes with no further
constraint, i.e. there are 365n possible cases. Thus the probability that the n
people at the party are born on n different days of the year is
365!
365n (365 âˆ’n)!.
We leave it to the reader to prove that the map
p : n âˆˆ{1, . . . , 365} â†’
365!
365n (365 âˆ’n)! âˆˆR
is strictly monotone decreasing, that p(n) â‰¥0.5 if and only if n â‰¤22 and
p(n) â‰¥0.1 if and only if n â‰¤40. In particular, 1 âˆ’p(n) â‰¥0.5 if n â‰¥23 and
1 âˆ’p(n) â‰¥0.9 if n â‰¥41: in words, if at least 23 people are at the party, then
the probability that at least two of them are born on the same day of the year is
greater than 0.5, while if there are at least 41 people, then the probability that
at least two of them are born on the same day of the year is greater than 0.9.
Exercise 2.11 An urn contains n balls labelled 1, 2, . . . , n; another urn contains
k balls labelled 1, 2, . . . , k. Assume k â‰¥n and draw randomly a ball from each
urn. Compute the following:
â€¢ The probability that the two balls are labelled with the same number.
â€¢ The probability that the two balls are labelled with an even number.
Solution. The set of possible cases is
 := {(a, b) | a âˆˆ{1, . . . , n}, b âˆˆ{1, . . . , k}} .

PROBABILITY MEASURES
31
Clearly the cardinality of  is || = kn. In the ï¬rst case, the set of successes is
A = {(a, a) | a âˆˆ{1, . . . , n}}
with cardinality |A| = min(k, n) = n. Thus P(A) = |A|
|| = 1
k .
In the second case the set of successes is
B =

(2i, 2j)
 i âˆˆ

1, . . . ,
 n
2
!
, j âˆˆ

1, . . . ,
"k
2
#$$
with cardinality |B| =
 n
2
!"k
2
#
so that P(B) = |B|
|| =
 n
2
!"k
2
#
kn
.
Exercise 2.12 An urn contains n balls labelled 1, 2, . . . , n. We randomly draw
two balls. Compute the probability that both balls are labelled with even numbers.
Solution. We are now drawing two balls from the same urn, thus the set 
of all possible cases is the family of the subset of {1, 2, . . . , 20} having exactly
two elements. Thus,
|| =
n
2

= n(n âˆ’1)
2
.
Since the balls are randomly drawn, we are dealing with the uniform probability
over a ï¬nite set. The set of favourable cases A is the family of all subsets of

2j | 1 â‰¤j â‰¤
 n
2

having two elements. Thus,
|A| =
 n
2

2

and
P(A) = |A|
|| =
âŒŠn
2âŒ‹
2

n
2
 .
Exercise 2.13 An urn contains 20 white balls, 30 red balls, 10 green balls and
40 black balls. Ten balls are randomly drawn. In each of the following cases
compute the probability of drawing 2 white balls, 3 red balls, 1 green ball and 4
black balls:
â€¢ The balls are pairwise distinguishable, i.e. they are labelled 1, 2, . . . , 100.
â€¢ The balls can be distinguished only by their colour.
Solution. In the ï¬rst case we draw 10 balls from an urn containing 100 balls
labelled 1, 2, . . . , 100. Thus the set  of all possible events is the family of all
the subsets of {1, . . . , 100} having cardinality 10, i.e.
|| =
100
10

.

32
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
We can assume that the white balls are labelled 1, 2, . . . , 20, the red balls
21, . . . , 50, the green balls 51, . . . , 60 and the black ones 61, . . . , 100.
The set A of successes is the Cartesian product of the following events:
â€¢ the set of all the subsets of {1, . . . , 20} made by 2 elements;
â€¢ the set of all the subsets of {21, . . . , 50} made by 3 elements;
â€¢ the singletons in {51, . . . , 60};
â€¢ the set of all the subsets of {61, . . . , 100} made by 4 elements.
Thus
|A| = C20
2 C30
3 C10
1 C40
4 =
20
2
30
3
10
1
40
4

and
P(A) =
20
2
30
3
10
1
40
4

100
10

â‰ƒ0.407
When the balls can be distinguished only by their colour, we draw 10 balls
from a population of 4 different objects, where each object has multiplicity greater
than or equal to 10; thus we are playing a simultaneous drawing from a multiset,
so the number of possible drawings is
4 + 10 âˆ’1
10

=
13
10

= 246.
Moreover, there is only one way to draw 2 white balls, 3 red balls, 1 green ball
and 4 black ones, i.e. there is only one favourable case. Thus the probability of
success is
P(A) =
1
13
10
 =
1
246 â‰ƒ0.004.
Exercise 2.14 An urn contains 5 white balls, 8 red balls and 7 black balls, labelled
1, 2, . . . , 20. Two balls are drawn without replacement. Compute the probability
that two balls are painted the same colour.
[â‰ƒ0.31]
Exercise 2.15 An urn contains 6 white balls, 5 red balls and 9 black balls,
labelled 1, 2, . . . , 20. Three balls are drawn without replacement. Compute the
probability that the three drawn balls are three different colours.
%
9/38 â‰ƒ0.24
&
Exercise 2.16 We are given two urns. The ï¬rst urn contains 6 white balls and
4 red ones. The second urn contains 4 white balls and 6 red ones. The balls are
pairwise distinguishable. A ball is randomly drawn from each urn. Compute the
probability that the two balls are the same colour.
[0.48]

PROBABILITY MEASURES
33
Exercise 2.17 Let A be a ï¬nite set, |A| = k. Compute the average cardinality of
its subsets.
Solution. By deï¬nition the average cardinality of the subsets of A is
1
|P(A)|

SâŠ‚P(A)
|S|.
For any j âˆˆ{0, 1, . . . , k}, there are
k
j

subsets with j elements. Thus
1
|P(A)|

SâŠ‚P(A)
|S| = 1
2k
k

j=0
j
k
j

= 1
2k
k

j=1
k
k âˆ’1
j âˆ’1

= k2kâˆ’1
2k
= k
2.
Exercise 2.18 Compute the average number of ï¬xed points in the set of permuta-
tions of n elements. The average number of ï¬xed points is the ratio between the
total number of ï¬xed points in all the permutations and the number of permuta-
tions.
Solution. For each interger j = 0, . . . , n, there are
n
j

dnâˆ’j permutations with
j ï¬xed points, see the proof of Proposition 1.10; thus the average number of
ï¬xed points is
1
n!
n

j=0
j
n
j

dnâˆ’j.
This ratio can be computed explicitly. We have
1
n!
n

j=0
j
n
j

dnâˆ’j = 1
n!n
n

j=1
n âˆ’1
j âˆ’1

dnâˆ’j = 1
n!n
n

j=1
n âˆ’1
n âˆ’j

dnâˆ’j
=
1
(n âˆ’1)!
nâˆ’1

j=0
n âˆ’1
j

dj = (n âˆ’1)!
(n âˆ’1)! = 1,
see (1.3). Thus the average number of ï¬xed points is 1.
2.2
Basic facts
Independently of the interpretationâ€“and the subjective interpretation is the most
ï¬‚exible oneâ€“one gets to an axiomatic deï¬nition of probability, which is due
to Andrey Kolmogorov (1903â€“1987) and is based on the deï¬nition of abstract
measure. In this setting, the choice of the set of possible cases, the set family
of possible events and the probability itself are not speciï¬ed. The choice will
be made from time to time on the basis of statistical considerations and model
theory. For our purposes, the choice is basically irrelevant: in this volume we
deal with the computation of the probability of events deï¬ned by means of other
events whose probability is already known.

34
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
2.2.1
Events
Intuitively, an event is a mathematical proposition to which we assign a number
in [0,1] which is called the probability of the event. In order to make negations
meaningful and to avoid paradoxes, one should consider only predicates, i.e.
mathematical propositions indexed by the elements of a given set . This way,
each predicate deï¬nes a subset
E =

x âˆˆ
 p(x) is true

,
and two predicates are equivalent if they deï¬ne the same subset of . For the
sake of clarity, it is better to call an event a subset of  instead of the different
equivalent predicates that deï¬ne it.
Logical connectives are thus â€˜translatedâ€™ into operators between sets: unions,
intersections, subsets and complementary sets. In fact, if p and q are two predi-
cates on  and
A =

x âˆˆ
 p(x) is true

B =

x âˆˆ
 q(x) is true

then
A âˆªB =

x âˆˆ
 p(x) or q(x) is true

A âˆ©B =

x âˆˆ
 both p(x) and q(x) are true

Ac =

x âˆˆ
 p(x) is false

A âŠ‚B
if and only if
p(x) â‡’q(x)
âˆ€x âˆˆ.
Propositional logic suggests that the set of events E has the following prop-
erties:
(i) âˆ…âˆˆE.
(ii) If A âˆˆE, then Ac :=  \ A âˆˆE.
(iii) If A and B âˆˆE, then A âˆªB âˆˆE and A âˆ©B âˆˆE.
So that, by induction:
(iv) If A1, . . . , An âˆˆE, then âˆªn
i=1Ai âˆˆE and âˆ©n
i=1Ai âˆˆE.
Notice that by (i) and (ii),  âˆˆE and that, by (iv), if A, B âˆˆE then A \ B and
B \ A âˆˆE.
The event âˆ…(characterized by x âˆˆâˆ…is always false) is called the impossible
event while the event  (x âˆˆ is always true) is called the certain event. The
event Ac :=  \ A is called the complementary event of A. Finally, two events
A, B âˆˆE are said to be incompatible if A âˆ©B = âˆ…, i.e. if and only if A âŠ‚Bc.

PROBABILITY MEASURES
35
Beware, one should resist the temptation to think that every subset of  is an
event, i.e. that the set of all events E is the set of all subsets of . Although this
is possible, and preferable, if  is ï¬nite or denumerable, it leads to contradictions
if  is not denumerable, see Section 2.2.7; for the moment, let us think of E as
a possible proper class of subsets of  with the properties (i)â€“(iv) above.
A family E of events of  satisfying properties (i), (ii) and (iii) above is
called an algebra of subsets of .
When the family of events E is inï¬nite, we require a stronger property for the
family E: the family of events E is closed with respect to denumerable unions
and intersections, i.e.
(v) For any sequence

Ai

âŠ‚E we have âˆªâˆ
i=1Ai âˆˆE and âˆ©âˆ
i=1Ai âˆˆE.
This property will bring many further properties that will be shown later.
Clearly this property boils down to (iii) when E is a ï¬nite family. Moreover, by
De Moivre formulas it can be also simpliï¬ed to:
(vi) If (ii) holds, then for any sequence

Ai

âŠ‚E either âˆªâˆ
i=1Ai âˆˆE or
âˆ©âˆ
i=1Ai âˆˆE.
We summarize the previous requests in a formal deï¬nition.
Deï¬nition 2.19 Let  be a nonempty set and let P() be the family of all subsets
of .
â€¢ An algebra of subsets of  is a family E âŠ‚P() such that:
(i) âˆ…âˆˆE.
(ii) If A âˆˆE, then Ac :=  \ A âˆˆE.
(iii) If A, B âˆˆE, then A âˆªB âˆˆE.
â€¢ A Ïƒ-algebra of subsets of  is a family E âŠ‚P() such that:
(i) âˆ…âˆˆE.
(ii) If A âˆˆE, then Ac :=  \ A âˆˆE.
(iii) For any sequence

Ai

âŠ‚E we have âˆªâˆ
i=1Ai âˆˆE.
Notice that if D âŠ‚P() is a family of subsets of , then the family
S :=
' 
E
 E is a Ïƒ-algebra, E âŠƒD

is a well deï¬ned family of subsets of . It is easy to show that S itself is
a Ïƒ-algebra, and is in fact the smallest Ïƒ-algebra that includes D. S is called
the Ïƒ-algebra generated by D.
Example 2.20 Let  := {1, 2, 3, 4, 5}. Let us describe the algebra E generated
by the subsets E1 = {1, 2} and E2 = {2, 3} of .

36
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Clearly, E1, E2, âˆ…and  âˆˆE. Moreover E contains the sets Ec
1 := {3, 4, 5}
and Ec
2 = {1, 4, 5} and their intersections E1 âˆ©Ec
2, E2 âˆ©Ec
1. Thus
{1},
{2},
{3},
{4, 5} âˆˆE.
The singletons {4} and {5} are not in E. The ï¬nite unions of the above sets
must be in E, so that |E| = 24 = 16. More precisely, the subsets of  that are
in E are:
âˆ…,
{1, 2, 3, 4, 5}
{1},
{2},
{3},
{4, 5}
{1, 2},
{1, 3},
{1, 4, 5},
{2, 3},
{2, 4, 5},
{3, 4, 5},
{1, 2, 3},
{1, 2, 4, 5},
{1, 3, 4, 5},
{2, 3, 4, 5}.
Deï¬nition 2.21 We denote by B(Rn) the smallest Ïƒ-algebra of subsets of Rn that
contains all the open sets of Rn. The subsets E âˆˆB(Rn) are called Borel sets of
Rn and B(Rn) is called the Borel Ïƒ-algebra of Rn.
In what follows the Ïƒ-algebra B(Rn) will play an inportant role.
2.2.2
Probability measures
Let  be the certain event and let E âŠ‚P() be a Ïƒ-algebra. We â€˜measureâ€™ the
probability of an event E âˆˆE by a real number P(E) âˆˆ[0, 1]; in particular, we
assign probability 0 to the impossible event and probability 1 to the certain event
. The subjective interpretation of probability suggests that the map P : E â†’R
has the following properties:
â€¢ If A âŠ‚B, then P(A) â‰¤P(B).
â€¢ P(Ac) = 1 âˆ’P(A).
â€¢ If A, B are incompatible, A âˆ©B = âˆ…, then P(A âˆªB) = P(A) + P(B).
Deï¬nition 2.22 Let  be a nonempty set. A non-negative measure on  is a
couple (E, P) where E âŠ‚P() is a Ïƒ-algebra of subsets of , called the family
of measurable sets and P : E â†’R+ is a map with the following properties:
(i) P(âˆ…) = 0.
(ii) (Monotonicity) If A, B âˆˆE and A âŠ‚B, then P(A) â‰¤P(B).
(iii) (Ïƒ-additivity) For any disjoint sequence

Ai

âŠ‚E we have
P
 âˆ
(
i=1
Ai

=
âˆ

i=1
P(Ai).

PROBABILITY MEASURES
37
If, moreover, P() = 1, we say that the non-negative measure (E, P) is a
probability measure on . In this case E is called a family of events and the
triplet (, E, P) is called a probability space.
Remark 2.23 Notice the following:
â€¢ If E is ï¬nite, then (iii) boils down to ï¬nite additivity for incompatible
events.
â€¢ If E is inï¬nite, then the sum on the right-hand side is to be understood as
a series with non-negative addenda. Ïƒ-additivity is crucial and is natural
in a large number of situations.
â€¢ For a non-negative measure (E, Î¼) we may have Î¼() = +âˆ.
Deï¬nition 2.24 Let (, E, P) be a probability space. An event A âˆˆE such that
P(A) = 0 is said to be almost impossible, an event A âˆˆE such that P(A) = 1 is
almost sure. If A is a singleton, then A is called an atomic event.
Let (E, P) be a measure on a set . We say that N âŠ‚ is P-negligible, or
simply a null set, if there exists E âˆˆE such that N âŠ‚E and P(E) = 0. Let )E be
the collection of all the subsets of  of the form F = E âˆªN where E âˆˆE and
N is P-negligible. It is easy to check that )E is a Ïƒ-algebra which is called the
P-completion of E. Moreover, setting P(F) := P(E) if F = E âˆªN âˆˆ)E, then
()E, P) is again a measure on  called the P-completion of (E, P). It is customary
to consider measures as P-complete measures.
2.2.3
Continuity of measures
The following proposition collects some properties that easily follow from Deï¬-
nition 2.22.
Proposition 2.25 Let (, E, P) be a probability space.
(i) If A âˆˆE, then 0 â‰¤P(A) â‰¤P() = 1.
(ii) If A, B âˆˆE and A âŠ‚B, then P(B \ A) = P(B) âˆ’P(A).
(iii) If A, B âˆˆE, then P(A âˆªB) + P(A âˆ©B) = P(A) + P(B).
(iv) If A, B âˆˆE, then P(A âˆªB) â‰¤P(A) + P(B).
(v) (Ïƒ-subadditivity) For any sequence

Ai

âŠ‚E we have
P
 âˆ
(
i=1
Ai

â‰¤
âˆ

i=1
P(Ai).
(2.3)
Another easy consequence of Deï¬nition 2.22 is the law of total probability.

38
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Proposition 2.26 (Law of total probability) Let (, E, P) be a probability space
and let

Di

i âŠ‚E be a ï¬nite or denumerable partition of , i.e.  = âˆªâˆ
i=1Di and
Di âˆ©Dj = âˆ…âˆ€i, j, i Ì¸= j. Then
P(A) =
âˆ

i=1
P(A âˆ©Di)
âˆ€A âˆˆE.
(2.4)
We ï¬nally point out the following important continuity property of probability
measures.
Proposition 2.27 (Continuity) Let (, E, P) be a probability space and let

Ei

âŠ‚E be a denumerable family of events.
(i) If Ei âŠ‚Ei+1 âˆ€i, then âˆªâˆ
i=1Ei âˆˆE and
P
 âˆ
(
i=1
Ei

= lim
iâ†’+âˆP(Ei).
(2.5)
(ii) If Ei âŠƒEi+1 âˆ€i, then âˆ©âˆ
i=1Ei âˆˆE and
P
 âˆ
'
i=1
Ei) = lim
iâ†’+âˆP(Ei).
(2.6)
Proof. We prove (i). Write E := âˆªâˆ
k=1Ek as
E = E1
(  âˆ
(
k=2
(Ek \ Ekâˆ’1)

.
The sets E1 and Ek \ Ekâˆ’1, k â‰¥2, are pairwise disjoint events of E. By the
Ïƒ-additivity property of measures, we get
P(E) = P(E1) +
âˆ

k=2
P(Ek \ Ekâˆ’1)
= P(E1) +
âˆ

k=2
(P(Ek) âˆ’P(Ekâˆ’1)) = lim
kâ†’âˆP(Ek).
In order to prove (ii) we point out that from P(E1) < +âˆand Ek âŠ‚E1 âˆ€k â‰¥2,
we get P(E1) âˆ’P(Ek) = P(E1 \ Ek) for any k â‰¥2. Moreover, the sets E1 \ Ek
are an increasing sequence of events of . Thus, applying (i) to the family of
events

E1 \ Ek

one gets
P(E1) âˆ’lim
kâ†’âˆP(Ek) = lim
kâ†’âˆP(E1 \ Ek)
= P
 (
k
(E1 \ Ek)

= P(E1) âˆ’P
 âˆ
'
k=2
Ek

.

PROBABILITY MEASURES
39
2.2.4
Integral with respect to a measure
Given a measure (E, P) on a nonempty set , one deï¬nes an integral with respect
to such measure,
*

f (x) P(dx)
whenever f is in an appropriate class of functions, called random variables, see
Section 3.1. Here we deï¬ne only the integral of functions f :  â†’R that have
a ï¬nite range. For the characteristic function 1E
1E(x) =

1
if x âˆˆE,
0
if x /âˆˆE
of E âˆˆE, set
*

1E(x) P(dx) := P(E).
A simple function is a linear combination of characteristic functions of pairwise
disjoint events

Ei

. The integral of a simple function Ï•(x) = n
i=1 ci1Ei(x),
x âˆˆ, is then deï¬ned by
*

Ï•(x) P(dx) :=
n

i=1
ciP(Ei).
Integration is a linear operator on the family of simple functions. In fact, the
following holds.
Proposition 2.28 Let Ï• and Ïˆ be simple functions, and let a, b âˆˆR. Then aÏ•(x) +
bÏˆ(x) is a simple function and
*

(aÏ•(x) + bÏˆ(x)) P(dx) = a
*

Ï•(x) P(dx) + b
*

Ïˆ(x) P(dx).
Proof. Let Ï•(x) = n
i=1 ci1Ei(x) and Ïˆ(x) = m
j=1 dj1Fj (x) where the sets

Ei

are pairwise disjoint and so are the sets

Fj

. Without any loss of generality,
we can assume that both the families

Ei

and

Fj

are ï¬nite partitions of .
Then

Ei âˆ©Fj

is a ï¬nite partition of  and
aÏ•(x) + bÏˆ(x) = aci + bdj
if x âˆˆEi âˆ©Fj.
Thus aÏ• + bÏˆ is a simple function and by the deï¬nition of integral
*

(aÏ•(x) + bÏˆ(x)) P(dx) =

i=1,n
j=1,m
(aci + bdj)P(Ei âˆ©Fj)

40
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
=
n

i=1
aci
m

j=1
P(Ei âˆ©Fj) +
m

j=1
bdj
n

i=1
P(Ei âˆ©Fj)
= a
n

i=1
ciP(Ei) + b
m

j=1
djP(Fj)
= a
*

Ï•(x) P(dx) + b
*

Ïˆ(x) P(dx).
A function Ï• having a ï¬nite range, Ï•(x) = n
i=1 ai1Ai(x), where the events

Ai

are not necessarily disjoint, is a linear combination of simple functions.
Proposition 2.28 then yields
*

Ï•(x) P(dx) =
n

i=1
ai
*

1Ai(x) P(dx) =
n

i=1
aiP(Ai),
(2.7)
as for simple functions.
2.2.5
Probabilities on ï¬nite and denumerable sets
2.2.5.1
Probabilities on ï¬nite sets
In Example 2.20 the certain event is  = {1, 2, 3, 4, 5} and the Ïƒ-algebra E
generated by the sets E1 = {1, 2}, E2 = {2, 3} is given by all the ï¬nite unions
of
{1},
{2},
{3},
{4, 5}.
In particular, the singletons {4} and {5} are not events. Thus, if (E, P) is a
probability measure on , then P({4}) and P({5}) are not deï¬ned. If one is
willing to deï¬ne the probability on any subset of , then one of the two following
procedures may be followed:
(i) Deï¬ne P({4}) and P({5}) so that P({4}) + P({5}) = P({4, 5}). Obviously
there are inï¬nitely many ways to do that.
(ii) Make  â€˜smallerâ€™ so that the events by which the Ïƒ-algebra can be gen-
erated by unions only are atomic. In the example we are considering, one
identiï¬es 4 and 5 by setting {A} = {4, 5} and chooses  = {1, 2, 3, A}.
Thus, if  is a ï¬nite set, by applying one of the previous procedures, one
may always assume that all the subsets of  are events, E = P(), so that P(A)
is deï¬ned for all A âŠ‚. In what follows, we always assume that E = P() if
 is ï¬nite, without explicitly stating it.
In particular, assuming  =

x1, . . . , xn

, each singleton

xk

is an atomic
event, with its own probability pk := P(

xk

). We call pk the density of P at xk

PROBABILITY MEASURES
41
and the vector p := (p1, . . . , pn) the mass density of P. Clearly,
pk â‰¥0 âˆ€k,
n

k=1
pk = 1
and for any subset A âŠ‚,
P(A) =

xkâˆˆA
P(

xk

) =

xkâˆˆA
pk.
2.2.5.2
Uniform probability
Let  be a ï¬nite set. If all the atomic events have the same probability, P({x}) =
p âˆ€x âˆˆ, then, by the additivity property, one gets,
1 = P() =

xâˆˆ
p = p ||
i.e.
p =
1
||.
Thus, for any set A âŠ‚, we may compute
P(A) = p |A| = |A|
||.
This case is called uniform probability on a ï¬nite set and the probability of
the event A coincides with the classical interpretation of probability: the ratio
between the number of favourable events and the number of possible events. Thus
the computation of the probability of an event implies only two counting opera-
tions, see Chapter 1.
Given a ï¬nite set , the everyday-language phrase â€˜choose x âˆˆ randomlyâ€™
will here be interpreted as: consider  as equipped with the uniform probability,
i.e. P({x}) :=
1
|| âˆ€x âˆˆ.
2.2.5.3
Finite Bernoulli process
Assume you perform an experiment which has only two possible results: success,
with probability p, 0 â‰¤p â‰¤1, or failure with probability q, q = 1 âˆ’p. This is
called a Bernoulli trial of parameter p. Thus the certain event has only two
elements:  = {0, 1}, where 0 is for failure and 1 is for success. The mass
density vector is (q, p).
We then perform the same experiment N times, and assume that each trial
does not interfere with the results of the other trials. This procedure is called a
ï¬nite Bernoulli process. The result of the repeated experiment is a N-tuple of
zeroes and ones, where the kth component is 1 if and only if we get a success at
the kth trial. Thus the certain event is  = {0, 1}N, the set of all binary N-tuples,
which is a ï¬nite set with 2N elements. The probability pv of a given sequence of
results v = (v1, . . . , vN) âˆˆ{0, 1}N depends only on the number of successes (or

42
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
failures) that are in it: if k components of v are equal to 1 and N âˆ’k components
of v are equal to zero, then
pv = P({v}) := pkqNâˆ’k
The mass density vector p = (pv)vâˆˆ{0,1}N , which has 2N components, completely
describes a probability measure on  := {0, 1}N, called a Bernoulli distribution of
parameter p on {0, 1}N and denoted by (P({0, 1}N), Ber(N, p)). We then have
Ber(N, p)(A) :=

vâˆˆA
pv
âˆ€A âŠ‚{0, 1}N.
Observe that, in the case p = q = 1/2, then pv =
1
2N
âˆ€v âˆˆ{0, 1}N, i.e.
Ber(N, 1/2) is the uniform probability on the set {0, 1}N.
Various examples ï¬t in the ï¬nite Bernoulli process: the repeated ï¬‚ipping of
a coin, games where further matches are played, such as championships, random
walks, the behaviour (up and down) of the stock exchange, medical tests (positive
or negative) or even answers (yes or no) of a population of N individuals.
The meaning of the sentence â€˜the trials of the experiment do not interfere one
anotherâ€™ must be made precise, see Section 4.3.1, and is a crucial request which
must be accurately checked any time one wishes to apply the ï¬nite Bernoulli
process model and its distribution.
Example 2.29 Compute the probability of getting k successes in n trials in a
ï¬nite Bernoulli process.
Let p, 0 â‰¤p â‰¤1 be the probability of success in each trial. We want to
compute the probability of the event Ek âŠ‚{0, 1}n deï¬ned by
Ek :=

x âˆˆ{0, 1}n  exactly k components of x are equal to 1

The probability of each atomic event v âˆˆEk is P({v}) = Ber(n, p)({v}) =
pk(1 âˆ’p)nâˆ’k and the cardinality of Ek is
n
k

, hence
P(Ek) =

vâˆˆEk
P({v}) = pk(1 âˆ’p)nâˆ’k 
vâˆˆEk
1 =
n
k

pk(1 âˆ’p)nâˆ’k.
2.2.6
Probabilities on denumerable sets
Let  be a denumerable set. As in the ï¬nite case, one may always assume that
all the subsets of  are events, E = P(), so that P(A) is deï¬ned for all A âŠ‚.
This will be tacitly assumed if the certain event  is denumerable.
Assume  =

xk

. As in the ï¬nite case, each singleton

xk

is an atomic
event, with its own probability pk := P(

xk

). We call pk the density of P at xk

PROBABILITY MEASURES
43
and the sequence p :=

pk

the mass density of P. Clearly,
pk â‰¥0 âˆ€k,
âˆ

k=1
pk = 1
and for any subset A âŠ‚,
P(A) =

xkâˆˆA
P(

xk

) =

xkâˆˆA
pk.
A noticeable departure from the ï¬nite case is the following.
Proposition 2.30 If  is denumerable, then there exists no uniform probability
on .
Proof. Assume, by contradiction, that (P(), P) is a uniform probability
measure on , P({x}) = p âˆ€x âˆˆ. Then Ïƒ-additivity yields
1 = P() =

xâˆˆ
p = p|| =

+âˆ
if p > 0,
0
if p = 0,
a contradiction.
If one wants to deï¬ne some uniform â€˜probabilityâ€™ P, say, on N, then P cannot
be countably additive. It may be useful, anyhow, to have a uniform and ï¬nitely
additive â€˜probability measureâ€™ P : P(N) â†’R such that a non-negative integer
is even with probability 1/2, or is divisible by 3 with probability 1/3 and so on.
For any E âŠ‚N we may deï¬ne P(E) using the frequentist interpretation
P(E) := lim
nâ†’âˆ
P(E âˆ©{1, 2, . . . , n})
n
,
but the limit on the right-hand side may not exist. For instance, let
E := {1, 10, 11, 12, 100, . . . , 129, 1000, . . . , 1299, . . . }
It can be shown that the limit limn P(E âˆ©{1, . . . , n})/n does not exist.
Another possible deï¬nition of a ï¬nitely additive â€˜probabilityâ€™ on N is due to
Lejeune Dirichlet (1805â€“1859). For any Î± > 1, consider the probability measure
(P(N), PÎ±) (it is a true probability measure) whose mass density is pÎ±(n) :=
1
nÎ±
so that, for any E âŠ‚N one gets
PÎ±(E) =

nâˆˆE
1
nÎ±
+ âˆ

n=1
1
nÎ± .
Deï¬ne P(E) := lim supÎ±â†’1+ PÎ±(E). One can easily verify that
P({even numbers}) = 1/2.
More generally, we have the following.

44
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Proposition 2.31 If P(E âˆ©{1, . . . , n})/n â†’L as n â†’âˆ, then P(E) = L.
We omit the proof. The interested reader may refer to, e.g. [2].
2.2.7
Probabilities on uncountable sets
2.2.7.1
Uniform probability on an interval
Let  = [0, 1] âŠ‚R. One may think of doing an experiment whose result is a
random number x âˆˆ[0, 1], where each number has the same chance of being
the result to the experiment. In particular, we require any closed interval [a, b]
0 â‰¤a â‰¤b â‰¤1 to be an event whose probability equals its length, P([a, b]) =
b âˆ’a. Since the class of the events E must be a Ïƒ-algebra, choosing a = b, we get
{a} = âˆ©n[a, a + 1/n] âˆˆE and P({a}) â‰¤1/n âˆ€n, i.e. P({a}) = 0. Thus the family
of the events E contains the closed intervals, the singletons, hence the open and
the half-closed intervals; moreover, P(]a, b[) = P(]a, b]) = P([a, b[) = b âˆ’a.
Since any open set in R can be written as the union of a denumerable family
of open intervals, one gets that open and closed sets in [0,1] are events and so
is any countable union of countable instersections of closed and open sets and
so on. One wishes to choose E as the Ïƒ-algebra of all subsets of [0,1], but a
famous example by Giuseppe Vitali (1875â€“1932) shows that this is not possible:
one cannot deï¬ne a Ïƒ-additive function on P([0, 1]) which is consistent with the
elementary length for intervals.
It can be shown that one can choose as the family of events the Ïƒ-algebra
generated by the closed intervals, called the Ïƒ-algebra of Borel sets of [0,1].
In fact, it can be proven that the map P deï¬ned on the closed intervals of [0,1]
as P([a, b]) := b âˆ’a can be extented to a probability measure (B([0, 1]), P) and
that the extension is unique. The procedure above actually deï¬nes the Lebesgue
measure on [0,1] starting from the elementary measure of the intervals, see
Appendix B.
Notice that each singleton {a} is an event of zero probability. Thus, atomic
events do not provide any information on the probability of the uncountably
inï¬nite events. In other words, the probability measure cannot be described by
its mass density, which is identically zero.
2.2.7.2
Inï¬nite Bernoulli process
Even in problems related to counting, the certain event may not be countable. For
instance, we want to compute the time of the ï¬rst success in the iterated ï¬‚ipping
of a coin, i.e. the ï¬rst time we get a head. We assume that the trials do not interfere
with each other. In principle, we may get the ï¬rst head after an arbitrary number
of coin ï¬‚ips or we may even never get it. Thus we must consider an inï¬nite
number of coin ï¬‚ips or, more generally, a denumerable number of Bernoulli
trials that do not interfere with each other. The process of doing inï¬nitely many
Bernoulli trials of parameter p that do not interfere with each other is called an
inï¬nite Bernoulli process.

PROBABILITY MEASURES
45
Let 1 and 0 denote the success (head) or the failure (tail) in each trial. Then
the certain event  is the set of all sequences with values in {0, 1}
0, 0, . . . , 0, 1, . . . , 1, 0, 1, 0 . . . .
which we denote as  = {0, 1}âˆ. It is worth recalling that {0, 1}âˆis also the
set of all maps a : N â†’{0, 1}, or the set of all sequences of binary digits
00 . . . 01 . . . 1000 . . . ,
which form an uncountable set (one may prove this fact by means of the Cantor
diagonal process). To be more precise, the following holds.
Proposition 2.32 {0, 1}âˆhas the cardinality of the continuum, i.e. the same car-
dinality of R.
Proof. Consider the map T : {0, 1}âˆâ†’[0, 1] deï¬ned as
T (

an

) :=
âˆ

i=1
ai
2i .
(2.8)
Clearly, T :  â†’[0, 1] is surjective, since for any x âˆˆ[0, 1[, the binary sequence
of
x,
x = 0, a0a1a2 Â· Â· Â·
is
such
that
T (

an

) = x
and,
for

an

=
{1, 1, 1, 1, 1, . . . } we have T (

an

) = 1. Thus, the cardinality of {0, 1}âˆ
is greater than or equal to the cardinality of [0, 1], i.e. of the continuum.
T is not injective since there are binary sequences that give the same real
number (e.g. 0, 00001111111 Â· Â· Â· = 0, 00010000 . . . ). These sequences are con-
stant for large enough nâ€™s hence they form a denumerable set. Thus, {0, 1}âˆhas
the same cardinality of [0, 1], i.e. of the continuum.
We want to deï¬ne a probability measure on {0, 1}âˆrelated to the Bernoulli
distributions Ber(n, p) constructed by means of the ï¬nite Bernoulli process.
Intuitively, n-tuples of trials must be events. This cannot be imposed as it is
since n-tuples are not sequences, so we proceed as follows. To any binary n-tuple
a = (a1, . . . , an) and any set J = (j1, . . . , jn) of index there corresponds a set
of sequences of trials, the â€˜cylinderâ€™,
EJ,a :=

x âˆˆ{0, 1}âˆ xji = ai âˆ€i = 1, . . . , n

that is the set of all sequences of trials that at step jk have value ak. We require
that the sets EJ,a âŠ‚{0, 1}âˆare events, and that the probability of the cylinders
Ej,a in {0, 1}âˆis the same as the probability of the n-tuple a in the ï¬nite
Bernoulli process, i.e.
P(EJ,a) := Ber(n, p)({a}) = pkqnâˆ’k
if a contains k ones and n âˆ’k zeroes.

46
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Consider the Ïƒ-algebra E generated by the cylinders. It can be shown that the
map EJ,a â†’P(EJ,a) extends from the family of cylinders to E as a probability
measure (E, Ber(âˆ, p)) and that this extension is unique, see Appendix B.
(E, Ber(âˆ, p)) is the Bernoulli distribution of parameter p on the set of binary
sequences.
Notice that we are close to the construction of the Lebesgue measure on R.
In fact, if we â€˜identifyâ€™ real numbers in [0, 1] with their binary representation
through the map T in (2.8), then E agrees with the family of Borel sets B([0, 1])
and Ber(âˆ, 1/2) agrees with the Lebesgue measure L1 on the interval [0, 1].
For a precise statement, see Theorem 3.43.
Example 2.33 The probability of getting successes only in an inï¬nite Bernoulli
process of parameter p < 1 is zero.
Let v = (1, 1, . . . , ). We want to compute P({v}) := Ber(âˆ, p)({v}). Let
An =

x = (xi) âˆˆ{0, 1}âˆ| xi = 1 âˆ€i = 1, . . . , n

. Then
{v} =
âˆ
'
n=1
An
and
An âŠƒAn+1.
Thus {v}, being a countable intersection of events, is an event and P({v}) =
limnâ†’âˆP(An). Let p be the probability of success in each trial. If p = 1, then
P(An) = 1 âˆ€n so that P({v}) = 1. If p < 1, then P(An) = pn so that P({v}) = 0.
Proceeding as in Example 2.33, one can prove that any singleton {v} âˆˆ
{0, 1}âˆis an almost impossible event for the Bernoulli distribution (E,
Ber(âˆ, p)) of parameter p if 0 < p < 1, i.e. {v} âˆˆE and Ber(âˆ, p)({v}) = 0.
2.2.8
Exercises
Exercise 2.34 Show that B(R) is the smallest Ïƒ-algebra generated by one of the
following families of sets:
â€¢ the closed sets;
â€¢ the open intervals;
â€¢ the closed intervals;
â€¢ the intervals [a, b[, a, b âˆˆR, a < b;
â€¢ the intervals ]a, b], a, b âˆˆR, a < b;
â€¢ the closed half-lines ] âˆ’âˆ, t], t âˆˆR.
Solution. [Hint. Show that any open set can be written as the union of a
countable family of intervals.]

PROBABILITY MEASURES
47
Exercise 2.35 A multiple choice test comprises 10 questions. Each question has
four possible answers: one is right, three are wrong. To pass the test the candidate
must correctly answer at least eight questions. Compute the probability of passing
the test if the candidate answers each question randomly.
Solution. The test is a ï¬nite Bernoulli process of 10 Bernoulli trials, and the
probablity of success is p = 0.25 at each trial. Let Ek be the event â€˜the candidate
answers k questions correctlyâ€™. Then we want to compute the probability of
E =

x âˆˆ{0, 1}10  there are at least 8 successes

= E8 âˆªE9 âˆªE10.
Thus,
P(E) = P(E8) + P(E9) + P(E10) =
10

k=8
10
k

(.25)k(.75)10âˆ’k â‰ƒ0.0004.
Exercise 2.36 It is more probable to obtain a 6 by throwing a single dice 4 times
than obtaining a double 6 by throwing two dice 24 times. This is the remark
made by the nobleman and hard gambler Chevalier de MÂ´erÂ´e to Pascal Blaise
(1623â€“1662) around 1650. The following (wrong) consideration in a letter from
Pascal to Pierre de Fermat (1601â€“1665), dated 1654, seems to reject the empiric
remark of de MÂ´erÂ´e: the probability of obtaining a 6 when throwing a dice is 1/6;
the probability of getting a double 6 when throwing two dice is 1/36; since 4/6 =
24/36, the two events have the same probability. Find the mistake.
Solution. At each throw of a dice, the probability of failure is 5/6, so that the
probability of 4 failures in 4 throws is (5/6)4; hence the probability of at least 1
success in 4 throws is
1 âˆ’
5
6
4
â‰ƒ0.5177.
Similarly the probability of never getting a double 6 in 24 throws of two dice is
(35/36)24, so that the probability of getting at least a double 6 is
1 âˆ’
35
36
24
â‰ƒ0.4914,
which is less than the previous probability.
In general, the probability of at least one success in n trials is
1 âˆ’(1 âˆ’p)n,
not np, as Pascal thought. Notice that if p is small enough, then 1 âˆ’(1 âˆ’p)n
and np are quite close since 1 âˆ’(1 âˆ’p)n = np + O(p2) as p â†’0.
Exercise 2.37 Compute the probability of getting the ï¬rst success at the kth trial
of a Bernoulli processs of n trials, n â‰¥k â‰¥1.

48
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Solution. Let p be the probability of success in a single trial, 0 â‰¤p â‰¤1.
Clearly, it sufï¬ces to play k trials and compute the probability of the k-tuple
x = (0, 0, 0, . . . , 0, 1), i.e.
P({x}) = (1 âˆ’p)kâˆ’1p.
Exercise 2.38 Compute the probability of getting k failures before obtaining the
ï¬rst success in a Bernoulli process of trials.
Solution. Let p be the probability of success in a single trial, 0 â‰¤p â‰¤1.
It sufï¬ces to play k + 1 trials and compute the probability of the (k + 1)-tuple
x = (0, 0, 0, . . . , 0, 1). Therefore,
P({x}) = (1 âˆ’p)kp.
Exercise 2.39 Compute the probability of getting k failures before obtaining the
nth success in a Bernoulli process of trials.
Solution. Let p be the probability of success in a single trial, 0 â‰¤p â‰¤1. It
sufï¬ces to play n + k trials to get the answer. We want to compute the probability
of the event E containing all the sequences of {0, 1}n+k with k zeroes and n ones,
whose (n + k) component is one. Thus |E| =
n+kâˆ’1
k

, cf. Section 1.4.2, so that
P(E) =
n + k âˆ’1
k

(1 âˆ’p)kpn =
âˆ’n
k

pn(p âˆ’1)k.
Exercise 2.40 Two players A and B play a 7 rubber game. In each match A wins
with probability p and loses with probability 1 âˆ’p. Compute the following:
â€¢ The probability that the game ends after the fourth, the ï¬fth, the sixth or the
seventh match.
â€¢ The probability that A wins the game.
Exercise 2.41 (Rubber games) Two players A and B play a series of fair matches
until one of them wins s matches. After some time A has won a matches and B
has won b matches and a, b < s. Compute the probability that A wins the game.
Solution. A must obtain a further s âˆ’a successes before obtaining a further
s âˆ’b failures. Let E be this event. For any k = 0, 1, . . . , s âˆ’b âˆ’1, let Ek be the
event â€˜A obtains k failures before obtaining s âˆ’a successesâ€™. The events

Ek

are pairwise disjoint and E = E0 âˆªE1 âˆªE2 . . . Esâˆ’bâˆ’1. Thus,
P(E) =
sâˆ’bâˆ’1

k=0
P(Ek) =
sâˆ’bâˆ’1

k=0
s âˆ’a + k âˆ’1
k

(0.5)k(0.5)sâˆ’a.

PROBABILITY MEASURES
49
Exercise 2.42 (Production lines) In a production line, each produced item has
probability 0.03 of being faulty, independently of all the other produced items.
Compute the following:
â€¢ The probability that 3 items out of 100 are faulty.
â€¢ The probability that the quality control inspector ï¬nds the ï¬rst faulty item
when inspecting the 15th item.
â€¢ The probability that the quality control inspector ï¬nds 100 nonfaulty items
before ï¬nding the ï¬rst faulty one.
â€¢ The probability that the quality control inspector ï¬nds at least 5 faulty items
when checking a stock of 200 produced items.
â€¢ The probability that the quality control inspector ï¬nds exactly 5 faulty items
when checking a stock of 200 produced items.
Exercise 2.43 We repeatedly throw a fair dice and count how many times we
obtain a 6. What is the probability of having to throw the dice more than 8 times
before getting a 6?
Solution. We need to consider the inï¬nite Bernoulli process and the Bernoulli
distribution P of parameter p = 1/6. For any k let Ek be the event â€˜The ï¬rst
success is at the kth throwâ€™. The events Ek, k â‰¥0, are pairwise disjoint and
we need to compute the probability of E := âˆªâˆ
k=9Ek. Thus, by the Ïƒ-additivity
property, we get
P(E) =
âˆ

k=9
P(Ek) =
âˆ

k=9
p(1 âˆ’p)kâˆ’1 = p
âˆ

k=8
(1 âˆ’p)k
= p(1 âˆ’p)8
âˆ

k=0
(1 âˆ’p)k = p(1 âˆ’p)8
1
1 âˆ’(1 âˆ’p) = (1 âˆ’p)8.
Another procedure is the computation of the complementary event â€˜Either there
is a success during the ï¬rst 8 trials or there never is a successâ€™. The probability
of never obtaining a success is zero, see Example 2.33. Thus,
P(E) = 1 âˆ’P(Ec) = 1 âˆ’
8

k=1
P(Ek) = 1 âˆ’
7

k=0
p(1 âˆ’p)k
= 1 âˆ’p1 âˆ’(1 âˆ’p)8
1 âˆ’1 + p
= (1 âˆ’p)8.
Exercise 2.44 Compute the probability of having to throw a fair dice more than
50 times in order to obtain 6 eight times.

50
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Solution. We consider the inï¬nite Bernoulli process and the Bernoulli
distribution P of parameter p = 1/6. We must compute the probability of
having n = 8 successes, at least k = 51 âˆ’n = 43 failures and that the last trial
is a success. For any k let Ek be the event â€˜We obtain k failures before getting
8 successesâ€™. We want to compute the probability of the event E = âˆªâˆ
k=43Ek,
hence, see Exercise 2.39,
P(E) =
âˆ

k=43
8 + k âˆ’1
k

p8(1 âˆ’p)k = p8
âˆ

k=43
8 + k âˆ’1
k

(1 âˆ’p)k
Since
âˆ

k=0
8 + k âˆ’1
k

(1 âˆ’p)k =
âˆ

k=0
âˆ’8
k

(âˆ’(1 âˆ’p))k
= (1 âˆ’1 + p)âˆ’8 = pâˆ’8,
i.e.
p8
âˆ

k=0
8 + k âˆ’1
k

(1 âˆ’p)k = 1,
we ï¬nally get
P(E) = 1 âˆ’p8
42

k=0
8 + k âˆ’1
k

(1 âˆ’p)k.
Exercise 2.45 Two players A and B ï¬‚ip in turn a fair coin. Player A is the ï¬rst
to play. The winner is the one who obtains the ï¬rst head. What is the probability
of the event â€˜A wins the gameâ€™?
Solution. We consider the Bernoulli distribution of parameter p = 0.5. It is
evident that A has more chances than B of winning the game, in fact, the probabil-
ity of the event â€˜A wins the game at the ï¬rst ï¬‚ippingâ€™ is 1/2. Let Ek be the event
â€˜A wins the game at the kth ï¬‚ippingâ€™. Since A does only the odd ï¬‚ippings, then
k must be odd, k = 2h + 1. The probability of obtaining the ï¬rst success at the
(2h + 1)th trial is P(E2h+1) = (1 âˆ’p)2hp. Since the events

E2h+1

are pairwise
disjoint and the event â€˜Player A wins the gameâ€™ is E = âˆªhE2h+1, we obtain
P(E) =
âˆ

h=0
P(E2h+1) = p
âˆ

h=0
(1 âˆ’p)2h
= p
âˆ

h=0

(1 âˆ’p)2h
=
p
1 âˆ’(1 âˆ’p)2 =
1
2 âˆ’p.
Since p = 0.5, player A wins the game with probability 2/3. Notice that
1
2âˆ’p > 1
2 for any p, 0 < p < 1, so that, however unbalanced the coin is,
player A has always more chances than player B.

PROBABILITY MEASURES
51
2.3
Conditional probability
In this section we introduce the notion of conditional probability, a very useful
tool when we want to compute the probability that two or more events are veriï¬ed.
2.3.1
Deï¬nition
Deï¬nition 2.46 Let (, E, P) be a probability space and let A, B âˆˆE such
that P(B) > 0. The conditional probability of A given B, denoted by P(A | B)
is deï¬ned as
P(A|B) := P(A âˆ©B)
P(B)
.
(2.9)
P(A|B) is the probability of A when B is taken as the certain event. In fact, let
PB : A âˆˆE â†’P(A|B) âˆˆ[0, 1]. Then (E, PB) is a new measure on  such that
PB(B) = 1 and, more generally, PB(C) = 1 âˆ€C âˆˆE such that C âŠƒB.
Example 2.47 Throw a fair dice. The probability of the event A =â€˜we get 6â€™ is
1/6, the probability of the event B =â€˜we get an even numberâ€™ is 3/6 = 1/2 and
the probability of getting 6 knowing that we get an even number is
P(A|B) = P(A âˆ©B)
P(B)
= P(A)
P(B) = 1/6
1/2 = 1/3.
By deï¬nition P(A|B) can be used to compute P(A âˆ©B). In fact, formula
(2.9) rewrites as the multiplication formula
P(A âˆ©B) = P(A|B)P(B)
(2.10)
if P(B) > 0. If P(B) = 0, P(A|B) is not deï¬ned; to make (2.10) meaningful
also in the case P(B) = 0, one sets P(A|B)P(B) = 0 if P(B) = 0.
Let

Di

be a partition of . Then the total probability formula P(A) =
âˆ
i=1 P(A âˆ©Di) reads
P(A) =
âˆ

i=1
P(A | Di)P(Di).
(2.11)
Example 2.48 Two cards are picked from a deck of 40. Compute the probability
of picking two aces. We already know that the required probability is the ratio
between successful and possible cases, i.e.
4
2

/
40
2

=
1
130.
Another procedure is the following. Let A and B be the events â€˜The ï¬rst
picked card is an aceâ€™ and â€˜The second picked card is an aceâ€™, respectively. Then
we must compute P(A âˆ©B). Clearly, P(A) = 4/40 = 1/10 and the probability
of the second card being an ace, given that the ï¬rst card was an ace also, is 3/39.
Thus, by the multiplication formula,
P(A âˆ©B) = P(A|B)P(B) =
4 Â· 3
40 Â· 39 =
1
130.

52
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
We conclude observing that formula (2.10) can be iterated. For three events
A, B and C with P(B âˆ©C) > 0 we have
P(A âˆ©B âˆ©C) = P(A|B âˆ©C)P(B âˆ©C)
= P(A|B âˆ©C)P(B | C)P(C);
(2.12)
for a ï¬nite family

A1, A2, . . . , An

of events, such that P(A2 âˆ©Â· Â· Â· âˆ©An) > 0
one gets
P(A1 âˆ©A2 âˆ©Â· Â· Â· âˆ©An) =P(A1 | A2 âˆ©Â· Â· Â· âˆ©An)
Â· P(A2 | A3 âˆ©Â· Â· Â· âˆ©An)
Â· P(A3 | A4 âˆ©Â· Â· Â· âˆ©An)
Â· Â· Â·
Â· P(Anâˆ’1 | An)P(An).
(2.13)
2.3.2
Bayes formula
Let (, E, P) be a probability space and let A, B âˆˆE. If both P(A) and P(B)
are positive, then
P(A|B)P(B) = P(A âˆ©B) = P(B âˆ©A) = P(B|A)P(A);
since
P(A) = P(A âˆ©B) + P(A âˆ©Bc) = P(A|B)P(B) + P(A|Bc)(1 âˆ’P(B))
we get the formula due to Thomas Bayes (1702â€“1761).
Proposition 2.49 (Bayes formula) Let (, E, P) be a probability space and let
A, B âˆˆE such that P(A)P(B)P(Bc) > 0. Then
P(B|A) =
P(A|B)P(B)
P(A|B)P(B) + P(A|Bc)(1 âˆ’P(B)).
In other words, one can compute the probability of B given A in terms of the
probability of A given B and the absolute probability of B.
Example 2.50 Clinical tests are a classical example. Clinical tests detect indi-
viduals ill with a disease. The test gives a result that can be either positive or
negative. In order to qualify the ability of detecting ill individuals, an â€˜unbiased
sampleâ€™ of a population is examined and divided into two groups of healthy and
ill individuals, respectively. Individuals of the sample are then subjected to the
test. Let Î± and Î² be the percentages of positive results for ill and healthy individ-
uals, respectively. Since the sample is assumed to be representative of the whole
population, we assume Î± and Î² to be the percentages of positive results for all

PROBABILITY MEASURES
53
the ill individuals and all the healthy individuals of the population, respectively.
Denoting by H and I the sets of healthy and ill individuals, respectively, and
denoting by P the set of individuals that would get a positive result in the test,
we assume
Î± := P(P |I),
Î² = P(P |H);
From Î±, Î² and the percentage x := P(I) of ill individuals, Bayes formula allows
us to compute the probability that an individual is ill given a positive result was
obtained:
P(I|P) =
P(P |I)P(I)
P(P |I)P(I) + P(P |H)(1 âˆ’P(I)) = Î±
1
(Î± âˆ’Î²) + Î²
x
.
(2.14)
If the test is a good one, then Î± is close to 1 and Î² is close to zero. Formula
(2.14) shows how, in practice, the test loses efï¬cacy in the ï¬eld with respect to
the quality shown in the laboratory. In fact, if x = Î² one gets
1
(Î± âˆ’Î²) + Î²
x
â‰ƒ
1
Î± âˆ’Î² + 1 â‰ƒ1
2.
If the test is to be helpful in detecting ill individuals, then the ratio Î²/x =
P(P |H)/P(I) must be small.
Of course, in the previous example, one can replace the population with the
items produced in a production process, where healthy individuals are replaced
by non-faulty items and ill individuals correspond to faulty items. The clinical
test is, of course, substituted by a quality control. The mathematics involved is
exactly the same. Knowing the probability that the test has of detecting known
faulty and non faulty items and the percentage of faulty items, we can compute
the probability that the test is able to detect the faulty items.
Example 2.51 In modelling an email spam ï¬lter, one needs to compute the proba-
bility that the messages containing a given word are spam messages. Let M be the
set of spam messages and let W be the set of the messages that contain the given
word. We want to compute P(M|W). By Bayes formula, it sufï¬ces to know:
(i) P(W|M) and P(W|Mc), i.e. the probabilities that the word appears in spam
messages and in non-spam messages, respectively. These probabilities can
be obtained by a statistical analysis on the messages already arrived.
(ii) P(M), the probability that a message is a spam one. This is an absolute
number that can be found in the net or via a statistical analysis of the
trafï¬c.
We then get
P(M|W) = P(W|M)
P(M)
P(W|M)P(M) + P(W|Mc)(1 âˆ’P(M)).

54
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
2.3.3
Exercises
Exercise 2.52 An urn contains 3 white balls and 5 red balls. The balls are pairwise
distinguished, for example by numbering them. Two balls are extracted randomly.
â€¢ Compute the probability of drawing 2 red balls.
â€¢ Compute the probability of drawing 2 red balls, given that at least one is
red.
Solution. For the ï¬rst question, the certain event  is given by all the subsets
having cardinality 2 of a set of 8 elements, thus
|| =
8
2

= 28.
The favourable event A is in a one-to-one correspondence with the family of the
subsets of cardinality 2 of a set of 5 elements, i.e.
|A| =
5
2

= 10,
P(A) = |A|
|| = 10
28 = 5
14.
For the second question, we take advantage of Bayes formula: Let B be the
event â€˜At least one of the extracted ball is redâ€™. One gets
|B| = C5
2 + C5
1C3
1 =
5
2

+
5
1
3
1

= 10 + 15 = 25,
P(B) = |B|
|| = 25
28.
Thus
P(A|B) = P(A âˆ©B)
P(B)
= P(A)
P(B) = |A|
|B| = 10
25 = 2
5.
Find the mistake. In the second question the certain event is smaller. In fact,
since one of the drawn balls is red, the problem reduces to a simpler one: we
may think that the urn contains 3 white balls and 4 red ones and that we are to
extract only one ball. The successful cases are the ones where the drawn ball
is red. Denote by ) the new certain event and let )
A be the new event of the
favourable cases
|)| =
7
1

= 7,
|)
A| =
4
1

= 4.
Thus,
P()
A) = 4
7.
This wrong answer is in fact the right answer for another question. Which
one?

PROBABILITY MEASURES
55
Exercise 2.53 We throw two fair dice:
â€¢ Compute the probability that the sum of the two dice is at least 7.
â€¢ On one of the two dice we get a 4. Compute the probability that the sum of
the two dice is at least 7.
Solution. The certain event  is the set of all the possible results of the
throwing:  = {1, . . . , 6}2, || = 36. The event of successes is
A = {(i, j) âˆˆ: i + j â‰¥7}
whose cardinality is |A| = 1 + 2 + . . . + 6 = 6 Â· 7
2
= 21. Since the dice are fair,
the probability measure P on  is the uniform one. Thus,
P(A) = |A|
|| = 21
36 = 7
12.
In the second case, it is known that on one of the two dice we get a 4. Consider
the event
B =

(i, j) âˆˆ
 i = 4 or j = 4

.
Bayes formula then gives
P(A|B) = P(A âˆ©B)
P(B)
= |A âˆ©B|
|B|
= 7
11.
Find the mistake. In the second question the certain event can be reduced
from  to a smaller one. In fact, since on a dice we get a 4, we may assume
we are throwing only a dice. The successful event is â€˜We get a 3 or more on the
thrown diceâ€™. Thus, denoting by ) the new certain event and by )
A the successful
event, we get
|)| = 6,
|)
A| = 4,
so that
P()
A) = 4
6 = 2
3.
Exercise 2.54 An urn contains w white balls and r red balls. Compute the prob-
ability of drawing one white ball in one drawing only. Assume you do not know
the colour of the ï¬rst drawn ball. Without replacing it, you draw another ball.
Compute the probability of drawing a white ball in this second drawing.
Solution. In this case, the certain event is the fact that two balls are drawn
and each of them can be either red or white. So we take  = {0, 1}2 where the
ith component of z = (z1, z2) âˆˆ is zero if the ith drawn is white and 1 if the
ith drawn is red. Thus the event â€˜The ï¬rst ball is whiteâ€™ is associated with
W1 = {(0, 0), (0, 1)}

56
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
so that P(W1) := w/(w + r). In fact, when we draw â€˜randomlyâ€™ the ï¬rst ball we
are performing a Bernoulli trial where the probability of success is w/(w + r).
Similarly, the event â€˜The ï¬rst ball is redâ€™ is associated with
R1 = {(1, 0), (1, 1)} =  \ W1
so that P(R1) = 1 âˆ’P(W1) = r/(r + w). We are asked to compute the proba-
bility of the event â€˜The second ball is whiteâ€™, which is is associated with
W2 = {(0, 0), (1, 0)}.
Once we have drawn the ï¬rst ball, two cases may occur. If the ï¬rst ball is white,
then we are left with w âˆ’1 white balls and r red balls, i.e.
P(W2 | W1) =
w âˆ’1
w + r âˆ’1,
and, similarly,
P(W2 | R1) =
w
w + r âˆ’1.
The law of total probability then yields
P(W2) = P(W2 âˆ©W1) + P(W2 âˆ©R1)
= P(W2|W1)P(W1) + P(W2|R1)P(R1)
=
w âˆ’1
w + r âˆ’1
w
w + r +
w
w + r âˆ’1
r
w + r =
w
w + r .
Notice that, without any knowledge of the colour of the ï¬rst drawn ball, the
probability of drawing a ball of the same colour in the second drawing remains
the same. Thus, iterating the result, we get the following: without any knowledge
of the colour of the previously drawn balls, the probability remains the same also
in the following drawings [as far as the drawn balls are less than min(r, w)].
Exercise 2.55 Two submarines comunicate with each other by Morse code, a
binary code whose two letters are dots and dashes. The operator of the ï¬rst sub-
marine sends a message where 45% of the letters are dashes.
The operator of the second submarine receives dashes and dots correctly with
probability 96% and 98% , respectively. Compute the following:
â€¢ The probability that the operator of the second submarine receives a dash.
â€¢ The probability that the ï¬rst operator has sent a dash, given that the second
operator has received a dash.
â€¢ The probability that the ï¬rst operator has sent a dot given that the second
operator has received a dot.

PROBABILITY MEASURES
57
Solution. For a single bit of the comunication the following cases may occur:
â€¢ When considering its transmission, the letter can be either a dot (0) or a
dash (1).
â€¢ When considering its reception, the letter can be either a dot (0) or a dash
(1).
Thus we may identify the certain event with  = {0, 1}2 where the ï¬rst compo-
nent of z = (z1, z2) âˆˆ is 0 if a dot is transmitted and is 1 if a dash is transmitted,
and the second component z2 is 0 if a dot is received and 1 otherwise. Thus, the
event â€˜A dot is transmittedâ€™ is associated with
S0 = {(0, 0), (0, 1)},
the event â€˜A dash is transmittedâ€™ is associated with
S1 = {(1, 0), (1, 1)} =  \ S0
while the events â€˜A dot is receivedâ€™ and â€˜A dash is receivedâ€™ are associated with
R0 = {(0, 0), (1, 0)}
and
R1 = {(0, 1), (1, 1)} =  \ R0,
respectively. Assumption tells us that P(S1) := 0.45 so that P(S0) = 1 âˆ’
P(S1) = 0.55 and that P(R0 | S0) = 0.98 and P(R1 | S1) = 0.96.
We are asked to compute P(R1), P(S1|R1) and P(S0|R0). We have
P(R1) = P(R1|S0)P(S0) + P(R1|S1)P(S1)
= (1 âˆ’P(R0|S0))P(S0) + P(R1|S1)P(S1)
= (1 âˆ’0.98)(0.55) + (0.96)(0.45) = 0.443,
P(S1|R1) = P(S1 âˆ©R1)
P(R1)
= P(R1|S1)P(S1)
P(R1)
â‰ƒ0.975,
P(S0|R0) = P(S0 âˆ©R0)
P(R0)
= P(R0|S0)P(S0)
1 âˆ’P(R1)
â‰ƒ0.968.
Exercise 2.56 We have n urns, labelled 1 to n. The ith urn contains i white
balls and n + 1 âˆ’i red balls. Two balls are randomly drawn from a randomly
chosen urn:
â€¢ Compute the probability of drawing a white ball and a red one.
â€¢ Compute the probability of having chosen the ith urn given that a white
ball and a red ball are drawn. Which urn has the maximum probability of
having been chosen?

58
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Solution. Here the certain event is that fact that one urn is chosen and two
balls are drawn from that urn, so we identify the certain event with
 := {1, . . . , n} Ã—

z = (z1, z2) | zi âˆˆ{0, 1}

where zj = 0 if the jth drawn ball is red and zj = 0 if the jth drawn ball is
white.
Denote N := {1, . . . , n} and Z = {0, 1}2 so that  = N Ã— Z. We know that
the urn is â€˜randomly chosenâ€™, i.e.
P({i} Ã— Z) = 1
n
âˆ€i = 1, . . . , n.
The event â€˜A white ball and a red ball are drawnâ€™ is associated with
A := N Ã— {(0, 1), (1, 0)}
Since the balls are â€˜randomlyâ€™ drawn, we know that
P(A | Ui) =
i
1
n+1âˆ’i
1

n+1
2

= 2i(n + 1 âˆ’i)
n(n + 1)
.
Thus, since A = ,n
i=1

A âˆ©Ui

, we get
P(A) =
n

i=1
P

A âˆ©Ui

=
n

i=1
P

A|Ui

P(Ui)
=
n

i=1
2i(n + 1 âˆ’i)
n(n + 1)
1
n = n + 2
3n .
To answer the second question, we apply Bayes formula, hence
P(Ui|A) = P(A|Ui)P(Ui)
P(A)
= 2i(n + 1 âˆ’i)
n(n + 1)
1
n
3n
n + 2 =
6i(n + 1 âˆ’i)
n2(n + 1)(n + 2).
The urn with the maximum probability of having been chosen is Ui where
i =

k, k + 1
if n = 2k,
k + 1
if n = 2k + 1.
Exercise 2.57 A ï¬rm produces a certain instrument. The failure rate in the pro-
duction process is 8%. A sample of the produced instruments is subjected to a
quality check. Eighty per cent of the faulty instruments fail the quality check,
while 1% of the nonfaulty instruments fails the check. Compute the probability
that an instrument that passed the test is faulty.

PROBABILITY MEASURES
59
Exercise 2.58 We have three cards. Both sides of one card are black, both sides
of another card are red and the other card has one black side and one red side.
We choose a card: one of its side is red. Compute the probability of having chosen
the card with two red sides.
Exercise 2.59 An urn a contains 2 red balls and 1 black ball. Another urn, b,
contains 3 red balls and 2 black ones. An urn is randomly chosen and a ball is
randomly drawn from that urn. Compute the probability of having drawn a black
ball. Given that you have drawn a black ball, what is the probability of having
chosen urn a?
Exercise 2.60 In a TV quiz show, the host shows three doors to a contestant
and states that behind one of the doors there is a prize. The contestant randomly
chooses a door and marks it. Then the host, who knows where the prize is, opens
a door that was not marked by the contestant and that does not hide the prize. The
host now asks the contestant whether he would like to change his choice. What
should the contestant do?
Exercise 2.61 A ï¬rm produces two kinds of bolt. Bolts of type A are 70% of the
production. Only 95% of them pass the quality check and can be sold, while only
80% of bolts of type B pass the check and can be sold. What percentage of the
production is ï¬t to be sold?
[90.5%]
Exercise 2.62 A web server may be either working or broken. When broken, it
cannot be accessed. Even when it is working, an access attempt may fail, due to
web congestion (which the web server cannot control). Assume the probability
that the server is working is 0.8 and that each access attempt is successful with
probability 0.9. Compute the following:
(i) The probability that the ï¬rst access attempt fails.
(ii) The probability that the web server is working, given that the ï¬rst access
attempt has failed.
(iii) The probability that the second attempt fails, given that the ï¬rst attempt has
failed.
(iv) The probability that the server is working, given that two consecutive access
attempts have failed.
Exercise 2.63 Assume that each vertex of a cube may be coloured in blue with
probability p, independently of the other vertices. Let B be the event â€˜All the
vertices of at least one face of the cube are coloured in blueâ€™. Compute;
(i) The probability of B given that 5 vertices are blue.
(ii) The probability of B.

60
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Exercise 2.64 We are given 3 urns a, b and c. Urn a contains 5 red balls, 5 ï¬ve
white balls and 5 black ones; urn b contains 3 red balls, 5 white balls and 7
black balls; urn c contains 6 red balls, 7 white balls and 2 black balls. Two balls
are randomly drawn by one randomly chosen urn (no replacement occurs). Given
that the drawn balls are both black, compute the probability that they were drawn
from urn b.
%
21/32
&
Exercise 2.65 We are given six urns, which we label as Uj j = 1, . . . , 6. Each urn
Uj contains j red balls and 6 âˆ’j black balls. An urn is selected. The probability
of selecting the urn Uj is proportional to j. A ball is randomly drawn from the
selected urn. Compute the probability that the drawn ball is red.
%
13/18
&
2.4
Inclusionâ€“exclusion principle
A typical problem is the computation of the probability of at least one event
among n given ones: In this section we show how to compute;
â€¢ the probability of at least one event among ngiven ones;
â€¢ the probability of exactly k events among n;
â€¢ the probability of at least k events among n.
With the inclusionâ€“exclusion principle we can compute these probabilities
knowing the probabilities that two or more events happen, something which is
usually more easily evaluated. For example, if A, B âˆˆE, then A \ B, A âˆ©B and
B \ A are pairwise disjoint, so that
P(A âˆªB) = P(A \ B) + P(A âˆ©B) + P(B \ A) + P(A âˆ©B) âˆ’P(A âˆ©B)
= P(A) + P(B) âˆ’P(A âˆ©B)
(2.15)
and
P((A âˆªB)c) = 1 âˆ’P(A âˆªB) = 1 âˆ’P(A) âˆ’P(B) + P(A âˆ©B).
(2.16)
In order to discuss the case of many events, it is useful to introduce a con-
venient notation. A multi-index is a subset I âŠ‚{1, . . . , n}. The cardinality |I| of
the multi-index I is called the length of I. Let  be a set and let A1, . . . , An be
nonempty subsets of . For any multi-index I âŠ‚{1, . . . , n}, deï¬ne
AI :=


if I = âˆ…,
Ai1 âˆ©Ai2 âˆ©Â· Â· Â· âˆ©Aik
if k â‰¥1 and I =

i1, . . . , ik

.
(2.17)

PROBABILITY MEASURES
61
Example 2.66 Let A1, A2, A3 âŠ‚ be subsets of . The multi-indexes of {1, 2, 3}
are
âˆ…, {1}, {2}, {3}, {1, 2}, {1, 3}, {2, 3}, {1, 2, 3}
and the associated subsets AI, I âŠ‚{1, 2, 3}, are, respectively,
Aâˆ…= ,
A{1} = A1,
A{2} = A2,
A{3} = A3,
A{1,2} = A1 âˆ©A2,
A{2,3} = A2 âˆ©A3,
A{1,3} = A1 âˆ©A3,
A{1,2,3} = A1 âˆ©A2 âˆ©A3.
Deï¬nition 2.67 Let  be a set and let A1, . . . , An âŠ‚. We call the multiplicity
of the family A1, . . . , An at x âˆˆ the number val(x) of subsets of the family
A1, . . . , An that contain x:
val(x) :=


j âˆˆ{1, . . . , n}
 x âˆˆAj
.
Moreover, for every k = 0, . . . , n, let
Ek :=

x âˆˆ
 val(x) = k

be the set of points of  that belong to exactly k subsets of the family A1, . . . , An.
Clearly,
(A1 âˆªA2 âˆªÂ· Â· Â· âˆªAn)c =

x âˆˆ
 val(x) = 0

= E0.
Proposition 2.68 Let A1, . . . , An be nonempty subsets of a set , let val(x) be
the multiplicity of the family A1, . . . , An at x âˆˆ and let Ek, k = 0, 1, . . . , n, be
the kth level set of the multiplicity function val(x). Then

|J|=j
1AJ (x) =
val(x)
j

=
n

k=0
k
j

1Ek(x)
âˆ€j = 0, . . . , n.
(2.18)
and
1Ek(x) =
n

j=k
(âˆ’1)k+j
j
k
 
|J|=j
1AJ (x)

âˆ€j = 0, . . . , n.
(2.19)
Proof. The number

|J|=j
1AJ (x) =

|J|=j
xâˆˆAJ
1

62
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
is the number of subfamilies of

A1, . . . , An

of cardinality j whose elements
contain x. Since x belongs to val(x) subsets, there are
val(x)
j

ways to choose
any such subfamily, hence the equality

|J|=j
1AJ (x) =
val(x)
j

in (2.18). Moreover, the second equality in (2.18) follows since
val(x)
j

if and
only if x âˆˆEk,
Formula (2.19) is an equivalent formulation of (2.18) as an application of the
inversion formula for the Pascal matrix of binomial coefï¬cients, see Corollary 1.6.
Theorem 2.69 Let (, E, P) be a probability space and let A1, . . . , An âˆˆE.
Let val(x), x âˆˆ, be the multiplicity function of A1, . . . , An and for every
k = 0, . . . , n let Ek be the k-level set of val(x). Then

|J|=j
P(AJ )(x) =
n

k=0
k
j

P(Ek)(x)
âˆ€j = 0, . . . , n
(2.20)
and
P(Ek) =
n

j=k
(âˆ’1)k+j
j
k
 
|J|=j
P(AJ )

âˆ€k = 0, . . . , n.
(2.21)
Proof. Notice that all the terms in the sums in (2.18) and (2.19) are linear
combinations of simple functions. Thus, (2.20) and (2.21) follow integrating with
respect to P both terms of (2.18) and (2.19), respectively, taking into account
the linearity of the integral of simple functions, see Proposition 2.28.
Equation (2.21) reduces the computation of the probability that exactly k
events among n happen to the computation of the probabilities of the intersections
of the events of the family. As a consequence, we get the inclusionâ€“exclusion
principle, a particularly useful tool for computing the probability that at least
one event among n happens.
Corollary 2.70 With the notation above, we have the Sylvester formula
P
 n
(
i=1
Ai
c
=
n

j=0
(âˆ’1)j 
|J|=j
P(AJ)

(2.22)
and the inclusionâ€“exclusion principle
P

n
(
i=1
Ai

=
n

j=1
(âˆ’1)j+1 
|J|=j
P(AJ)

.
(2.23)

PROBABILITY MEASURES
63
Proof. Since (A1 âˆªÂ· Â· Â· âˆªAn)c = E0, (2.22) is (2.21) with k = 0. Moreover,
since P(âˆªn
i=1Ai) = 1 âˆ’P((âˆªn
i=1)Ai)c), and 
|J|=0 P(AJ ) = P() = 1, (2.23)
follows from, and, actually, is equivalent to, (2.22).
Summing (2.21) for k = k, k + 1, . . . , n, we get an useful formula for com-
puting the probability that at least k events among n happen. In fact, the following
holds.
Corollary 2.71 Let (, E, P) be a probability space, let A1, . . . , An âˆˆE and, for
k = 0, 1, . . . , n, let Fk be the set of points of  that belong to at least k sets of
the family A1, . . . , An, k â‰¥1,
Fk :=

x âˆˆ
 val(x) â‰¥k

.
Then
P(Fk) =
n

j=k
(âˆ’1)j+k
j âˆ’1
k âˆ’1


JâŠ‚{1,...,n}
|J|=j
P(AJ )

.
(2.24)
Proof. For p = 0, 1, . . . , n, let Ep := {x âˆˆ | val(x) = p}. Obviously, the
sets Ep are pairwise disjoint and Fk = âˆªn
p=kEp. Thus, by (2.19) for any x âˆˆ
1Fk(x) =
n

p=k
1Ep(x) =
n

p=k
n

j=p
(âˆ’1)p+j
j
p


JâŠ‚{1,...,n}
|J|=j
1AJ (x)

=
n

j=k
(âˆ’1)j

j

p=k
(âˆ’1)p
j
p


JâŠ‚{1,...,n}
|J|=j
1AJ (x)

.
Since
j

p=k
(âˆ’1)p
j
p

= âˆ’
kâˆ’1

p=0
(âˆ’1)p
j
p

= âˆ’(âˆ’1)kâˆ’1
j âˆ’1
k âˆ’1

,
see Exercise A.13, one gets
1Fk(x) =
n

j=k
(âˆ’1)j+k
j âˆ’1
k âˆ’1


JâŠ‚{1,...,n}
|J|=j
1AJ (x)

.
The claim then follows by integrating the previous equality with respect to P.
2.4.1
Exercises
Exercise 2.72 (Derangements) Taking advantage of the inclusionâ€“exclusion
principle (2.23), compute the number of derangements of n objects, see
Section 1.2.2,
|Dn| := n!
n

j=0
(âˆ’1)j 1
j!.

64
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Solution. Let Pn and Dn be the set of permutations and of derangements of n
objects, respectively. For any i = 1, . . . , n, let Ai âŠ‚Pn be the set of permutations
that do not move i,
Ai =

Ï€ âˆˆPn
 Ï€(i) = i

.
Clearly,
Dn = (A1 âˆªA2 âˆªÂ· Â· Â· âˆªAn)c
so that, by the inclusionâ€“exclusion principle,
|Dn| =

JâŠ‚{1,...,n}
(âˆ’1)|J||AJ | =
n

j=0
(âˆ’1)j

JâŠ‚{1,...,n}
|J|=j
|AJ |.
If J =

k1, . . . , kj

then AJ is the set of permutations that do not move the
points

k1, . . . , kj

. These permutations are as many as the permutations of
the n âˆ’j remaining elements, i.e. |AJ | = (n âˆ’j)! Thus, denoting by cj the
number of multi-indexes J of length j in {1, . . . , n}, we get
|Dn| =
n

j=0
(âˆ’1)j(n âˆ’j)!


JâŠ‚{1,...,n}
|J|=j
1

=
n

j=0
(âˆ’1)j(n âˆ’j)! cj.
Since cj =
n
j

we ï¬nally get
|Dn| =
n

j=0
(âˆ’1)j(n âˆ’j)!
n
j

= n!
n

j=0
(âˆ’1)j 1
j!.
Exercise 2.73 (MÂ´enage problem) We ask for the number of different ways in
which it is possible to seat a set of n heterosexual couples at a dining round
table so that men and women alternate and nobody sits next to his or her partner.
The mÂ´enage problem is a classical problem in combinatorics, ï¬rst formulated by
Â´Edouard Lucas in 1891.
Solution. Let Kn be the possible arrangements. If n = 1 or n = 2 then obvi-
ously Kn = 0. If n = 3, there are 3! = 6 possible arrangements with the given
constraints. For larger n, n â‰¥4, we can proceed as follows: there are n! seat-
ing arrangements for women, thus it remains to count the number Un âŠ‚Pn of
permutations of seating men away from their wives.
Theorem (Touchard) We have
Kn = n! Un,
Un :=
n

k=0
(âˆ’1)k
2n
2n âˆ’k
2n âˆ’k
k

(n âˆ’k)!
(2.25)

PROBABILITY MEASURES
65
Proof. Without loss of generality, we may assume that the seats are anticlock-
wise numbered from 1 to 2n. For any h = 1, . . . , n, let
A2hâˆ’1 =

permutations in Pn that sit the husband h
on the left of his wife

,
A2h =

permutations in Pn that sit the husband h
on the right of his wife

.
The acceptable arrangements are one (A1 âˆªÂ· Â· Â· âˆªA2n)c âŠ‚Pn, thus
Un = |(A1 âˆªÂ· Â· Â· âˆªA2n)c|.
By the inclusionâ€“exclusion principle (2.22),
Un = |(A1 âˆªÂ· Â· Â· âˆªA2n)c| =

JâŠ‚{1,...,2n}
(âˆ’1)|J||AJ |
=
2n

j=0
(âˆ’1)j

JâŠ‚{1,...,2n}
|J|=j
|AJ |

,
thus, we have to compute |AJ| for J âŠ‚{1, 2, . . . , 2n}.
If |J| = j and J =

k1, . . . , kj

, then AJ = Ak1 âˆ©Â· Â· Â· âˆ©Akj . Notice that
A2h âˆ©A2h+1 for h = 1, . . . , n âˆ’1 are empty since any permutation of one of
these intersections puts husbands h and h + 1 on the same chair. Similarly,
A2n âˆ©A1 is empty since the permutations in it force the husbands 1 and n on the
same chair. Also the intersection A2hâˆ’1 âˆ©A2h is empty since any permutation
in this intersection is such that the husband h sits in two different chairs. We
can summarize these facts by saying that AJ = âˆ…if J contains two consecutive
integers in the sequence (1, 2, . . . , 2n, 1). In particular, AJ = âˆ…if j = |J| > n.
If J does not contain two consecutive integers in the sequence (1, 2, . . . , 2n, 1),
then every permutation in AJ, J = (k1, . . . , kj), ï¬xes the chairs of the husbands
k1, . . . , kj. Hence AJ contains as many permutations as the free permutations
of the remaining n âˆ’|J| husbands, i.e. |AJ | = (n âˆ’|J|)! Summarizing, if
j := |J|, then
|AJ| =
â§
âªâ¨
âªâ©
(n âˆ’j)!
if J does not contain two consecutive integers
in the sequence (1, . . . , 2n, 1),
0
otherwise.
Denote
by
f2n,j
the
number
of
subsets
J âŠ‚{1, . . . , 2n}
such
that
|J| = j and which do not contain two consecutive integers in the sequence
(1, 2, . . . , 2n, 1). Then
Un =
2n

j=0
(âˆ’1)j

JâŠ‚{1,...,2n}
|J|=j
|AJ|

=
n

j=0
(âˆ’1)j

JâŠ‚{1,...,2n}
|J|=j
|AJ|


66
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
=
n

j=0
(âˆ’1)j(n âˆ’j)! f2n,j.
(2.26)
In the next lemma, see (2.27), we will compute f2n,j:
f2n,j =
2n
2n âˆ’j
2n âˆ’j
j

.
Substituting in (2.26) we obtain the claim.
Lemma The number fn,k of subsets of {1, . . . , n} having cardinality k and that
do not contain two consecutive integers in the sequence (1, 2, . . . , n, 1) is
fn,k =
n
n âˆ’k
n âˆ’k
k

.
(2.27)
Proof. It can be shown, see Exercise 1.30, that the number gn,k of subsets of
cardinality k that do not contain two consecutive integers in (1, . . . , n) is
gn,k =
n âˆ’k + 1
k

.
Let S be the family of subsets of {1, . . . , n} having cardinality k and that do not
contain two consecutive integers in the sequence (1, 2, . . . , n, 1). Let S1 be the
family of the subsets in S that do not contain 1 and let S2 be its complement
in S, so that |S| = |S1| + |S2|. Each subset in S1 has cardinality k and its
elements are integers in {2, . . . , n} which are not pairwise consecutive. Thus
|S1| = gnâˆ’1,k. Each subset in S2 has cardinality k and since it contains 1, it
contains neither 2 nor n, and is detected by its remaining k âˆ’1 elements, Thus
|S2| = gnâˆ’3,kâˆ’1. Consequently,
fn,k = |S| = |S1| + |S2| = gnâˆ’1,k + gnâˆ’3,kâˆ’1
=
n âˆ’1 âˆ’k + 1
k

+
n âˆ’3 âˆ’k + 1 + 1
k âˆ’1

=
n
n âˆ’k
n âˆ’k
k

.
Exercise 2.74 (Euler function) For any positive integer n compute the number
of primes in {1, . . . , n âˆ’1} which are relative prime to n, i.e.
Ï†(n) :=


d
 1 â‰¤d â‰¤n, gcd(d, n) = 1
.
Solution. Write n as the product of prime numbers, n = pÎ±1
1 . . . pÎ±k
k
with
p1, p2, . . . , pk pairwise different prime numbers. If d and n are not coprime,

PROBABILITY MEASURES
67
then there exists i âˆˆ{1, . . . , k} such that pi divides d. For any i = 1, . . . , k let
Ai : =

d
 1 â‰¤d â‰¤n, pi divides d

=

pi, 2pi, 3pi, . . .

âˆ©{1, . . . , n}.
We want to compute
Ï†(n) =
(A1 âˆªA2 âˆª. . . Ak)c
by means of the inclusion-exclusion principle.
We ï¬rst compute |AJ| for every J âŠ‚{1, . . . , n}. By (2.17) we have Aâˆ…=
{1, . . . , n}, so that |Aâˆ…| = n. For any i, Ai =

pi, 2pi, 3pi, . . .

so that |Ai| =
n
pi . Moreover,
A{i,j} = Ai âˆ©Aj =

pipj, 2pipj, . . . , n

,
so that |A{i,j}| =
n
pipj and, in general,
|AJ | =
n
-
iâˆˆJ pi
âˆ€J âŠ‚{1, . . . , k}.
Applying the inclusion-exclusion principle we get
Ï†(n) =

JâŠ‚{1,...,n}
(âˆ’1)|J||AJ|
= n

1 âˆ’

i
1
pi
+

i<j
1
pipj
âˆ’

i<j<k
1
pipjpk
+ Â· Â· Â· + (âˆ’1)n
1
p1p2 Â· Â· Â· pk

= n

1 âˆ’1
p1

1 âˆ’1
p2

. . .

1 âˆ’1
pk

.
(2.28)

3
Random variables
Events and their probabilities are important objects in probability theory, but
not the only ones. Consider for instance the waiting time at a trafï¬c light. It is
impossible to evaluate the probability that the waiting time is, say, between 10
s and 20 s, simply because the answer depends on the arrival time probabilities.
For instance, if everybody arrives during the green phase, then the waiting time
is always zero! Waiting time probabilities depend in a deï¬nite manner on the
arrival time. This is a typical example of random variable, i.e. of maps that link
probability spaces. In Section 3.1 we ï¬rst introduce real valued random variables
and the basic related objects of value distribution, law and generated events, and
the standard two descriptors of expected value and variance. We also state a few
useful formulas to compute the distribution and law of the composition of random
variables. A few classical discrete and absolutely continuous distributions on R
are then presented in Section 3.2 and Section 3.3, respectively. Each section is
complemented with examples and exercises. Other examples and exercises can
be found e.g. in [3].
3.1
Random variables
Suppose (, E, P) is a probability space. Heuristically, a random variable is
the result of an experiment (that is a well-deï¬ned deterministic experience) on the
probability space (, E, P). The result of such an experiment is nevertheless
random since the probability measure on  induces a probability measure on the
set of the possible results of the experiment. As an example, consider a dice, for
which the base space is the set  = {1, . . . , 6}. If the experiment is â€˜What number
is on the top face?â€™, then the set of possible results is the set {1, 2, 3, 4, 5, 6} and
the result is random since the throwing of a dice is random. If the experiment
is â€˜Is the number on the top face an even number?â€™ then the set of possible
results is {â€˜Trueâ€™, â€˜Falseâ€™}, and again the answer is random since the throwing of
A First Course in Probability and Markov Chains, First Edition. Giuseppe Modica and Laura Poggiolini.
Â© 2013 John Wiley & Sons, Ltd. Published 2013 by John Wiley & Sons, Ltd.

RANDOM VARIABLES
69
a dice is random. Notice that in both cases the question is deterministic. Another
example we have already presented is the waiting time at a trafï¬c light: also in
this case, the waiting time depends in a deterministic way on the time of arrival
and randomness of the waiting time reï¬‚ects the randomness of arrival times. As
a further example, one may observe a certain feature of a physical system, say
the temperature, a parameter that is known to vary with the state of the system in
a well-deï¬ned way. If  is the base set of all possible states of the system, then
the experiment of â€˜measuring the temperatureâ€™ is a given map T :  â†’R from
 to R. What we observe is the value of such a mapping, not the state of the
system. A certain degree of randomness in the system may induce randomness
in the observed value of the temperature.
Summing up:
â€¢ A random variable is a map X :  â†’R deï¬ned on the base space  of
a probability space (, E, P). We use the name â€˜variableâ€™ to stress the
importance of the image of X.
â€¢ The probability measure P on  induces a probability measure on the
image X(), hence the name â€˜random variableâ€™. The emphasis will be on
the properties of the measure induced on X().
â€¢ In general, a random variable â€˜seesâ€™ only some events in , as well as an
observable on a physical system gives only partial information on the state
of the system.
To give a formal presentation, we must furthermore keep in mind that, in
general, not every subset of  is an event.
3.1.1
Deï¬nitions
3.1.1.1
Real valued random variables
Deï¬nition 3.1 A real valued random variable on a probability space (, E, P)
is an E-measurable function X :  â†’R, i.e. a real-valued function deï¬ned on 
such that for any t âˆˆR the t-sublevel set of X belongs to E,

x âˆˆ
 X(x) â‰¤t

âˆˆE.
Here R := R âˆª{+âˆ} âˆª{âˆ’âˆ}.
As previously noticed, we tacitly assume that E = P() if X() is ï¬nite or
denumerable. In this case, any function X :  â†’R is a random variable.
Example 3.2 Let (, E, P) be a probability space and let E âˆˆE. Then he char-
acteristic function of E,
1E(x) =

1
if x âˆˆE,
0
otherwise

70
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
is a random variable since for any t âˆˆR

x âˆˆ
 1E(x) â‰¤t

=
â§
âªâ¨
âªâ©

if t â‰¥1,
Ec
if 0 â‰¤t < 1,
âˆ…
if t < 0
and, of course, âˆ…, Ec and  are events.
3.1.1.2
Distribution of a random variable
Let X :  â†’R be a random variable on the probability space (, E, P). Starting
from
Xâˆ’1([âˆ’âˆ, t]) =

x âˆˆ
 X(x) â‰¤t

âˆˆE
and taking into account that E is a Ïƒ-algebra, one can show that
Xâˆ’1(A) =

x âˆˆ
 X(x) âˆˆA

is an event, Xâˆ’1(A) âˆˆE, for every Borel set A âˆˆB(R), see also Appendix B.
Consequently, we may deï¬ne
PX(A) := P(X âˆˆA) := P(Xâˆ’1(A))
âˆ€A âˆˆB(R).
(3.1)
We will write P(X âˆˆA) for P({x âˆˆ | X(x) âˆˆA}).
Using De Morgan formulas, it is then easy to show that (B(R), PX) is a
measure on R which is called the distribution of X induced by (E, P). Since
PX(R) = 1 âˆ’P(X = Â±âˆ), PX is a probability measure on R if and only if
P(X = Â±âˆ) = 0. If Î¼ is a measure and PX = Î¼ we also say that X is distributed
as Î¼ or that X follows Î¼.
We emphasize that the measure PX depends on X as a function and on the
measure P, see Example 3.3. However, as usual, we still refer in the following to
PX as to the distribution of the random variable X, thinking of the domain prob-
ability space as already understood in the deï¬nition of the random variable X.
3.1.1.3
Law or probability distribution function
An efï¬cient way to describe the distribution of a random variable X :  â†’R
is through the so-called probability distribution function or law of X. It is the
function FX : R â†’[0, 1] deï¬ned by
FX(t) := P(X â‰¤t),
t âˆˆR.
Example 3.3 In Figure 3.1 the laws of two random variables relative to the
function X(x) = x are drawn. Figure 3.1(a) shows the law of X driven by

RANDOM VARIABLES
71
t
0
1
1
t
6
(a)
(b)
1
1
Figure 3.1
The laws in Example 3.3.
the probability measure associated with the throwing of a dice; Figure 3.1(b)
shows the law of X driven by the uniform probability on the interval [0, 1].
Notice that the law, as well as the probability distribution, depends both on the
function X and on the domain probability space.
The law FX need not be continuous even if X is smooth, see e.g. Figure 3.1
where X(x) = x. However, we have the following.
Proposition 3.4 Let FX : R â†’R be the law of a random variable X. Then we
have:
(i) FX is monotone increasing.
(ii) FX(t) â†’P(X = âˆ’âˆ) as t â†’âˆ’âˆ.
(iii) FX(t) â†’1 âˆ’P(X = +âˆ) as t â†’+âˆ.
(iv) FX is continuous from the right, i.e. FX(t) = limsâ†’t+ FX(s) âˆ€t âˆˆR.
(v) FX(t) = PX([âˆ’âˆ, t]) âˆ€t âˆˆR.
(vi) P({x âˆˆ | X(x) = t}) = FX(t) âˆ’limsâ†’tâˆ’FX(s) âˆ€t âˆˆR.
Proof. Properties (i), (ii), (iii) and (v) are trivial. Let us prove (iv) and (vi).
(iv) Let t âˆˆ[âˆ’âˆ, âˆ[ and let sn â†“t. For every n set En :=

x âˆˆ | X(x) â‰¤sn

âˆˆE so that

En

is a monotone decreasing sequence in E. Since

x âˆˆ
 X(x) â‰¤t

=
'
n
En,
we infer from the continuity of measures that
FX(t) = P(X â‰¤t) = lim
nâ†’âˆP(En) =
lim
nâ†’+âˆFX(sn).
Claim (iv) then follows, since

sn

is arbitrary.

72
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
(vi) Let t âˆˆ] âˆ’âˆ, âˆ] and let sn â†‘t. Then for every n the set Fn :=

x âˆˆ | X(x) â‰¤sn

âˆˆE; moreover, the sequence

Fn

is monotone increasing.
Since

x âˆˆ
 X(x) < t

=
(
n
Fn,
we infer from the continuity of measures that
P(X < t) = lim
nâ†’âˆP(Fn) =
lim
nâ†’+âˆFX(sn),
hence
P(X < t) = lim
sâ†’tâˆ’FX(s) =: FX(tâˆ’).
Claim (vi) follows.
Although FX need not be continuous, it is worth recalling that any monotone
function f has at most a countable set of discontinuity points. In fact, for any
integer k there are at most a countable number of points (a ï¬nite number if f is
bounded) where the jump is larger than 1/k.
The law FX and the measure distribution PX are two equivalent ways to
describe the distribution of the random variable X. One can obtain FX from PX
just by deï¬nition. On the other hand, from (v) of Proposition 3.4 and taking into
account that PX is a measure, one gets
PX(]a, b]) = FX(b) âˆ’FX(a)
âˆ€a, b âˆˆR,
i.e. given FX, one recovers the value of PX on intervals that are left-open and
right-closed. Since any open set A âˆˆR is an at most denumerable and disjoint
union of such intervals, we can recover PX(A) from FX for any open set A âŠ‚R
and then for every Borel set because of the Ïƒ-additivity and continuity properties
of measures. In this way, the law t â†’FX(t) completely describes the measure
(B(R), PX), see also Appendix B.
3.1.1.4
Events generated by a random variable
Let X :  â†’R be a random variable on a probability space (, E, P). As already
stated, for every A âˆˆB(R) the preimage of A with respect to the random vari-
able X,
Xâˆ’1(A) :=

x âˆˆ
 X(x) âˆˆA

,
(3.2)
belongs to E. Using De Morgan formulas, it is easy to check that the family of
such events
EX :=

E âˆˆE
 E = Xâˆ’1(A) for some A âˆˆB(R)

is a Ïƒ-algebra, hence EX is called the family of the events detectable or generated
by X. Trivially, EX is the smallest Ïƒ-algebra that contains all the events of the
type Xâˆ’1(A) for A âˆˆB(R).

RANDOM VARIABLES
73
Example 3.5 Let X :  â†’R be a constant c. Then
Xâˆ’1(A) =


if c âˆˆA,
âˆ…
if c /âˆˆA.
Therefore, the only events detectable by X are âˆ…and , i.e. EX = {âˆ…, }.
Example 3.6 Suppose that the image of X :  â†’R is ï¬nite or denumerable,
X() =

yi

iâˆˆN. Then E(X) is the Ïƒ-algebra generated by the denumerable
family of events Ei, i âˆˆN, given for every i âˆˆN by Ei :=

x âˆˆ | X(x) = yi

,
i âˆˆN.
3.1.1.5
Special classes of distributions
The distributions of many random variables that appear in applications either ï¬t
in one of the two classes of measures described below or are linear combinations
of them.
â€¢ Discrete distribution. We recall that a measure Î¼ on R is atomic or discrete
if it is concentrated on a ï¬nite or denumerable set of points

tj

âŠ‚R, that
is, Î¼(A) = 0 if and only if A âˆ©

tj

= âˆ…. The vector (or sequence if the
number of points is denumerable) p = (pj), pj := Î¼(

tj

) is called the
density (with respect to the counting measure), or mass density function of
the measure Î¼. Moreover, the number pj is called the density of Î¼ at tj.
If X is a random variable with a discrete distribution PX concentrated
on

tj

, we can express the law of X in terms of the density (pj) of PX;
in fact,
FX(t) = PX([âˆ’âˆ, t]) =

tj â‰¤t
PX(

tj

) =

tj â‰¤t
pj.
Notice that FX(t) is monotone increasing and piecewise constant with
jumps at

tj

, and the jump at tj has size PX(

tj

).
â€¢ Absolutely continuous distribution. Recall that a measure (B(R), Î¼) on
R is said to be absolutely continuous if there exists a non-negative and
Lebesgue summable function f : R â†’R such that
Î¼(A) =
*
A
f (s) ds
âˆ€A âˆˆB(R).
(3.3)
The function f (s) is called the density of Î¼ (with respect to the Lebesgue
measure L1). In particular, for F(t) := Î¼(] âˆ’âˆ, t]) we have
F(t) :=
* t
âˆ’âˆ
f (s) ds
âˆ€t âˆˆR.
(3.4)
Observe that F(t) â†’0 as t â†’âˆ’âˆand F(t) â†’Î¼(R) as t â†’+âˆ.

74
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
The reader recognizes the relation (3.4) as a classical point in mathematical
analysis. For instance, if f is piecewise continuous, then F is continuous
and piecewise C1 by the fundamental theorem of calculus. Moreover,
F â€²(t) = f (t) if f is continuous at t. If f is merely summable, it can be
shown, see the absolute continuity theorem for the integral, Theorem B.58,
that F(t) is an absolutely continuous function, a condition strictly stronger
than continuity, see Deï¬nition B.66. A celebrated theorem by Vitali,
Theorem B.64, yields the converse: if F is an absolutely continuous
function, then there exists a summable function f such that (3.4) holds.
In conclusion, the following two claims agree:
â€” Î¼ is an absolutely continuous measure, (3.3);
â€” F(t) := Î¼(] âˆ’âˆ, t]) is an absolutely continuous function.
If either of them is true, then the derivative of F(t) exists for almost all t
and
F â€²(t) = f (t)
for a.e. t âˆˆR :
The density function agrees almost everywhere with the derivative of the
law.
In particular, if X is a real valued random variable with an absolutely con-
tinuous distribution of density fX, i.e.
PX(A) =
*
A
fX(t) dt
âˆ€A âŠ‚B(R),
then trivially,
FX(t) = P(X â‰¤t) = P(âˆ’âˆ< X â‰¤t) =
* t
âˆ’âˆ
fX(s) ds
âˆ€t âˆˆR.
Observe that
.
R fX(s) ds = 1.
A typical example in this class is a random variable X uniformly distributed
on an interval ]a, b[, that is, such that PX(A) :=
.
A fX(t) dt âˆ€A âˆˆB(R) where
fX(t) =
â§
â¨
â©
1
b âˆ’a
if t âˆˆ]a, b[,
0
otherwise.
Distributions of random variables may also be a combination of the two types
above, as in the following example.
Example 3.7 (Waiting time at a trafï¬c light) Consider for simplicity a trafï¬c
light with two states, red and green. The red and green lights are on for r and g
seconds, respectively. The cycle is iterated every r + g seconds. Here the certain
event is the time interval [0, r + g]. A car randomly reaches the trafï¬c light
according to the uniform distribution on [0, r + g], i.e. the probability that a car

RANDOM VARIABLES
75
driver arrives in a time interval I = [a, b], 0 â‰¤a â‰¤b â‰¤r + g is P(I) := (b âˆ’
a)/(r + g). Thus the probability associated with arrival time is (B([0, r + g]), P)
where P(A) :=
1
r+gL1(A).
For every arrival time x âˆˆ[0, r + g] the waiting time at the trafï¬c light is
T (x) :=

r âˆ’x
if 0 â‰¤x â‰¤r,
0
if r â‰¤x â‰¤r + g.
Since T is continuous, T is a random variable on the probability space ([0, r +
g], B([0, r + g]), P) with law
FT (t) := P(T â‰¤t) =
â§
âªâ¨
âªâ©
0
if t < 0,
t+g
r+g
if 0 < t < r,
1
if t â‰¥r,
see Figure 3.2. We point out that the law FT is neither piecewise constant nor
continuous. It has a jump at time t = 0 of amplitude g/(r + g). Of course,
FT is the sum of a continuous piecewise linear function and of a piecewise
constant function.
3.1.2
Expected value
Let X :  â†’R be a random variable on (, E, P). The integral
E [ X ] =
*

X(x) P(dx),
(3.5)
if it exists, is also called the expected value or the expectation of the random
variable X. Notice that E [ X ] is simply the mean value of X on 
E [ X ] =
1
P()
*

X(x) P(dx)
since P() = 1.
r
r + g
r + g
g
r
T(x)
FT(t)
1
r
0
(a)
(b)
Figure 3.2
The trafï¬c light. (a) The waiting time T (x); (b) the law according to
the uniform probability on [0, r + g].

76
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
The integral in (3.5) is the Lebesgue integral, which we now brieï¬‚y describe
in this contest, even though the assumption P() = 1 is not necessary. The
reader may refer to Appendix B for details.
We have already mentioned the deï¬nition of the Lebesgue integral of a simple
function, i.e. of a random variable with a ï¬nite range, i.e. of a function
Ï•(x) =
n

i=1
ci1Ei(x)
where c1, . . . , cn are pairwise distinct and the sets Ei :=

x âˆˆ | Ï•(x) = ci

are
events of the Ïƒ-algebra E. The integral of Ï• (with respect to the measure P) has
been deï¬ned as
E [ Ï• ] =
*

Ï•(x) P(dx) :=
n

i=1
ciP(Ei),
(3.6)
as intuition suggests.
Let X :  â†’R+ be a non-negative random variable (X may take the value
+âˆ). One can show that there exists a sequence

Ï•n

of simple functions such
that Ï•1(x) â‰¤Ï•2(x) â‰¤. . . and Ï•n(x) â†‘X(x) âˆ€x âˆˆ. For each n the integral
In :=
.
 Ï•n(x) P(dx) is deï¬ned in (3.6) and

In

is an increasing sequence of real
numbers, so that limnâ†’âˆIn exists and is in [0, +âˆ]. It is an easy consequence
of the Beppo Levi theorem that the limit does not depend on the choice of the
approximating sequence

Ï•n

. We then deï¬ne the Lebesgue integral, equivalently
the expectation of X, by
E [ X ] =
*

X(x) P(dx) := lim
nâ†’âˆ
*

Ï•n(x) P(dx).
Notice that E [ X ] = +âˆwhenever P(X = +âˆ) > 0, and that E [ X ] = 0 if and
only if P(X > 0) = 0; in the latter case, one says that X = 0 P-almost everywhere
or, when no confusion may arise we say that X = 0 almost everywhere, which
is usually shortened to X = 0 a.e.
Let now X :  â†’R be a random variable, not necessarily non-negative.
Split
X
as
X(x) = X+(x) âˆ’Xâˆ’(x)
where
X+(x) := max {X(x), 0}
and
Xâˆ’(x) = max {âˆ’X(x), 0}.
Since
X+
and
Xâˆ’
are
non-negative
random
variables, their expectations are deï¬ned. If either E
%
X+
&
or E
%
Xâˆ’
&
is ï¬nite, we say that X is Lebesgue integrable
and deï¬ne E [ X ] as
E [ X ] := E
%
X+
&
âˆ’E
%
Xâˆ’
&
. We point out that the expectation of X is
not deï¬ned if both E
%
X+
&
and E
%
Xâˆ’
&
are inï¬nite. Finally, observe that
|X(x)| = X+(x) + Xâˆ’(x) so that E [ |X| ] can be computed, and that E [ X ]
exists and is ï¬nite if and only if E [ |X| ] is ï¬nite. In the latter case, we say that
X is summable.
The usual properties of the integral or expectation are collected in
Theorem B.21. There the reader may ï¬nd the standard properties of the integral:

RANDOM VARIABLES
77
linearity, monotonicity and additivity, and the main result about limits, known
as the Beppo Levi theorem.
Since the above holds whatever P() is, this procedure deï¬nes the integral
of random variables X on a probability space (, E, P) (with respect to P) and
the integral of B(R)-measurable functions with respect to PX. Therefore, the
notations
*

X(x) P(dx)
and
*
R
Ï•(t)PX(dt)
make sense if X is a non-negative random variable and if Ï• : R â†’R is non-
negative and B(R)-measurable, respectively.
As already shown, the distribution function FX(t) : R â†’R completely
describes the distribution of the values of the random variable X. Thus, one
also writes
*

Ï•(t) dFX(t)
instead of
*
R
Ï•(t) PX(dt),
(3.7)
see also Appendix B and the exercises therein for explicit formulas of the integral
of random variables with respect to several measures. Here we only quote the
following two facts.
â€¢ Let X be a random variable with a discrete distribution PX concentrated
on

xi

and of density pi at xi. Then
*
R
Ï•(t) PX(dt) =

i
Ï•(xi)pi.
â€¢ Let X :  â†’R be a random variable with absolutely continuous distribu-
tion of density fX. Then
*
R
Ï•(t) dFX(t) =
*
R
Ï•(t) PX(dt) =
*
R
Ï•(t)fX(t) dt.
Because of this last formula, the absolute continuity property (3.3) is usu-
ally written as
PX(dt) = dFX(t) = fX(t) dt.
3.1.3
Functions of random variables
Let X be a real valued random variable on the probability space (, E, P), let
(B(R), PX) be its distribution and let Ï• : R â†’R be a Borel-measurable func-
tion on R. The composition Y := Ï• â—¦X :  â†’R is again a random variable
on (, E, P). In fact, for any open set A âŠ‚R the set Ï•âˆ’1(A) âŠ‚R is a Borel
set, hence (Ï• â—¦X)âˆ’1(A) = Xâˆ’1(Ï•âˆ’1(A)) is an event. The following formulas for
Y = Ï• â—¦X trivially hold:
PY (A) = P(Y âˆˆA) = P(X âˆˆÏ•âˆ’1(A)) = PX(Ï•âˆ’1(A)),
(3.8)

78
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
FY(s) = PX({t âˆˆR | Ï•(t) â‰¤s}).
(3.9)
From (3.9) we trivially infer that FY (s) = P(Ï• â—¦X â‰¤s) = 0 if s is below
the image of Ï• and FY(s) = 1 if s is above the image of Ï•. However, there is
no easy formula that follows from (3.9) as the following example shows.
Example 3.8 Let X be a real valued random variable and, for 0 < a â‰¤1, let
Ï•(t) :=
â§
âªâ¨
âªâ©
0
if t < 0,
a
if t = 0,
1
if t > 0.
Then

x âˆˆ
 Ï•(X(x)) â‰¤s

=
â§
âªâªâªâ¨
âªâªâªâ©
âˆ…
if s < 0,
{x | X(x) < 0}
if 0 â‰¤s < a,
{x | X(x) â‰¤0}
if a â‰¤s < 1,

if s â‰¥1.
Hence FY (0) = P(Ï•(X(x)) â‰¤0) = P(X < 0) = FX(0âˆ’).
A few special cases of (3.9) are described below.
â€¢ If Ï• : R â†’R is continuous and strictly monotone increasing then for any
s âˆˆÏ•(R) we have Ï•(t) â‰¤s if and only if t â‰¤Ï•âˆ’1(s), hence
FY (s) = PX(y â‰¤Ï•âˆ’1(s)) = FX(Ï•âˆ’1(s)).
â€¢ If Ï• is continuous and strictly monotone decreasing then for any s âˆˆÏ•(R)
we have Ï•(t) â‰¤s if and only if t â‰¥Ï•âˆ’1(s), so that
FY(s) = PX(y â‰¥Ï•âˆ’1(s)) = 1 âˆ’FX(tâˆ’),
t := Ï•âˆ’1(s).
â€¢ Assume Ï• : R â†’R is right-continuous and monotone increasing, possibly
with jumps. For any s âˆˆR the set
Es :=

x
 s â‰¤Ï•(x)

is either empty or a closed half-line or R. Accordingly, let Ïˆ(s) := min Es.
Trivially, Ïˆ(s) â‰¤t if and only if t âˆˆEs i.e. if and only if s â‰¤Ï•(t). Con-
sequently,

t
 t â‰¤Ïˆ(s)

=

t
 s â‰¤Ï•(t)

and we conclude that
FY(s) = FÏ•â—¦X(s) = FX(Ïˆ(s)).
(3.10)

RANDOM VARIABLES
79
The graph of s â†’Ïˆ(s) is obtained from the graph of Ï• by adding vertical
segments at the jump points and then looking at the resulting curve from
the vertical axis, see Figure 3.3. Clearly, if Ï• is continuous and invertible,
then Ïˆ(s) is ï¬nite on the range of Ï• and coincides with the inverse of Ï•.
The links between the distributions of X and Y := Ï• â—¦X given by (3.8) and
(3.9) may be cumbersome, as we have seen, if either Ï• has jumps or is not strictly
monotone. On the contrary, the relation between the relative integrals is much
more convenient. Let us state the main property.
Theorem 3.9 Let X :  â†’R be a random variable on a probability space
(, E, P). Then for every non-negative Borel-measurable function Ï• : R â†’R
we have
E [ Ï• â—¦X ] =
*

Ï•(X(x)) P(dx) =
*
R
Ï•(t) PX(dt).
(3.11)
Proof. Assume ï¬rst that Ï• is a simple function, Ï•(t) = n
i=1 ci1Ei(t),
where c1, . . . , cn are pairwise distinct real numbers and the sets Ei := {t âˆˆR |
Ï•(t) = ci} are events. Since

x âˆˆ | X(x) âˆˆEi

=

x âˆˆ | Ï• â—¦X(x) = ci

and by the deï¬nition of integral, we have
*
R
Ï•(t) PX(dt) =
n

i=1
ciPX(Ei) =
n

i=1
ciP(X âˆˆEi)
=
n

i=1
ci P(Ï• â—¦X = ci) =
*

Ï• â—¦X(x) P(dx),
hence the claim if Ï• is simple.
In the general case, let

Ï•k

be a monotone increasing sequence of simple
functions such that Ï•k â†‘Ï• pointwise. Then, from the above, for any integer k
we have
*
R
Ï•k(t) PX(dt) =
*

Ï•k(X(x)) P(dx).
Beppo Levi theorem allows us to pass to the limit in the previous equality as
k â†’âˆ, thus proving (3.11) for Ï•.
j
z
y
y(z)
Figure 3.3
The generalized inverse of Ï•.

80
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Corollary 3.10 Let X be a random variable on (, E, P). Then E [ X ] is well-
deï¬ned if and only if
.
R t PX(dt) exists and, in this case,
E [ X ] =
*
X(x) P(dx) =
* +âˆ
âˆ’âˆ
t PX(dt).
(3.12)
Proof. The claim trivially follows by applying (3.11) to X separately with
Ï•(t) = max {t, 0} and Ï•(t) = max {âˆ’t, 0}.
Corollary 3.10 shows in particular that the expectation of X depends only on
the distribution of values of X. There is no need to go back to the probability
space (, E, P) in order to compute the expectation of X. In particular, if
two random variables X and Y have the same distribution, PX = PY , then
E [ X ] = E [ Y ].
Theorem 3.9 yields a convenient formula for the distribution of a composition.
Corollary 3.11 (Composition) Let X be a random variable on (, E, P) and let
Ï• : R â†’R be a B(R)-measurable function. Then for every non-negative B(R)-
measurable function Ïˆ : R â†’R we have
*
R
Ïˆ(s) PÏ•â—¦X(ds) =
*
R
Ïˆ(Ï•(t))PX(dt).
(3.13)
Proof. By applying (3.11) to X with test function Ïˆ â—¦Ï• and to Ï• â—¦X with
test function Ïˆ we get
*
R
Ïˆ(s) PÏ•â—¦X(ds) =
*

Ïˆ(Ï•(X(x)) P(dx)
and
*
R
Ïˆ(Ï•(t))PX(dt) =
*

Ïˆ(Ï•(X(x)) P(dx),
respectively. The claim follows at once.
3.1.4
Cavalieri formula
Another interesting formula is the following consequence of the Cavalieri formula
(B.22):
E [ X ] =
* +âˆ
0
P(X > t) dt =
* +âˆ
0
(1 âˆ’FX(t)) dt
(3.14)
which holds for any non-negative random variable X. Applying (3.14) to X+
and Xâˆ’and summing, one gets
E [ X ] =
* +âˆ
0
(1 âˆ’FX(t)) dt âˆ’
* 0
âˆ’âˆ
FX(t) dt
(3.15)

RANDOM VARIABLES
81
provided X is summable, see Corollary B.24. Formula (3.15) shows again that
the expected value of a random variable X depends only on the distribution PX;
actually it shows how the expected value depends on the law of X. In particular
(3.15) yields E [ X ] = E [ Y ] if FX = FY.
Theorem 3.12 (Composition) Let X :  â†’R be a random variable on
(, E, P), let I be an interval such that I âŠƒX() and let Ï• : I â†’R be a
non-negative and monotone increasing function of class C1. Then
E [ Ï• â—¦X ] = mP() +
*
I
Ï•â€²(t)(1 âˆ’FX(t)) dt
(3.16)
where m := inftâˆˆI Ï•(t).
Proof. (i) Assume Ï• is strictly increasing. Let M := suptâˆˆI Ï•(t) so that
]m, M[âŠ‚Ï•(I) âŠ‚[m, M]. Notice that

x âˆˆ
 Ï• â—¦X(x) > s

=
â§
âªâªâ¨
âªâªâ©

if s â‰¤m, s /âˆˆÏ•(I),

x âˆˆ
 X(x) > Ï•âˆ’1(s)

if s âˆˆÏ•(I),
âˆ…
if s â‰¥M, s /âˆˆÏ•(I).
Therefore, applying the Cavalieri formula (3.15) to the random variable Ï• â—¦X
and then, changing variable with s = Ï•(t), t âˆˆI, we get
E [ Ï• â—¦X ] =
* âˆ
0
P(Ï• â—¦X > s) ds = mP() +
* M
m
P(X > Ï•âˆ’1(s)) ds
= mP() +
*
I
Ï•â€²(t)P(X > t) dt
= m P() +
*
I
Ï•â€²(t)(1 âˆ’FX(t)) dt.
(ii) When Ï• is not strictly monotone, consider a non-negative bounded, strictly
monotone function Ïˆ : I â†’R of class C1(I) with inftâˆˆI Ïˆ(t) = 0. Then Ï• + Ïˆ
is strictly monotone and (i) yields
E [ Ï• â—¦X ] + E [ Ïˆ â—¦X ] = E [ (Ï• + Ïˆ) â—¦X ]
= mP() +
*
I
(Ï•â€²(t) + Ïˆâ€²(t))(1 âˆ’FX(t)) dt,
E [ Ïˆ â—¦X ] =
*
I
Ïˆâ€²(t)(1 âˆ’FX(t)) dt.
The claim then follows by subtracting the second equality from the ï¬rst one since
E [ Ïˆ â—¦X ] is ï¬nite.

82
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
3.1.5
Variance
The expectation of a random variable X is a â€˜centralâ€™ value around which the
values of the range of X are distributed. Several indicators can be deï¬ned to
roughly describe the distribution of X around the expected value. For instance,
to evaluate how much of the range of X is dispersed (or concentrated) around the
expected value, a relevant indicator is the so-called variance of X deï¬ned as
Var [ X ] := E
%
(X âˆ’E [X])2 &
.
Of course, the variance is deï¬ned if and only if E [ |X| ] < +âˆ; moreover, in
this case, it may happen that Var [ X ] = +âˆ. The following formulas are easily
proven by using the linearity property of the expected value:
Var [ X ] = 0 if and only if X(x) = E [ X ] for P-a.e. x,
(3.17)
Var [ X ] = E
%
X2 âˆ’2E [X] X + E
%
X2& &
= E
%
X2 &
âˆ’(E [ X ])2,
(3.18)
Var [Î±X + Î²] = Î±2Var [ X ]
âˆ€Î±, Î² âˆˆR.
(3.19)
Finally, the number
Ïƒ(X) :=

Var [ X ].
(3.20)
is called the standard deviation of the random variable X. Notice that Ïƒ(X) is
positively homogeneous of degree 1, Ïƒ(Î»X) = |Î»| Ïƒ(X) âˆ€Î» âˆˆR.
3.1.6
Markov and Chebyshev inequalities
Proposition 3.13 Let X :  â†’R be a random variable on the probability space
(, E, P). Let I be an interval such that X() âŠ‚I and let Ï• : I â†’R be a non-
negative monotone increasing function of class C1. Then âˆ€t âˆˆI
Ï•(t) P(X â‰¥t) â‰¤E [ Ï• â—¦X ].
(3.21)
The inequality (3.21) is called Markov inequality. Moreover, if E[ |X| ] is
ï¬nite, then âˆ€t > 0 the Chebyshev inequality
P
X âˆ’E [ X ]
 â‰¥t

â‰¤Var [ X ]
t2
(3.22)
holds.
Proof. Let t âˆˆR. Since
{x âˆˆ | X(x) â‰¥t} âŠ‚{x âˆˆ | Ï•(X(x)) â‰¥Ï•(t)}
we have
Ï•(t)P(X â‰¥t) â‰¤Ï•(t)P

Ï• â—¦X â‰¥Ï•(t)

â‰¤
*
{Ï•â—¦Xâ‰¥Ï•(t)}
Ï•(X(x)) P(dx) â‰¤
*
Ï•(X(x)) P(dx),
i.e. Markov inequality.

RANDOM VARIABLES
83
Assume E [ |X| ] is ï¬nite. By applying Markov inequality to the random
variable x â†’|X(x) âˆ’E [ X ]| and the map Ï•(t) := t2 we get
P

|X âˆ’E [ X ]| â‰¥t

â‰¤1
t2 E
%
(X âˆ’E [X])2 &
= Var [ X ]
t2
,
that is, Chebyshev inequality.
3.1.7
Variational characterization of the median and of the
expected value
Deï¬nition 3.14 Let X :  â†’R be a random variable on a probability space
(, E, P). The real number
tM := inf

t
 FX(t) â‰¥1/2

.
is called the median of the distribution PX.
From the deï¬nition and the right-continuity of FX, we get
FX(tM) â‰¥1/2
and
P(X < tM) = lim
tâ†’tâˆ’
M
FX(t) â‰¤1/2.
Trivially, FX(tM) = 1/2 if FX is continuous at tM.
Proposition 3.15 Let X :  â†’R be a random variable on a probability space
(, E, P) with E [ |X| ] < +âˆ. Then tM is a minimum point of the function
Ï†(s) :=
*

|X(x) âˆ’s| P(dx),
s âˆˆR.
Proof. Let s < tM. Let us prove that Ï†(s) â‰¥Ï†(tM).
Ï†(s) =
*
{X(x)â‰¤s}
(s âˆ’X(x)) P(dx) +
*
{X(x) > s}
(X(x) âˆ’s) P(dx)
=
*
{X(x)â‰¤s}
(tM âˆ’X(x)) P(dx) +
*
{X(x)â‰¤s}
(s âˆ’tM) P(dx)
+
*
{s<X(x)â‰¤tM}
(X(x) âˆ’tM) P(dx) +
*
{s<X(x)â‰¤tM}
(tM âˆ’s) P(dx)
+
*
{X(x) > tM}
(X(x) âˆ’tM) P(dx) +
*
{X(x) > tM}
(tM âˆ’s) P(dx)

84
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
=
*
|X(x) âˆ’tM| P(dx) âˆ’2
*
{s<X(x)â‰¤tM}
(tM âˆ’X(x)) P(dx)
+ (tM âˆ’s)

âˆ’P(X â‰¤s) + P(s < X â‰¤tM) + P(X > s)

â‰¥Ï†(tM) âˆ’2(tM âˆ’s)P(s < X â‰¤tM)
+ (tM âˆ’s)

âˆ’P(X â‰¤s) + P(s < X â‰¤tM) + P(X > tM)

= Ï†(tM) + (tM âˆ’s)

âˆ’P(X â‰¤s) âˆ’P(s < X â‰¤tM) + 1 âˆ’P(X â‰¤tM)

= Ï†(tM) + (tM âˆ’s)

1 âˆ’2P(X â‰¤tM)

â‰¥Ï†(tM).
Similarly, one shows that Ï†(s) â‰¥Ï†(tM) if s > tM.
Proposition 3.16 Let X :  â†’R be a random variable on the probability space
(, E, P) with E [ |X| ]) < +âˆand Var [ X ] < +âˆ. Then E [ X ] is the unique
minimizer of the function
Ï†(s) :=
*

|X(x) âˆ’s|2 P(dx),
s âˆˆR.
Proof. The function s â†’Ï†(s) = E
%
X2 &
âˆ’2 s E [ X ] + s2 is a polynomial
of degree two. Therefore, Ï†(s) has a unique minimizer at E [ X ].
3.1.8
Exercises
For the readerâ€™s convenience the main deï¬nitions and formulas given in this
chapter are summarized in Figures 3.4â€“3.6.
Exercise 3.17 The life of a bulb (measured in days) is a random variable X with
an absolute continuous distribution of density
f (x) =
â§
â¨
â©
0
if x < 100,
3 Â· 106
x4
if x â‰¥100.
Compute the expected value of X.
[150]
Exercise 3.18 Let X be a random variable. Compute the law FX2 of the random
variable X2. Moreover, assuming that PX is absolutely continuous with density
ÏX(t), show that PX2 is absolutely continuous by computing its density.

RANDOM VARIABLES
85
Random variables
A random variable X on the probability space (, E, P) is an E-measurable
function X :  â†’R. Then its distribution, law, expected value and variance
are deï¬ned by
PX(A) := P(X âˆˆA)
âˆ€A âˆˆB(R),
FX(t) := P(X â‰¤t) = PX([âˆ’âˆ, t]),
E [ X ] :=
*

X(x) P(dx) =
* +âˆ
âˆ’âˆ
t PX(dt),
=
* +âˆ
0
(1 âˆ’FX(t)) dt âˆ’
* 0
âˆ’âˆ
FX(t) dt,
Var[X] := E
%
(X âˆ’E [X])2 &
= E
%
X2 &
âˆ’E [ X ]2,
respectively.
Composition formulas
Let X be a random variable on the probability space (, E, P), let Ï• : R â†’R
be a continuous function and let Y = Ï• â—¦X. Then
â€¢ PY (A) = PX(Ï•âˆ’1(A))
âˆ€A âˆˆB(R),
â€¢ FY(s) =

FX(t)
if Ï• is strictly increasing,
1 âˆ’FX(tâˆ’)
if Ï• is strictly decreasing, ,
t = Ï•âˆ’1(s)
â€¢ E [ Y ] =
. +âˆ
âˆ’âˆs PY (ds) =
. +âˆ
âˆ’âˆÏ•(t) PX(dt),
â€¢
.
Ïˆ(s) PY (ds) =
.
Ïˆ(Ï•(t)) PX(dt).
If Ï• âˆˆC1(R) is strictly monotone and PX is absolutely continuous, PX(ds) =
ÏX(s) ds, then also PY is absolutely continuous and
PY (ds) = ÏY(s) dx,
where
ÏY(s) = ÏX(t)
|Ï•â€²(t)|,
t = Ï•âˆ’1(s).
Figure 3.4
Random variables.
Solution. Since
FX2(t) = P(X2 â‰¤t) =

0
if t < 0,
P(âˆ’âˆšt â‰¤X â‰¤âˆšt)
if t â‰¥0.

86
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Random variables with discrete distribution
A random variable X is in this class if PX is a discrete measure concentrated
at {tj}. The sequence p = (pj) where
pj := PX(

tj

) = P(X = tj),
j = 1, . . . ,
is the density, or mass density function, of PX, from which the basic quantities
of distribution PX, law FX(t), expected value E [ X ] and variance Var[X] can
be computed as follows:
PX(A) =

tj âˆˆA
P(X = tj),
FX(t) =

tj â‰¤t
P(X = tj),
*
R
Ï•(t) PX(dt) =

j
Ï•(tj)P(X = tj),
E [ X ] =

j
tjP(X = tj),
Var[X] =

j
(tj âˆ’E [ X ])2P(X = tj).
Moreover, if the range of X is integer valued, then
E [ X ] =
âˆ

k=0
P(X > k) âˆ’
0

kâˆ’âˆ
P(X < k).
Figure 3.5
A few formulas relative to discrete random variables.
For every t > 0 we have
FX2(t) = P(âˆ’
âˆš
t â‰¤X â‰¤
âˆš
t) = FX(
âˆš
t) âˆ’FX(âˆ’
âˆš
t) + P(X =
âˆš
t).
Assume now that PX(dt) = ÏX(t) dt. Then for every t â‰¥0 we have
FX2(t) =
* âˆšt
âˆ’âˆ
Ï(s) ds âˆ’
* âˆ’âˆšt
âˆ’âˆ
Ï(s) ds =
* 0
âˆ’âˆšt
Ï(s) ds +
* âˆšt
0
Ï(s) ds
=
* t
0
Ï(âˆšÏƒ)
2âˆšÏƒ dÏƒ +
* t
0
Ï(âˆ’âˆšÏƒ)
2âˆšÏƒ
dÏƒ,

RANDOM VARIABLES
87
Random variables with absolutely continuous distribution
The distribution PX of a random variable X :  â†’R deï¬ned on a probability
space (, E, P) is said to be absolutely continuous if there exists a non-
negative L1-summable function fX : R â†’R such that
PX(A) =
*
A
fX(t) dt
âˆ€A âˆˆB(R)
or, equivalently, if the law FX is such that
FX(t) =
* t
âˆ’âˆ
fX(s) ds
âˆ€t âˆˆR.
The function fX is called the density of PX (with respect to the Lebesgue
measure). If PX(ds) = fX(s) ds, then
â€¢ FX is an absolutely continuous function,
â€¢ FX(t) is differentiable at a.e. t âˆˆR and F â€²
X(t) = fX(t) at a.e. t,
â€¢ if fX âˆˆC0(R) then FX âˆˆC1(R) and F â€²
X(t) = fX(t) âˆ€t,
â€¢ E [ X ] =
.
R t fX(t) dt,
â€¢ Var[X] =
.
R(t âˆ’E [ X ])2fX(t) dt =
.
R t2fX(t) dt âˆ’(E [ X ])2,
â€¢ for every Borel-measurable function Ï• : R â†’R
*
R
Ï•(t) PX(dt) =
*
R
Ï•(t)fX(t) dt.
Figure 3.6
A few formulas relative to absolutely continuous random variables.
hence PX2 is absolutely continuous, PX2(dt) = Ï„(t) dt, where
Ï„(t) :=

0
if t < 0,
Ï(âˆšt)+Ï(âˆ’âˆšt)
2âˆšt
if t > 0.
Exercise 3.19 Let X be a random variable. Compute the law of the random
variable Y := Î±X + Î² where Î±, Î² âˆˆR, Î± Ì¸= 0. Assuming PX to be absolutely
continuous of density Ï, PX(dt) = Ï(t) dt, show that PY is also absolutely con-
tinuous by computing its density.
Solution. We proceed by computing the law of Y. We have
FY(t) = P(Î±X + Î² â‰¤t) =
â§
â¨
â©
P

X â‰¤tâˆ’Î²
Î±

if Î± > 0,
P

X â‰¥tâˆ’Î²
Î±

if Î± < 0,

88
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
hence
FY(t) =
â§
â¨
â©
FX

tâˆ’Î²
Î±

if Î± > 0,
1 âˆ’FX

tâˆ’Î²
Î±

+ P

X = tâˆ’Î²
Î±

if Î± < 0.
Assume now PX(dt) = Ï(t) dt. If Î± > 0, then changing variable with
u = Î±s + Î², we get
FY (t) = FX
t âˆ’Î²
Î±

=
*
tâˆ’Î²
Î±
âˆ’âˆ
Ï(s) ds =
* t
âˆ’âˆ
Ï
u âˆ’Î²
Î±
 1
Î± du
i.e. PY (dt) = 1
Î±Ï

tâˆ’Î²
Î±

dt. If Î± < 0, then Î±X + Î² â‰¤t if and only if X â‰¥tâˆ’Î²
Î± ,
consequently, changing variable with u = Î±s + Î²
FY (t) = 1 âˆ’FX
t âˆ’Î²
Î±

=
* +âˆ
tâˆ’Î²
Î±
Ï(s) ds
=
* âˆ’âˆ
t
u âˆ’Î²
Î±
 1
Î± du = âˆ’
* t
âˆ’âˆ
u âˆ’Î²
Î±
 1
Î± du
i.e. PY (dt) = âˆ’1
Î± Ï

tâˆ’Î²
Î±

dt. The two cases above can be summarized to
PY(dt) = 1
|Î±|Ï
t âˆ’Î²
Î±

dt
if
PX(dt) = Ï(t) dt.
Exercise 3.20 Let X be a random variable with PX(dt) = r(t) dt and let
f : R â†’R be a strictly monotone function of class C1(R). Show that
f â—¦X
is
also
absolutely
continuous,
Pf â—¦X(dt) = s(t) dt,
with
density
s(t) = r(w)/|f â€²(w)|, w = f âˆ’1(t).
Solution. For any non-negative Borel-measurable function Ï• : R â†’R
we have
*
R
Ï•(s) Pf â—¦X(ds) =
*
R
Ï•(f (t)) PX(dt)
=
*
R
Ï•(f (t)) r(t) dt =
*
R
Ï•(s)r(f âˆ’1(s))
1
|f â€²(f âˆ’1(s))| ds.
In order to get the last equality, we substituted s = f (t), so that t = f âˆ’1(s) and
dt = (f âˆ’1)â€²(s) ds = 1/|f â€²(f âˆ’1(s))| ds. Therefore,
Pf â—¦X(ds) =
r(w)
|f â€²(w)| ds,
w = f âˆ’1(s).
since Ï• is arbitrary.

RANDOM VARIABLES
89
FX
1
0.5
1
2
Figure 3.7
The law in Exercise 3.22.
Exercise 3.21 Let X(x) be the life (measured in years) of a battery, rounded to
an integer. Assume that the density of PX is given by
pX(k) = PX({k}) =

0.2
if 3 â‰¤k â‰¤7,
0
otherwise.
Compute:
(i) The probability that a 3-years-old battery is still working.
(ii) The probability that a battery which is at least 3 years old is still working.
(iii) The probability that the battery is working a further 3 years even if it has
already been working for 5 years.
Exercise 3.22 Assume Figure 3.7 represents the graph of the law of a random
variable X. Compute E [ X ], Var [ X ] and P(X â‰¤0.8).
Exercise 3.23 Let the real-valued random variable X be uniformly distributed in
[0, 1]. Compute the law of Y = max {X âˆ’0.5, 0}.
Exercise 3.24 Show that for any real valued random variable X
E
%
X+
&
=
* +âˆ
0
(1 âˆ’FX(s)) ds,
E
%
|X|p &
= p
* +âˆ
0
tpâˆ’1(1 âˆ’FX(s)) ds.
As usual, X+ := max {X, 0}.
Exercise 3.25 Show that for any random variable X :  â†’R the following equal-
ities hold:
E [ max {X, 0} ] =
* +âˆ
0
|t| PX(dt),

90
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
E [ min {X, 0} ] =
* 0
âˆ’âˆ
|t| PX(dt),
E [ |X| ] =
* +âˆ
âˆ’âˆ
|t| PX(dt),
(3.23)
E
%
|X|p &
=
* +âˆ
âˆ’âˆ
|t|p PX(dt)
âˆ€p â‰¥0.
Exercise 3.26 Let X :  â†’R be a discrete random variable. Prove the following
inequalities.
E [ max {X, 0} ] =

yâˆˆX(),yâ‰¥0
yP(X = y),
E [ min {X, 0} ] =

yâˆˆX(),yâ‰¤0
yP(X = y),
E [ |X| ] =

yâˆˆX()
|y|P(X = y),
E
%
|X|p &
=

yâˆˆX()
|y|pP(X = y).
(3.24)
Exercise 3.27 Let X :  â†’R be a random variable and let Ï• : [a, b] â†’R be
a strictly monotone increasing function of class C1([a, b]). Prove the integration
by parts formula:
* b
a
Ï•â€²(t)FX(t) dt +
*
]a,b]
Ï•(t) PX(dt) = Ï•(b)FX(b) âˆ’Ï•(a)FX(a).
(3.25)
Solution. Let EÏ„ :=

t âˆˆR
 Ï•(t)1]a,b](t) > Ï„

. Cavalieri formula (B.22)
yields
*
]a,b]
Ï•(t) PX(dt) =
*
R
Ï•(t)1]a,b](t) PX(dt) =
* +âˆ
0
PX(EÏ„) dÏ„.
(3.26)
Since
EÏ„ =

t âˆˆ]a, b]
 Ï•(t) > Ï„

=
â§
âªâ¨
âªâ©
]a, b]
if Ï„ â‰¤Ï•(a),
]Ï•âˆ’1(Ï„), b]
if Ï•(a) < Ï„ â‰¤b,
âˆ…
if Ï„ > Ï•(b),
we get
PX(EÏ„) =
â§
âªâ¨
âªâ©
FX(b) âˆ’FX(a)
if 0 < Ï„ â‰¤Ï•(a),
FX(b) âˆ’FX(Ï•âˆ’1(Ï„))
if Ï•(a) < Ï„ â‰¤Ï•(b),
0
if Ï„ > Ï•(b).

RANDOM VARIABLES
91
Thus
* âˆ
0
PX(EÏ„) dÏ„ =
* Ï•(a)
0

FX(b) âˆ’FX(a)

dÏ„
+
* Ï•(b)
Ï•(a)

FX(b) âˆ’FX(Ï•âˆ’1(Ï„))

dÏ„
= Ï•(a)(FX(b) âˆ’FX(a))
+ FX(b)(Ï•(b) âˆ’Ï•(a)) âˆ’
* b
a
Ï•â€²(s)FX(s) ds
= FX(b)Ï•(b) âˆ’Ï•(a)FX(a) âˆ’
* b
a
Ï•â€²(s)FX(s) ds.
The last equality and (3.26) yield the claim.
3.2
A few discrete distributions
3.2.1
Bernoulli distribution
The Bernoulli distribution of parameter p, 0 â‰¤p â‰¤1, is the probability measure
B(p) supported on the two points set {0, 1} whose density is
B(p)({0}) = 1 âˆ’p,
B(p)({1}) = p.
The expectation and the variance of random variables X such that PX = B(p) are
E [ X ] = p
and
Var [ X ] = p(1 âˆ’p),
(3.27)
respectively.
Any random variable X whose range is the two points set {0, 1} has a
Bernoulli type distribution B(p) with p := P(X = 1). These random variables
are called Bernoulli trials of parameter p. For instance let (, E, P) be a prob-
ability space and E âˆˆE. The characteristic function 1E(x) is a Bernoulli trial of
parameter P(E) since

x âˆˆ | 1E(x) = 1

= E.
3.2.2
Binomial distribution
The binomial distribution B(n, p) of parameters n and p, n â‰¥1, 0 â‰¤p â‰¤1, is
the measure supported on the n + 1 points set {0, . . . , n} of density
B(n, p)({k}) =
n
k

pk(1 âˆ’p)nâˆ’k,
0 â‰¤k â‰¤n.
B(n, p) is a probability measure since the Newton binomial formula yields

k
B(n, p)({k}) =
n

k=0
n
k

pk(1 âˆ’p)nâˆ’k = (p + 1 âˆ’p)n = 1.

92
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
The expected value and the variance of a random variable X such that PX =
B(n, p) are
E [ X ] = np
and
Var [ X ] = np(1 âˆ’p),
(3.28)
respectively.
Let us prove (3.28). For p = 0 or 1, (3.28) is trivial. Assume 0 < p < 1 and
let z := p/(1 âˆ’p). From (iv) of Figure 1.4, we infer
E [ X ] =
n

k=0
k
n
k

pk(1 âˆ’p)nâˆ’k
= (1 âˆ’p)n
n

k=0
k
n
k

zk = (1 âˆ’p)nnz(1 + z)nâˆ’1 = np;
moreover, (v) of Figure 1.4 yields
E
%
X2 &
=
n

k=0
k2
n
k

pk(1 âˆ’p)nâˆ’k = (1 âˆ’p)n
n

k=0
k2
n
k

zk
= (1 âˆ’p)nnz(1 + z)nâˆ’2(1 + nz) = np(1 âˆ’p + np),
hence
Var [ X ] = E
%
X2 &
âˆ’E [ X ]2 = np(1 âˆ’p + np) âˆ’n2p2 = np(1 âˆ’p).
Example 3.28 Consider n â€˜independentâ€™ random trials of parameter p,
0 â‰¤p â‰¤1. Each sequence x of outcomes can be arranged as n-tuple of
zeros and ones, a n-byte, x = (x1, . . . , xn). We already know that any such
sequence has probability pk(1 âˆ’p)nâˆ’k, see Section 2.2.5, therefore we model n
â€˜independentâ€™ trials as the probability space (, E, P) where the sample space is
 = {0, 1}n, E = P() and P is deï¬ned by its density, P({x}) := pk(1 âˆ’p)nâˆ’k
if x has k ones and n âˆ’k zeros.
Let X : {0, 1}n â†’N be the random variable counting the number of suc-
cesses, i.e. the function that for each n-byte x returns the number of ones in it.
Then for every k = 0, 1, . . . ,
P(X = k) =
n
k

pk(1 âˆ’p)nâˆ’k
(3.29)
since there are
n
k

n-bytes with exactly k ones and all of them have probability
pk(1 âˆ’p)nâˆ’k. Therefore, the distribution of X is the binomial one of parameters
n and p, PX = B(n, p) for short.
3.2.2.1
Graph of the binomial distribution
As k increases from 0 to n âˆ’1, the quotient
B(n, p)({k + 1})
B(n, p)({k})
=
p
1 âˆ’p
n âˆ’k
k + 1
(3.30)

RANDOM VARIABLES
93
B(30, 0.8)
B(30, 0.2)
30
25
20
15
10
5
0
30
25
20
15
10
5
0
0.3
0.25
0.15
0.05
âˆ’0.05
0.2
0.1
0
âˆ’0.2
0
1.2
1
0.8
0.6
0.4
0.2
B(30, 0.8)
B(30, 0.2)
(a)
(b)
Figure 3.8
(a) The densities and (b) the laws of two binomial distributions.
decreases from
p
1âˆ’pn to
p
1âˆ’p
1
n. Thus,
(i) if n p
1âˆ’p < 1, then k â†’B(n, p)({k}) is monotone decreasing,
(ii) if 1
n
p
1âˆ’p > 1, then k â†’B(n, p)({k}) is monotone increasing,
(iii) if 1
n
p
1âˆ’p < 1 <
p
1âˆ’pn, then there exists k such that k â†’B(n, p)({k}) is
strictly increasing on 0, . . . , k âˆ’1 and strictly decreasing on k, . . . , n. By
(3.30), k is the smallest integer greater than the solution of
p
1âˆ’p
nâˆ’k
k+1 = 1,
that is the smallest integer greater than np âˆ’1 + p.
The densities and the laws of two binomial distributions are plotted in
Figure 3.8.
3.2.3
Hypergeometric distribution
Let w, r be non-negative and let 0 â‰¤n â‰¤w + r. The hypergeometric distribution
H(w, r, n) of parameters w, r and n is the discrete measure whose density is
p(k) = H(w, r, n)({k}) :=
w
k
 r
nâˆ’k

w+r
n
 ,
k = 0, 1, . . . , n.
H(w, r, n) is a probability measure since

k
H(w, r, n)({k}) =
n

k=0
w
k
 r
nâˆ’k

w+r
n

= 1
by the Vandermonde formula (A.5).
Of course, p(k) Ì¸= 0 only if 0 â‰¤k â‰¤w and n âˆ’r â‰¤k â‰¤n, so that H(w, r, n)
is supported on the integers between max {0, n âˆ’r} and min {w, n}.

94
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
One can prove, see Exercise 4.10, that the expected value and the variance
of any random variable X with PX = H(w, r, n) are
E [ X ] =
nw
w + r
and
Var [ X ] =
nwr
(w + r)2

1 âˆ’
n âˆ’1
w + r âˆ’1

,
(3.31)
respectively.
Here we only want to point out that X has the same expected value as
a random variable with binomial distribution B(n, p) where p := w/(w + r).
Moreover, when (w + r)/n â†’âˆ, that is, when the ratio between the total num-
ber of balls inside the urn and the number of drawings becomes larger and larger,
then the variance Var [ X ] of X converges to np(1 âˆ’p), i.e. to the variance of a
variable with binomial distribution B(n, p). Note that B(n, p) is also the distribu-
tion of the random variable that counts the number of drawn white balls when we
draw in sequence n balls reinserting each extracted ball before drawing the next.
Example 3.29 Assume we have an urn containing w distinguishable white balls
and r distinguishable red balls. We extract (without replacement) n balls. Con-
sider the probability space (, E, P) where the sample space  is the set of
all admissible drawings, i.e. of the n-words made of symbols chosen among w
white balls and r red balls, E = P() and P is the uniform probability on  of
density 1/
w+r
n

.
Trivially, the random variable X(x) from  into N that counts the number
of white balls in the drawn sequence x of n balls follows the distribution PX =
H(w, r, n). In fact, for any k, the number of drawings with k white balls and
n âˆ’k red balls is
w
k
 r
nâˆ’k

.
3.2.4
Negative binomial distribution
Let n â‰¥1 and p âˆˆ[0, 1]. The negative binomial or Pascal distribution B(âˆ’n, p)
is the measure supported on non-negative integers of density
B(âˆ’n, p)({k}) :=
n + k âˆ’1
k

pn(1 âˆ’p)k,
âˆ€k â‰¥0.
Since
âˆ

k=0
B(âˆ’n, p)({k}) =
âˆ

k=0
n + k âˆ’1
k

pn(1 âˆ’p)k = pn
âˆ

k=0
âˆ’n
k

(p âˆ’1)k
=
pn
(1 + p âˆ’1)n = 1,
see Proposition 1.2, B(âˆ’n, p) is a probability measure.
The expected value and the variance of a random variable X with PX =
B(âˆ’n, p) are given by
E [ X ] = n1 âˆ’p
p
and
Var [ X ] = n1 âˆ’p
p2
,
(3.32)

RANDOM VARIABLES
95
respectively. We have
E [ X ] = pn
âˆ

k=0
k
âˆ’n
k

(p âˆ’1)k
= âˆ’npnz(1 + z)nâˆ’1 = âˆ’npn(p âˆ’1)pâˆ’nâˆ’1 = n1 âˆ’p
p
from (iv) of Figure 1.4 with z := p âˆ’1; moreover, from (v) of Figure 1.4 again
with z := p âˆ’1, we get
E
%
X2 &
= pn
âˆ

k=0
k2
âˆ’n
k

(p âˆ’1)k
= âˆ’npnz(1 âˆ’nz)(1 + z)âˆ’nâˆ’2 = 1 âˆ’p
p2
(1 + n âˆ’np),
hence
Var [ X ] = E
%
X2 &
âˆ’E [ X ]2 = 1 âˆ’p
p2
(1 + n âˆ’np) âˆ’n2 (1 âˆ’p)2
p2
= n1 âˆ’p
p2
.
Example 3.30 Consider a denumerable sequence of Bernoulli trials. Each out-
come is a binary sequence. Consider the function T that counts the number of
failures before the nth success. T is a discrete random variable with values in
the set of non-negative integers. We claim that PT = B(âˆ’n, p).
Let En,k be the set of sequences of n + k trials with k zeroes and n ones,
and with a one at the (n + k)th trial. Then, trivially, P(T = k) = P(En,k). The
cardinality of En,k is
n+kâˆ’1
nâˆ’1

=
n+kâˆ’1
k

, i.e. the number of n + k âˆ’1 draw-
ings with n âˆ’1 ones and k zeroes, and each sequence in En,k has probability
(1 âˆ’p)kpn, see Section 2.2.5. Therefore,
PT ({k}) :=
n + k âˆ’1
k

(1 âˆ’p)kpn = B(âˆ’n, p)({k}),
thus concluding that PT = B(âˆ’n, p).
The densities and the laws of two negative binomial distributions are plotted
in Figure 3.9.
3.2.5
Poisson distribution
The Poisson distribution P(Î») of parameter Î» > 0 is the measure supported on
the non-negative integers of mass density
P(Î»)({k}) := Î»k
k! eâˆ’Î».
(3.33)

96
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
20
15
10
5
0
âˆ’0.2
1.2
1
0.8
0.6
0.4
0.2
0
20
15
10
5
0
âˆ’0.05
0
0.05
0.1
0.2
0.15
(a)
(b)
B(âˆ’20, 0.8)
B(âˆ’10, 0.5)
B(âˆ’20, 0.8)
B(âˆ’10, 0.5)
Figure 3.9
(a) The densities and (b) the laws of two negative binomial distribu-
tions.
P(Î») is a probability measure since
âˆ

k=0
P(Î»)({k}) = eâˆ’Î»
âˆ

k=0
Î»k
k! = eâˆ’Î»eÎ» = 1.
The mean and the variance of a random variable X such that PX = P(Î») are
given by
E [ X ] = Î»
and
Var [ X ] = Î»,
(3.34)
respectively. The proof is elementary.
Poisson distribution approximates B(n, Î»/n) for large n. More precisely, the
following holds.
Proposition 3.31 (Rare events property) Let Î» âˆˆR+ and let

pn

be a non-
negative sequence such that npn â†’Î». Then, for any k âˆˆN
B(n, pn)({k}) âˆ’â†’

P(Î»)({k})
if 0 < Î» < +âˆ,
0
if Î» = 0, +âˆ
as n â†’âˆ.
(3.35)
Proof. Since
B(n, pn)({k}) =
n
k

pk
n(1 âˆ’pn)nâˆ’k
= n(n âˆ’1) Â· Â· Â· (n âˆ’k + 1)
k!nk
(npn)k(1 âˆ’pn)nâˆ’k
=: n(n âˆ’1) Â· Â· Â· (n âˆ’k + 1)
k!nk
hn
(3.36)

RANDOM VARIABLES
97
and n(nâˆ’1)Â·Â·Â·(nâˆ’k+1)
nk
â†’1 as n â†’âˆ, it sufï¬ces to compute the limit of hn, or,
equivalently, of
log hn = k log(npn) + (n âˆ’k) log(1 âˆ’pn)
= npn

k log(npn)
npn
+

1 âˆ’k
n
log(1 âˆ’pn)
pn

.
If Î» < +âˆ, then pn â†’0. Since log(1âˆ’x)
x
â†’âˆ’1 as x â†’0, we get
log hn â†’k log Î» âˆ’Î»,
i.e.
hn â†’Î»keâˆ’Î»
as n â†’âˆ. This proves (3.36) for ï¬nite Î». If Î» = +âˆ, recalling that log x/x â†’0
as x â†’+âˆand log(1 âˆ’x)/x â‰¤âˆ’1 for any 0 < x < 1, we get that log hn â†’
âˆ’âˆ, so that hn â†’0.
Remark 3.32 Actually, we have just proved that if njpnj â†’Î» for some subse-
quence {pnj } of {pn}, then
B(nj, pnj )({k}) âˆ’â†’

P(Î»)(k)
if 0 < Î» < +âˆ,
0
if Î» = 0, +âˆ
as j â†’âˆ.
Remark 3.33 Using McLaurin expansions
n(n âˆ’1) Â· Â· Â· (n âˆ’k + 1)
nk
= 1 âˆ’k(k âˆ’1)
2n
+ O
 1
n2

,

1 âˆ’Î»
n
n
= eâˆ’Î» + eâˆ’Î» Î»2
n + O
 1
n2

one easily estimates the relative error: we have
B(n, Î»/n)({k}) âˆ’P(Î»)({k})
 â‰¤P(Î»)({k})(k + Î»)2
n
.
P(Î») is known as the distribution of rare events. In fact, many counting
problems can be seen as the counting of the number of successes in n
â€˜independentâ€™ trials with n large and the probability of success in each trial,
p, small.
Example 3.34 Assume a public service (such as the emergency services) receives
â€“ on averageâ€“ Î» calls per day. Assume there are n possible users and that they
call the service independently of the others. The number of daily calls thus follows
a binomial distribution B(n, p), where p is unknown. Since the expected value
of B(n, p) is np, we can assume p = Î»/n. Thus, for large n, the probability that
the service gets k daily calls is approximately P(Î»)({k}) = Î»k
k! eâˆ’Î».
Events randomly distributed in time or space that can be modelled by means of
a Poisson distribution with good approximation appear in many different contexts.

98
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
For instance, the number of calls per hour a callcentre receives, the number of
cars passing through a toll gate at a certain time of the day, the number of
car accidents that occur on a certain stretch of road on a public holiday, the
number of ï¬‚aws in a certain length of yarn produced by a textile machine, and
the number of wrong notes played per hour by a musician during a concert are
possible examples.
Example 3.35 Assume a machine is subject to an average number Î» of
breakdowns per unit time; assume also the average number of breakdowns
is proportional to the observation time. Thus, in an arbitrary time interval
[s, s + t], the average number of breakdowns is Î»t.
Let us divide the interval [0, t] in to N intervals I1, . . . , IN of equal length.
Assume:
â€¢ the probability that a breakdown occurs in the interval Ii is p = Î»t/N;
â€¢ the probability that two or more breakdowns occur in any of the intervals
Ii is negligible with respect to p;
â€¢ the events Xi, â€˜a breakdown occurs during the interval Iiâ€™ are independent,
so that the distribution of the random variable N
i=1 Xi that counts the num-
ber of breakdowns in the interval [0, t] is the binomial one, B(N, Î»t/N).
If the assumptions stated above hold for any large enough N, then the prob-
ability that k breakdowns occur in the time interval [0, t] is approximately
P(Î»t)({k}) = Î»ktk
k! eâˆ’Î»t.
For a precise statement and further details see Section 6.1.
The densities and the laws of a binomial distribution and of a Poisson one
are plotted in Figure 3.10.
3.2.6
Geometric distribution
The geometric distribution of parameter p, 0 < p < 1, is the probability measure
G(p) supported on positive integers of density
G(p)({k}) := (1 âˆ’p)kâˆ’1p,
âˆ€k â‰¥1.
Thus
FG(p)(t) =

1â‰¤kâ‰¤t
(1 âˆ’p)kâˆ’1p = 1 âˆ’(1 âˆ’p)[t].
The expected value and the variance of a random variable X with geometric
distribution, PX = G(p) are
E [ X ] = 1
p
and
Var [ X ] = (1 âˆ’p)
p2
,
(3.37)

RANDOM VARIABLES
99
P(15)
P(15)
âˆ’0.05
0
0.05
0.1
0.2
0.15
20
30
15
25
10
5
0
20
30
15
25
10
5
0
âˆ’0.2
1.2
1
0.8
0.6
0.4
0.2
0
(a)
(b)
B(30, 0.5)
B(30, 0.5)
Figure 3.10
(a) The densities and (b) the laws of the binomial distribution
B(30, 0.5) and of the Poisson distribution P(15), respectively.
respectively. To show the former, apply formula (i) of Figure 1.4 with
z = 1 âˆ’p; we get
E [ X ] =
âˆ

k=1
kG(p)({k}) =
p
1 âˆ’p
âˆ

k=1
k(1 âˆ’p)k =
p
1 âˆ’p
1 âˆ’p
p2
= 1
p.
For the latter, apply formula (ii) of Figure 1.4 with z = 1 âˆ’p to get
E
%
X2 &
=
âˆ

k=0
k2p(1 âˆ’p)kâˆ’1 = p2 âˆ’p
p3
,
hence
Var [ X ] = E
%
X2 &
âˆ’E [ X ]2 = 2 âˆ’p
p2
âˆ’1
p2 = 1 âˆ’p
p2
.
Example 3.36 Let the random variable T describe the waiting time for the ï¬rst
success in a Bernoulli process of parameter p, 0 < p < 1,
T (x) := min

n
 x = (xk), x1 = Â· Â· Â· = xnâˆ’1 = 0, xn = 1

,
where T (x) = +âˆif success never occurs, i.e. if x = (xn) is such that xn = 0
âˆ€n. The distribution of the random variable X is the geometric one G(p). In
fact, in Section 2.2.5 we observed that
P(T = +âˆ) = P({0, 0, . . . }) = 0
and
P(T = k) = P({(0, 0, . . . , 0



kâˆ’1
, 1)}) = (1 âˆ’p)kâˆ’1p.

100
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
One can consider also the shifted geometric distribution deï¬ned on the non-
negative integers
Gâ€²(p)({k}) := p(1 âˆ’p)k
âˆ€k â‰¥0.
(3.38)
For instance, the random variable that counts the number of failures before the
ï¬rst success in a Bernoulli process of parameter p has this type of distribution.
The densities of both G(p) and Gâ€²(p) are geometric sequences.
3.2.6.1
Memorylessness
An important feature of random variables with discrete geometric distribution is
the memoryless property.
Deï¬nition 3.37 Let X be a non-negative, integer valued random variable on a
probability space (, E, P). We say that X has the memoryless property if
P

X â‰¤i + j
 X â‰¥j

= P(X â‰¤i)
âˆ€i, j âˆˆN.
(3.39)
We have the following.
Theorem 3.38 Let X be a non-negative random variable with discrete distribution
supported on N and assume that p := PX(X = 0) is such that 0 < p < 1. Then
X is a discrete memoryless random variable if and only if PX = Gâ€²(p).
Proof. Suppose that PX = Gâ€²(p) with 0 < p < 1. Then for every k â‰¥0,
P(X = k) = p(1 âˆ’p)k, hence we have P(X = 0) = p and, moreover, for every
i, j â‰¥0
P(X â‰¤i) = p
i

k=0
(1 âˆ’p)k,
P(j â‰¤X â‰¤i + j) =
j+i

k=j
p(1 âˆ’p)k
= p(1 âˆ’p)j
i
k=0
(1 âˆ’p)k = (1 âˆ’p)jP(X â‰¤i)
P(X â‰¥j) = p
âˆ

k=j
(1 âˆ’p)k = p(1 âˆ’p)j
1
1 âˆ’(1 âˆ’p) = (1 âˆ’q)j,
from which (3.39) follows.
Let us prove the converse. For k = 0, 1, . . . , let xk := P(X = k) be the den-
sity of PX at k. We ï¬rst infer from (3.39) that P(X = 0) < 1 since P(X â‰¥j) > 0

RANDOM VARIABLES
101
for all non-negative integers j, and that P(X = 0) > 0 since otherwise
P(X = j) = 0 âˆ€j. Memorylessness property (3.39) with i = 0 yields
P(X = j)
P(X â‰¥j) = P(X = 0)
âˆ€j
i.e.
xj = x0
âˆ

k=j
xk
âˆ€j â‰¥0.
Subtracting from the previous formula a similar formula with j replaced by
j + 1, we get xj âˆ’xj+1 = x0xj, i.e.
xj+1 = xj(1 âˆ’x0)
âˆ€j â‰¥0,
hence by induction xj = x0(1 âˆ’x0)j âˆ€j â‰¥0, as required.
The density and the law of a geometric distribution are plotted in Figure 3.11.
3.2.7
Exercises
Exercise 3.39 Let X be the number of defective parts produced each day in
a production chain. Assume X is a random variable that follows the binomial
distribution, with mean 6 and variance 5.88:
â€¢ Compute the density of X.
â€¢ Compute the probability that no defective part is produced today. How can
this value be approximated?
%
50âˆ’300 â‰ƒeâˆ’6&
G(0.7)
G(0.7)
30
25
20
15
10
5
0
30
25
20
15
10
5
0
0.14
0.12
0.1
0.08
0.06
0.04
0.02
0
âˆ’0.04
âˆ’0.02
1.2
1
0.8
0.6
0.4
0.2
0
âˆ’0.2
(a)
(b)
Figure 3.11
(a) The density and (b) the law of a geometric distribution.

102
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Exercise 3.40 A random variable X follows the binomial distribution. The mean
and the variance are 6 and 2.4, respectively. Compute P(X = 5), P(X = 6) and
P(X = 7).
[P(X = 5) â‰ƒ0.2, P(X = 6) â‰ƒ0.25, P(X = 7) â‰ƒ0.215]
Exercise 3.41 Show that the memoryless property (3.39) is equivalent to
P(X = 0) = P(X = j)
P(X â‰¥j)
âˆ€j â‰¥0.
Exercise 3.42 Let X be a geometrically distributed random variable, that is
P(X = k) = (1 âˆ’p)kâˆ’1p âˆ€k â‰¥1. Show that
P

X < i + j
 X â‰¥j) = P(X â‰¤i)
âˆ€i, j â‰¥1.
Infer that the above equality is equivalent to
P(X = 1) = P(X = j)
P(X â‰¥j)
âˆ€j â‰¥1.
3.3
Some absolutely continuous distributions
3.3.1
Uniform distribution
Let ]a, b[âŠ‚R, a < b, be an interval of R and let
Ï(x) =

0
if x /âˆˆ]a, b[,
1
bâˆ’a
if x âˆˆ]a, b[.
The measure (B(R), U) deï¬ned as
U(A) := L1(A âˆ©]a, b[)
b âˆ’a
=
*
A
Ï(x) dx,
A âˆˆB(R),
is absolutely continuous with density Ï. Moreover, (B(R), U) is a probability
measure on  :=]a, b[ called the uniform distribution on ]a, b[. If X is a random
variable with PX = U, then
E [ X ] =
* b
a
t
1
b âˆ’a dt = a + b
2
,
Var [ X ] = E
%
X2 &
âˆ’E [ X ]2 = (a âˆ’b)2
12
.
(3.40)
Flipping a fair coin inï¬nitely many times is strictly related to the uniform
distribution. Let T : {0, 1}âˆâ†’[0, 1] map each binary sequence

Î±k

into the
real number âˆ
k=1
Î±k
2k :
T ({Î±k}) :=
âˆ

k=1
Î±k
2k .

RANDOM VARIABLES
103
Theorem 3.43
Let ({0, 1}âˆ, E, Ber(âˆ, 1
2)) denote the probability space
generated by an inï¬nite Bernoulli process of parameter p = 1/2. Then T is a
random variable on ({0, 1}âˆ, E, Ber(âˆ, 1
2)) which is uniformly distributed on
the interval [0, 1]. In other words, PT is the Lebesgue measure on the interval
[0, 1].
Proof. Let E be the family of events associated with the inï¬nite Bernoulli
process. We have to prove the following:
â€¢ T is a random variable, i.e.

{Î²k} | T ({Î²k}) â‰¤x

âˆˆE âˆ€x âˆˆ[0, 1].
â€¢ Ber

âˆ, 1
2

(T â‰¤x) = L1([0, x]) = x âˆ€x âˆˆ[0, 1].
As previously stated, see the proof of Proposition 2.32, the map T is surjective
but it is not injective. In fact if a sequence

Î±k

is deï¬nitely 0 but not identically
0 (deï¬nitely 1 but not identically 1), then there exists a sequence

Î²k

which
is deï¬nitely 1 (0, respectively) such that T (

Î±k

) = T (

Î²k

). Thus, if N is the
subset of the sequences which are deï¬nitely 1, T is a one-to-one map between
{0, 1}âˆ\ N and [0, 1[. Notice that N is denumerable, hence a zero-probability
event in E, see Example 2.33.
Let x, y âˆˆ[0, 1[ and Î± =

Î±k

, Î² =

Î²k

âˆˆ{0, 1}âˆ\ N such that T (Î±) = x,
T (Î²) = y. One can easily check that y â‰¤x if and only if Î² â‰¤Î± with respect
to the lexicographic order, i.e. Î²1 < Î±1, or Î²1 = Î±1 and Î²2 < Î±2, or Î²1 = Î±1,
Î²2 = Î±2 and Î²3 < Î±3 and so on.
For any Î± =

Î±k

âˆˆ{0, 1}âˆ\ N and for any non-negative integer k â‰¥1
deï¬ne
Ak :=

Î² âˆˆ{0, 1}âˆ Î²i = Î±i âˆ€i = 1, . . . , k âˆ’1, Î²k < Î±k

so that T (Î²) = y â‰¤x = T (Î±) if and only if Î² âˆˆAk for some k, that is
âˆªkAk âŠ‚

Î²
 T (Î²) â‰¤x

âŠ‚âˆªkAk âˆªN.
Thus, there exists a zero-probability event M âŠ‚N such that

Î²
 T (Î²) â‰¤x

= âˆªkAk âˆªM.
Notice that Ak is empty whenever Î±k = 0. If Î±k = 1, then the elements of
Ak are the sequences Î² =

Î²j

such that Î²j = Î±j for every j = 1, . . . , k âˆ’1
and Î²k = 0. In particular each set Ak is a cylinder, hence Ak âˆˆE and therefore,
{Î² | T (Î²) â‰¤x} âˆˆE being a denumerable union of E-measurable sets. Since x âˆˆ
[0, 1[ is arbitrary, we have proven that T is a random variable.
Moreover, the previous description proves that for every k â‰¥1
Ber

âˆ, 1
2

(Ak) =
â§
â¨
â©
0
if Î±k = 0,
Ber

k, 1
2

({Î±1, . . . , Î±kâˆ’1, 0}) = 1
2k
if Î±k = 1,

104
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
i.e. Ber(âˆ, 1
2)(Ak) = Î±k
2k . Since Ber(âˆ, 1
2)(M) = 0 and the sets Ak are pairwise
disjoint, we get
Ber

âˆ, 1
2

(T â‰¤x) =
âˆ

k=1
Ber

âˆ, 1
2

(Ak) =
âˆ

k=1
Î±k
2k = x.
Both claims are proven.
3.3.2
Normal distribution
The
normal or Gaussian distribution of parameters m âˆˆR and Ïƒ > 0 is the
measure (B(R), N(m, Ïƒ 2)) with
N(m, Ïƒ 2)(A) :=
*
A
f (t) dt,
A âˆˆB(R)
where
f (t) :=
1
âˆš
2Ï€Ïƒ 2 exp
âˆ’(t âˆ’m)2
2Ïƒ 2

.
Since
* +âˆ
âˆ’âˆ
eâˆ’s2 ds = âˆšÏ€,
N(m, Ïƒ 2) is a probability measure on R. Any random variable X such that
PX = N(m, Ïƒ 2) has mean m and variance Ïƒ 2, that is
E [ X ] = m
and
Var [ X ] = Ïƒ 2,
as an easy computation shows. The law of the normal distribution N(0, 1) of
parameters m = 0 and Ïƒ 2 = 1 is usually denoted by (t) instead of FN(0,1)(t),
(t) :=
1
âˆš
2Ï€
* t
âˆ’âˆ
eâˆ’x2
2 dx.
Clearly (âˆ’âˆ) = 0, (0) = 0.5 and (+âˆ) = 1, see Figures 3.12 and 3.13.
In practice, â€˜independentâ€™ measurements are often â€˜distributedâ€™ according to
a normal distribution. As we shall see, the Gaussian distribution plays a central
role among distributions associated with â€˜independentâ€™ random variables.
Exercise 3.44 The densities of two normal distributions are rescaled versions of
each other since
f (t) =
1
âˆš
2Ï€Ïƒ 2 exp
âˆ’(t âˆ’m)2
2Ïƒ 2

= 1
Ïƒ â€²t âˆ’m
Ïƒ

.
Infer that if X is a random variable such that PX = N(m, Ïƒ 2), then the random
variable Y = (X âˆ’m)/Ïƒ follows the Gaussian distribution N(0, 1).

RANDOM VARIABLES
105
6
4
2
0
âˆ’6
âˆ’4
âˆ’2
4
2
0
âˆ’4
âˆ’2
0.5
0.2
0.3
0.4
0.1
0
âˆ’0.1
âˆ’0.2
0
0.2
0.4
0.6
0.8
1
1.2
(a)
(b)
N(0.00, 1.00)
N(0.0, 1.0)
Figure 3.12
(a) The density and (b) the law of the normal distribution N(0, 1).
t
FN(0,1)(t)
t
FN(0,1)(t) FN(0,1)(t)
t
FN(0,1)(t)
t
0.0
0.5
2.0
0.9772
0.5
0.0
0.8
0.8416
0.25
0.5987
2.25
0.9878
0.53
0.0753
0.85
1.0364
0.50
0.6915
2.5
0.9938
0.57
0.1764
0.9
1.2816
0.75
0.7734
2.75
0.9970
0.6
0.2533
0.95
1.6449
1.0
0.8413
3.0
0.9987
0.62
0.3055
0.99
2.3263
1.25
0.8944
3.25
0.9994
0.67
0.4399
0.999
3.0902
1.5
0.9332
3.5
0.9998
0.7
0.5244
0.9999
3.7190
1.75
0.9599
3.75
0.9999
0.75
0.6745
0.99999
4.2649
Figure 3.13
A few values of the normal law and of its inverse.
Exercise 3.45 Assume X is a Gaussian random variable whose mean and variance
are m and Ïƒ 2, respectively. Compute the distribution and the expected value of
the random variable |X âˆ’m|.
Solution. We ï¬rst compute the law of |X âˆ’m|. Clearly, P(|X âˆ’m| â‰¤t) = 0
if t â‰¤0. Since the random variable (X âˆ’m)/Ïƒ follows the distribution N(0, 1),
see Exercise 3.44, for t > 0 we have
P

|X âˆ’m| â‰¤t

= P

âˆ’t
Ïƒ â‰¤X âˆ’m
Ïƒ
â‰¤t
Ïƒ

=
2
âˆš
2Ï€
*
t
Ïƒ
0
exp

âˆ’x2
2

dx,
from which we infer that |X âˆ’m| is absolutely continuous and
P|Xâˆ’m|(A) =
*
A
g(t) dt

106
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
where
g(t) =
â§
âªâ¨
âªâ©
0
if t â‰¤0,
/
2
Ï€
1
Ïƒ exp

âˆ’t2
2Ïƒ 2

if t > 0.
We now compute the expected value:
E [ |X âˆ’m| ] =
* +âˆ
âˆ’âˆ
|t| g(t) dt =
* +âˆ
0
t g(t) dt =
/
2
Ï€ Ïƒ.
Exercise 3.46 The life (measured in hours) of a bulb is a Gaussian random vari-
able of expected value 200 and variance Ïƒ 2. A customer asks that at least 90%
of the bulbs live longer than 150h. What is the maximum possible value for Ïƒ 2?
[â‰ƒ39]
3.3.3
Exponential distribution
For Î» > 0, set
ÏÎ»(t) =

0
if t < 0,
Î»eâˆ’Î»t
if t â‰¥0,
(3.41)
and for any Borel set A âŠ‚R let
exp(Î»)(A) :=
*
A
ÏÎ»(t) dt.
Since exp(Î»)(R) =
. +âˆ
0
Î»eâˆ’Î»t dt = 1, exp(Î») is a probability measure on R sup-
ported on [0, âˆ[, called the exponential distribution of parameter Î». The expected
value and the variance of an exponentially distributed random variable X are
E [ X ] = 1
Î»
and
Var [ X ] = 1
Î»2 ,
(3.42)
respectively.
Deï¬nition 3.47 A non-negative random variable X is memoryless if
P

X â‰¤t + s
 X â‰¥t

= P(X â‰¤s)
âˆ€t, s > 0.
(3.43)
The meaning of the above property is clear: X is memoryless if the distribu-
tion of X does not change when we shift the observation interval from [0, s] to
[t, t + s], whatever t. The (conditional) distribution remains the same indepen-
dently of the beginning of observation. Observe that P(X â‰¤t + s | X â‰¥t) and
P(X â‰¤t + s | X > t) differ if and only if P(X = t) Ì¸= 0, i.e. if and only if FX
has a jump at t.

RANDOM VARIABLES
107
Example 3.48 Random variables that describe â€˜timeâ€™ often follow a memoryless
distribution. Assume, for instance, that a random variable X describes the time
needed for completing a certain task. Then P(X â‰¤t + s | X â‰¥s) is the proba-
bility that the task is completed by time t + s knowing that it was still going on
immediately before time s.
Exponentially distributed random variables are the only random variables
where the distribution takes values in [0, +âˆ] and which are â€˜memorylessâ€™.
Theorem 3.49 Assume that the range of a random variable X is in [0, +âˆ] and
FX(0) < 1. Thus X is memoryless if and only if X follows the exponential law
exp(Î¼) where Î¼ = âˆ’log(1 âˆ’FX(1)) = F â€²
X(0+).
In order to prove the theorem, we need the following.
Lemma 3.50 Let Î± : R+ â†’R be either continuous or monotone and such that
Î±(t + s) = Î±(t) + Î±(s) for any t, s â‰¥0. Then Î±(t) = t Î±(1) âˆ€t â‰¥0.
Proof. Choosing t = s = 0 we immediately get Î±(0) = 0. By induction, we
get Î±(k) = Î±(1 + Â· Â· Â· + 1) = k Î±(1) and nÎ±(k/n) = Î±(k/n) + Â· Â· Â· + Î±(k/n) =
Î±(k) = k Î±(1) for any two positive integers k and n. Thus Î±(q) = q Î±(1) for
any positive rational number q. If Î± is continuous the claim follows. If Î±
is monotone, then for any positive t let

pn

and

qn

be two sequences of
rational numbers approximating t from below and from the above, respectively.
Assuming, for instance, Î± monotone increasing, we have
pnÎ±(1) = Î±(pn) â‰¤Î±(t) â‰¤Î±(qn) = qnÎ±(1)
for any n, hence the claim, letting n â†’âˆ.
Proof of Theorem 3.49. If PX = exp(Î¼), then FX(t) = 1 âˆ’eâˆ’Î¼t for any t â‰¥0,
so that, for any t, s > 0 we get
P(X â‰¤t + s, X â‰¥t) = FX(t + s) âˆ’lim
sâ†’tâˆ’FX(s) = eâˆ’Î¼t âˆ’eâˆ’Î¼(t+s)
= eâˆ’Î¼t(1 âˆ’eâˆ’Î¼s) = (1 âˆ’FX(t))FX(s)
= P(X â‰¥t)P(X â‰¤s),
i.e. (3.43) is proven.
Conversely, deï¬ne FX(tâˆ’) := limsâ†’tâˆ’FX(s) and Î´X(t) := FX(t) âˆ’FX(tâˆ’).
Property (3.43) amounts to the equality
(1 âˆ’FX(tâˆ’))FX(s) = FX(t + s) âˆ’FX(tâˆ’)
âˆ€t, s > 0.
i.e.
(1 âˆ’FX(t) + Î´X(t))FX(s) = FX(t + s) âˆ’FX(t) + Î´X(t)
âˆ€t, s > 0. (3.44)

108
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
From the right continuity of FX and letting s â†’0+ in (3.44) we get
(1 âˆ’FX(t) + Î´X(t))FX(0) = Î´X(t)
âˆ€t > 0.
(3.45)
We now prove that FX(0) = 0. Assume, by contradiction, that FX(0) > 0. Since
FX is right-continuous and, by assumption FX(0) < 1, then FX(t) âˆˆ]0, 1[ for any
t in a right-hand neighbourhood of 0, so that by (3.45) the jump Î´X(t) would be
positive for any t in such a neighbourhood. This is a contradiction, since FX can
be discontinuous in at most a denumerable set of points.
Since FX(0) = 0, again from (3.45) we infer Î´X(t) = 0 for any t â‰¥0, i.e. FX
is continuous on R, hence (3.44) reduces to
(1 âˆ’FX(t))FX(s) = FX(t + s) âˆ’FX(t)
âˆ€t, s > 0,
or, equivalently, to
(1 âˆ’FX(t))(1 âˆ’FX(s)) = (1 âˆ’FX(t + s))
âˆ€t, s > 0.
(3.46)
Set Î±(t) := log(1 âˆ’FX(t)), t > 0. Then Î±(t + s) = Î±(t) + Î±(s) âˆ€t, s > 0. Since
Î±(t) is monotone decreasing, Lemma 3.50 yields Î±(t) = tÎ±(1) âˆ€t > 0, i.e.
1 âˆ’FX(t) = eâˆ’Î¼t
âˆ€t > 0
where Î¼ := âˆ’Î±(1) > 0. Finally, by continuity we infer 1 âˆ’FX(t) = eâˆ’Î¼t âˆ€t â‰¥0
and, consequently, the right-hand side derivative of FX at 0 exists and is equal
to Î¼
F â€²
X+(0) = lim
tâ†’0+
FX(t)
t
= Î¼.
Remark 3.51 Looking at the proof of Theorem 3.49, one sees that the exponen-
tially distributed random variables are the only random variables X with range
of the distribution in [0, +âˆ[ such that FX(0) < 1 and
P

X â‰¤t + s
 X > t

= P(X â‰¤s)
âˆ€t, s > 0.
(3.47)
Therefore (3.43) and (3.47) are equivalent formulations of the memoryless prop-
erty. We need a proof, since we have not assumed that the law of X is continuous.
The densities and the laws of three exponential distributions are plotted in
Figure 3.14.
3.3.4
Gamma distributions
Let Î± and Î» be positive real parameters, and for t âˆˆR, let
f (t) = fÎ±,Î»(t) :=

0
if t â‰¤0,
Î»Î±tÎ±âˆ’1eâˆ’Î»x
(Î±)
if t > 0,
(3.48)

RANDOM VARIABLES
109
4
3
2
1
0
â€“1
4
3
2
1
0
â€“1
0
0.5
1.5
1
2
0
0.5
1.5
1
2
fexp(0.5)
fexp(1.5)
fexp(2.0)
Fexp(0.5)
Fexp(1.0)
Fexp(2.0)
(a)
(b)
Figure 3.14
Three exponential distributions. On the left, their densities; on the
right, their laws.
0
1
0.5
1.5
2.5
3.5
4.5
2
3
4
10
9
8
7
6
5
4
3
2
1
0
Figure 3.15
The (Î±) function.
where (Î±) :=
. +âˆ
0
sÎ±âˆ’1 eâˆ’s ds, see Figure 3.15. For any Borel set A âŠ‚R let
(Î±, Î»)(A) :=
*
A
f (t) dt.
It can be easily shown that (Î±, Î») is a probability measure on R supported
on R+, called the Gamma distribution of shape Î± and scale 1/Î». Observe that
(1, Î») is the exponential distribution exp(Î»).
If X is a Gamma distributed random variable with shape Î± and scale 1/Î»,
then the expected value and the variance of X are
E [ X ] = Î±
Î»
and
Var [ X ] = Î±
Î»2 ,
(3.49)
respectively.

110
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
0.2 0.4 0.6 0.8
1
1.2 1.4 1.6 1.8
2
0
6
5
4
3
2
1
0
0.5
1.5
2.5
3
1
2
0
0.2
0.4
0.6
0.8
1
0
fÎ“(2.0,0.8)
fÎ“(2.0,1.0)
fÎ“(2.0,2.0)
FÎ“(1.0,0.5)
FÎ“(1.0,1.0)
FÎ“(1.0,2.0)
Figure 3.16
Three Gamma distributions. On the left, their densities; on the right,
their laws.
Gamma distributions (Î±, Î») with integer shape parameter Î± are also called
Erlang distributions. The distribution ( n
2, 1
2) is called a chi-squared distribution
with n degrees of freedom; it is also denoted by Ï‡2(n). Erlang and chi-squared
distributions are connected to exponential and normal distributions, respectively,
see Exercises 4.49 and 4.62.
The densities and the laws of three Gamma distributions are plotted in
Figure 3.16.
3.3.5
Failure rate
Assume the random variable X follows an absolutely continuous distribution
whose density is f (t) = F â€²
X(t). Deï¬ne
w(Ï„; t) := f (t + Ï„)
1 âˆ’FX(t).
Then Vitali theorem yields
P

X â‰¤t + s
 X â‰¥t

= FX(t + s) âˆ’FX(t)
1 âˆ’FX(t)
=
* s
0
w(Ï„; t) dÏ„.
The function w(0; t),
w(0; t) =
f (t)
1 âˆ’FX(t) =
F â€²
X(t)
1 âˆ’FX(t) = âˆ’d
dt log(1 âˆ’FX(t)),
is called the hazard function or failure rate of the distribution of X. In fact,
assuming that X represents a failure time, then
W(A) := P

X âˆˆA
 X â‰¥t

=
1
1 âˆ’FX(t)
*
Aâˆ©[t,âˆ[
f (s) ds

RANDOM VARIABLES
111
is the distribution probability of the failure time, assuming that no failure has
occurred before time t. Notice that W is supported on [t, +âˆ]. In particular, for
the probability of a failure during a small time interval [t, t + Î´t], we have
P(X â‰¤t + Î´t | X â‰¥t) =
1
1 âˆ’FX(t)
* t+Î´t
t
f (s) ds â‰ƒw(0; t) Î´t
if f is continuous at t. In this sense w(0; t) models the urgency of completing
a task at time t before the equipment devoted to it breaks down.
It can be easily checked that the failure rate function of a random variable
that follows the exponential distribution exp(Î») is constant and equal to Î».
3.3.6
Exercises
Exercise 3.52 The temperature T (measured in degrees Celsius) of a certain
volume of gas follows the Gaussian distribution of mean Î¼ = 40 and variance
Ïƒ 2 = 100. Compute:
â€¢ P(T â‰¤50).
â€¢ P(|T âˆ’Î¼| â‰¤5).
â€¢ P(|T âˆ’Î¼| â‰¤10|T â‰¥35).
0
(1), (0.5), (1)+(0.5)âˆ’1
(0.5)
1
Exercise 3.53 Assume X is a Gaussian random variable with mean and variance
equal to 1 and 4, respectively. Compute P(|X âˆ’1| â‰¤2) in terms of the law  of
the standard Gaussian distribution.
2

1
2

âˆ’
âˆ’3
2

= 
1
2

+ 
3
2

âˆ’1
3
Exercise 3.54 Assume X is a random variable with absolutely continuous distri-
bution of density
f (x) =

|1 âˆ’x|
if 0 â‰¤x â‰¤2,
0
otherwise.
Compute Var [ X ].
21
2
3
Exercise 3.55 Let
f (x) =
â§
âªâ¨
âªâ©
c
if âˆ’2 â‰¤x â‰¤âˆ’1,
2c
if 1 â‰¤x â‰¤2,
0
otherwise,
be the density of an absolutely continuously distributed random variable X. Com-
pute the density of Y := X2.

112
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Exercise 3.56 Let Î¸ > 0 and assume that
f (x, Î¸) =

Î¸xâˆ’Î¸âˆ’1
if x > 1,
0
otherwise,
is the density of an absolutely continuously distributed random variable X. Com-
pute E [ X ].
Exercise 3.57 John thinks that the life (measured in kilometers) of a car is an
exponentially distributed random variable with mean Î¼ = 300 000. He buys a
used car that has already done 100 000 km. What is the probability that the car
does another 25 000 km before it breaks down?
[â‰ƒ0.435]
Exercise 3.58 The daily production (measured in kilograms) of cheese from a
certain dairy farm is a Gaussian random variable of mean Î¼ = 1000 and standard
deviation Ïƒ = 50. Compute the probability that the daily production is at least
975 kg.
[(0.50) â‰ƒ0.69]
Exercise 3.59 The fuel consumption (measured in litres per/100 km) of an AAA
car is a Gaussian random variable with mean Î¼1 = 6.5 and standard deviation
Ïƒ1 = 0.8. The fuel consumption of a BBB car is another Gaussian random variable
with mean Î¼2 = 7 and standard deviation Ïƒ2 = 0.5. Compute the probability that
the AAA car consumes more fuel than the BBB car.
[â‰ƒ1 âˆ’(0.53) â‰ƒ0.30]
Exercise 3.60 The weight of a box of spaghetti (measured in grams) is a Gaussian
random variable whose expected value and standard deviation are 510 and 12,
respectively. Compute the probability that a box weighs more than 500 g.
[â‰ƒ0.80]
Exercise 3.61 Assume X is an exponentially distributed random variable whose
expected value is 1/Î». Compute the laws of the random variables eX and
min {X, 3}.
Exercise 3.62 Let X be a normally distributed random variable, PX = N(10, 9).
Compute for every t > 0 P(X â‰¥t) and P(X2 > t) in terms of the density of the
normalized Gaussian distribution N(0, 1).

4
Vector valued random
variables
4.1
Joint distribution
Let X and Y be two random variables. The distribution vector (PX, PY) does
not bear enough information about the relations occurring between X and Y,
for instance to compute P(A âˆ©B) where A and B are generated by X and Y,
respectively; one needs to introduce a new object called the joint (probability)
distribution of X and Y.
Example 4.1 (Discrete random variables) Let X and Y be two discrete random
variables on the same probability space (, E, P). Let X() =

x1, . . . , xn

,
Y() =

y1, . . . , ym

and let (p1, . . . , pn) and (q1, . . . , qm) be the mass density
vectors of PX and PY , respectively.
The image of the map (X, Y) :  â†’R2 is a subset of {(xi, yj), i = 1, . . . , n,
j = 1, . . . , m} (whose cardinality is nm) and its distribution is concentrated at
this set. Let

pij

be the nm-tuple deï¬ned by
pij := P(X = xi, Y = yj).
Clearly, the mass densities (pi) and (qj) can be computed in terms of the pijâ€™s:
in fact,
pi = P(X = xi) =
m

j=1
P(X = xi, Y = yj) =

j
pij
A First Course in Probability and Markov Chains, First Edition. Giuseppe Modica and Laura Poggiolini.
Â© 2013 John Wiley & Sons, Ltd. Published 2013 by John Wiley & Sons, Ltd.

114
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
qj = P(Y = yj) =
n

i=1
P(X = xi, Y = yj) =

i
pij.
But, since (pij) has nm components while the components of (pi) and (qj) are
only n + m, one cannot expect in general to recover (pij) from (pi) and (qj):
if n âˆ§m > 2, the vector (pij) is likely to bear more information than the (pi)â€™s
and the (qj)â€™s. Example 4.5 shows that, in general, even in the simplest case
n = m = 2, the knowledge of (p1, p2) and (q1, q2) does not yield the possibility
to compute (pij).
4.1.1
Joint and marginal distributions
4.1.1.1
Vector valued random variables
Deï¬nition 4.2 Let X1, . . . , XN :  â†’R be real-valued maps deï¬ned on a prob-
ability space (, E, P) and let X :  â†’RN, X = (X1, . . . , XN). If

x âˆˆ
 X(x) âˆˆA

âˆˆE
for any Borel set A âŠ‚RN, then X is said to be an E-measurable map, or a
RN-valued random variable or a multivariate random variable.
The following proposition can be easily proved.
Proposition 4.3 X = (X1, . . . , XN) is a RN-valued random variable if and only
if all the Xiâ€™s are real-valued random variables.
4.1.1.2
Joint distribution
Let X = (X1, . . . , XN) :  â†’RN be a random variable on the probability space
(, E, P). We can deï¬ne a new function on the Borel sets of RN, PX : B(RN) â†’
[0, 1], as
PX(A) := P(X âˆˆA) = P(Xâˆ’1(A))
âˆ€A âŠ‚B(RN).
Following the same line as in the scalar case, see Section 3.1.1, one can use De
Morgan formulas to prove that (B(RN), PX) is a probability measure on RN.
(B(RN), PX) is called the joint distribution of X = (X1, . . . , XN).
Also,
we
deï¬ne
the
joint distribution law
FX : RN â†’R
of
X =
(X1, . . . , XN) as
FX(t1, . . . , tN) = P(X1 â‰¤t1, X2 â‰¤t2, . . . , XN â‰¤tN).
Namely, if for each t = (t1, . . . , tN) âˆˆRN, we introduce the set
Et :=] âˆ’âˆ, t1]Ã—] âˆ’âˆ, t2] Ã— Â· Â· Â· Ã—] âˆ’âˆ, tN] âŠ‚RN;
(4.1)

VECTOR VALUED RANDOM VARIABLES
115
then
FX(t) := P(X1 â‰¤t1, X2 â‰¤t2, . . . , XN â‰¤tN) = PX(Et).
Thus, knowing PX one can compute FX and, as in the scalar case, PX can be
recovered from FX, see Section 3.1.1 and Appendix B.
4.1.1.3
Marginal random variables and marginal distributions
Let X = (X1, X2) :  â†’R2 be a random variable on a probability space
(, E, P), Both X1 and X2 are real valued random variables and their
distributions PX1 and PX2 can be computed from the joint distribution PX of
X1 and X2. In fact, for any Borel set A âŠ‚B(R), the sets A Ã— R and R Ã— A are
Borel sets in R2,
PX1(A) = P(X1 âˆˆA) = P(X1 âˆˆA, X2 âˆˆR)
= P((X1, X2) âˆˆA Ã— R) = P(X1,X2)(A Ã— R)
and, analogously,
PX2(A) = P(X1,X2)(R Ã— A).
When the stress is on the distribution PX of X := (X1, X2), PX1 and PX2 are
called the marginal distributions of PX.
Clearly, the above can be extended to random variables of arbitrary dimen-
sion. Assume, for example, that X :  â†’Rh, Y :  â†’Rk and Z := (X, Y) :
 â†’Rh+k. Then X and Y are random variables if and only if Z is a random
variable. Moreover, for any A âˆˆB(Rh) and any B âˆˆB(Rk) we have
PX(A) = PZ(A Ã— Rk)
and
PY(B) = PZ(Rh Ã— B).
Remark 4.4 Random variables are deï¬ned only by means of the set theoretic
notion of preimage. This fact suggests a possible generalization: let (, E, P) and
(, F, Q) be two probability spaces. A map X :  â†’ is said to be a random
variable between such spaces if Xâˆ’1(F) âˆˆE for every F âˆˆF. If X is a random
variable (according to this deï¬nition), then PX(F) := P(Xâˆ’1(F)), F âˆˆF, is a
set function deï¬ned on F and the couple (F, PX) is a probability measure on
, called the distribution of X. We are not going to treat this point any further.
Example 4.1 suggests that the joint distribution conveys more information
than the marginal ones. Here we provide one explicit example.
Example 4.5 Let E, F âŠ‚[0, 1] be two intervals. Let X = 1E, Y = 1F and let P
be the uniform distribution on [0, 1]. Thus
P(X = 0) = P(Ec),
P(X = 1) = P(E),
P(Y = 0) = P(F c),
P(Y = 1) = P(F),

116
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
and the matrix of joint densities is
P1E,1F ({i, j}) =

P(Ec âˆ©F c)
P(E âˆ©F c)
P(Ec âˆ©F)
P(E âˆ©F)

This clearly shows that moving E with respect to F changes PX,Y but does not
change PX and PY .
4.1.1.4
Composition
Let X :  â†’RN be a random variable on the probability space (, E, P). The
deï¬nition of joint distribution in terms of the probability P,
PX(A) := P(X âˆˆA)
âˆ€A âŠ‚RN
can be conveniently written by means of integrals on  and RN.
Theorem 4.6 Let X1, . . . , XN :  â†’R be random variables on (, E, P). Then,
for any B(RN)-measurable non-negative function Ïˆ : RN â†’R, we have
*

Ïˆ(X1(x), X2(x), . . . , XN(x)) P(dx)
=
*
RN Ïˆ(t1, . . . , tN) P(X1,...,XN )(dt1dt2 Â· Â· Â· dtN).
(4.2)
Proof. The proof follows the same line of the proof of Theorem 3.9.
The composition formula easily follows, see Corollary 3.11.
Corollary 4.7 Let X :  â†’RN be a random variable on (, E, P) and let Ï• :
RN â†’Rk be a B(RN)-measurable function. Then Ï• â—¦X :  â†’Rk is a random
variable on (, E, P) and for every non-negative B(Rk)-measurable function Ïˆ :
Rk â†’R we have
*
Rk Ïˆ(s1, . . . , sk) PÏ•â—¦X(ds1 Â· Â· Â· dsk)
=
*
RN Ïˆ(Ï•(t1, . . . , tN)) PX(dt1 Â· Â· Â· dtN).
(4.3)
4.1.1.5
Sum of random variables
Formula (4.3) allows to compute the distribution of the sum of two random
variables in terms of their joint distribution.
Proposition 4.8 Let X and Y :  â†’RN be two random variables on (, E, P).
Then
*
RN Ïˆ(s) PX+Y (ds) =
**
R2N Ïˆ(t + s) P(X,Y)(dtds)
(4.4)

VECTOR VALUED RANDOM VARIABLES
117
for any non-negative B(RN)-measurable function Ï• : RN â†’R. In particular,
PX+Y (A) = PX,Y

(x, y) âˆˆR2N  x + y âˆˆA

âˆ€A âˆˆB(R)
and
FX+Y(t) = PX,Y

(x, y) âˆˆR2N  x1 + y1 â‰¤t1, . . . , xN + yN â‰¤tN

for every t = (t1, . . . , tN) âˆˆRN.
Proof. Equality (4.4) is the claim of Corollary 4.7 for Ï• : RN Ã— RN â†’RN,
Ï•(x, y) := x + y. The other claims follow choosing Ïˆ = 1A in (4.4) and then
choosing A = -N
i=1] âˆ’âˆ, ti[.
4.1.2
Exercises
Exercise 4.9 Let X, Y be two random variables on (, E, P). Prove the following
identities:
E [ X ] =
**
R2 x PX,Y (dxdy),
E [ Y ] =
**
R2 y PX,Y (dxdy),
E [ X + Y ] =
**
R2(x + y) PX,Y (dxdy),
E [ XY ] =
**
R2 xy PX,Y (dxdy),
E [ Ï• â—¦X ] =
**
R2 Ï•(x) PX,Y (dxdy),
E [ Ï• â—¦Y ] =
**
R2 Ï•(y) PX,Y (dxdy),
E [ max(X, Y) ] =
**
R2 max(x, y) PX,Y (dxdy),
E [ min(X, Y) ] =
**
R2 min(x, y) PX,Y (dxdy).
(4.5)
Exercise 4.10 (Hypergeometric distribution) Assume we are given an urn
containing w white balls and r red balls. We draw n balls. Let X be the random
variable that counts the number of drawn white balls. Compute E [ X ] and
Var [ X ].
Solution. X follows the hypergeometric distribution. Let Xj, j = 1, . . . , n, be
the random variables such that Xj = 1 if the jth drawn ball is white and Xj = 0

118
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
otherwise. Then X = n
j=1 Xj and each random variable Xj is a Bernoulli
trial with distribution B(1, p) where p = w/(w + r) (see Section 3.2.3). Thus
E
%
Xj
&
= w/(w + r) for every j = 1, . . . , n so that
E [ X ] =
n

j=1
E
%
Xj
&
=
wr
w + r .
Iterating formula (4.15) one gets
Var [ X ] =
n

j=1
Var [Xj] + 2
n

j=2
jâˆ’1

i=1
Cov(Xi, Xj).
Since Cov(Xi, Xj) = E
%
XiXj
&
âˆ’E
%
Xi
&
E
%
Xj
&
and
E
%
XiXj
&
= P(Xi = 1, Xj = 1) = P(Xj = 1|Xi = 1)P(Xi = 1)
=
w âˆ’1
w + r âˆ’1
w
w + r ,
we get
Cov(Xi, Xj) =
(w âˆ’1)w
(w + r âˆ’1)(w + r) âˆ’
w2
(w + r)2
=
âˆ’wr
(w + r)2(w + r âˆ’1).
Finally,
Var [ X ] =
nwr
(w + r)2 âˆ’n(n âˆ’1)
2
wr
(w + r)2(w + r âˆ’1) =
wr
(w + r)2
w + r âˆ’n
w + r âˆ’1.
Exercise 4.11 Assume the joint distribution PX,Y of X and Y is uniformly
distributed on the square [0, 1]2. Compute the distribution of the random
variable XY.
Exercise 4.12 Assume the joint distribution PX,Y of X and Y is uniformly dis-
tributed on the parallelogram of vertices (0, 0), (1, 0), (2, 1) and (3, 1). Compute:
(i) The distributions PX and PY.
(ii) Mean and variance of X and Y.
Exercise 4.13 Assume that the joint distribution PX,Y of two random variables
X and Y is absolutely continuous with respect to L2 with density
f (x, y) =

cx2y2
if 0 â‰¤x â‰¤1 and 0 â‰¤y â‰¤1,
0
otherwise.
Find c and compute the joint distribution of 3X and XY.

VECTOR VALUED RANDOM VARIABLES
119
Exercise 4.14 Assume that the joint distribution PX,Y of two random variables
X and Y is absolutely continuous with respect to L2 with density
f (x, y) =
c(x âˆ’y)2
if 0 â‰¤x, y â‰¤1,
0
otherwise.
Find c and compute the joint distribution of X2 and X2Y 2.
Exercise 4.15 Assume that the joint distribution PX,Y of two random variables
X and Y is absolutely continuous with respect to L2 with density
f (x, y) =
â§
âªâ¨
âªâ©
3

x2 + y2
14 Ï€
if 1 â‰¤x2 + y2 â‰¤4,
0
otherwise.
Find r > 0 such that P(X2 + Y 2 â‰¥r2) = 1
2.
4
3âˆš
36
2
5
Exercise 4.16 Assume that the joint distribution PX,Y of two random variables
X and Y is absolutely continuous with respect to L2 with density
f (x, y) =
â§
â¨
â©
âˆš
2(x + y)
36
if x2 + y2 â‰¤9, x + y > 0,
0
otherwise.
Compute P(XY â‰¥0).
4âˆš
2
2
5
Exercise 4.17 Let a and b > 0 and let X and Y be two random variables with an
absolutely continuous joint distribution PX,Y of density
f (x, y) =
Ceâˆ’axeâˆ’by
if x > 0, y > 0,
0
otherwise.
Compute:
(i) The constant C.
(ii) The probability P(Y â‰¤X).
(iii) The joint law of X and Y.2
(i) ab, (ii)
a
a + b, (iii) (1 âˆ’eâˆ’as)(1 âˆ’eâˆ’bt)
3

120
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
4.2
Covariance
4.2.1
Random variables with ï¬nite expected
value and variance
Proposition 4.18 Let X, Y :  â†’R be two random variables on the probability
space (, E, P). Then
E [ |XY| ] â‰¤E
%
X2 &1/2E
%
Y 2 &1/2.
(4.6)
Proof. If either E
%
X2 &
= +âˆor E
%
Y 2 &
= +âˆ, the claim is trivial. If
E
%
X2 &
= 0, then X = 0 P-a.e., so also E [ |XY| ] = 0, hence (4.6) holds true.
The same is true if E
%
Y 2 &
= 0.
Let us assume that E
%
X2 &
and E
%
Y 2 &
are both ï¬nite and positive. Consider
the random variables
a(x) =
1
E
%
X2 &1/2 |X(x)|,
b(x) =
1
(E
%
Y 2 &
)1/2 |Y(x)|.
Since 2a(x)b(x) â‰¤a2(x) + b2(x) âˆ€x âˆˆ, integrating with respect to P we get
2 E [ ab ] = 2
*

a(x)b(x) P(dx)
â‰¤E
%
a2 &
+ E
%
b2 &
=
1
E
%
X2 &E
%
X2 &
+
1
E
%
Y 2 &E
%
Y 2 &
= 2,
i.e. E [ ab ] â‰¤1, which proves (4.6).
Let
L2(; P) :=

X :  â†’R is a random variable
 E
%
X2 &
< âˆ

.
(4.7)
When the context is clear, we shall write L2() or L2 in place of L2(; P). If
X âˆˆL2 we say that X is a square integrable random variable.
Proposition 4.19 If X, Y âˆˆL2, then E [ XY ] is ï¬nite. Moreover, L2 is a linear
space, the map (X, Y) â†’E [ XY ] is a positive semideï¬nite symmetric bilinear
form on L2, and X â†’E
%
X2 &1/2 is a seminorm on L2.
Proof. By inequality (4.6)
E [ XY ]
 is ï¬nite whenever X and Y âˆˆL2. Hence,
also E [ XY ] âˆˆR.
Let X, Y âˆˆL2. Since E [ XY ] is bilinear and again by (4.6) we get
E
%
(X + Y)2 &
= E
%
X2 &
+ 2E [ XY ] + E
%
Y 2 &
â‰¤

E
%
X2 &1/2 + E
%
Y 2 &1/22
< âˆ;

VECTOR VALUED RANDOM VARIABLES
121
thus X + Y âˆˆL2. Moreover, for any Î± âˆˆR and any X âˆˆL2, trivially
E
%
(Î±X)2 &
= Î±2E
%
X2 &
< âˆ, i.e. Î±X âˆˆL2. This proves that L2 is a linear
space. It is now obvious that (X, Y) â†’E [ XY ] is real valued, and therefore a
positive semideï¬nite symmetric bilinear form.
Remark 4.20 Notice the following:
â€¢ In general, the form (X|Y) := E [ XY ] is not positive deï¬nite and, con-
sequently, X â†’E
%
X2 &1/2 is not a norm. In fact, E
%
X2 &
= 0 does not
imply that X(x) = 0 âˆ€x but only that X = 0 P-a.e.
â€¢ Inequality (4.6) is the Cauchyâ€“Schwarz inequality for the positive semidef-
inite symmetric bilinear form (X, Y) â†’E [ XY ] on L2. In particular, for
X, Y âˆˆL2 we have
E [ XY ] â‰¤E [ |XY| ] â‰¤E
%
X2 &1/2 E
%
Y 2 &1/2
(4.8)
and the equality holds if and only if either Y = 0 P-a.e. or X(x) = Î»Y(x)
P-a.e. for some Î» âˆˆR, Î» â‰¥0.
Applying inequality (4.6) with Y = 1 we get the classical inequality between
mean and mean square of X
E [ |X| ] â‰¤
6
E
%
X2 &
.
(4.9)
Finally, (4.8) and (4.9) yield the following.
Proposition 4.21 X is square integrable, i.e. E
%
X2 &
< âˆif and only if both
E [ X ] and Var [ X ] are ï¬nite. In particular
L2 âŠ‚L1.
(4.10)
Example 4.22 In general, L2 and L1 do not coincide. For example, let (B(R), P)
the Lebesgue measure on the interval [0, 1] and let X(t) = 1/âˆšt, 0 < t < 1.
Then
E [ X ] =
* 1
0
1
âˆšt dt = 2
while
E
%
X2 &
=
* 1
0
1
t dt = +âˆ.
Deï¬nition 4.23 Let X, Y be two random variables in L2, equivalently two random
variables whose expected value and variance are both ï¬nite. The number
Cov(X, Y) := E
0 
X âˆ’E[X]

Y âˆ’E[Y]
 1
(4.11)
is called the covariance of X and Y.
Trivially:
â€¢ (X, Y) â†’Cov(X, Y) is a positive semideï¬nite symmetric bilinear form on
the linear space L2.

122
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
â€¢ Cov(X, X) = 0 if and only if X is P-a.e. constant. In this case X(x) =
E [ X ] for P-a.e. x.
â€¢ The following formulas hold:
Cov(X, Y) = E [ XY ] âˆ’E [ X ]E [ Y ],
Cov(Î±X + Î², Î³ Y + Î´) = Î±Î³ Cov(X, Y),
Cov(X, X) = Var [ X ] .
(4.12)
â€¢ Theorem 4.6 yields
Cov(X, Y) =
**
R2 xy PX,Y (dxdy) âˆ’E [ X ]E [ Y ]
=
**
R2(x âˆ’E [ X ]) (y âˆ’E [ Y ]) PX,Y (dxdy).
(4.13)
â€¢ The Cauchyâ€“Schwarz inequality for the form (X, Y) â†’Cov(X, Y) on L2
reads as follows:
Cov(X, Y) â‰¤

Var [ X ]

Var [Y],
(4.14)
where the equality holds if and only if either Y is constant P-a.e. or there
exist Î± â‰¥0 and Î² âˆˆR such that X(x) = Î± Y(x) + Î² P-a.e.
â€¢ The Carnot theorem reads
Var [X + Y] = Var [ X ] + Var [Y] + 2 Cov(X, Y)
(4.15)
from which the Pythagoras formula follows:
Var [X + Y] = Var [ X ] + Var [Y]
(4.16)
if and only if Cov(X, Y) = 0.
Deï¬nition 4.24 If X, Y âˆˆL2 and Cov(X, Y) = 0, i.e.
E [ XY ] = E [ X ]E [ Y ] ,
we say that X and Y are uncorrelated.
Finally, iterating (4.16) we get that
Var [X1 + Â· Â· Â· + Xn] = Var [X1] + Â· Â· Â· + Var [Xn]
(4.17)
if and only if the random variables X1, . . . , Xn are pairwise uncorrelated.

VECTOR VALUED RANDOM VARIABLES
123
4.2.2
Correlation coefï¬cient
For X, Y âˆˆL2, let Ïƒ(X) := Var [ X ]1/2 and Ïƒ(Y) := Var [Y]1/2. If X and Y are
not constant P-a.e., one deï¬nes the correlation coefï¬cient of X and Y as
Corr(X, Y) := Cov(X, Y)
Ïƒ(X)Ïƒ(Y).
(4.18)
Corr(X, Y) gives some measure of the â€˜similarities between the shapesâ€™ of the
distributions of X and Y, regardless of their expected value and variance. In fact,
Corr(X, Y) is invariant by change of scale either in X or in Y. Moreover, the
Cauchyâ€“Schwarz inequality reads
âˆ’1 â‰¤Corr(X, Y) â‰¤1,
(4.19)
and Corr(X, Y) = 1 (= âˆ’1) if and only if there exists Î± > 0 (Î± < 0, respectively)
and Î² âˆˆR such that X = Î±Y + Î² P-a.e.
4.2.3
Exercises
Exercise 4.25 Let X be a random variable with ï¬nite expected value and variance.
Let Y = aX + b, a Ì¸= 0, b âˆˆR. Show that Corr(X, Y) = sgn(a).
Exercise 4.26 Let X be a random variable uniformly distributed in [0, b]. Com-
pute Cov(X, X2) and the correlation coefï¬cient Corr(X, X2).
Solution. We have
E [ X ] =
* b
0
x 1
b dx = b
2,
E
%
X2 &
= 1
b
* b
0
x2 dx = b2
3 ,
E
%
X3 &
= 1
b
* b
0
x3 dx = b3
4 ,
E
%
X4 &
= 1
b
* b
0
x4 dx = b4
4 ,
Var [ X ] = E
%
X2 &
âˆ’E [ X ]2 = 1
12b2,
Var [X2] = E
%
X4 &
âˆ’E
%
X2 &2 = 4
45b4.
Hence
Cov(X, X2) = E
%
X3 &
âˆ’E [ X ]E
%
X2 &
=
1
4 âˆ’1
2
1
3

b3 = b3
12.
and
Corr(X, X2) =
Cov(X, X2)
âˆšVar [ X ]

Var [X2]
=
1
12
1
âˆš
12
2
âˆš
45
=
âˆš
15
4 .

124
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Exercise 4.27 Throw a fair dice. If the result is less than or equal to 3, ï¬‚ip a fair
coin. Otherwise ï¬‚ip two fair coins. Let Y be the result of the dice and let X be
the number of heads obtained in the ï¬‚ipping of the coins. Compute:
1. The distribution of X.
2. The expected value and the variance of X.
3. The correlation coefï¬cient Corr(X, Y).
Exercise 4.28 An experiment has three possible results, 1, 2 and 3, whose proba-
bilities are p1, p2 and p3, respectively. Repeat the experiment n times and assume
that the result of each trial is independent of the other trials.
Let N1 and N2 be the number of times that you obtain the results 1 and 2,
respectively. Compute Corr(N1, N2).
Taking
into
account
the
constraints
p1 â‰¥0,
p2 â‰¥0,
p3 â‰¥0
and
p1 + p2 + p3 = 1 compute the maximum and the minimum possible values for Ï.
Can Corr(N1, N2) be zero?
4.3
Independent random variables
4.3.1
Independent events
Deï¬nition 4.29 Let (E, P) be a probability space and let A, B âˆˆE. If
P(A âˆ©B) = P(A)P(B), then we say that A and B are independent events.
It can easily checked that, if P(B) > 0, then A and B are independent if and
only if P(A) = P(A | B): no knowledge on A is gained from the knowledge of B.
Example 4.30 Throw two dice. Here  = {1, 2, . . . , 6}2 and, if the dice are
fair, then each pair (i, j) in  has the same probability, i.e. P({(i, j)}) = 1
36
âˆ€(i, j) âˆˆ. Let A be the event â€˜The number on the top face of the ï¬rst dice
is 6â€™, i.e.
A =

(6, j)
 j = 1, . . . , 6

and let B be the event â€˜The number on the second dice is 4â€™, i.e.
B =

(j, 4)
 j = 1, . . . , 6

.
Then
P(A) = P(B) = 1
6.
Since
A âˆ©B = {(6, 4)},
then
P(A âˆ©B) = 1
36 =
P(A)P(B), thus A and B are independent events.
Deï¬nition 4.31 Let (, E, P) be a probability space and let A1, . . . , An âˆˆE.
A1, . . . , An are said to be independent if for any k = 2, . . . , n and for any choice
of k events Aj1, . . . , Ajk among them, then
P(Aj1 âˆ©Aj2 âˆ©Â· Â· Â· âˆ©Ajk) = P(Aj1)P(Aj2) Â· Â· Â· P(Ajk).
(4.20)

VECTOR VALUED RANDOM VARIABLES
125
We say that a denumerable family of events

An

is independent if for every
n the events A1, . . . , An are independent.
Notice that the pairwise independence of the events A1, . . . , An, n â‰¥3, does
not guarantee the independence of A1, . . . , An. Here we provide an example.
Example 4.32 Consider the uniform probability on  = {0, 1}2. Each single-
ton has probability 1/4. Let A1 = {(1, 0), (1, 1)}, A2 = {(0, 1), (1, 1)} and A3 =
{(i, j) | i + j = 1} = {(1, 0), (0, 1)}. Then
P(A1) = 1/2,
P(A2) = 1/2,
P(A3) = 1/2,
P(A1 âˆ©A2) = P({1, 1}) = 1/4,
P(A2 âˆ©A3) = P({0, 1}) = 1/4,
P(A1 âˆ©A3) = P({(1, 0)}) = 1/4.
Hence A1, A2 and A3 are pairwise independent but they are not independent
since
P(A1 âˆ©A2 âˆ©A3) = P(âˆ…) = 0 Ì¸= 1
8.
If A and B are independent events, then also Ac and B are independent.
In fact,
P(Ac âˆ©B) = P(B) âˆ’P(A âˆ©B) = P(B) âˆ’P(A)P(B) = P(Ac)P(B).
Similarly, one proves the independence of the couples (A, Bc) and (Ac, Bc). In
general, if A1, . . . , An are independent, then all the n-tuples of events whose ï¬rst
component is either A1 or Ac
1, the second component is either A2 or Ac
2 and so
on, are independent.
The above shows that the notion of independence is actually the independence
of the corresponding generated Ïƒ-algebras. This suggests the following extension:
let (, E, P) be a probability space. Two Ïƒ-algebras A, B âŠ‚E are independent
if P(A âˆ©B) = P(A)P(B) for every A âˆˆA and B âˆˆB.
Example 4.33 (Reliability: series and parallel systems) Assume you are given
a system made of n subsystems working in parallel, see Figure 4.1. For each
i = 1, . . . , n let Ei be the event â€˜The ith subsystem is not workingâ€™ and let E
be the event â€˜The whole system does not workâ€™. Then E = E1 âˆ©E2 âˆ©Â· Â· Â· âˆ©En,
hence
P(E) â‰¤min(P(E1), P(E2), . . . , P(En)).
The probability of a breakdown of the system is less than or equal to the
probability of a breakdown of the strongest component. If we assume that the
failures of the subsystems are independent, then we actually have
P(E) = P(E1)P(E2) Â· Â· Â· P(En).
For instance, if the probability that each subsystem fails is 0.5, then the
probability that the whole system is not working is (0.5)n, a huge increase in

126
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Figure 4.1
A parallel system.
Figure 4.2
A series system.
the reliability of the whole system. However, it is worth recalling that this gain
in the reliability of the system relies on the independence of the failures of the
subsystems, which is not so easily granted!
Assume now that the subsystems are working in series, see Figure 4.2. The
event E can now be written as:
E = E1 âˆªE2 âˆªÂ· Â· Â· âˆªEn;
therefore,
P(E) â‰¥max(P(E1), . . . , P(En)),
that is, the occurrence of the breakdown of the whole system is at least as probable
as the occurrence of a breakdown of the weakest component of the system. If
we assume that the failures of the subsystems

Ei

are independent, since
Ec = Ec
1 âˆ©Ec
2 âˆ©Â· Â· Â· âˆ©Ec
n.
then
P(Ec) = P(Ec
1)P(Ec
2) . . . P(Ec
n)
or, equivalently,
P(E) = 1 âˆ’(1 âˆ’P(E1))(1 âˆ’P(E2)) . . . (1 âˆ’P(En)).
For instance, if P(Ei) = 0.5 then P(E) = 1 âˆ’1/2n: the reliability is much worse
in a series system if the failures on the subsystems are independent.

VECTOR VALUED RANDOM VARIABLES
127
4.3.2
Independent random variables
Deï¬nition 4.34 Let X and Y be two random variables on the probability space
(, E, P). Assume X and Y take values on Rn and Rm, respectively. X and Y are
said to be independent random variables if
P(X âˆˆA, Y âˆˆB) = P(X âˆˆA) P(Y âˆˆB),
(4.21)
for any A âˆˆB(Rn) and B âˆˆB(Rm).
The independence of two random variables X and Y can be restated in several
equivalent ways:
â€¢ The Ïƒ-algebras EX and EY of the events detected by X and Y are indepen-
dent.
â€¢ The distribution of X does not provide any piece of information on the
distribution of Y and conversely: if A, B are such that P(X âˆˆA)P(Y âˆˆ
B) > 0, then
P

X âˆˆA
 Y âˆˆB

= P(X âˆˆA),
P

Y âˆˆB
 X âˆˆA

= P(Y âˆˆB).
â€¢ Equality (4.21) can be rewritten as
PX,Y (A Ã— B) = PX(A)PY (B)
âˆ€A âˆˆB(Rn), B âˆˆB(Rm).
(4.22)
Since the value of the joint distribution on â€˜rectanglesâ€™. A Ã— B determines
the joint distribution on all of B(Rn+m), we conclude that the joint distri-
bution of X and Y, hence the probabilistic interaction between X and Y,
is completely described by PX and PY .
â€¢ Since a law completely determines a measure, we also have that
X and Y
are independent if and only if F(X,Y)(t, s) = FX(t)FY (s)
âˆ€(t, s) âˆˆRn Ã— Rm.
In the jargon of measure theory, (4.22) says that PX,Y is the product measure
of PX and PY, PX,Y = PX Ã— PY. From Fubini theorem, see Appendix B, we
get the following.
Proposition 4.35 Let X and Y be two random variables on the probability space
(, E, P) with values in Rn and Rm, respectively. Then X and Y are independent
if and only if
**
Rn+m Ï•(x, y) PX,Y (dxdy) =
*
Rm
 *
Rn Ï•(x, y) PX(dx)

PY(dy)
=
*
Rn
 *
Rm Ï•(x, y) PY (dy)

PX(dx)
(4.23)
for any B(Rn+m)-measurable and non-negative function Ï• : Rn+m â†’R.

128
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Finally, from Deï¬nition 4.34 we get the following.
Proposition 4.36 Let X and Y be two independent variables on (, E, P) with
values in Rn and Rm, respectively, and let Î± : Rn â†’Rh and Î² : Rm â†’Rk be
Borel-measurable. Then the random variables Î± â—¦X and Î² â—¦Y are also indepen-
dent. In particular, equality (4.23) holds true also for the random variables Î± â—¦X
and Î² â—¦Y (replacing n and m with h and k, of course).
Theorem 4.37 (Expected value of a product) Let X and Y be two independent
random variables with ï¬nite expected value. Then X and Y are uncorrelated, i.e.
E [ XY ] = E [ X ] E [ Y ]
equivalently,
Cov(X, Y) = 0.
(4.24)
Proof. Applying (4.23)
E [ |XY| ] =
**
R2 |xy| PX,Y (dxdy) =
*
R
 *
R
|xy| PY(dy)

PX(dx)
=
 *
R
|x| PX(dx)
 *
R
|y| PY (dy)

= E [ |X| ] E [ |Y| ] < +âˆ.
Thus the function Ï• : (x, y) â†’xy is summable with respect to PX,Y and (4.23)
can be applied to Ï• to get
E [ XY ] =
**
R2 xy PX,Y (dxdy) =
*
R
 *
R
xy PY(dy)

PX(dx)
=
 *
R
x PX(dx)
 *
R
y PY (dy)

= E [ X ]E [ Y ].
Remark 4.38 Notice that proving that two variables are uncorrelated is a
much easier task than proving that they are independent. In fact, X and Y are
uncorrelated if and only if E [ XY ] = E [ X ]E [ Y ], which can be checked with
only one equality. In contrast, X and Y are independent means that (4.22) holds
for every couple of events A and B, which amounts to a huge, possibly inï¬nite,
set of equalities.
4.3.3
Independence of many random variables
The notion of independence extends to many variables, even sequences of random
variables.
Deï¬nition 4.39 Let Xn, n âˆˆN, be random variables on (, E, P).
(i) We say that the random variables Xn are pairwise independent if for every
i, j âˆˆN, i Ì¸= j, the random variables Xi and Xj are independent, see Def-
inition 4.34.

VECTOR VALUED RANDOM VARIABLES
129
(ii) n random variables X1, . . . , Xn are said to be independent if for
any k â‰¥2 and for any choice Xr1, . . . , Xrk of k of them and for any
A1, . . . , Ak âˆˆB(R)
P(Xr1 âˆˆA1, Xr2 âˆˆA2, . . . , Xrk âˆˆAk)
= P(Xr1 âˆˆA1)P(Xr2 âˆˆA2) Â· Â· Â· P(Xrk âˆˆAk).
(4.25)
(iii) The random variables of the sequence

Xn

are said to be independent if
for every k â‰¥2 the variables X1, . . . , Xk are independent.
Equation (4.25) says that the joint distribution of Xr1, . . . , Xrk in B(Rk) is
the product measure of the distributions of Xr1, . . . , Xrk, i.e.
PXr1,...,Xrk = PXr1 Ã— Â· Â· Â· Ã— PXrk on B(Rk).
Thus independence of X1, . . . , Xn is equivalent to the following: choose k
random variables between X1, . . . , Xn and group them to form two vector
valued random variables say Y := (Xr1, . . . , Xrh) and Z = (Xrh+1, . . . , Xrk),
then X1, . . . , Xn are independent if and only if Y and Z are independent,
PY,Z = PY Ã— PZ
on B(Rk)
whatever the variables used to build Y and Z are.
Although three or more independent variables are trivially pairwise indepen-
dent, the converse is false as the following example shows.
Example 4.40 Let A1, A2, A3 be the events in Example 4.32. Then the corre-
sponding random variables Xi = 1Ai i = 1, 2, 3 are pairwise independent but not
independent as a whole.
Remark 4.41 Beware that the notion of independence is somewhat delicate.
For instance, suppose that X, Y, Z, T are independent random variables. Then
(X, Y) and (Z, T ) are independent by deï¬nition and Proposition 4.36 yields that
X + Y and Z + T are independent variables, too. However, in general, X + Y
and Z + Y are not independent, as shown by Example 4.42.
Example 4.42 Throw three dice and let X, Y, Z be the outcome of each dice.
Then X + Y and Z + Y are not independent. In fact, let A := {X + Y = 6} and
B = {Y + Z = 6}. Then
P(X + Y = 6) =
5

j=1
P(X = j, Y = 6 âˆ’j)
=
5

j=1
P(X = j) P(Y = 6 âˆ’j) = 5
62

130
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
and, similarly, P(Z + Y = 6) = 5
62 . But
P(X + Y = 6, Z + Y = 6) =
5

j=1
P(Y = j, X = 6 âˆ’j, Z = 6 âˆ’j)
=
5

j=1
P(Y = j) P(X = 6 âˆ’j) P(Z = 6 âˆ’j) = 5
63 Ì¸= 25
64 .
4.3.4
Sum of independent random variables
Theorem 4.43 Let X and Y be two independent random variables with values
in Z. Let

pk

and

qk

be the mass densities of PX and PY , respectively. Then
X + Y is a random variable with values in Z and the mass density

rk

of PX+Y
is given by
rk =
+âˆ

j=âˆ’âˆ
pjqkâˆ’j
âˆ€k âˆˆZ.
Proof. For any k âˆˆZ one has
PX+Y({k}) = P(X + Y = k) = P
 (
j

x âˆˆ
 X = j, Y = k âˆ’j

=
+âˆ

j=âˆ’âˆ
P (X = j, Y = k âˆ’j) =
+âˆ

j=âˆ’âˆ
P(X = j)P(Y = k âˆ’j)
=
+âˆ

j=âˆ’âˆ
pjqkâˆ’j.
A similar result holds for the sum of two independent random variables
following an absolutely continuous distribution. We have the following.
Theorem 4.44 Let X and Y be two independent random variables with PX(dt) =
f (t) dt and PY(dt) = g(t) dt, where f and g are two summable functions. Then
X + Y follows the absolutely continuous distribution, PX+Y(dt) = Ï„(t) dt with
Ï„(t) =
* +âˆ
âˆ’âˆ
f (s)g(t âˆ’s) ds.
Proof. Let Ï• : R â†’R be a B(R)-measurable non-negative function. Then
*
R
Ï•(t) PX+Y(dt) =
**
R2 Ï•(x + y) PX,Y (dxdy)
(i)

VECTOR VALUED RANDOM VARIABLES
131
=
*
R
 *
R
Ï•(x + y) PY (dy)

PX(dx)
(ii)
=
* +âˆ
âˆ’âˆ
f (x)
 * +âˆ
âˆ’âˆ
Ï•(x + y)g(y) dy

dx
(iii)
=
* +âˆ
âˆ’âˆ
f (x)
 * +âˆ
âˆ’âˆ
Ï•(t)g(t âˆ’x) dt

dx
(iv)
=
* +âˆ
âˆ’âˆ
Ï•(t)
 * +âˆ
âˆ’âˆ
f (x)g(t âˆ’x) dx

dt
(v)
=
* +âˆ
âˆ’âˆ
Ï•(t)Ï„(t) dt.
Here we have taken advantage of (4.2) in (i), of the independence of X and Y
in (ii), and of the Fubini theorem in (iii). Moreover, in (iv) we have changed
variable y â†’t := x + y and in (v) we have used the Fubini theorem in order to
change the order of integration.
4.3.5
Exercises
Exercise 4.45 (Sum of two uniformly distributed random variables) Let X
and Y be two random variables, uniformly distributed on the same interval [a, b].
Compute the distribution of X + Y, and compare with the distribution of 2X.
Solution. With the notation of Theorem 4.44 we have
f (t) = g(t) =
â§
â¨
â©
1
b âˆ’a
if t âˆˆ(a, b),
0
otherwise.
The product f (s)g(t âˆ’s) is not zero (and equal to
1
(bâˆ’a)2 ) if and only if s and
t âˆ’s âˆˆ(a, b), i.e. if and only if
s âˆˆ(a, t âˆ’a), t âˆˆ(2a, a + b], s âˆˆ(t âˆ’b, b), t âˆˆ(a + b, 2b).
Thus
Ï„(t) =
â§
âªâªâªâªâ¨
âªâªâªâªâ©
t âˆ’2a
(b âˆ’a)2
if t âˆˆ(2a, a + b],
2b âˆ’t
(b âˆ’a)2
if t âˆˆ(a + b, 2b),
0
otherwise.
The density distribution Ï„(t) is called the triangular distribution on the interval
(2a, 2b): the graph of Ï„ is shown in Figure 4.3. The distribution of 2X is uniform
on the interval (2a, 2b) with density
1
2(bâˆ’a).

132
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
2a
2b
t
t(t)
a + b
1
b âˆ’ a
Figure 4.3
The sum of two independent random variables uniformly distributed
on (a, b) follows the triangular distribution on the interval (2a, 2b).
Exercise 4.46 (Sum of independent Poisson random variables) Assume X and
Y are independent random variables with PX = P(Î») and PY = P(Î¼). Prove the
following:
(i) PX+Y = P(Î» + Î¼).
(ii) For any k, n âˆˆN
P

X = k
 X + Y = n

= B(n, p)({k})
where p :=
Î»
Î»+Î¼.
Solution. (i) Let k âˆˆZ; then
PX+Y ({k}) =
+âˆ

j=âˆ’âˆ
P(Î»)({j})P(Î¼)({k âˆ’j}) =
k

j=0
P(Î»)({j})P(Î¼)({k âˆ’j})
=
k

j=0
Î»j
j! eâˆ’Î»
Î¼kâˆ’j
(k âˆ’j)!eâˆ’Î¼ = eâˆ’(Î»+Î¼) 1
k!
k

j=0
k
j

Î»jÎ¼kâˆ’j
= eâˆ’(Î»+Î¼) 1
k!(Î» + Î¼)k = P(Î» + Î¼)({k}).
(ii) For any n âˆˆN and k âˆˆ{0, . . . , n} one computes
P

X = k
 X + Y = n

= P(X=k, Y=n âˆ’k)
P(X + Y = n)
= P(X = k)P(Y=n âˆ’k)
P(X + Y=n)
= eâˆ’Î»Î»k
k!
eâˆ’Î¼Î¼nâˆ’k
(n âˆ’k)!
n!
eâˆ’Î»âˆ’Î¼(Î» + Î¼)n
=
n
k
 
Î»
Î» + Î¼
k 
Î¼
Î» + Î¼
nâˆ’k
=
n
k

pk (1 âˆ’p)nâˆ’k = B(n, p)({k}).

VECTOR VALUED RANDOM VARIABLES
133
Exercise 4.47 (Sum of independent Gaussian random variables) Assume that
X and Y are two independent random variables following two Gaussian distribu-
tions, PX = N(â„“, Ïƒ) and PY = N(m, Î´). Show that X + Y is a Gaussian random
variable of parameters â„“+ m and
âˆš
Ïƒ 2 + Î´2, PX+Y = N(â„“+ m,
âˆš
Ïƒ 2 + Î´2).
Solution. By considering X âˆ’â„“and Y âˆ’m instead of X and Y, it sufï¬ces to
prove the claim when â„“= m = 0. By Theorem 4.44, PX+Y (dt) = Ï„(t) dt where
Ï„(t) =
1
2Ï€ÏƒÎ´
* +âˆ
âˆ’âˆ
eâˆ’s2
2Ïƒ2 eâˆ’(tâˆ’s)2
2Î´2 ds.
One computes
s2
Ïƒ 2 + (t âˆ’s)2
Î´2
= Î±2s2 âˆ’2Î±Î²st + Î²2t2 + t2
Î´2 âˆ’Î²2t2 = (Î±s âˆ’Î²t)2 + Î³ 2t2
where
Î± :=
/
1
Ïƒ 2 + 1
Î´2 ,
Î² :=
1
Î´2Î± ,
Î³ 2 :=
1
Ïƒ 2 + Î´2 .
Thus
Ï„(t) =
1
2Ï€ÏƒÎ´ eâˆ’Î³ 2t2
2
* +âˆ
âˆ’âˆ
eâˆ’(Î±sâˆ’Î²t)2
2
ds =
1
2Ï€ÏƒÎ´ eâˆ’Î³ 2t2
2
âˆš
2Ï€
Î±
=
1
âˆš
2Ï€
âˆš
Ïƒ 2 + Î´2 e
âˆ’
t2
2(Ïƒ2+Î´2) .
Exercise 4.48 (Minimum of exponential random variables) Assume that X and
Y are two independent random variables with PX = exp(Î») and PY = exp(Î¼).
Show that the random variable Z := min(X, Y) follows the exponential distribu-
tion of parameter Î» + Î¼, PZ = exp(Î» + Î¼).
Solution. Let Ï• : R â†’R be a B(R)-measurable non-negative function. Then
*
R
Ï•(t) Pmin(X,Y)(dt) =
**
R2 Ï•(min(x, y)) PX,Y (dxdy)
=
*
R
 *
R
Ï•(min(x, y)) PX(dx)

PY (dy)
=
* +âˆ
0
Î»eâˆ’Î»t
 * +âˆ
0
Ï•(min(t, s))Î¼eâˆ’Î¼s ds

dt
= Î»Î¼
* +âˆ
0
eâˆ’Î»tÏ•(t)
 * +âˆ
t
eâˆ’Î¼sds

dt
+ Î»Î¼
* +âˆ
0
eâˆ’Î¼sÏ•(s)
 * +âˆ
s
eâˆ’Î»tdt

ds

134
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
= Î»
* +âˆ
0
Ï•(t)eâˆ’(Î»+Î¼)t dt + Î¼
* +âˆ
0
Ï•(s)eâˆ’(Î»+Î¼)s ds
=
* +âˆ
0
Ï•(t)(Î» + Î¼)eâˆ’(Î»+Î¼)t dt
=
*
R
Ï•(t) exp(Î» + Î¼)(dt).
Exercise 4.49 (Sum of Gamma distributed random variables) Let X and Y be
two independent random variables with PX = (Î±, Î») and PY = (Î², Î»), where
Î±, Î² and Î» are positive constants. Prove that PX+Y = (Î± + Î², Î»).
Solution. We recall that the Euler Beta function
B(p, q) :=
* âˆ
0
xpâˆ’1(1 âˆ’x)qâˆ’1 dx,
p, q > 0
can be computed in terms of the Euler Gamma function , in fact,
B(p, q) = (p) (q)
(p + q) .
Let fÎ±,Î»(t) and fÎ²,Î»(t) be the densities of PX and PY , respectively, see (3.48).
Since X and Y are independent, Theorem 4.44 yields PX+Y (dt) = r(t) dt where
r(t) is given by
r(t) =
*
R
fÎ±,Î»(x)fÎ²,Î»(t âˆ’x) dx.
Since fÎ±,Î»(s) and fÎ²,Î»(s) are zero if s â‰¤0, we infer that r(t) = 0 = fÎ±+Î²,Î»(t)
for t â‰¤0. For t > 0 we have
r(t) =
* âˆ
0
Î»Î±xÎ±âˆ’1eâˆ’Î»x
(Î±)
Î»Î²(t âˆ’x)Î²âˆ’1eâˆ’Î»(tâˆ’x)
(Î²)
dx
= Î»Î±+Î²eâˆ’Î»t
(Î±) (Î²)
* âˆ
0
xÎ±âˆ’1(t âˆ’x)Î²âˆ’1 dx.
After substituting y := x/t, the last integral is equal to
* âˆ
0
tÎ±âˆ’1yÎ±âˆ’1tÎ²âˆ’1(1 âˆ’y)Î²âˆ’1t dy = tÎ±+Î²âˆ’1B(Î±, Î²) = tÎ±+Î²âˆ’1 (Î±) (Î²)
(a + Î²) ,
so that
r(t) = Î»Î±+Î²tÎ±+Î²âˆ’1eâˆ’Î»t
(Î± + Î²)
= fÎ±+Î²,Î»(t).
Exercise 4.50 Consider the communication network in Figure 4.4. The capaci-
ties of the links, expressed in Mb/s, are C1,2 = C1,3 = 5, C2,4 = C3,4 = 10 and

VECTOR VALUED RANDOM VARIABLES
135
2
1
4
3
Figure 4.4
The network involved in Exercise 4.50.
C2,3 = 8, all working in the same direction. Let Fij be the event â€˜The link Cij is
brokenâ€™. Assume that the events Fij are independent and that P(Fij) = 0.2 for
each link. For each couple of connected nodes (i, j) compute the capacity of the
network in Mb/s when the link Cij is broken.
Exercise 4.51 Flip two fair coins. Let A =â€˜head on the ï¬rst coinâ€™, B =â€˜the same
outcome on both coinsâ€™ and C =â€˜head on the second coinâ€™. Show that:
â€¢ A, B and C are pairwise independent, but are not independent.
â€¢ C and A âˆ©B are not independent.
Exercise 4.52 Let X and Y be two independent random variables, and assume that
PX = B(2, 1/2) and PY = B(2, 1/3), respectively. Compute P(XY = 2).
21
6
3
Exercise 4.53 Let X and Y be two independent random variables and assume
that X is uniformly distributed on the interval [0, 1] while PY = exp(Î»);
(i) Compute E
%
Y 2/(1 + X)
&
.
(ii) Compute P(X â‰¤Y).
(iii) Compute the joint distribution of X2 and XY.
Exercise 4.54 Assume that X and Y are two independent random variables
on (, E, P). Assume X() = Y() = {âˆ’1, 1}, and that P(X = 1) = 1
2 and
P(Y = 1) = 1
3. Compute P(XY = 1).
21
2
3
Exercise 4.55 Assume X and Y are independent random variables. Suppose
that X and Y follow the geometric distribution of parameters p = 1/2 and
q = 1/4, respectively. Compute P(X = Y).
21
5
3

136
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Exercise 4.56 The joint density of two random variables X and Y is
f (x, y) =

C
if âˆ’1 < x < y < 1,
0
otherwise.
(i) Compute C.
21
2
3
(ii) Compute the densities of the marginal distributions PX and PY.
(iii) Are X and Y independent?
[No]
(iv) For each a âˆˆR compute P(X + Y > a).
â¡
â¢â¢â¢â¢â¢â¢â£
â§
âªâªâªâªâªâªâ¨
âªâªâªâªâªâªâ©
0
if a â‰¥1,
(2 âˆ’a)2
8
if a âˆˆ[0, 1[,
1 âˆ’(a + 2)2
8
if a âˆˆ] âˆ’2, 0[,
1
if a â‰¤âˆ’2.
â¤
â¥â¥â¥â¥â¥â¥â¦
Answer the same questions for the joint density
f (x, y) =

C
if x2 + y2 â‰¤R2,
0
otherwise,
where R > 0 is given.
Exercise 4.57 Let X and Y be two independent random variables with absolutely
continuous distributions, PX(dt) = fX(t) dt, PY (dt) = fY (t) dt where
fX(x) =

6x(1 âˆ’x)
x âˆˆ[0, 1],
0
otherwise,
and
fY (y) =

2y
y âˆˆ[0, 1],
0
otherwise,
respectively.
(i) Check that
.
R fX(s) ds =
.
R fY (s) ds = 1.
(ii) Compute the density of the random variable Z = X2Y.
%
x2 âˆ’8x3/2 + 6x if x âˆˆ[0, 1], 0 otherwise
&
.
Exercise 4.58 Let X and Y be independent random variables following the stan-
dard Gaussian distribution N(0, 1);
(i) Compute Cov(3X + 2Y, X + 5Y + 10).
(ii) Compute P(X + 4Y â‰¥2).
(iii) Compute P((X âˆ’Y)2 > 9).

VECTOR VALUED RANDOM VARIABLES
137
Exercise 4.59 Assume X and Y are independent random variables following two
exponential distributions. Compute the distribution of X/Y.
Exercise 4.60 Assume X and Y are independent random variables following the
exponential distribution exp(Î»). Compute the distribution of |X âˆ’Y|.
Exercise 4.61 Assume that both the independent random variables X and Y follow
the distribution (Î±, Î»). Compute the joint law of U := X + Y and V :=
X
X + Y .
Solution. Let Ï• be a non-negative B(R2) function and let fÎ±,Î» and fÎ²,Î» be
the densities of PX and PY, respectively. We have
**
R2 Ï•(u, v) PU,V (dudv) =
**
R2 Ï•(x + y,
x
x + y ) PX,Y (dxdy)
=
**
R2 Ï•(x + y,
x
x + y )fÎ±,Î»(x)fÎ²,Î», (y) dxdy.
Consider the map g(x, y) := (x + y,
x
x+y ). g is a one-to-one map between
R2 \ {x + y = 0}
onto

(r, s) âˆˆR2 | r = 0

with
inverse
h(r, s) :=
(rx, r(1 âˆ’s)). By changing variable the last integral amounts to
=
**
R2 Ï•(r, s)fÎ±,Î»(rs)fÎ²,Î»(r(1 âˆ’s)) |J(Dh(r, s))| drds
so that
P(U â‰¤u, V â‰¤v) =
**
râ‰¤u, sâ‰¤v
fÎ±,Î»(rs)fÎ²,Î»(r(1 âˆ’s)) |J(Dh(r, s))| drds.
Computing the previous double integral yields
P(U â‰¤u, V â‰¤v)
=
* u
0
dr
* min(1,v)
0
r Î»Î±(rs)Î±âˆ’1eâˆ’Î»rs
(Î±)
Î»Î²(r(1 âˆ’s))Î²âˆ’1eâˆ’Î»r(1âˆ’s)
(Î²)
ds =
= (Î± + Î²)
(Î±)(Î²)
* u
0
fÎ±+Î²,Î»(r)dr
* min(1,v)
0
sÎ±âˆ’1(1 âˆ’s)Î²âˆ’1 ds.
Thus, the random variable U follows a  distribution of parameters Î± + Î² and
Î» (a fact which was already proved in Exercise 4.49) and the distribution of V
is supported in the interval [0, 1], with density (Î± + Î²)
(Î±)(Î²)vÎ±âˆ’1(1 âˆ’v)Î²âˆ’1.
Exercise 4.62 Assume X1, . . . , Xn are independent random variables following
the standard Gaussian distribution N(0, 1), and let Y := n
k=1 X2
k. Show that
PY = Ï‡2(n). We recall that Ï‡2(n) = ( n
2, 1
2).

138
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Exercise 4.63 Mark and John have decided to meet at the Pub â€˜Born to be
Stochasticâ€™ between noon and 1pm without waiting for more than 15min for each
other. Assume Mark and Johnâ€™s arrival times at the Pub are independent random
variables that are uniformly distributed in the time interval from noon to 1pm.
Compute the probability of Mark and John meeting at the Pub.
Solution. Denote with M and J the random variables describing the arrival
time for Mark and John, respectively. Using the minute as the unit of measure-
ment, both M and J are uniformly distributed in the interval (0, 60). Mark and
John meet if and only if |G âˆ’M| â‰¤15. Since J and M are independent, the joint
distribution of (J, M) is uniformly distributed on the square [0, 60]2, that is, it
is absolutely continuous with density
1
36001[0,60]2(x, y). Denoting by R the set
R :=

(s, t) âˆˆ[0, 60]2  |s âˆ’t| â‰¤15

,
we conclude that
P(|G âˆ’M| â‰¤15) =
**
R
1
3600 dsdt = 7
16.
Exercise 4.64 Flip a fair coin and throw a fair dice together many times. Compute
the probability of the event â€˜We obtain a head on the coin before obtaining a six
on the diceâ€™. Compute the probability of the event â€˜The success of the ï¬rst process
occurs before the ï¬rst success of the second processâ€™.
Solution. We are considering two independent Bernoulli processes whose
probability of success is p = 1/2 and q = 1/6, respectively. Let H be the random
variable â€˜Flipping of the coin at which the ï¬rst head occursâ€™ and let S be the
random variable â€˜Throw of the dice at which the ï¬rst six occursâ€™. Thus, H and S
are geometric random variables of parameter p = 1/2 and q = 1/6, respectively:
P(H = k) = p(1 âˆ’p)kâˆ’1,
P(S = k) = q(1 âˆ’q)kâˆ’1,
k = 1, 2, . . . .
We want to compute P(H < S). Since
{H < S} =
âˆ
(
k=2
{S = k, H < k}
and H and S are independent random variables, we get
P(H < S) =
âˆ

k=2
P(S = k, H < k) =
+âˆ

k=2
P(S = k)P(H < k).
On the other hand,
P(H < k) =
kâˆ’1

j=1
P(H = j) =
kâˆ’1

j=1
p(1 âˆ’p)jâˆ’1

VECTOR VALUED RANDOM VARIABLES
139
=
kâˆ’2

i=0
p(1 âˆ’p)i = 1 âˆ’(1 âˆ’p)kâˆ’1,
hence we infer
P(H < S) =
+âˆ

k=2
q(1 âˆ’q)kâˆ’1 
1 âˆ’(1 âˆ’p)kâˆ’1
=
p(1 âˆ’q)
p + q âˆ’pq .
In particular, in the case of a fair coin and a fair dice we have P(H < S) = 5/7.
Exercise 4.65
Let W1, . . . , Wn be identically distributed independent random
variables following the exponential distribution exp(Î»). Compute the law of Sn :=
n
k=0 Wk.
Solution. By assumption, for each k = 1, . . . , n we have PWk = Ï(s) ds with
Ï(s) =
0
if s < 0,
Î»eâˆ’Î»s
if s â‰¥0.
By Theorem 4.44, PW1+W2(ds) = Ï2(s) ds where
Ï2(s) =
0
if s < 0,
. s
0 Î»2eâˆ’Î»teâˆ’Î»(sâˆ’t) dt = Î»eâˆ’Î»s(Î»s)
if s â‰¥0.
By induction, one proves that PSn(ds) = Ïn(s) ds where
Ïn(s) =
â§
âªâ¨
âªâ©
0
if s < 0,
Î»eâˆ’Î»s (Î»s)nâˆ’1
(n âˆ’1)! = Î»nsnâˆ’1eâˆ’Î»s
(n)
if s â‰¥0.
i.e. Sn follows the Gamma distribution (n, Î»), also known as the Erlang distri-
bution of parameters n and Î».
Clearly, P(Sn â‰¤t) = 0 if t â‰¤0. Assume now t > 0. Deï¬ne I0 = 0 and, for
each k â‰¥1 let Ik := P(Sk > t). Integrating by parts, we get the recursion formula
Ik+1 =
* âˆ
t
Ïk+1(s) ds =
* +âˆ
t
Î»eâˆ’Î»s (Î»s)k
k!
ds
=
* +âˆ
Î»t
eâˆ’Ï„ Ï„ k
k! dÏ„ = eâˆ’Î»t (Î»t)k
k!
+ Ik
for every k â‰¥1. This yields In = nâˆ’1
k=0 eâˆ’Î»t (Î»t)n
n!
and therefore
P(W1 + W2 + Â· Â· Â· + Wn â‰¤t) = 1 âˆ’In = 1 âˆ’
nâˆ’1

k=0
eâˆ’Î»t (Î»t)k
k! .

140
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
4.4
Sequences of independent random variables
Let

Xn

be a sequence of random variables deï¬ned on the same probability
space (, E, P) and with the same ï¬nite expected value: E
%
Xn
&
= E âˆˆR âˆ€n.
We are concerned with the convergence
X1 + X2 + Â· Â· Â· + Xn
n
â†’E
(4.26)
under appropriate independence relations of the sequence

Xn

.
Consider, for instance, a sequence

Xn

of independent Bernoulli trials of
parameter 1/2, so that E
%
Xn
&
= 1/2 and Var [Xn] = 1/4. Thus Sn := X1 +
X2 + Â· Â· Â· + Xn yields the number of successes in n trials and Sn/n is the rate
of success in n trials. The limit as n â†’âˆof Sn(x)/n may even not exist and,
in general, it should depend on x, that is, on the particular sequence of trials: if
success always occurs, then the rate of success is constantly 1, while, if failure
always occurs, then such a rate is zero for every n. Nevertheless, experience
suggests that almost certainly, that is for almost all sequences of trials, such a
rate approaches 1/2 as n â†’âˆ. The mathematical formulation of this intuition
is the so-called strong law of large numbers.
4.4.1
Weak law of large numbers
Before dealing with the law of large numbers, we start with an estimate of the
average of a ï¬xed number of random variables.
Theorem 4.66 (L2 and weak estimates) Let X1, . . . , Xn be real-valued random
variables on a probability space (, E, P), and let Sn(x) := n
k=1 Xk(x). If the

Xn

are pairwise uncorrelated, with the same expected value E := E
%
Xk
&
âˆ€k
and with ï¬nite variance, then
*

Sn(x)
n
âˆ’E

2
P(dx) â‰¤C2
n
(4.27)
where C2 := maxk Var
%
Xk
&
; in particular,
P

|Sn
n âˆ’E| â‰¥Î´

â‰¤C2
Î´2 n
âˆ€Î´ > 0.
(4.28)
Proof. Observe that
E
%
Sn
&
=
n

k=1
E
%
Xk
&
= nE,
hence, by (4.17),
*

Sn(x)
n
âˆ’E

2
P(dx) = Var
2 Sn
n
3
= 1
n2
n

k=1
Var
%
Xk
&
â‰¤C2
n .

VECTOR VALUED RANDOM VARIABLES
141
Therefore, the Chebyshev inequality yields
P

|Sn
n âˆ’E| â‰¥Î´

â‰¤1
Î´2
*

|Sn(x)
n
âˆ’E|2 P(dx) â‰¤C2
Î´2 n.
Inequality (4.28) says that the event â€˜The distance of Sn(x)/n from its mean
E is greater that Î´â€™ has probability smaller than C2/(Î´2n). If P is the uniform
probability on , then (4.28) reads as â€˜The distance between Sn(x)/n and its
mean E is larger than Î´ in no-more than 100 C2/(Î´2n) per cent of casesâ€™. Notice
that we have obtained an estimate on the percentage of cases, a fact which agrees
with having only a probabilistic knowledge of the phenomenon. In particular,
increasing n yields a better relative estimate, but, likely, the absolute number of
cases may increase.
Clearly, (4.28) is not interesting if C2/(Î´2n) is larger than or equal to 1.
Theorem 4.66 is not the only result of this kind; experience teaches than
if n is large enough, then the left-hand term in (4.28) is much smaller than the
right-hand one. The following theorem, also known as the law of large deviations
provides a hint.
Theorem 4.67 (Cernoff) Let X1, . . . , Xn be equidistributed independent random
variables such that E
%
eÎ¸0|X1| &
< +âˆfor some Î¸0 > 0. Let E := E
%
X1
&
and
Sn := n
k=1 Xk. Then for any Î´ > 0 there exists a positive constant C = C(Î´) > 0
such that
P

|Sn
n âˆ’E| > Î´

â‰¤2 eâˆ’C(Î´)n.
C(Î´) can be explicitly computed:
C(Î´) :=
sup
0<Î¸<Î¸0
(Î¸Î´ âˆ’log M(Î¸)),
where
M(Î¸) := E
%
eÎ¸|X1| &
.
Theorem 4.66 yields immediately a version of the weak law of large numbers,
or WLN, for short.
Theorem 4.68 (Weak law of large numbers) Let

Xn

be a sequence of random
variables on a probability space (, E, P). Assume that the Xnâ€™s are pairwise
uncorrelated with the same expected value E
%
Xn
&
= E and with equibounded
variances, Var
%
Xn
&
â‰¤C2 âˆ€n. For every n = 1, 2, . . . , set Sn := n
k=1 Xk. Then
*

Sn(x)
n
âˆ’E

2
P(dx) â†’0
as n â†’âˆ
and
P

|Sn
n âˆ’E| > Î´

â†’0
as n â†’âˆ.
(4.29)
Convergence in probability (4.29) also holds in other situations. Since the
almost sure convergence discussed below implies convergence in probability, the

142
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Etemadi theorem, Theorem 4.81, improves a classical result by Khinchin,
as follows.
Theorem 4.69 Let

Xn

be a sequence of summable, pairwise independent and
equidistributed random variables on a probability space (, E, P). Set Sn :=
n
k=1 Xk. Then for every Î´ > 0
P

|Sn
n âˆ’E| > Î´

â†’0
as n â†’âˆ.
4.4.2
Borelâ€“Cantelli lemma
We are now going to discuss an interesting property of the intersection of
inï¬nitely many events.
Assume (, E, P) is a probability space and let

An

âŠ‚E be a sequence of
events. Deï¬ne
lim sup
n
An :=
âˆ
'
m=1
âˆ
(
n=m
An
i.e. the set of those x âˆˆ belonging to inï¬nitely many Anâ€™s.
Proposition 4.70 (Borelâ€“Cantelli lemma) Let

An

be a sequence of events on
a probability space (, E, P). If âˆ
n=1 P(An) < +âˆ, then
P(lim sup
n
An) = 0.
Proof. Since P is denumerably subadditive and since the series âˆ
n=1 P(An)
converges, we infer
P(lim sup
n
An) â‰¤P
 âˆ
(
n=m
An

â‰¤
âˆ

n=m
P(An) â†’0
as m â†’âˆ.
If the events

An

are independent, then the statement of the Borelâ€“Cantelli
lemma is indeed an equivalence. In fact, the following holds.
Proposition 4.71 Assume that

An

is a sequence of independent events
on a probability space (, E, P). If the series âˆ
n=1 P(An) diverges, then
P(lim supn An) = 1.
Proof. Let m, q âˆˆN, m â‰¤q. By the independence assumption, using also the
inequality 1 âˆ’x â‰¤eâˆ’x âˆ€x âˆˆ[0, 1], we get
P

q'
n=m
Ac
n

=
q=
n=m
P(Ac
n) =
q=
n=m
(1 âˆ’P(An))
â‰¤
q=
n=m
eâˆ’P(An) = exp

âˆ’
q

n=m
P(An)

.

VECTOR VALUED RANDOM VARIABLES
143
As q goes to inï¬nity we get
P
 âˆ
'
n=m
Ac
n

â†’0
for every m,
thus,
P

(lim sup
n
An)c
= lim
mâ†’âˆP
 âˆ
'
n=m
Ac
n

= 0.
Combining Propositions 4.70 and 4.71 we get the following.
Corollary 4.72 (Kolmogorov 0-1 law) Let

An

be a sequence of independent
events in a probability space (, E, P). Then
P(lim sup
n
An) = 0
if and only if
âˆ

n=1
P(An) < âˆ
and
P(lim sup
n
An) = 1
if and only if
âˆ

n=1
P(An) = +âˆ.
Actually, the claims in Proposition 4.71 and Corollary 4.72 still hold for
pairwise independent events

An

.
Theorem 4.73 Let

An

be a sequence of pairwise independent events in a prob-
ability space (, E, P). If âˆ
n=1 P(An) = +âˆ, then
lim
nâ†’âˆ
n
k=1 1Ak(x)
n
k=1 P(Ak) = 1
P-a.e.;
in particular, for P-almost every x âˆˆ the series âˆ
k=1 1Ak(x) diverges, i.e. x
belongs to inï¬nitely many Anâ€™s for P-a.e. x, that is, P(lim supn An) = 1.
We omit the proof of Theorem 4.73, which can be found e.g. in [4].
Remark 4.74 Notice that the assumption of independence cannot be dropped. As
an example, throw a fair dice and let A be the event â€˜6 on the topâ€™. Deï¬ne An :=
A for every n. Thus âˆ
n=1 P(An) = 1/6 + 1/6 + Â· Â· Â· = +âˆwhile lim supn An =
A so that P(A) = 1/6.
4.4.3
Convergences of random variables
Three different kinds of convergence of random variables appear in discussing
the law of large numbers.
Deï¬nition 4.75 Let X and Xn, n âˆˆN, be random variables in a probability space
(, E, P).

144
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
(i) The sequence

Xn

is said to converge in L2 to X if
*

|Xn âˆ’X|2 P(dx) â†’0
as n â†’âˆ.
(ii) The sequence

Xn

is said to converge in probability to X if for every Î´ > 0
P

|Xn âˆ’X| > Î´

â†’0
as n â†’âˆ.
(iii) The sequence

Xn

is said to converge P-almost surely or P-almost
everywhere if the probability of the event
E : =

x âˆˆ
 Xn(x) â†’Â±âˆor Xn(x) Ì¸â†’X(x)

=

x âˆˆ
 lim sup
nâ†’âˆ
|Xn(x) âˆ’X(x)| > 0
$
is null, P(E) = 0. With a shortened notation we write Xn â†’X P-a.s., or
Xn â†’X P-a.e., or
P(Xn â†’X) = 1
when

Xn

converges to X P-almost surely.
Of course, the above three types of limit are unique P-a.e., provided they
exist. The three types of convergence are related in several ways although they
are not equivalent. In particular, it can be shown, see Appendix B, that
(i) If Xn â†’X in L2, then Xn â†’X in probability.
(ii) If Xn â†’X P-a.e., then Xn â†’X in probability.
The following example shows that convergence in probability and conver-
gence P-a.e. are not equivalent.
Example 4.76 Divide [0, 1] in one part, two parts, three parts, etc. Enu-
merate sequentially the intervals thus obtained, i.e. I0 = [0, 1], I1 = [0, 1/2],
I2 = [1/2, 1], I3 = [0, 1/3]. . . .. We therefore obtain a sequence

In

of
intervals. Consider the uniform probability on [0, 1]. It is then easy to check
that the sequence

1In(x)

converges in probability to the null random variable
but does not converge pointwisely at any x, in particular,

1In(x)

does not
converge almost surely.
The following proposition clariï¬es the meaning of the almost sure conver-
gence.
Proposition 4.77 Let X, Xn, n âˆˆN be random variables on the probability space
(, E, P). The following are equivalent:

VECTOR VALUED RANDOM VARIABLES
145
(i) Xn â†’X P-almost surely, P(Xn â†’X) = 1.
(ii) For every Î´ > 0 then with zero probability |Xn(x) âˆ’X(x)| > Î´ for inï¬nitely
many indexes n.
(iii) For every Î´ > 0 then P-almost surely |Xn(x) âˆ’X| â‰¤Î´ for n large enough
(depending on x).
More formally, if for Î´ > 0 and n âˆˆN,
An,Î´ :=

x âˆˆ
 |Xn âˆ’X| > Î´

and
EÎ´ := lim inf
n
An,Î´,
then (ii) means that P(EÎ´) = 0 for every Î´ > 0.
Proof of Proposition 4.77.
(i) â‡”(ii). Let
E =

x âˆˆ
 lim sup
nâ†’âˆ
|Xn(x) âˆ’X(x)| > 0
$
and let

Î´k

be a sequence monotonically decreasing to 0. Trivially,

EÎ´k

is an
increasing sequence of events and E = âˆªkEÎ´k. This shows that E is an event
and that P(EÎ´) â‰¤P(E) âˆ€Î´ > 0. If (i) holds, then P(EÎ´) â‰¤P(E) = 1 âˆ’P(Xn â†’
X) = 0, i.e. (ii).
Conversely, if (ii) holds, i.e. P(EÎ´) = 0 for every Î´ > 0, from the continuity
property of the measure, we get
P(E) = lim
k P(EÎ´k) = 0,
hence P(Xn â†’X) = 1 âˆ’P(E) = 1.
(ii) â‡”(iii). In fact, (ii) is equivalent to P(Ec
Î´) = 1 for every Î´ > 0, hence (ii) is
equivalent to (iii) since
Ec
Î´ =

x âˆˆ
 |Xn(x) âˆ’X(x)| â‰¤Î´ deï¬nitely

.
Let X, Xn, n â‰¥1, be random variables. For every Î´ > 0 and n âˆˆN set
An,Î´ =

x âˆˆ
 |Xn(x) âˆ’X(x)| > Î´

and EÎ´ := lim supnâ†’âˆAn,Î´. If âˆ
n=1 P(An,Î´) < +âˆ, then by the Borelâ€“Cantelli
lemma, P(EÎ´) = 0. Taking into account Proposition 4.77, we then state the fol-
lowing.
Proposition 4.78 If for every Î´ > 0 the series âˆ
n=1 P(An,Î´) converges, then
Xn â†’X P-almost surely.

146
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
4.4.4
Strong law of large numbers
Let

Xn

be a sequence of random variables and let Sn := n
j=1 Xj. We now
discuss P-almost sure convergence of the averages Sn/n of the Xnâ€™s.
Lemma 4.79 Let

Xn

be a sequence of random variables in the probability space
(, E, P) such that E
%
Xn
&
= E âˆ€n. If âˆ
n=1 Var
%
Xn
&
< +âˆ, then Xn â†’E
P-almost surely.
Proof. Since, by assumption, the series âˆ
n=1
.
 |Xn(x) âˆ’E|2 P(dx) con-
verges, Lebesgue dominated convergence theorem for series yields that the series
âˆ
k=1 |Xk(x) âˆ’E| converges in L2 and P-almost surely. In particular, Xn â†’E
P-almost surely.
Another proof of Lemma 4.79. For any positive Î´ and any n âˆˆN, let An,Î´ =

x âˆˆ | |Xn(x) âˆ’E| > Î´

. By the Chebyshev inequality
P(An,Î´) â‰¤1
Î´2
*

|Xn(x) âˆ’E|2 P(dx).
Thus, from the assumptions, the series âˆ
n=1 P(An,Î´) converges. The claim then
follows from Proposition 4.78 since Î´ is an arbitrary positive number.
We now state a version of the strong law of large numbers.
Theorem 4.80 (Rajchman) Let

Xn

be a sequence of pairwise uncorrelated
random variables on the probability space (, E, P). Assume E
%
Xn
&
= E and
Var
%
Xn
&
â‰¤C2 âˆ€n, and for n = 1, 2, . . . , let Sn := n
k=1 Xk. Then Sn/n â†’E
in L2, in probability and P-almost surely.
Proof. The L2 convergence and the convergence in probability are already
proved in Theorem 4.68. It remains to prove P-almost sure convergence.
Replacing Xn by Xn âˆ’E, we may assume E
%
Xn
&
= 0. Set, for convenience,
S0 = 0. Since the random variables Xn are pairwise uncorrelated, for any i, j,
0 â‰¤i < j, we have
Var [Sj âˆ’Si] = Var
4
j

k=i+1
Xk
5
=
j

k=i+1
Var [Xk] â‰¤C2(j âˆ’i).
(4.30)
Applying (4.30) with j = n2 and i = 0 we get
Var [Sn2] â‰¤C2 n2,
hence
âˆ

n=1
Var
2 Sn2
n2
3
â‰¤C2
âˆ

n=1
1
n2 < +âˆ,

VECTOR VALUED RANDOM VARIABLES
147
and consequently, since E
%
Sn2
&
= 0, we get
Sn2
n2 â†’0
P-almost surely
by Lemma 4.79.
For any p âˆˆN, let n = n(p) be such that n2 â‰¤p < (n + 1)2. Clearly,
Sn2
p = Sn2
n2
n2
p â†’0
P-almost surely.
(4.31)
On the other hand, since (n + 1)2 âˆ’n2 = 2n + 1 â‰¤2âˆšp + 1, by (4.30) we get
âˆ

p=1
Var
2Sp
p âˆ’Sn2
p
3
â‰¤C2
âˆ

p=1
p âˆ’n2
p2
â‰¤C2
âˆ

p=1
2âˆšp + 1
p2
< +âˆ,
and, since E
0 Sp
p âˆ’
Sn2
p
1
= 0, Lemma 4.79 implies that
Sp
p âˆ’Sn2
p â†’0
P-almost surely.
(4.32)
Since
Sp
p =
Sp
p âˆ’Sn2
p

+ Sn2
p ,
from (4.31) and (4.32) we ï¬nally conclude that Sp/p converges to zero P-almost
surely.
Theorem 4.80 is one of the possible results known as the strong law of large
numbers. It can be generalized in various directions, weakening certain assump-
tions and strengthening others. We refer the reader to the specialized literature,
see e.g. [4â€“6]. Here we quote the following theorem, where no assumption on
the variances is required.
Theorem 4.81 (Etemadi) Let

Xn

be a sequence of pairwise independent,
equally distributed and summable random variables on the probability space
(, E, P). Let E = E
%
X1
&
âˆˆR and for n â‰¥1 let Sn = n
k=1 Xk. Then
Sn(x)
n
â†’E
P-almost surely.
We remark that the summability assumption can be weakened: integrability
sufï¬ces, allowing E = +âˆor E = âˆ’âˆ, see Exercise 4.11.
Let us ï¬rst state a few lemmas.
Lemma 4.82

n > x
1
n2 â‰¤2
x for any x > 0.

148
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Proof. In fact, let m = âŒŠxâŒ‹+ 1. We then have
âˆ

n=m
1
n2 â‰¤1
m2 +
* âˆ
m
1
t2 dt = 1
m2 + 1
m â‰¤2
x .
Lemma 4.83 Let Î± > 1 and kn := âŒŠÎ±nâŒ‹. Then

n,knâ‰¥j
1
k2n
â‰¤
4Î±2
Î±2 âˆ’1
1
j2 .
Proof. We ï¬rst show that kn â‰¥Î±n/2. In fact, if Î±n â‰¤2, then kn â‰¥1 â‰¥Î±n/2;
if Î±n > 2 then kn â‰¥Î±n âˆ’1 > Î±n/2.
Let n0 :=
 
log j
log Î±
!
. If kn â‰¥j, then Î±n â‰¥j, so that n â‰¥log j
log Î± â‰¥n0. Thus

n, knâ‰¥j
1
k2n
â‰¤4
âˆ

n=n0
1
Î±2n =
4
Î±2n0
1
1 âˆ’Î±âˆ’2 â‰¤
4Î±2
Î±2 âˆ’1
1
j 2 .
Lemma 4.84 Let

Xn

be a sequence of identically distributed real valued random
variables. For any n âˆˆN, set
Yn(x) := Xn(x)1{|Xn|<n}(x) =

Xn(x)
if |Xn(x)| â‰¤n,
0
otherwise
and let Sn := n
j=1 Xj and Tn := n
j=1 Yj. If T n(x)/n â†’Î¼ P-almost surely,
then Sn(x)/n â†’Î¼ almost surely.
Proof. Let An :=

x âˆˆ | Xn(x) Ì¸= Yn(x)

. Applying the Cavalieri formula
(3.14) we get
âˆ

n=1
P(An) =
âˆ

n=1
P(|Xn| > n) =
âˆ

n=1
P(|X1| > n) = E
%
|X1|
&
< +âˆ.
Thus, we infer from the Borelâ€“Cantelli lemma that for almost every x âˆˆ there
exists n = n(x) such that Xn(x) = Yn(x) for every n â‰¥n, hence
Sn(x) âˆ’Tn(x)
n
=
Sn0(x) âˆ’Tn0(x)
n
â†’0
as n â†’âˆ
P-almost surely.
Since by assumption Tn(x)/n â†’Î¼ almost surely, also Sn(x)/n â†’Î¼ P-almost
surely.
Lemma 4.85 Let

Xn

be a sequence of summable, identically distributed random
variables. For any n â‰¥1, let Yn := Xn1{|Xn|â‰¤n}. Then
âˆ

j=1
E
0
Y 2
j
1
j2
â‰¤4E
%
|X1|
&
.

VECTOR VALUED RANDOM VARIABLES
149
Proof. The Cavalieri formula yields
E
%
Y 2
j
&
=
* âˆ
0
P(Y 2
j > t) dt =
* âˆ
0
2 s P(|Yj| > s) ds =
* j
0
2 s P(|Yj| > s) ds
â‰¤
* j
0
2 s P(|Xj| > s) ds =
* j
0
2 s P(|X1| > s) ds
=
* âˆ
0
2 s 1[0,j](s)P(|X1| > s) ds.
Then, using the Beppo Levi theorem, Lemma 4.82 and Cavalieri formula, we
conclude
âˆ

j=1
E
0
Y 2
j
1
j2
=
* âˆ
0
2 s
 âˆ

j=1
1
j2
1[0,j](s)

P(|X1| > s) ds
=
* âˆ
0
2 s

j > s
1
j 2 P(|X1| > s) ds
â‰¤4
* âˆ
0
P(|X1| > s) ds = 4E
%
|X1|
&
.
Proof of the Etemadi theorem. Both

X+
n

and

Xâˆ’
n

are sequences of
summable, identically distributed and pairwise independent random variables,
thus we may restrict ourselves to the case Xn â‰¥0 âˆ€n. The random variables
Yn(x) = Xn(x)1{|Xn|â‰¤n},
x âˆˆ,
are
bounded,
non-negative
and
pairwise
independent. Let Tk(x) := k
j=1 Yj(x). Thanks to Lemma 4.84 it is enough to
show that for P-almost all x âˆˆ
Tk(x)
k
â†’E
%
X1
&
as k â†’âˆ.
Let Î± > 1 and kn := âŒŠÎ±nâŒ‹. Since the random variables

Yn

are pairwise
independent, they are also uncorrelated, thus, using Chebyshev inequality we get
P

|Tkn âˆ’E
%
Tkn
&
| > knÎ´

â‰¤Var [Tkn]
Î´2k2n
=
1
Î´2k2n
kn

j=1
Var [Yj]
âˆ€Î´ > 0.
Thus, by Lemmas 4.83 and 4.84 we infer
âˆ

n=1
P

|Tkn âˆ’E
%
Tkn
&
| > knÎ´

â‰¤1
Î´2
âˆ

n=1
1
k2n
kn

j=1
Var [Yj] = 1
Î´2
âˆ

j=1
Var [Yj]
 
n, knâ‰¥j
1
k2n


150
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
â‰¤1
Î´2
4Î±2
Î±2 âˆ’1
âˆ

j=1
Var [Yj]
j2
â‰¤16Î±2
a2 âˆ’1
1
Î´2 E
%
|X1|
&
< +âˆ
for every Î´ > 0. Therefore, see Proposition 4.78,
Tkn(x) âˆ’E
%
Tkn
&
kn
â†’0
P-almost surely.
(4.33)
Since the random variables are non-negative, Beppo Leviâ€™s theorem yields
E
%
Yn
&
= E
%
Xn1{Xnâ‰¤n}
&
= E
%
X11{X1â‰¤n}
&
â†’E
%
X1
&
.
Hence by the Cesaro theorem,
E
%
Tkn
&
kn
â†’E
%
X1
&
.
(4.34)
Thus, (4.33) and (4.34) yield
Tkn(x)
kn
â†’E
%
X1
&
P-almost surely.
(4.35)
For any k â‰¥1, let n = n(k) such that kn < k â‰¤kn+1. Clearly n goes to inï¬nity
as k goes to inï¬nity. Since Yk â‰¥0 for any k, we have
kn
n
Tkn(x)
kn
â‰¤Tk(x)
k
â‰¤
Tkn+1(x)
kn+1
kn+1
n .
From kn â‰¤Î±n â‰¤kn + 1 â‰¤k â‰¤kn+1 â‰¤Î±n+1, we have
Î±n âˆ’1
Î±n+1
â‰¤kn
n ,
kn+1
n
â‰¤Î±n+1
Î±n
= Î±,
hence the inequalities
Î±n âˆ’1
Î±n
Tkn(x)
kn
â‰¤Tk(x)
k
â‰¤
Tkn+1(x)
kn+1
Î±.
(4.36)
Letting k â†’âˆin (4.36), we then get from (4.35)
1
Î± E
%
X1
&
â‰¤lim inf
kâ†’âˆ
Tk(x)
k
â‰¤lim sup
kâ†’âˆ
Tk(x)
k
â‰¤Î± E
%
X1
&
(4.37)
P-almost surely. Since Î± > 1 is arbitrary, we conclude that
lim
kâ†’âˆ
Tk(x)
x
= E
%
X1
&
P-almost surely,
see Exercise 4.110. The claim is proven.

VECTOR VALUED RANDOM VARIABLES
151
Finally, we quote a further estimate on the averages of a sequence of random
variables, known as the law of the iterated logarithm which yields a more precise
asymptotic behaviour as n â†’âˆ.
Theorem 4.86 (Hartmanâ€“Wintner) Let

Xn

be a sequence of independent
identically distributed random variables with zero expected value and variance,
E = E
%
Xn
&
= 0 and Var
%
Xn
&
= C2 (thus Sn/n â†’0 P-almost surely), and, for
n â‰¥1, let Sn = n
k=1 Xk. Then
lim sup
nâ†’âˆ
Sn(x)
C

2 n log log n
= 1
P-almost surely.
In particular, for any Î´ > 0 P-almost surely we have
|Sn(x)| â‰¤C
âˆš
2(1 + Î´)

n log log n
deï¬nitely.
4.4.4.1
Existence of a sequence of independent
random variables
A problem one should consider is the one of the existence of a sequence of inde-
pendent identically distributed random variables on the same probability space
(, E, P). Let us construct a sequence of this kind going back to the Bernoulli
inï¬nite process: ï¬x a probability space (, E, P). Denote by âˆthe set of all
sequences taking values in . As for the inï¬nite Bernoulli scheme, one proves,
using the Method I of construction of measures, see Section 2.2.5 and Appendix
B, the existence of a probability measure (Eâˆ, Pâˆ) on âˆsuch that for any
n âˆˆN and for any E1, . . . , En âˆˆE the set E âŠ‚âˆdeï¬ned by
E =

x =

xn

âˆˆâˆ xi âˆˆEi âˆ€i = 1, . . . , n

is an event, E âˆˆEâˆand
Pâˆ(E) =
n
=
i=1
P(Ei).
One can now easily check the following.
Proposition 4.87 Let X :  â†’R be a random variable on (, E, P). Then the
random variables Xk deï¬ned on (âˆ, Eâˆ, Pâˆ) for k = 1, 2, . . . by
Xk(x) := X(xk)
if
x =

xk

are independent random variables equidistributed as X, i.e. (Pâˆ)Xk = PX
âˆ€k.

152
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
4.4.5
A few applications of the law of large numbers
4.4.5.1
Bernstein polynomials
The following approximation theorem is a classical application of the weak law
of large numbers. Let f : [0, 1] â†’R be a function. The polynomials
pn(x) :=
n

j=0
n
j

f
j
n

xj(1 âˆ’x)nâˆ’j
are called Bernstein polynomials of f . Clearly the degree of pn(x) cannot
exceed n.
Theorem 4.88 (Bernstein) Let f âˆˆC0([0, 1]). Then pn(x) â†’f (x) uniformly in
the interval [0, 1].
In particular, the Bernstein theorem proves that the space of polynomials is
dense in C0([0, 1]) with respect to the uniform convergence; a property which
the space of partial sums of power series does not satisfy.
Proof. Let

Xn

be a sequence of independent Bernoulli trials of parameter
x. Thus E
%
Xn
&
= x and Var [Xn] = x(1 âˆ’x) â‰¤1/4. Recall the weak estimate
P

|Sn
n âˆ’x| > Î´

â‰¤
1
4 Î´2 n
âˆ€Î´ > 0
(4.38)
where Sn := n
k=1 Xk.
The random variable Sn counts the number of successes in n trials, hence Sn
follows the binomial distribution of parameters n and x, so that for every j âˆˆN
P
Sn
n = j
n

= B(n, x)({j}) =
n
j

xj(1 âˆ’x)nâˆ’j.
Thus, if f âˆˆC0([0, 1]), we have
E
%
f (Sn/n)
&
=
n

j=0
f
j
n

P(Sn = j) = pn(x).
Let Îµ > 0. f is continuous, hence it is bounded, i.e. there exists a constant
M > 0 such that ||f ||âˆâ‰¤M. Moreover, f is uniformly continuous, so that there
exists Î´ > 0 such that |f (x) âˆ’f (y)| < Îµ whenever |x âˆ’y| â‰¤Î´. Thus, by (4.38),
|pn(x) âˆ’f (x)| =
E
%
f (Sn/n)
&
âˆ’E [ 1 ]f (x)
 =
E
%
f (Sn/n) âˆ’f (x)
&
â‰¤E
%
|f (Sn/n) âˆ’f (x)|
&
=
*
| Sn(t)
n
âˆ’x| > Î´
f
Sn(t)
n

âˆ’f (x)
 P(dt)

VECTOR VALUED RANDOM VARIABLES
153
+
*
| Sn(t)
n
âˆ’x|â‰¤Î´
f
Sn(t)
n

âˆ’f (x)
 P(dt)
â‰¤2 M
4 Î´2 n + Îµ.
Consequently, choosing n := M/(2Î´2Îµ) we conclude that |pn(x) âˆ’f (x)| â‰¤2Îµ
whenever n â‰¥n and x âˆˆ[0, 1]. Since Îµ is arbitrary, pn(x) â†’f (x) uniformly in
[0, 1].
4.4.5.2
The Monte Carlo method
Let Q = [0, 1]N and f âˆˆC0(Q). We want to estimate
*
Q
f (x) dx.
We may consider a method which is analogous to the one-dimensional Simpson
method. Divide each edge of Q in k parts, then one has to evaluate f in kN
points, i.e. in a very large number of points (consider for instance k = 100,
N = 4). During the Second World War, Enrico Fermi (1901â€“1954), John von
Neumann (1903â€“1957) and Stanislaw Ulam (1909â€“1984) used a probabilistic
method, called the Monte Carlo method.
Example 4.89 Take a list of 2n phone numbers, for instance from a couple of
pages of the telephone directory and, with the last two digits of each number,
form n couples of integers (i, j) âˆˆ{0, . . . , 99}2. Let T (n) be the number of
couples (i, j) such that i2 + j2 â‰¤(99)2. One can see that, as n increases, the
ratio T (n)/n gets nearer and nearer to 0.769 â‰ƒÏ€
4 (0.99)2.
Let f : RN â†’R be a bounded measurable function and set M := ||f ||âˆ.
Assume (B(RN), Î¼) is a probability measure on RN. We want to compute
f :=
*
RN f (t) Î¼(dt).
The idea is to â€˜randomly chooseâ€™ points Xj in RN and to approximate
.
f (t) Î¼(dt) with 1
n
n
j=1 f (Xj).
We can model the random choice of points as a sequence of random variables

Xn

that follow the distribution Î¼, PX = Î¼, with a suitable degree of indepen-
dence. For instance, one can consider a random variable on a probability space
(, E, P) with values in Q and following the distribution PX = Î¼, and choose
the corresponding sequence

Xn

of independent and identically distributed ran-
dom variables on the Bernoulli scheme (âˆ, Eâˆ, Pâˆ) following the distribution
PX. Then, for every positive integer n we get
E
%
f (Xn)
&
= E
%
f (X)
&
=
*
RN f (t) Î¼(dt) = f ,

154
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
E
%
|f (Xn)|
&
= E
%
|f (X)|
&
=
*
RN |f (t)| Î¼(dt) â‰¤M,
Var [f (Xn)] = Var [f (X)] =
*
RN |f (t) âˆ’f |2 Î¼(dt) â‰¤4M2.
The random variables Yn := f (Xn) are independent, see Proposition 4.36, iden-
tically distributed and their variance is not larger than 4M2. Applying the strong
law of large numbers
1
n
n

j=1
f (Xj(x)) â†’f
P-almost surely on âˆ, in L2 and in probability. In particular, for any positive
Î´ > 0 and any positive integer n
Pâˆ1
n
n

j=1
f (Xj) âˆ’f
 > Î´

â‰¤4M2
Î´2 n .
(4.39)
Consider, e.g. the case M = 1 and n = 106. Then the probability that the distance
between 1
n
n
j=1 f (Xj) and f is larger than 0.02 is less than 0.01. In particular,
if Î¼ is uniform, in 99% of cases (i.e. of random choices of n points) the error is
smaller than 0.02.
Notice that, in order to discuss the Monte Carlo method, it is enough to sup-
pose that the random variables

Xn

are such that PXn = Î¼ for each n and that the
random variables Yn = f (Xn) are pairwise uncorrelated, an easier condition since
true independence is very hard to prove in practice. If we insist on having an inde-
pendence condition on the Xnâ€™s, the pairwise independence of the Xnâ€™s sufï¬ces.
Example 4.90 Consider E âŠ‚RN, so that
Î¼(E) =
*
1E(t) Î¼(dt).
Let X be a random variable on (, E, P) following the distribution Î¼ and let

Xn

be the sequence of independent and equidistributed random variables with
PXn = PX on the Bernoulli scheme (âˆ, Eâˆ, Pâˆ). For any random point Xk,
we say that we have a success if Xk âˆˆE, failure otherwise. The number of
successes in n trials Tn,E is given by
Tn,E :=
n

j=1
f (Xj),
where
f (t) := 1E(t).
Since the variables f (Xj) are pairwise independent,
1
nTn,E â†’P(E)
Pâˆ-almost surely, in L2 and in probability with respect to the measure Pâˆ.

VECTOR VALUED RANDOM VARIABLES
155
4.4.5.3
Empirical distribution function
Let X :  â†’R be a random variable on the probability space (, E, P). We
want to approximate the law FX(t) := P(X â‰¤t).
Let us apply Monte Carlo method: ï¬x t âˆˆR and set
Et :=

x âˆˆ
 X(x) â‰¤t

.
Consider a sequence of independent identically distributed random variables

Xn

following the distribution PX of X. For each n âˆˆN, let Tn,t(x) be the
number of random variables Xj such that j â‰¤n and Xj(x) â‰¤t (i.e. count how
many times, in n trials, a number, randomly chosen according the distribution
PX, is not larger than t). Of course,
Tn,t(x) =
n

j=1
1Et(x)
and Monte Carlo method yields
1
nTn,t(x) â†’E
%
1Et
&
= P(Et) = FX(t)
where the convergence is in probability, in L2 and Pâˆ-almost surely.
The family of random variables

Fn(x, t)

n deï¬ned for x âˆˆâˆby
Fn(x, t) := 1
nTn,t(x)
is called the empirical distribution function of X. One may think of these random
variables as distributed on the vertical line through (t, 0) on the plane where the
graph (t, FX(t)) of FX(t) lives.
As we have seen, Monte Carlo method yields
Fn(x, t) â†’FX(t)
as n â†’âˆ
(4.40)
Pâˆ-almost surely, in L2 and in probability at every t. With the same procedure
one can prove that we also have
Fn(x, tâˆ’) â†’FX(tâˆ’)
as n â†’âˆ
(4.41)
Pâˆ-almost surely, in L2 and in probability at every t. One may also prove that
the convergence in (4.40) is uniform with respect to t âˆˆR and thus get the
following result.
Theorem 4.91 (Glivenkoâ€“Cantelli) With the notations above,
sup
tâˆˆR
|Fn(t, x) âˆ’FX(t)| â†’0
Pâˆ-almost surely.
Theorem 4.91 easily follows from (4.40), (4.41) and the following lemma.

156
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Lemma 4.92 Let f and fn : R â†’R, âˆ€n â‰¥1 be monotone nondecreasing
and
right-continuous
functions
such
that
f (âˆ’âˆ) = fn(âˆ’âˆ) = 0
and
f (+âˆ) = fn(+âˆ) = 1. Assume that
fn(t) â†’f (t)
and
fn(tâˆ’) â†’f (tâˆ’)
(4.42)
for any t âˆˆR. Then
sup
tâ†’R
|fn(t) âˆ’f (t)| â†’0
as n â†’âˆ.
Proof. Let k â‰¥1. For any j = 0, 1, . . . , k, set Ej := {t | f (t) â‰¥j/k} and let
tj := inf Ej. Clearly, t0 = âˆ’âˆ, tk â‰¤+âˆand tjâˆ’1 â‰¤tj for every j. Since f
is right-continuous, |f (t) âˆ’f (s)| â‰¤1
k if tjâˆ’1 â‰¤t, s < tj; in particular, |f (t) âˆ’
f (tâˆ’
j )| and |f (t) âˆ’f (t+
jâˆ’1)| â‰¤1
k. Let tjâˆ’1 â‰¤t < tj, then
fn(t) â‰¤fn(tâˆ’
j ) = f (tâˆ’
j ) âˆ’(fn(tâˆ’
j ) âˆ’f (tâˆ’
j ))
â‰¤f (t) + |fn(tâˆ’
j ) âˆ’f (tâˆ’
j )| + 1
k
fn(t) â‰¥fn(t+
jâˆ’1) = f (t+
jâˆ’1) âˆ’(fn(t+
jâˆ’1) âˆ’f (t+
jâˆ’1))
â‰¥f (t) âˆ’1
k âˆ’|fn(tjâˆ’1) âˆ’f (tjâˆ’1)|
hence
|fn(t) âˆ’f (t)| â‰¤Rn + 2
k
âˆ€t âˆˆR
(4.43)
where
Rn := max
j=1,...,k(|fn(tjâˆ’1) âˆ’f (tjâˆ’1)| + |fn(tâˆ’
j ) âˆ’f (tâˆ’
j )|).
By assumption (4.42) and, since by assumption fn(âˆ’âˆ) = f (âˆ’âˆ), fn(+âˆ) =
f (+âˆ), we infer that Rn converges to 0 as n â†’âˆ. Thus, by (4.43) |fn(t) âˆ’
f (t)| â‰¤3/k uniformly on R for large enough nâ€™s. Since k is arbitrary, the claim
is proven.
4.4.5.4
Entropy
Consider a source of information producing a random sequence of symbols from
a ï¬nite alphabet E = {1, . . . , q}. Assume that each symbol i âˆˆE has a given
probability p(i). We can model the situation as follows: consider a random
variable X :  â†’E deï¬ned on a probability space (, E, P) with mass den-
sity p = (p(i)) and let

Xn

be the sequence of independent random variables
following the same distribution deï¬ned on the Bernoulli scheme (âˆ, Eâˆ, Pâˆ).
For each n â‰¥1, let Mn = (X1, . . . , Xn) be a sequence of n symbols in E. Then,

VECTOR VALUED RANDOM VARIABLES
157
the probability that the source of information has produced the sequence Mn is
the product of the probabilities of the symbols in Mn,
P(Mn) =
n
=
i=1
p(Xi).
(4.44)
Consider, for instance, the case of a fair dice, E = {1, . . . , 6}, where each symbol
is equiprobable, i.e. p(i) = 1/6 for every i. Then the probability of each message
is 1/6n.
In general, when different symbols have different probabilities, then P(Mn)
depends on the symbols appearing in Mn: if, e.g. Mn = (1, . . . , 1) then P(Mn) =
p(1)n while if Mn = (2, . . . , 2), then P(Mn) = p(2)n and so on. However,
we claim that, when n is large enough, P-almost surely P(Mn) has the same
behaviour. In fact, (4.44) can be written as
1
n log P(Mn) = 1
n
n

k=1
log(p(Xk)).
On the other hand, the random variables Yn := âˆ’log(p â—¦Xn) are independent,
see Proposition 4.36, and follow the same distribution, that is the distribution
of Y := log(p(X)). Thus they have also ï¬nite expected value and variance.
In particular,
E
%
Yn
&
= E [ Y ] =
*
log(p(x)) PX(dx) =
q

i=1
log(p(i)) p(i).
The strong law of large numbers applies, and we infer that
1
n log P(Mn) â†’E [ Y ]
as n â†’âˆ
P-almost surely, in L2 and in probability. The number
H(p) := âˆ’

yâˆˆE
p(y) log p(y),
is called the entropy of the probability distribution of the alphabet E.
The entropy function
H(p) := âˆ’
q

i=1
pi log pi
deï¬ned on the set
 :=

p = (p1, . . . , pn) âˆˆRn 
n

i=1
pi = 1, pi â‰¥0 âˆ€i
>
,
plays a crucial role in information theory. Here we just point out that H(p)
achieves its maximum on  in just one point, i.e. (1/n, . . . , 1/n). Thus the

158
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
entropy of a set E of n-symbols is maximized if and only if the symbols in E
are equiprobable.
4.4.5.5
Waiting time
Assume that the intervals of time occurring between two breakdowns in a certain
piece of machinery have all the same length E. Of course, during an interval of
time of length nE, exactly n breakdowns occur, so that the number of breakdowns
per unit of time is
N = n
nE = 1
E .
A similar relation occurs when the times between two subsequent breakdowns
are independent random variables with the same expected value; namely, we have
the following.
Proposition 4.93 Let

Tn

be a sequence of non-negative random variables on
(, E, P). Moreover, assume the Tnâ€™s are:
â€¢ summable, with the same expected value, pairwise uncorrelated and with
equibounded variances; or
â€¢ integrable, identically distributed and pairwise independent.
Set E := E
%
Xn
&
and let Sn := n
k=1 Tk, and, for each t âˆˆR, let
Nt(x) := sup

n
 Sn(x) â‰¤t

.
Then
lim
tâ†’âˆ
Nt(x)
t
= 1
E
P-almost surely.
Example 4.94 Let

Tn

be the length of time between the (n âˆ’1)th and the nth
event, so that Sn is the length of time one has to wait to have n events. Nt is
the number of events occurring until time t. We say that

Nt

is the counting
process associated with the time random variables

Tn

. Finally, Nt/t is the
average number of events occurring in [0, t].
Proof of Proposition 4.93. For each x âˆˆ, Nt := Nt(x) is an integer and, by
deï¬nition, SNt â‰¤t â‰¤SNt+1. The random variables Tk(x) are summable, so that
Tk < +âˆP-almost surely âˆ€k. As t goes to +âˆ,
Nt(x)+1

k=1
Tk(x) = SNt+1(x) â†’+âˆ
so that Nt(x) â†’âˆP-almost surely. Since SNt (x) â‰¤t â‰¤SNt+1(x) we have
SNt (x)
Nt(x) â‰¤
t
Nt(x) â‰¤SNt+1(x)
Nt(x) + 1
Nt(x) + 1
Nt(x)
.
(4.45)

VECTOR VALUED RANDOM VARIABLES
159
By the appropriate version of the strong law of large numbers, either the
Rajchman theorem, Theorem 4.80, or the Etemadi theorem, Theorem 4.81, or
its extension to integrable random variables, Exercise 4.111, we have
Sn(x)
n
â†’E
P-almost surely.
Since Nt(x)+1
Nt(x)
â†’1 P-almost surely, (4.45) yields
t
Nt(x) â†’E
P-almost surely.
4.4.6
Central limit theorem
4.4.6.1
Convergence in law and weak convergence
Let

Xn

be a sequence of random variables on a probability space (, E, P).
Assume

Xn

converges P-almost surely to a random variable X. What can be
said about the laws FXn and the distributions PXn?
Example 4.95 Let X be a random variable and let FXbe its law. For each n âˆˆN,
set Xn := X + 1
n, so that Xn converges uniformly to X. When we consider the
laws we have
FXn(t) = P(Xn â‰¤t) = P

X â‰¤t âˆ’1
n

hence FXn(t) converges to FX(tâˆ’) which agrees with FX(t) if and only if FX is
continuous at t.
Example 4.96 Consider the example provided in Exercise 4.105. There

Xn

is a sequence of Bernoulli trials of probability p = 1/2,

Xn

converges to 1/2
P-almost surely, but, for each t, FXn(t) converges pointwisely to the function
Ï†(t) :=
â§
âªâ¨
âªâ©
0
if t < 1/2,
1/2
if t = 1/2,
1
if t > 1/2.
The function Ï†(t) is not right-continuous, so it cannot be the law of a random
variable.
These examples justify the following deï¬nition.
Deï¬nition 4.97 Let

Xn

be a sequence of random variables. We say that

Xn

converges in law to a random variable X if FXn(t) converges to FX(t) at each
point t where FX is continuous.
It can be shown, see Proposition B.73, that if

Xn

converges to X in probabil-
ity (in particular if

Xn

converges to X P-almost surely), then

Xn

converges
to X in law.

160
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
The notion of convergence in law is strongly related to the notion of weak
convergence of measures.
Deï¬nition 4.98 Let (B(R), Î¼) and (B(R), Î¼n), n â‰¥1, be probability measures
on R. We say that

Î¼n

weakly converges to Î¼ and one writes Î¼n â‡€Î¼, if
*
R
Ï•(t) Î¼n(dt) â†’
*
R
Ï•(t) Î¼(dt)
for every continuous bounded function Ï• : R â†’R.
It can be shown, see Theorem B.71, that Î¼n â‡€Î¼ if and only if Fn(t) :=
Î¼n([âˆ’âˆ, t]) â†’F(t) := Î¼([âˆ’âˆ, t]) at every t âˆˆR such that F(t) is continuous.
In particular, if X and Xn, n â‰¥1, are random variables then

Xn

converges to
X in law if and only if

PXn

weakly converges to PX.
4.4.6.2
Central limit theorem
Recall that the normal distribution N(0, 1) is the absolutely continuous proba-
bility measure on R, whose density and law are respectively given by:
f (x) :=
1
âˆš
2Ï€
eâˆ’x2
2 ,
(t) :=
1
âˆš
2Ï€
* t
âˆ’âˆ
eâˆ’x2
2 dx.
The following convergence result can be proven.
Theorem 4.99 Central limit theorem Let

Xn

be a sequence of independent,
identically distributed random variables such that E
%
Xn
&
= E and Var
%
Xn
&
=
Ïƒ 2. For each n â‰¥1, set Sn := n
k=1 Xk. Then for any t âˆˆR
P
Sn âˆ’nE
Ïƒâˆšn
â‰¤t

â†’(t)
as n â†’âˆ.
(4.46)
The central limit theorem has a long history which dates to the works of Abraham
de Moivre (1667â€“1754) and Pierre-Simon Laplace (1749â€“1827) on the limits
of Bernoulli trials. The proof of Theorem 4.99 requires the introduction of ideas
and methods that are beyond the scope of this book. In this volume we limit
ourselves to a few simple remarks and refer the interested reader to, e.g. [4â€“10]
where several versions of the theorem, that also applies to sequences of random
variables following different distributions, are considered.
With the same assumptions of the central limit theorem, the weak law (4.29)
yields
P
Sn
n âˆ’E â‰¤t

â†’

0
if t < 0,
1
if t > 0.
On the other hand, (4.46) yields
P
Sn
n âˆ’E â‰¤Ïƒt
âˆšn

= P
Sn âˆ’nE
Ïƒâˆšn
â‰¤t

â†’(t) Ì¸= 0,
(4.47)

VECTOR VALUED RANDOM VARIABLES
161
In words, the central limit theorem provides the right rescaling (1/âˆšn) in
order to achieve a nontrivial limit (different from 0 and 1). The convergence
stated in (4.46) is equivalent to the weak convergence of the distribution of
(Sn âˆ’nE)/(Ïƒâˆšn) to N(0, 1), so that
P
 Ïƒa
âˆšn < Sn
n âˆ’E â‰¤Ïƒb
âˆšn

â†’(b) âˆ’(a)
as n â†’âˆ.
Trivially, we cannot rewrite (4.47) as
P
Sn
n âˆ’E â‰¤Ïƒb

âˆ’â†’(bâˆšn),
and, moreover, (4.47) does not straightforwardly imply that
P
Sn
n âˆ’E â‰¤Ïƒb

âˆ’(bâˆšn)
 âˆ’â†’0.
(4.48)
In order to get (4.48) one needs to know that the convergence in (4.46) is uniform
with respect to t âˆˆR. Lemma 4.92 provides this piece of information: hence,
(4.46) can be improved to
sup
tâˆˆR
P
Sn âˆ’nE
Ïƒâˆšn
â‰¤t

âˆ’(t)
 âˆ’â†’0
as n â†’âˆ,
or, equivalently, to
sup
tâˆˆR
P(Sn â‰¤t) âˆ’
t âˆ’nE
Ïƒâˆšn
 âˆ’â†’0
as n â†’âˆ.
Another piece of information that is missing is the speed of such convergence.
The following theorem provides a useful estimate under an additional hypothesis.
Theorem 4.100 (Berryâ€“Esseen) Let

Xn

be a sequence of independent, inden-
tically distributed random variables such that E
%
Xn
&
= 0, Var
%
Xn
&
= Ïƒ 2 > 0
and Î³ := E
%
|Xn|3 &
< âˆ. Let Sn = n
k=1 Xk. Then
P
 Sn
âˆšn â‰¤Ïƒt

âˆ’(t)
 â‰¤C
âˆšn,
(4.49)
where C := 0.8 Î³
Ïƒ 3 .
Estimate (4.49) is uniform with respect to t âˆˆR. Therefore, with the same
notations, we also have
P(Sn â‰¤t) âˆ’
t âˆ’nE
Ïƒâˆšn
 â‰¤C
âˆšn.
(4.50)

162
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Estimate
(4.50)
allows
us
to
approximate
FSn(t)
with
a
suitable
renormalization of the standard normal law,
FSn(t) â‰ƒ
t âˆ’nE
Ïƒâˆšn

(4.51)
with a known bound on the error.
In many applications, where PXn is not too badly distributed around its
expected value, both experience and numerics suggest that the approximation
in (4.51) is good enough for n â‰¥30, so that approximation (4.51) is often used
as if it were an equality.
Remark 4.101 One may ask if the sequence {Sn/âˆšn} converges P-almost surely
to a random variable Z following the normal law N(0, 1). The answer is negative.
In fact, applying the iterated logarithm law, Theorem 4.86,
lim sup
nâ†’âˆ
Sn
C

2n log log n
= 1
P-almost surely,
where C2 = Var [Xn], so that
lim sup
nâ†’+âˆ
Sn
âˆšn = +âˆ
P-almost surely.
As a consequence, if Sn/âˆšn â†’Z almost surely, then Z = +âˆP-almost surely,
a contradiction.
The proof of the Berryâ€“Esseen theorem, Theorem 4.100, as well as the proof
of central limit theorem requires the introduction of ideas and methods that are
beyond our scope. The interested reader may consult e.g. [4â€“7, 10].
Example 4.102 (Bernoulli trials and central limit theorem) Let Xn,
n â‰¥1, be independent Bernoulli trials of parameter p. Then E
%
Xn
&
= p,
Ïƒ 2 := Var [Xn] = p(1 âˆ’p) and
E
%
|X1 âˆ’p|3 &
= p3(1 âˆ’p) + (1 âˆ’p)3p = p(1 âˆ’p)(1 âˆ’2p).
For n â‰¥1, the random variable Sn := n
k=1 Xk follows the Bernoulli distribution
B(n, p),
P(Sn = k) = B(n, p)({k}) =
n
k

pk(1 âˆ’p)nâˆ’k
âˆ€k = 0, . . . , n,
hence
FSn(t) =

kâ‰¤t
B(n, p)({k}).
Thus, the Berryâ€“Esseen formula reads
FSn(t) âˆ’

t âˆ’np
âˆšnp(1 âˆ’p)
 â‰¤C
âˆšn
where C = 0.8 Î³ Ïƒ âˆ’3 = 0.8pâˆ’1/2(1 âˆ’p)âˆ’3/2.

VECTOR VALUED RANDOM VARIABLES
163
Experience teaches that the left-hand term in the previous estimate is in many
cases much smaller than the right-hand one. An empirical rule for a sequence of
Bernoulli trials of parameter p is that, if both np and n(1 âˆ’p) are larger than
5, then the approximation of B(n, p) with the normal distribution works well in
applications. A better approximation is achieved by a translation of the normal
law of 0.5 to the left: in fact, the law of the Bernoulli distribution is constant
on intervals of length 1 and is right-continuous. This procedure is called the
continuity correction and it must be done any time we approximate a discrete
law with the normal law. Thus a better approximation of FB(n,p) is
FB(n,p)(t) â‰ƒ
t âˆ’np + 0.5
âˆšnp(1 âˆ’p)

.
(4.52)
Another possibility is to normalize the Bernoulli distribution before â€˜compar-
ingâ€™ it with the normal law. In fact,
P
Sn âˆ’np
âˆšn
â‰¤Ïƒ t

=

kâˆ’npâ‰¤Ïƒâˆšnt
B(n, p)({k}) =

xkâ‰¤t
B(n, p)({k})
where xk := kâˆ’np
Ïƒâˆšn . Let Ï(t) be the piecewise constant function
Ï(t) =
n

k=0
yk1[xk,xk+1[(t),
yk := ÏƒâˆšnB(n, p)({k}).
Since xk+1 âˆ’xk =
1
Ïƒâˆšn, we get
P
Sn âˆ’np
âˆšn
â‰¤Ïƒ t

=
* t
âˆ’âˆ
Ï(t) dt.
The Berryâ€“Esseen theorem yields the estimate

* t
âˆ’âˆ
Ï(s) ds âˆ’(t)
 â‰¤C
âˆšn,
C â‰¤0.8 Î³
Ïƒ 3 ,
see Figure 4.5.
4.4.7
Exercises
Exercise 4.103 Let

Xn

be a sequence of independent random variables with
the same expected value E, E
%
Xn
&
= E âˆ€n, and with equibounded variances,
Var
%
Xn
&
â‰¤C2 âˆ€n. For n = 1, 2, . . . , let Yn := 1
n
n
k=1 Xk and let FYn(t) be its
law. Prove that
FYn(t) â†’

0
if t < E,
1
if t > E,
that is,

Yn

converges in law to the constant random variable Y(x) := E âˆ€x âˆˆ.

164
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
6
4
2
0
âˆ’6
âˆ’4
âˆ’2
4
2
0
(a)
(b)
âˆ’4
âˆ’2
0
âˆ’0.1
0.1
0.2
0
âˆ’0.2
0.4
0.6
0.8
1
1.2
0.2
0.3
0.4
0.5
0.6
N(0, 1)
B(30, 0.5)
N(0, 1)
B(30, 0.5)
Figure 4.5
A comparison between (a) the densities and (b) the laws of a rescaling
of B(30, 1/2) and N(0, 1).
Exercise 4.104 Let

Xn

be a sequence of independent Bernoulli trials of param-
eter 1/2. For n â‰¥1, set Yn := 1
n
n
k=1 Xk and let FYn(t) be the law of Yn. Show
that
P

|Yn âˆ’1
2| = 0

â†’0.
Notice that the weak law of large numbers yields instead
P

|Yn âˆ’1
2| â‰¤Î´

â†’1
âˆ€Î´ > 0.
Solution. Let Sn = n
j=1 Xj. We have
P

Yn = 1
2

= P

Sn = n
2

= B(n, 1/2)({n/2})
=

0
if n is odd,
1
2n
 n
n/2

if n is even = O
 1
âˆšn

by the Stirling formula.
Exercise 4.105 Let

Xn

be a sequence of independent Bernoulli trials of param-
eter 1/2. For n â‰¥1, set Yn := 1
n
n
k=1 Xk and let FYn(t) be the law of Yn. Show
that
FYn(t) â†’
â§
âªâ¨
âªâ©
0
if t < 1/2,
1/2
if t = 1/2,
1
if t > 1/2.
Notice that the limit function is not right-continuous.

VECTOR VALUED RANDOM VARIABLES
165
Solution. The weak law of large numbers yields FYn(t) â†’1 if t > 1/2 and
FYn(t) â†’0 if t < 1/2, see Exercise 4.103. Assume now t = 1/2 and let
Sn := n
j=1 Xj. For any q âˆˆN we have
P

Yn = q

= P

Sn = qn

= B(n, 1/2)({nq})
=

1
2n
 n
nq

if nq âˆˆ{0, . . . , n},
0
otherwise.
Therefore
P

Yn â‰¤1
2

= 1
2n
âŒŠn/2âŒ‹

k=0
n
k

=

1
2
if n is odd,
1
2 âˆ’1
2
 n
n/2

if n is even.
Hence P(Yn â‰¤1/2) = 1
2 + O( 1
âˆšn) by the Stirling formula.
Exercise 4.106 Let X, Xn, n âˆˆN, be random variables on a probability space
(, E, P). Show that lim supn Xn(x) â‰¤X(x) P-almost surely if and only if for
every Î´ > 0, P-almost surely Xn(x) â‰¤X(x) + Î´ deï¬nitely. We mean that for every
Î´ > 0 we have P(FÎ´) = 1 where
FÎ´ :=

x âˆˆ
 Xn(x) â‰¤X(x) + Î´ deï¬nitely

.
Exercise 4.107 Let X1, . . . , Xn be n independent, identically distributed random
variables on a probability space (, E, P) and set E := E
%
Xn
&
and Î¼ := PXn.
Show that
*

1
n
n

j=1
Xj âˆ’E

2
P(dx)
=
*
Rn
1
n
n

j=1
tj âˆ’E

2
Î¼(dt1)Î¼(dt2) Â· Â· Â· Î¼(dtn)
and
P
1
n
n

j=1
Xj âˆ’E
 > Î´

= Î¼ Ã— Â· Â· Â· Ã— Î¼

t = (tj) âˆˆRn 
1
n
n

j=1
tj âˆ’E
 > Î´

.
Exercise 4.108 Let

Xn

be a sequence of random variables such that Xn is
independent of X1, . . . , Xnâˆ’1 for every n â‰¥2. Show that the random variables
Xn are independent.

166
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Exercise 4.109 Let

Xn

and

Yn

converge to X and Y P-almost surely, respec-
tively. Show that

Xn + Yn

converges to X + Y P-almost surely.
Exercise 4.110 Let X, Xn, n â‰¥1 be random variables deï¬ned on a probability
space (, E, P) and assume that for any Î± > 1,
1
Î± X(x) â‰¤lim inf
nâ†’âˆXn(x) â‰¤lim sup
nâ†’âˆ
Xn(x) â‰¤Î±X(x)
P-almost surely. (4.53)
Show that Xn â†’X P-almost surely.
Solution. By assumption for any Î± > 1 there exists a set NÎ± âˆˆE with P(NÎ±) =
0 such that inequalities (4.53) hold for each x âˆˆ \ NÎ±. Let

Î±n

be a monotone
decreasing sequence converging to 1 and let N = âˆªnNÎ±n so that P(N) = 0. For
any x âˆˆ \ N and any n âˆˆN we have
1
Î±n
X(x) â‰¤lim inf
kâ†’âˆXk(x) â‰¤lim sup
kâ†’âˆ
Xk â‰¤Î±nX(x).
As n goes to inï¬nity we get
X(x) â‰¤lim inf
kâ†’âˆXk(x) â‰¤lim sup
kâ†’âˆ
Xk â‰¤X(x),
i.e.
lim
kâ†’âˆXk(x) = X(x)
âˆ€x âˆˆ \ N.
Exercise 4.111 Prove the following extension of the Etemadi version of the strong
law of large numbers, Theorem 4.81.
Theorem
Let

Xn

be integrable, pairwise independent and identically
distributed random variables. For every n â‰¥1, set Sn(x) := n
k=1 Xk(x). Then
E
2 Sn
n
3
â†’E
%
X1
&
.
Solution. Thanks to the Etemadi theorem, it remains to prove the claim
for sequences

Xn

of random variables such that Xn â‰¥0 âˆ€n and E
%
Xn
&
=
+âˆ
âˆ€n.
For any M > 0, let Yn,M(x) := Xn(x)1{0â‰¤Xnâ‰¤M}(x). The random variables

Yn,M

are pairwise independent, equidistributed and summable. Therefore, if
Sn,M(x) := n
k=1 Xn,M(x), the Etemadi theorem yields
E
2 Sn,M(x)
n
3
â†’E
%
Y1,M
&
so that
lim inf
nâ†’âˆE
2 Sn
n
3
â‰¥E
%
Y1,M
&
âˆ€M

VECTOR VALUED RANDOM VARIABLES
167
since Sn(x) â‰¥Sn,M(x). Since M is arbitrary, the Beppo Levi theorem implies
E
%
Y1,M
&
â†’E
%
X1
&
= âˆ, hence the claim is proven.
Exercise 4.112 Throw 100 fair dice and compute, approximately the probability
that the sum of the values of the dice is in [325, 375].
[â‰ƒ0.86]
Solution. Let Xn, n = 1, 2, . . . , 100, be the result of the nth dice. The random
variables Xn are independent, identically distributed with expected value Î¼ = 7/2
and variance Ïƒ 2 = 35/12.
We want to compute P
100
i=1 Xi âˆˆ[325, 375]

. By the central limit theorem
with the continuity correction, see (4.52), we get
P
? 100

i=1
Xi âˆˆ]324, 375]
@
= P
?
324.5 â‰¤
100

i=1
Xi â‰¤375.5
@
= P
â›
âœâ
324.5 âˆ’100 7
2
10
6
35
12
â‰¤
100
i=1 Xi âˆ’100 7
2
10
6
35
12
â‰¤375.5 âˆ’100 7
2
10
6
35
12
â
âŸâ 
â‰ƒ2(1.49 âˆ’1) â‰ƒ0.864.

5
Discrete time Markov chains
In this chapter we give a short survey of the properties of a class of simple
stochastic processes, namely, the discrete time homogeneous Markov chains with
discrete states, that widely appear both in pure and applied mathematics, and have
many applications in science and technology, see e.g. [11â€“15].
After introducing stochastic matrices in 5.1, and discrete time stochastic pro-
cesses and their transition matrices, we deal with discrete time Markov chains
and the Markov properties in Section 5.2. Section 5.3 is devoted to computing a
few interesting parameters related to a Markov chain. Convergence of the pow-
ers of the transition matrices and the characterization of the limit in terms of
return times are investigated in Sections 5.5 and 5.7. Markov chains with a ï¬nite
number of states are peculiar. The canonical form of a ï¬nite stochastic matrix is
presented in Section 5.4; in Section 5.5 we discuss the convergence of powers
of a ï¬nite regular transition matrix, the relation between the limit and the return
times and, ï¬nally, summarize the relations between the parameters introduced in
Section 5.3 and the transition matrix. In Section 5.6 we deal with the ergodic
property of Markov chains with an irreducible transition matrix. This eventually
leads to a probabilistic method for the computation of the expected value of a
random variable, known as Markov chain Monte Carlo, which plays a prominent
role in numerical and statistical applications. Section 5.7 contains the conver-
gence results for arbitrary transition matrices; therein the notion of periodicity is
introduced and the renewal theorem is proven.
5.1
Stochastic matrices
Before discussing stochastic processes and Markov chains, it is worth introducing
both stochastic vectors and matrices.
A First Course in Probability and Markov Chains, First Edition. Giuseppe Modica and Laura Poggiolini.
Â© 2013 John Wiley & Sons, Ltd. Published 2013 by John Wiley & Sons, Ltd.

DISCRETE TIME MARKOV CHAINS
169
5.1.1
Deï¬nitions
Let us start by ï¬xing some notations. Let RNâˆ—be the linear space of row vec-
tors having N real components. To each matrix P âˆˆMN,N(R) we can associate
the linear map P : RNâˆ—â†’RNâˆ—deï¬ned by x â†’xP. The row vectors e1 :=
(1, 0, . . . , 0), . . . , en := (0, . . . , 0, 1) are a basis for RNâˆ—, called the standard
basis of RNâˆ—. For each i = 1, . . . , N the row vector P(ei) := eiP is the ith row
of the matrix P.
A vector x = (xi) âˆˆRNâˆ—is a stochastic vector if xi â‰¥0 âˆ€i and N
i=1 xi = 1.
The set of stochastic vectors in RNâˆ—is denoted by T . Finally, a matrix P = (Pi
j) âˆˆ
MN,N is called stochastic if each of its rows is a stochastic vector
Pi
j â‰¥0,
N

j=1
Pi
j = 1
âˆ€i, j.
Proposition 5.1 Let P âˆˆMN,N(R) and let P(x) := xP. Then P is stochastic if
and only if P(T ) âŠ‚T .
Proof. Assume P is stochastic and let x = (x1, . . . , xN) âˆˆT . Thus (xP)j =
N
i=1 xiPi
j is non-negative and
N

j=1
(xP)j =
N

j=1
N

i=1
xiPi
j =
N

i=1
xi
N

j=1
Pi
j =
N

i=1
xi = 1.
This proves that P(x) âˆˆT .
Conversely, assume P(T ) âŠ‚T . Since for each i = 1, . . . , N, the ith row of
P is eiP = P(ei) âˆˆT , we conclude that P is stochastic.
With some care, the same holds when the set of indexes is denumerable.
Let S be a denumerable set. We call a vector indexed by S a sequence of real
numbers and denote it as x =

xj

jâˆˆS or x = (xj)jâˆˆS. We denote by â„“1 the set of
all vectors x = (xj) indexed by S such that 
jâˆˆS |xj| < âˆ. A vector x = (xj)
indexed by S is called a stochastic vector if
xj â‰¥0 âˆ€j âˆˆS
and

jâˆˆS
xj = 1.
The set of stochastic vectors will be denoted by T . Trivially T âŠ‚â„“1.
We shall also deal with double sequences P = (Pi
j)i,jâˆˆS that we call matrices
as in the case when S is ï¬nite. The set of relevant matrices are those for which
||P|| := sup
iâˆˆS

jâˆˆS
|Pi
j| < +âˆ.

170
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
A stochastic matrix is a matrix P = (Pi
j) such that
Pi
j â‰¥0,

jâˆˆS
Pi
j = 1
âˆ€i, j âˆˆS.
Notice that ||P|| = 1 and Pi
j â‰¤1 âˆ€i, j âˆˆS if P is stochastic.
If x = (xi) âˆˆâ„“1 and P is a matrix such that ||P|| < âˆ, we notice that
(xP)j := 
iâˆˆS xiPi
j is well deï¬ned, being the sum of an absolute convergent
series. Moreover,

jâˆˆS
|(xP)j| â‰¤

jâˆˆS

iâˆˆS
|xi||Pi
j| =

iâˆˆS
|xi|

jâˆˆS
|Pi
j| â‰¤||P||

iâˆˆS
|xi|,
i.e. xP âˆˆâ„“1. Therefore every matrix P such that ||P|| < âˆdeï¬nes a map P(x) :=
xP from â„“1 into itself.
Observe also that if P and Q are two matrices indexed by S such that
||P||, ||Q|| < âˆ, then their product PQ is well deï¬ned by (PQ)i
j := 
kâˆˆS Pi
kQk
j,
being the sum of an absolutely convergent series, and, moreover, ||PQ|| â‰¤
||Q|| ||P|| < âˆ. Denoting by P, Q : â„“1 â†’â„“1 the maps deï¬ned by P(x) := xP,
Q(x) := xQ, respectively, then Q(P(x)) = (xP)Q = x(PQ).
Proposition 5.2 Let P be a matrix indexed by S such that ||P|| < âˆand let
P : â„“1 â†’â„“1, P(x) := xP. Then P is a stochastic matrix if and only if P(T ) âŠ‚T .
The proof goes as the proof of proposition 5.1.
An easy consequence of proposition 5.1 and 5.2 is that products of stochastic
matrices are stochastic matrices hence, in particular, any power of a stochastic
matrix is a stochastic matrix. Notice also that a convex combination of stochastic
matrices, P = N
k=1 tiPi, ti â‰¥0, n
i=1 ti = 1, Pi stochastic, is a stochastic matrix
since

jâˆˆS
Pi
j =

jâˆˆS
n

k=1
tk(Pk)i
j =
n

k=1
tk

jâˆˆS
(Pk)i
j =
n

k=1
tk = 1.
In other words, the set of stochastic matrices is a convex set of non-negative
matrices.
5.1.2
Oriented graphs
An oriented graph is a pair (S, E) where S is a ï¬nite or denumerable set of points,
called nodes, and E is a set of ordered pairs of nodes E = {(i, j) | i, j âˆˆS}, called
arcs. We say that the arc (i, j) goes from i to j, or, equivalently, that it joins i to
j. An oriented path from i to j is a ï¬nite union of arcs (i, i1)(i1, i2) Â· Â· Â· (ik, j).
An oriented graph (S, E) can be represented by a matrix A indexed by S,
called the incidence matrix of the graph and deï¬ned as
Ai
j =

1
if there is an arc from i to j,
0
otherwise.

DISCRETE TIME MARKOV CHAINS
171
For each i, j âˆˆS we have
(A2)i
j =

kâˆˆS
Ai
kAk
j > 0
if and only if there exists k âˆˆS such that Ai
k = Ak
j = 1, i.e. if and only if there
exists at least a path from i to j made of exactly two arcs. Similarly, for each
positive integer n
(An)i
j =

i1,i2,...,inâˆ’1âˆˆS
Ai
i1Ai1
i2Ai2
i3 Â· Â· Â· Ainâˆ’1
j
is positive if and only if there exists at least one path from i to j made of exactly
n arcs.
The same reasoning applies to weighted oriented graphs, i.e. to those oriented
graphs such that a weight pij > 0 is attached to each arc (i, j) of the graph. In
fact, we can repeat the previous argument replacing the matrix A with the matrix
(Aâ€²)i
j =

pij
if there is an arc from i to j,
0
otherwise.
This way, a weighted oriended graph is represented by a matrix.
Conversely, to each non-negative matrix P indexed by S one associates a
weighted oriented graph as follows: let P = (pij)i,jâˆˆS. Whenever pij > 0 draw
a directed arc from i to j and associate the weight pij to such arc.
For example, assume S = {1, 2, 3}. Then the stochastic matrix
P =
â›
â
2/9
0
7/9
1/2
0
1/2
1/7
6/7
0
â
â 
(5.1)
can be represented as shown in Figure 5.1.
Deï¬nition 5.3 Let P be a stochastic matrix indexed by S and let i, j âˆˆS. If there
exists n â‰¥0 such that p(n)
ij := (Pn)i
j > 0, we say that i leads to j, or that j is
accessible from i, and denote it as i â†’j. If i â†’j and j â†’i, we say that i and
1
2
3
7 / 9
1 / 7
2 / 9
1 / 2
1 / 2
6 / 7
Figure 5.1
A graph representing the matrix P deï¬ned in (5.1).

172
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
j are comunicating and write i â†”j. If i â†”j for every i, j âˆˆS then the matrix
P is called irreducible.
Since P0 = Id, clearly i â†’i for any i âˆˆS. Moreover, if i â†’j and j â†’
k, then i â†’k. Furthermore, the relation i â†”j is an equivalence relation on
the set of indexes S, and therefore S can be split into equivalence classes of
comunicating indexes.
It is clear that i leads to j if and only if either i = j or i Ì¸= j and there exists
a path from i to j.
If the set of nodes S is ï¬nite, S = {1, . . . , N}, a path from i to j exists if
and only if there exists at least one path made by no more than N arcs [actually
(N âˆ’1) if i Ì¸= j]. Thus a path from i to j, i Ì¸= j, exists if and only if
Ci
j := (P + P2 + Â· Â· Â· + PNâˆ’1)i
j > 0.
In particular, for each node i âˆˆS, the set

j âˆˆS
 Ci
j > 0

is the set of the nodes that are reachable by at least an oriented path starting
from i.
Whenever S = {1, . . . , N}, i â†’j if and only if either i = j or i Ì¸= j and
there exists a path from i to j made by at most N âˆ’1 arcs. Thus i leads to j if
and only if
Bi
j := (Id + P + P2 + PNâˆ’1)i
j > 0.
(5.2)
In particular, the set of indexes (nodes) accessible from i is the set of indexes
(nodes) j such that Bi
j > 0,

j âˆˆ{1, . . . , N}
 i â†’j

=

j
 Bi
j > 0

.
(5.3)
5.1.3
Exercises
Exercise 5.4 Show that the set T âŠ‚RNâˆ—of stochastic vectors is closed and con-
vex. Show that the standard basis of RNâˆ—is the set of extreme points of T , i.e.
that T is the convex envelope of

e1, . . . eN
.
Exercise 5.5 Find the extreme points of the set of stochastic matrices in MN,N(R).
Exercise 5.6 Show that a matrix P âˆˆMN,N(R) is irreducible if and only if all the
elements of
P + P2 + Â· Â· Â· + PN
are positive.

DISCRETE TIME MARKOV CHAINS
173
5.2
Markov chains
In this section, after a short introduction to stochastic processes and their
transition matrices, we introduce Markov chains, a restricted class of stochastic
processes

Xn

with ï¬nite or denumerable state-space. Their main property is
that the joint distributions of the involved variables are ï¬xed by the transition
matrices of the process and by the distribution of the initial variable X0.
5.2.1
Stochastic processes
Let S be a ï¬nite or denumerable set. Without any loss of generality we can
assume S = Z or S = N or, when S is ï¬nite, S = {1, . . . , N}. A sequence of
random variables on a probability space (, E, P)

Xn

, Xn :  â†’S is called
a (discrete time) stochastic process with values in S. The elements of S are
called states and S is the state-space of the process. One can look at

Xn

in
several ways:
(i) The deï¬nition: a sequence

Xn

of random variables with values in S.
(ii) A sequence of states

Xn(x)

âŠ‚S indexed by the parameter x âˆˆ, that
is, the sequence of states taken by the point x âˆˆ.
(iii) A map X : N Ã—  â†’S on the product  Ã— N.
We are interested in describing the probabilistic laws related to the evolution of
the process and in computing the probabilities of various events detected by the
random variables

Xn

. Notice that, formally, we also need to have a probability
space structure on  Ã— N in such a way that X : N Ã—  â†’S, X(n, x) := Xn(x)
is a random variable. Here, we just point out that, in general, describing the evo-
lution of a stochastic process, i.e. computing for each n âˆˆN the joint distribution
of (X0, X1, . . . , Xn) is a difï¬cult task. In fact, in general, the complexity of this
computation grows exponentially with respect to n since (X0, . . . , Xn) is a ran-
dom variable with values in Sn := S Ã— Â· Â· Â· Ã— S. A huge complexity reduction in
computing the joint distributions appears for a subclass of stochastic processes,
the Markov chains, see Section 5.3.
Description (ii) provides a helpful point of view on the process: at the â€˜ï¬rst
stepâ€™ n = 0, we start from a random point X0(x) âˆˆS then, for each positive
integer n, we move from Xn(x) to Xn+1(x). Each x âˆˆ ï¬xes the sequence of
states

Xn(x)

âŠ‚S, i.e. the path on S deï¬ned by x. If j := Xn(x) we say that
the path (deï¬ned by) x visits j at step n. Then the set

x âˆˆ | Xn(x) = j

is the
set of parameters such that the corresponding path visits j at step n. By abuse
of language (in general, two points x, y âˆˆ, x Ì¸= y, can ï¬x the same path), one
refers to

x âˆˆ | Xn(x) = j

as the set of paths that visit j at the nth step.
Consequently P(Xn = j) is the probability that a path visits j at the nth step
and P(Xn = j | X0 = i) is the probability that a path starting from i visits j at
step n.

174
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
5.2.2
Transition matrices
Let

Xn

be a stochastic process with a ï¬nite or denumerable state-space S. For
each n â‰¥0, let P(n) := (P(n)i
j)i,jâˆˆS be the matrix
P(n + 1)i
j :=

P

Xn+1 = j
 Xn = i

if P(Xn = i) > 0,
Î´i
j
if P(Xn = i) = 0.
We call the stochastic matrix P(n) the matrix of transition probabilities or the
transition matrix of the process

Xn

from the nth step to the (n + 1)th step.
For every n â‰¥0, the matrix P(n + 1) links the distribution of the random
variables Xn and Xn+1. In fact, for every n â‰¥0, let Ï€(n) := (Ï€(n)i)iâˆˆS be the
mass density of PXn, that is, Ï€(n)i := P(Xn = i) âˆ€i âˆˆS. Then
Ï€(n + 1)j =

iâˆˆS
P

Xn+1 = j
 Xn = i

P(Xn = i) =

iâˆˆS
Ï€(n)iP(n + 1)i
j
i.e.
Ï€(n + 1) = Ï€(n)P(n + 1).
(5.4)
Also notice that iterating (5.4), we get for each n, k â‰¥0
Ï€(n + k) = Ï€(k)P(k + 1)P(k + 2) Â· Â· Â· P(k + n).
(5.5)
5.2.3
Homogeneous processes
Deï¬nition 5.7 A stochastic process

Xn

with a ï¬nite or denumerable state-space
S is said to be homogeneous if the transition matrices of the random variables

Xn

are independent of n, i.e. if there exists a stochastic matrix P = (Pi
j),
i, j âˆˆS, such that for any n âˆˆN and for any (i, j) âˆˆS such that P(Xn = i) > 0,
we have
P

Xn+1 = j
 Xn = i

= Pi
j.
Thus, if

Xn

is a homogeneous stochastic process with transition matrix P with
a ï¬nite or denumerable state-space S, then for every n, k â‰¥0, the mass densities
Ï€(n) and Ï€(n + k) of Xn and Xn+k, respectively, are related by
Ï€(n + k) = Ï€(k)Pn.
5.2.4
Markov chains
5.2.4.1
Markov property
Let us start with a deï¬nition.
Deï¬nition 5.8 (Markov chain) A stochastic process

Xn

with a ï¬nite or denu-
merable state-space S is said to have the Markov property if for any positive

DISCRETE TIME MARKOV CHAINS
175
integers k, n, k â‰¤n, and for any choice of states i0, . . . , in+1 in S we have
P

Xn+1 = in+1
 Xn = in, . . . , Xk+1 = ik+1, Xk = ik

= P

Xn+1 = in+1
 Xn = in

(5.6)
whenever the involved conditional probabilities are deï¬ned, i.e. whenever the
conditioning events have positive probabilities. If

Xn

has the Markov property,
we say that

Xn

is a Markov chain with state-space S.
We now state in a more appealing way the Markov property (5.6). Recall
that an event is said to be detected by X0, . . . Xnâˆ’1 if it is detected by their joint
distribution, i.e. if it is the disjoint union of events of the following kind

x âˆˆ
 Xnâˆ’1(x) = inâˆ’1, . . . , X1(x) = i1, X0(x) = i0

.
We then state the following.
Theorem 5.9 Let

Xn

be a stochastic process with a ï¬nite or denumerable state-
space S. Then

Xn

is a Markov chain if and only if for any triplet of integers
r, n, k with 0 â‰¤r < n < n + k and for any triplet of events G, F, E detected by
X0, . . . , Xr, Xr+1, . . . , Xn and Xn+1, . . . , Xn+k, respectively, we have
P

E
 F âˆ©G

= P

E
 F

.
(5.7)
Moreover, if P(F âˆ©G) > 0, then
P

E âˆ©F
 G

= P

E
 F

P

F
 G

.
(5.8)
Equality (5.7) says that from a statistical point of view, the future state of the
chain depends only on the present state, memoryless of the past history. Equality
(5.8) is similar to the formula for the probability of the intersection of independent
events and will play a crucial role in what follows.
Proof of theorem 5.9. Choose a sequence

in

of points in S, and for n â‰¥0 set
An :=

x âˆˆ
 Xn(x) = in

.
The Markov property, (5.6) and the law of total probability yield
P

An+1
 An âˆ©B

= P

An+1
 An

(5.9)
for any n â‰¥0 and for any event B detected by the random variables
X0, . . . , Xnâˆ’1. Clearly, (5.9) is meaningful if and only if P(An âˆ©B) > 0. We
now claim that we also have
P

An+1+k âˆ©Â· Â· Â· âˆ©An+1
 An âˆ©B

=
k+n
=
j=n
P

Aj+1
 Aj

(5.10)

176
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
if P(An+k âˆ©Â· Â· Â· âˆ©An âˆ©B) > 0. In fact, applying (5.9) and recalling that P(E âˆ©
F | G) = P(E | F âˆ©G)P(F | G) we get
P

An+1+k âˆ©Â· Â· Â· âˆ©An+1
 An âˆ©B

= P

An+1+k
 An+k âˆ©Â· Â· Â· âˆ©An+1 âˆ©An âˆ©B

P

An+k âˆ©Â· Â· Â· âˆ©An+1
 An âˆ©B

= P

An+1+k
 An+k

P

An+k âˆ©Â· Â· Â· âˆ©An+1
 An âˆ©B

.
An induction argument thus gives (5.10).
Equality (5.7) is an immediate consequence of (5.10) and of the law of total
probability. Moreover, (5.8) follows from (5.7) since
P(E âˆ©F | G) = P(E | F âˆ©G)P(F âˆ©G | G)
= P(E | F âˆ©G)P(F | G) = P(E | F)P(F | G).
We point out that equalities in (5.10) and the Markov property are in fact
special cases of (5.7). Finally, we mention another consequence of (5.7). Let

Xn

, r, k, n, and E, G be as in Theorem 5.9 and let

Fi

iâˆˆI be a family of
disjoint events detected by Xr+1, . . . , Xn and F = âˆªiâˆˆIFi. Then using the law
of total probability, we have
P

E âˆ©(âˆªiFi)
 G

=

iâˆˆI
P(E | Fi)P(Fi | G).
(5.11)
Let

Xn

be a stochastic process with a ï¬nite or denumerable state-space S.
As we have seen, the transition matrices {P(n)} of the process allow to compute
for any n â‰¥0 the mass density Ï€(n + 1) of Xn+1 in terms of the mass density
Ï€(n) of Xn by Ï€(n + 1) = Ï€(n)P(n + 1). Thus by an induction argument the
mass density of Xn+1 can be computed in terms of the mass density of X0,
Ï€(n + 1) = Ï€(0)P(1)P(2) Â· Â· Â· P(n + 1).
However, in general, the sequence {P(n)} does not contain enough information
to compute the joint distribution of two of the Xnâ€™s: for instance, in general, we
cannot compute from P the probability P(Xn = j | X0 = i) for n â‰¥2 and ï¬xed i
and j. Examples can be given of different stochastic processes having the same
initial state, the same transition matrices but different joint distributions.
A dramatic reduction of complexity occurs for Markov chains: if

Xn

is
a Markov chain, then for every n â‰¥1 the joint distribution of X0, . . . , Xn
can be computed in terms of the transition matrices P(1), . . . , P(n) and
of the mass density of
X0. In fact, for any choice of i0, . . . , in âˆˆS, set

DISCRETE TIME MARKOV CHAINS
177
Aj :=

x âˆˆ | Xj(x) = ij

. From (5.10) or (5.7) we then infer
P

Xn+k = in+k, . . . , Xn+1 = in+1
 Xn = in

= P

An+k âˆ©Â· Â· Â· âˆ©An+1
 An

=
n+kâˆ’1
=
j=n
P

Aj+1
 Aj

= P(n)in
in+1P(n + 1)in+1
in+2 Â· Â· Â· P(n + k)in+kâˆ’1
in+k
(5.12)
whenever P(An+k âˆ©Â· Â· Â· âˆ©An) > 0. In particular,
P

Xk = ik, . . . , X1 = i1, X0 = i0

= Ï€(0)i0P(1)i0
i1P(2)i1
i2 Â· Â· Â· P(k)ikâˆ’1
ik
.
(5.13)
5.2.4.2
Homogeneity
A Markov chain

Xn

with a ï¬nite of denumerable state-space is homogeneous
if P(n) = P âˆ€n. Therefore, (5.13) reads
P

Xk+n = ik, Â· Â· Â·, Xn+1 = i1
 Xn = i0

=
kâˆ’1
=
j=0
P
ij
ij+1 = Pi0
i1Pi1
i2Â· Â· Â·Pikâˆ’1
ik
.
(5.14)
As a consequence, since the right-hand side of (5.14) is independent of n, we
then deduce for any n, k â‰¥0 and for any i0, . . . , in âˆˆS the equality
P

Xn+k = ik, Â· Â· Â·, Xn+1 = i1
 Xn = i0

= P

Xk = ik, Â· Â· Â·, X1 = i1
 X0 = i0

.
(5.15)
This is the renewal property of homogeneous Markov chains: if P(Xn = i0) =
P(X0 = i0), then the joint distribution of the k variables following Xn is the
same as the joint distribution of the ï¬rst k variables. In words, the probabilistic
knowledge of Xn, that is of P(Xn = i0), restarts the chain: the stochastic process

Xn+k

k is a Markov chain with the same transition matrix P of {Xk}k.
5.2.4.3
Strong Markov property
Deï¬nition 5.10 Let

Xn

be a Markov chain on (, E, P) with a ï¬nite or
denumerable state-space S. A random variable T :  â†’N âˆª{+âˆ} is called a
stopping time for

Xn

if for any non-negative integer n, the set

x âˆˆ
 T (x) = n

(5.16)
is detected by the random variables X0, X1, . . . , Xn.

178
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Trivially, each of the following are stopping times:
â€¢ all constants;
â€¢ the ï¬rst passage time, i.e. the step at which the ï¬rst visit in A âŠ‚S occurs;
â€¢ the kth passage time, i.e. the step at which the k visit in A âŠ‚S occurs;
â€¢ the ï¬rst step at which we leave A âŠ‚S,
Observe that the step at which we leave a state j deï¬nitively, called the last exit
time, is not a stopping time.
Theorem 5.11 (Strong Markov property) Let

Xn

be a homogeneous Markov
chain with values in a ï¬nite or denumerable set S deï¬ned on a probability space
(, E, P). Let T be a stopping time for

Xn

. Then, for any i, j âˆˆS and any n â‰¥1
P

XT +n = j
 T < +âˆ, XT = i

= P

Xn = j
 X0 = i

.
That is, the sequence

Yn

, Yn(x) := XT (x)+n(x) restricted to the event
{x âˆˆ | T < +âˆ} âŠ‚ is a homogeneous Markov chain whose transition
matrix is the transition matrix of

Xn

. By abuse of language, one says that the
chain â€˜restartsâ€™ at each stopping time.
Proof. By the Markov property and homogeneity, for each integer h we get
P

XT +n = j,T = h, XT = i

= P

Xh+n = j, T = h, Xh = i

= P

Xh+n = j
 Xh = i, T = h

P

T = h, Xh = i

= P

Xh+n = j
 Xh = i

P

T = h, Xh = i

= P

Xn = j
 X0 = i

P

T = h, Xh = i

.
Thus, summing with respect to h, we conclude
P

XT +n = j,T < +âˆ, XT = i

= P

Xn = j
 X0 = i
 âˆ

h=0
P

T = h, XT = i

= P

Xn = j
 X0 = i

P

T < +âˆ, XT = i

.
5.2.5
Canonical Markov chains
Example 5.12 A typical example which may help intuition is that of random
walks. A person is at a random position k, k âˆˆZ, and at each step moves either

DISCRETE TIME MARKOV CHAINS
179
. . .
âˆ’1
0
1
2
p
p
p
p
p
q
q
q
q
q
. . .
Figure 5.2
A graph representing the transition matrix of an unbounded random
walk.
to the position k âˆ’1 or to the position k + 1 according to a Bernoulli trial of
parameter p, for example by ï¬‚ipping a coin. Let Xn be the position occupied
at the nth step and let

Î¶n

be a sequence of independent random variables that
follow B(1, p) and such that Î¶n decides if the person moves backward or foward
at step n. Then
Xn+1 = Xn + 2Î¶n âˆ’1
so that

Xn

is a Markov chain, see Theorem 5.13, whose transition matrix is
P =
â›
âœâœâœâœâœâœâœâœâœâœâœâ
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
p
0
0
0
0
. . .
. . .
0
p
0
0
0
. . .
. . .
q
0
p
0
0
. . .
. . .
0
q
0
p
0
. . .
. . .
0
0
q
0
p
. . .
. . .
0
0
0
q
0
. . .
. . .
0
0
0
0
q
. . .
. . .
. . .
. . .
. . .
. . .
. . .
. . .
â
âŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâ 
Matrix P is schematically represented in Figure 5.2.
Example 5.12 is indeed a standard way to construct Markov chains. The
following holds.
Theorem 5.13 Let S be a ï¬nite or denumerable set, and let X0 :  â†’S be a ran-
dom variable on (, E, P). Let

Î¾n

, Î¾n :  â†’RN be a sequence of independent,
identically distributed random variables on (, E, P) that are also independent
of X0 and let f : S Ã— RN â†’S be a Borel function. Then the sequence

Xn

,
Xn :  â†’S deï¬ned by
Xn+1(x) := f (Xn(x), Î¾n(x)),
âˆ€n â‰¥0,
(5.17)
is a homogeneous Markov chain with state-space S and transition matrix
Pi
j := P(f (i, Î¾k) = j)
âˆ€i, j âˆˆS.
Proof. From the deï¬nition, it is clear that for any integer k, the random
variable Xk is a function of X0 and Î¾1, . . . , Î¾kâˆ’1. Consequently, for any integer n,
the random variable Î¾n, which is by deï¬nition independent of (X0, Î¾1, . . . , Î¾nâˆ’1),

180
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
is also independent of (X0, . . . , Xn). Therefore,
P

Xn+1 = j
 Xn = i, . . . , X0 = i0

= P

f (i, Î¾n) = j
 Xn = i, . . . , X0 = i0

= P(f (i, Î¾n) = j);
(5.18)
the last equality holds since the random variable (X0, . . . , Xn) is independent of
Î¾n, hence of f (i, Î¾n). Since the right-hand side of (5.18) is independent of the
values of Xnâˆ’1, . . . , X0, we conclude that
P

Xn+1 = j
 Xn = i, . . . , X0 = i0

= P

Xn+1 = j
 Xn = i

,
i.e.

Xn

is a Markov chain. The transition matrix is then P = (Pi
j), Pi
j :=
P(f (i, Î¾n) = j) and is independent of n since the random variables Î¾n are iden-
tically distributed.
Theorem 5.14 Let S be a ï¬nite or denumerable set, and let P be a stochastic
matrix. Let X0 :  â†’S be a random variable on (, E, P) and let

Î¾n

, Î¾n :
 â†’[0, 1] be a sequence of independent, uniformly distributed random variables
that are also independent of X0. Deï¬ne
f (i, s) := min

j

j

h=1
Pi
h â‰¥s
>
âˆ€i > 0, s âˆˆR.
Then the sequence

Xn

, Xn :  â†’S deï¬ned by
Xn+1(x) = f (Xn(x), Î¾n(x)),
x âˆˆ, n â‰¥0,
is a homogeneous Markov chain with state-space S and transition matrix P.
Proof. By Theorem 5.13, the sequence

Xn

is a Markov chain. Moreover,
f (i, Î¾n(x)) = j if and only if
jâˆ’1

h=1
Pi
h < Î¾n(x) â‰¤
j

h=1
Pi
h
hence
P(f (i, Î¾n(x)) = j) =
j

h=1
Pi
h âˆ’
jâˆ’1

h=1
Pi
h = Pi
j.
The previous theorem constructs in fact a homogeneous Markov chain

Xn

with
a given transition matrix and a given initial data X0. In particular, Theorem 5.14
reduces the problem of the existence of a Markov chain with a given transition
matrix P on a probability space (, E, P) and a given initial data X0 to the
existence of a sequence of independent random variables that are uniformly
distributed on [0, 1], see Sections 2.2.5 and 4.4.4.

DISCRETE TIME MARKOV CHAINS
181
5.2.6
Exercises
Exercise 5.15 Let S be a ï¬nite or denumerable set and assume X and Y are
random variables taking values in S. Show that X and Y are independent if and
only if âˆ€(i, j) âˆˆS Ã— S if P(X = i) > 0 then the probability P(Y = j | X = i)
does not depend on i.
Exercise 5.16 Let {P(n)} be the sequence of transition matrices of a Markov
chain

Xn

with values in a ï¬nite or denumerable set S. For i, j âˆˆS and n, k â‰¥0
compute P

Xn+k = j
 Xk = i

.
Solution. Applying (5.11) we get
P

Xk+2 = j
 Xk = i

=

hâˆˆS
P

Xk+2 = j
 Xk+1 = h

P

Xk+1 = h
 Xk = i

= (P(k + 1)P(k + 2))i
j.
Thus, with an induction argument, we have
P

Xn+k = j
 Xk = i

=

P(k + 1) Â· Â· Â· P(k + n)
i
j.
For a homogeneous Markov chain, P(n) := P âˆ€n, so that
P

Xn+k = j
 Xk = i

= (Pn)i
j.
(5.19)
Exercise 5.17 Let

Xn

be a sequence of random variables with values in a ï¬nite
or denumerable set S. Prove the following.
(i) If the random variables Xn are independent, then

Xn

is a Markov chain.
(ii) If

Xn

is a Markov chain and for each integer n, the random variables Xn
and Xn+1 are independent, then all the Xnâ€™s are independent.
Exercise 5.18 Assume you need a certain piece of machinery for your work. Every
time you switch on this machinery it may either be broken or start working. At
the beginning of each working day, you switch it on. Assume the following:
(i) At the ï¬rst switch on, the probability that the machinery works is a, and the
probability that it is broken is b = 1 âˆ’a.
(ii) At each of the subsequent times it is switched on:
â€¢ If the machinery is broken, then it will be ï¬xed for the next day with
probability q.

182
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
â€¢ If the machinery works, then it is going to break down without being
repaired on time for the next day with probability p.
Describe the process.
Solution. Let Xn denote the state of the machinery at the nth switch on. The
state-space has only two points (working or broken), say S = {0, 1}: Xn = 0 if the
machinery is broken, Xn = 1 otherwise. The process is evidently a homogeneous
Markov chain: what happens at each switch on depends only on the previous
switch on. The process is then described by the initial condition,
P(X0 = 0) = 1 âˆ’a,
P(X0 = 1) = a
and by the transition matrix
P =

1 âˆ’q
q
p
1 âˆ’p

.
(5.20)
Matrix P is schematically represented in Figure 5.3.
The probabilities that the machinery is either broken or not on the nth day
are the components of the vector Ï€(n) = (P(Xn = 0), P(Xn = 1)) and

Ï€(n + 1) = Ï€(n) P
âˆ€n â‰¥0,
Ï€(0) = (b, a).
i.e. Ï€(n) = Ï€(0)Pn.
Let us compute Pn. If p = q = 0, then obviously
Pn =

1
0
0
1

âˆ€n.
If either p > 0 or q > 0, then P has two different eigenvalues. One can compute,
or prove by induction, that
Pn =
1
p + q

p
q
p
q

+ (1 âˆ’p âˆ’q)n

q
âˆ’q
âˆ’p
p

.
(5.21)
0
1
p
q
1 â€“ q
1 â€“ p
Figure 5.3
A graph representing the transition matrix in (5.20).

DISCRETE TIME MARKOV CHAINS
183
In particular, the probability that the machinery is working at the nth switch on,
knowing that it was working at the ï¬rst switch on is
P(Xn = 1 | X0 = 1

= Ï€(n)1 =
1
p + q

(ap + bq) + (1 âˆ’p âˆ’q)n(ap âˆ’bq)

=
1
p + q

q + (1 âˆ’p âˆ’q)n(ap âˆ’bq)

.
Let us compute the steady state or the asymptotic behaviour of the chain, i.e.
the limit of Ï€(0)Pn as n â†’âˆ.
â€¢ If (p, q) = (0, 0), then Pn = Id âˆ€n, so that the probabilities that the
machinery is either broken or working are the same at every switch on.
â€¢ If (p, q) Ì¸= (0, 0) and (p, q) Ì¸= (1, 1), then p + q < 2, hence |1 âˆ’p âˆ’
q| < 1, thus, by (5.21) Pn converges to the matrix
W :=
1
p + q

p
q
p
q

.
The asymptotic probabilities are Ï€(0)W =

p
p+q ,
q
p+q

which are indepen-
dent of the initial probabilities a, 1 âˆ’a.
â€¢ If p = q = 1, then P =

0
1
1
0

and
Pn =
â§
âªâªâªâªâ¨
âªâªâªâªâ©
?
1
0
0
1
@
if n is even,
?
0
1
1
0
@
if n is odd.
In this case the limit of Pn as n â†’âˆdoes not exist.
Exercise 5.19 (Random walks) Let us go back to Example 5.12 and let us assume
that the set of all possible positions is ï¬nite, S = {0, . . . , N}. We must specify how
to proceed when Xn = 0 or Xn = N. Typical examples are an absorbing walk as
in Figure 5.4, a reï¬‚ecting walk as in Figure 5.5 or a cyclic walk as in Figure 5.6.
For each of the ï¬gures, write the corresponding transition matrix.
1
2
3
4
1
p
p
q
q
1
Figure 5.4
A graph representing the transition matrix of an absorbing Markov
chain.

184
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
1
2
3
4
1
p
p
q
q
1
Figure 5.5
A graph representing the transition matrix of a reï¬‚ecting chain.
1
2
3
4
1
p
p
q
q
1
Figure 5.6
A graph representing the transition matrix of a cyclic chain.
Solution. For the random walk in Figure 5.4, which is absorbing at the right
end, the transition matrix is
P =
â›
âœâœâœâœâœâ
0
1
0
0
. . .
0
0
0
q
0
p
0
. . .
0
0
0
0
q
0
p
. . .
0
0
0
. . .
. . .
. . .
. . .
. . .
. . .
. . .
0
0
0
0
. . .
q
0
p
0
0
0
0
. . .
0
0
1
â
âŸâŸâŸâŸâŸâ 
.
For the reï¬‚ecting random walk in Figure 5.5 the transition matrix is
P =
â›
âœâœâœâœâœâ
0
1
0
0
. . .
0
0
0
q
0
p
0
. . .
0
0
0
0
q
0
p
. . .
0
0
0
. . .
. . .
. . .
. . .
. . .
. . .
. . .
0
0
0
0
. . .
q
0
p
0
0
0
0
. . .
0
1
0
â
âŸâŸâŸâŸâŸâ 
.
Finally, for the cyclic random walk in Figure 5.6 the transition matrix is
P =
â›
âœâœâœâœâœâ
0
1
0
0
. . .
0
0
0
q
0
p
0
. . .
0
0
0
0
q
0
p
. . .
0
0
0
. . .
. . .
. . .
. . .
. . .
. . .
. . .
0
0
0
0
. . .
q
0
p
1
0
0
0
. . .
0
0
0
â
âŸâŸâŸâŸâŸâ 
.

DISCRETE TIME MARKOV CHAINS
185
Exercise 5.20 (Ehrenfest diffusion model) Assume that c molecules, c â‰¥1, are
distributed in two boxes A and B. At each step a molecule is randomly chosen
(with probability 1/c for each molecule) and moved from its box to the other one.
Describe the process.
Solution. The state of the system is described by the number of molecules in
the box A. If, at a certain step, A contains i molecules, then at the next step we
pick a molecule from A with probability i/c or from B with probability 1 âˆ’i/c
and we move it to the other box. Therefore, A will contain either i âˆ’1 molecules
with probability i/c or i + 1 molecules with probability 1 âˆ’i/c. Since the state
at each step depends only on the state at the previous step, the process is a
Markov chain, see Figure 5.7. The transition matrix is the same at each step and
is given by the (c + 1) Ã— (c + 1) matrix
P =
â›
âœâœâœâœâœâœâ
0
1
0
0
. . .
0
0
1
c
0
1 âˆ’1
c
0
. . .
0
0
0
2
c
0
1 âˆ’2
c
. . .
0
0
. . .
. . .
. . .
. . .
. . .
. . .
. . .
0
0
0
0
. . .
0
1
c
0
0
0
0
. . .
1
0
â
âŸâŸâŸâŸâŸâŸâ 
.
Exercise 5.21 A repair workshop receives Zn objects to be repaired and repairs
one object per unit of time. At each time n, let Xn be the number of broken objects
which are in the workshop. Describe the process

Xn

.
Solution. Clearly, Xn+1 = max(Xn âˆ’1, 0) + Zn+1 âˆ€n â‰¥0. If the random
variables

Zn

are independent, identically distributed and also independent of
X0, then

Xn

is a homogeneous Markov chain, see Theorem 5.13. Let us com-
pute the transition matrix. If i = 0 (no object to be repaired is in the workshop)
P0
j = P

X1 = j
 X0 = 0

= P

Z1 = j
 X0 = 0

= P(Z1 = j).
If i = 1, then
P1
j = P

X1 = j
 X0 = 1

= P

Z1 = j
 X0 = 1

= P(Z1 = j)
1
2
3
4
5
1
1 â€“
1
c
1
2
c
3
c
1
c
1
c
1 â€“ 2
c
Figure 5.7
A graph representing the transition matrix of the Ehrenfest diffusion
model with c = 4.

186
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
and, if i > 1, then
P1
j = P

X1 = j
 X0 = i

= P

Z1 = j âˆ’i + 1
 X0 = i

= P(Z1 = j âˆ’i + 1).
Therefore, setting aj := P(Z1 = j) the transition matrix of

Xn

is
P =
â›
âœâœâœâœâœâ
a0
a1
a2
a3
. . .
a0
a1
a2
a3
. . .
0
a0
a1
a2
. . .
0
0
a0
a1
. . .
. . .
. . .
. . .
. . .
. . .
â
âŸâŸâŸâŸâŸâ 
.
Exercise 5.22 (Queues) In a shop customers arrive at the pay desk at times
0, 1, . . . . Let Î¾n be the number of customers arriving at the desk at time n. At
each time one customer (if there is at least one) pays and leaves the shop. Let

Xn

be the number of customers queuing at the pay desk at time n. Describe the
process.
Solution. Clearly,
Xn+1 =

Xn + Î¾n+1 âˆ’1
if Xn â‰¥1,
Î¾n
if Xn = 0.
or, equivalently, Xn := max(Xn âˆ’1, 0) + Î¾n+1. It is the same process as
described in Exercise 5.21.
Exercise 5.23 (Inventory) A logistic company manages the stock of a certain
good with the following strategy: the company ï¬xes two quantities m and M,
m < M; every day the company delivers the orders and at the end of the day the
people in charge check the stock. If, after delivering all the pending orders, the
stock is more than m they do not do anything. Otherwise, they buy immediately
enough supplies to fulï¬l all the pending orders and get the stock back to level M.
Describe the process, assuming that the initial stock amount is less than M.
Solution. For every n â‰¥0, let Zn be the aggregated demand of goods at day
n and let Xn be the current stock at the end of day n. Then Zn â‰¥0, X0 â‰¤M
and, clearly,
Xn+1 =

Xn âˆ’Zn+1
if Xn > m,
M âˆ’Zn+1
if Xn â‰¤m,
for every n â‰¥0. In particular, Xn â‰¤M âˆ€n. Assuming that the aggregated
demands Zn are independent, identically distributed random variables and also
independent of the initial stock X0, then

Xn

is a homogeneous Markov

DISCRETE TIME MARKOV CHAINS
187
chain, see Theorem 5.13. Let us compute the transition matrix of the

Xn

.
If âˆ’âˆ< i â‰¤m, then for every âˆ’âˆ< j â‰¤M
Pi
j = P

X1 = j
 X0 = i

= P

Z1 = M âˆ’j
 X0 = i) = P(Z1 = M âˆ’j)
while, if m < i â‰¤M, then for every âˆ’âˆ< j â‰¤M
Pi
j = P

X1 = j
 X0 = i

= P

Z1 = i âˆ’j
 X0 = i) = P(Z1 = i âˆ’j).
5.3
Some characteristic parameters
In this section, we compute a few characteristic parameters of homogeneous
Markov chains.
5.3.1
Steps for a ï¬rst visit
Let

Xn

be a homogeneous Markov chain on (, E, P) with a ï¬nite or denu-
merable state-space S and let C âŠ‚S. We recall that one says that x âˆˆ visits C
at step n if Xn(x) âˆˆC. We also say that x âˆˆ visits C if Xn(x) âˆˆC for some
n â‰¥1.
Consider the minimum number of steps to visit C,
tC(x) := min

n â‰¥1
 Xn(x) âˆˆC

,
called the ï¬rst passage time or the waiting time to get to C. We set tC(x) = +âˆ
if Xn(x) /âˆˆC âˆ€n. Trivially, the waiting time tC(x) is a random variable with
values in {1, 2, . . . } âˆª{+âˆ}; its distribution is obtained by computing its mass
distribution, that is the probabilities P(tC(x) = k) that the waiting time to get to
C occurs at step k for every k.
For any i âˆˆS we introduce the probabilities of visiting C at step k (starting)
from i, or ï¬rst passage time probabilities
f (k)
iC : = P

tC(x) = k
 X0 = i

= P

Xk âˆˆC, Xkâˆ’1 /âˆˆC, . . . , X1 /âˆˆC
 X0 = i

.
(5.22)
Thus, the total probability law gives
P(tC = k) =

iâˆˆS
f (k)
iC P(X0 = i).
Since the sets Ek :=

x âˆˆ | tC(x) = k

are pairwise disjoint, the probability of
visiting C (at least once) starting from i is
fiC := P

tC < +âˆ
 X0 = i

=
âˆ

k=1
P

tC = k
 X0 = i

=
âˆ

k=1
f (k)
iC .
(5.23)

188
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
If C is a singleton, C = {j}, we write tj(x), f (k)
ij , fij instead of t{j}(x), f (k)
i{j}
and fi{j}, respectively. If i = j, fjj and f (k)
jj
are more appropriately called the
return probability to state j and the return probability to state j at step k,
respectively. The return probabilities f (k)
jj
play a crucial role in what follows.
Proposition 5.24 The ï¬rst passage time probabilities f (k)
iC , k â‰¥1, satisfy the recur-
rence property
f (k)
iC =
â§
âªâªâ¨
âªâªâ©

â„“âˆˆC
piâ„“
if k = 1,

â„“/âˆˆC
piâ„“f (kâˆ’1)
â„“C
if k â‰¥2.
(5.24)
Proof. Let us prove the claim by induction on k. For k = 1, observe that f (1)
iC
is the probabilty to visit C at the ï¬rst step starting from i,
f (1)
iC =

â„“âˆˆC
P

X1 = â„“
 X0 = i

=

â„“âˆˆC
piâ„“.
Let k â‰¥2, and set
Ek
C :=

x âˆˆ
 X1(x) /âˆˆC, . . . , Xkâˆ’1(x) /âˆˆC, Xk(x) âˆˆC

so that Ek
C =

x | tC(x) = k

. If a path x from i visits C at step k, then the ï¬rst
step is outside C, X1(x) /âˆˆC, the next k âˆ’2 steps are again outside C and ï¬nally
the path hits C at the kth step. Set
E :=

x âˆˆ
 X2(x) /âˆˆC, . . . , Xkâˆ’1(x) /âˆˆC, Xk(x) âˆˆC

,
Fâ„“:=

x âˆˆ
 X1(x) = â„“

, â„“/âˆˆC.
Of course, Ek
C = E âˆ©(âˆªâ„“/âˆˆCFâ„“) and, by (5.11), we get
f (k)
iC = P

Ek
C
 X0 = i

= P

E âˆ©(âˆªâ„“/âˆˆCFâ„“)
 X0 = i

=

â„“/âˆˆC
P(E | Fâ„“)P(Fâ„“| X0 = i).
(5.25)
Since P

Fâ„“
 X0 = i

= P

X1 = â„“
 X0 = i

= piâ„“and
P

E
 Fâ„“

= P

X2 /âˆˆC, . . . , Xkâˆ’1 /âˆˆC, Xk âˆˆC
 X1 = â„“

= P

X1 /âˆˆC, . . . , Xkâˆ’2 /âˆˆC, Xkâˆ’1 âˆˆC
 X0 = â„“

= f (kâˆ’1)
â„“C
by the inductive assumption, (5.24) follows from (5.25).

DISCRETE TIME MARKOV CHAINS
189
5.3.2
Probability of (at least) r visits
Let

Xn

be a homogeneous Markov chain on (, E, P) with a ï¬nite or denu-
merable state-space S. For n â‰¥1 and C âŠ‚S, consider the event En := {x âˆˆ
 | Xn(x) âˆˆC} and let 1En be its characteristic function. Since 1En(x) = 1 if x
visits C at step n and is zero otherwise, the random variables
V (n)
C (x) :=
n

k=1
1Ek(x)
and
VC(x) :=
âˆ

k=1
1Ek(x)
(5.26)
give the number of visits of x in C in the ï¬rst n steps and the total number of
visits of x in C, respectively. Clearly, we may have VC(x) = +âˆ. Moreover,

x âˆˆ
 V (n)
C (x) â‰¥1

=

x âˆˆ
 tC â‰¤n

,

x âˆˆ
 VC(x) â‰¥1

=

x âˆˆ
 tC < +âˆ

.
(5.27)
Similarly, for each non-negative integer r the rth passage time in C is deï¬ned
recursively by setting T (0)
C (x) = 0, T (1)
C (x) = tC(x) and, for r â‰¥2,
T (r)
C (x) = inf

n â‰¥T (râˆ’1)
C
(x) + 1
 Xn(x) âˆˆC

,
x âˆˆ.
If no n â‰¥T (râˆ’1)
C
+ 1 such that Xn âˆˆC exists, we set T (r)
C (x) = +âˆ. The ran-
dom variables T (r)(x) are stopping times since, for each positive integer k, the
event {x | T (r)
C
= k} is detected by the random variables X0, . . . , Xk. The relations
between the random variables V (n)
C
and T (r)
C
and between the random variables
VC and TC are quite clear:

x âˆˆ
 V (n)
C (x) â‰¥r

=

x âˆˆ
 T (r)
C
â‰¤n

,

x âˆˆ
 VC(x) â‰¥r

=

x âˆˆ
 T (r)
C
< +âˆ

.
If C is a singleton, C = {j}, we use the shorter notation T (r)
j
, Tj, V (n)
j
, Vj
instead of T (r)
{j} , T{j}, V (n)
{j} , V{j}, respectively. Finally, we point out that
V (n)
C (x) =

jâˆˆC
V (n)
j
(x)
and
VC(x) =

jâˆˆC
Vj(x).
Let

Xn

be a Markov chain on (, E, P) with a ï¬nite or denumerable
state-space S. For any i, j âˆˆS and r â‰¥1, we look for the probabilities of visiting
j at least r times starting from i:
P

Vj â‰¥r
 X0 = i

.

190
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Theorem 5.25 For any positive integer r and for any pair of states i, j âˆˆS we
have
P

Vj â‰¥r
 X0 = i

= fij f râˆ’1
jj
.
In particular, the probability of having at least r visits in j starting from j is
P

Vj â‰¥r
 X0 = j

= f r
jj.
(5.28)
Proof. If r = 1, then (5.23) and (5.27) yield
P

Vj â‰¥1
 X0 = i

= P

tj < +âˆ
 X0 = i

= fij.
Assume now r â‰¥2. Let En :=

x âˆˆ | Xn(x) = j

and, for h â‰¥1, let
Rh(x) := âˆ
k=h+1 1Ek(x) so that

x âˆˆ
 Vj(x) â‰¥r

=
âˆ
(
h=1

x âˆˆ
 Rh(x) â‰¥r âˆ’1, tj(x) = h

âˆ€r â‰¥2.
Set
E :=

x âˆˆ | Rh(x) â‰¥2

,
F =

x âˆˆ | tj(x) = h

and
G = {x âˆˆ |
X0 = i}. From the disintegration formula, the renewal property (5.15) and the
homogeneity of the chain, we obtain
P

Rh â‰¥r âˆ’1, tj = h
 X0 = i

= P

E âˆ©F
 G

= P

E
 F âˆ©G

P

F âˆ©G

= P

Rh â‰¥r âˆ’1
 tj = h, X0 = i

P

tj = h
 X0 = i

= P

Rh â‰¥r âˆ’1
 Xh = j

P

tj = h
 X0 = i

= P

Vj â‰¥r âˆ’1
 X0 = j

f (h)
ij .
Thus,
P

Vj â‰¥r
 X0 = i

=
âˆ

h=1
P

Rh â‰¥r âˆ’1, tj = h
 X0 = i

=
 âˆ

h=1
f h
ij

P

Vj â‰¥r âˆ’1
 X0 = j

= fij P

Vj â‰¥r âˆ’1
 X0 = j

.
Then the claim follows by an induction argument.

DISCRETE TIME MARKOV CHAINS
191
5.3.3
Recurrent and transient states
Let

Xn

be a homogeneous Markov chain on (, E, P) with a ï¬nite or denu-
merable state-space S. For any i, j âˆˆS, we now compute the expected number
of visits in the state j starting from the state i, i.e. the averaged number of visits
with respect to the probability measure Pi(A) := P(A | X0 = i), i.e.
Ei[Vj] :=
1
P(X0 = i)
*
{X0=i}
Vj(x) P(dx).
Theorem 5.26 The following hold:
Ei[Vj] =
â§
â¨
â©
+âˆ
if P

Vj = +âˆ
 X0 = i

> 0,
âˆ
k=0 kP

Vj = k
 X0 = i

otherwise.
(5.29)
Ei[Vj] =
âˆ

n=0
p(n)
ij .
(5.30)
Ei[Vj] =
â§
â¨
â©
+âˆ
if fjj = 1,
fij
1âˆ’fjj
if fjj < 1.
(5.31)
In particular,
âˆ

n=0
p(n)
ij =
â§
âªâ¨
âªâ©
+âˆ
if fjj = 1,
fij
1 âˆ’fjj
if fjj < 1.
(5.32)
Proof. The Beppo Levi theorem, see Exercise B.33, gives
*
{X0=i}
Vj(x)P(dx) =
â§
â¨
â©
+âˆ
if P

Vj = +âˆ, X0 = i

> 0,
âˆ
k=0 kP

Vj = k, X0 = i

otherwise,
hence (5.29) is proven. Taking advantage of (5.26) and (5.19), the Beppo Levi
theorem also gives
Ei[Vj] := Ei
4 âˆ

n=0
1En
5
=
âˆ

n=0
Ei[1En]
=
âˆ

n=0
P

Xn = j
 X0 = i

=
âˆ

n=0
p(n)
ij .

192
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Finally, the Cavalieri formula yields
Ei[Vj] =
1
P(X0 = i)
âˆ

k=0
P

Vj > k, X0 = i

=
âˆ

k=0
P

Vj > k
 X0 = i

=
âˆ

k=1
P

Vj â‰¥k
 X0 = i

=
âˆ

k=1
fijf kâˆ’1
jj
=

+âˆ
if fjj = 1,
fij
1âˆ’fjj
if fjj < 1.
Deï¬nition 5.27 Let

Xn

be a homogeneous Markov chain with a ï¬nite or denu-
merable state-space S. Let P = (pij) be its transition matrix:
(i) j âˆˆS is called a recurrent state if âˆ
n=1 p(n)
jj = +âˆ,
(ii) j âˆˆS is called a transient state if âˆ
n=1 p(n)
jj < +âˆ.
Thus, a state can be either transient or recurrent. These terms are justiï¬ed by the
following propositions.
Proposition 5.28 The following are equivalent:
(i) j is a recurrent state.
(ii) Paths from j visit j almost surely, fjj = 1.
(iii) Paths from j visit j an inï¬nite number of times almost surely.
If j is recurrent, paths from i visit j an inï¬nite number of times with probability
fij, that is with the same probability of visiting j at least once.
Proof. (i) and (ii) are equivalent by (5.30) and (5.31). Moreover, (iii) implies
(ii) and, if (ii) holds, i.e. fjj = 1, then
P

Vj = +âˆ
 X0 = i

= lim
râ†’âˆP

Vj â‰¥r
 X0 = j

= lim
râ†’âˆfijf râˆ’1
jj
= fij.
In particular, choosing i = j, we get P

Vj = +âˆ
 X0 = j

= fjj = 1, i.e. (iii).
Proposition 5.29 The following are equivalent:
(i) j is a transient state.
(ii) The probability that paths from j visit j is less than 1, fjj < 1.
(iii) The probability that paths from j visit j an inï¬nite number of times is zero.
(iv) Paths from j visit j at most a ï¬nite number of times almost surely.

DISCRETE TIME MARKOV CHAINS
193
If j is transient, paths from i visit j an inï¬nite number of times with zero
probability.
Proof. (i) and (ii) are equivalent by (5.30) and (5.31). Moreover,
P

Vj = +âˆ
 X0 = i

= lim
râ†’âˆP

Vj â‰¥r
 X0 = i

= lim
râ†’âˆfijf râˆ’1
jj
.
Thus, P(Vj = +âˆ| X0 = j) = 0 if and only if fjj < 1, so that (ii) and (iii) are
equivalent, and P(Vj = +âˆ| X0 = i) = 0 if j is transient. Finally, the equiva-
lence between (iii) and (iv) is obvious.
Proposition 5.30 Let

Xn

be a homogeneous Markov chain with a ï¬nite or
denumerable state-space S. Let P = (pij) be its transition matrix. Then the fol-
lowing hold:
(i) If i â†’j and j is recurrent, then âˆ
k=1 p(k)
ij = +âˆ. Therefore, if fjj = 1
and i â†’j, then fij = 1.
(ii) If i and j communicate, i â†”j, then either both i and j are transient or
both i and j are recurrent. That is, if i â†”j, then fii = 1 if and only if
fjj = 1.
Proof. (i) If j is recurrrent and i â†’j, then there exists k such that p(k)
ij > 0.
Thus, for each n â‰¥0
p(k+n)
ij
=

Î±âˆˆS
p(k)
iÎ± p(n)
Î±j â‰¥p(k)
ij p(n)
jj .
In particular, âˆ
n=1 p(n)
ij = +âˆif âˆ
n=1 p(n)
jj = +âˆ.
(ii) If i â†”j, then there exist h, k such that p(h)
ij > 0 and p(k)
ji > 0. Thus, for each
n â‰¥0
p(h+k+n)
ii
=

Î±,Î²âˆˆS
p(h)
iÎ± p(n)
Î±Î² p(k)
Î²i â‰¥p(h)
ij p(n)
jj p(k)
ji .
In particular, âˆ
n=1 p(n)
ii
= +âˆif âˆ
n=1 p(n)
jj = +âˆ. Since the roles of i and j
can be interchanged, either both series converge or both series diverge.
5.3.4
Mean ï¬rst passage time
Let

Xn

be a homogeneous Markov chain with a ï¬nite or denumerable state-
space S and let C âŠ‚S. The mean ï¬rst passage time, or expected waiting time,
to get to C starting from i âˆˆS is the expected number of steps to get to C
starting from the state i, i.e. the averaged waiting time tC(x) with respect to the
probability measure Pi(A) := P(A | X0 = i),
Ei[tC] :=
1
P(X0 = i)
*
{X0=i}
tC(x) P(dx).

194
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
If C is a singleton, C = {j}, then Ej[tC] is brieï¬‚y denoted by T jj,
T jj := Ej[tj]
and is called the expected return time to j.
The Beppo Levi theorem, see B.33, yields
Ei[tC] =
â§
â¨
â©
+âˆ
if P

tC = âˆ
 X0 = i

> 0,
âˆ
k=1 kP

tC = k
 X0 = i

otherwise.
(5.33)
Since the probability of visiting C starting from i is
P

tC < +âˆ
 X0 = i

=
âˆ

k=1
P

tC = k
 X0 = i

= fiC,
see (5.22), we have
Ei[tC] :=

+âˆ
if fiC < 1,
âˆ
k=1 kf (k)
iC
if fiC = 1.
(5.34)
In other words, the expected time to get to C is inï¬nite if and only if either
fiC < 1 or fiC = 1 and âˆ
k=1 kf (k)
iC = +âˆ. In particular,
T jj =

+âˆ
if fjj < 1,
âˆ
k=1 kf (k)
jj
if fjj = 1.
(5.35)
Summarizing, the average return time T jj in j:
â€¢ is inï¬nite either if j is transient, fjj < 1, or if j is recurrent, fjj = 1,
and âˆ
k=1 kf (k)
jj = âˆ;
â€¢ is ï¬nite if and only if j is recurrent, fjj = 1, and âˆ
k=1 kf (k)
jj < âˆ.
If the expected return time of state j is ï¬nite, then the state j is called
positive recurrent. We shall see later, see Theorem 5.71 and 5.82, that the states
of a Markov chain with ï¬nite state-space whose transition matrix is irreducible
are positive recurrent.
Proposition 5.31 Let C âŠ‚S and i âˆˆS. Then
Ei[tC] = 1 +

â„“/âˆˆC
piâ„“Eâ„“[tC].
(5.36)
Proof. It sufï¬ces to assume Ei[tC] < +âˆand, consequently, fiC = 1. Recur-
rence equation (5.24) gives
Ei[tC] = f (1)
iC +
âˆ

k=2
kf (k)
iC = f (1)
iC +
âˆ

k=1
(k + 1)
 
â„“/âˆˆC
piâ„“f (k)
â„“C


DISCRETE TIME MARKOV CHAINS
195
= f (1)
iC +
âˆ

k=1

â„“/âˆˆC
piâ„“f (k)
â„“C +

â„“/âˆˆC
piâ„“
 âˆ

k=1
kf (k)
â„“C

= f (1)
iC +
âˆ

k=2
f (k)
iC +

â„“/âˆˆC
piâ„“Eâ„“[tC]
= fiC +

â„“/âˆˆC
piâ„“Eâ„“[tC].
Since fiC = 1, the claim is proven.
5.3.5
Hitting time and hitting probabilities
Let

Xn

be a homogeneous Markov chain on a probability space (, E, P) with
a ï¬nite or denumerate state-space S, and let P = (pij) be its transition matrix.
For each C âŠ‚S deï¬ne
Ï„C(x) := min

n â‰¥0 | Xn(x) âˆˆC

where, of course, we set Ï„C(x) = +âˆif Xn(x) /âˆˆC for any n â‰¥0. The random
variable Ï„C(x) is called the hitting time or ï¬rst time to absorption in C. Obviously,
Ï„C(x) = 0 if and only if x âˆˆC, and Ï„C(x) = tC(x) if and only if X0(x) /âˆˆC. The
mass density of Ï„C with respect to Pi is the sequence

h(k)
iC

where
h(k)
iC := P

Ï„C(x) = k
 X0 = i

is the probability that state i hits the set C at time k. Obviously,
h(0)
iC =

1
if i âˆˆC,
0
if i /âˆˆC,
(5.37)
and, for each k â‰¥1,
h(k)
iC =

0
if i âˆˆC,
f (k)
iC
if i /âˆˆC.
(5.38)
Starting from the mass density

h(k)
iC

of Ï„C we can compute the probability that
state i hits C,
hiC := P

Ï„C < âˆ
 X0 = i

=
âˆ

k=0
h(k)
iC
and the expected hitting time in C
Ei[Ï„C] :=
1
P(X0 = i)
*
{X0=i}
Ï„C(x) P(dx).

196
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Thus, (5.37) and (5.38) give
hiC =
1
if i âˆˆC,
fiC
if i /âˆˆC,
(5.39)
see (5.70), and
Ei[Ï„C] =
âˆ
if hiC < 1,
âˆ
k=1 kh(k)
iC
if hiC = 1.
(5.40)
In particular, see (5.34),
Ei[Ï„C] =
0
if i âˆˆC,
Ei[tC]
if i /âˆˆC.
In the next two theorems we characterize the hitting probabilities and the
expected hitting times.
Theorem 5.32 The vector (hiC)iâˆˆS of hitting probabilities is the minimal non-
negative solution x = (xi)iâˆˆS of the system
xi =
â§
âªâ¨
âªâ©
1
if i âˆˆC,

â„“âˆˆS
piâ„“xâ„“
if i /âˆˆC.
(5.41)
That is, (hiC) is a solution of (5.41) and, if (xi)iâˆˆS is any further non-negative
solution of (5.41), then xi â‰¥hiC âˆ€i âˆˆS.
Proof. (i) We ï¬rst show that (hiC)iâˆˆS is a solution of system (5.41). If i âˆˆC,
then Ï„C(x) = 0 âˆ€x âˆˆ, so that h(0)
iC = 1 and hiC = 1. If i /âˆˆC, then h(k)
iC = f (k)
iC ,
hence by (5.24), we get
hiC =
âˆ

k=1
h(k)
iC = h(1)
iC +
âˆ

k=2

â„“/âˆˆC
piâ„“h(kâˆ’1)
â„“C
=

â„“âˆˆC
piâ„“+

â„“/âˆˆC
piâ„“hâ„“C
=

â„“âˆˆS
piâ„“hâ„“C.
This proves that (hiC)iâˆˆS is a solution to system (5.41).
(ii) Assume (xi)iâˆˆS is a solution to (5.41). Trivially, xi = 1 = hiC if i âˆˆC. We
now prove by an induction argument that
xi â‰¥
n

k=0
h(k)
iC
âˆ€n âˆˆN, âˆ€i /âˆˆC.
(5.42)

DISCRETE TIME MARKOV CHAINS
197
Since xâ„“= 1 âˆ€â„“âˆˆC and (xi)iâˆˆS is non-negative, we get
xi =

â„“âˆˆC
piâ„“+

â„“/âˆˆC
piâ„“xâ„“â‰¥h(1)
iC ,
i.e. the claim holds true for n = 1.
Assume n > 1. By (5.41), the induction argument and since xi â‰¥0 âˆ€i, we
get
xi =

â„“âˆˆC
piâ„“+

â„“/âˆˆC
piâ„“xâ„“â‰¥h(1)
iC +

â„“/âˆˆC
piâ„“xâ„“â‰¥h(1)
iC +

â„“/âˆˆC
piâ„“

n

k=1
h(k)
iC

= h(1)
iC +
n

k=1
 
â„“/âˆˆC
piâ„“h(k)
â„“C

= h(1)
iC +
n+1

k=2
h(k)
iC =
n+1

k=1
h(k)
iC ,
i.e. (5.42) is proven. If we now let n go to âˆin (5.42), we get xi â‰¥âˆ
k=0 h(k)
iC =
hiC.
Theorem 5.33 The vector (Ei[Ï„C])iâˆˆS of the expected hitting times in C is a
solution of the system
yi =

0
if i âˆˆC,
1 + 
â„“/âˆˆC piâ„“yâ„“
if i /âˆˆC,
(5.43)
where we accept yi = +âˆ. If hiC = 1 and (yi)iâˆˆS is any further solution of (5.43),
then yi â‰¥Ei[Ï„C].
Proof. We ï¬rst show that Ei[Ï„C] solves (5.43). If i âˆˆC, then Ei[Ï„C] = 0. If
i /âˆˆC, then Ei[Ï„C] = Ei[tC], hence Ei[Ï„C] solves (5.43) by Proposition 5.31.
Assume (yi)iâˆˆS is a solution of (5.43). If i âˆˆC, then yi = 0 = Ei[Ï„C]. If
i /âˆˆC and hiC = 1, we show by induction that
yi â‰¥
n

k=1
kh(k)
iC
(5.44)
so that, as n goes to inï¬nity, we get yi â‰¥âˆ
k=1 kh(k)
iC = Ei[Ï„C], see (5.34).
If n = 1, then (5.44) holds trivially: yi â‰¥1 = hiC â‰¥h(1)
iC . Let n Ì¸= 2. From
the induction argument and (5.24) we infer
yi = 1 +

â„“/âˆˆC
piâ„“yâ„“â‰¥1 +

â„“/âˆˆC
piâ„“

n

k=1
kh(k)
â„“C

= 1 +
n

k=1
k
 
â„“/âˆˆC
piâ„“h(k)
â„“C

= 1 +
n

k=1
kh(k+1)
iC
= 1 +
n

k=2
(k âˆ’1)h(k)
iC = 1 âˆ’
n

k=2
h(k)
iC +
n+1

k=2
kh(k)
iC
â‰¥h(1)
iC +
n+1

k=2
kh(k)
iC =
n+1

k=1
kh(k)
iC .

198
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
5.3.6
Exercises
For the readerâ€™s convenience the main deï¬nitions on discrete time Markov chains
are summarized in Figure 5.8.
Exercise 5.34 (Holding time) Let

Xn

be a homogeneous Markov chain with a
ï¬nite or denumerable state-space S and transition matrix P = (pij). Compute the
probability distribution of the holding time in a state. We regard the paths starting
from j as staying at j at least once. Compute also the expected holding time in
a state.
0
Ej[SJj] =
1
1âˆ’pjj
1
Solution. The holding time at j âˆˆS is the random variable deï¬ned as
SJj(x) = min

n
 Xn(x) Ì¸= j

(SJj(x) = +âˆif Xn(x) = j âˆ€n). For k â‰¥1, set
Ek :=

x âˆˆ
 X1(x) = j, . . . , Xkâˆ’1(x) = j, Xk(x) Ì¸= j

.
We want to compute the holding time probabilities P

SJj = k
 X0 = j

=
P

Ek
 X0 = j

. If k = 1, then
P

SJj = 1
 X0 = j

= P

X1 Ì¸= j
 X0 = j

= 1 âˆ’pjj.
If k â‰¥2, (5.8) implies
P

SJj = k
 X0 = j

= P

Ek
 X0 = j

= P

Xk Ì¸= j
 Xkâˆ’1 = j
 kâˆ’1
=
h=1
P

Xh = j
 Xhâˆ’1 = j

= (1 âˆ’pjj)pkâˆ’1
jj .
Thus, the holding time in state j follows the geometric distribution of parameter
1 âˆ’pjj, i.e. it is a memoryless random variable.
Integrating SJj(x) one gets the expected holding time in state j starting
from j:
Ej[SJj] =
âˆ

k=1
kP

SJj = k
 X0 = j

= (1 âˆ’pjj)
âˆ

k=1
kpkâˆ’1
jj
= (1 âˆ’pjj)
1
(1 âˆ’pjj)2 =
1
1 âˆ’pjj
.
Exercise 5.35 (Gamblerâ€™s ruin paradox) A player possesses a capital i âˆˆN,
i â‰¥1 and plays a sequence of games. In each game, he either wins or loses

DISCRETE TIME MARKOV CHAINS
199
Characteristic parameters of discrete Markov chains
Let

Xn

be a homogeneous Markov chain with a ï¬nite or denumerable state-
space S and let i, j âˆˆS and C âŠ‚S.
â€¢ Conditional probability given the event

X0 = i

Pi(A) := P(A | X0 = i).
â€¢ Conditional expectation given the event

X0 = i

Ei[f ] :=
1
P(X0 = i)
*
{X0=i}
f (x) P(dx).
â€¢ Waiting time to get to C
tC(x) := min

n â‰¥1 | Xn âˆˆC

,
tj(x) if C = {j}.
â€¢ Probability to get to C for the ï¬rst time at step k starting from i
f (k)
iC := P

tC = k
 X0 = i

,
f (k)
ij
if C = {j}.
â€¢ Probability to get to C starting from i
fiC := P

tC < +âˆ
 X0 = i

,
fij if C = {j}.
â€¢ Number of visits at j in the ï¬rst n steps
V (n)
C (x),
V (n)
j
(x) if C = {j}.
â€¢ Expected number of visits at j starting from i Ei[Vj].
â€¢ Expected waiting time to get to C from i
Ei[tC],
Ei[tj] if C = {j}.
â€¢ Expected return time to j T jj := Ej[tj].
Figure 5.8
Some characteristic parameters for a homogeneous Markov chain
with ï¬nite or denumerable state-space.
1 with probabilities p and q := 1 âˆ’p, respectively. Compute the probability of
losing the capital and the expected number of matches to be played in order to
lose all the capital.
Solution. Let Xn be the capital available before the nth play. The game is
a one-dimensional random walk where we move forwards (the capital increases

200
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
0
1
2
3
. . .
p
p
p
q
q
q
q
1
Figure 5.9
A graph representing the transition matrix P in Exercise 5.35.
of 1 unit) with probability p and backwards with probability q := 1 âˆ’p. The
sequence

Xn

is a homogeneous Markov chain with transition matrix
P =
â›
âœâœâœâ
1
0
0
0
. . .
0
. . .
q
0
p
0
. . .
0
. . .
0
q
0
p
. . .
0
. . .
...
...
...
...
...
...
...
We want to compute the probability fi0 that, starting with a capital i the player
hits 0, hi0 = P(Ï„0 < âˆ| X0 = 1). If i = 0 then trivially hi0 = 1. If i Ì¸= 0, then
hi0 = fi0. Since 0 is recurrent and i â†’j, see Figure 5.9, then fi0 = 1. So,
whatever the initial capital and the seeming fortune of the game are, the player
will almost surely end up with no money left.
Let us now compute the expected number of matches the player has to play
before getting ruined. We denote by ti such expected time, when the player starts
with capital i, i.e. ti := hi0. Thus, see Theorem 5.33, the vector (ti) is the minimal
non-negative solution of the following system

t0 = 0,
ti = 1 + qtiâˆ’1 + pti+1
i > 0.
(5.45)
â€¢ If p Ì¸= q, then the solutions of the system (5.45) are the one parameter
family of sequences (ti), ti = 1 âˆ’a + a

q
p
i
+
i
qâˆ’p.
â€¢ If q < p, then ti diverges to âˆ’âˆas i â†’+âˆ, i.e. system (5.45) admits
no non-negative solution. Hence ti = +âˆâˆ€i.
â€¢ If p < q, then the minimal non-negative solution is ti =
i
qâˆ’p âˆ€i.
â€¢ If p = q, then the solutions of system (5.45) are the sequences (ti), ti =
a + bi âˆ’i2, a, b âˆˆR. There is no non-negative ï¬nite solution, so that ti =
+âˆâˆ€i.
Summarizing, the expected number of matches the gambler has to play, start-
ing with capital i is
ti =
â§
â¨
â©
i
q âˆ’p
if q > p,
+âˆ
if q â‰¤p.

DISCRETE TIME MARKOV CHAINS
201
5.4
Finite stochastic matrices
In this section we go back to ï¬nite stochastic matrices deï¬ned in Section 5.1
presenting their canonical representation, a very useful tool for describing the
powers of the matrix itself.
5.4.1
Canonical representation
5.4.1.1
Minimal absorbing classes
Let P be a N Ã— N stochastic matrix. For notational convenience, for every n âˆˆN,
we write p(n)
ij
instead of (Pn)i
j and pij := p(1)
ij = Pi
j. Of course p(0)
ij = Î´ij.
Deï¬nition 5.36 A nonempty subset C of {1, . . . , N} is called a closed class or an
absorbing class for P if for any i âˆˆC and for any j /âˆˆC, j is not accessible from
i, iâ†›j; equivalently, C is a closed class if and only if i âˆˆC and i â†’j imply
j âˆˆC.
In other words, C is a closed class if there is no path starting from any point
of C and arriving to points outside C. Notice that the points of C are not required
to be pairwise connected.
The simplest way to enumerate the closed classes of {1, . . . , N} is to consider
for any i âˆˆ{1, . . . , N} the set of nodes that are accessible from i

j âˆˆ{1, . . . , N}
 i â†’j

,
and which can be computed, e.g. via the matrix B in (5.2), see (5.3).
Trivially, the whole set of indexes is a closed class for P. Moreover, it is
easy to show that if C and D are closed classes, then so is C âˆªD, and so is also
C âˆ©D provided it is nonempty. Thus, closed classes are partially ordered with
respect to inclusion, and minimal closed classes C1, . . . , Cr, r â‰¥1 exist since P
is ï¬nite; each Ci is a closed class such that if D is a closed class and D âŠ‚Ci,
then D = Ci. In particular, minimal closed classes are pairwise disjoint. Minimal
closed classes can be found in the set of all closed classes. Using the partial order
with respect to inclusion, write the tree diagram of the closed classes starting
from the maximal closed class {1, . . . , N}; then the leaves of the tree are the
closed minimal classes.
Minimal closed classes can be also detected by the following proposition.
Proposition 5.37 A closed class is minimal if and only if all its elements are
pairwise communicating.
Proof. Let C be a closed class whose elements are pairwise comunicating.
Assume, by contradiction, that C is not minimal: then there exists a minimal
closed class D âŠ‚C, D Ì¸= C, and each element of D comunicates with at least
one element in C \ D âŠ‚Dc, a contradiction.

202
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Conversely, assume C is a minimal closed class. Let j âˆˆC and deï¬ne
Dj :=

i
 iâ†›j

.
(5.46)
We want to prove that Dj = âˆ…. Clearly, j /âˆˆDj, hence Dj is a proper subset
of C. We show that if Dj Ì¸= âˆ…, then Dj is a closed class, a contradiction since
Dj âŠ‚C, Dj Ì¸= C and C is minimal.
Assume Dj Ì¸= âˆ…. In order to prove that Dj is a closed class, we only need
to show that iâ†›k for i âˆˆDj and k /âˆˆDj. We distinguish between two cases:
â€¢ if k /âˆˆC, then iâ†›k since C is a closed class;
â€¢ if k âˆˆC \ Dj, then k â†’j by the deï¬nition of Dj. If i â†’k, then by
transitivity i â†’j, a contradiction since i âˆˆDj.
Minimal closed classes for P can be also detected via the matrix B in (5.2). In
fact, i â†”j if and only if Bi
j > 0 and Bj
i > 0, cf. (5.3), so that the following holds.
Proposition 5.38 The index i âˆˆ{1, . . . , N} belongs to a minimal closed class if
and only if for any j such that Bi
j > 0 then also Bj
i > 0.
Proof. In fact, by Proposition 5.37, a closed class C =

j | Bi
j > 0

containing
i is minimal if and only if

j
 Bi
j > 0

=

j
 Bi
j > 0, Bj
i > 0

.
We then summarize the above in the following theorem.
Theorem
5.39
Canonical
representation
Let
P âˆˆMN,N
be
stochastic,
S = {1, . . . , N}. Let C1, . . . , Cr be the minimal closed classes for P and for
i = 1, . . . .r denote by ki the cardinality of Ci. Finally, let T := {1, . . . , N} \
(C1 âˆªÂ· Â· Â· âˆªCr). Up to a reordering of rows and columns, a stochastic matrix P
has the canonical form
P =
â›
âœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâ
B1
0
0
Â· Â· Â·
0
0
0
B2
0
Â· Â· Â·
0
0
...
...
...
...
...
...
0
0
0
Â· Â· Â·
Br
0
R
V
â
âŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâ 
(5.47)
where B1, B2, . . . ; , Br are irreducible stochastic matrices of dimension k1 Ã— k1,
. . . , kr Ã— kr, respectively, see Proposition 5.37.

DISCRETE TIME MARKOV CHAINS
203
5.4.2
States classiï¬cation
Following the Markov chains terminology, we call states the indexes in {1, . . . ,
N}. Given a N Ã— N stochastic matrix P = (pij), we recall that a state j âˆˆ
{1, . . . , N} is recurrent if âˆ
k=1 p(k)
jj = +âˆand transient if âˆ
k=1 p(k)
jj < +âˆ,
cf. Deï¬nition 5.27.
Proposition 5.40 Let P be a N Ã— N stochastic matrix, S = {1, . . . , N}, and let
C1, . . . , Cr be the minimal closed classes in S. Set
C := C1 âˆªÂ· Â· Â· âˆªCr
and
T := {1, . . . , N} \ C
and let i, j âˆˆ{1, . . . , N}. We have the following:
(i) If j âˆˆC, then j is recurrent. Therefore, if i â†’j, then âˆ
k=1 p(k)
ij = +âˆ.
(ii) If j âˆˆT then j is transient. More precisely, for all i, j âˆˆT , p(k)
ij converges
to 0 exponentially fast as k â†’+âˆ, hence âˆ
k=1 p(k)
ij < +âˆ.
Proof. (i) Let j âˆˆCs for some s. Let us prove that j is recurrent.
Since p(n)
jh = 0 for any h /âˆˆCs
and any n â‰¥0, 
hâˆˆCs p(n)
jh = 1, hence

hâˆˆCs
âˆ
n=0 p(n)
jh = âˆ
n=0

hâˆˆCs p(n)
jh = +âˆ. In particular, there exists j0 âˆˆCs
such that âˆ
n=1 p(n)
jj0 = +âˆ. Since j0 â†”j, there exists k such that p(k)
j0j > 0, so
that from
p(n+k)
jj
=

Î±
p(n)
jÎ± p(k)
Î±j â‰¥p(n)
jj0p(k)
j0j
âˆ€n
we infer âˆ
n=1 p(n)
jj = +âˆ, i.e. j is recurrent. Now, if i â†’j âˆˆC, then
âˆ
k=1 p(k)
ij = +âˆby (i) of Proposition 5.30.
(ii) Let i âˆˆT . The set
D :=

j âˆˆ{1, . . . , N}
 i â†’j

is a closed class, so that D âˆ©C Ì¸= âˆ…. Thus, setting
p(n)
iC :=

jâˆˆC
p(n)
ij ,
there exists k = k(i) such that p(k)
iC > 0. We claim that the sequence

p(k)
iC

is
monotone nondecreasing with respect to k. In fact, for any Î± âˆˆC since pÎ±j = 0
âˆ€j /âˆˆC, we have 
jâˆˆC pÎ±j = 1. Therefore,
p(k+1)
iC
=

jâˆˆC
N

Î±=1
p(k)
iÎ± pÎ±j =
N

Î±=1
p(k)
iÎ±
 
jâˆˆC
pÎ±j

â‰¥

Î±âˆˆC
p(k)
iÎ±
 
jâˆˆC
pÎ±j

= p(k)
iC .

204
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Thus, for any i âˆˆT p(k)
iC â‰¥p(k)
iC > 0 if k â‰¥k. Since T is ï¬nite, there exist p0 > 0
and k0 such that p(k)
iC â‰¥p0 for any k â‰¥k0 and every i âˆˆT . In particular,
p(k0)
iT
=

jâˆˆT
p(k0)
ij
= 1 âˆ’p(k0)
iC
â‰¤1 âˆ’p0.
The equality p(k)
Î±j = 0 if Î± âˆˆC, j /âˆˆC also implies
p(2k0)
iT
=

jâˆˆT
p(2k0)
ij
=

jâˆˆT
N

Î±=1
pk0
iÎ±pk0
Î±j =

Î±âˆˆT
pk0
iÎ±

jâˆˆT
pk0
Î±j â‰¤(1 âˆ’p0)2
and, moreover, by an induction argument,
p(qk0)
iT
â‰¤(1 âˆ’p0)q
for any positive integer q.
Divide k by k0, k = qk0 + r, 0 â‰¤r < k0. Since the map k â†’p(k)
iT = 1 âˆ’p(k)
iC is
monotone decreasing, we ï¬nally get
p(k)
iT â‰¤p(qk0)
iT
â‰¤(1 âˆ’p0)q â‰¤(1 âˆ’p0)k/k0âˆ’1,
and
âˆ

k=1
p(k)
iT â‰¤k0 + k0
âˆ

q=1
p(qk0)
iT
â‰¤k0 + k0
âˆ

q=1
(1 âˆ’p0)q = k0
p0
.
We summarize Proposition 5.40 as follows. Let C1, . . . , Cr be the minimal
closed classes in {1, . . . , N} for P and, for i = 1, . . . .r, let ki be the cardinality
of Ci. As we have seen in Proposition 5.37, up to a relabelling of the states, we
may assume that P has the canonical form (5.47). Consequently, for each integer
n â‰¥1,
Pn =
â›
âœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâ
Bn
1
0
0
Â· Â· Â·
0
0
0
Bn
2
0
Â· Â· Â·
0
0
...
...
...
...
...
...
0
0
0
Â· Â· Â·
Bn
r
0
Rn
Vn
â
âŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâ 

DISCRETE TIME MARKOV CHAINS
205
so that, by (i) and (ii) of Proposition 5.40, setting for each i âˆˆT and j /âˆˆT
(Râˆ)i
j =

+âˆ
if i â†’j,
0
otherwise
we have
âˆ

n=0
Pn =
â›
âœâœâœâœâœâœâœâœâœâœâœâ
+âˆ
0
0
Â· Â· Â·
0
0
0
+âˆ
0
Â· Â· Â·
0
0
...
...
...
...
...
...
0
0
0
Â· Â· Â·
+âˆ
0
Râˆ
âˆ
n=0 Vn
â
âŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâ 
.
(5.48)
Finally, we point out that the matrix âˆ
n=0 Vn can be easily computed starting
from (5.47). Consider the identity
(Id âˆ’V)(Id + V + Â· Â· Â· + Vn) = Id âˆ’Vn+1.
(5.49)
Since Vn converges to the zero matrix exponentially fast as n goes to inï¬n-
ity, see (ii) of Proposition 5.40, the series âˆ
n=0 Vn converges. Passing to the
limit as n â†’âˆ, (5.40) yields (Id âˆ’V) âˆ
n=0 Vn = Id. In other words, Id âˆ’V
is invertible and
âˆ

n=0
Vn = (Id âˆ’V)âˆ’1.
(5.50)
5.4.3
Exercises
Exercise 5.41 Prove the following:
(i) The matrix P =

1
0
0
1

has two minimal closed classes and no transient
state.
(ii) The matrix P :=

0
1
1/2
1/2

is irreducible.
(iii) The matrix P :=

1
0
1/2
1/2

has one minimal closed class, {1}, and 2 is
a transient state.
(iv) The matrix P :=

0
1
1
0

is irreducible.

206
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Exercise 5.42 Find the canonical form of the stochastic matrix
P =
â›
âœâœâœâœâœâœâœâœâœâœâœâœâœâ
0
0
0
0
0
0
0.5
0
0.5
0
0
0.3
0
0.7
0
0
0
0
0
0
0
0
0
0
0.5
0
0
0.5
0
0
0
0
0
1
0
0
0
0
0
0
0
0.1
0.1
0.1
0.1
0
0
0
0
0.6
0.1
0
0
0
0.9
0
0
0
0
0
0.2
0
0
0
0
0
0
0
0.8
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0.6
0
0.4
0
0
0
0
0
0
0
0
0
0
1
â
âŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâ 
.
Exercise 5.43 Let P = (pij) be a N Ã— N irreducible stochastic matrix and let
C âŠ‚{1, . . . , N}, C Ì¸= âˆ…. Show that there exist h âˆˆC and k /âˆˆC such that phk > 0.
Solution. Without loss of generality, assume C = {1, . . . , s}. If phk = 0 âˆ€h âˆˆ
C and âˆ€k /âˆˆC, then P has the form
P =
?
A
0
B
@
,
a contradiction, since P is irreducible.
5.5
Regular stochastic matrices
In this section we deal with the convergence of the sequence of the powers of
the transition matrix for a particular class of homogenenous Markov chains with
ï¬nite state-space S = {1, . . . , N}.
A fundamental difference exists between ï¬nite dimensional stochastic vectors
and inï¬nite dimensional ones. Let

x(n)
âŠ‚[0, 1]âˆbe the sequence of stochastic
vectors deï¬ned by x(n) =

x(n)
j

j, x(n)
j
:= Î´j,n. For each ï¬xed j, x(n)
j
â†’0 as
n â†’âˆ, i.e.

x(n)
converges to (0, 0, 0, 0, . . . ) componentwise. This shows
that, in general, a converging sequence of stochastic vectors does not converge
to a stochastic vector. On the other hand, the set of stochastic vectors in RNâˆ—
T :=

x = (x1, . . . , xn) âˆˆRN  xi â‰¥0,
N

i=1
xi = 1
>
is a closed set: if

xn

âŠ‚T and xn â†’x, then x âˆˆT .
5.5.1
Iterated maps
We now recall a few facts from the theory of iterated maps.

DISCRETE TIME MARKOV CHAINS
207
Let X be a metric space and let f : X â†’X be a continuous map from
X into itself. For every k âˆˆN, we denote by f k : X â†’X the kth iterate of
f , i.e. f k := f â—¦f â—¦Â· Â· Â· â—¦f k times. For the sake of convenience we also set
f 0(x) = x. For every x âˆˆX, the sequence

f k(x)

k is called the path of x. We
say that p âˆˆX is a ï¬xed point for f if f (p) = p. Finally, if for every x âˆˆX
f k(x) â†’p we say that p is the sink of f .
Simple examples of the above can be drawn considering afï¬ne maps
f : [0, 1] â†’[0, 1]. The following claims are easily proved, see Exercise 5.63.
Proposition 5.44 The following hold:
(i) If p is a ï¬xed point for f , then, for every k â‰¥0, f k(p) = p, i.e. p is a ï¬xed
point for f k.
(ii) Let n > 1 and let p be a ï¬xed point for f n. Then p, f (p), . . . , f nâˆ’1(p)
are ï¬xed points for f n, too. In particular, if f n has a unique ï¬xed point,
then p is also the unique ï¬xed point of f .
(iii) If for some x âˆˆX, f k(x) â†’p as k â†’âˆ, then p is a ï¬xed point for f .
(iv) If p is the sink of f , then p is the unique ï¬xed point of f .
(v) There exist maps f that have ï¬xed points but no sink.
(vi) Let n â‰¥1. A point p âˆˆX is the sink of f if and only if p is the sink of f n.
The existence of ï¬xed points can be granted under quite general assumptions.
We have the following.
Theorem 5.45 (Brouwer) Let X be a compact and convex set in RN and let
f : X â†’X be a continuous map. Then f has a ï¬xed point.
Proof. Let x âˆˆX âŠ‚RN. Consider the path {f n(x)} of x. For every n
wn :=
1
n + 1
n

k=0
f n(x)
is a convex combination of f 0(x), f 1(x), . . . , f n(x), hence wn âˆˆX since X is
convex. Since X is also compact, there exist w âˆˆX and a subsequence of

wn

,
that for convenience we still denote by

wn

, such that wn â†’w. Let us prove
that f (w) = w. For every n we have
f (wn) âˆ’wn
 =
1
n + 1

n

j=0

f j+1(x) âˆ’f j(x)

=
1
n + 1
f n+1(x) âˆ’x
 â‰¤diam(X)
n + 1 .
Passing to the limit as n â†’âˆ, continuity of f yields |f (w) âˆ’w| = 0, i.e.
f (w) = w.

208
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Existence of a sink for f requires different assumptions on f . Let us start
with a deï¬nition.
A contraction map, or simply a contraction, on X is a map f : X â†’X which
shrinks distances uniformly, i.e. a map for which there exists a constant L, 0 <
L < 1, such that |f (x) âˆ’f (y)| â‰¤L|x âˆ’y| âˆ€x, y âˆˆX. Of course, a contraction
map is continuous on X.
Theorem 5.46 (Banach ï¬xed point theorem) Let X be a complete metric space
with distance d and let f : X â†’X be a contraction with contraction factor
L < 1. Then f has an unique sink p âˆˆX. More precisely, for every x âˆˆX the
path {f n(x)} converges to p at least exponentially fast,
d(f n(x), p) â‰¤
Ln
1 âˆ’Ld(f (x), x)
âˆ€n.
(5.51)
Proof. Uniqueness. If p, q âˆˆX are two ï¬xed points, then
d(p, q) = d(f (p), f (q)) â‰¤L d(p, q),
hence d(p, q) = 0, since L < 1.
Existence. For any x âˆˆX, let xk := f k(x), where, we recall, f k := f â—¦Â· Â· Â· â—¦f
k times. We then have
d(xk+1, xk) â‰¤Ld(xk, xkâˆ’1) â‰¤Â· Â· Â· â‰¤Lkd(x1, x0) = Lkd(f (x), x)
hence, for q â‰¥p â‰¥1,
d(xq, xp) â‰¤
qâˆ’1

k=p
d(xk+1, xk) â‰¤
qâˆ’1

k=p
Lk d(f (x), x) â‰¤
Lp
1 âˆ’L d(f (x), x)
(5.52)
since L < 1. The right-hand side of (5.52) converges to zero as p â†’âˆ, so that

xn

is a Cauchy sequence and thus converges to some p = p(x) âˆˆX which
is a ï¬xed point for f , see (iii) of Proposition 5.44. Since f has a unique ï¬xed
point, p(x) = p âˆ€x so that for every x âˆˆX, f k(x) â†’p, i.e. p is the sink of f .
Combining the Banach ï¬xed point theorem with (vi) of Proposition 5.44, we
have the following.
Corollary 5.47 Let X be a complete metric space and let f : X â†’X be contin-
uous. If, for some n â‰¥1, f n is a contraction with contraction factor L < 1, then
f has a unique sink p âˆˆX and for every x âˆˆX
d(f k(x)), p) â‰¤L
 
k
n
!
1 âˆ’L max
0â‰¤j<n d(f n(xj), xj)
(5.53)

DISCRETE TIME MARKOV CHAINS
209
where for j = 0, . . . , n âˆ’1, we set xj := f j(x). Moreover, if X is bounded,
diam(X) < âˆ, then
d(f k(x)), p) â‰¤diam(X)L
 
k
n
!
.
(5.54)
Proof. By the Banach ï¬xed point theorem, f n has a sink p and for every
x âˆˆX
d(f n(x), p) â‰¤
Ln
1 âˆ’Ld(f n(x), x).
Consequently, p is the sink of f by (vi) of Proposition 5.44. In order to prove
estimate (5.53), write every k as k = qn + j, 0 â‰¤j < n, q =
 k
n

. Then
d(f k(x), p) = d(f qn(f j(x)), p) â‰¤
Lq
1 âˆ’Ld(f n(xj), xj).
Taking the maximum of the right-hand sides for j = 0, . . . , n âˆ’1, we get (5.53).
Finally, with f n being a contraction and p being a ï¬xed point for f n, we have
d(f k(x)), p) = d(f qn(f j(x)), p) â‰¤L d(f (qâˆ’1)n(f j(x)), p)
â‰¤Â· Â· Â· â‰¤Lq d(f j(x), p) â‰¤Lq diam(X).
5.5.2
Existence of ï¬xed points
Let T âŠ‚RN be the set of stochastic vectors and let P be a stochastic matrix,
so that the linear map P(x) := xP maps T into itself. Since T is convex and
compact, the Brouwer ï¬xed point theorem applies to the map P and we have the
following.
Theorem 5.48 (Perronâ€“Frobenius) There exists at least a stochastic vector w
such that w := wP.
Example 5.49 Let P =

1
0
0
1

. Each vector of R2âˆ—is a ï¬xed point for the
associated linear map P(x) = xP and P has no sink.
Let P =

0
1
1
0

, then the only ï¬xed point for the map P(x) := xP in T
is w := (1/2, 1/2). Moreover,
Pn =

Id
if n is even,
P
if n is odd,
so that, if x âˆˆT , then xPn converges to w if and only if x = w and the map
P(x) := xP has no sink.

210
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Example 5.49 shows that, in general, a map can have more than one ï¬xed point
and, in general, the sequence {xPn} does not converge.
Example 5.50 Let P =

1 âˆ’Î±
Î±
Î²
1 âˆ’Î²

with 0 < Î±, Î² < 1. The only ï¬xed point
in T for P(x) = xP is w :=
1
Î±+Î² (Î², Î±). Moreover, computing Pn one can show
that w is a sink for P ,
xPn â†’
1
Î± + Î² (Î², Î±)
âˆ€x âˆˆT .
5.5.3
Regular stochastic matrices
Deï¬nition 5.51 A ï¬nite stochastic matrix P is said to be regular if there exists k0
such that all the entries of the matrix Pk0 are nonzero.
Trivially, a regular stochastic matrix is irreducible.
5.5.3.1
Convergence
We now prove that if P is regular then P(x) := xP has a unique sink w âˆˆT , that
is, xPn â†’w âˆ€x âˆˆT . In order to do that, we need to introduce some deï¬nitions.
For each x âˆˆRNâˆ—, set
||x||1 :=
N

i=1
|xi|.
(5.55)
Thus, x â†’||x||1 is a norm in RNâˆ—and for each stochastic vector x, ||x||1 = 1.
With an induction argument on the dimension N, it can be also easily proven
that
||x||2 â‰¤||x||1 â‰¤
âˆš
N||x||2
âˆ€x âˆˆRNâˆ—,
(5.56)
where ||x||2 :=
6N
i=1 |xi|2 is the Euclidean norm of x.
Lemma 5.52 The space RNâˆ—, equipped with the norm || ||1, is complete. Thus T ,
a closed subset of RNâˆ—, is a complete metric space.
Proof. By inequality (5.56) a sequence in RNâˆ—converges with respect to the
|| ||1 norm if and only if it converges with respect to the || ||2 norm. Similarly,
a sequence in RNâˆ—is a Cauchy sequence with respect to the || ||1 norm if and
only if it is a Cauchy sequence with respect to the || ||2 norm. Thus, since RNâˆ—
is complete with respect to the Euclidean norm, it is also complete with respect
to the || ||1 norm.
Proposition 5.53 Let P be a stochastic N Ã— N matrix. Denote by R1, . . . , RN the
rows of P and let K âŠ‚RNâˆ—be their convex envelope. Set
C := 1
2 max
i,j ||Ri âˆ’Rj||1.

DISCRETE TIME MARKOV CHAINS
211
Then:
(i) C â‰¤1.
(ii) If all the entries of P are nonzero, then C < 1.
(iii) diam1(K) := supx,yâˆˆK ||x âˆ’y||1 = 2C.
(iv) Let P(x) := xP. Then ||P(x) âˆ’P(y)||1 â‰¤C||x âˆ’y||1 âˆ€x, y âˆˆT .
Proof. (i) Each row of P belongs to T , hence ||Ri âˆ’Rj||1 â‰¤||Ri||1 +
||Rj||1 = 2 âˆ€i, j âˆˆ{1, . . . , N}.
(ii) Let x = (x1, . . . , xN) and y = (y1, . . . , yN) âˆˆT be such that ||x âˆ’y||1 =
2 = ||x||1 + ||y||1. Let A =

i âˆˆ{1, . . . , N} | xi > yi

and B := {1, . . . , N} \ A.
We claim that both A and B are nonempty sets. Assume by contradiction that
A is empty, so that xi â‰¤yi âˆ€i. Since x and y are stochastic, then x = y,
hence ||x âˆ’y||1 = 0 Ì¸= 2, a contradiction. If B is empty, then xi > yi âˆ€i, so that
1 = ||x||1 = N
i=1 xi > N
i= yi = ||y||1 = 1, a contradiction.
We show that some component of both x and y is null. In fact,
N

i=1
xi +
N

i=1
yi = 2 = ||x âˆ’y||1 =

iâˆˆA
(xi âˆ’yi) +

iâˆˆB
(yi âˆ’xi)
i.e.

iâˆˆA
yi +

iâˆˆB
xi = 0.
In particular, yi = 0 âˆ€i âˆˆA and xi = 0 âˆ€i âˆˆB.
If each entry of P is nonzero, then, from the above, ||Ri âˆ’Rj||1 < 2 for any
i, j = 1, . . . , N, i.e. C < 1.
(iii) Let Î´ := diam1(K). By deï¬nition, 2C â‰¤Î´. Let us show that Î´ â‰¤2C. Let
B(x, r) :=

y | ||y âˆ’x||1 â‰¤r

be the closed ball in RNâˆ—with respect to the || ||1
norm centred at x and with radius r. By deï¬nition of C, Ri âˆˆB(Rj, 2C) for any
i, j âˆˆ{1, . . . , N}. Since B(Rj, 2C) is convex, then K âŠ‚B(Rj, 2C) for any j, or,
equivalently, Rj âˆˆB(x, 2C) âˆ€x âˆˆK. Since B(x, 2C) is convex, K âŠ‚B(x, 2C)
âˆ€x âˆˆK, i.e. ||x âˆ’y||1 â‰¤2C âˆ€x, y âˆˆK.
(iv) We show that, if a = (a1, . . . , aN) is such that N
i=1 ai = 0, then
||P(a)||1 â‰¤C ||a||1.
(5.57)
Without loss of generality, we may assume ||a||1 = 2. For any x âˆˆRNâˆ—let
â€²
i xi = 
xi > 0 xi and â€²â€²
i xi = 
xi<0 xi, so that â€²
i ai = âˆ’â€²â€²
i ai = 1. Thus,
both the convex combinations xâ€² = â€²
iaiRi and xâ€²â€² = âˆ’â€²â€²
i aiRi belong to K, so
that by (iii)
||P(a)||1 = ||

i
aiRi||1 = ||xâ€² âˆ’xâ€²â€²||1 â‰¤2C = C ||a||1.

212
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Claim (iv) follows by choosing a = x âˆ’y in (5.57).
Theorem 5.54 Let P be a ï¬nite stochastic matrix. The following are equivalent:
(i) P is regular,
(ii) P is irreducible and the map P : T â†’T , P(x) = xP has a sink w âˆˆT ,
i.e. xPn â†’w âˆ€x âˆˆT .
(iii) âˆƒn such that âˆ€n â‰¥n all the entries of Pn are nonzero.
Moreover, in this case:
(a) w is the only ï¬xed point in T of the map x â†’xP.
(b) All the components of w are nonzero.
(c) Let R1, . . . , RN be the rows of Pk0. Then
C := 1
2
max
i,j=1,...,N ||Ri âˆ’Rj||1 < 1
and, for any x âˆˆT ,
||xPn âˆ’w||1 â‰¤2 CâŒŠn/k0âŒ‹.
(5.58)
Proof. (i) â‡’(ii). If all the entries of Pk0 are positive, then all the states
1, . . . , N are pairwise communicating, i.e. P is irreducible. By Proposition 5.53
C < 1 so that P k0(x) := xPk0 is a contraction on T with contraction factor less
than or equal to C. Thus, applying the Banach ï¬xed point theorem, P k0 admits
a unique sink w. Since diam(T ) â‰¤2, Corollary 5.47 yields
||P n(x) âˆ’w||1 â‰¤2C
 
n
k0
!
.
Finally, the components of w = (w1, . . . , wn) are positive, see Exercise 5.65.
(ii) â‡’(iii). P n(x) = xPn converges to w for any x âˆˆT if and only if eiPn â†’w
for any i = 1, . . . , N, i.e. if and only if each row of Pn converges w. Since P is
irreducible, all the components of w are positive, see Exercise 5.65, so that all
the entries of Pn are positive for n large enough.
(iii) â‡’(i). Obvious.
Remark 5.55 If P denotes the transition matrix of a Markov chain, the con-
vergence of xPn to w âˆ€x âˆˆT reads as follows: for any j âˆˆ{1, . . . , N} we
have
P(Xn = j) =
N

i=1
P(X0 = i) (Pn)i
j âˆ’â†’wj;
in other words, whatever the distribution of the initial random variable X0, the
mass distributions of the Xnâ€™s converge to the stochastic vector w = (wj).

DISCRETE TIME MARKOV CHAINS
213
We may rewrite the claim of Theorem 5.54 in terms of matrices. With the
notation above, let w âˆˆT be the ï¬xed point of the map P(x) := xP and let W
be the N Ã— N stochastic matrix whose rows coincide with w,
W := w(1, 1, . . . , 1)T .
Then:
(i) xPn â†’w âˆ€x âˆˆT if and only if Pn â†’W.
(ii) The exponential rate of convergence in (5.58) reads
||Pn âˆ’W|| â‰¤2 CâŒŠn/k0âŒ‹.
where
||A|| =
max
i=1,...,N ||Ai||1.
(iii) wP = w if and only if WP = W.
Finally, since all the rows of W are the same stochastic vector w and W = WP,
the following equalities can be easily proven
W = W2 = WP = PW.
(5.59)
5.5.3.2
Eigenvalues
Proposition 5.56 Let P be a N Ã— N stochastic matrix. Then 1 is an eigenvalue for
P with corresponding eigenvector v := (1, 1, . . . , 1)T . Moreover, for any eigen-
value Î» âˆˆC of P we have |Î»| â‰¤1.
Proof. Since P is stochastic, trivially, Pv = v.
Let Î» âˆˆC be an eigenvalue of P and z = (z1, . . . , zN) Ì¸= 0 be an eigenvector
of Î», Î»z = Pz. Let i0 be such that |zi0| = maxi |zi| so that |zi0| Ì¸= 0 and
|Î»| |zi0| = |(Pz)i0| =

N

j=1
Pi0
j zj â‰¤
N

i=1
Pi0
j |zj| â‰¤|zi0|
N

j=1
Pi0
j = |zi0|.
Therefore |Î»| â‰¤1.
The next theorem characterizes the eigenvalues of regular stochastic matrices.
We omit the proof, which can be found, e.g. in [16] Proposition 9.2.
Theorem 5.57 Let P be a regular stochastic matrix. Then 1 is the only eigenvalue
of P of modulus 1. Its algebraic and geometric multiplicities are 1. Consequently,
all the eigenvalues of P but 1 have modulus strictly less than 1.
Since P is regular, one can easily compute the powers of P and their limit
as n â†’âˆby Theorem 5.57. In fact, Theorem 5.57 implies that P has a Jordan

214
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
decomposition P = SJSâˆ’1 where the ï¬rst column of S is an eigenvector of P
relative to the eigenvalue 1, i.e. (1, 1, . . . , 1)T ,
J =
â›
âœâœâœâœâœâœâœâ
1
0
0
. . .
0
0
J1
0
. . .
0
0
0
J2
. . .
0
...
...
...
...
0
0
0
0
. . .
Jp
â
âŸâŸâŸâŸâŸâŸâŸâ 
and J1, J2, . . . , Jp are Jordan blocks relative to the eigenvalues of P but 1.
Therefore, from P = SJSâˆ’1 we infer Pn = SJnSâˆ’1 where
Jn =
â›
âœâœâœâœâœâœâœâ
1
0
0
. . .
0
0
Jn
1
0
. . .
0
0
0
Jn
2
. . .
0
...
...
...
...
0
0
0
0
. . .
Jn
r
â
âŸâŸâŸâŸâŸâŸâŸâ 
.
Since all the eigenvalues but 1 have modulus strictly smaller than 1, Jn con-
verges to
K :=
â›
âœâœâœâ
1
0
. . .
0
0
0
. . .
0
...
...
...
...
0
0
. . .
0
â
âŸâŸâŸâ 
and, for each Ïµ > 0 there exists a constant CÏµ such that
||Jn âˆ’K|| â‰¤CÏµ(Î»âˆ—+ Ïµ)n
as n â†’âˆ
where
Î»âˆ—:= max

|Î»|
 Î»eigenvalue of P, |Î»| < 1

.
We then infer
(Pn)i
j â†’(SKSâˆ’1)i
j = Si
1(Sâˆ’1)1
j = (1, 1, . . . , 1)T w,
(5.60)
where w = (w1, . . . , wN) is the row vector deï¬ned by wj := (Sâˆ’1)1
j âˆ€j. Denot-
ing by W the matrix with each row equal to w, we conclude from (5.60) that
Pn â†’W
with an exponential rate of convergence driven by Î»âˆ—: for any Ïµ > 0 there exists
CÏµ such that
||Pn âˆ’W|| â‰¤CÏµ(Î»âˆ—+ Ïµ)n.

DISCRETE TIME MARKOV CHAINS
215
Finally, observe that W is a stochastic matrix, being the limit of stochastic
matrices. Moreover, cf. Exercise 5.65, all its entries are positive.
5.5.3.3
Fixed point and expected return times
Let

Xn

be a homogeneous Markov chain with a ï¬nite or denumerable state-
space S and transition matrix P = (pij). Recall that for i, j âˆˆS, f (k)
ij
denotes the
probability that a path from i visits for the ï¬rst time j at step k.
Proposition 5.58 For any n â‰¥1 we have
p(n)
ij =
n

k=1
f (k)
ij p(nâˆ’k)
jj
.
(5.61)
Proof. Let k âˆˆ{1, . . . , n} and let
Fk,n :=

x âˆˆ
 X1(x) Ì¸= j, . . . , Xkâˆ’1(x) Ì¸= j, Xk(x) = j, Xn(x) = j

be the set of paths that visit state j for the ï¬rst time at step k and then return to
j again at time n. Let
E :=

x âˆˆ
 Xn = j

,
F :=

x âˆˆ
 Xk(x) = j, Xkâˆ’1(x) Ì¸= j, . . . , X1(x) Ì¸= j

,
G :=

x âˆˆ
 X0 = i

.
By (5.8) and the homogeneity of the chain, we infer
P

Fk,n
 X0 = i

= P(E | F)P(F | G)
= P

Xn = j
 Xk = j

P

Xk = j, Xkâˆ’1 Ì¸= j, . . . , X1 Ì¸= j
 X0 = i

= p(nâˆ’k)
jj
f (k)
ij .
Since the sets

Fk,n

, k = 1, . . . , n, are a partition of the set

x âˆˆ | Xn = j

,
we get
p(n)
ij = P

Xn = j
 X0 = i

=
n

k=1
P

Fk,n
 X0 = i

=
n

k=1
f (k)
ij p(nâˆ’k)
jj
.
Lemma 5.59 Let

pn

and

fn

be two sequences of non-negative numbers such
that p0 = 1, âˆ
i=1 fi = 1 and
pn =
n

j=1
fjpnâˆ’j
âˆ€n â‰¥1.
(5.62)

216
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
If pn â†’a âˆˆR+ (ï¬nite or inï¬nite), then
a = 1
T
T :=
âˆ

k=1
kfk.
Proof. Summing equalities (5.62) from 1 to N, we get
N

n=1
pn =
N

n=1
n

j=1
fjpnâˆ’j =
N

n=1
 nâˆ’1

j=0
fnâˆ’jpj

,
(5.63)
or, equivalently,
pN +
Nâˆ’1

j=1

1 âˆ’
Nâˆ’j

i=1
fi

pj =
N

j=1
fj.
(5.64)
or, taking into account that âˆ
j=1 fj = 1,
N

j=1
pj

âˆ

i=Nâˆ’j+1
fi

=
N

j=1
fj.
(5.65)
For each j â‰¥1, let Tj := âˆ
i=j fi. Then T1 = âˆ
i=1 fi = 1, and
âˆ

j=1
Tj =
âˆ

j=1
âˆ

i=j
fi =
âˆ

i=1
i

j=1
fi =
âˆ

i=1
ifi = T.
Thus, (5.64) or (5.65) reads N
j=1 pjTNâˆ’jâˆ’1 = N
j=1 fj, i.e.
N

j=1
TjpN+1âˆ’j =
N

j=1
pjTNâˆ’j+1 =
N

j=1
fj.
(5.66)
Let

Ï•N(j)

be the double indexed sequence deï¬ned as
Ï•N(j) :=

TjpN+1âˆ’j
if 1 â‰¤j â‰¤N,
0
if j > N.
Then equality (5.66) reads
âˆ

j=1
Ï•N(j) =
N

j=1
fj.
(5.67)
Since, by assumption, for any j âˆˆS Ï•N(j) â†’aTj as N â†’âˆ, the following
hold:

DISCRETE TIME MARKOV CHAINS
217
â€¢ If T = âˆ
j=1 Tj = +âˆ, then the Fatou lemma, Lemma B.51, together with
(5.67), gives
a T = a
âˆ

j=1
Tj =
âˆ

j=1
lim
Nâ†’âˆÏ•N(j)
â‰¤lim inf
Nâ†’âˆ
âˆ

j=1
Ï•N(j) =
âˆ

i=1
fi = 1
so that a = 0.
â€¢ If T < +âˆ, then supN Ï•N(j) â‰¤Tj âˆ€j, and âˆ
j=1 Tj = T < +âˆ. Thus,
the dominated convergence theorem for series, see Example B.56, yields
a T = a
âˆ

j=1
Tj =
âˆ

j=1
lim
Nâ†’âˆÏ•N(j) = lim
Nâ†’âˆ
âˆ

j=1
Ï•N(j) =
âˆ

i=1
fi = 1.
The proof is thus complete.
Lemma 5.60 Let

Xn

be a homogeneous Markov chain with ï¬nite or
denumerable state-space S and transition matrix P = (pij) and let j âˆˆS. If
p(n)
jj â†’Î», then
p(n)
ij â†’fijÎ»;
Similarly, if 1
n
n
k=1 p(k)
jj â†’Î», then 1
n
n
k=1 p(k)
ij â†’fijÎ».
Proof. Equality (5.61) can be written as
p(n)
ij =
n

k=1
f (k)
ij p(nâˆ’k)
jj
=
âˆ

k=1
Ï•n(k)
where
Ï•n(k) := 1{1,...,n}(k)f (k)
ij p(nâˆ’k)
jj
.
Since for any ï¬xed k, Ï•n(k) â†’f (k)
ij Î» as n â†’âˆ, applying the dominated con-
vergence theorem for series, Example B.56, we get
lim
nâ†’âˆp(n)
ij = lim
nâ†’âˆ
âˆ

k=1
Ï•n(k) =
âˆ

k=1
lim
nâ†’âˆÏ•n(k)
=
 âˆ

k=1
f (k)
ij

Î» = fijÎ».
Similarly, one proves the last claim, writing this time
1
n
n

k=1
p(k)
ij =
âˆ

r=1
Ïˆn(r)
where Ïˆn(r) := 1{1,...,n}(r)f (r)
ij

1
n
nâˆ’r
k=1 p(k)
jj

.

218
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Theorem 5.61 Let

Xn

be a homogeneous Markov chain with ï¬nite or
denumerable state-space S and transition matrix P = (pij). For any i, j âˆˆS let
T jj âˆˆR and fij be the expected return time in state j and the probability of
visiting j starting from i, respectively. If p(n)
jj â†’wj, then
wj =
1
T jj
and
p(n)
ij â†’fijwj.
Notice that, if j is transient, then trivially wj = 0 = fijwj. Moreover, if j is
recurrent and i â†’j, then fij = 1 so that fijwj = wj.
Proof. In order to prove that wj :=
1
T jj , we distinguish two cases:
â€¢ Assume j is transient, i.e. fjj < 1. Thus, T jj = +âˆby (5.34) and
âˆ
n=i p(n)
jj < +âˆby (5.32). Hence, p(n)
jj â†’0 = 1/T jj = wj.
â€¢ Assume j is recurrent, fjj = 1. Then, by (5.34) T jj = âˆ
j=1 kf (k)
jj
and,
by Proposition 5.58,
p(n)
jj =
n

k=1
f (k)
jj p(nâˆ’k)
jj
âˆ€n â‰¥1.
The claim now follows applying Lemma 5.59 to the sequences

pn

and

fk

where pn := p(n)
jj and fk := f (k)
jj .
The last claim follows from Lemma 5.60.
5.5.4
Characteristic parameters
For the readerâ€™s convenience we summarize the formulas that can be used to
compute the characteristic parameters introduced in Section 5.3 in terms of the
transition matrix P. Assuming P is reordered in a canonical form (5.47), then
(5.48) gives:
â€¢ the expected number of visits, see (5.30);
â€¢ the probability that a path from i visits j at least once, see (5.32);
â€¢ the probability of many passages in j starting from i, see (5.28).
5.5.4.1
Waiting time matrix
In Section 5.3.4 we have proven that if j is transient then the expected return time
T jj is inï¬nite, while, if j is recurrent, then T jj = âˆ
k=1 kf (k)
jj , see formula (5.35).
We now deal with the waiting time matrix T = (T
i
j), where T
i
j := Ei[tj] is
the conditional expected ï¬rst passage time to j starting from i. We only consider

DISCRETE TIME MARKOV CHAINS
219
homogeneous Markov chains

Xn

with a ï¬nite state-space S so that we can take
advantage of the canonical decomposition of its transition matrix P and therefore
conï¬ne ourselves to the case when P is irreducible.
We have already shown that, if P is regular, then P has a unique stochas-
tic ï¬xed point, w = (wj) âˆˆT with non-zero components, cf. Theorem 5.54.
Moreover, the expected return time to the state j is T jj = 1/wj, in particu-
lar, j is positive recurrent. This fact has already been proven if P is regular, see
Theorems 5.54 and 5.61, but the same holds if P is irreducible, see Theorem 5.71
and Remark 5.82. In other words, the computation of the diagonal entries of T,
i.e. of the expected return times, boils down to the computation of the unique
solution w âˆˆT of the equation w = wP.
In order to write an explicit formula for all the entries of T, let us introduce
a few notations. For any square matrix A = (aij), let Ad := (aijÎ´ij). Also let E
be the square matrix whose entries are all equal to 1. Clearly, (ABd)d = AdBd
for any A and B, and EAd is such that all its rows are equal to the row vector
of the diagonal elements of A. Finally, let W be the matrix whose rows agree
with the stochastic vector w âˆˆT such that w = wP. Then
Td = ((1/Wi
j)Î´ij) = (Î´ij/wj).
Proposition 5.62 (Expected ï¬rst passage time matrix) The matrix
Id âˆ’(P âˆ’W)
is invertible. Denoting Z := (Id âˆ’(P âˆ’W))âˆ’1, we have
T = (Id âˆ’Z + EZd)Td,
(5.68)
i.e. Ti
j = (Î´i
j âˆ’Zi
j + Zj
j) 1
wj âˆ€i, j âˆˆS.
Proof. Since W = W2 = PW = WP, cf. (5.59), we have (P âˆ’W)2 = P2 âˆ’
2PW + W2 = P2 âˆ’W. Moreover, it can be proved (either with an induction
argument or using Newton binomial theorem) that
(P âˆ’W)k = Pk âˆ’W
âˆ€k.
Since Pn â†’W, the previous formula yields (P âˆ’W)k â†’0. Therefore, one can
pass to the limit as n â†’âˆin the identity
(Id âˆ’(P âˆ’W))
n

k=0
(P âˆ’W)k = Id âˆ’(P âˆ’W)n+1
to get both the invertibility of Id âˆ’(P âˆ’W) and a formula for its inverse Z,
Z =
âˆ

k=0
(P âˆ’W)k = Id +
âˆ

k=1
(Pk âˆ’W).

220
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
We now prove (5.68) in three steps.
Step 1. From Proposition 5.31 we infer
Ei[tj] = 1 +

â„“Ì¸=j
piâ„“Eâ„“[tj],
i.e.
T = E + P(T âˆ’Td).
Therefore, T is a solution of the system

Xd = Td,
X = P(X âˆ’Td) + E.
(5.69)
Step 2. Let M be the right-hand side of (5.68),
M := (Id âˆ’Z + EZd)Td.
We claim that the matrix M satisï¬es system (5.69). In fact, Md = Td since all
the diagonal entries of (Id âˆ’Z + EZd) are equal to 1. In order to prove that M
satisï¬es also the second equation in (5.69), let us point out the followings:
(i) Id âˆ’Z = W âˆ’PZ: to prove it, multiply on the right by Z both sides
of the equality Zâˆ’1 = Id âˆ’P + W and recall that WZâˆ’1 = W, i.e
W = WZ.
(ii) WTd = E, which follows from the deï¬nition of W.
(iii) PEZd = EZd which easily follows from the identities N
j=1 pij = 1
âˆ€i âˆˆS.
Thus we have
P(M âˆ’Td) + E = P(âˆ’Z + EZd)Td + E = (âˆ’PZ + EZd)Td + E
= M âˆ’WTd + E = M.
Step 3. We now show that system (5.69) has a unique solution R, so that T = M
as claimed. Let M1 and M2 be two different solutions to system (5.69) and let
R := M1 âˆ’M2. Then, the diagonal entries of R are zero and R = PR. Let r be
a column of R so that r = Pr. Consequently, r = Pkr for any integer k and,
passing to the limit as k â†’âˆ, we get Wr = r. Since the rows of W are equal,
then so are the components of r, and since the diagonal of R is null, then all the
components of r are null. Hence r is the null vector, and since r is an arbitrary
column of R, we conclude that R = 0, i.e. M1 = M2.
5.5.5
Exercises
Exercise 5.63 Prove Proposition 5.44.

DISCRETE TIME MARKOV CHAINS
221
Solution. (i) Trivial.
(ii) If f n(p) = p, then for every j â‰¥1 f n(f j(p)) = f j(f n(p)) = f j(p), i.e.
f j(p) is a ï¬xed point for f n. If f n has a unique ï¬xed point p, then p = f (p),
i.e. p is a ï¬xed point for f , actually the unique ï¬xed point by (i).
(iii) If f k(x) â†’p, then f k+1(x) â†’p and f k+1(x) = f (f k(x)) â†’f (p) by
continuity, hence f (p) = p.
(iv) Let p1 be another ï¬xed point for f . Then f k(p1) = p1 for every k, i.e.
f k(p1) is constant and converges to p, hence p = p1.
(v) Consider f (x) = âˆ’x, x âˆˆ[âˆ’1, 1]. Then 0 is a ï¬xed point but for every x Ì¸= 0
f k(x) = (âˆ’1)kx.
(vi) If f k(x) â†’p, then trivially (f n)k(x) = f kn(x) â†’p. Conversely, if p is
the sink of f n, then p is the unique ï¬xed point of f n by (iv) and consequently
the unique ï¬xed point of f by (ii). Moreover, for every j â‰¥0, f hn+j(x) =
f j(f hn(x)) â†’f j(p) = p as h â†’âˆ. Writing every k as k = hn + j, 0 â‰¤j <
n, we conclude that f k(x) â†’p as k â†’+âˆ.
Exercise 5.64 Let P = (pij) be a N Ã— N irreducible stochastic matrix. If there
exists h âˆˆ{1, . . . , N} such that phh > 0, then P is regular.
Solution. P is irreducible, hence for every Î±, Î² âˆˆ{1, . . . , N} there exists n =
n(Î±, Î²) such that p(n(Î±,Î²))
Î±Î²
> 0. Let k0 := 2 maxÎ±,Î² n(Î±, Î²) + 1. Then, for any
i, j âˆˆ{1, . . . , N}, we get
p(k0)
ij
â‰¥p(n(i,h))
ih
p(q)
hh p(n(h,j))
hj
â‰¥p(n(i,h))
ih
(phh)qp(n(h,j))
hj
> 0
where q := k0 âˆ’n(i, h) âˆ’n(h, j) â‰¥1.
Exercise 5.65
Let P = (pij) be an irreducible N Ã— N stochastic matrix and
let j âˆˆ{1, . . . , N}. Show that, if 1
n
n
k=1 p(k)
jj converges to Î» (in particular, if
p(n)
jj â†’Î»), then Î» > 0.
Solution. Assume, by contradiction, that 1
n
n
k=1 p(k)
jj â†’0 converges to zero.
Since P is irreducible, for any i âˆˆ{1, . . . , N} there exists k0 = k0(i) such that
p(k0)
ij
> 0. Thus p(k)
ji p(k0)
ij
â‰¤p(k+k0)
jj
and
lim
nâ†’âˆ
1
n
n

k=1
p(k)
ji

p(k0)
ij
â‰¤lim
nâ†’âˆ
1
n
n

k=1
p(k+k0)
jj

= 0.
Therefore, 1
n
n
k=1 p(k)
ji â†’0 âˆ€i, a contradiction since N
i=1 p(k)
ji = 1.
Exercise 5.66 Let

Xn

be a homogeneous Markov chain with a ï¬nite state-
space S and a regular transition matrix P = (pij). For j âˆˆS, let T jj âˆˆR be the

222
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
expected return time to j. Show that p(n)
ij â†’
1
T jj âˆ€i, j âˆˆS. Conclude that each
state is positive recurrent, T jj < +âˆâˆ€j âˆˆS.
Solution. Since P is regular, P has a unique sink w = (wj), i.e. p(n)
ij â†’wj,
âˆ€i, j âˆˆS, and, moreover, wj > 0 âˆ€j, cf. Theorem 5.54. Finally, Theorem 5.61
yields wj =
1
T jj .
Exercise 5.67 Prove the following: let A be a N Ã— N complex matrix. For any
i = 1, . . . N set xi := Ai
i, ri := 
jÌ¸=i |Ai
j| and let Bi be the closed ball Bi :=

z âˆˆC | |z âˆ’xi| â‰¤ri

. Then the eigenvalues of A are contained in ,
i=1,...,N Bi.
Solution. Let Î» be an eigenvalue of A and let z = (z1, . . . , zN) be an eigen-
vector of Î», Az = Î»z. Let h = h(Î») be such that |zh| = maxi |zi|. Then
|Î» âˆ’xh| |zh| = |(Az)h âˆ’Ah
hzh| = |

jÌ¸=h
Ah
jzj|
â‰¤
 
jÌ¸=h
|Ah
j|

max
i
|zi| â‰¤rh|zh|.
Therefore |Î» âˆ’xh| â‰¤rh, i.e. Î» âˆˆBh.
5.6
Ergodic property
Let

Xn

be a homogeneous Markov chain whose state-space S is either ï¬nite
or denumerable. Assume its transition matrix P is irreducible. Let T jj be the
expected return time to state j and let V (n)
j
(x) be the number of visits in j
made by the path x in the ï¬rst n steps. Roughly speaking, the ergodic theorem
says that in the long run the frequency of the visits in state j converges almost
surely to
1
T jj ,
V (n)
j
(x)
n
âˆ’â†’
1
T jj
P-almost surely.
5.6.1
Number of steps between consecutive visits
Let

Xn

be a homogeneous Markov chain on a probability space (, E, P)
with a ï¬nite or denumerable state-space S and let j âˆˆS. Closely related to
the sequence of passage times

T (r)
j

r in j are the random variables

S(r)
j (x)

r = 1, . . . , where S(1)
j
= T (1)
j
= tj and, for r â‰¥2,
S(r)
j (x) :=

T (r)
j
(x) âˆ’T (râˆ’1)
j
(x)
if T (râˆ’1)
j
(x) < +âˆ,
0
otherwise.
S(r)
j (x) counts the number of steps between the (r âˆ’1)th visit and the rth visit
in j.

DISCRETE TIME MARKOV CHAINS
223
Theorem
5.68
Let
j âˆˆS
be
a
recurrent
state
and
let
i â†’j.
Set
i :=

x | X0(x) = i

. Assume P(i) > 0 and let Pi(A) := P(A | X0 = i). Then:
(i) S(r)
j (x) â‰¥1 for almost any x âˆˆi and for all r â‰¥1.
(ii)

S(r)
j

r is a sequence of independent random variables with respect to Pi.
(iii) The variables S(r)
j , r â‰¥2, are identically distributed with respect to the
probability measure Pi and, for every n â‰¥1 and r â‰¥2,
Pi(S(r)
j
= n) = f (n)
jj
and
Ei[S(r)
j ] = T jj.
Proof. (i) Since j is recurrent and i â†’j, paths from i visit j inï¬nitely many
times almost surely, see Proposition 5.30. Therefore, for any r â‰¥2, T (r)
j (x) <
+âˆfor a.e. x âˆˆi. In particular, 1 â‰¤S(r)
j (x) < +âˆfor almost every x âˆˆi.
(ii) Let r â‰¥2, T := T (râˆ’1)
j
, h1, . . . , hrâˆ’1 â‰¥1, h = (h1, . . . , hrâˆ’1) âˆˆNrâˆ’1,
r â‰¥1 and set
Hh :=

S(râˆ’1)
j
= hrâˆ’1, S(râˆ’2)
j
= hrâˆ’2, . . . , S(1)
j
= h1

.
Observe that:
â€¢ The events

x âˆˆi | S(r)
j (x) â‰¥1

are detected by the random variables
XT +1, XT +2, . . . .
â€¢ The event Hh is generated by the random variables X0, . . . , Xk where
k := h1 + Â· Â· Â· + hrâˆ’1 â‰¤T , and Hh âŠ‚

Xk = j

.
â€¢ T is a stopping time and T (x) < âˆfor a.e. x âˆˆi, that is, Pi-almost
surely.
Then the strong Markov property, Theorem 5.11, gives
Pi

S(r)
j
= n
 Hh

= Pi

S(r)
j
= n


Xk = j

âˆ©Hh âˆ©{T < âˆ}

= Pi

S(r)
j
= n
 T < âˆ, Xk = j

= P

S(r)
j
= n
 T < +âˆ, Xk = j

= P

S(1)
j
= n
 X0 = j

= f (n)
jj .
(5.70)
Therefore we conclude that the events detected by S(r)
j
are independent of h,
that is, independent of the events detected by S(râˆ’1)
j
, . . . , S(1)
j , if Pi(Hh) > 0.
Thus, S(r)
j
is independent of S(râˆ’1)
j
, . . . , S(1)
j , and, since r is arbitrary,

S(r)
j

is
a sequence of independent random variables with respect to Pi.

224
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
(iii) From (5.70), we get for r â‰¥2 and n â‰¥1
Pi(S(r)
j
= n) =

h
Pi

S(r)
j
= n
 Hh

Pi(Hh) = f (n)
jj

hâˆˆRrâˆ’1
Pi(Hh) = f (n)
jj ,
hence
Ei[S(r)
j ] =
âˆ

k=0
kPi(S(r)
j
= k) =
âˆ

k=1
kf (k)
jj = T jj.
5.6.2
Ergodic theorem
Let

Xn

be a homogeneous Markov chain on (, E, P) with a ï¬nite or denu-
merable state-space S and let j âˆˆS. Set
wj :=
1
T jj
where
T jj
is
the
expected
return
time
to
j.
For
any
i âˆˆS,
set
i :=

x âˆˆ | X0(x) = i

. If P(i) > 0, let Pi be the probability measure
deï¬ned by Pi(A) := P(A | i).
Proposition 5.69 The following hold:
(i) Assume i â†’j. Then the frequency of visits in the ï¬rst n steps,
V (n)
j
(x)
n
,
converges to wj for a.e. x âˆˆi, that is
Pi
V (n)
j
(x)
n
â†’wj

= 1.
(5.71)
(ii) For every i, j âˆˆS we have
1
n
n

k=1
p(k)
ij â†’fijwj.
(5.72)
Proof. (i) If j is transient, then wj = 0 by (5.35) and paths from i visit j a
ï¬nite number of times almost surely, see Proposition 5.37. Therefore
V (n)
j
(x)
n
â‰¤
Vj(x)
n
â†’0 = wj
P-almost surely.
If j âˆˆS is recurrent and i â†’j, then the random variables S(r)
j , r â‰¥2, are
independent and identically distributed with respect to Pi and Ei[S(r)
j ] = T jj âˆˆ
R+, see Theorem 5.68. Moreover,
V (n)
j
(x) = sup

k

k

r=2
S(r)
j (x) â‰¤n
>

DISCRETE TIME MARKOV CHAINS
225
almost surely. Thus, a consequence of the strong law of large numbers, Proposi-
tion 4.93, yields
Pi
?
V (n)
j
(x)
n
â†’wj
@
= 1.
(ii) Since
V (n)
j
(x)
n
â‰¤1 from (5.71) with i = j we get
*
j

V (n)
j
n
âˆ’wj
 P(dx) â†’0,
by the dominated convergence theorem, see Theorem B.54, hence by (5.30),
1
n
n

k=1
p(k)
jj = Ej
4
V (n)
j
n
5
â†’wj.
The conclusion (5.72) then follows from Lemma 5.60.
Theorem 5.70 (Ergodic theorem) Let

Xn

be a homogeneous Markov chain
with a ï¬nite or denumerable state-space and with an irreducible transition matrix
P. Then the following hold:
(i) For every state j âˆˆS we have
V (n)
j
(x)
n
â†’wj
P-almost surely.
(5.73)
(ii) Let Ï† : S â†’R be a function. Then
1
n
n

k=1
Ï†(Xk) â†’

jâˆˆS
Ï†(j)wj
P-almost surely.
(5.74)
Proof. (i) By (i) of Proposition 5.69
V (n)
j
(x)
n
â†’wj almost surely in i :=

x âˆˆ | X0(x) = i

for every i âˆˆS, hence
V (n)
j
(x)
n
â†’wj for P-a.e. x âˆˆ.
(ii) Set Ej,k :=

x | Xk(x) = j

. Trivially, V (n)
j
(x) = n
k=1 1Ek,j (x) and
Ï†(Xk(x)) =

jâˆˆS
Ï†(j)1Ej,k(x)
Therefore,
1
n
n

k=1
Ï†(Xk(x)) = 1
n
n

k=1
 
jâˆˆS
Ï†(j)1Ej,k(x)

=

jâˆˆS
Ï†(j)1
n
n

k=1
1Ej,k(x) =

jâˆˆS
Ï†(j)
V (n)
j
(x)
n
,

226
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
hence, by the dominated convergence theorem, Example B.56, and (5.73) one
concludes
lim
nâ†’âˆ
1
n
n

k=1
Ï†(Xk(x)) = lim
nâ†’âˆ

jâˆˆS
Ï†(j)
V (n)
j
(x)
n
=

jâˆˆS
Ï†(j)

lim
nâ†’âˆ
V (n)
j
(x)
n

=

jâˆˆS
Ï†(j)wj
P-almost surely.
Notice that in the previous computation the sum and the limit order can be
interchanged also if S is denumerable; in fact, since Ï† is bounded and V (n)
j
/n â‰¤1,
one can apply Lebesgue dominated convergence theorem, see Example B.56.
5.6.3
Powers of irreducible stochastic matrices
Let

Xn

be a homogeneous Markov chain with a ï¬nite or denumerable state-
space and an irreducible transition matrix P. Then from (5.72)
1
n
n

k=1
p(k)
ij â†’wj
âˆ€i, j âˆˆS
(5.75)
since fij = 1 âˆ€i, j âˆˆS.
Equation (5.75) allows the conclusions of Theorem 5.61 and Exercise 5.66
to be extended to irreducible matrices. We have the following.
Theorem 5.71 Let

Xn

be a homogeneous Markov chain with a ï¬nite or denu-
merable state-space S and an irreducible transition matrix P. For every j âˆˆS,
let wj :=
1
T jj . Then the following hold:
(i) The vector w = (wj)jâˆˆS is such that w = wP. Moreover, if z := (zi)iâˆˆS is
such that 
iâˆˆS |zi| < +âˆand z = zP, then z = Î»w for some Î» > 0.
(ii) Assume the state-space S is ï¬nite. Then w = (wj) is a stochastic vector,
w âˆˆT , hence the unique stochastic vector such that z = zP. Moreover,
all the components of w are nonzero, equivalently, every state is positive
recurrent.
Proof. (i) From the Beppo Levi theorem and (5.75), we have, for any j âˆˆS,
(wP)j =

â„“âˆˆS
wâ„“pâ„“j =

â„“âˆˆS

lim
nâ†’âˆ
1
n
n

k=0
p(k)
iâ„“

pâ„“j
= lim
nâ†’âˆ
1
n
n

k=0

â„“âˆˆS
p(k)
iâ„“pâ„“j = lim
nâ†’âˆ
1
n
n+1

k=1
p(k)
ij = wj.

DISCRETE TIME MARKOV CHAINS
227
Let z = (zi) with 
iâˆˆS |zi| < âˆ. and z = zP. Then z = zP = (zP)P = zP2,
and, by an induction argument, z = zPk for any k, i.e. zj := 
iâˆˆS zip(k)
ij for any
j and for any k. Therefore,
zj = 1
n
n

k=1

iâˆˆS
zip(k)
ij =

iâˆˆS
zi
1
n
n

k=1
p(k)
ij

.
Since 1
n
n
k=1 p(k)
ij â‰¤1 and 
iâˆˆS |zi| < +âˆ, one can apply the dominated con-
vergence theorem, see Example B.56. Thus, taking into account also (5.75), as
n â†’âˆone gets
zj = lim
nâ†’âˆ

iâˆˆS
zi
1
n
n

k=1
p(k)
ij

=

iâˆˆS
zi

lim
nâ†’âˆ
1
n
n

k=1
p(k)
ij ) =
 
iâˆˆS
zi

wj
i.e. z = Î»w, Î» := 
iâˆˆS zi âˆˆR.
(ii) If S is ï¬nite, S = {1, . . . , N}, then
N

j=1
wj =

jâˆˆS

lim
nâ†’âˆ
1
n
n

k=1
p(k)
ij

= lim
nâ†’âˆ
1
n

jâˆˆS

n

k=1
p(k)
ij

= lim
nâ†’âˆ
1
n
n

k=1
 
jâˆˆS
p(k)
ij

= lim
nâ†’âˆ
1
n
n

k=1
1 = 1.
i.e. w is a stochastic vector. Finally, the components of w are nonzero by
Exercise 5.65.
Remark 5.72 We point out that in the second part of the ergodic theorem,
Theorem 5.71, the assumption that S if ï¬nite cannot be dropped: consider the
unlimited one-dimensional random walk whose transition matrix is P = (pij)
where pij = 1/2 if |j âˆ’i| = 1 and zero otherwise. In this case the matrix is
clearly irreducible, and for every i, j âˆˆZ, (Pn)i
j â†’0 as n â†’âˆsince as n
goes to inï¬nity, more and more states are visited. What fails in extending the
proof we have given when S is ï¬nite, is that if S is not ï¬nite, then we cannot
exchange the limits:
lim
nâ†’âˆ
1
n
n

k=1

jâˆˆS
p(k)
ij Ì¸=

jâˆˆS
lim
nâ†’âˆ
1
n
n

k=1
p(k)
ij .
Finally, we observe that (5.75) and, consequently, Theorem 5.71 can also
be proven without taking advantage of the ergodic property of the chain, see
Theorem 5.81.

228
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
5.6.4
Markov chain Monte Carlo
In many applications one needs to evaluate the weighted sum of a certain quantity
f : S â†’R deï¬ned on a ï¬nite set S
E := 1
z

jâˆˆS
f (j)Ï€j,
z :=

jâˆˆS
Ï€j
(5.76)
with respect to the weight Ï€ = (Ï€j). With the language of probability, denoting
by Î¼ the probability measure on S with point mass density given by 1
z(Ï€j)jâˆˆS,
we want to evaluate
E :=
*
S
f (t)Î¼(dt).
(5.77)
If the set S is small, then it is easy to compute E straightforwardly. If S is a
large set (say |E| = (50)!), then the computation of E or even just of the total
mass z cannot be performed directly, so that some strategy has to be devised in
order to compute or at least approximate E.
5.6.4.1
Monte Carlo
One such strategy is the Monte Carlo method, see Section 4.4.5. In practice,
one has to specify a probability space (, E, P) and a random variable X :
 â†’S such that PX = Î¼; then one considers the Bernoulli scheme of -valued
sequences (âˆ, Eâˆ, Pâˆ) and the random variables Xn : âˆâ†’R deï¬ned for
n = 1, 2, . . . , by Xn(x) := X(xn) if x =

xn

âˆˆâˆ. Such random variables are
independent and equidistributed as X, see Proposition 4.87. The strong law of
large numbers says that, for almost any sequence of points x =

xk

, xk âˆˆ,
1
n
n

j=1
f (X(xj)) = 1
n
n

j=1
f (Xj(x)) â†’E
(5.78)
and the weak estimate (4.9) holds.
In order to obtain an algorithm from the strong law of large numbers, we
must face two issues:
(i) How to choose (as efï¬ciently as possible) the probability space (, E, P)
and the random variable X :  â†’S such that PX = Î¼.
(ii) Since the limit in (5.78) holds for almost any sequence

xk

âˆˆâˆ(and
not for every sequence), we must be sure to pick up a â€˜goodâ€™ sequence.
The â€˜riskâ€™ to pick up a â€˜badâ€™ sequence is zero, but, nevertheless, it cannot
be completely neglected.
If some sort of regularity (or pattern) appears in the sequence, then it
may inï¬‚uence the value of the limit or even its existence. For example,
assume we are ï¬‚ipping a fair coin an inï¬nite number of times. If we get
a success (head) at every ï¬‚ipping or every three ï¬‚ippings, then, in either

DISCRETE TIME MARKOV CHAINS
229
case, 1
n
n
k=1 Xk(x) = 1
x
n
k=1 X(xk) converges to 1 or 1/3 and not to the
expected value 1/2. We should be able to pick up a sequence that is as
â€˜irregularâ€™ or as â€˜randomâ€™ as possible.
There are several ways to get sequences or, better, large ï¬nite tuples of ran-
dom numbers uniformly distributed in the interval [0, 1]. We have to be cautious
with the terminology since these numbers are in fact integer multiples of a ï¬xed
small number. However, if f is not fastly oscillating and the approximation
needs not be too accurate, this would not be a problem. For instance, physi-
cal random number generators can be based on an essentially random atomic
or subatomic physical phenomenon whose unpredictability can be traced to the
laws of quantum mechanics. Potential sources include radioactive decay, ther-
mal noise and shot noise. With some conditioning they are suitable sources of
random samples that are uniformly distributed in [0, 1]. Also pseudo-random
number generators can be useful. They are deterministic algorithms that can
automatically create long runs of numbers with good random properties. They
actually output periodic sequences, although with a hopefully very long period,
so a complete â€˜randomlessâ€™ is out of the question. Also, correlations between
the outcomes, especially between far outcomes, or between groups of outcomes,
usually involve surprises and must be carefully checked. Nevertheless, software
libraries that contain pseudo-random generators with good and speciï¬ed statistic
properties are available. We do not enter into these aspects, which are or course
relevant in simulation, see e.g. [17], but which are out of the scope of proba-
bility. For the purpose of this discussion, we simply assume the availability of
generators of â€˜random sequencesâ€™ uniformly distributed in the interval [0, 1] and
such that grouping them in N-tuples yields a â€˜random sequence of N-tuplesâ€™
that are also uniformly distributed in Q = [0, 1]N. Thus, typical choices for
(, E, P) and X in computing E in (5.77) when Î¼ = LN are (Q, B(RN), LN)
and X(x) := x, respectively.
Integrating with respect to a nonuniform measure Î¼ is harder. We give a hint
in the scalar case. Assume we want to compute
E :=
* +âˆ
âˆ’âˆ
f (t) dÎ¼(t)
where f is a bounded and Borel-regular function and (B(R), Î¼) is a mea-
sure on R. In this case one takes ([0, 1], B(R), L1), considers the law F(t) :=
Î¼([âˆ’âˆ, t]) of Î¼ and deï¬nes X : [0, 1] â†’R by (3.10), i.e.
X(s) := min

t
 s â‰¤F(t)

.
(5.79)
Since F(t) is right-continuous, X(s) is left-continuous, hence Borel-measurable.
Moreover, {s âˆˆ[0, 1] | X(s) â‰¤t} = {s âˆˆ[0, 1] | 0 â‰¤s â‰¤F(t)} for every t âˆˆR
so that
L1(X â‰¤t) = L1([0, F(t)]) = F(t)
âˆ€t âˆˆR,

230
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
i.e. X follows Î¼. Therefore, for almost any sequence {xk} âŠ‚[0, 1] we get
1
n
n

k=1
f (X(xk)) â†’
* âˆ
âˆ’âˆ
f (t) Î¼(dt)
as n â†’âˆ.
The procedure described above cannot be implemented to evaluate (5.76) for
large sets S, since the computation of the law of Î¼ and of the random variable
X in (5.79) are of the same order of complexity as the direct computation of E.
When S can be seen as a product, S = S1 Ã— Â· Â· Â· Ã— SN and the measure Î¼ with
mass density 1
z(Ï€j) is a product,
Î¼ = Î¼1 Ã— Î¼2 Ã— Â· Â· Â· Ã— Î¼N
where each Î¼i is a measure on Si, we can factorize the computation of X.
For instance, if N = 2, we deï¬ne two random variables X : [0, 1] â†’S1 and
Y : [0, 1] â†’S2 following the distributions Î¼1 and Î¼2, respectively. Then
*
f (t, s)Î¼1(dt) Ã— Î¼2(dt) =
*  *
f (t, s)Î¼2(ds)

Î¼1(dt)
=
*  *
f (t, Y(y))P(dy)

Î¼1(dt) =
**
g(X(x), Y(y)) P Ã— P(dxdy),
so that the strong law of large numbers yields
1
n
n

k=1
f (X(xk), Y(yk)) â†’E
for almost any sequence

(xk, yk)

âˆˆ[0, 1]2.
5.6.4.2
Markov chain Monte Carlo
When Î¼ is not a product measure, one takes advantage of the ergodic property
of Markov chains and of the fact that arbitrary Markov chains can be run from
uniformly distributed random variables.
The paradigm we pursue in computing E in (5.76) is the following: given
the probability mass distribution w = (wj) âˆˆS, wj := 1
zÏ€j, we deï¬ne a homo-
geneous Markov chain on a probability space (, E, P) with state-space S and
such that w is a ï¬xed point for its transition matrix P, w = wP, i.e. Ï€ = Ï€P.
We have already proven, Theorem 5.14, that given a stochastic matrix P one
can always deï¬ne a homogeneous Markov chain whose transition matrix is P.
Thus, it sufï¬ces to deï¬ne a stochastic matrix P such that Ï€ is a ï¬xed point for P.
This is realized by the Hastingsâ€“Metropolis algorithm.
Let Q = (qij) be any stochastic matrix. For i, j âˆˆS, i Ì¸= j, let
pij := 1
Ï€i
min

Ï€iqij, Ï€jqji

,
(5.80)

DISCRETE TIME MARKOV CHAINS
231
so that 0 â‰¤pij â‰¤1 and 
jÌ¸=i pij â‰¤1. Deï¬ne P = (pij) as follows:
â€¢ if i Ì¸= j, then pij is deï¬ned by (5.80);
â€¢ if i = j, set pii = 1 âˆ’
jÌ¸=i pij;
so that P is a stochastic matrix. The matrix R = (rij), rij := min{Ï€iqij,
Ï€jqji} is symmetric, hence
Ï€ipij = Ï€jpji
âˆ€i, j âˆˆS
and
N

i=1
Ï€ipij =
N

i=1
Ï€jpji = Ï€j
âˆ€j âˆˆS
i.e. Ï€ = Ï€P.
With the Metropolis algorithm one chooses Q = (qij) as an irreducible and
symmetric matrix, so that if i Ì¸= j, then
pij = min

1,
Ï€j
Ï€i
$
qij,
hence P = (pij) where
pij =
â§
âªâªâªâ¨
âªâªâªâ©
qij
if Ï€j â‰¥Ï€i,
Ï€j
Ï€i
qij
if Ï€j < Ï€i,
1 âˆ’
jÌ¸=i pij
if i = j.
(5.81)
Possible choices for Q are
qij =

1/(N âˆ’1)
if i Ì¸= j,
0
if i = j,
where N = |S|, or, for instance, Q can be chosen as the matrix associated with
a symmetric circular random walk. Notice that, in general, in order to deï¬ne P
one does not need to know the total mass z or the cardinality N of S.
Now, let

Xn

be a homogeneous Markov chain whose transition matrix is P,
see Theorem 5.14. If P is irreducible, then 1
zÏ€ is the only stochastic vector which
is also a ï¬xed point of P(x) = xP. Moreover, for any j âˆˆS the number ( 1
zÏ€j)âˆ’1
is the return time in j for

Xn

, see Theorem 5.71. The ergodic theorem, (ii) of
Theorem 5.70, gives the convergence
1
n
n

k=1
f (Xk(x)) â†’1
z

jâˆˆS
f (j)Ï€j
for almost any x âˆˆ.

232
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
In order to simulate the chain, one only needs to have a large number
of independent variables that follow the uniform distribution in [0, 1], see
Theorem 5.14, so that, this procedure, known as a Markov chain Monte Carlo
procedure, may eventually lead to numerical algorithms for the approximate
computation of E, see e.g. [18].
The simulation of a Markov chain with transition matrix P is just the transition
from a position i âˆˆS at step n to a new position j at step (n + 1) following the
probability density (pij)j. In this case
pij = min

1,
Ï€j
Ï€i
$
qij.
Assume we are in state i at step n. We pick j âˆˆS according to the mass distri-
bution (qij)j. Then:
â€¢ if Ï€i â‰¤Ï€j we move to state j, Xn+1 = j;
â€¢ if Ï€i > Ï€j we play a Bernoulli trial of parameter p = Ï€i/Ï€j. Then we set
Xn+1 = j if we obtain a success and Xn+1 = i otherwise.
Two facts are crucial for numerical applications. First of all, there is the
irreducibility assumption on P, which can be achieved in many applications. The
second crucial point is the number of steps one needs to perform in order to
obtain an estimate of E which is as accurate as wished. We shall not deal with
these problems which involve both statistical and analytic estimates and are still
an open ï¬eld of research. We refer the reader to [18] and to the stimulating paper
[19] where further applications, such as optimization problems, of the Markov
chain Monte Carlo method, are investigated. Here, we only give the following
result, see [20].
Theorem 5.73 (Metropolis) If Ï€ is not constant and the matrix P deï¬ned in (5.81)
in the Metropolis algorithm is irreducible, then P is regular.
Proof.
We
prove
that
there
exists
h âˆˆS
such
that
phh > 0.
Let
C =

i | Ï€i = maxj Ï€j

.
Obviously,
C Ì¸= âˆ…
and,
by
assumption,
C Ì¸= S.
Thus, see Exercise 5.64, there exists h âˆˆC and k /âˆˆC such that qhk > 0 and
Ï€h > Ï€k. If i Ì¸= j, then pij â‰¤qij, and by deï¬nition of P
phh = 1 âˆ’

jÌ¸=h
phj = 1 âˆ’

jÌ¸=h,k
phj âˆ’phk
â‰¥1 âˆ’

jÌ¸=h,k
qhj âˆ’Ï€k
Ï€h
qhk = 1 âˆ’

jÌ¸=h
qhj + qhk

1 âˆ’Ï€k
Ï€h

= qhh + qhk

1 âˆ’Ï€k
Ï€h

> 0.
The claim thus follows from Exercise 5.64.

DISCRETE TIME MARKOV CHAINS
233
5.7
Renewal theorem
Let

Xn

be a homogeneous Markov chain with a ï¬nite or denumerable state-
space S and transition matrix P. In this section, we discuss the convergence of the
sequence {Pn} as n â†’âˆ. The results extend partially the results of Section 5.5:
there S was supposed ï¬nite and P regular.
5.7.1
Periodicity
Given two positive integers d and n, we say that d divides n and write d âŠ¥n
if n = kd for some positive integer k. If N is a ï¬nite or denumerable set of
positive integers, then the largest integer d â‰¥1 that divides any element of N
is called the greatest common divisor of N and is denoted by gcd(N). It can
be easily proven that if N is inï¬nite and d = gcd(N), then there exists a ï¬nite
subset M âŠ‚N such that d = gcd(M).
Deï¬nition 5.74 Let P = (pij) be a stochastic matrix with a ï¬nite or denumerable
set S of indices. The number
dj := gcd

n
 p(n)
jj > 0

is called the period of the state j. If dj = 1, then the state j is said to be aperiodic,
while if dj = d â‰¥2, then j is said to be d-periodic.
By Deï¬nition 5.74, if dj is d-periodic, then p(k)
jj = 0 whenever k is not a mul-
tiple of d. Notice that it is not excluded that p(k)
jj = 0 for some k such that
d âŠ¥k.
Exercise 5.75 Prove the following:
(i) If P = Id, then Pn = Id âˆ€n, so that all the states are aperiodic.
(ii) If P is irreducible and all its rows coincide, then Pn = P for every n and
all the states are aperiodic.
(iii) If P =

0
1
1
0

, then Pn =

Id
if n is even,
P
if n is odd. Both the states 1 and 2 have
period 2. Moreover, the limit of Pn as n â†’âˆdoes not exist.
Proposition 5.76 If two states i are j are communicating, i â†”j, then they have
the same period. Thus, the period of an irreducible stochastic matrix is well deï¬ned
as the period of any of its states.
Proof.
Let
Ni =

k | p(k)
ii > 0

,
Nj =

k | p(k)
jj > 0

,
di = gcd(Ni)
and
dj = gcd(Nj).
Let
h, k
be
such
that
p(h)
ij > 0
and
p(k)
ji > 0.
Then
p(h+k)
ii
= N
â„“=1 p(h)
iâ„“p(k)
â„“i â‰¥p(h)
ij p(k)
ji > 0, i.e. h + k âˆˆNi, so that di âŠ¥(h + k).

234
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
For
each
n âˆˆNj
we
also
have
p(h+k+n)
ii
â‰¥p(h)
ij p(n)
jj p(k)
ji > 0.
Therefore,
h + k + n âˆˆNi, hence di âŠ¥(h + k + n). Thus di âŠ¥n âˆ€n âˆˆNj, so that di â‰¤dj.
Interchanging i and j, the previous argument gives also dj â‰¤di, hence di = dj.
Proposition 5.77 Let

Xn

be a homogeneous Markov chain with a ï¬nite or
denumerable state-space S and transition matrix P = (pij). Let j âˆˆS be a state,
let f (k)
jj
be the probability that a path from j visits j for the ï¬rst time at step k
and denote by dj â‰¥1 the period of j. Then
gcd

k â‰¥1
 f (k)
jj > 0

= dj.
Proof. Let us denote pk := p(k)
jj , fk := f (k)
jj
and let P :=

k | pk > 0

and
F :=

k | fk > 0

. It sufï¬ces to show that d âŠ¥k âˆ€k âˆˆP if and only if d âŠ¥k
âˆ€k âˆˆF.
Assume d divides any h âˆˆP. Let k âˆˆF. Since, see Proposition 5.58,
pk = fk + fkâˆ’1p1 + Â· Â· Â· + f1pkâˆ’1
(5.82)
we get pk â‰¥fk > 0 so that k âˆˆP and d âŠ¥k.
Assume d divides any h âˆˆF. We show, with an induction argument on k,
that d divides any h âˆˆP such that h â‰¤k.
If k = 1, the claim is obviously true since p1 = f1 > 0. Assume the claim
holds true for k âˆ’1. Let k be such that pk > 0. Two cases may occur. Either
fk > 0, so that d âŠ¥k, or fk = 0. In the latter case (5.82) implies
fkâˆ’1p1 + Â· Â· Â· + f1pkâˆ’1 = pk > 0
so that at least one addendum must be positive: there exists kâ€² < k such that
pkâ€² > 0 and fkâˆ’kâ€² > 0. Since kâ€² < k, d âŠ¥kâ€² and d âŠ¥(k âˆ’kâ€²), so that d âŠ¥k.
5.7.2
Renewal theorem
Theorem 5.78 (ErdÂ¨osâ€“Fellerâ€“Pollard) Let

fn

, n â‰¥1, and

pn

, n â‰¥0, be
two non-negative sequences such that p0 = 1 and âˆ
n=1 fn = 1. Assume
pn =
n

j=1
fjpnâˆ’j
âˆ€n â‰¥1.
(5.83)
Let
T := âˆ
j=1 jfj
(T = +âˆ
is
allowed)
and
S :=

n | fn > 0

.
If
gcd(S) = 1, then
lim
nâ†’+âˆpn = 1
T
(0 if T = +âˆ).
Lemma 5.79 Let a1, . . . , ar be relatively prime integers. Then there exists n0 such
that any integer n â‰¥n0 is a linear combination of a1, . . . , ar with non-negative
coefï¬cients.

DISCRETE TIME MARKOV CHAINS
235
Proof. Since gcd(a1, . . . , ar) = 1, the Bezout identity holds: namely, there
exist Î²1, . . . , Î²r âˆˆZ such that r
i=1 Î²iai = 1. Let a := r
i=1 ai. Divide n by a,
n = qa + s with 0 â‰¤s < a, so that
n = q
r

i=1
ai + s
r

i=1
Î²iai =
r

i=1
(q + Î²is)ai.
The right-hand side of the previous equality is a linear combination of a1, . . . , ar
with positive coefï¬cients if n is such that q â‰¥a maxi(|Î²i|).
Lemma 5.80 Let

fj

, j â‰¥1, be a non-negative sequence such that âˆ
j=1 fj = 1,
and set S :=

j
 fj > 0

. Let a âˆˆR and let

qn

, n âˆˆZ, be a sequence such that
â§
âªâ¨
âªâ©
qn = âˆ
j=1 fjqnâˆ’j
âˆ€n âˆˆZ,
q0 = a,
qn â‰¤a
âˆ€n â‰¤0.
(5.84)
If gcd(S) = 1, then qn = a âˆ€n. The same holds if the assumption qn â‰¤a âˆ€n â‰¤0
in (5.84) is replaced by qn â‰¥a âˆ€n â‰¤0.
Proof. Up to a change of sign of

qn

we may assume qn â‰¤a âˆ€n â‰¤0. System
(5.84) gives
a = q0 =
âˆ

j=1
fjqâˆ’j â‰¤a
âˆ

j=1
fj = a.
Thus âˆ
j=1 fj(a âˆ’qâˆ’j) = 0 so that qâˆ’n = a whenever fn > 0, i.e. for any n âˆˆS.
For any n âˆˆS, (5.84) gives
a = qâˆ’n =
âˆ

j=1
fjqâˆ’nâˆ’j â‰¤a
âˆ

j=1
fj = a
so that âˆ
j=1 fj(a âˆ’qâˆ’nâˆ’j) = 0, i.e. qâˆ’nâˆ’m = a if both n, m âˆˆS. With an
induction argument, one can now show that qâˆ’Î±nâˆ’Î²m = 0 for any positive inte-
gers Î±, Î², and then that qâˆ’n = 0 for any integer n which is a linear combination
with positive coefï¬cients of integers in S.
Since gcd(S) = 1, there exist a1, . . . , ar âˆˆS such that gcd(a1, . . . , ar) = 1
so that by Lemma 5.79 each integer n â‰¥n0 is a linear combination of integers
in S with positive coefï¬cients. Therefore, we conclude that
qâˆ’n = a
âˆ€n â‰¥n0.
It is now easy to check by an induction argument that qâˆ’n0+1, qâˆ’n0+2, Â· Â· Â· = a.
In fact, if qn = a âˆ€n â‰¤h, then (5.84) reads
qh+1 =
âˆ

j=1
fjqh+1âˆ’j = a
âˆ

j=1
fj = a.

236
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Proof of Theorem 5.78. Step 1. Let a âˆˆR and let

hn

be a sequence such
that phn â†’a. We show that there exist a sequence

qj

jâˆˆZ and a subsequence

kn

of

hn

such that
pknâˆ’j â†’qj
for any j
(5.85)
and

qn = âˆ
j=1 fjqnâˆ’j
âˆ€n âˆˆZ,
q0 = a.
(5.86)
Let an,j := pnâˆ’j. For any integer j, the subsequence

an,j

n is bounded, hence,
by compactness, there exist a number qj and a subsequence k(j)
n
such that
ak(j)
n ,j â†’qj as n â†’âˆ. Iterating the procedure for j = 0, Â±1, Â±2, . . . , we may
assume that

k(âˆ’j)
n

=

k(j)
n

and that

k(j+1)
n

is a subsequence of

k(j)
n

. Let
kn := k(n)
n . Then, for every ï¬xed j and nj large enough, the sequence

kn

nâ‰¥nj
is a subsequence of

k(j)
n

so that akn,j â†’qj. Thus the limit (5.85) holds.
Let us now prove (5.86). Equation (5.83) reads
pknâˆ’h =
knâˆ’h

j=1
fjpknâˆ’hâˆ’j.
Since
â€¢ fjpknâˆ’hâˆ’j â†’fjqhâˆ’j as n â†’âˆfor any j,
â€¢ supn(fjpknâˆ’hâˆ’j) â‰¤fj for any j and âˆ
j=1 fj = 1,
applying the dominated convergence theorem, see Example B.56, we get
qh =
âˆ

j=1
fjqhâˆ’j
âˆ€h âˆˆZ,
i.e. (5.86) holds since q0 = a.
Step 2. Let a = lim supn pn and let

hn

be a sequence such that phn â†’a.
Let

kn

and

qj

as in Step 1. Then pknâˆ’j â†’qj so that qj â‰¤a âˆ€j. Since

qj

satisï¬es system (5.86), applying Lemma 5.80 we get qj = a âˆ€j âˆˆZ, thus
obtaining
lim
nâ†’âˆpknâˆ’j = a
âˆ€j âˆˆZ.
Step 3. Summing up (5.83) for 1, 2, . . . , N, we get
N

n=1
pn =
N

n=1
n

j=1
fjpnâˆ’j =
N

n=1
 nâˆ’1

j=0
fnâˆ’jpj

,
(5.87)

DISCRETE TIME MARKOV CHAINS
237
or, equivalently,
pN +
Nâˆ’1

j=1

1 âˆ’
Nâˆ’j

i=1
fi

pj =
N

j=1
fj.
(5.88)
For any j â‰¥1, let Tj := âˆ
i=j fi. Then T1 = âˆ
i=1 fi = 1 and âˆ
j=1 Tj =
âˆ
k=1 kfk = T . Equation (5.88) can equivalently be written as
pNT1 +
Nâˆ’1

j=1

1 âˆ’
Nâˆ’j

i=1
fi

pj =
N

j=1
fj,
or as
N

j=1
TjpN+1âˆ’j =
N

j=1
fj,
(5.89)
see (5.64), (5.65) and (5.66). Consider now the double index sequence
Ï•N(j) :=

TjpN+1âˆ’j
if 1 â‰¤j â‰¤N,
0
if j > N.
Equation (5.89) or (5.87) thus reads
âˆ

j=1
Ï•N(j) =
N

j=1
fj.
(5.90)
Since Ï•knâˆ’1(j) â†’Tjqj = aTj by Step 2, we get the following:
â€¢ If T = +âˆ, then Step 2, (5.90) and the Fatou lemma yield
T a =
 âˆ

j=1
Tj

a =
âˆ

j=1
lim
nâ†’âˆÏ•knâˆ’1(j) â‰¤lim inf
nâ†’âˆ
âˆ

j=1
Ï•knâˆ’1(j)
= lim inf
nâ†’âˆ
knâˆ’1

j=1
fj =
âˆ

j=1
fj = 1,
so that a = 0, i.e. lim supn pn = 0. Thus the claim is proven whenever
T = +âˆ.
â€¢ If T < âˆ, then Step 2, (5.90) and the dominated convergence theorem,
see Example B.56, yield
T a =
 âˆ

j=1
Tj

a =
âˆ

j=0
lim
nâ†’âˆÏ•knâˆ’1(j) = lim
nâ†’âˆ
âˆ

j=1
Ï•knâˆ’1(j)
= lim inf
nâ†’âˆ
knâˆ’1

j=1
fj =
âˆ

j=1
fj = 1,

238
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
so that lim supn pn = a = 1/T .
Since we may repeat Step 2 for any sequence hn such that phn â†’b :=
lim infn pn, from the above we also get lim infn pn = 1/T , thus concluding
that pn â†’1/T .
The renewal theorem has important consequences.
Theorem 5.81 Let

Xn

be a homogeneous Markov chain with a ï¬nite or denu-
merable space-state S and denote by P = (pij) its transition matrix. For j âˆˆS, let
T jj be the expected return time to j, wj :=
1
T jj and let d be the period of j. Then
p(nd)
jj
â†’dwj
and
1
n
n

k=1
p(k)
ij â†’fijwj
âˆ€i âˆˆS.
(5.91)
Proof. Step 1. Let us prove the ï¬rst limit of (5.91) when j is aperiodic, d = 1.
If j is a transient state, then wj = 1/T jj = 0, see (5.34) and âˆ
n=1 p(n)
jj <
âˆ. Therefore, p(n)
jj â†’0 = wj. If j is recurrent, let fk := f (k)
jj
and pk := p(k)
jj
so that fjj = âˆ
k=1 fk = 1. Thus, Proposition 5.77 gives gcd

k
 fk > 0

= 1.
Moreover, p0 = 1, pn = n
k=1 fkpnâˆ’k âˆ€n â‰¥1 by (5.61) and T jj = âˆ
k=1 kfk,
cf. (5.35). The renewal theorem, Theorem 5.78, gives p(n)
jj â†’wj.
Step 2. Let us prove the ï¬rst limit of (5.91) assuming j is d-periodic, d â‰¥2.
The sequence of random variables

Xkd

k is a homogeneous Markov chain
with state-space S and transition matrix )P := Pd. For this chain, j is aperiodic
since
)d = gcd

k
 p(kd)
jj
> 0

= 1
d gcd

kd
 p(kd)
jj
> 0

= d
d = 1.
Let )Tjj be the return time to j for the new chain and let )wj := 1/)Tjj. From
Step 1
p(nd)
jj
â†’)wj.
(5.92)
Denote by )
f (k)
ij
the probability that a path of the new chain from i visits j for
the ï¬rst time at step k. Trivially, )
f (k)
jj
is also the probability that the initial chain
visits j starting from j for the ï¬rst time at step kd, )
f (k)
jj = f (kd)
jj
. Moreover,
f (n)
jj
= 0 if n is not a multiple of d. Therefore,
)Tjj =
âˆ

k=1
k )
f (k)
jj = 1
d
âˆ

k=1
(kd)f (kd)
jj
= 1
d
âˆ

k=1
kf (k)
jj = 1
d T jj.
Therefore, (5.92) yields p(nd)
jj
â†’dwj.

DISCRETE TIME MARKOV CHAINS
239
Step 3. Let us prove that 1
n
n
k=1 p(k)
jj â†’wj. Since p(k)
jj = 0 if k is not a multiple
of d, by the Cesaro theorem,
1
n
n

k=1
p(k)
jj = 1
n
âŒŠn/dâŒ‹

k=1
p(kd)
jj
â†’1
d dwj = wj.
Step 4. The second limit in (5.91) then follows from Step 3 and (ii) of
Lemma 5.60.
Remark 5.82 The second limit in (5.91) is sufï¬cient to prove Theorem 5.71.
Thus we have another proof of Theorem 5.71 that does not mention the ergodic
property of Markov chains.
5.7.3
Exercises
Exercise 5.83 Let

Xn

be a homogeneous Markov chain with a ï¬nite state-space
S = {1, . . . , N} and irreducible transition matrix P. Let Mjj(n) be the expected
return time to j measured on a window of n steps, and let Njj be the expected
number of visits in j that paths starting from j do in the ï¬rst n steps. Compute
lim
nâ†’âˆ
Mjj(n)Njj(n)
n
.
Solution. By deï¬nition, Njj(n) = 1
nEj[V (n)
j
] = 1
n
n
k=1 p(k)
jj and
Mjj(n) = Ej[tj1{tj <n}] =
n

k=1
kf (k)
jj .
Therefore, since 1
n
n
k=1 p(k)
jj â†’
1
T j , we have
Mjj(n)Njj(n)
n
=

n

k=1
kf (k)
jj
1
n
n

k=1
p(k)
jj

â†’T jj
1
T jj
= 1.
Exercise 5.84 Let P = (pij) be the transition matrix of a Markov chain with ï¬nite
state-space S. Prove that P is irreducible and aperiodic if and only if P is regular.
Solution. Assume P is irreducibile and aperiodic. Then all the states are
pairwise communicating, aperiodic, and, since S is also a minimal closed class,
all states are recurrent, fij = 1 âˆ€i, j âˆˆS, see Proposition 5.40. Theorem 5.81
yields p(n)
jj â†’wj := 1/T jj and wj > 0 by Exercise 5.65. Moreover, Lemma
5.60 yields for any i and j âˆˆS
p(n)
ij â†’fijwj = wj > 0.
We then conclude that for n large enough, p(n)
ij > 0 âˆ€i, j âˆˆS.

240
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Conversely, if P is regular, then trivially P is irreducible. Moreover, for any
large enough n, all the entries of Pn are nonzero, see Theorem 5.54. P is therefore
aperiodic.
Exercise 5.85 Let P be a stochastic, irreducible matrix. Show that, if P is
d-periodic, d â‰¥2, then Pd is not irreducible.
Solution. Suppose, contrary to our claim, that Pd is irreducible. Since Pd is
aperiodic, then Pd is regular, see Exercise 5.84. Therefore P is regular, hence
aperiodic, again by Exercise 5.84, a contradiction, since d â‰¥2.
Exercise 5.86 Let P be a stochastic matrix and let i, j be two communicating
states. Show that either both i and j are positive recurrent or both are transient.
Solution. Assume j is positive recurrent. Then wj = 1/T jj > 0 and j is
recurrent fjj = 1. Let d be the period of j. We have p(nd)
jj
â†’dwj > 0, see
Theorem 5.81. Since i â†”j, i is d-periodic, see Proposition 5.76 and recur-
rent fii = 1, see Proposition 5.40. By Theorem 5.81 p(n)
ii
â†’wi, wi =
1
T ii . On
the other hand, there exist r, s > 0 such that p(r)
ij > 0 and p(s)
ji > 0. Therefore,
p(r+n+s)
ii
â‰¥p(r)
ij p(n)
jj p(s)
ji . Letting n â†’âˆ, we conclude that
wi â‰¥p(r)
ij wjjp(s)
ji > 0,
i.e. T ii < âˆ.

6
An introduction to continuous
time Markov chains
In this chapter, we give a very short introduction to continuous time Markov
chains. In Section 6.1 we discuss the Poisson process while in Section 6.2 we
consider homogeneous continuous time Markov chains with ï¬nite state-space and
right-continuous trajectories. The convergence to equilibrium of the transition
probabilities matrices and the description of the holding times are discussed.
6.1
Poisson process
We go back to Example 3.34 by giving an explicit example: the emission of clicks
of a Geiger counter. In this section we follow closely the presentation in [5].
Evidence shows the following features of the distribution of the number of
clicks produced by the counter:
(i) The number of clicks produced in pairwise disjoint time intervals are inde-
pendent.
(ii) The clicks are uniformly distributed with respect to time, i.e. the number of
clicks produced in the intervals [a + c, b + c] a, b, c â‰¥0 does not depend
on c.
(iii) In each time interval, the average number of clicks is ï¬nite,
(iv) At each moment, the Geiger counter produces at most one click.
When deï¬ning a model, the previous features can be formalized as follows.
Let I be the family of time intervals
I :=

I = [a, b]
 0 â‰¤a < b < +âˆ

.
A First Course in Probability and Markov Chains, First Edition. Giuseppe Modica and Laura Poggiolini.
Â© 2013 John Wiley & Sons, Ltd. Published 2013 by John Wiley & Sons, Ltd.

242
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Consider the Geiger counter as a probability space (, E, P) and, for any I âˆˆI,
let NI :  â†’N be the random variable on (, E, P) that counts the number of
clicks produced in the interval I. In terms of the family

NI

IâˆˆI, features (i),
(ii) and (iii) read:
(P1) NIâˆªJ = NI + NJ if I âˆ©J = âˆ…and I âˆªJ âˆˆI.
(P2) If J âŠ‚I is a family of pairwise disjoint intervals, then

NI

IâˆˆJ is a
family of independent random variables.
(P3) For any c > 0 and any I âˆˆI, NI and Nc+I follow the same distribution.
We recall that c + I := [c + a, c + b] if I = [a, b].
(P4) E
%
NI
&
< +âˆâˆ€I âˆˆI.
Properties (P1), (P2), (P3) and (P4) formalize properties (i), (ii) and (iii). We
must formulate (iv). Consider the event F âŠ‚ deï¬ned by the property â€˜Two or
more clicks are produced at a certain time t âˆˆ[0, 1]â€™. Then x âˆˆF if and only
if for any positive integer n there exists an interval Ik,n := [k/2n, (k + 1)/2n],
k = k(x, n) such that NIk,n(x) â‰¥2, i.e.
F :=
âˆ
'
n=1
2nâˆ’1
(
k=0

NIk,n â‰¥2

.
Consequently, the event E âŠ‚ deï¬ned by the property that two or more clicks
are produced at a certain time t âˆˆR+ is
E =
âˆ
(
q=0
(q + F).
and we can formalize feature (iv) as
(P5-1)
P(E) = 0
or
P(F) = 0.
Lemma 6.1 Let {NI, I âˆˆI} be a family of random variables satisfying (P1)â€“(P4).
Then P(E) = 0 if and only if
(P5)
lim supÏµâ†’0
P(N[0,Ïµ] â‰¥2)
Ïµ
= 0.
Proof. Using (P1), (P2) and (P3), we get
P(E) = lim
nâ†’âˆP
 2nâˆ’1
(
k=0

NIk,n â‰¥2

= 1 âˆ’lim
nâ†’âˆP
 2nâˆ’1
'
k=0

NIk,n â‰¤1

= 1 âˆ’lim
nâ†’âˆ
2nâˆ’1
=
k=0
P

NIk,n â‰¤1

= 1 âˆ’lim
nâ†’âˆ
2nâˆ’1
=
k=0

1 âˆ’P(NIk,n â‰¥2)


AN INTRODUCTION TO CONTINUOUS TIME MARKOV CHAINS
243
= 1 âˆ’lim
nâ†’âˆ

1 âˆ’P(NI0,n â‰¥2)
2n
.
Let f (t) := P(N{[0,t]} â‰¥2), t â‰¥0. By the above computation P(E) = 0 if and
only if
(1 âˆ’f (2âˆ’n))2n â†’1.
(6.1)
Let tn := 2âˆ’n then (1 âˆ’f (tn))1/tn â†’1 if and only if
log(1âˆ’f (tn))
tn
â†’0. Since
tn â†’0, (6.1) is equivalent to f (tn)/tn â†’0. Finally, for any Ïµ âˆˆ[0, 1], let n =
n(Ïµ) such that tnâˆ’1 â‰¤Ïµ < tn. Then
n(Ïµ) â†’+âˆ
and
f (Ïµ)
Ïµ
â‰¤f (tn)
tnâˆ’1
= 2f (tn)
tn
â†’0
as Ïµ â†’0.
By the above, (P5-1) is equivalent to (P5).
Deï¬nition 6.2 (Poisson process) A family

Nt

tâ‰¥0 of non-negative integer
valued random variables on a probability space (, E, P) is called a
Poisson process with intensity Î± if:
(i) N0(x) = 0 almost surely.
(ii) The map t â†’Nt(x) is increasing and right-continuous for a.e. x âˆˆ.
(iii) For any n and any list 0 = t0 < t1 < Â· Â· Â· < tn the random variables Ntk âˆ’
Ntkâˆ’1, k = 1, . . . , n, are pairwise independent.
(iv) For any t â‰¥s â‰¥0 the random variable Nt âˆ’Ns follows the Poisson dis-
tribution of parameter Î±(t âˆ’s), i.e.
P(Nt âˆ’Ns = k) = eâˆ’Î±(tâˆ’s) Î±k(t âˆ’s)k
k!
âˆ€k â‰¥0.
(6.2)
In particular, we point out that
P(Nt = k) = eâˆ’Î±t Î±ktk
k!
âˆ€k â‰¥0
so that
E
%
Nt
&
=
âˆ

k=0
eâˆ’Î±tk Î±ktk
k!
= Î± t.
Theorem 6.3 Let

NI

IâˆˆI be a family of random variables on the probability
space (, E, P) satisfying (P1)â€“(P5). Then the continuous family of random vari-
ables

Nt

tâ‰¥0, Nt := N[0,t], is a Poisson process with intensity Î± := E
%
N[0,1]
&
.
Conversely, let

Nt

tâ‰¥0 be a Poisson process of intensity Î± > 0 on (, E, P).
Then the family of random variables

NI

IâˆˆI deï¬ned by NI := Nt âˆ’Ns if I =
[s, t] satisï¬es properties (P1)â€“(P5) and E
%
N[0,1]
&
= Î±.
Proof. (i) Assume

NI

IâˆˆI satisï¬es (P1)â€“(P5). Obviously, (P1)â€“(P4) imply
that the process

Nt

, Nt = N[0,t] satisï¬es (i), (ii) and (iii) of Deï¬nition 6.2.

244
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Let Î±(t) := E
%
N[0,t]
&
, t > 0. By (P2) and (P3), Î±(t) is monotone increasing
and Î±(t + s) = Î±(t) + Î±(s). Thus, by Lemma 3.50, Î±(t) = Î± t, Î± := Î±(1).
In particular, E
%
Nt
&
= Î±t.
In order to prove that Nt follows the Poisson distribution of parameter Î±t,
we deï¬ne a sequence of Bernoulli processes that approximates Nt. Partition the
interval [0, t] in 2n pairwise intervals of equal length
Ik,n =
0(k âˆ’1)t
2n
, kt
2n
1
,
k = 1, . . . , 2n.
Let Xk,n(x) := NIk,n(x) and Xk,n(x) := 1{Xk,nâ‰¥1}(x) = 1[1,âˆ](Xk,n(x)). By (P2)
and (P3) the random variables

Xk,n

k are independent and identically distributed
and so are the random variables

Xk,n

k, see Proposition 4.36. More precisely, the
random variables
Xk,n

k are Bernoulli trials of parameter pn := P(Xk,n â‰¥1) =
P(N[0,2âˆ’n] â‰¥1). Therefore, the random variable Nn
t := 2n
k=1 Xk,n follows the
binomial distribution B(2n, pn). Let us now show that the random variables

Nn
t

approximate the random variable Nt. Clearly, Nn+1
t
â‰¥Nn
t , i.e.

Nn
t

n is a mono-
tone increasing sequence of random variables. Moreover, by (P5) and Lemma 6.1
P(Nn
t Ì¸= Nt) =
2n

k=1
P(Xk,n âˆ’Xk,n) =
2n

n=1
P(Xk,n â‰¥2)
= 2nP(N2âˆ’nt â‰¥2) â†’0,
i.e. Nn
t (x) â†‘Nt(x) almost surely. By the Beppo Levi theorem we then get
Î±t = E
%
Nt
&
= lim
nâ†’âˆE
%
Nn
t
&
= lim
nâ†’âˆ2npn,
and
P(Nn
t â‰¥k) â†’P(Nt â‰¥k)
âˆ€k âˆˆN.
Finally, we recall that limits of binomial distributions are Poisson distributions,
see Proposition 3.31. Thus, for any integer k,
P(Nt = k) = lim
nâ†’âˆP(Nn
t = k) = lim
nâ†’âˆB(2n, pn)({k}) = P(Î±t)({k}).
Conversely, assume

Nt

is a Poisson process with intensity Î±. Let I =
[s, t]. By properties (i) and (ii) of Poisson processes, the random variables NI :=
Nt âˆ’Ns are non-negative and (iii) of Deï¬nition 6.2 implies (P1). Moreover,
P(NI = k) = P(Nt âˆ’Ns = k) = P(Î±(t âˆ’s))({k}), so that also (P2) and (P3)
are satisï¬ed and E
%
NI
&
= Î±(t âˆ’s) < +âˆ, i.e. also (P4) holds. Finally, since
P(N[0,Ïµ] â‰¥2) = 1 âˆ’P(N[0,Ïµ] = 0) âˆ’P(N[0,Ïµ] = 1) = 1 âˆ’eâˆ’Î±Ïµ âˆ’Î±Ïµeâˆ’Î±Ïµ,
dividing by Ïµ and letting Ïµ â†’0, we get (P5). The claims are then proven.

AN INTRODUCTION TO CONTINUOUS TIME MARKOV CHAINS
245
If there is a click at time s > 0, then the probability that there is another click
before a further time, i.e. the probability that the time T (x) between two clicks or,
more formally, between two singularities of Nt(x) is smaller than t, is given by
P

T < t + s
 T â‰¥s

:= P(N[s,s+t[ = 0) = P(Nt+s âˆ’Ns = 0) = eâˆ’Î±t.
Thus:
(i) The waiting times between two consecutive clicks are independent.
(ii) The waiting times between two consecutive clicks are exponentially dis-
tributed, P(T < t + s | T â‰¥s) = eâˆ’Î±t.
The two properties (i) and (ii) above characterize Poisson processes. Let

Wk

be a sequence of positive random variables satisfying (i) and (ii). Let
Tn := n
k=1 Wk and let
Nt(x) := #

n
 Tn(x) â‰¤t

.

Nt

is an increasing family of random variables and, moreover, the map
t â†’Nt(x) is right-continuous. In fact, let tk â†“t. Then the sets Ek := {n |
Tn+1(x) > tk} is an increasing family of sets, Ek âŠ‚Ek+1 âˆ€k and E := âˆªkEk =

n | Tn+1(x) > t

. Thus, Nt(x) = inf E = limk(inf Ek) = limk Ntk(x) and

x âˆˆ
 Nt(x) = k

=

x âˆˆ
 Tk(x) â‰¤t < Tk+1(x)

.
Thus, each Nt, t â‰¥0, is a random variable and
P(Nt = k) = P(Tk â‰¤t < Tk+1) = P(t < Tk+1) âˆ’P(t < Tk)
= eâˆ’Î±t (Î±t)k
k! ,
see Exercise 4.65. Then one proves that

Nt(x)

is a Poisson process of
parameter Î±. We omit the proof as the proof of independence of the increments,
(iii) of Deï¬nition 6.2, is technical. We refer the interested reader to, e.g. [5].
Summarizing, we have the following.
Theorem 6.4 With the previous notation, the following are equivalent:
(i)

Nt

tâ‰¥0 is a Poisson process with intensity Î±.
(ii) The waiting time random variables

Wk

, that measure the time between
two consecutives jumps of Nt(x), are pairwise independent and identically
distributed with exponential distribution exp(Î±).

246
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
6.2
Continuous time Markov chains
6.2.1
Deï¬nitions
6.2.1.1
Transition probabilities matrix
A continuous time stochastic process is a one real parameter family

Xt

tâ‰¥0 of
random variables on a probability space (, E, P). We only consider stochastic
processes with a ï¬nite or denumerable state-space S.
For each s, t â‰¥0 and each i, j âˆˆS, let P(s, t) := (P(s, t)i
j) be the matrix
deï¬ned by
Pi
j(s, t) :=
â§
â¨
â©
P

Xt = j
 Xs = i

if P(Xs = i) > 0,
Î´i
j
if P(Xs = i) = 0.
We call the matrix P(s, t) the transition probabilities matrix from Xs to Xt.
Observe that P(s, t) is a stochastic matrix.
The law of total probability yields
P(Xt = j) =

iâˆˆS
P(Xs = i)P(s, t)i
j,
(6.3)
thus, denoting by Ï€(t) = (Ï€j(t)), Ï€j(t) := P(Xt = j), the mass density row vec-
tor of Xt, (6.3) reads equivalently as
Ï€(t) = Ï€(s)P(s, t).
(6.4)
Of course, Pi
j(t, t) = Î´i
j if P(Xt = i) > 0 so P(t, t) = Id âˆ€t â‰¥0.
Finally, by an induction argument, from (6.4) one gets for any n âˆˆN and any
0 â‰¤t0 â‰¤t1 â‰¤Â· Â· Â· â‰¤tn,
Ï€(tn) = Ï€(t0)P(t0, t1)P(t1, t2) Â· Â· Â· P(tnâˆ’1, tn).
6.2.1.2
Homogeneous processes
Deï¬nition 6.5 A continuous time stochastic process

Xt

tâ‰¥0 with values in a ï¬nite
or denumerable state-space S is called homogeneous if for any s, t, h â‰¥0 and
for any i, j âˆˆS
P

Xt+h = j
 Xs+h = i

= P

Xt = j
 Xs = i

.
For the transition probabilities matrices P(s, t) of the process we then have
P(s, t) = P(0, t âˆ’s)
âˆ€0 â‰¤s â‰¤t.
The map t â†’P(t) := P(0, t) is called the transition probabilities map of the
process.

AN INTRODUCTION TO CONTINUOUS TIME MARKOV CHAINS
247
6.2.1.3
Markovian processes
Deï¬nition 6.6 (Markov property) Let

Xt

tâ‰¥0 be a continuous time stochastic
process with a ï¬nite or denumerable state-space S. The process

Xt

tâ‰¥0 is called
Markovian if, for any positive integer n, for any 0 â‰¤t0 < t1 < Â· Â· Â· < tn, and any
i1, . . . , in âˆˆS we have
P

Xtn = in
 Xtnâˆ’1 = inâˆ’1, . . . , Xt0 = i0

= P

Xtn = in
 Xtnâˆ’1 = inâˆ’1

(6.5)
whenever P(Xtnâˆ’1 = inâˆ’1, . . . , Xt0 = i0) > 0.
With the same reasoning used for discrete time Markov chains, the process

Xt

tâ‰¥0 is Markovian if and only if for any 0 â‰¤r â‰¤s â‰¤n, for any 0 â‰¤t0 â‰¤t1 â‰¤
Â· Â· Â· â‰¤tn and any triplet of events G, F, E detected by Xt0, . . . , Xtr, Xtr+1, . . . , Xts
and Xts+1, . . . , Xtn, respectively, we have
P

E
 F âˆ©G

= P

E
 F

or
P

E âˆ©F
 G

= P

E
 F

P

F
 G

.
(6.6)
It is also still possible to compute the joint distribution of a ï¬nite number
of the random variables Xtâ€™s in terms of the transition matrices. Let k, n â‰¥0,
0 â‰¤t0 â‰¤t1 â‰¤Â· Â· Â· â‰¤tn+k. Denote
Ak :=

x âˆˆ
 Xtk = ik

.
By (6.6) one gets
P

An âˆ©Â· Â· Â· âˆ©A1
 A0

= P

An
 Anâˆ’1

P

Anâˆ’1 âˆ©Â· Â· Â· âˆ©A1
 A0

.
Thus, by induction,
P

An âˆ©Â· Â· Â· âˆ©A1
 A0

=
nâˆ’1
=
k=0
P

Ak+1
 Ak

i.e.
P

Xtn = in, . . . , Xt0 = i0

= P(Xt0 = i0)P(t0, t1)i0
i1 Â· Â· Â· P(tnâˆ’1, tn)inâˆ’1
in
.
(6.7)
Remark 6.7 Since the probabilities of the events detected by the Xtâ€™s are actually
deï¬ned by the value of the probabilities of ï¬nite intersections of the generat-
ing events, see Theorem B.6, property (6.5) or, equivalently, (6.6) impact on

248
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
the whole set of the events detected by the Xtâ€™s. As in the discrete case, the
Markov property says that the probabilistic prevision of the future state of the
chain depends on the past history only through its present state. Also, formula
(6.7) implies that the transiton matrices ï¬x, in principle, the probability of any
event detected by the random variables

Xt

. However, we must be careful,
since not every subset of  determined by the Xtâ€™s is an event, in general. For
instance, the set
E =

x âˆˆ
 XÏ„(x) = i âˆ€Ï„, r â‰¤Ï„ â‰¤s

needs not be an event, since E is the intersection of a non denumerable family
of events.
6.2.2
Continuous semigroups of stochastic matrices
6.2.2.1
Chapmanâ€“Kolmogorov equations
Proposition 6.8 Let

Xt

tâ‰¥0 be a Markovian stochastic process with ï¬nite or
denumerable state-space and transition probabilities matrix P(s, t). Then, the
Chapmanâ€“Kolmogorov equations hold

P(s, t) = P(s, Ï„)P(Ï„, t)
âˆ€s, Ï„, t such that 0 â‰¤s < Ï„ < t,
P(s, s) = Id
âˆ€s â‰¥0.
If the process is homogeneous and P(t) denotes the transition probabilities map
of the process, then the Chapmanâ€“Kolmogorov equations reduce to

P(t + s) = P(t)P(s)
âˆ€s, t â‰¥0,
P(0) = Id.
Proof. By the Markov property,
P(s, t)i
j = P

Xt = j
 Xs = i

=

hâˆˆS
P

Xt = j, XÏ„ = h
 Xs = i

=

hâˆˆS
P

Xt = j
 XÏ„ = h

P

XÏ„ = h
 Xs = i

=

hâˆˆS
P(Ï„, t)h
jP(s, Ï„)i
h = (P(s, Ï„)P(Ï„, t))i
j.
6.2.2.2
Right-continuous Markov processes
Examples show that no regularity can be expected for the transition probabil-
ities map (s, t) â†’P(s, t) of stochastic processes. However, for a subclass of
stochastic processes, the situation is better.

AN INTRODUCTION TO CONTINUOUS TIME MARKOV CHAINS
249
Deï¬nition 6.9 A stochastic process

Xt

tâ‰¥0 on (, E, P) is said to be right-
continuous if the trajectories t â†’Xt(x) are right-continuous for P-almost every
x âˆˆ.
Proposition 6.10 Let

Xt

tâ‰¥0 be a right-continuous stochastic process with a
ï¬nite state-space S. Then for any s â‰¥0
P(s, t) â†’Id
as t â†’s+.
In particular, the transition probabilities map of a homogeneous process t â†’P(t)
is continuous at 0,
P(t) â†’Id
as t â†’0+.
Proof. Let

tn

be such that tn â†“s. Observe that since the states are ï¬nite,
for any x âˆˆ the map t â†’Xt(x) is right-continuous at s if and only if there
exists n = n(x) such that Xtn(x) = i for any n â‰¥n. In other words, denoting by
E âŠ‚ the set of points x âˆˆ such that the map t â†’Xt(x) is right-continuous,
we have

x âˆˆE
 Xs(x) = i

=
âˆ
(
n=1
'
kâ‰¥n

x âˆˆ
 Xtk(x) = i

,
hence the events

x âˆˆ
 Xs(x) = i

and
âˆ
(
k=1
'
kâ‰¥n

x âˆˆ
 Xtk(x) = i

differ by a null set. Therefore, assuming P(Xs = i) > 0,
1 = P(s, s)i
i = P

Xs = i
 Xs = i

= lim
nâ†’âˆP
 '
kâ‰¥n

x âˆˆ | Xtk(x) = i
  Xs = i

â‰¤lim
nâ†’âˆP

Xtn = i
 Xs = i

= lim
nâ†’âˆP(s, tn)i
i.
Since obviously P(s, tn)i
i â‰¤1, we get P(s, tn)i
i â†’1. Thus, since the sequence

tn

is arbitrary, P(s, t)i
i â†’1 as t â†’s+. Furthermore, since for any i, j âˆˆS
with i Ì¸= j, we have
P(s, t)i
j = P

Xt = j
 Xs = i

â‰¤P

Xt Ì¸= i
 Xs = i

= 1 âˆ’P(s, t)i
i,
we also deduce that P(s, t)i
j â†’0 as t â†’s+.

250
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Remark 6.11 Let

Xt

tâ‰¥0 be a right-continuous stochastic process with ï¬nite
state-space S and let D be a denumerable dense set in R. Repeating the argument
in the proof of Proposition 6.10 one gets for every s âˆˆR+, for every i âˆˆS and
every sequence

tn

âŠ‚D such that tn â†“s, that

x âˆˆ
 Xs(x) = i

and
âˆ
(
k=1
'
kâ‰¥n

x âˆˆ
 Xtk(x) = i

differ by a null set. In particular, the generating events

x âˆˆ | Xs(x) = i

are
generated by the events detected by the random variables

Xs, s âˆˆD

. A similar
argument shows that any ï¬nite intersection of generating events is detected by
the random variables

Xs, s âˆˆD

. We then infer that the P-completions of the
Ïƒ-algebra of the events detected by all the Xtâ€™s and of the Ïƒ-algebra of the events
detected by the Xtâ€™s with t âˆˆD coincide, see Theorem B.6.
Deï¬nition 6.12 A homogeneous, Markovian and right-continuous stochastic pro-
cess

Xt

tâ‰¥0 is called a right-continuous Markov chain.
By combining Propositions 6.10 and 6.8 we get the following.
Theorem 6.13 Let

Xt

tâ‰¥0 be a right-continuous Markov chain with a ï¬nite state-
space S. Then the associated transition map t â†’P(t), t â‰¥0, is a continuous
semigroup, i.e.
â§
âªâ¨
âªâ©
P(t) â†’P(0)
as t â†’0+,
P(t + s) = P(t)P(s)
for every t, s â‰¥0,
P(0) = Id.
(6.8)
The theory of ordinary differential equations then applies. In particular,
Theorem C.10 yields the following.
Theorem 6.14 Let

Xt

tâ‰¥0 be a right-continuous Markov chain with transition
probabilites matrix P(t), t â‰¥0. Then P(t) is differentiable, and, if
Q := Pâ€²
+(0) := lim
tâ†’0+
P(t) âˆ’Id
t
,
(6.9)
then
P(t) = eQt =
âˆ

k=0
Qktk
k!
âˆ€t â‰¥0.
(6.10)
Actually, (6.8) are equivalent to (6.10). Also, it is well known that P(t) = eQt is
the unique solution of both the systems

Pâ€²(t) = QP(t),
P(0) = Id
and

Pâ€²(t) = P(t)Q,
P(0) = Id.

AN INTRODUCTION TO CONTINUOUS TIME MARKOV CHAINS
251
The matrix Q, which is the inï¬nitesimal generator of the semigroup P(t),
expresses the rate of change of P(t). We call Q the matrix of the intensity
factors or the intensities matrix of the (transition probabilities map of the) chain.
Example 6.15 At the initial stage 0 we wait for a random length of time that
follows the exponential distribution with intensity Î±, then we move to state 1.
There again, we wait for a random length of time that follows the same distri-
bution exp(Î±) then we move to the state 2 and so on. This is the description of
the Poisson process of parameter Î±, see Theorem 6.4. Its transition matrix and
its intensities matrix are
P(t) =
â›
âœâ
eâˆ’Î±t
1 âˆ’eâˆ’Î±t
0
. . .
0
eâˆ’Î±t
1 âˆ’eâˆ’Î±t
. . .
...
...
...
...
and
Q =
â›
âœâœâœâ
âˆ’Î±
Î±
0
0
. . .
0
âˆ’Î±
Î±
0
. . .
0
0
âˆ’Î±
Î±
. . .
...
...
...
...
...
.
Example 6.16 At the initial stage we are, for certain time in a state 1 and
move to states 2 and 3 after a random time following the distribution exp(2)
and exp(4), respectively. We move from state 2 to state 3 with a random time
following the distribution exp(5). Then the intensities matrix Q is
Q =
â›
â
âˆ’6
2
4
0
âˆ’5
5
0
0
0
â
â .
6.2.2.3
Q-matrices
Deï¬nition 6.17 A matrix Q âˆˆMN,N(R) is called a Q-matrix if
Qi
j â‰¥0
âˆ€i Ì¸= j,
N

j=1
Qi
j = 0
âˆ€i.
In particular, all the diagonal entries of Q are nonpositive, Qi
i â‰¤0, and
||Q||âˆ:=
max
i,j=1,...,N |Qi
j| =
max
i=1,...,N(âˆ’Qi
i).
Q-matrices provide an useful tool in order to deï¬ne stochastic matrices. Let
Q be a N Ã— N Q-matrix. For Î± â‰¥||Q||âˆdeï¬ne
R := RÎ± = Id + 1
Î± Q.

252
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
A trivial computation shows that R is stochastic. Moreover, since Q = Î±(R âˆ’Id),
we get
P(t) = eQt = eâˆ’Î±teÎ±Rt = eâˆ’Î±t
âˆ

k=0
Î±kRk tk
k!.
(6.11)
Proposition 6.18 Let Q âˆˆMN,N(R). Then the matrix P(t) = eQt is stochastic for
any t > 0 if and only if Q is a Q-matrix. Moreover, for any i, j âˆˆ{1, . . . , N} the
following are equivalent:
(i) there exists t0 > 0 such that P(t0)i
j > 0;
(ii) P(t)i
j > 0 for any t > 0.
In particular, P(t)i
i > 0 for any state i and any positive t. Finally, if there exists
t0 > 0 such that P(t0) is irreducible, then P(t)i
j > 0 for any i, j âˆˆ{1, . . . , N} and
any positive t > 0.
Before proving the proposition, let us point out that the proposition asserts
that the evolution of a continuous time Markov chain is much more regular than
the evolution of a discrete time one. Periodicity issues that could not be neglected
in the discrete case do not appear in the continuous time case.
Proof of Proposition 6.18. Assume P(t) is stochastic for any t âˆˆR. Since
P(t) = eQt âˆ€t, then Q = limtâ†’0+ P(t)âˆ’Id
t
from which we easily infer that Q is a
Q-matrix. Conversely, let Q be a Q-matrix. Let Î± â‰¥||Q||âˆand R := Id + 1
Î±Q.
By (6.11) P(t) is the sum of a series with non-negative coefï¬cients
P(t) = eâˆ’Î±t
âˆ

k=0
Î±ktkRk
k!
.
(6.12)
Since the matrix Rk is stochastic for any k, we get P(t)i
j â‰¥0 for any t > 0 and
for any i, j âˆˆ{1, . . . , N}. Moreover,
N

j=1
P(t)i
j = eâˆ’Î±t
âˆ

k=0
Î±ktk
k!
 N

j=1
(Rk)i
j

= eâˆ’Î±t
âˆ

k=0
Î±ktk
k!
= 1.
Let us show the equivalence between claims (i) and (ii). Obviously, (ii) â‡’(i).
It remains to prove that (i) â‡’(ii). If, by contradiction, P(t)i
j = 0 for some
positive t, then by (6.12) (Rk)i
j = 0 for any k and P(t)i
j = 0 âˆ€t â‰¥0.
Since P(t) = eQt, then for any t > 0 and for any positive integer k we have
P(t)k = P(kt). If for some t0 > 0 the matrix P(t0) is irreducible, then for any
i, j âˆˆ{1, . . . N} there exists k = k(i, j) such that P(kt0)i
j = (P(t0)k)i
j > 0. There-
fore equivalence between claims (i) and (ii) yields P(t)i
j > 0 for any t > 0 and
for any i, j.

AN INTRODUCTION TO CONTINUOUS TIME MARKOV CHAINS
253
Proposition 6.19 Let Q be a Q-matrix. Then 0 is an eigenvalue of Q. Any other
eigenvalue of Q has strictly negative real part.
Proof. For any i = 1, . . . , N, let ri := âˆ’Qi
i â‰¥0. By Exercise 5.67 the eigen-
values of Q are in âˆªN
i=1B(âˆ’ri, ri), where B(x, r) denote the closed ball of
radius r centered at x. Thus, all the eigenvalues but 0 of Q have strictly negative
real part. Moreover, if 0 were not an eigenvalue of Q, then all the eigenval-
ues of Q would have strictly negative real part, so that P(t) â†’0 as t â†’âˆ,
a contradiction since P(t) is stochastic for every t.
Example 6.20 Assume the matrix Q is deï¬ned as
Q =
â›
âœâœâ
âˆ’0.5
0.5
0
0
0.5
âˆ’1.5
1
0
0
0
âˆ’2
2
0
0
3
âˆ’3
â
âŸâŸâ 
and let Î± := 4. Then
4R = 4Id + Q =
â›
âœâœâ
3.5
0.5
0
0
0.5
2.5
1
0
0
0
2
2
0
0
3
1
â
âŸâŸâ .
Figure 6.1 shows a representation of both matrices Q and R.
6.2.2.4
Asymptotic behaviour
Using the Banach ï¬xed point theorem, it is easy to discuss the asymptotic
behaviour of P(t) := eQt as t â†’+âˆwhen Q is a Q-matrix.
1
2
3
4
.5
.5
1
2
3
1
2
3
4
1/8
3/4
1/8
1/4
1/2
7/8
5/8
1/2
1/4
(a)
(b)
Figure 6.1
Graphs representing the matrices (a) Q and (b) R in Example 6.20.

254
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
Lemma 6.21 Let Q be a N Ã— N Q-matrix, let P(t) := eQt, t â‰¥0, and let w be a
stochastic vector, w âˆˆT . The following hold:
(i) If for some t0 > 0 the vector w is the only solution of wP(t0) = w, then
wQ = 0.
(ii) wQ = 0 if and only if w = wP(t) for any positive t.
Proof. (i) If w is the only ï¬xed point of the map x â†’xP(t0), x âˆˆT , then for
any n, w is a ï¬xed point for x â†’xP(t0/n), since P(t0/n)n = P

n t0
n

= P(t0).
Therefore, for any positive integer n
w = weQt0/n = w + t0
n wQ + o
1
n

.
Since n is arbitrary, then wQ = 0.
(ii) If wQ = 0, then wQk = 0 for any positive integer k â‰¥1. Thus, for any t > 0
wP(t) = w
âˆ

k=0
Qktk
k!
= w +
âˆ

k=1
wQktk
k!
= w.
Conversely, if w = wP(t) for any positive t, then
w = weQt = w + t wQ + o(t)
as t â†’0+,
so that wQ = 0.
Theorem 6.22 Let P(t) = eQt be stochastic for any positive t. The following are
equivalent:
(i) There exists t0 > 0 such that P(t0) is irreducible.
(ii) There exists w âˆˆT whose components are all different from zero such that
xP(t) â†’w for any x âˆˆT .
In this case, w is the unique solution in T of wQ = 0.
Proof.
(i)
â‡’
(ii).
If
P(t0)
is
irreducible,
then
P(t)i
j > 0
for
any
i, j âˆˆ{1, . . . , N} and for any positive t, see Proposition 6.18. Thus x â†’xP(t)
is a contraction map on T , see Proposition 5.53. Let C(t) < 1 be its contraction
coefï¬cient. By the Banach ï¬xed point theorem x â†’xP(t) has a unique ï¬xed
point w(t) âˆˆT and, recalling that P(kt) = P(t)k, there exists A > 0 such that
for any x âˆˆT and any k â‰¥1
|xP(kt) âˆ’w(t)| â‰¤A C(t)k.
(6.13)
(i) of Lemma 6.21 yields w(t)Q = 0 and (ii) of Lemma 6.21 yields that for any
s > 0 w(t) is also a ï¬xed point for the map x â†’xP(s). Since a contraction has
a unique ï¬xed point, we conclude that w(t) = w(s) =: w for any positive s, t.

AN INTRODUCTION TO CONTINUOUS TIME MARKOV CHAINS
255
Let us now show that xP(t) â†’w for any x âˆˆT . From (iv) of Proposition
5.53 we can assume that the contraction coefï¬cient C(t) is continuous with
respect to t. Thus we may assume that C(t) â‰¤C < 1 for any t âˆˆ[1, 2]. Let
s â‰¥1. Applying (6.13) with k := âŒŠsâŒ‹and t := s/k yields
|xP(s) âˆ’w| â‰¤A C(t)k â‰¤A CâŒŠsâŒ‹.
Thus xP(s) â†’w as s â†’âˆ.
(ii) â‡’(i) If xP(t) â†’w for any x âˆˆT , then all the components of w are nonzero,
see Exercise 5.65. Thus there exists a large enough t0 such that P(t0) is regular.
Consequently, P(t) is regular for any postive t, by Proposition 6.18.
6.2.2.5
Computing eQt
Quite often in applications one needs to compute the exponential matrix
P(t) = eQt, given Q. Various methods can be found in the literature, see e.g.
[21], having different degrees of efï¬ciency, accuracy and usefulness either
from the analytical, numerical or symbolic viewpoint. Formula (6.11) proves to
be quite efï¬cient in computing P(t) = eQt when Q is a Q-matrix: it permits
to compute, for ï¬xed t, good approximations of P(t) with explicitly bounded
errors simply by truncation of the power series on the right-hand side.
Proposition 6.23 (Uniformization method) Let Q be a N Ã— N Q-matrix and let
P(t) = eQt. Let Î± â‰¥||Q||âˆ, R = Id + 1
Î±Q, and
PM(t) = eâˆ’Î±t
M

k=0
Î±kRk tk
k!.
Then
||P(t) âˆ’PM(t)|| â‰¤
(Î±t)M+1
(M + 1)! .
where ||A|| := maxi
N
j=1 |Ai
j|.
Proof. Since R is stochastic, then so are the matrices Rkâ€™s for every k, hence
||Rk|| = 1. Thus the elementary estimate
ex âˆ’
n

k=0
xk
k!
 â‰¤ex
xn+1
(n + 1)!
âˆ€x â‰¥0,
gives
||P(t) âˆ’PM(t)|| â‰¤eâˆ’Î±t
âˆ

k=M+1
Î±k||Rk||tk
k! = eâˆ’Î±t
âˆ

k=M+1
(Î±t)k
k!
â‰¤eâˆ’Î±teÎ±t
(Î±t)M+1
(M + 1)! =
(Î±t)M+1
(M + 1)! .

256
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
6.2.3
Examples of right-continuous Markov chains
At the initial stage 0 we wait for a random length of time that follows the
exponential distribution with intensity Î±1, then we move immediately to the
state 1. We then wait again independently for a random length of time that follows
the exponential distribution exp(Î±2) and we move immediately to the state 2 and
so on. This way one describes the counting process

Nt

tâ‰¥0 associated with a
point process in time.
If moreover

Yn

is a discrete Markov chain, and the families of random
variables

Yn

and

Nt

tâ‰¥0 are independent of each other, then it can be shown
that

Xt

tâ‰¥0, Xt = YNt is a right-continuous Markov chain.
We do not discuss the argument in its full generality and refer the interested
reader to the specialized literature, see e.g. [22â€“24]. Here we consider the sim-
plest case in which all the exponential distributions are the same, so that the
counting process

Nt

tâ‰¥0 is the Poisson process of intensity Î±, see Theorem 6.4.
Thanks to the uniformization method, we have the following.
Theorem 6.24 (Uniformization)
Let Q be a N Ã— N Q-matrix and let
P(t) := eQt. Let Î± â‰¥||Q||âˆand R := Id + Q/Î±. Let

Yn

be a discrete time
homogeneous Markov chain with ï¬nite state-space S, |S| = N, on a probability
space (, E, P) and transition matrix R, and let

Nt

tâ‰¥0 be a Poisson
process with intensity Î± on (, E, P). If the sets of random variables

Yn

and

Nt

tâ‰¥0 are independent, then the stochastic process

Xt

tâ‰¥0 deï¬ned by
Xt(x) := YNt(x)(x) is a right-continuous Markov chain with transition matrix
P(t) := eQt.
Lemma 6.25 Let

Nt

tâ‰¥0 be an integer valued right-continuous stochastic process
on (, E, P). Assume that Nt :  â†’N has the following properties:
(i) N0(x) = 0 and Nt is monotone nondecreasing, Ns(x) â‰¤Nt(x) for a.e. x
for any s, t with 0 â‰¤s â‰¤t.
(ii)

Nt

tâ‰¥0 is time homogeneous, i.e. Nt âˆ’Ns = Ntâˆ’s for any 0 â‰¤s â‰¤t.
(iii)

Nt

tâ‰¥0 has independent increments, i.e. for any 0 â‰¤rn â‰¤Â· Â· Â· â‰¤r1 â‰¤s â‰¤t
and for any n â‰¤q â‰¤p
P

Nt = p
 Ns = q, Nr1 = q1, . . . , Nrn = qn

= P(Ntâˆ’s = p âˆ’q).
Let

Yn

be a homogeneous discrete time Markov chain with a ï¬nite or denumer-
able state-space S on (, E, P). If

Nt

tâ‰¥0 and

Yn

are each other independent,
then the stochastic process

Xt

tâ‰¥0,
Xt(x) := YNt(x)(x)
is a right-continuous Markov chain.

AN INTRODUCTION TO CONTINUOUS TIME MARKOV CHAINS
257
Proof. Let us prove that

Xt

tâ‰¥0 is a homogeneous process. Let s < t and
i, j âˆˆS. From the properties (ii) and (iii) of

Nt

tâ‰¥0
P(Nt = p, Ns = q) = P(Nt âˆ’Ns = p âˆ’q, Ns = q)
= P(Ntâˆ’s = p âˆ’q)P(Ns = q).
Moreover, since

Yn

is a homogeneous Markov chain, for non-negative integers
p, q with p â‰¥q we have
P(Yp = j, Yq = i) = P

Ypâˆ’q = j
 Y0 = i

P(Yq = i).
Therefore
P(Xt = j, Xs = i) =

pâ‰¥q
P(Yp = j, Yq = i, Nt = p, Ns = q)
=

pâ‰¥q
P(Yp = j, Yq = i)P(Nt = p, Ns = q)
=

pâ‰¥q
P

Ypâˆ’q = j
 Y0 = i

P(Yq = i)P(Ntâˆ’s = p âˆ’q)P(Ns = q)
=
 
â„“â‰¥0
P

Yâ„“= j
 Y0 = i

P(Ntâˆ’s = â„“)
 
qâ‰¥0
P(Yq = i)P(Ns = q)

= P

Xtâˆ’s = j
 X0 = i

P(Xs = i).
i.e.
P

Xt = j
 Xs = i

= P

Xtâˆ’s = j
 X0 = i

.
(6.14)
Let us now prove that

Xt

tâ‰¥0 has the Markov property. Let r < s < t and
let h, i, j, âˆˆS. Then Nt(x) â‰¥Ns(x) â‰¥Nr(x), and for any non-negative integers
p, q, n such that p â‰¥q â‰¥n we get
P(Nt = p, Ns = q, Nr = n) = P(Ntâˆ’s = p âˆ’q)P(Ns = q, Nr = n)
P(Yp = j, Yq = i, Yn = h) = P

Ypâˆ’q = j
 Y0 = i

P(Yq = i, Yn = h).
We have
P(Xt = j, Xs = i, Xr = h)
=

pâ‰¥qâ‰¥nâ‰¥0
P(Yp = j, Yq = i, Yn = h, Nt = p, Ns = q, Nr = n)
=

pâ‰¥qâ‰¥nâ‰¥0
P(Yp = j, Yq = i, Yn = h)P(Nt = p, Ns = q, Nr = n)

258
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
=

pâ‰¥qâ‰¥n
P

Ypâˆ’q = j
 Y0 = i

P(Yq = i, Yn = h)
P(Ntâˆ’s = p âˆ’q)P(Ns = q, Nr = n)
=
 
Î»â‰¥0
P

Yl = j
 Y0 = i

P(Ntâˆ’s = l)

 
qâ‰¥nâ‰¥0
P(Yq = i, Yn = h)P(Ns = q, Nr = n)

= P

Xtâˆ’s = j
 X0 = i

P(Xt = i, Xr = h),
therefore, taking also into account (6.14), we ï¬nally get
P

Xt = j
 Xs = i, Xr = h

= P

Xtâˆ’s = j
 X0 = i

= P

Xt = j
 Xs = i

.
Similarly one proceeds to get
P

Xt = j
 Xs1 = i1, . . . , Xin = in

= P

Xt = j
 Xs1 = i1

.
Proof of Theorem 6.24. By Lemma 6.25 Xt(x) = YNt(x)(x) is a right-continuous
Markov chain.
Let S(t) be the transition matrix of

YNt

. Since N0(x) = 0 for a.e. x âˆˆ,
we have
S(t)i
j : = P

YNt(x)(x) = j
 YN0(x)(x) = i

=
1
P(Y0(x) = i)
âˆ

k=0
P

Yk(x) = j, Y0(x) = i, Nt(x) = k

=
âˆ

k=0
P

Yk(x) = j
 Y0(x) = i

P

Nt(y) = k

=
âˆ

k=0
(Rk)i
jeâˆ’Î±t Î±ktk
k!
= eâˆ’Î±teÎ±Rt = eÎ±(âˆ’Id+R)t = eQt = P(t).
Remark 6.26 Notice that Theorem 6.24 reduces the existence of a right-
continuous Markov chain with a given Q-matrix Q to the existence of a Poisson
process of suitable intensity Î± > ||Q||âˆand of a discrete time Markov chain
with transition matrix R := Id + Q/Î±.

AN INTRODUCTION TO CONTINUOUS TIME MARKOV CHAINS
259
Example 6.27 Poisson processes are right-continuous Markov chains. This is a
special case of Lemma 6.25.
6.2.4
Holding times
It can be shown that the holding times between two transitions of a right-
continuous Markov chain with a ï¬nite state-space are independent and follow
exponential distributions of possibly different intensities. We do not enter into
the whole argument, which is well-described in the literature, see e.g. [22â€“24]
and restrict ourselves to discuss the ï¬rst holding time.
Let

Xt

tâ‰¥0 be a homogeneous right-continuous stochastic process with a
ï¬nite or denumerable state-space S. Let P(t) be the transition matrix of the
process. For any state i âˆˆS let SJi be the holding time in state i, deï¬ned for
any x âˆˆ as
SJi(x) := inf

t
 Xt(x) Ì¸= i

.
Proposition 6.28 The holding time in a state i âˆˆS is a random variable. For any
t > 0 and any n â‰¥0, let tj := jt/2n, j = 0, . . . , 2n âˆ’1. Then
P(SJi(x) > t) = lim
nâ†’âˆP

Xtj (x) = i âˆ€j, 0 â‰¤j â‰¤2n âˆ’1

.
Proof. Let D be a denumerable dense set of R+ and let SD(x) :=
inf

t âˆˆD
 Xt(x) Ì¸= i

. Observe that
SJi(x) = SD(x)
if the trajectory t â†’Xt(x) is right-continuous. In fact, trivially SJi(x) â‰¤SD(x).
Moreover, let

tn

âŠ‚D be such that tn â†“SJi(x). Since t â†’Xt(x) is right-
continuous, then Xt Ì¸= i, t := SJi(x) and Xtn Ì¸= i for large enough n. Therefore
SD(x) â‰¤tn for large enough n and passing to the limit as n â†’âˆ, one gets
SD(x) â‰¤SJi(x).
Since the process is right-continuous, by the above the sets

x âˆˆ
 SJi(x) > t

and

x âˆˆ
 SD(x) > t

differ by a null set. Observe now that for t > 0
t < SD(x)
if and only if
Xs(x) = i âˆ€s âˆˆD, 0 â‰¤s â‰¤t
for a.e. x. Consequently,

x âˆˆ
 SJi(x) > t

and

x âˆˆ
 Xs(x) = i âˆ€s âˆˆD, 0 â‰¤s â‰¤t


260
A FIRST COURSE IN PROBABILITY AND MARKOV CHAINS
differ by a null set and
P(SJi(x) > t) = P

Xs(x) = i âˆ€s âˆˆD, 0 â‰¤s â‰¤t

.
In particular, SJi(x) is a random variable on (, E, P).
Fix now t and choose D as D := {jt/2n}j,n. For any n, set Dn := {jt/2n}j.
Trivially, Dn âŠ‚Dn+1 âˆ€n and D = âˆªâˆ
n=1Dn. Moreover,
P(SJi(x) > t) = P

Xs(x) = i âˆ€s âˆˆD, 0 â‰¤s â‰¤t

= P
 âˆ
'
n=1

x âˆˆ
 Xtj (x) = i âˆ€j, 0 â‰¤j â‰¤2n âˆ’1

= lim
nâ†’âˆP

Xtj (x) = i âˆ€j, 0 â‰¤j â‰¤2n âˆ’1

where tj = tj,n := tj/2n.
Proposition 6.29 Let

Xt

tâ‰¥0 be a homogeneous right-continuous Markov chain
with ï¬nite state-space S. Let Q = (qij) be its intensities matrix. Then the holding
time in a state i âˆˆS follows the exponential distribution of parameter âˆ’qii.
Proof. By Proposition 6.28 SJi is a random variable and
P(SJi(x) > t) = lim
nâ†’âˆP

Xtj (x) = i âˆ€j, 0 â‰¤j â‰¤2n âˆ’1

where tj = tj,n := tj/2n. Let P(t) = (pij(t)) be the transition probabilities matrix
of the process. Thus, by the Markov property and the homogeneity of the chain
we get
P(Xtj = i âˆ€j = 0, . . . , 2n âˆ’1) =
2nâˆ’1
=
j=0
P

Xtj+1 = i
 Xtj = i

=

pii
 t
2n
2n
.
Thus, since P(t) = (pij(t)) is right-differentiable at 0 and Pâ€²
+(0) = Q, we con-
clude
log P(SJi > t) = lim
nâ†’âˆ2n log pii
 t
2n

= lim
kâ†’âˆk

pii
 t
k

âˆ’1

= qiit.

Appendix A
Power series
We recall some results from the theory of power series which should already
be known to the reader. Proofs and further results can be found in textbooks on
Analysis, see e.g. [25, 26].
A.1
Basic properties
Let

an

be a sequence of complex numbers. The power series centred at zero
with coefï¬cients

an

is
âˆ

n=0
anzn := a0 +
âˆ

n=1
anzn,
z âˆˆC,
i.e. the sequence of polynomials

sn(z)

n
sn(z) =
n

k=0
akzk := a0 +
n

k=1
akzk,
z âˆˆC.
Given a power series âˆ
n=0 anzn, the non-negative real number Ï deï¬ned by
1
Ï := lim sup
nâ†’âˆ
n
|an|,
where 1/0+ = +âˆand 1/(+âˆ) = 0, is called the radius of convergence of the
series âˆ
n=0 anzn. In fact, one proves that the sequence

sn(z)

is absolutely
convergent if |z| < Ï and it does not converge if |z| > Ï. It can be shown that
Ï > 0 if and only if the sequence

|an|

is not more than exponentially increasing.
A First Course in Probability and Markov Chains, First Edition. Giuseppe Modica and Laura Poggiolini.
Â© 2013 John Wiley & Sons, Ltd. Published 2013 by John Wiley & Sons, Ltd.

262
APPENDIX A
In this case, the sum of the series
A(z) :=
âˆ

n=0
anzn
is deï¬ned in the disc {|z| < Ï}.
Power series can be integrated and differentiated term by term. More pre-
cisely, the following holds.
Theorem A.1 Let A(z) = âˆ
n=0 anzn be the sum of a power series with radius
of convergence Ï. Then the series âˆ
n=0 nanznâˆ’1 and âˆ
n=0 an
zn+1
n+1 have the
same radii of convergence Ï. If Ï > 0, then A(z) is holomorphic in B(0, Ï),
Aâ€²(z) =
âˆ

n=0
nanznâˆ’1,
and, given any piecewise C1 curve Î³ : [0, 1] â†’B(0, Ï),
*
Î³
A(z) dz =
âˆ

n=0
an
Î³ (1)n+1 âˆ’Î³ (0)n+1
n + 1
Then Corollary A.2 easily follows.
Corollary A.2 Let A(z) = âˆ
n=0 anzn be the sum of a power series of radius of
convergence Ï > 0. Then
an = DnA(0)
n!
.
Thus, if Ï > 0 the sum A(z), |z| < Ï, completely determines the sequence

an

. The function A(z) is called the generating function of the sequence

an

.
In other words,

an

and A(z) := âˆ
n=0 anzn contain the same â€˜informationâ€™
(we are assuming that

an

grows at most exponentially or, equivalently that
Ï > 0): we can say that the function A(z), |z| < Ï, is a new â€˜viewpointâ€™ on the
sequence

an

.
By Corollary A.2 if A(z) = âˆ
n=0 anzn and B(z) = âˆ
n=0 bnzn are the sums
of two power series with positive radii of convergence, that coincide near zero,
then an = bn âˆ€n, both series have the same radius Ï, and A(z) = B(z) for any
z such that |z| < Ï.
Example A.3 (Geometric series) The geometric series is the most classical
example of power series. It generates the sequence {1, 1, 1, . . . }
âˆ

n=0
zn

APPENDIX A
263
and its sum is
S(z) :=
âˆ

n=0
zn =
1
1 âˆ’z,
|z| < 1.
Example A.4 (Exponential) Taking advantage of Taylor expansions, one can
prove that
âˆ

n=0
zn
n! = ez,
z âˆˆC.
Example A.5 (Logarithm) Replacing z with âˆ’z in the equality
1
1âˆ’z = âˆ
n=0 zn
|z| < 1, we get
1
1 + z =
âˆ

n=0
(âˆ’1)nzn,
|z| < 1.
Integrating along the interval [0, x] âŠ‚R, we get
log(1 + x) =
* x
0
1
1 + t dt
=
* x
0
âˆ

n=0
(âˆ’1)ntn dt
=
âˆ

n=0
(âˆ’1)n xn+1
n + 1,
|x| < 1.
(A.1)
A.2
Product of series
Deï¬nition A.6 The convolution product of two sequences a =

an

and b =

bn

is the sequence {a âˆ—b}n deï¬ned for n = 0, 1, . . . by
(a âˆ—b)n :=

i+j=n
aibj =
n

j=0
ajbnâˆ’j.
In the ï¬rst sum we sum over all couples (i, j) of non-negative integers such that
i + j = n.
The ï¬rst terms are
(a âˆ—b)0 = a0b0,
(a âˆ—b)1 = a0b1 + a1b0,
(a âˆ—b)2 = a0b2 + a1b1 + a2b0,
. . . .
The convolution product is commutative, associative and bilinear. Moreover
the following holds.

264
APPENDIX A
Theorem A.7 (Cauchy) Let a =

an

and b =

bn

be two sequences and
let A(z) = âˆ
n=0 anzn and B(z) = âˆ
n=0 bnzn be the sums of the associated power
series deï¬ned for |z| < Ïa and |z| < Ïb, respectively. Then the power series of
their convolution products converges for any z such that |z| < min(Ïa, Ïb) and
âˆ

n=0
(a âˆ—b)nzn = A(z)B(z)
âˆ€z, |z| < min(Ïa, Ïb).
A.3
Banach space valued power series
Let V be a Banach space with norm || || and let

fn

âŠ‚V . Then one may consider
the series, with values in V ,
âˆ

k=0
fkzk =

n

k=0
fkzk
n.
(A.2)
Let Ï â‰¥0 be deï¬ned by
1
Ï := lim sup
nâ†’âˆ
n
||fn||.
As in the case of power series with complex coefï¬cients, the power series in
(A.2) absolutely converges in V for any z âˆˆC, |z| < Ï. Thus the sum of the
series is a well deï¬ned function on the disc |z| < Ï of the complex plane with
values in V
F(z) :=
âˆ

k=0
fkzk âˆˆV,
|z| < Ï.
As for complex valued power series, one differentiates term by term Banach
valued power series: the sum F(z) is a holomorphic function on the open disc
|z| < Ï and
F â€²(z) :=
âˆ

k=0
kfkzk âˆˆV,
|z| < Ï.
As a special case, one considers the space MN,N(C) of N Ã— N complex
matrices with norm
||F|| := sup
xâˆˆCN
xÌ¸=0
|Fx|
|x| ,
called the maximum expansion coefï¬cient of F. It is easy to prove that
|Fz| â‰¤||F|| |z|,
||Fn|| â‰¤||F||n
âˆ€n,

APPENDIX A
265
and that MN,N(C) equipped with this norm is a Banach space. Given a sequence

Fn

âŠ‚MN,N(C), the associated power series
âˆ

n=0
Fnzn
(A.3)
converges if |z| < Ï where
1
Ï := lim sup
nâ†’âˆ
n
||Fn||.
From the above, we have the following:
(i) Ï > 0 if and only if the sequence

||Fn||

grows at most exponentially fast.
(ii) If |z| < Ï, then the series (A.3) converges, both pointwise and absolutely,
to a matrix F(z) âˆˆMN,N(C),
F(z) :=
âˆ

n=0
Fnzn,
|z| < Ï,
i.e. we have âˆ€i, j âˆˆ{1, . . . , N} the complex valued limits
Fi
j(z) =
âˆ

n=0
(Fn)i
jzn,
|z| < Ï.
A.3.1.1
Power expansion of the inverse of a matrix
Let
P âˆˆMN,N(C)
be
a
N Ã— N
square
matrix
with
complex
entries.
If ||P|| |z| < 1, then âˆ
n=0 ||P||n|z|n =
1
1âˆ’||P|| |z| < âˆ. Thus the series âˆ
n=0 Pnzn
converges, both pointwisely and absolutely, to a matrix S(z) := âˆ
n=0 Pnzn. For
any positive n we can write
(Id âˆ’zP)
n

k=0
Pkzk =
n

k=0
(Pkzk âˆ’Pk+1zk+1) = Id âˆ’Pn+1zn+1
so that


Id âˆ’zP

n

k=0
Pkzk
âˆ’Id
 = ||Pn+1|| |z|n+1 â‰¤||P||n+1|z|n+1.
Since ||P|| |z| < 1, as n â†’âˆwe get

Id âˆ’zP

S(z) = Id.

266
APPENDIX A
Therefore, we conclude that, if |z| <
1
||P||, then Id âˆ’zP is invertible and
(Id âˆ’zP)âˆ’1 = S(z) =
âˆ

k=0
Pkzk.
A.3.1.2
Exponential of a matrix
Let Q âˆˆMN,N(C). The radius of convergence of the power series
âˆ

n=0
Qn
n! zn
is +âˆ, so that, for any z âˆˆC the power series âˆ
n=0
Qn
n! zn converges, both
absolutely and pointwisely, to a matrix denoted by eQz,
eQz :=
âˆ

n=0
Qn
n! zn
âˆ€z âˆˆC.
(A.4)
Proposition A.8 The following hold:
(i) eQ0 = Id.
(ii) eQz and Q commute.
(iii)

eQzâ€²
= QeQz for any z âˆˆC.
(iv) eQ(z+w) = eQzeQw for any z, w âˆˆC.
(v) eQz is invertible and its inverse is (eQz)âˆ’1 = eâˆ’Qz.
(vi) (eQz)n = eQnz for any z âˆˆC and any n âˆˆZ.
Proof. Properties (i) and (ii) are a direct consequence of the deï¬nition of eQz.
Property (iii) follows differentiating term by term the series âˆ
n=0
Qn
n! zn. Property
(iv) is a consequence of the formula for the product of power series: in fact,
eQzeQw =
âˆ

k=0
Qk
k! zk
âˆ

k=0
Qk
k! wk =
âˆ

n=0
n

k=0
QkQnâˆ’kzkwnâˆ’k
k!(n âˆ’k)!
=
âˆ

n=0
Qn
n!
n

k=0
n
k

zkwnâˆ’k =
âˆ

n=0
Qn
n! (z + w)n = eQ(z+w).
Finally, properties (v) and (vi) are particular cases of (iv).

APPENDIX A
267
A.3.2
Exercises
Exercise A.9 Prove the Newton binomial theorem:
(i) directly, with an induction argument on n;
(ii) taking advantage of the Taylor expansions;
(iii) starting from the formula D((1 + z)n) = n(1 + z)nâˆ’1;
(iv) starting from the identity et(x+y) = etxety.
Exercise A.10 Prove the following equalities:
n

j=0
2j
n
j

= 3n,
n

j=0
 n
2j

=
n

j=0

n
2j + 1

= 2nâˆ’1,
n

j=0
(âˆ’1)j
n
j
2
=

(âˆ’1)n/2 n
n/2

if n is even,
0
if n is odd,
n

j=a
j
a

=
n + 1
a + 1

,
âˆ

j=0
Î± + j
j

xj =
1
(1 âˆ’x)Î±+1 ,
2n
n

= (âˆ’4)n
âˆ’1/2
n

.
Exercise A.11 Show that
n

j=0
(âˆ’1)j
n
j
n + m âˆ’j
k âˆ’j

=
n
k

if m â‰¥k,
0
if m < k.
Exercise A.12 Let

an

be a complex valued sequence such that

|an|

grows at
most exponentially fast. Let A(z) = âˆ
n=0 anzn, |z| < Ï be its generating function.
Compute the generating function of the following sequences:
â€¢

Î±a0, Î±a1, Î±a2, Î±a3, . . .

, Î± âˆˆC,
â€¢

a0, 0, a1, 0, a2, 0, . . .

,

268
APPENDIX A
â€¢

a0, 0, a2, 0, a4, 0, . . .

,
â€¢

a1, 0, a3, 0, a5, 0, . . .

,
â€¢

0, 0, 0, a0, a1, a2, a3, . . .

,
â€¢

a3, a4, a5, a6, . . .

,
â€¢

a0, 2a1, 3a2, 4a3, 5a4, . . .

,
â€¢

a0, a1/2, a2/3, a3/4, a4/5, . . .

,
â€¢

a0, a0 + a1, a1 + a2, a2 + a3, . . .

,
â€¢

a0 + a1, a1 + a2, a2 + a3, a3 + a4, . . .

,
â€¢

a0, a0 + a1, a0 + a1 + a2, a0 + a1 + a2 + a3, . . .

.
Exercise A.13 Compute p
j=0(âˆ’1)jn
j

.
0
(âˆ’1)pnâˆ’1
p
1
.
Solution.
We prove this equality directly. Since for any p = 1, . . . , n âˆ’1 we have
n
p

=
nâˆ’1
p

+
nâˆ’1
pâˆ’1

, one gets
p

j=0
(âˆ’1)j
n
j

= 1 âˆ’n +
p

j=2
(âˆ’1)j
n âˆ’1
j

+
pâˆ’1

j=1
(âˆ’1)j+1
n âˆ’1
j

= 1 âˆ’n +
pâˆ’1

j=2
(âˆ’1)jn âˆ’1
j

âˆ’
n âˆ’1
j

+
n âˆ’1
1

+ (âˆ’1)p
n âˆ’1
p

= 1 âˆ’n + 0 + (n âˆ’1) + (âˆ’1)p
n âˆ’1
p

= (âˆ’1)p
n âˆ’1
p

.
The same result can be obtained via generating functions. From the formula
for the product of two power series, we get
âˆ

p=0

p

j=0
(âˆ’1)pâˆ’j
n
j

xp =
 âˆ

j=0
(âˆ’x)j âˆ

j=0
n
j

xj
=
1
1 + x (1 + x)n = (1 + x)nâˆ’1 =
nâˆ’1

p=0
n âˆ’1
p

xp.
The claim follows by the identity principle for polynomials.

APPENDIX A
269
Exercise A.14 For any p, q, k â‰¥0, prove Vandermonde formula
k

j=0
p
j

q
k âˆ’j

=
p + q
k

.
(A.5)
Solution. We prove the equality (A.5) by using generating functions. From
the formula for the product of power series, we get
âˆ

k=0

k

j=0
p
j

q
k âˆ’j

zk =
 âˆ

k=0
p
k

zk âˆ

k=0
q
k

zk
= (1 + z)p+q =
âˆ

k=0
p + q
k

zk,
hence the claim.
Exercise A.15 Show that âˆ
j=0
p
j
 q
jâˆ’1

=
p+q
pâˆ’1

âˆ€p, q â‰¥0.
Solution. Applying the Vandermonde formula (A.5), we get
âˆ

j=0
p
j

q
j âˆ’1

=
âˆ

j=0
p
j

q
q âˆ’j + 1

=
p + q
q + 1

=
p + q
p âˆ’1

.
Exercise A.16 Show that n
k=0
n
k
2 =
2n
n

.
Solution. Applying Vandermonde formula we get
n

k=0
n
k
2
=
n

k=0
n
k

n
n âˆ’k

=
2n
n

.

Appendix B
Measure and integration
The axiomatic approach to probability by Andrey Kolmogorov (1903â€“1987)
makes essential use of the measure theory. In this appendix we review the aspects
of the theory that are relevant to us. We do not prove everything and refer the
interested reader for proofs and further study to one of the many volumes on this
now classic subject, see e.g. [7, 27].
B.1
Measures
B.1.1
Basic properties
Here  shall denote a generic set. For a generic subset E of , Ec :=  \ E
denotes the complement of E in  and P() denotes the family of all subsets of
. A family E of subsets of  is then a subset of P(), E âŠ‚P(). We say that
a family E âŠ‚P() of subsets of a set  is an algebra if âˆ…,  âˆˆE and E âˆªF,
E âˆ©F and Ec âˆˆE whenever E, F âˆˆE.
Deï¬nition B.1 We say that E is a Ïƒ-algebra if E is an algebra and for every
sequence of subsets

Ek

âŠ‚E we also have âˆªkEk and âˆ©kFk âˆˆE.
In other words, if we operate on sets of a Ïƒ-algebra with differences, countable
unions or intersections, we get sets of the same Ïƒ-algebra: we also say that a
Ïƒ-algebra
is
closed
with
respect
to
differences,
countable
unions
and
intersections.
Let D âŠ‚P() be a family of subsets of . It is readily seen that the class
S :=
' 
E
 E is a Ïƒ-algebra, E âŠƒD

is again a Ïƒ-algebra, hence the smallest Ïƒ-algebra containing D. We say that S
is the Ïƒ-algebra generated by D.
A First Course in Probability and Markov Chains, First Edition. Giuseppe Modica and Laura Poggiolini.
Â© 2013 John Wiley & Sons, Ltd. Published 2013 by John Wiley & Sons, Ltd.

APPENDIX B
271
Deï¬nition B.2 The smallest Ïƒ-algebra B âŠ‚P(Rn) containing the open sets of
Rn is called the Ïƒ-algebra of Borel sets.
Deï¬nition B.3 A measure on  is a couple (E, P) of a Ïƒ-algebra E âŠ‚P() and
of a map P : E â†’R+ with the following properties:
(i) P(âˆ…) = 0.
(ii) (Monotonicity) If A, B âˆˆE with A âŠ‚B, then P(A) â‰¤P(B).
(iii) (Ïƒ-additivity) For any disjoint sequence

Ai

âŠ‚E we have
P
 âˆ
(
i=1
Ai

=
âˆ

i=1
P(Ai).
Obviously (iii) reduces to ï¬nite additivity for pairwise disjoint subsets if E is
ï¬nite. When E is inï¬nite, the inï¬nite sum on the right-hand side is understood
as the sum of a series of non-negative terms. From Deï¬nition B.3 we easily get
the following.
Proposition B.4 Let (E, P) be a measure on . We have:
(i) If A âˆˆE, then 0 â‰¤P(A).
(ii) If A, B âˆˆE with A âŠ‚B, then P(B \ A) + P(A) = P(B).
(iii) If A, B âˆˆE then P(A âˆªB) + P(A âˆ©B) = P(A) + P(B).
(iv) If A, B âˆˆE then P(A âˆªB) â‰¤P(A) + P(B).
(v) (Ïƒ-subadditivity) For any sequence

Ai

âŠ‚E we have
P
 âˆ
(
i=1
Ai

â‰¤
âˆ

i=1
P(Ai).
(B.1)
(vi) (Disintegration formula) If

Di

âŠ‚E is a partition of , then for every
A âŠ‚,
P(A) =
âˆ

i=1
P(A âˆ©Di).
(B.2)
(vii) (Continuity)
(a) If

Ei

âŠ‚E with Ei âŠ‚Ei+1 âˆ€i, then âˆªâˆ
i=1Ei âˆˆE and
P(âˆªâˆ
i=1Ei) = lim
iâ†’âˆP(Ei).
(B.3)
(b) Let

Ei

âŠ‚E be such that Ei âŠƒEi+1 âˆ€i. Then âˆ©âˆ
i=1Ei âˆˆE and more-
over, if P(E1) < +âˆ, then
P(âˆ©âˆ
i=1Ei) = lim
iâ†’âˆP(Ei).
(B.4)

272
APPENDIX B
Proof. (i)â€“(vi) follow trivially from the deï¬nition of measure. Let us prove
claim (a) of (vii). Since P(Ek) â‰¤P(âˆªkEk) for every k, the claim is trivial if for
some k P(Ek) = +âˆ. We may therefore assume P(Ek) < âˆfor all k. We set
E := âˆªkEk and decompose E as
E = E1
(  âˆ
(
k=2
(Ek \ Ekâˆ’1)

.
The sets E1 and Ek \ Ekâˆ’1, k â‰¥1, are of course in E and pairwise disjoint.
Because of the Ïƒ-additivity of P we then have
P(E) = P(E1) +
âˆ

k=2
P(Ek \ Ekâˆ’1)
= P(E1) +
âˆ

k=2
(P(Ek) âˆ’P(Ekâˆ’1)) = lim
kâ†’âˆP(Ek).
Claim (b) of (vii) easily follows. In fact, since P(E1) < +âˆand Ek âŠ‚E1, we
have P(Ek) = P(E1) âˆ’P(E1 \ Ek) for all k. Since

E1 \ Ek

is an increasing
sequence of sets, we deduce from (a) that
P(E1) âˆ’lim
kâ†’âˆP(Ek) = lim
kâ†’âˆP(E1 \ Ek)
= P
 (
k
(E1 \ Ek)

= P(E1) âˆ’P
 '
k
Ek

.
Let (E, P) be a measure on . We say that N âŠ‚ is P-negligible, or simply
a null set, if there exists E âˆˆE such that N âŠ‚E and P(E) = 0. Let )E be the
collection of all the subsets of  of the form F = E âˆªN where E âˆˆE and N
is P-negligible. It is easy to check that )E is a Ïƒ-algebra which is called the
P-completion of E. Moreover, setting P(F) := P(E) if F = E âˆªN âˆˆ)E, then
()E, P) is also a measure on  called the P-completion of (E, P). It is often
customary to consider measures as P-complete measures.
B.1.2
Construction of measures
B.1.2.1
Uniqueness
Let (E, P) be a measure on . The Ïƒ-additivity property of P suggests that the
values of P on E are in fact determined by the values of P on a restricted class
of subsets of E.
Deï¬nition B.5 A family D âŠ‚P() of subsets of  is said to be closed under
ï¬nite intersections if A, B âˆˆD implies A âˆ©B âˆˆD.
A set function Î± : I âŠ‚P() â†’R+ is Ïƒ-ï¬nite if there exists a sequence

Ik

âŠ‚I such that  = âˆªkIk and Î±(Ik) < âˆâˆ€k.

APPENDIX B
273
We have the following coincidence criterion. A proof can be found in, e.g. [7].
Theorem B.6 (Coincidence criterion) Let (E1, P1) and (E2, P2) be two measures
on  and let D âŠ‚E1 âˆ©E2 be a family that is closed under ï¬nite intersections.
Assume that P1(A) = P2(A) âˆ€A âˆˆD and that there exists a sequence

Dh

âˆˆD
such that  = âˆªhDh and P1(Dh) = P2(Dh) < +âˆfor any h. Then P1 and P2
coincide on the Ïƒ-algebra generated by D.
Corollary B.7 (Uniqueness of extension) Let  be an open set, let I be a family
of subsets of  closed under ï¬nite intersections and let Î± : I â†’R+ be Ïƒ-ï¬nite.
Then Î± has at most one extension Î¼ : E â†’R+ to the Ïƒ-algebra E generated by
I such that (E, Î¼) is a measure.
B.1.2.2
CarathÂ´eodory Method I
We now present the so-called Method I for constructing measures.
Let I be a family of subsets of  containing the empty set, and let Î± :
I â†’R+ be a set function such that Î±(âˆ…) = 0. For any E âŠ‚ set
Î¼âˆ—(E) := inf
 âˆ

i=1
Î±(Ii)
 âˆªi Ii âŠƒE, Ii âˆˆI
>
.
(B.5)
Of course, we set Î¼âˆ—(E) = +âˆif no covering of E by subsets in I exists. It
is easy to check that Î¼âˆ—(âˆ…) = 0, that Î¼âˆ—is monotone increasing and that Î¼âˆ—is
Ïƒ-subadditive, i.e.
Î¼âˆ— âˆ
(
i=1
Ei

â‰¤
âˆ

i=1
Î¼âˆ—(Ei)
for every denumerable family

Ei

of subsets of .
We now deï¬ne a Ïƒ-algebra M on which Î¼âˆ—is Ïƒ-additive. A ï¬rst attempt
is to choose the class of sets on which Î¼âˆ—is Ïƒ-additive, i.e. the class of sets E
such that
Î¼âˆ—(B âˆªE) = Î¼âˆ—(E) + Î¼âˆ—(B)
for every subset B disjoint from E, or, equivalently such that
Î¼âˆ—(A âˆ©E) + Î¼âˆ—(A âˆ©Ec) â‰¤Î¼âˆ—(A)
âˆ€A, A âŠƒE.
(B.6)
However, in general, this class is not a Ïƒ-algebra. Following CarathÂ´eodory, a
localization of (B.6) sufï¬ces. A set E âŠ‚ is said to be Î¼âˆ—-measurable if
Î¼âˆ—(A âˆ©E) + Î¼âˆ—(A âˆ©Ec) = Î¼âˆ—(A)
âˆ€A âˆˆP()
and the class of Î¼âˆ—-measurable sets will be denoted by M.
Theorem B.8 (CarathÂ´eodory) M is a Ïƒ-algebra and Î¼âˆ—is Ïƒ-additive on M. In
other words, (M, Î¼âˆ—) is a measure on .

274
APPENDIX B
Without additional hypotheses both on I and Î±, we might end up with I not
included in M or with a Î¼âˆ—that is not an extension of Î±.
Deï¬nition B.9 A family I âŠ‚P() of subsets of  is a semiring if:
(i) âˆ…âˆˆI.
(ii) For any E, F âˆˆI we have E âˆ©F âˆˆI.
(iii) If E, F âˆˆI, then E \ F = âˆªN
j=1Ij where the Ijâ€™s are pairwise disjoint ele-
ments in I.
Notice that, if E, F âˆˆI, then E âˆªF decomposes as E âˆªF = âˆªn
j=1Ij where
I1, . . . , In belong to I and are pairwise disjoint.
Theorem B.10 (CarathÂ´eodory) Let I âŠ‚P() be a semiring of subsets of , let
Î± : I â†’R+ be a Ïƒ-additive set function such that Î±(âˆ…) = 0 and let (M, Î¼âˆ—) be
the measure constructed by the above starting from I and Î±. Then:
(i) I âŠ‚M.
(ii) Î¼âˆ—extends Î± to M.
(iii) Let E âŠ‚ with Î¼âˆ—(E) < âˆ. Then E âˆˆM if and only if E = âˆ©kFk \ N
where Î¼âˆ—(N) = 0,

Fk

is a decreasing sequence of sets Fk and, for k â‰¥1,
Fk is a disjoint union Fk = âˆªjIk,j of sets Ik,j âˆˆI.
Assume Î± : I â†’R+ be such that I is a semiring, Î± is Ïƒ-additive and Ïƒ-ï¬nite
and let E be the Ïƒ-algebra generated by I. From Theorems B.6 and B.10 the
following easily follows:
â€¢ (iii) of Theorem B.10 implies that M is the Î¼âˆ—-completion of E: every set
A âˆˆM has the form A = E âˆªN where E âˆˆE and Î¼âˆ—(N) = 0.
â€¢ Corollary B.7 imples that (E, Î¼âˆ—) is the unique measure that extends Î±
to E.
B.1.2.3
Lebesgue measure in Rn
A right-closed interval I of Rn, n â‰¥1, is the product of n intervals closed to
the right and open to the left, I = -n
i=1]ai, bi]. The elementary volume of this
interval is |I| := -n
i=1(bi âˆ’ai).
An induction argument on the dimension n shows that I is a semiring. For
instance, let n = 2 and let A, B, C, D be right-closed intervals on R. Then
(A Ã— B) \ (C Ã— D) =

(A \ C) Ã— (B \ D)

âˆª

(A \ C) Ã— (B âˆ©D)

âˆª

(A âˆ©C) Ã— (B \ D)

.
The family of right-closed intervals of Rn will be denoted by I. We know
that B(Rn) is the Ïƒ-algebra generated by I, see Exercise B.16. Since I is trivially

APPENDIX B
275
closed under ï¬nite intersections, we infer from Theorem B.6 that two measures
that coincide on I and that are ï¬nite on bounded open sets coincide on every
Borel set E âˆˆB(Rn).
Proposition B.11 The volume map | | : I â†’R+ is a Ïƒ-additive set function.
Proof. It is easily seen that the elementary measure | | is ï¬nitely additive
on intervals. Let us prove that it is Ïƒ-subadditive. For that, let I, Ik be intervals
with I = âˆªkIk and, for Ïµ > 0 and any k denote by Jk an interval centred as
Ik that contains strictly Ik with |Jk| â‰¤|Ik| + Ïµ 2âˆ’k. The family of open sets

int(Jk)

k covers the compact set I, hence we can select k1, k2, . . . kN such that
I âŠ‚âˆªN
i=1int(Jki) concluding
|I| â‰¤
N

i=1
|Jki| â‰¤
âˆ

k=1
|Jk| â‰¤
âˆ

k=1
(|Ik| + Ïµ2âˆ’k) â‰¤
âˆ

k=1
|Ik| + 2Ïµ,
i.e. that || is Ïƒ-subadditive on I.
Suppose now that I = âˆªkIk where the

Ik

â€™s are pairwise disjoint. Of
course, by the Ïƒ-subadditivity property of ||, |I| â‰¤âˆ
k=1 |Ik|. On the other
hand, âˆªN
k=0Ik âŠ‚I for any integer N. Finite additivity then yields
N

k=0
|Ik| =

N
(
k=0
Ik
 â‰¤|I|
âˆ€N
and, as N â†’âˆ, also the opposite inequality âˆ
k=0 |Ik| â‰¤|I|.
Taking advantage of Proposition B.11, Theorem B.10 applies. We get the
existence of a unique measure (B(Rn), Ln) that is ï¬nite on bounded open sets,
called the Lebesgue measure on Rn, that extends to Borel sets the elementary
measure of intervals. From (B.5) we also get a formula for the measure of a
Borel set E âˆˆB(Rn),
Ln(E) = inf
 âˆ

k=1
|Ik|
 Ik intervals, E âŠ‚
âˆ
(
k=1
Ik
>
.
(B.7)
B.1.2.4
Stieltjesâ€“Lebesgue measure
Proposition B.12 Let F : R â†’R be a right-continuous and monotone nonde-
creasing function. Then the set function Î¶ : I â†’R deï¬ned by Î¶(]a, b]) := F(b) âˆ’
F(a) on the class I of right-closed intervals is Ïƒ-additive.
Proof. Obviously, Î¶ is additive and monotone increasing, hence ï¬nitely sub-
additive, on I. We now prove that Î¶ is Ïƒ-additive. Let

Ii

âŠ‚I, Ii :=]xi, yi],
be a disjoint partition of I :=]a, b]. Since Î¶ is additive, we get
âˆ

i=1
Î¶(Ii) â‰¤Î¶(I).

276
APPENDIX B
Let us prove the opposite inequality. For Ïµ > 0, let

Î´i

be such that F(yi +
Î´i) â‰¤F(yi) + Ïµ 2âˆ’i. The open intervals ]xi, yi + Î´i[ form an open covering of
[a + Ïµ, b], hence ï¬nitely many among them cover again [a + Ïµ, b]. Therefore,
by the ï¬nite subadditivity of Î¶,
F(b) âˆ’F(a + Ïµ) â‰¤
N

k=1
(F(yik + Î´ik) âˆ’F(xik)
=
N

k=1
(Î¶(Iik) + Ïµ 2âˆ’ik) â‰¤
âˆ

i=1
Î¶(Ii) + Ïµ.
Letting Ïµ go to zero, we conclude
Î¶(I) = F(b) âˆ’F(a) â‰¤
âˆ

i=1
Î¶(Ii).
Example B.13 If F is not right-continuous, the set function Î¶ : I â†’R,
Î¶(]a, b]) := F(b) âˆ’F(a) is not in general subadditive. For instance, for
0 â‰¤a â‰¤1, set
F(t) = Fa(t) =
â§
âªâ¨
âªâ©
0
if âˆ’1 â‰¤t < 0,
a
if t = 0,
1
if 0 < t â‰¤1.
Let I = {] âˆ’1, 0]} âˆª

]
1
j+1, 1
j ]

j, clearly âˆªIâˆˆII =] âˆ’1, 1], but
1 = F(1) âˆ’F(âˆ’1) = Î¶
 (
IâˆˆI
I

Ì¸=

IâˆˆI
Î¶(I) = F(0) âˆ’F(âˆ’1) = a
as soon as a < 1.
Theorem B.14 (Lebesgue) The following hold:
(i) Let (B(R), P) be a ï¬nite measure on R. Then the law F(t) := P(] âˆ’âˆ,
t]),
t âˆˆR,
is
real
valued,
monotone
nondecreasing
and
right-
continuous.
(ii) Let F : R â†’R be a real valued, monotone nonderecreasing and right-
continuous function. Then there exists a unique measure (B(R), P) ï¬nite
on bounded sets of R such that
P(]a, b]) = F(b) âˆ’F(a)
âˆ€a, b, a < b.
Proof. (i) F is real valued since (B(R), P) is ï¬nite on bounded Borel sets.
Moreover, monotonicity property of measures implies that F is monotone
nondecreasing. Let us prove that F is right-continuous. Let t âˆˆR and let

tn


APPENDIX B
277
be a monotone decreasing sequence such that tn â†“t. Since ] âˆ’âˆ, t] =
Dâˆ
n=1] âˆ’âˆ, tn]
and
P
is
ï¬nite,
one
gets
F(tn) = P(] âˆ’âˆ, tn]) â†’
P(] âˆ’âˆ, t]) = F(t) by the continuity property of measures.
(ii) Assume F(t) is right-continuous and monotone nondecreasing. Let I be
the semiring of right-closed intervals. The set function Î¶ : I â†’R+, Î¶(]a, b]) :=
F(b) âˆ’F(a) is Ïƒ-additive, see Proposition B.12. Therefore Theorem B.6 and
B.10 apply and Î¶ extends in a unique way to a measure on the Ïƒ-algebra generated
by I, i.e. on B(R), that is ï¬nite on bounded open sets.
The measure (B(R), P) in Theorem B.14 is called the Stieltjesâ€“Lebesgue
measure associated with the right-continuous monotone nondecreasing func-
tion F.
B.1.2.5
Approximation of Borel sets
Borel
sets are quite complicated if compared with open sets that are simply
denumerable unions of closed cubes with disjoint interiors. However, the follow-
ing holds.
Theorem B.15 Let (B(Rn), P) be a measure on Rn that is ï¬nite on bounded open
sets. Then for any E âˆˆB(Rn)
P(E) = inf

P(A)
 A âŠƒE, A open

,
(B.8)
P(E) = sup

P(F)
 F âŠ‚E, F closed

.
(B.9)
In particular, if E âˆˆB(Rn) has ï¬nite measure, P(E) < +âˆ, then for every Ïµ > 0
there exists an open set  and a compact set K such that K âŠ‚E âŠ‚ and P( \
K) < Ïµ.
Although the result can be derived from (iii) of Theorem B.10, it is actually
independent of it. We give here a proof that does not use Theorem B.10.
Proof. Step 1. Let us prove the claim assuming P is ï¬nite. Consider the family
A :=

E Borel
 (B.8) holds true for E

.
Of course, A contains the family of open sets. We prove that A is closed under
denumerable unions and intersections. Let

Ej

âŠ‚A and, for Ïµ > 0 and j =
1, 2, . . . , let Aj be open sets with Aj âŠƒEj and P(Aj) â‰¤P(Ej) + Ïµ 2âˆ’j, that
we rewrite as P(Aj \ Ej) < Ïµ 2âˆ’j since Ej and Aj are measurable with ï¬nite
measure. Since
 (
j
Aj

\
 (
j
Ej

âŠ‚
(
j
(Aj \ Ej),
 '
j
Aj

\
 '
j
Ej

âŠ‚
(
j
(Aj \ Ej),
we infer
P(A \ âˆªjEj) â‰¤Ïµ,
P(B \ âˆ©jEj) â‰¤Ïµ,
(B.10)

278
APPENDIX B
where
A := âˆªjAj
and
B := âˆ©jAj.
Since
A
is
open
and
A âŠƒâˆªjEj,
the
ï¬rst
inequality
of
(B.10)
yields
âˆªjEj âˆˆA.
On
the
other
hand,
CN := âˆ©N
j=1Aj is open, contains âˆ©jEj and, by the second inequality of (B.10),
P(CN \ âˆ©jEj) â‰¤2 Ïµ for sufï¬ciently large N. Therefore âˆ©jEj âˆˆA.
Moreover, since every closed set is the intersection of a denumerable family
of open sets, A also contains all closed sets. In particular, the family
ËœA :=

A âˆˆA, Ac âˆˆA

is a Ïƒ-algebra that contains the family of open sets. Consequently, A âŠƒËœA âŠƒ
B(Rn) and (B.8) holds for all Borel sets of .
Since (B.9) for E is (B.8) for Ec, we have also proved (B.9).
Step 2. Let us prove (B.8) and (B.9) for measures that are ï¬nite on bounded open
sets. Let us introduce the following notation: given a Borel set A âŠ‚Rn, deï¬ne
the restriction of P to A as the set function
P
A(E) := P(A âˆ©E)
âˆ€E âˆˆB(Rn).
(B.11)
It is easily seen that (B(Rn), P
A) is a measure on Rn that is ï¬nite
if P(A) < âˆ.
Let us prove (B.8). We may assume P(E) < +âˆsince otherwise (B.8) is
trivial. Let Vj := B(0, j) be the open ball centred at 0 or radius j. The measures
P
Vj are Borel and P
Vj(Rn) = P(Vj) < +âˆ. Step 1 then yields that for
any Ïµ > 0 there are open sets Aj with Aj âŠƒE and P
Vj(Aj \ E) < Ïµ 2âˆ’j. The
set A := âˆªj(Aj âˆ©Vj) is open, A âŠƒE and, by the subadditivity of P
P(A \ E) = P(âˆªj((Aj âˆ©Vj) \ E))
â‰¤
âˆ

j=1
P((Aj âˆ©Vj) \ E) â‰¤
âˆ

j=1
P
Vj(Aj \ E) â‰¤Ïµ.
Let us prove (B.9). The claim easily follows applying Step 1 to the measure
P
E if P(E) < +âˆ. If P(E) = +âˆ, then E = âˆªjEj with Ej measurable
and P(Ej) < +âˆ, then for every Ïµ > 0 and every j there exists a closed set Fj
with Fj âŠ‚Ej and P(Ej \ Fj) < Ïµ 2âˆ’j. The set F := âˆªjFj is contained in E and
P(E \ F) â‰¤P(âˆªj(Ej \ Fj)) â‰¤
âˆ

j=i
P(Ej \ Fj) â‰¤Ïµ,
hence, for sufï¬ciently large N, GN := âˆªN
i=1Fi is closed and P(E \ GN) < 2Ïµ.
Step 3. By assumption, E âˆˆB(Rn) and P(E) < +âˆ. By Step 2 for each Ïµ > 0
there exists an open set  and a closed set F such that F âŠ‚E âŠ‚ and

APPENDIX B
279
P() â‰¤P(E) + Ïµ, P(E) â‰¤P(F) + Ïµ, so that P() âˆ’P(F) â‰¤2Ïµ. Setting K :=
F âˆ©B(0, n) with large enough n, we still get
P(E) â‰¤P(K) + 2Ïµ,
thus concluding that A âŠƒE âŠƒK and P(A \ K) < 3Ïµ.
B.1.3
Exercises
Exercise B.16 Show that B(R) is the smallest Ïƒ-algebra generated by one of the
following families of sets:
â€¢ the closed sets;
â€¢ the open intervals;
â€¢ the closed intervals;
â€¢ the intervals ]a, b], a, b âˆˆR, a < b;
â€¢ the intervals [a, b[, a, b âˆˆR, a < b;
â€¢ the closed half-lines ] âˆ’âˆ, t], t âˆˆR.
Solution. [Hint. Show that any open set can be written as the union of an at
most denumerable family of intervals.]
Exercise B.17 The law of a ï¬nite measure (B(Rn), P) on Rn is deï¬ned by
F(t) = F(t1, . . . , tn) := P(] âˆ’âˆ, t1] Ã— Â· Â· Â· Ã—] âˆ’âˆ, tn]).
Show that two ï¬nite measures (B(Rn), P) and (B(Rn), Q) on Rn coincide if and
only if the corresponding laws agree.
B.2
Measurable functions and integration
Characterizing the class of Riemann integrable functions and understanding the
range of applicability of the fundamental theorem of calculus were the problems
that led to measures and to a more general notion of integral due to Henri
Lebesgue (1875â€“1941). The approach we follow here, which is very well adapted
to calculus of probability, is to start with a measure and deï¬ne the associated
notion of integral.
The basic idea is the following. Suppose one wants to compute the area of the
subgraph of a non-negative function f : R â†’R. One can do it by approximating
the subgraph in two different ways, see Figure B.1. One can take partitions of the

280
APPENDIX B
(a)
(b)
Figure B.1
The computation of an integral according to (a) Riemann and
(b) Lebesgue.
x axis, and approximate the integral by the area of a piecewise constant function
as we do when deï¬ning the Riemann integral, or one can take a partition of the y
axis, and approximate the area of the subgraph by the areas of the strips. The
latter deï¬nes the area of the subgraph as
* b
a
f (x) dx = lim
Nâ†’âˆ
1
2N
âˆ

k=1
|Ef,k 2âˆ’N|,
(B.12)
where
Ef,t :=

x âˆˆR
 f (x) > t

,
t âˆˆR,
is the t upper level of f and |Ef,t| denotes its â€˜measureâ€™. Since t â†’|Ef,t| is
monotone nonincreasing, hence Riemann integrable, (B.12) suggests deï¬ning the
integral by means of the Cavalieri formula
Lebesgue
* b
a
f (x) dx := Riemann
* âˆ
0
|Ef,t| dt
(B.13)
From this point of view, it is clear that the notion of integral makes essential
use of a measure on the domain, that must be able to measure even irregular
sets, since the upper levels can be very irregular, for instance if the function
is oscillating.
In the following, instead of deï¬ning the integral by means of (B.13), we adopt
a slightly more direct approach to the integral and then prove (B.13).
B.2.1
Measurable functions
Deï¬nition B.18 Let E be a Ïƒ-algebra of subsets of a set . We say that f :  â†’R
is E-measurable if for any t âˆˆR we have

x âˆˆ
 f (x) > t

âˆˆE.
There are several equivalent ways to say that a function is E-measurable.
Taking advantage of the fact that E is a Ïƒ-algebra, one proves that the following
are equivalent:
(i) {x âˆˆ | f (x) > t} âˆˆE for any t.
(ii) {x âˆˆ | f (x) â‰¥t} âˆˆE for any t.

APPENDIX B
281
(iii) {x âˆˆ | f (x) â‰¤t} âˆˆE for any t.
(iv) {x âˆˆ | f (x) < t} âˆˆE for any t.
Moreover, in the previous statements one can substitute â€˜for any tâ€™ with â€˜for any
t in a dense subset of Râ€™, in particular, with â€˜for any t âˆˆQâ€™.
Since any open set of R is an at most denumerable union of intervals, the
following are also equivalent:
(i) {x âˆˆ | f (x) > t} âˆˆE for any t.
(ii) For any open set A âŠ‚R we have f âˆ’1(A) âˆˆE.
(iii) For any closed F âŠ‚R we have f âˆ’1(F) âˆˆE.
(iv) For any Borel set B âŠ‚R we have f âˆ’1(B) âˆˆE.
The three last statements are independent of the ordering relation of R. They
suggest the following extension.
Deï¬nition B.19 Let E be a Ïƒ-algebra of subsets of a set . A vector valued
function f :  â†’RN, N â‰¥1, is E-measurable if one of the following holds:
(i) For any open set A âŠ‚RN we have f âˆ’1(A) âˆˆE.
(ii) For any closed set F âŠ‚RN we have f âˆ’1(F) âˆˆE.
(iii) For any Borel set B âŠ‚RN we have f âˆ’1(B) âˆˆE.
In general, not every function is E-measurable. However, since E is a
Ïƒ-algebra, one can prove that the algebraic manipulations as well as the
pointwise limits of E-measurable functions always result in E-measurable
functions. For instance, if f and g are E-measurable and Î± âˆˆR, then the
functions
f + g,
fg,
1
f ,
Î±f,
|f |,
max(f, g),
min(f, g)
are E-measurable. Moreover, let

fn

be a sequence of E-measurable functions.
Then:
â€¢ The functions
sup
n
fn(x),
inf
n fn(x),
lim inf
nâ†’âˆfn(x),
lim sup
nâ†’âˆ
fn(x)
are E-measurable.

282
APPENDIX B
â€¢ Let E âŠ‚ be the set
E :=

x âˆˆ
 âˆƒlim
nâ†’âˆfn(x)

and let f (x) := limnâ†’âˆfn(x), x âˆˆE. Then E âˆˆE and for any t âˆˆR we
have {x âˆˆE | f (x) > t} âˆˆE.
Recalling that a function Ï† : X â†’Y between metric spaces is continuous
if and only if for any open set A âŠ‚Y the set Ï†âˆ’1(A) âŠ‚X is open, we get
immediately the following:
â€¢ Continuous functions g : RN â†’Rm are B(RN)-measurable,
â€¢ Let f :  â†’RN be E-measurable and let Ï† : RN â†’Rm be B(RN)-
measurable, then Ï† â—¦f is E-measurable.
In particular, (ii) implies that |f |p, log |f |, . . . are E-measurable functions if f is
E-measurable and that f :  â†’RN, f = (f 1, . . . , f N) is E-measurable if and
only if its components f 1, . . . , f N are E-measurable.
Let (E, P) be a measure on . A simple function Ï• :  â†’R is a function
with a ï¬nite range and E-measurable level sets, that is,
Ï•(x) =
k

j=1
ajÏ‡Ej (x),
Ej :=

x | Ï•(x) = aj

âˆˆE.
The class of simple functions will be denoted by S. Simple functions being linear
combinations of E-measurable functions are E-measurable.
Proposition B.20 (Sampling) Let E be a Ïƒ-algebra of subsets of a set . A
non-negative function f :  â†’R+ is E-measurable if and only if there exists a
nondecreasing sequence

Ï•k

of non-negative simple functions such that Ï•k(x) â†‘
f (x) âˆ€x âˆˆ.
Proof. Let f be the pointwise limit of a sequence

Ï•k

of simple functions.
Since every Ï•k is E-measurable, then f is E-measurable.
Conversely, let f :  â†’R be a function. By sampling f , we then construct
a sequence

Ï•k

of functions with ï¬nite range approaching f , see Figure B.1.
More precisely, let Ek :=

x | f (x) > 2k
and for h = 0, 1, , . . . 4k âˆ’1, let
Ek,h :=

x | h/2k < f (x) â‰¤(h + 1)/2k
.
Deï¬ne Ï•k :  â†’R as
Ï•k(x) =

2k
if x âˆˆEk,
h
2k
if x âˆˆEk,h.
(B.14)
By deï¬nition, Ï•k(x) â‰¤f (x), moreover, Ï•k(x) â‰¤Ï•k+1(x) âˆ€x âˆˆ, since
passing from k to k + 1 we half the sampling intervals. Let us prove that
Ï•k(x) â†’f (x) âˆ€x. If f (x) = +âˆ, then Ï•k(x) = 2k âˆ€k, hence Ï•k(x) â†’+âˆ=

APPENDIX B
283
f (x). If f (x) < +âˆ, then for sufï¬ciently large k, f (x) â‰¤2k, hence there exists
h âˆˆ

0, . . . , 4k âˆ’1

such that x âˆˆEk,h. Therefore,
f (x) âˆ’Ï•k(x) â‰¤h + 1
2k
âˆ’h
2k = 1
2k .
Passing to the limit as k â†’âˆwe get again Ï•k(x) â†’f (x).
The previous construction applies to any non-negative function f :  â†’R+.
To conclude, notice that if f is E-measurable, then the sets Ek and Ek,h are
E-measurable for every k, h. Since
Ï•k(x) =
4kâˆ’1

h=0
h
2k Ï‡Ek,h(x) + 2kÏ‡Ek(x)
âˆ€x âˆˆ,
Ï•k is a simple function.
B.2.2
The integral
Let (E, P) be a measure on . For any simple function Ï• :  â†’R, one deï¬nes
the integral of Ï• with respect to the measure (E, P) as
I(Ï•) :=
k

j=1
ajP(Ï• = aj),
(B.15)
as intuition suggests. Since a priori P(Ï• = aj) may be inï¬nite, we adopt the
convention that ajP(Ï• = aj) := 0 if aj = 0. Notice that the integral may be
inï¬nite.
We then deï¬ne the integral of a non-negative E-measurable function with
respect to (E, P) as
*

f (x) P(dx) := sup

I(Ï•)
 Ï• simple, Ï•(x) â‰¤f (x) âˆ€x âˆˆ

.
(B.16)
For a generic E-measurable function f :  â†’R, decompose f as f (x) =
f+(x) âˆ’fâˆ’(x) where
f+(x) := max(f (x), 0),
fâˆ’(x) := max(âˆ’f (x), 0),
and deï¬ne
*

f (x) P(dx) :=
*

f+(x) P(dx) âˆ’
*

fâˆ’(x) P(dx)
(B.17)
provided that at least one of the integrals on the right-hand side of (B.17) is
ï¬nite. In this case one says that f is integrable with respect to (E, P). If both
the integrals on the right-hand side of (B.17) are ï¬nite, then one says that f
is summable. Notice that for functions that do not change sign, integrability is
equivalent to measurability.

284
APPENDIX B
Since |f (x)| = f+(x) + fâˆ’(x) and f+(x), fâˆ’(x) â‰¤|f (x)|, it is easy to check
that if f is E-measurable then so is |f |, and f is summable if and only if f is
E-measurable and
.
|f (x)| P(dx) < +âˆ. Moreover,

*

f (x) P(dx)
 â‰¤
*

|f (x)| P(dx).
The class of summable functions will be denoted by L1(, E, P) or simply by
L1() when the measure is understood.
When  = Rn, one refers to the integral with respect to the Lebesgue measure
(B(Rn), Ln) in (B.17) as the Lebesgue integral.
Finally, let f :  â†’R be a function and let E âˆˆE. One says that f is
measurable on E, integrable on E, and summable on E if f (x)Ï‡ E(x) is E-
measurable, integrable, and summable, respectively. If f is integrable on E,
one sets
*
E
f (x) P(dx) :=
*

f (x)Ï‡E(x) P(dx).
(B.18)
In particular,
*
E
1 P(dx) =
*

Ï‡E(x)dx = P(E).
B.2.3
Properties of the integral
From the deï¬nition of integral with respect to the measure (E, P) and taking also
advantage of the Ïƒ-additivity of the measure one gets the following.
Theorem B.21 Let (E, P) be a measure on .
(i) For any c âˆˆR and f integrable on E, we have
.
E c f (x) P(dx) =
c
.
E f (x) P(dx).
(ii) (Monotonicity) Let f, g be two integrable functions such that f (x) â‰¤g(x)
âˆ€x âˆˆ. Then
*

f (x) P(dx) â‰¤
*

g(x) P(dx).
(iii) (Continuity, the Beppo Levi theorem) Let

fk

be a nondecreasing
sequence of non-negative E-measurable functions fk :  â†’R+ and
let f (x) := limkâ†’âˆfk(x) be the pointwise limit of the fkâ€™s. Then f is
integrable and
*

f (x) P(dx) = lim
kâ†’âˆ
*

fk(x) P(dx).
(B.19)
(iv) (Linearity) L1 is a vector space and the integral is a linear operator on it:
for f, g âˆˆL1 and Î±, Î² âˆˆR we have
*

(Î±f (x) + Î²g(x)) P(dx) = Î±
*

f (x) P(dx) + Î²
*

g(x) P(dx).

APPENDIX B
285
A few comments on the Beppo Levi theorem are appropriate. Notice that the
measurability assumption is on the sequence

fk

. The measurability of the limit
f is for free, thanks to the fact that E is a Ïƒ-algebra. Moreover, the integrals in
(B.19) may be inï¬nite, and the equality is in both directions: we can compute
one side of the equality in (B.19) and conclude that the other side has the same
value. The Beppo Levi theorem is of course strictly related to the continuity
property of measures, and at the end, to the Ïƒ-additivity of measures.
Proof of theorem B.21. (i) and (ii) are trivial.
(iii) Let us prove the Beppo Levi theorem. Since f is the pointwise limit of
E-measurable functions, f is E-measurable. Moreover, since fk(x) â‰¤f (x) for
any x âˆˆ and every k, from (i) we infer limkâ†’âˆ
.
 fk P(dx) â‰¤
.
 f P(dx).
We now prove the opposite inequality
*

f (x) P(dx) â‰¤Î± := lim
kâ†’âˆ
*

fk(x) P(dx).
Assume without loss of generality that Î± < +âˆ. Let Ï† be a simple function,
Ï† = N
i=1 aiÏ‡Bi, Bi =

x | Ï†(x) = ai

âˆˆE, such that Ï† â‰¤f and let Î² be a real
number, 0 < Î² < 1. For k = 1, 2, . . . set
Ak :=

x âˆˆ
 fk(x) â‰¥Î² Ï†(x)

.

Ak

is a nondecreasing sequence of measurable sets such that âˆªkAk = . Hence,
from (B.15) and the continuity property of measures
*
Ak
Ï†(x) P(dx) =
N

i=1
aiP(Bi âˆ©Ak) â†’
N

i=1
aiP(Bi) =
*
Ï†(x) P(dx)
as k â†’âˆ. On the other hand, for any k we have
Î²
*
Ak
Ï†(x) P(dx) =
*
Ak
Î² Ï†(x) P(dx) â‰¤
*
Ak
fk(x) P(dx)
â‰¤
*

fk(x) P(dx) â‰¤Î±.
(B.20)
Therefore, passing to the limit ï¬rst as k â†’âˆin (B.20) and then letting Î² â†’1âˆ’
we get
*

Ï†(x) P(dx) â‰¤Î±.
Since the previous inequality holds for any simple function Ï† below f , the
deï¬nition of integral yields
.
 f (x) P(dx) â‰¤Î±, as required.
(iv) We have already proved the linearity of the integral on the class of simple
functions, see Proposition 2.28. To prove (iv), it sufï¬ces to approximate f and g
by simple functions, see Proposition B.20, and then pass to the limit using (iii).

286
APPENDIX B
We conclude with a few simple consequences.
Proposition B.22 Let (E, P) be a measure on .
(i) Let E âˆˆE have ï¬nite measure and let f : E â†’R be an integrable function
on E âˆˆE such that |f (x)| â‰¤M for any x âˆˆE. Then f is summable on E
and
.
E |f | P(dx) â‰¤M P(E).
(ii) Let E, F âˆˆE and let f : E âˆªF â†’R be an integrable function on E âˆªF.
Then f is integrable both on E and F and
*
E
f (x) P(dx) +
*
F
f (x) P(dx)
=
*
EâˆªF
f (x) P(dx) +
*
Eâˆ©F
f (x) P(dx).
(B.21)
B.2.4
Cavalieri formula
Theorem B.23 (Cavalieri formula) Let (E, P) be a measure on . For any
non-negative E-measurable function f :  â†’R+ we have
*

f (x) P(dx) = (Riemann)
* âˆ
0
P(f > t) dt.
(B.22)
As usual, we shorten the notation P({x âˆˆ | f (x) > t}) to P(f > t).
Proof. Let us prove the claim for non-negative simple functions. Assume
Ï•(x) = N
i=1 aiÏ‡Ei(x), where the sets

Ei

are measurable and pairwise disjoint.
For i = 1, . . . , N let Î±i(t) := 1[0,ai](t). For the piecewise (hence simple) function
t â†’P(Ï• > t) we have
P(Ï• > t) =
N

i=1
P(Ei âˆ©{Ï• > t}) =
N

i=1
Î±i(t)P(Ei)
hence, integrating with respect to t
* âˆ
0
P(Ï• > t) dt =
N

i=1
 * âˆ
0
Î±i(t) dt

P(Ei)
=
N

i=1
aiP(Ei) =
*
Ï•(x) P(dx).
Assume now f :  â†’R is non-negative and E-measurable. Proposition B.20
yields a nondecreasing sequence

Ï•k

of non-negative simple functions such that

APPENDIX B
287
Ï•k(x) â†‘f (x) pointwisely. As shown before, for each k = 1, 2, . . .
*

Ï•k(x) P(dx) =
* âˆ
0
P(Ï•k > t)dt.
Since Ï•k â†‘f (x) and P(Ï•k > t) â†‘P(f > t) as k goes to âˆ, we can pass to the
limit in the previous equality using the Beppo Levi theorem to get
Lebesgue
*

f (x) P(dx) = Lebesgue
* âˆ
0
P(f > t) dL1(t).
The claim then follows, since t â†’P(f > t), being nondecreasing, is Riemann
integrable and Riemann and Lebesgue integrals of Riemann integrable functions
coincide.
Corollary B.24 Let f :  â†’R be integrable and for any t âˆˆR, let F(t) :=
P(f â‰¤t). Then
*

f (x) P(dx) =
* +âˆ
0
(1 âˆ’F(t)) dt âˆ’
* 0
âˆ’âˆ
F(t) dt.
Proof. Apply (B.22) to the positive and negative parts of f and sum the
resulting equalities.
B.2.5
Markov inequality
Let (E, P) be a measure on . From the monotonicity of the integral one deduces
that for any non-negative measurable function f :  â†’R we have the inequality
t P(f > t) =
*
{f > t}
t P(dx) â‰¤
*
{f > t}
f (x) P(dx)
âˆ€t â‰¥0
i.e.
P(f > t) â‰¤1
t
*
{f > t}
f (x) P(dx)
âˆ€t > 0.
(B.23)
This last inequality has different names: Markov inequality, weak estimate or
Chebyshev inequality.
B.2.6
Null sets and the integral
Let (E, P) be a measure on .
Deï¬nition B.25 We
say that a set N âŠ‚ is a null set if there exists F âˆˆE
such that N âŠ‚F and P(F) = 0. We say that a predicate p(x), x âˆˆ, is true for

288
APPENDIX B
P-almost every x or P-a.e., and we write â€˜p(x) is true a.e.â€™ if the set
N :=

x âˆˆ
 p(x) is false

is a null set.
In particular, given an E-measurable function f :  â†’R, we say that â€˜f = 0
P-a.e.â€™ or that â€˜f (x) = 0 for P-almost every x âˆˆâ€™ if the set {x âˆˆ | f (x) Ì¸= 0}
has zero measure,
P

x âˆˆ
 f (x) Ì¸= 0

= 0.
Similarly, one says that â€˜|f | â‰¤M P-a.e.â€™ or that â€˜|f (x)| â‰¤M for P-almost
every xâ€™, if P({x âˆˆ | |f (x)| > M}) = 0. From the Ïƒ-additivity of the measure,
we immediately get the following.
Proposition B.26 Let (E, P) be a measure on  and let f :  â†’R be a
E-measurable function.
(i) If
.
 |f (x)| P(dx) < âˆ, then |f (x)| < +âˆP-a.e.
(ii)
.
 |f (x)| P(dx) = 0 if and only if f (x) = 0 for P-almost every x âˆˆ.
Proof. (i) Let C :=
.
 |f (x)| P(dx). Markov inequality yields for any posi-
tive integer k
P

x âˆˆ
 f (x) = +âˆ

â‰¤P

x âˆˆ
 f (x) > k

â‰¤C
k
Hence, passing to the limit as k â†’âˆwe infer that P({x âˆˆ | f (x) =
+âˆ}) = 0.
(ii) If f (x) = 0 for almost every x âˆˆ, then every simple function Ï• such that
Ï• â‰¤|f |, is nonzero on at most a null set. Thus
.
 Ï•(x) P(dx) = 0 and, by the
deï¬nition of the integral of |f |,
.
 |f (x)| P(dx) = 0.
Conversely, from the Markov inequality we get for any positive integer k
k P

x âˆˆ
 |f (x)| > 1/k

â‰¤
*

|f (x)| P(dx) = 0
so that P({x âˆˆ | |f (x)| > 1/k}) = 0. Since

x âˆˆ
 |f (x)| > 0

=
(
k

x âˆˆ
 |f (x)| > 1/k

,
passing to the limit as k â†’âˆthanks to the continuity property of the measure,
we conclude that P({x âˆˆ | |f (x)| > 0}) = 0, i.e. |f (x)| = 0 P-a.e.

APPENDIX B
289
B.2.7
Push forward of a measure
Let (E, P) be a measure on  and let f :  â†’RN be an E-measurable function.
Since inverse images of Borel sets are E-measurable, we deï¬ne a set function
Pf : B(RN) â†’[0, 1] on RN, also denoted by f#P, by
Pf (A) = f#P(A) := P(f âˆ’1(A))
âˆ€A âˆˆB(RN),
(B.24)
called the pushforward or image of the measure P. It is easy to check the
following.
Proposition B.27 (B(RN), f#P) is a measure on RN and for every non-negative
Borel function Ï• on RN we have
*
RN Ï•(t) f#P(dt) =
*

Ï•(f (x)) P(dx).
(B.25)
Proof. We essentially repeat the proof of Theorem 3.9. For the readerâ€™s con-
venience, we outline it again.
The Ïƒ-additivity of f#P follows from the Ïƒ-additivity of P using the De Mor-
gan formulas and the relations
f âˆ’1(âˆªiAi) = âˆªif âˆ’1(Ai),
f âˆ’1(âˆ©iAi) = âˆ©if âˆ’1(Ai),
which are true for any family of subsets

Ai

of RN.
In order to prove (B.25), we ï¬rst consider the case in which Ï• is a simple
function, Ï•(t) = n
i=1 ci1Ei(t) where c1, . . . , cn are distinct constants and the
level sets Ei :=

t | Ï•(t) = ci

, i = 1, . . . , n, are measurable. Then
Ï• â—¦f (x) =
n

i=1
ci1f âˆ’1(Ei)(x),
f âˆ’1(Ei) =

x âˆˆ | Ï• â—¦f (x) = ci

so that
*
RN g(t) f#P(dt) =
n

i=1
cif#P(Ei)
=
n

i=1
ci P(Ï• â—¦f = ci) =
*

Ï•(f (x)) P(dx),
i.e. (B.25) holds when Ï• is simple.
Let now Ï• be a non-negative measurable function. Proposition B.20 yields
an increasing sequence

Ï•k

of simple functions pointwisely converging to Ï•.

290
APPENDIX B
Since for every k we have already proved that
*
RN Ï•k(t) f#P(dt) =
*

Ï•k(f (x)) P(dx)
we can pass to the limit as k â†’âˆand take advantage of the Beppo Levi theorem
to get (B.25).
Pushforward of measures can be composed. Let (E, P) be a measure on ,
let f :  â†’RN be E-measurable and let g : RN â†’RM be B(RN)-measurable.
Then from (B.24) we infer
(g â—¦f )#P(A) = g#(f#P(A)) =: (g# â—¦f#)P(A)
âˆ€A âˆˆB(RM).
(B.26)
From (B.25) we infer the following relations for the associated integrals
*
RM Ï•(t) (g â—¦f )#P(dt) =
*

Ï•(g(f (x))) P(dx) =
*
RN Ï•(g(s)) f#P(ds)
(B.27)
for
every
non-negative,
B(RM)-measurable
function
Ï• : RM â†’R,
see
Theorem 4.6.
B.2.8
Exercises
Exercise B.28 Let E be a Ïƒ-algebra of subsets of a set  and let f, g :  â†’R
be E-measurable. Then {x âˆˆ | f (x) > g(x)} âˆˆE.
Solution. For any rational number r âˆˆQ, the set Ar := {x âˆˆ | f (x) >
r, g(x) < r} belongs to E. Moreover,

x âˆˆE
 f (x) > g(x)

=
(
râˆˆQ
Ar.
Thus {x âˆˆE | f (x) > g(x)} is a denumerable union of sets in E.
Exercise B.29 Let E be a Ïƒ-algebra of subsets of a set , let E âˆˆE and let
f, g :  â†’R be two E-measurable functions. Then the function
h(x) :=

f (x)
if x âˆˆE,
g(x)
if x âˆˆEc
is E-measurable.
Exercise B.30 Let E be a Ïƒ-algebra of subsets of a set , let f :  â†’R be
E-measurable and let E âˆˆE be such that P(E) < âˆ. Then P(E âˆ©{f = t}) Ì¸= 0
for at most a denumerable set of tâ€™s.
Exercise B.31 Show that if Ï• is a simple function, then
.
 Ï•(x) P(dx) = I(Ï•).

APPENDIX B
291
Exercise B.32 (Discrete value functions) Let (E, P) be a measure on a set .
Let X :  â†’R be an E-measurable non-negative function with discrete values,
i.e. X() is a countable set

ak

. Give an explicit formula for
.
 X(x) P(dx).
Solution. Let Ek :=

x âˆˆ | X(x) = ak

. Then
X(x) =
âˆ

j=1
aj1Ej (x)
âˆ€x âˆˆ.
Given x, the series has only one addendum since only one set Ej contains x.
If X has a ï¬nite range, then X is a simple function so that by deï¬nition
*

X(x) P(dx) =
k

j=1
ajP(X = aj).
(B.28)
If X() is denumerable, then for any non-negative integer k we have
*

k

j=1
aj1Ej (x) P(dx) =
k

j=1
ajP(X = aj).
Since X is non-negative, we can apply the Beppo Levi theorem and, as k â†’âˆ,
we get
*

X(x) P(dx) = lim
kâ†’âˆ
*


k

j=1
aj1Ej (x)

P(dx)
= lim
kâ†’âˆ
k

j=1
ajP(X = aj) =
âˆ

j=1
ajP(X = aj).
(B.29)
Formula (B.29) can also be written as
*

X(x) P(dx) =

tâˆˆR
tP(X = t)
(B.30)
since P(X = t) = 0 if t /âˆˆ

ak

.
Exercise B.33 Let (E, P) be a measure on a set  and let X :  â†’R be an
E-measurable non-negative function with discrete values and such that +âˆâˆˆ
X(). Give an explicit formula for
.
 X(x) P(dx).
Solution. Let

ak

âˆª{+âˆ} be the range of X. For k â‰¥1, let Ek := {x |
X(x) = ak}, so that
âˆ
(
k=1

x âˆˆ | X = ak

= {x âˆˆ | X < +âˆ}

292
APPENDIX B
and X(x) = âˆ
j=1 aj1Ej (x) if X(x) < +âˆ. From Exercise B.32,
âˆ

i=1
aiP(X = ai) =
*
{X<+âˆ}
X(x) P(dx).
Moreover,
*
{X=+âˆ}
X(x) P(dx) =
lim
kâ†’+âˆk P(X = +âˆ)
=

0
if P(X = +âˆ) = 0,
+âˆ
if P(X = +âˆ) > 0.
Thus
*

X(x) P(dx) =
âˆ
i=1 aiP(X = ai)
if P(X = +âˆ) = 0,
+âˆ
if P(X = +âˆ) > 0.
Exercise B.34 (Integral on countable sets) Let (E, P) be a measure on a ï¬nite
or denumerable set . Denote by p :  â†’R, p(x) := P({x}), its mass den-
sity. Let X :  â†’R be a non-negative function. Give an explicit formula for
.
 X(x) P(dx).
Solution. Let

aj

be the range of X. By (B.29)
*

X(x) P(dx) =
âˆ

j=0
ajP(X = aj) =
âˆ

j=0
aj


X(x)=aj
p(x)

=
âˆ

j=0

X(x)=aj
X(x)p(x) =

xâˆˆ
X(x)p(x).
Exercise B.35 (Dirac delta) Let  be a set and let x0 âˆˆ. The set function
Î´x0 : P() â†’R such that
Î´x0(A) =

1
if x0 âˆˆA,
0
otherwise,
is called the Dirac delta [named after Paul Dirac (1902â€“1984)] at x0, and is a
probability measure on . Prove that for any X :  â†’R,
*

X(x) Î´x0(dx) = X(x0).
(B.31)
Exercise B.36 (Sum of measures) Let (E, Î±) and (E, Î²) be two measures on 
and let Î», Î¼ âˆˆR+.

APPENDIX B
293
(i) Show that Î»Î± + Î¼Î² : E â†’R+ deï¬ned by (Î»Î± + Î¼Î²)(E) := Î»Î±(E) +
Î¼Î²(E) âˆ€E âˆˆE is such that (E, Î»Î± + Î¼Î²) is a measure on .
(ii) Show that for amy E-measurable non-negative function f :  â†’R+
*

f (x) (Î»Î± + Î¼Î²)(dx) = Î»
*

f (x) Î±(dx) + Î¼
*

f (x) Î²(dx). (B.32)
Solution. We ï¬rst consider the case when f is a non-negative simple function:
f = N
i=1 ciÏ‡Ei where Ei =

x âˆˆ | f = ci

, ci â‰¥0. Thus
*

f (x) (Î»Î± + Î¼Î²)(dx) =
n

i=1
ci(Î»Î± + Î¼Î²)(f = ci)
= Î»
n

i=1
ciÎ±(f = ci) + Î¼
n

i=1
ciÎ²(f = ci)
= Î»
*

f (x) Î±(dx) + Î¼
*

f (x) Î²(dx).
When f is an E-measurable non-negative function, we approximate it from below
with an increasing sequence

Ï•k

of simple functions that pointwise converges
to f (x). Since any Ï•k is simple, we have
*

Ï•k(x) (Î»Î± + Î¼Î²)(dx) = Î»
*

Ï•k(x) Î±(dx) + Î¼
*

Ï•k(x) Î²(dx).
Letting k â†’+âˆand taking advantage of the Beppo Levi theorem we get (B.32).
Example B.37 (Counting measure) Let  be a set. Given a subset A âŠ‚ let
H0(A) := |A| be the cardinality of A. It is easy to see that (P(), H0) is a
measure on , called counting measure. Clearly,
H0(A) =

xâˆˆA
1,
where the sum on the right-hand side is +âˆif A has inï¬nite many points. The
corresponding integral is
*

f (x) H0(dx) =

xâˆˆ
f (x).
The formula above is obvious if f is nonzero on a ï¬nite set only and can be
proven by passing to the limit and taking advantage of the Beppo Levi theorem
in the general case.

294
APPENDIX B
Exercise B.38 (Absolutely continuous measures) Let (B(R), P) be an absolutely
continuous measure with respect to the Lebesgue measure, i.e. assume there exists
a summable function Ï : R â†’R+ such that
P(A) =
*
A
Ï(t) dt
âˆ€A âˆˆB(R).
Show that, for any non-negative B(R)-measurable function f ,
*
R
f (x) P(dx) =
*
R
f (x)Ï(x) dx.
(B.33)
Solution. Assume f is simple, i.e. f (x) = n
i=1 ci1Ei(x), Ei = {x | f (x) =
ci} âˆˆE. Then
*
R
f (x) P(dx) =
n

i=1
ciP(f = ci) =
n

i=1
ci
*
R
1Ei(x)Ï(x) dx
=
*
R

n

i=1
ci1Ei(x)

Ï(x) dx =
*
R
f (x)Ï(x) dx.
The general case can be proven by an approximation argument, using Propo-
sition B.20 and the Beppo Levi theorem.
B.3
Product measures and iterated integrals
B.3.1
Product measures
Let (E, P) and (F, Q) be measures on two sets X and Y, respectively. Denote
by I the family of all â€˜rectanglesâ€™ in the Cartesian product X Ã— Y
I :=

A = E Ã— F
 E âˆˆE, F âˆˆF

and let Î¶ : I â†’R+ be the set function that maps any rectangle A Ã— B âˆˆI into
Î¶(A Ã— B) := P(A)Q(B). The following can be easily shown.
Proposition B.39 I is a semiring and Î¶ : I â†’R is a Ïƒ-additive set function.
Proof. It is quite trivial to show that I is a semiring. In fact, if E := A Ã— B
and F := C Ã— D âˆˆI, then E âˆ©F = (A âˆ©C) Ã— (B âˆ©D) and
E \ F =

(A \ C) Ã— (B \ D)

âˆª

(A âˆ©C) Ã— (B \ D)

âˆª

(A \ C) Ã— (B âˆ©D)

.

APPENDIX B
295
Let us prove that Î¶ is Ïƒ-additive. Let E Ã— F = âˆªk(Ek Ã— Fk), E, Ek âˆˆE,
F, Fk âˆˆF be such that the sets

Ek Ã— Fk

are pairwise disjoint so that
Ï‡E(x) Ï‡F(y) =
âˆ

k=1
Ï‡Ek(x)Ï‡Fk(y)
âˆ€x âˆˆX, y âˆˆY.
Integrating with respect to Q on Y and applying the Beppo Levi theorem, we
obtain
Ï‡E(x) Q(F) =
âˆ

k=1
Q(Fk)Ï‡Ek(x)
âˆ€x âˆˆX.
Moreover, integrating with respect to P on X and again by the Beppo Levi
theorem we get
Î¶(E Ã— F) := P(E)Q(F) =
âˆ

k=1
P(Ek)Q(Fk).
Thus, see Theorem B.10, Î¶ extends to a measure denoted (G, P Ã— Q) on the
smallest Ïƒ-algebra G containing I. This measure is called the product measure of
(E, P) and (F, Q). Moreover, such an extension is unique, provided Î¶ : I â†’R+
is Ïƒ-ï¬nite, see Theorem B.6. This happens in particular, if both (E, P) and (F, Q)
are Ïƒ-ï¬nite.
Of course one can consider the product of ï¬nitely many measures. Taking for
instance the product of n Bernoulli trials, one obtains the Bernoulli distribution
on {0, 1}n
Ber(n, p) = B(1, p) Ã— Â· Â· Â· Ã— B(1, p).
B.3.1.1
Inï¬nite Bernoulli process
Let (, E, P) be a probability measure on . Consider the set âˆ= -âˆ
i=1 
of -valued sequences, and consider the family C âŠ‚P(âˆ) of sets E âŠ‚âˆof
the form
E =
âˆ
=
i=1
Ei
where Ei âˆˆE âˆ€i and Ei =  except for a ï¬nite number of indexes, i.e. the family
of â€˜cylindersâ€™ with the terminology of Section 2.2.7. Deï¬ne also Î± : C â†’[0, 1]
by setting for E = -âˆ
i=1 Ei âˆˆC,
Î±(E) =
âˆ
=
i=1
P(Ei).
Notice that the product is actually a ï¬nite product, since P(Ei) = 1 except for a
ï¬nite number of indexes.

296
APPENDIX B
The following theorem holds. The interested reader may ï¬nd a proof in,
e.g. [7].
Theorem B.40 (Kolmogorov) C is a semiring and Î± is Ïƒ-additive on C.
Therefore, Theorem B.6 and B.10 apply so that there exists a unique proba-
bility measure (E, Pâˆ) on âˆthat extends Î± to the Ïƒ-algebra generated by C.
The existence and uniqueness of the Bernoulli distribution of parameter p
introduced in Section 2.2.7 is a particular case of the previous statement. One
obtains it by choosing the Bernoulli trial distribution B(1, p) on {0, 1} as starting
probability space (, E, P).
B.3.2
Reduction formulas
Let A âŠ‚X Ã— Y. For any point x âˆˆA let Ax be the subset of Y deï¬ned as
Ax :=

y âˆˆY
 (x, y) âˆˆA

.
Ax is called the section of A at x.
Theorem B.41 (Fubini) Let X, Y be two sets and let (G, P Ã— Q) be the product
measure on X Ã— Y of the two Ïƒ-ï¬nite measures (E, P) and (F, Q) on X and Y,
respectively. Then, for any A âˆˆG the following hold:
(i) Ax âˆˆF P-a.e. x âˆˆX.
(ii) x â†’Q(Ax) is an E-measurable function.
(iii) (P Ã— Q)(A) =
.
X Q(Ax) P(dx).
Changing the roles of the two variables, one also has:
(iv) Ay âˆˆE Q-a.e. y âˆˆY.
(v) y â†’P(Ay) is an F-measurable function.
(vi) (P Ã— Q)(A) =
.
Y P(Ay) Q(dy).
From the Fubini theorem, Theorem B.41, one obtains the following reduction
formulas.
Theorem B.42 (Fubiniâ€“Tonelli) Let (E, P) and (F, Q) be two Ïƒ-ï¬nite mea-
sures on the sets X and Y, respectively, and let (G, P Ã— Q) be the product measure
on X Ã— Y. Let f : X Ã— Y â†’R be G-measurable and non-negative (respectively,
P Ã— Q summable). Then the following hold:
(i) y â†’f (x, y) is F-measurable (respectively, Q-summable) P-a.e. x âˆˆX.
(ii) x â†’
.
Y f (x, y) Q(dy) is E-measurable (respectively, P-summable).

APPENDIX B
297
(iii) We have
*
XÃ—Y
f (x, y) P Ã— Q(dx dy) =
*
X
P(dx)
*
Y
f (x, y) Q(dy).
Of course, the two variables can be interchanged, so under the same assumption
of Theorem B.42 we also have:
(i) x â†’f (x, y) is E-measurable (respectively, P-summable) Q-a.e. y âˆˆY.
(ii) y â†’
.
X f (x, y) P(dx) is F-measurable (respectively, Q-summable).
(iii) We have
*
XÃ—Y
f (x, y) P Ã— Q(dx dy) =
*
Y
Q(dy)
*
X
f (x, y) P(dx).
Proof. The proof is done in three steps.
(i) If f is the characteristic function of a P Ã— Q measurable set, then we apply
the Fubini theorem, Theorem B.41. Because of additivity, the result still
holds true for any G-measurable simple function f .
(ii) If f is non-negative, then f can be approximated from below by an increas-
ing sequence of simple functions. Applying the Beppo Levi theorem and
the continuity of measures, the result holds true for f .
(iii) If f is P Ã— Q summable, then one applies the result of Step (ii) to the
positive and negative parts f+ and fâˆ’of f .
Notice that the ï¬niteness assumption on the two measures (E, P) and (F, Q)
in Theorems B.41 and B.42 cannot be dropped as the following example shows.
Example B.43 Let X = Y = R, P = L1, and let Q be the measure that counts the
points: Q(A) = |A|. Let S := {(x, x) | x âˆˆ[0, 1]} and let f (x, y) = Ï‡S(x, y) be
its characteristic function. S is closed, hence S belongs to the smallest Ïƒ-algebra
generated by â€˜intervalsâ€™, i.e. B(R2). Clearly (P Ã— Q)(S) = âˆ, but
*
R
P(dx)
*
R
f (x, y) Q(dy) =
* 1
0
1 dx = 1,
*
R
Q(dy)
*
R
f (x, y) P(dx) =
* 1
0
0 dQ = 0.
B.3.3
Exercises
Exercise B.44 Show that Ln Ã— Lk = Ln+k on the Borel sets of Rn Ã— Rk.

298
APPENDIX B
Exercise B.45 Let (E, P) be a measure on  and let f :  â†’R+ be a P-
measurable function. Show that the subgraph of f
SGf :=

(x, t) âˆˆ Ã— R
 0 < t < f (x)

is P Ã— L1-measurable and
P Ã— L1(SGf ) =
*

f (x) P(dx).
[Hint. Prove the claim for simple functions and use an approximation argument
for the general case.]
B.4
Convergence theorems
B.4.1
Almost everywhere convergence
Deï¬nition B.46 Let
(E, P) be a measure on  and let

Xn

and X be
E-measurable functions.
(i) We say that

Xn

converges in measure to X, if for any Î´ > 0
P

x
 |Xn âˆ’X| > Î´

â†’0
as n â†’âˆ.
(ii) We say that

Xn

converges to X almost everywhere, and we write Xn â†’X
P-a.e., if the measure of the set
E : =

x
 X(x) = Â±âˆo Xn(x) Ì¸â†’X(x)

=

x
 lim sup
nâ†’âˆ
|Xn(x) âˆ’X(x)| > 0
$
is null, P(E) = 0.
The difference between the above deï¬ned convergences becomes clear if one
ï¬rst considers the following sets, which can be constructed starting from a given
sequence of sets

An

; namely, the sets
lim sup
n
An :=
âˆ
'
m=1
âˆ
(
n=m
An
and
lim inf
n
An :=
âˆ
(
m=1
âˆ
'
n=m
An
In the following proposition we collect the elementary properties of such sets.
Proposition B.47 We have the following:
(i) x âˆˆlim infn An if and only if there exists n such that x âˆˆAn âˆ€n â‰¥n.

APPENDIX B
299
(ii) x âˆˆlim supn An if and only if there exists inï¬nite values of n such that
x âˆˆAn.
(iii) x âˆˆ(lim supn An)c if and only if

n | x âˆˆAn

is ï¬nite.
(iv) (lim supn An)c = lim infn Ac
n.
(v) Let E be a Ïƒ-algebra of subsets of . If

An

âŠ‚E, then both lim infn An
and lim supn An are E-measurable. Moreover,
P(lim inf
n
An) â‰¤lim inf
nâ†’âˆP(An) â‰¤lim sup
nâ†’âˆ
P(An) â‰¤P(lim sup
n
An).
Proof. (i) and (ii) agree with the deï¬nitions of lim infn An and lim supn An,
respectively. (iii) is a rewrite of (ii) and (iv) is a consequence of De Moivre for-
mulas. To prove (v) it sufï¬ces to observe that the E-measurability of lim infn An
and lim supn An comes from the properties of Ïƒ-algebras and that the inequality
in (v) is a consequence of the continuity of measures.
Let (E, P) be a measure on  and let

Xn

and X be E-measurable functions.
Given any Î´ â‰¥0, deï¬ne
An,Î´ :=

x âˆˆ
 |Xn(x) âˆ’X(x)| > Î´

,
EÎ´ :=

x âˆˆ
 lim sup
nâ†’âˆ
|Xn(x) âˆ’X(x)| > Î´
$
.
Since x âˆˆEÎ´ if and only if there exists a sequence

kn

such that |Xkn(x) âˆ’
X(x)| > Î´, then
EÎ´ = lim sup
n
An,Î´
âˆ€Î´ â‰¥0.
(B.34)
Proposition B.48 Let
(E, P) be a measure on  and let

Xn

and X be E-
measurable functions. With the notation above,

Xn

converges to X in measure
if and only if P(An,Î´) â†’0 as n â†’âˆfor any positive Î´. Moreover, the following
are equivalent:
(i) Xn â†’X P-a.e.
(ii) P(lim supn An,0) = 0.
(iii) P(lim supn An,Î´) = 0 for any Î´ > 0.
Proof. By deï¬nition, Xn â†’X P-a.e. if and only if P(E0) = 0. For any Î´ â‰¥0,
EÎ´ âŠ‚E0 = âˆªÎ´ > 0EÎ´, hence P(E0) = 0 if and only if P(EÎ´) = 0 for any Î´ > 0.
The claim follows from (B.34).
Convergence in measure and almost everywhere convergence are not equiv-
alent, see Example 4.76. Nevertheless, the two convergences are related, as the
following proposition shows.

300
APPENDIX B
Proposition B.49 Let (E, P) be a measure on  and let

Xn

and X be E-
measurable functions on . Then:
(i) If Xn â†’X P-a.e., then Xn â†’X in measure.
(ii) If Xn â†’X in measure, then there exists a subsequence

Xkn

of

Xn

such
that Xkn â†’X P-a.e.
Proof. (i) Let Î´ > 0. For any n let An,Î´ :=

x âˆˆ | |Xn âˆ’X| > Î´

. By Propo-
sition B.48, P(lim supn An,Î´) = 0 for any Î´ > 0. Let m â‰¥1 and deï¬ne Bm :=
âˆªâˆ
n=mAn,Î´. Then An,Î´ âŠ‚Bm âˆ€n â‰¥m hence
P(An,Î´) â‰¤P(Bm) â†’P
 âˆ
'
m=1
Bm

= P(lim sup
n
An,Î´) = 0.
(ii) Let An,0 :=

x âˆˆ | |Xn âˆ’X| > 0

. We must show that there exists a
sequence nj such that
P(lim sup
j
Anj ,0) = 0,
see
Deï¬nition
4.75
and
(B.34).
Let
An,Î´ =

x âˆˆ | |Xn âˆ’X| > Î´

.
By
assumption P(An,Î´) â†’0 for any Î´ > 0. Let n1 be the smallest integer such that
P(An1,1) < 1/2, and for any k â‰¥2, let nk+1 be the smallest integer greater
than nk such that P(Ank+1,1/(k+1)) â‰¤1/2k+1. Let Bm := âˆªjâ‰¥mAnj ,1/j. Since
Bm â†“âˆ©mBm = lim supj(Anj ,1/j) we obtain
P(lim sup
j
Anj ,1/j) = lim
mâ†’âˆP(Bm) â‰¤
lim
mâ†’+âˆ
âˆ

j=m
1/2j+1 = 0.
Since
P(lim sup
j
Anj ,0) â‰¤P(lim sup
j
Anj ,1/j),
the claim follows.
B.4.2
Strong convergence
We see here some different results related to the Beppo Levi theorem and the
convergence of integrals.
The ï¬rst result is about the convergence of integrals of series of non-negative
functions.
Proposition B.50 (Series of non-negative functions) Let (E, P) be a measure
on . Let

fk

be a sequence of E-measurable non-negative functions. Then
*

âˆ

k=1
fk(x) P(dx) =
âˆ

k=1
*

fk(x) P(dx).

APPENDIX B
301
Proof. The partial sums
n
k=1 fk(x)

are a nondecreasing sequence of
E-measurable non-negative functions. Applying the Beppo Levi theorem to this
sequence yields the result.
B.4.3
Fatou lemma
In the following lemma, the monotonicity assumption in the Beppo Levi theorem
is removed.
Lemma B.51 (Fatou) Let (E, P) be a measure on  and let

fk

be a sequence of
E-measurable non-negative functions. Then
*

lim inf
kâ†’âˆfk(x) P(dx) â‰¤lim inf
kâ†’âˆ
*

fk(x) P(dx).
Proof. Let gn(x) := infkâ‰¥n fk(x).

gn(x)

is an increasing sequence of
E-measurable non-negative functions. Moreover,
0 â‰¤gn(x) â‰¤fk(x), âˆ€k â‰¥n,
lim inf
Îºâ†’âˆfk(x) = lim
nâ†’âˆgn(x).
Thus
.
 gn(x) P(dx) â‰¤infkâ‰¥n
.
 fk(x) P(dx) and, applying the Beppo Levi
theorem, we get
*

lim inf
kâ†’âˆfk(x) P(dx) = lim
nâ†’âˆ
*

gn(x) P(dx) â‰¤lim
nâ†’âˆinf
kâ‰¥n
*

fk(x) P(dx)
= lim inf
kâ†’âˆ
*

fk(x) P(dx).
Remark B.52 The Fatou lemma implies the Beppo Levi theorem. In fact, let

fn

be an increasing sequence of functions that converges to f (x). Then f (x) =
limkâ†’âˆfk(x) = lim infkâ†’âˆfk(x). Since the sequence

fk

is monotone, we get
lim inf
kâ†’âˆ
*

fk(x) P(dx) = lim
kâ†’âˆ
*

fk(x) P(dx) â‰¤
*

f (x) P(dx),
and, by the Fatou lemma, we get the opposite inequality:
*

f (x) P(dx) =
*

lim inf
kâ†’âˆfk(x) P(dx) â‰¤lim inf
kâ†’âˆ
*

fk(x) P(dx).
Corollary B.53 (Fatou lemma) Let (E, P) be a measure on . Let

fk

be a
sequence of E-measurable functions and let Ï† :  â†’R be a P-summable func-
tion.
(i) If fk(x) â‰¥Ï†(x) âˆ€k and P-a.e. x âˆˆ, then
*

lim inf
kâ†’âˆfk(x) P(dx) â‰¤lim inf
kâ†’âˆ
*

fk(x) P(dx).

302
APPENDIX B
(ii) If fk(x) â‰¤Ï†(x) âˆ€k and P-a.e., then
lim sup
kâ†’âˆ
*

fk(x) P(dx) â‰¤
*

lim sup
kâ†’âˆ
fk(x) P(dx).
Proof.
Let
Ek :=

x âˆˆ | fk(x) â‰¥Ï†(x)

and
let
E := âˆ©kEk.
Since
P(Ec) = 0, we can assume without loss of generality that fk(x) â‰¥Ï†(x) âˆ€k and
âˆ€x âˆˆ. To prove (i) it sufï¬ces to apply the Fatou lemma, Lemma B.51, to the
sequence

fk âˆ’Ï†

. (ii) is proven similarly.
B.4.4
Dominated convergence theorem
Theorem B.54 (Lebesgue dominated convergence) Let (E, P) be a measure on
 and let

fk

be a sequence of E-measurable functions. Assume:
(i) fk(x) â†’f (x) P-a.e. x âˆˆ.
(ii) There exists a P-summable function Ï† such that |fk(x)| â‰¤Ï†(x) âˆ€k and for
P-a.e. x.
Then
*

|fk(x) âˆ’f (x)| P(dx) â†’0
and, in particular,
*

fk(x) P(dx) â†’
*

f (x) P(dx).
Proof. By assumption |fk(x) âˆ’f (x)| â‰¤2Ï†(x) for P-a.e. x and for any k.
Moreover, |fk(x) âˆ’f (x)| â†’0 âˆ€k and for P-a.e. x. Thus, by the Fatou lemma,
Corollary B.53, we get
lim sup
kâ†’âˆ
*

|fk(x) âˆ’f (x)| P(dx) â‰¤
*

lim sup
kâ†’âˆ
|fk(x) âˆ’f (x)| dx
=
*

0 P(dx) = 0.
The last claim is proven by the following inequality:

*

fk(x) P(dx) âˆ’
*

f (x) P(dx)
 =

*

(fk(x) âˆ’f (x)) P(dx)

â‰¤
*

|fk(x) âˆ’f (x)| P(dx).

APPENDIX B
303
Remark B.55 Notice that in Theorem B.54:
â€¢ Assumption (ii) is equivalent to the P-summability of the envelope Ï†(x) :=
supk |fk(x)| of the functions |fk|.
â€¢ Assumption (ii) cannot be dropped as the following sequence

fk

shows:
fk(x) =

k
if 0 < x < 1/k,
0
otherwise.
Example B.56 The dominated convergence theorem extends to arbitrary mea-
sures a classical dominated convergence theorem for series.
Theorem (Dominated convergence for series) Let

aj,n

be a double sequence
such that:
(i) For any j, aj,n â†’aj as n â†’âˆ.
(ii) There exists a non-negative sequence

cj

such that |aj,n| â‰¤cj for any n
and any j and âˆ
j=1 |cj| < âˆ.
Then the series âˆ
j=1 aj is absolutely convergent and
âˆ

j=1
aj,n â†’
âˆ

j=1
aj
as n â†’âˆ.
Proof. Consider the counting measure (P(N), H0) on  = N and apply the
Lebesgue dominated convergence theorem to the sequence

fn

deï¬ned by
fn(j) = aj,n.
For the readerâ€™s convenience, we include a direct proof. Since aj,n â†’aj and
|an,j| â‰¤cj âˆ€n, j, we get |aj| â‰¤cj âˆ€j so that âˆ
j=0 aj is absolutely convergent.
Let Ïµ > 0. Choose p = p(Ïµ) such that 2 âˆ
j=p+1 cj < Ïµ. Then

âˆ

j=0
aj,n âˆ’
âˆ

j=0
aj
 â‰¤
âˆ

j=0
|aj,n âˆ’aj| =
p

j=0
|aj,n âˆ’aj| +
âˆ

j=p+1
|aj,n âˆ’aj|
â‰¤
p

j=0
|aj,n âˆ’aj| + 2
âˆ

j=p+1
cj â‰¤
p

j=0
|aj,n âˆ’aj| + Ïµ.
Thus, as n â†’âˆ, we obtain
lim sup
nâ†’âˆ

âˆ

j=0
aj,n âˆ’
âˆ

j=0
aj
 â‰¤Ïµ.
Since Ïµ is arbitrary, the claim follows.

304
APPENDIX B
The next theorem is an important consequence on the convergence of integrals
of series of functions.
Theorem B.57 (Lebesgue) Let (E, P) be a measure on  and let

fk

be a
sequence of E-measurable functions such that
âˆ

k=0
*

|fk(x)| P(dx) < +âˆ.
Then for P-a.e. x the series âˆ
k=0 fk(x) is absolutely convergent to a P-summable
function f (x). Moreover,
*

f (x) âˆ’
p

k=0
fk(x)
 P(dx) â†’0
as p â†’âˆ,
(B.35)
and
*

f (x) P(dx) =
âˆ

k=0
*

fk(x) P(dx).
Notice that the assumptions are on the integrals only, while the claim is about
the P-a.e. convergence of the series âˆ
k=0 |fk(x)|.
Proof. For any x âˆˆ let g(x) âˆˆR+ be the sum of the non-negative addenda
series âˆ
k=0 |fk(x)|. Applying the Beppo Levi theorem, the assumption gives
*

g(x) P(dx) =
âˆ

k=0
*

|fk(x)| P(dx) < +âˆ,
i.e. g is P-summable. Thus, by Proposition B.26, g(x) < +âˆfor P-a.e. x, i.e.
the series âˆ
k=0 fk(x) absolutely converges to f (x) := âˆ
k=0 fk(x) and, for any
integer p â‰¥1 we have

âˆ

k=p
fk(x)
 â‰¤
âˆ

k=p
|fk(x)|.
(B.36)
In particular,
|f (x)| â‰¤
âˆ

k=0
|fk(x)| = g(x)
P-a.e. x âˆˆ,
so that f is summable. Integrating (B.36) we get
*

f (x) âˆ’
pâˆ’1

k=0
fk(x)
 P(dx) =
*


âˆ

k=p
fk(x)
 P(dx) â‰¤
*

âˆ

k=p
|fk(x)| P(dx)
=
âˆ

k=p
*

|fk(x)| P(dx).

APPENDIX B
305
As p â†’âˆwe get the ï¬rst part of the claim. The second part of the claim easily
follows since

*

f (x) P(dx)âˆ’
pâˆ’1

k=0
*

fk(x) P(dx)

â‰¤
*

f (x) âˆ’
pâˆ’1

k=0
fk(x)
 P(dx) â†’0
as p â†’âˆ.
B.4.5
Absolute continuity of integrals
Theorem B.58 (Absolute continuity of integrals) Let (E, P) be a measure on
 and let f be a P-summable function. For any Ïµ > 0 there exists Î´ > 0 such that
.
E |f | P(dx) < Ïµ for any E âˆˆE such that P(E) < Î´. Equivalently,
*
E
f (x) P(dx) â†’0
as P(E) â†’0.
Proof. Let
fk(x) =
â§
âªâ¨
âªâ©
k
if f (x) > k,
f (x)
if âˆ’k â‰¤f (x) â‰¤k,
âˆ’k
if f (x) < âˆ’k.
Then |fk(x) âˆ’f (x)| â†’0 for P-a.e. x and |fk(x) âˆ’f (x)| â‰¤2|f (x)|, Since |f |
is P-summable, the dominated convergence theorem, Theorem B.54, applies for
any Ïµ > 0 there exists N = NÏµ such that
*

|f (x) âˆ’fN(x)| P(dx) < Ïµ/2.
Let Î´ := Ïµ/(2N). Then for any E âˆˆE such that P(E) â‰¤Î´ we get
*
E
|fN(x)| P(dx) â‰¤N P(E) â‰¤N
Ïµ
2N = Ïµ/2
so that
*
E
|f (x)| P(dx) â‰¤
*
E
|fN(x)| P(dx) +
*

|f âˆ’fN| P(dx) â‰¤Ïµ
2 + Ïµ
2 = Ïµ.
B.4.6
Differentiation of the integral
Let f, g : Rn â†’R be Lebesgue-summable non-negative functions. Clearly,
.
A f (x) dx =
.
A g(x) dx
âˆ€A âŠ‚Rn
if
and
only
if
f (x) = g(x)
almost

306
APPENDIX B
everywhere. Thus one would like to characterize f (x) in terms of its integral,
i.e. of the map A â†’
.
A f (x) dx. Differentiation theory provides such a charac-
terization. Obviously, if f is continuous, then the mean value theorem gives
lim
râ†’0
1
|B(x, r)|
*
B(x,r)
f (y) dy = f (x)
âˆ€x.
More generally, the following theorem holds.
Theorem B.59 (Lebesgue) Let E âŠ‚Rn be a B(Rn)-measurable set and let f :
E â†’R be B(Rn)-measurable such that
.
E |f |p dx < +âˆfor some 1 â‰¤p <
+âˆ. Then for almost every x âˆˆE,
1
|B(x, r)|
*
Eâˆ©B(x,r)
|f (y) âˆ’f (x)|p dy â†’0
as r â†’0+.
In particular, for almost every x âˆˆE, the limit
lim
râ†’0+
1
|B(x, r)|
*
Eâˆ©B(x,r)
f (y) dy
exists, is ï¬nite and equal to f (x).
Example B.60 Let f be L1-summable on ] âˆ’1, 1[. Show that
lim
râ†’0+
1
2r
* x+r
xâˆ’r
f (y) dy = f (x)
a.e. x âˆˆ] âˆ’1, 1[.
Deï¬nition B.61 Let
f : E âŠ‚Rn â†’R be Ln-summable on E. The points of
the set
Lf :=

x âˆˆE
 âˆƒÎ» âˆˆR such that
1
|B(x, r)|
*
Eâˆ©B(x,r)
|f (y) âˆ’Î»| dy â†’0
$
are called Lebesgue points of f . For any x âˆˆLf the limit
Î»f (x) := lim
râ†’0+
1
|B(x, r)|
*
B(x,r)
f (y) dy
exists and is ï¬nite thus it deï¬nes a function Î»f : Lf â†’R called the Lebesgue
representative of f .
From the Lebesgue differentiation theorem, Theorem B.59, we get
Theorem B.62 Let f be a Ln-summable function on Rn. Then Ln(Rn \ Lf ) = 0
and f = Î»f Ln-a.e.
The differentiation theorem can be extended to more general sets than balls
centred at x. One may use cubes centred at x, cubes containing x or even

APPENDIX B
307
different objects. For example, let A be a bounded Borel set such that Ln(A) > 0.
Assume, e.g.
A âŠ‚B(0, 100) âŠ‚Rn,
|A| = c |B1|.
For any x âˆˆRn and any r > 0, let Ax,r := x + r A. Obviously, Ax,r âŠ‚
B(x, 100 r) and |Ax,r| = rn |A| = c rn |B1| = c |B(x, r)|. Theorem B.59 implies
the following.
Theorem B.63 Let E âŠ‚Rn be a Borel-measurable set and let f : E â†’R be
B(Rn)-measurable with
.
E |f |p dx < +âˆfor some 1 â‰¤p < âˆ. Then for Ln-
a.e. x âˆˆE
1
|Ax,r|
*
Eâˆ©Ax,r
|f (y) âˆ’f (x)|p dy â†’0
as r â†’0+.
We now collect some results due to Giuseppe Vitali (1875â€“1932) on the
differentiation of integrals and of monotone functions.
Theorem B.64 (Vitali) Let h : R â†’R be monotone nondecreasing. Then h is
differentiable at L1-a.e. x âˆˆR and the derivative hâ€²(x) is non-negative at L1-a.e.
x âˆˆR. Moreover, hâ€² is L1-summable on any bounded interval ]a, b[âˆˆR and
* y
x
hâ€²(t) dt â‰¤h(y) âˆ’h(x)
âˆ€x < y.
(B.37)
Remark B.65 Equality may not hold in (B.37). Take, e.g. h(x) := sgn(x) so
that hâ€²(x) = 0 âˆ€x Ì¸= 0, and, of course, 0 =
. 1
âˆ’1 hâ€²(t) dt < h(1) âˆ’h(âˆ’1) = 2.
Although surprising, one may construct examples of continuous and strictly
increasing functions whose derivative is zero almost everywhere: one some-
what simpler example of a continuous, nonconstant and nondecreasing function
with zero derivative almost everywhere is the famous Cantorâ€“Vitali function.
Obviously, for such functions the inequality in (B.37) may be strict.
Deï¬nition B.66 A function f : R â†’R is said to be absolutely continuous if for
any Ïµ > 0 there exists Î´ > 0 such that for any pair of sequences

xk

,

yk

such
that âˆ
k=1 |xk âˆ’yk| < Î´ we have âˆ
k=1 |f (xk) âˆ’f (yk)| < Ïµ.
Let f âˆˆL1([a, b]), Theorem B.58 implies that the integral function
F(x) :=
* x
a
f (t) dt,
x âˆˆ[a, b],
is absolutely continuous. The next theorem shows that integral functions are the
only absolutely continuous functions.
Theorem B.67 (Vitali) A function h : [a, b] â†’R is absolutely continuous if and
only if there exists a L1-summable function f on [a, b] such that
h(y) âˆ’h(x) =
* y
x
f (s) ds
âˆ€x, y âˆˆ[a, b], x < y.

308
APPENDIX B
Moreover, h is differentiable at almost every x âˆˆ[a, b] and hâ€²(x) = f (x) for a.e.
x âˆˆ[a, b].
Lipschitz continuous functions f : R â†’R are absolutely continuous; thus
by Theorem B.67 they are differentiable L1-a.e., the derivative f â€²(x) is L1-
summable and
f (y) âˆ’f (x) =
* y
x
f â€²(s) ds
âˆ€x, y âˆˆR, x < y.
Moreover, the following holds in Rn.
Theorem B.68 (Rademacher) Let f : Rn â†’R be Lipschitz continuous. Then
f is differentiable at Ln-almost every x âˆˆRn, the map x â†’Df (x) is B(Rn)-
measurable and |Df (x)| â‰¤Lip(f ) Ln-a.e. x âˆˆRn.
B.4.7
Weak convergence of measures
In this section we consider Borel measures on R, that is measures (B(R), Î¼) on
R. Since the Ïƒ algebra is understood, we simply write Î¼ to denote the measure
(B(R), Î¼).
Recall that the law of a ï¬nite Borel measure Î¼ on R is the function F :
R â†’R, F(t) := Î¼(] âˆ’âˆ, t]). We recall that F is monotone nondecreasing, in
particular, is right-continuous on R and the set of its discontinuity points is at most
denumerable. Moreover, F(t) â†’F(âˆ’âˆ) as t â†’âˆ’âˆand F(t) â†’F(+âˆ) as
t â†’+âˆand the measure Î¼ is completely determined by F.
Deï¬nition B.69 Let

Î¼n

, Î¼ be ï¬nite Borel measures on R. We say that

Î¼n

weakly converges to Î¼, and we write Î¼n â‡€Î¼, if for any continuous bounded
function Ï• : R â†’R one has
*
R
Ï•(t) Î¼n(dt) â†’
*
R
Ï•(t) Î¼(dt).
Proposition B.70 If the weak limit of a sequence of measures exists, then it is
unique.
Proof. Assume Î¼n â‡€Î¼1 and Î¼n â‡€Î¼2, and let P := Î¼1 âˆ’Î¼2. Then, for
every continuous bounded function Ï• : R â†’R
*
R
Ï•(t) P(dt) = 0.
The characteristic function of ] âˆ’âˆ, a] can be approximated from below by
an increasing sequence of continuous non-negative functions, thus obtaining
P([âˆ’âˆ, a]) = 0 âˆ€âˆˆR, hence P(A) = 0 âˆ€A âˆˆB(R).
Theorem B.71 Let

Î¼n

, Î¼ be ï¬nite Borel measures on R. Assume Î¼n(R) = Î¼(R)
âˆ€n and let Fn and F be their laws, respectively. The following are equivalent:

APPENDIX B
309
(i) If F is continous at t, then Fn(t) â†’F(t).
(ii) Î¼n weakly converges to Î¼.
Proof. (i) â‡’(ii) Without any loss of generality, we can assume that for any
n âˆˆN, Fn(âˆ’âˆ) = F(âˆ’âˆ) = 0 and Fn(+âˆ) = Î¼n(R) = Î¼(R) = F(+âˆ) = 1.
Fix Î´ > 0 and let a, b âˆˆR, a < b, such that F is continuous at a and b, and such
that F(a) â‰¤Î´ and 1 âˆ’F(b) â‰¤Î´. Fn(a) and Fn(b) converge to F(a) and F(b),
respectively, hence for large enough nâ€™s, Fn(a) â‰¤2Î´, 1 âˆ’Fn(b) â‰¤2Î´.
Let Ï• : R â†’R be a bounded continuous function, |Ï•| â‰¤M. Since Ï• is uni-
formly continuous in [a, b], there exists N = NÎ´ and intervals Ij = [aj, aj+1],
j = 1, . . . , NÎ´ where a = a1 < a2 < Â· Â· Â· < aN+1 = b such that the oscillation of
Ï• on every Ij is less than Î´, maxIj Ï• âˆ’minIj Ï• â‰¤Î´âˆ€j. Morever, perturbating the
extrema aj if necessary, we can assume that all the points aj are continuity points
for F. Let h(x) := N
j=1 Ï•(aj)1Ij (x). h is a simple function h|Ij = Ï•(aj) and
h = 0 in R \ [a, b]. Moreover, |Ï•(x) âˆ’h(x)| â‰¤Î´ on ]a, b]. Since Ï• is bounded
and Î¼n(R) = 1,

*
R
(Ï•(x) âˆ’h(x)) Î¼n(dx)

â‰¤
*
]âˆ’âˆ,a]
|Ï•(x)| Î¼n(dx) +
*
]b,+âˆ[
|Ï•(x)| dx
+
*
]a,b]
|Ï•(x) âˆ’h(x)| Î¼n(dx)
â‰¤4MÎ´ + Î´ = (4M + 1)Î´
and, similarly,

*
R
(Ï•(x) âˆ’h(x)) Î¼n(dx)
 â‰¤(2M + 1)Î´,
hence

*
R
Ï•(x) Î¼n(dx) âˆ’
*
R
Ï•(x) Î¼(dx)

â‰¤2(3M + 1)Î´ +

*
]a,b]
h(x)(Î¼n âˆ’Î¼)(dx)

â‰¤2(3M + 1)Î´ +
Nâˆ’1

j=1
|Ï•(aj)|

|Fn(aj+1) âˆ’F(aj+1)| + |Fn(aj) âˆ’F(aj)|

.
Since Fn(aj) â†’F(aj) for any j = 1, . . . , N, we get as n â†’âˆ
lim sup
nâ†’âˆ

*
R
Ï•(x) Î¼n(dx) âˆ’
*
R
Ï•(x) Î¼(dx)
 â‰¤2(3M + 1)Î´.

310
APPENDIX B
Since Î´ > 0 is arbitrary, the claim is proven.
(ii) â‡’(i) Let a âˆˆR. It sufï¬ces to show that
F(aâˆ’) â‰¤lim inf
nâ†’âˆFn(aâˆ’)
and
lim sup
nâ†’âˆ
Fn(a) â‰¤F(a).
(B.38)
In fact, from (B.38) one gets
F(aâˆ’) â‰¤lim inf
nâ†’âˆFn(aâˆ’) â‰¤lim inf
nâ†’âˆFn(a) â‰¤lim sup
nâ†’âˆ
Fn(a) â‰¤F(a),
i.e. F(a) = limnâ†’âˆFn(a) if F is continuous at a.
For any Î´ > 0, let Ï•(t) be the piecewise linear function that is null for any
t â‰¥a and is identically 1 for t â‰¤a âˆ’Î´. Then
F(a âˆ’Î´) =
*
R
1]âˆ’âˆ,aâˆ’Î´](t) Î¼(dt)
â‰¤
*
R
Ï•(t) Î¼(dt) = lim
nâ†’âˆ
*
R
Ï•(t) Î¼n(dt) = lim inf
nâ†’âˆ
*
R
Ï•(t) Î¼n(dt)
â‰¤lim inf
nâ†’âˆ
*
R
1]âˆ’âˆ,a[(t) Î¼n(dt) â‰¤lim inf
nâ†’âˆFn(aâˆ’).
As Î´ â†’0+, F(a âˆ’Î´) â†’F(aâˆ’), so the ï¬rst inequality in (B.38) is proven. Sim-
ilarly, let Ï•(t) be the piecewise linear function that is null for t â‰¥a + Î´ and is
identically 1 for t â‰¤a. Then
F(a + Î´) =
*
R
1]âˆ’âˆ,a+Î´](t) Î¼(dt)
â‰¥
*
R
Ï•(t) Î¼(dt) = lim
nâ†’âˆ
*
R
Ï•(t) Î¼n(dt) = lim sup
nâ†’âˆ
*
R
Ï•(t) Î¼n(dt)
â‰¥lim sup
nâ†’âˆ
*
R
1]âˆ’âˆ,a](t) Î¼n(dt) â‰¥lim sup
nâ†’âˆ
Fn(a).
As Î´ â†’0+, F(a + Î´) â†’F(a) so that the second inequality in (B.38) holds. The
proof of (B.38) is then complete.
Let (E, P) be a probability measure on a set . We recall that the law FX
associated with an E-measurable function X :  â†’R is the law of the image
measure of P through X, i.e.
FX(t) := P

x âˆˆ
 X(x) â‰¤t

.
Deï¬nition B.72 Let (E, P) be a ï¬nite measure on a set  and let

Xn

, X be
E-measurable functions. We say that

Xn

converges in law to X if FXn(t) con-
verges to FX(t) pointwisely in all points of continuity of FX.

APPENDIX B
311
Proposition B.73 Let (E, P) be a ï¬nite measure on a set  and let

Xn

, X be
E-measurable functions. If Xn â†’X in measure then Xn converges in law to X.
Proof. If sufï¬ces to prove that
FX(aâˆ’) â‰¤lim inf
nâ†’âˆFXn(a)
and
lim sup
nâ†’âˆ
FXn(a) â‰¤FX(a).
(B.39)
In fact, from (B.39) one gets
FX(aâˆ’) â‰¤lim inf
nâ†’âˆFXn(a) â‰¤lim sup
nâ†’âˆ
FXn(a) â‰¤FX(a),
hence FX(a) = limnâ†’âˆFXn(a) if FX is continuous at a.
Let us prove (B.39). Let Î´ > 0. Since

x âˆˆ
 X(x) â‰¤a âˆ’Î´

=

x âˆˆ
 X(x) â‰¤a âˆ’Î´, Xn(x) â‰¤a

( 
x âˆˆ
 X(x) â‰¤a âˆ’Î´, Xn(x) > a

âŠ‚

x âˆˆ
 Xn(x) â‰¤a
 ( 
x âˆˆ
 |Xn âˆ’X| > Î´

,
we have
FX(a âˆ’Î´) â‰¤FXn(a) + P(|X âˆ’Xn| > Î´).
Thus, passing to the limit with respect to n, we obtain
FX(a âˆ’Î´) â‰¤lim inf
nâ†’âˆFXn(a).
If we now let Î´ â†’0+, we get the ï¬rst inequality (B.39). Similarly,

x âˆˆ
 Xn(x) â‰¤a

=

x âˆˆ
 Xn(x) â‰¤a, X(x) â‰¤a + Î´

( 
x âˆˆ
 Xn(x) â‰¤a, X(x) > a + Î´

âŠ‚

x âˆˆ
 X(x) â‰¤a + Î´
 ( 
x âˆˆ
 |Xn âˆ’X| > Î´

so that
FXn(a) â‰¤FX(a + Î´) + P(|X âˆ’Xn| > Î´).
As n â†’âˆwe get
lim sup
nâ†’âˆ
FXn(a) â‰¤FX(a + Î´),
so that, by letting Î´ â†’0+ we obtain the second inequality of (B.39).

312
APPENDIX B
B.4.8
Exercises
Exercise B.74 Let f : Rn â†’R be Ln-summable. Prove that the function F :
Rn Ã— [0, âˆ[â†’R deï¬ned by
F(x, r) :=
*
B(x,r)
f (t) dLn(t)
is continuous.
Exercise B.75 Let f âˆˆL1(R). Prove that the following equalities hold for a.e.
x âˆˆR:
lim
râ†’0+
1
r
* r
0
f (x + t) dt = f (x);
lim
râ†’0+
1
r
* 0
âˆ’r
f (x + t) dt = f (x);
lim
râ†’0+
1
r
* 2r
r
f (x + t) dt = f (x).
Exercise B.76 Let Ï• : [a, b] â†’[c, d] be continuous and piecewise differentiable.
Let h : [c, d] â†’R be absolutely continuous. Prove that f â—¦Ï• : [a, b] â†’R is
absolutely continuous.
Exercise B.77 Let Ï• : [a, b] â†’[c, d] be continuous. Then Ï• is absolutely contin-
uous if and only if the graph of Ï• has ï¬nite length.
Exercise B.78 Let (E, P) be a measure on a set . Let

Xn

, X be E-measurable
functions and let p âˆˆ[1, âˆ[. Assume that:
(i) Xn â†’X P-a.e. x âˆˆ.
(ii)
.
 |Xn|p dx â†’
.
 |X|p dx.
Prove that
.
 |Xn âˆ’X|p dx â†’0.
Solution. For any positive n the function Yn := 2pâˆ’1(|X|p + |Xn|p) âˆ’|Xn âˆ’
X|p is non-negative. Moreover, as n â†’âˆ, Yn converges to 2p|X|p P-a.e. Thus,
by the Fatou lemma
2p
*

|X|p dx â‰¤lim inf
nâ†’âˆ
*

%
2pâˆ’1(|X|p + |Xn|p) âˆ’|Xn âˆ’X|p&
= 2p
*

|X|p dx âˆ’lim sup
nâ†’âˆ
*

|Xn âˆ’X|p dx.

Appendix C
Systems of linear ordinary
differential equations
We assume the reader is already familiar with ï¬rst- and second-order linear
ordinary differential equations (ODEs) with constant coefï¬cients, either homoge-
neous or not. Here, we review results on the solutions to systems of N ï¬rst-order
linear ODEs.
C.1
Cauchy problem
We ï¬rst consider the existence and uniqueness of a C1 solution X : [a, b] â†’RN
to the problem
â§
âªâ¨
âªâ©
t0 âˆˆ[a, b],
X(t0) = X0,
Xâ€²(t) = QX(t) + F(t)
âˆ€t âˆˆ[a, b]
(C.1)
where (t0, X0) âˆˆ[a, b] Ã— RN is the given initial datum, Q is a given real N Ã— N
matrix and F : [a, b] â†’RN is a given continuous function.
C.1.1
Uniqueness
Lemma C.1 (GrÂ¨onwall) Let W âˆˆC1(]a, b[, RN) satisfy the inequality
|W â€²(t)| â‰¤Î± + Î² |W(t)|
âˆ€t âˆˆ]a, b[
for some Î± â‰¥0 and Î² > 0. Then
|W(t)| â‰¤

|W(t0)| + Î±
Î²

eÎ²|tâˆ’t0|
âˆ€t, t0 âˆˆ]a, b[.
A First Course in Probability and Markov Chains, First Edition. Giuseppe Modica and Laura Poggiolini.
Â© 2013 John Wiley & Sons, Ltd. Published 2013 by John Wiley & Sons, Ltd.

314
APPENDIX C
Proof. Let Ïµ > 0. The function z(t) :=

Ïµ2 + |W(t)|2 is strictly positive and
of class C1(]a, b[), and
zâ€²(t) = (W(t)|W â€²(t))

Ïµ2 + |W(t)|2 â‰¤|W â€²(t)|
|W(t)|

Ïµ2 + |W(t)|2
â‰¤|W â€²(t)| â‰¤Î± + Î²|W(t)| â‰¤Î± + Î² z(t).
Thus,
zâ€²(t)
Î± + Î²z(t) â‰¤1
âˆ€t âˆˆ]a, b[
and integrating from t0 to t we get
1
Î² log
 Î± + Î²z(t)
Î± + Î²z(t0)
 =

* t
t0
zâ€²(s)
Î± + Î²z(s) ds
 â‰¤|t âˆ’t0|,
i.e.
 Î± + Î²z(t)
Î± + Î²z(t0)
 â‰¤eÎ²|tâˆ’t0|
âˆ€t âˆˆ]a, b[.
Thus,
Î²|W(t)| â‰¤Î± + Î²z(t) â‰¤(Î± + Î²z(t0))eÎ²|tâˆ’t0|
=

Î± + Î²
6
Ïµ2 + |W(t0)|2

eÎ²|tâˆ’t0|.
As Ïµ â†’0, we get the claim.
Theorem C.2 Let Q âˆˆMN,N and F(t) âˆˆC0([a, b], RN). Then the Cauchy prob-
lem (C.1) admits at most one solution.
Proof. Let us introduce the maximum expansion norm of the matrix
Q âˆˆMN,N
||Q|| := sup
|x|=1
|Qx|.
(C.2)
so that
|Qx| â‰¤||Q|| |x|
âˆ€x âˆˆRN.
We point out that the sup in (C.2) is in fact a maximum since the map x â†’|Qx|
is continuous.
Assume that X1(t) and X2(t) are two different C1 solutions to (C.1). Then
their difference W(t) := X1(t) âˆ’X2(t) is a solution to the Cauchy problem:

W â€²(t) = QW(t)
âˆ€t âˆˆ]a, b[,
W(t0) = 0.

APPENDIX C
315
Thus, |W â€²(t)| = |QW(t)| â‰¤||Q|| |W(t)| and the GrÂ¨onwall lemma applied to
W(t) with Î± = 0 and Î² = ||Q|| yields
|W(t)| â‰¤|W(t0)| exp(||Q|| |t âˆ’t0|)
âˆ€t âˆˆ]a, b[.
Since W(t0) = 0, the claim is proven.
C.1.2
Existence
Let Q âˆˆMN,N(R). For each z âˆˆC, the power series âˆ
k=0
Qkzk
k!
absolutely con-
verges to a matrix denoted by eQz, cf. (A.4),
eQz :=
âˆ

k=0
Qkzk
k!
Moreover, the series can be differentiated term by term, thus giving
(eQz)â€² =
âˆ

k=1
Qkzkâˆ’1
(k âˆ’1)! = Q
âˆ

k=1
Qkâˆ’1zkâˆ’1
(k âˆ’1)! = Q eQz
and eQ(t+s) = eQteQs âˆ€t, s âˆˆR, see Proposition A.8. Since eQ0 = Id, we have
the following.
Theorem C.3 The only C1 solution to the Cauchy problem (C.1) is the function
X : [a, b] â†’RN deï¬ned by
X(t) := eQ(tâˆ’t0)X0 + eQt
* t
t0
eâˆ’QsF(s) ds.
Proof. It sufï¬ces to show that X(t) satisï¬es all the equations in (C.1): we
have
X(t0) = eQ0X0 = IdX0 = X0,
Xâ€²(t) = QeQ(tâˆ’t0)X0 + QeQt
* t
t0
eâˆ’QsF(s) ds + eQteâˆ’QtF(t)
= QX(t) + F(t).
Corollary C.4 Let Q âˆˆMN,N(R). Then P(t) := eQt is the unique solution to

Pâ€²(t) = QP(t)
âˆ€t âˆˆR,
P(0) = Id.
(C.3)

316
APPENDIX C
Proof. By Theorem C.3 the ith column of P(t) is the solution to the Cauchy
problem

X(0) = ei,
Xâ€²(t) = QX(t)
(C.4)
where ei = (0, . . . , 1, . . . , 0)T is the ith vector of the standard basis of RN. Thus
P(t) is the only matrix solution of (C.3).
The exponential matrix P(t) = eQt has several properties, see Proposition A.8.
In particular, for any t, s the matrices P(t) and P(s) commute, since
P(s)P(t) = eQseQt = eQ(t+s) = eQteQs = P(t)P(s).
Moreover, P(t) commutes with Q and P(t) is invertible with inverse matrix
P(t)âˆ’1 = (eQt)âˆ’1 = eQ(âˆ’t) = P(âˆ’t)
âˆ€t âˆˆR.
In particular, for any t âˆˆR and n âˆˆZ
P(t)n = eQnt = P(nt).
The following proposition computes the determinant of P(t).
Proposition C.5 Let Q âˆˆMN,N(R), P(t) := eQt and let w(t) := det P(t). Then
wâ€²(t) = tr (Q)w(t) so that
w(t) = exp(tr (Q)t), âˆ€t âˆˆR,
where tr (Q) = N
i=1 Qi
i denotes the trace of the matrix Q = (Qi
j).
Proof. The determinant of a matrix is a multilinear function of the columns.
Let P(t) = [P1(t) | P2(t) | . . . | PN(t)] âˆˆMN,N. Then
d
dt det P(t) = det [P â€²
1 | P2 | . . . | PN]
+ det [P1 | P â€²
2 | . . . | PN] + Â· Â· Â· + det [P1 | P2 | . . . | P â€²
N].
Since P(0) = Id, we get
det [P â€²
1(0) | P2(0) | . . . | PN(0)] = (P1
1)â€²(0),
. . . ,
det [P1(0) | P2(0) | . . . | P â€²
N(0)] = (PN
N)â€²(0),
so that
ddet P(t)
dt
(0) = tr Pâ€²(0) = tr Q.
(C.5)

APPENDIX C
317
Thus, recalling that P(t + s) = P(s)P(t),
wâ€²(t) = ddet P(t)
dt
(t) = ddet P(s + t)
ds
(0)
= ddet (P(s)P(t))
ds
(0) = ddet P(s)
ds
(0)det P(t) = tr (Q)w(t).
Since w(0) = 1, we ï¬nally get w(t) = exp(tr (Q)t).
C.2
Efï¬cient computation of eQt
The exponential matrix P(t) := eQt can be computed via different techniques
which have different degrees of numerical efï¬ciency and accuracy also depending
on the structure of Q. This leads to a variety of methods and techniques to
compute, or to approximately compute, P(t), see e.g. [21]. For instance, if Q is
a Q-matrix, the uniformization method allows to easily approximate P(t) with
bounded errors, see Proposition 6.23. Here we discuss two simple methods that
apply to any matrix Q.
C.2.1
Similarity methods
A ï¬rst approach is by a similarity transformation. In fact, if Q = SJSâˆ’1, i.e. if
Q is C-similar to a matrix J via an invertible matrix S âˆˆMN,N(C), then for any
positive integer k, Qk = SJkSâˆ’1, so that
eQt =
âˆ

k=0
SJkSâˆ’1tk
k!
= S
âˆ

k=0
Jktk
k! Sâˆ’1 = SeJtSâˆ’1.
The computation thus boils down to the computation of S, Sâˆ’1 and the exponen-
tial of another matrix J.
Example C.6 Assume there exists a basis u1, . . . , uN of CN of eigenvectors of
Q and let Î»1, . . . , Î»N be the corresponding eigenvalues. Then Q = SJSâˆ’1 where
S = [u1|u2| Â· Â· Â· |un] and J = diag(Î»1, . . . , Î»n). Since J is diagonal, one can easily
show that
eJt = diag(eÎ»1t, eÎ»2t, . . . , eÎ»nt)
so that
eQt = S diag(eÎ»1t, eÎ»2t, . . . , eÎ»nt)Sâˆ’1 =
0
u1eÎ»1t|u2eÎ»2t| . . . |uneÎ»nt1
Sâˆ’1.
The same result can be proven by the following reasoning: let u be an eigen-
vector of Q and let Î» be the associated eigenvalue. It is trivial to check that
x(t) := eÎ»tu is the solution of the Cauchy problem xâ€² = Qx x(0) = u. Thus, if

318
APPENDIX C
there exists a basis (u1, . . . , uN) of CN where u1, . . . , uN are eigenvectors of Q,
then the matrix
R(t) :=
0
eÎ»1tu1|eÎ»2tu2| . . . |eÎ»NtuN
1
,
where Î»1, . . . , Î»N are the eigenvalues associated with u1, . . . , uN, is a solution to
â§
â¨
â©
Râ€²(t) = QR(t),
R(0) =
0
u1|u2| . . . |uN
1
.
Therefore, S(t) := R(t)R(0)âˆ’1 is a solution to
â§
â¨
â©
Sâ€²(t) = QS(t),
S(0) = Id.
thus concluding that
eQt = S(t) = R(t)
0
u1|u2| . . . |uN
1âˆ’1
.
A basis of RN made by eigenvectors of Q may not exist, but in general, the
Jordan decomposition formula holds, see e.g. [26]: one can ï¬nd an invertible
matrix S describing a change of basis in CN such that J = Sâˆ’1QS is in the
canonical Jordan form
J =
â›
âœâœâœâœâœâœâœâœâ
J1,1
0
0
. . .
0
0
J1,2
0
. . .
0
...
...
...
...
...
0
0
0
. . .
Jk,pk
â
âŸâŸâŸâŸâŸâŸâŸâŸâ 
where for any i = 1, . . . , k and any j = 1, . . . , pi
Ji,j =
â§
âªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâ¨
âªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâªâ©
Î»i
if Ji,j is a 1 Ã— 1 matrix,
â›
âœâœâœâœâœâœâœâœâœâœâœâœâœâœâœâ
Î»i
1
0
0
. . .
0
0
Î»i
1
0
. . .
0
0
0
Î»i
1
. . .
0
...
...
...
...
...
...
0
0
0
. . .
Î»i
1
0
0
0
. . .
0
Î»i
â
âŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâŸâ 
otherwise.

APPENDIX C
319
Thus, one easily gets
eJt :=
â›
âœâœâœâœâœâ
eJ1,1t
0
. . .
0
0
eJ1,2t
. . .
0
...
...
...
...
0
0
. . .
eJk,pk t
â
âŸâŸâŸâŸâŸâ 
;
where the matrices eJi,j t have to be computed.
If Jâ€² = Ji,j = (Î») is 1 Ã— 1, then obviously, etJâ€² = eÎ»t. If Jâ€² = Ji,j is a Jordan
block of dimension â„“â‰¥2, then
Jâ€² = Î»iId + N,
N = (NÎ±
Î²), NÎ±
Î² := Î´Î±+1,Î².
Since N and Id commute and since (Nk)Î±
Î² = (Î´Î±+k,Î²), so that Nk = 0 for any
k â‰¥â„“, we get
eJâ€²t =
âˆ

n=0
(Î»iId + N)ntn
n!
=
âˆ

n=0
n

k=0
tn
n!
n
k

Î»nâˆ’k
i
Nk
=
âˆ

n=0
min(n,â„“âˆ’1)

k=0
tn
n!
n
k

Î»nâˆ’k
i
Nk =
â„“âˆ’1

k=0
âˆ

n=k
tn
n!
n
k

Î»nâˆ’k
i
Nk
=
â„“âˆ’1

k=0
 âˆ

n=k
tnâˆ’kÎ»nâˆ’k
i
(n âˆ’k)!
tk
k!Nk = eÎ»it
â„“âˆ’1

k=0
tk
k!Nk.
Notice that eJt depends only on the eigenvalues of Q and that each entry of eJt
is the product of an exponential function and a polynomial. Thus, eQt = SeJtSâˆ’1
depends only on the eigenvalues of Q and on its Jordan basis, which characterizes
both S and Sâˆ’1.
C.2.2
Putzer method
The Jordan decomposition of Q yields a satisfying analytical description of the
exponential matrix eQt. On the other hand, the computation of S and Sâˆ’1, which
depends on a basis of generalized eigenvectors of Q, is often numerically unsta-
ble. Numerical algorithms that do not require an a priori knowledge of a basis
of generalized eigenvectors of Q have been developed, see [21].
The following algorithm, the Putzer method, is often sufï¬ciently efï¬cient and
precise. Let Î»1, . . . , Î»N be the N eigenvalues of Q. Consider the matrix
A =
â›
âœâœâœâœâœâ
Î»1
0
0
. . .
0
1
Î»2
0
. . .
0
...
...
...
...
...
0
. . .
1
Î»Nâˆ’1
0
0
0
. . .
1
Î»N
â
âŸâŸâŸâŸâŸâ 

320
APPENDIX C
and let P(t) be the solution to the following Cauchy problem

P â€²(t) = AP(t),
P(0) = (1, 0, . . . , 0)T ,
i.e. P(t) is the vector P(t) = (p1(t), p2(t), . . . , pN(t))T whose ï¬rst component
is the solution to the problem

pâ€²
1(t) = Î»1p1(t),
p1(0) = 1
and, for k = 1, 2, 3, . . . , N âˆ’1

pâ€²
k+1(t) = Î»k+1pk+1(t) + pk(t),
pk+1(0) = 0.
Notice that each component of P(t) is obtained by solving a ï¬rst-order linear
nonhomogeneous ODE.
Let Mk, k = 0, 1, . . . N, be the N Ã— N matrices such that

M0 := Id
if k = 0,
Mk := (Q âˆ’Î»kId)Mkâˆ’1
if k â‰¥1.
Notice that -N
j=1(z âˆ’Î»j) = det (zId âˆ’Q) =: pQ(z) is the characteristic poly-
nomial of Q, so that
MN =
N
=
j=1
(Q âˆ’Î»jId) = pQ(Q) = 0
by the Cayleyâ€“Hamilton theorem.
Proposition C.7 With the notation above, the exponential matrix P(t) := eQt is
given by
eQt =
Nâˆ’1

k=0
pk+1(t)Mk
âˆ€t âˆˆR.
Proof. Let Z(t) := Nâˆ’1
k=0 pk+1(t)Mk. It sufï¬ces to show, see Corollary C.4,
that

Zâ€²(t) = QZ(t)âˆ€t,
Z(0) = Id.
Clearly, Z(0) = Nâˆ’1
k=0 pk+1(0)Mk = M0 = Id. Moreover,
Zâ€²(t) âˆ’QZ(t) =
Nâˆ’1

k=0

pâ€²
k+1(t)Mk âˆ’pk+1(t)QMk


APPENDIX C
321
= pâ€²
1(t)M0 âˆ’p1(t)QM0
+
Nâˆ’1

k=1

pk(t)Mk + Î»k+1pk+1(t)Mk âˆ’pk+1(t)QMk

= p1(t)

Î»1Id âˆ’Q

M0 +
Nâˆ’1

k=1
pk(t)Mk
+
Nâˆ’1

k=1
pk+1(t)

Î»k+1Id âˆ’Q

Mk
= âˆ’p1(t)M1 +
Nâˆ’1

k=1

pk(t)Mk âˆ’pk+1(t)Mk+1

= âˆ’p1(t)M1 + p1(t)M1 âˆ’pN(t)MN = 0.
C.3
Continuous semigroups
Deï¬nition C.8 A map P : R+ â†’MN,N is called a continuous semigroup on R+
if P is continuous at 0+ and

P(t + s) = P(t)P(s)
âˆ€t, s â‰¥0,
P(0) = Id.
(C.6)
As a consequence of Corollary C.4 and of the properties of the matrix expo-
nential, Proposition A.8, one immediately sees the following.
Proposition C.9 The exponential matrix P(t) := eQt, t âˆˆR is a continuous semi-
group on R+.
Proof. Obviously, the map t â†’P(t) = eQt is continuous. For any s âˆˆR, the
function
W(t) := P(t + s) âˆ’P(t)P(s)
t âˆˆR.
is a solution to the Cauchy problem

Wâ€²(t) = QW(t)
âˆ€t âˆˆR,
W(0) = 0,
Therefore, W(t) = 0 âˆ€t âˆˆR, i.e. P(t + s) = P(t)P(s) âˆ€t âˆˆR. Since s is arbi-
trary, the claim follows.
The converse is also true and the following holds.

322
APPENDIX C
Theorem C.10 A continuous semigroup P : R+ â†’MN,N on R+ is differentiable
at every t âˆˆR+ and, setting
Q := Pâ€²
+(0) := lim
tâ†’0+
P(t) âˆ’Id
t
,
we have
P(t) = eQt
âˆ€t â‰¥0.
Proof. We ï¬rst show that t â†’P(t) is continuous at any t > 0. Since
P(h) â†’Id as h â†’0+, there exists a right-hand side neighbourhood of h = 0
such that P(h) is invertible for any h in such neighbourhood. Moreover,
P(h)âˆ’1 â†’Id as h â†’0+ and, by the semigroup property,
P(t + h) = P(t)P(h) â†’P(t)
as h â†’0+,
P(t âˆ’h) = P(t)P(h)âˆ’1 â†’P(t)
as h â†’0+.
Thus t â†’P(t) is continuous at any t â‰¥0.
The differentiability follows by Theorem C.12, hence the matrix Q :=
(P)â€²
+(0) exists. Since
P(t + s) âˆ’P(t)
s
= P(s)P(t) âˆ’P(t)
s
= P(s) âˆ’Id
s
P(t),
as s â†’0+ we obtain that P(t) is a solution to the Cauchy problem

Pâ€²(t) = QP(t)
âˆ€t â‰¥0,
P(0) = Id.
Thus, by Proposition C.9,
eQz :=
âˆ

k=0
Qkzk
k! .
Lemma C.11 Let f (t), t â‰¥0, be integrable, continuous at 0 and such that
|f (t)| â‰¤C ekt for some non-negative constants C, k â‰¥0. Then
* âˆ
0
neâˆ’nsf (s) ds â†’f (0)
as n â†’âˆ.
Proof. Let Ïµ > 0. There exists Î´ > 0 such that |f (t) âˆ’f (0)| < Ïµ for any
t âˆˆ[0, Î´[. Since n
. âˆ
0 eâˆ’ns ds = 1, we get

* âˆ
0
neâˆ’nsf (s) ds âˆ’f (0)
 â‰¤
* âˆ
0
neâˆ’ns|f (s) âˆ’f (0)| ds
=
* Î´
0
neâˆ’ns|f (s) âˆ’f (0)| ds +
* âˆ
Î´
neâˆ’ns|f (s) âˆ’f (0)| ds
â‰¤Ïµ + Cneâˆ’nÎ´(1 + ekÎ´).

APPENDIX C
323
As n â†’âˆwe obtain

* âˆ
0
neâˆ’nsf (s) ds âˆ’f (0)
 â‰¤Ïµ.
Since Ïµ is arbitrary, the claim is proven.
Theorem C.12 Let P(t) : [0, +âˆ[â†’MN,N(R) be a semigroup continuous at
every t âˆˆR+. Then P(t) is differentiable.
Proof. We ï¬rst show that ||P(t)|| grows at most exponentially fast. We recall
that we are considering the norm
||A|| := sup
|x|=1
|Ax|
so that ||AB|| â‰¤||A|| ||B|| and |Ai
j| â‰¤||A|| âˆ€i, j.
By the semigroup property, ||P(t + s)|| â‰¤||P(t)|| ||P(s)||, hence the function
w(t) := supsâ‰¤t log ||P(s)|| is nondecreasing and satisï¬es

w(t + s) â‰¤w(t) + w(s),
w(0) = 0.
In particular, w(t) â‰¤qw(1) for any positive rational number q. By approxima-
tion the same property holds for any non-negative t: w(t) â‰¤w(1)t âˆ€t, so that
||P(t)||1 â‰¤ek0t, k0 := w(1).
We now prove the claim of the theorem. For any n > k0 consider the matrix
Zn :=
* âˆ
0
neâˆ’nsP(s) ds.
From the above all the entries of P(t) grow at most exponentially fast. Thus,
one applies Lemma C.11 to the sequence

Zn

n > k0 to get Zn â†’P(0) = Id as
n â†’âˆ. In particular, if n is large enough, the matrix Zn is invertible. Finally,
consider the product
P(t)Zn = P(t)
* âˆ
0
neâˆ’nsP(s) ds =
* âˆ
0
neâˆ’nsP(t)P(s) ds
=
* âˆ
0
neâˆ’nsP(t + s) ds = ent
* âˆ
t
neâˆ’nuP(u) du
=: Fn(t).
Since Fn(t) is of class C1 by the fundamental theorem of calculus, P(t) =
Fn(t)Zâˆ’1
n
is also of class C1.

References
[1] Dallâ€™Aglio, G. Calcolo delle Probabilit`a. Zanichelli, Bologna, 1987.
[2] Baclawski, K., Cerasoli, M., and Rota, G. Introduzione alla Probabilit`a. UMI,
Bologna, 1984.
[3] Hajek, B. ECE 313, Probability with Engineering Applications. 2010. http://www.ifp
.illinois.edu/âˆ¼hajek/Papers/probability.html.
[4] BaËœnuelos, R. Lecture Notes on Measure Theory and Probability. 2003. http://www
.math.purdue.edu/âˆ¼banuelos/probability.pdf.
[5] Klenke, A. Probability Theory. Universitext. Springer-Verlag London Ltd, London,
2008. A comprehensive course, Translated from the 2006 German original. http://dx
.doi.org/10.1007/978-1-84800-048-3.
[6] Varadhan, S. R. S. Probability Theory, vol. 7 of Courant Lecture Notes in Math-
ematics. New York University, Courant Institute of Mathematical Sciences, New
York, 2001.
[7] Ambrosio, L., Da Prato, G., and Mennucci, A. An Introduction to Measure Theory
and Probability. Lectures at Scuola Normale Superiore, Pisa, 2010.
[8] Feller, W. An Introduction to Probability Theory and its Applications. Vol. I . Third
edition. John Wiley & Sons, Ltd, New York, 1968.
[9] Feller, W. An Introduction to Probability Theory and its Applications. Vol. II . Second
edition. John Wiley & Sons, Ltd, New York, 1971.
[10] Mennucci, A., and Mitter, S. K. Probabilit`a e Informazione. Edizioni della Normale.
Scuola Normale Superiore, Pisa, 2008.
[11] Hajek, B. Communication Network Analysis. 2006. http://www.ifp.illinois.edu/
âˆ¼hajek/Papers/networkanalysisDec06.pdf.
[12] Hajek, B. An Exploration of Random Processes for Engineers. 2009. http://www.ifp
.illinois.edu/âˆ¼hajek/Papers/randomprocJan09.pdf.
[13] Marsan, M., Balbo, G., Conte, G., Donatelli, S., and Franceschinis, G. Modelling
with Generalized Stochastic Petri Nets. Wiley Series in Parallel Computing. John
Wiley & Sons, Ltd, New York, 1994.
[14] Varadhan, S. R. S. Stochastic Processes, vol. 16 of Courant Lecture Notes in
Mathematics. New York University, Courant Institute of Mathematical Sciences,
New York, 2007.
A First Course in Probability and Markov Chains, First Edition. Giuseppe Modica and Laura Poggiolini.
Â© 2013 John Wiley & Sons, Ltd. Published 2013 by John Wiley & Sons, Ltd.

REFERENCES
325
[15] Vicario, E. Metodi di Veriï¬ca e Testing. Appunti del corso. Dipartimento di Sistemi
e Informatica, University of Florence, 2008.
[16] Behrends, E. Introduction to Markov Chains with Special Emphasis on Rapid
Mixing. Advanced Lectures in Mathematics. F. Vieweg and Son, Wiesbaden, 2000.
[17] Marinari, E., and Parisi, G. Trattatello di Probabilit`a. 2000. http://chimera.roma1
.infn.it/ENZO/SISDIS/PROBABILITA/versione26.pdf.
[18] Liu, J. S. Monte Carlo Strategies on Scientiï¬c Computing. Springer Series in Statis-
tics. Springerâ€“Verlag, New York, 2001.
[19] Diaconis, P. The Markov chain Monte Carlo revolution. Bull. AMS 2009, 46,
179â€“205.
[20] Baldi, P. Calcolo delle Probabilit`a e Statistica. McGraw-Hill Libri Italia, Milan,
1992.
[21] Molery, C., and Van Loan, C. Nineteen Dubious Ways to Compute the Exponential
of a Matrix, Twenty Five Years Later. SIAM Rev. 2003, 45. http://www.cs.cornell
.edu/cv/researchpdf/19ways+.pdf.
[22] Norris, J. R. Markov Chains. Cambridge Series on Statistical and Probabilistic
Mathematics Cambridge University Press, Cambridge, 1997.
[23] Kulkarni, V. G. Modeling and Analysis of Stochastic Systems. Chapman & Hall,
London, 1995.
[24] BrÂ´emaud, P. Markov Chains - Gibbs Fields, Monte Carlo Simulation and Queues.
Texts in Applied Mathematics, 31. Springerâ€“Verlag, New York, 1999.
[25] Giaquinta, M., and Modica, G. Mathematical Analysis, vol. 2. Approximation and
Discrete Processes. BirkhÂ¨auser, Boston, 2004.
[26] Giaquinta, M., and Modica, G. Note di metodi matematici per Ingegneria Informat-
ica, Edizione 2007. Pitagora Ed., Bologna, 2007.
[27] Giaquinta, M., and Modica, G. Mathematical Analysis, vol. 5. Foundations and
Advanced Techniques for Functions of Several Variables. BirkhÂ¨auser, Boston, 2012.


Index
algebra, 35
events, 35
algorithm
Hastingsâ€“Metropolis, 230
Bernoulli
distribution, 42, 46
process
ï¬nite, 41, 295
inï¬nite, 44, 45, 95, 103, 151,
296
Bernstein polynomials, 152
binary sequences, 45
inï¬nite Bernoulli process, 46,
103
binomial
coefï¬cient, 1
generalized binomial, 3
series, 3
cardinality
denumerable, 45
multiplicity function, 62
of the continuum, 45
of the set of
derangements, 9, 63
functions, 12
lists, 11
multisets, 11
permutations, 8, 9
subsets, 8
central limit, 160
continuity correction, 163
uniform bound, 161
A First Course in Probability and Markov Chains, First Edition. Giuseppe Modica and Laura Poggiolini.
Â© 2013 John Wiley & Sons, Ltd. Published 2013 by John Wiley & Sons, Ltd.
uniform convergence, 161
coefï¬cient
binomial, 1
correlation, 123
generalized binomial, 3
multinomial, 20
collocations of objects
identical, 22
multiplicative property, 23
multiplicity function, 22
pairwise distinct, 19â€“21
grouping map, 19
multiplicative property, 23
conditional probability, 51
Bayes, 52
multiplication formula, 51
transition probabilities, 174
continuous semigroup, 250, 321
differentiability, 322, 323
exponential of a matrix, 321
inï¬nitesimal generator, 250, 322
intensities matrix, 250
matrix exponential, 250
convergence
almost everywhere, 298â€“300
almost sure, 143â€“5, 159, 166
in L2, 143
in law, 159, 308, 310
in measure, 298â€“300
in probability, 143
weak of measures, 160, 308
counting process, 158
covariance, 121

328
INDEX
density
mass, 41, 43
of the sum, 130
with respect to the Lebesgue
measure, 73
derangement, 9
derivative of the determinant, 316
Dirac delta, 292
approximation of, 322
distribution
Bernoulli, 42, 46
Bernoulli trial, 91
binomial, 91
Ï‡-square, 110, 137
discrete, 84
Erlang, 110, 139
exponential, 106, 107
Gamma, 108
Gaussian, 104
geometric, 98, 100
hypergeometric, 93, 117
intensity, 110
joint, 113â€“14, 116
Lebesgue, 95
marginals, 115
mass density, 84
negative binomial, 94
normal, 104
of a composition of random
variables, 77
of a random variable, 70
of rare events, 96
of the minimum of independent
exponentials, 133
of the sum of
independent exponentials, 139
independent Gammas, 134
independent Gaussians, 133
independent Poisson, 132
independent uniformly
distributed, 131
independent variables, 130
squared independent
Gaussians, 137
variables, 116
Pascal, 94
Poisson, 95
triangular, 131
uniform, 41, 74, 102
on an interval, 44
waiting time at the trafï¬c light,
74
drawing
ordered, 16
from a multiset, 17
from a set, 16
multiplicative property, 18
simple, 16
from a multiset, 17
from a set, 17
multiplicative property, 18
with repetition, 16
equations
Chapmanâ€“Kolmogorov, 248
events, 34
almost impossible, 37
almost sure, 37
atomic, 37
certain, 34
complementary, 34
detected by a random variable,
70, 72
impossible, 34
incompatible, 34
independent, 124
rare, 96
expectation, 75
expected number of
ï¬xed points, 33
points in subsets, 33
expected value, 75
from the distribution, 80
from the law, 80
of a composition, 116
of binary operations, 117
of the product, 127
of the sum, 116
variational characterization,
84

INDEX
329
failure rate, 110
family of sets
algebra, 270
closed under ï¬nite intersections,
272
semiring, 274
Ïƒ-algebra, 270
Ïƒ-algebra generated, 270
Ïƒ-algebra of Borel sets, 270
ï¬xed point of a
contraction, 208
map, 207
permutation, 9
stochastic matrix, 209
formula
Bayes, 52
clinic tests, 52
spam ï¬lters, 53
binomial coefï¬cients, 2, 4
Cavalieri, 80, 280, 286
integration by parts, 90
inverse of Pascal matrix, 5, 6
Jordan decomposition, 318
Newton binomial, 1
reduction for multiple integrals,
296
Sylvester, 62
Vandermonde, 93, 269
function
absolutely continuous, 307
approximation by sampling, 282
Bernstein polynomials, 152
characteristic, 39
contraction, 208
distribution function, 70
empirical distribution, 155
entropy, 157
Euler, 66
ï¬xed point, 207
hazard, 110
image, 12
image-list, 8, 12
image-word, 12
integrable, 76, 283
iterated composition
path, 207
sink, 207
Lebesgue representative, 306
mass density, 73
measurable, 76, 280, 281
multiplicity of a covering, 61
of a random variable, 77
simple, 39, 282
square integrable, 120
summable, 76, 283
Geiger counter, 241
graph, 170
arc, 170
incidence matrix, 170
matrix of arcs, 172
node, 170
oriented, 170
hazard function, 110
hitting time
expected, 195, 197
probabilities, 196
holding time
expected, 198
probabilities, 198
independence
Bernoulli process
ï¬nite, 41
inï¬nite, 44
of a sequence of random
variables, 128, 151
of compositions, 128
of events, 124
of holding times, 223, 245
of random variables, 127
of sequences, 165
product measure, 127
reliability of systems, 125, 126
inequality
between mean and mean square,
121
Chebyshev, 82, 287
L2 estimate, 140

330
INDEX
inequality (continued)
Markov, 82, 287
weak estimate, 140
inï¬nitesimal generator, 250
integral, 283
absolute continuity, 305
Lebesgue, 76
linearity of, 39
Monte Carlo method, 153
of a composition, 81
of a random variable, 75
of discrete value functions, 291
of simple functions, 283
on countable sets, 292
with respect to
a measure, 39
an absolutely continuous
measure, 294
Dirac delta, 292
the counting measure, 293
the image measure, 79, 289
the joint distribution, 116
the sum of measures, 292
law, 70
absolutely continuous, 74
differentiable a.e., 74
discrete, 73
empirical, 155
joint, 114
of a composition of random
variables, 77
of a measure, 277
of large deviations, 141
of the iterated logarithm, 151
of total probability, 38, 51â€“2
strong of large numbers, 146,
147, 166
uniform approximation, 156
weak of large numbers, 141â€“2
Lebesgue points, 306
lemma
Borelâ€“Cantelli, 142
Fatou, 301
GrÂ¨onwall, 313
Markov chain, 174
asymptotic behaviour, 183
canonical, 179â€“180
Chapmanâ€“Kolmogorov
equations, 248
composition, 256
Ehrenfest diffusion model, 185
ergodic theorem, 225
existence of a, 179, 180, 256,
258
expected return time, 193
hitting time, 195
holding time, 198, 223, 245, 259
Q-matrix, 259
homogeneous, 177
Monte Carlo method, 230
Poisson process, 251
queue, 186
random walk, 183
renewal property, 177
return time, 238
right-continuous, 250
stochastic matrix, 250
stopping time, 177
transition probabilities, 246
visits, 178
with two states, 181
mass density, 41, 43
matrix
exponential, 250
exponential of a, 266, 314â€“5,
317
continuous semigroup, 321,
322
Jordan decomposition, 318
Putzer method, 319
similarity transformations
method, 317
incidence, 170
Q-matrix, 251
stochastic, 169, 246
asymptotic behaviour, 254
Chapmanâ€“Kolmogorov
equations, 248
continuous semigroup, 250

INDEX
331
ï¬xed point, 254
intensities, 250
uniformization, 255
transition probabilities, 246
mean value, 75
measure, 36, 271
P-complete, 37, 272
absolutely continuous, 73
density, 73
approximation of Borel sets, 277
atomic, 73
mass density, 73
continuity, 38, 271
discrete, 73
mass density, 73
image, 289
integral, 39
law, 277
Lebesgue, 44, 103, 274
probability, 36
product, 127, 294â€“5
push-forward, 70, 77, 114, 289
restriction, 278
Ïƒ-ï¬nite, 272
Stieltjesâ€“Lebesgue, 275â€“6
median, 83
variational characterization, 83
memoryless property, 100, 106â€“7
method
CarathÂ´eodory, 274
Jordan decomposition, 318
Markov chain Monte Carlo,
228
Monte Carlo, 153
Putzer, 319
similarity transformations, 317
uniformization, 255, 317
multiindex, 60
multiplicity of a covering, 61
norm
of a matrix
L1, 169, 210, 255
maximum expansion
coefï¬cient, 264
ODE
Cauchy problem, 313
linear systems of, 313
existence for the Cauchy
problem, 315
uniqueness for the Cauchy
problem, 314
P-almost everywhere, 287â€“8
paradox
birthdayâ€™s, 30
gamblerâ€™s ruin, 198
Pascal triangle, 1
permutation
derangement, 9
ï¬xed point, 9
image-list, 9
image-word, 9
with no ï¬xed points, 9
power series, 261
binomial series, 3
expansion
of the exponential, 263
of the inverse matrix, 265
of the logarithm, 263
geometric series, 262
matrix exponential, 266
matrix valued, 265
radius of convergence, 261,
264â€“5
sum, 6
term by term differentiation, 262
term by term integration, 262
vector valued, 264
principle
inclusionâ€“exclusion, 60, 62
probability
A given B, 51
Ïƒ-algebra of events, 35
algebra of events, 35
certain event, 34
conditional, 51
distribution, 28
event, 34
horse racing, 28

332
INDEX
probability (continued)
inclusionâ€“exclusion principle,
60, 62
interpretation
classic, 27
frequentist, 27
subjectivist, 27
measure, 36
of at least k events among n
given, 63
of one event among n given, 60,
62
space, 36
uniform, 41
problem
Cauchy for ODE, 313
mÂ´enage problem, 64
three cards, 59
product
Cauchy, 263, 264
convolution, 130, 263â€“4
property
Markov, 174
memoryless, 100, 106â€“7
multiplicative
of collocations, 23
of drawings, 18
renewal, 177
strong Markov, 178
Q-matrix, 251
eigenvalues, 253
exponential
asymptotic behaviour, 254
ï¬xed point, 254
uniformization, 255â€“6
exponential of a, 252
kernel, 254
radius of convergence, 261, 265
random variable, 69
detected events, 72
distribution, 70
distribution function, 70
expectation, 75
expected value, 75
generated events, 72
integrable, 76
integral, 75
law, 70
mean value, 75
median, 83
RN-valued, 114
square integrable, 120â€“121
standard deviation, 82
summable, 76
variance, 82
with ï¬nite expected value and
variance, 121
X follows Î¼, 70
random variables
almost sure convergence, 146,
147
correlation coefï¬cient, 123
covariance, 121
identically distributed, 128
independent, 127â€“8
integral
with respect to joint
distribution, 116
joint distribution, 113â€“14, 116
joint law, 114
uncorrelated, 122
random walks, 178
reliability of systems
parallel connected, 125
series connected, 126
Ïƒ-algebra, 35, 270
completion, 37, 272
events, 35
of Borel sets, 36, 271
of events, 72
selection
ordered, 16
from a multiset, 17
from a set, 16
simple, 16
from a multiset, 17
from a set, 17

INDEX
333
with repetition, 16
semiring, 274
sequences
convolution product, 263
set
Borel, 36, 271
measurable, 36
negligible, 37, 272
null, 37, 272, 287
singleton, 37
set function
measure, 271
Ïƒ-additive, 274
Ïƒ-ï¬nite, 272
standard deviation, 82
state
j leads to i, 171
aperiodic, 233
communicating, 171, 193, 203
period, 233
i â†’j, 171
period, 233
periodic, 233
positive recurrent, 194, 221
recurrent, 192â€“3, 203
transient, 192, 203
statistics
Boseâ€“Einstein, 24
Fermiâ€“Dirac, 24
Maxwellâ€“Boltzmann, 24
stochastic matrix, 169
absorbing class, 201
canonical form, 202
powers, 204
canonical representation, 202
closed class, 201
convergence of powers, 212
convex envelop, 210
eigenvalues, 213
ï¬xed points, 212
irreducible, 171, 221
minimal closed class, 201
regular, 210
asymptotics, 212
convergence of powers, 214
eigenvalues, 213
ï¬xed point, 218
Jordan normal form, 214
sink, 221
transition probabilities, 174
stochastic process, 246
Bernoulli, 44
counting, 256
discrete time, 173
homogeneous, 174, 177, 246
Markov chain, 174, 247
Markov property, 174â€“5, 177
Markovian, 247
path, 173
point process, 256
Poisson, 241, 243
holding time, 245
intensity, 243
right-continuous, 249
state-space, 173
states, 173
transition matrix, 174
transition probabilities, 246
stochastic vector, 169
stopping time, 177
strong Markov property, 178
theorem
Banach ï¬xed point, 208
Bayes, 52
Beppo Levi, 77, 284
Beppo Levi for series, 300
Bernstein, 152
Berryâ€“Esseen, 161
Brouwer ï¬xed point, 207
Caleyâ€“Hamilton, 320
CarathÂ´eodory, 274
Carnot, 122
central limit, 160
Cernoff, 141
coincidence criterion for
measures, 273
differentiability of continuous
semigroups, 323
dominated convergence, 302

334
INDEX
theorem (continued)
for series, 303
ErdÂ¨osâ€“Fellerâ€“Pollard, 234
ergodic, 225
Etemadi, 147
existence for the Cauchy
problem, 315
Fubini, 296
Fubiniâ€“Tonelli, 296
fundamental of calculus, 74, 307
Glivenkoâ€“Cantelli, 155
Hartmanâ€“Wintner, 151
inclusionâ€“exclusion, 62
Khitchin, 142
Kolmogorov, 296
Kolmogorov 0-1, 143
Lebesgue differentiation, 306
Lebesgue for series, 304
Markov chain realization, 179,
180
Metropolis, 232
Perronâ€“Frobenius, 209
Rademacher, 308
Rajchman, 146
renewal, 234
strong law of large numbers,
146, 147
Touchard, 64
uniformization, 256
uniqueness for the Cauchy
problem, 314
Vitali, 74
Vitali characterization of
absolute continuity, 307
Vitali differentiation of
monotone functions, 307
variance, 82
of the sum, 122
variational characterization
expected value, 84
median, 83
visits
expected number of, 191â€“2
expected return time, 194, 218,
239
expected return times, 218
ï¬rst passage time probabilities,
187, 188, 218
frequency of, 239
multiple visits, 218
number of, 189, 218
probability of more, 190
return probabilities, 188
return time, 188
expected, 193
steps between, 223
time for a ï¬rst visit, 178
time to r visits, 189
waiting time, 187
waiting time, 99, 158
weak estimate, 287

