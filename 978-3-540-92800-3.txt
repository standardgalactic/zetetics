
Lecture Notes in Computer Science
5250
Commenced Publication in 1973
Founding and Former Series Editors:
Gerhard Goos, Juris Hartmanis, and Jan van Leeuwen
Editorial Board
David Hutchison
Lancaster University, UK
Takeo Kanade
Carnegie Mellon University, Pittsburgh, PA, USA
Josef Kittler
University of Surrey, Guildford, UK
Jon M. Kleinberg
Cornell University, Ithaca, NY, USA
Alfred Kobsa
University of California, Irvine, CA, USA
Friedemann Mattern
ETH Zurich, Switzerland
John C. Mitchell
Stanford University, CA, USA
Moni Naor
Weizmann Institute of Science, Rehovot, Israel
Oscar Nierstrasz
University of Bern, Switzerland
C. Pandu Rangan
Indian Institute of Technology, Madras, India
Bernhard Steffen
University of Dortmund, Germany
Madhu Sudan
Massachusetts Institute of Technology, MA, USA
Demetri Terzopoulos
University of California, Los Angeles, CA, USA
Doug Tygar
University of California, Berkeley, CA, USA
Gerhard Weikum
Max-Planck Institute of Computer Science, Saarbruecken, Germany

Nadia Creignou Phokion G. Kolaitis
Heribert Vollmer (Eds.)
Complexity
of Constraints
An Overview of Current Research Themes
1 3

Volume Editors
Nadia Creignou
LIF (CNRS UMR 6166)
Aix-Marseille Université
Marseille, France
E-mail: creignou@lif.univ-mrs.fr
Phokion G. Kolaitis
IBM Almaden Research Center
E-mail: kolaitis@almaden.ibm.com
and
Computer Science Department
University of California, Santa Cruz
E-mail: kolaitis@cs.ucsc.edu
Heribert Vollmer
Institut für Theoretische Informatik
Leibniz Universität Hannover
Hannover, Germany
E-mail: vollmer@thi.uni-hannover.de
Library of Congress Control Number: Applied for
CR Subject Classiﬁcation (1998): F.2, E.1, G.2, I.2.8, I.3.5, G.1
LNCS Sublibrary: SL 1 – Theoretical Computer Science and General Issues
ISSN
0302-9743
ISBN-10
3-540-92799-9 Springer Berlin Heidelberg New York
ISBN-13
978-3-540-92799-0 Springer Berlin Heidelberg New York
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is
concerned, speciﬁcally the rights of translation, reprinting, re-use of illustrations, recitation, broadcasting,
reproduction on microﬁlms or in any other way, and storage in data banks. Duplication of this publication
or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965,
in its current version, and permission for use must always be obtained from Springer. Violations are liable
to prosecution under the German Copyright Law.
springer.com
© Springer-Verlag Berlin Heidelberg 2008
Printed in Germany
Typesetting: Camera-ready by author, data conversion by Scientiﬁc Publishing Services, Chennai, India
Printed on acid-free paper
SPIN: 12592739
06/3180
5 4 3 2 1 0

Preface
In October 2006, the editors of this volume organized a Dagstuhl Seminar on
“Complexity of Constraints” at the Schloss Dagstuhl Leibniz Center for Infor-
matics in Wadern, Germany. This event consisted of both invited and contributed
talks by some of the approximately 40 participants, as well as problem sessions
and informal discussions. After the conclusion of the seminar, the organizers
invited a number of speakers to write surveys presenting the state-of-the-art
knowledge in their area of expertise. These contributions were peer-reviewed by
experts in the ﬁeld and revised before they were included in this volume. In addi-
tion, this volume contains a reprint of a survey by P.G. Kolaitis and M.Y. Vardi
on the logical approach to constraint satisfaction that ﬁrst appeared in “Finite
Model Theory and Its Applications,” (Springer 2007).
We thank the Directorate of Schloss Dagtuhl for its support, the speakers
of the seminar for making it a successful event, and, above all, the contributors
to this volume for their informative and well-written surveys. We also thank
Arne Meier for technical assistance during the ﬁnal compilation of this book,
and Alfred Hofmann at Springer for his support and guidance.
July 1 (the birthday of Gottfried Wilhelm Leibniz) 2008
Nadia Creignou
Phokion G. Kolaitis
Heribert Vollmer

Table of Contents
Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
Boolean Constraint Satisfaction Problems: When Does Post’s Lattice
Help? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
Nadia Creignou and Heribert Vollmer
Basics of Galois Connections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
Ferdinand B¨orner
Recent Results on the Algebraic Approach to the CSP . . . . . . . . . . . . . . . .
68
Andrei A. Bulatov and Matthew A. Valeriote
Dualities for Constraint Satisfaction Problems . . . . . . . . . . . . . . . . . . . . . . .
93
Andrei A. Bulatov, Andrei Krokhin, and Benoit Larose
A Logical Approach to Constraint Satisfaction . . . . . . . . . . . . . . . . . . . . . . .
125
Phokion G. Kolaitis and Moshe Y. Vardi
Uniform Constraint Satisfaction Problems and Database Theory . . . . . . .
156
Francesco Scarcello, Georg Gottlob, and Gianluigi Greco
Constraint Satisfaction Problems with Inﬁnite Templates . . . . . . . . . . . . .
196
Manuel Bodirsky
Partial Polymorphisms and Constraint Satisfaction Problems . . . . . . . . . .
229
Henning Schnoor and Ilka Schnoor
Introduction to the Maximum Solution Problem . . . . . . . . . . . . . . . . . . .
255
Peter Jonsson and Gustav Nordh
Present and Future of Practical SAT Solving . . . . . . . . . . . . . . . . . . . . . . . .
283
Oliver Kullmann
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
321

Introduction
The ﬁrst systematic complexity-theoretic study of constraints was carried out by
T.J. Schaefer in 1978 with a paper on Boolean constraint satisfaction problems
(CSPs). This volume opens with a survey of Boolean constraints by N. Creignou
and H. Vollmer. Schaefer proved a Dichotomy Theorem about the satisﬁabil-
ity problem for Boolean CSPs, which asserts that each Boolean CSP is either
NP-complete or in P (hence, assuming P ̸= NP, all inﬁnitely many intermediate
complexity degrees are avoided). Creignou and Vollmer present a modern alge-
braic proof of Schaefer’s Dichotomy Theorem, a proof that makes use of Galois
theory and of the structure of the lattice of Boolean clones, known as Post’s
lattice. In addition to the satisﬁability problem, several other algorithmic prob-
lems, including counting, optimization, and circumscription, can be completely
classiﬁed from a complexity point of view using Post’s lattice. The ﬁrst contri-
bution to this volume surveys these results and poses the question: what is so
special about certain algorithmic tasks that makes Post’s lattice applicable to
their classiﬁcation.
The realm of Boolean universes is by now quite well understood. When moving
to larger ﬁnite domains, the complexity-theoretic study of CSPs relies on Galois
connections. The second contribution to this volume, by F. B¨orner, presents
a systematic introduction to Galois theory, to the widely used Pol-Inv Galois
connection, and also to variants of this Galois connection that only very recently
have turned out to be important for the study of CSPs.
One complication that arises when moving from 2-element universes to larger
ones is that the lattice of clones is well-understood only for the former case.
As a matter of fact, this lattice becomes uncountable even for 3-element do-
mains. Consequently, even though the algebraic underpinnings remain the same,
the situation now becomes much more complicated in a fundamental way. In
1993, T. Feder and M.Y. Vardi articulated their Dichotomy Conjecture to the
eﬀect that the satisﬁability problem will avoid all degrees between 0 (polynomial
time) and 1 (NP-complete) in all ﬁnite domains. This conjecture was proved by
A. Bulatov for 3-element universes in 2002, but it remains open to this day
for all domains of cardinality bigger than 3. The survey by A. Bulatov and
M. Valeriote describes recent algebraic attacks to the Feder-Vardi Dichotomy
Conjecture, leading to some rather unexpected universal-algebraic formulations
of this conjecture in the language of tame congruence theory.
The survey by A. Bulatov, A. Krokhin, and B. Larose focuses on dualities and
their relationship to the Feder-Vardi Dichotomy Conjecture. In fact, the class of
CSPs that exhibit the so called bounded treewidth duality is one of the largest
classes with a tractable satisﬁability problem. Additional large tractable classes
can be identiﬁed using a logical approach, as described in the survey by Kolaitis
and Vardi.
N. Creignou et al. (Eds.): Complexity of Constraints, LNCS 5250, pp. 1–2, 2008.
c
⃝Springer-Verlag Berlin Heidelberg 2008

2
An important line of research identiﬁes “islands of tractability” for the uni-
form constraint satisfaction problem, where not only the conjunctive query but
also the algebraic structure of the constraints is part of the input. Interestingly,
this ﬁeld has a tight connection to database theory, and many algorithmic ap-
proaches from there lead to signiﬁcant progress in the complexity of (uniform)
CSPs. This is the topic of the survey by F. Scarcello, G. Gottlob, and S. Greco.
In another variant of CSPs, which has been studied only very recently, one
considers the situation where the constraints are deﬁned over an inﬁnite domain.
The survey by M. Bodirsky presents important examples of such problems, shows
how the universal-algebraic approach ﬁnds applications here, and overviews both
the main results and certain fundamental questions that remain open.
The contribution by H. Schnoor and I. Schnoor returns to question of deter-
mining for which algorithmic problems Post’s lattice may help. While the usual
Pol-Inv Galois connection is tailored towards the satisﬁability problem (and for
additional algorithmic tasks), Shnoor and Schnoor show that a similar Galois
connection involving clones of partial functions is potentially applicable to a
wide range of algorithmic problems. Unfortunately, even in the Boolean case,
the lattice of partial clones is uncountable; nonetheless, Schnoor and Schnoor
show that for such algorithmic problems as enumeration, equivalence, and many
others, a countable spine of this lattice can be identiﬁed that is good enough for
obtaining a complexity-theoretic classiﬁcation.
The interesting issue of the complexity of approximation for optimization
problems makes also sense in the context of CSPs. The survey by P. Jonsson and
G. Nordh introduces an optimization variant of the constraint satisfaction prob-
lem, and presents complexity and approximability results. This variant, which
associates a weight to every solution, captures many well-known combinatorial
optimization problems. Thus, many diﬀerent problems can be given a uniform
treatment when it comes to solve them or to analyze their complexity.
Formulating algorithmic problems as propositional satisﬁability (SAT) prob-
lems has become an important problem-solving technique that competes with
the CSP approach. In particular, there is a considerable interest in transferring
SAT techniques to the CSP context. In the last contribution to this volume,
O. Kullmann presents an overview of current paradigms of SAT solving.

Boolean Constraint Satisfaction Problems:
When Does Post’s Lattice Help?
Nadia Creignou1 and Heribert Vollmer2
1 LIF (CNRS UMR 6166), Aix-Marseille Universit´e, 163 avenue de Luminy,
F-13288 Marseille, France
creignou@lif.univ-mrs.fr
2 Institut f¨ur Theoretische Informatik, Leibniz Universit¨at Hannover, Appelstr. 4,
D-30167 Hannover, Germany
vollmer@thi.uni-hannover.de
1
Satisﬁability Problems
The propositional satisﬁability problem SAT, i.e., the problem to decide, given
a propositional formula φ (without loss of generality in conjunctive normal form
CNF), if there is an assignment to the variables in φ that satisﬁes φ, is the his-
torically ﬁrst and standard NP-complete problem [Coo71]. However, there are
well-known syntactic restrictions for which satisﬁability is eﬃciently decidable,
for example if every clause in the CNF formula has at most two literals (2CNF
formulas) or if every clause has at most one positive literal (Horn formulas) or
at most one negative literal (dual Horn formulas), see [KL99]. To study this phe-
nomenon more generally, we study formulas with “clauses” of arbitrary shapes,
i.e., consisting of applying arbitrary relations R ⊆{0, 1}k to (not necessarily
distinct) variables x1, . . . , xk. A constraint language Γ is a ﬁnite set of such rela-
tions. In the rest of this chapter, Γ and Γ ′ will always denote Boolean constraint
languages. A Γ-formula is a conjunction of clauses R(x1, . . . , xk) as above us-
ing only relations R from Γ. The for us central family of algorithmic problems,
parameterized by a constraint language Γ, now is the problem to determine
satisﬁability of a given Γ-formula, denoted by Csp(Γ).
The NP-complete problem 3SAT, the satisﬁability problem for CNF formulas
with exactly three literals per clause, now is the problem CSP(Γ3SAT), where
Γ3SAT = {x ∨y ∨z, x ∨y ∨¬z, x ∨¬y ∨¬z, ¬x ∨¬y ∨¬z}; here and in the sequel
we do not distinguish between a formula φ and the logical relation Rφ it deﬁnes,
i.e., the relation consisting of all satisfying assignments of φ. If every relation
in Γ is deﬁnable by a Horn formula, then Csp(Γ) is polynomial-time decidable,
also if every relation in Γ is deﬁnable by a 2-CNF formula. Hence we see that the
family of problems Csp(Γ) has NP-complete members as well as easily solvable
members.
A question attacked by Thomas Schaefer [Sch78] is the following: Can we
determine for each constraint language Γ the complexity of Csp(Γ)? Is there
even a simple algorithm that, given Γ, determines the complexity of Csp(Γ)?
Are there more cases than NP-complete and polynomial-time solvable? In this
chapter we will present a way to answer these questions that relies on notions
N. Creignou et al. (Eds.): Complexity of Constraints, LNCS 5250, pp. 3–37, 2008.
c
⃝Springer-Verlag Berlin Heidelberg 2008

4
N. Creignou and H. Vollmer
and results from universal algebra. A central rˆole in our development will be an
exploitation of the structure of Post’s lattice of all Boolean clones, all classes of
Boolean functions closed under superposition (composition). Post’s lattice will
turn out to be a very helpful tool to classify the complexity of Csp(Γ), but also
of related algorithmic problems for Γ-formulas and generalizations thereof such
as quantiﬁed Boolean formulas, for instance counting the number of satisfying
assignments of quantiﬁed Boolean formulas, model checking for circumscription
(minimal satisﬁability), and many more.
In this chapter we will ﬁrst present a full account of Schaefer’s Theorem and
related results for quantiﬁed formulas. Then we will survey complexity classiﬁca-
tions obtained for many further computational problems for Boolean constraint
satisfaction problems in the recent past, with a particular emphasis on the ques-
tion when Post’s lattice can be used in obtaining the classiﬁcation and when not.
2
Background from Universal Algebra
A logical relation (or constraint relation) of arity k is a relation R ⊆{0, 1}k. A
constraint (or constraint application) is a formula R(x1, . . . , kk), where R is a
logical relation of arity k and the x1, . . . , xk are (not necessarily distinct) vari-
ables. An assignment I of truth values to the variables satisﬁes the constraint
if

I(x1), . . . , I(xk)

∈R. A constraint language Γ is a ﬁnite set of logical rela-
tions. A Γ-formula is a conjunction of constraint applications using only logical
relations from Γ. Such a formula φ is satisﬁed by an assignment I if I satisﬁes
all constraints in φ simultaneously.
Problem:
Csp(Γ)
Input:
a Γ-formula φ
Question:
Is φ satisﬁable, i.e., is there an assignment that satisﬁes
φ?
When we want to determine the complexity of all CSP-problems, we will
certainly need a way to compare the complexity of Csp(Γ) and Csp(Γ ′) for
diﬀerent constraint languages Γ and Γ ′. For example, to show that some Csp(Γ)
is NP-complete we might show that using Γ we can “ simulate” or “implement”
all relations in Γ3SAT, and to show that Csp(Γ) is polynomial-time decidable we
might implement all relations in Γ using Horn-formulas. As it turns out, a useful
notion of implementation comes from universal algebra, from clone theory.
Deﬁnition 2.1. For a constraint language Γ, let ⟨Γ⟩, the relational clone (or
co-clone) generated by Γ, be the smallest set of relations such that
– ⟨Γ⟩contains the equality relation and all relations in Γ, and
– ⟨Γ⟩is closed under primitive positive deﬁnitions, i.e., if φ is a ⟨Γ⟩-formula
and R(x1, . . . , xn) ≡∃y1 . . . yℓφ(x1, . . . , xn, y1, . . . , yℓ), then R ∈⟨Γ⟩.
Intuitively, ⟨Γ⟩contains all relations that can be implemented by Γ and is thus
called the expressive power of Γ, as justiﬁed by the following observation:

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
5
Proposition 2.2. If Γ ⊆⟨Γ ′⟩then Csp(Γ) ≤log
m Csp(Γ ′).
Proof. Let φ be a Γ-formula. We construct a formula φ′ by performing the
following steps:
– Replace every constraint from Γ by its deﬁning existentially quantiﬁed

Γ ′∪
{=}

-formula.
– Delete existential quantiﬁers.
– Delete equality clauses and replace all variables that are connected via a
chain of equality constraints by a common new variable.
Then, obviously, φ′ is a Γ ′-formula, and moreover, φ is satisﬁable if and only if
φ′ is satisﬁable. The complexity of the above transformation is dominated by the
last step, which is essentially an instance of the undirected graph reachability
problem, which is solvable in logarithmic space [Rei05]. Hence we conclude that
Csp(Γ) is reducible to CSP(Γ ′) under logspace reductions.
□
In particular, we thus have shown that the complexity of Csp(Γ) depends only
on ⟨Γ⟩in the following sense:
Proposition 2.3. If ⟨Γ⟩= ⟨Γ ′⟩, then Csp(Γ) ≡log
m Csp(Γ ′),
Thus, we “only” have to study co-clones in order to obtain a full classiﬁcation,
and the question arises what co-clones there are. Astonishingly, all co-clones,
each with a “simple” basis, are known. The key to obtain this list is to study
closure properties of relations.
Deﬁnition 2.4. Let f : {0, 1}m →{0, 1} and R ⊆{0, 1}n. We say that f pre-
serves R, f ≈R, if for all x1, . . . , xm ∈R, where xi = (xi[1], xi[2], . . . , xi[n]), we
have

f

x1[1], · · · , xm[1]

, f

x1[2], · · · , xm[2]

, . . . , f

x1[n], · · · , xm[n]

∈R.
In other words, f ≈R if the coordinate-wise application of f to a sequence of m
vectors in R always results in a vector that again is in R. Then we also say that
R is invariant under f or that f is a polymorphism of R, and for a set of relations
Γ we write Pol(Γ) to denote the set of all polymorphisms of Γ, i.e., the set of all
Boolean functions that preserve every relation in Γ. For technical reasons, we
will exclude the empty relation (constraint) and nullary polymorphisms in the
rest of this paper.
It is now straightforward to verify that for every Γ, Pol(Γ) is a clone, i.e., a set
of Boolean functions that contains all projections (all functions In
k(x1, . . . , xn) =
xk for 1 ≤k ≤n) and is closed under composition; the smallest clone containing
a set B of Boolean functions will be denoted by [B] in the sequel (B is also called
a basis for [B]). In fact, the connection between clones and relational clones is
much tighter. For a set B of Boolean functions, let Inv(B) denote the set of all
invariants of B, i.e., the set of all Boolean relations that are preserved by every
function in B. It can be observed that each Inv(B) is a relational clone.

6
N. Creignou and H. Vollmer
As shown ﬁrst in [Gei68, BKKR69] (see also [Lau06, Sect. 2.9]), the operators
Pol-Inv constitute a Galois correspondence between the lattice of sets of Boolean
relations and the lattice of sets of Boolean functions. In particular, for every set
Γ of Boolean relations and every set B be of Boolean functions,
Proposition 2.5.
– Inv

Pol(Γ)

= ⟨Γ⟩,
– Pol

Inv(B)

= [B].
Hence, Proposition 2.2 can equivalently be stated as follows:
Proposition 2.6. If Pol(Γ) ⊇Pol(Γ ′) then Csp(Γ) ≤log
m Csp(Γ ′).
Thus, there is a one-to-one correspondence between clones and co-clones and we
may compile a full list of relational clones from the list of clones obtained by
Emil Post in [Pos20, Pos41]. In these papers, Post presented a complete list of
Boolean clones, the inclusion structure among them (see Fig. 1), and a ﬁnite
basis for each of them (Fig. 2). We do not have enough space here to give a
full account of Post’s lattice, as the structure became known, but we refer the
interested reader to [Pip97] for a gentle introduction to clones, co-clones, the
Galois connection, and Post’s results. A rigorous comprehensive study is given
in [Lau06]. Complexity-theoretic applications of Post’s lattice in the constraint
context but also the Boolean circuit context are surveyed in [BCRV03, BCRV04].
A compilation of all co-clones with simple bases is given in [BRSV05].
For the purpose of this paper, we deﬁne the clones by simply giving a basis for
each of them, see Fig. 2, i.e., the third column of the table gives for each clone its
deﬁning basis. One function appearing in the bases that is maybe not so familiar
is the threshold function Tn
k, where Tn
k(x1, . . . , xn) = 1 ⇐⇒n
i=1 xi ≥k. Also,
for a function f, dual(f), the dual function of f, is given by dual

f(a1, . . . , an)

=
f(a1, . . . , an).
Let us turn in a little bit more detail to that part of the lattice that will be
important here. First, let us give an additional deﬁnition. Assuming a canoni-
cal order on variables, one can regard assignments as tuples. Thus, with each
quantiﬁer free propositional formula φ one can associate the relation Rφ of all
satisfying assignments of φ. In the following, we say that a relation R is deﬁned
by a formula φ if R = Rφ. The clone generated by the logical AND function is
denoted by E2. A relation is preserved by AND if and only if it is Horn, that is,
deﬁnable by a Horn-formula, i.e., Inv(E2) is the set of all Horn relations. Simi-
larly, V2 = [{OR}], and Inv(V2) is the set of all dual Horn relations. Relations
deﬁnable by 2CNF formulas, the so-called bijunctive relations, are exactly those
in Inv(D2), where D2 is the clone generated by the 3-ary majority function. Fi-
nally, the clone L2 is generated by the 3-ary exclusive-or x ⊕y ⊕z (the 3-ary
addition in GF[2]), and Inv(L2) is the set of all aﬃne formulas, i.e., conjunctions
of XOR-clauses (consisting of an XOR of some variables plus maybe the constant
1)—these formulas may also be seen as systems of linear equations over GF[2].
Let us say that a constraint language is Schaefer, if it belongs to one of
the above four types, i.e., Γ is Horn (i.e., every relation in Γ is Horn), dual
Horn, bijunctive, or aﬃne. If Γ is Schaefer then Csp(Γ) is polynomial-time

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
7
R1
R0
BF
R2
M
M1
M0
M2
S2
0
S3
0
S0
S2
02
S3
02
S02
S2
01
S3
01
S01
S2
00
S3
00
S00
S2
1
S3
1
S1
S2
12
S3
12
S12
S2
11
S3
11
S11
S2
10
S3
10
S10
D
D1
D2
L
L1
L0
L2
L3
V
V1
V0
V2
E
E0
E1
E2
I
I1
I0
I2
N2
N
Fig. 1. Post’s lattice
solvable, as already noted above for the cases Horn, dual Horn, and bijunctive;
for the remaining case of aﬃne relations we remark that we use the interpretation
as equations over GF[2] and thus may check satisﬁability eﬃciently using the
Gaussian algorithm. (A detailed exposition can be found in [CKS01].)
There is a unique minimal relational clone that is not Schaefer: this is the
co-clone Inv(N), where the clone N is generated by the negation function NOT
plus the Boolean constants 0, 1. This relational clone consists of all relations

8
N. Creignou and H. Vollmer
Class Description
Base
BF
all Boolean functions
{∧, ¬}
R0
0-reproducing functions
{∧, ⊕}
R1
1-reproducing functions
{∨, x ⊕y ⊕1}
R2
R1 ∩R0
{∨, x ∧(y ⊕z ⊕1)}
M
monotone functions
{∧, ∨, 0, 1}
M1
M ∩R1
{∧, ∨, 1}
M0
M ∩R0
{∧, ∨, 0}
M2
M ∩R2
{∧, ∨}
Sn
0
functions that are 0-separating of degree n
{→, dual(Tn+1
n
)}
S0
0-separating functions
{→}
Sn
1
functions that are 1-separating of degree n
{x ∧y, Tn+1
n
}
S1
1-separating functions
{x ∧y}
Sn
02
Sn
0 ∩R2
{x ∨(y ∧z), dual(Tn+1
n
)}
S02
S0 ∩R2
{x ∨(y ∧z)}
Sn
01
Sn
0 ∩M
{dual(Tn+1
n
), 1}
S01
S0 ∩M
{x ∨(y ∧z), 1}
Sn
00
Sn
0 ∩R2 ∩M
{x ∨(y ∧z), dual(Tn+1
n
)}
S00
S0 ∩R2 ∩M
{x ∨(y ∧z)}
Sn
12
Sn
1 ∩R2
{x ∧(y ∨z), Tn+1
n
}
S12
S1 ∩R2
{x ∧(y ∨z)}
Sn
11
Sn
1 ∩M
{Tn+1
n
, 0}
S11
S1 ∩M
{x ∧(y ∨z), 0}
Sn
10
Sn
1 ∩R2 ∩M
{x ∧(y ∨z), Tn+1
n
}
S10
S1 ∩R2 ∩M
{x ∧(y ∨z)}
D
self-dual functions
{xy ∨xz ∨yz}
D1
D ∩R2
{xy ∨xz ∨yz}
D2
D ∩M
{T3
2}
L
linear functions
{⊕, 1}
L0
L ∩R0
{⊕}
L1
L ∩R1
{≡}
L2
L ∩R2
{x ⊕y ⊕z}
L3
L ∩D
{x ⊕y ⊕z ⊕1}
V
∨-functions plus constant functions
{∨, 0, 1}
V0
[{∨}] ∪[{0}]
{∨, 0}
V1
[{∨}] ∪[{1}]
{∨, 1}
V2
[{∨}]
{∨}
E
∧-functions plus constant functions
{∧, 0, 1}
E0
[{∧}] ∪[{0}]
{∧, 0}
E1
[{∧}] ∪[{1}]
{∧, 1}
E2
[{∧}]
{∧}
N
[{¬}] ∪[{0}] ∪[{1}]
{¬, 1}, {¬, 0}
N2
[{¬}]
{¬}
I
I2 ∪[{1}] ∪[{0}]
{0, 1}
I0
I2 ∪[{0}]
{0}
I1
I2 ∪[{1}]
{1}
I2
all projections
∅
Fig. 2. List of all Boolean clones with their deﬁning bases

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
9
Pol(R) ⊇V2
⇔R is dual Horn
Pol(R) ⊇E2
⇔R is Horn
Pol(R) ⊇V0
⇔R is deﬁnite dual Horn
Pol(R) ⊇E1
⇔R is deﬁnite Horn
Pol(R) ⊇S00 ⇔R is IHSB+
Pol(R) ⊇S10 ⇔R is IHSB−
Pol(R) ⊇L2
⇔R is aﬃne
Pol(R) ⊇D2
⇔R is bijunctive
Pol(R) ⊇D1
⇔R is aﬃne with width 2
Pol(R) ⊇N2
⇔R is complementive
Pol(R) ⊇I1
⇔R is 1-valid
Pol(R) ⊇I0
⇔R is 0-valid
Pol(R) ⊇I2
⇔R is any relation
Pol(R) ⊇N
⇔R is compl.,
0- and 1-valid
Fig. 3. Characterizations of some classes of relations
that are at the same time complementive (negating all entries of a tuple in
the relations leads again to a tuple in the relation), 1-valid (the all-1 tuple
is in the relation), and 0-valid (the all-0 tuple is in the relation). Because of
these latter two properties, satisﬁability for CSPs build using only relations
from Inv(N) is again eﬃciently decidable (in fact, they are all satisﬁable). If we
drop the requirement 1-valid and 0-valid we arrive at the relational clone Inv(N2)
consisting of all complementive relations (N2 = [{NOT}]). Obviously, Inv(N) ⊆
Inv(N2), and from Post’s lattice it can be seen that there is no relational clone
in between. The only super-co-clone of Inv(N2) is the co-clone Inv(I2) of all
relations (I2 = [∅]). These remarks are summarized in Fig. 3.
For some of the classiﬁcations we give below, we want to introduce other
classes of relations. Let us ﬁrst introduce classes of formulas which form sub-
classes of and are less expressive than the class of Horn and dual Horn formulas,
namely deﬁnite Horn and IHSB (for implicative hitting set bounded); for more
background the reader is asked to consult [CKS01]. A deﬁnite Horn (resp. def-
inite dual Horn) formula is a CNF formula having exactly one positive (resp.,
negative) literal in each clause. A clause is said to be IHSB−if it is of one of
the following types: (xi), (¬xi1 ∨xi2) or (¬xi1 ∨. . . ∨¬xik) for some k ≥1.
Dually, a clause is said to be IHSB+ if it is of one of the following types: (¬xi),
(¬xi1 ∨xi2) or (xi1 ∨. . . ∨xik) for some k ≥1. Finally, a formula is said to be
IHSB−(resp. IHSB+) if all its clauses are IHSB−(resp. IHSB+).
As usual a Boolean relation R is said to be IHSB−(resp. IHSB+, deﬁnite
Horn, deﬁnite dual Horn) if R can be deﬁned by a CNF formula which is IHSB−
(resp. IHSB+, , deﬁnite Horn, deﬁnite dual Horn). A relation is aﬃne with width
2 if it is deﬁnable by a conjunction of clauses, each of which being either a unary
clause or a 2-XOR-clause (consisting of an XOR of 2 variables plus maybe the
constant 1)— such a conjunctive formula may also be seen as a system of linear
equations over GF[2] with at most two variables per equation. It can be proved
that a relation is aﬃne with width 2 if and only if it is both aﬃne and bijunctive.
Finally, a constraint language Γ is said to be aﬃne with width 2 (resp. IHSB−,
IHSB+, deﬁnite Horn, deﬁnite dual Horn) if every relation in Γ is aﬃne with
width 2 (resp. IHSB−, IHSB+, deﬁnite Horn, deﬁnite dual Horn).
As for the above introduced classes, all these subclasses of aﬃne and (dual)
Horn relations can be characterized by their polymorphisms, see again Fig. 3.

10
N. Creignou and H. Vollmer
3
Complexity of Satisﬁability for Γ -Formulas and
Quantiﬁed Γ -Formulas
We have seen that if Γ is Schaefer or 0-valid or 1-valid then Csp(Γ) is decidable
in polynomial time. If Γ is not of this form, then we have seen that that ⟨Γ⟩⊇
Inv(N2), the co-clone of all complementive relations. A particular example here
is the relation
RNAE =

(0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0)

(“NAE” here stands for “not all equal”). The language Csp({RNAE}) thus con-
sists of 3CNF formulas with only positive literals where we require that in ev-
ery clause not all literals obtain the same truth value. This is the so-called
Not-All-Equal problem, known to be NP-complete (see, e.g., [Pap94]). Thus,
we have proved Schaefer’s Theorem:
Theorem 3.1. If ⟨Γ⟩⊇Inv(N2) then Csp(Γ) is NP-complete, in all other
cases, Csp(Γ) is polynomial-time decidable.
In making use of Post’s lattice (Fig. 1) this theorem can be reformulated as
follows: If Pol(Γ) ⊇E2 or Pol(Γ) ⊇V2 or Pol(Γ) ⊇D2 or Pol(Γ) ⊇L2, or if
Pol(Γ) ⊇I0 or Pol(Γ) ⊇I1 then Csp(Γ) is polynomial-time decidable, otherwise
Csp(Γ) is NP-complete. Finally, in using the characterizations summarized in
Fig. 3, Schaefer’s theorem can be stated in more familiar terms: If Γ is Schaefer
or 0-valid or 1-valid then Csp(Γ) is polynomial-time decidable, otherwise Γ can
express all complementive relations and Csp(Γ) is NP-complete. In the list of
complexity results that we will present in Sect. 6 below we will most of the time
prefer the formulation as in Theorem 3.1; only in a few particular cases we will
additionally present the classiﬁcation using classical terms.
Because each member of the inﬁnite family of the CSP-problems falls in two com-
plexity cases and avoids the (under the assumption P ̸= NP) inﬁnitely many inter-
mediate degrees, this theorem is also known as Schaefer’s Dichotomy Theorem.
Recently there has been growing interest in quantiﬁed constraints, and we
want to survey some of the developments here. The Csp(Γ) problem is equivalent
to asking if a Γ-formula with all variables existentially quantiﬁed evaluates to
true. In the quantiﬁed CSP problem one allows also universal quantiﬁers.
Let us ﬁrst go one step back and look at usual propositional formulas again.
The problem QBF of deciding, whether a given closed quantiﬁed propositional
formula is true, is PSPACE-complete [SM73], even if the formula is restricted
to 3CNF. If the number of quantiﬁer alternations is bounded, the problem is
complete in the polynomial-time hierarchy, which was deﬁned by Meyer and
Stockmeyer [MS72]. Following the notation of [Pap94], Σ0P = Π0P = P and for
all i ≥0, Σi+1P = NPΣiP and Πi+1P = coNPΣiP. The set QBFk of all closed,
true quantiﬁed Boolean formulas with k −1 quantiﬁer alternations starting with
an ∃-quantiﬁer, is complete for ΣkP for all k ≥1 [SM73]. This problem remains
ΣkP-complete if we restrict the Boolean formula to be 3CNF for k odd, and
3DNF for k even [Wra77]. Since disjunctive normal forms cannot be naturally

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
11
modelled in a constraint satisfaction context, in order to generalize QBFk to
arbitrary set of constraints Γ in the same way we generalized SAT to Csp(Γ), we
consider the unsatisﬁability problem for these cases and we adopt the following
deﬁnition for Qcspk(Γ) from [Hem04].
Let Γ be a constraint language and k ≥1. For k odd, a Qcspk(Γ) formula is
a closed formula of the form φ = ∃X1∀X2 . . . ∃Xkψ, and for k even, a Qcspk(Γ)
formula is a closed formula of the form φ = ∀X1∃X2 . . . ∃Xkψ, where the Xj,
j = 1, . . . , k, are disjoint sets of variables and ψ is a quantiﬁer-free Γ-formula
with variables from 
j Xj.
Problem:
Qcspk(Γ)
Input:
a Qcspk(Γ)-formula φ
Question:
If k is odd: Is φ true?
If k is even: Is φ false?
As in the case of simple CSPs above, we note that the Galois connection still
helps to study the complexity of QCSP:
Proposition 3.2. If Γ ⊆⟨Γ ′⟩then Qcspk(Γ) ≤log
m Qcspk(Γ ′) for all k ≥1.
Proof. The proof of this is very similar to the one for Proposition 2.2: Given a
Γ-formula φ, we construct a formula φ′ by replacing every constraint from Γ by
its deﬁning existentially quantiﬁed

Γ ′ ∪{=}

-formula. The newly introduced
quantiﬁed variables will be quantiﬁed in the ﬁnal quantiﬁer block which is by
deﬁnition of Qcspk(Γ)-formulas always existential. All that remains to do now
is to delete equality clauses as above.
□
Certainly, for every constraint language Γ and every k ≥1, Qcspk(Γ) ∈ΣkP
and Qcspk(Γ3SAT) is ΣkP-complete. In fact, even for the single constraint rela-
tion
R1-IN-3 = {(1, 0, 0), (0, 1, 0), (0, 0, 1)}
we have that Qcspk({R1-IN-3}) is ΣkP-complete. This follows since R1-IN-3 is
only closed under projections and, thus, Pol(R1-IN-3) is the minimal clone I2 in
Post’s lattice and ⟨R1-IN-3⟩is the co-clone Inv(I2) of all Boolean relations. Thus,
from Proposition 3.2 we conclude Qcspk(Γ3SAT) ≤log
m Qcspk({R1-IN-3}).
In the case of Schaefer’s theorem for CSP, already the constraint language
consisting of the relation RNAE is hard. We want to show an analogous result for
QCSP next. To show this, we will reduce Qcspk({R1-IN-3}) to Qcspk({RNAE}):
Let φ be a Qcspk({R1-IN-3})-formula,
φ = Q1X1 . . . ∃Xk
p	
j=1
R1-IN-3(xj1, xj2, xj3),
where Q is existential if k is odd and universal if k is even. We now replace each
constraint R1-IN-3(xj1, xj2, xj3) by the following conjunction:
	
j̸=k∈{j1,j2,j3}
RNAE(xj, xk, t) ∧RNAE(xj1, xj2, xj3).

12
N. Creignou and H. Vollmer
It can be checked that this conjunction is true if and only if exactly two of the four
variables xj1, xj2, xj3, t are true, hence we will abbreviate the above formula by
R2-IN-4(xj1, xj2, xj3, t). Now let φ′ = Q1X1 . . . ∃Xk

p
j=1 R2-IN-4(xj1, xj2, xj3, t).
Since R1-IN-3(x, y, z) = R2-IN-4(x, y, z, 1), the formula φ′[t = 1] (every occurrence
of t in φ is replaced by 1) is true if and only if φ is true. Since R1-IN-3(¯x, ¯y, ¯z) =
R2-IN-4(x, y, z, 0), the formula φ′[t/0] is true if and only if Ren(φ) is true, where
Ren(φ) is obtained from φ by renaming all variables x by their negation ¯x.
Finally, since Ren(φ) is true if and only if φ is true, we proved that φ is true if
and only if φ′ is true. Thus, Qcspk({R1-IN-3}) ≤log
m Qcspk({RNAE}).
Hence we now know that if ⟨Γ⟩⊇Inv(N2), then Qcspk(Γ) is complete for
ΣkP for every k ≥1. What about the next lower relational clone Inv(N)? In the
case of Csp(Γ) (i.e., Qcsp1(Γ)), satisﬁability is trivial for all Γ ⊆Inv(N), since
every formula is satisﬁed by the constant-0 or constant-1 assignment. However,
this tells us nothing about Qcspk(Γ) for k ≥2. Let us look at the relation
R0 =

(u, v, x1, x2, x3)
 u = v or RNAE(x1, x2, x3)

.
It is easy to see that R0 is complementive, 0-valid, and 1-valid. We will show
that Qcspk({RNAE}) reduces to Qcspk({R0}). Let
φ = Q1X1 . . . ∃Xk
p	
j=1
RNAE(xj1, xj2, xj3),
where Q1 is existential if k is odd and universal if k is even, be an instance of
Qcspk({RNAE}). We deﬁne
φ′ = Q1X1 . . . ∀Xk−1∀u∀v∃Xk
p	
j=1
R0(u, v, xj1, xj2, xj3).
Clearly φ is true if and only if φ′ is true, thus Qcspk({RNAE}) ≤log
m Qcspk({R0})
for all k ≥2.
We conclude that if ⟨Γ⟩⊇Inv(N), then Qcspk(Γ) is complete for ΣkP for
every k ≥2. If we drop the bound on the number of quantiﬁer alternations
and denote the resulting problem by Qcsp(Γ), we know from [SM73] that
Qcsp(Γ3SAT) is PSPACE-complete. The just given reductions thus also show
that if ⟨Γ⟩⊇Inv(N), then Qcsp(Γ) is PSPACE-complete.
If Γ does not include Inv(N), we know from the structure of Post’s lattice
that it must be Schaefer. However, it is known that in all four cases (Horn, dual
Horn, bijunctive, and aﬃne), the evaluation of quantiﬁed formulas is computable
in polynomial time (the algorithms for the ﬁrst three cases rely on Q-resolution,
a variant of resolution for quantiﬁed propositional formulas, see [KL99]; the algo-
rithm for the aﬃne case is a reﬁnement of the Gaussian algorithm, see [CKS01]).
Thus we have proved the following classiﬁcation:
Theorem 3.3. If Γ is Schaefer then Qcsp(Γ) is polynomial-time decidable, in
all other cases, Qcsp(Γ) is PSPACE-complete.

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
13
This result was stated without proof and only for constraint languages that
include the constants in Schaefer’s paper [Sch78]. In its full form it was stated
and proven for the ﬁrst time in [Dal97] and later published in [CKS01].
Looking at QCSPs with bounded quantiﬁer alternations we obtain with the
same proof as above Hemaspaandra’s Theorem [Hem04]. For all k ≥2 (the case
k = 1 is given by Schaefer’s Theorem) the following holds:
Theorem 3.4. If Γ is Schaefer then Qcspk(Γ) is polynomial-time decidable,
in all other cases, Qcspk(Γ) is ΣkP-complete.
Theorems 3.1, 3.3, and 3.4 were originally proven in a diﬀerent much more
involved way in [Sch78, Hem04]. The above simple proofs using Galois theory
appeared later. The proof of Theorem 3.1 is implicit in [JCG97, Dal00]. The
proofs of Theorems 3.3 and 3.4 are from [BBC+07]. Yet a diﬀerent proof is given
in [Che06].
4
When Does Post’s Lattice Help?
Many further results, classifying the computational complexity of diﬀerent algo-
rithmic tasks for Boolean CSPs have been obtained in the past decades. Some of
these rely on the algebraic approach explained above, for others this approach
does not seem to be useful. To make this a little bit more precise, let Π(Γ) be
any computational problem deﬁned for Γ-formulas or quantiﬁed Γ-formulas. If
a result as
If Γ ⊆⟨Γ ′⟩then Π(Γ) ≤log
m Π(Γ ′)
(1)
can be proven and then be used to obtain a complexity classiﬁcation of Π, then
we will say that the Galois connection holds a priori for Π. For the problems
studied in the previous section, the Galois connection holds a priori.
For many problems that we will address below, a classiﬁcation cannot be
obtained with the help of a result as (1). Instead, the classiﬁcation was obtained
in sometimes very involved and technically complicated ways making use of
diﬀerent types of implementing one constraint relation by another. However,
once the full classiﬁcation is obtained, it sometimes happens incidentally that
it obeys the borders among co-clones, that is, (1) holds but it can only be read
from the obtained classiﬁcation and not be used to obtain the classiﬁcation. In
such a case, we will say that the Galois connection holds a posteriori for the
problem Π under consideration.
Also, there are some problems where the Galois connection simply does not
hold, i.e., an implication as (1) is not true and the known complexity classiﬁca-
tion does not follow Post’s lattice; there might, e.g., exist constraint languages
with diﬀerent complexities that nevertheless give rise to the same co-clone.
The distinction between a priori and a posteriori should of course not be taken
as a mathematical deﬁnition—after all, in both cases (1) holds. The distinction
should better be regarded as a historical notion.

14
N. Creignou and H. Vollmer
In Sect. 6 we will survey complexity classiﬁcations obtained for many compu-
tational problems in the past decades. For each of them, we will pay particular
attention to the question if Post’s lattice could be used. Before we do so, however,
we would like to address an important point concerning the type of reduction
that is obtained from the Galois connection.
5
Reducibilities
Schaefer’s Dichotomy theorem states that Csp(Γ) is either NP-complete or
polynomial-time decidable. This means that under polynomial-time many-one
reductions, there are only two possible degrees of complexity for this decision
problem.
However, the statement of the Galois connection, Proposition 2.2, speaks of
logspace many-one reductions. Hence, together with Post’s lattice this can be
used to determine all degrees of Csp(Γ) with respect to logspace m-reductions.
First results in this direction appear already in Schaefer’s paper [Sch78, Theo-
rem 5.1] and in [CKS01, Theorem 6.5]. A thorough examination has been un-
dertaken by Allender, Bauland, Immerman, Schnoor and Vollmer [ABI+05], and
it was shown there that the complexity of Csp(Γ) falls into one of ﬁve logspace
m-degrees: NP-complete, P-complete, NL-complete, ⊕L-complete, or decidable
in logspace. Here, a logspace m-degree is a class of the form [A]≡log
m
= { B |
B ≡log
m A } for some language A, where B ≡log
m A denotes that A ≤log
m B and
B ≤log
m A. The name stems from the fact that we are talking about logspace
m-reductions ≤log
m .
In fact, Allender et al. even make a further step by looking at still stricter
reductions, namely the so-called AC0 many-one-reductions ≤AC0
m
. The class AC0
consists of all languages/functions computable by uniform families of Boolean
circuits of polynomial size and constant depth; for an exact deﬁnition and a
thorough discussion of the type of uniformity involved we refer the reader to
[Vol99]. Now ≤AC0
m
reductions are just many-one reductions where the reduction
function is computable by AC0 circuits. These reductions are also known as FO-
reductions, since the reduction function can be deﬁned by ﬁrst-order formulas,
see [Imm99].
Example 5.1. Let Γ1 = {x, x}. An easy calculation, using Post’s lattice, shows
that Pol(Γ1) = R2, the class of all Boolean functions f that are at the same time
0-reproducing and 1-reproducing, i.e., f(0, . . . , 0) = 0 and f(1, . . . , 1) = 1. Now,
deﬁne Γ2 = Γ1 ∪{=}, then obviously Pol(Γ1) = Pol(Γ2).
Formulas over Γ1 only contain clauses of the form x or x for some variables
x, such a formula is unsatisﬁable if and only if for some variable x, both x and
x are clauses. This is easily decidable by AC0 circuits, and Csp(Γ1) ∈AC0.
In Γ2 we additionally have the binary equality predicate, and we will now
show that Csp(Γ2) is complete for L under ≤AC0
m
reductions: The complement
of the graph accessibility problem (GAP) for undirected graphs, which is known
to be complete for L [Rei05], can be reduced to Csp(Γ2) as follows: Given a

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
15
ﬁnite, undirected graph G = (V, E) and vertices s, t in V , we build, for every
edge (v1, v2) ∈E, a constraint v1 = v2. Also we build the two clauses s and t.
Finally, let φG be the conjunction of all these constraints. It is easy to see that
there exists a path in G from s to t if and only if φG is not satisﬁable. Since,
moreover, Csp(Γ2) ∈L, we conclude that Csp(Γ2) is complete for L under ≤AC0
m
reductions.
This example shows that the Galois connection Proposition 2.2 does not hold
for ≤AC0
m
-recutions, since we constructed two constraint languages with the same
expressive power but provably diﬀerent complexity (note that AC0 ̸= L). In other
words, Γ2 ⊆⟨Γ1⟩yet Csp(Γ2)̸≤AC0
m
Csp(Γ1). All we can state is the following
proposition:
Proposition 5.2. If Γ ⊆⟨Γ ′⟩then Csp(Γ)≤AC0
m
Csp(Γ ′ ∪{=}) ≤log
m Csp(Γ ′).
Proof. The proof follows the one for Proposition 2.2: The ﬁrst reduction Csp(Γ)
≤AC0
m
Csp(Γ ′ ∪{=}) just consists of the local replacement of relations from Γ
by their deﬁning primitive positive deﬁnitions using relations in Γ ′ ∪{=} and
removing the existential quantiﬁers; this can be computed in AC0. For the second
reduction Csp(Γ ′ ∪{=}) ≤log
m Csp(Γ ′) we delete all equality clauses and identify
variables forced to be equal, and, as argued before, this can be computed in
logspace.
□
Some constraint languages, however, can express equality in the following sense:
Recall from Deﬁnition 2.1 that R ∈⟨Γ⟩if and only if R can be deﬁned by
a primitive positive deﬁnition using relations in Γ ∪{=}. Now we explicitly do
not allow equality constraints to deﬁne new relations. More precisely, we say
that a constraint language Γ can express a relation R, if R can be deﬁned with
a primitive positive deﬁnition using only relations in Γ. Obviously, if Γ can
express equality then Csp(Γ ∪{=})≤AC0
m
Csp(Γ), using local replacement of all
equality constraints by deﬁning Γ-formulas.
Proposition 5.3. If Γ ⊆⟨Γ ′⟩and Γ ′ can express equality then
Csp(Γ)≤AC0
m
Csp(Γ ′).
Allender et al. [ABI+05] present a simple algorithm to determine if a constraint
language can express equality.
With these tools at hand, Allender et al. obtained the following classiﬁcation:
Theorem 5.4.
– If ⟨Γ⟩⊇Inv(N2) then Csp(Γ) is ≤AC0
m
-complete for NP.
– If ⟨Γ⟩= Inv(V2) or ⟨Γ⟩= Inv(E2) then Csp(Γ) is ≤AC0
m
-complete for P.
– If Inv(L3) ⊆⟨Γ⟩⊆Inv(L2) then Csp(Γ) is ≤AC0
m
-complete for ⊕L.
– If Inv(S2
00) ⊆⟨Γ⟩⊆Inv(S00) or Inv(S2
10) ⊆⟨Γ⟩⊆Inv(S10) or ⟨Γ⟩= Inv(D2)
or ⟨Γ⟩= Inv(M2) then Csp(Γ) is ≤AC0
m
-complete for NL.
– If Inv(D) ⊆⟨Γ⟩⊆Inv(D1) then Csp(Γ) is ≤AC0
m
-complete for L.
– If Inv(R2) ⊆⟨Γ⟩⊆Inv(S02) or Inv(R2) ⊆⟨Γ⟩⊆Inv(S12) then either
Csp(Γ) is in AC0, or Csp(Γ) is complete for L under ≤AC0
m
. There is an
algorithm deciding which case occurs.

16
N. Creignou and H. Vollmer
– If Γ ⊆Inv(I0) or Γ ⊆Inv(I1) then every constraint formula over Γ is
satisﬁable, and therefore Csp(Γ) is trivial.
Hence we see that the problem Csp(Γ) can assume only one of six diﬀerent AC0
m-degrees (assuming all relevant classes are diﬀerent). Using Agrawal’s First-
Order Isomorphism Theorem [Agr01] an even stronger statement can be made:
For any set of relations Γ, Csp(Γ) is AC0-isomorphic either to 0Σ∗or to the
standard complete set for one of the following complexity classes: NP, P, ⊕L,
NL, L. In a sense there is not an inﬁnite family of CSP-problems but in fact
there are only 6 diﬀerent such problems.
The question which type of reduction one obtains from the Galois connec-
tion will come up again in a diﬀerent context in the next section. For counting
problems for quantiﬁed constraints, the Galois connection yields parsimonious re-
ductions (Proposition 6.11). Parsiminious reductions (to be deﬁned in Sect. 6.3),
however, are often too strict—not many completeness results for counting prob-
lems under parsimonious reductions are known—and one has to look for suitable
coarser reductions.
6
Complexity Classiﬁcations
This section is intended to give a survey of complexity classiﬁcations obtained
up to now in the framework of Boolean CSPs. Such results are so numerous
that it would be too ambitious to make an exhaustive list of them. However
we will review a large selection of results, organized according to the kind of
computational task they address. In each case we will try to highlight the features
of the problems for which the Galois holds a priori or at least can help. As we
have seen in Theorem 3.1 and in the discussion that followed, a classiﬁcation
that matches Post’s lattice can be stated in diﬀerent ways, in any case it is easy
to go from one statement to the other in using Fig. 1 and Fig. 3.
6.1
Nonmonotonic Reasoning
Circumscription is an important and well-studied formalism in the realm of
nonmonotonic reasoning. The model checking and inference problem for propo-
sitional circumscription have been studied from the viewpoint of computational
complexity.
Given a formula φ, let Var(φ) denote its set of variables. If |Var(φ)| = n,
then any assignment of truth values to the variables of φ can be seen as a
word in {0, 1}n. Circumscription is deﬁned in using a partial order ≤(P,Q) on
{0, 1}n, where P, Q are two disjoint subsets of {1, . . . , n}. Let β = (b1, . . . , bn)
and α = (a1, . . . , an) be two truth assignments. We write β ≤(P,Q) α to denote
that bi ≤ai for all i ∈P and bj = aj for all j ∈Q. Let β <(P,Q) α denote
that β ≤(P,Q) α and there exists i ∈P such that bi ̸= ai. Given a formula φ, we
say that α is a minimal model of φ with respect to the partial order ≤(P,Q) if α
satisﬁes φ and and there is no β satisfying φ such that β <(P,Q) α.

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
17
The model checking for propositional circumscription is deﬁned as follows,
Problem:
Min-Csp(Γ)
Input:
a Γ-formula φ, two disjoint subsets P, Q of Var(φ) and a
truth assignment I to Var(φ)
Question:
Is I a model of φ minimal with respect to the partial order
≤(P,Q)?
while the inference problem is
Problem:
Min-Inf-Csp(Γ)
Input:
a Γ-formula φ, two disjoint subsets P, Q of Var(φ) and a
clause c
Question:
Is c satisﬁed in every model of φ which is minimal with
respect to the partial order ≤(P,Q)?
It was proved in [NJ04] that the Galois connection holds a priori for Min-Csp
and Min-Inf-Csp.
Proposition 6.1. If Γ ⊆⟨Γ ′⟩, then
– Min-Csp(Γ) ≤log
m Min-Csp(Γ ′), and
– Min-Inf-Csp(Γ) ≤log
m Min-Inf-Csp(Γ ′).
Proof. The proof is very similar to the one for Proposition 2.2: given an input
(φ, P, Q, I) of Min-Csp(Γ), we construct an input (φ′, P ′, Q′, I′) of Min-Csp(Γ).
The formula φ′ is obtained by ﬁrst replacing every constraint from Γ by its
deﬁning existentially quantiﬁed

Γ ′ ∪{=}

-formula, and second deleting the
existential quantiﬁers. The newly introduced quantiﬁed variables are in Var(φ′).
At this step the sets P ′ and Q′ are unchanged, i.e., P ′ = P and Q′ = Q. It
remains to delete equality clauses and replace all variables that are connected
via a chain of equality constraints by a common new variable. If one of the
variables in the chain is a variable from Q, then the new variable is added to
Q′, otherwise if one of the variables in the chain is a variable from P, then the
new variable is added to P ′. Finally we remove from P ′ and Q′ the variables
that do not occur anymore in φ′. It is then easy to check that I is a model of φ
minimal with respect to the partial order ≤(P,Q) if and only if I′ is a model of
φ′ minimal with respect to the partial order ≤(P ′,Q′). A similar proof applies to
the problem Min-Inf-Csp.
□
Using this algebraic connection Nordh and Jonsson [NJ04] proved the following
dichotomy theorem.
Theorem 6.2. [Model checking for propositional circumscription ]
– If Γ is Schaefer then Min-Csp(Γ) is polynomial-time decidable.
– In all other cases, Min-Csp(Γ) is coNP-complete.
For the inference problem Nordh [Nor05] obtained a trichotomy classiﬁcation.

18
N. Creignou and H. Vollmer
Theorem 6.3. [Inference for propositional circumscription ]
– If ⟨Γ⟩⊇Inv(N) then Min-Inf-Csp(Γ) is Π2P-complete.
– Otherwise if ⟨Γ⟩⊇Inv(S2
11) or ⟨Γ⟩⊇Inv(S2
0) or ⟨Γ⟩⊇Inv(E) or ⟨Γ⟩⊇
Inv(V) or ⟨Γ⟩⊇Inv(L), then Min-Inf-Csp(Γ) is coNP-complete.
– In all other cases, Min-Inf-Csp(Γ) is polynomial-time decidable.
Kirousis and Kolaitis studied basic circumscription, where Q = ∅and P =
Var(φ), which means that the partial order taken into account is the usual
coordinate-wise order. Actually this special case is much harder to study. In-
deed, there is no way to restrict P and Q in order to hide the newly introduced
existential variables as in the proof of Theorem 6.1. Thus the Galois connec-
tion cannot be applied a priori and the results are obtained in a much more
involved way. For the Min-Csp problem in which Q = ∅and P = Var(φ) (de-
noted by Min-Sat in the original paper [KK03]) Kirousis and Kolaitis obtained
a dichotomy classiﬁcation, P/coNP-complete, from which Theorem 6.2 can be
derived. As for the inference problems (denoted by Inf-Circ in [KK04]) they
obtained only a dichotomy classiﬁcation (in coNP/Π2P-complete), the possible
trichotomy remains an open problem. It is worth noticing that these classiﬁ-
cations follow Post’s lattice, thus showing that for these problems the Galois
connection holds a posteriori.
Abduction is another fundamental nonmonotonic process, which consists in
searching for an explanation of a given observed manifestation with respect to
some background knowledge. We deﬁne below the abduction problem we are in-
terested in, the query to be explained consists of a single positive literal (whence
PQ below for positive query). Given a set of variables A, Lit(A) denotes the set
of literals x and ¬x one can build upon the variables x from A.
Problem:
PQ-Abduction(Γ)
Input:
a Γ-formula φ, a set of variables A ⊆Var(φ) and a variable
q ∈Var(φ) \ A.
Question:
Is there a set E ⊂Lit(A) such that φ ∧
 E is satisﬁable
but φ ∧
 E ∧(¬q) is not? (If one exists such a set E is
called a solution of the abduction problem, or sometimes
an “explanation” of q.)
The Galois connection helps to study the complexity of PQ-Abduction.
Proposition 6.4. If Γ ⊆⟨Γ ′⟩then
PQ-Abduction(Γ) ≤log
m PQ-Abduction(Γ ′).
Proof. Given (φ, A, q) an instance of PQ-Abduction(Γ), we procede as in the
proof of Proposition 2.2 and construct φ′ by replacing every constraint from Γ
by its deﬁning existentially quantiﬁed

Γ ′ ∪{=}

-formula, and then by deleting
the equality clauses. Then, it can be shown that (φ, A, q) and (φ′, A, q) have the
same solutions for the PQ-Abduction problem (see [CZ06, Corollary 18]).
□

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
19
From this proposition one can obtain the following classiﬁcation.
Theorem 6.5. [Abduction]
– If ⟨Γ⟩⊇Inv(N) then PQ-Abduction(Γ) is Σ2P-complete.
– Otherwise if ⟨Γ⟩⊇Inv(V) or ⟨Γ⟩⊇Inv(E0), then PQ-Abduction(Γ) is
NP-complete.
– In all other cases, PQ-Abduction(Γ) is polynomial-time decidable.
This classiﬁcation was originally obtained in [CZ06] without making use of the
Galois connection. Maybe here, it is interesting to state the classiﬁcation in
classical more familiar terms: Polynomial-time decidability holds for constraint
languages that are aﬃne, bijunctive, deﬁnite Horn, IHSB−or IHSB+; the NP-
case arises for constraint languages that are none of the above but Horn or
dual-Horn; and the remaining hard case is the case of constraint languages that
can express all relations that are simultaneously complementive, 0-valid, and
1-valid.
Nordh and Zanuttini studied such an abduction problem in the case where
hypotheses as well as manifestations are sets of literals. In using the Galois
connection they also obtained a trichotomy classiﬁcation (see [NZ05]).
As a third example for nonmonotonic reasoning, we would like to mention
that Ilka Schnoor [Sch07b] (building on previous work in [CHS07]) classiﬁed the
complexity of some problems for default logic where the formulas are Γ-formulas
for some constraint language Γ.
6.2
Equivalence, Implication and Isomorphism
Two formulas φ1 and φ2 are equivalent if every truth assignment to the variables
of φ1 and φ2 satisﬁes φ1 if and only if it satisﬁes φ2. As usual we write this as
φ1 ≡φ2. Thus we can deﬁne the following equivalence problem.
Problem:
Equiv(Γ)
Input:
two Γ-formulas φ1 and φ2
Question:
Does φ1 ≡φ2 hold?
This problem also makes sense in the context of quantiﬁed formulas. Given two
quantiﬁed formulas φ1 and φ2, we say that φ1 is equivalent to φ2, and we still
write φ1 ≡φ2, if every truth assignment to the free variables of φ1 and φ2 is a
solution for φ1 (i.e., makes φ1 true) if and only if it is a solution for φ2. Thus we
can deﬁne the equivalence problem for Qcspk(Γ) formulas.
Problem:
Qequivk(Γ)
Input:
two Qcspk(Γ)-formulas φ1 and φ2
Question:
Does φ1 ≡φ2 hold?
The algebraic framework will still be of use for this problem. However we have
to be careful with the equality constraints resulting from the application of the
Galois connection. Indeed, the removal of the equality constraints by identify-
ing variables may not preserve the equivalence of the formulas. However, if our

20
N. Creignou and H. Vollmer
constraint language can express equality (in the sense of the deﬁnition given in
Sect. 5), then this problem does not arise.
Proposition 6.6. If Γ ⊆⟨Γ ′⟩and Γ ′ can express equality, then
Qequivk(Γ) ≤log
m Qequivk(Γ ′).
Proof. Given a formula φ we construct a formula φ′ by replacing every constraint
from Γ by its deﬁning existentially quantiﬁed

Γ ′ ∪{=}

-formula. Any occur-
ring equality constraint can be removed in using the Γ ′-implementation of the
equality relation, which exists due to the prerequisites. All the newly introduced
variables will be quantiﬁed in the ﬁnal (existential) quantiﬁer block. So, we ob-
tain a formula φ′ which is equivalent to φ. Thus, applying this transformation
to the pair of formulas given as instance for the problem Qequiv(Γ) provides a
proof of the above claim.
□
With this tool the following classiﬁcation was obtained in [BBC+07, Sch07a].
Theorem 6.7. [Equivalence for quantiﬁed formulas]
– If ⟨Γ⟩⊇Inv(N) then Qequivk(Γ) is Πk+1P-complete.
– Otherwise if ⟨Γ⟩⊇Inv(V) or ⟨Γ⟩⊇Inv(E), then Qequivk(Γ) is coNP-
complete.
– In all other cases, Qequivk(Γ) is polynomial-time decidable.
Here again it is interesting to state the classiﬁcation in classical terms:
Polynomial-time decidability holds for constraint languages that are aﬃne, bi-
junctive, IHSB−or IHSB+; the coNP-case arises for constraint languages that
are none of the above but Horn or dual-Horn; and the remaining hard case is
the case of constraint languages can express all relations that are simultaneously
complementive, 0-valid, and 1-valid.
When considering unquantiﬁed formulas there is no way to hide the new exis-
tential variables resulting from the application of the Galois connection. There-
fore the Galois connection does not hold a priori to study the complexity of
the equivalence problem Equiv(Γ). However, as proved by B¨ohler, Hemaspaan-
dra, Reith and Vollmer in [BHRV02], it holds a posteriori since the complexity
classiﬁcation for this problem follows the structure of Post’s lattice.
Theorem 6.8. [Equivalence of formulas]
– If Γ is Schaefer then Equiv(Γ) is polynomial-time decidable.
– In all other cases, Equiv(Γ) is coNP-complete.
Besides equivalence another problem of interest is the one of isomorphism. We
say that two formulas φ1 and φ2 over a set of variables X are isomorphic, and
we write φ1 ∼= φ2, if there exists a permutation π of X such that π(φ1) ≡φ2.
Thus one can deﬁne the following isomorphism problem.
Problem:
Iso(Γ)
Input:
two Γ-formulas φ1 and φ2
Question:
Does φ1 ∼= φ2 hold?

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
21
The complexity of this problem is related to the one of the Graph Isomorphism
problem (GI for short). The exact complexity of GI is not known. It is only
known that it is in NP; it is not known to be in P and it is unlikely to be
NP-complete, cf. [KST93]. The following classiﬁcation result was obtained by
B¨ohler, Hemaspaandra, Reith and Vollmer in [BHRV04].
Theorem 6.9. [Isomorphism]
– If Γ is aﬃne with width 2 then Iso(Γ) is polynomial-time decidable.
– Otherwise, if Γ is Schaefer, then Iso(Γ) is polynomial-time many-one equiv-
alent to GI.
– In all other cases, Iso(Γ) is coNP-hard and GI-hard.
Whereas the Galois connection does not apply a priori for this problem, the
complexity classiﬁcation follows the structure of Post’s lattice since it can be re-
formulated in the following way. This follows from the observation that a relation
R is 2-aﬃne if and only if it is aﬃne and bijunctive, i.e., Pol(R) ⊇D1.
Theorem 6.10. [Isomorphism classiﬁcation with co-clones]
– If ⟨Γ⟩⊇Inv(N) then Iso(Γ) is coNP-hard and GI-hard.
– Otherwise if ⟨Γ⟩⊇Inv(S2
0) or ⟨Γ⟩⊇Inv(S2
1) or ⟨Γ⟩⊇Inv(M) or ⟨Γ⟩⊇
Inv(L), then Iso(Γ) is polynomial-time many-one equivalent to GI.
– In all other cases, Iso(Γ) is polynomial-time decidable.
Additional results were obtained by Bauland and Hemaspaandra [BH05] for the
implication and isomorphic implication problems. These problems are deﬁned in
a similar way as the ones above in weakening the equivalence requirement to
an implication. For these problems again, while the Galois connection does not
apply a priori, the complexity classiﬁcations they obtain follow Post’s lattice.
6.3
Counting and Enumeration
The problems considered up to now have been decision problems. We now turn to
counting problems where typically we do not ask whether a formula has a satis-
fying assignment but want to determine the number of satisfying assignments of
a formula. Let us recall the deﬁnition of some complexity classes and reducibil-
ity notions relevant for such computational problems (see [Val79a], [Val79b],
[Tod91a], [Tod91b], [Vol94] and [HV95]; a somewhat more detailed exposition of
the material below can be found in [BBC+07]). Let Σ and ∆be alphabets and
let R ⊆Σ∗×∆∗be a binary relation between strings such that, for each x ∈Σ∗,
the set R(x) = {y ∈∆∗| R(x, y)} is ﬁnite. We write #R to denote the following
counting problem: Given a string x ∈Σ∗, ﬁnd the cardinality |R(x)|, of the set
R(x) associated with x. The members of this set R(x) are called witnesses for
x and the relation R is called the witness relation of the counting problem. If C
is a complexity class of decision problems, then #·C is the class of all counting
problems whose witness relation R satisﬁes the following conditions:

22
N. Creignou and H. Vollmer
1. There is a polynomial p(n) such that for every x and every y with R(x, y)
we have |y| ≤p(|x|).
2. The witness recognition problem “given x and y, does R(x, y) hold?” is in C.
The following inclusion chain is well-known [Tod91a, Vol94]: #·ΣkP ⊆#·ΠkP =
#PΣkP ⊆#·Σk+1P for each k.
Several notions of reducibilities among counting problems have been deﬁned.
We say that #A reduces to #B by a Turing reduction (see [Val79b]) if #A
can be computed in polynomial-time by an oracle Turing machine with ora-
cle #B. Zank´o [Zan91] introduced counting reductions (essentially truth-table-
reduction with one oracle query) i.e., #A reduces to #B by a counting re-
duction if there exist polynomial-time computable functions f and g such that
#A(x) = f(#B(g(x))). The strongest notion of reduction is the one of parsimo-
nious reduction, which exactly preserves the number of solutions and thus which
is a special case of counting reduction where the function f is simply the identity.
Unlike parsimonious reductions, counting reductions do not have the property
that the classes of the hierarchy #·ΣkP are closed under these reductions, unless
this hierarchy collapses (see [TW92]).
This is the reason why researchers have looked for a reduction stricter than
Turing reductions but not as strict as parsimonious ones. Building on a previous
notion of subtractive reductions introduced in [DHK05], so called complementive
reductions were introduced in [BCC+05]. For this, let Σ1, Σ2, ∆1, ∆2 be alpha-
bets and let #A and #B be two counting problems determined by the binary
relations A ⊆Σ∗
1 × ∆∗
1 and B ⊆Σ∗
2 × ∆∗
2.
We say that #A reduces to #B via a strong complementive reduction, if:
– for every string x ∈Σ∗
2, B(x) is complementive, i.e., there is a permutation π
on ∆2 such that for all words x, y we have that y ∈B(x) ⇐⇒π(y) ∈B(x),
– there exist polynomial-time computable functions f, g: Σ∗
1 →Σ∗
2 such that
for every string x ∈Σ∗
1:
• B(g(x)) ⊆B(f(x)),
• 2 · |A(x)| = |B(f(x))| −|B(g(x))|.
A complementive reduction #A ≤p
compl #B is a sequence of strong complemen-
tive reductions. It is known that the classes #·ΠkP are closed under comple-
mentive reductions, and the closure of #·ΣkP under these reductions is #·ΠkP
[BCC+05].
Let us now examine the counting problems associated with quantiﬁed formu-
las. Given a formula with free variables φ(Y ) = Q1X1 . . . ∃Xkψ(Y, X1, . . . , Xk)
where ψ is quantiﬁer free and the X1, . . . , Xk, Y are vectors of variables, we
are interested in the number of assignments for Y such that φ(Y ) holds. We
denote this number by #sat(φ) (and by #unsat(φ) we denote the number of
assignments for Y such that φ(Y ) does not hold). The following problems are
the counting versions of the decision problems studied in Sect. 3.

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
23
Problem:
#Qcspk(Γ)
Input:
a Qcspk(Γ)-formula φ with free variables
Output:
If k is odd: #sat(φ)
If k is even: #unsat(φ)
It is tempting to conclude that (by a proof essentially identical to the one
of Proposition 3.2) the Galois connection holds for these counting problems,
i.e., if Γ ⊆⟨Γ ′⟩then there is a parsimonious reduction from #Qcspk(Γ) to
#Qcspk(Γ ′). An easy counterexample shows, however, that this is not the case:
Take Γ = {x} and Γ ′ = {x, =}. These two constraint sets certainly have the same
polymorphisms and obviously, every Γ-formula will have exactly one solution,
since every appearing variable must be set to true, but with Γ ′, we can build
formulas with exactly 2k solutions using the formula (x1 = x1)∧· · ·∧(xk = xk).
However, it turns out that the only problematic case is that of constraint sets
Γ consisting only of relations with exactly one tuple. Hence one obtains (see
[BBC+07]):
Proposition 6.11. If Γ ⊆⟨Γ ′⟩and not every relation in Γ is equivalent to a
conjunction of literals, then there is a parsimonious reduction from #Qcspk(Γ)
to #Qcspk(Γ ′).
Using this algebraic result Bauland, B¨ohler, Creignou, Reith, Schnoor, and Voll-
mer [BBC+07], building on previous results from [BCC+05] for the case k = 1,
obtained the following classiﬁcation.
Theorem 6.12. [Counting for quantiﬁed formulas]
– If ⟨Γ⟩⊇Inv(N) then #Qcspk(Γ) is #·ΣkP-complete under complementive
reductions.
– Otherwise, if ⟨Γ⟩⊇Inv(M) or ⟨Γ⟩⊇Inv(S2
0) or ⟨Γ⟩⊇Inv(S2
1) then
#Qcspk(Γ) is #·P-complete under Turing reductions.
– In all other cases #Qcspk(Γ) can be solved in polynomial time.
The use of diﬀerent reducibility notions in the statements of the previous theorem
may be confusing, let us mention, however, that (under reasonable complexity-
theoretic assumptions) the theorem places the counting problem for quantiﬁed
Γ-formulas optimally in the ΣkP-classes, since the following holds [BBC+07]:
Corollary 6.13.
1. If ⟨Γ⟩⊇Inv(N) then for any k, #Qcspk(Γ) ∈#·ΣkP
but #Qcspk(Γ) ̸∈#·Σk−1P unless #·ΣkP = #Πk−1P (implying that ΣkP-
computations can be made “unambiguous”), and #Qcspk(Γ) is not polyno-
mial-time solvable unless P = NP.
2. Otherwise, if ⟨Γ⟩⊇Inv(M) or ⟨Γ⟩⊇Inv(S2
0) or ⟨Γ⟩⊇Inv(S2
1) then for
any k, #Qcspk(Γ) ∈#·P but #Qcspk(Γ) is not polynomial-time solvable
unless P = NP.
Let us now examine the counting problem for unquantiﬁed formulas.
Problem:
#Csp(Γ)

24
N. Creignou and H. Vollmer
Input:
a Γ-formula φ
Output:
number of satisfying assignments of φ
When dealing with unquantiﬁed formulas the problem is more complicated since
one cannot take advantage of the existentially quantiﬁed variables in order to
hide the new variables resulting from the application of the Galois connection.
However, in [BD03] Bulatov and Dalmau obtained in a more involved way the
following result, which shows that the Galois connection applies for counting
problems under Turing reductions.
Proposition 6.14. If Γ ⊆⟨Γ ′⟩then there is a Turing reduction from #Csp(Γ)
to #Csp(Γ ′).
Proof. Given a Γ-formula φ, one constructs a formula φ′ by replacing every
constraint from Γ by its deﬁning existentially quantiﬁed

Γ ′∪{=}

-formula, and
then omitting the existential quantiﬁers. The diﬃculty is that if an individual
constraint from Γ can be implemented by:
Ri(x1, . . . , xri) = ∃y1 . . . ∃yqiφ′
i(x1, . . . , xri, y1, . . . , yqi),
where φ′
i is a Γ ′-formula, then for each tuple aj = (a1, . . . , ari) ∈Ri there are
several tuples (b1, . . . , bqi) such that φ′
i(a1, . . . , ari, b1, . . . , bqi) holds (we denote
by uj the number of such extensions of aj). Therefore, the number of satisfying
assignments of φ cannot be directly computed from the number of satisfying
assignments of φ′. The trick is not to compute the formula φ′ but p such formulas
φ′(l) for l = 1, . . . , p, for a well chosen polynomial p in the input size, such that for
each l, φ′(l) is an expanded copy of φ′, in which each Γ ′-constraint is replicated l
times. Let Nl denote the number of solutions of φ′(l). It turns out that the number
of solutions of the original formula φ can be expressed as the sum of p terms,
which verify a linear system whose coeﬃcients involve the uj’s and the Nl’s
deﬁned above. This linear system has the good property of being Vandermonde,
and therefore inversible. Thus these terms, and hence the number of solutions of
φ can be computed in polynomial time from the Nl’s (and the uj’s). Therefore,
there is a Turing reduction from #Csp(Γ) to #Csp(Γ ′) with p queries to the
oracle.
□
Remark 6.15. For most of the above computational problems where the Galois
connection helps a priori, the deﬁnition of the problem somehow allows to “hide”
the new existentially quantiﬁed variables that are introduced by the application
of the Galois connection. For the above proposition, however, it is the power of
the reduction that helps to remove these variables.
In [CH96] Creignou and Hermann proved the following classiﬁcation.
Theorem 6.16. [Counting]
– If Γ is aﬃne then #Csp(Γ) can be solved in polynomial-time.
– Otherwise, #Csp(Γ) is #·P-complete under Turing reductions.

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
25
Related to the counting problem is the unique satisﬁability problem. Thus,
Unique-Sat(Γ) is the problem of deciding whether a given Γ-formula has a
unique model. This problem is in the complexity class DP, the class of lan-
guages equal to an intersection of two languages, one from NP and the other
from coNP. Unless the polynomial hierarchy collapses, DP is a strict superclass
of NP and coNP. In fact, following [BG82], let us deﬁne the class US as the
closure of Unique-Sat (i.e., without restrictions on the clauses) under usual
polynomial-time many-one reductions. Then US is a (supposedly proper) sub-
class of DP, showing that while Unique-Sat ∈DP it is most likely not complete
in this class.
In order to reduce a problem Unique-Sat(Γ) to another one we need a par-
simonious reduction that exactly preserves the number of solutions. Whereas as
noticed above the Galois connection cannot help a priori for such a reduction, it
holds a posteriori: a classiﬁcation following Post’s lattice was obtained by Juban
[Jub99].
Theorem 6.17. [Unique satisﬁability]
– If Γ is Schaefer or Γ is both 0-valid and 1-valid or Γ is complementive, then
Unique-Sat(Γ) is polynomial-time decidable.
– Otherwise, Unique-Sat(Γ) is coNP-hard.
This classiﬁcation theorem can indeed be reformulated as follows.
Theorem 6.18. [Unique satisﬁability classiﬁcation with co-clones]
– If ⟨Γ⟩⊇Inv(I0) or ⟨Γ⟩⊇Inv(I1), then Unique-Sat(Γ) is coNP-hard.
– Otherwise Unique-Sat(Γ) is polynomial-time decidable.
Looking at the proof given by Juban it is easy to see that in the cases where
Unique-Sat(Γ) is coNP-hard, it is in fact complete for the class US.
Besides counting another computational goal of interest is to enumerate all the
solutions. Polynomial-delay algorithms (see [JPY88]) are eﬃcient enumerating
algorithms that generate all the solutions, one after the other (i.e., without repe-
titions), in such a way that the delay until the ﬁrst is output, and thereafter, the
delay between any two consecutive solutions (and between the last solution and
the halting) is bounded by a polynomial in the input size. Creignou and H´ebrard
[CH97] obtained a complexity classiﬁcation for the enumeration problem asso-
ciated with Γ-formulas which shows that in the Boolean case the property of
having an eﬃcient enumeration algorithm only depends on the polymorphisms
of the set of relations Γ.
Theorem 6.19. [Enumeration]
– If Γ is Schaefer, then there is a polynomial-delay algorithm that generates
all satisfying assignments of a Γ-formula.
– Otherwise such an algorithm does not exist unless P = NP.
The fact that the Galois connection holds a posteriori for the enumeration prob-
lem in the Boolean case is rather unexpected. Indeed in [SS07] Henning and Ilka

26
N. Creignou and H. Vollmer
Schnoor showed that the Galois connection does not work for the enumeration
problems associated with CSPs over (non Boolean) ﬁnite domains; namely they
showed that there exist relations R and R′ (over a non Boolean domain) that
give rise to the same co-colone, i.e., ⟨R⟩= ⟨R′⟩, and such that Csp(R) has an
eﬃcient enumerating algorithm whereas Csp(R′) has none unless P = NP.
6.4
Optimisation Problems
In contrast to the decision and counting worlds, where there is essentially a
unique way to obtain constraint satisfaction versions of the corresponding class,
the case of optimization is somewhat more general.
The study of optimization problems in computational complexity started with
the work of Krentel [Kre88, Kre92]; he deﬁned the class OptP as follows. We say
that a function h is in MinP if there are a function f in FP (i.e., is computable
in polynomial-time) and a polynomial p such that h(x) = min|y|=p(|x|) f(x, y),
where minimization is taken with respect to the lexicographical order. The class
MaxP is deﬁned by taking the maximum of these values. Finally OptP = MinP∪
MaxP. Krentel considered the following reducibility in connection with these
classes. A function f is metric reducible to a function h, f ≤p
met h, if there exist
two functions g1, g2 ∈FP such that for all x, f(x) = g1(h(g2(x)), x). The class
OptP is a subclass of FPNP and it is well known that the closure of all three
classes MinP, MaxP and OptP under metric reductions coincide with the class
FPNP, which means that showing completeness for a problem in MinP generally
implies hardness for the same problem for MaxP and completeness for OptP. In
the context of Boolean constraint satisfaction the typical problem for OptP is
deﬁned as follows.
Problem:
Lex-Min-Sat(Γ)
Input:
a Γ-formula φ
Output:
the lexicographically smallest satisfying assignment of φ
The algebraic framework will still be of use for this problem. However once again
we have to be careful with the equality constraints resulting from the application
of the Galois connection. Indeed, the removal of the equality constraints by iden-
tifying variables may make some variables disappear. However, if our constraint
language can implement the equality relation, then this problem does not arise.
Proposition 6.20. If Γ ⊆⟨Γ ′⟩and Γ ′ can express equality, then
Lex-Min-Sat(Γ) ≤p
met Lex-Min-Sat(Γ ′).
Proof. Let φ be a Γ-formula with Var(φ) = {x1, . . . , xn} ordered by their index,
i.e., x1 < · · · < xn. We construct a formula by replacing in φ every constraint
from Γ by its deﬁning existentially quantiﬁed

Γ ′ ∪{=}

-formula. Any occur-
ring equality constraint can be removed in using the Γ ′-implementation of the
equality relation, which exists due to the prerequisites. Finally we delete all the
existential quantiﬁers. The Γ ′-formula φ′ so obtained is over a set of variables
{x1, . . . , xn} ∪{y1, . . . , ym}. This process corresponds to the function g2 in the

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
27
deﬁnition of metric reductions. The variables are ordered by their index and
their alphabet, i.e., x1 < x2 < . . . xn < y1 < y2 < · · · < ym. The ordering of the
variables ensures that in the minimal satisfying assignment of φ′ the variables
in {x1, . . . , xn} will be minimal with respect to the satisfaction of φ. Now the
function g1 shortens the assignment and removes all bits belonging to the vari-
ables yj. Hence g1 applied to the minimal satisfying assignment of φ′ produces
the minimal satisfying assignment of φ, thus concluding the proof.
□
It is worth noticing that, here again as in the case of counting problems with
Turing reductions (see Remark 6.15), it is the power of the reduction that makes
the Galois connection help a priori.
Though not stated explicitly, this was the main tool to obtain the following
classiﬁcation in [RV03] by Reith and Vollmer.
Theorem 6.21. [Lexicographically minimal satisfying assignment]
– If Γ is Schaefer or 0-valid then Lex-Min-Sat(Γ) is polynomial-time com-
putable.
– Otherwise, Lex-Min-Sat(Γ) is OptP-complete under metric reductions.
Also it was shown that to determine the last bit of the lexicographically min-
imal satisfying assignment of Γ-formulas is either complete for the class PNP
or in P, and which case occurs depends on Γ in exactly the same way as for
Lex-Min-Sat(Γ). Similar results (in switching 0-valid to 1-valid) hold for the
corresponding maximization problems.
In the last decades, a lot of work in complexity theory has been devoted to
classify the approximability of NP optimization problems (NPO). We propose
to review here some of the results obtained on this subject for Boolean CSPs in
an informal way. For a more detailed exposition we refer the reader to [CKST99]
and [CKS01]. Recall that a generic NPO problem is speciﬁed by a four-tuple
(I, S, m, opt) where I describes the set of instances, S the set of feasible solutions,
m deﬁnes the value of a given solution and opt describes the goal, max or min, to
achieve. We will focus here on maximization problems, i.e., in which opt = max.
We say that an approximation algorithm has a performance ratio R(n) if, given
an instance x ∈I such that |x| = n and the maximum value of its feasible
solutions is opt(x), it computes a solution y ∈S(x) whose value, m(x, y) satisﬁes
m(x, y) ≤R(n) · opt(x). An NPO problem Π is in the class APX if there exists
a polynomial-time approximation algorithm for Π whose performance ratio is
bounded by a constant, and it is in poly-APX if there exists a polynomial-
time approximation algorithm for Π whose performance ratio is bounded by a
polynomial factor in the size of the input. Completeness in approximation classes
is deﬁned via appropriate approximation preserving reducibilities. We refer here
to AP-reducibility ≤AP, whose precise deﬁnition can be found in [CKST99] or
in [CKS01, Deﬁnition 2.44]. In particular this notion of reducibility preserves
membership in poly-APX as well as in APX.
We review results concerning two diﬀerent optimisation problems Max-Ones
and Max-Sat. In these problems the instances are still the same: Γ-formulas.

28
N. Creignou and H. Vollmer
These problems diﬀer in their deﬁnition of feasible solutions and the manner
in which the value of a feasible solution is computed. First let us examine the
Max-Ones problem, where a Γ-formula has as its feasible solution space the
set of satisfying assignments. The objective function is then simply set to that
of maximizing the number of variables set to 1.
Problem:
Max-Ones(Γ)
Input:
a Γ-formula φ
Output:
A satisfying assignment of φ that maximizes the number
of variables set to true
In the study of optimization problems it is natural to consider weighted problems.
Problem:
weighted-Max-Ones(Γ)
Input:
a Γ-formula φ over n variables and n non-negative integers
w1, . . . , wn
Output:
A satisfying assignment of φ that maximizes the sum of
the weights of the variables set to true
When dealing with weighted problems the Galois connection works in the ap-
proximation framework.
Proposition 6.22. If Γ ⊆⟨Γ ′⟩then
weighted-Max-Ones(Γ) ≤AP weighted-Max-Ones(Γ ′).
Proof. Given φ a Γ-formula with weighted variables, we construct a formula φ′
by performing the following steps:
– Replace every constraint from Γ by its deﬁning existentially quantiﬁed

Γ ′∪
{=}

-formula.
– Delete existential quantiﬁers.
– All the newly introduced variables get the weight 0.
– Delete equality clauses and replace all variables that are connected via a
chain of equality constraints by a common new variable. This new variable
gets as weight the sum of the weights of the variables in the chain.
Then, obviously, φ′ is a Γ ′-formula. Moreover, for any t, φ is satisﬁed by an
assignment of weight t if and only φ′ is satisﬁed by an assignment of weight t (an
assignment has weight t if the sum of the weights of the variables it sets to true
is t). Therefore, this provides a reduction that preserves approximability.
□
It turns out that when the set Γ is Schaefer or 1-valid, then there is no essential
diﬀerence in the approximability of the weighted and unweighted problems, and
otherwise the task of ﬁnding either any feasible solutions or a solution of positive
value is already NP-hard. For this reason the Galois connection can help in the
framework of approximability of Max-Ones problems and thus Khanna, Sudan
and Williamson [KSW97] obtained the classiﬁcation below, which follows Post’s
lattice.

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
29
Theorem 6.23. [Maximum ones satisﬁability]
– If Γ is 1-valid or dual Horn or aﬃne with width 2, then Max-Ones(Γ) is
in PO.
– Else if Γ is aﬃne, then Max-Ones(Γ) is APX-complete.
– Else if Γ is Horn or bijunctive, then Max-Ones(Γ) is poly-APX-complete.
– Else if Γ is 0-valid, then ﬁnding a feasible solution to Max-Ones(Γ) is in
P but ﬁnding a solution of positive value is NP-hard.
– Else the task of ﬁnding any feasible solution to Max-Ones(Γ) is NP-hard.
Now let us examine the problem Max-Sat in which a given Γ-formula φ has
as feasible solutions space the set of all truth assignments. The objective is to
maximize the number of satisﬁed constraints in φ.
Problem:
Max-Sat(Γ)
Input:
a Γ-formula φ
Output:
A truth assignment that maximizes the number of con-
straints satisﬁed in φ
Creignou [Cre95], and Khanna and Sudan [KS96] obtained a dichotomy classiﬁ-
cation for the approximability of Max-Sat(Γ). Before stating the corresponding
theorem we recall that a relation R is said to be 2-monotone if it is expressible
as a DNF-formula either of the form (x1 ∧. . . ∧xp) or (¬y1 ∧. . . ∧¬yq) or
(x1 ∧. . . ∧xp) ∨(¬y1 ∧. . . ∧¬yq). A set Γ of relations is said to be 2-monotone
if every relation R from Γ is 2-monotone.
Theorem 6.24. [Maximum satisﬁability]
– If Γ is 0-valid or 1-valid or 2-monotone, then Max-Sat(Γ) is in PO.
– Otherwise Max-Sat(Γ) is APX-complete.
It is worth pointing out that this classiﬁcation does not follow Post’s lattice.
Indeed it is easy to check that 2-monotone relations do not constitute a co-
clone. (The usual implication is obviously 2-monotone, however the conjunction
x →y ∧u →v is not.) Therefore the Galois connection is of no help in or-
der to get the complexity classiﬁcation of Max-Sat(Γ). A similar dichotomy
(P/PLS-complete) was obtained by Chapdelaine and Creignou [CC05] for the
local search problems, in which the objective is to ﬁnd an assignment that is
locally maximum, that is to say such that ﬂipping any bit does not increase
the number of satisﬁed constraints. Note that the minimization problems, whose
approximability properties might be diﬀerent from the ones of the maximization
problems, were also studied in [KSTW01].
6.5
Further Problems
We examine here further problems that do not fall in the previous categories.
Let us start with the Inverse satisﬁability problem.

30
N. Creignou and H. Vollmer
Problem:
Inverse-Sat(Γ)
Input:
a set M ⊆{0, 1}n
Question:
Does there exist a Γ-formula over n variables that has M
as its set of models?
As noticed in [KS98] the fact that Γ ⊆⟨Γ ′⟩is not suﬃcient to ensure that
Inverse-Sat(Γ) is reducible to Inverse-Sat(Γ ′). Indeed one needs a stronger
notion of implementation, which from a Γ-formula φ allows to build a Γ ′-formula
φ′ such that not only φ is satisﬁable if and only if φ′ is satisﬁable, but there is
also a one-to-one onto correspondence between their respective set of models.
However Kavvadias and Sideri [KS98] obtained a classiﬁcation theorem that
follows Post’s lattice.
Theorem 6.25. [Inverse satisﬁability ] Let Γ be a constraint language that con-
tains the constants 0 and 1.
– If Γ is Schaefer then Inverse-Sat(Γ) is in P.
– Otherwise Inverse-Sat(Γ) is coNP-complete.
Observe that a complexity classiﬁcation for sets Γ that do not necessarily contain
the constants is still an open question.
The parameterized complexity of constraint satisfaction problems is also of
interest. In parameterized complexity we are dealing with problems where each
instance has a distinguished part called the parameter. A parameterized problem
is ﬁxed-parameter-tractable (FPT) if it can be solved in polynomial-time for
every ﬁxed value of the problem parameter k, and moreover, the degree of the
polynomial in the time bound does not depend on k. By showing that a problem
is NP-complete one gives strong evidence that it does not have a polynomial-time
algorithm. There is a similar completeness program in parameterized complexity
that allows to show that certain problems are unlikely to be in FPT. In particular
the class W[1] contains the parameterized problems that can be reduced to the
problem “Does the given nondeterministic Turing machine accept input x in at
most k steps?”. (The parameter for this problem is k.) It is believed that W[1]-
complete problems are not ﬁxed-parameter-tractable. For more background on
parameterized complexity the reader is asked to consult the monograph [FG06].
In [Mar05] Marx investigated the parameterized complexity of p-Sat(Γ) de-
ﬁned as follows.
Problem:
p-Sat(Γ)
Input:
a Γ-formula φ where each variable can occur at most once
in each constraint, and an integer k
Parameter:
k
Question:
Is there a truth assignment setting exactly k variables to
true that satisﬁes φ?
He introduced a new property, weak separability, that plays a crucial role in
the parameterized complexity of problems.

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
31
Deﬁnition 6.26. A relation R is weakly separable if
1. whenever x1 and x2 are in R, if x1 ∧x2 is in R, then so is x1 ∨x2,
2. whenever x1 < x2 < x3 are in R (where < refers to the coordinate-wise
order) then so is x1 ⊕x2 ⊕x3.
All operations are taken coordinate-wise.
Marx got the following classiﬁcation result.
Theorem 6.27. [Parameterized complexity]
– If every relation in Γ is weakly separable then p-Sat(Γ) is in FPT.
– Otherwise p-Sat(Γ) is W[1]-complete.
This classiﬁcation does not follow Post’s lattice. Indeed it is easy to check that
weakly separable relations do not constitute a co-clone (for instance the relation
R = {000, 101, 110} is weakly separable, however R′(y, z) = ∃xR(x, y, z), R′ =
{00, 01, 10} is not).
To conclude let us mention other complexity results for Boolean constraint
satisfaction problems that are related to geometric properties of the solution
space. A ﬁrst result in this vein (even if it was not originally advertised in
this way) was obtained by Jonsson and Krokhin [JK04], who studied the frozen
variables problem, actively used e.g. in the study of phase transition phenomena,
but also closely related to a problem from the database context (of “auditing
variables” [KPR03]):
Problem:
Frozen-Var(Γ)
Input:
a Γ-formula φ and V ′ a nonempty subset of Var(φ)
Question:
Is every variable x in V ′ frozen? (a variable x is said to be
frozen if |{I(x)|I is a truth assignment satisfying φ}| = 1)
The problem to recognize frozen variables is a generalization of the Unique-Sat
problem in which the uniqueness requirement is applied to all variables. As
proved in [JK04] the Galois connection applies a priori for this problem and
leads to the following classiﬁcation.
Theorem 6.28. [Frozen variables]
– If ⟨Γ⟩⊇Inv(N2), then Frozen-Var(Γ) is DP-complete.
– Otherwise, if ⟨Γ⟩⊇Inv(I0) or ⟨Γ⟩⊇Inv(I1), then Frozen-Var(Γ) is
coNP-complete.
– In all other cases Frozen-Var(Γ) is in P.
Connectivity properties of the solution space were investigated by Gopalan, Ko-
latitis, Maneva and Papadimitriou in [GKMP06]. In particular they studied the
st-connectivity problem deﬁned as follows.
Problem:
st-Conn(Γ)
Input:
a Γ-formula φ, and two satisfying assignments s and t of φ
Question:
Is there a path in G(φ), the subgraph of the n-dimensional
hypercube induced by the solutions of φ, from s to t?

32
N. Creignou and H. Vollmer
Gopalan et al. [GKMP06] introduced the notion of a tight set of Boolean rela-
tions, deﬁned as follows: A relation R is tight if it is componentwise bijunctive
(that is, every connected component in the hypercube of all tuples in R is bi-
junctive), OR-free (that is, the binary disjunction is not deﬁnable from R by
setting all but two of the variables to constants), or NAND-free (that is, the
binary NAND is not deﬁnable from R by setting all but two of the variables to
constants); and as usual a set of relations is tight if every relation in it is tight.
The class of tight constraint languages properly includes the class of Schaefer
constraint languages. Gopalan et al. showed that if Γ is tight then st-Conn(Γ)
is in P, otherwise it is PSPACE-complete. This classiﬁcation does not follow
Post’s lattice, therefore one can deduce that the Galois connection does not
help in studying the connectivity properties of the solution space of constraint
satisfaction problems. Gopalan et al. also investigated the more general problem
Conn(Γ), in which the question is whether G(φ) is connected. They proved that
if Γ is tight then Conn(Γ) is in coNP, otherwise it is PSPACE-complete. The
only tight cases for which Conn(Γ) is not known to be coNP-complete or in P
are Horn and dual Horn. While these cases were conjectured in [GKMP06] to be
polynomial, Makino, Tamaki and Yamamoto recently exhibited in [MTY07] a
Horn set Γ such that Conn(Γ) is coNP-complete. So, a complete classiﬁcation
for the connectivity problem is still an open problem.
7
Conclusion
We have seen that Post’s lattice helps if the deﬁnition of the considered com-
putational problem allows to hide the existential quantiﬁers that are obtained
from the usual local-replacement reduction, and to remove the equality clauses
by identifying variables. The article by Ilka and Henning Schnoor in this volume
addresses similar but diﬀerent Galois connections that apply if one or both of
these conditions are not given. These connections do not involve Post’s lattice
but ﬁner structures. Nevertheless it turns out that also here, Post’s lattice is
often the important spine.
While the complexity of Boolean constraint satisfaction problems has been
extensively studied, there still remain some interesting open questions as we
have seen along this survey. For instance, a complete complexity classiﬁcation
for the above mentionned connectivity problem appears as a challenging prob-
lem. Another problem that has raised considerable attention is a complexity
classiﬁcation of the inference problem for basic circumscription, where “basic”
here means that a model is deﬁned to be minimal if it is minimal in the compo-
nentwise order involving all variables (in the notation of the deﬁnition given in
Sect. 6.1 on p. 16 we thus require that P is the set of all variables); the Galois
connection is not known to hold for this case.
The interest of the complexity of Boolean CSPs lies in its strong connection to
Post’s lattice. The latter being well-known, we can take advantage of it in order
to study the complexity of Boolean CSPs, which in turn can help to develop
new tools and strategies towards the more ambitious goal of the complexity of

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
33
constraint satisfaction problems over arbitrary ﬁnite domains. To name only one
example, the recent detailed complexity study of CSPs solvable in logarithmic
space published in [ELT07] gained many of its initial ideas from a corresponding
ﬁne classiﬁcation of Boolean CSPs (presented in Sect. 5 of this survey). Moreover,
the dual connection between Boolean CSPs and Post’s lattice works also the
other way round. Indeed, complexity studies have renewed the interest in Post
lattice and motivated some advanced studies in the description of the lattice
itself (see for instance [BRSV05] and [CKZ08] where diﬀerent bases of the co-
clones were proposed) as well as in the description of ﬁners structures underlying
Post lattice [Sch07b, SS].
Boolean satisﬁability problems and related counting and optimization prob-
lems form the nucleus of most complexity classes since they usually provide the
ﬁrst and canonical complete problems. Their study, thus, is a hardly disguised
study of complexity classes, their inclusion structure, and their properties. We
think we have made this very clear in the course of this chapter by talking about
the power of reductions, the structure of complete sets, the complexity of iso-
morphism problems—these address typical complexity-theoretic questions, and
this provides a main motivation for a further pursue of the study of Boolean
constraint satisfaction problems.
Acknowledgement
We are grateful to Henning Schnoor for many helpful comments on a previous
version of this paper.
References
[ABI+05]
Allender, E., Bauland, M., Immerman, N., Schnoor, H., Vollmer, H.: The
complexity of satisﬁability problems: Reﬁning Schaefer’s theorem. In: Je-
drzejowicz, J., Szepietowski, A. (eds.) MFCS 2005. LNCS, vol. 3618, pp.
71–82. Springer, Heidelberg (2005)
[Agr01]
Agrawal, M.: The ﬁrst-order isomorphism theorem. In: Hariharan, R.,
Mukund, M., Vinay, V. (eds.) FSTTCS 2001. LNCS, vol. 2245, pp. 70–82.
Springer, Heidelberg (2001)
[BBC+07]
Bauland, M., B¨ohler, E., Creignou, N., Reith, S., Schnoor, H., Vollmer, H.:
The complexity of problems for quantiﬁed constraints. Technical Report
07-023, Electronic Colloquium on Computational Complexity (2007)
[BCC+05]
Bauland, M., Chapdelaine, P., Creignou, N., Hermann, M., Vollmer,
H.: An algebraic approach to the complexity of generalized conjunctive
queries. In: Hoos, H.H., Mitchell, D.G. (eds.) SAT 2004. LNCS, vol. 3542,
pp. 30–45. Springer, Heidelberg (2005)
[BCRV03]
B¨ohler, E., Creignou, N., Reith, S., Vollmer, H.: Playing with Boolean
blocks, part I: Post’s lattice with applications to complexity theory. ACM-
SIGACT Newsletter 34(4), 38–52 (2003)
[BCRV04]
B¨ohler, E., Creignou, N., Reith, S., Vollmer, H.: Playing with Boolean
blocks, part II: Constraint satisfaction problems. ACM-SIGACT Newslet-
ter 35(1), 22–35 (2004)

34
N. Creignou and H. Vollmer
[BD03]
Bulatov, A., Dalmau, V.: Towards a dichotomy theorem for the counting
constraint satisfaction problem. In: Proceedings Foundations of Computer
Science, pp. 562–572. ACM Press, New York (2003)
[BG82]
Blass, A., Gurevich, Y.: On the unique satisﬁability problem. Information
and Control 82, 80–88 (1982)
[BH05]
Bauland, M., Hemaspaandra, E.: Isomorphic implication. In: Jedrzejowicz,
J., Szepietowski, A. (eds.) MFCS 2005. LNCS, vol. 3618, pp. 119–130.
Springer, Heidelberg (2005)
[BHRV02]
B¨ohler, E., Hemaspaandra, E., Reith, S., Vollmer, H.: Equivalence and
isomorphism for Boolean constraint satisfaction. In: Bradﬁeld, J.C. (ed.)
CSL 2002 and EACSL 2002. LNCS, vol. 2471, pp. 412–426. Springer, Hei-
delberg (2002)
[BHRV04]
B¨ohler, E., Hemaspaandra, E., Reith, S., Vollmer, H.: The complexity of
Boolean constraint isomorphism. In: Diekert, V., Habib, M. (eds.) STACS
2004. LNCS, vol. 2996, pp. 164–175. Springer, Heidelberg (2004)
[BKKR69]
Bodnarchuk, V.G., Kaluˇznin, L.A., Kotov, V.N., Romov, B.A.: Galois the-
ory for Post algebras I, II. Cybernetics 5, :243–252, 531–539 (1969)
[BRSV05]
B¨ohler, E., Reith, S., Schnoor, H., Vollmer, H.: Bases for Boolean co-clones.
Information Processing Letters 96, 59–66 (2005)
[CC05]
Chapdelaine, P., Creignou, N.: The complexity of boolean constraint sat-
isfaction local search problems. Annals of Mathematics and Artiﬁcial In-
telligence 43(1-4), 51–63 (2005)
[CH96]
Creignou, N., Hermann, M.: Complexity of generalized satisﬁability count-
ing problems. Information and Computation 125, 1–12 (1996)
[CH97]
Creignou, N., H´ebrard, J.-J.: On generating all solutions of generalized sat-
isﬁability problems. Informatique Th´eorique et Applications/Theoretical
Informatics and Applications 31(6), 499–511 (1997)
[Che06]
Chen, H.: A rendezvous of logic, complexity, and algebra. ACM-SIGACT
Newsletter 37(4), 85–114 (2006)
[CHS07]
Chapdelaine, P., Hermann, M., Schnoor, I.: Complexity of default logic on
generalized conjunctive queries. In: Baral, C., Brewka, G., Schlipf, J. (eds.)
LPNMR 2007. LNCS, vol. 4483, pp. 58–70. Springer, Heidelberg (2007)
[CKS01]
Creignou, N., Khanna, S., Sudan, M.: Complexity Classiﬁcations of
Boolean Constraint Satisfaction Problems. Monographs on Discrete Ap-
plied Mathematics. SIAM, Philadelphia (2001)
[CKST99]
Crescenzi, P., Kann, V., Silvestri, R., Trevisan, L.: Structure in approxi-
mation classes. SIAM Journal on Computing 28(5), 1759–1782 (1999)
[CKZ08]
Creignou, N., Kolaitis, Ph., Zanuttini, B.: Structure Identiﬁcation for
Boolean Relations and Plain Bases for co-Clones. Journal of Computer
and System Sciences 74, 1103–1115 (2008)
[Coo71]
Cook, S.A.: The complexity of theorem proving procedures. In: Proceed-
ings 3rd Symposium on Theory of Computing, pp. 151–158. ACM Press,
New York (1971)
[Cre95]
Creignou, N.: A dichotomy theorem for maximum generalized satisﬁability
problems. Journal of Computer and System Sciences 51, 511–522 (1995)
[CZ06]
Creignou, N., Zanuttini, B.: A complete classiﬁcation of the complexity
of propositional abduction. SIAM Journal on Computing 36(1), 207–229
(2006)
[Dal97]
Dalmau, V.: Some dichotomy theorems on constant-free quantiﬁed boolean
formulas. Technical Report LSI-97-43-R, Department de Llenguatges i Sis-
temes Inform`atica, Universitat Polit´ecnica de Catalunya (1997)

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
35
[Dal00]
Dalmau, V.: Computational complexity of problems over generalized for-
mulas. Ph.D thesis, Department de Llenguatges i Sistemes Inform`atica,
Universitat Polit´ecnica de Catalunya (2000)
[DHK05]
Durand, A., Hermann, M., Kolaitis, P.G.: Subtractive reductions and com-
plete problems for counting complexity classes. Theoretical Computer Sci-
ence 340(3), 496–513 (2005)
[ELT07]
Egri, L., Larose, B., Tesson, P.: Symmetric datalog and constraint sat-
isfaction problems in logspace. In: 22nd IEEE Symposium on Logic in
Computer Science, pp. 193–202. IEEE Computer Society, Los Alamitos
(2007)
[FG06]
Flum, J., Grohe, M.: Parameterized complexity theory. Springer, Heidel-
berg (2006)
[Gei68]
Geiger,
D.:
Closed
systems
of
functions
and
predicates.
Pac.
J.
Math. 27(2), 228–250 (1968)
[GKMP06] Gopalan, P., Kolaitis, P.G., Maneva, E.N., Papadimitriou, C.H.: The
connectivity of boolean satisﬁability: Computational and structural di-
chotomies. In: Bugliesi, M., Preneel, B., Sassone, V., Wegener, I. (eds.)
ICALP 2006. LNCS, vol. 4051, pp. 346–357. Springer, Heidelberg (2006)
[Hem04]
Hemaspaandra, E.: Dichotomy theorems for alternation-bounded quanti-
ﬁed boolean formulas. CoRR, cs.CC/0406006 (2004)
[HV95]
Hemaspaandra, L., Vollmer, H.: The satanic notations: counting classes
beyond #P and other deﬁnitional adventures. Complexity Theory Column
8, ACM-SIGACT News 26(1), 2–13 (1995)
[Imm99]
Immerman, N.: Descriptive Complexity. Graduate Texts in Computer Sci-
ence. Springer, New York (1999)
[JCG97]
Jeavons, P.G., Cohen, D.A., Gyssens, M.: Closure properties of constraints.
Journal of the ACM 44(4), 527–548 (1997)
[JK04]
Jonsson, P., Krokhin, A.: Recognizing frozen variables in constraint satis-
faction problems. Theoretical Computer Science 329(1-3), 93–113 (2004)
[JPY88]
Johnson, D.S., Papadimitriou, C.H., Yannakakis, M.: On generating all
maximal independent sets. Information Processessing Letters 27(3), 119–
123 (1988)
[Jub99]
Juban, L.: Dichotomy theorem for generalized unique satisﬁability prob-
lem. In: Ciobanu, G., P˘aun, G. (eds.) FCT 1999. LNCS, vol. 1684, pp.
327–337. Springer, Heidelberg (1999)
[KK03]
Kirousis, L.M., Kolaitis, P.G.: The complexity of minimal satisﬁability
problems. Information and Computation 187(1), 20–39 (2003)
[KK04]
Kirousis, L.M., Kolaitis, P.G.: A dichotomy in the complexity of proposi-
tional circumscription. Theory of Computing Systems 37, 695–715 (2004)
[KL99]
Kleine B¨uning, H., Lettmann, T.: Propositional Logic: Deduction and Al-
gorithms. Cambridge Tracts in Theoretical Computer Science. Cambridge
University Press, Cambridge (1999)
[KPR03]
Kleinberg, J., Papadimitriou, C., Raghavan, P.: Auditing Boolean at-
tributes. Journal of Computer and System Sciences 66(1), 244–253 (2003)
[Kre88]
Krentel, M.W.: The complexity of optimization functions. Journal of Com-
puter and System Sciences 36, 490–509 (1988)
[Kre92]
Krentel, M.W.: Generalizations of OptP to the polynomial hierarchy. The-
oretical Computer Science 97, 183–198 (1992)
[KS96]
Khanna, S., Sudan, M.: The optimization complexity of constraint satisfac-
tion problems. Technical Report STAN-CS-TN-96-29, Stanford University
(1996)

36
N. Creignou and H. Vollmer
[KS98]
Kavvadias, D., Sideri, M.: The inverse satisﬁability problem. SIAM Journal
of Computing 28(1), 152–163 (1998)
[KST93]
K¨obler, J., Sch¨oning, U., Tor´an, J.: The Graph Isomorphism Problem:
its Structural Complexity. Progress in Theoretical Computer Science.
Birkh¨auser, Basel (1993)
[KSTW01]
Khanna, S., Sudan, M., Trevisan, L., Williamson, D.P.: The approximabil-
ity of constraint satisfaction problems. SIAM Journal on Computing 30,
1863–1920 (2001)
[KSW97]
Khanna, S., Sudan, M., Williamson, D.: A complete classiﬁcation of the ap-
proximability of maximization problems derived from Boolean constraint
satisfaction. In: Proceedings 29th Symposium on Theory of Computing,
pp. 11–20. ACM Press, New York (1997)
[Lau06]
Lau, D.: Function Algebras on Finite Sets. Monographs in Mathematics.
Springer, Heidelberg (2006)
[Mar05]
Marx, D.: Parameterized complexity of constraint satisfaction problems.
Computational Complexity 14(2), 153–183 (2005)
[MS72]
Meyer, A.R., Stockmeyer, L.J.: The equivalence problem for regular ex-
pressions with squaring requires exponential time. In: Proceedings 13th
Symposium on Switching and Automata Theory, pp. 125–129. IEEE Com-
puter Society Press, Los Alamitos (1972)
[MTY07]
Makino, K., Tamaki, S., Yamamoto, M.: On the boolean connectivity prob-
lem for horn relations. In: Marques-Silva, J., Sakallah, K.A. (eds.) SAT
2007. LNCS, vol. 4501, pp. 187–200. Springer, Heidelberg (2007)
[NJ04]
Nordh, G., Jonsson, P.: An algebraic approach to the complexity of propo-
sitional circumscription. In: 19th Symposium on Logic in Computer Sci-
ence, pp. 367–376. IEEE Computer Society, Los Alamitos (2004)
[Nor05]
Nordh, G.: A trichotomy in the complexity of propositional circumscrip-
tion. In: Baader, F., Voronkov, A. (eds.) LPAR 2004. LNCS, vol. 3452, pp.
257–269. Springer, Heidelberg (2005)
[NZ05]
Nordh, G., Zanuttini, B.: Propositional abduction is almost always hard.
In: Proceedings International Joint Conference on Artiﬁcial Intelligence,
pp. 534–539 (2005)
[Pap94]
Papadimitriou, C.H.: Computational Complexity. Addison-Wesley, Read-
ing (1994)
[Pip97]
Pippenger, N.: Theories of Computability. Cambridge University Press,
Cambridge (1997)
[Pos20]
Post, E.L.: Determination of all closed systems of truth tables. Bulletin of
the AMS 26, 437 (1920)
[Pos41]
Post, E.L.: The two-valued iterative systems of mathematical logic. Annals
of Mathematical Studies 5, 1–122 (1941)
[Rei05]
Reingold, O.: Undirected st-connectivity in log-space. In: Proceedings of
the 37th Symposium on Theory of Computing, pp. 376–385. ACM Press,
New York (2005)
[RV03]
Reith, S., Vollmer, H.: Optimal satisﬁability for propositional calculi and
constraint satisfaction problems. Information and Computation 186(1),
1–19 (2003)
[Sch78]
Schaefer, T.J.: The complexity of satisﬁability problems. In: Proccedings
10th Symposium on Theory of Computing, pp. 216–226. ACM Press, New
York (1978)

Boolean Constraint Satisfaction Problems: When Does Post’s Lattice Help?
37
[Sch07a]
Schnoor, H.: Algebraic Techniques for Satisﬁability Problems. PhD thesis,
Leibniz Universit¨at Hannover, Fakult¨at f¨ur Elektrotechnik und Informatik
(2007)
[Sch07b]
Schnoor, I.: The Weak Base Method for Constraint Satisfaction. Ph.D
thesis, Leibniz Universit¨at Hannover, Fakult¨at f¨ur Elektrotechnik und In-
formatik (2007)
[SM73]
Stockmeyer, L.J., Meyer, A.R.: Word problems requiring exponential time.
In: Proceedings 5th ACM Symposium on the Theory of Computing, pp.
1–9. ACM Press, New York (1973)
[SS]
Schnoor, H., Schnoor, I.: Partial polymorphisms and constraint satisfac-
tion problems. In: Creignou, N., Kolaitis, P.G., Vollmer, H. (eds.) Com-
plexity of Constraints. LNCS, vol. 5250. Springer, Heidelberg (2008)
[SS07]
Schnoor, H., Schnoor, I.: Enumerating all solutions for constraint satisfac-
tion problems. In: 24th Symposium on Theoretical Aspects of Computer
Science. LNCS, pp. 694–705. Springer, Heidelberg (2007)
[Tod91a]
Toda, S.: Computational Complexity of Counting Complexity Classes.
Ph.D thesis, Tokyo Institute of Technology, Department of Computer Sci-
ence, Tokyo (1991)
[Tod91b]
Toda, S.: PP is as hard as the polynomial time hierarchy. SIAM Journal
on Computing 20, 865–877 (1991)
[TW92]
Toda, S., Watanabe, O.: Polynomial time 1-Turing reductions from #PH
to #P. Theoretical Computer Science 100, 205–221 (1992)
[Val79a]
Valiant, L.G.: The complexity of computing the permanent. Theoretical
Computer Science 8, 189–201 (1979)
[Val79b]
Valiant, L.G.: The complexity of enumeration and reliability problems.
SIAM Journal of Computing 8(3), 411–421 (1979)
[Vol94]
Vollmer, H.: Komplexit¨atsklassen von Funktionen. Ph.D thesis, Univer-
sit¨at W¨urzburg, Fakult¨at f¨ur Mathematik und f¨ur Informatik (1994)
[Vol99]
Vollmer, H.: Introduction to Circuit Complexity – A Uniform Approach.
Texts in Theoretical Computer Science. Springer, Heidelberg (1999)
[Vol07]
Vollmer, H.: Computational complexity of constraint satisfaction. In:
Cooper, S.B., L¨owe, B., Sorbi, A. (eds.) CiE 2007. LNCS, vol. 4497, pp.
748–757. Springer, Heidelberg (2007)
[Wra77]
Wrathall, C.: Complete sets and the polynomial-time hierarchy. Theoret-
ical Computer Science 3, 23–33 (1977)
[Zan91]
Zank´o, V.: #P-completeness via many-one reductions. International Jour-
nal of Foundations of Computer Science 2, 77–82 (1991)

Basics of Galois Connections
Ferdinand B¨orner
Universit¨at Potsdam, Institut f¨ur Informatik,
PF 90 03 27, D–14 439 Potsdam
fboerner@rz.uni-potsdam.de
Abstract. We give an overview of basic properties of Galois connections
between sets of relations and sets of functions or generalized functions.
First we focus on the Galois connections Inv –Pol and Inv –mPol . Then
we use these results to provide some tools for the representation of sev-
eral closure operators on relations as closure operators of some Galois
connections.
Introduction
Galois connections appear very frequently in all parts of Mathematics. Often
they are of importance, they simplify things, they relate diﬀerent objects to
each other, and they are easy to deﬁne. We only need two sets X and Y and a
deﬁning relation Ξ ⊆X × Y. Then the operators
α : X ⊇X →αX := {y ∈Y | (∀x ∈X)Ξ(x, y)} ⊆Y
β : Y ⊇Y →βY := {x ∈X | (∀y ∈Y ) ∈Ξ(x, y)} ⊆X
form a Galois connection, and all Galois connections can be deﬁned in this
way. In Section 1 we give a short introduction to the general properties of such
abstract Galois connections. (This is not the most general way to consider Galois
connections. For a study in the framework of lattice theory we refer to [1].)
The “Galois closed subsets” of X and Y are the sets X ⊆X and Y ⊆Y
with X = βαX and Y = αβY . The closed subsets of X and Y are in one-one
correspondence, “small” subsets of X determine “large” closed subsets of Y and
vice versa. To “characterize” a Galois connection means to describe the Galois
closed subsets with other tools.
Of course, the name “Galois connection” reminds of E. Galois’ famous con-
nection between elements a of a ﬁeld E and its automorphisms π, based on the
ﬁxpoint relation π(a) = a. Marc Krasner was impressed by this connection, and,
with the intention to generalize the notion of a ﬁeld, he extended it to a “Galois
connection” between permutations π of a set D and relations ϱ on D ([16, 17]).
The deﬁning relation was given by “π(ϱ) ⊆ϱ”, where π(ϱ) := {π(a) | a ∈ϱ}.
If D is ﬁnite, then the Galois closed permutation sets are just the permutation
groups, and they correspond to those sets of relations that are closed under all
operations that can be deﬁned by ﬁrst-order formulas.
This was the starting point for an investigation of Galois connections between
sets of relations and sets of functions or generalized functions. Krasner’s approach
N. Creignou et al. (Eds.): Complexity of Constraints, LNCS 5250, pp. 38–67, 2008.
c
⃝Springer-Verlag Berlin Heidelberg 2008

Basics of Galois Connections
39
was extended to unary functions, arbitrary functions, partial functions and so
on ([2, 3, 26, 29, 31, 32, 27]). In particular, L.A. Kaluˇznin and his collaborators
simpliﬁed proofs, generalized the notation and found applications in various
ﬁelds of algebra. Corresponding investigations in the english literature can be
found in the paper [13] by D. Geiger.
In the center of this approach stands the Galois connection Inv –Pol between
sets of functions and sets of relations on a basic set D. (In this article we always
assume that D is ﬁnite.) Inv –Pol is based on the “invariance relation” f(ϱ) ⊆ϱ,
where f is an n-ary function, ϱ an m-ary relation and f(ϱ) = {f(a1, . . . , an) |
a1, . . . , an ∈ϱ}. The closed sets of functions are clones (i.e. sets of functions,
closed under superposition and containing all projections), and the closed sets
of relations, called relational clones, are sets of relations that are closed under
deﬁnitions with ﬁrst-order primitive positive formulas. This connection became
one of the main tools for the investigation of clones and clone lattices with
applications from Universal Algebra to Technical Computer Science. We refer to
the monographs [20] and [18].
Then it was a nice surprise when P. Jeavons et.al. discovered a very successful
application of this Galois connection to the investigation of the algorithmic com-
plexity of Constraint Satisfaction Problems (CSPs) ([14, 15, 10]). In Section 3
we shortly introduce the starting idea.
Motivated by these results, we want to provide tools for the description of
more closure operators on sets of relations with the help of Galois connections.
For this aim, in Section 4, we ﬁrst introduce the general notion of a “multifunc-
tion” (also called multioperation, partial hyperfunction, correspondence, . . . ),
and characterize the corresponding Galois connection Inv –mPol ([32, 4, 27]).
In Section 5 we start with this general connection and obtain new closure
operators by restricting the set of multifunctions to various subsets M. If a
closure operator H on sets of relations is given, then we want to ﬁnd a set M of
multifunctions such that H = Inv (M ∩mPol ). If this is possible, then H can be
described with the help of a Galois connection. Theorem 5.3 shows under which
conditions this is really possible. Then we give a short overview of some known
connections that can be obtained in this way. (Here we restrict ourselves to the
case of a ﬁnite basic set D; for a more general survey we refer to [22].)
Finally, in Section 6, we investigate a special closure operator which is con-
nected with the algorithmic Quantiﬁed Constraint Satisfaction Problem (QCSP),
a generalization of the CSP. Using the results of the previous Sections, we show
that the set of surjective functions can serve as a suitable base for the represen-
tation of this closure operator via a new Galois connection. This result leads to
a similar application to the QCSP as before for the CSP.
1
Basic Properties of Galois Connections
Galois connections can be considered as tools for the description of closure ope-
rators. In this article, closure operators on sets of relations (or on sets of func-
tions or generalized or specialized functions) will play an important role. In this

40
F. B¨orner
Section we collect some general properties of closure operators and Galois con-
nections. Almost everything here is standard and well known (see e.g.
[18, 19, 20]). In the last Subsection we investigate the problem of how to ap-
proximate a closure operator H with the help of a given Galois connection α–β.
The proofs in this Section are mainly straight forward, and we usually skip
them.
Closure Operators
If Z is a set, then P Z := {Z | Z ⊆Z} is the set of all subsets of Z. An operator
H : P Z →P Z is a closure operator on Z if for all Z0, Z1 ⊆Z the following
hold:
1. Z0 ⊆HZ0 (H is extensive.)
2. Z0 ⊆Z1 =⇒HZ0 ⊆HZ1 (H is monotone.)
3. HHZ0 = HZ0 (H is idempotent.)
A set Z ⊆Z is closed under the closure operator H if Z = HZ. The set of all
closed subsets of Z is the closure system of H and denoted by
CH
Z := {Z ⊆Z | Z = HZ}.
If C = CH
Z for some closure operator H, then
1. Z ∈C and
2. if Zi ∈C for all i ∈I, I arbitrary index set, then 
i∈I Zi ∈C.
Vice versa, every set C ⊆P Z with (1.) and (2.) is called a closure system. Such
a closure system C induces a closure operator HC by
HC(Z0) :=

{Z ∈C | Z0 ⊆Z}.
Closure systems C and closure operators H on Z are in one-one connection;
we always have CHC
Z
= C and HCH = H.
Closure systems are complete lattices.
Theorem 1.1. Let H be a closure operator on Z and CH
Z the corresponding
closure system. Let Z1, Z2, Zi ∈C, (i ∈I, I arbitrary index set) and consider
the operations
Z1 ∧Z2 = Z1 ∩Z2,
	
i∈I
Zi =

i∈I
Zi
Z1 ∨Z2 = H(Z1 ∪Z2),

i∈I
Zi = H

i∈I
Zi

.
Then CH
Z with the operations ∧and ∨is a complete lattice. The order of this
lattice is just the set theoretical inclusion.
⊓⊔

Basics of Galois Connections
41
A closure operator H and the system CH
Z are called algebraic if HZ = {HZ0 |
Z0 ⊆Z and Z0 is ﬁnite} for all Z ⊆Z. In this case,

CH
Z ; ∧, ∨

is an algebraic
lattice. The set of all subalgebras of a universal algebra is an example of an
algebraic closure system.
For closure operators H1 and H2 on Z we write H1 ≤H2 if H1Z0 ⊆H2Z0 for
all Z0 ⊆Z.
Lemma 1.2. The following are equivalent for two closure operators H1, H2.
1. H1 ≤H2
2. H1H2 = H2
3. CH2
Z
⊆CH1
Z
⊓⊔
So every H2–closed subset Z ⊆Z is also H1–closed. But note that CH2
Z
is in
general not a sublattice of CH1
Z
Galois connections
We start with a general deﬁnition of “Galois connection”.
Deﬁnition 1.3. Let X and Y be nonempty sets. A pair α–β of operators α :
P X →P Y and β : P Y →P X is called a Galois connection (G.C.) between
X and Y if the following hold for all X, X1, X2 ⊆X and all Y, Y1, Y2 ⊆Y.
1. X1 ⊆X2 =⇒αX2 ⊆αX1.
2. Y1 ⊆Y2 =⇒βY2 ⊆βY1.
3. X ⊆βαX and Y ⊆αβY .
⊓⊔
Throughout this section, let α–β denote a Galois connection between X and Y.
The following useful facts are immediate consequences of Def. 1.3.
Corollary 1.4. The following hold for all x ∈X, X, Xi ⊆X and all y ∈Y,
Y, Yi ⊆Y (i ∈I, arbitrary index set).
1. α∅= Y and β∅= X.
2. X ⊆βY ⇐⇒Y ⊆αX and x ∈β{y} ⇐⇒y ∈α{x}.
3. βαβY = βY and αβαX = αX.
4. α 
i∈I
Xi = 
i∈I
αXi and β 
i∈I
Yi = 
i∈I
βYi.
5. The operators βα : P X →P X and αβ : P Y →P Y are closure operators
on X and Y respectively.
⊓⊔
So every G.C. generates two closure operators αβ and βα. Next we consider a
general deﬁnition scheme for Galois connections.
Theorem 1.5.
1. Let Ξ ⊆X × Y be a relation between X and Y and deﬁne
operators αΞ : P X →P Y and βΞ : P Y →P X by
αΞX := {y ∈Y | (∀x ∈X)Ξ(x, y)}
βΞY := {x ∈X | (∀y ∈Y )Ξ(x, y)}.
Then the pair αΞ– βΞ is a Galois connection between P X and P Y.

42
F. B¨orner
2. Let α–β be a G.C. between P X and P Y and deﬁne a relation Ξ ⊆X × Y
by
Ξ := {(x, y) ∈X × Y | x ∈β{y}} ( = {(x, y) ∈X × Y | y ∈α{x}} ).
Then αΞ = α and βΞ = β.
⊓⊔
Consequently every G.C. is determined by a relation Ξ ⊆X ×Y between X and
Y, and each such relation deﬁnes a Galois connection. If α–β is a G.C., then we
call the corresponding relation Ξ the deﬁning relation for this connection, or we
say that α–β is based on Ξ.
Usually the subsets of X and Y which are closed under the closure operators
βα and αβ play an important role.
Deﬁnition 1.6. The sets X ⊆X and Y ⊆Y that are closed under βα or αβ,
i.e. X = βαX and Y = αβY resp., are called Galois closed with respect to the
G.C. α–β.
Consequently the closure systems Cβα
X
and Cαβ
Y
for βα and αβ consist of the
Galois closed sets. If the G.C. α–β is ﬁxed, then we simply write CX and CY.
⊓⊔
According to (1.1), Cβα
X
and Cαβ
Y
are complete lattices. These lattices are inter-
connected.
Theorem 1.7. The lattices

Cβα
X ; ∧, ∨

and

Cαβ
Y ; ∧, ∨

are dually isomorphic.
The dual isomorphisms are the operators α : CX →CY and β : CY →CX.
⊓⊔
This shows a great advantage of Galois connections. The “large” elements of CX
are determined by the “small” elements of CY and vice versa. Information on
one side of the G.C. often can be carried over to information on the other side.
Derived Galois Connections
There is an easy way to derive new Galois connections from α–β. Let M ⊆X
be a so called restriction set and consider the new relation
ΞM := Ξ ∩(M × Y) ⊆M × Y.
Then this relation ΞM deﬁnes a new Galois connection.
Theorem 1.8. If M ⊆X then the operator pair α – M-β,
α : P M →P Y,
X →αX
M-β : P Y →P M,
Y →M ∩βY,
forms a Galois connection between M and Y, based on the relation ΞM.
A subset N ⊆M is Galois closed under M-β α if and only if N = M ∩X
for some X ∈Cβα
X , i.e. if N is the restriction of some βα—closed set X to M.
For the closure operator α M-β always holds αβ ≤α M-β. Therefore (1.2)
Cα M-β
Y
⊆Cαβ
Y
and αβα M-β = α M-β.
⊓⊔

Basics of Galois Connections
43
(The operator α in the new G.C. is not exactly the α of the old G.C. α – β,
it is the restriction of α to P M. But we will use the old symbol α further on,
instead of writing α|P M.)
Now we consider, how CM-β α
M
and Cβα
X
are related. From (1.8) we already know
that X ∈Cβα
X
implies M ∩X ∈CM-β α
M
. Conversely, if N ∈CM-β α
M
, then
βαN ∈Cβα
X . This mapping is injective.
Theorem 1.9. Let γ denote the operator γ : CM-β α
M
→Cβα
X ,
N →βαN.
Then γ is injective, and for all N ∈CM-β α
M
holds N = M ∩γ(N). Moreover,
αγ M-β = α M-β.
If N1, N2 ∈CM-β α
M
, then γ(N1 ∨N2) = γ(N1) ∨γ(N2) and γ(N1 ∧N2) ⊆
γ(N1) ∧γ(N2).
If M ⊆X is closed under βα, then CM-β α
M
is a sublattice of Cβα
X
(and γ is
the identity).
⊓⊔
In general, γ is not a lattice embedding. But in all cases, γ gives the opportunity
to represent the elements of CM-β α
M
with the help of some elements in Cβα
X .
Approximation of Closure Operators
Let H be a closure operator on Y with αβ ≤H. We want to ﬁnd a subset M ⊆X
with H ≤α M-β and such that α M-β is a good “approximation” for H.
H ≤α M-β implies Cα M-β
Y
⊆CH
Y (1.2). Because of (1.4(3)) the sets α{x}
with x ∈M are closed under α M-β. So, if H ≤α M-β then α{x} must be
closed under H whenever x ∈M. This motivates the next Deﬁnition.
Deﬁnition 1.10. The approximation set of H is the set
App(H) := {x ∈X | α{x} = Hα{x}}.
⊓⊔
Theorem 1.11. Let M1, M2, M ⊆X. Then the following hold.
1. M1 ⊆M2 =⇒αM2-β ≤αM1-β
2. H ≤α M-β ⇐⇒M ⊆App(H)
Consequently, αApp(H)-β is the least closure operator α M-β with H ≤α M-β.
Proof.
1. If M1 ⊆M2 then for all Y ⊆Y holds M1-βY = M1 ∩βY ⊆
M2 ∩βY = M2-βY, and therefore αM2-βY ⊆αM1-βY .
2. “⇒” If H ≤α M-β, then by (1.2) every α M-β–closed set is also closed
under H. If x ∈M, then α{x} is closed under α M-β, therefore it must be
closed under H, therefore x ∈App(H).
“⇐” If M ⊆App(H) and Y ⊆Y, then
M-β Y = M ∩βY =

{{x} | x ∈M and x ∈βY }.
Therefore α M-β Y = {α{x} | x ∈M and x ∈βY } (1.4(4)). Now x ∈βY
implies Y ⊆αβY ⊆α{x} and x ∈App(H) implies HY ⊆Hα{x} = α{x}.
Consequently HY ⊆{α{x} | x ∈M and x ∈βY } = α M-β Y.
⊓⊔

44
F. B¨orner
The question, whether we can reach H = α M-β can only be answered if the
special properties of the basic Galois connection α – β are known.
Remark. Every closure operator H on Y can be deﬁned in a trivial way by
some Galois connection. (Choose X = CH
Y and Ξ = {(Y, y) ∈X × Y | y ∈Y }.)
But this trivial Galois connection provides no new information.
2
The Galois Connection Inv –Pol
In the following we consider Galois connections between sets of functions and
sets of relations. They all are based on certain “preservation relations”. During
the last ten years it became clear that these G.C.s also are of importance for the
description of the complexity of Constraint Satisfaction Problems. We will focus
on this interconnection in the next section.
Now we consider the G.C. Inv – Pol between sets of functions and sets of
relations on a common basic set D. This Galois connection is well investigated
([20], [18]), and can serve as a model for all other connections that we will
consider later. Therefore we study this special case in greater detail.
Notions and Notations
First we introduce the sets that correspond to X and Y in the last section. N+
denotes the set of all positive natural numbers. Let D be a nonempty ﬁnite basic
set with at least two elements. For n ∈N+, the set of all n–ary functions on D
is O(n)
D
:= {f
| f
: Dn →D}, and the set of all ﬁnitary functions on D is
OD := 
n∈N+ O(n)
D . If F ⊆OD, then F (n) := F ∩O(n)
D
denotes the set of all
n-ary functions in F.
An m–ary relation on D is a subset ϱ ⊆Dm. The elements of ϱ are m–tuples
a = (a1, . . . , am) ∈Dm. We write a(i) to denote the ith entry ai of a. The
set of all m–ary relations on D is R(m)
D
:= {ϱ | ϱ ⊆Dm}, and the set of all
ﬁnitary relations on D is RD := 
m∈N+ R(m)
D . For a relation set Γ ⊆RD we
put Γ (m) := Γ ∩R(m)
D .
We do not distinguish sharply between relations and predicates. So instead of
a ∈ϱ we also write ϱ(a).
The arity of a function f or a relation ϱ is denoted by ar(f) and ar(ϱ).
Let f ∈O(n)
D , f : Dn →D, m ∈N+. Then we can assign to f also a function
f : (Dm)n →Dm. For i = 1 . . . n let ai ∈Dm. Then we put
f(a1, . . . , an) := (f(a1(1), . . . , an(1)), . . . , f(a1(m), . . . , an(m))) ∈Dm.
If ϱ ∈R(m)
D , then we deﬁne f(ϱ) := {f(a1, . . . , an) | a1, . . . , an ∈ϱ} ⊆Am,
which is again an m–ary relation.
The sets OD and RD will play the role of X and Y in Section 1. Now we
describe the deﬁning relation Ξ for our Galois connection.

Basics of Galois Connections
45
Deﬁnition 2.1. Let f ∈O(n)
D
and ϱ ∈R(m)
D . We say that f preserves ϱ, or
that ϱ is an invariant relation for f, or that f is a polymorphism of ϱ, if for all
a1, . . . , an ∈Dm holds
a1, . . . , an ∈ϱ =⇒f(a1, . . . , an) ∈ϱ,
or equivalently, if f(ϱ) ⊆ϱ. With pres we denote the deﬁning relation
pres := {(f, ϱ) ∈OD × RD | f preserves ϱ}.
Based on this relation pres, we deﬁne a Galois connection Inv D – Pol D by
Inv D : P OD →P RD,
F →{ϱ ∈RD | (∀f ∈F) f pres ϱ}
Pol D : P RD →P OD,
Γ0 →{f ∈OD | (∀ϱ ∈Γ0) f pres ϱ}.
As long as the basic set D is ﬁxed, we suppress the index D.
⊓⊔
Examples
– Let D = {0, 1}. Then the relation ≤(= {(0, 0), (0, 1), (1, 1)}) is invariant for
f iﬀf is monotone, Pol {≤} is the set of all monotone Boolean functions.
– Let ∆D = {(a, a) | a ∈D} denote the equality relation on D. Every function
f ∈OD preserves ∆D, Pol {∆D} = OD.
– Let Co ∆D = {(a, b) ∈D2 | a ̸= b} be the inequality relation on D. If
D = {0, 1}, then Pol {Co ∆D} is the set of all selfdual Boolean functions, i.e.
functions satisfying f(x1, . . . , xn) = f(x1, . . . , xn) for all (x1, . . . , xn) ∈Dn.
An example of such a function is the ternary function x1 ⊕x2 ⊕x3. (Here ⊕
denotes addition modulo 2.)
But if |D| ≥3, then Pol D{Co ∆D} consists only of functions f of the form
f(x1, . . . , xn) = π(xi), where 1 ≤i ≤n and π is a permutation.
Now we are going to characterize the Galois connection, i.e. we want to describe
the Galois closed sets of functions and relations. We have to introduce certain
operations on functions and on relations.
Clones of Functions on D
The elementary functions or projections on D are the functions
en
i,D : Dn →D,
(a1, a2, . . . , an) →ai (with 1 ≤i ≤n).
The set of all elementary functions on D is denoted by
JD := {en
i,D | i, n ∈N+ and 1 ≤i ≤n}.
If D is ﬁxed, then we write en
i instead of en
i,D.
Let f ∈O(n)
D and g1, . . . , gn ∈O(m)
D
be functions on D. Then the superposition
of f and g1, . . . , gn is the m-ary function
f[g1, . . . , gn] : Dm →D,
(a1, . . . , am) →f(g1(a1, . . . , am), . . . , gn(a1, . . . , am)).

46
F. B¨orner
Deﬁnition 2.2. A set C ⊆OD is called a clone of functions on D, if C contains
all elementary functions en
i and if C is closed under superposition, i.e. if f ∈
C(n), g1, . . . , gn ∈C(m) then always f[g1, . . . , gn] ∈C. The set of all clones of
functions on D is denoted by LOD.
If F ⊆OD is a set of functions, then
clone F :=

{C ⊆OD | C is a clone and F ⊆C}
denotes the clone, generated by F. (This is the least clone that contains F.)
⊓⊔
Examples of clones are the set OD of all functions on D, the set JD of all
elementary functions, or the set of all monotone Boolean functions on the two-
element set D = {0, 1}.
We mention that clone is an algebraic closure operator on OD, and LOD is
the corresponding algebraic lattice. We can obtain clone F also in the following
way: Let C0 := F ∪JD and
Ck+1 := Ck ∪{f[g1, . . . , gn] | (∃n, m ∈N+)f ∈F (n), g1, . . . , gn ∈C(m)
k
},
then clone F =
∞

k=0
Ck.
In the Boolean case |D| = 2 there are countably many clones and the structure
of LOD is completely known by the work of E.L. Post ([23, 24, 25]). Figure 1 on
page 47 shows the structure of this lattice.
But for |D| ≥3 there are continuum many clones on D, and the structure of
LOD is largely unknown.
The ﬁrst interconnection with our G.C. Inv –Pol comes from the facts that
obviously the elementary functions preserve every relation, and that the super-
position f[g1, . . . , gn] preserves a relation ϱ whenever f and g1, . . . , gn preserve
ϱ. This immediately yields:
Corollary 2.3.
1. If Γ0 ⊆RD, then Pol Γ0 is a clone.
2. For all F ⊆OD, cloneF ⊆Pol Inv F; i.e. clone ≤Pol Inv .
Proof. The preceding remarks show that Pol Γ0 is a clone. And F ⊆Pol Inv F
implies clone F ⊆clone Pol Inv F = Pol Inv F.
⊓⊔
Operations on Relations
We turn to the relational side. In order to deﬁne operations on the relations in
RD, we use a ﬁrst–order predicate calculus with logical symbols from the set
Symb := {∃, ∀, ∧, ∨, ¬, =, ̸=, f, t}.
(1)
The symbols f and t are included for technical reasons; f is a formula that is
always false and t stands for the always true formula.
Let S be a list of logical symbols from Symb. With Φ(S) we denote the set
of all ﬁrst–order formulas that contain (besides variables, predicate symbols and
brackets) only logical symbols from the list S.

Basics of Galois Connections
47
OD
JD
Fig. 1. Post’s Lattice of all Clones on D = {0, 1}
Now let ϕ = ϕ(P1, . . . , Pk; x1, . . . , xm) be a ﬁrst–order formula with pred-
icate symbols Pi of arity mi, and with free variables among x1, . . . , xm. (We
always assume that the number m of free variables assigned to ϕ is known. It
is not necessary that all variables explicitly occur in ϕ.) If ϕ holds in the model
⟨D; σ1, . . . , σk; a1, . . . , am⟩, then we denote this by |= ϕD(σ1, . . . , σk; a1, . . . , am).
In the following we will use instead of the predicate symbols Pi mostly the
symbols σi or ϱi for the relations (predicates) itself in our formulas ϕ. Moreover,
we also allow y, z, yj, . . . to occur as variable symbols in our formulas.
To ϕ we assign a logical operation Lϕ (= Lϕ,m) by
Lϕ : R(m1)
D
× · · · × R(mk)
D
→R(m)
D
(σ1, . . . , σk) →{(a1, . . . , am) ∈Am ||= ϕD(σ1, . . . , σk; a1, . . . , am)}
Some Examples and Deﬁnitions
– Φ(∅) contains all formulas of the form σ(xi1, . . . , xin).
– Φ(∃, ∧, =) consists of all primitive positive formulas.
– If ϕ ≡σ1(x1, . . . , xm) ∧σ2(x1, . . . , xm), then Lϕ describes the intersection
of two m-ary relations, Lϕ(σ1, σ2) = σ1 ∩σ2.
– For the formula f (considered with m free variables) we obtain as Lf the
(m-ary) empty relation Lf = ∅(m) ∈R(m)
D .
Similarly, the formula t (considered with m free variables) describes the full
relation Lt = Dm ∈R(m)
D .

48
F. B¨orner
– If ϕ ≡(x1 = x2), then Lϕ is the binary equality relation ∆D on D.
– If ϕ ≡(∃xm+1)σ(x1, . . . , xm, xm+1), then the logical operation Lϕ describes
the projection of an (m + 1)-ary relation σ to its ﬁrst m components.
Lϕ = Pr(m) : R(m+1)
D
→R(m)
D , σ →{a ∈Dm | (∃am+1) σ(a, am+1)}
– The formula ϕ ≡¬σ(x1, . . . , xm) deﬁnes the complement of an m-ary rela-
tion,
Lϕ(σ) = Co σ := Dm \ σ = {a ∈Dm | ¬σ(a)}.
Each set of logical operations deﬁnes an algebraic closure operator on RD.
Deﬁnition 2.4. Let S be a list of logical symbols from the set Symb (see Eq. (1))
and let Γ ⊆RD. We say that Γ is S–closed, if Γ is closed under all logical
operations Lϕ with ϕ ∈Φ(S).
If Γ0 ⊆RD, then the S–closed set of relations, generated by Γ0 is denoted
with

Γ0

S :=

{Γ ⊆RD | Γ0 ⊆Γ and Γ is S–closed }.
A set Γ ⊆RD is called a relational clone if Γ is ∃, ∧, =, f–closed.
Γ relational clone : ⇐⇒

Γ

∃,∧,=,f = Γ
The set of all relational clones ist denoted by LRD.
For Γ0 ⊆RD we call

Γ0

∃,∧,=,f the relational clone, generated by Γ0.
⊓⊔
Clearly, the operator
 
S : Γ0 →

Γ0

S is an algebraic closure operator and if
S = ∃, ∧, =, f, then LRD is the corresponding algebraic lattice.
By Deﬁnition 2.4, a set Γ is a relational clone iﬀ
– Γ contains the empty relations ∅(m) and the equality relation ∆D.
– Γ is closed under intersections  of m–ary relations.
– Γ is closed under projections Pr(m).
– Γ is closed under rearrangements of arguments, i.e. under operations Lϕ :
R(m)
D
→R(k)
D where ϕ ≡σ(xs(1), . . . , xs(m)) for some function
s : {1, . . . , m} →{1, . . ., k}.
In particular this implies that the full relations Dm also belong to every relational
clone on D.
It is not diﬃcult to see that the equality relation ∆D, the empty relations ∅(m)
and the full relations Dm are invariant for all functions in OD. If ϱ1, ϱ2 ∈R(m)
D
are both invariant for a function f ∈OD, then the intersection ϱ1 ∩ϱ2 is also
invariant for f. Moreover, if ϱ is an (m+1)-ary invariant relation for f, then the
projection Pr(m)ϱ is also invariant for f.
Corollary 2.5.
1. If F ⊆OD, then Inv F is a relational clone.
2. For all Γ0 ⊆RD,

Γ0

∃,∧,=,f ⊆Inv Pol Γ0, i.e.
 
∃,∧,=,f ≤Inv Pol .
Proof. The preceding remarks imply the ﬁrst statement. And Γ0 ⊆Inv Pol Γ0
implies

Γ0

∃,∧,=,f ⊆

Inv Pol Γ0

∃,∧,=,f = Inv Pol Γ0.
⊓⊔
Now we want to prove that (for ﬁnite D) the clones of functions and the relational
clones are always Galois closed.

Basics of Galois Connections
49
The Characterization of Inv –Pol
First we deﬁne an important technical tool.
Deﬁnition 2.6. Let Γ ⊆RD and ϱ ∈R(m)
D . We deﬁne
µΓ (ϱ) :=

{σ ∈Γ (m) | ϱ ⊆σ}.
(If the set of relations on the right side is empty, then we put µΓ (ϱ) = Dm.)
If a1, a2, . . . , ak ∈Dm then we write µΓ (a1, a2, . . . , ak) instead of µΓ ({a1,
a2, . . . , ak}).
⊓⊔
Lemma 2.7.
1. Let Γ ⊆RD such that for all m ∈N+ the set Γ (m) is closed
under the intersection of m–ary relations and Dm ∈Γ (m). Then ϱ ⊆µΓ (ϱ) ∈
Γ for all ϱ ∈RD and ϱ ∈Γ ⇐⇒ϱ = µΓ (ϱ).
2. Let F ⊆OD and a1, . . . , an ∈O(m)
D . Then
µInv F (a1, . . . , an) = {f(a1, . . . , an) | f ∈clone(n)F}.
Proof. (1.) is obvious. In order to see (2.) note that Γ = Inv F satisﬁes the
assumptions of (1.) (Lemma 2.5) and therefore µInv F (a1, . . . , an) is the smallest
m-ary relation in Inv F that contains a1, . . . , an. Such a relation must contain
all f(a1, . . . , an) with f ∈clone(n)F. It is easy to see that the relation on the
right side is also invariant for the functions in F. Therefore on both sides of the
equation stands the least relation which contains a1, a2, . . . , an and is invariant
for all functions from F.
⊓⊔
We still need a special relation for the characterization.
Deﬁnition 2.8. Let n ∈N+. We deﬁne a relation χn,D on D with ar(χn,D) =
|D|n and |χn,D| = n. Let k = |D|n and let c1, . . . , cn ∈Dk be k-tuples such that
for i = 1 . . . k the n-tuple (c1(i), . . . , cn(i)) runs through all k elements of Dn in
a lexicographic order. Then we put χn,D := {c1, . . . , cn}.
⊓⊔
Now we are able to give a characterization for the closure operator Pol Inv .
Theorem 2.9. Let D be a ﬁnite basic set.
1. A subset C ⊆OD is Galois closed for the G.C. Inv –Pol , (i.e. C = Pol Inv C)
if and only if C is a clone of functions.
2. For all F ⊆OD, cloneF = Pol Inv F.
Proof. It suﬃces to prove (2.). Because of 2.3 we only have to prove Pol Inv F ⊆
clone F. Let g ∈Pol (n) Inv F. Then g has to preserve the relation µInv F (χn,D) ∈
Inv F. Because of χn,D = {c1, . . . , cn} it follows from 2.7 that
g(c1, . . . , cn) ∈µInv F (c1, . . . , cn) = {f(c1, . . . , cn) | f ∈clone(n)F}.
Consequently g(c1, . . . , cn) = f(c1, . . . , cn) for some f ∈clone(n)F. Therefore
g(c1(i), . . . , cn(i)) = f(c1(i), . . . , cn(i)) for all i = 1 . . . |D|n. But the n-tuples
(c1(i), . . . , cn(i)) run through all possible n-tuples in Dn, so g = f ∈cloneF.
⊓⊔

50
F. B¨orner
The characterization of the Galois closed relation sets is a bit more diﬃcult. The
crucial point in the proof is the following:
Lemma 2.10. Let Γ ⊆RD be a relational clone and let a1, . . . , an ∈Dm. Then
µΓ (a1, . . . , an) = {f(a1, . . . , an) | f ∈Pol (n)Γ}.
Proof. The inclusion ⊇is clear, because Γ is closed under intersection and con-
tains the relations Dm, therefore by 2.7 µΓ (a1, . . . , an) ∈Γ and every f ∈Pol Γ
has to preserve µΓ (a1, . . . , an).
It remains to prove the other inclusion ⊆. For each b ∈µΓ (a1, . . . , an) we
must ﬁnd an f ∈Pol Γ with b = f(a1, . . . , an).
First we prove that this is true for the elements c1, . . . , cn of χn,D with
ar(χn,D) = k := |D|n. Let d ∈µΓ (c1, . . . , cn). We deﬁne a function gd by
gd(c1(i), . . . , cn(i)) = d(i) for all i with 1≤i≤k. Then we have d=gd(c1, . . . , cn)
and we want to show that gd ∈Pol Γ. Assume that this is not true. Then there
exist r ∈N+, σ ∈Γ (r) and a′
1, . . . , a′
n ∈σ with gd(a′
1, . . . , a′
n) /∈σ. Now for
all j with 1 ≤j ≤r there exists s(j) ∈{1, . . . , k} with (a′
1(j), . . . , a′
n(j)) =
(c1(s(j)), . . . , cn(s(j))). Let γ be the relation
γ := {(c′
1, . . . , c′
k) ∈Dk | σ(c′
s(1), . . . , c′
s(r))}.
The relation γ is deﬁned from σ by the formula σ(xs(1), . . . , xs(r)) ∈Φ(∃, ∧, =, f),
therefore γ ∈Γ. Moreover, c1, . . . , cn ∈γ, consequently µΓ (c1, . . . , cn) ⊆γ. But
d /∈γ, and this contradicts d ∈µΓ (c1, . . . , cn). Consequently gd ∈Pol Γ.
Now we turn to the general case b ∈µΓ (a1, . . . , an). Again, for all j with
1 ≤j ≤m there exists s(j) with 1 ≤s(j) ≤k such that (a1(j), . . . , an(j)) =
(c1(s(j)), . . . , cn(s(j))). Consider the formula
ϕ(µ; x1, . . . , xm) : ⇐⇒(∃y1) · · · (∃yk)( µ(y1, . . . , yk) ∧
m
	
j=1
xj = ys(j) ).
Then ϕ ∈Φ(∃, ∧, =, f) and therefore Lϕ(µΓ (c1, . . . , cn)) ∈Γ. Moreover, a1, . . . ,
an ∈Lϕ(µΓ (c1, . . . , cn)) and so µΓ (a1, . . . , an) ⊆Lϕ(µΓ (c1, . . . , cn)). Then
b ∈µΓ (a1, . . . , an) implies b ∈Lϕ(µΓ (c1, . . . , cn)), hence there exists d ∈
µΓ (c1, . . . , cn) with b(j) = d(s(j)) for all j = 1 . . . m. But then b = gd(a1, . . . ,
an), and because of gd ∈Pol Γ the proof is ﬁnished.
⊓⊔
Now the characterization Theorem follows from 2.5, 2.10 and the general Theo-
rem 5.3 that we prove a bit later.
Theorem 2.11. Let D be a ﬁnite basic set.
1. A subset Γ ⊆RD is Galois closed for the G.C. Inv –Pol , (i.e. Γ = Inv Pol Γ)
if and only if Γ is a relational clone.
2. For all Γ0 ⊆RD,

Γ0

∃,∧,=,f = Inv Pol Γ0; i.e.
 
∃,∧,=,f = Inv Pol .
⊓⊔
An immediate consequence of 1.7, 2.9 and 2.11 is the following

Basics of Galois Connections
51
Corollary 2.12. The lattice CPol Inv
OD
of all Galois closed function sets coincides
with the lattice LOD of all clones on D. The lattice CInv Pol
RD
of all Galois closed
relation sets coincides with the lattice LRD of all relational clones on D.
These lattices are dually isomorphic, the dual isomorphisms are the operators
Inv and Pol .
⊓⊔
Figure 2 on page 51 illustrates this interconnection. (WD denotes the least
relational clone on D, WD =

∅

∃,∧,=,f = Inv OD.) Consequently, Post’s lattice
of all clones on D = {0, 1} in Fig. 1 on page 47 also describes the structure of
the lattice of all relational clones on D, if we turn it around.
Inv –Pol
JD
Lattice of the relational clones
Lattice of the clones of functions
WD
RD
OD
Fig. 2. Interconnection between clones of functions and relational clones
3
An Application to the CSP
Constraint Satisfaction Problems have a wide range of applications and so the
study of their algorithmic complexity is of some importance. In the last decade,
P. Jeavons and others discovered an interconnection between these complexity
theoretic questions and the theory of clones ([11, 14, 15]). The link between these
ﬁelds is the Galois connection Inv – Pol . In this section we want to give a short
insight into the starting idea. We start with a (slightly simpliﬁed) deﬁnition of
the Constraint Satisfaction Problems.
Deﬁnition 3.1. Let D be a ﬁnite basic set and let Γ0 ⊆RD be a ﬁnite set of
relations. Then the Constraint Satisfaction Problem on Γ0, denoted by CSP(Γ0),
is the following decision problem:
Input: A sentence of the form
(∃x1) . . . (∃xn) (ϱ1(xi1,1, . . .) ∧. . . ∧ϱm(xim,1, . . .) ),

52
F. B¨orner
where the ϱj are (symbols for the) relations ϱj ∈Γ0 and the indices is,t are
in {1, . . ., n}.
Problem: Is this sentence true?
(The relations ϱj ∈Γ0 are also called the constraints of the problem.)
⊓⊔
Let Γ1 = {σ1, . . . σk} ⊆RD and Γ2 = {ϱ1, . . . , ϱn} ⊆RD be two ﬁnite sets
of relations with Γ1 ⊆

Γ2

∃,∧,=,f. Then for each nonempty relation σj ∈Γ1
there exists a formula ϕj ∈Φ(∃, ∧, =) such that σj = Lϕ(ϱ1, . . . , ϱn). If an
instance of CSP(Γ1) is given, then the relation symbols σj in this input sentence
can be replaced by the formulas ϕj(ϱ1, . . . , ϱn). Then the equality signs can be
removed, the new sentence can be converted into prenex normal form, and we
obtain an instance of CSP(Γ2). It was shown in [15] that this reduction can be
done in polynomial time. Consequently, CSP(Γ1) is polynomially time reducible
to CSP(Γ2).
Now we can apply our Galois connection: Because of Theorem 2.11 we have

Γ2

∃,∧,=,f = Inv Pol Γ2 and therefore Γ1 ⊆

Γ2

∃,∧,=,f is equivalent with Γ1 ⊆
Inv Pol Γ2, and this is equivalent with Pol Γ2 ⊆Pol Γ1 (1.4). This yields the
following Theorem.
Theorem 3.2. ([15]) Let Γ1, Γ2 ⊆RD be ﬁnite sets of relations. If Pol Γ2 ⊆
Pol Γ1, then CSP(Γ1) is polynomially time reducible to CSP(Γ2). If Pol Γ2 =
Pol Γ1, then CSP(Γ1) and CSP(Γ2), are polynomially time equivalent.
⊓⊔
Consequently, the complexity of CSP(Γ0) is (modulo polynomial time equiva-
lence) in some sense determined by the clone Pol (Γ0).
The interconnection between CSP(Γ0) and Pol Γ0 has further consequences.
It is known that CSP(Γ0) is NP–complete if

Γ0

∃,∧,=,f = RD. This is the case
if Pol Γ0 = Pol RD = JD, the least clone in LOD. But if

Γ0

∃,∧,=,f ̸= RD,
then Pol Γ0 ̸= JD. Now it is well known that the clone lattice LOD is atomic
with ﬁnitely many atoms – the so called minimal clones. These minimal clones
must be generated by a single function. At present there is no exact general
classiﬁcation of the minimal clones, except for some small values of |D|. But a
beautiful Theorem of I.G. Rosenberg ([30]) gives a list of functions such that all
minimal clones are generated by a function from this list.
If Pol Γ0 ̸= JD, then Pol Γ0 must contain a minimal clone and therefore also
one of the functions f from Rosenberg’s list. But then f is a polymorphism for
all relations in Γ0. Very often this knowledge helps to ﬁnd algorithms to solve the
CSP(Γ0). To give a trivial example: If Pol Γ0 contains a constant function with
the constant value c, then every relation ϱ ∈Γ0 is preserved by this function,
and for ϱ ̸= ∅this means (c, c, . . . , c) ∈ϱ. But then all instances of CSP(Γ0) are
trivially true, provided that ∅/∈Γ0.
So the lattice structure of LOD is of some interest for the CSP. In the Boolean
case D = {0, 1} there are 7 minimal clones (see Fig. 1), generated by the func-
tions 0, 1, ∧, ∨, x ⊕y ⊕z, xy ∨xz ∨yz and the negation x. It can be shown
(see [15]) that CSP(Γ0) is in PTIME whenever Pol Γ0 contains one of the ﬁrst
6 functions. Post’s lattice shows that this is true for all clones on D, with the

Basics of Galois Connections
53
exceptions JD and clone{x}. If Pol Γ0 is one of these 2 clones, then CSP(Γ0) is
NP-complete. (This “dichotomy result” was already obtained by Schaefer in [33]
with other combinatorial methods. But these methods are diﬃcult to generalize
to the case |D| ≥3.)
The “algebraic” interconnection between clones and the CSP has provided a
lot of strong complexity theoretical results, also in the general case, we refer to
[14, 15, 10].
4
The Galois Connection Inv –mPol
We want to describe more closure operators on sets of relations with the help
of Galois connections. Therefore we ﬁrst generalize our concept of functions, in
order to have a general starting point for the next investigations.
Notions and Notations
An n-ary multifunction on the basic set D is a function f
:
Dn →P D.
The set of all n-ary multifunctions on D is denoted with M(n)
D
and the set of
all ﬁnitary multifunctions is MD :=
∞

n=1
M(n)
D . For a subset F ⊆MD we put
F (n) := F ∩M(n)
D .
The domain dom f of a multifunction is the set
dom f := {a ∈Dn | f(a) ̸= ∅}.
If dom f = Dn, then f is called total. The set of all total multifunctions is
denoted by tMD.
Remark. These multifunctions appear under various names, e.g. multiopera-
tions, correspondences etc. In [32, 27], they are called partial hyperfunctions,
and the total multifunctions are called hyperfunctions.
If g, f ∈M(n)
D
such that g(a) ⊆f(a) for all a ∈Dn, then g is called a submul-
tifunction of f and we write g ⊆f. If F ⊆MD, then ⇓F (“down F”) denotes
the set of all submultifunctions of multifunctions in F.
⇓F := {g ∈MD | (∃f ∈F)g ⊆f}
Clearly, ⇓is a closure operator. A set F with ⇓F = F is called down closed or
strong. If M ⊆MD, then we call a subset F ⊆M M–strong if F = M∩⇓F.
We can assign to each “ordinary” function g ∈O(n)
D
a total multifunction
g : Dn →P D, a →{g(a)}.
For G ⊆OD we put G := {g | g ∈G}. In this sense we sometimes identify OD
with the subset 
OD of tMD.

54
F. B¨orner
Similar as for functions, we can extend a multifunction f : Dn →P D to a
multifunction on Dm, f : (Dm)n →P Dm by
f(a1, . . . an) := f(a1(1), . . . , an(1)) × · · · × f(a1(m), . . . , an(m)).
(If (a1(i), . . . , an(i)) /∈dom f for some i ∈{1, . . . , m}, then f(a1, . . . an) = ∅.)
For ϱ ∈RD we put f(ϱ) := {f(a1, . . . an) | a1, . . . , an ∈ϱ}.
Now we extend our deﬁning relation pres ⊆OD ×RD to a relation mpres ⊆
MD × RD between multifunctions and relations. Then this extended relation
again deﬁnes a Galois connection. Here the sets MD and RD play the role of X
and Y in Section 1.
Deﬁnition 4.1. Let f ∈M(n)
D
and ϱ ∈R(m)
D . We say that f preserves ϱ, or
that ϱ is an invariant relation for f, or that f is a multi-polymorphism of ϱ, if
for all a1, . . . , an inDm holds
a1, . . . , an ∈ϱ =⇒f(a1, . . . , an) ⊆ϱ,
or equivalently, if f(ϱ) ⊆ϱ. With mpres we denote the deﬁning relation
mpres := {(f, ϱ) ∈MD × RD | f preserves ϱ}.
Based on this relation mpres, we deﬁne a Galois connection Inv D – mPol D
by
Inv D : P MD →P RD,
F →{ϱ ∈RD | (∀f ∈F) f mpres ϱ}
mPol D : P RD →P MD,
Γ0 →{f ∈MD | (∀ϱ ∈Γ0) f mpres ϱ}.
(As long as the basic set D is ﬁxed, we suppress the index D.)
⊓⊔
For the characterization of this G.C. we mainly follow the lines of the proofs in
Section 2. First we need the notion of a clone of multifunctions.
Clones of Multifunctions on D
The elementary multifunctions are the functions
en
i
: Dn →D, (a1, . . . , an) →{ai}.

JD is the set of all elementary multifunctions.
The superposition of multifunctions f ∈M(n)
D , g1, . . . , gn ∈M(m)
D
is the mul-
tifunction
f[g1, . . . , gn] : Dm →P D
a →

{f(b1, . . . , bn) | bi ∈gi(a) for i = 1 . . . n}.
This notion is a generalization of the superposition of ordinary functions. If
f, g1, . . . , gn are in OD, then f[g1, . . . .gn] =

f[g1, . . . , gn].

Basics of Galois Connections
55
Deﬁnition 4.2. A set C ⊆MD is called a clone of multifunctions on D, if C
contains all elementary multifunctions en
i and if C is closed under superposition,
i.e. if f ∈C(n), g1, . . . , gn ∈C(m), then also f[g1, . . . , gn] ∈C.
If F ⊆MD, then
cloneF :=

{C ⊆MD | C is a clone and F ⊆C}
denotes the clone, generated by F. This is the least clone of multifunctions on
D that contains F.
⊓⊔
The sets 
JD, 
OD, MD, tMD are examples of clones of multifunctions. Moreover,
C ⊆OD is a clone of functions iﬀC is a clone of multifunctions. The lattice of
all clones of multifunctions is uncountable, even in the case |D| = 2. The same
holds for the sublattice of all clones of total multifunctions.
The superposition of multifunctions is monotone with respect to ⊆. If f ′ ⊆f
and g′
i ⊆gi, then f ′[g′
1, . . . , g′
n] ⊆f[g1, . . . , gn]. Therefore, if C is a clone of
multifunctions, then ⇓C is also a clone. A clone C of multifunctions with ⇓C =
C is called a strong clone or a down closed clone.
The set of all strong clones on D also forms an algebraic lattice. We denote this
lattice with LMD. The meet in this lattice is just the set theoretical intersection
while the join of two strong clones is given by C1 ∨C2 =⇓clone(C1 ∪C2).
The elementary multifunctions preserve every relation. If f, g1, . . . , gn preserve
a relation ϱ, then ϱ is also invariant under f[g1, . . . , gn]. Therefore mPol Γ0 is
always a clone. Moreover, if f preserves ϱ and g ⊆f, then g also preserves ϱ.
We obtain:
Corollary 4.3. If Γ0 ⊆RD, then mPol Γ0 is a ⇓-closed clone of multifunctions,
⇓clone mPol Γ0 = mPol Γ0. Therefore ⇓clone F ⊆mPol Inv F for all F ⊆MD,
i.e. ⇓clone ≤mPol Inv .
⊓⊔
Weak Systems of Relations
The sets Inv F with F ⊆MD are in general not closed under projections, and do
not contain the equality relation. But it is easy to see that Inv F is closed under
intersection of m-ary relations and contains the empty and the full relations.
Deﬁnition 4.4. A set Γ ⊆RD is called a weak system with zero, if Γ is ∧, f, t–
closed, i.e. if Γ =

Γ

∧,t,f. If Γ0 ⊆RD, then

Γ0

∧,t,f is the weak system with
zero, generated by Γ0.
⊓⊔
(A weak system is a set Γ ⊆RD with Γ =

Γ

∧,t.)
Corollary 4.5. If F ⊆MD then Inv F is a weak system with zero,

Inv F

∧,t,f =
Inv F. Therefore

Γ0

∧,t,f ⊆Inv mPol Γ0 for all Γ0 ⊆RD, i.e.
 
∧,t,f ≤
Inv mPol .
⊓⊔
The Characterization of Inv –mPol
The following statements correspond to 2.7 and 2.10.

56
F. B¨orner
Lemma 4.6. Let a1, . . . , an ∈Dm.
1. For all F ⊆MD holds
µInv F (a1, . . . , an) =

{f(a1, . . . , an) | f ∈clone(n)F}.
2. Let Γ0 ⊆RD and Γ =

Γ0

∧,t,f. Then
µΓ (a1, . . . , an) =

{f(a1, . . . , an) | f ∈mPol (n)Γ}.
Proof.
1. The proof is analogous to the proof of 2.7(2.). Both sides of the equa-
tion describe the least relation containing a1, . . . , an which is invariant for
all functions in F.
2. “⊇” is clear: Γ is closed under intersection, therefore µΓ (a1, . . . , an) ∈Γ
and so the multifunctions in mPol Γ preserve µΓ (a1, . . . , an).
“⊆”: Let b ∈µΓ (a1, . . . , an). We claim b ∈f(a1, . . . , an) for some f ∈
mPol (n) Γ. We deﬁne a multifunction gb : Dn →P D by
gb(a1, . . . , an) := {b(i) | 1 ≤i ≤m and (a1(i), . . . , an(i)) = (a1, . . . , an)}.
Then b ∈gb(a1, . . . , an). Assume gb /∈mPol (n) Γ. Then there exists k,
σ ∈Γ (k), c1, . . . , cn ∈σ and d ∈gb(c1, . . . , cn) with d /∈σ. Then for each j
with 1 ≤j ≤k there is a number s(j) with 1 ≤s(j) ≤m such that
(c1(j), . . . , cn(j), d(j)) = (a1(s(j)), . . . , an(s(j)), b(s(j))).
Now consider the formula ϕ(x1, . . . , m; σ) : ⇐⇒σ(xs(1), . . . , xs(k)). This for-
mula is in Φ(∧, f, t), therefore Lϕ(σ) ∈Γ. Now a1, . . . , an ∈Lϕ(σ), therefore
µΓ (a1, . . . , an) ⊆Lϕ(σ). But d /∈σ implies b /∈Lϕ(σ) – a contradiction.
This shows gb ∈mPol Γ and ﬁnishes the proof.
⊓⊔
Now we can give the characterizations for mPol Inv and Inv mPol . The proof of
4.7 is similar to the proof 2.9 and we skip it here. Theorem 4.8 follows from 4.6
and Theorem 5.3.
Theorem 4.7. Let D be a ﬁnite basic set.
1. A subset C ⊆MD is Galois closed for the G.C. Inv –mPol , (i.e. C =
mPol Inv C) if and only if C is a ⇓-closed clone of multifunctions.
2. For all F ⊆MD, ⇓clone F = mPol Inv F.
⊓⊔
Theorem 4.8. Let D be a ﬁnite basic set.
1. A subset Γ ⊆RD is Galois closed for the G.C. Inv –mPol , (i.e. Γ=Inv mPol Γ)
if and only if Γ is a weak system with zero.
2. For all Γ0 ⊆RD,

Γ0

∧,t,f = Inv mPol Γ0.
⊓⊔

Basics of Galois Connections
57
5
Derived Galois Connections
In this section we want to generate more Galois connections in order to describe
other closure operators on sets of relations. We start with the general connection
Inv – mPol and then we restrict the set MD of multifunctions to various subsets
M. Theorem 1.8 ensures that we obtain new Galois connections.
We choose a restriction set M ⊆MD and consider the operators
Inv : P M →P RD,
F →Inv F
and
M-mPol : P RD →P M,
Γ0 →M ∩mPol Γ0.
The deﬁning relation for this G.C. is ΞM = {(f, ϱ) ∈M × RD | f mpres ϱ}.
From Theorems 1.8 and 4.7 we already obtain the description of the Galois closed
subsets of M.
Corollary 5.1. If F ⊆M, then M-mPol Inv F = M∩⇓clone F.
A subset C ⊆M is Galois closed for Inv – M-mPol (i.e. C =M-mPol Inv C)
if and only if C is an M-strong clone of multifunctions, i.e. C = M∩⇓clone C.
⊓⊔
At this point we want to agree on a small inexactness of our notation: If f ∈OD
is an ordinary function, then we identify f with the corresponding multifunction
f even if we do not write the tilde. In this sense we have the inclusions OD ⊆
tMD ⊆MD. We also use this agreement for the following sets:
P(n)
D
:= {f | f : Dn ⊇dom f →D}
PD :=

n∈N+
P(n)
D
(set of all partial functions)
SD := {π | π : D →D is a permutation }
So an n-ary partial function f ∈P(n)
D
is identiﬁed with the multifunction
f : a →

{f(a)} if a ∈dom f
∅
else
.
The set PD corresponds to the set {f ∈MD | (∀a ∈Dar(f))|f(a)| ≤1}, and
OD is the set of all partial functions with dom f = Dn.
For these and other sets M the operators M-mPol have special abbreviations:
pPol := PD- mPol, wAut := SD- mPol, tmPol := tMD- mPol , Pol = OD- mPol ,
End := O(1)
D - mPol .
Please note that every subset C ⊆OD is OD-strong. Therefore an OD-strong
clone C ⊆OD is just a clone. Consequently, for M = OD we reobtain Theo-
rem 2.9 from Corollary 5.1.
Approximating Closure Operators on RD with Galois connections
We want to use these restricted Galois connections to approximate closure ope-
rators H on RD with operators of the form Inv M-mPol and therefore we adapt

58
F. B¨orner
the constructions in 1.10 and 1.11. We assume that H satisﬁes

Γ0

∧,t,f ⊆HΓ0
for all Γ0 ⊆RD, i.e.
 
∧,t,f ≤H. According to 1.10 we have to consider the
approximation set for H:
App(H) = {f ∈MD | H Inv {f} = Inv {f}}.
We collect some properties.
Lemma 5.2.
1. H Inv F = Inv F for all F ⊆App(H).
2. ⇓
JD ⊆App(H)
3. Let H := H1∨H2 denote the least closure operator with H1 ≤H and H2 ≤H.
(This means, the H–closed subsets of RD are exactly the sets that are closed
under H1 and under H2.) Then App(H) = App(H1) ∩App(H2).
4. H ≤Inv M- mPol iﬀM ⊆App(H)
Proof. (1.)–(3.) are immediate from the Deﬁnition. (4.) follows from Theorem 1.11.
⊓⊔
Unless (2.) holds, the approximation sets are usually not clones. So sometimes
instead of M = App(H) one chooses a more convenient proper subset M ⊂
App(H).
It remains to answer the question, under which conditions we can guarantee
the equality H = Inv M-mPol .
Theorem 5.3. Let H : P RD →P RD be a closure operator and M ⊆MD.
Then H = Inv M-mPol if and only if the following three conditions hold.
1. HΓ0 =

HΓ0

∧,t,f for all Γ0 ⊆RD. (I.e. the H–closed relation sets are closed
under intersections and contain the empty and full relations,
 
∧,t,f ≤H.)
2. M ⊆App(H)
3. For all Γ0 ⊆RD and all a1, . . . , an ∈Dm holds
µHΓ0(a1, . . . , an) ⊆

{f(a1, . . . , an) | f ∈clone(n) M-mPol Γ0}
Proof. “⇒” Let H = Inv M-mPol .
1. Because of 4.5 and by 1.4(3) we have
HΓ0 ⊆

HΓ0

∧,t,f ⊆Inv mPol HΓ0 = Inv mPol Inv M-mPol Γ0
= (Inv mPol Inv ) M-mPol Γ0 = Inv M-mPol Γ0 = HΓ0.
2. If f ∈M, then Inv {f} is closed under Inv M-mPol and therefore under H.
3. Because of H = Inv M-mPol and of 4.6(1) we have
µHΓ0(a1, . . . , an) = µInv M- mPol Γ0(a1, . . . , an)
=

{f(a1, . . . , an) | f ∈clone(n) M-mPol Γ0}

Basics of Galois Connections
59
“⇐” Because of 5.2(4) we have HΓ0 ⊆Inv M-mPol Γ0 for all Γ0 ⊆RD. It
remains to show Inv M-mPol Γ0 ⊆HΓ0. Let ϱ ∈Inv M-mPol Γ0. If ϱ = ∅(m)
then (1.) implies ϱ ∈HΓ0.
Otherwise put n := |ϱ| ≥1 and ϱ = {a1, . . . , an}. Let b ∈µHΓ0(ϱ) =
µHΓ0(a1, . . . , an). Then because of (3) we have b ∈f(a1, . . . , an) for some
f ∈clone(n) M-mPol Γ0. The relation ϱ is invariant under all multifunctions
in M-mPol Γ0, therefore it is also invariant for all f ∈clone M-mPol Γ0. Con-
sequently, b ∈ϱ = {a1, . . . , an}. Therefore µHΓ0(ϱ) = ϱ. Because of (1) HΓ0
is closed under intersections, and so µHΓ0(ϱ) = ϱ implies ϱ ∈HΓ0. This shows
Inv M-mPol Γ0 ⊆HΓ0.
⊓⊔
Now we want to discuss some approximation sets for extensions of the closure
operator
 
∧,t,f. Let S1, S2, . . . be a list of logical symbols in Symb (Eq. 1). Then
instead of App(
 
∧,f,t,S1,S2,...) we write App(∧, f, t, S1, S2, . . .).
– Because of ∆D ∈Inv {f} ⇐⇒f ∈mPol {∆D} (see 1.4(2)) we have
App(∧, f, t, =) = mPol ({∆D}). In particular, mPol {∆D} = 
PD, and

Γ0

∧,f,t,= =

Γ0 ∪{∆D}

∧,t,f = Inv mPol (Γ0 ∪{∆D})
= Inv (mPol {∆D} ∩mPol Γ0) = Inv pPolΓ0
holds for all Γ0 ⊆RD.
– Similarly we ﬁnd App(∧, f, t, ̸=) = mPol(Co ∆D) and with
M0 := mPol (Co ∆D) we obtain

Γ0

∧,f,t,̸= = Inv M0- mPol Γ0.
– It is easy to see that M(1)
D ⊆App(∧, f, t, ∨) and that the conditions (1.) and
(2.) of 5.3 are satisﬁed for H =
 
∧,f,t,∨and M = M(1)
D . In order to see
5.3 (3.), note that

Γ0

∧,f,t,∨is closed under union and therefore
µHΓ0(a1, . . . , an) =
n

i=1
µHΓ0(ai).
Then

Γ0

∧,t,f ⊆HΓ0 implies µHΓ0(a) ⊆µ
Γ0

∧,t,f
(a) and by 4.6 (2.) we
have µ
Γ0

∧,t,f
(a) = {f(a) | f ∈mPol (1) Γ0}. Now 5.3 implies H =
Inv mPol (1).
– “¬”: If f ∈App(∧, f, t, ¬), then Inv {f} has to be closed under comple-
mentation, i.e. for all ϱ ∈RD, f mpres ϱ
⇐⇒
f mpres Co ϱ. Clearly
SD ⊆App(∧, f, t, ¬). As we will see below, in this case f even strongly pre-
serves ϱ and it seems to be more natural to use a stronger Galois connection
for the description – see Def. 5.4.
– “∃”: If we add the existential quantiﬁer then tMD ⊆App(∧, f, t, ∃). The
restriction set M = tMD suﬃces to describe the closure operator
 
∧,t,f,∃.
– “∀”: A multifunction f ∈M(n)
D
is called surjective, if 
a∈Dn f(a) = D. We
put
sur-MD := {f ∈MD | f is surjective }.

60
F. B¨orner
It is not hard to see that sur-MD ⊆App(∧, f, t, ∀), and with some eﬀort it
can be shown that this set suﬃces to describe
 
∧,t,f,∀.
– If we add more than one symbol from Symb to our list S, then 5.2 (3.) gives
a hint how to construct a possible approximation set for
 
S. For example,
if we add =, ∃and ∀to ∧, t, f, then the intersection
sur-OD := 
PD ∩tMD ∩sur-MD
of the restriction sets for =, ∃, ∀is a good candidate. (sur-OD corresponds
to the set of all surjective total functions.) It turns out, that this set really
suﬃces to model the corresponding closure operator (see 6.2 and 6.3).
Table 1. Some Galois Connections, derived from Inv – mPol
Restriction Abbreviation
closed sets
closure operator
closed sets
set M
for M ∩mPol of multifunctions
of relations
MD
mPol
strong clones of
⟨Γ0⟩∧,f,t
weak systems
multifunctions
with zero ([4],[28])
tMD
tmPol
strong clones of
˙
Γ0
¸
∃,∧,f,t
weak systems with
total multif.
projections and zero
([32],[27],[6])
PD
pPol
strong clones of
⟨Γ0⟩∧,=,f
weak systems with
partial functions
zero and identity
( [26],[18])
OD
Pol
clones of
˙
Γ0
¸
∃,∧,=,f
relational clones
functions
([2],[3],[20],[13])
The Tables 1 and 2 on pages 60 and 61 give an overview of certain Galois
connections of the form Inv –M-mPol . In Table 2 some Galois connections with
unary restriction sets are listet. The basic set D is always assumed to be ﬁnite.
(For a more general survey, including the inﬁnite case, we refer to [22].) Note that
t ⇐⇒(x = x); so we can omit the t whenever the equality sign = is involved.
Moreover, the word “strong” always means M-strong w.r.t. the appropriate
restriction set M.
A Remark on the Empty Relations
In the deﬁnitions of clones of functions or multifunctions we considered only
(multi)functions with arities greater or equal than 1. This is the reason why
empty relations are always invariant for all (multi)functions under consideration,
and therefore we always have to carry the f-symbol in the description of our
logical closure operators. But it is not diﬃcult to extend the notion of a clone to
a “clone with constants”. In the case of functions, we have to add a set O(0)
D of
nullary functions to OD and we obtain cOD := OD ∪O(0)
D . The nullary functions
are just the constants, i.e. the elements of D. In the deﬁnition of a clone with
constants C ⊆cOD we must extend the superposition to the case f[c1, . . . , cn]

Basics of Galois Connections
61
Table 2. Some Galois Connections, derived from Inv – mPol (1)
Restriction
Abbreviation
closed sets
closure operator
closed sets
set M
for M ∩mPol (1) of multifunctions
of relations
M(1)
D
mPol (1)
strong monoids of
˙
Γ0
¸
∧,∨,f,t
distributive systems
unary multif.
with zero ([6])
tM(1)
D
tmPol (1)
strong monoids of
˙
Γ0
¸
∃,∧,∨,f,t
distributive systems
unar. total multif.
with project. and
zero ([6])
P(1)
D
pPol(1)
strong monoids of
⟨Γ0⟩∧,∨,=,f
distributive systems
unary part. funct.
with zero and
identity ([6])
O(1)
D
End
transformation
˙
Γ0
¸
∃,∧,∨,=,f
weak Krasner
monoids
algebras ([17],[21])
SD
wAut (= Aut
permutation
˙
Γ0
¸
∃,∀,∧,∨,=,̸=
Krasner alge-
if D ﬁnite)
groups
(=
˙
Γ0
¸
∃,∧,¬,=)
bras ([16],[20],[6])
(= f(c1, . . . , cn)), where c1, . . . , cn ∈O(0)
D . And we have to require for a clone
with constants C, that for each c ∈C(0) there exists a unary function cxc ∈C(1)
with constant value cxc(x) = c for all x ∈D. (The usual clones also are clones
with constants – with an empty set of constants.)
The notion of an invariant relation can easily be extended: ϱ is invariant for
a constant c if ϱ(c, c, . . . , c). Then all the deﬁnitions and proofs of section 2
can be extended to this case. We obtain a Galois connection Inv – c- Pol with
Inv c- Pol =
 
∃,∧,=.
Similarly, for multifunctions a constant in M(0)
D
is a unary relation B ⊆D.
(B = ∅is possible.) A relation ϱ ∈R(m)
D
is invariant for such a constant B if
Bm ⊆ϱ. Then, following the same line as before, we obtain a G.C. Inv – c- mPol
with Inv c- mPol =
 
∧,t.
Therefore we also can describe the closure operators
 
∧,t,
 
∃,∧,t,
 
∧,=,
etc. with appropriate Galois connections.
For the Galois connection Inv – c- Pol it follows that Γ ⊆RD is closed under
Inv c- Pol iﬀΓ =

Γ

∃,∧,=. And C ⊆cOD is closed under c- Pol Inv iﬀC is a
clone with constants.
The lattice of all clones with constants on D is uniquely determined by the
lattice LOD of all (usual) clones. If we have a clone with constants C and C(0) ̸=
∅, then C′ := C \ C(0) is an ordinary clone, and C covers C′ in the lattice of all
clones of constants. Vice versa, to an ordinary clone C′ we can add exactly the
set of constants c with cxc ∈C′ to obtain another clone with constants. Figure 3
on page 62 shows the lattice of all clones with constants for the Boolean case.
The white circles denote the additional clones with constants.

62
F. B¨orner
JD
OD
Fig. 3. Post’s lattice, extended to clones with constants
Strongly Invariant Relations
The negation symbol did not occur in the closure operators of Tables 1 and 2.
(But note that for ﬁnite D the Galois closed sets

Γ0

∃,∀,∧,∨,=,̸= for the G.C.
Inv – wAut are also closed under complementation.) We already have noted that
f ∈App(∧, t, ¬) implies
f mpres ϱ ⇐⇒f mpres Co ϱ.
This is a hard restriction to f and therefore, if we want to investigate relational
systems closed under complementation, it is more natural to use another kind
of Galois connections.
We restrict the functional side to the set M(1)
D
of all unary multifunctions.
Superposition then reduces to composition f ◦g with
(f ◦g)(a) =

{f(b) | b ∈g(a)}.
The only elementary multifunction in M(1)
D is e1
1. The set M(1)
D with the operation
◦and unit e1
1 is a monoid.
Deﬁnition 5.4. ([7]) Let f ∈M(1)
D
and ϱ ∈RD. We say that f strongly pre-
serves the relation ϱ, or that ϱ is a strongly invariant relation for f, if f preserves
both, ϱ and its complement Co ϱ. In this case we write f spres ϱ.
f spres ϱ : ⇐⇒f mpres ϱ and f mpres Co ϱ

Basics of Galois Connections
63
Based on the deﬁning relation spres we deﬁne a Galois connection sInv – smEnd:
sInv : P M(1)
D →P RD,
F →{ϱ ∈RD | (∀f ∈F)f spres ϱ}
smEnd : P RD →P M(1)
D ,
Γ0 →{f ∈M(1)
D | (∀ϱ ∈Γ0)f spres ϱ}.
⊓⊔
For unary multifunctions f ∈M(1)
D we can deﬁne a new operation, the involution
f →f −1 ∈M(1)
D by f −1(a) := {b ∈D | a ∈f(b)}.
Lemma 5.5. ([7]) A unary multifunction f strongly preserves a relation ϱ iﬀ
both, f and f −1 preserve ϱ.
⊓⊔
Consequently, smEnd Γ0 is always closed under involution, and sInv F is always
closed under complementation.
Deﬁnition 5.6. A set Γ ⊆RD is called a Boolean system if Γ =

Γ

∧,¬.
A set C ⊆M(1)
D
is a strong involuted monoid if C = ⟨C; ◦, −1, e1
1⟩is an
involuted monoid and C is ⇓-closed, ⇓C = C.
⊓⊔
Now we give the characterization Theorems for the Galois connection sInv–
smEnd. For the proofs we refer to [7].
Theorem 5.7. Let D be a ﬁnite basic set.
1. A subset C ⊆M(1)
D
is Galois closed for the G.C. sInv–smEnd, (i.e. C =
smEnd sInv C) if and only if C is a strong involuted monoid.
2. For all F ⊆M(1)
D , smEnd sInv F is the least strong involuted monoid that
contains F.
3. A subset Γ ⊆RD is Galois closed for the G.C. sInv–smEnd, (i.e. Γ =
sInv smEnd Γ) if and only if Γ is a Boolean system.
4. For all Γ0 ⊆RD,

Γ0

∧,¬ = sInv smEnd Γ0.
⊓⊔
Now we can proceed in the same way as before. If we choose a suitable restriction
set M ⊆M(1)
D then by 1.8 the operator pair
sInv : P M →P RD,
M ⊇F →sInv F
M- smEnd : P RD →P M,
RD ⊇Γ0 →M ∩smEnd Γ0
forms a Galois connection. The Galois closed subsets of M are the restrictions
of strong involuted monoids in M(1)
D to M.
Again we obtain several Galois connections in this way. Here all the Galois
closed relation sets are closed under complementation. Table 3 on page 64 shows
some examples. As restriction sets in Table 3 we choose the following subsets of
M(1)
D :
– The set pPD := {f ∈P(1)
D | f
injective on dom f} of all partial permuta-
tions.
– The set BD := {f ∈M(1)
D
| dom f = D and dom f −1 = D} of all bitotal
multifunctions.
– The set O(1)
D of all unary functions.
– The set SD of all permutations on D.
As before, the word “strong” always means “M-strong”. Again, for the proofs
we refer to [7].

64
F. B¨orner
Table 3. Some Galois Connections, derived from sInv — smEnd
Restriction Abbreviation
closed sets
closure operator
closed sets
set M
for M ∩smEnd
of multifunctions
sInv M- smEnd Γ0
of relations
M(1)
D
smEnd
str. invol. monoids of
˙
Γ0
¸
∧,¬
Boolean
unary multifunctions
systems
pPD
spmEnd
str. invol. monoids
˙
Γ0
¸
∧,¬,=
Boolean systems
of unar. part. perm.
with identity
BD
sbmEnd
str. invol. monoids
˙
Γ0
¸
∃,∧,¬
Boolean systems
of bitotal unar. multif.
with projections
O(1)
D
sEnd
special monoids of
˙
Γ0
¸
∃,∧,¬
Boolean systems
transformations
with projections
SD
Aut
permutation
˙
Γ0
¸
∃,∧,¬,=
Krasner
groups
algebras
6
The QCSP and Surjectively Generated Clones
The Quantiﬁed Constraint Satisfaction Problem is a generalization of the CSP
(Def. 3.1). Besides existential quantiﬁcation we also allow universal quantiﬁca-
tion in our input sentences.
Deﬁnition 6.1. Let D be a ﬁnite basic set and let Γ0 ⊆RA be a ﬁnite set of
relations. Then the Quantiﬁed Constraint Satisfaction Problem on Γ0, denoted
by QCSP(Γ0), is the following decision problem:
Input: A sentence of the form
(Q1x1) . . . (Qnxn) (ϱ1(xi1,1, . . .) ∧. . . ∧ϱm(xim,1, . . .) )
where the ϱj are (symbols for the) relations ϱj ∈Γ0, the indices is,t are in
{1, . . . , n} and the Ql are quantiﬁers from the set {∃, ∀}.
Problem: Is this sentence true?
⊓⊔
We want to treat this problem in a similar way as in the case of the CSP in
Section 3. So let Γ1 = {σ1, . . . σk} ⊆RD and Γ2 = {ϱ1, . . . , ϱn} ⊆RD be two
ﬁnite sets of relations with Γ1 ⊆

Γ2

∃,∀,∧,=,f. Then for each nonempty relation
σj ∈Γ1 there exists a formula ϕj ∈Φ(∃, ∀, ∧, =) such that σj = Lϕ(ϱ1, . . . , ϱn).
If an instance of QCSP(Γ1) is given, then the relation symbols σj in this in-
put sentence can be replaced by the formulas ϕj(ϱ1, . . . , ϱn). Then the equality
signs can be omitted and the new sentence can be converted into prenex nor-
mal form, and we obtain an instance of QCSP(Γ2). Again it was shown (in [8])
that this reduction can be done in polynomial time. Consequently, QCSP(Γ1) is
polynomially time reducible to QCSP(Γ2).
Now we want to proceed as in Section 3. But then we need a Galois connection
that describes the closure operator
 
∃,∀,∧,=,f. If possible, this should be a
G.C., derived from Inv – Pol . So we are looking for a subset M ⊆OD with

Basics of Galois Connections
65
 
∃,∀,∧,=,f = Inv M- Pol . Because of 1.11(2.), the subset M must satisfy M ⊆
App(∃, ∀, ∧, =, f). The discussion of the approximation sets in Section 5 shows
that the set M = sur-OD of all surjective functions on D is a candidate for the
restriction set. Because of 1.11 this choice guarantees
 
∃,∀,∧,=,f ≤Inv M- Pol .
But to ensure the equality, we have to investigate whether the conditions (1)–(3)
of Theorem 5.3 are satisﬁed. Obviously, the conditions (1) and (2) of 5.3 are true
for H =
 
∃,∀,∧,=,f and M = sur-OD. The diﬃcult part is condition (3).
Lemma 6.2. ([8]) Let Γ0 ⊆RD and a1, . . . , an ∈Dm. Then
µ
Γ0

∃,∀,∧,=,f
(a1, . . . , an) ⊆{f(a1, . . . , an) | f ∈sur-OD ∩Pol Γ0}.
⊓⊔
Consequently, condition (3) of Theorem 5.3 is also satisﬁed and as a consequence
we obtain the following result.
Theorem 6.3. Let sPol denote the operator sur-OD- Pol , i.e.
sPol : P RD →P sur-OD, Γ0 →sur-OD ∩Pol Γ0.
Then the pair Inv
: P sur-OD →P RD and sPol forms a Galois connection.
For all Γ0 ⊆RD holds Inv sPol Γ0 =

Γ0

∃,∀,∧,=,f.
⊓⊔
Now we obtain an analogue to Theorem 3.2.
JD
OD
Fig. 4. The lattice of all surjectively generated clones for |D| = 2

66
F. B¨orner
Theorem 6.4. ([15]) Let Γ1, Γ2 ⊆RD be ﬁnite sets of relations. If sPol Γ2 ⊆
sPol Γ1, then QCSP(Γ1) is polynomially time reducible to QCSP(Γ2). If sPol Γ2 =
sPol Γ1, then QCSP(Γ1) and QCSP(Γ2), are polynomially time equivalent.
⊓⊔
So we have a similar starting point as in the case of the CSP. One disadvantage
is the fact that sur-OD is not a clone. Because of 1.8 the Galois closed subsets
are just the intersections of clones on D with sur-OD, and these subsets are
in general not closed under superposition. But here helps the construction of
Theorem 1.9. To each Galois closed subset F ⊆sur-OD we assign Pol Inv F =
clone F. By 1.9 this assignment is injective, we reobtain F as sur-OD ∩clone F.
Moreover, we have Inv clone sPol Γ0 = Inv sPol Γ0 for all Γ0.
The clones C with C = clone F for some F = sPolInv F are exactly the clones
with a surjective generating system. We call such clones surjectively generated
and we denote the set of all these clones with sur-LOD. This set is a lattice,
isomorphic to CsPol Inv
sur-OD, but for |D| ≥3 it is not a sublattice of the lattice LOD of
all clones on D. Now we can use our knowledge about LOD to obtain information
on sur-LOD. (It turns out that the structure of sur-LOD is not essentially easier
than the structure of LOD. E.g., sur-LOD is also uncountable for |D| ≥3.)
So we have related the complexity of QCSP–problems with a special lattice
of clones. For the complexity theoretic results obtained with this “algebraic
approach” we refer to [8, 9].
A case by case investigation of the clones in Post’s lattice (Figure 1 on page
47) yields the picture of the lattice of all surjectively generated clones in the
Boolean case. Figure 4 on page 65 shows this lattice, black points denote clones,
consisting only of surjective functions, half-black points denote the other surjec-
tively generated clones .
References
[1] Blyth, T.S., Janowitz, M.F.: Residuation Theory. Pergamon Press, Oxford (1972)
[2] Bodnarˇzuk, V.G., Kaluˇznin, L.A., Kotov, N.N., Romov, B.A.: Galois theory for
Post algebras I. Kibernetika 3, 1–10 (1969) (Russian)
[3] Bodnarˇzuk, V.G., Kaluˇznin, L.A., Kotov, N.N., Romov, B.A.: Galois theory for
Post algebras II. Kibernetika 5, 1–9 (1969) (Russian)
[4] B¨orner, F.: Operationen auf Relationen. Diss., Universit¨at Leipzig (1989)
[5] B¨orner, F.: Krasneralgebren. Logos-Verlag (2000)
[6] B¨orner, F.: Total multifunctions and relations. Contributions to General Alge-
bra 13, 23–36 (2001)
[7] B¨orner, F., P¨oschel, R., Sushchansky, V.: Boolean systems of relations and Galois
connections. Acta Sci. Math (Szeged) 68, 535–560 (2002)
[8] B¨orner, F., Krokhin, A., Bulatov, A., Jeavons, P.: Quantiﬁed constraints and
surjective polymorphisms. Technical Report PRG-RR-02-11, Comp. Lab., Univ.
of Oxford, UK (2002)
[9] B¨orner, F., Bulatov, A., Jeavons, P., Krokhin, A.: Quantiﬁed Constraints: Algo-
rithms and Complexity. In: Baaz, M., Makowsky, J.A. (eds.) Proc. 17th Int. Work-
shop on Computer Science Logic CSL, pp. 58–70. Springer, Heidelberg (2003)

Basics of Galois Connections
67
[10] Bulatov, A., Krokhin, A., Jeavons, P.: The complexity of maximal constraint
languages. In: Proc. 33rd ACM Symp. on Theory of Computing, STOC 2001, pp.
667–674 (2001)
[11] Creignou, N., Khanna, S., Sudan, M.: Complexity Classiﬁcations of Boolean Con-
straint Satisfaction Problems. SIAM Monographs on Discrete Math. and Appl. 7
(2001)
[12] Freivald, R.V.: Functional completeness for not everywhere deﬁned functions of
the algebra of logic. Diskr. Analiz. 8, 55–68 (1966)
[13] Geiger, D.: Closed systems of functions and predicates. Paciﬁc J. Math. 27, 95–100
(1968)
[14] Jeavons, P., Cohen, D., Gyssens, M.: Closure Properties of Constraints. J. of the
ACM 44, 527–548 (1997)
[15] Jeavons, P.: On the algebraic structure of combinatorial problems. Theoretical
Computer Science 200, 185–204 (1998)
[16] Krasner, M.: Une g´en´eralisation de la notion de corps. J. Math. pure et appl. 17,
367–385 (1938)
[17] Krasner, M.: G´en´eralisation abstraite de la th´eorie de Galois. Colloq. internat.
Centre nat. Rech. Sci., Alg`ebre et Th´eorie des Nombres 24, 163–168 (1950)
[18] Lau, D.: Function Algebras on Finite Sets. Springer, Heidelberg (2006)
[19] McKenzie, R.N., McNulty, G.F., Taylor, W.F.: Algebras, Lattices, Varieties, vol. 1.
Wadsworth & Brooks/Cole, Monterey (1987)
[20] P¨oschel, R., Kaluznin, L.A.: Funktionen- und Relationenalgebren. Verlag der Wis-
senschaften, Berlin (1979)
[21] P¨oschel, R.: Closure properties for relational systems with given endomorphism
structure. Beitr. Alg. Geom. 18, 153–166 (1984)
[22] P¨oschel, R.: Galois connections for operations and relations. Technical Report
MATH-AL-8-2001, TU Dresden (2001)
[23] Post, E.L.: Determination of all closed systems of truth tables. Bull. Amer. Math.
Soc. 26, 437 (1920)
[24] Post, E.L.: Introduction to a general theory of elementary propositions. Amer. J.
Math. 43, 163–185 (1921)
[25] Post, E.L.: The two-valued iterative system of mathematical logic. Annals Math.
Stud. 5 (1941)
[26] Romov, B.A.: The algebras of partial functions and their invariants. Kibernetika 2,
1–11 (1981); Engl. transl.: Cybernetics 17, 157–167 (1981)
[27] Romov, B.A.: Hyperclones on a ﬁnite set. In: Mult. Val. Logic 1998, vol. 3, pp.
285–300 (1998)
[28] Romov, B.A.: Partial hyperclones on a ﬁnite set. In: Proc. 32nd IEEE Int. Symp.
Multiple-Valued Logic, pp. 17–27 (2002)
[29] Rosenberg, I.G.: Galois theory for partial algebras. In: Freese, R., Garcia, O.
(eds.) Universal Algebra and Lattice Theory. Lect. Notes in Math., pp. 257–272.
Springer, Heidelberg (1883)
[30] Rosenberg, I.G.: Minimal clones I: the ﬁve types. Lectures in Universal Algebra.
Colloq. Math. Soc. J. Bolyai 43, 405–427 (1983)
[31] Rosenberg, I.G.: Composition of functions on ﬁnite sets, completeness and re-
lations, a short survey. In: Rine, D. (ed.) Multiple-valued Logic and Computer
Science, 2nd edn., pp. 150–192. North-Holland, Amsterdam (1984)
[32] Rosenberg, I.G.: An algebraic approach to hyperalgebras. In: Proc. 26th ISMVL,
pp. 203–207. IEEE, Los Alamitos (1996)
[33] Schaefer, T.: The complexity of satisfyability problems. In: Proc. 10th ACM Symp.
on Theory of Computing, STOC 1978, pp. 216–226 (1978)

Recent Results on the Algebraic Approach to
the CSP
Andrei A. Bulatov1 and Matthew A. Valeriote2
1 School of Computing Science
Simon Fraser University
Burnaby, BC, Canada, V5A 1S6
abulatov@cs.sfu.ca
2 Department of Mathematics & Statistics
McMaster University
Hamilton, Ontario, Canada L8S 4K1
matt@math.mcmaster.ca
Abstract. We describe an algebraic approach to the constraint satis-
faction problem (CSP) and present recent results on the CSP that make
use of, in an essential way, this algebraic framework.
1
Introduction
This paper presents material from the talks that the authors gave at the Dagstuhl
seminar on the Complexity of Constraints held in 2006. The primary goals of
the talks were to describe an algebraic approach to the constraint satisfaction
problem and to present, within the algebraic context, recent results relating to
two of the main motivating conjectures in the ﬁeld.
During our talks, by necessity, a fair amount of time was occupied in describing
basic and advanced universal algebra. In particular, overviews of two approaches
to analyzing the local structure of ﬁnite algebras were given. The ﬁrst, known as
tame congruence theory, was developed in the 1980s by David Hobby and Ralph
McKenzie and has played an important role in the development of universal
algebra ever since. The second is a much more recent approach developed by
Bulatov speciﬁcally to address questions relating to the CSP. For readers who
wish to learn more about basic universal algebra we recommend [17] and [36]. For
more information on tame congruence, the works [26] or [19] can be consulted.
The paper [10] contains details of the theory developed by Bulatov.
2
Constraint Satisfaction and Algebra
2.1
Constraint Satisfaction
We use the homomorphism deﬁnition of the CSP. A vocabulary τ is a ﬁnite set
of relational symbols; each symbol has an associated arity. A (ﬁnite) relational
structure H with vocabulary τ consists of a ﬁnite set H, its universe, and, for
N. Creignou et al. (Eds.): Complexity of Constraints, LNCS 5250, pp. 68–92, 2008.
c
⃝Springer-Verlag Berlin Heidelberg 2008

Recent Results on the Algebraic Approach to the CSP
69
every relational symbol R ∈τ of arity n, an n-ary relation RH on H, the
interpretation of R by H. A homomorphism of a structure G to a structure H
with the same vocabulary τ is a mapping ϕ: G →H from the universe of G to
the universe of H such that for each (n-ary) relational symbol R ∈τ and any
tuple (a1, . . . , an) ∈RG the tuple (ϕ(a1), . . . , ϕ(an)) belongs to RH.
For a ﬁnite structure H the non-uniform constraint satisfaction problem, de-
noted CSP(H), is the following combinatorial problem: Given a structure G of
the same vocabulary as H, decide whether or not there is a homomorphism from
G to H. The structure H is called the template, and G is called the instance. For
a class H of relational structures, in the uniform constraint satisfaction problem,
denoted CSP(H), the question is: given a structure H ∈H and a structure G
over the same vocabulary as H, decide whether there exists a homomorphism
from G to H. Sometimes it is convenient to think of a uniform problem as of the
union or collection of non-uniform problems CSP(H) for H ∈H.
Example 1 (NAE, Linear Equations, and H-Colouring).
1. Let HNAE be a relational structure with universe {0, 1} and one ternary
relation RHNAE = {0, 1}3 \ {(0, 0, 0), (1, 1, 1)}. It is easy to see that the
problem CSP(HNAE) is the same as the Not-All-Equal Satisfiability
problem, in which, given a set of propositional variables and a set of triples of
these variables, the question is whether or not it is possible to assign values
to the variables such that the variables from each of the speciﬁed triples take
both possible values, 0 and 1.
2. Let F be a ﬁnite ﬁeld and Γ the set of all relations over F that can be
represented as the set of solutions of a linear equation over F. Let HLQ(F)
denote the set of all structures with universe F, whose relations are from Γ.
Then the uniform problem CSP(HLQ(F)) is equivalent in a certain sense to
the problem of solving systems of linear equations over F.1
3. Let H be a (directed) graph. In the H-Colouring problem we are asked
whether there is a homomorphism from a given graph G to H. So, the H-
Colouring problem is just the problem CSP(H).
Two major issues have arisen in the study of the study of the constraint sat-
isfaction problem. The ﬁrst one is the computational complexity of solving such
problems. Although constraint satisfaction problems may belong to and be com-
plete in many complexity classes, see, e.g. [1,32,33], in this paper we concentrate
1 The size of a CSP instance is deﬁned to be the length of a reasonable encoding
of the structures involved, that is the instance in the case of a non-uniform prob-
lem, and the source structure and the template in the case of a uniform problem.
Usually such an encoding includes a list of elements of the structures and a list of
tuples in all relations. In some cases such a general representation is not the most
natural. For example, the natural representation of a CSP(HLQ(F)) instance is a
list of equations deﬁning relations of the template. Although no example is known,
diﬀerent representation may aﬀect the complexity of uniform problems. However,
for the sake of generality throughout the paper we use the explicit representation of
relational structures. The choice of representation does not aﬀect the complexity of
non-uniform problems.

70
A.A. Bulatov and M.A. Valeriote
on problems solvable in polynomial time (such problems are often said to be
tractable). The remaining problems are called intractable. (Throughout the pa-
per we assume P̸=NP.) All the intractable problems known so far turn out to
be NP-complete. This prompted Feder and Vardi [24] to suggest the Dichotomy
Conjecture: Every non-uniform CSP is either tractable or NP-complete.
The second issue is the descriptive complexity of non-uniform problems. Let
H be a relational structure. The class of structures homomorphic to H is often
denoted by CSP(H) (this does not cause any confusion, because CSP(H) is
the class of yes-instances of the corresponding constraint satisfaction problem,
and therefore the language associated to this problem). In many cases the class
CSP(H) can be characterized as the class of all structures satisfying some formula
in a certain logic. The goal is to describe structures H such that CSP(H) is
expressible in this logic. We concentrate on the logic corresponding to Datalog.
For deﬁnitions of Datalog, Datalog expressibility, related properties of structures
and problems, as well as results on other important logical languages the reader
is referred to [16] from the same volume.
Example 2 (continued).
1. NAE is NP-complete, [38].
2. Linear Equations is not expressible in Datalog, [24].
3. H-Coloring is tractable if and only if H is a bipartite graph. In this case
it is expressible in Datalog. Otherwise it is NP-complete, [25].
2.2
Polymorphisms and Algebras
In this section we provide a brief overview of the algebraic approach to the
constraint satisfaction problem.
At the core of this approach is the concept of a polymorphism. Let R be a
relation on a set A. An (n-ary) operation f on the same set is said to be a poly-
morphism of R if for any tuples a1, . . . , an ∈R the tuple f(a1, . . . , an) obtained
by applying f component-wise also belongs to R. The relation R is called an
invariant of f. An operation f is a polymorphism of a relational structure H if it
is a polymorphism of each relation of the structure. The set of all polymorphisms
of H is denoted by Pol(H). For a collection C of operations Inv(C) denotes the
set of invariants of all operations from C.
Example 3 ([39]). Let R be the solution space of a system of linear equations
over a ﬁnite ﬁeld F. Then the operation m(x, y, z) = x−y+z is a polymorphism
of R. Indeed, let A · x = b be the system deﬁning R, and x, z, y ∈R. Then
A · m(x, z, y) = A · (x −z + y) = A · x −A · z + A · y = b −b + b = b.
In fact, the converse can also be shown: if R is invariant under m then it is the
solution space of a certain system of linear equations.
The following theorem relates polymorphisms, complexity, and expressibility in
Datalog

Recent Results on the Algebraic Approach to the CSP
71
Theorem 1 ([28,30,34]). Let H1 and H2 be two structures with a common
universe.
1. If Pol(H1) ⊆Pol(H2) then CSP(H2) is log-space reducible to CSP(H1).
2. If Pol(H1) ⊆Pol(H2) and CSP(H1) is expressible in Datalog, then CSP(H2)
is expressible in Datalog.
An algebra is a pair A = (A; F) consisting of a set A, the universe of A, and
a set F of operations on A, the basic operations of A. Operations that can be
obtained from the basic operations of A and the projection operations on A,
that is operations of the form f(x1, . . . , xn) = xi, by means of compositions are
called term operations of A. Term(A) denotes the set of all term operations of A.
Operations that can be obtained from term operations by substituting constants
are called polynomial operations (or just polynomials) of A.
Any relational structure H and therefore any non-uniform constraint satisfac-
tion problem can be associated with an algebra Alg(H) = (H; Pol(H)) where H
is the universe of H. Conversely, any algebra A = (A; F) corresponds to a class
of structures Str(A) that includes all the structures H with universe A, having
a ﬁnite vocabulary, and such that Term(A) ⊆Pol(H). Therefore every algebra
gives rise to a uniform constraint satisfaction problem CSP(Str(A)), which we
will denote by CSP(A).
An algebra A is called tractable if CSP(H) is tractable for each H ∈Str(A) and
is called NP-complete if CSP(H) for some H ∈Str(A) is. Theorem 1 implies that
if CSP(H) is tractable then the algebra Alg(H) is tractable. We make two obser-
vations. First, if an algebra A is not tractable, it does not mean that CSP(H) is
intractable for all H ∈Str(A); this class always contains poor structures whose
associated class of constraint satisfaction problems is very easy. Second, if A
is tractable it does not necessarily mean that the uniform problem CSP(A) is
tractable. Although no example is known, it may be the case that the time com-
plexity of problems CSP(H), H ∈Str(A), does not have a uniform polynomial
bound, even though the complexity of each problem is polynomially bounded. To
distinguish these two potential situations we sometimes call tractable algebras
locally tractable and algebras for which CSP(A) is tractable, globally tractable.
In other words, A is locally tractable if every non-uniform problem from CSP(A)
is solvable in polynomial time.
The relational width of an algebra A is a parameter related to certain prop-
erties of Datalog programs or propagation algorithms that solve the problems
CSP(H) for H ∈Str(A). The algebra A is said to be of bounded width if CSP(H)
is expressible in Datalog for any structure H ∈Str(A). For complete deﬁnitions
and discussion of this concept see [16] in the same volume.
The tractability and relational width of an algebra usually follows from the
presence of a certain polymorphism of a structure (or a term operation of an
algebra).
Example 4 ([5,13,20,22,28,30]). If one of the following operations is a term oper-
ation of an algebra A [a polymorphism of a relational structure H] then CSP(A)
[CSP(H)] is tractable:

72
A.A. Bulatov and M.A. Valeriote
• a semilattice operation, that is a binary operation f satisfying the equations:
(a) f(x, x) ≈x (idempotency); (b) f(x, y) ≈f(y, x) (commutativity);
(c) f(f(x, y), z) ≈f(x, f(y, z)) (associativity);
• a 2-semilattice operation, that is a binary operation f satisfying the equa-
tions f(x, x) ≈x, f(x, y) ≈f(y, x), and f(x, f(x, y)) ≈f(x, y);
• a near-unanimity (NU ) operation, that is an operation f satisfying the equa-
tions f(x, . . . , x, y) ≈f(x, . . . , x, y, x) ≈. . . ≈f(y, x, . . . , x) ≈x.
• a majority operation, that is a ternary operation g satisfying the equations
g(x, x, y) ≈g(x, y, x) ≈g(y, x, x) ≈x (thus a majority operation is a ternary
near-unanimity operation).
• a Mal’tsev operation, that is a ternary operation h satisfying the equations
h(x, x, y) ≈h(y, x, x) ≈y.
• a generalized majority-minority (GMM ) operation, that is an operation f
such that for any a, b ∈A one of the following two conditions holds:
f(x, . . . , x, y) = f(x, . . . , x, y, x) = . . . = f(y, x, . . . , x) = x, for x, y ∈{a, b};
or
f(x, . . . , x, y) = f(y, x, . . . , x) = x, for x, y ∈{a, b}.
Example 5. If one of the following operations is a polymorphism of a relational
structure H, then CSP(H) is expressible in Datalog:
• a semilattice operation;
• a 2-semilattice operation;
• a near-unanimity operation;
• a majority operation.
On the other hand, the intractability of a relational structure (or an algebra)
seems to imply that it has rather uninteresting polymorphisms (term operations,
respectively). An operation f on a set A is said to be an essentially unary
surjective operation if f(x1, . . . , xn) = g(xi) for some i and some surjective map
g(x) of A.
Example 6 (continued).
1. An operation f is a polymorphism of HNAE if and only if f is an essentially
unary surjective operation, [30,31].
2. An operation f is a polymorphism of all relations representable by lin-
ear equations over a ﬁeld F if and only if f = α1x1 + . . . + αnxn where
α1, . . . , αn ∈F are such that α1 + . . . + αn = 1, [39].
3. If H = Kℓ, a complete graph on ℓ> 2 vertices, then an operation f is a poly-
morphism of H if and only if f is an essentially unary surjective operation.
If H = K2 then H has a majority polymorphism.
The examples above and Theorem 1 provide necessary conditions for tractability
and expressibility in Datalog.

Recent Results on the Algebraic Approach to the CSP
73
Corollary 1
1. If every polymorphism of a structure H [every term operation of an alge-
bra A] is an essentially unary surjective operation then CSP(H) [CSP(A),
respectively] is NP-complete.
2. If there is a ﬁeld F such that every polymorphism of a structure H [every
term operation of an algebra A] is of the form f = α1x1 + . . . + αnxn, where
α1, . . . , αn ∈F are such that α1 + . . . + αn = 1, then CSP(H) [CSP(A),
respectively] is not expressible in Datalog [is not of bounded relational width].
If every term operation of a ﬁnite algebra A is essentially unary surjective then
A is said to be a G-set. If there is a module M over a ring R such that every
term operation of A can be represented as α1x1 + . . . + αnxn for α1, . . . , αn ∈R
and α1 + . . . + αn = 1, then A is called an idempotent reduct of a module.
Example 4 allows one to classify 2-element algebras in terms of complexity.
Proposition 1 (Schaefer’s Dichotomy Theorem, [38]). For any 2-element
algebra A, the problem CSP(A) is (globally) tractable if and only if Term(A)
contains one of the following:
– the constant 0 or constant 1 operation;
– the conjunction or disjunction operations (which are semilattice);
– the majority operation (x ∨y) ∧(y ∨z) ∧(z ∨x);
– the Mal’tsev operation x −y + z(mod 2).
In all other cases CSP(A) is NP-complete.
2.3
Varieties
For the purposes of settling the Dichotomy Conjecture and related questions, the
class of algebras to be considered can be signiﬁcantly reduced. An algebra A is
called surjective if every one of its unary term operations is surjective. One way
to transform an algebra into a surjective algebra is as follows: Let g be a unary
term operation of A = (A; F) with a minimal range. Then g(A) denotes the
algebra (g(A); Fg) where Fg = {gf|g(A) | f ∈Term(A)}. It is not diﬃcult to see
that this algebra is surjective. The algebra A is called idempotent if every one of
its term operations f satisﬁes the equation f(x, . . . , x) ≈x. The full idempotent
reduct of A is the algebra Id(A) = (A; Fid) where Fid is the set of all idempotent
operations from Term(A).
Theorem 2 ([14]). Let A be an algebra.
1. If g is a unary term operation of A with minimal range then A is tractable
if and only if g(A) is tractable. The algebra A is NP-complete if and only if
g(A) is NP-complete.
2. If A is surjective then A is tractable if and only if Id(A) is tractable. The
algebra A is NP-complete if and only if Id(A) is NP-complete.

74
A.A. Bulatov and M.A. Valeriote
The main idea of the algebraic approach is to use some properties of an algebra
in order to determine the complexity of the associated constraint satisfaction
problem. To identify these properties, some connections between the complexity
of an algebra and the complexity of those algebras that can be obtained from it
by some standard algebraic constructions will be very helpful.
– Let A = (A; F) be an algebra. The k-th direct power of A is the algebra
Ak = (Ak; F) where we treat each (n-ary) operation f ∈F as acting on Ak
component-wise.
– Let A = (A; F) be an algebra, and let B be a subset of A such that, for any
(n-ary) f ∈F, and for any b1, . . . , bn ∈B, we have f(b1, . . . , bn) ∈B. Such
a subset is called a subuniverse of A. When B is non-empty, the algebra
B = (B; F
B), where F
B consists of restrictions of operations f ∈F to B, is
called a subalgebra of A.
– Let A1 = (A1; F1) and A2 = (A2; F2) such that F1 = {f 1
i
| i ∈I},
F2 = {f 2
i | i ∈I}, and f 1
i , f 2
i are of the same arity, for some set I and
each i ∈I. A mapping ϕ : A1 →A2 is called a homomorphism from A1
to A2 if ϕf 1
i (a1, . . . , ani) = f 2
i (ϕ(a1), . . . , ϕ(ani)) holds for all i ∈I and all
a1, . . . , ani ∈A1. If the mapping ϕ is onto then A2 is said to be a homomor-
phic image of A1.
By a classic result of Birkhoﬀ(see Theorem 11.9 from [17]), properties of alge-
bras that are preserved under the taking of subalgebras, homomorphic images,
and direct products (a natural generalization of the direct power construction)
are precisely those that can be deﬁned by equations. We note that except for the
last one, all of the properties of the operations listed in Example 4 are deﬁned
by equations. Equationally deﬁned classes of algebras, also known as varieties
of algebras, are fundamental objects of study in universal algebra [26,36]. The
following theorems thus provide an important link between the constraint satis-
faction problem and universal algebra.
Theorem 3 ([14,8]). Let A be a ﬁnite algebra. Then
1. if A is tractable then so is every subalgebra, homomorphic image, and direct
power of A.
2. if A has an NP-complete subalgebra, homomorphic image, or direct power,
then A is NP-complete itself.
Theorem 4 ([34]). Let A be a ﬁnite algebra. If A has bounded width then every
subalgebra, homomorphic image, and direct power of A has bounded width.
Using Birkhoﬀ’s Theorem, the variety that an algebra A determines, denoted by
var(A), can be deﬁned either as the class of all algebras that satisfy the same
equations that A does, or as the class of all algebras that arise as homomorphic
images of subalgebras of direct powers of A.

Recent Results on the Algebraic Approach to the CSP
75
Corollary 2
1. If A is tractable then so is every ﬁnite algebra from var(A). If var(A) contains
an NP-complete algebra then A is NP-complete.
2. If A has bounded width then every ﬁnite algebra from var(A) has bounded
width. If var(A) contains an algebra of unbounded width then A does not
have bounded width.
3. Tractability, NP-completeness, and bounded width are properties of an alge-
bra that depend only on the equations satisﬁed by the algebra.
Using Corollary 2 we can strengthen Corollary 1 as follows.
Theorem 5 ([14,34]). Let A be an algebra
1. If var(A) contains a G-set then A is NP-complete.
2. If var(A) contains a reduct of a module then A does not have bounded width.
To date no NP-complete or unbounded width algebra is known that does not
satisfy the corresponding condition of Theorem 5. It is widely believed that these
necessary conditions are also suﬃcient, at least for idempotent algebras.
Conjecture 1 (complexity dichotomy conjecture). An idempotent algebra
A is tractable if and only if var(A) does not contain a G-set. Otherwise it is
NP-complete.
Conjecture 2 (bounded width conjecture). An idempotent algebra A has
bounded width if and only if var(A) does not contain a reduct of a module.
Conjectures 1 and 2 have been proved in a number of particular cases: 2-element
algebras ([38]), 3-element algebras ([12]), semigroups ([9,23]). The following ex-
ample shows that the undirected graphs dichotomy theorem by Hell and Neˇsetˇril
[25] also ﬁts Conjecture 1.
Example 7 ([11]). Let H be an undirected graph, A = Alg(H), and g a unary
term operation of A with a minimal range. Then H is non-bipartite if and only
if var(g(A)) contains a G-set. Otherwise g(H) is K2 and g(A) has a majority
term operation.
3
Alternate Versions of the Conjectures
The goal of this section is to present new formulations of Conjectures 1 and 2
that have emerged over the past several years. Central to our ﬁrst formulation is
the notion of a congruence of an algebra A. A congruence θ of A is an equivalence
relation on A that is invariant under all basic (and therefore term) operations of
A. Every algebra A has two distinguished congruences 0A and 1A corresponding
to the smallest and largest equivalence relations on the set A. For θ a congruence
of A = (A; F) and a ∈A by a/θ we denote the θ-class containing a; and denote
{a/θ | a ∈A}, the set of all θ-classes, by A/θ. The quotient algebra A/θ is the

76
A.A. Bulatov and M.A. Valeriote
algebra with universe A/θ and whose basic operations are {f/θ : f ∈F}, where
for f ∈F,
f/θ(a1/θ, . . . , an/θ) = (f(a1, . . . , an))/θ.
It is elementary that the mapping ϕ: A →A/θ that maps an element a ∈A to
a/θ is a surjective homomorphism and so it follows that A/θ is a homomorphic
image of A.
3.1
Tame Congruence Theory
In the early 1980’s Hobby and McKenzie developed a theory of the local structure
of ﬁnite algebras called tame congruence theory [26]. At the heart of the theory is
a notion of a neighbourhood of a ﬁnite algebra, relativized to certain congruences
of the algebra. The local structure of a ﬁnite algebra that emerges from their
theory is surprisingly well-behaved and has been used to prove many striking
theorems in universal algebra.
Deﬁnition 1. Let A be a ﬁnite algebra and α a minimal congruence of A (i.e.,
0A < α and if β is a congruence of A with 0A < β ≤α then β = α.)
– An α-minimal set of A is a subset U of A such that
• U = p(A) for some unary polynomial p(x) of A that is not constant on
at least one α-class, and
• with respect to containment, U is minimal with this property.
– An α-neighbourhood (or α-trace) of A is a subset N of A such that
• N = U ∩(a/α) for some α-minimal set U and α-class a/α, and
• |N| > 1.
It follows from the deﬁnition that a given α-minimal set U contains within it
at least one (and possibly several) α-neighbourhoods. The union of all of the
α-neighbourhoods in U is called the body of U, while the remaining elements of
U form the tail of U. What is surprising is that the structure that A induces
on any one of its α-neighbourhoods is quite uniform and is restricted to one
of ﬁve possible types. What is meant by induced structure is given in the next
deﬁnition.
Deﬁnition 2. Let A be an algebra and U ⊆A. The algebra induced by A on U
is the algebra with universe U whose basic operations consist of the restriction
to U of all polynomials of A under which U is closed. We denote this induced
algebra by A|U.
Note the diﬀerence between this notion and the more familiar one of subuniverse
(recall that a subuniverse of an algebra A is a subset of A that is closed under
all term operations of A). In the theory developed by Hobby and McKenzie,
the polynomials of an algebra play a central role and in fact, two ﬁnite polyno-
mially equivalent algebras (i.e., two algebras over the same universe whose sets
of polynomials coincide) are, for the most part, indistinguishable using tame
congruence theory.

Recent Results on the Algebraic Approach to the CSP
77
Theorem 6. Let A be a ﬁnite algebra and α a minimal congruence of A.
– If U and V are α-minimal sets then A|U and A|V are isomorphic and in fact
there is a polynomial p(x) of A that maps U bijectively on to V .
– If N and M are α-neighbourhoods then A|N and A|M are isomorphic via the
restriction of some polynomial of A.
– If N is an α-neighbourhood then A|N is polynomially equivalent to one of:
1. A unary algebra whose basic operations are all permutations (unary
type);
2. A one-dimensional vector space over some ﬁnite ﬁeld (aﬃne type);
3. A 2-element boolean algebra (boolean type);
4. A 2-element lattice (lattice type);
5. A 2-element semilattice (semilattice type).
Much more can be said about the α-neighbourhoods and minimal sets of an alge-
bra but for now we point out that the previous theorem allows us to assign a type
to each minimal congruence α of an algebra according to the behaviour of the
α-neighbourhoods. For example, a minimal congruence whose α-neighbourhoods
are all polynomially equivalent to a vector-space is said to have aﬃne type (or
to have type 2).
In Figure 1 two α-minimal sets of an algebra A, U and V , of a minimal con-
gruence α are pictured, along with two α-neighbourhoods, N and M, contained
in them. The dashed lines delineate the α-blocks of the algebra.
N
classes
α−
A
M
V
U
Fig. 1. Minimal Sets

78
A.A. Bulatov and M.A. Valeriote
Taking this idea one step further, given a pair of congruences (α, β) of A with
β covering α (i.e., α < β and there are no congruences of A strictly between the
two), one can form the quotient algebra A/α and then consider the congruence
β/α = {(a/α, b/α) : (a, b) ∈β}. Since β covers α in the congruence lattice of
A then β/α is a minimal congruence of A/α and so can be assigned one of the
ﬁve types. In this way we can assign to each covering pair of congruences of A a
type and so end up with a labelled congruence lattice for A.
For modestly sized algebras, one can, without too much eﬀort, compute their
labelled congruence lattices. Since in general, the size of the congruence lattice
of a ﬁnite algebra can be much larger than the algebra, the task of computing
the labelled congruence lattice of an algebra is by no means tractable. If one is
just interested in determining the type of a given covering pair of congruences or
in the set of labels that appear in the labelled congruence lattice of an algebra,
polynomial time algorithms exist (see [3]).
Example 8. Consider the algebra A with universe {0, 1, 2, 3} having a single bi-
nary basic operation x · y deﬁned by:
· 0 1 2 3
0 0 0 0 3
1 0 1 0 1
2 0 0 2 3
3 3 1 3 3
Besides the two congruence 0A and 1A, A only has two other (minimal) con-
gruences, α and β, pictured in Figure 2 as partitions (using the dotted lines) of
the universe of A.
We claim that the type of α is boolean and the type of β is semilattice. To
see this, consider the polynomials p(x) = x · 1 and q(x) = x · 2. The range of p
is {0, 1} and so N = {0, 1} is both an α-minimal set and an α-neighbourhood
(since p is non constant on some α-class and has minimal range subject to
this property). On the other hand, the range of q is {0, 2, 3} and so is either a
β-minimal set or properly contains one since q is not constant on the only non-
trivial β-class. By analyzing the set of unary polynomials of A it can be seen
that in fact V = {0, 2, 3} is indeed a β-minimal set and hence that M = {0, 2}
is a β-neighbourhood.
Now that α and β-neighbourhoods have been identiﬁed, we need only deter-
mine the types of the algebras that A induces on each of them to determine the
1
α   = 
0
3
2
0
2
1
3
β  =   
Fig. 2. The Congruences α and β, with their minimal sets

Recent Results on the Algebraic Approach to the CSP
79
types of α and β. We see that the restriction of x · y to N provides a semilattice
operation on N and so the type of α cannot be unary or aﬃne since algebras
of these types do not support a semilattice polynomial. Since all boolean opera-
tions can be obtained by composition from a boolean semilattice operation and
complementation, it suﬃces to produce a unary polynomial of A that maps 0
to 1 and 1 to 0 in order to establish that the type of α is boolean. It can be
checked that the polynomial (((x · 3) · 2) · 1) ﬁts the bill. We leave the details of
the calculation of the type of β to the reader and conclude the presentation of
this example by claiming that the types of the covering pairs (β, 1A) and (α, 1A)
are boolean and semilattice, respectively.
While the type-labelled congruence lattice of a ﬁnite algebra carries much infor-
mation about the algebra, it turns out that just knowing the set of labels that
appear in the labelled congruence lattice of a ﬁnite algebra or the variety that
it generates is useful.
Deﬁnition 3
1. The typeset of a ﬁnite algebra A, denoted typ{A}, is the set of labels that
appear in its labelled congruence lattice, and so is a subset of {unary, aﬃne,
boolean, lattice, semi-lattice}.
2. The typeset of a class of algebras K is the union of the typesets of all of its
ﬁnite members and is denoted by typ{K}.
3. We say that a ﬁnite algebra or a class of algebras omits a particular type if
that type does not appear in its typeset.
The following result, found in [8] provides a connection with Conjecture 1, the
Complexity Dichotomy Conjecture.
Theorem 7. Let A be a ﬁnite idempotent algebra and V the variety generated
by A. Then V omits the unary type if and only if var(A) does not contain a G-set.
In fact, this condition holds if and only if there is no algebra in HS(A) that is
term equivalent to a set (i.e., whose basic operations are just projections).
This theorem allows us to restate the Complexity Dichotomy Conjecture in terms
of types:
Conjecture 1 (the complexity dichotomy conjecture, version 2). A ﬁ-
nite idempotent algebra A is tractable if and only if the variety generated by A
omits the unary type (or equivalently, that every subalgebra of A omits the unary
type).
Something similar occurs when considering Conjecture 2, the Bounded Width
Conjecture, namely we can express it in terms of omitting tame congruence
theoretic types.
Theorem 8 ([40]). Let A be a ﬁnite idempotent algebra and V the variety gen-
erated by A. Then V omits the unary and aﬃne types if and only if var(A) does

80
A.A. Bulatov and M.A. Valeriote
not contain an algebra that is term equivalent to a reduct of a module over some
ﬁnite ring. In fact, this condition holds if and only if there is no algebra in HS(A)
that is term equivalent to a set or to the full idempotent reduct of a module over
some ﬁnite ring.
In the language of tame congruence theory, the Bounded Width Conjecture
becomes:
Conjecture 2 (the bounded width conjecture, version 2). A ﬁnite idem-
potent algebra A has bounded width if and only if the variety generated by A
omits the unary and aﬃne types (or equivalently, that every subalgebra of A
omits these types).
3.2
Weak Near-Unanimity Operations
Recall that a near-unanimity operation on a set A is a function t(x1, . . . , xn),
for n > 1, that satisﬁes the equations
t(y, x, x, . . . , x) ≈t(x, y, x, . . . , x) ≈· · · ≈t(x, x, . . . , x, y) ≈x
From [29] we know that if a relational structure H has a near-unanimity poly-
morphism then CSP(H) is tractable. The following variation of this notion was
developed by E. Kiss and Valeriote while investigating the Bounded Width
Conjecture.
Deﬁnition 4. An operation t(x1, . . . , xn), for n > 1, on a set A is a weak near-
unanimity operation if it is idempotent and satisﬁes the equations
t(y, x, x, . . . , x) ≈t(x, y, x, . . . , x) ≈· · · ≈t(x, x, . . . , x, y)
Clearly any near-unanimity operation is also a weak near-unanimity operation
but there are algebras that have term operations of the latter sort but not of the
former. For example, for any positive integer n, the term operation x1 + x2 +
· · ·+xn+1 of the group of integers modulo n is a weak near-unanimity operation.
It is not diﬃcult to show that this group fails to have a near-unanimity term
operation in any number of variables. We leave it as an exercise to show that the
operation x·(y·z) on our 4-element example is a weak near-unanimity operation
(and that this algebra does not have a near unanimity term operation).
While it is not too diﬃcult to show that if a ﬁnite algebra has a weak near-
unanimity term operation then the variety that it generates must omit the unary
type, the converse is much more diﬃcult to show. A recent result of Maroti and
McKenzie establishes this, along with a characterization of ﬁnite algebras that
generate varieties that omit both the unary and aﬃne types.
Theorem 9 ([37]). Let A be a ﬁnite algebra and V the variety that it generates.
1. V omits the unary type if and only if A has a weak near-unanimity term
operation.

Recent Results on the Algebraic Approach to the CSP
81
2. V omits the unary and aﬃne types if and only if there is some N > 0 such
that for all k ≥N, A has a weak near unanimity term of arity k.
This surprising result allows us to provide restatements of the conjectures.
Conjecture 1 (the complexity dichotomy conjecture, version 3). A ﬁ-
nite idempotent algebra A is tractable if and only if A has a weak near-unanimity
term.
Conjecture 2 (the bounded width conjecture, version 3). A ﬁnite idem-
potent algebra A has bounded width if and only if for all but ﬁnitely many k > 0,
A has a k-ary weak near unanimity term.
4
Tractability Via Few Subpowers
In this section we discuss a thread of tractability results that culminates in a
theorem that uniﬁes them in terms of a notion of a ﬁnite algebra having few
subpowers.
Deﬁnition 5 ([2]). A ﬁnite algebra A is said to have few subpowers if there is
some polynomial p(n) such that for each n > 0,
sA(n) = log2 |{B : B is a subuniverse of An}| ≤p(n).
It is not diﬃcult to see that for any ﬁnite algebra A of size m, the function
sA(n) is bounded above by mn. In general sA(n) will grow exponentially and
so the few subpowers condition imposes certain restrictions on the algebra A.
One consequence of a ﬁnite algebra A having few subpowers is the existence of a
polynomial g(n) such that for any n > 0, every subalgebra of An has a generating
set of size bounded above by g(n). In fact this “small generating set” property
is equivalent to having few subpowers. Before characterizing such algebras, we
present some examples.
Using a theorem of Baker and Pixley from [4] it follows that if A is a ﬁnite
algebra that has a k-ary near unanimity term operation (see Example 4) then
the function sA(n) is bounded above by a polynomial of degree k −1 and so such
algebras have few subpowers. An early tractability result of Jeavons, Cohen and
Cooper [29] establishes that algebras having near unanimity terms are tractable,
and it is no coincidence that this tractability result can be proved using the
Baker-Pixley theorem.
In [24], Feder and Vardi prove that if a relational structure H has a polymor-
phism of the form x · y−1 · z for some group operation x · y on H then CSP(H)
is tractable. Generalizing this, Bulatov [5] proves that if a ﬁnite algebra A has
a term p(x, y, z) that satisﬁes the equations p(x, x, y) ≈p(y, x, x) ≈y for all
x, y ∈A then A is also tractable (any operation that satisﬁes these equations
is known as a Mal’tsev operation, see Example 4). The proof of this theorem

82
A.A. Bulatov and M.A. Valeriote
found in [13] exploits the fact that any ﬁnite algebra with a Mal’tsev term has
the small generating sets property (and hence, few subpowers).
While Mal’tsev and near unanimity operations are of quite diﬀerent charac-
ter, Dalmau in [22] managed to ﬁnd a common generalization of them via the
generalized majority-minority operation (see Example 4 for the deﬁnition). In a
modiﬁcation of the algorithm presented in [13], Dalmau shows in [22] that any
ﬁnite algebra that has a GMM term is tractable. As in the case of algebras with
Mal’tsev terms, these algebras have few subpowers and the small generating sets
property and it is this latter property that plays a crucial role in the proof.
In [2] a characterization of ﬁnite algebras with few subpowers is given in terms
of the presence of a special type of operation.
Deﬁnition 6. A k-edge operation on a set A is a k +1-variable operation t that
satisﬁes the equations:
t(x, x, y, y, y, . . . , y, y) ≈y
t(x, y, x, y, y, . . . , y, y) ≈y
t(y, y, y, x, y, . . . , y, y) ≈y
t(y, y, y, y, x, . . . , y, y) ≈y
...
t(y, y, y, y, y, . . ., y, x) ≈y.
Theorem 10 ([2]). A ﬁnite algebra A has few subpowers if and only if it has
a k-edge term for some k > 0. If this condition fails to hold then the function
sA(n) grows exponentially.
Using this characterization the tractability of algebras with few subpowers can
be deduced.
Corollary 3 ([27]). If the ﬁnite algebra A has few subpowers then it is globally
tractable.
We note that the proof of this corollary closely follows the GMM tractability
proof of Dalmau. We also note that the theorem and corollary settle conjec-
tures posed by Chen [18] and Dalmau [21] on the nature of algebras with few
subpowers.
We conclude this section with a result of Markovi´c and McKenzie [2,35] that
highlights the singular position that algebras with near unanimity term opera-
tions occupy. We have already noted that if a ﬁnite idempotent algebra has a
near unanimity operation, then it has bounded width and few subpowers and
so can be shown to be tractable in two distinct ways. The following theorem
provides a converse to this.
Theorem 11. Let A be a ﬁnite idempotent algebra. If A is of bounded width
and has few subpowers then it has a near unanimity term operation.

Recent Results on the Algebraic Approach to the CSP
83
5
Coloured Graphs and Finite Algebras
The conditions of tractability and bounded width that appear in Conjectures 1
and 2 are known to be necessary. In order to prove that they are also suﬃ-
cient for the complexity dichotomy conjecture one needs to design an algorithm
(or algorithms) that solves CSPs satisfying the tractability condition, and for
the bounded width conjecture, that the constraint propagation algorithm solves
CSPs satisfying the bounded width condition. In all known cases algorithms (of
proofs of the soundness of algorithms) use some local structure of algebras. Usu-
ally this structure can be explained in terms of the action of term operations of
algebras on small subsets. In this section we propose an approach to the local
structure of a ﬁnite idempotent algebra that is based on term operations of the
algebra.
5.1
Coloured Graphs of Algebras
5.2
The Graph
The results of this section were ﬁrst presented in [10]. We relate to every idem-
potent ﬁnite algebra A an edge-coloured graph Gr(A). If A = (A; F) and B ⊆A,
then by ⟨B⟩we denote the subalgebra generated by B, that is the smallest sub-
algebra of A containing B.
Deﬁnition 7. Let A = (A; F) be a ﬁnite idempotent algebra. The vertex set of
the graph Gr(A) is the universe A of A. A pair ab of vertices is an edge if and
only if there exists a congruence θ of ⟨a, b⟩and a term operation f of A such that
either f/θ is an aﬃne operation on ⟨a, b⟩/θ, or f/θ is a semilattice operation
on {a/θ, b/θ}, or f/θ is a majority operation on {a/θ, b/θ} (see Figure 3).
The color of an edge is deﬁned as follows.
– If there exists a congruence θ and a term operation f ∈Term(A) such that
f/θ is a semilattice operation on {a/θ, b/θ} then ab is said to have the semi-
lattice type.
– An edge ab is of the majority type if it is not of the semilattice type and
there are a congruence θ and a term operation f of A such that f/θ is a
majority operation on {a/θ, b/θ}.
– An edge ab is of the aﬃne type if it is not of the semilattice or majority type
and there are a congruence θ and a term operation f of A such that f/θ is
an aﬃne operation on ⟨a, b⟩/θ.
We sometimes call the set a/θ ∪b/θ a thick edge.
Example 9. Let A = ({0, 1, 2}; f) be an algebra, where the operation f is deﬁned
by its Cayley table
f(x, y) 0 1 2
0 0 1 2
1 1 1 0
2 2 0 2

84
A.A. Bulatov and M.A. Valeriote
H
classes of 
edge
θ
<a,b>
a
b
Fig. 3. Edges
2
1
0
Fig. 4. Gr(A); edges of the semilattice type are drawn solid, edges of the majority type
are dotted
(In fact, f occurs in [12]; in that paper it is called operation (6).) We have:
⟨0, 1⟩= {0, 1}, ⟨0, 2⟩= {0, 2}, ⟨1, 2⟩= {1, 2, 3}; the only congruence of ⟨1, 2⟩
such that 1, 2 belong to distinct classes is the equality relation; f witnesses that
01 and 02 are edges of semilattice type; 12 cannot be an edge of the semilat-
tice type because no term operation of A is semilattice on {1, 2}; however, the
operation g(x, y, z) = f(f(x, f(y, z)), f(f(x, y), z)) is a majority operation on
{1, 2}. Thus, Gr(A) is the graph shown in Figure 4. Note also that this graph
was implicitly used in [12] to prove the tractability of A.
Observe that it is possible that for some pair a, b diﬀerent congruences of ⟨a, b⟩
witness diﬀerent types of the edge ab. Following the deﬁnition we always choose
the ‘strongest’ type of the edge. Thus, the semilattice type is stronger than the
majority type, which, in turn, is stronger than the aﬃne type.
Example 10. Let A, B be algebras with universes {0, 1} and {a, b}, respectively,
and operations f, g. These operations are deﬁned as follows:
– f is a semilattice operation on A, i.e. f(0, 0) = f(0, 1) = f(1, 0) = 0, f(1, 1)=1;
– f is the ﬁrst projection on B, i.e. f(x, y) = x for all x, y ∈{a, b};
– g is the ternary ﬁrst projection on A, i.e. g(x, y, z) = x for all x, y, z ∈{0, 1};
– g is a majority operation on B; note that there is only one majority operation
on a 2-element set.
Then let C denote the direct product of A and B, that is the algebra with universe
C = {(x, y) | x ∈{0, 1}, y ∈{a, b}}, and operations f, g on C acting as follows:
f((x1, y1), (x2, y2)) = (f(x1, x2), f(y1, y2))
and
g((x1, y1), (x2, y2), (x3, y3)) = (g(x1, x2, x3), g(y1, y2, y3)).

Recent Results on the Algebraic Approach to the CSP
85
As is easily seen, ⟨(0, a), (1, b)⟩= C and the equivalence relations η1, η2 deﬁned
by ((x1, y1), (x2, y2)) ∈η1 if and only if x1 = x2, and ((x1, y1), (x2, y2)) ∈η2 if
and only if y1 = y2, are congruences of C. Observe that f/η1 is a semilattice
operation on C/η1 = {(0, a)/η1, (1, b)/η1}; and that C/η2 = {(0, a)/η2, (1, b)/η2}
is isomorphic to B. Thus, congruence η1 witnesses that (0, a)(1, b) is an edge of
semilattice type, while η2 witnesses that the same edge has majority type. Since
the semilattice type is stronger, this edge has semilattice type.
5.3
Connectedness and Omitting Types
We show that connectedness of the graph Gr(A) and the colours of edges that
appear in it are closely related to omitting types in the sense of tame congruence
theory, and to Conjectures 1 and 2.
Theorem 12 ([10]). For an idempotent algebra A the following conditions are
equivalent:
(1) var(A) omits the unary type;
(2) var(A) does not contain a G-set;
(3) for any subalgebra B of A the graph Gr(B) is connected.
We shall refer to condition (3) from Theorem 12 as to the connectedness condi-
tion.
Theorem 13. Let A be an idempotent algebra. The following conditions are
equivalent:
(1) var(A) omits the unary and aﬃne types;
(2) var(A) does not contain an algebra that is term equivalent to a reduct of a
module over some ﬁnite ring;
(3) A satisﬁes the connectedness condition, and Gr(A) does not contain edges of
the aﬃne type.
Since this result appears here for the ﬁrst time we give a proof of it. We shall
use an improved version of Lemma 1 from [10].
Lemma 1. Let A be a ﬁnite idempotent algebra, and let ab be an edge of the
aﬃne type in Gr(A). Then there are a maximal congruence θ of ⟨a, b⟩(that
is there is no congruence strictly between θ and the total congruence) and a
module M with the universe ⟨a, b⟩/θ over a ring R such that every term operation
of ⟨a, b⟩/θ can be represented as an operation α1x1 + . . . + αnxn of M with
α1, . . . , αn ∈R, α1 + . . . + αn = 1.
Proof (of Theorem 13). The equivalence of (1) and (2) is follows from Theorem 8.
We show that (3) is equivalent to (1).
If for some subalgebra B of A the graph Gr(B) is not connected then by
Theorem 12 var(B) ⊆var(A) contains a G-set that is term equivalent to a reduct
of any module, because in an idempotent variety any G-set is term equivalent

86
A.A. Bulatov and M.A. Valeriote
to an algebra whose basic operations are projections. If Gr(A) contains an edge
of the aﬃne type ab then by Lemma 1 the algebra ⟨a, b⟩/θ for a certain θ is a
reduct of a module.
By Theorem 8 if var(A) contains an algebra term equivalent to a reduct of a
module, then there is a subalgebra B of A and a congruence θ of B such that B/θ
is term equivalent to a reduct of a module. If this algebra is a G-set then Gr(B)
is not connected by Theorem 12. Otherwise we assume that B is a minimal (with
respect to containment) subalgebra with this property and θ is a maximal con-
gruence of B. Then θ is the only maximal congruence of B. Indeed, if η is another
maximal congruence of B, then any class C of η that is not contained in a class of
θ induces a proper subalgebra C of B, and C/θ is still term equivalent to a reduct
of a module; a contradiction with minimality of B. It is not hard to see, that,
for any a, b ∈B such that (a, b) ̸∈θ, the pair ab is an edge of the aﬃne type. 2
Using Theorems 12 and 13 we can give yet another formulation of the complexity
and bounded width conjectures.
Conjecture 1 (the complexity dichotomy conjecture, version 4). A ﬁ-
nite idempotent algebra is tractable if and only if it satisﬁes the connectedness
condition.
Conjecture 2 (the bounded width conjecture, version 4). A ﬁnite idem-
potent algebra A has bounded width if and only if it satisﬁes the connectedness
condition and the graph Gr(A) does not contain edges of the aﬃne type.
5.4
Improving an Algebra
The study of ﬁnite algebras in the context of the complexity of the CSP does not
necessarily suppose investigation of the exact structure of ﬁnite algebras. There-
fore we can transform algebras under consideration as long as such a transfor-
mation preserves properties supposedly responsible for tractability, e.g. omitting
the unary type. In this subsection we show two such transformations.
We say that the graph Gr(A) is semilattice-connected, if for any two vertices
a, b ∈A there is a path in Gr(A) consisting of edges of the semilattice type. The
semilattice/majority connectedness of Gr(A) is deﬁned similarly.
Proposition 2. Let A be an idempotent algebra satisfying the connectedness
condition, let ab be an edge of Gr(A) of the semilattice or majority type, and
let Rab = (a/θ ∪b/θ) be the corresponding thick edge, where θ is a congruence
certifying the type of ab.
(1) Aab = (A; F ′), where F ′ is the set of all term operations of A preserving
Rab, satisﬁes the connectedness condition.
(2) If ab is has the semilattice type and Gr(A) is semilattice-connected, then
Gr(Aab) is semilattice-connected.
(3) If ab has the majority type and Gr(A) is semilattice/majority-connected, then
Gr(Aab) is semilattice/majority-connected.

Recent Results on the Algebraic Approach to the CSP
87
As the following example shows, constructing a reduct by adding an edge of the
aﬃne type can destroy the connectedness condition and even make a tractable
algebra NP-complete.
Example 11. Let A = ({0, 1, 2}; h), where h(x, y, z) = x −y + z and +, −denote
the operation of addition and subtraction modulo 3. It is well known (see e.g.
[39]) that the term operations of A are the operations of the form α1x1 + . . . +
αnxn, where α1, . . . , αn are integers and α1 + . . . + αn = 1 (mod 3). Therefore,
for any a, b ∈A, ⟨a, b⟩= A, the only maximal congruence of ⟨a, b⟩is the equality
relation, and ab is an edge of the aﬃne type.
Since the aﬃne operation x −y + z is an operation of A, the problem CSP(A)
can be solved by Gaussian elimination [30]. Take an edge of Gr(A), say 01 and a
term operation f(x1, . . . , xn) = α1x1+. . .+αnxn of A. If f preserves {0, 1}, then,
for any i ∈{1, . . . , n}, we have f(0, . . . , 0, 1, 0, . . ., 0) = αi ∈{0, 1} (1 is on the
ith place). Furthermore, if αi, αj = 1, then f(0, . . . , 0, 1, 0, . . ., 0, 1, 0, . . ., 0) =
αi + αj = 2 ̸∈{0, 1} (1s are on the ith and jth places). Thus, only one of the αs
is non-zero, which means that f is a projection. Hence, every term operation of
A01 is a projection and CSP(A01) is NP-complete.
Proposition 2 amounts to saying that we may restrict our attention to algebras
A such that every thick edge of the semilattice or majority type of Gr(A) is a
subalgebra.
The second transformation preserving the connectedness condition is based
on the following statement that shows that the term operations certifying the
type of edges can be signiﬁcantly uniﬁed.
Proposition 3. Let A be an idempotent algebra. For an edge, θ always denotes
a congruence certifying its type. There are term operations f, g, h of A such that
f
{a/θ,b/θ} is a semilattice operation if ab is an edge of the semilattice type, it
is the ﬁrst projection if ab is an edge of the majority or aﬃne type;
g
{a/θ,b/θ} is a majority operation if ab is an edge of the majority type, it is the
ﬁrst projection if ab is an edge of the aﬃne type, and g
{a/θ,b/θ}(x, y, z) =
f
{a/θ,b/θ}(x, f
{a/θ,b/θ}(y, z)) if ab has the semilattice type;
h
⟨ab⟩/θ
is an aﬃne operation operation if ab is an edge of the aﬃne type, it is the
ﬁrst projection if ab is an edge of the majority type, and h
{a/θ,b/θab}(x, y, z)=
f
{a/θ,b/θ}(x, f
{a/θ,b/θ}(y, z)) if ab has the semilattice type.
Example 9 (continued). Let us reconsider the algebra A from Example 9. By
Proposition 2, since 12 is an edge of the majority type, the algebra A12 satisﬁes
the connectedness condition. The operations f, g, h satisfying the conditions of
Proposition 3 can be chosen as follows: g is the operation obtained in Example 9,
f(x, y) = g(x, x, y) (the binary operation deﬁned in Example 9 does not ﬁt,
because it does not preserve {1, 2}) and h(x, y, z) = f(x, f(y, z)).

88
A.A. Bulatov and M.A. Valeriote
Propositions 2 and 3 together allow us to restrict ourselves to the study of
idempotent algebras that have at most three basic operations, one binary and
two ternary, and such that, for any edge of the semilattice or majority ab and
a congruence θ certifying this, the thick edge a/θ ∪b/θ is a subalgebra. In the
next section we shall see that the class of algebras to be studied can be further
narrowed down.
Edges of the semilattice type. In this section we focus on edges of the semi-
lattice type of the graph Gr(A). Note ﬁrst that if one ﬁxes a congruence θab for
each edge of Gr(A) that certiﬁes its type, and a term operation f such that f is a
semilattice operation on {a/θab, b/θab} for every edge ab of the semilattice type
of Gr(A), then one can deﬁne an orientation of every such edge. An edge ab of
the semilattice type is oriented from a to b if f(a/θab, b/θab) = f(b/θab, a/θab) =
b/θab. For instance, the edges 01, 02 of the graph from Example 9 are oriented
from 0 to 1 and 2 respectively. Clearly, orientation strongly depends on the choice
of the operation f. The graph Gr(A) oriented accordingly to a term operation f
will be denoted by Grf(A). We then can deﬁne semilattice-connected and strongly
semilattice-connected components of Grf(A). We will also use the natural order
on the set of strongly semilattice-connected components of Grf(A): for compo-
nents A, B, A ≤B if there is a directed path in Grf(A) consisting of edges of the
semilattice type and connecting a vertex from A with a vertex from B. Later
we show that certain restrictions on the set of strongly semilattice-connected
components of Grf(A) yield the tractability of CSP(A).
First we show that if for an edge ab of the semilattice type there is no semi-
lattice term operation on the set {a, b} then ab can be thrown out of the graph
Gr(A) such that the connectedness condition is preserved in the remaining graph.
Therefore, we can assume that for any edge of the semilattice type ab there is a
semilattice term operation on {a, b}.
Proposition 4. Let A be an algebra and Gr′(A) the subgraph of Gr(A) obtained
by omitting edges ab of the semilattice type such that there is no semilattice
operation on {a, b}. Then Gr′(A) is connected. If Gr(A) is semilattice-connected
then Gr′(A) is semilattice-connected. If Gr(A) is semilattice/majority-connected
then Gr′(A) is semilattice/majority-connected.
The graph Gr′(A) oriented according to a binary term operation f will be denoted
by Gr′
f(A).
We conclude this subsection with a result that shows how properties of the
graph Gr(A) can help in establishing the tractability and bounded width of the
algebra A. Let us consider algebras A with a binary term operation f such that,
for every subalgebra B of A, the subgraph of Gr′
f(A) induced by B has a unique
maximal strongly semilattice-connected component. This condition we shall call
the maximal semilattice component condition.
Theorem 14. If an algebra A satisﬁes the maximal semilattice component con-
dition, then CSP(A) is of relational width 3.

Recent Results on the Algebraic Approach to the CSP
89
Observe that a 2-semilattice, that is a groupoid with a 2-semilattice basic opera-
tion, satisﬁes the maximal semilattice component condition. Indeed, if A has a 2-
semilattice term operation f, then f is a semilattice operation on {a, f(a, b)} and
{b, f(a, b) = f(b, a)}. This means that Gr′
f(A) is semilattice-connected. More-
over, if a, b belong to diﬀerent maximal strongly semilattice-connected compo-
nents B and C, then f(a, b) belongs to a strongly semilattice-connected com-
ponent D such that B ≤D and C ≤D, a contradiction with the maximality
of B, C. The same argument is valid for any subalgebra of A, thus, A satisﬁes
the maximal semilattice component condition. Since every semilattice operation
is also a 2-semilattice operation, the same holds for algebras with a semilat-
tice term operation. Thus, by Theorem 14, we obtain the main result of [6],
and also the results of [7], since a binary commutative conservative operation is
a 2-semilattice operation, and also the results of [30,28] concerning semilattice
operations.
5.5
Conservative Algebras and Their Graphs
Let H be a relational structure. In the conservative (list) constraint satisfaction
problem, denoted CCSP(H), the question is, given a structure G and, for each
element g ∈G, a list L(g) of elements of H, whether there exists a homomorphism
ϕ: G →H such that ϕ(g) ∈L(g) for all g ∈G.
Example 12 (List-H-Colouring). Let H be a (directed) graph. In the List
H-Colouring problem we are given a graph G and, for each vertex v of G,
a set L(v) of vertices of H. The question is whether there is a homomorphism
ϕ from G to H such that ϕ(v) ∈L(v) for every vertex v of G. Clearly, List
H-Colouring can be represented in the form of the conservative CSP.
Notice that, for any structure H, the problem CCSP(H) is equivalent to CSP(H∗),
where H∗is an expansion of H obtained by adding all unary relations. A struc-
ture H such that for each subset S ⊆H there is a relational symbol R in the
vocabulary with RH = S is said to be conservative. Thus, instead of conservative
CSPs we may study ordinary constraint satisfaction problems corresponding to
conservative structures.
On the algebraic side, every term operation f of an algebra A that gives rise
to a conservative CSP must be conservative, that is f(x1, . . . , xn) ∈{x1, . . . , xn}
for all x1, . . . , xn. Algebras satisfying this condition are also called conservative.
If A is a conservative algebra, then in particular every 2-element subset of A
induces a subalgebra of A. Therefore, A satisﬁes the connectedness condition if
and only if every pair of its elements constitutes an edge of Gr(A). Moreover,
every edge of this graph is 2-element, implying that the operations f, g, h con-
structed in Proposition 3 are a semilattice (that is conjunction or disjunction)
operation, the majority operation (x ∨y) ∧(y ∨z) ∧(z ∨x), and the Mal’tsev
operation x −y + z(mod 2) on each 2-element subset from A, respectively (we
denote the elements of this subset by 0 and 1).
Theorem 15. A conservative algebra A is tractable if and only if it satisﬁes the
connectedness condition, that is, for any 2-element subalgebra B of A (we assume

90
A.A. Bulatov and M.A. Valeriote
B = {0, 1}), there exists a term operation t such that t
B is either a semilattice
operation x ∨y or x ∧y, or the majority operation (x ∨y) ∧(y ∨z) ∧(z ∨x), or
the Mal’tsev operation x −y + z(mod 2). In this case A is also globally tractable.
Otherwise A is NP-complete.
Observe that by Proposition 3 the tractability of a conservative algebra is wit-
nessed by term operations of arity at most 3. This observation implies a stronger
version of Theorem 15. An algebra such that each of its k-element subsets induces
a subalgebra is called k-conservative.
Corollary 4. If A is a 3-conservative algebra then A is globally tractable if and
only if it satisﬁes the connectedness condition. Otherwise it is NP-complete.
References
1. Allender, E., Bauland, M., Immerman, N., Schnoor, H., Vollmer, H.: The com-
plexity of satisﬁability problems: Reﬁning schaefer’s theorem. In: Jedrzejowicz, J.,
Szepietowski, A. (eds.) MFCS 2005. LNCS, vol. 3618, pp. 71–82. Springer, Heidel-
berg (2005)
2. Berman, J., Idziak, P., Markovi´c, P., McKenzie, R., Valeriote, M., Willard, R.:
Varieties with few subalgebras of powers. Journal of the AMS (to appear)
3. Berman, J.D., Kiss, E.W., Pr¨ohle, P., Szendrei, ´A.: The set of types of a ﬁnitely
generated variety. Discrete Math. 112(1-3), 1–20 (1993)
4. Baker, K.A., Pixley, A.F.: Polynomial interpolation and the chinese remainder
theorem. Mathematische Zeitschrift 143, 165–174 (1975)
5. Bulatov, A.A.: Mal’tsev constraints are tractable. Technical Report PRG-RR-02-
05, Computing Laboratory, University of Oxford, Oxford, UK (2002)
6. Bulatov, A.A.: Combinatorial problems raised from 2-semilattices. Journal of Al-
gebra 298(2), 321–339 (2006)
7. Bulatov, A.A., Jeavons, P.G.: Tractable constraints closed under a binary opera-
tion. Technical Report PRG-TR-12-00, Computing Laboratory, University of Ox-
ford, Oxford, UK (2000)
8. Bulatov,
A.A., Jeavons,
P.G.: Algebraic
structures in combinatorial
prob-
lems.
Technical
Report
MATH-AL-4-2001,
Technische
universit¨at
Dresden,
Dresden, Germany (2001), http://web.comlab.ox.ac.uk/oucl/research/areas/
constraints/publications/index.html
9. Bulatov, A.A., Jeavons, P.G., Volkov, M.V.: Finite semigroups imposing tractable
constraints. In: Gomes, G.M.S., Pin, J.-E., Silva, P.V. (eds.) Semigroups, Algo-
rithms, Automata and Languages, pp. 313–329. World Scientiﬁc, Singapore (2002)
10. Bulatov, A.A.: A graph of a relational structure and constraint satisfaction prob-
lems. In: LICS, pp. 448–457 (2004)
11. Bulatov, A.A.: H-coloring dichotomy revisited. Theor. Comput. Sci. 349(1), 31–39
(2005)
12. Bulatov, A.A.: A dichotomy theorem for constraint satisfaction problems on a 3-
element set. J. ACM 53(1), 66–120 (2006)
13. Bulatov, A.A., Dalmau, V.: A simple algorithm for Mal’tsev constraints. SIAM J.
Comput. 36(1), 16–27 (2006)
14. Bulatov, A.A., Jeavons, P., Krokhin, A.A.: Classifying the complexity of constraints
using ﬁnite algebras. SIAM J. Comput. 34(3), 720–742 (2005)

Recent Results on the Algebraic Approach to the CSP
91
15. Atserias, A., Bulatov, A., Dawar, A.: Aﬃne systems of equations and counting
inﬁnitary logic. In: Arge, L., Cachin, C., Jurdzi´nski, T., Tarlecki, A. (eds.) ICALP
2007. LNCS, vol. 4596. Springer, Heidelberg (2007)
16. Bulatov, A.A., Krokhin, A.A., Larose, B.: Dualities for Constraint Satisfaction
Problems. In: Creignou, N., Kolaitis, P., Vollmer, H. (eds.) Complexity of Con-
straints. LNCS, vol. 5250, pp. 93–124. Springer, Heidelberg (2008)
17. Burris, S., Sankappanavar, H.P.: A course in universal algebra. Graduate Texts in
Mathematics, vol. 78. Springer, New York (1981)
18. Chen, H.: The expressive rate of constraints. Ann. Math. Artif. Intell. 44(4), 341–
352 (2005)
19. Clasen, M., Valeriote, M.: Tame congruence theory. In: Lectures on algebraic model
theory. Fields Inst. Monogr., vol. 15, pp. 67–111. Amer. Math. Soc., Providence
(2002)
20. Dalmau, V.: A new tractable class of constraint satisfaction problems. Annals of
Mathematics and Artiﬁcial Intelligence 44(1-2), 61–85 (2005)
21. Dalmau, V.: Computational Complexity of Problems over Generalised Formulas.
Ph.D thesis, Department LSI of the Universitat Politecnica de Catalunya (UPC),
Barcelona (March 2000)
22. Dalmau, V.: Generalized majority-minority operations are tractable. In: LICS, pp.
438–447 (2005)
23. Dalmau, V., Gavald`a, R., Tesson, P., Th´erien, D.: Tractable clones of polynomials
over semigroups. In: van Beek, P. (ed.) CP 2005. LNCS, vol. 3709, pp. 196–210.
Springer, Heidelberg (2005)
24. Feder, T., Vardi, M.Y.: The computational structure of monotone monadic SNP
and constraint satisfaction: A study through datalog and group theory. SIAM Jour-
nal on Computing 28, 57–104 (1998)
25. Hell, P., Neˇsetˇril, J.: On the complexity of H-coloring. Journal of Combinatorial
Theory, Ser. B 48, 92–110 (1990)
26. Hobby, D., McKenzie, R.N.: The Structure of Finite Algebras. Contemporary
Mathematics, vol. 76. American Mathematical Society, Providence (1988)
27. Idziak, P., Markovi´c, P., McKenzie, R., Valeriote, M., Willard, R.: Tractability and
learnability arising from algebras with few subpowers. In: LICS 2007: Proceedings
of the 22nd Annual IEEE Symposium on Logic in Computer Science, Washington,
DC, USA, pp. 213–224. IEEE Computer Society, Los Alamitos (2007)
28. Jeavons, P.G.: On the algebraic structure of combinatorial problems. Theoretical
Computer Science 200, 185–204 (1998)
29. Jeavons, P.G., Cohen, D.A., Cooper, M.C.: Constraints, consistency and closure.
Artiﬁcial Intelligence 101(1-2), 251–265 (1998)
30. Jeavons, P.G., Cohen, D.A., Gyssens, M.: Closure properties of constraints. Journal
of the ACM 44, 527–548 (1997)
31. Jeavons, P.G., Cohen, D.A., Pearson, J.K.: Constraints and universal algebra. An-
nals of Mathematics and Artiﬁcial Intelligence 24, 51–67 (1998)
32. Larose, B., Loten, C., Tardif, C.: A characterisation of ﬁrst-order constraint satis-
faction problems. In: LICS, pp. 201–210 (2006)
33. Larose, B., Tesson, P.: Universal algebra and hardness results for constraint sat-
isfaction problems. In: Arge, L., Cachin, C., Jurdzi´nski, T., Tarlecki, A. (eds.)
ICALP 2007. LNCS, vol. 4596, pp. 267–278. Springer, Heidelberg (2007)
34. Larose, B., Zadori, L.: Bounded width problems and algebras. Algebra Univer-
salis 56(3-4), 439–466 (2007)
35. Markovi´c, P., McKenzie, R.: Few subpowers, congruence distributivity and near-
unanimity. Algebra Universalis 58(2), 119–128 (2008)

92
A.A. Bulatov and M.A. Valeriote
36. McKenzie, R.N., McNulty, G.F., Taylor, W.F.: Algebras, Lattices and Varieties,
vol. I. Wadsworth and Brooks, California (1987)
37. McKenzie, R., Mar´oti, M.: Existence theorems for weakly symmetric operations.
In: Algebra Universalis (to appear, 2006)
38. Schaefer, T.J.: The complexity of satisﬁability problems. In: Proceedings of the
10th ACM Symposium on Theory of Computing (STOC 1978), pp. 216–226 (1978)
39. Szendrei, A.: Clones in Universal Algebra. Seminaires de Mathematiques Su-
perieures, vol. 99. Universit´e de M´ontreal (1986)
40. Valeriote, M.: A subalgebra intersection property for congruence distributive vari-
eties. Canadian Journal of Mathematics (accepted, 2006)

Dualities for Constraint Satisfaction Problems
Andrei A. Bulatov1, Andrei Krokhin2, and Benoit Larose3
1 School of Computing Science
Simon Fraser University
Burnaby, BC, Canada, V5A 1S6
abulatov@cs.sfu.ca
2 Department of Computer Science
Durham University
Durham, DH1 3LE, UK
andrei.krokhin@durham.ac.uk
3 Department of Mathematics and Statistics
Concordia University
Montr´eal, Qc, Canada, H3G 1M8
larose@mathstat.concordia.ca
Abstract. In a nutshell, a duality for a constraint satisfaction problem
equates the existence of one homomorphism to the non-existence of other
homomorphisms. In this survey paper, we give an overview of logical,
combinatorial, and algebraic aspects of the following forms of duality
for constraint satisfaction problems: ﬁnite duality, bounded pathwidth
duality, and bounded treewidth duality.
1
Introduction
The constraint satisfaction problem (CSP) provides a framework in which it
is possible to express, in a natural way, many combinatorial problems encoun-
tered in artiﬁcial intelligence, computer science, discrete mathematics, and else-
where [19,34,61]. An instance of the constraint satisfaction problem is repre-
sented by a ﬁnite set V of variables, a (ﬁnite) domain D of values for each
variable, and a set of constraints {(s1, R1), . . . , (sq, Rq)}. Each constraint con-
sists of a constraint scope si, which is an mi-tuple of variables, and a constraint
relation Ri ⊆Dmi. The aim is then to decide whether there is an assignment
h : V →D that satisﬁes the constraints, i.e., such that h(si) ∈Ri for all i.
It has been observed [28] (see also [42]) that the constraint satisfaction prob-
lem can be recast as the following fundamental problem: given two ﬁnite re-
lational structures A and B, is there a homomorphism from A to B? One of
the most studied restrictions on the CSP is the non-uniform CSP – when the
structure B is ﬁxed, and only A is part of the input. The obtained problem
is denoted by CSP(B). Examples of such problems include various versions of
k-Sat, Graph Colouring, and Systems of Equations (see [17,34,42,50]).
Strong motivation for studying this framework was given in [28] where it was
shown that such problems can be used in attempts to identify a largest natural
subclass of NP that avoids problems of intermediate complexity.
N. Creignou et al. (Eds.): Complexity of Constraints, LNCS 5250, pp. 93–124, 2008.
c
⃝Springer-Verlag Berlin Heidelberg 2008

94
A.A. Bulatov, A. Krokhin, and B. Larose
The two main general classiﬁcation problems about the class of problems of
the form CSP(B) are:
1. classify the problems CSP(B) with respect to computational complexity, that
is, for a given complexity class K, characterise (under suitable complexity-
theoretic assumptions) structures B such that CSP(B) is in K;
2. classify the problems CSP(B) with respect to descriptive complexity, that
is, for a given logic L, characterise structures B such that CSP(B), as the
class of all structures admitting a homomorphism to B, is deﬁnable in L.
In addition, there is a so-called meta-problem:
3. Determine the (computational) complexity of deciding whether, for a given
structure
B,
CSP(B)
has
a
certain
(computational
or
descriptive)
complexity.
A variety of mathematical approaches to study problems CSP(B) has been
recently suggested. The most advanced approaches use logic (e.g., [48]), combi-
natorics (e.g., [32,34,51]), universal algebra (e.g., [7,10,12,17,41,50]), or combina-
tions of those (e.g., [2,8,20,28,52]). In this survey, we will discuss a combinatorial
idea that has a bearing on all the above problems, and has strong links with the
three approaches — the idea of homomorphism duality.
The concept of duality has been much used to study homomorphism prob-
lems. In essence, a duality equates the existence of one homomorphism to the
non-existence of some other homomorphism(s). The idea is to provide a set OB
of obstructions for B such that, for any relational structure A, A homomorphi-
cally maps to B if and only if A does not admit a homomorphism from any
structure from OB. Of course, the set OB can always be chosen to consist of
all structures that do not homomorphically map to B, but this choice does not
give any information about CSP(B). If, however, OB can be chosen so that it
has certain nice properties then this can tell us much about the computational
or descriptive complexity of CSP(B).
Most of the early studies of dualities were restricted to the case of (di)graphs
(see survey [36], also [34,35,38,39,49,58]). For general relational structures, the
main forms of duality that have been considered in the literature are ﬁnite du-
ality, bounded pathwidth duality, and bounded treewidth duality. We give the
necessary combinatorial, logical, and algebraic preliminaries in Section 2, and
then consider the three dualities in Sections 3, 4, and 5, respectively. Sections 6
and 7 contain some remarks and a list of open problems concerning dualities.
2
Preliminaries
2.1
Basic Deﬁnitions
Most of the terminology introduced in this section is fairly standard. A vocab-
ulary is a ﬁnite set of relation symbols or predicates. In what follows, τ always
denotes a vocabulary. Every relation symbol R in τ has an arity r = ρ(R) ≥0
associated to it. We also say that R is an r-ary relation symbol.

Dualities for Constraint Satisfaction Problems
95
A τ-structure A consists of a set A, called the universe of A, and a relation
RA ⊆Ar for every relation symbol R ∈τ where r is the arity of R. Let maxar(A)
denote the maximum arity of a relation in A. Unless speciﬁed otherwise, all
structures in this paper are assumed to be ﬁnite, i.e., structures with a ﬁnite
universe. Throughout the paper we use the same boldface and slanted capital
letters to denote a structure and its universe, respectively.
Let A and A′ be τ-structures. We say that A′ is a substructure of A, denoted
by A′ ⊆A, if A′ ⊆A and for every R ∈τ, RA′ ⊆RA. If A is a τ-structure and
I ⊆A, then A|I denotes the substructure induced by A on I, i.e., the τ-structure
I with universe I and RI = RA ∩Ir for every r-ary R ∈τ.
A homomorphism from a τ-structure A to a τ-structure B is a mapping
h : A →B such that for every r-ary R ∈τ and every (a1, . . . , ar) ∈RA, we
have (h(a1), . . . , h(ar)) ∈RB. We denote this by h : A →B, and the set of
all homomorphisms from A to B is denoted by hom(A, B). We also say that
A homomorphically maps to B, and write A →B if there is a homomorphism
from A to B and A ̸→B if there is no homomorphism. Now CSP(B) can be
deﬁned to be the class of all structures A such that A →B. The class of all
structures A such that A ̸→B will be denoted by co-CSP(B).
Example 1. If Bhc is a digraph H then CSP(Bhc) is the much-studied problem,
H-colouring, of deciding whether there is a homomorphism from a given di-
graph to H [34]. If H is the complete graph Kk on k vertices then it is well
known (and easy to see) that CSP(Bhc) is precisely the k-colouring problem.
Example 2. If Blhc is a structure obtained from a digraph H by adding, for each
non-empty subset U of H, a unary relation U then CSP(Blhc) is exactly the List
H-colouring problem, in which every vertex v of the input digraph G gets a
list Lv of vertices of H, and the question is whether there is a homomorphism
h : G →H such that h(v) ∈Lv for all v ∈G (see [34]).
Example 3. If Bunr is the Boolean (i.e., with universe {0, 1}) structure with one
binary relation Eq, which is the equality relation, and two unary relations {0}
and {1} then CSP(Bunr) is the (undirected) Unreachability problem where
one is given a graph and two sets of vertices in it, S and T , and the question is
whether there is no path in the graph from any vertex in S to a vertex in T .
Example 4. In the Path System Accessibility problem [31], one is given a
relational structure A with one ternary relation P A, and two unary relations SA
and T A. The unary relations represent “source” and “terminal” nodes, respec-
tively. The question is whether there is an “accessible” terminal node, where a
node x is accessible if x ∈SA or (a, b, x) ∈P A for some accessible a, b ∈A.
Let Bps be the Boolean structure with one ternary relation P Bps = {(x, y, z) |
x∧y →z} and two unary relations SBps = {1} and T Bps = {0}. Then it is easy to
verify that the Path System Accessibility problem is precisely co-CSP(Bps).
Example 5. Let B3H be the structure with universe {0, 1}, one unary rela-
tion U B3H = {1} and two ternary relations P B3H = {0, 1}3 \ {(1, 1, 0)} and

96
A.A. Bulatov, A. Krokhin, and B. Larose
N B3H = {0, 1}3 \ {(1, 1, 1)}. It is easy to see that every Horn 3-CNF formula
ϕ with variables x1, . . . , xn can be represented as a structure Aϕ with universe
{x1, . . . , xn} and relations U Aϕ, P Aϕ, N Aϕ where U Aϕ is the set of all unit
clauses (in ϕ), P Aϕ is the set of all clauses of the form (¬x ∨¬y ∨z), and N Aϕ
is the set of all clauses of the form (¬x ∨¬y ∨¬z). Clearly, we have Aϕ →B3H
if and only if ϕ is satisﬁable. Hence Horn 3-Sat is precisely CSP(B3H).
Example 6. Let Ble be a structure with universe {0, 1}, one ternary relation
{(x, y, z) | x + y + z = 1(mod 2)}, and one unary relation {0}. It is well known,
and easy to verify, that CSP(Ble) is the problem of solving systems of linear
equations (with at most 3 variables per equation) over the two-element ﬁeld.
For any subset I of A, any homomorphism from A|I to B is called a partial
homomorphism from A to B. A projective homomorphism from A to B is a
partial mapping h from A to B such that, for any R ∈τ (say, of arity n) and
any tuple (a1, . . . , an) ∈RA, there exists a tuple (b1, . . . , bn) ∈RB such that
h(ai) = bi for every ai in dom(h), the domain of h. Clearly, every projective
homomorphism is also a partial homomorphism.
A retract of a structure B is an induced substructure B′ of B such that there
is a homomorphism g : B →B′ with g(b) = b for every b ∈B′. In this case we
(trivially) have that CSP(B) and CSP(B′) coincide. A structure is called a core
if it has no homomorphism to any of its proper substructures. A retract of B
that has minimal size among all retracts of B is called a core of B. It is well
known that all cores of a structure are isomorphic, and so one speaks of the core,
core(B), of a structure B.
2.2
Obstructions and Dualities
In order to deﬁne some of our dualities, we will need the notions of pathwidth
and treewidth of relational structures.
Deﬁnition 1. For 0 ≤j ≤k, a τ-structure A is said to have treewidth at most
(j, k) if there is a tree T , called a tree-decomposition of A, such that
1. the nodes of T are subsets of A of size at most k,
2. adjacent nodes can share at most j elements,
3. nodes containing any given element of A form a subtree,
4. for any tuple in any relation in A, there is a node in T containing all ele-
ments from that tuple.
If T is a path then it is called a path-decomposition of A, and A is said to
have pathwidth at most (j, k).
Example 7.
1. Consider the graph G from Fig. 1. The top-left decomposition
shows that G has treewidth at most (1,3), the top-right and the bottom
decompositions imply that G has pathwidth at most (1,5) and at most (2,4),
respectively.

Dualities for Constraint Satisfaction Problems
97
h
i
a
b
c
d
g
e
f
a
b
c
a
b
e
d
a
b
f
g
c
h
i
G has pathwidth at most (2,4)
G has pathwidth
at most (1,5)
G has treewidth 
at most (1,3)
G
Fig. 1. Examples of pathwidth and treewidth
2. Any cycle has pathwidth at most (2,3). Indeed, assume that the nodes of the
cycle are 0, 1, . . ., n−1 and the edges are (i, i+1), where addition is modulo
n. Consider a path with nodes S1, S2, . . . , Sn−2 where Si = {0, i, i + 1}. It is
easy to check that this is a path-decomposition of the cycle.
3. Any tree has treewidth at most (1,2). Indeed, take T to have the edges of
the original tree as nodes and the adjacency relation given by the incidence
relation of edges in the original tree.
Note that we use two numbers to parameterise treewidth and pathwidth, as
is customary in the study of CSPs [20,28,54] (rather than one as is customary in
graph theory [34]), for the following reason. The ﬁrst parameter j gives a more
convenient parameterisation of CSPs, since the second parameter k is bounded
from below by the maximum arity of a relation in a structure, and hence it is
less convenient to use for uniform treatment of structures of diﬀerent vocabu-
laries that behave essentially in the same way with respect to homomorphisms.
Nevertheless, the notions of pathwidth and treewidth of relational structures are
closely related to the corresponding notions from graph theory, as follows. The
Gaifman graph G(A) of a structure A is deﬁned to have the same universe (set
of vertices) as A and the edges of G(A) are the pairs (a, a′) of distinct elements
such that a and a′ appear in the same tuple in some relation in A. Then it is
not hard to check that the following numbers are equal:
– the minimum k such that A has pathwidth (treewidth) at most (k, k + 1),
– pathwidth (treewidth, respectively) of G(A) in the sense of graph theory.
Deﬁnition 2. A set O of τ-structures is called an obstruction set for B if, for
any τ-structure A, A →B if and only if A′ ̸→A for all A′ ∈O.
Note that sometimes such sets are called “complete obstruction sets”.

98
A.A. Bulatov, A. Krokhin, and B. Larose
Deﬁnition 3. A structure B is said to have ﬁnite duality if it has a ﬁnite
obstruction set.
Example 8. Let Tn be the transitive tournament on n vertices, that is, the
universe of Tn is {0, 1, . . ., n −1}, and the only relation is the binary rela-
tion {(i, j) | 0 ≤i < j ≤n −1}. Also, let Pn be the directed path on
n + 1 vertices, that is the structure with universe {0, 1, . . ., n} and the relation
{(i, i + 1) | 0 ≤i ≤n −1}. It is well known (see, e.g., Proposition 1.20 of [34])
and easy to show that, for any digraph G, G →Tn if and only if Pn ̸→G.
Hence, {Pn} is an obstruction set for Tn, and Tn has ﬁnite duality.
Deﬁnition 4. A τ-structure B is said to have (j, k)-pathwidth duality1 if it has
an obstruction set consisting of structures of pathwidth at most (j, k). In other
words, B has (j, k)-pathwidth duality if, for any τ-structure A, we have A →B
if and only if C →A implies C →B for every τ-structure C of pathwidth at
most (j, k).
We say that B has j-pathwidth duality if it has (j, k)-pathwidth duality for
some k ≥j, and B has bounded pathwidth duality if it has j-pathwidth duality
for some j ≥0.
Example 9. It is well known that a graph G is 2-colourable if and only if it
contains no odd cycles, which is the same as to say that G does not admit
a homomorphism from any odd cycle. Since the 2-colourability problem is
the same as CSP(K2), we obtain that the family of all odd cycles forms an
obstruction set for K2. By Example 7, any cycle has pathwidth at most (2,3),
so the structure K2 has (2,3)-pathwidth duality. It is easy to see that K2 does
not have ﬁnite duality.
Deﬁnition 5. By replacing “pathwidth” with “treewidth” throughout Deﬁnition 4,
one obtains the corresponding deﬁnitions of treewidth dualities.
Example 10. The structure Bps from Example 4 has (1,3)-treewidth duality. To
prove this, we need to show that, for any structure A ∈co-CSP(Bps), there
exists a structure C ∈co-CSP(Bps) such that C →A and C has treewidth at
most (1,3). If A ∈co-CSP(Bps) then we can choose some terminal node in A
that can be “accessed” (or “derived”) from the source nodes. It is clear that this
derivation procedure can be represented as a “tree”, as shown in Fig. 2. The
substructure A′ of A (corresponding to the derivation) is shown on the right;
d and e are source nodes, t is a terminal node, and every oval depicts a unit
derivation via a triple from the relation P A. Now modify the structure A′ as
follows: for every element x ∈A′, give new names to the occurrences of x in A′
so that each element in the obtained structure appears either in a single oval or
else in two ovals such that this element is the intersection of the two ovals, and
then modify the set of source nodes accordingly. Let C be the obtained structure
(see Fig. 2, left). It is clear that C has treewidth at most (1,3). Furthermore,
we have C ∈co-CSP(Bps) because a terminal node is still accessible from the
1 Called (j, k)-path duality in [20].

Dualities for Constraint Satisfaction Problems
99
a ∧b
c ∧f
d ∧e
d ∧c
t
d ∧e
e ∧d
a ∧b
c1 ∧f
d3∧e3
d4 ∧c2
t
d1∧e1
e2∧d2
C →A′
Fig. 2. (1,3)-treewidth duality for the structure Bps
source nodes, and we also have that C →A because the reverse renaming of
elements is a homomorphism from C to A′, and hence to A.
2.3
Datalog and Inﬁnitary Logics
For logical descriptions of the three dualities, we use ﬁrst-order logic, the logic
programming language Datalog, and its restriction, linear Datalog, and also some
inﬁnitary ﬁnite-variable logics. We assume that the reader is familiar with ﬁrst-
order logic, and we now brieﬂy describe the basics of Datalog (for more details,
see, e.g., [45]).
Fix a vocabulary τ. A Datalog program is a ﬁnite set of rules of the form
t0 : −t1, . . . , tn where each ti is an atomic formula R(xi1, . . . , xik). Then t0
is called the head of the rule, and the sequence t1, . . . , tn the body of the rule.
The predicates occurring in the heads of the rules are not from τ and are called
IDBs (from “intensional database predicates”), while all other predicates come
from τ and are called EDBs (from “extensional database predicates”). One of
the IDBs, which is usually 0-ary in our case, is designated as the goal predicate
of the program. Since the IDBs may occur in the bodies of rules, each Datalog
program is a recursive speciﬁcation of the IDBs, with semantics obtained via
least ﬁxed-points of monotone operators. The goal predicate is assumed to be
initially set to false, and we say that a Datalog program accepts a τ-structure
A if its goal predicate evaluates to true on A.
For 0 ≤j ≤k, a (j, k)-Datalog program is a Datalog program with at most
j variables in the head and at most k variables per rule. A Datalog program is
called linear if every rule in it has at most one occurrence of an IDB in its body.
A class C of structures is said to be deﬁnable in (linear) (j, k)-Datalog if there is
a (linear) (j, k)-Datalog program which accepts precisely the structures from C.
Note that, for any Datalog program, the class C of all structures accepted by
the program is closed under extension (that is, if a structure A has a substructure
A′ which is in C then A is also in C). Every class of the form co-CSP(B) has
this monotonicity property, but it is not the case for CSP(B). Hence, when using

100
A.A. Bulatov, A. Krokhin, and B. Larose
Datalog to study CSPs, one usually speaks of deﬁnability of co-CSP(B) in (some
version of) Datalog.
Example 11. Consider the structure B3H from Example 5. It is well known that
Horn 3-Sat can be solved by the unit propagation algorithm which can be
represented as the following Datalog program.
T (X) : −U(X)
T (Z) : −P(X, Y, Z), T (X), T (Y )
unsat : −N(X, Y, Z), T (X), T (Y ), T (Z)
Hence, co-CSP(B3H) is deﬁnable in (1,3)-Datalog.
Example 12. The following linear (2,4)-Datalog program accepts a graph (as a
structure with one binary relation E) if and only if the graph is not 2-colourable
Odd(X, Y ) : −E(X, Y )
Odd(X, Y ) : −Odd(X, Z), E(Z, T ), E(T, Y )
non2col
: −Odd(X, X)
It is easy to see how to modify this program so that it accepts a digraph if
and only if the digraph is not 2-colourable (just add all rules obtained from the
second rule by permuting Z, T , and Y in the part E(Z, T ), E(T, Y )). Hence,
co-CSP(K2) is deﬁnable in linear (2,4)-Datalog.
The notion of a canonical (j, k)-Datalog program for a τ-structure B has proved
to be useful in the study of dualities [28]. Let τ = {R1, . . . , Rn}, and let S0,
S1, . . . , Sp be an enumeration of relations of arity j on B that can be expressed
by a ﬁrst-order ∃∧-formula over B. Assume that S0 is the empty relation. For
each Si, introduce a j-ary IDB Ii. Then the canonical (j, k)-Datalog program for
B involves the IDBs I0, . . . , Ip and EDBs R1, . . . , Rn, and contains all the rules
with at most k variables with the following property: if every Ii in the rule is
replaced by Si and every Rs by RB
s , then every assignment of elements of B to
the variables that satisﬁes the conjunction of atomic formulas in the body must
also satisfy the atomic formula in the head. Finally, introduce one 0-ary IDB G
together with the rule G : −I0(x1, . . . , xj), and make G the goal predicate of
the program. The canonical linear (j, k)-Datalog program for B consists of all
linear rules from the canonical program described above.
Our deﬁnitions of inﬁnitary logics are inspired by [20,45,47]. Let L∞ω be the
ﬁrst-order logic extended with inﬁnitary conjunctions 
 and inﬁnitary disjunc-
tions . For every k ≥0, let ∃Lk
∞ω be the existential positive (i.e., without
negation and universal quantiﬁers) fragment of L∞ω with at most k diﬀerent
variables. A (possibly inﬁnitary) conjunction 
 Φ of L∞ω-formulas is said to be
j-restricted if every formula from Φ that contains more than j free variables is
quantiﬁer-free, and it is said to be strongly j-restricted if, in addition, at most
one formula in Φ having quantiﬁers is not a sentence. Then ∃Lj,k
∞ω is the fragment
of ∃Lk
∞ω obtained by using atomic formulas, existential quantiﬁcation, arbitrary

Dualities for Constraint Satisfaction Problems
101
disjunctions, and j-restricted conjunctions. It is known that every class of struc-
tures deﬁnable in (j, k)-Datalog is also deﬁnable in ∃Lj,k
∞ω. The logic ∃M j,k
∞ω
is deﬁned similarly to ∃Lj,k
∞ω, but with strongly j-restricted conjunctions, and
deﬁnability in linear (j, k)-Datalog implies deﬁnability in this logic.
We will also need the inﬁnitary counting logics. Let C∞ω (see [3,55]) be the
logic whose formulas are obtained from atomic formulas by using negation, inﬁni-
tary conjunction and disjunction, and counting quantiﬁers (∃ix for any i ≥0).
The fragment Ck
∞ω consists of those formulas of C∞ω in which at most k distinct
variables appear, and Cω
∞ω = 
k∈ω Ck
∞ω.
2.4
Pebble Games
We will now deﬁne two pebble games, the pebble-relation game and the ex-
istential pebble game, which have proved to be very useful in the analysis of
pathwidth and treewidth dualities. These games have been introduced in [20]
and [46], respectively.
Let 0 ≤j ≤k, and let A and B be τ-structures. The (j, k)-pebble-relation
(or (j, k)-PR) game on (A, B) is played between two players, the Spoiler and
the Duplicator. A conﬁguration of the game consists of a subset I ⊆A with
|I| ≤k and a collection of partial homomorphisms T ⊆hom(A|I, B). If T ⊆
hom(A|I, B) then we say that I is the domain of T . For a subset J ⊆I, let T|J
denote the set {f|J | f ∈T }.
Initially, I = ∅and T contains the (unique) homomorphism from A|∅to B.
Each round of the game consists of a move of the Spoiler and a move of the
Duplicator. Intuitively, the Spoiler has control on the domain I of T , which can
be regarded as placing some pebbles on the elements of A that constitute I,
whereas the Duplicator decides the content of T after the domain I has been set
by the Spoiler. There are two types of rounds: shrinking and blowing rounds.
Let T n be the conﬁguration after the n-th round. The Spoiler decides whether
the following round is a blowing or shrinking round.
– If the (n + 1)-th round is a shrinking round, the Spoiler sets In+1 to be
a non-empty subset of the domain In of T n. The Duplicator responds by
restricting every function in T n onto In+1, that is, T n+1 = T n
|In+1.
– A blowing round only can be performed if |In| ≤j. In this case the Spoiler
sets In+1 to be a superset of In with |In+1| ≤k. The Duplicator responds
by providing a family T n+1 ⊆hom(A|In+1, B) such that T n+1
|In
⊆T n.
The Spoiler wins the game if the response of the Duplicator sets T n+1 to ∅, i.e.,
the Duplicator cannot extend successfully any of the partial homomorphisms
from T n. Otherwise, the game resumes. The Duplicator wins the game if he has
a strategy that allows him to play “forever”, i.e., if the Spoiler can never win
a round of the game. The notion of winning strategy for the Duplicator can be
conveniently formalised as follows.
Deﬁnition 6. Let 0 ≤j < k, and let A and B be τ-structures. We say that the
Duplicator has a winning strategy for the (j, k)-pebble-relation game on (A,B)
if there is a non-empty family H of sets of partial homomorphisms such that:

102
A.A. Bulatov, A. Krokhin, and B. Larose
1. for every T ∈H, T ⊆hom(A|I, B) for some I ⊆A, |I| ≤k, and ∅̸∈T ,
2. H is closed under restrictions: for every T ∈H with domain I and every
I′ ⊆I, we have that T|I′ ∈H,
3. H has the (j, k)-forth property: for every T ∈H with domain I, |I| ≤j, and
every superset I′ of I with |I′| ≤k, there exists T ′ ∈H with domain I′ such
that T ′
|I ⊆T .
The intuition behind the above deﬁnition is that every set T in a winning strategy
corresponds to a winning conﬁguration for the Duplicator in the game.
If we impose the restriction that every conﬁguration in the (j, k)-PR game
consists of a single function (i.e., in every round, the Duplicator commits to
a particular partial homomorphism) then the obtained game is known as the
existential (j, k)-pebble game. The notion of a winning strategy for the Duplicator
in this game is obtained in a natural way from the one in Deﬁnition 6, by
restricting each set T to consist of a single partial homomorphism.
Note that if we have a homomorphism h : A →B then the Duplicator always
has a winning strategy in any PR or existential pebble game on (A, B): to
win, the Duplicator only has to always include the suitable restriction of the
homomorphism h in his response. However, the converse does not always hold.
That is, the existence of a winning strategy for the Duplicator on (A, B) does
not, in general, imply that A →B (see Example 13 below). Thus, the structures
B, for which the converse also holds (for a particular type of game), must have
some special properties. These properties are closely related with dualities, as
we will discuss in Sections 4 and 5.
Example 13. Let A be the undirected cycle with 5 nodes and B the undirected
cycle with 6 nodes. Obviously, we have A ̸→B, but the Duplicator still wins
the existential (1,2)-pebble game. Indeed, ﬁx any two adjacent elements, b1 and
b2 in B, and let the winning strategy simply contain all partial homomorphisms
that have at most two-element domains and range {b1, b2}. It is straightforward
to check that this is indeed a winning strategy. However, it is not hard to verify
that the Spoiler wins the existential (2,3)-pebble game on (A, B).
2.5
Algebraic Background
The algebraic approach to constraint satisfaction (see, e.g., [11,12,13,17,50]) has
proved to be extremely successful. It provides a convenient dual language to
analyse CSPs, and, more importantly, allows one to use powerful machinery
from universal algebra.
First, let us formally deﬁne polymorphisms of relations and structures.
Deﬁnition 7. Let f be an n-ary operation on B, and R a relation on B. Then
f is said to be a polymorphism of R (or R is invariant under f) if, for any tuples
¯a1, . . . , ¯an ∈R, the tuple obtained by applying f componentwise also belongs to
the relation R.
An operation is called a polymorphism of a relational structure if it is a poly-
morphism of every relation in the structure. Let Pol(B) denote the set of all
polymorphisms (of all arities) of a structure B.

Dualities for Constraint Satisfaction Problems
103
For τ-structures B1, . . . , Bn, deﬁne the direct product structure C = n
i=1 Bi to
be a τ-structure with base set C = B1 × . . . × Bn, and, for any m-ary R ∈τ, let
(a1, . . . , am) ∈RC if and only if (a1[i], . . . , am[i]) ∈RBi for each 1 ≤i ≤n. As
usual, the direct product of n copies of a structure B is called the n-th power
of B, and is denoted Bn. It is easy to check that the n-ary polymorphisms of B
are precisely the homomorphisms from Bn to B.
Example 14. It is straightforward to verify that the Boolean relation OR =
{0, 1}2 \ {(0, 0)} is invariant under the binary operation max on {0, 1}, but is
not invariant under the operation min.
One nice feature of the polymorphisms is that they allow one to simultaneously
deal with structures over diﬀerent vocabularies. For example, it is known (see [12]
or [42]) that if τ1-structure B1 and τ2-structure B2 have the same universe and
Pol(B1) ⊆Pol(B2) then every relation in B2 can be deﬁned by a primitive
positive ﬁrst-order formula (i.e., ∃∧-formula with equality) in B1, and hence
the problem CSP(B2) is polynomial-time (even logarithmic-space) reducible to
CSP(B1). In particular, if Pol(B1) = Pol(B2) then CSP(B1) and CSP(B2) are
equivalent. Hence, it is very convenient to group relational structures accord-
ing to their polymorphisms. Note that sets of operations of the form Pol(B)
are clones of operations, they are well-studied objects in universal algebra (see,
e.g., [63]).
We will now deﬁne some types of operations which will be useful in the sub-
sequent sections.
Deﬁnition 8. An n-ary operation f on B is called idempotent if it satisﬁes the
identity f(x, . . . , x) = x.
– A binary commutative idempotent operation f is called a 2-semilattice oper-
ation if it satisﬁes the identity f(x, f(x, y)) = f(x, y).
– An n-ary (n ≥2) operation f is called totally symmetric if f(x1, . . . , xn) =
f(y1, . . . , yn) whenever {x1, . . . , xn} = {y1, . . . , yn}. If, in addition, f is
idempotent then we say that it is a TSI operation.
– An n-ary (n ≥3) operation is called an NU (near-unanimity) operation if it
satisﬁes the identities
f(y, x, . . . , x, x) = f(x, y, . . . , x, x) = . . . = f(x, x, . . . , x, y) = x.
– A ternary NU operation is called a majority operation.
– An n-ary (n ≥2) idempotent operation is called a WNU (weak NU) opera-
tion if it satisﬁes the identities
f(y, x, . . . , x, x) = f(x, y, . . . , x, x) = . . . = f(x, x, . . . , x, y).
Example 15.
1. For any binary idempotent operation f, the following condi-
tions are equivalent: (a) f is a TSI operation, (b) f is a WNU operation,
and (c) f is commutative.

104
A.A. Bulatov, A. Krokhin, and B. Larose
2. A binary operation g is called conservative if g(a, b) ∈{a, b} for all a, b. Any
binary commutative conservative operation is a 2-semilattice operation.
3. Let f be a binary idempotent commutative associative operation. Then f is
called a semilattice operation. It is easy to see that f is also a 2-semilattice
operation, and, for any n≥2, the operation f(x1, f(x2, f(. . . , f(xn−1, xn) . . .)
is a TSI operation.
4. It is easy to check that the (ternary) median operation on a totally ordered
set is a majority operation.
5. Any TSI operation and any NU operation is a WNU operation. Also, the
Boolean aﬃne operation f(x, y, z) = x + y + z(mod 2) is a WNU operation.
Example 16. Schaefer’s celebrated dichotomy theorem for Boolean CSP can be
restated (see, e.g., [12,17,50]) as follows. For a Boolean core structure B, if
B has a semilattice polymorphism, or a majority polymorphism, or the aﬃne
polymorphism, then CSP(B) is in PTIME. In all other cases, CSP(B) is NP-
complete. A reﬁnement of this theorem, including a classiﬁcation for deﬁnability
in Datalog and its restrictions, can be found in [52].
The subsequent deﬁnitions in this subsection are sketchy, for more details see
the surveys [13,16] or the monograph [40].
Deﬁnition 9. A ﬁnite algebra is a pair A = (A, F) where A is a ﬁnite set and
F = (fi)i∈I is a family of ﬁnitary operations on A. For a relational structure B,
the algebra AB = (B, Pol(B)) is called the algebra associated with B.
Deﬁnition 10. A variety is a class of algebras closed under taking homomorphic
images, subalgebras, and (possibly inﬁnite) direct products. The variety generated
by a ﬁnite algebra A, denoted var(A), consists of all homomorphic images of
subalgebras of direct powers of A.
Every ﬁnite algebra A can be assigned a set of types. The types are numbers
from 1 to 5, and they correspond to diﬀerent possible basic “local behaviours”
of the algebra. The correspondence is as follows:
type 1 – unary algebra,
type 2 – vector space over a ﬁnite ﬁeld,
type 3 – 2-element Boolean algebra,
type 4 – 2-element lattice,
type 5 – 2-element semilattice.
A variety is said to admit a type i if this type occurs in some ﬁnite algebra in
the variety, and it omits type i otherwise.
It is known (see [12,13,50]) that if, for a core structure B, the variety var(AB)
admits type 1 (or, equivalently, B has no WNU polymorphism of any arity [57])
then CSP(B) is NP-complete. Moreover, all core structures B that are known
to give rise to NP-complete problems CSP(B) do satisfy this condition. It
has been conjectured that all other core structures give rise to problems in
PTIME, and this conjecture has been conﬁrmed in many important cases (see,
e.g., [7,10,12,13]). For other results about the correspondence between the type
set of var(AB) on one side and the computational and descriptive complexity of
CSP(B) on the other side, see [3,13,52].

Dualities for Constraint Satisfaction Problems
105
3
Finite Duality
Arguably, the simplest case of duality is that of ﬁnite duality. In this section,
we outline several characterisations of constraint satisfaction problems with this
property. We shall address, in particular, questions about the relationship of ﬁ-
nite duality to deﬁnability in ﬁrst-order logic (FO), the nature of the obstruction
set of a structure with ﬁnite duality, and the (meta-)problem of recognising such
structures.
Recall from Example 8 that the transitive tournament Tn has an obstruction
set consisting of a single structure Pn. In general, a structure with ﬁnite duality
might not have a set of obstructions that consists of a single structure:
Example 17. Let B=⟨{0, 1}; R, {0}, {1}⟩where R = {(0, 0), (0, 1), (1, 0)}. View-
ing structures of this type as coloured digraphs (with colours given by the unary
relations), it is easy to see that A ̸→B if and only if there exists a vertex v
of A which is coloured with both colours 0 and 1, or an edge (a, b) with both
endpoints coloured 1. Consequently B has a two-element obstruction set, one
structure A1 consisting of a single vertex with two colours, the other structure
A2 consisting of one directed edge with both ends coloured 1. It is easy to see
that B does not have a one-element obstruction set.
Example 18. Recall the problem Unreachability, or CSP(Bunr) from Exam-
ple 3. It is not diﬃcult to see that Bunr does not have ﬁnite duality. As in
Example 17, we can view structures as coloured digraphs. Note that any path
with ends coloured 0 and 1 does not have a homomorphism to Bunr, but any
proper substructure of the path does. If O is a ﬁnite obstruction set for Bunr,
then one can ﬁnd a long enough path P (with coloured ends) such that ev-
ery structure in O can have only non-surjective homomorphisms (if any) to P.
Hence, either none of the structures in O has a homomorphism to P or some
structure in O has a homomorphism to Bunr. In either case, O cannot be an
obstruction set for Bunr.
It is easy to see that if a structure B has ﬁnite duality then CSP(B) is FO-
deﬁnable; in fact, co-CSP(B) is deﬁnable in existential positive FO, or said
diﬀerently, it is deﬁnable in Datalog without IDBs other than the goal predicate.
Indeed, let C be a τ-structure with C = {c1, . . . , cl}, and consider the following
sentence TC = ∃x1 . . . ∃xl

R∈τ

(ci1,...,cir )∈RC R(xi1, . . . , xir). It is well known
and easy to check that, for any τ-structure A, we have C →A if and only if A
satisﬁes TC. Hence, if O is a ﬁnite obstruction set for a τ-structure B, then a
τ-structure A belongs to co-CSP(B) if and only if the sentence 
C∈O TC holds
true in A.
Atserias ([2], see also [62]) has shown that the converse also holds: if CSP(B)
is FO-deﬁnable then B has ﬁnite duality. We now show how this result follows
from other, more recent, results.
Theorem 1 ([52]). If a structure B does not have ﬁnite duality then CSP(B)
is LOGSPACE-hard under ﬁrst-order reductions.

106
A.A. Bulatov, A. Krokhin, and B. Larose
Recall that the complexity class non-uniform AC0 consists of all languages ac-
cepted by polynomial-size constant-depth families of Boolean circuits (see,
e.g., [55]). It is known that any FO-deﬁnable class of structures belongs to this
complexity class (see Theorem 6.4 of [55]). Moreover, any problem which is
LOGSPACE-hard under ﬁrst-order reductions cannot lie in non-uniform AC0
because there are problems in LOGSPACE which are not in non-uniform AC0
(see [30]) and non-uniform AC0 is closed under ﬁrst-order reductions. These
facts and Theorem 1 imply the following result.
Theorem 2. For any structure B, the following conditions are equivalent:
1. B has ﬁnite duality.
2. CSP(B) is FO-deﬁnable.
3. CSP(B) is in non-uniform AC0.
Let us now consider the question about the nature of ﬁnite obstruction sets.
Deﬁnition 11. Let A be a τ-structure. The incidence multigraph of A, denoted
Inc(A), is deﬁned as the bipartite multigraph with parts A and Block(A), where
Block(A) consists of all pairs (R, a) such that R ∈τ and a ∈RA, and with
edges ea,i,Z joining a ∈A to Z = (R, (a1, . . . , ar)) ∈Block(A) when ai = a. We
say that the structure A is a τ-tree (or simply a tree) if its incidence multigraph
is a tree (in particular, it has no multiple edges).
Theorem 3 ([59,60]). If a ﬁnite structure has ﬁnite duality, then it admits an
obstruction set consisting of ﬁnitely many trees. Conversely, for any ﬁnite set
O of trees, there is a structure B that can be explicitly constructed from O such
that O = OB.
Note that the structure B obtained in the above theorem may not be a core; in
fact, it may be much larger than its core.
We now give an algebraic characterisation of structures with ﬁnite duality.
Deﬁnition 12. Let R be a relation on the set A. An n-ary operation f on A
is a 1-tolerant polymorphism of R if, for any tuples ¯a1, . . . , ¯an at least n −1 of
which belong to R, the tuple obtained by applying f componentwise also belongs
to R.
Theorem 4 ([51]). A structure B has ﬁnite duality if and only if its core has
a 1-tolerant NU polymorphism.
In fact, the arity of such a 1-tolerant NU polymorphism is determined by the
total number of tuples in the relations of minimal obstructions. A structure A
is a critical obstruction of B if A ̸→B and A′ →B for any proper substructure
A′ of A. Call any tuple of any relation of a structure A a hyperedge of this
structure. Then we have the following:
Theorem 5 ([51]). The core of B admits a 1-tolerant NU polymorphism of
arity n+1 if and only if each critical obstruction of B has at most n hyperedges.

Dualities for Constraint Satisfaction Problems
107
Example 19.
1. The transitive tournament Tn of Example 8 admits a 1-tolerant
NU polymorphism of arity n + 1, but none of smaller arity (even though it
has a majority polymorphism).
2. The structure B of Example 17 admits a 1-tolerant NU polymorphism of
arity 4, but not 3. Indeed, if m was a ternary 1-tolerant NU polymorphism
of the relation R of B, we would have (1, 1) = (m(1, 1, 0), m(1, 0, 1)) ∈R,
which is false. On the other hand, it is straightforward to check that the
4-ary operation f such that f(x1, . . . , x4) = 1 if and only if at most one xi
is equal to 0 is a 1-tolerant NU polymorphism of B. This structure also has
a majority polymorphism.
Core structures with ﬁnite duality that admit a majority polymorphism were
described in [56]. For a τ-tree A, we say that an element of A is a leaf if it
is incident to exactly one block in Inc(A). A block of A (i.e., a member of
Block(A)) is said to be pendant if it is incident to at most one non-leaf element,
and it is said to be non-pendant otherwise. We say that a τ-tree is a τ-caterpillar
(or simply a caterpillar) if each of its blocks is incident to at most two non-leaf
elements, and each element is incident to at most two non-pendant blocks.
Theorem 6 ([56]). Let B be a core with ﬁnite duality. Then B has a majority
polymorphism if and only if it has an obstruction set consisting of ﬁnitely many
caterpillars.
Call a relation R on B biredundant if the projection of R onto some two coordi-
nates is the equality relation on some subset C ⊆B with |C| ≥2.
Theorem 7 ([25,51]). Let B1 and B2 be structures such that B1 is a core with
ﬁnite duality and Pol(B1) ⊆Pol(B2). Then the following holds.
1. If B2 does not have ﬁnite duality then CSP(B2) is LOGSPACE-complete.
2. If none of the relations in B2 is biredundant then B2 also has ﬁnite duality.
If B2 is a core then the converse holds as well.
Example 20. We will now describe Boolean structures that are cores with ﬁ-
nite duality. (Boolean non-core structures trivially have this property). It can
be derived from [51,52] that these are precisely the (Boolean) core structures
B without biredundant relations and such that (at least) one of the ternary
operations x ∨(y ∧¯z) and x ∧(y ∨¯z) is a polymorphism of B.
We shall now describe a simple algorithm to determine if a structure B has ﬁnite
duality. A slight modiﬁcation of this algorithm also provides a way of producing
solutions of a CSP with ﬁnite duality. First, we require a few straightforward
deﬁnitions.
Deﬁnition 13. Let A be a structure and let a, b ∈A. We say that the element
a dominates the element b if, in any tuple t in any relation R in A, replacement
in t of any number of occurrences of b by a yields a tuple also in R.

108
A.A. Bulatov, A. Krokhin, and B. Larose
For example, if a dominates b and (b, c, b) ∈R then (a, c, b), (b, c, a), and (a, c, a)
are all in R. Note that this notion is a direct generalisation of the notion of
domination in graph theory.
Recall from Section 2.5 the deﬁnition of the n-th power of a structure. Ob-
viously, the second power B2 of a structure B is called the square of B. The
diagonal ∆(B2) of the square B2 is the substructure of B2 induced by the set
{(b, b) | b ∈B}. Note that ∆(B2) is isomorphic to B.
Deﬁnition 14. A structure A is said to dismantle to its substructure C if there
exists a sequence of induced substructures A0, . . . , Ak of A such that (i) A0 = A,
(ii) Ak = C and (iii) for each 0 ≤j < k the structure Aj+1 is obtained from
Aj by removal of a dominated element of Aj.
It is known [51] that the procedure of dismantling can always be done greedily,
by successively removing arbitrary dominated elements in substructures of A to
eventually obtain C.
Theorem 8 ([51]). A structure B has ﬁnite duality if and only if it has a
retract A whose square A2 dismantles to its diagonal ∆(A2).
Example 21. Consider the tournament T3 (see Example 8). We know that T3
is a core with ﬁnite duality, so its square T2
3 should dismantle to its diagonal.
We will now show that this is indeed the case. The process of dismantling is
shown on Fig. 3. The digraph T2
3 is shown in Fig. 3, top-left. The vertices (2, 0)
and (0, 2) are dominated by all vertices, so they are removed, and the resulting
digraph is shown in Fig. 3, top-right. Next, the vertices (1, 0) and (0, 1) are now
dominated by (0, 0), so they are are removed (see Fig. 3, bottom-left). Finally,
the vertices (1, 2) and (2, 1) are now dominated by (2, 2), so they are removed
as well, which leaves only the diagonal ∆(T2
3), shown in Fig. 3, bottom-right.
From Theorem 8, the problem of recognising structures with ﬁnite duality is in
NP. Indeed, one only needs to guess a mapping φ from B onto its subset A,
and then to check that the induced (by A) substructure A of B is a retract of
B (via φ), then to form the square A2 and, ﬁnally, to check (greedily) that A2
dismantles to its diagonal, which clearly can all be done in polynomial time.
Theorem 9 ([51])
1. The problem of deciding whether a given structure B has ﬁnite duality is
NP-complete.
2. The problem of deciding whether a given structure B is a core with ﬁnite
duality is in PTIME.
We now present a slight modiﬁcation of this algorithm which will yield a solution
to the CSP when one exists. In a product A × B, an element (a, b) is said to be
dominated in the second coordinate if it is dominated by an element of the form
(a, b′). We say that A × B dismantles in the second coordinate to its substructure
C if C can be obtained from A × B by successively removing elements that are
dominated in the second coordinate.

Dualities for Constraint Satisfaction Problems
109
(0,0)
(0,1)
(0,2)
(1,0)
(1,1)
(1,2)
(2,0)
(2,1)
(2,2)
(0,0)
(0,1)
(1,0)
(1,1)
(1,2)
(2,1)
(2,2)
(0,0)
(1,1)
(1,2)
(2,1)
(2,2)
(0,0)
(1,1)
(2,2)
Fig. 3. Dismantling T2
3 to its diagonal
Theorem 10 ([51]). Let B be a core with ﬁnite duality and let A be a structure
similar to B. Let C be a structure with no dominations which is obtained from
A × B by dismantling in the second coordinate. Then A →B if and only if C
is the graph of a homomorphism from A to B.
In other words, the procedure is as follows: (i) dismantle greedily the product
A × B in the second coordinate until no dominations are left; (ii) check if the
resulting set is of the form C = {(a, φ(a)) : a ∈A} for some map φ : A →B;
if it is, verify that φ is a homomorphism. Then either it is and φ is the desired
solution, or else there is no homomorphism from A to B. Note that the result
remains valid not only for cores, but for any structure B whose square dismantles
to the diagonal.
4
Bounded Pathwidth Duality
In this section we consider bounded pathwidth duality, which is a property shared
by all structures B such that CSP(B) is currently known to belong to NL. The
following result ties together pathwidth dualities, linear Datalog, and PR games.
Theorem 11 ([20]). For any structure B, the following conditions are equiva-
lent:
1. B has (j, k)-pathwidth duality.
2. co-CSP(B) is deﬁnable in linear (j, k)-Datalog.

110
A.A. Bulatov, A. Krokhin, and B. Larose
3. co-CSP(B) is deﬁnable by the canonical linear (j, k)-Datalog program for B.
4. co-CSP(B) is deﬁnable in ∃M j,k
∞ω.
5. CSP(B) is the class of all structures A such that the Duplicator wins the
(j, k)-PR game on (A, B).
If these conditions hold then CSP(B) is in NL.
Dalmau [20] also provides other equivalent conditions, including deﬁnability in
other inﬁnitary ﬁnite-variable logics and in fragments of second-order logic.
We will now give examples of structures with bounded pathwidth duality.
Example 22. An oriented path is a digraph obtained from a path by orient-
ing its edges in some way. A digraph is called a local tournament if the set of
out-neighbours of any vertex induces a tournament. For example, all transitive
tournaments and all directed paths (see Example 8) are local tournaments. It
was shown in [37,38] that any digraph H that is an oriented path or an acyclic
local tournament has an obstruction set consisting of oriented paths. Since any
oriented path has pathwidth at most (1,2), it follows that H has (1,2)-pathwidth
duality.
Example 23. An oriented cycle is a digraph obtained from a cycle by orienting its
edges in some way. An oriented cycle is called balanced if it has the same number
of edges in one direction and in the other, and it is unbalanced otherwise. It
was shown in [39] that any unbalanced oriented cycle H has an obstruction
set consisting of oriented paths and oriented cycles. Since oriented cycles have
pathwidth at most (2,3) (see Example 7), such a digraph H has (2,3)-pathwidth
duality. Moreover, if the diﬀerence between the number of edges in H going in
one direction and the number of edges in the other direction is exactly one then
H has an obstruction set consisting only of oriented paths [39], and so it has
(1,2)-pathwidth duality.
Example 24. A binary relation on B is called implicational (or 0/1/all) if it has
one of the following three forms: (1) C × D for some C, D ⊆B, (2) {(c, f(c)) |
c ∈C} for some C ⊆B and some permutation f on B, (3) ({c}×D)∪(C ×{d})
for some C, D ⊆B, c ∈C, and d ∈D. A structure is called implicational if all
of its relations are such. For example, it is easy to show (or see [20]) that the
2-Sat problem can be represented as CSP(B) for an implicational structure B
(with universe {0, 1}). It was shown in [20] that every implicational structure
has (2,3)-pathwidth duality.
Example 25. The class of implicative hitting-set bounded (IHS-B) relations was
introduced in [19]. For k ≥2, a Boolean relation is in k-IHS-B+ if it can be
expressed as a CNF where each clause is of the form ¬x, ¬x ∨y, or x1 ∨. . . ∨xk.
Dually, a Boolean relation is in k-IHS-B−if it can be expressed as a CNF where
each clause is of the form x, ¬x ∨y, or ¬x1 ∨. . .∨¬xk. It was shown in [20] that
any structure Bihs (with universe {0, 1}) all whose relations are in k-IHS-B+
(or in k-IHS-B−) has (k, k −1 + maxar(Bihs))-pathwidth duality.

Dualities for Constraint Satisfaction Problems
111
We mentioned in Section 2.5 that the polymorphisms of a structure B determine
the complexity of CSP(B). Similarly, the polymorphisms determine whether a
structure has bounded pathwidth duality.
Theorem 12 ([25,52]). Let B1 and B2 be relational structures with the same
universe and such that Pol(B1) ⊆Pol(B2). If co-CSP(B1) is deﬁnable in linear
Datalog, then so is co-CSP(B2).
For a structure B, let Bc denote the structure obtained from B by adding all
elements of B as singleton unary relations.
Theorem 13 ([52]). For a core structure B, co-CSP(B) is deﬁnable in linear
Datalog if and only if co-CSP(Bc) is.
Note that the polymorphisms of the structure Bc in the above theorem are
the idempotent polymorphisms of B. Hence, for core structures, the idempotent
polymorphisms determine whether a structure has bounded pathwidth duality.
The only currently known suﬃcient algebraic condition for general structures
to have bounded pathwidth duality is given by the following result:
Theorem 14 ([22]). If |B| = k and B has a majority polymorphism then B
has (3k + 2, 3k + maxar(B))-pathwidth duality.
Note that Theorem 14 can be used to obtain bounded pathwidth duality for
all structures from Examples 22-24 (though, with worse bounds). For example,
it was shown in [26] that any oriented path and any unbalanced oriented cycle
has a majority polymorphism, and the same can be shown for any acyclic local
tournament. If B is an implicational structure then, as shown in [18], B has a
majority polymorphism of a very speciﬁc form, the so-called dual discriminator.
For certain types of structures B, the presence of a majority polymorphism
is the dividing line, for CSP(B), between membership in PTIME (which, by
Theorems 11 and 14, becomes membership in NL) and NP-completeness, that
is, either B has a majority polymorphism or else CSP(B) is NP-complete. For
example, this is the case when B is a structure Blhc (from Example 2) whose un-
derlying digraph H is undirected [27]. A combinatorial description of the bound-
ary for the classiﬁcation can also be found in [27].
The structures Bihs from Example 25, with k ≥3 have bounded pathwidth
duality, but do not have a majority polymorphism. However these structures are
known to have an NU polymorphism of arity k +1. Furthermore, it follows from
known algebraic results (see, e.g., [63]) that a Boolean core structure B has an
NU polymorphism (of some arity) if and only if B has a majority polymorphism
or it is a structure of the form Bihs. Moreover, it can be derived from [52] that in
all other cases B does not have bounded pathwidth duality. That is, we obtain
the following result:
Theorem 15. Let |B| = 2. Then B has bounded pathwidth duality if and only
B has an NU polymorphism of some arity.

112
A.A. Bulatov, A. Krokhin, and B. Larose
It is not known whether the presence of an NU polymorphism is a suﬃcient
condition for general structures to have bounded pathwidth duality. However, it
is known that, in general, this condition is not necessary, i.e., there exist struc-
tures B such that B has bounded pathwidth duality, but no NU polymorphism
of any arity. The simplest (known) structure B with these properties is obtained
as follows. Take the poset Q whose Hasse diagram is shown in Fig. 4. Then B
is obtained from this poset by adding all elements of the universe as singleton
unary relations. An explicit description of the minimal obstructions for B in
which the binary relation is a partial order (i.e., the so-called Q-zigzags) can
be found in [65]. It can be easily derived from this description that B has the
required properties.
Fig. 4. A poset without NU polymorphisms
Let us now consider the question of which structures do not have bounded
pathwidth duality. Trivially, any structure without bounded treewidth duality
cannot have bounded pathwidth duality.
Example 26. Reconsider the structure Bps from Example 4. This structure has
1-treewidth duality, as shown in Example 10. By using the game technique (see
below), it can be shown that Bps does not have bounded pathwidth duality (an
alternative proof of this can be found in [1]).
At present, the most general algebraic necessary condition for the presence of
bounded pathwidth duality is given by the following result.
Theorem 16 ([52]). If a core structure B has bounded pathwidth duality then
the variety var(AB) omits types 1, 2, and 5.
By using Theorem 9.11 of [40], the previous theorem can be re-stated as follows.
Theorem 17. If a core structure B has bounded pathwidth duality then B has
ternary polymorphisms d0, . . . , dn, n ≥2, satisfying the following identities:
d0(x, y, z) = x,
dn(x, y, z) = z,
di(x, y, x) = di+1(x, y, x) for all even i < n,
di(x, y, y) = di+1(x, y, y) for all even i < n,
di(x, x, y) = di+1(x, x, y) for all odd i < n.

Dualities for Constraint Satisfaction Problems
113
Moreover, if a core structure B does not have the polymorphisms described above
(or, equivalently, the variety var(AB) admits at least one of the types 1,2, and
5) then CSP(B) is hard for PTIME or for ModpL (for some prime p) under
ﬁrst-order reductions [52], and thus is unlikely to belong to NL.
One very natural question about pathwidth dualities is whether they form a
proper hierarchy or the hierarchy collapses to some level. That is, the question is
whether there exists a number j such that, for any j′ ≥j, every structure with
j′-pathwidth duality also has j-pathwidth duality.
It follows from Theorem 11 that, in order to prove that a certain structure
B does not have (j, k)-pathwidth duality, one only needs to provide a structure
A such that the Duplicator has a winning strategy in the (j, k)-PR game on
(A, B), but it holds that A ̸→B. This game technique was used in [22] to give a
negative answer to the above question. Let us now describe the structures that
were used in [22].
Let n ≥1 and let Bn be the structure with universe Bn and relations Rl
n,
1 ≤l ≤n, deﬁned as follows. The universe Bn is the set {1, . . ., n} × {1, 2}. For
every 1 ≤l ≤n, Rl
n is a binary symmetric relation on Bn that consists of all
pairs ((i, m), (i′, m′)) satisfying at least one of the following conditions:
– i > l, i = i′, m = m′
– i = i′ = l, m ̸= m′,
– i < l and i′ ≤l,
– i ≤l and i′ < l.
Theorem 18 ([22]). For every n ≥2, the structure Bn does not have n-
pathwidth duality, but Bn has a majority polymorphism (and hence (6n + 2)-
pathwidth duality).
The only known fact concerning the meta-problem for bounded pathwidth du-
ality is that, for any ﬁxed k ≥1, the problem of recognising structures with
(1, k)-pathwidth duality is decidable [20].
5
Bounded Treewidth Duality
In this section we consider bounded treewidth duality. Arguably, it is the most
important duality because it is one of the two most general basic properties of
relational structures B that are known to guarantee that the problem CSP(B)
is solvable in polynomial time (the other property can be found, e.g., in [41]),
and the vast majority of such structures have bounded treewidth duality. The
notion of bounded treewidth duality has strong links with methods of solving
constraint satisfaction problems based on establishing local consistency (see,
e.g., [17,24,34,43]).
The following result links together treewidth dualities, Datalog, inﬁnitary log-
ics, and existential pebble games.

114
A.A. Bulatov, A. Krokhin, and B. Larose
Theorem 19 ([28,47]). For any structure B, the following conditions are equiv-
alent:
1. B has (j, k)-treewidth duality.
2. co-CSP(B) is deﬁnable in (j, k)-Datalog.
3. co-CSP(B) is deﬁnable by the canonical (j, k)-Datalog program for B.
4. co-CSP(B) is expressible in ∃Lj,k
∞ω.
5. CSP(B) consists of all structures A such that Duplicator has a winning
strategy in the existential (j, k)-pebble game on (A,B).
If these conditions hold then CSP(B) is in PTIME.
To prevent possible confusion, we note that the paper [47] speaks about de-
ﬁnability of co-CSP(B) in k-Datalog meaning (k, k)-Datalog (in our notation).
Hence, this does not exactly correspond to k-treewidth duality in our sense.
In [28] and some subsequent papers (e.g., in [54]), problems CSP(B) that
have j-treewidth duality (or bounded treewidth duality) are called width-j (or
bounded width, respectively) problems.
We will now give some examples of structures with and without bounded
treewidth duality. Note that, trivially, every structure with bounded pathwidth
duality also has bounded treewidth duality.
Example 27. Recall the structure B3H from Example 5; the problem CSP(B3H)
is precisely Horn-3-Sat. It follows from Example 11 that B3H has (1,3)-tree-
width duality. By replacing relations P B3H and N B3H in B3H with k-ary rela-
tions P BkH = {0, 1}k\{(1, . . ., 1, 1)} and N BkH = {0, 1}k\{(1, . . ., 1, 0)}, respec-
tively, one obtains a structure BkH such that CSP(BkH) is exactly Horn-k-Sat.
An obvious modiﬁcation of Example 11 shows that BkH has (1, k)-treewidth
duality.
Example 28. Recall from Example 23 that each unbalanced oriented cycle has
(2,3)-pathwidth duality. It was shown in [26] that if H is a balanced oriented
cycle then either it has bounded treewidth duality or CSP(H) is NP-complete.
The description of the boundary between the cases is rather involved.
Example 29. Let τ be the vocabulary (P, S, T, E) where P is ternary, E is bi-
nary, and S and T are unary relation symbols. Consider the τ-structure B with
4-element universe {0, 1, a, b} and relations deﬁned as follows. Reconsider struc-
tures Bps from Example 4 and K2 from Example 9, and assume that the universe
of K2 is {a, b}. If R ∈{P, S, T } then deﬁne RB = RBps, and let EB = EK2.
We claim that the structure B has 2-treewidth duality, but neither 1-treewidth
duality nor bounded pathwidth duality. It is easy to see that if a connected τ-
structure A homomorphically maps to B then either EA is empty or else the
other three relations in A are empty. Hence, B has an obstruction set consisting
of structures from OBps and OK2 (suitably expanded with empty relations) and
of ﬁnitely many structures in which some element appears both in the binary
relation and in one of the other three relations. Since Bps has 1-treewidth du-
ality and K2 has (2,3)-pathwidth duality, we conclude that B has 2-treewidth

Dualities for Constraint Satisfaction Problems
115
duality. On the other hand, Bps does not have bounded pathwidth duality (see
Example 26) and it is straightforward to show that K2 does not have 1-treewidth
duality. Hence, B cannot have either of these two properties.
Example 30. As we know from Example 1, the H-Coloring problem coincides
with the problem CSP(Bhc) where Bhc is the (di)graph H. If H is a bipartite
graph, then core(H) = K2 and CSP(Bhc) coincides with the 2-colourabilty
problem, and Bhc hence has (2,3)-pathwidth duality (see Example 9). If H is
a non-bipartite graph then CSP(Bhc) is NP-complete [33]. It is known (see,
e.g., [34]) that in this case Bhc does not have bounded treewidth duality (without
any complexity-theoretic assumptions).
Example 31. A triad is a digraph obtained from three oriented paths by choosing
one end of each path and identifying these three vertices. It is shown in [2] that
there exists a triad H such that CSP(Bhc) is in PTIME, but H does not have
bounded treewidth duality.
Within the algebraic approach to the CSP, a diﬀerent concept, relational width,
is often very useful, see, e.g., [10]. This concept is applicable even for inﬁnite
sets of relations, but in the case of relational structures (with ﬁnite vocabu-
lary) relational width is strongly related to treewidth duality, as we shall now
see. Relational width is usually (e.g., in [7,9,10,13]) deﬁned using the “variable-
value” form (as given in Section 1) of the constraint satisfaction problem. A
straightforward translation into the homomorphism form goes as follows.
Deﬁnition 15. For k ≥1, a family M = {HI | I ⊆A, |I| ≤k}, where each HI
is a non-empty set of mappings from I to B, is called a k-minimal family for
(A, B) if
1. for any I′ ⊆I ⊆A, |I| ≤k, we have HI′ = {h|I′ | h ∈HI}, and
2. for any I ⊆A with |I| ≤k, any h ∈HI, any (n-ary) R ∈τ, and any
(a1, . . . , an) ∈RA, there exists a tuple (b1, . . . , bn) ∈RB such that
(a) h(ai) = bi for all ai ∈I,
(b) for any J ⊆A with |J| ≤k, there exists h′ ∈HJ such that h′(ai) = bi
for all ai ∈J.
A structure B is said to have relational width k if, for any structure A such
that there is a k-minimal family for (A, B), we have A →B. A structure B has
bounded relational width if it has relational width k for some k.
Note that property 2(a) shows that every member of every HI ∈M is a pro-
jective homomorphism, while properties 1 and 2(b) show that there is strong
compatibility between diﬀerent sets in M.
A duality characterisation of structures of relational width k was obtained
in [21]. Call a structure A a k-reltree if it has a tree-decomposition in which (i)
each node with more than k elements consists of all elements in some tuple in a
relation in A, and (ii) two adjacent nodes can share at most k elements.
Theorem 20 ([21]). A structure has relational width k if and only if it has an
obstruction set consisting of k-reltrees.

116
A.A. Bulatov, A. Krokhin, and B. Larose
The following result can be easily derived from the above theorem.
Corollary 1. For any structure B, the following holds.
1. If B has (j, k)-treewidth duality, then it has relational width k.
2. If B has relational width k and maxar(B) = r, then it has (k, k′)-treewidth
duality where k′ = max(k, r).
In particular, B has bounded treewidth duality if and only if it has bounded
relational width.
Note that Corollary 1 shows that there is a correspondence between the parame-
ters of relational width and treewidth duality, but it does not show how optimal
parameters for these widths are related in general.
We will state results about bounded treewidth duality and bounded relational
width in the way they were stated originally. By the above theorem, one can
translate such results between the widths.
Similarly to Theorems 12 and 13, the (idempotent) polymorphisms determine
whether a (core) structure has bounded treewidth duality.
Theorem 21 ([54]). Let B1 and B2 be relational structures with the same uni-
verse and such that Pol(B1) ⊆Pol(B2). If co-CSP(B2) is deﬁnable in Datalog,
then so is co-CSP(B1).
Theorem 22 ([52]). For a core structure B, co-CSP(B) is deﬁnable in Datalog
if and only if co-CSP(Bc) is.
We will now give examples of polymorphisms that guarantee that a structure
has bounded treewidth duality.
Theorem 23 ([28], see also [43]). If a structure B has a (l+1)-ary NU poly-
morphism then B has l-treewidth duality.
Tree duality is just a shorter name for 1-treewidth duality. It is known [28,51]
that every structure with tree duality has an obstruction set consisting of trees
in the sense of Deﬁnition 11. (Note that this fact does not follow trivially from
the deﬁnition of 1-treewidth duality.) In particular, if a structure B has tree
duality then it has (1, maxar(B))-treewidth duality. Structures with tree duality
have been completely characterised in [28]. To state this result, we need to give
a certain construction. For a τ-structure B, its power structure is a τ-structure
P1(B) with universe consisting of all non-empty subsets of B, and, for each r-ary
R ∈τ, we have (A1, . . . , Ar) ∈RP1(B) if and only if, for each 1 ≤i ≤r and
each a ∈Ai, there is (a1, . . . , ar) ∈RB such that ai = a.
Theorem 24 ([28], see also [24]). For any structure B, the following condi-
tions are equivalent:
1. B has tree duality.
2. The structure P1(B) admits a homomorphism to B.
3. For every n ≥2, B has an n-ary totally symmetric polymorphism.

Dualities for Constraint Satisfaction Problems
117
Example 32. It is not diﬃcult to see that, for n ≥2, the operation fn = 
n
i=1 xi
is a TSI polymorphism of the structure BkH (see Example 27).
Structures with caterpillar duality (see Theorem 6 for ﬁnite caterpillar duality)
can be characterised in the spirit of Theorem 24, see [14] for details.
Theorem 20 implies that every structure has relational width 1 if and only
if it has 1-treewidth duality. Note that, in general, the optimal parameters for
relational width and treewidth duality need not be equal. For example, the
structure B = K2 of Example 9 has (2,3)-treewidth duality, but not tree duality
(since it has no binary TSI polymorphism). On the other hand, K2 has relational
width 3 by Corollary 1, but not 2 (which can be seen by taking K3 as A). In
fact, it is shown in [21] that if a structure B has relational width 2 then it has
relational width 1.
Theorem 25 ([9]). If a structure B has a 2-semilattice polymorphism then B
has relational width 3.
Some of the most studied varieties in universal algebra are the so-called con-
gruence distributive varieties (see, e.g., [40,44,64]). For a core structure B, the
algebra AB belongs to a congruence distributive variety if, for some n ≥2, B
has ternary polymorphisms d0, . . . , dn (called J´onsson operations) satisfying the
identities from Theorem 17, and, in addition, such that di(x, y, x) = x for all
0 ≤i ≤n. In this case we say that AB is in the class CD(n). Note that AB is in
CD(2) if and only if B has a majority polymorphism (which is d1 in this case).
Theorem 26 ([44]). For any structure B, if the algebra AB is in CD(3) then
B has relational width min(|B|2, max(3, maxar(B))).
Theorem 27 ([15]). For any structure B, if the algebra AB is in CD(4) then
B has (k −1, k)-treewidth duality where k = max(3, maxar(B)).
Theorem 21 makes it possible to introduce algebras having bounded treewidth
duality: An algebra A = (B; F) has bounded treewidth duality if every structure
B with universe B such that F ⊆Pol(B) has bounded treewidth duality. The
following result shows that bounded treewidth duality can be lifted further to
varieties of algebras.
Theorem 28 ([54]). If A is an algebra with bounded treewidth duality then
every ﬁnite algebra from the variety var(A) also has bounded treewidth duality.
Clearly, if CSP(B) is NP-complete, then it does not have bounded treewidth
duality unless PTIME = NP. Systems of linear equations (see Example 6 in this
paper or the proof of Theorem 1 of [8]), as well as problems that can “simulate”
them, provide benchmark examples of structures B such that CSP(B) is in
PTIME, but B does not have bounded treewidth duality [28]. Combining these
two reasons for not having bounded treewidth duality, one obtains the following
equivalent necessary conditions for bounded treewidth duality.

118
A.A. Bulatov, A. Krokhin, and B. Larose
Theorem 29. If a core structure B has bounded treewidth duality then the fol-
lowing equivalent conditions hold:
1. The variety var(AB) omits types 1 and 2.
2. There is k ≥2 such that B has n-ary weak NU polymorphisms for all n ≥k.
In the above theorem, the necessity of condition (1) was proved in [54], and
the equivalence of conditions (1) and (2) in [57]. It is shown in [53] that (the
complement of) condition (1) is very closely related with the so-called property
of “ability to count” which was introduced in [28] and conjectured there to be
the main obstacle for a structure to have bounded treewidth duality.
Conjecture 1 ([54]). A core structure B has bounded treewidth duality if and
only if the equivalent conditions from Theorem 29 hold.
A somewhat diﬀerent way of applying algebras to analyse a relational structure
B, via an edge-coloured graph Gr(B) of the structure, was introduced in [8] (see
also [13]). The conditions in Theorem 29 can be equivalently expressed in terms
of properties of this graph, and a conjecture equivalent to Conjecture 1 was made
in [8,13].
Conjecture 1 was conﬁrmed in the following important cases, and, interest-
ingly, the best possible bound for some width turns out to be quite small.
Theorem 30 ([28]). If B is a 2-element core structure then B has bounded
treewidth if and only if B has a semilattice polymorphism or a majority poly-
morphism. Moreover, in this case B has 2-treewidth duality.
A factor of an algebra A is a homomorphic image of a subalgebra of A.
Theorem 31 ([10]). If B is a core structure with |B| ≤3 then B has bounded
relational width if and only if the algebra AB itself or each of its factors have an
operation (depending on a factor) which is a majority operation or a 2-semilattice
operation. Moreover, in this case B has relational width 3.
Theorem 32 ([7]). Let B be a structure containing all unary relations. Then B
has bounded relational width if and only if, for each two-element subset C ⊆B,
there is a polymorphism f ∈Pol(B) (depending on C) such that f|C is either
a semilattice operation or a majority operation. Moreover, in this case B has
relational width 3.
Conjecture 1 can be strengthened in the following sense. As we saw above,
bounded treewidth duality is equivalent to expressibility in a certain inﬁnitary
logic. The expressive power of this logic is relatively weak, and it is natural to
ask if it possible to express constraint satisfaction problems in terms of a more
powerful logic. One such logic is Cω
∞ω (see Section 2.3). This logic can express a
number of undecidable problems (e.g., the halting problem). However, if Con-
jecture 1 is true than its expressive power for constraint satisfaction problems is
no greater than that of Datalog.

Dualities for Constraint Satisfaction Problems
119
Theorem 33 ([3]). Let B be a structure. If the variety var(AB) admits type 1
or 2 then CSP(B) is not expressible in Cω
∞ω.
In the direction of solving the meta-problem for bounded treewidth, the following
is known.
Theorem 34 ([64]). There is a polynomial time algorithm which, given a ﬁnite
idempotent algebra A, checks whether the variety var(A) omits types 1 and 2.
Following a strategy from [11] where the case of omitting type 1 is treated,
Theorem 34 can be used to show that, for a core structure B with at most n
elements (where n is any ﬁxed number), it can be checked in polynomial time
whether the variety var(AB) omits types 1 and 2. Thus, we have the following
corollary.
Corollary 2. Assuming Conjecture 1 holds, the meta-problem for bounded tree-
width duality is tractable for structures of bounded size.
It is a natural question to determine the complexity of recognising structures
with j-treewidth duality for a ﬁxed j. For j = 1, it follows from Theorem 24
that this problem is decidable, while the proof of Theorem 6.1 of [51] implies the
following lower bound.
Theorem 35 ([51]). It is NP-hard to decide whether a given structure B has
tree duality.
In Section 4, we have considered the hierarchy problem for j-pathwidth duali-
ties and found (see Theorem 18) that the hierarchy does not collapse. We now
consider a similar problem for j-treewidth dualities. Let T Wj be the class of all
structures with j-treewidth duality. Clearly, we have a hierarchy T W1 ⊆T W2 ⊆
T W3 ⊆T W4 ⊆. . . .
It is easy to show that T W1 ⊊T W2. Consider the problem 2-colourability,
or CSP(K2), from Example 9. The structure K2 has (2,3)-pathwidth duality,
and hence (2,3)-treewidth duality. On the other hand, it is easy to see that K2
does not have a binary commutative polymorphism, and hence, by Theorem 24
(see also Example 15(1)), it cannot have 1-treewidth duality. Surprisingly, the
question whether any other inclusion in the treewidth duality hierarchy is strict
remains open. It may seem that Theorems 23, 26 and 27 contradict this claim.
However, they give only an upper bound for the treewidth duality. For instance,
every 2-element structure with an NU polymorphism has 2-treewidth duality.
6
Additional Remarks
6.1
Symmetric Datalog
A restriction of linear Datalog, symmetric Datalog, has been recently introduced
in [25]. A linear Datalog program is called symmetric, if, for every rule of the
form t0 : −t1, t2, . . . , tn (n ≥1), where t0 and t1 are IDBs, that appears in the

120
A.A. Bulatov, A. Krokhin, and B. Larose
program, the program also contains its “symmetric” rule t1 : −t0, t2, . . . , tn,
obtained by formally swapping the IDBs in the rule. We say that co-CSP(B) is
deﬁnable in symmetric Datalog if it is accepted by a symmetric Datalog program.
In broad terms, symmetric Datalog for CSP is to LOGSPACE what linear
Datalog for CSP is to NL: if co-CSP(B) is deﬁnable in symmetric Datalog
then CSP(B) is in LOGSPACE, and, for all problems CSP(B) that are known
to be in LOGSPACE, co-CSP(B) is deﬁnable in symmetric Datalog [25]. In
particular, this holds for all Boolean problems CSP(B) in LOGSPACE. If B1
and B2 are structures such that Pol(B1) ⊆Pol(B2) and co-CSP(B1) is deﬁnable
in symmetric Datalog, then co-CSP(B2) is also deﬁnable in symmetric Datalog
(compare with Theorems 12 and 21). The following analog of Theorems 16 and 29
holds for symmetric Datalog: for a core structure B, if co-CSP(B) is deﬁnable
in symmetric Datalog then the variety var(AB) omits types 1, 2, 4, and 5 (i.e.,
it admits only type 3) [52]. It is proved in [23] that if co-CSP(B) is deﬁnable
in Datalog and B has a Mal’tsev polymorphism (i.e., a ternary polymorphism
m with m(x, y, y) = m(y, y, x) = x for all x, y) then co-CSP(B) is deﬁnable
in symmetric Datalog. It is shown in [25] that deﬁnability of co-CSP(B) in
symmetric Datalog is equivalent to deﬁnability in a certain fragment of second
order logic (this parallels a result in [20]). It would be interesting to ﬁnd a
convenient pebble game and an appropriate notion of duality for symmetric
Datalog, in the spirit of Theorems 11 and 19.
6.2
Extending Datalog with Inequality and Negation
One can extend (j, k)-Datalog, and the logic ∃Lj,k
∞ω by allowing the use of in-
equalities (̸=) and negated atomic formulas (which must be EDBs in the case of
Datalog). The obtained logics are denoted (j, k)-Datalog(̸=, ¬) and ∃Lj,k
∞ω(̸=, ¬),
respectively. It was shown in [29] that these extensions do not add any expres-
sive power for homomorphism-closed classes (e.g., such as co-CSP(B)). In other
words, if a class co-CSP(B) is deﬁnable in (j, k)-Datalog(̸=, ¬) then it is also
deﬁnable in (j, k)-Datalog, and the same holds for ∃Lj,k
∞ω(̸=, ¬). Moreover, a
closer inspection of the proof reveals that this result remains true for linear
(j, k)-Datalog and the logic ∃M j,k
∞ω.
6.3
Inﬁnite CSP
Up until now we have considered only ﬁnite structures. However, one can also
consider the problem of deciding whether a given ﬁnite τ-structure admits a
homomorphism to a ﬁxed inﬁnite τ-structure B (see survey [4]). Some natural
problems such as Betweenness (see [31]) and the Acyclicity problem for di-
graphs can be represented as CSP(B) for suitable inﬁnitely countable structures
B (but not for any ﬁnite structure B). Bounded treewidth duality for inﬁnitely
countable structures has been considered in [5,6]. It was shown in these papers
that, for general countable structures, Theorem 19 fails. However, there is a large

Dualities for Constraint Satisfaction Problems
121
class of structures (ω-categorical structures), for which Theorem 19 holds. Recall
that a structure B is called ω-categorical if, for each n ≥1, there are only ﬁnitely
many inequivalent ﬁrst-order formulas with n free variables over B. Moreover,
analogs of Theorems 23 and 24 hold for such structures.
7
A List of Open Questions
1. If B is a core structure with ﬁnite duality, how large can the minimal arity
of its 1-tolerant NU polymorphism be?
2. Is the property of having j-pathwidth and j-treewidth duality for ﬁxed j
determined by the polymorphisms of a structure?
3. Is it true that a structure B has bounded pathwidth duality whenever
CSP(B) is in NL?
4. Prove that every structure with an NU polymorphism has bounded path-
width duality.
5. Are the conditions in Theorems 16 and 17 necessary and suﬃcient for a core
structure to have bounded pathwidth duality?
6. Prove Conjecture 1 (that the conditions in Theorem 29 are necessary and
suﬃcient for a core structure to have bounded treewidth duality).2
7. For j ≥2, is there a structure Pj(B) such that B has j-treewidth duality if
and only if Pj(B) →B (particularly, for j = 2)?
8. Does the treewidth duality hierarchy collapse (in particular, to its second
level) or not?
9. Are there structures that have bounded relational width, but not relational
width 3?
10. Is it true that the number k from Theorem 29 can always be chosen to be
equal to 3?
11. Prove that a structure B has bounded treewidth (or even bounded path-
width) duality whenever the algebra AB is in CD(n) for some n?
12. Find a pebble-game and a duality characterisation for structures B such that
co-CSP(B) is deﬁnable in symmetric Datalog.
13. Is it true that co-CSP(B) is deﬁnable in symmetric Datalog whenever CSP(B)
is in LOGSPACE?
14. Is it true that, for a core structure B, co-CSP(B) is deﬁnable in symmetric
Datalog whenever the variety var(AB) admits only type 3?
15. Are there other naturally arising dualities for the CSP?
Acknowledgements
The authors would like to thank Catarina Carvalho, V´ıctor Dalmau, Pavol Hell,
Jarik Neˇsetˇril, Claude Tardif and Pascal Tesson for useful discussions and helpful
comments. Remarks from an anonymous reviewer are also appreciated.
2 While this article was in press, a solution to problem 6 was announced by L. Barto
and M. Kozik.

122
A.A. Bulatov, A. Krokhin, and B. Larose
References
1. Afrati, F., Cosmodakis, S.: Expressiveness of restricted recursive queries. In: STOC
1989, pp. 113–126 (1989)
2. Atserias, A.: On digraph coloring problems and treewidth duality. European Jour-
nal of Combinatorics 29(4), 796–820 (2008)
3. Atserias, A., Bulatov, A., Dawar, A.: Aﬃne systems of equations and counting
inﬁnitary logic. In: Arge, L., Cachin, C., Jurdzi´nski, T., Tarlecki, A. (eds.) ICALP
2007. LNCS, vol. 4596, pp. 558–570. Springer, Heidelberg (2007)
4. Bodirsky, M.: Constraint satisfaction problems with inﬁnite templates. In:
Creignou, N., Kolaitis, P.G., Vollmer, H. (eds.) Complexity of Constraints. LNCS,
vol. 5250. Springer, Heidelberg (2008)
5. Bodirsky, M., Dalmau, V.: Datalog and constraint satisfaction with inﬁnite tem-
plates. In: Durand, B., Thomas, W. (eds.) STACS 2006. LNCS, vol. 3884, pp.
646–659. Springer, Heidelberg (2006)
6. Bodirsky, M., Dalmau, V.: Datalog and constraint satisfaction with inﬁnite tem-
plates (2008) arXiv: 0809.2386v1
7. Bulatov, A.: Tractable conservative constraint satisfaction problems. In: LICS 2003,
pp. 321–330 (2003)
8. Bulatov, A.: A graph of a relational structure and constraint satisfaction problems.
In: LICS 2004, pp. 448–457 (2004)
9. Bulatov, A.: Combinatorial problems raised from 2-semilattices. Journal of Alge-
bra 298(2), 321–339 (2006)
10. Bulatov, A.: A dichotomy theorem for constraint satisfaction problems on a 3-
element set. Journal of the ACM 53(1), 66–120 (2006)
11. Bulatov, A., Jeavons, P.: Algebraic structures in combinatorial problems. Technical
Report MATH-AL-4-2001, Technische Universit¨at Dresden, Germany (2001)
12. Bulatov, A., Jeavons, P., Krokhin, A.: Classifying complexity of constraints using
ﬁnite algebras. SIAM Journal on Computing 34(3), 720–742 (2005)
13. Bulatov, A., Valeriote, M.: Recent results on the algebraic approach to the CSP.
In: Creignou, N., Kolaitis, P., Vollmer, H. (eds.) Complexity of Constraints. LNCS,
vol. 5250, pp. 68–92. Springer, Heidelberg (2008)
14. Carvalho, C., Dalmau, V., Krokhin, A.: Caterpillar duality for constraint satisfac-
tion problems. In: LICS 2008, pp. 307–316 (2008)
15. Carvalho, C., Dalmau, V., Markovi´c, P., Mar´oti, M.: CD(4) has bounded width.
Algebra Universalis (accepted)
16. Clasen, M., Valeriote, M.: Tame congruence theory. In: Lectures on Algebraic
Model Theory. Fields Institute Monographs, vol. 15, pp. 67–111 (2002)
17. Cohen, D., Jeavons, P.: The complexity of constraint languages. In: Rossi, F., van
Beek, P., Walsh, T. (eds.) Handbook of Constraint Programming, ch. 8. Elsevier,
Amsterdam (2006)
18. Cooper, M.C., Cohen, D.A., Jeavons, P.G.: Characterising tractable constraints.
Artiﬁcial Intelligence 65, 347–361 (1994)
19. Creignou, N., Khanna, S., Sudan, M.: Complexity Classiﬁcations of Boolean Con-
straint Satisfaction Problems. SIAM Monographs on Discrete Mathematics and
Applications, vol. 7 (2001)
20. Dalmau, V.: Linear Datalog and bounded path duality for relational structures.
Logical Methods in Computer Science 1(1) (2005) (electronic)
21. Dalmau, V.: There are no pure relational width 2 constraint satisfaction problems
(submitted, 2008)

Dualities for Constraint Satisfaction Problems
123
22. Dalmau, V., Krokhin, A.: Majority constraints have bounded pathwidth duality.
European Journal of Combinatorics 29(4), 821–837 (2008)
23. Dalmau, V., Larose, B.: Maltsev + Datalog ⇒Symmetric Datalog. In: LICS 2008,
pp. 297–306 (2008)
24. Dalmau, V., Pearson, J.: Set functions and width 1 problems. In: Jaﬀar, J. (ed.)
CP 1999. LNCS, vol. 1713, pp. 159–173. Springer, Heidelberg (1999)
25. Egri, L., Larose, B., Tesson, P.: Symmetric Datalog and constraint satisfaction
problems in Logspace. In: LICS 2007, pp. 193–202 (2007)
26. Feder, T.: Classiﬁcation of homomorphisms to oriented cycles and of k-partite
satisﬁability. SIAM Journal on Discrete Mathematics 14(4), 471–480 (2001)
27. Feder, T., Hell, P., Huang, J.: Bi-arc graphs and the complexity of list homomor-
phisms. Journal of Graph Theory 42, 61–80 (2003)
28. Feder, T., Vardi, M.Y.: The computational structure of monotone monadic SNP
and constraint satisfaction: A study through Datalog and group theory. SIAM
Journal on Computing 28, 57–104 (1998)
29. Feder, T., Vardi, M.Y.: Homomorphism closed vs. existential positive. In: Proc.
18th IEEE Symp. on Logic in Computer Science, LICS 2003, pp. 311–320 (2003)
30. Furst, M., Saxe, J., Sipser, M.: Parity, circuits, and the polynomial-time hierarchy.
Mathematical Systems Theory 17(1), 13–27 (1984)
31. Garey, M., Johnson, D.S.: Computers and Intractability: A Guide to the Theory
of NP-Completeness. Freeman, San Francisco (1979)
32. Hell, P.: From graph colouring to constraint satisfaction: there and back again.
In: Topics in Discrete Mathematics. Algorithms and Combinatorics, vol. 26, pp.
407–432. Springer, Heidelberg (2006)
33. Hell, P., Neˇsetˇril, J.: On the complexity of H-coloring. Journal of Combinatorial
Theory, Ser. B 48, 92–110 (1990)
34. Hell, P., Neˇsetˇril, J.: Graphs and Homomorphisms. Oxford University Press, Oxford
(2004)
35. Hell, P., Neˇsetˇril, J., Zhu, X.: Duality and polynomial testing of tree homomor-
phisms. Trans. Amer. Math. Soc. 348, 147–156 (1996)
36. Hell, P., Neˇsetˇril, J., Zhu, X.: Duality of graph homomorphisms. In: Combinatorics,
Paul Erd¨os is Eighty. Bolyai Soc. Math. Stud., vol. 2, pp. 271–282. J´anos Bolyai
Math. Soc. (1996)
37. Hell, P., Zhou, H., Zhu, X.: On homomorphisms to acyclic local tournaments.
Journal of Graph Theory 20(4), 467–471 (1995)
38. Hell, P., Zhu, X.: Homomorphisms to oriented paths. Discrete Mathematics 132,
107–114 (1994)
39. Hell, P., Zhu, X.: The existence of homomorphisms to oriented cycles. SIAM Jour-
nal on Discrete Mathematics 8, 208–222 (1995)
40. Hobby, D., McKenzie, R.N.: The Structure of Finite Algebras. Contemporary
Mathematics, vol. 76. American Mathematical Society, Providence (1988)
41. Idziak, P., Markovic, P., McKenzie, R., Valeriote, M., Willard, R.: Tractability and
learnability arising from algebras with few subpowers. In: LICS 2007, pp. 213–222
(2007)
42. Jeavons, P.: On the algebraic structure of combinatorial problems. Theoretical
Computer Science 200, 185–204 (1998)
43. Jeavons, P.G., Cohen, D.A., Cooper, M.C.: Constraints, consistency and closure.
Artiﬁcial Intelligence 101(1-2), 251–265 (1998)
44. Kiss, E.W., Valeriote, M.: On tractability and congruence distributivity. Logical
Methods in Computer Science 3(2) (2007) (electronic)

124
A.A. Bulatov, A. Krokhin, and B. Larose
45. Kolaitis, P.G.: On the expressive power of logics on ﬁnite models. In: Finite Model
Theory and its Applications. EATCS Series: Texts in Theoretical Computer Sci-
ence, pp. 27–124. Springer, Heidelberg (2007)
46. Kolaitis, P.G., Vardi, M.Y.: On the expressive power of Datalog: tools and a case
study. Journal of Computer and System Sciences 51, 110–134 (1995)
47. Kolaitis, P.G., Vardi, M.Y.: Conjunctive-query containment and constraint satis-
faction. Journal of Computer and System Sciences 61, 302–332 (2000)
48. Kolaitis, P.G., Vardi, M.Y.: A logical approach to constraint satisfaction. In: Finite
Model Theory and its Applications. EATCS Series: Texts in Theoretical Computer
Science, pp. 339–370. Springer, Heidelberg (2007)
49. Kom´arek, P.: Some new good characterisations of directed graphs. ˇCasopis Pˇest.
Mat. 51, 348–354 (1984)
50. Krokhin, A., Bulatov, A., Jeavons, P.: The complexity of constraint satisfaction: an
algebraic approach. In: Structural Theory of Automata, Semigroups, and Universal
Algebra. NATO Science Series II: Math., Phys., Chem., vol. 207, pp. 181–213.
Springer, Heidelberg (2005)
51. Larose, B., Loten, C., Tardif, C.: A characterisation of ﬁrst-order constraint satis-
faction problems. Logical Methods in Computer Science 3(4) (2007) (electronic)
52. Larose, B., Tesson, P.: Universal algebra and hardness results for constraint sat-
isfaction problems. In: Arge, L., Cachin, C., Jurdzi´nski, T., Tarlecki, A. (eds.)
ICALP 2007. LNCS, vol. 4596, pp. 267–278. Springer, Heidelberg (2007)
53. Larose, B., Valeriote, M., Z´adori, L.: Omitting types, bounded width and the ability
to count (submitted, 2008)
54. Larose, B., Z´adori, L.: Bounded width problems and algebras. Algebra Univer-
salis 56(3-4), 439–466 (2007)
55. Libkin, L.: Elements of Finite Model Theory. EATCS Series: Texts in Theoretical
Computer Science. Springer, Heidelberg (2004)
56. Loten, C., Tardif, C.: Majority functions on structures with ﬁnite duality. European
Journal of Combinatorics 29(4), 979–986 (2008)
57. Mar´oti, M., McKenzie, R.: Existence theorems for weakly symmetric operations.
In: Algebra Universalis (to appear, 2007)
58. Neˇsetˇril, J., Pultr, A.: On classes of relations and graphs determined by subobjects
and factorobjects. Discrete Mathematics 22, 287–300 (1978)
59. Neˇsetˇril, J., Tardif, C.: Duality theorems for ﬁnite structures (characterising gaps
and good characterisations). Journal of Combinatorial Theory, Ser. B 80, 80–97
(2000)
60. Neˇsetˇril, J., Tardif, C.: Short answers to exponentially long questions: extremal
aspects of homomorphism duality. SIAM Journal on Discrete Mathematics 19(4),
914–920 (2005)
61. Rossi, F., van Beek, P., Walsh, T. (eds.): Handbook of Constraint Programming.
Elsevier, Amsterdam (2006)
62. Rossman, B.: Existential positive types and preservation under homomorphisms.
In: LICS 2005, pp. 467–476 (2005)
63. Szendrei, A.: Clones in Universal Algebra. Seminaires de Mathematiques Su-
perieures, vol. 99. University of Montreal (1986)
64. Valeriote, M.: A subalgebra intersection property for congruence-distributive vari-
eties. Canadian Journal of Mathematics (to appear, 2007)
65. Z´adori, L.: Posets, near-unanimity functions and zigzags. Bulletin of the Australian
Mathematical Society 47, 79–93 (1993)

A Logical Approach to Constraint Satisfaction
Phokion G. Kolaitis1 and Moshe Y. Vardi2
1 IBM Almaden Research Center, Computer Science Principles and Methodologies
and Computer Science Department, University of California, Santa Cruz
kolaitis@almaden.ibm.com, kolaitis@cs.ucsc.edu
2 Department of Computer Science, Rice University, 6100 S. Main Street,
Houston, TX 77005-1892
vardi@rice.edu
1
Introduction
Since the early 1970s, researchers in artiﬁcial intelligence (AI) have investigated
a class of combinatorial problems that became known as constraint-satisfaction
problems (CSP). The input to such a problem consists of a set of variables, a set of
possible values for the variables, and a set of constraints between the variables;
the question is to determine whether there is an assignment of values to the
variables that satisﬁes the given constraints. The study of constraint satisfaction
occupies a prominent place in artiﬁcial intelligence, because many problems that
arise in diﬀerent areas can be modelled as constraint-satisfaction problems in
a natural way; these areas include Boolean satisﬁability, temporal reasoning,
belief maintenance, machine vision, and scheduling (cf. [Dec92a,Kum92,Mes89,
Tsa93]). In its full generality, constraint satisfaction is an NP-complete problem.
For this reason, researchers in artiﬁcial intelligence have pursued both heuristics
for constraint-satisfaction problems and tractable cases obtained by imposing
various restrictions on the input (cf. [MF93,Dec92a,DM94,Fro97,PJ97]).
Over the past decade, it has become clear that there is an intimate connec-
tion between constraint satisfaction and various problems in database theory and
ﬁnite-model theory. The goal of this chapter is to describe several such connec-
tions. We start in Section 2 by deﬁning the constraint-satisfaction problem and
showing how it can be phrased also as a homomorphism problem, conjunctive-
query evaluation problem, or join-evaluation problem. In Section 3, we discuss
the computational complexity of constraint satisfaction and show that it can be
studied from two perspectives, a uniform perspective and a non-uniform perspec-
tive. We relate both perspectives to the study of the computational complexity of
query evaluation. In Section 4, we focus on the non-uniform case and describe a
Dichotomy Conjecture, asserting that every non-uniform constraint-satisfaction
problem is either in PTIME or NP-complete. In Section 5, we examine the com-
plexity of non-uniform constraint satisfaction from a logical perspective and show
that it is related to the data complexity of a fragment of existential second-order
logic. We then go on in Section 6 and oﬀer a logical approach, via deﬁnability in
Datalog, to establishing the tractability of non-uniform constraint-satisfaction
problems. In Section 7, we leverage the connection between Datalog and certain
N. Creignou et al. (Eds.): Complexity of Constraints, LNCS 5250, pp. 125–155, 2008.
c
⃝Springer-Verlag Berlin Heidelberg 2008

126
P.G. Kolaitis and M.Y. Vardi
pebble games, and show how these pebble games oﬀer an algorithmic approach
to solving uniform constraint-satisfaction problems. In Section 8, we relate these
pebble games to consistency properties of constraint-satisfaction instances, a
well-known approach in constraint solving. Finally, in Section 9, we show how
the same pebble games can be used to identify large “islands of tractability”
in the constraint-satisfaction terrain that are based on the concept of bounded
treewidth.
Much of the logical machinery used in this chapter is described in detail
in [GKL+05, Chapter 2]. For a book-length treatment of constraint satisfac-
tion from the perspective of graph homomorphism, see [HN04]. Two books on
constraint programming and constraint processing are [Apt03,Dec03].
2
Preliminaries
The standard terminology in AI formalizes an instance P of constraint satisfac-
tion as a triple (V, D, C), where
1. V is a set of variables;
2. D is a set of values, referred to as the domain;
3. C is a collection of constraints C1, . . . , Cq, where each constraint Ci is a
pair (t, R) with t a k-tuple over V , k ≥1, referred to as the scope of the
constraint, and R a k-relation on D.
A solution of such an instance is a mapping h : V →D such that, for each
constraint (t, R) in C, we have that h(t) ∈R, where h is deﬁned on tuples
component-wise, that is, if t = (a1, . . . , ak), then h(t) = (h(a1), . . . , h(ak)). The
constraint-satisfaction problem asks whether a given instance is solvable,
i.e., whether it has a solution. Note that, without loss of generality, we may
assume that all constraints (t, Ri) involving the same scope t have been consol-
idated to a single constraint (t, R), where R is the intersection of all relations
Ri constraining t. Thus, we can assume that each tuple t of variables occurs at
most once in the collection C.
Consider the Boolean satisﬁability problem 3-Sat: given a 3CNF-formula ϕ
with variables x1, . . . , xn and clauses c1, . . . , cm, is ϕ satisﬁable? Such an in-
stance of 3-Sat can be thought of as the constraint-satisfaction instance in
which the set of variables is V = {x1, . . . , xn}, the domain is D = {0, 1}, and
the constraints are determined by the clauses of ϕ. For example, a clause of the
form (¬x ∨¬y ∨z) gives rise to the constraint ((x, y, z), {0, 1}3 −{(1, 1, 0)}).
In an analogous manner, 3-Colorability can be modelled as a constraint-
satisfaction problem. Indeed, an instance G = (V, E) of 3-Colorability can
be thought of as the constraint-satisfaction instance in which the set of variables
is the set V of the nodes of the graph G, the domain is the set D = {r, b, g} of
three colors, and the constraints are the pairs ((u, v), Q), where (u, v) ∈E and
Q = {(r, b)(b, r), (r, g)(g, r), (b, g)(g, b)} is the disequality relation on D.
Let A and B be two relational structures1 over the same vocabulary. A ho-
momorphism h from A to B is a mapping h : A →B from the universe A of A
1 We consider only ﬁnite structures in this chapter.

A Logical Approach to Constraint Satisfaction
127
to the universe B of B such that, for every relation RA of A and every tuple
(a1, . . . , ak) ∈RA, we have that (h(a1), . . . , h(ak)) ∈RB. The existence of a
homomorphism from A to B is denoted by A →B, or by A →h B, when we
want to name the homomorphism h explicitly. An important observation made
in [FV98]2 is that every such constraint-satisfaction instance P = (V, D, C) can
be viewed as an instance of the homomorphism problem, asking whether there
is a homomorphism between two structures AP and BP that are obtained from
P in the following way:
1. the universe of AP is V and the universe of BP is D;
2. the relations of BP are the distinct relations R occurring in C;
3. the relations of AP are deﬁned as follows: for each distinct relation R on
D occurring in C, we have the relation RA = {t : (t, R) ∈C}. Thus, RA
consists of all scopes associated with R.
We call (AP, BP) the homomorphism instance of P. Conversely, it is also clear
that every instance of the homomorphism problem between two structures A
and B can be viewed as a constraint-satisfaction instance CSP(A, B) by simply
“breaking up” each relation RA on A as follows: we generate a constraint (t, RB)
for each t ∈RA. We call CSP(A, B) the constraint-satisfaction instance of
(A, B). Thus, as pointed out in [FV98], the constraint-satisfaction problem can
be identiﬁed with the homomorphism problem.
To illustrate the passage from the constraint-satisfaction problem to the ho-
momorphism problem, let us consider 3-Sat. A 3CNF-formula ϕ with vari-
ables x1, . . . , xn and clauses c1, . . . , cm gives rise to a homomorphism instance
(Aϕ, Bϕ) deﬁned as follows:
– Aϕ = ({x1, . . . , xn}, Rϕ
0 , Rϕ
1 , Rϕ
2 , Rϕ
3 ), where Rϕ
i is the ternary relation con-
sisting of all triples (x, y, z) of variables that occur in a clause of ϕ with i
negated literals, 0 ≤i ≤3; for instance, Rϕ
2 consists of all triples (x, y, z) of
variables such that (¬x ∨¬y ∨z) is a clause of ϕ (here, we assume without
loss of generality that the negated literals precede the positive literals).
– Bϕ = ({0, 1}, R0, R1, R2, R3), where Ri consists of all triples that satisfy a
3-clause in which the ﬁrst i literals are negated; for instance, R2 = {0, 1}3 −
{1, 1, 0}.
Note that Bϕ does not depend on ϕ. It is clear that ϕ is satisﬁable if and only
if there is a homomorphism from Aϕ to Bϕ (in symbols, Aϕ →Bϕ).
As another example, 3-Colorability is equivalent to the problem of deciding
whether there is a homomorphism h from a given graph G to the complete graph
K3 = ({r, b, g}, {(r, b)(b, r), (r, g)(g, r), (b, g)(g, b)} with 3 nodes. More generally,
k-Colorability, k ≥2, amounts to the existence of a homomorphism from
a given graph G to the complete graph Kk with k nodes (also known as the
k-clique).
Numerous other important NP-complete problems can be viewed as special
cases of the Homomorphism Problem (and, hence, also of the Constraint-
Satisfaction Problem). For example, consider the Clique problem: given a
2 An early version appeared in [FV93].

128
P.G. Kolaitis and M.Y. Vardi
graph G and an integer k, does G contain a clique of size k? As a homomor-
phism instance this is equivalent to asking if there is a homomorphism from
the complete graph Kk to G. As a constraint-satisfaction instance, the set of
variables is {1, 2, . . ., k}, the domain is the set V of nodes of G, and the con-
straints are the pairs ((i, j), E) such that i ̸= j, 1 ≤i, j ≤k, and E is the edge
relation of G. For another example, consider the Hamiltonicity Problem:
given a graph G = (V, E) does it have a Hamiltonian cycle? This is equivalent
to asking if there is a homomorphism from the structure (V, CV , ̸=) to the struc-
ture (V, E, ̸=), where CV is some cycle on the set V of nodes of G and ̸= is the
disequality relation on V . NP-completeness of the Homomorphism problem was
pointed out explicitly in [Lev73]. In this chapter, we use both the traditional AI
formulation of constraint satisfaction and the formulation as the homomorphism
problem, as each has its own advantages.
It turns out that in both formulations constraint satisfaction can be expressed
as a database-theoretic problem. We start with the homomorphism formulation,
which is intimately related to conjunctive-query evaluation [KV00a]. A conjunc-
tive query Q of arity n is a query deﬁnable by a positive existential ﬁrst-order
formula ϕ(X1, . . . , Xn) having conjunction as its only propositional connective,
that is, by a formula of the form
∃Z1 . . . ∃Zmψ(X1, . . . , Xn, Z1, . . . , Zm),
where ψ(X1, . . . , Xn, Z1, . . . , Zm) is a conjunction of (positive) atomic formulas.
The free variables X1, . . . , Xn of the deﬁning formula are called the distinguished
variables of Q. Such a conjunctive query is usually written as a rule, whose head
is Q(X1, . . . , Xn) and whose body is ψ(X1, . . . , Xn, Z1, . . . , Zm). For example,
the formula
∃Z1∃Z2(P(X1, Z1, Z2) ∧R(Z2, Z3) ∧R(Z3, X2))
deﬁnes a binary conjunctive query Q, which as a rule becomes
Q(X1, X2) :- P(X1, Z1, Z2), R(Z2, Z3), R(Z3, X2).
If the formula deﬁning a conjunctive query Q has no free variables (i.e., if it is
a sentence), then Q is a Boolean conjunctive query. For example, the sentence
∃Z1∃Z2∃Z3(E(Z1, Z2) ∧E(Z2, Z3) ∧E(Z3, Z1))
deﬁnes the Boolean conjunctive query “is there a cycle of length 3?”.
If D is a databaseand Q is a n-ary query, then Q(D) is the n-ary relation on
D obtained by evaluating the query Q on D, that is, the collection of all n-tuples
from D that satisfy the query (cf. [GKL+05, Chapter 2]). The conjunctive-
query evaluation problem asks: given a n-ary query Q, a database D, and
a n-tuple a from D, does a ∈Q(D)? Let Q1 and Q2 be two n-ary queries having
the same tuple of distinguished variables. We say that Q1 is contained in Q2, and
write Q1 ⊆Q2, if Q1(D) ⊆Q2(D) for every database D. The conjunctive-
query containment problem asks: given two conjunctive queries Q1 and Q2,

A Logical Approach to Constraint Satisfaction
129
is Q1 ⊆Q2? These concepts can be deﬁned for Boolean conjunctive queries
in an analogous manner. In particular, if Q is a Boolean query and D is a
database, then Q(D) = 1 if D satisﬁes Q; otherwise, Q(D) = 0. Moreover, the
containment problem for Boolean queries Q1 and Q2 is equivalent to asking
whether Q1 logically implies Q2.
It is well known that conjunctive-query containment can be reformulated both
as a conjunctive-query evaluation problem and as a homomorphism problem.
What links these problems together is the canonical database DQ associated
with Q. This database is deﬁned as follows. Each variable occurring in Q is con-
sidered a distinct element in the universe of DQ. Every predicate in the body of
Q is a predicate of DQ as well; moreover, for every distinguished variable Xi of
Q, there is a distinct monadic predicate Pi (not occurring in Q). Every subgoal
in the body of Q gives rise to a tuple in the corresponding predicate of DQ;
moreover, if Xi is a distinguished variable of Q, then Pi(Xi) is also a (monadic)
tuple of DQ. Thus, returning to the preceding example, the canonical database
of the conjunctive query ∃Z1∃Z2(P(X1, Z1, Z2)∧R(Z2, Z3)∧R(Z3, X2)) consists
of the facts P(X1, Z1, Z2), R(Z2, Z3), R(Z3, X2), P1(X1), P2(X2). The relation-
ship between conjunctive-query containment, conjunctive-query evaluation, and
homomorphisms is provided by the following classical result, due to Chandra
and Merlin.
Theorem 2.1.
[CM77] Let Q1 and Q2 be two conjunctive queries having the
same tuple (X1, . . . , Xn) of distinguished variables. Then the following state-
ments are equivalent.
– Q1 ⊆Q2.
– (X1, . . . , Xn) ∈Q2(DQ1).
– There is a homomorphism h : DQ2 →DQ1.
It follows that the homomorphism problem can be viewed as a conjunctive-
query evaluation problem or as a conjunctive-query containment problem. For
this, with every structure A, we view the universe A = {X1, . . . , Xn} of A as a
set of individual variables and associate with A the Boolean conjunctive query
∃X1 . . . ∃Xn ∧t∈RA R(t); we call this query the canonical conjunctive query of A
and denote it by QA. It is clear that A is isomorphic to the canonical database
associated with QA.
Corollary 2.2. Let A and B be two structures over the same vocabulary. Then
the following statements are equivalent.
– A →B.
– B |= QA.
– QB ⊆QA.
As an illustration, we have that a graph G is 3-colorable iﬀK3 |= QG iﬀ
QK3 ⊆QG.
A relational join, denoted by the symbol 1, is a conjunctive query with no ex-
istentially quantiﬁed variables. Thus, relational-join evaluation is a special case

130
P.G. Kolaitis and M.Y. Vardi
of conjunctive-query evaluation. For example, E(Z1, Z2)∧E(Z2, Z3)∧E(Z3, Z1)
is a relational join that, when evaluated on a graph G = (V, E), returns all
triples of nodes forming a 3-cycle. There is a well known connection between
the traditional AI formulation of constraint satisfaction and relational-join eval-
uation that we describe next. Suppose we are given a constraint-satisfaction
instance (V, D, C). We can assume without loss of generality that in every con-
straint (t, R) ∈C the elements in t are distinct. (Suppose to the contrary that
ti = tj. Then we can delete from R every tuple in which the ith and jth en-
tries disagree, and then project out that j-th column from t and R.) We can
thus view every element of V as a relational attribute, every tuple of distinct
elements of V as a relational schema, and every constraint (t, R) as a relation R
over the schema t (cf. [AHV95]). It now follows from the deﬁnition of constraint
satisfaction that CSP can be viewed as a relational-join evaluation problem.
Proposition 2.3.
[Bib88, GJC94] A constraint-satisfaction instance (V, D, C)
is solvable if and only if 1(t,R)∈C R is nonempty.
Note that Proposition 2.3 is essentially the same as Corollary 2.2. Indeed, the
condition B |= QA amounts to the non-emptiness of the relational join obtained
from QA by dropping all existential quantiﬁers and using the relations from B as
interpretations of the relational symbols in QA. Moreover, the homomorphisms
from A to B are precisely the tuples in the relational join associated with the
constraint-satisfaction instance CSP(A, B).
3
Computational Complexity of Constraint Satisfaction
The Constraint-Satisfaction Problem is NP-complete, because it is clearly
in NP and also contains NP-hard problems as special cases, including 3-Sat,
3-Colorability, and Clique. As explained in Garey and Johnson’s classic
monograph [GJ79], one of the main ways to cope with NP-completeness is to
identify polynomial-time solvable cases of the problem at hand that are obtained
by imposing restrictions on the possible inputs. For instance, Horn 3-Sat, the
restriction of 3-Sat to Horn 3CNF-formulas, is solvable in polynomial-time us-
ing a unit-propagation algorithm. Similarly, it is known that 3-Colorability
restricted to graphs of bounded treewidth is solvable in polynomial time (see
[DF99]). In the case of constraint satisfaction, the pursuit of tractable cases has
evolved over the years from the discovery of isolated cases to the discovery of
large “islands of tractability” of constraint satisfaction. In what follows, we will
give an account of some of the progress made in this area. Using the fact that the
Constraint-Satisfaction Problem can be identiﬁed with the Homomor-
phism Problem, we begin by introducing some terminology and notation that
will enable us to formalize the concept of an “island of tractability” of constraint
satisfaction.
In general, an instance of the Homomorphism Problem consists of two
relational structures A and B. Thus, all restricted cases of this problem can be
obtained by imposing restrictions on the input structures A and B.

A Logical Approach to Constraint Satisfaction
131
Deﬁnition 3.1. Let A, B be two classes of relational structures. We write
CSP(A, B) to denote the restriction of the Homomorphism Problem to in-
put structures from A and B. In other words,
CSP(A, B) = {(A, B) : A ∈A, B ∈B and A →B}.
An island of tractability of constraint satisfaction is a pair (A, B) of classes
of relational structures such that CSP(A, B) is in the complexity class PTIME
of all decision problems solvable in polynomial time.
(A more general deﬁnition of islands of tractability of constraint satisfaction
would consider classes of pairs (A, B) of structures, cf. [FF05]; we do not pursue
this more general deﬁnition here.)
The ultimate goal in the pursuit of islands of tractability of constraint satis-
faction is to identify or characterize classes A and B of relational structures such
that CSP(A, B) is in PTIME. The basic starting point in this investigation is to
consider the cases in which one of the two classes A, B is as small as possible,
while the other is as large as possible. This amounts to considering the cases
in which one of A, B is the class All of all relational structures over some arbi-
trary, but ﬁxed, relational vocabulary, while the other is a singleton, consisting of
some ﬁxed structure over that vocabulary. Thus, the starting points of the inves-
tigation is to determine, for ﬁxed relational structures A, B, the computational
complexity of the decision problems CSP({A}, All) and CSP(All, {B}).
Clearly, for each ﬁxed A, the decision problem CSP({A}, All) can be solved in
polynomial time, because, given a structure B, the existence of a homomorphism
from A to B can be checked by testing all functions h from the universe A of
A to the universe B of B (the total number of such functions is |B||A|, which
is a polynomial number in the size of the structure B when A is ﬁxed). Thus,
having a singleton structure “on the left’ is of little interest.
At the other extreme, however, the situation is quite diﬀerent, since the com-
putational complexity of CSP(All, {B}) may very well depend on the partic-
ular structure B. Indeed, CSP(All, {K3}) is NP-complete, because it is the
3-Colorability problem; in contrast, CSP(All, {K2}) is in P, because it is
the 2-Colorability problem. For simplicity, in what follows, for every ﬁxed
structure B, we deﬁne CSP(B) = CSP(All, {B}) and call this the non-uniform
constraint-satisfaction problem associated with B. For such problems, we refer
to B as the template. Thus, the ﬁrst major goal in the study of the computa-
tional complexity of constraint satisfaction is to identify those templates B for
which CSP(B) is in PTIME. This goals gives rise to an important open decision
problem.
The Tractability Classification Problem: Given a relational structure
B, decide if CSP(B) is in PTIME.
In addition to the family of non-uniform constraint-satisfaction problems
CSP(B), where B is a relational structure, we also study decision problems of
the form CSP(A, All), where A is a class of structures. We refer to such problems
as uniform constraint-satisfaction problems.

132
P.G. Kolaitis and M.Y. Vardi
It is illuminating to consider the complexity of uniform and non-uniform con-
straint satisfaction from the perspective of query evaluation. As argued in [Var82]
(see [GKL+05, Chapter 2]), there are three ways to measure the complexity of
evaluating queries (we focus here on Boolean queries) expressible in a query
language L:
– The combined complexity of L is the complexity of the following decision
problem: given an L-query Q and a structure A, does A |= Q? In symbols,
{⟨Q, A⟩: Q ∈L and A |= Q}.
– The expression complexity of L is the complexity of the following decision
problems, one for each ﬁxed structure A:
{Q : Q ∈L and A |= Q}.
– The data complexity of L is the complexity of the following decision problems,
one for each ﬁxed query Q ∈L:
{A : A |= Q}.
As discussed in [GKL+05, Chapter 2], the data complexity of ﬁrst-order logic
is in LOGSPACE, which means that, for each ﬁrst-order query Q, the problem
{A : A |= Q} is in LOGSPACE. In contrast, the combined complexity for ﬁrst-
order logic is PSPACE-complete. Furthermore, the expression complexity for
ﬁrst-order logic is also PSPACE-complete. In fact, for all but trivial structures
A, the problem {Q : Q ∈FO and A |= Q} is PSPACE-complete. This exponen-
tial gap between data complexity, on one hand, and combined and expression
complexity, on the other hand, is typical [Var82]. For conjunctive queries, on the
other hand, both combined and expression complexity are NP-complete.
Consider now the uniform constraint-satisfaction problem CSP(A, All) =
{(A, B) : A ∈A, and A →B}, where A is a class of structures. By Corol-
lary 2.2, we have that
CSP(A, All) = {(A, B) : A ∈A, B is a structure and B |= QA}.
Thus, studying the complexity of uniform constraint satisfaction amounts to
studying the combined complexity for a class of conjunctive queries, as, for exam-
ple, in [CR97,GLS99b,Sar91]. In contrast, consider the non-uniform constraint-
satisfaction problem CSP(B) = {A : A →B}. By Corollary 2.2 we have that
CSP(B) = {A : B |= QA}. Thus, studying the complexity of non-uniform con-
straint satisfaction amounts to studying the expression complexity of conjunctive
queries with respect to diﬀerent structures. This is a problem that has not been
studied in the context of database theory.
4
Non-uniform Constraint Satisfaction
The ﬁrst major result in the study of non-uniform constraint-satisfaction prob-
lems was obtained by Schaefer [Sch78], who, in eﬀect, classiﬁed the computa-
tional complexity of all Boolean non-uniform constraint-satisfaction problems.

A Logical Approach to Constraint Satisfaction
133
A Boolean structure is simply a relational structure with a 2-element universe,
that is, a structure of the form B = ({0, 1}, RB
1 , . . . , RB
m). A Boolean non-uniform
constraint-satisfaction problem is a problem of the form CSP(B) with a Boolean
template B. These problems are also known as Generalized-Satisfiability
Problems, because they can be viewed as variants of Boolean-satisﬁability prob-
lems in which the formulas are conjunctions of generalized connectives [GJ79].
In particular, they contain the well known problems k-Sat, k ≥2, 1-in-3-
Sat, Positive 1-in-3-Sat, Not-All-Equal 3-Sat, and Monotone 3-Sat
as special cases. For example, as seen earlier, 3-Sat is CSP(B), where B =
({0, 1}, R0, R1, R2, R3) and Ri is the set of all triples that satisfy a 3-clause in
which the ﬁrst i-literals are negated, i = 0, 1, 2, 3 (thus, R0 = {0, 1}3−{(0, 0, 0)}).
Similarly, Monotone 3-SAT is CSP(B), where B = ({0, 1}, R0, R3).
Ladner [Lad75] showed that if PTIME ̸= NP, then there are decision prob-
lems in NP that are neither NP-complete, nor belong to PTIME. Such problems
are called intermediate problems. Consequently, it is conceivable that a given
family of NP-problems contains intermediate problems. Schaefer [Sch78], how-
ever, showed that the family of all Boolean non-uniform constraint-satisfaction
problems contains no intermediate problems.
Theorem 4.1. (Schaefer’s Dichotomy Theorem [Sch78])
– If B = ({0, 1}, RB
1 , . . . , RB
m) is Boolean structure, then either CSP(B) is in
PTIME or CSP(B) is NP-complete.
– The Tractability Classification Problem for Boolean structures is
decidable; in fact, there is a polynomial-time algorithm to decide, given a
Boolean structure B, whether CSP(B) is in PTIME or is NP-complete.
Schaefer’s Dichotomy Theorem can be described pictorially as follows:
↗
NP-complete
CSP(B)
NP −PTIME, not NP-complete
↘
P
Schaefer [Sch78] actually showed that there are exactly six types of Boolean
structures such that CSP(B) is in PTIME, and provided explicit descriptions of
them. Speciﬁcally, he showed that CSP(B) is in PTIME precisely when at least
one of the following six conditions is satisﬁed:
– Every relation RB
i , 1 ≤i ≤m, of B is 0-valid, that is, RB
i
contains the
all-zeroes tuple (0, . . . , 0).
– Every relation RB
i , 1 ≤i ≤m, of B is 1-valid, that is, RB
i
contains the
all-ones tuple (1, . . . , 1).

134
P.G. Kolaitis and M.Y. Vardi
– Every relation RB
i , 1 ≤i ≤m, of B is bijunctive, that is, RB
i is the set of
truth assignments satisfying some 2-CNF formula.
– Every relation RB
i , 1 ≤i ≤m, of B is Horn, that is, RB
i is the set of truth
assignments satisfying some Horn formula.
– Every relation RB
i , 1 ≤i ≤m, of B is dual Horn, that is, RB
i is the set of
truth assignments satisfying some dual Horn formula.
– Every relation RB
i , 1 ≤i ≤m, of B is aﬃne, that is, RB
i
is the set of
solutions to a system of linear equations over the two-element ﬁeld.
Schaefer’s Dichotomy Theorem established a dichotomy and a decidable clas-
siﬁcation of the complexity of CSP(B) for Boolean templates B. After this, Hell
and Neˇsetˇril [HN90] established a dichotomy theorem for CSP(B) problems in
which the template B is an undirected graph: if B is bipartite, then CSP(B)
is solvable in polynomial time; otherwise, CSP(B) is NP-complete. To illus-
trate this dichotomy theorem, let Cn, n ≥3, be a cycle with n elements. Then
CSP(Cn) is in PTIME if n is even, and is NP-complete if n is odd.
The preceding two dichotomy results raise the challenge of classifying the
computational complexity of CSP(B) for arbitrary relational templates B. Ad-
dressing this question, Feder and Vardi [FV98] formulated the following conjec-
ture.
Conjecture 4.2. (Dichotomy Conjecture) [FV98]
If B = (B, RB
1 , . . . , RB
m) is an arbitrary relational structure, then either CSP(B)
is in PTIME or CSP(B) is NP-complete.
In other words, the Dichotomy Conjecture says that the picture above describes
the complexity of non-uniform constraint-satisfaction problems CSP(B) for ar-
bitrary structures B. The basis for the conjecture is not only the evidence from
Boolean constraint satisfaction and undirected constraint satisfaction, but also
from the seeming inability to carry out the diagonalization argument of [Lad75]
using the constraint-satisfaction machinery [Fed06].
The Dichotomy Conjecture inspired intensive research eﬀorts that signiﬁcantly
advanced our understanding of the complexity of non-uniform constraint satis-
faction. In particular, Bulatov conﬁrmed two important cases of this conjecture.
We say that a structure B = (B, RB
1 , . . . , RB
m) is a 3-element structure if B
contains at most three element. We say that B is conservative if all possible
monadic relations on the universe included, that is, every non-empty subset of
B is one of the relations RB
i of B.
Theorem 4.3.
[Bul02, Bul03] If B a 3-element structure or a conservative
structure, then either CSP(B) is in PTIME or CSP(B) is NP-complete. More-
over, in both cases the Tractability Classification Problem is decidable
in polynomial time.
In spite of the progress made, the Dichotomy Conjecture remains unresolved in
general. The research eﬀorts towards this conjecture, however, have also resulted
into the discovery of broad suﬃcient conditions for tractability and intractability

A Logical Approach to Constraint Satisfaction
135
of non-uniform constraint satisfaction that have provided unifying explanations
for numerous seemingly disparate tractability and intractability results and have
also led to the discovery of new islands of tractability of CSP(B). These broad
suﬃcient conditions are based on concepts and techniques from two diﬀerent
areas: universal algebra and logic.
The approach via universal algebra yields suﬃcient conditions for tractability
of CSP(B) in terms of closure properties of the relations in B under certain
functions on its universe B. Let R be a n-ary relation on a set B and f :
Bk →B a k-ary function. We say that R is closed under f, if whenever t1 =
(t1
1, t2
1, . . . , tn
1), . . . , tk = (t1
k, t2
k, . . . , tn
k) are k (not necessarily distinct) tuples in
R, then the tuple
(f(t1
1, . . . , t1
k), f(t2
1, . . . , t2
k), . . . , f(tn
1, . . . , tn
k))
is also in R. We say that f : Bk →B is a polymorphism of a structure B =
(B, R1, . . . , Rm) if each of the relations Rj, 1 ≤j ≤m, is closed under f. It is
easy to see that f is a polymorphism of B if and only if f is a homomorphism
from Bk to B, where Bk is the k-th power of B. By deﬁnition, the k-th power Bk
is the structure (Bk, R′
1 . . . , R′
m) over the same vocabulary as B with universe
Bk and relations R′
j, 1 ≤j ≤m, deﬁned as follows: if Rj is of arity n, then
R′
j(s1, . . . , sn) holds in Bk if and only if Rj(si
1, . . . , si
n) holds in B for 1 ≤i ≤n.
We write Pol(B) for the set of all polymorphisms of B. As it turns out, the
complexity of CSP(B) is intimately connected to the kinds of functions that
Pol(B) contains. This connection was ﬁrst unveiled in [FV98], and explored in
depth by Jeavons and his collaborators; for a recent survey see [BJK05]. In
particular, they showed that if Pol(B1) = Pol(B2) for two structures B1 and
B2 (over ﬁnite vocabularies), then CSP(B1) and CSP(B2) are polynomially
reducible to each other. Thus, the polymorphisms of a template B characterize
the complexity of CSP(B). The above mentioned dichotomy results for 3-element
and conservative constraint satisfaction are based on a rather deep analysis of
the appropriate sets of polymorphisms.
5
Monotone Monadic SNP and Non-uniform Constraint
Satisfaction
We discussed earlier how non-uniform constraint satisfaction is related to the
study of the expression complexity of conjunctive queries. We now show that it
can also be viewed as the study of the data complexity of second-order logic.
This will suggest a way to identify islands of tractability via logic.
As described in [GKL+05, Chapter 3] and [GKL+05, Chapter 2], existential
second-order logic ESO deﬁnes, by Fagin’s Theorem, precisely the complexity
class NP. The class SNP (for strict NP) [KV87, PY91] is a fragment of ESO,
consisting of all existential second-order sentences with a universal ﬁrst-order
part, namely, sentences of the form (∃S′)(∀x)Φ(x, S, S′), where Φ is a ﬁrst-order
quantiﬁer-free formula. We refer to the relations over the input vocabulary S as

136
P.G. Kolaitis and M.Y. Vardi
input relations, while the relations over the quantiﬁed vocabulary S′ are referred
to as existential relations. 3-Sat is an example of an SNP problem. The input
structure consists of four ternary relations C0, C1, C2, C3, on the universe {0, 1},
where Ci corresponds to a clause on three variables with the ﬁrst i of them
negated. There is a single existential monadic relation T describing a truth as-
signment. The condition that must be satisﬁed states that for all x1, x2, x3, if
C0(x1, x2, x3) then T (x1) or T (x2) or T (x3), and similarly for the remaining
Ci by negating T (xj) if j ≤i. Formally, we can express 3-Sat with the SNP
sentence:
(∃T )(∀x1, x2, x3) ((C0(x1, x2, x3) →T (x1) ∨T (x2) ∨T (x3))∧
(C1(x1, x2, x3) →¬T (x1) ∨T (x2) ∨T (x3))∧
(C2(x1, x2, x3) →¬T (x1) ∨¬T (x2) ∨T (x3))∧
(C3(x1, x2, x3) →¬T (x1) ∨¬T (x2) ∨¬T (x3))).
It is easy to see that CSP(B) is in SNP for each structure B. For each ele-
ment a in the universe of B, we introduce an existentially quantiﬁed monadic
relation Ta; intuitively, Ta(x) indicates that a variable x has been assigned value
a by the homomorphism. The sentence ϕB says that the sets Ta cover all el-
ements in the universe3, and that the tuples in the input relations satisfy the
constraints imposed by the structure B. Thus, if R(a1, . . . , an) does not hold in
B, then ϕB contains the conjunct ¬(R(x1, . . . , xn) ∧
n
i=1 Tai(xi)). For exam-
ple, 3-Colorability over a binary input relation E can be expressed by the
following sentence:
(∃C1, C2, C3)(∀x, y) ((C1(x) ∨C2(x) ∨C3(x))∧
¬(E(x, y) ∧C1(x) ∧C1(y))∧
¬(E(x, y) ∧C2(x) ∧C2(y))∧
¬(E(x, y) ∧C3(x) ∧C3(y))).
It follows that CSP(B) = {A : A |= ϕB}. Thus, the study of the complexity
of non-uniform constraint satisfaction can be viewed as the study of the data
complexity of certain SNP sentences.
A close examination of ϕB above shows that it actually resides in a syntactic
fragment of SNP. For monotone SNP, we require that all occurrences of an input
relation Ci in Φ have the same polarity (the polarity of a relation is positive
if it is contained in an even number of subformulas with a negation applied to
it, and it is negative otherwise); by convention, we assume that this polarity
is negative, so that the Ci can be interpreted as constraints, in the sense that
imposing Ci on more elements of the input structure can only make the instance
“less satisﬁable”. For monadic SNP we require that the existential structure S′
consist of monadic relations only. Normally we assume that the language contains
also the equality relation, so both equalities and inequalities are allowed in Φ,
unless we say without inequality, which means that the ̸= relation cannot be
used (note that equalities can always be eliminated here). We refer to the class
3 It is not necessary to require disjointness.

A Logical Approach to Constraint Satisfaction
137
when all restrictions hold, that is, monotone monadic SNP without inequality,
as MMSNP. It is clear then that non-uniform constraint satisfaction can be
expressed in MMSNP.
What is the precise relationship between non-uniform constraint satisfaction
and MMSNP? It is easy to see that MMSNP is more expressive than non-uniform
constraint satisfaction. The property asserting that the input graph is triangle-
free is clearly in MMSNP (in fact, it can be expressed by a universal ﬁrst-
order sentence), but it can be easily shown that there is no graph G such that
CSP(G) consists of all triangle-free graphs [FV98]. From a computational point
of view, however, MMSNP and non-uniform constraint satisfaction turn out to
be equivalent.
Theorem 5.1.
[FV98] Every problem in MMSNP is polynomially equivalent
to CSP(B) for some template B. The equivalence is by a randomized Turing
reduction4 from CSP to MMSNP and by a deterministic Karp reduction from
MMSNP to CSP.
An immediate corollary is that the Dichotomy Conjecture holds for CSP if and
only if it holds for MMSNP. At the same time, MMSNP seems to be a maxi-
mal class with this property. Speciﬁcally, any attempt to relax the syntactical
restrictions of MMSNP yields a class that is polynomially equivalent to NP, and,
consequently, a class for which dichotomy fails.
Theorem 5.2.
[FV98]
– Every problem in NP has a polynomially equivalent problem in monotone
monadic SNP with inequality.
– Every problem in NP has a polynomially equivalent problem in monadic SNP
without inequality.
– Every problem in NP has a polynomially equivalent problem in monotone
SNP without inequality.
By Ladner’s Theorem it follows that if PTIME ̸= NP, then there are intermedi-
ate problems, which are neither in PTIME nor NP-complete, in each of monotone
monadic SNP with inequality, monadic SNP without inequality, and monotone
SNP without inequality. This is the sense in which MMSNP is a maximal class
for which we would expect a dichotomy theorem to hold.
The fact that each constraint-satisfaction problem CSP(B) can be expressed
by the MMSNP sentence ϕB suggests a way to identify templates B for which
CSP(B) is tractable: characterize those templates B for which ϕB is equivalent
to a sentence in a logic whose data complexity is in PTIME. We discuss this
approach in the next section.
6
Datalog and Non-uniform Constraint Satisfaction
Consider all tractable problems of the form CSP(B). In principle, it is conceivable
that every such problem requires a completely diﬀerent algorithm. In practice,
however, there seem to be two basic algorithmic approaches for solving tractable
4 G. Kun recently announced a derandomization of this reduction.

138
P.G. Kolaitis and M.Y. Vardi
constraint-satisfaction problems: one based on a logical framework and one based
on an algebraic framework.5 Feder and Vardi [FV98] conjectured that these
two algorithmic approaches cover all tractable constraint-satisfaction problems.
Their group-theoretic approach, which extended the algorithm used to solve
aﬃne Boolean constraint-satisfaction problems [Sch78], has more recently been
subsumed by a universal-algebraic approach [Bul02,Bul03]. We discuss here the
logical approach.
As described in [GKL+05, Chapter 2], a Datalog program is a ﬁnite set of rules
of the form t0 :- t1, . . . , tm, where each ti is an atomic formula R(x1, . . . , xn).
The relational predicates that occur in the heads of the rules are the intensional
database predicates (IDBs), while all others are the extensional database predi-
cates (EDBs). One of the IDBs is designated as the goal of the program. Note
that IDBs may occur in the bodies of rules and, thus, a Datalog program is a
recursive speciﬁcation of the IDBs with semantics obtained via least ﬁxed-points
of monotone operators. Each Datalog program deﬁnes a query which, given a
set of EDB predicates, returns the value of the goal predicate. Moreover, this
query is computable in polynomial time, since the bottom-up evaluation of the
least ﬁxed-point of the program terminates within a polynomial number of steps
(in the size of the given EDBs). It follows that Datalog has data complexity in
PTIME. Thus, expressibility in Datalog is a suﬃcient condition for tractability
of a query. This suggests trying to identify those templates B for which the
MMSNP sentence ϕB is equivalent to a Boolean Datalog query.
It should be noted, however, that Datalog queries are preserved under homo-
morphisms. This means that if A →h A′ and t ∈P(A) for a Datalog program
M, with goal predicate P, then h(t) ∈P(A′). In contrast, constraint-satisfaction
problems are not preserved under homomorphism; however, their complements
are. If B is a relational structure, then we write CSP(B) for the complement
of CSP(B), that is, the class of all structures A such that there is no homo-
morphism h : A →B. If A →h A′ and A ∈CSP(B), then it does not follow
that A′ ∈CSP(B). On the other hand, if A →h A′ and A ∈CSP(B), then
A′ ∈CSP(B), since homomorphisms compose. Thus, rather then try to identify
those templates B for which ϕB is equivalent to a Boolean Datalog query, we try
to identify those templates B for which the negated sentence ¬ϕB is equivalent
to a Boolean Datalog query.
Along this line of investigation, Feder and Vardi [FV98] provided a unify-
ing explanation for the tractability of many non-uniform CSP(B) problems by
showing that the complement of each of these problems is expressible in Data-
log. It should be pointed out, however, that Datalog does not cover all tractable
constraint-satisfaction problems. For example, it is shown in [FV98] that Dat-
alog cannot express the complement of aﬃne Boolean constraint-satisfaction
problems; see also [Ats05]. Aﬃne Boolean constraint-satisfaction problems and
their generalizations require algebraic techniques to establish their tractabil-
ity [Bul02,FV98]).
5 The two approaches, however, are not alwasy cleanly separated; in fact, they can be
fruitfully combined to yield new tractable classes, cf. [Dal05].

A Logical Approach to Constraint Satisfaction
139
For every positive integer k, let k-Datalog be the collection of all Datalog
programs in which the body of every rule has at most k distinct variables and
also the head of every rule has at most k variables (the variables of the body
may be diﬀerent from the variables of the head). For example, the query Non-
2-Colorability is expressible in 3-Datalog, since it is deﬁnable by the goal
predicate Q of the following Datalog program, which asserts that a cycle of odd
length exists:
P1(X, Y ) : −E(X, Y )
P0(X, Y ) : −P1(X, Z), E(Z, Y )
P1(X, Y ) : −P0(X, Z), E(Z, Y )
Q : −P1(X, X).
The fact that expressibility in Datalog, and, more speciﬁcally, expressibility
in k-Datalog provide suﬃcient conditions for tractability, gives rise to two clas-
siﬁcation problems:
– The k-Datalog Classification Problem: Given a relational structure
B and k > 1, decide if CSP(B) is expressible in k-Datalog?
– The Datalog Classification Problem: Given a relational structure B,
decide if CSP(B) is expressible in k-Datalog for some k > 1.
The universal-algebraic approach does oﬀer some suﬃcient conditions for
CSP(B) to be expressible in Datalog. We mention here two examples. A k-ary
function f : Bk →B with k ≥3 is a near-unanimity function if f(a1, . . . , ak) =
b, for every k-tuple (a1, . . . , ak) such that at least k −1 of the ai’s are equal to b.
Note that the ternary majority function from {0, 1}3 to {0, 1} is a near-unanimity
function.
Theorem 6.1. [FV98] Let B be relational structure, and k ≥3. If Pol(B) con-
tains a k-ary near-unanimity function, then CSP(B) is expressible in k-Datalog.
Since the number of k-ary functions over the universe B of B is ﬁnite, checking
the condition of the preceding theorem for a given k is clearly decidable. It is not
known, however, whether it is decidable to check, given B, if Pol(B) contains a
k-ary near-unanimity function for some k.
A special class of Datalog consists of those programs whose IDB predicates are
all monadic. We refer to such Datalog programs as monadic Datalog programs.
It can easily be seen that the Horn case of Boolean constraint satisfaction can be
dealt with by monadic programs. Consider, for example, a Boolean template with
three relations: H1 is a monadic relation corresponding to positive Horn clauses
(“facts”), H2 is a ternary relation corresponding to Horn clauses of the form
p ∧q →r, and H3 is a ternary relation corresponding to negative Horn clause
of the form ¬p ∨¬q ∨¬r. Then, unsatisﬁability of Horn formulas with at most
three literals per clause is expressed by the following monadic Datalog program:

140
P.G. Kolaitis and M.Y. Vardi
H(X) : −H1(X)
H(X) : −H(X), H2(Y, Z, X)
Q : −H(X), H(Y ), H(Z), H2(X, Y, Z)
It turns out that we can fully characterize expressibility in monadic Datalog.
A k-ary function f is a set function if f(a1, . . . , ak) = f(b1, . . . , bk) whenever
{a1, . . . , ak} = {b1, . . . , bk}. In other words, a set function depends only the set
of its arguments. As a concrete example, the binary Boolean functions ∧and ∨
are set functions.
Theorem 6.2. [FV98] Let B be relational structure with universe B. Then the
following two statements are equivalent.
– CSP(B) is expressible in monadic Datalog.
– Pol(B) contains a |B|-ary set function.
Since the number of |B|-ary functions over the universe B of B is ﬁnite, checking
the condition of the theorem is clearly decidable; in fact, it is in NEXPTIME.
Thus, the classiﬁcation problem for monadic Datalog is decidable.
The main reason for the focus on Datalog as a language to solve constraint-
satisfaction problems is that its data complexity is in PTIME. Datalog, however,
is not the only logic with this property. We know, for example, that the data
complexity of ﬁrst-order logic is in LOGSPACE. Thus, it would be interesting to
characterize the templates B such that CSP(B) is expressible in ﬁrst-order logic.
This turns out to have an intimate connection to expressibility in (non-recursive)
Datalog.
Theorem 6.3.
[Ats05, Ros95] Let B be a relational structure. The following
are equivalent:
– CSP(B) is expressible in ﬁrst-order logic.
– CSP(B) is expressible by a ﬁnite union of conjunctive queries.
It is known that a Datalog program is always equivalent to a (possibly inﬁnite)
union of conjunctive queries. A Datalog program is bounded if it is equivalent to a
ﬁnite union of conjunctive queries [GMSV87]. It is known that a Datalog program
is bounded if and only if it is equivalent to a ﬁrst-order formula [AG94,Ros05].
Thus, expressibility of non-uniform CSP in ﬁrst-order logic is a special case of
expressibility in Datalog. Concerning the classiﬁcation problem, Larose, Loten,
and Tardif [LLT06] have shown that there is an algorithm to decide, given a
structure B, whether CSP(B) is expressible in ﬁrst-order logic; actually, this
problem turns out to be NP-complete.
In another direction, we may ask if there are constraint-satisfaction problems
that cannot be expressed by Datalog, but can be expressed in least ﬁxed-point
logic LFP, whose data complexity is also in PTIME. This is an open question.
It is conjectured in [FV98] that if CSP(B) is expressible in LFP, then it is also
expressible in Datalog.

A Logical Approach to Constraint Satisfaction
141
7
Datalog, Games, and Constraint Satisfaction
So far, we focused on using Datalog to obtain tractability for non-uniform con-
straint satisfaction. Kolaitis and Vardi [KV00a] showed how the logical frame-
work also provides a unifying explanation for the uniform tractability of con-
straint-satisfaction problems. Note that, in general, non-uniform tractability re-
sults do not uniformize. Thus, tractability results for each problem in a collection
of non-uniform CSP(B) problems do not necessarily yield a tractable case of the
uniform constraint-satisfaction problem. The reason is that both structures A
and B are part of the input to the constraint-satisfaction problem, and the
running times of the polynomial-time algorithms for CSP(B) may very well be
exponential in the size of B. We now leverage the intimate connection between
Datalog and pebble games to shed new light on expressibility in Datalog, and
show how tractability via k-Datalog does uniformize.
As discussed in [GKL+05, Chapter 2], Datalog can be viewed as a fragment
of least ﬁxed-point logic LFP; furthermore, on the class All of all ﬁnite struc-
tures, LFP is subsumed by the ﬁnite-variable inﬁnitary logic Lω
∞ω = 
k>0 Lk
∞ω
(see [GKL+05, Chapter 2]). Here we are interested in the existential positive
fragments of ∃Lk
∞ω, k a positive integer, which are tailored for the study of
Datalog.
Theorem 7.1.
[KV00a] Let k be a positive integer. Every k-Datalog query
over ﬁnite structures is expressible in ∃Lk
∞ω. Thus, k-Datalog ⊆∃Lk
∞ω on ﬁnite
structures.
We make use here of the (∃, k)-pebble games discussed in [GKL+05, Chapter 2].
We saw there that if k is a positive integer and Q a Boolean query on a class C of
ﬁnite structures, then Q is expressible in ∃Lk
∞ω on C iﬀfor all A, B ∈C such that
A |= Q and the Duplicator wins the (∃, k)-pebble game on A and B, we have
that B |= Q. The next theorem establishes a connection between expressibility
in k-Datalog and (∃, k)-pebble games. (A closely related, but somewhat less
precise, such connection was established in [FV98]). In what follows, if A is a
class of structures and B is a structure, we write CSP(A, B) to denote the class
of structures A such that A ∈A and A →B.
Theorem 7.2.
[KV00a] Let k be a positive integer, B a relational structure,
and A a class of relational structures such that B ∈A. Then the following
statements are equivalent.
1. CSP(A, B) is expressible in k-Datalog on A.
2. CSP(A, B) is expressible in ∃Lk
∞ω on A.
3. CSP(A, B)={A∈A :The Spoiler wins the (∃, k)-pebble game on A and B}.
Recall also from [GKL+05, Chapter 2] that the query “Given two structures A
and B, does the Spoiler win the (∃, k)-pebble on A and B?” is deﬁnable in LFP;
as a result, there is a polynomial-time (in fact, O(n2k)) algorithm that, given
two structures A and B, determines whether the Spoiler wins the (∃, k)-pebble
game on A and B.

142
P.G. Kolaitis and M.Y. Vardi
By combining Theorem 7.2 with the results of [GKL+05, Chapter 2], we ob-
tain the following uniform tractability result for classes of constraint-satisfaction
problems expressible in Datalog.
Theorem 7.3.
[KV00a] Let k be a positive integer, A a class of relational
structures, and B = {B ∈A : ¬CSP(A, B) is expressible in k-Datalog}. Then
the uniform constraint-satisfaction problem CSP(A, B) is solvable in polynomial
time. Moreover, the running time of the algorithm is O(n2k), where n is the
maximum of the sizes of the input structures A and B.
Intuitively, if we consider the class of all templates B for which k-Datalog solves
CSP(B), then computing the winner in the existential k-pebble game oﬀers
a uniform polynomial-time algorithm. That is, the algorithm determining the
winner in the existential k-pebble game is a uniform algorithm for all (non-
uniform) constraint-satisfaction problems that can be expressed in k-Datalog.
The characterization in terms of pebble games turns also sheds light on non-
uniform constraint satisfaction. As described in [GKL+05, Chapter 2], for every
relational structure B and every positive integer k, there is a k-Datalog program
ρk
B that expresses the query “Given a structure A, does the Spoiler win the
(∃, k) pebble game on A and B?”. As an immediate consequence of this fact, we
get that CSP(B) is expressible in k-Datalog if and only if it is expressible by a
speciﬁc k-Datalog program.
Theorem 7.4.
[FV98,KV00a] CSP(B) is expressible in k-Datalog if and only
if it is expressible by ρk
B.
It follows that CSP(B) is expressible in k-Datalog if and only if ¬ϕB is logically
equivalent to ρk
B, where ϕB is the MMSNP sentence expressing CSP(B). Unfor-
tunately, it is not known if equivalence of complemented MMSNP to Datalog is
decidable.
8
Games and Consistency
One of the most fruitful approaches to coping with the intractability of constraint
satisfaction has been the introduction and use of various consistency concepts
that make explicit additional constraints implied by the original constraints. The
connection between consistency properties and tractability was ﬁrst described
in [Fre78, Fre82]. In a similar vein, the relationship between local consistency
and global consistency is investigated in [Dec92b,vB94,vBD97]. Intuitively, local
consistency means that any partial solution on a set of variables can be extended
to a partial solution containing an additional variable, whereas global consistency
means that any partial solution can be extended to a global solution. Note that
if the inputs are such that local consistency implies global consistency, then
there is a polynomial-time algorithm for constraint satisfaction; moreover, in
this case a solution can be constructed via a backtrack-free search. We now
describe this approach from the Datalog perspective. The crucial insight is that

A Logical Approach to Constraint Satisfaction
143
the key concept of strong k-consistency [Dec92b] is equivalent to a property
of winning strategies for the Duplicator in the (∃, k)-pebble game. Speciﬁcally,
an instance of a constraint-satisfaction problem is strongly k-consistent if and
only if the family of all k-partial homomorphisms f is a winning strategy for
the Duplicator in the (∃, k)-pebble game on the two relational structures that
represent the given instance.
The connection between pebble games and consistency properties, however,
is deeper than just a mere reformulation of the concept of strong k-consistency.
Indeed, as mentioned earlier, consistency properties underly the process of mak-
ing explicit new constraints that are implied by the original constraints. A key
technical step in this approach is the procedure known as “establishing strong
k-consistency”, which propagates the original constraints, adds implied con-
straints, and transforms a given instance of a constraint-satisfaction problem to
a strongly k-consistent instance with the same solution space [Coo89,Dec92b]. In
fact, strong k-consistency can be established if and only if the Duplicator wins the
(∃, k)-pebble game. Moreover, whenever strong k-consistency can be established,
one method for doing this is to ﬁrst compute the largest winning strategy for
the Duplicator in the (∃, k)-pebble game and then modify the original problem
by augmenting it with the constraints expressed by the largest winning strat-
egy; this method gives rise to the least constrained instance that establishes
strong k-consistency and, in addition, satisﬁes a natural coherence property.
By combining this result with known results concerning the deﬁnability of the
largest winning strategy, it follows that the algorithm for establishing strong k-
consistency in this way (with k ﬁxed) is actually expressible in least ﬁxed-point
logic; this strengthens the fact that strong k-consistency can be established in
polynomial time, when k is ﬁxed. If we consider non-uniform constraint satisfac-
tion, it follows that for every relational structure B, the complement of CSP(B)
is expressible by a Datalog program with k variables if and only if CSP(B) co-
incides with the collection of all relational structures A such that establishing
strong k-consistency on A and B implies that there is a homomorphism from A
to B.
We start the formal treatment by returning ﬁrst to (∃, k)-pebble games. Re-
call from [GKL+05, Chapter 2] that a winning strategy for the Duplicator in
the (∃, k)-pebble game on A and B is a nonempty family of k-partial homomor-
phisms (that is, partial homomorphisms deﬁned on at most k elements) from A
to B that is closed under subfunctions and has the forth property up to k. A
conﬁguration for the (∃, k)-pebble game on A and B is a 2k-tuple a, b, where
a = (a1, . . . , ak) and b = (b1, . . . , bk) are elements of Ak and Bk, respectively,
such that if ai = aj, then bi = bj; this means that the correspondence ai →bi,
1 ≤i ≤k, is a partial function from A to B, which we denote by ha,b. A winning
conﬁguration for the Duplicator in the existential k-pebble game on A and B is
a conﬁguration a, b for this game such that ha,b is a member of some winning
strategy for the Duplicator in this game. We denote by Wk(A, B) the set of all
such conﬁgurations. The following results show that expressibility in ∃Lk
∞ω can
be characterized in terms of the set Wk(A, B).

144
P.G. Kolaitis and M.Y. Vardi
Proposition 8.1.
[KV00b] If F and F′ are two winning strategies for the
Duplicator in the (∃, k)-pebble game on two structures A and B, then also the
union F ∪F′ is a winning strategy for the Duplicator. Consequently, there is
a largest winning strategy for the Duplicator in the (∃, k)-pebble game, namely
the union of all winning strategies, which is precisely the set Hk(A, B) = {ha,b :
(a, b) ∈Wk(A, B)}.
Corollary 8.2.
[KV00a] Let k be a positive integer and Q a k-ary query on a
class C of ﬁnite structures. Then the following two statements are equivalent:
1. Q is expressible in ∃Lk
∞ω on C.
2. If A, B are two structures in C, (a, b) ∈Wk(A, B), and A |= Q(a), then
B |= Q(b).
The following lemma is a crucial deﬁnability result.
Lemma 8.3.
[KV00a] There is a positive-in-S ﬁrst-order formula ϕ(x, y, S),
where x and y are k-tuples of variables, such that the complement of its least
ﬁxed-point on a pair (A, B) of structures deﬁnes the set Wk(A, B) of all winning
conﬁgurations for the Duplicator in the (∃, k)-pebble game on A, B.
We now formally deﬁne the concepts of i-consistency and strong k-consistency.
Deﬁnition 8.4. Let P = (V, D, C) be a constraint-satisfaction instance.
– A partial solution on a set V ′ ⊂V is an assignment h : V ′ →D that satisﬁes
all the constraints whose scope is contained in V ′.
– P is i-consistent if for every i−1 variables v1, . . . , vi−1, for every partial so-
lution on these variables, and for every variable vi ̸∈{v1, . . . , vi−1}, there is
a partial solution on the variables v1, . . . , vi−1, vi extending the given partial
solution on the variables v1, . . . , vi−1.
– P is strongly k-consistent if it is i-consistent for every i ≤k.
To illustrate these concepts, consider the Boolean formula
(¬x1 ∨x3) ∧(¬x2 ∨x3) ∧(x2 ∨¬x3).
It is easy to verify that this formula, viewed as a constraint-satisfaction instance,
is strongly 3-consistent. For instance, the partial solution x2 = 0, x3 = 0 can
be extended to the solution x1 = 0, x2 = 0, x3 = 0, while the partial solution
x1 = 1, x3 = 1 can be extended to the solution x1 = 1, x2 = 1, x3 = 1. In
contrast, the Boolean formula
(x1 ∨x2) ∧(¬x1 ∨x3) ∧(¬x2 ∨x3) ∧(x2 ∨¬x3)
is satisﬁable and strongly 2-consistent, but not 3-consistent (hence, it is not
strongly 3-consistent either). The reason is that the partial solution x2 = 0,
x3 = 0 cannot be extended to a solution, since the only solutions of this formula
are x1 = 0, x2 = 1, x3 = 1 and x1 = 1, x2 = 1, x3 = 1. We note that the
concepts of strong 2-consistency and strong 3-consistency were ﬁrst studied in the
literature under the names of arc consistency and path consistency (see [Dec03]).
A key insight is that the concepts of i-consistency and strong k-consistency
can be naturally recast in terms of existential pebble games.

A Logical Approach to Constraint Satisfaction
145
Proposition 8.5.
[KV00b] Let P be a CSP instance, and let (AP, BP) be the
associated homomorphism instance.
– P is i-consistent if and only if the family of all partial homomorphisms from
AP to BP with i −1 elements in their universe has the i-forth property.
– P is strongly k-consistent if and only if the family of all k-partial homo-
morphisms from AP to BP is a winning strategy for the Duplicator in the
(∃, k)-pebble game on AP and BP.
Let us now recall the concept of establishing strong k-consistency, as deﬁned,
for instance, in [Coo89,Dec92b]. This concept has been deﬁned rather informally
in the AI literature to mean that, given a constraint-satisfaction instance P, we
associate with it another instance P′ that has the following properties: (1) P′
has the same set of variables and the same set of values as P (2) P′ is strongly
k-consistent; (3) P′ is at least as constrained as P; and (4) P and P′ have the
same space of solutions. The next deﬁnition formalizes the above concept in the
context of the homomorphism problem (cf. [DP99,KV00b]).
Deﬁnition 8.6. Let A and B be two relational structures over a k-ary vocabu-
lary σ (i.e., every relation symbol in σ has arity at most k). Establishing strong
k-consistency for A and B means that we associate two relational structures A′
and B′ with the following properties:
1. A′ and B′ are structures over some k-ary vocabulary σ′ (in general, diﬀer-
ent than σ); moreover, the universe of A′ is the universe A of A, and the
universe of B′ is the universe B of B.
2. CSP(A′, B′) is strongly k-consistent.
3. if h is a k-partial homomorphism from A′ to B′, then h is a k-partial ho-
momorphism from A to B.
4. If h is a function from A to B, then h is a homomorphism from A to B if
and only if h is a homomorphism from A′ to B′.
If the structures A′ and B′ have the above properties, then we say that A′ and
B′ establish strong k-consistency for A and B.
A constraint-satisfaction instance P is coherent if every constraint (t, R) of P
completely determines all constraints (u, Q) in which all variables occurring in
u are among the variables of t. We formalize this concept as follows.
Deﬁnition 8.7. An instance A, B of the homomorphism problem is coherent
if its associated constraint-satisfaction instance CSP(A, B) has the following
property: for every constraint (a, R) of CSP(A, B) and every tuple b ∈R, the
mapping ha,b is well deﬁned and is a partial homomorphism from A to B.
Note that a constraint-satisfaction instance can be made coherent in polynomial-
time by constraint propagation.
The main result of this section is that strong k-consistency can be estab-
lished precisely when the Duplicator wins the (∃, k)-pebble game. Moreover, one
method for establishing strong k-consistency is to ﬁrst compute the largest win-
ning strategy for the Duplicator in this game and then generate an instance of

146
P.G. Kolaitis and M.Y. Vardi
the constraint-satisfaction problem consisting of all the constraints embodied in
the largest winning strategy. Furthermore, this method gives rise to the largest
coherent instance that establishes strong k-consistency (and, hence, the least
constrained such instance).
Theorem 8.8. [KV00b] Let k be a positive integer, let σ be a k-ary vocabulary,
and let A and B be two relational structures over σ with universes A and B, re-
spectively. It is possible to establish strong k-consistency for A and B if and only
if Wk(A, B) ̸= ∅. Furthermore, if Wk(A, B) ̸= ∅, then the following sequence of
steps gives rise to two structures A′ and B′ that establish strong k-consistency
for A and B:
1. Compute the set Wk(A, B).
2. For every i ≤k and for every i-tuple a ∈Ai, form the set Ra = {b ∈Bi :
(a, b) ∈Wk(A, B)}.
3. Form the constraint-satisfaction instance P with A as the set of variables,
B as the set of values, and {(a, Ra) : a ∈∪k
i=1Ai} as the collection of
constraints.
4. Let (A′, B′) be the homomorphism instance of P.
In addition, the structures A′ and B′ obtained above constitute the largest coher-
ent instance establishing strong k-consistency for A and B, that is, if (A′′, B′′) is
another such coherent instance, then for every constraint (a, R) of CSP(A′′, B′′),
we have that R ⊆Ra.
The key step in the procedure described in Theorem 8.8 is the ﬁrst step, in which
the set Wk(A, B) is computed. The other steps simply “re-format” Wk(A, B).
From Lemma 8.3 it follows that we can establish strong k-consistency by com-
puting the ﬁxed-point of a monotone ﬁrst-order formula. We can now relate the
concept of strong k-consistency to the results in [FV98] regarding Datalog and
non-uniform CSP.
Theorem 8.9.
[KV00b] Let B be a relational structure over a vocabulary σ.
Then the following two statements are equivalent.
– CSP(B) is expressible in k-Datalog.
– For every structure A over σ, establishing strong k-consistency for A, B
implies that there is a homomorphism from A to B.
Given the fundamental role that the set Wk(A, B) plays here, it is natural to
ask about the complexity of computing it. To turn it into a decision problem,
we just ask about the non-emptiness of this set.
Theorem 8.10.
[KP03] The problem {(A, B, k) : Wk(A, B) ̸= ∅}, with k
encoded in unary, is EXPTIME-complete. In words, the following problem is
EXPTIME-complete: given a positive integer k and two structures A and B,
does the Duplicator win the (∃, k)-pebble game on A and B?
This result is rather surprising. After all, the complexity of constraint satisfaction
is “only” NP-complete. In contrast, the complexity of establishing strong k-
consistency is provably exponential and not in PTIME. This oﬀers an a posteriori
justiﬁcation of the practice of establishing only a “low degree” of consistency,
such as arc consistency or path consistency [Apt03,Dec03].

A Logical Approach to Constraint Satisfaction
147
9
Uniform Constraint Satisfaction and Bounded
Treewidth
So far, we focused on the pursuit of islands of tractability of non-uniform con-
straint satisfaction, that is, islands of the form CSP(B) = CSP(All, {B}), where
B is a ﬁxed template. Even when we discussed uniform constraint satisfaction,
it was with respect to tractable templates. In this section we focus on uniform
constraint satisfaction of the form CSP(A, All), where A is a class of structures.
The goal is to identify conditions on A that ensure uniform tractability.
As is well known, many algorithmic problems that are “hard” on arbitrary
structures become “easy” on trees. This phenomenon motivated researchers to
investigate whether the concept of a tree can be appropriately relaxed while
maintaining good computational behavior. As part of their seminal work on
graph minors, Robertson and Seymour introduced the concept of
treewidth,
which, intuitively, measures how “tree-like” a structure is; moreover, they showed
that graphs of bounded treewidth exhibit such good behavior, cf. [NR90].
Deﬁnition 9.1. A tree decomposition of a relational structure A is a labelled
tree T such that the following conditions hold:
1. every node of T is labelled by a non-empty subset of the universe A of A,
2. for every relation R of A and every tuple (a1, . . . , an) in R, there is a node
of T whose label contains {a1, . . . , an},
3. for every a ∈A, the set of nodes of T whose labels include a forms a subtree
of T .
The width of a tree decomposition T is the maximum cardinality of a label of a
node in T minus 1. The treewidth of A, denoted tw(A), is the smallest positive
integer k such that A has a tree decomposition of width k. We write T (k) to
denote the class of all structures A such that tw(A) < k.
Clearly, if T is a tree, then tw(T) = 1. Similarly, if n ≥3 and Cn is the n-element
(directed) cycle, then tw(C) = 2. At the other end of the scale, tw(Kk) =
k −1, for every k ≥2. Computing the treewidth of a structure is an intractable
problem. Speciﬁcally, the following problem is NP-complete [ACP87]: given a
graph H and an integer k ≥1, is tw(H) ≤k? Nonetheless, Bodlaender [Bod93]
showed that for every ﬁxed integer k ≥1, there is a linear-time algorithm such
that, given a structure A, it determines whether or not tw(A) < k. In other
words, each class T (k) is recognizable in polynomial time.
Dechter and Pearl [DP89] and Freuder [Fre90] showed that the classes of struc-
tures of bounded treewidth give rise to large islands of tractability of uniform
constraint satisfaction.
Theorem 9.2. [DP89,Fre90] If k ≥2 is a positive integer, then CSP(T (k), All)
is in PTIME.
The polynomial-time algorithm for CSP(T (k), All) in the above theorem is often
described as a bucket-elimination algorithm [Dec99]. It should be noted that it is

148
P.G. Kolaitis and M.Y. Vardi
not a constraint-propagation algorithm. Instead, this algorithm uses the bound
on the treewidth to test if a solution to the constraint-satisfaction problem exists
by solving a join-evaluation problem in which all intermediate relations are of
bounded arity.
Kolaitis and Vardi [KV00a], and Dalmau, Kolaitis and Vardi [DKV02] investi-
gated certain logical aspects of the treewidth of a relational structure and showed
that this combinatorial concept is closely connected to the canonical conjunctive
query of the structure being deﬁnable in a fragment of ﬁrst-order logic with a
ﬁxed number of variables. This made it possible to show that the tractability of
CSP(T (k), All) can be explained in purely logical terms. Moreover, it led to the
discovery of larger islands of tractability of uniform constraint satisfaction.
Deﬁnition 9.3. Let k ≥2 be a positive integer.
– FOk is the collection of all ﬁrst-order formulas with at most k distinct vari-
ables.
– Lk is the collection of all FOk-formulas built using atomic formulas, con-
junction, and existential ﬁrst-order quantiﬁcation only.
Intuitively, queries expressible in FOk and Lk are simply ﬁrst-order queries and
conjunctive queries, respectively, with a bound k on the number of distinct vari-
ables (each variable, however, may be reused any number of times).
As an example, it is easy to see that if Cn is the n-element cycle, n ≥3, then
the canonical conjunctive query QCn is expressible in L3. For instance, QC4 is
logically equivalent to (∃x∃y∃z)(E(x, y) ∧E(y, z) ∧(∃y)(E(z, y) ∧E(y, x))). As
mentioned earlier, for every n ≥3, we have that tw(Cn) = 2.
The logics FOk and Lk are referred to as variable-conﬁned logics [KV96]. The
complexity of query evaluation for such queries has been studied in [Var95]. Since
in data complexity the queries are ﬁxed, bounding the number of variables does
not change data complexity. The change in expression and combined complexity,
however, is quite dramatic, as the combined complexity of FOk has been shown
to be in PTIME [Var95]. (More generally, the exponential gap between data
complexity and expression and combined complexity shrinks when the number
of variables is bounded.)
The next result shows that the relationship we just saw in the example between
treewidth and number of variables needed to express the canonical conjunctive
query of a cycle is not an accident.
Theorem 9.4.
[KV00a] Let k ≥2 be a positive integer. If A ∈T (k), then the
canonical conjunctive query QA is expressible in Lk.
Corollary 9.5. CSP(T (k), All) can be solved in polynomial time by determin-
ing, given a structure A ∈T (k) and an arbitrary structure B, whether B |= QA.
A precise complexity analysis of CSP(T (k), All) is provided in [GLS98], where it
is shown that the problem is LOGFCL-complete; by deﬁnition, LOGCFL is the
class of decision problems that are logspace-reducible to a context-free language.
Note that, in contrast, the combined complexity of evaluating FOk-queries, for
k > 3, is PTIME-complete [Var95].

A Logical Approach to Constraint Satisfaction
149
Theorem 9.4 can be viewed as a logical recasting of the bucket-elimination
algorithm. It derives the tractability of CSP(T (k), All) from the fact that the
canonical conjunctive query QA can be written using at most k variables. Con-
sequently, evaluating this query amounts to solving a join-evaluation problem in
which all intermediate relations are of bounded arity. For an investigation of how
the ideas underlying Theorem 9.4 can be used to solve practical join-evaluation
problems, see [MPPV04].
It turns out, however, that we can also approach solving CSP(T (k), All) from
the perspective of k-Datalog and (∃, k)-pebble games. This is because Lk is a
fragment of ∃Lk
∞ω, whose expressive power, as seen earlier, can be characterized
in terms of such games.
Theorem 9.6.
[DKV02] Let k ≥2 be a positive integer.
– If B is an arbitrary, but ﬁxed, structure, then T (k) ∩CSP(T (k), {B}) is
expressible in k-Datalog6.
– CSP(T (k), All) can be solved in polynomial time by determining whether,
given a structure A ∈T (k) and an arbitrary structure B, the Duplicator
wins the (∃, k)-pebble on A and B.
The situation for bounded treewidth structures, as described by Theorem 9.6,
should be contrasted with the situation for bounded cliquewidth structures (cf.
[CMR00]). Let C(k) be the class of structures of cliquewidth bounded by k. It
is shown in [CMR00] that CSP(C(k), {B}) is in PTIME for each structure B.
Since, however, complete graphs have bounded cliquewidth, it follows that the
Clique problem can be reduced to CSP(C(k), All), implying NP-hardness of the
latter.
As a consequence of Theorem 9.6, we see that CSP(T (k), All) can be solved
in polynomial time using a constraint-propagation algorithm that is quite diﬀer-
ent from the bucket-elimination algorithm in Theorem 9.2. It should be noted,
however, that this requires knowing that we are given an instance A, B where
tw(A) ≤k. In contrast, the bucket-elimination algorithm can be used for arbi-
trary constraint-satisfaction instances (with no tractability guarantee, in
general).
The classes CSP(T (k), All) enjoy also nice tractability properties from the
perspective of Parameterized Complexity Theory [DF99], as they are ﬁxed-para-
meter tractable, and, in a precise technical sense, are maximal with this property
under a certain complexity-theoretic assumption (see [GSS01]).
The development so far shows that T (k) provides an island of tractability for
uniform constraint satisfaction. We now show that this island can be expanded.
Deﬁnition 9.7. Let A and B be two relational structures.
– We say that A and B are homomorphically equivalent, denoted A ∼h B, if
both A →B and B →A hold.
6 The intersection with T (k) ensures that only structures with treewidth bounded
by k are considered.

150
P.G. Kolaitis and M.Y. Vardi
– We say that B is the core of A, and write core(A) = B, if B is a substructure
of A, A →B holds, and A →B′ fails for each proper substructure B′ of B.
Clearly, core(Kk) = Kk and core(Cn) = Cn. On the other hand, if H is a 2-
colorable graph with at least one edge, then core(H) = K2. It should be noted
that cores play an important role in database query processing and optimization
(see [CM77]). The next result shows that they can also be used to characterize
when the canonical conjunctive query is deﬁnable in Lk.
Theorem 9.8.
[DKV02] Let k ≥2 be a positive integer and A a relational
structure. Then the following are equivalent:
– QA is deﬁnable in Lk.
– There is a structure B ∈T (k) such that A ∼h B.
– core(A) ∈T (k).
The tight connection between deﬁnability in Lk and the boundedness of the
treewidth of the core suggests a way to expand the “island” T (k).
Deﬁnition 9.9. If k ≥2 is a positive integer, then H(T (k)) is the class of
relational structures A such that core(A) has treewidth less than k.
It should noted that T (k) is properly contained in H(T (k)), for every k ≥2. In-
deed, it is known that there are 2-colorable graphs of arbitrarily large treewidth.
In particular, grids are known to have these properties (see [DF99]). Yet, these
graphs are members of H(T (2)), since their core is K2.
Theorem 9.10.
[DKV02] Let k ≥2 be a positive integer.
– If B is an arbitrary, but ﬁxed, structure, then H(T (k))∩CSP(H(T (k)), {B})
is expressible in k-Datalog.
– CSP(H(T (k)), All) is in PTIME. Moreover, CSP(H(T (k)), All) can be sol-
ved in polynomial time by determining whether, given a structure A ∈H(
T (k)) and an arbitrary structure B, the Spoiler or the Duplicator wins the
(∃, k)-pebble on A and B.
The preceding Theorem 9.10 yields new islands of tractability for uniform con-
straint satisfaction, which properly subsume the islands of tractability consti-
tuted by the classes of structures of bounded treewidth. This expansion of the
tractability landscape comes, however, at a certain price. Speciﬁcally, as seen
earlier, for every ﬁxed k ≥2, there is a polynomial-time algorithm for de-
termining membership in T (k) [Bod93]. In contrast, it has been shown that,
for every ﬁxed k ≥2, determining membership in H(T (k)) is an NP-complete
problem [DKV02]. Thus, these new islands of tractability are, in some sense,
“inaccessible”.
Since H(T (k)) contains structures of arbitrarily large treewidth, the bucket-
elimination algorithm cannot be used to solve CSP(H(T (k)), All) in polyno-
mial time. Thus, Theorem 9.10 also shows that determining the winner of the

A Logical Approach to Constraint Satisfaction
151
(∃, k)-pebble is a polynomial-time algorithm that applies to islands of tractability
not covered by the bucket elimination algorithm.
It is now natural to ask whether there are classes A of relational structures
that are larger than the classes H(T (k)) and CSP(A, All) is solvable in polyno-
mial time. A remarkable result by Grohe [Gro03] essentially shows that, if we
ﬁx the vocabulary, no such classes exist, provided a certain complexity-theoretic
hypothesis is true.
Theorem 9.11.
[Gro03] Assume that FPT ̸= W[1]. If A is a recursively
enumerable class of relational structures over some ﬁxed vocabulary such that
CSP(A, All) is in PTIME, then there is a positive integer k such that A ⊆
H(T (k)).
The hypothesis FPT ̸= W[1] is a statement in parameterized complexity that is
analogous to the hypothesis PTIME ̸= NP, and it is widely accepted as being
true (see [DF99]). In eﬀect, Grohe’s Theorem 9.11 is a converse to Theorem 9.10
for ﬁxed vocabularies. Together, these two theorems yield a complete characteri-
zation of all islands of tractability of the form CSP(A, All), where A is a class of
structures over some ﬁxed vocabulary. Moreover, they reveal that all tractable
cases of the form CSP(A, All) can be solved by the same polynomial-time al-
gorithm, namely, the algorithm for determining the winner in the (∃, k)-pebble
game. In other words, all tractable cases of constraint satisfaction of the form
CSP(A, All) can be solved in polynomial time using constraint propagation.
It is important to emphasize that the classes H(T (k)) are the largest islands
of tractability for uniform constraint satisfaction only under the assumption in
Theorem 9.11 of a ﬁxed vocabulary. For variable vocabularies, there is a long
line of research, studying the impact of the “topology” of conjunctive queries on
the complexity of their evaluation; this line of research goes back to the study of
acyclic joins in [Yan81], The connection between acyclic joins and acyclic con-
straints was pointed out in [GJC94]. This is still an active research area. Chekuri
and Ramajaran [CR97] showed that the uniform constraint-satisfaction problem
CSP(Q(k), All) is solvable in polynomial time, where Q(k) is the class of struc-
tures of querywidth k. Gottlob, Leone, and Scarcello [GLS99b] deﬁne another
notion of width, called hypertree width. They showed that the querywidth of a
structure A provides a strict upper bound for the hypertree width of A, but that
the class H(k) of structures of hypertree width at most k is polynomially recog-
nizable (unlike the class Q(k)), and that CSP(H(k), All) is tractable. For further
discussion on the relative merit of various notions of “width”, see [GLS99a]. This
is an active area of research (see [CD05,CJG05]).
Acknowledgements. We are grateful to Benoit Larose and Scott Weinstein for
helpful comments on a previous draft of this chapter. This work was supported in
part by NSF grants CCR-9988322, CCR-0124077, CCR-0311326, ANI-0216467,
and a Guggenheim Fellowship. Part of this work was done while the second
author was visiting the Isaac Newton Institute for Mathematical Science, as
part of a Special Programme on Logic and Algorithms.

152
P.G. Kolaitis and M.Y. Vardi
References
[ACP87]
Arnborg, S., Corneil, D.G., Proskurowski, A.: Complexity of ﬁnding em-
beddings in a k-tree. SIAM J. of Algebraic and Discrete Methods 8, 277–
284 (1987)
[AG94]
Ajtai, M., Gurevich, Y.: Datalog vs ﬁrst-order logic. J. Comput. Syst.
Sci. 49(3), 562–588 (1994)
[AHV95]
Abiteboul, S., Hull, R., Vianu, V.: Foundations of Databases. Addison-
Wesley, Reading (1995)
[Apt03]
Apt, K.: Principles of Constraint Programming. Cambridge Univ. Press,
Cambridge (2003)
[Ats05]
Atserias, A.: On digraph coloring problems and treewidth duality. In: Proc.
20th IEEE Symp. on Logic in Computer Science, pp. 106–115. IEEE Com-
puter Society Press, Los Alamitos (2005)
[Bib88]
Bibel, W.: Constraint satisfaction from a deductive viewpoint. Artiﬁcial
Intelligence 35, 401–413 (1988)
[BJK05]
Bulatov, A.A., Jeavons, P., Krokhin, A.A.: Classifying the complexity of
constraints using ﬁnite algebras. SIAM J. Comput. 34(3), 720–742 (2005)
[Bod93]
Bodlaender, H.L.: A linear-time algorithm for ﬁnding tree-decompositions
of small treewidth. In: Proc. 25th ACM Symp. on Theory of Computing,
pp. 226–234 (1993)
[Bul02]
Bulatov, A.A.: A dichotomy theorem for constraints on a three-element
set. In: Proc. 43rd Symp. on Foundations of Computer Science, pp. 649–
658. IEEE Computer Society, Los Alamitos (2002)
[Bul03]
Bulatov, A.A.: Tractable conservative constraint satisfaction problems. In:
Proc. 18th IEEE Symp. on Logic in Computer Science, pp. 321–330. IEEE
Computer Society, Los Alamitos (2003)
[CD05]
Chen, H., Dalmau, V.: Beyond hypertree width: Decomposition methods
without decompositions. In: van Beek, P. (ed.) CP 2005. LNCS, vol. 3709,
pp. 167–181. Springer, Heidelberg (2005)
[CJG05]
Cohen, D.A., Jeavons, P., Gyssens, M.: A uniﬁed theory of structural
tractability for constraint satisfaction and spread cut decomposition. In:
Proc. 19th Int’l Joint Conf. on Artiﬁcial Intelligence, pp. 72–77 (2005)
[CM77]
Chandra, A.K., Merlin, P.M.: Optimal implementation of conjunctive
queries in relational databases. In: Proc. 9th ACM Symp. on Theory of
Computing, pp. 77–90 (1977)
[CMR00]
Courcelle, B., Makowsky, J.A., Rotics, U.: Linear time solvable optimiza-
tion problems on graphs of bounded clique-width. Theory of Computing
Systems 33, 125–150 (2000)
[Coo89]
Cooper, M.C.: An optimal k-consistency algorithm. Artiﬁcial Intelli-
gence 41(1), 89–95 (1989)
[CR97]
Chekuri, C., Rajaraman, A.: Conjunctive query containment revisited. In:
Afrati, F.N., Kolaitis, P.G. (eds.) ICDT 1997. LNCS, vol. 1186, pp. 56–70.
Springer, Heidelberg (1996)
[Dal05]
Dalmau, V.: Generalized majority-minority operations are tractable. In:
Proc. 20th IEEE Symp. on Logic in Computer Science (LICS 2005), pp.
438–447 (2005)
[Dec92a]
Dechter, R.: Constraint networks. In: Shapiro, S.C. (ed.) Encyclopedia of
Artiﬁcial Intelligence, pp. 276–185. Wiley, Chichester (1992)
[Dec92b]
Dechter, R.: From local to global consistency. Artiﬁcial Intelligence 55(1),
87–107 (1992)

A Logical Approach to Constraint Satisfaction
153
[Dec99]
Dechter, R.: Bucket elimination: a unifying framework for reasoning. Ar-
tiﬁcial Intelligence 113(1–2), 41–85 (1999)
[Dec03]
Dechter, R.: Constraint Processing. Morgan Kaufmann, San Francisco
(2003)
[DF99]
Downey, R.G., Fellows, M.R.: Parametrized Complexity. Springer, Heidel-
berg (1999)
[DKV02]
Dalmau, V., Kolaitis, P.G., Vardi, M.Y.: Constraint satisfaction, bounded
treewidth, and ﬁnite-variable logics. In: Van Hentenryck, P. (ed.) CP 2002.
LNCS, vol. 2470, pp. 310–326. Springer, Heidelberg (2002)
[DM94]
Dechter, R., Meiri, I.: Experimental evaluation of preprocessing algorithms
for constraint satisfaction problems. Artiﬁcial Intelligence 68, 211–241
(1994)
[DP89]
Dechter, R., Pearl, J.: Tree clustering for constraint networks. Artiﬁcial
Intelligence, 353–366 (1989)
[DP99]
Dalmau, V., Pearson, J.: Closure functions and width 1 problems. In: Jaf-
far, J. (ed.) CP 1999. LNCS, vol. 1713, pp. 159–173. Springer, Heidelberg
(1999)
[Fed06]
Feder, T.: Constraint satisfaction: A personal perspective. Technical re-
port, Electronic Colloquium on Computational Complexity, Report TR06-
021 (2006)
[FF05]
Feder, T., Ford, D.: Classiﬁcation of bipartite boolean constraint satisfac-
tion through delta-matroid intersection (2005)
[Fre78]
Freuder, E.C.: Synthesizing constraint expressions. Communications of the
ACM 21(11), 958–966 (1978)
[Fre82]
Freuder, E.C.: A suﬃcient condition for backtrack-free search. Journal of
the Association for Computing Machinery 29(1), 24–32 (1982)
[Fre90]
Freuder, E.C.: Complexity of k-tree structured constraint satisfaction
problems. In: Proc. AAAI 1990, pp. 4–9 (1990)
[Fro97]
Frost, D.H.: Algorithms and Heuristics for Constraint Satisfaction Prob-
lems. Ph.D thesis, Department of Computer Science, University of Cali-
fornia, Irvine (1997)
[FV93]
Feder, T.A., Vardi, M.Y.: Monotone monadic SNP and constraint satis-
faction. In: Proc. 25th ACM Symp. on Theory of Computing, pp. 612–622
(1993)
[FV98]
Feder, T., Vardi, M.Y.: The computational structure of monotone monadic
SNP and constraint satisfaction: a study through Datalog and group the-
ory. SIAM J. on Computing 28, 57–104 (1998); Preliminary version in
Proc. 25th ACM Symp. on Theory of Computing, pp. 612–622 (May 1993)
[GJ79]
Garey, M.R., Johnson, D.S.: Computers and Intractability - A Guide to the
Theory of NP-Completeness. W. H. Freeman and Co., New York (1979)
[GJC94]
Gyssens, M., Jeavons, P.G., Cohen, D.A.: Decomposition constraint sat-
isfaction problems using database techniques. Artiﬁcial Intelligence 66,
57–89 (1994)
[GKL+05]
Gr¨adel, E., Kolaitis, P.G., Libkin, L., Marx, M., Spencer, J., Vardi, M.Y.,
Venema, Y., Weinstein, S.: Finite Model Theory and Its Applications
(Texts in Theoretical Computer Science. In: Finite Model Theory and Its
Applications (Texts in Theoretical Computer Science. An EATCS Series).
Springer, New York (2005)
[GLS98]
Gottlob, G., Leone, N., Scarcello, F.: The complexity of acyclic conjunctive
queries. In: Proc. 39th IEEE Symp. on Foundation of Computer Science,
pp. 706–715 (1998)

154
P.G. Kolaitis and M.Y. Vardi
[GLS99a]
Gottlob, G., Leone, N., Scarcello, F.: A comparison of structural CSP
decomposition methods. In: Proc. 16th Int’l. Joint Conf. on Artiﬁcial In-
telligence (IJCAI 1999), pp. 394–399 (1999)
[GLS99b]
Gottlob, G., Leone, N., Scarcello, F.: Hypertree decompositions and
tractable queries. In: Proc. 18th ACM Symp. on Principles of Database
Systems, pp. 21–32 (1999)
[GMSV87]
Gaifman, H., Mairson, H., Sagiv, Y., Vardi, M.Y.: Undecidable optimiza-
tion problems for database logic programs. In: Proc. 2nd IEEE Symp. on
Logic in Computer Science, pp. 106–115 (1987)
[Gro03]
Grohe, M.: The complexity of homomorphism and constraint satisfaction
problems seen from the other side. In: Proc. 44th IEEE Symp. on Foun-
dations of Computer Science, pp. 552–561. IEEE Computer Society, Los
Alamitos (2003)
[GSS01]
Grohe, M., Schwentick, T., Segouﬁn, L.: When is the evaluation of con-
junctive queries tractable? In: Proc. 33rd ACM Symp. on Theory of Com-
puting, pp. 657–666 (2001)
[HN90]
Hell, P., Neˇsetˇril, J.: On the complexity of H-coloring. Journal of Combi-
natorial Theory, Series B 48, 92–110 (1990)
[HN04]
Hell, P., Neˇsetˇril, J.: Graphs and Homomorphisms. Oxford Lecture Series
in Mathematics and Its applications, vol. 28. Oxford Univ. Press, Oxford
(2004)
[KP03]
Kolaitis, P.G., Panttaja, J.: On the complexity of existential pebble games.
In: Baaz, M., Makowsky, J.A. (eds.) CSL 2003. LNCS, vol. 2803, pp. 314–
329. Springer, Heidelberg (2003)
[Kum92]
Kumar, V.: Algorithms for constraint-satisfaction problems. AI Maga-
zine 13, 32–44 (1992)
[KV87]
Kolaitis, P.G., Vardi, M.Y.: The decision problem for the probabilities of
higher-order properties. In: Proc. 19th ACM Symp. on Theory of Com-
puting, pp. 425–435 (1987)
[KV96]
Kolaitis, P.G., Vardi, M.Y.: On the expressive power of variable-conﬁned
logics. In: Proc. 11th IEEE Symp. on Logic in Computer Science, pp.
348–359 (1996)
[KV00a]
Kolaitis, P.G., Vardi, M.Y.: Conjunctive-query containment and constraint
satisfaction. Journal of Computer and System Sciences, 302–332 (2000);
Earlier version in Proc. 17th ACM Symp. on Principles of Database Sys-
tems (PODS 1998)
[KV00b]
Kolaitis, P.G., Vardi, M.Y.: A game-theoretic approach to constraint satis-
faction. In: Proc. of the 17th National Conference on Artiﬁcial Intelligence
(AAAI 2000), pp. 175–181 (2000)
[Lad75]
Ladner, R.E.: On the structure of polynomial time reducibility. J. Assoc.
Comput. Mach. 22, 155–171 (1975)
[Lev73]
Levin, L.A.: Universal sorting problems. Problemy Peredaci Informacii 9,
115–116 (1973); English translation in Problems of Information Transmis-
sion 9, 265–266 (in Russian)
[LLT06]
Larose, B., Loten, C., Tardiﬀ, C.: A characterization of ﬁrst-order con-
straint satisfaction problems. In: Proc. 21st IEEE Symp. on Logic in Com-
puter Science (2006)
[Mes89]
Meseguer, P.: Constraint satisfaction problem: an overview. AICOM 2,
3–16 (1989)
[MF93]
Mackworth, A.K., Freuder, E.C.: The complexity of constraint satisfaction
revisited. Artiﬁcial Intelligence 59(1-2), 57–62 (1993)

A Logical Approach to Constraint Satisfaction
155
[MPPV04]
McMahan, B.J., Pan, G., Porter, P., Vardi, M.Y.: Projection pushing revis-
ited. In: Bertino, E., Christodoulakis, S., Plexousakis, D., Christophides,
V., Koubarakis, M., B¨ohm, K., Ferrari, E. (eds.) EDBT 2004. LNCS,
vol. 2992, pp. 441–458. Springer, Heidelberg (2004)
[NR90]
Seymour, P.D., Robertson, N.: Graph minors iv: Tree-width and well-
quasi-ordering. J. Combinatorial Theory, Ser. B 48(2), 227–254 (1990)
[PJ97]
Pearson, J., Jeavons, P.: A survey of tractable constraint satisfaction prob-
lems. Technical Report CSD-TR-97-15, Royal Holloway University of Lon-
don (1997)
[PY91]
Papadimitriou, C., Yannakakis, M.: Optimization, approximation and
complexity classes. J. Comput. System Sci. 43, 425–440 (1991)
[Ros95]
Rosen, E.: Finite Model Theory and Finite Variable Logics. Ph.D thesis,
University of Pennsylvania (1995)
[Ros05]
Rossman, B.: Existential positive types and preservation under homomor-
phisisms. In: Proc. 20th IEEE Symp. on Logic in Computer Science, pp.
467–476. IEEE Computer Society, Los Alamitos (2005)
[Sar91]
Saraiya, Y.: Subtree elimination algorithms in deductive databases. Ph.D
thesis, Department of Computer Science, Stanford University (1991)
[Sch78]
Schaefer, T.J.: The complexity of satisﬁability problems. In: Proc. 10th
ACM Symp. on Theory of Computing, pp. 216–226 (1978)
[Tsa93]
Tsang, E.P.K.: Foundations of Constraint Satisfaction. Academic Press,
London (1993)
[Var82]
Vardi, M.Y.: The complexity of relational query languages. In: Proc. 14th
ACM Symp. on Theory of Computing, pp. 137–146 (1982)
[Var95]
Vardi, M.Y.: On the complexity of bounded-variable queries. In: Proc.
14th ACM Symp. on Principles of Database Systems, pp. 266–276 (1995)
[vB94]
van Beek, P.: On the inherent tightness of local consistency in constraint
networks. In: Proc. of National Conference on Artiﬁcial Intelligence (AAAI
1994), pp. 368–373 (1994)
[vBD97]
van Beek, P., Dechter, R.: Constraint tightness and looseness versus local
and global consistency. Journal of the ACM 44(4), 549–566 (1997)
[Yan81]
Yannakakis, M.: Algorithms for acyclic database schemes. In: Proc. 7 Int’l.
Conf. on Very Large Data Bases, pp. 82–94 (1981)

Uniform Constraint Satisfaction Problems and
Database Theory
Francesco Scarcello1, Georg Gottlob2, and Gianluigi Greco3
1 DEIS, Universit`a della Calabria, Italy
scarcello@deis.unical.it
2 Computing Laboratory, University of Oxford, UK
georg.gottlob@comlab.ox.ac.uk
3 Dipartimento di Matematica, Universit`a della Calabria, Italy
ggreco@mat.unical.it
Abstract. It is well-known that there is a close similarity between con-
straint satisfaction and conjunctive query evaluation. This paper explains
this relationship and describes structural query decomposition methods
that can equally be used to decompose CSP instances. In particular, we
explain how “islands of tractability” can be achieved by decomposing the
query on a database, or, equivalently, the scopes of a constraint satis-
faction problem. We focus on advanced decomposition methods such as
hypertree decompositions, which are hypergraph-based and subsume ear-
lier graph-based decomposition methods. We also discuss generalizations
thereof, such as weighted hypertree decompositions, and subedge-based
decompositions. Finally, we report on an interesting new type of struc-
tural tractability results that, rather than explicitly computing problem
decompositions, use algorithms that are guaranteed to ﬁnd a correct so-
lution in polynomial time if a decomposition exists.
1
Uniform CSPs and DBs
Constraint Satisfaction is a well-known framework to model and solve search
problems, and has an impressive spectrum of applications [64].
An instance of a constraint satisfaction problem (CSP) (also constraint net-
work) (e.g., [21]) is a triple I = (Var, U, C), where Var is a ﬁnite set of variables,
U is a ﬁnite domain of values, and C = {C1, C2, . . . , Cq} is a ﬁnite set of con-
straints. Each constraint Ci is a pair (Si, ri), where Si is a list of variables of
length mi called the constraint scope, and ri is an mi-ary relation over U, called
the constraint relation. (The tuples of ri indicate the allowed combinations of
simultaneous values for the variables Si). A solution to a CSP instance is a
substitution θ : Var −→U, such that for each 1 ≤i ≤q, Siθ ∈ri. The prob-
lem of deciding whether a CSP instance has any solution is called constraint
satisﬁability (CS).
Observe that in this chapter we will focus on CSPs where the constraint
relations are ﬁnite and explicitly given. If they are represented as functions to
be computed, or in other succinct ways, then many results that we describe may
N. Creignou et al. (Eds.): Complexity of Constraints, LNCS 5250, pp. 156–195, 2008.
c
⃝Springer-Verlag Berlin Heidelberg 2008

Uniform Constraint Satisfaction Problems and Database Theory
157
b
c
d
e
f
g
h
a
Fig. 1. The graph G1
be not usable as they are, and requires suitable adaptations. In some cases, they
cannot proﬁtably be applied at all.
Many well-known problems in Computer Science and Mathematics can be
formulated as CSPs.
Example 1. The famous graph three-colorability (3COL) problem, i.e., deciding
whether the vertices of a graph G = (Vertices, Edges) can be colored by three
colors (say: red, green, blue) such that no edge links two vertices having the
same color, is formulated as follows as a CSP. The set Var contains a variable
Xv for each vertex v ∈Vertices. For each edge e = {v, w} ∈Edges, where v < w
according to some ordering on Vertices, the set C contains a constraint Ce =
(Se, re), where Se = (Xv, Xw) and re is the relation r̸= consisting of all pairs
of diﬀerent colors, i.e., r̸= = {⟨red, green⟩, ⟨red, blue⟩, ⟨green, red⟩, ⟨green, blue⟩,
⟨blue, red⟩, ⟨blue, green⟩}.
For instance, the set of constraints for the graph G1 in Figure 1 is the following
C = {((A, B), r̸=), ((A, D), r̸=), ((A, G), r̸=), ((B, C), r̸=), . . ., ((G, H), r̸=)}.
◁
Example 2. Figure 2 shows a combinatorial crossword puzzle, which is a typical
CSP [20,64]. A set of legal words is associated to each horizontal or vertical array
of white boxes delimited by black boxes. A solution to the puzzle is an assignment
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
Fig. 2. A crossword puzzle

158
F. Scarcello, G. Gottlob, and G. Greco
of a letter to each white box such that to each white array is assigned a word
from its set of legal words.
This problem is represented as follows. There is a variable Xi for each white
box, and a constraint C for each array D of white boxes. (For simplicity, we
just write the index i for variable Xi.) The scope of C is the list of variables
corresponding to the white boxes of the sequence D; the relation of C con-
tains the legal words for D. For the example in Figure 2, we have C1H
=
((1, 2, 3, 4, 5), r1H), C8H
=
((8, 9, 10), r8H), C11H
=
((11, 12, 13), r11H),
C20H
=
((20, 21, 22, 23, 24, 25, 26), r20H), C1V
=
((1, 7, 11, 16, 20), r1V ),
C5V
=
((5, 8, 14, 18, 24), r5V ), C6V
=
((6, 10, 15, 19, 26), r6V ), C13V
=
((13, 17, 22), r13V ). Subscripts H and V stand for “Horizontal” and “Vertical,” re-
spectively, resembling the usual naming of deﬁnitions in the crossword puzzles. A
possible instance for the relation r1H is {⟨h, o, u, s, e⟩, ⟨c, o, i, n, s⟩, ⟨b, l, o, c, k⟩}. ◁
It is well-known and easy to see that Constraint Satisﬁability is an NP-complete
problem. Membership in NP is obvious. NP-hardness follows, e.g., immediately
from the NP hardness of 3COL [29].
Moreover, it has been observed [55] that constraint satisﬁability can be recast
as the fundamental homomorphism problem (HOM). Recall that a relational
structure A consists of a set U, called the universe of A, and a sequence of
relations R1, R2, . . . , Rm over U. For example, a graph is a structure with a
single binary relation that is symmetric and irreﬂexive. All structures in this
chapter are assumed to be ﬁnite, i.e., having a ﬁnite universe.
Let A = ⟨U, R1, R2, . . . , Rm⟩and B = ⟨V, S1, S2, . . . , Sm⟩be two relational
structures. A mapping between the two domains h : U →V is a homomorphism
if, for every tuple X and every 1 ≤i ≤m, X ∈Ri entails h(X) ∈Si, where
h(⟨X1, X2, . . . , Xa⟩) denotes the tuple ⟨h(X1), h(X2), . . . , h(Xa)⟩. A pair of re-
lational structures (A, B) is a “yes” instance of the homomorphism problem if
there exists such a mapping from A to B. If this is the case, we will simply write
A →B, hereafter.
For instance, the CSP in Example 1 can be seen as the homomorphism in-
stance (G, T ), where G = ⟨Vertices, Edges⟩is the graph relational structure, and
T is the relational structure ⟨{red, green, blue}, r̸=⟩(that is in fact the triangle
graph K3, because any pair of diﬀerent colors is a tuple of the binary relation r̸=).
More
in
general,
any
CSP
instance
(Var, U, {C1, C2, . . . , Cq}),
with
Ci
=
(Si, ri), 1
≤
i
≤
q, corresponds to a homomorphism instance
(⟨Var, S1, S2, . . . , Sq⟩, ⟨U, r1, r2, . . . , rq⟩), and vice versa. Note that, in case of
arbitrary (non-binary) relations, we cannot simply look at these structures as
graphs, e.g., think of the crossword puzzle example in Figure 2.
Denote the former relational structure—with the constraint scopes—by S,
and the latter one—with the constraint relations—by R. Then, we may formally
deﬁne the Constraint Satisﬁability language in terms of homomorphisms:
CSP = {(S, R) | S →R},
where (S, R) is a suitable (string) encoding of the two relational structures. This
general version of the problem, where the input is such a pair (S, R), and we

Uniform Constraint Satisfaction Problems and Database Theory
159
have to decide whether (S, R) ∈CSP, is also known as the Uniform Constraint
Satisfaction Problem. We will see some important restricted variants of this
problem in the following sections.
It has been shown that Constraint Satisﬁability and Homomorphism are in
fact equivalent to various problems in Database theory [49,20,55], e.g., to the
problem of conjunctive query containment [55], or to the problem of evaluating
Boolean conjunctive queries over a relational database [58]. Recall that a con-
junctive query Q on a database schema DS = {R1, . . . , Rm} consists of a formula
of the form
Q :
ans(u0) ←r1(u1) ∧· · · ∧rn(un),
where n ≥0; r1, . . . rn are relation names (not necessarily distinct) of DS; ans is
a relation name not in DS; and u0, u1, . . . , un are lists of terms (i.e., variables or
constants) of appropriate length. The set of variables occurring in Q is denoted by
var(Q). The set of atoms contained in the body of Q is referred to as atoms(Q).
The answer of Q on a database instance db (of the schema DS), with as-
sociated universe U, consists of a relation ans, whose arity is equal to the
length of u0, deﬁned as follows. Relation ans contains all tuples u0θ such that
θ : var(Q) −→U is a substitution replacing each variable in var(Q) by a value
of U and such that for 1 ≤i ≤n, ri(ui)θ ∈db. (For an atom A, Aθ denotes
the atom obtained from A by uniformly substituting θ(X) for each variable X
occurring in A.) If u0 is empty, Q is a Boolean conjunctive query.
Observe that answering a Boolean conjunctive query Q on db is exactly the
same problem as CSP (Homomorphism). Indeed, consider the relational struc-
tures Q = ⟨var(Q), atoms(Q)⟩and D = ⟨U, db⟩corresponding to query and
database, respectively. Then, the answer of Q is “yes” if and only if Q →D, as
the substitution θ in the answer deﬁnition is nothing else than a homomorphism
between these relational structures. That is, answering Q on db means solving
the CSP instance (Q, D). On the other hand, every CSP instance is associated
with a query having the constraint scopes as its atoms. For instance, the CSP in
Example 1 can be seen as the Boolean conjunctive query ans ←
e∈Edges, where
the set of variables occurring in the query is the set Nodes, and the database has
the colors as its universe and consists only of the relation r̸=.
Therefore, cross fertilization among these diﬀerent research ﬁelds was possi-
ble and led to major achievements both in the AI and the DB communities.
However, observe that, even if in principle we are talking about equivalent prob-
lems, in practice the instances considered in the applications are very diﬀerent,
and thus one cannot simply take any technique from AI and apply it to DB, or
vice-versa. Typical CSP instances are characterized by many constraints with
relatively small constraint relations, while typical query-answering tasks involve
relatively small queries on large (often huge) databases. In fact, e.g., the pow-
erful backtracking-like procedures developed for CSPs does not work for typical
queries, while the sophisticated indexing techniques developed for DBs are quite
useless in typical CSPs.
It follows that, not surprisingly, the major interactions and most of the
results applicable to both ﬁelds are about the CSP uniform problem and,

160
F. Scarcello, G. Gottlob, and G. Greco
correspondingly, about query answering tasks where both the query and the
database are part of the problem input. Indeed, in the uniform case, we have to
take care of both relational structures, as we are not allowed to assume either to
be very small—and hence representable in the applications by a ﬁxed parameter
of the problem, as in the non-uniform case.
2
Islands of Tractability
As we have seen, in its general version Constraint Satisﬁability is an intractable
problem. Therefore, diﬀerent restrictions of the basic fundamental problem have
been studied, in order to circumvent its hardness and to model speciﬁc applica-
tion domains, sometimes easier and tractable.
Let A and B be two classes (possibly inﬁnite sets) of relational structures.
Then, the Uniform Constraint Satisfaction Problem can be generalized as follows:
CSP(A, B) = {(S, R) | S ∈A, S ∈B, and S →R}.
That is, the input is a pair of relational structures (S, R), and we have to decide
whether (S, R) ∈CSP(A, B), with A and B parameters of the problem. Clearly,
according to this notation, the standard Uniform Constraint Satisfaction Prob-
lem is CSP(All, All), where All denotes the class of all relational structures,
and thus no restriction is given for the possible inputs of both sides of the homo-
morphism (constraints scopes and constraint relations). In database theory, the
complexity of the general unrestricted problem is called the combined complex-
ity of conjunctive queries, because the input of the problem consists of both the
query and the database. However, in many applications, the query is very small
or ﬁxed, while the database is large and growing. Then, the query is modeled as
a ﬁxed parameter Q of the problem and the input consists of the database only.
That is, the homomorphism problem to be solved is CSP({Q}, All), where Q is
the relational structure associated with the ﬁxed query Q, and we actually have
a single input because the pair of input structures reduces to the only structure
D ∈All associated with the given database db. In these cases, we speak of the
data complexity of conjunctive queries. Finally, the last combination where the
database is ﬁxed and the query is the input is called expression complexity [78].
Correspondingly, in constraint satisfaction research, an important role is
played by the Non-Uniform Constraint Satisfaction Problem, deﬁned for any
ﬁxed relational structure R:
CSP(All, {R}).
In this case, the input is thus a single relational structure S ∈All, and we
have to decide whether there is a homomorphism from S to R. Note that this
is precisely the expression complexity of conjunctive queries, as the database
(also, the set of constraint relations) is ﬁxed. Clearly enough, this restriction of
the general problem ﬁnds many more applications in CSPs than in databases,
and thus received much more attention in the former research area, as witnessed

Uniform Constraint Satisfaction Problems and Database Theory
161
by many chapters of this book, devoted to the study of the Non-Uniform CSP.
Interestingly, this problem is also equivalent to the data complexity of existential
MMSNP formulas (monotone monadic strict NP without inequality) [25,57].
The quest for tractable cases of constraint satisﬁability and database problems
leads the researchers to the identiﬁcation of tractable classes of CSP instances. In
fact, looking at the deﬁnition of the problem, we may naturally consider diﬀerent
ways of restricting the problem, focusing either on the class of structures A or on
the class of structures B. The former approaches are usually classiﬁed as left-hand
restrictions, while the latter ones are classiﬁed as right-hand restrictions, because
of the side where their instances S ∈A, R ∈B occur in the homomorphism
relationship S →R.
The case of restrictions on both sides is clearly a very attracting option, but
we do not have equally attracting results, up to now. Finding such combined
left-right tractable classes—not trivially following from known results on either
kind of restriction—is currently a challenging research issue.
In this chapter we deal with left-hand restrictions for the Uniform Constraint
Satisfaction Problem, looking for the so-called islands of tractability, where
tractability is based on structural properties of CSPs [54].
Deﬁnition 1. A class A of relational structures is an island of tractability if
1. deciding whether S ∈A belongs to P, i.e., checking membership to the class
is feasible in polynomial time, and
2. CSP(A, All) ∈P, that is, for each S ∈A and for each R, deciding whether
there is a homomorphism from S to R is feasible in polynomial time.
2
Note that the two conditions above are only the basic requirements, and model
the tractability of the decision problem. In fact, in real-world applications, we are
mainly interested in the search problem of “computing” a homomorphism, i.e., a
mapping for the variables of the CSP (or of the query). In many applications—
almost always in databases, we actually need all solutions of the problem. How-
ever, in these cases a polynomial-time algorithm cannot exist, because in general
there are exponentially many solutions, and thus the best we can do is to have
an algorithm that compute all mappings in time polynomial in the combined
size of the input and of the output, also called input-output polynomial time.
Therefore, a highly desirable property for an island of tractability A is
2′. for each S ∈A and for each R, the set H of all homomorphisms from S to
R can be computed in O((|S| + |R| + |H|)k), for some constant k ≥0, and
where | · | denotes the size of a structure.
2
A slightly stronger property that entails both Condition 2 and Condition 2′ is
called polynomial-time output delay. In this case, it is required to have an algo-
rithm that is able to compute all solutions, with the delay to output any new
solution being bounded by a polynomial of the input. This could be particularly
useful if we do not actually need all solutions, but just look for some solution
that meets speciﬁc requirements, or we are interested in a small number of so-
lutions. Indeed, such an algorithm would be any-time, that is, you can stop it

162
F. Scarcello, G. Gottlob, and G. Greco
whenever you are satisﬁed with the solutions you obtained up to that moment
(if any), with the guarantee that the time you have waited is (polynomially)
proportional with the number of solutions in your hands. Instead, in the case
of input-output polynomial time algorithms (without the polynomial-time out-
put delay property), if there are exponentially many solutions, you can wait
exponential time (in the input) before starting to get them. For instance, the
algorithm may require some long preliminary step, proportional to the number
of solutions, before starting its output phase.
2.1
Graphs and Hypergraphs
In order to identify islands of tractability, we have to ﬁnd classes of relational
structures A, whose elements have something in common that make the ho-
momorphism problem CSP(A, All) easy. The idea is to look at their structure,
looking for some feature to be exploited in the algorithms. In particular, we are
interested in the way tuples belonging to diﬀerent relations interact with each
other. For a basic example, if there is no connection, that is, every value of the
universe occurs in one relation only, the problem is trivial. We will see that there
are much more interesting properties that characterize tractable classes.
The structure of a relational structure S = ⟨V, R1, R2, . . . , Rm⟩is best rep-
resented by its associated hypergraph H(S) = (V, H), whose set of vertices is
the universe V of S and the set of hyperedges consists of the tuples of S, i.e.,
H = {t | t ∈Ri, 1 ≤i ≤m}.
Since we are dealing with left-hand structures, each relation corresponds to
a constraint scope and contains just one tuple, with the list of variables of that
scope. Thus, the vertices of the hypergraph are the variables of the CSP prob-
lem, and the hyperedges are its constraint scopes—actually, the sets of variables
occurring therein. Figure 3 shows the hypergraph Hcp associated with the cross-
word puzzle in Example 2.
1
5
20
25
4
3
2
7
11
12
21
23
24
26
16
8
9
10
14
18
15
19
13
17
22
6
6V
5V
20H
13V
11H
1V
1H
8H
Fig. 3. Hypergraph Hcp of the crossword puzzle in Example 2

Uniform Constraint Satisfaction Problems and Database Theory
163
Fig. 4. Hypergraph H(Qa) (right) and join tree JTa (left) for query Qa
Of course, for database queries we have the analogous situation: for a con-
junctive query Q, its query hypergraph H(Q) has the set of variables occurring in
Q as its vertices, and the query atoms as its hyperedges. More precisely, for each
query atom A of Q, the set var(A) of all variables occurring in A is a hyperedge
of H(Q).
Example 3. Consider the following query Qa: ans ←p1(J, X , Y , X ′, Y ′) ∧
p2(X , X ′, Y , Y ′, S, C, C ′, F, F ′) ∧p3(X , Y , C, C ′, Z) ∧p4(X ′, Y ′, F, F ′, Z ′) ∧
p5(X , Z) ∧p6(Y , Z) ∧p7(X ′, Z ′) ∧p8 (Y ′, Z ′).
Figure 4 shows on the left its associated hypergraph H(Qa).
◁
Since in this paper we always deal with hypergraphs corresponding to CSPs
instances or queries, the vertices of any hypergraph H = (V, H) are always
variables of some instance of these problems. Thus, we will often use the term
variable as a synonym for vertex, when referring to elements of V . Moreover,
var(H) and edges(H) will denote the sets V and H, respectively.
Before leaving this section we note that, historically, the ﬁrst attempts to
identify islands of tractability for constraint satisfaction problems have been
done in the context of binary CSPs, i.e., when each relation Ri in the structure
S = ⟨V, R1, R2, . . . , Rm⟩is binary. In this case, it is easy to see that H(S) =
(V, H) is in fact a graph. Therefore, it comes with no surprise that several eﬀorts
have been spent to exploit the many existent methods to the case of general (non-
binary) CSPs, by representing any CSP instance by some graph, rather than by
its associated hypergraph. In particular, for a given hypergraph H = (V, H), the
following graph representations have been proposed in the literature:
Primal-graph Representation. The primal graph of H, denoted by G(H) =
(N, E), is the graph whose set of vertices N is the set of variables V , and
whose edges connect each pair of vertices (i.e., variables) occurring together
in some hyperedge, that is E = {{V1, V2} | ∃h ∈H s.t. {V1, V2} ⊆h}.
Dual-graph Representation [20]. The
dual
graph
of
H,
denoted
by
dual(H) = (N, E), is the graph whose set of vertices N is the set of hy-
peredges H, and whose edges connect each pair of vertices (i.e., hyper-
edges) having some variable in common, that is E = {{h1, h2} | h1, h2 ∈
H and h1 ∩h2 ̸= ∅}.

164
F. Scarcello, G. Gottlob, and G. Greco
Hidden-variable Representation [72]. The incidence graph of H, denoted
by inc(H) = (N, E), is bipartite graph where N = H ∪V and E = { {h, a} |
h ∈H and a ∈h)}, i.e. it contains an edge from h to a if and only if the
variable a occurs in the hyperedge h.
The relationships among the islands of tractability designed for binary prob-
lems, and hence based on graph properties of such binarized instances, as well as
their relationships with hypergraph based techniques, have been studied in [34]
and in [45]. In particular, the latter work focused on the relationships among
islands of tractability—possibly based on the same graph property—when the
above diﬀerent graph representations are chosen.
It turned out that, using graphs instead of hypergraphs we have a substantial
loss in information and, consequently, we are not able to identify some large
tractable classes of instances. Therefore, since in this chapter we focus on the
general non-binary CSP uniform problem, we next deal with hypergraph-based
approaches only.
2.2
Solving Acyclic Problems
One of the most important and deeply studied island of tractability is the class
of acyclic structures [8,14,23,32,55,63,67,81,82].
Deﬁnition 2. A relational structure S is acyclic if and only if its hypergraph
H(S) is acyclic or, equivalently, if it has a join forest. A join forest for the
hypergraph H(S) is a forest G whose set of vertices VG is the set edges(H(S)) and
such that, for each pair of hyperedges h1, h2 ∈VG having variables in common
(i.e., such that h1 ∩h2 ̸= ∅), the following conditions hold:
1. h1 and h2 belong to the same connected component of G, and
2. all variables common to h1 and h2 occur in every vertex on the (unique)
path in G from h1 to h2. This is known as the connectedness condition of
join forests.
If G is a tree, then it is called a join tree for H(S). For instance, Figure 4 shows
a join tree of the hypergraph H(Qa) associated with query Qa in Example 3. 2
Solving CSP instances whose left-hand sides have associated acyclic hypergraphs
is feasible in polynomial time. In fact, this was ﬁrstly observed within the
database theory community. Therefore, it is easier and more convenient for the
presentation to describe techniques and results tailored for acyclic instances in
terms of queries and databases, keeping in mind their equivalence with CSPs
and homomorphisms.
Consider a conjunctive query
Q :
ans(u0) ←r1(u1) ∧· · · ∧rn(un)
on a database instance db. Recall that a join operation between a pair of
atoms ri(ui) and rj(uj) with respect to db, denoted by ri(ui) ▷◁rj(uj), gives

Uniform Constraint Satisfaction Problems and Database Theory
165
a new database relation rij containing the set of tuples {ti · tj | ti ∈ri, tj ∈
rj, and ti matches tj}, where · is the concatenation operator, and two tuples are
matching if they have the same values in correspondence to any variable X ∈ui∩
uj they have in common. In other words, rij contains all homomorphisms from
the relational structure associated with such pair of atoms to the relational struc-
tures associated with the two relations ri and rj in db. Note that ri(ui) ▷◁rj(uj)
can be computed in O(|ri(ui)| log(|ri(ui)|) + |rj(uj)| log(|rj(uj)|) + |rij(ui, uj)|),
by using sorting and merging techniques. Of course this cost in general is
quadratic, because the size of the output relation rij can be O(|ri(ui)||rj(uj)|),
if all pair of tuples from the two relations are matching. Moreover, recall that the
projection 
v r(u) with respect to db of an atom r(u) over a set of variables v
is a new database relation r′ containing the set of tuples obtained by restricting
the tuples of r to (the values corresponding to) those variables that u and v have
in common. This operation is feasible in linear time, plus the cost of deleting
possible duplicates (in this chapter we deal with mathematical relations, which
are sets, and not with the so called bag semantics, where duplicates are allowed).
Finally, a semijoin operation between a pair of atoms ri(ui) and rj(uj) with re-
spect to db, denoted by ri(ui) ⋉rj(uj), modiﬁes the database relation ri by
assigning to it the result of the relational expression 
ui(ri(ui) ▷◁rj(uj)). That
is, the relation ri ∈db is ﬁltered by deleting those tuples that matches no tuple
in rj. This operation is feasible in O(|ri(ui)| log(|ri(ui)|)+|rj(uj)| log(|rj(uj)|)),
by using sorting and merging techniques, and the size of the result is clearly
bounded by |ri(ui)|.
It is well-known and easy to see that the answer of Q on a database instance
db can be computed simply by performing the join of all query atoms and then
computing the projection of the resulting ﬁnal atom rQ(var(Q)) over the output
variables u0. The relation obtained from the projection is the desired answer-
relation ans. Note that rQ(var(Q)) encodes all homomorphisms between the
relational structure associated with Q and the one associated with the database
instance db. Of course, the decision problem does not need the ﬁnal projection
step, as it is suﬃcient to check whether rQ(var(Q)) is empty or not. The above
procedure is in fact used in real-world database applications, with the help of
indices based on advanced data structures, join ordering techniques and so on.
The problem is that, when the query involves many atoms (the typical CSP
situation), the temporary atoms obtained after the join computations may grow
exponentially, up to O(|r1| · |r2| · · · |rn|), where the number of tuples in any
relation may be in the order of several thousands, with sizes of several hundreds
of megabytes, in typical database applications. For the sake of presentation, we
may consider the simple upper bound O(|rmax|n), where rmax is the relation
of db having the largest size. It is worthwhile noting that a huge temporary
relation may be computed even if the result is eventually empty, because it
could be discovered at the very end, after the join of this temporary relation
with the last query atom to be processed.
For acyclic instances, we can do much better. In fact, according to Yan-
nakakis’s algorithm [81], they can be evaluated by processing any of their join

166
F. Scarcello, G. Gottlob, and G. Greco
trees bottom-up, by performing upward semijoins, thus keeping the size of the
intermediate relations small. At the end, if the relation associated with the root
atom of the join tree is not empty, then the answer of the query is not empty, or,
equivalently, there are some homomorphisms. Therefore, acyclic Boolean con-
junctive queries can be evaluated in O((n −1)|rmax| log |rmax|), because we per-
form n −1 semijoins, one for each edge of the join tree, whose vertices are the n
atoms in the body of the query.
Example 4. Consider again the Boolean query Qa in Example 3 and its join
tree in Figure 4. Then, we know that it can be evaluated very eﬃciently,
in O(6|rmax| log |rmax|): we start computing the semijoin p3(X, Y, C, C′, Z) ⋉
p5(X, Z), then the semijoin of p3(X, Y, C, C′, Z) ⋉p6(X, Z), and so on, fol-
lowing a topological order of the tree. Eventually, we compute the semijoin of
p1(J, X, Y, X′, Y ′) with its child, and we are done. The answer of the Boolean
query Qa is true if and only if the relation obtained after the last semijoin is not
empty.
◁
Let us recall the highly desirable computational properties of acyclic instances:
1. Acyclicity is eﬃciently recognizable: deciding whether a hypergraph is acyclic
is feasible in linear time [76] and belongs to the class L (deterministic
logspace). The latter result is quite new: it follows from the fact that hyper-
graph acyclicity belongs to SL [37], and from the recent proof that SL is in
fact equal to L [61].
2. Acyclic instances can be eﬃciently solved. Besides the polynomial time al-
gorithm for Boolean acyclic queries, Yannakakis showed that the answer of
a non-Boolean acyclic conjunctive query can be computed in input-output
polynomial time [81]. Indeed, after the bottom-up step described above, one
can perform the reverse top-down step, again based on semi-join operations
but changing the order, this time ﬁltering a child vertex of the join tree
from those tuples that do not match with its parent tuples. The relations
obtained after the top-down step contain only tuples whose values are part
of some answer of the query, no useless tuples are kept. The new database
consisting of these ﬁltered relations is called full reducer. Moreover, we say
that the new instance has the global consistency property: no tuple can be
missed if we compute the join of all query atoms (with respect to the new
database). Then, from the full reducer, we can easily compute all solutions
with a backtrack-free procedure (i.e., with backtracks occurring only look-
ing for further solutions, never for wrong choices). Note that this is in fact
a polynomial-time output delay algorithm, because the cost of the ﬁrst two
preliminary phases is O(n log n), where n is the input size, and the delay
between the computation of any two solutions in the ﬁnal step is O(n), and
thus polynomial in the input.
3. Pairwise Consistency entails Global Consistency [6]. Recall that pairwise
consistency holds if, for every pair of atoms p, q, no tuple is missed by com-
puting the join p ▷◁q with respect to the given database, that is, every tuple

Uniform Constraint Satisfaction Problems and Database Theory
167
in one relation has a corresponding matching tuple in the other one. For-
mally, both p ⋉q = p and q ⋉p = q hold. The acyclic instances that fulﬁl
this property also fulﬁl the global consistency property, and thus we may
easily compute all answers in polynomial-time output delay, e.g., trough the
above mentioned backtrack-free procedure. Note that this equivalence be-
tween local and global consistency (as the other direction trivially holds)
yields another simple algorithm for solving acyclic instances: Enforce pair-
wise consistency, by taking the semijoins between all pairs of atoms until a
ﬁxpoint is reached, or some database relation becomes empty. If the latter
case occurs, then the query has no answer. Otherwise, we eventually get a
pairwise consistent instance. In this case, we know that the query has some
answer (the Boolean problem is solved), and we have obtained a full reducer,
from which we may easily compute all answers, if desired. It is easy to see that
the cost of this consistency enforcing procedure is O(m2t|rmax| log |rmax|),
where t is the total number of tuples in the given database, which is higher
than the O((m −1)|rmax| log |rmax|) we take by using Yannakakis’s Algo-
rithm. Of course, this is not surprisingly, because the latter one exploits
the knowledge of a given join tree (computable in linear time), while the
consistency-enforcing algorithm acts repeatedly on all pairs, in a brute-force
like manner.
4. It has been shown that answering queries is highly parallelizable on acyclic
queries, as this problem (actually, the decision problem of answering Boolean
queries) is complete for the low complexity class LOGCFL [37]. Eﬃcient par-
allel algorithms for Boolean and non-Boolean queries have been proposed
in [37] and [35]. They run on parallel database machines that exploit the
inter-operation parallelism [80], i.e., machines that execute diﬀerent rela-
tional operations in parallel. These algorithms can be also employed for
solving acyclic queries eﬃciently in a distributed environment.
2.3
Generalizing Acyclicity
We have seen our ﬁrst example of an island of tractability: the class of acyclic
relational structures. Many attempts have been made in the literature for ex-
tending the good results about this class to relevant classes of nearly acyclic
structures. We call these techniques structural decomposition methods, because
they are based on the acyclicization of cyclic (hyper)graphs. More precisely,
each method speciﬁes how appropriately transforming the hypergraph of a given
instance into the join tree of an equivalent acyclic instance, by organizing its
hyperedges into a polynomial number of clusters, and suitably arranging the
clusters as a tree.
Example 5. Consider the following query: Q0: ans
←
s1(A, B, D)
∧
s2(B, C, D) ∧s3(B, E) ∧s4(D, G) ∧s5(E, F, G) ∧s6(E, H ) ∧s7(F, I ) ∧
s8(G, J).
◁
Figure 5 shows the Query Decomposition approach for Q0: Each cluster contains
a number of atoms; after performing the join of the atoms contained in each

168
F. Scarcello, G. Gottlob, and G. Greco
s
s
1
2
(A,B,D),
(B,C,D)
s
s
1
3
(A,B,D),
(B,E)
s6(E,H)
s
s
3
4
(B,E),
(D,G)
s8(G,J)
s5(E,F,G)
s7(F,I)
s
s
1
5
(A,B,C),
(E,F,G)
s6(E,H)
s2(B,C,D)
s3(B,E)
s4(D,G)
s7(F,I)
s8(G,J)
s1
s2
s3
s5
s4
s6
s7
s8
A
B
C
D
E
F
G
H
I
J
Fig. 5. Hypergraph H(Q0) (left), two query decompositions of width 2 of H(Q0) (right
and bottom)
cluster, we obtain a join tree of an acyclic query which is equivalent to the
original query. The resulting query can thus be answered eﬃciently (e.g., by using
Yannakakis’s algorithm). The tree produced by a structural query decomposition
method on a given query Q is referred to as the decomposition of Q.
Thus, the eﬃciency of a structural decomposition method essentially depends
on the maximum size of the produced clusters, measured (according to the cho-
sen decomposition method) either in terms of the number of variables or in terms
of the number of atoms. For a given decomposition, this size is referred-to as the
width of the decomposition. For example, if we follow the query-decomposition
approach and adopt the number of atoms, then the width of both decomposi-
tions shown in Figure 5 is 2. Intuitively, the complexity of transforming a given
decomposition into an equivalent tree query is exponential in its width w. In
fact, the evaluation cost of each of the (polynomially many) clusters is bounded
by the cost of performing the (at most) w joins of its relations, which is in turn
bounded by O(|rmax|w), where |rmax| denotes the size of the largest relation
rmax in the database.
In general, a rough upper bound for the cost of answering a given instance
(Q, db) according to any structural method D is given by O(nw+1 log n), where
w is the D-width of H(Q) and n is the total size of the input problem, that is,
the size of the query and of the database encoding [34]. Therefore, once we ﬁx a
bound k for such a width, the structural method D identiﬁes a class of queries
that can be answered in polynomial time exploiting D-decompositions, namely,
the class of all queries having k-bounded D-width (i.e., D-width at most k).1
More in general, if A is a class of relational structures whose hypergraphs have
D-width bounded by some ﬁnite k ≥1, and whose D-decompositions can be
computed in P, then CSP(A, All) ∈P. Moreover, if the membership in A is
decidable in P, then A is an island of tractability.
1 Intuitively, the D-width of a query Q is the minimum width of the decompositions
of Q obtainable by method D.

Uniform Constraint Satisfaction Problems and Database Theory
169
The main islands of tractability based on structural decomposition meth-
ods are based on the notions of Biconnected Components [27], Tree Decompo-
sitions [14,21,26,48,55,65], Hinge Decompositions [49], Spread-cuts [17] 2, and
Hypertree Decompositions [33,37,39,69].
We refer the interested reader to [34] for a detailed comparison of these de-
composition methods (but the more recent Spread-cuts), and to [45] for further
results about graph-based techniques when relational structures are represented
according to diﬀerent graph representations (primal graph, dual graph, hidden-
variable encoding). See also [17] for a nice unifying view of such structural decom-
position methods in terms of acyclic guarded covers of hypergraphs. Moreover, a
survey of most of these techniques is currently available in the Wikipedia (look
for “decomposition method”, at http://www.wikipedia.org). We next focus
on hypertree decompositions and their extensions, which give the largest classes
of tractable instances.
3
Hypertree Decompositions
In this section, we describe the structural decomposition method based on hy-
pertree decompositions. For more details on this notion, see [33,40].
3.1
Embedding Hypergraphs in (Hyper)Trees
A hypertree for a hypergraph H is a triple ⟨T, χ, λ⟩, where T = (N, E) is a rooted
tree, and χ and λ are labeling functions that associate with each vertex p ∈N
two sets χ(p) ⊆var(H) and λ(p) ⊆edges(H). The width of a hypertree is the
cardinality of its largest λ label, i.e., maxp∈N|λ(p)|.
We denote the set of vertices of any rooted tree T by vertices(T), and its
root by root(T ). Moreover, for any p ∈vertices(T), Tp denotes the subtree of T
rooted at p. If T ′ is a subtree of T , we deﬁne χ(T ′) = 
v∈vertices(T ′) χ(v).
Deﬁnition 3. [39] A generalized hypertree decomposition of a hypergraph H is
a hypertree HD = ⟨T, χ, λ⟩for H that satisﬁes the following conditions:
1. For each edge h ∈edges(H), all of its variables occur together in some vertex
of the decomposition tree, that is, there exists p ∈vertices(T ) such that
h ⊆χ(p) (we say that p covers h).
2. Connectedness Condition: for each variable Y
∈var(H), the set {p ∈
vertices(T ) | Y ∈χ(p)} induces a (connected) subtree of T .
3. For each vertex p ∈vertices(T ), all variables in the χ labeling should belong
to edges in the λ labeling, that is, χ(p) ⊆var(λ(p)).
A hypertree decomposition is a generalized hypertree decomposition that satisﬁes
the following additional condition:
2 Actually, a ﬁrst version of spread-cut decomposition has been presented in [16].
However, it turned out that deciding whether a hypergraph has spread-cut width at
most k is NP-hard (even for k = 4). When we speak of islands of tractability based
on spread-cuts, we thus consider the more recent notion deﬁned in [17].

170
F. Scarcello, G. Gottlob, and G. Greco
4. Descendant Condition: for each p ∈vertices(T ), var(λ(p))∩χ(Tp) ⊆χ(p).
The HYPERTREE width hw(H) (resp., generalized hypertree width ghw(H)) of H
is the minimum width over all its hypertree decompositions (resp., generalized
hypertree decompositions).
An edge h ∈edges(H) is strongly covered in HD if there exists p ∈vertices(T )
such that var(h) ⊆χ(p) and h ∈λ(p). In this case, we say that p strongly covers
h. A decomposition HD of hypergraph H is a complete decomposition of H if
every edge of H is strongly covered in HD. From any (generalized) hypertree de-
composition HD of H, we can easily compute a complete (generalized) hypertree
decomposition of H having the same width.
2
Note that the notions of hypertree width and generalized hypertree width are
true generalizations of acyclicity, as the acyclic hypergraphs are precisely those
hypergraphs having hypertree width and generalized hypertree width one. In
particular, as we will see in the next section, the classes of conjunctive queries
having bounded (generalized) hypertree width have the same desirable compu-
tational properties as acyclic queries [33].
At a ﬁrst glance, a generalized hypertree decomposition of a hypergraph may
simply be viewed as a clustering of the hyperedges (i.e., query atoms) where
the classical connectedness condition of join trees holds. However, a generalized
hypertree decomposition may deviate in two ways from this principle: (1) A
hyperedge already used in some cluster may be reused in some other cluster;
(2) Some variables occurring in reused hyperedges are not required to fulﬁll any
condition.
For a better understanding of this notion, let us focus on the two labels as-
sociated with each vertex p: the set of hyperedges λ(p), and the set of eﬀective
variables χ(p), which are subject to the connectedness condition (2). Note that
all variables that appear in the hyperedges of λ(p) but that are not included
in χ(p) are “ineﬀective” for v and do not count w.r.t. the connectedness con-
dition. Thus, the χ labeling plays the crucial role of providing a join-tree like
re-arranging of all connections among variables. Besides the connectedness con-
dition, this re-arranging should fulﬁll the fundamental Condition 1: every hy-
peredge (i.e., query atom, in our context) has to be properly considered in the
decomposition, as for graph edges in tree-decompositions and for hyperedges in
join trees (where this condition is actually even stronger, as hyperedges are in
a one-to-one correspondence with vertices of the tree). Since the only relevant
variables are those contained in the χ labels of vertices in the decomposition tree,
the λ labels are “just” in charge of covering such relevant variables (Condition 3)
with as few hyperedges as possible. Indeed, the width of the decomposition is
determined by the largest λ label in the tree. This is the most important novelty
of this approach, and comes from the speciﬁc properties of hypergraph-based
problems, where hyperedges often play a predominant role. For instance, think
of our database framework: the cost of evaluating a join operation with k atoms
(read: k hyperedges) is O(nk), no matter of the number of variables occurring
in the query.

Uniform Constraint Satisfaction Problems and Database Theory
171
Fig. 6. Hypergraph H1 associated with query Q1 in Example 6
Fig. 7. A 2-width hypertree decomposition of hypergraph H1 in Example 6 (left), and
atom representation (right)
Example 6. Consider the following conjunctive query Q1:
ans ←a(S, X, X′, C, F) ∧b(S, Y, Y ′, C′, F ′) ∧c(C, C′, Z) ∧d(X, Z) ∧
∧e(Y, Z) ∧f(F, F ′, Z′) ∧g(X′, Z′) ∧h(Y ′, Z′) ∧j(J, X, Y, X′, Y ′).
Figure 6 shows the hypergraph H1 associated with Q1. As you can see, this
hypergraphs looks quite intricate, in fact H1 is cyclic, and thus hw(H1) > 1
holds. However, surprisingly, it turns out that it is quasi-acyclic. Indeed, Figure 7
shows a (complete) hypertree decomposition HD1 of H1 having width 2, hence
hw(H1) = 2.
In order to help the intuition, the ﬁgure also shows an alternative representa-
tion of this decomposition, called atom (or hyperedge) representation [33]: each
node p in the tree is labeled by a set of atoms representing λ(p); χ(p) is the set
of all variables, distinct from ‘ ’, appearing in these hyperedges. Thus, in this
representation, possible occurrences of the anonymous variable ‘ ’ take the place
of variables in var(λ(p)) −χ(p).
Another example is depicted in Figure 5, which shows two hypertree de-
compositions of query Q0. Indeed, we presented them as query decomposi-
tions, but every query decomposition is in fact a hypertree decomposition with

172
F. Scarcello, G. Gottlob, and G. Greco
var(λ(p)) = χ(p) for each vertex p of the tree.3 Both decompositions have width
two and are complete hypertree decompositions of Q0.
◁
Let k ≥1 be a ﬁxed positive integer. We say that a relational structure I has k-
bounded (generalized) hypertree width if (g)hw(H(I)) ≤k. A class of relational
structures has k-bounded (generalized) hypertree width if all instances in the
class have k-bounded (generalized) hypertree width. Also, we say that a class A
has bounded (generalized) hypertree width if there is a integer k ≥1 such that
A has k-bounded (generalized) hypertree width.
Clearly enough, choosing a tree and a clever combination of χ and λ labeling
for its vertices in order to get a decomposition below a ﬁxed threshold-width k
is not that easy, and is deﬁnitely more diﬃcult than computing a simple tree
decomposition, where only variables are associated with each vertex. In fact, it
has been shown very recently that generalized hypertree-width is an intractable
notion, as deciding whether a hypergraph has generalized hypertree width at
most k is an NP-complete problem, for any ﬁxed k ≥3 [41].
It is thus very nice and somehow surprising that dealing with the hypertree
width is a very easy task. More precisely, for any ﬁxed k ≥1, deciding whether a
given hypergraph has hypertree width at most k is in LOGCFL, and thus it is a
tractable and highly parallelizable problem. Correspondingly, the search problem
of computing a k-bounded hypertree decomposition belongs to the functional
version of LOGCFL, which is LLOGCFL [33].
Let us brieﬂy discuss the only diﬀerence of hypertree decompositions with re-
spect to generalized hypertree decompositions, that is, the descendant condition
(Condition 4 in Deﬁnition 3). Consider a vertex p of a hypertree decomposition
and a hyperedge h ∈λ(p) such that some variables ¯X ⊆h occur in the χ labeling
of some vertex in the subtree Tp rooted at p. Then, according to this condition,
these variables must occur in χ(p), too. This means, intuitively, that we have to
deal with variables in ¯X at this point of the decomposition tree, if we want to
put h in λ(p). For instance, as a consequence of this condition, for the root r of
any hypertree decomposition we always have χ(r) = var(λ(r)). However, once
a hyperedge has been covered by some vertex of the decomposition tree, any
subset of its variables can be used freely in order to decompose the remaining
cycles in the hypergraph.
To shed more light on this restriction, consider what happens in the related
(but intractable) hypergraph-based notions: in query decompositions [14], all
variables are relevant; at the opposite side, in generalized hypertree decompo-
sitions, we can choose as relevant variables any subset of variables occurring in
λ, without any limitation; in hypertree decompositions, we can choose any sub-
set of relevant variables as long as the above descendant condition is satisﬁed.
Therefore, the notion of hypertree width is clearly more powerful than the notion
3 Actually, the tree labels in the original notion of query decompositions may contain
both variables and atoms [14]. However, for the sake of presentation, we consider
here the so called pure query decompositions, where the labels contain only atoms,
since they are equivalent to the original ones [37].

Uniform Constraint Satisfaction Problems and Database Theory
173
of query width, but less general than the notion of generalized hypertree width,
which is the most liberal notion.
For instance, consider again Figure 7: the variables in the hyperedge corre-
sponding to atom j in H1 are jointly included only in the root of the decom-
position, while we exploit two diﬀerent subsets of this hyperedge in the rest of
the decomposition tree. Note that the descendant condition is satisﬁed. Take the
vertex at level 2, on the left: the variables J, X′ and Y ′ are not in the χ label of
this vertex (they are replaced by the anonymous variable ‘ ’), but they do not
occur anymore in the subtree rooted at this vertex. On the other hand, if we
were forced to take all the variables occurring in every atom in the decomposi-
tion tree, it would not be possible to ﬁnd a decomposition of width 2. Indeed, j
is the only atom containing both pairs X, Y and X′, Y ′, and it cannot be used
again entirely, for its variable J cannot occur below the vertex labeled by a and
b, otherwise it would violate the connectedness condition (i.e., Condition 2 of
Deﬁnition 3). In fact, every query decomposition of this hypergraph has width
3, while the hypertree width is 2. In this case the generalized hypertree width is
2, as well, but in general it may be less than the hypertree width.
3.2
Characterizations of Hypertree Decompositions
Though the formal deﬁnition of hypertree width is rather involved, it is worth-
while noting that this notion has very natural characterizations in terms of games
and logics [39]:
– The robber and marshals game (R&Ms game). It is played by one
robber and a number of marshals on a hypergraph. The robber moves on
variables, while marshals move on hyperedges. At each step, any marshal
controls an entire hyperedge. During a move of the marshals from the set of
hyperedges E to the set of hyperedges E′, the robber cannot pass through the
vertices in B = (∪E) ∩(∪E′), where, for a set of hyperedges F, ∪F denotes
the union of all hyperedges in F. Intuitively, the vertices in B are those not
released by the marshals during their move. As in the monotonic robber and
cops game deﬁned for treewidth [71], it is required that the marshals capture
the robber by monotonically shrinking the moving space of the robber. The
game is won by the marshals if they corner the robber somewhere in the
hypergraph. A hypergraph H has k-bounded hypertree width if and only if
k marshals win the R&Ms game on H.
– Logical characterization of hypertree width. Let L denote the existen-
tial conjunctive fragment of positive ﬁrst order logic (FO). Then, the class
of queries having k-bounded hypertree width is equivalent to the k-guarded
fragment of L, denoted by GFk(L). Roughly, we say that a formula Φ be-
longs to GFk(L) if, for any subformula φ of Φ, there is a conjunction of up
to k atoms jointly acting as a guard, that is, covering the free variables of
φ. Note that this notion is related to the loosely guarded fragment as deﬁned
(in the context of full FO) by Van Benthem [7], where an arbitrary number
of atoms may jointly act as guards (see also [43]).

174
F. Scarcello, G. Gottlob, and G. Greco
3.3
Exploiting (Generalized) Hypertree Decompositions
We next describe how to use a given generalized hypertree decomposition for
answering a conjunctive query. Of course, the same applies to hypertree decom-
positions, because they are generalized hypertree decompositions (satisfying an
additional requirement).
Let k ≥1 be a ﬁxed constant, Q a conjunctive query over a database db,
and HD = ⟨T, χ, λ⟩a generalized hypertree decomposition of Q of width w ≤k.
Then, we can answer Q in two steps:
1. For each vertex p ∈vertices(T), compute the join operations among the
atoms occurring together in λ(p) (w.r.t. the given database db), and project
onto the variables in χ(p). At the end of this phase, the conjunction of these
intermediate results forms an acyclic conjunctive query, say Q′, equivalent
to Q. Moreover, the decomposition tree T represents a join tree of Q′.
2. Answer Q′, and hence Q, by using any algorithm for acyclic queries, e.g.
Yannakakis’s algorithm.
For instance, Figure 4 shows the tree JTa obtained after Step 1 above, from
the query Q1 in Example 6 and the generalized hypertree decomposition in Fig-
ure 7. E.g. observe how the vertex of JTa labeled by atom p3(X, Y, C, C′, Z) is
built. Its database relation p3 comes from the join of atoms j(J, X, Y, X′, Y ′) and
c(C, C′, Z) (occurring in its corresponding vertex in Figure 7) w.r.t. db, and from
the subsequent projection onto the variables X, Y, C, C′, and Z (belonging to the
χ label of that vertex). By construction, JTa satisﬁes the connectedness condi-
tion, because the variables occurring in its vertices are precisely those occurring
in the χ labeling of a hypertree decompositions, which fulﬁls the connectedness
condition. Therefore, JTa is a join tree. More precisely, it is the join tree of the
acyclic query consisting of (the conjunction of) its atoms. In our example it is
the join tree of the acyclic query Qa in Example 4. Moreover, it is easy to see
that Qa (on the database obtained from db by performing the above mentioned
join operations) has the same answer as Q1 (on db) [33].
As we observed in our introduction to structural methods for the similar
query decompositions, Step 1 is feasible in O(m|rmax|w) time, plus the (typically
dominated) cost of the projections, where m is the number of vertices of T ,
and rmax is the relation of db having the largest size. For Boolean queries,
Yannakakis’s algorithm in Step 2 takes O((m −1)|rmax|w log |rmax|) time. For
non-Boolean queries, Yannakakis’s algorithm works in input-output polynomial
time (also, in polynomial-time output delay), and thus we should add to the
above cost a term that depends on the answer of the given query (which may
be exponential w.r.t. the input size). For instance, if we consider query Q1, the
above upper bound is O(6|rmax|2 log |rmax| + 7|rmax|2), which sounds very nice,
compared with typical (non-structural) query answering algorithms, that would
take O(|rmax|7) time, in the worst case.
It has been observed that, according to Deﬁnition 3, a hypergraph may have
some (usually) undesirable hypertree decompositions [33], possibly with a large
number m of vertices in the decomposition tree. For instance, a decomposition

Uniform Constraint Satisfaction Problems and Database Theory
175
may contain two vertices with exactly the same labels. Therefore, a normal form
for hypertree decompositions has been deﬁned in [33], and then strengthened in
[70], in order to avoid such kind of redundancies. The number m of vertices
of these decompositions cannot exceed the number of variables v in H, and
is typically much smaller. It follows that, having such a decomposition of H,
an upper bound for query evaluation is O((v −1)|rmax|w log |rmax| + v|rmax|w)
Moreover, H has a hypertree decomposition of width w if and only if it has a
normal-form hypertree decomposition of the same width w. These same results
can be proved for a suitable irredundant restriction of generalized hypertree
decompositions. Therefore, the above upper bound on the query evaluation cost
holds when such (irredundant) generalized hypertree decompositions are given,
as well.
3.4
Islands of Tractability Based on Hypertree-Width
Let k ≥1 be a ﬁnite integer, and let HW[k] be the class of all relational structures
whose associated hypergraphs have hypertree width at most k. For instance, the
class of acyclic structures is in fact HW[1], because it is precisely the class of all
structures having hypertree width 1. As we have seen in the previous section,
for any ﬁxed k, all these instances may be evaluated in polynomial time, once
a suitable decomposition is given. Moreover, they can be easily recognized, as
well.
Proposition 1 ([33]). Let k ≥1 be a ﬁxed constant, and let HW[k] be the class
of all relational structures whose associated hypergraphs have hypertree width at
most k. Then, HW[k] is an island of tractability.
In fact, both computing a width-k hypertree decomposition for a given structure,
and solving the associated problem instance is feasible in (the functional version
of) LOGCFL, and thus can be eﬃciently solved by parallel algorithms.
Recall that the class-membership tractability property does not hold for gen-
eralized hypertree decompositions, because deciding whether a hypergraph has
generalized hypertree-width at most k is NP-complete, even if k is a ﬁxed con-
stant [41]. It follows that, unlike hypertree decompositions, generalized hypertree
decompositions are not useful for identifying islands of tractability. However, as
better described in Section 4.2, it is known that the diﬀerence between hyper-
tree width and generalized hypertree width is within a small constant factor. It
follows that a class of hypergraphs has k-bounded generalized hypertree width
if and only if it has k′-bounded hypertree width, where k and k′ are two positive
integer constants. Therefore, the two notions identify the same set of tractable
classes, because every class of CSPs that is tractable according to generalized
hypertree width is tractable according to hypertree width, as well.
Moreover, since the width of the acyclic guarded covers in [17] is precisely
the generalized hypertree width, the above result can be applied immediately to
the islands of tractability based on every notion D in the uniﬁed view described
in [17], because all of them are special kinds of acyclic guarded covers. That is,

176
F. Scarcello, G. Gottlob, and G. Greco
if k is a (ﬁnite) constant and A is a class of structures having k-bounded D-
width, then A has k′-bounded hypertree width, where k′ is a (ﬁnite) constant,
possibly smaller than k, and never greater than 3k+1 [4]. In this sense, hypertree
decompositions allow us to identify the largest islands of tractability among all
these generalizations of acyclicity. In Section 4.3, we will see a diﬀerent kind of
structural method that is incomparable with hypertree decompositions.
However, observe that the above important theoretical result does not mean
that, in practice, hypertree decompositions is always the best choice. In fact, one
has to choose the right decomposition method looking at the particular problem
at hand. For instance, as shown in [17], there are some classes of hypergraphs
where the spread-cut width is less than the hypertree width—of course, the max-
imum diﬀerence is within a constant factor, given the above result. In these cases,
such a choice may be preferable, because the cost of evaluating CSP instances or
queries is exponential in the width, whence even small improvements in the width
may lead to a signiﬁcant speed-up of the evaluation time. For completeness, note
that the other side of this relationship between hypertree decompositions and
spread-cut decompositions is not known: in principle, there may exist a class
of CSPs having k-bounded hypertree width, but unbounded spread-cut width
(hence such a class would be intractable, according to the spread-cut method).
Moreover, in order to achieve the minimum possible width, sometimes may be
convenient to look for the more powerful generalized hypertree decompositions.
Indeed, it is worthwhile noting that the cost of computing such decompositions
depends only on the size of the given left-hand structure. In the database frame-
work, this means that this cost depends only on the size of the query, while
the beneﬁts of having a small width involves the whole evaluation time, which
heavily depends on the (typically) huge database size. Therefore, investing some
time for computing a generalized hypertree decomposition of minimum width
may well pay oﬀ. Instead, in the Constraint Satisfaction framework such left-
hand structures are not small, as we usually have many constraints. In these
cases, generalized hypertree decompositions are usually computed by resorting
to heuristics, as described next.
3.5
Algorithms
Because of the practical relevance of the notion of (generalized) hypertree decom-
position, several eﬀorts have been spent to devise algorithms for its computation.
The ﬁrst proposal in the literature appeared in [33], where it has been shown
that, for any ﬁxed k ≥1, the search problem of computing a k-bounded hy-
pertree decomposition is a tractable and highly parallelizable problem. Indeed,
to establish this tractability result, an algorithm called k-decomp has been pre-
sented constructing a (normal-form) hypertree decomposition of minimal width
less than or equal to k (if such a decomposition exists). However, k-decomp
is an alternating algorithm that “runs” on alternating Turing machines using
logarithmic workspace, and hence is not designed for real-world applications.
A more practical algorithm to compute hypertree decompositions, named
opt-k-decomp, has been presented in [36]. In fact, opt-k-decomp is obtained

Uniform Constraint Satisfaction Problems and Database Theory
177
by “uprolling” k-decomp in a sequential bottom-up fashion. As for many other
decomposition methods, the running time of this algorithm to ﬁnd a hypergraph
decomposition is exponential in the parameter k. More precisely, opt-k-decomp
runs in O(m2kv2) time, where m and v are the number of edges and the number
of vertices of the hypergraph, respectively. This algorithm has been improved
subsequently in [50], where some techniques for limiting redundant computa-
tions have been discussed, which actually do not improve on the asymptotic
worst-case bounds of the original algorithm.
Very recently, a diﬀerent approach for computing hypertree decompositions
has been discussed in [73]. Its basic idea is to exploit a backtracking procedure
that stops as soon as it discovers a decomposition of width at most k (diﬀerently
from opt-k-decomp, which implicitly builds a structure from which it is possible
to enumerate easily all possible normal-form decompositions of width at most
k). The time complexity of this approach is O(v3k+3). Moreover, a technique to
identify isomorphic components of a hypergraph in order to speed-up the com-
putation is also presented, and integrated into the basic algorithm. Interestingly,
this work also discusses a generalization of the backtracking procedure that re-
sults in two new tractable decomposition methods: HyperSpread and Connected
Hypertree.
The main problem with the exact approaches discussed above is that, al-
though polynomial, they needs a huge amount of time (and sometimes of mem-
ory) to deal with large hypergraphs. In fact, it is worthwhile noting that, un-
like treewidth, recognizing k-bounded hypertree width is not ﬁxed-parameter
tractable, with respect to its natural parameter k [40]. Therefore, unless some
unlikely collapse occurs in ﬁxed-parameter complexity theory, a bad exponen-
tial dependency of the form O(f1(n)f2(k)) is unavoidable in the running time of
sound and complete algorithms.
Motivated by these bad news, most recent research focuses on heuristic
approaches for the construction of (generalized) hypertree decompositions of
“small” but not necessarily minimal width.
A successful algorithm of this kind has been presented in [59], where it has
been observed that generalized hypertree decompositions can be constructed
starting from tree decompositions, and subsequently covering the the variables
at each vertex label by a small number of hyperedges. This latter condition
can be straightforwardly implemented by set covering (heuristics), so that it is
possible to use tree decomposition heuristics for the (heuristic) construction of
generalized hypertree decompositions. In particular, in [59], Bucket Elimination
is used in combination with several variable ordering heuristics.
Another successful technique has been discussed in [68], which shows how to
use the branch-decomposition approach for ordinary graphs [18] for the heuris-
tic construction of generalized hypertree decompositions (based on the fact that
every branch decomposition of width k can be transformed into a tree decom-
position of width at most 3k/2).
In [56], it has been investigated the idea of generating generalized hypertree
decompositions based on the tree decompositions of the primal and of the dual

178
F. Scarcello, G. Gottlob, and G. Greco
graph. To generate tree decompositions, Bucket Elimination is coupled with
three heuristics for ﬁnding good vertex orderings. Moreover, a further method
based on recursive partitioning of the hypergraph in weakly connected subgraphs
is discussed.
The use of tabu search for computing (generalized) hypertree decompositions
has been considered in [60].
More recently, [42] considered a combination of exact and heuristic approaches
in the sense that the search space is restricted by a ﬁxed upper bound k, and
some heuristics are used to accelerate the search for a generalized hypertree
decomposition of width at most k (but not necessarily the minimal one). The
resultant algorithm det-k-decomp is based on backtracking, and can also be
implemented for parallel executions.
See the Hypertree Decomposition HomePage [69], for available implementa-
tions of algorithms for computing hypertree decompositions, and further links
to heuristics and other papers on this subject.
4
Extending Hypertree Decompositions
In this section, we describe some recent approaches to generalize the notion of
hypertree decompositions. The ﬁrst one allows us to express preferences, for those
problems where “any” decomposition (even below a desired width) is not enough,
and we rather want the best one, according to a given criterion. The second
approach aims at identifying decomposition methods that are more powerful
than hypertree decompositions but still polynomially computable, whose degree
of generality is somewhere between hypertree decompositions and generalized
hypertree decompositions. The third one, based on the notion of fractional edge
cover, is instead more powerful than generalized hypertree decompositions, but
likely intractable.
4.1
Weighted Hypertree Decompositions
In this section, we consider hypertree decompositions with an associated weight,
which encodes our preferences, and allows us to take into account further require-
ments, besides the width. We will see how to answer queries more eﬃciently, by
looking for their best decompositions.
Formally, given a hypergraph H, a hypertree weighting function (short: HWF)
ωH is any polynomial-time function that maps each generalized hypertree de-
composition HD = ⟨T, χ, λ⟩of H to a real number, called the weight of HD.
For
instance,
a
very
simple
HWF
is
the
function
ωw
H(HD)
=
maxp∈vertices(T ) |λ(p)|, that weights a decomposition HD just on the ba-
sis of its worse vertex, that is the vertex with the largest λ label, which also
determines the width of the decomposition.
In many applications, ﬁnding such a decomposition having the minimum
width is not the best we can do. We can think of minimizing the number of
vertices having the largest width w and, for decompositions having the same

Uniform Constraint Satisfaction Problems and Database Theory
179
numbers of such vertices, minimizing the number of vertices having width
w −1, and continuing so on, in a lexicographical way. To this end, we can
deﬁne the HWF ωlex
H (HD) = w
i=1 |{p ∈N such that |λ(p)| = i}| × Bi−1, where
N = vertices(T ), B = |edges(H)| + 1, and w is the width of HD. Note that any
output of this function can be represented in a compact way as a radix B number
of length w, which is clearly bounded by the number of edges in H. Consider
again the query Q0, and the hypertree decomposition, say HD′, of H(Q0) shown
in Figure 5, on the right. It is easy to see that HD′ is not the best decomposition
w.r.t. ωlex
H
and the class of hypertree decompositions in normal form. Indeed,
ωlex
H (HD′) = 4 × 90 + 3 × 91, and thus the decomposition HD′′ shown on the
bottom of Figure 5 is better than HD′, as ωlex
H (HD′′) = 6 × 90 + 1 × 91.
Let k > 0 be a ﬁxed integer and H a hypergraph. We deﬁne the class kHDH
(resp., kNFDH) as the set of all hypertree decompositions (resp., normal-form
hypertree decompositions) of H having width at most k.
Deﬁnition 4. [70]Let H be a hypergraph, ωH a weighting function, and CH
a class of generalized hypertree decompositions of H. Then, a decomposition
HD ∈CH is minimal w.r.t. ωH and CH, denoted by [ωH, CH]-minimal, if there
is no HD′ ∈CH such that ωH(HD′) < ωH(HD).
2
For instance, the [ωw
H, kHDH]-minimal decompositions are exactly the k-
bounded hypertree decompositions having the minimum possible width, while
the [ωlex
H , kHDH]-minimal hypertree decompositions are a subset of them, cor-
responding to the lexicographically minimal decompositions described above.
It is not diﬃcult to show that, for general weighting functions, the compu-
tation of minimal decompositions is a diﬃcult problem even if we consider just
bounded hypertree decompositions [70]. We thus restrict our attention to simpler
HWFs.
Let ⟨R+, ⊕, min, ⊥, +∞⟩be a semiring, that is, ⊕is a commutative, associa-
tive, and closed binary operator, ⊥is the neuter element for ⊕(e.g., 0 for +, 1 for
×, etc.) and the absorbing element for min, and min distributes over ⊕.4 Given
a function g and a set of elements S = {p1, ..., pn}, we denote by 
pi∈S g(pi)
the value g(p1) ⊕. . . ⊕g(pn).
Deﬁnition 5. [70]Let H be a hypergraph. Then, a tree aggregation function
(short: TAF) is any hypertree weighting function of the form
F⊕,v,e
H
(HD) =

p∈N

vH(p) ⊕

(p,p′)∈E
eH(p, p′)

,
associating a value from R+ with the hypertree decomposition HD
=
⟨(N, E), χ, λ⟩, where vH : N →R+ and eH : N × N →R+ are two polyno-
mial functions evaluating vertices and edges of hypertrees, respectively.
2
4 For the sake of presentation, we refer to min and hence to minimal hypertree de-
compositions. However, it is easy to see that all the results can be generalized to any
semiring, possibly changing min, R+, and +∞.

180
F. Scarcello, G. Gottlob, and G. Greco
We next focus on a tree aggregation function that is useful for query optimiza-
tion. We refer the interested reader to [70] for further examples and applications.
Given a query Q over a database db, let HD = ⟨T, χ, λ⟩be a hypertree de-
composition in normal form for H(Q). For any vertex p of T , let E(p) denote the
relational expression E(p) = 1h∈λ(p)

χ(p) rel(h), i.e., the join of all relations
in db corresponding to hyperedges in λ(p), suitably projected onto the variables
in χ(p). Given also an incoming node p′ of p in the decomposition HD, we deﬁne
v∗
H(Q)(p) and e∗
H(Q)(p, p′) as follows:
– v∗
H(Q)(p) is the estimate of the cost of evaluating the expression E(p), and
– e∗
H(Q)(p, p′) is the estimate of the cost of evaluating the semi-join E(p) ⋉
E(p′).
Let costH(Q) be the TAF F+,v∗,e∗
H(Q)
(HD), determined by the above functions.
Intuitively, costH(Q) weights the hypertree decompositions of the query hyper-
graph H(Q) in such a way that minimal hypertree decompositions correspond
to “optimal” query evaluation plans for Q over db. Note that any method for
computing the estimates for the evaluation of relational algebra operations from
the quantitative information on db (relations sizes, attributes selectivity, and so
on) may be employed for v∗and e∗. See, for instance, the standard techniques
described in [30,51].
Clearly, all these powerful weighting functions would be of limited practi-
cal applicability, without a polynomial time algorithm for the computation of
minimal decompositions. Surprisingly, it turns out that, unlike the traditional
(non-weighted) framework, working with normal-form hypertree decompositions,
rather than with any kind of bounded-width hypertree decomposition, does mat-
ter. Indeed, computing such minimal hypertree decompositions with respect to
any tree aggregation function is a tractable problem, while it has been proved
that the problem is still NP-hard if the whole class of bounded-width hyper-
tree decomposition is considered. A polynomial time algorithm for this problem,
called cost-k-decomp, is presented in [70] and subsequently improved in [31].
An example of the practical advantages of this approach is reported in Fig-
ure 8. It shows the execution times for evaluating query Q1 in Example 6 and two
further queries Q2 (consisting of 8 atoms and 9 distinct variables) and Q3 (con-
sisting of 9 atoms, 12 distinct variables, and 4 output variables), on a well-known
commercial DBMS system (name omitted for software license restrictions), by
using two conﬁgurations of its query engine: in the ﬁrst one, labeled by Com-
mDB, the DBMS internal optimizer is used to ﬁnd the query plans; in the second
one, labeled by Cost-k-decomp, the DBMS query engine is feed with the query
plan determined by the hypertree decomposition computed by cost-k-decomp.
In particular, Figure 8 reports, on the left, the results for query Q1 for diﬀer-
ent values of the parameter k. Observe that higher values of k clearly mean
more power for the hypertree-based optimizer, that can possibly choose even
decompositions with a non-minimum width, if it is convenient according to the
database statistics available and the query-evaluation estimates. In fact, all these
queries have hypertree width 2, and thus any k ≥2 would work, but we get the

Uniform Constraint Satisfaction Problems and Database Theory
181
Fig. 8. Example performances for cost-k-decomp
best results since k = 4. The execution cost of cost-k-decomp is also reported.
Note that its computation times are negligible, if compared with the CommDB
evaluation times on the considered queries. On the right, Figure 8 shows the
evaluation times for the other two queries, when the parameter k = 3 is used
for cost-k-decomp. More details on these (and further) experimental results are
available in [31].
4.2
Approximating Generalized Hypertree Decompositions
Recall from Section 3.1 that a generalized hypertree decomposition (GHD) is a
decomposition that satisﬁes the ﬁrst three conditions of Deﬁnition 3, but not
necessarily Condition 4, the Descendant Condition. Given that GHDs are more
liberally deﬁned than hypertree decompositions (HDs), there are hypergraphs
H whose general hypertree width ghw(H) is smaller than their hypertree width
hw(H). Concrete examples of such hypergraphs can be found in [3,41]. Since
GHDs—once computed—have the same favorable properties for problem solving
as HDs, it would actually be better to use GHDs instead of HDs because of
the smaller width of the former, which would lead to better solution algorithms.
However, there is a problem with GHDs, that was already mentioned in Section 3.
As shown in [41], checking whether for a constant k, ghw(H) ≤k is NP-hard
(even for k = 3).
The unfavorable complexity results related to generalized hypertree decom-
positions motivate the search for somewhat weaker hypergraph decomposition
methods that in some sense approximate GHDs, and that fulﬁll the criteria of
polynomial query evaluation and polynomial recognizability. We can thus look
for decomposition methods M which associate with each hypergraph H a set
M(H) of generalized hypertree decompositions of H, and search for a gener-
alized hypertree decomposition in M(H) of minimal width. Intuitively, we thus
consider methods which “approximate generalized hypertree width from above”,
and are still better than the notion of hypertree width. The width MW(H) of
a hypergraph H, according to some decomposition method M, is the minimum

182
F. Scarcello, G. Gottlob, and G. Greco
generalized hypertree width of a decomposition in M(H). For two methods M
and N we write M ≤N iﬀfor each hypergraph H, MW(H) ≤NW(H). If
M ≤N and there is some hypergraph H such that MW(H) < NW(H), then
we write M < N.
An example of a decomposition that approximates GHD is the spread cut
decomposition (SCD) with the associated notion of spread cut width (scw) [17].
In a similar way as HDs, SCDs explicitly restrict the sets χ(p) that may appear
at a decomposition node p. There are many other possible decompositions one
can imagine that are weaker than GHDs but stronger than HDs and SCDs. A
key question is, how much we can gain through such decompositions, in other
terms, how do their associated widths compare with hypertree width.
In [4] the following was shown:
Proposition 2 ([4]). For each hypergraph H, ghw(H) ≤hw(H) ≤3 ×
ghw(H) + 1.
This means that hypertree width approximates generalized hypertree width by
a factor of three. It is currently open whether this factor can be improved. Of
course, all concepts of decomposition widths that are between hypertree width
and generalized hypertree width also approximate generalized hypertree width
by (at most) the same factor.
Subedge-based decomposition methods. Motivated by the goal to improve
hypertree decompositions, and to get a clearer picture of the “grey area” of the
islands of tractability lying between HDs and GHDs, the concept of subedge-
based decomposition methods was deﬁned in [41]. A subedge of a hypergraph
H = (V, E) is a subset of some edge of H. A subedge-based decomposition
method M relies on a subedge function. This is a function f which associates
to each integer k > 0 and each hypergraph H a set f(H, k) of subedges of H.
Moreover, the set of k-width M-decompositions can be obtained as follows: (1)
obtain a hypertree decomposition D of H′ = (V, E ∪f(H, k)), and (2) convert
D into a generalized hypertree decomposition of H by replacing each subedge
e ∈λ(p), for each decomposition node p, by some edge e′ of H such that e ⊆e′.
We call such a decomposition method M subedge-based. The following result was
derived in [41]:
Proposition 3 ([41]).
For
each
polynomially
recognizable
decomposition
method M ≤GHD, there exists a polynomially recognizable subedge-based de-
composition method M ′ such that M ′ ≤M.
The above result is useful from a methodological point of view. In fact, it tells us
that, when searching for some new decomposition method M such that GHD <
M < HD, then we may concentrate on subedge-based decomposition, and thus
study appropriate subedge functions.
Component Hypertree decompositions. In order to improve at the same
time HDs and SCDs, in [41] a particular subedge function f C was deﬁned, whose

Uniform Constraint Satisfaction Problems and Database Theory
183
deﬁnition is based on structural properties of the input hypergraph H = (V, E).
In particular, each subedge in f C(H, k) is obtained from a full edge e ∈E and
some candidate decomposition block M of at most k edges containing e, by elim-
inating from e all vertices that are edge-connected to some induced component
of V \vertices(M ), or all vertices that are not edge-connected to any component
of V \ M, or all vertices from e \ ∪(M \ {e}) that are edge-connected to some
component of V \ vertices(M). The new subedge based decomposition method
deﬁned through this subedge function f C is called component hypertree decom-
position (CHD) and its associated width is referred to as component hypertree
width. In [41] it is shown that Component hypertree decompositions fulﬁll both
criteria, polynomial query answering and polynomial recognizability, and thus
deﬁne an island of tractability. Moreover, it was shown that CHD < HD and
CHD < SCD.
The method of component hypertree decompositions is currently the most
general known polynomially recognizable hypergraph decomposition method,
i.e., the largest island of tractability. But it is easy to see that the subedge-based
paradigm allows one to deﬁne even larger tractable islands.
The only published method we are aware of, that does not ﬁt into the
“subedge-based” framework is the fractional hypertree-decomposition method,
described next.
4.3
Fractional Hypertree Decompositions
In [47], it was observed that, for solving problems in polynomial time using
(sub)edge based decompositions, a key requirement is that the cluster of atoms
at each vertex p of the decomposition tree corresponds to a subproblem with a
polynomial number of solutions. Of course, this is guaranteed if each cluster λ(p)
(using the notation of hypertree decompositions) contains at most k atoms, for a
ﬁxed constant k. Indeed, we have seen that such a p identiﬁes a subquery, whose
answer is given by the join of the atoms in λ(p) (possibly projected over some
subset of their variables). Then, the size of this answer is O(nk), where n is the
size of the largest relation associated with the atoms in λ(p). A very interesting
result by Grohe and Marx [47] shows that there is a more general property that
makes the size of a query answer polynomial (w.r.t. the input size).
Deﬁnition 6. Let H = (V, E) be a hypergraph. A fractional edge cover is a
non-negative weight assignment f to the hyperedges in E such that every vertex
X ∈V is covered by total weight at least 1, that is, 
h∈E|X∈h f(h) ≥1. The
weight of the cover f is 
h∈E f(h). Then, the fractional edge cover number
(FCN) of H, denoted by ρ∗(H), is the smallest weight over all its fractional edge
covers.
2
By exploiting a combinatorial lemma known as Shearer’s Lemma [15], it can be
shown that, for every instance of the query problem I = (Q, db), the size of
the answer Q(db) is O(|I|ρ∗(H(Q))). Thus, if a class of structures has k-bounded
FCN, for some ﬁnite integer k ≥1, |Q(db)| is polynomial in the input size, and it

184
F. Scarcello, G. Gottlob, and G. Greco
can be seen that Q(db) can be computed in polynomial time. Moreover, the FCN
of a hypergraph can be computed in polynomial time by linear programming. It
follows that this notion can be used to identify classes of tractable instances.
Proposition 4 ([47]). Let k ≥1 be a ﬁxed constant, and let FCN[k] be the
class of all structures whose associated hypergraphs have fractional edge cover
number at most k. Then, FCN[k] is an island of tractability.
It is worthwhile noting that this island of tractability is incomparable with those
based on hypertree width and its extensions: it is known that there are classes
of hypergraphs having bounded FCN, but unbounded (generalized) hypertree
width. On the other hand, there are classes of very simple hypergraphs that have
unbounded FCN, but bounded (generalized) hypertree width. E.g., the class of
acyclic instances, having hypertree width 1, has no ﬁnite bound for the FCN. In
fact, recall that the size of the answer of an acyclic query may be exponential
in the input (even if it can be computed in polynomial-time output delay). In
order to overcome these drawbacks, a new more powerful decomposition method
has been deﬁned.
A fractional hypertree for a hypergraph H is a triple ⟨T, χ, γ⟩, where T =
(N, E) is a rooted tree, and χ and γ are labeling functions that associate with
each vertex p ∈N a set χp ⊆var(H) and a mapping γp : edges(H) →[0, ∞).
The width of a hypertree is the maximum weight over the vertices of HD, where
the weight of a vertex p is 
e∈edges(H) γp(e).
Deﬁnition 7. [47] A fractional hypertree decomposition of a hypergraph H is a
fractional hypertree HD = ⟨T, χ, γ⟩for H that satisﬁes the following conditions:
1. For each edge h ∈edges(H), all of its variables occur together in some vertex
of the decomposition tree, that is, there exists p ∈vertices(T ) such that
h ⊆χp.
2. Connectedness Condition: for each variable Y
∈var(H), the set {p ∈
vertices(T ) | Y ∈χp} induces a (connected) subtree of T .
3. For each vertex p ∈vertices(T ), all variables in the χp label should be
fractionally edge covered according to γp, that is, χp ⊆{X ∈var(H) |

h∈edges(H)|X∈h γp(h) ≥1}.
The fractional hypertree width (fhw) of H is the minimum width over all its
fractional hypertree decompositions.
2
Note that the only diﬀerence with a generalized hypertree decomposition is the
fractional covering condition 3, which replaces the analogous condition of stan-
dard GHDs, where covering of variables in any χ label is ensured by the union
of the hyperedges in its corresponding λ label. Of course, the notion of width is
consequently based on the weight of these fractional edge covers.
Let k ≥1, and let FHW[k] be the class of all structures whose associated hy-
pergraphs have k-bounded fractional hypertree width. From what we have seen
in the previous sections, it is easy to see that every query Q whose structure is

Uniform Constraint Satisfaction Problems and Database Theory
185
in FHW[k] is tractable (on every database db) if a fractional hypertree decom-
position HD of H(Q) is given. Indeed, the only diﬀerence with the evaluation
exploiting k-bounded GHDs is that here the hyperedges associated with each
vertex p of the decomposition (i.e., those covering the variables in χp) may be
many more than k. However, the FCN of the sub-query corresponding to p is at
most k, and thus the polynomial-time evaluation of this sub-query is guaranteed
by the FCN approach.
Let us call FHD the decomposition method based on fractional hypertree
width. It was shown in [47] that FHD < GHD, but the computational proper-
ties of FHD are unexplored. It was conjectured in [41] that fractional hypertree-
width is not polynomially recognizable unless P = NP.
We remark that the above results show how the general setting considered
in this chapter, where relational structures do not have a ﬁxed arity, is very
diﬀerent and more complex than the setting with ﬁxed arity. Note that, in the
latter case, most research problems are now solved, because everything works
as for binary instances, where the bounded treewidth property is necessary and
suﬃcient for tractability [46].
5
Structural Methods without Structural Decompositions
A new group of interesting results about structural tractability provided a num-
ber of polynomial algorithms for solving the homomorphism problem, with the
guarantee that they give the correct output if the input instances belong to
certain classes.
5.1
Promise Problems and Tractability
When the result of an algorithm is conditioned to some property of the input,
possibly not easily checkable, following [46], we may give a diﬀerent deﬁnition of
tractability:
Deﬁnition 8 (Tractability, promise version). CSP(A, All) is in promise
polynomial-time for an arbitrary class A of problems if there is a polynomial
time algorithm such that,
– if its input consists of (the encoding of) two structures S ∈A and R, then
it correctly decides whether there is a homomorphism from S to R;
– if the input is not of this form, then the answer of the algorithm may be
arbitrary.
2
Note that every island of tractability is a tractable class, according to the above
promise version of tractability. However, the converse does not hold, because
checking the membership in the class is not required to be feasible in polynomial
time, in Deﬁnition 8.
Another important notion for both CSPs and databases is the core of a rela-
tional structure.

186
F. Scarcello, G. Gottlob, and G. Greco
Deﬁnition 9. Let A be a relational structure. The core of A is a substructure
C of A such that A →C, and no proper substructure of C has this property,
i.e., C is minimal.
2
It is well known that the core of a relational structure is unique (up to isomor-
phism). Moreover, if (A, B) is a CSP instance and C is the core of A, then (A, B)
is equivalent to the instance (C, B). That is, using the core is the same as using
the original structure A.
For instance, in the case of a conjunctive query Q, its core is the minimal query
Q′ with atoms(Q′) ⊆atoms(Q) such that there exists a homomorphism h such
that ∀r( ¯
X) ∈atoms(Q), r(h( ¯
X)) ∈atoms(Q). Therefore, in order to answer the
query Q eﬃciently, we may think of computing its reduced equivalent version
Q′ and then computing the answer of Q′. However, as shown below, dealing
with the core is an intractable problem. Moreover, note that, if all atoms of a
query are over diﬀerent relation symbols, then the query coincides with its core.
Since in conjunctive queries there are typically only a few atoms over the same
database relation, in practice exploiting the core is not very useful for query
answering. Instead, in the constraint satisfaction framework, it is more frequent
to ﬁnd many constraint scopes with the same constraint relations.
Example 7. Recall the 3-coloring CSP in Example 1. The constraint scopes
are the edges of the graph G to be colored, and for all constraints the relation
is r̸=, containing all pairs of diﬀerent colors. Then, r̸= is just the triangle graph
K3, and in fact it is well known that G is 3-colorable if and only if G →K3.
Moreover, if G contains a triangle, this entails that G is 3-colorable if and only
if K3 is the core of G.
◁
From the above example, we clearly see that, given a pair of relational structures
A and B, deciding whether B is the core of A is an NP-hard problem, where
the hardness holds even if B is ﬁxed, and thus is a constant structure not part
of the input of the problem. More precisely, it has been shown that the precise
complexity of this problem is DP-complete [24].
The following result, proved exploiting pebble games on relational struc-
tures, provides a large class of tractable instances, which extends—but in the
promise version—the well-known island of tractability of the bounded treewidth
structures.
Proposition 5 ([19]). Let w ≥1 be a ﬁxed constant. Moreover, let A be a class
of structures such that the core of each structure in A has tree-width at most w.
Then CSP(A, All) is in promise polynomial-time.
Interestingly, it was later proved that the above property is also necessary for
tractability, as far as relational structures with ﬁxed arity are concerned, and
assuming that a (very unlikely) collapse does not occur in the theory of ﬁxed-
parameter tractability [22].
Proposition 6 ([46]). Assume that FPT ̸= W[1]. Then, for every recursively
enumerable class A of structures of bounded arity, CSP(A, All) is in polynomial
time only if the cores of all structures in A have bounded treewidth.

Uniform Constraint Satisfaction Problems and Database Theory
187
This is a remarkable theoretical result. However, exploiting the above property
in practice may be rather diﬃcult, because of the hardness of dealing with the
cores of relational structures, while it can be useful if we have some guarantee
that our instances belong to the class A.
It is worthwhile noting that, if we do not have such a guarantee, (in general)
the polynomial time algorithms for CSP(A, All) cannot give a checkable justi-
ﬁcation for their answers, or a way to compute a solution (unless P = NP). To
see that, consider the following simple example, where checking the membership
in the class is in fact “the” problem: Let 3COL be the class of all (structures en-
coding the) 3-colorable graphs that contains a triangle. Therefore, ∀G ∈3COL
the core of G is the triangle K3, because K3 is a subgraph of G, and G →K3,
from the 3-colorability of G. Moreover, the treewidth of K3 is 2, and thus the
core of all structures in 3COL is 2. From Proposition 5, CSP(3COL, All) is in
polynomial time for any right-hand class of structures and thus, in particular, for
the class B consisting of the one relational structure B = ⟨{red, green, blue}, r̸=⟩.
Let ALG be any polynomial-time algorithm that solves the 3-coloring problem
CSP(3COL, B) (trivial, as restricted to the “yes” instances of 3COL) according
to Deﬁnition 8. Now, let (G, B) be an input instance of this problem such that
G is any graph containing a triangle, and assume that ALG outputs “yes” on
(G, B). Then, this output may be
- correct, if G in fact belongs to the class 3COL, and hence is 3-colorable, by
deﬁnition of the class, or
- wrong, if G /∈3COL, and thus the output of ALG may be arbitrary.
Therefore, a positive answer gives no information on the problem instance at
hand (while a possible negative answer is always correct). However, if ALG gave
some polynomial-time checkable justiﬁcation for its answers, rather than a mere
“yes” or “no”, we would be able to solve in polynomial-time the NP-hard 3-
colorability problem: given any graph G, just add a (disconnected) triangle to
it, feed ALG with the resulting graph, get its output, and decide whether the
result is correct by checking in polynomial-time its justiﬁcation (or directly, for
negative answers).
It follows that the usual approach of calling a Boolean procedure many times,
in order to build a solution node-by-node by adding “something” to the initial
instance at each call, does not work here. Why that? Intuitively, because such
a “something” in general may lead us out of the required class A. In fact, we
may also loose a possible initial guarantee of membership in A. Of course, such
Boolean procedures may instead be useful if the class A has the property to be
closed under adding such a “something.”
5.2
No-Promise Solutions
More useful results for the applications are about no-promise tractability, where
the output of algorithms is always reliable, and may be “don’t know” only if the
input instance does not belong to the desired class of structures.

188
F. Scarcello, G. Gottlob, and G. Greco
Deﬁnition 10 (Tractability, no-promise version). CSP(A, All) is in no-
promise polynomial-time for an arbitrary class A of problems if there is a poly-
nomial time algorithm such that, given (the encoding of) two structures S and
R,
– says “yes” only if (S, R) ∈CSP(A, All), that is only if there is a homomor-
phism from S to R;
– says “no” only if (S, R) /∈CSP(A, All);
– says “don’t know” only if S /∈A.
2
A nice result in this respect was recently proven by Chen and Dalmau [13]. It
can be seen as a generalization of Proposition 5 to structures of unbounded arity,
since the hypergraph-based notion of generalized hypertree-width is considered,
instead of the graph-based notion of treewidth. It is shown that instances hav-
ing bounded generalized hypertree-width are eﬃciently solvable, even without
computing a decomposition. This is a remarkable result, as computing such a
decomposition is NP-hard [41]. Moreover, the tractability result is extended to
structures homomorphically equivalent to structures having this property, where
A is homomorphically equivalent to A′ if A →A′ and A′ →A. Note that this
is slightly more general than considering the core of the structure, because A′ is
not required to be a substructure of A.
Proposition 7 ([13]). Let w ≥1 be a ﬁxed constant, and let A be a class of
structures homomorphically equivalent to structures having generalized hypertree-
width at most w. Then CSP(A, All) is in no-promise polynomial-time. Moreover,
“no” instances are always recognized (we never get a “don’t know” answer for
them).
5.3
A Database View
We give a database-theory reading of Proposition 7 and of its proof. We may gen-
eralize the property of acyclic instances that pairwise consistency entails global
consistency to the class of bounded generalized hypertree-width instances, where
pairwise consistency is replaced by the following notion of local consistency.
Deﬁnition 11. Let Q be a conjunctive query over a database db. We
say that Q is ℓ-consistent w.r.t. db if, for every set of ℓatoms S
=
{r1( ¯X1), r2( ¯X2), . . . , rℓ( ¯Xℓ)} ⊆atoms(Q), no tuple of any relation in S is missed
by taking the join of all these ℓatoms. That is, for every atom ri( ¯Xi) ∈S, we
have 
¯
Xi(r1( ¯X1) ▷◁r2( ¯X2) ▷◁· · · ▷◁rℓ( ¯Xℓ)) = ri.
2
Note that this deﬁnition is a simple extension of the classical one: pairwise
consistency is just 2-consistency. Moreover, as for pairwise consistency, for any
ﬁxed ℓ, it can be enforced in polynomial time. Indeed, Figure 9 shows a procedure
that, given a query Q over a database db, removes from the relations in db those
tuples that do not fulﬁl the desired local consistency property, and outputs a new
(smaller) database db′ such that Q is ℓ-consistent w.r.t. db′. If some relations
in db′ is empty, then we know that Q has no answer on db′, as well as on

Uniform Constraint Satisfaction Problems and Database Theory
189
the original database db (as we only performs operations that represent sub-
queries of the full—more constrained—query Q). Let t be the number of tuples
in db, that is the sum the cardinalities of all relations in db, a the number of
atoms in the body of Q, and rmax the relation having the largest size tmax over
the relations in db. Then, it is easy to check that the cost of this procedure is
O(
a
ℓ

tℓ
maxt), which is clearly polynomial in the input, if ℓis a constant, because
a
ℓ

is O(aℓ).
The following result shows that, for (suﬃciently) low-width instances, this
local consistency property entails global consistency.
Input: A conjunctive query Q over a database db.
Output: A database db′ ⊆db such that Q is ℓ-consistent w.r.t. db′, or
failure, only if Q has no answer on db.
Repeat
For each S = {r1( ¯
X1), r2( ¯
X2), . . . , rℓ( ¯
Xℓ)} ⊆atoms(Q) Do
Compute rS = r1( ¯X1) ▷◁r2( ¯
X2) ▷◁· · · ▷◁rℓ( ¯Xℓ);
For each ri ∈S Do
Compute ri = Q
¯
Xi(r1( ¯
X1) ▷◁r2( ¯X2) ▷◁· · · ▷◁rℓ( ¯
Xℓ))
Until a ﬁxpoint is reached or some database relation becomes empty.
Let db′ be the database obtained after the previous steps.
If some relation in db′ is empty Then Output failure,
Else Output db′.
Fig. 9. Enforcing ℓ-consistency
Proposition 8. Let k be any positive integer, let Qf be a conjunctive query
over a database db, and let Q be a query homomorphically equivalent to Qf
(that is, whose associated relational structures are homomorphically equivalent)
such that ghw(H(Q)) ≤k. Then, 2k-consistency entails global consistency for Q
w.r.t. db.
Proof. From the hypothesis, there exists a width-k generalized hypertree-
decomposition HD = ⟨T, χ, λ⟩of the hypergraph H(Q). From Section 3, we
know that there is an equivalent acyclic query Qa on a database dba that we
can build by computing, for each vertex p of T , the join of the (at most k)
atoms in λ(p), and then projecting the resulting relation on the variables in
χ(p). Moreover, assume that Q is 2k-consistent w.r.t. db. Then, we know that
computing the join of any set of 2k atoms of Q we do not miss any tuple from
any involved database relation. Of course this property trivially holds for any
set of k′ atoms, with k′ ≤2k. Now, consider the join ri( ¯Xi) ▷◁rj( ¯Xj) of any
pair of atoms ri( ¯
Xi), rj( ¯Xj) of the acyclic query Qa. Since either relation comes
from the join of at most k atoms, this relational expression involves the join of
at most 2k atoms of db. From the 2k-consistency of Q w.r.t. db, no tuple can be
missed in any relation by taking the join of such a set of atoms. It easily follows
that ri( ¯Xi)⋉rj( ¯Xj) = ri, as well as rj( ¯Xj)⋉ri( ¯Xi) = rj. Therefore, the acyclic
query Qa is pairwise consistent and thus globally consistent w.r.t. dba. Then,

190
F. Scarcello, G. Gottlob, and G. Greco
its equivalent query Q (and hence the original query Qf) is globally consistent
w.r.t. db, too.
2
Let ℓ= 2k. It is worthwhile noting that, after Proposition 8, the simple procedure
shown in Figure 9 is able to decide in polynomial time whether a given query Q
has some answer on a database db without computing any decomposition of its
hypergraph H(Q). If the procedure outputs failure, then Q(db) = ∅; otherwise
we have the guarantee that, if ghw(H(Q)) ≤k, then Q has some answers on
db. In practice, in this case we try to compute such an answer from the reduced
database db′. If we fail, we infer that ghw(H(Q)) > k, but we cannot say
anything about the answer of Q; otherwise, if we actually get an answer (all
atoms/constraints are satisﬁed), we clearly know that Q(db) ̸= ∅, but we cannot
say anything on the generalized hypertree width of the hypergraph—however,
this is not really important, at this point!
After these interesting no-promise tractability results, one may wonder
whether decompositions are still important to compute or not. Observe that,
as for pairwise consistency in acyclic queries, consistency enforcing techniques
are somehow brute-force: by enforcing the consistency on any group of 2k atoms,
we also enforce pairwise consistency on any pair of groups of k atoms belong-
ing to any possible k-width generalized hypertree decomposition of the query.
However, while in the case of acyclic instances computing a join tree is feasible
in linear time, in the case of bounded-width instances computing a generalized
hypertree decomposition is NP-hard. It follows that there is not a clear answer
here, it depends on the applications.
To be more precise, let us have a look at the cost of evaluation procedures. Let
a be the number of atoms in the body of the given query Q and v the number
of its variables. Applying the no-promise approach takes O(
 a
2k

t|rmax|2k), while
by exploiting a given (generalized) hypertree decomposition HD of Q in normal
form, we take O((m −1)|rmax|k log |rmax| + m|rmax|k), where m is the number
of vertices of HD, which is at most the number of variables v for decompositions
in normal form (actually, m << v in typical applications). In the latter case,
it is also easier to compute all solutions of the given problem, but we have to
compute such a width-k decomposition HD. Of course, if the database/constraint
relations are large, it is clearly preferable to spend some time in computing a
good decomposition, since its computation time does not depend on the database
size (see Section 3.5). Also, this task may be easier if we have some information
on the structure of our problem instances that can proﬁtably be exploited. On
the other hand, if we miss any (useful) structural information on the problem
and the relations sizes are very small, the no-promise approach may be useful,
because the larger factor
 a
2k

and the larger exponent 2k may be balanced by
the decomposition time.
For completeness, we observe that the no-promise approach can be also im-
plemented working on groups of k atoms, and performing semi-join operations
between all pairs of these groups, until a ﬁxpoint is reached. This variation
of the consistency enforcing procedure, which is similar to the procedure de-
scribed in [13], takes O(
a
k
2t|rmax|k log |rmax|). Thus, this latter approach may

Uniform Constraint Satisfaction Problems and Database Theory
191
be preferable to the procedure shown in Figure 9 if we want to enforce consis-
tency but there are some large relations in the database, because the database
exponent becomes k instead of 2k. However, note that
a
k
2 may be much larger
than
 a
2k

. For instance, if a = 50 and k = 3, the former is about 384 · 106, while
the latter one is about 16 · 106. In any case, compared with the hypertree-based
approach (without considering the cost of computing the decomposition), if we
assume v = 100 variables, the consistency enforcing procedure is about 3 million
times slower in this example.
Open problem. It remains to understand whether the property of a structure
to have k-bounded generalized hypertree width is also necessary for a correct use
of the local consistency approach. We know that it holds for k = 1, because 2-
consistency entails global consistency with respect to every right-hand structure
if and only if (the core of) a structure has generalized hypertree width 1 (i.e.,
it is acyclic) [6]. This means that, if we consider a conjunctive query Q whose
core is not acyclic, there exists a database db such that the consistency enforc-
ing approach fails, that is, Q is pairwise consistent w.r.t. db but not globally
consistent.
However, this problem is open for an arbitrary bound k. Let S be a structure
and S′ its core: is it the case that 2k-consistency entails global consistency with
respect to every right-hand (database) structure if and only if ghw(H(S′)) ≤k ?
It is worthwhile noting that this problem has been recently closed for struc-
tures having a ﬁxed arity bound, where variables, graphs, and the notion of
treewidth play the roles of hyperedges, hypergraphs, and generalized hypertree
width, respectively. In this framework, one can deﬁne a variable oriented variant
of the notion of k-consistency, by considering all partial homomorphisms whose
domain contain at most k variables. As observed in [55], this is equivalent to
play the existential k-pebble game on the given pair of structures. Let a ≥1
be a ﬁxed constant, let S be a relational structure whose relations have arity at
most a, and let S′ be its core. Then, the variable variant of k-consistency entails
global consistency with respect to every right-hand structure if and only if the
treewidth of (the graph associated with) S′ is at most k [5].
References
1. Abiteboul, S., Hull, R., Vianu, V.: Foundations of Databases. Addison-Wesley,
Reading (1995)
2. Abiteboul, S., Duschka, O.M.: Complexity of Answering Queries Using Material-
ized Views. In: Proc. of the PODS 1998, Seattle, Washington, pp. 254–263 (1998)
3. Adler, I.: Marshals, Monotone Marshals, and Hypertree-Width. Journal of Graph
Theory 47(4), 275–296 (2004)
4. Adler, I., Gottlob, G., Grohe, M.: Hypertree-Width and Related Hypergraph In-
variants. In: Proc. of EuroComb 2005, Berlin (2005)
5. Atserias, A., Bulatov, A., Dalmau, V.: On the Power of k-Consistency. In: Arge,
L., Cachin, C., Jurdzi´nski, T., Tarlecki, A. (eds.) ICALP 2007. LNCS, vol. 4596,
pp. 279–290. Springer, Heidelberg (2007)

192
F. Scarcello, G. Gottlob, and G. Greco
6. Beeri, C., Fagin, R., Maier, D., Yannakakis, M.: On the desirability of acyclic
database schemes. Journal of the ACM 30(3), 479–513 (1983)
7. Van Benthem, J.: Dynamic Bits and Pieces. ILLC Research Report, University of
Amsterdam (1997)
8. Bernstein, P.A., Goodman, N.: The power of natural semijoins. SIAM Journal on
Computing 10(4), 751–771 (1981)
9. Bodlaender, H.L., Fomin, F.V.: Tree decompositions with small cost. Discrete Ap-
plied Mathematics 145(2), 143–154 (2005)
10. Cai, J., Chakaravarthy, V.T., Kaushik, R., Naughton, J.F.: On the Complexity of
Join Predicates. In: Proc. of PODS 2001 (2001)
11. Chandra, A.K., Kozen, D.C., Stockmeyer, L.J.: Alternation. Journal of the
ACM 26, 114–133 (1981)
12. Chandra, A.K., Merlin, P.M.: Optimal Implementation of Conjunctive Queries in
relational Databases. In: Proc. of STOC 1977, pp. 77–90 (1977)
13. Chen, H., Dalmau, V.: Beyond hypertree width: Decomposition methods without
decompositions. In: van Beek, P. (ed.) CP 2005. LNCS, vol. 3709, pp. 167–181.
Springer, Heidelberg (2005)
14. Chekuri, C., Rajaraman, A.: Conjunctive query containment revisited. Theoretical
Computer Science 239(2), 211–229 (2000)
15. Chung, F., Frank, P., Graham, R., Shearer, J.: Some intersection theorems for
ordered sets and graphs. Journal of Combinatorial Theory, Series A 43, 23–37
(1986)
16. Cohen, D.A., Jeavons, P.G., Gyssens, M.: A Uniﬁed Theory of Structural Tractabil-
ity for Constraint Satisfaction and Spread Cut Decomposition. In: Proc. IJCAI
2005, Edinburgh, UK, pp. 72–77 (2005)
17. Cohen, D.A., Jeavons, P.G., Gyssens, M.: A uniﬁed theory of structural tractabil-
ity for constraint satisfaction problems. Journal of Computer and System Sci-
ences 74(5), 721–743 (2008)
18. Cook, W., Seymour, P.: Tour merging via branch-decomposition. INFORMS Jour-
nal on Computing 15(3), 233–248 (2003)
19. Dalmau, V., Kolaitis, P.G., Vardi, M.Y.: Constraint Satisfaction, Bounded
Treewidth, and Finite-Variable Logics. In: Van Hentenryck, P. (ed.) CP 2002.
LNCS, vol. 2470, pp. 310–326. Springer, Heidelberg (2002)
20. Dechter, R.: Constraint networks. In: Shapiro, S.C. (ed.) Encyclopedia of Artiﬁcial
Intelligence, 2nd edn., vol. 1, pp. 276–285. Wiley, Chichester (1992)
21. Dechter, R.: Constraint Processing. Morgan Kaufmann, San Francisco (2003)
22. Downey, R., Fellows, M.: Parameterized Complexity. Springer, Heidelberg (1999)
23. Fagin, R., Mendelzon, A.O., Ullman, J.D.: A simpliﬁed universal relation assump-
tion and its properties. ACM Transactions on Database Systems 7(3), 343–360
(1982)
24. Fagin, R., Kolaitis, P.G., Popa, L.: Data exchange: getting to the core. ACM Trans.
Database Syst. 30(1), 174–210 (2005)
25. Feder, T., Vardi, M.Y.: The computational structure of monotone monadic SNP
and constraint satisfaction: a study through Datalog and group theory. SIAM Jour-
nal of Computing 28, 57–104 (1998)
26. Flum, J., Frick, M., Grohe, M.: Query evaluation via tree-decompositions. Journal
of the ACM 49(6), 716–752 (2002)
27. Freuder, E.C.: A suﬃcient condition for backtrack-bounded search. Journal of
ACM 32(4), 755–761 (1985)
28. Frick, M., Grohe, M.: Deciding ﬁrst-order properties of locally tree-decomposable
structures. Journal of the ACM 48(6), 1184–1206 (2001)

Uniform Constraint Satisfaction Problems and Database Theory
193
29. Garey, M.R., Johnson, D.S.: Computers and Intractability: A Guide to the Theory
of NP-Completeness. Freeman, New York (1979)
30. Garcia-Molina, H., Ullman, J., Widom, J.: Database system implementation. Pren-
tice Hall, Englewood Cliﬀs (2000)
31. Ghionna, L., Granata, L., Greco, G., Scarcello, F.: Hypertree Decompositions for
Query Optimization. In: Proc. of ICDE 2007, pp. 36–45 (2007)
32. Goodman, N., Shmueli, O.: Tree queries: a simple class of relational queries. ACM
Transactions on Database Systems 7(4), 653–6773 (1982)
33. Gottlob, G., Leone, N., Scarcello, F.: Hypertree decompositions and tractable
queries. Journal of Computer and System Sciences 64(3), 579–627 (2002)
34. Gottlob, G., Leone, N., Scarcello, F.: A comparison of structural CSP decomposi-
tion methods. Artiﬁcial Intelligence 124(2), 243–282 (2000)
35. Gottlob, G., Leone, N., Scarcello, F.: Advanced parallel algorithms for processing
acyclic conjunctive queries, rules, and constraints. In: Proceedings of the 2000
Conference on Software Engineering and Knowledge Engineering (SEKE 2000),
Chicago, pp. 167–176 (2000)
36. Gottlob, G., Leone, N., Scarcello, F.: On tractable queries and constraints. In:
Bench-Capon, T.J.M., Soda, G., Tjoa, A.M. (eds.) DEXA 1999. LNCS, vol. 1677,
pp. 1–15. Springer, Heidelberg (1999)
37. Gottlob, G., Leone, N., Scarcello, F.: The complexity of acyclic conjunctive queries.
Journal of the ACM 48(3), 431–498 (2001)
38. Gottlob, G., Leone, N., Scarcello, F.: Computing LOGCFL Certiﬁcates. Theoretical
Computer Science 270(1-2), 761–777 (2002)
39. Gottlob, G., Leone, N., Scarcello, F.: Robbers, marshals, and guards: game the-
oretic and logical characterizations of hypertree width. Journal of Computer and
System Sciences 66(4), 775–808 (2003)
40. Gottlob, G., Grohe, M., Musliu, N., Samer, M., Scarcello, F.: Hypertree decom-
positions: Structure, algorithms, and applications. In: Kratsch, D. (ed.) WG 2005.
LNCS, vol. 3787, pp. 1–15. Springer, Heidelberg (2005)
41. Gottlob, G., Miklos, Z., Schwentick, T.: Generalized hypertree decompositions:
NP-Hardness and Tractable Variants. In: Proc. of PODS 2007, pp. 13–22 (2007)
42. Gottlob,
G.,
Samer,
M.:
A
Backtracking-Based
Algorithm
for
Computing
Hypertree-Decompositions. arXiv:cs/0701083 (2007)
43. Gr¨adel, E.: On the Restraining Power of Guards. Journal of Symbolic Logic 64,
1719–1742 (1999)
44. Greibach, S.H.: The Hardest Context-Free Language. SIAM Journal on Comput-
ing 2(4), 304–310 (1973)
45. Greco, G., Scarcello, F.: Non-Binary Constraints and Optimal Dual-Graph Repre-
sentations. In: Proc. of IJCAI 2003, pp. 227–232 (2003)
46. Grohe, M.: The Complexity of Homomorphism and Constraint Satisfaction Prob-
lems Seen from the Other Side. Journal of the ACM 54(1) (2007)
47. Grohe, M., Marx, D.: Constraint solving via fractional edge covers. In: Proc. of
SODA 2006, Miami, Florida, USA, pp. 289–298 (2006)
48. Grohe, M., Schwentick, T., Segouﬁn, L.: When is the evaluation of conjunctive
queries tractable? In: Proc. of STOC 2001, Heraklion, Crete, Greece, pp. 657–666
(2001)
49. Gyssens, M., Jeavons, P.G., Cohen, D.A.: Decomposing constraint satisfaction
problems using database techniques. Journal of Algorithms 66, 57–89 (1994)
50. Harvey, P., Ghose, A.: Reducing Redundancy in the Hypertree Decomposition
Scheme. In: Proc. of 5th IEEE International Conference on Tools with Artiﬁcial
Intelligence, pp. 474–481 (2003)

194
F. Scarcello, G. Gottlob, and G. Greco
51. Ioannidis, Y.E.: Query Optimization. The Computer Science and Engineering
Handbook, pp. 1038–1057 (1997)
52. Ioannidis, Y.E.: The History of Histograms (abridged). In: Proc. of VLDB 2003,
Berlin, Germany, pp. 19–30 (2003)
53. Johnson, D.S.: A Catalog of Complexity Classes. In: Handbook of Theoretical
Computer Science, Volume A: Algorithms and Complexity, pp. 67–161 (1990)
54. Kolaitis, P.G.: Constraint Satisfaction, Databases, and Logic. In: Proc. of IJCAI
2003, Acapulco, Mexico, pp. 1587–1595 (2003)
55. Kolaitis, P.G., Vardi, M.Y.: Conjunctive-query containment and constraint satis-
faction. Journal of Computer and System Sciences 61(2), 302–332 (2000)
56. Korimort, T.: Constraint Satisfaction Problems – Heuristic Decomposition. Ph.D
thesis, Vienna University of Technology (April 2003)
57. Kun, G.:
Constraints,
MMSNP and
expander
relational
structures (2007)
ArXiv.org, http://www.citebase.org/abstract?id=oai:arXiv.org:0706.1701
58. Maier, D.: The Theory of Relational Databases. Computer Science Press (1986)
59. McMahan, B.: Bucket eliminiation and hypertree decompositions. Implementation
report, Institute of Information Systems (DBAI), TU Vienna (2004)
60. Musliu, N.: Tabu Search for Generalized Hypertree Decompositions. In: Proc. of
MIC 2007 (2007)
61. Reingold, O.: Undirected ST-connectivity in log-space. In: Proc. of STOC 2005,
Baltimore, MD, USA, pp. 376–385 (2005)
62. McMahan, B.J., Pan, G., Porter, P., Vardi, M.Y.: Projection Pushing Revisited. In:
Bertino, E., Christodoulakis, S., Plexousakis, D., Christophides, V., Koubarakis,
M., B¨ohm, K., Ferrari, E. (eds.) EDBT 2004. LNCS, vol. 2992, pp. 441–458.
Springer, Heidelberg (2004)
63. Papadimitriou, C.H., Yannakakis, M.: On the complexity of database queries. In:
Proc. of PODS 1997, Tucson, Arizona, pp. 12–19 (1997)
64. Pearson, J., Jeavons, P.G.: A Survey of Tractable Constraint Satisfaction Problems,
CSD-TR-97-15, Royal Holloway, Univ. of London (1997)
65. Robertson, N., Seymour, P.D.: Graph minors. II. Algorithmic aspects of tree width.
Journal of Algorithms 7, 309–322 (1986)
66. Ruzzo, W.L.: Tree-size bounded alternation. Journal of Cumputer and System
Sciences 21, 218–235 (1980)
67. Sacc`a, D.: Closures of database hypergraphs. Journal of the ACM 32(4), 774–803
(1985)
68. Samer, M.: Hypertree-decomposition via Branch-decomposition. In: Proceeding of
IJCAI 2005, pp. 1535–1536 (2005)
69. Scarcello, F.: The Hypertree Decompositions HomePage (2002),
http://www.deis.unical.it/scarcello/Hypertrees/,
http://www.dbai.tuwien.ac.at/proj/hypertree/ maintained by N. Musliu
70. Scarcello, F., Greco, G., Leone, N.: Weighted Hypertree Decompositions and Op-
timal Query Plans. In: Proc. of PODS 2004, pp. 210–221 (2004)
71. Seymour, P.D., Thomas, R.: Graph Searching and a Min-Max Theorem for Tree-
Width. Journal of Combinatorial Theory, Series B 58, 22–33 (1993)
72. Seidel, R.: A new method for solving constraint satisfaction problems. In: Proc. of
IJCAI 1981 (1981)
73. Subbarayan, S., Andersen, H.R.: Backtracking Procedures for Hypertree, Hyper-
Spread and Connected Hypertree Decomposition of CSPs. In: Proc. of IJCAI 2007,
pp. 180–185 (2007)
74. Skyum, S., Valiant, L.G.: A complexity theory based on Boolean algebra. Journal
of the ACM 32, 484–502 (1985)

Uniform Constraint Satisfaction Problems and Database Theory
195
75. Sudborough, I.H.: Time and Tape Bounded Auxiliary Pushdown Automata. In:
Gruska, J. (ed.) MFCS 1977. LNCS, vol. 53, pp. 493–503. Springer, Heidelberg
(1977)
76. Tarjan, R.E., Yannakakis, M.: Simple linear-time algorithms to test chordality of
graphs, test acyclicity of hypergraphs, and selectively reduce acyclic hypergraphs.
SIAM Journal on Computing 13(3), 566–579 (1984)
77. Ullman, J.D.: Principles of Database and Knowledge Base Systems. Computer
Science Press (1989)
78. Vardi, M.: Complexity of relational query languages. In: Proc. of STOC 1982, San
Francisco, California, United States, pp. 137–146 (1982)
79. Vardi, M.: Constraint Satisfaction and Database Theory. In: Tutorial at the 19th
ACM Symposium on Principles of Database Systems, PODS 2000 (2000)
80. Wilschut, A.N., Flokstra, J., Apers, P.M.G.: Parallel evaluation of multi-join
queries. In: Proceedings of SIGMOD 1995, San Jose, CA, USA, pp. 115–126 (1995)
81. Yannakakis, M.: Algorithms for acyclic database schemes. In: Proc. of VLDB 1981,
Cannes, France, pp. 82–94 (1981)
82. Yu, C.T., ¨Ozsoyo˘glu, M.Z.: On determining tree-query membership of a distributed
query. Infor. 22(3), 261–282 (1984)
83. Yu, C.T., ¨Ozsoyo˘glu, M.Z., Lam, K.: Optimization of Distributed Tree Queries.
Journal of Computer and System Sciences 29(3), 409–445 (1984)

Constraint Satisfaction Problems
with Inﬁnite Templates
Manuel Bodirsky
´Ecole polytechnique, Laboratoire d’informatique (LIX), France
bodirsky@informatik.hu-berlin.de
Abstract. Allowing templates with inﬁnite domains greatly expands
the range of problems that can be formulated as a non-uniform con-
straint satisfaction problem. It turns out that many CSPs over inﬁnite
templates can be formulated with templates that are ω-categorical. We
survey examples of such problems in temporal and spatial reasoning,
inﬁnite-dimensional algebra, acyclic colorings in graph theory, artiﬁcial
intelligence, phylogenetic reconstruction in computational biology, and
tree descriptions in computational linguistics.
We then give an introduction to the universal-algebraic approach to
inﬁnite-domain constraint satisfaction, and discuss how cores, polymor-
phism clones, and pseudo-varieties can be used to study the computa-
tional complexity of CSPs with ω-categorical templates. The theoretical
results will be illustrated by examples from the mentioned application
areas. We close with a series of open problems and promising directions
of future research.
1
Introduction
Some of the oldest results in constraint satisfaction concern constraint satisfac-
tion problems over inﬁnite domains. Examples are the constraint satisfaction
problem (CSP) for Allen’s interval algebra and its fragments, and the CSPs for
many other temporal reasoning formalisms. Also in spatial reasoning, some of
the earliest computational problems can be formulated as CSPs, e.g., the CSP
for the region connection calculus.
In the 1990’s, several systematic results about the computational complex-
ity of CSPs in spatial and temporal reasoning were obtained, mostly for binary
constraint languages. An important step was Nebel and B¨urckert’s discovery
of Ord-Horn, a tractable fragment of Allen’s interval algebra. In a computer-
assisted proof, they showed that Ord-Horn is a largest tractable fragment of
Allen’s interval algebra, i.e., adding any (binary) relation from Allen’s interval
algebra to Ord-Horn results in an NP-complete constraint language. Another
important step in complexity classiﬁcation was the complete classiﬁcation of
all tractable fragments of the region connection calculus RCC-5 in spatial rea-
soning by Jonsson and Drakengren [44]. The corresponding result for Allen’s
interval algebra was obtained later by Krokhin, Jeavons, and Jonsson [49]. Simi-
lar classiﬁcations for the cardinal direction calculus, for constraint languages for
N. Creignou et al. (Eds.): Complexity of Constraints, LNCS 5250, pp. 196–228, 2008.
c
⃝Springer-Verlag Berlin Heidelberg 2008

Constraint Satisfaction Problems with Inﬁnite Templates
197
branching time, and constraint languages for partially ordered time were mostly
obtained by a case-by-case study and ad-hoc methods. There are some common
themes [29] and tools (e.g., local consistency techniques), but so far there is no
general theory of tractabilility and hardness for such problems.
A typical property of constraint satisfaction problems is that if we add con-
straints to an unsatisﬁable instance of the CSP, the instance stays unsatisﬁable.
Moreover, if we form the disjoint union of two satisﬁable instances of the CSP,
the resulting instance is again satisﬁable. In fact, all computational problems
(i.e., all sets of relational structures) that share these two properties can be for-
mulated as a homomorphism problem for a ﬁxed inﬁnite relational structure Γ
(in other words, as a non-uniform CSP with an inﬁnite template). Many exam-
ples of computational problems that have been studied in the literature have
a natural formulation as a homomorphism problem for a ﬁxed inﬁnite struc-
ture Γ, and we will mention examples from graph theory, artiﬁcial intelligence,
phylogenetic reconstruction, ﬁnite model theory, and tree description logics in
computational linguistics.
This survey is about techniques to study the computational complexity of
CSPs with inﬁnite templates. We focus mostly on the border between CSPs that
can be solved by a polynomial-time algorithm, and CSPs that are known to be
NP-hard. This border has been of central interest in most of the mentioned work
on temporal and spatial reasoning. Our main theme will be the question which
of the powerful universal-algebraic techniques that are employed to study the
complexity of the ﬁnite domain CSP (see e.g. [22]) can be generalized to inﬁnite
domain templates. It turns out that the universal-algebraic approach applies if
the template satisﬁes an important and central property in model theory, called
ω-categoricity.
The article is divided into two parts: in the ﬁrst part we demonstrate that the
class of computational problems that can be formulated with an ω-categorical
template is very large (actually, it contains all the inﬁnite-domain CSPs we
have mentioned so far). In the second part, we set out to develop the universal-
algebraic theory for ω-categorical templates. We recall the deﬁnitions of poly-
morphisms, algebras, and (pseudo-) varieties, and show that these concepts are
useful not only for ﬁnite but also for inﬁnite ω-categorical structures. Some of the
tractability results presented here do not have a ﬁnite domain counterpart. We
only give proofs of the statements in this text if they are are instructive, previ-
ously unpublished, or more conceptual than the existing proofs in the literature,
and give references to the literature in all other cases.
2
Inﬁnite Templates
The notation used in this text mostly follows Hodges’ text book [42]. A signa-
ture τ is a set of relation and function symbols, each equipped with an arity. A
τ-structure A is a set A (the domain of A) together with a relation RA ⊆Ak for
each k-ary relation symbol in τ and a function f A : Ak →A for each k-ary func-
tion symbol in τ. When there is no danger of confusion, we use the same symbol

198
M. Bodirsky
for a function and its function symbol, and for a relation and its relation symbol.
By convention, A, B, C, . . . denotes the domain of the structures A, B, C, . . . ,
respectively. We sometimes write (A, RA
1 , RA
2 , . . . , f A
1 , f A
2 , . . . ) for the relational
structure A with relations RA
1 , RA
2 , . . . and functions f A
1 , f A
2 , . . . We say that a
structure is inﬁnite if its domain is inﬁnite. The most important special cases
of structures that appear in this paper are relational structures, that is, struc-
tures with a purely relational signature, and algebras, that is, structures with a
purely functional signature. Algebras with domain A, B, C, . . . are denoted by
A, B, C, . . .
Homomorphisms. A homomorphism h from a structure A to a structure B
with the same signature τ is a mapping from A to B that preserves each function
and each relation for the symbols in τ; that is,
– if (a1, . . . , ak) is in RA, then (h(a1), . . . , h(ak)) must be in RB;
– if f A(a1, . . . , ak) = a0, then f B(h(a1), . . . , h(ak)) = h(a0).
In this article, a (non-uniform) constraint satisfaction problem (CSP) is a com-
putational problem that is speciﬁed by a single structure with a ﬁnite relational
signature, called the template of the CSP. Relational structures that denote tem-
plates for CSPs will be denoted by capital greek letters Γ, ∆(and their domain
by D(Γ), D(∆), respectively).
Deﬁnition 1. Let Γ be a (possible inﬁnite) relational structure with a ﬁnite
relational signature τ. Then CSP(Γ) is the computational problem to decide
whether a given ﬁnite τ-structure homomorphically maps to Γ.
We sometimes also write CSP(D, R1, . . . , Rl) instead of CSP((D, R1, . . . , Rl)).
Note that due to the assumption that the signature τ is ﬁnite, we can ﬁx any
representation of the relation symbols in τ to represent the input structure.
CSP(Γ) can also be considered to be a set – the set of all ﬁnite structures that
homomorphically map to Γ.
Logic. As for ﬁnite domain CSPs, there is another way of looking at the con-
straint satisfaction problem for Γ that uses terminology from logic. A ﬁrst-order
τ-formula is called primitive positive if it is of the form
∃x1, . . . , xm. ψ1 ∧· · · ∧ψl
where ψ1, . . . , ψl are atomic τ-formulas.
It is straightforward to verify (in the same way as for ﬁnite domain CSPs) that
CSP(Γ) is polynomial-time equivalent to the following computational problem
(in fact, the two problems can be considered to be the same computational prob-
lem, up to formalization). The input consists of a primitive positive τ-sentence
Φ (i.e., a primitive positive τ-formula without free variables), and the question
is whether Φ is holds true in Γ. The conjuncts in the primitive positive sentence
are then called the constraints of Φ. From this formulation of the constraint sat-
isfaction problem it is obvious that CSP(Γ) is fully determined by the ﬁrst-order
theory of Γ (i.e., the set of ﬁrst-order sentences that are valid in Γ).

Constraint Satisfaction Problems with Inﬁnite Templates
199
We would like to remark that the logic perspective on CSP(Γ) is closely
related to the evaluation problem for conjunctive queries studied in database
theory. We freely switch between the relational homomorphism and the logic
perspective whenever this is convenient. We also say that A is satisﬁable (with
respect to CSP(Γ) if A homomorphically maps to Γ, and the homomorphism
from A to Γ is called a solution for A.
Example 1. Consider the problem CSP(N, =, ̸=). An instance of this problem
consists of a set of variables, some linked by equality, some by disequality con-
straints. Such an instance is unsatisﬁable if and only if there is a path x1, . . . , xn
from a variable x1 to a variable xn that uses only equality edges, i.e., ‘xi = xi+1’
is a constraint in the instance for each 1 ≤i ≤n −1, and additionally ‘x1 ̸= xn’
is a constraint in the instance. Clearly, it can be tested in linear time in the size
of the input instance whether the instance contains such a path.
Example 2. Next, consider the problem CSP(Q, <). Here, < denotes the strict
linear order on the relational numbers Q (i.e., < is a binary relation). An instance
of this problem can be viewed as a directed graph (potentially with loops), where
there is an arc between the vertices x and y if there is the constraint ‘x < y’ in
the instance. It is easy to see that an instance homomorphically maps to (Q, <)
if and only if there is no directed cycle in the graph. Again, this can be tested
in linear time, e.g., by depth-ﬁrst search.
Example 3. The so-called betweenness problem is CSP(Q, Betw) where Betw is
the ternary relation {(x, y, z) ∈Q3 | x < y < z ∨z < y < x}. This problem is an
NP-complete problem from the famous book of Garey and Johnson [37].
We have deﬁned the constraint satisfaction problem only for relational struc-
tures, but the generalization to structures that also include function symbols is
straightforward, and has been studied for ﬁnite domains [47]. If we allow function
symbols and inﬁnite domains, we can for instance formulate the famous uniﬁca-
tion problem (see, e.g., [56]) as CSP(Γ) for an appropriate inﬁnite structure Γ.
In this article we focus on relational templates only.
Having structures with function symbols will be convenient in Section 8 where
we use algebras to study the computational complexity of CSPs. Moreover, sev-
eral templates that we use to illustrate the theory have a convenient deﬁnition
by means of structures that contain functions, e.g., in Subsections 5.3 and 5.2.
The next lemma is a convenient tool to determine whether a computational
problem can be formulated as CSP(Γ) for an inﬁnite relational structure Γ. The
disjoint union of a set of τ-structures C is a τ-structure B whose domain is the
disjoint union of the domains of the structures in C. The relations in B are the
union of the corresponding relations in the structures in C.
Deﬁnition 2. We say that a set C of relational structures is closed under (ﬁnite)
disjoint unions iﬀwhenever A, B ∈C then the disjoint union of A and B is also
in C. We say that C is closed under inverse homomorphisms iﬀwhenever B ∈C
and A homomorphically maps to B then A ∈C.

200
M. Bodirsky
The following is a fundamental lemma for constraint satisfaction problems.
Lemma 1. Let C be a set of ﬁnite τ-structures, for a ﬁnite relational signature
τ. Then C = CSP(Γ) for some relational structure Γ over an inﬁnite domain if
and only if C is closed under disjoint unions and inverse homomorphisms.
Proof. Clearly, the disjoint union of two instances of CSP(Γ) that homomor-
phically map to Γ also homomorphically maps to Γ. Moreover, if A does not
homomorphically map to Γ, and there is a homomorphism from A to B, then
B does not homomorphically map to Γ either.
For the other direction, suppose that C is a set of relational structures that is
closed under disjoint unions and inverse homomorphisms. Let Γ be the (inﬁnite)
disjoint union of all structures in C. Clearly, every structure in C homomorphi-
cally maps to Γ. Now, let A be a ﬁnite structure with a homomorphism h to
Γ. By construction of Γ, the set h(A) is contained in the disjoint union B of a
ﬁnite set of structures from C. Since C is closed under disjoint unions, B is in C.
Clearly, A homomorphically maps to B, and because C is closed under inverse
homomorphisms, A is in C as well.
⊓⊔
To apply the techniques presented in this paper it will be important that the
templates of the CSPs are ω-categorical (ω-categoricity will be deﬁned in Sec-
tion 3). The structures produced by Lemma 1 are usually not ω-categorical.
Let us conclude this section with remarks concerning the computational com-
plexity of CSP(Γ). So far, we have seen CSPs in Examples 1, 2, and 3 that are in
P or NP-complete. However, it is not hard to come up with undecidable CSPs.
For example, Hilbert’s 10’th problem, the problem to decide whether a given
diophantine equation has a solution, is undecidable [54], and is computationally
equivalent to CSP(Z, R+, R∗) where R+ = {(x, y, z) ∈Z3 | x + y + z = 1} and
R∗= {(x, y, z) ∈Z3 | xy = z}.
Bauslaugh [6] has constructed for every recursive function f an inﬁnite digraph
Γ such that CSP(Γ) is decidable, but has time complexity at least f. In this
paper, we focus on CSPs that are in NP.
3
Good Templates: ω-Categorical Structures
Many important inﬁnite-domain constraint satisfaction problems can be formu-
lated with templates that are ω-categorical. The concept of ω-categoricity is of
central importance in model theory.
Deﬁnition 3. A countably inﬁnite structure Γ is called ω-categorical if all count-
able models of its ﬁrst-order theory are isomorphic to Γ.
One of the ﬁrst structures that were found to be ω-categorical (by Kantor) is the
linear order of the rational numbers (Q, <). We will see many more examples
of ω-categorical structures in this section and in Section 5. One of the standard
approaches to verify that a structure is ω-categorical is via a so-called back-and-
forth argument. We sketch the back-and-forth argument that shows that (Q, <)

Constraint Satisfaction Problems with Inﬁnite Templates
201
is ω-categorical; much more detail about this important concept in model theory
can be found in [42, 57]. Let A be a countable model of the ﬁrst-order theory
of (Q, <). An isomorphism i between A and (Q, <) can be deﬁned inductively
as follows. Suppose that we have already deﬁned i on a ﬁnite subset S of Q
and that f is an embedding of the structure S induced by S in (Q, <) into A.
Since <A is dense and unbounded, we can extend f to any other element of Q
such that the extension is still an embedding from a substructure of Q into A
(going forth). Symmetrically, for every element v of A we can ﬁnd an element
u ∈Q such that the extension of f that maps u to v is also an embedding (going
back). We now alternate between going forth and going back; when going forth,
we extend the domain of f by the next element of Q, according to some ﬁxed
enumeration of the elements in Q. When going back, we extend f such that the
image of A contains the next element of A, according to some ﬁxed enumeration
of the elements of A. If we continue in this way, we have deﬁned the value of
f on all elements of Q. Moreover, f will be surjective, and an embedding, and
hence an isomorphism between (Q, <) and A.
There are many equivalent characterizations of ω-categoricity. Let G be a
permutation group acting on a set X. For n ≥1 the orbit of (t1, . . . , tn) ∈Xn
under G is the set {(α(t1), . . . , α(tn)) | α ∈G}. We say that a permutation group
is oligomorphic if for each n ≥1 there are ﬁnitely many orbits of n-tuples. An
accessible proof of the following theorem can be found in Hodges’ book (Theorem
6.3.1 in [42]).
Theorem 1 (Engeler, Ryll-Nardzewski, Svenonius). The following are
equivalent:
1. Γ is ω-categorical;
2. The automorphism group of Γ is oligomorphic;
3. for each n ≥1, there are ﬁnitely many inequivalent formulas with n free
variables over Γ;
4. for each n ≥1, the orbits of n-tuples are ﬁrst-order deﬁnable in Γ.
The second condition in Theorem 1 provides another possibility to verify that a
structure is ω-categorical. We again illustrate this with the structure (Q, <). It is
not diﬃcult but a good exercise to verify that the orbit of an n-tuple (t1, . . . , tn)
from Qn in the automorphism group of (Q, <) is determined by the weak linear
order that is induced by t1, . . . , tn in (Q, <) (we write weak linear order, and
not linear order, because some of the elements t1, . . . , tn might be equal). Hence,
there is a ﬁnite number of orbits of n-tuples, for all n ≥1.
Lemma 2 below states a useful fact that ω-categorical structures have in
common with ﬁnite structures. A homomorphism h from A to B is called a
strong homomorphism if it also preserves the complements of the relations from
A. Note that an embedding is an injective strong homomorphism.
Lemma 2. Let Γ be a ﬁnite or inﬁnite ω-categorical structure with relational
signature τ, and let A be a countable relational structure with the same signature
τ. If there is no homomorphism (embedding) from A to Γ, then there is a ﬁnite
substructure of A that does not homomorphically map (embed) to Γ.

202
M. Bodirsky
The lemma is an easy consequence of K¨onigs tree lemma; a proof for homomor-
phisms can be found in [11], and the proof for embeddings (and, similarly, for
strong homomorphisms and for injective homomorphisms) is analogous.
3.1
Fra¨ıss´e Amalgamation – ω-Categorical Structures for Everyone
A versatile tool to construct ω-categorical templates is Fra¨ıss´e-amalgamation.
We present it here for structures that might contain relations and functions;
this will sometimes be convenient even if we are only interested in relational
structures (see Subsections 5.2 and 5.3).
If A and B are structures, A ⊆B, and the inclusion map from A to B is an
embedding, then we say that A is a substructure of B. Note that for every subset
S of B there is a unique smallest substructure A of B such that A contains S.
We call A the substructure of B generated by S, also denoted by B[S]. We say
that A is ﬁnitely generated if S is a ﬁnite set of elements.
Let C be a set of ﬁnitely generated structures. We say that C has the
HP Hereditary property if whenever A ∈C and B is a ﬁnitely generated sub-
structure of A then B is isomorphic to a structure in C.
JEP Joint embedding property if whenever A, B ∈C then there is C ∈C such
that both A and B embed into C.
AP Amalgamation property if whenever A, B1, B2 ∈C and e1 : A →B 1
and e2 : A →B2 are embeddings there exists C ∈C and embeddings
f1 : B1 →C and f2 : B2 →C such that f1e1 = f2e2.
A structure Γ is homogeneous (sometimes also called ultra-homogeneous [42])
if every isomorphism between ﬁnitely generated substructures of Γ can be ex-
tended to an automorphism of Γ. It is well-known that a homogeneous structure
Γ with a signature that contains ﬁnitely many relation symbols of arity k, for
each k, is ω-categorical (this is not explicitly mentioned in Hodges’ book [42], but
can easily be shown with the background from there). Moreover, Γ admits quan-
tiﬁer elimination, i.e., for every ﬁrst-order τ-formula there exists an equivalent
quantiﬁer-free τ-formula [42]. In fact, an ω-categorical structure is homogeneous
if and only if it admits quantiﬁer elimination (Statement 2.22 in [25]).
Theorem 2 (Fra¨ıss´e [36]; see [42]). Let τ be a countable signature and let
C be a non-empty ﬁnite or countable set of ﬁnitely generated τ-structures which
has HP, JEP, and AP. Then there is a homogeneous and at most countable
τ-structure Γ such that a structure is a ﬁnitely generated substructure of Γ if
and only if it is isomorphic to a structure in C. The structure Γ is unique up to
isomorphism, and called the Fra¨ıss´e-limit of C.
With Theorem 2 we have seen a third possibility how to verify the ω-categoricity
of our running example (Q, <): it suﬃces to verify that the class of all ﬁnite weak
linear orders is an amalgamation class.
Remark 1. It is sometimes convenient to deﬁne an ω-categorical τ-structure Γ by
deﬁning an amalgamation class C with a signature that is larger than τ such that

Constraint Satisfaction Problems with Inﬁnite Templates
203
Γ is a reduct1 of the Fra¨ıss´e-limit of C. It is an easy consequence of Theorem 1
that Γ must then be ω-categorical.
3.2
New ω-Categorical Structures from Old
Many ω-categorical structures can be derived from other ω-categorical struc-
tures via ﬁrst-order interpretations. Our deﬁnition of ﬁrst-order interpretations
essentially follows [42].
If δ(x1, . . . , xk) is a ﬁrst-order formula with the k free variables x1, . . . , xk,
and Γ is a structure, we we write δ(Ak) for the k-ary relation that is deﬁned by
δ on A.
Deﬁnition 4. A relational σ-structure B has a (ﬁrst-order) interpretation in
a τ-structure A if there exists a natural number d, called the dimension of the
interpretation, and
– a τ-formula δ(x1, . . . , xd) – called domain formula,
– for each k-ary relation symbol R in σ a τ-formula φR(x1, . . . , xk) where the
xi denote disjoint d-tuples of distinct variables – called the deﬁning formulae,
– a τ-formula φ=(x1, . . . , xd, y1, . . . , yd), and
– a surjective map h : δ(Ad) →B – called coordinate map,
such that for all relations R in B and all tuples ai ∈δ(Ad)
(h(a1), . . . , h(ak)) ∈RB ⇔A |= φR(a1, . . . , ak) , and
h(a1) = h(a2) ⇔A |= φ=(a1, a2) .
If the formulas δ, φR, and φ= are all primitive positive, we say that B has a
primitive positive interpretation in A. We say that B is interpretable in Γ with
ﬁnitely many parameters if there are c1, . . . , cn ∈A such that B is interpretable
in the expansion of A by the singleton relations {ci} for all 1 ≤i ≤n. First-
order deﬁnitions are a special case of interpretations: a structure B is (ﬁrst-
order) deﬁnable in A if B has an interpretation in B of dimension one where
the domain formula is logically equivalent to true.
Lemma 3 (see e.g. [42]). If Γ is an ω-categorical structure, then every struc-
ture ∆that is ﬁrst-order interpretable in Γ with ﬁnitely many parameters is
ω-categorical as well.
Suppose that A and B are ﬁnite or ω-categorical structures. In the remainder
of the section we show that then the disjoint union A⊎B (which was deﬁned in
Section 2) and the compositionA ◦B (Deﬁnition 5 below) of A and B are ﬁnite
or ω-categorical as well. Again, this will be convenient to specify templates of
constraint satisfaction problems.
The composition of A and B is, roughly speaking, the structure obtained
from A by replacing each element in A by a copy of B.
1 A reduct of a structure A is a structure that is obtained from A by removing relations
and/or functions from A.

204
M. Bodirsky
Deﬁnition 5. If A, B are τ-structures, then A ◦B is the τ-structure with do-
main A × B, where ((a1, b1), . . . , (ak, bk)) ∈RA◦B for a k-ary relation symbol
R ∈τ iﬀ(a1, . . . , ak) ∈RA or (a1 = · · · = ak and (b1, . . . , bk) ∈B).
To verify ω-categoricity of disjoint union and composition it is most convenient
to use the second condition from Theorem 1 (i.e., we will count the orbits of
k-tuples in the resulting structure). For an ω-categorical structure A, let fn(A)
be the number of orbits of n-tuples in the automorphism group of A, and let
F(A, x) be the exponential generating function in one formal variable x, deﬁned
by 
n≥0 fn(A)xn/n!. The following reﬂects well-known facts in enumerative
combinatorics (for a presentation in the context of oligomorphic permutation
groups, see [25]).
Lemma 4. Let A, B be ﬁnite or ω-categorical structures. Then
F(A ⊎B, x) = F(A, x)F(B, x)
F(A ◦B, x) = F(A, F(B, x) −1)
In particular, for all n ≥1 we have that fn(A ⊎B) and fn(A ◦B) are ﬁnite,
and therefore A ⊎B and A ◦B is ﬁnite or ω-categorical.
We would like to remark that the automorphism group of A ◦B is also known
as the wreath product of the automorphism group of B with the automorphism
group of A.
4
Better Templates: Model-Complete Cores
It might be that the same CSP can be formulated with diﬀerent ω-categorical
templates. For example, if T3 is the transitive tournament on three vertices,
then CSP(Q, <) and CSP(T3 ◦(Q, <)) (for the deﬁnition of the operation ◦, see
Subsection 3.2) are the same computational problem, namely graph acyclicity.
For ﬁnite and for ω-categorical templates we have a very elegant characteri-
zation of those pairs of templates that have the same CSP. Call two structures
Γ and ∆homomorphically equivalent if there is a homomorphism from Γ to ∆
and a homomorphism from ∆to Γ (this is in fact an equivalence relation). The
following is an easy consequence of Lemma 2.
Lemma 5. Let Γ, ∆be ﬁnite or ω-categorical. Then CSP(Γ) equals CSP(∆) if
and only if Γ and ∆are homomorphically equivalent.
Lemma 5 is false for general relational structures. Consider for example the
structure (Z, {(x, y) | y = x + 1}) — the ‘inﬁnite line’, and the structure
(N, {(x, y) | y = x + 1}) — the ‘inﬁnite ray’. Clearly, these two structures give
rise to the same CSP, but there is no homomorphism from the line to the ray.
It turns out that every equivalence class of ﬁnite or ω-categorical templates
(with respect to homomorphic equivalence) has a member with very good prop-
erties for the universal-algebraic approach. Moreover, this member is unique up
to isomorphism.

Constraint Satisfaction Problems with Inﬁnite Templates
205
Deﬁnition 6. An ω-categorical structure Γ is called model-complete if every
embedding of Γ into Γ is elementary, i.e., preserves all ﬁrst-order deﬁnable
relations. An ω-categorical structure is called a core if every endomorphism is
an embedding.
The structure (Q, <), for example, is easily seen to be a model-complete core,
in contrast to T3 ◦(Q, <), which is not a core.
Note that for every ﬁnite structure Γ every embedding of Γ into Γ is elemen-
tary (because it must be an automorphism of Γ).
Theorem 3 (of [7]). Every ω-categorical relational structure Γ is homomorphi-
cally equivalent to a model-complete core ∆, which is unique up to isomorphism,
and ω-categorical or ﬁnite. For all k ≥1, the orbits of k-tuples in ∆are primitive
positive deﬁnable.
Hence, if we want to classify the complexity of CSP(Γ) for an ω-categorical
structure Γ, we can without loss of generality assume that Γ is a core. We
state an important consequence of Theorem 3, which is well-known (and also
non-trivial) for ﬁnite templates. The consequence will be used in Theorem 10.
Corollary 1 (of [7]). Let Γ be an ω-categorical model-complete core, and let
∆be the expansion of Γ by ﬁnitely many singleton relations, i.e., relations of
the form {a} for a ∈D(Γ). Then CSP(Γ) and CSP(∆) are polynomial-time
equivalent.
5
Examples
Most of the examples of CSPs that we present in this Section can be solved in
polynomial-time, and we come back to most of these problems in Section 10 when
discussing tractability criteria for CSPs. Coming up with NP-hard CSPs is much
easier: each CSP in this section becomes NP-hard if we expand the template by
the relation {(x, y, z) | x = y ∨y = z}. More on NP-hardness criteria of CSPs
follows in later sections, culminating in Section 9.
5.1
Temporal Reasoning
Temporal reasoning is an important sub-discipline in Artiﬁcial Intelligence. One
of the most basic temporal reasoning problems is the constraint satisfaction
problem of the so-called point algebra. Here, the variables denote time points,
and the constraints are of the form x = y, x < y, x ≤y, and x ̸= y. In this
CSP, it does not matter whether we use as the domain the natural, the rational,
or the real numbers. The problem can e.g. be formalized as CSP(Q, =, <, ≤, ̸=),
and can be solved in linear time in the size of the input instances.
If we do not restrict our attention to binary constraints, it is natural to study
expansions of the point-algebra by higher-ary relations with a ﬁrst-order deﬁni-
tion in (Q, <). For instance, consider the relation

206
M. Bodirsky
Rmin = {(x, y, z) | x > y ∨x > z} .
The relation Rmin(x, y, z) speciﬁes that x is larger than the minimum of y and
z. The constraint satisfaction problem CSP(Q, Rmin) will be discussed in Sec-
tion 10.
Another famous temporal reasoning problem is the CSP for Allen’s Interval
Algebra. It is easiest to describe the template for this CSP by an interpreta-
tion in (Q, <). The dimension of this interpretation is two, and the domain
formula δ(x, y) is x < y. Hence, the variables of the CSP denote non-empty
time intervals. The template contains for each inequivalent {<}-formula with
four variables φ a binary relation R such that (a1, a2, a3, a4) satisﬁes φ if and
only if ((a1, a2), (a3, a4)) ∈R. In particular, we have relations for containment
of intervals, disjointness of intervals, and so forth. By Lemma 3, this template is
ω-categorical. Its CSP is NP-complete [5]. The computational complexity of the
CSP for all fragments of Allen’s inteval algebra has been determined in [55,49].
5.2
Spatial Reasoning
One of the most fundamental spatial reasoning formalisms is the RCC-5 calculus
(also known as the containment algebra in the theory of relation algebras [31]). In
this formalism, the variables denote non-empty regions, and the basic relations
in the calculus express containment of regions, disjointness of regions, etc; formal
deﬁnitions will be provided below. The constraint satisfaction problem for RCC-
5 is NP-complete; the computational complexity of its fragments was classiﬁed
in [58,44].
To formulate the CSPs for RCC-5 and its fragments with ω-categorical tem-
plates, let B be the countable atomless boolean ring without an identity element.
That is, B is an algebra with an operation + for addition and an operation ·
for multiplication satisfying the usual axioms for rings. A ring is boolean if it
satisﬁes x · x = x for all elements x. A ring is without (multiplicative) identity
element if there is no element x1 such that x1 · y = y for all elements y. A ring
without identity element is atomless if the partial order ≤deﬁned by x ≤y if
x·y = x does not have minimal elements. Every countable atomless boolean ring
without an identity element is unique up to isomorphism [1], homogeneous (this
can be shown by Theorem 2), and hence ω-categorical. We can interpret the
elements of this boolean ring as non-empty sets (regions), where x + y denotes
the symmetric diﬀerence, and x · y the intersection of x and y.
Now, consider the relational structure that has the same domain B as the
boolean ring B, and that contains all binary relations with a ﬁrst-order deﬁnition
in B. This is exactly the template for the constraint satisfaction problem for
RCC-5 (several equivalent deﬁnitions can be found in the literature). Ordered
by inclusion, there are ﬁve minimal non-empty binary relations with a ﬁrst-order
deﬁnition in B, and they are known as the basic relations of RCC-5. Traditionally,
these relations are denoted by DR,PO,PP,PPI,EQ, and they have the following
ﬁrst-order deﬁnitions in B (with their intuitive meaning in braces).

Constraint Satisfaction Problems with Inﬁnite Templates
207
DR(x, y) iﬀ(x + y)x = x
‘x and y are disjoint’
PP(x, y) iﬀxy = x ∧x ̸= y
‘y properly contains x’
PPI(x, y) iﬀxy = y ∧x ̸= y
‘x properly contains y’
EQ(x, y) iﬀx = y
‘x equals y’
PO(x, y) iﬀ¬(DR(x, y) ∨PP(x, y) ∨PPI(x, y) ∨EQ(x, y))
‘x and y properly overlap’
It is known that CSP(B, DR, PP, PPI, EQ, PO) is in P [58]. A larger tractable
fragment of RCC-5 is discussed in Section 10.
5.3
Vector Space CSPs
Next, we discuss a natural algebraic constraint satisfaction problem.
Vector Space CSP
INSTANCE: A set of equalities of the form x + y = z and disequalities of the
form x + y ̸= z over a set of variables V .
QUESTION: Can we assign d-dimensional boolean vectors to the variables such
that all the equalities and disequalities are satisﬁed, for some d?
It is easy to observe that if there exists a solution, then there is a solution
where d = |V |. However, note that |V | grows with the input size, and it is easy
to see that this problem cannot be formulated with a ﬁnite template.
The vector space CSP has a natural formulation as a CSP with an ω-categorical
template. Let V be the inﬁnite-dimensional vector space over the 2-element ﬁeld
F2. Inﬁnite-dimensional vector spaces over ﬁnite ﬁelds are known to be homoge-
neous and ω-categorical [33], and they play an important role in the classiﬁcation
of so-called strictly minimal sets in ω-categorical structures [61,26,27]. They are
also examples of totally categorical structures, i.e., structures with a ﬁrst-order
theory that has one model of every inﬁnite cardinality, up to isomorphism.
The signature of V is operational, with function symbols for + and a unary
function for scalar multiplication for each element of the ﬁeld. Then the template
V of the above CSP is the relational structure with the same domain as V,
and with the ternary relation {(x, y, z) | x + y = z} and the ternary relation
{(x, y, z) | x + y ̸= z}. Since V clearly has a ﬁrst-order deﬁnition in V, it is
ω-categorical as well. It is not hard to see that V is a model-complete core. An
polynomial time algorithm for CSP(V ) will be discussed in Section 10.
5.4
Graph Coloring Problems
The H -coloring problem in graph theory is the special case of the CSP where
the template H has a single binary relation, and therefore can be viewed as
a digraph (directed graph). If we allow inﬁnite digraphs H , many more graph
coloring problems that have been studied in the literature can be formulated as
H -coloring problems.
The complexity of the following class of inﬁnite H -coloring problems has been
classiﬁed completely by Feder, Hell, and Mohar [34].

208
M. Bodirsky
Acyclic H -coloring
INSTANCE: A ﬁnite digraph G.
QUESTION: Is there a mapping c from G to H such that for every edge xy in G
the digraph H contains the arc c(x)c(y), and such that the pre-image of every
vertex is acyclic?
For every digraph H , we can formulate the acyclic H -coloring problem as
a constraint satisfaction problem with an ω-categorical template. The acyclic
H -coloring problem is CSP(H ◦(Q, <)).
5.5
Phylogenetic Reconstruction
Modern biology holds the view that the species in the evolution of life on earth
developed in a mostly tree-like fashion: at certain time periods, species separated
into sub-species. The goal of phylogenetic reconstruction is to determine the
evolutionary tree from given partial information about the tree. This motivates
the computational problem of rooted triple consistency, deﬁned below. In 1981,
Aho, Sagiv, Szymanski, and Ullman [4] presented a quadratic time algorithm to
this problem, motivated independently from computational biology by questions
in database theory.
We ﬁx some terminology concerning rooted trees. Let T be a tree with a
distinguished vertex r, the root of T. For u, v ∈T , we say that u lies below v
if the path from u to r passes through v. We say that u lies strictly below v if
u lies below v and u ̸= v. The youngest common ancestor (yca) of two vertices
u, v ∈T is the node w such that both u and v liew below w and w has maximal
distance from r.
Rooted-Triple-Consistency
INSTANCE: A ﬁnite relational structure (V, Ryca), where Ryca is a ternary re-
lation.
QUESTION: Is there a rooted tee T with leaves X and a mapping α : V →X
such that for every triple (x, y, z) ∈Ryca the yca of α(x) and α(y) lies strictly
below the yca of α(x) and α(z) in T?
The rooted-triple-consistency problem can be formulated as CSP(Γ) for an
ω-categorical template Γ. To deﬁne Γ, we ﬁrst consider the following structure
∆with domain N →Q, i.e., the set of all functions from the natural numbers
to the rational numbers (hence, ∆is uncountable). For two elements f, g of ∆,
let kf,g be the largest natural number such that f(i) = g(i) for all i < kf,g. The
ternary relation fg|h in ∆holds on elements f, g, h of ∆if they are pairwise
distinct and either kf,g > kf,h or (kf,g = kf,h and f(kf,g) < h(kf,h)). It is
known that the ﬁrst-order theory of ∆is ω-categorical [30]. It follows from the
theorem of L¨owenheim-Skolem (see [42]) that the ﬁrst-order theory of ∆also
has a countable model Γ, and it is straightforward to verify that CSP(Γ) is the
rooted triple consistency problem.

Constraint Satisfaction Problems with Inﬁnite Templates
209
5.6
Reasoning over Branching-Time
Another important model in temporal reasoning is branching time, where for
every time point the past is linearly ordered, but the future is only partially
ordered.
Branching-Time-Consistency
INSTANCE: A ﬁnite relational structure I = (V, ≤, ∥, ̸≡) where ≤, ∥, and ̸≡are
binary relations
QUESTION: Is there a rooted tree T and a mapping α : V →T such that in
T the following is satisﬁed:
a) If x ≤y, then α(x) lies above α(y);
b) If x ∥y, then neither α(x) lies strictly above α(y) nor α(y) lies strictly above
α(x);
c) If x ̸≡y, then α(x) ̸= α(y).
This problem can be formulated as CSP(Γ) for an ω-categorical structure
(D, ≤, ∥, ̸≡), which has been studied intensively in the theory of inﬁnite permu-
tation groups [30, 25]. The reduct (D, ≤) is a partial order with the property
mentioned above: for all x ∈D, the set {y | y ≤x} is linearly ordered.
The ﬁrst polynomial-time algorithm for this problem is due to Hirsch [41], and
has a worst-case running time in O(n5). This was later improved by Broxvall and
Jonsson [19], who presented an algorithm running in O(n3.376) (this algorithm
uses an O(n2.376) algorithm for fast integer matrix multiplication). A simpler
algorithm which does not use fast matrix multiplication and runs in O(nm) can
be found in [15]. It is an easy exercise to eﬃciently reduce the rooted-triple-
consisteny problem to the branching-time-consistency problem.
5.7
CSPs without an ω-Categorical Template
Of course, there are constraint satisfaction problems that can not be formulated
with an ω-categorical template. Since it might not be obvious whether a CSP
has this property, we demonstrate with a simple example how one can show that
a CSP can not be formulated with an ω-categorical template.
Consider the CSP for the relational structure Γ with domain Q and the three
relations {(x, y, z) | x + y = z}, ̸=, {0}, and {1}. To specify constraints for
instances of CSP(Γ) we write x + y = z, x = 0, and x = 1, to keep expressions
simple.
Proposition 1. CSP(Γ) cannot be formulated as CSP(Γ ′) for an ω-categorical
template Γ ′.
Proof. Suppose for contradiction that there is such an ω-categorical template
∆. We construct an inﬁnite sequence p0, p1, p2 . . . of elements from pairwise
distinct orbits of the automorphism group of ∆, which will be a contradiction
by Theorem 1. Let z0 and z1 be elements in ∆such that z0 = 0 and z1 = 1 hold
in ∆. Note that if there was an element z′
0 distinct from z0 such that z′
0 = 0 holds

210
M. Bodirsky
in ∆, then x = 0 ∧x ̸= y ∧y = 0 would be a satisﬁable instance of CSP(∆),
but unsatisﬁable in CSP(Γ), which is impossible by assumption. Hence, z0 is
uniquely deﬁned. Let p0 be z0. Assume inductively that pn is deﬁned uniquely
in Γ by a primitive positive formula φ(x). Consider the following instance of
CSP(Γ), which is speciﬁed by the primitive positive formula ψ:
φ(s) ∧(s + x = y) ∧(y + x = l) ∧l = 1 .
Clearly, if we set s to pn, x to (1 −pn)/2, and y to (1 + pn)/2, all conjuncts of
ψ are satisﬁed in Γ. By assumption, ψ is also satisﬁable over ∆, i.e., there is an
assignment h : {s, x, y, l} →D(∆) to the free variables that satisﬁes all conjuncts
in ψ. Let pn+1 be h(y). We claim that pn+1 is uniquely determined: if there was
solution with another value for y, then ψ(s, x, y, l) ∧ψ(s, x′, y′, l) ∧x′ ̸= x would
be satisﬁable over ∆, but not over Γ, a contradiction. We also claim that pn+1 lies
in an orbit that is distinct from the orbits of p1, . . . , pn, respectively: otherwise,
if there was an automorphism α of Γ that maps pi to pn+1, for some i ≤n, then
pn+1 would not have been unique, since α(h) is an assignment that also satisﬁes
all conjuncts but assigns a diﬀerent value to y.
⊓⊔
6
CSPs and Existential Second-Order Logic
One of the motivating questions in the landmark paper of Feder and Vardi [35]
is
Question 1. Which natural subclasses of NP do exhibit a complexity dichotomy,
i.e., only contain problems that are either NP-complete or in P?
Whether the class FCSP of ﬁnite domain constraint satisfaction problems has
such a complexity dichotomy is one of the greatest open problems in constraint
satisfaction theory.
Feder and Vardi approached Question 1 from two sides. One the one hand,
they conjectured that the class FCSP exhibits a dichotomy and made important
contributions to this end. On the other hand, they investigated larger classes of
computational problems that provably do not exhibit a complexity dichotomy.
These larger classes are deﬁned with syntactic restrictions of existential second
order logic (ESO).
By Fagin’s famous theorem, a set C of ﬁnite τ-structures is in NP if and only
if there is a sentence Φ in existential second-order logic such that Φ is true on
a τ-structure A if and only if A is in C. An important syntactic restriction of
existential second-order logic is SNP (for strict NP): here we require that the
sentence is of the form
∃R1, . . . , Rk.∀x1, . . . , xl. ψ
where R1, . . . , Rk are (existentially quantiﬁed) relation symbols, x1, . . . , xl are
(universally quantiﬁed) ﬁrst-order variables, and ψ is a quantiﬁer-free formula.
Furthermore, we say that an SNP-formula is monadic if all second-order variables
are unary. Let MSNP be the class of all problems that can be described by a
monadic SNP sentence.

Constraint Satisfaction Problems with Inﬁnite Templates
211
Theorem 4 (of [35]). Every problem in NP has a polynomial-time equivalent
problem in MSNP.
Theorem 4 shows that there is no complexity dichotomy for all problems in
MSNP, because if P ̸= NP there are problems in NP that are neither in P nor
NP-complete [52].
However, Feder and Vardi also showed that if we restrict our attention to (in-
ﬁnite domain) constraint satisfaction problems in MSNP, we obtain a class that
is ‘computationally equivalent’ to FCSP. Let CSP be the class of all constraint
satisfaction problems (with domains of arbitrary cardinality).
Theorem 5 (of [35], [50]). Every problem in CSP ∩MSNP is polynomial-time
equivalent to an FCSP (and FCSP is contained in CSP ∩MSNP).
Hence, a complexity dichotomy for FCSP is equivalent to a complexity dichotomy
for CSP ∩MSNP. The dichotomy conjecture for FCSP is wide open, and not
undisputed. Instead of disproving the dichotomy conjecture for FCSP, it might
be easier to disprove it for CSPs in SNP that can be formulated with an ω-
categorical template.
Question 2. Is every problem in NP polynomial-time equivalent to a CSP with
an ω-categorical template?
The logic of SNP and MSNP are natural logics in the context of constraint
satisfaction with ω-categorical templates, as witnessed by the following theorem.
Theorem 6 (of [11]). Every CSP in MSNP can be formulated as CSP(Γ) for
an ω-categorical structure Γ.
So far, we have not touched the question how inﬁnite templates Γ might be
ﬁnitely represented. For the deﬁnition of CSP(Γ) we don’t have to ﬁx a repre-
sentation. But for several algorithmic “meta-questions” concerning CSP(Γ) such
a representation is necessary.
Most natural CSPs with ω-categorical templates are in SNP. Thus, SNP sen-
tences can be used to specify constraint satisfaction problems for ω-categorical
templates (up to homomorphic equivalence, see Lemma 5). However, the follow-
ing questions remain open.
Question 3. Is every CSP in SNP a CSP over an ω-categorical template?
7
Preservation Theorems
Primitive positive deﬁnability plays an important role in hardness proofs for the
CSP. In this section, we discuss a model-theoretic preservation theorem that
characterizes primitive positive deﬁnability. We then use this result to estab-
lish that the computational complexity of a CSP with a ﬁnite or ω-categorical
template is fully described by an algebra that can be associated to a template.

212
M. Bodirsky
Let A and B be two structures with the same signature τ. Then the (direct)
product C = A × B of A and B is the τ-structure with domain A × B, and
for each k-ary R ∈τ the structure C has the relation that contains a tuple
((a1, b1), . . . , (ak, bk)) if and only if R(a1, . . . , ak) holds in A and R(b1, . . . , bk)
holds in B. For each k-ary f ∈τ the structure C has the operation that maps
((a1, b1), . . . , (ak, bk)) to (f(a1, . . . , ak), f(b1, . . . , bk)). We write Ak for A×Ak−1
if k > 1, and A1 for A.
Deﬁnition 7. Let A be a structure. Then f : Ak →A is called a polymorphism
of A if f is a homomorphism from Ak to A.
If R is a relation over D, and f is a polymorphism of (D, R), we also say that
f preserves R. A relation R has a primitive positive deﬁnition in a ﬁnite struc-
ture if and only if R is preserved by all polymorphisms of this structure. This
was discovered by Geiger [38] and by Bodnarcuk et al. [18], and is of central
importance in universal algebra.
The following generalization of this theorem to ω-categorical structures was
shown in [17]. We give a new proof here, which derives the theorem from the well-
known homomorphism preservation theorem in model-theory. The proof given
in [17] is neither long nor very complicated; however, we believe that the proof
given below is also interesting, because it demonstrates how universal-algebraic
preservation theorems can be derived from classical preservation theorems in
model theory.
Theorem 7 (of [17]). Let A be an ω-categorical or a ﬁnite structure. A relation
R has a primitive-positive deﬁnition in A if and only if R is preserved by all
polymorphisms of A.
The corresponding preservation theorem in model theory is as follows (even
though we have not been able to ﬁnd a reference for this fact, it should be consid-
ered to be known). We say that a ﬁrst-order formula φ is equivalent to ψ modulo
a ﬁrst-order theory T if ∀x.φ(x) ↔ψ(x) holds in all models of T . We also say that
φ(x1, . . . , xl) is preserved by a homomorphism f from a direct product of mod-
els Γ1, . . . , Γk of T to a model Γ of T if whenever φ holds on l-tuples a1, . . . , al
in Γ1, . . . , Γk, respectively, then φ also holds on f((a1
1, . . . , a1
l ), . . . , (ak
1, . . . , ak
l ))
in Γ.
Theorem 8.
Let T be a ﬁrst-order theory. A ﬁrst-order formula φ is equivalent
to a primitive positive formula modulo T if and only if φ is preserved by all
homomorphisms from ﬁnite direct products of models of T to models of T .
The theorem can be shown by a slight modiﬁcation of the proofs in [46]. This
approach relies on several concepts and basic results in model-theory, and is out
of the scope of this paper. We recommend Hodges’ book [42] as an accessible
introduction to model-theoretic preservation theorems.
Proof (of Theorem 7). First, observe that every relation R with a primitive posi-
tive deﬁnition in Γ is preserved by all polymorphisms of Γ. This can be shown in

Constraint Satisfaction Problems with Inﬁnite Templates
213
a straightforward way by induction on the syntactic structure of primitive posi-
tive deﬁnitions. To prove the converse, let R be a k-ary relation that is preserved
by all polymorphisms of Γ. In particular, R is preserved by all automorphisms
of Γ, and Theorem 1 implies that R has a ﬁrst-order deﬁnition φ in Γ.
Let T be the ﬁrst-order theory of Γ. We claim that if R is preserved by all
polymorphisms of Γ then φ is preserved by all homomorphisms from ﬁnite direct
products of models Γ1, . . . , Γl of T to a model Γ0 of T . If we have shown the
claim, Theorem 7 follows directly from Theorem 8.
So assume to the contrary that φ is not preserved by a homomorphism f from
a ﬁnite direct product of models Γ1, . . . , Γl of T to a model Γ0 of T (note that
Γ1, . . . , Γl, and Γ0 might be uncountable). We prove by a standard application of
the downward L¨owenheim-Skolem theorem (see e.g. [42]) that φ is not preserved
by some l-ary polymorphism of Γ, as follows. Let ∆be the disjoint union of
Γ0, Γ1, . . . , Γl. Additionally, ∆has a relation S∆that denotes the union of the
relations deﬁned by φ in Γ0, Γ1, . . . , Γl, and has unary relations P ∆
0 , P ∆
1 , . . . , P ∆
l ,
where P ∆
i
denotes the elements from Γi, for 1 ≤i ≤l. Finally, ∆has an l-
ary function g∆, which is interpreted as follows. If v1, . . . , vl are elements from
∆, where vi is from Γi for 1 ≤i ≤l, then g∆(v1, . . . , vl) is the value of the
homomorphism f from Γ1 × · · · × Γl to Γ0. Because φ is not preserved by f,
there are k-tuples t1, . . . , tl from S∆such that (f(t1), . . . , f(tl)) is not in S∆.
For all other l-tuples from ∆, the interpretation of g∆is set arbitrarily to some
ﬁxed element from ∆. By downward L¨owenheim-Skolem, the ﬁrst-order theory
of ∆has a countable model ∆′. Note that P ∆′
i
denotes a countable, but still
necessarily an inﬁnite set. It is also easy to see that the structures Γ ′
1, . . . , Γ ′
k
induced by the sets P ∆′
1 , . . . , P ∆′
k
in ∆′ have the same ﬁrst-order theory as Γ,
and by ω-categoricity of Γ are isomorphic to Γ. The function g∆′ maps tuples
v1, . . . , vk where vi ∈Γ ′
i for 1 ≤i ≤k to Γ ′
0, and still the restriction of g∆′
to those tuples violates the relation S∆′. Hence, the restriction of g∆′ to these
tuples gives rise to a polymorphism of Γ that violates φ.
⊓⊔
8
The Algebra of a Template
In this section we discuss how the algebraic approach to constraint satisfaction
might be extended to ω-categorical templates Γ. We have already seen in the
previous section that the polymorphisms of Γ characterize primitive positive
deﬁnability of relations in Γ. Therefore, the algebra deﬁned on the domain D
of Γ that contains as operations all the polymorphisms of Γ fully describes the
computational complexity of CSP(Γ). The algebra that we just deﬁned for an
ω-categorical template Γ will be denoted by AΓ .
AΓ has several important properties. First of all, its set of operations forms a
clone, i.e., is closed under compositions and contains the projections [59]. Clones
with inﬁnite domains are a subject in its own right [39]. Clones that arise as the
set of polymorphisms of a structure are always locally closed, a concept which
only becomes relevant for inﬁnite domains. We need a couple of deﬁnitions.

214
M. Bodirsky
Let D be an inﬁnite set, and let O(k) be the set of operations from Dk to D,
for k ≥1. The symbol O denotes ∞
k=1 O(k). We say that an operation f ∈O(k)
is interpolated by a set F ⊆O if for every ﬁnite subset A of D there is some
operation g ∈F such that f(t) = g(t) for every t ∈Ak. The set of all operations
that are interpolated by F is denoted by I(F). A clone is called a local clone
(or locally closed) if I(F) = F. The smallest clone that contains F is the clone
generated by F, and denoted by G(F). The smallest local clone that contains F
is called the clone locally generated by F, and denoted by L(F).
Proposition 2 (see e.g. [59]). For all F ⊆O we have that L(F) = I(G(F)).
We say that an algebra A is called oligomorphic if the unary bijective oper-
ations (i.e., the permutations) in A form an oligomorphic permutation group.
Theorem 1 asserts that AΓ is oligomorphic if Γ is ω-categorical. Conversely, it
is not hard to see that for every oligomorphic algebra A whose operations form
a local clone there is an ω-categorical structure Γ such that A = AΓ . Such an
ω-categorical structure Γ can be obtained by equipping the domain of A with
all relations that are preserved by all operations in A; we call this structure the
canonical structure for A.
An operation of an oligomorphic clone is called elementary if it is locally
generated by its permutations. Clearly, for clones with a ﬁnite domain, the el-
ementary operations are the operations that are composed of a projection with
a permutation. Note that all endomorphisms of a model-complete ω-categorical
core are elementary. Conversely, if all endomorphisms of an oligomorphic algebra
A are elementary, then the canonical structure for A is a core [8].
We now deﬁne several other important properties of k-ary operations. A k-ary
operation f is
– idempotent iﬀf(x, . . . , x) = x;
– essentially unary iﬀthere is a unary operation g such that f(x1, . . . , xk) =
g(xi) for some i ∈{1, . . . , k};
– essential iﬀf is not essentially unary;
– commutative iﬀf is binary and f(x, y) = f(y, x);
– a quasi near-unanimity operation (short, qnu-operation) iﬀf(x, . . . , x) =
f(x, . . . , x, y) = · · · = f(x, . . . , x, y, x, . . . , x) = · · · = f(y, x, . . . , x);
– a quasi Maltsev operation iﬀk = 3 and f(x, y, y) = f(y, y, x) = f(x, x, x);
An idempotent quasi near-unanimity and quasi Maltsev operation is known as
near-unanimity and Maltsev operation, respectively.
9
The Pseudo-variety of a Template
A class V of algebras with the same signature τ is called a pseudo-variety if V
contains all homomorphic images (Section 2), subalgebras (i.e., substructures as
deﬁned in Section 3), and ﬁnite direct products (Section 7) of algebras in V. The
diﬀerence between pseudo-varieties and varieties is that pseudo-varieties need
not be closed under direct products of arbitrary cardinality (which we did not

Constraint Satisfaction Problems with Inﬁnite Templates
215
deﬁne here). The smallest pseudo-variety that contains an algebra A is called
the pseudo-variety generated by A.
The results in this section link the universal-algebraic concept of pseudo-
varieties with the model-theoretic concept of primitive positive interpretations.
We already mentioned that ﬁrst-order interpretations are a convenient tool to
construct ω-categorical structures from simpler ω-categorical structures. Primi-
tive positive interpretations (see Section 3) can be used to study the computa-
tional complexity of constraint satisfaction problems.
Proposition 3. Let ∆and Γ be a structures with ﬁnite relational signatures. If
there is a primitive positive interpretation of ∆in Γ, then there is a polynomial-
time reduction from CSP(∆) to CSP(Γ).
Proof. Let d be the dimension of the primitive positive interpretation of the
τ-structure ∆in the σ-structure Γ, let δ(x1, . . . , xd) be the domain formula,
let h : δ(Γ d) →D(∆) be the coordinate map, and let φR(x1, . . . , xdk) be the
formula for the k-ary relation R from ∆.
Let A be an instance of CSP(∆), and let A = {a1, . . . , an} be the elements of
A. We construct an instance B of CSP(Γ) as follows. The domain B of B con-
sists of dn vertices b1
1, . . . , bd
n. For all 1 ≤i ≤n, we impose δ in B on (b1
i , . . . , bd
i ):
note that δ is a primitive positive σ-formula, and therefore can be simulated by
a conjunction of constraints from τ, possibly with adding new vertices for the
existentially quantiﬁed variables in the deﬁnition. If a tuple (ai1, . . . , aik) is con-
tained in a k-ary relation R in A, then we impose φR(b1
i1, . . . , bd
i1, . . . , b1
ik, . . . , bd
ik)
in B. Clearly, the structure B is an instance of CSP(Γ) and can be constructed
in polynomial time in the size of A.
We claim that there is a homomorphism from A to ∆if and only if there is a
homomorphism from B to Γ. Suppose f : B →D(Γ) is a homomorphism from B
to Γ. By construction, if R(ai1, . . . , aik) holds in A then φR((f(b1
i1), . . . , f(bd
i1)),
. . . , (f(b1
i1), . . . , f(bd
i1))) holds in Γ. By the deﬁnition of interpretations, this is
the case if and only if R(h(f(b1
i1), . . . , f(bd
i1)), . . . , h(f(b1
ik), . . . , f(bd
ik))) holds
in ∆. Hence, the mapping g : A →D(∆) that maps ai to h(f(b1
i ), . . . , f(bd
i )) is
a homomorphism from A to ∆.
Now, suppose that f is a homomorphism from A to ∆. Since h is a sur-
jective mapping from δ(Γ)d to ∆, there are elements e1
i , . . . , ed
i in Γ such that
h(e1
i , . . . , ed
i ) = f(ai), for all i ∈{1, . . . , n}. We claim that the mapping g : B →
D(Γ) that maps bj
i to ej
i is a homomorphism from B to Γ. By construction,
any constraint in B comes from a primitive positive formula φR(b1
i1, . . . , bd
i1, . . . ,
b1
ik, . . . , bd
ik) that was introduced for a constraint R(ai1, . . . , aik) in A. It there-
fore suﬃces to show that φR(g(b1
i1), . . . , g(bd
i1), . . . , g(b1
ik), . . . , g(bd
ik)) holds in
Γ. Since f is a homomorphism from A to ∆, R(f(ai1), . . . , f(aik)) holds in ∆.
By the choice of e1
1, . . . , ed
n, this shows that R(h(e1
i1, . . . , ed
i1), . . . , h(e1
ik, . . . , ed
ik))
holds in Γ. By the deﬁnition of interpretations, this is the case if and only if
φR(e1
i1, . . . , ed
1, . . . , e1
ik, . . . , ed
ik) holds in Γ, which is what we had to show.
⊓⊔

216
M. Bodirsky
Section 11 contains a hardness proof that uses this proposition. We now present
the mentioned connection between primitive positive interpretations and pseudo-
varieties. We have not been able to ﬁnd the following theorem explicitely in the
literature even in the case of ﬁnite algebras, and therefore present its proof in
full detail.
Theorem 9. Let Γ be a ﬁnite or ω-categorical relational structure. Then a
structure ∆has a primitive positive interpretation in Γ if and only if there
is an algebra B in the pseudo-variety generated by AΓ such that all operations
of B are polymorphisms of ∆.
Proof. Let V be the pseudo-variety generated by AΓ . Similarly to the famous
HSP theorem for varieties, every algebra in V is the homomorphic image of a
subalgebra of a ﬁnite direct product of AΓ (we can use the same proof as for the
HSP theorem given in [24]).
First assume that there is an algebra B in V all of whose operations are
polymorphisms of ∆. Then there exists a ﬁnite number d ≥1, a subalgebra C
of (AΓ )d, and a surjective homomorphism h from C to B.
We claim that ∆has a ﬁrst-order interpretation with dimension d in Γ. All
operations of AΓ preserve C (viewed as a d-ary relation over D(Γ)), since C
is a subalgebra of (AΓ )d. By Theorem 7, this implies that C has a primitive
positive deﬁnition δ(x1, . . . , xd) in Γ, which becomes the domain formula of our
interpretation. As coordinate map we choose the mapping h.
If R is a k-ary relation in ∆, let R′ the dk-ary relation over D(Γ) that con-
tains the dk-tuple (a1
1, . . . , ad
1, . . . , a1
k, . . . , ad
k) whenever R contains the tuple
(h(a1
1, . . . , ad
1), . . . , h(a1
k, . . . , ad
k)). Let f be any operation in AΓ . By assump-
tion, the corresponding operation f in B preserves R. It is easy to verify that
then the operation f in AΓ preserves R′. Hence, all polymorphisms of Γ pre-
serve R′, and because Γ is ω-categorical, the relation R′ has a primitive positive
deﬁnition φR in Γ. The formula φR becomes the deﬁning formula for R in the
interpretation of ∆in Γ.
Finally, since h is an algebra homomorphismus, the kernel2 K of h is a congru-
ence3 of C. In other words, if ((a1
1, . . . , ad
2), (a1
2, . . . , ad
2)) ∈K then (f(a1
1, . . . , ad
2),
f(a1
2, . . . , ad
2)) ∈K for all operations f from C, and hence ((f(a1
1), . . . , f(ad
2)),
(f(a1
2), . . . , f(ad
2))) ∈K for all operations f from AΓ . It follows that K, viewed
as a 2d-ary relation over D(Γ), is preserved by all operations from AΓ . The-
orem 7 implies that K has a primitive positive deﬁntion in Γ. This deﬁnition
becomes the formula φ= in the interpretation of ∆in Γ. It is straightforward to
verify that we have found a primitive positive interpretation of ∆in Γ.
To prove the opposite direction, suppose that ∆has a primitive positive in-
terpretation in an ω-categorical τ-structure Γ. We have to show that V contains
2 The kernel of a map f : A →B is the equivalence relation on A that contains all
pairs (x, y) such that f(x) = f(y).
3 A congruence of an algebra A is an equivalence relation that is preserved by all
operations in A; equivalently, a congruence is the kernel of a homomorphic image
of A.

Constraint Satisfaction Problems with Inﬁnite Templates
217
an algebra B such that all operations in B are polymorphisms of ∆. Let d be the
dimension and δ be the domain formula of the interpretation. Clearly, the set
δ(Γ d) is preserved by all operations in AΓ , and therefore induces a subalgebra
C of (AΓ )d.
We ﬁrst show that the kernel of the coordinate map h of the interpretation
is a congruence ρ of C. For all d-tuples a, b ∈C the 2d-tuple (a, b) satisﬁes φ=
in Γ if and only if h(a) = h(b). Hence, the restriction of φ= to C deﬁnes the
kernel of h. Since φ= is primitive positive deﬁnable in Γ, it is preserved by all
polymorphisms of Γ, and therefore is a congruence of (AΓ )d. By the second
isomorphism theorem in universal algebra [24], the restriction of this congruence
to C is a congruence ρ of C.
Also by basic universal algebra [24] the natural map g that maps an element
c from C to its congruence class c/ρ in the quotient algebra C/ρ is a surjective
homomorphism from C to C/ρ. By the ﬁrst isomorphism theorem, the elements
of B := C/ρ are in bijective correspondence to the elements of ∆, and we assume
without loss of generality that B and ∆have the same domain. We ﬁnally verify
that every operation in B is a polymorphism of ∆: It suﬃces to prove that every
relation R of ∆is preserved by all operations f in B. Let φR be the deﬁning
τ-formula of R in the primitive positive interpretation of ∆in Γ. The operation
f in B preserves R if and only if the operation f in AΓ preserves the relation
deﬁned by φR. Since the operations in AΓ are polymorphisms of Γ, and since φR
is a primitive positive τ-formula, the operation f preserves the relation deﬁned
by φR.
⊓⊔
Theorem 10. Let Γ be ω-categorical. Then CSP(Γ) is NP-hard if there is an
expansion ∆of the model-complete core of Γ by ﬁnitely many singleton rela-
tions such that V(A∆) contains an 2-element algebra where all operations are
projections.
Proof. By Corollary 1 there is a polynomial-time reduction from CSP(∆) to
CSP(Γ). Combining Theorem 9 with Proposition 3, we can show that CSP(∆)
is NP-hard, by reduction from the well-known NP-complete problem positive 1-
in-3-3SAT, which can be formulated as CSP({0, 1}, {(1, 0, 0), (0, 1, 0), (0, 0, 1)}).
⊓⊔
All known ω-categorical templates with an NP-hard CSP satisfy the condition
in Theorem 10. It is therefore natural to ask whether the suﬃcient condition for
hardness given in Theorem 10 is also necessary. For ﬁnite templates, it has been
conjectured that this is true [21].
Question 4. Does Theorem 10 describe exactly the NP-hard CSPs with an ω-
categorical template?
10
Tractable Templates
For ﬁnite templates Γ, all known tractable problems CSP(Γ) can be solved
by a Datalog program [35] or by an algorithm for templates with a Maltsev

218
M. Bodirsky
polymorphism [23, 43] (generalizing group-theoretic algorithms introduced in
[35]), or combinations of those [20].
An ω-categorical model-complete core Γ can not have a Maltsev polymor-
phism, not even a quasi Maltsev polymorphism [25]. This does not imply that
group-theoretic algorithms do not occur for ω-categorical templates, as we will
see in Subsection 10.2.
Datalog continues to play an important role also for ω-categorical templates.
All tractability results known for temporal and spatial reasoning can be formu-
lated with Datalog programs. We will discuss in this section a result showing that
every ω-categorical model-complete core with a quasi near-unanimity operation
can be solved by a Datalog program. In fact, in this case we can use the Datalog
program to compute a globally consistent instance. We also present examples of
templates in temporal and spatial reasoning that have a quasi near-unanimity
polymorphism.
For a large family of CSPs we can show tractability because the template
has a certain binary bijective polymorphism. The powerful tractability criterion
explains several results in the literature on temporal and spatial reasoning and
will be introduced in Subsection 10.2.
We ﬁnally present an ω-categorical template whose CSP can be solved by a
simple linear-time algorithm, but which can neither be solved by Datalog nor by
algebraic algorithms related to Maltsev polymorphisms.
10.1
From Local to Global Consistency
An introduction to Datalog for constraint satisfaction with ﬁnite templates can
be found in [Cite Bulatov,Krokhin,Larose in this book]. Datalog programs can
also be used to solve CSPs with inﬁnite templates in polynomial time: recall that
every Datalog program derives on a given ﬁnite input structure only a polyno-
mially bounded number of facts. Thus, any Datalog program can be evaluated
in polynomial time. An example of a CSP with an inﬁnite template that can be
solved by a (2, 3)-Datalog program is CSP(Q, ̸=, ≤) [60].
Datalog is particularly useful when the template is ω-categorical, since in this
case there exist canonical Datalog programs, as in the case of ﬁnite templates.
Deﬁnition 8. Let Γ be an ω-categorical structure. The canonical (l, k)-Datalog
program for CSP(Γ) is a Datalog program Π that contains an IDB for every
at most l-ary primitive positive deﬁnable relation in Γ (by ω-categoricity of Γ,
there are only ﬁnitely many such relations). The empty 0-ary relation will be
denoted by false. The EDBs are precisely the relation symbols in τ. The program
Π contains a rule ψ :- ψ1, . . . , ψj if the implication ψ1 ∧· · · ∧ψj ⇒ψ contains
at most k variables, is valid in Γ, and ψ is of the form R(y1, . . . , ys) for an IDB
R and s ≤l.
The ﬁnal stage in the evaluation of a canonical Datalog program on a given
instance gives rise to another instance A of CSP(Γ ′), where Γ ′ is the expansion
of Γ by all at most l-ary primitive positive deﬁnable relations, and where A
contains all the derived tuples from these relations [32].

Constraint Satisfaction Problems with Inﬁnite Templates
219
Proposition 4 (of [11]). A constraint satisfaction problem CSP(Γ) with an
ω-categorical template Γ can be solved with an (l, k)-Datalog program if and only
if the canonical (l, k)-Datalog program solves CSP(Γ).
Global consistency. Some templates Γ have the strong property that the in-
stance computed by the canonical Datalog program is always globally consistent,
see Deﬁnition 9 below.
Deﬁnition 9.
Let Γ be a structure with ﬁnite relational signature. An instance
A of CSP(Γ) is called strongly k-consistent if for every subset S = {v1, . . . , vl}
of A with l ≤k and every homomorphism h from A[{v1, . . . , vl−1}] to Γ there
exists an extension of h that is a homomorphism from A[S] to Γ. An instance A
of CSP(Γ) is called globally consistent if it is k-consistent for all 1 ≤k ≤|A|.
Note that if Γ has the property that every strongly k-consistent instance of
CSP(Γ) is globally consistent, then CSP(Γ) can be solved in polynomial time. As
an example, consider again CSP(Q, ≤, ̸=). It is known that the canonical (4, 5)-
Datalog program computes globally consistent instances, but the canonical (3, 4)-
Datalog program does not [48]. We will see a universal-algebraic explanation of
this fact in the next paragraph.
Quasi near-unanimity functions. We present a universal-algebraic characteri-
zation of those ω-categorical model-complete cores where the canonical (l, k)-
Datalog program computes globally consistent instances. Recall the deﬁnition
of (quasi) near-unanimity functions given in Section 8. As an example of a
near-unanimity function, consider the structure (Q, ≤, <), and the operation
median, which is the ternary function that returns the median of its three argu-
ments. More precisely, for three elements x, y, z from Q, suppose that {x, y, z} =
{a, b, c}, where a ≤b ≤c. Then median(x, y, z) is deﬁned to have value b. It is
easy to verify that median is a ternary near-unanimity function, and that it is a
polymorphism of (Q, ≤, <).
The structure (N, ̸=) is an example of a structure that has no near-unanimity
polymorphism (exercise!), but has a ternary quasi near-unanimity operation, de-
ﬁned as follows. Consider the structure (N, ̸=)3, where for all x, y ∈N the triples
of the form (y, x, x), (x, y, x), (x, x, y), and (x, x, x) are identiﬁed. The resulting
structure homomorphically maps to (N, ̸=) (Lemma 2), and this homomorphism
is a ternary polymorphism of (N, ̸=) and a quasi near-unanimity operation.
Similarly, we can construct a 5-ary quasi near-unanimity polymorphism of
(N, R) where R = {(x, y, u, v) | x ̸= y ∨u ̸= v}). To see that this structure
has no 4-ary quasi near-unanimity, consider the tuples t1 = (1, 0, 0, 0), t2 =
(0, 1, 0, 0), t3 = (0, 0, 1, 0), and t4 = (0, 0, 0, 1). Any 4-ary quasi near-unanimity
operation applied to (t1, t2, t3, t4) yields a tuple (c, c, c, c) for some c ∈N. But
note that t1, . . . , t4 are in R, whereas c is not.
Theorem 11 (of [11]). An ω-categorical model-complete core Γ has a k-ary
quasi near-unanimity polymorphism if and only if every strongly k-consistent
instance of CSP(Γ) is globally consistent.

220
M. Bodirsky
Examples. A 5-ary quasi near-unanimity polymorphism of (Q, ≤, ̸=) was de-
scribed in [9]. We give a diﬀerent construction of such a polymorphism here. Let
f : Q10 →Q be an injective operation that preserves ≤. Such an operation ex-
ists; we can simply take any operation such that f(x1, . . . , x10) < f(y1, . . . , y10)
if and only if (x1, . . . , x10) is lexicographically smaller than (y1, . . . , y10).
Proposition 5. Let h(x, y, z, u, v) be the 5-ary operation
f(median(x, y, z), median(x, y, u), median(y, z, v), ...,
median(y, u, v), median(z, u, v) )
(That is, we apply the median to all of the 10 three-element subsets of {x, y, z,
u, v}.) Then h is a 5-ary quasi near-unanimity polymorphism of (Q, ≤, ̸=).
It can also be shown that the template with the basic relations of the spatial
reasoning formalisms RCC-5 (see Section 5) has a 5-ary quasi near-unanimity
polymorphism [9].
We would like to remark that the concept of quasi near-unanimity opera-
tions is a natural concept also for ﬁnite domain constraint satisfaction problem.
For example, it allows to formulate the well-known dichotomy of CSP(H) for
undirected graphs H as follows: CSP(H) is in P if and only if H has a quasi
near-unanimity operation (unless P=NP). This is easy to derive from the well-
known theorem that CSP(H) is NP-hard if H is not bipartite [40].
10.2
Horn Tractability
In this section we describe a powerful tractability criterion, which in particular
explains many results in temporal and spatial reasoning. But also CSPs with a
group-theoretic algorithm will be treated here.
We say that a relation R has a quantiﬁer-free Horn deﬁnition in a τ-structure
Γ if R can be deﬁned by a quantiﬁer-free τ-formula in conjunctive normal form
in which each clause contains at most one positive literal. If A is a structure,
we denote by ˆA the expansion4 of A that also contains the complement for each
relation in A.
Theorem 12 (of [10]). Let Γ be an ω-categorical homogeneous structure, and
let ∆be a structure with a ﬁrst-order deﬁnition in Γ. If ∆has a polymorphism
i which is a strong homomorphism from Γ 2 to Γ, then ∆has a quantiﬁer-free
Horn deﬁnition in Γ. Moreover, if CSP( ˆΓ ) is tractable, then CSP(∆) is tractable
as well.
Note that if i is bijective (in other words, if i is an isomorphism between Γ 2 and
Γ) then the binary polymorphism of ∆satisﬁes the equation
i(x, y) = a(i(y, x))
4 An expansion of a structure A is a structure that is obtained from A by adding
relations and/or functions to A.

Constraint Satisfaction Problems with Inﬁnite Templates
221
for some automorphism a of ∆[10]. In this case, every expansion of ∆by some
relation with a ﬁrst-order deﬁnition in Γ that is not equivalent to a quantiﬁer-
free Horn formula over Γ has an NP-hard CSP [10]; in this sense, the tractability
result is strongest possible. We illustrate the use of this theorem by examples.
Solving Equations over Inﬁnite Vector Spaces. We come back to the application
on solving systems of equations over boolean vectors, described in Subsection 5.3.
To recall, the template for this CSP had a ﬁrst-order deﬁnition in the inﬁnite-
dimensional vector space V over the 2-element ﬁeld F2. It is well-known that V2,
the direct product of V with itself, is isomorphic to V; similarly, we have that
V 2 (as deﬁned in Subsection 5.3) is isomorphic to V . Let i be the isomorphism.
Note that ˆV = V , since V already contains the complements of all its relations.
It was shown in [10] that CSP(V ) can be solved in polynomial time.
Finally, let ∆be any relational structure where all relations have a ﬁrst-order
deﬁnition in Γ which is a quantiﬁer-free Horn formula. It is straightforward to
verify that such relations are preserved by i. Now we can apply Theorem 12, and
obtain the result that CSP(∆) can be solved in polynomial time as well.
Spatial Reasoning. Theorem 12 can also be applied to study tractable CSPs in
spatial reasoning. The countable atomless boolean ring without identity element
B, as introduced in Subsection 5.2, is isomorphic to B2 (because B2 is again an
atomless boolean ring without identity element, and all such boolean rings are
isomorphic [1]); let i : B2 →B denote this isomorphism. The constraint satis-
faction problem for (B, DR, PP, ¬DR, ¬PP) is in P [58] (in fact, this structure
has a 5-ary qnuf, as shown in [9]). Theorem 12 then implies that CSP(Γ) is in P
if all relations of Γ have a ﬁrst-order deﬁnition in (B, DR, PP) and are preserved
by i. These are precisely the relations that have a ﬁrst-order Horn deﬁnition
in (B, DR, PP). In particular, we obtain a result by Renz and Nebel [58] who
determined a largest tractable fragment of RCC-5. It follows from the result
in [44] that this fragment is the unique largest tractable fragment that contains
the basic relations DR and PP. However, note that Theorem 12 also applies to
relational structures ∆with relations of arbitrary arity.
10.3
Other Tractable Templates
All known tractable problems of the form CSP(Γ) for templates Γ with a ﬁnite
domain can be solved by Datalog, or by an algebraic algorithm, or combinations
and extensions of these approaches. For inﬁnite templates Γ, there are new kinds
of algorithms to solve CSP(Γ) in polynomial time. We present a simple example
of such an algorithm, and give some details here, because the algorithm is a
prototype for several more advanced algorithms [16,4].
In Section 5, we have already mentioned the problem CSP(Q, Rmin), which we
call the min-ordering problem: in this problem we are given a set A of variables,
and a set Rmin of triples on these variables. We want to ﬁnd a mapping α : A →Q
such that for each triple (x, y, z) either α(x) > α(y) or α(x) > α(z). It can be
shown [14] that there is no Datalog program that solves this problem. However,
here is a simple linear-time algorithm for CSP(Q, Rmin).

222
M. Bodirsky
The algorithm we present relies on the fact that Rmin has the binary operation
min as a polymorphism, where min(x, y) is by deﬁnition the minimum of x and
y. The operation min is an example of a semilatttice operation, which is an asso-
ciative, commutative, and idempotent operation. For ﬁnite structures it is known
that if a template Γ has an semilattice polymorphism, then CSP(Γ) is tractable
by a Datalog program. This result does not carry over to ω-categorical templates
(we have already mentioned that (Q, Rmin) has a semilattice polymorphism, but
cannot be solved by a Datalog program).
Let A be an instance of the min-ordering problem that has a solution α. It
will be easy to generalize our algorithm to all templates where all relations have
a ﬁrst-order deﬁnition in (Q, <) and are preserved by min. The algorithm was
found in the course of the classiﬁcation of the complexity of CSP(Γ) for all Γ
with a ﬁrst-order deﬁnition in (Q, <), and is one of the simplest cases in this
classiﬁcation [13,14].
Deﬁnition 10. A set S of variables in an instance A of the min-ordering prob-
lem is called free if the instance has a solution α where α(x) ≤α(y) for all y ∈A
and x ∈S.
If x is from a free set of variables S, then Rmin cannot contain a triple (x, y, z)
where x appears in the ﬁrst entry, because then either α(y) or α(z) are strictly
smaller than α(x), a contradiction. We say that a variable x ∈A is blocked if
Rmin contains a tuple (x, y, z) where x appears in the ﬁrst entry (and unblocked
otherwise).
Lemma 6. If all variables in an instance of the min-ordering problem are blocked,
then the instance is unsatisﬁable.
Proof. Suppose the instance has a solution, then there must exist a free set of
variables. But as we have seen, free variables cannot be blocked.
⊓⊔
It turns out that if an instance of the min-ordering problem is satisﬁable, then
the set of all min-candidates is free. This follows from the correctness of the
following algorithm.
Min-Ordering(A)
Input: A structure (A, Rmin) with a ternary relation Rmin.
If A = ∅then accept
else
Compute the set S of min-candidates;
If S = ∅then reject;
else Min-Ordering(A[A \ S])
end if
Fig. 1. The Min-Ordering algorithm

Constraint Satisfaction Problems with Inﬁnite Templates
223
Proposition 6. The Min-Ordering procedure given in Figure 1 correctly decides
the min-ordering problem in linear time in the input size.
Proof. Let A be an instance of the min-ordering problem. If at some point during
the execution of the Min-Ordering procedure on A we recursively apply the
min-ordering procedure to a substructure B of A and do not ﬁnd an unblocked
variable, then Lemma 6 implies that B and therefore also A does not have a
solution.
Otherwise, it is clear that A has a solution if the set of variables is empty. So,
suppose the algorithm ﬁnds a non-empty set S. Inductively assume that A[A\S]
has a solution α. Then the extension α′ of α that maps all variables in S to a
value smaller than the value of α(y) for all other variables y ∈A \ S is clearly
a solution to A. Hence, the algorithm is correct. It is not diﬃcult to see that it
can be implemented such that it has a linear worst-case running time.
⊓⊔
A similar, but more complicated algorithm based on ﬁnding a free set of variables
can be used to solve the branching-time consistency problem (and therefore also
the rooted triple consistency problem, as we have noticed before) in quadratic
time [16].
11
Classiﬁcation for Equality Constraint Languages
In this section, we show how to use the concepts we have seen so far to describe
a full classiﬁcation for a very restricted, but important class of ω-categorical
templates. We study countably inﬁnite relational structures that are ﬁrst-order
deﬁnable in (N, =). Equivalently, we study relational structures where all rela-
tions have a deﬁnition by a boolean combination of atomic formulas of the form
x = y. Such templates are called equality constraint languages [12]. Example 1
in Section 2 is an example of an equality constraint language. Another example
is (N, S) where
S = {(x, y, z) ∈N3 | x = y = z ∨x ̸= y ̸= z ̸= x} .
It is not hard to see that equality constraint languages are precisely those
templates that are preserved by all permutations of the domain.
Theorem 13 (of [12]). Let Γ be an equality constraint language. If Γ is pre-
served by a unary constant operation, or by a binary injective operation, then
CSP(Γ) is in P. Otherwise, all polymorphisms of Γ are essentially unary and
preserve ̸=, and CSP(Γ) is NP-complete.
We can answer Question 4 positively in case that Γ is an equality constraint
language. In fact, Theorem 13 has the following reformulation using pseudo-
varieties and equations.
Theorem 14. Let Γ be an equality constraint language. The either V(AΓ ) con-
tains a 2-element algebra where all operations are projections, and CSP(Γ) is
NP-complete, or AΓ contains operations a, f satisfying f(x, y) = a(f(y, x)).

224
M. Bodirsky
Proof. If AΓ contains operations a, f satisfying f(x, y) = a(f(y, x)) then this
equation holds for all members of V(AΓ ), and since the projections do not satisfy
this equation, the two cases mentioned in the theorem are indeed disjoint.
Now, suppose that all polymorphisms of AΓ are essentially unary and preserve
̸=. Let f : D(Γ)2 →{0, 1} be such that (x, y) is mapped to 0 for x = y and
to 1 for x ̸= y. It is straightforward to verify that f is a surjective algebra
homomorphism from A2
Γ to an algebra B where all operations are projections.
Theorem 10 implies that CSP(Γ) is NP-complete.
If AΓ contains an operation that does not preserve ̸=, or is not essentially
unary, then Theorem 13 shows that AΓ contains a constant operation or a binary
injective operation. It is easy to see that in both cases there is a permutation a
and a binary operation f in AΓ such that f(x, y) = a(f(y, x)).
⊓⊔
12
Outlook
In the opinion of the author, there are three important directions of future
research on CSPs with inﬁnite templates.
1. Apply the universal-algebraic approach to unify and generalize
existing CSP complexity results in the application areas. Similarly as
for the mentioned classiﬁcation for equality constraint languages, it would be
interesting to have a complete classiﬁcation for templates for reasoning over
time points, time intervals (i.e., the generalization of Allen’s interval algebra
to constraint languages with arbitrary, and not only binary constraints), for
reasoning over partially ordered time, branching time, and spatial reasoning
with RCC-5, and for other important qualitative reasoning formalisms that
have been studied in the literature. I am optimistic that with the universal-
algebraic approach a classiﬁcation in the style of Theorem 13 can be obtained
in all these areas. In particular, I expect that in this way we discover new
and interesting tractable languages.
2. Further develop the universal-algebraic theory for ω-categorical
templates.
(a) When is it useful to work with varieties instead of pseudo-varieties? For
ﬁnite templates Γ, the pseudo-variety and the variety of the Γ contain
the same ﬁnite algebras. Birkhoﬀ’s theorem thus asserts that the com-
putational complexity of CSP(Γ) is captured by the set of equations sat-
isﬁed by the operations in AΓ . Indeed, also for ω-categorical templates
several tractability criteria can be formulated by equations satisﬁed by
the polymorphisms of the template (see Section 10).
(b) Develop tame congruence theory for oligomorphic algebras A. An inter-
esting approach might be to apply classical tame congruence theory to
the ﬁnite algebras in the pseudo-variety generated by A, and to study
the implications for the algebra A (recall the examples in Section 11).
(c) Suppose we have classiﬁed the computational complexity for all tem-
plates with a ﬁrst-order deﬁnition in another ω-categorical structure Γ.

Constraint Satisfaction Problems with Inﬁnite Templates
225
Can we lift this classiﬁcation to a classiﬁcation for all structures with a
ﬁrst-order interpretation in Γ?
(d) Follow the successful lines in model-theory where ω-categorical struc-
tures were classiﬁed under certain additional assumptions, for exam-
ple strict minimality [61, 26], ﬁnite homogeneity or stability [51, 28], or
smooth approximability [45, 27]. These classiﬁcations are usually up to
inter-deﬁnability, sometimes even bi–inter-pretability, so even if a classi-
ﬁcation is complete in the model-theoretic sense, quite some eﬀort might
be necessary to classify the complexity of the corresponding CSPs. Fi-
nally, we would like to mention that many of the ω-categorical templates
in Artiﬁcial Intelligence have an automorphism group that is a Jordan
group [53,25], for which strong classiﬁcation results are known [2,3].
3. Clarify which constraint satisfaction problems in NP can be for-
mulated with an ω-categorical template. We have seen an example that
does not have such a formulation in Section 5. But we have also seen that all
CSPs in MSNP do have a formulation with an ω-categorical template. Is the
same true for all problems in SNP? Which constraint satisfaction problems
in NP are in SNP?
Acknowledgements. I would like to thank the referee for his critical and help-
ful comments, all my CSP co-authors for the cooperation: Hubie Chen, Victor
Dalmau, Jan K´ara, Martin Kutz, Jaroslav Neˇsetˇril, Michael Pinsker, Timo von
Oertzen.
References
1. Abian, A.: Categoricity of denumerable atomless boolean rings. Studia Log-
ica 30(1), 63–67 (1972)
2. Adeleke, S., Neumann, P.M.: Structure of partially ordered sets with transitive
automorphism groups. AMS Memoir 57(334) (1985)
3. Adeleke, S.A., Macpherson, D.: Classiﬁcation of inﬁnite primitive jordan permu-
tation groups. Proceedings of the London Mathematical Society s3-72(1), 63–123
(1996)
4. Aho, A., Sagiv, Y., Szymanski, T., Ullman, J.: Inferring a tree from lowest common
ancestors with an application to the optimization of relational expressions. SIAM
Journal on Computing 10(3), 405–421 (1981)
5. Allen, J.F.: Maintaining knowledge about temporal intervals. Communications of
the ACM 26(11), 832–843 (1983)
6. Bauslaugh, B.L.: The complexity of inﬁnite h-coloring. J. Comb. Theory, Ser.
B 61(2), 141–154 (1994)
7. Bodirsky, M.: Cores of countably categorical structures. In: Logical Methods in
Computer Science, LMCS (2007), doi:10.2168/LMCS-3(1:2)
8. Bodirsky, M., Chen, H.: Oligomorphic clones. Algebra Universalis 57(1), 109–125
(2007)
9. Bodirsky, M., Chen, H.: Qualitative temporal and spatial reasoning revisited. In:
Duparc, J., Henzinger, T.A. (eds.) CSL 2007. LNCS, vol. 4646, pp. 194–207.
Springer, Heidelberg (2007)

226
M. Bodirsky
10. Bodirsky, M., Chen, H., Kara, J., von Oertzen, T.: Maximal inﬁnite-valued con-
straint languages. In: Arge, L., Cachin, C., Jurdzi´nski, T., Tarlecki, A. (eds.)
ICALP 2007. LNCS, vol. 4596, pp. 546–557. Springer, Heidelberg (2007)
11. Bodirsky, M., Dalmau, V.: Datalog and constraint satisfaction with inﬁnite tem-
plates. In: Durand, B., Thomas, W. (eds.) STACS 2006. LNCS, vol. 3884, pp.
646–659. Springer, Heidelberg (2006)
12. Bodirsky, M., K´ara, J.: The complexity of equality constraint languages. In: Grig-
oriev, D., Harrison, J., Hirsch, E.A. (eds.) CSR 2006. LNCS, vol. 3967, pp. 114–126.
Springer, Heidelberg (2006)
13. Bodirsky, M., K´ara, J.: The complexity of temporal constraint satisfaction prob-
lems (preprint, 2007)
14. Bodirsky, M., K´ara, J.: A fast algorithm and lower bound for temporal reasoning
(preprint, 2007)
15. Bodirsky, M., Kutz, M.: Pure dominance constraints. In: Alt, H., Ferreira, A. (eds.)
STACS 2002. LNCS, vol. 2285, pp. 287–298. Springer, Heidelberg (2002)
16. Bodirsky, M., Kutz, M.: Determining the consistency of partial tree descriptions.
Artiﬁcial Intelligence 171, 185–196 (2007)
17. Bodirsky, M., Neˇsetˇril, J.: Constraint satisfaction with countable homogeneous
templates. In: Baaz, M., Makowsky, J.A. (eds.) CSL 2003. LNCS, vol. 2803, pp.
44–57. Springer, Heidelberg (2003)
18. Bodnarˇcuk, V.G., Kaluˇznin, L.A., Kotov, V.N., Romov, B.A.: Galois theory for
post algebras, part I and II. Cybernetics 5, 243–539 (1969)
19. Broxvall, M., Jonsson, P.: Point algebras for temporal reasoning: Algorithms and
complexity. Artif. Intell. 149(2), 179–220 (2003)
20. Bulatov, A.: A graph of a relational structure and constraint satisfaction problems.
In: Proceedings of the 19th IEEE Annual Symposium on Logic in Computer Science
(LICS 2004), Turku, Finland (2004)
21. Bulatov, A., Jeavons, P.: Algebraic structures in combinatorial problems. Technical
report MATH-AL-4-2001, Technische Universitat Dresden. International Journal
of Algebra and Computing (submitted, 2001)
22. Bulatov, A., Krokhin, A., Jeavons, P.G.: Classifying the complexity of constraints
using ﬁnite algebras. SIAM Journal on Computing 34, 720–742 (2005)
23. Bulatov, A.A., Dalmau, V.: A simple algorithm for Mal’tsev constraints. SIAM J.
Comput. 36(1), 16–27 (2006)
24. Burris, S., Sankappanavar, H.: A Course in Universal Algebra. Springer, Berlin
(1981)
25. Cameron, P.J.: Oligomorphic Permutation Groups. Cambridge Univ. Press, Cam-
bridge (1990)
26. Cherlin, G., Harrington, L., Lachlan, A.: ℵ0-categorical, ℵ0-stable structures. An-
nals of Pure and Applied Logic 28, 103–135 (1985)
27. Cherlin, G., Hrushovski, E.: Finite Structures with Few Types. Princeton Univer-
sity Press, Princeton (2003)
28. Cherlin, G., Lachlan, A.H.: Stable ﬁnitely homogeneous structures. TAMS 296,
815–850 (1986)
29. Cohen, D., Jeavons, P., Jonsson, P., Koubarakis, M.: Building tractable disjunctive
constraints. Journal of the ACM 47(5), 826–853 (2000)
30. Droste, M.: Structure of partially ordered sets with transitive automorphism
groups. AMS Memoir 57(334) (1985)
31. D¨untsch, I.: Relation algebras and their application in temporal and spatial rea-
soning. Artiﬁcial Intelligence Review 23, 315–357 (2005)

Constraint Satisfaction Problems with Inﬁnite Templates
227
32. Ebbinghaus, H.-D., Flum, J.: Finite Model Theory, 2nd edn. Springer, Heidelberg
(1999)
33. Evans, D.: Examples of ℵ0-categorical structures. In: Kaye, R., Macpherson, H.D.
(eds.) Automorphisms of ﬁrst-order structures, pp. 33–72. Oxford University Press,
Oxford (1994)
34. Feder, T., Hell, P., Mohar, B.: Acyclic homomorphisms and circular colorings of
digraphs. SIAM J. Discrete Math. 17(1), 161–169 (2003)
35. Feder, T., Vardi, M.: The computational structure of monotone monadic SNP and
constraint satisfaction: A study through Datalog and group theory. SIAM Journal
on Computing 28, 57–104 (1999)
36. Fra¨ıss´e, R.: Theory of Relations. North-Holland, Amsterdam (1986)
37. Garey, M., Johnson, D.: A guide to NP-completeness. CSLI Press (1978)
38. Geiger, D.: Closed systems of functions and predicates. Paciﬁc Journal of Mathe-
matics 27, 95–100 (1968)
39. Goldstern, M., Pinsker, M.: A survey of clones on inﬁnite sets. arXiv:0701030
(preprint, 2007)
40. Hell, P., Neˇsetˇril, J.: On the complexity of H-coloring. Journal of Combinatorial
Theory, Series B 48, 92–110 (1990)
41. Hirsch, R.: Expressive power and complexity in algebraic logic. Journal of Logic
and Computation 7(3), 309–351 (1997)
42. Hodges, W.: A shorter model theory. Cambridge University Press, Cambridge
(1997)
43. Idziak, P.M., Markovic, P., McKenzie, R., Valeriote, M., Willard, R.: Tractability
and learnability arising from algebras with few subpowers. In: LICS, pp. 213–224
(2007)
44. Jonsson, P., Drakengren, T.: A complete classiﬁcation of tractability in RCC-5. J.
Artif. Intell. Res. 6, 211–221 (1997)
45. Kantor, W.M., Macpherson, H.D., Liebeck, M.W.: ℵ0-categorical structures
smoothly approximated by ﬁnite substructures. Proc. London Math. Soc. 59, 439–
463 (1989)
46. Keisler, J.: Reduced products and Horn classes. Trans. Amer. Math. Soc. 117,
307–328 (1965)
47. Kl´ıma, O., Tesson, P., Th´erien, D.: Dichotomies in the complexity of solving sys-
tems of equations over ﬁnite semigroups. Theory Comput. Syst. 40(3), 263–297
(2007)
48. Koubarakis, M.: Tractable disjunctions of linear constraints: Basic results and
applications to temporal reasoning. Theoretical Computer Science 266, 311–339
(2001)
49. Krokhin, A.A., Jeavons, P., Jonsson, P.: Reasoning about temporal relations: The
tractable subalgebras of Allen’s interval algebra. JACM 50(5), 591–640 (2003)
50. Kun, G.: Constraints, mmsnp, and expander relational structures. arXiv:0706.1701
(2007)
51. Lachlan, A.H.: Stable ﬁnitely homogeneous structures: A survey. In: Algebraic
Model Theory, NATO ASI Series, vol. 496, pp. 145–159 (1996)
52. Ladner, R.E.: On the structure of polynomial time reducibility. JACM 22(1), 155–
171 (1975)
53. Macpherson, D.: A survey of jordan groups. In: Kaye, R., Macpherson, H.D. (eds.)
Automorphisms of ﬁrst-order structures, pp. 73–110. Oxford University Press, Ox-
ford (1994)
54. Matiyasevich, Y.: Enumerable sets are diophantine. Doklady Akademii Nauk
SSSR 191, 279–282 (1970)

228
M. Bodirsky
55. Nebel, B., B¨urckert, H.-J.: Reasoning about temporal relations: A maximal
tractable subclass of Allen’s interval algebra. JACM 42(1), 43–66 (1995)
56. Paterson, M.S., Wegman, M.N.: Linear uniﬁcation. Journal of Computer and Sys-
tem Sciences 16, 158–167 (1978)
57. Poizat, B.: A Course in Model Theory: An Introduction to Contemporary Mathe-
matical Logic. Springer, Heidelberg (2000)
58. Renz, J., Nebel, B.: On the complexity of qualitative spatial reasoning: A maximal
tractable fragment of the region connection calculus. Artif. Intell. 108(1-2), 69–123
(1999)
59. Szendrei, A.: Clones in universal Algebra. Seminaire de mathematiques superieures.
Les Presses de L’Universite de Montreal (1986)
60. van Beek, P., Cohen, R.: Exact and approximate reasoning about temporal rela-
tions. Computational Intelligence 6, 132–144 (1990)
61. Zilber, B.: Uncountable categorical theories, Tranlations of Mathematical Mono-
graphs, vol. 117. Amer. Math. Soc. (1993)

Partial Polymorphisms and Constraint
Satisfaction Problems
Henning Schnoor1 and Ilka Schnoor2
1 Institut f¨ur Informatik, Christian-Albrechts-Universit¨at Kiel,
Christian-Albrechts-Platz 4, D-24118 Kiel, Germany
schnoor@ti.informatik.uni-kiel.de
2 Institut f¨ur Theoretische Informatik, Universit¨at L¨ubeck, Ratzeburger Allee 160,
D-23538 L¨ubeck, Germany
schnoor@tcs.uni-luebeck.de
Abstract. The Galois connection between clones and and co-clones has
received a lot of attention in the context of complexity considerations for
constraint satisfaction problems. However, it fails if we are interested in
a reduction giving equivalence instead of only satisﬁability-equivalence.
We show how a similar Galois connection involving weaker closure oper-
ators can be applied for these problems. As an example of the usefulness
of our construction, we show how to obtain very short proofs of com-
plexity classiﬁcations in this context.
Keywords: partial polymorphisms, clones, constraint satisfaction prob-
lems, computational complexity.
1
Introduction
Constraint satisfaction problems (CSPs) play an important role in computa-
tional complexity theory. In particular, the non-uniform version of the problem,
CSP (Γ) has been studied. In this context, a set of relations Γ, called a con-
straint language, over a ﬁnite domain is ﬁxed, and so-called Γ-formulas, i.e.,
conjunctions of applications of relations from Γ to variables, are studied. For the
Boolean domain, these problems generalize many well-known restrictions of the
propositional satisﬁability problem, for example 2SAT, 3SAT, Horn-SAT, etc. For
non-Boolean domains, CSPs can be used to express various problems related to
graphs (like search, colorability problems, and others) as well as database queries
and scheduling problems. Many combinatorial problems can be expressed in this
context, and therefore constraint satisfaction problems can be seen as embodying
the quintessence of the combinatorial aspects of complexity theory.
The study of constraint related problems in computational complexity started
with Thomas Schaefer’s seminal paper [Sch78]. He showed that for Boolean
constraint languages Γ, the complexity of the satisﬁability problem CSP (Γ)
(the problem to determine if a given Γ-formula is satisﬁable) is dichotomic: For
N. Creignou et al. (Eds.): Complexity of Constraints, LNCS 5250, pp. 229–254, 2008.
c
⃝Springer-Verlag Berlin Heidelberg 2008

230
H. Schnoor and I. Schnoor
a given Γ, this problem can be solved in P, or is already complete for NP, hence
avoiding the inﬁnitely many complexity degrees between these two classes which
are known to exist (if P ̸= NP) due to a classic result by Richard Ladner [Lad75].
Since Schaefer’s work, many results have been obtained about the complexity of
the problem CSP (Γ) for non-Boolean domains, leading to a proof of a similar
dichotomy theorem for the three-element case by Andrei Bulatov [Bul06].
One of the most successful techniques to obtain results on the complexity
of constraint-related problems has been the application of tools from Universal
Algebra. In particular, a Galois connection between constraint languages and
functions on ﬁnite domains has been studied. This Galois connection can be
used to show that if two constraint languages Γ1 and Γ2 have the same algebraic
closure properties, then the complexity of the problems CSP (Γ1) and CSP (Γ2)
is the same [Jea98] (up to ≤log
m -reductions, [ABI+05]). The Galois connection
relates the expressive power of a constraint language to its set of polymorphisms,
i.e., algebraic closure properties. By a work of Emil Post [Pos41], the structure
of the polymorphism sets occurring here, so-called clones, is well known for the
Boolean case. Hence the Galois connection can be used to transfer results from
these well-known classes to the complexity of constraint satisfaction problems.
The Galois connection gives a procedure transforming Γ1-formulas into equiv-
alent Γ2-formulas, where in the newly constructed Γ2-formulas, additional exis-
tentially quantiﬁed variables and equality clauses may occur. It is easy to see
that this leads to a transformation from Γ1- to Γ2-formulas preserving satis-
ﬁability, as in the satisﬁability problem, new free variables in a formula can
be regarded as existentially quantiﬁed, and the occurring equality clauses can
be dealt with using variable identiﬁcation. Similarly, in many cases where the
newly introduced variables can be “hidden” in some way (for example, in many
cases of problems involving quantiﬁed formulas), this transformation can easily
be seen to preserve all relevant properties of the involved formulas. An intro-
duction to this technique can be found in [BCRV04], and background over the
algebraic properties of the involved structure is given in Dietlinde Lau’s excellent
survey [Lau06].
However, for most problems diﬀerent from satisﬁability, this transformation
is not suﬃcient. In the case of problems like counting and enumeration of solu-
tions for constraint formulas, it is evident that the newly introduced variables
are problematic, as they can change the set and the number of solutions to a
given formula. In [SS06], it was shown that this feature of the Galois connection
makes it inapplicable for the enumeration problem over non-Boolean domains.
Similarly, if the goal is to determine whether two formulas are equivalent, the
introduction of equality clauses is an additional problem.
The identiﬁcation of equality-constrained variables is also problematic when
considering low complexity classes. In [ABI+05], it was shown that the intro-
duction of equality clauses makes it impossible to reﬁne the logspace reduction
given by the Galois connection to a reduction computable in AC0.
From these considerations, it is evident that other algebraic tools are required
when looking at questions in the constraint context diﬀerent from determining

Partial Polymorphisms and Constraint Satisfaction Problems
231
the ≤log
m -degree of complexity of the satisﬁability problem. A natural approach
is to consider restricted closures, where the problematic features from the Ga-
lois connection mentioned above, i.e., introduction of new variables and equality
clauses, are absent. This closure operator has been studied in mathematics al-
ready in the 1960s, and a similar relation to closure properties of the involved
relations was proven. This reﬁned Galois connection tells us that instead of
looking at the set of polymorphisms, we need to consider the set of partial poly-
morphisms. These form a structure which is a reﬁnement of the clone structure
exhibited by Post for the Boolean case. In particular, we know that instead of the
countably many classes arising in Post’s classiﬁcation, there is an uncountable
number of partial clones [AV94]. In other words, the step from the usual Galois
connection to the reﬁnement comes with the price of additional complexity of
the mathematical structures involved.
In light of these considerations, it is surprising to see that for many of the com-
putational problems where the above-mentioned diﬃculties occur, a complexity
classiﬁcation, when achieved, often follows the lines of the well-studied closure
operator. In this case, we say that the Galois connection can be applied. The
question for which problems the Galois connection can be applied is an interest-
ing question in the constraint context. While proofs for an “a priori”-application
of the Galois connection are very often close to trivial, there are many cases
where the fact that the Galois connection can be applied only follows from a
complete complexity classiﬁcation of the involved problem (for example enumer-
ation [CH97] and equivalence [BHRV02] problems in the Boolean case).
The contribution of this paper is twofold: First, we exhibit, among the poten-
tially uncountably many partial clones corresponding to each clone C, a unique
one which leads to the constraint problems with the lowest complexity among
those with polymorphism set C, and show how canonical constraint languages
with this complexity behavior can be constructed. These “weak bases” can be
used to show lower complexity bounds for all constraint languages sharing the
same set of polymorphisms, even when the usual Galois connection cannot be
applied to the problem at hand. Therefore, they address a common problem
encountered when proving complexity classiﬁcations. Second, we give an answer
to the above question: we give a method which can be used to determine if for
a given problem, the usual Galois connection can be applied.
The paper is structured as follows: In Section 2, we give the necessary deﬁni-
tions. In Section 3, we state the reﬁned Galois connection. In Section 4, we con-
struct the “weak bases” mentioned above. While this work focuses on eliminating
the need for existential quantiﬁcation, Section 5 then considers the problem of re-
quired equality clauses. Finally, in Section 6, we demonstrate our technique with
giving very short re-proofs of the above mentioned results about enumeration
and equivalence for Boolean constraint languages, where much of the technical
diﬃculty of the original proofs can be avoided using our algebraic results. We
also prove a complexity classiﬁcation for the implication problem for constraint
formulas, which is closely related to the equivalence problem.

232
H. Schnoor and I. Schnoor
2
Preliminaries
We ﬁrst brieﬂy repeat the basic deﬁnitions in the constraint satisfaction context.
In this paper, we only consider ﬁnitary relations over a ﬁnite domain. For a tuple
v, the value v[i] denotes its i-th component. A constraint language Γ is a ﬁnite
set of non-empty, ﬁnitary relations over a ﬁnite domain D. For a (not necessarily
ﬁnite) set of relations Γ, a Γ-formula is a conjunction of the form
ϕ =
n
	
i=1
Ri(xi
1, . . . , xi
ki),
where each Ri is a ki-ary relation from Γ, and the xi
j are (not necessarily dis-
tinct) variables. For a single-element constraint language {R}, we often simply
speak about R-formulas, etc. We denote the set of variables occurring in ϕ with
VAR (ϕ). An assignment I : VAR (ϕ) →D satisﬁes ϕ or is a solution of ϕ, if
for all i ∈{1, . . . , n}, it holds that (I(xi
1), . . . , I(xi
ki)) is a tuple from Ri. We
say that a constraint language is Boolean, if the domain D has cardinality 2.
The unary relation D is also denoted as ⊤, since ⊤(x) is a tautological clause.
Finally, for any set D, let OPD denote the total ﬁnitary functions on D.
There is a close relationship between formulas and relations, as each formula
deﬁnes the relation of its satisfying assignments. We say that a formula represents
or expresses the relation of its solutions.
We now deﬁne three closure operators for relations and constraint languages.
The ﬁrst one, ⟨.⟩, is the one usually considered in the constraint context, which
has successfully been applied to classify the complexity of satisﬁability problems.
The other two are the reﬁnements where we disallow the introduction of equality
clauses and/or new variables.
Deﬁnition 2.1. Let Γ be a set of relations.
– ⟨Γ⟩is the set of relations which can be expressed as a Γ ∪{=}-formula with
additional existentially quantiﬁed variables.
– ⟨Γ⟩∄is the set of relations which can be expressed as a Γ ∪{=}-formula.
– ⟨Γ⟩∄,̸= is the set of relations which can be expressed as a Γ-formula.
In the notation above, ̸= does not mean that the closure operator is allowed to use
the inequality predicate, but that the operator is not allowed to use the equality
predicate (unless it is present in Γ), similarly ∄means that the introduction of
existentially quantiﬁed variables is not allowed. It is evident that for any set of
relations Γ, the inclusion ⟨Γ⟩∄,̸= ⊆⟨Γ⟩∄⊆⟨Γ⟩holds.
The operators deﬁned above are closure operators in the usual mathematical
sense, i.e., for an operator C ∈{⟨.⟩, ⟨.⟩∄, ⟨.⟩∄,̸=} and sets of relations Γ1 and
Γ2, it holds that Γ1 ⊆C(Γ1), if Γ1 ⊆Γ2, then C(Γ1) ⊆C(Γ2) also holds, and
ﬁnally C(C(Γ1)) = C(Γ1). Sets Γ satisfying C(Γ) = Γ are also called C-closed.
The ⟨.⟩-closed sets are called co-clones, and the ⟨.⟩∄-closed sets are called weak
systems. We say that Γ is a base of the co-clone ⟨Γ⟩.
It is obvious that each closure operator C ∈{⟨.⟩, ⟨.⟩∄, ⟨.⟩∄,̸=} gives rise to a
formula transformation. Let Γ1 ⊆C(Γ2). Then a Γ1-formula can be transformed

Partial Polymorphisms and Constraint Satisfaction Problems
233
into an equivalent Γ2-formula by replacing a clause R(x1, . . . , xn) for some re-
lation R ∈Γ1 with its Γ2-implementation, possibly adding new existentially
quantiﬁed variables and/or equality clauses, depending on the closure operator.
To remove these features and produce an actual Γ2-formula, we proceed as fol-
lows: In the case of equality clauses (x = y), we simply replace every occurrence
of the variable y with x, and remove the equality clause. For existentially quan-
tiﬁed variables, we simply drop the quantiﬁers, leaving the variables free. The
Γ2-formula constructed in this way is not necessarily equivalent to the old one,
but the transformation preserves many properties of the formulas which we are
interested in. In particular, it preserves satisﬁability, and hence is very useful
when studying the complexity of satisﬁability problems.
In the following, let Problem be a computational problem where the input
instances are propositional formulas, and let Problem(Γ) be its restriction to Γ-
formulas as inputs. As examples, we introduce the following: CSP is the problem
to determine whether a formula is satisﬁable, EQUIV is the problem to deter-
mine whether two input formulas are equivalent, and ENUM is the problem to
enumerate the set of solutions for a formula. If P ̸= NP, then all these problems
are intractable: the problems CSP and EQUIV are NP-complete resp. coNP-
complete. The problem ENUM is not a decision problem and hence cannot easily
be related to these standard complexity classes, but any eﬃcient enumeration
algorithm can be used to eﬃciently decide the satisﬁability problem.
For the problem Problem and a complexity reduction ≤, we say that the op-
erator C can be ≤-applied a to Problem, if for any two constraint languages
Γ1 and Γ2 such that Γ1 ⊆C(Γ2), Problem (Γ1) ≤-reduces to Problem (Γ2). The
enumeration problem does not fall into the category of counting and decision
problems for which established notions of reductions exist. However, in the con-
straint context it turns out that the question if there is an eﬃcient enumeration
algorithm exists for a given constraint language Γ is again closely related to the
co-clone generated by Γ. We therefore say that a closure operator C can be ap-
plied to the enumeration problem if for all constraint languages Γ1 and Γ2 such
that Γ1 ⊆C(Γ2), it holds that if there is an eﬃcient enumeration algorithm for
Γ2-formulas, then there also is one for Γ1-formulas.
Such results can very often be obtained “for free,” since in many cases trans-
forming Γ1-formulas into Γ2-formulas in the way described above gives a reduc-
tion from the problem Problem (Γ1) to Problem (Γ2). For example, it was shown
in [ABI+05] that the closure operator ⟨.⟩leads to a ≤log
m -reduction, and ⟨.⟩∄,̸=
leads to an ≤AC0
m
-reduction for the satisﬁability problem. Similarly, it is obvi-
ous that the closure operator ⟨.⟩∄,̸= leads to a parsimonious reduction for the
problem to count solutions for a constraint formula, and ⟨.⟩∄can be applied to
the enumeration problem, since ⟨.⟩∄allows us to transform a Γ1-formula into a
Γ2-formula in such a way that there is a canonical and easily computable relation
between the solution sets of the formulas.
It is worth noting that, contrary to intuition, the operator ⟨.⟩∄provably cannot
be applied to the counting problem. Consider the languages Γ1 = {x, x} and
Γ2 = {x, x, =}. Obviously, ⟨Γ1⟩∄= ⟨Γ2⟩∄, but Γ1-formulas always have exactly

234
H. Schnoor and I. Schnoor
0 or exactly 1 solutions, while for every k, there is a Γ2-formula with exactly 2k
solutions, namely (x1 = x1) ∧(x2 = x2) ∧· · · ∧(xk = xk). Therefore, there is no
parsimonious reduction between their respective counting problems.
Note that the formula transformations given by the closure operators do not
only diﬀer with respect to the question for which problems they can be applied,
the complexity of the resulting transformation procedure is diﬀerent as well. If
we allow equality clauses in the closure operator, then a transformation to the
ﬁnal constraint language must be able to remove them, and will usually do this
by identifying variables. Hence it needs to perform a search in an undirected
graph, and therefore needs the computational power of LOGSPACE. When this
problem does not arise, the formula transformation is simply a local replacement,
and can be computed by an AC0-reduction. The operator ⟨.⟩∄,̸= obviously allows
for a transformation of formulas into equivalent ones. Therefore, this operator
can be applied to the majority of problems in the constraint context. In partic-
ular, this holds for the equivalence problem, the counting problem, and all other
problems mentioned. Since the formula transformation in this case just needs
local replacement, it can be performed by AC0-reductions. It is natural that the
weakest of our closure operators gives us the strongest results: it is applicable
to most problems, and its formula transformation needs the least computational
resources.
From the above discussion, we conclude:
Proposition 2.2.
– ⟨.⟩can be ≤log
m -applied to CSP,
– ⟨.⟩∄can be applied to ENUM,
– ⟨.⟩∄,̸= can be ≤AC0
m -applied to EQUIV.
It is obvious that if ⟨.⟩can be applied to a problem, then the weaker closure
operators can be applied as well, and similarly, if ⟨.⟩∄can be applied, then this
also is true for ⟨.⟩∄,̸= In many cases, it cannot easily be seen that one of the above
closure operators can be applied, but this result follows from a full complexity
classiﬁcation of the problem. This is true for the following problems:
Theorem 2.3.
– ⟨.⟩can be applied to ENUM over Boolean domains [CH97],
– ⟨.⟩can be ≤p
m-applied to the EQUIV over Boolean domains [BHRV02].
For both the enumeration and the equivalence problem, it is not clear that
the complexity of the problem only depends on ⟨Γ⟩, since the introduction of
new existentially quantiﬁed variables changes the set of solutions of a given
formula signiﬁcantly. Yet in the Boolean case, this was shown to be true. On the
other hand, it was proven that ⟨.⟩cannot be applied to ENUM over non-Boolean
domains [SS06]. In the survey [CV08], Creignou and Vollmer give an extensive
list of problems, and the known results about whether the ⟨.⟩can be applied to
them. We give a general criterion about applicability of this operator at the end
of Section 4.
The study of the closure operators we deﬁned above is closely related to
algebraic properties of the involved relations. In particular, the notion of a poly-
morphism has proven to be very useful. We will now deﬁne a generalization,
which we then use to state the reﬁned Galois connection.

Partial Polymorphisms and Constraint Satisfaction Problems
235
Deﬁnition 2.4. Let D be a ﬁnite domain, and let R ⊆Dn be a relation. Let A ⊆
Dm, and let f : A →D be a function. We say that f is a partial polymorphism
of R, f ∈pPol (R), if the following holds: For any u1 = (u1
1, . . . , u1
n), . . . , um =
(um
1 , . . . , um
n ) ∈R, if (u1
i , . . . , um
i ) ∈A for all i ∈{1, . . . , n}, then the coordinate-
wise application
f(u1, . . . , um) := (f(u1
1, . . . , um
1 ), . . . , f(u1
n, . . . , um
n ))
is in R. If A = Dm, we say that f is a polymorphism of R, f ∈Pol(R).
For a set of relations Γ, the set Pol (Γ) (pPol (Γ)) denotes the set of (partial)
functions which are a polymorphism of every relation in Γ. We say that f in the
deﬁnition above is a partial function on D if A ̸= Dm, and f is total if A = Dm.
The condition demanding that the vectors (u1
i , . . . , um
i ) must be elements of A
ensures that the coordinate-wise application of the (possibly partial) function f
gives a well-deﬁned vector. It is obvious that for any relation R, it holds that
Pol(R) = pPol (R) ∩OPD. For a set of functions B, the set Inv (B) denotes the
set of relations R such that B ⊆pPol(R). It is worth noting that although the
operators pPol (.) and Pol(.) obviously diﬀer, there is no need for two “versions”
of the Inv (.)-operator.
Polymorphisms have interesting algebraic properties: We say that a set C of
(partial) functions on D is a (partial) clone, if C contains all projections and
is closed under arbitrary composition. C is a strong partial clone, if in addition
for every (partial) function f ∈B, every further restriction of f (i.e., a partial
function whose domain is a subset of f’s domain, and that agrees with f for all
values in its domain) again is a member of B. For a set B of (partial) functions, we
denote with [B] ([B]p) the (strong partial) clone generated by B, i.e., the smallest
(strong partial) clone which is a superset of B. It is obvious that [B] ([B]p) is
the set of functions which can be generated from B by adding all projections
and closing the set under arbitrary composition (and further restriction).
It is easy to see that the set Pol(Γ) is always a clone for a constraint language
Γ, and the set pPol (Γ) always is a strong partial clone. For the Boolean case,
Emil Post obtained a complete classiﬁcation of all clones in [Pos41]. This classiﬁ-
cation is a powerful tool for the complexity classiﬁcations of Boolean constraint-
related problems: Whenever it can be shown that ⟨.⟩can be applied to a problem,
then his list of clones gives, via the Galois connection, a complete list of cases
to consider. Therefore in these cases, the Galois connection and the well-known
complete list of Boolean clones often makes the complexity analysis of a problem
where ⟨.⟩can be applied a straight-forward task.
3
The Galois Connection
The following theorem summarizes the main properties of the standard Galois
connection which has been used to prove complexity results in the constraint
satisfaction context:

236
H. Schnoor and I. Schnoor
Theorem 3.1 ([Gei68, BKKR69]). Let Γ be a constraint language over a
ﬁnite domain D, and let R be a non-empty relation over D. Then R ∈⟨Γ⟩if
and only if Pol (Γ) ⊆Pol(R).
In particular, this theorem can be used to show the following complexity result. It
was ﬁrst stated for polynomial-time many-one reductions in [Jea98], and reﬁned
to a logspace reduction in [ABI+05].
Theorem 3.2 ([Jea98, ABI+05]). Let Γ1 and Γ2 be constraint languages over
a ﬁnite domain D, such that Pol (Γ2) ⊆Pol(Γ1). Then CSP (Γ1) ≤log
m CSP (Γ2).
This theorem is useful because as mentioned before, the sets Pol(Γ) are always
clones, and their structure is well-studied. The following theorem is the reﬁne-
ment of the Galois connection exhibited in Theorem 3.1 to the ⟨.⟩∄operator. It
was proven by Boris Romov in 1981 [Rom81], but is already implicit in [Gei68].
Theorem 3.3 ([Rom81]). Let Γ be a constraint language over a ﬁnite domain
D, and let R be a non-empty relation over D. Then R ∈⟨Γ⟩∄if and only if
pPol (Γ) ⊆pPol (R).
The above Theorem 3.3 does not consider the closure operator ⟨.⟩∄,̸=. There also
is a further reﬁnement of the Galois connection to this case, where instead of
functions, we consider partial hyperfunctions. However, we will show in Section 5
that for many practical applications, this is not necessary.
It should be noted that the seemingly subtle step from polymorphisms to
partial polymorphisms has unfortunate consequences. While, as mentioned, the
lattice of clones for the Boolean case is well understood and completely classiﬁed
due to Post’s work [Pos41], the picture for partial clones is much less clear.
Already over the Boolean domain, there is an uncountable number of partial
clones [AV94], and the structure of the lattice of partial clones is not completely
known. This is the key reason why results that the operator ⟨.⟩can be applied
are so useful in practice: For a given Boolean constraint language Γ, it is easy to
determine its set of polymorphisms. In fact, this can be done automatically by
an algorithm. Hence, if there is a classiﬁcation theorem giving the complexity of
Problem (Γ) as an easy function of ⟨Γ⟩, then the complexity of Problem (Γ) can
be determined automatically.
In [Rom81], Theorem 3.1 was also proven to hold for inﬁnite constraint lan-
guages. In the Boolean case, there are exactly 8 clones C for which there does not
exist a ﬁnite constraint language Γ with ⟨Γ⟩= Inv (C), for larger ﬁnite domains,
there exists a continuum of such co-clones [BKKR69].
4
Weak Bases
The Galois connection stated in Theorem 3.3 shows that in order to classify
the complexity of problems where the standard Galois connection cannot be
proven to be applicable in a straight-forward way, we need to study the sets
of partial polymorphisms of a given constraint language. It is obvious that a

Partial Polymorphisms and Constraint Satisfaction Problems
237
given clone corresponds to many diﬀerent partial clones. In fact, since there
are uncountably many partial clones and in the Boolean case, there are only
countably many clones, there are clones with uncountably many partial clones
associated with them. We therefore need a more detailed examination of the
partial clones occurring inside a given clone. As mentioned, the sets pPol (Γ)
always form strong partial clones, and therefore we can restrict ourselves to
those.
Deﬁnition 4.1. For a clone C over a ﬁnite domain D, let
I(C) =def {D | D is a strong partial clone and D ∩OPD = C}
denote the interval of C. Further, let
I∪(C) =def

D∈I(C)
D
be the union of all partial clones in the interval I(C).
The set I(C) represents all strong partial clones which are “inside” the given
clone C. Hence the set of all partial functions which are in any of these partial
clones form the largest set of partial functions which can be related naturally
to C. It turns out that this set has very important properties. We will soon see
that the set I∪(C) forms a strong partial clone. It is the largest strong partial
clone contained in I(C), and hence the interval I(C) contains exactly the strong
partial clones D such that [C]p ⊆D ⊆I∪(C). Therefore, a constraint language
Γ satisfying pPol (Γ) = I∪(C) is in a certain way one of those which lead to the
“easiest” problems among those languages with polymorphism set C. It turns out
that constraint languages satisfying this condition are central for our complexity
considerations.
Deﬁnition 4.2. Let C be a clone over a domain D. Then a constraint language
Γ over D is called a weak base for Inv (C) if pPol (Γ) = I∪(C).
These weak bases are the main tool that we introduce to prove hardness results
for constraint-related problems. One of the important properties of weak bases,
as discussed informally above, is the following:
Corollary 4.3. Let C be a clone over D and Γ a weak base for Inv (C). Then
for any constraint language Γ ′ with ⟨Γ⟩= ⟨Γ ′⟩, it follows that Γ ⊆⟨Γ ′⟩∄.
Proof. Since Γ is a weak base for Inv (C), we know that pPol (Γ) = I∪(C). Now
let Γ ′ be a constraint language over D such that ⟨Γ ′⟩= ⟨Γ⟩. From Theorem 3.1,
it follows that Pol (Γ) = Pol(Γ ′) = C. Therefore, pPol (Γ ′) ∈I(C) and hence
pPol (Γ ′) ⊆I∪(C) = pPol (Γ). Therefore, from Theorem 3.3, it follows that
⟨Γ⟩∄⊆⟨Γ ′⟩∄, and since Γ ⊆⟨Γ⟩∄obviously holds, this concludes the proof.
□

238
H. Schnoor and I. Schnoor
For complexity considerations, Corollary 4.3 is of crucial importance. If we have
a weak base Γ for some co-clone Inv (C), then we know that this constraint
language is in the ⟨.⟩∄-closure of all constraint languages Γ ′ with polymorphism
set C. This implies that for all computational problems from the constraint
context where the ⟨.⟩∄-operator can be applied, the problem for the constraint
language Γ reduces to the problem for the constraint language Γ ′. Therefore,
the language Γ can be regarded as being the “easiest” among those with the
same set of polymorphisms. As the name weak base suggests, such a Γ has the
lowest expressive power with respect to the ⟨.⟩∄-operator among those with the
same set of polymorphisms.
Corollary 4.4. Let ≤be a complexity reduction, let Problem be a computa-
tional problem such that ⟨.⟩∄can be ≤-applied to Problem, let Γ ′ be a con-
straint language, and let Γ be a weak base of ⟨Γ ′⟩. Then Problem (Γ) reduces
to Problem (Γ ′).
Proof. Let C =def Pol(Γ ′). Since Γ a weak base of ⟨Γ ′⟩, Corollary 4.3 implies that
Γ ⊆⟨Γ ′⟩∄. Since ⟨.⟩∄can be ≤-applied to Problem, we know that Problem (Γ)
reduces to Problem (Γ ′).
□
Corollary 4.4 states that weak bases are exactly the tools we need if we want
to prove hardness results for all constraint languages generating a particular
co-clone, if the closure operator ⟨.⟩∄can be applied to the given computational
problem. It is therefore very desirable to be able to construct weak bases—
from the deﬁnition, it is not clear that ﬁnite languages having these properties
actually exist. Hence the rest of this section shows how weak bases (which in
our case will always be single relations) can be constructed. We will show that
in fact for all clones C, such that the co-clone has a ﬁnite base in the usual
sense (i.e., a ﬁnite constraint language Γ such that Pol (Γ) = C), a weak base
exists. For other clones C, a ﬁnite weak base cannot exist, because in particular,
if pPol(Γ) = I∪(C), then Pol(Γ) = C. Also, the clones with ﬁnite bases (weak
or otherwise) are the ones which usually appear in practical applications, since
often, we are concerned with a ﬁnite vocabulary.
We will give a characterization of I∪(C) and show that it again is a partial
clone with total functions C. In order to prove this result, we ﬁrst introduce
another way to relate a partial function to the clone C:
Deﬁnition 4.5. Let C be a clone over a ﬁnite domain D and f : A →D be a par-
tial function, where A ⊆Dn. Then f is C-total, if for all functions g1, . . . , gn ∈C
the function
f(g1(x1
1, . . . , x1
m1), . . . , gn(xn
1, . . . , xn
mn))
is either non-total or from C, where the xi
j are (not necessarily distinct) variables.
It is immediate that a total function is C-total if and only if it is an element of
C. The ﬁrst thing we need to note about C-total functions is that they form a
strong partial clone:

Partial Polymorphisms and Constraint Satisfaction Problems
239
Theorem 4.6. Let C be a clone over a ﬁnite domain D, and let F be a set of
C-total functions over D. Then every function in [F]p is C-total. In particular,
the set of C-total functions is a strong partial clone.
Proof. It obviously suﬃces to prove the ﬁrst part. Note that projections are
trivially C-total, hence it remains to show that the set of C-total functions is
closed under arbitrary composition and restriction of the domain of functions.
It is obvious that a restriction of a C-total function remains C-total. Therefore
let f, h1, . . . , hn be C-total partial functions where f is of arity n and hi is of
arity mi for all i ∈{1, . . . , n}. We need to prove that any function f ′ obtained
from these by composition again is C-total. Hence let f ′ be deﬁned as f ′ =
f(h1(x1
1, . . . , x1
m1), . . . , hn(xn
1 , . . . , xn
mn)). Let g1
1, . . . , gn
mn be functions from C,
where each gi
j is an li,j-ary function. We need to prove that the function
f ′′ = f (h1(g1
1(x1,1
1 , . . . , x1,1
l1,1), . . . , g1
m1(x1,m1
1
, . . . , x1,m1
l1,m1 )),
...
hn(gn
1 (xn,1
1 , . . . , xn,1
ln,1), . . . , gn
mn(xn,mn
1
, . . . , xn,mn
ln,mn)))
is either non-total, or a function from C. We consider two cases. First, assume
that one of the terms hi(gi
1(xi,1
1 , . . . , xi,1
li,1), . . . , gi
mi(xi,mi
1
, . . . , xi,mi
li,mi )) represents
a non-total function. Then obviously, the function f ′′ is non-total as well. Now
assume that all of these terms represent total functions. Then, since the hi are C-
total, and the functions gi
j are from C, we know that all of these terms represent
functions from C. Since f is C-total, this implies that the function f ′′ is a function
from C or non-total, as required.
□
We now show that the C-total functions are exactly those which are contained
in the clones from I(C). One important consequence of this theorem is that,
together with Theorem 4.6, it implies that the set I∪(C) forms a strong partial
clone. This implies that the set I(C) has a largest element, which is not imme-
diate. The fact that I∪(C) is a strong partial clone is a crucial requirement for
weak bases to exist.
Theorem 4.7. Let C be a clone on the ﬁnite domain D. Then I∪(C) is exactly
the set of partial functions which are C-total.
Proof. First, let f ∈I∪(C). Then there is a strong partial clone D, such that
D ∩OPD = C, and f ∈D. In particular, it follows that C ⊆D. Thus, since D is
a partial clone, the composition of f and functions from C still gives a function
from D, in particular a function which is either non-total, or a member of C.
Hence, f is C-total.
For the other direction, let f be a C-total function. Since every function from
C is trivially C-total, Theorem 4.6 implies that every function from [{f} ∪C]p
is C-total. Since every function from OPD which is C-total is a member of C,
it follows that [{f} ∪C]p ∩OPD = C. Therefore, by deﬁnition we have that
[{f} ∪C]p ∈I(C), and therefore f ∈I∪(C).
□

240
H. Schnoor and I. Schnoor
We now construct weak bases, i.e., constraint languages whose partial polymor-
phisms are exactly I∪(C) for a given clone C. In order to introduce the con-
struction, we need some more notation. In the following, we consider relations
as matrices, where the rows of the matrix correspond to the tuples of the rela-
tion. For this representation to be unique, we demand that the rows are ordered
lexicographically. For example, the relation {(0, 0, 1, 2), (2, 1, 0, 1), (1, 1, 2, 0)} is
represented by the matrix
⎛
⎝
0 0 1 2
1 1 2 0
2 1 0 1
⎞
⎠.
For a relation R, let R(l, k) be the value at row l and column k in the matrix
representation of R. By R(l, −) we denote the l-th row vector and by R(−, k)
the k-th column vector of R. The relation D-COLSs is deﬁned to be the |D|s-
ary relation of cardinality s such that D-COLSn(l, k) =def Dn(k, l). The main
feature of this relation is that its columns contain every s-ary tuple over the
domain D.
Example 4.8. The columns of the matrix representation of {0, 1} -COLS3 are
exactly the binary numbers from 0 to 23 −1 = 7:
{0, 1} -COLS3 =
⎛
⎝
0 0 0 0 1 1 1 1
0 0 1 1 0 0 1 1
0 1 0 1 0 1 0 1
⎞
⎠
For a set of D-valued functions F, the F-closure of a relation R over D, denoted
by F(R), is the relation ∩S∈Inv(F),R⊆SS, i.e. the minimal superset of R that is
closed under F. This relation can be obtained from R by applying all functions
from F repeatedly, and adding the result to R. It is immediate that F(R) =
[F] (R). We say R is an F-core of F(R). For a single partial function f we write
f(R) instead of {f}(R) and speak of f-closures and f-cores.
Deﬁnition 4.9. Let C be a clone. We say that Inv (C) has core-size s if there
is a relation R such that ⟨R⟩= Inv (C) and R has a C-core with cardinality s.
Obviously, the core-size of a clone is not unique. As we will see in Theorem 4.11,
the core-size of a co-clone is closely related to weak bases of Inv (C).
Example 4.10. Let D be the Boolean clone generated by f(x, y, z) = xy ∨xz ∨
(y ∧z). Then Inv (D) has core-size 1.
Proof. From [BRSV05], we know that for the Boolean relation R = {(0, 1), (1, 0)}
it holds that Pol(R) = D, and hence ⟨R⟩= Inv (D). Since f(0, 0, 0) = 1 and
f(1, 1, 1) = 0, we know that the set {(0, 1)} is an f-core of R, and therefore a
C-core of R. Therefore we have shown that R has a C-core of cardinality 1.
□
Since every relation R is a Pol(R)-core of itself, it is obvious that every co-
clone ⟨R⟩has core-size |R|. Therefore the results from [BRSV05], in which ﬁnite
bases were given for each co-clone where they exist, directly give core-sizes of

Partial Polymorphisms and Constraint Satisfaction Problems
241
all Boolean co-clones with ﬁnite bases (it is obvious that every co-clone which
has a ﬁnite base also has a base with just one relation, by taking the Cartesian
product). The signiﬁcance of C-cores and their cardinalities is explained in the
next theorem: The knowledge of the core-size of a co-clone is enough to exhibit
a relation R which is a weak base of Inv (C). In the following, we often simply
write C (COLSs) instead of C(D-COLSs), as the domain should be clear from
the context.
We will now show that the relations of the form C (COLSs) are weak bases,
and therefore, as shown above, constitute the “easiest” bases with regard to all
problems where the closure operator ⟨.⟩∄can be applied.
Theorem 4.11. Let C be a clone and let Inv (C) have core-size s. Then the
relation C (COLSs) is a weak base of Inv (C).
Proof. We need to show that pPol (C (COLSs)) = I∪(C). By the prerequi-
sites there exists a relation R such that Pol(R) = C, and which has a C-core
S of size s. Let B =def pPol (C (COLSs)). First we show that I∪(C) ⊆B.
Let f ∈I∪(C) be an n-ary partial function and assume that f /∈B. That
means there are t1, . . . , tn ∈C (COLSs) such that f(t1, . . . , tn) is well-deﬁned
and not from C (COLSs). Since D-COLSs is a C-core of C (COLSs), every t ∈
C (COLSs) can be derived by applying a function from C to the elements of
D-COLSs. Therefore there are s-ary functions h1, . . . , hn ∈C such that ti =
hi(D-COLSs(1, −), . . . , D-COLSs(s, −)). We look at the partial function
g =def f ◦(h1(x1, . . . , xn), . . . , hn(x1, . . . , xs)).
The following equation is true:
g(D-COLSs(1, −), . . . , D-COLSs(s, −)) = f(t1, . . . , tn) /∈D-COLSs
Since f is deﬁned for (t1, . . . , tn), it holds that g is deﬁned on every column of
D-COLSs, and since D-COLSs contains of all possible s-tuples on the domain
D, this means that g is a total function. Then g ∈C, because f is C-total due to
Theorem 4.7. It follows that g ∈Pol (C) (D-COLSs), but this is a contradiction.
Thus, f ∈B.
We prove B ⊆I∪(C) by showing that B ∩OPD = C. The main idea is that
we ﬁnd R in D-COLSs and therefore these two relations have the same set of
polymorphisms. By construction, it is obvious that C ⊆B ∩OPD. To prove
the other inclusion note that, since S and D-COLSs have the same size, all
columns of S are columns of D-COLSs as well. Let k be the arity of S and
c1, . . . , ck ∈{1, . . . , |D|s} such that for all i ∈{1, . . . , k} hold
S(−, i) = D-COLSs(−, ci).
Since S is a C-core of R, it follows that, if we only look at the columns c1, . . . , ck
of C (COLSs), we see R. More precisely, it holds
R =

(d1, . . . , dk) | there is a 1 ≤j ≤q such that
di = C (COLSs) (j, ci) for all 1 ≤i ≤k
"
(1)
where q is the size of C (COLSs).

242
H. Schnoor and I. Schnoor
Now let f ∈OPD \ C be an n-ary function. Since f /∈Pol(R), there are
t1, . . . , tn ∈R such that f(t1, . . . , tn) /∈R. Let r1, . . . , rn ∈{1, . . . , q} such that
ti = (C (COLSs) (ri, c1), . . . , C (COLSs) (ri, ck)).
We take a look at v =def f(C (COLSs) (r1, −), . . . , C (COLSs) (rn, −)). It holds
that (v[c1], . . . , v[ck]) = f(t1, . . . , tn) /∈R and using Equation 1 it follows v /∈
C(-COLSs). This means f /∈B and therefore B ∩OPD ⊆C.
Thus we showed B ∩OPD = C, which means B ⊆I∪(C).
□
Theorem 4.11 can be used to construct weak bases for any co-clone which has a
ﬁnite base at all, if we know a core-size of the co-clone. Therefore, an important
question is how to determine a core-size of a co-clone. Moreover, we are interested
in determining a core-size as small as possible, as the weak bases constructed
above grow exponentially in the core-size. In particular, we want to be prove
smaller core-sizes than the ones provided by the above-mentioned base-list in
[BRSV05] for the Boolean domain. We ﬁrst note that Theorem 4.11 already
gives a way to characterize core-sizes, since its converse is also true:
Proposition 4.12. Let C be a clone. Then Inv (C) has core-size s if and only if
Pol(C (COLSs)) = C.
Proof. First assume that Pol(C (COLSs)) = C. By deﬁnition of C (COLSs), we
know that D-COLSs is a C-core of C (COLSs) which has size s. Hence, Inv (C)
has core-size s. For the other direction, if Inv (C) has core-size s, then the result
follows directly from Theorem 4.11.
□
We now give a second criterion to determine if a number s is a core-size of a
co-clone. In the following, OPD
s denotes the set of s-ary total functions on D.
Theorem 4.13. Let C be a clone. Then Inv (C) has core-size s if and only if for
all functions f, if [{f} ∪C] ∩OPD
s ⊆C, it follows that f ∈C.
Proof. We prove both directions indirectly. First assume that Inv (C) does not
have core-size s, then due to Proposition 4.12, there is some function f ∈
Pol(C(D-COLSs)) such that f /∈C. Now let g be an arbitrary function from
[{f} ∪C] ∩OPD
s. We show that g ∈C. Since f ∈Pol (C(D-COLSs)), and
C ⊆Pol(C(D-COLSs)), and since Pol (C(D-COLSs)) is a clone, it follows that
g ∈Pol (C(D-COLSs)). Let u1, . . . , us denote the rows of D-COLSs. In particu-
lar it then follows that g(u1, . . . , us) ∈C(D-COLSs). Due to the construction of
this relation, it follows that there is a function h ∈C such that h(u1, . . . , us) =
g(u1, . . . , us). Since g is an s-ary function, and all tuples from Ds occur in
D-COLSs, it follows that g is the same function as h, and in particular, g ∈C.
For the other direction, assume that f is an l-ary function with [{f} ∪C] ∩
OPD
s ⊆C and f /∈C. It suﬃces to prove that f ∈Pol(C(D-COLSs)), the re-
sult then follows from Proposition 4.12. Again, let u1, . . . , us denote the rows
of D-COLSs. In order to prove that f is a polymorphism of C(D-COLSs), let
t1, . . . , tl ∈C(D-COLSs). Due to construction of the relation, this implies that

Partial Polymorphisms and Constraint Satisfaction Problems
243
there are functions h1, . . . , hl ∈C such that ti = hi(u1, . . . , us) for all relevant
i. Then f(t1, . . . , tl) = f(h1(u1, . . . , us), . . . , ht(u1, . . . , us)). Let g be deﬁned as
g(x1, . . . , xs) = f(h1(x1, . . . , xs), . . . , ht(x1, . . . , xs)). By construction, it follows
that g ∈[{f} ∪C] ∩OPD
s, and hence g ∈C ⊆Pol (C(D-COLSs)). Obviously,
g(u1, . . . , us) = f(t1, . . . , tl), and therefore f(t1, . . . , tl) ∈C(D-COLSs). It fol-
lows that f is a polymorphism of C(D-COLSs), as claimed.
□
From the above Theorem, we immediately obtain the following corollary:
Corollary 4.14. Let C be a clone on a ﬁnite domain. If s is a core-size of
Inv (C), then s + 1 is a core-size of Inv (C) as well.
Proof. Let f be a function such that [{f} ∪C] ∩OPD
s+1 ⊆C. We need to show
that f ∈C, the result then follows from Theorem 4.13. Since s is a core-size
of Inv (C), from the same theorem it follows that it is suﬃcient to show that
[{f} ∪C] ∩OPD
s ⊆C. Hence, let g be an s-ary function from [{f} ∪C], and
assume that g /∈C. Let g′ be the s+1-ary function deﬁned by g′(α1, . . . , αs+1) :=
g(α1, . . . , αs). Since g /∈C, it is obvious that g′ /∈C, since g ∈[g′]. This is a
contradiction, since g′ ∈[{f} ∪C] ∩OPD
s+1 ⊆C.
□
We therefore have two possibilities to determine a core-size of a co-clone: Propo-
sition 4.12 gives us a criterion which can easily be veriﬁed by an algorithm, and
Theorem 4.13 gives a more theoretical answer to this question. Since we can
determine the core-size of the co-clone, we have now established that we can
easily construct relations which have exactly those partial polymorphisms that
we are interested in, and hence allow us to apply the closure operator ⟨.⟩∄.
In some situations, working directly with the relations C (COLSs) is inconve-
nient. Therefore, we introduce the following construction. For relations R and
S with the same cardinality, where R = {r1, . . . , rn}, S = {s1, . . . , sn}, we de-
note with R ◦S the relation containing the tuples r1 ◦s1, . . . , rn ◦sn, where
for tuples a = (α1, . . . , αl) and b = (β1, . . . , βk), the tuple a ◦b is deﬁned as
(α1, . . . , αl, β1, . . . , βk).
Deﬁnition 4.15. Let R be a relation over the ﬁnite domain D. Then the ex-
tension of R, R[ext], is deﬁned as Pol (R)

R ◦D-COLS|R|

.
The extension of a relation is closely related to the weak bases of the form
C (COLSs) constructed earlier. There are two main diﬀerences: For once, the
expressibility result for the extension of R is weaker than that for the earlier
weak bases. For the latter, we will see in Section 5 that it can be expressed
by the relevant constraint languages without equality (possibly needing the ⊤-
relation), while for the former we can only obtain this result for the less strict
closure operator ⟨.⟩∄. Another disadvantage of the extension is that the arity of
this relation is usually huge: It is exponential in the cardinality of the original
relation R. Therefore, it is not feasible to work with the extension for speciﬁc
relations. The reason we introduce it is that the extension is a very helpful tool
if we do not need to consider speciﬁc examples, but want to perform uniform
proofs for arbitrary relations. The main feature of the extension is that it allows

244
H. Schnoor and I. Schnoor
us to start with a relation R and obtain a relation which is closely related to R
in such a way that it can easily simulate R-formulas, and on the other hand can
be expressed by all constraint languages having the same set of polymorphisms
as R. We will see an application of this idea in the proof of Theorem 6.3.
Proposition 4.16. Let R be a relation. Then R[ext] is a weak base of ⟨R⟩, and
R[ext] ∈⟨Γ⟩∄for all constraint languages Γ with Pol(Γ) = Pol (R).
Proof. It suﬃces to prove pPol

R[ext]
= I∪(Pol (R)), the second point then
follows from Corollary 4.3. In order to prove this equality, from Theorem 4.11 we
know that pPol

C(D-COLS|R|)

= I∪(C). Now note that R[ext] can be obtained
from C(D-COLS|R|) by reordering and doubling columns, an operation which
obviously leaves the ⟨.⟩∄-closure and therefore, due to Theorem 3.3, the set of
partial polymorphisms invariant.
□
We give an example for the extension.
Example 4.17. Let R = {(0, 1), (1, 0)}. Then R[ext] =
⎛
⎜
⎜
⎝
0 1 0 0 1 1
0 1 1 0 1 0
1 0 0 1 0 1
1 0 1 1 0 0
⎞
⎟
⎟
⎠.
Proof. We have already mentioned in Example 4.10, that Pol (R) = D, where
D is the Boolean clone generated by the function f(x, y, z) = xy ∨xz ∨(y ∧z).
Since |R| = 2, and the domain D is the Boolean universe {0, 1}, it follows that
D-COLS|R| =
%0 0 1 1
0 1 0 1
&
.
Therefore the relation R ◦D-COLS|R|, which is obtained by concatenating the
tuples from R and those from D-COLS|R| is the relation
%0 1 0 0 1 1
1 0 0 1 0 1
&
.
By deﬁnition, R[ext] is the f-closure of this relation, and it can be veriﬁed that
this is exactly the relation as claimed: Note that f(x, x, x) = x, and therefore
R[ext] must contain all tuples from R ◦D-COLS|R| along with their negations. It
can be veriﬁed that the set of these four tuples then is indeed closed under the
function f, and hence under D = Pol (R).
□
From the earlier Example 4.10, we know that this is not an “optimal” weak base
for the coclone Inv (D), since we there showed that this co-clone has core-size
1. Hence, from Theorem 4.11 it follows that f({0, 1} -COLS1) already is a weak
base for Inv (D). Since {0, 1} -COLS1 is the relation {(0, 1)}, it follows that the
closure of this relation under f, which can be veriﬁed to be the relation R, is a
weak base for Inv (D). Therefore, there is an

R[ext], =

-formula expressing R.
It can be veriﬁed that the formula R[ext](x, y, x, x, y, y) indeed expresses R. On

Partial Polymorphisms and Constraint Satisfaction Problems
245
the other hand, since R[ext] is the extension of R, we know that R[ext] ∈⟨R⟩∄,
and therefore there must be an {R, =}-formula expressing R[ext]. It can be seen
that R[ext](a, b, c, d, e, f) is equivalent to R(a, b) ∧(a = d) ∧(b = e) ∧R(c, f).
The fact that the equality relation is not actually required to express R with
the relation R[ext] is not a coincidence. We will give some more details on this
in Section 5.
We now return to the question commented on in the introduction: When can
the ⟨.⟩-operator be applied? Our weak bases are in a certain way the “easiest”
constraint languages among those with the same sets of polymorphisms. On the
other hand, the entire co-clone Inv (C) certainly is a “hardest” set of relations
with polymorphisms C. For the Boolean case, we have another option of “hard-
est” bases: In [CKZ05], Creignou, Kolaitis, and Zanuttini constructed, for each
Boolean clone C, a set of relations ΓC such that every constraint language Γ with
Pol(Γ) = C is contained in ⟨ΓC⟩∄. These sets are in most cases not ﬁnite, but
they are highly uniform, for example consisting of all relations ORm for every
possible arity m. In the following, assume that for each clone C over an arbitrary
domain, the set ΓC is some ﬁxed set satisfying Inv (C) = ⟨ΓC⟩∄and Pol (ΓC) = C.
We are now in a position to state a characterization which tells us exactly
when the usual closure operator can be applied to a given problem.
Theorem 4.18. Let ≤be a transitive complexity reduction, let Problem be a
computational problem for constraint formulas such that ⟨.⟩∄can be applied to
Problem. Then the following statements are equivalent:
1. ⟨.⟩can be ≤-applied to Problem
2. For every constraint language Γ, every ﬁnite subset Γ ′ of ΓPol(Γ), and every
weak base Γw of ⟨Γ⟩, Problem (Γ ′) ≤-reduces to Problem (Γw).
Note that the second point of the theorem is equivalent to saying that there
is some weak base Γw of ⟨Γ⟩for which the condition holds: Since ⟨.⟩∄can be
≤-applied to Problem, all weak bases of ⟨Γ⟩lead to the same complexity.
Proof. First assume that ⟨.⟩can be ≤-applied to Problem, let Γ be a constraint
language, let R be a weak base of ⟨Γ⟩, and let Γ ′ be a ﬁnite subset of ΓPol(Γ).
In particular, this implies that Pol (Γ ′) ⊇Pol (Γ) = Pol (R). Since ⟨.⟩can be
≤-applied to Problem, this implies that Problem (Γ ′) ≤Problem (R).
For the other direction, assume that for Γ ′ and R with the required proper-
ties, Problem (Γ ′) always reduces to Problem (R), and let Γ1 and Γ2 be constraint
languages such that Pol(Γ2) ⊆Pol(Γ1). We need to show that Problem (Γ1) ≤
Problem (Γ2). For i = 1, 2, let Ci := Pol (Γi). Since Pol(Γ2) is a subset of
Pol(Γ1), we know that Γ1 ⊆⟨Γ2⟩⊆⟨ΓC2⟩∄. Since Γ1 is ﬁnite, there exists
a ﬁnite subset Γ ′ of ΓC2 such that Γ1 ⊆⟨Γ ′⟩∄. Since ⟨.⟩∄can be ≤-applied
to Problem, this implies that Problem (Γ1) ≤Problem (Γ ′). Let R be a weak
base of Inv (C2). Due to the prerequisites, since Γ ′ is a ﬁnite subset of ΓC2,
we know that Problem (Γ ′) ≤Problem (R). Since R is a weak base of Inv (C2),
Corollary 4.4 implies that Problem (R) ≤Problem (Γ2). Therefore we have that
Problem (Γ1) ≤Problem (Γ ′) ≤Problem (R) ≤Problem (Γ2), and since ≤is tran-
sitive, it follows that Problem (Γ1) ≤Problem (Γ2), as required.
□

246
H. Schnoor and I. Schnoor
For the Boolean case, when working with the sets ΓC from [CKZ05], the ﬁnite
subsets of ΓPol(Γ) appearing in the above constructions are of a very regular
form: Since the sets ΓPol(Γ) are uniform sets of relations containing, for example,
the relation OR of arbitrary arities, for the arbitrary ﬁnite subsets it suﬃces to
consider subsets containing, for example, all OR-relations up to some ﬁnite arity.
5
The Equality Relation
Up to now, we only considered the closure operator ⟨.⟩∄, and showed that our
weak bases give rise to the problems of the lowest complexity among those gen-
erating the same co-clone. We now show how these techniques can be applied
to the more restricted operator ⟨.⟩∄,̸=. In order to do this, we need to consider
a technical property of relations, which is closely related to the introduction of
equality clauses in the closure operator ⟨.⟩∄.
Deﬁnition 5.1. Let R be an n-ary relation over the ﬁnite domain D. We say
that R is =-redundant, if there are two identical columns in the matrix represen-
tation of R. We say that R is ⊤-redundant if there is 1 ≤i ≤n such that for all
β, β′, α1, . . . , αi−1, αi+1, . . . , αn ∈D, it holds (α1, . . . , αi−1, β, αi+1, . . . , αn) ∈R
if and only if (α1, . . . , αi−1, β′, αi+1, . . . , αn) ∈R. In this case we also say that
the i-th column of R is ⊤-redundant. We say that R is redundant if it is =-
redundant or ⊤-redundant.
Redundant relations play a role in connection with the =-operator which is
allowed in two of our closure operators: It is obvious that any non-empty relation
which is deﬁned with a formula containing a non-tautological equality clause is
=-redundant. In particular, the equality relation itself is obviously redundant.
The following proposition is obvious:
Proposition 5.2. Let Γ be a constraint language, and let R be an =-irredundant
relation such that R ∈⟨Γ⟩∄. Then R ∈⟨Γ ∪{⊤}⟩∄,̸=.
Proof. Since R ∈⟨Γ⟩∄, we know that there is a Γ ∪{=}-formula which represents
R, and hence there also is a Γ ∪{=, ⊤}-formula ϕ representing R with a minimal
number of equality clauses. If no equality clause occurs in ϕ, then by deﬁnition
R ∈⟨Γ ∪{⊤}⟩∄,̸=. Therefore assume that a clause xi = xj occurs in ϕ. If
i = j, then the clause is obviously tautological and can be replaced with ⊤(xi),
a contradiction to the minimality of ϕ. Hence assume i ̸= j. Then in every
solution I of ϕ, I(xi) and I(xj) have the same value, and since ϕ represents
R, we know that the i-th component and the j-th component of every tuple
in R have the same value. Since i ̸= j, then this is a contradiction, since R is
irredundant.
□
Since obviously, D-COLSs is =-irredundant for any domain D and any number s,
it follows that all relations of the form C (COLSs) are =-irredundant. Therefore,
we obtain the following result:

Partial Polymorphisms and Constraint Satisfaction Problems
247
Corollary 5.3. Let C be a clone, and let Inv (C) have core-size s. Then for every
constraint language Γ with Pol (Γ) = C, it holds that C (COLSs) ∈⟨Γ ∪⊤⟩∄,̸=.
Proof. By Theorem 4.11, we know that pPol (C (COLSs)) = I∪(C). Therefore,
from Corollary 4.3, we know that C (COLSs) ∈⟨Γ⟩∄. Since C (COLSs) is =-
irredundant, Proposition 5.2 implies the result.
□
It can easily be seen that there are co-clones where weak bases of the form
C (COLSs) are not ⊤-irredundant (the co-clones corresponding to the Boolean
clones containing all functions f satisfying f(0, . . . , 0) = 0, or all functions f
with f(1, . . . , 1) are two examples). There are several ways to deal with this
problem. One possibility is to allow a constraint formula to formally depend on
variables which do not appear in any clause, which is equivalent to allowing the
⊤-operator in every Γ-formula regardless of the constraint language. A more
satisfying solution is to remove the redundancy from the relations.
Deﬁnition 5.4. Let R be an =-irredundant relation over a ﬁnite domain D,
where R is not of the form Dn for any n. Then the irredundant core of R is
obtained from R by deleting all ⊤-redundant columns from its matrix represen-
tation.
Example 5.5. Let R0 be the Boolean clone generated by the set {∧, ⊕}. It
can be veriﬁed that R0 contains exactly those Boolean functions f for which
f(0, . . . , 0) = 0 holds, and that the minimal core size of Inv (R0) is 1. The weak
base R0 (COLS1) of Inv (R0) is the relation R := {(0, 0), (0, 1)}, and hence it is
⊤-redundant in the second column. Its irredundant core is therefore the relation
{(0)}, which can be represented by the formula R(x, x).
Since the relations of the form C (COLSs) are =-irredundant, their irredundant
cores therefore neither need the equality nor the ⊤-relation to be represented.
Therefore, they form the analog of weak bases for the ⟨.⟩∄,̸=-operator:
Corollary 5.6. Let OPD ̸= C be a clone over a ﬁnite domain D and let s be
a core-size of Inv (C). Let R be the irredundant core of C (COLSs). Then for
all constraint languages Γ with Pol(Γ) = C, it holds that R ∈⟨Γ⟩∄,̸=. Further,
Pol(R) = C.
Proof. Let Γ be a constraint language with Pol (Γ) = C. From Theorem 4.11,
we know that C (COLSs) is a weak base of Inv (C). Since C does not contain all
functions from OPD, we know that C (COLSs) cannot be of the form Dn, since
this relation clearly is invariant under all functions from OPD. It is obvious that
pPol (R) = pPol(C (COLSs)), and hence R also is a weak base of Inv (C), in par-
ticular it follows that Pol (R) = C. From Corollary 4.3, we therefore know that
R ∈⟨Γ⟩∄. Since C (COLSs) is trivially =-irredundant, and R is the irredundant
core of this relation, we know that R is =-irredundant. Therefore, from Proposi-
tion 5.2, we know that R ∈⟨Γ ∪{⊤}⟩∄,̸=. Therefore, there is a Γ ∪{⊤}-formula
ϕ expressing R. By construction, R is ⊤-irredundant, and hence all appearing
⊤-clauses in ϕ can be removed without changing the relation expressed by ϕ.
Therefore, we can assume that ϕ is a Γ-formula, and hence R ∈⟨Γ⟩∄,̸=, as
claimed.
□

248
H. Schnoor and I. Schnoor
Corollary 5.6 shows that the irredundant cores of our weak bases of the form
C (COLSs) are the exact analog of weak bases for the ⟨.⟩∄,̸=-operator: Just like
the weak bases for the ⟨.⟩∄-operator, they represent the “easiest” cases among
the constraint languages with the same co-clone. The following summarizes the
complexity behavior of interest to us:
Corollary 5.7. Let Problem be a problem such that ⟨.⟩∄,̸= can be ≤-applied to
Problem. Let OPD ̸= C be a clone over the ﬁnite domain D such that Inv (C)
has core-size s, and let R be the irredundant core of C (COLSs) . Then for any
constraint language Γ with Pol (Γ) = C, it holds that Problem (R) ≤Problem (Γ) .
Finally, the analogous statement of Theorem 4.18 obviously also holds for the
closure operator ⟨.⟩∄,̸= instead of ⟨.⟩∄. The bases from [CKZ05] are also bases
for the corresponding co-clone with regard to the closure operator ⟨.⟩∄,̸=.
6
Applications
For problems where the complexity of the problem does not only depend on the
set of total polymorphisms, like enumeration for the non-Boolean case [SS06], it
is obvious that for a classiﬁcation it is necessary to look into the partial clones,
which constitute a reﬁnement of the clone lattice. However, as we mentioned in
Theorem 2.3 and the surrounding discussion, there are many cases where the
closure operator ⟨.⟩can be applied, but this only follows from a full complexity
classiﬁcation of the problem.
For the already-mentioned problems ENUM and EQUIV, we show how our
methods can be used to obtain a full complexity classiﬁcation. We will only
cover the hardness proofs of the considered problems in detail, and just give a
rough idea of how the polynomial time algorithms work, because the purpose of
this paper is to explain how our techniques can be applied to these problems.
For the enumeration problem, the ⟨.⟩∄-operator can be applied, and hence we
can work with the extension of a relation, R[ext]. For the equivalence problem,
this is not obvious. Therefore we work with the ⟨.⟩∄,̸=-closure and hence with
irredundant weak bases of the form C (COLSs) .
Since we consider these problems over the Boolean domain only, we give some
background on the Boolean case, in which a full list of all clones is known
[Pos41]. For a Boolean constraint language Γ, we say that Γ is Schaefer if
Γ has a polymorphism which depends on at least two variables. Using this ter-
minology, we can state a version of Schaefer’s theorem. Note that the problem
CSP (Γ ∪{{(0)} , {(1)}}) is the problem to determine whether a given Γ-formula
which also may contain clauses like x = 0 or y = 1 is satisﬁable. This problem
also is known as the “satisﬁability problem with constants.”
Theorem 6.1 ([Sch78]). Let Γ be a constraint language over the Boolean do-
main. If Γ is Schaefer, then CSP (Γ ∪{{(0)} , {(1)}}) can be solved in polynomial
time. Otherwise, this problem is NP-complete under ≤log
m -reductions.

Partial Polymorphisms and Constraint Satisfaction Problems
249
This version of Schaefer’s theorem covers almost all of the tractable cases of
CSP (Γ), the only additional cases are the trivial ones: if the constant 0- or 1-
function is a polymorphism of Γ, then every Γ-formula is trivially satisﬁable by
the all-0-vector or the all-1-vector.
The clone N contains all Boolean functions which are either constant or de-
pend only on one variable, i.e., constants, projections, and negation. The clone
N2 contains all non-constant functions from N. The clone I contains both con-
stants and the projections, I1 (I0) contains the projections and the constant 1
(the constant 0), and ﬁnally I2 contains only the projections. It is easy to see
that a constraint language Γ is not Schaefer if and only if its polymorphism
set is one of the above-deﬁned clones, and all of these clones are subsets of N.
The Schaefer property is essential in the case of Boolean constraint languages,
because for many problems, the tractable instances are exactly those which are
Schaefer.
6.1
Enumeration
An eﬃcient enumeration algorithm enumerates, given a formula ϕ, the set of
solutions of ϕ such that the time between the printing of the ﬁrst solution, the
time between the printing of each two consecutive solutions, and between the
printing of the ﬁnal solution and the termination of the algorithm is bounded
by a polynomial in the input. In order to obtain a complexity classiﬁcation of
this problem, we use CSP∗as an intermediate problem, which is the problem to
decide whether a propositional formula has a solution which is not constant. We
ﬁrst note that the ⟨.⟩∄-operator can be applied to CSP∗—this is trivial for the
⟨.⟩∄,̸=-operator, but applying the stronger closure operator requires an additional
argument.
Proposition 6.2. ⟨.⟩∄can be ≤log
m -applied to CSP∗.
Proof. Let Γ1 ⊆⟨Γ2⟩∄. We show CSP∗(Γ1) ≤log
m CSP∗(Γ2) . If every Γ2-formula
only has constant solutions, there is an a such that all relations in Γ2 contain
only the (a, . . . , a)-tuple. Since we can transform Γ1-formulas into equivalent
(Γ2 ∪{=})-formulas, it follows that CSP∗(Γ1) ∈LOGSPACE. Hence assume
that this case does not occur.
For a Γ1-formula ϕ, we can compute an equivalent (Γ2 ∪{=})-formula ϕ′.
In ϕ′, identify variables connected with equality clauses, and replace (x = x)
with ⊤(x). Remove ⊤(x) if x appears in a non-equality clause. Then ϕ has a
non-constant solution if and only if ϕ′ has one. If no clause ⊤(x) occurs in ϕ′,
then ϕ′ is the desired Γ2-formula. Otherwise, x is irrelevant for ϕ, and thus ϕ
has a non-constant solution if and only if it has a solution at all. Let ψ be a
Γ2-formula such that ψ does not only have constant solutions, and such that
VAR (ψ) ∩VAR (ϕ′) = ∅. Then ϕ has a solution if and only if ϕ′ has a solution,
if and only if ϕ′ ∧ψ has a non-constant solution, completing the reduction.
□
In [CH97], the following result was shown using a number of technical implemen-
tation results. We now show how this theorem can be proven in a much simpler
way, using the tools introduced in Section 4.

250
H. Schnoor and I. Schnoor
Theorem 6.3. Let Γ be a ﬁnite constraint language such that Γ is not Schaefer.
Then CSP∗(Γ) is NP-complete under ≤log
m -reductions.
Proof. It is obvious that the problem is in NP. For Γ = {R1, . . . , Rn} let
R = R1×· · ·×Rn. Since CSP∗(R) ≤log
m CSP∗(Γ), we can assume Γ = {R} with-
out loss of generality. We show CSP ({R, {(0)} , {(1)}}) ≤log
m CSP∗
R[ext]
≤log
m
CSP∗(R) . For the ﬁrst reduction let
ϕ =
k	
i=1
R(xi
1, . . . , xi
r)
l	
i=1
yi
m
	
i=1
zi
for not necessarily distinct variables xi
j, yi, zi (the variables yi and zi are the ones
appearing in the {(0)} and {(1)}-constraints). We construct an R[ext]-formula
ψ. If {y1, . . . , yl} ∩{z1, . . . , zm} ̸= ∅we set ψ = R[ext](x, . . . , x), otherwise we
deﬁne
ψ =
k	
i=1
R[ext](x′i
1 , . . . , x′i
r , f, wi
1, . . . , wi
2|R|−2, t),
with x′i
j =
⎧
⎪
⎨
⎪
⎩
t
if xi
j ∈{y1, . . . , yl},
f
if xi
j ∈{z1, . . . , zm},
xi
j
otherwise.
for new distinctive variables t, f, and
wi
j for 1 ≤i ≤k and 1 ≤j ≤2|R| −2.
By construction of R[ext], for every (v1, . . . , vr) ∈R there are t1, . . . , t2|R|−2 ∈
{0, 1} such that (v1, . . . , vr, 0, t1, . . . , t2|R|−2, 1) is an element of R[ext]. Therefore
every truth assignment for ϕ can be extended to a non-constant solution for ψ.
Now let ψ have a non-constant solution I. Then there must be a clause in ψ
such that I restricted to the variables appearing in the clause is non-constant
(otherwise I would be constant because t appears in every clause). Since Γ is
not Schaefer, Pol (Γ) = Pol(R) ⊆N.
Case: Pol (R) ∈{I, I0, I1, I2}. If R[ext] has elements where the last 2|R| values
are all 0 or all 1, then that are the tuples (0, . . . , 0) and (1, . . . , 1). In all
other tuples the (r + 1)-st value, which in all clauses of ψ is addressed by f,
is 0 and the last value, addressed by t, is 1. Since I is non-constant for some
clause in ψ, that means that I(f) = 0 and I(t) = 1.
Case: Pol (R) ∈{N, N2}. Again the last 2|R| values of a tuple of R[ext] can be
all equal only if all values of the tuple are equal. In all other elements the
(r+1)-st and the last value are not equal. Therefore it holds that I(f) ̸= I(t).
Since Pol

R[ext]
= Pol (R) ∈{N, N2}, it holds that R[ext] is complementive,
so we can assume I(f) = 0 and I(t) = 1 without loss of generality (otherwise
consider the solution I′ deﬁned by I′(x) = 1 iﬀI(x) = 0).
So, the assignment J deﬁned by J(x) =
⎧
⎪
⎨
⎪
⎩
I(t)
if x ∈{y1, . . . , yl}
I(f)
if x ∈{z1, . . . , zm}
I(x)
otherwise
is a solu-
tion for ϕ. Hence, ϕ is satisﬁable if and only if ψ ∈CSP∗
R[ext]
. The second

Partial Polymorphisms and Constraint Satisfaction Problems
251
reduction CSP∗
R[ext]
≤log
m CSP∗(R) is trivial since due to Proposition 4.16,
R[ext] ∈⟨R⟩∄, and ⟨.⟩∄can be ≤log
m -applied to CSP∗due to Proposition 6.2.
□
From this result, the complexity classiﬁcation for the enumeration problem easily
follows:
Corollary 6.4. Let Γ be a Boolean constraint language. If Γ is Schaefer, then
there exists an eﬃcient algorithm computing for each Γ-formula its set of solu-
tions. If Γ is not Schaefer, then such an algorithm does not exist, unless P = NP.
Proof. First assume that Γ is Schaefer. Due to Theorem 6.1, it follows that for
any Γ-formula ϕ with variables x1, . . . , xn, the questions if ϕ[x1/0] or ϕ[x1/1] are
satisﬁable can be solved in polynomial time. This easily gives an eﬃcient algo-
rithm to enumerate all satisfying assignments for ϕ, by recursively enumerating
the solutions for these two formulas, if they are satisﬁable.
Now assume that Γ is not Schaefer. Due to Theorem 6.3, we know that the
problem to determine for a given Γ-formula if it has a non-constant solution
is NP-complete. Obviously, any eﬃcient enumeration algorithm can be used to
answer this question. Hence, such an algorithm cannot exist, unless P = NP.
□
6.2
Equivalence and Implication
The equivalence problem, EQUIV (Γ), is the problem to decide whether two Γ-
formulas have the same set of solutions. This problem is obviously in coNP, and
can be shown to be truth-table reducible to the constraint satisfaction problem
for Γ-formulas with constants ([BHRV02]). Hence, the equivalence problem is
solvable in polynomial time if Γ is Schaefer due to Theorem 6.1. For the di-
chotomy, it remains to prove that the problem is coNP-hard in all other cases.
The result was originally proven by B¨ohler, Hemaspaandra, Reith, and Vollmer in
[BHRV02]. Again, we show how the proof can be simpliﬁed using our techniques
(note that the proof from [BHRV02] also relies on the complexity classiﬁcation
of CSP∗from [CH97]).
Our proof for the result on equivalence also classiﬁes the complexity of the
implication problem for constraint formulas: Let IMPL (Γ) be the problem to
decide, given Γ-formulas ϕ1 and ϕ2, if ϕ1 implies ϕ2. To our knowledge, this
problem has not yet been studied in the constraint context.
Theorem 6.5. Let Γ be a Boolean constraint language. If Γ is Schaefer, then
IMPL (Γ) and EQUIV (Γ) can be solved in polynomial time, otherwise they are
coNP-complete under ≤log
m -reductions.
Proof. Obviously, IMPL (Γ) ≤log
m EQUIV (Γ), since ϕ1 implies ϕ2 if and only if ϕ1
is equivalent to ϕ1 ∧ϕ2. Hence, it suﬃces to prove the polynomial time result for
equivalence and the hardness result for implication. The former follows from the
above-mentioned Turing reduction from EQUIV (Γ) to the constraint satisfaction
problem for Γ-formulas with constants. For the latter, let R be the Cartesian
product over all relations in Γ, then Pol(R) = Pol(Γ), and since IMPL (R) ≤p
m
IMPL (Γ), by Theorem 6.3, it suﬃces to show CSP∗(R) ≤log
m IMPL (R).

252
H. Schnoor and I. Schnoor
Let R′ := {0, 1} -COLS|R|, and R′′ := Pol(R) (R′) = Pol(R)

COLS|R|

.
By construction, the ﬁrst column of R′ contains only 0s, and the last column
contains only 1s. Since Γ is not Schaefer, R is not either, and thus not closed
under conjunction. Hence, R has at least two elements, and R′ is at least 4-ary.
Let ϕ be an R-formula containing at least 2 variables, and let x be a variable
from ϕ. For each variable y ∈VAR (ϕ), introduce a clause R′′(x, y, . . . , y, x),
and let ψ denote the conjunction of all these clauses. Due to Corollary 5.3,
R′′ ∈⟨R ∪⊤⟩∄,̸=. Therefore, ψ can be written as an {R, ⊤}-formula. We will
later see that ψ can in fact be written as an R-formula.
We show that ϕ has a non-constant solution if and only if ϕ does not imply ψ.
Note that ϕ and ψ have the same constant solutions: The constant c-assignment
is a solution for ϕ if and only if (c, . . . , c) ∈R if and only if c is a polymorphism
of R if and only if c is a polymorphism of R′′ (since Pol (R) = Pol (R′′)) if and
only if the constant c-assignment is a solution for ψ.
We prove that all solutions of ψ are constant. By construction of R′′, the
only tuples in R′′ where the ﬁrst and the last components are identical are
constant tuples: In the relation R′, the ﬁrst and the last components of each
tuple are diﬀerent. Since Pol (R) only contains injective functions and constants,
tuples in which these values are identical are only generated by the application
of constant polymorphisms. Therefore, every variable is assigned the same value
as x in every solution for ψ, i.e., ψ only has constant solutions. In particular,
since ψ has at least two variables, this implies that there can be no variable x
which only appears in a clause of the form ⊤(x). Therefore, all clauses of the
form ⊤(x) can be removed, and we can assume that ψ is an R-formula.
If ϕ has a non-constant solution, then ϕ obviously cannot imply ψ, since the
latter only has constant solutions. On the other hand, if ϕ only has constant so-
lutions, then ϕ implies ψ, since they have the same constant solutions. Therefore,
the reduction is complete.
□
7
Conclusion and Future Research
We have shown that the reﬁnement of the usual Galois connection to partial
polymorphisms can be applied to give easier proofs for complexity classiﬁcations
over the Boolean domain. By constructing weak bases, we have exhibited nat-
ural relations such that it is suﬃcient to prove hardness results for these, thus
addressing a common diﬃculty in many proofs of complexity classiﬁcations for
constraint-related problems.
We believe that our techniques can be used for classiﬁcations of the complex-
ity of many problems in the constraint context where it cannot be shown in a
straightforward way that the ⟨.⟩-operator can be applied. The next interesting
question in this line of research is the application of our tools to problems where
the ⟨.⟩operator cannot be applied at all. Here the weak bases can still be used
to give hardness results, and Theorem 4.18 can be used to determine the clones
which give rise to problems with diﬀerent complexity. Among other problems, we
believe that using these techniques, further results on the enumeration problem
for non-Boolean domains can be achieved.

Partial Polymorphisms and Constraint Satisfaction Problems
253
Acknowledgments
We thank Marcel Ern´e, Boris Romov, and Gustav Nordh for hints and discus-
sions. We also thank the anonymous referee for helpful suggestions and improve-
ments.
References
[ABI+05]
Allender, E., Bauland, M., Immerman, N., Schnoor, H., Vollmer, H.: The
complexity of satisﬁability problems: Reﬁning schaefer’s theorem. In: Pro-
ceedings of the 30th International Symposium on Mathematical Founda-
tions of Computer Science, pp. 71–82 (2005)
[AV94]
Alekseev, V., Voronenko, A.: On some closed classes in partial two-valued
logic. Discrete Mathematics and Applications 4(5), 401–419 (1994)
[BCRV04]
B¨ohler, E., Creignou, N., Reith, S., Vollmer, H.: Playing with Boolean
blocks, part II: Constraint satisfaction problems. SIGACT News 35(1),
22–35 (2004)
[BHRV02]
B¨ohler, E., Hemaspaandra, E., Reith, S., Vollmer, H.: Equivalence and
isomorphism for Boolean constraint satisfaction. In: Bradﬁeld, J.C. (ed.)
CSL 2002 and EACSL 2002. LNCS, vol. 2471, pp. 412–426. Springer, Hei-
delberg (2002)
[BKKR69]
Bodrarchuk, V., Kaluzhnin, L., Kotov, V., Romov, B.: Galois theory for
Post algebras i. Kibernetika 5(3), 1–10 (1969)
[BRSV05]
B¨ohler, E., Reith, S., Schnoor, H., Vollmer, H.: Bases for Boolean co-clones.
Information Processing Letters 96, 59–66 (2005)
[Bul06]
Bulatov, A.: A dichotomy theorem for constraint satisfaction problems on
a 3-element set. Journal of the ACM 53(1), 66–120 (2006)
[CH97]
Creignou, N., H´ebrard, J.: On generating all solutions of generalized sat-
isﬁability problems. Informatique Th´eorique et Applications/Theoretical
Informatics and Applications 31(6), 499–511 (1997)
[CKZ05]
Creignou, N., Kolaitis, P., Zanuttini, B.: Preferred representations of
Boolean relations. Technical Report TR05-119, Electronic Colloquium on
Computational Complexity, ECCC (2005)
[CV08]
Creignou, N., Vollmer, H.: Boolean Constraint Satisfaction Problems. In:
Creignou, N., Kolaitis, P.G., Vollmer, H. (eds.) Complexity of Constraints.
LNCS, vol. 5250. Springer, Heidelberg (2008)
[Gei68]
Geiger,
D.:
Closed
systems
of
functions
and
predicates.
Pac.
J.
Math. 27(1), 95–100 (1968)
[Jea98]
Jeavons, P.: On the algebraic structure of combinatorial problems. Theo-
retical Computer Science 200, 185–204 (1998)
[Lad75]
Ladner, R.: On the structure of polynomial-time reducibility. Journal of
the ACM 22, 155–171 (1975)
[Lau06]
Lau, D.: Function Algebras on Finite Sets: Basic Course on Many-Valued
Logic and Clone Theory (Springer Monographs in Mathematics). Springer,
New York (2006)
[Pos41]
Post, E.: The two-valued iterative systems of mathematical logic. Annals
of Mathematical Studies 5, 1–122 (1941)
[Rom81]
Romov, B.: The algebras of partial functions and their invariants. Cyber-
netics and Systems Analysis 17(2), 157–167 (1981)

254
H. Schnoor and I. Schnoor
[Sch78]
Schaefer, T.: The complexity of satisﬁability problems. In: Proceedings
10th Symposium on Theory of Computing, pp. 216–226. ACM Press, New
York (1978)
[SS06]
Schnoor, H., Schnoor, I.: Enumerating all solutions for constraint satisfac-
tion problems. In: Creignou, N., Kolaitis, P., Vollmer, H. (eds.) Complexity
of Constraints, number 06401 in Dagstuhl Seminar Proceedings. Inter-
nationales Begegnungs- und Forschungszentrum fuer Informatik (IBFI),
Schloss Dagstuhl, Germany (2006)

Introduction to the Maximum Solution Problem
Peter Jonsson1 and Gustav Nordh2
1 Department of Computer and Information Science, Link¨opings Universitet
S-581 83 Link¨oping, Sweden
petej@ida.liu.se
2 Laboratoire d’Informatique, ´Ecole Polytechnique
F-91128 Palaiseau, France
nordh@lix.polytechnique.fr
Abstract. This paper surveys complexity and approximability results
for the Maximum Solution (Max Sol) problem. Max Sol is an opti-
misation variant of the constraint satisfaction problem. Many important
and well-known combinatorial optimisation problems are instances of
Max Sol: for example, Max Sol restricted to the domain {0, 1} is ex-
actly the Max Ones problem (which, in turn, captures problems such
as Independent Set and 0/1 Integer Programming). By using this
relationship, many diﬀerent problems in logic, graph theory, integer pro-
gramming, and algebra can be given a uniform treatment. This opens
up for new ways of analysing and solving combinatorial optimisation
problems.
1
Introduction
A large number of natural optimisation problems can be viewed as instances of
the Maximum Solution (Max Sol) problem. In this survey, we will describe
the problem and present complexity and approximability results. This section
provides the formal deﬁnition together with some background information. Some
additional material on approximability and universal algebra can be found in
Section 2. All results for Max Sol on Boolean domains are collected in Section 3.
In order to familiarise the reader with the basic tools, Section 3 also contains
a derivation of new, sharper inapproximability bounds for the Boolean Max
Sol problem. Sections 4–9 contain results for the Max Sol problem on non-
Boolean domains; the examples come from many diﬀerent areas such as logic,
graph theory, and algebra. To make the survey more readable, we devote the
ﬁrst of these sections to two general tractability results. The Max Sol problem
is compared to other optimisation formalisms in Section 10, and some open
questions are posed in Section 11.
1.1
Background and Basic Assumptions
We introduce Max Sol by ﬁrst considering the well-known Max Ones prob-
lem [35]: an instance of Max Ones consists of constraints applied to a number
N. Creignou et al. (Eds.): Complexity of Constraints, LNCS 5250, pp. 255–282, 2008.
c
⃝Springer-Verlag Berlin Heidelberg 2008

256
P. Jonsson and G. Nordh
of Boolean variables, and the goal is to ﬁnd an assignment that satisﬁes all con-
straints while maximising the number of variables set to 1. The only diﬀerence
between Max Ones and Max Sol is that we do not require the domain of the
variables to be Boolean—the domain of the variables in Max Sol are allowed to
be any subset of the natural numbers, and the objective is to ﬁnd an assignment
that satisfy all the constraints and that maximise the sum of the variables. We
parameterise the problem according to the set of allowed constraint types, i.e.
for any set Γ of relations, Max Sol(Γ) denotes the set of problems where the
constraint types are restricted to Γ. The main goal of this survey is to present
complexity and approximability results for Max Sol(Γ) under diﬀerent choices
of Γ.
Let us now take a look at the maximisation problem Integer Program-
ming:
Instance: m × n matrix A of rationals, m-vector b of rationals, and n-vector c
of rationals.
Solution: An n-vector x of integers such that Ax ≥b and x ≥0;
Measure: cT x.
Obviously, one can view the integer programming problem as a Max Sol(Γ)
problem for a certain constraint language Γ over the integers. However, we will
restrict ourselves to a certain subclass of Max Sol problems in this survey;
in fact, this class do not contain Integer Programming. The restrictions
we encompass are two ﬁniteness conditions: we only consider ﬁnite domains
and ﬁnite constraint languages. This enables us to use algebraic techniques for
studying Max Sol.
The ﬁniteness conditions do not prevent us from capturing interesting prob-
lems, though. It is easy to see that Max Sol over the domain {0, 1} captures, for
instance, Max Independent Set (problem GT23 in [2]), and certain variants
of Max 0/1 Programming (problem MP2 in [2]). There are also many inter-
esting non-Boolean Max Sol problems: examples include problems in integer
programming [25], multiple-valued logic [33], and equation solving over Abelian
groups [36].
Only considering ﬁnite constraint languages may seem quite restrictive but,
in many cases, it is not. Consider for instance integer programming over the
bounded domain {0, . . . , d −1}, i.e., the size of the domain is bounded by a
constant but the length of the inequalities are not. Each row in the constraint
matrix can be viewed as an inequality
a1x1 + a2x2 + . . . + akxk ≥b.
Obviously, such an inequality is equivalent to the following three inequalities
a1x1 + a2x2 + . . . + a⌊k/2⌋x⌊k/2⌋−z ≥0
−a1x1 −a2x2 −. . . −a⌊k/2⌋x⌊k/2⌋+ z ≥0
z + a⌊k/2⌋+1 + . . . + akxk ≥b
where z denotes a fresh variable that is given the weight 0 in the objective
function. By repeating this process, one ends up with a set of inequalities where

Introduction to the Maximum Solution Problem
257
each inequality contains at most three variables, and the optimal solution to
this instance have the same measure as the original instance. There are at most
2d + 2d2 + 2d3 diﬀerent relations (and thus inequalities) of length ≤3 on a
d element domain. Since the size of the domain is constant, we have reduced
the problem to one with a ﬁnite constraint language. Finally, this reduction is
polynomial-time: each inequality of length k in the original instance give rise to
at most 3⌈log2 k⌉= O(k2) inequalities and at most O(k2) new variables.
The restriction to ﬁnite domains appears to be more problematic since it
provably excludes certain prominent problems (such as unbounded Integer
Programming). There has been some eﬀorts lately in order to make the al-
gebraic framework applicable to inﬁnite-domain problems [4]. To the best of
our knowledge, such extended methods have not been applied to the Max Sol
problem.
1.2
Formal Deﬁnition
Let us now formally deﬁne Max Sol: let D ⊂N (the domain) be a ﬁnite set.
The set of all n-tuples of elements from D is denoted by Dn. Any subset of
Dn is called an n-ary relation on D. The set of all ﬁnitary relations over D
is denoted by RD. A constraint language over a ﬁnite set, D, is a ﬁnite set
Γ ⊆RD. Constraint languages are the way in which we specify restrictions on
our problems. The constraint satisfaction problem over the constraint language
Γ, denoted Csp(Γ), is deﬁned to be the decision problem with instance (V, D, C),
where
– V is a set of variables,
– D is a ﬁxed ﬁnite set of values (sometimes called a domain), and
– C is a set of constraints {C1, . . . , Cq}, in which each constraint Ci is a pair
(si, Ri) where si is a list of variables of length mi, called the constraint
scope, and Ri is an mi-ary relation over the set D, belonging to Γ, called
the constraint relation.
The question is whether there exists a solution to (V, D, C) or not, that is, a
function from V to D such that, for each constraint in C, the image of the
constraint scope is a member of the constraint relation. To exemplify this def-
inition, let NAE be the following ternary relation on {0, 1}: NAE = {0, 1}3 \
{(0, 0, 0), (1, 1, 1)}. It is easy to see that the well-known NP-complete problem
Not-All-Equal 3-Sat can be expressed as Csp({NAE}).
The optimisation problem that we are going to study, Weighted Maximum
Solution(Γ) (which we abbreviate Max Sol(Γ)) is deﬁned as follows:
Instance: Tuple (V, D, C, w), where D is a ﬁxed ﬁnite subset of N, (V, D, C) is
a Csp(Γ) instance, and w : V →N is a weight function.
Solution: An assignment f : V →D to the variables such that all constraints
are satisﬁed.
Measure: 
v∈V
w(v) · f(v)

258
P. Jonsson and G. Nordh
Note that in the deﬁnition of the Max Sol(Γ)) problem, the domain D is part of
the input even though it is implicitly deﬁned by the constraint language Γ. From
a complexity point of view, this does not matter since the domain is deﬁned to
be a ﬁxed ﬁnite set and the size of the domain is constant.
We illustrate this deﬁnition with a simple example:
Example 1. Consider the domain D = {0, 1} and the binary relation R =
{(0, 0), (1, 0), (0, 1)}. Then, Max Sol({R}) is exactly the weighted Max In-
dependent Set problem.
Several related problems can be deﬁned along the same lines, e.g. Min Sol
where the objective is to minimise 
v∈V w(v) · f(v) and Max AW Sol where
we allow the weight function w to be a function from V to the integers Z. The
Boolean variants of these problems have been studied earlier [30,35]. Note that
for Boolean constraint languages Γ, the Max Sol(Γ) problem is usually denoted
Max Ones(Γ).
There are several aspects of the deﬁnition of Max Sol that can be discussed.
Below, we consider two points that have been questioned and/or criticised in the
past.
I. Choice of measure function. Note that our choice of measure function in
the deﬁnition of Max Sol(Γ) is just one of several reasonable choices. Another
reasonable alternative, used in [36], would be to let the domain D be any ﬁnite
set and introduce an additional function g : D →N mapping elements from the
domain to natural numbers. The measure could then be deﬁned as 
v∈V w(v) ·
g(f(v)). This would result in a parameterised problem Max Sol(Γ, g) where
the goal is to classify the complexity of Max Sol(Γ, g) for all combinations of
constraint languages Γ and functions g. Note that our deﬁnition of Max Sol(Γ)
is equivalent to the deﬁnition of Max Sol(Γ, g) if in addition g is required to be
injective. Our main motivation for the choice of measure function is to stay close
to integer programming and Max Ones. However, we will use the alternative
deﬁnition when studying equations over Abelian groups in Section 7.
II. Weighted vs. unweighted problems. We remark that we do not deal
explicitly with the unweighted version of the problem (in the unweighted version,
all variables have weight 1). The correspondence, in terms of approximability,
between the weighted and unweighted versions of the problem has already been
discussed in depth [13,35]. In summary, Khanna et al. [35] prove that if Max
Sol(Γ) is in poly-APX, then hardness results (for the weighted version) implies
the corresponding hardness results for the unweighted version. The basic idea of
the proof is to simulate weights by replication of variables.
Moreover, since all tractability results for Max Sol(Γ) (that we are aware of)
hold for the weighted version of the problem, it should be clear that the classiﬁ-
cations we report here also hold for the unweighted version of the Max Sol(Γ)
problem. But, in general, it is still open whether tractability for the unweighted
version implies tractability of the weighted version of the Max Sol(Γ) problem.
The correspondence between unweighted and weighted problems does not hold
if negative weights are allowed [30].

Introduction to the Maximum Solution Problem
259
1.3
Methods
The complexity and approximability of Max Ones(Γ) are completely known for
all choices of Γ [35]. For any Boolean constraint language Γ, Max Ones(Γ) is
either in PO or is APX-complete or poly-APX-complete or ﬁnding a solution
of non-zero value is NP-hard or ﬁnding any solution is NP-hard. The exact bor-
derlines between the diﬀerent cases are given in [35]. For larger domains, it seems
signiﬁcantly harder to obtain an exact characterisation of approximability than
in the Boolean case. Such a characterisation would, for instance, show whether
the dichotomy conjecture for constraint satisfaction problems is true or not –
a famous open question which is believed to be diﬃcult [16]. Hence, it seems
reasonable to study restricted (but as general as possible) families of constraint
languages where the complexity and approximability can be determined. In do-
ing so, the algebraic approach appears to be indispensable. When the algebraic
approach is applicable to a certain problem, there is an equivalence relation on
the constraint languages such that two constraint languages which are equivalent
under this relation have the same complexity. More speciﬁcally, two constraint
languages are in the same equivalence class if they generate the same relational
clone. The relational clone generated by Γ, captures the expressive power of Γ
and is denoted by ⟨Γ⟩. Hence, instead of studying every possible ﬁnite set of
relations it is enough to study the relational clones.
The algebraic approach is known to be applicable to Max Sol. In fact, it is
known that constraint languages Γ1 and Γ2 such that ⟨Γ1⟩= ⟨Γ2⟩, then Max
Sol(Γ1) S-reduces to Max Sol(Γ2), and vice-versa. An S-reduction is a certain
strong approximation-preserving reduction: if ⟨Γ1⟩= ⟨Γ2⟩, then Γ1 and Γ2 are
very similar with respect to approximability. For instance, if Max Sol(Γ1) is
NP-hard to approximate within some constant c, then Max Sol(Γ2) is NP-
hard to approximate within c, too. We note that the clone-theoretic approach
was not used in the original classiﬁcation of Max Ones.
2
Preliminaries
The purpose of this section is to provide a brief overview of approximability
and the algebraic approach. We refer the reader to [2] for a deeper treatment of
approximability and to [7,41] for a deeper treatment of the algebraic approach.
2.1
Approximability, Reductions, and Completeness
A combinatorial optimisation problem is deﬁned over a set of instances (admis-
sible input data); each instance I has a ﬁnite set sol(I) of feasible solutions
associated with it. Given an instance I and a feasible solution s of I, m(I, s)
denotes the positive integer measure of s. The objective is, given an instance I,
to ﬁnd a feasible solution of optimum value with respect to the measure m. The
optimal value is the largest one for maximisation problems and the smallest one
for minimisation problems. A combinatorial optimisation problem is said to be
an NPO problem if its instances and solutions can be recognised in polynomial

260
P. Jonsson and G. Nordh
time, the solutions are polynomially bounded in the input size, and the objective
function can be computed in polynomial time (see, e.g., [2]).
We say that a solution s ∈sol(I) to an instance I of an NPO problem Π is
r-approximate if it is satisfying
max
m(I, s)
opt(I), opt(I)
m(I, s)
"
≤r,
where opt(I) is the optimal value for a solution to I. An approximation algo-
rithm for an NPO problem Π has performance ratio R(n) if, given any instance
I of Π with |I| = n, it outputs an R(n)-approximate solution.
We deﬁne PO to be the class of NPO problems that can be solved (to
optimality) in polynomial time. An NPO problem Π is in the class APX if
there is a polynomial-time approximation algorithm for Π whose performance
ratio is bounded by a constant. Similarly, Π is in the class poly-APX if there
is a polynomial-time approximation algorithm for Π whose performance ratio
is bounded by a polynomial in the size of the input. Completeness in APX
and poly-APX is deﬁned using appropriate reductions, called AP-reductions
and A-reductions, respectively [12,35]. AP-reductions are more sensitive than A-
reductions and every AP-reduction is also an A-reduction [35]. In this paper we
will not need the added ﬂexibility of A-reductions for proving our poly-APX-
completeness results. Hence, we only need the deﬁnition of AP-reductions.
Deﬁnition 2. An NPO problem Π1 is said to be AP-reducible to an NPO
problem Π2 if two polynomial-time computable functions F and G and a constant
α exist such that
(a) for any instance I of Π1, F(I) is an instance of Π2;
(b) for any instance I of Π1, and any feasible solution s′ of F(I), G(I, s′) is a
feasible solution of I;
(c) for any instance I of Π1, and any r ≥1, if s′ is an r-approximate solution
of F(I) then G(I, s′) is an (1 + (r −1)α + o(1))-approximate solution of I
where the o-notation is with respect to |I|.
In some cases we will use another kind of reduction, S-reductions. They are
deﬁned as follows:
Deﬁnition 3. An NPO problem Π1 is said to be S-reducible to an NPO prob-
lem Π2 if two polynomial-time computable functions F and G exist such that
(a) given any instance I of Π1, algorithm F produces an instance I′ = F(I) of
Π2, such that the measure of an optimal solution for I′, opt(I′), is exactly
opt(I).
(b) given I′ = F(I), and any solution s′ to I′, algorithm G produces a solution
s to I such that m1(I, G(s′)) = m2(I′, s′), where m1 is the measure for Π1
and m2 is the measure for Π2.
Obviously, the existence of an S-reduction from Π1 to Π2 implies the existence
of an AP-reduction from Π1 to Π2. The reason why we need S-reductions is

Introduction to the Maximum Solution Problem
261
that AP-reductions do not (generally) preserve membership in PO [35]. We also
note that S-reduction preserve approximation thresholds exactly for problems in
APX: let Π1, Π2 be problems in APX, assume that it is NP-hard to approx-
imate Π1 within c, and that there exists an S-reduction from Π1 to Π2. Then,
it is NP-hard to approximate Π2 within c, too.
2.2
Algebraic Approach
We begin by giving a number of basic deﬁnitions. An operation on a ﬁnite set
D (the domain) is an arbitrary function f : Dk →D. Any operation on D can
be extended in a standard way to an operation on tuples over D, as follows: let
f be a k-ary operation on D and let R be an n-ary relation over D. For any
collection of k tuples, t1, t2, . . . , tk ∈R, the n-tuple f(t1, t2, . . . , tk) is deﬁned as
follows: f(t1, t2, . . . , tk) = (f(t1[1], t2[1], . . . , tk[1]), f(t1[2], t2[2], . . . , tk[2]), . . . ,
f(t1[n], t2[n], . . . , tk[n])), where tj[i] is the i-th component in tuple tj. A tech-
nique that has been shown to be useful in determining the computational com-
plexity of Csp(Γ) is that of investigating whether the constraint language Γ is
invariant under certain families of operations [28].
Now, let Ri ∈Γ. If f is an operation such that for all t1, t2, . . . , tk ∈Ri
f(t1, t2, . . . , tk) ∈Ri, then Ri is invariant (or, in other words, closed) under f.
If all constraint relations in Γ are invariant under f then Γ is invariant under f.
An operation f such that Γ is invariant under f is called a polymorphism of Γ.
The set of all polymorphisms of Γ is denoted Pol(Γ). Given a set of operations
F, the set of all relations that are invariant under all the operations in F is
denoted Inv(F). Whenever there is only one operation under consideration, we
write Inv(f) instead of Inv({f}).
We will need a number of operations in the sequel: an operation f over D is
said to be
– a constant operation if f is unary and f(a) = c for all a ∈D and some
c ∈D;
– a majority operation if f is ternary and f(a, a, b) = f(a, b, a) = f(b, a, a) = a
for all a, b ∈D;
– a binary commutative idempotent operation if f is binary, f(a, a) = a for all
a ∈D, and f(a, b) = f(b, a) for all a, b ∈D;
– an aﬃne operation if f is ternary and f(a, b, c) = a −b + c for all a, b, c ∈D
where + and −are the binary operations of an Abelian group (D, +, −).
Example 4. Let D = {0, 1, 2} and let f be the majority operation on D where
f(a, b, c) = a if a, b and c are all distinct. Furthermore, let
R = {(0, 0, 1), (1, 0, 0), (2, 1, 1), (2, 0, 1), (1, 0, 1)}.
It is easy to verify that for every triple of tuples, x, y, z ∈R, we have f(x, y, z) ∈
R. For example, if x = (0, 0, 1), y = (2, 1, 1), and z = (1, 0, 1), then
f(x, y, z) =
%
f(x[1], y[1], z[1]), f(x[2], y[2], z[2]), f(x[3], y[3], z[3])
&
=

f(0, 2, 1), f(0, 1, 0), f(1, 1, 1)

= (0, 0, 1) ∈R.

262
P. Jonsson and G. Nordh
We can conclude that R is invariant under f or, equivalently, that f is a poly-
morphism of R.
We sometimes need to deﬁne relations in terms of other relations, using certain
logical formulas. In doing so, the algebraic approach provides a convenient tool.
A ﬁrst-order formula φ over a constraint language Γ is said to be primitive
positive (or pp-formula for short) if it is of the form
∃x : (R1(x1) ∧. . . ∧Rk(xk))
where R1, . . . , Rk ∈Γ and x1, . . . , xk are vectors of variables such that the arity
of Ri equals the length of the vector xi for all i. Note that a pp-formula φ with m
free variables deﬁnes an m-ary relation R ⊆Dm, denoted R ≡pp φ; the relation
R is the set of all m-tuples satisfying the formula φ.
We continue by deﬁning a closure operation ⟨·⟩on sets of relations: for any
set Γ ⊆RD the set ⟨Γ⟩consists of all relations that can be expressed using
relations from Γ ∪{=D} (=D is the equality relation on D), conjunction, and
existential quantiﬁcation, i.e. ⟨Γ⟩is the set of all relations that can be expressed
via pp-formulas over Γ. The sets of relations of the form ⟨Γ⟩are referred to as
relational clones. There is a very strong connection between a relational clone
⟨Γ⟩and the operators that Γ is invariant under:
Theorem 5 ([37]). For every set Γ ⊆RD, ⟨Γ⟩= Inv(Pol(Γ)).
The following result shows that the algebraic approach is applicable when study-
ing the approximability of Max Sol(Γ):
Theorem 6 ([33]). Let Γ be a constraint language and Γ ′ ⊆⟨Γ⟩ﬁnite. Then,
Max Sol(Γ ′) is S-reducible to Max Sol(Γ).
The concept of cores has been important when studying the complexity of Csp;
a constraint language is a core if every unary polymorphism is injective (i.e. a
permutation). We will use a related concept (that was introduced in [33]) when
studying Max Sol.
Deﬁnition 7. A constraint language Γ is a max-core if and only if there is no
non-injective unary operation f in Pol(Γ) such that f(d) ≥d for all d ∈D. A
constraint language Γ ′ is a max-core of Γ if and only if Γ ′ is a max-core and
Γ ′ = f(Γ) for some unary operation f ∈Pol(Γ) such that f(d) ≥d for all
d ∈D.
The constraint language {R} where R = {(0, 0), (1, 1), (2, 1), (1, 2)} is not a max-
core since it admits a unary polymorphism f : {0, 1, 2} →{0, 1, 2} deﬁned such
that f(0) = 1, f(1) = 1, and f(2) = 2. It is easy to see that {R′} is a max-core
of {R} where R′ = {(1, 1), (2, 1), (1, 2)}.
Lemma 8 ([33]). If Γ ′ is a max-core of Γ, then Max Sol(Γ) and Max
Sol(Γ ′) are polynomial-time equivalent.

Introduction to the Maximum Solution Problem
263
3
Boolean Domain
The Max Sol(Γ) problem over Boolean constraint languages Γ goes under the
name Max Ones(Γ) and the approximability for every ﬁnite Boolean constraint
language has been classiﬁed by Khanna et al. in [35]. Before stating this result,
we recall the following standard restrictions on Boolean constraint languages
(see, e.g. [12]).
Deﬁnition 9
– Γ is 0-valid if (0, 0, . . . , 0) ∈R for every relation R in Γ,
– Γ is 1-valid if (1, 1, . . . , 1) ∈R for every relation R in Γ,
– Γ is Horn if every relation R in Γ is the set of models of a CNF formula
having at most one unnegated variable in each clause,
– Γ is dual Horn if every relation R in Γ is the set of models of a CNF formula
having at most one negated variable in each clause,
– Γ is bijunctive if every relation R in Γ is the set of models of a CNF formula
having at most two literals in each clause,
– Γ is aﬃne if every relation R in Γ is the set of models of a system of linear
equations over GF(2), the ﬁeld with two elements,
– Γ is width-2 aﬃne if every relation R in Γ is the set of models of a system of
linear equations over GF(2) in which each equation has at most 2 variables.
Theorem 10 ([35]). Given a constraint language Γ over the Boolean domain
{0, 1},
– if Γ is 1-valid or dual-Horn or width-2 aﬃne, then Max Sol(Γ) is in PO;
– otherwise if Γ is aﬃne, then Max Sol(Γ) is APX-complete;
– otherwise if Γ is Horn or bijunctive, then Max Sol(Γ) is poly-APX-
complete;
– otherwise if Γ is 0-valid, then ﬁnding a solution of positive measure is NP-
hard;
– otherwise ﬁnding a feasible solution to Max Sol(Γ) is NP-hard.
We remark that Khanna et al.’s proof of the preceding theorem does not make
use of the algebraic approach via relational clones. The bulk of their proof is
spent on showing numerous explicit implementations/reductions between diﬀer-
ent constraint languages. The advantage of using the algebraic approach is that
there is no need to deal with these implementations/reductions explicitly.
In fact, it is quite easy to strengthen Khanna et al.’s result and give tight
approximability thresholds for Max Sol(Γ) over Boolean constraint languages.
Theorem 11. Given a constraint language Γ over {0, 1},
– if Γ is 1-valid or dual-Horn or width-2 aﬃne, then Max Sol(Γ) is in PO;
– otherwise if Γ is aﬃne, then Max Sol(Γ) is 2-approximable but not ap-
proximable to within 2 −ε for any ε > 0 unless P=NP;

264
P. Jonsson and G. Nordh
– otherwise if Γ is Horn or bijunctive, then Max Sol(Γ) is approximable to
within O(|V |) but not to within O(|V |1−ε) for any ε > 0 unless P = NP;
– otherwise if Γ is 0-valid, then ﬁnding a solution of positive measure is NP-
hard;
– otherwise ﬁnding a feasible solution to Max Sol(Γ) is NP-hard.
All the bounds except the 2 −ε hardness for aﬃne constraint languages (that
are not 1-valid) and the O(|V |1−ε)-hardness for Horn and bijunctive constraint
languages are proved in (or easily follows from) [35]. The 2−ε hardness for aﬃne
constraint languages consisting of relations expressed by equations on the form
{x1 + · · · + xk = c (mod 2) | k even, c ∈{0, 1}}
follows from a more general result due to Kuivinen [36]. The proof in [36] consists
of a gap preserving reduction from the problem Max-E3-Lin-2. Max-E3-Lin-2
is the following problem: given a set of equations over Z2 with exactly three
variables per equation, satisfy as many equations as possible. It is proved in [26]
that it is NP-hard to approximate Max-E3-Lin-2 within 2 −ε for any ε > 0.
The remaining aﬃne constraint languages that need to be classiﬁed consist of
relations expressed by equations on the form
{x1 + · · · + xk = 0 (mod 2) | k ∈N}.
The 2 −ε hardness for these constraint languages can be proved by modifying
the corresponding reduction in [36]. For more details, please consult [32].
The O(|V |1−ε)-hardness for Horn and bijunctive constraint languages (that
are neither 1-valid, nor dual-Horn, nor aﬃne) may seem trivial at ﬁrst sight since
Theorem 6 together with the inclusion structure among Boolean relational clones
tells us that there is an S-reduction from Max Independent Set to Max Sol
over any such constraint language. But please keep in mind that S-reductions do
not (in general) preserve instance size. For example, if Max Sol(Γ1) is NP-hard
to approximate within O(|V |) and there is an S-reduction from Max Sol(Γ1)
to Max Sol(Γ2) which blows up the instance size by a quadratic factor. Then,
this only implies that Max Sol(Γ2) is NP-hard to approximate within O(|V |2).
Hence, we cannot use the S-reduction implied by Theorem 6 directly since it
may increase instance sizes by a polynomial factor. Fortunately, it is possible
with some extra work to give an S-reduction from Max Independent Set
to Max Sol(Γ), which increase instance sizes by at most a factor 2, for Horn
and bijunctive constraint languages (that are neither 1-valid, nor dual-Horn,
nor aﬃne). In fact, in the Horn case it is possible to give an S-reduction which
only introduces two extra variables. Hence, the O(|V |1−ε)-hardness result follows
from the corresponding hardness result for Max Independent Set [26,44].
4
Tractability Results
In this section, we present tractability results for two classes of constraint lan-
guages: injective constraint languages and generalised max-closed constraint lan-
guages. These two classes includes almost all of the known tractable classes

Introduction to the Maximum Solution Problem
265
of constraint languages presented in the literature for this problem. In par-
ticular, they can be seen as substantial and nontrivial generalisations of the
tractable classes known for the corresponding Max Ones problem over the
Boolean domain. We have already (in Section 3) pointed out that there are
only three tractable classes of constraint languages over the Boolean domain:
width-2 aﬃne, 1-valid, and dual-Horn [35]. Width-2 aﬃne constraint languages
are examples of injective constraint languages and the classes of 1-valid and
dual-Horn constraint languages are examples of generalised max-closed con-
straint languages. The monotone constraints which are, for instance, studied
by Hochbaum et al. [24,25] (in relation with integer programming) and Woegin-
ger [42] (in relation with constraint satisfaction) are also related to generalised
max-closed constraints. Hochbaum & Naor [25] show that monotone constraints
can be characterised as those constraints that are simultaneously invariant under
the max and min operators. Hence, monotone constraints are also generalised
max-closed constraints as long as the underlying domain is ﬁnite.
4.1
Injective Relations
We begin by formally deﬁning injective relations.
Deﬁnition 12. A binary relation, R ∈RD, is called injective if there exists a
subset D′ ⊆D and an injective function π : D′ →D such that
R = {(x, π(x)) | x ∈D′}.
It is important to note that the function π is not assumed to be total on D. Let
ID denote the set of all injective relations on the domain D and let Γ D
I = ⟨ID⟩.
We say that a constraint language Γ is injective if Γ ⊆Γ D
I .
Example 13. Let D = {0, 1} and let R = {(x, y) | x, y ∈D, x + y ≡1 (mod 2)}.
R is injective because the function f : D →D deﬁned as f(0) = 1 and f(1) = 0
is injective. More generally, let G = (D′, +, −) be an arbitrary Abelian group
and let c ∈D′ be an arbitrary group element. It is easy to see that the relation
{(x, y) | x, y ∈D′, x + y = c} is injective.
R is an example of a relation which is invariant under an aﬃne operation. Such
relations have previously been studied in relation with the Max Ones problem
in [36]. We will give some additional results for such constraints in Section 7.
With the terminology used in [36], R is said to be width-2 aﬃne. The relations
which can be expressed as the set of solutions to an equation with two variables
over an Abelian group are exactly the width-2 aﬃne relations in [36], so the
injective relations are a superset of the width-2 aﬃne relations. The following
result is a direct consequence of [10, Sec. 4.4].
Theorem 14. If Γ is injective, then Max Sol(Γ) is in PO.
An alternative way of proving Theorem 14 goes like this: Max Sol(Γ D
I ) is in
PO if and only if Max Sol(ID) is in PO (by Theorem 6) so we can concen-
trate on ID. Given an instance of Max Sol(ID), consider the graph having the

266
P. Jonsson and G. Nordh
variables as vertices and edges between the vertices/variables occurring together
in the same constraint. Each connected component of this graph represents an
independent subproblem that can be solved in separately. If a value is assigned
to a variable/vertex, all variables/vertices in the same component will be forced
to take a value by propagating this assignment. Hence, each connected compo-
nent have at most |D| diﬀerent solutions (that can be easily enumerated) and
an optimal one can be found in polynomial time.
Injective relations can also be deﬁned via a polymorphism: deﬁne the discrim-
inator t : D3 →D such that
t(a, b, c) =
c
if a = b,
a
otherwise.
It is known that Γ D
I = Inv(t) [41, Theorem 4.2].
4.2
Generalised Max-Closed Relations
We begin by giving the basic deﬁnition.
Deﬁnition 15. A constraint language Γ over a domain D ⊂N is generalised
max-closed if and only if there exists a binary operation f ∈Pol(Γ) such that f
satisﬁes the following two conditions:
1. for all a, b ∈D such that a ̸= b it holds that if f(a, b) ≤min(a, b), then
f(b, a) > max(a, b); and
2. for all a ∈D it holds that f(a, a) ≥a.
The following two examples will clarify the deﬁnition above.
Example 16. Assume that the domain D is {0, 1, 2, 3}. As an example of a gener-
alised max-closed relation consider R = {(0, 0), (1, 0), (0, 2), (1, 2)}. R is invariant
under max and is therefore generalised max-closed as max satisﬁes the properties
of Deﬁnition 15. Now, consider the relation Q deﬁned as
Q = {(0, 1), (1, 0), (2, 1), (2, 2), (2, 3)}.
Q is not invariant under max because
max((0, 1), (1, 0)) = (max(0, 1), max(1, 0)) = (1, 1) /∈Q.
Let the operation ◦: D2 →D be deﬁned by the following Cayley table (note
that we write x ◦y instead of ◦(x, y)):
◦0 1 2 3
0 0 2 2 3
1 2 1 2 2
2 2 2 2 3
3 3 2 3 3
Now, it is easy to verify that Inv(◦) is a set of generalised max-closed relations
and that Q ∈Inv(◦).

Introduction to the Maximum Solution Problem
267
Example 17. Consider the relations R1 and R2 deﬁned as,
R1 = {(1, 1, 1), (1, 0, 0), (0, 0, 1), (1, 0, 1)}
and R2 = R1 \ {(1, 1, 1)}. The relation R1 is 1-valid because the tuple consisting
only of ones is in R1, i.e., (1, 1, 1) ∈R1. The relation R2, on the other hand,
is not 1-valid but is dual-Horn positive because it is invariant under max. Note
that both R1 and R2 are generalised max-closed since R1 is invariant under
f(x, y) = 1 and R2 is invariant under f(x, y) = max(x, y). It is in fact the
case that every dual-Horn relation is invariant under max so the 1-valid and
dual-Horn relations are subsets of the generalised max-closed relations.
We are now ready to explain the tractability of generalised max-closed constraint
languages.
Theorem 18 ([32]). If Γ is generalised max-closed, then Max Sol(Γ) is in
PO.
The tractability of generalised max-closed constraint languages crucially depends
on the following property. If Γ is generalised max-closed, then all relations
R = {(d11, d12, . . . , d1m), . . . , (dt1, dt2, . . . , dtm)}
in Γ have the property that the tuple
tmax = (max{d11, . . . , dt1}, . . . , max{d1m, . . . , dtm})
is in R, too.
This property is the basis for the simple consistency based algorithm for Csps
over max-closed constraint languages, from [29]. We use the same algorithms to
solve Max Sol(Γ) when Γ is generalised max-closed. The algorithm for Csps
over max-closed constraint languages from [29], gives us a solution (if one exists)
which has the property that the value assigned to each variable is the maximum
value this variable is allowed to take in any solution. Hence, this solution is also
the optimum solution to the corresponding Max Sol problem. Since the only
property of max-closed constraint languages that is exploited by this algorithm is
that the tuple tmax is in every relation, it follows that the same algorithm solves
(to optimum) Max Sol(Γ) for generalised max-closed constraint languages.
5
Clausal Constraints
We will now introduce our ﬁrst example of a non-Boolean Max Sol problem.
We consider a framework for expressing constraint languages based on regular
signed logic [23] over totally-ordered sets. This approach was introduced by
Creignou et al. [11]. The set of relations that we consider is based on regular
signed logic [23], where the underlying domain is a (possibly inﬁnite) totally-
ordered set of integers {0, 1, . . .}. This logic provides us with convenient concepts
for deﬁning a class of relations with strong modelling capabilities. Jeavons and

268
P. Jonsson and G. Nordh
Cooper [29] have proved that any constraint can be expressed as the conjunction
of expressions over this class of relations. A disadvantage with their approach is
that the resulting set of constraints may by exponentially large (in the number
of tuples in the constraint to be expressed). An improved algorithm solving the
same problem has been suggested by Gil et al. [17]. It takes a constraint/relation
represented by the set of all assignments/tuples that satisﬁes it and outputs in
polynomial time (in the number of tuples) an expression that is equivalent to
the original constraint.
Let V be a set of variables. For x ∈V and a ∈D, the inequalities x ≥
a and x ≤a are called positive and negative literals, respectively. A clause
is a disjunction of literals. A clausal pattern is a multiset of the form P =
(+a1, . . . , +ap, −b1, . . . , −bq) where p, q ∈N and ai, bi ∈D for all i. The pattern
P is said to be negative if p = 0 and positive if q = 0. The sum p+q, also denoted
|P|, is the length of the pattern.
A clausal language L is a set of clausal patterns. Given a clausal language
L, an L-clause is a pair (P, x), where P ∈L is a pattern and x is a vector of
not necessarily distinct variables from V such that |P| = |x|. A pair (P, x) with
a pattern P = (+a1, . . . , +ap, −b1, . . . , −bq) and variables x = (x1, . . . , xp+q)
represents the clause
(x1 ≥a1 ∨. . . ∨xp ≥ap ∨xp+1 ≤b1 ∨. . . ∨xp+q ≤bq),
where ∨is the disjunction operator. An L-formula φ is a conjunction of a ﬁnite
number of L-clauses. An assignment is a mapping I : V →D assigning a domain
element I(x) to each variable x ∈V . An assignment I satisﬁes an L-formula φ
if and only if
(I(x1) ≥a1 ∨. . . ∨I(xp) ≥ap ∨I(xp+1) ≤b1 ∨. . . ∨I(xp+q) ≤bq)
holds for every clause in φ. It can be easily seen that the literals +0 and −d are
superﬂuous since the inequalities x ≥0 and x ≤d vacuously hold. Without loss
of generality, it is suﬃcient to only consider patterns and clausal languages with-
out such literals. We see that clausal patterns are nothing more than a convenient
way of specifying certain relations — consequently, we can use them for deﬁning
constraint languages. Thus, we make the following deﬁnitions: given a clausal lan-
guage L and a clausal pattern P = (+a1, . . . , +ap, −b1, . . . , −bq), we let Rel(P)
denote the corresponding relation, i.e. Rel(P) = {x ∈Dp+q | (P, x) hold} and
ΓL = {Rel(P) | P ∈L}.
It is easy to see that several well-studied optimisation problems are captured
by this framework.
Example 19. Let the domain D be {0, 1}. The problem Independent Set
(where the objective is to ﬁnd an independent set of maximum weight in an
undirected graph) can be viewed as the Max Sol(Γ(−0,−0)) problem. Similarly,
Max Sol(Γ(−0,...,−0)) (with k literals) is the Max k-Hypergraph Stable Set
problem.

Introduction to the Maximum Solution Problem
269
We can now present suﬃcient conditions for when Max Sol over clausal lan-
guages is tractable and prove that it is APX-hard otherwise. To do so, we use
a family of operations maxu : D2 →D, u ∈D, deﬁned such that
maxu(a, b) =
u
if max(a, b) ≤u
max(a, b) otherwise
Theorem 20 ([33]). Max Sol(ΓL) is tractable if ΓL is invariant under maxu
for some u ∈D. Otherwise, Max Sol(ΓL) is APX-hard.
Note that Inv(maxu) is generalised max-closed so the tractability part of Theo-
rem 20 follows immediately from Theorem 18. The APX-hardness is proved by
reductions from Max Independent Set and Max-E3SAT.
The Min Sol and Max AW Sol problems for clausal constraints have also
been studied: deﬁne a new family of operations minu : D2 →D, u ∈D, such
that
minu(a, b) =

u
if min(a, b) ≥u
min(a, b) otherwise
Theorem 21 ([33]). Min Sol(ΓL) is tractable if ΓL is invariant under minu
for some u ∈D. Otherwise, Min Sol(ΓL) is APX-hard. Max AW Sol(ΓL) is
tractable if ΓL is simultaneously invariant under max and min. Otherwise, Max
AW Sol(ΓL) does not admit polynomial-time approximation schemes.
The tractability proof for Min Sol is analogous to the proof of Theorem 18
while the tractability proof for Max AW Sol is based on supermodular max-
imisation [27,39]. Note that we do not prove APX-hardness for Max AW Sol;
the reason is that we are now forced to handle instances with negative optimal
measure and APX-hardness and AP-reductions are only deﬁned for problems
with positive measure. However, it is still possible to rule out the existence of
polynomial-time approximation schemes. For ordinary approximation problems,
we say that a solution s is r-approximate if
opt(I)
r
≤m(I, s) ≤opt(I) · r.
This does not work for problems with negative optima since in this case opt(I)
r
≥
opt(I) · r. With this in mind, we say that Π admits a Ptas if there exists an
algorithm A satisfying the following property: for any instance I of Π and any
rational value r > 1, A(I, r) returns a solution s (in time polynomial in |I|) such
that m(I, s) ∈[opt(I)/r, r · opt(I)].
6
Binary Symmetric Relations
The complexity of Csp(R) is known for every binary and symmetric relation R
due to Hell and Neˇsetˇril’s celebrated result: Csp(R) is NP-complete unless R
is bipartite or contains a loop (and the problem is easily solvable in polynomial

270
P. Jonsson and G. Nordh
time). Such a dichotomy is not known for the Max Sol problem but there are
some preliminary results by Jonsson et al. [34]. These results are presented next.
From now on, we view binary symmetric relations as undirected graphs in the
obvious way where vertices denote domain elements and an edge (a, b) is present
if and only if the tuples (a, b), (b, a) are members of the relation. We do not
restrict ourselves to reﬂexive or irreﬂexive graphs, i.e. each vertex may or may
not have a loop. We begin by showing that we can concentrate on connected
graphs.
Let H = {H1, . . . , Hn} be a set of connected graphs and let H be the disjoint
union of these graphs. We are interested in the complexity of Max Sol(H),
given the complexities of the individual problems. Let Hi = H \ {Hi}. We say
that Hi extends the set Hi if there exists an instance I = (V, D, C, w) of Max
Sol(Hi) such that for all 1 ≤j ≤n, j ̸= i it holds that opt(I) > opt(Ij) where
Ij = (V, Dj, {Hj(x, y) | Hi(x, y) ∈C}, w). We call I a witness to the extension.
Assume that for some 1 ≤i ≤n, it holds that Hi does not extend Hi. It is
clear that for any connected instance I = (V, D, C, w) of Max Sol(H), we have
opt(I) = opt(Ij) for some j, where Ij = (V, Dj, {Hj(x, y) | H(x, y) ∈C}, w).
Furthermore, since Hi does not extend Hi, we know that we can choose this j ̸= i.
Let H′ be the disjoint union of the graphs in Hi. Then, opt(I) = opt(I′), where
I′ = (V, D, {H′(x, y) | H(x, y) ∈C}, w) is an instance of Max Sol(H′). For this
reason, we may assume that every Hi ∈H extends every graph in Hi.
Lemma 22 ([34]). Let H1, . . . , Hn be graphs and H their disjoint union. If
the problems Max Sol(Hi), 1 ≤i ≤n are all tractable, then Max Sol(H) is
tractable. If Max Sol(Hi) is NP-hard and Hi extends the set {H1, . . . , Hi−1,
Hi+1, . . . , Hn} for some i, then Max Sol(H) is NP-hard.
Next, we need a couple of algorithmic results. Let F = {I1, . . . , Ik} be a family
of intervals on the real line. A graph G with V (G) = F and (Ii, Ij) ∈E(G) if
and only if Ii ∩Ij ̸= ∅is called an interval graph. If the intervals are chosen to
be inclusion-free, G is called a proper interval graph.
Let F1 = {I1, . . . , Ik} and F2 = {J1, . . . , Jl} be two families of intervals on
the real line. A graph G with V (G) = F1 ∪F2 and (Ii, Jj) ∈E(G) if and only if
Ii ∩Jj ̸= ∅is called an interval bigraph. If the intervals in each family are chosen
to be inclusion-free, G is called a proper interval bigraph.
Lemma 23 ([34]). If H is a connected graph which is a proper interval graph
or a proper interval bigraph, then Max Sol(H) is polynomial time solvable.
We will now present some complexity results for Max Sol(H). Let H be an
irreﬂexive graph such that deg(H) ≤2. It is easy to see that H is the disjoint
union of paths and cycles. By Lemma 22, we can without loss of generality
assume that H contains only one connected component. Every irreﬂexive path
is a proper interval bigraph so Lemma 23 immediately gives a tractability result.
Proposition 24 ([34]). If H is an irreﬂexive path, then Max Sol(H) is in
PO.

Introduction to the Maximum Solution Problem
271
Assume now that H is a cycle. If H is an odd cycle, then Csp(H) and Max
Sol(H) are NP-complete by Hell and Neˇsetˇril’s [22] result. If H is isomorphic
to C4, then H cannot be a max-core. One can see that the max-core of H is an
irreﬂexive path so Max Sol(H) is in PO by Proposition 24 and Lemma 8. More
generally, every irreﬂexive even cycle that is not a max-core has a max-core that
is an irreﬂexive path. Thus, we can additionally assume that H is a max-core.
Proposition 25 ([34]). Let H be a max-core which is isomorphic to an even
cycle, i.e., C2k. Assume a bipartition V (H) = {d1, . . . , dk} ∪{d′
1, . . . , d′
k} of H
with d1 < d2 < · · · < dk and d′
1 < d′
2 < · · · < d′
k and, without loss of generality,
assume that dk > d′
k. We denote by Pol1(H) the set of unary polymorphisms of
H. Let F = {π ∈Pol1(H) | ∃j ̸= k : π(dj) ̸= dj ∨π(d′
j) ̸= d′
j}. If there exist non-
negative constants a1, . . . , ak−1, a′
1, . . . , a′
k−1 such that for each π ∈Pol1(H)\F,
it is true that
k−1
+
i=1

ai · di + a′
i · d′
i

>
k−1
+
i=1

ai · π(di) + a′
i · π(d′
i)

.
Then, Max Sol(H) is NP-hard and, otherwise, Max Sol(H) is in PO.
The proof of Proposition 25 largely builds on constructing unary relations via
pp-formulas and exploiting complexity results for the retraction problem [15].
We now turn our attention to graphs H such that |V (H)| ≤4. For |V (H)| = 2
there are only two (types) of max-cores, H1 and H2 in Figure 1. Max Sol(H1) is
essentially the problem of ﬁnding the largest (heaviest) bipartition in a bipartite
graph, which is in PO. Max Sol(H2) is closely related to the Max Indepen-
dent Set problem (in fact, it is exactly Max Independent Set for d1 = 0
and d2 = 1) and it is NP-hard (actually, poly-APX-complete when d1 = 0,
and APX-complete otherwise).
The complexity for 3-element graphs is completely determined in the next
theorem. The main diﬃculty in proving the theorem is the tractability part
where the Critical Independent Set problem [1,43] plays an important role.
The hardness results can be obtained quite comfortably by reductions from the
retraction problem and the Max Independent Set problem.
Theorem 26 ([34]). There are six (types of) max-cores over {d1, d2, d3} where
d1 < d2 < d3, denoted H1, . . . , H6 and shown in Figure 2. Max Sol(H) is NP-
hard for all of these except for H5. Max Sol(H5) is in PO if d3 + d1 ≤2d2
and NP-hard otherwise.
d1
d2
d1
d2
H1
H2
Fig. 1. Max-cores H1 and H2 for V (H) = {d1, d2} where d1 < d2

272
P. Jonsson and G. Nordh
We consider the graph H5 closer since it highlights one of the diﬃculties with
obtaining complexity classiﬁcations for Max Sol(Γ). Consider the graph H =
{(2, 0), (0, 2), (0, 0), (0, 1), (1, 0), (1, 1)} in Figure 3 and note that it is isomorphic
to H5 by setting d1 = 0, d2 = 1, and d3 = 2. One consequence of Theorem 26 is
that Max Sol(H) is in PO. However, it is easy to see that H is a max-core but
not an injective relation nor a relation that is invariant under a generalised max
operation. The relation H is thus an example of a relation whose tractability
cannot be explained in terms of the general results in Section 4. In fact, Max
Sol(H) is essentially the Critical Independent Set problem, which was
shown to be in PO in [1,43] by a rather clever algorithm.
If we instead consider the graph H′ = {(3, 0), (0, 3), (0, 0), (0, 1), (1, 0), (1, 1)}
in Figure 4 (which is also isomorphic to H5), then Theorem 26 tells us that Max
Sol(H′) is NP-hard. Hence, despite the striking similarity of the graphs H and
H′, they have diﬀerent complexity with respect to the Max Sol problem. More-
over, it follows from Theorem 6 that the diﬀerence in complexity between Max
Sol(H) and Max Sol(H′) can be explained by analysing the set of polymor-
phisms of H and H′, i.e., Pol(H) and Pol(H′). In our opinion, this example, and
d1
d2
d3
H1
d3
d2
d1
H3
d2
d1
d3
H2
H4
d3
d1
d2
H6
H5
d3
d1
d2
d1
d2
d3
Fig. 2. Max-cores Hi for |V (H)| = 3
1
0
2
Fig. 3. A graph H for which Max Sol is in PO
1
0
3
Fig. 4. A graph H′ for which Max Sol is NP-hard

Introduction to the Maximum Solution Problem
273
in particular the fact that we have not (yet) been able to explain the tractability
of Max Sol(H) in terms of properties of Pol(H) indicate that it might be quite
challenging to classify the complexity of Max Sol(Γ) over ﬁnite domains.
After this short digression we move on to the |V | = 4 case. The complexity
of the |V | = 4 case is not completely known, but if we restrict ourselves to the
vertex set {0, 1, 2, 3}, then we have the following result:
Theorem 27 ([34]). Let H be a max-core on D = {0, 1, 2, 3}. Then, Max
Sol(H) is in PO if H is an irreﬂexive path, and otherwise, Max Sol(H) is
NP-hard.
The proof of Theorem 27 builds on the same ideas as the proof of Theorem 26.
7
Equations over Groups
The complexity of solving equations over diﬀerent algebraic structures is a very
well-studied topic; we refrain from giving a long list of examples but simply
remind the reader that solving linear equations is an instance of this problem.
If we assign natural numbers to the elements of the structure, then it is obvious
that we can also view such a problem as an instance of the Max Sol problem.
In this section, we consider the Max Sol problem over group equations and this
motivates the next deﬁnition.
Deﬁnition 28. Let G = (G; +, −, 0G) be a group (we use + for the binary group
operation, −for inversion and 0G for the identity element) and g : G →N a
function. The Max Sol problem over group equations is denoted by Max Sol
Eqn(G, g). An instance of Max Sol Eqn(G, g) is deﬁned to be a triple (V, E, w)
where,
– V is a set of variables,
– E is a set of equations of the form w1 + . . . + wk = 0G, where each wi is
either a variable, an inverted variable or a group constant, and
– w is a weight function w : V →N.
The objective is to ﬁnd an assignment f : V →G to the variables such that
all equations are satisﬁed and the sum
+
v∈V
w(v) · g(f(v))
is maximised.
Note that the function g and the group G are not parts of the input so Max
Sol Eqn(G, g) is parameterised by G and g.
Goldmann and Russell [18] have shown that solving systems of equations over
non-Abelian groups is NP-hard. Thus, it is NP-hard to ﬁnd feasible solutions
to Max Sol Eqn(H, g) if H is non-Abelian, too. It is therefore suﬃcient to
study Max Sol Eqn(H, g) where H is Abelian.

274
P. Jonsson and G. Nordh
The main result is for groups of the form Zp where p is prime. For a function
g : Zp →N we deﬁne the following two quantities,
gmax = max
x∈Zp g(x)
and
gsum =
+
x∈Zp
g(x).
We are now ready to state the result.
Theorem 29 ([36]). For every prime p and every function g : Zp →N, Max
Sol Eqn(Zp, g) is approximable within α where
α = p · gmax
gsum
.
Furthermore, for every prime p and every non-constant function g : Zp →N
Max Sol Eqn(Zp, g) is not approximable within α −ϵ for any ϵ > 0, unless
P = NP.
Note that if g is a constant function then every solution has the same measure.
Obviously, an optimal can be found in polynomial time in this case. The in-
approximability proof builds on the inapproximability of Max-Ek-Lin-G [26]
combined with a series of reductions. The approximability result is obtained by
an application of random sampling. This gives a randomised algorithm, which
in expectation produces solutions of the required quality. A straightforward de-
randomisation of this algorithm is possible.
8
Maximal Constraint Languages
A maximal constraint language Γ is a constraint language such that ⟨Γ⟩⊂RD,
and if R /∈⟨Γ⟩, then ⟨Γ ∪{R}⟩= RD. That is, the maximal constraint languages
are the largest constraint languages that are not able to express all ﬁnitary
relations over D. This implies, among other things, that there exists an operation
f such that ⟨Γ⟩= Inv(f) whenever Γ is a maximal constraint language [38].
The complexity of the Csp(Γ) problem for all maximal constraint languages
on domains |D| ≤3 was determined in [8]. Moreover, it was shown in [8] that
the only case that remained to be classiﬁed in order to extend the classiﬁcation
to all maximal constraint languages over a ﬁnite domain was the case where
⟨Γ⟩= Inv(f) for binary commutative idempotent operations f. These constraint
languages were ﬁnally classiﬁed by Bulatov in [5].
Theorem 30 ([5,8]). Let Γ be a maximal constraint language on an arbitrary
ﬁnite domain D. Then, Csp(Γ) is in P if ⟨Γ⟩= Inv(f) where f is a constant
operation, a majority operation, a binary commutative idempotent operation, or
an aﬃne operation. Otherwise, Csp(Γ) is NP-complete.
We now present an approximability classiﬁcation, from [32], of Max Sol(Γ) for
all maximal constraint languages Γ over |D| ≤4. Moreover, it is proved in [32]
that the only cases that remain to be classiﬁed, in order to extend the classi-
ﬁcation to all maximal constraint languages over ﬁnite domains, are constraint

Introduction to the Maximum Solution Problem
275
languages Γ such that ⟨Γ⟩= Inv(f) for a binary commutative idempotent op-
eration f. It is also proved in [32] that if a certain conjecture regarding minimal
clones generated by binary operations, due to Szczepara [40], holds, then the
classiﬁcation can be extended to capture also these last cases.
Theorem 31. Let Γ be maximal constraint language on a ﬁnite domain D, with
|D| ≤4, and ⟨Γ⟩= Inv(f).
1. If Γ is generalised max-closed or an injective constraint language, then Max
Sol(Γ) is in PO;
2. else if f is an aﬃne operation, a constant operation diﬀerent from the con-
stant 0 operation, or a binary commutative idempotent operation satisfying
f(0, b) > 0 for all b ∈D \ {0} (assuming 0 ∈D); or if 0 /∈D and f is
a binary commutative idempotent operation or a majority operation, then
Max Sol(Γ) is APX-complete;
3. else if f is a binary commutative idempotent operation or a majority opera-
tion, then Max Sol(Γ) is poly-APX-complete;
4. else if f is the constant 0 operation, then ﬁnding a solution with non-zero
measure is NP-hard;
5. otherwise, ﬁnding a feasible solution is NP-hard.
Moreover, if Conjecture 131 from [40] holds, then the results above hold for
arbitrary ﬁnite domains D.
The proof of the preceding theorem consists of a careful analysis of the ap-
proximability of Max Sol(Γ) for all maximal constraint languages Γ such that
⟨Γ⟩= Inv(f), where f is one of the types of operations in Theorem 30.
9
Homogeneous Constraint Languages
In this section, we describe a classiﬁcation result from [32] on the complexity of
Max Sol when the constraint language is homogeneous. A constraint language
is called homogeneous if every permutation relation is contained in the language.
Deﬁnition 32. A binary relation R is a permutation relation if there is a per-
mutation π : D →D such that
R = {(x, π(x)) | x ∈D}.
Let Q denote the set of all permutation relations on D. The complexity classi-
ﬁcation of Max Sol(Γ) when Q ⊆Γ from [32] provide the exact borderlines
between tractability, APX-completeness, poly-APX-completeness, and NP-
hardness of ﬁnding a feasible solution. Due to space constraints we only describe
the borderline between tractability (i.e., membership in PO) and NP-hardness.
This classiﬁcation is described in Theorem 33.
Dalmau completely classiﬁed the complexity of Csp(Γ) when Γ is a homo-
geneous constraint language [14], and this classiﬁcation relies heavily on the
structure of homogeneous algebras. An algebra is called homogeneous if and

276
P. Jonsson and G. Nordh
only if every permutation on its universe is an automorphism of the algebra. For
a formal deﬁnition and further information on the properties of homogeneous
algebras we refer the reader to [41].
The approximability classiﬁcation of Max Sol(Γ) when Γ is a homogeneous
constraint language uses the same approach as in [14], namely, the inclusion
structure of homogeneous algebras is exploited. The (only) tractable class of
Max Sol(Γ), over homogenous constraint languages, can be characterised by
the presence in Pol(Γ) of a discriminator operation t (as deﬁned in Section 4.1).
Theorem 33 ([32]). Let Γ be a homogeneous constraint language. If a discrim-
inator operation t is in Pol(Γ), then Max Sol(Γ) is in PO. Otherwise, Max
Sol(Γ) is NP-hard.
Since a constraint language Γ is injective if and only if Γ ⊆Inv(t), the tractabil-
ity part of the theorem follows from Theorem 14. The hardness part of the
theorem is proved by reductions from variants of the Max Independent Set
problem and the Max Sol Eqn(G, g) problem, as deﬁned in Section 7.
As a direct consequence of Theorem 33 we get that the class of injective
relations, as deﬁned in Section 4.1, is a maximal tractable class for Max Sol(Γ).
That is, if we add a single relation which is not an injective relation to the class
of all injective relations, then the problem is no longer in PO (unless P = NP).
10
Outlook
In this section, we describe the relationship between the Max Sol problem and
some other frameworks for optimisation problems.
10.1
Relation to Valued CSPs
We begin by giving a simpliﬁed account of the VCSP (valued CSP) framework
studied in, e.g., [9,10]. The VCSP framework involves two types of constraints:
crisp constraints (which must be satisﬁed) and soft constraints (which are satis-
ﬁed by any assignment, but diﬀerent assignments may generate diﬀerent costs).
More formally, a soft constraint (or valued constraint) is a pair (σ, ϕ) where
σ = (x1, . . . , xk) is a k-tuple of variables (the constraint scope) and ϕ is a k-ary
cost function from D to Z. The cost of the assignment (a1, . . . , ak) is given by
ϕ(a1, . . . , ak). The objective is to ﬁnd a solution (satisfying all crisp constraints)
that minimise (or maximise) the total cost of all soft constraints.
Just as for the ordinary Csp problem, much eﬀort has been put into studying
the complexity of the VCSP problem for various constraint languages. The con-
straint language can be viewed as consisting of two parts: the crisp constraint
language Γ (a set of relations) and the valued constraint language ΓV (a set of
cost functions). The VCSP(Γ, ΓV ) problem can now be deﬁned as follows:
Deﬁnition 34. A VCSP(Γ, ΓV ) instance is a tuple (V, C, CV , D), where V is
a set of variables, C is a set of crisp constraints (whose constraint relations are
in Γ), CV is a set of valued constraints (whose cost functions are in ΓV ), and

Introduction to the Maximum Solution Problem
277
D is the domain. The objective is to ﬁnd an assignment f : V →D such that
all constraints in C are satisﬁed and the sum
+
(σ,ϕ)∈CV
ϕ(f(σ[1]), . . . , f(σ[i]))
is minimised.
We denote the corresponding problem where the objective is to ﬁnd the solution
that maximises the sum above by Max-VCSP(Γ, ΓV ). Note that the deﬁnitions
of VCSP problems in [9,10] are much more sophisticated and elegant than our
simpliﬁed account above. We also remark that, in order to comply with the
existing literature on VCSP problems, we do not assume that the domain and
the constraint languages Γ and ΓV are ﬁnite.
It is easy to see that instances of Max Sol(Γ), Min Sol(Γ), and Max AW
Sol(Γ) problems can be seen as instances of VCSP problems.
Proposition 35.
– Instances of Max Sol(Γ) can be seen as instances of Max-VCSP(Γ, ΓV )
where ΓV consists of a single unary cost function ϕ, deﬁned such that ϕ(d) =
d for all d ∈D.
– Instances of Min Sol(Γ) can be seen as instances of VCSP(Γ, ΓV ) where
ΓV consists of a single unary cost function ϕ, deﬁned such that ϕ(d) = d for
all d ∈D.
– Instances of Max AW Sol(Γ) can be seen as instances of Max-VCSP(Γ,
ΓV ) where ΓV consists of two unary cost functions ϕ and ϕ, such that ϕ(d) =
d for all d ∈D, and ϕ(d) = −d for all d ∈D.
Variable weights can be handled in the VCSP setting by repeated applications of
the unary cost function ϕ (and ϕ in the case of negative weights).
10.2
Relation to Minimum Cost Homomorphism
The Minimum Cost Homomorphism problem (denoted Min Hom(H)) has
recently received a lot of attention [19,20,21]. The problem Min Hom(H) can
be deﬁned as follows:
Deﬁnition 36. An instance of Min Hom(H) is a graph G together with a
weight function w(x, y) : V (G) × V (H) →N. The objective is to ﬁnd a ho-
momorphism h : V (G) →V (H) such that the sum
+
v∈V (G)
w(v, h(v))
is minimised.
An instance of the Min Hom(H) problem can also be seen as an instance of the
VCSP(Γ, ΓV ) problem, where Γ consists of the single binary relation H and
ΓV is a set of unary cost functions, deﬁned such that ϕv(d) = w(v, d) for all
v ∈V (G) and d ∈V (H). Note that ΓV , as deﬁned here, is not ﬁnite. We note
in passing that an analogous result to Theorem 6 holds for Min Hom(H).

278
P. Jonsson and G. Nordh
Proposition 37. Let H be a graph and Γ ′ ⊆⟨H⟩ﬁnite. Then, Min Hom(Γ ′)
is S-reducible to Min Hom(H).
A dichotomy is known for the complexity of Min Hom(H) in the case when H
is an undirected graph.
Theorem 38 ([19]). If each component of H is a proper interval graph or a
proper interval bigraph, then the problem Min Hom(H) is in PO. In all other
cases, Min Hom(H) is NP-hard.
A list extension of the Max AW Sol(H) problem (denoted List Max AW
Sol(H)) is studied in [34]. The Max AW Sol(H) problem is extended by
introducing lists, {L(v) ⊆V (H) | v ∈V (G)}, and requiring that any solution
must assign to v one of the vertices in L(v). It is not hard to realise that the
List Max AW Sol(H) problem is a restriction of the Min Hom(H) problem.
One of the results of [34] is a complexity classiﬁcation of List Max AW Sol(H)
for undirected graphs H.
Theorem 39 ([34]). Let H be an undirected graph with loops allowed. Then
List Max AW Sol(H) is solvable in polynomial time if all components of H
are proper interval graphs or proper interval bigraphs. Otherwise List Max AW
Sol(H) is NP-hard.
The preceding result, together with the complexity classiﬁcation of Min Hom(H)
from [19], gives us the following corollary.
Corollary 40. Let H be an undirected graph with loops allowed. Then, List
Max AW Sol(H) is polynomial-time equivalent to Min Hom(H).
11
Open Questions
The long-term goal for this line of research is, of course, to completely classify
the approximability of Max Sol for all ﬁnite constraint languages. However,
this is probably a hard problem since not even a complete classiﬁcation for the
corresponding decision problem Csp is known. A more manageable task would
be to completely classify Max Sol for constraint languages over small domains
(say, of size 3 or 4). For size 3, this has already been accomplished for Csp [6]
and Max Csp [31]. Another obvious open problem is to classify the complexity
of Max Sol(Γ) for the remaining maximal constraint languages Γ described
in Section 8. The known results for the complexity of Max Sol suggest the
following conjecture:
Conjecture 41. For every ﬁnite constraint language Γ, one of the following holds:
1. Max Sol(Γ) is in PO;
2. Max Sol(Γ) is APX-complete;
3. Max Sol(Γ) poly-APX-complete;
4. it is NP-hard to ﬁnd a non-zero solution to Max Sol(Γ); or
5. it is NP-hard to ﬁnd any solution to Max Sol(Γ).

Introduction to the Maximum Solution Problem
279
If this conjecture is true, then there does not exist any constraint language Γ
such that Max Sol(Γ) has a polynomial-time approximation scheme (Ptas) but
Max Sol(Γ) is not in PO. However, if one impose simultaneous restrictions on
the allowed constraint types and the way constraints are applied to variables
(instead of only restricting the allowed constraint types), then the situation
changes. Consider for example Max Independent Set (and, equivalently, Max
Ones({(0, 0), (1, 0), (0, 1)})): the unrestricted problem is poly-APX-complete
and not approximable within O(n1−ϵ), ϵ > 0 (unless P=NP) [44], but the
problem restricted to planar instances admits a Ptas [3]. One may ask several
questions in connection with this: For which constraint languages does Max Sol
admit a Ptas on planar instances? Or more generally: under what restrictions
on variable scopes does Max Sol(Γ) admit a Ptas?
The investigation of the complexity of Max Sol(Γ) when Γ is a graph [34]
indicates that giving a complete complexity classiﬁcation of Max Sol(Γ) for
every ﬁxed constraint language Γ is probably harder than ﬁrst anticipated. In
particular, the tractable class for the Max Sol problem identiﬁed in [34] (and
described in Section 6) depends very subtly on the values of the domain ele-
ments and no characterisation of this tractable class in terms of polymorphisms
is known. Hence, this tractable class seems to be of a diﬀerent ﬂavour com-
pared to the other tractable classes for the Max Sol problem [32,33,35]. On the
other hand, there is a complete classiﬁcation for the complexity of the arbitrary
weighted list version of the problem, List Max AW Sol(Γ), in the important
case where Γ is an undirected graph.
Interestingly, for undirected graphs H the borderline between tractability and
NP-hardness for List Max AW Sol(H) coincide exactly with Gutin et al.’s [19]
recent complexity classiﬁcation of Min Hom(H). This is surprising, since the
Min Hom(H) problem is much more expressive than the List Max AW Sol(H)
problem, and we were expecting graphs H such that Min Hom(H) were NP-
hard and List Max AW Sol(H) were in PO. Moreover, it is not hard to prove
that Min Hom(Γ) over Boolean constraint languages Γ is in PO if Γ is width-2
aﬃne, or if Γ is Horn and dual-Horn; and that Min Hom(Γ) is NP-hard for all
other Boolean constraint languages Γ. This borderline between PO and NP-
hardness coincides with the borderline between PO and NP-hardness for Max
AW Sol(Γ) over Boolean constraint languages Γ proved in [30]. The obvious
question raised by these results is how far can we extend the correspondence in
complexity between List Max AW Sol(Γ) and Min Hom(Γ)? More speciﬁ-
cally, is it the case that List Max AW Sol(Γ) is in PO (NP-hard) if and only
if Min Hom(Γ) is in PO (NP-hard) for arbitrary ﬁnite constraint languages Γ?
Acknowledgments
The authors thank Fredrik Kuivinen and Johan Thapper for making important
contributions to this survey. We also thank the anonymous referee for providing
some very useful comments. Peter Jonsson is partially supported by the Cen-
ter for Industrial Information Technology (CENIIT) under grant 04.01, and by

280
P. Jonsson and G. Nordh
the Swedish Research Council (VR) under grant 621-2003-3421. Gustav Nordh
is partially supported by the Swedish-French Foundation, and by the National
Graduate School in Computer Science (CUGS), Sweden.
References
1. Ageev, A.: On ﬁnding critical independent and vertex sets. SIAM J. Discrete
Math. 7(2), 293–295 (1994)
2. Ausiello, G., Crescenzi, P., Gambosi, G., Kann, V., Marchetti Spaccamela, A.,
Protasi, M.: Complexity and approximation: Combinatorial optimization problems
and their approximability properties. Springer, Heidelberg (1999)
3. Baker, B.: Approximation algorithms for NP-complete problems on planar graphs.
Journal of the ACM 41, 153–180 (1994)
4. Bodirsky, M., Neˇsetˇril, J.: Constraint satisfaction with countable homogeneous
templates. Journal of Logic and Computation 16(3), 359–373 (2006)
5. Bulatov, A.: A graph of a relational structure and constraint satisfaction problems.
In: Proceedings of the 19th IEEE Symposium on Logic in Computer Science (LICS
2004), pp. 448–457 (2004)
6. Bulatov, A.: A dichotomy theorem for constraint satisfaction problems on a 3-
element set. Journal of the ACM 53(1), 66–120 (2006)
7. Bulatov, A., Jeavons, P., Krokhin, A.: Classifying the complexity of constraints
using ﬁnite algebras. SIAM J. Comput. 34(3), 720–742 (2005)
8. Bulatov, A., Krokhin, A., Jeavons, P.: The complexity of maximal constraint lan-
guages. In: Proceedings of the 33rd ACM Symposium on Theory of Computing
(STOC 2001), pp. 667–674 (2001)
9. Cohen, D., Cooper, M., Jeavons, P.: An algebraic characterisation of complexity for
valued constraint. In: Benhamou, F. (ed.) CP 2006. LNCS, vol. 4204, pp. 107–121.
Springer, Heidelberg (2006)
10. Cohen, D., Cooper, M., Jeavons, P., Krokhin, A.: The complexity of soft constraint
satisfaction. Artiﬁcial Intelligence 170(11), 983–1016 (2006)
11. Creignou, N., Hermann, M., Krokhin, A., Salzer, G.: Complexity of clausal con-
straints over chains. Theory Comput. Syst. 42(2), 239–255 (2008)
12. Creignou, N., Khanna, S., Sudan, M.: Complexity classiﬁcations of Boolean con-
straint satisfaction problems. SIAM, Philadelphia (2001)
13. Crescenzi, P., Silvestri, R., Trevisan, L.: On weighted vs unweighted versions of
combinatorial optimization problems. Inf. Comput. 167(1), 10–26 (2001)
14. Dalmau, V.: A new tractable class of constraint satisfaction problems. Annals of
Mathematics and Artiﬁcial Intelligence 44(1-2), 61–85 (2005)
15. Feder, T., Hell, P., Huang, J.: List homomorphisms and circular arc graphs. Com-
binatorica 19, 487–505 (1999)
16. Feder, T., Vardi, M.Y.: The computational structure of monotone monadic SNP
and constraint satisfaction: A study through datalog and group theory. SIAM J.
Comput. 28(1), 57–104 (1999)
17. Gil, `A., Hermann, M., Salzer, G., Zanuttini, B.: Eﬃcient algorithms for constraint
description problems over ﬁnite totally ordered domains. In: Basin, D., Rusinow-
itch, M. (eds.) IJCAR 2004. LNCS, vol. 3097, pp. 244–258. Springer, Heidelberg
(2004)
18. Goldmann, M., Russell, A.: The complexity of solving equations over ﬁnite groups.
In: IEEE Conference on Computational Complexity, pp. 80–86 (1999)

Introduction to the Maximum Solution Problem
281
19. Gutin, G., Hell, P., Raﬁey, A., Yeo, A.: A dichotomy for minimum cost graph
homomorphisms. European J. Combin. 29(4), 900–911 (2008)
20. Gutin, G., Raﬁey, A., Yeo, A.: Minimum cost and list homomorphisms to semi-
complete digraphs. Discrete Applied Mathematics 154(6), 890–897 (2006)
21. Gutin, G., Raﬁey, A., Yeo, A., Tso, M.: Level of repair analysis and minimum cost
homomorphisms of graphs. Discrete Applied Mathematics 154(6), 881–889 (2006)
22. Hell, P., Neˇsetˇril, J.: On the complexity of H-colouring. Journal of Combinatorial
Theory B 48, 92–110 (1990)
23. H¨ahnle, R.: Complexity of many-valued logics. In: Proceedings of the 31st IEEE
International Symposium on Multiple-valued Logic (ISMVL 2001), pp. 137–148
(2001)
24. Hochbaum, D., Megiddo, N., Naor, J., Tamir, A.: Tight
bounds and 2-
approximation algorithms for integer programs with two variables per inequality.
Mathematical Programming 62, 69–84 (1993)
25. Hochbaum, D., Naor, J.: Simple and fast algorithms for linear and integer programs
with two variables per inequality. SIAM J. Comput. 23(6), 1179–1192 (1994)
26. H˚astad, J.: Some optimal inapproximability results. Journal of the ACM 48(4),
798–859 (2001)
27. Iwata, S., Fleischer, L., Fujishige, S.: A combinatorial strongly polynomial algo-
rithm for minimizing submodular functions. Journal of the ACM 48(4), 761–777
(2001)
28. Jeavons, P., Cohen, D., Gyssens, M.: Closure properties of constraints. Journal of
the ACM 44, 527–548 (1997)
29. Jeavons, P., Cooper, M.: Tractable constraints on ordered domains. Artiﬁcial In-
telligence 79, 327–339 (1996)
30. Jonsson, P.: Boolean constraint satisfaction: complexity results for optimization
problems with arbitrary weights. Theoretical Computer Science 244(1-2), 189–203
(2000)
31. Jonsson, P., Klasson, M., Krokhin, A.: The approximability of three-valued Max
CSP. SIAM J. Comput. 35(3), 1329–1349 (2006)
32. Jonsson, P., Kuivinen, F., Nordh, G.: Max Ones generalised to larger domains.
SIAM J. Comput. 38(1), 329–365 (2008)
33. Jonsson, P., Nordh, G.: Generalised integer programming based on logically deﬁned
relations. In: Kr´aloviˇc, R., Urzyczyn, P. (eds.) MFCS 2006. LNCS, vol. 4162, pp.
549–560. Springer, Heidelberg (2006)
34. Jonsson, P., Nordh, G., Thapper, J.: The maximum solution problem on graphs. In:
Kuˇcera, L., Kuˇcera, A. (eds.) MFCS 2007. LNCS, vol. 4708, pp. 228–239. Springer,
Heidelberg (2007)
35. Khanna, S., Sudan, M., Trevisan, L., Williamson, D.: The approximability of con-
straint satisfaction problems. SIAM J. Comput. 30(6), 1863–1920 (2001)
36. Kuivinen, F.: Tight approximability results for the maximum solution equation
problem over Zp. In: Jedrzejowicz, J., Szepietowski, A. (eds.) MFCS 2005. LNCS,
vol. 3618, pp. 628–639. Springer, Heidelberg (2005)
37. P¨oschel, R., Kaluznin, L.: Funktionen- und Relationenalgebren. DVW, Berlin
(1979)
38. Rosenberg, I.: Minimal clones I: the ﬁve types. In: Szab´o, L., Szendrei, ´A. (eds.)
Lectures in Universal Algebra. North-Holland, Amsterdam (1986)
39. Schrijver, A.: A combinatorial algorithm for minimizing submodular functions in
polynomial time. Journal of Combinatorial Theory B 80, 346–355 (2000)
40. Szczepara, B.: Minimal clones generated by groupoids. PhD thesis, Universit´e de
Montr´eal (1996)

282
P. Jonsson and G. Nordh
41. Szendrei, ´A.: Clones in Universal Algebra. In: S´eminaires de Math´ematiques
Sup´erieures, University of Montreal, vol. 99 (1986)
42. Woeginger, G.: An eﬃcient algorithm for a class of constraint satisfaction problems.
Operations Research Letters 30(1), 9–16 (2002)
43. Zhang, C.: Finding critical independent sets and critical vertex subsets are poly-
nomial problems. SIAM J. Discrete Math. 3(3), 431–438 (1990)
44. Zuckerman, D.: Linear degree extractors and the inapproximability of max clique
and chromatic number. In: Proceedings of the 38th ACM Symposium on Theory
of Computing (STOC 2006), pp. 681–690 (2006)

Present and Future of Practical SAT Solving
Oliver Kullmann1,⋆
Computer Science Department, Swansea University
Swansea, SA2 8PP, UK
O.Kullmann@Swansea.ac.uk
http://cs.swan.ac.uk/∼csoliver
Abstract. We review current SAT solving, concentrating on the two
paradigms of conﬂict-driven and look-ahead solvers, and with a view
towards the uniﬁcation of these two paradigms. A general “modern”
scheme for DPLL algorithms is presented, which allows natural repre-
sentations for “modern” solvers of these two types.
1
Introduction
The number as well as the breadth of applications of SAT solving, like veriﬁca-
tion of hardware and software or solving diﬃcult concrete combinatorial problem
instances, has steadily increased over the last 10 years. Two main paradigms for
backtracking solvers have emerged, the “conﬂict-driven solver” and the “look-
ahead solver”, the former better suited for veriﬁcation problems, the latter better
for diﬃcult problems. Both paradigms now have reached some form of plateau,
and the purpose of this article is to present these two diﬀerent plateaus (kind
of “ﬁxed points”), and to discuss several ideas towards possible combinations of
these two approaches, to overcome the current relative stagnation (regarding the
core algorithms). We focus on “practical” algorithms which “work” (at least rea-
sonably often), as represented by the SAT conference and the SAT competition.
Two basic approaches for SAT solving in general can be identiﬁed: Local
search (for satisfying assignments), and backtracking. Local search has still a
stronghold for satisﬁable random formulas, and in recent years the theoretically
very interesting “survey propagation” algorithm was developed, but outside the
domain of (satisﬁable) random formulas local search lost inﬂuence, and in this
article we will not consider it (unquestionably there is a lot of potential, but it
needs further development). Steady improvements of look-ahead backtracking
solvers are noticeable, but the strongest development took place w.r.t. conﬂict-
driven backtracking solvers, and accordingly we will put emphasise in this article
on the notion of “clause learning”. Motivated by the success of SAT, extensions of
SAT (like pseudo-boolean formulas, quantiﬁed boolean formulas or “SAT modulo
theory”) become increasingly popular, but yet no clear pattern emerged here.
For the whole area there are many beliefs, many observations, but no proofs;
⋆Partially supported by grant EPSRC GR/S58393/01.
N. Creignou et al. (Eds.): Complexity of Constraints, LNCS 5250, pp. 283–319, 2008.
c
⃝Springer-Verlag Berlin Heidelberg 2008

284
O. Kullmann
nevertheless it seems that the subjects of this article are mature enough that a
more systematic treatment might be possible.
Yet, in SAT no “theoretical idea” had impact on the “practice” of SAT solving:
Although there have been many attempts, they never went far enough, and we
do not understand the practical applications. I believe
– practice needs a dedicated eﬀort, much more details and care in some areas,
and more looseness in other areas,
– but there is much more to discover than the current “trivial” solvers!
So in this article I want somehow to present the “practical world” — hopefully we
can learn from their observations and ideas. The observable stagnation regarding
the core algorithms can be overcome in my opinion by unifying yet separate
development lines:
1. The three main paradigms for SAT solving, “conﬂict-driven”, “look-ahead”
and “local search” should be combined (in a new, intelligent way).
2. SAT (with its focus on global structure) and CSP (with its focus on local
structure) need to be uniﬁed. Here with “global structure” I allude at the
fact that SAT problems in CNF representation come “chopped into little
pieces”, and the solution process considers statistical properties arising from
pieces potentially belonging to very diﬀerent parts of the problem instance. In
contrast, traditionally the ﬁeld of constraint satisfaction studies extensively
“intelligent” problem representations, but at the cost of more global (and
less predictable) structures.
In this article we focus on look-ahead versus conﬂict-driven (both are resolution-
based, and thus closer together), trying to bring out the (quite diﬀerent) un-
derlying ideas, and to discuss how potentially those two approaches could be
brought together (and what (considerable) problems have to be overcome for
such a uniﬁcation).1 An outline of this article follows:
1. Conjunctive normal forms seem to be at the heart of “SAT”, and they are
discussed in Section 2.
2. An overview on polynomial time methods which seem relatively close to
“practice” is given in Section 3.
3. ThegistofthisarticleisgivenbythenewgeneralschemeGforDPLL-algorithm
presented in Subsection 4.1, unifying the look-ahead and the conﬂict-driven
paradigms. Specialisations yield a general look-ahead scheme la in Subsection
5.1, and a general conﬂict-driven scheme cd in Subsection 6.1.3.
4. DPLL in general is discussed in Section 4, while look-ahead solvers are pre-
sented in Section 5, and the main features of conﬂict-driven solvers are the
subject of Section 6.
5. Approaches for understanding and extending clause-learning are outlined in
Section 7.
6. Finally some conclusions are drawn in Section 8.
1 The new OKsolver, tentatively called “OKsolver2009” and developed in the frame-
work of the OKlibrary (http://www.ok-sat-library.org), an open-source library
for generalised SAT solving (embracing CSP), aims at unifying all three paradigms.

Present and Future of Practical SAT Solving
285
Now before going into more details, I will try to “outline in a nutshell” fun-
damental concepts and ideas. The basic notion for a backtracking solver (of any
kind) is that of a “partial assignment” ϕ, ﬁxing some variables to values deter-
mined previously (according to the current path in the search tree from the root
to the current node), while leaving other variables open, either to be decided
later, or to be ﬁxed by reasoning, or left open since they do not play a role.
Since it as at the core of (current) SAT solving, in this article we concentrate
on problems represented by conjunctive normal forms, or, more combinatorially,
represented by “clause-sets”, where each clause C can be seen as a negated par-
tial assignment ϕ, a constraint forbidding all (total) assignments which extend
ϕ. We will represent this via C = Cϕ in Subsection 2.2.2. Furthermore we only
consider backtracking approaches, due to its current dominance for practical
applications.
The two basic paradigms for backtracking SAT solvers (also “DPLL solvers”)
are “look-ahead” and “conﬂict-driven”. The look-ahead paradigm, based on
stronger polynomial-time reductions and stronger heuristics, is similar to CSP
solvers using appropriate constraint propagators, only that here now the empha-
sise is on the use of partial assignments. Look-ahead solvers are easily parallelis-
able, and thus might become more important again in the future, at this time
however conﬂict-driven solvers are in the foreground. Again, the basic approach
is known from constraint programming, based on “clause-learning”, which is no-
good learning of clauses Cϕ for the current path ϕ, but using several mechanisms
to strengthen the learning eﬀort (this is easier in this setting, since the problem
representation (via CNF) is just what is needed to represent the no-goods).
Conﬂict-driven solvers are derived from DPLL-solvers, however it seems ap-
propriate to describe their behaviour no longer in the usual tree-based (recursive)
fashion, but as a simple iterative approach (more similar to dynamic program-
ming, as put by David Mitchell). The basic idea is for a problem instance P to
guess a satisfying partial assignment ϕ, guided by only the most basic look-ahead,
namely unit-clause propagation, and once a contradiction was realised, then this
“conﬂict” is analysed for its “real causes”, and added via clause-learning to the
clause database. The whole solution process then might completely re-start from
scratch again (but using the modiﬁed problem instance P ′, including now the
learned clauses), though in practice only a part of the current path is undone,
just to the point where the freshly learned information has obvious consequences.
SAT solving based on DPLL-approaches is close to the resolution calculus, and
from the early beginnings by Martin Davis and Hilary Putnam these connections
have been exploited. Resolution is just the logical consequence relation restricted
to the clause language and only two premises — it is easy to see that then the
conclusion is either trivial or the (unique) “resolvent” of the two parent clauses.
Now a “resolution-based” solver (as common in ATP at the level of ﬁrst-order
logic) starts with the premises, and tries to derive the empty clause from it, while
a DPLL-solver in eﬀect reverts this process: The goal becomes the input clause-
set F (the root of the tree), for which backtracking seeks to ﬁnd the premises from
which F can be shown unsatisﬁable. Conﬂict-driven solvers can be understood

286
O. Kullmann
as breaking the tree-like structure, and so in a sense they combine the resolution-
based approaches with the backtracking approaches. A classic references for the
resolution calculus is [46], while a recent overview on proof systems is [42]. The
earliest paper on the connection of backtracking (in the form of decision trees)
and resolution is [36], while a fuller account, also applicable to more general
problem representations, can be found in [26].
2
Conjunctive Normal Forms
One peculiar aspect of “SAT solving” is the focus on a very speciﬁc form of
constraint satisfaction problems:
– only boolean variables are considered;
– only (disjunctive) clauses are allowed as constraints (but involving arbitrarily
many variables).
In other words, only boolean CNF’s are considered for core SAT solving, and
recent extensions build on top of this. Due to the tight coupling of this repre-
sentation with the algorithms and data structures, the role of (boolean) CNF’s
goes far beyond sheer problem representation, and seems actually to a certain
degree essential for the success of SAT solving for applications. In this section
we will discuss the various aspects of “boolean CNF’s” and their role for SAT
solving.
In this article we put the emphasise on boolean clause-sets, since they (seem)
to embody the “secret” of SAT, but it is natural to ask to what extend the special
properties of boolean clause-sets can be generalised to CSP’s (with unrestricted
constraint scopes). A natural settings is given by “signed CNF”, which allow
for non-boolean variables v with domains Dv, and where literals are of the form
“v /∈S” for some “sign” S ⊆Dv; this is the most general form of clause-sets (as
CNFs) where literals contain only a single variable, and many logical properties
can be generalised (for a recent entry point to the literature see [1]). However for
the more combinatorial properties of boolean clause-sets, signed clause-sets seem
a vast generalisation, and the notion of “clause-sets with non-boolean variables”
should better be reserved in my opinion to clauses containing only literals of the
form “v ̸= ε” for ε ∈Dv; such “sets of no-goods” are thoroughly studied in [27].
2.1
Clause-Sets and Partial Assignments
The theoretical foundations of SAT are best framed as follows:
– We have variables with boolean domain {0, 1}; the set of all variables is
VA.
– From variables we build positive literals and negative literals, stating
that the variables must become true resp. false. Identifying positive literals
with variables, and denoting negative literals with underlying variable v by
“v”, we obtain the set LIT = VA ·∪VA of all literals, where now comple-
mentation becomes an involution (a self-inverse bijection) of LIT onto itself.
The underlying variable of literal x is denoted by var(x).

Present and Future of Practical SAT Solving
287
– Two literals x, y clash if they have the same underlying variable, but diﬀer-
ent “polarities” (or “signs”), that is, iﬀx = y.
– Clauses are ﬁnite and clash-free sets of literals, understood as disjunctions;
the set of all clauses is denoted by CL. A special clause is the empty clause
⊥:= ∅∈CL, and var(C) := {var(x) : x ∈C} for C ∈CL.
– Clause-sets are ﬁnite sets of clauses, understood as conjunctions; the set of
all clause-sets is denoted by CLS. A special clause-set is the empty clause-set
⊤:= ∅∈CLS, and var(F) := 
C∈F var(C) for F ∈CLS.
– A partial assignment is a map ϕ : V →{0, 1} for some ﬁnite set V ⊆VA
of variables, the set of all partial assignments is PASS, and we use var(ϕ) :=
V . ϕ(x) for literals x is deﬁned (in the obvious way) if var(x) ∈var(ϕ);
a term ⟨x1 →ε1, . . . , xm →εm⟩for literals xi (with diﬀerent underlying
variables) and εi ∈{0, 1} denotes the partial assignment ϕ with var(ϕ) =
var({x1, . . . , xm}) and ϕ(xi) = εi.
– The most important operation for SAT is the operation
∗: PASS × CLS →CLS
of partial assignments on clause-sets, called “application”, where ϕ ∗F for
ϕ ∈PASS and F ∈CL is obtained from F by removing all satisﬁed clauses
(those C ∈F containing x ∈C with ϕ(x) = 1), and removing all falsiﬁed
literals (i.e., literals x with ϕ(x) = 0) from the remaining clauses.
– Finally the set SAT of satisﬁable clause-sets is deﬁned as the set of
F ∈CLS such that there exists ϕ ∈PASS with ϕ ∗F = ⊤, while USAT :=
CLS \ SAT denotes the set of unsatisﬁable clause-sets.
Several special properties of this setting need to be pointed out:
1. A fundamental fact, justifying the use of partial assignments, is that if a
partial assignment ϕ satisﬁes a clause-set F then every extension of ϕ
also satisﬁes F (this is just guaranteed by the process of applying partial
assignments), where an “extension” of ϕ is just a partial assignment ψ with
ϕ ⊆ψ (using the deﬁnition of partial assignments as maps, that is, as sets
of ordered pairs).
2. Every clause is falsiﬁable, and thus the property that a partial assignment
ϕ satisﬁes a clause-set F, i.e., ϕ ∗F = ⊤, is equivalent to the property that
every extension ψ ⊇ϕ of ϕ can be further extended to satisfy F. But that
ϕ falsiﬁes F, i.e., ⊥∈ϕ ∗F, says much less (it’s trivial to falsify, but
hard to satisfy) and is in general only the ﬁnal visible expression (during
the search process) of unsatisﬁability, for example F might be unsatisﬁable
right away. To obtain more symmetric conditions, one could say that ϕ
“allows satisfaction” of F if ϕ ∗F is satisﬁable, that is, there exists an
extension of ϕ which satisﬁes F, while ϕ “disallows satisfaction” of F if
ϕ ∗F is unsatisﬁable. Then one could characterise look-ahead solvers as
solvers which try to give good indications that the current partial assignment
(under construction) allows satisfaction, while conﬂict-driven solvers could
be characterised as solvers trying to ﬁnd better and better reasons that the
current partial assignment disallows satisfaction.

288
O. Kullmann
3. If a variable v is set to a value ε, then we can apply the partial assignment
⟨v →ε⟩to a clause-set F and obtain a new clause-set ⟨v →ε⟩∗F which
does not contain the variable anymore. This allows us to replace iterated
application of partial assignments as in ψ ∗(ϕ ∗F) by a single application of
the composition ψ◦ϕ of both partial assignments via ψ∗(ϕ∗F) = (ψ◦ϕ)∗F,
where the construction of the composition is obvious for variables v where
ψ, ϕ do not clash, while in case of a clash only ϕ is relevant, since after
application of ϕ the variable v has been eliminated and the value of ψ on v
doesn’t matter.
Theoretically clause-sets are a convenient framework — are they also used in
practice ? Let us consider the corresponding conditions:
– Associativity of disjunction and conjunction is always implemented (typically
by using lists to represent clauses and clause-sets).
– Commutativity:
• Commutativity of disjunction (in a clause) may be implemented by or-
dering the literals in a clause. Often this is not done, but it seems not
very relevant.
• Commutativity of conjunction is never implemented, and especially for
industrial benchmarks the order of clauses is quite important (successful
conﬂict-driven solvers employ a lot of “dirty tricks”).
– Input-clauses containing clashes are removed, and are also never introduced.
– Idempotency:
• Literals are not repeated in clauses, achieved by preprocessing the input,
while maintenance is basically trivial (for the type of solvers considered,
where resolution operations are restricted to the preprocessing phase).
• However repeated clauses are only removed during pre-processing (if at
all, and then applying the stronger reduction of subsumption-elimination
(see Subsection 3.4.1)), while they may be created during solving.
To summarise:
1. “Clauses in practice” can be adequately understood as we deﬁned them.
2. “Clause-sets in practice” are actually lists of clauses (order is important, and
the eﬀort of removing duplicated clauses is too high).
The notion of literals, clause and clause-sets install several normalisation con-
ditions when regarding literals, clauses and clause-sets as boolean functions (or
constraints):
– Literals are never constant true or constant false.
– A clause is never constant true, while ⊥is the unique clause which is constant
false.
– The unique clause-set which is constant true is ⊤.
– Exactly the unsatisﬁable clause-sets are constant false. The clause-sets which
are falsiﬁed by every partial assignment are those containing ⊥, which is
reduced to the unique form {⊥} by reduction r0 (see Subsection 3.1).

Present and Future of Practical SAT Solving
289
2.2
Properties
Partial assignments and boolean clause-sets have many special properties, com-
pared to the situation for constraint satisfaction, and in this subsection the
properties which seem most outstanding for practical SAT solving are discussed:
1. If we have a unit-clause {x} ∈F, then the assignment ⟨x →1⟩is enforced,
and this process of “unit-clause elimination” is considered in Subsection 2.2.1
(while unit-clause propagation is the subject of Subsection 3.1.1).
2. The close relation between clauses and partial assignment, the basis for
clause-learning, is considered in Subsection 2.2.2.
3. The input-problem doesn’t need to be given in a special form, but we can
apply the logic of clause-sets and partial assignments under very general
conditions, which are discussed in Subsection 2.2.3.
2.2.1
Unit-Clause Elimination
Arguably the most important aspect of clauses for SAT solving is:
Once all literals are falsiﬁed except of one, then
the remaining variable gets an enforced value.
This is based on three properties of clauses and literals:
1. falsiﬁcation of clauses only by giving every variable the wrong value;
2. easy satisfaction of a clause by giving just one variable not the wrong value;
3. since there are only two values, there is no choice for a right value.
The ﬁrst two properties are still maintained by generalised clauses, allowing non-
boolean variables v with domain Dv and literals “v ̸= ε” for some ε ∈Dv, but
the third property requires boolean variables, and thus the strong form of unit-
clause elimination is characteristic for boolean clause-sets. Repeated elimination
of unit-clauses is called “unit-clause propagation”, and this most basic process
for SAT solving is considered in more details in Subsection 3.1.1).
2.2.2
Correspondence between Clauses and Partial Assignments
At least second in importance to unit-clause elimination is the 1-1 correspon-
dence between clauses and partial assignments:
For every partial assignment ϕ there is exactly one clause Cϕ, such that the
falsifying assignments for Cϕ are exactly the extensions of ϕ.
And conversely, for every clause C there is exactly one partial assignment ϕC
such that the clauses falsiﬁed by ϕC are exactly the sub-clauses of C.
Obviously Cϕ consists exactly of the literals falsiﬁed by ϕ, while ϕC sets exactly
the literals in C to false, and these two formations are inverse to each other:
1. This correspondence establishes the close relation between the search trees
of backtracking algorithms and resolution refutations, as further explained
in Subsection 7.1.
2. Clauses Cϕ for falsifying assignments ϕ are also called “no-goods”, and are
the essence of “learning” as explored in Subsection 6.1.

290
O. Kullmann
2.2.3
An Axiomatic Approach
A generalisation of “satisﬁability” by allowing arbitrary problem representations,
on which partial assignments “operate”, has been introduced and studied in [26].
The key observation here is, when considering only partial assignments, where
assigned variables get a unique value2, then a sequence ψ∗(ϕ∗F) of applications
of partial assignments can be elegantly represented by a unique application of the
composition (ψ ◦ϕ)∗F, and the essence of basic satisﬁability considerations can
be captured by a simple algebraic framework, where problem instances are left
unspeciﬁed, and only via the application of partial assignments can we “query”
them. Clauses and resolution then appear as a meta-structure on top of the
given domain of problem instances. In Subsection 7.3 we will use this theory,
which allows generalised resolution “modulo oracles”, for a “compressed” form
of learning.
2.3
Data Structures
Especially the handling of variables can be somewhat complicated from a software
engineering point of view, when maximal generality is the goal, however from the
purely algorithmic point of view there are no real complications involved:
– Variables are often implemented as unsigned positive integers; literals are
then signed integers (other than zero). If variables are not already positive
integers themselves, then they need to be associated with an index, so that
we can establish constant time access to properties of variables.
– An alternative is to implement variables and literals by pointers to associated
data structures with relevant meta-data (like occurrence numbers etc.).
– In any case variables and literals need to be light-weight objects which
can be easily copied (note the diﬀerence between a literal and a literal-
occurrence: given n variables, there are 2n literals, while the number of
literal-occurrences is the sum of the clause-lengths).
Regarding the implementation of clauses and clause-sets, the basic decision
is whether to use “lazy” or “eager” data structures; this is further discussed
in Subsection 4.2, and here it suﬃces to say that conﬂict-driven solvers are
lazy (avoiding to do much work at each node, since they might backtrack soon
anyway), while look-ahead solvers are more eager (since the look-ahead at each
node needs better support):
1. In the lazy case it is suﬃcient to implement clauses as vectors (ﬁxed after
reading the input).
2. While for the eager case clauses are dynamically changed, and are imple-
mented as doubly-linked lists of literal-occurrences.
3. The list of all clauses is not of great importance (since one should avoid to
run through all clauses), but clauses are accessed through the “clause-literal
graph” discussed below.
4. In the eager as well as the lazy case, clauses must enable quick access to
associated statistical data.
2 While multivalued assignments can allow a set of values.

Present and Future of Practical SAT Solving
291
Clause-sets are
– generalisations of hypergraphs (adding signs to vertices), as well as
– special cases of hypergraphs (with literals as vertices).
Hypergraphs can be represented by bipartite graphs. For clause-sets we obtain
the bipartite clause-literal graph, which is of fundamental importance:
– the nodes are the literals on one side, and the clauses on the other side;
– edges indicate membership of literals in clauses.
The clause-variable graph, connecting now clauses with variables, is also called
“incidence graph”. Using the standard adjacency-list representation of digraphs
and representing graphs by symmetric digraphs, we obtain a basic implementa-
tion of clause-sets through the representation of the clause-literal graph, allowing
quick access to the literal-occurrences in a clause as well as to the clauses in which
a literal occurs. This representation can be considered as fundamental for the
lazy as well as for the eager approach, where the former saves certain elements,
while the latter adds further structure. Some remarks on the clause-literal graph:
1. More correct is to speak of a 3-partite graph, where the clause-literal graph
is augmented with an additional layer for variables.
2. Literal-occurrence correspond to edges between clauses and literals.
3. I consider the graph and hypergraph concepts as a good conceptual frame-
work, however it is used only implicitly by solver implementations.3
4. The technique of “watched literals” together with the “lazy datastructure”
for clause-sets can be considered as removing certain (directed) edges from
literals to clauses in the clause-literal graph: From a clause we can still reach
all contained literals, but a clause is reachable only from two “watched”
literal occurrences in each clause, which are updated if necessary; see Sub-
section 3.1.1.
Finally, for partial assignments two complementary structures are used:
– For search purposes, partial assignments are treated as stacks of assignments
(moving down and up the search tree).
– Via an additional global vector of assignments we can check in constant time,
whether a variable is assigned, and which value it has.
Local search typically works only with “total” assignments (i.e., with partial
assignments ϕ with var(ϕ) = var(F), where F is the input clause-set), while for
the algorithms considered in this paper partial assignments are fundamental, and
then the eﬃcient implementation of the application of partial assignments is of
utmost importance (needing additional data structures). Copying is perhaps the
most fundamental enemy of eﬃciency, and the application of partial assignments
is (in non-parallel computations) performed in-place; more on this and the two
fundamental approaches, “eager” and “lazy”, can be found in Subsection 4.2.
3 The upcoming OKlibrary will give direct support for using these graph-theoretic
abstractions.

292
O. Kullmann
2.4
Transformations
Let us close this section by some remarks on how to translate other problems
into boolean CNFs. First there is the somewhat surprising fact that boolean
transformations are surprisingly eﬃcient. There are several important extensions
of clauses, like
1. cardinality clauses, e.g., v1 + v2 + v3 ⪋k;
2. more generally pseudo-boolean clauses, allowing constant coeﬃcients;
3. crisp CSP.
For all these cases, direct translation (avoiding sophistication) into boolean CNFs
is an eﬃcient way to deal with them (at this time), if a reasonable amount
of “logical reasoning” is required by the problem. Boolean CNFs seem to be
supported by superiorly eﬃcient data structures — every deviation from this
ideal is punished by a big loss in eﬃciency, which can be compensated only in
special situations. But there is another important advantage by using a boolean
translation: Not only do we get eﬃcient data structures for free,
but the “atomisation” of information achieved by using boolean variables can
be inherently more eﬃcient for backtracking algorithms (with exponential
speed-ups) than the original information representation.
This important point was raised in [39]: Chopping up a problem into boolean
pieces in general increases the search space, but this richer space allows also for
more eﬃcient re-combinations.
3
Reductions: Poly-Time Methods
The purpose of this section is to introduce the main reductions used in SAT
solving:
1. Unit clause propagation and generalisations are considered in Subsection 3.1.
2. Basic methods directly based on resolution are considered in Subsection 3.2.
3. Some basic comparisons between diﬀerent notions of “local consistency” are
given in Subsection 3.3.
4. Less common reductions are surveyed in Subsection 3.4.
A reduction here is simply a map r : CLS →CLS such that r(F) is satisﬁability-
equivalent to F, and we consider here only polynomial-time computable r. Now
one can study classes C ⊆CLS such that r is already suﬃcient to decide satisﬁa-
bility for F ∈C, however this point of view in isolation is not very useful for SAT
solving (at least not for practical SAT solving), as discussed in Subsection 3.5.
3.1
Generalised Unit-Clause Propagation
We deﬁne hierarchies rk, r′
k : CLS →CLS of poly-time reductions for k ∈N0 as
follows:

Present and Future of Practical SAT Solving
293
1. r0 = r′
0 detects the empty clause, and otherwise does nothing:
r0(F) :=
,
{⊥}
if ⊥∈F
F
otherwise .
2. rk+1 reduces F to rk+1(⟨x →1⟩∗F) in case rk yields an inconsistency for
⟨x →0⟩∗F for some literal x:
rk+1(F):=
,
rk+1(⟨x →1⟩∗F)
for literals x with rk(⟨x →0⟩∗F) = {⊥}
F
otherwise
.
r′
k+1 also notices when a satisfying assignment was found:
r′
k+1(F):=
⎧
⎪
⎨
⎪
⎩
r′
k+1(⟨x →1⟩∗F)
for literals x with r′
k(⟨x →0⟩∗F)={⊥}
⊤
for literals x with r′
k(⟨x →1⟩∗F) = ⊤
F
otherwise
.
Main properties:
– Though the deﬁnition of rk, r′
k is non-deterministic, these reductions yields
unique results (are conﬂuent).
– There always exists partial assignments ϕ, ϕ′ such that rk(F) = ϕ ∗F resp.
r′
k(F) = ϕ′ ∗F; here ϕ is a forced (or “necessary”) assignment.
– By applying r0, r1, . . . , rn(F ) (where n(F) := |var(F)| is the number of vari-
ables) until either an inconsistency is found or at the end we know that F is
satisﬁable, we obtain a SAT decision algorithm which quasi-automatises tree
resolution, and which is the (real) essence of Stalmarck’s solver. Obviously
it is preferable to use the reductions r′
k, which for k large enough (at most
k = n(F)) will also ﬁnd a satisfying assignment if F is satisﬁable. See [19]
for a thorough treatment of the reductions rk, r′
k.4
– In [26] the treatment of rk, r′
k is extended to axiomatically given systems of
problem instances with non-boolean variables (compare Subsection 2.2.3 in
this article).
The fundamental open question is how eﬃciently rk can be computed for general
k:
1. r1 is just unit-clause-propagation, and we will see in Subsection 3.1.1 that r1
can be computed in linear time, that is, in O(ℓ(F)) where ℓ(F) := 
C∈F|C|
is the number of literal occurrences in F.
2. We obtain that rk can be computed in time O(n(F)2(k−1) · ℓ(F)) for k ≥1.
4 Using the hierarchy Gk(U, S) from [19] (with oracles U ⊆USAT for unsatisﬁability
and S ⊆SAT for satisﬁability) we have r′
k(F) = {⊥} ⇔F ∈G0
k(U0, S0) and
r′
k(F) = ⊤⇔F ∈G1
k(U0, S0), where U0 is the basic oracle for unsatisﬁability,
just recognising the empty clause, and S0 is the basic oracle for satisﬁability, just
recognising the empty clause-set.

294
O. Kullmann
3. Thus already for r2 in general we obtain only a cubic-time algorithm. Can
we do better ? And what about general k ?
The reductions r′
k can be naturally strengthened via the use of (weak) autarky
reduction (see Subsection 3.4.3; a similar early approach is [5]):
r∗
k+1(F):=
⎧
⎪
⎨
⎪
⎩
r∗
k+1(⟨x →1⟩∗F)
for literals x with r∗
k(⟨x →0⟩∗F)={⊥}
r∗
k+1(r∗
k(⟨x →1⟩∗F))
for x with r∗
k(⟨x →1⟩∗F) ⊆F
F
otherwise
.
Conﬂict-driven solvers only use r1, while look-ahead solvers employ rk for “k ≈
2”: The OKsolver-2002 (see [24]) uses exactly r∗
2 (apparently as the only solver at
each node), while “modern” look-ahead solvers exclude “unpromising” variables
from r2 (thus go below k = 2), while employing r3 for “promising” variables (see
Subsection 5.2); the march-solvers also employ certain aspects of weak autarky
reduction.
3.1.1
Unit-Clause Propagation
The special case r1 is unit-clause propagation (UCP). UCP of central importance
for backtracking solvers, and for eﬃciency reasons support for UCP needs to be
integrated into the main data structure. The basic algorithm for UCP is the
linear time algorithm, best understood as operating on the clause-literal graph
(recall Subsection 2.3), which is represented by an adjacency list:
– a given unit clause {x} is “propagated” by removing the literal occurrences
of literal x (the graph representation yields quick access from a literal to its
occurrences, and allows to remove edges eﬃciently), and it is checked whether
this removal creates a new unit-clause (which by the graph representation is
a constant-time operation);
– as soon as a new unit-clause is created, it is pushed on the buﬀer (typically
a queue or a stack), used for the unit-clauses waiting to be propagated;
– a partial assignment with constant time access keeps track of the assign-
ments, discarding multiple occurrences of the same unit clause, and detecting
contradictory unit clauses.
Note that for “lazy UCP”, which only needs to obtain the assignments resulting
from the unit-clause propagation (used by conﬂict-driven solvers or in the look-
ahead of look-ahead solvers), and not the resulting clause-set, we do not need to
consider satisﬁed clauses. For faster UCP (achieving a better constant factor) the
main problem is to make the propagation process more eﬃcient, so that with less
work we can detected (relevant) new unit-clauses. A ﬁrst step is not to remove
the occurrences of x but just to decrement counters for the clause-lengths, and
if this counter reaches 1 then the clause is inspected for the new unit-clause.
This is driven further by watched literals: We do not need to know the precise
(current) length of all clauses, but we need only to be alerted if possibly we have
less than 2 literals in a clause. So we can thin out the clause-literal graph by
using only two literal-neighbours of a clause, and updating these neighbours (the

Present and Future of Practical SAT Solving
295
watched literals) if one of them disappears. All these methods are only relevant
for lazy UCP, which is also for look-ahead solvers of great importance due to the
time spent during the look-ahead.
3.1.2
Failed Literals and Extensions
Reduction by r2 is called “(full) failed literal reduction”. It is not used by conﬂict-
driven solvers, but essential for look-ahead solvers. Failed literal reduction relies
on the eﬃcient implementation of UCP, and, as already mentioned, the central
question here is: How much can we do better than by just following the deﬁni-
tion ?! (Better than just checking for all assignments to variables, whether UCP
yields a conﬂict, and repeating this process if a reduction was found.) The current
“front” of research (for look-ahead solver) considers weakenings and strengthen-
ings of r2 (trying only “promising” variables, and locally learning binary clauses
encoding the inferred unit-clauses). See Subsection 5.2 for more information.
3.2
Resolution Based Reductions
Given two clauses C, D clashing in exactly one literal x ∈C ∧x ∈D, the
resolvent is
C ⋄D := (C \ {x}) ∪(D \ {x}).
Given two clauses C, D and a clause R, the relation {C, D} |= R, that is, C ∧D
logically implies R, is equivalent to the following:
– Either C and D are resolvable (clash in exactly one literal), and then C ⋄D ⊆
R,
– or C and D are not resolvable (clash in zero or at least two literals), and
then we have C ⊆R or D ⊆R.
Thus on the clause level, syntax and semantics coincide! Resolution calculi or-
ganise the iterated application of the resolution operation until either the empty
clause has been derived, and thus the clause-set is unsatisﬁable, or it is estab-
lished that this is not possible (and thus the clause-set must be satisﬁable).
Resolution in its various forms, especially tree-like resolution, where the search
process can be (relatively) eﬃciently inverted (starting with the goal), is the
central tool for SAT. Via the correspondence between clauses and partial as-
signments, every backtracking solver is constructing a resolution refutation of
its input (see Subsection 7.1). Additional resolution power (moving from tree
resolution to full resolution) is gained by “clause learning”, and is discussed fur-
ther in Subsection 6.1 and Section 7. Via the following methods, the resolution
operation can be involved in a more direct way:
Adding resolvents. Just adding arbitrary resolvents is highly ineﬃcient (ex-
cept of some special cases). So only short resolvents are added (of length at
most 3), and this only during preprocessing.
DP-reductions. The DP-operator (also referred to as “variable elimination”)
is
DPv(F) :=

C ⋄D : C, D ∈F ∧C ∩D = {v}

∪{C ∈F : v /∈var(F)}.

296
O. Kullmann
DPv(F) is sat-equivalent to F, more precisely, DPv(F) is equivalent to the
quantiﬁed boolean formula (∃v ∈{0, 1} : F), and variable v is eliminated by
applying DPv. So by applying DP until all variables are removed we can de-
cide SAT, but in general this is very ineﬃcient (requiring exponential space).
Thus DP is only applied (during preprocessing) in “good cases” (typically
when size is not increased).
A general problem here (and elsewhere) regarding reductions is:
To remove or to add clauses ?
That is, simplifying the formula or adding inference power ?
Regarding resolvents, they are typically added.
3.3
Comparison with Local Consistency Notions for CSP’s
UCP is the natural mechanism for extending a partial assignment by the obvious
inferences. In the language of constraint satisfaction problems, UCP establishes
node-consistency (while hyper-arc consistency for clause-sets is trivially fulﬁlled).
More generally, for k ≥1 call a clause-set F rk-reduced if rk(F) = F holds
(so r1-reduced is the same as node-consistency). How is this consistency notion
related to strong k-consistency for k ≥1 and clause-sets F (i.e., for every partial
assignment ϕ using strictly less than k variables and fulﬁlling ⊥/∈ϕ ∗F and for
every variable v there is an extension ϕ′ of ϕ with var(ϕ′) = var(ϕ) ∪{v}, such
that ⊥/∈ϕ′ ∗F)? Call a clause-set F closed under k-bounded resolution if for all
resolvable C, D ∈F with |C ⋄D| ≤k we have C ⋄D ∈F. Now it is easy to see
that F ∈CLS is strongly k-consistent for k ≥1 if and only if F is closed under
(k −1)-bounded resolution. So the question is, how is being rk-reduced related
to being closed under k′-bounded resolution:
1. r1 is suﬃcient to show unsatisﬁability of all Horn clause-sets, while for every k
there exists an unsatisﬁable Horn clause-set which is closed under k-bounded
resolution but ⊥/∈F, simply due to the incapability of bounded resolution
to handle large clauses.
2. Via small strengthenings of “bounded resolution” however, as discussed in
[26], we obtain versions of “k-resolution” which properly generalise rk for
k ≥2.
So in a sense by an adequate repair of the notion of strong (k + 1)-consistency
we obtain a consistency notion which is considerably stronger than being rk-
reduced, however the price is an explosion in memory consumption. One should
note here the diﬀerent contexts for “strong k-consistency” and “rk-reduced”:
– Algorithms for establishing strong k-consistency exploit that constraints as
sets of (satisfying) tuples allow to remove arbitrary tuples (which have been
found inconsistent), which is not possible with such simple “atomic con-
straints” as clauses.
– On the other hand, rk-reduction exploits application of partial assignments
by applying enforced assignments, which is supported due to the simplicity
of clauses, while constraints typically only handle assignments which cover
all their variables.

Present and Future of Practical SAT Solving
297
3.4
Other Reductions
3.4.1
Subsumption
Removing subsumed clauses is quite costly, and so mostly done only during
preprocessing. See [47] for subsumption elimination also during search, which
currently seems to be worth the eﬀort only for harder problems like QBF. This
is true for many somewhat more complicated algorithms:
SAT is too easy (currently) for them.
3.4.2
Equivalences
– Equivalences a ↔b often are detected (for conﬂict-driven solvers only during
preprocessing), and substituted.
– In general, clauses which correspond to linear equations over Z2 are some-
times (partially) detected, and some elementary reasoning on them is per-
formed; see [14] for an overview. Most recently however, these facilities seem
to be getting removed from “practical SAT solving”.
3.4.3
Autarkies
A partial assignment ϕ is an autarky for a clause-set F if every clause of F
touched by ϕ is satisﬁed by ϕ:
1. The empty assignment is always an autarky.
2. Every satisfying assignment is an autarky.
3. Composition of two autarkies is again an autarky.
4. Autarkies can be applied satisﬁability-equivalently, and thus we have autarky
reduction.
5. A simplest case of autarky reduction is elimination of pure literals.
6. Since clause-sets contract multiple clauses there is also the concept of a
weak autarky for a clause-set F, a partial assignment ϕ such that ϕ∗F ⊆F.
Every autarky is a weak autarky, but not vice versa. Also application of
weak autarkies yields satisﬁable equivalent (sub-)clause-sets.
Autarkies emerged in a natural way from improved exponential upper bounds on
SAT decision ([40,31,32,20]), while the accruing theory of autarkies ([22,25,23,
28,27]) focuses on polynomial-time SAT decision classes on the one hand (em-
bedding matching theory, linear programming and combinatorial reasoning into
the (generalised) satisﬁability world), and on the other hand on the structure of
lean clause-sets which are reduced w.r.t. autarky reduction. Via the notion of an
autarky system we obtain also generalisations of the notion of minimally unsatis-
ﬁable clause-sets, parameterised by special notions of autarkies. In Subsection 3.1
we have already seen initial examples of the use of autarkies in SAT solvers; and
see [33] for applications of the fundamental duality between autarkies and res-
olution. At this time the practical applications seem to be marginal, however
I expect this to change within the next 5 years (perhaps especially regarding
QBF); see [35] for a recent application.

298
O. Kullmann
3.4.4
Blocked Clauses
The concept of a blocked clause was introduced in [20], with a forerunner in [41],
and allows to add to or delete from F ∈CLS a special type of clause called
“blocked”:
– Clause C is blocked for F if there is some v ∈var(C) such that addition
resp. removal of C does not change the outcome of applying DPv (so one
could speak of “inverted DP-reduction”).
– Blocked clauses can be added / removed satisﬁability-equivalently.
– Addition of blocked clauses containing possibly new variables covers Ex-
tended Resolution; so in principle this is very powerful, but we have no
guidelines when to perform such an addition.
– Addition of blocked clauses without new variables still goes beyond resolu-
tion, as shown in [21], and could be interesting for SAT solvers (the obtained
additional inferred assignments are applied directly in [41] for special cases).
– Elimination of blocked clauses was implemented (lsat; see [44]), and can
help solving some special classes very quickly where all other solvers fail.
3.5
Poly-time Classes
Poly-time SAT-decidable classes can play a role for SAT solving as target
classes:
The heuristics aims at bringing the clause-set closer to the class,
and ﬁnally the special algorithm is applied.
However, in practice poly-time classes play yet no role for SAT:
1. They do not occur (on their own!).
2. They do not provide good guidance for the heuristics.
The essential lesson to be learned here seems to me:
Algorithms are more important than classes!
Solvers are algorithm-driven, that is, algorithms are applied also “when they are
not applicable”, and they are only good, if they are better “than they should
be”. (And algorithms need a lot of attention and care; they have their own rights,
and are not just “attachments” to classes.) For some examples, let us examine
the 3 main Schaefer classes:
2-CNF. Unsatisﬁable instances are handled by failed literal elimination, while
satisﬁable instances are handled by simple autarky reduction. So some look-
ahead solvers solve them “by the way”; but it’s not worth looking for them.
Horn. Unsatisﬁable (renamable) Horn are handled by UCP; there have been
many attempts to integrate also the satisﬁable cases, but they all failed
(in practice). Perhaps a main problem with this class is its brittleness (as
clause-sets), while for example the closure under renaming makes it more
complicated to deal with, and on the unsatisﬁability side we still have a
rather trivial class (solved by UCP).

Present and Future of Practical SAT Solving
299
Aﬃne. This is the only case of some interest (and further potential), since
equivalences do occur in special cases, and resolution cannot handle them
eﬃciently. However, due to their special character, aﬃne formulas (resp. their
expressions as clause-sets) do not serve as a target class, but are handled by
dedicated reasoning mechanisms (see Subsection 3.4.2 above), which could
be understood as being handled by specialised “dynamic constraints”.
The above statement “it’s not worth looking for 2-CNFs” means
– Applying a special test for detecting the (narrow) class of 2-CNF seems to
be rather useless.
– Heuristics aiming (just) at bringing down a clause-set to a 2-CNF are too
crude.
However, for look-ahead solvers 2-CNFs are kind of basic:
Some algorithms used to solve 2-CNF (and Horn) are important —
since these algorithms can solve much more than just 2-CNF (or Horn)!
I hope this illustrates the assertion “algorithms more important than classes”.
4
DPLL in General
In this section now we outline the “modern DPLL scheme”, with look-ahead
solvers (see Section 5) and conﬂict driven solvers (see Section 6) as special cases.
First a note on terminology: “DP, DLL, DPL, DPLL” — these four combinations
have been used to describe backtracking algorithms with inference and learning:
1. “DP” is incorrect, since [7] only introduced DP-reduction (see Subsection
3.2) but not the splitting approach.
2. “DLL” refers to [6], the basic backtracking algorithm with unit-clause propa-
gation, elimination of pure literals, and a simple max-occurrences heuristics.
3. “DPL, DPLL” acknowledge the inﬂuence of Putnam.
The following pattern seems reasonable (and not uncommon):
1. “DP” for DP-reduction (as it is standard now);
2. “DLL” for simple backtrackers;
3. “DPLL” for the combination of backtracking with resolution (including clause-
learning).
4.1
Modern DPLL
A general scheme G for DPLL algorithms is now presented, comprising look-
ahead as well as conﬂict-driven solvers. The input is F0 ∈CLS (possibly after
pre-processing). A global variable L0 contains the learned clauses, and we have
F0 |= L0 throughout. Thus learning as reﬂected by L0 is “global learning”, that
is, the learned clauses are always to be interpreted w.r.t. the original input F0
(and not w.r.t. the respective residual clause-sets at each node). Initially L0 is

300
O. Kullmann
empty. A parameter, the “history stack” H, contains the information how to
interprete L0 in the current situation, denoted by H ∗L0 ∈CLS (this might
be just application of the partial assignment according to the current path,
but it might also contain renamings, substitutions, etc.). Furthermore via H
we can also perform “conﬂict analysis” (which is not further speciﬁed here;
for a concrete example see Subsection 6.1.1), and relate a “residual conﬂict”
to F0. Besides the global variable L0 (which might be accessed from parallel
processes or threads, and thus might need access-control), the procedure G is a
normal recursive function, with a clause-set F as ﬁrst argument and H as second
argument (following standard scope rules; initially F is F0 and H is empty), and
returning an element of {0, 1, ∗}, where “∗” stands for “unknown”. The history
“stack” H actually needs to be readable as a whole for conﬂict analysis, and thus
one should better speak of the “history list”, but since we mention explicitely
only the stack operations (mirroring the ups and downs of the current path) we
stick to the notion of a “stack”.
G(F ∈CLS, H) : {0, 1, ∗}
0. Initialise the local history H as empty.
1. Reduction:
(a) F := r(F, H ∗L0);
(b) add the information about this reduction to H.
2. Analysis:
(a) Success: If F = ⊤then return 1.
(b) Conﬂict learning and backtracking: If ⊥∈F then
i. via H compute a set L of learned clauses;
ii. L0 := L0 ∪L;
iii. H.pop();
iv. return 0.
(c) Non-chronological backtracking: Otherwise, if appropriate then
i. H.pop();
ii. return ∗.
3. Branching: Compute a ﬁnite set B ⊆PASS of partial assignments, and for
all ϕ ∈B do (possibly in parallel)
(a) H.push((H, ϕ));
(b) δϕ := G(ϕ ∗F, H);
(c) if δϕ = 1 then F := ⊤;
(d) if δϕ = 0 then F := F ∪{Cϕ}.
If these computations are not performed in parallel, then sort B appropriately
before these computations, and break this loop (over ϕ ∈B) in case of δϕ = 1.
4. Goto Step 1.
Due to the given speciﬁcations, the returned result is always correct; we are
not concerned here about establishing general rules for termination (which is
not too complicated), nor are we concerned about completeness (equivalent to
not performing a non-chronological backtrack at the root of the search tree) —
these properties are easily established for the special cases we consider later.
Explanations and remarks:

Present and Future of Practical SAT Solving
301
– The map r : CLS × CLS →CLS is any “reduction”, where we just require
that r(F, L) is always satisﬁability-equivalent to F ∪L; the separation into
two arguments enables special treatment of learned clauses.
– The purpose of the learning step is to enable the reduction r to circumvent
the same conﬂict earlier in the future (when a similar situation arises).
– Non-chronological backtracking is performed if the current situation is better
handled at a lower level (closer to the root) in the search tree; this includes
the case of a (complete) restart as a special case (through repetition of this
step).
– The elements of B are the “decision assignments”:
• For a look-ahead solver there is a variable v with B = {⟨v →0⟩, ⟨v →1⟩},
where v is the “branching variable”. Thus if both branches returned “un-
satisﬁable”, then the analysis step will conﬁrm the current F as unsat-
isﬁable.
• For a conﬂict-driven solver there exists a variable v (again called the
“branching variable)” and ε ∈{0, 1} with B = {⟨v →ε⟩}, and thus here
the iterative character of G is emphasised.
– Sorting of B shall take advantage of an early success (i.e., a satisfying assign-
ment was found) in some branch: Imagine the situation where one branch is
a hard unsatisﬁable problem, while the other is an easy satisﬁable problem
— if not already performed in parallel, then we gain a large speed-up if we
have put the satisﬁable branch ﬁrst.
– Note that the return value in Step 3b might be ∗, in which case just another
iteration of the loop is performed.
– Pushing the item “(H, ϕ)” onto the history stack means that we can recon-
struct how from the current F0 ∪L0 we obtained the current F (through
the successive reduction steps as stored on the (whole) stack) and which
decisions were involved. The only point where H is used is Step 2(b)i, where
we compute the learned clauses derived from the conﬂict (and since learned
clauses are “global” we need to re-connect the current F to the global level);
the loose concept of the history stack is just there to make the ﬂow of infor-
mations more visible.
– At Step 3d a “local learning” step is performed (compare Subsection 7.2),
that is, the learned clause Cϕ is added to the residual clause-set F, and is not
traced back to F0. One could also apply conﬂict analysis here, but regarding
the character of local learning it seems more appropriate to use the cheaper
“full clause-learning” here.
There exist further global monitoring schemes:
– removal of “old” learned clauses;
– using some form of breadth-ﬁrst search (typically at an early level);
– re-arranging the call order over an initial part of the search tree according
to some statistical analysis (compare Subsection 5.3.3).
However yet these extensions have more the character of an “add-on”, and time
seems not ripe yet to formulate more general patterns, whence these schemes are

302
O. Kullmann
not present in G. An important point here is that we have a recursive element of
G, present in the branching step in case of |B| ≥2, and an iterative element by
looping through Steps 1 to 3: Look-ahead solvers (see Section 5) only use this
recursive (parallel(!)) aspect, while conﬂict driven solvers (see Section 6) focus
on the iterative aspect (since there always |B| = 1 is the case, the recursion can
be eliminated altogether, as done in algorithm cd in Subsection 6).5
4.2
The Role of Partial Assignments and Resolution
There are two fundamental possibilities when applying partial assignments for
branching in Step 3b:
eager. Really apply the assignment, so that at each node we only see the sim-
pliﬁed instances;
lazy. Only record the assignment, and interprete the clauses as they are visited.
Since look-ahead solvers perform a lot of work at each node, they tend to be “ea-
ger” while conﬂict-driven solver are all “lazy” (if they perform non-chronological
backtracking then the work would get lost anyway). Important:
Application of partial assignments happens “in place”, not by copying the
instance, but by modiﬁcation and undoing the modiﬁcation.
Naturally, undoing the assignment(s) is easier for lazy data structures, but eager
data structures pay oﬀin case of heavy local workloads (as for the look-ahead).
DPLL solvers are based on a strong connection to tree resolution and strength-
enings (see Subsection 7.1). I regard this as the backbone of SAT solving: Res-
olution is the “logic of partial assignments”, for CSP and beyond, and can be
based on a simple algebraic framework (see [26]). In this sense “SAT” and “CSP”
can be seen as complementary: Where SAT emphasises the (global) operation of
partial assignments on the problem instance, CSP puts more emphasise on ex-
ploiting (local) structure of constraints. The resolution connection explains also
intelligent backtracking: By just computing the variables (really) used in the
resolution refutation found, intelligent backtracking is possible (implemented in
the OKsolver-2002; see Subsection 7.1).
5
Look-Ahead Solvers
In the history of look-ahead solvers, two lines can be distinguished:
1. Posit ( [11], Satz ( [34]), and kcnfs ( [8])
2. Boehm-solver ( [4]) and the OKsolver-2002 ( [24])
while the march-solvers ( [13,15]) can be seen as combining those two lines.
5 These algorithmic aspects should not be mixed up with the purely implementational
aspects of simulating recursion in a look-ahead solver via an iterative procedure (using
additional stacks). Actually, if the main data structures for the problem instance use
in-place modiﬁcations (eagerly or lazily), and thus are not included in the recursion,
then according to my experience the diﬀerence in resource consumption between the
more elegant recursive approach and simulation of recursion is negligible.

Present and Future of Practical SAT Solving
303
The Boehm-solver introduced the special “two-dimensional linked-list” repre-
sentation of clause-sets as a prototype for an eager data-structure ( [18] discusses
the same idea in a diﬀerent context), which allows at each node to just see the
residual clause-set (after application of the current partial assignment), while
the OKsolver-2002, using this data structure, demonstrated at the SAT2002-
competition that a generic solver with full failed-literal reduction (i.e., r2), full
look-ahead and autarky reduction can be quite eﬃcient (see [45]). The line of
Posit, Satz and kcnfs uses a simpler data-structure, more in direction of lazy
data structures, where Posit uses partial r2, while Satz and kcnfs use partial
r2 and partial r3.
The general “world view” of look-ahead solvers could be summarised as fol-
lows:
– For hard problems (thus they can’t be too big; say several thousand vari-
ables).
– Failed literal reduction and extensions, intelligent heuristics and special struc-
ture recognition at the centre.
– The heuristics considers both branches as independent and assumes the worst
case. The choice of the ﬁrst branch (the “direction heuristics”, based on esti-
mating the probability of satisﬁability) is important on satisﬁable instances.
– Eager data structures, with lazy aspects for the look-ahead.
– The aim is as much as possible reduction of problem complexity by inferred
assignments (now and in the future).
5.1
The General Scheme for Look-Ahead Solvers
We present a simpliﬁed version of the general algorithm G from Subsection 4.1,
where now no conﬂict learning (and thus no history) is involved, and also no
non-chronological backtracking (but see below for examples of restricted usage
of global learning in look-ahead solvers to achieve “intelligent backtracking”);
on the other side now more details are given about the heuristics for branching.
la(F ∈CLS) : {0, 1}
1. Reduction: F := r(F).
2. Analysis: If F = ⊤then return 1, if ⊥∈F then return 0.
3. Branching:
(a) For each variable v ∈var(F) do:
i. For each ε ∈{0, 1} do:
A. Consider F v
ε := r′(⟨v →ε⟩∗F),
B. Compute a “distance vector” dv
ε ∈Rm, where component dv
ε(i)
for index i ∈{1, . . . , m} measures the progress achieved from F
to F v
ε in “dimension i”.
ii. Summarise the distance vector dv
ε ∈Rm by “distances” dv
ε ∈R>0.
iii. Combine the two distance values dv
0, dv
1 into ρv := ρ(dv
0, dv
1) ∈R>0.
(b) Choose a branching variable v with minimal ρv.

304
O. Kullmann
(c) Return max(la(⟨v →0⟩∗F), la(⟨v →1⟩∗F)), where in case of a non-
parallel computation the ﬁrst branch ε ∈{0, 1} is chosen such that F v
ε
appears more likely to be satisﬁable than F v
ε (and if the ﬁrst branch
returned 1 then the second branch is not considered).
Remarks
1. r′ is the reduction used only for the look-ahead; typically r ≈rk and r′ ≈
rk−1.
2. A distance vector dv
ϕ ∈Rm measures the progress from F to F v
ε in an m-
dimensional way; a simple example would be to use the number of variables,
the number of clauses and the number of literal occurrences (so here m = 3).
Since there are m components, some of them could be zero (no progress) or
even negative (deterioration) if the positive entries outweigh the non-positive
entries. See Subsection 5.3.1 for further discussions.
3. See Subsection 5.3.2 for the discussion of the “projection” ρ : R>0 × R>0 →
R>0.
4. In order to really present an “algorithm” (with well-deﬁned semantics, and
not just an “implementation”), the OKsolver-2002 performs the look-ahead
step 3a fully for all variables, while all other look-ahead solver only perform a
“partial look-ahead” on selected variables (this can be incorporated into the
above scheme by using appropriate low distance values for variables which
don’t get selected).
5.2
Reductions: Failed Literals and Beyond
The most important reductions for look-ahead solvers is given by the range from
r1 to r3, as presented in Subsection 3.1. The following methods are used to
increase eﬃciency:
1. (Additional) lazy data structures are used, employing time stamps to avoid
permanent re-initialisation.
2. Often only “promising” variables are considered for the failed literal reduc-
tion (thus weaker than r2), while for “very promising variables” a double-look
ahead is used (reaching r3 here); see [15] for a recent study.
3. A main problem with rk for k ≥2 is the (apparent) necessity to run over the
formula over and over again to determine whether one reduction triggered
other reductions. The simplest thing (perhaps ﬁrst used by the OKsolver-
2002) is to realise that if from x →1 we obtain y →1 while x →1 does not
yield a contradiction, then (later) y →1 on its own won’t reach a contradic-
tion neither (if nothing has changed meanwhile). This line of reasoning has
been considerably strengthened by “tree-based look-ahead” as introduced
in [13].
4. Strengthening of r2 by “local learning”: If unsuccessfully x →0 has been
tested (i.e., it does not yield a contradiction), but at least y →1 was inferred,
then the binary clause (x ∨y) may be learned (locally).

Present and Future of Practical SAT Solving
305
What is the point of local learning: Isn’t the clause (x ∨y) already “contained”
in the current formula, and we only get a shortcut? The point here is that x ∨y is
equivalent to ¬x →y as well as to ¬y →x, and the ﬁrst direction, “from x →0
infer y →1”, is given by the current formula, but the second direction “from
y →0 infer x →1” in general needs a higher level to be inferred; see Subsection
7.2 for more on local learning. All enforced assignments found (iteratively) by
rk strengthened with local learning are also found by rk+1, and thus r2 with
local learning (discussed in Section 3.5 in [19], an experimental feature of the
OKsolver-2002, and (partially) used by the march-solvers) can be seen as an
approximation of r3. An equivalent process to r2 with local learning is “hyper
binary resolution” ( [2]).
Regarding autarkies, basic autarky testing was included in the OKsolver-
2002, and further extended by the march-solvers, but yet it seems not of great
importance.
5.3
Heuristics
Given a multi-dimensional “distance vector”, the simplest possible way to pack it
into one number is to use a linear combination; for further information see [30,29],
while here we do not investigate this issue further, but assume that already a
“distance” is given.
5.3.1
Distances
The ﬁrst main task for the heuristics is:
Given the current F and the envisaged branch v →ε, how “far” do we get
when applying v →ε (and simpliﬁcations) ?
So for each variable v we get two positive real numbers (dv
0, dv
1) (the bigger
the better). Motivated by the 3-SAT upper bound in [20], the OKsolver-2002
introduced as distance
the number of new clauses.
This might be surprising, since we are not reducing the problem size — but
we want to maximise the future gains by the look-ahead reductions! Note that
a partial assignment is an autarky iﬀit does not produce new clauses; this
was the reason why autarky testing for branching assignments is included in
the OKsolver-2002. This distance turned out to be far better than the earlier
simple counts (which can be understood as approximations of the number of
new clauses created), and has been taken over by the march-solvers. Now, since
shorter clauses are better, we need clause weights. Despite many eﬀorts, yet no
convincing dynamic scheme exists. A reasonable heuristics gives weight ( 1
5)k−2
to new clauses of size k ≥2. (For random 3-CNF an empirically optimal scheme
is obtained around these values, and look-ahead solvers can be optimised quite
well for general purpose SAT solving by just looking at random formulas.)

306
O. Kullmann
5.3.2
Projections
Assume now that for each variable the pair (dv
0, dv
1) of positive real numbers
is given, and we want to “project” the pair to one value ρ(dv
0, dv
1), so that the
variable with minimal projection is best. For 2 distances, i.e., binary branching, it
turns out, that the product dv
0 ·dv
1 is good enough, that is, since we are here going
for minimisation, the reciprocal value. For arbitrary branching width, in [30,29] a
general theory on distances and projections has been developed (based on [20]),
which shows that in general there is exactly one projection, namely the “τ-
function”, and that for width two the product is a good approximation (while
in general, approximations are given by generalised harmonic means).
5.3.3
The First Branch
The most reasonable basic approximation for the probability of a clause-set
F being satisﬁable seems to consider F as a random clause-set in the constant-
density model, with mixed densities for the diﬀerent clause-sizes, and to compute
the probability that a random assignment satisﬁes such a random F, which
amounts to minimise
+
C∈F
−log(1 −2−|C|).
This was applied in the OKsolver-2002, and an alternative scheme of similar
quality is to minimise 
C∈F 2−|C|; for more information see [30]. Howsoever
the approximation is obtained, the choice of the ﬁrst branch is then to choose
the branch which looks more likely to be satisﬁable. [16] add an additional layer
of control by introducing a monitoring depth m (for example m = 15), and
when it comes to backtracking to this depth (where we have 2m nodes minus
the ones already decided), then the simple “chronological” backtracking order is
interrupted, but search continues with another branch at this level according to
the principles,
1. that the left branch is preferred over the right branch (because of the direc-
tion heuristics),
2. and that higher up the search tree the direction heuristics is more error-prone
(since the problems are bigger).
Good results at the SAT2007-competition are demonstrated.
6
Conﬂict-Driven Solvers
In this section we give an overview on the main innovations of “conﬂict-driven”
solvers, centred around the notion of “clause learning”. The basic intuitions
behind conﬂict-driven solvers seem to be as follows:
– for “simple” but big problems (up to millions of variables);
– optimised for problems from model checking and circuit veriﬁcation;
– “fast and cheap” (light-weight), nowadays only lazy data structures are used;
– zero look-ahead for the heuristics, just unit-clause propagation reduction;
– the basic aim is: seek for conﬂicts, learn much.

Present and Future of Practical SAT Solving
307
Historically, one might distinguish 3 main phases:
1. Around 1996 learning was introduced to SAT by Grasp ( [43]), motivated
by previous work in the constraint satisfaction area, but adding the speciﬁc
“SAT point of view”, heavily exploiting clauses and their integration with
the problem instance itself.
2. Around 2001 laziness and streamlined learning together with an associated
heuristics was introduced by Chaff ( [37]), emphasising the “fast and cheap”
attitude. The success of this solver was the main breakthrough, and the
related ideology of a “modern solver” started spinning.
3. Finally, Minisat started the “clean up” (for an introduction with algorithms
and implementations see [10]).
6.1
Learning
For some initial theoretical analysis (in the framework of proof complexity) see
[3]; in this article we focus more on the conceptual side.
6.1.1
The Basic Ideas
Assume a DPLL-solver reached a conﬂict, that is, for the current partial assign-
ment ϕ we have ⊥∈ϕ ∗F (where ϕ collects all the assignments leading to the
current node). The idea is to learn about the conﬂict so that we can early (!)
avoid it at other places in the search tree (thus going beyond tree resolution):
More precisely, we want to learn a “conﬂict-clause” L
(adding it to the clause-set F)
such that F |= L and ϕ(L) = 0.
The condition ϕ(L) = 0 is equivalent to L ⊆Cϕ, and so this part of the learning
condition is perfectly clear. It is the ﬁrst condition, which is equivalent to ϕL ∗F
being unsatisﬁable, which has a wide scope (being a coNP-complete problem),
and where all the variation lies. In Section 7, based on the general considerations
from Subsection 2.2.3, approaches towards a general theory of learning are out-
lined, which might give better explanations of the fundamental ideas of “clause
learning” and might open new and more powerful perspectives for the future,
especially for the uniﬁcation with look-ahead solvers. Here now I outline the
“traditional” ideas underlying learning in the context of conﬂict-driven solvers.
First we specify the situation. Let var(ϕ) = {v1, . . . , vn(ϕ)} be ordered ac-
cording to the sequence of unit-clause-eliminations and decisions along the path,
where i1 < · · · < id are the indices of the decision variables. So d ∈N0 is the cur-
rent depth in the search tree, and, using ϕi := ϕ | {v1, . . . , vi} and Fi := ϕi ∗F
for i ∈{0, . . . , n(ϕ)}, we have that for p ∈{1, . . ., d} the clause-set Fip−1 is
reduced w.r.t. r1, so that decision variable vip ∈var(Fip−1) was needed for fur-
ther progress, while for p ∈{0, . . ., d} and ip < j < ip+1 (with i0 := −∞and
id+1 := +∞) we have {xj} ∈Fj−1, where var(xj) = vj and ϕ(xj) = 1 (this just
means that xj was obtained by unit-clause-elimination). Furthermore assume

308
O. Kullmann
⊥∈ϕ ∗F, that is, we reached a conﬂict, and thus n(ϕ) > id; we also assume
d ≥1 (so that we are not already done). Now we have:
1. It’s (nearly) completely senseless to learn Lϕ (the full path), since the re-
cursive traversal of the search tree will avoid this path anyway, except of
schemes with restarts or non-systematic backjumping, where completeness is
only guaranteed by clause-learning, and where actually this simplest scheme
of learning just the full path is suﬃcient to establish completeness.
2. By deﬁnition there is a clause L0 ∈F with ϕ(L0) = 0. Now L0 itself is also
not very exciting (we know it already), but perhaps we can do something
about it? We know that there is id < j ≤n(ϕ) with vj ∈var(L0) (at least
one implied variable from the current level must be involved).
3. Consider any inferred variable vi ∈var(L0), and thus xi ∈L0. When infer-
ring vi, an implication
	
j∈J
xj →xi
has been established with J ⊆{1, . . ., i −1}. Thus we can replace xi in L0
and obtain L1 := (L0 \{xi})∪{xj : j ∈J}, using that the above implication
is equivalent to ¬xi →
j∈J ¬xj.
4. This process of “conﬂict analysis”, replacing inferred literals by their premises
(using contraposition), can be repeated, obtaining L2, . . . , maximally until
only decision variables are left, obtaining a “strongest” conﬂict-clause L∗.
That’s all about the basics of (current) clause-learning, and all learning schemes
essentially just vary in
– which inferred literals are replaced, and how far to go back with this process;
– what conﬂict-clauses then actually to “learn”, i.e., to add to F (we might
learn several of the Li above, and potentially also some “side-clauses” in-
volved in the derivation);
– and when learned clauses will be eliminated again (there might be a large
number of learned clauses).
The point in adding clause L to F is to enable future tree pruning by more in-
ferred variables (see Subsection 6.1.4) and to guide the “non-chronological back-
jumping” process (see Subsection 6.1.2). Performing “conﬂict analysis”, that is,
recovering the implications in Step 3, is quite simple for a conﬂict-driven solver:
Since such a solver only performs unit-clause-propagation as reduction, every
inference step, that is, every new inferred assignment, is witnessed by an exist-
ing clause, in the above case by the clause Ci := {xj : j ∈J} ∪{xi} ∈F, and
thus together with the assignment xi →1 a pointer to Ci is stored. This doesn’t
cause much space overhead, and when doing the conﬂict analysis, one only has
to look-up the inferred literals in the current envisaged learned clause L and to
decide whether to perform the substitution process of Step 3 (which corresponds
to a so-called “input resolution” step). We conclude this introduction into the

Present and Future of Practical SAT Solving
309
learning process by some observations on clauses Lp obtained in the process of
conﬂict analysis:
1. Every Lp contains some variable from level d > 0 (that is, there is i ≥id
with vi ∈var(Lp); this is not necessarily true for d = 0, since for this level
there is no decision variable, but it is the initialisation of the process).
2. If Lp contains some variable from level q, then this is also true for all p′ ≥p;
for p′ large enough we have var(Lp′) ∩{vi : iq ≤i < iq+1} = {viq} (with
xiq ∈Lp′).
6.1.2
Dynamic Aspects of Clause-Learning
One aspect of learning seems most important to me, and it is here that CNF
plays an important role: The learned clauses are fully integrated into the original
problem, and this can happens here in a simple way, since the original problem is
given as a CNF, and we learn clauses. It is this dynamic aspect which gives the
power to clause-learning, and also makes it a much more complicated process
than it ﬁrst appears.
Consider the situation from the previous Subsection 6.1.1, and moreover we
consider the point where the ﬁrst clause is learned, that is, we are on the left-
most branch of the branching tree and encounter the ﬁrst conﬂict (so the current
clause-database F0 is the original input-clause-set6). The clearest approach is to
consider a “purged” conﬂict-clause L∗(which only contains decision variables).
To make the example simpler, let’s assume that the depth d of the current leaf
is 100. L∗necessarily contains the literal xi100; in the best of all cases that’s
it (since conﬂict-driven solvers only use r1-reductions, this would amount to a
r2-reduction for F0), but in general many more of the literals xi1, . . . , xi99 will
appear in L∗. The worst case is that L∗contains all of them, and then L∗is
essentially useless, but let’s be optimistic and assume that L∗= {xi1, xi50, xi100}.
We see now that at depth 50 of the current path, that is for Fi50, we could
have inferred the assignment ⟨xi100 →1⟩(in general, if the solver uses rk-
reduction, this amounts to a rk+1-reduction). This is now the point where “non-
chronological backtracking” sets in (actually taking an “eager approach”), and
the whole tree starting with this node (which in our assumed case is yet just a
path) is reworked, since already the node at level 50 is no longer reduced with
respect to r1, and decision variables vi51, . . . , vi99 possibly could be turned into
inferred variables (and furthermore, given the new situation the heuristics might
decide diﬀerently).
Whatever the learned clause L is, all implied literals from level 100 should
be eliminated (i.e., for vi ∈var(L) we have i ≤i100), and then in any case
the previous decision variable vi100 is now turned into an inferred variable, with
the forced value the opposite of the previous value. Thus, while search in the
“chronological” recursive approach would consider the second branch belonging
to the decision level 100, the non-chronological approach goes back to decision
6 With “current” we refer to the possible additions of learned clauses, and not to the
“residual” clause-set obtained by applying the current partial assignment.

310
O. Kullmann
level 50 (99 in the worst case). We see now why the algorithms for conﬂict-
driven solvers are better expressed as an iterative procedure (instead of the usual
recursive presentation), where branching and backtracking is just managed by
increasing resp. decreasing the decision level, and where the second branch is
induced by the conﬂict clauses: It is not just a matter of convenience, but the
clear tree structure (as used by look-ahead solvers) is blurred by doing “partial
restarts” in the form of non-chronological backjumping (restarting at Fi50 in
the above example) and leaving the alternation of branches to the inference
mechanism — so actually there is no “second branch”, and in a sense we are
always in the above situation, with just a left-most branch, only that F0 grows
over time (and in practice also shrinks, due to the removal of “inactive” learned
clauses — this makes the whole process completely mysterious, and I will mostly
ignore this aspect here). A ﬁnal remark here: As already stated for the general
case, the learned clause in the above case must include some variable from level
100 (since otherwise we would have found the conﬂict at an earlier level), and
if we then would ﬁnd (directly) a conﬂict at level 50, again the conﬂict clause
must then use some variable from level 50; if however we backtrack to level 0,
then there is no decision variable at this level, and thus here we might learn the
empty clause and thus conclude that the original input is unsatisﬁable.
6.1.3
The Iterative Solving Scheme
More precisely, the iterative (“conﬂict-driven”) procedure cd : CLS →{0, 1}, a
special case of the general procedure G from Subsection 4.1, works as follows.
We use d ∈Z for the decision level (with d = −1 indicating an “impossible
backtrack”). Instead of managing one global current partial assignment ϕ ∈
PASS, which is expanded on branching and shrunk on backtracking, for the
clarity of exposition we use ψi ∈PASS for the initial partial assignment at level
i, while ψ′
i ∈PASS is the extended partial assignment with forced assignments
added:
cd(F ∈CLS) : {0, 1}
0. Initialisation: d := 0, ψd := ∅. If ⊥∈F, then return 0.
1. Reduction: Let ψ′
d be obtained by unit-clause-propagation on ψd ∗F, that
is, ψ′
d ⊇ψd with ψ′
d ∗F = r1(ψ′
d ∗F) = r1(ψd ∗F).
2. Analysis: Evaluate ψ′
d ∗F.
(a) If ψ′
d ∗F = ⊤, then return 1.
(b) If ⊥∈ψ′
d ∗F then backtrack:
i. Compute a conﬂict-clause L /∈F (with var(L) ⊆var(F)) w.r.t. ψ′
d.
ii. F := F ∪{L}.
iii. While d ≥0 and ⊥∈ψ′
d ∗F do d := d −1.
iv. If d = −1 then return 0.
v. While d ≥1 and r1(ψ′
d−1 ∗F) ̸= ψ′
d−1 ∗F do d := d −1.
vi. Go to Step 1.
3. Branching:
(a) Choose a branching variable v ∈var(ψ′
d ∗F) and ε ∈{0, 1}.
(b) d := d + 1, ψd := ψ′
d−1 ∪⟨v →ε⟩.
(c) Go to Step 1.

Present and Future of Practical SAT Solving
311
Explanations and remarks:
1. Procedure cd is correct and also always terminates (whatever the conﬂict-
clause is — if only it is just a new clause).
2. The main choices are the choice of branching variable and ﬁrst branch in Step
3a, which is discussed in Subsection 6.2, and the choice of the conﬂict-clause
L, which is discussed in Subsection 6.1.4.
3. The conﬂict-clause L in Step 2(b)i can be chosen here according to the most
loose semantics, namely any clause L with L ⊆Cψ′
d and F |= L. It seems not
being discussed in the literature, but in the OKlibrary we are experimenting
with an “afterburner” for clause-learning, which uses additional reasoning
power for strengthening the conﬂict-clause7, and then in Step 2(b)iii possibly
the “real backtrack” (the backtrack which is necessary) could be more than
one step, but if learning is restricted to the conﬂict analysis from Subsection
6.1.1, then in Step 2(b)iii the depth d is decremented exactly once.
4. In the above formulation of cd we consistently used applications of partial
assignments to the original input, and not to residual formulas, in order to
emphasise the “lazy” aspect of handling the application of partial assign-
ments.
5. Step 2(b)v is the non-chronological backtracking step:
(a) Correctness and termination does not depend on this step (but only on
the added conﬂict clauses): We could leave it out, or backtrack even
further; backtracking to level d = 0 would be a full restart (while still
keeping the learned clauses(!)).8
(b) If r1(ψ′
d−1 ∗F) ̸= ψ′
d−1 ∗F, i.e., one level down there are further unit-
clause eliminations possible, then we have also r1(ψ′
d ∗F) ̸= ψ′
d ∗F. So in
general the decision levels after adding the conﬂict-clause can be divided
into three connected parts: At the end we have the “contradicting levels”
(only d in the standard situation), then come the “active levels” where
further unit-clause propagations are possible, and Step 2(b)iii jumps to
the beginning of this segment, and ﬁnally (i.e., at the beginning of the
decision stack) we have the “unaﬀected levels” (this segment is empty iﬀ
we learned a clause L which after elimination of level-0-variables contains
at most one literal).
(c) Since we only learn one clause L (instead of several clauses) and only use
r1 (instead of for example r2), the condition “r1(ψ′
d−1 ∗F) ̸= ψ′
d−1 ∗F”
is equivalent to |ψ′
d−1 ∗L| = 1, that is, all but exactly one literal in L
is falsiﬁed by the “current” partial assignment of level d −1. This is the
condition as normally stated, but the condition in Step 2(b)v seems to
be the real underlying reasoning (also allowing to use stronger means
than r1).
7 This is more natural for “look-ahead solvers”, since they have a stronger reasoning
machinery anyway.
8 However if this step is not performed fully then the “real backtrack” in Step 2(b)iii
could involve more than one level even when sticking to the conﬂict analysis from
Subsection 6.1.1, since earlier decision levels might have unprocessed unit-clause
propagations.

312
O. Kullmann
6.1.4
Learning Schemes
Now we consider Step 2(b)i in algorithm cd from Subsection 6.1.3 in more de-
tail; in Subsection 6.1.1 we have outlined the general idea, resulting in a non-
deterministic sequence L0, . . . , L∗of conﬂict clauses (but with well-deﬁned ﬁrst
and last element), and the question is now which Lp to learn.
As we have already explained, in order to make the backtracking system
“aware” of the fact, that the decision xid →1 was a failure, and hence xid →0
is inferred, we need ⊥∈ψd ∗F after the learning step, i.e., all inferred literals
from level d must have been eliminated in the learned clause L (such a conﬂict-
clause then is called “asserting”). Just performing such elimination steps (that is,
only eliminating inferred literals from level d) we obtain a well-deﬁned conﬂict-
clause L+, which can be considered as the “weakest” conﬂict-clause, while at the
other end of the spectrum we have the “strongest” conﬂict-clause L∗, where all
possible elimination steps have been performed (and only decision variables are
left). All existing learning schemes are situated between L+ and L∗, where the
choice of L+ is called “1UIP” ( [48]), while the choice of L∗has been given diﬀer-
ent names like “decision cut”.9 Unfortunately not much can really be said here,
but let us consider the most fundamental decision, between L+ and L∗. Above
they have been called “weakest” and “strongest” according to the eﬀort involved
to obtain these clauses — now is this really true, that is, does the increased eﬀort
for computing L∗at least pay oﬀin a smaller search tree? Due to the “sporadic”
character of problem instances where conﬂict-driven solvers are successful (not
on the most amenable instances for systematic studies, random formulas, where
conﬂict-driven solvers perform badly), and due to the high sensitivity of solvers
regarding the learning process (which is determinative for the heuristics), it seems
that all empirical arguments are rather weak. And there are no theoretical results
in any form. However, “in practice” L+ (that is, the 1UIP-scheme) turns out to be
the winner (and this for all learning schemes). It seems that despite all arguments
for various schemes now the ﬁeld of conﬂict-driven solvers converges on 1UIP.
As we have already mentioned, if some variable from level i is involved, then
never level i can be emptied (because we only use the old inferences), and since
the literal elimination process replaces literals by literals with smaller indices, we
see that for the non-chronological backjump depth the clause L+ is as good as L∗
or anything between, so this step is not inﬂuenced by the learning scheme. In [9]
it is argued that 1UIP has an advantage over other schemes because empirically
more unit-clause propagations are enabled by these conﬂict-clauses (one could
roughly say that 1UIP oﬀers more “surface” for future conﬂicts (i.e., resolution
steps), while going far back somehow narrows the choices). At other places it is
furthermore argued that going “far back” conﬂicts with the idea of “locality”,
namely that statistics on usage of conﬂict clauses shall guide the branching
heuristics.
9 This is perhaps the right point to remark that I fail to see the point of the common
“cut terminology”, where a (fake) directed graph is constructed recording the events
of literal inferences: The (in principal) very simple character of learning is obscured
in this way, and if graph-theoretical notions shall be employed then one should use
the appropriate notion of directed hypergraphs here.

Present and Future of Practical SAT Solving
313
6.2
Heuristic
Finally we investigate the heuristics for the choice of branching variable v and
branching value ε in Step 3a of procedure cd from Subsection 6.1.3. It seems
that regarding the heuristics, conﬂict-driven solvers still live in the “stone age”
of simple literal counts, far behind look-ahead solvers — but they have one
special weapon, based on the dynamic nature of the “clause database” due to
the added conﬂict-clauses. However, compared to the situation for look-ahead
solvers, where we have two independent branches and thus the total workload
is minimised while as ﬁrst branch one is chosen which could make a diﬀerence
(i.e., where actually the independence breaks down, since in case of a satisﬁable
assignment found we simply abort), here now the notion of “branches” is broken
open, and a more global situation has to be faced. The current guideline seems
to be a greedy approach, seeking for as many “proﬁtable” conﬂicts as possible.10
Regarding the branching value, there are two conﬂicting goals: Seeking for
“good” conﬂicts, or trying to ﬁnd a satisfying assignment. In [37] the greedy
choice of searching for conﬂicts is also applied to the branching value, but ap-
parently this wasn’t very successful and the simple choice ε := 0 seems to be
more popular and still the prevalent method (and only with SAT 2007 some
discussions started regarding an improved choice). Perhaps due to their weak
“statistical infrastructure”, conﬂict-driven solvers don’t have good measures at
hand to estimate the probability of satisﬁability, and thus do not employ a
direction heuristics as discussed in Subsection 5.3.3 for look-ahead solvers. Fur-
thermore it seems that on many instances coming from hardware veriﬁcation
actually truth value 0 is a reasonable choice due to the special encoding. And,
as already mentioned, while for a look-ahead solver in principle the direction is
clear (towards satisﬁability), for a conﬂict-driven solver also a “fruitful conﬂict”
might be attractive.
Now regarding the branching variable (for an overview on some techniques see
[37]) the basic is just the (static) literal count for the input clause-set (preference
for higher counts). This static count evolves into some activity measurement by
dynamic updates:
– learning a clause containing the variable increases the activity;
– the activity decays over time.
Following the “locality idea”, branching variables are chosen which have the
highest activity. The motivation for such schemes might be summarised by
Where are many conﬂicts, there will be more.
And conﬂicts are good (since they cut oﬀbranches).
Various schemes about how much to increase and to decay have been proposed,
but it seems to me that only the idea of variable activity regarding activity in
conﬂict-clauses has fundamental virtues.
10 Perhaps it is this analogy which drives proponents of conﬂict-driven solvers to call
their approach “modern”, while denying this qualiﬁcation to “modern” look-ahead
solvers: “Modern” in a sense of “modern (disaster) capitalism”, and “old-fashioned”
in the sense of “socialistic planning”.

314
O. Kullmann
7
Towards a General Theory of Clause-Learning
In this ﬁnal section I want to present some general ideas and methods which
extend clause-learning, and can help putting it into a wider context.
7.1
From Branching Trees to Resolution Trees
The essential ﬁrst step in understanding clause-learning is to understand the
full translation of backtracking trees (possibly with local reductions like rk) into
resolution trees. A complete presentation in a general context is given in [26],
but the principle is very simple:
1. Unfold the backtracking tree, replacing rk-reductions by little sub-trees in
(generalised) input-resolution-tree shape, ﬁnally obtaining a pure backtrack-
ing tree where nodes just represent splitting on variables.
2. At each leaf select a clause falsiﬁed by the partial assignment corresponding
to the path to that leaf.
3. Starting from the leaves, perform resolution operations where branching vari-
ables now become resolution variables.
4. Cases, where actually one of the parent clauses of an envisaged resolution
step does not contain the resolution variable, correspond to “intelligent back-
tracking”: Only this branch is kept, while the other is discarded.
A “global learning step” corresponds to creating the tree from the leaves in a
certain order and then allowing to link to the learned clause from later parts
of the graph (which becomes a dag now). Learning “non-conﬂict clauses” corre-
sponds to learning clauses from the “little sub-trees” corresponding to inference
steps.
7.2
Local Versus Global Learning
Due to their lazy datastructures, conﬂict-driven solvers have problem seeing the
current clause-set (that is, with the current partial assignment applied), and
accordingly the clauses they learn are always “global”, that is, all assumptions
are carried out and the clause can be added to the original input clause-set.
However, it might be worth learning clauses ﬁrst “locally”, and unfolding the
assumptions (decisions) only when backtracking.
The simplest such learning scheme for look-ahead solvers has been already
mentioned in Subsection 5.2: Recall the r2-reduction from Subsection 3.1, and
assume that when testing the assignment x →1 we derived y →1 (by unit-clause
propagation) but we didn’t reach a failed literal (and thus r2 was unsuccessful
in this case); actually any reduction which allows from assumptions x →1 to
infer forced assignments y →1 can be used here. Though the reduction attempt
failed, nevertheless we gained some inference information, and how can we use
it? The derivation x ; y is just equivalent to the fact that the clause {x, y}
follows from the current clause-set, and thus it can be learned here. Note that the
clause {x, y} is a valid inference only “locally”, that is, w.r.t. the current partial

Present and Future of Practical SAT Solving
315
assignment (which is carried out in look-ahead solvers), while when backtracking
then either the clause must be “unfolded”, that is, some conﬂict analysis has
to be performed to make the assumption about the previous decision variable
explicit, or the locally learned clauses are just discarded when backtracking.
Let us again point out what is the use of locally learning the clause {x, y}:
For global learning, as described before, we mentioned the tree pruning eﬀect,
exploiting conﬂict analysis, which obviously cannot happen if we discard the
clause upon backtracking. And the implication x →y is contained in the current
formula anyway, so why learning {x, y} ? First, there is the aspect of a “short
cut”, but more importantly the clause {x, y} represents both implications x →y
and ¬y →¬x, and while the ﬁrst implication is found by the current reduction
scheme like rk, for the converse we need the next level of reduction rk+1 ! This
eﬀect is also active for global learning, and so learning of clauses L (as discussed
in Subsection 6.1.1) which still contain inferred literals can yield inferences which
are not obtained by the in a sense strongest learned clause L∗— again, the
“forward” implications are all contained in L∗, but the “backward” implications
need a higher level of reduction to come to light.
In the general DPLL-procedure G from Subsection 4.1, local learning is the
task of the reduction r: the learned clauses are discarded upon backtracking, and
only via Step 2(b)i of G (the formation of learned clauses) can information be
saved from oblivion. G doesn’t allow intermediate steps, the gradual unfolding
of learned information, and it seems to me that this should be an interesting
possibility to explore; for now however we only consider “pure” local learning.
We have already seen that rk-reduction with local learning can be simulated by
rk+1-reduction. Asking about the strength as a proof system of branching trees
with local learning in this sense is thus translated into the question about the
strength of branching trees with reduction rk+1 at each node. If k is ﬁxed, then
such trees can save a polynomial factor over simple branching trees (that is, over
tree resolution), which can be relevant for practice, but is less impressive from a
proof-theoretical point of view: The reason about the reduced strength of local
learning is that the learned clauses only gather information along the path from
the root to the current node, while a global learned clause gathers information
from its whole corresponding sub-tree. So aspects of global learning are deﬁnitely
necessary to reach greater proof-theoretic strength.
However a (theoretical) possibility for a form of local learning which can even
go beyond full resolution is that in Step 3d of G we use a branching B such
that {Cϕ : ϕ ∈B} is a hard unsatisﬁable clause-set.11 Yet such schemes were
rarely considered, and they look rather diﬃcult to make eﬃcient; a possibly more
accessible extension of resolution is considered in the following subsection.
7.3
Compressed Learning
In [26] resolution was generalised by using “oracles” ⊥∈U ⊆USAT for un-
satisﬁability, where the only condition is that U is stable under application of
11 The task then is to make B as “similar” to F as possible — the best case is to use
B = {ϕC : C ∈F} !

316
O. Kullmann
partial assignments. Using U = USAT trivialises everything, while U = {⊥} is
exactly tree resolution. The abstract point of view of [26] is that from a problem
instance P we “see” only whether for a partial assignment ϕ we have ϕ ∗P ∈U
or not, where in the positive case we learn Cϕ, and the set of all learned clauses
constitutes F which is the basis for some ordinary resolution process. For conﬂict-
driven solvers, U would be just the set of clause-sets refutable by r1 (that is, the
set of clause-sets containing an unsatisﬁable renamed Horn clause-set), while a
reasonable stronger U here could be the set of clause-sets refuted by r2 combined
with some form of equivalence reasoning. Learning only clauses consisting solely
of decision variables abstracts away from the inferences, and a strong U yields
smaller branching trees as well as shorter learned clauses. One should remark
here that in [26] a kind of simple “static” point of view is taken, and learning
happens only at the leaves while at inner nodes just resolution steps happen, but
obviously this can be made dynamic by taking the learned clauses into account
for new learning steps (and by using non-chronological backtracking).
A big problem (quite literally) for the uniﬁcation of look-ahead techniques
with the conﬂict-driven approach is that the latter focuses on rather big in-
stances, where the polynomial-time overhead of look-ahead solvers can actually
result in weeks(!) of wasted run-time (on a single instance). As envisaged in the
plans for the new OKsolver (which are contained in the OKlibrary themselves),
the usage of an “after-burner” for learning, which only turns on the stronger
inference machine for compressing clauses to be learned, could be a solution for
this problem.
8
Conclusion
There is something more fundamental to “clause-learning” and “conﬂict-driven
solvers” than, as suggested, “raw speed, super-eﬃcient implementations and
cleverly adapted heuristics”. Instead, the old paradigm of backtracking-search
has been made “reﬂective”, reﬂecting the search meta-level onto the problem
object-level. Perhaps only in the “puriﬁed context” of SAT (compared to CSP)
this paradigm could have been evolved further, given our current (lack of) un-
derstanding.
However, also the traditional backtracking approach has seen substantial im-
provements through the look-ahead techniques and the related theory of back-
tracking heuristics. There is a certain agreement that SAT has reached in a cer-
tain way three “local optima” (for local search, look-ahead and conﬂict-driven),
which actually seem to be three rather large plateaus. One opinion on this situ-
ation is that further progress with SAT lies mainly in considering applications,
the “user interface”, and integration with extensions. A (smaller) part of the
SAT community however believes that we just started, and I hope that with
this article some elements of the SAT-solvers to come have been outlined. If,
metaphorically speaking, the learning-based approaches created a mirror-cabinet
on the search process, the task is now to look behind the mirrors.

Present and Future of Practical SAT Solving
317
References
1. Ans´otegui, C., Bonet, M.L., Levy, J., Many`a, F.: Mapping CSP into many-valued
SAT. In: Marques-Silva and Sakallah [38], pp. 10–15, ISBN 978-3-540-72787-3
2. Bacchus, F., Winter, J.: Eﬀective preprocessing with hyper-resolution and equality
reduction. In: Giunchiglia and Tacchella [12], pp. 341–355, ISBN 3-540-20851-8
3. Beame, P., Kautz, H., Sabharwal, A.: Towards understanding and harnessing the
potential of clause learning. Journal of Artiﬁcial Intelligence Research 22, 319–351
(2004)
4. B¨ohm, M.: Verteilte L¨osung harter Probleme: Schneller Lastausgleich. Ph.D thesis,
Universit¨at K¨oln (1996)
5. Dalal, M., Etherington, D.W.: A hierarchy of tractable satisﬁability problems. In-
formation Processing Letters 44, 173–180 (1992)
6. Davis, M., Logemann, G., Loveland, D.: A machine program for theorem-proving.
Communication of the ACM 5, 394–397 (1962)
7. Davis, M., Putnam, H.: A computing procedure for quantiﬁcation theory. Journal
of the ACM 7, 201–215 (1960)
8. Dequen, G., Dubois, O.: Kcnfs: An eﬃcient solver for random k-SAT formulae. In:
Giunchiglia and Tacchella [12], pp. 486–501, ISBN 3-540-20851-8
9. Dershowitz, N., Hanna, Z., Nadel, A.: Towards a better understanding of the func-
tionality of a conﬂict-driven SAT solver. In: Marques-Silva and Sakallah [38], pp.
287–293, ISBN 978-3-540-72787-3
10. E´en, N., S¨orensson, N.: An extensible SAT-solver. In: Giunchiglia and Tacchella
[12], pp. 502–518, ISBN 3-540-20851-8
11. Freeman, J.W.: Improvements to propositional satisﬁability search algorithms.
PhD thesis, University of Pennsylvania (1995)
12. Giunchiglia, E., Tacchella, A. (eds.): SAT 2003. LNCS, vol. 2919. Springer, Hei-
delberg (2004)
13. Heule, M., Dufour, M., van Zwieten, J., van Maaren, H.: March eq: Implementing
additional reasoning into an eﬃcient look-ahead SAT solver. In: Hoos and Mitchell
[17], pp. 345–359, ISBN 3-540-27829-X
14. Heule, M., van Maaren, H.: Aligning CNF- and equivalence-reasoning. In: Hoos
and Mitchell [17], pp. 145–156, ISBN 3-540-27829-X
15. Heule, M., van Maaren, H.: Eﬀective incorporation of double look-ahead proce-
dures. In: Marques-Silva and Sakallah [38], pp. 258–271, ISBN 978-3-540-72787-3
16. Heule, M.J.H., van Maaren, H.: Whose side are you on? Finding solutions in a
biased search-tree (October 2007) (to appear)
17. Hoos, H.H., Mitchell, D.G. (eds.): SAT 2004. LNCS, vol. 3542. Springer, Heidelberg
(2005)
18. Knuth, D.E.: Dancing links. Technical Report cs/0011047v1, arXiv (November
2000), http://www.arxiv.org/abs/cs/0011047v1
19. Kullmann, O.: Investigating a general hierarchy of polynomially decidable classes
of CNF’s based on short tree-like resolution proofs. Technical Report TR99-041,
Electronic Colloquium on Computational Complexity (ECCC) (October 1999)
20. Kullmann, O.: New methods for 3-SAT decision and worst-case analysis. Theoret-
ical Computer Science 223(1-2), 1–72 (1999)
21. Kullmann, O.: On a generalization of extended resolution. Discrete Applied Math-
ematics 96-97(1-3), 149–176 (1999)
22. Kullmann, O.: Investigations on autark assignments. Discrete Applied Mathemat-
ics 107, 99–137 (2000)

318
O. Kullmann
23. Kullmann, O.: On the use of autarkies for satisﬁability decision. In: Kautz, H.,
Selman, B. (eds.) LICS 2001 Workshop on Theory and Applications of Satisﬁability
Testing (SAT 2001). Electronic Notes in Discrete Mathematics (ENDM), vol. 9.
Elsevier Science, Amsterdam (2001)
24. Kullmann, O.: Investigating the behaviour of a SAT solver on random formulas.
Technical Report CSR 23-2002, Swansea University, Computer Science Report Se-
ries (October 2002), http://www-compsci.swan.ac.uk/reports/2002.html
25. Kullmann, O.: Lean clause-sets: Generalizations of minimally unsatisﬁable clause-
sets. Discrete Applied Mathematics 130, 209–249 (2003)
26. Kullmann, O.: Upper and lower bounds on the complexity of generalised resolu-
tion and generalised constraint satisfaction problems. Annals of Mathematics and
Artiﬁcial Intelligence 40(3-4), 303–352 (2004)
27. Kullmann, O.: Constraint satisfaction problems in clausal form: Autarkies and
minimal unsatisﬁability. Technical Report TR 07-055, Electronic Colloquium on
Computational Complexity (ECCC) (June 2007)
28. Kullmann, O.: Polynomial time SAT decision for complementation-invariant
clause-sets, and sign-non-singular matrices. In: Marques-Silva and Sakallah [38],
pp. 314–327, ISBN 978-3-540-72787-3
29. Kullmann, O.: Fundaments of branching heuristics. In: Biere, A., van Maaren, H.,
Walsh, T. (eds.) Handbook of Satisﬁability. IOS Press, Amsterdam (2008)
30. Kullmann, O.: Fundaments of branching heuristics: Theory and examples. Tech-
nical Report CSR 7-2008, Swansea University, Computer Science Report Series
(April 2008),
http://www.swan.ac.uk/compsci/research/reports/2008/index.html
31. Kullmann, O., Luckhardt, H.: Deciding propositional tautologies: Algorithms and
their complexity, 82 pages (preprint) (January 1997),
http://cs.swan.ac.uk/∼csoliver/
32. Kullmann, O., Luckhardt, H.: Algorithms for SAT/TAUT decision based on various
measures, 71 pages (preprint) (December 1998),
http://cs.swan.ac.uk/∼csoliver/
33. Kullmann, O., Lynce, I., Marques-Silva, J.: Categorisation of clauses in conjunctive
normal forms: Minimally unsatisﬁable sub-clause-sets and the lean kernel. In: Biere,
A., Gomes, C.P. (eds.) SAT 2006. LNCS, vol. 4121, pp. 22–35. Springer, Heidelberg
(2006)
34. Li, C.M., Anbulagan: Heuristics based on unit propagation for satisﬁability prob-
lems. In: Proceedings of 15th International Joint Conference on Artiﬁcial Intel-
ligence (IJCAI 1997), pp. 366–371. Morgan Kaufmann Publishers, San Francisco
(1997)
35. Liﬃton, M., Sakallah, K.: Searching for autarkies to trim unsatisﬁable clause sets.
In: Kleine B¨uning, H., Zhao, X. (eds.) SAT 2008. LNCS, vol. 4996, pp. 182–195.
Springer, Heidelberg (2008)
36. Lov´asz, L., Naor, M., Newman, I., Wigderson, A.: Search problems in the decision
tree model. SIAM Journal on Discrete Mathematics 8(1), 119–132 (1995)
37. Mahajan, Y.S., Fu, Z., Malik, S.: Zchaﬀ2004: An eﬃcient SAT solver. In: Hoos and
Mitchell [17], pp. 360–375, ISBN 3-540-27829-X
38. Marques-Silva, J., Sakallah, K.A. (eds.): SAT 2007. LNCS, vol. 4501. Springer,
Heidelberg (2007)
39. Mitchell, D.G., Hwang, J.: 2-way vs. d-way branching for CSP. In: van Beek, P.
(ed.) CP 2005. LNCS, vol. 3709, pp. 343–357. Springer, Heidelberg (2005)
40. Monien, B., Speckenmeyer, E.: Solving satisﬁability in less than 2n steps. Discrete
Applied Mathematics 10, 287–295 (1985)

Present and Future of Practical SAT Solving
319
41. Purdom, P.W.: Solving satisﬁability with less searching. IEEE Transactions on
Pattern Analysis and Machine Intelligence 6(4), 510–513 (1984)
42. Segerlind, N.: The complexity of propositional proofs. The Bulletin of Symbolic
Logic 13(4), 417–481 (2007)
43. Marques Silva, J.P., Sakallah, K.A.: GRASP: A search algorithm for propositional
satisﬁability. IEEE Transactions on Computers 48(5), 506–521 (1999)
44. Simon, L., Le Berre, D.: The essentials of the SAT 2003 competition. In:
Giunchiglia, E., Tacchella, A. (eds.) SAT 2003. LNCS, vol. 2919, pp. 452–467.
Springer, Heidelberg (2004)
45. Simon, L., Le Berre, D., Hirsch, E.A.: The SAT2002 competition. Annals of Math-
ematics and Artiﬁcial Intelligence 43, 307–342 (2005)
46. Urquhart, A.: The complexity of propositional proofs. The Bulletin of Symbolic
Logic 1(4), 425–467 (1995)
47. Zhang, L.: On subsumption removal and on-the-ﬂy CNF simpliﬁcation. In: Bac-
chus, F., Walsh, T. (eds.) SAT 2005. LNCS, vol. 3569, pp. 482–489. Springer,
Heidelberg (2005)
48. Zhang, L., Madigan, C.F., Moskewicz, M.H., Malik, S.: Eﬃcient conﬂict driven
learning in a boolean satisﬁability solver. In: Proceedings of the International Con-
ference on Computer Aided Design (ICCAD), pp. 279–285. IEEE Press, Los Alami-
tos (2001)

Author Index
Bodirsky, Manuel
196
B¨orner, Ferdinand
38
Bulatov, Andrei A.
68, 93
Creignou, Nadia
3
Gottlob, Georg
156
Greco, Gianluigi
156
Jonsson, Peter
255
Kolaitis, Phokion G.
125
Krokhin, Andrei
93
Kullmann, Oliver
283
Larose, Benoit
93
Nordh, Gustav
255
Scarcello, Francesco
156
Schnoor, Henning
229
Schnoor, Ilka
229
Valeriote, Matthew A.
68
Vardi, Moshe Y.
125
Vollmer, Heribert
3

