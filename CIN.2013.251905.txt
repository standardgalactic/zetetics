An Overview of Bayesian Methods for Neural Spike Train Analysis
The MIT Faculty has made this article openly available. Please share 
how this access benefits you. Your story matters.
Citation
Chen, Zhe. â€œAn Overview of Bayesian Methods for Neural Spike
Train Analysis.â€ Computational Intelligence and Neuroscience 2013
(2013): 1â€“17.
As Published
http://dx.doi.org/10.1155/2013/251905
Publisher
Hindawi Publishing Corporation
Version
Final published version
Citable link
http://hdl.handle.net/1721.1/96120
Terms of Use
Creative Commons Attribution
Detailed Terms
http://creativecommons.org/licenses/by/2.0

Hindawi Publishing Corporation
Computational Intelligence and Neuroscience
Volume 2013, Article ID 251905, 17 pages
http://dx.doi.org/10.1155/2013/251905
Review Article
An Overview of Bayesian Methods for
Neural Spike Train Analysis
Zhe Chen1,2
1 Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, 43 Vassar Street, Cambridge, MA 02139, USA
2 Picower Institute for Learning and Memory, Massachusetts Institute of Technology, Cambridge, MA 02139, USA
Correspondence should be addressed to Zhe Chen; zhechen@mit.edu
Received 16 May 2013; Revised 10 September 2013; Accepted 23 September 2013
Academic Editor: Wei Wu
Copyright Â© 2013 Zhe Chen. This is an open access article distributed under the Creative Commons Attribution License, which
permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.
Neural spike train analysis is an important task in computational neuroscience which aims to understand neural mechanisms and
gain insights into neural circuits. With the advancement of multielectrode recording and imaging technologies, it has become
increasingly demanding to develop statistical tools for analyzing large neuronal ensemble spike activity. Here we present a tutorial
overview of Bayesian methods and their representative applications in neural spike train analysis, at both single neuron and
population levels. On the theoretical side, we focus on various approximate Bayesian inference techniques as applied to latent
state and parameter estimation. On the application side, the topics include spike sorting, tuning curve estimation, neural encoding
and decoding, deconvolution of spike trains from calcium imaging signals, and inference of neuronal functional connectivity and
synchrony. Some research challenges and opportunities for neural spike train analysis are discussed.
1. Introduction
Neuronal action potentials or spikes are the basic lan-
guage that neurons use to represent and transmit informa-
tion. Understanding neuronal representations of spike trains
remains a fundamental task in computational neuroscience
[1, 2]. With the advancement of multielectrode array and
imaging technologies, neuroscientists have been able to
record a large population of neurons at a fine temporal and
spatial resolution [3]. To extract (â€œread outâ€) information
from or inject/restore (â€œwrite inâ€) signals to neural circuits
[4], there are emerging needs for modeling and analyzing
neural spike trains recorded directly or extracted indirectly
from neural signals, as well as building closed-loop brain-
machine interfaces (BMIs). Many good examples and appli-
cations can be found in the volumes of the current or other
special issues [5, 6].
In recent years, cutting-edge Bayesian methods have
gained increasing attention in the analysis of neural data and
neural spike trains. Despite its well-established theoretic
principle since the inception of Bayesâ€™ rule [7], Bayesian ma-
chinery has not been widely used in large-scaled data analysis
until very recently. This was partially ascribed to two facts:
first, the development of new methodologies and effective
algorithms; second, the ever-increasing computing power.
The major theoretic or methodological development has been
reported in the field of statistics, and numerous algorithms
were developed in applied statistics and machine learning for
successful real-world applications [8]. It is time to push this
research frontier to neural data analysis. With this purpose
in mind, this paper provides a tutorial review on the basic
theory and the state-of-the-art Bayesian methods for neural
spike train analysis.
The rest of the paper is organized as follows. Section 2
presents the background information about statistical infer-
ence and estimation, Bayesâ€™ theory, and statistical characteri-
zation of neural spike trains. Section 3 reviews several impor-
tant Bayesian modeling and inference methods in light of
different approximation techniques. Section 4 reviews a few
representative applications of Bayesian methods for neural
spike train analysis. Finally, Section 5 concludes the paper
with discussions on a few challenging research topics in
neural spike train analysis.

2
Computational Intelligence and Neuroscience
2. Background
2.1. Estimation and Inference: Statistic versus Dynamic.
Throughout this paper, we denote by ğ‘Œthe observed vari-
ables, by ğ‘‹the hidden variables and by ğœƒan unknown param-
eter vector, and by âŠ¤the transpose operator for vector or
matrix. We assume that ğ‘(ğ‘Œ| ğ‘‹, ğœƒ) has a regular and well-
defined form of the likelihood function. For neural spike
train analysis, ğ‘Œtypically consists of time series of single or
multiple spike trains. Given a fixed time interval (0, ğ‘‡], by
time discretization we have ğ‘Œ= {ğ‘Œ1, ğ‘Œ2, . . . , ğ‘Œğ¾} (where ğ¾=
ğ‘‡/Î” and Î” denotes the temporal bin size). A general statistical
inference problem is stated as follows: given observations ğ‘Œ,
estimate the unknown hidden variable ğ‘‹with a known ğœƒ, or
estimate ğœƒalone, or jointly estimate ğœƒand ğ‘‹. The unknown
variables ğœƒand ğ‘‹can be either static or dynamic (e.g., time-
varying with a Markovian structure). We will review the
approaches that tackle these scenarios in this paper.
There are two fundamental approaches to solve the infer-
ence problem: likelihood approach and Bayesian approach.
The likelihood approach [9] computes a point estimate
by maximizing the likelihood function and represents the
uncertainty of estimate via confidence intervals. The maxi-
mum likelihood estimate (m.l.e.) is asymptotically consistent,
normal, and efficient, and it is invariant to reparameterization
(i.e., functional invariance). However, the m.l.e. is known
to suffer from overfitting, and therefore model selection is
required in statistical data analysis. In contrast, the Bayesian
philosophy lets data speak for themselves and models the
unknowns (parameters, latent variables, and missing data)
and uncertainties (which are not necessarily random) with
probabilities or probability densities. The Bayesian approach
computes the full posterior of the unknowns based on the
rules of probability theory; the Bayesian approach can resolve
the overfitting problem in a principled way [7, 8].
2.2. Bayesian Inference. The foundation of Bayesian inference
is given by Bayesâ€™ rule, which consists of two rules: product
rule and sum rule. Bayesâ€™ rule provides a way to compute
the conditional, joint, and marginal probabilities. Specifically,
let ğ‘‹and ğ‘Œbe two continuous random variables (r.v.); the
conditional probability ğ‘(ğ‘‹| ğ‘Œ) is given by
ğ‘(ğ‘‹| ğ‘Œ) = ğ‘(ğ‘‹, ğ‘Œ)
ğ‘(ğ‘Œ)
=
ğ‘(ğ‘Œ| ğ‘‹) ğ‘(ğ‘‹)
âˆ«ğ‘(ğ‘Œ| ğ‘‹) ğ‘(ğ‘‹) ğ‘‘ğ‘‹
.
(1)
If ğ‘‹= {ğ‘‹ğ‘–} is discrete, then (1) is rewritten as
ğ‘(ğ‘‹ğ‘–| ğ‘Œ) = ğ‘(ğ‘‹ğ‘–, ğ‘Œ)
ğ‘(ğ‘Œ)
=
ğ‘(ğ‘Œ| ğ‘‹ğ‘–) ğ‘(ğ‘‹ğ‘–)
âˆ‘ğ‘—ğ‘(ğ‘Œ| ğ‘‹ğ‘—) ğ‘(ğ‘‹ğ‘—)
.
(2)
In Bayesian language, ğ‘(ğ‘Œ| ğ‘‹), ğ‘(ğ‘‹), and ğ‘(ğ‘‹| ğ‘Œ) are
referred to as the likelihood, prior and posterior, respectively.
The Bayesian machinery consists of three types of basic oper-
ations: normalization, marginalization, and expectation, all
of which involve integration. And the optimization problem
consists in maximizing the posterior ğ‘(ğ‘‹| ğ‘Œ) and find-
ing the maximum a posteriori (MAP) estimate ğ‘‹MAP
=
argğ‘‹max ğ‘(ğ‘‹| ğ‘Œ). Notably, except for very few scenarios
(i.e., Gaussianity), most integrations are computationally
intractable or costly when dealing with high-dimensional
problems. Therefore, for the sake of computational tractabil-
ity, various types of approximations are often assumed at dif-
ferent stages of the inference procedure.
More specifically, for the state and parameter estimation
problem, Bayesian inference aims to infer the joint posterior
of the state and the parameter using Bayesâ€™ rule
ğ‘(ğ‘‹, ğœƒ| ğ‘Œ) â‰ˆğ‘(ğ‘‹| ğ‘Œ) ğ‘(ğœƒ| ğ‘Œ)
= ğ‘(ğ‘Œ| ğ‘‹, ğœƒ) ğ‘(ğ‘‹) ğ‘(ğœƒ)
ğ‘(ğ‘Œ)
=
ğ‘(ğ‘Œ| ğ‘‹, ğœƒ) ğ‘(ğ‘‹) ğ‘(ğœƒ)
âˆ¬ğ‘(ğ‘Œ| ğ‘‹, ğœƒ) ğ‘(ğ‘‹) ğ‘(ğœƒ) ğ‘‘ğ‘‹ğ‘‘ğœƒ
,
(3)
where the first equation assumes a factorial form of the
posterior for the state and the parameter (first-stage approx-
imation) and ğ‘(ğ‘‹) and ğ‘(ğœƒ) denote the prior distributions
for the state and parameter, respectively. The denominator of
(3) is a normalizing constant known as the partition function.
When dealing with a prediction problem for unseen data ğ‘Œâˆ—,
we compute the posterior predictive distribution
ğ‘(ğ‘Œâˆ—| ğ‘Œ) = âˆ¬ğ‘(ğ‘Œâˆ—| ğ‘Œ, ğœƒ, ğ‘‹) ğ‘(ğ‘‹| ğ‘Œ) ğ‘(ğœƒ| ğ‘Œ) ğ‘‘ğ‘‹ğ‘‘ğœƒ
(4)
or its expected mean Ì‚ğ‘Œâˆ—= Eğ‘(ğ‘Œâˆ—|ğ‘Œ)[ğ‘Œâˆ—] = âˆ­ğ‘Œâˆ—ğ‘(ğ‘Œâˆ—| ğ‘Œ,
ğœƒ, ğ‘‹)ğ‘(ğ‘‹| ğ‘Œ)ğ‘(ğœƒ| ğ‘Œ)ğ‘‘ğ‘‹ğ‘‘ğœƒğ‘‘ğ‘Œâˆ—.
Sometimes, instead of maximizing the posterior, Bayesian
inference attempts to maximize the marginal likelihood (also
known as â€œevidenceâ€) ğ‘(ğ‘Œ) as follows:
ğ‘(ğ‘Œ) = âˆ¬ğ‘(ğ‘Œ| ğ‘‹, ğœƒ) ğ‘(ğ‘‹) ğ‘(ğœƒ) ğ‘‘ğ‘‹ğ‘‘ğœƒ.
(5)
The second-stage approximation in approximate Bayesian
inference deals with the integration in computing (3), (4), or
(5), which will be reviewed in Section 3.
Note. Maximum likelihood inference can be viewed as a
special case of Bayesian inference, in which ğœƒis represented
by a Dirac-delta function centered at the point estimate
Ì‚ğœƒm.l.e.; namely, ğ‘(ğœƒ) = ğ›¿(ğœƒâˆ’Ì‚ğœƒm.l.e.). Nevertheless, Bayesian
inference can still be embedded into likelihood inference to
estimate ğ‘(ğ‘‹) given a point estimate of ğœƒ. The ğ‘(ğ‘‹) can
either have an analytic form (with finite natural parameters)
or be represented by Monte Carlo samples; the latter approach
may be viewed as a specific case of Monte Carlo expectation-
maximization (EM) methods.
2.3. Characterization of Neural Spike Trains. Neural spike
trains can be modeled as a simple (temporal) point process
[10]. For a single neural spike train observed in (0, ğ‘‡], we
often discretize it with a small bin size Î” such that each bin
contains no more than one spike. The conditional intensity

Computational Intelligence and Neuroscience
3
Table 1: Probability distributions for modeling neuronal spike count observations.
Distribution
Mean statistic
Variance
Note for observations ğ‘Œ
Binomial (ğ‘)
E[ğ‘Œ] = ğ‘
ğ‘(1 âˆ’ğ‘)
ğ‘Œâˆˆ{0, 1}
Poisson (ğœ†)
E[ğ‘Œ] = ğœ†
ğœ†
ğ‘Œâ‰¥0, ğ‘ŒâˆˆZ+
Negative binomial (ğ‘Ÿ, ğ‘)
E[ğ‘Œ] = ğ‘ğ‘Ÿ/(1 âˆ’ğ‘)
ğ‘ğ‘Ÿ/(1 âˆ’ğ‘)2
ğ‘Œâ‰¥0, ğ‘ŒâˆˆZ+ (overdispersed Poisson)
Skellam (ğœ‡1, ğœ‡2)
E[ğ‘Œ] = ğœ‡1 âˆ’ğœ‡2
ğœ‡1 + ğœ‡2
ğ‘ŒâˆˆZ (difference between two Poissons)
function (CIF), denoted as ğœ†(ğ‘¡| ğ»ğ‘¡), is used to characterize
the spiking probability of a neural point process as follows:
ğœ†(ğ‘¡| ğ»ğ‘¡) = lim
Î” â†’0
Pr {spike in (ğ‘¡, ğ‘¡+ Î”] | ğ»ğ‘¡}
Î”
,
(6)
where ğ»ğ‘¡denotes all history information available up to time
ğ‘¡(that may include spike history, stimulus covariate, etc.).
When ğœ†(ğ‘¡| ğ»ğ‘¡) is history independent, then the stochastic
process is an inhomogeneous Poisson process. For notation
simplicity, we sometimes use ğœ†ğ‘¡to replace ğœ†(ğ‘¡| ğ»ğ‘¡) when no
confusion occurs. When Î” is sufficiently small, the product
ğœ†(ğ‘¡
|
ğ»ğ‘¡)Î” is approximately equal to the probability of
observing a spike within the interval ((ğ‘¡âˆ’1)Î”, ğ‘¡Î”]. Assuming
that the CIF ğœ†ğ‘¡is characterized by a parameter ğœƒand
an observed or latent variable ğ‘‹, then the point process
likelihood function is given as [11â€“13]
ğ‘(ğ‘Œ| ğ‘‹, ğœƒ) = exp {âˆ«
ğ‘‡
0
log ğœ†(ğœ| ğœƒ, ğ‘‹) ğ‘‘ğ‘¦(ğœ)
âˆ’âˆ«
ğ‘‡
0
ğœ†(ğœ| ğœƒ, ğ‘‹) ğ‘‘ğœ} ,
(7)
where ğ‘‘ğ‘¦(ğ‘¡) is an indicator function of the spike presence
within the interval ((ğ‘¡âˆ’1)Î”, ğ‘¡Î”]. In the presence of multiple
spike trains from ğ¶neurons, assuming that multivariate point
process observations are conditionally independent at any
time ğ‘¡given a new parameter ğœƒ, one then has
ğ‘(Y1:ğ¶| ğ‘‹, ğœƒ) =
ğ¶
âˆ
ğ‘=1
ğ‘(ğ‘Œğ‘| ğ‘‹, ğœƒ)
=
ğ¶
âˆ
ğ‘=1
exp {âˆ«
ğ‘‡
0
log ğœ†ğ‘(ğœ| ğœƒ, ğ‘‹) ğ‘‘ğ‘¦ğ‘(ğœ)
âˆ’âˆ«
ğ‘‡
0
ğœ†ğ‘(ğœ| ğœƒ, ğ‘‹) ğ‘‘ğœ} .
(8)
Since neural spike trains are fully characterized by the
CIF, the modeling goal is then turned to model the CIF, which
can have a parametric or nonparametric form. Identifying
the CIF and its associated parameters is essentially a neural
encoding problem (Section 4.2). A convenient modeling
framework is the generalized linear model (GLM) [14, 15],
which can model the binary (0/1) or spike count measure-
ments. Within the exponential family, one can use the logit
link function to model the binomial distribution, which has a
generic form of log(ğ‘ğ‘¡/(1 âˆ’ğ‘ğ‘¡)) = ğœƒâŠ¤ğ‘‹; one can also use the
log link function to model the Poisson distribution, which
has a generic form of log(ğœ†ğ‘¡) = ğœƒâŠ¤ğ‘‹.
In addition, researchers have used the negative binomial
distribution to model spike count observations to capture the
overdispersion phenomenon (where the variance is greater
than the mean statistic). In many cases, for the purpose of
computational tractability, researchers often use a Gaussian
approximation for Poisson spike counts through a variance
stabilization transformation. Table 1 lists a few population
probability distributions for modeling spike count observa-
tions.
Another popular statistical model for characterizing pop-
ulation spike trains is the maximum entropy (MaxEnt) model
with a log-linear form [16, 17]. Given an ensemble of ğ¶
neurons, the ensemble spike activity can be characterized by
the following form:
ğ‘(ğ‘‹) =
1
Z (ğ‘‹) exp (
ğ¶
âˆ‘
ğ‘–=1
ğœƒğ‘âŸ¨ğ‘¥ğ‘âŸ©+
ğ¶
âˆ‘
ğ‘–,ğ‘—
ğœƒğ‘–ğ‘—âŸ¨ğ‘¥ğ‘–ğ‘¥ğ‘—âŸ©)
â‰¡
1
Z (ğ‘‹) exp (
ğ¶+ğ¶2
âˆ‘
ğ‘–=1
ğœƒğ‘–ğ‘“ğ‘–(ğ‘‹)) ,
(9)
where ğ‘¥ğ‘–âˆˆ{âˆ’1, +1}, âŸ¨â‹…âŸ©denotes the sample average, âŸ¨ğ‘¥ğ‘âŸ©
denotes the mean firing rate of the ğ‘th neuron, ğ‘“ğ‘–(ğ‘‹) denotes
a generic function of ğ‘‹(where the couplings ğœƒğ‘–have to
match the measured expectation values âŸ¨ğ‘“ğ‘–(ğ‘‹)âŸ©), and Z(ğ‘‹)
denotes the partition function. The basic MaxEnt model (9)
assumes the stationarity of the data and includes the first- and
second-order moment statistics but no stimulus component,
but these assumptions can be relaxed to further derive an
extended model.
An important issue for characterizing neural spike trains
is model selection and the associated goodness-of-fit assess-
ment. For goodness-of-fit assessment of spike train models,
the reader is referred to [11, 18]. In addition, standard statis-
tical techniques such as cross-validation, leave-one-out, and
the receiver-operating-characteristic (ROC) curve may be
considered. The model selection issue can be resolved by the
likelihood principle based on well-established criteria (such
as the Bayesian information criterion or Akaikeâ€™s information
criterion) [9, 11] or resolved by the Bayesian principle.
Bayesian model selection and variable selection will be
reviewed in Section 3.4.
3. Bayesian Modeling and Inference Methods
The common strategy of Bayesian modeling is to start with
specific prior distributions for the unknowns. The prior

4
Computational Intelligence and Neuroscience
distributions are characterized by some hyperparameters,
which can be directly optimized or modeled by the second-
level hyperpriors. If the prior is conjugate to the likelihood,
then the posterior has the same form as the prior [8]. Hier-
archical Bayesian modeling characterizes the uncertainties of
all unknowns at different levels.
In this section, we will review some, either exact or
approximate, Bayesian inference methods. The approximate
Bayesian inference methods aim to compute or evaluate
the integration by approximation. There are two types of
approaches to accomplish this goal: deterministic approx-
imation and stochastic approximation. The deterministic
approximation can rely on Gaussian approximation, deter-
ministic sampling (e.g., sigma-point approximation [19, 20])
or variational approximation [21â€“23]. The stochastic approx-
imation uses Monte Carlo sampling to achieve a point mass
representation of the probability distribution. These two
approaches have been employed to approximate the likeli-
hood or posterior function in many inference problems, such
as model selection, filtering and smoothing, and state and
parameter joint estimation. Detailed coverage of these topics
can be found in many excellent books (e.g., [24â€“28]).
3.1. Variational Bayes (VB). VB is based on the idea of vari-
ational approximation [21â€“23] and is also referred to as
ensemble learning [24]. To avoid overfitting in maximum
likelihood estimation, VB aims to maximize the marginal log-
likelihood or its lower bound as follows:
log ğ‘(ğ‘Œ) = log âˆ«ğ‘‘ğœƒâˆ«ğ‘‘ğ‘‹ğ‘(ğœƒ) ğ‘(ğ‘‹, ğ‘Œ| ğœƒ)
= log âˆ«ğ‘‘ğœƒâˆ«ğ‘‘ğ‘‹ğ‘(ğ‘‹, ğœƒ) ğ‘(ğœƒ) ğ‘(ğ‘‹, ğ‘Œ| ğœƒ)
ğ‘(ğ‘‹, ğœƒ)
â‰¥âˆ«ğ‘‘ğœƒâˆ«ğ‘‘ğ‘‹ğ‘(ğ‘‹, ğœƒ) log ğ‘(ğœƒ) ğ‘(ğ‘‹, ğ‘Œ| ğœƒ)
ğ‘(ğ‘‹, ğœƒ)
= âŸ¨log ğ‘(ğ‘‹, ğ‘Œ, ğœƒ)âŸ©ğ‘+ Hğ‘(ğ‘‹, ğœƒ) â‰¡F (ğ‘(ğ‘‹, ğœƒ)) ,
(10)
where ğ‘(ğœƒ) denotes the parameter prior distribution, ğ‘(ğ‘‹, ğ‘Œ|
ğœƒ) defines the complete data likelihood, and ğ‘(ğ‘‹, ğœƒ) is called
the variational posterior distribution which approximates the
joint posterior of the unknown state and parameter ğ‘(ğ‘‹, ğœƒ|
ğ‘Œ). The term Hğ‘represents the entropy of the variational
posterior distribution ğ‘, and F(ğ‘(ğ‘‹, ğœƒ)) is referred to as the
free energy. The lower bound is derived based on the Jensenâ€™s
inequality [29]. Maximizing the free energy F(ğ‘(ğ‘‹, ğœƒ)) is
equivalent to minimizing the Kullback-Leibler (KL) diver-
gence [29] between the variational posterior and true pos-
terior (denoted by KL(ğ‘â€– ğ‘)); since the KL divergence is
nonnegative, we have F(ğ‘) = log ğ‘(ğ‘Œ) âˆ’KL(ğ‘â€– ğ‘) â‰¤
log ğ‘(ğ‘Œ). The optimization problem in (10) can be resorted to
the VB-EM algorithm [23] in a similar fashion as the standard
EM algorithm [30].
A common (but not necessary) VB assumption is a facto-
rial form of the posterior ğ‘(ğ‘‹, ğœƒ) = ğ‘(ğ‘‹)ğ‘(ğœƒ), although one
can further impose certain structure within the parameter
space. In the case of mean-field approximation, we have
ğ‘(ğ‘‹, ğœƒ) = ğ‘(ğ‘‹)âˆğ‘–ğ‘(ğœƒğ‘–). With selected priors ğ‘(ğ‘‹) and ğ‘(ğœƒ),
one can maximize the free energy by alternatively solving two
equations: ğœ•F/ğœ•ğ‘‹= 0 and ğœ•F/ğœ•ğœƒ= 0. Specifically, VB-
EM inference can be viewed as a natural extension of the EM
algorithm, which consists of the following two steps.
(i) VB-E step: given the available information of ğ‘(ğœƒ),
maximize the free energy F with respect to the func-
tion ğ‘(ğ‘‹) and update the posterior ğ‘(ğ‘‹).
(ii) VB-M step: given the available information of ğ‘(ğ‘‹),
maximize the free energy F with respect to the func-
tion ğ‘(ğœƒ) and update the posterior ğ‘(ğœƒ). The posterior
update will have an analytic form provided that the
prior ğ‘(ğœƒ) is conjugate to the complete-data likeli-
hood function (the conjugate-exponential family).
These two steps are alternated repeatedly until the VB
algorithm reaches the convergence (say, the incremental
change of F value is below a small threshold). Similar to the
iterative EM algorithm, the VB-EM inference has local max-
ima in optimization. To resolve this issue, one may use multi-
ple random initializations or employ a deterministic anneal-
ing procedure [31]. The EM algorithm can be viewed as a
variant of the VB algorithm in that the VB-M step replaces the
point estimate (i.e., ğ‘(ğœƒ) = ğ›¿(ğœƒâˆ’ğœƒMAP)) from the traditional
M-step with a full posterior estimate. Another counterpart of
the VB-EM is the maximization-expectation (ME) algorithm
[32], in which the VB-E step uses the MAP point estimate
ğ‘(ğ‘‹) = ğ›¿(ğ‘‹âˆ’ğ‘‹MAP), while the VB-M step updates the full
posterior.
It is noted that when the latent variables and parameters
are intrinsically coupled or statistically correlated, the mean-
field approximation will not be accurate, and consequently
the VB estimate will be strongly biased. To alleviate this
problem, the latent-space VB (LSVB) method [33, 34] aims
to maximize a tighter lower bound of the marginal log-
likelihood from (10) as follows:
log ğ‘(ğ‘Œ) â‰¥âˆ«ğ‘‘ğ‘‹ğ‘(ğ‘‹) log ğ‘(ğ‘‹, ğ‘Œ)
ğ‘(ğ‘‹)
= âˆ«ğ‘‘ğ‘‹ğ‘(ğ‘‹) log
âˆ«ğ‘‘ğœƒğ‘(ğ‘‹, ğ‘Œ, ğœƒ) ğ‘(ğœƒ)
ğ‘(ğ‘‹)
â‰¡F (ğ‘(ğ‘‹)) â‰¥max
ğ‘(ğœƒ) F (ğ‘(ğ‘‹) ğ‘(ğœƒ)) .
(11)
The reader is referred to [33, 34] for more details and algo-
rithmic implementation.
Note. (i) Depending on specific problems, the optimization
bound of VB methods may not be tight, which may cause
a large estimate bias or underestimated variance [35]. Desir-
ably, a data-dependent lower bound is often tighter (such as
the one used in Bayesian logistic regression [25]). (ii) It was
shown in [36] that the VB method for statistical models
with latent variables can be viewed as a special case of local
variational approximation, where the log-sum-exp function
is used to form the lower bound of the log-likelihood. (iii)
The VB-EM inference was originally developed for the proba-
bilistic models in the conjugate-exponential family, but it can

Computational Intelligence and Neuroscience
5
be extended to more general models based on approximation
[37].
3.2. Expectation Propagation (EP). EP is a message-passing
algorithm that allows approximate Bayesian inference for
factor graphs (one type of probabilistic graphical model that
shows how a function of several variables can be factored into
a product of simple functions and can be used to represent
a posterior distribution) [38]. For a specific r.v. ğ‘‹(either
continuous or discrete), the probability distribution ğ‘(ğ‘‹) is
represented as a product of factors as follows:
ğ‘(ğ‘‹) = âˆ
ğ‘
ğ‘“ğ‘(ğ‘‹) .
(12)
The basic idea of EP is to â€œdivide-and-conquerâ€ by approxi-
mating the factors one by one as follows:
ğ‘“ğ‘(ğ‘‹) ó³¨€â†’Ìƒğ‘“ğ‘(ğ‘‹)
(13)
and then use the product of approximated term as the final
approximation as follows:
ğ‘(ğ‘‹) = âˆ
ğ‘
Ìƒğ‘“ğ‘(ğ‘‹) .
(14)
As a result, EP replaces the global divergence KL(ğ‘(ğ‘‹) â€–
ğ‘(ğ‘‹)) by the local divergence between two product chains as
follows:
KL (ğ‘(ğ‘‹) â€– ğ‘(ğ‘‹))
= KL (ğ‘“ğ‘(ğ‘‹) âˆ
ğ‘Ì¸= ğ‘
ğ‘“ğ‘(ğ‘‹) â€– Ìƒğ‘“ğ‘(ğ‘‹) âˆ
ğ‘Ì¸= ğ‘
Ìƒğ‘“ğ‘(ğ‘‹))
â‰ˆKL (ğ‘“ğ‘(ğ‘‹) âˆ
ğ‘Ì¸= ğ‘
Ìƒğ‘“ğ‘(ğ‘‹) â€– Ìƒğ‘“ğ‘(ğ‘‹) âˆ
ğ‘Ì¸= ğ‘
Ìƒğ‘“ğ‘(ğ‘‹)) .
(15)
To minimize (15), the EP inference procedure is planned
as follows.
Step
1. Use message-passing algorithms to pass messages
Ìƒğ‘“ğ‘(ğ‘‹) between factors.
Step 2. Given the received message Ìƒğ‘“ğ‘(ğ‘‹) for factor ğ‘(for
all ğ‘Ì¸= ğ‘), minimize the local divergence to obtain Ìƒğ‘“ğ‘(ğ‘‹), and
send it to other factors.
Step 3. Repeat the procedure until convergence.
Note. (i) EP aims to find the closest approximation ğ‘such
that KL(ğ‘â€– ğ‘) is minimized, whereas VB aims to find the
variational distribution to minimize KL(ğ‘â€– ğ‘) (note that the
KL divergence is asymmetric, and KL(ğ‘â€– ğ‘) and KL(ğ‘â€– ğ‘)
have different geometric interpretations [39]). (ii) Unlike the
global approximation technique (e.g., moment matching), EP
uses a local approximation strategy to minimize a series of
local divergence.
3.3. Markov Chain Monte Carlo (MCMC). MCMC methods
are referred to as a class of algorithms for drawing random
samples from probability distributions by constructing a
Markov chain that has the equilibrium distribution as the
desired distribution [40]. The designed Markov chain is
reversible and has detailed balance. For example, given a tran-
sition probability ğ‘ƒ, the detailed balance holds between each
pair of state ğ‘–and ğ‘—in the state space if and only if ğœ‹ğ‘–ğ‘ƒğ‘–ğ‘—= ğœ‹ğ‘—ğ‘ƒğ‘—ğ‘–
(where ğœ‹ğ‘–= Pr(ğ‘‹ğ‘¡âˆ’1 = ğ‘–) and ğ‘ƒğ‘–ğ‘—= Pr(ğ‘‹ğ‘¡âˆ’1 = ğ‘–, ğ‘‹ğ‘¡= ğ‘—)). The
appealing use of MCMC methods for Bayesian inference is
to numerically calculate high-dimensional integrals based on
the samples drawn from the equilibrium distribution [41].
The most common MCMC methods are the random walk
algorithms, such as the Metropolis-Hastings (MH) algorithm
[42, 43] and Gibbs sampling [44]. The MH algorithm is the
simplest yet the most generic MCMC method to generate
samples using a random walk and then to accept them with a
certain acceptance probability. For example, given a random-
walk proposal distribution ğ‘”(ğ‘
â†’
ğ‘ó¸€ ) (which defines a
conditional probability of moving state ğ‘to ğ‘ó¸€ ), the MH
acceptance probability A(ğ‘â†’ğ‘ó¸€ ) is
A (ğ‘ó³¨€â†’ğ‘ó¸€ ) = min (1,
ğ‘(ğ‘ó¸€ ) ğ‘”(ğ‘ó¸€ ó³¨€â†’ğ‘)
ğ‘(ğ‘) ğ‘”(ğ‘ó³¨€â†’ğ‘ó¸€ ) ) ,
(16)
which gives a simple MCMC implementation. Gibbs sam-
pling is another popular MCMC method that requires no
parameter tuning. Given a high-dimensional joint distribu-
tion ğ‘(ğ‘) = ğ‘(ğ‘§1, . . . , ğ‘§ğ‘›), Gibbs sampler draws samples
from the individual conditional distribution ğ‘(ğ‘§ğ‘–| ğ‘âˆ’ğ‘–) in
turn while holding others fixed (where ğ‘âˆ’ğ‘–denote the ğ‘›âˆ’1
variables in ğ‘except for ğ‘§ğ‘–).
For high-dimensional sampling problems, the random-
walk behavior of the proposal distribution may not be effi-
cient. Imagine that there are two directions (increase or
decrease in the likelihood space) for a one-dimensional
search; there will be 2ğ‘›search directions in an ğ‘›-dimensional
space. On average, it will take about 2ğ‘›/ğ‘›steps to hit the exact
search direction. Notably, some sophisticated MCMC algo-
rithms employ side information to improve the efficiency of
the sampler (i.e., the â€œmixingâ€ of the Markov chain). Exam-
ples of non-random-walk methods include successive over-
relaxation, hybrid Monte Carlo, gradient-based Langevin
MCMC, and Hessian-based MCMC [24, 45â€“47].
Many statistical estimation problems (e.g., change point
detection, clustering, and segmentation) consist in identify-
ing the unknown number of statistical objects (e.g., change
points, clusters, and boundaries), which are categorized as
the variable-dimensional statistical inference problem. For
this kind of inference problem, the so-called reversible jump
MCMC (RJ-MCMC) method has been developed [48], which
can be viewed as a variant of MH algorithm that allows
proposals to change the dimensionality of the space while
satisfying the detailed balance of the Markov chain.
Note. As discussed in Section 2.2, since the fundamental
operations of Bayesian statistics involve integration, the
MCMC methods appear naturally as the most generic tech-
niques for Bayesian inference. On the one hand, the recent

6
Computational Intelligence and Neuroscience
decades have witnessed an exponential growth in the MCMC
literature for its own theoretic and algorithmic developments.
On the other hand, there has been also an increasing trend
in applying MCMC methods to neural data analysis, ranging
from spike sorting, tuning curve estimation, and neural
decoding to functional connectivity analysis, some of which
will be briefly reviewed in Section 4.
3.4. Bayesian Model Selection and Variable Selection. Statisti-
cal model comparison can be carried on by Bayesian infer-
ence. From Bayesâ€™ rule, the model posterior probability is
expressed by
ğ‘(Mğ‘–| ğ·) âˆğ‘(ğ·| Mğ‘–) ğ‘(Mğ‘–) .
(17)
Under the assumption of equal model priors, maximizing
the model posterior is equivalent to maximizing the model
evidence (or marginal likelihood) as follows:
ğ‘(ğ·| Mğ‘–) = âˆ«
ğœƒ
ğ‘(ğ·, ğœƒ| Mğ‘–) ğ‘‘ğœƒ
= âˆ«
ğœƒ
ğ‘(ğ·| ğœƒ, Mğ‘–) ğ‘(ğœƒ| Mğ‘–) ğ‘‘ğœƒ.
(18)
The Bayes factor (BF), defined as the ratio of evidence
between two models, can be computed as [49]
BF = ğ‘(ğ·| M1)
ğ‘(ğ·| M2) =
âˆ«ğ‘(ğ·, ğœƒ1 | M1) ğ‘‘ğœƒ1
âˆ«ğ‘(ğ·, ğœƒ2 | M2) ğ‘‘ğœƒ2
=
âˆ«ğ‘(ğœƒ1 | M1) ğ‘(ğ·| ğœƒ1, M1) ğ‘‘ğœƒ1
âˆ«ğ‘(ğœƒ2 | M2) ğ‘(ğ·| ğœƒ2, M2) ğ‘‘ğœƒ2
.
(19)
Specifically, the BF is treated as the Bayesian alternative to
ğ‘ƒvalues for testing hypotheses (in model selection) and for
quantifying the degree the observed data support or conflict
with a hypothesis [50]. As discussed previously in Section 3.1,
the marginal likelihood may be intractable for a large class of
probabilistic models. In practice, the BF is often computed
based on numerical approximation, such as the Laplace-
Metropolis Estimator [51] or sequential Monte Carlo meth-
ods [52]. In addition, for a large sample size, the logarithm of
the BF can be roughly approximated by the Bayesian informa-
tion criterion (BIC) [9], whose computation is much simpler
without involving numerical integration.
Bayesian model selection can also be directly imple-
mented via the so-called MCMC model composition (MC3).
The basic idea of MC3 is to simulate a Markov chain {M(ğ‘¡)}
with an equilibrium distribution as ğ‘(Mğ‘–| ğ·). For each
model M, define a neighborhood nbd(M) and a transition
matrix ğ‘by setting ğ‘(M â†’Mó¸€ ) = 0 for all Mó¸€ âˆ‰nbd(M).
Draw a new sample Mó¸€ from ğ‘(M â†’Mó¸€ ) and accept the
new sample with a probability
min {1,
ğ‘(Mó¸€ | ğ·)
ğ‘(M | ğ·) } .
(20)
Otherwise the chain remains unchanged. Once the Markov
chain converges to the equilibrium, one can construct the
model posterior based on Monte Carlo samples.
Within a fixed model class, it is often desirable to have
a compact or sparse representation of the model to alleviate
overfitting. Namely, many coefficients of the model parame-
ters are zeros. A very useful approach for variable selection
is the so-called automatic relevance determination (ARD)
that encourages sparse Bayesian learning [24, 26, 53]. More
specifically, ARD provides a way to infer hyperparameters in
hierarchical Bayesian modeling. Given the likelihood ğ‘(ğ‘Œ|
ğœƒ) and the parameter prior ğ‘(ğœƒ| ğœ”) (where ğœ”denotes the
hyperparameters), one can assign a hyperprior ğ‘(ğœ”| ğœ‚) for ğœ”
such that the marginal distribution ğ‘(ğœƒ) = âˆ«ğ‘(ğœƒ| ğœ”)ğ‘(ğœ”)ğ‘‘ğœ”
is peaked and long-tailed (thereby favoring a sparse solution).
The hyperprior ğ‘(ğœ”) can be either identical or different for
each element in ğœƒ. In the most general form, we can write
ğ‘(ğœƒ) = âˆ
ğ‘–
ğ‘(ğœƒğ‘–) = âˆ
ğ‘–
âˆ«ğ‘(ğœƒğ‘–| ğœ”ğ‘–) ğ‘(ğœ”ğ‘–| ğœ‚ğ‘–) ğ‘‘ğœ”ğ‘–.
(21)
The hyperprior parameters ğœ‚= {ğœ‚ğ‘–} can be fixed or optimized
from data. Upon completing Bayesian inference, the esti-
mated mean and variance statistics of some coefficients ğœƒğ‘–will
be close to zero (i.e., with the least relevance) and therefore
can be truncated. The ARD principle has been widely used
in various statistical models, such as linear regression, GLM,
and the relevance vector machine (RVM) [26].
3.5. Bayesian Model Averaging (BMA). BMA is a statistical
technique aiming to account for the uncertainty in the model
selection process [54]. By averaging many different com-
peting statistical models (e.g., linear or Cox regression and
GLM), BMA incorporates model uncertainties into parame-
ter inference and data prediction.
Consider an example of GLM involving choosing inde-
pendent variables and the link function. Every possible
combination of choices defines a different model, say
{M0, M1, . . . , Mğ¾} (where M0 denotes the null model).
Upon computing ğ¾Bayes factors BF10 = ğ‘(ğ·| M1)/ğ‘(ğ·|
M0), BF20 = ğ‘(ğ·| M2)/ğ‘(ğ·| M0), . . ., and BFğ¾0 = ğ‘(ğ·|
Mğ¾)/ğ‘(ğ·| M0), the posterior probability ğ‘(Mğ‘˜| ğ·) is
computed as [54]
ğ‘(Mğ‘˜| ğ·) =
ğœ‹ğ‘˜BFğ‘˜0
âˆ‘ğ¾
ğ‘–=0 ğœ‹ğ‘–BFğ‘–0
,
(22)
where ğœ‹ğ‘˜= ğ‘(Mğ‘˜)/ğ‘(M0) denotes the prior odds for model
Mğ‘˜against M0. In the case of GLM, the marginal likelihood
can be approximated by the Laplace method [55].
3.6. Bayesian Filtering: Kalman Filter, Point Process Filter, and
Particle Filter. Bayesian filtering aims to infer a filtered or
predictive posterior distribution of temporal data in a
sequential fashion, which is often cast within the framework
of state space model (SSM) [13, 56, 57]. Without loss of
generality, let xğ‘¡denote the state at discrete time ğ‘¡and let y0:ğ‘¡
denote the cumulative observations up to time ğ‘¡. The filtered

Computational Intelligence and Neuroscience
7
posterior distribution of the state, conditional on the obser-
vations y0:ğ‘¡, bears a form of recursive Bayesian estimation as
follows:
ğ‘(xğ‘¡| y0:ğ‘¡) = ğ‘(xğ‘¡) ğ‘(y0:ğ‘¡| xğ‘¡)
ğ‘(y0:ğ‘¡)
= ğ‘(xğ‘¡) ğ‘(yğ‘¡, y0:ğ‘¡âˆ’1 | xğ‘¡)
ğ‘(yğ‘¡, y0:ğ‘¡âˆ’1)
= ğ‘(xğ‘¡) ğ‘(yğ‘¡| xğ‘¡, y0:ğ‘¡âˆ’1) ğ‘(y0:ğ‘¡âˆ’1 | xğ‘¡)
ğ‘(yğ‘¡| y0:ğ‘¡âˆ’1) ğ‘(y0:ğ‘¡âˆ’1)
= ğ‘(xğ‘¡) ğ‘(yğ‘¡| xğ‘¡, y0:ğ‘¡âˆ’1) ğ‘(xğ‘¡| y0:ğ‘¡âˆ’1) ğ‘(y0:ğ‘¡âˆ’1)
ğ‘(yğ‘¡| y0:ğ‘¡âˆ’1) ğ‘(y0:ğ‘¡âˆ’1) ğ‘(xğ‘¡)
= ğ‘(yğ‘¡| xğ‘¡, y0:ğ‘¡âˆ’1) ğ‘(xğ‘¡| y0:ğ‘¡âˆ’1)
ğ‘(yğ‘¡| y0:ğ‘¡âˆ’1)
= ğ‘(yğ‘¡| xğ‘¡) ğ‘(xğ‘¡| y0:ğ‘¡âˆ’1)
ğ‘(yğ‘¡| y0:ğ‘¡âˆ’1)
,
(23)
where the first four steps are derived from Bayesâ€™ rule and the
last equality of (23) assumes the conditional independence
between the observations. The one-step state prediction, also
known as the Chapman-Kolmogorov equation [58], is given by
ğ‘(xğ‘¡| y0:ğ‘¡âˆ’1) = âˆ«ğ‘(xğ‘¡| xğ‘¡âˆ’1) ğ‘(xğ‘¡âˆ’1 | y0:ğ‘¡âˆ’1) ğ‘‘xğ‘¡âˆ’1,
(24)
where the probability distribution (or density) ğ‘(xğ‘¡| xğ‘¡âˆ’1)
describes a state transition equation and the probability dis-
tribution (or density) ğ‘(yğ‘¡| xğ‘¡) is the observation equation.
Together (23) and (24) provide the fundamental relations
to conduct state space analyses. The above formulation of
recursive Bayesian estimation holds for both continuous and
discrete variables, for either x or y or both. When the state
variable is discrete and countable (in which we use ğ‘†ğ‘¡to
replace xğ‘¡), the SSM is also referred to as a hidden Markov
model (HMM), with associated ğ‘(ğ‘†ğ‘¡| ğ‘†ğ‘¡âˆ’1) and ğ‘(yğ‘¡| ğ‘†ğ‘¡).
Various approximate Bayesian methods for the HMM have
been reported [23, 59, 60]. When the hidden state consists of
both continuous and discrete variables, the SSM is referred
to as a switching SSM, with associated ğ‘(xğ‘¡| xğ‘¡âˆ’1, ğ‘†ğ‘¡) and
ğ‘(yğ‘¡| xğ‘¡, ğ‘†ğ‘¡) [27, 61]. In this case, the inference and prediction
involve multiple integrals or summations. For example, the
prediction equation (24) will be rewritten as
ğ‘(xğ‘¡| y0:ğ‘¡âˆ’1, ğ‘†0:ğ‘¡âˆ’1) = âˆ«âˆ‘
ğ‘†ğ‘¡âˆ’1
ğ‘(xğ‘¡| xğ‘¡âˆ’1, ğ‘†ğ‘¡) ğ‘(ğ‘†ğ‘¡| ğ‘†ğ‘¡âˆ’1)
Ã— ğ‘(xğ‘¡âˆ’1 | y0:ğ‘¡âˆ’1, ğ‘†0:ğ‘¡âˆ’1) ğ‘‘xğ‘¡âˆ’1
(25)
whose exact or naive implementation can be computationally
prohibitive given a large discrete state space.
When the state and observation equations are both con-
tinuous and Gaussian, the Bayesian filtering solution yields
the celebrated Kalman filter [62], in which the posterior mean
and posterior variance are updated recursively. In fact, based
on a Gaussian approximation of nonnegative spike count
observations, the Kalman filter has been long used in spike
train analysis [63, 64]. However, such a naive Gaussian
approximation does not consider the point process nature of
neural spike trains. Brown and his colleagues [65â€“67] have
proposed a point process filter to recursively estimate the state
or parameter in a dynamic fashion. Without loss of generality,
assume that the CIF (6) is characterized by a parameter ğœƒvia
an exponential form, namely, ğœ†ğ‘¡â‰¡ğœ†(ğ‘¡| ğœƒğ‘¡) = exp(ğœƒâŠ¤
ğ‘¡ğ‘‹ğ‘¡), and
assume that the parameter follows a random-walk equation
ğœƒğ‘¡= ğœƒğ‘¡âˆ’1 +ğ‘¤ğ‘¡(where ğ‘¤ğ‘¡denotes random Gaussian noise with
zero mean and variance ğœ2); then one can use a point process
filter to estimate the time-varying parameter ğœƒat arbitrarily
fine temporal resolution (i.e., the bin size can be as small as
possible for the discrete-time index ğ‘¡) as follows:
ğœƒğ‘¡+1|ğ‘¡= ğœƒğ‘¡|ğ‘¡(one-step mean prediction) ,
(26)
ğ‘‰ğ‘¡+1|ğ‘¡(ğœƒ) = ğ‘‰ğ‘¡+1|ğ‘¡(ğœƒ) + ğœ2 (one-step variance prediction) ,
(27)
ğœƒğ‘¡+1|ğ‘¡+1 = ğœƒğ‘¡+1|ğ‘¡+ ğ‘‰ğ‘¡+1|ğ‘¡(ğœƒ) âˆ‡ğœƒğœ†(ğœƒğ‘¡+1|ğ‘¡)
ğœ†(ğœƒğ‘¡+1|ğ‘¡)
Ã— [ğ‘‘ğ‘¦ğ‘¡+1 âˆ’ğœ†(ğœƒğ‘¡+1|ğ‘¡+1) Î”]
= ğœƒğ‘¡+1|ğ‘¡+ ğ‘‰ğ‘¡+1|ğ‘¡(ğœƒ) ğ‘‹ğ‘¡+1
Ã— [ğ‘‘ğ‘¦ğ‘¡+1 âˆ’ğœ†(ğœƒğ‘¡+1|ğ‘¡+1) Î”] (posterior mode) ,
(28)
ğ‘‰ğ‘¡+1|ğ‘¡+1 (ğœƒ) = [(ğ‘‰ğ‘¡+1|ğ‘¡(ğœƒ))âˆ’1 + ğ‘‹ğ‘¡+1ğ‘‹âŠ¤
ğ‘¡+1ğœ†(ğœƒğ‘¡+1|ğ‘¡) Î”]
âˆ’1
(posterior variance) ,
(29)
where ğœƒğ‘¡+1|ğ‘¡+1 and ğ‘‰ğ‘¡+1|ğ‘¡+1(ğœƒ) denote the posterior mode
and posterior variance for the parameter ğœƒ, respectively.
Equations (26)â€“(29) are reminiscent of Kalman filtering.
Equations (26) and (27) for one-step mean and variance
predictions are the same as Kalman filtering, but (28) and
(29) are different from Kalman filtering due to the presence of
non-Gaussian observations and nonlinear operation in (28).
In (28), [ğ‘‘ğ‘¦ğ‘¡+1 âˆ’ğœ†(ğœƒğ‘¡+1|ğ‘¡+1)Î”] is viewed as the innovations
term, and ğ‘‰ğ‘¡+1|ğ‘¡ğ‘‹ğ‘¡+1 may be interpreted as a â€œKalman gain.â€
The quantity of the Kalman gain determines the â€œstep sizeâ€
in error correction. In (29), the posterior state variance is
derived by inverting the second derivative of the log-posterior
probability density log ğ‘(ğœƒğ‘¡| ğ‘Œ) based on a Gaussian approx-
imation of the posterior distribution around the posterior
mode [65â€“67]. For this simple example, we have
log ğ‘(ğœƒğ‘¡| ğ‘Œ0:ğ‘¡, ğ»ğ‘¡)
âˆâˆ’1
2(ğœƒğ‘¡âˆ’ğœƒğ‘¡âˆ’1|ğ‘¡âˆ’1)
âŠ¤ğ‘‰âˆ’1
ğ‘¡+1|ğ‘¡(ğœƒğ‘¡âˆ’ğœƒğ‘¡âˆ’1|ğ‘¡âˆ’1)
+ [log ğœ†ğ‘¡ğ‘‘ğ‘¦ğ‘¡âˆ’ğœ†ğ‘¡Î”] ,

8
Computational Intelligence and Neuroscience
ğœ•log ğ‘(ğœƒğ‘¡| ğ‘Œ0:ğ‘¡, ğ»ğ‘¡)
ğœ•ğœƒğ‘¡
= âˆ’(ğœƒğ‘¡âˆ’ğœƒğ‘¡âˆ’1|ğ‘¡âˆ’1)
âŠ¤ğ‘‰âˆ’1
ğ‘¡+1|ğ‘¡
+ 1
ğœ†ğ‘¡
âˆ‡ğœƒğœ†ğ‘¡[ğ‘‘ğ‘¦ğ‘¡âˆ’ğœ†ğ‘¡Î”] ,
ğœ•2 log ğ‘(ğœƒğ‘¡| ğ‘Œ0:ğ‘¡, ğ»ğ‘¡)
ğœ•ğœƒğ‘¡ğœ•ğœƒâŠ¤
ğ‘¡
= âˆ’ğ‘‰âˆ’1
ğ‘¡+1|ğ‘¡+ [ ( ğœ•2ğœ†ğ‘¡
ğœ•ğœƒğ‘¡ğœ•ğœƒâŠ¤
ğ‘¡
1
ğœ†ğ‘¡
âˆ’(ğœ•ğœ†ğ‘¡
ğœ•ğœƒğ‘¡
)
2 1
ğœ†2
ğ‘¡
)
Ã— [ğ‘‘ğ‘¦ğ‘¡âˆ’ğœ†ğ‘¡Î”] âˆ’(ğœ•ğœ†ğ‘¡
ğœ•ğœƒğ‘¡
)
2 1
ğœ†ğ‘¡
Î”] .
(30)
Setting the first-order derivative ğœ•log ğ‘(ğœƒğ‘¡| ğ‘Œ0:ğ‘¡, ğ»ğ‘¡)/ğœ•ğœƒğ‘¡
to zero and rearranging terms yield (28), and setting
ğ‘‰ğ‘¡+1|ğ‘¡+1(ğœƒ) = âˆ’[ğœ•2 log ğ‘(ğœƒğ‘¡| ğ‘Œ0:ğ‘¡, ğ»ğ‘¡)/(ğœ•ğœƒğ‘¡ğœ•ğœƒâŠ¤
ğ‘¡)]âˆ’1 yields (29).
The Gaussian approximation is based on the first-order
Laplace method. In theory one can also use a second-
order method to further improve the approximation accuracy
[68]. However, in practice the performance gain is relatively
small in the presence of noise and model uncertainty while
analyzing real experimental data sets. Although the above
example only considers a univariate point process (i.e., a
single neuronal spike train), it is straightforward to extend the
analysis to multivariate point processes (multiple neuronal
spike trains). When the number of the neurons increases,
the accuracy of Gaussian approximation of log-posterior also
improves due to the Law of large numbers.
An alternative way for estimating a non-Gaussian poste-
rior is to use a particle filter [69]. Several reports have been
published in the context of neural spike train analysis [70, 71].
The basic idea of particle filtering is to employ sequential
Monte Carlo (importance sampling and resampling) meth-
ods and draw a set of independent and identically distributed
(i.i.d.) samples (i.e., â€œparticlesâ€) from a proposal distribution;
the samples are propagated through the likelihood function,
weighted, and reweighted after each iteration update. In the
end, one can use Monte Carlo samples (or their importance
weights) to represent the posterior. For example, to evaluate
the expectation of a function ğ‘“(xğ‘¡) with respect to the
posterior ğ‘(xğ‘¡| y0:ğ‘¡), we have
E [ğ‘“(xğ‘¡)] = âˆ«ğ‘“(xğ‘¡) ğ‘(xğ‘¡| y0:ğ‘¡)
ğ‘(xğ‘¡| y0:ğ‘¡) ğ‘(xğ‘¡| y0:ğ‘¡) ğ‘‘xğ‘¡
= âˆ«ğ‘“(xğ‘¡) ğ‘Š(xğ‘¡) ğ‘(xğ‘¡| y0:ğ‘¡) ğ‘‘xğ‘¡
â‰ˆ
âˆ‘ğ‘ğ‘
ğ‘–=1 ğ‘“(x(ğ‘–)
ğ‘¡) ğ‘Š(x(ğ‘–)
ğ‘¡)
âˆ‘ğ‘ğ‘
ğ‘–=1 ğ‘Š(x(ğ‘–)
ğ‘¡)
= Ì‚ğ‘“(xğ‘¡) ,
(31)
where ğ‘Š(xğ‘¡) = ğ‘(xğ‘¡| y0:ğ‘¡)/ğ‘(xğ‘¡| y0:ğ‘¡) denotes the impor-
tance weight function and {x(ğ‘–)
ğ‘¡}ğ‘ğ‘
ğ‘–=1 denotes the ğ‘ğ‘particles
drawn from the proposal distribution ğ‘(xğ‘¡| y0:ğ‘¡). When
the sample size ğ‘ğ‘is sufficiently large (depending on the
dimensionality of x), the estimate Ì‚ğ‘“(xğ‘¡) will be an unbiased
estimate of E[ğ‘“(xğ‘¡)]. Based on sequential important sampling
(SIS), the importance weights of each sample can be recur-
sively updated as follows [69]:
ğ‘Š(x(ğ‘–)
ğ‘¡) = ğ‘Š(x(ğ‘–)
ğ‘¡âˆ’1)
ğ‘(yğ‘¡| x(ğ‘–)
ğ‘¡) ğ‘(x(ğ‘–)
ğ‘¡| x(ğ‘–)
ğ‘¡âˆ’1)
ğ‘(x(ğ‘–)
ğ‘¡| x(ğ‘–)
0:ğ‘¡âˆ’1, yğ‘¡)
.
(32)
In practice, choosing a proper proposal distribution ğ‘(xğ‘¡|
x0:ğ‘¡âˆ’1, yğ‘¡) is crucial (see [69] for detailed discussions). In the
neuroscience literature, Brockwell et al. [70] used a transition
prior ğ‘(xğ‘¡| xğ‘¡âˆ’1) as the proposal distribution, which yields a
simple form of update from (32) as follows:
ğ‘Š(x(ğ‘–)
ğ‘¡) = ğ‘Š(x(ğ‘–)
ğ‘¡âˆ’1) ğ‘(yğ‘¡| x(ğ‘–)
ğ‘¡) .
(33)
That is, the importance weights ğ‘Š(x(ğ‘–)
ğ‘¡) are only scaled by
the instantaneous likelihood value. Despite its simplicity,
the transition prior proposal distribution completely ignores
the information of current observation yğ‘¡. To overcome
this limitation, Ergun et al. [71] used a filtered (Gaussian)
posterior density derived from the point process filter as the
proposal distribution, and they reported a significant perfor-
mance gain in estimation while maintaining the algorithmic
simplicity (i.e., sampling from a Gaussian distribution). In
addition, the VB approach can be integrated with particle
filtering to obtain a variational Bayesian filtering algorithm
[72].
Note. (i) If the online operation is not required, we can esti-
mate a smoothed posterior distribution ğ‘(xğ‘¡| y0:ğ‘‡) to obtain
a more accurate estimate. The above Bayesian filters can be
extended to the fixed-lag Kalman smoother, point process
smoother, and particle smoother [63, 66, 69]. (ii) For neural
spike train analysis, the formulation of Bayesian filtering is
applicable not only to simple point processes but also to
marked point processes [73] or even spatiotemporal point
processes.
3.7. Bayesian Nonparametrics. The contrasting methodolog-
ical pairs â€œfrequentist versus Bayesâ€ and â€œparametric versus
nonparametricâ€ are two examples of dichotomy in modern
statistics [74]. The historical roots of Bayesian nonparamet-
rics are dated back to the late 1960s and 1970s. Despite its
theoretic development over the past few decades, successful
applications of nonparametric Bayesian inference have not
been widespread until recently, especially in the field of
machine learning [75]. Since nonparametric Bayesian models
accommodate a large number of degrees of freedom (infinite-
dimensional parameter space) to exhibit a rich class of proba-
bilistic structure, such approaches are very powerful in terms
of data representation. The fundamental building blocks
are two stochastic processes: Dirichlet process (DP) and
Gaussian process (GP). Although detailed technical reviews
of these topics are far beyond the scope of this paper, we
would like to point out the strengths of these methods in two
aspects of statistical data analysis.
(i) Data clustering, partitioning, and segmentation:
unlike the finite mixture models, nonparametric

Computational Intelligence and Neuroscience
9
Bayesian models define a prior distribution over the
set of all possible partitions, in which the number
of clusters or partitions may grow as the increase
of the data samples in both static and dynamic set-
tings, including the infinite Gaussian mixture model,
Dirichlet process mixtures, Chinese restaurant pro-
cess, and infinite HMM [74â€“76]. The model selection
issue is resolved implicitly in the process of infinite
mixture modeling.
(ii) Prediction and smoothing: unlike the fixed finite-
dimensional parametric models, the GP defines pri-
ors for the mean function and covariance function,
where the covariance kernel function determines
the smoothness and stationarity between the data
points. Since the predictive posterior is Gaussian, the
prediction uncertainty can be computed analytically
[28, 77].
Therefore, Bayesian nonparametrics offer greater flexi-
bility for modeling complex data structures. Unfortunately,
most inference algorithms for Bayesian nonparametric mod-
els involve MCMC methods, which can be computationally
prohibitive for large-scale neural data analysis. Therefore,
exploiting the sparsity structure of specific neural data and
designing efficient inference algorithms are two important
directions in practical applications [78].
4. Bayesian Methods for Neural Spike
Train Analysis
In this section, we review some representative applications of
Bayesian methods for neural spike train analysis, with specific
emphases on the real experimental data. Nevertheless, the list
of the references is by no means complete, and some other
complementary references can be found in [79, 80]. Specifi-
cally, the strengths of the Bayesian methods are highlighted
in comparison with other standard methods; the potentially
issues arising from these methods are also discussed.
4.1. Spike Sorting and Tuning Curve Estimation. To charac-
terize the firing property of single neurons, it is necessary to
first identify and sort the spikes from the recorded multiunit
activity (MUA) (which is referred to as the discrete ensemble
spikes passing the threshold criterion) [81â€“83]. However,
spike sorting is often a difficult and error-prone process. Tra-
ditionally, spike sorting is formulated as a clustering problem
based on spike waveform features [84]. Parametric and
nonparametric Bayesian inference methods have been devel-
oped for mixture modeling and inference (e.g., [25, 26]),
especially for determining the model size [85, 86]. Unlike
the maximum likelihood estimation (which produces a hard
label for each identified spike), Bayesian approaches produce
a soft label (posterior probability) for individual spike; such
uncertainties may be considered in subsequent analyses (such
as tuning curve estimation and decoding). Spike sorting can
also be formulated as a dynamic model inference problem, in
the context of state space analysis [87] or in the presence of
nonstationarity [88]. Recent studies have suggested that spike
sorting should take into account not only spike waveform
features but also the neuronal tuning property [89, 90],
suggesting that these two processes shall be integrated.
At the single neuron level, a Poisson neuronal firing
response is completely characterized by its tuning curve or
receptive field (RF). Naturally, estimating the neuronal tuning
curve is the second step following spike sorting. Standard
tuning curve or RF estimation methods include the spike-
triggered average (STA) and spike-triggered covariance
(STC). The Bayesian versions of the STA and STC have been
proposed [91, 92]. Binning and smoothing are two important
issues in firing rate estimation Bayesian methods provide
a principled way to estimate the peristimulus time histogram
(PSTH) [93]. For estimating a time-varying firing rate profile
similar to PSTH, the Bayesian adaptive regression splines
(BARS) method offers a principled solution for bin size selec-
tion and smoothing based on the RJ-MCMC method [94].
Notably, BARS is more computationally intensive. For similar
estimation performance (validated on simulated data), a
more computationally efficient approach has been developed
using Bayesian filtering-based state space analysis [95]. In
addition, Metropolis-type MCMC approaches have been
proposed for high-dimensional tuning curve estimation [96,
97].
4.2. Neural Encoding and Decoding. The goal of neural
encoding is to establish a statistical mapping (which can
be either a biophysical or data-driven model) between the
stimulus input and neuronal responses, and the goal of neural
decoding is to extract or reconstruct information of the
stimulus given the observed neural signals. For instance, the
encoded and decoded variables of interest can be a rodentâ€™s
position during spatial navigation, the monkeyâ€™s movement
kinematics in a reach-to-grasp task, or specific visual/audi-
tory/olfactory stimuli during neuroscience experiments.
Without loss of generality, let {Ìƒğ‘‹, Ìƒğ‘Œ} denote the observed
stimuli and neuronal responses, respectively, at the encoding
stage, and let ğœƒdenote the model parameter of a specific
encoding model M; then the posterior distribution of the
model (and model parameters) is written as
ğ‘(ğœƒ, M | Ìƒğ‘‹, Ìƒğ‘Œ) âˆğ‘(Ìƒğ‘‹, Ìƒğ‘Œ| ğœƒ, M) ğ‘(ğœƒ| M) ğ‘(M) . (34)
Once the model M is determined, one can infer the posterior
mean by Ì‚ğœƒ= âˆ«ğœƒğ‘(ğœƒ| Ìƒğ‘‹, Ìƒğ‘Œ, M)ğ‘‘ğœƒ. Depending on the selected
likelihood or prior, variations of Bayesian neural encoding
methods have been developed [98â€“100].
Given the parameter posterior ğ‘(ğœƒ
|
Ìƒğ‘‹, Ìƒğ‘Œ, M) from
the encoding analysis, decoding analysis aims to infer the
latent variable ğ‘‹given new data ğ‘Œat the decoding stage
(with preselected M). Within the Bayesian framework, it is
equivalent to finding the ğ‘‹MAP [101] as follows:
ğ‘‹MAP = arg max
ğ‘‹ğ‘(ğ‘‹| ğœƒ, ğ‘Œ, M)
= arg max
ğ‘‹âˆ«ğ‘(ğ‘Œ| ğ‘‹, ğœƒ, M) ğ‘(ğœƒ| Ìƒğ‘‹, Ìƒğ‘Œ, M) ğ‘(ğ‘‹) ğ‘‘ğœƒ
â‰ˆarg max
ğ‘‹ğ‘(ğ‘Œ| ğ‘‹, Ì‚ğœƒ, M) ğ‘(ğ‘‹) ,
(35)

10
Computational Intelligence and Neuroscience
which consists of two numerical problems: maximization and
integration. In the approximation in the last step of (35), we
have used ğ‘(ğœƒ| Ìƒğ‘‹, Ìƒğ‘Œ, M) â‰ˆğ›¿(ğœƒâˆ’Ì‚ğœƒ), where Ì‚ğœƒdenotes the
estimated mean or mode statistic from ğ‘(ğœƒ| Ìƒğ‘‹, Ìƒğ‘Œ, M). The
optimization problem is more conveniently written in the log
domain as follows:
log ğ‘(ğ‘‹| ğ‘Œ, Ì‚ğœƒ) âˆlog ğ‘(ğ‘Œ| ğ‘‹, Ì‚ğœƒ) + log ğ‘(ğ‘‹) .
(36)
If ğ‘‹follows a Markovian process, this can be solved by
recursive Bayesian filtering [65, 67] (Section 3.6). When ğ‘‹
is non-Markovian but ğ‘(ğ‘‹) and the likelihood are both log-
concave, this can be resorted to a global optimization problem
[57, 102]. Imposing prior information and structure (e.g.,
sparsity, spatiotemporal correlation) onto ğ‘(ğ‘‹) is important
for obtaining either a meaningful solution or a significant
optimization speedup [103, 104]. In contrast, when ğ‘(ğ‘‹) is
flat or noninformative, the MAP solution will be similar to
the m.l.e.
In the literature, the majority of neural encoding or
decoding models fall within two parametric families: linear
model (e.g., [63, 105]) and GLM (e.g., [64, 106, 107]), although
nonparametric encoding models have also been considered
[108, 109]. Methods for Bayesian neural decoding include (i)
Kalman filtering [63], (ii) point process filtering [65â€“67, 110,
111], (iii) particle filtering [70, 71], and (iv) MCMC methods
[112]. The areas of experimental neuroscience data include
the retina, primary visual cortex, primary somatosensory
cortex, auditory periphery (auditory nerves and midbrain
auditory neurons), primary auditory cortex, primary motor
cortex, premotor cortex, hippocampus, and the olfactory
bulb.
It is important to point out that most spike-count or point
process based decoding algorithms rely on the assumptions
that neural spikes have been properly sorted (some neural
decoding algorithms (e.g., [113]) are based on detected MUA
instead of sorted single unit activity). Recently, there have
been a few efforts in developing spike-sorting-free decoding
algorithms, by either estimating the cell identities as missing
variables [114] or modeling the spike identities by their
proxy based on a spatiotemporal point process [115, 116].
Although this work has been carried out using likelihood
inference, it is straightforward to extend it to the Bayesian
framework. In the example of decoding the ratâ€™s position from
recorded ensemble hippocampal spike activity [115, 116], we
used a model-free (without ğœƒ) and data-driven Bayesâ€™ rule as
follows:
ğ‘(ğ‘‹| ğ‘Œ, Ìƒğ‘‹, Ìƒğ‘Œ) âˆğ‘(ğ‘Œ| ğ‘‹, Ìƒğ‘‹, Ìƒğ‘Œ) ğ‘(ğ‘‹) ,
(37)
in which ğ‘(ğ‘‹) denotes the prior and the likelihood ğ‘(ğ‘Œ| ğ‘‹,
Ìƒğ‘‹, Ìƒğ‘Œ) is evaluated nonparametrically (namely, nonparamet-
ric neural decoding). By assuming that the joint/marginal/
conditional distributions (ğ‘(ğ‘‹, ğ‘Œ) and ğ‘(Ìƒğ‘‹, Ìƒğ‘Œ), ğ‘(ğ‘‹) and
ğ‘(Ìƒğ‘‹), and ğ‘(ğ‘Œ| ğ‘‹) and ğ‘(Ìƒğ‘Œ| Ìƒğ‘‹)) are stationary during
both encoding and decoding phases, the MAP estimate of
decoding analysis is obtained by
ğ‘‹MAP
= arg
ğ‘‹
max ğ‘(ğ‘Œ| ğ‘‹, Ìƒğ‘‹, Ìƒğ‘Œ) ğ‘(ğ‘‹)
â‰ˆarg
ğ‘‹
max ğ‘“(ğ‘Œóµ„¨óµ„¨óµ„¨óµ„¨óµ„¨ğ‘(ğ‘‹| Ìƒğ‘‹) , ğ‘(ğ‘‹, ğ‘Œ| Ìƒğ‘‹, Ìƒğ‘Œ)) ğ‘(ğ‘‹) ,
(38)
where ğ‘“is a nonlinear function that involves the marginal
and joint pdfâ€™s in the argument [115, 116], in which the pdfâ€™s
are constructed based on a kernel density estimator (KDE).
Alternatively, the nonparametric pdf in (38) can be replaced
by a parametric form [115] as follows:
ğ‘‹MAP â‰ˆarg
ğ‘‹
max ğ‘“(ğ‘Œóµ„¨óµ„¨óµ„¨óµ„¨ğ‘(ğ‘‹| ğœƒ) , ğ‘(ğ‘‹, ğ‘Œ| ğœƒ)) ğ‘(ğ‘‹) , (39)
where ğ‘(ğ‘‹| ğœƒ) = âˆ«ğ‘(ğ‘‹, ğ‘Œ| ğœƒ)ğ‘‘ğ‘Œis the parametric marginal
and ğœƒis the point estimate obtained from the training samples
{Ìƒğ‘‹, Ìƒğ‘Œ}.
Note. (i) Neural encoding and decoding analyses are estab-
lished upon the assumption that the neural codes are well
understoodâ€”namely, how neuronal spikes represent and
transmit the information of the external world. Whether
being a rate code, a timing code, a latency code, or an inde-
pendent or correlated population code, Bayesian approach
provides a universal strategy to test the coding hypothesis
or extract the information [117]. (ii) The sensitivity of spike
trains to noise may affect the effectiveness to the encoding-
decoding process. From an information-theoretic perspec-
tive, various sources of spike noise, such as misclassified
spikes (false positives) and misdetected, or misclassified
spikes (false negatives), may affect differently the mutual
information between the input (stimulus) and output (spikes)
channel [118, 119]. In designing a Bayesian decoder, it is
important to take into account the noise issue. A decoding
strategy that is robust to the noise assumption will presum-
ably yield the best performance [115, 116].
4.3. Deconvolution of Neural Spike Trains. Fluorescent cal-
cium imaging tools have become increasingly popular for
observing the spiking activity of large neuronal populations.
However, extracting or deconvolving neural spike trains from
the raw fluorescence movie or video sequences remains a
challenging estimation problem. The standard ğ‘‘ğ¹/ğ¹or
Wiener filtering approaches do not capture the true statistics
of neural spike trains and are sensitive to the noise statistics
[120].
A principled approach is to formulate the deconvolution
problem of a filtered point process via state space analysis
and Bayesian inference [121, 122] (see also [123] for another
type of Bayesian deconvolution approach using MCMC).
Let ğ¹ğ‘¡denote the measured univariate fluorescence time
series, which is modeled as a linear Gaussian function of the
intracellular calcium concentration ([Ca2+]) as follows:
ğ¹ğ‘¡= ğ›¼[Ca2+]ğ‘¡+ ğ›½+ ğœ–ğ‘¡,
(40)

Computational Intelligence and Neuroscience
11
where ğ›½denotes a constant baseline and ğœ–ğ‘¡
âˆ¼N(0, ğœ2)
denotes the Gaussian noise with zero mean and variance ğœ2.
The calcium concentration can be modeled as a first-order
autoregressive (AR) process corrupted by Poisson noise as
follows:
ğ›¼[Ca2+]ğ‘¡= ğ›¼[Ca2+]ğ‘¡âˆ’1 + ğ‘›ğ‘¡,
(41)
where ğ‘›ğ‘¡âˆ¼Poisson (ğœ†Î”) and the bin size Î” is chosen to
assure that the mean firing rate is independent of the imaging
frame rate.
Let ğœƒ= {ğ›¼, ğ›½, ğ›¾, ğœ2, ğœ†}; given the above generative bio-
physical model, Bayesian deconvolution aims to seek the
MAP estimate of spike train as follows:
Ì‚n = arg max
ğ‘›ğ‘¡âˆˆN0
ğ‘(n | F, ğœƒ)
= arg max
ğ‘›ğ‘¡âˆˆN0
ğ‘(F | n, ğœƒ) ğ‘(n | ğœƒ)
= arg max
ğ‘›ğ‘¡âˆˆN0
ğ‘‡
âˆ
ğ‘¡=1
ğ‘(ğ¹ğ‘¡| Ca2+
ğ‘¡, ğœƒ)
ğ‘‡
âˆ
ğ‘¡=1
ğ‘(ğ‘›ğ‘¡| ğœƒ) .
(42)
Within the state space framework, Vogelstein and colleagues
[121] proposed a particle filtering method to infer the pos-
terior probability of spikes at each imaging frame, given
the entire fluorescence traces. However, the Monte Carlo
approach is computationally expensive and may not be suit-
able for analyses of a large population of neurons. To meet
the real-time processing requirement, they further proposed
an approximate yet fast solution by replacing the Poisson
distribution by an exponential distribution with the same
mean (therefore relaxing the nonnegative integer constraint
to the nonnegative real number) [122]. And the approximate
solution is given by the following optimization problem:
Ì‚n = arg max
ğ‘›ğ‘¡â‰¥0
ğ‘‡
âˆ‘
ğ‘¡=1
âˆ’
1
2ğœ2 (ğ¹ğ‘¡âˆ’ğ›¼Ca2+
ğ‘¡âˆ’ğ›½)
2 âˆ’ğ‘›ğ‘¡ğœ†Î”
= arg
max
Ca2+
ğ‘¡âˆ’ğ›¾Ca2+
ğ‘¡âˆ’1â‰¥0
ğ‘‡
âˆ‘
ğ‘¡=1
âˆ’
1
2ğœ2 (ğ¹ğ‘¡âˆ’ğ›¼Ca2+
ğ‘¡âˆ’ğ›½)
2
âˆ’(Ca2+
ğ‘¡âˆ’ğ›¾Ca2+
ğ‘¡âˆ’1) ğœ†Î”.
(43)
The approximation of exponential form makes the optimiza-
tion problem concave with respect to Ca2+, from which the
global optimum can be obtained using constrained convex
optimization [102]. Once the estimate of the calcium trace is
obtained, the MAP spike train can be simply inferred by a
linear transformation.
In a parallel fashion, the parameter ğœƒcan be similarly
estimated by Bayesian inference as follows:
ğœƒMAP = arg max
ğœƒ
âˆ«ğ‘(F | Ca2+, ğœƒ) ğ‘(Ca2+ | ğœƒ) ğ‘‘Ca2+
â‰ˆarg max
ğœƒğ‘(F | Ì‚n, ğœƒ) ğ‘(Ì‚n | ğœƒ) ,
(44)
where the approximation in the second step assumes that the
major mass in the integral is around the MAP sequence Ì‚n
(or equivalently the Ca2+ traces). Therefore, the joint estimate
(Ì‚n, ğœƒMAP) can be computed iteratively from (43) and (44) until
convergence.
Note. The output of Bayesian deconvolution yields a proba-
bility vector between 0 and 1 of having a spike in a given time
frame. Selection of different thresholds on the probability
vector leads to different detection errors (a tradeoff between
the false positives and false negatives). Nevertheless, the
Bayesian solution is much more superior to the standard
least-squares method. It is noteworthy that a new fast decon-
volution method has recently been proposed based on finite
rate of innovation (FRI) theory, with reported performance
better than the approximate Bayesian solution [124].
4.4. Inference of Neuronal Functional Connectivity and Syn-
chrony. Identifying the functional connectivity of simultane-
ously recorded neuronal ensembles is an important research
objective in computational neuroscience. This analysis has
many functional applications such as in neural decoding [125]
and in understanding the collective dynamics of coordinated
spiking cortical networks [126]. Compared to the stan-
dard nonparametric approaches such as cross-correlogram
and joint peristimulus time histogram (JPSTH), parametric
model-based statistical approaches offer several advantages
in neural data interpretation [127].
To model the spike train point process data, without loss
of generality we use the following logistic regression model
with a logit link function. Specifically, let ğ‘be the index
of a target neuron, and let ğ‘–= 1, . . . ğ¶be the indices of
triggered neurons (whose spike activity is assumed to trigger
the firing of the target neuron). The Bernoulli (binomial)
logistic regression GLM is written as
logit (ğœ‹ğ‘¡) = ğœƒâŠ¤
ğ‘ğ‘‹ğ‘¡= ğœƒğ‘
0 +
ğ½
âˆ‘
ğ‘—=1
ğœƒğ‘
ğ‘—ğ‘¥ğ‘—,ğ‘¡
= ğœƒğ‘
0 +
ğ¶
âˆ‘
ğ‘–=1
ğ¾
âˆ‘
ğ‘˜=1
ğœƒğ‘
ğ‘–,ğ‘˜ğ‘¥ğ‘–,ğ‘¡âˆ’ğ‘˜,
(45)
where dim(ğœƒğ‘) = ğ½+1 = ğ¶Ã—ğ¾+1 for the augmented param-
eter vector ğœƒğ‘= {ğœƒğ‘
0, ğœƒğ‘
ğ‘–,ğ‘˜} and ğ‘‹ğ‘¡= {ğ‘¥0, ğ‘¥ğ‘–,ğ‘¡âˆ’ğ‘˜}. Here, ğ‘¥0 â‰¡1,
and ğ‘¥ğ‘–,ğ‘¡âˆ’ğ‘˜denotes the raw spike count from neuron ğ‘–at the
ğ‘˜th time-lag history window (or a predefined smooth basis
function such as in [125]). The spike count is nonnegative;
therefore ğ‘¥ğ‘–,ğ‘¡âˆ’ğ‘˜â‰¥0. Alternatively, (45) can be rewritten as
ğœ‹ğ‘¡=
exp (ğœƒâŠ¤
ğ‘ğ‘‹ğ‘¡)
1 + exp (ğœƒâŠ¤
ğ‘ğ‘‹ğ‘¡) =
exp (ğœƒğ‘
0 + âˆ‘ğ½
ğ‘—=1 ğœƒğ‘
ğ‘—ğ‘¥ğ‘—,ğ‘¡)
1 + exp (ğœƒğ‘
0 + âˆ‘ğ½
ğ‘—=1 ğœƒğ‘
ğ‘—ğ‘¥ğ‘—,ğ‘¡)
,
(46)
which yields the probability of a spiking event at time ğ‘¡.
Equation (46) defines a spiking probability model for neuron
ğ‘based on its own spiking history and that of the other
neurons in the ensemble. Here, exp(ğœƒğ‘
0) can be interpreted
as the baseline firing probability of neuron ğ‘. Depending on
the algebraic (positive or negative) sign of coefficient ğœƒğ‘
ğ‘–,ğ‘˜,
exp(ğœƒğ‘
ğ‘–,ğ‘˜) can be viewed as a â€œgainâ€ factor (dimensionless, >1 or
<1) that influences the relative firing probability of neuron ğ‘

12
Computational Intelligence and Neuroscience
from another neuron ğ‘–at the previous ğ‘˜th time lag. Therefore,
a negative value of ğœƒğ‘
ğ‘–,ğ‘˜will strengthen the inhibitory effect; a
positive value of ğœƒğ‘
ğ‘–,ğ‘˜will enhance the excitatory effect. Two
neurons are said to be functionally connected if any of their
pairwise connections is nonzero (or the statistical estimate is
significantly nonzero).
For inferring the functional connectivity of neural
ensembles, in addition to the standard likelihood approaches
[127, 128], various forms of Bayesian inference have been
developed for the MaxEnt model, GLM, and Bayesian net-
work [129â€“132]. In a similar context, a Bayesian method has
been developed based on the deconvolved neuronal spike
trains from calcium imaging data [133].
Bayesian methods also proved useful in detecting higher-
order correlations among neural assemblies [134, 135].
Higher-order correlations are often characterized by synchro-
nous neuronal firing at a timescale of 5â€“10 ms. These findings
have been reported in experimental data from prefrontal
cortex, somatosensory cortex, and visual cortex across many
species and animals. Consider a set of ğ¶neurons. Each
neuron is represented by two states: 1 (firing) or 0 (silent).
At any time instant, the state of the ğ¶neurons is represented
by the vector ğ‘‹= (ğ‘¥1, ğ‘¥2, . . . , ğ‘¥ğ¶) (the time index is omitted
for simplicity), and in total there are 2ğ¶neuronal states. For
instance, a general joint distribution of three neurons can be
expressed by a log-linear model [134]
ğ‘(ğ‘¥1, ğ‘¥2, ğ‘¥3) = exp (ğœƒ0 + ğœƒ1ğ‘¥1 + ğœƒ2ğ‘¥2 + ğœƒ3ğ‘¥3
+ ğœƒ12ğ‘¥1ğ‘¥2 + ğœƒ13ğ‘¥1ğ‘¥3
+ğœƒ23ğ‘¥2ğ‘¥3 + ğœƒ123ğ‘¥1ğ‘¥2ğ‘¥3) ,
(47)
which is a natural extension of the MaxEnt model described
in (9). A nonzero coefficient of ğœƒ123 would imply the presence
of third-order correlation among the three neurons. In
experimental data, the number of synchronous events may
be scarce in single trials, and the interaction coefficients
may also be time-varying. State space analysis and Bayesian
filtering offer a principled framework to address these issues
[135]. However, the computational bottleneck is the curse of
dimensionality when the value of ğ¶is moderately large (220 â‰ˆ
106). In the presence of finite data sample size, it is reasonable
to impose certain structural priors onto the parameter space
for the Bayesian solution.
5. Discussion
We have presented an overview of Bayesian inference meth-
ods and their applications to neural spike train analysis.
Although the focus of current paper is on neural spike trains,
the Bayesian principle is also applicable to other modalities
of neural data (e.g., [136]). Due to space limitation, we only
cover representative methods and applications in this paper,
and the references are reflective of our personal choices from
the humongous literature.
In comparison with the standard methods, Bayesian
methods provide a flexible framework to address many fun-
damental estimation problems at different stages of neural
data analysis. Regardless of the specific Bayesian approach to
be employed, the common goal of Bayesian solutions consists
in replacing a single point estimate (or hard decision label)
with a full posterior distribution (or soft decision label). As a
tradeoff, Bayesian practioners have to encounter the increas-
ing cost of computational complexity (especially while using
MCMC), which may be prohibitive for large-scale spike train
data sets. Furthermore, special attention shall be paid to select
the optimal technique among different Bayesian methods
that ultimately lead to quantitatively different approximate
Bayesian solutions.
Despite the significant progresses made to date, there
remain many research challenges and opportunities for
applying Bayesian machinery to neural spike trains, and we
will mention a few of them below.
5.1. Nonstationarity. Neural spiking activity is highly non-
stationary at various timescales. Sources that account for
such nonstationarity may include the animalâ€™s behavioral
variability across trials, top-down attention, learning, motiva-
tion, or emotional effects across time. These effects are time-
varying across behaviors. In addition, individual neuronal
firing may be affected by other unobserved neural activity,
such as through modulatory or presynaptic inputs from other
nonrecorded neurons. Therefore, it may be important to
consider these latent variables while analyzing neural spike
trains [137]. Bayesian methods are a natural solution to model
and infer such latent variables. Traditional mixed-effects
models can be adapted to a hierarchical Bayesian model to
capture various sources of randomness.
5.2. Characterization of Neuronal Dependencies. Neural
responses may appear correlated or synchronous at different
timescales. It is important to characterize such neuronal
dependencies in order to fully understand the nature of neu-
ral codes. It is also equally important to associate the neu-
ral responses to other measurements, such as behavioral
responses, learning performance, or local field potentials.
Commonly, correlation statistics or information-theoretic
measures have been used (e.g., [138]). Other advanced sta-
tistical measures have also been proposed, such as the log-
linear model [139], Granger causality [140], transfer entropy
[141], or copula model [142]. Specifically, the copula offers
a universal framework to model statistical dependencies
among continuous, discrete, or mixed-valued r.v., and it has
an intrinsic link to the mutual information; Bayesian methods
may prove useful for selecting the copula class or the copula
mixtures [143]. However, because of the nonstationary nature
of neural codes (Section 5.1), it remains a challenge to identify
the â€œtrueâ€ dependencies among the observed neural spike
trains, and it remains important to rule out and rule in neural
codes under specific conditions.
5.3. Characterization and Abstraction of Neuronal Ensemble
Representation. Since individual neuronal spike activity is
known to be stochastic and noisy, in the single-trial analysis
it is anticipated that the information extracted from neuronal
populations is more robust than that from a single neuron.
How to uncover the neural representation of population
codes in a single-trial analysis has been an active research

Computational Intelligence and Neuroscience
13
topic in neuroscience. This is important not only for abstrac-
tion, interpretation, and visualization of population codes
but also for discovering invariant neural representations and
their links to behavior. Standard dimensionality reduction
techniques (e.g., principle component analysis, multidimen-
sional scaling, or locally linear embedding) have been widely
used for such analyses. However, these methods have ignored
the temporal component of neural codes. In addition, no
explicit behavioral correlate may become available in certain
modeling tasks. Recently, Bayesian dynamic models, such as
the Gaussian process factor analysis (GPFA) [144] and VB-
HMM [145â€“147], have been proposed to visualize population
codes recorded from large neural ensembles across different
experimental conditions. To learn the highly complex struc-
ture of spatiotemporal neural population codes, it may be
beneficial to borrow the ideas from the machine learning
community and to integrate the state-of-the-art unsupervised
and supervised deep Bayesian learning techniques.
5.4. Translational Neuroscience Applications. Finally in the
long run, it is crucial to apply basic neuroscience knowledge
derived from quantitative analyses of neural data to trans-
lational neuroscience research. Many clinical research areas
may benefit from the statistical analyses reviewed here, such
as design of neural prosthetics for patients with tetraplegia
[107], detection and control of epileptic seizures, optical
control of neuronal firing in behaving animals, or simulation
of neural firing patterns to achieve optimal electrotherapeutic
effect [148]. Bridging the gap between neural data analysis
and their translational applications (such as treating neuro-
logical or neuropsychiatric disorders) would continue to be
a prominent mission accompanying the journey of scientific
discovery.
Acknowledgments
The author was supported by an Early Career Award from
the Mathematical Biosciences Institute, Ohio State University.
This work was also supported by the NSF-IIS CRCNS (Col-
laborative Research in Computational Neuroscience) Grant
(no. 1307645) from the National Science Foundation.
References
[1] E. N. Brown, R. E. Kass, and P. P. Mitra, â€œMultiple neural spike
train data analysis: state-of-the-art and future challenges,â€
Nature Neuroscience, vol. 7, no. 5, pp. 456â€“461, 2004.
[2] S. GrÂ¨un and S. Rotter, Analysis of Parallel Spike Trains, Springer,
New York, NY, USA, 2010.
[3] I. H. Stevenson and K. P. Kording, â€œHow advances in neural
recording affect data analysis,â€ Nature Neuroscience, vol. 14, no.
2, pp. 139â€“142, 2011.
[4] G. B. Stanley, â€œReading and writing the neural code,â€ Nature
Neuroscience, vol. 16, pp. 259â€“263, 2013.
[5] Z. Chen, T. W. Berger, A. Cichocki, K. G. Oweiss, R. Quian
Quiroga, and N. V. Thakor, â€œSignal processing for neural spike
trains,â€ Computational Intelligence and Neuroscience, vol. 2010,
Article ID 698751, 2 pages, 2010.
[6] J. Macke, P. Berens, and M. Bethge, â€œStatistical analysis of multi-
cell recordings: linking population coding models to experi-
mental data,â€ Frontiers in Computational Neuroscience, vol. 5,
article 35, 2011.
[7] J. Bernardo and A. F. M. Smith, Bayesian Theory, John & Wiley,
New York, NY, USA, 1994.
[8] A. Gelman, J. B. Carlin, H. S. Stern, and D. B. Rubin, Bayesian
Data Analysis, Chapman & Hall/CRC, New York, NY, USA, 2nd
edition, 2004.
[9] Y. Pawitan, In All Likelihood: Statistical Modelling and Inference
Using Likelihood, Clarendon Press, New York, NY, USA, 2001.
[10] D. J. Daley and D. Vere-Jones, An Introduction to the Theory
of Point Processes, Springer, New York, NY, USA, 2nd edition,
2003.
[11] E. N. Brown, R. Barbieri, U. T. Eden, and L. M. Frank, â€œLike-
lihood methods for neural data analysis,â€ in Computational
Neuroscience: A Comprehensive Approach, J. Feng, Ed., pp. 253â€“
286, CRC Press, New York, NY, USA, 2003.
[12] E. N. Brown, â€œTheory of point processes for neural systems,â€ in
Methods and Models in Neurophysics, C. C. Chow, B. Gutkin, D.
Hansel et al., Eds., pp. 691â€“727, Elsevier, San Diego, Calif, USA,
2005.
[13] Z. Chen, R. Barbieri, and E. N. Brown, â€œState-space modeling
of neural spike train and behavioral data,â€ in Statistical Signal
Processing for Neuroscience and Neurotechnology, K. Oweiss,
Ed., pp. 161â€“200, Elsevier, San Diego, Calif, USA, 2010.
[14] W. Truccolo, U. T. Eden, M. R. Fellows, J. P. Donoghue, and E. N.
Brown, â€œA point process framework for relating neural spiking
activity to spiking history, neural ensemble, and extrinsic
covariate effects,â€ Journal of Neurophysiology, vol. 93, no. 2, pp.
1074â€“1089, 2005.
[15] P. McCullagh and A. Nelder, Generalized Linear Models, vol. 22
of Computational Intelligence and Neuroscience, Chapman &
Hall/CRC Press, New York, NY, USA, 2nd edition, 1989.
[16] E. Schneidman, M. J. Berry II, R. Segev, and W. Bialek, â€œWeak
pairwise correlations imply strongly correlated network states
in a neural population,â€ Nature, vol. 440, no. 7087, pp. 1007â€“1012,
2006.
[17] H. Nasser, O. Marre, and B. Cessac, â€œSpatio-temporal spike train
analysis for large scale networks using the maximum entropy
principle and Monte Carlo method,â€ Journal of Statistical
Mechanics, vol. 2013, Article ID P03006, 2013.
[18] E. N. Brown, R. Barbieri, V. Ventura, R. E. Kass, and L. M. Frank,
â€œThe time-rescaling theorem and its application to neural spike
train data analysis,â€ Neural Computation, vol. 14, no. 2, pp. 325â€“
346, 2002.
[19] S. Julier, J. Uhlmann, and H. F. Durrant-Whyte, â€œA new method
for the nonlinear transformation of means and covariances in
filters and estimators,â€ IEEE Transactions on Automatic Control,
vol. 45, no. 3, pp. 477â€“482, 2000.
[20] S. SÂ¨arkkÂ¨a, â€œOn unscented Kalman filtering for state estimation
of continuous-time nonlinear systems,â€ IEEE Transactions on
Automatic Control, vol. 52, no. 9, pp. 1631â€“1641, 2007.
[21] M. I. Jordan, Z. Ghahramani, T. S. Jaakkola, and L. K. Saul,
â€œIntroduction to variational methods for graphical models,â€
Machine Learning, vol. 37, no. 2, pp. 183â€“233, 1999.
[22] H. Attias, â€œA variational Bayesian framework for graphical
models,â€ in Advances in Neural Information Processing Systems
(NIPS) 12, S. A. Solla, T. K. Leen, and K. R. MÂ¨uller, Eds., MIT
Press, Boston, Mass, USA, 2000.

14
Computational Intelligence and Neuroscience
[23] M. Beal and Z. Ghahramani, â€œVariational Bayesian learning of
directed graphical models,â€ Bayesian Analysis, vol. 1, no. 4, pp.
793â€“832, 2006.
[24] D. J. MacKay, Information Theory, Inference, and Learning Algo-
rithms, Cambridge University Press, New York, NY, USA, 2003.
[25] C. M. Bishop, Pattern Recognition and Machine Learning,
Springer, New York, NY, USA, 2006.
[26] K. P. Murphy, Machine Learning: A Probabilistic Perspective,
MIT Press, Cambridge, Mass, USA, 2012.
[27] D. Barber, Bayesian Reasoning and Machine Learning, Cam-
bridge University Press, New York, NY, USA, 2012.
[28] D. Barber, A. T. Cemgil, and S. Chiappa, Bayesian Time Series
Models, Cambridge University Press, New York, NY, USA, 2011.
[29] T. M. Cover and J. A. Thomas, Elements of Information Theory,
John Wiley & Sons, New York, NY, USA, 2nd edition, 2006.
[30] A. Dempster, N. Laird, and D. B. Rubin, â€œMaximum likelihood
from incomplete data via the EM algorithm,â€ Journal of the
Royal Statistical Society B, vol. 39, pp. 1â€“38, 1977.
[31] K. Katahira, K. Watanabe, and M. Okada, â€œDeterministic
annealing variant of variational Bayes method,â€ Journal of
Physics, vol. 95, no. 1, Article ID 012015, 2008.
[32] K. Kurihara and M. Welling, â€œBayesian k-means as a â€œmaximi-
zation-expectationâ€ algorithm,â€ Neural Computation, vol. 21, no.
4, pp. 1145â€“1172, 2009.
[33] J. Sung, Z. Ghahramani, and S.-Y. Bang, â€œLatent-space vari-
ational bayes,â€ IEEE Transactions on Pattern Analysis and
Machine Intelligence, vol. 30, no. 12, pp. 2236â€“2242, 2008.
[34] J. Sung, Z. Ghahramani, and S.-Y. Bang, â€œSecond-order latent-
space variational bayes for approximate bayesian inference,â€
IEEE Signal Processing Letters, vol. 15, pp. 918â€“921, 2008.
[35] R. E. Turner and M. Sahani, â€œTwo problems with variational
expectation maximisation for time series models,â€ in Bayesian
Time Series Models, D. Barber, A. T. Cemgil, and S. Chiappa,
Eds., pp. 115â€“138, Cambridge University Press, New York, NY,
USA, 2011.
[36] K. Watanabe, â€œAn alternative view of variational Bayes and
asymptotic approximations of free energy,â€ Machine Learning,
vol. 86, no. 2, pp. 273â€“293, 2012.
[37] A. Honkela, T. Raiko, M. Kuusela, M. Tornio, and J. Karhunen,
â€œApproximate riemannian conjugate gradient learning for fixed-
form variational bayes,â€ Journal of Machine Learning Research,
vol. 11, pp. 3235â€“3268, 2010.
[38] T. P. Minka, A family of algorithms for approximate Bayesian
inference [Ph.D. thesis], Department of EECS, Massachusetts
Institute of Technology, Cambridge, Mass, USA, 2001.
[39] S.-I. Amari and H. Nagaoka, Methods of Information Geometry,
Oxford University Press, New York, NY, USA, 2007.
[40] W. R. Gilks, S. Richardson, and D. J. Spiegelhalter, Markov Chain
Monte Carlo in Practice, Chapman & Hall/CRC, New York, NY,
USA, 1995.
[41] C. P. Robert and G. Casella, Monte Carlo Statistical Methods,
Springer, New York, NY, USA, 2nd edition, 2004.
[42] N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A. H.
Teller, and E. Teller, â€œEquation of state calculations by fast
computing machines,â€ The Journal of Chemical Physics, vol. 21,
no. 6, pp. 1087â€“1092, 1953.
[43] W. K. Hastings, â€œMonte carlo sampling methods using Markov
chains and their applications,â€ Biometrika, vol. 57, no. 1, pp. 97â€“
109, 1970.
[44] S. Geman and D. Geman, â€œStochastic relaxation, gibbs distri-
butions, and the bayesian restoration of images,â€ IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, vol. 6, no. 6,
pp. 721â€“741, 1984.
[45] R. M. Neal, â€œSuppressing random walks in Markov chain Monte
Carlo using ordered overrelaxation,â€ Tech. Rep. 9508, Univer-
sity of Toronto; Department of Statistics, 1995.
[46] T. Marshall and G. Roberts, â€œAn adaptive approach to Langevin
MCMC,â€ Statistics and Computing, vol. 22, no. 5, pp. 1041â€“1057,
2012.
[47] Y. Qi and T. P. Minka, â€œHessian-based Markov chain Monte-
Carlo algorithms,â€ in Proceedings of the 1st Cape Cod Workshop
on Monte Carlo Methods, Cape Cod, Mass, USA, September
2002.
[48] P. J. Green, â€œReversible jump Markov chain monte carlo compu-
tation and Bayesian model determination,â€ Biometrika, vol. 82,
no. 4, pp. 711â€“732, 1995.
[49] R. E. Kass and A. E. Raftery, â€œBayes factors,â€ Journal of the Amer-
ican Statistical Association, vol. 90, no. 430, pp. 773â€“795, 1995.
[50] M. Lavine and M. J. Schervish, â€œBayes factors: what they are and
what they are not,â€ American Statistician, vol. 53, no. 2, pp. 119â€“
122, 1999.
[51] S. M. Lewis and A. E. Raftery, â€œEstimating Bayes factors via
posterior simulation with the Laplace-Metropolis estimator,â€
Journal of the American Statistical Association, vol. 92, no. 438,
pp. 648â€“655, 1997.
[52] T. Toni and M. P. H. Stumpf, â€œSimulation-based model selection
for dynamical systems in systems and population biology,â€
Bioinformatics, vol. 26, no. 1, pp. 104â€“110, 2009.
[53] R. M. Neal, Bayesian Learning for Neural Networks, Springer,
New York, NY, USA, 1996.
[54] J. A. Hoeting, D. Madigan, A. E. Raftery, and C. T. Volinsky,
â€œBayesian model averaging: a tutorial,â€ Statistical Science, vol.
14, no. 4, pp. 382â€“417, 1999.
[55] A. E. Raftery, â€œApproximate Bayes factors and accounting for
model uncertainty in generalised linear models,â€ Biometrika,
vol. 83, no. 2, pp. 251â€“266, 1996.
[56] Z. Chen and E. N. Brown, â€œState space model,â€ Scholarpedia, vol.
8, no. 3, Article ID 30868, 2013.
[57] L. Paninski, Y. Ahmadian, D. G. Ferreira et al., â€œA new look at
state-space models for neural data,â€ Journal of Computational
Neuroscience, vol. 29, no. 1-2, pp. 107â€“126, 2010.
[58] A. Papoulis, Probability, Random Variables, and Stochastic
Processes, McGraw-Hill, New York, NY, USA, 4th edition, 2002.
[59] C. P. Robert, T. RydÂ´en, and D. M. Titterington, â€œBayesian
inference in hidden Markov models through the reversible
jump Markov chain Monte Carlo method,â€ Journal of the Royal
Statistical Society B, vol. 62, no. 1, pp. 57â€“75, 2000.
[60] S. L. Scott, â€œBayesian methods for hidden Markov models:
recursive computing in the 21st century,â€ Journal of the Amer-
ican Statistical Association, vol. 97, no. 457, pp. 337â€“351, 2002.
[61] Z. Ghahramani, â€œLearning dynamic Bayesian networks,â€ in
Adaptive Processing of Sequences and Data Structures, C. L. Giles
and M. Gori, Eds., pp. 168â€“197, Springer, New York, NY, USA,
1998.
[62] R. E. Kalman, â€œA new approach to linear filtering and prediction
problems,â€ Transactions of the ASME, vol. 82, pp. 35â€“45, 1960.
[63] W. Wu, Y. Gao, E. Bienenstock, J. P. Donoghue, and M. J. Black,
â€œBayesian population decoding of motor cortical activity using
a Kalman filter,â€ Neural Computation, vol. 18, no. 1, pp. 80â€“118,
2006.

Computational Intelligence and Neuroscience
15
[64] W. Wu, J. E. Kulkarni, N. G. Hatsopoulos, and L. Paninski,
â€œNeural decoding of hand motion using a linear state-space
model with hidden states,â€ IEEE Transactions on Neural Systems
and Rehabilitation Engineering, vol. 17, no. 4, pp. 370â€“378, 2009.
[65] E. N. Brown, L. M. Frank, D. Tang, M. C. Quirk, and M. A.
Wilson, â€œA statistical paradigm for neural spike train decoding
applied to position prediction from ensemble firing patterns of
rat hippocampal place cells,â€ Journal of Neuroscience, vol. 18, no.
18, pp. 7411â€“7425, 1998.
[66] A. C. Smith and E. N. Brown, â€œEstimating a state-space model
from point process observations,â€ Neural Computation, vol. 15,
no. 5, pp. 965â€“991, 2003.
[67] U. T. Eden, L. M. Frank, R. Barbieri, V. Solo, and E. N. Brown,
â€œDynamic analysis of neural encoding by point process adaptive
filtering,â€ Neural Computation, vol. 16, no. 5, pp. 971â€“998, 2004.
[68] S. Koyama, L. Castellanos PÂ´erez-Bolde, C. Rohilla Shalizi, and
R. E. Kass, â€œApproximate methods for state-space models,â€
Journal of the American Statistical Association, vol. 105, no. 489,
pp. 170â€“180, 2010.
[69] A. Doucet, N. de Freitas, and N. Gordon, Sequential Monte
Carlo Methods in Practice, Springer, New York, NY, USA, 2001.
[70] A. E. Brockwell, A. L. Rojas, and R. E. Kass, â€œRecursive Bayesian
decoding of motor cortical signals by particle filtering,â€ Journal
of Neurophysiology, vol. 91, no. 4, pp. 1899â€“1907, 2004.
[71] A. Ergun, R. Barbieri, U. T. Eden, M. A. Wilson, and E. N.
Brown, â€œConstruction of point process adaptive filter algo-
rithms for neural system using sequential Monte Carlo meth-
ods,â€ IEEE Transactions on Biomedical Engineering, vol. 54, pp.
419â€“428, 2007.
[72] V. Ë‡SmÂ´Ä±dl and A. Quinn, â€œVariational Bayesian filtering,â€ IEEE
Transactions on Signal Processing, vol. 56, no. 10, pp. 5020â€“5030,
2008.
[73] Y. Salimpour, H. Soltanian-Zadeh, S. Salehi, N. Emadi, and M.
Abouzari, â€œNeuronal spike train analysis in likelihood space,â€
PLoS ONE, vol. 6, no. 6, Article ID e21256, 2011.
[74] N. L. Hjort, C. Holmes, P. MÂ¨uller, and S. G. Walker, Bayesian
Nonparametrics, Cambridge University Press, New York, NY,
USA, 2010.
[75] Z. Ghahramani, â€œBayesian nonparametrics and the probabilistic
approach to modeling,â€ Philosophical Transactions on Royal
Society of London A, vol. 371, Article ID 20110553, 2012.
[76] E. Fox, E. Sudderth, M. Jordan, and A. Willsky, â€œBayesian non-
parametric methods for learning markov switching processes,â€
IEEE Signal Processing Magazine, vol. 27, no. 6, pp. 43â€“54, 2010.
[77] C. E. Rasmussen and C. K. I. Williams, Gaussian Processes for
Machine Learning, MIT Press, Cambridge, Mass, USA, 2005.
[78] J. Van Gael, Y. Saatci, Y. W. Teh, and Z. Ghahramani, â€œBeam
sampling for the infinite hidden Markov model,â€ in 25th Inter-
national Conference on Machine Learning, pp. 1088â€“1095, fin,
July 2008.
[79] F. Gabbiani and C. Koch, â€œPrinciples of spike train analysis,â€ in
Methods in Neuronal Modeling: From Synapses to Networks, C.
Koch and I. Segev, Eds., pp. 313â€“360, MIT Press, Boston, Mass,
USA, 2nd edition, 1998.
[80] R. E. Kass, V. Ventura, and E. N. Brown, â€œStatistical issues in the
analysis of neuronal data,â€ Journal of Neurophysiology, vol. 94,
no. 1, pp. 8â€“25, 2005.
[81] J. S. Prentice, J. Homann, K. D. Simmons, G. TkaË‡cik, V. Bala-
subramanian, and P. C. Nelson, â€œFast, scalable, bayesian spike
identification for Multi-Electrode arrays,â€ PLoS ONE, vol. 6, no.
7, Article ID e19884, 2011.
[82] F. Wood, M. J. Black, C. Vargas-Irwin, M. Fellows, and J. P.
Donoghue, â€œOn the variability of manual spike sorting,â€ IEEE
Transactions on Biomedical Engineering, vol. 51, no. 6, pp. 912â€“
918, 2004.
[83] C. Ekanadham, D. Tranchina, and E. P. Simoncelli, â€œA blind
deconvolution method for neural spike identification,â€ in Pro-
ceedings of the 25th Annual Conference on Neural Information
Processing Systems (NIPS â€™11), vol. 23, MIT Press, December 2011.
[84] M. S. Lewicki, â€œA review of methods for spike sorting: the detec-
tion and classification of neural action potentials,â€ Network, vol.
9, no. 4, pp. R53â€“R78, 1998.
[85] D. P. Nguyen, L. M. Frank, and E. N. Brown, â€œAn application of
reversible-jump Markov chain Monte Carlo to spike classifica-
tion of multi-unit extracellular recordings,â€ Network, vol. 14, no.
1, pp. 61â€“82, 2003.
[86] F. Wood and M. J. Black, â€œA nonparametric Bayesian alternative
to spike sorting,â€ Journal of Neuroscience Methods, vol. 173, no.
1, pp. 1â€“12, 2008.
[87] J. A. Herbst, S. Gammeter, D. Ferrero, and R. H. R. Hahnloser,
â€œSpike sorting with hidden Markov models,â€ Journal of Neuro-
science Methods, vol. 174, no. 1, pp. 126â€“134, 2008.
[88] A. Calabrese and L. Paninski, â€œKalman filter mixture model for
spike sorting of non-stationary data,â€ Journal of Neuroscience
Methods, vol. 196, no. 1, pp. 159â€“169, 2011.
[89] V. Ventura, â€œAutomatic spike sorting using tuning information,â€
Neural Computation, vol. 21, no. 9, pp. 2466â€“2501, 2009.
[90] V. Ventura, â€œTraditional waveform based spike sorting yields
biased rate code estimates,â€ Proceedings of the National Academy
of Sciences of the United States of America, vol. 106, no. 17, pp.
6921â€“6926, 2009.
[91] M. Park and J. W. Pillow, â€œReceptive field inference with local-
ized priors,â€ PLoS Computational Biology, vol. 7, no. 10, Article
ID e1002219, 2011.
[92] I. M. Park and J. W. Pillow, â€œBayesian spike-triggered covariance
analysis,â€ in Advances in Neural Information Processing Systems
(NIPS), J. Shawe-Taylor, R. Zemel, P. Bartlett, F. Fereira, and K.
Q. Weinberger, Eds., vol. 24, pp. 1692â€“1700, MIT Press, Boston,
Mass, USA, 2011.
[93] D. Endres and M. Oram, â€œFeature extraction from spike trains
with Bayesian binning: â€˜Latency is where the signal startsâ€™,â€ Jour-
nal of Computational Neuroscience, vol. 29, no. 1-2, pp. 149â€“169,
2010.
[94] I. Dimatteo, C. R. Genovese, and R. E. Kass, â€œBayesian curve-
fitting with free-knot splines,â€ Biometrika, vol. 88, no. 4, pp.
1055â€“1071, 2001.
[95] A. C. Smith, J. D. Scalon, S. Wirth, M. Yanike, W. A. Suzuki,
and E. N. Brown, â€œState-space algorithms for estimating spike
rate functions,â€ Computational Intelligence and Neuroscience,
vol. 2010, Article ID 426539, 2010.
[96] B. Cronin, I. H. Stevenson, M. Sur, and K. P. KÂ¨ording, â€œHier-
archical bayesian modeling and Markov chain Monte Carlo
sampling for tuning-curve analysis,â€ Journal of Neurophysiology,
vol. 103, no. 1, pp. 591â€“602, 2010.
[97] H. Taubman, E. Vaadia, R. Paz, and G. Chechik, â€œA Bayesian
approach for characterizing direction tuning curves in the sup-
plementary motor area of behaving monkeys,â€ Journal of Neu-
rophysiology, 2013.
[98] L. Paninski, J. Pillow, and J. Lewi, â€œStatistical models for neural
encoding, decoding, and optimal stimulus design,â€ in Compu-
tational Neuroscience: Theoretical Insights Into Brain Function, P.
Cisek, T. Drew, and J. Kalaska, Eds., Elsevier, 2007.

16
Computational Intelligence and Neuroscience
[99] S. Gerwinn, J. H. Macke, M. Seeger, and M. Bethge, â€œBayesian
inference for spiking neuron models with a sparsity prior,â€ in
Advances in Neural Information Processing Systems (NIPS), J. C.
Platt, D. Koller, Y. Singer, and S. Roweis, Eds., vol. 20, pp. 529â€“
536, MIT Press, Boston, Mass, USA, 2008.
[100] J. W. Pillow and J. G. Scott, â€œFully Bayesian inference for neural
models with negative-binomial spiking,â€ in Advances in Neural
Information Processing Systems (NIPS), P. Bartlett, F. C. N.
Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds.,
vol. 25, pp. 1907â€“1915, MIT Press, Boston, Mass, USA, 2012.
[101] S. Koyama, U. T. Eden, E. N. Brown, and R. E. Kass, â€œBayesian
decoding of neural spike trains,â€ Annals of the Institute of
Statistical Mathematics, vol. 62, no. 1, pp. 37â€“59, 2010.
[102] S. Boyd and L. Vandenberghe, Convex Optimization, Cambridge
University Press, New York, NY, USA, 2004.
[103] J. W. Pillow, Y. Ahmadian, and L. Paninski, â€œModel-based
decoding, information estimation, and change-point detection
techniques for multineuron spike trains,â€ Neural Computation,
vol. 23, no. 1, pp. 1â€“45, 2011.
[104] A. D. Ramirez, Y. Ahmadian, J. Schumacher, D. Schneider, S.
M. N. Woolley, and L. Paninski, â€œIncorporating naturalistic cor-
relation structure improves spectrogram reconstruction from
neuronal activity in the songbird auditory midbrain,â€ Journal
of Neuroscience, vol. 31, no. 10, pp. 3828â€“3842, 2011.
[105] Z. Chen, K. Takahashi, and N. G. Hatsopoulos, â€œSparse Bayesian
inference methods for decoding 3D reach and grasp kinematics
and joint angles with primary motor cortical ensembles,â€ in
Proceedings of the 35th Annual International Conference of the
IEEE Engineering in Medicine and Biology (EMBC â€™13), pp. 5930â€“
5933, 2013.
[106] K. Zhang, I. Ginzburg, B. L. McNaughton, and T. J. Sejnowski,
â€œInterpreting neuronal population activity by reconstruction:
unified framework with application to hippocampal place cells,â€
Journal of Neurophysiology, vol. 79, no. 2, pp. 1017â€“1044, 1998.
[107] W. Truccolo, G. M. Friehs, J. P. Donoghue, and L. R. Hochberg,
â€œPrimary motor cortex tuning to intended movement kinemat-
ics in humans with tetraplegia,â€ Journal of Neuroscience, vol. 28,
no. 5, pp. 1163â€“1178, 2008.
[108] W. Truccolo and J. P. Donoghue, â€œNonparametric modeling of
neural point processes via stochastic gradient boosting regres-
sion,â€ Neural Computation, vol. 19, no. 3, pp. 672â€“705, 2007.
[109] T. P. Coleman and S. S. Sarma, â€œA computationally efficient
method for nonparametric modeling of neural spiking activity
with point processes,â€ Neural Computation, vol. 22, no. 8, pp.
2002â€“2030, 2010.
[110] M. M. Shanechi, E. N. Brown, and Z. M. Williams, â€œNeural pop-
ulation partitioning and a concurrent brain-machine interface
for sequential control motor function,â€ Nature Neuroscience,
vol. 12, pp. 1715â€“1722, 2012.
[111] M. M. Shanechi, G. W. Wornell, Z. Williams, and E. N. Brown,
â€œA parallel point-process filter for estimation of goal-directed
movements from neural signals,â€ in Proceedings of the IEEE
International Conference on Acoustics, Speech, and Signal Pro-
cessing (ICASSP â€™10), pp. 521â€“524, Dallas, Tex, USA, March 2010.
[112] Y. Ahmadian, J. W. Pillow, and L. Paninski, â€œEfficient Markov
chain monte carlo methods for decoding neural spike trains,â€
Neural Computation, vol. 23, no. 1, pp. 46â€“96, 2011.
[113] A. K. Bansal, W. Truccolo, C. E. Vargas-Irwin, and J. P.
Donoghue, â€œDecoding 3D reach and grasp from hybrid signals
in motor and premotor cortices: spikes, multiunit activity, and
local field potentials,â€ Journal of Neurophysiology, vol. 107, no. 5,
pp. 1337â€“1355, 2012.
[114] V. Ventura, â€œSpike train decoding without spike sorting,â€ Neural
Computation, vol. 20, no. 4, pp. 923â€“963, 2008.
[115] Z. Chen, F. Kloosterman, S. Layton, and W. A. Wilson, â€œTrans-
ductive neural decoding of unsorted neuronal spikes of rat
hippocampus,â€ in Proceedings of the 34th Annual International
Conference of the IEEE Engineering in Medicine and Biology
(EMBC â€™12), pp. 1310â€“1313, August 2012.
[116] F. Kloosterman, S. Layton, Z. Chen, and M. A. Wilson,
â€œBayesian decoding of unsorted spikes in the rat hippocampus,â€
Journal of Neurophysiology, 2013.
[117] A. L. Jacobs, G. Fridman, R. M. Douglas et al., â€œRuling out and
ruling in neural codes,â€ Proceedings of the National Academy
of Sciences of the United States of America, vol. 106, no. 14, pp.
5936â€“5941, 2009.
[118] D. H. Johnson, â€œInformation theory and neural information
processing,â€ IEEE Transactions on Information Theory, vol. 56,
no. 2, pp. 653â€“666, 2010.
[119] C. Smith and L. Paninski, â€œComputing loss of efficiency in
optimal Bayesian decoders given noisy or incomplete spike
trains,â€ Network, vol. 24, no. 2, pp. 75â€“98, 2013.
[120] D. S. Greenberg, A. R. Houweling, and J. N. D. Kerr, â€œPopulation
imaging of ongoing neuronal activity in the visual cortex of
awake rats,â€ Nature Neuroscience, vol. 11, no. 7, pp. 749â€“751, 2008.
[121] J. T. Vogelstein, B. O. Watson, A. M. Packer, R. Yuste, B. Jedynak,
and L. Paninskik, â€œSpike inference from calcium imaging using
sequential Monte Carlo methods,â€ Biophysical Journal, vol. 97,
no. 2, pp. 636â€“655, 2009.
[122] J. T. Vogelstein, A. M. Packer, T. A. Machado et al., â€œFast nonneg-
ative deconvolution for spike train inference from population
calcium imaging,â€ Journal of Neurophysiology, vol. 104, no. 6, pp.
3691â€“3704, 2010.
[123] C. Andrieu, E. Barat, and A. Doucet, â€œBayesian deconvolution
of noisy filtered point processes,â€ IEEE Transactions on Signal
Processing, vol. 49, no. 1, pp. 134â€“146, 2001.
[124] J. OËœnativia, S. R. Schultz, and P. L. Dragotti, â€œA finite rate of inno-
vation algorithm for fast and accurate spike detection from two-
photon calcium imaging,â€ Journal of Neural Engineering, vol. 10,
Article ID 046017, 2013.
[125] J. W. Pillow, J. Shlens, L. Paninski et al., â€œSpatio-temporal corre-
lations and visual signalling in a complete neuronal population,â€
Nature, vol. 454, no. 7207, pp. 995â€“999, 2008.
[126] W. Truccolo, L. R. Hochberg, and J. P. Donoghue, â€œCollective
dynamics in human and monkey sensorimotor cortex: predict-
ing single neuron spikes,â€ Nature Neuroscience, vol. 13, no. 1, pp.
105â€“111, 2010.
[127] E. S. Chornoboy, L. P. Schramm, and A. F. Karr, â€œMaximum like-
lihood identification of neural point process systems,â€ Biological
Cybernetics, vol. 59, no. 4-5, pp. 265â€“275, 1988.
[128] M. Okatan, M. A. Wilson, and E. N. Brown, â€œAnalyzing func-
tional connectivity using a network likelihood model of ensem-
ble neural spiking activity,â€ Neural Computation, vol. 17, no. 9,
pp. 1927â€“1961, 2005.
[129] F. Rigat, M. de Gunst, and J. van Pelt, â€œBayesian modelling and
analysis of spatio-temporal neuronal networks,â€ Bayesian Anal-
ysis, vol. 1, no. 4, pp. 733â€“764, 2006.
[130] I. H. Stevenson, J. M. Rebesco, N. G. Hatsopoulos, Z. Haga, L.
E. Miller, and K. P. Kording, â€œBayesian inference of functional
connectivity and network structure from spikes,â€ IEEE Transac-
tions on Neural Systems and Rehabilitation Engineering, vol. 17,
no. 3, pp. 203â€“213, 2009.

Computational Intelligence and Neuroscience
17
[131] Z. Chen, D. F. Putrino, S. Ghosh, R. Barbieri, and E. N. Brown,
â€œStatistical inference for assessing functional connectivity of
neuronal ensembles with sparse spiking data,â€ IEEE Transac-
tions on Neural Systems and Rehabilitation Engineering, vol. 19,
no. 2, pp. 121â€“135, 2011.
[132] S. Eldawlatly, Y. Zhou, R. Jin, and K. G. Oweiss, â€œOn the use of
dynamic Bayesian networks in reconstructing functional neu-
ronal networks from spike train ensembles,â€ Neural Computa-
tion, vol. 22, no. 1, pp. 158â€“189, 2010.
[133] Y. Mishchenko, J. Vogelstein, and L. Paninski, â€œA Bayesian
approach for inferring neuronal connectivity from calcium
uorescent imaging data,â€ Annals of Applied Statistics, vol. 5, pp.
1229â€“1261, 2011.
[134] L. Martignon, G. Deco, K. Laskey, M. Diamond, W. Freiwald,
and E. Vaadia, â€œNeural coding: higher-order temporal patterns
in the neurostatistics of cell assemblies,â€ Neural Computation,
vol. 12, no. 11, pp. 2621â€“2653, 2000.
[135] H. Shimazaki, S. Amari, E. N. Brown, and S. Gruen, â€œState-
space analysis of time-varying higherorder spike correlation for
multiple neural spike train data,â€ PLoS Computational Biology,
vol. 8, no. 3, Article ID e1002385, 2012.
[136] B. M. Turner, B. U. Forstmann, E.-J. Wagenmakers, S. D. Brown,
P. B. Sederberg, and M. Steyvers, â€œA Bayesian framework for
simultaneously modeling neural and behavioral data,â€ Neu-
roImage, vol. 72, pp. 193â€“206, 2013.
[137] J. W. Pillow and P. Latham, â€œNeural characterization in partially
observed populations of spiking neurons,â€ in Advances in Neural
Information Processing Systems (NIPS), J. C. Platt, D. Koller, Y.
Singer, and S. Roweis, Eds., vol. 20, pp. 1161â€“1168, MIT Press,
Boston, Mass, USA, 2008.
[138] L. Li, I. M. Park, S. Seth, J. C. Sanchez, and J. C. PrÂ´Ä±ncipe,
â€œFunctional connectivity dynamics among cortical neurons: a
dependence analysis,â€ IEEE Transactions on Neural Systems and
Rehabilitation Engineering, vol. 20, no. 1, pp. 18â€“30, 2012.
[139] R. E. Kass, R. C. Kelly, and W.-L. Loh, â€œAssessment of synchrony
in multiple neural spike trains using loglinear point process
models,â€ The Annals of Applied Statistics, vol. 5, no. 2B, pp. 1262â€“
1292, 2011.
[140] S. Kim, D. Putrino, S. Ghosh, and E. N. Brown, â€œA Granger
causality measure for point process models of ensemble neural
spiking activity,â€ PLoS Computational Biology, vol. 7, no. 3,
Article ID e1001110, 2011.
[141] R. Vicente, M. Wibral, M. Lindner, and G. Pipa, â€œTransfer
entropy-a model-free measure of effective connectivity for the
neurosciences,â€ Journal of Computational Neuroscience, vol. 30,
no. 1, pp. 45â€“67, 2011.
[142] P. Berkes, F. Woood, and J. Pillow, â€œCharacterizing neural
dependencies with copula models,â€ in Advances in Neural Infor-
mation Processing Systems (NIPS), J. C. Platt, D. Koller, Y. Singer,
and S. Roweis, Eds., vol. 20, MIT Press, Boston, Mass, USA,
2008.
[143] M. S. Smith, â€œBayesian approaches to copula modelling,â€ in
Bayesian Theory and Applications, P. Damien, P. Dellaportas, N.
Polson, and D. Stephens, Eds., Oxford University Press, New
York, NY, USA, 2013.
[144] B. M. Yu, J. P. Cunningham, G. Santhanam, S. I. Ryu, K. V.
Shenoy, and M. Sahani, â€œGaussian-process factor analysis
for low-dimensional single-trial analysis of neural population
activity,â€ Journal of Neurophysiology, vol. 102, no. 1, pp. 614â€“635,
2009.
[145] Z. Chen, F. Kloosterman, E. N. Brown, and M. A. Wilson,
â€œUncovering spatial topology represented by rat hippocampal
population neuronal codes,â€ Journal of Computational Neuro-
science, vol. 33, no. 2, pp. 227â€“255, 2012.
[146] Z. Chen, S. N. Gomperts, J. Yamamoto, and W. A. Wilson,
â€œNeural representation of spatial topology in the rodent hip-
pocampus,â€ Neural Computation, vol. 26, no. 1, pp. 1â€“39, 2014.
[147] Z. Chen and M. A. Wilson, â€œA variational nonparametric
Bayesian approach for inferring rat hippocampal population
codes,â€ in Proceedings of the 35th Annual International Confer-
ence of the IEEE Engineering in Medicine and Biology (EMBC
â€™13), pp. 7092â€“7095, 2013.
[148] K. Famm, B. Litt, K. J. Tracey, E. S. Boyden, and M. Slaoui, â€œA
jump-start for electroceuticals,â€ Nature, vol. 496, pp. 159â€“161,
2013.

