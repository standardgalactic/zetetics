MIRAI: Evaluating LLM Agents for Event Forecasting
Chenchen Yeâˆ—1, Ziniu Huâˆ—2, Yihe Dengâˆ—1, Zijie Huang1,
Mingyu Derek Ma1, Yanqiao Zhu1, Wei Wang1
1University of California, Los Angeles
2California Institute of Technology
https://mirai-llm.github.io/
Abstract
Recent advancements in Large Language Models (LLMs) have empowered LLM
agents to autonomously collect world information, over which to conduct reasoning
to solve complex problems. Given this capability, increasing interests have been
put into employing LLM agents for predicting international events, which can
influence decision-making and shape policy development on an international scale.
Despite such a growing interest, there is a lack of a rigorous benchmark of LLM
agentsâ€™ forecasting capability and reliability. To address this gap, we introduce
MIRAI, a novel benchmark designed to systematically evaluate LLM agents as
temporal forecasters in the context of international events. Our benchmark features
an agentic environment with tools for accessing an extensive database of historical,
structured events and textual news articles. We refine the GDELT1 event database
with careful cleaning and parsing to curate a series of relational prediction tasks with
varying forecasting horizons, assessing LLM agentsâ€™ abilities from short-term to
long-term forecasting. We further implement APIs to enable LLM agents to utilize
different tools via a code-based interface. In summary, MIRAI comprehensively
evaluates the agentsâ€™ capabilities in three dimensions: 1) autonomously source
and integrate critical information from large global databases; 2) write codes
using domain-specific APIs and libraries for tool-use; and 3) jointly reason over
historical knowledge from diverse formats and time to accurately predict future
events. Through comprehensive benchmarking, we aim to establish a reliable
framework for assessing the capabilities of LLM agents in forecasting international
events, thereby contributing to the development of more accurate and trustworthy
models for international relation analysis.2
1
Introduction
Accurate forecasting of international events is crucial [1], as understanding the evolution of geopo-
litical developments enables stakeholders to make informed decisions, mitigate risks, and seize
opportunities in the interconnected world. Traditionally, researchers in international relations rely
on domain expertise [2, 3]. They conduct detailed analyses of the complex interplay among nations,
considering alliances, trade agreements, ideological affinities, and historical rivalries to forecast
events such as conflicts, collaborations, or alliance shifts [4]. With the rapid development of deep
learning techniques, forecasting through data-driven neural networks becomes an attractive alterna-
tive. Despite their success, current methods rely on single types of informationâ€”either structured
knowledge graphs [5â€“7] or textual datasets [8, 9]. Knowledge graphs, although organized, can
suffer from incompleteness [10] or bias [11], while textual analyses may lack the necessary factual
grounding for precise predictions. Moreover, these models are unable to ground their reasoning to
âˆ—Equal Contribution.
1GDELT: https://www.gdeltproject.org/
2Our dataset is available on Google Drive, the code can be found on GitHub, and an interactive demo is provided
through a Google Colab notebook.
Preprint. Under review.
arXiv:2407.01231v1  [cs.CL]  1 Jul 2024

036 Express intent to meet 
or negotiate
172 Impose administrative 
sanctions
(2023-11-18,
AUS, ?, CHN)
042 Make a visit
050 Engage in diplomatic 
cooperation
2023-11-1
2023-11-3
2023-11-4
2023-11-7
2023-11-18
News 1: Albanese first 
Australian leader to visit 
China in 7 years
News 2: China, Australia 
agree to ease tensions
Related news
2023-11-17
News 3: Anthony 
Albanese to meet with 
Japanese counterpart
News 4: Australia 
accuses China of injuring 
navy divers with sonar
110 Disapprove; 112 Accuse
042 Make a visit
050 Engage in diplomatic 
cooperation
Relations
Query
Ground truths
LLM predictions
Figure 1: An example of forecasting the relations between Australia and China on Nov.18.2023. The
database contains query-related historical relations and news articles, while the agent fails to predict
the change of relation and makes a wrong forecast.
historical evidence, which compromises the interpretability and validation of their forecasts. These
limitations raise concerns about AI forecastersâ€™ reliability, particularly for high-stake scenarios [12].
Large Language Model (LLM) agents present a promising path for overcoming these challenges [13â€“
17]. These advanced AI systems exhibit the potential to mimic human experts by utilizing a diverse
array of tools to automatically gather and process information from various sources, including text,
knowledge graphs, and numerical data [18â€“21]. Trained on extensive textual data, LLMs [22â€“25] are
capable of grasping the subtleties of international relations, reasoning through complex relationships
with linguistic explanations, and planning their tool usage effectively [26â€“29]. Such capability opens
up new possibilities for developing transparent and interpretable forecasting models that can be
further scrutinized and refined.
Despite the immense potential of LLM agents for event forecasting, there is a lack of standardized
benchmarks to assess their forecasting abilities in the realm of intricate international events. To
address this gap, we introduce MIRAI (Multi-Information FoRecasting Agent Interface), a novel
benchmarking environment designed to rigorously assess and advance the capabilities of LLM agents
for international event forecasting over time. MIRAI adapts real-world international event data derived
from the Global Database of Events, Language, and Tone (GDELT) [30] to an event-forecasting
task format across different horizons, providing a robust assessment of LLM performance. The
frameworkâ€™s agentic environment enables LLMs to interact with both relational and textual databases
through Application Programming Interfaces (APIs), facilitating autonomous information gathering,
processing, and application in a contextually relevant manner.
We evaluate both open and closed sourced LLMs on MIRAI with ReAct-Style [31] Agents and
â€œSingle Functionâ€ and â€œCode Blockâ€ action types. Our extensive experiments revealed: 1) Temporal
forecasting tasks are challenging for LLM agents, with the highest-performing GPT-4o agent using
full suite of APIs achieves a 29.6 F1 score in second-level relation prediction tasks; while tasks
involving long-term and fine-grained event forecasting are even more challenging; 2) The â€œCode
Blockâ€ tool-use strategy, which allows more flexible interactions, demands robust code generation
capabilities. Notably, GPT-4o is the only model that effectively utilizes and benefits from this strategy.
These findings emphasize the need for ongoing research into temporal reasoning and the effective use
of tools by LLM agents. We expect that MIRAI could serve as a standard benchmark for evaluating
LLMs in event forecasting. This would support the development of more precise and reliable models
for political analysis, enhancing our understanding of global dynamics.
2
The MIRAI Benchmark
In this section, we introduce MIRAI benchmark from: the specifics of the data and tasks (Sec. 2.1),
the implemented agents and environments (Sec. 2.2), and the database construction details (Sec. 2.3).
2.1
Data and Tasks
We introduce MIRAI, a benchmark crafted for evaluating LLM agents for temporal forecasting in the
realm of international events, with tool-use and complex reasoning. We consider forecasting as the
process of collecting essential historical data and performing temporal reasoning to anticipate the
outcomes of future events.
Formally, we represent an event as et = (t, s, r, o), where t is the timestamp3, s, o âˆˆC are respectively
the subject and object countries4 from the country pool C, and r âˆˆR denotes the relation type
3Each timestamp uniquely represents a day, formatted in "YYYY-MM-DD".
4In this paper, the term "country" includes all countries, dependent territories, special geographic areas, and their
subdivisions. We use the standardized ISO-3166 Alpha-3 codes for country names, such as "AUS" for Australia
and "CHN" for China, to maintain global consistency.
2


















































: 



	



Â
ÂÂ
Â
Â
ÂÂ

ÂÂ

ÂÂ Â­
Â
Â

ÂÂ€
Â
ÂÂ‚
ÂÂƒ
Â

ÂÂ
ÂÂ
ÂÂÂ
ÂÂ
ÂÂ
Â
Â
ÂÂ
ÂÂ
ÂÂƒ
ÂÂƒÂ
ÂÂƒ
ÂÂ
Â
ÂÂ
ÂÂ
ÂÂ
Â

Â

Âƒ


Â


Â
Â
Â
Â
ÂÂ
ÂÂ
Â
Binary
Quadratic






























Event Root Code
(1st CAMEO layer)
Event Base Code
(2nd CAMEO layer)



		
Figure 2: MIRAI comprehensively covers global event data. (a) The circular chart shows the relation
hierarchy and distribution in MIRAI. (b) The heatmap visualizes the intensity of these events globally,
distinguishing between areas of conflict (red) and mediation (blue). (c) The heatmap illustrates the
frequency of these events, highlighting regions with the most occurrences.
defined by the Conflict and Mediation Event Observations (CAMEO) ontology [32]5. As shown
in Figure 2a, we incorporate two hierarchical levels from the CAMEO ontology to facilitate a
detailed and comprehensive analysis of geopolitical dynamics. The first level includes 20 broad
categories, represented by a two-digit code (e.g., â€œ01: Public Statementâ€ or â€œ04: Consultâ€),
which are subdivided into second-level categories identified by a three-digit code that corresponds to
its parent category. For example, â€œ03: Express intent to cooperateâ€ is a first-level category
that includes 10 different second-level relations such as â€œ036: Express intent to meet or
negotiateâ€. Subsequently, the quadruple â€œ(2023-11-03, AUS, 036, CHN)â€ denotes that on 3
November 2023, the Australian leader announces a planned visit to China. These relations are also
organized along two dimensions, from Verbal to Material and from Conflict to Cooperation,
to form a quadratic categorization in the inner circle of Figure 2a.
Furthermore, a collection of events that happened at the same timestamp t form a timestamped event
set Et = {et
1, ..., et
M}, where M is the number of unique events at time t. These events {Et}T
t=1 can
therefore be organized into a temporal graph, with countries as nodes and eventsâ€™ relations as edges.
The task of event forecasting (t + l, s, ?, o) is to predict all the events between a pair of countries s
and o, happening l days in the future from the current time t. Formally, given historical events up to
the current time Eâ‰¤t, our goal is to forecast future relationships Et+l
s,o between a pair of countries.
This includes utilizing events involving third parties, such as interactions with their mutual neighbors.
In the example of Figure 1, we demonstrate how to predict which actions Australia will adopt towards
China on 18 November 2023 based on all available information up to 17 November 2023. This can
also be formatted as a structured query â€œ(2023-11-17 + [1 day], AUS, ?, CHN)â€, where the temporal
distance of the forecasted event is one day. From the historical events, we can see that the two
countries last long-standing tensions; though news show the leader of Australia visited China and
agreed to ease tension, this signal does not change the overall tendency, and their relationship keeps
being Disapprove and Accuse on certain focuses. Thus, the agent over-relying short-term news
and eventually gives the wrong prediction diplomatic cooperation.
2.2
Agents and Environments
Similar to human political analysts, LLM agents must leverage a variety of information sources to
make reliable predictions. To this end, we abstract the environment by incorporating coding APIs
that facilitate interactions with various knowledge sources. Within this environment, we can develop
an LLM agent that employs these APIs through the ReAct strategy [33], characterized by the iterative
steps of think, act, and observe. This structured approach allows the agent to analyze the current
situation, retrieve additional data, and observe outcomes to make reliable forecasting.
APIs. We provide a comprehensive set of API to the LLM agent, enabling the execution of the
generated codes to access a rich database of historical events and news articles. The API contains the
5CAMEO is a well-established ontology for categorizing international political events, meticulously developed
by experts to enable detailed analysis across multiple levels of granularity.
3

LLM Agent



	
	



	Â
(1) Think
ÂÂ:
:
Â
ÂÂÂ Â­Â€
Â
Â
Â‚ÂƒÂ„


	Â
Â
Â…Â†
Â‡
Â


	



from collections import 
Counter 
relation_codes = [event.re-
lation.code for event in 
events]

get_relation_distribution(
  head_entities=[ISO-
  Code("AUS")], 
  tail_entities=[ISO-
  Code("CHN")]
)
{11: [110 - Disapprove, not 
specified, 112 - Accuse]}

def get_relation_distribution
(head_entities, tail_entities): 
    curr_data = data_kg.copy() 
    curr_data.drop_duplicates(â€¦)
    â€¦ 
    return relation_counts
Memory




	






Â
ÂÂ
class Date: 
  """Represents a date."""   
def get_relation_distribu-
tion(head_entities, tail_en-
tities) -> Dict[CAMEOCode, 
int]: 
     """Gets distribution of 
  relations."""
Answer?

# Below is the event distribution between AUS and CHN 
before 2023-11-18
CAMEOCode(code='042'): 45,  CAMEOCode(code='036'): 37, 
CAMEOCode(code='040'): 23, CAMEOCode(code='061'): 17, 


	
ÂÂÂÂ
(3) Execute
(2) Act

Figure 3: Overview of the LLM agentâ€™s interaction with the multi-source environment using the
ReAct strategy for forecasting a query event. The framework consists of three main steps: (1) Think:
The agent analyzes the current status and plans the next action based on the query and the provided
API specifications. (2) Act: The agent generates a â€œSingle Functionâ€ call or a â€œCode Blockâ€ to
retrieve and analyze relevant data from the database. (3) Execute: The Python interpreter runs the
generated code with the API implementation and database and produces observations. These steps
are iteratively performed until the agent reaches a final forecast for the future relation.
essential data classes and a suite of functions designed to accommodate various types of information
within the database. Data classes range from unary types such as date, country, and relation, to
composite types like date range, event, and news articles. Functions, executable via standard Python
syntax, allow the agent to efficiently query the database through code interface. The design of these
functions is characterized in two aspects:
â€¢ Information types. These functions cover various types of information, including country and
relation code-name mapping and hierarchy, and count, listing, and distribution of events and news
articles. For example, the function map_relation_description_to_cameo takes a relation
description and returns a list of the five most likely relations with their respective CAMEO codes,
names, and descriptions, providing precise relation information as needed.
â€¢ Search conditions. Additionally, the API functions related to events and news articles include
various optional parameters that enable tailored searches based on different criteria. For in-
stance, the function get_event enables searches by specifying conditions like date_range,
head_entities, tail_entities, relations, and text_description to fetch events that
meet these conditions from the database.
The API specifications and full implementations are shown in Appendix M.
Interaction with environment. In MIRAI, agents are given the API specifications, which include
meticulously documented Python docstrings for all data classes and function definitions, abstracting
the underlying implementation details. The environment is equipped with a Python code sandbox
with full access to APIs and databases. The agent uses the ReAct strategy in an iterative manner,
alternating between think, act, and observe to gather information and perform forecasting. The
pipeline is illustrated in Figure 3.
1. Think. Specifically, the agent first thinks about the current situation. If it is confident to deliver a
final forecast based on the current information and analysis, it provides the answer and stops the
iteration. Otherwise, it further analyzes the current status and plans subsequent actions. In the first
step shown in Figure 3, the agent plans to first retrieve recent events directly involving the two
countries and later verify the details by checking related news articles.
2. Act. Next, the agent acts by generating executable codes to interact with the environment. There
are two types of action: â€œSingle Functionâ€ or â€œCode Blockâ€. A â€œSingle Functionâ€ facilitates
straightforward data retrieval, whereas a â€œCode Blockâ€ supports a more flexible and larger action
space, accommodating complex control flows such as loops and conditional statements. Also,
the agent is allowed to use functions defined in the API and can additionally utilize safe, well-
4

established Python libraries such as numpy, networkx, and scikit-learn. As shown in Figure 3,
the agent can write either a â€œCode Blockâ€ with an imported library and an inline loop, or a â€œSingle
Functionâ€ call with targeted countries as the argument value.
3. Observe. The environment receives the code generated by the agent, executing it internally using
a Python interpreter with full access to API implementations and the database. The output from
this execution is then passed to the agent as the content of its â€˜Observationâ€™ step. In particular, the
agent can observe the corresponding output if its generated code executes successfully; otherwise,
it can only observe a specified error message along with the error type. In the figure, the written
code is executed, and results are sent back to the agent memory to proceed next iteration.
These â€˜Thoughtâ€™, â€˜Actionâ€™, and â€˜Observationâ€™ from the previous iterations are stored in the agentâ€™s
memory base and used as the context of the agent in the next iteration. Additionally, the variables
defined in the code generated in any previous action steps are stored and available for future actions.
Examples are shown in Appendix L.
2.3
Database Construction
Pre-processing. We construct a GDELT-based environment to enable agentsâ€™ interaction with both
knowledge graph and textual information. Initially, we filtered the dataset for events occurring
between Jan. 1, 2023, and Nov. 30, 2023, aligning event dates with their respective news publish
dates to avoid information leakage. We standardize the CountryCode to ISO-3166 norms and exclude
any entries with missing or outdated codes, and standardize Event codes to the second level of the
CAMEO ontology to ensure a consistent and detailed representation. Third-level event codes, which
are more noisy and contain more extraction errors were excluded. We also only consider international
events. For the news articles, credibility was assessed by counting the daily mentions of each event,
with a threshold of at least 50 mentions to filter out unreliable sources. News content, including
titles and body text, was then downloaded and cleaned following the OBELICS [34] protocol, which
involved removing low-quality text based on word counts, character and word repetition ratios,
and the presence of special characters and flagged words, thereby significantly reducing noise and
enhancing the reliability of the textual information stored in our database. We list the details for
dataset construction in Appendix F. We finalized a collection of 991,759 GDELT event records,
corresponding to 59,161 unique (t, s, r, o) events and 296,630 unique news articles. We display our
curated events over the world map in Figure 2b and 2c, illustrating global coverage and varying
intensities of conflict and mediation across regions.
Test query set construction. We construct the test data using records from November 2023,
comprising 152,500 GDELT event records and 7385 unique events. To further ensure the data quality
and minimize potential extraction errors inherent in GDELT records, we set a higher threshold of
at least 100 daily mentions and 5 downloaded news articles for each event. This stricter filtering
results in a collection of 2,136 unique (t, s, r, o) events. We construct the test query set based on
this collection, which leads to 705 (t, s, ?, o) query and answer, where each answer includes a list of
relations occurring between the specified subject and object country at time t in this collection. Note
that this stricter filtering is only applied for the test query construction and will not remove data from
the database. Additionally, we sample 100 queries from the test query set to form a test query subset,
ensuring a balanced representation of dates throughout the month, countries across continents, and
relations spanning the first-level CAMEO code types.
Evaluation metrics. We instruct the agent to generate final forecasting answer in a JSON dictionary,
where keys are predicted two-digit first-level CAMEO codes and the values are lists of predicted
three-digit second-level CAMEO codes inherited from the keys. For example, the JSON dictio-
nary â€œ{"01": ["011", "012"], "02": ["023"]}â€ indicates the first level relation predictions for "01:
Make public statement" and "02: Appeal", along with second level relation predictions "011:
Decline comment", "012: Make pessimistic comment", and "023: Appeal for material
aid". We evaluate these relation predictions by calculating precision, recall, and F1 score between
the predicted and ground-truth lists. Moreover, we map the predicted and ground truth relations
to their respective binary and quadratic classes (as shown in Figure 2a). Since each relation in
the ground-truth list may belong to different classes, we employ the empirical Kullback-Leibler
(KL) divergence of predictions to the ground truth: DKL(P||Q) = P
i P(i) log

P (i)
Q(i)

to measure
the discrepancy, where P and Q represent the frequencies of ground-truth and predicted relations
respectively. A lower KL divergence indicates a better alignment of the modelâ€™s predictions with the
ground-truth list.
5

Table 1: Experimental results on the test set with different agent tools and the tool-use strategies. The
best-performing score is highlighted in bold and the second-best is underlined.
Agent
Tool-Use
Binary
KL (â‡“)
Quad
KL (â‡“)
First-level Relation (%)
Second-level Relation (%)
Action Type
API
Pre. (â‡‘)
Rec. (â‡‘)
F1 (â‡‘)
Pre. (â‡‘)
Rec. (â‡‘)
F1 (â‡‘)
Direct IO
â€”
â€”
6.5Â±1.7
15.9Â±1.5
27.6Â±8.1
19.7Â±5.9
18.8Â±6.9
6.6Â±1.5
5.1Â±0.4
3.5Â±0.8
ZS-COT
â€”
â€”
6.9Â±0.8
10.1Â±0.8
27.6Â±4.0
36.0Â±4.5
26.7Â±4.1
10.2Â±1.4
17.4Â±1.1
10.5Â±0.7
ReAct
Single Function
Event-Only
33.5Â±0.7
6.7Â±0.7
44.3Â±3.9
54.2Â±3.9
41.4Â±1.7
25.3Â±2.6
47.4Â±2.4
26.9Â±1.9
Single Function
News-Only
6.1Â±1.0
12.8Â±0.6
27.8Â±3.1
25.9Â±2.9
21.8Â±2.3
6.3Â±2.2
9.0Â±2.0
5.4Â±1.3
ReAct
Single Function
All
3.1Â±0.5
5.9Â±1.0
47.6Â±5.8
58.3Â±2.6
44.2Â±4.0
28.7Â±3.9
51.0Â±4.0
29.6Â±3.7
Code Block
All
5.1Â±0.9
8.9Â±0.5
27.1Â±4.0
38.6Â±2.5
25.9Â±2.2
11.6Â±2.4
26.3Â±2.0
12.6Â±1.7
3
Experiments
Our experiment section begins with comparing the forecasting performance of different agent
methods with different prediction horizons (Sec.3.1). Moreover, we evaluate agents with different
base language models (Sec.3.2), and finally analyze several key aspects (Sec.3.3) to understand
agentsâ€™ behavior.
3.1
Evaluate Forecasting with Different Agent Methods and Tools
We investigate the effect of different tools (APIs) and agent tool-use strategies. We use gpt-3.5-
turbo-0125 [35] as the base model and evaluate on the 705 queries in the test set. For all experiments,
we set the model temperature to 0.4 and run 5 times to calculate the mean and standard deviation. We
provide the detailed prompts in Appendix K.
For agent implementations, we consider the following two methods without tool-use:
Direct IO represents the standard LLM chatbot approach that provides answers without tool-use or
explicit reasoning. This serves as a baseline to reflect the internal world knowledge of the LLMs
when forecasting.
Zero-Shot Chain-of-Thought (ZS-CoT) [36, 37]: In the ZS-CoT variant, we add an instruction
prompt to the LLM to encourage explicit step-by-step thinking before making the final prediction.
For Tool-Use agents, We follow ReAct [31] to interact with our provided environments through an
iterative process of thinking, acting, and observing. We implement two variants of ReAct for tool-use:
1) â€œSingle Functionâ€ and 2) â€œCode Blockâ€. Details are discussed in Sec. 2.2.
ReAct agents can utilize tools. We thus implement different variants by restricting their access to
utilize 1) News-Only APIs; 2) Event-Only APIs; 3) All data classes and functions.
The experimental results in Table 1 reveal several key insights into agent performance:
1) MIRAI presents a challenging task for LLM agents. The best agent (ReAct with â€œSingle
Functionâ€ using all APIs) for second-level relation predictions achieves a precision of 28.7 and an F1
score of 29.6. These results underscore the complexity and difficulty of the temporal forecasting tasks
in MIRAI and highlight the substantial room for improvement in LLM agents for event forecasting.
2) Predicting fine-grained relations proves more difficult. All models exhibit higher KL divergence
for quadratic than binary classes, and lower F1 scores for second-level predictions compared to first-
level ones. These findings confirm that predicting fine-grained relation types is more challenging.
3) Diverse tool-use is critical for temporal forecasting. ZS-CoT and Direct-IO, which rely solely on
the internal world knowledge of LLMs for forecasting without tool-use, significantly underperform
the ReAct agent with full API access to the database. This emphasizes the importance of basing
forecasting and reasoning on retrieved historical data and knowledge. In terms of tool types, ReAct
agents using News-Only APIs perform much worse than agents with Event-Only APIs. While news
articles provide detailed context for events, they can also introduce noise and lead to issues such as
excessively long context, posing additional challenges for LLM agents. Moreover, the agents using
both types of information achieve the optimal results.
3.2
Evaluate Forecasting with Different Base LLMs
We then investigate the role of the underlying LLMs in the agentâ€™s performance. We evaluate
both open-sourced LLM Mistral-7B-Instruct-v0.2 [38] (run on a single NVIDIA RTX A6000
GPU), as well as close-sourced LLMs including gpt-3.5-turbo-0125 [35], gpt-4-turbo-2024-
04-09 [22], and the recently released gpt-4o-2024-05-13 [39]. Comparisons are done on a data-
balanced test subset comprising 100 queries, with all models evaluated under the ReAct framework,
allowing access to all APIs. The action types can be either â€œSingle Functionâ€ or â€œCode Blockâ€ with
a maximum tool call limit set to 20 steps. All models use the same prompt content and structure
6

Table 2: Experimental results on the test subset using different base LLMs and action types. The
best-performing score is highlighted in bold and the second-best is underlined.
Model
Training Data
Cutoff Date
Action Type
Binary
KL (â‡“)
Quad
KL (â‡“)
First-level Relation (%)
Second-level Relation (%)
Pre. (â‡‘)
Rec. (â‡‘)
F1 (â‡‘)
Pre. (â‡‘)
Rec. (â‡‘)
F1 (â‡‘)
Mistral-7B
â€”
Single Function
9.6Â±2.4
14.1Â±1.9
27.2Â±8.2
13.1Â±3.6
14.4Â±3.2
14.1Â±4.4
7.0Â±2.2
6.6Â±2.3
Code Block
9.0Â±3.0
13.1Â±2.3
25.8Â±6.9
10.4Â±4.8
11.1Â±3.8
10.0Â±3.8
5.8Â±4.1
4.6Â±1.1
gpt-3.5-turbo
2021-09
Single Function
3.9Â±1.0
6.7Â±1.7
52.6Â±9.3
46.8Â±8.5
38.2Â±4.9
36.7Â±9.2
41.7Â±7.6
27.9Â±3.6
Code Block
3.6Â±0.7
8.0Â±1.7
32.8Â±4.7
41.0Â±2.0
29.7Â±2.9
14.4Â±5.0
33.7Â±5.3
14.4Â±2.6
gpt-4-turbo
2023-12
Single Function
2.4Â±0.6
6.1Â±0.8
55.0Â±7.5
43.9Â±7.8
39.8Â±4.9
33.5Â±7.5
43.5Â±5.4
30.0Â±1.9
Code Block
2.0Â±1.1
6.0Â±2.0
46.4Â±8.7
51.7Â±10.0
40.0Â±8.7
32.7Â±4.9
43.2Â±9.5
28.7Â±5.0
gpt-4o
2023-10
Single Function
1.8Â±1.0
4.4Â±1.8
48.7Â±8.7
63.7Â±8.8
45.5Â±4.6
31.2Â±6.7
59.2Â±7.3
32.6Â±2.7
Code Block
1.6Â±1.1
4.3Â±1.9
42.3Â±9.4
64.5Â±9.5
44.1Â±8.1
29.1Â±7.3
59.6Â±7.6
32.8Â±6.4
1
2
3
4
5
6
7
8
9
10
K (number of times to make the prediction)
0
5
10
15
20
25
30
35
Second Level relation F1
6.6
15.0
19.7
22.8
24.9
25.8
28.3
29.8
31.5
33.9
2.5
6.1
9.7
12.3
13.5
14.7
16.0
17.6
19.2
27.9
30.0
32.6
Mistral F1 (Max@K)
Mistral Self-Consistency
GPT-3.5
GPT-4-turbo
GPT-4o
Verbal
Cooperation
Material
Cooperation
Verbal
Conflict
Material
Conflict
0
10
20
30
40
50
60
70
First Level F1 Score
32.4
4.8
7.1
16.2
43.0
17.4
24.2
58.3
41.4
16.5
19.1
64.8
55.6
31.3
29.2
65.1
Mistral
GPT-3.5
GPT-4 Turbo
GPT-4o
Figure 4: a) Self-consistency of Mistral-7B model increases with more samples. b) F1 scores of
different base LLM agents on relation prediction, categorized based on the quadratic classes.
shown in Appendix K. The experimental results are presented in Table 2, and a further analysis of the
agentâ€™s final status is provided in Appendix J.1. We observe the following findings:
1) Code Block benefits stronger LLMs but hurts weaker models: The â€œCode Blockâ€ action
type provides greater flexibility than the â€œSingle Functionâ€. However, its benefits are not uniformly
achieved across all models. Mistral-7B and gpt-3.5-turbo show reduced performance with
Code Block, while stronger models like gpt-4-turbo and gpt-4o gains improvements from it.
This indicates that the ability to generate coherent and practical long Code Blocks is a distinguishing
factor that determines LLMs as reliable forecasting agents.
2) GPT-4o consistently outperforms other models: gpt-4o, the most recent LLM, consistently
achieves the highest performance across different metrics. Notably, for second-level relation pre-
diction, gpt-4o achieves F1 scores of 32.6 and 32.8 using â€œSingle Functionâ€ and â€œCode Blockâ€,
surpassing all other models including gpt-4-turbo-2024-04-09. This indicates that MIRAI is
hard enough, and can effectively distinguish different LLMsâ€™ advanced reasoning capabilities.
Can self-consistency make a small model stronger? It is evident that stronger LLMs have better
agent performance; however, can we enhance a weaker LLM to achieve comparable forecasting
performance using inference-time computation? To explore this, we take Mistral-7B as the base
LLM with ReAct using the â€œSingle Functionâ€ strategy. For each query, we perform multiple sampling
at a temperature of 0.4. We then consider a variant of self-consistency, which only keeps entries
appearing more than twice. We also calculate F1 (Max@K), which assesses the F1 score for each
instance and keeps the maximum score across all rounds. As shown in Figure 4a, with more samples,
the performance of Mistral-7B significantly improves. Initially, a single sample achieves an F1
score of 6.6 for Mistral-7B, which is considerably lower than the scores achieved by larger models.
However, as more solutions being sampled, the F1 (Max@K) and self-consistency of Mistral-7B
improve progressively. By the 10th samples, the Max@K reaches 33.9, even surpassing gpt-4o.
This result highlights the potential of the inference-time search methods like self-consistency to push
the boundaries of smaller language models in event forecasting.
Code execution error analysis. Our implemented agents interact with tools via code but often
encounter execution error. We summarize the error types for different LLMs in Figure 5b. We can
see that invalid dates and invalid attributes are the two most frequent errors, with even gpt-4-turbo
exhibiting a frequency of such errors. Notably, gpt-4o makes significantly fewer execution errors.
This enhanced code generation capability contributes to its superior performance for event forecasting.
7

0.0
0.2
0.4
0.6
First-Level F1
browse_news_article
get_relation_distribution
get_news_articles
get_parent_relation
get_events
map_cameo_to_relation
get_sibling_relations
get_entity_distribution
get_child_relations
0.0
0.2
0.4
Second-Level F1
Invalid date
Python syntax error
Invalid argument
Invalid attribute
Undefined variable
0
10
20
30
Count
11
18
12
32
4
23
11
1
11
6
20
0
2
19
6
5
1
1
0
1
Mistral
GPT-3.5
GPT-4 Turbo
GPT-4o
Figure 5: a) F1 Accuracy for each API function. b) Code execution error analysis for different LLMs.
0
20
40
60
80
Temporal Distance (days)
15
20
25
30
35
40
45
F1 Score
44.2
1d
41.0
7d
39.6
30d
36.6
90d
29.6
1d
26.1
7d
25.1
30d
22.7
90d
1st level
2nd level
0
20
40
60
80
Temporal Distance (days)
3
4
5
6
7
8
9
KL Divergence
3.1
3.8
4.0
4.3
5.9
7.1
7.0
8.3
Binary
Quad
Figure 6: Evaluation of LLM Agents in different temporal distances of the forecasting event.
get_relation
_distribution
browse_news_article
answer
get_news
_articles
get_parent_relation
map_cameo_to_relation
get_sibling
_relations
get_events
start
get_relation
_distribution
get_parent
_relation
get_sibling_relations
get_events
get_relation
_distribution
map_cameo
_to_relation
get_news
_articles
answer
get_child
_relations
browse_news_article
get_entity
_distribution
Figure 7: Action order analysis in LLM agents. a) Tool-Use Transition Graph of called API functions.
Edge thickness indicates transition frequency. b) Freq.(correct) - Freq.(incorrect), in which red (blue)
edges indicate positive (negative) contributions.
3.3
Analyzing Agent Behaviours
Impact of temporal distance of the forecasting target. Our defined event forecasting task varies by
temporal distance l, which specifies how far into the future we want to predict. We thus conduct an
ablation study with l set to 1, 7, 30, and 90 days. Specifically, we fix the query event date and limit the
accessible data to l days prior to the query event date. The experimental results depicted in Figure 6
reveal a clear trend: as the temporal distance increases, the F1 score decreases and KL-divergence
increases. This indicates that the agentâ€™s ability to provide accurate predictions diminishes for events
further in the future. When the temporal distance is small, such as 1 or 7 days, the agent has access to
more recent and relevant information, providing a strong signal (e.g., human expertsâ€™ analysis) for
making accurate predictions. Thus, to comprehensively benchmark the forecasting capabilities of
LLM agents, we should focus on long-term predictions such as those spanning 30 or 90 days. These
longer durations require the agents to capture and anticipate potential trend shifts, which may be
influenced by a broader range of factors and more complex dependencies.
Forecasting accuracy on different relation types. We further split the datasets into distinct quadratic
relation classes and compute the F1 score for each class, as illustrated in Figure 4b. The results
show that all models exhibit significantly higher performance for â€œverbal cooperationâ€ and â€œmaterial
conflictâ€, while lower in the other two categories. Several factors contribute to these observations.
First, â€œverbal cooperationâ€ events are more prevalent in the dataset, allowing the model to retrieve
more such historical events. Second, â€œmaterial conflictsâ€ has a consistent pattern of extended duration
within the same set of countries. Conversely, events categorized under â€œmaterial cooperationâ€ and
8

Table 3: Comparison of MIRAI with other temporal reasoning benchmarks. â€œMethodâ€ refers to the
methodology of original and recent models evaluated on the benchmark. ICL stands for LLM w/
In-Context Learning, FT stands for Task-Specific Fine-Tuning.
Benchmark
Temporal Reasoning
Task Format
Information
Method
Understanding
Forecasting
Time Series
KG
Textual
API
TempQuestions [40]
âœ“
KGQA
âœ“
KGQA Systems
CRONQuestions [41]
âœ“
KGQA
âœ“
Bert-based FT
TempoQR [42]
âœ“
KGQA
âœ“
Bert-based FT
TORQUE [43]
âœ“
QA
âœ“
Bert-based FT
TempReason [44]
âœ“
QA
âœ“
âœ“
ICL + Task-specific FT
TRAM [45]
âœ“
MCQ
âœ“
ICL + Bert-based FT
TCELongBench [46]
âœ“
âœ“
Ordering QA; MCQ
âœ“
ICL
ForecastQA [47]
âœ“
MCQ
âœ“
Bert-based FT
Approach [48]
âœ“
QA
âœ“
ICL
IntervalQA [8]
âœ“
Numerical QA; MCQ
âœ“
âœ“
ICL
TKGs [49, 30]
âœ“
Link Prediction
âœ“
Graph FT + ICL + Task-specific FT
MIRAI
âœ“
Relation List
âœ“
âœ“
âœ“
LLM Agent
â€œverbal conflictsâ€, such as â€œ057: Sign formal agreementâ€ and â€œ084: Return or releaseâ€,
tend to be more abrupt and unpredictable, demanding subtle trend analysis and contextual knowledge,
leading to lower performance in these categories. These observations highlight the need for LLMs
capable of understanding the nuances and complexities of different event types.
How tool-use ordering influences forecasting. We further investigate the impact of action order on
the GPT-4o agent in â€œSingle Functionâ€ mode. Figure 7 shows the transition graph from the initial
query to the correct final answer, with thicker edges indicating more frequent transitions. Typically,
the agent begins with get_relation_distribution or get_event to gather an initial set of
recent and frequent events for key information, and often concludes with browse_news_article
and get_news_articles, which retrieve news content to make accurate forecasts. To further
understand whether each function helps forecasting, we subtract the frequency of incorrect predictions
from those of correct predictions, as shown in Figure 7b. Here, red edges represent sequences
typically leading to accurate outcomes, and blue edges indicate error-prone paths. Actions like
browse_news_article and get_entity_distribution typically result in correct answers more
frequently. Notably, get_news_articles has a direct blue link to the answer, suggesting that
this function leads more often to incorrect answers because it only returns news titles, which are
too vague for accurate prediction. However, when followed by browse_news_article and then
providing the answer, the agent is more likely to produce correct outcomes. Similar patterns are
observed with get_event, where adding get_entity_distribution turns a negative link to a
positive one to the answer. Figure 5a further demonstrates how each function contributes to the
final performance, showing that for the first-level prediction, get_{child/sibling}_relation
are more useful. These results emphasize the importance for strategic action planning in LLM agents
for effective temporal forecasting.
4
Related Work
In recent years, various benchmarks have been developed to evaluate temporal reasoning capabilities
in AI systems, focusing primarily on question answering and link prediction. MIRAI distinguishes
itself by assessing LLMs in the forecasting task, and further employing a relational task format,
incorporating diverse information sources of knowledge graphs, text, and code-based APIs, and
utilizing an agent-based methodology that supports intermediate reasoning steps. We summarize
our differences to these existing benchmarks in Table 3, and provide further discussions from the
following aspects and more in Appendix D.
4.1
Temporal Reasoning Benchmarks
Many benchmarks sensing the temporal reasoning ability of AI models have been constructed, but
they have different focuses and settings with MIRAI, particularly in terms of task, information,
and method, as shown in Table 3. One line of benchmarks focuses on the temporal understanding
ability of the model [40â€“45], such as understanding the temporal relations between available facts
in knowledge graphs (KGs) or text, either a short piece of text or a document corpus. While the
temporal forecasting task largely differs from understanding, where the reasoning target is unseen
in the database for the model, and as such, the model has to not only understand but to reason. For
forecasting, there are two main task formulations among previous benchmarks: the QA task format
for benchmarks with history information represented in textual format [8, 46â€“48, 50], and graph link
9

prediction task format for temporal knowledge graph(TKG)-based benchmarks [49, 30]. However,
the uniformat of information sources either lacks of support to clearly structural facts or contextual
detail for the model to perform advanced reasoning, while in MIRAI, we provide both information
sources. Additionally, we provide carefully constructed API with various data classes and functions
that access to various part of the data. With the flexibility provided by code generation, the model is
exposed to a broader and more flexible range of information. More importantly, MIRAI distinguishes
itself by introducing an agentic environment specifically designed to evaluate LLM agents in the
forecasting task. This represents a significant departure from previous work, which has not explored
or even considered the potential of performing temporal forecasting tasks using LLM agents.
4.2
Evaluation of Language Agents
Previous research has investigated the performance of LLM agents in a variety of domains, including
arithmetic reasoning focused on obtaining correct solutions [51â€“53], proficiency assessment in
utilizing tools and reporting results [54â€“56], evaluation of web navigation skills to find specific
websites [57â€“59], and planning travel itineraries under given constraints [60]. However, these
evaluations do not fully address the challenges posed by tasks involving complex international events
with diverse information formats and temporal attributes. MIRAI presents a unique task in this context,
where the agent must navigate and reason over the structured events and textual news articles with
temporal information. This setup requires the agent to effectively handle multilateral relationships
and information spanning different time periods. Furthermore, MIRAI assesses the LLM agentâ€™s
ability to reason and predict information that not be directly available in the provided database. This
adds an additional layer of complexity, as the agent must leverage its understanding of the available
information to make informed predictions about future events or fill in missing details. By evaluating
LLM agents in this challenging setting, MIRAI provides valuable insights into their capacity to
process and reason over complex, temporally-structured information and their ability to generate
accurate predictions based on incomplete data.
4.3
LLMs for Tool-Use
Large Language Models (LLMs) have demonstrated remarkable language understanding [61] and
reasoning capabilities [62]. However, they also possess inherent limitations, such as their inability
to provide up-to-date responses based on external knowledge or to perform complex mathematical
reasoning. In response to these challenges, recent advancements have seen the integration of LLMs
with various external tools [63]. Notable examples include TALM [64] and ToolFormer [65], which
utilize in-context learning to enhance the modelâ€™s ability to leverage different tools in tasks like
question answering and mathematical reasoning. Chameleon [66] employs an LLM as a natural
language planner to deduce the optimal sequence of tools to be used, subsequently executing these
tools to generate the final output. AVIS [67] employs dynamic tree search to synthesize the most
effective tool-use sequence. ToolkenGPT [68] integrates tool-use operators as special tokens and
trains the model through sequence-to-sequence training. ToolLLM [69] introduces an instruction
tuning dataset encompassing over 16,000 real-world APIs, significantly enhancing the modelâ€™s
capability to utilize these tools effectively.
5
Conclusion and Limitation
In conclusion, we introduce MIRAI, a benchmark constructed for evaluating LLM agents in temporal
forecasting international event with tools (APIs) to access an extensive historical event and news
database. The results reveals the complexity and difficulty for current LLM Agents in generating
contextually and syntax-wise correct code and performing complex temporal reasoning over the
multi-party and multi-timestamped data for an effective prediction, highlighting a substantial space
for further effects in this direction.
Our work also has several limitations: 1) Only a few representative LLMs were tested, leaving
broader evaluations with more open-sourced models; 2) The current API is basic, primarily providing
functions for counting, listing, and statistical distribution. Future enhancements could include time
series analysis and the ability for agents to add new functions for more comprehensive analysis. 3)
The study was limited by cost of API usage, so we only conduct small number of experimental rounds
and result in high variance. More extensive testing is suggested for future studies to achieve more
stable results. Full discussion of limitation can be found in Appendix C. In the future, we plan to
incorporate APIs to support more knowledge sources such as time-series and multimodal information,
and consider testing more open-source LLMs and agent architectures.
10

Acknowledgements
Research was supported in part by NIH U24DK097771, U54HG012517, NSF 1829071, 2106859,
2119643, 2200274, 2202693, and 2312501, DARPA HR00112490370, and Optum Lab.
References
[1] Thomas Brown and Susan Lee. Predictive analytics in economic sanctions and international policy.
Journal of International Economics, 26(4):311â€“330, 2018. 1
[2] Johnathan Smith and Jane Doe. Geopolitical risk assessment in international relations. Journal of Global
Politics, 15(3):200â€“225, 2020. 1
[3] Emily Johnson and Mark Roberts. The role of diplomacy in shaping foreign policy. Diplomatic Review,
12(2):145â€“170, 2019. 1
[4] Richard Davis and Anh Nguyen. Strategic alliances and predictive diplomacy: A review of historical data.
Political Science Quarterly, 132(1):45â€“72, 2017. 1
[5] Farzaneh Mahdisoltani, Joanna Biega, and Fabian M Suchanek. YAGO3: A Knowledge Base from
Multilingual Wikipedias. January 2015. CIDR 2015. 1
[6] Woojeong Jin, Meng Qu, Xisen Jin, and Xiang Ren. Recurrent Event Network: Autoregressive Structure
Inference over Temporal Knowledge Graphs, October 2020. EMNLP 2020.
[7] Zixuan Li, Xiaolong Jin, Wei Li, Saiping Guan, Jiafeng Guo, Huawei Shen, Yuanzhuo Wang, and Xueqi
Cheng. Temporal Knowledge Graph Reasoning Based on Evolutional Representation Learning, April
2021. SIGIR 2021. 1
[8] Andy Zou, Tristan Xiao, Ryan Jia, Joe Kwon, Mantas Mazeika, Richard Li, Dawn Song, Jacob Steinhardt,
Owain Evans, and Dan Hendrycks. Forecasting Future World Events with Neural Networks. arXiv,
October 2022. NeurIPS 2022. 1, 9, 22
[9] Revanth Gangi Reddy, Yi R. Fung, Qi Zeng, Manling Li, Ziqi Wang, Paul Sullivan, and Heng Ji.
SmartBook: AI-Assisted Situation Report Generation, March 2023. arXiv. 1
[10] Luis GalÃ¡rraga, Simon Razniewski, Antoine Amarilli, and Fabian M. Suchanek. Predicting completeness
in knowledge bases. In Maarten de Rijke, Milad Shokouhi, Andrew Tomkins, and Min Zhang, editors,
Proceedings of the Tenth ACM International Conference on Web Search and Data Mining, WSDM 2017,
Cambridge, United Kingdom, February 6-10, 2017, pages 375â€“383. ACM, 2017. 1
[11] Zijie Huang, Jeehyun Hwang, Junkai Zhang, Jinwoo Baik, Weitong Zhang, Dominik Wodarz, Yizhou Sun,
Quanquan Gu, and Wei Wang. Causal graph ODE: continuous treatment effect modeling in multi-agent
dynamical systems. In Tat-Seng Chua, Chong-Wah Ngo, Ravi Kumar, Hady W. Lauw, and Roy Ka-Wei
Lee, editors, Proceedings of the ACM on Web Conference 2024, WWW 2024, Singapore, May 13-17,
2024, pages 4607â€“4617. ACM, 2024. 1
[12] Dr Mclean, Alan Patterson, and John Williams. Risk assessment, policy-making and the limits of
knowledge: The precautionary principle and international relations. International Relations, 23:548â€“566,
12 2009. 2
[13] Theodore R. Sumers, Shunyu Yao, Karthik Narasimhan, and Thomas L. Griffiths. Cognitive Architectures
for Language Agents, March 2024. arXiv:2309.02427 [cs]. 2
[14] Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen
Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng
Shen, Tianjun Zhang, Yu Su, Huan Sun, Minlie Huang, Yuxiao Dong, and Jie Tang. AgentBench:
Evaluating LLMs as Agents, October 2023. arXiv:2308.03688 [cs].
[15] Lilian Weng. LLM Powered Autonomous Agents, June 2023. Section: posts.
[16] AutoGPT Documentation.
[17] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and
Anima Anandkumar. Voyager: An Open-Ended Embodied Agent with Large Language Models, October
2023. arXiv:2305.16291 [cs]. 2
[18] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. HuggingGPT:
Solving AI Tasks with ChatGPT and its Friends in Hugging Face, December 2023. arXiv:2303.17580
[cs]. 2
11

[19] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu,
and Jianfeng Gao. Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models,
October 2023. arXiv:2304.09842 [cs].
[20] Yuchen Zhuang, Yue Yu, Kuan Wang, Haotian Sun, and Chao Zhang. ToolQA: A Dataset for LLM
Question Answering with External Tools, June 2023. arXiv:2306.13304 [cs].
[21] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang,
and Yongbin Li. API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs, October 2023.
arXiv:2304.08244 [cs]. 2
[22] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman,
Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv
preprint arXiv:2303.08774, 2023. 2, 6, 22
[23] Anthropic. Claude: An ai assistant by anthropic, 2023.
[24] Google DeepMind. Gemini: An ai model by google deepmind, 2023.
[25] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix,
Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation
language models, 2023. 2, 22
[26] Siyu Yuan, Jiangjie Chen, Ziquan Fu, Xuyang Ge, Soham Shah, Charles Robert Jankowski, Yanghua
Xiao, and Deqing Yang. Distilling Script Knowledge from Large Language Models for Constrained
Language Planning, May 2023. arXiv:2305.05252 [cs]. 2
[27] Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, and Peter Stone.
LLM+P: Empowering Large Language Models with Optimal Planning Proficiency, September 2023.
arXiv:2304.11477 [cs].
[28] Karthik Valmeekam, Matthew Marquez, Alberto Olmo, Sarath Sreedharan, and Subbarao Kambhampati.
PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning
about Change, November 2023. arXiv:2206.10498 [cs].
[29] Yunshan Ma, Chenchen Ye, Zijian Wu, Xiang Wang, Yixin Cao, and Tat-Seng Chua. Context-aware
Event Forecasting via Graph Disentanglement. In Proceedings of the 29th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining, pages 1643â€“1652, August 2023. KDD 2023. 2
[30] Kalev Leetaru and Philip A Schrodt. GDELT: Global Data on Events, Location and Tone,. 2013. 2, 9, 10
[31] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R. Narasimhan, and Yuan Cao.
React: Synergizing reasoning and acting in language models. In The Eleventh International Conference
on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. 2, 6
[32] Elizabeth Boschee, Jennifer Lautenschlager, Sean Oâ€™Brien, Steve Shellman, James Starz, and Michael
Ward. Cameo.cdb.09b5.pdf. In ICEWS Coded Event Data. Harvard Dataverse, 2015. 3
[33] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. ReAct:
Synergizing Reasoning and Acting in Language Models, March 2023. arXiv:2210.03629 [cs]. 3
[34] Hugo LaurenÃ§on, Lucile Saulnier, LÃ©o Tronchon, Stas Bekman, Amanpreet Singh, Anton Lozhkov,
Thomas Wang, Siddharth Karamcheti, Alexander M. Rush, Douwe Kiela, Matthieu Cord, and Victor
Sanh. OBELICS: an open web-scale filtered dataset of interleaved image-text documents. In Alice Oh,
Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Advances
in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing
Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, 2023. 5, 28
[35] GPT-3.5-Turbo, https://platform.openai.com/docs/models/gpt-3-5-turbo, 2023. 6
[36] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le,
and Denny Zhou. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models, January
2023. arXiv:2201.11903 [cs]. 6
[37] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language
models are zero-shot reasoners. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho,
and A. Oh, editors, Advances in Neural Information Processing Systems 35: Annual Conference on
Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 -
December 9, 2022, 2022. 6
12

[38] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego
de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, LÃ©lio Renard
Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, TimothÃ©e
Lacroix, and William El Sayed. Mistral 7b, 2023. 6
[39] Gpt-4o contributions. 2024. 6
[40] Zhen Jia, Abdalghani Abujabal, Rishiraj Saha Roy, Jannik StrÃ¶tgen, and Gerhard Weikum. TempQues-
tions: A Benchmark for Temporal Question Answering. In Companion Proceedings of the The Web
Conference 2018, WWW â€™18, pages 1057â€“1062, Republic and Canton of Geneva, CHE, April 2018.
International World Wide Web Conferences Steering Committee. ISBN 978-1-4503-5640-4. WWW
2018. 9
[41] Apoorv Saxena, Soumen Chakrabarti, and Partha Talukdar. Question Answering Over Temporal Knowl-
edge Graphs. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics
and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers),
pages 6663â€“6676, Online, August 2021. Association for Computational Linguistics. ACL 2021. 9
[42] Costas Mavromatis, Prasanna Lakkur Subramanyam, Vassilis N. Ioannidis, Soji Adeshina, Phillip R.
Howard, Tetiana Grinberg, Nagib Hakim, and George Karypis. TempoQR: Temporal Question Reasoning
over Knowledge Graphs. arXiv, December 2021. AAAI 2022. 9
[43] Qiang Ning, Hao Wu, Rujun Han, Nanyun Peng, Matt Gardner, and Dan Roth. TORQUE: A Reading
Comprehension Dataset of Temporal Ordering Questions. In Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing (EMNLP), pages 1158â€“1172, Online, November
2020. Association for Computational Linguistics. EMNLP 2020. 9
[44] Qingyu Tan, Hwee Tou Ng, and Lidong Bing. Towards Benchmarking and Improving the Temporal
Reasoning Capability of Large Language Models. In Proceedings of the 61st Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers), pages 14820â€“14835, Toronto,
Canada, July 2023. Association for Computational Linguistics. ACL 2023. 9
[45] Yuqing Wang and Yun Zhao. TRAM: Benchmarking Temporal Reasoning for Large Language Models,
May 2024. arXiv:2310.00835 [cs]. 9
[46] Zhihan Zhang, Yixin Cao, Chenchen Ye, Yunshan Ma, Lizi Liao, and Tat-Seng Chua. Analyzing
Temporal Complex Events with Large Language Models? A Benchmark towards Temporal, Long Context
Understanding, June 2024. arXiv:2406.02472 [cs]. 9, 22
[47] Woojeong Jin, Rahul Khanna, Suji Kim, Dong-Ho Lee, Fred Morstatter, Aram Galstyan, and Xiang
Ren. ForecastQA: A Question Answering Challenge for Event Forecasting with Temporal Text Data.
In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the
11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages
4636â€“4650, Online, August 2021. Association for Computational Linguistics. ACL 2021. 9
[48] Danny Halawi, Fred Zhang, Chen Yueh-Han, and Jacob Steinhardt.
Approaching Human-Level
Forecasting with Language Models, February 2024. URL http://arxiv.org/abs/2402.18563.
arXiv:2402.18563 [cs]. 9
[49] Elizabeth Boschee, Jennifer Lautenschlager, Sean Oâ€™Brien, Steve Shellman, James Starz, and Michael
Ward. Icews coded event data, 2015. 9, 10
[50] Philipp Schoenegger, Indre Tuminauskaite, Peter S. Park, and Philip E. Tetlock. Wisdom of the Silicon
Crowd: LLM Ensemble Prediction Capabilities Rival Human Crowd Accuracy, May 2024.
URL
http://arxiv.org/abs/2402.19379. arXiv:2402.19379 [cs]. 9
[51] Subhro Roy and Dan Roth. Solving general arithmetic word problems. In Proceedings of EMNLP, 2015.
10
[52] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word
problems. arXiv preprint arXiv:2110.14168, 2021.
[53] Arkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP models really able to solve simple math
word problems? In Proceedings of NAACL, 2021. 10
[54] Minghao Li, Yingxiu Zhao, Bowen Yu, Feifan Song, Hangyu Li, Haiyang Yu, Zhoujun Li, Fei Huang,
and Yongbin Li. Api-bank: A comprehensive benchmark for tool-augmented llms. In Proceedings of
EMNLP, 2023. 10
13

[55] Qiantong Xu, Fenglu Hong, Bo Li, Changran Hu, Zhengyu Chen, and Jian Zhang. On the tool manipula-
tion capability of open-source large language models. arXiv preprint arXiv:2305.16504, 2023.
[56] Yuchen Zhuang, Yue Yu, Kuan Wang, Haotian Sun, and Chao Zhang. ToolQA: A dataset for LLM
question answering with external tools. In Proceedings of NeurIPS, 2023. 10
[57] Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su.
Mind2web: Towards a generalist agent for the web. In Proceedings of NeurIPS, 2023. 10
[58] Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan
Bisk, Daniel Fried, Uri Alon, et al. Webarena: A realistic web environment for building autonomous
agents. In Proceedings of ICLR, 2024.
[59] Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen
Men, Kejuan Yang, et al. Agentbench: Evaluating llms as agents. In Proceedings of ICLR, 2024. 10
[60] Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong Tian, Yanghua Xiao, and
Yu Su. TravelPlanner: A Benchmark for Real-World Planning with Language Agents, February 2024.
arXiv:2402.01622 [cs]. 10
[61] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language understand-
ing by generative pre-training. 2018. 10
[62] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi,
Quoc V. Le, and Denny Zhou.
Chain-of-thought prompting elicits reasoning in large language
models.
In NeurIPS, 2022.
URL http://papers.nips.cc/paper_files/paper/2022/hash/
9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html. 10
[63] GrÃ©goire Mialon, Roberto DessÃ¬, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta
Raileanu, Baptiste RoziÃ¨re, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, Edouard Grave, Yann
LeCun, and Thomas Scialom. Augmented language models: a survey. In arXiv preprint arXiv:2302.07842,
2023. 10
[64] Aaron Parisi, Yao Zhao, and Noah Fiedel. Talm: Tool augmented language models. In arXiv preprint
arXiv:2205.12255, 2022. 10
[65] Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke
Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves
to use tools. In Proceedings of NeurIPS, 2023. 10
[66] Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu,
and Jianfeng Gao. Chameleon: Plug-and-play compositional reasoning with large language models. In
Proceedings of NeurIPS, 2023. 10
[67] Ziniu Hu, Ahmet Iscen, Chen Sun, Kai-Wei Chang, Yizhou Sun, David Ross, Cordelia Schmid,
and Alireza Fathi.
AVIS: autonomous visual information seeking with large language model
agent.
In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey
Levine, editors, Advances in Neural Information Processing Systems 36: Annual Conference on
Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, Decem-
ber 10 - 16, 2023, 2023.
URL http://papers.nips.cc/paper_files/paper/2023/hash/
029df12a9363313c3e41047844ecad94-Abstract-Conference.html. 10
[68] Shibo Hao, Tianyang Liu, Zhen Wang, and Zhiting Hu. Toolkengpt: Augmenting frozen language models
with massive tools via tool embeddings. In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko,
Moritz Hardt, and Sergey Levine, editors, Advances in Neural Information Processing Systems 36: Annual
Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA,
December 10 - 16, 2023, 2023. URL http://papers.nips.cc/paper_files/paper/2023/hash/
8fd1a81c882cd45f64958da6284f4a3f-Abstract-Conference.html. 10
[69] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru
Tang, Bill Qian, Sihan Zhao, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan
Liu, and Maosong Sun. Toolllm: Facilitating large language models to master 16000+ real-world apis.
CoRR, abs/2307.16789, 2023. doi: 10.48550/ARXIV.2307.16789. URL https://doi.org/10.48550/
arXiv.2307.16789. 10
[70] Qingyu Tan, Hwee Tou Ng, and Lidong Bing. Towards benchmarking and improving the temporal rea-
soning capability of large language models. In ACL, pages 14820â€“14835. Association for Computational
Linguistics, 2023. 22
14

[71] Qiang Ning, Hao Wu, Rujun Han, Nanyun Peng, Matt Gardner, and Dan Roth. TORQUE: A reading
comprehension dataset of temporal ordering questions. In EMNLP, pages 1158â€“1172, 2020.
[72] Ben Zhou, Daniel Khashabi, Qiang Ning, and Dan Roth. â€œgoing on a vacationâ€ takes longer than â€œgoing
for a walkâ€: A study of temporal commonsense understanding. In EMNLP, pages 3363â€“3369, 2019.
[73] Michael Zhang and Eunsol Choi. Situatedqa: Incorporating extra-linguistic contexts into qa. In EMNLP,
2021.
[74] Yuqing Wang and Yun Zhao. Tram: Benchmarking temporal reasoning for large language models. 2023.
22
[75] Woojeong Jin, Meng Qu, Xisen Jin, and Xiang Ren. Recurrent event network: Autoregressive structure in-
ferenceover temporal knowledge graphs. In EMNLP (1), pages 6669â€“6683. Association for Computational
Linguistics, 2020. 22
[76] Zixuan Li, Xiaolong Jin, Wei Li, Saiping Guan, Jiafeng Guo, Huawei Shen, Yuanzhuo Wang, and Xueqi
Cheng. Temporal knowledge graph reasoning based on evolutional representation learning. In SIGIR,
pages 408â€“417. ACM, 2021.
[77] Namyong Park, Fuchen Liu, Purvanshi Mehta, Dana Cristofor, Christos Faloutsos, and Yuxiao Dong.
Evokg: Jointly modeling event time and network structure for reasoning over temporal knowledge graphs.
In WSDM, pages 794â€“803. ACM, 2022. 22
[78] Cunchao Zhu, Muhao Chen, Changjun Fan, Guangquan Cheng, and Yan Zhan. Learning from history:
Modeling temporal knowledge graphs with sequential copy-generation networks. In AAAI Conference on
Artificial Intelligence, 2020. 22
[79] Haohai Sun, Jialu Zhong, Yunpu Ma, Zhen Han, and Kun He. Timetraveler: Reinforcement learning for
temporal knowledge graph forecasting. In EMNLP, 2021.
[80] Zixuan Li, Xiaolong Jin, Saiping Guan, Wei Li, Jiafeng Guo, Yuanzhuo Wang, and Xueqi Cheng. Search
from history and reason for future: Two-stage reasoning on temporal knowledge graphs. In ACL, 2021.
22
[81] Rakshit Trivedi, Hanjun Dai, Yichen Wang, and Le Song. Know-evolve: deep temporal reasoning for
dynamic knowledge graphs. In ICML, page 3462â€“3471, 2017. 22
[82] Zifeng Ding, Zhen Han, Yunpu Ma, and Volker Tresp. Temporal knowledge graph forecasting with neural
ode. abs/2101.05151, 2021. 22
[83] Songgaojun Deng, Huzefa Rangwala, and Yue Ning. Dynamic knowledge graph based multi-event
forecasting. In KDD, pages 1585â€“1595. ACM, 2020. 22
[84] Songgaojun Deng, Huzefa Rangwala, and Yue Ning. Understanding event predictions via contextualized
multilevel feature learning. In CIKM, pages 342â€“351. ACM, 2021. 22
[85] Yunshan Ma, Chenchen Ye, Zijian Wu, Xiang Wang, Yixin Cao, and Tat-Seng Chua. Context-aware event
forecasting via graph disentanglement. In KDD, pages 1643â€“1652. ACM, 2023. 22
[86] Yunshan Ma, Chenchen Ye, Zijian Wu, Xiang Wang, Yixin Cao, Liang Pang, and Tat-Seng Chua.
Structured, complex and time-complete temporal event forecasting. CoRR, abs/2312.01052, 2023. 22
[87] Wenjie Xu, Ben Liu, Miao Peng, Xu Jia, and Min Peng. Pre-trained language model with prompts
for temporal knowledge graph completion. In ACL (Findings), pages 7790â€“7803. Association for
Computational Linguistics, 2023. 22
[88] Dong-Ho Lee, Kian Ahrabian, Woojeong Jin, Fred Morstatter, and Jay Pujara. Temporal knowledge
graph forecasting without knowledge using in-context learning. In EMNLP, pages 544â€“557. Association
for Computational Linguistics, 2023. 22
[89] Ruotong Liao, Xu Jia, Yunpu Ma, and Volker Tresp. Gentkg: Generative forecasting on temporal
knowledge graph. CoRR, abs/2310.07793, 2023. 22
[90] Xiaoming Shi, Siqiao Xue, Kangrui Wang, Fan Zhou, James Y. Zhang, JUN ZHOU, Chenhao Tan, and
Hongyuan Mei. Language models can improve event prediction by few-shot abductive reasoning. In
NeurIPS, 2023. 22
15

[91] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners.
Advances in neural information processing systems, 33:1877â€“1901, 2020. 22
[92] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts,
Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language
modeling with pathways. Journal of Machine Learning Research, 24(240):1â€“113, 2023. 22
[93] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan,
Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models
trained on code. arXiv preprint arXiv:2107.03374, 2021. 22
[94] Yue Wang, Weishi Wang, Shafiq Joty, and Steven CH Hoi. Codet5: Identifier-aware unified pre-trained
encoder-decoder models for code understanding and generation. In Proceedings of the 2021 Conference
on Empirical Methods in Natural Language Processing, pages 8696â€“8708, 2021. 22
[95] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, and
Caiming Xiong. Codegen: An open large language model for code with multi-turn program synthesis.
arXiv preprint arXiv:2203.13474, 2022. 22
[96] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, RÃ©mi Leblond, Tom Eccles,
James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation with alphacode.
Science, 378(6624):1092â€“1097, 2022. 22
[97] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou,
Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, et al. Starcoder: may the source be with you! arXiv
preprint arXiv:2305.06161, 2023. 22
[98] Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma,
Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering code large language models with evol-instruct.
arXiv preprint arXiv:2306.08568, 2023. 22
[99] Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio CÃ©sar Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi,
Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, et al. Textbooks are all you need.
arXiv preprint arXiv:2306.11644, 2023. 22
[100] Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi,
Jingyu Liu, Tal Remez, JÃ©rÃ©my Rapin, et al. Code llama: Open foundation models for code. arXiv
preprint arXiv:2308.12950, 2023. 22
[101] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han,
Fei Huang, et al. Qwen technical report. arXiv preprint arXiv:2309.16609, 2023. 22
[102] Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guanting Chen, Xiao Bi,
Y Wu, YK Li, et al. Deepseek-coder: When the large language model meets programmingâ€“the rise of
code intelligence. arXiv preprint arXiv:2401.14196, 2024. 22
[103] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan,
Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. Program synthesis with large language models.
arXiv preprint arXiv:2108.07732, 2021. 22
16

Appendix
A Reproducibility Statement
19
B
Datasheet for MIRAI
19
B.1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
B.2
Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
B.3
Maintenance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
B.4
Composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
B.5
Collection Process
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
B.6
Uses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
C Limitations
21
D Additional related work
22
D.1 Temporal Event Forecasting Methods
. . . . . . . . . . . . . . . . . . . . . . . .
22
D.2
LLMs for Code Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
E Additional Details of the Database
23
E.1
Countries and ISO Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
E.2
Relations and CAMEO Codes
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
F
Details of Dataset Construction
28
G Term of Use for GDELT Dataset
28
H Broader Impact
28
I
Additional Details about Agent Setup
28
J
Additional Experimental Results and Analysis
29
J.1
Analysis of the Final Status of Different LLM Agents . . . . . . . . . . . . . . . .
29
J.2
Analysis on Function Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
K Prompts
31
K.1
System Prompts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
K.1.1
System Prompt for ReAct Agent with Action Type as â€œSingle Functionâ€ . .
31
K.1.2
System Prompt for ReAct Agent with Action Type as â€œCode Blockâ€ . . . .
32
K.1.3
System Prompt for Direct Agent . . . . . . . . . . . . . . . . . . . . . . .
33
K.1.4
System Prompt for CoT Agent . . . . . . . . . . . . . . . . . . . . . . . .
34
K.2
Query Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
K.3 Answer Extraction Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
L Additional Forecasting Examples of LLM Agent
36
L.1
GPT-4o-based Agent with ReAct and â€œCode Blockâ€ Action . . . . . . . . . . . . .
36
L.1.1
Query Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
L.1.2
Query Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
L.1.3
System Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
L.1.4
Agent ReAct Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
L.1.5
Agent Final Status
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
L.2
GPT-4o-based Agent with ReAct and â€œSingle Functionâ€ Action . . . . . . . . . . .
41
L.2.1
Query Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
17

L.2.2
Query Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
L.2.3
System Prompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
L.2.4
Agent ReAct Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
L.2.5
Agent Final Status
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
M Additional Information about API
47
M.1 Overview of API Data Classes and Functions
. . . . . . . . . . . . . . . . . . . .
47
M.2 API Specification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
M.3 API Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
18

A
Reproducibility Statement
We provide detailed information and explanation of our experimental setup, dataset, and evaluation
metrics, ensuring reproducibility. Specifically, we describe the following:
â€¢ Experimental setup (Sec. 3): Detailed descriptions of the hardware and software configurations,
including libraries and tools used.
â€¢ Dataset (Sec. 2 & Appendix F): Comprehensive information on the dataset used, including sources,
preprocessing steps, and any techniques applied.
â€¢ Evaluation Metrics (Sec. 2.3): Clear definitions for the metrics chosen to evaluate performance.
Additionally, we commit to releasing the following resources for the replication of our results:
â€¢ Codebase: The complete codebase, including scripts for data preprocessing, model serving, and
evaluation. This is made available on a public repository (https://github.com/yecchen/
MIRAI).
â€¢ Dataset: The processed dataset, along with detailed instructions on how to construct the dataset
(https://drive.google.com/file/d/1xmSEHZ_wqtBu1AwLpJ8wCDYmT-jRpfrN/view?
usp=sharing).
By providing these resources, we aim to ensure that our work is fully reproducible and can be
independently verified by the research community.
B
Datasheet for MIRAI
B.1
Motivation
1. For what purpose was the dataset created?
The MIRAI dataset was created to evaluate different capabilities of Large Language Model (LLM)
agents in forecasting international events.
2. Who created the dataset and on behalf of which entity?
The dataset was developed by a group of university researchers studying LLM reasoning. All
rights are held by the individuals themselves, rather than by third-party stakeholders.
3. Who funded the creation of the dataset?
The academic institutions support the university reasearch lab that the authors affiliate in.
B.2
Distribution
1. Will the dataset be distributed to third parties outside of the entity?
Yes, the dataset, evaluation codes and leaderboards are intended to be publicly available to foster
future research and development.
2. How will the dataset be distributed?
The database and codebase are currently available on Google Drive and Github.
3. Have any third parties imposed IP-based or other restrictions on the data associated with
the instances?
No, there are no IP-based or other restrictions on the data: MIRAI is curated based on the GDELT6
Event Database, which is an open platform for research and analysis of global society and all
datasets released by the GDELT Project are available for unlimited and unrestricted use for any
academic, commercial, or governmental use of any kind without fee; Data are allowed for any
redistribution, rehost, republish, and mirror of the GDELT datasets in any form, with necessary
citations7.
4. Do any export controls or other regulatory restrictions apply to the dataset or to individual
instances?
No, there are no export controls or other regulatory restrictions applied to this dataset.
5. When will the dataset be distributed?
The dataset has been made publicly available with the project website, Google Drive, and Github.
6. Will the dataset be distributed under a copyright or other IP license, and/or under applicable
terms of use (ToU)?
The dataset will be distributed under the CC BY-NC 4.0 license, allowing for use and distribution
for non-commercial purposes with appropriate attribution.
6GDELT Project: https://www.gdeltproject.org/
7GDELT Term of Use: https://www.gdeltproject.org/about.html#termsofuse
19

B.3
Maintenance
1. Who will be supporting/hosting/maintaining the dataset?
The dataset maintenance will be supporting/hosting/maintaining by the authors.
2. How can the owner/curator/manager of the dataset be contacted?
The owner/curator/manager of the dataset can be contacted through the authorsâ€™ emails.
3. Will the dataset be updated? (e.g., to correct labeling errors, add new instances, delete
instances)?
Yes, the dataset will be updated whenever necessary to ensure accuracy, and announcements will
be made accordingly.
4. If the dataset relates to people, are there applicable limits on the retention of the data
associated with the instances (e.g., were the individuals in question told that their data would
be retained for a fixed period of time and then deleted?)
NA. This dataset does not contain data related to individuals or personal identifiers.
5. Will older version of the dataset continue to be supported/hosted/maintained?
NA. Currently, there are no older versions of the dataset, as this is its first release. As the dataset
evolves, the possibility of supporting and maintaining older versions will be considered based on
community needs and resource availability.
6. If others want to extend/augment/build on/contribute to the dataset, is there a mechanism
for them to do so?
Researchers and developers interested in extending, augmenting, or contributing to the dataset
are encouraged to submit their changes through GitHub pull requests. For additional inquiries or
detailed discussions, contacting the authors via email is recommended.
B.4
Composition
1. What do the instances that comprise the dataset represent?
Each instance in the dataset represents a structured record of international events, including the
date, involved countries, and type of event, along with associated news articles and metadata.
2. How many instances are there in total?
The database comprises 991,759 GDELT event records from January 2023 to November 2023,
corresponding to 59,161 unique events and 296,630 news articles. The test set contains 705
relation prediction queries, and the test subset contains 100 queries.
3. Does the dataset contain all possible instances or is it a sample of instances from a larger set?
The dataset represents a curated sample from the entire GDELT database. It has been created
through meticulously designed data cleaning and preprocessing steps aimed at enhancing the
quality and reliability of the event data.
4. Is there a label or target associated with each instance?
Yes, each instance in the dataset is an event labeled with a relation type derived from the CAMEO8
event taxonomy.
5. Is any information missing from individual instances?
No, all instances are complete with all available information.
6. Are there recommended data splits (e.g., training, development/validation, testing)?
The dataset includes records from January 2023 to November 2023. The recommended testing
set is constructed based on records from November 2023. For testing, each instance utilizes all
preceding records as its historical dataset to ensure accuracy and relevance in analysis.
7. Are there any errors, sources of noise, or redundancies in the dataset?
The dataset has undergone extensive cleaning and structuring to minimize errors and noise.
However, residual noise from the original GDELT database may still be present.
8. Is the dataset self-contained, or does it link to or otherwise rely on external resources (e.g.,
websites, tweets, other datasets)?
While the dataset is primarily self-contained, it includes URLs to news articles, providing links to
external resources for further context and verification.
9. Does the dataset contain data that might be considered confidential?
No, the dataset contains publicly available data and does not include confidential information.
8Conflict and Mediation Event Observations (CAMEO): https://parusanalytics.com/eventdata/data.dir/cameo.html
20

10. Does the dataset contain data that, if viewed directly, might be offensive, insulting, threaten-
ing, or might otherwise cause anxiety?
The dataset may include descriptions of sensitive events, such as global conflicts, due to its focus
on international relations. However, thorough checks such as flagging word ratios are employed
during the data cleaning process to identify and potentially exclude inappropriate paragraphs
or entire news articles and events. This ensures the minimization of distressing content while
maintaining the integrity and relevance of the dataset for academic study.
B.5
Collection Process
1. How was the data associated with each instance acquired?
Data for each instance was sourced from the GDELT project, which aggregates global event data
and news articles from various worldwide media. Detailed information can be found in Section 2.3
and Appendix F of the paper.
2. What mechanisms or procedures were used to collect the data (e.g., hardware apparatus or
sensor, manual human curation, software program, software API)?
Data collection was facilitated through software programs that aggregate event data and news
articles from various sources. This automated collection is followed by data cleaning processes to
enhance completeness and reliability. For a detailed description of the collection and cleaning
methods, please refer to Section 2.3 and Appendix F of the paper. All dataset construction scripts
are available in Github and also described in the README.
3. Who was involved in the data collection process? (e.g., students, crowdworkers, contractors)
and how were they compensated (e.g., how much were crowdworkers paid)
The data collection and preprocessing were conducted by the authors, who are university re-
searchers. This work was performed as part of their academic research activities.
4. Does the dataset relate to people?
No. The dataset does not contain personal data or directly relate to individual people.
5. Did you collect the data from the individuals in questions directly, or obtain it via third
parties or other sources (e.g., websites)?
The dataset does not involve data collected from individuals directly. Instead, it is curated from
the GDELT project, which aggregates information from various global news media sources.
B.6
Uses
1. Has the dataset been used for any tasks already?
The dataset has not been used for any tasks other than the ones proposed and examined in
this current paper, specifically for benchmarking the forecasting capabilities of LLM agents in
predicting international relations.
2. What (other) tasks could the dataset be used for?
In addition to benchmarking LLM agents, the dataset could be valuable for research in geopolitics,
the development of other event prediction algorithms, sentiment analysis of international events,
and trend analysis in global political dynamics.
3. Is there anything about the composition of the dataset or the way it was collected and
preprocessed/cleaned/labeled that might impact future uses?
The dataset was meticulously collected and preprocessed to ensure high quality and reliability.
However, the reliance on the GDELT project as the primary data source and the specific cleaning
process applied might influence its applicability to certain tasks. Users should consider these
factors when applying the dataset to different research areas or methodologies.
4. Are there tasks for which the dataset should not be used?
The dataset should not be used for any tasks that violate the terms of use associated with the
GDELT project.
C
Limitations
We acknowledge a few limitations in our current work. Firstly, the forecasting events in the test set
might have been exposed to the most recently published LLMs, such as the gpt-4-turbo-2024-
04-09, which has training data up to December 2023. While the background knowledge of LLMs
about international relations matters for accurate forecasting, this benchmark still challenges them in
retrieving grounded facts from the database and performing reliable forecasting. Secondly, many other
base LLMs are not tested in the experiments. However, we chose some representative models for both
21

open-source and closed-source LLMs, leaving more comprehensive tests for future work. Thirdly,
while the current API covers functions like count, listing, and basic distribution statistics of events
and news articles, more functionality can be added to the function pool in the future. For example,
to further encourage the agent to analyze based on temporal trends, functions related to time series
could be added to the API. We could also allow agents to generate and add useful functions to the
API during their reasoning process to support a more diverse toolset. Fourthly, current experiments
are limited by cost and time considerations. More rounds of experiments should be added for each
different LLM and various settings. We observe some large variance in the experimental results,
which may be caused by the current model temperature of 0.4 and the limited number of 5 rounds per
experiment.
D
Additional related work
D.1
Temporal Event Forecasting Methods
LLMs have been tested for their temporal understanding through tasks such as temporal event
ordering or storyline comprehension [70â€“74]. In the context of temporal forecasting, LLMs have
also been evaluated on recent text-based temporal forecasting benchmarks [8, 46]. However, these
evaluations typically involve providing LLMs with retrieved context for in-context learning and
then directly answering the forecast question. This approach limits the interaction between the
LLM and the database and lacks important intermediate thinking and reasoning steps crucial for
accurate forecasting. In contrast, MIRAI establishes a comprehensive environment that enables an
LLM to act as an agent, interacting with the database through multiple rounds of thinking, retrieving
diverse information, and providing a complete reasoning path to the final forecast answer. This setup
allows for a more thorough evaluation of the LLMâ€™s temporal reasoning capabilities and its ability to
effectively retrieving and analyzing the available information.
Significant research has also been conducted in the field of structured event temporal forecasting.
Various methods have been proposed, including aggregating temporal and relational information
among entities [75â€“77], retrieving relevant historical events [78â€“80], and modeling the continuous
time evolution of events [81, 82]. Efforts have also been made to incorporate textual event information
into Temporal Knowledge Graphs (TKGs). Glean [83] and CMF [84] integrate textual embeddings
into graph edges, while SeCoGD [85] employs textual topic modeling to separate subgraphs. The
MidEast-TE dataset and LoGo model [86] utilize text clustering to construct complex events for
forecasting with local and global contexts. However, these methods still perform forecast reasoning
solely on graphs using graph-based techniques. Recent studies have explored the use of LLMs
for temporal event forecasting by transforming the TKG formulation into text sequences and con-
verting missing object prediction into next token prediction [87]. GPT-NeoX-ICL [88] employs
in-context learning of LLMs and constructs prompts as a list of historical events in quadruplet format.
GENTKG [89] enhances the selection of historical event inputs using a temporal logical rule-based
retrieval strategy, while LAMP [90] applies LLMs to perform abductive reasoning to assist the
retrieval process. However, these works only investigate LLMs with in-context learning or simple
task-specific fine-tuning. In contrast, MIRAI explores forecasting with an LLM agent that supports
explicit information gathering and reasoning steps, enabling a hybrid approach that leverages both
text and graph data.
D.2
LLMs for Code Generation
Early advancements in LLMs have greatly impacted the field of code generation. Notable early
models such as GPT-3 [91] and PALM [92] have demonstrated the potential of LLMs to assist in code
completion and generation. Subsequent models have built upon the foundation of pre-trained LLMs,
further refining capabilities specific to code generation. This has led to the development of code-
specific LLMs such as Codex [93], Code T5 [94], CodeGen [95], AlphaCode [96], StarCoder [97],
WizardCoder [98], and phi-1 [99]. Moreover, code from open-source platforms such as GitHub has
increasingly been incorporated into the pre-training data for recent LLMs [25, 22]. This integration
has led to improved performance of LLMs such as Code Llama [100], Code-Qwen [101], and
DeepSeek-Coder [102] on popular code-related tasks [93, 103].
22

E
Additional Details of the Database
E.1
Countries and ISO Codes
We show the ISO 3166 Alpha-3 country codes and names in Table 4 and Table 5.
Table 4: List of Countries and their ISO-3166 Alpha-3 Codes (Part 1)
Code
Country
Code
Country
Code
Country
AND
Andorra
ARE
United Arab Emirates
AFG
Afghanistan
ATG
Antigua and Barbuda
AIA
Anguilla
ALB
Albania
ARM
Armenia
AGO
Angola
ATA
Antarctica
ARG
Argentina
ASM
American Samoa
AUT
Austria
AUS
Australia
ABW
Aruba
ALA
Ã…land
AZE
Azerbaijan
BIH
Bosnia and Herzegovina
BRB
Barbados
BGD
Bangladesh
BEL
Belgium
BFA
Burkina Faso
BGR
Bulgaria
BHR
Bahrain
BDI
Burundi
BEN
Benin
BLM
Saint BarthÃ©lemy
BMU
Bermuda
BRN
Brunei
BOL
Bolivia
BES
Bonaire, Sint Eustatius, and Saba
BRA
Brazil
BHS
Bahamas
BTN
Bhutan
BVT
Bouvet Island
BWA
Botswana
BLR
Belarus
BLZ
Belize
CAN
Canada
CCK
Cocos (Keeling) Islands
COD
DR Congo
CAF
Central African Republic
COG
Congo Republic
CHE
Switzerland
CIV
Ivory Coast
COK
Cook Islands
CHL
Chile
CMR
Cameroon
CHN
China
COL
Colombia
CRI
Costa Rica
CUB
Cuba
CPV
Cabo Verde
CUW
CuraÃ§ao
CXR
Christmas Island
CYP
Cyprus
CZE
Czechia
DEU
Germany
DJI
Djibouti
DNK
Denmark
DMA
Dominica
DOM
Dominican Republic
DZA
Algeria
ECU
Ecuador
EST
Estonia
EGY
Egypt
ESH
Western Sahara
ERI
Eritrea
ESP
Spain
ETH
Ethiopia
FIN
Finland
FJI
Fiji
FLK
Falkland Islands
FSM
Micronesia
FRO
Faroe Islands
FRA
France
GAB
Gabon
GBR
United Kingdom
GRD
Grenada
GEO
Georgia
GUF
French Guiana
GGY
Guernsey
GHA
Ghana
GIB
Gibraltar
GRL
Greenland
GMB
The Gambia
GIN
Guinea
GLP
Guadeloupe
GNQ
Equatorial Guinea
GRC
Greece
SGS
South Georgia and South Sandwich Islands
GTM
Guatemala
GUM
Guam
GNB
Guinea-Bissau
GUY
Guyana
HKG
Hong Kong
HMD
Heard and McDonald Islands
HND
Honduras
HRV
Croatia
HTI
Haiti
HUN
Hungary
IDN
Indonesia
IRL
Ireland
ISR
Israel
IMN
Isle of Man
IND
India
IOT
British Indian Ocean Territory
IRQ
Iraq
IRN
Iran
ISL
Iceland
ITA
Italy
JEY
Jersey
JAM
Jamaica
JOR
Jordan
JPN
Japan
KEN
Kenya
KGZ
Kyrgyzstan
KHM
Cambodia
KIR
Kiribati
COM
Comoros
KNA
St Kitts and Nevis
PRK
North Korea
KOR
South Korea
KWT
Kuwait
CYM
Cayman Islands
KAZ
Kazakhstan
LAO
Laos
LBN
Lebanon
LCA
Saint Lucia
LIE
Liechtenstein
LKA
Sri Lanka
LBR
Liberia
LSO
Lesotho
LTU
Lithuania
LUX
Luxembourg
LVA
Latvia
LBY
Libya
MAR
Morocco
MCO
Monaco
MDA
Moldova
MNE
Montenegro
MAF
Saint Martin
MDG
Madagascar
MHL
Marshall Islands
MKD
North Macedonia
MLI
Mali
MMR
Myanmar
MNG
Mongolia
MAC
Macao
MNP
Northern Mariana Islands
MTQ
Martinique
MRT
Mauritania
MSR
Montserrat
MLT
Malta
MUS
Mauritius
MDV
Maldives
MWI
Malawi
MEX
Mexico
MYS
Malaysia
MOZ
Mozambique
NAM
Namibia
NCL
New Caledonia
NER
Niger
NFK
Norfolk Island
NGA
Nigeria
NIC
Nicaragua
NLD
The Netherlands
NOR
Norway
NPL
Nepal
NRU
Nauru
NIU
Niue
NZL
New Zealand
OMN
Oman
PAN
Panama
PER
Peru
PYF
French Polynesia
PNG
Papua New Guinea
PHL
Philippines
PAK
Pakistan
POL
Poland
SPM
Saint Pierre and Miquelon
PCN
Pitcairn Islands
PRI
Puerto Rico
PSE
Palestine
PRT
Portugal
PLW
Palau
PRY
Paraguay
QAT
Qatar
REU
RÃ©union
ROU
Romania
SRB
Serbia
RUS
Russia
RWA
Rwanda
SAU
Saudi Arabia
SLB
Solomon Islands
SYC
Seychelles
SDN
Sudan
SWE
Sweden
SGP
Singapore
SHN
Saint Helena
SVN
Slovenia
SJM
Svalbard and Jan Mayen
SVK
Slovakia
SLE
Sierra Leone
SMR
San Marino
23

Table 5: List of Countries and their ISO-3166 Alpha-3 Codes (Part 2)
Code
Country
Code
Country
Code
Country
SEN
Senegal
SOM
Somalia
SUR
Suriname
SSD
South Sudan
STP
SÃ£o TomÃ© and PrÃ­ncipe
SLV
El Salvador
SXM
Sint Maarten
SYR
Syria
SWZ
Eswatini
TCA
Turks and Caicos Islands
TCD
Chad
ATF
French Southern Territories
TGO
Togo
THA
Thailand
TJK
Tajikistan
TKL
Tokelau
TLS
Timor-Leste
TKM
Turkmenistan
TUN
Tunisia
TON
Tonga
TUR
TÃ¼rkiye
TTO
Trinidad and Tobago
TUV
Tuvalu
TWN
Taiwan
TZA
Tanzania
UKR
Ukraine
UGA
Uganda
UMI
U.S. Outlying Islands
USA
United States
URY
Uruguay
UZB
Uzbekistan
VAT
Vatican City
VCT
St Vincent and Grenadines
VEN
Venezuela
VGB
British Virgin Islands
VIR
U.S. Virgin Islands
VNM
Vietnam
VUT
Vanuatu
WLF
Wallis and Futuna
WSM
Samoa
XKX
Kosovo
YEM
Yemen
MYT
Mayotte
ZAF
South Africa
ZMB
Zambia
ZWE
Zimbabwe
E.2
Relations and CAMEO Codes
We show the CAMEO relation codes and names, where the first-level relations are in two digits, and
the second-level relations are in three digits with the first two digits be the same as its parent relation:
â€¢ 01: Make public statement
â€“ 010: Make statement, not specified
â€“ 011: Decline comment
â€“ 012: Make pessimistic comment
â€“ 013: Make optimistic comment
â€“ 014: Consider policy option
â€“ 015: Acknowledge or claim responsibility
â€“ 016: Reject accusation or deny responsibility
â€“ 017: Engage in symbolic act
â€“ 018: Make empathetic comment
â€“ 019: Express accord
â€¢ 02: Appeal
â€“ 020: Make an appeal or request, not specified
â€“ 021: Appeal for material cooperation
â€“ 022: Appeal for diplomatic cooperation
â€“ 023: Appeal for material aid
â€“ 024: Appeal for political reform
â€“ 025: Appeal to yield
â€“ 026: Appeal to others to meet or negotiate
â€“ 027: Appeal to others to settle dispute
â€“ 028: Appeal to others to engage in or accept mediation
â€¢ 03: Express intent to cooperate
â€“ 030: Express intent to cooperate, not specified
â€“ 031: Express intent to engage in material cooperation
â€“ 032: Express intent to engage in diplomatic cooperation
â€“ 033: Express intent to provide material aid
â€“ 034: Express intent to institute political reform
â€“ 035: Express intent to yield
â€“ 036: Express intent to meet or negotiate
â€“ 037: Express intent to settle dispute
â€“ 038: Express intent to accept mediation
â€“ 039: Express intent to mediate
24

â€¢ 04: Consult
â€“ 040: Consult, not specified
â€“ 041: Discuss by telephone
â€“ 042: Make a visit
â€“ 043: Host a visit
â€“ 044: Meet at a third location
â€“ 045: Engage in mediation
â€“ 046: Engage in negotiation
â€¢ 05: Engage in diplomatic cooperation
â€“ 050:Engage in diplomatic cooperation, not specified
â€“ 051: Praise or endorse
â€“ 052: Defend verbally
â€“ 053: Rally support on behalf of
â€“ 054: Grant diplomatic recognition
â€“ 055: Apologize
â€“ 056: Forgive
â€“ 057: Sign formal agreement
â€¢ 06: Engage in material cooperation
â€“ 060: Engage in material cooperation, not specified
â€“ 061: Cooperate economically
â€“ 062: Cooperate militarily
â€“ 063: Engage in judicial cooperation
â€“ 064: Share intelligence or information
â€¢ 07: Provide aid
â€“ 070: Provide aid, not specified
â€“ 071: Provide economic aid
â€“ 072: Provide military aid
â€“ 073: Provide humanitarian aid
â€“ 074: Provide military protection or peacekeeping
â€“ 075: Grant asylum
â€¢ 08: Yield
â€“ 080: Yield, not specified
â€“ 081: Ease administrative sanctions
â€“ 082: Ease political dissent
â€“ 083: Accede to requests or demands for political reform
â€“ 084: Return or release
â€“ 085: Ease economic sanction or boycott or embargo
â€“ 086: Allow international involvement
â€“ 087: De-escalate military engagement
â€¢ 09: Investigate
â€“ 090: Investigate, not specified
â€“ 091: Investigate crime or corruption
â€“ 092: Investigate human rights abuses
â€“ 093: Investigate military action
â€“ 094: Investigate war crimes
â€¢ 10: Demand
â€“ 100: Demand, not specified
â€“ 101: Demand material cooperation
â€“ 102: Demand for diplomatic cooperation
â€“ 103: Demand material aid
25

â€“ 104: Demand political reform
â€“ 105: Demand that target yield
â€“ 106: Demand meeting or negotiation
â€“ 107: Demand settling of dispute
â€“ 108: Demand mediation
â€¢ 11: Disapprove
â€“ 110: Disapprove, not specified
â€“ 111: Criticize or denounce
â€“ 112: Accuse
â€“ 113: Rally opposition against
â€“ 114: Complain officially
â€“ 115: Bring lawsuit against
â€“ 116: Find guilty or liable (legally)
â€¢ 12: Reject
â€“ 120: All rejections and refusals
â€“ 121: Reject material cooperation
â€“ 122: Reject request or demand for material aid
â€“ 123: Reject request or demand for political reform
â€“ 124: Refuse to yield
â€“ 125: Reject proposal to meet or discuss or negotiate
â€“ 126: Reject mediation
â€“ 127: Reject plan or agreement to settle dispute
â€“ 128: Defy norms or law
â€“ 129: Veto
â€¢ 13: Threaten
â€“ 130: Threaten, not specified
â€“ 131: Threaten non-force
â€“ 132: Threaten with administrative sanctions
â€“ 133: Threaten political dissent
â€“ 134: Threaten to halt negotiations
â€“ 135: Threaten to halt mediation
â€“ 136: Threaten to halt international involvement
â€“ 137: Threaten with repression
â€“ 138: Threaten with military force
â€“ 139: Give ultimatum
â€¢ 14: Protest
â€“ 140: Engage in political dissent, not specified
â€“ 141: Demonstrate or rally
â€“ 142: Conduct hunger strike
â€“ 143: Conduct strike or boycott
â€“ 144: Obstruct passage or block
â€“ 145: Protest violently or riot
â€¢ 15: Exhibit military posture
â€“ 150: Exhibit military or police power, not specified
â€“ 151: Increase police alert status
â€“ 152: Increase military alert status
â€“ 153: Mobilize or increase police power
â€“ 154: Mobilize or increase armed forces
â€“ 155: Mobilize or increase cyber-forces
â€¢ 16: Reduce relations
26

â€“ 160: Reduce relations, not specified
â€“ 161: Reduce or break diplomatic relations
â€“ 162: Reduce or stop material aid
â€“ 163: Impose embargo or boycott or sanctions
â€“ 164: Halt negotiations
â€“ 165: Halt mediation
â€“ 166: Expel or withdraw
â€¢ 17: Coerce
â€“ 170: Coerce
â€“ 171: Seize or damage property
â€“ 172: Impose administrative sanctions
â€“ 173: Arrest or detain
â€“ 174: Expel or deport individuals
â€“ 175: Use repression
â€“ 176: Attack cybernetically
â€¢ 18: Assault
â€“ 180: Use unconventional violence, not specified
â€“ 181: Abduct or hijack or take hostage
â€“ 182: Physically assault
â€“ 183: Conduct suicide or car or other non-military bombing
â€“ 184: Use as human shield
â€“ 185: Attempt to assassinate
â€“ 186: Assassinate
â€¢ 19: Fight
â€“ 190: Use conventional military force, not specified
â€“ 191: Impose blockade or restrict movement
â€“ 192: Occupy territory
â€“ 193: Fight with small arms and light weapons
â€“ 194: Fight with artillery and tanks
â€“ 195: Employ aerial weapons
â€“ 196: Violate ceasefire
â€¢ 20: Engage in unconventional mass violence
â€“ 200: Use massive unconventional force, not specified
â€“ 201: Engage in mass expulsion
â€“ 202: Engage in mass killings
â€“ 203: Engage in ethnic cleansing
â€“ 204: Use weapons of mass destruction
27

F
Details of Dataset Construction
We construct the database based on the GDELT9 project, which systematically captures global news
media, extracts information about countries and events mentioned, and updates this data every 15
minutes. The data stored in GDLET contains attributes about the event date, actor, action (relation),
geography, and source news. The original GDELT dataset, while extensive, contains significant noise
due to its rapid update frequency and the diverse nature of its sources. We thus propose the folowing
data-cleaning pre-processing steps.
Events. We focus on the GDELT data from Jan. 1, 2023, to Nov. 30, 2023. To mitigate potential
information leakage, we ensured that the event date coincided exactly with its source news publish
date. We standardized the CountryCode to the ISO-3166 and excluded any missing or outdated
entries. As our analysis was restricted to international events, we then filte out all domestic events
where the subject was identical to the object at the country level. The EventCode was standardized
to the second level of the CAMEO ontology, providing a specific yet consistent level of detail. We
opted not to include third-level relation information for two primary reasons: the absence of sublevel
relations for all second-level categories, which introduces inconsistencies, and the higher likelihood
of extraction errors in the finely detailed third-level data in the GDELT dataset.
News articles. To enhance the reliability of the information, we utilized the news sources of the events
to assess credibility. Specifically, we calculated the daily mentions of each eventâ€”defined as the
number of distinct news sources discussing the eventâ€”based on the 15-minute updates from GDELT.
We only retained events with at least 50 daily mentions to diminish the influence of less reliable
sources, such as personal blogs or advertisements, and to decrease the incidence of erroneously
extracted events. We then download the news documents from the corresponding news URLs of each
event. In the current database, we only keep textual information from the news, including new titles
and news content. Following the OBELICS [34] protocol for web text cleaning, we applied rigorous
filters at both the paragraph and document levels, targeting criteria such as a low number of words,
high repetition ratios of characters and words, and an excessive presence of special characters and
flagged words. These measures were crucial in significantly reducing the noise from web content.
G
Term of Use for GDELT Dataset
Based on https://www.gdeltproject.org/about.html#termsofuse, GDELT dataset â€œis an
open platform for research and analysis of global society and thus all datasets released by the
GDELT Project are available for unlimited and unrestricted use for any academic, commercial, or
governmental use of any kind without fee.â€, as long as â€œany use or redistribution of the data must
include a citation to the GDELT Project and a link to this website (https: // www. gdeltproject.
org/ ).â€, which weâ€™ve cited in abstract.
H
Broader Impact
Positive impact.
This paper aims to construct high-level and high-quality instruction to improve the
scientific reasoning capability of LLMs, which helps LLMs to better give the answers to questions at
the college level. Collecting diverse instructions, annotating self-reflective instructions, and filtering
out low-quality instructions provide researchers insights to prepare training datasets.
Negative impact.
A drawback of this work is that the scale of the training dataset and model is
relatively small, and we can address this by bootstrapping a more large training dataset. We believe
that the benefits of data generation manner outweigh the downside.
I
Additional Details about Agent Setup
Final answer extraction. Our agent has two stopping criteria: 1) The agent makes the final answer. 2)
The reasoning process fails to reach an answer (Consecutive Invalid Actions, Consecutive Repetitive
Actions, or Max Iterations Exceeded). Afterwards, we always perform an answer extraction step,
which is performed by gpt-3.5-turbo. The prompt for answer extraction is shown in Appendix
K.3.
9https://www.gdeltproject.org/
28

J
Additional Experimental Results and Analysis
J.1
Analysis of the Final Status of Different LLM Agents
Table 6: Average number of ReAct iterations and the number of test cases ending in different final
status.
Model
Training Data
Cutoff Date
Action Type
Avg. Iterations
Final Status
Final Answer
Consecutive
Invalid Actions
Consecutive
Repetitive Actions
Max Iterations
Exceeded
Mistral-7B
â€”
Single Function
4.23
79
19
2
0
Code Block
2.84
54
45
1
0
gpt-3.5-turbo
2021-09
Single Function
2.54
98
1
1
0
Code Block
3.43
84
15
1
0
gpt-4-turbo
2023-12
Single Function
8.76
99
0
1
0
Code Block
4.68
93
5
2
0
gpt-4o
2023-10
Single Function
8.79
98
0
0
2
Code Block
5.58
95
4
1
0
Following the experiment on different base LLMs in Sec. 3.2, we further analyze the final status of
the agent when it triggers the termination conditions in the ReAct process. The agent-environment
interactions were terminated based on four different statuses:
â€¢ Final Answer: This status is triggered when the model explicitly indicates completion by declaring
a "final answer," indicating that it has generated its final forecast.
â€¢ Consecutive Invalid Actions: Interaction is halted if the model consecutively executes non-
executable actions more than three times.
â€¢ Consecutive Repetitive Actions: A similar threshold of three consecutive repetitive actions prompts
termination under this status.
â€¢ Maximum Iterations Exceeded: Termination occurs if the agent engages in more than 20 rounds of
iterations without making a forecast answer.
We show the final status 1) The GPT series demonstrates enhanced capability in concluding
interactions with a final answer: The GPT series frequently concludes interactions with a final
answer, indicating its superior ability to comprehend instructions, utilize tools correctly, and perform
reasoning to generate the final forecast. In contrast, the smaller open-source model, Mistral-7b, has a
round one-quarter of cases and one-half of the cases generating consecutive invalid answers when
using single function and code block, respectively, suggesting limited abilities in adhering to data
types, functions, Python syntax, and following detailed instructions.
2) Generating code blocks proves more challenging than generating single functions as action:
Across all models, there is a higher occurrence of errors when generating code blocks compared to
single functions. This pattern highlights the greater complexity and increased likelihood of errors
associated with composing multiple lines of code over simple function calls.
3) Advanced models engage in more extensive information gathering, resulting in better fore-
casting performance: Advanced models, such as GPT-4 Turbo and GPT-4o, engage in significantly
more information gathering, with average iterations much more or even double than GPT-3.5 Turbo
and Mistral-7B. This intensive data collection from the database may contribute to their enhanced
performance, as previously illustrated in Table 2. These models exhibit better planning capability,
effectively identifying and searching for related historical information.
J.2
Analysis on Function Types
29

Figure 8: Correlation of F1 Accuracy to Action Sequence Length
30

K
Prompts
K.1
System Prompts
The system prompt provides the necessary background information, task description, and guidelines
for the LLM agent. In our case, we introduce the forecasting task, basic information of the database,
the defined API, and the planning strategies in the system prompt.
K.1.1
System Prompt for ReAct Agent with Action Type as â€œSingle Functionâ€
System prompt for ReAct agent with action type as single function (part 1)
You are an expert in forecasting future events based on historical data. The database contains
news articles from January 1, 2023 to the current date {current_date_nlp} and the events
extracted from these articles. The events are in the form of (date, subject country, relation,
object country), where the countries are represented by ISO 3166-1 alpha-3 codes and the
relations are represented by the CAMEO codes defined in the â€˜Conflict and Mediation Event
Observationsâ€™ ontology. The relations are hierarchical: first-level relations are general parent
relations represented by two-digit CAMEO codes, while second-level relations are more
specific child relations represented by three-digit CAMEO codes. Child relations have the
same first two digits as their parent relations. For example, â€˜01â€™ is a first-level relation, and
â€˜010â€™ and â€˜011â€™ are some of its second-level relations. The relations in the database are
represented in the second-level form.
Your task is to forecast the future relations between two entities in a given query. You have
access to a defined Python API that allows you to query the database for historical events and
statistics, and to get precise information about the ISO country codes and CAMEO relation
codes.
The defined API is described as follows:
```python
{api_description}
```
You will use an iterative approach, interleaving â€™Thoughtâ€™, â€™Actionâ€™, and â€™Observationâ€™ steps
to collect information and perform the forecast. You may perform up to {max_iterations}
iterations. The steps are as follows:
- â€˜Thoughtâ€™: Analyze the current information and reason about the current situation, and
predicts which API you want to use (try to use different APIs to collect diverse information)
or make a decision that you want to make a final answer.
- â€˜Actionâ€™: Use the API to gather more information or provide the final forecast.
- If using the API: the action must be only one single line of exactly one function
call from the API with appropriate inputs, without additional code, explanations, or
natural language descriptions.
- If making the final forecast: the action must start immediately with â€˜Final Answer:â€™,
and follow with the results in the expected JSON format.
- â€˜Observationâ€™: Return the output of the called function.
To make a reasonable forecast, you should collect both news and relational evidence to support
your prediction. When you are fully confident that you accumulate enough information to
make the final forecast, you should start the â€˜Thoughtâ€™ with your reasoning using the news
and structural information to make the prediction, and then start the â€˜Actionâ€™ step with â€˜Final
Answer:â€™ followed by the answer in the expected JSON format. The answer should be a
JSON dictionary where the keys are the forecasted two-digit first-level CAMEO codes and the
values are lists of forecasted three-digit second-level CAMEO codes that are child relations
of the key. For example, â€˜Action: Final Answer: "01": ["010", "011", "012"], "02": ["020",
"023"]â€™.
31

System prompt for ReAct agent with action type as single function (part 2)
The final answer will be evaluated based on the precision and recall of the forecasted
first-level and second-level relations, so only include confident first-level and second-level
CAMEO codes in your final forecast.
Try to use different APIs to collect diverse information (including multi-hop relations), such
as the precise meaning of CAMEO codes, insights from news content, relational data, and
statistical analyses to support your forecasts. Consider not only the frequency of the relations
but also the temporal aspects of the data when making your forecast.
K.1.2
System Prompt for ReAct Agent with Action Type as â€œCode Blockâ€
System prompt for ReAct agent with action type as code block (part 1)
You are an expert in forecasting future events based on historical data. The database contains
news articles from January 1, 2023 to the current date {current_date_nlp} and the events
extracted from these articles. The events are in the form of (date, subject country, relation,
object country), where the countries are represented by ISO 3166-1 alpha-3 codes and the
relations are represented by the CAMEO codes defined in the â€˜Conflict and Mediation Event
Observationsâ€™ ontology. The relations are hierarchical: first-level relations are general parent
relations represented by two-digit CAMEO codes, while second-level relations are more
specific child relations represented by three-digit CAMEO codes. Child relations have the
same first two digits as their parent relations. For example, â€˜01â€™ is a first-level relation, and
â€˜010â€™ and â€˜011â€™ are some of its second-level relations. The relations in the database are
represented in the second-level form.
Your task is to forecast the future relations between two entities in a given query. You have
access to a defined Python API that allows you to query the database for historical events
and statistics, and to get precise information about the ISO country codes and CAMEO
relation codes. You are also authorized to utilize additional safe, well-established Python
libraries such as numpy, pandas, scikit-learn, and NetworkX to enhance your data analysis
and forecasting accuracy.
The defined API is described as follows:
``` python
{api_description}
```
You will use an iterative approach, interleaving â€˜Thoughtâ€™, â€˜Actionâ€™, and â€˜Observationâ€™ steps
to collect information and perform the forecast. You may perform up to max_iterations
iterations. The steps are as follows:
- â€˜Thoughtâ€™: Analyze the current information and reason about the current situation, and
predicts which API you want to use (try to use different APIs to collect diverse information)
or make a decision that you want to make a final answer.
- â€˜Actionâ€™: Use the API to gather more information or provide the final forecast.
- If gathering more data: the action must be an executable Python code snippet that
starts with â€˜```pythonâ€™ and ends with â€˜```â€™. It can contain multiple lines of codes and
function calls using the defined API or Python libraries. You must use print() to output
the results, and only the printed output will be returned in the observation step.
- If making the final forecast: the action must start immediately with â€˜Final Answer:â€™,
and follow with the answer in the expected JSON format. This should not be enclosed
within triple backticks.
- â€˜Observationâ€™: Return the printed output of the executed code snippet.
32

System prompt for ReAct agent with action type as code block (part 2)
To make a reasonable forecast, you should collect both news and relational evidence
to support your prediction. When you are fully confident that you accumulate enough
information to make the final forecast, you should start the â€˜Thoughtâ€™ with your reasoning
using the news and structural information to make the prediction, and then start the â€˜Actionâ€™
step with â€˜Final Answer:â€™ followed by the answer in the expected JSON format. The answer
should be a JSON dictionary where the keys are the forecasted two-digit first-level CAMEO
codes and the values are lists of forecasted three-digit second-level CAMEO codes that are
child relations of the key. For example, â€˜Action: Final Answer: {"01": ["010", "011", "012"],
"02": ["020", "023"]}â€™.
The final answer will be evaluated based on the precision and recall of the forecasted
first-level and second-level relations, so only include confident first-level and second-level
CAMEO codes in your final forecast.
Try to use different APIs and Python libraries to collect diverse information (including
multi-hop relations), such as the precise meaning of CAMEO codes, insights from news
content, relational data, and statistical analyses to support your forecasts. Consider not only
the frequency of the relations but also the temporal aspects of the data when making your
forecast.
K.1.3
System Prompt for Direct Agent
System prompt for direct agent
You are an expert in forecasting future events based on historical data. The events are in the
form of (date, subject country, relation, object country), where the countries are represented
by ISO 3166-1 alpha-3 codes and the relations are represented by the CAMEO codes defined
in the â€˜Conflict and Mediation Event Observationsâ€™ ontology. The relations are hierarchical:
first-level relations are general parent relations represented by two-digit CAMEO codes,
while second-level relations are more specific child relations represented by three-digit
CAMEO codes. Child relations have the same first two digits as their parent relations. For
example, â€˜01â€™ is a first-level relation, and â€˜010â€™ and â€˜011â€™ are some of its second-level
relations. The relations in the database are represented in the second-level form.
Your task is to forecast the future relations between two entities in a given query. The answer
should be a JSON dictionary where the keys are the forecasted two-digit first-level CAMEO
codes and the values are lists of forecasted three-digit second-level CAMEO codes that are
child relations of the key. For example, â€˜Final Answer: {{â€œ01â€: [â€œ010â€, â€œ011â€, â€œ012â€], â€œ02â€:
[â€œ020â€, â€œ023â€]}}â€™.
The final answer will be evaluated based on the precision and recall of the forecasted first-level
and second-level relations, so only include confident first-level and second-level CAMEO
codes in your final forecast.
33

K.1.4
System Prompt for CoT Agent
System prompt for CoT
You are an expert in forecasting future events based on historical data. The events are in the
form of (date, subject country, relation, object country), where the countries are represented
by ISO 3166-1 alpha-3 codes and the relations are represented by the CAMEO codes defined
in the â€˜Conflict and Mediation Event Observationsâ€™ ontology. The relations are hierarchical:
first-level relations are general parent relations represented by two-digit CAMEO codes,
while second-level relations are more specific child relations represented by three-digit
CAMEO codes. Child relations have the same first two digits as their parent relations. For
example, â€˜01â€™ is a first-level relation, and â€˜010â€™ and â€˜011â€™ are some of its second-level
relations. The relations in the database are represented in the second-level form.
Your task is to forecast the future relations between two entities in a given query. To make
a reasonable forecast, you should first think and reason based on your background
knowledge. When you are confident that you have conducted enough analysis to make
the final answer, you should start answering by â€™Therefore, the final answer is:â€˜ followed by
the answer in the expected JSON format. The JSON format should be a JSON dictionary
where the keys are the forecasted two-digit first-level CAMEO codes and the values are lists
of forecasted three-digit second-level CAMEO codes that are child relations of the key. For
example, â€˜{{â€œ01â€: [â€œ010â€, â€œ011â€, â€œ012â€], â€œ02â€: [â€œ020â€, â€œ023â€]}}â€™.
The final answer will be evaluated based on the precision and recall of the forecasted first-level
and second-level relations, so only include confident first-level and second-level CAMEO
codes in your final forecast.
K.2
Query Prompt
Query prompt
Please
forecast
the
relations
that
{actor1_name}
will
take
towards
{ac-
tor2_name}
on
{future_date_nlp}
based
on
historical
information
up
to
{cur-
rent_date_nlp}.
I.e.
forecast
the
relation
CAMEO
codes
in
query
event
Event(date={future_date}, head_entity=ISOCode({actor1_code}), relation=CAMEOCode(?),
tail_entity=ISOCode({actor2_code})).
34

K.3
Answer Extraction Prompt
Answer extraction prompt
Please help me extract final answer for forecasting the future relations between
two entities in a given query:
forecast the relations that {actor1_name} will take
towards {actor2_name} on {future_date_nlp} based on historical information up
to current_date_nlp.
I.e.
forecast the relation CAMEO codes in query event
Event(date={future_date}, head_entity=ISOCode({actor1_code}), relation=CAMEOCode(?),
tail_entity=ISOCode({actor2_code})).
I have used interleaving â€˜Thoughtâ€™, â€˜Actionâ€™, and â€˜Observationâ€™ steps to collect information
from the database and perform the forecast. The database contains news articles from January
1, 2023 to the current date current_date_nlp and the events extracted from these articles.
The events are in the form of (date, subject country, relation, object country), where the
countries are represented by ISO 3166-1 alpha-3 codes and the relations are represented by
the CAMEO codes defined in the â€˜Conflict and Mediation Event Observationsâ€™ ontology.
The relations are hierarchical: first-level relations are general parent relations represented
by two-digit CAMEO codes, while second-level relations are more specific child relations
represented by three-digit CAMEO codes. Child relations have the same first two digits as
their parent relations. For example, â€˜01â€™ is a first-level relation, and â€˜010â€™ and â€˜011â€™ are some
of its second-level relations. The relations in the database are represented in the second-level
form.
The final forecast answer need to forecast both first-level and second-level CAMEO codes,
and will be evaluated based on the precision and recall of both levels of relations. The final
answer content should be a JSON dictionary where the keys are the forecasted two-digit
first-level CAMEO codes and the values are lists of forecasted three-digit second-level
CAMEO codes that are child relations of the key. For example, {{â€œ01â€: [â€œ010â€, â€œ011â€,
â€œ012â€], â€œ02â€: [â€œ020â€, â€œ023â€]}}.
The latest information and forecast I have collected is as follows:
{info}
If final forecast answer has been made in the collected information indicated by "Final
Answer:", you must only reformat the final forecast answer in the expected JSON dictionary
format inside XML tags. For example: <answer>{{â€œ01â€: [â€œ010â€, â€œ011â€, â€œ012â€], â€œ02â€:
[â€œ020â€, â€œ023â€]}}</answer>.
Otherwise, if no final forecast is made, you must reason based on the information you have
collected and generate a confident final forecast answer to the query, and then reformat your
answer in the expected JSON dictionary format inside XML tags.
35

L
Additional Forecasting Examples of LLM Agent
In this section, we show examples of how LLM agents perform reasoning for the forecasting query.
The query-specific values are highlighted in yellow in the system prompt and query prompt, which
follows the prompt templates shown in Appendix K. For simplicity, we use {api_description} as
a placeholder for the API specification in the prompt, which is replaced by the actual contents shown
in Appendix M in experiments.
L.1
GPT-4o-based Agent with ReAct and â€œCode Blockâ€ Action
L.1.1
Query Details
â€¢ Query Quadruplet: (2023-11-03, AUS, ?, CHN)
â€¢ Temporal Distance: 1; therefore, the current date is 2023-11-02
â€¢ Agent Max Steps: 20
L.1.2
Query Prompt
Please forecast the relations that Australia will take towards China on November 03, 2023 based
on historical information up to November 02, 2023. I.e. forecast the relation CAMEO codes
in query event Event(date=2023-11-03, head_entity=ISOCode(AUS), relation=CAMEOCode(?),
tail_entity=ISOCode(CHN)).
L.1.3
System Prompt
You are an expert in forecasting future events based on historical data. The database contains news
articles from January 1, 2023 to the current date November 02, 2023 and the events extracted from
these articles. The events are in the form of (date, subject country, relation, object country), where
the countries are represented by ISO 3166-1 alpha-3 codes and the relations are represented by the
CAMEO codes defined in the "Conflict and Mediation Event Observations" ontology. The relations
are hierarchical: first-level relations are general parent relations represented by two-digit CAMEO
codes, while second-level relations are more specific child relations represented by three-digit
CAMEO codes. Child relations have the same first two digits as their parent relations. For example,
"01" is a first-level relation, and "010" and "011" are some of its second-level relations. The relations
in the database are represented in the second-level form.
Your task is to forecast the future relations between two entities in a given query.
You
have access to a defined Python API that allows you to query the database for historical events and
statistics, and to get precise information about the ISO country codes and CAMEO relation codes.
You are also authorized to utilize additional safe, well-established Python libraries such as numpy,
pandas, scikit-learn, and NetworkX to enhance your data analysis and forecasting accuracy.
The defined API is described as follows:
``` python
{api_description}
```
You will use an iterative approach, interleaving "Thought", "Action", and "Observation"
steps to collect information and perform the forecast. You may perform up to 20 iterations. The steps
are as follows:
- "Thought":
Analyze the current information and reason about the current situation, and
predicts which API you want to use (try to use different APIs to collect diverse information) or make
a decision that you want to make a final answer.
- "Action": Use the API to gather more information or provide the final forecast.
- If gathering more data: the action must be an executable Python code snippet that starts with
```python and ends with ```. It can contain multiple lines of codes and function calls using the
defined API or Python libraries. You must use print() to output the results, and only the printed output
will be returned in the observation step.
- If making the final forecast: the action must start immediately with "Final Answer:", and follow
with the answer in the expected JSON format. This should not be enclosed within triple backticks.
- "Observation": Return the printed output of the executed code snippet.
36

To make a reasonable forecast, you should collect both news and relational evidence to
support your prediction. When you are fully confident that you accumulate enough information
to make the final forecast, you should start the "Thought" with your reasoning using the news
and structural information to make the prediction, and then start the "Action" step with "Final
Answer:" followed by the answer in the expected JSON format.
The answer should be a
JSON dictionary where the keys are the forecasted two-digit first-level CAMEO codes and
the values are lists of forecasted three-digit second-level CAMEO codes that are child relations
of the key. For example, "Action: Final Answer: {"01": ["010", "011", "012"], "02": ["020", "023"]}".
The final answer will be evaluated based on the precision and recall of the forecasted first-
level and second-level relations, so only include confident first-level and second-level CAMEO codes
in your final forecast.
Try to use different APIs and Python libraries to collect diverse information (including
multi-hop relations), such as the precise meaning of CAMEO codes, insights from news content,
relational data, and statistical analyses to support your forecasts. Consider not only the frequency of
the relations but also the temporal aspects of the data when making your forecast.
L.1.4
Agent ReAct Process
1. Thought: To forecast the relations that Australia will take towards China on November 03, 2023,
we need to gather historical data on the interactions between these two countries. This includes
examining the frequency and types of relations observed in the past, as well as any recent trends
or significant events that might influence future relations.
We will proceed with the following steps:
(a) Retrieve Historical Events: Gather events involving Australia (AUS) and China (CHN) to
understand the context and types of relations that have occurred in the past.
(b) Analyze Relation Distribution: Analyze the distribution of different CAMEO codes in these
events to identify the most common types of interactions.
(c) Examine Recent Trends: Focus on recent events to detect any emerging trends or shifts in
relations.
(d) Contextual Analysis: Review news articles to gain insights into the context and underlying
reasons for these relations.
Let"s start by retrieving historical events between Australia and China.
Action:
1 from
datetime
import
datetime
2
3 # Define
the
date
range
for the
historical
data
collection
4
start_date = Date("2023 -01 -01")
5
end_date = Date("2023 -11 -02")
6
date_range = DateRange(start_date =start_date , end_date=end_date)
7
8 # Define
the ISO
codes
for
Australia
and
China
9
aus_code = ISOCode("AUS")
10
chn_code = ISOCode("CHN")
11
12 # Retrieve
historical
events
involving
Australia
and
China
13
events = get_events(date_range=date_range , head_entities =[ aus_code], tail_entities =[
chn_code ])
14
15 # Print
the
retrieved
events
16 for
event in events:
17
print(event)
Observation:
1
Event(date=Date("2023 -11 -02"), head_entity =ISOCode("AUS"), relation=CAMEOCode("042"),
tail_entity=ISOCode("CHN"))
2
Event(date=Date("2023 -11 -02"), head_entity =ISOCode("AUS"), relation=CAMEOCode("040"),
tail_entity=ISOCode("CHN"))
3
Event(date=Date("2023 -11 -02"), head_entity =ISOCode("AUS"), relation=CAMEOCode("036"),
tail_entity=ISOCode("CHN"))
4
Event(date=Date("2023 -11 -01"), head_entity =ISOCode("AUS"), relation=CAMEOCode("042"),
tail_entity=ISOCode("CHN"))
37

5
Event(date=Date("2023 -11 -01"), head_entity =ISOCode("AUS"), relation=CAMEOCode("173"),
tail_entity=ISOCode("CHN"))
6
Event(date=Date("2023 -11 -01"), head_entity =ISOCode("AUS"), relation=CAMEOCode("036"),
tail_entity=ISOCode("CHN"))
7
Event(date=Date("2023 -10 -31"), head_entity =ISOCode("AUS"), relation=CAMEOCode("036"),
tail_entity=ISOCode("CHN"))
8
Event(date=Date("2023 -10 -31"), head_entity =ISOCode("AUS"), relation=CAMEOCode("042"),
tail_entity=ISOCode("CHN"))
9
Event(date=Date("2023 -10 -31"), head_entity =ISOCode("AUS"), relation=CAMEOCode("046"),
tail_entity=ISOCode("CHN"))
10
Event(date=Date("2023 -10 -30"), head_entity =ISOCode("AUS"), relation=CAMEOCode("036"),
tail_entity=ISOCode("CHN"))
11
Event(date=Date("2023 -10 -30"), head_entity =ISOCode("AUS"), relation=CAMEOCode("042"),
tail_entity=ISOCode("CHN"))
12
Event(date=Date("2023 -10 -30"), head_entity =ISOCode("AUS"), relation=CAMEOCode("046"),
tail_entity=ISOCode("CHN"))
13
Event(date=Date("2023 -10 -29"), head_entity =ISOCode("AUS"), relation=CAMEOCode("036"),
tail_entity=ISOCode("CHN"))
14
Event(date=Date("2023 -10 -27"), head_entity =ISOCode("AUS"), relation=CAMEOCode("036"),
tail_entity=ISOCode("CHN"))
15
Event(date=Date("2023 -10 -27"), head_entity =ISOCode("AUS"), relation=CAMEOCode("042"),
tail_entity=ISOCode("CHN"))
16
Event(date=Date("2023 -10 -26"), head_entity =ISOCode("AUS"), relation=CAMEOCode("173"),
tail_entity=ISOCode("CHN"))
17
Event(date=Date("2023 -10 -26"), head_entity =ISOCode("AUS"), relation=CAMEOCode("061"),
tail_entity=ISOCode("CHN"))
18
Event(date=Date("2023 -10 -26"), head_entity =ISOCode("AUS"), relation=CAMEOCode("042"),
tail_entity=ISOCode("CHN"))
19
Event(date=Date("2023 -10 -25"), head_entity =ISOCode("AUS"), relation=CAMEOCode("042"),
tail_entity=ISOCode("CHN"))
20
Event(date=Date("2023 -10 -23"), head_entity =ISOCode("AUS"), relation=CAMEOCode("042"),
tail_entity=ISOCode("CHN"))
21
Event(date=Date("2023 -10 -23"), head_entity =ISOCode("AUS"), relation=CAMEOCode("036"),
tail_entity=ISOCode("CHN"))
22
Event(date=Date("2023 -10 -23"), head_entity =ISOCode("AUS"), relation=CAMEOCode("031"),
tail_entity=ISOCode("CHN"))
23
Event(date=Date("2023 -10 -23"), head_entity =ISOCode("AUS"), relation=CAMEOCode("061"),
tail_entity=ISOCode("CHN"))
24
Event(date=Date("2023 -10 -22"), head_entity =ISOCode("AUS"), relation=CAMEOCode("040"),
tail_entity=ISOCode("CHN"))
25
Event(date=Date("2023 -10 -22"), head_entity =ISOCode("AUS"), relation=CAMEOCode("061"),
tail_entity=ISOCode("CHN"))
26
Event(date=Date("2023 -10 -22"), head_entity =ISOCode("AUS"), relation=CAMEOCode("036"),
tail_entity=ISOCode("CHN"))
27
Event(date=Date("2023 -10 -22"), head_entity =ISOCode("AUS"), relation=CAMEOCode("043"),
tail_entity=ISOCode("CHN"))
28
Event(date=Date("2023 -10 -22"), head_entity =ISOCode("AUS"), relation=CAMEOCode("042"),
tail_entity=ISOCode("CHN"))
29
Event(date=Date("2023 -10 -21"), head_entity =ISOCode("AUS"), relation=CAMEOCode("042"),
tail_entity=ISOCode("CHN"))
30
Event(date=Date("2023 -10 -21"), head_entity =ISOCode("AUS"), relation=CAMEOCode("040"),
tail_entity=ISOCode("CHN"))
2. Thought: The retrieved events indicate a variety of relations between Australia and China. To
forecast the future relations, we need to analyze the distribution of these relations to identify the
most common types and any recent trends.
Next, we will analyze the distribution of the different CAMEO codes in these events to identify
the most frequent interactions. This will help us understand the dominant types of relations and
any emerging patterns.
Action:
1 from
collections
import
Counter
2
3 # Extract
the
CAMEO
codes
from
the
retrieved
events
4
cameo_codes = [event.relation.code
for
event in events]
5
6 # Count
the
frequency
of each
CAMEO
code
7
cameo_code_counts = Counter(cameo_codes )
8
9 # Print
the
distribution
of CAMEO
codes
10 for code , count in
cameo_code_counts .items ():
11
print(f"CAMEO
Code: {code}, Count: {count}")
Observation:
1
CAMEO
Code: 042, Count: 10
2
CAMEO
Code: 040, Count: 3
38

3
CAMEO
Code: 036, Count: 8
4
CAMEO
Code: 173, Count: 2
5
CAMEO
Code: 046, Count: 2
6
CAMEO
Code: 061, Count: 3
7
CAMEO
Code: 031, Count: 1
8
CAMEO
Code: 043, Count: 1
3. Thought: The distribution of CAMEO codes from the historical events between Australia and
China reveals that certain types of interactions are more frequent than others. Specifically, the
most common relations are:
- 042: 10 occurrences
- 036: 8 occurrences
- 040: 3 occurrences
- 061: 3 occurrences
- 046: 2 occurrences
- 173: 2 occurrences
- 031: 1 occurrence
- 043: 1 occurrence
To make a more informed forecast, we should understand what these CAMEO codes represent.
We will map these codes to their descriptions to gain insights into the nature of these interactions.
Action:
1 # Define
the
CAMEO
codes to map
2
cameo_codes_to_map = ["042", "036", "040", "061", "046", "173", "031", "043"]
3
4 # Map the
CAMEO
codes to their
descriptions
5
relations = [ map_cameo_to_relation (CAMEOCode(code)) for
code in
cameo_codes_to_map ]
6
7 # Print
the
descriptions
of the
CAMEO
codes
8 for
relation
in
relations:
9
print(f"CAMEO
Code: {relation. cameo_code .code}, Name: {relation.name}, Description
: {relation.description }")
Observation:
1
CAMEO
Code: 042, Name: Make a visit , Description : Travel
to
another
location
for a
meeting
or other
event.
2
CAMEO
Code: 036, Name: Express
intent to meet or negotiate , Description : Offer ,
promise , agree to , or
otherwise
indicate
willingness
or
commitment
to meet , visit
, or engage in talks or
negotiations .
3
CAMEO
Code: 040, Name: Consult , not
specified , Description : All
consultations
and
meetings , not
otherwise
specified.
4
CAMEO
Code: 061, Name: Cooperate
economically , Description : Initiate , resume , improve ,
or expand
economic
exchange
or
cooperation .
5
CAMEO
Code: 046, Name: Engage in negotiation , Description : Negotiate
or
bargain
with
others.
6
CAMEO
Code: 173, Name: Arrest or detain , Description : Legal or
extrajudicial
arrests ,
detentions , or
imprisonments .
7
CAMEO
Code: 031, Name: Express
intent to
engage in
material
cooperation , Description :
Offer , promise , agree to , or
otherwise
indicate
willingness
or
commitment
to
engage
in or
expand
material
cooperative
exchange , such as
express
intent to
cooperate
economically , militarily , on
judicial
matters , and on
intelligence .
8
CAMEO
Code: 043, Name: Host a visit , Description : Host or
receive a visitor
at
residence , office
or home
country.
4. Thought: The mapped CAMEO codes and their descriptions provide valuable insights into the
nature of interactions between Australia and China. Here are the key relations observed:
- 042 (Make a visit): 10 occurrences â€“ Indicates frequent travel for meetings or events.
- 036 (Express intent to meet or negotiate): 8 occurrences â€“ Shows a strong intent to engage in
talks or negotiations.
- 040 (Consult, not specified): 3 occurrences â€“ General consultations and meetings.
- 061 (Cooperate economically): 3 occurrences â€“ Economic cooperation initiatives.
- 046 (Engage in negotiation): 2 occurrences â€“ Actual negotiations or bargaining.
- 173 (Arrest or detain): 2 occurrences â€“ Legal or extrajudicial arrests or detentions.
- 031 (Express intent to engage in material cooperation): 1 occurrence â€“ Intent to cooperate
materially.
- 043 (Host a visit): 1 occurrence â€“ Hosting visitors.
39

Given this data, we can see that the most frequent interactions involve visits, expressions of intent
to meet or negotiate, and economic cooperation. These interactions suggest a pattern of diplomatic
engagement and economic collaboration, with occasional legal actions.
To further solidify our forecast, we should examine recent news articles to understand the context
and any underlying reasons for these interactions. This will help us identify any emerging trends
or significant events that might influence future relations.
Next, we will retrieve recent news articles involving Australia and China to gain contextual
insights.
Action:
1 # Define
the
date
range
for
recent
news
articles
2
recent_start_date = Date("2023 -10 -01")
3
recent_end_date = Date("2023 -11 -02")
4
recent_date_range = DateRange(start_date =recent_start_date , end_date= recent_end_date )
5
6 # Retrieve
recent
news
articles
involving
Australia
and
China
7
news_articles = get_news_articles ( date_range =recent_date_range , head_entities =[
aus_code], tail_entities =[ chn_code ])
8
9 # Print
the
retrieved
news
articles
10 for
article
in
news_articles :
11
print(article)
Observation:
1 (Date(date="2023 -11 -02"), "No quick
fix to
remaining
tariffs
ahead of China
visit")
2 (Date(date="2023 -11 -02"), "China"s aggression
in Indo -Pacific
leads to "concern
and
angst": Peter
Dutton , Australia"s leader of
opposition ")
3 (Date(date="2023 -11 -02"), "Australia
and
China
eye new
ways to heal
old
wounds")
4 (Date(date="2023 -11 -02"), "Albanese
must
aim
beyond
bilateral
outcomes
on
Beijing
visit")
5 (Date(date="2023 -11 -02"), "Western
Australian
Premier
Announces
Visit to China")
6 (Date(date="2023 -11 -02"), "Australian
PM"s China
visit
will
help
normalize
relations ,
says ex -trade
minister")
7 (Date(date="2023 -11 -02"), "Nicholas
Moore on how to get in early on the
next
big
growth
story")
8 (Date(date="2023 -11 -02"), "PM"s China
trip
cements
new era for
ties")
9 (Date(date="2023 -11 -02"), "PM to take a hard
line on trade
with
China")
10 (Date(date="2023 -11 -01"), "Australian
Prime
Minister
Anthony
Albanese
to raise
imprisoned
democracy
blogger
during
China
visit")
5. Thought: The recent news articles provide valuable context for the relations between Australia
and China. Key themes include:
1. Diplomatic Visits and Engagements: Multiple articles highlight the upcoming visit of
Australian Prime Minister Anthony Albanese to China. This aligns with the frequent occurrence
of CAMEO code 042 (Make a visit).
2. Economic Cooperation and Trade: Discussions around trade and economic cooperation are
prominent, indicating ongoing efforts to improve economic ties. This supports the relevance of
CAMEO codes 061 (Cooperate economically) and 036 (Express intent to meet or negotiate).
3. Concerns and Tensions: Articles mention concerns about China"s aggression in the Indo-
Pacific and human rights issues, suggesting underlying tensions. This is reflected in the occasional
occurrence of CAMEO code 173 (Arrest or detain).
Given the historical data and recent news context, the most likely relations that Australia will
take towards China on November 03, 2023, include diplomatic visits, economic cooperation, and
negotiations, with a possibility of addressing underlying tensions.
Final Answer:
1 {
2
"03": ["031", "036"],
3
"04": ["040", "042", "043", "046"],
4
"06": ["061"],
5
"17": ["173"]
6 }
Action: Final Answer:
1 {
2
"03": ["031", "036"],
40

3
"04": ["040", "042", "043", "046"],
4
"06": ["061"],
5
"17": ["173"]
6 }
L.1.5
Agent Final Status
â€¢ End State: Final Answer
â€¢ Number of Steps Taken: 5
â€¢ Final Answer:
1 {
2
"03": ["031", "036"],
3
"04": ["040", "042", "043", "046"],
4
"06": ["061"],
5
"17": ["173"]
6 }
We show the corresponding relation names of the predicted codes here for a better review:
1 {
2
"Express
intent to
cooperate": ["Express
intent to
engage in
material
cooperation ", "
Express
intent to meet or
negotiate"],
3
"Consult": ["Consult , not
specified", "Make a visit", "Host a visit", "Engage in
negotiation"],
4
"Engage in
material
cooperation ": ["Cooperate
economically "],
5
"Coerce": ["Arrest
or detain"]
6 }
â€¢ Ground Truth Answer:
1 {
2
"03": ["036"],
3
"04": ["042"],
4
"17": ["172"]
5 }
We show the corresponding relation names of the ground-truth codes here for a better review:
1 {
2
"Express
intent to
cooperate": ["Express
intent to meet or
negotiate"],
3
"Consult": ["Make a visit"],
4
"Coerce": ["Impose
administrative
sanctions"]
5 }
L.2
GPT-4o-based Agent with ReAct and â€œSingle Functionâ€ Action
L.2.1
Query Details
â€¢ Query Quadruplet: (2023-11-03, AUS, ?, CHN)
â€¢ Temporal Distance: 1; therefore, the current date is 2023-11-02
â€¢ Agent Max Steps: 20
L.2.2
Query Prompt
Please forecast the relations that Australia will take towards China on November 03, 2023 based
on historical information up to November 02, 2023. I.e. forecast the relation CAMEO codes
in query event Event(date=2023-11-03, head_entity=ISOCode(AUS), relation=CAMEOCode(?),
tail_entity=ISOCode(CHN)).
L.2.3
System Prompt
You are an expert in forecasting future events based on historical data. The database contains news
articles from January 1, 2023 to the current date November 02, 2023 and the events extracted from
these articles. The events are in the form of (date, subject country, relation, object country), where
the countries are represented by ISO 3166-1 alpha-3 codes and the relations are represented by the
CAMEO codes defined in the "Conflict and Mediation Event Observations" ontology. The relations
are hierarchical: first-level relations are general parent relations represented by two-digit CAMEO
codes, while second-level relations are more specific child relations represented by three-digit
41

CAMEO codes. Child relations have the same first two digits as their parent relations. For example,
"01" is a first-level relation, and "010" and "011" are some of its second-level relations. The relations
in the database are represented in the second-level form.
Your task is to forecast the future relations between two entities in a given query.
You
have access to a defined Python API that allows you to query the database for historical events and
statistics, and to get precise information about the ISO country codes and CAMEO relation codes.
The defined API is described as follows:
``` python
{api_description}
```
You will use an iterative approach, interleaving "Thought", "Action", and "Observation"
steps to collect information and perform the forecast. You may perform up to 20 iterations. The steps
are as follows:
- "Thought":
Analyze the current information and reason about the current situation, and
predicts which API you want to use (try to use different APIs to collect diverse information) or make
a decision that you want to make a final answer.
- "Action": Use the API to gather more information or provide the final forecast.
- If using the API: the action must be only one single line of exactly one function call from the
API with appropriate inputs, without additional code, explanations, or natural language descriptions.
- If making the final forecast: the action must start immediately with "Final Answer:", and follow
with the results in the expected JSON format.
- "Observation": Return the output of the called function.
To make a reasonable forecast, you should collect both news and relational evidence to
support your prediction. When you are fully confident that you accumulate enough information
to make the final forecast, you should start the "Thought" with your reasoning using the news
and structural information to make the prediction, and then start the "Action" step with "Final
Answer:" followed by the answer in the expected JSON format.
The answer should be a
JSON dictionary where the keys are the forecasted two-digit first-level CAMEO codes and
the values are lists of forecasted three-digit second-level CAMEO codes that are child relations
of the key. For example, "Action: Final Answer: {"01": ["010", "011", "012"], "02": ["020", "023"]}".
The final answer will be evaluated based on the precision and recall of the forecasted first-
level and second-level relations, so only include confident first-level and second-level CAMEO codes
in your final forecast.
Try to use different APIs to collect diverse information (including multi-hop relations),
such as the precise meaning of CAMEO codes, insights from news content, relational data, and
statistical analyses to support your forecasts. Consider not only the frequency of the relations but also
the temporal aspects of the data when making your forecast.
L.2.4
Agent ReAct Process
1. Thought: To forecast the relations that Australia (AUS) will take towards China (CHN) on
November 03, 2023, I will start by gathering historical data on the interactions between these two
countries. This will include the types of relations, their frequencies, and the context in which they
occurred. I will use the following steps:
(a) Retrieve the distribution of second-level relations between Australia and China.
(b) Analyze the distribution to identify the most common types of interactions.
(c) Examine recent news articles to understand the context and any ongoing trends or events that
might influence future relations.
Action:
1
get_relation_distribution ( head_entities =[ ISOCode("AUS")], tail_entities =[ ISOCode("CHN"
)])
Observation:
42

1 {CAMEOCode(code="042"): 32,
2
CAMEOCode(code="036"): 30,
3
CAMEOCode(code="040"): 17,
4
CAMEOCode(code="061"): 16,
5
CAMEOCode(code="046"): 12,
6
CAMEOCode(code="043"): 11,
7
CAMEOCode(code="010"): 6,
8
CAMEOCode(code="020"): 5,
9
CAMEOCode(code="173"): 5,
10
CAMEOCode(code="012"): 5,
11
CAMEOCode(code="051"): 4,
12
CAMEOCode(code="163"): 3,
13
CAMEOCode(code="128"): 2,
14
CAMEOCode(code="050"): 2,
15
CAMEOCode(code="084"): 2,
16
CAMEOCode(code="090"): 2,
17
CAMEOCode(code="174"): 1,
18
CAMEOCode(code="112"): 1,
19
CAMEOCode(code="130"): 1,
20
CAMEOCode(code="160"): 1,
21
CAMEOCode(code="172"): 1,
22
CAMEOCode(code="192"): 1,
23
CAMEOCode(code="190"): 1,
24
CAMEOCode(code="060"): 1,
25
CAMEOCode(code="030"): 1,
26
CAMEOCode(code="035"): 1,
27
CAMEOCode(code="138"): 1,
28
CAMEOCode(code="071"): 1,
29
CAMEOCode(code="031"): 1}
2. Thought: The distribution of second-level relations between Australia and China shows a va-
riety of interactions, with some relations being more frequent than others. The most common
interactions include:
- "042" (Consult): 32 occurrences
- "036" (Express intent to cooperate): 30 occurrences
- "040" (Assure): 17 occurrences
- "061" (Cooperate economically): 16 occurrences
- "046" (Praise or endorse): 12 occurrences
- "043" (Apologize): 11 occurrences
These frequent interactions suggest a trend towards diplomatic and cooperative engagements.
However, to make a more informed forecast, it is essential to understand the context and any
recent developments that might influence future relations.
Next, I will retrieve recent news articles involving Australia and China to gather insights on the
current context and any ongoing trends or events.
Action:
1
get_news_articles (date_range=DateRange( start_date =Date("2023 -10 -01"), end_date=Date("
2023 -11 -02")), head_entities =[ ISOCode("AUS")], tail_entities =[ ISOCode("CHN")])
Observation:
1 [( Date(date="2023 -11 -02"), "No quick
fix to
remaining
tariffs
ahead of China
visit"),
2
(Date(date="2023 -11 -02"), "China"s aggression
in Indo -Pacific
leads to "concern
and
angst": Peter
Dutton , Australia"s leader of
opposition "),
3
(Date(date="2023 -11 -02"), "Australia
and
China
eye new
ways to heal
old
wounds"),
4
(Date(date="2023 -11 -02"), "Albanese
must
aim
beyond
bilateral
outcomes
on
Beijing
visit"),
5
(Date(date="2023 -11 -02"), "Western
Australian
Premier
Announces
Visit to China"),
6
(Date(date="2023 -11 -02"), "Australian
PM"s China
visit
will
help
normalize
relations ,
says ex -trade
minister"),
7
(Date(date="2023 -11 -02"), "Nicholas
Moore on how to get in early on the
next
big
growth
story"),
8
(Date(date="2023 -11 -02"), "PM"s China
trip
cements
new era for
ties"),
9
(Date(date="2023 -11 -02"), "PM to take a hard
line on trade
with
China"),
10
(Date(date="2023 -11 -01"), "Australian
Prime
Minister
Anthony
Albanese
to raise
imprisoned
democracy
blogger
during
China
visit")]
3. Thought: The recent news articles indicate a mix of diplomatic, economic, and security-related
interactions between Australia and China. Key themes include:
43

- Diplomatic engagements and efforts to normalize relations, as seen in articles about the
Australian Prime Minister"s visit to China and efforts to heal old wounds.
- Economic cooperation and trade discussions, including addressing tariffs and trade issues.
- Security concerns and criticisms, particularly related to China"s actions in the Indo-Pacific
region and human rights issues.
Given these themes, it is likely that the future relations between Australia and China will involve
a combination of diplomatic assurances, economic cooperation, and some critical statements or
actions related to security and human rights.
Next, I will retrieve detailed descriptions of the most frequent second-level relations to ensure
accurate mapping and understanding of these interactions.
Action:
1
map_cameo_to_relation (CAMEOCode("042"))
Observation:
1
Relation(cameo_code=CAMEOCode("042"), name="Make a visit", description ="Travel to
another
location
for a meeting
or other
event.")
4. Thought: The relation "042" (Make a visit) involves traveling to another location for a meeting
or other event, which aligns with the recent news about the Australian Prime Minister"s visit to
China. This suggests that diplomatic visits are a significant aspect of the interactions between
Australia and China.
To further refine the forecast, I will retrieve detailed descriptions for the other most frequent
second-level relations: "036", "040", "061", "046", and "043".
Action:
1
map_cameo_to_relation (CAMEOCode("036"))
Observation:
1
Relation(cameo_code=CAMEOCode("036"), name="Express
intent
to meet or
negotiate",
description="Offer , promise , agree to , or
otherwise
indicate
willingness
or
commitment
to meet , visit , or
engage in talks or
negotiations .")
5. Thought: The relation "036" (Express intent to meet or negotiate) involves indicating a willingness
or commitment to meet, visit, or engage in talks or negotiations. This aligns with the ongoing
diplomatic efforts and discussions mentioned in the recent news articles.
Next, I will retrieve detailed descriptions for the relations "040", "061", "046", and "043" to further
understand the context of these interactions.
Action:
1
get_parent_relation (CAMEOCode("040"))
Observation:
1
Relation(cameo_code=CAMEOCode("04"), name="Consult", description ="All
consultations
and
meetings.")
6. Thought: The parent relation â€˜04â€˜ (Consult) encompasses all consultations and meetings, which
is consistent with the frequent diplomatic interactions between Australia and China. The specific
relation "040" (Assure) likely involves providing assurances during these consultations.
To further refine the forecast, I will retrieve detailed descriptions for the relations "061", "046",
and "043".
Action:""
Observation: No feedback from the environment due to the null action.
7. Thought: I will continue retrieving detailed descriptions for the relations "061", "046", and "043"
to further understand the context of these interactions.
Action:""
Observation: No feedback from the environment due to the null action.
44

8. Thought: It seems there was an issue with my previous actions. I will now proceed to retrieve the
detailed descriptions for the remaining frequent second-level relations: "061", "046", and "043".
Action:
1
map_cameo_to_relation (CAMEOCode("061"))
Observation:
1
Relation(cameo_code=CAMEOCode("061"), name="Cooperate
economically ", description ="
Initiate , resume , improve , or expand
economic
exchange
or
cooperation .")
9. Thought: The relation "061" (Cooperate economically) involves initiating, resuming, improving,
or expanding economic exchange or cooperation. This aligns with the recent news articles
discussing trade issues and economic cooperation between Australia and China.
Next, I will retrieve detailed descriptions for the relations "046" and "043".
Action:
1
map_cameo_to_relation (CAMEOCode("046"))
Observation:
1
Relation(cameo_code=CAMEOCode("046"), name="Engage in
negotiation ", description ="
Negotiate
or
bargain
with
others.")
10. Thought: The relation "046" (Engage in negotiation) involves negotiating or bargaining with
others. This is consistent with the ongoing discussions and negotiations mentioned in the news
articles, particularly regarding trade and diplomatic issues.
Next, I will retrieve the detailed description for the relation "043".
Action:""
Observation: No feedback from the environment due to the null action.
11. Thought: It seems there was an issue with my previous actions. I will now proceed to retrieve
the detailed description for the relation "043" to complete the understanding of the most frequent
interactions between Australia and China.
Action:
1
map_cameo_to_relation (CAMEOCode("043"))
Observation:
1
Relation(cameo_code=CAMEOCode("043"), name="Host a visit", description ="Host or
receive a visitor
at residence , office or home
country.")
12. Thought: The relation "043" (Host a visit) involves hosting or receiving a visitor at a residence,
office, or home country. This aligns with the diplomatic visits and engagements mentioned in the
recent news articles.
Based on the detailed descriptions and the recent news context, the most frequent interactions
between Australia and China involve diplomatic visits, economic cooperation, negotiations, and
assurances. These interactions suggest a trend towards diplomatic and cooperative engagements,
with some critical statements or actions related to security and human rights.
Given this information, I am confident in forecasting the following relations between Australia
and China on November 03, 2023:
- Diplomatic visits and engagements ("042", "043", "036") - Economic cooperation ("061") -
Negotiations ("046") - Assurances ("040")
Action: Final Answer: {"04": ["040", "042", "043", "046"], "03": ["036"], "06": ["061"]}
L.2.5
Agent Final Status
â€¢ End State: Final Answer
â€¢ Number of Steps Taken: 12
â€¢ Final Answer:
45

1 {
2
"03": ["036"],
3
"04": ["040", "042", "043", "046"],
4
"06": ["061"]
5 }
We show the corresponding relation names of the predicted codes here for a better review:
1 {
2
"Express
intent to
cooperate": ["Express
intent to meet or
negotiate"],
3
"Consult": ["Consult , not
specified", "Make a visit", "Host a visit", "Engage in
negotiation"],
4
"Engage in
material
cooperation ": ["Cooperate
economically "]
5 }
â€¢ Ground Truth Answer:
1 {
2
"03": ["036"],
3
"04": ["042"],
4
"17": ["172"]
5 }
We show the corresponding relation names of the ground-truth codes here for a better review:
1 {
2
"Express
intent to
cooperate": ["Express
intent to meet or
negotiate"],
3
"Consult": ["Make a visit"],
4
"Coerce": ["Impose
administrative
sanctions"]
5 }
46

M
Additional Information about API
M.1
Overview of API Data Classes and Functions
Table 7: API data classes and their attributes
Class Name
Attributes and Types
Date
date: str # â€˜YYYY-MM-DDâ€™
DateRange
start_date: Optional[Date], end_date: Optional[Date]
ISOCode
code: str # 3-letter ISO code
Country
iso_code: ISOCode, name: str
CAMEOCode
code: str # CAMEO code
Relation
cameo_code: CAMEOCode, name: str, description: str
Event
date: Date, head_entity: ISOCode, relation: CAMEOCode, tail_entity: ISOCode
NewsArticle
date: Date, title: str, content: str, events: List[Event]
Table 8: API functions categorized by functionality
Functions related to Countries and Relations
map_country_name_to_iso(name: str) -> List[Country]
map_iso_to_country_name(iso_code: ISOCode) -> str
map_relation_description_to_cameo(description: str) -> List[Relation]
map_cameo_to_relation(cameo_code: CAMEOCode) -> Relation
get_parent_relation(cameo_code: CAMEOCode) -> Relation
get_child_relations(cameo_code: CAMEOCode) -> List[Relation]
get_sibling_relations(cameo_code: CAMEOCode) -> List[Relation]
Functions related to Events
count_events(date_range: Optional[DateRange], head_entities: Optional[List[ISOCode]], tail_entities:
Optional[List[ISOCode]], relations: Optional[List[CAMEOCode]]) -> int
get_events(date_range: Optional[DateRange], head_entities: Optional[List[ISOCode]], tail_entities:
Optional[List[ISOCode]], relations: Optional[List[CAMEOCode]], text_description: Optional[str]) ->
List[Event]
get_entity_distribution(date_range: Optional[DateRange], involved_relations: Optional[List[CAMEOCode
]], interacted_entities: Optional[List[ISOCode]], entity_role: Optional[str]) -> Dict[ISOCode, int]
get_relation_distribution(date_range: Optional[DateRange], head_entities: Optional[List[ISOCode]],
tail_entities: Optional[List[ISOCode]]) -> Dict[CAMEOCode, int]
Functions related to News
count_news_articles(date_range: Optional[DateRange], head_entities: Optional[List[ISOCode]],
tail_entities: Optional[List[ISOCode]], relations: Optional[List[CAMEOCode]], keywords: Optional[List
[str]]) -> int
get_news_articles(date_range: Optional[DateRange], head_entities: Optional[List[ISOCode]],
tail_entities: Optional[List[ISOCode]], relations: Optional[List[CAMEOCode]], keywords: Optional[List
[str]], text_description: Optional[str]) -> List[Tuple[Date, str]]
browse_news_article(date: Date, title: str) -> str
47

M.2
API Specification
In this section, we provide the API specification, which is part of the system prompt for the ReAct
agent. It contains the definition of data classes and functions, with detailed Python docstring. For
dataclass, the specification includes class definition and description, attributes and their description,
and the example of initializing the class object. For functions, the specification includes the function
definition and description, the parameter and description, the return and description, and the example
of usage.
1
@dataclass
2
class
Date:
3
""" Represents a date."""
4
date: str # Date in the
format â€™YYYY -MM -DDâ€™
5
# Example: Date ("2022 -01 -01")
6
7
@dataclass
8
class
DateRange:
9
""" Represents a range of dates (inclusive)."""
10
start_date: Optional[Date] # If None , the
earliest
date is used
11
end_date: Optional[Date] # If None , the
current
date is used
12
# Example: DateRange(start_date =Date ("2022 -01 -01") , end_date=Date ("2022 -01 -31"))
13
14
@dataclass
15
class
ISOCode:
16
""" Represents
an ISO alpha -3
country
code."""
17
code: str # 3-letter
ISO
code
18
# Example: ISOCode (" USA ")
19
20
@dataclass
21
class
Country:
22
""" Represents a country
entity."""
23
iso_code: ISOCode
24
name: str
25
# Example: Country(iso_code=ISOCode (" USA "), name =" United
States ")
26
27
@dataclass
28
class
CAMEOCode:
29
""" Represents a CAMEO
verb
code."""
30
code: str # 2-digit
CAMEO
code
for
first
level
relations , 3-digit
CAMEO
code
for
second
level
relations
31
# Example: CAMEOCode ("01") , CAMEOCode ("010")
32
33
@dataclass
34
class
Relation:
35
""" Represents a relation."""
36
cameo_code: CAMEOCode
37
name: str
38
description : str # A brief
description
of what
event
the
relation
represents
39
# Example: Relation(cameo_code =CAMEOCode ("010") , name =" Make
statement , not
specified
", description =" All
public
statements
expressed
verbally
or in action , not
otherwise
specified ."
40
41
@dataclass
42
class
Event:
43
""" Represents
an event
characterized
by date , head
entity , relation , and
tail
entity.
"""
44
date: Date
45
head_entity : ISOCode
46
relation: CAMEOCode
47
tail_entity : ISOCode
48
# Example: Event(date=Date ("2022 -01 -01") , head_entity =ISOCode (" USA "), relation=
CAMEOCode ("010") , tail_entity =ISOCode (" CAN "))
49
50
@dataclass
51
class
NewsArticle:
52
""" Represents a news
article , including
metadata
and
content."""
53
date: Date
54
title: str
55
content: str # Full
text
content
of the
news
article
56
events: List[Event] # List of events
mentioned
in the
article
57
# Example: NewsArticle (date=Date ("2022 -01 -01") , title =" Trade
agreement
between
USA
and
China", content ="On
January 1, 2022 , a trade
agreement
was
signed
between
the
USA and
China ..." ,
events =[ Event(date=Date ("2022 -01 -01") , head_entity =ISOCode (" USA ")
, relation=CAMEOCode ("010") , tail_entity =ISOCode (" CHN ")])
58
59
def
__str__(self):
60
return f"{self.date }:\n{self.title }\n{self.content}"
61
62 def
map_country_name_to_iso (name: str) -> List[Country ]:
48

63
"""
64
Maps a country
name to the
most
likely
corresponding
Country
objects
with
ISO
codes.
65
66
Parameters:
67
name (str): The
country
name to map.
68
69
Returns:
70
List[Country ]: A list of 5 most
likely
Country
objects
sorted by
relevance.
71
72
Example:
73
>>> map_country_name_to_iso (" Korea ")
74
[Country(iso_code=ISOCode (" KOR "), name =" Republic
of Korea "), Country(iso_code=
ISOCode ("PRK "), name =" Democratic
People â€™s Republic
of Korea ")]
75
"""
76
pass
77
78 def
map_iso_to_country_name (iso_code: ISOCode) -> str:
79
"""
80
Maps an ISO
code to a country
name.
81
82
Parameters:
83
iso_code (ISOCode): The ISO
code to map.
84
85
Returns:
86
str: The
corresponding
country
name.
87
88
Example:
89
>>> map_iso_to_country_name (ISOCode (" CHN "))
90
"China"
91
"""
92
pass
93
94 def
map_relation_description_to_cameo ( description : str) -> List[Relation ]:
95
"""
96
Maps a relation
description
to the
most
likely
Relation
objects.
97
98
Parameters:
99
description (str): The
relation
description
to map.
100
101
Returns:
102
List[Relation ]: A list of 5 most
likely
Relations
sorted by
relevance.
103
104
Example:
105
>>> map_relation_description_to_cameo (" Fight
with
guns ")
106
[Reltion(cameo_code=CAMEOCode ("19") , name =" Fight", description =" All
uses of
conventional
force
and
acts of war
typically
by
organized
armed
groups .") , Relation(
cameo_code=CAMEOCode ("193") , name =" Fight
with
small
arms
and
light
weapons",
description =" Attack
using
small
arms
and
light
weapons
such as rifles , machine -guns ,
and
mortar
shells ."), Relation( cameo_code =CAMEOCode ("190") , name =" Use
conventional
military
force , not
specified", description =" All
uses of
conventional
force
and
acts
of war
typically
by
organized
armed
groups , not
otherwise
specified .")]
107
"""
108
pass
109
110 def
map_cameo_to_relation (cameo_code : CAMEOCode) -> Relation:
111
"""
112
Maps a CAMEO
code to a relation , including
its
name
and
description .
113
114
Parameters:
115
cameo_code (CAMEOCode): The
CAMEO
code to map.
116
117
Returns:
118
Relation: The
corresponding
relation.
119
120
Example:
121
>>> map_cameo_to_relation (CAMEOCode ("190"))
122
Relation(cameo_code=CAMEOCode ("190") , name =" Use
conventional
military
force , not
specified", description ="All
uses of
conventional
force
and
acts of war
typically
by
organized
armed
groups , not
otherwise
specified .")
123
"""
124
pass
125
126 def
get_child_relations (cameo_code : CAMEOCode) -> List[Relation ]:
127
"""
128
Retrieves
child
relations
of a given
relation
identified
by CAMEO
code.
129
130
Parameters:
131
cameo_code (CAMEOCode): The
CAMEO
code of the
relation
whose
children
are
sought.
Only
first
level
relations
are
accepted.
132
133
Returns:
49

134
List[Relation ]: A list of second
level
child
relations.
135
136
Example:
137
>>> get_child_relations (CAMEOCode ("19"))
138
[Relation(caemo_code=CAMEOCode ("190") , name =" Use
conventional
military
force , not
specified", description ="All
uses of
conventional
force
and
acts of war
typically
by
organized
armed
groups , not
otherwise
specified .") , Relation( cameo_code =CAMEOCode
("191") , name =" Impose
blockade
or
restrict
movement", description =" Prevent
entry
into
and/or exit
from a territory
using
armed
forces .") , ...]
139
"""
140
pass
141
142 def
get_sibling_relations (cameo_code : CAMEOCode) -> List[Relation ]:
143
"""
144
Retrieves
sibling
relations
of a given
relation
identified
by CAMEO
code.
145
146
Parameters:
147
cameo_code (CAMEOCode): The
CAMEO
code of the
relation
whose
siblings
are
sought.
Both
first
and
second
level
relations
are
accepted.
148
149
Returns:
150
List[Relation ]: A list of
sibling
relations
at the
same
level.
151
152
Example:
153
>>> get_sibling_relations (CAMEOCode ("193"))
154
[Relation(caemo_code=CAMEOCode ("190") , name =" Use
conventional
military
force , not
specified", description ="All
uses of
conventional
force
and
acts of war
typically
by
organized
armed
groups , not
otherwise
specified .") , Relation( cameo_code =CAMEOCode
("191") , name =" Impose
blockade
or
restrict
movement", description =" Prevent
entry
into
and/or exit
from a territory
using
armed
forces .") , ...]
155
"""
156
pass
157
158 def
count_events (date_range: Optional[DateRange] = None , head_entities : Optional[List[
ISOCode ]] = None , tail_entities : Optional[List[ISOCode ]] = None , relations: Optional
[List[CAMEOCode ]] = None) -> int:
159
"""
160
Counts
the
number
of
events in the
knowledge
graph
based on
specified
conditions.
161
162
Parameters:
163
date_range (Optional[DateRange ]): Range of dates to filter
the
events. If None ,
all
dates
are
included.
164
head_entities (Optional[List[ISOCode ]]): List of head
entity
ISO
codes to be
included. If None , all
countries
are
included.
165
tail_entities (Optional[List[ISOCode ]]): List of tail
entity
ISO
codes to be
included. If None , all
countries
are
included.
166
relations (Optional[List[CAMEOCode ]]): List of
relation
CAMEO
codes to be
included. If first
level
relations
are listed , all
second
level
relations
under
them
are
included. If None , all
relations
are
included.
167
168
Returns:
169
int: Count of unique
events
matching
the
conditions .
170
171
Example:
172
>>> count_events (date_range =DateRange(start_date=Date ("2022 -01 -01") , end_date=
Date ("2022 -01 -31")), head_entities =[ ISOCode (" USA "), ISOCode (" CHN ")], tail_entities =
None , relations =[ CAMEOCode ("010") ])
173
4
174
"""
175
pass
176
177 def
get_events(date_range: Optional[DateRange] = None , head_entities : Optional[List[
ISOCode ]] = None , tail_entities : Optional[List[ISOCode ]] = None , relations: Optional
[List[CAMEOCode ]] = None , text_description : Optional[str] = None) -> List[Event ]:
178
"""
179
Retrieves
events
from
the
knowledge
graph
based on
specified
conditions.
180
Inherits
common
filter
parameters
from
count_events . See
count_events
for
more
details
on these
parameters.
181
182
Additional
Parameters:
183
text_description (Optional[str ]): Textual
description
to match
with
the
source
news
articles
of
events. If None , the
returned
events
are
sorted by date in
descending
order; otherwise , sorted
by
relevance
of the
source
news
article
to the
description .
184
185
Returns:
186
List[Event ]: A list of
maximum
30 events
matching
the
specified
conditions .
187
188
Example:
50

189
>>> get_events(date_range=DateRange( start_date =Date ("2022 -01 -01") , end_date=Date
("2022 -01 -31")), head_entities =[ ISOCode (" USA "), ISOCode (" CHN ")], tail_entities =None ,
relations =[ CAMEOCode ("010")], text_description =" economic
trade ")
190
[Event(date=Date ("2022 -01 -15") , head_entity =ISOCode (" USA "), relation=CAMEOCode
("010") , tail_entity=ISOCode (" CAN "), Event(date=Date ("2022 -01 -10") , head_entity =
ISOCode ("CHN "), relation=CAMEOCode ("010") , tail_entity =ISOCode (" USA "), ...]
191
"""
192
pass
193
194 def
get_entity_distribution (date_range : Optional[DateRange] = None , involved_relations :
Optional[List[CAMEOCode ]] = None , interacted_entities : Optional[List[ISOCode ]] =
None , entity_role : Optional[str] = None) -> Dict[ISOCode , int ]:
195
"""
196
Gets
the
distribution
of
entities
in the
knowledge
graph
under
specified
conditions .
197
198
Parameters:
199
date_range (Optional[DateRange ]): Range of dates to filter
the
events. If None ,
all
dates
are
included.
200
involved_relations (Optional[List[CAMEOCode ]]): List of
relations
that
the
returned
entities
must be
involved
in any of. If first
level
relations
are listed ,
all
second
level
relations
under
them
are
included. If None , all
relations
are
included.
201
interacted_entities (Optional[List[ISOCode ]]): List of
entities
that
the
returned
entities
must
have
interacted
with
any of. If None , all
entities
are
included.
202
entity_role (Optional[EntityRole ]): Specifies
the
role of the
returned
entity in
the
events. Options
are â€™head â€™, â€™tail â€™, or â€™both â€™. If â€™both â€™ or None , the
returned
entity
can be either
head or tail.
203
204
Returns:
205
Dict[ISOCode , int]: A dictionary
mapping
returned
entities â€™ ISO
codes to the
number
of events
with
the
specified
conditions
in which
they
are
involved , sorted by
counts
in
descending
order.
206
207
Example:
208
>>> get_entity_distribution ( date_range =DateRange( start_date =Date ("2022 -01 -01") ,
end_date=Date ("2022 -01 -31")), involved_relations =[ CAMEOCode ("010")],
interacted_entities =[ ISOCode (" USA "), ISOCode (" CHN ")], entity_role =" tail ")
209
{ISOCode ("USA "): 3, ISOCode (" CHN "): 1}
210
"""
211
pass
212
213 def
get_relation_distribution (date_range : Optional[DateRange] = None , head_entities :
Optional[List[ISOCode ]] = None , tail_entities : Optional[List[ISOCode ]] = None) ->
Dict[CAMEOCode , int ]:
214
"""
215
Gets
the
distribution
of
second
level
relations
in the
knowledge
graph
under
specified
conditions.
216
217
Parameters:
218
date_range (Optional[DateRange ]): Range of dates to filter
the
events. If None ,
all
dates
are
included.
219
head_entities (Optional[List[ISOCode ]]): List of head
entities
that
the
events
must
involve
any of. If None , all
head
entities
are
included.
220
tail_entities (Optional[List[ISOCode ]]): List of tail
entities
that
the
events
must
involve
any of. If None , all
tail
entities
are
included.
221
222
Returns:
223
Dict[CAMEOCode , int ]: A dictionary
mapping
second
level
relations â€™ CAMEO
codes to
the
number of events
with
the
specified
conditions
in which
they
are
involved ,
sorted
by counts in
descending
order.
224
225
Example:
226
>>> get_relation_distribution ( date_range=DateRange(start_date =Date ("2022 -01 -01") ,
end_date=Date ("2022 -01 -31")), head_entities =[ ISOCode (" USA "), ISOCode (" CHN ")],
tail_entities =None)
227
{CAMEOCode ("010"): 3, CAMEOCode ("011"): 1}
228
"""
229
pass
230
231 def
count_news_articles (date_range : Optional[DateRange] = None , head_entities : Optional[
List[ISOCode ]] = None , tail_entities : Optional[List[ISOCode ]] = None , relations:
Optional[List[CAMEOCode ]] = None , keywords: Optional[List[str ]] = None) -> int:
232
"""
233
Counts
the
number
of news
articles
based on
specified
conditions .
234
235
Parameters:
236
date_range (Optional[DateRange ]): Range of dates to filter
the
news
articles. If
None , all
dates
are
included.
237
head_entities (Optional[List[ISOCode ]]): At least
one of the
entities
must be
mentioned
in the
articles
and be the
head
entity in the
events. If None , all
entities
are
included.
51

238
tail_entities (Optional[List[ISOCode ]]): At least
one of the
entities
must be
mentioned
in the
articles
and be the
tail
entity in the
events. If None , all
entities
are
included.
239
relations (Optional[List[CAMEOCode ]]): At least
one of the
relations
must be
mentioned
in the
articles. If first
level
relations
are listed , all
second
level
relations
under
them
are
included. If None , all
relations
are
included.
240
keywords (Optional[List[str ]]): At least
one of the
keywords
must be
present
in
the
articles. If None , all
articles
are
included.
241
242
Returns:
243
int: The
count of news
articles
matching
the
conditions .
244
245
Example:
246
>>> count_news_articles (date_range =DateRange( start_date =Date ("2022 -01 -01") ,
end_date=Date ("2022 -01 -31")), head_entities =[ ISOCode (" USA "), ISOCode (" CHN ")],
tail_entities =[ ISOCode ("USA "), ISOCode (" CHN ")], relations =[ CAMEOCode ("010")],
keywords =[" trade "])
247
2
248
"""
249
pass
250
251 def
get_news_articles (date_range: Optional[DateRange] = None , head_entities : Optional[
List[ISOCode ]] = None , tail_entities : Optional[List[ISOCode ]] = None , relations:
Optional[List[CAMEOCode ]] = None , keywords: Optional[List[str ]] = None ,
text_description : Optional[str] = None) -> List[Tuple[Date , str ]]:
252
"""
253
Retrieves
news
articles
based on
specified
conditions.
254
Inherits
common
filter
parameters
from
count_news_articles . See
count_news_articles
for
more
details
on these
parameters .
255
256
Additional
Parameters:
257
text_description (Optional[str ]): Textual
description
to match
with
the
news
articles. If None , the
returned
articles
are
sorted by date in
descending
order;
otherwise , sorted
by
relevance
to the
description .
258
259
Returns:
260
List[Tuple[Date , str ]]: A list of
maximum
15 news
articles
matching
the
specified
conditions , each
represented
by a tuple of date
and
title.
261
262
Example:
263
>>> get_news_articles (date_range=DateRange(start_date =Date ("2022 -01 -01") ,
end_date=Date ("2022 -01 -31")), head_entities =[ ISOCode (" USA "), ISOCode (" CHN ")],
tail_entities =[ ISOCode ("USA "), ISOCode (" CHN ")], relations =[ CAMEOCode ("010")],
keywords =[" trade "],
text_description =" Economic
trade is
encouraged
between
USA and
China .")
264
[( NewsArticle .date=Date ("2022 -01 -15") , NewsArticle .title =" China
and USA
sign
trade
deal "), ( NewsArticle.date=Date ("2022 -01 -10") , NewsArticle .title =" Trade
agreement
between
USA and
China ")]
265
"""
266
pass
267
268 def
browse_news_article (date: Date , title: str) -> str:
269
"""
270
Retrieves
the
full
text of a news
article
by its
title.
271
272
Parameters:
273
date (Date): The
date of the
news
article
to
retrieve.
274
title (str): The
title of the
news
article
to
retrieve.
275
276
Returns:
277
str: The date , the
title
and
full
contents
of the
news
article.
278
279
Example:
280
>>> browse_news_article (Date ("2022 -01 -10") , "Trade
agreement
between
USA and
China ")
281
2022 -01 -10:
282
Trade
agreement
between
USA and
China
283
On
January 10, 2022 , a trade
agreement
was
signed
between
the USA and
China to
promote
economic
cooperation ...
284
"""
285
pass
52

M.3
API Implementation
In this section, we provide the full implementation of the API, which is part of the environment and
is accessible to the Python executor.
1
@dataclass
2
class
Date:
3
""" Represents a date."""
4
date: str # Date in the
format â€™YYYY -MM -DDâ€™
5
# Example: Date ("2022 -01 -01")
6
7
def
__init__(self , date: str):
8
# check
type
9
if not
isinstance(date , str):
10
raise
ValueError(f"Attribute
â€™date â€™ of class
Date
must be a string in the
format
â€™YYYY -MM -DD â€™, but
received: {date} in type {type(date)}")
11
12
# check if date is in the
correct
format by trying
to
convert
it to a date
object
13
try:
14
datetime.datetime.strptime(date , â€™%Y-%m-%dâ€™)
15
except
ValueError:
16
raise
ValueError(f"Date
must be in the
format
â€™YYYY -MM -DD â€™, but
received: {
date}")
17
if date < DEFAULT_START_DATE :
18
raise
ValueError(f"Date
must be on or after { DEFAULT_START_DATE }, but
received: {date}")
19
if
DEFAULT_END_DATE
and
date > DEFAULT_END_DATE :
20
raise
ValueError(f"Date
must be on or
before
the
current
date {
DEFAULT_END_DATE }, but
received: {date}")
21
22
self.date = date
23
24
def
__str__(self):
25
return f"Date(â€™{self.date}â€™)"
26
27
def
__hash__(self):
28
return
hash(self.date)
29
30
def
__eq__(self , other):
31
if
isinstance(other , Date):
32
return
self.date == other.date
33
return
False
34
35
@dataclass
36
class
DateRange:
37
""" Represents a range of dates (inclusive)."""
38
start_date: Optional[Date] # If None , the
earliest
date is used
39
end_date: Optional[Date] # If None , the
current
date is used
40
# Example: DateRange(start_date =Date ("2022 -01 -01") , end_date=Date ("2022 -01 -31"))
41
42
def
__init__(self , start_date: Optional[Date] = None , end_date: Optional[Date] = None
):
43
# check
type
44
if
start_date
and not
isinstance (start_date , Date):
45
raise
ValueError(f"Attribute
â€™start_date â€™ of class
DateRange
must be a Date
object , but
received
type {type(start_date)}")
46
if
end_date
and not
isinstance(end_date , Date):
47
raise
ValueError(f"Attribute
â€™end_date â€™ of class
DateRange
must be a Date
object , but
received
type {type(end_date)}")
48
49
self.start_date = start_date
if
start_date
else
Date( DEFAULT_START_DATE )
50
self.end_date = end_date
if
end_date
else
Date( DEFAULT_END_DATE )
51
if
start_date
and
end_date
and
start_date .date > end_date.date:
52
raise
ValueError("Start
date
must be before or equal to end date , but
received: start_date ={},
end_date ={}".format( start_date .date , end_date.date))
53
54
def
__str__(self):
55
return f"DateRange(start_date ={ self. start_date }, end_date ={ self.end_date })"
56
57
def
__hash__(self):
58
return
hash (( self.start_date , self.end_date))
59
60
def
__eq__(self , other):
61
if
isinstance(other , DateRange):
62
return
self.start_date
== other. start_date
and
self.end_date
== other.
end_date
63
return
False
64
65
@dataclass
66
class
ISOCode:
67
""" Represents
an ISO alpha -3
country
code."""
53

68
code: str # 3-letter
ISO
code
69
# Example: ISOCode (" USA ")
70
71
def
__init__(self , code: str):
72
# check
type
73
if not
isinstance(code , str):
74
raise
ValueError(f"Attribute
â€™code â€™ of class
ISOCode
must be a string , but
received
type {type(code)}")
75
76
if len(code) != 3:
77
raise
ValueError(f"ISO
code
must be a 3-letter
string , but
received: {code}")
78
if code
not in
dict_iso2alternames :
79
raise
ValueError(f"ISO
code
must be a valid
ISO alpha -3
country
code , but
received: {code}")
80
self.code = code
81
82
def
__str__(self):
83
return f"ISOCode (â€™{self.code}â€™)"
84
85
def
__hash__(self):
86
return
hash(self.code)
87
88
def
__eq__(self , other):
89
if
isinstance(other , ISOCode):
90
return
self.code == other.code
91
return
False
92
93
@dataclass
94
class
Country:
95
""" Represents a country
entity."""
96
iso_code: ISOCode
97
name: str
98
# Example: Country(iso_code=ISOCode (" USA "), name =" United
States ")
99
100
def
__init__(self , iso_code: ISOCode , name: str):
101
# check
type
102
if not
isinstance(iso_code , ISOCode):
103
raise
ValueError(f"Attribute
â€™iso_code â€™ of class
Country
must be an
ISOCode
object , but
received
type {type(iso_code)}")
104
if not
isinstance(name , str):
105
raise
ValueError(f"Attribute
â€™name â€™ of class
Country
must be a string , but
received
type {type(name)}")
106
107
if
dict_iso2alternames [iso_code.code ][0] != name:
108
raise
ValueError(f"Country
name
must
match
the
name
corresponding
to the ISO
code , but
received: {name} for ISO
code: {iso_code.code}")
109
self.iso_code = iso_code
110
self.name = name
111
112
def
__str__(self):
113
return f"Country(iso_code ={ self.iso_code}, name=â€™{self.name}â€™)"
114
115
def
__hash__(self):
116
return
hash (( self.iso_code , self.name))
117
118
def
__eq__(self , other):
119
if
isinstance(other , Country):
120
return
self.iso_code
== other.iso_code
and
self.name == other.name
121
return
False
122
123
@dataclass
124
class
CAMEOCode:
125
""" Represents a CAMEO
verb
code."""
126
code: str # 2-digit
CAMEO
code
for
first
level
relations , 3-digit
CAMEO
code
for
second
level
relations
127
# Example: CAMEOCode ("01") , CAMEOCode ("010")
128
129
def
__init__(self , code: str):
130
# check
type
131
if not
isinstance(code , str):
132
raise
ValueError(f"Attribute
â€™code â€™ of class
CAMEOCode
must be a string , but
received
type {type(code)}")
133
134
if len(code) not in [2, 3]:
135
raise
ValueError(f"CAMEO
code
must be a valid 2 or 3-digit
string
defined
in
the â€™Conflict
and
Mediation
Event
Observations â€™ Codebook , but
received: {code}")
136
if code
not in
dict_code2relation :
137
raise
ValueError(f"CAMEO
code
must be a valid
CAMEO
code
defined
in the â€™
Conflict
and
Mediation
Event
Observations â€™ Codebook , but
received: {code}")
138
self.code = code
139
54

140
def
__str__(self):
141
return f"CAMEOCode (â€™{self.code}â€™)"
142
143
def
__hash__(self):
144
return
hash(self.code)
145
146
def
__eq__(self , other):
147
if
isinstance(other , CAMEOCode):
148
return
self.code == other.code
149
return
False
150
151
@dataclass
152
class
Relation:
153
""" Represents a relation."""
154
cameo_code: CAMEOCode
155
name: str
156
description : str # A brief
description
of what
event
the
relation
represents
157
# Example: Relation(cameo_code =CAMEOCode ("010") , name =" Make
statement , not
specified
", description =" All
public
statements
expressed
verbally
or in action , not
otherwise
specified ."
158
159
def
__init__(self , cameo_code: CAMEOCode , name: str , description : str):
160
# check
type
161
if not
isinstance(cameo_code , CAMEOCode):
162
raise
ValueError(f"Attribute
â€™cameo_code â€™ of class
Relation
must be a
CAMEOCode
object , but
received
type {type( cameo_code )}")
163
if not
isinstance(name , str):
164
raise
ValueError(f"Attribute
â€™name â€™ of class
Relation
must be a string , but
received
type {type(name)}")
165
if not
isinstance(description , str):
166
raise
ValueError(f"Attribute
â€™description â€™ of class
Relation
must be a string
, but
received
type {type(description )}")
167
168
if
dict_code2relation [cameo_code.code ][â€™Name â€™] != name:
169
raise
ValueError(f"Relation
name
must
match
the
name
corresponding
to the
CAMEO code , but
received: {name} for
CAMEO
code { cameo_code.code}")
170
if
dict_code2relation [cameo_code.code ][â€™Description â€™] !=
description :
171
raise
ValueError(f"Relation
description
must
match
the
description
corresponding
to the
CAMEO code , but
received: { description } for
CAMEO
code {
cameo_code.code}")
172
self.cameo_code = cameo_code
173
self.name = name
174
self. description = description
175
176
def
__str__(self):
177
return f"Relation(cameo_code ={ self.cameo_code }, name=â€™{self.name}â€™, description
=â€™{self. description }â€™)"
178
179
def
__hash__(self):
180
return
hash (( self.cameo_code , self.name , self. description ))
181
182
def
__eq__(self , other):
183
if
isinstance(other , Relation):
184
return
self.cameo_code
== other. cameo_code
and
self.name == other.name
and
self. description
== other.description
185
return
False
186
187
@dataclass
188
class
Event:
189
""" Represents
an event
characterized
by date , head
entity , relation , and
tail
entity.
"""
190
date: Date
191
head_entity : ISOCode
192
relation: CAMEOCode
193
tail_entity : ISOCode
194
# Example: Event(date=Date ("2022 -01 -01") , head_entity =ISOCode (" USA "), relation=
CAMEOCode ("010") , tail_entity =ISOCode (" CAN "))
195
196
def
__init__(self , date: Date , head_entity : ISOCode , relation: CAMEOCode , tail_entity
: ISOCode):
197
# check
type
198
if not
isinstance(date , Date):
199
raise
ValueError(f"Attribute
â€™date â€™ of class
Event
must be a Date
object , but
received
type {type(date)}")
200
if not
isinstance(head_entity , ISOCode):
201
raise
ValueError(f"Attribute
â€™head_entity â€™ of class
Event
must be an
ISOCode
object , but
received
type {type( head_entity )}")
202
if not
isinstance(relation , CAMEOCode):
203
raise
ValueError(f"Attribute
â€™relation â€™ of class
Event
must be a CAMEOCode
object , but
received
type {type(relation)}")
204
if not
isinstance(tail_entity , ISOCode):
55

205
raise
ValueError(f"Attribute
â€™tail_entity â€™ of class
Event
must be an
ISOCode
object , but
received
type {type( tail_entity )}")
206
207
self.date = date
208
self. head_entity = head_entity
209
self.relation = relation
210
self. tail_entity = tail_entity
211
212
def
__str__(self):
213
return f"Event(date ={ self.date}, head_entity ={ self. head_entity }, relation ={ self.
relation}, tail_entity ={ self. tail_entity })"
214
215
def
__hash__(self):
216
return
hash (( self.date , self.head_entity , self.relation , self. tail_entity ))
217
218
def
__eq__(self , other):
219
if
isinstance(other , Event):
220
return
self.date == other.date
and
self. head_entity
== other. head_entity
and
self.relation
== other.relation
and
self. tail_entity
== other. tail_entity
221
return
False
222
223
@dataclass
224
class
NewsArticle:
225
""" Represents a news
article , including
metadata
and
content."""
226
date: Date
227
title: str
228
content: str # Full
text
content
of the
news
article
229
events: List[Event] # List of events
mentioned
in the
article
230
# Example: NewsArticle (date=Date ("2022 -01 -01") , title =" Trade
agreement
between
USA
and
China", content ="On
January 1, 2022 , a trade
agreement
was
signed
between
the
USA and
China ..." ,
events =[ Event(date=Date ("2022 -01 -01") , head_entity =ISOCode (" USA ")
, relation=CAMEOCode ("010") , tail_entity =ISOCode (" CHN ")])
231
232
def
__init__(self , date: Date , title: str , content: str , events: List[Event ]):
233
# check
type
234
if not
isinstance(date , Date):
235
raise
ValueError(f"Attribute
â€™date â€™ of class
NewsArticle
must be a Date
object , but
received
type {type(date)}")
236
if not
isinstance(title , str):
237
raise
ValueError(f"Attribute
â€™title â€™ of class
NewsArticle
must be a string ,
but
received
type {type(title)}")
238
if not
isinstance(content , str):
239
raise
ValueError(f"Attribute
â€™content â€™ of class
NewsArticle
must be a string ,
but
received
type {type(content)}")
240
if not
isinstance(events , list):
241
raise
ValueError(f"Attribute
â€™events â€™ of class
NewsArticle
must be a list ,
but
received
type {type(events)}")
242
243
self.date = date
244
self.title = title
245
self.content = content
246
self.events = events
247
248
def
__str__(self):
249
return f"{self.date }:\n{self.title }\n{self.content}"
250
251
def
__hash__(self):
252
return
hash (( self.date , self.title , self.content))
253
254
def
__eq__(self , other):
255
if
isinstance(other , NewsArticle ):
256
return
self.date == other.date
and
self.title == other.title
and
self.content
== other.content
257
return
False
258
259 def
map_country_name_to_iso (name: str) -> List[Country ]:
260
"""
261
Maps a country
name to the
most
likely
corresponding
Country
objects
with
ISO
codes.
262
263
Parameters:
264
name (str): The
country
name to map.
265
266
Returns:
267
List[Country ]: A list of 5 most
likely
Country
objects
sorted by
relevance.
268
269
Example:
270
>>> map_country_name_to_iso (" Korea ")
271
[Country(iso_code=ISOCode (" KOR "), name =" Republic
of Korea "), Country(iso_code=
ISOCode ("PRK "), name =" Democratic
People â€™s Republic
of Korea ")]
272
"""
273
# check
type
56

274
if not
isinstance(name , str):
275
raise
ValueError(f"Input â€™name â€™ must be a string , but
received
type {type(name)}"
)
276
277
if name in
dict_countryname2iso :
278
return [Country(iso_code=ISOCode( dict_countryname2iso [name ]), name=name)]
279
else:
280
# get top 5 ISO
codes
with
the
highest
cosine
similarity
281
name_embeddings = get_embedding (name)
282
similarities = cosine_similarity (country_embeddings , name_embeddings )
283
top_indices = np.argsort( similarities )[:: -1][:5]
284
countries = []
285
for idx in
top_indices:
286
iso_code = list( dict_iso2alternames .keys ())[idx]
287
curr_name = dict_iso2alternames [iso_code ][0]
288
countries.append(Country(iso_code=ISOCode(iso_code), name=curr_name))
289
return
countries
290
291 def
map_iso_to_country_name (iso_code: ISOCode) -> str:
292
"""
293
Maps an ISO
code to a country
name.
294
295
Parameters:
296
iso_code (ISOCode): The ISO
code to map.
297
298
Returns:
299
str: The
corresponding
country
name.
300
301
Example:
302
>>> map_iso_to_country_name (ISOCode (" CHN "))
303
"China"
304
"""
305
# check
type
306
if not
isinstance(iso_code , ISOCode):
307
raise
ValueError(f"Input â€™iso_code â€™ must be an
ISOCode
object , but
received
type
{type(iso_code)}")
308
309
return
dict_iso2alternames [iso_code.code ][0]
310
311 def
map_relation_description_to_cameo ( description : str) -> List[Relation ]:
312
"""
313
Maps a relation
description
to the
most
likely
Relation
objects.
314
315
Parameters:
316
description (str): The
relation
description
to map.
317
318
Returns:
319
List[Relation ]: A list of 5 most
likely
Relations
sorted by
relevance.
320
321
Example:
322
>>> map_relation_description_to_cameo (" Fight
with
guns ")
323
[Reltion(cameo_code=CAMEOCode ("19") , name =" Fight", description =" All
uses of
conventional
force
and
acts of war
typically
by
organized
armed
groups .") , Relation(
cameo_code=CAMEOCode ("193") , name =" Fight
with
small
arms
and
light
weapons",
description =" Attack
using
small
arms
and
light
weapons
such as rifles , machine -guns ,
and
mortar
shells ."), Relation( cameo_code =CAMEOCode ("190") , name =" Use
conventional
military
force , not
specified", description =" All
uses of
conventional
force
and
acts
of war
typically
by
organized
armed
groups , not
otherwise
specified .")]
324
"""
325
# check
type
326
if not
isinstance(description , str):
327
raise
ValueError(f"Input â€™description â€™ must be a string , but
received
type {type(
description )}")
328
329
if
description
in
dict_relation2code :
330
code = dict_relation2code [ description ]
331
return [Relation(cameo_code =CAMEOCode(code), name= dict_code2relation [code ][â€™Name â€™
], description = dict_code2relation [code ][â€™Description â€™])]
332
else:
333
# get top 5 CAMEO
codes
with
the
highest
cosine
similarity
334
description_embedding = get_embedding ( description )
335
similarities = cosine_similarity ( relation_embeddings , description_embedding )
336
top_indices = np.argsort( similarities )[:: -1][:5]
337
relations = []
338
for idx in
top_indices:
339
code = list( dict_code2relation .keys ())[idx]
340
relations.append(Relation( cameo_code =CAMEOCode(code), name= dict_code2relation
[code ][â€™Name â€™], description = dict_code2relation [code ][â€™Description â€™]))
341
return
relations
342
343 def
map_cameo_to_relation (cameo_code : CAMEOCode) -> Relation:
57

344
"""
345
Maps a CAMEO
code to a relation , including
its
name
and
description .
346
347
Parameters:
348
cameo_code (CAMEOCode): The
CAMEO
code to map.
349
350
Returns:
351
Relation: The
corresponding
relation.
352
353
Example:
354
>>> map_cameo_to_relation (CAMEOCode ("190"))
355
Relation(cameo_code=CAMEOCode ("190") , name =" Use
conventional
military
force , not
specified", description ="All
uses of
conventional
force
and
acts of war
typically
by
organized
armed
groups , not
otherwise
specified .")
356
"""
357
# check
type
358
if not
isinstance(cameo_code , CAMEOCode):
359
raise
ValueError(f"Input â€™cameo_code â€™ must be a CAMEOCode
object , but
received
type {type(cameo_code)}")
360
361
info = dict_code2relation [cameo_code.code]
362
return
Relation(cameo_code=cameo_code , name=info[â€™Name â€™], description =info[â€™
Description â€™])
363
364 def
get_parent_relation (cameo_code : CAMEOCode) -> Relation:
365
"""
366
Retrieves
the
parent
relation
of a given
relation
identified
by CAMEO
code.
367
368
Parameters:
369
cameo_code (CAMEOCode): The
CAMEO
code of the
relation
whose
parent is sought.
Only
second
level
relations
are
accepted.
370
371
Returns:
372
Relation: The
first
level
parent
relation.
373
374
Example:
375
>>> get_parent_relation (CAMEOCode ("193"))
376
Relation(cameo_code=CAMEOCode ("19") , name =" Fight", description =" All
uses of
conventional
force
and
acts of war
typically
by
organized
armed
groups .")
377
"""
378
# check
type
379
if not
isinstance(cameo_code , CAMEOCode):
380
raise
ValueError(f"Input â€™cameo_code â€™ must be a CAMEOCode
object , but
received
type {type(cameo_code)}")
381
382
if len(cameo_code.code) != 3:
383
raise
ValueError("Only
second
level
relations
are
accepted , but
received: {}".
format(cameo_code.code))
384
parent_code =cameo_code.code [:2]
385
return
map_cameo_to_relation (CAMEOCode( parent_code ))
386
387 def
get_child_relations (cameo_code : CAMEOCode) -> List[Relation ]:
388
"""
389
Retrieves
child
relations
of a given
relation
identified
by CAMEO
code.
390
391
Parameters:
392
cameo_code (CAMEOCode): The
CAMEO
code of the
relation
whose
children
are
sought.
Only
first
level
relations
are
accepted.
393
394
Returns:
395
List[Relation ]: A list of second
level
child
relations.
396
397
Example:
398
>>> get_child_relations (CAMEOCode ("19"))
399
[Relation(caemo_code=CAMEOCode ("190") , name =" Use
conventional
military
force , not
specified", description ="All
uses of
conventional
force
and
acts of war
typically
by
organized
armed
groups , not
otherwise
specified .") , Relation( cameo_code =CAMEOCode
("191") , name =" Impose
blockade
or
restrict
movement", description =" Prevent
entry
into
and/or exit
from a territory
using
armed
forces .") , ...]
400
"""
401
# check
type
402
if not
isinstance(cameo_code , CAMEOCode):
403
raise
ValueError(f"Input â€™cameo_code â€™ must be a CAMEOCode
object , but
received
type {type(cameo_code)}")
404
405
if len(cameo_code.code) != 2:
406
raise
ValueError("Only
first
level
relations
are
accepted , but
received: {}".
format(cameo_code.code))
407
children = []
408
for code , info in
dict_code2relation .items ():
409
if code [:2] ==
cameo_code.code
and len(code) == 3:
58

410
children.append(Relation(cameo_code=CAMEOCode(code), name=info[â€™Name â€™],
description =info[â€™Description â€™]))
411
return
children
412
413 def
get_sibling_relations (cameo_code : CAMEOCode) -> List[Relation ]:
414
"""
415
Retrieves
sibling
relations
of a given
relation
identified
by CAMEO
code.
416
417
Parameters:
418
cameo_code (CAMEOCode): The
CAMEO
code of the
relation
whose
siblings
are
sought.
Both
first
and
second
level
relations
are
accepted.
419
420
Returns:
421
List[Relation ]: A list of
sibling
relations
at the
same
level.
422
423
Example:
424
>>> get_sibling_relations (CAMEOCode ("193"))
425
[Relation(caemo_code=CAMEOCode ("190") , name =" Use
conventional
military
force , not
specified", description ="All
uses of
conventional
force
and
acts of war
typically
by
organized
armed
groups , not
otherwise
specified .") , Relation( cameo_code =CAMEOCode
("191") , name =" Impose
blockade
or
restrict
movement", description =" Prevent
entry
into
and/or exit
from a territory
using
armed
forces .") , ...]
426
"""
427
# check
type
428
if not
isinstance(cameo_code , CAMEOCode):
429
raise
ValueError(f"Input â€™cameo_code â€™ must be a CAMEOCode
object , but
received
type {type(cameo_code)}")
430
431
if len(cameo_code.code) == 3:
432
return
get_child_relations ( get_parent_relation (cameo_code ). cameo_code )
433
elif
len(cameo_code.code) == 2:
434
# get
â€™01â€™ to
â€™20â€™ relations
435
first_level_codes = [str(i).zfill (2) for i in range (1, 21)]
436
relations = []
437
for
code in
first_level_codes :
438
relations.append( map_cameo_to_relation (CAMEOCode(code)))
439
return
relations
440
441 def
count_events (date_range: Optional[DateRange] = None , head_entities : Optional[List[
ISOCode ]] = None , tail_entities : Optional[List[ISOCode ]] = None , relations: Optional
[List[CAMEOCode ]] = None) -> int:
442
"""
443
Counts
the
number
of
events in the
knowledge
graph
based on
specified
conditions.
444
445
Parameters:
446
date_range (Optional[DateRange ]): Range of dates to filter
the
events. If None ,
all
dates
are
included.
447
head_entities (Optional[List[ISOCode ]]): List of head
entity
ISO
codes to be
included. If None , all
countries
are
included.
448
tail_entities (Optional[List[ISOCode ]]): List of tail
entity
ISO
codes to be
included. If None , all
countries
are
included.
449
relations (Optional[List[CAMEOCode ]]): List of
relation
CAMEO
codes to be
included. If first
level
relations
are listed , all
second
level
relations
under
them
are
included. If None , all
relations
are
included.
450
451
Returns:
452
int: Count of unique
events
matching
the
conditions .
453
454
Example:
455
>>> count_events (date_range =DateRange(start_date=Date ("2022 -01 -01") , end_date=
Date ("2022 -01 -31")), head_entities =[ ISOCode (" USA "), ISOCode (" CHN ")], tail_entities =
None , relations =[ CAMEOCode ("010") ])
456
4
457
"""
458
# check
type
459
if
date_range
and not
isinstance (date_range , DateRange):
460
raise
ValueError(f"Input â€™date_range â€™ must be a DateRange
object , but
received
type {type(date_range)}")
461
if
head_entities
and not
isinstance (head_entities , list):
462
raise
ValueError(f"Input â€™head_entities â€™ must be a list , but
received
type {type(
head_entities )}")
463
if
head_entities
and not all(isinstance (iso , ISOCode) for iso in
head_entities ):
464
raise
ValueError(f"Elements
in â€™head_entities â€™ must be
ISOCode
objects")
465
if
tail_entities
and not
isinstance (tail_entities , list):
466
raise
ValueError(f"Input â€™tail_entities â€™ must be a list , but
received
type {type(
tail_entities )}")
467
if
tail_entities
and not all(isinstance (iso , ISOCode) for iso in
tail_entities ):
468
raise
ValueError(f"Elements
in â€™tail_entities â€™ must be
ISOCode
objects")
469
if
relations
and not
isinstance (relations , list):
470
raise
ValueError(f"Input â€™relations â€™ must be a list , but
received
type {type(
relations)}")
59

471
if
relations
and not all(isinstance (code , CAMEOCode) for
code in
relations):
472
raise
ValueError(f"Elements
in â€™relations â€™ must be
CAMEOCode
objects")
473
474
# process
data_kg
by
filtering
based on the
specified
conditions
475
curr_data = data_kg.copy ()
476
curr_data. drop_duplicates (subset =[â€™QuadEventCode â€™], inplace=True)
477
curr_data = curr_data[curr_data[â€™DateStr â€™] <= DEFAULT_END_DATE ]
478
if
date_range:
479
curr_data = curr_data [( curr_data[â€™DateStr â€™] >= date_range. start_date .date) & (
curr_data[â€™DateStr â€™] <= date_range.end_date.date)]
480
if
head_entities :
481
curr_data = curr_data[curr_data[â€™Actor1CountryCode â€™]. isin ([ iso.code
for iso in
head_entities ])]
482
if
tail_entities :
483
curr_data = curr_data[curr_data[â€™Actor2CountryCode â€™]. isin ([ iso.code
for iso in
tail_entities ])]
484
if
relations:
485
# if first
level
relations
are listed , include
all
second
level
relations
under
them
486
for
code in
relations:
487
if len(code.code) == 2:
488
relations.extend ([ CAMEOCode(c) for c in
dict_code2relation
if c[:2] ==
code.code
and len(c) == 3])
489
curr_data = curr_data[curr_data[â€™EventBaseCode â€™]. isin ([ code.code
for
code in
relations ])]
490
return
len(curr_data)
491
492 def
get_events(date_range: Optional[DateRange] = None , head_entities : Optional[List[
ISOCode ]] = None , tail_entities : Optional[List[ISOCode ]] = None , relations: Optional
[List[CAMEOCode ]] = None , text_description : Optional[str] = None) -> List[Event ]:
493
"""
494
Retrieves
events
from
the
knowledge
graph
based on
specified
conditions.
495
Inherits
common
filter
parameters
from
count_events . See
count_events
for
more
details
on these
parameters.
496
497
Additional
Parameters:
498
text_description (Optional[str ]): Textual
description
to match
with
the
source
news
articles
of
events. If None , the
returned
events
are
sorted by date in
descending
order; otherwise , sorted
by
relevance
of the
source
news
article
to the
description .
499
500
Returns:
501
List[Event ]: A list of
maximum
30 events
matching
the
specified
conditions .
502
503
Example:
504
>>> get_events(date_range=DateRange( start_date =Date ("2022 -01 -01") , end_date=Date
("2022 -01 -31")), head_entities =[ ISOCode (" USA "), ISOCode (" CHN ")], tail_entities =None ,
relations =[ CAMEOCode ("010")], text_description =" economic
trade ")
505
[Event(date=Date ("2022 -01 -15") , head_entity =ISOCode (" USA "), relation=CAMEOCode
("010") , tail_entity=ISOCode (" CAN "), Event(date=Date ("2022 -01 -10") , head_entity =
ISOCode ("CHN "), relation=CAMEOCode ("010") , tail_entity =ISOCode (" USA "), ...]
506
"""
507
# check
type
508
if
date_range
and not
isinstance (date_range , DateRange):
509
raise
ValueError(f"Input â€™date_range â€™ must be a DateRange
object , but
received
type {type(date_range)}")
510
if
head_entities
and not
isinstance (head_entities , list):
511
raise
ValueError(f"Input â€™head_entities â€™ must be a list , but
received
type {type(
head_entities )}")
512
if
head_entities
and not all(isinstance (iso , ISOCode) for iso in
head_entities ):
513
raise
ValueError(f"Elements
in â€™head_entities â€™ must be
ISOCode
objects")
514
if
tail_entities
and not
isinstance (tail_entities , list):
515
raise
ValueError(f"Input â€™tail_entities â€™ must be a list , but
received
type {type(
tail_entities )}")
516
if
tail_entities
and not all(isinstance (iso , ISOCode) for iso in
tail_entities ):
517
raise
ValueError(f"Elements
in â€™tail_entities â€™ must be
ISOCode
objects")
518
if
relations
and not
isinstance (relations , list):
519
raise
ValueError(f"Input â€™relations â€™ must be a list , but
received
type {type(
relations)}")
520
if
relations
and not all(isinstance (code , CAMEOCode) for
code in
relations):
521
raise
ValueError(f"Elements
in â€™relations â€™ must be
CAMEOCode
objects")
522
if
text_description
and not
isinstance(text_description , str):
523
raise
ValueError(f"Input â€™text_description â€™ must be a string , but
received
type {
type( text_description )}")
524
525
# process
data_kg
by
filtering
based on the
specified
conditions
526
curr_data = data_kg.copy ()
527
curr_data = curr_data[curr_data[â€™DateStr â€™] <= DEFAULT_END_DATE ]
528
if
date_range:
529
curr_data = curr_data [( curr_data[â€™DateStr â€™] >= date_range. start_date .date) & (
curr_data[â€™DateStr â€™] <= date_range.end_date.date)]
60

530
if
head_entities :
531
curr_data = curr_data[curr_data[â€™Actor1CountryCode â€™]. isin ([ iso.code
for iso in
head_entities ])]
532
if
tail_entities :
533
curr_data = curr_data[curr_data[â€™Actor2CountryCode â€™]. isin ([ iso.code
for iso in
tail_entities ])]
534
if
relations:
535
# if first
level
relations
are listed , include
all
second
level
relations
under
them
536
for
code in
relations:
537
if len(code.code) == 2:
538
relations.extend ([ CAMEOCode(c) for c in
dict_code2relation
if c[:2] ==
code.code
and len(c) == 3])
539
curr_data = curr_data[curr_data[â€™EventBaseCode â€™]. isin ([ code.code
for
code in
relations ])]
540
if not
text_description :
541
# get max 30
events
from
the
filtered
data
542
events = []
543
curr_data. drop_duplicates (subset =[â€™QuadEventCode â€™], inplace=True)
544
# sorted by date in
descending
order
545
curr_data.sort_values (by=â€™DateStr â€™, ascending=False , inplace=True)
546
count = 0
547
for _, row in
curr_data.iterrows ():
548
if count
>= 30:
549
break
550
events.append(Event(date=Date(row[â€™DateStr â€™]), head_entity =ISOCode(row[â€™
Actor1CountryCode â€™]), relation=CAMEOCode(row[â€™EventBaseCode â€™]), tail_entity =ISOCode(
row[â€™Actor2CountryCode â€™])))
551
return
events [:30]
552
else:
553
# concat
the
Docids
list of
current
data to get the
news
articles
554
docids_list = [eval(docids) for
docids in
curr_data[â€™Docids â€™]. unique ().tolist ()]
555
docids = list(set([ item
for
sublist
in
docids_list
for
item in
sublist ]))
556
docids = [str(docid) for
docid in docids]
557
news_articles = data_news[data_news[â€™Docid â€™]. isin(docids)]
558
# get the max 30
docids
with
the
highest
BM25
score to the
text_description
559
corpus = news_articles [â€™Title â€™] + â€™ â€™ + news_articles [â€™Text â€™]
560
tokenized_corpus = [doc.split(" ") for doc in corpus]
561
bm25 = BM25Okapi( tokenized_corpus )
562
tokenized_query = text_description .split(" ")
563
doc_scores = bm25.get_scores ( tokenized_query )
564
top_indices = np.argsort(doc_scores )[:: -1][:30]
565
news_articles = news_articles .iloc[ top_indices ]
566
docids = news_articles [â€™Docid â€™]. tolist ()
567
# get max 30
events
from
the
filtered
data
568
events = set ()
569
for
docid in docids:
570
if len(events) >= 30:
571
break
572
doc_curr_data = curr_data[curr_data[â€™Docid â€™] == docid]
573
# reverse
the
order of the
events to get the
latest
events
first
574
doc_curr_data = doc_curr_data . sort_values (by=â€™DateStr â€™, ascending=False)
575
for _, row in
doc_curr_data .iterrows ():
576
events.add(Event(date=Date(row[â€™DateStr â€™]), head_entity =ISOCode(row[â€™
Actor1CountryCode â€™]), relation=CAMEOCode(row[â€™EventBaseCode â€™]), tail_entity =ISOCode(
row[â€™Actor2CountryCode â€™])))
577
return
list(events)
578
579 def
get_entity_distribution (date_range : Optional[DateRange] = None , involved_relations :
Optional[List[CAMEOCode ]] = None , interacted_entities : Optional[List[ISOCode ]] =
None , entity_role : Optional[str] = None) -> Dict[ISOCode , int ]:
580
"""
581
Gets
the
distribution
of
entities
in the
knowledge
graph
under
specified
conditions .
582
583
Parameters:
584
date_range (Optional[DateRange ]): Range of dates to filter
the
events. If None ,
all
dates
are
included.
585
involved_relations (Optional[List[CAMEOCode ]]): List of
relations
that
the
returned
entities
must be
involved
in any of. If first
level
relations
are listed ,
all
second
level
relations
under
them
are
included. If None , all
relations
are
included.
586
interacted_entities (Optional[List[ISOCode ]]): List of
entities
that
the
returned
entities
must
have
interacted
with
any of. If None , all
entities
are
included.
587
entity_role (Optional[EntityRole ]): Specifies
the
role of the
returned
entity in
the
events. Options
are â€™head â€™, â€™tail â€™, or â€™both â€™. If â€™both â€™ or None , the
returned
entity
can be either
head or tail.
588
589
Returns:
590
Dict[ISOCode , int]: A dictionary
mapping
returned
entities â€™ ISO
codes to the
number
of events
with
the
specified
conditions
in which
they
are
involved , sorted by
counts
in
descending
order.
61

591
592
Example:
593
>>> get_entity_distribution ( date_range =DateRange( start_date =Date ("2022 -01 -01") ,
end_date=Date ("2022 -01 -31")), involved_relations =[ CAMEOCode ("010")],
interacted_entities =[ ISOCode (" USA "), ISOCode (" CHN ")], entity_role =" tail ")
594
{ISOCode ("USA "): 3, ISOCode (" CHN "): 1}
595
"""
596
# check
type
597
if
date_range
and not
isinstance (date_range , DateRange):
598
raise
ValueError(f"Input â€™date_range â€™ must be a DateRange
object , but
received
type {type(date_range)}")
599
if
involved_relations
and not
isinstance (involved_relations , list):
600
raise
ValueError(f"Input â€™involved_relations â€™ must be a list , but
received
type {
type( involved_relations )}")
601
if
involved_relations
and not all( isinstance (code , CAMEOCode) for
code in
involved_relations ):
602
raise
ValueError(f"Elements
in â€™involved_relations â€™ must be
CAMEOCode
objects")
603
if
interacted_entities
and not
isinstance (interacted_entities , list):
604
raise
ValueError(f"Input â€™interacted_entities â€™ must be a list , but
received
type
{type( interacted_entities )}")
605
if
interacted_entities
and not all( isinstance (iso , ISOCode) for iso in
interacted_entities ):
606
raise
ValueError(f"Elements
in â€™interacted_entities â€™ must be
ISOCode
objects")
607
if
entity_role
and
entity_role
not in [â€™head â€™, â€™tail â€™, â€™both â€™]:
608
raise
ValueError(f"Input â€™entity_role â€™ must be a string â€™head â€™, â€™tail â€™, or â€™both
â€™, but
received: {entity_role }")
609
610
# process
data_kg
by
filtering
based on the
specified
conditions
611
curr_data = data_kg.copy ()
612
curr_data. drop_duplicates (subset =[â€™QuadEventCode â€™], inplace=True)
613
curr_data = curr_data[curr_data[â€™DateStr â€™] <= DEFAULT_END_DATE ]
614
if
date_range:
615
curr_data = curr_data [( curr_data[â€™DateStr â€™] >= date_range. start_date .date) & (
curr_data[â€™DateStr â€™] <= date_range.end_date.date)]
616
if
involved_relations :
617
# if first
level
relations
are listed , include
all
second
level
relations
under
them
618
for
code in
involved_relations :
619
if len(code.code) == 2:
620
involved_relations .extend ([ CAMEOCode(c) for c in
dict_code2relation
if c
[:2] == code.code
and len(c) == 3])
621
curr_data = curr_data[curr_data[â€™EventBaseCode â€™]. isin ([ code.code
for
code in
involved_relations ])]
622
if
interacted_entities :
623
if
entity_role ==â€™head â€™:
624
curr_data = curr_data[curr_data[â€™Actor2CountryCode â€™]. isin ([ iso.code
for iso
in
interacted_entities ])]
625
elif
entity_role ==â€™tail â€™:
626
curr_data = curr_data[curr_data[â€™Actor1CountryCode â€™]. isin ([ iso.code
for iso
in
interacted_entities ])]
627
else:
628
curr_data = curr_data [( curr_data[â€™Actor1CountryCode â€™]. isin ([ iso.code
for iso
in
interacted_entities ])) | (curr_data[â€™Actor2CountryCode â€™]. isin ([ iso.code
for iso
in
interacted_entities ]))]
629
# count
the
number of events
for
each
entity
630
entity_counts = curr_data[â€™Actor1CountryCode â€™]. _append(curr_data[â€™Actor2CountryCode â€™
]). value_counts ()
631
entity_counts = entity_counts .to_dict ()
632
# sort
the
dictionary
by values in
descending
order
633
entity_counts = dict(sorted( entity_counts .items (), key=lambda
item: item [1],
reverse=
True))
634
entity_counts = {ISOCode(key): value
for key , value in
entity_counts .items ()}
635
return
entity_counts
636
637 def
get_relation_distribution (date_range : Optional[DateRange] = None , head_entities :
Optional[List[ISOCode ]] = None , tail_entities : Optional[List[ISOCode ]] = None) ->
Dict[CAMEOCode , int ]:
638
"""
639
Gets
the
distribution
of
second
level
relations
in the
knowledge
graph
under
specified
conditions.
640
641
Parameters:
642
date_range (Optional[DateRange ]): Range of dates to filter
the
events. If None ,
all
dates
are
included.
643
head_entities (Optional[List[ISOCode ]]): List of head
entities
that
the
events
must
involve
any of. If None , all
head
entities
are
included.
644
tail_entities (Optional[List[ISOCode ]]): List of tail
entities
that
the
events
must
involve
any of. If None , all
tail
entities
are
included.
645
646
Returns:
62

647
Dict[CAMEOCode , int ]: A dictionary
mapping
second
level
relations â€™ CAMEO
codes to
the
number of events
with
the
specified
conditions
in which
they
are
involved ,
sorted
by counts in
descending
order.
648
649
Example:
650
>>> get_relation_distribution ( date_range=DateRange(start_date =Date ("2022 -01 -01") ,
end_date=Date ("2022 -01 -31")), head_entities =[ ISOCode (" USA "), ISOCode (" CHN ")],
tail_entities =None)
651
{CAMEOCode ("010"): 3, CAMEOCode ("011"): 1}
652
"""
653
# check
type
654
if
date_range
and not
isinstance (date_range , DateRange):
655
raise
ValueError(f"Input â€™date_range â€™ must be a DateRange
object , but
received
type {type(date_range)}")
656
if
head_entities
and not
isinstance (head_entities , list):
657
raise
ValueError(f"Input â€™head_entities â€™ must be a list , but
received
type {type(
head_entities )}")
658
if
head_entities
and not all(isinstance (iso , ISOCode) for iso in
head_entities ):
659
raise
ValueError(f"Elements
in â€™head_entities â€™ must be
ISOCode
objects")
660
if
tail_entities
and not
isinstance (tail_entities , list):
661
raise
ValueError(f"Input â€™tail_entities â€™ must be a list , but
received
type {type(
tail_entities )}")
662
if
tail_entities
and not all(isinstance (iso , ISOCode) for iso in
tail_entities ):
663
raise
ValueError(f"Elements
in â€™tail_entities â€™ must be
ISOCode
objects")
664
665
# process
data_kg
by
filtering
based on the
specified
conditions
666
curr_data = data_kg.copy ()
667
curr_data. drop_duplicates (subset =[â€™QuadEventCode â€™], inplace=True)
668
curr_data = curr_data[curr_data[â€™DateStr â€™] <= DEFAULT_END_DATE ]
669
if
date_range:
670
curr_data = curr_data [( curr_data[â€™DateStr â€™] >= date_range. start_date .date) & (
curr_data[â€™DateStr â€™] <= date_range.end_date.date)]
671
if
head_entities :
672
curr_data = curr_data[curr_data[â€™Actor1CountryCode â€™]. isin ([ iso.code
for iso in
head_entities ])]
673
if
tail_entities :
674
curr_data = curr_data[curr_data[â€™Actor2CountryCode â€™]. isin ([ iso.code
for iso in
tail_entities ])]
675
# count
the
number of events
for
each
relation
676
relation_counts = curr_data[â€™EventBaseCode â€™]. value_counts ()
677
relation_counts = relation_counts .to_dict ()
678
# sort
the
dictionary
by values in
descending
order
679
relation_counts = dict(sorted( relation_counts .items (), key=lambda
item: item [1],
reverse=True))
680
relation_counts = {CAMEOCode(key): value
for key , value in
relation_counts .items ()}
681
return
relation_counts
682
683 def
count_news_articles (date_range : Optional[DateRange] = None , head_entities : Optional[
List[ISOCode ]] = None , tail_entities : Optional[List[ISOCode ]] = None , relations:
Optional[List[CAMEOCode ]] = None , keywords: Optional[List[str ]] = None) -> int:
684
"""
685
Counts
the
number
of news
articles
based on
specified
conditions .
686
687
Parameters:
688
date_range (Optional[DateRange ]): Range of dates to filter
the
news
articles. If
None , all
dates
are
included.
689
head_entities (Optional[List[ISOCode ]]): At least
one of the
entities
must be
mentioned
in the
articles
and be the
head
entity in the
events. If None , all
entities
are
included.
690
tail_entities (Optional[List[ISOCode ]]): At least
one of the
entities
must be
mentioned
in the
articles
and be the
tail
entity in the
events. If None , all
entities
are
included.
691
relations (Optional[List[CAMEOCode ]]): At least
one of the
relations
must be
mentioned
in the
articles. If first
level
relations
are listed , all
second
level
relations
under
them
are
included. If None , all
relations
are
included.
692
keywords (Optional[List[str ]]): At least
one of the
keywords
must be
present
in
the
articles. If None , all
articles
are
included.
693
694
Returns:
695
int: The
count of news
articles
matching
the
conditions .
696
697
Example:
698
>>> count_news_articles (date_range =DateRange( start_date =Date ("2022 -01 -01") ,
end_date=Date ("2022 -01 -31")), head_entities =[ ISOCode (" USA "), ISOCode (" CHN ")],
tail_entities =[ ISOCode ("USA "), ISOCode (" CHN ")], relations =[ CAMEOCode ("010")],
keywords =[" trade "])
699
2
700
"""
701
# check
type
702
if
date_range
and not
isinstance (date_range , DateRange):
63

703
raise
ValueError(f"Input â€™date_range â€™ must be a DateRange
object , but
received
type {type(date_range)}")
704
if
head_entities
and not
isinstance (head_entities , list):
705
raise
ValueError(f"Input â€™head_entities â€™ must be a list , but
received
type {type(
head_entities )}")
706
if
head_entities
and not all(isinstance (iso , ISOCode) for iso in
head_entities ):
707
raise
ValueError(f"Elements
in â€™head_entities â€™ must be
ISOCode
objects")
708
if
tail_entities
and not
isinstance (tail_entities , list):
709
raise
ValueError(f"Input â€™tail_entities â€™ must be a list , but
received
type {type(
tail_entities )}")
710
if
tail_entities
and not all(isinstance (iso , ISOCode) for iso in
tail_entities ):
711
raise
ValueError(f"Elements
in â€™tail_entities â€™ must be
ISOCode
objects")
712
if
relations
and not
isinstance (relations , list):
713
raise
ValueError(f"Input â€™relations â€™ must be a list , but
received
type {type(
relations)}")
714
if
relations
and not all(isinstance (code , CAMEOCode) for
code in
relations):
715
raise
ValueError(f"Elements
in â€™relations â€™ must be
CAMEOCode
objects")
716
if
keywords
and not
isinstance(keywords , list):
717
raise
ValueError(f"Input â€™keywords â€™ must be a list , but
received
type {type(
keywords)}")
718
if
keywords
and not all(isinstance(keyword , str) for
keyword
in
keywords):
719
raise
ValueError(f"Elements
in â€™keywords â€™ must be
strings")
720
721
# process
data_kg
by
filtering
based on the
specified
conditions
722
curr_data = data_kg.copy ()
723
curr_data. drop_duplicates (subset =[â€™QuadEventCode â€™], inplace=True)
724
curr_data = curr_data[curr_data[â€™DateStr â€™] <= DEFAULT_END_DATE ]
725
if
date_range:
726
curr_data = curr_data [( curr_data[â€™DateStr â€™] >= date_range. start_date .date) & (
curr_data[â€™DateStr â€™] <= date_range.end_date.date)]
727
if
head_entities :
728
curr_data = curr_data[curr_data[â€™Actor1CountryCode â€™]. isin ([ iso.code
for iso in
head_entities ])]
729
if
tail_entities :
730
curr_data = curr_data[curr_data[â€™Actor2CountryCode â€™]. isin ([ iso.code
for iso in
tail_entities ])]
731
if
relations:
732
# if first
level
relations
are listed , include
all
second
level
relations
under
them
733
for
code in
relations:
734
if len(code.code) == 2:
735
relations.extend ([ CAMEOCode(c) for c in
dict_code2relation
if c[:2] ==
code.code
and len(c) == 3])
736
curr_data = curr_data[curr_data[â€™EventBaseCode â€™]. isin ([ code.code
for
code in
relations ])]
737
# concat
the
Docids
list of
current
data to get the
news
articles
738
docids_list = [eval(docids) for
docids in
curr_data[â€™Docids â€™]. unique ().tolist ()]
739
docids = list(set([ item
for
sublist
in
docids_list
for
item in
sublist ]))
740
docids = [str(docid) for
docid in docids]
741
news_articles = data_news[data_news[â€™Docid â€™]. isin(docids)]
742
if
keywords:
743
# filter
the
news
articles
that
contain
at least
one of the
keywords
in the
title
or text
string
744
news_articles = news_articles [ news_articles [â€™Title â€™]. str.contains(â€™|â€™.join(
keywords), case=False) | news_articles [â€™Text â€™]. str.contains(â€™|â€™.join(keywords), case
=False)]
745
return
len( news_articles )
746
747 def
get_news_articles (date_range: Optional[DateRange] = None , head_entities : Optional[
List[ISOCode ]] = None , tail_entities : Optional[List[ISOCode ]] = None , relations:
Optional[List[CAMEOCode ]] = None , keywords: Optional[List[str ]] = None ,
text_description : Optional[str] = None) -> List[Tuple[Date , str ]]:
748
"""
749
Retrieves
news
articles
based on
specified
conditions.
750
Inherits
common
filter
parameters
from
count_news_articles . See
count_news_articles
for
more
details
on these
parameters .
751
752
Additional
Parameters:
753
text_description (Optional[str ]): Textual
description
to match
with
the
news
articles. If None , the
returned
articles
are
sorted by date in
descending
order;
otherwise , sorted
by
relevance
to the
description .
754
755
Returns:
756
List[Tuple[Date , str ]]: A list of
maximum
15 news
articles
matching
the
specified
conditions , each
represented
by a tuple of date
and
title.
757
758
Example:
759
>>> get_news_articles (date_range=DateRange(start_date =Date ("2022 -01 -01") ,
end_date=Date ("2022 -01 -31")), head_entities =[ ISOCode (" USA "), ISOCode (" CHN ")],
tail_entities =[ ISOCode ("USA "), ISOCode (" CHN ")], relations =[ CAMEOCode ("010")],
64

keywords =[" trade "],
text_description =" Economic
trade is
encouraged
between
USA and
China .")
760
[( NewsArticle .date=Date ("2022 -01 -15") , NewsArticle .title =" China
and USA
sign
trade
deal "), ( NewsArticle.date=Date ("2022 -01 -10") , NewsArticle .title =" Trade
agreement
between
USA and
China ")]
761
"""
762
# check
type
763
if
date_range
and not
isinstance (date_range , DateRange):
764
raise
ValueError(f"Input â€™date_range â€™ must be a DateRange
object , but
received
type {type(date_range)}")
765
if
head_entities
and not
isinstance (head_entities , list):
766
raise
ValueError(f"Input â€™head_entities â€™ must be a list , but
received
type {type(
head_entities )}")
767
if
head_entities
and not all(isinstance (iso , ISOCode) for iso in
head_entities ):
768
raise
ValueError(f"Elements
in â€™head_entities â€™ must be
ISOCode
objects")
769
if
tail_entities
and not
isinstance (tail_entities , list):
770
raise
ValueError(f"Input â€™tail_entities â€™ must be a list , but
received
type {type(
tail_entities )}")
771
if
tail_entities
and not all(isinstance (iso , ISOCode) for iso in
tail_entities ):
772
raise
ValueError(f"Elements
in â€™tail_entities â€™ must be
ISOCode
objects")
773
if
relations
and not
isinstance (relations , list):
774
raise
ValueError(f"Input â€™relations â€™ must be a list , but
received
type {type(
relations)}")
775
if
relations
and not all(isinstance (code , CAMEOCode) for
code in
relations):
776
raise
ValueError(f"Elements
in â€™relations â€™ must be
CAMEOCode
objects")
777
if
keywords
and not
isinstance(keywords , list):
778
raise
ValueError(f"Input â€™keywords â€™ must be a list , but
received
type {type(
keywords)}")
779
if
keywords
and not all(isinstance(keyword , str) for
keyword
in
keywords):
780
raise
ValueError(f"Elements
in â€™keywords â€™ must be
strings")
781
if
text_description
and not
isinstance(text_description , str):
782
raise
ValueError(f"Input â€™text_description â€™ must be a string , but
received
type {
type( text_description )}")
783
784
# process
data_kg
by
filtering
based on the
specified
conditions
785
curr_data = data_kg.copy ()
786
curr_data. drop_duplicates (subset =[â€™QuadEventCode â€™], inplace=True)
787
curr_data = curr_data[curr_data[â€™DateStr â€™] <= DEFAULT_END_DATE ]
788
if
date_range:
789
curr_data = curr_data[
790
(curr_data[â€™DateStr â€™] >= date_range . start_date .date) & (curr_data[â€™DateStr â€™]
<= date_range.end_date.date)]
791
if
head_entities :
792
curr_data = curr_data[curr_data[â€™Actor1CountryCode â€™]. isin ([ iso.code
for iso in
head_entities ])]
793
if
tail_entities :
794
curr_data = curr_data[curr_data[â€™Actor2CountryCode â€™]. isin ([ iso.code
for iso in
tail_entities ])]
795
if
relations:
796
# if first
level
relations
are listed , include
all
second
level
relations
under
them
797
for
code in
relations:
798
if len(code.code) == 2:
799
relations.extend ([ CAMEOCode(c) for c in
dict_code2relation
if c[:2] ==
code.code
and len(c) == 3])
800
curr_data = curr_data[curr_data[â€™EventBaseCode â€™]. isin ([ code.code
for
code in
relations ])]
801
docids_list = [eval(docids) for
docids in
curr_data[â€™Docids â€™]. unique ().tolist ()]
802
docids = list(set([ item
for
sublist
in
docids_list
for
item in
sublist ]))
803
docids = [str(docid) for
docid in docids]
804
news_articles = data_news[data_news[â€™Docid â€™]. isin(docids)]
805
if
keywords:
806
# filter
the
news
articles
that
contain
at least
one of the
keywords
in the
title
or text
string
807
news_articles = news_articles [ news_articles [â€™Title â€™]. str.contains(â€™|â€™.join(
keywords), case=False) | news_articles [â€™Text â€™]. str.contains(â€™|â€™.join(keywords), case
=False)]
808
if not
text_description :
809
# get max 15 news
articles
from
the
filtered
data
810
# sorted by date in
descending
order
811
news_articles .sort_values (by=â€™Date â€™, ascending=False , inplace=True)
812
news_articles = news_articles [[â€™Date â€™, â€™Title â€™]]. head (15)
813
return
[( Date(row[â€™Date â€™]), row[â€™Title â€™]) for _, row in
news_articles .iterrows ()]
814
else:
815
# get the max 15 news
articles
with
the
highest
BM25
score to the
text_description
816
corpus = news_articles [â€™Title â€™] + â€™ â€™ + news_articles [â€™Text â€™]
817
tokenized_corpus = [doc.split(" ") for doc in corpus]
818
bm25 = BM25Okapi( tokenized_corpus )
819
tokenized_query = text_description .split(" ")
820
doc_scores = bm25.get_scores ( tokenized_query )
65

821
top_indices = np.argsort(doc_scores )[:: -1][:15]
822
news_articles = news_articles .iloc[ top_indices ]
823
return
[( Date(row[â€™Date â€™]), row[â€™Title â€™]) for _, row in
news_articles .iterrows ()]
824
825 def
browse_news_article (date: Date , title: str) -> str:
826
"""
827
Retrieves
the
full
text of a news
article
by its
title.
828
829
Parameters:
830
date (Date): The
date of the
news
article
to
retrieve.
831
title (str): The
title of the
news
article
to
retrieve.
832
833
Returns:
834
str: The date , the
title
and
full
contents
of the
news
article.
835
836
Example:
837
>>> browse_news_article (Date ("2022 -01 -10") , "Trade
agreement
between
USA and
China ")
838
2022 -01 -10:
839
Trade
agreement
between
USA and
China
840
On
January 10, 2022 , a trade
agreement
was
signed
between
the USA and
China to
promote
economic
cooperation ...
841
"""
842
# check
type
843
if not
isinstance(date , Date):
844
raise
ValueError(f"Input â€™date â€™ must be a Date
object , but
received
type {type(
date)}")
845
if not
isinstance(title , str):
846
raise
ValueError(f"Input â€™title â€™ must be a string , but
received
type {type(title)
}")
847
848
# process
data_news
to find
the
news
article
with
the
specified
date
and
title
849
curr_data = data_news [( data_news[â€™Date â€™] == date.date) & (data_news[â€™Title â€™] == title
)]
850
if len(curr_data) == 0:
851
raise
ValueError(f"No news
article
found
with
the
specified
date {date.date} and
title {title}")
852
return f"{date }:\n{title }\n{curr_data[â€™Text â€™]. values [0]}"
66

