This journal is © The Royal Society of Chemistry 2023
Soft Matter, 2023, 19, 8329–8336 |  8329
Cite this: Soft Matter, 2023,
19, 8329
Learning to write with the fluid rope trick†
Gaurav Chaudhary,
ab Stephanie Christ,a A. John Hart
b and L. Mahadevan
*ac
Direct ink writing, a versatile method of 3D and 4D printing, requires the precise placement of a nozzle just
above the print surface to prevent fluid instabilities that cause deviations from the prescribed print path. But
what if one could harness the instability associated with the spontaneously folding or coiling of a thin stream
of viscous fluid, i.e. use the ‘‘fluid rope trick’’ to write specified patterns on a substrate? Here we use Deep
Reinforcement Learning to derive control strategies for the motion of the extruding nozzle and thus the fluid
patterns that are deposited on the surface. The method proceeds by having a learner (nozzle) repeatedly
interact with the environment (a viscous filament simulator), and improves its strategy using the results of this
experience. We demonstrate the outcome of the learned control instructions using experiments to
manipulate a falling viscous jet and create cursive writing patterns and Pollockian paintings on substrates.
1 Introduction
The rapid evolution of three-dimensional (3D) printing technol-
ogy has enabled new manufacturing capabilities1,2 and allowed
for the creation of complex patterns via the additive deposition
of complex materials through a computer-controlled nozzle.
However, the ultimate limits on print quality are imposed by
the rheodynamics of the printed material that is a function of
material rheology and the ability to design robust print paths for
the nozzle. Defects in printing typically arise in non-uniformly
extruded/deposited material and instabilities such as folding
and coiling of fluid jets.3 A simple protocol to prevent these
defects follows by forcing the nozzle trajectory to exactly mimic
the target print pattern from a very small height oﬀset.
While this approach increases the accuracy of layer-by-layer
direct writing of 3D objects, the result is that printing is
typically a very slow process. Moreover, it is challenging to
adapt these methods to complex topographies of the substrate
on which the deposited material is laid down, or to precisely
control sharp turns without distorting the extruded filament.
Here, we explore the possibility that 3D printing could be sped
up by operating with a nozzle that is elevated above the print
surface, and harnessing the dynamic instability of a falling
fluid jet4–9 to enable rapid accurate printing without requiring
the nozzle to exactly mimic the target pattern.
While the coiling instability of a falling jet has been studied
in variety of diﬀerent situations,3,10–13 most prior work has
focused on explorations of the resulting patterns in response to
simple controls of the nozzle. It is perhaps thus natural to ask if
we can actively learn to precisely control the nozzle in space-
time and print desired patterns by harnessing folding and
coiling instabilities rather than avoiding them. That this can
be done, and very well, is evidenced in the striking art of
Jackson Pollock, who created paintings by dripping and pour-
ing paint on a canvas from a height while moving his hand.14
This raises the question: given a final target pattern or shape in
a plane, how can we optimize the nozzle trajectory so that a
continuous stream of material can be printed accurately and
quickly, without having to precisely translate the nozzle along
the print path, or bringing the nozzle close to the substrate. Put
simply, can a machine learn and deploy these optimal strate-
gies from experience?
Our approach taps into the recent success of a class of
machine learning algorithms known as reinforcement learning
methods15 that are able to harness the expressive power of
neural nets (NN) to explore and exploit a large state and action
space and find solutions to diﬃcult tasks. The starting point
is a physical simulator that characterizes the physics of
thin threads of viscous fluid extruded from a height and
captures the interactions between an agent (the nozzle head)
and the environment (a print surface). Then, by building
a framework of learning through repeated interactions with
the environment, we show that it is possible to find a nozzle
trajectory that can print a target pattern. Here, we only consider
the case of learning to print a single layer of material onto a
flat surface and leave the challenging problem of stacking
multiple such layers to build a 3D structure for future
investigation.
a School of Engineering and Applied Sciences, Harvard University, Cambridge, MA
02138, USA. E-mail: lmahadev@g.harvard.edu
b Department of Mechanical Engineering, Massachusetts Institute of Technology,
Cambridge, MA 02139, USA
c Department of Physics, Department of Organismic and Evolutionary Biology,
Harvard University, Cambridge, MA 02138, USA
† Electronic supplementary information (ESI) available: Supplementary Videos
1–4. See DOI: https://doi.org/10.1039/d3sm00177f
Received 12th February 2023,
Accepted 21st September 2023
DOI: 10.1039/d3sm00177f
rsc.li/soft-matter-journal
Soft Matter
PAPER
Published on 23 October 2023. Downloaded by Harvard University on 3/22/2024 2:06:45 AM. 
View Article Online
View Journal | View Issue

8330 |  Soft Matter, 2023, 19, 8329–8336
This journal is © The Royal Society of Chemistry 2023
2 The dynamics of viscous filaments
The simulator used to model the liquid-rope instability of a
viscous fluid follows earlier work on characterizing the coiling
of liquid jets,16 which we summarize briefly. A thin stream of
viscous liquid is represented using a discrete Lagrangian descrip-
tion that takes advantage of the large aspect ratio (length/radius)
of the system to deduce a reduced order description for the fluid
thread. Then, the centerline x(S,t) A R3 and an orthonormal
material frame [d1(S,t),d2(S,t),d3(S,t)] suﬃces to capture the time
evolution of viscous thread as shown in Fig. 1. Here, the material
frame is adapted to the centerline by requiring d3 to align with the
tangent to the centerline, so that d1,d2 span the plane normal to
centerline’s tangent. The dynamical equations of the thread of the
thread are given by the balance of linear and angular momentum
and yield equations for the position x(S,t) and the orthonormal
frame associated with di(S,t), or equivalently, the spin angular
velocity v(S,t), given by:16
rA0x¨(S,t) = Fv(S,t) + f (S,t)
(1)
lJ:v(S,t) = Mv(S,t) + m(S,t)
(2)
Here, Fv and Mv are the internal resultant viscous forces and
moments in the thread arising from the rates of stretching,
bending and twisting of the thread, while f and m are the external
body force and body moment density, respectively. The expres-
sions for the resultant force and moments in the fluid thread are
expressed using the kinematics of the centerline, the local area A0
and moments of inertia J at every cross-section S, as well as the
viscosity of the fluid (assuming it can be modeled as a simple
Newtonian liquid); see,8,16 for details of the expressions of the
individual terms in the above equation and their respective
discretizations. To complete the formulation of the problem, we
supplement the equations of motion with boundary conditions
for the position and velocity of the filament as it exits the nozzle
and conditions when it contacts the substrate assuming that it
touches down tangentially and adheres instantly.
A critical dynamical variable underlying the generation of
complex patterns17 is the ability to move the nozzle; we assume
that it can be moved freely in a plane using horizontal movements
and can also rotate relative to two axes, as shown in Fig. 2(A), with
the angles f and y describing the rotational degrees of freedom
(DoF). Assuming that the flow rate (Q) and nozzle extrusion
diameter a are constant, controlling the writing/painting pattern
on the substrate requires that the agent (nozzle) have time-varying
translational and rotational velocities, likely to be bounded within
a range of practical relevance. Vertical motion of the nozzle
changes the nature of the pattern deposited; at low heights, the
jet is rectilinear, then starts to coil slowly as the height is increased
past a first threshold. When allowed to fall from even larger
heights, the jet coils rapidly as inertial eﬀects start to dominate.
In Fig. 2(A) (bottom), we show a coiling pattern deposited on
the surface (z = 0); plotted using the normalized coordinates
x* = x/a and y* = y/a with the nozzle radius a. For the remainder
of the article, we normalize all the relevant lengths with the
nozzle radius and velocity with
ﬃﬃﬃﬃﬃ
gh
p
, where g is the gravitational
acceleration and h is the nozzle height. The coil radius
increases as the height of the nozzle is increased, and when
the agent is translated linearly along the y-axis with a constant
velocity, following a short transient, we see that an overlaid
coiling pattern is deposited on the substrate z = 0 similar to
what has been observed experimentally.17 These observations
suggest that writing a desired pattern requires controlling the
various DoFs of the nozzle. But how can we learn the form of
the nozzle’s actions for a given substrate pattern?
3 A reinforcement learning framework
Reinforcement learning (RL)15 provides one possible answer by
allowing the action of an agent to repeatedly interact with the
environment and converge towards an optimal policy without
having any prior knowledge of the underlying model. An RL
problem is defined in terms of states, actions and rewards. The
state s A S is a quantitative description of the environment at the
current time, with S being the set of all possible states. In every
state, a set of actions A(s) are available to the agent. By taking an
action a A A(s), the agent transitions from one state to another and
receives a numerical scalar reward signal r from the environment.
The reward is a measure of how desirable it is to take action a in
state s. Overall, the goal of the learner (or agent) is to find an action
policy p(a|s) which maximizes the cumulative reward over the
entire learning episode by exploring diﬀerent ways of interacting
with the environment; this schematic is summarized in Fig. 2(B).
For the printing problem, the current state is defined by the
following parameters: the arc length S of the pattern that has
been printed so far, the current position of the nozzle (x,y,z,f,y)
with zA [hmin,hmax], and the last action, corresponding to the
velocity of the nozzle (vx,vy,vz,vf,vy). If the height of the nozzle z is
outside of its prescribed range, the state is considered invalid.
Just as the states, the actions (DoFs) that describe the motion of
the nozzle are assumed to be continuous. The agent has up to
five degrees of freedom: translation velocities (vx,vy,vz) and
rotational velocities (vf,vy). Furthermore, we assume that the
range of all actions is bounded within the interval [vmin,vmax]. For
the position and motion of the nozzle, only the DoF that are part
of the action are considered; the other parameters are assumed
Fig. 1
Representation of the fluid thread and the associated material
frame. Taking advantage of the slender aspect ratio of the filament,
we can completely define its trajectory in space-time using its center line
x(S,t) A R3 and an orthonormal material frame [d1(S,t),d2(S,t),d3(S,t)] whose
dynamics follow from the balance of linear and angular momentum;
Figure adapted from Audoly et al.16
Paper
Soft Matter
Published on 23 October 2023. Downloaded by Harvard University on 3/22/2024 2:06:45 AM. 
View Article Online

This journal is © The Royal Society of Chemistry 2023
Soft Matter, 2023, 19, 8329–8336 |  8331
to stay constant. Thus, the dimension of the state is between 3
(one DoF) and 11 (five DoF).
We use an oﬀ-policy actor-critic named V-RACER18 as our RL
framework, although many other methods are also likely to
work. A summary of our process follows: the algorithm trains a
neural network to approximate a continuous path pw(a|s) for
the nozzle (continuous policy approximation). The policy network
is randomly initialized and then iteratively updated through
repeated attempts to reach the target following the policy gradient
theorem. We employ ‘‘Remember and Forget Experience Replay’’
to reuse past experiences over multiple iterations to update the
policy in a stable and data-eﬃcient manner, with hidden network
layers that each have 128 LSTM (long short-term memory) units.
This representational capacity of the network was found to be
suﬃcient for the cases considered in this work. The actuation
period (temporal resolution) of our simulations was generally
fixed to 0.01 s; varying the number of units and the number of
layers did not change the final optimized solutions.
Since the goal of the learning to write is equivalent to depositing
a 2D pattern of the same shape as a target input pattern, the
reward/penalty is chosen so as to reflect the mismatch between the
target and the printed pattern. The target pattern is given as a time-
ordered list of 2D coordinates of the path. We implemented the
reward by comparing the position of the printed vertices with
vertices of the given target shape. Denoting the total arc length of
the pattern that has been created so far by Si – where i is the current
learning step, the error is computed by integrating the actual
position relative to the target from the last step to the current step:
r ¼ 
ðSi
Si1
~xtargetðSÞ  ~xðSÞ

dS
(3)
Here we have chosen the error at a certain arc length in terms of the
absolute difference between the target position and the actual
position, linearly interpolated from their two respective neighbors.
In addition to the reward based on the pattern, we give a strong
negative reward for invalid states, i.e. for invalid heights z. Using
this reward function, the maximum – and optimal – cumulative
reward is 0, as this would indicate that the created pattern does not
deviate from the target pattern at any point.
To create regular initial conditions for learning, the simulation
is first stabilized by using a constant velocity (vx,vy,vz,vf,vy) =
(v0,0,0,0,0) for a fixed number of time steps until the pattern
follows a simple straight line. From there, the agent is allowed to
start learning the appropriate set of actions to replicate the target
pattern. In practice, in addition to the simulation parameters
(nozzle flow/radius and fluid properties) and RL parameters
(learning rate, discount factor, size of NN, activation function),
we also specify the maximum number of steps per episode step ns,
i.e. the number of actions that the agent can take before the
episode is over.
4 Using reinforcement to learn writing
To validate that the RL agent takes optimal actions, we first ask
if we can reproduce the simplified scenario of printing a
straight line from a nozzle. As shown earlier in Fig. 2(A), for
an arbitrary unidirectional velocity, an uncontrolled agent,
translating with an arbitrary velocity produces a pattern con-
sisting of overlaid coils.11 If the nozzle is allowed to vary its
planar velocity (vx and vy), we see that over time associated with
an increase in the number of episodes, the agent converges to
create a straight line as shown in Fig. 3(A)-i (green curves).
Consistent with this, the cumulative reward plateaus with
increasing episode number (Fig. 3(A)-ii); the value of the
plateau depends on the height of fluid extrusion and bounds
on the nozzle actions. To draw a straight line, the agent speed
must counter the eﬀective velocity at which the coils are
naturally laid on the surface, i.e. the optimal solution must
satisfy the relations vx Z OR, and vy B 0. The action density
plots in Fig. 3(A)-iii show that the agent does indeed reach this
Fig. 2
Printing with the liquid-rope instability. (A) The state of a printing nozzle is represented by its translational coordinates (X,Y,Z) w.r.t. a stationary
frame. The azimuthal angle f and polar angle y further specify the ink extrusion direction (solid red arrow). Simulation of viscous thread (Z = 5000 cP)
coiling as the print head is translated vertically at a constant speed. The top view shows coils of increasing radii as the nozzle is raised from z = 0.5 to z =
12.5 cm. Translating the nozzle at a constant speed of 0.5 cm s1 creates periodic coils on the surface as shown for a fixed set of parameters. (B) In the
controlled setting, the agent (nozzle) interacts with the environment to improve its action-selection policy p. It receives a state st and numerical reward rt
from the environment, based on which it updates its policy and returns the next action at. By taking action at, the environment transitions to the next state
st+1. It measures its desirability through the reward rt+1 and sends the information, along with the new state, back to the agent.
Soft Matter
Paper
Published on 23 October 2023. Downloaded by Harvard University on 3/22/2024 2:06:45 AM. 
View Article Online

8332 |  Soft Matter, 2023, 19, 8329–8336
This journal is © The Royal Society of Chemistry 2023
state. We also test the performance by restricting the action to a
lower maximum velocity (shown in red in Fig. 3(A)-i) and find
that the agent is unable to converge to a straight line in this
case, consistent with our expectation. To understand the ability
of the RL algorithm to learn, we also increase the height of
fluid extrusion, keeping the flow rate same as previous cases.
A higher height allows for fluid jet to accelerate resulting in a
higher coiling frequency. In such a case the appropriate actions
required to prevent depositing coil require a higher velocity
bound, in the absence of which the cumulative reward will
decrease further, as shown in Fig. 3(A)-ii.
To learn to write well, the agent must learn to negotiate
curves with complex curvature profiles. Therefore, we need a
target pattern with a wide range of curvatures and rates of
variation of the curvature; an exponentially decaying sinusoidal
wave y = 10e1000x sin2000px serves both purposes. The agent is
now allowed an additional action vz a 0 in addition to its
ability to vary vx,vy. In Fig. 3(B) we show the learned patterns as
a function of episode number, and see that after about 5000
episodes, the correct shape is learned; the visible accuracy of
the task does not improve much beyond that. A closer look at
the evolution of the learned pattern shows that the agent first
learns to match the pattern on larger length scales, followed by
further improvements to closely match the features with sharp
changes in curvature, i.e. on smaller length scales. This is
consistent with the cumulative reward first showing a sharp
increase (i.e. getting the rough pattern right) followed by a
smaller increase (i.e. getting the finer details right) corres-
ponding to the plateau-like regime in Fig. 3(A)-ii associated
with later episodes.
One expects that the optimal strategy for the agent ought to
either utilize or avoid the coiling instability depending on the
nature of the curvature profiles in the target pattern. Thus, for
curvatures comparable to the coiling radius, one should use the
natural coiling instability, and otherwise avoid it by moving
quickly. However, when the (position and velocity) actions of
the nozzle are bounded, writing patterns with curvatures that
are significantly larger than the coil radius can be diﬃcult. To
challenge the agent with such patterns, we change the absolute
scale of the target pattern, thus changing the curvature profiles
overall. This allows us to ask how well the RL agent, with the
same bounds on action, learns to draw patterns at diﬀerent
scales. In Fig. 3(C) we compare the absolute curvature of the
target pattern with that of the learned patterns as a function of
scale, using the same exponential form used in Fig. 3(B). For
each case, the overall scale of the target pattern is either halved
or doubled, keeping all other parameters fixed. We see that the
magnitude of curvature of the learned patterns is generally
Fig. 3
Using reinforcement learning to control the liquid coiling instability. (A-i) The agent takes actions, at = {vx,vy} while extruding liquid from a fixed
height of 7 cm and learns to draw a straight line over multiple iterations, seeking to maximize the total reward. The red and green curves correspond of
the maximum limit of 1 cm s1 and 5 cm s1 on the velocity components. (A-ii) Maximum reward depends on the limits on translation velocity, and the
height from which the liquid is extruded. A better control can be learned when extruding from a smaller height for the same limits of velocity
components. (A-iii) A density plot of the actions taken at various episodes. To create a straight line, the agent learns to suppress coiling by moving solely
in the x-direction. (B) A more complex task of drawing a varying amplitude wave using a larger set of actions, at = {vx,vy,vz}. Unlike the straight line in (A),
the agent harnesses the liquid coils to draw the curved pattern. (C) The performance of the agent also depends on the relative scale of liquid coils and
target curvature. A comparison of the local curvature (|k|) of the drawn pattern at diﬀerent scales show the challenge in learning when the scale of target
curvature is significantly smaller than the nature curvature of liquid coils. (D-i) The constrained set of actions limits the agent’s performance in drawing
larger curvature. (D-ii) The fluid material properties, such as the kinematic viscosity Z, also limit the accuracy of the learned pattern.
Paper
Soft Matter
Published on 23 October 2023. Downloaded by Harvard University on 3/22/2024 2:06:45 AM. 
View Article Online

This journal is © The Royal Society of Chemistry 2023
Soft Matter, 2023, 19, 8329–8336 |  8333
diﬀerent from the target curves at the locations of extreme
curvature. The case with smallest scale shows significant devia-
tions from the target, implying that decreasing the scale of the
target pattern (hence increasing the curvature), results in a
reduction of the agent’s ability to print the target. The bounds
on velocity and position of the nozzle determine the largest
curvature that can be deposited on the surface. A slow moving
agent deposits overlaid coils whose radius change with the
height of fluid extrusion (as shown in Fig. 2(A)) leading to
deposited patterns that resemble the naturally occurring state
while a fast moving agent very close to the surface ideally can
realize any curvature. Restricting the agent to a minimum
height above the surface requires finding an action sequence
to realize curvatures through reinforcement. For the smallest
scales in Fig. 3(B), we see that the agent is unable to find any
action sequence that will allow it to deposit the concomitantly
large curvatures in the target pattern.
The substrate patterns associated with the jet coiling instability
are aﬀected by both the limits on the dynamics of the nozzle as
well as the properties of the fluid. To explore their respective roles,
in Fig. 3(D)-i we show the eﬀect of limiting the agent’s actions to
vx,vy a 0,vz = 0, i.e. planar motion and compare it to the case when
vz a 0. In Fig. 3(B) we see that extruding fluid from a constant
height introduces an unwanted coiling response in the learned
pattern, especially near the regions of large curvature in the target
pattern, demonstrating the influence of limiting the action space
in the learning problem. In Fig. 3(D)-ii we show the eﬀect of
changing the magnitude of the viscous forces by simply changing
the kinematic viscosity (Z) of the fluid; reducing the viscosity leads
to an increase in the coiling frequency in a predictable way and we
see that after a similar number of learning episodes, the learned
pattern is not quite as accurate. These tests of deploying RL point
to a simple but important lesson; choosing the right range of
actions is critical for good performance in any task, and becomes
Fig. 4
Using RL to reproduce cursive writing. The agent, with actions at = {vx,vy}, can harness liquid coiling to write cursive text. (A) The predicted deposited
patterns from fixed heights as shown. In each case the z-component of velocity is set to zero. (B) The nozzle trajectories at corresponding heights are
shown. The mismatch between the deposited pattern and the nozzle trajectory is apparent at higher nozzle location. (C) A comparison of local direction
(local orientation w.r.t the horizontal y) of translation of the nozzle and the printed pattern show that non-trivial actions are performed to control the target
pattern, and the agent does not just follow the trajectory of target pattern. (D) The normalized magnitude of actions, v
j
j ¼
ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ
vx2 þ vy2


q
.
ﬃﬃﬃﬃﬃ
gh
p
, that were
used from printing are shown. (E) The magnitude squared coherence between the printed patterns and the target pattern is shown. A higher coherence is
observed at lower spatial frequencies. (F) The curvature of the cursive text plotted as a function of arc length shows misaligned curvature peaks for patterns
deposited from diﬀerent heights. The error in k vs. S curves can be decomposed into vertical and a horizontal components (in G) using elastic functional
data analysis. (H) Changing the height of extrusion allows for directly controlling the total printing time (inset). A speed-error trade-oﬀresults as a
consequence. Within a given range of actions, a lower error, defined as e ¼
Ð
1  kðSÞ=k0ðSÞ
ð
ÞpdS

1=p, is achieved when nozzle is held closer to the surface
as a result of low-coiling frequency and smaller liquid coil radii. Here we define non-dimensional printing speed v ¼ Stotal

tp


ﬃﬃﬃﬃﬃ
gh
p
.
Soft Matter
Paper
Published on 23 October 2023. Downloaded by Harvard University on 3/22/2024 2:06:45 AM. 
View Article Online

8334 |  Soft Matter, 2023, 19, 8329–8336
This journal is © The Royal Society of Chemistry 2023
particularly clear in the context of interacting with and learning
using physical systems.
To further explore the ability of RL in more realistic and useful
tasks, we now demonstrate how to guide a nozzle to mimic cursive
writing, or paint like Pollock. We first prescribe the target pattern:
a continuous curve associated with the word ‘‘Cambridge’’ along
with an action space (vx,vy), but no vertical velocity, i.e. vz = 0. Since
the coiling frequency is higher when fluid is extruded from a
larger height (h), the nozzle must translate faster to avoid
unstable/unwanted coiling. The natural coiling frequency for the
range of extrusion heights explored in Fig. 4 ranges between 0.1–
0.6 s1. The ratio of the agent’s translational speed to the natural
coiling speed varies widely in the range 0.05–5 for each height due
to the use of the coiling mode and its avoidance. In Fig. 4(A), we
show how the agent learns to write from different fixed heights in
the range z A [2,10] cm, after the same number of training
episodes. While the overall patterns look similar, a closer look
shows noticeable differences in the regions of the curve with large
curvature e.g. letters ‘‘r’’, ‘‘d’’ and ‘‘g’’. In Fig. 4(B) we show the
trajectory of the nozzle at a fixed height as it moves to deposit the
pattern on the substrate; in regions of the pattern that are almost
straight (or weakly curved), the agent avoids the coiling instability
by generally moving rapidly, while it uses the coiling instability to
achieve higher curvature in regions where the target pattern
demands it. Indeed, the deployment of coils becomes more
apparent when printing from higher heights, when the nozzle
makes sharper turns in its path (e.g. for the letter ‘‘m’’) to be able
to print smooth patterns on the surface.
Continuing to characterize the properties of printing using a
nozzle operating from a height, in Fig. 4(C) we show the diﬀer-
ences between the local direction of motion of the nozzle and the
local direction of the pattern that gets laid on the surface. We see
that there are two types of errors: at some places, the local
orientation of curves appears phase-shifted, while in other regions
the amplitudes of the curves are poorly correlated. The phase-shift
corresponds to the lag between the nozzle’s position and the point
of contact of fluid jet with the surface; locations where the two are
poorly correlated correspond to the case when the nozzle deploys
fluid coils to print. In contrast, the normalized velocity magnitude,
v
j
j ¼ jvj

ﬃﬃﬃﬃﬃ
gh
p
, shows frequent changes when the nozzle is held at
a small but fixed height as shown in Fig. 4(D), and thus leads to
diﬀerences in the curvature of the nozzle and the pattern being
printed. We see that the nozzle is likely to more closely follow the
target pattern while printing the pattern from a lower height.
To quantify the accuracy of learning the task, we use two
approaches based on local measures to derive global metrics.
Since we work with planar curves, up to rigid motions (that we
do not worry about), the target and learned patterns are
completely characterized by their scalar curvature as a function
of the arc-length. For one measure of the error on the scale of
the whole pattern, we define the coherence metric in terms of
the spatial Fourier of the pattern as follows:
Ck0kðf Þ ¼
Pk0kðf Þ

2
Pk0k0ðf ÞPkkðf Þ


(4)
where Pkk(f) and Pk0k0(f) are the power spectral densities of the
curvatures k0(S) (target) and k(S) (learned), respectively, and
Pk0k(f) is the cross power spectral density between k0(S) and
k(S),19 observing that Ck0k(f) A [0,1]. Plotting the coherence in
Fig. 4(C), we note that k0(S) and k(S) are strongly associated at
very low spatial frequencies (or relatively larger scales) while at
higher spatial frequencies the association is relatively weak.
This is consistent with the observations from other learning
experiments as well: the agent is can capture the large scale
features of the curves either by moving along straighter or
slightly curved paths, but when the target curvature scales are
larger than the natural coiling scales, there is a mismatch
between the target and learned curvature.
To compare the diﬀerence between the target and learned
curvature along the trajectory raises a familiar problem of curve
registration – how does one align points along the learned path
with points along the target pattern, given that the speed of the
nozzle is not necessarily a constant? To solve this problem, we
use methods from functional and shape data analysis20 whereby
we simultaneously solve the problem of registration and deter-
mination of error by insisting on reparametrization invariance of
the error metric. A natural solution that presents itself is to align
the curvature data for various cases with the curvature of the
target curve using the Fisher-Rao metric and the square-root
velocity function (SRVF) representation of curvature data,20 thus
separating out errors in the phase and the amplitude of the
curvature. Fig. 4(E) shows the aligned curvature of different cases
shows in Fig. 4(D) and their respective phase shift. Defining the
error as the l–p norm of the curvature mismatch,
e ¼
ð
1  kðSÞ
k0ðSÞ

p
dS
	

1=p
;
(5)
we quantify agent’s capability to print from various heights above
the surface. Printing with different nozzle heights is associated
with a trade-off. Small nozzle heights lead to very accurate learned
paths but ones that are very slow, since they do not exploit the
instability, while larger nozzle heights lead to faster printing albeit
with poorer accuracy. In the inset of Fig. 4(F, G), we show that a
higher extrusion height results in a higher coiling frequency and
hence faster overall printing. In Fig. 4(H) we show the trade-off by
comparing the overall curves printed from different heights; faster
printing is also less accurate. Additionally, since the filament
diameter at the substrate changes with the height of the nozzle,
there are also variations in the width of the pattern, but here we
ignore this and only consider matching the target pattern with the
centerline of the fluid jet.
Finally we ask if the agent can learn to not just write, but
sketch, paint or draw. As an exemplar, we chose part of a
painting by Jackson Pollock (Figure, 194821), famous for his
‘‘painting at a distance’’ style, wherein he allowed paint to drip
and drizzle from a brush or a rod held far above the canvas,
thus exploiting both fluid coiling and jetting instabilities14 as
shown in Fig. 5(A). Could an agent learn the complex move-
ments of the artist given the final result? Restricting ourselves
to a limited part of the painting which we could easily track as a
Paper
Soft Matter
Published on 23 October 2023. Downloaded by Harvard University on 3/22/2024 2:06:45 AM. 
View Article Online

This journal is © The Royal Society of Chemistry 2023
Soft Matter, 2023, 19, 8329–8336 |  8335
continuous curve as shown in Fig. 5(B) inset, we show that by
allowing the action space for the RL agent to be non-zero allows
us to learn and reproduce a fragment of the Pollockian painting
as shown in Fig. 5(B).
5 Physical experiments on learning
to write
The real test of the RL protocols described above is to see if they
work by deploying them in physical experiments. To do so, we
dispense a viscous fluid, silicone oil (Z = 500 cP), through a nozzle
at a fixed flow rate, and deposit it along a predefined path from
above a smooth sheet of paper glued on a flat, stationary platform.
We use the RL control learned in the numerical setting as the
digital path along which the printer head (nozzle) translates. Since
a fixed time step, Dt = 0.01 s was used in the simulations, we find
this digital path by integrating the action set (velocities) at every
step. The diameter of the nozzle and flow rate are same as in the
numerical simulations. In all the experiments the oil is first
extruded until the coiling becomes steady, to ensure similar initial
conditions to those in our numerical simulations.
In Fig. 6(A) we first show the diﬀerence between the learned
RL protocol and an uncontrolled approach, (see ESI,† Video 1).
To test the ability to write cursively, in Fig. 6(B) (see ESI,† Video
2) we show an example parallel to the simulation results in
Fig. 4(A) using the action set vx,vy,vz, with RL controls based on
allowable states for nozzle heights z A [4–10] cm. An overlay of
the numerically learned pattern on the experimentally printed
pattern shows that the regions of highest errors are generally
the regions of maximum curvature, most likely due to velocity
mismatch between the RL actions and the experimental imple-
mentation. In particular when the nozzle makes sharp changes
in direction over a short time corresponding to high curvature
regions, the experimentally executed velocity actions are
expected to be different from the desired actions. As a conse-
quence, the overall mismatch (error) between the numerical
and the experimental pattern builds up as a function of arc
length of the pattern. We emphasize this by attempting to
mimic a self-similar target pattern of a Peano curve in Fig. 6(C)
(see ESI,† Video 3) using actions vx,vy. We observe that the
experimental print and the simulated print show close agree-
ment in the initial part of arc length, but as the printing
progresses, the experimental error accumulates over the arc
length. A comparison between the curvatures of the computed
pattern and the target pattern, as well as a comparison between
the experimentally printed pattern and computed pattern is
shown in Fig. 6(D), computed using the methods of shape data
Fig. 5
Using RL to mimic Pollock’s paintings. Liquid coiling was extensively
utilized by famous American painter Jackson Pollock in his drip paintings
(as shown in (A)21). (B) With the available set of action (vx,vy,vz), the agent can
learn to draw parts of Jackson Pollock’s, Figure, 1948, indicating that
Pollock’s drip painting may owe its complexity to the liquid coiling instability.
Fig. 6
Testing the predicted RL strategies using physical experiments to write. (A) An experimental print showing a pattern with a first region printed with RL-
derived and a second region without control where the nozzle is moved at 0.5 cm s1. (inset) The pattern printed in simulation. (B) RL controlled cursive handwriting
using silicone oil, overlaid with the numerically simulated solution. (C) An experimentally printed self-similar structure (solid line), and the numerically learned pattern
(dashed line). The mismatch between the experiment and numerical result grows as the arc length grows starting from the bottom left corner. (Inset) The
experimental pattern deposited with a noisy set of actions shows the sensitivity of the final pattern to the RL actions. (D) A comparison of error in the curvature along
the entire arc length of the pattern in (C) is shown. Here, kc(S) and ke(S) are the curvatures of computed and experimentally printed pattern, respectively, from the
learned set of actions. (E) In a practical setting, the RL agent can be deployed to automate processes such as printing chocolate syrup on edible surfaces. (insets) a
natural coiling of chocolate syrup extruded from a stationary nozzle held at a height of 6.6 cm above the surface and the top view of the final print.
Soft Matter
Paper
Published on 23 October 2023. Downloaded by Harvard University on 3/22/2024 2:06:45 AM. 
View Article Online

8336 |  Soft Matter, 2023, 19, 8329–8336
This journal is © The Royal Society of Chemistry 2023
analysis described in the previous section. It is evident that
along the entire arc length, the error in the curvature of the
computed pattern deviates consistently from the target curva-
ture. The error between the computed and the experimentally
printed pattern has even larger magnitude due the additional
experimental errors. In the inset of Fig. 6(C) we show the
sensitivity of the resulting pattern by adding random noise to
the optimal actions (o5% of the action value), and use the
noisy actions to the print the pattern. The resulting pattern
deviates significantly, highlighting the non-trivial nature of the
action-reward landscape due to the unsteady and nonlinear
effects in the physical problem.
As a sweet test of the RL control approach developed for
Newtonian fluids extruded on smooth surfaces, we ask how well
the strategy does when printing a thick chocolate syrup on a
textured wafer, inspired by a tasty application of our approach.
Chocolate syrup is a non-Newtonian fluid with a strain-rate
dependent viscosity, but here we assume that it has a constant
shear viscosity (B100 cP based on ball drop experiments). We
find that this approximation results in a reasonable agreement
between the printed shape and the target pattern as shown in
Fig. 6(D) (see ESI,† Video 4). We note that printing from a
height naturally handles rough surfaces, unlike the traditional
direct-ink write where an irregular surface will result in irregu-
larities in the deposited material.
6 Conclusions
Complementing the substantial literature on understanding
and predicting fluid instabilities, here we have focused on
controlling a somewhat non-intuitive low Reynolds number
instability associated with the buckling, folding and coiling of
a slowly flowing slender viscous filament. Inspired by 3-d and 4-
d printing technologies that rely on the movement of a nozzle
that dispenses complex fluids onto a substrate from just above,
we ask if we can harness the folding and coiling instabilities
that arise as soon as the jet falls from a suﬃcient height above a
surface. We answer this in the aﬃrmative by combining a
physics-based simulation engine and a variant of reinforce-
ment learning to control the fluid coiling instability and learn
to ‘‘print at a distance.’’ By varying the action space, material
properties and geometric scales that govern the dynamics of
viscous coiling, we quantify the performance of an RL agent for
a variety of problems, and show that it is possible to learn to
write cursively and mimic Pollockian paintings. Deploying the
learned policy in physical experiments demonstrates that we
can create complex physical patterns leveraging a natural fluid
instability. We envision such an approach can be further
extended to more challenging scenarios such as printing on
non-planar surfaces and using robotic manipulators with
greater dexterity and improved motion control, or stacking
multiple layers out of the plane. These extensions would likely
require a more sophisticated model for the dynamics of contact
of the jet with the substrate to account for the non-flat nature of
the substrate.
Conflicts of interest
There are no conflicts to declare.
Acknowledgements
The computations in this paper were run on the FASRC Cannon
cluster supported by the FAS Division of Science Research
Computing Group at Harvard University. We thank Crystal
Owens and the Hatsopoulos Microfluids Laboratory at MIT
for help and support with the experiments, and the NSF
Harvard MRSEC DMR-2011754, the Simons Foundation and
the Henri Seydoux fund for partial financial support.
Notes and references
1 A. Sydney Gladman, E. A. Matsumoto, R. G. Nuzzo,
L. Mahadevan and J. A. Lewis, Nat. Mater., 2016, 15, 413–418.
2 J. W. Boley, W. M. Van Rees, C. Lissandrello, M. N.
Horenstein, R. L. Truby, A. Kotikian, J. A. Lewis and
L. Mahadevan, Proc. Natl. Acad. Sci. U. S. A., 2019, 116,
20856–20862.
3 H. Yuk and X. Zhao, Adv. Mater., 2018, 30, 1704028.
4 G. Barnes and R. Woodcock, Am. J. Phys., 1958, 26, 205–209.
5 L. Mahadevan, W. S. Ryu and A. D. Samuel, Nature, 1998, 392, 140.
6 L. Mahadevan, W. S. Ryu and A. D. Samuel, Nature, 2000, 403, 502.
7 H.-Y. Kim, M. Lee, K. J. Park, S. Kim and L. Mahadevan,
Nano Lett., 2010, 10, 2138–2140.
8 N. M. Ribe, J. Fluid Mech., 2017, 812, 9745–9754.
9 A. Chakrabarti, S. Al-Mosleh and L. Mahadevan, Soft Matter,
2021, 17, 9745–9754.
10 F. Gallaire and P.-T. Brun, Philos. Trans. R. Soc., A, 2017,
375, 20160155.
11 P.-T. Brun, B. Audoly, N. M. Ribe, T. S. Eaves and J. R. Lister,
Phys. Rev. Lett., 2015, 114, 174501.
12 P.-T. Brun, C. Inamura, D. Lizardo, G. Franchin, M. Stern,
P. Houk and N. Oxman, Philos. Trans. R. Soc., A, 2017,
375, 20160156.
13 R. Passieux, L. Guthrie, S. H. Rad, M. Le´vesque, D. Therriault
and F. P. Gosselin, Adv. Mater., 2015, 27, 3676–3680.
14 A. Herczynski, C. Cernuschi and L. Mahadevan, Phys. Today,
2011, 31–36.
15 R. S. Sutton and A. G. Barto, Reinforcement Learning: An
Introduction (2nd Edition, Draft), MIT Press, Cambridge, MA,
2nd edn, 2017, p. 455.
16 B. Audoly, N. Clauvelin, P.-T. Brun, M. Bergou, E. Grinspun
and M. Wardetzky, J. Comput. Phys., 2013, 253, 18–49.
17 S. W. Morris, J. H. Dawes, N. M. Ribe and J. R. Lister, Phys.
Rev. E: Stat., Nonlinear, Soft Matter Phys., 2008, 77, 066218.
18 G. Novati and P. Koumoutsakos, International Conference on
Machine Learning, 2019, vol. 97, pp. 4851–4860.
19 S. M. Kay, Modern Spectral Estimation, Englewood Cliﬀs, 1988.
20 A. Srivastava and E. P. Klassen, Functional and shape data
analysis, Springer, 2016.
21 J. Pollock, Figure, 1970, https://sammlung.staedelmuseum.
de/en/work/figure.
Paper
Soft Matter
Published on 23 October 2023. Downloaded by Harvard University on 3/22/2024 2:06:45 AM. 
View Article Online

