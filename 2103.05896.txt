Streaming Linear System Identiﬁcation with Reverse
Experience Replay
Prateek Jain
Google AI Research Lab,
Bengaluru, India 560016
prajain@google.com
Suhas S Kowshik
Department of EECS
MIT,
Cambridge, MA 02139
suhask@mit.edu
Dheeraj Nagaraj
Department of EECS
MIT,
Cambridge, MA 02139
dheeraj@mit.edu
Praneeth Netrapalli
Google AI Research Lab,
Bengaluru, India 560016
pnetrapalli@google.com
Abstract
We consider the problem of estimating a linear time-invariant (LTI) dynamical
system from a single trajectory via streaming algorithms, which is encountered in
several applications including reinforcement learning (RL) and time-series analysis.
While the LTI system estimation problem is well-studied in the ofﬂine setting, the
practically important streaming/online setting has received little attention. Standard
streaming methods like stochastic gradient descent (SGD) are unlikely to work
since streaming points can be highly correlated. In this work, we propose a novel
streaming algorithm, SGD with Reverse Experience Replay (SGD −RER), that
is inspired by the experience replay (ER) technique popular in the RL literature.
SGD −RER divides data into small buffers and runs SGD backwards on the data
stored in the individual buffers. We show that this algorithm exactly deconstructs
the dependency structure and obtains information theoretically optimal guarantees
for both parameter error and prediction error. Thus, we provide the ﬁrst – to the
best of our knowledge – optimal SGD-style algorithm for the classical problem
of linear system identiﬁcation with a ﬁrst order oracle. Furthermore, SGD −RER
can be applied to more general settings like sparse LTI identiﬁcation with known
sparsity pattern, and non-linear dynamical systems. Our work demonstrates that
the knowledge of data dependency structure can aid us in designing statistically and
computationally efﬁcient algorithms which can “decorrelate” streaming samples.
1
Introduction
In this paper, we study the problem of learning linear-time invariant (LTI) systems, where the goal is
to estimate the matrix A∗∈Rd×d from the given samples (X0, . . . , XT ) that obey:
Xτ+1 = A∗Xτ + ητ,
Xτ ∈Rd,
ητ
i.i.d.
∼µ,
(1)
where µ is an unbiased noise distribution. The problem is central in control theory and reinforcement
learning (RL) literature [1, 2]. It is also equivalent to estimating Vector Autoregressive (VAR) model
popular in the time-series analysis literature [3], where it has been used in several applications like
ﬁnding gene regulatory information network [4].
Despite a long line of classical literature for the problem, most of the existing results focus on the
ofﬂine setting, where all the samples (X0, . . . , XT ) are available apriori. In this setting, ordinary
arXiv:2103.05896v3  [cs.LG]  1 Dec 2021

least squares (OLS) method that estimates A as, ˆA = arg minA
PT −1
τ=0 ∥Xτ+1 −AXτ∥2 is known
to be nearly optimal [5, 6]. However, such ofﬂine solutions do not apply to the streaming setting –
where A∗needs to be estimated online – that has applications in several domains like RL, large-scale
forecasting systems, recommendation systems [7, 8].
In this paper, we study the above mentioned problem of learning LTI systems via ﬁrst order gradient
oracle with streaming data. The goal is to design an estimator that provides accurate estimation while
ensuring nearly optimal time complexity and space complexity that is nearly independent of T. Note
that due to speciﬁc form arising in linear regression, the optimal solution to OLS can be estimated in
online fashion using Sherman-Morrison-Woodbury formula. But such a solution is limited and does
not apply to practically important settings like generalized non-linear dynamical system or when A∗
is high-dimensional and has special structure like low-rank or sparsity [9, 10].
So, in this work, we focus on designing Stochastic Gradient Descent (SGD) style methods that can
work directly with ﬁrst order gradient oracle, and hence is more widely applicable to the settings
mentioned above. In fact, after the ﬁrst appearance of this manuscript, the algorithm (SGD −RER)
and the techniques introduced in this paper were used to obtain near-optimal guarantees for learning
certain classes of non-linear dynamical systems [11] as well as in Q-learning tabular MDPs in RL
[12]. We note that prior to [11], even optimal ofﬂine algorithms were unknown for such non-linear
systems.
SGD is a popular method for general streaming settings, and has been shown to be optimal for
problems like streaming linear regression [13]. However, when the data has temporal dependencies,
as in the estimation of linear dynamical systems, such a naive implementation of SGD may not
perform well as observed in [14, 15]. In fact, for linear system identiﬁcation, our experiments suggest
that SGD suffers from a non-zero bias (Section 6). In order to address temporal dependencies in data,
practitioners use a heuristic called experience replay, which maintains a buffer of points, and samples
points randomly from the buffer. However, for linear system identiﬁcation, experience replay does
not seem to provide an accurate unbiased estimator for reasonable buffer sizes (see Section 6).
In this work, we propose reverse experience replay for linear system identiﬁcation. Our method
maintains a small buffer of points, but instead of random ordering, we replay the points in a reverse
order. We show that this algorithm exactly unravels the temporal correlations to obtain a consistent
estimator for A∗. Similar to the standard linear regression problem with i.i.d. samples, we can break
the error in two parts: a) bias: that depends on the initial error ∥A0 −A∗∥, b) variance: the steady
state error due to noise η. We show that our proposed method, under fairly standard assumptions
and with a small buffer size, is able to decrease the bias at fast rate, while the variance error is
nearly optimal (see Theorem 1), matching the information theoretic lower bounds [5, Theorem
2.3]. To the best of our knowledge, we provide ﬁrst non-trivial analysis for a purely streaming
SGD-style algorithm with optimal computation complexity and nearly bounded space complexity
that is dependent logarithmically on T. We note here that the idea of reverse experience replay was
independently discovered in experimental reinforcement learning by [16] based on reverse replay
observed in Hippocampal place cells [17] in Neurobiology. We also refer to [18] for more on this
connection.
In addition to the transition matrix estimation error ∥A −A∗∥, we also provide analysis of prediction
error, i.e., E[∥AX −A∗X∥2] (see Theorem 2). Here again, we bound the bias and the variance part
of the error separately. We further derive new lower bounds for prediction error (see Theorem 4) and
show that our algorithm is minimax optimal, under standard assumptions on the model. As mentioned
earlier, our method work with general ﬁrst order oracles, hence applies to more general problems like
sparse LTI estimation with known sparsity structure and unlike online OLS methods, SGD −RER
has nearly optimal time complexity. Finally, we also provide empirical validation of our method on
simulated data, and demonstrate that the proposed method is indeed able to provide error rate similar
to the OLS method while methods like SGD and standard experience replay, lead to biased estimates.
Related Work.
Due to applications in RL, recently LTI system identiﬁcation has been widely
studied. In particular, [19] studied the problem in ofﬂine setting under the “stability" condition,
i.e., the spectral radius (ρ(A∗)) of A∗is a constant bounded away from 1. The sequence of papers
[5, 6, 20, 21] provide optimal analyses of the ofﬂine OLS estimator beyond assumptions of stability.
That is, they show that OLS recovers A∗near optimally even the process deﬁned by (1) is stable
but does not mix within time T (when ρ(A∗) is 1 −O(1/T)) or is unstable (when ρ(A∗) is larger
2

than 1). Further [5, 22] provide information theoretic lower bounds for the LTI system identiﬁcation
problem. [11, 23, 24] consider the problem of identifying non-linear dynamical systems of the form
Xt+1 = φ(A∗Xt) + ηt where φ is a one dimensional link function which acts co-ordinate wise. In
this setting, however, there is no closed for expressions for the estimator of A∗. [23, 24] give ofﬂine
algorithms whose error guarantees are worse off by factors of mixing time whereas [11] obtains near
optimal ofﬂine and streaming algorithms for this setting. In fact, [11] uses SGD −RER which was
ﬁrst introduced in this work in order to obtain the streaming algorithm.
LTI identiﬁcation problem has been studied in time series forecasting literature as well. For example,
[25] obtains asymptotic consistency results for system identiﬁcation problem and [26, 27] consider
the problem of ﬁnite time recovery. Both consider a certain parameterized predictor for a linear
system with empirical risk minimization for the parameter and analyzes the deviation from population
risk. Similarly, [28] also studies generalization error guarantees. In contrast, our work is able to
provide precise bias and variance (similar to generalization error) of the estimator in the streaming
setting, and show that the asymptotic error is minimax optimal.
[29] studied SISO systems with observations (xτ, yτ) ∈R2 and a hidden state hτ which is high
dimensional, thus their model and applications are signiﬁcantly different than the LTI system we
study. For the SISO system, [29] analyzes SGD to provide error bounds contain (a large) polynomial
in the hidden state dimension. Here, the hidden state has an evolution similar to Equation 1 whereas
x1, . . . , xT are drawn i.i.d from some distribution.
System identiﬁcation has been studied in the context of partially observed LTI systems as well.
Recent works [19, 30–34] focus on identifying a certain Hankel-like matrix of the system. These are
not directly comparable to the fully observed setting in this work since the model parameters are
identiﬁable only upto a similarity transformation in the partially observed setting.
Recently, there has been an exciting line of work in the related domain of online control (see [35–38]
and references therein). The state equation studied in these papers also contain an additive term
of Buτ for some unknown matrix B and a control signal uτ and the noise ητ is either stochastic
(as in [35]) or adversarial (as in [36–38]). The goal is to output control signals uτ after observing
X1, . . . , Xτ, such that the cost P
τ cτ(Xτ, uτ) is minimized for some sequence of convex costs
cτ. We focus on the LTI system identiﬁcation(or estimation) problem while the goal of the above
mentioned line of work is to design an online controller.
We also note here another line of works [32, 39–44] focused on online prediction of both fully
observed and partially observed LTI systems, and the similar problem of time series forecasting
by regret minimization [28, 45]. In particular, the main goal there is to design online prediction
algorithms minimizing regret against a certain class (for instance, against a Kalman ﬁlter with
knowledge of the system parameters in the case of partially observed LTI systems). The situation
considered in our work is different in atleast two aspects: 1) we focus signiﬁcantly on parameter
recovery or system identiﬁcation and 2) our notion of prediction is prediction at stationarity which
can be thought of as one-step regret (compared to T–step regret for instance in [39, 40]).
Finally, [9] considers ofﬂine sparse linear regression with ℓ1 penalty where the feature vector is
derived from an auto regressive model. Similarly, [14] considers the problem of linear regression
where the feature vectors come from a Markov chain. This line of work is different from ours in that
we try to estimate the parameters of the Markov process itself.
Paper Organization.
We provide the problem deﬁnition and introduce the notations in the next
section. We then present our algorithm and the key intuition behind it in Section 3. We then present
our main result in Section 4 and provide a proof sketch in Section 5. Finally, we present simulation
results in Section 6.
2
Problem Setting and Notation
In this section, we ﬁrst introduce the data generation model, the required assumptions and then
provide the precision problem deﬁnition. Throughout the paper, we use ∥A∥to denote the operator
norm of A unless otherwise speciﬁed. ∥A∥F denotes the Frobenius norm of A. σi(A) denotes
the i-th largest singular value of A, i.e., σmax(A) = σ1(A). κ(A) := σmax(A)/σmin(A) denotes
the condition number of A. ρ(A) denotes the spectral radius of A. For two symmetric matrices
3

A, B ∈Rd×d we say A ⪯B if B −A is positive semideﬁnite (psd). For notational simplicity, we
use C to denote a constant, and it’s value can be different in different equations.
Linear Dynamical System/VAR(1) model.
Given an initial (possibly random) data point X0
which is independent of the noise sequence, we generate the (X0, . . . , XT ) from the VAR model as:
Xτ+1 = A∗Xτ + ητ,
0 ≤τ ≤T −1,
(2)
where A∗∈Rd×d be the transition matrix. Let η1, . . . , ηT ∈Rd be an i.i.d noise sequence with
0 mean and ﬁnite second moment with probability measure µ. We will denote this model by
VAR(A∗, µ). We also make the following assumptions about A∗, µ, and X0:
Assumption 1. External Stability. ∥A∗∥< 1
Assumption 2. Sub-Gaussian Noise. µ has co-variance Σ and for all x ∈Rd, ⟨x, ητ⟩is Cµ⟨x, Σ·x⟩
sub-Gaussian. Further, Σ is full rank. Also, let µ4 := E
h
∥ητ∥4i
be the fourth moment of the noise.
Assumption 3. Stationarity. X0 ∼π, the stationary distribution corresponding to (A∗, µ). Let
M4 := E
h
∥X0∥4i
.
Due to Assumption 1, we can show that the law of the iterate XT from the VAR model deﬁned
above converges to a stationary distribution π as T →∞for arbitrary choice of X0 and has
a mixing time of the order τmix = O

1
1−∥A∗∥

. For simplicity, we will absorb Cµ into other
constants. Finally, we will use (Z0, . . . , ZT ) ∼VAR(A∗, µ) to mean that Z0, . . . , ZT is a stationary
sequence corresponding to VAR(A∗, µ). We also note that the covariance matrix under stationarity,
G := EX∼πXX⊤= P∞
s=0 A∗sΣ(A∗⊤)s ⪰Σ.
Remark. It is indeed possible to replace Assumption 1 with the weaker condition on the spectral
radius of A∗: ρ(A∗) < 1. While our results still hold in this case, the bound might have additional
condition number factors. See Section A.1 for more details.
Remark. The full rank assumption on Σ is needed for polynomial sample complexity [46].
Problem Statement.
Let (X0, X1, · · · , XT ) be sampled from VAR(A∗, µ) model for a ﬁxed hori-
zon T. Then, the goal is to design and analyze an online algorithm that uses only ﬁrst order gradient
oracle to estimate the system matrix A∗. That is, at each time-step τ, we obtain gradient for the
transition (Xτ, Xτ+1) and output estimate Aτ. The goal is to ensure that each Aτ has small estima-
tion error wrt A∗; naturally, we would expect better estimation error with increasing τ. We quantify
estimation error using the following two loss functions:
1. Parameter error: Lop(A; A∗, µ) = ∥A −A∗∥
2. Prediction error at stationarity: Lpred(A; A∗, µ) := EXτ ∼π∥Xτ+1 −AXτ∥2
Note that the problem is equivalent to d linear regression problems, but with dependent samples,
making it signiﬁcantly more challenging. Whenever Assumption 1 holds, stationary distribution
π exists, so the prediction error Lpred is meaningful. Furthermore: Lpred(A) −Lpred(A∗) =
Tr

(A −A∗)⊤(A −A∗)G

where G := EX∼πXX⊤.
3
Algorithm
As mentioned in related works, the standard OLS estimator that minimizes the empirical loss is
known to be nearly optimal in the ofﬂine setting [5]:
ˆAOLS = arg min
A
T −1
X
τ=0
∥AXτ −Xτ+1∥2 .
(3)
Note that for least squares loss, one can indeed maintain covariance matrix and residual vector to
compute the OLS solution online. But such a solution does not work if we have access to only
gradients and breaks down even for generalized linear models, whereas as the techniques introduced
in this work has been extended to non-linear systems [11].
4

Figure 1: Data Processing Order in SGD −RER. A cell represents a data point. Time goes from left
to right, buffers are also considered from left to right. Within each buffer, the data is processed in the
reverse order. Gaps ensure that data in successive buffers are approximately independent.
On the other hand, using standard SGD we can obtain update to A efﬁciently by using gradient at the
current point. That is, assuming A0 = 0, we get the following SGD update (for all τ ≥0):
Aτ+1 = Aτ −2γ(AτXτ −Xτ+1)X⊤
τ ,
(4)
where γ is the stepsize. While SGD is known to be an optimal estimator in certain streaming problems
with i.i.d. data, for the VAR(A∗, µ) problem the standard SGD does not apply, as samples (Xτ, Xτ+1)
and (Xτ+1, Xτ+2) are highly correlated. To see why this is the case, let us unroll the recursion for
two steps and using Equation (2):
A2 −A∗= (A0 −A∗)(I −2γX0X⊤
0 )(I −2γX1X⊤
1 ) + 2γη1X⊤
1 + 2γη0X⊤
0 (I −2γX1X⊤
1 ).
Note that the last term does not have 0 mean because X1 depends on η0 by Equation (2). Even
in the case when A0 = A∗, this means that EA2 ̸= A∗in general. In fact, in Section 6, we show
empirically that SGD with constant step-size converges to a signiﬁcantly larger error than OLS, even
when T is very large. This shows that we cannot naively treat this problem as a collection of d linear
regressions. This is consistent with the results in [14, 15] which show a similar behavior for constant
step-size SGD with dependent data. Now, one can use techniques like data drop that drops a large
fraction of points (either explicitly or during the mathematical analysis) from the stream to obtain
nearly independent samples [14, 47], but such methods waste a lot of samples and have signiﬁcantly
suboptimal error rate than OLS.
So, the goal is to design a streaming method for the problem of learning dynamical systems that
at each time-step t provides an accurate estimate of A∗, while also ensuring small space+time
complexity.We now present a novel algorithm that addresses the above mentioned problem.
3.1
SGD with Reverse Experience Replay
We now discuss a novel algorithm called SGD with Reverse Experience Replay (SGD −RER) that
addresses the problem of learning stationary auto-regressive models (or linear dynamical systems) in
the streaming setting. Our method is inspired by the experience replay technique [48], used extensively
in RL to break temporal correlations between dependent data. We make the following crucial
observation. Suppose in Equation (4), instead of processing the samples in the order (X1, X2) →
(X2, X3) →· · · →(XT −1, XT ), we process it in the reverse order. That is: (XT −1, XT ) →
(XT −2, XT −1) →· · · →(X1, X2). Then,
A2 −A∗= (A0 −A∗)(I −2γXT −1X⊤
T −1)(I −2γXT −2X⊤
T −2) + 2γηT −2X⊤
T −2
+2γηT −1X⊤
T −1(I −2γXT −2X⊤
T −2)
(5)
Now, observe that (XT −2, XT −1) are independent of ηT −1. Therefore the problematic last term,
2γηT −1X⊤
T −1(I −2γXT −2X⊤
T −2), now has expectation 0. So the updates for reverse order SGD
would be unbiased. This, however, requires us to know all the data points beforehand which is
infeasible in the streaming setting. We alleviate this issue by designing SGD −RER, which is the
online variant of the above algorithm. SGD −RER uses a buffer of large enough size to store values
of consecutive data points and then performs reverse SGD in each of these buffers and then discards
this buffer. Experience replay methods also use such (small) buffers of data, but typically samples
point randomly from the buffer instead of the reverse order that we propose. We refer to Figure 1 for
an illustration of the proposed data processing order.
We present a pseudocode of SGD −RER in Algorithm 1. Note that the algorithm forms non-
overlapping buffers of size S = B + u. Here B is the actual size of the buffer while u samples are
used to interleave between two buffers so that the buffers are almost independent of each other. Now
5

Algorithm 1: SGD −RER
Input
:Streaming data {Xτ}, horizon T, buffer size B, buffer gap u, bound R, tail average
start: a
Output :Estimate ˆAa,t, for all a < t ≤N −1; N = T/(B + u)
1 begin
2
Step-size: γ ←
1
8RB , Total buffer size: S ←B + u, Number of buffers: N ←T/S
3
A0
0 = 0 /*Initialization*/
4
for t ←1 to N do
5
Form buffer Buft−1 = {Xt−1
0
, . . . , Xt−1
S−1}, where, Xt−1
i
←X(t−1)·S+i
6
If ∃i, s.t.,
Xt−1
i
2 > R, then return ˆAa,t = 0
7
for i ←0 to B −1 do
9
At−1
i+1 ←At−1
i
−2γ(At−1
i
Xt−1
S−1−i −Xt−1
S−i)
 Xt−1
S−1−i
⊤
10
end
11
At
0 = At−1
B
12
If t > a, then ˆAa,t ←
1
t−a
Pt
τ=a+1 Aτ−1
B
13
end
14 end
within a buffer, we perform the usual SGD but with samples read in reverse order. Formally, suppose
we index our buffers by t = 0, 1, 2, · · · and let S = B + u be the total samples (including those
that were dropped) in the buffers. Let N denote the total number of buffers in horizon T. Within
each buffer t, we index the samples as Xt
i where i = 0, 1, 2, · · · , S −1. That is Xt
i ≡XtS+i is
the i-th sample in buffer t. Similarly ηt
i ≡ηtS+i. Further let Xt
−i ≡Xt
(S−1)−i. Similarly we set
ηt
−i ≡ηt
(S−1)−i Then, the algorithm performs the recursion stated in Line 1 of Algorithm 1. Note
that the recursion can also be written as,
At−1
i+1 −A∗=
 At−1
i
−A∗ 
I −2γXt−1
−i Xt−1
−i
⊤
+ 2γηt−1
−i Xt−1
−i .
(6)
for 1 ≤t ≤N and 0 ≤i ≤B −1 with At
0 = At−1
B
and A0
0 = A0.
We then ignore the iterates corresponding to ﬁrst a buffers as part of the burn-in period, and
output average of the remaining iterates (t > a) at each step as that step’s estimator (see Line 2 of
Algorithm 1). That is, we have the tail-averaged iterate:
ˆAa,t =
1
t −a
t
X
τ=a+1
Aτ−1
B
.
(7)
We output the new iterate ˆAa,t only at the end of each buffer t. At intermediate steps, (t −1)B + 1 ≤
τ ≤tB, we output ˆAa,t−1. Also, note that the tail average can be computed in small space and time
complexity, by using a running sum of the tail iterates. The update for each point is rank-one, so
can be computed in time linear in number of parameters (O(d2)). In the next section, we show that
despite using small buffer size S = B + u (that depends logarithmically on T), and by throwing
away a small constant–independent of any problem parameter–fraction of points u in each buffer, we
are still able to provide error bound similar to that of OLS.
4
Main Results
We now state our main results with leading order terms. For simplicity, we only state the results
for the tail average ˆA N
2 ,N but a similar result holds for any ˆAa,t when a = Ω(dBκ(G) log2 T). We
refer to Section A for complete statements. Recall the problem setting, and the covariance matrix
G := EX∼πXX⊺. Before stating the results, we choose the parameters B, R, α and u as follows,
which can be estimated using upper bounds on ∥A∗∥:
1. d ≤Poly(T). We use this to bound the norm of covariates in the next item.
2. α ≥22 ;
R ≥C(α) Tr(Σ) log T
1−∥A∗∥2 = O(dτmix log T) s.t. P
h
∥Xτ∥2 ≤R, τ ≤T
i
≥1 −
1
T α . See
lemma 9 in appendix.
6

3. u ≥α
log T
log

1
∥A∗∥
 = O(τmix log T);
B = 10u
For all the results below, we suppose that Assumptions 1, 2 and 3 hold, the stream of samples Xτ is
sampled from VAR(A∗, µ) model described in Section 2 and that R, B, α and u are chosen as above.
Further we hide some mild conditions on N and T.
Theorem 1 (Informal version of Theorem 5). Let the step size γ < min

C
Bσmin(G),
1
8BR

for some
constant C depending only on Cµ. Then, with probability at least 1 −
1
T 100 , we have:
Lop( ˆA N
2 ,N, A∗, µ) ≤C
s
(d + log T)σmax(Σ)
Tσmin(G)
+ Lower Order Terms .
Theorem 2 (Informal version of Theorem 6). Consider the setting of Theorem 1 but where the step
size γ = min
  1
2R,
c
BR

for some constant 0 < c < 1. Then, the following holds:
E
h
Lpred( ˆA N
2 ,N; A∗, µ)
i
−Tr(Σ) ≤C d Tr(Σ)
T
+ Lower Order Terms
where “lower order” is with respect to d
T .
See Section F.1, Section F.3 for a detailed proof of the parameter error bound and see Section G.1,
Section G.2 for a detailed proof of the prediction error bound.
We now make the following observations:
(1) The dominant term in our bound on Lop (Theorem 1) matches the information theoretically
optimal bound (up to logarithmic factors) for the VAR(A∗, µ) estimation problem [5] as long as
∥A∗∥≤1 −
1
T ξ for ξ ∈(0, 1/2). Note that despite working with dependent data, leading term
in our error bound is nearly independent of mixing time τmix. In contrast, most of the existing
streaming/SGD style methods for dependent data have strong dependence on τmix [14].
(2) SGD for linear regression with independent data [13, 49], but with similar problem setting incurs
error O( d Tr(Σ)
T
) for Lpred. So our bound for SGD −RER matches the independent data setting
bound in the minimax sense.
(3) The space complexity of our method is O(Bd + d2) where B = O(τmix log T) is independent of
d and only logarithmically dependent on T.
(4) Sparse matrices with known support: Suppose A∗is known to be sparse and we know the
support (say by running L1 regularized OLS on a small set of samples). Let sj denote the sparsity
of row j of A∗. Then the SGD −RER algorithm can be modiﬁed to run row by row such that it
operates only on the support of row j. That is the covariates can be projected onto the support
of each row. Then it can be shown that the prediction error is bounded as O
Pd
j=1 σ2
j sj/T

where σ2
j is the j-th diagonal entry of Σ. Note that SGD −RER requires only O(|supp(A∗)|)
operations per iteration while applying online version of standard OLS would require O(d2)
operations. In the simple case of Σ = σ2I, we note that G ⪰σ2I and hence the bound for Lpred
becomes O

|supp(A∗)|
T

. We refer to Section O for a sketch of this extension.
Next, we show that our error bounds are nearly information theoretically optimal. For the lower
bound on Lop we directly use [5, Theorem 2.3].
Theorem 3. Let ρ < 1 and δ ∈(0, 1/4). Let µ be the distribution N(0, σ2I). For any estimator
ˆA ∈F, there exists an matrix A∗∈Rd×d where A∗= ρO for some orthogonal matrix O such that
|σmax(A∗)| = ρ and we have that with probability at least δ:
∥ˆA −A∗∥= Ω
r
(d + log(1/δ))(1 −ρ)
T
.
(8)
Notice that in the setting of Theorem 3, we have G = P∞
i=0 σ2(A∗)i(A∗)i,⊤=
σ2
1−ρ2 I. Therefore,
σmin(G) =
1
1−ρ2 ∼
1
1−ρ. The bound in Theorem 1 matches the above minimax bound up to
logarithmic factors.
Next we consider the prediction loss. We ﬁx dimension d and horizon T and consider the class of
VAR models M such that Assumptions 1, 2, and 3 hold such that Tr(Σ(µ)) = β ∈R+ be ﬁxed. Let
7

F be the class of all estimators for parameter A∗given data (Z0, . . . , ZT ). We want to lower bound
the minimax error:
Lminmax(M) := inf
f∈F
sup
(A∗,µ)∈M
E(Zt)∼VAR(A∗,µ)Lpred(f(Z0, . . . , ZT ); A∗, µ) −Lpred(A∗; A∗, µ).
Theorem 4. For some universal constant c, we have:
Lminmax(M) ≥cβ(d −1) min
 1
T , 1
d2

, where β = Tr(Σ(µ)).
Note that the theorem shows that our algorithm is minimax optimal with respect to the prediction loss
at stationarity, Lpred. See Section M for a detailed proof of the above lower bound.
5
Idea Behind Proofs
In this section, we provide an overview of the key techniques to prove our results. As observed in the
discussion following Equation (5), when the data is processed in the reverse order within a buffer, it
behaves similar to SGD for linear regression with i.i.d. data. Due to the gaps of size u, we can take
the buffers to be approximately independent. Therefore, we analyze the algorithm as follows:
1. Analyze reverse order within a buffer using the property noted in Equation (5).
2. Treat different buffers to be i.i.d. due to gap and present an i.i.d data type analysis.
To execute the proposed proof strategy, we introduce the following technical notions:
Coupled Process.
For the real data points (Xτ), the points in different buffers are weakly dependent.
In order to make the analysis straight forward, we introduce the ﬁctitious coupled process ˜Xτ such
that
 ˜Xτ −Xτ
 ≲
1
T α for large enough α, for every data point Xτ used by SGD −RER. We have
the additional property that the successive buffers are actually independent for this coupled process.
We refer to Deﬁnition 1 in the appendix for the construction of the coupled process ˜Xτ.
Suppose we run SGD−RER with the coupled process ˜Xτ instead of Xτ to obtain the coupled iterates
˜At
i. We can then show that ˜At
i ≈At
i. Thus it sufﬁces analyze the coupled iterates ˜At
i. We refer to
Sections B and C for the details.
Bias Variance Decomposition.
We consider the standard bias variance decomposition with individ-
ual buffers as the basic unit as opposed to individual data points. We refer to Section D for the details.
We decompose the error in the iterates into the bias part

˜At−1,b
B
−A∗
= (A0 −A∗) Qt−1
s=0 ˜Hs
0,B−1
and the variance part

˜At−1,v
B

= 2γ Pt
r=1
PB−1
j=0 ηt−r
−j ˜Xt−r,⊤
−j
˜Ht−r
j+1,B−1
Q1
s=r−1 ˜Ht−s
0,B−1 where
the matrices ˜Hs
0,B−1 = QB−1
i=0

I −2γ ˜Xs
−i ˜Xs,⊤
−i

are the independent ’contraction’ matrices asso-
ciated with each buffer s. This result in the geometric decay of the initial distance between (A0 −A∗).
The variance part is due to the inherent noise present in the data. In Section F.1 we ﬁrst establish the
exponential decay of the ‘bias’. We then consider the second moment of the variance term. Observe
that the distinct terms in the expression for

˜At−1,v
B

are uncorrelated either due to reverse order
within a buffer as noted in Equation (5) or due to independence between the data in distinct buffers
(due to coupling). This allows us to split the second moment into diagonal terms with non-zero mean
and cross terms with zero mean. Diagonal terms are analyzed via a recursive argument in Claim 1
and the following discussion in order to remove dependence on mixing time factors. The analysis
for parameter recovery (the result of Theorem 2) is similar but we bound the relevant exponential
moments using sub-Gaussianity of the noise sequence ηt to obtain high-probability bounds which
when combined with standard ϵ-net arguments give us guarantees for the operator norm error Lop.
Averaged Iterates.
We then combine the bias and variance bounds obtained for individual iterates
in Section F.1 to analyze the tail averaged output. Using techniques standard in the analysis of SGD
for linear regression, we ﬁnally show that this averaging leads error rates of the order d2
T . We refer to
Sections E (for parameter recover) and G (for prediction error) for the detailed results.
8

102
103
104
105
10-3
10-2
10-1
102
103
104
105
10-3
10-2
10-1
Figure 2: Gaussian VAR(A∗, µ): Parameter error for tail averaged and full average iterates of
SGD −RER and baselines. SGD −RER and OLS incur similar parameter error, while error incurred
by SGD and SGD−ER saturate at signiﬁcantly higher level, indicating non-zero bias. The parameters
used are ρ = 0.9, d = 5, T = 107, B = 100, u = 10. R is estimated and γ = 1/2R.
Picking the Step Sizes and Conditioning.
Due to the auto-regressive nature of the data generation,
the iterates can grow to be of the size O(
d
1−ρ). The step sizes need to be set small enough so that the
γ∥XτX⊤
τ ∥≤1 in order for the SGD −RER iterations to not diverge to inﬁnity. In the statement of
Theorem 2, we condition on the event where ∥Xτ∥2 are all bounded by a sufﬁciently large number
R for every τ in order to ensure this property. The relevant events where the norm is bounded are
deﬁned in Section B. Conditioning on these events results in previously zero mean terms to be not
zero mean. Routine calculations using triangle inequality and Cauchy-Schwarz inequality ensure that
the means are still of the order
1
T α for any ﬁxed constant α > 0. Furthermore, we actually require
step sizes such that γ
P
τ∈Buﬀer XτX⊤
τ
 ≤1 to show exponential contraction of ˜Hs
0,B−1 matrices
due to the Grammian G as described next.
Probabilistic Results.
We establish some properties of ˜Hs
0,B−1, which are products of dependent
random matrices in Section L. Speciﬁcally we refer to Lemmas 28, 29, 30, and 31 which establish
that
Qt−1
s=0 ˜Hs
0,B−1
 ≲(1 −γBσmin(G))t with high probability.
6
Experiments
In this section, we compare performance of our SGD −RER method on synthetic data against the
performance of standard baselines OLS and SGD, along with SGD−ER method that applies standard
experience replay technique, but where points from a buffer are sampled randomly.
Synthetic data: We sample data from VAR(A∗, µ) with X0 = 0, µ ∼N(0, σ2I) and A∗∈Rd×d
is generated from the "RandBiMod" distribution. That is, A∗= UΛU ⊤with random orthogonal
U, and Λ is diagonal with ⌈d/2⌉entries on diagonal being ρ and the remaining diagonal entries are
set to ρ/3. We set d = 5, ρ = 0.9 and σ2 = 1. We ﬁx a horizon T = 107 and set the buffer size as
B = 100 and u = 10. To estimate R from the data, we use the ﬁrst ⌊2 log T⌋= 32 samples and set
R as the sum of the norms of these samples. We let the stepsize to be γ =
1
2R which is aggressive
compared to our theorems. We start the SGD −RER and other SGD-like algorithms from the second
buffer onward.
For tail averaging, as described in algorithm 1, we ignore the ﬁrst ⌊log T⌋= 16 buffers, and maintain
a running tail average at the end of each of the subsequent buffers. In ﬁgure 2, we plot the parameter
errors
 ˆAlog T,t −A∗ and
 ˆA0,t −A∗ versus the buffer index t as the algorithm runs for horizon
T. For OLS, we include samples in the ﬁrst buffer as well (which were used for estimating R).
Clearly, SGD −RER has very similar performance as that of OLS whereas SGD −ER and SGD seem
to display residual bias for the chosen step-size (which is logarithmic in the horizon T) and buffer
lengths. We also observe a similar behavior when we choose A∗= ρI.
9

7
Conclusion
In this paper, we studied the problem of linear system identiﬁcation in streaming setting and provided
an efﬁcient algorithm (SGD −RER). We proved that SGD −RER achieves nearly minimax optimal
error rate, both in terms of parameter error as well as prediction error. Furthermore, using experiments,
we validated that standard SGD as well as SGD with experience replay can have large bias error.
Our algorithm and analysis demonstrates that the knowledge of dependency structure can aid us in
designing accurate algorithms for dependent data.
This work opens up a myriad of open questions about learning from dependent data in general
and Markov processes in particular. Our work currently assumes a speciﬁc Markovian dependency
structure – extending the intuition and techniques to handle more general data dependencies is an
interesting open question. Further, our work does not address the question of recovering a sparse
system matrix with unknown sparsity pattern. So online learning of such linear dynamical systems
with (unknown) sparsity pattern or low-rank structure is an exciting question with applications to
domains like bioinformatics. Moreover, even in our linear setting, extending SGD −RER to the
situation of partially observed states with or without control inputs would be another direction to
pursue. Finally, it would be interesting to understand how the techniques introduced in this work
perform in practical RL settings where learning with data from Markov processes is essential.
Acknowledgments and Disclosure of Funding
D.N. was supported in part by NSF grant DMS-2022448.
S.S.K was supported in part by Teaching Assistantship (TA) from EECS, MIT.
Part of this work was done when S.S.K was visiting Microsoft Research Lab India Pvt Ltd during
summer 2020.
10

References
[1] Panqanamala Ramana Kumar and Pravin Varaiya. Stochastic systems: Estimation, identiﬁcation,
and adaptive control. SIAM, 2015.
[2] Behçet Açıkme¸se, John M Carson, and Lars Blackmore. Lossless convexiﬁcation of nonconvex
control bound and pointing constraints of the soft landing optimal control problem. IEEE
Transactions on Control Systems Technology, 21(6):2104–2113, 2013.
[3] James Douglas Hamilton. Time series analysis. Princeton university press, 2020.
[4] André Fujita, João R Sato, Humberto M Garay-Malpartida, Rui Yamaguchi, Satoru Miyano,
Mari C Sogayar, and Carlos E Ferreira. Modeling gene expression regulatory networks with the
sparse vector autoregressive model. BMC Systems Biology, 1:39, 2007.
[5] Max Simchowitz, Horia Mania, Stephen Tu, Michael I Jordan, and Benjamin Recht. Learning
without mixing: Towards a sharp analysis of linear system identiﬁcation. arXiv preprint
arXiv:1802.08334, 2018.
[6] Tuhin Sarkar and Alexander Rakhlin. Near optimal ﬁnite time identiﬁcation of arbitrary linear
dynamical systems. In International Conference on Machine Learning, pages 5610–5618.
PMLR, 2019.
[7] Christoph Hanck, Martin Arnold, Alexander Gerber, and Martin Schmelzer. Introduction to
econometrics with r. University of Duisburg-Essen, 2019.
[8] Yin Zheng, Bangsheng Tang, Wenkui Ding, and Hanning Zhou. A neural autoregressive
approach to collaborative ﬁltering. In International Conference on Machine Learning, pages
764–773. PMLR, 2016.
[9] Sumanta Basu, George Michailidis, et al. Regularized estimation in sparse high-dimensional
time series models. The Annals of Statistics, 43(4):1535–1567, 2015.
[10] Sumanta Basu, Xianqi Li, and George Michailidis. Low Rank and Structured Modeling of
High-Dimensional Vector Autoregressions. IEEE Transactions on Signal Processing, 67(5):
1207–1222, Mar 2019. ISSN 1941-0476. doi: 10.1109/tsp.2018.2887401.
[11] Prateek Jain, Suhas S Kowshik, Dheeraj Nagaraj, and Praneeth Netrapalli. Near-optimal
Ofﬂine and Streaming Algorithms for Learning Non-Linear Dynamical Systems. arXiv preprint
arXiv:2105.11558, 2021.
[12] Naman Agarwal, Syomantak Chaudhuri, Prateek Jain, Dheeraj Nagaraj, and Praneeth Netrapalli.
Online target q-learning with reverse experience replay: Efﬁciently ﬁnding the optimal policy
for linear mdps. arXiv preprint arXiv:2110.08440, 2021.
[13] Prateek Jain, Praneeth Netrapalli, Sham M Kakade, Rahul Kidambi, and Aaron Sidford. Paral-
lelizing stochastic gradient descent for least squares regression: mini-batching, averaging, and
model misspeciﬁcation. The Journal of Machine Learning Research, 18(1):8258–8299, 2017.
[14] Dheeraj Nagaraj, Xian Wu, Guy Bresler, Prateek Jain, and Praneeth Netrapalli. Least Squares
Regression with Markovian Data: Fundamental Limits and Algorithms. Advances in Neural
Information Processing Systems, 33, 2020.
[15] László Györﬁand Harro Walk. On the averaged stochastic approximation for linear regression.
SIAM Journal on Control and Optimization, 34(1):31–61, 1996.
[16] Egor Rotinov. Reverse Experience Replay. arXiv preprint arXiv:1910.08780, 2019.
[17] R Ellen Ambrose, Brad E Pfeiffer, and David J Foster. Reverse replay of hippocampal place
cells is uniquely modulated by changing reward. Neuron, 91(5):1124–1136, 2016.
[18] Matthew T Whelan, Tony J Prescott, and Eleni Vasilaki. A robotic model of hippocampal
reverse replay for reinforcement learning. arXiv preprint arXiv:2102.11914, 2021.
11

[19] Samet Oymak and Necmiye Ozay. Non-asymptotic identiﬁcation of lti systems from a single
trajectory. In 2019 American Control Conference (ACC), pages 5655–5661. IEEE, 2019.
[20] Mohamad Kazem Shirani Faradonbeh, Ambuj Tewari, and George Michailidis. Finite time
identiﬁcation in unstable linear systems. Automatica, 96:342–353, 2018.
[21] Yassir Jedra and Alexandre Proutiere. Finite-time Identiﬁcation of Stable Linear Systems
Optimality of the Least-Squares Estimator. In 2020 59th IEEE Conference on Decision and
Control (CDC), pages 996–1001. IEEE, 2020.
[22] Yassir Jedra and Alexandre Proutiere. Sample complexity lower bounds for linear system
identiﬁcation. In 2019 IEEE 58th Conference on Decision and Control (CDC), pages 2676–
2681. IEEE, 2019.
[23] Yahya Sattar and Samet Oymak. Non-asymptotic and accurate learning of nonlinear dynamical
systems. arXiv preprint arXiv:2002.08538, 2020.
[24] Dylan Foster, Tuhin Sarkar, and Alexander Rakhlin. Learning nonlinear dynamical systems
from a single trajectory. In Learning for Dynamics and Control, pages 851–861. PMLR, 2020.
[25] TL Lai and CZ Wei. Asymptotic properties of general autoregressive models and strong
consistency of least-squares estimates of their parameters. Journal of multivariate analysis, 13
(1):1–23, 1983.
[26] Marco C Campi and Erik Weyer. Finite sample properties of system identiﬁcation methods.
IEEE Transactions on Automatic Control, 47(8):1329–1334, 2002.
[27] Mathukumalli Vidyasagar and Rajeeva L Karandikar. A learning theory approach to system
identiﬁcation and stochastic adaptive control. In Probabilistic and randomized methods for
design under uncertainty, pages 265–302. Springer, 2006.
[28] Vitaly Kuznetsov and Mehryar Mohri. Theory and algorithms for forecasting time series. arXiv
preprint arXiv:1803.05814, 2018.
[29] Moritz Hardt, Tengyu Ma, and Benjamin Recht. Gradient descent learns linear dynamical
systems. The Journal of Machine Learning Research, 19(1):1025–1068, 2018.
[30] Anastasios Tsiamis and George J Pappas. Finite sample analysis of stochastic system identiﬁca-
tion. In 2019 IEEE 58th Conference on Decision and Control (CDC), pages 3648–3654. IEEE,
2019.
[31] Tuhin Sarkar, Alexander Rakhlin, and Munther A Dahleh. Finite Time LTI System Identiﬁcation.
J. Mach. Learn. Res., 22:26–1, 2021.
[32] Sahin Lale, Kamyar Azizzadenesheli, Babak Hassibi, and Anima Anandkumar. Logarithmic
regret bound in partially observable linear dynamical systems. arXiv preprint arXiv:2003.11227,
2020.
[33] Holden Lee. Improved rates for identiﬁcation of partially observed linear dynamical systems.
arXiv preprint arXiv:2011.10006, 2020.
[34] Bruce Lee and Andrew Lamperski. Non-asymptotic closed-loop system identiﬁcation using
autoregressive processes and hankel model reduction. In 2020 59th IEEE Conference on
Decision and Control (CDC), pages 3419–3424. IEEE, 2020.
[35] Alon Cohen, Avinatan Hasidim, Tomer Koren, Nevena Lazic, Yishay Mansour, and Kunal
Talwar. Online linear quadratic control. In International Conference on Machine Learning,
pages 1029–1038. PMLR, 2018.
[36] Naman Agarwal, Brian Bullins, Elad Hazan, Sham Kakade, and Karan Singh. Online control
with adversarial disturbances. In International Conference on Machine Learning, pages 111–119.
PMLR, 2019.
[37] Elad Hazan, Sham Kakade, and Karan Singh. The nonstochastic control problem. In Algorithmic
Learning Theory, pages 408–421. PMLR, 2020.
12

[38] Xinyi Chen and Elad Hazan. Black-box control for linear dynamical systems. arXiv preprint
arXiv:2007.06650, 2020.
[39] Udaya Ghai, Holden Lee, Karan Singh, Cyril Zhang, and Yi Zhang. No-regret prediction in
marginally stable systems. In Conference on Learning Theory, pages 1714–1757. PMLR, 2020.
[40] Paria Rashidinejad, Jiantao Jiao, and Stuart Russell. SLIP: Learning to predict in unknown
dynamical systems with long-term memory. arXiv preprint arXiv:2010.05899, 2020.
[41] Mark Kozdoba, Jakub Marecek, Tigran Tchrakian, and Shie Mannor. On-line learning of
linear dynamical systems: Exponential forgetting in kalman ﬁlters. In Proceedings of the AAAI
Conference on Artiﬁcial Intelligence, volume 33, pages 4098–4105, 2019.
[42] Elad Hazan, Karan Singh, and Cyril Zhang. Learning linear dynamical systems via spectral
ﬁltering. Advances in Neural Information Processing Systems, 30:6702–6712, 2017.
[43] Anastasios Tsiamis, Nikolai Matni, and George Pappas. Sample complexity of kalman ﬁltering
for unknown systems. In Learning for Dynamics and Control, pages 435–444. PMLR, 2020.
[44] Anastasios Tsiamis and George Pappas. Online learning of the kalman ﬁlter with logarithmic
regret. arXiv preprint arXiv:2002.05141, 2020.
[45] Vitaly Kuznetsov and Mehryar Mohri. Time series prediction and online learning. In Conference
on Learning Theory, pages 1190–1213. PMLR, 2016.
[46] Anastasios Tsiamis and George J Pappas. Linear systems can be hard to learn. arXiv preprint
arXiv:2104.01120, 2021.
[47] John C. Duchi, Alekh Agarwal, Mikael Johansson, and Michael I. Jordan. Ergodic Mirror
Descent. SIAM Journal on Optimization, 22(4):1549–1578, 2012. doi: 10.1137/110836043.
URL https://doi.org/10.1137/110836043.
[48] Long-Ji Lin. Self-improving reactive agents based on reinforcement learning, planning and
teaching. Machine learning, 8(3-4):293–321, 1992.
[49] Alexandre Défossez and Francis Bach. Averaged least-mean-squares: Bias-variance trade-offs
and optimal sampling distributions. In Artiﬁcial Intelligence and Statistics, pages 205–213.
PMLR, 2015.
[50] Fedor Petrov. Non-asympototic version of Gelfand’s formula. MathOverﬂow, 2016. URL
https://mathoverflow.net/q/228561.
[51] Stéphane Boucheron, Gábor Lugosi, and Pascal Massart.
Concentration inequalities: A
nonasymptotic theory of independence. Oxford university press, 2013.
[52] Roman Vershynin. High-dimensional probability: An introduction with applications in data
science, volume 47. Cambridge university press, 2018.
[53] Torgny Lindvall. Lectures on the coupling method. Courier Corporation, 2002.
[54] Stanislaw J Szarek. Nets of Grassmann manifold and orthogonal group. In Proceedings of
research workshop on Banach space theory (Iowa City, Iowa, 1981), volume 169, page 185,
1982.
[55] T Tony Cai, Zongming Ma, Yihong Wu, et al. Sparse PCA: Optimal rates and adaptive
estimation. The Annals of Statistics, 41(6):3074–3110, 2013.
13

Organization of the appendix
We provide a map of the results in the appendix.
1. In section A we provide formal statements of theorems 1 and 2. We also discuss the more
general spectral gap condition maxi |λi(A)| < 1 instead of the stronger condition ∥A∥< 1
and its impact on the results.
2. In section B we construct the coupled process ˜Xt and setup notations used in the rest of
the paper. The coupled process has the additional property that the successive buffers are
independent.
3. In section C we show that the SGD −RER iterates generated using the coupled process are
close to ones generated by the actual data. After this, we only deal with the coupled iterates.
4. In section D we provide the bias-variance decomposition
5. In section E we provide the proof of the parameter error bound of theorem 1. Required
intermediary results are discussed in section L.
6. In section F we present the bounds on the bias and variance terms separately (for last and
average iterates), which are necessary to prove theorem 6. Most of the proofs are relegated
to sections H, I, J, K and N.
7. In section G we prove theorem 2.
8. In section M, we prove the lower bounds for the prediction error given in theorem 4.
9. In section O we discuss the scenario of VAR(A∗, µ) where A∗is sparse with known sparsity
pattern. We provide a proof sketch of the bound on prediction error in terms of sparsity.
A
Formal Results and Proof Sketch
In this Section, we formally state the full results and sketch the outline of our proof. Recall
the deﬁnitions of Lop and Lpred from section 2. For all the theorems below, we suppose that
Assumptions 1, 2 and 3 hold. Assume that u, γ, B, α and R are as chosen in section 4.
Let t > a and let ˆAa,t be the tail averaged output of SGD −RER after buffer t −1. Further let
T α/2 > cdκ(G).
Theorem 5. Suppose we pick the step size γ = min

C
Bσmin(G),
1
8BR

for some constant C depend-
ing only on Cµ. Then, there are constants C, ci > 0, 0 ≤i ≤4 such that if a > c0 (d + α log T)
then with probability at least 1 −
C
T α , we have:
Lop( ˆAa,t, A∗, µ) ≤c1
s
(d + α log T)σmax(Σ)
(t −a)Bσmin(G)
+ βb ∥A0 −A∗∥+ c4
T 2
B2 ∥A∗u∥
(9)
where
βb = c3
dκ(G) log T
t −a
e−c2
a
dκ(G) log T
(10)
The techniques for the proof is developed in Section L and the Theorem 5 is proved in Section E.
Theorem 6. Let R, B, u, α be chosen as in section 4. Let γ =
c
4RB ≤
1
2R for 0 < c < 1. Then there
are constants c1, c2, c3, c4 > 0 such that for T α/2 > c1
√M4
σmin(G) the expected prediction loss Lpred is
bounded as
E
h
Lpred( ˆAa,t; A∗, µ)
i
−Tr(Σ) ≤c2
"
d Tr(Σ)
B(t −a) + d2σmax(Σ)
B(t −a)
p
κ(G)
B
#
+
c3
d2σmax(Σ)
B2(t −a)2 (κ(G))3/2dB log T+
βb Tr(G) ∥A0 −A∗∥2 +
 T 3
B3 ∥A∗u∥+ dσmax(Σ)
R
T 2
B2
1
T α/2

Tr(G)

(11)
14

where βb is deﬁned in (10).
The above theorem is proven only for the case t = N. The proof for general t is almost the same. The
proof follows by ﬁrst considering E
h
Lpred( ˆAa,N; A∗, µ)1

D0,N−1i
(D0,N−1 is deﬁned in B.1)
and using theorem 20 and theorem 21 along with lemma 12 in the appendix sections G.1, G.2 and C.
Then noting that if the norm of any of the covariates Xt exceed
√
R the algorithm returns the zero
matrix we have that E
h
Lpred( ˆAa,N; A∗, µ)1

D0,N−1,Ci
≤c ∥A∗∥Tr(G) 1
T α .
Remark.
(1) In theorem 6 the term d2σmax(Σ)
B(t−a)
√
κ(G)
B
is strictly a lower order term compared to d Tr(Σ)
B(t−a)
when ∥A∗∥< c0 < 1. To see this note that σmax(G) ≤σmax(Σ)
1−∥A∗∥2 and σmin(G) ≥σmin(Σ).
Hence κ(G) ≤
κ(Σ)
1−∥A∗∥2 = O(τmixκ(Σ)). By the choice of B in the section 4 we see that
√
κ(G)
B
= o(1) and it does not depend on condition number of A∗.
(2) If a = Ω

dκ(G) (log T)2
the βb is a lower order term. Further choosing u and α as in
section 4 we see that the terms depending on ∥A∗u∥and
1
T α/2 are strictly lower order.
(3) Thus for the choice of a as in the previous remark such that a < (1 + c)t (for some c > 0),
we get minimax optimal rates: d Tr(Σ)
Bt
for Lpred and up to log factors,
q
dσmax(Σ)
T σmin(G) for Lop
A.1
Spectral Gap Condition
In Assumption 1, we could have used the more general spectral radius condition ρ(A∗) =
supi |λi(A∗)| < 1 rather than the one on the operator norm. We have the Gelfand formula for
spectral radius which shows that limk→∞∥A∗k∥1/k = ρ(A∗). Now, if A∗is such that ρ(A∗) < 1
but ∥A∗∥> 1 (a case studied by [5]), then we need to make u as large as Cd log T which would lead
to a relatively large buffer size B of d log T. To see this, we verify the proof by [50] (by replacing A
with
A
∥A∥and ρ(A) with
ρ
∥A∥in the proof) to show that ∥A∗k∥≤(2k∥A∗∥)d ρk−d whenever k ≥d.
Therefore, in the worst case, we can pick u = O
 (log (Tσmax(G)) + d log d∥A∥) / log 1/ρ

.
In the case of ρ < 1 but ∥A∗∥> 1, κ(G) can grow super linearly in d. For instance, consider A∗
to be nilpotent of order d (i.e. A∗d−1 ̸= 0 but A∗d = 0). Here σmax(G) can grow like ∥A∗∥d. So
we need exponentially (in d) many samples for bias decay. However, in many cases of interest (ex:
symmetric matrices, normal matrices etc) the spectral radius is the same as the operator norm.
B
Basic Lemmas and Notations
Since the covariates {Xτ}τ≤T are correlated, we will introduce a coupled process such that we
have independence across buffers and that Euclidean distance between the covariates of the original
process and the coupled process can be controlled.
Remark. Note that the coupled process is imaginary and we do not actually run the algorithm with
the coupled process. We construct it to make the analysis simple by ﬁrst analyzing the algorithm
with the imaginary coupled process and then showing that the output of the actual algorithm cannot
deviate too much when run with the actual data.
Deﬁnition 1 (Coupled process). Given the covariates {Xτ : τ = 0, 1, . · · · T} and noise {ητ : τ =
0, 1, · · · , T}, we deﬁne { ˜Xτ : τ = 0, 1, · · · , T} as follows:
1. For each buffer t generate, independently of everything else, ˜Xt
0 ∼π, the stationary distri-
bution of the VAR(A∗, µ) model.
2. Then, each buffer has the same recursion as eq (2):
˜Xt
i+1 = A∗˜Xt
i + ηt
i, i = 0, 1, · · · S −1,
(12)
where the noise vectors as same as in the actual process {Xτ}.
With this deﬁnition, we have the following lemma:
15

Lemma 7. For any buffer t, ∥Xt
i −˜Xt
i∥≤∥A∗i∥∥Xt
0 −˜Xt
0∥, a.s.. That is,
∥Xt
iXt
i
T −˜Xt
i ˜Xt
i
T ∥≤2 ∥X∥∥Xt
i −˜Xt
i∥≤(2 ∥X∥)2∥A∗i∥.
(13)
Here ∥X∥denotes supτ≤T ∥Xτ∥.
Lemma 8. Suppose µ obeys Assumption 2 and A∗obeys Assumption 1. Suppose X ∼π, which is
the stationary distribution of VAR(A∗, µ). ⟨X, x⟩has mean 0 and is sub-Gaussian with variance
proxy Cµx⊤Gx
Proof. Suppose η1, . . . , ηn, . . . is a sequence of i.i.d random vectors drawn from the noise distri-
bution µ. We consider the partial sums Pn
i=0 A∗iηi. Call the law of this to be πn. Clearly πn
converges in distribution to π as n →∞since πn is the law of the n + 1-th iterate of VAR(A∗, µ)
chain stated at X0 = 0. By Skorokhod representation theorem, we can deﬁne the inﬁnite se-
quence X(1), . . . , X(n), . . . , and another random variable X such that X(i) ∼πi, X ∼π and
limn→∞X(n) = X a.s. Deﬁne Gn = Pn
i=0 A∗iΣ(A∗i)T . Clearly, Gn ⪯G = P∞
i=0 A∗iΣ(A∗i)T .
A simple evaluation of Chernoff bound for ⟨X(n), x⟩by decomposing it into the partial sum of noises
shows that:
E exp(λ⟨X(n), x⟩) ≤exp
λ2Cµ
2
⟨x, Gnx⟩

≤exp
λ2Cµ
2
⟨x, Gx⟩

We now apply Fatou’s lemma, since X(n) →X almost surely, to the inequality above to conclude
that:
E exp(λ⟨X, x⟩) ≤exp
λ2Cµ
2
⟨x, Gx⟩

.
Hence ⟨x, Xt⟩is subgaussian with mean 0 and variance proxy Cµσmax(G) ∥x∥2. This will provide
uniform variance for all x such that ∥x∥2 = 1.
From subgaussianity and standard ϵ-net argument we have the following lemma.
Lemma 9. For any β > 0 there is a constant c > 0 such that
P
h
∃τ ≤T : ∥Xτ∥2 > c Tr G log T
i
≤d
T β
(14)
Thus as long as d < Poly(T), for every α > 0 there is a c > 0 such that
P
h
∃τ ≤T : ∥Xτ∥2 > c Tr G log T
i
≤1
T α
(15)
B.1
Notations
Before we analyze this algorithm, we deﬁne some notations. We work in a probability space (Ω, F, P)
and all the random elements are deﬁned on this space. We deﬁne the following notations:
Xt
−i = Xt
(S−1)−i, 0 ≤i ≤S −1,
G =
∞
X
s=0
A∗sΣ(A∗⊤)s,
Gt =
t−1
X
s=0
A∗sΣ(A∗⊤)s,
˜P t
i =

I −2γ ˜Xt
i ˜Xt,⊤
i

,
˜Ht
i,j =
(Qj
s=i ˜P t
−s
i ≤j
I
i > j ,
ˆγ = 4γ(1 −γR),
Ct
−j =

∥Xt
−j∥2 ≤R
	
,
˜Ct
−j =
n
∥˜Xt
−j∥2 ≤R
o
,
Dt
−j =

∥Xt
−i∥2 ≤R : j ≤i ≤B −1
	
=
B−1
\
i=j
Ct
−i,
Ds,t =
Tt
r=s Dr
−0
s ≤t
Ω
s > t ,
˜Dt
−j =
n
∥˜Xt
−i∥2 ≤R : j ≤i ≤B −1
o
=
B−1
\
i=j
˜Ct
−i,
˜Ds,t =
Tt
r=s ˜Dr
−0
s ≤t
Ω
s > t ,
ˆDt
−j = Dt
−j ∩˜Dt
−j,
ˆDs,t = Ds,t ∩˜Ds,t.
16

Lastly c and ci for i = 0, 1, · · · denote absolute constants that can change from line to line in the
proofs.
C
Initial Coupling
We consider the coupled process introduced in Deﬁnition 1 and run SGD −RER with the ﬁctitious
coupled process ˜Xτ instead of Xτ in order to obtain the iterates ˜At
i instead of At−1
i
. Using Lemma 7,
we can show that ˜At−1
i
≈At−1
i
. It is easier to analyze the iterates ˜At
i due to buffer independence.
Lemma 10. Let γ ≤
1
2R. Under the event D0,N−1, for every t ∈[N] and 0 ≤i ≤B −1 we have:
∥At−1
i
∥≤2γRT .
Lemma 11. Suppose γ <
1
2R. Under the event ˆD0,N−1 we have for every t ∈[N] and 0 ≤i ≤B−1.
∥At−1
i
−˜At−1
i
∥≤(16γ2R2T 2 + 8γRT) ∥A∗u∥
We can now just analyze the iterates ˜At−1
i
and then use Lemma 11 to infer error bounds for At−1
i
.
Henceforth, we will only consider ˜At−1
i
.
Lemma 12. Consider the algorithmic iterates obtained from the actual process and coupled process
(At
j) and ( ˜At
j). Then
E
h At−1
j
−A∗⊤ At−1
j
−A∗
1

D0,t−1i
⪯E

˜At−1
j
−A∗⊤
˜At−1
j
−A∗
1
h
˜D0,t−1i
+ c

γ3R3T 3 ∥A∗u∥+ γ2dσmax(Σ)RT 2
1
T α/2

I
(16)
for some constant c. Furthermore, the same conclusion holds for the average iterates. That is let
ˆAa,N =
1
N −a
N
X
t=a+1
At−1
B
ˆ˜Aa,N =
1
N −a
N
X
t=a+1
˜At−1
B
Then
E

ˆAa,N −A∗⊤
ˆAa,N −A∗
1

D0,N−1
⪯E
 ˆ˜Aa,N −A∗⊤ ˆ˜Aa,N −A∗
1
h
˜D0,N−1i
+ c

γ3R3T 3 ∥A∗u∥+ γ2dσmax(Σ)RT 2
1
T α/2

I
(17)
Remark. The above lemma holds as is when At−1
j
, ˜At−1
j
is replaced by At−1,v
j
, ˜At−1,v
j
respectively.
We refer to Section N for the proofs of the three lemmas.
D
Bias Variance Decomposition
Now, we can unroll the recursion in (6), but for the coupled iterates ˜At−1
i
as
˜At−1
B
−A∗=

˜At−1,b
B
−A∗
+

˜At−1,v
B

,
(18)
where

˜At−1,b
B
−A∗
= (A0 −A∗)
t−1
Y
s=0
˜Hs
0,B−1
(19)
17

is the bias term, and the variance term is given by:

˜At−1,v
B

= 2γ
t
X
r=1
B−1
X
j=0
ηt−r
−j ˜Xt−r,⊤
−j
˜Ht−r
j+1,B−1
1
Y
s=r−1
˜Ht−s
0,B−1
(20)
Here we use the convention that whenever r = 1, the product Q1
s=r−1 is empty i.e, equal to 1.
The ‘bias’ term is obtained when the noise terms are set to 0, and captures the movement of the
algorithm towards the optimal A∗when we set the initial iterate far away from it. The ‘variance’
term
 At,v
B −A∗
capture the uncertainty due to the inherent noise in the data. Our main goal is
to understand the performance (estimation and prediction) of the tail-averaged iterates output by
SGD −RER. Here, we consider just the last iterate, but the same technique applies to all the outputs
of SGD −RER. That is, ˆ˜Aa,N =
1
N−a
PN
t=a+1 ˜At−1
B , for a = ⌈θN⌉with 0 < θ < 1. We can
decompose the above into bias and variance as: ˆ˜Aa,N = ˆ˜Av
a,N + ˆ˜Ab
a,N, with,
ˆ˜Av
a,N =
1
N −a
N
X
t=a+1
˜At−1,v
B
(21)
ˆ˜Ab
a,N =
1
N −a
N
X
t=a+1
˜At−1,b
B
.
(22)
Similarly, we can decompose the ﬁnal error into ‘bias’ and ‘variance’ as in Lemma 13 below.
Lemma 13 (Bias-Variance Decomposition). We have the following decomposition:

˜At−1
B
−A∗⊤
˜At−1
B
−A∗
⪯2

˜At−1,b
B
−A∗⊤
˜At−1,b
B
−A∗
+

˜At−1,v
B
⊤
˜At−1,v
B

.
E
Parameter Error Bound–Proof of Theorem 5
In this section, we formally prove the bounds on Lop(; A∗, µ), by combining several operator norm
inequalities that we prove in Section L. As mentioned previously, we will just focus on the algorithmic
iterates from the coupled process ( ˜At−1
j
). Recall the output ˜At−1
B
after the t −1-th buffer from
Equation (18). For any initial buffer index a ∈{0, 1, . . . , N −1}, the tail averaged output of our
algorithm is:
ˆ˜Aa,N :=
1
N −a
N
X
t=a+1
˜At−1
B .
Recall the quantities ˜At−1,v
B
and ˜At−1,b
B
as deﬁned in (19) and (20). We can use this decomposition
to write:
ˆ˜Aa,N −A∗= ˆ˜Ab
a,N −A∗+ ˆ˜Av
a,N.
Here
ˆ˜Ab
a,N −A∗
:=
1
N−a
PN
t=a+1

˜At−1,b
B
−A∗
denotes the bias part and
ˆ˜Av
a,N
:=
1
N−a
PN
t=a+1

˜At−1,v
B

denotes the variance part.
E.1
Variance
Note that
ˆ˜Av
a,N =
N
N −a
 ˆ˜Av
0,N

−
a
N −a
 ˆ˜Av
0,a

(23)
Now, we apply Theorem 33 with δ in the deﬁnition of ˜
M0,N−1 to be
1
T υ for some ﬁxed υ ≥1. We
conclude that conditioned on the event ˜
M0,N−1 ∩˜D0,N−1, with probability at least 1 −
1
T υ , we have:
18

∥ˆ˜Av
0,N∥≤C
r
γ(d + υ log T)2σmax(Σ)
N
+ C
s
(d + υ log T)σmax(Σ)
NBσmin(G)
.
Similarly, applying Theorem 33 with N = a shows that with probability at least 1 −
1
T υ conditioned
on the event ˜
M0,N−1 ∩˜D0,N−1:
∥ˆ˜Av
0,a∥≤C
r
γ(d + υ log T)2σmax(Σ)
a
+ C
s
(d + υ log T)σmax(Σ)
aBσmin(G)
.
Here, the constant C depends only on Cµ. We also note that when we pick γBR ≤C0 where
R ≳Tr(G) + υ log T, the ﬁrst term in the equations above becomes smaller than the second term.
Therefore, under this assumption we can simplify the expressions to:
∥ˆ˜Av
0,N∥≤C
s
(d + υ log T)σmax(Σ)
NBσmin(G)
.
(24)
∥ˆ˜Av
0,a∥≤C
s
(d + υ log T)σmax(Σ)
aBσmin(G)
.
(25)
Applying Equations (24) and (25) to Equation (23) we conclude that conditioned on the event
˜
M0,N−1 ∩˜D0,N−1, with probability at least 1 −
2
T υ , we have:
∥ˆ˜Av
a,N∥≤
N
N −a∥
 ˆ˜Av
0,N

∥+
a
N −a∥
 ˆ˜Av
0,a

∥
≤
CN
N −a
s
(d + υ log T)σmax(Σ)
NBσmin(G)
+
Ca
N −a
s
(d + υ log T)σmax(Σ)
aBσmin(G)
.
(26)
Choose a < N/2. Since
P
h
˜
M0,N−1 ∩˜D0,N−1i
≥1 −( 1
T υ + 1
T α )
we have
P
"
∥ˆ˜Av
a,N∥> C
s
(d + υ log T)σmax(Σ)
(N −a)Bσmin(G)
#
≤1
T α + 3
T υ
(27)
E.2
Bias
We now consider the bias term: ˆ˜Ab
a,N −A∗:=
1
N−a
PN
t=a+1

˜At−1,b
B
−A∗
. First note that, from
equation (19), we have
 ˆ˜Ab
a,N −A∗ ≤
1
N −a
N
X
t=a+1
∥A0 −A∗∥

t−1
Y
s=0
˜Hs
0,B−1

(28)
Now from lemma 31, if a > c1
 d + log N
δ

then conditional on ˜D0,N−1 with probability at least
1 −δ, for all a + 1 ≤t ≤N we have

t−1
Y
s=0
˜Hs
0,B−1
 ≤2 (1 −γBσmin(G))c2t
(29)
Note that in lemma 31 we only condition on ˜D0,t−1 but due to buffer independence and that
P
h
˜D0,N−1i
≥1 −
1
T α we can condition on ˜D0,N−1.
19

Note that in the proof of lemma 31 the constant c2 is actually at most 1 i.e., 0 < c2 ≤1. Hence from
Bernoulli’s inequality, for x < 1
(1 −x)c2 ≤1 −c2x
Thus conditional on ˜D0,N−1 with probability at least 1 −δ
 ˆ˜Ab
a,N −A∗ ≤∥A0 −A∗∥
N −a
∞
X
t=a+1
2 (1 −γBσmin(G))c2t
= 2∥A0 −A∗∥
N −a
(1 −γBσmin(G))c2a
c2γBσmin(G)
≤c3
∥A0 −A∗∥
N −a
e−c2aγBσmin(G)
γBσmin(G)
(30)
Hence choosing δ =
1
T υ we have for a > c1
 d + log N
δ

P
 ˆ˜Ab
a,N −A∗ > c3
∥A0 −A∗∥
N −a
e−c2aγBσmin(G)
γBσmin(G)

≤1
T α + 1
T υ
(31)
Deﬁne βb as
βb = c3
1
N −a
e−c2aγBσmin(G)
γBσmin(G)
(32)
Thus by union bound and equations (27) and (31) we get
P
" ˆ˜Aa,N −A∗ > C
s
(d + υ log T)σmax(Σ)
(N −a)Bσmin(G)
+ βb ∥A0 −A∗∥
#
≤2
T α + 4
T υ
(33)
Now from lemma 11 we see that on the event ˆD0,N−1
 ˆAa,N −ˆ˜Aa,N
 ≤cγ2R2T 2 ∥A∗u∥
(34)
Since P
h
ˆD0,N−1i
≥1 −
1
T α , we obtain
P
h ˆAa,N −ˆ˜Aa,N
 ≤cγ2R2T 2 ∥A∗u∥
i
≥1 −1
T α
(35)
Therefore choosing δ =
1
T υ we have for N/2 > a > c1
 d + log N
δ

P
" ˆAa,N −A∗ > C
s
(d + υ log T)σmax(Σ)
(N −a)Bσmin(G)
+ βb ∥A0 −A∗∥+ c4γ2R2T 2 ∥A∗u∥
#
≤3
T α + 4
T υ
(36)
where βb is deﬁned in (32).
The theorem follows by adjusting the constants (in choosing δ) such the above probability is at most
3
T α +
1
2T υ and then choosing υ such that
3
T α ≤
1
2T υ .
F
Bias Variance Analysis of Last and Average Iterate
In this section, our goal is to provide a PSD upper bound on
E

˜At−1
B
−A∗⊤
˜At−1
B
−A∗
, E
 ˆ˜Aa,N −A∗⊤ ˆ˜Aa,N −A∗
using the bias variance decomposition in (18) and (22). This bound leads to Theorem 15 which is
critical for our parameter error proof (Theorem 5).
20

F.1
Variance of the Last Iterate
The goal of this section is to bound error due to

˜At−1,v
B

. For brevity, we will introduce the
following notation:
˜Vt−1 = E

˜At−1,v
B
⊤
˜At−1,v
B

1
h
˜D0,t−1i
.
(37)
The following proposition is the main result of this section.
Proposition 1. Let γ ≤
1
2R. Let the noise covariance be E

ηtηT
t

= Σ. Then,
˜Vt−1 ⪯γ Tr(Σ)
1 −γR
"
I −E
" 
t
Y
s=1
˜Ht−s,⊤
0,B−1
!  1
Y
s=t
˜Ht−s
0,B−1
!
1
h
˜D0,t−1i##
+ c1γ2dσmax(Σ)(Bt)2
1
T α/2 I,
˜Vt−1 ⪰γ Tr(Σ)
"
I −E
" 
t
Y
s=1
˜Ht−s,⊤
0,B−1
!  1
Y
s=t
˜Ht−s
0,B−1
!
1
h
˜D0,t−1i##
−c4γ2dσmax(Σ)(Bt)2
1
T α/2 I,
for some absolute constants ci > 0, 1 ≤i ≤4.
We refer to Section H in the appendix for a full proof. Note that we have,
1
1−γ∥X∥2 ≤2.
Corollary 1. In the same setting as Proposition 1, we have:
˜Vt−1 ⪯c1γ Tr(Σ)I + c2γ2dσmax(Σ)(Bt)2
1
T α/2 I,
(38)
for some constants c1, c2 > 0. If T α/2 > T 2, then Vt,1 ⪯cγdσmaxI, for some constant c > 0.
F.2
Variance of the Average Iterate
In this section we are interested in bounding: E
 ˆ˜Av
a,N
⊤ ˆ˜Av
a,N

1
h
˜D0,N−1i
, for a = θN with
0 ≤θ < 1, where,
ˆ˜Av
a,N =
1
N −a
N
X
t=a+1
˜At−1,v
B
,
(39)
and further, recall that T = N(B + u). The main bound in this section is given in Proposition 2.
Note that we have,
E
 ˆ˜Av
a,N
⊤ ˆ˜Av
a,N

1
h
˜D0,N−1i
=
1
(N −a)2
N
X
t=a+1
E

˜At−1,v
B
⊤
˜At−1,v
B

1
h
˜D0,N−1i
+
1
(N −a)2
X
t1̸=t2
E

˜At1−1,v
B
⊤
˜At2−1,v
B

1
h
˜D0,N−1i
(40)
Proposition 2. Let γ ≤min{
c
6RB
1
2R} for 0 < c < 1. Then for ˆ˜Av
a,N deﬁned in (39), there are
constants c1, c2 > 0 such that if T α/2 > c1
√M4
σmin(G), then:
E
 ˆ˜Av
a,N
⊤ ˆ˜Av
a,N

1
h
˜D0,N−1i
⪯
1
(N −a)2
N
X
t=a+1

˜Vt−1
 N−t
X
s=0
Hs
!
+
 N−t
X
s=0
Hs
!⊤
˜Vt−1

+ c2δI
(41)
=
1
(N −a)2
N
X
t=a+1
h
˜Vt−1 (I −H)−1 +
 I −H⊤−1 ˜Vt−1
i
+ c2δI +
1
(N −a)2
N
X
t=a+1
h
˜Vt−1 (I −H)−1 HN−t+1 +
 H⊤N−t+1  I −H⊤−1 ˜Vt−1
i
(42)
21

and,
δ ≡δ(N, B, R) = γ2T 2Rdσmax(Σ)
1
T α/2
(43)
and H is given by,
H = E


B−1
Y
j=0

I −2γ ˜X0
−j ˜X0,⊤
−j

1
h
∩B−1
j=0
n
∥˜X0
−j∥2 ≤R
oi

,
(44)
with ˜X0 sampled from the stationary distribution π and ˜Xt follows the VAR(A∗, µ).
See section I in the appendix for the proof.
F.3
Bias of the Last Iterate
In this we will analyze the bias term of the last iterate. That is we want to bound:
E

˜At−1,b
B
−A∗⊤
˜At−1,b
B
−A∗
1
h
˜D0,t−1i
.
Where

˜At−1,b
B
−A∗
is deﬁned in (19).
Theorem 14. Let γRB ≤c
6 for some 0 < c < 1 with B such that γR ≤1
2. Then there are constants
c1, c2, c3 > 0 such that if T α/2 > c1
√M4
σmin(G) (where M4 = E
h
∥˜X0
−0∥4i
) then
E

˜At−1,b
B
−A∗⊤
˜At−1,b
B
−A∗
1
h
˜D0,t−1i
⪯∥A0 −A∗∥2 (1 −c2γBσmin(G))t I (45)
See section J for the proof.
F.4
Bias of the Tail-Averaged Iterate
We deﬁne the tail averaged bias as
ˆ˜Ab
a,N =
1
N −a
N
X
t=a+1
˜At−1,b
B
(46)
Theorem 15. Let γRB ≤c
6 for some 0 < c < 1 and B such that γR ≤1
2. There exist constants
c1, c2 > 0 such that if T = N(B + u) satisﬁes T α/2 > c1
√M4
σmin(G) then for a = θN with 0 < θ < 1
we have
E
 ˆ˜Ab
a,N −A∗⊤ ˆ˜Ab
a,N −A∗
1
h
˜D0,N−1i ≤
c2
1
B(N −a)
e−c3Bγσmin(G)a
γσmin(G)
∥A0 −A∗∥2
(47)
See section K for the proof.
G
Prediction Error
Recall the deﬁnition of the prediction error at stationarity.
Lpred( ˆA; A∗, µ) := EXt∼π∥Xt+1 −ˆAXt∥2
(48)
where π is the stationary distribution.
Note that the prediction loss is a function of possibly random estimator ˆA. Hence the expectation
in (48) is only with respect to the process (Xt) (which is considered independent of ˆA). Letting
G = E

XtX⊤
t

as the covariance matrix of the process at stationarity, we can write
Lpred( ˆA; A∗, µ) = Tr(G( ˆA −A∗)⊤( ˆA −A∗)) + Tr(Σ)
(49)
22

We are interested in bounding the expected prediction loss of the estimator which is the average
iterate ˆAa,N of our algorithm SGD −RER (with a = θN). Note that ˆAa,N = ˆAb
a,N + ˆAv
a,N where
the superscripts b and v correspond to bias and variance respectively (c.f. (22))
Hence
E
h
Lpred( ˆAa,N; A∗, µ)
i
= Tr(Σ) + Tr

G1/2E

ˆAa,N −A∗⊤
ˆAa,N −A∗
G1/2

≤Tr(Σ) + 2 Tr

G1/2E

ˆAv
a,N
⊤
ˆAv
a,N

G1/2

+ 2 Tr

G1/2E

ˆAb
a,N −A∗⊤
ˆAb
a,N −A∗
G1/2

(50)
But we will only bound E
h
Lpred( ˆAa,N; A∗, µ)1

D0,N−1i
so that we have a tight upper bound on
the conditional expectation of Lpred over a high probability event.
As before we will just focus on the prediction error obtained using the algorithmic iterates from the
coupled process, i.e., we will bound E
h
Lpred( ˆ˜Aa,N; A∗, µ)1
h
˜D0,N−1ii
G.1
Variance of prediction error
In this section we will focus on analyzing the variance part of the expected prediction loss under the
coupled process
˜Lv = Tr

G1/2E
 ˆ˜Av
a,N
⊤ ˆ˜Av
a,N

1
h
˜D0,N−1i
G1/2

(51)
where T = N(B + u).
We begin with few lemmata which would be useful in bounding ˜Lv. Recall the deﬁnition of H
H = E


B−1
Y
j=0

I −2γ ˜X0
−j ˜X0,⊤
−j

1[ ˜D0
−0]


(52)
with ˜X0 sampled from the stationary distribution π.
Lemma 16. Let γ ≤
1
8RB . Then
H + H⊤⪯2

I −4
3γBG

+ 8
3γB
p
M4
1
T α/2 I
(53)
where M4 = E
h
∥˜X0
−0∥4i
. For simplicity, we just say that for γRB < c
4 with 0 < c < 1 then
H + H⊤⪯2 (I −c1γBG) + c2γB
p
M4
1
T α/2 I
(54)
for some absolute constants c1, c2 > 0.
The proof is similar to the combined proofs of Lemmas 28 and 29. We therefore skip it.
Next we will bound Tr(G(I −H)−1).
Lemma 17. Let γRB < c1
4 with 0 < c1 < 1. Then for T such that T α/2 > c2
√M4
σmin(G) we have
Tr
 G(I −H)−1
≤c d
γB
(55)
for some absolute constant c > 0.
23

Proof. First note that
Tr
 G(I −H)−1
) = Tr

G1/2(I −H)−1G1/2
)
= Tr

G−1 −G−1/2HG−1/2−1
≤d


G−1 −G−1/2HG−1/2−1
=
d
σmin
 G−1 −G−1/2HG−1/2
(56)
Let Q =
 G−1 −G−1/2HG−1/2
. Let Sym (Q) = Q + Q⊤. We will relate σmin(Q) with
σmin

Sym(Q)
2

. From AM-GM inequality, for any θ > 0, we have
Q⊤Q
θ
+ θI ⪰Sym (Q)
(57)
Also
σ2
min(Q) =
inf
x:∥x∥=1 x⊤Q⊤Qx
(58)
Further, from lemma 16 we have
Sym (Q) = G−1 −G−1/2 H + HT
2
G−1/2
⪰c1γBI −c2γB
p
M4
1
T α/2 G−1
⪰c1γBI −c2γB
p
M4
1
T α/2
1
σmin(G)I
(59)
Hence combining equations (57), (58) and (59) we have:
σ2
min(Q)
θ
+ θ ⪰c1γB −c2γB
p
M4
1
T α/2
1
σmin(G).
(60)
Now choosing θ = 1
2c1γB we get:
σ2
min(Q) ≥c2
1
4 γ2B2 −c2c1
2 γ2B2p
M4
1
T α/2
1
σmin(G).
(61)
Now choose T large enough such that c2c1
2
√M4
1
T α/2
1
σmin(G) ≤c2
1
8 . Then, σ2
min(Q) ≥c3γ2B2, for
some constant c3 > 0. Hence from (56),
Tr
 G(I −H)−1
≤c4
d
γB .
Next we bound Tr(∆(I −H)−1G) for any symmetric matrix ∆. Let κ(G) =
σmax(G)
σmin(G) denote the
condition number of G.
Lemma 18. Let γRB ≤c1
4 with 0 < c1 < 1. Then for T such that T α/2 > c2
√M4
σmin(G) we have
Tr
 ∆(I −H)−1G
 ≤c d
γB ∥∆∥
p
κ(G)
(62)
for some absolute constant c > 0.
Proof. We have
Tr
 ∆(I −H)−1G
 =
Tr

G1/2∆G−1/2G1/2(I −H)−1G1/2
≤d
G1/2∆G−1/2
G1/2(I −H)−1G1/2
≤d
p
κ(G) ∥∆∥
G1/2(I −H)−1G1/2
(63)
24

From the proof of lemma 17, we know that
G1/2(I −H)−1G1/2 ≤c 1
γB
(64)
for T satisfying the condition the statement of the lemma.
Hence:
Tr
 ∆(I −H)−1G
 ≤c
p
κ(G) ∥∆∥d
γB
(65)
Our goal is to bound Tr( ˜Vt−1(I −H)−1G). From proposition 1 we can decompose ˜Vt−1 as:
˜Vt−1 = γ Tr(Σ)I + ( ˜Vt−1 −γ Tr(Σ)I),
(66)
and hence,
Tr( ˜Vt−1(I −H)−1G) = γ Tr(Σ) Tr((I −H)−1G) + Tr

( ˜Vt−1 −γ Tr(Σ))(I −H)−1G

. (67)
To bound the second term in (67) we want to use lemma 18. Hence we need to bound the norm of
˜Vt−1 −γ Tr(Σ).
Lemma 19. Let γ ≤min

c
4RB ,
1
2R
	
for 0 < c < 1. Then there are constants c1, c2, c3 > 0 such
that for T α/2 > c1
√M4
σmin(G) we have
 ˜Vt−1 −γ Tr(Σ)
 ≤c2γdσmax
 1
B + (1 −c3γBσmin(G))t

(68)
for some constant c1 > 0.
Proof. From proposition 1 we have
 ˜Vt−1 −γ Tr(Σ)I
 ≤γ Tr(Σ)
γR
1 −γR +
c1γ Tr(Σ)
E
" tY
s=1
˜Ht−s,⊤
0,B−1
!  1
Y
s=t
˜Ht−s
0,B−1
!
1
h
˜D0,t−1i#
+ c2γdσmax(Σ)T 2
1
T α/2 .
(69)
From lemma 26 equation (111) we can show that
E
" tY
s=1
˜Ht−s,⊤
0,B−1
!  1
Y
s=t
˜Ht−s
0,B−1
!
1
h
˜D0,t−1i# ≤(1 −c3γBσmin(G))t .
(70)
Hence
 ˜Vt−1 −γ Tr(Σ)I
 ≤c4γdσmax(Σ)

γR
1 −γR + (1 −c3γBσmin(G))t

≤c5γdσmax
h
γR + (1 −c3γBσmin(G))ti
≤c6γdσmax
 1
B + (1 −c3γBσmin(G))t

. (71)
Now we have all required ingredients for the main theorem of this section
Theorem 20. Let γ ≤min

c
4RB ,
1
2R
	
for 0 < c < 1. Then there are constants c1, c2, c3, c4 > 0
such that for T α/2 > c1
√M4
σmin(G) the variance part of the expected prediction loss ˜Lv (deﬁned in (51))
for a = θN is bounded as
˜Lv ≤c1
d Tr(Σ)
NB(1 −θ) + c2
d2σmax(Σ)
NB(1 −θ)
p
κ(G)
B
+ c3
d2σmax(Σ)
(NB)2(1 −θ)2
p
κ(G)
1
γσmin(G)
+ c4γ2Rdσmax(Σ)T 2
1
T α/2 Tr(G)
(72)
25

Proof. From (51) and proposition 2 equation (42) we have
˜Lv ≤
2
(N −a)2
N
X
t=a+1
Tr

˜Vt−1(I −H)−1G

(73)
+
2
(N −a)2
N
X
t=a+1
Tr

˜Vt−1(I −H)−1HN−t+1G

(74)
+ cδ Tr(G)
(75)
where δ = γ2T 2Rdσmax(Σ)
1
T α/2 as deﬁned in (43)
For the ﬁrst term (73) we have from (67), lemma 17, lemma 18 and lemma 19
Tr

˜Vt−1(I −H)−1G

≤c1γ Tr(Σ) d
γB +
c2
d
γB
p
κ(G)γdσmax(Σ)
 1
B + (1 −c3γBσmin(G))t

= c1
d Tr(Σ)
B
+ c2
d2σmax(Σ)
B
p
κ(G)
B
+
c4
d2σmax(Σ)
B
p
κ(G) (1 −c3γBσmin(G))t
(76)
Therefore
2
(N −a)2
N
X
t=a+1
Tr

˜Vt−1(I −H)−1G

≤c1
d Tr(Σ)
NB(1 −θ) + c2
d2σmax(Σ)
NB(1 −θ)
p
κ(G)
B
+
c5
d2σmax(Σ)
N 2B(1 −θ)2
p
κ(G)(1 −c3γBσmin(G))a+1
γBσmin(G)
(77)
Similarly, for the second term (74), from corollary 1, lemma 18, lemma 26 and the fact that (I −H)−1
and HN−t+1 commute, we get
Tr

˜Vt−1(I −H)−1HN−t+1G
 ≤c1
d
γB
√κ∥˜Vt−1∥∥HN−t+1∥
≤c2
d
γB
p
κ(G)γdσmax(Σ) (1 −c3γBσmin(G))(N−t+1)
= c2
d2σmax(Σ)
B
p
κ(G) (1 −c3γBσmin(G))(N−t+1)
(78)
Therefore

2
(N −a)2
N
X
t=a+1
Tr

˜Vt−1(I −H)−1HN−t+1G
 ≤c d2σmax(Σ)
N 2B(1 −θ)2
p
κ(G)
1
γBσmin(G)(79)
Hence we obtain,
˜Lv ≤c1
d Tr(Σ)
NB(1 −θ) + c2
d2σmax(Σ)
NB(1 −θ)
p
κ(G)
B
+
c3
d2σmax(Σ)
N 2B2(1 −θ)2
p
κ(G)
1
γσmin(G) + c4γ2Rdσmax(Σ)T 2
1
T α/2 Tr(G).
(80)
G.2
Bias of prediction error
In this section we will focus on analyzing the (tail-averaged) bias part of the expected prediction loss
from the coupled process
˜Lb = Tr

G1/2E
 ˆ˜Ab
a,N −A∗⊤ ˆ˜Ab
a,N −A∗
1
h
˜D0,N−1i
G1/2

(81)
where T = N(B + u) and a = θN for 0 < θ < 1.
26

Theorem 21. Let γRB ≤c
6 for some 0 < c < 1 and B such that γR ≤1
2. There exist constants
c1, c2, c3, c4 > 0 such that if T satisﬁes T α/2 > c1
√M4
σmin(G) then for a = θN with 0 < θ < 1 we have
˜Lb ≤c2
1
NB(1 −θ)
Tr(G)
γσmin(G)e−c3NBγσmin(G)θ ∥A0 −A∗∥2
(82)
Proof. Proof follows directly from (81) and theorem 15.
G.3
Overall Prediction Error
Combining theorem 20 and theorem 21 along with lemma 12 we obtain the main theorem on
prediction error of SGD −RER
Theorem 22. Let R, B, u, α be chosen as in section 4. Let γ =
c
4RB ≤
1
2R for 0 < c < 1. Then
there are constants c1, c2, c3, c4 > 0 such that for T α/2 > c1
√M4
σmin(G) the expected prediction loss L
(deﬁned in (49)) is bounded as
E
h
Lpred( ˆAa,N; A∗, µ)1

D0,N−1i
≤c2
"
d Tr(Σ)
B(N −a) + d2σmax(Σ)
B(N −a)
p
κ(G)
B
#
+
c3
 d2σmax(Σ)
B2(N −a)2
p
κ(G)
1
γσmin(G)+
1
B(N −a)dκ(G)RBe−c4
σmin(G)
R
a ∥A0 −A∗∥2 +
 T 3
B3 ∥A∗u∥+ dσmax(Σ)
R
T 2
B2
1
T α/2

Tr(G)

(83)
Hence, if ∥A∗∥< c0 < 1 then choosing a ≥C R log T
σmin(G) such that B(N −a) = Θ(T) and B, u as in
section 4 we get
E
h
Lpred( ˆAa,N; A∗, µ)1

D0,N−1i
≤c2
d Tr(Σ)
T
+ o
 1
T

(84)
H
Proof of Proposition 1
Proof of Proposition 1. First note that

˜At−1,v
b
⊤
˜At−1,v
b

=
t
X
r=1
B−1
X
j=0
f
Dg(t, r, j) +
t
X
r1,r2=1
B−1
X
j1,j2=0
f
Cr(t, r1, j1, r2, j2)
(85)
where
f
Dg(t, r, j) = 4γ2 ηt−r
−j
2 ·
 r−1
Y
s=1
˜Ht−s,⊤
0,B−1
!
˜Ht−r,⊤
j+1,B−1 ˜Xt−r
−j ˜Xt−r,⊤
−j
˜Ht−r
j+1,B−1
 
1
Y
s=r−1
˜Ht−s
0,B−1
!
(86)
f
Cr(t, r1, j1, r2, j2) = 4γ2
 
ηt−r1
−j1 ˜Xt−r1,⊤
−j1
˜Ht−r1
j1+1,B−1
1
Y
s=r1−1
˜Ht−s
0,B−1
!⊤
·
 
ηt−r2
−j2 ˜Xt−r2,⊤
−j2
˜Ht−r2
j2+1,B−1
1
Y
s=r2−1
˜Ht−s
0,B−1
!
(87)
denote the diagonal and cross terms respectively.
We begin by noting the following two facts about

˜At−1,v
b

:
27

• It has zero mean
E
h
˜At−1,v
B
i
= 0
(88)
• Let (r1, j1) ̸= (r2, j2). Then
E
h
f
Cr(t, r1, j1, r2, j2)
i
= 0
(89)
This follows because, assuming r1 > r2, the term ηt−r1
−j1 ˜Xt−r1,⊤
−j1
˜Ht−r1
j1+1,B−1 is independent of
everything else in that expression, and that ηt−r1
−j1 is independent of ˜Xt−r1,⊤
−j1
˜Ht−r1
j1+1,B−1. A similar
argument can be made for the case when r1 = r2 but j1 ̸= j2.
But we are interested in expectation on the event ˜D0,t−1.
We will bound the expectation of cross terms in the following lemma.
Lemma 23. We have

E

X
r1,r2
X
j1,j2
f
Cr(t, r1, j1, r2, j2)

1
h
˜D0,t−1i

≤8(Bt)2γ2R Tr(Σ)
1
T α/2
(90)
Proof. Let
Consider a single cross term: f
Cr(t, r1, j1, r2, j2) and without loss of generality, assume that either
r1 > r2 or r1 = r2 but j1 < j2. In either case, we note that ηt−r1
−j1 is unconditionally independent
of all other terms present in f
Cr(t, r1, j1, r2, j2). The main problem here is to bound the expectation
over the event ˜D0,t−1. For the sake of convenience, only in this proof, we will deﬁne the following
notation:
f
Cr(t, r1, j1, r2, j2) = E1ηt−r1,⊤
−j1
ηt−r2
−j2 E2
Where E1 and E2 are random matrices deﬁned according to the deﬁnition of f
Cr(t, r1, j1, r2, j2)
and are unconditionally independent of ηt−r1,⊤
−j1
. Let FE = σ(E1, E2, ηt−r2
−j2 ). Note that when
conditioned on the event ˜D0,t−1, we must have the event M := {∥E1∥≤4γ2√
R}∩{∥E2∥≤
√
R}
almost surely. Therefore, we conclude:
E
h
f
Cr(t, r1, j1, r2, j2)1
h
˜D0,t−1ii
= E
h
f
Cr(t, r1, j1, r2, j2)1
h
˜D0,t−1i
1 [M]
i
= E

1 [M] E1E

ηt−r1,⊤
−j1
1
h
˜D0,t−1iFE

ηt−r2
−j2 E2

≤E

1 [M] ∥E1∥
E

ηt−r1,⊤
−j1
1
h
˜D0,t−1iFE

ηt−r2
−j2
 ∥E2∥

≤4γ2RE
E

ηt−r1,⊤
−j1
1
h
˜D0,t−1iFE

ηt−r2
−j2


(91)
In the third step, we have used the fact that under the event M, the norms ∥E1∥, ∥E2∥are bounded.
We will now bound E

ηt−r1,⊤
−j1
1
h
˜D0,t−1iFE

. Clearly, due to the unconditional independence, we
must have:
E

ηt−r1,⊤
−j1
FE

= 0
=⇒E

ηt−r1,⊤
−j1
1
h
˜D0,t−1iFE

= −E

ηt−r1,⊤
−j1
1
h
˜D0,t−1,CiFE

=⇒
E

ηt−r1,⊤
−j1
1
h
˜D0,t−1iFE
 ≤
√
Tr Σ
s
P

˜D0,t−1,C
FE

(92)
28

In the last step, we have used Cauchy Schwarz inequality and the fact that ηt−r1,⊤
−j1
is independent of
FE. We combine the Equation above with Equation (91) and apply Jensen’s inequality once again to
conclude:
E
h
f
Cr(t, r1, j1, r2, j2)1
h
˜D0,t−1ii ≤4γ2R Tr(Σ)
r
P
h
˜D0,t−1,C
i
≤4γ2RTr(Σ)
T α/2
(93)
In the last step, we have used Lemma 9 to bound P

˜D0,t−1,C
. Summing over all the indices
(r1, j1, r2, j2), we conclude the statement of the lemma.
Lemma 24. We have:
E


t
X
r=1
B−1
X
j=0
f
Dg(t, r, j)1
h
˜D0,t−1i

⪯4γ2 Tr(Σ)E


t
X
r=1
B−1
X
j=0
 r−1
Y
s=1
˜Ht−s,⊤
0,B−1
!
˜Ht−r,⊤
j+1,B−1 ˜Xt−r
−j ·
˜Xt−r,⊤
−j
˜Ht−r
j+1,B−1
 
1
Y
s=r−1
˜Ht−s
0,B−1
!
1
h
˜D0,t−1i#
+ δDgI
(94)
and
E


t
X
r=1
B−1
X
j=0
f
Dg(t, r, j)1
h
˜D0,t−1i

⪰4γ2 Tr(Σ)E


t
X
r=1
B−1
X
j=0
 r−1
Y
s=1
˜Ht−s,⊤
0,B−1
!
˜Ht−r,⊤
j+1,B−1 ˜Xt−r
−j ·
˜Xt−r,⊤
−j
˜Ht−r
j+1,B−1
 
1
Y
s=r−1
˜Ht−s
0,B−1
!
1
h
˜D0,t−1i#
−δDgI
(95)
where
δDg ≡δDg(T, Σ, R, µ4) = 4γ2(Bt)R√µ4
1
T α/2
(96)
Proof. The evaluation of expectations is clear when there is no indicator 1
h
˜D0,t−1i
within the
expectation. We will now deal with it just like in the proof of Lemma 23. Consider f
Dg(t, r, j). For
the sake of convenience, only in this proof, we will use the following notation:
f
Dg(t, r, j) = 4γ2 ηt−r
−j
2 E .
Where the random PSD matrix E is unconditionally independent of ηt−r
−j . Let M = {∥E∥≤R}.
Conditioned on the event ˜D0,t−1, the event M holds almost surely. Let FE = σ(E).
Now consider:
E
h
f
Dg(t, r, j)1
h
˜D0,t−1ii
= E
h
f
Dg(t, r, j)1
h
˜D0,t−1i
1 [M]
i
= 4γ2E
hηt−r
−j
2 E1
h
˜D0,t−1i
1 [M]
i
= 4γ2E
h
E
hηt−r
−j
2 1
h
˜D0,t−1i
|FE
i
E1 [M]
i
(97)
It can be easily shown via similar techniques used in Lemma 23 that:
Tr(Σ) −√µ4
r
P

˜D0,t−1,CFE

≤E
hηt−r
−j
2 1
h
˜D0,t−1i
|FE
i
≤Tr(Σ)
Using this in Equation (97), we conclude:
29

E
h
f
Dg(t, r, j)1
h
˜D0,t−1ii
⪯4γ2 Tr(Σ)E [E1 [M]]
= 4γ2 Tr(Σ)E
h
E1 [M] 1
h
˜D0,t−1i
+ E1 [M] 1
h
˜D0,t−1,Cii
= 4γ2 Tr(Σ)E
h
E1
h
˜D0,t−1i
+ E1 [M] 1
h
˜D0,t−1,Cii
⪯4γ2 Tr ΣE
h
E1
h
ˆD0,t−1ii
+ 4γ2 Tr(Σ)R I
T α
(98)
In the third step, we have used the fact that ˜D0,t−1 ⊆M. In the last step we have used the fact that
E is PSD and over the event M, E ⪯RI. We have used Lemma 9 to bound P( ˜D0,t−1,C). Using a
similar technique as above, we can show that:
E
h
f
Dg(t, r, j)1
h
˜D0,t−1ii
⪰4γ2 Tr ΣE
h
E1
h
˜D0,t−1ii
−4γ2
√µ4R
T α/2 I
(99)
Note that
√µ4R
T α/2 ≥Tr(Σ)R
T α
. Summing over r, j and combining Equations (99) and (98), we conclude
the result.
For convenience, deﬁne Ks := PB−1
j=0 ˜Hs,⊤
j+1,B−1 ˜Xs
−j ˜Xs,⊤
−j ˜Hs
j+1,B−1
Claim 1. Suppose γ < 1
R. Under the event ˜D0,t−1, for every s ≤t −1 we must have:
I −˜Hs,⊤
0,B−1 ˜Hs
0,B−1
4γ
⪯Ks ⪯
I −˜Hs,⊤
0,B−1 ˜Hs
0,B−1
ˆγ
Where ˆγ = 4γ(1 −γR)
Proof. In the entire proof, we suppose that the event ˜D0,t−1 holds. Consider:
˜Hs,⊤
j,B−1 ˜Hs
j,B−1 + 4γ ˜Hs,⊤
j+1,B−1 ˜Xs
−j ˜Xs,⊤
−j ˜Hs
j+1,B−1
= ˜Hs,⊤
j+1,B−1

I −

4γ −4γ2∥˜Xs
−j∥2
˜Xs
−j ˜Xs,⊤
−j

˜Hs
j+1,B−1 + 4γ ˜Hs,⊤
j+1,B−1 ˜Xs
−j ˜Xs,⊤
−j ˜Hs
j+1,B−1
= ˜Hs,⊤
j+1,B−1

I + 4γ2∥˜Xs
−j∥2 ˜Xs
−j ˜Xs,⊤
−j

˜Hs
j+1,B−1
⪰˜Hs,⊤
j+1,B−1 ˜Hs
j+1,B−1
(100)
Using the recursion in Equation (100), we show that:
˜Hs,⊤
0,B−1 ˜Hs
0,B−1 + 4γKs ⪰I .
This establishes the lower bound. To establish the upper bound, we consider
˜Hs,⊤
j,B−1 ˜Hs
j,B−1 + ˆγ ˜Hs,⊤
j+1,B−1 ˜Xs
−j ˜Xs,⊤
−j ˜Hs
j+1,B−1 .
Following similar technique used to establish Equation (100), using the fact that under the event
˜D0,t−1 we have ∥˜Xs
−j∥2 ≤R we show that:
˜Hs,⊤
j,B−1 ˜Hs
j,B−1 + ˆγ ˜Hs,⊤
j+1,B−1 ˜Xs
−j ˜Xs,⊤
−j ˜Hs
j+1,B−1 ⪯˜Hs,⊤
j+1,B−1 ˜Hs
j+1,B−1 .
Using a similar recursion as before, we establish that:
˜Hs,⊤
0,B−1 ˜Hs
0,B−1 + ˆγKs ⪯I .
30

We are now ready to bound the ﬁrst term in (94):
E
"
t
X
r=1
 r−1
Y
s=1
˜Ht−s,⊤
0,B−1
!
Kt−r
 
1
Y
s=r−1
˜Ht−s
0,B−1
!
1
h
˜D0,t−1i#
(101)
It is easy to show via. telescoping sum argument that:
t
X
r=1
 r−1
Y
s=1
˜Ht−s,⊤
0,B−1
! 
I −˜Ht−r,⊤
0,B−1 ˜Ht−r
0,B−1
  
1
Y
s=r−1
˜Ht−s
0,B−1
!
= I−
 tY
s=1
˜Ht−s,⊤
0,B−1
!  1
Y
s=t
˜Ht−s
0,B−1
!
(102)
We then use Claim 1 to show that under the event ˜D0,t−1, we must have:
I −
Qt
s=1 ˜Ht−s,⊤
0,B−1
 Q1
s=t ˜Ht−s
0,B−1

4γ
⪯
t
X
r=1
 r−1
Y
s=1
˜Ht−s,⊤
0,B−1
!
Kt−r
 
1
Y
s=r−1
˜Ht−s
0,B−1
!
(103)
And:
t
X
r=1
 r−1
Y
s=1
˜Ht−s,⊤
0,B−1
!
Kt−r
 
1
Y
s=r−1
˜Ht−s
0,B−1
!
⪯
I −
Qt
s=1 ˜Ht−s,⊤
0,B−1
 Q1
s=t ˜Ht−s
0,B−1

ˆγ
(104)
Finally, combining Lemma 23, Lemma 24, claim 1, Equations (103), (104) and the bound on µ4
(stated after assumption 3 in section 2) along with ˆγ = 4γ(1 −γR) we get the statement of the
proposition.
I
Proof of Proposition 2
Before delving into the proof, we note some useful results below.
Lemma 25. For any random matrix B ∈Rd×d we have that
E

B⊤
E [B] ⪯E

B⊤B

(105)
Hence
∥E [B]∥≤
q
∥E [B⊤B]∥
(106)
Proof. Note that for any vector x ∈Rd we have
x⊤E

B⊤
E [B] x = ∥E [Bx]∥2 ≤E
h
∥Bx∥2i
= x⊤E

B⊤B

x
(107)
Lemma 26. Let γRB ≤
c
6 for 0 < c < 1. The there are constants c1, c2 > 0 such that for
T α/2 > c1
√M4
σmin(G) we have
∥H∥≤
p
1 −c2γBσmin(G) ≤1 −c2
2 γBσmin(G)
(108)
with 1 −c2γBσmin(G) > 0.
Proof. Note that H can be written as H = E
h
˜H0
0,B−11[ ˜D0
−0]
i
. First we use Lemma 25 to get
∥H∥≤
rE
h
˜H0,⊤
0,B−1 ˜H0
0,B−11[ ˜D0
−0]
i
(109)
31

Then, from Lemma 29 we can show that there are constants c1, c2 > 0 such that
E
h
˜H0,⊤
0,B−1 ˜H0
0,B−11[ ˜D0
−0]
i ≤

1 −c1γBσmin(G) + c2γB
p
M4
1
T α/2

(110)
Now choosing T such that T α/2 >
c2
√M4
2c1σmin(G) we get
E
h
˜H0,⊤
0,B−1 ˜H0
0,B−11[ ˜D0
−0]
i ≤(1 −c3γBσmin(G))
(111)
where c3 is such that the RHS in (111) is positive. Hence the claim follows.
Proof of Proposition 2. We will prove the proposition only for a = 0. The arguments for general a
are exactly the same.
For simplicity, we denote
ˆ˜Av
N ≡
 ˆ˜Av
0,N

(112)
From recursion (6) we have the following relation between

˜At2−1,v
B

and

˜At1−1,v
B

for t2 > t1

˜At2−1,v
B

=

˜At1−1,v
B
  
1
Y
s=t2−t1
˜Ht2−s
0,B−1
!
+
2γ
t2−t1
X
r=1
B−1
X
j=0
ηt2−r
−j
˜Xt2−r,⊤
−j
˜Ht2−r
j+1,B−1
 
1
Y
s=r−1
˜Ht2−s
0,B−1
!
.
(113)
Hence we have

˜At1−1,v
B
⊤
˜At2−1,v
B

=

˜At1−1,v
B
⊤
˜At1−1,v
B
  
1
Y
s=t2−t1
˜Ht2−s
0,B−1
!
+
2γ

˜At1−1,v
B
⊤t2−t1
X
r=1
B−1
X
j=0
ηt2−r
−j
˜Xt2−r,⊤
−j
˜Ht2−r
j+1,B−1
 
1
Y
s=r−1
˜Ht2−s
0,B−1
!
.
(114)
The second term in (114) is bounded in claim 2
The ﬁrst term in (114) can be analyzed using independence as follows.
E
"
˜At1−1,v
B
⊤
˜At1−1,v
B

1
h
˜D0,t1−1i  
1
Y
s=t2−t1
˜Ht2−s
0,B−1
!
1
h
˜Dt1,N−1i#
= ˜Vt1−1E
" 
1
Y
s=t2−t1
˜Ht2−s
0,B−1
!
1
h
˜Dt1,N−1i#
= ˜Vt1−1E
" 
1
Y
s=t2−t1
˜Ht2−s
0,B−1
!
1
h
˜Dt1,t2−1i#
E
h
1
h
˜Dt2,N−1ii
= ˜Vt1−1
 
1
Y
s=t2−t1
E
h
˜Ht2−s
0,B−11
h
˜Dt1,t2−1ii!
E
h
1
h
˜Dt2,N−1ii
= ˜Vt1−1Ht2−t1E
h
1
h
˜Dt2,N−1ii
= ˜Vt1−1Ht2−t1 −˜Vt1−1Ht2−t1E
h
1
h
˜Dt2,N−1,Cii
.
(115)
Note that,

˜At1−1,v
B
⊤
˜At1−1,v
B

⪯4γ2(Bt1)
t1
X
r=1
B−1
X
j=0
ηt1−r
−j
2 ·
 r−1
Y
s=1
˜Ht1−s,⊤
0,B−1
!
˜Ht1−r,⊤
j+1,B−1 ˜
Xt1−r
−j
˜
Xt1−r,⊤
−j
˜Ht1−r
j+1,B−1
 
1
Y
s=r−1
˜Ht1−s
0,B−1
!
.
(116)
32

From equation (116), we have:
 ˜Vt1−1
 ≤cγ2(Bt1)2Rdσmax,
(117)
and further, ∥H∥< 1 from Lemma 26. Hence,
 ˜Vt1−1Ht2−t1E
h
1
h
˜Dt2,N−1,Cii ≤
 ˜Vt1−1Ht2−t1
 1
T α ≤cγ2(Bt1)2Rdσmax
1
T α .
For brevity, given a matrix Q ∈Rd×d, let,
Sym (Q) = Q + Q⊤.
(118)
Combining everything so far, we have, for t2 > t1:
Sym

E

˜At1−1,v
B
⊤
˜At2−1,v
B

1
h
˜D0,N−1i
⪯Sym

˜Vt1−1Ht2−t1
+ c1γ2(Bt1)2Rdσmax 1
T α I +

c3γ2B2t1t2Rdσmax
1
T α/2

I
(119)
Since Bt2 ≤T we get:
Sym

E

˜At1−1,v
B
⊤
˜At2−1,v
B

1
h
˜D0,N−1i
⪯Sym

˜Vt1−1Ht2−t1
+
c3γ2T 2Rdσmax
1
T α/2 I.
(120)
Therefore we have,
1
N 2
X
t1̸=t2
E

˜At1−1,v
B
⊤
˜At2−1,v
B

⪯
1
N 2
N−1
X
t1=1
Sym
 
˜Vt1−1
 X
t2>t1
Ht2−t1
!!
+c3γ2T 2Rdσmax
1
T α/2 I.
Next observe that,
1
N 2
N
X
t=1
˜Vt−1 + 1
N 2
N−1
X
t1=1
Sym
 
˜Vt1−1
 X
t2>t1
Ht2−t1
!!
=
1
N 2
N
X
t=1
˜Vt−1 + 1
N 2
N−1
X
t1=1
Sym
 
˜Vt1−1
 N−t1
X
s=1
Hs
!!
⪯
1
N 2
N
X
t=1
Sym
 
˜Vt−1
 N−t
X
s=0
Hs
!!
.
Hence, substituting in (40), we obtain:
E

ˆAv
N
⊤
ˆAv
N

1
h
˜D0,N−1i
⪯
1
N 2
N
X
t=1
Sym
 
˜Vt−1
 N−t
X
s=0
Hs
!!
+
(121)
c3γ2T 2Rdσmax
1
T α/2 I.
(122)
From Equations (121)-(122) we obtain (41).
Now PN−t
s=0 Hs = (I −H)−1(I −HN−t+1) since from Lemma 26 we know that ∥H∥< 1 for large
T. Thus we get (42).
33

I.1
Claims
Claim 2. For γ ≤
1
2R we have

E

2γ

˜At1−1,v
B
⊤t2−t1
X
r=1
B−1
X
j=0
ηt2−r
−j
˜Xt2−r,⊤
−j
˜Ht2−r
j+1,B−1
 
1
Y
s=r−1
˜Ht2−s
0,B−1
!
1
h
˜D0,N−1i

≤c1γ2B2t1t2Rdσmax
1
T α/2
(123)
for some constant c1 > 0.
Proof. The proof is similar to the proof of Lemma 23.
J
Proof of Theorem 14
Proof of Theorem 14. We start with the following

˜At−1,b
b
−A∗⊤
˜At−1,b
b
−A∗
=
 tY
s=1
˜Ht−s,⊤
0,B−1
!
(A0 −A∗)⊤(A0 −A)
 1
Y
s=t
˜Ht−s
0,B−1
!
⪯∥A0 −A∗∥2
 tY
s=1
˜Ht−s,⊤
0,B−1
!  1
Y
s=t
˜Ht−s
0,B−1
!
(124)
From Lemma 29 we can show that there are constants c1, c2 > 0 such that
E
" tY
s=1
˜Ht−s,⊤
0,B−1
!  1
Y
s=t
˜Ht−s
0,B−1
!
1
h
˜D0,t−1i#
≤

1 −c1γBσmin(G) + c2γB
p
M4
1
T α/2
t
.
(125)
Now choosing T such that T α/2 >
c2
√M4
2c1σmin(G) we get,
E
" tY
s=1
ˆHt−s,⊤
0,B−1
!  1
Y
s=t
ˆHt−s
0,B−1
!# ≤(1 −c3γBσmin(G))t .
(126)
Thus we get the theorem.
K
Proof of Theorem 15
Proof of Theorem 15. We use the following inequality that is obtained from Lemma 25
 ˆ˜Ab
a,N −A∗⊤ ˆ˜Ab
a,N −A∗
⪯
1
N −a
N
X
t=a+1

˜At−1,b
B
−A∗⊤
˜At−1,b
B
−A∗
(127)
Therefore
E
 ˆ˜Ab
a,N −A∗⊤ ˆ˜Ab
a,N −A∗
1
h
˜D0,N−1i
⪯
1
N −a
N
X
t=a+1
E

˜At−1,b
B
−A∗⊤
˜At−1,b
B
−A∗
1
h
˜D0,N−1i
⪯
1
N −a
N
X
t=a+1
E

˜At−1,b
B
−A∗⊤
˜At−1,b
B
−A∗
1
h
˜D0,t−1i
(128)
34

Now using theorem 14, we get
E
 ˆ˜Ab
a,N −A∗⊤ ˆ˜Ab
a,N −A∗
1
h
˜D0,N−1i
⪯
 
1
N −a
(1 −c1γBσmin(G))a+1
c1γBσmin(G)
!
∥A0 −A∗∥2 I
(129)
Hence using 1 −x ≤e−x we get
E
 ˆ˜Ab
a,N −A∗⊤ ˆ˜Ab
a,N −A∗
1
h
˜D0,N−1i
≤c
1
B(N −a)
e−cBγσmin(G)a
γσmin(G)
∥A0 −A∗∥2
(130)
L
Operator Norm Inequalities
In this section, we develop the concentration inequalities necessary to obtain bounds on Lop. Consider
Equation (20)

˜At−1,v
B

= 2γ
t
X
r=1
B−1
X
j=0
ηt−r
−j ˜Xt−r,⊤
−j
˜Ht−r
j+1,B−1
1
Y
s=r−1
˜Ht−s
0,B−1
(131)
Splitting the sum into r = 1 and r = 2, . . . , t, it is easy to show the following recursion:

˜At−1,v
B

= 2γ
B−1
X
j=0
ηt−1
−j ˜Xt−1,⊤
−j
˜Ht−1
j+1,B−1 +

˜At−2,v
B

˜Ht−1
0,B−1
(132)
We will consider the matrix ∆t−1 := 2γ PB−1
j=0 ηt−1
−j ˜Xt−1,⊤
−j
˜Ht−1
j+1,B−1. Recall the sequence of
events ˜Dt−1
−j for j = 0, 1, . . . , B −1 as deﬁned in Section B.1. We will pick R as in Section 4 so that
P( ˜Dt−1
−0 ) is close to 1.
For the sake of clarity, we drop the dependence on t while stating and proving some of the technical
results since the events and random variables considered there are identically distributed for every t.
That is, consider ˜D−j instead of ˜Dt−1
−j and
∆:= 2γ
B−1
X
j=0
η−j ˜X⊤
−j ˜Hj+1,B−1
We will bound the exponential moment generating function of ∆:
Lemma 27. Suppose Assumption 2 holds and that γR < 1. Let λ ∈R and x, y ∈Rd are arbitrary.
Then, we have:
1.
E
h
exp(γλ2Cµ⟨x, Σx⟩⟨y, ˜H⊤
0,B−1 ˜H0,B−1y⟩+ λ⟨x, ∆y⟩)| ˜D−0
i
≤exp
 γλ2Cµ⟨x, Σx⟩∥y∥2
P( ˜D−0)
2.
E
h
exp(λ⟨x, ∆y⟩)| ˜D−0
i
≤exp
 γλ2Cµ⟨x, Σx⟩∥y∥2
P( ˜D−0)
Where Cµ is as given in Assumption 2
35

Proof. We will just prove item 1 since item 2 follows from it trivially as
γλ2Cµ⟨x, Σx⟩⟨y, ˜H⊤
0,B−1 ˜H0,B−1y⟩≥0 .
For the sake of clarity, we will take:
Ξ0 := γλ2Cµ⟨x, Σx⟩⟨y, ˜H⊤
0,B−1 ˜H0,B−1y⟩
and more generally,
Ξk = γλ2Cµ⟨x, Σx⟩⟨y, ˜H⊤
k,B−1 ˜Hk,B−1y⟩
Consider ∆−k := 2γ PB−1
j=k η−j ˜X⊤
−j ˜Hj+1,B−1. We will ﬁrst prove the following claim before
bounding the exponential moment:
Claim 3. Whenever ∥˜X−k∥2 ≤R and γR < 1/2, we have:
Ξk + 2γ2λ2Cµ⟨x, Σx⟩⟨y, ˜H⊤
k+1,B−1 ˜X−k ˜X⊤
−k ˜Hk+1,B−1y⟩≤Ξk+1
Proof. We use the fact that ˜H⊤
k,B−1 ˜Hk,B−1 = ˜H⊤
k+1,B−1(I −2γ ˜X−k ˜X⊤
−k)2 ˜Hk+1,B−1 to conclude
that:
Ξk + 2γ2λ2Cµ⟨x, Σx⟩⟨y, ˜H⊤
k+1,B−1 ˜X−k ˜X⊤
−k ˜Hk+1,B−1y⟩
= γλ2Cµ⟨x, Σx⟩⟨y, ˜H⊤
k+1,B−1

I −2γ ˜X−k ˜X⊤
−k + 4γ2∥˜X−k∥2 ˜X−k ˜X⊤
−k

˜Hk+1,B−1y⟩
≤γλ2Cµ⟨x, Σx⟩⟨y, ˜H⊤
k+1,B−1 ˜Hk+1,B−1y⟩= Ξk+1
(133)
In the second step we have used the fact that when γ∥˜X−k∥2 ≤1/2, we have that
I −2γ ˜X−k ˜X⊤
−k + 4γ2∥˜X−k∥2 ˜X−k ˜X⊤
−k ⪯I
First note that ∆= 2γη0 ˜X⊤
0 ˜H1,B−1 + ∆−1. Now,
E
h
exp(Ξ0 + λ⟨x, ∆y⟩)| ˜D−0
i
=
1
P( ˜D−0)
E
h
exp(Ξ0 + λ⟨x, ∆y⟩)1

˜D−0
i
=
1
P( ˜D−0)
E
h
exp

Ξ0 + 2λγ⟨x, η−0⟩⟨˜X−0, ˜H1,B−1y⟩+ λ⟨x, ∆−1y⟩

1

˜D−0
i
≤
1
P( ˜D−0)
E
h
exp

Ξ0 + 2γ2λ2Cµ⟨x, Σx⟩⟨y, ˜H⊤
1,B−1 ˜X−0 ˜X⊤
−0 ˜H1,B−1y⟩+ λ⟨x, ∆−1y⟩

1

˜D−0
i
≤
1
P( ˜D−0)
E
h
exp (Ξ1 + λ⟨x, ∆−1y⟩) 1

˜D−0
i
≤
1
P( ˜D−0)
E
h
exp (Ξ1 + λ⟨x, ∆−1y⟩) 1

˜D−1
i
(134)
In the ﬁrst step we have used the deﬁnition of conditional expectation, in the third step we have
used the fact that η−0 is independent of ˜D−0, ∆−1, ˜X⊤
−0 ˜H1,B−1, and ∆−1 and have applied the sub-
Gaussianity from Assumption 2. In the fourth step, using the fact under the event ˜D−0, ∥˜X−0∥2 ≤R
we have applied Claim 3. In the ﬁnal step, we have used the fact that ˜D−0 ⊆˜D−1. We proceed by
induction over Equation (134) to conclude the result.
We now consider the matrix ˜H0,B−1 under the event ˜D−0.
Lemma 28. Suppose that γRB < 1
6. Then, under the event ˜D−0, we have:
I −4γ

1 +
2γBR
1−4γBR
 B−1
X
i=0
˜X−i ˜X⊤
−i ⪯˜H⊤
0,B−1 ˜H0,B−1 ⪯I −4γ

1 −
2γBR
1−4γBR
 B−1
X
i=0
˜X−i ˜X⊤
−i
36

Proof. By deﬁnition, we have: ˜H0,B−1 = QB−1
j=0 (I −2γ ˜X−j ˜X⊤
−j). Expanding out the product, we
get an expression of the form:
˜H⊤
0,B−1 ˜H0,B−1 = I −4γ
B−1
X
i=0
˜X−i ˜X⊤
−i + (2γ)2 X
i,j
˜X−i ˜X⊤
−i ˜X−j ˜X⊤
−j + . . .
(135)
Here, the summation P
i,j is over all possible combinations possible when the product is expanded
and . . . denotes higher order terms of the form ˜X−i1 ˜X⊤
−i1 . . . ˜X−ik ˜X⊤
−ik
Claim 4. Assume k ≥2 and i1, . . . , ik ∈{0, . . . , B −1}. Under the event ˜D−0, for any x ∈Rd,
we have: x⊤˜X−i1 ˜X⊤
−i1 . . . ˜X−ik ˜X⊤
−ikx
 ≤Rk−1
2
h
x⊤˜X−i1 ˜X⊤
−i1x + x⊤˜X−ik ˜X⊤
−ikx
i
Proof. This follows from an application of AM-GM inequality. It is clear by Cauchy-Schwarz
inequality that |⟨˜Xil, ˜Xil+1⟩| ≤R, which implies:
x⊤˜X−i1 ˜X⊤
−i1 . . . ˜X−ik ˜X⊤
−ikx
 ≤Rk−1

h
x⊤˜X−i1 ˜X⊤
−ikx
i ≤Rk−1
2
h
⟨x, ˜X−i1⟩2 + ⟨˜X−ik, x⟩2i
.
Where the last inequality follows from an application of the AM-GM inequality.
From Claim 4, we conclude that:
X
i1,...,ik
˜X−i1 ˜X⊤
−i1 . . . ˜X−ik ˜X⊤
−ik ⪯(2B)k−1Rk−1
B−1
X
i=0
˜X−i ˜X⊤
−i
Plugging this into Equation (135), we have that under the event ˜D−0:
˜H⊤
0,B−1 ˜H0,B−1 ⪯I −4γ
B−1
X
i=0
B−1
X
i=0
˜X−i ˜X⊤
−i +
2B
X
k=2
(2γ)k(2B)k−1Rk−1
B−1
X
i=0
˜X−i ˜X⊤
−i
⪯I −4γ
B−1
X
i=0
B−1
X
i=0
˜X−i ˜X⊤
−i + 2γ
4γBR
1 −4γBR
B−1
X
i=0
B−1
X
i=0
˜X−i ˜X⊤
−i
(136)
Here we have used the fact that 4γBR < 1 to convert the ﬁnite sum to an inﬁnite sum. Using the
bound on γ, we conclude the upper bound. The lower bound follows with a similar proof.
Lemma 29. Suppose γBR < 1
6. Let G := E ˜X−i ˜X⊤
−i and M4 := E
 ˜X−i
4. Then, we have:
E
h
˜H⊤
0,B−1 ˜H0,B−1
 ˜D−0
i
⪯I −
4γB
P( ˜D−0)

1 −
2γBR
1−4γBR

G +
4γB
q
M4(1 −P( ˜D−0))
P( ˜D−0)

1 −
2γBR
1−4γBR

I
Proof. The result follows from the statement of Lemma 28, once we show the following inequality
via Cauchy Schwarz inequality and the deﬁnition of conditional expectation:
E
h
˜X−i ˜X⊤
−i
 ˜D−0
i
⪰
G
P( ˜D−0)
−I
q
E
 ˜X−i
4q
1 −P( ˜D−0)
P( ˜D−0)
.
37

Now we will show that ˜H0,B−1 contracts any given vector with probability at-least p0 > 0. For this
we will refer to lemma 8 where it is shown that if X ∼π then ⟨X, x⟩has mean 0 and is sub-Gaussian
with variance proxy Cµx⊤Gx. Using this will show that the matrix ˜H0,B−1 operating on a given
vector x contracts it with a high enough probability.
Lemma 30. Suppose γRB < 1
8 and that µ obeys Assumption 2. There exists a constant c0 > 0
which depends only on Cµ such that whenever 1 −P( ˜D−0) ≤c0, then for any arbitrary x ∈R2
P

∥˜H0,B−1x∥2 ≥∥x∥2 −Bγx⊤Gx
 ˜D−0

≤1 −p0 < 1 .
Where p0 > 0 depends only on Cµ.
Proof. Initially we do not condition on ˜D−0. Consider the quantity: Y := PB−1
i=0 ⟨x, ˜X−i⟩2.
Claim 5.
P
 Y ≥1/2Bx⊤Gx

≥q0
where q0 > 0 depends only on sub-Gaussianity parameter Cµ
Proof. We consider the Payley-Zygmund inequality which states that for any positive random variable
Y with a ﬁnite second moment, we have:
P
 Y > 1
2EY

≥1
4
(EY )2
EY 2 .
Note that EY = Bx⊤Gx. The statement of the lemma follows once we lower bound the quantity
(EY )2
EY 2 . Clearly, (EY )2 = B2x⊤Gx. Now,
EY 2 =
X
i,j
E⟨x, Xi⟩2⟨x, Xj⟩2 ≤
X
i,j
p
E⟨x, Xi⟩4
q
E⟨x, Xj⟩2 = B2E⟨x, Xi⟩4
≤B2c1C2
µ(x⊤Gx)2
(137)
Here, the second step follows from Cauchy-Schwarz inequality. The third step follows from the fact
that Xi are all identically distributed. The fourth step follows from Lemma 8 and Theorem 2.1 from
[51]. The statement of the claim follows once we apply Payley-Zygmund inequality.
Now, by deﬁnition of conditional probabililty and Claim 5, we have:
P
 B−1
X
i=0
⟨x, ˜X−i⟩2 ≤B
2 xT Gx
 ˜D−0
!
≤(1 −q0)
P( ˜D−0)
Now the statement of the lemma follows from an application of Lemma 28
Now we want to bound the operator norm of Qa+b
s=a ˜Hs
0,B−1 with high probability under the event
∩a+b
s=a ˜Ds
−0.
Lemma 31. Suppose the conditions in Lemma 30 hold. Let σmin(G) denote the smallest eigenvalue
of G. We also assume that P( ˜Da,b) > 1/2. Conditioned on the event ˜Da,b,
1. ∥Qb
s=a ˜Hs
0,B−1∥≤1 almost surely
2. Whenever b −a + 1 is larger than some constant which depends only on Cµ, we have:
P
 
∥
b
Y
s=a
˜Hs
0,B−1∥≥2(1 −γBσmin(G))c4(b−a+1)
 ˜Da,b
!
≤exp(−c3(b −a + 1) + c5d)
Where c3, c4 and c5 are constants which depend only on Cµ
Proof.
38

1. The proof follows from an application of Lemma 28.
2. We will prove this with an ϵ net argument over the sphere in Rd dimensions.
Suppose we have arbitrary x ∈Rd such that ∥x∥= 1. Conditioned on the event ˜Da,b, the ma-
trices ˜Hs
0,B−1 are all independent for a ≤s ≤b. We also note that ˜Hs
0,B−1 is independent
of ˜Dt for t ̸= s. Let Kv := Qb
s=v ˜Hs
0,B−1. When v ≥b+1, we take this product to be iden-
tity. Consider the set of events Gv := {∥˜Hv
0,B−1Kv+1x∥2 ≤∥Kv+1x∥2(1 −γBσmin(G)}.
From Lemma 30, we have that whenever v ∈(a, b):
P(Gc
v| ˜Dv, ˜Hs
0,B−1 : s ̸= v) ≤1 −p0
(138)
Where p0 is given in Lemma 30
Let D ⊆{a, . . . , b} such that |D| = r. It is also clear from item 1 and the deﬁnitions above
that whenever the event ∩v∈DGv holds, we have:
∥
b
Y
s=a
˜Hs
0,B−1x∥≤(1 −γBσmin(G))
r
2 .
(139)
Therefore, whenever Equation (139) is violated, we must have a set Dc ⊆{a, . . . , b} such
that |Dc| ≥b −a −r and the event ∩v∈DcGc
v holds. We will union bound all such events
indexed by Dc to obtain an upper bound on the probability that Equation (139) is violated.
Therefore, using Equation (138) along with the union bound, we have:
P
 
∥
b
Y
s=a
˜Hs
0,B−1x∥≥(1 −γBσmin(G))
r
2
 ˜Da,b
!
≤
b −a + 1
b −a −r

(1 −p0)b−a−r
Whenever b −a + 1 is larger than some constant depending only on Cµ, we can pick
r = c2(b −a + 1) for some constant c2 > 0 small enough such that:
P
 
∥
b
Y
s=a
˜Hs
0,B−1x∥≥(1 −γBσmin(G))
r
2
 ˜Da,b
!
≤exp(−c3(b −a + 1))
Now, let N be a 1/2-net of the sphere Sd−1. Using Corollary 4.2.13 in [52], we can choose
|N| ≤6d. By Lemma 4.4.1 in [52] we show that:
∥
b
Y
s=a
˜Hs
0,B−1∥≤2 sup
x∈N
∥
b
Y
s=a
˜Hs
0,B−1x∥
(140)
By union bounding Equation (140) for every x ∈N, we conclude that:
P
 
∥
b
Y
s=a
˜Hs
0,B−1∥≥2(1 −γBσmin(G))c4(b−a+1)
 ˜Da,b
!
≤|N| exp(−c3(b −a + 1))
= exp(−c3(b −a + 1) + c5d)
(141)
Now we will give a high probability bound for the following operator:
Fa, N :=
N−1
X
r=a
r
Y
s=a+1
˜Hs
0,B−1
(142)
Here, we use the convention that Qa
s=a+1 ˜Hs
0,B−1 = I
Lemma 32. Suppose c4γBσmin(G) < 1
4 for the constant c4 as given in Lemma 31. Suppose all the
conditions given in the statement of Lemma 31 hold. Then, for any δ ∈(0, 1), we have:
P

∥Fa,N∥≥C

d + log N
δ +
1
γBσmin(G)
 ˜Da,N−1

≤δ
Where C is a constant which depends only on Cµ
39

Proof. We consider the triangle inequality: ∥Fa,N∥≤PN−1
t=a
Qt
s=a+1 ˜Hs
0,B−1
. By Lemma 31,
we have that whenever t −a ≥c5d
c3 + log N
δ
c3 :
P
 
∥
tY
s=a+1
˜Hs
0,B−1∥≥2(1 −γBσmin(G))c4(t−a)
 ˜Da,N−1
!
≤δ
N
Using union bound, we show that when conditioned on ˜Da,N−1, with probability at least 1 −δ the
following holds:
1. For all a ≤t ≤N −1 such that t −a ≥c5d
c3 + log N
δ
c3 :
∥
N
Y
s=t
˜Hs
0,B−1∥≤2(1 −γBσmin(G))c4(t−a)
2. For all t such that t −a < c5d
c3 + log N
δ
c3 , we have: ∥QN
s=t ˜Hs
0,B−1∥≤1. For this, we use
the almost sure bound given in item 1 of Lemma 31
Therefore, when conditioned on ˜Da,N−1, with probability at least 1 −δ we have:
∥Fa,N∥≤C(d + log N
δ ) + 2
∞
X
j=0
(1 −γBσmin(G))c4j
≤C(d + log N
δ ) + 2
∞
X
j=0
exp(−c4jγBσmin(G))
≤C(d + log N
δ ) +
2
1 −exp(−c4γBσmin(G))
≤C(d + log N
δ ) +
2
c4γBσmin(G) −c2
4γ2Bσmin(G)
2
≤C

d + log N
δ +
1
γBσmin(G)

(143)
In the ﬁrst step, we have used the event described above to bound the operator norm via. the inﬁnite
geometric series. In the second step, we have used the inequality (1 −x)a ≤exp(−ax) whenever
x ∈[0, 1] and a > 0. In the fourth step, we have used the inequality exp(−x) ≤1−x+ x2
2 whenever
x ∈[0, 1]. In the last step, we have absorbed constants into a single constant C
We will now consider the averaged iterate of the coupled process as deﬁned in Equation (21) with
a = 0.
ˆ˜Av
0,N := 1
N
N
X
t=1

˜At−1,v
B

(144)
We recall the deﬁnition of ∆t−1 from the beginning of the Section L and the recursion shown in
Equation (132). We combine these with Equation (144) to show:
ˆ˜Av
0,N = 1
N
N
X
t=1
∆t−1Ft−1,N
(145)
Where Fa,N is as deﬁned in Equation (142). Using the results in Lemma 27 and a similar proof tech-
nique we show the following theorem. We deﬁne the following event as considered in Lemma (32):
˜
Mt−1 :=

∥Ft−1,N∥≤C

d + log N
δ +
1
γBσmin(G)

Deﬁne the event ˜
M0,N−1 = ∩N−1
t=0
˜
Mt and recall the deﬁnition of the event ˜D0,N−1.
40

Theorem 33. We suppose that the conditions in Lemmas 27, 32 and 28 hold. We also assume that
P( ˜
M0,N−1 ∩˜D0,N−1) ≥1
2. Deﬁne α := C(d+log N
δ +
1
γBσmin(G)) as in the deﬁnition of the event
˜
Mt
P

∥ˆ˜Av
0,N∥> β
 ˜
M0,N−1 ∩˜D0,N−1

≤exp

c1d −
β2N
16γCµσmax(Σ)(1 + 2α)

.
Proof. Recall the events ˜Dt,N−1 and deﬁne ˜
Mt,N−1 := ∩N−1
s=t
˜
Mt. We recall that ∆t−1 is indepen-
dent of Ft−1,N and ˜Dt,N−1. Now consider arbitrary x, y ∈Rd such that ∥x∥= ∥y∥= 1. Deﬁne
Γt−1,N−1 := 1
N
PN
s=t ∆s−1Fs−1,N. For any λ > 0, consider the following exponential moment:
E

exp

λ⟨x, ( ˆ˜Av
0,N)y⟩
 ˜
M0,N−1 ∩˜D0,N−1

=
E
h
exp

λ⟨x, ( ˆ˜Av
0,N)y⟩

1

˜
M0,N−1 ∩˜D0,N−1i
P

˜
M0,N−1 ∩˜D0,N−1

=
E
h
exp
  λ
N ⟨x, ∆0F0,Ny⟩+ λ⟨x, Γ1,N−1y⟩

1

˜
M0,N−1 ∩˜D0,N−1i
P

˜
M0,N−1 ∩˜D0,N−1

(146)
Here, we note that ∆0 is independent of
˜
M0,N−1, F0,N and ˜D1,N−1. We integrate out ∆0 in
Equation (146) using item 2 of Lemma 27 by using the fact that ˜D0,N−1 = ˜D1,N−1 ∩˜D0
−0 to show:
E

exp

λ⟨x, ( ˆ˜Av
0,N)y⟩
 ˜
M0,N−1 ∩˜D0,N−1

≤
E
h
exp

γ λ2Cµ
N2 ⟨x, Σx⟩∥F0,Ny∥2 + λ⟨x, Γ1,N−1y⟩

1

˜
M0,N−1 ∩˜D1,N−1i
P

˜
M0,N−1 ∩˜D0,N−1

(147)
We use the fact that F0,N = I+ ˜H1
0,B−1F1,N to conclude: ∥F0,Ny∥2 = ∥y∥2+2⟨y, ˜H1
0,B−1F1,Ny⟩+
⟨y, F T
1,N ˜H1,⊤
0,B−1 ˜H1
0,B−1F1,Ny⟩. Under the event ˜
M0,N−1 ∩˜D1,N−1, we have: ∥˜H1
0,B−1∥≤1 and
∥F1,N∥≤α. Therefore, ∥F0,Ny∥2 ≤∥y∥2(1 + 2α) + ⟨y, F T
1,N ˜H1,⊤
0,B−1 ˜H1
0,B−1F1,Ny⟩. Using this
in Equation (147), we conclude:
P

˜
M0,N−1 ∩˜D0,N−1
E

exp

λ⟨x, ( ˆ˜Av
0,N)y⟩
 ˜
M0,N−1 ∩˜D0,N−1

≤E
h
exp (Ω+ λ⟨x, Γ1,N−1y⟩) 1

˜
M0,N−1 ∩˜D1,N−1i
≤E
h
exp (Ω+ λ⟨x, Γ1,N−1y⟩) 1

˜
M1,N−1 ∩˜D1,N−1i
,
(148)
where Ω:= γ λ2Cµ
N 2 ⟨x, Σx⟩(1 + 2α)∥y∥2 + γ λ2Cµ
N 2 ⟨x, Σx⟩⟨y, F T
1,N ˜H1,⊤
0,B−1 ˜H1
0,B−1F1,Ny⟩. In the
last step we have used the fact that
˜
M0,N−1 ∩˜D1,N−1 ⊆
˜
M1,N−1 ∩˜D1,N−1. We continue
just like before but use item 1 of Lemma 27 instead of item 2 to keep peeling terms of the form
⟨x, ∆t−1Ft−1,Ny⟩to conclude:
E

exp

λ⟨x, ( ˆ˜Av
0,N)y⟩
 ˜
M0,N−1 ∩˜D0,N−1

≤2 exp

γ λ2Cµ
N
⟨x, Σx⟩(1 + 2α)∥y∥2

≤2 exp

γ λ2Cµ
N
σmax(Σ)(1 + 2α)

(149)
Where σmax(Σ) is the maximum eigenvalue of the covariance matrix Σ. Here we have used the
assumption that P

˜
M0,N−1 ∩˜D0,N−1
≥1
2 and the fact that ∥x∥= ∥y∥= 1. We apply Chernoff
41

bound to ⟨x, ( ˆ˜Av
0,N)y⟩using Equation (149) to conclude that for any β, λ ∈R+
P

⟨x, ( ˆ˜Av
0,N)y⟩> β
 ˜
M0,N−1 ∩˜D0,N−1

≤2 exp

γ λ2Cµ
N
σmax(Σ)⟩(1 + 2α) −βλ

(150)
Choose λ =
Nβ
2γCµσmax(Σ)(1+2α) to conclude:
P

⟨x, ( ˆ˜Av
0,N)y⟩> β
 ˜
M0,N−1 ∩˜D0,N−1

≤2 exp

−
β2N
4γCµσmax(Σ)(1 + 2α)

We now apply an ϵ net argument just like in Lemma 31. Suppose N is a 1/4-net of the sphere in Rd.
By Corollary 4.2.13 in [52], we can choose |N| ≤12d. By Exercise 4.4.3 in [52], we conclude that:
∥ˆ˜Av
0,N∥≤2 sup
x,y∈N
⟨x, ( ˆ˜Av
0,N)y⟩.
Therefore,
P

∥ˆ˜Av
0,N∥> β
 ˜
M0,N−1 ∩˜D0,N−1

≤P

sup
x,y∈N
⟨x, ( ˆ˜Av
0,N)y⟩> β
2
 ˜
M0,N−1 ∩˜D0,N−1

≤|N|2 sup
x,y∈N
P

⟨x, ( ˆ˜Av
0,N)y⟩> β
2
 ˜
M0,N−1 ∩˜D0,N−1

≤2(12)2d exp

−
β2N
16γCµσmax(Σ)(1 + 2α)

≤exp

c1d −
β2N
16γCµσmax(Σ)(1 + 2α)

(151)
M
Lower Bounds
Consider the notations as deﬁned in Section 4. The idea behind the proof is to consider an appropriate
Bayesian error lower bound to the minimax error. To construct such a prior distribution, we consider
binary tuples M = (Mij for i, j ∈[d], i < j) ∈{0, 1}d(d−1)/2 and ϵ ∈(0, 1
4d). We construct the
symmetric matrix corresponding to M, denoted by A(M) as:
A(M)ij =
 1
2 if i = j
1
4d −ϵMij if i < j
(152)
For the sake of clarity, we denote Lpred(·; A(M), N(0, σ2I)) by Lpred(·; M). We use πM to denote
the stationary distribution of VAR(A(M), N(0, σ2I)) and the data co-variance matrix at stationarity
to be GM := EX∼πM XX⊤. By (Zt) ∼M, we mean (Z1, . . . , ZT ) ∼VAR(A(M), N(0, σ2I)).
We will ﬁrst list some useful results in the following Lemmas:
Lemma 34. Suppose Assumption 1 holds for VAR(A∗, µ) and let its stationary distribution be π.
Let G := EX∼πXX⊤. Then,
Lpred(A) −Lpred(A∗) = Tr

(A −A∗)⊤(A −A∗)G

Lemma 35. For every M ∈{0, 1}d(d−1)/2 we have:
σ2I ⪯GM ⪯3σ2I
Proof. First we note by Gershgorin circle theorem that ∥A(M)∥≤3
4. Given a stationary sequence
(Z0, . . . , ZT ) ∼M and the corresponding noise sequence η0, . . . , ηT ∼N(0, σ2I) i.i.d, we have by
stationarity deﬁnition: Zt+1 = A(M)Zt + ηt and Zt+1, Zt are both stationary. Therefore:
GM = EZt+1Z⊤
t+1 = A(M)EZtZ⊤
t A(M)⊤+ Eηtη⊤
t = A(M)GMA(M)⊤+ σ2I .
42

From this we conclude that GM ⪰σ2I. Now, expanding the recursion above, we have:
GM = σ2
∞
X
i=0
A(M)i(A(M)⊤)i ⪯σ2
∞
X
i=0
 9
16
i
I = 16σ2
7
I
(153)
In the second step we have the fact that ∥A(M)∥≤3
4 to show that A(M)i(A(M)⊤)i ⪯
  9
16
i I
Suppose M and M ′ are such that their Hamming distance is 1 (i.e, A(M) and A(M ′) differ
in exactly two places). We want to bound the total variation distance between the correspond-
ing stationary sequences (Z0, Z1, . . . , ZT ) ∼VAR(A(M), N(0, σ2I)) and (Z′
0, Z′
1, . . . , Z′
T ) ∼
VAR(A(M ′), N(0, σ2I)).
Lemma 36. Let the quantities be as deﬁned above. For some universal constant c, whenever
ϵ < c min( 1
√
T , 1
d), we have:
TV ((Z0, . . . , ZT ), (Z′
0, . . . , Z′
T )) ≤1
2
By the existence of maximal coupling (see Chapter I, Theorem 5.2 in [53]), we conclude that we can
deﬁne (Z0, . . . , ZT ) and (Z′
0, . . . , Z′
T ) on a common probability space such that:
P((Z0, . . . , ZT ) = (Z′
0, . . . , Z′
T )) ≥1
2
Proof. We will ﬁrst bound the KL divergence between the two distributions and infer the bound on
TV distance from Pinsker’s inequality. Consider pM,T and pM ′,T to be the respective probability
density functions of (Z0, . . . , ZT ) ∼M and (Z′
0, . . . , Z′
T ) ∼M ′ respectively. In this proof, we will
use Zt,−to denote the tuple (Z0, . . . , Zt). Now, by deﬁnition of KL divergence, we have:
KL(pM,T ∥pM ′,T ) = EZ∼pM,T log pM,T (Z0, . . . , ZT )
pM ′,T (Z0, . . . , ZT )
= EZ∼pM,T log pM,T (ZT |ZT −1,−)
pM ′,T (ZT |ZT −1,−) + EZ∼pM,T log pM,T −1(Z0, . . . , ZT −1)
pM ′,T −1(Z0, . . . , ZT −1)
= EZ∼pM,T log pM,T (ZT |ZT −1,−)
pM ′,T (ZT |ZT −1,−) + KL(pM,T −1∥pM ′,T −1)
= EZ∼pM,T log pM,T (ZT |ZT −1)
pM ′,T (ZT |ZT −1) + KL(pM,T −1∥pM ′,T −1)
(154)
The ﬁrst 3 steps above follow from the deﬁnition of KL divergence and conditional density. In the
last step we have used the Markov property of the sequence Z0, . . . , ZT which in this case shows
that the law of ZT |ZT −1 is the same as the law ZT |ZT −1,−. Using Equation (154) recursively and
noting that (Zt, Zt−1) are identically distributed for every t ∈{1, . . . , T}, we conclude:
KL(pM,T ∥pM ′,T ) = TE(Z0,Z1)∼pM,1 log pM,1(Z1|Z0)
pM ′,1(Z1|Z0) + KL(πM∥πM ′)
(155)
We will ﬁrst bound E(Z0,Z1)∼pM,1 log pM,1(Z1|Z0)
pM′,1(Z1|Z0). Conditioned on Z0, the law of Z1 under the
model M is N(A(M)Z0, σ2I).
Similarly, the conditional law of Z1 under the model M ′ is
N(A(M ′)Z0, σ2I). Therefore, a simple calculation shows that:
E(Z0,Z1)∼pM,1 log pM,1(Z1|Z0)
pM ′,1(Z1|Z0) = EZ0∼πM
∥(A(M) −A(M ′)) Z0∥2
2σ2
= EZ0∼πM Tr

(A(M) −A(M ′))⊤(A(M) −A(M ′)) Z0Z⊤
0
2σ2

=
1
2σ2 Tr

(A(M) −A(M ′))⊤(A(M) −A(M ′)) GM

≤3
2 Tr

(A(M) −A(M ′))⊤(A(M) −A(M ′))

= 3
2∥A(M) −A(M ′)∥2
F = 3ϵ2.
(156)
43

In the ﬁrst step, we have used standard KL formula for Gaussians with different mean but same
variance. In the third step we have used the fact that Z0 ∼πM. In the fourth step, we have used the
upper bound on GM from Lemma 35. In the last step we have used the deﬁnition of A(M) and the
fact that the Hamming distance between M and M ′ is 1. Now we consider: KL(πM∥πM ′)
Clearly, πM = N(0, GM). By standard formula for KL divergence between Gaussians,
KL(πM∥πM ′) = 1
2

Tr(G−1
M ′GM) −d + log detGM ′
detGM

.
(157)
First we consider Tr(G−1
M ′GM). Clearly, GM = σ2(I −A(M)2)−1 and GM ′ = σ2(I −A(M ′)2)−1.
Therefore, G−1
M ′ = G−1
M + A(M)2−A(M ′)2
σ2
. We have:
Tr(G−1
M ′GM) = Tr(I) + Tr
A(M)2 −A(M ′)2
σ2
GM

≤d + d
 A(M)2−A(M ′)2
σ2
GM

≤d + d∥GM∥
σ2
∥A(M)2 −A(M ′)2∥≤d + 3d∥A(M)2 −A(M ′)2∥
= d + 3d∥(A(M) −A(M ′))A(M) + A(M ′)(A(M) −A(M ′))∥
≤d + 3d [∥A(M) −A(M ′)∥∥A(M)∥+ ∥A(M ′)∥∥A(M) −A(M ′∥]
≤d + 9
2dϵ.
(158)
In the second step we have used the fact that tr(B) ≤d∥B∥. In the future steps, we have made use
of the sub-multiplicativity of the operator norm and the upper bound on ∥GM∥given by Lemma 35.
We have also used the fact that by Gershgorin theorem ∥A(M)∥≤3
4 and ∥A(M) −A(M ′)∥= ϵ.
Next, we will bound log detGM′
detGM . Suppose µ1 ≥· · · ≥µd be the eigenvalues of A(M) and µ′
1 ≥
· · · ≥µ′
d be the eigenvalues of A(M ′). We conclude that:
log detGM ′
detGM
=
d
X
i=1
log
 1 −µ2
i
1 −(µ′
i)2

.
Now, ∥A(M) −A(M ′)∥≤ϵ. Therefore, we conclude by Weyl inequalities that |µi −µ′
i| ≤ϵ. By
Gershgorin circle theorem, we also conclude that 1
4 ≤µ′
i ≤3
4
Plugging this into the equation above, we have:
log detGM ′
detGM
=
d
X
i=1
log
 1 −µ2
i
1 −(µ′
i)2

≤
d
X
i=1
log
1 −(µ′
i −ϵ)2
1 −(µ′
i)2

=
d
X
i=1
log

1 + 2µ′
i −ϵ2
1 −(µ′
i)2

≤
d
X
i=1
log (1 + 4ϵ) ≤4ϵd
(159)
Combining Equations (158) and (159) along with Equation (157) we conclude:
KL(πM∥πM ′) ≤5ϵd.
Using this along with Equations (156) and (155), we conclude:
KL(pM,T ∥pM ′,T ) = 3ϵ2T + 5ϵd.
(160)
From this we conclude that when ϵ is as given in the statement of the lemma, we have:
KL(pM,T ∥pM ′,T ) ≤1
8.
(161)
By Pinsker’s inequality, which states that TV ≤
√
2KL, we conclude the result of the lemma.
Theorem 4. We ﬁrst note that when we choose σ2 such that dσ2 = β, we have
VAR(A(M), N(0, σ2I)) ∈M
44

for every M ∈{0, 1}d(d−1)/2. We pick ϵ = c min( 1
√
T , 1
d) so that Lemma 36 is satisﬁed.
We draw M randomly from the uniform measure over {0, 1}d(d−1)/2 and lower bound the minimax
error by Bayesian error.
Lminmax(M) ≥inf
f∈F EME(Zt)∼MLpred(f(Z0, . . . , ZT ); M) −Lpred(A(M); M)
(162)
We will now uniformly lower bound EME(Zt)∼MLpred(f(Z0, . . . , ZT ); M) −Lpred(A(M); M)
for every ﬁxed choice of f ∈F to conclude the statement of the theorem from Equation (162).
Henceforth, we will denote f(Z0, . . . , ZT ) by ˆA(M) whenever (Zt) ∼M. By Lemma 34, we
conclude that:
Lpred( ˆA(M); M) −Lpred(A(M); M) = Tr
h
( ˆA(M) −A(M))⊤( ˆA(M) −A(M))GM
i
.
( ˆA(M) −A(M))⊤( ˆA(M) −A(M)) is a PSD matrix and by Lemma 35, GM ≥σ2I for every M.
Therefore, we conclude that with probability 1 we have:
Lpred( ˆA(M); M)−Lpred(A(M); M) ≥σ2 Tr
h
( ˆA(M) −A(M))⊤( ˆA(M) −A(M))
i
= σ2∥ˆA(M) −A(M)∥2
F ≥2σ2 X
i,j∈[d]
i<j
( ˆA(M)ij −A(M)ij)2.
(163)
Therefore, we conclude that:
EMEZt∼MLpred( ˆA(M); M) −Lpred(A(M); M) ≥2
X
i,j∈[d]
i<j
EME(Zt)∼M( ˆA(M)ij −A(M)ij)2.
(164)
We will now lower bound every term in the summation in the RHS of Equation (164). Fix (i, j). Let
M∼ij denote all the co-ordinates of M other than (i, j). We deﬁne M +, M −∈{0, 1}d(d−1)/2 so
that M +
∼ij = M∼ij and M +
ij = 1. Similarly, let M −
∼ij = M∼ij and M −
ij = 0. Therefore, we have:
EME(Zt)∼M( ˆA(M)ij −A(M)ij)2 = 1
2EM∼ijE(Zt)∼M +( ˆA(M +)ij −A(M +)ij)2
+ 1
2EM∼ijE(Zt)∼M −( ˆA(M −)ij −A(M −)ij)2.
(165)
Now, M + and M −differ in exactly one co-ordinate. We invoke Lemma 36 to show that there
exists a coupling between (Z+
t ) ∼M + and Z−
t
∼M −such that P(Z+
t
= Z−
t ) ≥1
2. Call this
event Γ (we ignore the dependence on M∼ij for the sake of clarity). In this event, we must have
ˆA(M +) = ˆA(M −) since our estimator f ∈F is a measurable function of the data. For any ﬁxed
M∼ij, we have:
E(Zt)∼M +( ˆA(M +)ij −A(M +)ij)2 + E(Zt)∼M −( ˆA(M −)ij −A(M −)ij)2
≥E(Zt)1(Γ)
h
( ˆA(M +)ij −A(M +)ij)2 + ( ˆA(M +)ij −A(M −)ij)2i
≥P(Γ)(A(M −)ij −A(M +)ij)2 ≥1
2(A(M −)ij −A(M +)ij)2 = ϵ2
2 .
(166)
In the second line we have used the fact that under event Γ, ˆA(M +) = ˆA(M −). In the third line, we
have used the inequality (x −y)2 + (x −z)2 ≥1
2(y −z)2. In the fourth line, we have used the fact
that P(Γ) ≥1/2. Using Equation (166) along with Equations (165) and (164), we conclude that for
every estimator f ∈F the following holds:
EMEZt∼M[Lpred( ˆA(M); M) −Lpred(A(M); M)] ≥d(d −1)ϵ2σ2
4
.
Using above equation with Equation (162), we conclude the statement of the theorem.
45

Remark. We can show a similar lower bound by considering a discrete prior over the space of
orthogonal matrices. In particular taking A∗to be an orthogonal matrix scaled by ρ, we can endow
the orthogonal (or special orthogonal) group with metric induced by the Frobenius norm. Then from
[54, Proposition 7], we can construct an ϵ-cover of cardinality d
d(d−1)
2
. But then from the proof of
[55, Proposition 3], for α ∈(0, 1), there exists a local packing of the space with packing distance αϵ
and cardinality at least cd(d−1)/2 where c > 1. Further the diameter of this local packing is at most
2ϵ (in Frobenius norm). Now using standard arguments from Fano’s inequality (c.f.[55, Proposition
3]) or Birge’s inequality (c.f.[5, Lemma F.1]) we can get a similar lower bound on the prediction
error as Theorem 4 but with explicit dependence on ρ.
N
Techincal Proofs
N.1
Proof of Lemma 10
Proof. Consider the SGD −RER iteration:
At−1
i+1 = At−1
i
−2γ(At−1
i
Xt−1
−i −Xt−1
−(i+1))Xt−1,⊤
−i
= At−1
i
(I −2γXt−1
−i Xt−1,⊤
−i
) + 2γXt−1
−(i−1))Xt−1,⊤
−(i+1)
(167)
Observe that for our choice of γ and under the event D0,N−1, we have ∥(I −2γXt−1
−i Xt−1,⊤
−i
)∥≤1
and ∥Xt−1
−(i+1)Xt−1,⊤
−i
∥≤R. Therefore, triangle inequality implies:
∥At−1
i+1∥≤∥At−1
i
∥+ 2γR
We conclude the bound in the Lemma.
N.2
Proof of Lemma 11
Proof. We again consider the evolution equation: ˜Xt−1
−i
At−1
i+1 = At−1
i
−2γ(At−1
i
Xt−1
−i −Xt−1
−(i+1))Xt−1,⊤
−i
= At−1
i
−2γ(At−1
i
˜Xt−1
−i −˜Xt−1
−(i+1)) ˜Xt−1,⊤
−i
+ ∆t,i
(168)
Where
∆t,i = 2γAt−1
i

˜Xt−1
−i
˜Xt−1,⊤
−i
−Xt−1
−i Xt−1,⊤
−i

+ 2γ

Xt−1
−(i+1)Xt−1,⊤
−i
−˜Xt−1
−(i+1) ˜Xt−1,⊤
−i

Using Lemmas 10 and 7, we conclude that:
∥∆t,i∥≤(16γ2R2T + 8γR) ∥A∗u∥
Using the recursion for ˜At
i, we conclude:
At−1
i+1 −˜At−1
i+1 = (At−1
i
−˜At−1
i
) ˜P t
i + ∆t,i
=⇒
At−1
i+1 −˜At−1
i+1
 ≤
At−1
i
−˜At−1
i

 ˜P t
i
 + (16γ2R2T + 8γR) ∥A∗u∥
=⇒
At−1
i+1 −˜At−1
i+1
 ≤
At−1
i
−˜At−1
i
 + (16γ2R2T + 8γR) ∥A∗u∥
(169)
In the last step we have used the fact that under the event ˆD0,N−1, we must have
 ˜P t
i
 ≤1. We
conclude the statement of the lemma from Equation (169).
46

N.3
Proof of Lemma 12
Proof. First we have
E
h At−1
j
−A∗⊤ At−1
j
−A∗
1

D0,t−1i
⪯E
h At−1
j
−A∗⊤ At−1
j
−A∗
1
h
ˆD0,t−1ii
+ 4γ2(Bt)2R√µ4
1
T α/2 I
⪯E
h At−1
j
−A∗⊤ At−1
j
−A∗
1
h
ˆD0,t−1ii
+ cγ2dσmax(Σ)RT 2
1
T α/2 I
(170)
Next, we have

 At−1
j
−A∗⊤ At−1
j
−A∗
−

˜At−1
j
−A∗⊤
˜At−1
j
−A∗
≤
At−1
j
−˜At−1
j

 At−1
j
−A∗ +


˜At−1
j
−A∗

≤
At−1
j
−˜At−1
j


2 ∥A∗∥+
At−1
j
 +
 ˜At−1
j


(171)
Thus on the event ˆD0,t−1, using lemma 11 and lemma 10 we get

 At−1
j
−A∗⊤ At−1
j
−A∗
−

˜At−1
j
−A∗⊤
˜At−1
j
−A∗
≤c(γ2R2T 2 + γRT)(γRT + ∥A∗∥+ ∥A0∥) ∥A∗u∥≤cγ3R3T 3 ∥A∗u∥
(172)
for some constant c. (We have suppressed the dependence on A0 and A∗since they are constants and
γRT grows with T).
The proof follows by combining (170) and (172).
The proof of (17) follows similarly.
O
Prediction error for sparse systems
In this section we consider the VAR(A∗, µ) model with sparse A∗whose sparsity pattern is known.
We will present a modiﬁcation of SGD −RER that takes into account the sparsity pattern information.
Formally, let Sl = {k : A∗
l,k ̸= 0} be support or sparsity pattern of row l of A∗. Further let sl = |Sl|
denote the sparsity of row j. We assume that Sl is known for each 1 ≤l ≤d. The claim is that
the excess expected prediction loss is of order
P
l slσ2
l
T
. We will present only a sketch of the proof
highlighting the main steps. Detailed calculations follow similarly as in sections F and G.
The modiﬁcation of the SGD −RER algorithm to use the sparsity pattern is as follows. Let a∗,⊤
l
denote row l of A∗. The algorithmic iterates are given by (At−1
j
) where row l is at−1,⊤
j,l
. Let
a0
0,l = 0 ∈Rd. Let {el : 1 ≤l ≤d} denote the standard basis of Rd. Let PSl : Rd →Rd denote
the (self adjoint) orthogonal projection operator onto the subspace spanned by {el : l ∈Sl}. Then
update for row l is given by
at−1,⊤
j+1,l =
h
at−1,⊤
j,l
−2γ(at−1,⊤
j,l
Xt−1
−j −⟨el, Xt−1
−(j−1)⟩)Xt−1,⊤
−j
i
PSl
(173)
and at
0,l = at−1
B,l . Since each iterate above has sparsity pattern Sl by construction, we can rewrite the
above as
at−1,⊤
j+1,l = at−1,⊤
j,l
−2γ(at−1,⊤
j,l
Xt−1
−j −⟨el, Xt−1
−(j−1)⟩)
 PSlXt−1
−j
⊤
(174)
Notice that at−1,⊤
j,l
Xt−1
−j = at−1,⊤
j,l
PSlXt−1
−j and
⟨el, Xt−1
−(j−1)⟩= a∗,⊤
l
Xt−1
−j + ηt−1
−j,l
47

Thus

at−1
j+1,l −a∗
l
⊤
=

at−1
j,l −a∗
l
⊤
PSl −2γ
 PSlXt−1
−j
  PSlXt−1
−j
⊤
+ 2γηt−1
−j,l
 PSlXt−1
−j
⊤
(175)
For a vector v ∈Rd, let vSl ∈Rsl be the vector corresponding to the support Sl i.e. entries in vSl
correspond to the entries in v whose indices are in Sl. So we can rewrite (175) completely in Rsl as

at−1
j+1,l −a∗
l
⊤
Sl
=

at−1
j,l −a∗
l
⊤
Sl

Isl −2γ
 Xt−1
−j

Sl
 Xt−1
−j
⊤
Sl

+ 2γηt−1
−j,l
 Xt−1
−j
⊤
Sl
(176)
where Isl is the identity matrix of dimension sl.
Our goal is to bound the expected prediction error for this modiﬁed SGD −RER. To that end, we
will make some important observations.
(1) Since we focus on prediction error, the entire analysis can be carried out row by row. To see
this, if ˆA is any estimator, the
Lpred( ˆA; A∗, µ) −Tr(Σ) = Tr(G( ˆA −A∗)⊤( ˆA −A)) =
d
X
l=1
Tr(G(ˆal −a∗
l )(ˆal −a∗
l )⊤)
where ˆa⊤
l is the row l of ˆA.
(2) If ˆal and a∗
l have sparsity pattern Sl then
Tr(G(ˆal −a∗
l )(ˆal −a∗
l )⊤) = Tr(PSlGPSl(ˆal −a∗
l )(ˆal −a∗
l )⊤)
= Tr(GSl(ˆal −a∗
l )Sl(ˆal −a∗
l )⊤
Sl)
where GSl ∈Rsl×sl is the submatrix of G obtained by picking rows and columns corre-
sponding to indices in Sl.
(3) Under the stationary measure, we have E
h PSlXt−1
−j
  PSlXt−1
−j
⊤i
= PSlGPSl. Thus,
with high probability
PSlXt−1
−j
2 ≤cslσmax(G) log T.
(4) Letting s0 = maxl sl, we can set R = cs0σmax(G) log T and use step size γ = O(1/RB).
(5) We can perform the same bias-variance decomposition as described in section D to obtain
at−1,v
B,l
and at−1,b
B,l
.
(6) From previous observations, the variance of last iterate corresponding to row l turns out to
be
γσ2
l (1 −o(1))Isl ⪯E

at−1,v
B,l

Sl

at−1,v
B,l
⊤
Sl

⪯
γ
1 −γRσ2
l (1 + o(1))Isl
where σ2
l = Σl,l.
(7) Similarly, the variance of the average iterate E
h
(ˆav
0,N,l)(ˆav
0,N,l)⊤i
corresponding to row l
can be bounded upto leading order by
1
N 2
N
X
t=1

Vt−1,l(Isl −HSl)−1 + (Isl −H⊤
Sl)−1Vt−1,l

where Vt−1,l = E

at−1,v
B,l

Sl

at−1,v
B,l
⊤
Sl

and (with abuse of notation) HSl is deﬁned as
HSl = E


B−1
Y
j=0

Isl −2γ( ˜X0
−j)Sl( ˜X0
−j)⊤
Sl

1

∩B−1
j=0
( ˜X0
−j)Sl

2
≤R


where ˜X0
0 ∼π.
(8) Now, similar to lemma 16 we can bound HSl + H⊤
Sl by 2(Isl −cγBGsl) upto leading order.
48

(9) Thus similar to lemma 17 we obtain
Tr(GSl(I −HSl)−1) ≤c sl
γB
(10) Finally as in section G.1 we can bound the variance of prediction error of row l upto leading
order by
Tr(GE

(ˆav
0,N,l)(ˆav
0,N,l)⊤
) ≲σ2
l sl
T
Thus summing over l we get
Tr

GE
h
( ˆAv
0,N)( ˆAv
0,N)⊤i
≲
P
l σ2
l sl
T
(11) Bias can also be analyzed in a similar way and it will be of strictly lower order (using
suitable tail-averaging).
(12) Thus the excess prediction loss is given bounded as
E
h
Lpred( ˆAN/2,N; A∗, µ)
i
−Tr(Σ) ≲
P
l σ2
l sl
T
So the modiﬁed SGD −RER algorithm effectively utilizes the low dimensional structure in A∗.
49

