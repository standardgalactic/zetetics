André Platzer
Geoff Sutcliffe (Eds.)
 123
LNAI 12699
28th International Conference on Automated Deduction
Virtual Event, July 12–15, 2021
Proceedings
Automated Deduction – 
CADE 28

Lecture Notes in Artiﬁcial Intelligence
12699
Subseries of Lecture Notes in Computer Science
Series Editors
Randy Goebel
University of Alberta, Edmonton, Canada
Yuzuru Tanaka
Hokkaido University, Sapporo, Japan
Wolfgang Wahlster
DFKI and Saarland University, Saarbrücken, Germany
Founding Editor
Jörg Siekmann
DFKI and Saarland University, Saarbrücken, Germany

More information about this subseries at http://www.springer.com/series/1244

André Platzer
• Geoff Sutcliffe (Eds.)
Automated Deduction –
CADE 28
28th International Conference on Automated Deduction
Virtual Event, July 12–15, 2021
Proceedings
123

Editors
André Platzer
Carnegie Mellon University
Pittsburgh, PA, USA
Geoff Sutcliffe
University of Miami
Coral Gables, FL, USA
ISSN 0302-9743
ISSN 1611-3349
(electronic)
Lecture Notes in Artiﬁcial Intelligence
ISBN 978-3-030-79875-8
ISBN 978-3-030-79876-5
(eBook)
https://doi.org/10.1007/978-3-030-79876-5
LNCS Sublibrary: SL7 – Artiﬁcial Intelligence
© The Editor(s) (if applicable) and The Author(s) 2021. This book is an open access publication.
Open Access This book is licensed under the terms of the Creative Commons Attribution 4.0 International
License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution
and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and
the source, provide a link to the Creative Commons license and indicate if changes were made.
The images or other third party material in this book are included in the book’s Creative Commons license,
unless indicated otherwise in a credit line to the material. If material is not included in the book’s Creative
Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use,
you will need to obtain permission directly from the copyright holder.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are
believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors
give a warranty, expressed or implied, with respect to the material contained herein or for any errors or
omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in
published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
This volume contains the proceedings of the 28th International Conference on Auto-
mated Deduction (CADE-28). CADE is the major forum for the presentation of
research in all aspects of automated deduction, including foundations, applications,
implementations, and practical experience. CADE-28 was hosted by Carnegie Mellon
University, Pittsburgh, USA, 11–16 July 2021, but held online due to the COVID-19
pandemic. CADE-28 emphasized the breadth of topics that are of interest, including
applications in and beyond STEM, and the use/contribution of automated deduction
in AI.
The Program Committee (PC) accepted 36 papers (29 full papers and 7 system
descriptions) out of 76 submissions (59 full papers, 4 short papers, and 13 system
descriptions). Each submission was reviewed by at least three Program Committee
members or their external reviewers. The criteria for evaluation were originality and
signiﬁcance, technical quality, comparison with related work, quality of presentation,
and reproducibility of experiments.
The program of the conference included four invited talks:
– Liron Cohen (Ben-Gurion University, Israel): “Non-well-founded Deduction for
Induction and Coinduction”
– Guido Governatori (CSIRO, Australia): “Computational Law: Automated Rea-
soning in the Legal Domain”
– Mooly Sagiv (Tel Aviv University, Israel): “Formal Reasoning about Decentralized
Financial Applications”
– Markus Rabe (Google, USA): “What are the Limits of Neural Networks for
Automated Reasoning?”
The conference hosted several workshops, tutorials, and competitions:
– Workshop: 10th International Workshop on Theorem Proving Components for
Educational Software.
– Workshop: Proof eXchange for Theorem Proving.
– Workshop: Parallel and Distributed Automated Reasoning.
– Workshop: 17th International Workshop on Termination.
– Workshop: Logical Frameworks and Meta-Languages - Theory and Practice.
– Workshop: 3rd International Workshop on Automated Reasoning: Challenges,
Applications, Directions, Exemplary Achievements.
– Tutorial: Program Validation and Veriﬁcation in PVS. Paolo Masci (NIA), Mariano
Moscato (NIA), César Munoz (NASA), Aaron Dutle (NASA), and Tanner Slagel
(NASA).
– Tutorial: Practice of First-Order Reasoning. Stephan Schulz (DHBW), Adam Pease
(Articulate Software), and Geoff Sutcliffe (University of Miami).
– Tutorial: Learning to Prove: Machine Learning for Better SAT and QSAT Solvers.
Sean Holden (University of Cambridge).

– Tutorial: Proof-Theoretical Analysis of Non-Fregean Logic. Szymon Chlebowski,
Marta Gawek, Dorota Leszczyńska-Jasion, and Agata Tomczyk (Adam Mickiewicz
University).
– Competition: 28th CADE ATP System Competition. Geoff Sutcliffe (University of
Miami) and Martin Desharnais (Vrije Universiteit Amsterdam).
– Competition: Termination Competition 2021. Albert Rubio (UPC Barcelona) and
Akihisa Yamada (AIST Tsukuba).
In addition to the best paper awards, three CADE awards were presented at the
conference:
– The Herbrand Award for Distinguished Contributions to Automated Reasoning
(for 2020 and 2021).
– The Thoralf Skolem Awards for CADE papers that have passed the test of time by
being the most inﬂuential papers in the ﬁeld, for papers from CADE-5 (1980),
CADE-11 (1992), CADE-17 (2000), and CADE-23 (2011).
– The (newly established) Bill McCune PhD Award for a PhD thesis’ substantive
contributions to the ﬁeld of Automated Reasoning.
Thanks go to the many people without whom the conference would not have been
possible - the authors, participants, invited spakers, members of the PC and their
subreviewers, conference chairs, local organizers, the workshop/tutorial/competitions
chair, the publicity chair, the CADE trustees, the board of the Association for Auto-
mated Reasoning, the staff at Springer, and the EasyChair team. CADE-28 gratefully
received support from the Automated Reasoning Group at Amazon Web Services, The
Journal of Artiﬁcial Intelligence, Imandra Inc., and Springer.
July 2021
André Platzer
Geoff Sutcliffe
vi
Preface

Organization
Program Committee
Peter Baumgartner
CSIRO, Australia
Bernhard Beckert
Karlsruhe Institute of Technology, Germany
Christoph Benzmüller
Freie Universität Berlin, Germany
Armin Biere
Johannes Kepler University, Austria
Nikolaj Bjorner
Microsoft Research, USA
Jasmin Blanchette
Vrije Universiteit Amsterdam, The Netherlands
Maria Paola Bonacina
Università degli Studi di Verona, Italy
Agata Ciabattoni
Vienna University of Technology, Austria
Koen Claessen
Chalmers University of Technology, Sweden
Hans de Nivelle
Nazarbayev University, Kazakhstan
Stéphane Demri
CNRS, LMF, France
Huimin Dong
Sun Yat-sen University, China
Gilles Dowek
Inria and ENS Paris-Saclay, France
Mnacho Echenim
Grenoble Alpes University, France
Pascal Fontaine
Université de Liège, Belgium
Nathan Fulton
IBM, USA
Silvio Ghilardi
Università degli Studi di Milano, Italy
Jürgen Giesl
RWTH Aachen University, Germany
Rajeev Gore
The Australian National University, Australia
Nao Hirokawa
Japan Advanced Institute of Science
and Technology, Japan
Moa Johansson
Chalmers University of Technology, Sweden
Dejan Jovanović
SRI International, USA
Cezary Kaliszyk
University of Innsbruck, Austria
Laura Kovacs
Vienna University of Technology, Austria
Tomer Libal
American University of Paris, France
Assia Mahboubi
Inria, France
Cláudia Nalon
University of Brasília, Brazil
Vivek Nigam
Huawei Technologies, China
Tobias Nipkow
Technical University of Munich, Germany
Frank Pfenning
Carnegie Mellon University, USA
Giles Reger
University of Manchester, UK
Andrew Reynolds
University of Iowa, USA
Philipp Rümmer
Uppsala University, Sweden
Katsuhiko Sano
Hokkaido University, Japan
Renate A. Schmidt
University of Manchester, UK
Stephan Schulz
DHBW Stuttgart, Germany
Viorica Sofronie-Stokkermans
University Koblenz-Landau, Germany

Martin Suda
Czech Technical University in Prague,
Czech Republic
Tanel Tammet
Tallinn University of Technology, Estonia
Sophie Tourret
Inria, France
Christian Urban
King’s College London, UK
Uwe Waldmann
Max Planck Institute for Informatics, Germany
Yoni Zohar
Stanford University, USA
Subreviewers
Ruba Alassaf
Johannes Åman Pohjola
Paolo Baldi
Haniel Barbosa
Lee Barnett
Filip Bártek
Ahmed Bhayat
Lionel Blatter
Pierre Boutry
Martin Bromberger
James Brotherston
Claudia Cauli
Anupam Das
Jeremy Dawson
Emanuele De Angelis
Stefan Dollase
Manuel Eberl
Santiago Escobar
Michael Färber
Mathias Fleury
Carsten Fuhs
Thibault Gauthier
Alessandro Gianola
Yuri Gil Dantas
Christoph Haase
Ludovic Henrio
Jera Hensel
Stepan Holub
Ullrich Hustadt
Jan Jakubuv
Peter Jipsen
Daniela Kaufmann
Daisuke Kimura
Michael Kirsten
Patrick Koopmann
Hanna Lachnitt
Florian Lanzinger
Dominique Larchey-Wendling
Jonathan Laurent
Alexander Leitsch
Chencheng Liang
Andrea Mazzullo
Aart Middeldorp
Dale Miller
Julien Narboux
Ulf Norell
Mizuhito Ogawa
Miroslav Olšák
Hitoshi Omori
Jens Otten
Xavier Parent
Dirk Pattinson
Lawrence Paulson
Nicolas Peltier
Michael Rawson
Adrian Rebola Pardo
Giselle Reis
Simon Robillard
Jonas Schifﬂ
Claudia Schon
Hans-Jörg Schurr
Ying Sheng
Jonni Virtema
Alexander Weigl
Emre Yolcu
Marco Ziener
viii
Organization

Conference Chairs
Marijn Heule
Carnegie Mellon University, USA
Iliano Cervesato
Carnegie Mellon University, USA
Local Organizers
Marijn Heule
Carnegie Mellon University, USA
André Platzer
Carnegie Mellon University, USA
Iliano Cervesato
Carnegie Mellon University, USA
Workshop/Tutorial/Competitions Chair
Alexander Steen
University of Luxembourg, Luxembourg
Publicity Chair
Sophie Tourret
Inria, France
Board of Trustees of CADE Inc.
Christoph Benzmüller
(Vice-president)
Freie Universität Berlin, Germany
Jasmin Blanchette
(IJCAR 2022 PC Co-chair)
Vrije Universiteit Amsterdam, The Netherlands
Pascal Fontaine
University of Liège, Belgium
Marijn Heule
Carnegie Mellon University, USA
Laura Kovács
Vienna University of Technology, Austria
Aart Middeldorp
University of Innsbruck, Austria
Neil Murray (Treasurer)
State University of New York, USA
André Platzer
(CADE-28 PC Co-chair)
Carnegie Mellon University, USA
Andrew Reynolds
University of Iowa, USA
Philipp Rümmer (Secretary)
Uppsala University, Sweden
Renate A. Schmidt
University of Manchester, UK
Stephan Schulz
DHBW Stuttgart, Germany
Christoph Weidenbach
(President)
Max Planck Institute for Informatics, Germany
Board of the Association for Automated Reasoning
Christoph Benzmüller (CADE)
Freie Universität Berlin, Germany
Uli Furbach (Vice-president)
Universität Koblenz-Landau, Germany
Jürgen Giesl (CADE)
RWTH Aachen University, Germany
Philipp Rümmer (Secretary)
Uppsala University, Sweden
Sophie Tourret
(Newsletter Editor)
Inria, France
Organization
ix

Contents
Invited Talks
Non-well-founded Deduction for Induction and Coinduction. . . . . . . . . . . . .
3
Liron Cohen
Towards the Automatic Mathematician . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
Markus N. Rabe and Christian Szegedy
Logical Foundations
Tableau-based Decision Procedure for Non-Fregean Logic
of Sentential Identity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
Joanna Golińska-Pilarek, Taneli Huuskonen, and Michał Zawidzki
Learning from Łukasiewicz and Meredith: Investigations into
Proof Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
58
Christoph Wernhard and Wolfgang Bibel
Efficient Local Reductions to Basic Modal Logic . . . . . . . . . . . . . . . . . . . .
76
Fabio Papacchini, Cláudia Nalon, Ullrich Hustadt, and Clare Dixon
Isabelle’s Metalogic: Formalization and Proof Checker . . . . . . . . . . . . . . . .
93
Tobias Nipkow and Simon Roßkopf
Theory and Principles
The ksmt Calculus Is a d-complete Decision Procedure
for Non-linear Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
113
Franz Brauße, Konstantin Korovin, Margarita V. Korovina,
and Norbert Th. Müller
Universal Invariant Checking of Parametric Systems with Quantifier-free
SMT Reasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
131
Alessandro Cimatti, Alberto Griggio, and Gianluca Redondi
Politeness and Stable Infiniteness: Stronger Together. . . . . . . . . . . . . . . . . .
148
Ying Sheng, Yoni Zohar, Christophe Ringeissen, Andrew Reynolds,
Clark Barrett, and Cesare Tinelli
Equational Theorem Proving Modulo . . . . . . . . . . . . . . . . . . . . . . . . . . . .
166
Dohan Kim and Christopher Lynch

Unifying Decidable Entailments in Separation Logic
with Inductive Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
183
Mnacho Echenim, Radu Iosif, and Nicolas Peltier
Subformula Linking for Intuitionistic Logic with Application
to Type Theory. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
200
Kaustuv Chaudhuri
Efficient SAT-based Proof Search in Intuitionistic Propositional Logic. . . . . .
217
Camillo Fiorentini
Proof Search and Certificates for Evidential Transactions . . . . . . . . . . . . . . .
234
Vivek Nigam, Giselle Reis, Samar Rahmouni, and Harald Ruess
Non-clausal Redundancy Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
252
Lee A. Barnett and Armin Biere
Multi-Dimensional Interpretations for Termination of Term Rewriting . . . . . .
273
Akihisa Yamada
Finding Good Proofs for Description Logic Entailments using Recursive
Quality Measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
291
Christian Alrabbaa, Franz Baader, Stefan Borgwardt,
Patrick Koopmann, and Alisa Kovtunova
Computing Optimal Repairs of Quantified ABoxes w.r.t.
Static EL TBoxes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
309
Franz Baader, Patrick Koopmann, Francesco Kriegel,
and Adrian Nuradiansyah
Generalized Completeness for SOS Resolution and its Application
to a New Notion of Relevance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
327
Fajar Haifani, Sophie Tourret, and Christoph Weidenbach
A Unifying Splitting Framework. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
344
Gabriel Ebner, Jasmin Blanchette, and Sophie Tourret
Integer Induction in Saturation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
361
Petra Hozzová, Laura Kovács, and Andrei Voronkov
Superposition with First-class Booleans and Inprocessing Clausification. . . . .
378
Visa Nummelin, Alexander Bentkamp, Sophie Tourret,
and Petar Vukmirović
Superposition for Full Higher-order Logic . . . . . . . . . . . . . . . . . . . . . . . . .
396
Alexander Bentkamp, Jasmin Blanchette, Sophie Tourret,
and Petar Vukmirović
xii
Contents

Implementation and Application
Making Higher-Order Superposition Work . . . . . . . . . . . . . . . . . . . . . . . . .
415
Petar Vukmirović, Alexander Bentkamp, Jasmin Blanchette,
Simon Cruanes, Visa Nummelin, and Sophie Tourret
Dual Proof Generation for Quantified Boolean Formulas
with a BDD-based Solver. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
433
Randal E. Bryant and Marijn J. H. Heule
Reliable Reconstruction of Fine-grained Proofs in a Proof Assistant . . . . . . .
450
Hans-Jörg Schurr, Mathias Fleury, and Martin Desharnais
An Automated Approach to the Collatz Conjecture . . . . . . . . . . . . . . . . . . .
468
Emre Yolcu, Scott Aaronson, and Marijn J. H. Heule
Verified Interactive Computation of Definite Integrals . . . . . . . . . . . . . . . . .
485
Runqing Xu, Liming Li, and Bohua Zhan
ATP and AI
Confidences for Commonsense Reasoning . . . . . . . . . . . . . . . . . . . . . . . . .
507
Tanel Tammet, Dirk Draheim, and Priit Järv
Neural Precedence Recommender . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
525
Filip Bártek and Martin Suda
Improving ENIGMA-style Clause Selection while Learning From History . . .
543
Martin Suda
System Descriptions
A Normative Supervisor for Reinforcement Learning Agents . . . . . . . . . . . .
565
Emery Neufeld, Ezio Bartocci, Agata Ciabattoni,
and Guido Governatori
Automatically Building Diagrams for Olympiad Geometry Problems . . . . . . .
577
Ryan Krueger, Jesse Michael Han, and Daniel Selsam
The Fusemate Logic Programming System. . . . . . . . . . . . . . . . . . . . . . . . .
589
Peter Baumgartner
Twee: An Equational Theorem Prover . . . . . . . . . . . . . . . . . . . . . . . . . . . .
602
Nicholas Smallbone
The Isabelle/Naproche Natural Language Proof Assistant . . . . . . . . . . . . . . .
614
Adrian De Lon, Peter Koepke, Anton Lorenzen, Adrian Marti,
Marcel Schütz, and Makarius Wenzel
Contents
xiii

The Lean 4 Theorem Prover and Programming Language . . . . . . . . . . . . . .
625
Leonardo de Moura and Sebastian Ullrich
Harpoon: Mechanizing Metatheory Interactively . . . . . . . . . . . . . . . . . . . . .
636
Jacob Errington, Junyoung Jang, and Brigitte Pientka
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
649
xiv
Contents

Invited Talks

Non-well-founded Deduction for
Induction and Coinduction
Liron Cohen
cliron@cs.bgu.ac.il
https://www.cs.bgu.ac.il/~cliron/
Abstract. Induction and coinduction are both used extensively within
mathematics and computer science. Algebraic formulations of these prin-
ciples make the duality between them apparent, but do not account
well for the way they are commonly used in deduction. Generally, the
formalization of these reasoning methods employs inference rules that
express a general explicit (co)induction scheme. Non-well-founded proof
theory provides an alternative, more robust approach for formalizing
implicit (co)inductive reasoning. This approach has been extremely suc-
cessful in recent years in supporting implicit inductive reasoning, but
is not as well-developed in the context of coinductive reasoning. This
paper reviews the general method of non-well-founded proofs, and puts
forward a concrete natural framework for (co)inductive reasoning, based
on (co)closure operators, that oﬀers a concise framework in which induc-
tive and coinductive reasoning are captured as we intuitively understand
and use them. Through this framework we demonstrate the enormous
potential of non-well-founded deduction, both in the foundational theoret-
ical exploration of (co)inductive reasoning and in the provision of proof
support for (co)inductive reasoning within (semi-)automated proof tools.
1
Introduction
The principle of induction is a key technique in mathematical reasoning that
is widely used in computer science for reasoning about recursive data types
(such as numbers or lists) and computations. Its dual principle—the princi-
ple of coinduction [49,69,70]—is not as widespread, and has only been investi-
gated for a few decades, but still has many applications in computer science,
e.g. [42,56,39,52,82,55,57]. It is mainly used for reasoning about coinductive data
types (codata), which are data structures containing non-well-founded elements,
e.g., inﬁnite streams or trees. One prominent application of coinduction is as
a generic formalism for reasoning about state-based dynamical systems, which
typically contain some sort of circularity. It is key in proofs of the bisimula-
tion of state-transition systems (i.e., proving that two systems are behaviorally
equivalent) and is a primary method for reasoning about concurrent systems [53].
A duality between induction and coinduction is observed when formulating
them within an algebraic, or categorical, framework, e.g., [71,64,70,69]. Whereas
© The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5 1
3–24, 2021.
Dept. of Computer Science, Ben-Gurion University, Be’er Sheva, Israel

4
L. Cohen
induction corresponds to a least-ﬁxed-point semantics (or initial algebras), coin-
duction corresponds to a greatest-ﬁxed-point semantics (or ﬁnal coalgebras).
However, such an algebraic formulation does not account well for the way these
principles are commonly used in deduction, where they are usually applied in dif-
ferent ways: induction to prove properties of certain collections, and coinduction
to show equivalences between processes and systems.
Since the principle of induction is so well-known, induction methods are
relatively well-developed. They are available in most (semi-)automated deduction
systems, and tools for the formal veriﬁcation of software and hardware such as
theorem provers. Generally, implementations of the induction method employ
one or more inference rules that express a general explicit induction scheme that
holds for the elements being reasoned over. That is, to prove that some property,
say P, holds for all elements in an inductively deﬁned set, we (i) show that it
holds for the initial elements, and (ii) show that P is preserved in the inductive
generation of new elements. A side-eﬀect of such implementations is that in
applying inductive reasoning, the induction invariant must be provided explicitly.
While advanced provers oﬀer powerful facilities for producing and manipulating
inductive goals, this still poses a major automation challenge. This formalization
of the induction principle uses the classical notion of formal proofs invoked in
standard theorem provers. There, proofs are well-founded trees, starting at the
goal and reaching axioms while proceeding by applications of inference rules.
A more robust and natural alternative formalization of inductive reasoning
is implicit induction, which avoids the need for explicitly specifying induction
invariants. This form of reasoning is enabled by extending the standard notion
of well-founded, ﬁnite proof trees into non-well-founded proof trees, where the
presence of cycles can be exploited instead of cluttering the proof with explicit
inductive invariants. For example, to prove P(x) using implicit induction, one
repeatedly decomposes the goal into subgoals that are either provable in the
standard way (via well-founded subtrees) or reducible back to P(x). This alter-
native has deep historic roots (originating in Fermat’s inﬁnite-descent method)
and recently has seen a ﬂourishing of its proof theory via cyclic proof systems.
Non-well-founded proof theory and its cyclic fragment (comprising only of
ﬁnite and regular proofs) have been extremely successful in recent years in sup-
porting implicit inductive reasoning. For one, the non-well-founded approach has
been used to obtain (optimal) cut-free completeness results for highly expressive
logics, such as the μ-calculus [3,35,34,37] and Kleene algebra [32,33], providing
further evidence of its utility for automation. Other works focus on the structural
proof theory of non-well-founded systems, where these promote additional insights
into standard proof-theoretical questions by separating local steps of deductive
inference from global well-foundedness arguments. In particular, syntactic cut
elimination for non-well-founded systems has been studied extensively in the
linear logic settings [41,7]. Much work has been devoted to the formal study of
explicit versus implicit forms of induction in various logical settings including the
μ-calculus [72,75,7,62], systems for arithmetics [74,31], and ﬁrst-order logics with
inductive deﬁnitions [19,14,19]. The latter oﬀers a system parameterized by a set

Non-well-founded Deduction for Induction and Coinduction
5
of inductive predicates with associated rules, rather than a single rule for induc-
tion as with the others. The cyclic machinery has also been used to eﬀectively
search for proofs of inductive properties and automatically verify properties of
inductive programs, especially in the context of separation logic [78,68,16,17,18].
Unlike induction, the coinduction principle has not been so fully and nat-
urally incorporated into major theorem provers, but it has gained importance
and attention in recent years. As noted by Basold, Komendantskaya, and Li:
“it may be surprising that automated proof search for coinductive predicates in
ﬁrst-order logic does not have a coherent and comprehensive theory, even after
three decades...” [8]. Automated provers, to the best of our knowledge, cur-
rently do not oﬀer any support for coinduction, and while coinductive data types
have been implemented in interactive theorem provers (a.k.a. proof assistants)
such as Coq [11,47,83], Nuprl [30], Isabelle [13,81,12,38], Agda [1], Lean [4],
and Dafny [54], the treatment of these forms of data is often partial. These
formalizations, as well as other formal frameworks that support the combina-
tion of induction and coinduction, e.g., [80,61,6,46], generally rely on making
(co)invariants explicit within proofs. But just as inductive reasoning is naturally
captured via proof cycles, cyclic systems seem to be particularly well-suited
for also encompassing the implicit notion of coinduction. Nonetheless, while
non-well-founded proof theory has been very successful in supporting inductive
reasoning, this proof method has not been equally incorporated and explored
in the context of coinductive reasoning. Some notable cyclic systems that do
support coinduction in various settings include [67,58,72,36,2]. Another related
framework is that of Coq’s parameterized coinduction [47,83], which oﬀers a
diﬀerent, but highly related, implicit nature of proofs (based on patterns within
parameters, rather than within proof sequents).
This paper reviews the general method of non-well-founded proof theory,
focusing on its use in capturing both implicit inductive and coinductive reasoning.
Throughout the paper we focus on one very natural and simple logical framework
to demonstrate the beneﬁts of the approach—that of the transitive (co)closure
logic. This logic oﬀers a succinct and intuitive dual treatment to induction and
coinduction, while still supporting their common practices in deduction, making
it great for prototyping. More speciﬁcally, it has the beneﬁts of (1) conciseness: no
need for a separate language or interpretation for deﬁnitions, nor for fully general
least/greatest-ﬁxed-point operators; (2) intuitiveness: the concept of transitive
closure is basic, and the dual closure is equally simple to grasp, resulting in
a simpler metatheory; (3) illumination: similarities, dualities, and diﬀerences
between induction and coinduction are clearly demonstrated; and (4) naturality:
local reasoning is rudimentary, and the global structure of proofs directly reﬂects
higher-level reasoning. The framework presented is based on ongoing work by
Reuben Rowe and the author, some of which can be found in [26,29,28,23]. We
conclude the paper by brieﬂy discussing two major open research questions
in the ﬁeld of non-well-founded theory: namely, the need for a user-friendly
implementation of the method into modern proof assistants, in order to make it
applicable and to facilitate advancements in automated proof search and program

6
L. Cohen
veriﬁcation, and the task of determining the precise relationship between systems
for cyclic reasoning and standard systems for explicit reasoning.
2
The Principles of Induction and Coinduction
A duality between the induction principle and the coinduction principle is clearly
observed when formulating them within an algebraic, or categorical, framework.
This section reviews such a general algebraic formalization (Section 2.1), and
then presents transitive (co)closure logic, which will serve as our running example
throughout this paper as it provides simple, yet very intuitive, inductive and
coinductive notions (Section 2.2).
2.1
Algebraic Formalization of Induction and Coinduction
Both the induction principle and the coinduction principle are usually deﬁned
algebraically via the concept of ﬁxed points, where the deﬁnitions vary in diﬀerent
domains such as order theory, set theory or category theory. We opt here for
a set-theoretical representation for the sake of simplicity, but more general
representations, e.g., in a categorical setting, are also well-known [71].
Let Ψ : ℘(D) →℘(D) be a monotone operator on sets for some ﬁxed domain
D (where ℘(D) denotes the power set of D). Since (℘(D), ⊆) is a complete lattice,
by the Knaster–Tarski theorem, both the least-ﬁxed point and greatest-ﬁxed
point of Ψ exist. The least-ﬁxed point (μ) is given by the intersection of all its
preﬁxed points—that is, those sets A satisfying Ψ(A) ⊆A—and, dually, the
greatest-ﬁxed point (ν) is given by the union of all its postﬁxed points—that is,
those sets A satisfying A ⊆Ψ(A). These deﬁnitions naturally yield corresponding
induction and coinduction principles.
Induction Principle:
Ψ(A) ⊆A =⇒μ(Ψ) ⊆A
Coinduction Principle:
A ⊆Ψ(A) =⇒A ⊆ν(Ψ)
The induction principle states that μ(Ψ) is contained in every Ψ-closed set, where
a set A is called Ψ-closed if, for all a ∈A and b ∈D, (a, b) ∈Ψ(A) implies
b ∈A (which means that μ(Ψ) = {A | Ψ(A) ⊆A}). The coinduction principle
dually states that ν(Ψ) contains every Ψ-consistent set, where a set A is called
Ψ-consistent if, for all a ∈A, there is some b ∈D such that both (a, b) ∈Ψ(A)
and b ∈A (which means that ν(Ψ) = {A | A ⊆Ψ(a)}).
The intuition behind an inductively deﬁned set is that of a “bottom-up”
construction. That is, one starts with a set of initial elements and then applies
the constructor operators ﬁnitely many times. One concrete example of an
inductively deﬁned set is that of ﬁnite lists, which can be constructed starting
from the empty list and one constructor operator that adds an element to the
head of the list. The ﬁniteness restriction stems from the fact that induction
is the smallest subset that can be constructed using the operators. Using the
induction principle, one can show that all elements of an inductively deﬁned set
satisfy a certain property, by showing that the property is preserved for each

Non-well-founded Deduction for Induction and Coinduction
7
constructor operator. A coinductively deﬁned set is also constructed by starting
with a set of initial elements and applying the constructor operators, possibly
inﬁnitely many times. One example, which arises from the same initial element
and constructors as the inductive set of lists, is that of possibly inﬁnite lists,
i.e. the set that also contains inﬁnite streams. The fact that we can apply the
operators inﬁnitely many times is due to coinduction being the largest subset
that can (potentially) be constructed using the operators. Using the coinduction
principle, one can show that an element is in a coinductively deﬁned set.
2.2
Transitive (Co)closure Operators
Throughout the paper we will use two instances of ﬁxed points that provide a
minimal framework which captures applicable forms of inductive and coinductive
reasoning in an intuitive manner, and is more amenable for automation than
the full theory of ﬁxed points. This section introduces these ﬁxed points and
discusses the logical framework obtained by adding them to ﬁrst-order logic.
Deﬁnition 1 ((Post-)Composition Operator). Given a binary relation, X,
ΨX is an operator on binary relations that post-composes its input with X, that
is ΨX(R) = X ∪(X ◦R) = {(a, c) | (a, c) ∈X ∨∃b . (a, b) ∈X ∧(b, c) ∈R}.
Because unions and compositions are monotone operators over a complete
lattice, so are composition operators, and therefore both μ(ΨX) and ν(ΨX) exist.
A pair of elements, (a, b), is in μ(ΨX) when b is in every X-closed set that can be
reached by some X-steps from a, which is equivalent to saying that there is a ﬁnite
(non-empty) chain of X steps from a to b. A pair of elements, (a, b), is in ν(ΨX)
when there exists a set A that contains a such that the set A\{b} is X-consistent,
which is equivalent to saying that either there is a ﬁnite (non-empty) chain of X
steps from a to b, or there is an inﬁnite chain of X steps starting from a.
The μ(ΨX) operator is in fact the standard transitive closure operator. Extend-
ing ﬁrst-order logic (FOL) with the addition of this transitive closure operator
results in the well-known transitive closure logic (a.k.a. ancestral logic), a generic,
minimal logic for expressing ﬁnitary1 inductive structures [48,73,5,24,25,23].
Transitive closure (TC) logic was recently extended with a dual operator, called
transitive co-closure, that corresponds to ν(ΨX) [27]. The deﬁnition below presents
the syntax and semantics of the extended logic, called Transitive (co)Closure
logic, or TcC logic.
Deﬁnition 2 (TcC Logic). For σ a ﬁrst-order signature, let s, t and P range
over terms and predicate symbols over σ (respectively), and let M be a structure
for σ, and ν a valuation in M.
Syntax. The language LT cC (over σ) is given by the following grammar:
ϕ, ψ ::= s = t | P(t1, . . . , tn) | ¬ϕ | ϕ ∧ψ | ϕ ∨ψ | ϕ →ψ | ∀x . ϕ | ∃x . ϕ |
(TC x,y ϕ)(s, t) | (TC op
x,y ϕ)(s, t)
1 See [40] for a formal deﬁnition of “ﬁnitary” inductive deﬁnitions.

8
L. Cohen
where the variables x, y in the formulas (TC x,y ϕ)(s, t) and (TC op
x,y ϕ)(s, t)
are distinct and are bound in the subformula ϕ.
Semantics. The satisfaction relation M, ν |= ϕ extends the standard satisfaction
relation of classical ﬁrst-order logic with the following clauses:
M, ν |= (TC x,y ϕ)(s, t) ⇔
∃(di)i≤n . d1 = ν(s) ∧dn = ν(t) ∧∀i < n . M, ν[x := di, y := di+1] |= ϕ
M, ν |= (TC op
x,y ϕ)(s, t) ⇔
∃(di)i>0 . d1 = ν(s) ∧∀i > 0 . di = ν(t) ∨M, ν[x := di, y := di+1] |= ϕ
where ν[x1 := dn, . . . , xn := dn] denotes the valuation that maps xi to di and
behaves as ν otherwise; ϕ

t1
x1 , . . . , tn
xn

denotes simultaneous substitution;
and (di)i≤n and (di)i>0 denote, respectively, non-empty ﬁnite and (countably)
inﬁnite sequences of elements from the domain.
Intuitively, the formula (TC x,y ϕ)(s, t) asserts that there is a (possibly empty)
ﬁnite ϕ-path from s to t, while the formula (TC op
x,y ϕ)(s, t) asserts that either
there is a (possibly empty) ﬁnite ϕ-path from s to t, or an inﬁnite ϕ-path starting
at s. For simplicity of presentation we take here the reﬂexive forms of the closure
operators, which yields the following correspondence.2
Proposition 1. Let [[ϕ]]M,ν
x,y := {(a, b) | M, ν[x := a, y := b] |= ϕ}.
(i) M, ν |= (TC x,y ϕ)(s, t)
⇔
ν(s) = ν(t) or (ν(s), ν(t)) ∈μ(Ψ[[ϕ]]M,ν
x,y ).
(ii) M, ν |= (TC op
x,y ϕ)(s, t)
⇔
ν(s) = ν(t) or (ν(s), ν(t)) ∈ν(Ψ[[ϕ]]M,ν
x,y ).
Note that, unlike the situation in standard ﬁxed-point logics, the two closure
operators are not inter-deﬁnable. The TC operator is deﬁnable in arithmetics
(i.e. in Peano Arithmetics, PA), but the TC op operator is not.
Thus, TcC logic is subsumed by ﬁxed-point logics, such as the ﬁrst-order
μ-calculus [64], but the concept of the transitive (co)closure is intuitively simpler
than that of general ﬁxed-point operators, and it does not require any syntactic
restrictions to ensure monotonicity. In fact, due to its complexity and generality,
the investigation of the full ﬁrst-order μ-calculus tends to focus only on variants
and fragments, and is mainly concentrated on the logical and model-theoretic
aspects, lacking a comprehensive proof theory.3Another reason for focusing on
these (co)closure operators is that they allow for the embedment of many forms of
inductive and coinductive reasoning within one concise logical framework. Thus,
while other extensions of FOL with inductive deﬁnitions are a priori parametrized
by a set of inductive deﬁnitions [59,60,79,19], bespoke induction principles do
2 The deﬁnition of the post-composition operator can be reformulated to incorporate
the reﬂexive case, however, we opt to keep the more standard deﬁnition.
3 Proof theory has been developed for the propositional modal μ-calculus fragment [51],
and recently also for matching μ-logic [20,21,22] which generalizes the μ-calculus.

Non-well-founded Deduction for Induction and Coinduction
9
not need to be added to TcC logic; instead, applicable (co)induction schemes are
available within a single, uniﬁed language. This conciseness allows the logic to
be formally captured using one ﬁxed set of inference rules, and thus makes it
particularly amenable for automation. Moreover, in TcC logic, the same signature
is shared for both inductive and coinductive data, making certain aspects of the
relationship between the two principles more apparent.
Deﬁning inﬁnite structures via the coclosure operators in TcC logic leads to a
symmetric foundation for functional languages where inductive and coinductive
data types can be naturally mixed. For example, using the standard list con-
structors (the constant nil and the (inﬁx) binary function symbol ‘::’) and their
axiomatization, the collections of ﬁnite lists, possibly inﬁnite lists, and inﬁnite
lists (i.e., streams) are straightforwardly deﬁnable as follows.
List(σ) := (TC x,y ∃a. x = a :: y)(σ, nil)
List∞(σ) := (TC op
x,y ∃a. x = a :: y)(σ, nil)
Stream(σ) := (TC op
x,y ∃a. x = a :: y ∧y ̸= nil)(σ, nil) ∧σ ̸= nil
TcC logic also naturally captures properties of, and functions on, streams [29].
3
Non-well-founded Deduction for Induction
This section presents the general method of non-well-founded proof theory (Sec-
tion 3.1), and then provides a concrete example of a non-well-founded proof
system for inductive reasoning in the setting of the transitive closure (Section 3.2),
where the implicit form of inductive reasoning is then compared against the
explicit one. Note that this section ﬁrst presents the proof theory only for TC
logic, which is the inductive fragment of TcC logic, i.e., the one based only on
the transitive closure operator.
3.1
Non-well-founded Proof Theory
The method of non-well-founded proofs provides an alternative approach to
explicit inductive reasoning by exploiting the fact that there are no inﬁnite
descending chains of elements of well-ordered sets. Clearly, not all non-well-
founded proof trees constitute a valid proof, i.e. a proof of the validity of the
conclusion in the root. A proof tree that simply has one loop over the conclusion
or one that repeatedly uses the substitution or permutation rules to obtain cycles
are examples of non-well-founded proof trees that one would not like to consider
as valid. Thus, a non-well-founded proof tree is allowed to be inﬁnite, but to
be considered as a valid proof, it has to obey an additional requirement that
prevents such unsound deductions. Hence, non-well-founded proofs are subject to
the restriction that every inﬁnite path in the proof admits some inﬁnite descent.
Intuitively, the descent is witnessed by tracing syntactic elements, terms or
formulas, for which we can give a correspondence with elements of a well-founded
set. In this respect, non-well-founded proof theory enables a separation between

10
L. Cohen
local steps of deductive inference and global well-foundedness arguments, which
are encoded in traces of terms or formulas through possibly inﬁnite derivations.
Below we present proof systems in the style of sequent calculus. Sequents are
expressions of the form Γ ⇒Δ, for ﬁnite sets of formulas Γ and Δ. We write Γ, ϕ
as a shorthand for Γ ∪{ϕ}, and fv(Γ) for the set of free variables of the formulas
in Γ. A sequent Γ ⇒Δ is valid if and only if the formula 
ϕ∈Γ ϕ →
ψ∈Δ ψ is.
Let S be a collection of inference rules. First, we deﬁne the notion of a
non-well-founded proof tree, a pre-proof, based on S.
Deﬁnition 3 (Pre-proofs). A pre-proof in S is a possibly inﬁnite derivation
tree formed using the inference rules of S. A path in a pre-proof is a possibly
inﬁnite sequence of sequents, s0, s1, . . . (, sn), such that s0 is the root sequent of
the proof, and si+1 is a premise of si in the derivation tree for each i < n.
As mentioned, not every pre-proof is a proof: only those in which there is some
notion of inﬁnite descent in every inﬁnite branch, which allows one to formalize
inductive arguments. To make this concrete, one picks some syntactic element,
which can be formulas or terms, to be tracked through a pre-proof. We call such
elements traced elements. The intuition behind picking the traced elements is that
eventually, when we are given a pre-proof, we could trace these elements through
the inﬁnite branches, and map them into some well-founded set. This is what
underpins the soundness of the non-well-founded method, as explained below.
Given certain traced elements, we inductively deﬁne a notion of trace pairs which
corresponds to the appearances of such traced elements within applications of
the inference rules throughout the proof. That is, for traced elements, τ, τ ′, and a
rule with conclusion s and a premise s′ such that τ appears in s and τ ′ appears
in s′, (τ, τ ′) is said to be a trace pair for (s, s′) for certain rule applications,
and there has to be at least one case identiﬁed as a progressing trace pair. The
progression intuitively stands for the cases in which the elements of the trace pair
are mapped to strictly decreasing elements of the well-founded set. We provide a
concrete example of traced elements and a trace pair deﬁnition in the transitive
closure setting in Section 3.2.
Deﬁnition 4 (Traces). A trace is a (possibly inﬁnite) sequence of traced el-
ements. We say that a trace τ1, τ2, . . . (, τn) follows a path s1, s2, . . . (, sm) in a
pre-proof P if, for some k ≥0, each consecutive pair of formulas (τi, τi+1) is a
trace pair for (si+k, si+k+1). If (τi, τi+1) is a progressing pair, then we say that
the trace progresses at i, and we say that the trace is inﬁnitely progressing if it
progresses at inﬁnitely many points.
Proofs, then, are pre-proofs which satisfy a global trace condition.
Deﬁnition 5 (Inﬁnite Proofs). A proof is a pre-proof in which every inﬁnite
path is followed by some inﬁnitely progressing trace.
We denote by S∞the non-well-founded proof system based on the rules in S.
The general soundness argument for such inﬁnite systems follows from a
combination of standard local soundness of the inference rules in S together

Non-well-founded Deduction for Induction and Coinduction
11
(TC ref )
Γ ⇒Δ, (TC x,y ϕ)(s, s)
Γ ⇒Δ, ϕ { s
x, r
y}
Γ ⇒Δ, (TC x,y ϕ)(r, t)
(TC R)
Γ ⇒Δ, (TC x,y ϕ)(s, t)
Γ, s = t ⇒Δ
Γ, ϕ { s
x, z
y}, (TC x,y ϕ)(z, t) ⇒Δ
(TC im
L )
Γ, (TC x,y ϕ)(s, t) ⇒Δ
Γ, ψ(x), ϕ(x, y) ⇒Δ, ψ {
y
x}
(TC ex
L )
Γ, ψ { s
x}, (TC x,y ϕ)(s, t) ⇒Δ, ψ
 t
x

where in (TC im
L ), z ̸∈fv(Γ, Δ, (TC x,y ϕ)(s, t)), and in (TC ex
L ), x ̸∈fv(Γ, Δ) and y ̸∈fv(Γ, Δ, ψ).
Fig. 1: Proof rules for the TC operator
with a global soundness argument via an inﬁnite descent-style construction, due
to the presence of inﬁnitely progressing traces for each inﬁnite path in a proof.
One assumes for contradiction that the conclusion of the proof is invalid, which,
by the local soundness of the rules, entails the existence of an inﬁnite sequence
of counter-models, going along an inﬁnite branch. Then, one demonstrates a
mapping of these models into a well-founded set, (D, <), which decreases while
following the sequence of counter-models, and strictly decreases when going
over progression points. But then, by the global trace condition, there exists an
inﬁnitely descending chain in D, which of course yields a contradiction.
While a full inﬁnitary proof system is clearly not eﬀective, eﬀectiveness can
be obtained by restricting consideration to the cyclic proofs, i.e., those that are
ﬁnitely representable. These are the regular inﬁnite proof trees, which contain
only ﬁnitely many distinct subtrees. Intuitively, the cycles in the proofs capture
the looping nature of inductive arguments and, thereby, the cyclic framework
provides the basis for an eﬀective system for automated inductive reasoning. A
possible way of formalizing such proof graphs is as standard proof trees containing
open nodes, called buds, to each of which is assigned a syntactically equal internal
node of the proof, called a companion (see, e.g., [19, Sec.7] for a formal deﬁnition).
Deﬁnition 6 (Cyclic Proofs). The cyclic proof system Sω is the subsystem
of S∞comprising of all and only the ﬁnite and regular inﬁnite proofs (i.e., those
proofs that can be represented as ﬁnite, possibly cyclic, graphs).
3.2
Explicit vs. Implicit Induction in Transitive Closure Logic
Since we focus on the formal treatment of induction in this section, we here
present the proof systems for TC logic, i.e., the logic comprising only the TC
operator extension. Both proof systems presented are extensions of LK=, the
sequent calculus for classical ﬁrst-order logic with equality [44]. 4
Figure 1 presents proof rules for the TC operator. Rules (TC ref ), (TC R)
assert the reﬂexivity and the transitivity of the TC operator, respectively. Rule
4 Here LK= includes a substitution rule, which was not a part of the original systems.

12
L. Cohen
(TC ex
L ) can be intuitively read as follows: if the extension of ψ is ϕ-closed, then
it is also closed under the reﬂexive transitive closure of ϕ. Rule (TC im
L ) is in
a sense a case-unfolding argument, stating that to prove something about the
reﬂexive transitive closure of ϕ, one must prove it for the base case (i.e., s = t)
and also prove it for one arbitrary decomposition step (i.e., where the ϕ-path is
decomposed to the ﬁrst step and the remaining path).
The explicit (well-founded) proof system STC is based on rules (TC ref ), (TC R)
and (TC ex
L ). The implicit (non-well-founded) proof system S∞
TC is based on rules
(TC ref ), (TC R) and (TC im
L ), and its cyclic subsystem is denoted by Sω
TC. In S∞
TC,
the traced elements are TC formulas on the left-hand side of the sequents, and
the points of progression are highlighted in blue in Figure 1. The soundness of
the S∞
TC system is then underpinned by mapping each model of an TC formula
of the form (TC x,y ϕ)(s, t) to the minimal length of the ϕ-path between s and t.
Rules (TC ex
L ) and (TC im
L ) both oﬀer a uniﬁed treatment of inductive reason-
ing, in the sense that bespoke induction principles do not need to be added to
the systems. A big advantage of the implicit system is that it can ameliorate
the major challenge in automating inductive reasoning of ﬁnding the induction
invariant a priori. Indeed, a major diﬀerence between these two induction rules
is the presence of the induction invariant. In (TC ex
L ), unlike in (TC im
L ), there is
an explicit appearance of the induction invariant, namely ψ. Instead, in S∞
TC, the
induction invariant, which is often stronger than the goal one is attempting to
prove, can (usually) be inferred via the cycles in the proof.
Since TC logic subsumes arithmetics, by G¨odel’s result, the system STC, while
sound, is incomplete with respect to the standard semantics.5 Nonetheless, the
full non-well-founded proof system S∞
TC is sound and (cut-free) complete for
TC logic [28,26]. Furthermore, the cyclic subsystem Sω
TC subsumes the explicit
system STC.
4
Adding Coinductive Reasoning
This section extends the non-well-founded proof theory of TC logic from Sec-
tion 3.2 to support the transitive coclosure operator, and thus the full TcC logic
(Section 4.1). We then provide an illustrative example of the use of the resulting
framework, demonstrating its potential for automated proof search (Section 4.2).
4.1
Implicit Coinduction in Transitive (Co)closure Logic
The implicit (non-well-founded) proof system for TcC logic, denoted S∞
TcC, is an
extension of the system S∞
TC, obtained by the addition of the proof rules for the
TC op operator presented in Figure 2. Again, rules (TC op
ref ), (TC op
R ) state the
reﬂexivity and transitivity of the TC op operator, respectively, and rule (TC op
L )
is a case-unfolding argument. However, unlike the case for the TC op operator in
which rule (TC im
L ) can be replaced by a rule that decomposes the path from the
5 STC is sound and complete with respect to a generalized form of Henkin semantics [23].

Non-well-founded Deduction for Induction and Coinduction
13
(TC op
ref )
Γ ⇒Δ, (TC op
x,y ϕ)(s, s)
Γ ⇒Δ, ϕ

s
x, r
y

Γ ⇒Δ, (TC op
x,y ϕ)(r, t)
(TC op
R )
Γ ⇒Δ, (TC op
x,y ϕ)(s, t)
Γ, s = t ⇒Δ
Γ, ϕ

s
x, z
y

, (TC op
x,y ϕ)(z, t) ⇒Δ
(TC op
L )
Γ, (TC op
x,y ϕ)(s, t) ⇒Δ
where in (TC op
L ), z ̸∈fv(Γ, Δ, (TC op
x,y ϕ)(s, t)).
Fig. 2: Proof rules for the TC op operator
end, in rule (TC op
L ) it is critical that the decomposition starts at the ﬁrst step
(as there is no end point). Apart from the additional inference rules, S∞
TcC also
extends the traced elements to include TC op formulas, which are traced on the
right-hand side of the sequents, and the points of progression are highlighted in
pink in Figure 2.
Interestingly, the two closure operators are captured proof-theoretically using
inference rules with the exact same structure. The diﬀerence proceeds from
the way the decomposition of the corresponding formulas is traced in a proof
derivation: for induction, TC formulas are traced on the left-hand sides of the
sequents; for coinduction, TC op formulas are traced on the right-hand sides of
sequents. Thus, traces of TC formulas show that certain inﬁnite paths cannot
exist (induction is well-founded), while traces of TC op formulas show that other
inﬁnite paths must exist (coinduction is productive). This formation of the rules
for the (co)closure operators is extremely useful with respect to automation, as
the rules are locally uniform, thus enabling the same treatment for induction
and coinduction, but are also globally dual, ensuring that the underlying system
handles them appropriately (at the limit). Also, just like the case for induction,
the coinduction invariant is not explicitly mentioned in the inference rules.
The full non-well-founded system S∞
TcC is sound and (cut-free) complete with
respect to the semantics of TcC logic [27]. It has been shown to be powerful enough
to capture non-trivial examples of mixed inductive and coinductive reasoning
(such as the transitivity of the substream relation), and to provide a smooth
integration of induction and coinduction while also highlighting their similarities.
To exemplify the naturality of the system, Figure 3 demonstrates a proof that
the transitive closure is contained within the transitive co-closure. The proof has
a single cycle (and thus a single inﬁnite path), but, following this path, there is
both a trace, consisting of the TC formulas highlighted in blue, and a co-trace,
consisting of the TC op formulas highlighted in pink (the progression points are
marked with boxes). Thus, the proof can be seen both as a proof by induction
and as a proof by coinduction.
4.2
Applications in Automated Proof Search
The cyclic reasoning method seems to have enormous potential for the automation
of (co)inductive reasoning, which has not been fully realized. Most notably, as

14
L. Cohen
(TCop
ref )
⇒(TC op
x,y ϕ)(u, u)
(Eq)
u = v ⇒(TC op
x,y ϕ)(u, v)
.
.
.
.
.
.
.
.
(Ax)
ϕ

u
x , w
y

, (TC x,y ϕ)(w, v) ⇒ϕ

u
x , w
y

(TC x,y ϕ)(u, v) ⇒(TC op
x,y ϕ)(u, v)
(Sub)
(TC x,y ϕ)(w, v) ⇒(TC op
x,y ϕ)(w, v)
(Wk)
ϕ

u
x , w
y

, (TC x,y ϕ)(w, v) ⇒
(TC op
x,y ϕ)(w, v)
(TCop
R )
ϕ

u
x , w
y

, (TC x,y ϕ)(w, v)
⇒(TC op
x,y ϕ)(u, v)
(TCim
L )
(TC x,y ϕ)(u, v) ⇒(TC op
x,y ϕ)(u, v)
Fig. 3: Proof that the TC op operator subsumes the TC operator
mentioned, cyclic systems can facilitate the discovery of a (co)induction invariant,
which is a primary challenge for mechanized (co)inductive reasoning.6 Thus, in
implicit systems, the (co)inductive arguments and hypotheses may be encoded
in the cycles of a proof, in the sense that when developing the proof, one can
start with the goal and incrementally adjust the invariant as many times as
necessary. Roughly speaking, one can perform lazy unfolding of the (co)closure
operators to a point in which a cycle can be obtained, taking advantage of
non-local information retrieved in other branches of the proof.
The implications of these phenomena for proof search can be examined using
proof-theoretic machinery to analyze and manipulate the structures of cyclic
proofs. For example, when verifying properties of mutually deﬁned relations,
the associated explicit (co)induction principles are often extremely complex. In
the cyclic framework, such complex explicit schemes generally correspond to
overlapping cycles. Exploring such connections between hard problems that arise
from explicit invariants and the corresponding structure of cyclic proofs, can
facilitate automated proof search. The cyclic framework oﬀers yet another beneﬁt
for veriﬁcation in that it enables the separation of the two critical properties
of a program, namely liveness (termination) and safety (correctness). Thus,
while proving a safety property (validity of a formula), one can extract liveness
arguments via inﬁnite descent.
4.2.1
Program Equivalence in the TcC Framework
The use of the (co)closure operators in the TcC framework seems to be particularly
well-suited for formal veriﬁcation, as these operators can be used to simultaneously
express the operational semantics of programs and the structure of the (co)data
manipulated by them. Use of the same constructors for both features of the
program constitutes an improvement over current formal frameworks, which
6 Some veriﬁcation approaches can discover inductive invariants automatically [43,45],
or direct their construction based on the property being veriﬁed [63,50], but they do
not currently support coinductive reasoning.

Non-well-founded Deduction for Induction and Coinduction
15
rest
:=
fix rest(f).λn. if n > 0 then (output n; rest f (n −1)) else f 0
f
:=
fix f(n). let v = (output n; input()) ∗2 in (if v ̸= 0 then f else rest f) (v + n)
g
:=
fix g(m). output (2 ∗m); let v = input() in if v = 0 then rest g (2 ∗m) else g (v + n)
RES :=
(TC ⟨u1,u2⟩,⟨v1,v2⟩(u1 > 0 ∧v1 = u1 −1 ∧u2 = u1 :: v2) ∨(u1 = v1 = 0 ∧u2 = v2))(⟨n, s⟩, ⟨0, s′⟩)
ψf := ∃i, w. x2 = i :: w∧
[(i ∗2 ̸= 0 ∧y1 = i ∗2 + x1 ∧w = x1 :: y2) ∨(i = y1 = 0 ∧RES(x1, w, x1 :: y2))]
ψg := ∃i, w. x2 = i :: w∧
[(i ̸= 0 ∧y1 = i + x1 ∧w = (2 ∗x1) :: y2) ∨(i = y1 = 0 ∧RES(2 ∗x1, w, (2 ∗x1) :: y2))]
SPEC :
(TC op
⟨x1,x2⟩,⟨y1,y2⟩ψf)(⟨2 ∗m, s⟩, ⟨⊥, ⊥⟩) ⇐⇒(TC op
⟨x1,x2⟩,⟨y1,y2⟩ψg)(⟨m, s⟩, ⟨⊥, ⊥⟩)
Fig. 4: The recursive programs and their formalization in TcC
usually employ qualitatively diﬀerent formalisms to describe the operational
semantics of programs and the associated data.7 For instance, although many
formalisms employ separation logic to describe the data structures manipulated
by programs (e.g., the Cyclist prover [18]), they also encode the relationships
between the program’s memory and its operational behavior via bespoke symbolic-
execution inference rules [10,65].
To demonstrate the capabilities and beneﬁts of the TcC framework for veriﬁca-
tion and automated proof search, we present the following example, posed in [47,
Sec. 3]. The example consists of proving that the two recursive programs given
in Figure 4 (weakly) simulate one another. Both programs continually read the
next input, compute the double of the sum of all inputs seen so far, and output
the current sum. On input zero, both programs count down to zero and start
over. The goal is to formally verify that g(m) is equivalent to f(2m). However, as
noted in [47], a formal proof of this claim via the standard Tarskian coinduction
principle is extremely laborious. This is mainly because one must come up with
an appropriate “simulation relation” that contains all the intermediate execution
steps of f and g, appropriately matched, which must be fully deﬁned before we
can even start the proof.
The (co)closure operators oﬀer a formalization of the problem which is very
natural and amenable to automation, formalizing the programs by encoding all
(inﬁnite) traces of f and g as streams of input/output events. Hence, the simulation
amounts to the fact that each such stream for f can be simulated by g, and vice
versa. The bottom part of Figure 4 shows the formalization of the speciﬁcation
in TcC logic, where the encoding of each program is a natural simpliﬁcation that
can easily (and automatically) be obtained from either structural operational
semantics or Floyd–Hoare-style axiomatic semantics. We use ⊥as a designated
unreachable element (i.e., an element not related to any other element). The fact
7 Notable exceptions include [66,76,20,21,22], which take a similar approach but invoke
second-order elements.

16
L. Cohen
(⊥inequalities)
⟨2 ∗m, s⟩= ⟨⊥, ⊥⟩⇒(TCop ψg)⊥(⟨m, s⟩)
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(FOL+Arith)
ψf

2m
x1
, s
x2
, z1
y1
, z2
y2

⇒ψg

m
x1
, s
x2
, ?
y1
,
??
y2

(TCop ψf)⊥(⟨2 ∗m, s⟩) ⇒(TCop ψg)⊥(⟨m, s⟩) (Sub)
(TCop ψf)⊥(⟨z1, z2⟩) ⇒
(TCop ψg)⊥(⟨?, ??⟩)
(TCop
R , W k)
ψf

2m
x1
, s
x2
, z1
y1
, z2
y2

, (TCop ψf)⊥(⟨z1, z2⟩) ⇒(TCop ψg)⊥(⟨m, s⟩)
(TCop
L )
(TCop ψf)⊥(⟨2 ∗m, s⟩) ⇒(TCop ψg)⊥(⟨m, s⟩)
···
z1 = i ∗2 + 2m
∧
w = (2m) :: z2
⇒? = i + m
∧
w = (2m) :: ??
.
.
.
.
? := z1/2
?? := z2
Fig. 5: Structure of the proof of one direction of SPEC
that the (co)closure operators can be applied to complex formulas that include,
for example, quantiﬁers, disjunctions and nesting of the (co)closure operators,
enables a concise, natural presentation without resorting to complex case analysis.
This oﬀers a signiﬁcant a priori simpliﬁcation of the formula we provide to the
proof system (and, in turn, to a prover), even before starting the proof-search
procedure.
The cyclic proof system, in turn, enables a natural treatment of the coinduc-
tive reasoning involved in the proof, in a way that is particularly amenable to
automation. Figure 5 outlines the structure of the proof of one direction of the
equivalence deﬁned in SPEC. For conciseness, the subscripts ⟨x1, x2⟩, ⟨y1, y2⟩are
omitted from all TC op formulas and we use (TC op ϕ)⊥(⟨u, v⟩) as a shorthand
for (TC op ϕ)(⟨u, v⟩, ⟨⊥, ⊥⟩). The proof is compact and the local reasoning is
standard: namely, the unfolding of the TC op operator. The proof begins with
a single unfolding of the TC op formula on the left and then proceeds with its
unfolding on the right. The key observation is that the instantiation of the
unfolding on the right (i.e., the choice of the term r in Rule (TC op
R )) can be
automatically inferred from the terms of the left unfolding, by uniﬁcation. Thus,
when applying Rule (TC op
R ), one does not have to guess the intermediate term
(in this case, ⟨z1/2, z2⟩); instead, the term can be automatically inferred from
the equalities in the subproof of the single-step implication, as illustrated by the
green question marks in Figure 5.
Finally, to formally establish the correctness of our simpliﬁed formalization,
one needs to prove that, for example, the abstract RES(n, s, s′) is indeed equivalent
to the concrete program restart on f and on g. This can be formalized and proved
in a straightforward manner, as the proof has a dual structure and contains a TC
cycle. This further demonstrates the compositionality of TcC framework, as such
an inductive subproof is completely independent of the general, outer coinductive
TC op cycle.

Non-well-founded Deduction for Induction and Coinduction
17
5
Perspectives and Open Questions
As mentioned, the approach of non-well-founded proof theory holds great potential
for improving the state-of-the-art in formal support for automated inductive
and coinductive reasoning. But the investigation of cyclic proof systems is far
from complete, and much work is still required to provide a full picture. This
section concludes by describing two key research questions, one concerning
the applicability of the framework and the other concerning the fundamental
theoretical study of the framework.
5.1
Implementing Non-well-founded Machinery
Current theorem provers oﬀer little or no support for implicit reasoning. Thus,
major veriﬁcation eﬀorts are missing its great potential for lighter, more legible
and more automated proofs. The main implementation of cyclic reasoning can be
found in the cyclic theorem prover Cyclist [18], which is a fully automated prover
for inductive reasoning based on the cyclic framework developed in [15,16,19].
Cyclist has been very successful in formal veriﬁcation in the setting of separation
logic. Cyclic inductive reasoning has also been partially implemented into the
Coq proof assistant through the development of external libraries and func-
tional schemas [77]. Both implementations do not support coinductive reasoning,
however.
To guarantee soundness, and decide whether a cyclic pre-proof satisﬁes the
global trace condition, most cyclic proof systems feature a mechanism that
uses a construction involving an inclusion between B¨uchi automata (see, for
example, [15,74]). This mechanism can be (and has been) applied successfully
in automated frameworks, but it lacks the transparency and ﬂexibility that one
needs in interactive theorem proving. For example, encoding proof validity into
B¨uchi automata makes it diﬃcult to understand why a cyclic proof is invalid
in order to attempt to ﬁx it. Therefore, to fully integrate cyclic reasoning into
modern interactive theorem provers in a useful manner, an intrinsic criterion for
soundness must be developed, which does not require the use of automata but
instead operates directly on the proof tree.
5.2
Relative Power of Explicit and Implicit Reasoning
In general, explicit schemes for induction and coinduction are subsumed by their
implicit counterparts. The converse, however, does not hold in general. In [19],
it was conjectured that the explicit and cyclic systems for FOL with inductive
deﬁnitions are equivalent. Later, they were indeed shown to be equivalent when
containing arithmetics [19], where the embedding of the cyclic system in the
explicit one relied on an encoding of the cycles in the proof. However, it was
also shown, via a concrete counter-example, that in the general case the cyclic
system is strictly stronger than the explicit one [9]. But a careful examination of
this counter-example reveals that it only refutes a weak form of the conjecture,
according to which the inductive deﬁnitions available in both systems are the

18
L. Cohen
same. That is, if the explicit system is extended with other inductive predicates,
the counter-example for the equivalence no longer holds. Therefore, the less strict
formulation of the question—namely, whether for any proof in the cyclic system
there is a proof in the explicit system for some set of inductive predicates—has
not yet been resolved. In particular, in the TcC setting, while the equivalence
under arithmetics also holds, the fact that there is no a priori restriction on the
(co)inductive predicates one is allowed to use makes the construction of a similar
counter-example in the general case much more diﬃcult. In fact, the explicit and
cyclic systems may even coincide for TcC logic.
Even in cases where explicit (co)induction can capture implicit (co)induction
(or a fragment of it), there are still open questions regarding the manner in which
this capturing preserves certain patterns. A key question is whether the capturing
can be done while preserving important properties such as proof modularity.
Current discourse contains only partial answers to such questions [75,77,68] which
should be investigated thoroughly and systematically. The uniformity provided
by the closure operators in the TcC setting can facilitate a study of this subtle
relationship between implicit and explicit (co)inductive reasoning.
Acknowledgements. As mentioned in the introduction, the TcC framework is
based on a wonderful ongoing collaboration with Reuben Rowe. The author is also
extremely grateful to Andrei Popescu and Shachar Itzhaky for their contributions
to the framework.
References
1. Andreas Abel and Brigitte Pientka. Well-founded Recursion with Copatterns and
Sized Types. Journal of Functional Programming, 26:e2, 2016.
2. Bahareh Afshari and Graham E. Leigh. Circular Proofs for the Modal Mu-Calculus.
Pamm, 16:893–894, 2016.
3. Bahareh Afshari and Graham E. Leigh. Cut-free Completeness for Modal Mu-
calculus. In Proceedings of the 32nd Annual ACM/IEEE Symposium on Logic in
Computer Science, LICS 2017, pages 1–12, 2017.
4. Jeremy Avigad, Mario Carneiro, and Simon Hudon. Data Types as Quotients of
Polynomial Functors. In J. Harrison, J. O’Leary, and A. Tolmach, editors, 10th
International Conference on Interactive Theorem Proving (ITP ’19), volume 141 of
Leibniz International Proceedings in Informatics, pages 6:1–6:19, Dagstuhl, 2019.
5. Arnon Avron. Transitive Closure and the Mechanization of Mathematics. In F. D.
Kamareddine, editor, Thirty Five Years of Automating Mathematics, volume 28 of
Applied Logic Series, pages 149–171. Springer, Netherlands, 2003.
6. David Baelde. Least and Greatest Fixed Points in Linear Logic. ACM Trans.
Comput. Logic, 13(1):2:1–2:44, Jan 2012.
7. David Baelde, Amina Doumane, and Alexis Saurin. Inﬁnitary Proof Theory: the
Multiplicative Additive Case. In Proceedings of the 25th EACSL Annual Conference
on Computer Science Logic, CSL 2016, pages 42:1–42:17, 2016.
8. Henning Basold, Ekaterina Komendantskaya, and Yue Li. Coinduction in Uniform:
Foundations for Corecursive Proof Search with Horn Clauses. In L. Caires, editor,
Programming Languages and Systems, pages 783–813, Cham, 2019.

Non-well-founded Deduction for Induction and Coinduction
19
9. Stefano Berardi and Makoto Tatsuta. Classical System of Martin-L¨of’s Inductive
Deﬁnitions Is Not Equivalent to Cyclic Proof System. In Proceedings of the 20th
International Conference on Foundations of Software Science and Computation
Structures, FOSSACS 2017, pages 301–317, Berlin, Heidelberg, 2017.
10. Josh Berdine, Cristiano Calcagno, and Peter W. O’Hearn. Symbolic Execution with
Separation Logic. In K. Yi, editor, Programming Languages and Systems, pages
52–68, Berlin, Heidelberg, 2005.
11. Yves Bertot and Ekaterina Komendantskaya. Inductive and Coinductive Compo-
nents of Corecursive Functions in Coq. Electronic Notes in Theoretical Computer
Science, 203(5):25 – 47, 2008. Proceedings of the Ninth Workshop on Coalgebraic
Methods in Computer Science (CMCS 2008).
12. Jasmin C. Blanchette, Aymeric Bouzy, Andreas Lochbihler, Andrei Popescu, and
Dmitriy Traytel. Friends with Beneﬁts. In H. Yang, editor, Programming Languages
and Systems, pages 111–140, Berlin, Heidelberg, 2017.
13. Jasmin C. Blanchette, Johannes H¨olzl, Andreas Lochbihler, Lorenz Panny, Andrei
Popescu, and Dmitriy Traytel. Truly Modular (Co)datatypes for Isabelle/HOL.
In G. Klein and R. Gamboa, editors, Interactive Theorem Proving, pages 93–110,
Cham, 2014.
14. James Brotherston. Cyclic Proofs for First-Order Logic with Inductive Deﬁnitions.
In Bernhard Beckert, editor, Automated Reasoning with Analytic Tableaux and
Related Methods, pages 78–92, Berlin, Heidelberg, 2005. Springer Berlin Heidelberg.
15. James Brotherston. Formalised Inductive Reasoning in the Logic of Bunched
Implications. In Hanne Riis Nielson and Gilberto Fil´e, editors, Proceedings of Static
Analysis, 14th International Symposium, SAS 2007, Kongens Lyngby, Denmark,
August 22–24, 2007, pages 87–103, 2007.
16. James Brotherston, Richard Bornat, and Cristiano Calcagno. Cyclic Proofs of Pro-
gram Termination in Separation Logic. In Proceedings of the 35th ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages, POPL 2008, pages
101–112, 2008.
17. James Brotherston, Dino Distefano, and Rasmus Lerchedahl Petersen. Automated
Cyclic Entailment Proofs in Separation Logic. In Nikolaj Bjørner and Viorica
Sofronie-Stokkermans, editors, Automated Deduction – CADE-23, pages 131–146,
Berlin, Heidelberg, 2011. Springer Berlin Heidelberg.
18. James Brotherston, Nikos Gorogiannis, and Rasmus L. Petersen. A Generic Cyclic
Theorem Prover. In R. Jhala and A. Igarashi, editors, Programming Languages and
Systems, pages 350–367, Berlin, Heidelberg, 2012.
19. James Brotherston and Alex Simpson. Sequent Calculi for Induction and Inﬁnite
Descent. Journal of Logic and Computation, 21(6):1177–1216, 2010.
20. Xiaohong Chen and Grigore Ro¸su.
Matching μ-Logic.
In 2019 34th Annual
ACM/IEEE Symposium on Logic in Computer Science (LICS), pages 1–13, 2019.
21. Xiaohong Chen and Grigore Ro¸su. Matching μ-Logic: Foundation of K Framework.
In M. Roggenbach and A. Sokolova, editors, 8th Conference on Algebra and Coalgebra
in Computer Science (CALCO), volume 139 of Leibniz International Proceedings in
Informatics, pages 1:1–1:4, Dagstuhl, 2019.
22. Xiaohong Chen, Minh-Thai Trinh, Nishant Rodrigues, Lucas Pe˜na, and Grigore
Ro¸su. Towards A Uniﬁed Proof Framework for Automated Fixpoint Reasoning
Using Matching Logic. In PACMPL Issue OOPSLA 2020, pages 1–29. ACM/IEEE,
Nov 2020.
23. Liron Cohen. Completeness for Ancestral Logic via a Computationally-Meaningful
Semantics. In Renate A. Schmidt and Cl´audia Nalon, editors, Proceedings of the

20
L. Cohen
26th International Conference on Automated Reasoning with Analytic Tableaux and
Related Methods, TABLEAUX 2017, pages 247–260, Cham, 2017.
24. Liron Cohen and Arnon Avron. Ancestral Logic: A Proof Theoretical Study. In
Ulrich Kohlenbach, Pablo Barcel´o, and Ruy de Queiroz, editors, Logic, Language,
Information, and Computation, volume 8652 of Lecture Notes in Computer Science,
pages 137–151. Springer, 2014.
25. Liron Cohen and Arnon Avron. The Middle Ground–Ancestral Logic. Synthese,
196:2671–2693, 2015.
26. Liron Cohen and Reuben N. S. Rowe. Uniform Inductive Reasoning in Transitive
Closure Logic via Inﬁnite Descent. In Proceedings of the 27th EACSL Annual
Conference on Computer Science Logic, CSL 2018, pages 16:1–16:17, 2018.
27. Liron Cohen and Reuben N. S. Rowe. Integrating Induction and Coinduction via
Closure Operators and Proof Cycles. In N. Peltier and V. Sofronie-Stokkermans,
editors, Automated Reasoning, volume 21, pages 375–394, Cham, 2020.
28. Liron Cohen and Reuben N. S. Rowe. Non-Well-Founded Proof Theory of Transitive
Closure Logic. ACM Trans. Comput. Logic, 21(4), August 2020.
29. Liron Cohen, Reuben N. S. Rowe, and Yoni Zohar. Towards Automated Reasoning
in Herbrand Structures. Journal of Logic and Computation, 29(5):693–721, 2019.
30. Robert L. Constable, Stuart F. Allen, and Mark Bromley et al. Implementing
mathematics with the Nuprl proof development system. Prentice-Hall, Inc., Upper
Saddle River, NJ, USA, 1986.
31. Anupam Das. On the logical complexity of cyclic arithmetic. Logical Methods in
Computer Science, Volume 16, Issue 1, January 2020.
32. Anupam Das and Damien Pous.
A Cut-Free Cyclic Proof System for Kleene
Algebra. In Renate A. Schmidt and Cl´audia Nalon, editors, Proceedings of the 26th
International Conference Automated Reasoning with Analytic Tableaux and Related
Methods, TABLEAUX 2017, pages 261–277, 2017.
33. Anupam
Das
and
Damien
Pous.
Non-Wellfounded
Proof
Theory
for
(Kleene+Action)(Algebras+Lattices). In Dan Ghica and Achim Jung, editors,
Proceedings of the 27th EACSL Annual Conference on Computer Science Logic,
CSL 2018, volume 119, pages 19:1–19:18. Schloss Dagstuhl–Leibniz-Zentrum fuer
Informatik, 2018.
34. Christian Dax, Martin Hofmann, and Martin Lange. A Proof System for the
Linear Time μ-Calculus. In S. Arun-Kumar and Naveen Garg, editors, FSTTCS
2006: Foundations of Software Technology and Theoretical Computer Science, pages
273–284, Berlin, Heidelberg, 2006. Springer Berlin Heidelberg.
35. Amina Doumane. Constructive Completeness for the Linear-time μ-calculus. In
Proceedings of the 32nd Annual ACM/IEEE Symposium on Logic in Computer
Science, LICS 2017, pages 1–12, 2017.
36. Amina Doumane. On the Inﬁnitary Proof Theory of Logics with Fixed Points. PhD
thesis, 06 2017.
37. Amina Doumane, David Baelde, Lucca Hirschi, and Alexis Saurin. Towards Com-
pleteness via Proof Search in the Linear Time μ-Calculus: The Case of B¨uchi
Inclusions. In Proceedings of the 31st Annual ACM/IEEE Symposium on Logic in
Computer Science, LICS ’16, page 377–386, New York, NY, USA, 2016. Association
for Computing Machinery.
38. S´olr´un Halla Einarsd´ottir, Moa Johansson, and Johannes ˚Aman Pohjola. Into the
Inﬁnite - Theory Exploration for Coinduction. In Jacques Fleuriot, Dongming Wang,
and Jacques Calmet, editors, Artiﬁcial Intelligence and Symbolic Computation, pages
70–86, Cham, 2018. Springer International Publishing.

Non-well-founded Deduction for Induction and Coinduction
21
39. J¨org Endrullis, Helle Hvid Hansen, Dimitri Hendriks, Andrew Polonsky, and Alexan-
dre Silva. Coinductive Foundations of Inﬁnitary Rewriting and Inﬁnitary Equational
Logic. Logical Methods in Computer Science, Volume 14, Issue 1, January 2018.
40. Solomon Feferman. Finitary Inductively presented Logics. Studies in Logic and the
Foundations of Mathematics, 127:191–220, 1989.
41. J´erˆome Fortier and Luigi Santocanale. Cuts for Circular Proofs: Semantics and
Cut-elimination. In S. Ronchi D. Rocca, editor, Computer Science Logic 2013
(CSL 2013), volume 23 of Leibniz International Proceedings in Informatics (LIPIcs),
pages 248–262, Dagstuhl, Germany, 2013.
42. Vladimir Gapeyev, Michael Y Levin, and Benjamin C Pierce. Recursive Subtyping
Revealed. Journal of Functional Programming, 12(6):511–548, 2002.
43. Pranav Garg, Christof L¨oding, P Madhusudan, and Daniel Neider. ICE: A Robust
Framework for Learning Invariants. In Armin Biere and Roderick Bloem, editors,
International Conference on Computer Aided Veriﬁcation, pages 69–87, Cham, 2014.
Springer, Springer International Publishing.
44. Gerhard Gentzen. Untersuchungen ¨uber das Logische Schließen. I. Mathematische
Zeitschrift, 39(1):176–210, 1935.
45. Arie Gurﬁnkel and Alexander Ivrii. K-Induction without Unrolling. In Proceedings
of the 17th Conference on Formal Methods in Computer-Aided Design, FMCAD
’17, page 148–155, Austin, Texas, 2017. FMCAD Inc.
46. Quentin Heath and Dale Miller. A Proof Theory for Model Checking. J. Autom.
Reasoning, 63(4):857–885, 2019.
47. Chung-Kil Hur, Georg Neis, Derek Dreyer, and Viktor Vafeiadis. The Power of
Parameterization in Coinductive Proof. In Proceedings of the 40th Annual ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL
’13, page 193–206, New York, NY, USA, 2013.
48. Neil Immerman. Languages that Capture Complexity Classes. SIAM Journal on
Computing, 16(4):760–778, 1987.
49. Bart Jacobs and Jan Rutten. A Tutorial on (Co) Algebras and (Co) Induction.
Bulletin of the European Association for Theoretical Computer Science, 62:222–259,
1997.
50. Aleksandr Karbyshev, Nikolaj Bjørner, Shachar Itzhaky, Noam Rinetzky, and
Sharon Shoham. Property-Directed Inference of Universal Invariants or Proving
Their Absence. J. ACM, 64(1), March 2017.
51. Dexter Kozen. Results on the Propositional μ-Calculus. In M. Nielsen and E. M.
Schmidt, editors, Automata, Languages and Programming, pages 348–359, Berlin,
Heidelberg, 1982.
52. Dexter Kozen and Alexandra Silva. Practical Coinduction. Mathematical Structures
in Computer Science, 27(7):1132–1152, 2017.
53. Clemens Kupke and Jurriaan Rot. Expressive Logics for Coinductive Predicates.
In M. Fern´andez and A. Muscholl, editors, 28th EACSL Annual Conference on
Computer Science Logic (CSL 2020), volume 152 of Leibniz International Proceedings
in Informatics, pages 26:1–26:18, Dagstuhl, 2020.
54. Rustan Leino and Michal Moskal. Co-Induction Simply: Automatic Co-Inductive
Proofs in a Program Veriﬁer.
Technical Report MSR-TR-2013-49, Microsoft
Research, July 2013.
55. Xavier Leroy.
A Formally Veriﬁed Compiler Back-End.
J. Autom. Reason.,
43(4):363–446, December 2009.
56. Xavier Leroy and Herv´e Grall.
Coinductive Big-Step Operational Semantics.
Information and Computation, 207(2):284–304, 2009.

22
L. Cohen
57. Thomas Letan and Yann R´egis-Gianas. Freespec: Specifying, verifying, and ex-
ecuting impure computations in coq. In Proceedings of the 9th ACM SIGPLAN
International Conference on Certiﬁed Programs and Proofs, CPP 2020, page 32–46,
New York, NY, USA, 2020. Association for Computing Machinery.
58. Dorel Lucanu and Grigore Ro¸su.
CIRC: A Circular Coinductive Prover.
In
Till Mossakowski, Ugo Montanari, and Magne Haveraaen, editors, International
Conference on Algebra and Coalgebra in Computer Science, pages 372–378. Springer,
2007.
59. Per Martin-L¨of. Hauptsatz for the Intuitionistic Theory of Iterated Inductive
Deﬁnitions. In J. E. Fenstad, editor, Proceedings of the Second Scandinavian Logic
Symposium, volume 63 of Studies in Logic and the Foundations of Mathematics,
pages 179–216. Elsevier, 1971.
60. Raymond McDowell and Dale Miller. Cut-elimination for a Logic with Deﬁnitions
and Induction. Theoretical Computer Science, 232(1-2):91–119, 2000.
61. Alberto Momigliano and Alwen Tiu. Induction and Co-Induction in Sequent Calcu-
lus. In Stefano Berardi, Mario Coppo, and Ferruccio Damiani, editors, International
Workshop on Types for Proofs and Programs, pages 293–308. Springer, 2003.
62. R´emi Nollet, Christine Tasson, and Alexis Saurin. PSPACE-Completeness of a
Thread Criterion for Circular Proofs in Linear Logic with Least and Greatest Fixed
Points. In Serenella Cerrito and Andrei Popescu, editors, Proceedings of the 27th
International Conference on Automated Reasoning with Analytic Tableaux and
Related Methods, TABLEAUX 2019, pages 317–334. Springer, 2019.
63. Oded Padon, Kenneth L. McMillan, Aurojit Panda, Mooly Sagiv, and Sharon
Shoham. Ivy: Safety Veriﬁcation by Interactive Generalization. In Proceedings
of the 37th ACM SIGPLAN Conference on Programming Language Design and
Implementation, PLDI ’16, page 614–630, NY, USA, 2016.
64. David Michael Ritchie Park. Finiteness is Mu-Ineﬀable. Theor. Comput. Sci.,
3(2):173–181, 1976.
65. John C. Reynolds. Separation Logic: A Logic for Shared Mutable Data Structures.
In Proceedings 17th Annual IEEE Symposium on Logic in Computer Science, pages
55–74. IEEE, 2002.
66. Grigore Ro¸su, Andrei Stefanescu, Stefan Ciobˆaca, and Brandon M. Moore. One-
Path Reachability Logic. In Proceedings of the 28th Annual ACM/IEEE Symposium
on Logic in Computer Science, LICS ’13, page 358–367, USA, 2013.
67. Grigore Ro¸su and Dorel Lucanu.
Circular Coinduction: A Proof Theoretical
Foundation. In Alexander Kurz, Marina Lenisa, and Andrzej Tarlecki, editors,
Proceedings of Algebra and Coalgebra in Computer Science, CALCO’09, pages
127–144. Springer, 2009.
68. Reuben N. S. Rowe and James Brotherston. Automatic Cyclic Termination Proofs
for Recursive Procedures in Separation Logic. In Proceedings of the 6th ACM
SIGPLAN Conference on Certiﬁed Programs and Proofs, CPP 2017, Paris, France,
January 16–17, 2017, pages 53–65, 2017.
69. Jan Rutten. Universal Coalgebra: a Theory of Systems. Theoretical computer
science, 249(1):3–80, 2000.
70. Jan Rutten. The Method of Coalgebra: Exercises in Coinduction. Amsterdam: CWI,
Netherlands, 2019.
71. Davide Sangiorgi and Jan Rutten. Advanced Topics in Bisimulation and Coinduc-
tion. Cambridge University Press, USA, 1st edition, 2011.
72. Luigi Santocanale. A Calculus of Circular Proofs and Its Categorical Semantics. In
Mogens Nielsen and Uﬀe Engberg, editors, Proceedings of the 5th International Con-

Non-well-founded Deduction for Induction and Coinduction
23
ference on Foundations of Software Science and Computation Structures, FOSSACS
2002, pages 357–371, Berlin, Heidelberg, 2002. Springer Berlin Heidelberg.
73. Stewart Shapiro. Foundations without Foundationalism: A Case for Second-order
Logic, volume 17. Clarendon Press, 1991.
74. Alex Simpson. Cyclic Arithmetic Is Equivalent to Peano Arithmetic. In Proceedings
of the 20th International Conference on Foundations of Software Science and
Computation Structures - Volume 10203, page 283–300, Berlin, Heidelberg, 2017.
75. Christoph Sprenger and Mads Dam. On the Structure of Inductive Reasoning:
Circular and Tree-shaped Proofs in the μ-Calculus. In Proceedings of Foundations
of Software Science and Computational Structures, 6th International Conference,
FOSSACS 2003, pages 425–440, 2003.
76. Andrei S¸tef˘anescu, S¸tefan Ciobˆac˘a, Radu Mereuta, Brandon M. Moore, Traian Florin
S¸erb˘anut˘a, and Grigore Ro¸su. All-Path Reachability Logic. In G. Dowek, editor,
Rewriting and Typed Lambda Calculi, pages 425–440, Cham, 2014.
77. Sorin Stratulat. Structural vs. Cyclic Induction: A Report on Some Experiments
with Coq.
In 2016 18th International Symposium on Symbolic and Numeric
Algorithms for Scientiﬁc Computing (SYNASC), pages 29–36, 2016.
78. Gadi Tellez and James Brotherston. Automatically Verifying Temporal Properties
of Pointer Programs with Cyclic Proof. In Proceedings of the 26th International
Conference on Automated Deduction, CADE 26, Gothenburg, Sweden, August 6–11,
2017, pages 491–508, 2017.
79. Alwen Tiu. A Logical Framework For Reasoning About Logical Speciﬁcations. PhD
thesis, Penn. State University, 2004.
80. Alwen Tiu and Alberto Momigliano. Cut Elimination for a Logic with Induction
and Co-induction. Journal of Applied Logic, 10(4):330–367, 2012.
81. Dmitriy Traytel, Andrei Popescu, and Jasmin C. Blanchette. Foundational, Com-
positional (Co)datatypes for Higher-Order Logic: Category Theory Applied to
Theorem Proving. In 2012 27th Annual IEEE Symposium on Logic in Computer
Science, pages 596–605, 2012.
82. Li-yao Xia, Yannick Zakowski, Paul He, Chung-Kil Hur, Gregory Malecha, Ben-
jamin C. Pierce, and Steve Zdancewic. Interaction Trees: Representing Recursive
and Impure Programs in Coq. Proc. ACM Program. Lang., 4(POPL), December
2019.
83. Yannick Zakowski, Paul He, Chung-Kil Hur, and Steve Zdancewic. An Equational
Theory for Weak Bisimulation via Generalized Parameterized Coinduction. In
Proceedings of the 9th ACM SIGPLAN International Conference on Certiﬁed
Programs and Proofs, CPP 2020, page 71–84, NY, USA, 2020.

24
L. Cohen
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.
0/), which permits use, sharing, adaptation, distribution and reproduction in any
medium or format, as long as you give appropriate credit to the original author(s) and
the source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Towards the Automatic Mathematician
Markus N. Rabe
and Christian Szegedy
Google Research
Mountain View, California, USA
{mrabe,szegedy}@google.com
Abstract. Over the recent years deep learning has found successful ap-
plications in mathematical reasoning. Today, we can predict ﬁne-grained
proof steps, relevant premises, and even useful conjectures using neu-
ral networks. This extended abstract summarizes recent developments
of machine learning in mathematical reasoning and the vision of the
N2Formal group at Google Research to create an automatic mathemati-
cian. The second part discusses the key challenges on the road ahead.
Keywords: Automated reasoning · machine learning · mathematical
reasoning · theorem proving · natural language understanding.
1
Introduction
The combination of machine learning and mathematical reasoning goes back at
least to the 2000s when Stephan Schulz pioneered ideas to use machine learning
to control the search process [44], and Josef Urban used machine learning to
select relevant axioms [46,47]. With the advent of deep learning, interest in the
area surged, as deep learning promises to enable the automatic discovery of new
knowledge from data, while requiring minimal engineering. This suddenly oﬀered
a ﬂurry of new possibilities also for theorem proving.
One of the most challenging and impactful tasks in automated theorem prov-
ing is premise selection, that is to ﬁnd relevant premises from a large body of
available theorems/axioms. Many classical reasoning systems do not scale well
into thousands of potentially relevant facts, but some pioneering results by Urban
et al. [47] proposed fast machine learning techniques using manually engineered
features. However, with the inroads of deep learning, it has become clear that
large quality improvements are possible by utilizing deep learning techniques.
DeepMath [24] demonstrated that premise selection could be tackled with deep
learning, directly (i.e., without feature engineering) applying neural networks to
the text of the premise and that of the (negated) conjecture.
In DeepMath, both premise and conjecture are embedded into a vector space
by a (potentially expensive) neural network and then a second (preferably cheap)
neural network compares the embedding of the current state to each available
premise to judge whether the premise is useful. Loos et al. [36] for the ﬁrst
time, demonstrated that the same approach as DeepMath yields substantial
improvements as an internal guidance method within a ﬁrst-order automated
theorem prover.
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5 2
25–37, 2021.

26
Markus N. Rabe and Christian Szegedy
Neural Theorem Provers. Emboldened by these early works and by break-
throughs in deep learning, several groups extended interactive theorem provers1
for the use in deep learning research, including Gamepad [23], HOList [5], Coq-
Gym [54], GPT-f [39], and recently TacticZero [51]. A typical tactic application
predicted by these systems looks as follows (here in HOL Light syntax):
REWRITE TAC



tactic name
[ PREMISE1 ; PREMISE2 ]



list of premises
This speciﬁc tactic expects the given premises to be equalities, with which it
attempts to rewrite subexpressions in the current proof goal. The hard part
about predicting good tactics is to select the right list of premises from all
the previously proven theorems. Some tactics also include free-form expressions,
which can be a challenge as well.
In contrast to approaches using lightweight machine learning approaches
(e.g. [13,25,26,38,31]), neural theorem provers aim to replicate the human ap-
proach to proving theorems in ITPs, searching only through a relatively small
number (e.g., hundreds) of proof steps that are very promising. To get high-
quality proof steps, increasingly large neural networks (currently up to 774M
parameters [39]) are trained on human proofs, or with reinforcement learning.
Already, neural theorem provers can prove a signiﬁcant portion (up to 70%
[4]) of test theorems and some have found proofs that are shorter and more
elegant than the proofs that human mathematicians have formalized in these
systems. For example, for the theorem CLOSURE CONVEX INTER AFFINE, proven
with over 40 tactic calls in HOL Light [20], HOList/DeepHOL has found a proof
with just two tactic calls:
let CLOSURE_CONVEX_INTER_AFFINE = prove
(‘!s t:real^N->bool.
convex s /\ affine t /\ ~(relative_interior s INTER t = {})
==> closure(s INTER t) = closure(s) INTER t‘,
SIMP_TAC [INTER_COMM; AFFINE_IMP_CONVEX;
CLOSURE_INTER_CONVEX; RELATIVE_INTERIOR_AFFINE]
THEN
ASM_MESON_TAC [RELATIVE_INTERIOR_EQ_CLOSURE; INTER_COMM;
RELATIVE_INTERIOR_UNIV; IS_AFFINE_HULL]);;
1 The focus has been on interactive theorem provers as they are general enough to
capture most of mathematics in theory, and several large-scale formalization eﬀorts
of the last decades have demonstrated that involved theories can be formalized in
practice [28,14,19]. Also ITPs oﬀer relatively short proofs compared to other auto-
mated reasoning tools, which allows us to use stronger neural networks for the same
computational budget.

Towards the Automatic Mathematician
27
Similarly, Polu et al. reported several cases where they found proofs with their
neural theorem prover GPT-f that were shorter and more elegant than than
those found by humans [39].
Neural Solvers. Closely related to neural theorem provers are methods that,
instead of predicting proof steps, directly predict the solution to mathematical
problems. A ﬁrst impressive example was proposed by Selsam et al., who showed
that graph neural networks can predict satisfying assignments of small Boolean
formulas [45]. Lample and Charton have demonstrated that also higher-level rep-
resentations, such as the integral of a formula, can be predicted directly using
a Transformer [29]. They exploited the fact that for some mathematical opera-
tions, such as taking the integral, the inverse operation (taking the derivative) is
much easier. Hence, they can train on predicting generated formulas from their
derivative without needing a tool that can generate the integral in the ﬁrst place.
Recently, Hahn et al. demonstrated that also classical veriﬁcation problems, such
as LTL satisﬁability, can be solved directly with Transformers, beating existing
tuned algorithms on their own dataset in some cases [18].
2
Towards the Automatic Mathematician
We are convinced that the success of neural theorem provers and neural solvers is
only the beginning of a larger development in which deep learning will revolution-
ize automated reasoning, and have set out to build an automatic mathematician.
Ideally, we could simply talk to an automatic mathematician like a colleague,
and it would be able to contribute to mathematical research, for example by
publishing papers without human support.
An automatic mathematician would thus go far beyond theorem proving, as
it would have to formulate and explore its own theories and conjectures, and be
able to communicate in natural language. Yet, we believe that neural theorem
provers are an important instrument of our plan, as they allow us to evaluate
(generated) conjectures, which grounds the learning process in mathematically
correct reasoning steps. And because neural theorem provers build on existing
interactive theorem provers, they already come with a nucleus of formalized
mathematics that we believe might be necessary to bootstrap the understanding
of mathematics. In the following, we review some of the main challenges on the
path towards an automatic mathematician and ﬁrst approaches to address them.
2.1
Neural Network Architectures
Naturally, we need neural network architectures that can “understand” formulas,
that is, make useful predictions based on formulas. The main question for the
design of neural networks appears to be whether and, if yes, how to exploit the
tree structure of formulas.

28
Markus N. Rabe and Christian Szegedy
Exploiting the Structure of Formulas. It is tempting to believe that the embed-
dings of formulas should represent their semantics. Hence, many authors have
suggested to process formulas with tree-structured recurrent neural networks
(TreeRNNs), which compute embeddings of expressions from the embeddings
of their subexpressions, as this resembles the bottom-up way we deﬁne their
semantics (e.g., [11,1,23,54]). That intuition, however, may be misleading. In
our experiments, bottom-up TreeRNNs have performed signiﬁcantly worse than
top-down architectures (followed by a max-pool aggregation) [37]. This suggests
that, to make good predictions based on formulas, it is important to consider
subformulas in their context, which bottom-up TreeRNNs cannot do easily.
Sequence Models. The alternative to representing the formula structure in the
neural architecture is to interpret formulas simply as sequences of characters
or symbols and apply sequence models. Early works using sequence model-
ing relied on convolutional networks (simple convolutional networks [24] and
wave-nets [36,5]), which compared favorably to gated recurrent architectures
like LSTM/GRU. With the recent rise of the Transformer architecture [48] se-
quence models have caught up to those that exploit the formula structure and
yielded excellent performance in various settings [29,41,52,39,18].
Sequence models come with two major advantages: First, it is straight-
forward to not only read formulas, but also generate formulas, which is sur-
prisingly challenging with TreeRNNs or graph neural networks. This allows us
to directly predict proof steps as strings [39,52], and to tackle a wider range of
mathematical reasoning tasks, such as predicting the integral of a formula [29],
satisfying traces for formulas in linear temporal logics [18], or even more creative
tasks, such as missing assumptions and conjectures [41].2 Second, transformer
models have shown a surprising ﬂexibility and promise a uniform way to process
not only formulas, but also natural language, and even images [10]. This could
prove crucial for processing natural language mathematics, which frequently con-
tains formulas, text, and diagrams, and any model processing papers would need
to understand how they relate to each other. Transformers certainly set a high
bar for the ﬂexibility, generality, and performance of future neural architectures.
Large Models. Scaling up language models to larger and larger numbers of pa-
rameters has steadily improved their results [27,22]. Also when we use language
models for mathematics, we have observed that larger models tend to improve
the quality of predictions [39,41]. GPT-3 has shown that certain abilities, such
as basic arithmetic, appear to only materialize in models with at least a certain
number of parameters [6]. If this turns out to be true for other abilities, this raises
the question how large models have to be to exhibit human-level mathematical
reasoning abilities.
2 Yet, there are still cases where hard-coding some formula structure in transformer
architectures can improve the results, as shown, for example, by Wu et al. [21,35,18],
which suggests that transformers are not the end of the story regarding formula
understanding.

Towards the Automatic Mathematician
29
There is also the question of how exactly to scale up models. The mere
number of parameters may not be as important as how we use them. More
eﬃcient alternatives to simply scaling up the transformer architecture might help
with the problem to make large models accessible to more researchers (e.g., [32]).
2.2
Training Methodology
Neural networks have shown the ability to learn even advanced reasoning tasks
via supervised learning, given the right training data. However, for many inter-
esting tasks, we do not have such data and hence the question is how to train
neural networks for tasks for which we have only limited data or no data at all.
Reinforcement Learning. Reinforcement learning can be seen as a way to re-
duce the amount of human-written proof data needed to learn a strong theorem
prover. By training on the proofs generated by the system itself, we can improve
its abilities to some extent, and the perhaps strongest neural theorem provers
often use some form reinforcement learning (e.g., up to 70% of the proofs in
HOL Light [4]). But, for an open-ended training methodology, we need a sys-
tem that can eﬀectively explore new and interesting theories, without getting
lost in irrelevant branches of mathematics. Partial progress has been made in
training systems without access to human-written proofs [4,51], and to generate
conjectures to train on in a reinforcement learning setting [12], but the problem
is wide-open.
Pretraining. In natural language understanding it is already common practice to
pretrain transformers on a large body text before ﬁne-tuning them on the ﬁnal
task, especially when only limited data is available for that task. Even though the
pretraining data is only loosely related to the ﬁnal tasks, transformers beneﬁt a
lot from pretraining, as it contains general world knowledge and useful inductive
biases [9]. Polu et al. have shown that the same can be observed when pretraining
transformers on natural language texts from arXiv [39].
Self-supervised Training. The GPT models for natural language have shown that
self-supervised language modeling (i.e., only “pre”training without training on
any particular task) alone can equip transformers with surprising abilities [42,6].
Mathematical reasoning abilities, including type inference, predicting missing
assumptions and conjecturing, can be learned in a very similar way by training
transformers to predict missing subexpressions (skip-tree training) [41].
Lample et al. devised several clever approaches to train transformers when
data is not directly available. In unsupervised translation training transformers
successfully learn to translate between diﬀerent natural languages starting only
with monolingual corpora and without any corresponding pairs of sentences [30].
This approach was even generalized to learn to translate between programming
languages without corresponding pairs of programs in diﬀerent languages [43].
The application of these unsupervised translation ideas to mathematics is tempt-
ing, but we experienced that their straight-forward application does not lead to
good results. Also Wang et al. [49] report mixed results.

30
Markus N. Rabe and Christian Szegedy
Learning to Retrieve Relevant Information. If we apply standard language mod-
els to mathematics, e.g., to predict the next proof step, we expect them to store
all the information necessary to make good predictions in their parameters. As
the large transformer models have shown (see, e.g., GPT [42,6]), this approach
actually works pretty well for natural language question answering, and also for
mathematical benchmarks it has been surprisingly successful [41,39,53]. How-
ever, there may be a limit to this approach in cases where we expect detailed,
consistent, and up-to-date predictions. Guu et al. [17] introduced a hybrid of
transformer and retrieval model, REALM, which learns to retrieve Wikipedia
articles that are relevant to a given question and extract useful information
from the article. REALM is trained self-supervised to retrieve multiple articles
and try to use each of them individually to make predictions. The article that
led to the best prediction is deemed to be the most relevant, and is used to
train the retrieval query for future training iterations. This approach has been
extended in follow-up work [33,2,34,3] and appears to be a promising approach
also to retrieve the relevant context, such as deﬁnitions, possible premises, and
even related proofs, for mathematical reasoning.
2.3
Instant Utilization of New Premises
Theorem proving has a key diﬀerence compared to other reinforcement learning
settings: whenever we reach one of the goals, i.e., prove a theorem, we can use
that goal as a premise for future proof attempts. Any learning method applied
in a reinforcement learning setting for theorem proving thus needs the ability to
adapt to this growing action space, and ideally does not need to be retrained at
all when a new theorem becomes available to be used.
Premise selection approaches that are built on retrieval, such as DeepMath
[24,36] and HOList [5,37], oﬀer this ability: When a new theorem is proven, we
can add it to the list of premises that can be retrieved and future retrieval queries
can return the statement. This appears to work well, even when the provers are
applied to a new set of theorems, as demonstrated by the DeepHOL prover when
it was applied to the unseen Flyspeck theorem database [5]. We can even exploit
this kind of generalization for exploration and bootstrap neural theorem provers
without access to human proofs as training data [4].
A new challenge arises from the use of language models for theorem proving.
Theorem provers using transformers currently have no dedicated retrieval mod-
ule, and instead predict the statements or names of premises as part of the tactic
string (cf. [39]). In our experience this does not provide the required generaliza-
tion to unseen premises without retraining. (Though there are experiments that
suggest that it might be possible [8].) Future approaches will have to ﬁnd a way
to combine the strong reasoning skills and generative abilities of Transformer
models with the ability to use new premises without retraining.

Towards the Automatic Mathematician
31
2.4
Natural Language
We believe that, perhaps counterintuitively, natural language plays a central
role in automated reasoning. The most direct reason is that only a small part of
mathematics has been formalized so far, and a pragmatic approach to tap into
much more training data is to ﬁnd a way to learn from natural language mathe-
matics (books and papers on mathematical topics). In this section, however, we
want to look beyond the question of feasibility and training data, and discuss
the broad advantages of a natural language approach to mathematics.
Accessibility. A bridge between natural and formal mathematics could help to
make the system much more accessible, by not requiring the users to learn a
speciﬁc formal language. This might open up mathematics to a much wider au-
dience, enabling advanced mathematical assistants (think WolframAlpha [50]),
and tools for education.
Vice versa, an advanced automatic mathematician without the ability to
explain their reasoning in natural language might be hard to understand. Even
if the system’s predictions and theories are correct, sophisticated, and relevant,
we might not be able to use them to inform our own understanding if the notions
the system comes up with are only available as vast synthetic formal objects.
Conjecturing, Theory Exploration, and Interestingness. Various approaches have
been suggested to produce new conjectures, including heuristic ﬁlters [40], de-
riving rules from data [7], and learning and sampling from a distribution of
theorems using language modeling [41].
A particularly interesting idea is the use of adversarial training to generate
conjectures (e.g., [12]). Here, two neural networks compete against each other—
one with the aim to prove statements and the other with the aim to suggest
hard-to-prove statements, somewhat akin to generative adversarial nets [15]. The
idea is that the competition between the two networks generates a curriculum of
harder and harder problems to solve and also automatically explores new parts
of mathematics (as old parts get easier over time). However, there seems to be
a catch: Once the network that suggests problems has ﬁgured out how to deﬁne
a one-way function, it becomes very easy to produce an unlimited number of
hard problems, such as to ﬁnd an input to the SHA256 function that produces
a certain output hash. This class of problems is almost impossible to solve, and
thus likely leads the process into a dead-end.
Once again, natural language seems to be a possible answer. Using the large
body of natural language mathematics could help to equip machine learning
models with a notion of what human mathematicians ﬁnd interesting, and focus
on these areas.
Grounding Language Models. Autoformalization does not only produce formal
objects as a desired outcome, it also serves the dual purpose to improve language
models. Checking the models’ outputs and feeding back their correctness as a
training signal would provide valuable grounding for their understanding.

32
Markus N. Rabe and Christian Szegedy
Of course, the gap between formalized and informal mathematics is huge:
it will likely require a considerable level of eﬀort to automatically create high
quality formalizations. Also, we believe that we will likely need a very high qual-
ity theorem prover to bootstrap any autoformalization system. However, recent
progress in neural language processing [9,42], unsupervised translation [30,43]
and also neural network based symbolic mathematics [29,41,18,39] makes this
path seem increasingly feasible and appealing in the long run.
3
Conclusion
In this extended abstract, we surveyed recent results in neural theorem proving
and our mission to build an artiﬁcial mathematician, as well as some of the
challenges on this path. While there is no guarantee that we can overcome these
challenges, and there might be challenges that we cannot even anticipate yet,
mere partial success to our mission could help the formal methods community
with tools to simplify the formalization process, and impact adjacent areas, such
as veriﬁcation, program synthesis, and natural language understanding.
In a 2018 survey among AI researchers, the median prediction for when ma-
chines “routinely and autonomously prove mathematical theorems that are pub-
lishable in top mathematics journals today, including generating the theorems
to prove” was in the 2060s [16]. However, over the last years, deep learning has
already beaten a lot of expectations (at least ours) as to what is possible in au-
tomated reasoning. There are still several challenges to be solved, some of which
we laid out in this abstract, but we believe that creating a truly intelligent ar-
tiﬁcial mathematician is within reach and will happen on a much shorter time
frame than many experts expect.
References
1. Arabshahi, F., Singh, S., Anandkumar, A.: Combining symbolic expressions and
black-box function evaluations in neural programs. In: 6th International Confer-
ence on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April
30 - May 3, 2018, Conference Track Proceedings. OpenReview.net (2018), https:
//openreview.net/forum?id=Hksj2WWAW
2. Asai, A., Hashimoto, K., Hajishirzi, H., Socher, R., Xiong, C.: Learning to retrieve
reasoning paths over wikipedia graph for question answering. In: 8th International
Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia,
April 26-30, 2020. OpenReview.net (2020), https://openreview.net/forum?id=
SJgVHkrYDH
3. Balachandran, V., Vaswani, A., Tsvetkov, Y., Parmar, N.: Simple and eﬃcient ways
to improve REALM. CoRR abs/2104.08710 (2021), https://arxiv.org/abs/2104.
08710
4. Bansal, K., Loos, S.M., Rabe, M.N., Szegedy, C.: Learning to reason in large
theories without imitation. CoRR abs/1905.10501 (2019), http://arxiv.org/abs/
1905.10501

Towards the Automatic Mathematician
33
5. Bansal, K., Loos, S.M., Rabe, M.N., Szegedy, C., Wilcox, S.: Holist: An environ-
ment for machine learning of higher order logic theorem proving. In: Chaudhuri,
K., Salakhutdinov, R. (eds.) Proceedings of the 36th International Conference on
Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA.
Proceedings of Machine Learning Research, vol. 97, pp. 454–463. PMLR (2019),
http://proceedings.mlr.press/v97/bansal19a.html
6. Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Nee-
lakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A.,
Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D.M., Wu, J., Win-
ter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark,
J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., Amodei, D.: Language
models are few-shot learners. In: Larochelle, H., Ranzato, M., Hadsell, R., Balcan,
M., Lin, H. (eds.) Advances in Neural Information Processing Systems 33: An-
nual Conference on Neural Information Processing Systems 2020, NeurIPS 2020,
December 6-12, 2020, virtual (2020)
7. Brunton,
S.L.,
Proctor,
J.L.,
Kutz,
J.N.:
Discovering
governing
equations
from
data
by
sparse
identiﬁcation
of
nonlinear
dynamical
systems.
Pro-
ceedings of the National Academy of Sciences 113(15), 3932–3937 (2016).
https://doi.org/10.1073/pnas.1517384113
8. Cao, N.D., Izacard, G., Riedel, S., Petroni, F.: Autoregressive entity retrieval. In:
9th International Conference on Learning Representations, ICLR 2021. OpenRe-
view.net (2021)
9. Devlin, J., Chang, M., Lee, K., Toutanova, K.: BERT: pre-training of deep bidirec-
tional transformers for language understanding. In: Burstein, J., Doran, C., Solorio,
T. (eds.) Proceedings of the 2019 Conference of the North American Chapter of
the Association for Computational Linguistics: Human Language Technologies,
NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and
Short Papers). pp. 4171–4186. Association for Computational Linguistics (2019).
https://doi.org/10.18653/v1/n19-1423
10. Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner,
T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., Houlsby, N.:
An image is worth 16x16 words: Transformers for image recognition at scale. In:
9th International Conference on Learning Representations, ICLR 2021. OpenRe-
view.net (2021)
11. Evans, R., Saxton, D., Amos, D., Kohli, P., Grefenstette, E.: Can neural networks
understand logical entailment? In: 6th International Conference on Learning Rep-
resentations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Confer-
ence Track Proceedings. OpenReview.net (2018), https://openreview.net/forum?
id=SkZxCk-0Z
12. Firoiu, V., Ayg¨un, E., Anand, A., Ahmed, Z., Glorot, X., Orseau, L., Zhang, L.,
Precup, D., Mourad, S.: Training a ﬁrst-order theorem prover from synthetic data.
CoRR abs/2103.03798 (2021), https://arxiv.org/abs/2103.03798
13. Gauthier, T., Kaliszyk, C., Urban, J.: TacticToe: Learning to reason with HOL4
tactics. In: Eiter, T., Sands, D. (eds.) LPAR-21, 21st International Conference on
Logic for Programming, Artiﬁcial Intelligence and Reasoning, Maun, Botswana,
May 7-12, 2017. EPiC Series in Computing, vol. 46, pp. 125–143. EasyChair (2017),
https://easychair.org/publications/volume/LPAR-21
14. Gonthier, G., Asperti, A., Avigad, J., Bertot, Y., Cohen, C., Garillot, F., Roux,
S.L., Mahboubi, A., O’Connor, R., Biha, S.O., Pasca, I., Rideau, L., Solovyev, A.,
Tassi, E., Th´ery, L.: A machine-checked proof of the odd order theorem. In: Blazy,

34
Markus N. Rabe and Christian Szegedy
S., Paulin-Mohring, C., Pichardie, D. (eds.) Interactive Theorem Proving - 4th
International Conference, ITP 2013, Rennes, France, July 22-26, 2013. Proceed-
ings. Lecture Notes in Computer Science, vol. 7998, pp. 163–179. Springer (2013).
https://doi.org/10.1007/978-3-642-39634-2 14
15. Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
S., Courville, A.C., Bengio, Y.: Generative adversarial nets. In: Ghahramani, Z.,
Welling, M., Cortes, C., Lawrence, N.D., Weinberger, K.Q. (eds.) Advances in Neu-
ral Information Processing Systems 27: Annual Conference on Neural Information
Processing Systems 2014, December 8-13 2014, Montreal, Quebec, Canada. pp.
2672–2680 (2014)
16. Grace, K., Salvatier, J., Dafoe, A., Zhang, B., Evans, O.: Viewpoint: When will
AI exceed human performance? evidence from AI experts. J. Artif. Intell. Res. 62,
729–754 (2018). https://doi.org/10.1613/jair.1.11222
17. Guu, K., Lee, K., Tung, Z., Pasupat, P., Chang, M.: Retrieval augmented lan-
guage model pre-training. In: Proceedings of the 37th International Conference
on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event. Proceed-
ings of Machine Learning Research, vol. 119, pp. 3929–3938. PMLR (2020),
http://proceedings.mlr.press/v119/guu20a.html
18. Hahn, C., Schmitt, F., Kreber, J.U., Rabe, M.N., Finkbeiner, B.: Teaching tempo-
ral logics to neural networks. In: 9th International Conference on Learning Repre-
sentations, ICLR 2021. OpenReview.net (2021)
19. Hales, T., Adams, M., Bauer, G., Dang, T.D., Harrison, J., Le Truong, H., Kaliszyk,
C., Magron, V., McLaughlin, S., Nguyen, T.T., et al.: A formal proof of the Kepler
conjecture. In: Forum of Mathematics, Pi. vol. 5, p. e2. Cambridge University Press
(2017)
20. Harrison, J.: HOL Light: A tutorial introduction. In: Srivas, M.K., Camilleri, A.J.
(eds.) Formal Methods in Computer-Aided Design, First International Conference,
FMCAD ’96, Palo Alto, California, USA, November 6-8, 1996, Proceedings. Lecture
Notes in Computer Science, vol. 1166, pp. 265–269. Springer (1996)
21. Hellendoorn, V.J., Sutton, C., Singh, R., Maniatis, P., Bieber, D.: Global relational
models of source code. In: 8th International Conference on Learning Represen-
tations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net
(2020), https://openreview.net/forum?id=B1lnbRNtwr
22. Henighan, T., Kaplan, J., Katz, M., Chen, M., Hesse, C., Jackson, J., Jun, H.,
Brown, T.B., Dhariwal, P., Gray, S., Hallacy, C., Mann, B., Radford, A., Ramesh,
A., Ryder, N., Ziegler, D.M., Schulman, J., Amodei, D., McCandlish, S.: Scaling
laws for autoregressive generative modeling. CoRR abs/2010.14701 (2020), https:
//arxiv.org/abs/2010.14701
23. Huang, D., Dhariwal, P., Song, D., Sutskever, I.: Gamepad: A learning environment
for theorem proving. In: 7th International Conference on Learning Representations,
ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net (2019), https:
//openreview.net/forum?id=r1xwKoR9Y7
24. Irving, G., Szegedy, C., Alemi, A.A., E´en, N., Chollet, F., Urban, J.: Deepmath
- deep sequence models for premise selection. In: Lee, D.D., Sugiyama, M., von
Luxburg, U., Guyon, I., Garnett, R. (eds.) Advances in Neural Information Pro-
cessing Systems 29: Annual Conference on Neural Information Processing Systems
2016, December 5-10, 2016, Barcelona, Spain. pp. 2235–2243 (2016)
25. Jakubuv, J., Urban, J.: ENIGMA: eﬃcient learning-based inference guiding ma-
chine. In: Geuvers, H., England, M., Hasan, O., Rabe, F., Teschke, O. (eds.) Intel-
ligent Computer Mathematics - 10th International Conference, CICM 2017, Ed-
inburgh, UK, July 17-21, 2017, Proceedings. Lecture Notes in Computer Science,

Towards the Automatic Mathematician
35
vol. 10383, pp. 292–302. Springer (2017). https://doi.org/10.1007/978-3-319-62075-
6 20
26. Kaliszyk, C., Urban, J., Michalewski, H., Ols´ak, M.: Reinforcement learning of
theorem proving. In: Bengio, S., Wallach, H.M., Larochelle, H., Grauman, K.,
Cesa-Bianchi, N., Garnett, R. (eds.) Advances in Neural Information Processing
Systems 31: Annual Conference on Neural Information Processing Systems 2018,
NeurIPS 2018, December 3-8, 2018, Montr´eal, Canada. pp. 8836–8847 (2018)
27. Kaplan, J., McCandlish, S., Henighan, T., Brown, T.B., Chess, B., Child, R., Gray,
S., Radford, A., Wu, J., Amodei, D.: Scaling laws for neural language models
(2020), https://arxiv.org/abs/2001.08361
28. Klein, G., Elphinstone, K., Heiser, G., Andronick, J., Cock, D., Derrin, P., Elka-
duwe, D., Engelhardt, K., Kolanski, R., Norrish, M., Sewell, T., Tuch, H., Win-
wood, S.: seL4: formal veriﬁcation of an OS kernel. In: Matthews, J.N., Anderson,
T.E. (eds.) Proceedings of the 22nd ACM Symposium on Operating Systems Prin-
ciples 2009, SOSP 2009, Big Sky, Montana, USA, October 11-14, 2009. pp. 207–220.
ACM (2009). https://doi.org/10.1145/1629575.1629596
29. Lample, G., Charton, F.: Deep learning for symbolic mathematics. In: 8th In-
ternational Conference on Learning Representations, ICLR 2020, Addis Ababa,
Ethiopia, April 26-30, 2020. OpenReview.net (2020), https://openreview.net/
forum?id=S1eZYeHFDS
30. Lample, G., Conneau, A., Denoyer, L., Ranzato, M.: Unsupervised machine trans-
lation using monolingual corpora only. In: 6th International Conference on Learn-
ing Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018,
Conference Track Proceedings. OpenReview.net (2018), https://openreview.net/
forum?id=rkYTTf-AZ
31. Lederman, G., Rabe, M.N., Seshia, S., Lee, E.A.: Learning heuristics for quantiﬁed
boolean formulas through reinforcement learning. In: 8th International Conference
on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30,
2020. OpenReview.net (2020), https://openreview.net/forum?id=BJluxREKDB
32. Lepikhin, D., Lee, H., Xu, Y., Chen, D., Firat, O., Huang, Y., Krikun, M., Shazeer,
N., Chen, Z.: GShard: Scaling giant models with conditional computation and auto-
matic sharding. In: International Conference on Learning Representations, ICLR.
OpenReview.net (2021)
33. Lewis, M., Ghazvininejad, M., Ghosh, G., Aghajanyan, A., Wang, S., Zettlemoyer,
L.: Pre-training via paraphrasing. In: Larochelle, H., Ranzato, M., Hadsell, R.,
Balcan, M., Lin, H. (eds.) Advances in Neural Information Processing Systems
33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS
2020, December 6-12, 2020, virtual (2020)
34. Lewis, P.S.H., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., K¨uttler,
H., Lewis, M., Yih, W., Rockt¨aschel, T., Riedel, S., Kiela, D.: Retrieval-augmented
generation for knowledge-intensive NLP tasks. In: Larochelle, H., Ranzato, M.,
Hadsell, R., Balcan, M., Lin, H. (eds.) Advances in Neural Information Processing
Systems 33: Annual Conference on Neural Information Processing Systems 2020,
NeurIPS 2020, December 6-12, 2020, virtual (2020)
35. Li, W., Yu, L., Wu, Y., Paulson, L.C.: IsarStep: A benchmark for high-level math-
ematical reasoning. In: 9th International Conference on Learning Representations,
ICLR 2021. OpenReview.net (2021)
36. Loos, S.M., Irving, G., Szegedy, C., Kaliszyk, C.: Deep network guided proof search.
In: Eiter, T., Sands, D. (eds.) LPAR-21, 21st International Conference on Logic
for Programming, Artiﬁcial Intelligence and Reasoning, Maun, Botswana, May

36
Markus N. Rabe and Christian Szegedy
7-12, 2017. EPiC Series in Computing, vol. 46, pp. 85–105. EasyChair (2017),
https://easychair.org/publications/paper/ND13
37. Paliwal, A., Loos, S.M., Rabe, M.N., Bansal, K., Szegedy, C.: Graph repre-
sentations for higher-order logic and theorem proving. In: The Thirty-Fourth
AAAI Conference on Artiﬁcial Intelligence, AAAI 2020, The Thirty-Second In-
novative Applications of Artiﬁcial Intelligence Conference, IAAI 2020, The Tenth
AAAI Symposium on Educational Advances in Artiﬁcial Intelligence, EAAI 2020,
New York, NY, USA, February 7-12, 2020. pp. 2967–2974. AAAI Press (2020),
https://aaai.org/ojs/index.php/AAAI/article/view/5689
38. Piotrowski, B., Urban, J.: Atpboost: Learning premise selection in binary setting
with ATP feedback. In: Galmiche, D., Schulz, S., Sebastiani, R. (eds.) Automated
Reasoning - 9th International Joint Conference, IJCAR 2018, Held as Part of the
Federated Logic Conference, FloC 2018, Oxford, UK, July 14-17, 2018, Proceed-
ings. Lecture Notes in Computer Science, vol. 10900, pp. 566–574. Springer (2018).
https://doi.org/10.1007/978-3-319-94205-6 37
39. Polu, S., Sutskever, I.: Generative language modeling for automated theorem prov-
ing. CoRR abs/2009.03393 (2020), https://arxiv.org/abs/2009.03393
40. Puzis, Y., Gao, Y., Sutcliﬀe, G.: Automated generation of interesting theorems. In:
Sutcliﬀe, G., Goebel, R. (eds.) Proceedings of the Nineteenth International Florida
Artiﬁcial Intelligence Research Society Conference, Melbourne Beach, Florida,
USA, May 11-13, 2006. pp. 49–54. AAAI Press (2006), http://www.aaai.org/
Library/FLAIRS/2006/ﬂairs06-009.php
41. Rabe, M.N., Lee, D., Bansal, K., Szegedy, C.: Mathematical reasoning via self-
supervised skip-tree training. In: International Conference on Learning Represen-
tations, ICLR. OpenReview.net (2021)
42. Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I.: Language
models are unsupervised multitask learners. In: OpenAI Blog (2018)
43. Rozi`ere, B., Lachaux, M., Chanussot, L., Lample, G.: Unsupervised translation of
programming languages. In: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.,
Lin, H. (eds.) Advances in Neural Information Processing Systems 33: Annual Con-
ference on Neural Information Processing Systems 2020, NeurIPS 2020, December
6-12, 2020, virtual (2020)
44. Schulz, S.: Learning search control knowledge for equational theorem proving. In:
Baader, F., Brewka, G., Eiter, T. (eds.) KI 2001: Advances in Artiﬁcial Intelligence,
Joint German/Austrian Conference on AI, Vienna, Austria, September 19-21, 2001,
Proceedings. Lecture Notes in Computer Science, vol. 2174, pp. 320–334. Springer
(2001). https://doi.org/10.1007/3-540-45422-5 23
45. Selsam, D., Lamm, M., B¨unz, B., Liang, P., de Moura, L., Dill, D.L.: Learning a
SAT solver from single-bit supervision. In: 7th International Conference on Learn-
ing Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenRe-
view.net (2019), https://openreview.net/forum?id=HJMC iA5tm
46. Urban, J.: MPTP - motivation, implementation, ﬁrst experiments. J. Autom. Rea-
son. 33(3-4), 319–339 (2004). https://doi.org/10.1007/s10817-004-6245-1
47. Urban, J., Sutcliﬀe, G., Pudl´ak, P., Vyskocil, J.: Malarea SG1- machine learner
for automated reasoning with semantic guidance. In: Armando, A., Baum-
gartner, P., Dowek, G. (eds.) Automated Reasoning, 4th International Joint
Conference, IJCAR 2008, Sydney, Australia, August 12-15, 2008, Proceedings.
Lecture Notes in Computer Science, vol. 5195, pp. 441–456. Springer (2008).
https://doi.org/10.1007/978-3-540-71070-7 37

Towards the Automatic Mathematician
37
48. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser,
L., Polosukhin, I.: Attention is all you need. In: Guyon, I., von Luxburg, U., Bengio,
S., Wallach, H.M., Fergus, R., Vishwanathan, S.V.N., Garnett, R. (eds.) Advances
in Neural Information Processing Systems 30: Annual Conference on Neural Infor-
mation Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA. pp.
5998–6008 (2017)
49. Wang, Q., Brown, C.E., Kaliszyk, C., Urban, J.: Exploration of neural machine
translation in autoformalization of mathematics in Mizar. In: Blanchette, J.,
Hritcu, C. (eds.) Proceedings of the 9th ACM SIGPLAN International Conference
on Certiﬁed Programs and Proofs, CPP 2020, New Orleans, LA, USA, January
20-21, 2020. pp. 85–98. ACM (2020). https://doi.org/10.1145/3372885.3373827
50. WolframAlpha: WolframAlpha (2016), http://www.wolframalpha.com/
51. Wu, M., Norrish, M., Walder, C., Dezfouli, A.: Tacticzero: Learning to prove the-
orems from scratch with deep reinforcement learning. CoRR abs/2102.09756
(2021), https://arxiv.org/abs/2102.09756
52. Wu, Y., Jiang, A., Ba, J., Grosse, R.B.: INT: An inequality benchmark for evaluat-
ing generalization in theorem proving. In: 9th International Conference on Learning
Representations, ICLR 2021. OpenReview.net (2021)
53. Wu, Y., Rabe, M., Li, W., Ba, J., Grosse, R., Szegedy, C.: LIME: Learning inductive
bias for primitives of mathematical reasoning. In: Proceedings of International
Conference on Machine Learning (to appear) (2021)
54. Yang, K., Deng, J.: Learning to prove theorems via interacting with proof assis-
tants. In: Chaudhuri, K., Salakhutdinov, R. (eds.) Proceedings of the 36th In-
ternational Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long
Beach, California, USA. Proceedings of Machine Learning Research, vol. 97, pp.
6984–6994. PMLR (2019), http://proceedings.mlr.press/v97/yang19a.html
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Logical Foundations

Tableau-based Decision Procedure for
Non-Fregean Logic of Sentential Identity⋆
Joanna Goli´nska-Pilarek
, Taneli
Huuskonen
, and Michal Zawidzki
1 Faculty of Philosophy, University of Warsaw, 3 Krakowskie Przedmiescie St. 00-927
Warsaw, Poland
2 Department of Computer Science, University of Oxford, Oxford OX1 3QD, UK
3 Department of Logic, University of Lodz, 3/5 Lindleya St., 90-131 L´od´z, Poland
j.golinska@uw.edu.pl
taneli@poczta.onet.pl
michal.zawidzki@cs.ox.ac.uk
Abstract. Sentential Calculus with Identity (SCI) is an extension of
classical propositional logic, featuring a new connective of identity be-
tween formulas. In SCI two formulas are said to be identical if they share
the same denotation. In the semantics of the logic, truth values are dis-
tinguished from denotations, hence the identity connective is strictly
stronger than classical equivalence. In this paper we present a sound,
complete, and terminating algorithm deciding the satisﬁability of SCI-
formulas, based on labelled tableaux. To the best of our knowledge, it
is the ﬁrst implemented decision procedure for SCI which runs in NP,
i.e., is complexity-optimal. The obtained complexity bound is a result of
dividing derivation rules in the algorithm into two sets: decomposition
and equality rules, whose interplay yields derivation trees with branches
of polynomial length with respect to the size of the investigated formula.
We describe an implementation of the procedure and compare its perfor-
mance with implementations of other calculi for SCI (for which, however,
the termination results were not established). We show possible reﬁne-
ments of our algorithm and discuss the possibility of extending it to other
non-Fregean logics.
Keywords: Sentential Calculus with Identity · non-Fregean logics · la-
belled tableaux · decision procedure · termination · computational com-
plexity.
1
Introduction
In this paper, we present a decision procedure for the non-Fregean sentential
calculus with identity SCI. The contribution of the paper is twofold. First of
all, this is the ﬁrst implemented and complexity-optimal decision procedure for
⋆Research reported in this paper is supported by the National Science Centre, Poland
(grant number: UMO-2017/25/B/HS1/00503).
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp. 41 57, 2021.
https://doi.org/10.1007/978-3-030-79876-5_3
–
2,3
1
1

42
J. Goli´nska-Pilarek et al.
SCI, although several deduction systems for SCI have already been presented in
the literature. Second, our decision procedure is constructed in the paradigm of
labelled tableaux, which makes the whole approach more robust to modiﬁcations
and extensions to other non-Fregean logics.
Non-Fregean logic is an alternative to both classical and many non-classical
systems whose semantics identiﬁes semantical correlates of sentences with their
logical values. According to the classical approach in model theory, semanti-
cal structures (realities) correspond to the language that is meant to describe
them, and therefore, symbols and expressions of that language, such as individual
constants or relational symbols, have their denotations in these structures (re-
spectively, objects or relations between objects). However, sentences are treated
diﬀerently, as they are interpreted in models only in terms of logical values or
other semantical relations such as satisfaction or truth. This classical approach
allows us to answer the very basic logical question of whether the sentences are
logically equivalent; however, it does not provide any tool that would allow to
check whether the sentences describe or refer to the same situation, or have the
same meaning. Thus, the main motivation for non-Fregean logic was the need
for an extensional and two-valued logic that could be used to represent seman-
tical denotations of sentences that – depending on the underlying philosophical
theory of language or the reality to which a logic is supposed to refer – could
be understood as situations, states of aﬀairs, meanings, etc. In order to express
(non)identities or other interactions between the referents of sentences, at least
the universe of denotations of sentences needs to be added to the semantics and
the new identity connective to the language.
The minimal two-valued non-Fregean propositional logic SCI (Sentential Cal-
culus with Identity), introduced by Suszko (see [21]), is an extension of classical
propositional logic with a new binary connective of identity (≡) and axioms re-
ﬂecting its fundamental properties. The identity connective represents the iden-
tity of the denotations of sentences, and so, an expression ‘ϕ ≡ψ’ should be read
as ‘the sentences ϕ and ψ describe the same «thing»’. The semantics for SCI is
based on structures determined by a universe of the denotations of sentences, a
set of facts (those denotations that actually hold), and operations corresponding
to all the connectives. The identity connective is then interpreted as an operation
representing an equivalence relation that additionally satisﬁes the extensionality
property. In the non-Fregean approach the identity and equivalence connectives
are in general not equivalent: two sentences with the same truth value can have
diﬀerent denotations. Take, for instance, the following three statements:
A ‘There is an eﬀective method for determining whether an arbitrary formula
of classical propositional logic is a theorem of that logic.’
B ‘Classical propositional logic is ﬁnitely axiomatizable, has a recursive set of
recursive rules and enjoys the ﬁnite model property.’
C ‘Classical propositional logic is Post consistent.’
A, B, C are all (necessarily) true as theorems of mathematical logic. Therefore,
they are pairwise logically equivalent, that is, all three equivalences: A ↔B,
B ↔C, and A ↔C hold. One can fairly claim that A and B refer to the same

fact, so A ≡B, but C has clearly a diﬀerent semantic correlate than both A and
B, as decidability is independent of Post consistency. Thus, we have A ̸≡C and
B ̸≡C.
It is known that the class of all non-equivalent non-Fregean propositional
logics satisfying the laws of classical logic is uncountable [7], and some of these
logics are equivalent to the well-known non-classical logics (e.g., modal logics S4
and S5, many-valued logics). Higher-order non-Fregean logics are very expres-
sive. In particular, a logic obtained from SCI by adding propositional quantiﬁers
is undecidable and can express many mathematical theories, e.g., Peano arith-
metic, the theory of groups, rings, and ﬁelds [8]. Furthermore, non-classical and
deviant modiﬁcations of SCI have been developed and extensively studied in
the literature, in particular intuitionistic logics [17,14,4], modal and epistemic
logics [15,16], logics with non-classical identity [13], paraconsistent [6,9]. The
non-Fregean approach could turn out to be more adequate than the classical
one in cognitive science or natural language processing. Moreover, non-Fregean
logic could serve as a general framework for comparing diﬀerent aspects of logics
with incompatible languages and semantics and help in addressing the question
of which class of logics handles logical symbols in the most adequate way from
the perspective of natural language.
In the original works by Suszko and Bloom the deduction system for SCI
was deﬁned in the Hilbert style [1,2]. Sound and complete deduction systems
which are better suited for automated theorem proving were constructed later:
Gentzen sequent calculi [18,22,23,3] and dual tableau systems [5,19,10]. A de-
tailed presentation of all of them can be found in [10]. The main disadvantage of
the aforementioned systems is that they are not decision procedures, while SCI
is decidable and in particular in NP [2, Theorem 2.3]. Although the system by
Wasilewska [22] can be seen as a meta-tool for deciding validity of SCI-formulas,
it is equipped with external meta-machinery that is not a part of the system it-
self. As a result, it constitutes another proof for decidability of SCI, rather than
being a decision procedure in the classical sense of the term, that is suitable
for computer implementations. In [11] a tableau-based algorithm for SCI was
presented as a work-in-progress. The decision procedure presented in this paper
is a result of a substantial remodelling of the preliminary system introduced
in [11], for which we prove soundness and completeness, present surprisingly
straightforward proofs of termination and membership in NP, and provide an
implementation.
In this paper, we present a new deduction system TSCI for the logic SCI, based
on labelled tableaux. To the best of our knowledge, it is the ﬁrst decision pro-
cedure for SCI. Moreover, its upper complexity bound, that is NP, matches the
complexity class of the satisﬁability problem for SCI, thus, making the algorithm
complexity-optimal. TSCI is built in the paradigm of labelled tableaux. The lan-
guage of deduction is an extension of the SCI-language with two sorts of labels
representing the denotations of formulas (i.e., «facts» and «non-facts») as well
as with the equality and the inequality relation that can hold between labels.
(In)Equality formulas occurring in a derivation tree provide additional informa-
Tableau-based Decision Procedure for Non-Fregean Logic. . .
43

44
J. Goli´nska-Pilarek et al.
tion on identity or distinctness of the denotations of formulas. In Section 2, we
provide a formal overview of the logic SCI, in Section 3, we introduce the tableau
algorithm TSCI and prove its soundness, completeness, and termination, estab-
lish that it is complexity-optimal with respect to SCI-satisﬁability, and show a
possible reﬁnement thereof. In Section 4, we discuss an implementation of TSCI
and compare it with an older prover based on a heuristic, unproven algorithm.
Conclusions and directions of further research are presented in Section 5.
2
SCI
Syntax Let LSCI be a language of the logic SCI with the alphabet ⟨AF, ¬, →, ≡⟩,
where AF = {p, q, r, . . .} is a denumerable set of atomic formulas. The set FOR
of SCI-formulas is deﬁned by the following abstract grammar:
ϕ ::= p | ¬ϕ | ϕ →ϕ | ϕ ≡ϕ,
where p ∈AF.
Axiomatization The logic SCI is axiomatized by the following set of truth-
functional (1–3) and identity (4–8) axiom schemes:
1. ϕ →(ψ →ϕ)
2. (ϕ →(ψ →χ)) →((ϕ →ψ) →(ϕ →χ))
3. (¬ϕ →¬ψ) →(ψ →ϕ)
4. ϕ ≡ϕ
5. ϕ ≡ψ →¬ϕ ≡¬ψ
6. ϕ ≡ψ →(χ ≡θ →(ϕ →χ) ≡(ψ →θ))
7. ϕ ≡ψ →(χ ≡θ →(ϕ ≡χ) ≡(ψ ≡θ))
8. ϕ ≡ψ →(ϕ →ψ).
Semantics Let U ̸= ∅, D ⊂U, and let ˜¬ : U −→U, ˜→: U × U −→U,
and ˜≡: U × U −→U be functions on U. An SCI-model is a structure M =
⟨U, D, ˜¬, ˜→, ˜≡⟩, where U and D are called, respectively, universe and set of
designated values, and the following conditions are satisﬁed for all a, b ∈U:
˜¬a ∈D
iﬀ
a /∈D
(1)
a ˜→b ∈D
iﬀ
a /∈D or b ∈D
(2)
a˜≡b ∈D
iﬀ
a = b.
(3)
A valuation in an SCI- model M = ⟨U, D, ˜¬, ˜→, ˜≡⟩is a function V : FOR −→U
such that for all ϕ, ψ ∈FOR it holds that V (¬ϕ) = ˜¬V (ϕ) and V (ϕ#ψ) =
V (ϕ) ˜#V (ψ), for # ∈{→, ≡}. An element a ∈U such that a = V (ϕ) is called
the denotation of ϕ. Interestingly, SCI-model can be deﬁned alternatively as a
triple M = ⟨U, D, V ⟩, where a valuation V : FOR −→U needs to satisfy the
conditions analogous to (1)–(3) (for instance, V (¬ϕ) ∈D iﬀV (ϕ) /∈D etc.).
In the original approach V may as well be deﬁned only for atomic formulas

and then lifted up homomorphically to the set of all formulas, like in classical
propositional logic. In the latter setting it is not the case, as a valuation deﬁned
solely for atoms does usually not have a unique extension to all formulas. We
say that a formula ϕ is satisﬁed in an SCI-model M = ⟨U, D, ˜¬, ˜→, ˜≡⟩and a
valuation V in M, and refer to it as M, V |=SCI ϕ, if its denotation belongs to
D. We call a formula ϕ satisﬁable if it is satisﬁed in some SCI-model by some
valuation. We say that a formula ϕ is true in a model M = ⟨U, D, ˜¬, ˜→, ˜≡⟩, and
refer to it as M |=SCI ϕ, whenever it is satisﬁed in M by all the valuations in M.
We call a formula ϕ valid, and refer to it as |=SCI ϕ, if it is true in all SCI-models.
Note that over the class of models where D and U \D are singletons SCI collapses
to classical propositional logic. In fact all formulas which are SCI-instances of
formulas valid in classical propositional are also valid in SCI. It suﬃces, however,
to take a three-element model to tell ↔and ≡apart, as shown in the following
example.
Example 1. Although the formula ¬¬p ↔p is a tautology of classical proposi-
tional logic, the formula ¬¬p ≡p is not valid in SCI. Indeed, consider an SCI-
model M = ⟨U, D, ˜¬, ˜to, ˜≡⟩, where U = {0, 1, 2}, D = {1, 2}, and the operations
˜¬, ˜→, ˜≡are deﬁned by:
˜¬a =

0,
if a ̸= 0,
1,
otherwise. a ˜→b =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
0,
if a ̸= 2 and
b = 0,
2,
if a = b,
1,
otherwise.
a˜≡b =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
0,
if a ̸= b
a,
if a = b and
a ̸= 0,
1,
otherwise.
It is easy to verify that such a structure is an SCI-model. Then, the following
hold:
– ˜¬˜¬2 = 1, and so, M and a valuation V in M such that V (p) = 2 falsify the
formula ¬¬p ≡p,
– 1 ˜→2 = 1, but ˜¬2 ˜→˜¬1 = 2, and so, the formula (p →q) ≡(¬q →¬p) is not
true in M.
What is also characteristic of SCI is that identical formulas can be inter-
changed within other formulas with not only truth preservation, but also iden-
tity preservation. For instance, if p ≡(p →q), then p ≡((p →q) →q),
p ≡(((p →q) →q) →q) and so on. On the other hand, identity of two formu-
las does not automatically yield identity of their subformulas. For example, if
¬p ≡¬q, it does not necessarily mean that p ≡q. It is worth noting that in SCI
we lack the usual equivalence between treating ∧, ∨, and ↔as abbreviations
involving ¬ and →and treating them as independent connectives whose mutual
relations are established axiomatically. For instance, when ¬(ϕ →¬ψ) is just a
notational variant for ϕ∧ψ, then (ϕ∧ψ) ≡¬(ϕ →¬ψ) is, of course, SCI-valid;
however, it would not be the case if we regarded ∧as a separate connective. Nev-
ertheless, extending our results to other connectives introduced as independent
logical constants is a matter of routine.
Tableau-based Decision Procedure for Non-Fregean Logic. . .
45

46
J. Goli´nska-Pilarek et al.
3
Tableaux
In this section, we provide a characterization of a sound, complete and termi-
nating labelled tableau system for the logic SCI, which we call TSCI.
Let L+, L−be countably inﬁnite disjoint sets and let L = L+ ∪L−. We will
call an expression w : ϕ a labelled formula, where w ∈L and ϕ ∈FOR, and
w will be called a label. We will abbreviate the set of all labelled formulas by
LF. Any labels superscribed with ‘+’ are restricted to belong to L+ and labels
superscribed with ‘−’ to belong to L−. Labels without a superscript are not
restricted. Intuitively, w stands for the denotation of ϕ in an intended model.
Labels with ‘+’ in the superscript denote elements of D, whereas labels with
superscribed ‘−’ represent elements of U \D. Thus, expressions of the form w = v
or w ̸= v reﬂect, respectively, the equality or distinctness of two denotations. By
Id+, Id−we denote the sets of, respectively, all equalities and all inequalities of
labels. Finally, we let Id = Id+ ∪Id−.
A tableau generated by the system for the logic SCI is a derivation tree whose
nodes are assigned labelled formulas and (in)equality expressions. A simple path
B from the root to a leaf in a tableau T is called branch of T . We will identify
a branch B with the set of labelled formulas and (in)equalities occurring on B.
The rules of our tableau system have the following general form:
Φ
Ψ1|...|Ψn ,
where Φ is the set of premises and each Ψi, for i ∈{1, . . . , n}, is a set of
conclusions. Intuitively, the ‘|’ symbol should be read as a meta-disjunction. A
rule with only one set of conclusions is called a non-branching rule. A rule with
several sets of conclusions is a branching rule. In TSCI all rules where Ψi, for
i ∈{1, . . . , n} contain labelled formulas are called decomposition rules. All rules
with a single equality statement as the conclusion are called equality rules. The
remaining rules, in which ⊥occurs as the conclusion, are referred to as closure
rules. If we have a decomposition rule (R) with w : ϕ as its premise, then (R) is
applicable to w : ϕ occurring on a branch B if it has not been applied to w : ϕ
on B before. Otherwise w : ϕ is called (R)-expanded on B. For an equality rule
(R) with Φ as the set of premises and w = v as the conclusion, (R) is applicable
to Φ ⊆B if w = v is not present on B. Otherwise Φ is (R)-expanded on B.
Intuitively, if a set of premises Φ is (R)-expanded on B, then applying (R) to Φ
would not add any new information to B.
A branch B of a tableau T is extended by applying rules of the system to
sets of labelled formulas and (in)equality statements that are already on B. A
label w is present on B if there exists a formula ϕ such that w : ϕ occurs on B.
Otherwise w is fresh on B. A branch B is called closed if one of the closure rules
has been applied to it, that is, when an inconsistency occurs on B. A branch
that is not closed, is open. A branch B is fully expanded if it is closed or no rules
are applicable on it. A tableau T is called closed if all of its branches are closed.
Otherwise T is called open. We call T fully expanded if all of its branches are
fully expanded.
Analytic tableaux are satisﬁability checkers, so a tableau proof of a formula ϕ
is a closed tableau with a labelled formula w−: ϕ at its root. A formula is tableau-
valid if all tableaux with w−: ϕ at the root are closed. On the other hand, a

(¬+)
w+ : ¬ϕ
v−: ϕ
(¬−)
w−: ¬ϕ
v+ : ϕ
(→+)
w+ : ϕ →ψ
v−: ϕ
u−: ψ

v−: ϕ
u+ : ψ

v+ : ϕ
u+ : ψ
(→−)
w−: ϕ →ψ
v+ : ϕ
u−: ψ
(≡+)
w+ : ϕ ≡ψ
v+ : ϕ
u+ : ψ
v+ = u+

v−: ϕ
u−: ψ
v−= u−
(≡−)
w−: ϕ ≡ψ
v+ : ϕ
u+ : ψ
v+ ̸= u+

v+ : ϕ
u−: ψ

v−: ϕ
u+ : ψ

v−: ϕ
u−: ψ
v−̸= u−
(≡¬)
ϕ ≈ψ
u : ¬ϕ
y : ¬ψ
u = y
(≡→)
ϕ ≈ψ
χ ≈θ
x : ϕ →χ
z : ψ →θ
x = z
(≡≡)
ϕ ≈ψ
χ ≈θ
x : ϕ ≡χ
z : ψ ≡θ
x = z
(F)
w : ϕ
v : ϕ
w = v
(sym)
w = v
v = w
(tran)
w = v
v = u
w = u
(⊥1)
w = v
w ̸= v
⊥
(⊥2)
w+ = v−
⊥
1 Labels occurring in conclusions of the rules: (¬+), (¬−), (→+), (→−), (≡+), (≡−)
are fresh on the branch.
2 The abbreviation ϕ ≈ψ represents the set of three preconditions: w : ϕ, v : ψ,
w = v, for some w, v ∈L. Similarly for χ ≈θ.
Fig. 1. Tableau system TSCI
formula ϕ is tableau-satisﬁable if there exists an open and fully expanded tableau
with a labelled formula w+ : ϕ at its root. Note that our notion of tableau-
satisﬁability matches the usual notion of satisﬁability as a failure of ﬁnding a
proof. Indeed, if a formula ϕ is not tableau-valid, that is, there exists a tableau
with w−: ϕ at the root which has an open branch, then ¬ϕ is tableau-satisﬁable.
Thus, the standard duality between validity and satisﬁability is reﬂected in the
concepts of tableau-validity and tableau-satisﬁability.
3.1
Tableau System for SCI
The rules presented in Figure 1 constitute the tableau system TSCI for the logic
SCI. The decomposition rules (¬+), (¬−), (→+), (→−), (≡+), (≡−) reﬂect the
semantics of ¬, →and ≡deﬁned in the conditions 1–3 from Section 2. Note that
an application of any of these rules introduces to a branch fresh labels for each of
the subformulas into which the premise formula is decomposed. By that means,
all occurrences of subformulas of the input formula ϕ are assigned their unique
Tableau-based Decision Procedure for Non-Fregean Logic. . .
47

48
J. Goli´nska-Pilarek et al.
labels. A few words of extra commentary on the rule (≡−) are in order. It de-
composes a formula involving the ≡connective, which is assumed to be false. By
the semantics of ≡we know that the constituents of the initial ≡-formula have
distinct denotations. If these denotations have diﬀerent polarities, representing
diﬀerent truth values (disjuncts 2 and 3 in the denominator of the rule), then no
additional information has to be stored about the distinctness of these denota-
tions. If, on the other hand, the denotations have the same polarity, representing
the same truth value (disjuncts 1 and 4 in the denominator of the rule), then
extra information is added, namely that the denotations of both formulas are dis-
tinct. The rules (≡¬), (≡→) and (≡≡) are tableau-counterparts of the axioms 5,
6, and 7, respectively. The rule (F) ensures that a valuation that can be read
oﬀfrom an open branch is a function, i.e., that all denotations assigned to the
same formula on a branch are equal. The rules (sym) and (tran) guarantee that
equalities appearing on a branch preserve all properties of the =-relation. Note
that an application of a closure rule to a branch is always a result of transforma-
tions of equality statements. While executing TSCI we always apply closure rules
eagerly, that is, whenever a closure rule can be applied, it should be applied.
An example of a tableau proof generated by TSCI can be found in Figure 2.
w−: ϕ ≡ψ →(ϕ →ψ)
v+ : ϕ ≡ψ
u−: ϕ →ψ
x+ : ϕ
y−: ψ
z+ : ϕ
t+ : ψ
z+ = t+
y−= t+
⊥
(⊥2)
(F)
(≡+)
z−: ϕ
t−: ψ
z−= t−
x+ = z−
⊥
(⊥2)
(F)
(→−)
(→−)
Fig. 2. Tableau proof for the axiom ϕ ≡
ψ →(ϕ →ψ)
The tableau system TSCI is a user-
friendly and elegant solution to the
problem most non-labelled systems
for SCI struggle with, namely substi-
tutability of identical formulas within
other formulas with identity preser-
vation. In a derivation that can re-
sult in yielding conclusions of greater
complexity than premises, as shown
at the end of Section 2. It often leads
to a loss of subformula property in a
deduction system. TSCI, on the other
hand, reduces the whole reasoning to
a simple equality calculus where only
identities or non-identities between la-
bels are substantial for the result of
a given derivation. It allows us to cir-
cumvent the abovementioned problem
by replacing it with a question: are la-
bels representing given formulas equal
or distinct?
3.2
Soundness and Completeness4
First, we will prove soundness of the tableau system TSCI.
4 A technical appendix to the paper with all omitted proofs can be found in [12]

Let A, B be ﬁnite sets such that A ⊆LF and B ⊆Id. A set A ∪B is said to
be satisﬁed in an SCI-model M = ⟨U, D, ˜¬, ˜→, ˜≡⟩by a valuation V in M and a
function f : L −→U if and only if the following hold: (1) V (ϕ) = f(w), for all
w ∈L and ϕ ∈FOR such that w : ϕ ∈A, (2) f(w) ∈D iﬀw ∈L+, for all labels
w that occur in A ∪B, (3) f(w) = f(v), for all w, v ∈L such that w = v ∈B,
(4) f(w) ̸= f(v), for all w, v ∈L such that w ̸= v ∈B. A set A ∪B is said
to be SCI-satisﬁable whenever there exist an SCI-model M = ⟨U, D, ˜¬, ˜→, ˜≡⟩, a
valuation V in M, and a function f : L −→U such that A ∪B is satisﬁed in M
by V and f.
Proposition 1. For every satisﬁable SCI-formula ϕ and for all w+ ∈L+ it
holds that {w+ : ϕ} is SCI-satisﬁable.
Proposition 2. For all w, v ∈L, w+ ∈L+, and v−∈L−, and for all ﬁnite
X ⊆LF ∪Id, the sets X ∪{w = v, w ̸= v} and X ∪{w+ = v−} are not SCI-
satisﬁable.
Let (R)
Φ
Ψ1|...|Ψn , for n ≥1, be a decomposition or equality rule of the tableau
system TSCI. A rule (R) is referred to as sound whenever, for every ﬁnite set
X ⊆LF∪Id, it holds that X ∪Φ is SCI-satisﬁable iﬀX ∪Φ∪Ψi is SCI-satisﬁable
for some i ∈{1, . . . , n}.
Proposition 3. Decomposition and equality rules of the tableau system TSCI are
sound.
Theorem 1 (Soundness). The tableau system TSCI is sound, that is, if an SCI
formula ϕ is satisﬁable, then ϕ is tableau-satisﬁable.
Proof. We prove the contrapositive. Let T be a closed TSCI-tableau with w+ : ϕ
at its root. Then, each branch of T contains either w+ = v−or both w = v
and w ̸= v, for some w, v ∈L, w+ ∈L+, v−∈L−. By Proposition 2, both
sets X ∪{w+ = v−} and X ∪{w = v, w ̸= v} are not SCI-satisﬁable, for any
ﬁnite set X ⊆LF ∪Id. By Proposition 3, each application of TSCI-rules preserves
SCI-satisﬁability. Hence, going from the bottom to the top of the tree T , on each
step of the construction of TSCI-tableau we get SCI-unsatisﬁable sets. Thus, we
can conclude that w+ : ϕ is not SCI-satisﬁable, and thus by Proposition 1 we
obtain that ϕ is not SCI-satisﬁable. Therefore, each satisﬁable SCI-formula ϕ is
tableau-satisﬁable.
To prove completeness of the system TSCI we need to show that if, for a given
formula ϕ, TSCI does not yield a tableau proof, then ϕ is not valid, i.e., there
exists a countermodel M = ⟨U, D, V ⟩such that M ̸|= ϕ.
Suppose that we want to obtain a tableau-proof for a formula ϕ. To that
end, we run the TSCI-tableau algorithm with a labelled formula w−: ϕ at the
root of the tableau, for w−∈L−. Suppose that it yields an open tableau as a
result. It means that the tableau contains an open and fully expanded branch
B. We will demonstrate how to construct a structure MB = ⟨U, D, ˜¬, ˜→, ˜≡⟩
using information stored on B and show that it actually is an SCI-countermodel
Tableau-based Decision Procedure for Non-Fregean Logic. . .
49

50
J. Goli´nska-Pilarek et al.
falsifying ϕ. Let L+
B be the set of all labels superscribed with ‘+’ occurring on
B, let L−
B be the set of all labels superscribed with ‘−’ occurring on B and
let LB = L+
B ∪L−
B. Moreover, let FORB be the set of all SCI-formulas ϕ such
that w : ϕ occurs on B, for some w ∈LB. Note that all elements of FORB are
subformulas of ϕ. Before we characterize the construction of MB, we deﬁne a
binary relation ∼⊆LB × LB in the following way:
w ∼v
iﬀ
w = v occurs on B.
Proposition 4. The relation ∼is an equivalence relation and (L+
B ×L−
B)∩∼= ∅.
Let ML+
B be a set resulting from choosing exactly one label from each element
of (L+
B)/∼. Sets ML−
B and MLB are deﬁned analogically with the assumption that
w−∈ML−
B, where w−is such that w−: ϕ is at the root of an open tableau. Of
course, neither of these sets is uniquely determined.
Proposition 5. For all ψ ∈FOR and w, v ∈LB the following holds:
if both w : ψ and v : ψ belong to B, then w ∼v.
We say that w ∈MLB is (¬)-closed whenever there are ψ ∈FOR, u ∈MLB,
and v, t ∈LB such that w ∼v, u ∼t and labelled formulas v : ψ, t : ¬ψ belong
to B. Let w, v ∈MLB and # ∈{→, ≡}. The pair (w, v) is said to be (#)-closed
whenever there exist ψ, θ ∈FOR, u ∈MLB, and t, x, y ∈LB such that w ∼t,
v ∼x, u ∼y and labelled formulas t : ψ, x : θ, y : (ψ#θ) occur on the branch B.
The branch structure MB = ⟨U, D, ˜¬, ˜→, ˜≡⟩is deﬁned as follows:
– D = {w+ | w+ ∈ML+
B} ∪{w+}, where w+ /∈LB
– U = D ∪ML−
B.
It follows from the above that U \D = ML−
B. The operations ˜¬, ˜→, ˜≡are deﬁned
for all w, v ∈U in the following way:
˜¬w
df=
⎧
⎪
⎨
⎪
⎩
u ∈U,
if there are ψ ∈FOR and v, t ∈LB such that w = v, u = t,
v : ψ, and t : ¬ψ are on B
w+,
if w is not (¬)-closed and w ̸∈D
w−,
otherwise
w ˜→v
df=
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
u ∈U,
if there are ψ, θ ∈FOR and t, x, y ∈LB such that w = t,
v = x, u = y, t : ψ, x : θ, and y : (ψ →θ) are on B
w+,
if v = w+ or both (w = w+ and v ∈D), or it holds that
(w, v) is not (→)-closed and either w ̸∈D or v ∈D
w−,
otherwise
w ˜≡v
df=
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
u ∈U,
if there are ψ, θ ∈FOR and t, x, y ∈LB such that w = t,
v = x, u = y, t : ψ, x : θ, and y : (ψ ≡θ) are on B
w+,
if w = v and either w = w+ or the pair (w, v) is not
(≡)-closed
w−,
otherwise
Due to the properties of the sets ML+
B and ML−
B, we obtain:

Proposition 6. The sets D and U \ D are non-empty and D ∩(U \ D) = ∅.
The following series of results ensure that the operations ˜¬, ˜→, and ˜≡reﬂect
the semantics of SCI.
Proposition 7. ˜¬ is a function on U and for all w ∈U:
(∗) ˜¬w ∈D iﬀw ̸∈D.
Proposition 8. ˜→is a function on U and for all w, v ∈U, the following holds:
(∗) w ˜→v ∈D iﬀw ̸∈D or v ∈D.
Proposition 9. ˜≡is a function on U and for all w, v ∈U the following holds:
(∗) w ˜≡v ∈D iﬀw = v.
Propositions 6–9 imply:
Proposition 10. The structure MB is an SCI-model.
In what follows, the structure MB will be referred to as branch model.
Now, let V : FOR −→U be a function such that for all p ∈AF:
V (p) =

u ∈MLB,
if there is w ∈LB such that w : p ∈B and w ∼u
w+,
otherwise
and for all ψ, θ ∈FOR the following hold:
V (¬ψ) = ˜¬V (ψ)
V (ψ#θ) = V (ψ) ˜#V (θ), for # ∈{→, ≡}.
Proposition 11. The function V is well deﬁned and it is a valuation in MB.
Proposition 12. For all ψ ∈FOR and w ∈LB it holds that:
(∗) If w : ψ ∈B, then w ∼V (ψ).
Theorem 2 (Completeness). The tableau system TSCI is complete, that is, if
a formula ϕ is SCI-valid, then ϕ has a tableau proof.
Proof. Let ϕ be a valid SCI-formula. Suppose that ϕ does not have a tableau
proof. Then, each TSCI-tableau with w−: ϕ at its root is open. Let B be an open
and fully expanded branch of an open tableau for w−: ϕ. By Proposition 10,
the structure MB = ⟨U, D, ˜¬, ˜→, ˜≡⟩is an SCI-model. Let V be a valuation in
MB deﬁned as before Proposition 11 Then, by Proposition 12, w−∼V (ϕ), and
hence V (ϕ) ̸∈D. Thus, ϕ is not true in MB, which contradicts the assumption
that ϕ is SCI-valid.
Tableau-based Decision Procedure for Non-Fregean Logic. . .
51

52
J. Goli´nska-Pilarek et al.
3.3
Termination
It turns out that the system presented in Section 3.1 terminates without any
external blocking mechanisms involved which would impose some additional re-
strictions on rule-application. The only caveat that has to be added to the system
is the one that we have already expressed, namely that no rule (R) can be applied
to the set of premises that is (R)-expanded.
Theorem 3. The tableau system TSCI is terminating.
Proof. The argument hinges on two observations. First, the decomposition rules
are the only rules that introduce fresh labels to a branch B of a TSCI-tableau
T , and, as mentioned before, on a branch B each occurrence of a subformula of
the initial formula ϕ is assigned its unique label. Thus, since an application of
any of the above rules decreases the complexity of the processed formula and
the rule cannot be applied twice to the same premise, the total number of labels
occurring on a branch does not exceed the size of ϕ measured as the number of
all occurrences of subformulas of ϕ (henceforth denoted by |ϕ|). Secondly, the
equality rules can only add equalities between labels to a branch, provided that
such an equality statement is not already present thereon. The maximal number
of such equalities is quadriatic in the total number of labels occurring on a
branch. Thus, for each SCI-formula ϕ, on any branch B of a TSCI-tableau for ϕ,
rules are applied at most |ϕ|+|ϕ|2 +1 times, where ‘1’ in the formula represents
an application of a closure rule. This makes the whole derivation ﬁnite.
Corollary 1. For each SCI-formula ϕ every branch B of a TSCI-tableau deriva-
tion for ϕ is of polynomial size with respect to the size of ϕ.
Since SCI contains classical propositional logic, it inherits the NP-lower bound
for the satisﬁability problem therefrom. Together with membership of SCI-satis-
ﬁability in NP it gives the following:
Theorem 4. TSCI is a complexity-optimal decision procedure for the NP-com-
plete problem of SCI-satisﬁability.
Proof. Immediate from Corollary 1 and the fact that each branching rule of TSCI
is ﬁnitely branching.
3.4
Limiting the Number of Labels
To boost the performance of the system TSCI we propose a reﬁnement thereof. It
consists in limiting the number of fresh labels introduced to a tableau by decom-
position rules by introducing an additional condition called urfather blocking
Given a formula ϕ for which we construct a TSCI-tableau T , for each sub-
formula ψ of ϕ, let’s call the ﬁrst occurrence of a labelled formula w : ψ on a
branch B of T the ψ-urfather on B. The system TSCI + (UB) (tableau system for
SCI with urfather blocking) is composed of the rules of TSCI and an additional
constraint:

(UB) For each labelled formula w : ϕ that occurs on a branch B, no decompo-
sition rule can be applied to w : ϕ unless it is the ϕ-urfather on B.
It turns out that augmenting TSCI with (UB) does not lead to any unwanted
consequences such as giving up the completeness.
Proposition 13. For every SCI-formula ϕ, if ϕ has a TSCI-tableau proof, then
ϕ has TCSCI + (UB)-tableau proof.
Theorem 5. TSCI + (UB) is sound, complete, terminating, and complexity-op-
timal for SCI-satisﬁability.
Proof. The soundness of TSCI + (UB) straightforwardly follows from the sound-
ness of TSCI and the fact that both systems share the full set of rules. The argu-
ment for termination of TSCI + (UB) and complexity-optimality of TSCI + (UB)
for SCI-satisﬁability goes along the same lines as the proofs of Theorems 3 and 4,
and rests on the fact that, for each formula ϕ, a TSCI + (UB)-tableau contains
at most as many labels as a TSCI-tableau. The completeness of
TSCI + (UB) is a direct consequence of Proposition 13 and Theorem 2.
4
Implementation
4.1
Overview
We have written proof-of-concept type implementations of the labelled tableau
system described in the present article and its variant with urfather blocking, as
well as a dual-tableau-based theorem prover for SCI based on the system from [5].
Since the last system does not enjoy the termination property, the implemen-
tation relies on heuristics in this respect. All three provers are implemented in
the Haskell language using similar programming techniques in a casual manner,
without any serious attempt to optimize the code or to test it extensively, as the
programs are only intended as temporary aids to ongoing research.
In testing, the labelled-tableau provers turned out to need drastically more
computing resources even in many quite modest test cases. For instance, the
axiom ((p ≡q) ∧(r ≡s)) →((p ≡r) ≡(q ≡s)) generates a labelled tableau of
depth 37 consisting of 619 nodes, which urfather blocking reduces to depth 33
and 555 nodes, while the tree of the dual-tableau prover has depth 18 and only
67 nodes. The diﬀerence appears to be mostly due to the large branching factor of
the identity rules of the labelled-tableau system. However, in some test cases the
labelled-tableau system yields a smaller tree than the other prover. In general,
the labelled tableau method seems to tolerate relatively well formulas consisting
of a large number of very simple identitities.
4.2
Technical Notes
Unlike the abstract tree described above, each node of which contains only a
single labelled formula, each node of the tree built by the program contains a
Tableau-based Decision Procedure for Non-Fregean Logic. . .
53

54
J. Goli´nska-Pilarek et al.
list of all the labelled formulas encountered so far on the branch. This allows the
program to freely manipulate the list to keep track of what rules have already
been applied to which formulas. There are three main types of nodes: normal
nodes, identity nodes, and leaves. First, the decomposition rules are applied in
normal nodes. Once they have been applied to exhaustion, the tree is extended
with identity nodes, in which the identity rules are applied. At any point, one
of the closure rules (⊥1) or (⊥2) can be applied to append a special closure leaf
node. An open leaf node is appended whenever there are no more rules to apply
in an identity node and the branch remains open.
4.3
Test Results
We found a randomly generated provable SCI-formula that turned out to be
somewhat challenging to an earlier prover. The formula, which we will call the
ϕ here, looks as follows:
(((q ≡p) →(p →r)) ≡((p →(p ↔p)) ≡p))
→(((r ∧p) ↔(p ≡p)) ∨((p ∧p) ∨¬q))
We denote by ψ the formula obtained by replacing each occurrence of p in ϕ
by ϕ itself. We deﬁned a provability-preserving transformation T that turns an
SCI-formula into a Horn clause consisting of very simple identities.
We present the results of attempting to prove the formulas ϕ, ¬ϕ, ψ, ¬ψ,
T(ϕ), and T(¬ϕ). These are chosen to illustrate some of the variety of outcomes
we observed. As noted above, ϕ is provable, and therefore also ψ and T(ϕ) are
provable. The results are of the form depth/size, where depth is the maximal
branch length and size is the number of nodes in the entire tree. There are
entries for the dual-tableau-based prover (DTSCI), the current labelled-tableau
prover (TSCI), and the same with the urfather blocking condition (TSCI + (UB)).
Several entries are missing due to exhaustion of memory (the programs were
tested on a machine with 8GB of RAM; adding several gigabytes of swap space
did not make a diﬀerence).
Formula
DTSCI
TSCI
TSCI + (UB)
depth
size
depth
size
depth
size
ϕ
27
299
37
4724
32
4659
¬ϕ
12
42
202
111539
106
95724
ψ
61
17729
−
−
46
3023804
¬ψ
42
602
−
−
−
−
T(ϕ)
−
−
143
40230
106
34158
T(¬ϕ)
−
−
529
52789
490
46153
5
Conclusions
In this paper we introduced the system TSCI which is the ﬁrst complexity-optimal
decision procedure for the logic SCI devised in the paradigm of labelled tableaux.

TSCI is conceptually simple and directly reﬂects the semantics of the logic. The
reasoning performed in TSCI has two components: decomposition and equality
reasoning. Interestingly, it is the latter that is responsible for closing tableau
branches, and thus, yielding tableau proofs for formulas. In this respect TSCI
is based on similar conceptual foundations as calculi generated by the tableau-
synthesis framework from [20].We provided an implementation of TSCI and a
variant with urfather blocking, and we compared their performance with the
performance of another implemented deduction system for SCI which has not
been proven to be terminating or complete. There was no unique winner; the new
system was better at dealing with formulas with complex networks of identities,
while the old, unproven system handled other types of formulas better. Urfather
blocking yielded modest reductions in depth and total size.
In future research we want to address three main problems. First, we would
like to optimize our tableau algorithm by introducing further reﬁnements to it,
such as decreasing the branching factor of the rule (→+) and, by that means,
making it “information-deleting”. Some prelimiary results on the implementa-
tion of TSCI with the modiﬁed rule (→+) show a promising reduction of the
size of generated tableaus. Moreover, we plan to search for heuristics and rule-
application strategies which would, too, allow to minimize the size of tableaux
yielded by TSCI for certain classes of formulas. It seems that it is not always
necessary to fully decompose the input formula before performing any equality
reasoning, if a contradiction is to be reached on a branch. Secondly, we would like
to develop the dual-tableau systems from [5] and [10] to full-ﬂedged decision pro-
cedures, implement them, and compare the performance of all three algorithms
on an extensive set of various SCI-formulas. Thirdly, we intend to extend the
labelled tableaux-based approach presented in this paper to other non-Fregean
logics, both classical (such as modal non-Fregean logics) and deviant (such as in-
tuitionistic or many-valued non-Fregean logics, or Grzegorczyk’s logic). Finally,
we would like to take a closer look at various normal forms of SCI formulas, one
of which was mentioned in Section 4, and decide in what cases it pays oﬀto
transform a formula into a normal form before running a decision procedure,
rather than running it directly on the initial formula.
References
1. Bloom, S.L., Suszko, R.: Semantics for the sentential calculus with identity. Studia
Logica 28(1), 77–81 (1971). https://doi.org/10.1007/BF02124265
2. Bloom,
S.L.,
Suszko,
R.:
Investigations
into
the
sentential
calculus
with
identity.
Notre
Dame
Journal
of
Formal
Logic
13(3),
289–308
(1972).
https://doi.org/10.1305/ndjﬂ/1093890617
3. Chlebowski, S.: Sequent calculi for SCI. Studia Logica 106, 541–563 (2018).
https://doi.org/10.1007/s11225-017-9754-8
4. Chlebowski, S., Leszczy´nska-Jasion, D.: An investigation into intuitionistic
logic with identity. Bulletin of the Section of Logic 48(4), 259–283 (2019).
https://doi.org/10.18778/0138-0680.48.4.02
Tableau-based Decision Procedure for Non-Fregean Logic. . .
55

56
J. Goli´nska-Pilarek et al.
5. Goli´nska-Pilarek, J.: Rasiowa-sikorski proof system for the non-Fregean senten-
tial logic SCI. Journal of Applied Non-Classical Logics 17(4), 511–519 (2007).
https://doi.org/10.3166/jancl.17.511-519
6. Goli´nska-Pilarek, J.: On the minimal non-Fregean Grzegorczyk’s logic. Studia Log-
ica 104(2), 209–234 (2016). https://doi.org/10.1007/s11225-015-9635-y
7. Goli´nska-Pilarek,
J.,
Huuskonen,
T.:
Number
of
extensions
of
non-
Fregean
logics.
Journal
of
Philosophical
Logic
34(2),
193–206
(2005).
https://doi.org/10.1007/s10992-004-6366-3
8. Goli´nska-Pilarek,
J.,
Huuskonen,
T.:
Non-Fregean
propositional
logic
with
quantiﬁers.
Notre
Dame
Journal
of
Formal
Logic
57(2),
249–279
(2016).
https://doi.org/10.1215/00294527-3470547
9. Goli´nska-Pilarek, J., Huuskonen, T.: A mystery of Grzegorczyk’s logic of descrip-
tions. In: Garrido, A., Wybraniec-Skardowska, U. (eds.) The Lvov-Warsaw School.
Past and Present, pp. 731–745. Studies in Universal Logic, Springer Nature (2018).
https://doi.org/10.1007/978-3-319-65430-0_51
10. Goli´nska-Pilarek, J., Welle, M.: Deduction in non-Fregean propositional logic SCI.
Axioms 8, 115 (2019). https://doi.org/10.3390/axioms8040115
11. Goli´nska-Pilarek, J., Zawidzki, M.: Tableau-based decision procedure for the logic
SCI. In: Gigante, N., Mari, F., Orlandini, A. (eds.) Proceedings of the 1st Workshop
on Artiﬁcial Intelligence and Formal Veriﬁcation, Logic, Automata, and Synthe-
sis, co-located with the 18th International Conference of the Italian Association
for Artiﬁcial Intelligence, OVERLAY@AI*IA 2019, Rende, Italy, November 19-20,
2019. CEUR Workshop Proceedings, vol. 2509, pp. 23–28 (2019)
12. Goli´nska-Pilarek, J., Huuskonen, T., Zawidzki, M.: Tableau-based decision proce-
dure for non-fregean logic of sentential identity (2021), arXiv: 2104.14697
13. Ishii, T.: Propositional calculus with identity. Bulletin of the Section of Logic 27(3),
96–104 (1998)
14. Lewitzka, S.: ϵI: : An intuitionistic logic without Fregean Axiom and with pred-
icates for truth and falsity. Notre Dame Journal of Formal Logic 50(3), 275–301
(2009). https://doi.org/10.1215/00294527-2009-012
15. Lewitzka, S.: ϵK: a non-Fregean logic of explicit knowledge. Studia Logica 97(2),
233–264 (2011). https://doi.org/10.1007/s11225-011-9304-8
16. Lewitzka, S.: Denotational semantics for modal systems S3 S5 extended by axioms
for propositional quantiﬁers and identity. Studia Logica 103(3), 507–544 (2015).
https://doi.org/10.1007/s11225-014-9577-9
17. Lukowski, P.: Intuitionistic sentential calculus with classical identity. Bulletin of
the Section of Logic 19(4), 147–150 (1990)
18. Michaels, A.: A uniform proof procedure for SCI tautologies. Studia Logica 33(3),
299–310 (1974). https://doi.org/10.1007/BF02123284
19. Orlowska, E., Goli´nska-Pilarek, J.: Dual Tableaux: Foundations, Methodol-
ogy,
Case
Studies,
Trends
in
Logic,
vol.
33.
Springer,
Dordrecht
(2011).
https://doi.org/10.1007/978-94-007-0005-5
20. Schmidt, R.A., Tishkovsky, D.: Automated synthesis of tableau calculi. Logi-
cal Methods in Computer Science 7(2) (2011). https://doi.org/10.2168/LMCS-
7(2:6)2011
21. Suszko,
R.:
Abolition
of
the
Fregean
axiom.
In:
Parikh,
R.
(ed.)
Logic
Colloquium. Lecture Notes in Mathematics, vol. 453, pp. 169–239 (1975).
https://doi.org/10.1007%2FBFb0064874
22. Wasilewska, A.: A sequence formalization for SCI. Studia Logica 35(3), 213–217
(1976). https://doi.org/10.1007/BF02282483

23. Wasilewska,
A.:
DFC-algorithms
for
Suszko
logic
and
one-to-one
Gentzen
type
formalizations.
Studia
Logica
43(4),
395–404
(1984).
https://doi.org/10.1007/BF00370509
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/
4.0/), which permits use, sharing, adaptation, distribution and reproduction in any
medium or format, as long as you give appropriate credit to the original author(s) and
the source, provide a link to the Creative Commons license and indicate if changes
were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.
Tableau-based Decision Procedure for Non-Fregean Logic. . .
57

Learning from Łukasiewicz and Meredith:
Investigations into Proof Structures
1 Berlin, Germany info@christophwernhard.com
2 Technical University Darmstadt, Darmstadt, Germany
bibel@gmx.net
Abstract. The material presented in this paper contributes to estab-
lishing a basis deemed essential for substantial progress in Automated
Deduction. It identiﬁes and studies global features in selected problems
and their proofs which oﬀer the potential of guiding proof search in a
more direct way. The studied problems are of the wide-spread form of “ax-
iom(s) and rule(s) imply goal(s)”. The features include the well-known
concept of lemmas. For their elaboration both human and automated
proofs of selected theorems are taken into a close comparative considera-
tion. The study at the same time accounts for a coherent and comprehen-
sive formal reconstruction of historical work by Łukasiewicz, Meredith
and others. First experiments resulting from the study indicate novel
ways of lemma generation to supplement automated ﬁrst-order provers
of various families, strengthening in particular their ability to ﬁnd short
proofs.
1
Introduction
Research in Automated Deduction, also known as Automated Theorem Proving
(ATP), has resulted in systems with a remarkable performance. Yet, deep math-
ematical theorems or otherwise complex statements still withstand any of the
systems’ attempts to ﬁnd a proof. The present paper is motivated by the thesis
that the reason for the failure in more complex problems lies in the local orient-
edness of all our current methods for proof search like resolution or connection
calculi in use.
In order to ﬁnd out more global features for directing proof search we start
out here to study the structures of proofs for complex formulas in some detail
and compare human proofs with those generated by systems. Complex formulas
of this kind have been considered by Łukasiewicz in [19]. They are complex in the
sense that current systems require tens of thousands or even millions of search
steps for ﬁnding a proof if any, although the length of the formulas is very short
indeed. How come that Łukasiewicz found proofs for those formulas although
he could never carry out more than, say, a few hundred search steps by hand?
Which global strategies guided him in ﬁnding those proofs? Could we discover
such strategies from the formulas’ global features?
By studying the proofs in detail we hope to come closer to answers to those
questions. Thus it is proofs, rather than just formulas or clauses as usually in
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5_4
Christoph Wernhard1
and Wolfgang Bibel2
58–75, 2021.

Investigations into Proof Structures
59
ATP, which is in the focus of our study. In a sense we are aiming at an ATP-
oriented part of Proof Theory, a discipline usually pursued in Logic yet under
quite diﬀerent aspects. This meta-level perspective has rarely been taken in ATP
for which reason we cannot rely on the existing conceptual basis of ATP but have
to build an extensive conceptual basis for such a study more or less from scratch.
This investigation thus analyzes structures of, and operations on, proofs for
formulas of the form “axiom(s) and rule(s) imply goal(s)”. It renders condensed
detachment, a logical rule historically introduced in the course of studying these
complex proofs, as a restricted form of the Connection Method (CM) in ATP. All
this is pursued with the goal of enhancing proof search in ATP in mind. As noted,
our investigations are guided by a close inspection into proofs by Łukasiewicz
and Meredith. In fact, the work presented here amounts at the same time to a
very detailed reconstruction of those historical proofs.
The rest of the paper is organized as follows: In Sect. 2 we introduce the
problem and a formal human proof that guides our investigations and compare
diﬀerent views on proof structures. We then reconstruct in Sect. 3 the historical
method of condensed detachment in a novel way as a restricted variation of the
CM where proof structures are represented as terms. This is followed in Sect. 4 by
results on reducing the size of such proof terms for application in proof shortening
and restricting the proof search space. Section 5 presents a detailed feature table
for the investigated human proof, and Sect. 6 shows ﬁrst experiments where the
features and new techniques are used to supplement the inputs of ATP systems
with lemmas. Section 7 concludes the paper. Supplementary technical material
including proofs is provided in the report [37]. Data and tools to reproduce the
experiments are available at http://cs.christophwernhard.com/cd.
2
Relating Formal Human Proofs with ATP Proofs
In 1948 Jan Łukasiewicz published a formal proof of the completeness of his
shortest single axiom for the implicational fragment (IF), that is, classical propo-
sitional logic with implication as the only logic operator [19]. In his notation the
implication p →q is written as Cpq. Following Frank Pfenning [27] we formal-
ize IF on the meta-level in the ﬁrst-order setting of modern ATP with a single
unary predicate P to be interpreted as something like “provable” and represent
the propositional formulas by terms using the binary function symbol i for im-
plication. We will be concerned with the following formulas.
Nickname [28][29, p. 319]
Łukasiewicz’s notation
First-order representation
Simp
CpCqp
∀pq P(i(p, iqp))
Peirce
CCCpqpp
∀pq P(i(i(ipq), p), p)
Syll
CCpqCCqrCpr
∀pqr P(i(ipq, i(iqr, ipr)))
Syll Simp
CCCpqrCqr
∀pqr Pi(i(ipq, r), iqr)
Łukasiewicz
CCCpqrCCrpCsp
∀pqrs P(i(i(ipq, r), i(irp, isp)))
IF can be axiomatized by the set of the three axioms Simp, Peirce and Syll,
known as Tarski-Bernays Axioms. Alfred Tarski in 1925 raised the problem to

60
C. Wernhard and W. Bibel
Pi(i(ipq, r), i(irp, isp)) ∧(Px ∧Pixy →Py) →Pi(ipq, i(iqr, ipr))
5
4
3
2
1
Fig. 1. ŁDS along with its ﬁve uniﬁable connections.
characterize IF by a single axiom and solved it with very long axioms, which led
to a search for the shortest single axiom, which was found with the axiom nick-
named after him in 1936 by Łukasiewicz [19]. In 1948 he published his derivation
that Łukasiewicz entails the three Tarski-Bernays Axioms, expressed formally by
the method of substitution and detachment. Detachment is also familiar as modus
ponens. Łukasiewicz’s proof involves 34 applications of detachment. Among the
Tarski-Bernays axioms Syll is by far the most challenging to prove, hence his
proof centers around the proof of Syll, with Peirce and Simp spinning oﬀas
side results. Carew A. Meredith presented in [24] a “very slight abridgement” of
Łukasiewicz’s proof, expressed in his framework of condensed detachment [28],
where the performed substitutions are no longer explicitly presented but implic-
itly assumed through uniﬁcation. Meredith’s proof involves only 33 applications
of detachment. In our ﬁrst-order setting, detachment can be modeled with the
following meta-level axiom.
Det
def
= ∀xy (Px ∧Pixy →Py).
In Det the atom Px is called the minor premise, Pixy the major premise, and
Py the conclusion. Let us now focus on the following particular formula.
ŁDS
def
= Łukasiewicz ∧Det →Syll.
“Problem ŁDS” is then the problem of determining the validity of the ﬁrst order
formula ŁDS. In view of the CM [1,2,3], a formula is valid if there is a spanning
and complementary set of connections in it. In Fig. 1 ŁDS is presented again,
nicknames dereferenced and quantiﬁers omitted as usual in ATP, with the ﬁve
uniﬁable connections in it. Observe that p, q, r, s on the left side of the main
implication are variables, while p, q, r on the right side are Skolem constants. Any
CM proof of ŁDS consists of a number of instances of the ﬁve shown connections.
Meredith’s proof, for example, corresponds to 491 instances of Det, each linked
with three instances of its ﬁve incident connections.
Figure 2 compares diﬀerent representations of a short formal proof with
the Det meta axiom. There is a single axiom, Syll Simp, and the theorem
is ∀pqrstu Pi(p, i(q, i(r, i(s, i(t, ius))))). Figure 2a shows the structure of a CM
proof. It involves seven instances of Det, shown in columns D1, . . . , D7. The
major premise Pixiyi is displayed there on top of the minor premise Pxi, and
the (negated) conclusion ¬Pyi, where xi, yi are variables. Instances of the ax-
iom appear as literals ¬Pai, with ai a shorthand for the term i(i(ipiqi, ri), iqiri).
The rightmost literal Pg is a shorthand for the Skolemized theorem. The clause
instances are linked through edges representing connection instances. The edge

Investigations into Proof Structures
61
(a)
D1
Pix1y1
Px1
¬Py1
Pg
D2
¬Pa1
Pix2y2
¬Pa2
Px2
¬Py2
D3
Pix3y3
Px3
¬Py3
D4
¬Pa3
Pix4y4
Px4
¬Py4
D5
¬Pa4
Pix5y5
¬Pa5
Px5
¬Py5
D6
¬Pa6
Pix6y6
Px6
¬Py6
D7
¬Pa7
Pix7y7
¬Pa8
Px7
¬Py7
1
2
3
4
5
2
3
4
3
4
5
4
3
4
5
(b)
D1
D2
D3
A1
A2
D4
D6
A3
D5
A6
D7
A4 A5
A7 A8
2
3
4
5
2
3
4
3
4
3
4
5
4
5
(c)
1. CCCpqrCqr
2. CpCqp = D11
3. CpCqCrp = D12
* 4. CpCqCrCsCtCus = D2D33
(d)
4
2
1
1
3
3
1
2
1
2
1
1
1
1
2
3
4
5
2
3
4
3
4
3
4
5
4
5
(e)
4
2
1
3
2
3
4
5
2
3
4
3
Fig. 2. A proof in diﬀerent representations.
labels identify the respective connections as in Fig. 1. An actual connection proof
is obtained by supplementing this structure with a substitution under which all
pairs of literals related through a connection instance become complementary.
Figure 2b represents the tree implicit in the CM proof. Its inner nodes corre-
spond to the instances of Det, and its leaf nodes to the instances of the axiom.
Edges appear ordered to the eﬀect that those originating in a major premise of
Det are directed to the left and those from a minor premise to the right. The
goal clause Pg is dropped. The resulting tree is a full binary tree, i.e., a binary
tree where each node has 0 or 2 children. We observe that the ordering of the
children makes the connection labeling redundant as it directly corresponds to
the tree structure.
Figure 2c presents the proof in Meredith’s notation. Each line shows a for-
mula, line 1 the axiom and lines 2–4 derived formulas, with proofs annotated in
the last column. Proofs are written as terms in Polish notation with the binary
function symbol D for detachment where the subproofs of the major and minor
premise are supplied as ﬁrst and second, resp., argument. Formula 4, for exam-
ple, is obtained as conclusion of Det applied to formula 2 as major premise and
as minor premise another formula that is not made explicit in the presentation,
namely the conclusion of Det applied to formula 3 as both, major and minor,
premises. An asterisk marks the goal theorem.

62
C. Wernhard and W. Bibel
1. CCCpqrCCrpCsp
2. CCCpqpCrp = DDD1D111n
3. CCCpqrCqr = DDD1D1D121n
4. CpCCpqCrq = D31
5. CCCpqCrsCCCqtsCrs = DDD1D1D1D141n
6. CCCpqCrsCCpsCrs = D51
7. CCpCqrCCCpsrCqr = D64
8. CCCCCpqrtCspCCrpCsp = D71
9. CCpqCpq = D83
10. CCCCrpCtpCCCpqrsCuCCCpqrs = D18
11. CCCCpqrCsqCCCqtsCpq = DD10.10.n
12. CCCCpqrCsqCCCqtpCsq = D5.11
13. CCCCpqrsCCsqCpq = D12.6
14. CCCpqrCCrpp = D12.9
15. CpCCpqq = D3.14
16. CCpqCCCprqq = D6.15
*17. CCpqCCqrCpr = DD13.D16.16.13
*18. CCCpqpp = D14.9
*19. CpCqp = D33
Fig. 3. Proof MER, Meredith’s reﬁnement [24] of
Łukasiewicz’s proof [19].
Figure 2d is like Fig. 2b, but
with a diﬀerent labeling: Node
labels now refer to the line in
Fig. 2c that corresponds to the
subproof rooted at the node.
The blank node represents the
mentioned subproof of the for-
mula that is not made explicit in
Fig. 2b. An inner node represents
a condensed detachment step ap-
plied to the subproof of the ma-
jor premise (left child) and minor
premise (right child).
Figure 2e shows a DAG (di-
rected acyclic graph) representa-
tion of Figure 2d. It is the unique
maximally factored DAG repre-
sentation of the tree, i.e., it has
no multiple occurrences of the
same subtree. Each of the four
proof line labels of Fig. 2c appears exactly once in the DAG.
We conclude this introductory section with reproducing Meredith’s reﬁne-
ment of Łukasiewicz’s completeness proof in Fig. 3, taken from [24]. Since we
will often refer to this proof, we call it MER. There is a single axiom (1), which is
Łukasiewicz. The proven theorems are Syll (17), Peirce (18) and Simp (19). In
addition to line numbers also the symbol n appears in some of the proof terms.
Its meaning will be explained later on in the context of Def. 19. For now, we can
read n just as “1”. Dots are used in the Polish notation to disambiguate numeric
identiﬁers with more than a single digit.
3
Condensed Detachment and a Formal Basis
Following [4], the idea of condensed detachment can be described as follows:
Given premises F →G and H, we can conclude G′, where G′ is the most general
result that can be obtained by using a substitution instance H′ as minor premise
with the substitution instance F ′ →G′ as major premise in modus ponens.
Condensed detachment was introduced by Meredith in the mid-1950s as an evo-
lution of the earlier method of substitution and detachment, where the involved
substitutions were explicitly given. The original presentations of condensed de-
tachment are informal by means of examples [28,17,29,25], formal speciﬁcations
have been given later [16,13,4]. In ATP, the rendering of condensed detachment
by hyperresolution with the clausal form of axiom Det is so far the prevalent
view. As overviewed in [23,31], many of the early successes of ATP were based
on condensed detachment. Starting from the hyperresolution view, structural as-
pects of condensed detachment have been considered by Robert Veroﬀ[34] with

Investigations into Proof Structures
63
the use of term representations of proofs and linked resolution. Results of ATP
systems on deriving the Tarski-Bernays axioms from Łukasiewicz are reported
in [27,39,22,23,11]. Our goal in this section is to provide a formal framework
that makes the achievements of condensed detachment accessible from a mod-
ern ATP view. In particular, the incorporation of uniﬁcation, the interplay of
nested structures with explicitly and implicitly associated formulas, sharing of
structures through lemmas, and the availability of proof structures as terms.
Our notation follows common practice [6] (e.g., s ≥· t expresses that t sub-
sumes s, and s  t that t is a subterm of s) with some additions [37]. For
formulas F we write the universal closure as ∀F, and for terms s, t, u we use
s[t →u] to denote s after simultaneously replacing all occurrences of t with u.
3.1
Proof Structures: D-Terms, Tree Size and Compacted Size
In this section we consider only the purely structural aspects of condensed de-
tachment proofs. Emphasis is on a twofold view on the proof structure, as a tree
and as a DAG (directed acyclic graph), which factorizes multiple occurrences
of the same subtree. Both representation forms are useful: the compacted DAG
form captures that lemmas can be repeatedly used in a proof, whereas the tree
form facilitates to specify properties in an inductive manner. We call the tree
representation of proofs by terms with the binary function symbol D D-terms.
Deﬁnition 1. (i) We assume a distinguished set of symbols called primitive
D-terms. (ii) A D-term is inductively speciﬁed as follows: (1.) Any primitive
D-term is a D-term. (2.) If d1 and d2 are D-terms, then D(d1, d2) is a D-term.
(iii) The set of primitive D-terms occurring in a D-term d is denoted by Prim(d).
(iv) The set of all D-terms that are not primitive is denoted by D.
A D-term is a full binary tree (i.e, a binary tree in which every node has either 0
or 2 children), where the leaves are labeled with symbols, i.e., primitive D-terms.
An example D-term is
d
def
= D(D(1, 1), D(D(1, D(1, 1)), D(1, D(1, 1)))),
(i)
which represents the structure of the proof shown in Fig. 2 and can be visualized
by the full binary tree of Fig. 2d after removing all labels with exception of the
leaf labels. The proof annotations in Fig. 2c and Fig. 3 are D-terms written in
Polish notation. The expression D2D33 in line 4 of Fig. 2, for example, stands
for the D-term D(2, D(3, 3)). Prim(D(2, D(3, 3))) = {2, 3}.
A ﬁnite tree and, more generally, a ﬁnite set of ﬁnite trees can be represented
as DAG, where each node in the DAG corresponds to a subtree of a tree in the
given set. It is well known that there is a unique minimal such DAG, which
is maximally factored (it has no multiple occurrences of the same subtree) or,
equivalently, is minimal with respect to the number of nodes, and, moreover,
can be computed in linear time [7]. The number of nodes of the minimal DAG
is the number of distinct subtrees of the members of the set of trees. There are
two useful notions of measuring the size of a D-term, based directly on its tree
representation and based on its minimal DAG, respectively.

64
C. Wernhard and W. Bibel
Deﬁnition 2. (i) The tree size of a D-term d, in symbols t-size(d), is the number
of occurrences of the function symbol D in d. (ii) The compacted size of a D-term
d is deﬁned as c-size(d)
def
= |{e ∈D | d  e}|. (iii) The compacted size of a ﬁnite
set D of D-terms is deﬁned as c-size(D)
def
= |{e ∈D | d ∈D and d  e}|.
The tree size of a D-term can equivalently be characterized as the number of
its inner nodes. The compacted size of a D-term is the number of its distinct
compound subterms. It can equivalently be characterized as the number of the
inner nodes of its minimal DAG. As an example consider the D-term d deﬁned
in formula (i), whose minimal DAG is shown in Fig. 2e. The tree size of d is
t-size(d) = 7 and the compacted size of d is c-size(d) = 4, corresponding to
the cardinality of the set {e ∈D | d  e} of compound subterms of d, i.e.,
{D(1, 1), D(1, D(1, 1)), D(D(1, D(1, 1)), D(1, D(1, 1))), d}.
As will be explicated in more detail below, each occurrence of the function
symbol D in a D-term corresponds to an instance of the meta-level axiom Det
in the represented proof. Hence the tree size measures the number of instances
of Det in the proof. Another view is that each occurrence of D in a D-term
corresponds to a condensed detachment step, without re-using already proven
lemmas. The compacted size of a D-term is the number of its distinct compound
subterms, corresponding to the view that the size of the proof of a lemma is
only counted once, even if it is used multiply. Tree size and compacted size of
D-terms appear in [34] as CDcount and length, respectively.
3.2
Proof Structures, Formula Substitutions and Semantics
We use a notion of uniﬁer that applies to a set of pairs of terms, as convenient
in discussions based on the CM [1,9,8].
Deﬁnition 3. Let M be a set of pairs of terms and let σ be a substitution. (i) σ
is said to be a uniﬁer of M if for all {s, t} ∈M it holds that sσ = tσ. (ii) σ is
called a most general uniﬁer of M if σ is a uniﬁer of M and for all uniﬁers σ′
of M it holds that σ′ ≥· σ. (iii) σ is called a clean most general uniﬁer of M
if it is a most general uniﬁer of M and, in addition, is idempotent and satisﬁes
Dom(σ) ∪VRng(σ) ⊆Var(M).
The additional properties required for clean most general uniﬁers do not hold for
all most general uniﬁers.3 However, the uniﬁcation algorithms known from the
literature produce clean most general uniﬁers [9, Remark 4.2]. If a set of pairs
of terms has a uniﬁer, then it has a most general uniﬁer and, moreover, also a
clean most general uniﬁer.
Deﬁnition 4. (i) If M is a set of pairs of terms that has a uniﬁer, then mgu(M)
denotes some clean most general uniﬁer of M. M is called uniﬁable and mgu(M)
is called deﬁned in this case, otherwise it is called undeﬁned. (ii) We make the
convention that proposition, lemma and theorem statements implicitly assert
their claims only for the case where occurrences of mgu in them are deﬁned.
3 The inaccuracy observed by [13] in early formalizations of condensed detachment
can be attributed to disregarding the requirement Dom(σ) ∪VRng(σ) ⊆Var(M).

Investigations into Proof Structures
65
Since we deﬁne mgu(M) as a clean most general uniﬁer, we are permitted to make
use of the assumption that it is idempotent and that all variables occurring in
its domain and range occur in M. Convention 4.ii has the purpose to reduce
clutter in proposition, lemma and theorem statements.
The structural aspects of condensed detachment proofs represented by
D-terms, i.e., full binary trees, will now be supplemented with associated for-
mulas. Condensed detachment proofs, similar to CM proofs, involve diﬀerent
instances of the input formulas (viewed as quantiﬁer-free, e.g., clauses), which
may be considered as obtained in two steps: ﬁrst, “copies”, that is, variants with
fresh variables, of the input formulas are created; second a substitution is applied
to these copies. Let us consider now the ﬁrst step. The framework of D-terms
permits to give the variables in the copies canonical designators with an index
subscript that identiﬁes the position in the structure, i.e., in the D-term, or tree.
Deﬁnition 5. For all positions p and positive integers i let xi
p and yp denote
pairwise diﬀerent variables.
Recall that positions are path speciﬁers. For a given D-term d and leaf position p
of d the variables xi
p are for use in a formula associated with p which is the copy of
an axiom. Diﬀerent variables in the copy are distinguished by the upper index i.
If p is a non-leaf position of d, then yp denotes the variable in the conclusion of
the copy of Det that is represented by p. In addition, yp for leaf positions p may
occur in the antecedents of the copies of Det. The following substitution shiftp
is a tool to systematically rename position-associated variables while preserving
the internal relationships between the index-referenced positions.
Deﬁnition 6. For all positions p deﬁne the substitution shiftp as follows: shiftp
def
= {yq →yp.q | q is a position} ∪{xi
q →xi
p.q | i ≥1 and q is a position}.
The application of shiftp to a term s eﬀects that p is prepended to the position
indexes of all the position-associated variables occurring in s. The association of
axioms with primitive D-terms is represented by mappings which we call axiom
assignments, deﬁned as follows.
Deﬁnition 7. An axiom assignment α is a mapping whose domain is a set
of primitive D-terms and whose range is a set of terms whose variables are in
{xi
ϵ | i ≥1}. We say that α is for a D-term d if Dom(α) ⊇Prim(d).
We deﬁne a shorthand for a form of Łukasiewicz that is suitable for use as a
range element of axiom assignments. It is parameterized with a position p.
Łukasiewicz p
def
= i(i(i(x1
p, x2
p), x3
p), i(i(x3
p, x1
p), i(x4
p, x1
p))).
(ii)
The mapping {1 →Łukasiewicz ϵ} is an axiom assignment for all D-terms d with
Prim(d) = {1}. The second step of obtaining the instances involved in a proof
can be performed by applying the most general uniﬁer of a pair of terms that
constrain it. The tree structure of D-terms permits to associate exactly one such
pair with each term position. Inner positions represent detachment steps and
leaf positions instances of an axiom according to a given axiom assignment. The
following deﬁnition speciﬁes these constraining pairs.

66
C. Wernhard and W. Bibel
Deﬁnition 8. Let d be a D-term and let α be an axiom assignment for d. For all
positions p ∈Pos(d) deﬁne the pair of terms pairingα(d, p)
def
= {yp, α(d|p)shiftp}
if p ∈Leaf Pos(d) and {yp.1, i(yp.2, yp)} if p ∈InnerPos(d).
A uniﬁer of the set of pairings of all positions of a D-term d equates for a leaf
position p the variable yp with the value of the axiom assignment α for the
primitive D-term at p, after “shifting” variables by p. This “shifting” means that
the position subscript ϵ of the variables in the axiom argument term α(d|p) is
replaced by p, yielding a dedicated copy of the axiom argument term for the leaf
position p. For inner positions p the uniﬁer equates yp.1 and i(yp.2, yp), reﬂecting
that the major premise of Det is proven by the left child of p.
The substitution induced by the pairings associated with the positions of a
D-term allow to associate a speciﬁc formula with each position of the D-term,
called the in-place theorem (IPT). The case where the position is the top posi-
tion ϵ is distinguished as most general theorem (MGT).
Deﬁnition 9. For D-terms d, positions p ∈Pos(d) and axiom assignments
α for d deﬁne the in-place theorem (IPT) of d at p for α, Iptα(d, p), and
the most general theorem (MGT) of d for α, Mgtα(d), as (i) Iptα(d, p)
def
=
P(ypmgu({pairingα(d, q) | q ∈Pos(d)})). (ii) Mgtα(d)
def
= Iptα(d, ϵ).
Since Ipt and Mgt are deﬁned on the basis of mgu, they are undeﬁned if the set
of pairs of terms underlying the respective application of mgu is not uniﬁable.
Hence, we apply the convention of Def. 4.ii for mgu also to occurrences of Ipt
and Mgt. If Ipt and Mgt are deﬁned, they both denote an atom whose variables
are constrained by the clean property of the underlying application of mgu. The
following proposition relates IPT and MGT with respect to subsumption.
Proposition 10. For all D-terms d, positions p ∈Pos(d) and axiom assign-
ments α for d it holds that Iptα(d, p) ≥· Mgtα(d|p).
By Prop. 10, the IPT at some position p of a D-term d is subsumed by the MGT
of the subterm d|p of d rooted at position p. An intuitive argument is that the
only constraints that determine the most general uniﬁer underlying the MGT
are induced by positions of d|p, that is, below p (including p itself). In contrast,
the most general uniﬁer underlying the IPT is determined by all positions of d.
The following lemma expresses the core relationships between a proof struc-
ture (a D-term), a proof substitution (accessed via the IPT) and semantic en-
tailment of associated formulas.
Lemma 11. Let d be a D-term and let α be an axiom assignment for d. Then for
all p ∈Pos(d) it holds that: (i) If p ∈Leaf Pos(d), then ∀P(α(d|p)) |= Iptα(d, p).
(ii) If p ∈InnerPos(d), then Det ∧Iptα(d, p.1) ∧Iptα(d, p.2) |= Iptα(d, p).
Based on this lemma, the following theorem shows how Detachment together
with the axioms in an axiom assignment entail the MGT of a given D-term.
Theorem 12. Let d be a D-term and let α be an axiom assignment for d. Then
Det ∧
p∈Leaf Pos(d) ∀P(α(d|p)) |= ∀Mgtα(d).

Investigations into Proof Structures
67
Theorem 12 states that Det together with the axioms referenced in the proof,
that is, the values of α for the leaf nodes of d considered as universally closed
atoms, entail the universal closure of the MGT of d for α. The universal closure
of the MGT is the formula exhibited in Meredith’s proof notation in the lines
with a trailing D-term, such as lines 2–19 in Fig. 3.
4
Reducing the Proof Size by Replacing Subproofs
The term view on proof trees suggests to shorten proofs by rewriting subterms,
that is, replacing occurrences of subproofs by other ones, with three main aims:
(1) To shorten given proofs, with respect to the tree size or the compacted
size. (2) To investigate given proofs whether they can be shortened by certain
rewritings or are closed under these. (3) To develop notions of redundancy for
use in proof search. A proof fragment constructed during search may be rejected
if it can be rewritten to a shorter one.
It is obvious that if a D-term d′ is obtained from a D-term d by replacing an
occurrence of a subterm e with a D-term e′ such that t-size(e) ≥t-size(e′), then
also t-size(d) ≥t-size(d′). Based on the following ordering relations on D-terms,
which we call compaction orderings, an analogy for reducing the compacted size
instead of the tree size can be stated.
Deﬁnition 13. For D-terms d, e deﬁne (i) d ≥c e
def
= {f ∈D | d  f} ⊇{f ∈
D | e  f}. (ii) d >c e
def
= d ≥c e and e ̸≥c d.
The relations d ≥c e and d >c e compare D-terms d and e with respect to the su-
perset relationship of their sets of those strict subterms that are compound terms.
For example, D(D(D(1, 1), 1), 1) >c D(1, D(1, 1)) because {D(1, 1), D(D(1, 1), 1)}
⊇{D(1, 1)}.
Theorem 14. Let d, d′, e, e′ be D-terms such that e occurs in d, and d′ = d[e →
e′]. It holds that (i) If e ∈D and e ≥c e′, then c-size(d) ≥c-size(d′). (ii) If e >c e′,
then sc-size(d) > sc-size(d′), where, for all D-terms d sc-size(d)
def
= 
de c-size(e).
Theorem 14.i states that if d′ is the D-term obtained from d by simultaneously
replacing all occurrences of a compound D-term e with a “c-smaller” D-term e′,
i.e., e ≥c e′, then the compacted size of d′ is less or equal to that of d. As stated
with the supplementary Theorem 14.ii, the sc-size is a measure that strictly
decreases under the strict precondition e >c e′, which is useful to ensure ter-
mination of rewriting. The following proposition characterizes the number of
D-terms that are smaller than a given D-term w.r.t the compaction ordering ≥c.
Proposition 15. For all D-terms d it holds that |{e | d ≥c e and Prim(e) ⊆
Prim(d)}| = (c-size(d) −1 + |Prim(d)|)2 + |Prim(d)|.
By Prop. 15, for a given D-term d, the number of D-terms e that are smaller
than d with respect to ≥c is only quadratically larger than the compacted size
of d and thus also than the tree size of d. Hence techniques that inspect all these
smaller D-terms for a given D-term can eﬃciently be used in practice.

68
C. Wernhard and W. Bibel
According to Theorem 12, a condensed detachment proof, i.e., a D-term d
and an axiom assignment α, proves the MGT of d for α along with instances of
the MGT. In general, replacing subterms of d should yield a proof of at least
these theorems. That is, a proof whose MGT subsumes the original one. The
following theorem expresses conditions which ensure that subterm replacements
yield a proof with a MGT that subsumes original one.
Theorem 16. Let d, e be D-terms, let α be an axiom assignment for d and
for e, and let p1, . . . , pn, where n ≥0, be positions in Pos(d) such that for all
i, j ∈{1, . . . , n} with i ̸= j it holds that pi ̸≤pj. If for all i ∈{1, . . . , n} it holds
that Iptα(d, pi) ≥· Mgtα(e), then Mgtα(d) ≥· Mgtα(d[e]p1[e]p2 . . . [e]pn).
Theorem 16 states that simultaneously replacing a number of occurrences of
possibly diﬀerent subterms in a D-term by the same subterm with the property
that its MGT subsumes each of the IPTs of the original occurrences results in an
overall D-term whose MGT subsumes that of the original overall D-term. The
following theorem is similar, but restricted to a single replaced occurrence and
with a stronger precondition. It follows from Theorem 16 and Prop. 10.
Theorem 17. Let d, e be D-terms and let α be an axiom assignment for d and
for e. For all positions p ∈Pos(d) it then holds that if Mgtα(d|p) ≥· Mgtα(e),
then Mgtα(d) ≥· Mgtα(d[e]p).
Simultaneous replacements of subterm occurrences are essential for reducing the
compacted size of proofs according to Theorem 14. For replacements according
to Theorem 17 they can be achieved by successive replacements of individual
occurrences. In Theorem 16 simultaneous replacements are explicitly considered
because the replacement of one occurrence according to this theorem can in-
validate the preconditions for another occurrence. Theorem 17 can be useful in
practice because the precondition Mgtα(d|p) ≥·
Mgtα(e) can be evaluated on
the basis of α, e and just the subterm d|p of d, whereas determining Iptα(d, p)
for Theorem 16 requires also consideration of the context of p in d. Based on
Theorems 16 and 14 we deﬁne the following notions of reduction and regularity.
Deﬁnition 18. Let d be a D-term, let e be a subterm of d and let α be an
axiom assignment for d. For D-terms e′ the D-term d[e →e′] is then obtained
by C-reduction from d for α if e >c e′, Mgtα(e′) is deﬁned, and for all positions
p ∈Pos(d) such that d|p = e it holds that Iptα(d, p) ≥· Mgtα(e′). The D-term d is
called C-reducible for α if and only if there exists a D-term e′ such that d[e →e′]
is obtained by C-reduction from d for α. Otherwise, d is called C-regular.
If d′ is obtained from d by C-reduction, then by Theorem 16 and 14 it follows
that Mgtα(d) ≥· Mgtα(d′), c-size(d) ≥c-size(d′) and sc-size(d) > sc-size(d′). C-
regularity diﬀers from well known concepts of regularity in clausal tableaux (see,
e.g., [14]) in two respects: (1) In the comparison of two nodes on a branch (which
is done by subsumption as in tableaux with universal variables) for the upper
node the stronger instantiated IPT is taken and for the lower node the more
weakly instantiated MGT. (2) C-regularity is not based on relating two nested

Investigations into Proof Structures
69
subproofs, but on comparison of all occurrences of a subproof with respect to all
proofs that are smaller with respect to the compaction ordering.
Proofs may involve applications of Det where the conclusion Py is actually
independent from the minor premise Px. Any axiom can then serve as a trivial
minor premise. Meredith expresses this with the symbol n as second argument
of the respective D-term. Our function simp-n simpliﬁes D-terms by replacing
subterms with n accordingly on the basis of the preservation of the MGT.
Deﬁnition 19. If d is a D-term and α is an axiom assignment for d, then
the n-simpliﬁcation of d with respect to α is the D-term simp-nα(d), where
simp-n is the following function: simp-nα(d)
def
= d, if d is a primitive D-term;
simp-nα(D(d1, d2))
def
= D(simp-nα′(d1), n) if
Mgtα′D(d1, n) = MgtαD(d1, d2),
where α′
=
α ∪{n →k} for a fresh constant k; simp-nα(D(d1, d2))
def
=
D(simp-nα(d1), simp-nα(d2)), else.
5
Properties of Meredith’s Reﬁned Proof
Our framework renders condensed detachment as a restricted form of the CM.
This view permits to consider the expanded proof structures as binary trees or
D-terms. On this basis we obtain a natural characterization of proof properties
in various categories, which seem to be the key towards reducing the search space
in ATP. Table 1 shows such properties for each of the 34 structurally diﬀerent
subproofs of proof MER (Fig. 3). Column M gives the number of the subproof
in Fig. 3. We use the following short identiﬁers for the observed properties:
Structural Properties of the D-Term. These properties refer to the respec-
tive subproof as D-term or full binary tree. DT, DC, DH: Tree size, compacted
size, height. DKL, DKR: “Successive height”, that is, the maximal number of
successive edges going to the left (right, resp.) on any path from the root to a
leaf. DP: Is “prime”, that is, DT and DC are equal. DS: Relationship between
the subproofs of major and minor premise. Identity is expressed with =, the
subterm and superterm relationships with  and , resp., and the compaction
ordering relationship (if none of the other relationships holds) with <c and >c.
In addition it is indicated if a subproof is an axiom or n. DD: “Direct sharings”,
that is, the number of incoming edges in the DAG representation of the overall
proof of all theorems. DR: “Repeats”, that is, the total number of occurrences
in the set of expanded trees of all roots of the DAG.
Properties of the MGT. These properties refer to the argument term of the
MGT of the respective subproof. TT, TH: Tree size (deﬁned as for D-terms) and
height. TV: Number of diﬀerent variables occurring in the term. TO: Is “organic”
[21], that is, the argument term has no strict subterm s such that P(s) itself is
a theorem. We call an atom weakly organic (indicated by a gray bullet) if it is
not organic and the argument term is of the form i(p, t) where p is a variable
that does not occur in the term t and P(t) is organic. For axiomatizations of
fragments of propositional logic, organic can be checked by a SAT solver.
Regularity. RC: The respective subproof as D-term is C-regular (see Def. 18).

70
C. Wernhard and W. Bibel
M DT DC DH DKL DKR DP DS DD DR TT TC TH TV TO RC
MT
MC
ITU ITM IHU IHM
1. 1
1
0
0
0
0
0 •
–
17 554
6
6
3
4 •
•
0
0 4451 203
18
11
2. D11
1
1
1
1
1 • 1=1
1 45
8
7
4
5 •
•
1
1 1640 220
17
12
3. D12
2
2
2
1
2 •
1
1 45 11
8
4
6 •
•
2
2 1881 252
17
12
4. D31
3
3
3
2
2 •
1
1 45
5
5
4
4 •
•
3
3 689
92
16
11
5. D4n
2
4
4
4
3
2 •
n
1 45
4
4
3
3 •
•
4
4 688
91
15
10
6. D15
5
5
5
3
2 •
1
1 45
6
5
3
4 •
•
5
5 1667 198
15
10
7. D16
6
6
6
3
3 •
1
1 45
7
6
4
5 •
•
6
6 1802 208
16
11
8. D17
7
7
7
3
4 •
1
1 45
9
7
4
6 •
•
7
7 2648 303
16
11
9. D81
8
8
8
3
4 •
1
1 45
5
5
4
4 •
•
8
8 1032 119
15
10
10. D9n
3
9
9
9
3
4 •
n
5 45
4
4
3
3 •
•
9
9 1031 118
14
9
11. D10.1
4 10 10 10
4
4 •
1
2 37
4
4
3
3 •
•
10
10 448
60
13
9
12. D1.11
11 11 11
4
4 •
1
1 23
7
7
5
5 •
•
11
11 498
73
14
10
13. D1.12
12 12 12
4
4 •
1
1 23 12
8
5
6 •
•
12
12 1157 168
14
10
14. D1.13
13 13 13
4
4 •
1
1 23 10
9
6
7 •
•
13 [[12,13]] 1050 159
15
11
15. D1.14
14 14 14
4
5 •
1
1 23 15 10
6
8 •
•
14 [[12,14]] 1657 246
15
11
16. D15.1
15 15 15
4
5 •
1
1 23
9
8
5
6 •
•
15 [[12,15]] 684 100
14
10
17. D16.n
5 16 16 16
4
5 •
n
2 23
8
7
4
5 •
•
16 [[12,16]] 683
99
13
9
18. D17.1
6 17 17 17
4
5 •
1
3 18
7
6
3
4 •
•
17 [[12,17]] 395
56
12
8
19. D18.11 7 28 18 18
5
5 –

1 14
7
6
4
4 •
•
14 [[12,14]] 209
61
11
9
20. D19.1
8 29 19 19
6
5 –
1
2 14
9
8
5
5 •
•
15 [[12,15]] 132
38
10
8
21. D1.20 10 30 20 20
6
5 –
1
2 10 12
9
5
6 •
•
16 [[12,16]] 158
47
10
8
22. D21.21
61 21 21
6
5 –
=
1
5 10
9
5
6 •
•
[[23,33]] [[12,17]]
53
16
9
7
23. D22.n 11 62 22 22
6
5 –
n
1
5
9
8
4
5 •
•
[[23,34]] [[12,18]]
52
15
8
6
24. D17.23 12 79 23 23
6
5 –

2
5
9
8
4
5 •
•
[[23,51]] [[12,23]]
57
16
7
5
25. D24.18 13 97 24 24
6
5 –

2
2
7
6
4
4 •
•
[[23,69]] [[12,24]]
27
17
6
5
26. D20.10 9 39 20 20
7
5 –

2
4
3
2
2
2 •
–
8
6
27
7
6
4
27. D24.26 14 119 25 24
7
5 –
>c
2
3
5
5
3
3 •
•
[[23,91]] [[12,25]]
24
7
6
4
28. D10.27 15 129 26 25
7
5 –

1
2
3
3
3
2 •
• [[23,101]] [[12,26]]
19
12
6
5
29. D18.28 16 147 27 26
7
5 –

2
2
5
5
4
3 •
•
[[23,36]] [[12,26]]
19
12
6
5
30. D29.29
295 28 27
7
6 –
=
1
1 10
7
5
4 •
• [[23,239]] [[12,27]]
13
13
5
5
31. D25.30
393 30 28
7
7 –
<c
1
1
7
7
5
4 •
• [[23,121]] [[12,29]]
13
13
5
5
32. D31.25 17 491 31 29
7
7 –

0
1
5
5
3
3 •
• [[23,191]] [[12,30]]
5
5
3
3
33. D27.26 18 159 26 25
7
5 –

0
1
3
3
3
2 •
•
15
11
3
3
3
3
34. D10.10 19 19 10 10
4
4 –
=
0
1
2
2
2
2 •
•
7
6
2
2
2
2
Table 1. Properties of all subproofs of the proof MER [24] shown in Fig. 3.
Comparisons with all Proofs of the MGT. These properties relate to the
set of all proofs (as D-terms) of the MGT of the respective subproof. MT,
MC: Minimal tree size and minimal compacted size of a proof. These values
can be hard to determine such that in Table 1 they are often only narrowed
down by an integer interval. To determine them, we used the proof MER, proofs
obtained with techniques described in Sect. 6, and enumerations of all D-terms
with deﬁned MGT up to a given tree size or compacted size.
Properties of Occurrences of the IPTs. The respective subproof has DR
occurrences in the set of expanded trees of the roots of the DAG, where each
occurrence has an IPT. The following properties refer to the multiset of argu-
ment terms of the IPTs of these occurrences. ITU, ITM: Maximal tree size and
rounded median of the tree size. IHU, IHM: Maximal height and rounded me-
dian of the height. In Table 1 these values are much larger than those of the
corresponding columns for the MGT, i.e, TT and TH, illustrating Prop. 10.
6
First Experiments
First experiments based on the framework developed in the previous sections
are centered around the generation of lemmas where not just formulas but, in
the form of D-terms, also proofs are taken into account. This leads in general
to preference of small proofs and to narrowing down the search space by re-

Investigations into Proof Structures
71
Lemmas
# Time
Prover
Time
DC
DT DH
1.
Łukasiewicz∗
32
435
29
2.
Meredith
31
491
29
3.
Prover9
37 s
94
304,890
40
4.
Prover9 ∗
37 s
83
8,217
38
5.
Prover9 ∗depth ≤7
6 s
102
19,113
48
6.
PrimeCore(17)
17
Prover9 ∗
30 s
44
763
28
7.
ProofSubproof (93,7)
291
78 s
Prover9 ∗
3 s
51
1,405
31
8.
ProofSubproof (93,7)
291
78 s
CMProver
2 s
30
394
29
9.
ProofSubproof (100,8) 330
94 s
CMProver
4 s
30
535
29
10.
Reduction of (8.)
48
191
24
Table 2. Proof dimensions of various proofs of problem ŁDS.
stricted structuring principles to build proofs. The experiments indicate novel
potential calculi which combine aspects from lemma-based generative, bottom-
up, methods such as hyperresolution and hypertableaux with structure-based
approaches that are typically used in an analytic, goal-directed, way such as the
CM. In addition, ways to generate lemmas as preprocessing for theorem proving
are suggested, in particular to obtain short proofs. This resulted in a reﬁnement
of Łukasiewicz’s proof [19], whose compacted size is by one smaller than that of
Meredith’s reﬁnement [24] and by two than Łukasiewicz’s original proof.
Table 2 shows compacted size DC, tree size DT and height DH of various
proofs of ŁDS. Asterisks indicate that n-simpliﬁcation was applied with reducing
eﬀect on the system’s proof. Proof (1.) is the one by Łukasiewicz [19], translated
into condensed detachment, proof (2.) is proof MER (Fig. 3) [24]. Rows (3.)–(5.)
show results from Prover9, where in (5.) the value of max_depth was limited
to 7, motivated by column TH of Table 1. Proof (4.) illustrates the eﬀect of n-
simpliﬁcation.4 For proofs (6.)–(9.) additional axioms were supplied to Prover9
and CMProver [5,35,36], a goal-directed system that can be described by the
CM. Columns indicate the lemma computation method, the number of lem-
mas supplied to the prover and the time used for lemma computation. Method
PrimeCore adds the MGTs of subproof 18 from Table 1 and all its subproofs
as lemmas. Subproof 18 is the largest subproof of proof MER that is prime and
can be characterized on the basis of the axiom – almost uniquely – as a proof
that is prime, whose MGT has no smaller prime proof and has the same number
of diﬀerent variables as the axiom, i.e., 4, and whose size, given as parameter,
is 17. Method ProofSubproof is based on detachment steps with a D-term and a
subterm of it as proofs of the premises, which, as column DS of Table 1 shows,
suﬃces to justify all except of two proof steps in MER. It proceeds in some anal-
ogy to the given clause algorithm on lists of D-terms: If d is the given D-term,
then the inferred D-terms are all D-terms that have a deﬁned MGT and are of
the form D(d, e) or D(e, d), where e is a subterm of d. To determine which of the
inferred D-terms are kept, values from Table 1 were taken as guide, including
RC and TO. The ﬁrst parameter of ProofSubproof is the number of iterations
of the “given D-term loop”. Proof (9.) can be combined with Peirce and Syll to
the overall proof with compacted size 32, one less than MER. The maximal value
of DKL is shown as second parameter, because, when limited to 7, proof (9.)
4 All machine results refer to a system with Intel i7-8550U CPU and 16 GB RAM.
Results for further systems: KRHyper∗[26]: 1.610 s, DC: 73; E 2.5 [30]: 30 s, proof
length 91; Vampire 5.4.1 [33] –mode casc -t 300: 128 s, proof length 144.

72
C. Wernhard and W. Bibel
cannot be found. Proof (10.), which has a small tree size, was obtained from (8.)
by rewriting subproofs with a variation of C-reduction that rewrites single term
occurrences, considering also D-terms from a precomputed table of small proofs.
7
Conclusion
Starting out from investigating Łukasiewicz’s classic formal proof [19], via its
reﬁnement by Meredith [24] we arrived at a formal reconstruction of Meredith’s
condensed detachment as a special case of the CM. The resulting formalism yields
proofs as objects of a very simple and common structure: full binary trees which,
in the tradition of term rewriting, appear as terms, D-terms, as we call them. To
form a full proof, formulas are associated with the nodes of D-terms: axioms with
the leaves and lemmas with the remaining nodes, implicitly determined from the
axioms through the node position and uniﬁcation. The root lemma is the most
general proven theorem. Lemmas also relate to compressed representations of
the binary trees, for example as DAGs, where the re-use of a lemma directly
corresponds to sharing the structure of its subproof. For future work we intend
to position our approach also in the context of earlier works on proofs, proof
compression and lemma introduction, e.g., [38,12], and think of compressing
D-Terms in forms that are stronger than DAGs, e.g., by tree grammars [18].
The combination of formulas and explicitly available proof structures natu-
rally leads to theorem proving methods that take structural aspects into account,
in various ways, as demonstrated by our ﬁrst experiments. This goes beyond the
common clausal tableau realizations of the CM, which in essence operate by enu-
merating uncompressed proof structures. The discussed notions of regularity and
lemma generation methods seem immediately suited for further investigations
in the context of ﬁrst-order theorem proving in general. For other aspects of
the work we plan a stepwise generalization by considering further single axioms
for the implicational fragment IF [21,19,32], single axioms and axiom pairs for
further logics [32], the about 200 condensed detachment problems in the LCL
domain of the TPTP, problems which involve multiple non-unit clauses, and
adapting D-terms to a variation of binary resolution instead of detachment. In
the longer run, our approach aims at providing a basis for approaches to theo-
rem proving with machine learning (e.g. [10,15]). With the reiﬁcation of proof
structures more information is available as starting point. As indicated with our
exemplary feature table for Meredith’s proof, structural properties are consid-
ered thereby from a global point of view, as a source for narrowing down the
search space in many diﬀerent ways in contrast to just the common local view
“from within a structure”, where the narrowing down is achieved for example by
focusing on a “current branch” during the construction of a tableau. A general
lead question opened up by our setting is that for exploring relationships between
properties of proof structures and the associated formulas in proofs of meaning-
ful theorems. One may expect that characterizations of these relationships can
substantially restrict the search space for ﬁnding proofs.
Acknowledgments. We appreciate the competent comments of all the referees.

Investigations into Proof Structures
73
References
1. Bibel, W.: Automated Theorem Proving. Vieweg, Braunschweig (1982). https://
doi.org/10.1007/978-3-322-90102-6, second edition 1987
2. Bibel, W.: Deduction: Automated Logic. Academic Press, London (1993)
3. Bibel, W., Otten, J.: From Schütte’s formal systems to modern automated deduc-
tion. In: Kahle, R., Rathjen, M. (eds.) The Legacy of Kurt Schütte, chap. 13, pp.
215–249. Springer (2020). https://doi.org/10.1007/978-3-030-49424-7_13
4. Bunder, M.W.: A simpliﬁed form of condensed detachment. J. Log., Lang. Inf.
4(2), 169–173 (1995). https://doi.org/10.1007/BF01048619
5. Dahn, I., Wernhard, C.: First order proof problems extracted from an article in
the Mizar mathematical library. In: Bonacina, M.P., Furbach, U. (eds.) FTP’97.
pp. 58–62. RISC-Linz Report Series No. 97–50, Joh. Kepler Univ., Linz (1997),
https://www.logic.at/ftp97/papers/dahn.pdf
6. Dershowitz, N., Jouannaud, J.: Notations for rewriting. Bull. EATCS 43, 162–174
(1991)
7. Downey, P.J., Sethi, R., Tarjan, R.E.: Variations on the common subexpression
problem. JACM 27(4), 758–771 (1980). https://doi.org/10.1145/322217.322228
8. Eder, E.: Relative Complexities of First Order Calculi. Vieweg, Braunschweig
(1992). https://doi.org/10.1007/978-3-322-84222-0
9. Eder, E.: Properties of substitutions and uniﬁcation. J. Symb. Comput. 1(1), 31–46
(1985). https://doi.org/10.1016/S0747-7171(85)80027-4
10. Färber, M., Kaliszyk, C., Urban, J.: Machine learning guidance for connection
tableaux. J. Autom. Reasoning 65(2), 287–320 (2021). https://doi.org/10.1007/s1
0817-020-09576-7
11. Fitelson, B., Wos, L.: Missing proofs found. J. Autom. Reasoning 27(2), 201–225
(2001). https://doi.org/10.1023/A:1010695827789
12. Hetzl, S., Leitsch, A., Reis, G., Weller, D.: Algorithmic introduction of quantiﬁed
cuts. Theor. Comput. Sci. 549, 1–16 (2014). https://doi.org/10.1016/j.tcs.2014.0
5.018
13. Hindley, J.R., Meredith, D.: Principal type-schemes and condensed detachment.
Journal of Symbolic Logic 55(1), 90–105 (1990). https://doi.org/10.2307/2274956
14. Hähnle, R.: Tableaux and related methods. In: Robinson, A., Voronkov, A. (eds.)
Handb. of Autom. Reasoning, vol. 1, chap. 3, pp. 101–178. Elsevier (2001). https:
//doi.org/10.1016/b978-044450813-3/50005-9
15. Jakubuv, J., Chvalovský, K., Olsák, M., Piotrowski, B., Suda, M., Urban, J.:
ENIGMA Anonymous: Symbol-independent inference guiding machine (system de-
scription). In: Peltier, N., Sofronie-Stokkermans, V. (eds.) IJCAR 2020. LNCS,
vol. 12167, pp. 448–463. Springer (2020). https://doi.org/10.1007/978-3-030-5105
4-1_29
16. Kalman, J.A.: Condensed detachment as a rule of inference. Studia Logica 42,
443–451 (1983). https://doi.org/10.1007/BF01371632
17. Lemmon, E.J., Meredith, C.A., Meredith, D., Prior, A.N., Thomas, I.: Calculi
of pure strict implication. In: Davis, J.W., Hockney, D.J., Wilson, W.K. (eds.)
Philosophical Logic, pp. 215–250. Springer Netherlands, Dordrecht (1969). https://
doi.org/10.1007/978-94-010-9614-0_17, reprint of a technical report, Canterbury
University College, Christchurch, 1957
18. Lohrey, M.: Grammar-based tree compression. In: Potapov, I. (ed.) DLT 2015.
LNCS, vol. 9168, pp. 46–57. Springer (2015). https://doi.org/10.1007/978-3-319-
21500-6_3

74
C. Wernhard and W. Bibel
19. Łukasiewicz, J.: The shortest axiom of the implicational calculus of propositions.
In: Proc. of the Royal Irish Academy. vol. 52, Sect. A, No. 3, pp. 25–33 (1948),
http://www.jstor.org/stable/20488489, republished in [20], p. 295–305
20. Łukasiewicz, J.: Selected Works. North Holland (1970), edited by L. Borkowski
21. Łukasiewicz, J., Tarski, A.: Untersuchungen über den Aussagenkalkül. Comptes
rendus des séances de la Soc. d. Sciences et d. Lettres de Varsovie 23 (1930),
English translation in [20], p. 131–152
22. Lusk, E.L., McCune, W.W.: Experiments with ROO, a parallel automated de-
duction system. In: Fronhöfer, B., Wrightson, G. (eds.) Parallelization in In-
ference Systems. LNCS (LNAI), vol. 590, pp. 139–162. Springer (1992). https:
//doi.org/10.1007/3-540-55425-4_6
23. McCune, W., Wos, L.: Experiments in automated deduction with condensed de-
tachment. In: Kapur, D. (ed.) CADE-11. LNCS (LNAI), vol. 607, pp. 209–223.
Springer (1992). https://doi.org/10.1007/3-540-55602-8_167
24. Meredith, C.A., Prior, A.N.: Notes on the axiomatics of the propositional calculus.
Notre Dame J. of Formal Logic 4(3), 171–187 (1963). https://doi.org/10.1305/nd
jfl/1093957574
25. Meredith, D.: In memoriam: Carew Arthur Meredith (1904–1976). Notre Dame J.
of Formal Logic 18(4), 513–516 (10 1977). https://doi.org/10.1305/ndjfl/109388
8116
26. Pelzer, B., Wernhard, C.: System description: E-KRHyper. In: Pfenning, F. (ed.)
CADE-21. LNCS (LNAI), vol. 4603, pp. 503–513. Springer (2007). https://doi.or
g/10.1007/978-3-540-73595-3_37
27. Pfenning, F.: Single axioms in the implicational propositional calculus. In: Lusk,
E., Overbeek, R. (eds.) CADE-9. LNCS (LNAI), vol. 310, pp. 710–713. Springer
(1988). https://doi.org/10.1007/BFb0012869
28. Prior, A.N.: Logicians at play; or Syll, Simp and Hilbert. Australasian Journal of
Philosophy 34(3), 182–192 (1956). https://doi.org/10.1080/00048405685200181
29. Prior, A.N.: Formal Logic. Clarendon Press, Oxford, 2nd edn. (1962). https://doi.
org/10.1093/acprof:oso/9780198241560.001.0001
30. Schulz, S., Cruanes, S., Vukmirović, P.: Faster, higher, stronger: E 2.3. In: Fontaine,
P. (ed.) CADE 27. pp. 495–507. No. 11716 in LNAI, Springer (2019). https://doi.
org/10.1007/978-3-030-29436-6_29
31. Ulrich, D.: A legacy recalled and a tradition continued. J. Autom. Reasoning 27(2),
97–122 (2001). https://doi.org/10.1023/A:1010683508225
32. Ulrich, D.: Single axioms and axiom-pairs for the implicational fragments of R,
R-Mingle, and some related systems. In: Bimbó, K. (ed.) J. Michael Dunn on
Information Based Logics, Outstanding Contributions to Logic, vol. 8, pp. 53–80.
Springer (2016). https://doi.org/10.1007/978-3-319-29300-4_4
33. Vampire Team: Vampire, online: https://vprover.github.io/, accessed Feb 5, 2021
34. Veroﬀ, R.: Finding shortest proofs: An application of linked inference rules. J.
Autom. Reasoning 27(2), 123–139 (2001). https://doi.org/10.1023/A:1010635625
063
35. Wernhard, C.: The PIE system for proving, interpolating and eliminating. In:
Fontaine, P., Schulz, S., Urban, J. (eds.) PAAR 2016. CEUR Workshop Proc.,
vol. 1635, pp. 125–138. CEUR-WS.org (2016), http://ceur-ws.org/Vol-1635/paper
-11.pdf
36. Wernhard, C.: Facets of the PIE environment for proving, interpolating and elimi-
nating on the basis of ﬁrst-order logic. In: Hofstedt, P., Abreu, S., John, U., Kuchen,
H., Seipel, D. (eds.) DECLARE 2019. LNCS (LNAI), vol. 12057, pp. 160–177
(2020). https://doi.org/10.1007/978-3-030-46714-2_11

Investigations into Proof Structures
75
37. Wernhard, C., Bibel, W.: Learning from Łukasiewicz and Meredith: Investigations
into proof structures (extended version). CoRR abs/2104.13645 (2021), https:
//arxiv.org/abs/2104.13645
38. Woltzenlogel Paleo, B.: Atomic cut introduction by resolution: Proof structuring
and compression. In: Clarke, E.M., Voronkov, A. (eds.) LPAR-16. LNCS, vol. 6355,
pp. 463–480. Springer (2010). https://doi.org/10.1007/978-3-642-17511-4_26
39. Wos, L., Winker, S., McCune, W., Overbeek, R., Lusk, E., Stevens, R., Butler,
R.: Automated reasoning contributes to mathematics and logic. In: Stickel, M.E.
(ed.) CADE-10. pp. 485–499. Springer (1990). https://doi.org/10.1007/3-540-5288
5-7_109
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Eﬃcient Local Reductions to Basic Modal Logic⋆
Fabio Papacchini1
, Cl´audia Nalon2
,
Ullrich Hustadt1
, and Clare Dixon4
1 Department of Computer Science, University of Liverpool, UK,
{Fabio.Papacchini,U.Hustadt}@liverpool.ac.uk
2 Department of Computer Science, University of Bras´ılia, nalon@unb.br
3 Department of Computer Science, University of Manchester,
clare.dixon@manchester.ac.uk
Abstract. We present novel reductions of the propositional modal logics
KB, KD, KT, K4 and K5 to Separated Normal Form with Sets of Modal
Levels. The reductions result in smaller formulae than the well-known
reductions by Kracht and allow us to use the local reasoning of the prover
KSP to determine the satisﬁability of modal formulae in these logics. We
show experimentally that the combination of our reductions with the
prover KSP performs well when compared with a specialised resolution
calculus for these logics and with the ˘built-in reductions of the ﬁrst-order
prover SPASS.
1
Introduction
The main motivation for reducing problems in one logic (the source logic) to
‘equivalent’ problems in another logic (the target logic) is to exploit results and
tools for the target logic to solve theoretical or practical problems in the source
logic. For propositional modal logics this approach has been researched exten-
sively for reductions of the satisﬁability problem in these logics to the satisﬁabil-
ity problem in ‘stronger’ logics such as ﬁrst-order logic [10,20], the second-order
theory of n successors [6], simple type theory [4], and regular grammar logics [19].
An alternative approach is to reduce propositional modal logics to a ‘weaker’
logic, in particular, the basic modal logic K. For extensions of K with one of the
axioms B, D, alt1, T, and 4, Kracht [12] deﬁnes reduction functions of their global
and local satisﬁability problem to the corresponding problem in K and proves
their correctness. He also deﬁnes a reduction function for K5, the extension
of K with 5, to K4, but this reduction is incorrect as not all theorems of K4
are theorems of K5. Several features of Kracht’s approach are relevant to our
work. First, as is not uncommon in modal logic, he treats the modal operator
3 as abbreviation for ¬2¬, that is, 2 is the only modal operator occurring
in modal formulae. Second, the basic idea underlying his reduction functions
⋆C. Dixon was partially supported by the EPSRC funded RAI Hubs FAIR-SPACE
(EP/R026092/1) and RAIN (EP/R026084/1), and the EPSRC funded programme
Grant S4 (EP/N007565/1).
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp. 76 92, 2021.
https://doi.org/10.1007/978-3-030-79876-5 5
–

Eﬃcient Local Reductions to Basic Modal Logic
77
is for a given modal formula ϕ to generate suﬃciently many instances Δ of
a modal axiom Λ so that ϕ is KΛ-satisﬁable iﬀϕ ∧Δ is K-satisﬁable. Third,
Kracht is only concerned with preservation of the computational complexity
of the satisﬁability problem under consideration, as well as the preservation of
other theoretical properties. For instance, the local satisﬁability problem in the
modal logics covered by Kracht is PSPACE-complete. So, it is suﬃcient to ensure
that Δ is polynomial in size with respect to ϕ. As Kracht himself concludes, his
method oﬀers a uniform way of transferring results about one modal logic to
another, but may not be as useful for practical applications.
In [16,15] we have introduced a new normal form for basic multi-modal logic,
called Separated Normal Form with Modal Levels, SNFml, that uses labelled
modal clauses. These labels refer to the level within a tree Kripke structure
at which a modal clause holds. This can be seen as a compromise between ap-
proaches that label formulae with worlds at unspeciﬁed level [1,3] and approaches
that label formulae with paths [5,23]. A combination of a normal form transfor-
mation for modal formulae and a resolution-based calculus for labelled modal
clauses can then be used to decide local and global satisﬁability in basic modal
logic. In [17,18] we have presented KSP, an implementation of that calculus, to-
gether with an experimental evaluation that indicates that KSP performs well
if propositional variables are evenly spread across a wide range of modal levels
within the formulae one wants to decide.
A feature of SNFml is its use of additional propositional symbols as ‘surro-
gates’ for subformulae of a modal formula ϕ. In the following we take advantage
of the availability of those surrogates to provide a novel transformation from ex-
tensions of K with a single one of the axioms B, D, T, 4 and 5 to SNFml. Another
novel aspect is that we modify the normal form so that it uses sets of modal
levels as labels instead of a single modal level. In K we only need a deﬁnition of
a surrogate at the modal level at which the corresponding subformula occurs in
ϕ. But in KB, KT, K4 and K5, we need a deﬁnition at every reachable modal
level, of which there can be many. We call the resulting normal form, Separated
Normal Form with Sets of Modal Levels, SNFsml.
The structure of the paper is as follows. In Section 2 we recap common con-
cepts of propositional modal logic including its syntax and semantics. Section
3 deﬁnes SNFsml and the reductions of K, KB, KD, KT, K4 and K5 to SNFsml.
Correctness is proved in Section 4. Related work is discussed in Section 5. In
Section 6 we compare the performance of a combination of our reductions and
the modal-layered resolution calculus implemented in prover KSP with reso-
lution calculi speciﬁcally designed for the logics under consideration and with
translation-based approaches built into the ﬁrst-order theorem prover SPASS.
2
Preliminaries
The language of modal logic is an extension of the language of propositional
logic with a unary modal operator 2 and its dual 3. More precisely, given a
denumerable set of propositional symbols, P = {p, p0, q, q0, t, t0, . . .} as well as

78
F. Papacchini et al.
propositional constants true and false, modal formulae are inductively deﬁned
as follows: Constants and propositional symbols are modal formulae. If ϕ and ψ
are modal formulae, then so are ¬ϕ, (ϕ ∧ψ), (ϕ ∨ψ), (ϕ →ψ), 2ϕ, and 3ϕ.
We also assume that ∧and ∨are associative and commutative operators and
consider, e.g., (p∨(q∨r)) and (r∨(q∨p)) to be identical formulae. We often omit
parentheses if this does not cause confusion. By var(ϕ) we denote the set of all
propositional symbols occurring in ϕ. This function straightforwardly extends
to ﬁnite sets of modal formulae. A modal axiom (schema) is a modal formula ψ
representing the set of all instances of ψ.
A literal is either a propositional symbol or its negation; the set of literals is
denoted by L. We denote by ¬l the complement of the literal l ∈L, that is, ¬l
denotes ¬p if l is the propositional symbol p, and ¬l denotes p if l is the literal
¬p. A modal literal is either 2l or 3l, where l ∈L.
A (normal) modal logic is a set of modal formulae which includes all propo-
sitional tautologies, the axiom schema 2(ϕ →ψ) →(2ϕ →2ψ), called the
axiom K, is closed under modus ponens (if ⊢ϕ and ⊢ϕ →ψ then ⊢ψ) and the
rule of necessitation (if ⊢ϕ then ⊢2ϕ).
K is the weakest modal logic, that is, the logic given by the smallest set
of modal formulae constituting a normal modal logic. By KΣ we denote an
extensions of K by a set Σ of axioms.
The standard semantics of modal logics is the Kripke semantics or possible
world semantics. A Kripke frame F is an ordered pair ⟨W, R⟩where W is a
non-empty set of worlds and R is a binary (accessibility) relation over W. A
Kripke structure M over P is an ordered pair ⟨F, V ⟩where F is a Kripke frame
and the valuation V is a function mapping each propositional symbol in P to
a subset V (p) of W. We say M = ⟨F, V ⟩is based on the frame F. A rooted
Kripke structure is an ordered pair ⟨M, w0⟩with w0 ∈W. To simplify notation,
in the following we write ⟨W, R, V ⟩and ⟨W, R, V, w0⟩instead of ⟨⟨W, R⟩, V ⟩and
⟨⟨⟨W, R⟩, V ⟩, w0⟩, respectively.
Satisfaction (or truth) of a formula at a world w of a Kripke structure M =
⟨W, R, V ⟩is inductively deﬁned by:
⟨M, w⟩|= true;
⟨M, w⟩̸|= false;
⟨M, w⟩|= p
iﬀw ∈V (p), where p ∈P;
⟨M, w⟩|= ¬ϕ
iﬀ⟨M, w⟩̸|= ϕ;
⟨M, w⟩|= (ϕ ∧ψ) iﬀ⟨M, w⟩|= ϕ and ⟨M, w⟩|= ψ;
⟨M, w⟩|= (ϕ ∨ψ) iﬀ⟨M, w⟩|= ϕ or ⟨M, w⟩|= ψ;
⟨M, w⟩|= (ϕ →ψ) iﬀ⟨M, w⟩|= ¬ϕ or ⟨M, w⟩|= ψ;
⟨M, w⟩|= 2ϕ
iﬀfor every v, w R v implies ⟨M, v⟩|= ϕ;
⟨M, w⟩|= 3ϕ
iﬀthere is v, w R v and ⟨M, v⟩|= ϕ.
If ⟨M, w⟩|= ϕ holds then M is a model of ϕ, ϕ is true at w in M and M satisﬁes
ϕ. A modal formula ϕ is satisﬁable iﬀthere exists a Kripke structure M and a
world w in M such that ⟨M, w⟩|= ϕ. A modal formula ϕ is globally true or valid
in a Kripke structure M if it is true at all worlds of M; it is valid if it is valid in
all Kripke structures.

Eﬃcient Local Reductions to Basic Modal Logic
79
Name Axiom
Frame Property
D
2ϕ →3ϕ
Serial
∀v∃w.v R w
T
2ϕ →ϕ
Reﬂexive
∀w.w R w
B
ϕ →23ϕ
Symmetric ∀vw.v R w →w R v
4
2ϕ →22ϕ Transitive ∀uvw.(u R v ∧v R w) →u R w
5
3ϕ →23ϕ Euclidean ∀uvw.(u R v ∧u R w) →v R w
Table 1. Modal axioms and relational frame properties
In the following we are interested in extensions of K with the axiom schemata
shown in Table 1. Each of these axiom schemata deﬁnes a class of Kripke frames
where the accessibility relation R satisﬁes the ﬁrst-order property stated in the
table. Given a normal modal logic L with corresponding class of frames F, we say
a modal formula ϕ is L-satisﬁable iﬀthere exists a frame F ∈F, a valuation V
and a world w0 ∈F such that ⟨F, V, w0⟩|= ϕ.
A path rooted at w of length k, k ≥0, in a frame F = ⟨W, R⟩is a sequence
⃗w = (w0, w1, . . . , wk) where for every i, 1 ≤i ≤k, wi−1 R wi. We say that the
path (w0, w1, . . . , wk) connects w0 and wk. For a path ⃗w = (w0, . . . , wk) and
world wk+1 with wk R wk+1, ⃗w ◦wk+1 denotes the path (w0, . . . , wk, wk+1). A
path (w0) of length 0 is identiﬁed with its root w0. We denote the set of all paths
rooted at a world w0 in F by ⃗F[w0] and the set of all paths by ⃗F. The function
trm : ⃗F →W maps every path ⃗w = (w0, . . . , wk) to its terminal world wk while
the function len : ⃗F →N maps every path ⃗w = (w0, w1, . . . , wk) to its length k.
A rooted Kripke structure M = ⟨W, R, V, w0⟩is a rooted tree Kripke structure
iﬀR is a tree, that is, a directed acyclic connected graph where each node has at
most one predecessor, with root w0. It is a rooted tree Kripke model of a modal
formula ϕ iﬀ⟨W, R, V, w0⟩|= ϕ. In a rooted tree Kripke structure with root w0
for every world wk ∈W there is exactly one path ⃗w connecting w0 and wk; the
modal level of wk (in M), denoted by mlM(wk), is given by len(⃗w).
Let F = ⟨W, R⟩be a Kripke frame with w ∈W. The unravelling F u[w] of F
at w is the frame ⟨⃗W, ⃗R⟩where:
– ⃗W = ⃗F[w] is the set of all rooted paths at w in F;
– for all ⃗v, ⃗w ∈⃗W, if ⃗w = ⃗v ◦w for some w ∈W, then ⃗v ⃗R ⃗w.
Let F = ⟨W, R⟩and F ′ = ⟨W ′, R′⟩be two Kripke frames. A function f : W →W ′
is a p-morphism (or a bounded morphism) from F to F ′ if the following holds:
– if v R w, then f(v) R′ f(w).
– if f(u) R′ w, then there exists v ∈W s.t. f(v) = w and u R v.
Analogously for Kripke models. For F = ⟨W, R⟩, M ′ = ⟨F, V ′, w0⟩, and M =
⟨F u[w0], V, (w0)⟩, the function trm is a p-morphism from M to M ′.
When considering local satisﬁability, the following holds (see, [8]):
Theorem 1. Let ϕ be a modal formula. Then ϕ is K-satisﬁable iﬀthere is a
ﬁnite rooted tree Kripke structure M = ⟨F, V, w0⟩such that ⟨M, w0⟩|= ϕ.

80
F. Papacchini et al.
ϕ ∧ϕ ⇒ϕ
ϕ ∨ϕ ⇒ϕ
ϕ ∧true ⇒ϕ
ϕ ∧¬ϕ ⇒false
ϕ ∨¬ϕ ⇒true
ϕ ∧false ⇒false
2true ⇒true
3false ⇒false
ϕ ∨false ⇒ϕ
¬true ⇒false
¬false ⇒true
ϕ ∨true ⇒true
¬¬ϕ ⇒ϕ
Table 2. Rewriting Rules for Simpliﬁcation
For the normal form transformation presented in the next section we assume
that any modal formula ϕ has been simpliﬁed by exhaustively applying the
rewrite rules in Table 2 and is in Negation Normal Form (NNF), that is, a
formula where only propositional symbols are allowed in the scope of negations.
We say that such a formula is in simpliﬁed NNF.
3
Layered Normal Form with Sets of Levels
A formula to be tested for satisﬁability is ﬁrst transformed into a normal form
called Separated Normal Form with Sets of Modal Levels, SNFsml, whose lan-
guage extends that of modal logic with labels consisting of sets of modal levels.
Informally, we write S : ϕ, where S is a set of natural numbers, to denote that
a formula ϕ is true at modal levels ml ∈S. We write ⋆: ϕ instead of N : ϕ.
We introduce some notation that will be used in the following. Let S+ =
{l +1 ∈N | l ∈S}, S−= {l −1 ∈N | l ∈S}, and S≥= {n | n ≥min(S)}, where
min(S) is the least element in S. Note that the restriction of the elements being
in N implies that S−cannot contain negative numbers.
The labels in SNFsml work as a kind of weak universal operator, allowing us
to talk about formulae that are satisﬁed at all worlds in a given set of modal
levels. Formally, we restrict ourselves to rooted tree Kripke structures M =
⟨W, R, V, w0⟩and if S is a set of modal levels, then by M[S] we denote the set of
worlds that are at a modal level in S, that is, M[S] = {w ∈W | mlM(w) ∈S}.
The satisfaction of labelled formulae in a rooted tree Kripke structure M is then
deﬁned as follows:
M |= S : ϕ iﬀfor every world w ∈M[S], we have ⟨M, w⟩|= ϕ.
If M |= S : ϕ, then we say that S : ϕ holds in M. Note that if S = ∅, then
M |= S : ϕ trivially holds. For a set Φ of labelled formulae, M |= Φ iﬀM |= S : ϕ
for every S : ϕ in Φ, and we say Φ is K-satisﬁable.
A labelled modal formula is then an SNFsml clause iﬀit is of one of the
following forms:
– Literal clause
S : r
b=1 lb
– Positive modal clause
S : l′ →2l
– Negative modal clause
S : l′ →3l
where S ⊆N and l, l′, lb are propositional literals with 1 ≤b ≤r, r ∈N. Positive
and negative modal clauses are together known as modal clauses. We regard a

Eﬃcient Local Reductions to Basic Modal Logic
81
literal clause as a set of literals, that is, two clauses are the same if they contain
the same set of literals.
We assume that the set P of propositional symbols is partitioned into two
inﬁnite sets Q and T such that for every modal formula ψ we have var(ψ) ⊂Q
and there exists a propositional symbol tψ ∈T uniquely associated with ψ.
Given a modal formula ϕ in simpliﬁed NNF and L ∈{K, KB, KD, KT, K4, K5},
then we can obtain a set ΦL of clauses in SNFsml such that ϕ is L-satisﬁable iﬀ
ΦL is K-satisﬁable as ΦL = {{0} : tϕ} ∪ρL({0} : tϕ →ϕ), where ρL is deﬁned
as follows:
ρL(S : t →true) = ∅
ρL(S : t →false) = {S : ¬t}
ρL(S : t →(ψ1 ∧ψ2)) = {S : ¬t ∨η(ψ1), S : ¬t ∨η(ψ2)} ∪δL(S, ψ1) ∪δL(S, ψ2)
ρL(S : t →ψ) = {S : ¬t ∨ψ}
if ψ is a disjunction of literals
ρL(S : t →(ψ1 ∨ψ2)) = {S : ¬t ∨η(ψ1) ∨η(ψ2)} ∪δL(S, ψ1) ∪δL(S, ψ2)
if ψ1 ∨ψ2 is not a disjunction of literals
ρL(S : t →3ψ) = {S : t →3η(ψ)} ∪δL(S+, ψ)
ρL(S : t →2ψ) = PL(S : t →2ψ) ∪ΔL(S : t →2ψ)
where η and δL are deﬁned as follows:
η(ψ) =
⎧
⎪
⎨
⎪
⎩
ψ,
if ψ is a
literal
tψ,
otherwise
δL(S, ψ) =
⎧
⎪
⎨
⎪
⎩
∅,
if ψ is a
literal
ρL(S : tψ →ψ),
otherwise
and functions PL, ΔL are deﬁned as shown in Table 3. The function η maps
a propositional literal ψ to itself while it maps every other modal formula ψ
to a new propositional symbol tψ ∈T uniquely associated with ψ. We call tψ
the surrogate of ψ or simply a surrogate. The functions PKB and PK5 introduce
additional propositional symbols, called supplementary propositional symbols,
t2¬t2ψ ∈T and t3t2ψ ∈T, respectively, that do not correspond to subformulae
of the formula we are transforming.
Intuitively, PKB is based on the following consideration: Take a world w in
a Kripke structure M with a symmetric accessibility relation R. If there exists
a world v with w R v such that ⟨M, v⟩|= 2ψ, then ⟨M, w⟩|= ψ. Now, take the
contrapositive of that statement: If ⟨M, w⟩̸|= ψ, then for every world v with
w R v, ⟨M, v⟩̸|= 2ψ. Equivalently, ⟨M, w⟩|= ψ or ⟨M, w⟩|= 2¬2ψ. This is
expressed by the formula η(ψ) ∨t2¬t2ψ.
For PK5, the formula t3t2ψ →2t3t2ψ
expresses an instance of axiom schema 5, 3ϕ →23ϕ, with ϕ = 2ψ, i.e.,
32ψ →232ψ. The contrapositive of axiom schema 5 is 32ϕ →2ϕ, equivalent
to ¬32ϕ ∨2ϕ. For ϕ = ψ this is expressed by the formula ¬t3t2ψ ∨t2ψ. For
the formula ¬t3t2ψ →2¬t2ψ, consider ¬32ψ. By duality of 2 and 3, this is

82
F. Papacchini et al.
L
PL(S : t2ψ →2ψ)
ΔL(S : t2ψ →2ψ)
K
S : t2ψ →2η(ψ)
δL(S+, ψ)
KT S : t2ψ →2η(ψ), S : ¬t2ψ ∨η(ψ)
δL(S ∪S+, ψ)
KD S : t2ψ →2η(ψ), S : t2ψ →3η(ψ)
δL(S+, ψ)
KB S : t2ψ →2η(ψ),
S−: η(ψ) ∨t2¬t2ψ, S−: t2¬t2ψ →2¬t2ψ
δL(S−∪S+, ψ)
K4
S≥: t2ψ →2η(ψ), S≥: t2ψ →2t2ψ
δL((S+)≥, ψ)
K5
⋆: t2ψ →2η(ψ),
⋆: ¬t3t2ψ ∨t2ψ, ⋆: t3t2ψ →3t2ψ,
⋆: ¬t3t2ψ →2¬t2ψ, ⋆: t3t2ψ →2t3t2ψ
δL(⋆, ψ)
Table 3. Transformation of 2-formulae in modal logic L
equivalent to ¬¬2¬2ψ and 2¬2ψ. So, ¬32ψ →2¬2ψ in every normal modal
logic, not only K5. The remaining labelled formulae introduced by PKB and PK5
ensure that supplementary propositional symbols are deﬁned. For the remaining
logics the additional clauses are also based directly on the axiom schemata.
To simplify presentation in the following, we deﬁne a function ηf as follows:
ηf(ϕ1 ∧ϕ2) = η(ϕ1) ∧η(ϕ2)
ηf(ϕ1 ∨ϕ2) = η(ϕ1) ∨η(ϕ2)
ηf(2ϕ) = 2η(ϕ)
ηf(3ϕ) = 3η(ϕ)
and we treat the two clauses S : ¬tψ1∧ψ2 ∨η(ψ1) and S : ¬tψ1∧ψ2 ∨η(ψ2)
resulting from the normal form transformation of ψ1 ∧ψ2 as a single ‘clause’
S : ¬tψ1∧ψ2 ∨ηf(ψ1 ∧ψ2). We also interchangeably write S : ¬t2ψ ∨ηf(2ψ) for
S : t2ψ →ηf(2ψ) and, analogously, S : ¬t3ψ ∨ηf(3ψ) for S : t3ψ →ηf(3ψ).
We then call any clause of the form S : ¬tψ ∨ηf(ψ) a deﬁnitional clause.
Deﬁnition 1. Let Φ be a set of SNFsml clauses. We say tψ ∈T occurs at level
ml in Φ iﬀeither
(a) there exists a clause S : ϑ in Φ with ml ∈S such that ϑ is a propositional
formula and tψ occurs positively in ϑ, or
(b) there exists a clause S : t2ψ →2tψ in Φ with ml −1 ∈S, or
(c) there exists a clause S : t3ψ →3tψ in Φ with ml −1 ∈S.
Deﬁnition 2. Let Φ be a set of SNFsml clauses. Then Φ is deﬁnition-complete
iﬀfor every tψ ∈T and every level ml, if tψ occurs at level ml in Φ then there
exists a clause S : ¬tψ ∨ηf(ψ) in Φ with ml ∈S.
Theorem 2. Let L ∈{K, KB, KD, KT, K4, K5}. Then ΦL = {{0} : tϕ} ∪
ρL({0} : tϕ →ϕ) is deﬁnition-complete.

Eﬃcient Local Reductions to Basic Modal Logic
83
Proof. By induction over the computation of ΦL. It is straightforward to see that
the transformation of labelled formulae S : t →(ψ1 ∧ψ2) and S : t →(ψ1 ∨ψ2)
only introduces surrogates at levels in S and ΔL then adds deﬁnitional clauses
for those surrogates. The transformation of a labelled formula S : t3ψ →3ψ may
introduce a surrogate at levels in S+ and δL(S+, ψ) then adds deﬁnitional clauses
for those surrogates. The transformation of a labelled formula S : t2ψ →2ψ
depends on the logic L. We can see that for every level at which a new surrogate
occurs in PL(S : t2ψ →2ψ), then ΔL(S : t2ψ →2ψ) contains a deﬁnitional
clause for it at that level.
4
Correctness
Due to space constraints we only prove the correctness of the transformation for
KB. We ﬁrst state several lemmata that are used in the correctness proofs for
all logics.
Lemma 1. Let Φ be a set of deﬁnitional clauses such that every tψ occurring
in Φ is an element of T and all other propositional symbols occurring in Φ are
in Q. Let M = ⟨W, R, V, w0⟩be a rooted Kripke structure. Let ⟨⃗W, ⃗R⟩be the
unravelling of ⟨W, R⟩at w0. Let ⃗M = ⟨⃗W, ⃗R, ⃗
VΣ, (w0)⟩be a Kripke structure
such that
–
⃗
VΣ(p) = {⃗w ∈⃗W | trm(⃗w) ∈V (p)} for every propositional symbol p ∈Q, and
–
⃗
VΣ(tψ) = {⃗w ∈⃗W | ⟨⃗M, ⃗w⟩|= ψ} for every surrogate tψ ∈T ∩var(Φ).
Then ⃗M |= Φ.
Lemma 2. Let ϕ be a L-satisﬁable modal formula in simpliﬁed NNF where
L is a normal modal logic and let Φ = {{0} : tϕ} ∪ρK({0} : tϕ →ϕ). Let
M = ⟨W, R, V, w0⟩be a rooted K model of ϕ. Let ⟨⃗W, ⃗R⟩be the unravelling of
⟨W, R⟩at w0. Let ⃗M = ⟨⃗W, ⃗R, ⃗V , (w0)⟩be a Kripke structure such that
– ⃗V (p) = {⃗w ∈⃗W | trm(⃗w) ∈V (p)} for every propositional symbol p ∈var(ϕ),
and
– ⃗V (tψ) = {⃗w ∈⃗W | ⟨⃗M, ⃗w⟩|= ψ} for every surrogate tψ ∈T ∩var(Φ).
Then ⃗M |= Φ.
Lemma 3. Let M = ⟨W, R, V, w0⟩be a rooted Kripke structure. Let ⟨⃗W, ⃗R⟩be
the unravelling of ⟨W, R⟩at w0. Let ⃗M = ⟨⃗W, ⃗R, ⃗
VΣ, (w0)⟩where ⃗
VΣ(p) = {⃗w ∈
⃗W | trm(⃗w) ∈V (p)} for every propositional symbol p ∈Q.
Then for every modal formula ψ over Q and for every world ⃗w ∈⃗W, ⟨⃗M, ⃗w⟩|=
ψ iﬀ⟨M, trm(⃗w)⟩|= ψ.
Lemma 4. Let ϕ be a modal formula in simpliﬁed NNF. Let ΦK = {{0} :
tϕ}∪ρK({0} : tϕ →ϕ). Let Φ with ΦK ⊆Φ be a deﬁnition-complete set of SNFsml
clauses, let M = ⟨W, R, V, w0⟩be a tree K model of Φ and let M ′ = ⟨W, R′, V, w0⟩
be such that

84
F. Papacchini et al.
(4a) R ⊆R′;
(4b) for every modal clause S : t2ψ →2η(ψ) in Φ and every world w ∈M[S],
⟨M ′, w⟩|= t2ψ →2η(ψ);
(4c) for every modal clause S : t2ψ →2tψ in Φ and all worlds v, w ∈W, if
(i) w ∈M[S] and (ii) wR′v then (iii) there exists a clause S′ : ¬tψ∨ηf(ψ)
in Φ with v ∈M[S′].
Then ⟨M ′, w0⟩|= ϕ.
Theorems 3 and 4 now state the correctness of our transformation for KB.
Theorem 3. Let ϕ be a modal formula in simpliﬁed NNF. Let ΦB = {{0} :
tϕ} ∪ρKB({0} : tϕ →ϕ). If ϕ is KB-satisﬁable, then ΦB is K-satisﬁable.
Proof. The main idea is to show that given a rooted KB model of ϕ, then a small
variation of its unravelling is a rooted tree K model of ΦB.
Let M = ⟨W, R, V, w0⟩be a rooted KB model of ϕ with ⟨M, w0⟩|= ϕ and
symmetric relationship R. Let ⟨⃗W, ⃗R⟩be the unravelling of ⟨W, R⟩at w0. Let
⃗MB = ⟨⃗W, ⃗R, ⃗VB, (w0)⟩where
– ⃗VB(p) = {⃗w ∈⃗W | trm(⃗w) ∈V (p)} for every propositional symbol p ∈var(ϕ),
– ⃗VB(tψ) = {⃗w ∈⃗W | ⟨⃗MB, ⃗w⟩|= ψ} for every surrogate tψ ∈var(ΦB) \ var(ϕ)
introduced by rewriting, and
– ⃗VB(t2¬t2ψ) = {⃗w ∈⃗W | ⟨⃗MB, ⃗w⟩|= 2¬2ψ} for every supplementary propo-
sitional symbol t2¬t2ψ introduced in the normal form transformation of a
labelled formula S : t2ψ →2ψ.
Note that ⃗VB is well-deﬁned as for every surrogate tψ ∈T, ψ only contains
propositional symbols in Q. Let ΦK = {{0} : tϕ} ∪ρK({0} : tϕ →ϕ).
We now consider the clauses occurring in ΦB and show that they hold in ⃗MB.
By Lemma 2 it follows that ⃗MB |= ΦK. Also, all deﬁnitional clauses in ΦB \ ΦK
are true in ⃗MB by Lemma 1.
Next consider clauses of the form
(1) S′ : η(ψ) ∨t2¬t2ψ
(2) S′ : t2¬t2ψ →2¬t2ψ
where t2ψ is a surrogate for 2ψ. These are not in ΦK. We show both are true in
⃗MB. We do so by ﬁrst considering that t2¬t2ψ is true at a world and then that
it is false.
Case (a): Let ⃗w ∈⃗MB[S′] with ⟨⃗MB, ⃗w⟩|= t2¬t2ψ. Clearly, ⟨⃗MB, ⃗w⟩|= η(ψ) ∨
t2¬t2ψ. Also, by deﬁnition of ⃗MB, ⟨MB, ⃗w⟩|= 2¬2ψ. So, for every ⃗v ∈⃗W
with ⃗w ⃗R ⃗v, ⟨⃗MB,⃗v⟩|= ¬2ψ. As t2ψ is a surrogate for 2ψ, by deﬁnition of
⃗
VB, ⃗v ̸∈⃗
VB(t2ψ) and ⟨⃗MB,⃗v⟩|= ¬t2ψ. Thus, ⟨⃗MB, ⃗w⟩|= 2¬t2ψ and, by the
semantics of implication, ⟨⃗MB, ⃗w⟩|= t2¬t2ψ →2¬t2ψ.
Case (b): Let ⃗w ∈⃗MB[S′] with ⟨⃗MB, ⃗w⟩̸|= t2¬t2ψ. Clearly, by the semantics
of implication, ⟨⃗MB, ⃗w⟩|= t2¬t2ψ →2¬t2ψ. Also, by deﬁnition of ⃗
VB, ⃗w ̸∈
⃗
VB(t2¬t2ψ) implies ⟨⃗MB, ⃗w⟩̸|= 2¬2ψ which in turn implies ⟨⃗MB, ⃗w⟩|= 32ψ. So,
there exists ⃗v ∈⃗W with ⃗w ⃗R⃗v and ⟨⃗MB,⃗v⟩|= 2ψ. Since trm is a p-morphism from

Eﬃcient Local Reductions to Basic Modal Logic
85
⃗MB to M, trm(⃗w) R trm(⃗v). Since R is symmetric, we also have trm(⃗v) R trm(⃗w)
and by construction of ⃗MB, for ⃗u = ⃗v ◦trm(⃗w) we have ⃗v ⃗R ⃗u. Since ⟨⃗MB,⃗v⟩|=
2ψ, ⟨⃗MB, ⃗u⟩|= ψ. As trm is a p-morphism and ⟨M, trm(⃗u)⟩|= ψ and since
trm(⃗w) = trm(⃗u), ⟨M, trm(⃗w)⟩|= ψ. By Lemma 3, from ⟨M, trm(⃗w)⟩|= ψ we
obtain ⟨⃗MB, ⃗w⟩|= ψ. If ψ is a literal, then η(ψ) = ψ and ⟨M, ⃗w⟩|= η(ψ). If
ψ is not a literal, then η(ψ) = tψ and from ⟨⃗MB, ⃗w⟩|= ψ, by deﬁnition of ⃗VB,
⃗w ∈⃗VB(tψ) and ⟨⃗MB, ⃗w⟩|= tψ. So, ⟨M, ⃗w⟩|= η(ψ) ∨t2¬t2ψ.
Thus, in both cases, for arbitrary ⃗w ∈⃗MB[S′], η(ψ)∨t2¬t2ψ and t2¬t2ψ →2¬t2ψ
and therefore Clauses (1) and (2) are true in ⃗MB.
Theorem 4. Let ϕ be a modal formula in simpliﬁed NNF. Let ΦB = {{0} :
tϕ} ∪ρKB({0} : tϕ →ϕ). If ΦB is K-satisﬁable, then ϕ is KB-satisﬁable.
Proof. The main idea is to show that given a rooted tree K model of ΦB, its
symmetric closure is a rooted KB model of ϕ.
Let M = ⟨W, R, V, w0⟩be a rooted tree K model of ΦB. Let M B = ⟨W, RB,
V B, w0⟩be a structure such that
(a) RB is the symmetric closure of R, that is, RB is the smallest relation on W
such that R ⊆RB and for every v, w ∈W, v RB w implies w RB v;
(b) V B(p) = V (p) for every propositional symbol.
Let ΦK = {{0} : tϕ} ∪ρK({0} : tϕ →ϕ). We show that M B |= ΦB satisﬁes the
three preconditions of Lemma 4. By Lemma 4 this in turn implies that M B |= ϕ.
– Condition (4a) holds as R ⊆RB.
– For Condition (4b) let (3) S : t2ψ →2η(ψ) be a modal clause in ΦB.
Then ΦB also contains the additional clauses (4) S−: η(ψ) ∨t2¬t2ψ and
(5) S−: t2¬t2ψ →2¬t2ψ. Let w ∈M[S]. We have to show that (6) ⟨M B, w⟩|=
t2ψ →2η(ψ). Assume ⟨M B, w⟩|= t2ψ. As V B(t2ψ) = V (t2ψ) this implies
⟨M, w⟩|= t2ψ. Let v ∈W such that w RB v.
Case (a): Assume w R v. As ⟨M, w⟩|= t2ψ and ⟨M, w⟩|= t2ψ →2η(ψ), we
have ⟨M, w⟩|= 2η(ψ). As w R v, ⟨M, v⟩|= η(ψ). As η(ψ) is a literal and
V B = V we obtain ⟨M B, v⟩|= η(ψ). So, ⟨M B, w⟩|= t2ψ →2η(ψ).
Case (b): Assume v is not reachable from w via R. Then wRBv was introduced
by the symmetric closure operation on R and we must have v R w. That is,
v is a R-predecessor of w and from w ∈M[S] it follows that v ∈M[S−].
So, (7) ⟨M, v⟩|= η(ψ) ∨t2¬t2ψ and (8) ⟨M, v⟩|= t2¬t2ψ →2¬t2ψ. From
v R w, ⟨M, w⟩|= t2ψ and (8), it follows that ⟨M, v⟩|= ¬t2¬t2ψ. This together
with (7) implies ⟨M, v⟩|= η(ψ). As η(ψ) is a literal and V B = V we obtain
⟨M B, v⟩|= η(ψ). So, ⟨M B, w⟩|= t2ψ →2η(tψ).
Case (a) and Case (b) together show that Property (6) holds.
– For Condition (4c) let (9) S : t2ψ →2tψ be in ΦB, v, w ∈W, mlM(w) = ml ∈
S (i.e., w ∈M[S]) and w RB v. We need to show that there exists a clause
S′ : ¬tψ ∨ηf(ψ) in ΦB with v ∈M[S′].
As in the previous case w RB v implies either w R v or v R w. In the ﬁrst case
mlM(v) = ml + 1 while in the second case mlM(v) = ml −1.

86
F. Papacchini et al.
As ΦB contains Clause (9), tψ occurs at level ml+1 in ΦB. By deﬁnition of ρKB,
ΦB also contains the clause (10) S−: tψ ∨t2¬t2ψ. As ml ∈S, ml−1 ∈S−and
therefore tψ also occurs at level ml −1 in ΦB. By Theorem 2, ΦB is deﬁnition-
complete, so there must be a clause S′ : ¬tψ ∨ηf(ψ) in ΦB such that ml + 1
and ml −1 in S′.
Theorem 5. Let ϕ be a modal formula in simpliﬁed NNF, L ∈{K, KB, KD, KT,
K4, K5}, and ΦL = {{0} : tϕ} ∪ρL({0} : tϕ →ϕ). Then ϕ is L-satisﬁable iﬀΦL
is K-satisﬁable.
5
Comparison With Related Work
The approaches most closely related to ours are Kracht’s reductions of normal
modal logics to basic modal logic [11,12], the global modal resolution calcu-
lus [14], and Schmidt and Hustadt’s axiomatic translation principle for transla-
tions of normal modal logics to ﬁrst-order logic [24].
The ﬁrst signiﬁcant diﬀerence to our approach is that Kracht’s reductions
and the axiomatic translation exclude the modal operator 3 from the language
and only consider the modal operator 2.
In order to present Kracht’s approach, we need some additional notions.
Let sf(ϕ), dg(ϕ), and |S| denote the set of all subformulae of ϕ, the maximum
nesting of modal operators in ϕ, and the cardinality of the set S, respectively.
Let 30ψ = 20ψ = 2<1ψ = ψ, 2<n+1ψ = (ψ ∧22<nψ), 2n+1ψ = 22nψ, and
3n+1ψ = 33nψ. We can then deﬁne a reduction function ρK
L for a normal modal
logic L in {KB, KD, KT, K4} as follows:
ρK
L(ϕ) =
⎧
⎨
⎩
ϕ ∧2<|sf(ϕ)|+1P K
K4(ϕ),
for L = K4
ϕ ∧2<dg(ϕ)+1P K
L (ϕ)
otherwise
where P K
KB(ϕ)= {¬ψ →2¬2ψ | 2ψ ∈sf(ϕ)} P K
KD(ϕ)= {¬2false}
P K
K4(ϕ)= {2ψ →22ψ | 2ψ ∈sf(ϕ)}
P K
KT(ϕ)= {2ψ →ψ | 2ψ ∈sf(ϕ)}
Kracht shows that ϕ is L-satisﬁable iﬀρK
L(ϕ) is K-satisﬁable. There are three
diﬀerences to our approach. First, P K
L (ϕ) will include an axiom instance for
every occurrence of a subformula ¬2ψ, equivalent to 3¬ψ, in ϕ. In contrast,
our approach requires no logic speciﬁc treatment of such subformulae. Second,
the use of 2<nP K
L (ϕ) in ρK
L means that the axiom instance is available at every
modal level. This means, for example, that for ϑ1 = 3100(¬p ∧2p), the formula
ρK
KT(ϑ1) contains the axiom instance 2p →p over 100 times, although it is only
required at the level at which 2p occurs. Third, this is further compounded if
the formula ψ in 2ψ is itself a complex formula. We try to avoid that by using
a surrogate propositional symbol tψ instead, but this will only have a positive
eﬀect if the deﬁnitional clauses for tψ do not have to be repeated.
The global modal resolution (GMR) calculus operates on SNFK clauses, that
is, clauses of the form
2∗(start →r
b=1 lb)
2∗(true →r
b=1 lb)
2∗(l′ →2l)
2∗(l′ →¬2l)

Eﬃcient Local Reductions to Basic Modal Logic
87
[EUC1]
2∗(l1 →¬2¬l)
2∗(true →¬l1 ∨t3l)
2∗(t3l →¬2¬l)
2∗(¬t3l →2¬l)
2∗(t3l →2t3l)
[EUC2]
2∗(l →2l2)
2∗(t3l →2l2)
2∗(t3l →¬2¬l)
2∗(¬t3l →2¬l)
2∗(t3l →2t3l)
Table 4. Inference rules in [14] for K5 (EUC1 and EUC2).
where l, l′, lb are propositional literals with 1 ≤b ≤r, r ∈N, and 2∗is the uni-
versal operator. The calculus has speciﬁc inference rules for normal modal logics
such as KB, KD, KT, K4, K5. Table 4 shows the two additional rules for K5, the
only logic for which there are rules for both 2 and ¬2¬, i.e., 3. These inference
rules can be seen to perform an ‘on-the-ﬂy’ computation of a transformation.
Note that the clauses produced by PK5 diﬀer from those produced by GMR for
K5. Implicitly, our results here also show that it should be possible to eliminate
EUC1 from the GMR calculus.
For the axiomatic translation, we only present the function P RS
L
that com-
putes the logic dependent ﬁrst-order clausal formulae that are part of the overall
translation.
P RS
KB(2ψ) = {∀x(¬Q2ψ(y) ∨¬R(x, y) ∨Qψ(x)) | 2ψ ∈sf(ϕ)}
P RS
KD(2ψ) = {∀x(¬Q2ψ(x) ∨Q¬2¬ψ(x)) | 2ψ ∈sf(ϕ)}
P RS
KT(2ψ) = {∀x(¬Q2ψ(x) ∨Qψ(x)) | 2ψ ∈sf(ϕ)}
P RS
K4 (2ψ) = {∀xy(¬Q2ψ(x) ∨¬R(x, y) ∨Q2ψ(y)) | 2ψ ∈sf(ϕ)}
P RS
K5 (2ψ) = {∀xy(¬Q2ψ(y) ∨¬R(x, y) ∨Q2ψ(x)),
∀xy(¬Q2¬2ψ(y) ∨¬R(x, y) ∨Q2¬2ψ(x)) | 2ψ ∈sf(ϕ)}
The predicate symbols Qψ correspond to our surrogate symbols tψ. The clausal
formulae used in the treatment of KT and K4 are translations of the SNFml
clauses we use (or vice versa). KB and K5 are handled in a diﬀerent way as the
ﬁrst-order clausal formulae refer directly the accessibility relation and can there-
fore more easily express the transfer of information to a predecessor world. The
universal quantiﬁcation over worlds also means that the constraints expressed
by the formulae hold at all modal levels without the need of any repetition.
In Section 6 we will also use the relational and semi-functional translation
of modal logics to ﬁrst-order logic combined with structural transformation to
clause normal form. In both approaches 2ψ is translated as ∀xy(¬Q2ψ(x) ∨
¬R(x, y)∨Qψ, while 3ψ becomes ∀x∃y(¬Q3ψ(x)∨R(x, y)) and ∀x∃α(¬Q3ψ(x)∨
R(x, [xα])) in the relational and semi-functional translation, respectively. Then,
depending on the modal logics, further formulae representing the semantic prop-
erties of the accessibility R are added. For the relational translation these will
simply be the formulae in the fourth column of Table 1. The semi-functional
translation uses collections of partial accessibility function in addition to the ac-
cessibility relation. A predicate def is used to represent on which worlds a partial

88
F. Papacchini et al.
accessibility function is deﬁned. For each modal logic there is then again a back-
ground theory consisting of formulae over def and R that represents the prop-
erties of the underlying accessibility relation which is added to the translation
of a formula. For example, for K5 the background theory is: ∀xy∀αβ((¬def(x) ∨
def(y)) ∧(¬def(w0)∨R(w0, [w0α])) ∧(¬def(x)∨¬def(y)∨R([xα], [yβ]))), where
w0 is a constant representing the root world in a rooted Kripke structure.
6
Evaluation
We have compared the performance of the following approaches: (i) the com-
bination of our reductions with the modal-layered resolution (MLR) calculus
for SNFml clauses [15] implemented in the modal theorem prover KSP, with
three diﬀerent reﬁnements for resolution inferences on labelled propositional
clauses; (ii) the global modal resolution (GMR) calculus, also implemented in
KSP, with three diﬀerent reﬁnements for resolution inferences on propositional
clauses; (iii) the combinations of the relational and semi-functional translation of
modal logics to ﬁrst-order logic with ordered ﬁrst-order resolution implemented
in the ﬁrst-order theorem prover SPASS. In total this gives us eight diﬀerent
approaches to compare. The axiomatic translation is currently not implemented
in SPASS. Other provers, such as LEO-III [26], LWB [9], MleanCoP [21], do not
have built-in support for the full range of logics considered here. LoTREC 2.0 [7]
supports all the logics, but is not intended as automatic theorem prover.
The modal-layered resolution calculus operates on SNFml clauses, that is,
clauses of the form
ml : r
b=1 lb
ml : l′ →2l
ml : l′ →3l
where ml ∈N ∪{⋆} and l, l′, lb are propositional literals with 1 ≤b ≤r,
r ∈N. In the implementation of the reductions presented in Section 3, we take
a SNFsml clause S : ψ simply as an abbreviation of the set of SNFml clauses
{ml : ψ | ml ∈S}. Note that this also means that we will have to repeat similar
resolution inferences for diﬀerent modal levels.
KSP [13] implements the reductions presented in Section 3 as well as a normal
form transformation of modal formulae to sets of SNFK clauses. It implements
both the MLR and the GMR calculus. Resolution inferences between (labelled)
propositional clauses can either be unrestricted (cplain option), restricted by
an ordering (cord option), that is, clauses can only be resolved on their maximal
literals with respect to an ordering chosen by the prover in such a way to preserve
completeness, restricted to negative resolution (cneg option), that is, one of the
premises in an inference has to be a negative clause, or restricted to positive
resolution. We do not include the last option in our evaluation as it typically
performs worse. KSP also implements a range of simpliﬁcation rules that are
applied to modal formulae before their transformation to normal form. Of those
we have enabled pure literal elimination (early ple option), simpliﬁcation using
the Box Normal Form [22] and Prenex Normal Form (bnfsimp and prenex

Eﬃcient Local Reductions to Basic Modal Logic
89
Logic Status Total
KSP
(GMR
calcu-
lus,
cneg)
KSP
(GMR
calcu-
lus,
cord)
KSP
(GMR
calcu-
lus,
cplain)
KSP
(MLR
calcu-
lus,
cneg)
KSP
(MLR
calcu-
lus,
cord)
KSP
(MLR
calcu-
lus,
cplain)
SPASS
(semi-
func-
tional)
SPASS
(rela-
tional)
K
Sat
180
110
139
93
141
155
132
92
97
K
Unsat
180
154
156
151
154
156
153
134
122
KD
Sat
180
125
143
118
141
155
133
107
103
KD
Unsat
180
154
156
151
154
156
153
136
130
KT
Sat
100
53
60
37
46
56
26
47
39
KT
Unsat
260
233
236
225
230
238
220
222
199
KB
Sat
122
28
35
41
49
89
22
31
23
KB
Unsat
238
186
196
197
207
211
205
159
169
K4
Sat
161
33
39
38
68
125
36
0
0
K4
Unsat
199
124
112
146
168
165
163
109
35
K5
Sat
60
14
10
9
7
10
4
7
0
K5
Unsat
300
251
246
259
255
254
246
255
124
All
Sat
803
363
426
336
452
590
353
284
262
All
Unsat
1357
1102
1102
1129
1168
1180
1140
1015
779
Table 5. Experimental results on LWB benchmark collection
options) [17]. For clause processing, unit resolution and pure elimination are
enabled (unit, lhs unit, and ple options).
SPASS 3.9 [27,28] supports automated reasoning in extended modal logics,
including all logics considered here, PDL-like modal logics as well as descrip-
tion logics. It includes eight diﬀerent translations of modal logics to ﬁrst-order
logic. In our evaluation we have used the relational translation and the semi-
functional translation. For the local satisﬁability problem in KB to K5, for the
relational translation we have added the ﬁrst-order frame properties given in
Table 1 while for the semi-functional translation we have added the background
theories devised by Nonnengart [20]. For the transformation to ﬁrst-order clausal
form, we have enabled renaming of quantiﬁed subformulae. The only inference
rules used are ordered resolution and ordered factoring, the reduction rules used
are condensing, backward subsumption and forward subsumption. For the rela-
tional and semi-functional translation for K, KB, KD, and KT we thereby obtain
a decision procedure, while for the other logics we do not. For K4 and K5, the
fragment of ﬁrst-order clausal logic corresponding to the semi-functional trans-
lation of modal formula and their background theories is decidable by ordered
resolution with selection [25]. However, the non-trivial ordering and selection
function required is not currently implemented in SPASS.
For our evaluation we have chosen the LWB basic modal logic benchmark
collection [2], with 20 formulae in each of 18 parameterised classes. For K, all
formulae in 9 classes are satisﬁable while all formulae in the other 9 classes are
unsatisﬁable. In their negation normal form, 63% of modal operators are 2 and

90
F. Papacchini et al.
37% are 3 operators. We have used the collection for each of the six logics. If a
formula is unsatisﬁable in K then it remains unsatisﬁable in the other ﬁve logics,
while the opposite is not true. As we move to logics other than K, it is also no
longer the case that all formulae in a class have the same satisﬁability status.
The third column in Table 5 indicates the total number of satisﬁable and
unsatisﬁable formulae for each logic. In the last two lines of the table we sum
up the results for all logics. The last eight columns in the table show how many
formulae each of the approaches were able to solve with a time limit of 100 CPU
seconds for each formula. Benchmarking was performed on a PC with an AMD
Ryzen 5 5600X CPU @ 4.60GHz max and 32GB main memory using Fedora
release 33 as operating system.
As we can see, the new reductions combined with the modal-layered reso-
lution (MLR) calculus and ordered resolution reﬁnement (cord) perform best,
achieving the highest number of solved formulae in 8 out of 12 individual cat-
egories in the table, on two of those equal with the global modal resolution
(GMR) calculus. On 3 categories, GMR outperfoms MLR. On both satisﬁable
and unsatisﬁable formulae in K5 this can be seen as evidence that ‘on-the-ﬂy’
transformation oﬀers a (slight) advantage over our approach given that the ad-
ditional clauses hold universally in both approaches. For SPASS we see a clear
advantage of the semi-functional translation over the relational one, on both
satisﬁable and unsatisﬁable formulae.
7
Conclusion and Future Work
We have presented new reductions of propositional modal logics KB, KD, KT,
K4, K5 to Separated Normal Form with Sets of Modal Levels. We have shown
experimentally that these reductions allow us to reason eﬀectively in these logics.
The obvious next step is to consider extensions of the basic modal logic K
with combinations of the axioms B, D, T, 4, and 5. Unfortunately, a simple
combination of the reductions for each of the axioms is not suﬃcient to obtain a
satisﬁability-preserving reduction for the such modal logics. An example is the
simple formula ¬p ∧332p which is KB4-unsatisﬁable. If we deﬁne
PKB4(S : t2ψ →2ψ) = PKB(S : t2ψ →2ψ) ∪PK4(S : t2ψ →2ψ)
ΔKB4(S : t2ψ →2ψ) = δKB4(⋆, ψ),
that is, PKB4 is the union of PKB and PK4, then the clause set obtained from
{{0} : t0} ∪ρKB4({0} : t0 →¬p ∧332p) is K-satisﬁable. The same issue also
occurs in the axiomatic translation of modal logics to ﬁrst-order logic where the
translation for KB4 is not simply the combination of the translations for KB and
K4 [24, Theorem 5.6]. We are currently exploring solutions to this problem.
Regarding practical applications, it would be advantageous to have an im-
plementation of a calculus that operates directly SNFsml clauses. This would
greatly reduce the number of inference steps performed on satisﬁable formulae
and simplify proof search in general. Again, such an implementation is future
work.

Eﬃcient Local Reductions to Basic Modal Logic
91
References
1. Balbiani, P., Demri, S.: Preﬁxed tableaux systems for modal logics with enriched
languages. In: IJCAI 1997. pp. 190–195. Morgan Kaufmann (1997)
2. Balsiger, P., Heuerding, A., Schwendimann, S.: A benchmark method for the propo-
sitional modal logics K, KT, S4. J. Autom. Reasoning 24(3), 297–317 (2000)
3. Basin, D., Matthews, S., Vigano, L.: Labelled propositional modal logics: Theory
and practice. J. Log. Comput. 7(6), 685–717 (1997)
4. Benzm¨uller, C., Paulson, L.C.: Multimodal and intuitionistic logics in simple type
theory. Log. J. IGPL 18(6), 881–892 (2010)
5. Fitting, M.: Preﬁxed tableaus and nested sequents. Ann. Pure Appl. Log. 163(3),
291–313 (2012)
6. Gabbay, D.M.: Decidability results in non-classical logics: Part I. Ann. Math. Log.
8, 237–295 (1975)
7. Gasquet, O., Herzig, A., Longin, D., Sahade, M.: LoTREC: Logical tableaux re-
search engineering companion. In: TABLEAUX 2005. LNCS, vol. 3702, pp. 318–
322. Springer (2005). https://doi.org/10.1007/11554554 25
8. Halpern, J.Y., Moses, Y.: A guide to completeness and complexity for modal logics
of knowledge and belief. Artif. Intell. 54(3), 319–379 (1992)
9. Heuerding, A., J¨ager, G., Schwendimann, S., Seyfried, M.: The Logics Workbench
LWB: A snapshot. Euromath Bulletin 2(1), 177–186 (1996)
10. Horrocks, I., Hustadt, U., Sattler, U., Schmidt, R.A.: Computational modal logic.
In: Blackburn, P., van Benthem, J., Wolter, F. (eds.) Handbook of Modal Logic,
chap. 4, pp. 181–245. Elsevier (2006)
11. Kracht, M.: Reducing modal consequence relations. J. Log. Comput. 11(6), 879–
907 (2001)
12. Kracht, M.: Notes on the space requirements for checking satisﬁability in modal
logics. In: Advances in Modal Logic 4, pp. 243–264. King’s College Publications
(2003)
13. Nalon, C.: KSP (2021), https://cic.unb.br/∼nalon/#software
14. Nalon, C., Dixon, C.: Clausal resolution for normal modal logics. J. Algorithms
62, 117–134 (2007)
15. Nalon, C., Dixon, C., Hustadt, U.: Modal resolution: Proofs, layers, and reﬁne-
ments. ACM Trans. Comput. Log. 20(4), 23:1–23:38 (2019)
16. Nalon, C., Hustadt, U., Dixon, C.: A modal-layered resolution calculus for K. In:
TABLEAUX 2015. LNCS, vol. 9323, pp. 185–200. Springer, Heidelberg (2015).
https://doi.org/10.1007/978-3-319-24312-2 13
17. Nalon, C., Hustadt, U., Dixon, C.: KSP: A resolution-based prover for multimodal
K. In: IJCAR 2016. LNCS, vol. 9706, pp. 406–415. Springer, Heidelberg (2016).
https://doi.org/10.1007/978-3-319-40229-1 28
18. Nalon, C., Hustadt, U., Dixon, C.: KSP: Architecture, reﬁnements, strategies and
experiments. J. Autom. Reason. 64(3), 461–484 (2020)
19. Nguyen, L.A., Szalas, A.: Exptime tableau decision procedures for regular grammar
logics with converse. Studia Logica 98(3), 387–428 (2011)
20. Ohlbach, H.J., Nonnengart, A., de Rijke, M., Gabbay, D.M.: Encoding two-valued
nonclassical logics in classical logic. In: Robinson, A., Voronkov, A. (eds.) Hand-
book of Automated Reasoning, chap. 21, pp. 1403–1485. Elsevier (2001)
21. Otten, J.: MleanCoP: A connection prover for ﬁrst-order modal logic. In: IJCAR
2014. LNCS, vol. 8562, pp. 269–276. Springer (2014). https://doi.org/10.1007/978-
3-319-08587-6 20

92
F. Papacchini et al.
22. Pan, G., Sattler, U., Vardi, M.Y.: BDD-based decision procedures for the modal
logic K. J. Appl. Non-Class. Log. 16(1-2), 169–208 (2006)
23. Schmidt, R.A.: Decidability by resolution for propositional modal logics. J. Autom.
Reasoning 22(4), 379–396 (1999)
24. Schmidt, R.A., Hustadt, U.: The axiomatic translation principle for modal logic.
ACM Trans. Comput. Log. 8(4), 19 (2007)
25. Schmidt, R.A., Hustadt, U.: First-order resolution methods for modal logics. In:
Programming Logics: Essays in Memory of Harald Ganzinger. LNCS, vol. 7797,
pp. 345–391. Springer (2013). https://doi.org/10.1007/978-3-642-37651-1 15
26. Steen, A., Benzm¨uller, C.: The higher-order prover Leo-III. In: ECAI 2020. Fron-
tiers in Artiﬁcial Intelligence and Applications, vol. 325, pp. 2937–2938. IOS Press
(2020). https://doi.org/10.3233/FAIA200462
27. The SPASS Team: Spass 3.9 (2016), http://www.spass-prover.org/
28. Weidenbach, C.: Combining superposition, sorts and splitting. In: Robinson, J.A.,
Voronkov, A. (eds.) Handbook of Automated Reasoning, pp. 1965–2013. Elsevier
and MIT Press (2001)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Isabelle’s Metalogic:
Formalization and Proof Checker⋆
Technical University of Munich, Munich, Germany
Abstract. Isabelle is a generic theorem prover with a fragment of higher-
order logic as a metalogic for deﬁning object logics. Isabelle also provides
proof terms. We formalize this metalogic and the language of proof terms
in Isabelle/HOL, deﬁne an executable (but ineﬃcient) proof term checker
and prove its correctness w.r.t. the metalogic. We integrate the proof
checker with Isabelle and run it on a range of logics and theories to
check the correctness of all the proofs in those theories.
1
Introduction
One of the selling points of proof assistants is their trustworthiness. Yet in prac-
tice soundness problems do come up in most proof assistants. Harrison [11]
distinguishes errors in the logic and errors in the implementation (and cites ex-
amples). Our work contributes to the solution of both problems for the proof
assistant Isabelle [31]. Isabelle is a generic theorem prover: it implements M, a
fragment of intuitionistic higher-order logic, as a metalogic for deﬁning object
logics. Its most developed object logic is HOL and the resulting proof assistant
is called Isabelle/HOL [25,24]. The latter is the basis for our formalizations.
Our ﬁrst contribution is the ﬁrst complete formalization of Isabelle’s meta-
logic. Thus our work applies to all Isabelle object logics, e.g. not just HOL but
also ZF. Of course Paulson [30] describes M precisely, but only on paper. More
importantly, his description does not cover polymorphism and type classes, which
were introduced later [26]. The published account of Isabelle’s proof terms [4] is
also silent about type classes. Yet type classes are a signiﬁcant complication (as,
for example, Kunˇcar and Popescu [18] found out).
Our second contribution is a veriﬁed (against M) and executable checker for
Isabelle’s proof terms. We have integrated the proof checker with Isabelle. Thus
we can guarantee that every theorem whose proof our proof checker accepts is
provable in our deﬁnition of M. So far we are able to check the correctness of
moderatly sized theories across the full range of logics implemented in Isabelle.
Although Isabelle follows the LCF-architecture (theorems that can only be
manufactured by inference rules) it is based on an infrastructure optimized for
⋆Supported by Wirtschaftsministerium Bayern under DIK-2002-0027//DIK0185/03
and DFG GRK 2428 ConVeY
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5_6
Tobias Nipkow
and Simon Roßkopf
93–110, 2021.

94
T. Nipkow and S. Roßkopf
performance. In particular, this includes multithreading, which is used in the ker-
nel and has once lead to a soundness issue1 . Therefore we opt for the “certiﬁcate
checking” approach (via proof terms) instead of verifying the implementation.
This is the ﬁrst work that deals directly with what is implemented in Isabelle
as opposed to a study of the metalogic that Isabelle is meant to implement. In-
stead of reading the implementation you can now read and build on the more
abstract formalization in this paper. The correspondence of the two can be es-
tablished for each proof by running the proof checker.
Our formalization reﬂects the ML implementation of Isabelle’s terms and
types and some other data structures. Thus a few implementation choices are
visible, e.g. De Bruijn indices. This is necessary because we want to integrate
our proof checker as directly as possible with Isabelle, with as little unveriﬁed
glue code as possible, for example no translation between De Bruijn indices and
named variables. We refer to this as our intentional implementation bias. In prin-
ciple, however, one could extend our formalization with diﬀerent representations
(e.g. named terms) and prove suitable isomorphisms. Our work is purely proof
theoretic; semantics is out of scope.
The formalization can be found in the Archive of Formal Proofs[28].
2
Related Work
Harrison [11] was the ﬁrst to verify some of HOL’s metatheory and an imple-
mentation of a HOL kernel in HOL itself. Kumar et al. [13] formalized HOL
including deﬁnition principles, proved its soundness and synthesized a veriﬁed
kernel of a HOL prover down to the machine language level. Abrahamsson [2]
veriﬁed a proof checker for the OpenTheory [12] proof exchange format for HOL.
Wenzel [38] showed how to interpret type classes as predicates on types. We
follow his approach of reﬂecting type classes in the logic but cannot remove them
completely because of our intentional implementation bias (see above). Kunˇcar
and Popescu [15,16,17,18] focus on the subtleties of deﬁnition principles for HOL
with overloading and prove that under certain conditions, type and constant
deﬁnitions preserve consistency. ˚Aman Pohjola et al. [1] formalize [15,18].
Adams [3] presents HOL Zero, a basic theorem prover for HOL that addresses
the problem of how to ensure that parser and pretty-printer do not misrepresent
formulas.
Let us now move away from Isabelle and HOL. Sozeau et al. [36] present the
ﬁrst implementation of a type checker for the kernel of Coq that is proved correct
in Coq with respect to a formal speciﬁcation. Carneiro [6] has implemented a
highly performant proof checker for a multi-sorted ﬁrst order logic and is in the
process of verifying it in its own logic.
We formalize a logic with bound variables, and there is a large body of related
work that deals with this issue (e.g. [37,21,7]) and a range of logics and systems
with special support for handling bound variables (e.g. [33,34,35]). We found
that De Bruijn indices worked reasonably well for us.
1 https://mailmanbroy.in.tum.de/pipermail/isabelle-dev/2016-December/007251.html

Isabelle’s Metalogic: Formalization and Proof Checker
95
3
Preliminaries
Isabelle types are built from type variables, e.g. ′a, and (postﬁx) type construc-
tors, e.g. ′a list; the function type arrow is ⇒. Isabelle also has a type class
system explained later. The notation t :: τ means that term t has type τ. Isa-
belle/HOL provides types ′a set and ′a list of sets and lists of elements of type
′a. They come with the following vocabulary: function set (conversion from lists
to sets), (#) (list constructor), (@) (append), |xs| (length of list xs), xs ! i (the
ith element of xs starting at 0), list-all2 p [x 1, . . ., x m] [y1, . . ., yn] = (m = n
∧p x 1 y1 ∧. . . ∧p x n yn) and other self-explanatory notation.
The Field of a relation r is the set of all x such that (x, ) or ( ,x) is in r.
There is also the predeﬁned data type
datatype ′a option = None | Some
′a
The type τ 1 ⇀τ 2 abbreviates τ 1 ⇒τ 2 option, i.e. partial functions, which we
call maps. Maps have a domain and a range:
dom m = {a | m a ̸= None}
ran m = {b | ∃a. m a = Some b}.
Logical equivalence is written = instead of ←→.
4
Types and Terms
A name is simply a string. Variables have type var; their inner structure is
immaterial for the presentation of the logic.
The logic has three layers: terms are classiﬁed by types as usual, but in
addition types are classiﬁed by sorts. A sort is simply a set of class names. We
discuss sorts in detail later.
Types (typically denoted by T, U, . . . ) are deﬁned like this:
datatype typ = Ty name (typ list) | Tv var sort
where Ty κ [T 1,...,T n] represents the Isabelle type (T 1,. . .,T n) κ and Tv a S
represents a type variable a of sort S — sorts are directly attached to type
variables. The notation T →U is short for Ty ”fun” [T,U ], where ”fun” is the
name of the function type constructor.
Isabelle’s terms are simply typed lambda terms in De Bruijn notation:
datatype term = Ct name typ | Fv var typ | Bv nat | Abs typ term | (·) term term
A term (typically r, s, t, u . . . ) can be a typed constant Ct c T or free variable
Fv v T, a bound variable Bv n (a De Brujin index), a typed abstraction Abs T t
or an application t · u.
The term-has-type proposition has the syntax Ts ⊢τ t : T where Ts is a list
of types, the context for the type of the bound variables.
⊢τ Ct
T : T
⊢τ Fv
T : T
i < |Ts|
Ts ⊢τ Bv i : Ts ! i

96
T. Nipkow and S. Roßkopf
T # Ts ⊢τ t : T ′
Ts ⊢τ Abs T t : T →T ′
Ts ⊢τ u : U
Ts ⊢τ t : U →T
Ts ⊢τ t · u : T
We deﬁne ⊢τ t : T = [] ⊢τ t : T.
Function fv :: term ⇒(var × typ) set collects the free variables in a term.
Because bound variables are indices, fv t is simply the set of all (v, T) such that
Fv v T occurs in t. The type is an integral part of a variable.
A type substitution is a function ϱ of type var ⇒sort ⇒typ. It assigns a type
to each type variable and sort pair. We write ϱ $$ T or ϱ $$ t for the overloaded
function which applies such a type substitution to all type variables (and their
sort) occurring in a type or term. The type instance relation is deﬁned like this:
T 1 ≲T 2 = (∃ϱ. ϱ $$ T 2 = T 1)
We also need to β-contract a term Abs T t · u to something like “t with
Bv 0 replaced by u”. We deﬁne a function subst-bv such that subst-bv u t is
that β-contractum. The deﬁnition of subst-bv is shown in the Appendix and can
also be found in the literature (e.g. [23]).
In order to abstract over a free (term) variable there is a function bind-fv (v,
T) t that (roughly speaking) replaces all occurrences of Fv v T in t by Bv 0.
Again, see the Appendix for the deﬁnition. This produces (if Fv v T occurs in
t) a term with an unbound Bv 0. Function Abs-fv binds it with an abstraction:
Abs-fv v T t = Abs T (bind-fv (v, T) t)
While this section described the syntax of types and terms, they are not
necessarily wellformed and should be considered pretypes/preterms. The well-
formedness checks are described later.
5
Classes and Sorts
Isabelle has a built-in system of type classes [22] as in Haskell 98 except that
class constraints are directly attached to variable names: our Tv a [C,D,. . .]
corresponds to Haskell’s (C a, D a, ...) => ... a ....
A sort is Isabelle’s terminology for a set of (class) names, e.g. {C,D,. . .},
which represent a conjunction of class constraints. In our work, variables S, S ′
etc. stand for sorts.
Apart from the usual application in object logics, type classes also serve an
important metalogical purpose: they allow us to restrict, for example, quantiﬁ-
cation in object logics to object-level types and rule out meta-level propositions.
Isabelle’s type class system was ﬁrst presented in a programming language
context [29,27]. We give the ﬁrst machine-checked formalization. The central
data structure is a so-called order-sorted signature. Intuitively, it is comprised
of a set of class names, a partial subclass ordering on them and a set of type
constructor signatures. A type constructor signature κ :: (S 1, . . ., S k) c for a

Isabelle’s Metalogic: Formalization and Proof Checker
97
type constructor κ states that applying κ to types T 1, . . ., T k such that T i has
sort S i (deﬁned below) produces a type of class c. Formally:
type synonym osig = ((name × name) set × (name ⇀(class ⇀sort list)))
To explain this formalization we start from a pair (sub,tcs) :: osig and recover
the informal order-sorted signature described above. The set of classes is simply
the Field of the sub relation. The tcs component represents the set of all type
constructor signatures κ :: (Ss) c (where Ss is a list of sorts) such that tcs κ =
Some dm and dm c = Some Ss. Representing κ :: (Ss) c as a triple, we deﬁne
TCS = {(κ, Ss, c) | ∃domf . tcs κ = Some domf ∧domf c = Some Ss}
TCS is the translation of tcs, the data structure close to the implementation,
to an equivalent but more intuitive version TCS that is close to the informal
presentations in the literature.
The subclass ordering sub can be extended to a subsort ordering as follows:
S 1 ≤sub S 2 = (∀c2∈S 2. ∃c1∈S 1. c1 ≤sub c2)
The smaller sort needs to subsume all the classes in the larger sort. In particular
{c1} ≤sub {c2} iﬀ(c1, c2) ∈sub.
Now we can deﬁne a predicate has-sort that checks whether, in the context
of some order-sorted signature (sub,tcs), a type fulﬁlls a given sort constraint:
S ≤sub S ′
has-sort (sub, tcs) (Tv a S) S ′
tcs κ = Some dm
∀c∈S. ∃Ss. dm c = Some Ss ∧list-all2 (has-sort (sub, tcs)) Ts Ss
has-sort (sub, tcs) (Ty κ Ts) S
The rule for type variables uses the subsort relation and is obvious. A type (T 1,
. . ., T n) κ has sort {c1, . . .} if for every ci there is a signature κ :: (S 1, . . ., S n)
ci and has-sort (sub, tcs) T j S j for j = 1, . . ., n.
We normalize a sort by removing “superﬂuous” class constraints, i.e. retain-
ing only those classes that are not subsumed by other classes. This gives us
unique representatives for sorts which we call normalized:
normalize-sort sub S = {c ∈S | ¬ (∃c ′∈S. (c ′, c) ∈sub ∧(c, c ′) /∈sub)}
normalized-sort sub S = (normalize-sort sub S = S)
We work with normalized sorts because it simpliﬁes the derivation of eﬃcient
executable code later on.
Now we can deﬁne wellformedness of an osig:
wf-osig (sub, tcs) = (wf-subclass sub ∧wf-tcsigs sub tcs)
A sublass relation is wellformed if it is a partial order where reﬂexivity is re-
stricted to its Field. Wellformedness of type constructor signatures (wf-tcsigs) is
more complex. We describe it in terms of TCS derived from tcs (see above). The
conditions are the following:

98
T. Nipkow and S. Roßkopf
– The following property requires a) that for any κ :: (...)c1 there must be a
κ :: (...)c2 for every superclass c2 of c1 and b) coregularity which guarantees
the existence of principal types [29,10].
∀(κ, Ss1, c1)∈TCS.
∀c2. (c1, c2) ∈sub −→
(∃Ss2. (κ, Ss2, c2) ∈TCS ∧list-all2 (λS 1 S 2. S 1 ≤sub S 2) Ss1 Ss2)
– A type constructor must always take the same number of argument types:
∀κ Ss1 c1 Ss2 c2.
(κ, Ss1, c1) ∈TCS ∧(κ, Ss2, c2) ∈TCS −→|Ss1| = |Ss2|
– Sorts must be normalized and must exists in sub:
∀(κ, Ss, c)∈TCS. ∀S∈set Ss. wf-sort sub S
where wf-sort sub S = (normalized-sort sub S ∧S ⊆Field sub)
These conditions are used in a number of places to show that the type system
is well behaved. For example, has-sort is upward closed:
wf-osig (sub, tcs) ∧has-sort (sub, tcs) T S ∧S ≤sub S ′
−→has-sort (sub, tcs) T S ′
6
Signatures
A signature consist of a map from constant names to their (most general) types, a
map from type constructor names to their arities, and an order-sorted signature:
type synonym signature = (name ⇀typ) × (name ⇀nat) × osig
The three projection functions are called const-type, type-arity and osig. We now
deﬁne a number of wellformedness checks w.r.t. a signature Σ. We start with
wellformedness of types, which is pretty obvious:
type-arity Σ κ = Some |Ts|
∀T∈set Ts. wf-type Σ T
wf-type Σ (Ty κ Ts)
wf-sort (subclass (osig Σ)) S
wf-type Σ (Tv a S)
Wellformedness of a term essentially just says that all types in the term are
wellformed and that the type T ′ of a constant in the term must be an instance
of the type T of that constant in the signature: T ′ ≲T.
wf-type Σ T
wf-term Σ (Fv v T)
wf-term Σ (Bv n)
const-type Σ s = Some T
wf-type Σ T ′
T ′ ≲T
wf-term Σ (Ct s T ′)
wf-term Σ t
wf-term Σ u
wf-term Σ (t · u)
wf-type Σ T
wf-term Σ t
wf-term Σ (Abs T t)

Isabelle’s Metalogic: Formalization and Proof Checker
99
These rules only check whether a term conforms to a signature, not that the
contained types are consistent. Combining wellformedness and ⊢τ yields well-
typedness of a term:
wt-term Σ t = (wf-term Σ t ∧(∃T. ⊢τ t : T))
Wellformedness of a signature Σ = (ctf , arf , oss) where oss = (sub, tcs) is
deﬁned as follows:
wf-sig Σ =
((∀T∈ran ctf . wf-type Σ T) ∧wf-osig oss ∧dom tcs = dom arf ∧
(∀κ dm. tcs κ = Some dm −→(∀Ss∈ran dm. arf κ = Some |Ss|)))
In words: all types in ctf are wellformed, oss is wellformed, the type constructors
in tcs are exactly those that have an arity in arf, for every type constructor
signature (κ, Ss, ) in tcs, κ has arity |Ss|.
7
Logic
Isabelle’s metalogic M is an extension of the logic described by Paulson [30]. It
is a fragment of intuitionistic higher-order logic. The basic types and connectives
of M are the following:
Concept
Representation
Abbreviation
Type of propositions Ty ”prop” []
prop
Implication
Ct ”imp” (prop →prop →prop)
=⇒
Universal quantiﬁer Ct ”all” ((T →prop) →prop)

T
Equality
Ct ”eq” (T →T →prop)
≡T
The type subscripts of  and ≡are dropped in the text if they can be inferred.
Readers familiar with Isabelle syntax must keep in mind that for readability
we use the symbols , =⇒and ≡for the encodings of the respective symbols
in Isabelle’s metalogic. We avoid the corresponding metalogical constants com-
pletely in favour of HOL’s ∀, −→, = and inference rule notation.
The provability judgment of M is of the form Θ,Γ ⊢t where Θ is a theory,
Γ (the hypotheses) is a set of terms of type prop and t a term of type prop.
A theory is a pair of a signature and a set of axioms:
type synonym theory = signature × term set
The projection functions are sig and axioms. We extend the notion of wellformed-
ness from signatures to theories:
wf-theory (Σ, axs) =
(wf-sig Σ ∧(∀p∈axs. wt-term Σ p ∧⊢τ p : prop) ∧is-std-sig Σ ∧eq-axs ⊆axs)
The ﬁrst two conjuncts need no explanation. Predicate is-std-sig (not shown)
requires the signature to have certain minimal content: the basic types (→, prop)
and constants (≡, , =⇒) of M and the additional types and constants for type

100
T. Nipkow and S. Roßkopf
class reasoning from Section 7.3. Our theories also need to contain a minimal set
of axioms. The set eq-axs is an axiomatic basis for equality reasoning and will
be explained in Section 7.2.
We will now discuss the inference system in three steps: the basic inference
rules, equality and type class reasoning.
7.1
Basic Inference Rules
The axiom rule states that wellformed type-instances of axioms are provable:
wf-theory Θ
t ∈axioms Θ
wf-inst Θ ϱ
Θ,Γ ⊢ϱ $$ t
where ϱ :: var ⇒sort ⇒typ is a type substitution and $$ denotes its applica-
tion (see Section 4). The types substituted into the type variables need to be
wellformed and conform to the sort constraint of the type variable:
wf-inst (Σ, axs) ϱ =
(∀v S. ϱ v S ̸= Tv v S −→has-sort (osig Σ) (ϱ v S) S ∧wf-type Σ (ϱ v S))
The conjunction only needs to hold if ϱ actually changes something, i.e. if ϱ v S
̸= Tv v S. This condition is not superﬂuous because otherwise has-sort oss (Tv
v S) S and wf-type Σ (Tv v S) only hold if S is wellformed w.r.t Σ.
Note that there are no extra rules for general instantiation of type or term
variables. Type variables can only be instantiated in the axioms. Term instanti-
ation can be performed using the forall introduction and elimination rules.
The assumption rule allows us to prove terms already in the hypotheses:
wf-term (sig Θ) t
⊢τ t : prop
t ∈Γ
Θ,Γ ⊢t
Both  and =⇒are characterized by introduction and elimination rules:
wf-theory Θ
Θ,Γ ⊢t
(x, T) /∈FV Γ
wf-type (sig Θ) T
Θ,Γ ⊢

T (Abs-fv x T t)
Θ,Γ ⊢

T (Abs T t)
⊢τ u : T
wf-term (sig Θ) u
Θ,Γ ⊢subst-bv u t
wf-theory Θ
Θ,Γ ⊢u
wf-term (sig Θ) t
⊢τ t : prop
Θ,Γ −{t} ⊢t =⇒u
Θ,Γ 1 ⊢t =⇒u
Θ,Γ 2 ⊢t
Θ,Γ 1 ∪Γ 2 ⊢u
where FV Γ = (
t∈Γ fv t).

Isabelle’s Metalogic: Formalization and Proof Checker
101
7.2
Equality
Most rules about equality are not part of the inference system but are axioms
(the set eq-axs mentioned above). Consequences are obtained via the axiom rule.
The ﬁrst three axioms express that ≡is reﬂexive, symmetric and transitive:
x ≡x
x ≡y =⇒y ≡x
x ≡y =⇒y ≡z =⇒x ≡z
The next two axioms express that terms of type prop (A and B) are equal iﬀ
they are logically equivalent:
A ≡B =⇒A =⇒B
(A =⇒B) =⇒(B =⇒A) =⇒A ≡B
The last equality axioms are congruence rules for application and abstraction:
f ≡g =⇒x ≡y =⇒(f · x) ≡(g · y)
 (Abs T ((f · Bv 0) ≡(g · Bv 0))) =⇒Abs T (f · Bv 0) ≡Abs T (g · Bv 0)
Paulson [30] gives a slightly diﬀerent congruence rule for abstraction, which
allows to abstract over an arbitrary, free x in f ,g. We are able to derive this rule
in our inference system.
Finally there are the lambda calculus rules. There is no need for α conversion
because α-equivalent terms are already identical thanks to the De Brujin indices
for bound variables. For β and η conversion the following rules are added. In
contrast to the rest of this subsection, these are not expressed as axioms.
wf-theory Θ
wt-term (sig Θ) (Abs T t)
wf-term (sig Θ) u
⊢τ u : T
Θ,Γ ⊢(Abs T t · u) ≡subst-bv u t
(β)
wf-theory Θ
wf-term (sig Θ) t
⊢τ t : T →T ′
Θ,Γ ⊢Abs T (t · Bv 0) ≡t
(η)
Rule (β) uses the substitution function subst-bv as explained in Section 4 (and
deﬁned in the Appendix).
Rule (η) requires a few words of explanation. We do not explicitly require
that t does not contain Bv 0. This is already a consequence of the precondition
that ⊢τ t : T →T ′: it implies that t is closed. For that reason it is perfectly
unproblematic to remove the abstraction above t.
7.3
Type Class Reasoning
Wenzel [38] encoded class constraints of the form “type T has class c” in the
term language as follows. There is a unary type constructor named ”itself” and
T itself abbreviates Ty ”itself” [T]. The notation TYPET itself is short for
Ct ”type” (T itself ) where ”type” is the name of a new uninterpreted constant.
You should view TYPET itself as the term-level representation of type T.
Next we represent the predicate “is of class c” on the term level. For this we
deﬁne some ﬁxed injective mapping const-of-class from class to constant names.

102
T. Nipkow and S. Roßkopf
For each new class c a new constant const-of-class c of type T itself →prop is
added. The term Ct (const-of-class c) (T itself →prop) · TYPET itself represents
the statement “type T has class c”. This is the inference rule deriving such
propositions:
wf-theory Θ
const-type (sig Θ) (const-of-class C) = Some ( ′a itself →prop)
wf-type (sig Θ) T
has-sort (osig (sig Θ)) T {C}
Θ,Γ ⊢Ct (const-of-class C) (T itself →prop) · TYPET itself
This is how the has-sort inference system is integrated into the logic.
This concludes the presentation of M. We have shown some minimal sanity
properties, incl. that all provable terms are of type prop and wellformed:
Theorem 1. Θ,Γ ⊢t −→⊢τ t : prop ∧wf-term (sig Θ) t
The attentive reader will have noticed that we do not require unused hy-
potheses in Γ to be wellformed and of type prop. Similarly, we only require
wf-theory Θ in rules that need it to preserve wellformedness of the terms and
types involved. To restrict to wellformed theories and hypotheses we deﬁne a
top-level provability judgment that requires wellformedness:
Θ,Γ ⊢⊢t = (wf-theory Θ ∧(∀h∈Γ. wf-term (sig Θ) h ∧⊢τ h : prop) ∧Θ,Γ ⊢t)
8
Proof Terms and Checker
Berghofer and Nipkow [4] added proof terms to Isabelle. We present an ex-
ecutable checker for these proof terms that is proved sound w.r.t. the above
formalization of the metalogic. Berghofer and Nipkow also developed a proof
checker but it was unveriﬁed and checked the generated proof terms by feeding
them back through Isabelle’s unveriﬁed inference kernel.
It is crucial to realize that all we need to know about the proof term checker
is the soundness theorem below. The internals are, from a soundness perspective,
irrelevant, which is why we can get away with sketching them informally. This
is in contrast to the logic itself, which acts like a speciﬁcation, which is why we
presented it in detail.
This is our data type of proof terms:
datatype proofterm = PAxm term (((var × sort) × typ) list) | PBound nat
| Abst typ proofterm | AbsP term proofterm | Appt proofterm term
| AppP proofterm proofterm | OfClass typ name | Hyp term
These proof terms are not designed to record proofs in our inference system, but
to mirror the proof terms generated by Isabelle. Nevertheless, the constructors
of our proof terms correspond roughly to the rules of the inference system. PAxm
contains an axiom and a type substitution. This substitution is encoded as an
association list instead of a function. AbsP and Abst correspond to introduction

Isabelle’s Metalogic: Formalization and Proof Checker
103
of =⇒and , AppP and Appt correspond to the respective eliminations. Hyp
and PBound relate to the assumption rule, where Hyp refers to a free assumption
while PBound contains a De Brujin index referring to an assumption added
during the proof by an AbsP constructor. OfClass denotes a proof that a type
belongs to a given type class.
Isabelle looks at terms modulo αβη-equivalence and therefore does not save
β or η steps, while they are explicit steps in our inference system. Therefore
we have no constructors corresponding to the (β) and (η) rules. The remaining
equality axioms are naturally handled by the PAxm constructor.
In the rest of the section we discuss how to derive an executable proof checker.
Executability means that the checker is deﬁned as a set of recursive functions that
Isabelle’s code generator can translate into one of a number of target languages,
in particular its implementation language SML [5,9,8].
Because of the approximate correspondence between proof term constructors
and inference rules, implementing the proof checker largely amounts to providing
executable versions of each inference rule, as in LCF: each rule becomes a func-
tion that checks the side conditions, and if they are true, computes the conclusion
from the premises given as arguments. The overall checker is a function
replay :: theory ⇒proofterm ⇒term option
In particular we need to make the inductive wellformedness checks for sorts, types
and terms, signatures and theories executable. Mostly, this amounts to providing
recursive versions of inductive deﬁnitions and proving them equivalent.
We now discuss some of the more diﬃcult implementation steps. To model
Isabelle’s view of terms modulo αβη-equivalence, we βη normalize our terms (α-
equivalence is for free thanks to De Brujin notation) during the reconstruction
of the proof. A lengthy proof shows that this preserves provability (we do not
go into the details):
wf-theory Θ ∧ﬁnite Γ ∧(∀A∈Γ. wt-term (sig Θ) A ∧⊢τ A : prop) ∧Θ,Γ ⊢t ∧
beta-eta-norm t = Some u −→Θ,Γ ⊢u
Isabelle’s code generator needs some help handling the maps used in the (order-
sorted) signatures. We provide a reﬁnement of maps to association lists. Another
problematic point is the deﬁnition of the type instance relation (≲), which con-
tains an (unbounded) existential quantiﬁer. To make this executable, we provide
an implementation which tries to compute a suitable type substitution. In an-
other step, we reﬁne the type substitution to an association list as well.
In the end we obtain a proof checker
check-proof Θ P p = (wf-theory Θ ∧replay Θ P = Some p)
that checks theory Θ and checks if proof P proves the given proposition p. The
latter check is important because the Isabelle theorems that we check contain
both a proof and a proposition that the theorem claims to prove. Function check-
proof checks this claim. As one of our main results, we can prove the correctness
of our checker:

104
T. Nipkow and S. Roßkopf
Theorem 2. check-proof Θ P p −→Θ,set (hyps P) ⊢⊢p
The proof itself is conceptually simple and proceeds by induction over the struc-
ture of proof terms. For each proof constructor we need to show that the corre-
sponding inference rule leads to the same conclusion as its functional version used
by replay. Most of the proof eﬀort goes into a large library of results about terms,
types, signatures, substitutions, wellformedness etc. required for the proof, most
importantly the fact that βη normalization preserve provability.
9
Size and Structure of the Formalization
All material presented so far has been formalized in Isabelle/HOL. The deﬁnition
of the inference system (incl. types, terms etc.) resides in a separate theory Core
that depends only on the basic library of Isabelle/HOL. It takes about 300 LOC
and is fairly high level and readable – we presented most of it. This is at least an
order or magnitude smaller than Isabelle’s inference kernel (which is not clearly
delineated) – of course the latter is optimized for performance. Its abstract type
of theorems alone takes about 2,500 LOC, not counting any infrastructure of
terms, types, uniﬁcation etc.
The whole formalization consists of 10,000 LOC. The main components are:
– Almost half the formalization (4,700 LOC) is devoted to providing a library
of operations on types and terms and their properties. This includes, among
others, executable functions for type checking, diﬀerent types of substitu-
tions, abstractions, the wellformedness checks and β and η reductions.
– Proving derived rules of our inference system takes up 3,000 LOC. A large
part of this is deriving rules for equality and the β and η reductions. Weak-
ening rules are also derived.
– Making the wellformedness checks for (order-sorted) signatures and theories
as well as the type instance checks executable takes 1,800 LOC.
– Deﬁnition and correctness proof for the checker builds on the above material
and take only about 500 additional LOC.
10
Integration with Isabelle
As explained above, Isabelle generates SML code for the proof checker. This
code has its own deﬁnitions of types, terms etc. and needs to be interfaced with
the corresponding data structures in Isabelle. This step requires 150 lines of
handwritten SML code (glue code) that translates Isabelle’s data structures into
the corresponding data structures in the generated proof checker such that we
can feed them into check-proof. We cannot verify this code and therefore aim
to keep it as small and simple as possible. This is the reason for the previously
mentioned intentional implementation bias we introduced in our formalization.
We describe now how the various data types are translated. We call a translation
trivial if it merely replaces one constructor by another, possibly forgetting some
information.

Isabelle’s Metalogic: Formalization and Proof Checker
105
The translation of types and terms is trivial as their structure is almost
identical in the two settings. For Isabelle code experts it should be mentioned
that the two term constructors Free and Var in Isabelle (which both represent
free variables but Var can be instantiated by uniﬁcation) are combined in type
var of the formalization which we left unspeciﬁed but which in fact looks like
this: datatype var = Free name | Var indexname. This is purely to trivialize
the glue code, in our formalization var is totally opaque.
Proof term translation is trivial except for two special cases. Previously
proved lemmas become axioms in the translation (see also below) and so-called
“oracles” (typically the result of unﬁnished proofs, i.e. “sorry” on the user level)
are rejected (but none of the theories we checked contain oracles). Also remem-
ber that the translation of proofs is not safety critical because all that matters
is that in the end we obtain a correct proof of the claimed proposition.
We also provide functions to translate relevant content from the background
theory: axioms and (order-sorted) signatures. This mostly amounts to extracting
association lists from eﬃcient internal data structures. Translating the axioms
also involves translating some alternative internal representation of type class
constraints into their standard form presented in Sect. 7.3.
The checker is integrated into Isabelle by calling it every time a new named
theorem has been proved. The set of theorems proved so far is added to the ax-
iomatic basis for this check. Cyclic dependencies between lemmas are ruled out
by this ordering because every theorem is checked before being added to the ax-
iomatic basis. However, an explicit cyclicity check is not part of the formalization
(yet), which speaks only about checking single proofs.
11
Running the Proof Checker
We run this modiﬁed Isabelle with our proof checker on multiple theories in
various object logics contained in the Isabelle distribution. A rough overview
of the scope of the covered material for some logics and the required running
times can be found in the following table. The running times are the total times
for running Isabelle, not just the proof checking, but the latter takes 90% of
the time. All tests were performed on a Intel Core i7-9750H CPU running at
2.60GHz and 32GB of RAM.
Logic
LOC
Time
FOL
4,500
45 secs
ZF
55,000
25 mins
HOL
10,000
26 mins
We can check the material in several smaller object logics in their entirety.
One of the larger such logics is ﬁrst-order logic (FOL). These logics do not de-
velop any applications but FOL comes with proof automation and theories test-
ing that automation, in particular Pelletier’s collection of problems that were
considered challenges in their day [32]. Because the proofs are found automat-
ically, the resulting proof terms will typically be quite complex and good test
material for a proof checker.

106
T. Nipkow and S. Roßkopf
The logic ZF (Zermelo-Fraenkel set theory) builds on FOL but contains real
applications and is an order of magnitude larger than FOL. We are able to check
all material formalized in ZF in the Isabelle distribution.
Isabelle’s most frequently used and largest object logic is HOL. We managed
to check about 12% of the Main library. This includes the basic logic and the
libraries of sets, functions, orderings, lattices and groups. The formalizations are
non-trivial and make heavy use of Isabelle’s type classes.
Why can we check about ﬁve times as many lines of code in ZF compared to
HOL? Proﬁling revealed that the proof checker spends a lot of time in functions
that access the signature, especially the wellformedness checks. The primary rea-
sons: ineﬃcient data structures (e.g. association lists) and thus the running time
depends heavily on size of signature and increases with every new constant, type
and class. To make matters worse, there is no sharing of any kind in terms/types
and their wellformedness checks. Because ZF is free of polymorphism and type
classes, these wellformedness checks are much simpler.
12
Trust Assumptions
We need to trust the following components outside of the formalization:
– The veriﬁcation (and code generation) of our proof checker in Isabelle/HOL.
This is inevitable, one has to trust some theorem prover to start with. We
could improve the trustworthiness of this step by porting our proofs to the
veriﬁed HOL prover by Kumar et el. [13] but its code generator produces
CakeML [14], not SML.
– The unveriﬁed glue code in the integration of our proof checker into Isabelle
(Sect. 10).
Because users currently cannot examine Isabelle’s internal data structures
that we start from, they have to trust Isabelle’s front end that parses and trans-
forms some textual input ﬁle into internal data structures. One could add a
(possibly veriﬁed) presentation layer that outputs those internal representations
into a readable format that can be inspected, while avoiding the traps Adams
[3] is concerned with.
13
Future Work
Our primary focus will be on scaling up the proof checker to not just deal with all
of HOL but with real applications (including itself!). There is a host of avenues
for exploration. Just to name a few promising directions: more eﬃcient data
structures than association lists (e.g. via existing frameworks [19,20]); caching
of wellformedness checks for types and terms; exploiting sharing within terms
and types (tricky because our intentionally simple glue code creates copies);
working with the compressed proof terms [5] that Isabelle creates by default
instead of uncompressing them as we do now.

Isabelle’s Metalogic: Formalization and Proof Checker
107
We will also upgrade the formalization of our checker from individual the-
orems sets of theorems, explicitly checking cyclic dependencies (which are cur-
rently prevented by the glue code, see Sect. 10).
A presentation layer as discussed in Sect. 12 would not just allow the inspec-
tion of the internal representation of the theories but could also be extended to
the proofs themselves, thus permitting checkers to be interfaced with Isabelle on
a textual level instead of internal data structures.
It would also be nice to have a model-theoretic semantics for M. We believe
that the work by Kunˇcar and Popescu [15,16,17,18] could be adapted from HOL
to M. This would in particular yield semantically justiﬁed cyclicity checks for
constant and type deﬁnitions which we currently treat as axioms because a purely
syntactic justiﬁcation is unclear.
Acknowledgements
We thank Kevin Kappelmann, Magnus Myreen, Larry Paulson, Andrei Popescu,
Makarius Wenzel and the anonymous reviewers for their comments.
A
Appendix
subst-bv u t = subst-bv2 t 0 u
subst-bv2 (Bv i) n u = (if i < n then Bv i else if i = n then u else Bv (i −1))
subst-bv2 (Abs T t) n u = Abs T (subst-bv2 t (n + 1) (lift u 0))
subst-bv2 (f · t) n u = subst-bv2 f n u · subst-bv2 t n u
subst-bv2 t
= t
lift (Bv i) n = (if n ≤i then Bv (i + 1) else Bv i)
lift (Abs T t) n = Abs T (lift t (n + 1))
lift (f · t) n = lift f n · lift t n
lift t
= t
bind-fv T t = bind-fv2 T 0 t
bind-fv2 var n (Fv v T) = (if var = (v, T) then Bv n else Fv v T)
bind-fv2 var n (Abs T t) = Abs T (bind-fv2 var (n + 1) t)
bind-fv2 var n (f · u) = bind-fv2 var n f · bind-fv2 var n u
bind-fv2
t = t
References
1. ˚Aman Pohjola, J., Gengelbach, A.: A mechanised semantics for HOL with ad-
hoc overloading. In: Albert, E., Kov´acs, L. (eds.) LPAR 2020: 23rd International
Conference on Logic for Programming, Artiﬁcial Intelligence and Reasoning. EPiC
Series in Computing, vol. 73, pp. 498–515. EasyChair (2020), https://doi.org/
10.29007/413d

108
T. Nipkow and S. Roßkopf
2. Abrahamsson, O.: A veriﬁed proof checker for higher-order logic. J. Log. Al-
gebraic Methods Program. 112, 100530 (2020), https://doi.org/10.1016/j.
jlamp.2020.100530
3. Adams, M.: HOL Zero’s solutions for Pollack-inconsistency. Lect. Notes in
Comp. Sci., vol. 9807, pp. 20–35. Springer (2016), https://doi.org/10.1007/
978-3-319-43144-4_2
4. Berghofer, S., Nipkow, T.: Proof terms for simply typed higher order logic. In:
Harrison, J., Aagaard, M. (eds.) Theorem Proving in Higher Order Logics. Lect.
Notes in Comp. Sci., vol. 1869, pp. 38–52. Springer (2000)
5. Berghofer, S., Nipkow, T.: Executing higher order logic. In: Callaghan, P., Luo, Z.,
McKinna, J., Pollack, R. (eds.) Types for Proofs and Programs (TYPES 2000).
Lect. Notes in Comp. Sci., vol. 2277, pp. 24–40. Springer (2002)
6. Carneiro, M.M.: Metamath Zero: Designing a theorem prover prover. In:
Benzm¨uller, C., Miller, B.R. (eds.) Intelligent Computer Mathematics, CICM
2020. Lect. Notes in Comp. Sci., vol. 12236, pp. 71–88. Springer (2020), https:
//doi.org/10.1007/978-3-030-53518-6_5
7. Gheri, L., Popescu, A.: A formalized general theory of syntax with bindings: Ex-
tended version. J. Automated Reasoning 64(4), 641–675 (2020), https://doi.
org/10.1007/s10817-019-09522-2
8. Haftmann, F., Krauss, A., Kunˇcar, O., Nipkow, T.: Data reﬁnement in Isa-
belle/HOL. In: Blazy, S., Paulin-Mohring, C., Pichardie, D. (eds.) Interactive Theo-
rem Proving (ITP 2013). Lect. Notes in Comp. Sci., vol. 7998, pp. 100–115. Springer
(2013)
9. Haftmann, F., Nipkow, T.: Code generation via higher-order rewrite systems. In:
Blume, M., Kobayashi, N., Vidal, G. (eds.) Functional and Logic Programming
(FLOPS 2010). Lect. Notes in Comp. Sci., vol. 6009, pp. 103–117. Springer (2010)
10. Haftmann, F., Wenzel, M.: Constructive type classes in isabelle. In: Altenkirch, T.,
McBride, C. (eds.) Types for Proofs and Programs, TYPES 2006. Lect. Notes in
Comp. Sci., vol. 4502, pp. 160–174. Springer (2006), https://doi.org/10.1007/
978-3-540-74464-1_11
11. Harrison, J.: Towards self-veriﬁcation of HOL Light. In: Furbach, U., Shankar, N.
(eds.) Proceedings of the third International Joint Conference, IJCAR 2006. Lect.
Notes in Comp. Sci., vol. 4130, pp. 177–191. Springer, Seattle, WA (2006)
12. Hurd, J.: OpenTheory: Package management for higher order logic theories. In:
Reis, G., Th´ery, L. (eds.) Workshop on Programming Languages for Mechanized
Mathematics Systems (ACM SIGSAM PLMMS 2009). pp. 31–37 (2009)
13. Kumar, R., Arthan, R., Myreen, M.O., Owens, S.: Self-formalisation of higher-order
logic — semantics, soundness, and a veriﬁed implementation. J. Automated Rea-
soning 56(3), 221–259 (2016), https://doi.org/10.1007/s10817-015-9357-x
14. Kumar, R., Myreen, M.O., Norrish, M., Owens, S.: CakeML: A veriﬁed implemen-
tation of ML. In: Principles of Programming Languages (POPL). pp. 179–191.
ACM Press (Jan 2014), https://doi.org/10.1145/2535838.2535841
15. Kunˇcar, O., Popescu, A.: A consistent foundation for Isabelle/HOL. In: Urban,
C., Zhang, X. (eds.) Interactive Theorem Proving, ITP 2015. Lect. Notes in
Comp. Sci., vol. 9236, pp. 234–252. Springer (2015), https://doi.org/10.1007/
978-3-319-22102-1_16
16. Kunˇcar, O., Popescu, A.: Comprehending Isabelle/HOL’s consistency. In: Yang,
H. (ed.) Programming Languages and Systems, ESOP 2017. Lect. Notes in
Comp. Sci., vol. 10201, pp. 724–749. Springer (2017), https://doi.org/10.1007/
978-3-662-54434-1_27

Isabelle’s Metalogic: Formalization and Proof Checker
109
17. Kunˇcar, O., Popescu, A.: Safety and conservativity of deﬁnitions in HOL and
Isabelle/HOL. Proc. ACM Program. Lang. 2(POPL), 24:1–24:26 (2018), https:
//doi.org/10.1145/3158112
18. Kunˇcar,
O.,
Popescu,
A.:
A
consistent
foundation
for
Isabelle/HOL.
J.
Automated
Reasoning
62(4),
531–555
(2019),
https://doi.org/10.1007/
s10817-018-9454-8
19. Lammich, P., Lochbihler, A.: The Isabelle collections framework. In: Kaufmann,
M., Paulson, L.C. (eds.) Interactive Theorem Proving, ITP 2010. Lect. Notes in
Comp. Sci., vol. 6172, pp. 339–354. Springer (2010), https://doi.org/10.1007/
978-3-642-14052-5_24
20. Lochbihler, A.: Light-weight containers for isabelle: Eﬃcient, extensible, nestable.
In: Blazy, S., Paulin-Mohring, C., Pichardie, D. (eds.) Interactive Theorem Proving,
ITP 2013. Lect. Notes in Comp. Sci., vol. 7998, pp. 116–132. Springer (2013),
https://doi.org/10.1007/978-3-642-39634-2_11
21. Journal of Automated Reasonig: Special Issue: Theory and Applications of Ab-
straction, Substitution and Naming, vol. 49. Springer (Aug 2012), https://link.
springer.com/journal/10817/volumes-and-issues/49-2
22. Nipkow, T.: Order-sorted polymorphism in Isabelle. In: Huet, G., Plotkin, G. (eds.)
Logical Environments. pp. 164–188. Cambridge University Press (1993)
23. Nipkow, T.: More Church-Rosser proofs (in Isabelle/HOL). J. Automated Reason-
ing 26, 51–66 (2001)
24. Nipkow, T., Klein, G.: Concrete Semantics with Isabelle/HOL. Springer (2014),
http://concrete-semantics.org
25. Nipkow, T., Paulson, L., Wenzel, M.: Isabelle/HOL — A Proof Assistant for
Higher-Order Logic, Lect. Notes in Comp. Sci., vol. 2283. Springer (2002)
26. Nipkow, T., Paulson, L.C.: Isabelle-91. In: Kapur, D. (ed.) Automated Deduction
- CADE-11. Lect. Notes in Comp. Sci., vol. 607, pp. 673–676. Springer (1992),
https://doi.org/10.1007/3-540-55602-8_201
27. Nipkow, T., Prehofer, C.: Type reconstruction for type classes. J. Functional Pro-
gramming 5(2), 201–224 (1995)
28. Nipkow, T., Roßkopf, S.: Isabelle’s metalogic: Formalization and proof checker.
Archive of Formal Proofs (Apr 2021), https://isa-afp.org/entries/Metalogic_
ProofChecker.html, Formal proof development
29. Nipkow, T., Snelting, G.: Type classes and overloading resolution via order-sorted
uniﬁcation. In: Hughes, J. (ed.) Proc. 5th ACM Conf. Functional Programming
Languages and Computer Architecture. Lect. Notes in Comp. Sci., vol. 523, pp.
1–14. Springer (1991)
30. Paulson, L.C.: The foundation of a generic theorem prover. J. Automated Reason-
ing 5, 363–397 (1989)
31. Paulson, L.C.: Isabelle: A Generic Theorem Prover, Lect. Notes in Comp. Sci.,
vol. 828. Springer (1994)
32. Pelletier, F.: Seventy-ﬁve problems for testing automatic theorem provers. J. Au-
tomated Reasoning 2, 191–216 (06 1986), https://doi.org/10.1007/BF02432151
33. Pfenning, F.: Elf: A language for logic deﬁnition and veriﬁed metaprogramming.
In: Logic in Computer Science (LICS 1989). pp. 313–322. IEEE Computer Society
Press (1989)
34. Pfenning, F., Sch¨urmann, C.: System description: Twelf - A meta-logical framework
for deductive systems. In: Ganzinger, H. (ed.) Automated Deduction, CADE-16.
Lect. Notes in Comp. Sci., vol. 1632, pp. 202–206. Springer (1999), https://doi.
org/10.1007/3-540-48660-7_14

110
T. Nipkow and S. Roßkopf
35. Pientka, B.: Beluga: Programming with dependent types, contextual data, and
contexts. In: Blume, M., Kobayashi, N., Vidal, G. (eds.) Functional and Logic Pro-
gramming, FLOPS 2010. Lect. Notes in Comp. Sci., vol. 6009, pp. 1–12. Springer
(2010), https://doi.org/10.1007/978-3-642-12251-4_1
36. Sozeau, M., Boulier, S., Forster, Y., Tabareau, N., Winterhalter, T.: Coq Coq
correct! Veriﬁcation of type checking and erasure for Coq, in Coq. Proc. ACM
Program. Lang. 4(POPL), 8:1–8:28 (2020), https://doi.org/10.1145/3371076
37. Urban, C.: Nominal techniques in Isabelle/HOL. J. Automated Reasoning 40, 327–
356 (2008), https://doi.org/10.1007/s10817-008-9097-2
38. Wenzel, M.: Type classes and overloading in higher-order logic. In: Gunter, E.L.,
Felty, A.P. (eds.) Theorem Proving in Higher Order Logics, TPHOLs’97. Lect.
Notes in Comp. Sci., vol. 1275, pp. 307–322. Springer (1997), https://doi.org/
10.1007/BFb0028402
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/
4.0/), which permits use, sharing, adaptation, distribution and reproduction in any
medium or format, as long as you give appropriate credit to the original author(s) and
the source, provide a link to the Creative Commons license and indicate if changes
were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Theory and Principles

The ksmt Calculus Is a δ-complete Decision
Procedure for Non-linear Constraints⋆
1 Abteilung Informatikwissenschaften, Universität Trier, Trier, Germany
2 The University of Manchester, Manchester, UK
3 A.P. Ershov Institute of Informatics Systems, Novosibirsk, Russia
brausse@informatik.uni-trier.de, konstantin.korovin@manchester.ac.uk
Abstract. ksmt is a CDCL-style calculus for solving non-linear con-
straints over the real numbers involving polynomials and transcendental
functions. In this paper we investigate properties of the ksmt calculus
and show that it is a δ-complete decision procedure for bounded prob-
lems. We also propose an extension with local linearisations, which allow
for more eﬃcient treatment of non-linear constraints.
1
Introduction
Solving non-linear constraints is important in many applications, including veriﬁ-
cation of cyber-physical systems, software veriﬁcation, proof assistants for math-
ematics [25,21,2,1,15,6]. Hence there has been a number of approaches for solv-
ing non-linear constraints, involving symbolic methods [16,23,29,18] as well as
numerically inspired ones, in particular for dealing with transcendental func-
tions [13,30], and combinations of symbolic and numeric methods [7,11,12].
In [7] we introduced the ksmt calculus for solving non-linear constraints over
a large class of functions including polynomial, exponential and trigonometric
functions. The ksmt calculus4 combines CDCL-style reasoning [28,22,3] over the
reals based on conﬂict resolution [19] with incremental linearisations of non-
linear functions using methods from computable analysis [31,24]. Our approach is
based on computable analysis and exact real arithmetic which avoids limitations
of double precision computations caused by rounding errors and instabilities in
numerical methods. In particular, satisﬁable and unsatisﬁable results returned
by ksmt are exact as required in many applications. This approach also supports
implicit representations of functions as solutions of ODEs and PDEs [26].
It is well known that in the presence of transcendental functions the con-
straint satisﬁability problem is undecidable [27]. However if we only require so-
lutions up to some speciﬁed precision δ, then the problem can be solved algorith-
mically on bounded instances and that is the motivation behind δ-completeness,
⋆This research was partially supported by an Intel research grant, the DFG grant
WERA MU 1801/5-1 and the RFBR-JSPS 20-51-5000 grant.
4 Implementation is available at http://informatik.uni-trier.de/~brausse/ksmt/
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp. 113 130, 2021.
https://doi.org/10.1007/978-3-030-79876-5_7
–
Franz Brauße2
, Konstantin Korovin2
, Margarita V. Korovina3
,
and Norbert Th. M¨uller1

114
F. Brauße, K. Korovin, M. V. Korovina, N. Th. Müller
which was introduced in [13]. In essence a δ-complete procedure decides if a
formula is unsatisﬁable or a δ weakening of the formula is satisﬁable.
In this paper we investigate theoretical properties of the ksmt calculus, and
its extension δ-ksmt for the δ-SMT setting. Our main results are as follows:
1. We introduced a notion of ϵ-full linearisations and prove that all ϵ-full runs
of ksmt are terminating on bounded instances.
2. We extended the ksmt calculus to the δ-satisﬁability setting and proved that
δ-ksmt is a δ-complete decision procedure for bounded instances.
3. We introduced an algorithm for computing ϵ-full local linearisations and
integrated it into δ-ksmt. Local linearisations can be used to considerably
narrow the search space by taking into account local behaviour of non-linear
functions avoiding computationally expensive global analysis.
In Section 3, we give an overview about the ksmt calculus and introduce
the notion of ϵ-full linearisation used throughout the rest of the paper. We
also present a completeness theorem. Section 4 introduces the notion of δ-
completeness and related concepts. In Section 5 we introduce the δ-ksmt adapta-
tion, prove it is correct and δ-complete, and give concrete eﬀective linearisations
based on a uniform modulus of continuity. Finally in Section 6, we introduce local
linearisations and show that termination is independent of computing uniform
moduli of continuity, before we conclude in Section 7.
2
Preliminaries
The following conventions are used throughout this paper. By ∥· ∥we denote
the maximum-norm ∥(x1, x2, . . . , xn)∥= max{|xi| : 1 ≤i ≤n}. When it helps
clarity, we write ﬁnite and inﬁnite sequences x = (x1, . . . , xn) and y = (yi)i in
bold typeface. We are going to use open balls B(c, ϵ) = {x : ∥x −c∥< ϵ} ⊆Rn
for c ∈Rn and ϵ > 0 and sA to denote the closure of the set A ⊆Rn in the
standard topology induced by the norm. By Q>0 we denote the set {q ∈Q :
q > 0}. For sets X, Y , a (possibly partial) function from X to Y is written as
X →Y . We use the notion of compactness: a set A is compact iﬀevery open
cover of A has a ﬁnite subcover. In Euclidean spaces this is equivalent to A being
bounded and closed [32].
Basic Notions of Computable Analysis
Let us recall the notion of computability of functions over real numbers used
throughout this paper. A rational number q is an n-approximation of a real
number x if ∥q −x∥≤2−n. Informally, a function f is computed by a function-
oracle Turing machine M ?
f, where ? is a placeholder for the oracle representing
the argument of the function, in the following way. The real argument x is repre-
sented by an oracle function ϕ : N →Q, for each n returning an n-approximation
ϕn of x. For simplicity, we refer to ϕ by the sequence (ϕn)n. When run with ar-
gument p ∈N, M ϕ
f (p) computes a rational p-approximation of f(x) by querying

The ksmt Calculus Is a δ-complete Decision Procedure
115
its oracle ϕ for approximations of x. Let us note that the deﬁnition of the oracle
machine does not depend on the concrete oracle, i.e., the oracle can be seen as a
parameter. In case only the machine without a concrete oracle is of interest, we
write M ?
f. We refer to [17] for a precise deﬁnition of the model of computation
by function-oracle Turing machines which is standard in computable analysis.
Deﬁnition 1 ([17]).
Consider x ∈Rn. A name for x is a rational sequence
ϕ = (ϕk)k such that ∀k : ∥ϕk−x∥≤2−k. A function f : Rn →R is computable
iﬀthere is a function-oracle Turing machine M ?
f such that for all x ∈dom f
and names ϕ for x, |M ϕ
f (p) −f(x)| ≤2−p holds for all p ∈N.
This deﬁnition is closely related to interval arithmetic with unrestricted pre-
cision, but enhanced with the guarantee of convergence and it is equivalent
to the notion of computability used in [31]. The class of computable functions
contains polynomials and transcendental functions like sin, cos, exp, among oth-
ers. It is well known [17,31] that this class is closed under composition and
that computable functions are continuous. By continuity, a computable function
f : Rn →R total on a compact D ⊂Rn has a computable uniform modulus of
continuity μf : N →N on D [31, Theorem 6.2.7], that is,
∀k ∈N ∀y, z ∈D : ∥y −z∥≤2−μ(k) =⇒|f(y) −f(z)| ≤2−k.
(2.1)
A uniform modulus of continuity of f expresses how changes in the value of f
depend on changes of the arguments in a uniform way.
3
The ksmt Calculus
We ﬁrst describe the ksmt calculus for solving non-linear constraints [7] infor-
mally, and subsequently recall the main deﬁnitions which we use in this paper.
The ksmt calculus consists of transition rules, which, for any formula in linear
separated form, allow deriving lemmas consistent with the formula and, in case
of termination, produce a satisfying assignment for the formula or show that it
is unsatisﬁable. A quantiﬁer-free formula is in separated linear form L ∪N if
L is a set of clauses over linear constraints and N is a set of non-linear atomic
constraints; this notion is rigorously deﬁned below.
In the ksmt calculus there are four transition rules applied to its states:
Assignment reﬁnement (A), Conﬂict resolution (R), Backjumping (B) and Lin-
earisation (L). The ﬁnal ksmt states are sat and unsat. A non-ﬁnal ksmt state is
a triple (α, L, N) where α is a (partial) assignment of variables to rationals. A
ksmt derivation starts with an initial state where α is empty and tries to extend
this assignment to a solution of L ∪N by repeatedly applying the Assignment
reﬁnement rule. When such assignment extension is not possible we either ob-
tain a linear conﬂict which is resolved using the conﬂict resolution rule, or a
non-linear conﬂict which is resolved using the linearisation rule.
The main idea behind the linearisation rule is to approximate the non-linear
constraints around the conﬂict using linear constraints in such a way that the

116
F. Brauße, K. Korovin, M. V. Korovina, N. Th. Müller
separated linear form
lin.
check
choice
A
B
∃z
R
nlin.
check
L
α = nil
p.lin.cons.
p.lin.incons.
∃q
¬∃q
p.nlin.cons.
p.nlin.incons.
Fig. 1. Core of ksmt calculus. Derivations terminate in red nodes.
conﬂict will be shifted into the linear part where it will be resolved using conﬂict
resolution. Application of either of these two rules results in a state containing a
clause evaluating to false under the current assignment. This is followed by either
application of the backjumping rule, which undoes assignments or by termination
in case the formula is unsat. In this procedure, only the assignment and linear
part of the state change and the non-linear part stays ﬁxed.
Notations. Let Flin consist of rational constants, addition and multiplication by
rational constants; Fnl denotes an arbitrary collection of non-linear computable
functions including transcendental functions and polynomials over the reals. We
consider the structure (R, ⟨Flin ∪Fnl, P⟩) where P = {<, ≤, >, ≥, =, ̸=} and a
set of variables V = {x1, x2, . . . , xn, . . .}. We will use, possibly with indices, x to
denote variables and q, c, e for rational constants. Deﬁne terms, predicates and
formulas over V in the standard way. An atomic linear constraint is a formula of
the form: q + c1x1 + . . . + cnxn ⋄0 where q, c1, . . . , cn ∈Q and ⋄∈P. Negations
of atomic formulas can be eliminated by rewriting the predicate symbol ⋄in the
standard way, hence we assume that all literals are positive. A linear constraint is
a disjunction of atomic linear constraints, also called (linear) clause. An atomic
non-linear constraint is a formula of the form f(x) ⋄0, where ⋄∈P and f
is a composition of computable non-linear functions from Fnl over variables
x. Throughout this paper for every computable real function f we use M ?
f to
denote a function-oracle Turing machine computing f. We assume quantiﬁer-free
formulas in separated linear form [7, Deﬁnition 1], that is, L∪N where L is a set
of linear constraints and N is a set of non-linear atomic constraints. Arbitrary
quantiﬁer-free formulas can be transformed equi-satisﬁably into separated linear
form in polynomial time [7, Lemma 1]. Since in separated linear form all non-
linear constraints are atomic we will call them just non-linear constraints.
Let α : V →Q be a partial variable assignment. The interpretation xα
of a vector of variables x under α is deﬁned in a standard way as component-

The ksmt Calculus Is a δ-complete Decision Procedure
117
wise application of α. Deﬁne the notation tα as evaluation of term t under
assignment α, that can be partial, in which case tα is treated symbolically. We
extend ·α to predicates, clauses and CNF in the usual way and true, false denote
the constants of the Boolean domain. The evaluation t ⋄0α for a predicate ⋄
and a term t results in true or false only if all variables in t are assigned by α.
In order to formally restate the calculus, the notions of linear resolvent and
linearisation are essential. A resolvent Rα,L,z on a variable z is a set of linear con-
straints that do not contain z, are implied by the formula L and which evaluate
to false under the current partial assignment α; for more details see [19,7].
Deﬁnition 2. Let P be a non-linear constraint and let α be an assignment with
Pα = false. A linearisation of P at α is a linear clause C with the properties:
1. ∀β : Pβ = true =⇒Cβ = true, and
2. Cα = false.
Wlog. we can assume that the variables of C are a subset of the variables of P.
Let us note that any linear clause C represents the complement of a rational
polytope R and we will use both interchangeably. Thus for a rational polytope
R, x ̸∈R also stands for a linear clause. In particular, any linearisation excludes
a rational polytope containing the conﬂicting assignment from the search space.
Transition rules. For a formula L0 ∪N in separated linear form, the initial ksmt
state is (nil, L0, N). The calculus consists of the following transition rules from
a state S = (α, L, N) to S′:
(A) Assignment. S′ = (α :: z →q, L, N) iﬀLα ̸= false and there is a variable
z unassigned in α and q ∈Q with Lα::z→q ̸= false.
(R) Resolution. S′ = (α, L ∪Rα,L,z, N) iﬀLα ̸= false and there is a variable
z unassigned in α with ∀q ∈Q : Lα::z→q = false and Rα,L,z is a resolvent.
(B) Backjump. S′ = (γ, L, N) iﬀLα = false and there is a maximal preﬁx γ
of α such that Lγ ̸= false.
(L) Linearisation. S′ = (α, L∪{Lα,P }, N) iﬀLα ̸= false, there is P in N with
Pα = false and there is a linearisation Lα,P of P at α.
(F sat) Final sat. S′ = sat if all variables are assigned in α, Lα = true and
none of the rules (A), (R), (B), (L) is applicable.
(F unsat) Final unsat. S′ = unsat if Lnil = false. In other words a trivial con-
tradiction, e.g., 0 > 1 is in L.
A path (or a run) is a derivation in a ksmt. A procedure is an eﬀective
(possibly non-deterministic) way to construct a path.
Termination. If no transition rule is applicable, the derivation terminates. For
clarity, we added the explicit rules (F sat) and (F unsat) which lead to the ﬁnal
states. This calculus is sound [7, Lemma 2]: if the ﬁnal transition is (F sat), then
α is a solution to the original formula, or (F unsat), then a trivial contradiction
0 > 1 was derived and the original formula is unsatisﬁable. The calculus also
makes progress by reducing the search space [7, Lemma 3].

118
F. Brauße, K. Korovin, M. V. Korovina, N. Th. Müller
C = (y ≤1/x)



P
∧(x/4 + 1 ≤y)
∧(y ≤4 · (x −1))
∧

(x ≤12
19) ∨(y ≤19
12)

∧

(x ≤220
223) ∨(y ≤223
220)

∧( 4
3 ≤x) ∧(x ≤220
223)
∧( 4
3 ≤220
223)
 0
 1
 2
 3
 0
 1
 2
 3
 4
(1)
(2)
(3a)
(3b)
(4a)
(4b)
y
x
(1)
(1)
(3b
(4a)
(4b)
(
b)
b
(2)
(3a)
Linearisation of P on conﬂicts (x, y) at α here:
– choose d := (1/xα + yα)/2,
– C =

x ≤1/d ∨y ≤d

rule
α
note
(A)
x →2
(A)
x →2, y →8
3
(3a)
(L)
x →2, y →8
3
(3b)
(B)
x →2
(A)
x →2, y →84
55
(4a)
(L)
x →2, y →84
55
(4b)
(B)
x →2
(R)
x →2
on y
(B)
(R)
on x
(F unsat)
unsat
Fig. 2. unsat example run of ksmt using interval linearisation [7].
An example run of the ksmt calculus is presented in Figure 2. We start in a
state with a non-linear part N = {y ≤1/x}, which deﬁnes the pink area and
the linear part L = {(x/4 + 1 ≤y), (y ≤4 · (x −1))}, shaded in green. Then we
successively apply ksmt rules excluding regions around candidate solutions by
linearisations, until we derive linearisations which separates the pink area from
the green area thus deriving a contradiction.
Remark 1. In general a derivation may not terminate. The only cause of non-
termination is the linearisation rule which adds new linear constraints and can
be applied inﬁnitely many times. To see this, observe that ksmt with only the
rules (A), (R), (B) corresponds to the conﬂict resolution calculus which is known
to be terminating [19,20]. Thus, in inﬁnite ksmt runs the linearisation rule (L) is
applied inﬁnitely often. This argument is used in the proof of Theorem 1 below.
Let us note that during a run the ksmt calculus neither conﬂicts nor lemmas can
be generated more than once. In fact, any generated linearisation is not implied
by the linear part, prior to adding this linearisation.
3.1
Suﬃcient Termination Conditions
In this section we will assume that (α, L, N) is a ksmt state obtained by applying
ksmt inference rules to an initial state. As in [13] we only consider bounded
instances. In many applications this is a natural assumption as variables usually
range within some (possibly large) bounds. We can assume that these bounds
are made explicit as linear constraints in the system.
Deﬁnition 3. Let F be the formula L0 ∧N in separated linear form over vari-
ables x1, . . . , xn and let Bi be the set deﬁned by the conjunction of all clauses

The ksmt Calculus Is a δ-complete Decision Procedure
119
in L0 univariate in xi, for i = 1, . . . , n; in particular, if there are no univariate
linear constraints over xi then Bi = R. We call F a bounded instance if:
– DF :=×
n
i=1 Bi is bounded, and
– for each non-linear constraint P : f(xi1, . . . , xik)⋄0 in N with ij ∈{1, . . . , n}
for j ∈{1, . . . , k} it holds that Ě
DP ⊆dom f where DP :=×
k
j=1 Bij.
By this deﬁnition, already the linear part of bounded instances explicitly deﬁnes
a bounded set by univariate constraints. Consequently, the set of solutions of F
is bounded as well.
In Theorem 1 we show that when we consider bounded instances and restrict
linearisations to so-called ϵ-full linearisations, then the procedure terminates.
We use this to show that the ksmt-based decision procedure we introduce in
Section 5 is δ-complete.
Deﬁnition 4. Let ϵ > 0, P be a non-linear constraint over variables x and let
α be an assignment of x. A linearisation C of P at α is called ϵ-full iﬀfor all
assignments β of x with xβ ∈B(xα, ϵ), Cβ = false.
A ksmt run is called ϵ-full for some ϵ > 0, if all but ﬁnitely many linearisa-
tions in this run are ϵ-full.
The next theorem provides a basis for termination of ksmt-based decision
procedures for satisﬁability.
Theorem 1. Let ϵ > 0. On bounded instances, ϵ-full ksmt runs are terminating.
Proof. Let F : L0 ∧N be a bounded instance and ϵ > 0. Towards a contradic-
tion assume there is an inﬁnite ϵ-full derivation (α0, L0, N), . . . , (αn, Ln, N), . . .
in the ksmt calculus. Then, by deﬁnition of the transition rules, Lk ⊆Ll for
all k, l with 0 ≤k ≤l. According to Remark 1 in any inﬁnite derivation the
linearisation rule must be applied inﬁnitely many times. During any run of ksmt
the set of non-linear constraints N is ﬁxed and therefore there is a non-linear
constraint P in N over variables x to which linearisation is applied inﬁnitely
often. Let (αi1, Li1, N), . . . , (αin, Lin, N), . . . be a corresponding subsequence
in the derivation such that Ci1 ∈Li1+1, . . . , Cin ∈Lin+1, . . . are ϵ-full lineari-
sations of P. Consider two diﬀerent linearisation steps k, ℓ∈{ij : j ∈N} in
the derivation where k < ℓ. By the precondition of rule (L) applied in step ℓ
we have Lℓαℓ̸= false. In particular the linearisation Ck ∈Lk+1 ⊆Lℓof P
constructed in step k does not evaluate to false under αℓ. Since the set of vari-
ables in Ck is a subset of those in P, Ckαℓ̸= false implies Ckαℓ= true.
By assumption, the linearisation Ck is ϵ-full, thus from Deﬁnition 4 it follows
that xαℓ/∈B(xαk, ϵ). Therefore the distance between xαk and xαℓis
at least ϵ. However, every conﬂict satisﬁes the variable bounds deﬁning DF , so
there could be only ﬁnitely many conﬂicts with pairwise distance at least ϵ. This
contradicts the above.
Concrete algorithms to compute ϵ-full linearisations are presented in Sec-
tions 5 and 6.

120
F. Brauße, K. Korovin, M. V. Korovina, N. Th. Müller
f(x)
0
δ
δ-sat
]
(
unsat
Fig. 3. The overlapping cases in the δ-SMT problem f(x) ≤0.
4
δ-decidability
In the last section, we proved termination of the ksmt calculus on bounded
instances when linearisations are ϵ-full. Let us now investigate how ϵ-full lin-
earisations of constraints involving non-linear computable functions can be con-
structed. To that end, we assume that all non-linear functions are deﬁned on the
closure of the bounded space DF deﬁned by the bounded instance F.
So far we described an approach which gives exact results but at the same
time is necessarily incomplete due to undecidability of non-linear constraints in
general. On the other hand, non-linear constraints usually can be approximated
using numerical methods allowing to obtain approximate solutions to the prob-
lem. This gives rise to the bounded δ-SMT problem [13] which allows an overlap
between the properties δ-sat and unsat of formulas as illustrated by Figure 3. It
is precisely this overlap that enables δ-decidability of bounded instances.
Let us recall the notion of δ-decidability, adapted from [13].
Deﬁnition 5. Let F be a formula in separated linear form and let δ ∈Q>0. We
inductively deﬁne the δ-weakening Fδ of F.
– If F is linear, let Fδ := F.
– If F is a non-linear constraint f(x) ⋄0, let
Fδ :=
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
f(x) −δ ⋄0,
if ⋄∈{<, ≤}
f(x) + δ ⋄0,
if ⋄∈{>, ≥}
|f(x)| −δ ≤0,
if ⋄∈{=}
(f(x) < 0 ∨f(x) > 0)δ,
if ⋄∈{̸=}.
– Otherwise, F is A ◦B with ◦∈{∧, ∨}. Let Fδ := (Aδ ◦Bδ).
δ-deciding F designates computing

unsat,
if Fα = false for all α
δ-sat,
if Fδα = true for some α.
In case both answers are valid, the algorithm may output any.
An assignment α with Fδα = true we call a δ-satisfying assignment for F.
For non-linear constraints P this deﬁnition of the δ-weakening Pδ corresponds ex-
actly to the notion of δ-weakening P −δ used in the introduction of δ-decidability
[14, Deﬁnition 4.1].

The ksmt Calculus Is a δ-complete Decision Procedure
121
Remark 2. The δ-weakening of a non-linear constraint f(x) ̸= 0 is a tautology.
We now consider the problem of δ-deciding quantiﬁer-free formulas in sepa-
rated linear form. The notion of δ-decidability is slightly stronger than in [13]
in the sense that we do not weaken linear constraints. Consider a formula F in
separated linear form. As before, we assume variables x to be bounded by linear
constraints x ∈DF . We additionally assume that for all non-linear constraints
P : f(x) ⋄0 in N, f is deﬁned on Ě
DP and, in order to simplify the presentation,
throughout the rest of paper we will assume only the predicates ⋄∈{>, ≥} are
part of formulas, since the remaining ones <, ≤, = can easily be expressed by the
former using simple arithmetic transformations, and by Remark 2 predicates ̸=
are irrelevant for δ-deciding formulas.
An algorithm is δ-complete, if it δ-decides bounded instances [13].
5
δ-ksmt
Since δ-decidability as introduced above adapts the condition when a formula
is considered to be satisﬁed to δ-sat, this condition has to be reﬂected in the
calculus, which we show solves the bounded δ-SMT problem in this section.
Adding the following rule (F sat
δ
) together with the new ﬁnal state δ-sat to ksmt
relaxes the termination conditions and turns it into the extended calculus we
call δ-ksmt.
(F sat
δ
) Final δ-sat. If (α, L, N) is a δ-ksmt state where α is a total assignment
and L ∧Nδα = true, transition to the δ-sat state.
The applicability conditions on the rules (L) and (F sat
δ
) individually are not
decidable [27,5], however, when we compute them simultaneously, we can eﬀec-
tively apply one of these rules, as we will show in Lemma 3. In combination with
ϵ-fullness of the computed linearisations (Lemma 4), this leads to Theorem 3,
showing that δ-ksmt is a δ-complete decision procedure.
Let us note that if we assume δ = 0 then δ-ksmt would just reduce to ksmt
as (F sat) and (F sat
δ
) become indistinguishable, but in the following we always
assume δ > 0.
In the following sub-section, we prove that terminating derivations of the δ-
ksmt calculus lead to correct results. Then, in Section 5.2, we present a concrete
algorithm for applying rules (L) and (F sat
δ
) and show its linearisations to be
ϵ-full, which is suﬃcient to ensure termination, as shown in Theorem 1. These
properties lead to a δ-complete decision procedure. In Section 6 we develop a
more practical algorithm for ϵ-full linearisations that does not require computing
a uniform modulus of continuity.
5.1
Soundness
In this section we show soundness of the δ-ksmt calculus, that is, validity of
its derivations. In particular, this implies that derivability of the ﬁnal states
unsat, δ-sat and sat directly corresponds to unsatisﬁability, δ-satisﬁability and
satisﬁability of the original formula, respectively.

122
F. Brauße, K. Korovin, M. V. Korovina, N. Th. Müller
Lemma 1. For all δ-ksmt derivations of S′ = (α′, L′, N) from a state S =
(α, L, N) and for all total assignments β, L ∧Nβ = L′ ∧Nβ.
Proof. Let β be a total assignment of the variables in L ∧N. Since the set of
variables remains unchanged by δ-ksmt derivations, β is a total assignment for
L′ ∧N as well. Let S′ = (α′, L′, N) be derived from S = (α, L, N) by a single
application of one of δ-ksmt rules. By the structure of S′, its derivation was
not caused by neither (F unsat), (F sat) or (F sat
δ
). For rules (A) and (B) there
is nothing to show since L = L′. If (R) caused S →S′, the claim holds by
soundness of arithmetical resolution. Otherwise (L) caused S →S′ in which
case the direction ⇒follows from the deﬁnition of a linearisation (condition 1
in Deﬁnition 2) while the other direction trivially holds since L ⊆L′.
The condition on derivations of arbitrary lengths then follows by induction.
Lemma 2. Let δ ∈Q>0. Consider a formula G = L0 ∧N in separated linear
form and let S = (α, L, N) be a δ-ksmt state derivable from the initial state
S0 = (nil, L0, N). The following hold.
– If rule (F unsat) is applicable to S then G is unsatisﬁable.
– If rule (F sat
δ
) is applicable to S then α is a δ-satisfying assignment for G,
hence G is δ-satisﬁable.
– If rule (F sat) is applicable to S then α is a satisfying assignment for G,
hence G is satisﬁable.
Proof. Let formula G and states S0, S be as in the premise. As S is not ﬁnal
in δ-ksmt, only ksmt rules have been applied in deriving it. The statements for
rules (F unsat) and (F sat) thus hold by soundness of ksmt [7, Lemma 2].
Assume (F sat
δ
) is applicable to S, that is, L ∧Nδα is true. Then, since
L0 ⊆L, we conclude that α satisﬁes L0 ∧Nδ which, according to Deﬁnition 5,
equals Gδ. Therefore α is a δ-satisfying assignment for G.
Since the only way to derive one of the ﬁnal states unsat, δ-sat and sat from the
initial state in δ-ksmt is by application of the rule (F unsat), (F sat
δ
) and (F sat),
respectively, as corollary of Lemmas 1 and 2 we obtain soundness.
Theorem 2 (Soundness). Let δ ∈Q>0. The δ-ksmt calculus is sound.
5.2
δ-completeness
We proceed by introducing Algorithm 1 computing linearisations and deciding
which of the rules (F sat
δ
) and (L) to apply. These linearisations are then shown
to be ϵ-full for some ϵ > 0 depending on the bounded instance. By Theorem 1,
this property implies termination, showing that δ-ksmt is a δ-complete decision
procedure.
Given a non-ﬁnal δ-ksmt state, the function nlinStepδ in Algorithm 1 com-
putes a δ-ksmt state derivable from it by application of (F sat
δ
) or (L). This is
done by evaluating the non-linear functions and adding a linearisation ℓbased
on their uniform moduli of continuity as needed. To simplify the algorithm, it
assumes total assignments as input. It is possible to relax this requirement, e.g.,
by invoking rules (A) or (R) instead of returning δ-sat for partial assignments.

The ksmt Calculus Is a δ-complete Decision Procedure
123
Algorithm 1 (nlinStepδ) Algorithm computing a δ-ksmt derivation according
to either rule (L) or (F sat
δ
) from a state (α, L, N) where α is total. The functions
f are assumed to be computed by machines M ?
f and μf to be a computable
uniform modulus of continuity of f.
function lineariseδ(f, x, ⋄, α)
compute p ≥−⌊log2(min{1, δ/4})⌋
ϕ ←(n →xα)
ϵ ←2−μf (p)
˜y ←M ϕ
f (p)
if ˜y ⋄−δ/2 then
return None
end if
return (x /∈B(xα, ϵ))
end function
function nlinStepδ(α, L, N)
for P : (f(x) ⋄0) in N do
ℓ←lineariseδ(f, x, ⋄, α)
if ℓ̸= None then
return (α, L ∪{ℓ}, N)
▷(L)
end if
end for
return δ-sat
▷(F sat
δ
)
end function
Lemma 3. Let δ ∈Q>0 and let S = (α, L, N) be a δ-ksmt state where α is
total and Lα = true. Then nlinStepδ(α, L, N) computes a state derivable by
application of either (L) or (F sat
δ
) to S.
Proof. In the proof we will use notions from computable analysis, as deﬁned
in Section 2. Let (α, L, N) be a state as in the premise and let P : f(x) ⋄0
be a non-linear constraint in N. Let M ?
f compute f as in Algorithm 1. The
algorithm computes a rational approximation ˜y = M (xα)i
f
(p) of f(xα) where
p ≥−⌊log2(min{1, δ/4})⌋∈N. Lα = true implies xα ∈DP ⊆dom f, thus
the computation of ˜y terminates. Since M ?
f computes f, ˜y is accurate up to
2−p ≤δ/4, that is, ˜y ∈[f(xα) ± δ/4]. By assumption ⋄∈{>, ≥}, thus
1. ˜y ⋄−δ/2 implies f(xα) ⋄−δ, which is equivalent to Pδα = true, and
2. ¬(˜y ⋄−δ/2) implies ¬(f(xα) ⋄−δ/2 + δ/4), which in turn implies Pα =
false and the applicability of rule (L).
For Item 1 no linearisation is necessary and indeed the algorithm does not lin-
earise P. Otherwise (Item 2), it adds the linearisation (x /∈B(xα, ϵ)) to the
linear clauses. Since xα ∈DP by Eq. (2.1) we obtain that 0 /∈B(f(z), δ/4)
holds, implying ¬(f(z)⋄0), for all z ∈B(xα, ϵ)∩Ě
DP . Hence, (x /∈B(xα, ϵ))
is a linearisation of P at α.
In case nlinStepδ(α, L, N) returns δ-sat, the premise of Item 1 holds for
every non-linear constraint in N, that is, Nδα = true. By assumption Lα =
true, hence the application of the (F sat
δ
) rule deriving δ-sat is possible in δ-ksmt.
Lemma 4. For any bounded instance L0 ∧N there is a computable ϵ ∈Q>0
such that any δ-ksmt run starting in (nil, L0, N), where applications of (L) and
(F sat
δ
) are performed by nlinStepδ, is ϵ-full.
Proof. Let P : f(x) ⋄0 be a non-linear constraint in N. Since L0 ∧N is a
bounded instance, DP ⊆Rn is also bounded. Let ϵP := 2−μf (p) where p ≥

124
F. Brauße, K. Korovin, M. V. Korovina, N. Th. Müller
−⌊log2(min{1, δ/4})⌋∈N as in Algorithm 1. As μf is a uniform modulus of con-
tinuity, the inequalities in the following construction hold on the whole domain
Ě
DP of f and do not depend on the concrete assignment α where the linearisa-
tion is performed. Since log2 and μf are computable, so are p and ϵP . There
are ﬁnitely many non-linear constraints P in N, therefore the linearisations the
algorithm nlinStepδ computes are ϵ-full with ϵ = min{ϵP : P in N} > 0.
We call δ-ksmt derivations when linearisation are computed using Algo-
rithm 1 δ-ksmt with full-box linearisations, or δ-ksmt-fb for short. As the runs
computed by it are ϵ-full for ϵ > 0, by Theorem 1 they terminate.
Theorem 3. δ-ksmt-fb is a δ-complete decision procedure.
Proof. δ-ksmt-fb is sound (Theorem 2) and terminates on bounded instances
(Theorem 1 and Lemma 4).
6
Local ϵ-full Linearisations
In practice, when the algorithm computing ϵ-full linearisations described in the
previous section is going to be implemented, the question arises of how to get a
good uniform modulus of continuity μf for a computable function f. Depending
on how f is given, there may be several ways of computing it. Implementations
of exact real arithmetic, e.g., iRRAM [24] and Ariadne [2], are usually based on
the formalism of function-oracle Turing machines (see Deﬁnition 1) which allow
to compute with representations of computable functions [10] including implicit
representations of functions as solutions of ODEs/PDEs [26,9]. If f is only avail-
able as a function-oracle Turing machine M ?
f computing it, a modulus μf valid
on a compact domain can be computed, however, in general this is not possible
without exploring the behaviour of the function on the whole domain, which in
many cases is computationally expensive. Moreover, since μf is uniform, μf(n)
is constant throughout DF , independent of the actual assignment α determining
where f is evaluated. Yet, computable functions admit local moduli of continuity
that additionally depend on the concrete point in their domain. In most cases
these would provide linearisations with ϵ larger than that determined by μf lead-
ing to larger regions being excluded, ultimately resulting in fewer linearisation
steps and general speed-up. Indeed, machines producing ﬁnite approximations
of f(x) from ﬁnite approximations of x internally have to compute some form of
local modulus to guarantee correctness. In this section, we explore this approach
of obtaining linearisations covering a larger part of the function’s domain.
In order to guarantee a positive bound on the local modulus of continuity
extracted directly from the run of the machine M ?
f computing f, it is neces-
sary to employ a restriction on the names of real numbers M ?
f computes on.
The set of names should in a very precise sense be “small”, i.e., it has to be
compact. The very general notion of names used in Deﬁnition 1 is too broad to
satisfy this criterion since the space of rational approximations is not even locally
compact. Here, we present an approach using practical names of real numbers as

The ksmt Calculus Is a δ-complete Decision Procedure
125
sequences of dyadic rationals of lengths restricted by accuracy. For that purpose,
we introduce another representation [31] of R, that is, the surjective mapping
ξ : Dω →R. Here, Dω denotes the set of inﬁnite sequences ϕ of dyadic rationals
with bounded length. If ϕ has a limit (in R), we write lim ϕ.
Deﬁnition 6.
– For k ∈ω let Dk := Z · 2−(k+1) = {m/2k+1 : m ∈Z} ⊂Q
and let Dω :=×k∈ω Dk be the set of all sequences (ϕk)k with ϕk ∈Dk for
all k ∈ω. By default, Dω is endowed with the Baire space topology, which
corresponds to that induced by the metric
d : (ϕ, ψ) →

0
if ϕ = ψ
1/min{1 + n : n ∈ω, ϕn ̸= ψn}
otherwise.
– Deﬁne ξ : Dω →R as the partial function mapping ϕ ∈Dω to lim ϕ iﬀ
∀i, j : |ϕi −ϕi+j| ≤2−(i+1). Any ϕ ∈ξ−1(x) is called a ξ-name of x ∈R.
– The representation ρ : (xk)k →x mapping names (xk)k of x ∈R to x as per
Deﬁnition 1 is called Cauchy representation.
Using a standard product construction we can easily generalise the notion of
ξ-names to ξn-names of Rn. When clear from the context, we will drop n and
just write ξ to denote the corresponding generalised representation Dn
ω →Rn.
Computable equivalence between two representations not only implies that
there are continuous maps between them but also that names can computably
be transformed [31]. Since the Cauchy representation itself is continuous [4] we
derive continuity of ξ, which is used below to show compactness of preimages
ξ−1(X) of compact sets X ⊆R under ξ. All proofs can be found in [8].
Lemma 5. The following properties hold for ξ.
1. ξ is a representation of Rn: it is well-deﬁned and surjective.
2. Any ξ-name of x ∈Rn is a Cauchy-name of x.
3. ξ is computably equivalent to the Cauchy representation.
4. ξ is continuous.
The converse of Item 2 does not hold. An example for a Cauchy-name of 0 ∈R
is the sequence (xn)n with xn = (−2)−n for all n ∈ω, which does not satisfy
∀i, j : |xi −xi+j| ≤2−(i+1). However, given a name of a real number, we can
compute a corresponding ξ-name, this is one direction of the property in Item 3.
As a consequence of Item 2 a function-oracle machine M ? computing f :
Rn →R according to Deﬁnition 1 can be run on ξ-names of x ∈Rn leading
to valid Cauchy-names of f(x). Note that this proposition does not require
M ?
f to compute a ξ-name of f(x). Any rational sequence rapidly converging
to f(x) is a valid output. This means, that the model of computation remains
unchanged with respect to the earlier parts of this paper. It is the set of names the
machines are operated on, which is restricted. This is reﬂected in Algorithm 2
by computing dyadic rational approximations ˜xk of xα such that ˜xk ∈Dn
k
instead of keeping the name of xα constant as has been done in Algorithm 1.

126
F. Brauße, K. Korovin, M. V. Korovina, N. Th. Müller
Algorithm 2 (Local linearisation) Algorithm δ-deciding P : f(x) ⋄0 and –
in case unsat – computing a linearisation at α or returning “None” and in this
case α satisﬁes Pδ. The function f is computed by machine M ?
f.
function LineariseLocalδ(f, x, ⋄, α)
ϕ ←(m →approx(xα, m))
▷then ϕ is a ξ-name of xα
compute p ≥−⌊log2(min{1, δ/4})⌋
run M ϕ
f (p + 2), record its output ˜y and its maximum query k ∈ω to ϕ
if ˜y ⋄−δ/2 then
return None
else
return (x /∈B(xα, 2−k))
end if
end function
In particular, in Theorem 4 we show that linearisations for the (Lδ) rule can
be computed by Algorithm 2, which – in contrast to lineariseδ in Algorithm 1
– does not require access to a procedure computing an upper bound μf on the
uniform modulus of continuity of the non-linear function f ∈Fnl valid on the
entire bounded domain. It not just runs the machine M ?
f, but also observes the
queries M ϕ
f poses to its oracle in order to obtain a local modulus of continuity of
f at the point of evaluation. The function approx(x, m) := ⌊x · 2m+1⌉/2m+1 used
to deﬁne Algorithm 2 computes a dyadic approximation of x, with ⌊·⌉: Qn →Zn
denoting a rounding operation, that is, it satisﬁes ∀q : ∥⌊q⌉−q∥≤
1
2. On
rationals (our use-case), ⌊·⌉is computable by a classical Turing machine.
Deﬁnition 7 ([31, Deﬁnition 6.2.6]).
Let f : Rn →R and x ∈dom f. A
function γ : N →N is called a (local) modulus of continuity of f at x if for all
p ∈N and y ∈dom f, ∥x −y∥≤2−γ(p) =⇒|f(x) −f(y)| ≤2−p holds.
We note that in most cases a local modulus of continuity of f at x is smaller
than the best uniform modulus of f on its domain, since it only depends on the
local behaviour of f around x. One way of computing a local modulus of f at x
is using the function-oracle machine M ?
f as deﬁned next.
Deﬁnition 8. Let M ?
f compute f : Rn →R and let x ∈dom f have Cauchy-
name ϕ. The function γM ?
f ,ϕ : p →max{0, k : M ϕ
f (p + 2) queries index k of ϕ}
is called the eﬀective local modulus of continuity induced by M ?
f at ϕ.
The eﬀective local modulus of continuity of f at a name ϕ of x ∈dom f indeed is
a local modulus of continuity of f at x [17, Theorem 2.13]. Algorithm 2 computes
ϵ-full linearisations by means of the eﬀective local modulus [8], as stated next.
Lemma 6. Let P : f(x)⋄0 be a non-linear constraint in N and α be an assign-
ment of x to rationals in dom f. Whenever C = LineariseLocalδ(f, x, ⋄, α)
and C ̸= None, C is an ϵ-full linearisation of P at α, with ϵ corresponding to
the eﬀective local modulus of continuity induced by M ?
f at a ξ-name of xα.

The ksmt Calculus Is a δ-complete Decision Procedure
127
Thus, the function lineariseLocalδ in Algorithm 2 is a drop-in replacement
for lineariseδ in Algorithm 1 since the condition on returning a linearisation of
P versus accepting Pδ is identical. The linearisations however diﬀer in the radius
ϵ, which now, according to Lemma 6, corresponds to the eﬀective local modulus
of continuity. The resulting procedure we call nlinStepLocalδ. One of its ad-
vantages over nlinStepδ is running M ?
f on ξ-names instead of Cauchy-names,
is that they form a compact set for bounded instances, unlike the latter. This
allows us to bound ϵ > 0 for the computed ϵ-full local linearisations of otherwise
arbitrary δ-ksmt runs. A proof of the following Lemma showing compactness of
preimages ξ−1(X) of compact sets X ⊆R under ξ is given in [8].
Lemma 7. Let X ⊂Rn be compact. Then the set ξ−1(X) ⊂Dn
ω of ξ-names of
elements in X is compact as well.
The proof involves showing ξ−1(X) to be closed and uses the fact that for each
component ϕk of names (ϕk)k of x ∈X there are just ﬁnitely many choices
from Dk due to the restriction of the length of the dyadics. This is not the case
for the Cauchy representation used in Deﬁnition 1 and it is the key for deriving
existence of a strictly positive lower bound ϵ on the ϵ-fullness of linearisations.
Theorem 4. Let δ ∈Q>0. For any bounded instance L0 ∧N there is ϵ > 0
such that any δ-ksmt run starting in (nil, L0, N), where applications of (L) and
(F sat
δ
) are performed according to nlinStepLocalδ, is ϵ-full.
Proof. Assume L0 ∧N is a bounded instance. Set ϵ := min{ϵP : P ∈N}, where
ϵP is deﬁned as follows. Let P : f(x)⋄0 in N. Then the closure Ě
DP of the bounded
set DP is compact. Let E be the set of ξ-names of elements of Ě
DP ⊆dom f (see
Deﬁnition 6) and for any ϕ ∈E let kϕ be deﬁned as γM ?
f ,ϕ(p) (see Deﬁnition 8)
where p is computed from δ as in Algorithm 2 and is independent of ϕ. Since the
preimage of each kϕ is open, the function ϕ →kϕ is continuous. By Lemma 7
the set E is compact, thus, there is ψ ∈E such that 2−kψ = inf{2−kϕ : ϕ ∈E}.
Set ϵP := 2−kψ. The claim then follows by Lemma 6.
Thus we can conclude.
Corollary 1. δ-ksmt with local linearisations is a δ-complete decision procedure.
7
Conclusion
In this paper we extended the the ksmt calculus to the δ-satisﬁability setting
and proved that the resulting δ-ksmt calculus is a δ-complete decision procedure
for solving non-linear constraints over computable functions which include poly-
nomials, exponentials, logarithms, trigonometric and many other functions used
in applications. We presented algorithms for constructing ϵ-full linearisations
ensuring termination of δ-ksmt. Based on methods from computable analysis
we presented an algorithm for constructing local linearisations. Local lineari-
sations exclude larger regions from the search space and can be used to avoid
computationally expensive global analysis of non-linear functions.

128
F. Brauße, K. Korovin, M. V. Korovina, N. Th. Müller
References
1. Bard, J., Becker, H., Darulova, E.: Formally veriﬁed roundoﬀerrors using SMT-
based certiﬁcates and subdivisions. In: ter Beek, M.H., McIver, A., Oliveira, J.N.
(eds.) Formal Methods - The Next 30 Years - Third World Congress, FM 2019,
Proceedings. LNCS, vol. 11800, pp. 38–44. Springer (2019)
2. Benvenuti, L., Bresolin, D., Collins, P., Ferrari, A., Geretti, L., Villa, T.: As-
sume–guarantee veriﬁcation of nonlinear hybrid systems with Ariadne. Interna-
tional Journal of Robust and Nonlinear Control 24(4), 699–724 (2014)
3. Bonacina, M.P., Graham-Lengrand, S., Shankar, N.: Conﬂict-driven satisﬁability
for theory combination: Transition system and completeness. J. Autom. Reason.
64(3), 579–609 (2020)
4. Brattka, V., Hertling, P.: Topological properties of real number representations.
Theor. Comput. Sci. 284(2), 241–257 (2002)
5. Brattka, V., Hertling, P., Weihrauch, K.: A Tutorial on Computable Analysis, pp.
425–491. Springer New York, New York, NY (2008)
6. Brauße, F., Khasidashvili, Z., Korovin, K.: Selecting stable safe conﬁgurations for
systems modelled by neural networks with ReLU activation. In: Ivrii, A., Strich-
man, O. (eds.) 2020 Formal Methods in Computer Aided Design, FMCAD 2020.
pp. 119–127. IEEE (2020)
7. Brauße, F., Korovin, K., Korovina, M.V., Müller, N.T.: A CDCL-style calculus
for solving non-linear constraints. In: Herzig, A., Popescu, A. (eds.) Frontiers of
Combining Systems - 12th International Symposium, FroCoS 2019, Proceedings.
LNCS, vol. 11715, pp. 131–148. Springer (2019)
8. Brauße, F., Korovin, K., Korovina, M.V., Müller, N.T.: The ksmt calculus is a
δ-complete decision procedure for non-linear constraints. CoRR abs/2104.13269
(2021)
9. Brauße, F., Korovina, M.V., Müller, N.T.: Towards using exact real arithmetic for
initial value problems. In: Mazzara, M., Voronkov, A. (eds.) Perspectives of System
Informatics - 10th International Andrei Ershov Informatics Conference, PSI 2015,
in Memory of Helmut Veith, Revised Selected Papers. LNCS, vol. 9609, pp. 61–74.
Springer (2015)
10. Brauße, F., Steinberg, F.: A minimal representation for continuous functions.
CoRR abs/1703.10044 (2017)
11. Cimatti, A., Griggio, A., Irfan, A., Roveri, M., Sebastiani, R.: Incremental lin-
earization for satisﬁability and veriﬁcation modulo nonlinear arithmetic and tran-
scendental functions. ACM Trans. Comput. Log. 19(3), 19:1–19:52 (2018)
12. Fontaine, P., Ogawa, M., Sturm, T., Vu, X.: Subtropical satisﬁability. In: Dixon, C.,
Finger, M. (eds.) Frontiers of Combining Systems - 11th International Symposium,
FroCoS 2017, Proceedings. LNCS, vol. 10483, pp. 189–206. Springer (2017)
13. Gao, S., Avigad, J., Clarke, E.M.: δ-complete decision procedures for satisﬁability
over the reals. In: Gramlich, B., Miller, D., Sattler, U. (eds.) Automated Reasoning
- 6th International Joint Conference, IJCAR 2012, Proceedings. LNCS, vol. 7364,
pp. 286–300. Springer (2012)
14. Gao, S., Avigad, J., Clarke, E.M.: Delta-decidability over the reals. In: Proceedings
of the 27th Annual IEEE Symposium on Logic in Computer Science, LICS 2012.
pp. 305–314. IEEE Computer Society (2012)
15. Hales, T.C., Adams, M., Bauer, G., Dang, D.T., Harrison, J., Hoang, T.L.,
Kaliszyk, C., Magron, V., McLaughlin, S., Nguyen, T.T., Nguyen, T.Q., Nipkow,
T., Obua, S., Pleso, J., Rute, J.M., Solovyev, A., Ta, A.H.T., Tran, T.N., Trieu,

The ksmt Calculus Is a δ-complete Decision Procedure
129
D.T., Urban, J., Vu, K.K., Zumkeller, R.: A formal proof of the Kepler conjecture.
CoRR abs/1501.02155 (2015)
16. Jovanovic, D., de Moura, L.: Solving non-linear arithmetic. ACM Commun. Com-
put. Algebra 46(3/4), 104–105 (2012)
17. Ko, K.: Complexity Theory of Real Functions. Birkhäuser / Springer (1991)
18. Korovin, K., Kosta, M., Sturm, T.: Towards conﬂict-driven learning for virtual
substitution. In: Gerdt, V.P., Koepf, W., Seiler, W.M., Vorozhtsov, E.V. (eds.)
Computer Algebra in Scientiﬁc Computing - 16th International Workshop, CASC
2014, Proceedings. LNCS, vol. 8660, pp. 256–270. Springer (2014)
19. Korovin, K., Tsiskaridze, N., Voronkov, A.: Conﬂict resolution. In: Gent, I.P. (ed.)
Principles and Practice of Constraint Programming - CP 2009, 15th International
Conference, CP 2009, Proceedings. LNCS, vol. 5732, pp. 509–523. Springer (2009)
20. Korovin, K., Voronkov, A.: Solving systems of linear inequalities by bound prop-
agation. In: Bjørner, N., Sofronie-Stokkermans, V. (eds.) Automated Deduction -
CADE-23 - 23rd International Conference on Automated Deduction, Proceedings.
LNCS, vol. 6803, pp. 369–383. Springer (2011)
21. Kurátko, J., Ratschan, S.: Combined global and local search for the falsiﬁcation
of hybrid systems. In: Legay, A., Bozga, M. (eds.) Formal Modeling and Analysis
of Timed Systems - 12th International Conference, FORMATS 2014, Proceedings.
LNCS, vol. 8711, pp. 146–160. Springer (2014)
22. de Moura, L.M., Jovanovic, D.: A model-constructing satisﬁability calculus. In:
Giacobazzi, R., Berdine, J., Mastroeni, I. (eds.) Veriﬁcation, Model Checking, and
Abstract Interpretation, 14th International Conference, VMCAI 2013, Proceed-
ings. LNCS, vol. 7737, pp. 1–12. Springer (2013)
23. de Moura, L.M., Passmore, G.O.: Computation in real closed inﬁnitesimal and
transcendental extensions of the rationals. In: Bonacina, M.P. (ed.) Automated
Deduction - CADE-24 - 24th International Conference on Automated Deduction,
Proceedings. LNCS, vol. 7898, pp. 178–192. Springer (2013)
24. Müller, N.T.: The iRRAM: Exact arithmetic in C++. In: Blanck, J., Brattka, V.,
Hertling, P. (eds.) Computability and Complexity in Analysis, 4th International
Workshop, CCA 2000, Selected Papers. LNCS, vol. 2064, pp. 222–252. Springer
(2000)
25. Platzer, A.: Logical Foundations of Cyber-Physical Systems. Springer (2018)
26. Pour-El, M.B., Richards, J.I.: Computability in analysis and physics. Perspectives
in Mathematical Logic, Springer (1989)
27. Richardson, D.: Some undecidable problems involving elementary functions of a
real variable. J. Symb. Log. 33(4), 514–520 (1968)
28. Silva, J.P.M., Sakallah, K.A.: GRASP - a new search algorithm for satisﬁability.
In: Rutenbar, R.A., Otten, R.H.J.M. (eds.) Proceedings of the IEEE/ACM Inter-
national Conference on Computer-Aided Design, ICCAD 1996. pp. 220–227. IEEE
Computer Society / ACM (1996)
29. Tiwari, A., Lincoln, P.: A search-based procedure for nonlinear real arithmetic.
Formal Methods Syst. Des. 48(3), 257–273 (2016)
30. Tung, V.X., Khanh, T.V., Ogawa, M.: raSAT: An SMT solver for polynomial
constraints. In: Olivetti, N., Tiwari, A. (eds.) Automated Reasoning - 8th Interna-
tional Joint Conference, IJCAR 2016, Proceedings. LNCS, vol. 9706, pp. 228–237.
Springer (2016)
31. Weihrauch, K.: Computable Analysis – An Introduction. Texts in Theoretical Com-
puter Science. An EATCS Series, Springer (2000)
32. Willard, S.: General Topology. Addison-Wesly (1970)

130
F. Brauße, K. Korovin, M. V. Korovina, N. Th. Müller
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Universal Invariant Checking of Parametric
Systems with Quantiﬁer-free SMT Reasoning
Alessandro Cimatti
, Alberto Griggio
, and Gianluca Redondi
Fondazione Bruno Kessler, Trento, Italy
{cimatti, griggio, gredondi}@fbk.eu
Abstract. The problem of invariant checking in parametric systems –
which are required to operate correctly regardless of the number and
connections of their components – is gaining increasing importance in
various sectors, such as communication protocols and control software.
Such systems are typically modeled using quantiﬁed formulae, describ-
ing the behaviour of an unbounded number of (identical) components,
and their automatic veriﬁcation often relies on the use of decidable frag-
ments of ﬁrst-order logic in order to eﬀectively deal with the challenges
of quantiﬁed reasoning.
In this paper, we propose a fully automatic technique for invariant check-
ing of parametric systems which does not rely on quantiﬁed reason-
ing. Parametric systems are modeled with array-based transition sys-
tems, and our method iteratively constructs a quantiﬁer-free abstraction
by analyzing, with SMT-based invariant checking algorithms for non-
parametric systems, increasingly-larger ﬁnite instances of the parametric
system. Depending on the veriﬁcation result in the concrete instance, the
abstraction is automatically reﬁned by leveraging canditate lemmas from
inductive invariants, or by discarding previously computed lemmas.
We implemented the method using a quantiﬁer-free SMT-based IC3
as underlying veriﬁcation engine. Our experimental evaluation demon-
strates that the approach is competitive with the state of the art, solving
several benchmarks that are out of reach for other tools.
Keywords: Parametric Systems · Array-based transitions systems ·
Abstraction-reﬁnement · SMT
1
Introduction
Parametric systems consist of a ﬁnite but unbounded number of components. Ex-
amples include communication protocols (e.g. leader election), feature systems,
or control algorithms in various application domains (e.g. railways interlocking
logics). The key challenge is to prove the correctness of the parametric system
for all possible conﬁgurations corresponding to instantiations of the parameters.
Parametric systems can be described as symbolic array-based transition sys-
tems [10], where the dependence on the conﬁguration is expressed with ﬁrst-order
quantiﬁers in the initial condition and the transition relation of the model.
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp. 131 147, 2021.
https://doi.org/10.1007/978-3-030-79876-5 8
–

132
Alessandro Cimatti, Alberto Griggio, and Gianluca Redondi
In this paper, we propose a fully automated approach for solving the uni-
versal invariant problem of array-based systems. The distinguishing feature is
that the approach, grounded in SMT, does not require dealing with quantiﬁed
theories, with obvious computational advantages. The algorithm implements an
abstraction-reﬁnement loop, where the abstract space is a quantiﬁer-free transi-
tion system over some SMT theories. Our inspiration and starting point is the Pa-
rameter Abstraction of [3,15], which we extend in two directions. First, we modify
the deﬁnition of the abstraction, by introducing a set of diﬀerent environment
variables, which intuitively overapproximate the behaviour of all the instances
not precisely tracked by the abstraction, and by introducing a special stuttering
transition in which the environment is allowed to change non-deterministically.
Second, we combine the abstraction with a method for automatically inferring
candidate universal lemmas, which are used to strengthen the abstraction in case
of spurious counterexamples. The candidate lemmas are obtained by generaliza-
tion from the spuriousness proof carried out in a ﬁnite-domain instantiation of
the concrete system. However, we do not require quantiﬁed reasoning to prove
that they universally hold; rather, the algorithm takes into account the fact that
candidate lemmas may turn out not to be universally valid. In such cases, the
method is able to automatically discover such bad lemmas and discard them, by
examining increasingly-higher-dimension bounded instances of the parametric
system.
We implemented the method in a tool called Lambda. At its core, Lambda
leverages modern model checking approaches for quantiﬁer-free inﬁnite-state
systems, i.e. the SMT-based approach of IC3 with implicit abstraction [4], in
contrast to other approaches [19] where the abstract space is Boolean. In our
experimental evaluation, we compared Lambda with the state-of-the-art tools
MCMT [11] and Cubicle [7]. The results show the advantage of the approach,
that is able to solve multiple benchmarks that are out of reach for its competi-
tors.
The rest of the paper is structured as follows. In Section 2 we present some
logical background, and in Section 3 we describe array-based systems. We give
an informal overview of the algorithm in Section 4. In Section 5 we deﬁne the
abstraction and state its formal properties. In Section 6 we discuss the approach
to concretization and reﬁnement, and we present the techniques for inferring
candidate lemmas. We discuss the related work in Section 7, and we present
our experimental evaluation in Section 8. Finally, in Section 9 we draw some
conclusions and present directions for future work. For lack of space, the proofs
of our theoretical results, as well as further details on our experiments, are
reported in an extended techical report [5].
2
Preliminaries
Our setting is standard ﬁrst order logic. A theory T in the SMT sense is a pair
T = (Σ, C), where Σ is a ﬁrst order signature and C is a class of models over
Σ. A theory T is closed under substructure if its class C of structures is such

Invariant Checking of Parametric Systems via Quantiﬁer-free SMT
133
that whenever M ∈C and N is a substructure of M, then N ∈C. We use the
standard notions of Tarskian interpretation (assignment, model, satisﬁability,
validity, logical consequence). We refer to 0-arity predicates as Boolean variables,
and to 0-arity uninterpreted functions as (theory) variables. A literal is an atom
or its negation. A clause is a disjunction of literals. A formula is in conjunctive
normal form (CNF) iﬀit is a conjuction of clauses. If x1, ..., xn are variables
and φ is a formula, we might write φ(x1, ..., xn) to indicate that all the variables
occurring free in φ are in x1, ..., xn.
If φ is a formula, t is a term and v is a variable which occurs free in φ, we write
φ[v/t] for the substitution of every occurrence of v with t. If t and v are vectors
of the same length, we write φ[v/t] for the simultaneous substitution of each vi
with the corresponding term ti. We use an if-then-else notation for formulae.
We write if φ1 then ψ1 elif φ2 then ψ2 elif . . . ψn−1 else ψn to denote the
formula (φ1 →ψ1) ∧((¬φ1 ∧φ2) →ψ2) ∧. . . ((¬φ1 . . . ¬φn−1 ∧¬φn) →ψn).
Given a set of variables v, we denote with v′ the set {v′|v ∈v}. A symbolic
transition system is a triple (v, I(v), T(v, v′)), where v is a set of variables, and
I(v), T(v, v′) are ﬁrst order formulae over some signature. An assignment to
the variables in v is a state. A state s is initial iﬀit is a model of I(v), i.e.
s |= I(v). The states s, s′ denote a transition iﬀs ∪s′ |= T(v, v′), also written
T(s, s′). A path is a sequence of states s0, s1, . . . such that s0 is initial and
T(si, s′
i+1) for all i. We denote paths with π, and with π[j] the j-th element of
π. A state s is reachable iﬀthere exists a path π such that π[i] = s for some i. A
variable v is frozen iﬀfor all π, i it holds that π[i](v) = π[0](v). In the following,
when we deﬁne a frozen variable v, we assume that this is done by having a
constraint v′ = v as a top-level conjunct of the transition formula. A formula
φ(v) is an invariant of the transition system C = (v, I(v), T(v, v′)) iﬀit holds
in all the reachable states. Following the standard model checking notation, we
denote this with C |= φ(v).1A formula φ(v) is an inductive invariant for C iﬀ
I(v) |= φ(v) and φ(v) ∧T(v, v′) |= φ(v′).
3
Modeling Parametric Systems as Array-based
Transition Systems
In order to describe parametric systems, we adapt from [10] the notion of array-
based systems. In the following, we ﬁx a theory of indexes TI = (ΣI, CI) and a
theory of elements TE = (ΣE, CE). In order to model the parameters, we require
that the class CI is closed under substructure. Then with AE
I we denote the
theory whose signature is Σ = ΣI ∪ΣE ∪{[ ]}, and a model for it is given by
a set of total functions from a model of TI to a model of TE. In general, we
can have several array theories with multiple sorts for indexes and elements.
1 Note that we use the symbol |= with three diﬀerent denotations: if φ, ψ are formulae,
φ |= ψ denotes that ψ is a logical consequence of φ; if μ is an interpretation, and
ψ is a formula, μ |= ψ denotes that μ is a model of ψ; if C is a transition system,
C |= ψ denotes that ψ is an invariant of C.

134
For simplicity, we ﬁx only an index sort and an elem sort. In the following, an
array-based transition system
C = (a, ι(a), τ(a, a′))
is a symbolic transition system, with the additional constraints that:
– a is a variable of sort index →elem. We use a single variable for the sake
of simplicity: additional variables of arbitrary type (also of index or element
type) can be added without loss of generality.
– ι(a) is a ﬁrst-order formula of the form ∀i.φ(i, a[i]), where i is of index sort
and φ is a quantiﬁer-free formula.
– τ(a, a′) is a ﬁnite disjunction of formulae, ∨n
k=1τk, such that every τk is a
formula of the following type (with i, j of index sort):
∃i∀j.ψ(i, j, a[i], a[j], a′[i], a′[j])
with ψ a quantiﬁer-free formula.
This syntactic requirement subsumes the common guard and update formalism
used for the description of parametric systems, used e.g in [10,12,15].
In the following, we shall refer to the disjuncts τk of τ as transition rules (or
simply rules when clear from the context).
An array-based transition system can be seen as a family of transition sys-
tems, one for each cardinality of the ﬁnite models MI of TI. In the following,
given d an integer, we denote with Cd the ﬁnite instance of C of size d obtained
by instantiating the quantiﬁers of C over a set of fresh index variables of car-
dinality d (considered implicitly diﬀerent from each other). Note that this Cd
is a symmetric presentation [15]: if c = {c1, . . . , cd} are the fresh index vari-
ables, and σ is a permutation of c, we have that, for every formula φ(c, a[c]),
Cd |= φ(c, a[c]) ⇔Cd |= φ(σ(c), a[σ(c)]).
Example 1 (Mutex Protocol for Ring Topology). Here we describe a simple pro-
tocol for accessing a shared resource, with processes in a ring-shaped topol-
ogy. As an index theory, we use the ﬁnite sets of integers. As an element the-
ory, we use both the Booleans and an enumerated data type of two elements,
namely {idle, critical}. The array variable t, with sort index →boolean, is
true in an index variable x if x holds the token. The variable s, with sort
index →{idle, critical} holds the current state of the process. In addition,
we have an integer frozen variable length, which represents the length of the
ring. The transition system is described by the following formulae:
Initial states. Initially, only one process holds the token, and every process is
idle. We model this initial process with an additional constant init token
of sort index. Moreover, each index is bounded by the value of length. The
initial formula is:
∀j.p[j] = idle ∧j ≥1 ∧j ≤length ∧length > 0
∧

if j = init token then t[j] = true
else t[j] = false
Alessandro Cimatti, Alberto Griggio, and Gianluca Redondi

Invariant Checking of Parametric Systems via Quantiﬁer-free SMT
135
Transition rule 1. A process which holds the token can enter the critical sec-
tion:
∃i.s[i] = idle ∧t[i] = true ∧s′[i] = critical ∧t′[i] = t[i]∧
∀j, j ̸= i.(s′[j] = s[j] ∧t′[j] = t[j])
Transition rule 2. A process exits from the critical section and passes the
token to the process at its right:
∃i. ∧s[i] = critical ∧s′[i] = idle ∧t′[i] = false∧
∀j, j ̸= i.
⎧
⎪
⎨
⎪
⎩
if j = 1 ∧i = length then s′[j] = s[j] ∧t′[j] = true
elif j = i + 1 ∧i < length then s′[j] = s[j] ∧t′[j] = true
else s′[j] = s[j] ∧t′[j] = t[j]
3.1
Universal invariant problem for array-based systems
In the following, given an array-based transition system
C = (a, ι(a), τ(a, a′)),
the universal invariant problem is the problem of proving (or disproving) that a
formula of the form Φ
def
= ∀i.φ(i, a[i]) is an invariant for C.
Guard Strengthening In order to prove that ∀i.φ(i, a[i]) is an invariant of a
system C = (a, ι(a), τ(a, a′)), we can ﬁrst strengthen the rules of C by adding the
candidate invariant in conjunction with the transition relation, and then prove
that the formula is an invariant of the newly-restricted system. This induction
principle is justiﬁed by the following proposition:
Proposition 1 (Guard strenghtening [15]) Let C = (a, ι(a), τ(a, a′)) be a
transition system and let Φ be ∀i.φ(i, a[i]). Let CΦ = (a, ι(a), τ(a, a′) ∧Φ) be the
guard-strengthening of C with respect to Φ. Then, if Φ is an invariant of CΦ, it
is also an invariant of C.
Prophecy variables The universal quantiﬁers in the candidate invariant can
be replaced with fresh frozen variables, called prophecy variables, that intuitively
contain the indexes of the processes witnessing the violation of the property.
Proposition 2 (Removing quantiﬁers [19]) Let C = (a, ι(a), τ(a, a′)) be an
array-based system. The formula ∀i.φ(i, a[i]) is an invariant for C iﬀthe formula
φ(p, a[p]) is an invariant for C+p = (a∪p, ι(a), τ(a, a′)), where p is a set of fresh
frozen variables of index sort.
For better readability, in the following we will omit the subscript +p. More-
over, we assume that the index variables universally quantiﬁed in the candidate
invariant are considered to be diﬀerent. This does not limit expressiveness, and
simpliﬁes our discourse. Therefore, the prophecy variables induced by a candi-
date invariant are considered to be implicitly diﬀerent.

136
C, Φ
Ψ
Guard
Strengthening
Parameter
Abstraction
Prophecies Computation
Environment Computation
Instantiation
˜CΦ∧Ψ |= ˜Φ ∧˜Ψ?
Safe
˜π Abstract Cex
Analysis
˜π concretizable?
violates Φd?
Reﬁnement
by Generalization
Compute lemma from
Inductive invariant Id
Find and ﬁx
bad lemmas
Unsafe
CΦ∧Ψ
yes
no
yes
no
yes
no
Fig. 1. An overview of the algorithm. C is an array-based transition system; Φ is a
quantiﬁed candidate invariant; Ψ
def
= {ψ1, . . . ψn} is the set of candidate lemmas; CΦ∧Ψ
is a quantiﬁed transition system resulting from the strengthening of C; ˜CΦ∧Ψ is a
quantiﬁer-free transition system.
4
Overview of the Method
In the following, let an array-based transition system C
def
= (a, ι(a), τ(a, a′)), and
a candidate universal invariant Φ
def
= ∀i.φ(i, a[i]) for C be given.
We now summarize the algorithm that attempts to solve the universal invari-
ant problem for C and Φ. The algorithm, depicted in Figure
either to construct an abstraction suﬃciently precise to prove the property (exit
with Safe), or to ﬁnd a ﬁnite instantiation of the problem exhibiting a concrete
counterexample (exit with Unsafe). The abstract space is quantiﬁer-free, and
obtained by instantiating the universally quantiﬁed formulae over two sets of in-
dex variables: the prophecy variables, which arise from the candidate invariant
(as explained in Proposition 2), and are denoted with p; and the environmen-
tal variables, denoted with x, which arise from the transition formula and are
intended to represent the environment surrounding the p indexes, interacting
with them in the behaviour leading to the violation. While prophecy variables
are frozen, thus representing the same indexes for the whole run, environmental
variables are free to change at each time step, hence producing possibly spuri-
ous behaviours. The algorithm maintains a set of candidate lemmas Ψ
def
= {Ψi}i,
composed of universally quantiﬁed formulae, that are used to strengthen the
property and to tighten the abstraction. Initially, Ψ is empty. In the following, if
Cd is a ﬁnite instance of C and Φ is a candidate universal invariant, with Φd we
denote the formula obtained from Φ by instantiating the quantiﬁers in variables
used for the domain of cardinality d.
1, iterates trying
Alessandro Cimatti, Alberto Griggio, and Gianluca Redondi

Invariant Checking of Parametric Systems via Quantiﬁer-free SMT
137
At each iteration, we carry out the following high-level steps (described in
detail in the next sections):
– the property Φ to be proved is conjoined with the candidate lemmas in Ψ,
and its quantiﬁers are moved in prenex form;2
– we construct the guard-strengthening CΦ∧Ψ (cfr. Proposition 1), conjoining
Φ ∧Ψ to the transition rules of C;
– we compute our modiﬁed Parameter Abstraction of CΦ∧Ψ (deﬁned in §5.1).
First, we deﬁne the necessary prophecy variables p and environmental vari-
ables x. Then, we instantiate the quantiﬁers obtaining the quantiﬁer-free
array transition system ˜CΦ∧Ψ.
– we (try to) solve the invariant checking problem ˜CΦ∧Ψ |= ˜Φ ∧˜Ψ by calling a
model checker for quantiﬁer-free transition systems. ˜Φ ∧˜Ψ is obtained from
Φ ∧Ψ by removing quantiﬁers with prophecy variables, as in Proposition 2
– if the model checker concludes that there is no violation, then Φ holds in C
(for the properties of the Parameter Abstraction), and we exit with Safe.
– otherwise, we try to check whether the property violation in the abstract
space corresponds to a real counterexample. We do so by checking whether
the current property Φ ∧Ψ is falsiﬁed in Cd, a suitable ﬁnite instance of C.
That is, we check whether Cd |= (Φ ∧Ψ)d.
– if Cd |= (Ψ ∧Φ)d, then the abstraction must be tightened. When the veriﬁ-
cation of the ﬁnite instance succeeds, an inductive invariant Id is produced,
which is used to compute (candidate) lemmas by generalization from d to
the universal case.
– if Cd ̸|= (Ψ ∧Φ)d, two cases are possible. First, we check if the (instantiation
of the) property Φ is indeed violated. If so, we exit with Unsafe, and we pro-
duce a concrete counterexample to the original problem, ﬁnitely witnessed
in Cd.
– However, it is also possible that Cd does not violate Φd, but it falsiﬁes some
lemmas. In fact, the candidate lemmas obtained at previous iterations, by
generalization on Cd−with d−̸= d, may not hold universally in C. In that
case, the bad lemmas must be ﬁxed, and the iteration is restarted.
When the algorithm terminates with Unsafe, we are able to exhibit a ﬁnite
counterexample trace in a ﬁnite instance of C violating the property. When
the algorithm terminates with safe, then the property holds in C. The result
is obtained by the following chain of implications: from Theorem 3, stated in
the next section, we have that ˜CΦ∧Ψ |= ˜Φ ∧˜Ψ implies CΦ∧Ψ |= ˜Φ ∧˜Ψ. From
Proposition 2, we have that CΦ∧Ψ |= Φ ∧Ψ. Therefore, from Proposition 1, we
have C |= Φ ∧Ψ. In particular, we have C |= Φ.
5
Modiﬁed Parameter Abstraction
We describe here our Parameter Abstraction. The ﬁrst version of this approach
was introduced in [3], and later formalized in [15]. In the following, we describe
2 In the following, with Φ ∧Ψ we denote the prenex form Φ ∧
i Ψi

138
a novel version of the abstraction, and how it can be applied to array-based
transition systems. The main novelty is that, instead of using a special abstract
index “∗” that overapproximates the behaviour of the system in the array loca-
tions that are not explicitly tracked, we use n environmental (index) variables
which are not abstracted, but are allowed to change nondeterministically in some
transitions. This can be achieved by the usage of an additional stuttering tran-
sition: this rule allows the environmental variables to change value arbitrarily,
while not changing the values of the array in the prophecies.
5.1
Abstraction Computation
Let an array-based transition system C and a universal invariant Φ be given3.
By conjoining Φ to the transition rules in C, we obtain CΦ, the guard strength-
ening of C with respect to Φ. Then, we deﬁne two sets of variables: the prophecy
variables p, in number determined by Proposition 2, and the environmental vari-
ables x, in number determined by the greatest existential quantiﬁcation depth
in the transition rules of CΦ. While the prophecies are frozen variables, the in-
terpretation of the environmental variables is not ﬁxed. Moreover, we assume
that the values taken by p and x are diﬀerent. We now deﬁne ˜C, the parameter
abstraction of C.
Initial formula Let ι(a) be ∀i.φ(i, a[i]), the initial formula of C in prenex
form, with φ(i, a[i]) quantiﬁer-free. The initial formula of the abstract system is
a quantiﬁer-free ﬁrst order formula, denoted ˜ι(p, a[p]) obtained by instantiating
all the universal quantiﬁers in ι over the set of prophecy variables p.
Transition formula The transition formula of CΦ is still represented by a
disjuction of formulae of the form4
τ(a, a′)
def
=
∃i∀j.ψ(i, j, a[i], a[j], a′[i], a′[j]).
For simplicity, we can assume that we have only one rule τ(a, a′). First, we
compute the set of all substitutions of the i over p ∪x, and we consider the set
of formulae {˜τj(p, x, a, a′)}, where j ranges over the substitutions, and ˜τj is the
result of applying the substitution to τ.
Then, for each formula in the set {˜τj}, we instantiate the universal quanti-
ﬁers over the set p ∪x, obtaining a quantiﬁer-free formula over prophecy and
environmental variables.
Moreover, we consider an additional transition formula, called the stuttering
transition, deﬁned by:
˜τS
def
=

p∈p
a′[p] = a[p] ∧p′ = p
3 These represent the system and the property in input to each iteration of the loop.
4 Possibly by performing trivial logical manipulations to distribute the guard strength-
ening inside the rules.
Alessandro Cimatti, Alberto Griggio, and Gianluca Redondi

Invariant Checking of Parametric Systems via Quantiﬁer-free SMT
139
The disjunction of all the abstracted transition formulae is the transition
formula ˜τ. So, we can now deﬁne the transition system
˜C
def
= ({a, p, x}, ˜ι(p, a[p]), ˜τ(p, x, a[p ∪x], a′[p ∪x])).
Example 2. We apply the abstraction procedure to the transition rule 2 of the
token in the ring protocol of Example 1.
Since the invariant is the formula ∀i, j.¬(s[i] = critical ∧s[j] = critical) it fol-
lows that we have two prophecy variables p1, p2. Recall that the invariant itself is
added to the transition as an additional conjunct. Since the existential quantiﬁ-
cation depth is one, we have only one environment variable x1. In the abstraction
system we obtain three transition formulae from the original transition; we re-
port the one indexed by the substitution mapping i into x1; such a formula is
equivalent to the following:
s[x1] = crit ∧t[x1] = true ∧s′[x1] = idle ∧t′[x1] = false∧

j∈{p1,p2}
⎧
⎪
⎨
⎪
⎩
if j = 1 ∧x1 = length then s′[j] = s[j] ∧t′[j] = false
elif j = x1 + 1 ∧x1 < length then s′[j] = s[j] ∧t′[j] = false
else s′[j] = s[j] ∧t′[j] = t[j]

i,j∈{p1,p2,x1}
i̸=j
¬(s[i] = critical ∧s[j] = critical)
5.2
Stuttering Simulation
We deﬁne here the stuttering simulation induced by our version of the Parameter
Abstraction. The proof of the main theorem can be found in the appendix. The
stuttering is induced by ˜τS: this is a weaker version than the simulation induced
by [15], yet it is suﬃcient for preserving invariants.
Deﬁnition 1 (Stuttering simulation) Given two symbolic transition systems
C1 = (x1, ι1, τ1) and C2 = (x2, ι2, τ2), with sets of states S1 and S2, a stuttering
simulation S is a relation S ⊂S1 × S2, such that:
– for every s1 ∈S1 such that s1 |= ι1, there exists some s2 ∈S2 such that
(s1, s2) ∈S and s2 |= ι2;
– for every (s1, s2) ∈S, and for every s′
1 ∈S1 such that s1 ∪s′
1 |= τ1, there
exists either some s′
2 ∈S2 such that (s′
1, s′
2) ∈S and s2 ∪s′
2 |= τ2, or some
(s′
2, s′′
2) ∈S2 × S2 such that (s′
1, s′′
2) ∈S, and s2 ∪s′
2 |= τ2, s′
2 ∪s′′
2 |= τ2.
If such a relation exists, we say that C2 stutter simulates C1.
We write S(s1) for {s2|(s1, s2)} ∈S. We recall that stutter simulation pre-
serves reachability, i.e. if C2 stutter simulates C1, then if s1 is reachable in C1
then the set S(s1) is reachable in C2. Formally, the stuttering simulation induced
by the Parameter Abstraction is deﬁned as follows.

140
Deﬁnition 2 (Simulation) Let C be the original transition system and let ˜C
be its Parameter Abstraction. Let s and ˜s denote states of C and ˜C, respectively.
We deﬁne S as follows:
S(s, ˜s) iﬀs(a)[i] = ˜s(a)[i] for all i ∈

p∈p
˜s(p).
Intuitively, we require that in the concrete state s and the abstract state ˜s,
the array is interpreted in the same way for all the locations referred by the
prophecy variables. We then have the following:
Theorem 3. The relation S is a stuttering simulation between C and ˜C. More-
over, if ˜C |= Φ(p, a[p]), then C |= Φ(p, a[p]).
6
Reﬁnement
If Φ(p, a[p]) does not hold in ˜C, in general we cannot conclude anything, since the
abstraction could be too coarse. So, if an abstract counterexample is encountered,
we try to explore a small instance of the system to see if this counterexample
occurs in it. To choose the appropriate size, our algorithm keeps a counter d,
whose value is equal to the size to explore. Initially, d is equal to the number
of (universally-quantiﬁed) index variables in the property Φ.5 When an abstract
counterexample is encountered, we check whether Cd |= (Φ∧Ψ)d. For this check,
we use a model checker able to return, in case of success, an inductive invariant
Id. From the inductive invariant we compute some ﬁrst order formulae J which
will be a new set of candidate lemmas. We will see later how to obtain this
generalization. After computing the new lemmas, we set d = d + 1. If a con-
crete counterexample is found, then there are two cases: (i) the counterexample
falsiﬁes the original property, and we exit from the algorithm with a concrete
counterexample; (ii) the counterexample falsiﬁes some lemmas; in this case we
remove the lemma and restart the loop (without changing d).
6.1
From Invariants to Universal Lemmas
Deﬁnition 3 Let d be an integer, and let Id be a set of clauses containing
d variables. A generalization of Id is a ﬁrst-order formula J such that, when
evaluating the quantiﬁers in J in a domain with precisely d elements, we obtain
a formula equivalent to Id.
We use the following technique for generalization. Suppose that Id is in CNF,
and that we used c1, . . . , cd as variables for an instance with d elements. Then,
Id = C1 ∧· · · ∧Cn is a conjunction of clauses. From each of those clauses we
5 Recall that we assume that quantiﬁed index variables are required to be diﬀerent.
Therefore, the property holds vacuously on instances of size smaller than the number
of index variables in Φ.
Alessandro Cimatti, Alberto Griggio, and Gianluca Redondi

Invariant Checking of Parametric Systems via Quantiﬁer-free SMT
141
will obtain a new candidate lemma. Let AllDiﬀ(i) be the formula which states
that all variables in i are diﬀerent from each other. Since every Cd is given by
a symmetric presentation [15], we have that, for every i ∈{1, . . . , n}, Cd |=
∀i1, . . . , ih.AllDiﬀ(i1, . . . , ih) →Ci(i1, . . . , ih), where the quantiﬁers range over
c1, . . . , cd and h ≤d is the number of variables which occur in Ci. This means
that J
def
= 	
i ∀i.AllDiﬀ(i) →Ci(i) is a generalization of Id. In our algorithm, we
add the set {∀i.Ci(i)}n
i=1 of new candidate lemmas to Ψ. Note that we omitted
the formula AllDiﬀfor our assumption on the diﬀerent values of index variables.
Fixing Unsound Lemmas Unfortunately, we know a priori that a lemma
holds only for the instance from which it was generalized. In general, its universal
generalization obtained as outlined above might not hold in the system.
Suppose that the formula ψ1 is a candidate lemma, obtained by generaliza-
tion after the successful veriﬁcation of an instance of size d. Suppose that later,
a counterexample for ψ1 is found by exploring a diﬀerent instance Cd′ (with
d′ > d). This means that the lemma ψ1 does not hold universally, but only for
some ﬁnite instances of the system (including Cd), and not in general. In this
case, we simply remove ψ1 from the set of candidate lemmas Ψ, thus eﬀectively
weakening our working property (from Φ ∧Ψ to Φ ∧(Ψ \ {ψ1})). While this may
cause a particular (abstract) counterexample to be encountered more than once
during the main loop of the algorithm, since the ﬁnite instances are explored
monotonically and their size d is increased after every successful veriﬁcation
of a bounded instance, the overall procedure still makes progress by exploring
increasingly-large instances of the system. The hope is that eventually the algo-
rithm will discover enough good lemmas that block the abstract counterexample.
This notion of (weak) progress is justiﬁed by the following:
Proposition 4 Let ˜π be an abstract counterexample, Ψ be the current set of
universally quantiﬁed lemmas, and d be the size of the bounded instance to ex-
plore. During every execution of the algorithm, the same triple (˜π, Ψ, d) never
occurs twice.
7
Related Work
Parametric veriﬁcation is a challenging problem, and there is a large body of
work in the literature devoted to this problem. Here, we (necessarily) focus on
the approaches that are most related to ours.
Several methods are based on quantiﬁer elimination using decidable frag-
ments of ﬁrst order logic, with notable examples in [7, 10, 22]. These methods
guarantee a high degree of automation, but typically impose strong syntactic
requirements in the input problem, and may suﬀer from scalability issues. A
second popular approach is based on abstraction and abstraction reﬁnement.
Within this family of abstractions, earlier versions of the Paramater Abstrac-
tion [3, 15] have been used successfully also for industrial protocols [24]. The

142
main drawback is that the degree of automation is limited, and substantial ex-
pertise is required to obtain the desired results. The ﬁrst steps of our abstraction
algorithm are inspired by the ones in [19] and [15]. The key diﬀerence from [19]
is that in that work the abstract transition system ˜C is given by an eager propo-
sitional abstraction, with the axioms of the background theories recovered by
the usage of some schemata. Here we retain the theory of arrays in the abstract
space ˜C. Moreover, diﬀerently from both [15] and [19], our procedure includes
an automatic reﬁnement of the abstraction in a counterexample-driven manner.
Ivy [20, 22] implements both semi-automatic invariant checking with decid-
able logics (namely, Eﬀectively Propositional Logic – EPR) and compositional
abstraction with eager axioms [19]. MyPyvy [13,14] is a model checker inspired
by the language of Ivy. It implements a version of IC3 capable of dealing with uni-
versal formulas [13]; the algorithm is completely automatic, but it is still based
on quantiﬁer elimination via reduction to decidable logics. In a more recent work,
MyPyvy has gained the capability of inferring invariants with quantiﬁer alter-
nations, using a procedure that combines separators and ﬁrst-order logic [14]. At
the moment, our framework is capable of handling only universally quantiﬁed
invariants. On the other hand, our approach is not limited to EPR, but it can
in principle handle formulae with arbitrary SMT theories.
Exploring small instances of a parameterized system for candidate lemmas
is a popular approach for parametric veriﬁcation. In [8], this idea is used to
over-approximate backward reachable states inside an algorithm which combines
backward search and quantiﬁer elimination. In [16], a ﬁnite-instance exploration
is used together with a theorem prover to check the validity of candidate lemmas.
In [17], candidate invariants are obtained from the set of reachable states of
small instances. Similarly to our approach, these lemmas are used to strengthen
an earlier version of the parameter abstraction. However, human intervention is
still needed for the reﬁnement.
A similar approach is presented in [23], where lemmas are obtained from a
generalization of the proof of the property in a small instance of the protocol.
The main diﬀerence with our technique, besides the methods used to extract
such invariants, is the following: in [23], the authors show that to prove that a
property (conjoined with lemmas) is inductive for all N, it is enough to prove
that it is inductive for a particular N0, which is computable from the number
of variables in the description of the system. This result is obtained from the
imposed syntactic structure of the system. On the other hand, we impose less
structure, and we rely on proving the property in an abstract version (and not
a concrete instance) of the system. Moreover, our approach is integrated in an
abstraction/reﬁnement loop, which is missing from [23].
Another SMT-based approach for parametric veriﬁcation is in [12]. The
method is based on a reduction of invariant checking to the satisﬁability of
non-linear Constrained Horn Clauses (CHCs). Besides diﬀering substantially in
the overall approach, the method is more restrictive in the input language, and
handles invariants only with a speciﬁc syntactic structure.
Alessandro Cimatti, Alberto Griggio, and Gianluca Redondi

Invariant Checking of Parametric Systems via Quantiﬁer-free SMT
143
The use of prophecy variables for inferring universally quantiﬁed invariants
has been explored also in non-parametric contexts, such as [18]. The main dif-
ference with our work is that [18] focuses on ﬁnding quantiﬁed invariants for
quantiﬁer-free transition systems with arrays, rather than array-based systems
with quantiﬁers. The overall abstraction-reﬁnement approach is also substan-
tially diﬀerent.
8
Experimental Evaluation
We have implemented our algorithm in a tool called Lambda (for Learning
Abstractions froM BoundeD Analysis). Lambda is written in Python, and
uses the SMT-based IC3 with implicit predicate abstraction of [4] as underly-
ing quantiﬁer-free veriﬁcation engine.6 Lambda accepts as input array-based
systems speciﬁed either in the language of MCMT [11] or in VMT format (a
light-weight extension of SMT-LIB to model transition systems [25]). In case
of successful termination, Lambda generates either a counterexample trace (for
violated properties) in a concrete instance of the parametric system, or a quanti-
ﬁed inductive invariant that proves the property for any instance of the system.
In the latter case, Lambda can also generate proof obligations that can be in-
dependently checked with an SMT solver supporting quantiﬁers, such as Z3 [21]
or CVC4 [2]. More speciﬁcally, the quantiﬁed inductive invariant can be gener-
ated by Lambda by simply universally quantifying all the (index) variables in
the inductive invariant generated for ˜C, and conjoining it with the lemmas Ψ
discovered during the main loop iterations. Computing such an invariant is im-
mediate after the termination of the algorithm, and does not require additional
reasoning.
In order to evaluate the eﬀectiveness of our method, we have compared
Lambda with two state-of-the-art tools for the veriﬁcation of array-based sys-
tems, namely Cubicle [7] and MCMT. We could not include MyPyvy in the
comparison, due to the many diﬀerences in input languages and modeling for-
malisms, which make an automatic translation of the benchmarks very diﬃcult.
We would also have liked to compare with the technique of [12], however the
prototype tool mentioned in the paper doesn’t seem to be available.
For our evaluation, we have collected a total of 116 benchmarks, divided in
three diﬀerent groups:
Protocols consists of 42 instances taken from the MCMT or the Cubicle dis-
tributions, and used in previous works on verifcation of array-based systems. We
have used all the instances which were available in both input formats, and we
have split benchmarks containing multiple properties into diﬀerent ﬁles.
DynArch consists of 57 instances of veriﬁcation problems of dynamic architec-
tures, taken from [6]. These benchmarks make use of arithmetic constraints on
6 In our implementation, we use the theory of integers as an index theory. At ﬁrst, this
may seem odd, since we should consider all ﬁnite subsets of the integers. However,
this is not a problem, since the satisﬁability of a quantiﬁer-free UFLIA formula is
equivalent to its satisﬁability in a ﬁnite index model.

144
Table 1. Summary of experimental results.
Lambda
MCMT
Cubicle
Benchmark family # of instances Solved Unique Solved Unique Solved Unique
Protocols
42
34
3
24
0
30
1
DynArch
57
48
5
48
5
–
–
Trains
17
17
–
–
–
–
–
index terms, which are not supported by Cubicle. Therefore, we could only
compare Lambda with MCMT on them.
Trains consists of 17 instances derived by (a simpliﬁed version of) veriﬁca-
tion problems on railway interlocking logics [1]. These benchmarks make use of
several features that are not fully supported by Cubicle and MCMT (such
as non-functional updates in the transition relation, transition rules with more
than one universally-quantiﬁed variable, real-valued variables). None of such re-
strictions applies to Lambda, which in general accepts models with signiﬁcatly
fewer syntactic constraints than Cubicle and MCMT. Since these instances
are inspired by relevant real-world veriﬁcation problems, we believe that it is
interesting to include them in the evaluation even though we could only run
Lambda on them.
Our implementation, all the benchmarks, and the scripts for reproducing the
results are available at http://es.fbk.eu/people/griggio/papers/cade21-lambda.
tar.gz. We have run our experiments on a cluster of machines with a 2.90GHz
Intel Xeon Gold 6226R CPU running Ubuntu Linux 20.04.1, using a time limit of
1 hour and a memory limit of 4GB for each instance. We have used the default
settings for MCMT, whereas for Cubicle we have also enabled the BRAB
algorithm.7 A summary of the results of our evaluation are presented in Table 1.
More details are provided in our extended version [5].
Overall, Lambda is very competitive with the state of the art, and in fact
it solves the largest number of instances (even when disregarding the Trains
group, which cannot be handled by the other tools).When considering the Pro-
tocols group, Cubicle is often signiﬁcantly faster than Lambda, especially on
easier problems, thanks to its explicit-state exploration component (part of the
BRAB algorithm). However, the symbolic techniques used by Lambda allow it to
generally scale better to larger, more challenging problems: in the end, Lambda
solves 4 more instances than Cubicle, and 10 more than MCMT. The situa-
tion is diﬀerent for the DynArch group, in which Lambda and MCMT solve the
same number of instances. However, it is interesting to observe that both tools
can solve 5 instances that the other tool cannot solve; more in general, it seems
that the two approaches have somewhat complementary strengths. Moreover, as
already stated above, the fact that Lambda imposes signiﬁcantly less syntactic
restrictions than the other two tools considered allowed it to handle all the in-
stances of the Trains group, which cannot be easily modeled in the languages of
MCMT or Cubicle.
7 The results reported were obtained using -brab 2; we have however experimented
also with other (small) values for -brab, without noticing any signiﬁcant diﬀerence.
Alessandro Cimatti, Alberto Griggio, and Gianluca Redondi

Invariant Checking of Parametric Systems via Quantiﬁer-free SMT
145
Finally, we wish to remark that we have generated SMT proof obligations for
checking the correctness of all the (universally quantiﬁed) inductive invariants
produced by Lambda, and checked them with both CVC4 and Z3. None of the
solvers reported any error, and overall the combination of the two solvers was able
to successfully verify all the proof obligations for 65 of the 67 instances reported
as safe.8 We believe that the fact that we can easily produce proof obligations
that can be independently checked is another strength of our approach. This is
in contrast to the approach of Cubicle, where generating proof obligations is
nontrivial [9].
9
Conclusions
In this paper we tackled the problem of universal invariant checking for paramet-
ric systems. We proposed a fully-automated abstraction-reﬁnement approach,
based on quantiﬁer-free reasoning. The abstract model, that stutter simulates
the concrete model, is a quantiﬁer-free symbolic transition system reﬁned by (the
instantiation of) candidate universal lemmas. These are obtained by analyzing
the proofs of validity of the property in a ﬁnite instance of the parametric system.
We experimentally evaluated an implementation on standard benchmarks from
the literature. The results show the eﬀectiveness of the method, also in compar-
ison with state-of-the-art tools (Cubicle, MCMT). We are able to prove, in a
fully automated manner and without manual intervention, several benchmarks
that are considered challenging. In the future, we plan to work on generalization,
to improve the ability of inferring the right lemmas from a small instance, and
to ﬁnd more eﬀective ways to ﬁlter out bad candidates. On the theoretical side,
we will investigate the relation between the termination of the algorithm and
decidable classes of parametric systems (e.g. those that enjoy a cut-oﬀprop-
erty). Finally, we will work on the veriﬁcation of temporally extended properties
which are also preserved by stuttering simulations (such as fragments of Linear
Temporal Logic).
References
1. Amendola, A., Becchi, A., Cavada, R., Cimatti, A., Griggio, A., Scaglione, G.,
Susi, A., Tacchella, A., Tessi, M.: A model-based approach to the design, veriﬁ-
cation and deployment of railway interlocking system. In: Margaria, T., Steﬀen,
B. (eds.) Leveraging Applications of Formal Methods, Veriﬁcation and Validation:
Applications - 9th International Symposium on Leveraging Applications of Formal
Methods, ISoLA 2020, Rhodes, Greece, October 20-30, 2020, Proceedings, Part III.
Lecture Notes in Computer Science, vol. 12478, pp. 240–254. Springer (2020)
2. Barrett, C.W., Conway, C.L., Deters, M., Hadarean, L., Jovanovic, D., King, T.,
Reynolds, A., Tinelli, C.: CVC4. In: CAV. Lecture Notes in Computer Science,
vol. 6806, pp. 171–177. Springer (2011)
8 In the remaining two cases, both solvers returned unknown when trying to prove the
validity of some of the proof obligations.

146
3. Chou, C.T., Mannava, P.K., Park, S.: A simple method for parameterized veriﬁca-
tion of cache coherence protocols. In: Hu, A.J., Martin, A.K. (eds.) Formal Meth-
ods in Computer-Aided Design. pp. 382–398. Springer Berlin Heidelberg, Berlin,
Heidelberg (2004)
4. Cimatti, A., Griggio, A., Mover, S., Tonetta, S.: Inﬁnite-state invariant checking
with IC3 and predicate abstraction. Formal Methods Syst. Des. 49(3), 190–218
(2016)
5. Cimatti, A., Griggio, A., Redondi, G.: Universal Invariant Checking of Paramet-
ric Systems with Quantiﬁer-Free SMT Reasoning (extended version). Tech. rep.,
Fondazione Bruno Kessler (2021), https://es-static.fbk.eu/people/griggio/papers/
cade21extended.pdf
6. Cimatti, A., Stojic, I., Tonetta, S.: Formal speciﬁcation and veriﬁcation of dynamic
parametrized architectures. In: Havelund, K., Peleska, J., Roscoe, B., de Vink,
E.P. (eds.) Formal Methods - 22nd International Symposium, FM 2018, Held as
Part of the Federated Logic Conference, FloC 2018, Oxford, UK, July 15-17, 2018,
Proceedings. Lecture Notes in Computer Science, vol. 10951, pp. 625–644. Springer
(2018)
7. Conchon, S., Goel, A., Krstic, S., Mebsout, A., Za¨ıdi, F.: Cubicle: A Parallel SMT-
based Model Checker for Parameterized Systems. In: Parthasarathy, M., Seshia,
S.A. (eds.) CAV 2012: Proceedings of the 24th International Conference on Com-
puter Aided Veriﬁcation. Lecture Notes in Computer Science, Springer Verlag,
Berkeley, California, USA (July 2012)
8. Conchon, S., Goel, A., Krstic, S., Mebsout, A., Za¨ıdi, F.: Invariants for ﬁnite in-
stances and beyond. In: Formal Methods in Computer-Aided Design, FMCAD
2013, Portland, OR, USA, October 20-23, 2013. pp. 61–68. IEEE (2013)
9. Conchon, S., Mebsout, A., Za¨ıdi, F.: Certiﬁcates for parameterized model checking.
In: FM. Lecture Notes in Computer Science, vol. 9109, pp. 126–142. Springer (2015)
10. Ghilardi, S., Nicolini, E., Ranise, S., Zucchelli, D.: Towards smt model checking of
array-based systems. In: Armando, A., Baumgartner, P., Dowek, G. (eds.) Auto-
mated Reasoning. pp. 67–82. Springer Berlin Heidelberg, Berlin, Heidelberg (2008)
11. Ghilardi, S., Ranise, S.: Backward reachability of array-based systems by SMT
solving: Termination and invariant synthesis. Log. Methods Comput. Sci. 6(4)
(2010)
12. Gurﬁnkel, A., Shoham, S., Meshman, Y.: Smt-based veriﬁcation of parameterized
systems. In: Proceedings of the 2016 24th ACM SIGSOFT International Sympo-
sium on Foundations of Software Engineering. p. 338–348. FSE 2016, Association
for Computing Machinery, New York, NY, USA (2016)
13. Karbyshev, A., Bjørner, N., Itzhaky, S., Rinetzky, N., Shoham, S.: Property-
directed inference of universal invariants or proving their absence. In: Kroening,
D., P˘as˘areanu, C.S. (eds.) Computer Aided Veriﬁcation. pp. 583–602. Springer
International Publishing, Cham (2015)
14. Koenig, J.R., Padon, O., Immerman, N., Aiken, A.: First-order quantiﬁed separa-
tors. In: Donaldson, A.F., Torlak, E. (eds.) Proceedings of the 41st ACM SIGPLAN
International Conference on Programming Language Design and Implementation,
PLDI 2020, London, UK, June 15-20, 2020. pp. 703–717. ACM (2020)
15. Krstic, S.: Parametrized system veriﬁcation with guard strengthening and param-
eter abstraction (2005)
16. Li, Y., Duan, K., Jansen, D.N., Pang, J., Zhang, L., Lv, Y., Cai, S.: An automatic
proving approach to parameterized veriﬁcation. ACM Trans. Comput. Logic 19(4)
(Nov 2018)
Alessandro Cimatti, Alberto Griggio, and Gianluca Redondi

Invariant Checking of Parametric Systems via Quantiﬁer-free SMT
147
17. Lv, Y., Lin, H., Pan, H.: Computing invariants for parameter abstraction. In:
2007 5th IEEE/ACM International Conference on Formal Methods and Models
for Codesign (MEMOCODE 2007). pp. 29–38 (2007)
18. Mann, M., Irfan, A., Griggio, A., Padon, O., Barrett, C.W.: Counterexample-
guided prophecy for model checking modulo the theory of arrays. CoRR
abs/2101.06825 (2021)
19. McMillan, K.L.: Eager abstraction for symbolic model checking. In: Chockler, H.,
Weissenbacher, G. (eds.) Computer Aided Veriﬁcation. pp. 191–208. Springer In-
ternational Publishing, Cham (2018)
20. McMillan, K.L., Padon, O.: Ivy: A multi-modal veriﬁcation tool for distributed
algorithms. In: Lahiri, S.K., Wang, C. (eds.) Computer Aided Veriﬁcation. pp.
190–202. Springer International Publishing, Cham (2020)
21. de Moura, L.M., Bjørner, N.: Z3: an eﬃcient SMT solver. In: TACAS. Lecture
Notes in Computer Science, vol. 4963, pp. 337–340. Springer (2008)
22. Padon, O., McMillan, K.L., Panda, A., Sagiv, M., Shoham, S.: Ivy: Safety veriﬁ-
cation by interactive generalization. SIGPLAN Not. 51(6), 614–630 (Jun 2016)
23. Pnueli, A., Ruah, S., Zuck, L.D.: Automatic deductive veriﬁcation with invisible
invariants. In: Margaria, T., Yi, W. (eds.) Tools and Algorithms for the Construc-
tion and Analysis of Systems, 7th International Conference, TACAS 2001 Held
as Part of the Joint European Conferences on Theory and Practice of Software,
ETAPS 2001 Genova, Italy, April 2-6, 2001, Proceedings. Lecture Notes in Com-
puter Science, vol. 2031, pp. 82–97. Springer (2001)
24. Talupur, M., Tuttle, M.R.: Going with the ﬂow: Parameterized veriﬁcation using
message ﬂows. In: 2008 Formal Methods in Computer-Aided Design. pp. 1–8 (2008)
25. VMT-LIB. http://www.vmt-lib.org
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Politeness and Stable Inﬁniteness: Stronger
Together
1 Stanford University, Stanford, CA, USA
2 Universit´e de Lorraine, CNRS, Inria, LORIA, F-54000 Nancy, France
3 The University of Iowa, Iowa City, IA, USA
Abstract. We make two contributions to the study of polite combina-
tion in satisﬁability modulo theories. The ﬁrst is a separation between
politeness and strong politeness, by presenting a polite theory that is not
strongly polite. This result shows that proving strong politeness (which
is often harder than proving politeness) is sometimes needed in order to
use polite combination. The second contribution is an optimization to
the polite combination method, obtained by borrowing from the Nelson-
Oppen method. The Nelson-Oppen method is based on guessing arrange-
ments over shared variables. In contrast, polite combination requires an
arrangement over all variables of the shared sorts. We show that when
using polite combination, if the other theory is stably inﬁnite with re-
spect to a shared sort, only the shared variables of that sort need be
considered in arrangements, as in the Nelson-Oppen method. The time
required to reason about arrangements is exponential in the worst case,
so reducing the number of variables considered has the potential to im-
prove performance signiﬁcantly. We show preliminary evidence for this
by demonstrating a speed-up on a smart contract veriﬁcation benchmark.
1
Introduction
Solvers for satisﬁability modulo theories (SMT) [5] are used in a wide variety
of applications. Many of these applications require determining the satisﬁability
of formulas with respect to a combination of background theories. In order to
make reasoning about combinations of theories modular and easily extensible,
a combination framework is essential. Combination frameworks provide mecha-
nisms for automatically deriving a decision procedure for the combined theories
by using the decision procedures for the individual theories as black boxes. To
integrate a new theory into such a framework, it then suﬃces to focus on the de-
coupled decision procedure for the new theory alone, together with its interface
to the generic combination framework.
In 1979, Nelson and Oppen [16] proposed a general framework for combining
theories with disjoint signatures. In this framework, a quantiﬁer-free formula in
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5 9
Ying Sheng1(B)
, Yoni Zohar1
, Christophe Ringeissen2
, Andrew
Reynolds3
, Clark Barrett1
, and Cesare Tinelli3
148–165, 2021.

the combined theory is puriﬁed to a conjunction of formulas, one for each theory.
Each pure formula is then sent to a dedicated theory solver, along with a guessed
arrangement (a set of equalities and disequalities that capture an equivalence re-
lation) of the variables shared among the pure formulas. For completeness [15],
this method requires all component theories to be stably inﬁnite. While many
important theories are stably inﬁnite, some are not, including the widely-used
theory of ﬁxed-length bit-vectors. To address this issue, the polite combination
method was introduced by Ranise et al. [17], and later reﬁned by Jovanovic
and Barrett [12]. In polite combination, one theory must be polite, a stronger
requirement than stable-inﬁniteness, but the requirement on the other theory is
relaxed: speciﬁcally, it need not be stably inﬁnite. The price for this generality is
that unlike the Nelson-Oppen method, polite combination requires guessing ar-
rangements over all variables of certain sorts, not just the shared ones. At a high
level, polite theories have two properties: smoothness and ﬁnite witnessability
(see Section 2). The polite combination theorem in [17] contained an error, which
was identiﬁed in [12]. A ﬁx was also proposed in [12], which relies on stronger
requirements for ﬁnite witnessability. Following Casal and Rasga [8], we call this
strengthened version strong ﬁnite witnessability. A theory that is both smooth
and strongly ﬁnitely witnessable is called strongly polite.
This paper makes two contributions. First, we give an aﬃrmative answer to
the question of whether politeness and strong politeness are diﬀerent notions, by
giving an example of a theory that is polite but not strongly polite. The given
theory is over an empty signature and has two sorts, and was originally studied
in [8] in the context of shiny theories. Here we state and prove the separation
of politeness and strong politeness, without using shiny theories. Proving that a
theory is strongly polite is harder than proving that it is just polite. This result
shows that the additional eﬀort is sometimes needed in order to be able to use the
combination theorem from [12]. We show that for empty signatures, at least two
sorts are needed to present a polite theory that is not strongly polite. However,
for the empty signature with only one sort, there is a ﬁnitely witnessable theory
that is not strongly ﬁnite witnessable. Such a theory cannot be smooth.
Second, we explore diﬀerent polite combination scenarios, where additional
information is known about the theories being combined. In particular, we im-
prove the polite combination method for the case where one theory is strongly
polite w.r.t. a set S of sorts and the other is stably inﬁnite w.r.t. a subset S′ ⊆S
of the sorts. For such cases, we show that it is possible to perform Nelson-Oppen
combination for S′ and polite combination for S \ S′. This means that for the
sorts in S′, only shared variables need to be considered for the guessed arrange-
ment, which can considerably reduce its size. We also show that the set of shared
variables can be reduced for a couple of other variations of conditions on the the-
ories. Finally, we present a preliminary case study using a challenge benchmark
from a smart contract veriﬁcation application. We show that the reduction of
shared variables is evident and signiﬁcantly improves the solving time. Veriﬁca-
tion of smart contracts using SMT (and the analyzed benchmark in particular)
is the main motivation behind the second contribution of this paper.
149
Y. Sheng et al.

Related Work: Polite combination is part of a more general eﬀort to replace the
stable inﬁniteness symmetric condition in the Nelson-Oppen approach with a
weaker condition. Other examples of this eﬀort include the notions of shiny [21],
parametric [13], and gentle [11] theories. Gentle, shiny, and polite theories can
be combined `a la Nelson-Oppen with any arbitrary theory. Shiny theories were
introduced by Tinelli and Zarba [21] as a class of mono-sorted theories. Based
on the same principles as shininess, politeness is particularly well-suited to deal
with theories expressed in many-sorted logic. Polite theories were introduced by
Ranise et al. [17] to provide a more eﬀective combination approach compared
to parametric and shiny theories, the former requiring solvers to reason about
cardinalities and the latter relying on expensive computations of minimal car-
dinalities of models. Shiny theories were extended to many-sorted signatures
in [17], where there is a suﬃcient condition for their equivalence with polite
theories. For the mono-sorted case, a suﬃcient condition for the equivalence of
shiny theories and strongly polite theories was given by Casal and Rasga [7].
In later work [8], the same authors proposed a generalization of shiny theories
to many-sorted signatures diﬀerent from the one in [17], and proved that it is
equivalent to strongly polite theories with a decidable quantiﬁer-free fragment.
The strong politeness of the theory of algebraic datatypes [4] was proven in [18].
That paper also introduced additive witnesses, that provided a suﬃcient con-
dition for a polite theory to be also strongly polite. In this paper we present a
theory that is polite but not strongly polite. In accordance with [18], the witness
that we provide for this theory is not additive.
The paper is organized as follows. Section 2 provides the necessary notions
from ﬁrst-order logic and polite theories. Section 3 discusses the diﬀerence be-
tween politeness and strong politeness and shows they are not equivalent. Sec-
tion 4 gives the improvements for the combination process under certain condi-
tions, and Section 5 demonstrates the eﬀectiveness of these improvements for a
challenge benchmark. 4
2
Preliminaries
2.1
Signatures and Structures
We brieﬂy review the usual deﬁnitions of many-sorted ﬁrst-order logic with
equality (see [10,19] for more details). A signature Σ consists of a set SΣ (of
sorts), a set FΣ of function symbols, and a set PΣ of predicate symbols. We as-
sume SΣ, FΣ and PΣ are countable. Function symbols have arities of the form
σ1 × . . . × σn →σ, and predicate symbols have arities of the form σ1 × . . . × σn,
with σ1, . . . , σn, σ ∈SΣ. For each sort σ ∈SΣ, PΣ includes an equality symbol
=σ of arity σ × σ. We denote it by = when σ is clear from context. When =σ
are the only symbols in Σ, we say that Σ is empty. If two signatures share no
symbols except =σ we call them disjoint. We assume an underlying countably
4
Due to space constraints, some proofs are omitted. They can be found in an
extended version at https://arxiv.org/abs/2104.11738.
Politeness and Stable Inﬁniteness: Stronger Together
150

inﬁnite set of variables for each sort. Terms, formulas, and literals are deﬁned in
the usual way. For a Σ-formula φ and a sort σ, we denote the set of free variables
in φ of sort σ by varsσ(φ). This notation naturally extends to varsS(φ) when S
is a set of sorts. vars(φ) is the set of all free variables in φ. We denote by QF(Σ)
the set of quantiﬁer-free Σ-formulas.
A Σ-structure is a many-sorted structure that provides semantics for the
symbols in Σ (but not for variables). It consists of a domain σA for each sort
σ ∈SΣ, an interpretation f A for every f ∈FΣ, as well as an interpretation P A
for every P ∈PΣ. We further require that =σ be interpreted as the identity
relation over σA for every σ ∈SΣ. A Σ-interpretation A is an extension of a
Σ-structure with interpretations for some set of variables. For any Σ-term α,
αA denotes the interpretation of α in A. When α is a set of Σ-terms, αA =

xA | x ∈α

. Satisfaction is deﬁned as usual. A |= ϕ denotes that A satisﬁes ϕ.
A Σ-theory T is a class of all Σ-structures that satisfy some set Ax of
Σ-sentences. For each such set Ax, we say that T is axiomatized by Ax. A Σ-
interpretation whose variable-free part is in T is called a T -interpretation. A
Σ-formula φ is T -satisﬁable if A |= φ for some T -interpretation A. A set A of
Σ-formulas is T -satisﬁable if A |= φ for every φ ∈A. Two formulas φ and ψ are
T -equivalent if they are satisﬁed by the same T -interpretations.
Note that for any class C of Σ-structures there is a theory TC that corresponds
to it, with the same satisﬁable formulas: the Σ-theory axiomatized by the set
Ax of Σ-sentences that are satisﬁed in every structure of C. In the examples that
follow, we deﬁne theories TC implicitly by specifying only the class C, as done in
the SMT-LIB 2 standard [2]. This can be done without loss of generality.
Example 1. Let ΣList be a signature of ﬁnite lists containing the sorts elem1,
elem2, and list, as well as the function symbols cons of arity elem1×elem2×list →
list, car1 of arity list →elem1, car2 of arity list →elem2, cdr of arity list →list,
and nil of arity list. The ΣList-theory TList corresponds to an SMT-LIB 2 theory
of algebraic datatypes [2,4], where elem1 and elem2 are interpreted as some sets
(of “elements”), and list is interpreted as ﬁnite lists of pairs of elements, one
from elem1 and the other from elem2. cons is a list constructor that takes two
elements and a list, and inserts the two elements at the head of the list. The
pair (car1(l), car2(l)) is the ﬁrst entry in l, and cdr(l) is the list obtained from l
by removing its ﬁrst entry. nil is the empty list.
⊓⊔
Example 2. The signature ΣInt includes a single sort int, all numerals 0, 1, . . .,
the function symbols +, −and · of arity int × int →int and the predicate
symbols < and ≤of arity int × int. The ΣInt-theory TInt corresponds to integer
arithmetic in SMT-LIB 2, and the interpretation of the symbols is the same as
in the standard structure of the integers. The signature ΣBV4 includes a single
sort BV4 and various function and predicate symbols for reasoning about bit-
vectors of length 4 (such as & for bit-wise and, constants of the form 0110, etc.).
The ΣBV4-theory TBV4 corresponds to SMT-LIB 2 bit-vectors of size 4, with the
expected semantics of constants and operators.
⊓⊔
151
Y. Sheng et al.

Let Σ1, Σ2 be signatures, T1 a Σ1-theory, and T2 a Σ2-theory. The combina-
tion of T1 and T2, denoted T1⊕T2, consists of all Σ1∪Σ2-structures A, such that
AΣ1 is in T1 and AΣ2 is in T2, where AΣi is the reduct of A to Σi for i ∈{1, 2}.
Example 3. Let TIntBV4 be TInt ⊕TBV4. It is the combined theory of integers and
bit-vectors. It has all the sorts and operators from both theories. If we rename
the sorts elem1 and elem2 of ΣList to int and BV4, respectively, we can obtain a
theory TListIntBV4 deﬁned as TIntBV4 ⊕TList. This is the theory of lists of pairs,
where each pair consists of an integer and a bit-vector of size 4.
⊓⊔
The following deﬁnitions and theorems will be useful in the sequel.
Theorem 1 (Theorem 9 of [19]). Let Σ be a signature, and A a set of Σ-
formulas that is satisﬁable. Then there exists an interpretation A that satisﬁes
A, in which σA is countable whenever it is inﬁnite.5
Deﬁnition 1 (Arrangement). Let V be a ﬁnite set of variables whose sorts
are in S and let {Vσ | σ ∈S} be a partition of V such that Vσ is the set of
variables of sort σ in V . A formula δ is an arrangement of V if
δ =

σ∈S
(

(x,y)∈Eσ
(x = y) ∧

x,y∈Vσ,(x,y)/∈Eσ
(x ̸= y)) ,
where Eσ is some equivalence relation over Vσ for each σ ∈S.
The following theorem from [12] is a variant of a theorem from [20].
Theorem 2 (Theorem 2.5 of [12]). For i = 1, 2, let Σi be disjoint signatures,
Si = SΣi with S = S1 ∩S2, Ti be a Σi-theory, Γi be a set of Σi-literals, and
V = vars(Γ1)∩vars(Γ2). If there exist a T1-interpretation A, a T2 interpretation
B, and an arrangement δV of V such that: 1. A |= Γ1 ∪δV ; 2. B |= Γ2 ∪δV ; and
3. |Aσ| = |Bσ| for every σ ∈S, then Γ1 ∪Γ2 is T1 ⊕T2-satisﬁable.
2.2
Polite Theories
We now give the background deﬁnitions necessary for both Nelson-Oppen and
polite combination. In what follows, Σ is an arbitrary (many-sorted) signature,
S ⊆SΣ, and T is a Σ-theory. We start with stable inﬁniteness and smoothness.
Deﬁnition 2 (Stably Inﬁnite). T is stably inﬁnite with respect to S if ev-
ery quantiﬁer-free Σ-formula that is T -satisﬁable is also satisﬁable in a T -
interpretation A in which σA is inﬁnite for every σ ∈S.
Deﬁnition 3 (Smooth). T is smooth w.r.t. S if for every quantiﬁer-free for-
mula φ, T -interpretation A that satisﬁes φ, and function κ from S to the class of
cardinals such that κ(σ) ≥
σA for every σ ∈S, there exists a T -interpretation
A′ that satisﬁes φ with
σA′ = κ(σ) for every σ ∈S.
5 In [19] this was proven more generally, for ordered sorted logics.
Politeness and Stable Inﬁniteness: Stronger Together
152

We identify singleton sets with their single elements when there is no ambiguity
(e.g., when saying that a theory is smooth w.r.t. a sort σ).
We next deﬁne politeness and related concepts, following the presentation
in [18]. Let φ be a quantiﬁer-free Σ-formula. A Σ-interpretation A ﬁnitely wit-
nesses φ for T w.r.t. S (or, is a ﬁnite witness of φ for T w.r.t. S), if A |= φ
and σA = varsσ(φ)A for every σ ∈S. We say that φ is ﬁnitely witnessed for
T w.r.t. S if it is either T -unsatisﬁable or has a ﬁnite witness for T w.r.t. S.
We say that φ is strongly ﬁnitely witnessed for T w.r.t. S if φ ∧δV is ﬁnitely
witnessed for T w.r.t. S for every arrangement δV of V , where V is any set of
variables whose sorts are in S. A function wit : QF(Σ) →QF(Σ) is a (strong)
witness for T w.r.t. S if for every φ ∈QF(Σ) we have that: 1. φ and ∃−→
w .wit(φ)
are T -equivalent for −→
w = vars(wit(φ)) \ vars(φ); and 2. wit(φ) is (strongly)
ﬁnitely witnessed for T w.r.t. S. T is (strongly) ﬁnitely witnessable w.r.t. S if
there exists a computable (strong) witness for T w.r.t. S. T is (strongly) polite
w.r.t. S if it is smooth and (strongly) ﬁnitely witnessable w.r.t. S.
3
Politeness and Strong Politeness
In this section, we study the diﬀerence between politeness and strong politeness.
Since the introduction of strong politeness in [12], it has been unclear whether
it is strictly stronger than politeness, that is, whether there exists a theory
that is polite but not strongly polite. We present an example of such a theory,
answering the open question aﬃrmatively. This result is followed by further
analysis of notions related to politeness. This section is organized as follows.
In Section 3.1 we reformulate an example given in [12], showing that there are
witnesses that are not strong witnesses. We then present a polite theory that
is not strongly polite in Section 3.2. The theory is over a signature with two
sorts that is otherwise empty. We show in Section 3.3 that politeness and strong
politeness are equivalent for empty signatures with a single sort. Finally, we show
in Section 3.4 that this equivalence does not hold for ﬁnite witnessability alone.
3.1
Witnesses vs. Strong Witnesses
In [12], an example was given for a witness that is not strong. We reformulate
this example in terms of the notions that are deﬁned in the current paper, that is,
witnessed formulas are not the same as strongly witnessed formulas (Example 4),
and witnesses are not the same as strong witnesses (Example 5).
Example 4. Let Σ0 be a signature with a single sort σ and no function or pred-
icate symbols, and let T0 be a Σ0-theory consisting of all Σ0-structures with at
least two elements. Let φ be the formula x = x ∧w = w. This formula is ﬁnitely
witnessed for T0 w.r.t. σ, but not strongly. Indeed, for δV ≡(x = w), φ ∧δV is
not ﬁnitely witnessed for T0 w.r.t. σ: a ﬁnite witness would be required to have
only a single element and would therefore not be a T0-interpretation.
⊓⊔
The next example shows that witnesses and strong witnesses are not equivalent.
153
Y. Sheng et al.

Example 5. Take Σ0, σ, and T0 as in Example 4, and deﬁne wit(φ) as the function
(φ ∧w1 = w1 ∧w2 = w2) for fresh w1, w2. The function is a witness for T0
w.r.t. σ. However, it is not a strong witness for T w.r.t. σ.
⊓⊔
Although the theory T0 in the above examples does serve to distinguish for-
mulas and witnesses that are and are not strong, it cannot be used to do the
same for theories themselves. This is because T0 is, in fact, strongly polite, via
a diﬀerent witness function.
Example 6. The function wit′(φ) = (φ ∧w1 ̸= w2), for some w1, w2 /∈varsσ(φ),
is a strong witness for T0 w.r.t. S, as proved in [12].
⊓⊔
A natural question, then, is whether there is a theory that can separate the two
notions of politeness. The following subsection provides an aﬃrmative answer.
3.2
A Polite Theory that is not Strongly Polite
Let Σ2 be a signature with two sorts σ1 and σ2 and no function or predicate
symbols (except =). Let T2,3 be the Σ2-theory from [8], consisting of all Σ2-
structures A such that either
σA
1
 = 2 ∧
σA
2
 ≥ℵ0 or
σA
1
 ≥3 ∧
σA
2
 ≥3 [8].6
T2,3 is polite, but is not strongly polite. Its smoothness is shown by extending
any given structure with new elements as much as necessary.
Lemma 1. T2,3 is smooth w.r.t. {σ1, σ2}.
For ﬁnite witnessability, consider the function wit deﬁned as follows:
wit(φ) := φ ∧x1 = x1 ∧x2 = x2 ∧x3 = x3 ∧y1 = y1 ∧y2 = y2 ∧y3 = y3
(1)
for fresh variables x1, x2, and x3 of sort σ1 and y1, y2, and y3 of sort σ2. It can
be shown that wit is a witness for T2,3 but there is no strong witness for it.
Lemma 2. T2,3 is ﬁnitely witnessable w.r.t. {σ1, σ2}.
Lemma 3. T2,3 is not strongly ﬁnitely witnessable w.r.t. {σ1, σ2}.
Lemmas 1 to 3 have shown that T2,3 is polite but is not strongly polite. And
indeed, using the polite combination method from [12] with this theory can cause
problems. Consider the theory T1,1 that consists of all Σ2-structures A such that
σA
1
 =
σA
2
 = 1. Clearly, T1,1⊕T2,3 is empty, and hence no formula is T1,1⊕T2,3-
satisﬁable. However, denote the formula true by Γ1 and the formula x = x by
Γ2 for some variable x of sort σ1. Then wit(Γ2) is x = x∧3
i=1 xi = xi ∧yi = yi.
Let δ be the arrangement x = x1 = x2 = x3 ∧y1 = y2 = y3. It can be shown that
wit(Γ2)∧δ is T2,3-satisﬁable and Γ1 ∧δ is T1,1-satisﬁable. Hence the combination
method of [12] would consider Γ1 ∧Γ2 to be T1,1 ⊕T2,3-satisﬁable, which is
impossible. Hence the fact that T2,3 is not strongly polite propagates all the way
to the polite combination method.7
6 In [8], the ﬁrst condition is written
σA
1
 ≥2. We use equality as this is equivalent
and we believe it makes things clearer.
7
Notice that T2,3 can be axiomatized using the following set of axioms, given the
deﬁnitions in Figure 1:

ψσ1
≥2, ψσ2
≥3

∪{ψσ1
=2 →¬ψσ2
=n | n ≥3}
Politeness and Stable Inﬁniteness: Stronger Together
154

distinct(x1, . . . , xn) :=

1≤i<j<=n
xi ̸= xj
ψσ
≥n := ∃x1, . . . , xn.distinct(x1, . . . , xn)
ψσ
≤n := ∃x1, . . . , xn.∀y.
n

i=1
y = xi
ψσ
=n := ψσ
≥n ∧ψσ
≤n
Fig. 1. Cardinality formulas for sort σ. All variables are assumed to have sort σ.
Remark 1. An alternative way to separate politeness from strong politeness us-
ing T2,3 can be obtained through shiny theories, as follows. Shiny theories were
introduced in [21] for the mono-sorted case, and were generalized to many-sorted
signatures in two diﬀerent ways in [8] and [17]. In [8], T2,3 was introduced as a
theory that is shiny according [17], but not according to [8]. Theorem 1 of [8]
states that their notion of shininess is equivalent to strong politeness for theories
in which the satisﬁability problem for quantiﬁer-free formulas is decidable. Since
this is the case for T2,3, and since it is not shiny according to [8], we get that
T2,3 is not strongly polite. Further, Proposition 18 of [17] states that every shiny
theory (according to their deﬁnition) is polite. Hence we get that T2,3 is polite
but not strongly polite.
We have (and prefer) a direct proof based only on politeness, without a detour
through shininess. Note also that [8] dealt only with strongly polite theories and
did not study the weaker notion of polite theories. In particular, the fact that
strong politeness is diﬀerent from politeness was not stated nor proved there.
3.3
The Case of Mono-sorted Polite Theories
Theory T2,3 includes two sorts but is otherwise empty. In this section, we show
that requiring two sorts is essential for separating politeness from strong polite-
ness in otherwise empty signatures. That is, we prove that politeness implies
strong politeness otherwise. Let Σ0 be the signature with a single sort σ and
no function or predicate symbols (except =). We show that smooth Σ0-theories
have a certain form and conclude strong politeness from politeness.
Lemma 4. Let T be a Σ0-theory. If T is smooth w.r.t. σ and includes a ﬁnite
structure, T is axiomatized by ψσ
≥n from Figure 1 for some n > 0.
Proposition 1. If T is a Σ0-theory that is polite w.r.t. σ, then it is strongly
polite w.r.t. σ.
Remark 2. We again note (as we did in Remark 1) that an alternative way
to obtain this result is via shiny theories, using [17], which introduced polite
theories, as well as [7], which compared strongly polite theories to shiny theories
155
Y. Sheng et al.

in the mono-sorted case. Speciﬁcally, in the presence of a single sort, Proposition
19 of [17] states that:
(∗)
if the question of whether a polite theory over a ﬁnite signature con-
tains a ﬁnite structure is decidable, the theory is shiny.
In turn, Proposition 1 of [7] states that:
(∗∗) every shiny theory over a mono-sorted signature with a decidable sat-
isﬁability problem for quantiﬁer-free formulas is also strongly polite.
It can be shown that the question of whether a polite Σ0-theory contains a ﬁnite
structure is decidable. It can also be shown that satisﬁability of quantiﬁer-free
formulas is decidable for such theories. Using (∗) and (∗∗), we get that in Σ0-
theories, politeness implies strong politeness. As above (Remark 1), we prefer a
direct route for showing this result, without going through shiny theories.
3.4
Mono-sorted Finite Witnessability
We have seen that for Σ0-theories, politeness and strong politeness are the same.
Now we show that smoothness is crucial for this equivalence, i.e., that there is
no such equivalence between ﬁnite witnessability and strong ﬁnite witnessability.
Let T ∞
Even be the Σ0-theory of all Σ0-structures A such that
σA is even or
inﬁnite.8 Clearly, this theory is not smooth.
Lemma 5. T ∞
Even is not smooth w.r.t. σ.
We can construct a witness wit for T ∞
Even as follows. Let φ be a quantiﬁer-free
Σ0-formula, and let E be the set of all equivalence relations over vars(φ) ∪{w}
for some fresh variable w. Let even(E) be the set of all equivalence relations in
E with an even number of equivalence classes. Then, wit(φ) is φ∧
e∈even(E) δe,
where for each e ∈even(E), δe is the arrangement induced by e:

(x,y)∈e
x = y ∧

x,y∈vars (φ)∪{w}∧(x,y)̸∈e
x ̸= y
It can be shown that wit is indeed a witness, and that T ∞
Even has no strong
witness, with a proof similar to that of Lemma 3.
Lemma 6. T ∞
Even is ﬁnitely witnessable w.r.t. σ.
Lemma 7. T ∞
Even is not strongly ﬁnitely witnessable w.r.t. σ.
4
A Blend of Polite and Stably-Inﬁnite Theories
In this section, we show that the polite combination method can be optimized
to reduce the search space of possible arrangements. In what follows, Σ1 and Σ2
are disjoint signatures, S = SΣ1 ∩SΣ2, T1 is a Σ1-theory, T2 is a Σ2-theory, Γ1
is a set of Σ1-literals, and Γ2 is a set of Σ2-literals.
8 Notice that T ∞
Even can be axiomatized using the set {¬ψσ
=2n+1 | n ∈N}.
Politeness and Stable Inﬁniteness: Stronger Together
156

The Nelson-Oppen procedure reduces the T1 ⊕T2-satisﬁability of Γ1 ∪Γ2
to the existence of an arrangement δ over the set V = varsS(Γ1) ∩varsS(Γ2),
such that Γ1 ∪δ is T1-satisﬁable and Γ2 ∪δ is T2-satisﬁable. The correctness of
this reduction relies on the fact that both theories are stably inﬁnite w.r.t. S. In
contrast, the polite combination method only requires a condition (namely strong
politeness) from one of the theories, while the other theory is unrestricted and,
in particular, not necessarily stably inﬁnite. In polite combination, the T1 ⊕T2-
satisﬁability of Γ1 ∪Γ2 is again reduced to the existence of an arrangement δ,
but over a diﬀerent set V ′ = varsS(wit(Γ2)), such that Γ1 ∪δ is T1-satisﬁable
and wit(Γ2) ∪δ is T2-satisﬁable, where wit is a strong witness for T2 w.r.t. S.
Thus, the ﬂexibility oﬀered by polite combination comes with a price. The set
V ′ is potentially larger than V as it contains all variables with sorts in S that
occur in wit(Γ2), not just those that also occur in Γ1. Since the search space
of arrangements over a set grows exponentially with its size, this diﬀerence can
become crucial. If T1 happens to be stably inﬁnite w.r.t. S, however, we can fall
back to Nelson-Oppen combination and only consider variables that are shared
by the two sets. But what if T1 is stably inﬁnite only w.r.t. to some proper subset
S′ ⊂S? Can this knowledge about T1 help in ﬁnding some set V ′′ of variables
between V and V ′, such that we need only consider arrangements of V ′′? In this
section we prove that this is possible by taking V ′′ to include only the variables
of sorts in S′ that are shared between Γ1 and wit(Γ2), and all the variables of
sorts in S \ S′ that occur in wit(Γ2). We also identify several weaker conditions
on T2 that are suﬃcient for the combination theorem to hold.
4.1
Reﬁned Combination Theorem
To put the discussion above in formal terms, we recall the following theorem.
Theorem 3 ([12]).
If T2 is strongly polite w.r.t. S with a witness wit, then
the following are equivalent: 1. Γ1 ∪Γ2 is (T1 ⊕T2)-satisﬁable; 2. there exists an
arrangement δV over V , such that Γ1 ∪δV is T1-satisﬁable and wit(Γ2) ∪δV is
T2-satisﬁable, where V = 
σ∈S Vσ, and Vσ = varsσ(wit(Γ2)) for each σ ∈S.
Our goal is to identify general cases in which information regarding T1 can
help reduce the size of the set V . We extend the deﬁnitions of stably inﬁnite,
smooth, and strongly ﬁnitely witnessable to two sets of sorts rather than one.
Roughly speaking, in this extension, the usual deﬁnition is taken for the ﬁrst
set, and some cardinality-preserving constraints are enforced on the second set.
Deﬁnition 4. Let Σ be a signature, S1, S2 two disjoint subsets of SΣ, and T a
Σ-theory.
T is (strongly) stably inﬁnite w.r.t. (S1, S2) if for every quantiﬁer-free Σ-
formula φ and T -interpretation A satisfying φ, there exists a T -interpretation B
such that B |= φ, |σB| is inﬁnite for every σ ∈S1, and |σB| ≤|σA| (|σB| = |σA|)
for every σ ∈S2.
T
is smooth w.r.t. (S1, S2) if for every quantiﬁer-free Σ-formula φ, T -
interpretation A satisfying φ, and function κ from S1 to the class of cardinals
157
Y. Sheng et al.

such that κ(σ) ≥
σA for each σ ∈S1, there exists a T -interpretation B that
satisﬁes φ, with
σB = κ(σ) for each σ ∈S1, and with
σB inﬁnite whenever
σA is inﬁnite for each σ ∈S2.
T is strongly ﬁnitely witnessable w.r.t. (S1, S2) if there exists a computable
function wit : QF(Σ) →QF(Σ) such that for every quantiﬁer-free Σ-formula
φ: 1. φ and ∃−→
w . wit(φ) are T -equivalent for −→
w = vars(wit(φ)) \ vars(φ); and
2. for every T -interpretation A and arrangement δ of any set of variables whose
sorts are in S1, if A satisﬁes wit(φ) ∧δ, then there exists a T -interpretation B
that ﬁnitely witnesses wit(φ)∧δ w.r.t. S1 and for which
σB is inﬁnite whenever
σA is inﬁnite, for each σ ∈S2.
Our main result is the following.
Theorem 4. Let Ssi ⊆S and Snsi = S \ Ssi. Suppose T1 is stably inﬁnite
w.r.t. Ssi and one of the following holds:
1. T2 is strongly stably inﬁnite w.r.t. (Ssi, Snsi) and strongly polite w.r.t. Snsi
with a witness wit.
2. T2 is stably inﬁnite w.r.t. (Ssi, Snsi), smooth w.r.t. (Snsi, Ssi), and strongly
ﬁnitely witnessable w.r.t. Snsi with a witness wit.
3. T2 is stably inﬁnite w.r.t. Ssi while smooth and strongly ﬁnitely-witnessable
w.r.t. (Snsi, Ssi) with a witness wit.
Then the following are equivalent: 1. Γ1∪Γ2 is (T1⊕T2)-satisﬁable; 2. There exists
an arrangement δV over V such that Γ1∪δV is T1-satisﬁable, and wit(Γ2)∪δV is
T2-satisﬁable, where V = 
σ∈S Vσ, with Vσ = varsσ(wit(Γ2)) for every σ ∈Snsi
and Vσ = varsσ(Γ1) ∩varsσ(wit(Γ2)) for every σ ∈Ssi.
All three items of Theorem 4 include assumptions that guarantee that the two
theories agree on cardinalities of shared sorts. For example, in the ﬁrst item, we
ﬁrst shrink the Snsi-domains of the T2-model using strong ﬁnite witnessability,
and then expand them using smoothness. But then, to obtain inﬁnite domains
for the Ssi sorts, stable inﬁniteness is not enough, as we need to maintain the
cardinalities of the Snsi domains while making the domains of the Ssi sorts
inﬁnite. For this, the stronger property of strong stable inﬁniteness is used.
The formal proof of this theorem is provided in Section 4.2, below. Figure 2
is a visualization of the claims in Theorem 4. The theorem considers two variants
of strong ﬁnite witnessability, two variants of smoothness, and three variants of
stable inﬁniteness. For each of the three cases of Theorem 4, Figure 2 shows
which variant of each property is assumed. The height of each bar corresponds
to the strength of the property. In the ﬁrst case, we use ordinary strong ﬁnite
witnessability and smoothness, but the strongest variant of stable inﬁniteness;
in the second, we use ordinary strong ﬁnite witnessability with the new variants
of stable inﬁniteness and smoothness; and for the third, we use ordinary stable
inﬁniteness and the stronger variants of strong ﬁnite witnessability and smooth-
ness. The order of the bars corresponds to the order of their usage in the proof of
each case. The stage at which stable inﬁniteness is used determines the required
Politeness and Stable Inﬁniteness: Stronger Together
158

Case 1
Case 2
Case 3
regular
medium
strong
strong ﬁnite witnessability
smoothness
stable inﬁniteness
Fig. 2. Theorem 4. The height of each bar corresponds to the strength of the
property. The bars are ordered according to their usage in the proof.
strength of the other properties: whatever is used before is taken in ordinary
form, and whatever is used after requires a stronger form.
Going back to the standard deﬁnitions of stable inﬁniteness, smoothness, and
strong ﬁnite witnessability, we get the following corollary by using case 1 of the
theorem and noticing that smoothness w.r.t. S implies strong stable inﬁniteness
w.r.t. any partition of S.
Corollary 1. Let Ssi ⊆S and Snsi = S \ Ssi. Suppose T1 is stably inﬁnite
w.r.t. Ssi and T2 is strongly ﬁnitely witnessable w.r.t. Snsi with witness wit and
smooth w.r.t. S. Then, the following are equivalent:
1. Γ1 ∪Γ2 is (T1 ⊕T2)-satisﬁable; 2. there exists an arrangement δV over
V such that Γ1 ∪δV is T1-satisﬁable and wit(Γ2) ∪δV is T2-satisﬁable, where
V = 
σ∈S Vσ, with Vσ = varsσ(wit(Γ2)) for σ ∈Snsi and Vσ = varsσ(Γ1) ∩
varsσ(wit(Γ2)) for σ ∈Ssi.
Finally, the following result, which is closest to Theorem 3, is directly ob-
tained from Corollary 1, since the strong politeness of T2 w.r.t. Ssi ∪Snsi implies
that it is strongly ﬁnitely witnessable w.r.t. Snsi and smooth w.r.t. Ssi ∪Snsi.
Corollary 2. Let Ssi ⊆S and Snsi = S \ Ssi. If T1 is stably inﬁnite w.r.t. Ssi
and T2 is strongly polite w.r.t. S with a witness wit, then the following are
equivalent: 1. Γ1 ∪Γ2 is (T1 ⊕T2)-satisﬁable; 2. there exists an arrangement
δV over V such that Γ1 ∪δV is T1-satisﬁable and wit(Γ2) ∪δV is T2-satisﬁable,
where V = 
σ∈S Vσ, with Vσ = varsσ(wit(Γ2)) for each σ ∈Snsi and Vσ =
varsσ(Γ1) ∩varsσ(wit(Γ2)) for each σ ∈Ssi.
Compared to Theorem 3, Corollary 2 partitions S into Ssi and Snsi and
requires that T1 be stably inﬁnite w.r.t. Ssi. The gain from this requirement is
that the set Vσ is potentially reduced for σ ∈Ssi. Note that unlike Theorem 4
and Corollary 1, Corollary 2 has the same assumptions regarding T2 as the
original Theorem 3 from [12]. We show its potential impact in the next example.
Example 7. Consider the theory TListIntBV4 from Example 3. Let Γ1 be x =
5 ∧v = 0000 ∧w = w & v, and let Γ2 be a0 = cons(x, v, a1) ∧n
i=1 ai =
159
Y. Sheng et al.

cons(yi, w, ai+1). Using the witness function wit from [18], wit(Γ2) = Γ2. The
polite combination approach reduces the TListIntBV4-satisﬁability of Γ1 ∧Γ2 to
the existence of an arrangement δ over {x, v, w}∪{y1, . . . , yn}, such that Γ1∧δ is
TIntBV4-satisﬁable and wit(Γ2) ∧δ is TList-satisﬁable. Corollary 2 shows that we
can do better. Since TIntBV4 is stably inﬁnite w.r.t. {int}, it is enough to check
the existence of an arrangement over the variables of sort BV4 that occur in
wit(Γ2), together with the variables of sort int that are shared between Γ1 and
Γ2. This means that arrangements over {x, v, w} are considered, instead of over
{x, v, w}∪{y1, . . . , yn}. As n becomes large, standard polite combination requires
considering exponentially more arrangements, while the number of arrangements
considered by our combination method remains the same.
⊓⊔
4.2
Proof of Theorem 4
The left-to-right direction is straightforward, using the reducts of the satisfy-
ing interpretation of Γ1 ∪Γ2 to Σ1 and Σ2. We now focus on the right-to-left
direction, and begin with the following lemma, which strengthens Theorem 1,
obtaining a many-sorted L¨owenheim-Skolem Theorem, where the cardinality of
the ﬁnite sorts remains the same.
Lemma 8. Let Σ be a signature, T a Σ-theory, ϕ a Σ-formula, and A a T -
interpretation that satisﬁes φ. Let SΣ = Sﬁn
A ⊎Sinf
A , where σA is ﬁnite for
every σ ∈Sﬁn
A
and σA is inﬁnite for every σ ∈Sinf
A . Then there exists a T -
interpretation B that satisﬁes ϕ such that
σB =
σA for every σ ∈Sﬁn
A
and
σB is countable for every σ ∈Sinf
A .
The proof of Theorem 4 continues with the following main lemma.
Lemma 9 (Main Lemma).
Let Ssi ⊆S and Snsi = S \ Ssi, Suppose T1
is stably inﬁnite w.r.t. Ssi and that one of the three cases of Theorem 4 holds.
Further, assume there exists an arrangement δV over V such that Γ1 ∪δV is
T1-satisﬁable, and wit(Γ2) ∪δV is T2-satisﬁable, where V = 
σ∈S Vσ, with Vσ =
varsσ(wit(Γ2)) for each σ ∈Snsi and Vσ = varsσ(Γ1) ∩varsσ(wit(Γ2)) for each
σ ∈Ssi. Then, there is a T1-interpretation A that satisﬁes Γ1 ∪δV and a T2-
interpretation B that satisﬁes wit(Γ2) ∪δV such that
σA =
σB for all σ ∈S.
Proof : Let ψ2 := wit(Γ2). Since T1 is stably inﬁnite w.r.t. Ssi, there is a T1-
interpretation A satisfying Γ1 ∪δV in which σA is inﬁnite for each σ ∈Ssi.
By Theorem 1, we may assume that σA is countable for each σ ∈Ssi. We
consider the ﬁrst case of Theorem 4 (the others are omitted due to space con-
straints). Suppose T2 is strongly stably inﬁnite w.r.t. (Ssi, Snsi) and strongly
polite w.r.t. Snsi. Since T2 is strongly ﬁnitely-witnessable w.r.t. Snsi, there
exists a T2-interpretation B that satisﬁes ψ2 ∪δV such that σB = V B
σ
for
each σ ∈Snsi. Since A and B satisfy δV , we have that for every σ ∈Snsi,
σB =
V B
σ
 =
V A
σ
 ≤
σA. T2 is also smooth w.r.t. Snsi, and so there ex-
ists a T2-interpretation B′ satisfying ψ2 ∪δV such that
σB′ =
σA for each
Politeness and Stable Inﬁniteness: Stronger Together
160

σ ∈Snsi. Finally, T2 is strongly stably inﬁnite w.r.t. (Ssi, Snsi), so there is a T2-
interpretation B′′ that satisﬁes ψ2 ∪δV such that σB′′ is inﬁnite for each σ ∈Ssi
and
σB′′ =
σB′ =
σA for each σ ∈Snsi. By Lemma 8, we may assume that
σB′′ is countable for each σ ∈Ssi. Thus,
σB′′ =
σA for each σ ∈S.
⊓⊔
We now conclude Theorem 4: Let T := T1 ⊕T2. Lemma 9 gives us a T1
interpretation A with A |= Γ1 ∪δV and a T2 interpretation B with B |= ψ2 ∪δV ,
and
σA =
σB for σ ∈S. Set Γ ′
1 := Γ1 ∪δV and Γ ′
2 := ψ2 ∪δV . Then, Vσ =
varsσ(Γ ′
1)∩varsσ(Γ ′
2) for σ ∈S. Now, A |= Γ ′
1∪δV and B |= Γ ′
2∪δV . Also, |σA| =
|σB| for σ ∈S. By Theorem 2, Γ ′
1 ∪Γ ′
2 is T -satisﬁable. In particular, Γ1 ∪{ψ2} is
T -satisﬁable, and hence also Γ1 ∪{∃w.ψ2}, with w = vars(wit(Γ2)) \ vars(Γ2).
Finally, ∃w.wit(Γ2) is T2-equivalent to Γ2, hence Γ1 ∪Γ2 is T -satisﬁable.
⊓⊔
5
Preliminary Case Study
The results presented in Section 4 was motivated by a set of smart contract
veriﬁcation benchmarks. We obtained these benchmarks by applying the open-
source Move Prover veriﬁer [22] to smart contracts found in the open-source Diem
project [9]. The Move prover is a formal veriﬁer for smart contracts written in the
Move language [6] and was designed to target smart contracts used in the Diem
blockchain [1]. It works via a translation to the Boogie veriﬁcation framework
[14], which in turn produces SMT-LIB 2 benchmarks that are dispatched to SMT
solvers. The benchmarks we obtained involve datatypes, integers, Booleans, and
quantiﬁers. Our case study began by running CVC4 [3] on the benchmarks. For
most of the benchmarks that were solved by CVC4, theory combination took a
small percentage of the overall runtime of the solver, accounting for 10% or less
in all but 1 benchmark. However, solving that benchmark took 81 seconds, of
which 20 seconds was dedicated to theory combination.
We implemented an optimization to the datatype solver of CVC4 based on
Corollary 2. With the original polite combination method, every term that orig-
inates from the theory of datatypes with another sort is shared with the other
theories, triggering an analysis of the arrangements of these terms. In our op-
timization, we limit the sharing of such terms to those of Boolean sort. In the
language of Corollary 2, T1 is the combined theory of Booleans, uninterpreted
functions, and integers, which is stably inﬁnite w.r.t. the uninterpreted sorts
and integer sorts. T2 is an instance of the theory of datatypes, which is strongly
polite w.r.t. its element sorts, which in this case are the sorts of T1.
A comparison of an original and optimized run on the diﬃcult benchmark
is shown in Figure 3. As shown, the optimization reduces the total running
time by 75%, and the time spent on theory combination in particular by 83%.
To further isolate the eﬀectiveness of our optimization, we report the number of
terms that each theory solver considered. In CVC4, constraints are not ﬂattened,
so shared terms are processed instead of shared variables. Each theory solver
161
Y. Sheng et al.

total (s) comb (s)
DT
INT UFB shared
optimized
34.9
3.4
236.1 212.1 78.4
125.8
original
81.5
20.3
116.0 281.0 123.9 163.5
Fig. 3. Runtimes (in seconds) and number of terms (in thousands) added to the
data structures of DT, INT, UFB, and the number of shared terms (shared).
maintains its own data structure for tracking equality information. These data
structures contain terms belonging to the theory that either come from the
input assertions or are shared with another theory. A data structure is also
maintained that contains all shared terms belonging to any theory. The last 4
columns of Figure 3 count the number of times (in thousands) a term was added
to the equality data structure for the theory of datatypes (DT), integers (INT),
and uninterpreted functions and Booleans (UFB), as well as to the the shared
term data structure (shared). With the optimization, the datatype solver keeps
more inferred assertions internally, which leads to an increase in the number of
additions of terms to its data structure. However, sharing fewer terms, reduces
the number of terms in the data structures for the other theories. Moreover, while
the total number of terms considered remains roughly the same, the number of
shared terms decreases by 24%. This suggests that although the workload on the
individual theory solvers is roughly similar, a decrease in the number of shared
terms in the optimized run results in a signiﬁcant improvement in the overall
runtime. Although our evidence is only anecdotal at the moment, we believe this
benchmark is highly representative of the potential beneﬁts of our optimization.
6
Conclusion
This paper makes two contributions. First, we separated politeness and strong
politeness, which shows that sometimes, the (typically harder) task of ﬁnding
a strong witness is not a waste of eﬀort. Then, we provided an optimization to
the polite combination method, which applies when one of the theories in the
combination is stably inﬁnite w.r.t. a subset of the sorts.
We envision several directions for future work. First, the sepration of polite-
ness from strong politeness demonstrates a need to identify suﬃcient criteria for
the equivalence of these notions — such as, for instance, the additivity criterion
introduced by Sheng et al. [18]. Second, polite combination might be optimized
by applying the witness function only to part of the puriﬁed input formula. Fi-
nally, we plan to extend the initial implementation of this approach in CVC4
and evaluate its impact based on more benchmarks.
Politeness and Stable Inﬁniteness: Stronger Together
162

References
1. Amsden, Z., Arora, R., Bano, S., Baudet, M., Blackshear, S., Bothra, A., Cabrera,
G., Catalini, C., Chalkias, K., Cheng, E., Ching, A., Chursin, A., Danezis, G.,
Giacomo, G.D., Dill, D.L., Ding, H., Doudchenko, N., Gao, V., Gao, Z., Garillot,
F., Gorven, M., Hayes, P., Hou, J.M., Hu, Y., Hurley, K., Lewi, K., Li, C., Li, Z.,
Malkhi, D., Margulis, S., Maurer, B., Mohassel, P., de Naurois, L., Nikolaenko,
V., Nowacki, T., Orlov, O., Perelman, D., Pott, A., Proctor, B., Qadeer, S., Rain,
Russi, D., Schwab, B., Sezer, S., Sonnino, A., Venter, H., Wei, L., Wernerfelt, N.,
Williams, B., Wu, Q., Yan, X., Zakian, T., Zhou, R.: The Diem Blockchain. https://
developers.diem.com/docs/technical-papers/the-diem-blockchain-paper/ (2019)
2. Barrett, C., Fontaine, P., Tinelli, C.: The SMT-LIB Standard: Version 2.6. Tech.
rep., Department of Computer Science, The University of Iowa (2017), available
at www.SMT-LIB.org
3. Barrett, C.W., Conway, C.L., Deters, M., Hadarean, L., Jovanovic, D., King, T.,
Reynolds, A., Tinelli, C.: CVC4. In: Gopalakrishnan, G., Qadeer, S. (eds.) Com-
puter Aided Veriﬁcation - 23rd International Conference, CAV 2011, Snowbird, UT,
USA, July 14-20, 2011. Proceedings. Lecture Notes in Computer Science, vol. 6806,
pp. 171–177. Springer (2011), https://doi.org/10.1007/978-3-642-22110-1 14
4. Barrett, C.W., Shikanian, I., Tinelli, C.: An abstract decision procedure for a
theory of inductive data types. Journal on Satisﬁability, Boolean Modeling and
Computation 3(1-2), 21–46 (2007)
5. Barrett, C.W., Tinelli, C.: Satisﬁability modulo theories. In: Clarke, E.M., Hen-
zinger, T.A., Veith, H., Bloem, R. (eds.) Handbook of Model Checking, pp. 305–
343. Springer (2018), https://doi.org/10.1007/978-3-319-10575-8 11
6. Blackshear, S., Cheng, E., Dill, D.L., Gao, V., Maurer, B., Nowacki, T.,
Pott, A., Qadeer, S., Rain, Russi, D., Sezer, S., Zakian, T., Zhou, R.: Move:
A language with programmable resources. https://developers.diem.com/docs/
technical-papers/move-paper/ (2019)
7. Casal, F., Rasga, J.: Revisiting the equivalence of shininess and politeness. In:
McMillan, K.L., Middeldorp, A., Voronkov, A. (eds.) Logic for Programming, Ar-
tiﬁcial Intelligence, and Reasoning - 19th International Conference, LPAR-19, Stel-
lenbosch, South Africa, December 14-19, 2013. Proceedings. Lecture Notes in Com-
puter Science, vol. 8312, pp. 198–212. Springer (2013), https://doi.org/10.1007/
978-3-642-45221-5 15
8. Casal, F., Rasga, J.: Many-sorted equivalence of shiny and strongly polite
theories. J. Autom. Reason. 60(2), 221–236 (2018), https://doi.org/10.1007/
s10817-017-9411-y
9. diem: https://github.com/diem/diem
10. Enderton, H.B.: A mathematical introduction to logic. Academic Press (2001)
11. Fontaine, P.: Combinations of theories for decidable fragments of ﬁrst-order logic.
In: Ghilardi, S., Sebastiani, R. (eds.) Frontiers of Combining Systems, 7th Inter-
national Symposium, FroCoS 2009, Trento, Italy, September 16-18, 2009. Proceed-
ings. Lecture Notes in Computer Science, vol. 5749, pp. 263–278. Springer (2009),
https://doi.org/10.1007/978-3-642-04222-5 16
12. Jovanovic, D., Barrett, C.W.: Polite theories revisited. In: Ferm¨uller, C.G.,
Voronkov, A. (eds.) Logic for Programming, Artiﬁcial Intelligence, and Reasoning
- 17th International Conference, LPAR-17, Yogyakarta, Indonesia, October 10-15,
2010. Proceedings. Lecture Notes in Computer Science, vol. 6397, pp. 402–416.
Springer (2010), https://doi.org/10.1007/978-3-642-16242-8 29
163
Y. Sheng et al.

13. Krstic, S., Goel, A., Grundy, J., Tinelli, C.: Combined satisﬁability modulo para-
metric theories. In: Grumberg, O., Huth, M. (eds.) Tools and Algorithms for the
Construction and Analysis of Systems, 13th International Conference, TACAS
2007, Held as Part of the Joint European Conferences on Theory and Practice
of Software, ETAPS 2007 Braga, Portugal, March 24 - April 1, 2007, Proceed-
ings. Lecture Notes in Computer Science, vol. 4424, pp. 602–617. Springer (2007),
https://doi.org/10.1007/978-3-540-71209-1 47
14. Leino, K.R.M.: This is Boogie 2. manuscript KRML 178(131),
9 (2008), https:
//www.microsoft.com/en-us/research/publication/this-is-boogie-2-2/
15. Nelson, G.: Techniques for program veriﬁcation. Tech. Rep. CSL-81-10, Xerox, Palo
Alto Research Center (1981)
16. Nelson, G., Oppen, D.C.: Simpliﬁcation by cooperating decision procedures.
ACM Trans. Program. Lang. Syst. 1(2), 245–257 (1979), https://doi.org/10.1145/
357073.357079
17. Ranise, S., Ringeissen, C., Zarba, C.G.: Combining data structures with non-
stably inﬁnite theories using many-sorted logic. In: Gramlich, B. (ed.) Frontiers
of Combining Systems, 5th International Workshop, FroCoS 2005, Vienna, Aus-
tria, September 19-21, 2005, Proceedings. Lecture Notes in Computer Science,
vol. 3717, pp. 48–64. Springer (2005), extended technical report is available at
https://hal.inria.fr/inria-00070335/
18. Sheng, Y., Zohar, Y., Ringeissen, C., Lange, J., Fontaine, P., Barrett, C.W.: Polite-
ness for the theory of algebraic datatypes. In: Peltier, N., Sofronie-Stokkermans,
V. (eds.) Automated Reasoning - 10th International Joint Conference, IJCAR
2020, Paris, France, July 1-4, 2020, Proceedings, Part I. Lecture Notes in Com-
puter Science, vol. 12166, pp. 238–255. Springer (2020), https://doi.org/10.1007/
978-3-030-51074-9 14
19. Tinelli, C., Zarba, C.G.: Combining decision procedures for sorted theories. In:
Alferes, J.J., Leite, J.A. (eds.) Logics in Artiﬁcial Intelligence, 9th European Con-
ference, JELIA 2004, Lisbon, Portugal, September 27-30, 2004, Proceedings. Lec-
ture Notes in Computer Science, vol. 3229, pp. 641–653. Springer (2004)
20. Tinelli, C., Zarba, C.G.: Combining decision procedures for sorted theories. In:
Alferes, J.J., Leite, J.A. (eds.) Logics in Artiﬁcial Intelligence, 9th European
Conference, JELIA 2004, Lisbon, Portugal, September 27-30, 2004, Proceedings.
Lecture Notes in Computer Science, vol. 3229, pp. 641–653. Springer (2004),
https://doi.org/10.1007/978-3-540-30227-8 53
21. Tinelli, C., Zarba, C.G.: Combining nonstably inﬁnite theories. J. Autom. Reason.
34(3), 209–238 (2005), https://doi.org/10.1007/s10817-005-5204-9
22. Zhong, J.E., Cheang, K., Qadeer, S., Grieskamp, W., Blackshear, S., Park, J.,
Zohar, Y., Barrett, C.W., Dill, D.L.: The Move prover. In: Lahiri, S.K., Wang, C.
(eds.) Computer Aided Veriﬁcation - 32nd International Conference, CAV 2020,
Los Angeles, CA, USA, July 21-24, 2020, Proceedings, Part I. Lecture Notes in
Computer Science, vol. 12224, pp. 137–150. Springer (2020), https://doi.org/10.
1007/978-3-030-53288-8 7
Politeness and Stable Inﬁniteness: Stronger Together
164

Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.
165
Y. Sheng et al.

Equational Theorem Proving Modulo
Clarkson University, Potsdam, NY, USA
{dohkim,clynch}@clarkson.edu
Abstract. Unlike other methods for theorem proving modulo with con-
strained clauses [12, 13], equational theorem proving modulo with con-
strained clauses along with its simpliﬁcation techniques has not been well
studied. We introduce a basic paramodulation calculus modulo equa-
tional theories E satisfying certain properties of E and present a new
framework for equational theorem proving modulo E with constrained
clauses. We propose an inference rule called Generalized E-Parallel for
constrained clauses, which makes our inference system completely ba-
sic, meaning that we do not need to allow any paramodulation in the
constraint part of a constrained clause for refutational completeness. We
present a saturation procedure for constrained clauses based on relative
reducibility and show that our inference system including our contraction
rules is refutationally complete.
1
Introduction
Equations occur frequently in many areas of mathematics, logics, and com-
puter science. Equational theorem proving
[6, 8, 19, 22] is, in general, con-
cerned with proving mathematical or logical statements in ﬁrst-order clause
logic with equality. While resolution [24] has been successful for theorem prov-
ing for ﬁrst-order clause logic without equality, it has some limitations to deal
with the equality predicate. For example, when dealing with the equality pred-
icate using resolution, one must add the congruence axioms explicitly for each
predicate and function symbol in order to express the properties of equal-
ity [8,22].
Paramodulation [23] is based on the replacement of equals by equals, in or-
der to improve the eﬃciency of resolution in equational theorem proving. How-
ever, paramodulation, in general, often produces a large amount of unnecessary
clauses, so the search space for a refutation expands very rapidly. Therefore, var-
ious improvements have been developed for paramodulation. For example, it was
shown that the functional reﬂexivity equations used by the traditional paramod-
ulation rule [23] are not needed, and paramodulation into variables does not need
to be allowed (see [8]).
Basic paramodulation [9,20] restricts paramodulation by forbidding paramod-
ulation at (sub)terms introduced by substitutions from previous inference steps,
and uses orderings on terms and literals in order to further restrict paramod-
ulation inferences. In [21, 26], basic paramodulation had been extended to
basic paramodulation modulo associativity and commutativity (AC) axioms.
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5_10
Dohan Kim(B)
and Christopher Lynch
166–182, 2021.

Equational Theorem Proving Modulo
167
(See [25] also for basic paramodulation modulo the associativity (A) axiom.)
Basic paramodulation modulo AC uses the symbolic constraints, overcoming a
drawback of traditional paramodulation modulo AC (see [7,27]) that often gener-
ates many slightly diﬀerent permuted variants of clauses. For example, more than
a million conclusions can possibly be generated by paramodulating the equation
x + x + x = x into the clause P(y1 + y2 + y3 + y4) for which + is an AC symbol,
since a minimal complete set of AC-uniﬁers for x + x + x and y1 + y2 + y3 + y4
contains more than a million AC-uniﬁers [21,26]. On the other hand, one only
needs a single conclusion P(x) || x + x + x ≈?
AC y1 + y2 + y3 + y4 for the above
inference using basic paramodulation modulo AC with an equality constraint.
In this paper, we present a new basic paramodulation calculus modulo equa-
tional theories E (including E = AC) parameterized by a suitable E-compatible
ordering ≻. Our main inference rule for basic paramodulation modulo E is given
(roughly) as follows:
C ∨s ≈t || φ1
D ∨L[s′] || φ2
C ∨D ∨L[t] || s ≈?
E s′ ∧φ1 ∧φ2
The equality constraints are inherited and the accumulated E-uniﬁcation prob-
lems are kept in the constraint part of conclusion. Instead of generating as
many conclusions as minimal and complete E-uniﬁers of two terms s and s′,
a single conclusion is generated with its constraint keeping the E-uniﬁcation
problem of s and s′. Another key inference rule in our basic paramodulation
calculus modulo E is the Generalized E-Parallel (or E-Parallel) rule, adapted
from our recent work on basic narrowing modulo [18]. This rule allows our basic
paramodulation calculus to adapt the free case (i.e. E = ∅) to the modulo E
case (i.e. E ̸= ∅).1 For example, suppose that we have three clauses 1 : a+b ≈c,
2 : a+(b+x) ≈c+x, and 3 : (a+a)+(b+b) ̸≈c+c, where + is an AC symbol
with + ≻a ≻b ≻c. We use the E-Parallel rule from clause 1 and 2 and obtain
the clause 4 : a + (b + (a + b)) ≈c + c, which derives a contradiction with clause
3 because a + (b + (a + b)) ≈AC (a + a) + (b + b) (i.e. the equality constraint is
satisﬁable). The details of this inference rule are discussed in Section 4.
Throughout this paper, we assume that (i) we are given an E-compatible
reduction ordering ≻on terms with the subterm property that is E-total on
ground terms, (ii) E has a ﬁnitary and complete uniﬁcation algorithm, and (iii)
E-congruence classes are ﬁnite. (If E satisﬁes condition (i), then E is necessarily
regular [2].) With these assumptions of E, we can deal uniformly with diﬀerent
equational theories E in our framework and show that our inference system in-
cluding our contraction rules is refutationally complete.
The known practical theories satisfying the above assumptions of E are AC
and ﬁnite permutation theories [1, 17]. (For example, if one considers an ACI
symbol + using our approach, then AC should be a modulo E part and the
idempotency axiom (I : x + x ≈x) should be a part of the input formulas.) Al-
though associative (A)-uniﬁcation is inﬁnitary, our approach is also applicable
1 If E = ∅, then we may disregard the Generalized E-Parallel (or E-Parallel) rule along
with the E-Completion rule and replace E-uniﬁcation with syntactic uniﬁcation.

168
D. Kim and C. Lynch
to the case where E = A in practice, since there is a tool for A-uniﬁcation which
is guaranteed to terminate with a ﬁnite and complete set of A-uniﬁers for a sig-
niﬁcantly large class of A-uniﬁcation problems (see [14]).
The longer version of this paper is found in [16].
2
Preliminaries
We assume that the reader has some familiarity with rewrite systems [3] (in-
cluding the extended rewrite system for R modulo E (i.e. R, E) [11, 15]) and
uniﬁcation [4]. We use the standard terminology of paramodulation [6,9,22].
We denote by T(F, X) the set of terms over a ﬁnite set of function sym-
bols F and a denumerable set of variables X. An equation is an expression
s ≈t, where s and t are (ﬁrst-order) terms built from T(F, X). A literal is
either an equation L (a positive literal) or a negative equation ¬L (a negative
literal). A clause is a ﬁnite multiset of literals, written as a disjunction of literals
¬A1 ∨· · · ∨¬Am ∨B1 ∨· · · ∨Bn or as an implication Γ →Δ, where the multi-
set Γ is called the antecedent and the multiset Δ is called the succedent of the
clause. (Recall that a multiset is an unordered collection with possible duplicate
elements.)
An equational theory is a set of equations. (In this paper, an equational the-
ory and a set of axioms are used interchangeably.) We denote by ≈E the least
congruence on T(F, X) that is closed under substitutions and contains a set of
equations E. If s ≈E t for two terms s and t, then s and t are E-equivalent.
A (strict) ordering ≻on terms is monotonic if s ≻t implies u[s]p ≻u[t]p
for all s, t, u and positions p. An ordering ≻on terms is stable under substitu-
tions if s ≻t implies sσ ≻tσ for all s, t, and substitutions σ. An ordering ≻on
terms is a rewrite ordering if it is monotonic and stable under substitutions. A
well-founded rewrite ordering is a reduction ordering. An ordering ≻on terms
has the subterm property if t[s]p ≻s for all s, t, and p ̸= λ. (In this paper, λ
denotes the top position.) A simpliﬁcation ordering is a rewrite ordering with
the subterm property. An ordering ≻on terms is E-compatible if s ≻t, s ≈E s′,
and t ≈E t′ implies s′ ≻t′ for all s, s′, t and t′. An ordering ≻on ground terms
is E-total if s ̸≈E t implies s ≻t or t ≻s for all ground terms s and t.
Given a multiset S and an E-compatible ordering ≻on S, we say that x is
maximal (resp. strictly maximal) in S if there is no y ∈S (resp. y ∈S \ {x})
with y ≻x (resp. y ⪰x).
Clauses may also be considered as multisets of occurrences of equations. An
occurrence of an equation s ≈t in the antecedent of a clause is the multiset
{{s, t}}, and in the succedent it is the multiset {{s}, {t}}. We denote ambigu-
ously all those orderings on terms, equations and clauses by ≻.
An equational theory is permutative if each equation in the theory contains
the same symbols on both sides with the same number of occurrences. The
depth of a term t is deﬁned as depth(t) = 0 if t is a variable or a constant and
depth(f(s1, . . . , sn)) = 1+max{depth(si) | 1 ≤i ≤n}. We say that an equational
theory has maximum depth at most k if the maximum depth of all terms in the

Equational Theorem Proving Modulo
169
equations in the theory is less than or equal to k.
A (Herbrand) interpretation I is a congruence on ground terms. I satisﬁes
(is a model of) a ground clause Γ →Δ, denoted by I |= Γ →Δ, if I ̸⊇Γ
or I ∩Δ ̸= ∅. In this case, we say that Γ →Δ is true in I. A ground clause
C follows from a set of ground clauses {C1, . . . , Ck} |= C if C is true in every
model of {C1, . . . , Ck}.
3
Constrained Clauses
Deﬁnition 1 (Constrained clauses) [22,26] A constrained clause is a pair C || φ,
where C is a clause and φ is an equality constraint consisting of a conjunction of
the form s ≈?
E t for terms s and t. The set of solutions of a constraint φ, denoted
by Sol(φ), is the set of the ground substitutions deﬁned inductively as:
Sol(φ1 ∧φ2) = Sol(φ1) ∩Sol(φ2),
Sol(s ≈?
E t) = {σ | sσ and tσ are E-equivalent},
A constraint φ is satisﬁable if it admits at least one solution.
A constrained clause with an unsatisﬁable constraint is a tautology. If every
ground substitution with domain V ars(φ) of C || φ is a solution of φ, then φ is
a tautological constraint. An unconstrained clause can also be considered as a
constrained clause with a tautological constraint.
The main technical diﬃculties in lifting a reduced ground inference to an
inference at the clause level in a basic paramodulation inference system involve
a ground clause of the form Cσ := Dσ ∨xσ ≈tσ with C := D ∨x ≈t || φ
and σ ∈Sol(φ), where xσ ⇒tσ ∈R for a given ground rewrite system R.
This motivates the following deﬁnition of irreducibility to lift a reduced ground
inference to an inference at the clause level in our inference system. (See [9] also
for order-irreducibility in the free case.)
Deﬁnition 2 (Order-irreducibility) Given a ground rewrite system R and an
equational theory E, a ground literal L[l′]p is order-reducible (at position p)
by R, E with l ⇒r ∈R if l′ ≈E l, l ≻r and L ≻l ≈r. A literal L[s] is
order-irreducible in s by R, E if L[s] is not order-reducible at any position of s.
In Deﬁnition 2, the condition L ≻l ≈r is always true when L is a negative
literal or else l′ does not occur at the top (i.e. p = λ) of the largest term of L.
Deﬁnition 3 (Reduced ground instances) Given a ground rewrite system R
and an equational theory E, Cσ is a ground instance of C || φ if σ is a solution
of φ (i.e. σ ∈Sol(φ)). It is a reduced ground instance of C || φ w.r.t. R, E if σ is
a solution of φ and each ground literal L[xσ] in Cσ is order-irreducible in xσ by
R, E for each variable x ∈V ars(C). In this case, σ is a reduced solution of C || φ
w.r.t. R, E.
Deﬁnition 4 (A model of a constrained clause) An interpretation I satisﬁes
(is a model of) a constrained clause C || φ, denoted by I |= C || φ, if it satisﬁes
every ground instance of C || φ (i.e. every Cσ for which σ is a solution of φ).

170
D. Kim and C. Lynch
Deﬁnition 5 (Reductiveness, weak reductiveness, semi-reductiveness, and weak
maximality) An equation s ≈t is reductive (resp. weakly reductive) for C || φ :=
D ∨s ≈t || φ if there exists a ground instance Cσ such that sσ ≈tσ is strictly
maximal (resp. maximal) in Cσ with sσ ≻tσ. The clause C || φ is simply called
reductive if there exists a reductive equation s ≈t for C || φ. A negative equation
u ̸≈v is semi-reductive (resp. weakly reductive) for C || φ := D∨u ̸≈v || φ if there
exists a ground instance Cσ such that uσ ≻vσ (resp. uσ ≻vσ and uσ ̸≈vσ is
maximal in Cσ). A literal L is weakly maximal for C || φ := D ∨L || φ if there
exists a ground instance Cσ such that Lσ is maximal in Cσ.
4
Inference Rules
The inference rules in our inference system are parameterized by a selection
function S and an E-compatible reduction ordering ≻with the subterm property
that is E-total on ground terms, where S selects at most one (occurrence of a)
negative literal in the clause part C of each (constrained) clause C || φ. For
technical convenience, if a literal L is selected in C, then we also say that L is
selected in C || φ. In our inference rules, a literal in a clause C || φ is involved in
some inference if it is selected in C (by S) or nothing is selected and it is maximal
in C (cf. [8]). The following Basic Paramodulation rule is our main inference
rule for equational theorem proving modulo E, where only the maximal sides of
literals in clauses are involved in inferences by this rule. We rename variables
in the premises in our inference rules if necessary so that no variable is shared
between premises (i.e. standardized apart).
Basic Paramodulation
C ∨s ≈t || φ1
D ∨L[s′] || φ2
if
C ∨D ∨L[t] || s ≈?
E s′ ∧φ1 ∧φ2
1. s′ is not a variable,
2. s ≈t is reductive for the left premise, and C contains no selected literal,
3. either one of the following three conditions is met:
(a) L is selected in the right premise, and
L is of the form u[s′] ̸≈v and is semi-reductive for the right premise.
(b) nothing is selected in the right premise, and
L is of the form u[s′] ≈v and is reductive for the right premise.
(c) nothing is selected in the right premise, and
L is of the form u[s′] ̸≈v and is weakly reductive for the right premise.
Equality Resolution
C ∨s ̸≈t || φ
if
C || s ≈?
E t ∧φ

Equational Theorem Proving Modulo
171
s ̸≈t is selected, or else nothing is selected and s ̸≈t is weakly maximal for the
premise.
E-Factoring
C ∨s ≈t ∨s′ ≈t′ || φ
if
C ∨t ̸≈t′ ∨s′ ≈t′ || s ≈?
E s′ ∧φ
s ≈t is weakly reductive for the premise, and C contains no selected literal.
E-Completion
C ∨s ≈t || φ
if
C ∨e1[t]p ≈e2 || s ≈?
E s′ ∧φ
1. e1[s′]p ≈e2 ∈E and p ̸= λ, where s′ is not a variable,
2. s ≈t is reductive for the premise, and C contains no selected literal.
The above E-Completion rule is an adaptation of the E-closure [27] rule
using equality constraints (cf. E-extension [5]).
E-Parallel
C ∨s ≈t || φ1
D ∨l ≈r || φ2
if
C ∨Dσ ∨lσ ≈rθ || φ1 ∧φ2
1. s ≈t is reductive for the left premise, and C contains no selected literal,
2. l ≈r is reductive for the right premise, and D contains no selected literal,
3. both l and s are not variables,
4. σ = {x →s} and θ = {x →t} for some variable x ∈V ars(l) ∩V ars(r) with
x /∈V ars(φ2),
5. there is a term u′ with u′ ≈E lσ, such that u′ is R, E-reducible with
R = {l ⇒r, s ⇒t} only at the top position (i.e. no strict subterm of u′
is R, E-reducible).
Generalized E-Parallel
C ∨s ≈t || φ1
D ∨l ≈r || φ2
if
C ∨Dσ ∨lσ ≈rθ || φ1 ∧φ2
1. s ≈t is reductive for the left premise, and C contains no selected literal,
2. l ≈r is reductive for the right premise, and D contains no selected literal,
3. both l and s are not variables,
4. e1[u] ≈e2 ∈E, where u is not a variable,
5. σ = {x →u[s]p} and θ = {x →u[t]p} for some variable x ∈V ars(l) ∩
V ars(r) with x /∈V ars(φ2) and some position p,

172
D. Kim and C. Lynch
6. there is a term u′ with u′ ≈E lσ, such that u′ is R, E-reducible with
R = {l ⇒r, s ⇒t} only at the top position.
We mark each clause produced by the Generalized E-Parallel (or E-Parallel)
rule as “protected” so that it is protected from our contraction rules discussed in
Section 5. (We simply say each marked clause is a protected clause.) Protected
clauses behave the same way as other clauses in our inference rules, but our
contraction rules are not applied to protected clauses (see Section 5 for details).
We may also use predicate terms [6] P(t1, . . . , tn) in our inference system,
where a predicate term cannot be a proper subterm of any term. Note that a
predicate term P(t1, . . . , tn) can be expressed as an equation P(t1, . . . , tn) ≈⊤,
where ⊤is a special constant symbol minimal in the ordering ≻and P is con-
sidered as a function symbol. (In this sense, ¬P(t1, . . . , tn) can be expressed
as P(t1, . . . , tn) ̸≈⊤.) In the remainder of this paper, by BP we denote the
inference system consisting of the Basic Paramodulation, Equality Resolution,
E-Factoring, E-Completion, and the Generalized E-Parallel rule. If E is a per-
mutative theory with maximum depth at most 2 (e.g. E = A, C, or AC), then
we use the simpler E-Parallel rule instead of the Generalized E-Parallel rule in
BP (see Lemma 6).
Example 1. Let + be an AC symbol (in inﬁx notation) with + ≻a ≻b ≻0 and
consider the following inconsistent set of clauses 1: x + 0 ≈x, 2: a + a ≈0, 3:
b + b ≈0, and 4: (a + b) + (a + b) ̸≈0. Now we show how the empty clause (with
a satisﬁable constraint) is derived:
5: (x + y) + z ≈x + 0 || y + z ≈?
AC a + a (E-Completion with 2 using the
associativity axiom x + (y + z) ≈(x + y) + z.)
6: ((b + b) + y) + z ≈0 + 0 || y + z ≈?
AC a + a (E-Parallel with 3 into 5. In
condition 5 of the E-Parallel rule, term u′ corresponds to (b + y) + (b + z) here.)
7: 0 + 0 ̸≈0 || ((b + b) + y) + z ≈?
AC (a + b) + (a + b) ∧y + z ≈?
AC a + a (Basic
Paramodulation with 6 into 4)
8: x ̸≈0 || x+0 ≈?
AC 0+0 ∧((b+b)+y)+z ≈?
AC (a+b)+(a+b) ∧y+z ≈?
AC a+a
(Basic Paramodulation with 1 into 7)
9: □|| x ≈?
AC 0 ∧x+0 ≈?
AC 0+0 ∧((b+b)+y)+z ≈?
AC (a+b)+(a+b)∧y+z ≈?
AC
a + a (Equality Resolution on 8)
In contrast, the existing approaches for basic paramodulation modulo AC [21,
26] use clauses 2 and 4, for example, and produce clause 5′: 0+x ̸≈0 || x ≈?
AC b+b
and then clause 6′: 0 + y ̸≈0 || x ≈?
AC b+b ∧y ≈?
AC 0 by their inference
rules. Then 6′ is used to derive a contradiction with 1. It can be viewed that
6′ is obtained from 5′ by an indirect paramodulation with 3 in the constraint
part. In our approach, we simply block clauses like 5′ from further inferences
(see Deﬁnition 12), and no direct or indirect paramodulation is allowed in the
constraint part of any clause.
Example 2. Consider S = {f(g(x)) ≈x, a ≈b, c ̸≈g(b)} and E = {f(g(g(a))) ≈
c} with f ≻g ≻a ≻b, where E is a regular theory with maximum depth 3.
The Generalized E-Parallel rule with premises f(g(x)) ≈x and a ≈b produces

Equational Theorem Proving Modulo
173
the conclusion f(g(g(a))) ≈g(b). (Choose l as f(g(x)), s as a, and u as g(a) in
the Generalized E-Parallel rule.) Then it is used to derive a contradiction with
clause c ̸≈g(b) since f(g(g(a))) ≈E c.
In the above example, a suitable E-compatible reduction ordering ≻on
ground terms is obtained in such a way that given two ground terms, we rewrite
each occurrence of c in each ground term into f(g(g(a))) at the same position
with (the occurrence of) c and then use the standard lexicographic path order-
ing [3,22] for comparing (rewritten) ground terms without any occurrence of c.
Then we may compare terms with variables by considering ground substitutions
and using this ordering on ground terms.
In what follows, by the Parallel rule we mean the E-Parallel or the Gener-
alized E-Parallel rule. First, observe that we cannot derive a contradiction in
both Examples 1 and 2 using inference rules in BP without the Parallel rule.
The intuition behind the Parallel rule is that above all, a reductive ground
clause corresponds to a reductive ground conditional rewrite rule [19] with pos-
itive and negative conditions. Therefore, roughly speaking, the premises of the
Parallel rule are reductive conditional rewrite rules with positive and negative
conditions. (The Parallel rule applies to only reductive clauses.) Now the con-
clusion of the Parallel rule combines two steps: (i) instantiating a “problematic”
variable in a special and restricted way, and (ii) selectively rewriting an instan-
tiated term if conditions are met. (Therefore, conditions C is included in the
conclusion.) A problematic variable is often determined by a built-in equational
theory E. It is mostly a variable produced by an E-Completion inference (see
Example 1) for AC cases, which is the counterpart of an extension variable for
AC-extension [7,27].
Observe that the Generalized E-Parallel rule is more general than the E-
Parallel rule. If p is always the top position for the Generalized E-Parallel rule,
then they are equivalent. This is the case for permutative theories with maximum
depth at most 2 (e.g. E = A, C, or AC).
Lemma 6 If E is a permutative theory with maximum depth at most 2, then
the E-Parallel rule and the Generalized E-Parallel rule are equivalent, i.e., they
generate the same conclusion for the same input premises.
Note that the E-Completion and the Parallel rule are not always needed
for every built-in equational theory E. The following example is a simple vari-
ant of the reachability problem [15] modulo a permutation theory [1,17], where
¬P(f(c, b, b, d, e)) is the query from the initial conﬁguration P(f(a, b, c, d, e)).
We may view E in the following example as all permutations of variables
x1, x2, x3, x4, and x5, since the symmetric group S5 is generated by two cycles
(1 2) and (1 2 3 4 5).
Example 3. Let E = {f(x1, x2, x3, x4, x5) ≈f(x2, x1, x3, x4, x5), f(x1, x2, x3, x4,
x5) ≈f(x2, x3, x4, x5, x1)} with P
≻f
≻a ≻b ≻c ≻d ≻e and
consider the following set of clauses 1: ¬P(f(c, b, b, d, e)), 2: P(f(a, b, c, d, e)),
and 3: f(a, b, x, y, z) ≈f(b, b, x, y, z). Basic Paramodulation with 3 into 2

174
D. Kim and C. Lynch
yields clause 4: P(f(b, b, x, y, z)) || f(a, b, x, y, z) ≈?
E f(a, b, c, d, e). By apply-
ing Basic Paramodulation with 1 and 4 (using P(f(c, b, b, d, e)) ̸≈⊤and
P(f(b, b, x, y, z)) ≈⊤|| f(a, b, x, y, z) ≈?
E
f(a, b, c, d, e)) and then applying
Equality Resolution, we have clause 5: □|| f(b, b, x, y, z) ≈?
E f(c, b, b, d, e) ∧
f(a, b, x, y, z) ≈?
E f(a, b, c, d, e). The equality constraint in 5 is satisﬁable and
we have a contradiction. Note that clause 4 schematizes the set of ground clauses
{P(f(b, b, c, d, e)), P(f(b, b, c, e, d)), P(f(b, b, d, c, e)), P(f(b, b, d, e, c)), P(f(b, b, e,
c, d)), P(f(b, b, e, d, c))}.
5
Redundancy Criteria and Contraction Techniques
Deﬁnition 7 (Relative reducibility) Given an equational theory E, a ground
instance Cσ1 of C || φ1 is reduced relative to a ground instance Dσ2 of D || φ2 if
for any rewrite system R, Cσ1 is a reduced ground instance of C || φ1 w.r.t. R, E
whenever Dσ2 is a reduced ground instance of D || φ2 w.r.t. R, E.
In what follows, the relation ⊴on terms represents the subterm relation, i.e.,
s ⊴t if s is a subterm of t. The relation ⊑on sets of terms is deﬁned as follows:
{s1, . . . , sm} ⊑{t1, . . . , tn} if for all 1 ≤i ≤m, there is some 1 ≤j ≤n such
that si ⊴tj, and ∅⊑X for any set of terms X. Given a clause C || φ, we denote
by Ran(σ|V ars(C)) for some σ ∈Sol(φ) the range of the restriction of σ to the set
of variables V ars(C) if V ars(C) ̸= ∅. If C is a ground clause with a tautological
constraint (e.g. the empty constraint), then we set Ran(σ|V ars(C)) = ∅. (Note
that any ground substitution is a solution of a tautological constraint.)
We say that a clause C || φ is a clause with a succedent top variable [21]
w.r.t. σ ∈Sol(φ) if there is a variable x ∈V ars(C) ∩V ars(φ) only appearing in
equations x ≈t of the succedent of C with xσ ≻tσ for some t. The following
lemma, which directly follows from Deﬁnition 7, is a suﬃcient syntactic condition
for Cσ1 being reduced relative to Dσ2 in Deﬁnition 7 if D || φ2 is not a clause
with a succedent top variable w.r.t. σ2. If D || φ2 is a clause with a succedent top
variable x w.r.t. some σ2 ∈Sol(φ2), then one may (partially) instantiate x in
D with σ2 if possible, so that one may use the syntactic condition for checking
whether Cσ1 is reduced relative to Dσ2 as in the following lemma.
Lemma 8 Given an equational theory E, a ground instance Cσ1 of C || φ1
is reduced relative to a ground instance Dσ2 of D || φ2 if Ran(σ1|V ars(C)) ⊑
Ran(σ2|V ars(D)) and D || φ2 is not a clause with a succedent top variable
w.r.t. σ2.
In what follows, we denote by E≺C (resp. R≺C) the set of ground instances
of equations in E (resp. the set of ground rewrite rules in R) smaller than the
ground clause C (w.r.t. ≻), and by S modulo E a set of clauses S with a built-in
equational theory E.
Deﬁnition 9 (Redundancy) A clause C || φ is redundant in S modulo E
(w.r.t. relative reducibility) if for every ground instance Cσ, there exist ground

Equational Theorem Proving Modulo
175
instances C1σ1, . . . , Ckσk of clauses C1 || φ1, . . . , Ck || φk in S reduced relative to
Cσ, such that Cσ ≻Ciσi, 1 ≤i ≤k, and {C1σ1, . . . , Ckσk}∪R≺Cσ∪E≺Cσ |= Cσ
for any ground rewite system R contained in ≻. (In this case, we also say that
each Cσ is redundant in S modulo E (w.r.t. relative reducibility).)
Deﬁnition 10 (Basic E-simpliﬁcation) An equation l ≈r simpliﬁes a clause
C ∨L[l′]p || φ into C ∨L[rρ]p || φ if the following conditions are met:
(i) p is a non-variable position;
(ii) there is a substitution ρ such that lρ ≈E l′, L[l′] ≻lρ ≈rρ, V ars(lρ) ⊇
V ars(rρ), lρ ≻rρ, and C ∨L[l′]p || φ is neither protected nor a clause with
a succedent top variable w.r.t. any σ ∈Sol(φ).
Lemma 11 If an equation l ≈r simpliﬁes a clause C ∨L[l′]p || φ into C ∨
L[rρ]p || φ as in Deﬁnition 10, then C ∨L[l′]p || φ is redundant in S modulo E,
where S = {l ≈r, C ∨L[rρ]p || φ}.
The following deﬁnition extends the blocking rule in the free case (see [9])
to the modulo case, where a blocked clause does not contribute to ﬁnding a
refutation during a theorem proving derivation w.r.t. BP (see Deﬁnition 16)
starting with an initial set of unconstrained clauses.
Deﬁnition 12 (Basic E-blocking) A clause C || φ is blocked in S modulo E if
the following conditions are met:
(i) C || φ is not a clause with a succedent top variable w.r.t. any τ ∈Sol(φ);
(ii) there is a variable x ∈V ars(C) ∩V ars(φ) such that for every σ ∈Sol(φ),
there exist ground instances C1σ1, . . . , Ckσk of clauses C1 || φ1, . . . , Ck || φk
in S reduced relative to Cσ, such that Cσ ≻Ciσi, 1 ≤i ≤k, and
{C1σ1, . . . , Ckσk} ∪E≺Cσ |= xσ ≈s with xσ ≻s for some ground term s.
Deﬁnition 13 (Basic E-instance) A clause C || φ is a basic E-instance in S
modulo E if the following conditions are met:
(i) C || φ is protected;
(ii) there is a protected clause D || ψ ∈S such that for every ground instance Cσ
(resp. Dτ) of C || φ (resp. D || ψ), there is a ground instance Dτ (resp. Cσ)
of D || ψ (resp. C || φ) such that they are reduced relative to each other with
Cσ = Dτ.
Observe that protected clauses are produced in a restricted way (e.g. see
condition 5 in the E-Parallel rule) and if two protected clauses are the same up
to variable renaming, then they are basic E-instances of each other and they do
not need to be distinguished.
Deﬁnition 14 (Redundancy of an inference) An inference π with conclusion
D || φ is redundant in S modulo E (w.r.t. relative reducibility) if D || φ is blocked
or a basic E-instance in S modulo E, or for every ground instance πσ with max-
imal premise C and conclusion Dσ, there exist ground instances C1σ1, . . . , Ckσk
of clauses C1 || φ1, . . . , Ck || φk in S reduced relative to Dσ, such that C ≻Ciσi,
1 ≤i ≤k, and {C1σ1, . . . , Ckσk} ∪R≺C ∪E≺C |= Dσ for any ground rewrite
system R contained in ≻.

176
D. Kim and C. Lynch
The following lemma immediately follows from Deﬁnition 9 and the observa-
tion that if {C1σ1, . . . , Ckσk} ∪E≺Cσ |= Cσ, then {C1σ1, . . . , Ckσk} ∪R≺Cσ ∪
E≺Cσ |= Cσ for any ground rewite system R contained in ≻, which serves as a
suﬃcient condition for redundancy of clauses. Also, if an (unconstrained) clause
C properly subsumes an (unconstrained) clause C′ ∨D in the classical sense,
where C and C′ are the same up to variable renaming, then it is easy to see that
C′ ∨D is redundant in {C} modulo E.
Lemma 15 A clause C || φ is redundant in S modulo E if for every ground
instance Cσ, there exist ground instances C1σ1, . . . , Ckσk of clauses C1 || φ1, . . . ,
Ck || φk in S reduced relative to Cσ, such that Cσ ≻Ciσi, 1 ≤i ≤k, and
{C1σ1, . . . , Ckσk} ∪E≺Cσ |= Cσ.
Deﬁnition 16 (Theorem proving derivation) A theorem proving derivation is a
sequence of sets of clauses S0 = S, S1, . . . such that:
(i) Deduction: Si = Si−1 ∪{C || φ} for some C || φ if it can be deduced from
premises in Si−1 by applying an inference rule in BP or basic E-simpliﬁcation.
(ii) Deletion: Si = Si−1 \ {D || ψ} for some D || ψ if it is not protected, and is
redundant or blocked in Si−1 modulo E.
The set S∞of persistent clauses is deﬁned as 
i(
j≥i Sj), which is called
the limit of the derivation. A theorem proving derivation S0, S1, S2, . . . is fair [6]
w.r.t. the inference system BP if every inference π by BP with premises in S∞
is redundant in 
j Sj modulo E.
Deﬁnition 17 (Saturation w.r.t. relative reducibility) Given an equational the-
ory E, we say that S modulo E is saturated under BP w.r.t. relative reducibility
if every inference by BP with premises in S is redundant in S modulo E.
In what follows, we say that a clause C || φ is non-protected redundant (resp.
non-protected blocked) in S modulo E if it is not protected and is redundant
(resp. blocked) in S modulo E. (If C || φ is non-protected redundant in S modulo
E, then we also say that each ground instance Cσ of C || φ is non-protected
redundant in S modulo E.)
Lemma 18 (i) If S ⊆S′, then any clause which is non-protected redundant or
non-protected blocked in S modulo E is also non-protected redundant or non-
protected blocked in S′ modulo E.
(ii) Let S ⊆S′ such that all clauses in S′ \ S are non-protected redundant
or non-protected blocked in S′ modulo E. Then (ii.1) any clause which is non-
protected redundant or non-protected blocked in S′ modulo E is also non-protected
redundant or non-protected blocked in S modulo E, and (ii.2) any inference which
is redundant in S′ modulo E is also redundant in S modulo E.
Lemma 19 Let S0, S1, . . . be a fair theorem proving derivation w.r.t. BP such
that S0 is a set of unconstrained clauses. Then S∞modulo E is saturated under
BP w.r.t. relative reducibility.

Equational Theorem Proving Modulo
177
Proof. If S∞contains the empty clause, then it is immediate that S∞modulo E
is saturated under BP w.r.t. relative reducibility, so we assume that the empty
clause is not in S∞.
If a clause C || φ is deleted in a theorem proving derivation, then we see that
it is non-protected redundant or non-protected blocked in some Sj modulo E. It
is also non-protected redundant or non-protected blocked in 
j Sj modulo E by
Lemma 18(i). Similarly, every clause in 
j Sj \ S∞is non-protected redundant
or non-protected blocked in 
j Sj modulo E.
Now by fairness of the derivation, every inference π by BP with premises in
S∞is redundant in 
j Sj modulo E. Then by Lemma 18(ii.2) and the above, π
is also redundant in S∞modulo E. Thus, S∞modulo E is saturated under BP
w.r.t. relative reducibility.
⊓⊔
6
Refutational Completeness
The soundness of BP (w.r.t. a fair theorem proving derivation) is straightfor-
ward, i.e., Si ∪E |= Si+1 ∪E for all i ≥0. If the empty clause is in some Sj,
then S0 ∪E is unsatisﬁable by the soundness of BP. The following theorem
states that BP with our contraction rules (i.e. basic E-simpliﬁcation and basic
E-blocking) is refutationally complete. In order to prove the following theorem,
we adapt a variant of model construction techniques [7–9,21,27]. In this section,
we assume that the equality is the only predicate by expressing other predicates
(i.e. predicate terms) as (predicate) equations as discussed in Section 4.
Theorem 20 Let S0, S1, . . . be a fair theorem proving derivation w.r.t. BP such
that S0 is a set of unconstrained clauses. Then S0 ∪E is unsatisﬁable if and only
if the empty clause is in some Sj.
Deﬁnition 21 (Model construction) Let S be a set of (constrained) clauses. We
use induction on ≻to deﬁne the sets RulesC, RC, EC, and IC, for all ground
instances C of clauses in S. Let C be such a ground instance of a clause in S and
suppose that RulesC′ has been deﬁned for all ground instances C′ of clauses in
S for which C ≻C′. Then we deﬁne by RC = 
C≻C′ RulesC′ and by EC the
set of ground instances e1 ≈e2 of equations in E, such that C ≻e1 ≈e2, and
e1 and e2 are both irreducible by RC. We also deﬁne by IC the interpretation
(RC ∪EC)∗(i.e. the least congruence containing RC ∪EC).
Now let C := D∨s ≈t be a reduced ground instance of a clause in S w.r.t. RC
such that C is not an instance of a clause with a selected literal. Then C produces
the set of ground rewrite rules RulesC = {u ⇒t | u ≈E s and u is irreducible by
RC} if the following conditions are met: (1) IC ̸|= C (resp. IC ̸|= D) if C is an
instance of a non-protected clause (resp. protected clause), (2) IC ̸|= t ≈t′ for
every s′ ≈t′ in D with s′ ≈E s, (3) s ≈t is reductive for C, and (4) there exists
u with u ≈E s for which u is irreducible by RC. We say that C is productive and
produces RulesC if it satisﬁes all of the above conditions. Otherwise, RulesC = ∅.
Finally, we deﬁne RS = 
C RC, ES = 
C EC, and IS = (RS ∪ES)∗.

178
D. Kim and C. Lynch
We may include the special non-productive ground clause tt ≈tt in S for
the above (inductive) deﬁnition, where tt ≈tt is assumed to be greater than all
ground instances of clauses in S∪E w.r.t. ≻other than tt ≈tt itself (see [21,27]).
(If C is the strictly maximal ground instance among ground instances of clauses
in S and is productive, then RS may not include RulesC by the above inductive
deﬁnition of RC without tt ≈tt.) In what follows, we say that a ground instance
πσ of an inference π with premises in S is reduced if each premise and conclusion
of πσ is a reduced ground instance of a clause in S ∪E w.r.t. RS, ES.
Deﬁnition 22 (Redundancy w.r.t. RS, ES) A clause C || φ is redundant in S
modulo E w.r.t. RS, ES if for every reduced ground instance Cσ w.r.t. RS, ES,
there exist reduced ground instances C1σ1, . . . , Ckσk of clauses C1 || φ1 . . . Ck || φk
in S w.r.t. RS, ES, such that Cσ ≻Ciσi, 1 ≤i ≤k, and {C1σ1, . . . , Ckσk} ∪
R≺Cσ
S
∪E≺Cσ |= Cσ. (In this case, we also say that each Cσ is redundant in S
modulo E w.r.t. RS, ES.)
An inference π with conclusion D || φ is redundant in S modulo E w.r.t. RS, ES
if D || φ is blocked or a basic E-instance in S modulo E, or for every reduced
ground instance πσ with maximal premise C and conclusion Dσ, there exist
reduced ground instances C1σ1, . . . , Ckσk of clauses C1 || φ1, . . . , Ck || φk in S
w.r.t. RS, ES, such that C ≻Ciσi, 1 ≤i ≤k, and {C1σ1, . . . , Ckσk} ∪R≺C
S
∪
E≺C |= Dσ.
Deﬁnition 23 (Saturation w.r.t. RS, ES) Given an equational theory E, we
say that S modulo E is saturated under BP w.r.t. RS, ES if every inference by
BP with premises in S is redundant in S modulo E w.r.t. RS, ES.
Lemma 24 (i) There are no overlaps among the left-hand sides of rules in RS.
(ii) A term t is reducible by RS if and only if it is reducible by RS, ES at the
same position.
(iii) For every l ⇒r, s ⇒t ∈RS, if l ≈E s, then r and t are the same term.
(iv) RS/ES is terminating.
(v) For ground terms u and v, if IS |= u ≈v, then u ↓RS,ES v.
(vi) If a ground instance Cθ := Dθ ∨lθ ≈rθ of a clause C || φ := D ∨l ≈r || φ
is productive, then it is a reduced ground instance of C || φ w.r.t. RS, ES.
The proofs of (i), (ii), and (iii) in Lemma 24 follow from the construction of
RS in Deﬁnition 21. For (iv), since RS is contained in an E-compatible reduction
ordering ≻on terms that is E-total on ground terms, RS/ES is terminating.
Meanwhile, Lemma 24(v) describes the ground Church-Rosser property [19] of
RS, ES. Since RS/ES is terminating by (iv), this shows that RS, ES is ground
convergent modulo ES. In the following, we assume that any saturated clause
set under BP is obtained from an initial set of clauses without constraints.
Lemma 25 Let S modulo E be saturated under BP w.r.t. RS, ES not contain-
ing the empty clause and let C be a reduced ground instance of a clause in S
w.r.t. RS, ES or a ground instance of an equation in E. Then C is true in IS.
More speciﬁcally,

Equational Theorem Proving Modulo
179
(i) C is not an instance of a blocked clause in S modulo E.
(ii) If C is redundant in S modulo E w.r.t. RS, ES, then it is true in IS.
(iii) If C is an instance of a clause with a selected literal, then it is true in IS.
(iv) If C contains a maximal negative literal (w.r.t. ≻) and is not an instance
of a clause with a selected literal, then it is true in IS.
(v) If C is an instance of an equation in E, then it is true in IS.
(vi) If C is an instance of a protected clause or a basic E-instance of it, then it
is true in IS.
(vii) If C is non-productive, then it is true in IS.
(viii) If C := C′∨s ≈t is productive and produces RulesC with s ⇒t ∈RulesC,
then C′ is false and C is true in IS.
We leave it to the reader to verify the following lemma using the deﬁnitions
of redundancy of an inference w.r.t. relative reducibility and w.r.t. RS, ES, along
with Lemma 19.
Lemma 26 Let S0, S1, . . . be a fair theorem proving derivation w.r.t. BP such
that S0 is a set of unconstrained clauses. Then S∞modulo E is saturated under
BP w.r.t. RS∞, ES∞.
Theorem 27 Let S0, S1, . . . be a fair theorem proving derivation w.r.t. BP such
that S0 is a set of unconstrained clauses. If S∞does not contain the empty clause,
then IS∞|= S0 ∪E (i.e., S0 ∪E is satisﬁable).
Proof. By Lemma 26, we know that S∞modulo E is saturated under BP
w.r.t. RS∞, ES∞. Let C be a ground instance of an equation in E or a ground
instance of a clause C′ in S0. By Lemma 25(v), if C is a ground instance
of an equation in E, then it is true in IS∞. Therefore, we assume that C is
not a ground instance of an equation in E. Suppose ﬁrst that C := C′σ′ is
a reduced ground instance of C′ ∈S0 w.r.t. RS∞, ES∞. Then there are two
cases to consider. If C′ ∈S∞, then C is true in IS∞by Lemma 25. Other-
wise, if C′ ̸∈S∞, then C′ is (non-protected) redundant in some Sj modulo E
w.r.t. relative reducibility because C′ ∈S0 (with the empty constraint) is neither
protected nor can it be a blocked clause in some Sj modulo E. Thus, C′ is (non-
protected) redundant in 
j Sj modulo E w.r.t. relative reducibility, and hence
is (non-protected) redundant in S∞modulo E w.r.t. relative reducibility by
Lemma 18. It follows that there exist ground instances C1σ1, . . . , Ckσk of clauses
C1 || φ1, . . . , Ck || φk in S∞reduced relative to C, such that C ≻Ciσi, 1 ≤i ≤k,
and {C1σ1, . . . , Ckσk} ∪R≺C ∪E≺C |= C for any ground rewrite system R con-
tained in ≻. Since C is a reduced ground instance of C′ w.r.t. RS∞, ES∞, we
see that Ciσi, 1 ≤i ≤k, are also reduced ground instances w.r.t. RS∞, ES∞by
Deﬁnition 7 and are true in IS∞by Lemma 25. Similarly, R≺C
S∞and E≺C are
true in IS∞by Lemma 25, and hence we may infer that C is also true in IS∞.
Now suppose that C := C′σ′ is a reducible ground instance of C′ ∈S0
w.r.t. RS∞, ES∞. Let σ′′ be a ground substitution such that xσ′′ = xσ′↓RS∞,ES∞
for each x ∈V ars(C′). Since C′σ′′ is a reduced ground instance of C′ ∈S0
w.r.t. RS∞, ES∞, C′σ′′ is true in IS∞by the previous paragraph, and hence C
is also true in IS∞.
⊓⊔

180
D. Kim and C. Lynch
We may now present the proof that BP with our contraction rules is refuta-
tionally complete.
Proof of Theorem 20 Let S0, S1, . . . be a fair theorem proving derivation
w.r.t. BP such that S0 is a set of unconstrained clauses. If the empty clause is in
some Sj, then S0 ∪E is unsatisﬁable by the soundness of BP. Otherwise, if the
empty clause is not in Sk for all k, then by the soundness of BP, S∞does not
contain the empty clause, and hence S0 ∪E is satisﬁable by Theorem 27.
⊓⊔
7
Conclusion
We have presented a basic paramodulation calculus modulo and provided a
framework for equational theorem proving modulo equational theories E satis-
fying some properties of E using constrained clauses, where a constrained clause
may schematize a set of unconstrained clauses by keeping E-uniﬁcation problems
in its constraint part. Our results imply that we can deal uniformly with diﬀerent
equational theories E in our equational theorem proving modulo framework. We
only need a single refutational completeness proof for our basic paramodulation
calculus modulo E for diﬀerent equational theories E.
Our contraction techniques (i.e. basic E-simpliﬁcation and basic E-blocking)
for constrained clauses can also be applied uniformly for diﬀerent equational
theories E satisfying some properties of E in our equational theorem proving
modulo framework. Since a constrained clause may schematize a set of uncon-
strained clauses, the simpliﬁcation or deletion of a constrained clause may cor-
respond to the simpliﬁcation or deletion of a set of unconstrained clauses. We
have proposed a saturation procedure for constrained clauses based on relative
reducibility and showed the refutational completeness of our inference system
using a saturated clause set (w.r.t. ≻).
Some possible improvements remain to be done. One of the main issues is
the broadening the scope of our equational theorem proving modulo E to more
equational theories E. This can be achieved by dropping or weakening some
ordering requirements of ≻(e.g. monotonicity of ≻) for a basic paramodula-
tion calculus modulo E, while maintaining the refutational completeness of the
calculus (cf. [10]). This can also be achieved by ﬁnding suitable E-compatible
orderings for more equational theories E. In fact, we provided an E-compatible
simpliﬁcation ordering ≻on terms that is E-total on ground terms for ﬁnite per-
mutation theories E in [17], which allows us to provide a refutationally complete
equational theorem proving with built-in permutation theories using the results
of this paper. Since permutations play an important role in mathematics and
many ﬁelds of science including computer science, we believe that developing
applications for equational theorem proving with built-in permutation theories
is another promising future research direction.

Equational Theorem Proving Modulo
181
References
1. Avenhaus, J.: Eﬃcient Algorithms for Computing Modulo Permutation Theories.
In: Basin, D., Rusinowitch, M. (eds.) Automated Reasoning - IJCAR 2004, Cork,
Ireland, July 4–8. pp. 415–429. Springer, Berlin, Heidelberg (2004)
2. Baader, F.: Combination of compatible reduction orderings that are total on
ground terms. In: Winskel, G. (ed.) Proceedings of the Twelfth Annual IEEE Sym-
posium on Logic in Computer Science. pp. 2–13. IEEE Computer Society Press,
Warsaw, Poland (1997)
3. Baader, F., Nipkow, T.: Term Rewriting and All That. Cambridge University Press,
Cambridge, UK (1998)
4. Baader, F., Snyder, W.: Uniﬁcation Theory. In: Handbook of Automated Reason-
ing, chap. 8, pp. 445 – 532. Volume I, Elsevier, Amsterdam (2001)
5. Bachmair, L., Dershowitz, N.: Completion for rewriting modulo a congruence. The-
oretical Computer Science 67(2), 173 – 201 (1989)
6. Bachmair, L., Ganzinger, H.: Rewrite-based Equational Theorem Proving with
Selection and Simpliﬁcation. J. Log. Comput. 4(3), 217–247 (1994)
7. Bachmair, L., Ganzinger, H.: Associative-commutative superposition. In: Der-
showitz, N., Lindenstrauss, N. (eds.) Conditional and Typed Rewriting Systems.
pp. 1–14. Springer, Berlin, Heidelberg (1995)
8. Bachmair, L., Ganzinger, H.: Equational Reasoning in Saturation-Based Theorem
Proving. In: Bibel, W., Schmitt, P. (eds.) Automated Deduction. A basis for ap-
plications, chap. 11, p. 353–397. Volume I, Kluwer, Dordrecht, Netherlands (1998)
9. Bachmair, L., Ganzinger, H., Lynch, C., Snyder, W.: Basic Paramodulation. Infor-
mation and Computation 121(2), 172 – 192 (1995)
10. Boﬁll, M., Rubio, A.: Paramodulation with Non-Monotonic Orderings and Simpli-
ﬁcation. Journal of Automated Reasoning 50, 51–98 (2013)
11. Dershowitz, N., Plaisted, D.A.: Rewriting. In: Handbook of Automated Reasoning,
chap. 9, pp. 535 – 610. Volume I, Elsevier, Amsterdam (2001)
12. Dowek, G.: Polarized Resolution Modulo. In: Calude, C.S., Sassone, V. (eds.) The-
oretical Computer Science. pp. 182–196. Springer, Berlin, Heidelberg (2010)
13. Dowek, G., Hardin, T., Kirchner, C.: Theorem Proving Modulo. Journal of Auto-
mated Reasoning 31(1), 33–72 (2003)
14. Dur´an, F., Eker, S., Escobar, S., Mart´ı-Oliet, N., Meseguer, J., Talcott, C.: As-
sociative Uniﬁcation and Symbolic Reasoning Modulo Associativity in Maude. In:
Rusu, V. (ed.) Rewriting Logic and Its Applications. pp. 98–114. Springer, Cham
(2018)
15. Escobar, S., Sasse, R., Meseguer, J.: Folding variant narrowing and optimal variant
termination. The Journal of Logic and Algebraic Programming 81(7), 898 – 928
(2012)
16. Kim, D., Lynch, C.: Equational Theorem Proving Modulo (2021), Technical Re-
port, Web link: https://people.clarkson.edu/~clynch/PAPERS/etpm.pdf
17. Kim, D., Lynch, C.: An RPO-based ordering modulo permutation equations and its
applications to rewrite systems. In: 6th International Conference on Formal Struc-
tures for Computation and Deduction, FSCD 2021, Buenos Aires, Argentina (Vir-
tual Conference), July 17–24, to appear. vol. 195, pp. 19:1–19:17. LIPIcs (2021),
preprint: http://people.clarkson.edu/~dohkim/tech_reports/ERPO.pdf
18. Kim, D., Lynch, C., Narendran, P.: Reviving Basic Narrowing Modulo. In: Herzig,
A., Popescui, A. (eds.) Frontiers of Combining Systems. pp. 313–329. Springer,
Cham, Switzerland (2019)

182
D. Kim and C. Lynch
19. Kirchner, C., Kirchner, H.: Rewriting, Solving, Proving (1999), Preliminary ver-
sion: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.144.5349
20. Nieuwenhuis, R., Rubio, A.: Basic superposition is complete. In: Krieg-Br¨uckner,
B. (ed.) ESOP ’92. pp. 371–389. Springer, Berlin, Heidelberg (1992)
21. Nieuwenhuis, R., Rubio, A.: Paramodulation with Built-in AC-Theories and Sym-
bolic Constraints. Journal of Symbolic Computation 23(1), 1 – 21 (1997)
22. Nieuwenhuis, R., Rubio, A.: Paramodulation-based theorem proving. In: Handbook
of Automated Reasoning, chap. 7, pp. 371–443. Volume I, Elsevier, Amsterdam
(2001)
23. Robinson, G., Wos, L.: Paramodulation and theorem-proving in ﬁrst-order theories
with equality. In: Meltzer, B., Michie, D. (eds.) Machine Intelligence 4, pp. 133–150.
American Elsevier, New York (1969)
24. Robinson, J.A.: A machine-oriented logic based on the resolution principle. J. ACM
12(1), 23–41 (1965)
25. Rubio, A.: Theorem Proving modulo Associativity. In: B¨uning, H.K. (ed.) Com-
puter Science Logic. pp. 452–467. Springer, Berlin, Heidelberg (1996)
26. Vigneron, L.: Associative-Commutative Deduction with Constraints. In: Bundy,
A. (ed.) Automated Deduction - CADE-12. pp. 530–544. Springer, Berlin (1994)
27. Wertz, U.: First-order theorem proving modulo equations. Tech. Rep. MPI-I-92-
216, Max-Planck-Institut f¨ur Informatik, Saarbr¨ucken (1992)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/
4.0/), which permits use, sharing, adaptation, distribution and reproduction in any
medium or format, as long as you give appropriate credit to the original author(s) and
the source, provide a link to the Creative Commons license and indicate if changes
were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Unifying Decidable Entailments in Separation Logic
with Inductive Deﬁnitions
Mnacho Echenim1
, Radu Iosif2
, and Nicolas Peltier1
1 Univ. Grenoble Alpes, CNRS, LIG, F-38000 Grenoble France
2 Univ. Grenoble Alpes, CNRS, VERIMAG, F-38000 Grenoble France
Abstract. The entailment problem ϕ |= ψ in Separation Logic [12,15], between
separated conjunctions of equational (x ≈y and x ̸≈y), spatial (x →(y1,...,yκ))
and predicate (p(x1,...,xn)) atoms, interpreted by a ﬁnite set of inductive rules,
is undecidable in general. Certain restrictions on the set of inductive deﬁnitions
lead to decidable classes of entailment problems. Currently, there are two such
decidable classes, based on two restrictions, called establishment [10,13,14] and
restrictedness [8], respectively. Both classes are shown to be in 2EXPTIME by
the independent proofs from [14] and [8], respectively, and a many-one reduction
of established to restricted entailment problems has been given [8]. In this paper,
we strictly generalize the restricted class, by distinguishing the conditions that ap-
ply only to the left- (ϕ) and the right- (ψ) hand side of entailments, respectively.
We provide a many-one reduction of this generalized class, called safe, to the es-
tablished class. Together with the reduction of established to restricted entailment
problems, this new reduction closes the loop and shows that the three classes of
entailment problems (respectively established, restricted and safe) form a single,
uniﬁed, 2EXPTIME-complete class.
1
Introduction
Separation Logic [12,15] (SL) was primarily introduced for writing concise Hoare logic
proofs of programs that handle pointer-linked recursive data structures (lists, trees, etc).
Over time, SL has evolved into a powerful logical framework, that constitutes the basis
of several industrial-scale static program analyzers [3,2,5], that perform scalable com-
positional analyses, based on the principle of local reasoning: describing the behavior
of a program statement with respect only to the small (local) set of memory locations
that are changed by that statement, with no concern for the rest of the program’s state.
Given a set of memory locations (e.g., addresses), SL formulæ describe heaps, that
are ﬁnite partial functions mapping ﬁnitely many locations to records of locations. A
location ℓis allocated if it occurs in the domain of the heap. An atom x →(y1,...,yκ)
states that there is only one allocated location, associated with x, that moreover refers
to the tuple of locations associated with (y1,...,yκ), respectively. The separating con-
junction φ ∗ψ states that the heap can split into two parts, with disjoint domains, that
make φ and ψ true, respectively. The separating conjunction is instrumental in support-
ing local reasoning, because the disjointness between the (domains of the) models of its
arguments ensures that no update of one heap can actually affect the other.
c⃝The Author(s) 2021
A. Platzer and G. Sutcliffe (Eds.): CADE 2021, LNAI 12699, pp. 183 199, 2021.
https://doi.org/10.1007/978-3-030-79876-5 11
–

184
M. Echenim et al.
Reasoning about recursive data structures of unbounded sizes (lists, trees, etc.) is
possible via the use of predicate symbols, whose interpretation is speciﬁed by a user-
provided set of inductive deﬁnitions (SID) of the form p(x1,...,xn) ⇐π, where p is
a predicate symbol of arity n and the free variables of the formula π are among the
parameters x1,...,xn of the rule. Here the separating conjunction ensures that each un-
folding of the rules, which substitute some predicate atom p(y1,...,yn) by a formula
π[x1/y1,...,xn/yn], corresponds to a way of building the recursive data structure. For
instance, a list is either empty, in which case its head equals its tail pointer, or is built
by ﬁrst allocating the head, followed by all elements up to but not including the tail, as
stated by the inductive deﬁnitions ls(x,y) ⇐x ≈y and ls(x,y) ⇐∃z . x →(z)∗ls(z,y).
An important problem in program veriﬁcation, arising during the construction of
Hoare-style correctness proofs of programs, is the discharge of veriﬁcation conditions
of the form φ |= ψ, where φ and ψ are SL formulæ, asking whether every model of φ is
also a model of ψ. These problems, called entailments, are, in general, undecidable in
the presence of inductively deﬁned predicates [11,1].
A ﬁrst decidable class of entailments, described in [10], involves three restrictions
on the SID rules: progress, connectivity and establishment. Intuitively, the progress (P)
condition states that every rule allocates exactly one location, the connectivity (C) con-
dition states that the set of allocated locations has a tree-shaped structure, and the es-
tablishment (E) condition states that every existentially quantiﬁed variable from a rule
deﬁning a predicate is (eventually) allocated in every unfolding of that predicate. A
2EXPTIME algorithm was proposed for testing the validity of PCE entailments [13,14]
and a matching 2EXPTIME-hardness lower bound was provided shortly after [6].
Later work relaxes the establishment condition, necessary for decidability [7], by
proving that the entailment problem is still in 2EXPTIME if the establishment condition
is replaced by the restrictedness (R) condition, which requires that every disequality
(x ̸≈y) involves at least one free variable from the left-hand side of the entailment,
propagated through the unfoldings of the inductive system [8]. Interestingly, the rules of
a progressive, connected and restricted (PCR) entailment may generate data structures
with “dangling” (i.e. existentially quantiﬁed but not allocated) pointers, which was not
possible with PCE entailments.
In this paper, we generalize PCR entailments further, by showing that the connec-
tivity and restrictedness conditions are needed only on the right-hand side of the en-
tailment, whereas the only condition required on the left-hand side is progress (which
can usually be enforced by folding or unfolding deﬁnitions). Our results thus allow for
“asymetric” entailments, i.e., one can test whether the structures described by induc-
tive rules that are (almost) arbitrary fulﬁll some restricted formula. Although the class
of data structures that can be described is much larger, we show that this new class of
entailments, called safe, is also 2EXPTIME-complete, by a many-one reduction of the
validity of safe entailments to the validity of PCE entailments. A second contribution
of the paper is the cross-certiﬁcation of the two independent proofs of the 2EXPTIME
upper bounds, for the PCE [6,14,8] and PCR [8] classes of entailments, respectively,
by closing the loop. Namely, the reduction given in this paper enables the translation
of any of the three entailment problems into an equivalent problem in any other class,
while preserving the 2EXPTIME upper bound. This is because all the reductions are

Unifying Decidable Entailments in Separation Logic with Inductive Deﬁnitions
185
polynomial in the overall size of the SID and singly-exponential in the maximum size
of the rules in the SID. The theoretical interest of the reduction is that it makes the proof
of decidability and of the complexity class much shorter and clearer. It also has some
practical advantages, since it allows one to re-use existing implementations designed
for established systems instead of having to develop entirely new automated reasoning
systems. Due to space restrictions, some of the proofs are omitted. All proofs can be
found in [9].
2
Deﬁnitions
For a (partial) function f : A →B, we denote by dom( f) and rng( f) its domain and
range, respectively. For a relation R ⊆A×A, we denote by R∗the reﬂexive and transitive
closure of R.
Let κ be a ﬁxed natural number throughout this paper and let P be a countably
inﬁnite set of predicate symbols. Each predicate symbol p ∈P is associated a unique
arity, denoted ar(p). Let V be a countably inﬁnite set of variables. For technical con-
venience, we also consider a special constant ⊥, which will be used to denote “empty”
record ﬁelds. Formulæ are built inductively, according to the following syntax:
φ := x ̸≈x′ | x ≈x′ | x →(y1,...,yκ) | p(x1,...,xn) | φ1 ∗φ2 | φ1 ∨φ2 | ∃x . φ1
where p ∈P is a predicate symbol of arity n = ar(p), x,x′,x1,...,xn ∈V are variables
and y1,...,yκ ∈V ∪{⊥} are terms, i.e. either variables or ⊥.
The set of variables freely occurring in a formula φ is denoted by fv(φ), we assume
by α-equivalence that the same variable cannot occur both free and bound in the same
formula φ, and that distinct quantiﬁers bind distinct variables. The size |φ| of a formula
φ is the number of occurrences of symbols in φ. A formula x ≈x′ or x ̸≈x′ is an equa-
tional atom, x →(y1,...,yκ) is a points-to atom, whereas p(x1,...,xn) is a predicate
atom. Note that ⊥cannot occur in an equational or in a predicate atom. A formula is
predicate-less if no predicate atom occurs in it. A symbolic heap is a formula of the form
∃xxx .∗m
j=1αi, where each αi is an atom and xxx is a possibly empty vector of variables.
Deﬁnition 1. A variable x is allocated by a symbolic heap φ iff φ contains a sequence
of equalities x1 ≈x2 ≈... ≈xn−1 ≈xn, for n ≥1, such that x = x1 and xn →(y1,...,yκ)
occurs in φ, for some variables x1,...,xn and some terms y1,...,yκ ∈V ∪{⊥}.
A substitution is a partial function mapping variables to variables. If σ is a substitution
and φ is a formula, a variable or a tuple, then φσ denotes the formula, the variable or
the tuple obtained from φ by replacing every free occurrence of a variable x ∈dom(σ)
by σ(x), respectively. We denote by {⟨xi,yi⟩| i ∈1,n} the substitution with domain
{x1,...,xn} that maps xi to yi, for each i ∈1,n.
A set of inductive deﬁnitions (SID) R is a ﬁnite set of implications (or rules) of the
form p(x1,...,xn) ⇐π, where p ∈P, n = ar(p), x1,...,xn are pairwise distinct variables
and π is a quantiﬁer-free symbolic heap. The predicate atom p(x1,...,xn) is the head of
the rule and R (p) denotes the subset of R consisting of rules with head p(x1,...,xn)
(the choice of x1,...,xn is not important). The variables in fv(π)\{x1,...,xn} are called

186
M. Echenim et al.
the existential variables of the rule. Note that, by deﬁnition, these variables are not
explicitly quantiﬁed inside π and that π is quantiﬁer-free. For simplicity, we denote by
p(x1,...,xn) ⇐R π the fact that the rule p(x1,...,xn) ⇐π belongs to R . The size of R is
deﬁned as |R |
def= ∑p(x1,...,xn)⇐R π |π|+n and its width as w(R )
def= maxp(x1,...,xn)⇐R π |π|+
n.
We write p ⪰R q, p,q ∈P iff R contains a rule of the form p(x1,...,xn) ⇐π, and q
occurs in π. We say that p depends on q if p ⪰∗
R q. For a formula φ, we denote by P(φ)
the set of predicate symbols q, such that p ⪰∗
R q for some predicate p occurring in φ.
Given formulæ φ and ψ, we write φ ⇐R ψ if ψ is obtained from φ by replacing an
atom p(u1,...,un) by π{⟨x1,u1⟩,...,⟨xn,un⟩}, where R contains a rule p(x1,...,xn) ⇐
π. We assume, by a renaming of existential variables, that the set (fv(π)\{x1,...,xn})∩
fv(φ) is empty. We call ψ an unfolding of φ iff φ ⇐∗
R ψ.
We now deﬁne the semantics of SL. Let L be a countably inﬁnite set of locations
containing, in particular, a special location ‚. A structure is a pair (s,h), where:
– s is a partial function from V ∪{⊥} to L, called a store, such that ⊥∈dom(s) and
s(x) = ‚ ⇐⇒x = ⊥, for all x ∈V ∪{⊥}, and
– h : L →Lκ is a ﬁnite partial function, such that ‚ ̸∈dom(h).
If x1,...,xn are pairwise distinct variables and ℓ1,...,ℓn ∈L are locations, we denote by
s[xi ←ℓi | 1 ≤i ≤n] the store s′ deﬁned by dom(s′) = dom(s)∪{x1,...,xn}, s′(y) = ℓi
if y = xi for some i ∈1,n, and s′(y) = s(x) otherwise. If x1,...,xn ̸∈dom(s), then the
store s′ is called an extension of s to {x1,...,xn}.
Given a heap h, we deﬁne ref(h)
def= 
l∈dom(h){ℓi | h(ℓ) = (ℓ1,...,ℓκ),i ∈1,κ} and
loc(h)
def= dom(h)∪ref(h). Two heaps h1 and h2 are disjoint iff dom(h1)∩dom(h2) = /0,
in which case h1 ⊎h2 denotes the union of h1 and h2, undeﬁned whenever h1 and h2 are
not disjoint.
Given an SID R , (s,h) |=R φ is the least relation between structures and formulæ
such that whenever (s,h) |=R φ, we have fv(φ) ⊆dom(s) and the following hold:
(s,h) |=R x ≈x′
if dom(h) = /0 and s(x) = s(x′)
(s,h) |=R x ̸≈x′
if dom(h) = /0 and s(x) ̸= s(x′)
(s,h) |=R x →(y1,...,yκ) if dom(h) = {s(x)} and h(s(x)) = ⟨s(y1),...,s(yκ)⟩
(s,h) |=R φ1 ∗φ2
if there exist disjoint heaps h1 and h2 such that
h = h1 ⊎h2 and (s,hi) |=R φi, for both i = 1,2
(s,h) |=R φ1 ∨φ2
if (s,h) |=R φi, for some i = 1,2
(s,h) |=R ∃x . φ
if there exists ℓ∈L such that (s[x ←ℓ],h) |= φ
(s,h) |=R p(x1,...,xn)
if p(x1,...,xn) ⇐R φ, and there exists a store se
coinciding with s on {x1,...,xn}, such that (se,h) |= φ
Given formulæ φ and ψ, we write φ |=R ψ whenever (s,h) |=R φ ⇒(s,h) |=R ψ,
for all structures (s,h) and φ ≡R ψ for (φ |=R ψ and ψ |=R φ). We omit the subscript
R whenever these relations hold for any SID. It is easy to check that, for all formulæ
φ1,φ2,ψ, it is the case that (φ1 ∨φ2)∗ψ ≡(φ1 ∗ψ)∨(φ2 ∗ψ) and (∃x.φ1)∗φ2 ≡∃x . φ1 ∗
φ2. Consequently, each formula can be transformed into an equivalent ﬁnite disjunction
of symbolic heaps.

Unifying Decidable Entailments in Separation Logic with Inductive Deﬁnitions
187
Deﬁnition 2. An entailment problem is a triple P
def= φ ⊢R ψ, where φ is a quantiﬁer-
free formula, ψ is a formula and R is an SID. The problem P is valid iff φ |=R ψ. The
size of the problem P is deﬁned as |P|
def= |φ| + |ψ| + |R | and its width is deﬁned as
w(P)
def= max(|φ|,|ψ|,w(R )).
Note that considering φ to be quantiﬁer-free loses no generality, because ∃x.φ |=R
ψ ⇐⇒φ |=R ψ.
3
Decidable Entailment Problems
The class of general entailment problems is undecidable, see Theorem 5 below for a
reﬁnement of the initial undecidability proofs [11,1]. A ﬁrst attempt to deﬁne a natural
decidable class of entailment problems is described in [10] and involves three restric-
tions on the SID rules, formally deﬁned below:
Deﬁnition 3. A rule p(x1,...,xn) ⇐π is:
1. progressing (P) iff π = x1 →(y1,...,yκ)∗ρ and ρ contains no points-to atoms,
2. connected (C) iff it is progressing, π = x1 →(y1,...,yκ) ∗ρ and every predicate
atom in ρ is of the form q(yi,uuu), for some i ∈1,κ,
3. established (E) iff every existential variable x ∈fv(π)\{x1,...,xn} is allocated by
every predicate-less unfolding π ⇐∗
R φ.
An SID R is P (resp. C, E) for a formula φ iff every rule in 
p∈P(φ)R (p) is P (resp.
C,E). An entailment problem φ ⊢R ψ is left- (resp. right-) P (resp. C, E) iff R is P (resp.
C, E) for φ (resp. ψ). An entailment problem is P (resp. C, E) iff it is both left- and
right-P (resp. C, E).
The decidability of progressing, connected and left-established entailment problems is
an immediate consequence of the result of [10]. Moreover, an analysis of the proof
[10] leads to an elementary recursive complexity upper bound, which has been recently
tighten down to 2EXPTIME-complete [14,8,6]. In the following, we refer to Table 1
for a recap of the complexity results for the entailment problem. The last line is the
main result of the paper and corresponds to the most general (known) decidable class
of entailment problems (Deﬁnition 8).
Table 1. Decidability and Complexity Results for the Entailment Problem (✓means that the
corresponding condition holds on the left- and right-hand side of the entailment)
Reference
Progress Connected Established Restricted Complexity
Theorem 4
✓
✓
left
-
2EXP-co.
Theorem 5
✓
left
✓
-
undec.
[7, Theorem 6]
✓
✓
-
-
undec.
[8, Theorem 32]
✓
✓
-
✓
2EXP-co.
Theorem 31
✓
right
-
right
2EXP-co.
The following theorem is an easy consequence of previous results [6].

188
M. Echenim et al.
Theorem 4. The progressing, connected and left-established entailment problem is
2EXPTIME-complete. Moreover, there exists a decision procedure that runs in time
22O(w(P)8·log|P|) for every instance P of this problem.
A natural question arises in this context: which of the restrictions from the above
theorem can be relaxed and what is the price, in terms of computational complexity, of
relaxing (some of) them? In the light of Theorem 5 below, the connectivity restriction
cannot be completely dropped. Further, if we drop the establishment condition, the
problem becomes undecidable [7, Theorem 6], even if both the left/right progress and
connectivity conditions apply.
Theorem 5. The progressing, left-connected and established entailment problem is un-
decidable.
The second decidable class of entailment problems [8] relaxes the connectivity con-
dition and replaces the establishment with a syntactic condition (that can be checked
in polynomial time in the size of the SID), while remaining 2EXPTIME-complete. In-
formally, the deﬁnition forbids (dis)equations between existential variables in symbolic
heaps or rules: the only allowed (dis)equations are of the form x ▷◁y where x is a free
variable (viewed as a constant in [8]). The deﬁnition given below is essentially equiv-
alent to that of [8], but avoids any reference to constants; instead it uses a notion of
R -positional functions, which helps to identify existential variables that are always re-
placed by a free variable from the initial formula during unfolding.
An R -positional function maps every n-ary predicate symbol p occurring in R to a
subset of 1,n. Given an R -positional function λ and a formula φ, we denote by Vλ(φ)
the set of variables xi such that φ contains a predicate atom p(x1,...,xn) with i ∈λ(p).
Note that Vλ is stable under substitutions, i.e. Vλ(φσ) = (Vλ(φ))σ, for each formula φ
and each substitution σ.
Deﬁnition 6. Let ψ be a formula and R be an SID. The fv-proﬁle of the pair (ψ,R )
is the R -positional function λ such that the sets λ(p), for p ∈P, are the maximal sets
satisfying the following conditions:
1. Vλ(ψ) ⊆fv(ψ).
2. For all predicate symbols p ∈P(ψ), all rules p(x1,...,xn) ⇐π in R , all predicate
atoms q(y1,...,ym) in π and all i ∈λ(q), there exists j ∈λ(p) such that x j = yi.
The fv-proﬁle of (ψ,R ) is denoted by λψ
R .
Intuitively, given a predicate p ∈P, the set λψ
R (p) denotes the formal parameters of p
that, in every unfolding of ψ, will always be substituted by variables occurring freely
in ψ. It is easy to check that λψ
R can be computed in polynomial time w.r.t. |ψ| + |R |,
using a straightforward greatest ﬁxpoint algorithm. The algorithm starts with a function
mapping every predicate p of arity n to 1,n and repeatedly removes elements from
the sets λ(p) to ensure that the above conditions hold. In the worst case, we may have
eventually λ(p) = /0 for all predicate symbols p.
Deﬁnition 7. Let λ be an R -positional function, and V be a set of variables. A formula
φ is λ-restricted (λ-R) w.r.t. V iff the following hold:

Unifying Decidable Entailments in Separation Logic with Inductive Deﬁnitions
189
1. for every disequation y ̸≈z in φ, we have {y,z}∩V ̸= /0, and
2. Vλ(φ) ⊆V.
A rule p(x1,...,xn) ⇐x →(y1,...,yκ)∗ρ is:
– λ-connected (λ-C) iff for every atom q(z1,...,zm) occurring in ρ, we have z1 ∈
Vλ(p(x1,...,xn))∪{y1,...,yκ},
– λ-restricted (λ-R) iff ρ is λ-restricted w.r.t. Vλ(p(x1,...,xn)).
An SID R is P (resp. λ-C, λ-R) for a formula φ iff every rule in 
p∈P(φ)R (p) is P
(resp. λ-C, λ-R).
An SID R is λ-C (λ-R) for a formula φ iff every rule in 
p∈P(φ)R (p) is λ-C (λ-R).
An entailment problem φ ⊢R ψ is left- (right-) λ-C, (λ-R) iff R is λ-C (λ-R) for φ (ψ),
where λ is considered to be λφ
R (λψ
R ). An entailment problem is λ-C (λ-R) iff it is both
left- and right-λ-C (λ-R).
The class of progressing, λ-connected and λ-restricted entailment problems has been
shown to be a generalization of the class of progressing, connected and left-established
problems, because the latter can be reduced to the former by a many-one reduction [8,
Theorem 13] that runs in time |P| · 2O(w(P)2) on input P (Figure 1) and preserves the
problem’s width asymptotically.
Fig. 1. Many-one Reductions between Decidable Entailment Problems
right λ-restricted
|P|·2O(w(P)2)
|P|·2O(w(P)logw(P))
⊇
progressing
connected
left established
progressing
λ-connected
λ-restricted
(safe)
progressing
right λ-connected
In the rest of this paper we close the loop by deﬁning a syntactic extension of λ-
progressing, λ-connected and λ-restricted entailment problems and by showing that
this extension can be reduced to the class of progressing, connected and left-established
entailment problems by a many-one reduction. The new fragment is deﬁned as follows:
Deﬁnition 8. An entailment problem φ ⊢R ψ is safe if, for λ
def= λψ
R , the following hold:
1. every rule in R is progressing,
2. ψ is λ-restricted w.r.t. fv(φ),
3. all the rules from 
p∈P(ψ)R (p) are λ-connected and λ-restricted.
Note that there is no condition on the formula φ, or on the rules deﬁning the predicates
occurring only in φ, other than the progress condition. The conditions in Deﬁnition
8 ensure that all the disequations occurring in any unfolding of ψ involve at least one

190
M. Echenim et al.
variable that is free in φ. Further, the heaps of the model of ψ must be forests, i.e. unions
of trees, the roots of which are associated with the ﬁrst argument of the predicate atoms
in ψ or to free variables from φ.
A typical yet very simple example of such an entailment is the so-called “reversed
list” problem that consists in checking that any list segment revls(z,y) deﬁned in the
reverse direction (from the tail to the head) is a list segment ls(x,y) in the usual sense
(deﬁned inductively from head to tail). This corresponds to the entailment problem
revls(z,y) ⊢R ∃x.ls(x,y) where R contains the following rules:
ls(x,y) ⇐x →(y)
revls(z,y) ⇐z →(y)
ls(x,y) ⇐x →(z)∗ls(z,y)
revls(z,y) ⇐z →(y)∗revls(u,z)
This problem is considered as challenging for proof search-based automated reasoning
procedures (see, e.g., [4,16]). The antecedent does not fulﬁll the connectivity condition,
but the subsequent does, hence the entailment is safe. Similar, more complex examples
can be deﬁned, for instance a list can be constructed by interleaving elements at odd or
even positions. Another example is the case of a data structure containing an unbounded
number of acylic lists (e.g., a list of acyclic lists). Such a data structure does not fulﬁll
the restricteness condition, since one needs to compare the pointers occurring along
each list to the point at the end. Checking, for instance, that the concatenation of two
lists of acyclic lists is again a list of (possibly cyclic) lists is a problem that ﬁts into the
safe class and can thus be effectively checked by our algorithm.
We refer the reader to Figure 1 for a general picture of the entailment problems
considered so far and of the many-one reductions between them, where the reduction
corresponding to the dashed arrow is the concern of the next section. Importantly, since
all reductions are many-one, taking time polynomial in the size and exponential in the
width of the input problem, while preserving its width asymptotically, the three classes
from Figure 1 can be uniﬁed into a single (2EXPTIME-complete) class of entailments.
4
Reducing Safe to Established Entailments
In a model of a safe SID (Deﬁnition 8), the existential variables introduced by the
replacement of predicate atoms with corresponding rule bodies are not required to be
allocated. This is because safe SIDs are more liberal than established SIDs and allow
heap structures with an unbounded number of dangling pointers. As observed in [8],
checking the validity of an entailment (w.r.t a restricted SID) can be done by considering
only those structures in which the dangling pointers point to pairwise distinct locations.
The main idea of the hereby reduction of safe to established entailment problems is that
any such structure can be extended by allocating all dangling pointers separately and,
moreover, the extended structures can be deﬁned by an established SID.
In what follows, we ﬁx an arbitrary instance P = φ ⊢R ψ of the safe entailment
problem (Deﬁnition 8) and denote by λ
def= λψ
R the fv-proﬁle of (ψ,R ) (Deﬁnition
6). Let www
def= (w1,...,wν) be the vector of free variables from φ and ψ, where the or-
der of variables is not important and assume w.l.o.g. that ν > 0. Let Pl
def= P(φ) and

Unifying Decidable Entailments in Separation Logic with Inductive Deﬁnitions
191
Pr
def= P(ψ) be the sets of predicate symbols that depend on the predicate symbols oc-
curring in the left- and right-hand side of the entailment, respectively. We assume that
φ and ψ contain no points-to atoms and that Pl ∩Pr = /0. Again, these assumptions lose
no generality, because a points-to atom u →(v1,...,vκ) can be replaced by a predi-
cate atom p(u,v1,...,vκ), where p is a fresh predicate symbol associated with the rule
p(x,y1,...,yκ) ⇐x →(y1,...,yκ). Moreover the condition Pl ∩Pr ̸= /0 may be enforced
by considering two copies of each predicate, for the left-hand side and for the right-hand
side, respectively. Finally, we assume that every rule contains exactly μ existential vari-
ables, for some ﬁxed μ ∈N; this condition can be enforced by adding dummy literals
x ≈x if needed.
We describe a reduction of P to an equivalent progressing, connected, and left-
established entailment problem. The reduction will extend heaps, by adding ν+μ record
ﬁelds. We shall therefore often consider heaps and points-to atoms having κ + ν + μ
record ﬁelds, where the formal deﬁnitions are similar to those given previously. Usu-
ally such formulæ and heaps will be written with a prime. These additional record ﬁelds
will be used to ensure that the constructed system is connected, by adding all the exis-
tential variables of a given rule (as well as the variables in w1,...,wν) into the image of
the location allocated by the considered rule. Furthermore, the left-establishment condi-
tion will be enforced by adding predicates and rules in order to allocate all the locations
that correspond to existential quantiﬁers and that are not already allocated, making such
locations point to a dummy vector ⊥⊥⊥
def= (⊥,...,⊥), of length κ+ν+μ, where ⊥is the
special constant denoting empty heap entries. To this aim, we shall use a predicate sym-
bol ⊥⊥⊥associated with the rule ⊥⊥⊥(x) ⇐x →⊥⊥⊥. Note that allocating all these locations
will entail (by deﬁnition of the separating conjunction) that they are distinct, thus the
addition of such predicates and rules will reduce the number of satisﬁable unfoldings.
However, due to the restrictions on the use of disequations3, we shall see that this does
not change the status of the entailment problem.
Deﬁnition 9. For any total function γ : L →L and any tuple ℓℓℓ= ⟨ℓ1,...,ℓn⟩∈Ln, we
denote by γ(ℓℓℓ) the tuple ⟨γ(ℓ1),...,γ(ℓn)⟩. If s is a store, then γ(s) denotes the store
with domain dom(s), such that γ(s)(x)
def= γ(s(x)), for all x ∈dom(s). Consider a heap
h such that for all ℓ̸= ℓ′ ∈dom(h), we have γ(ℓ) ̸= γ(ℓ′). Then γ(h) denotes the heap
with domain dom(γ(h)) = {γ(ℓ) | ℓ∈dom(h)}, such that γ(h)(γ(ℓ))
def= γ(h(ℓ)), for all
ℓ∈dom(h).
The following lemma identiﬁes conditions ensuring that the application of a map-
ping to a structure (Deﬁnition 9) preserves the truth value of a formula.
Lemma 10. Given a set of variables V, let α be a formula that is λ-restricted w.r.t.
V, such that P(α) ⊆Pr and let (s,h) be an R -model of α. For every mapping γ :
L →L such that γ(ℓ) = γ(ℓ′) ⇒ℓ= ℓ′ holds whenever either {ℓ,ℓ′} ⊆dom(h) or
{ℓ,ℓ′}∩s(V) ̸= /0, we have (γ(s),γ(h)) |=R α.
If γ is, moreover, injective, then the result of Lemma 10 holds for any formula:
Lemma 11. Let α be a formula and let (s,h) be an R -model of α. For every injective
mapping γ : L →L we have (γ(s),γ(h)) |=R α.
3 Point (1) of Deﬁnition 7 in conjunction with point (2) of Deﬁnition 8.

192
M. Echenim et al.
Fig. 2. Heap Expansion and Truncation
γ(ℓ)
h
main(h′)
aux(h′)
⊥
⊥
a1
aκ s(w1)
s(wν)
γ(a1)
γ(aκ)
γ
⊥
...
...
...
b1
bμ
...
⊥...
...
κ+ν+μ
κ+ν+μ
ℓ
4.1
Expansions and Truncations
We introduce a so-called expansion relation on structures, as well as a truncation op-
eration on heaps. Intuitively, the expansion of a structure is a structure with the same
store and whose heap is augmented with new allocated locations (each pointing to ⊥)
and additional record ﬁelds, referring in particular to all the newly added allocated lo-
cations. These locations are introduced to accommodate all the existential variables
of the predicate-less unfolding of the left-hand side of the entailment (to ensure that
the obtained entailment is left-established). Conversely, the truncation of a heap is the
heap obtained by removing these extra locations. We also introduce the notion of a
γ-expansion which is a structure whose image by γ is an expansion.
We recall that, throughout this and the next sections, www = (w1,...,wν) denotes the
vector of free variables occurring in the problem, which is assumed to be ﬁxed through-
out this section and that {w1,...,wν,⊥} ⊆dom(s), for every store s considered here.
Moreover, we assume w.l.o.g. that w1,...,wν do not occur in the considered SID R and
denote by μ the number of existential variables in each rule of R . We refer to Figure 2
for an illustration of the deﬁnition below:
Deﬁnition 12. Let γ : L →L be a total mapping. A structure (s,h′) is a γ-expansion
(or simply an expansion if γ = id) of some structure (s,h), denoted by (s,h′)▷γ (s,h), if
h : L →Lκ, h′ : L →Lκ+μ+ν and there exist two disjoint heaps, main(h′) and aux(h′),
such that h′ = main(h′)⊎aux(h′) and the following hold:
1. for all ℓ1,ℓ2 ∈dom(main(h′)), if γ(ℓ1) = γ(ℓ2) then ℓ1 = ℓ2,
2. γ(dom(main(h′))) = dom(h),
3. for each ℓ∈dom(main(h′)), we have h′(ℓ) = ⟨aaa,s(www),bℓ
1,...,bℓ
μ⟩, for some loca-
tions bℓ
1,...,bℓ
μ ∈L and γ(aaa) = h(γ(ℓ)),
4. for each ℓ∈dom(aux(h′)), we have h′(ℓ) = ‚
‚
‚ and there exists a location ℓ′ ∈
dom(main(h′)) such that main(h′)(ℓ′) is of the form ⟨aaa,ℓℓℓ,bℓ′
1 ,...,bℓ′
μ ⟩where ℓis
a tuple of locations and ℓ= bℓ′
i , for some i ∈1,μ. The element ℓ′ is called the
connection of ℓin h′ and is denoted by Ch′(ℓ).4
Let (s,h′) be a γ-expansion of (s,h) and let ℓ∈dom(main(h′)) be a location. Since ν > 0
and for all i ∈1,ν, s(wi) occurs in h′(ℓ), and since we assume that s(wi) ̸= ‚ = s(⊥)
for every i ∈1,ν, necessarily main(h′)(ℓ) ̸= ‚
‚
‚. This entails that the decomposition
4 Note that ℓ′ does not depend on γ, and if several such locations exist, then one is chosen
arbitrarily.

Unifying Decidable Entailments in Separation Logic with Inductive Deﬁnitions
193
h′ = main(h′)⊎aux(h′) is unique: main(h′) and aux(h′) are the restrictions of h′ to the
locations ℓin dom(h′) such that h′(ℓ) ̸=‚
‚
‚ and h′(ℓ) =‚
‚
‚, respectively. In the following,
we shall thus freely use the notations aux(h′) and main(h′), for arbitrary heaps h′.
Deﬁnition 13. Given a heap h′, we denote by trunc(h′) the heap h deﬁned as follows:
dom(h)
def= dom(h′) \ {ℓ∈dom(h′) | h′(ℓ) = ‚
‚
‚} and for all ℓ∈dom(h), if h′(ℓ) =
(ℓ1,...,ℓκ+ν+μ), then h(ℓ)
def= (ℓ1,...,ℓκ).
Note that, if h = trunc(h′) then h : L →Lκ and h′ : L →Lκ+μ+ν are heaps of differ-
ent out-degrees. In the following, we silently assume this fact, to avoid cluttering the
notation by explicitly specifying the out-degree of a heap.
Example 14. Assume that L = N, ν = μ = 1. Let s be a store such that s(w1) = 0. We
consider:
h
def= {⟨1,2⟩,⟨2,2⟩},
h′
1
def= {⟨1,(2,0,1)⟩,⟨2,(2,0,3)⟩,⟨3,(⊥,⊥,⊥)⟩},
h′
2
def= {⟨1,(3,0,1)⟩,⟨2,(4,0,3)⟩,⟨3,(⊥,⊥,⊥)⟩}.
We have (s,h′
1)▷id (s,h) and (s,h′
2)▷γ (s,h), with γ
def= {⟨1,1⟩,⟨2,2⟩,⟨3,2⟩,⟨4,2⟩}. Also,
trunc(h′
1) = {⟨1,2⟩,⟨2,2⟩} = h and trunc(h′
2) = {⟨1,3⟩,⟨2,4⟩}. Note that h has out-
degree κ = 1, whereas h′
1 and h′
2 have out-degree 3.
■
Lemma 15. If (s,h′)▷γ (s,h) then h = γ(trunc(h′)), hence (s,h′)▷id (s,trunc(h′)).
The converse of Lemma 15 does not hold in general, but it holds under some addi-
tional conditions:
Lemma 16. Consider a store s, let h′ be a heap and let h
def= trunc(h′). Let D2
def= {ℓ∈
dom(h′) | h′(ℓ) = ‚
‚
‚} and D1
def= dom(h′)\D2. Assume that:
1. for every location ℓ∈D1, h(ℓ) is of the form (ℓ1,...,ℓκ) and h′(ℓ) is of the form
(ℓ1,...,ℓκ,s(www),ℓ′
1,...,ℓ′
μ);
2. every location ℓ∈D2 has a connection in h′.
Then (s,h′)▷id (s,h).
4.2
Transforming the Consequent
We ﬁrst describe the transformation for the right-hand side of the entailment problem,
as this transformation is simpler.
Deﬁnition 17. We associate each n-ary predicate p ∈Pr with a new predicate p of arity
n + ν. We denote by α the formula obtained from α by replacing every predicate atom
p(x1,...,xn) by p(x1,...,xn,www), where www = (w1,...,wν).
Deﬁnition 18. We denote by R the set of rules of the form:
p(x1,...,xn,www) ⇐x1 →(y1,...,yκ,www,z1,...,zμ)σ∗ρσ∗ξI ∗χσ
where:

194
M. Echenim et al.
– p(x1,...,xn) ⇐x1 →(y1,...,yκ)∗ρ is a rule in R with p ∈Pr,
– z1,...,zμ are variables not occurring in fv(ρ)∪{x1,...,xn,y1,...,yκ,w1,...,wν},
– σ is a substitution with dom(σ) ⊆fv(ρ)\{x1} and rng(σ) ⊆{w1,...,wν},
– ξI
def= ∗i∈I⊥⊥⊥(zi), with I ⊆{1,...,μ},
– χσ
def= ∗x∈dom(σ)x ≈xσ.
We denote by Rr the set of rules in R that are connected5.
Note that the free variables www are added as parameters in the rules above, instead of
some arbitrary tuple of fresh variables ωωω, of the same length as www. This is for the sake
of conciseness, since these parameters ωωω will be systematically mapped to www.
Example 19. Assume that ψ = ∃x . p(x,w1), with ν = 1, μ = 1 and λ(p) = {2}. Assume
also that p is associated with the rule: p(u1,u2) ⇐u1 →u1 ∗q(u2). Observe that the rule
is λ-connected, but not connected. Then dom(σ) ⊆{u2}, rng(σ) ⊆{w1} and I ⊆{1},
so that R contains the following rules:
(1) p(u1,u2,w1) ⇐u1 →(u1,w1,z1)∗q(u2)
(2) p(u1,u2,w1) ⇐u1 →(u1,w1,z1)∗q(u2)∗⊥⊥⊥(z1)
(3) p(u1,u2,w1) ⇐u1 →(u1,w1,z1)∗q(w1)∗u2 ≈w1
(4) p(u1,u2,w1) ⇐u1 →(u1,w1,z1)∗q(w1)∗⊥⊥⊥(z1)∗u2 ≈w1
Rules (1) and (2) are not connected, hence do not occur in Rr. Rules (3) and (4) are
connected, hence occur in Rr. Note that (4) is established, but (3) is not.
■
We now relate the SIDs R and Rr by the following result:
Lemma 20. Let α be a formula that is λ-restricted w.r.t. {w1,...,wν} and contains no
points-to atoms, with P(α) ⊆Pr. Given a store s and two heaps h and h′, such that
(s,h′)▷id (s,h), we have (s,h′) |=Rr α if and only if (s,h) |=R α.
4.3
Transforming the Antecedent
We now describe the transformation operating on the left-hand side of the entailment
problem. For technical convenience, we make the following assumption:
Assumption 21. We assume that, for every predicate p ∈Pl, every rule of the form
p(x1,...,xn) ⇐π in R and every atom q(x′
1,...,x′
m) occurring in π, x′
1 ̸∈{x1,...,xn}.
This is without loss of generality, because every variable x′
1 ∈{x1,...,xn} can be re-
placed by a fresh variable z, while conjoining the equational atom z ≈x′
1 to π. Note that
the obtained SID may no longer be connected, but this is not problematic, because the
left-hand side of the entailment is not required to be connected anyway.
Deﬁnition 22. We associate each pair (p,X), where p ∈Pl, ar(p) = n and X ⊆1,n,
with a fresh predicate symbol pX, such that ar(pX) = n+ν. A decoration of a formula α
containing no points-to atoms, such that P(α) ⊆Pl, is a formula obtained by replacing
each predicate atom β
def= q(y1,...,ym) in α by an atom of the form qXβ(y1,...,ym,www),
with Xβ ⊆1,m. The set of decorations of a formula α is denoted by D(α).
5 Note that all the rules in R are progressing.

Unifying Decidable Entailments in Separation Logic with Inductive Deﬁnitions
195
The role of the set X in a predicate atom pX(x1,...,xn,www) will be explained below. Note
that the set of decorations of an atom α is always ﬁnite.
Deﬁnition 23. We denote by D(R ) the set of rules of the form
pX(x1,...,xn,www) ⇐x1 →(y1,...,yκ,www,z1,...,zμ)σ∗ρ′ ∗∗i∈I⊥⊥⊥(zi),
where:
– p(x1,...,xn) ⇐x1 →(y1,...,yκ)∗ρ is a rule in R and X ⊆1,n;
– {z1,...,zμ} = (fv(ρ)∪{y1,...,yκ})\{x1,...,xn},
– σ is a substitution, with dom(σ) ⊆{z1,...,zμ} and rng(σ) ⊆{x1,...,xn,w1,...,wν,
z1,...,zμ};
– ρ′ is a decoration of ρσ;
– I ⊆{1,...,μ} and zi ̸∈dom(σ), for all i ∈I.
Lemma 24. Let α be a formula containing no points-to atom, with P(α) ⊆Pl, and let
α′ be a decoration of α. If (s,h′) |=D(R ) α′ and (s,h′)▷id (s,h), then (s,h) |=R α.
At this point, the set X for predicate symbol pX is of little interest: atoms are simply
decorated with arbitrary sets. However, we shall restrict the considered rules in such
a way that for every model (s,h) of an atom pX(x1,...,xn+ν), with n = ar(p), the set
X denotes a set of indices i ∈1,n such that s(xi) ∈dom(h). In other words, X will
denote a set of formal parameters of pX that are allocated in every model of pX.
Deﬁnition 25. Given a formula α, we deﬁne the set Alloc(α) as follows: x ∈Alloc(α)
iff α contains either a points-to atom of the form x →(y1,...,yκ+μ+ν), or a predicate
atom qX(x′
1,...,x′
m+ν) with x′
i = x for some i ∈X.
Note that, in contrast with Deﬁnition 1, we do not consider that x ∈Alloc(α), for those
variables x related to a variable from Alloc(α) by equalities.
Deﬁnition 26. A rule pX(x1,...,xn+ν) ⇐π in D(R ) with n = ar(p) with ρ = x1 →
(y1,...,yk,www,z1,...,zμ)∗ρ′ is well-deﬁned if the following conditions hold:
1. {x1} ⊆Alloc(pX(x1,...,xn+ν)) ⊆Alloc(π);
2. fv(π) ⊆Alloc(π)∪{x1,...,xn+ν}.
We denote by Rl the set of well-deﬁned rules in D(R ).
We ﬁrst state an important properties of Rl.
Lemma 27. Every rule in Rl is progressing, connected and established.
We now relate the systems R and Rl by the following result:
Deﬁnition 28. A store s is quasi-injective if, for all x,y ∈dom(s), the implication
s(x) = s(y) ⇒x = y holds whenever {x,y} ̸⊆{w1,...,wν}.
Lemma 29. Let L be an inﬁnite subset of L. Consider a formula α containing no
points-to atom, with P(α) ⊆Pl, and let (s,h) be an R -model of α, where s is quasi-
injective, and (rng(s)∪loc(h))∩L = /0. There exists a decoration α′ of α, a heap h′ and
a mapping γ : L →L such that:

196
M. Echenim et al.
– (s,h′)▷γ (s,h),
– if ℓ̸∈L then γ(ℓ) = ℓ,
– loc(h′)\rng(s) ⊆L,
– dom(aux(h′)) ⊆L and
– (s,h′) |=Rl α′.
Furthermore, if s(u) ∈dom(h′)\{s(wi) | 1 ≤i ≤ν} then u ∈Alloc(α′).
4.4
Transforming Entailments
We deﬁne R
def= Rl ∪Rr. We show that the instance φ ⊢R ψ of the safe entailment prob-
lem can be solved by considering an entailment problem on R involving the elements
of D(φ) (see Deﬁnition 22). Note that the rules from Rl are progressing, connected and
established, by Lemma 27, whereas the rules from Rr are progressing and connected,
by Deﬁnition 18. Hence, each entailment problem φ′ ⊢R ψ, where φ′ ∈D(φ), is pro-
gressing, connected and left-established.
Lemma 30. φ |=R ψ if and only if 
φ′∈D(φ) φ′ |= R ψ.
Proof. “⇒” Assume that φ |=R ψ and let φ′ ∈D(φ) be a formula, (s,h′) be an R -model
of φ′ and h
def= trunc(h′). By construction, (s,h′) is an Rl-model of φ′. By deﬁnition of
D(φ), φ′ is a decoration of φ. Let D2
def= {ℓ∈dom(h′) | h′(ℓ) = ‚
‚
‚}, D1
def= dom(h′)\D2,
and consider a location ℓ∈dom(h′). By deﬁnition, ℓmust be allocated by some rule
in Rl. If ℓis allocated by a rule of the form given in Deﬁnition 23, then necessarily
h′(ℓ) is of the form (ℓ1,...,ℓκ,s(w),ℓ′
1,...,ℓ′
μ) and ℓ∈D1. Otherwise, ℓis allocated
by the predicate ⊥⊥⊥and we must have ℓ∈D2 by deﬁnition of the only rule for ⊥⊥⊥.
Since this predicate must occur within a rule of the form given in Deﬁnition 23, ℓ
necessarily occurs in the μ last components of the image of a location in D1, hence
admits a connection in h′. Consequently, by Lemma 16 (s,h′)▷id (s,h), and by Lemma
24, (s,h) |=R φ. Thus (s,h) |=R ψ, and by Lemma 20, (s,h′) |=Rr ψ, thus (s,h′) |= R ψ.
“⇐” Assume that 
φ′∈D(φ) φ′ |= R ψ and let (s,h) be a R -model of φ. Since the
truth values of φ and ψ depend only on the variables in fv(φ)∪fv(ψ), we may assume,
w.l.o.g., that s is quasi-injective. Consider an inﬁnite set L ⊆L such that (rng(s) ∪
loc(h)) ∩L = /0. By Lemma 29, there exist a heap h′, a mapping γ : L →L and a
decoration φ′ of φ such that γ(ℓ) = ℓfor all ℓ/∈L, (s,h′)▷γ (s,h) and (s,h′) |= φ′. Since
rng(s) ∩L = /0, we also have γ(s) = s. Then (s,h′) |= ψ. Let h1
def= trunc(h′). Since
(s,h′)▷γ (s,h), by Lemma 15 we have (s,h′)▷id (s,h1), and by Lemma 20, (s,h1) |= ψ.
By Lemma 15 we have h = γ(h1). Since ψ is λ-restricted w.r.t. {w1,...,wn}, we deduce
by Lemma 10 that (s,h) |= ψ.
⊓⊔
This leads to the main result of this paper:
Theorem 31. The safe entailment problem is 2EXPTIME-complete.
Proof. The 2EXPTIME-hard lower bound follows from [8, Theorem 32], as the class
of progressing, λ-connected and λ-restricted entailment problems is a subset of the safe

Unifying Decidable Entailments in Separation Logic with Inductive Deﬁnitions
197
entailment class. For the 2EXPTIME membership, Lemma 30 describes a many-one
reduction to the progressing, connected and established class, shown to be in 2EXP-
TIME, by Theorem 4. Considering an instance P = φ ⊢R ψ of the safe class, Lemma
30 reduces this to checking the validity of |D(φ)| instances of the form φ′ ⊢R ψ, that are
all progressing, connected and established, by Lemma 27. Since a formula φ′ ∈D(φ)
is obtained by replacing each predicate atom p(x1,...,xn) of φ by pX(x1,...,xn,www)
and there are at most 2n such predicate atoms, it follows that |D(φ)| = 2O(w(P)). To
obtain 2EXPTIME-membership of the problem, it is sufﬁcient to show that each of
the progressing, connected and established instances φ′ ⊢R ψ can be built in time
|P|·2O(w(P)·logw(P)). First, for each φ′ ∈D(φ), by Deﬁnition 22, we have |φ′| ≤|φ|·(1+
ν) ≤|φ|·(1+w(P)) = |φ|·2O(logw(P)). By Deﬁnition 17, we have |φ| ≤|φ|·(1+ν) =
|φ| · 2O(logw(P)). By Deﬁnition 23, D(R ) can be obtained by enumeration in time that
depends linearly of
|D(R )| ≤|R |·2μ ·(n+ν+μ)ν ≤|R |·2w(P)+w(P)·logw(P) = |P|·2O(w(P))
This is because the number of intervals I is bounded by 2μ and the number of substitu-
tions σ by (n + ν + μ)ν, in Deﬁnition 23. By Deﬁnition 25, checking whether a rule is
well-deﬁned can be done in polynomial time in the size of the rule, hence in 2O(w(P)),
so the construction of Rl takes time |P| · 2O(w(P)logw(P)). Similarly, by Deﬁnition 23,
the set R is constructed in time
| R | ≤|R |·2μ ·w(P)ν ≤|R |·2w(P)·2w(P)·logw(P) = |P|·2O(w(P))
Moreover, checking that a rule in R is connected can be done in time polynomial in
the size of the rule, hence the construction of Rr takes time 2O(w(P)logw(P)). Then the
entire reduction takes time 2O(w(P)logw(P)), which proves the 2EXPTIME upper bound
for the safe class of entailments.
⊓⊔
5
Conclusion and Future Work
Together with the results of [10,14,6,8], Theorem 31 draws a clear and complete picture
concerning the decidability and complexity of the entailment problem in Separation
Logic with inductive deﬁnitions. The room for improvement in this direction is probably
very limited, since Theorem 31 pushes the frontier quite far. Moreover, virtually any
further relaxation of the conditions leads to undecidability.
A possible line of future research which could be relevant for applications would be
to consider inductive rules constructing simultaneously several data structures, which
could be useful for instance to handle predicates comparing two structures, but it is
clear that very strong conditions would be required to ensure decidability. We are also
interested in deﬁning effective, goal-directed, proof procedures (i.e., sequent or tableaux
calculi) for testing the validity of entailment problems. Thanks to the reduction devised
in the present paper, it is sufﬁcient to focus on systems that are progressing, connected
and left-established. We are also trying to extend the results to entailments with formulæ
involving data with inﬁnite domains, either by considering a theory of locations (e.g.,
arithmetic on addresses), or, more realistically, by considering additional sorts for data.

198
M. Echenim et al.
References
1. Timos Antonopoulos, Nikos Gorogiannis, Christoph Haase, Max I. Kanovich, and Jo¨el
Ouaknine. Foundations for decision problems in separation logic with general inductive
predicates. In Anca Muscholl, editor, FOSSACS 2014, ETAPS 2014, Proceedings, volume
8412 of Lecture Notes in Computer Science, pages 411–425, 2014.
2. Josh Berdine, Byron Cook, and Samin Ishtiaq. Slayer: Memory safety for systems-level
code. In Ganesh Gopalakrishnan andShaz Qadeer, editor, Computer Aided Veriﬁcation - 23rd
International Conference, CAV 2011, Snowbird, UT, USA, July 14-20, 2011. Proceedings,
volume 6806 of LNCS, pages 178–183. Springer, 2011.
3. Cristiano Calcagno, Dino Distefano, J´er´emy Dubreil, Dominik Gabi, Pieter Hooimeijer, Mar-
tino Luca, Peter W. O’Hearn, Irene Papakonstantinou, Jim Purbrick, and Dulma Rodriguez.
Moving fast with software veriﬁcation. In Klaus Havelund, Gerard J. Holzmann, and Rajeev
Joshi, editors, NASA Formal Methods - 7th International Symposium, NFM 2015, Pasadena,
CA, USA, April 27-29, 2015, Proceedings, volume 9058 of LNCS, pages 3–11. Springer,
2015.
4. Duc-Hiep Chu, Joxan Jaffar, and Minh-Thai Trinh. Automatic induction proofs of data-
structures in imperative programs. In David Grove and Stephen M. Blackburn, editors, Pro-
ceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and
Implementation, Portland, OR, USA, June 15-17, 2015, pages 457–466. ACM, 2015. URL:
https://doi.org/10.1145/2737924.2737984, doi:10.1145/2737924.2737984.
5. Kamil Dudka, Petr Peringer, and Tom´as Vojnar. Predator: A practical tool for checking
manipulation of dynamic data structures using separation logic. In Ganesh Gopalakrishnan
and Shaz Qadeer, editors, Computer Aided Veriﬁcation - 23rd International Conference, CAV
2011, Snowbird, UT, USA, July 14-20, 2011. Proceedings, volume 6806 of LNCS, pages
372–378. Springer, 2011.
6. Mnacho Echenim, Radu Iosif, and Nicolas Peltier. Entailment checking in separation logic
with inductive deﬁnitions is 2-exptime hard. In LPAR 2020: 23rd International Conference
on Logic for Programming, Artiﬁcial Intelligence and Reasoning, Alicante, Spain, May 22-
27, 2020, volume 73 of EPiC Series in Computing, pages 191–211. EasyChair, 2020.
7. Mnacho Echenim, Radu Iosif, and Nicolas Peltier. Entailment is Undecidable for Symbolic
Heap Separation Logic Formulae with Non-Established Inductive Rules. working paper or
preprint, September 2020. URL: https://hal.archives-ouvertes.fr/hal-02951630.
8. Mnacho Echenim, Radu Iosif, and Nicolas Peltier. Decidable entailments in separation logic
with inductive deﬁnitions: Beyond establishment. In CSL 2021: 29th International Confer-
ence on Computer Science Logic, EPiC Series in Computing. EasyChair, 2021.
9. Mnacho Echenim, Radu Iosif, and Nicolas Peltier. Unifying decidable entailments in sepa-
ration logic with inductive deﬁnitions, 2021. arXiv:2012.14361.
10. Radu Iosif, Adam Rogalewicz, and Jiri Simacek. The tree width of separation logic with
recursive deﬁnitions. In Proc. of CADE-24, volume 7898 of LNCS, 2013.
11. Radu Iosif, Adam Rogalewicz, and Tom´as Vojnar. Deciding entailments in inductive sepa-
ration logic with tree automata. In Franck Cassez and Jean-Franc¸ois Raskin, editors, ATVA
2014, Proceedings, volume 8837 of Lecture Notes in Computer Science, pages 201–218.
Springer, 2014.
12. Samin S Ishtiaq and Peter W O’Hearn. Bi as an assertion language for mutable data struc-
tures. In ACM SIGPLAN Notices, volume 36, pages 14–26, 2001.
13. Jens Katelaan, Christoph Matheja, and Florian Zuleger. Effective entailment checking for
separation logic with inductive deﬁnitions. In Tom´as Vojnar and Lijun Zhang, editors, TACAS
2019, Proceedings, Part II, volume 11428 of Lecture Notes in Computer Science, pages 319–
336. Springer, 2019.

Unifying Decidable Entailments in Separation Logic with Inductive Deﬁnitions
199
14. Jens Pagel and Florian Zuleger. Beyond symbolic heaps: Deciding separation logic with
inductive deﬁnitions. In LPAR-23, volume 73 of EPiC Series in Computing, pages 390–408.
EasyChair, 2020.
15. J.C. Reynolds. Separation Logic: A Logic for Shared Mutable Data Structures. In Proc. of
LICS’02, 2002.
16. Quang-Trung Ta, Ton Chanh Le, Siau-Cheng Khoo, and Wei-Ngan Chin. Automated lemma
synthesis in symbolic-heap separation logic. Proc. ACM Program. Lang., 2(POPL):9:1–9:29,
2018. URL: https://doi.org/10.1145/3158097, doi:10.1145/3158097.
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which per-
mits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as
you give appropriate credit to the original author(s) and the source, provide a link to the Creative
Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s Creative
Commons license, unless indicated otherwise in a credit line to the material. If material is not in-
cluded
in
the
chapter’s
Creative
Commons
license
and
your
intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain
permission directly from the copyright holder.

Subformula Linking for Intuitionistic
Logic with Application to Type Theory
Kaustuv Chaudhuri
Inria & LIX/Ecole polytechnique, Palaiseau, France
kaustuv.chaudhuri@inria.fr, https://chaudhuri.info
Abstract. Subformula linking is an interactive theorem proving tech-
nique that was initially proposed for (classical) linear logic. It is based on
truth and context preserving rewrites of a conjecture that are triggered
by a user indicating links between subformulas, which can be done by
direct manipulation, without the need of tactics or proof languages. The
system guarantees that a true conjecture can always be rewritten to
a known, usually trivial, theorem. In this work, we extend subformula
linking to intuitionistic ﬁrst-order logic with simply typed lambda-terms
as the term language of this logic. We then use a well known embedding
of intuitionistic type theory into this logic to demonstrate one way to
extend linking to type theory.
1
Introduction
Suppose you want to prove a conjecture such as:
(∀x. ∃y. a(f(x), y)) ∧(∀z. a(f(f(c)), z) ⊃b(z)) ⊃∃u. b(f(u))
or to ﬁnd replacements for the ?s that would allow a dependent type such as the
following to be inhabited:
Πu∶(Πx∶a. Πy∶(b x). c x y). Πv∶(Πx∶a. b x). Πw∶a. (c ? ?).
In a mainstream interactive theorem proving system you would attempt it by
giving instructions to a carefully constructed proof veriﬁcation engine using a
formal proof language, often with a read-eval-print loop for immediate feedback.
Your instructions would guide the veriﬁer through the twists and turns of a formal
derivation until it is satisﬁed that all formal obligations have been established.
Your language of instructions could be tactics-based (such as in Coq), or it could
be a programming language itself (such as in HOL-Light or Agda); it could also
have a formal structure or be declarative (such as Isabelle/Isar).1 Despite these
superﬁcial diﬀerences, all such systems can broadly be called linguistic because
the internal state of the veriﬁer can only be modiﬁed by means of the formal
1 These are just illustrative examples of mainstream proof systems and should not be
read as assigning them a position of privilege or authority.
© The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp. 200 216, 2021.
https://doi.org/10.1007/978-3-030-79876-5 12
–

Linking for Intuitionistic Logic (and Type Theory)
201
proof language (and the whims—or semantics, if you prefer—of the interpreter
of the language).
An alternative to such a linguistic system would be a system of direct manip-
ulation, wherein there is a tangible representation of the state of the veriﬁer that
one can modify directly using such tools as one’s ﬁngers, pointing devices, or eye
movements. The veriﬁer’s job is then to make sure that the direct manipulation
attempts are allowed when they are logically permissible and prevented when
they are not. A prominent example of such a direct manipulation system is the
proof by pointing technique [3], where mouse clicks on the representation of a
proof state (in a version of Coq) are given a meaning: a click on a connective deep
in a formula is interpreted as a sequence of Coq tactics that bring the connective
to the top, at which point it could be made to interact with the other hypotheses
or the conclusion in the usual manner.
A generalization of this idea, called proof by linking, was proposed in [4]. It
allows the user not only to point but also to link diﬀerent subformulas, say with
a multi-touch input device or with a drag-and-drop metaphor. There are two
immediate beneﬁts of linking over pointing: (1) the surrounding context of a
formula is not destroyed because the linked subformulas are not brought to the
top, and (2) the interaction mode is easier to describe to complete novices. For
instance, a novice could be instructed to “match the atoms” for the ﬁrst example
above, in which case they might start by attempting the following link:
(∀x. ∃y. a(f(x), y)) ∧(∀z. a(f(f(c)), z) ⊃b(z)) ⊃∃u. b(f(u)).
The linking procedure would interpret this link as a desire to “bring” the
source atom “to” the destination atom. Without touching any other part of the
conjecture except the smallest subformula containing both the source and the
destination of the link, the conjecture would be rewritten to a diﬀerent one:
∃x. ∀y. ∀z. ((a(f(x), y) ⊃a(f(f(c)), z)) ⊃b(z)) ⊃∃u. b(f(u)).
The surrounding context of the link is preserved as nothing is brought to the
top; instead, the source moves through the formula tree to meet the destination.
The rewrites that underlie the transformation are provability preserving: if the
rewritten conjecture is provable, then so is the original conjecture. Eventually,
the conjecture (if true) would be reduced to a trivial theorem such as ⊤. Note
that the novice user does not need to know any proof language to draw these
links, not even a conceptual proof system such as the sequent calculus.
The original proof by linking technique was proposed for classical linear logic
and freely exploited the calculus of structures [17]. In this paper we show how
to adapt the technique to intuitionistic logics and intuitionistic type theories,
where the calculus of structures is not so well behaved [18,8] (or, in the case of
dependent type theory, entirely missing), and where preserving the context of
the rewrites is a more delicate task. We do this by ﬁrst deﬁning the technique for
intuitionistic ﬁrst-order logic over λ-terms, and then we use an existing complete

202
K. Chaudhuri
(shallow) embedding of dependent type theory in this logic [6,15]. A secondary
contribution is to give some insight into what a deep inference formalism might
look like for dependent type theory.
2
Subformula Linking for Intuitionistic First-Order Logic
This section will serve both as an introduction to the subformula linking procedure,
and as evidence that the technique can be applied to intuitionistic logics. Let us
do this in two phases: ﬁrst for the the propositional fragment, and then extended
with ﬁrst-order quantiﬁcation.
2.1
The Propositional Fragment
We will use the following grammar of formulas (written A, B, . . . ), where atomic
formulas are written in lowercase (a, b, . . . ).
A, B, . . . ∶∶= a ∣A ∧B ∣⊤∣A ∨B ∣⊥∣A ⊃B
Following usual conventions, the connectives ∧and ∨are left-associative, while
⊃is right-associative; the binding priority from strongest to weakest is ∧, ∨, ⊃.
The true formulas of this calculus can be deﬁned in terms of derivability in a
variety of formal systems such as with the sequent calculus LJ or G3ip [11]. In
this paper the precise sequent calculus is not of primary concern; however, we
will use the notation Γ ⊢C where Γ is a multiset of formulas to denote that
the formula C is derivable from the assumptions Γ using any such calculus.
A positively signed formula context (written C{}) is a formula with a single
occurrence of a hole {} in the place where a positively signed subformula may
occur; it is deﬁned mutually recursively with an negatively signed formula context
(written A{}) by the following grammar, where ∗∈{∧, ∨}.
C{} ∶∶= {} ∣A ∗C{} ∣C{} ∗B ∣A ⊃C{} ∣A{} ⊃B
A{} ∶∶= A ∗A{} ∣A{} ∗B ∣A ⊃A{} ∣C{} ⊃B
The replacement of the hole in C{} (resp. A{}) with a formula A yields a
new formula, which we write as C{A} (resp. A{A}). For instance, if C{} is
a ∧((b ⊃{}) ∨d), then C{c ⊃⊥} is a ∧((b ⊃(c ⊃⊥)) ∨d).
Theorem 1. Suppose that A ⊢B. Then:
– for any positively signed context C{}, it is the case that C{A} ⊢C{B}; and
– for any negatively signed context A{}, it is the case that A{B} ⊢A{A}.
Proof. Induction on the structure of the contexts C{} or A{}.
⊓⊔
In order to deﬁne the subformula linking procedure for this calculus, we work
with interaction formulas; an interaction formula is a formula where:

Linking for Intuitionistic Logic (and Type Theory)
203
Terminal rules
C{⊤}
C{a ▹a} in
C{A ⊃B}
C{A ▹B} rel
(the conclusion of rel is understood as not overlapping that of in)
Positively signed rules
C{(A ▹B) ∧F}
C{A ▹(B ∧F)}
▹∧1
C{F ∧(A ▹B)}
C{A ▹(F ∧B)}
▹∧2
C{(A ▹B) ∧(F ⊃B)}
C{(A ∨F) ▹B}
∨▹1
C{(F ⊃B) ∧(A ▹B)}
C{(F ∨A) ▹B}
∨▹2
C{(A ◦B) ⊃F}
C{A ▹(B ⊃F)}
▹⊃1
C{F ⊃(A ▹B)}
C{A ▹(F ⊃B)}
▹⊃2
C{A ▹B}
C{A ▹(B ∨F)}
▹∨1
C{A ▹B}
C{A ▹(F ∨B)}
▹∨2
C{A ▹B}
C{(A ∧F) ▹B}
∧▹1
C{A ▹B}
C{(F ∧A) ▹B}
∧▹2
C{F ∧(A ▹B)}
C{(F ⊃A) ▹B} ⊃▹
Negatively signed rules
A{(A ◦B) ∨F}
A{A ◦(B ∨F)}
◦∨1
A{F ∨(A ◦B)}
A{A ◦(F ∨B)}
◦∨2
A{A ◦B}
A{A ◦(B ∧F)}
◦∧1
A{A ◦B}
A{A ◦(F ∧B)}
◦∧2
A{(A ▹B) ⊃F}
A{A ◦(B ⊃F)}
◦⊃1
A{F ⊃(A ◦B)}
A{A ◦(F ⊃B)}
◦⊃2
(plus all the symmetric variants)
Fig. 1. Inference rules for interaction formulas
– either a single occurrence of ⊃is replaced with ▹,
– or a single occurrence of ∧is replaced with ◦.
We will deﬁne an inference system for interaction formulas that consist of
inference rules with a single conclusion and a single premise, both of which
are either formulas or interaction formulas. The inference rule represents an
admissible rule of intuitionistic logic: if the premise is a theorem, then so is the
conclusion. The full collection of rules is shown in ﬁg. 1. There are three kinds of
rules, explained below in an upwards (conclusion to premises) reading.
– Terminal rules are used to terminate a ▹-interaction in a positively signed
context. In the case where the ▹-interaction links two occurrences of the

204
K. Chaudhuri
Interaction creation rules
C{A ▹B}
C{A ⊃B} ▹
A{A ◦B}
A{A ∧B} ◦
Contraction
C{A ⊃A ⊃F}
C{A ⊃F}
cont
Simpliﬁcation rules
C{⊤}
C{A ⊃⊤}
C{B}
C{⊤⊃B}
C{⊤}
C{⊥⊃B}
C{F}
C{⊤∧F}
C{F}
C{F ∧⊤}
A{F}
A{⊥∨F}
A{F}
A{F ∨⊥}
A{⊥}
A{⊥∧F}
A{⊥}
A{F ∧⊥}
C{⊤}
C{⊤∨F}
C{⊤}
C{F ∨⊤}
Fig. 2. Link creation, contraction, and simpliﬁcation. The conclusion in each case must
not be an interaction formula.
same atom, the result is ⊤; otherwise the ▹turns back into ⊃. These are the
only rules that can transition out of interaction formulas.
– Positively signed rules operate on a ▹-interaction in a positively signed
context. The rules are written in ﬁg. 1 in such a way that the subformulas
A and B are brought together in the premise, and occurrences of F (if they
exist) are side formulas.
– Negatively signed rules operate on a ◦-interaction in an negatively signed
context. Fig. 1 only shows one of the two symmetric variants for each case; the
other variant is built by permuting A with B and transposing the operands
of ◦. For instance, ◦∨1 has the following symmetric variant.
A{(A ◦B) ∨F}
A{(A ∨F) ◦B} ◦∨1′
We will use primes to systematically name the symmetric variants of rules.
Proposition 2 (Soundness). Interpreting ▹as ⊃and ◦as ∧, each rule of
ﬁg. 1 with premise P and conclusion Q has the property that P ⊢Q.
Proof. Straightforward consequence of theorem 1.
⊓⊔
Two further administrative steps remain to complete the technique. First,
since the rules of ﬁg. 1 always contain an interaction formula in the conclusion,
we need to add some rules that can conclude ordinary (non-interaction) formulas.
Since we read each inference rule from conclusion to premise, we will call these the
interaction creation rules, which are shown in the ﬁrst part of ﬁg. 2. To incorporate
non-linearity, we add a separate contraction rule; this keeps the interaction
creation rules simple, but it needs to be explicitly invoked. These interaction
creation rules are obviously sound under the interpretation of proposition 2.

Linking for Intuitionistic Logic (and Type Theory)
205
a ⊃(a ∧a ∧⊤∧⊤)
a ⊃(a ∧a ∧⊤∧c ▹c) in
a ⊃(a ⊃a ⊃⊤⊃c) ▹c ⊃▹×3
(a ⊃a ⊃⊤⊃c) ▹a ⊃c ▹⊃2×2
(a ⊃a ⊃⊤⊃c) ⊃a ⊃c
▹
(a ⊃a ⊃b ▹b ⊃c) ⊃a ⊃c in
(a ⊃a ⊃(b ⊃c) ◦b) ⊃a ⊃c
◦⊃1′
(a ⊃(a ⊃b ⊃c) ◦b) ⊃a ⊃c
◦⊃2′
(a ⊃b ⊃c) ◦(a ⊃b) ⊃a ⊃c
◦⊃2
(a ⊃b ⊃c) ▹(a ⊃b) ⊃a ⊃c
▹⊃1
(a ⊃b ⊃c) ⊃(a ⊃b) ⊃a ⊃c ▹
⊤.... simpliﬁcation
⊤∧⊤∧⊤∧⊤
⊤∧a ▹a ∧⊤∧⊤in
a ▹(⊤∧a ∧⊤∧⊤)
▹∧1×2,▹∧2
a ⊃(⊤∧a ∧⊤∧⊤)
▹
a ⊃(a ▹a ∧a ∧⊤∧⊤) in
a ⊃a ▹(a ∧a ∧⊤∧⊤)
▹∧1×3
a ⊃a ⊃(a ∧a ∧⊤∧⊤)
▹
a ⊃(a ∧a ∧⊤∧⊤)
cont
Fig. 3. Lnip derivation fragment for the S-combinator
The ﬁnal step is to detect when a proof is complete. Since every inference
rule presented so far has a single premise, we will say that a proof is complete
when the ﬁnal (again reading bottom to top) premise is, eﬀectively, ⊤. What
do we mean by “eﬀectively”? One candidate deﬁnition could be that a purely
algorithmic procedure can detect when a proof is ﬁnished in linear time. For
instance, we can say that a proof is complete if its premise can be established
using only the simpliﬁcation rules shown in the second part of ﬁg. 2. These rules
may be applied in any arbitrary order and at any time. An implementation of
the technique may choose to apply these simpliﬁcation rules on the ﬂy.
Deﬁnition 3. The collection of rules in ﬁgures 1 and 2 will be known as the
proof system Lnip. If A and B are formulas or interaction formulas, we write
A
Lnip
−−−→B to mean that either A = B or there is an Lnip derivation where the
topmost rule has premise A and the bottom-most rule has conclusion B.
⊓⊔
Theorem 4 (Completeness of Lnip). If
⊢F, then ⊤
Lnip
−−−→F.
Proof (Sketch). There are many ways to prove this, both syntactic and semantic.
An instructive syntactic proof goes as follows. For a small variant of the G3ip
sequent calculus [11], we show that every inference rule is admissible in Lnip
under a suitable formula interpretation of sequents. Thus, any sequent proof is
recoverable in terms of Lnip inferences. We then just appeal to completeness of
the sequent calculus.
⊓⊔
Example 5. A Lnip derivation of the S-combinator formula, (a⊃b⊃c)⊃(a⊃b)⊃a⊃c,
is shown in ﬁg. 3. The interaction connectives ▹and ◦take the precedence and
associativity of ⊃and ∧respectively. The locus where a Lnip rule is applied is
depicted with a highlight. Of course, the S-combinator formula cannot be proved
without appealing to contraction at least once, which is seen by the appeal to
cont in the derivation.

206
K. Chaudhuri
An extremely interesting aspect of this example Lnip derivation is that it
begins by considering the ﬁrst two assumptions, (a ⊃b ⊃c) and (a ⊃b), of
the S-combinator formula. The user might have indicated this consideration by
drawing a link between the two occurrences of b, highlighted in orange and blue
in ﬁg. 3. The eﬀect of this consideration is to perform a “composition” of the
two assumptions into the stronger assumption (a ⊃a ⊃⊤⊃c), which could of
course have been simpliﬁed to (a ⊃a ⊃c) immediately. In shallow proof systems
such as the sequent calculus or natural deduction this kind of compositional step
cannot be taken as such, and would require cuts or lemmas.
As explained in the introduction, this kind of composition might have been
discovered in the process of exploration by the simple strategy of drawing a link
between the two occurrences of b. Such a link is legal because in the common
context that contains both occurrences of b, their ancestral connective is ⊃, which
can be turned into a ▹interaction using the ▹rule. Once these two occurrences
are linked, we can interpret the interaction rules (ﬁg. 1) as trying to bring the
two ends of the link closer. Indeed, in each of the rules of ﬁg. 1, we can say that
one of the ends of the link is in the formula A and the other is in the formula B.
We are therefore ready to formulate the linking procedure.
Deﬁnition 6 (Subformula Linking Procedure). Repeat the following se-
quence of steps until the conjecture formula (i.e., end-formula) F is transformed
to ⊤(success), no fruitful progress can be made (failure), or the proof attempt is
aborted by the user.
1. (Optional) Ask the user to indicate negatively signed subformulas of F that
need to be contracted using the cont rule.
2. Ask the user to indicate two diﬀerent subformulas of F; this is the link.
3. If the ﬁrst common ancestor connective of the two linked subformulas is a ⊃
that occurs in a positively signed context, use the ▹rule to turn it into a ▹;
likewise, if the ancestor is a ∧in an negatively signed context, use the ◦rule
to turn it into a ◦. If neither case applies, then the user indicated an invalid
link, so we return immediately to step 2.
4. Use the interaction rules (ﬁg. 1) in such a way that the endpoints of the link
stay in the same interaction from conclusion to premise.
5. Eventually, one of the terminal rules in or rel will be applicable to remove
the interaction; at this point we say that the link is resolved.
6. After resolving a link, the simpliﬁcation rules may be applied eagerly in an
arbitrary order.
The most important step in the inner loop of the procedure is step 4. The
rules for interaction are not unambiguous because the conclusions of diﬀerent
rules can overlap. Let us start by examining the positively signed rules; as an
example, consider the interaction C{(F ⊃A) ▹(G ⊃B)}, with the understanding
that the endpoints of the indicated link in step 2 are present in A and B. There

Linking for Intuitionistic Logic (and Type Theory)
207
are two possible ways to resolve this link:
C{F ∧(G ⊃(A ▹B))}
C{F ∧(A ▹(G ⊃B))} ▹⊃2
C{(F ⊃A) ▹(G ⊃B)} ⊃▹
C{G ⊃(F ∧(A ▹B))}
C{G ⊃((F ⊃A) ▹B)} ⊃▹
C{(F ⊃A) ▹(G ⊃B)} ▹⊃2
Does the choice matter? Yes, because the formulas F ∧(G ⊃H) and G ⊃(F ∧H)
are not intuitionistically equivalent; indeed, the former strictly entails the latter.
Hence, one of the two alternatives produces a strictly stronger—and potentially
unprovable!—premise. Which one should the procedure pick?
This ambiguity also existed in the original formulation of the formula linking
procedure for classical linear logic [4], and we can use the same answer used in
that work. The key insight is that many of the ambiguous cases can be resolved
by a simple analysis of polarities. A detailed discussion of polarity (and the
oft-associated focusing discipline [1]) is not relevant to this work, however.2 We
will instead just use the observation that some of the interaction rules of ﬁg. 1
are asynchronous, meaning that the premise of the rule is equiderivable as the
conclusion—assuming we replace ▹and ◦with ⊃and ∧respectively—while
other rules are synchronous, which means that the premise strictly entails the
conclusion. For the speciﬁc example above, the ▹⊃2 rule is asynchronous, because
the order of assumptions in an implication is immaterial (at least in intuitionistic
logic), while the ⊃▹rule is synchronous since its conclusion cannot justify the
premise. We can draw up this table for all the positively signed rules.
asynchronous rules:
▹∧1, ▹∧2, ∨▹1, ∨▹2, ▹⊃1, ▹⊃2
synchronous rules:
▹∨1, ▹∨2, ∧▹1, ∧▹2, ⊃▹
Whenever there is a choice between a synchronous and an asynchronous rule
to apply ﬁrst (reading from bottom to top), we should pick the asynchronous rule,
since that does not destroy derivability. If we have a choice of two asynchronous
rules, then the choice is immaterial, as derivability is preserved regardless; the
procedure can pick arbitrarily. Diﬀerent choices would just lead to associative-
commutative variants of the same ultimate premise. Finally, for a choice between
two synchronous rules, we can consider all such pairs from the table above to see
that the choice is immaterial: all choices have the same result.
The story is not quite as simple for the negatively signed rules of ﬁg. 1, where
every single rule would be synchronous by our deﬁnition. Unlike in the positively
signed case, here we have a critical pair.
A{(F ⊃(A ◦B)) ∨G}
A{((F ⊃A) ◦B) ∨G} ◦⊃2′
A{(F ⊃A) ◦(B ∨G)} ◦∨1
A{F ⊃(A ◦B) ∨G)}
A{F ⊃(A ◦(B ∨G))} ◦∨1
A{(F ⊃A) ◦(B ∨G)} ◦⊃2′
As before, the premises are not equiderivable. Resolving this ambiguity is going to
be as hard as fully automated proof search, which will therefore not be recursively
2 Our choice of connectives here has only negative polarity connectives except ∃and
∨. In intuitionistic logic it is also possible to have a positive ∧and atoms of both
polarities [5,10], but this generality is not necessary for the present work.

208
K. Chaudhuri
Terminal rules
C{⃗s ≐⃗t }
C{a⋅⃗s ▹a⋅⃗t } in
Quantiﬁer rules
C{∀x. (A ▹B)}
C{A ▹∀x. B}
▹∀
C{∃x. (A ▹B)}
C{(∀x. A) ▹B} ∀▹
A{∀y. (A ◦B)}
A{A ◦∀y. B}
◦∀
C{∃y. (A ▹B)}
C{A ▹∃y. B}
▹∃
C{∀x. (A ▹B)}
C{(∃x. A) ▹B} ∃▹
A{∃y. (A ◦B)}
A{A ◦∃y. B}
◦∃
(in each rule, x#B and y#A)
Simpliﬁcation and instantiation rules
C{⊤}
C{∀x. ⊤}
C{⊤}
C{x ≐x} reﬂ
C{⃗s ≐⃗t }
C{f⋅⃗s ≐f⋅⃗t }
cong
C{t term}
C{[t/x]A}
C{∃x. A}
inst
Fig. 4. System Lni: rules for quantiﬁers and terms
solvable as soon as we introduce quantiﬁers. The subformula linking procedure
needs further guidance from the user to resolve the ambiguity. A variant of this
ambiguity can also be found in the original subformula linking work for classical
linear logic [4]; there, the solution was to make the links directed. Then, whenever
there is a choice to be made—which will necessarily have to be a choice between
one subformula containing the source of the link and the other containing the
destination—the procedure can choose to perform the rule corresponding to the
destination ﬁrst. In the above critical pair, for instance, if A contained the source
and B the destination, then we would perform the ◦∨1 step ﬁrst (i.e., follow the
left derivation). This choice is made to evoke the intuition that the source is
brought to the destination; the context of the destination swallows the context of
the source.
Deﬁnition 7 (Directed Subformula Linking Procedure). We modify the
procedure of deﬁnition 6 by making the links in step 2 directed, and in the
resolution step 4 we break synchronous/synchronous ties for negatively signed
rules by performing the rule for the destination ﬁrst.
2.2
Quantiﬁers
Extending Lnip with ﬁrst-order quantiﬁers can be done in a number of ways.
Here we present a parsimonious extension that avoids any up front commitments
with regard to the strength of the term language. Our terms (written s, t, . . . )
have the following grammar:
s, t, . . . ∶∶= x ∣f⋅⃗s

Linking for Intuitionistic Logic (and Type Theory)
209
where we write ⃗s to stand for a list of terms [s1, s2, . . . , sn]. We use x, y, . . .
to range over variables and f, g, . . . to range over function symbols, and we
abbreviate f⋅[] to f. We also extend atomic formulas: they are now written a⋅⃗s
where a is a predicate symbol, and we again abbreviate a⋅[] to a. To formulas
and contexts we now add the two quantiﬁers, ∀and ∃, to give the following
extended grammars, where ∗∈{∧, ∨} and Q ∈{∀, ∃}.
A, B, . . . ∶∶= a⋅⃗s ∣A ∧B ∣⊤∣A ∨B ∣⊥∣A ⊃B ∣∀x. A ∣∃x. A
C{} ∶∶= {} ∣A ∗C{} ∣C{} ∗B ∣Qx. C{} ∣A ⊃C{} ∣A{} ⊃B
A{} ∶∶= A ∗A{} ∣A{} ∗B ∣Qx. A{} ∣A ⊃A{} ∣C{} ⊃B
We write C{t term} to assert that the term t is well-formed for the hole in
C{}, i.e., all the (free) variables of t are bound by some quantiﬁer that the hole
in C{} is in the scope of. We also write x#t or x#A to indicate that the variable
x is not free in t or A respectively. Finally, the capture-avoiding substitution of
t for x in a term u or formula A is written [t/x]u or [t/x]A respectively. The
replacement of formulas in contexts, on the other hand, is not capture-avoiding
C{A}; instead, this replacement is considered to be well-formed whenever every
free variable x of A has the property that C{x term}.
In order to give ourselves maximum freedom in the deﬁnition of the ﬁrst-order
extension, we will use the additional binary predicate symbol ≐to denote equality.
Given two lists of terms ⃗s = [s1, . . . , sn] and ⃗t = [t1, . . . , tn] of equal length, we
will write ⃗s ≐⃗t to stand for (s1 ≐t1) ∧⋯∧(sn ≐tn) if n > 0 and for ⊤otherwise.
Using this additional predicate, the terminal rule in of Lnip is modiﬁed to account
for the term arguments.
Deﬁnition 8 (System Lni). The system Lni is an extension of Lnip by removing
the in rule of Lnip and adding the rules of ﬁg. 4.
Theorem 9 (Completeness of Lni). If
⊢F in a complete sequent calculus
for ﬁrst-order intuitionistic logic (e.g., G3i [11]) then ⊤
Lni
−−→F.
Proof (Sketch). We can follow the same strategy as for theorem 4. Note that for
any term t, the rules reﬂand cong suﬃce to reduce C{t≐t} to C{⊤}. A transitivity
rule for ≐is not needed: no ≐is created in an negatively signed context.
⊓⊔
Example 10. Two example Lni derivations are shown in ﬁg. 5.
(a) This is a derivation for a provable formula where the user may have linked
the two occurrences of a. Observe that the simpliﬁcation rules {cong, inst,
reﬂ} help to implement ﬁrst-order uniﬁcation under a mixed quantiﬁer preﬁx.
However, since Lni simpliﬁcation rules can be applied at any time, we can
solve uniﬁcation problems incrementally, in tandem with logical reasoning.
(b) This is a derivation for an unprovable formula containing an illegal quantiﬁer
exchange, where once again the indicated link is between the two occurrences
of a. This derivation cannot be completed because there is no instantiation
for x for which ∀w. x ≐w is true.

210
K. Chaudhuri
⊤....
∀y. (⊤∧⊤)
∀y. (f⋅[c] ≐f⋅[c] ∧y ≐y)
cong×2,reﬂ
∀y. ∃z. (f⋅[c] ≐f⋅[c] ∧y ≐z) inst
∃x. ∀y. ∃z. (x ≐f⋅[c] ∧y ≐z) inst
∃x. ∀y. ∃z. (f⋅[x] ≐f⋅[f⋅[c]] ∧y ≐z)
cong
∃x. ∀y. ∃z. (a⋅[f⋅[x], y] ▹a⋅[f⋅[f⋅[c]], z]) in
∃x. ∀y. (a⋅[f⋅[x], y] ▹(∃z. a⋅[f⋅[f⋅[c]], z])) ▹∃
∃x. ((∃y. a⋅[f⋅[x], y]) ▹(∃z. a⋅[f⋅[f⋅[c]], z])) ∃▹
(∀x. ∃y. a⋅[f⋅[x], y]) ▹(∃z. a⋅[f⋅[f⋅[c]], z])
∀▹
(∀x. ∃y. a⋅[f⋅[x], y]) ⊃(∃z. a⋅[f⋅[f⋅[c]], z]) ▹
∃x. ∀y. ∃z. ∀w. (x ≐w ∧y ≐z)
∃x. ∀y. ∃z. ∀w. (a⋅[x, y] ▹a⋅[w, z]) in
∃x. ∀y. ∃z. (a⋅[x, y] ▹(∀x. a⋅[x, z])) ▹∀
∃x. ∀y. (a⋅[x, y] ▹(∃y. ∀x. a⋅[x, y])) ▹∃
∃x. ((∃y. a⋅[x, y]) ▹(∃y. ∀x. a⋅[x, y])) ∃▹
(∀x. ∃y. a⋅[x, y]) ▹(∃y. ∀x. a⋅[x, y])
∀▹
(∀x. ∃y. a⋅[x, y]) ⊃(∃y. ∀x. a⋅[x, y]) ▹
(a)
(b)
Fig. 5. Two example Lni derivations
3
Incorporating Arity-Typed λ-Terms
To make the calculus Lni of the previous section suitable to host a type theory
as an object language, we will need to generalize from ﬁrst-order terms to
general λ-terms. We will follow a standard technique known variously as higher-
order abstract syntax (HOAS) [12] or λ-tree syntax [7] that treats the pure
λ-calculus—together with αβη-equality as its equational theory—to represent
object languages. To keep things computable, we will use simply typed λ-terms
with only one basic type, which is sometimes known as arity typing. Arity types
(α, β, . . . ) and terms (s, t, . . . ) have the following grammar.
α, β, . . . ∶∶= ⋆∣α →β
h ∶∶= x ∣k
s, t, . . . ∶∶= h⋅⃗s ∣λx∶α. t
where x, y, . . . range over variables, and sans-serif identiﬁers such as k range over
term constants. For formulas, we also change the quantiﬁers Qx. F to their arity
typed forms Qx∶α. F, where Q ∈{∀, ∃}.
We keep λ-terms in canonical spine form, where the head (h) of an application
is identiﬁed and separated; in more usual notation, h⋅[s1, . . . , sn] would be written
as the iterated application (⋯(h s1) ⋯sn). The deﬁnition of substitution, [t/x]s,
must be modiﬁed to retain spine forms, which is usually done by removing redexes
on the ﬂy; for example (using @ as an auxiliary operation):
[t/x]k = k⋅[]
[t/x]x = t
[t/x]y = y⋅[]
(where x and y are diﬀerent)
[t/x](λy∶α. s) = λy∶α. [t/x]s
[t/x](h⋅[s1, . . . , sn]) = ([t/x]h) @ [[t/x]s1, . . . , [t/x]sn]
(λx∶α. s) @ [t1, t2, . . . , tn] = ([t1/x]s) @ [t2, . . . , tn]
(h⋅[s1, . . . , sm]) @ [t1, . . . , tn] = h⋅[s1, . . . , sm, t1, . . . , tn]

Linking for Intuitionistic Logic (and Type Theory)
211
Most of the inference rules of system Lni generalize easily to this setting. The
immediate diﬀerences will be with respect to the simpliﬁcation rules. For the inst
rule, we use a variant judgement C{t ∶α} to mean that the λ-term t is well-typed
at type α based on the type assumptions of its free variables that are bound
in the scope of the hole in C{}. It is possible to view this judgement as being
deﬁned by inference rules; for instance (for Q ∈{∀, ∃}):
C{Qx∶α. C′{x ∶α}}
C{∀x∶α. (t ∶β)}
C{(λx∶α. t) ∶α →β}
C{h ∶α1 →⋯→αn →β}
C{si ∶αi}
C{(h⋅[s1, . . . , sn]) ∶β}
The rules reﬂand cong of Lni are replaced with:
C{⃗s ≐⃗t }
C{h⋅⃗s ≐h⋅⃗t}
cong
C{∀x∶α. (s ≐t)}
C{(λx∶α. s) ≐(λx∶α. t)} abs
C{(λx∶α. h⋅[s1, . . . , sn, x]) ≐(λx∶α. t)}
C{h⋅[s1, . . . , sn] ≐(λx∶α. t)}
η-exp
(and its symm. variant)
Deﬁnition 11 (System Lniλ). The system Lniλ is a modiﬁcation of Lni with
the ▽rules, cong, abs, η-exp, and in above.
Theorem 12 (Completeness of Lniλ). For any formula F in the language
of ﬁrst-order logic over λ-terms but without any occurrence of ≐, if
⊢F in a
complete sequent calculus then ⊤
Lniλ
−−−→F.
Proof (Sketch). Once again, this is a straightforward extension of the proof
of theorem 9. Since there are no occurrences of ≐in F, and in particular no
occurrence of it in a negatively signed context, the rules cong, abs and η-exp are
suﬃcient to implement αβη-equivalence.
⊓⊔
4
Application: Embedding Intuitionistic Type Theories
The ﬁrst-order language over arity-typed λ-terms of the previous section has
enough expressive power for a complete encoding of any pure type system [6,15].
To keep things simple in this paper, we will demonstrate the case for LF (aka
λΠ) using the simple embedding from [15]. Expressions in LF belong to one of
the following three syntactic categories: kinds, types, or terms.
K ∶∶= type ∣Πx∶A. K
(kinds)
A, B, . . . ∶∶= a M1 ⋯Mn ∣Πx∶A. B
(types)
M, N, . . . ∶∶= x ∣k ∣λx∶A. M ∣M N
(terms)
The LF type system is formally speciﬁed using inference rules in [9] and will not
be repeated here. Instead, we will directly present a complete encoding of LF
expressions using the language of Lniλ.

212
K. Chaudhuri
The encoding proceeds in two steps. First, we transform the dependently
typed terms of LF into their simply typed forms, normalizing them as necessary.
However, since LF terms can mention their types, we simultaneously transform LF
types into simple types. This transformation erases not just the type dependencies
but also the identities of the types by collapsing all of them to the same base
type ⋆.
Deﬁnition 13. The forgetful map φ speciﬁed below transforms LF terms into
Lniλ λ-terms and LF types and kinds into Lniλ types.
φ(k) = k⋅[]
φ(x) = x⋅[]
φ(λx∶A. M) = λx∶φ(A). φ(M)
φ(M N) = φ(M) @ [φ(N)]
φ(a M1 ⋯Mn) = ⋆
φ(Πx∶A. B) = φ(A) →φ(B)
φ(type) = ⋆
φ(Πx∶A. K) = φ(A) →φ(K)
The second stage of the transformation recovers the information that was lost
in the φ map by means of one atomic propositions, has. Using this we deﬁne a
mapping ⟦⟧that transforms types and kinds to formulas in such a way that if
M ∶A holds then ⟦A⟧φ(M) is true.
Deﬁnition 14. The mapping ⟦⟧transforms an LF type/kind and a Lniλ λ-terms
into a Lniλ formula, speciﬁed recursively as follows.
⟦a M1 ⋯Mn⟧m = has⋅[m, a⋅[φ(M1), . . . , φ(Mn)]]
⟦type⟧m = has⋅[m, type]
⟦Πx∶A. J⟧m = ∀x∶φ(A). ⟦A⟧x ⊃⟦J⟧(m @ [x])
(where J can be a LF type or kind).
Proposition 15 (Completeness [15]). If the judgement x1∶J1, . . . , xn∶Jn ⊢
M ∶A is derivable in LF [9], then the following formula is provable in Lniλ:
∀x1∶φ(J1). ⟦J1⟧(x1⋅[]) ⊃⋯⊃∀xn∶φ(Jn). ⟦Jn⟧(xn⋅[]) ⊃⟦A⟧φ(M).
⊓⊔
The converse of proposition 15 does not necessarily hold, since the forgetful
map φ is injective, not surjective.3 In particular, since the encoding of atomic
types forgets the term arguments, we have that φ(λx∶A1. s) = φ(λx∶A2. s) if
φ(A1) = φ(A2); however, the latter does not guarantee that A1 = A2. Thus,
⟦Πx∶A1. B⟧φ(λx∶A2. s) may hold even when A1 ≠A2. To guarantee surjectivity,
we must use the canonical LF variant of the LF type theory where the type
ascription on λ is omitted and the type system is made bidirectional [19]; this
will guarantee that only Π-types will ascribe types to bound variables, removing
the issue highlighted above.
3 This issue, pointed out in [16], is a mistake in earlier papers such as [6,15].

Linking for Intuitionistic Logic (and Type Theory)
213
∀u. ∀z. ∃k. z⋅[u] ≐k
∀u. ∀z. ∃k. u ≐u ∧z⋅[u] ≐k ∧b⋅[u] ≐b⋅[u]
∀u. ∀z. ∃k. ∃x. u ≐x ∧z⋅[x] ≐k ∧b⋅[x] ≐b⋅[u] inst[u/x]
∀u. ∀z. ∃k. ∃x. u ≐x ∧(has⋅[z⋅[x], b⋅[x]] ▹has⋅[k, b⋅[u]])
∀u. ∀z. ∃k. (∀x. u ≐x ⊃has⋅[z⋅[x], b⋅[x]]) ▹has⋅[k, b⋅[u]]
∀u. ∀z. ∃k. (∀x. u ≐x ⊃has⋅[z⋅[x], b⋅[x]]) ⊃has⋅[k, b⋅[u]] ▹
∀u. ∀z. ∃k. (∀x. (u ≐x ∧a ≐a) ⊃has⋅[z⋅[x], b⋅[x]]) ⊃has⋅[k, b⋅[u]]
∀u. ∀z. ∃k. (∀x. (has⋅[u, a] ▹has⋅[x, a]) ⊃has⋅[z⋅[x], b⋅[x]]) ⊃has⋅[k, b⋅[u]]
∀u. ∀z. ∃k. (∀x. has⋅[u, a] ◦has⋅[x, a] ⊃has⋅[z⋅[x], b⋅[x]]) ⊃has⋅[k, b⋅[u]]
∀u. ∀z. ∃k. has⋅[u, a] ◦(∀x. has⋅[x, a] ⊃has⋅[z⋅[x], b⋅[x]]) ⊃has⋅[k, b⋅[u]]
∀u. ∀z. ∃k. has⋅[u, a] ▹(∀x. has⋅[x, a] ⊃has⋅[z⋅[x], b⋅[x]]) ⊃has⋅[k, b⋅[u]]
∀u. ∀z. has⋅[u, a] ▹(∀x. has⋅[x, a] ⊃has⋅[z⋅[x], b⋅[x]]) ⊃∃k. has⋅[k, b⋅[u]]
∀u. has⋅[u, a] ▹∀z. (∀x. has⋅[x, a] ⊃has⋅[z⋅[x], b⋅[x]]) ⊃∃k. has⋅[k, b⋅[u]]
∀u. has⋅[u, a] ⊃∀z. (∀x. has⋅[x, a] ⊃has⋅[z⋅[x], b⋅[x]]) ⊃∃k. has⋅[k, b⋅[u]] ▹
Fig. 6. A Lniλ derivation of an embedded LF type (example 16). Some type ascriptions
are elided, and doubled lines denote simpliﬁcations.
Example 16. Consider the following LF type A ≜Πu∶a. Πz∶(Πx∶a. b x). b u. By
deﬁnition 14, we have:
⟦A⟧k =∀u∶⋆. has⋅[u, a] ⊃
∀z∶⋆→⋆. (∀x∶⋆. has⋅[x, a] ⊃has⋅[z⋅[x], b⋅[x]]) ⊃
has⋅[k, b⋅[u]].
Fig. 6 has an example Lniλ derivation of this formula where k is existentially
quantiﬁed. As usual, highlights are used to indicate the two links the user
indicated in the two ▹rules. The derivation can be complete with the instantiation
[z⋅[u]/k]; this means that the LF type A is inhabited by some LF term M for
which φ(M) = z⋅[u].
Note that the fact that we have not discovered a LF term for k using the Lniλ
derivation is not a problem. Given a Lniλ term k for which ⟦A⟧k is derivable, it
is possible to ﬁnd a term M for which φ(M) = k and M ∶A holds in LF. One
way to do this would be to use bidirectional type checking [14,19] to recreate—
deterministically—the missing LF types.
While the encoding of LF in Lniλ suﬃces to implement the proof by linking
technique, it is a leaky encoding. As the derivation in ﬁg. 6 proceeds, the conjecture
resembles the image of the ⟦⟧map less and less; in particular, the conjecture starts
to accumulate things that are not fundamentally present in the LF type system,
such as term equations, conjunctions, and existential quantiﬁers. The purported
novice user mentioned in the introduction thus needs to be familiar with at least
two languages: LF and (a somewhat esoteric variant of) ﬁrst-order logic. One way

214
K. Chaudhuri
to improve matters would be to try to deﬁne the linking procedure directly on
the LF type system, but this example seems to indicate that the LF language is
not expressive enough to capture all the structures that will occur when resolving
a link. At the very least, it seems that some kind of pairing construct—i.e.,
Σ-types—is essential. Moreover, to capture free ﬂoating has assumptions, the
language of LF might need to be extended further with judgemental expressions
of the form ⟨M∶A⟩.
5
Conclusion and Future Directions
We have presented a formal system of proof by linking for intuitionistic logic
and a derived system for the dependent type theory LF. We are currently in the
process of implementing this system as a variant of the Profound tool, which was
initially developed for classical linear logic in [4].
In order for this system to be usable in a general purpose interactive theorem
prover based on ﬁrst-order logic (such as Abella [2]) or dependent type theory
(such as Twelf [13]), the most important missing ingredient is support for inductive
deﬁnitions and reasoning by induction. The ﬁrst step in a proof by structural
induction is to indicate which assumption(s) will drive the analysis, which is
closer to a pointing than a linking. Thus, proof by linking and pointing will need
to co-exist.
A further improvement that would be made as a matter of course in an
implementation would be the use of a uniﬁcation engine to remove the clutter
of ≐formulas. It is worth investigating (in future work) if the linking metaphor
can also be used for algebraic operations on terms based on ≐. In many systems
≐-assumptions can be used to rewrite terms, which is readily incorporated into
the linking scheme: just link a term to one side of a ≐. We can in fact see it as
variants of the inst rule:
C{[t/x]C′{⊤}}
C{∃x. C′{x ≐t}}
A{[t/x]A′{⊤}}
A{∀x. A′{x ≐t}}
It is worth investigating if such variants of inst can make the embedding of LF
into Lniλ less leaky.
Note that proof by linking, like proof by pointing, can easily be incorporated
as a tactic in an existing proof system. After all, each of the inference rules of
Lniλ is logically motivated, and can therefore be established as a certifying tactic.
The quality of the formal proof terms produced in this way will be poor since
most proof term languages are not designed for deep rewriting – indeed, the proof
term for each Lniλ inference rule may have a size that is exponential in that of
the conjecture. It is perhaps better to see proof by linking as a proof exploration
tool for quickly testing out logical properties of a conjecture before attempting
a traditional structured proof. In the hands of an expert user, this exploration
mode can also help to discover useful lemmas to bridge the gap between an
existing collection of proved theorems and a desired target theorem.

Linking for Intuitionistic Logic (and Type Theory)
215
References
1. J.-M. Andreoli. Logic Programming with Focusing Proofs in Linear Logic. Journal
of Logic and Computation, 2(3):297–347, 1992.
2. D. Baelde, K. Chaudhuri, A. Gacek, D. Miller, G. Nadathur, A. Tiu, and Y. Wang.
Abella: A system for reasoning about relational speciﬁcations. Journal of Formalized
Reasoning, 7(2), 2014.
3. Y. Bertot, G. Kahn, and L. Th´ery. Proof by pointing. In Theoretical Aspects of
Computer Software, pages 141–160, 1994.
4. K. Chaudhuri. Subformula linking as an interaction method. In S. Blazy, C. Paulin-
Mohring, and D. Pichardie, editors, 4th Conference on Interactive Theorem Proving
(ITP), volume 7998 of LNCS, pages 386–401. Springer, July 2013.
5. K. Chaudhuri, F. Pfenning, and G. Price. A logical characterization of forward
and backward chaining in the inverse method. Journal of Automated Reasoning,
40(2-3):133–177, Mar. 2008.
6. A. Felty and D. Miller. Encoding a dependent-type λ-calculus in a logic programming
language. In CADE, volume 449 of LNAI, pages 221–235. Springer, 1990.
7. A. Gacek, D. Miller, and G. Nadathur. A two-level logic approach to reasoning
about computations. Journal of Automated Reasoning, 49(2):241–273, 2012.
8. N. Guenot. Nested Deduction in Logical Foundations for Computation. Ph.d. thesis,
Ecole Polytechnique, 2013.
9. R. Harper, F. Honsell, and G. Plotkin. A framework for deﬁning logics. Journal of
the ACM, 40(1):143–184, 1993.
10. C. Liang and D. Miller. Focusing and polarization in linear, intuitionistic, and
classical logics. Theoretical Computer Science, 410(46):4747–4768, 2009.
11. S. Negri and J. von Plato. Structural Proof Theory. Cambridge University Press,
2001.
12. F. Pfenning and C. Elliott. Higher-order abstract syntax. In ACM-SIGPLAN
Conference on Programming Language Design and Implementation (PLDI), pages
199–208. ACM Press, June 1988.
13. F. Pfenning and C. Sch¨urmann. System description: Twelf — A meta-logical
framework for deductive systems. In H. Ganzinger, editor, 16th International
Conference on Automated Deduction (CADE), number 1632 in LNAI, pages 202–
206, Trento, 1999. Springer.
14. B. C. Pierce and D. N. Turner.
Local type inference.
ACM Transactions of
Programming Language Systems, 22(1):1–44, 2000.
15. Z. Snow, D. Baelde, and G. Nadathur. A meta-programming approach to realizing
dependently typed logic programming. In Principles and Practices of Declarative
Programming (PPDP), pages 187–198, 2010.
16. M. Southern. A Framework for Reasoning about LF Speciﬁcations. PhD thesis,
University of Minnesota, Mar. 2021. Defended; ﬁnal version to appear.
17. L. Straßburger. Linear Logic and Noncommutativity in the Calculus of Structures.
PhD thesis, Technische Universit¨at Dresden, 2003.
18. A. Tiu. A local system for intuitionistic logic. In Logic for Programming, Artiﬁcial
Intelligence, and Reasoning (LPAR), volume 4246 of LNCS, pages 242–256. Springer,
2006.
19. K. Watkins, I. Cervesato, F. Pfenning, and D. Walker.
A concurrent logical
framework I: The propositional fragment. In Post-proceedings of TYPES 2003
Workshop, number 3085 in LNCS. Springer, 2003.

216
K. Chaudhuri
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium or
format, as long as you give appropriate credit to the original author(s) and the source,
provide a link to the Creative Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Eﬃcient SAT-based Proof Search
in Intuitionistic Propositional Logic
Abstract. We present an eﬃcient proof search procedure for Intuition-
istic Propositional Logic which involves the use of an incremental SAT-
solver. Basically, it is obtained by adding a restart operation to the sys-
tem intuit by Claessen and Ros´en, thus we call our implementation
intuitR. We gain some remarkable advantages: derivations have a simple
structure; countermodels are in general small; using a standard bench-
marks suite, we outperform intuit and other state-of-the-art provers.
1
Introduction
The intuit theorem prover by Claessen and Ros´en [2] implements an eﬃcient
decision procedure for Intuitionistic Propositional Logic (IPL) based on a Sat-
isﬁability Modulo Theories (SMT) approach. Given an input formula α, the
clausiﬁcation module of intuit computes a sequent σ = R, X ⇒g equivalent
to α with respect to IPL-validity, where R, X and g have a special form: R is
a set of clauses, X is a set of implications (a →b) →c, with a, b, c atoms, g
is an atom. The decision procedure at the core of intuit searches for a Kripke
model K such that at its root all the formulas in R and X are forced and g is
not forced; we call K a countermodel for σ, since it witnesses the non-validity
of σ in IPL. The search is performed via a proper variant of the DPLL(T ) pro-
cedure [12], whose top-level loop exploits an incremental SAT-solver. This leads
to a highly performant decision strategy; actually, on the basis of a standard
benchmarks suite, intuit outperforms two of the state-of-the-art provers for
IPL, namely fCube [5] and intHistGC [11]. At ﬁrst sight, the intuit decision
procedure seems to be far away from the traditional techniques for deciding IPL
validity; on the other hand, the in-depth investigation presented in [10] unveils
a close and surprising connection between the intuit approach based on SMT
and the known proof-theoretic methods. The crucial point is that the main loop
of the decision procedure mimics a standard root-ﬁrst proof search strategy for
the sequent calculus LJTSAT [10] (see Fig. 7), a variant of Dyckhoﬀ’s calculus
LJT [3]. In [10] the intuit decision procedure is re-formulated so that, given a
sequent σ, it outputs either a derivation of σ in LJTSAT or a countermodel for σ.
Here we continue this investigation to better take advantage of the interplay
between the SMT perspective and proof-theoretic methods. At ﬁrst, we have en-
hanced the Haskell intuit code1 by implementing the derivation/countermodel
1 Available at https://github.com/koengit/intuit.
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5 13
Camillo Fiorentini(B)
–
, 2021.
217 233
Department of Computer Science, Universit`a degli Studi di Milano, Milan, Italy

extraction procedures discussed in [10]. We experimented some unexpected and
weird phenomena: derivations are often convoluted and contain applications of
the cut rule which cannot be trivially eliminated; countermodels in general con-
tain lots of redundancies. To overcome these issues, we have redesigned the deci-
sion procedure. Diﬀerently from intuit, in the main loop we keep all the worlds
of the countermodel under construction. Whenever the generation of a new world
fails, the current model is emptied and the computation restarts with a new it-
eration of the main loop. We call the obtained prover intuitR (intuit with
Restart). We gain some remarkable advantages. Firstly, the proof search proce-
dure has a plain and intuitive presentation, consisting of two nested loops (see the
ﬂowchart in Fig. 3). Secondly, derivations have a linear structure, formalized by
the calculus C→in Fig. 1; basically, a derivation in C→is a cut-free derivation in
LJTSAT having only one branch. Thirdly, the countermodels obtained by intuitR
are in general smaller than the ones obtained by intuit, since restarts cross out
redundant worlds. We have replicated the experiments in [2] (1200 benchmarks):
as reported in the table in Fig. 9 and in the scatter plot in Fig. 11, intuitR has
better performances than intuit. The intuitR implementation and other addi-
tional material (e.g., the omitted proofs, a detailed report on experiments) can
be downloaded at https://github.com/cfiorentini/intuitR.
2
Preliminary Notions
Formulas, denoted by lowercase Greek letters, are built from an inﬁnite set of
propositional variables V , the constant ⊥and the connectives ∧, ∨, →; the
formula α ↔β stands for (α →β) ∧(β →α). Elements of the set V ∪{⊥}
are called atoms and are denoted by lowercase Roman letters, uppercase Greek
letters denote sets of formulas. A (classical) interpretation M is a subset of V ,
identifying the propositional variables assigned to true. By M |= α we mean
that α is true in M; moreover, M |= Γ iﬀM |= α for every α ∈Γ. We write
Γ ⊢c α iﬀ, for every interpretation M, M |= Γ implies M |= α. A formula α is
CPL-valid (valid in Classical Propositional Logic) iﬀ∅⊢c α.
A (rooted) Kripke model for IPL (Intuitionistic Propositional Logic) is a
quadruple ⟨W, ≤, r, ϑ⟩where W is a ﬁnite and non-empty set (the set of worlds),
≤is a reﬂexive and transitive binary relation over W, the world r (the root of
K) is the minimum of W w.r.t. ≤, and ϑ : W →2V (the valuation function) is
a map obeying the persistence condition: for every pair of worlds w1 and w2 of
K, w1 ≤w2 implies ϑ(w1) ⊆ϑ(w2). The valuation ϑ is extended into a forcing
relation between worlds and formulas as follows:
w ⊩p iﬀp ∈ϑ(w), ∀p ∈V
w ⊮⊥
w ⊩α ∧β iﬀw ⊩α and w ⊩β
w ⊩α ∨β iﬀw ⊩α or w ⊩β
w ⊩α →β iﬀ∀w′ ≥w, w′ ⊩α implies w′ ⊩β.
By w ⊩Γ we mean that w ⊩α for every α ∈Γ. A formula α is IPL-valid iﬀ,
for every Kripke model K we have r ⊩α (here and below r designates the root
of K). Thus, if there exists a model K such that r ⊮α, then α is not IPL-valid;
we call K a countermodel for α, written K ̸|= α, and we say that α is counter-
satisﬁable. We write Γ ⊢i δ iﬀ, for every model K, r ⊩Γ implies r ⊩δ; thus,
218
C. Fiorentini

R ⊢c g
cpl0
R, X ⇒g
R, A ⊢c b
R, ϕ, X ⇒g
cpl1
R, X ⇒g
(a →b) →c ∈X
A ⊆V
ϕ = (A \ {a}) →c
Fig. 1. The sequent calculus C→; R, X ⇒g is an r-sequent.
α is IPL-valid iﬀ∅⊢i α. Let σ be a sequent of the form Γ ⇒δ; σ is IPL-valid
iﬀΓ ⊢i δ. By K ̸|= σ we mean that r ⊩Γ and r ⊮δ. Note that such a model
K witnesses that σ is not IPL-valid; we say that K is a countermodel for σ and
that σ is counter-satisﬁable.
Clausiﬁcation We review the main concepts about the clausiﬁcation procedure
described in [2]. Flat clauses ϕ and implication clauses λ are deﬁned as
ϕ :=  A1 → A2 |  A2
∅⊂Ak ⊆V ∪{⊥}, for k ∈{1, 2}
λ := (a →b) →c
a ∈V, {b, c} ⊆V ∪{⊥}
where  A1 and  A2 denote the conjunction and the disjunction of the atoms
in A1 and A2 respectively ({a} = {a} = a). Henceforth,  ∅→ A2 must
be read as  A2; moreover, R, R1, . . . denote sets of ﬂat clauses; X, X1, . . . sets
of implication clauses; A, A1, . . . sets of atoms. The intuit procedure relies on
the following property (see Lemma 2 in [10]):
Lemma 1. For every set of ﬂat clauses R and every atom g, R ⊢i g iﬀR ⊢c g.
In the decision procedure, ﬂat clauses are actively used only in classical rea-
soning. A pair (R, X) is →-closed iﬀ, for every (a →b) →c ∈X, b →c ∈R. An
r-sequent (reduced sequent) is a sequent Γ ⇒g where g is an atom, Γ = R ∪X
and (R, X) is →-closed. Given a formula α, the clausiﬁcation procedure yields a
triple (R, X, g) such that R, X ⇒g is an r-sequent and:
(1) ⊢i α iﬀR, X ⊢i g; (2) K ̸|= R, X ⇒g implies K ̸|= α, for every K. 2
Thus, IPL-validity of formulas can be reduced to IPL-validity of r-sequents.
3
The Calculus C→
The sequent calculus C→consists of the rules cpl0 and cpl1 from Fig. 1. Rule
cpl0 (axiom rule) can only be applied if the condition R ⊢c g holds, rule cpl1
requires that R, A ⊢c b holds. In rule cpl1, (a →b) →c is the main formula
and A the local assumptions; note that A is any set of propositional variables
(not necessarily containing a). Derivations are deﬁned as usual (see e.g. [14]);
2 In [2] the clausiﬁcation procedure outputs a triple (R, X, g) satisfying (1) and (2);
the →-closure of (R, X) is performed at the beginning of the decision procedure (for
every (a →b) →c ∈X, the clause b →c is added to R).
Eﬃcient SAT-based Proof Search in Intuitionistic Propositional Logic
219

R0, A0 ⊢c b0
R1, A1 ⊢c b1
Rm−1, Am−1 ⊢c bm−1
Rm ⊢c g
Rm, X ⇒g
λm−1
Rm−1, X ⇒g
...
R2, X ⇒g
λ1
R1, X ⇒g
λ0
R0, X ⇒g
λk = (ak →bk) →ck ∈X,
ϕk = (Ak \ {ak}) →ck,
Rk+1 = Rk ∪{ϕk}
Fig. 2. Derivation of R0, X ⇒g in C→(0 ≤k ≤m −1).
by ⊢C→σ we mean that there exists a derivation of the r-sequent σ in C→. In
showing derivations, we leave out rule names and we display the main formulas
of cpl1 applications. Soundness of rule cpl1 relies on the following property:
(a) If R, A ⊢c b, then R, (a →b) →c ⊢i ϕ, where ϕ = (A \ {a}) →c.
Indeed, let R, A ⊢c b. By Lemma 1 R, A ⊢i b, thus R, A \ {a} ⊢i a →b.
It follows that R, (a →b) →c, A \ {a} ⊢i c, hence R, (a →b) →c ⊢i ϕ. By
Lemma 1 and (a), the soundness of C→follows:
Proposition 1. ⊢C→R, X ⇒g implies R, X ⊢i g.
A derivation of σ0 = R0, X ⇒g has the plain form shown in Fig. 2: it
only contains the branch of sequents σk = Rk, X ⇒g where the sets Rk
are increasing. Nevertheless, the design of a root-ﬁrst proof search strategy for
C→is not obvious. Let σ0 be the r-sequent to be proved; we try to bottom-
up build the derivation in Fig. 2 by running a loop where, at each iteration
k ≥0, we search for a derivation of σk. It is convenient to ﬁrstly check whether
Rk ⊢c g so that, by applying rule cpl0, we immediately get a derivation of
σk. If this is not the case, we should pick an implication λk from X and guess
a proper set of local assumptions Ak in order to bottom-up apply rule cpl1.
Rk, bk ⊢c bk
Rk, X ⇒g
λk
Rk, X ⇒g
λk = (ak →bk) →ck ∈X, bk →ck ∈Rk
Ak = {bk}, ϕk = bk →ck, Rk+1 = Rk
If we followed a blind choice, the
procedure would be highly ineﬃ-
cient; for instance, the application
of rule cpl1 shown on the left trig-
gers a non-terminating loop. In-
stead, we pursue this strategy: we search for a countermodel for σk; if we suc-
ceed, then Rk, X ⊬i g and, being R0 ⊆Rk, we conclude that R0, X ⊬i g and
proof search ends. Otherwise, from the failure we learn the proper λk and Ak
to be used in the application of rule cpl1; in next iteration, proof search restarts
with the sequent σk+1, where Rk+1 is obtained by adding the learned clause
ϕk to Rk. To check classical provability, we exploit a SAT-solver; each time the
solver is invoked, the set Rk has increased, thus it is advantageous to use an
incremental SAT-solver.
220
C. Fiorentini

Countermodels Henceforth we deﬁne Kripke models by specifying the interpre-
tations associated with its worlds. Let W be a ﬁnite set of interpretations with
minimum M0, namely: M0 ⊆M for every M ∈W. By K(W) we denote the
Kripke model ⟨W, ≤, M0, ϑ⟩where ≤coincides with the subset relation ⊆and ϑ
is the identity map, thus M ⊩p (in K(W)) iﬀp ∈M. We introduce the following
realizability relation ▷W between W and implication clauses:
M ▷W (a →b) →c
iﬀ
(a ∈M) or (b ∈M) or (c ∈M) or
( ∃M ′ ∈W s.t. M ⊂M ′ and a ∈M ′ and b ̸∈M ′ ).
By M ▷W X we mean that M ▷W λ for every λ ∈X. Countermodels of r-sequents
can be characterized as follows:
Proposition 2. Let σ = R, X ⇒g be an r-sequent and let W be a ﬁnite set of
interpretations with minimum M0. Then, K(W) ̸|= σ iﬀ:
(i) g ̸∈M0; (ii) for every M ∈W, M |= R and M ▷W X.
4
The Procedure proveR
The strategy outlined in Sec. 3 is implemented by the decision procedure proveR
(prove with Restart) deﬁned by the ﬂowchart in Fig. 3. The call proveR(R,X,g)
returns Valid if the r-sequent σ = R, X ⇒g is IPL-valid, CountSat otherwise;
by tracing the computation, we can build a C→-derivation of σ in the former
case, a countermodel for σ in the latter. We exploit a single incremental SAT-
solver s: clauses can be added to s but not removed; by R(s) we denote the set
of clauses stored in s. The solver s has associated a set of propositional variables
U(s) (the universe of s); we assume that every clause ϕ supplied to s is built over
U(s) (namely, every variable occurring in ϕ belongs to U(s)). The SAT-solver is
required to support the following operations:
– newSolver()
Create a new SAT-solver.
– addClause(s, ϕ) // s is a SAT-solver, ϕ a ﬂat clause built over U(s)
Add the clause ϕ to s.
– satProve(s, A, g) // s is a SAT-solver, A ⊆U(s), g ∈U(s) ∪{⊥}
Call s to decide whether R(s), A ⊢c g (A is a set of local assumptions). The
solver outputs one of the following answers:
• Yes(A′): thus, A′ ⊆A and R(s), A′ ⊢c g;
• No(M): thus, A ⊆M ⊆U(s) and M |= R(s) and g ̸∈M.
In the former case it follows that R(s), A ⊢c g, in the latter R(s), A ⊬c g.
The procedure newSolver(R), deﬁned using the primitive operations, creates
a new SAT-solver containing all the clauses in R. The computation of the call
proveR(R, X, g) consists of the following steps:
(S0) A new SAT-solver s storing all the clauses in R is created.
(S1) A loop starts (main loop) with empty W.
Eﬃcient SAT-based Proof Search in Intuitionistic Propositional Logic
221

s ←newSolver(R)
Input Assumptions
R: ﬁnite set of ﬂat clauses
X: ﬁnite set of implication clauses
g ∈V ∪{⊥}
(R, X) is →-closed
Output Properties
Valid
implies R, X ⊢i g
CountSat implies R, X ⊬i g
(S0)
R, X, g
W ←∅
(S1)
satProve(s, ∅, g)
(S2)
Valid
W ←W ∪{M}
(S3)
select ⟨w, λ⟩s.t.
w ∈W, λ ∈X, w⋫W λ
(S4)
CountSat
satProve(s, w ∪{a}, b)
(S5)
ϕ ←(A \ {a}) →c
addClause(s, ϕ)
(S6)
W: set of interpretations
ϕ: ﬂat clause
(learned clause)
Yes(∅)
No(M)
No such ⟨w, λ⟩
⟨w, (a →b) →c ⟩
Yes(A)
No(M)
Fig. 3. Computation of proveR(R, X, g).
(S2) The SAT-solver s is called to check whether R(s) ⊢c
g. If the answer
is Yes(∅), the computation stops yielding Valid. Otherwise, the output is
No(M) and the computation continues at Step (S3).
(S3) A loop starts (inner loop) by adding the interpretation M computed at
Step (S2) to the set W (thus, W = {M}).
(S4) We have to select a pair ⟨w, λ⟩such that w ∈W, λ ∈X and w⋫W λ. If such
a pair does not exist, the procedure ends with output CountSat. Otherwise,
the computation continues at Step (S5).
(S5) Let ⟨w, (a →b) →c⟩be the pair selected at Step (S4). The SAT-solver s is
called to check whether R(s), w, a ⊢c b. If the result is No(M), then a new
iteration of the inner loop is performed where M is added to W. Otherwise,
the answer is Yes(A) and the computation continues at Step (S6); we call A
the learned assumptions and ⟨w, (a →b) →c⟩the learned pair.
(S6) The clause ϕ (the learned clause) is added to the solver s and the computa-
tion restarts from Step (S1) with a new iteration of the main loop.
222
C. Fiorentini

Note that during the computation no new variables are created, thus U(s) can
be deﬁned as the set of propositional variables occurring in R ∪X ∪{g}. We
show that the call proveR(R,X,g) is correct, namely: if R, X, g match the Input
Assumptions, then the Output Properties hold (see Fig. 3). We stipulate that:
– Rk denotes the set R(s) at the beginning of iteration k of the main loop;
– ϕk denotes the clause learned at iteration k of the main loop;
– Wk,j denotes the set W at iteration k of the main loop and just after
Step (S3) of iteration j of the inner loop.
– ∼c denotes classical equivalence, namely: α ∼c β iﬀ⊢c α ↔β.
We prove some properties about the computation of proveR(R, X, g).
(P1) Let k, j ≥0 be such that Wk,j is deﬁned. Then:
(i) The set Wk,j has a minimum element M0 and g ̸∈M0.
(ii) For every M ∈Wk,j, M |= Rk.
(iii) If Wk,j+1 is deﬁned, then Wk,j ⊂Wk,j+1.
(P2) For every 0 ≤h < k such that ϕk is deﬁned, ϕh ̸∼c ϕk.
Let Wk,0 = {M}; one can easily check that, setting M0 = M, (i) holds. Point (ii)
follows by the fact that each M in Wk,j comes from an answer No(M), thus
M |= Rk. Let Wk,j+1 be deﬁned and let Wk,j+1 = Wk,j∪{M}, with M computed
at step (S5); there is w ∈Wk,j and λ = (a →b) →c ∈X such that w⋫Wk,jλ
and w ∪{a} ⊆M and b ̸∈M. We cannot have M ∈Wk,j, otherwise, since
w ⊆M and a ∈M and b ̸∈M, we would get w ▷Wk,j λ, a contradiction. Thus
M ̸∈Wk,j, and this proves (iii).
Let 0 ≤h < k be such that ϕk is deﬁned, let ⟨wk, λk = (ak →bk) →ck⟩
and Ak be the pair and the assumptions learned at iteration k respectively;
note that Ak ⊆wk ∪{ak}. Since Rh ∪{ϕh} = Rh+1 ⊆Rk, we have ϕh ∈Rk;
by (P1)(ii), it holds that wk |= Rk, hence wk |= ϕh. We show that wk ̸|= ϕk, and
this proves (P2). Since ⟨wk, λk⟩has been selected at Step (S4), ck ̸∈wk; by the
fact that ϕk = (Ak \ {ak}) →ck and Ak \ {ak} ⊆wk, we conclude wk ̸|= ϕk.
Exploiting the above properties, we prove the correctness of proveR, also
showing how to extract derivations and countermodels from computations.
Proposition 3. The call proveR(R,X,g) is correct.
Proof. We start by proving that the computation never diverges. By (P2), the
learned clauses ϕk are pairwise not classically equivalent; since each ϕk is built
over the ﬁnite set U(s), at most 2|U(s)| such clauses can be generated, and this
proves the termination of the main loop. Since every interpretation M in W is
a subset of U(s), by (P1)(iii) the termination of the inner loop follows.
Let σ = R, X ⇒g. If proveR(R,X,g) returns CountSat, then the com-
putation ends at Step (S4) since no pair ⟨w, λ⟩can be selected. By (P1), the
current set W satisﬁes the assumptions (i),(ii) of Prop. 2; accordingly, K(W) is
a countermodel for σ, thus R, X ⊬i g. If proveR(R,X,g) outputs Valid, then
there exists m ≥0 such that, at Step (S2) of iteration m of the main loop, the
Eﬃcient SAT-based Proof Search in Intuitionistic Propositional Logic
223

SAT-solver yields Yes(∅), hence Rm ⊢c g. For every iteration k in 0 . . . m −1 of
the main loop, let ⟨wk, λk = (ak →bk) →ck⟩be the learned pair and Ak the
learned assumptions (thus, Rk, Ak ⊢c bk). We can apply rule cpl1 as follows:
Rk, Ak ⊢c bk
Rk+1, X ⇒g λk
Rk, X ⇒g
ϕk = (Ak \ {ak}) →ck
R0 = R,
Rk+1 = Rk ∪{ϕk}
Accordingly, we can build the derivation of R, X ⇒g displayed in Fig. 2 and,
by Prop. 1, we conclude R, X ⊢i g.
⊓⊔
As a corollary, we get the completeness of the calculus C→:
Proposition 4. For every r-sequent σ = R, X ⇒g, ⊢C→σ iﬀR, X ⊢i g.
We give two examples of computations using formulas from the ILTP (Intu-
itionistic Logic Theorem Proving) library [13].
Example 1. Let χ be the ﬁrst instance of problem class SYJ201 from the ILTP
library [13], where ηij = pi ↔pj and γ = p1 ∧p2 ∧p3:
χ = ((η12 →γ) ∧(η23 →γ) ∧(η31 →γ)) →γ
The clausiﬁcation of χ yields the triple (R0, X, ˜g), where X contains the impli-
cation clauses λ0, . . . , λ5 deﬁned in Fig. 4 and R0 the following 17 clauses (we
mark by a tilde the fresh variables introduced during clausiﬁcation): 3
˜p0 →˜p4,
˜p3 →p2,
˜p3 →p3,
˜p4 →p1,
˜p4 →˜p3,
˜p5 →˜p4,
˜p8 →˜p4,
˜p1 ∧˜p2 →˜p0,
˜p6 ∧˜p7 →˜p5,
˜p9 ∧˜p10 →˜p8,
p1 ∧p2 ∧p3 →˜g,
p1 →˜p2,
p1 →˜p9,
p2 →˜p1,
p2 →˜p7,
p3 →˜p6,
p3 →˜p10.
The trace of the computation of proveR(R0,X,˜g) is shown in Fig. 4. Each
row displays the validity tests performed by the SAT-solver and the computed
answers. If the result is No( ), the last two columns show the worlds wk in the
current set W and, for each wk, the list of λ such that wk⋫W λ; the pair selected
at Step (S4) is underlined. For instance, after call (0) we have W = {w0} and
w0⋫W λk for every 0 ≤k ≤5; the selected pair is ⟨w0, λ0⟩. After call (1), the set
W is updated by adding the world w1 and w1⋫W λ3, w1⋫W λ5 and w0⋫W λk for
every 2 ≤k ≤5 (since w1 ∈W, we get w0 ▷W λ0); the selected pair is ⟨w1, λ3⟩.
Whenever the SAT-solver outputs Yes(A), we display the learned clause ϕk. The
SAT-solver is invoked 15 times and there are 6 restarts. Fig. 4 also shows the
derivation of R0, X ⇒˜g extracted from the computation.
♦
Example 2. Let ψ be the second instance of problem class SYJ207 from the ILTP
library [13], where ηij = pi ↔pj and γ = p1 ∧p2 ∧p3 ∧p4:
ψ = ((η12 →γ) ∧(η23 →γ) ∧(η34 →γ) ∧(η41 →γ)) →(p0 ∨¬p0 ∨γ)
3 With intuit, the set R0 consists of the 11 clauses in the ﬁrst two rows; the remaining
6 clauses are added when the →-closure of (R , X
0
) is performed (see footnote 2).
224
C. Fiorentini

λ0 = (p3 →p2) →˜p7
λ1 = (p3 →p1) →˜p9
λ2 = (p2 →p3) →˜p6
λ3 = (p2 →p1) →˜p2
λ4 = (p1 →p3) →˜p10
λ5 = (p1 →p2) →˜p1
w0 = ∅
w1 = {p3, ˜p6, ˜p10}
w2 = {p2, ˜p1, ˜p7, ˜p10}
w3 = {p3, ˜p2, ˜p6, ˜p10}
w4 = {p1, ˜p2, ˜p6, ˜p9}
w5 = {˜p1, ˜p7, ˜p9}
w6 = w5 ∪{p2}
w7 = {p1, ˜p2, ˜p7, ˜p9}
@SAT
Answer
W
λ s.t. w⋫W λ
Start
(0) R0 ⊢?
c ˜g
No(w0)
w0
λ0, . . . , λ5
(1) R0, w0, p3 ⊢?
c p2
No(w1)
w1
λ3, λ5
w0
λ2, . . . , λ5
(2) R0, w1, p2 ⊢?
c p1
Yes({p2, ˜p6})
ϕ0 = ˜p6 →˜p2
Rest 1
(3) R1 ⊢?
c ˜g
No(w2)
w2
λ1
(4) R1, w2, p3 ⊢?
c p1
Yes({p3, ˜p1})
ϕ1 = ˜p1 →˜p9
Rest 2
(5) R2 ⊢?
c ˜g
No(w3)
w3
λ5
(6) R2, w3, p1 ⊢?
c p2
Yes({p1, ˜p10})
ϕ2 = ˜p10 →˜p1
Rest 3
(7) R3 ⊢?
c ˜g
No(w4)
w4
λ0
(8) R3, w4, p3 ⊢?
c p2
Yes({p3})
ϕ3 = ˜p7
Rest 4
(9) R4 ⊢?
c ˜g
No(w5)
w5
λ2, λ3, λ4
(10) R4, w5, p2 ⊢?
c p3
No(w6)
w6
λ4
w5
λ4
(11) R4, w6, p1 ⊢?
c p3
Yes({p1, ˜p1})
ϕ4 = ˜p1 →˜p10
Rest 5
(12) R5 ⊢?
c ˜g
No(w7)
w7
λ2
(13) R5, w7, p2 ⊢?
c p3
Yes({p2})
ϕ5 = ˜p6
Rest 6 (14) R6 ⊢?
c ˜g
Yes(∅)
Valid
R0, p2, ˜p6 ⊢c p1
R1, p3, ˜p1 ⊢c p1
R2, p1, ˜p10 ⊢c p2
R3, p3 ⊢c p2
R4, p1, ˜p1 ⊢c p3
R5, p2 ⊢c p3
R6 ⊢c ˜g
R6, X ⇒˜g
λ2
R5, X ⇒˜g
λ4
R4, X ⇒˜g
λ0
R3, X ⇒˜g
λ5
R2, X ⇒˜g
λ1
R1, X ⇒˜g
λ3
R0, X ⇒˜g
Fig. 4. Computation of proveR(R0,X,˜g), see Ex. 1.
Eﬃcient SAT-based Proof Search in Intuitionistic Propositional Logic
225

λ0 = (p4 →p3) →˜p11
λ1 = (p4 →p1) →˜p13
λ2 = (p3 →p4) →˜p10
λ3 = (p3 →p2) →˜p8
λ4 = (p2 →p3) →˜p7
λ5 = (p2 →p1) →˜p2
λ6 = (p1 →p4) →˜p14
λ7 = (p1 →p2) →˜p1
λ8 = (p0 →⊥) →˜g
w0 = ∅
w1 = {p4, ˜p10, ˜p14}
w2 = {p3, ˜p7, ˜p11, ˜p14}
w3 = {p4, ˜p8, ˜p10, ˜p14}
w4 = w3 ∪{p2, ˜p1}
w5 = w4 ∪{p0, ˜g}
w6 = {p1, ˜p2, ˜p8, ˜p10, ˜p13}
w7 = {p4, ˜p1, ˜p8, ˜p10, ˜p14}
w8 = w7 ∪{p2}
w9 = w7 ∪{p0, ˜g}
@SAT
Answer
W
λ s.t. w⋫W λ
Start
(0) R0 ⊢?
c ˜g
No(w0)
w0
λ0, . . . , λ8
(1) R0, w0, p4 ⊢?
c p3
No(w1)
w1
λ3, λ4, λ5, λ7, λ8
w0
λ2, . . . , λ8
(2) R0, w1, p3 ⊢?
c p2
Yes({p3, ˜p10})
ϕ0 = ˜p10 →˜p8
Rest 1
(3) R1 ⊢?
c ˜g
No(w2)
w2
λ1, λ5, λ7, λ8
(4) R1, w2, p4 ⊢?
c p1
Yes({p4, ˜p11})
ϕ1 = ˜p11 →˜p13
Rest 2
(5) R2 ⊢?
c ˜g
No(w3)
w3
λ4, λ5, λ7, λ8
(6) R2, w3, p2 ⊢?
c p3
No(w4)
w4
λ8
w3
λ7, λ8
(7) R2, w4, p0 ⊢?
c ⊥
No(w5)
w5
∅
w4
∅
w3
λ7
(8) R2, w3, p1 ⊢?
c p2
Yes({p1, ˜p14})
ϕ2 = ˜p14 →˜p1
Rest 3
(9) R3 ⊢?
c ˜g
No(w6)
w6
λ0, λ4, λ8
(10) R3, w6, p4 ⊢?
c p3
Yes({p4, ˜p13})
ϕ3 = ˜p13 →˜p11
Rest 4
(11) R4 ⊢?
c ˜g
No(w7)
w7
λ4, λ5, λ6
(12) R4, w7, p2 ⊢?
c p3
No(w8)
w8
λ8
w7
λ8
(13) R4, w8, p0 ⊢?
c ⊥
No(w9)
w9
∅
CountSat
w8
∅
w7
∅
p4, ˜p1,
˜p8, ˜p10, ˜p14
p2, p4, ˜p1,
˜p8, ˜p10, ˜p14
p0, p2, p4, ˜p1,
˜p8, ˜p10, ˜p14, ˜g
w9
w8
w7
K({w7, w8, w9})
∅
p0, p3, ˜p2,
˜p7, ˜p11, ˜p13, ˜g
p0, p4, ˜p1,
˜p8, ˜p10, ˜p14, ˜g
p2, p4, ˜p1,
˜p8, ˜p10, ˜p14
p0, p1, p3, ˜p2,
˜p7, ˜p11, ˜p13, ˜g
p0, p2, p4, ˜p1,
˜p8, ˜p10, ˜p14, ˜g
Generated by our implementation of intuit
Fig. 5. Computation of proveR(R0,X,˜g), see Ex. 2.
226
C. Fiorentini

1 procedure prove(R, X, g)
2
// Same Input Ass. and Output Prop. as for intuitR (Fig. 3)
3
s ←newSolver(R);
τ ←prAux(X, ∅, g)
4
if τ = Yes(∅) then return Valid else return CountSat
5
procedure prAux( ˜
X, ˜A, q)
6
// Output: Yes(A) or No(M), where A ⊆˜A and M ⊆˜A
7
τ0 ←satProve(s, ˜A, q)
8
if τ0 = Yes(A) then return Yes(A)
9
else
// τ0 = No(M)
10
for λ = (a →b) →c ∈X s.t. a ̸∈M and b ̸∈M and c ̸∈M do
11
τ1 ←prAux( ˜
X \ {λ}, M ∪{a}, b)
12
if τ1 = Yes(A) then
13
ϕ ←(A \ {a}) →c;
addClause(s, ϕ)
14
return prAux( ˜
X, ˜A, q)
15
return No(M)
16 end
Fig. 6. The prove procedure of intuit [2,10].
We proceed as in Ex. 1. The clausiﬁcation procedure yields (R0, X, ˜g), where X
consists of the implication clauses λ0, . . . , λ8 in Fig. 5 and the set R0 contains
the 24 ﬂat clauses below:
p0 →˜g, p1 →˜p2, p1 →˜p13, p2 →˜p1, p2 →˜p8, p3 →˜p7, p3 →˜p11, p4 →˜p10, p4 →˜p14,
˜p0 →˜p5, ˜p3 →p3, ˜p3 →p4, ˜p4 →p2, ˜p4 →˜p3, ˜p5 →p1, ˜p5 →˜p4, ˜p6 →˜p5, ˜p9 →˜p5
˜p1 ∧˜p2 →˜p0, ˜p7 ∧˜p8 →˜p6, ˜p10 ∧˜p11 →˜p9, ˜p13 ∧˜p14 →˜p12, ˜p12 →˜p5, γ →˜g.
The execution of proveR(R0,X,˜g) (see Fig. 5) requires 14 calls to the SAT-
solver and 4 restarts. After the last call we get W = {w7, w8, w9} and wk ▷W X
for every wk ∈W, thus the computation ends yielding CountSat. The model
K(W), depicted at the bottom left of the ﬁgure, is a countermodel for R0, X ⇒˜g
and for ψ (see Sec. 2).
♦
5
Related Work and Experimental Results
We compare the procedure proveR of intuitR with its intuit counterpart,
namely the procedure prove deﬁned in Fig. 6. Here we comply with the pre-
sentation in [10], equivalent to the original one in [2]. The recursive auxiliary
function prAux plays the role of the main loop of proveR (but in proveR the set
of atoms ˜A is not used); the loop inside prAux corresponds to the inner loop of
proveR. 4 We point out some major diﬀerences. Firstly, in prAux the interpre-
tations M computed by the SAT-solver are not collected; in the loop, only the
interpretation M computed at line 8 is considered, thus at the beginning of each
4 Actually intuit implements a variant of prAux where as much as possible clauses
ϕ are added to the solver.
Eﬃcient SAT-based Proof Search in Intuitionistic Propositional Logic
227

R ⊢c q
cpl0
R, X ⇒q
R1, b →c, X, A ⇒b
R2, ϕ, X, (a →b) →c ⇒q
ljt
R1, R2, X, (a →b) →c ⇒q
R1, X1 ⊢i ϕ
ϕ, R2, X2 ⇒q
cut
R1, R2, X1, X2 ⇒q
A ⊆V , q ∈V ∪{⊥}
ϕ = (A \ {a}) →c
Fig. 7. The calculus LJTSAT.
iteration just the “local” conditions of the test M⋫W λ are checked (line 10).
Secondly, the call satProve(s, w ∪{a}, b) to the SAT-solver at Step (S5) is
replaced by the recursive call prAux( ˜X \ {λ}, M ∪{a}, b) at line 11; as a
consequence, we cannot build derivations by applying rule cpl1. As thoroughly
discussed in [10], the calculus underlying intuit is the sequent calculus LJTSAT
in Fig. 7, obtained from C→by replacing the rule cpl1 with the more general
rule ljt and introducing a cut rule. Rule ljt can be seen as a generalization of
Dyckhoﬀ’s implication-left rule from the calculus LJT (alias G4ip) [3,14]. We re-
mark that a C→-derivation is isomorphic to a cut-free LJTSAT-derivation where,
in every application of rule ljt, the left-premise has a trivial proof (just apply
rule cpl0). In [10] it is shown how countermodels and LJTSAT-derivations can
be extracted from prove computations. In brief, countermodels are obtained by
considering some of the interpretations coming from No( ) answers; countermod-
els are in general bigger than the ones built by proveR, where at each restart
the model is emptied. As an example, let σ0 = R0, X ⇒˜g be deﬁned as in
Ex. 2; the computation of prove(R0,X,˜g) requires 31 calls to the SAT-solver
(24 No( ) answers) and the computed countermodel for σ0 has 6 worlds (see
Fig. 5); instead, proveR(R0,X,˜g) requires 14 calls and the countermodel has 3
worlds. Derivation extraction presents some awkward aspects. The key insight
is that, for every recursive call prAux( ˜X, ˜A,q) occurring in the computation of
prove(R,X,g), if prAux( ˜X, ˜A,q) returns Yes(A) (where A ⊆˜A), then we can
build an LJTSAT-derivation of a sequent R, R′, A, ˜X ⇒q, where R′ contains some
of the clauses added to the SAT-solver. The derivation is built either by applying
the rule cpl0 if prAux ends at line 8, or else by applying rule ljt, exploiting the
derivations obtained by the recursive calls at lines 11 and 14. Accordingly, the
main call prove(R,X,g) yields a derivation of R, R′, X ⇒g. The crucial point
is that the redundant clauses ϕ in R′ satisfy R, X ⊢i ϕ (this ultimately follows
by property (a) in Sec. 3), thus we can eliminate them by applying the cut rule.
Example 3. Let σ0 = R0, X ⇒˜g be deﬁned as in Ex. 1; prove(R0,X,˜g) yields
the LJTSAT-derivation D0 of R2, ϕ4, X ⇒˜g in Fig. 8. By applying the cut rule
three times, we get an LJTSAT-derivation of σ0. We stress that the C→-derivation
of σ0 obtained with intuitR (see Fig. 4) has a simpler structure.
⊓⊔
Finally, we remark that the clauses ϕ computed in prAux do not enjoy prop-
erty (P2) (Sec. 4); we have experimented cases where such clauses are even
duplicated (e.g., with formulas from class SYJ205 of ILTP library).
228
C. Fiorentini

R0, p2, ˜p6 ⊢c p1
R0, X{0,3}, p2, ˜p6 ⇒p1
R1, p1, ˜p10 ⊢c p2
R1, X{0,5}, p1, ˜p10 ⇒p2
R2, p3 ⊢c p2
R2, X{0}, p3 ⇒p2
λ5
R1, X{0}, p3 ⇒p2
λ3 = (p2 →p1) →˜p2
ˆσ = R0, X{0}, p3 ⇒p2
...
shown
above
...
ˆσ
R3, p3 ⊢c p1
R3, X{1}, p3 ⇒p1
R4, p1, ˜p1 ⊢c p3
R4, X{2,4}, p1, ˜p1 ⇒p3
R5, p2 ⊢c p3
R5, X{2}, p2 ⇒p3
λ4
R4, X{2}, p2 ⇒p3
R6 ⊢c ˜g
R6, X ⇒˜g
λ2
R5, X ⇒˜g
λ1 = (p3 →p1) →˜p9
R3, ϕ4, X ⇒˜g
λ0 = (p3 →p2) →˜p7
R2, ϕ4, X ⇒˜g
λ2 = (p2 →p3) →˜p6
λ4 = (p1 →p3) →˜p10
λ5 = (p1 →p2) →˜p1
ϕ0 = ˜p6 →˜p2
ϕ1 = ˜p10 →˜p1
ϕ2 = ˜p7
ϕ3 = ˜p9
ϕ4 = ˜p1 →˜p10
ϕ5 = ˜p6
XI = X \ { λk | k ∈I }
Rk+1 = Rk ∪{ϕk}
Fig. 8. Derivation D0 of R2, ϕ4, X ⇒˜g in LJTSAT (see Ex. 3).
Experimental results We have implemented intuitR in Haskell on the top of
intuit: we have replaced the function prove with proveR and added some fea-
tures (e.g., trace of computations, construction of derivations/countermodels);
as in intuit, we exploit the module MiniSat, a Haskell bundle of the MiniSat
SAT-solver [4] (but in principle we can use any incremental SAT-solver). We
compare intuitR with intuit and with two of the state-of-the-art provers for
IPL by replicating the experiments in [2]. The ﬁrst prover is fCube [5]; it is based
on a standard tableaux calculus and exploits a variety of simpliﬁcation rules [6]
that can signiﬁcantly reduce branching and backtracking. The second prover is
intHistGC [11]; it relies on a sequent calculus with histories and uses dependency
directed backtracking for global caching to restrict the search space; we run it
with its best ﬂags (-b -c -c3). All tests were conducted on a machine with
an Intel i7-8700 CPU@3.20GHz and 16GB memory. We considered the bench-
marks provided with intuit implementation, including the ILTP library, the
intHistGC benchmarks and the API problems introduced by intuit developers.
This amounts to a total of 1200 problems, 498 Valid and 702 CountSat; we used
a 600s (seconds) timeout. Fig. 9 reports the more signiﬁcant results, among which
the classes where at least a prover fails and the classes where intuitR performs
poorly. In all the tests, the time required by clausiﬁcation is negligible. Even
though no optimized data structure has been implemented, intuitR solve more
problems than its competitors; in families SYJ201 (Valid formulas) and SYJ207
(CountSat formulas) intuitR outperforms its rivals, in all the other cases, except
the families EC, negEC and portia, intuitR is comparable to the best prover
(which is intuit in most cases). The most remarkable improvement with respect
to intuit occurs with class SYJ212 (see Fig. 10), where intuit timings are ﬂuc-
Eﬃcient SAT-based Proof Search in Intuitionistic Propositional Logic
229

Class (number of
intuitR
intuit
fCube
intHistGC
problems)
SYJ201(50)
50 (2.259)
50 (11.494)
50 (259.776)
50 (39.466)
SYJ202(38)
10⋆(49.265)
10⋆(50.658)
9⋆(176.984)
6⋆(324.673)
SYJ203(50)
50 (0.250)
50 (0.335)
50 (1.671)
50 (0.293)
SYJ204(50)
50 (0.442)
50 (0.477)
50 (0.972)
50 (0.203)
SYJ205(50)
50 (0.500)
50 (0.730)
50 (1.317)
50 (4.129)
SYJ206(50)
50 (0.303)
50 (0.348)
50 (0.759)
50 (0.112)
SYJ207(50)
50 (2.291)
50 (109.919)
50 (138.546)
50 (1014.476)
SYJ208(38)
38 (5.225)
38 (5.479)
29⋆(2.755)
38 (497.715)
SYJ209(50)
50 (0.226)
50 (0.278)
50 (1.690)
50 (0.254)
SYJ210(50)
50 (0.272)
50 (0.252)
50 (0.988)
50 (0.288)
SYJ211(50)
50 (0.462)
50 (1.251)
50 (1.073)
50 (63.686)
SYJ212(50)
50 (0.669)
42⋆(587.794)
50 (2.698)
50 (1.624)
EC(100)
100 (2.738)
100 (0.821)
100 (6.183)
100 (0.651)
negEC(100)
100 (3.614)
100 (1.116)
100 (13.733)
100 (5.807)
cross(4)
4 (0.100)
4 (0.097)
4 (3.417)
2⋆(0.005)
jm cross(4)
4 (0.120)
4 (0.090)
4 (5.404)
3⋆(4.324)
jm lift(3)
3 (0.170)
3 (0.133)
3 (6.847)
2⋆(0.028)
lift(3)
3 (0.119)
3 (0.102)
3 (6.494)
2⋆(0.012)
mapf(4)
4 (0.187)
4 (0.400)
4 (446.921)
3⋆(0.043)
portia(100)
100 (32.878)
100 (22.596)
100 (3255.818) 100 (3200.135)
negportia(100)
100 (7.956)
100 (8.309)
98⋆(3826.011) 100 (28.289)
negportiav2(100)
100 (8.081)
100 (8.411)
98⋆(1264.103) 100 (3212.293)
nishimura2(28)
28 (9.784)
28 (12.285)
27⋆(141.326)
28 (7.616)
Unsolved
28
36
43
38
Fig. 9. For each prover, we report the number of solved problems within 600s timeout
and between brackets the total time in seconds required for the solved problems. The
best prover is highlighted, a star reports that there are some unsolved problems.
tuating. To give a close comparison, let us consider the case k = 25; clausiﬁcation
produces 246 ﬂat clauses and 100 implications clauses (176 atoms). Our intuit
implementation requires 11214 calls to the SAT-solvers (10181 No( )) and the
computed countermodel has 1955 worlds. Instead, intuitR requires 45 calls to
the SAT-solvers, 8 restarts and yields a countermodel consisting of 4 worlds; the
set W contains 26 worlds before the ﬁrst restart, one world before the remaining
ones. With all the benchmarks the models generated during the computation are
small (typically, big models occur before the ﬁrst restart); however, diﬀerently
from [7,8,9], we cannot guarantee that countermodels have minimum depth or
minimum number of worlds. To complete the picture, the scatter plot in Fig. 11
compares intuitR and intuit on all the benchmarks.
230
C. Fiorentini

k
intuitR
intuit
1 .. 24 < 0.01
< 0.1
25
0.007
0.691
26
0.007
25.064
27
0.007
0.020
28
0.008
0.083
29
0.009
8.412
30
0.008
-
Problem k:
k
intuitR
intuit
31
0.007
8.724
32
0.007
4.216
33
0.012
0.034
34
0.010
2.445
35
0.033
77.226
36
0.018
0.038
37
0.016
22.445
38
0.017
-
k
intuitR
intuit
39
0.020
0.404
40
0.016
0.838
41
0.027
-
42
0.020
0.785
43
0.036
435.324
44
0.026
0.098
45
0.070
0.639
46 .. 50
≤0.07
-
(. . . ((¬¬p1 ↔p2) ↔p3) ↔. . . ↔pk) ↔(. . . ((p1 ↔p2) ↔p3) ↔. . . ↔pk)
¬α := α →⊥
Fig. 10. Timings for problems k = 1..50 of SYJ212 (CountSat), - means timeout (600s).
10−3 10−2 10−1 100
101
102
10−3
10−2
10−1
100
101
102
intuitR (Valid, 498 tests)
intuit
10−3 10−2 10−1 100
101
102
10−3
10−2
10−1
100
101
102
intuitR (CountSat, 674 tests)
intuit
Fig. 11. Comparison between intuitR and intuit (1172 problems, the 28 problems
where both provers run out of time have been omitted); time axis are logarithmic, the
8 red squares indicates that intuit has exceeded the timeout.
To conclude, we point out that intuitR can be extended to deal with some
superintuitionistic logics [1]. For instance, let us consider the G¨oedel-Dummett
logic GL, characterized by linear models; at any step of the computation of
proveR, the model K(W) must be kept linear. Whenever the insertion of a new
world to W breaks linearity, we follow a “restart with learning” strategy [12]: let
γ = (a →b) ∨(b →a) be the instance of the GL-axiom falsiﬁed at the root of
K(W); we restart by taking γ as “learned axiom”, so to avoid the repetition of
the ﬂaw. However, we cannot add γ to the SAT-solver, because γ is not a clause,
but the clausiﬁcation of γ, namely the clauses ˜q1 ∨˜q2, ˜q1 ∧a →b, ˜q2 ∧b →a,
where ˜q1 and ˜q2 are fresh atoms; despite the language of the SAT-solver must
be extended, the process converges. The other generalizations suggested in [2]
(modal logics, fragments of ﬁrst-order logic) seem to be more challenging.
Acknowledgments. I am grateful to the reviewers for their valuable sugges-
tions. This work has been funded by the INdAM-GNCS project 2020 “Estensioni
del Property-based Testing di e con linguaggi di programmazione dichiarativa”.
Eﬃcient SAT-based Proof Search in Intuitionistic Propositional Logic
231

References
1. Chagrov, A.V., Zakharyaschev, M.: Modal Logic, Oxford logic guides, vol. 35.
Oxford University Press (1997)
2. Claessen, K., Ros´en, D.: SAT Modulo Intuitionistic Implications. In: Davis,
M., Fehnker, A., McIver, A., Voronkov, A. (eds.) Logic for Programming, Ar-
tiﬁcial Intelligence, and Reasoning - 20th International Conference, LPAR-20
2015, Suva, Fiji, November 24-28, 2015, Proceedings. Lecture Notes in Com-
puter Science, vol. 9450, pp. 622–637. Springer (2015), https://doi.org/10.1007/
978-3-662-48899-7_43
3. Dyckhoﬀ, R.: Contraction-free sequent calculi for intuitionistic logic. J. Symb. Log.
57(3), 795–807 (1992), https://doi.org/10.2307/2275431
4. E´en, N., S¨orensson, N.: An Extensible SAT-solver. In: Giunchiglia, E., Tacchella,
A. (eds.) Theory and Applications of Satisﬁability Testing, 6th International Con-
ference, SAT 2003. Santa Margherita Ligure, Italy, May 5-8, 2003 Selected Re-
vised Papers. Lecture Notes in Computer Science, vol. 2919, pp. 502–518. Springer
(2003), https://doi.org/10.1007/978-3-540-24605-3_37
5. Ferrari, M., Fiorentini, C., Fiorino, G.: fCube: An Eﬃcient Prover for Intu-
itionistic Propositional Logic. In: Ferm¨uller, C.G., Voronkov, A. (eds.) Logic for
Programming, Artiﬁcial Intelligence, and Reasoning - 17th International Confer-
ence, LPAR-17, Yogyakarta, Indonesia, October 10-15, 2010. Proceedings. Lec-
ture Notes in Computer Science, vol. 6397, pp. 294–301. Springer (2010), https:
//doi.org/10.1007/978-3-642-16242-8_21
6. Ferrari, M., Fiorentini, C., Fiorino, G.: Simpliﬁcation Rules for Intuitionistic
Propositional Tableaux. ACM Trans. Comput. Log. 13(2), 14:1–14:23 (2012),
https://doi.org/10.1145/2159531.2159536
7. Ferrari, M., Fiorentini, C., Fiorino, G.: Contraction-Free Linear Depth Sequent
Calculi for Intuitionistic Propositional Logic with the Subformula Property and
Minimal Depth Counter-Models. J. Autom. Reason. 51(2), 129–149 (2013), https:
//doi.org/10.1007/s10817-012-9252-7
8. Fiorentini, C.: An ASP Approach to Generate Minimal Countermodels in Intuition-
istic Propositional Logic. In: Kraus, S. (ed.) Proceedings of the Twenty-Eighth In-
ternational Joint Conference on Artiﬁcial Intelligence, IJCAI 2019, Macao, China,
August 10-16, 2019. pp. 1675–1681. ijcai.org (2019), https://doi.org/10.24963/
ijcai.2019/232
9. Fiorentini, C., Ferrari, M.: Duality between unprovability and provability in for-
ward refutation-search for intuitionistic propositional logic. ACM Trans. Comput.
Log. 21(3), 22:1–22:47 (2020), https://doi.org/10.1145/3372299
10. Fiorentini, C., Gor´e, R., Graham-Lengrand, S.: A Proof-Theoretic Perspective on
SMT-Solving for Intuitionistic Propositional Logic. In: Cerrito, S., Popescu, A.
(eds.) Automated Reasoning with Analytic Tableaux and Related Methods - 28th
International Conference, TABLEAUX 2019, London, UK, September 3-5, 2019,
Proceedings. Lecture Notes in Computer Science, vol. 11714, pp. 111–129. Springer
(2019), https://doi.org/10.1007/978-3-030-29026-9_7
11. Gor´e, R., Thomson, J., Wu, J.: A History-Based Theorem Prover for Intuition-
istic Propositional Logic Using Global Caching: IntHistGC System Description.
In: Demri, S., Kapur, D., Weidenbach, C. (eds.) Automated Reasoning - 7th
International Joint Conference, IJCAR 2014, Held as Part of the Vienna Sum-
mer of Logic, VSL 2014, Vienna, Austria, July 19-22, 2014. Proceedings. Lec-
ture Notes in Computer Science, vol. 8562, pp. 262–268. Springer (2014), https:
//doi.org/10.1007/978-3-319-08587-6_19
232
C. Fiorentini

12. Nieuwenhuis, R., Oliveras, A., Tinelli, C.: Solving SAT and SAT Modulo Theories:
From an abstract Davis–Putnam–Logemann–Loveland procedure to DPLL(T). J.
ACM 53(6), 937–977 (2006), https://doi.org/10.1145/1217856.1217859
13. Raths, T., Otten, J., Kreitz, C.: The ILTP problem library for intuitionistic
logic. J. Autom. Reason. 38(1-3), 261–271 (2007), https://doi.org/10.1007/
s10817-006-9060-z
14. Troelstra, A.S., Schwichtenberg, H.: Basic proof theory, Second Edition, Cambridge
tracts in theoretical computer science, vol. 43. Cambridge University Press (2000)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/
4.0/), which permits use, sharing, adaptation, distribution and reproduction in any
medium or format, as long as you give appropriate credit to the original author(s) and
the source, provide a link to the Creative Commons license and indicate if changes
were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.
Eﬃcient SAT-based Proof Search in Intuitionistic Propositional Logic
233

Proof Search and Certiﬁcates for
Evidential Transactions
1 Huawei Munich Research Center, Munich, Germany vivek.nigam@gmail.com
srahmoun@andrew.cmu.edu
3 fortiss GmbH, Munich, Germany ruess@fortiss.org
Abstract. Attestation logics have been used for specifying systems with
policies involving diﬀerent principals. Cyberlogic is an attestation logic
used for the speciﬁcation of Evidential Transactions (ETs). In such trans-
actions, evidence has to be provided supporting its validity with respect
to given policies. For example, visa applicants may be required to demon-
strate that they have suﬃcient funds to visit a foreign country. Such ev-
idence can be expressed as a Cyberlogic proof, possibly combined with
non-logical data (e.g., a digitally signed document). A key issue is how
to construct and communicate such evidence/proofs. It turns out that
attestation modalities are challenging to use established proof-theoretic
methods such as focusing. Our ﬁrst contribution is the reﬁnement of Cy-
berlogic proof theory with knowledge operators which can be used to
represent knowledge bases local to one or more principals. Our second
contribution is the identiﬁcation of an executable fragment of Cyberlogic,
called Cyberlogic programs, enabling the speciﬁcation of ETs. Our third
contribution is a sound and complete proof system for Cyberlogic pro-
grams enabling proof search similar to search in logic programming. Our
ﬁnal contribution is a proof certiﬁcate format for Cyberlogic programs
inspired by Foundational Proof Certiﬁcates as a means to communicate
evidence and check its validity.
Keywords: Attestation Logics · Proof Search · Sequent Calculus
1
Introduction
Attestation logics [1,14,21,15,6,5,29] have been used for the speciﬁcation of poli-
cies of distributed systems, such as access control systems [1], distributed autho-
rization policies [14,21], and evidential transactions (ETs) [15,5,6,6,29]. In these
logics, one speciﬁes policies involving attestation formulas of the form K :▷F,
where K is a principal (or agent) in the system.
Cyberlogic is an attestation logic for ETs. In Cyberlogic, cryptographic keys
K are identiﬁed with speciﬁc authorities, and attestations K :▷A express the
fact that principal K attests to statement A. For example, K may be a visa-
granting authority and A the statement that the visa requester is authorized
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5 14
Vivek Nigam1
, Giselle Reis2
, Samar Rahmouni2
, and Harald Ruess3
2 Carnegie Mellon University, Ar-Rayyan, Qatar giselle@cmu.edu,
234–251, 2021.

Proof Search and Certiﬁcates for Evidential Transactions
235
to enter the speciﬁed country by the end of the year and at most once. An
evidential transaction might issue a visa given that proof of suﬃcient funds has
been provided in the form of a digital certiﬁcate whose validity can then be
veriﬁed by customs authorities upon entry.
Formally, evidence in ETs can be expressed as a Cyberlogic proof. To carry
out an ET, a Cyberlogic proof demonstrating policy compliance shall be pro-
duced and communicated. ETs therefore enable trust in, for example, distributed
exchanges in electronic commerce, by enabling the exchange of various forms of
veriﬁable evidence, such as evidence of funds in the visa example above.
The problem of producing attestation logic proofs (and proof objects) has
not been given enough attention so far. Attestation logics have been formalized
as Hilbert-style proof systems [1,15] that do not have the sub-formula property
and therefore are not suitable for proof search. Other works on authorization
logics [14,21] have proposed sequent calculi which do possess the sub-formula
property. However, the search space is too great to enable eﬃcient proof search.
The established proof-theoretic method for proof search is focusing [3,18]. Fo-
cusing distinguishes between inference rules that have “don’t know” and “don’t
care” non-determinism to prune the proof search space. Interestingly, focused
proof systems [7,18] provide a proof-theoretical justiﬁcation for backward and
forward-chaining, two proof-search strategies for Horn clauses (logic programs).
Such justiﬁcation, however, breaks when programs contain modalities, such as at-
testation modalities, i.e., formulas of the form K :▷F. This is because focusing is
lost whenever any of these formulas is encountered and therefore, improvements
to the search space because of focusing is not so signiﬁcant for attestation logics.
Our main goal is the study of Cyberlogic’s proof theory in order to enable
proof search (similar to the search involved in logic programming) and the gen-
eration of proof certiﬁcates for the communication of evidence in ETs.
Our ﬁrst contribution, detailed in Section 2, is a Gentzen style proof system
for Cyberlogic that admits cut elimination. A feature of the proof system is that
it enables the combination of evidence represented as logical derivations as well as
digital evidence, e.g., signed hashes of documents, ﬁnancial statements, medical
records. The logic also includes a knowledge operator for sets of principals.
Our second contribution, detailed in Section 3, is the identiﬁcation of a frag-
ment of Cyberlogic, called Cyberlogic programs, akin to Horn clauses used in
logic programming. This is motivated by the ongoing work on building dis-
tributed logic programming engines for ETs which extend existing engines [10]
with attestations of the form K :▷A.
Our third contribution, also detailed in Section 3, addresses the challenge of
how to eﬃciently construct Cyberlogic program proofs. We propose a focused
inspired proof system for Cyberlogic programs and prove that it is sound and
complete in this fragment. This system enables more eﬃcient proof search.
Our last contribution, detailed in Section 4, addresses the challenge of how to
eﬃciently communicate evidence. We propose a proof certiﬁcate format for Cy-
berlogic programs inspired by Foundational Proof Certiﬁcates (FPCs) [9]. FPCs
enable the reconstruction of proofs by using simple logic programs as guides. This

236
Nigam et al.
Γ, A −→A init
evidenceKA
Γ −→K :▷A ext
Γ −→⊤⊤r
Γ, ⊥−→C ⊥l
Γ, F1, F2 −→G
Γ, F1 ∧F2 −→G ∧l
Γ −→F1
Γ −→F2
Γ −→F1 ∧F2
∧r
Γ, F1 −→G
Γ, F2 −→G
Γ, F1 ∨F2 −→G
∨l
Γ −→Fi
Γ −→F1 ∧F2
∨ri
Γ, F1 ⊃F2 −→F1
Γ, F2 −→G
Γ, F1 ⊃F2 −→G
⊃l
Γ, F1 −→F2
Γ −→F1 ⊃F2 ⊃r
Γ, ∀x.F, F[t/x] −→G
Γ, ∀x.F −→G
∀l
Γ −→F[α/x]
Γ −→∀x.F
∀r
Γ, F[α/x] −→G
Γ, ∃x.F −→G
∃l
Γ −→F[t/x]
Γ −→∃x.F
∃r
Γ, F −→K :▷G
Γ, K :▷F −→K :▷G :▷l
Γ −→F
Γ −→K :▷F :▷r Γ, kbQF, F −→G
Γ, kbQF −→G
kbl
Γ |Q−→F
Γ −→kbQF kbr
Fig. 1. CLK – Cyberlogic proof system for K = {K1, . . . , Kn}. Here A is an atomic
formula, Q ⊆K, and Γ |Q= {kbQ′F | kbQ′F ∈Γ ∧Q′ ⊆Q}. Moreover, in rules ∃L
and ∀R, α is a fresh constant not appearing in Γ nor F.
means that such certiﬁcates can elide parts that can be easily reconstructed or
which one is willing to reconstruct.
2
Cyberlogic Proof Theory
Cyberlogic [29] is an intuitionistic modal logic which can be used for specifying
ETs. The logic is parametrized by a ﬁnite set of principals K = {K1, . . . , Kn},
which are used in formulas as follows:
– Ki :▷F: meaning that principal Ki attests the (Cyberlogic) formula F;
– kbQF, where Q ⊆K: meaning that all principals in Q know F, or, alterna-
tively, that the combined knowledge of principals in Q imply F; and
– evidenceKiA: standing for an external evidence signed by principal Ki.
External evidences are left unspeciﬁed since they fall outside the logical scope
and depend on the ET being formalized. For example, evidenceKiA could be
signed hashes of tickets, ﬁnancial statments, medical records, etc. In Cyberlogic
the evidence associated with an ET is a combination of a formal proof (in sequent
calculus) and a collection of external evidences.
Cyberlogic formulas are constructed according to the following grammar:
F, G ::= A | F ∧G | F ∨G | F ⊃G | ⊤| ⊥| K :▷F | kbQF | ∀x.F | ∃x.F
where A is an atom, K ∈K, and Q ⊆K. The formula K :▷F is read as “principal
K attests F” and acts like the says modality in lax logics [13,27]. The formula
kbQF is read as “principals in Q know F” and is inspired by the knows modality
used in linear authorization logics [14,21]. Diﬀerent from that logic, Cyberlogic
allows the direct speciﬁcation of knowledge shared by multiple principals, as
illustrated in Example 1.
Cyberlogic sequents are of the shape Γ −→G, where Γ is a multiset of
formulas. The Cyberlogic proof system, CLK, is depicted in Figure 1. Rules for

Proof Search and Certiﬁcates for Evidential Transactions
237
the intuitionistic connectives ∧, ∨, ⊃, ∀, ∃are as in LJ [30]. The new rules are
the ones involving assertions K :▷F and kbQ. Note that a “built-in” contraction
of the main formula is needed on the left premise of ⊃l and the premise of ∀l, as
expected in intuitionistic logics. Also, the rule kbl has an explicit contraction on
the premise. These contractions are needed for cut admissibility (Theorem 2).
Rules :▷l and :▷r specify that :▷is a lax modality [27,21,24]. The intuition
behind :▷l is: if an assertion G of a principal K is provable using F, then it
is also provable if K attests F. Rule :▷r speciﬁes that principals are rational,
i.e., they can always attest formulas that are derivable. Diﬀerently from existing
systems with lax modalities, CLK has the rule ext. This rule allows a proof of
an attestation K :▷A to be completed whenever a principal provides evidence
evidenceKA for the claim A. This formalizes the intuition that principals may use
digital evidence signed by their private key. We leave the deﬁnition of evidence
unspeciﬁed as it depends on the intended ET speciﬁed.
Rules kbl and kbr reﬁne Cyberlogic by enabling the collection of logical the-
ories known by a set of principals. Such theories act as knowledge bases. Rule kbl
speciﬁes that any common knowledge can be part of a knowledge base. The in-
teresting rule is kbr, which speciﬁes that kbQF can only be proved using the local
knowledge or evidence provided by principals in Q. This is formally captured by
restricting Γ in kbr’s premise to the set Γ |Q= {kbQ′F | kbQ′F ∈Γ ∧Q′ ⊆Q}.
This is a powerful construct that increases the expressiveness of Cyberlogic. In
particular, it is straightforward to specify that certain assertions can be con-
cluded from the shared knowledge of a set of principals.
Proposition 1. The following sequents are provable in CLK for all K ∈K and
formulas F1, F2. F1 ≡F2 represents the sequents (F1 −→F2) and (F2 −→F1):
1. F −→K :▷F
2. kbQF −→F
3. kb{K}F −→K :▷F
4. K :▷K :▷F ≡K :▷F
5. kbQ′F −→kbQF, if Q′ ⊆Q. In par-
ticular, kbQ1kbQ2F −→kbQ1∪Q2F.
6. kbQ1F ∧kbQ2F −→kbQ1∪Q2F
7. K :▷(F1 ∧F2) ≡K :▷F1 ∧K :▷F2
8. kbQ(F1 ∧F2) ≡kbQF1 ∧kbQF2
9. (K :▷F1 ∨K :▷F2) −→K :▷(F1 ∨F2)
10. kbQA ∨kbQB −→kbQ(A ∨B)
11. K :▷(F1 ⊃F2)−→(K :▷F1 ⊃K :▷F2)
12. kbQ(F1 ⊃F2) −→(kbQF1 ⊃K :▷F2)
13. K :▷(∇x.F) ≡∇x.K :▷F, ∇∈{∀, ∃}
14. kbQ(∇x.F) ≡∇x.kbQF, ∇∈{∀, ∃}
Moreover, the following sequents are not provable if K1 ̸= K2 and Q1 ̸= Q2:
1. K :▷F
̸−→F
2. F
̸−→kbQF
3. K :▷F
̸−→kb{K}F
4. K1 :▷(K2 :▷F) ̸−→K2 :▷(K1 :▷F)
5. kbQ1(kbQ2F) ̸−→kbQ2(kbQ1F)
6. kbQ1∪Q2F
̸−→kbQiF, i ∈{1, 2}
7. kbQ1∪Q2F
̸−→kbQ1F ∧kbQ2F
8. kbQK :▷A ̸−→K :▷kbQA
9. K :▷kbQA ̸−→kbQK :▷A
In the remainder of the paper, we elide the set of principals K whenever it
can be deduced from the context.

238
Nigam et al.
Example 1. (Shared Knowledge) The ability to use kb with multiple princi-
pals allows the derivation of facts that depend on the combination of knowledge
of multiple principals. Consider that principal K1 knows A and B ⊃C, and
principal K2 knows A ⊃B, then the following sequent is provable in CL:
kb{K1}A, kb{K1}B ⊃C, kb{K2}A ⊃B −→kb{K1,K2}C
Remark 1. The original Cyberlogic paper [5] (and technical report [4]) proposed
two kinds of attestations, :▷and ▷, to distinguish when an attestation is derived
from a digital evidence or logical inferences. This combination, however, does not
yield to a proof system with the cut-elimination property [28].
The meta-theory of CL has been analysed using the L-framework [25], which
uses rewriting logic to automatically derive structural proofs of sequent calculi
properties [26]. The following lemma was used in the proofs of cut-elimination
and invertibility.
Lemma 1. If Γ, K :▷F −→G, then Γ, F −→G.
The proof proceeds by structural induction on the derivation of Γ, K :▷F −→
G. The proof has been mechanically checked using the the L-framework with
some few cases proved by hand.
As expected, ⊃r, ∧r, ∧l, ∨l, ∀r, ∃l are invertible whereas ∨r, ⊃l, ∀l, ∃r are not
invertible. In addition, the rules :▷l and kbl are invertible whereas the :▷r and
kbr are not invertible.
Lemma 2. If Γ, K :▷F −→K :▷G then Γ, F −→K :▷G.
This is a simple corollary of Lemma 1. Invertibility of kbl is straighforward
because of the contraction of the main formula.
Rules :▷r and kbr are not invertible. The counter examples are:
[ :▷r]
K :▷a −→K :▷a but K :▷a ̸−→a
[kbr]
a, a ⊃kbKb −→kbKb but
̸−→b
Weakening is height perserving admissible in CL.
Theorem 1 (Identity expansion). F −→F is provable in CL for any cyber-
logic formula F.
The proof is by structural induction on F.
Theorem 2 (Cut elimination). If Γ −→F and Γ, F −→C, then Γ −→C.
The proof proceeds by a nested induction on the structure of the proofs of
Γ −→F and Γ, F −→C, and the formula F. The noteworthy cases are the
ones where cut needs to permute over kb rules. For kbl, contraction of the main
formula is needed, and the permutation over kbr can be done only if cut is
principal on the left (which is a lemma that can be proved). Details about these
transformations are in Appendix A.

Proof Search and Certiﬁcates for Evidential Transactions
239
3
Cyberlogic Programs
Cyberlogic programs are fragment of CL which resembles Horn clauses in logic
programming. Section 3.2 proposes a proof search operational semantics for cy-
berlogic programs and proves its soundness and completeness. The proof search
discipline relies on ideas from focusing [3]. Focused proof systems for LJ [18] pro-
vide a proof theoretical justiﬁcation of forward and backward chaining search.
Each technique is enforced by the choice of polarity of atomic formulas: positive
atoms lead to forward chaining and negative atoms lead to backward chaining.
This correspondence, however, does not extend to cyberlogic due to attesta-
tion formulas K :▷A which cause focusing to be lost [21]. Consider the following
example where the formula under focus is in brackets:
K1 :▷a −→[K1 :▷a]
K1 :▷a, [K2 :▷b] −→K2 :▷b
K1 :▷a, [K1 :▷a ⊃K2 :▷b] −→K2 :▷b
⊃l
In focused proof systems, forward chaining can be enforced by disallowing focus
to be lost on the right formula in the left premise, i.e. [K1 :▷a]. However, if :▷r is
applied to this sequent the premise would be K1 :▷a −→a, which is not provable
(see Proposition 1). In fact, [K1 :▷a] must lose focus on the right for the proof
to be completed. Therefore, if :▷modalities are used in logic programs, other
strategies for proof search need to be analysed.
3.1
Cyberlogic Program Syntax
Cyberlogic programs can be divided into goals, knowledge bases, common knowl-
edge, and attestation clauses.
Goals (G) Cyberlogic programs are used to derive a goal G, deﬁned as:
G ::= ⊤| K :▷kbQA | G1 ∧G2 | ∃x.G
where A is an atomic formula. The restriction of :▷kbQ to atoms does not reduce
the expressiveness of goals, given the equivalences in Proposition 1.
Knowledge Bases (B): A knowledge base, written kb{Ki}Γ, of a principal Ki ∈K
is a set of formulas Γ not containing the connectives :▷or kb. Here, kb{Ki}Γ
represents the set of formulas {kb{Ki}F | F ∈Γ}.
Intuitively, a knowledge base kb{Ki}Γ can be interpreted as Ki’s local knowl-
edge. This means that Ki may use its own prover to derive new facts. For ex-
ample, if Γ is a collection of Horn-clauses, then Ki may deploy a Prolog engine
to derive some goal. Alternatively if Γ is a set of formulas in CNF form, then
Ki may use resolution provers. The absence of modal connectives in knowledge
bases has important impacts on the design of the proof certiﬁcate described in
Section 4, as those may rely on existing certiﬁcates for diﬀerent provers [9].

240
Nigam et al.
Common Knowledge (C): Common knowledge are knowledge bases that are
known to all principals, written as kb∅Γ. Since ∅⊆Q for every Q, these formulas
remain in the context when applying kbr. In this sense they contain ﬁrst order
formulas that may be used by all principals.
Attestation Formulas (D): Formulas of the form K :▷kbQA are derived by attes-
tation formulas of the form below where for all 1 ≤i ≤n, Ki ∈K, Qi ⊆K, and
A1, . . . , An, A are atomic formulas and ⃗X are bounded by universal quantiﬁers:
∀⃗X.

kbQ1(K1 :▷A1) ∧· · · ∧kbQn(Kn :▷An) ∧G ⊃K :▷(kb∅A)

∀⃗X.

kbQ1(K1 :▷A1) ∧· · · ∧kbQn(Kn :▷An) ∧G ⊃K :▷(kb{K}A)

Intuitively, an attestation formula belongs to a principal, namely K in the
right-hand side of ⊃. Such formulas derive K’s attestation of an atomic formula
which is its own knowledge (kb{K}A), or common knowledge (kb∅A). This means
that K’s attestation formulas cannot derive knowledge belonging to other prin-
cipals. Furthermore to derive an attestation, one can use the knowledge base
of other principals, i.e. the formulas kbQi(Ki :▷Ai) or additional goals, i.e. G.
Finally notice that K :▷(kb∅A) and K :▷(kb{K}A) are attestation formulas them-
selves, where the left-hand side of ⊃is empty (denoting ⊤).
The diﬀerence between formulas K :▷A and K :▷(kb{K}A) is subtle. Note that
the former can be derived using the evidence rule ext, while the latter cannot.
K :▷(kb{K}A) is K’s attestation that A follows from its local knowledge base.
It is possible to specify that A can be derived from an external evidence, but
this has to be made explicit by an attestation formula, e.g., kb{K}(K :▷A) ⊃
K :▷(kb{K}A). Note that this formula is not a tautology.
We are interested in proving goals from attestation formulas, knowledge
bases, and common knowledge, which are formally represented by cyberlogic
program sequents deﬁned as follows.
Deﬁnition 1 (Cyberlogic Program Sequents (CPS)). A cyberlogic pro-
gram sequent (CPS) is a sequent C, B, D −→G, where B is a set of knowledge
bases, C is a set of common knowledge formulas, D is a set of attestation for-
mulas, and G is a goal formula.
Example 2. (Local Computations) This example illustrates the use of kb to
specify when parts of a derivation can be proved locally using a principal’s
knowledge. Consider that the following clause
kb{K1}(K1 :▷F1) ∧kb{K2}(K2 :▷F2) ⊃K :▷kb{K}G
speciﬁes that for K to attest G, K1 and K2 have to attest F1 and F2 respectively,
using their own local theories, common knowledge, or evidence. This means that
computations carried out by K1 and K2 to derive their assertions K1 :▷F1 and
K2 :▷F2 respectively, do not depend on other principals and therefore, the search
for these derivations can be performed locally.

Proof Search and Certiﬁcates for Evidential Transactions
241
Example 3. (Levels of Trust) This example illustrates the use of kb to specify
that some evidence should only be trusted if derived from trusted sources. Con-
sider three principals K = {KT , KU, K} where K trusts evidence from KT , but
not all evidence from KU. Then the following clause
kb{K,KT }(K :▷critical(ok)) ∧kbK(K :▷nonCritical(ok)) ⊃K :▷kb∅(all(ok))
speciﬁes that K can attest that everything is ok as a common knowledge if all
the non-critical and critical elements are ok. However, the check of critical parts
can only be performed by principals K trusts, namely K itself or KT . Information
from KU’s knowledge bases cannot be used in the proof of critical(ok).
Example 4. (Simpliﬁed Visa) Consider a visa issuing scenario where an appli-
cant applies to a consulate (cons) for an entry visa. This is an example of an
ET as, to obtain the visa, evidence has to be provided that, for example, the
applicant has no crime records, or that they have suﬃcient funds. We illustrate
how such an ET can be speciﬁed in Cyberlogic.
The formula below labelled main speciﬁes conditions for a visa to be issued:
main: ∀Id.∀Doc.∀V.

kb{cons}(cons :▷visitOk(Id, Doc))
∧kb{cons}(cons :▷prepVisa(Id, V))
∧cons :▷kb{cons}(sufFin(Doc)) ∧police :▷kb{police}(noCrimeRec(Id))
⊃cons :▷kbcons(issVisa(Id, Doc, V))

The transaction for cons issuing a visa V to an applicant Id requires cons to attest
validity of Id’s visit by itself (visitOk(Id, Doc)) and Id’s criminal record with the
help of the police (noCrimeRec(Id)). In addition, cons also needs to attest Id’s
ﬁnancial status (sufFin(Doc)).
The following two clauses expand on how cons can attest sufFin(Doc): either
via an employment contract or a bank statement.
cont: kb{cons}

∀Doc.∀Cont.

empContract(Doc, Cont) ∧valid(Cont)
⊃sufFin(Doc)

bankStmt: ∀Doc.∀Stmt.

kb{cons}(cons :▷bankStmt(Doc, Stmt))
∧bank :▷kb{bank}(valid(Stmt)) ⊃cons :▷kb{cons}(sufFin(Doc))

The formula labeled cont belongs to cons’s knowledge base. This means that cons
can check the validity of an employment contract without evidence from other
principals. For example, valid(Cont) may check the contract duration and salary.
The formula labeled bankStmt, on the other hand, takes the bank statement
Stmt from the given documents, Doc, and requires the bank to validate it using
its knowledge base. This makes sense as Id’s ﬁnancial records are sensitive and
do not need to be disclosed to anyone else apart from her ﬁnancial institute.
These clauses also illustrate the subtle diﬀerence between goal formulas
K :▷kb{K}F and knowledge base formulas kb{K}K :▷F . For example, in the
main clause, the fact that applicant has come to their appointment at the con-
sulate does not depend on other agents and that is why we use a knowledge base
formula. The same applies to the visa preparation. On the other hand, the fact
that applicant has suﬃcient funds may require evidence from other parties, e.g.,
the applicant’s bank. Therefore this is speciﬁed as a goal.

242
Nigam et al.
Goal decomposition
Θ; Λ; Δ −→[⊤] ⊤r
Θ; Λ; Δ −→[G1]
Θ; Λ; Δ −→[G2]
Θ; Λ; Δ −→[G1 ∧G2]
∧r
Θ; Λ; Δ −→[G[t/x]]
Θ; Λ; Δ −→[∃x.G]
∃r
Θ; Λ; [Δ] −→K :▷kbQA
Θ; Λ; Δ −→[K :▷kbQA] G ⇒:▷l
Θ |⋆
Q−→A
Θ; Λ; Δ −→[K :▷kbQA] :▷r +kbr + kbl
:▷l application
Θ, kbQA; Λ; [Δ] −→K :▷kbQ′A′
Θ; Λ; [Δ, K :▷kbQA] −→K :▷kbQ′A′ :▷l
Θ; [Λ]; Δ† −→K :▷kbQA
Θ; Λ; [Δ†] −→K :▷kbQA
:▷l ⇒att
Θ; Λ; Δ† −→[K :▷kbQA]
Θ; Λ; [Δ†] −→K :▷kbQA
:▷l ⇒G
Attestation formula decomposition
Θ; Λ; Δ −→[Gσ]
Θ; Λ; [Δ, K :▷kbQAσ] −→K′ :▷kbQ′A′
Θ |Q1; ·; · −→[K1 :▷A1σ]
· · ·
Θ |Qn; ·; · −→[Kn :▷Anσ]
Θ; [Λ, ∀⃗X.

kbQ1(K1 :▷A1) ∧· · · ∧kbQn(Kn :▷An) ∧G ⊃K :▷kbQA

]; Δ −→K′ :▷kbQ′A′ att
K :▷A decomposition
evidenceKA
Θ; ·; · −→[K :▷A] ext
Θ⋆−→A
Θ; ·; · −→[K :▷A] :▷r +kbl
First-order reasoning:
All ﬁrst-order rules from CL on Θ⋆−→A sequents
Fig. 2. CLP – Sequent calculus for cyberlogic programs. A, A′ and Ai are atoms, Δ†
is such that for all K′ :▷kb′
QA′ ∈Δ†, K′ ̸= K, and Θ⋆= {F | kbQF ∈Θ}.
3.2
CPS Proof Search
Proof search of CPS can be divided into the following phases: goal decomposition,
:▷l application, attestation formula decomposition, K :▷A decomposition, and
ﬁrst-order reasoning. We deﬁne a (focusing inspired) sequent calculus for the
CPS fragment, called CLP (Figure 2) for enforcing this proof search discipline.
Sequents in CLP have the following shape: Θ; Λ; Δ −→F, where Θ contains
kb formulas, Λ contains attestation formulas, Δ contains formulas of the form
K :▷kbQA, and F is either a goal formula, kbQ(K :▷A), K :▷A or A, where A is
an atom. Moreover, the part of the sequent containing the formula that is being
decomposed will be enclosed in square brackets. This will help distinguishing the
phases mentioned above.
Lemma 3. The kbr rules permutes down every left rule in the CPS fragment.
Proof. First we note that, in the CPS fragment, ∧, ∨, ∀, and kb formulas on the
left do not have kb modalities as subformulas. We look at the case of kbl, as the
others follow a similar argument.

Proof Search and Certiﬁcates for Evidential Transactions
243
Since F is not a kb formula, then F /∈(Γ, kbQ′F, F) |Q. Therefore we can
conclude that (Γ, kbQ′F, F) |Q= (Γ, kbQ′F) |Q and the permutation is:
ϕ
(Γ, kbQ′F, F) |Q−→G
Γ, kbQ′F, F −→kbQG kbr
Γ, kbQ′F −→kbQG
kbl
⇝
ϕ
(Γ, kbQ′F) |Q−→G
Γ, kbQ′F −→kbQG kbr
The case for :▷l holds vacuously, as it is impossible to have :▷l immediately
below kbr since the former requires the right formula to be of the shape K :▷.
The remaining case is ⊃l. Observe that in the CPS fragment, the formula
F2 in F1 ⊃F2 is of the form K :▷kbQ′A. Therefore, (Γ, F2) |Q= Γ |Q. Also,
(Γ, F1 ⊃F2) |Q= Γ |Q. Thus the permutation is:
Γ −→F1
ϕ
(Γ, F2) |Q−→G
Γ, F2 −→kbQG kbr
Γ, F1 ⊃F2 −→kbQG
⊃l
⇝
ϕ
(Γ, F1 ⊃F2) |Q−→G
Γ, F1 ⊃F2 −→kbQG kbr
⊓⊔
Notice that it is crucial for attestation formulas to have a :▷modality formula
on the consequent, otherwise Lemma 3 would not hold. As seen below, this lemma
is key to proving completeness of the proof search procedure for CPS.
Theorem 3 (Soundness and completeness of CLP). Θ; Λ; Δ −→[F] in
CLP if and only if Θ, Λ, Δ −→F in CL
Proof. Soundness is straightforward: a proof in CLP can be transformed into a
proof in CL by using the same logical rules (possibly expanded – e.g. att becomes
a sequence of ∀l+ ⊃l +∧r+kbr) and skipping the phase transition rules ⇒(which
only change the syntax of the sequent, but not its content).
Completeness is achieved by reasoning about invertibility and permutability
of inference rules in the speciﬁc case of CPS. We argue that each phase can be
performed in the proposed order.
Goal decomposition The goal formula can be eagerly decomposed until
becoming K :▷kbQA before applying other rules because: ⊤r and ∧r are invert-
ible, and in the absence of ∀r and ∃l, ∃r permutes down every rule. Once the
right side formula is K :▷kbQA, there are two options to continue: (1) change to
:▷l application phase, or (2) apply rules :▷r +kbr + kbl in Figure 1.
The ﬁrst case is discussed below. In the second case, we need to argue that
kbr may be applied immediately above :▷r. Once :▷r is applied, we could choose
a formula from the context to continue with. However, kbr permutes down all
left rules for the CPS fragment, as shown in Lemma 3. Therefore any proof that
continues with a formula in Θ, Λ, or Δ above :▷r can be transformed into a
proof where kbr is applied immediately above :▷r. Since kbl is invertible, it can
be applied to exhaustion safely.
:▷l application After eagerly decomposing the goal, :▷l can be applied to
exhaustion since it is an invertible rule (Lemma 2).

244
Nigam et al.
Attestation formula decomposition This phase contains only one rule,
namely att, which encompasses ∀l, ⊃l, ∧r, and kbr. The quantiﬁer rule can
always be delayed until its subformula is needed, and ∧r is an invertible rule,
therefore these can be chained together without loss of completeness. Due to
Lemma 3, the application of kbr can be permuted down for the CPS fragment
and thus it is safe to apply the rule as soon as possible.
The two top premises of att force the proof search to go back to applying
invertible rules, which does not break completeness.
K :▷A decomposition Once this state is reached, Θ is left with kb formulas
whose subformulas are in ﬁrst-order logic (i.e., no modalities). In this case, one
can either close the proof with an external evidence, or apply :▷r +kbl to release
the atom on the right side. The eager application of kbl is justiﬁed due to its
invertibility. It can also be delayed until this point because it permutes up ⊃l
and :▷r in CL, and it permutes up kbr in the CPS fragment (Lemma 3).
First-order reasoning From this point onwards, there are no modalities in
the sequent so it will be proved using only ﬁrst-order reasoning.
⊓⊔
4
Proof Certiﬁcates
Cyberlogic programs may be used to derive facts about attestation (goals), us-
ing pure logical reasoning (knowledge bases), principal delegation (attestation
formulas), and external evidence. Once a goal is derived, evidence shall be avail-
able so that any interested party can verify that the proof is correct. Veriﬁable
evidence means that entities do not need to trust each other’s proof producing
process, as long as they can check the proofs using their own trusted processes.
Given a cyberlogic program sequent of the shape: Θ; Λ; Δ −→G one could
take its full sequent calculus proof in CLP as evidence. If the interested parties
know the calculus, checking validity of proofs reduces to checking the valid ap-
plication of each rule. However, these proofs are too ﬁne grained, and contain
many uninteresting details that can be easily inferred. Proof certiﬁcates elide
such details, and keep only the crucial steps for proof reconstruction.
Proof certiﬁcates for cyberlogic are deﬁned inspired by λ-terms and founda-
tional proof certiﬁcates [8,20] (FPC). FPC is a framework for checking proofs
in diﬀerent formalisms using a small trusted kernel. The proposed kernels are
the sequent calculus focused systems LKF and LJF [18] for LK and LJ respec-
tively, augmented with predicates for guiding proof search [9]. The deﬁnition of
proof certiﬁcates for a proof system S relies on two parts: (1) a translation of
S’s formulas into LKF or LJF formulas; and (2) a correspondence of S proofs
(or proof steps) to LKF or LJF proof steps. Given these two elements, a proof
certiﬁcate for a proof of F in S consists of a predicate which guides a proof of
F’ s translation in LKF or LJF. The following proof formats can be checked in
FPC: resolution, λ-terms, Horn clauses, Frege proofs, matings, tableaux, etc.
Deﬁning LKF or LJF FPCs for cyberlogic is challenging due to the modalities
:▷and kb, and digital evidences. LKF has been used to check proofs in modal
logics [19], but the translation of modal formulas into LK formulas used the

Proof Search and Certiﬁcates for Evidential Transactions
245
top : Θ; Λ; Δ −→[⊤] ⊤r
Ξ : Θ; Λ; Δ −→[G[t/x]]
Ξ : Θ; Λ; Δ −→[∃x.G]
∃r
Ξ1 : Θ; Λ; Δ −→[G1]
Ξ2 : Θ; Λ; Δ −→[G2]
split(Ξ1, Ξ2) : Θ; Λ; Δ −→[G1 ∧G2]
∧r
Ξ : Θ; Λ; [Δ] −→K :▷kbQA
toSaysL(Ξ) : Θ; Λ; Δ −→[K :▷kbQA] G ⇒:▷l
Ψ : Θ |⋆
Q−→A
fol(Ψ) : Θ; Λ; Δ −→[K :▷kbQA] :▷r +kbr + kbl
Ξ : Θ, kbQA; Λ; [Δ] −→K :▷kbQ′A′
Ξ : Θ; Λ; [Δ, K :▷kbQA] −→K :▷kbQ′A′ :▷l
Ξ : Θ; [Λ]; Δ† −→K :▷kbQA
toAtt(Ξ) : Θ; Λ; [Δ†] −→K :▷kbQA
:▷l ⇒att
Ξ : Θ; Λ; Δ† −→[K :▷kbQA]
toGoal(Ξ) : Θ; Λ; [Δ†] −→K :▷kbQA
:▷l ⇒G
Ξ′ : Θ; Λ; Δ −→[Gσ]
Ξ′′ : Θ; Λ; [Δ, K :▷kbQAσ] −→K′ :▷kbQ′A′
Ξ1 : Θ |Q1; ·; · −→[K1 :▷A1σ]
· · ·
Ξn : Θ |Qn; ·; · −→[Kn :▷Anσ]
att(i, σ, [Ξ1, ..., Ξn], Ξ′, Ξ′′) :
Θ; [Λ, i : ∀⃗X.

kbQ1(K1 :▷A1) ∧· · · ∧kbQn(Kn :▷An) ∧G ⊃K :▷kbQA

]; Δ −→K′ :▷kbQ′A′
att
evidenceK(E, A)
ext(E) : Θ; ·; · −→[K :▷A] ext
Ψ : Θ⋆−→A
fol(Ψ) : Θ; ·; · −→[K :▷A] :▷r +kbl
Fig. 3. CLa
P – CLP kernel for verifying CLP proof certiﬁcates of Cyberlogic programs.
Δ† is such that for all K′ :▷kb′
QA′ ∈Δ†, K′ ̸= K and Θ⋆= {F | kbQF ∈Θ}.
modalities’ semantic deﬁnition. Instead, we propose a modular CLP kernel which
allows facts derived from knowledge bases or external evidence to be checked by
the appropriate engine or entity.
The CLP kernel CLa
P (Figure 3) is constructed by augmenting sequents with a
certiﬁcate Ξ (a term indicating how the proof must proceed) and indices for the
formulas in Λ. A certiﬁcate for a proof of Θ; Λ; Δ −→G is Ξ : Θ; ΛI; Δ −→G,
where Ξ is a term built from the predicates used in CLa
P, and ΛI is a mapping
from indices to formulas in Λ. The indices are used in Ξ. The checking of a
cyberlogic sequent Θ; Λ; Δ −→G with certiﬁcate Ξ starts from the sequent
Ξ : Θ; ΛI; Δ −→[G]. Certiﬁcates denoted by the letter Ψ can represent proofs
in other formalisms and may be checked by another engine. The predicates in Ξ
are used for the following purposes during a derivation in CLa
P.
First of all, they indicate how the proof should continue when there are mul-
tiple choices. For example, if the sequent is of the form Θ; Λ; Δ −→[K :▷kbQA],
then Ξ must be one of toSaysL( ) or fol( ), indicating whether to work on :▷
modalities on the left, or ﬁnish the proof with ﬁrst-order reasoning, respectively.
Secondly, certiﬁcates relay information at the appropriate moment. For ex-
ample, split( , ) contains the certiﬁcates for each of the branches on a splitting
rule, and ext( ) includes an external evidence for proposition A. Note that there
is no certiﬁcate for ∃R since these can be instantiated with meta-variables, and
uniﬁcation can be veriﬁed when the proof is completed.
The certiﬁcate for rule att is more interesting. It includes the index i of the
attestation formula to be decomposed, the substitution σ for the ∀quantiﬁer,
and certiﬁcates for each premise. Note that each Ξ1, ...Ξn must be ext( ) or fol( ).

246
Nigam et al.
Example 5. Consider Example 4, and let the indices of the formulas be their
labels: main, cont, and bankStmt. The certiﬁcate for a proof that alice can get
a visa is Ξ : cont; main, bankStmt; · −→cons :▷kb{cons}issVisa(alice, doc, visa).
Where Ξ is:
att(main, {Id →alice, Doc →doc, V →visa}, [fol(ΨvisitOk), fol(ΨprepVisa)], ΞG, Ξ0)
The certiﬁcates ΨvisitOk and ΨprepVisa are ﬁrst-order logic proof certiﬁcates from
derivations using the consulate’s own knowledge base.
Certiﬁcate Ξ0 corresponds to att’s premise where the conclusion of main is
added to the context. This branch can be closed by removing the modalities, so
Ξ0 = toGoal(fol(id)), where id is a ﬁrst-order logic directive to close the proof.
Certiﬁcate ΞG guides the proof of the new goal:
cons :▷kb{cons}(sufFin(doc)) ∧police :▷kb{police}(noCrimeRec(alice))
and thus ΞG = split(Ξﬁn, Ξcrime). Ξﬁn depends on how cons decides to check
for suﬃcient funds. It could rely on the bank and use the attestation formula
bankStmt, in which case Ξﬁn has the shape
toSaysL(toAtt(att(bankStmt, , , , )))
Or it could use cont from its knowledge base, in which case Ξﬁn would be fol( ).
5
Related Work
Attestation logics have been proposed for the speciﬁcation of policies of several
distributed systems [14,21,15,5,29,1]. We have been inspired by some of this work
in the design of Cyberlogic. Actually, Cyberlogic was proposed some decades
ago [29,5], but until now its proof theory had not been carefully investigated. In
particular, there were no statements on cut-elimination. Additionally, we have
been inspired by the previous works on authorization logics [14,21,15] to extend
Cyberlogic with knowledge operators.
The main contribution of our work is the study of proof search and proof
certiﬁcates for attestation logics with knowledge operators.
In previous work [14] in intuitionistic authorization logic, knowledge was
restricted to one principal. As demonstrated in Example 1, allowing for multiple
principal knowledge databases ensures collaboration in reasoning.
Proof search for attestation logics is not adequately addressed in the liter-
ature. Either the proposed proof systems are Hilbert-style [1,2,17] which do
not enjoy the sub-formula property and therefore are not suitable for proof
search, or they are sequent calculus proof system, but not focused proof sys-
tems [14,21,29,5,16]. [14] only speculates that logic programming languages can
be used to carry out proof search for fragments of attestation logic. We conﬁrm
this speculation with the deﬁnition of Cyberlogic programs.
Our main inspiration for proof certiﬁcate is the work on foundational proof
certiﬁcates [9]. However, the existing work did not consider proof certiﬁcates for
attestation logics. Closer to our objective is the work of Libal and Volpe [19],

Proof Search and Certiﬁcates for Evidential Transactions
247
which deﬁne proof certiﬁcates for modal logics by encoding (the semantics of)
these logics in LKF. Our work instead proposes proof certiﬁcates directly in
Cyberlogic. This means that we are able to capitalize on rules, such as attestation
rules, to build more compact certiﬁcates. Another diﬀerence is that our proof
certiﬁcates may contain (pointers to) extra-logical evidence.
Cyberlogic has been formalized in Coq [11], encoding evidential transactions
for Schengen Visa applications. Our approach is diﬀerent in that it lays a proof
theoretic foundation to Cyberlogic. In particular, proof search is formally justi-
ﬁed as well as the representation of Cyberlogic proofs as FPCs.
Logic programming engines, such as ETB [10], have been proposed for pro-
gramming ETs. However, these engines do not (yet) support attestations, such
as K :▷F, local knowledge, such as kbQF, nor the use of digital certiﬁcates. We
believe that this work can greatly proﬁt from the foundations laid by this paper.
Finally, works [15,6] propose the use of evidence for authorization. Speciﬁ-
cally, [16] show that a fragment of their system is decidable in linear time. It
would be interesting to investigate how this fragment relates to Cyberlogic pro-
grams, and whether proof certiﬁcates as deﬁned in this work can be applied to
the decidable fragment. This is left for future work.
6
Conclusions
This paper lays the proof-theoretic foundations for Cyberlogic, an attestation
logic for evidential transactions, and reﬁne Cyberlogic with epistemic modalities.
We identify a fragment of Cyberlogic, Cyberlogic programs, and propose a proof
system similar to focused proof systems for enabling sound and complete proof
search. The necessary permutations for completeness rely on the careful interplay
between attestation, :▷, and knowledge modalities, kbQ. We then propose a
concise proof certiﬁcate format for proofs of Cyberlogic programs.
This paper is the ﬁrst step for a framework enabling evidential transactions
that we are currently implementing. In particular, we are extending Distributed
Datalog engines available in [10] to support Cyberlogic. Moreover, we are in-
tegrating such engines with PKI infrastructure, available in, for example, Dis-
tributed Ledger Technologies. This means that evidence, both in the form of
digital evidence and logical derivations in the form of FPCs, can be stored and
audited through the Ledger Technologies.
We are currently investigating extensions to Cyberlogic programs to include
other modalities, such as temporal and epistemic [23,12] while still preserving
its good proof search properties. We have also started to study conditions for
when two attestation rules can be introduced in any order. If two clauses can be
introduced in any order, then they can also be introduced in parallel. Therefore,
this would provide proof-theoretic justiﬁcation for proof search optimization.
This could be used, for example, for proposing reﬁnements to dependency graphs
used for evaluating distributed logic programming [22] which take principals into
account. These results will impact the maintenance of evidential transactions,

248
Nigam et al.
whose applications can have important consequences to, e.g., certiﬁcation in
automotive and avionics domains.
Acknowledgment: We would like to thank Dian Balta, Natarajan Shankar and
Tewodros Beyene for useful discussions and valuable feedback on earlier versions
of this paper. This project has received funding from the European Union’s
Horizon 2020 research and innovation programme under grant agreement No
830892 and from BayernCloud 3, AZ: 20-13-3410.I-01A-2017. Nigam is partially
supported CNPq grant 303909/2018-8.
A
Cut-elimination
Proof. (Sketch) The proof follows the usual Gentzen strategy of reducing the
cuts’ grade and rank. The interesting cases are rank reduction over kb rules.
In the case of kbl, contraction of the main formula is needed for the permu-
tation to work. If this was not the case, we could not conclude Γ, A −→G from
Γ, kbQA −→G. The transformations are:
ϕ1
Γ, kbQA, A −→C
Γ, kbQA −→C
kbl
ϕ2
Γ, kbQA, C −→G
Γ, kbQA −→G
cut
⇝
ϕ1
Γ, kbQA, A −→C
ϕ2 + weakening
Γ, kbQA, A, C −→G
Γ, kbQA, A −→G
cut
Γ, kbQA, −→G
kbl
ϕ1
Γ, kbQA −→C
ϕ2
Γ, kbQA, A, C −→G
Γ, kbQA, C −→G
kbl
Γ, kbQA −→G
cut
⇝
ϕ1 + weakening
Γ, kbQA, A −→C
ϕ2
Γ, kbQA, A, C −→G
Γ, kbQA, A −→G
cut
Γ, kbQA −→G
kbl
The other interesting case is when we need to permute a cut over a kbr rule
on the right branch:
ϕ1
Γ −→C
ϕ2
(Γ, C) |Qi−→G
Γ, C −→kbQiG kbr
Γ −→kbQiG
cut
There are two cases to consider:
1. C ≡kbQjC′ and Qi ⪯Qj: in this case, we can permute the cut over rules on
ϕ1 (left rules except :▷L, which is never applicable) until it is principal. This
lemma can be proved by case analysis. At this point, the premise on the left
branch will be Γ |Qj−→C′. Then kbR can be applied to the end-sequent,
resulting in:
ϕ′
1
Γ |Qi−→kbQjC′
ϕ′
2
Γ |Qi, kbQjC′ −→G
Γ |Qi−→G
cut
Γ −→kbQiG kbr
The proof ϕ′
2 is exactly ϕ2, since (Γ, kbQjC′) |Qi≡Γ |Qi, kbQjC′ when
Qi ⪯Qj. The proof ϕ′
1 is obtained from the proof of Γ |Qj−→C′, since
Γ |Qj⊆Γ |Qi when Ki ⪯Qj.
2. C ̸≡kbQjC′ or Qi ̸⪯Qj : in this case C /∈(Γ, C) |Qi, so kbr can be applied
directly to the end-sequent, and the cut can be removed.
⊓⊔

Proof Search and Certiﬁcates for Evidential Transactions
249
References
1. Abadi, M.: Logic in Access Control. In: 18th IEEE Symposium on Logic in Com-
puter Science (LICS) Proceedings. pp. 228–233. IEEE Computer Society (2003).
https://doi.org/10.1109/LICS.2003.1210062
2. Abadi, M., Burrows, M., Lampson, B.W., Plotkin, G.D.: A Calculus for Access
Control in Distributed Systems. ACM Trans. Program. Lang. Syst. 15(4), 706–
734 (1993). https://doi.org/10.1145/155183.155225
3. Andreoli,
J.M.:
Logic
Programming
with
Focusing
Proofs
in
Lin-
ear
Logic.
Joural
of
Logic
and
Computation
2(3),
297–347
(1992).
https://doi.org/10.1093/logcom/2.3.297
4. Bernat,
V.:
First-Order
Cyberlogic
Hereditary
Harrop
Logic.
Tech.
rep.,
SRI
International
(2006),
http://www.lsv.ens-cachan.fr/Publis/PAPERS/PS/
Bernat-cyberlogic1.ps
5. Bernat, V., Ruess, H., Shankar, N.: First-order Cyberlogic. Technical Report CSL-
SRI-04-03, SRI International Computer Science Laboratory (2004)
6. Blass, A., Gurevich, Y., Moskal, M., Neeman, I.: Evidential Authorization. In:
Nanz, S. (ed.) The Future of Software Engineering. pp. 73–99. Springer (2010).
https://doi.org/10.1007/978-3-642-15187-3 5
7. Chaudhuri, K., Pfenning, F., Price, G.: A Logical Characterization of For-
ward
and
Backward
Chaining
in
the
Inverse
Method.
In:
Furbach,
U.,
Shankar, N. (eds.) Automated Reasoning, Third International Joint Confer-
ence, IJCAR, Proceedings. pp. 97–111. Springer Berlin Heidelberg (2006).
https://doi.org/10.1007/11814771 9
8. Chihani, Z., Miller, D., Renaud, F.: Foundational Proof Certiﬁcates in First-Order
Logic. In: Bonacina, M.P. (ed.) CADE-24 - 24th International Conference on Au-
tomated Deduction. Proceedings. Lecture Notes in Computer Science, vol. 7898,
pp. 162–177. Springer (2013). https://doi.org/10.1007/978-3-642-38574-2 11
9. Chihani, Z., Miller, D., Renaud, F.: A Semantic Framework for Proof Evidence.
J. Autom. Reasoning 59(3), 287–330 (2017). https://doi.org/10.1007/s10817-016-
9380-6
10. Cruanes, S., Hamon, G., Owre, S., Shankar, N.: Tool Integration with the Ev-
idential Tool Bus. In: Giacobazzi, R., Berdine, J., Mastroeni, I. (eds.) Veriﬁ-
cation, Model Checking, and Abstract Interpretation, 14th International Con-
ference, VMCAI. Proceedings. pp. 275–294. Springer Berlin Heidelberg (2013).
https://doi.org/10.1007/978-3-642-35873-9 18
11. Dargaye, Z., Kirchner, F., Tuccı-Piergiovanni, S., G¨urcan, O.: Towards Secure and
Trusted-by-Design Smart Contracts. In: JFLA (2018)
12. DeYoung, H., Garg, D., Pfenning, F.: An Authorization Logic With Ex-
plicit Time. In: Proceedings of the 21st IEEE Computer Security Foun-
dations
Symposium,
CSF.
pp.
133–145.
IEEE
Computer
Society
(2008).
https://doi.org/10.1109/CSF.2008.15
13. Fairtlough, M., Mendler, M.: Propositional Lax Logic. Inf. Comput. 137(1), 1–33
(1997). https://doi.org/10.1006/inco.1997.2627
14. Garg, D., Bauer, L., Bowers, K.D., Pfenning, F., Reiter, M.K.: A Linear Logic of
Authorization and Knowledge. In: Gollmann, D., Meier, J., Sabelfeld, A. (eds.)
Computer Security - ESORICS 2006, 11th European Symposium on Research in
Computer Security, Proceedings. pp. 297–312. Springer Berlin Heidelberg (2006).
https://doi.org/10.1007/11863908 19

250
Nigam et al.
15. Gurevich,
Y.,
Neeman,
I.:
DKAL:
Distributed-Knowledge
Authoriza-
tion
Language.
Tech.
Rep.
MSR-TR-2008-09,
Microsoft
Research
(Jan-
uary
2008),
https://www.microsoft.com/en-us/research/publication/
191tr-dkal-distributed-knowledge-authorization-language/
16. Gurevich,
Y.,
Neeman,
I.:
DKAL
2
-
A
Simpliﬁed
and
Improved
Au-
thorization
Language.
Tech.
Rep.
MSR-TR-2009-11,
Microsoft
Re-
search
(2009),
https://www.microsoft.com/en-us/research/publication/
200-dkal-2-a-simpliﬁed-and-improved-authorization-language/
17. Gurevich, Y., Neeman, I.: Logic of infons: The propositional case. ACM Trans.
Comput. Log. 12(2), 9:1–9:28 (2011). https://doi.org/10.1145/1877714.1877715
18. Liang,
C.,
Miller,
D.:
Focusing
and
polarization
in
linear,
intuitionis-
tic, and classical logics. Theor. Comput. Sci.
410(46), 4747–4768 (2009).
https://doi.org/10.1016/j.tcs.2009.07.041
19. Libal,
T.,
Volpe,
M.:
A
general
proof
certiﬁcation
framework
for
modal
logic.
Math.
Struct.
Comput.
Sci.
29(8),
1344–1378
(2019).
https://doi.org/10.1017/S0960129518000440
20. Miller, D.: Foundational Proof Certiﬁcates. In: Delahaye, D., Paleo, B.W. (eds.) All
about Proofs, Proofs for All, All about Proofs, Proofs for All, vol. Mathematical
Logic and Foundations, 55, pp. 150–163. College Publications (2015), https://hal.
inria.fr/hal-01239733
21. Nigam, V.: A framework for linear authorization logics. Theor. Comput. Sci. 536,
21–41 (2014). https://doi.org/10.1016/j.tcs.2014.02.018
22. Nigam, V., Jia, L., Loo, B.T., Scedrov, A.: Maintaining distributed logic programs
incrementally. Computer Languages, Systems & Structures 38(2), 158–180 (2012).
https://doi.org/10.1016/j.cl.2012.02.001
23. Nigam, V., Olarte, C., Pimentel, E.: A General Proof System for Modalities in
Concurrent Constraint Programming. In: D’Argenio, P.R., Melgratti, H.C. (eds.)
CONCUR 2013 - Concurrency Theory - 24th International Conference. Proceed-
ings. Lecture Notes in Computer Science, vol. 8052, pp. 410–424. Springer (2013).
https://doi.org/10.1007/978-3-642-40184-8 29
24. Nigam, V., Pimentel, E., Reis, G.: An extended framework for specifying
and reasoning about proof systems. J. Log. Comput. 26(2), 539–576 (2016).
https://doi.org/10.1093/logcom/exu029
25. Olarte, C.: L-framework. https://carlosolarte.github.io/L-framework/, accessed on
03-01-2021
26. Olarte, C., Pimentel, E., Rocha, C.: Proving Structural Properties of Sequent Sys-
tems in Rewriting Logic. In: Rusu, V. (ed.) Rewriting Logic and Its Applications
- 12th International Workshop, WRLA 2018, Held as a Satellite Event of ETAPS,
Proceedings. Lecture Notes in Computer Science, vol. 11152, pp. 115–135. Springer
(2018). https://doi.org/10.1007/978-3-319-99840-4 7
27. Pfenning,
F.,
Davies,
R.:
A
judgmental
reconstruction
of
modal
logic.
Mathematical
Structures
in
Computer
Science
11(4),
511–540
(2001).
https://doi.org/10.1017/S0960129501003322
28. Reis, G.: Observations about the proof theory of cyberlogic. http://www.gisellereis.
com/papers/cyberlogic-report.pdf (2019)
29. Ruess, H., Shankar, N.: Introducing Cyberlogic (2003)
30. Troelstra, A.S., Schwichtenberg, H.: Basic Proof Theory. Cambridge University
Press (1996)

Proof Search and Certiﬁcates for Evidential Transactions
251
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Non-clausal Redundancy Properties ⋆
Johannes Kepler University Linz
Altenbergerstraße 69, 4040 Linz, Austria
{lee.barnett,armin.biere}@jku.at
Abstract. State-of-the-art refutation systems for SAT are largely based
on the derivation of clauses meeting some redundancy criteria, ensuring
their addition to a formula does not alter its satisﬁability. However, there
are strong propositional reasoning techniques whose inferences are not
easily expressed in such systems. This paper extends the redundancy
framework beyond clauses to characterize redundancy for Boolean con-
straints in general. We show this characterization can be instantiated to
develop eﬃciently checkable refutation systems using redundancy prop-
erties for Binary Decision Diagrams (BDDs). Using a form of reverse
unit propagation over conjunctions of BDDs, these systems capture, for
instance, Gaussian elimination reasoning over XOR constraints encoded
in a formula, without the need for clausal translations or extension vari-
ables. Notably, these systems generalize those based on the strong Prop-
agation Redundancy (PR) property, without an increase in complexity.
1
Introduction
The correctness and reliability of Boolean satisﬁability (SAT) solvers is critical
for many applications. For instance SAT solvers are used for verifying hardware
and software systems (e.g. [19,28,44]), to search for solutions to open problems
in mathematics (e.g. [38,46]), and as subroutines of other logical reasoning tools
(e.g. [7,67]). Solvers should be able to provide solution certiﬁcates that are easily
and externally checkable. For a satisﬁable formula, any satisfying assignment is
a suitable certiﬁcate and typically can be easily produced by a solver. For an
unsatisﬁable formula, a solver should be able to produce a refutation proof.
Modern SAT solvers primarily refute unsatisﬁable formulas using clausal
proof systems, such as the popular DRAT system [69] used by the annual SAT
competition in recent years [4], or newer systems based on the surprisingly strong
Propagation Redundancy (PR) property [33]. Clausal proof systems iteratively
extend a formula, typically given in conjunctive normal form (CNF), by adding
clauses that are redundant; that is, their addition to the formula does not aﬀect
whether it is satisﬁable. Systems are distinguished by their underlying redun-
dancy properties, restricted but eﬃciently-decidable forms of redundancy.
⋆Supported by the Linz Institute of Technology AI Lab funded by the State of Upper
Austria, as well as the Austrian Science Fund (FWF) under project W1255-N23, the
LogiCS Doctoral College on Logical Methods in Computer Science.
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5_15
Lee A. Barnett
and Armin Biere
252–272, 2021.

Redundancy is a useful notion in SAT as it captures most inferences made
by state-of-the-art solvers. This includes clauses implied by the current formula,
such as the resolvent of two clauses or clauses learned during conﬂict-driven
clause learning (CDCL) [8,51], as well as clauses which are not implied but de-
rived nonetheless by certain preprocessing and inprocessing techniques [43], such
as those based on blocked clauses [42,45,48]. Further, clausal proof systems based
on properties like PR include short refutations for several hard families of formu-
las, such as those encoding the pigeonhole principle, that have no polynomial-
length refutations in resolution [2] (see [16] for an overview). These redundancy
properties, seen as inference systems, thus potentially oﬀer signiﬁcant improve-
ments in eﬃciency, as the CDCL algorithm at the core of most solvers searches
only for refutations in resolution [9]. While the recent satisfaction-driven clause
learning (SDCL) paradigm has shown some initial success [35,37], it is still un-
clear how to design solving techniques which take full advantage of this potential.
Conversely, there are existing strong reasoning techniques which similarly ex-
ceed the abilities of CDCL alone, but are diﬃcult to express using clausal proof
systems. Important examples include procedures for reasoning over CNF formu-
las encoding pseudo-Boolean and cardinality constraints (see [58]), as well as
Gaussian elimination (see [12,61,62,68]), which has been highlighted as a chal-
lenge for clausal proof systems [31]. Gaussian elimination, applied to sets of
“exclusive-or” (XOR) constraints, is a crucial technique for many problems from
cryptographic applications [62], and can eﬃciently solve, for example, Tseitin for-
mulas hard for resolution [64,66]. This procedure, implemented by CryptoMin-
iSAT [62], Lingeling [10], and Coprocessor [50] for example, can be polynomially
simulated by extended resolution, allowing inferences over new variables, and
similar systems (see [56,60]). However due to the diﬃculty of such simulations
they are not typically implemented. Instead solvers supporting these techniques
simply prevent them from running when proof output is required, preferring less
eﬃcient techniques whose inferences can be more easily represented.
This paper extends the redundancy framework for clausal proof systems to
include non-clausal constraints, such as XOR or cardinality constraints, pre-
senting a characterization of redundancy for Boolean functions in general. We
demonstrate a particular use of this characterization by instantiating it for func-
tions represented by Binary Decision Diagrams [13], a powerful representation
with a long history in SAT solving (e.g. [14,23,24,52,54]) and other areas of au-
tomated reasoning (e.g. [15,29,47,57]). We show the resulting refutation systems
succinctly express Gaussian elimination while also generalizing existing clausal
systems. Results using a prototype implementation conﬁrm these systems al-
low compact and eﬃciently checkable refutations of CNF formulas that include
embedded XOR constraints solvable by Gaussian elimination.
In the rest of the paper, Section 2 includes preliminaries and Section 3
presents the characterization of redundancy for Boolean functions. Section 4
introduces redundancy properties for BDDs, and Section 5 demonstrates their
use for Gaussian elimination. Section 6 presents the results of our preliminary
implementation, and Section 7 concludes.
Non-clausal Redundancy Properties
253

254
L. A. Barnett, A. Biere
2
Preliminaries
We assume a set of Boolean variables V under a ﬁxed order ≺and use standard
SAT terminology. The set of truth values is B = {0, 1}. An assignment is a
function τ : V →B and the set of assignments is BV . A function f : BV →B
is Boolean. If f(τ) = 1 for some τ ∈BV then f is satisﬁable, otherwise f is
unsatisﬁable. Formulas express Boolean functions as usual, are assumed to be
in conjunctive normal form, and are written using capital letters F and G. A
clause can be represented by its set of literals and a formula by its set of clauses.
A partial assignment is a non-contradictory set of literals σ; that is, if l ∈σ
then ¬l ̸∈σ. The application of a partial assignment σ to a clause C is written
C|σ and deﬁned by: C|σ = ⊤if every τ ∈BV that satisﬁes 
l∈σ l also satisﬁes C,
otherwise C|τ = {l | l ∈C and l, ¬l ̸∈σ}. For example, (x1 ∨x2)|{¬x1,x2} = ⊤,
and (x1 ∨x2)|{¬x2,¬x3} = (x1). Similarly the application of σ to a formula F
is written F|σ and deﬁned by: F|σ = ⊤if C|σ = ⊤for all C ∈F, otherwise
F|σ = {C|σ | C ∈F and C|σ ̸= ⊤}. Unit propagation is the iterated replacement
of F with F|{l} for each unit clause (l) ∈F, until F includes the empty clause
⊥, or F contains no unit clauses. A formula F implies a clause C by reverse unit
propagation (RUP) if unit propagation on F ∧¬C ends by producing ⊥[27].
For a formula F and clause C, if F and F ∧C are equisatisﬁable (both sat-
isﬁable or both unsatisﬁable) then C is redundant with respect to F. Eﬃciently
identiﬁable redundant clauses are at the foundation of many formula simpli-
ﬁcation techniques and refutation systems (for instance, see [32,33,37,43]). In
general, deciding whether a clause is redundant is complete for the complement
of the class DP [6], containing both NP and co-NP [55], so solvers and proof sys-
tems rely on polynomially-decidable redundancy properties for checking speciﬁc
instances of redundancy. The following characterization of redundant clauses
provides a common framework for formulating such properties.
Theorem 1 (Heule, Kiesl, and Biere [36]). A clause C ̸= ⊥is redundant
with respect to a formula F if and only if there is a partial assignment ω such
that C|ω = ⊤and F|α ⊨F|ω, for the partial assignment α = {¬l | l ∈C}.
The partial assignment ω, usually called a witness for C, includes at least one
of the literals occurring in C, while α is said to block the clause C. Redundancy
properties can be deﬁned by replacing ⊨in the theorem above with eﬃciently-
decidable relations R such that R ⊆⊨. Propagation redundancy (PR) [33] re-
places ⊨with ⊢1, where F ⊢1 G if and only if F implies each D ∈G by RUP.
The property PR gives rise to a refutation system, in which a refutation is a
list of clauses C1, . . . , Cn and witnesses ω1, . . . , ωn such that Ck|ωk = ⊤and
(F k−1
i=1 Ci)|αk ⊢1 (F k−1
i=1 Ci)|ωk for all 1 ≤k ≤n, and F n
i=1 Ci ⊢1 ⊥.
Most redundancy properties used in SAT solving can be understood as re-
stricted forms of propagation redundancy. The RAT property [43] is equivalent
to literal propagation redundancy, where the witness ω for any clause C may
diﬀer from the associated α on only one literal; that is, ω = (α \ {¬l}) ∪{l} for
some l ∈C [36]. The DRAT system [69] is based on RAT, with the added ability
to remove clauses from the accumulated formula F  Ci.

Rf
RBDD
R
RCNF+XOR
RCNF+Card
. . .
PRBDD
PR [33]
RAT [43]
RUP [27]
RUPBDD
GE [68]
CR [39]
Fig. 1: Diﬀerent notions of redundancy and their relationships. An arrow from A
to B indicates A generalizes B. Properties to the right of the thick dashed line
are polynomially checkable; those to the right of the thin dotted line only derive
logical consequences. Novel properties deﬁned in this paper are grey.
3
Redundancy for Boolean Functions
Theorem 1 provides a foundation for clausal proof systems by characterizing re-
dundant clauses in a convenient way. However, the restriction to clauses places
limitations on these systems, making some forms of non-clausal reasoning diﬃ-
cult to express. For solvers aiming to construct refutations in these systems, this
translates directly to restrictions on which solving techniques can be used.
We show this characterization can be broadened to include redundancy for
non-clausal constraints, and can be used to deﬁne useful redundancy properties
and refutation systems. The contributions of this paper are divided into three
corresponding levels of generality. The top level, covered in the current section,
is the direct extension of Theorem 1 from redundancy for clauses, written R,
to redundancy for Boolean functions, written Rf. The middle level, the focus of
Section 4, instantiates the resulting Theorem 2 to deﬁne the refutation systems
RUPBDD and PRBDD based on redundancy for Binary Decision Diagrams. At
the bottom level, these systems are shown to easily handle Gaussian elimination
(GE) in Section 5, as well as some aspects of cardinality reasoning (CR). The
relationships between these notions of redundancy are shown in Figure 1.
Each level of generality is individually important to this work. At the bottom
level, the straightforward expression of Gaussian elimination by RUPBDD and
PRBDD makes it more feasible for solvers to use this eﬃcient technique with
proof production, especially as these systems generalize their clausal analogs
already in use. The results in Section 6 conﬁrm the usefulness of RUPBDD for
this purpose. At the middle level, we show the notion of redundancy instantiated
255
Non-clausal Redundancy Properties

256
L. A. Barnett, A. Biere
for BDDs in this way may be capable of other strong forms of reasoning as well.
Finally, the top level provides a very general form of redundancy, independent
of function representation. This may make possible the design of redundancy
properties and refutation systems in contexts where the BDD representation
of constraints is too large; for example, it is known that some pseudo-Boolean
constraints can in general have exponential size BDD representations [1,41].
This section presents in Theorem 2 a characterization of redundancy for
Boolean functions in general. One way of instantiating this characterization is
demonstrated in Section 4 where the functions are represented by Binary Deci-
sion Diagrams; the resulting refutation systems are shown in Section 5 to easily
express Gaussian elimination. However, the applicability of Theorem 2 is much
broader, providing a foundation for redundancy-based refutation systems inde-
pendent of the representation used.
Proofs of theoretical results not included in the text can be found in an
extended version of this paper [5]. We begin with the property Rf.
Deﬁnition 1. A Boolean function g is redundant with respect to a Boolean
function f if the functions f and f ∧g are both satisﬁable, or both unsatisﬁable.
As we will see, extending Theorem 1 to the non-clausal case relies on the notion
of a Boolean transformation, or just transformation: a function ϕ : BV →BV ,
mapping assignments to assignments. Importantly, for a function f and trans-
formation ϕ, in fact f ◦ϕ : BV →B is a function as well, where as usual
f ◦ϕ (τ) = f(ϕ(τ)). For instance let F = x1 ∧x2 and for all τ ∈BV , the
transformation ϕ ﬂips x1, so that ϕ(τ)(x1) = ¬τ(x1), and ignores x2, that is,
ϕ(τ)(x2) = τ(x2). Then in fact F ◦ϕ is expressed by the formula ¬x1 ∧x2.
Composing a function with a transformation can be seen as a generalization
of the application of a partial assignment to a formula or clause as deﬁned in
the previous section. Speciﬁcally, for a partial assignment σ let ˆσ refer to the
following transformation: for any assignment τ, the assignment ˆσ(τ) satisﬁes

l∈σ l, and ˆσ ignores any x ∈V such that x, ¬x ̸∈σ. Then for any formula F
the formula F|σ expresses exactly the function F ◦ˆσ. In particular, if α is the
partial assignment blocking a clause C then notice C ◦ˆα(τ) = 0 for all τ, but ˆα
ignores variables not appearing in C; consequently ˆα(τ) = τ if τ already falsiﬁes
C. Generalizing this idea to transformations that block non-clausal constraints is
more complicated. In particular, there may be multiple blocking transformations.
Example 1. Let g be the function g(τ) = 1 if and only if τ(a) ̸= τ(b) (i.e. g is
an XOR constraint). Transformations α1, α2 are shown in the table below.
τ(a) τ(b)
g
α1(τ)(a) α1(τ)(b) g ◦α1
α2(τ)(a) α2(τ)(b) g ◦α2
0
0
0
0
0
0
0
0
0
0
1
1
0
0
0
1
1
0
1
0
1
0
0
0
0
0
0
1
1
0
1
1
0
1
1
0
Both transformations ignore all x ̸= a, b. Notice if g(τ) = 0 then τ is unaﬀected
by either transformation, and g ◦α1(τ) = g ◦α2(τ) = 0 for any assignment τ.

However α1 and α2 are diﬀerent, so that, for example, if F = ¬a ∧(b ∨c) and τ
satisﬁes the literals ¬a, b, and c then F ◦α1(τ) = 1 but F ◦α2(τ) = 0.
Motivated by this we deﬁne transformations blocking a function as follows.
Deﬁnition 2. A transformation α blocks a function g if g ◦α is unsatisﬁable,
and for any assignment τ if g(τ) = 0 then α(τ) = τ.
Notice any g not equal to the constant function 1 has blocking transformations;
for example, by mapping every τ satisfying g to a particular assignment falsifying
it. Using this deﬁnition, the following theorem shows how the redundancy of a
Boolean function g with respect to another function f can be demonstrated.
This is a direct generalization of Theorem 1, using a transformation blocking g
in the place of the partial assignment blocking a clause, and a transformation ω
such that g ◦ω is the constant function 1 in place of the witnessing assignment.
Theorem 2. Let f be a function and g a non-constant function. Then g is
redundant with respect to f if and only if there exist transformations α and ω
such that α blocks g and g◦ω is the constant function 1, and further f ◦α ⊨f ◦ω.
Proof. (⇒) Suppose g is redundant with respect to f and let α be any transfor-
mation blocking g. If f is unsatisﬁable then f ◦α is as well, so that f ◦α ⊨f ◦ω
holds for any ω. Thus we can take as ω the transformation ω(τ) = τ ∗for all
τ ∈BV , where τ ∗is some assignment satisfying g. If instead f is satisﬁable, by
redundancy so is f ∧g. Here we can take as ω the transformation ω(τ) = τ ∗for
all τ ∈BV , where τ ∗is some assignment satisfying f ∧g. Then both f ◦ω and
g ◦ω are the constant function 1, so that f ◦α ⊨f ◦ω holds in this case as well.
(⇐) Suppose α, ω meet the criteria stated in the theorem. We show that g
is redundant by demonstrating that if f is satisﬁable, then so is f ∧g. Suppose
τ is an assignment satisfying f. If also g(τ) = 1, then of course τ satisﬁes
f ∧g. If instead g(τ) = 0, then α(τ) = τ as α blocks the function g. Thus
f ◦α (τ) = f(α(τ)) = f(τ) = 1. As f ◦α ⊨f ◦ω, this means f(ω(τ)) = 1. As
g ◦ω is the constant function 1 then g(ω(τ)) = 1, so ω(τ) satisﬁes f ∧g.
⊓⊔
The clausal characterization in Theorem 1 shows that the redundancy of a
clause can be evidenced by providing a witnessing assignment and demonstrating
that an implication holds, providing a foundation for refutations based on the
iterative conjunction of clauses. Theorem 2 above shows that the redundancy of
a function in general can be seen in the same way by providing transformations
α and ω. Consequently this suggests how to construct refutations based on the
iterative conjunction of Boolean functions.
Deﬁnition 3. A sequence σ = (g1, α1, ω1), . . . , (gn, αn, ωn) is a redundancy se-
quence for a Boolean function f if:
1. αk blocks gk and gk ◦ωk is the constant function 1, for all 1 ≤k ≤n,
2. (f ∧k−1
i=1 gi) ◦αk ⊨(f ∧k−1
i=1 gi) ◦ωk, for all 1 ≤k ≤n.
257
Non-clausal Redundancy Properties

258
L. A. Barnett, A. Biere
As for clausal redundancy, refutations are intuitively based on the following: if
g1 is redundant with respect to f, and g2 is redundant with respect to f ∧g1,
then f and f ∧g1∧g2 are equisatisﬁable; that is, g1∧g2 is redundant with respect
to f. The following holds as a direct consequence.
Proposition 1. Let f be a Boolean function. If (g1, α1, ω1), . . . , (gn, αn, ωn) is
a redundancy sequence for f, and f ∧n
i=1 gi is unsatisﬁable, then so is f.
This shows, abstractly, how redundant Boolean functions can be used as a ba-
sis for refutations in the same way as redundant clauses. To deﬁne practical, and
polynomially-checkable, refutation systems based on non-clausal redundancy in
this way, we focus on a representation of Boolean functions that can be used
within the framework described above. Speciﬁcally, we consider sets of BDDs in
conjunction, just as formulas are sets of clauses in conjunction. Clauses are easily
expressed by BDDs, and thus this representation easily expresses (CNF) formu-
las; this is necessary as we are typically interested in proving the unsatisﬁability
not of functions in general, but of (CNF) formulas. It is important to notice this
is only a particular instantiation of Theorem 2, and that other representations
of Boolean functions may give rise to useful and eﬃcient systems as well.
BDDs [3,13,49] are compact expressions of Boolean functions in the form of
rooted, directed, acyclic graphs consisting of decision nodes, each labeled by a
variable x ∈V and having two children, and two terminal nodes, labeled by 0
and 1. The BDD for a function f : BV →B is based on its Shannon expansion,
f = (¬x ∧f ◦ˆσ0) ∨(x ∧f ◦ˆσ1)
where σ0 = {¬x} and σ1 = {x}, for x ∈V . As is common we assume BDDs are
ordered and reduced: if a node with variable label x precedes a node with label
y in the graph then x ≺y, and the graph has no distinct, isomorphic subgraphs.
Representation this way is canonical up to variable order, so that no two distinct
BDDs with the same variable order represent the same Boolean function [13].
Our use of BDDs for representing non-clausal redundancy relies on the con-
cept of cofactors as developed in BDD literature. The functions f ◦ˆσ0 and f ◦ˆσ1
are called literal cofactors of f by ¬x and x, respectively, and are usually written
f|¬x and f|x. The cofactor of f by a conjunction of literals c = l1∧· · ·∧ln can be
deﬁned similarly, so that f|c = f◦ˆσc, for the partial assignment σc = {l1, . . . , ln}.
This notation is the same as for the application of a partial assignment to a clause
or formula from Section 2, as the notions coincide. More precisely, if a formula
F and BDD f express the same function, so do the formula F|σc and BDD f|c.
More broadly, for BDDs f and g, a generalized cofactor of f by g is a BDD
h such that f ∧g = h ∧g; that is, f and h agree on all assignments satisfying
g. This leaves unspeciﬁed what value h(τ) should take when g(τ) = 0, and vari-
ous diﬀerent BDD operations have been developed for constructing generalized
cofactors [20,21,22] The constrain operation [21] produces for f and g, with g
not equal to the always false 0 BDD, a generalized cofactor which can be seen

as the composition f ◦πg, where πg is the transformation [63]:
πg(τ) =
⎧
⎨
⎩
τ
if g(τ) = 1
arg min
{τ ′ | g(τ ′)=1}
d(τ, τ ′)
otherwise.
The function d is deﬁned as follows: d(τ, τ ′) = n
i=1 |τ(xi)−τ ′(xi)|·2n−i, where
V = {x1, . . . , xn} with x1 ≺· · · ≺xn. Intuitively, d is a measure of distance
between two assignments based on the variables on which they disagree, weighted
by their position in the variable order. It is important to notice then that the
transformation πg and the resulting f ◦πg depend on the variable order, and
may diﬀer for distinct orders. For a conjunction of literals c, though, f ◦πc = f|c
regardless of the order, so that f|g refers to f ◦πg in general.
As the transformation πg maps an assignment falsifying the function g to
the nearest assignment (with respect to d) satisfying it, a transformation that
blocks the function g can surely be obtained as follows.
Lemma 1. If g is not equal to the constant function 1 then π¬g blocks g.
This form of generalized cofactor, as computed by the constrain operation,
is well suited for use in redundancy-based reasoning as described above, as the
transformation π¬g depends only on g. As a consequence, for BDDs f1 and f2
in fact (f1 ∧f2)|¬g ≡f1|¬g ∧f2|¬g; that is, the BDD (f1 ∧f2)|¬g expresses the
same function as the BDD for the conjunction f1|¬g ∧f2|¬g. Thus given a set of
BDDs f1, . . . , fn we can represent (f1 ∧· · ·∧fn)|¬g simply by the set of cofactors
fi|¬g and without constructing the BDD for the conjunction f1 ∧· · · ∧fn, which
is NP-hard in general. In particular, given a formula F = C1 ∧· · · ∧Cn and a
Boolean constraint g, the function F|¬g can be represented simply by applying
the constrain operation to each of the BDDs representing Ci. Therefore, from
Theorem 2 we can characterize redundancy for conjunctions of BDDs, written
RBDD, as follows.
Proposition 2. Suppose f1, . . . , fn are BDDs and g is a non-constant BDD. If
there is a partial assignment {l1, . . . , lk} such that for ω = k
i=1 li,
f1|¬g ∧· · · ∧fn|¬g ⊨f1|ω ∧· · · ∧fn|ω
and g|ω = 1 then g is redundant with respect to f1 ∧. . . ∧fn.
4
BDD Redundancy Properties
The previous section provided a characterization of redundancy for Boolean
functions, and showed how this could be instantiated for BDDs. In this section we
develop polynomially-checkable properties for showing that a BDD is redundant
with respect to a conjunction of BDDs, and describe their use in refutation
systems for proving the unsatisﬁability of formulas.
259
Non-clausal Redundancy Properties

260
L. A. Barnett, A. Biere
UnitProp(f1, . . . , fn)
1
repeat
2
if fi = 0 or fi = ¬fj for some 1 ≤i, j ≤n then
3
return “conﬂict”
4
if U (fi) ̸= ∅for some 1 ≤i ≤n then
5
fj := fj| U(fi) for all 1 ≤j ≤n
6
until no update to f1, . . . , fn
Fig. 2: A procedure for unit propagation over a set of BDDs
As Theorem 1 is used for deﬁning clausal redundancy properties, Proposi-
tion 2 gives rise to BDD redundancy properties by replacing ⊨with polynomially-
decidable relations. Similar to the use of the unit propagation procedure by the
clausal properties RUP and PR, we describe a unit propagation procedure for
use with a set of BDDs and derive analogous properties RUPBDD and PRBDD.
For a BDD f, the Shannon expansion shows that if f|¬l = 0 (i.e. f|¬l is the
always false 0 BDD) for some literal l, then f = l ∧fl, and therefore f ⊨l. Then
the units implied by f, written U (f), can be deﬁned as follows.
Deﬁnition 4. U (f) = {l | var(l) ∈V and f|¬l = 0}, for f : BV →B.
As f|¬l can be computed in O(|f|), where |f| is the number of nodes in the BDD
for f [59], then U (f) can certainly be computed in O(|V |·|f|) ⊆O(|f|2), though
this can be reduced to O(|f|). We write  U (f) to mean 
l∈U(f) l.
Figure 2 provides a sketch of the unit propagation procedure. Whenever U (f)
is non-empty for some f in a set of BDDs, each BDD in the set can be replaced
with its cofactor by  U (f). This approach to unit propagation is largely similar
to that of Olivo and Emerson [53], except we consider two conﬂict situations: if
some BDD becomes 0, or if two BDDs are the negations of each other.
For N = |f1| + · · · + |fn| the procedure UnitProp(f1, . . . , fn) can be per-
formed in time O(N 2). In line 5, if fj and  U (fi) share no variables, then
fj = fj| U(fi), otherwise the BDD for fj| U(fi) can be constructed in time
O(|fj|) and further |fj| U(fi)| < |fj|. This procedure is correct: “conﬂict” is only
returned when n
i=1 fi is unsatisﬁable (see the extended paper for the proof).
Proposition 3. If UnitProp(f1, . . . , fn) returns “conﬂict” then f1 ∧· · ·∧fn ≡0.
UnitProp generalizes the usual unit propagation procedure on a formula: if
C is a clause, then U (C) ̸= ∅implies C is a unit clause and 
l∈U(C) l = C. We
extend the relation ⊢1 and the deﬁnition of RUP accordingly.
Deﬁnition 5. Let f1, . . . , fn and g ̸= 0 be BDDs. Then f1 ∧· · · ∧fn implies g
by RUPBDD if UnitProp(f1|¬g, . . . , fn|¬g) returns “conﬂict.”
Example 2. Let F = {C1 = b ∨c, C2 = a ∨b, C3 = a ∨c}, and assume a ≺b ≺c.
Consider g as shown in Figure 3, expressing the cardinality constraint g(τ) = 1
if and only if τ satisﬁes at least two a, b, c; also written {a, b, c} ≥2. Figure 3

a
b
b
c
1
0
(a) The constraint g
(b ∨c)|¬g
(a ∨b)|¬g
(a ∨c)|¬g
a
b
c
1
0
a
b
1
0
a
b
c
1
0
Unit: ¬a
b
c
1
0
b
1
0
b
c
1
0
Unit: b
1
1
0
conﬂict
(b) UnitProp((b ∨c)|¬g, (a ∨b)|¬g, (a ∨c)|¬g)
Fig. 3: Example derivation of a constraint g, shown in (a), using RUPBDD. In (b),
the top line shows the BDDs for each of the clauses (b ∨c), (a ∨c), (a ∨b) after
cofactoring by g. The second line shows each of these BDDs after cofactoring
by the unit ¬a ∈U((b ∨c)|¬g). Here, the middle BDD becomes simply the unit
b, and the third line shows each BDD cofactored by the unit b. In this line, the
third BDD has become 0, so a conﬂict is returned.
shows the updates made throughout UnitProp(C1|¬g, C2|¬g, C3|¬g). Notice that
U (C1|¬g) = {¬a}, and U ((C2|¬g)|¬a) = {b}. Then C3|¬g after cofactoring by
¬a and b becomes the constant BDD 0, so the procedure returns “conﬂict.” As
a result, F implies the BDD g by RUPBDD.
We show that RUPBDD is a redundancy property. Given BDDs f1, . . . , fn, g,
checking whether g is implied by RUPBDD primarily consists of the UnitProp
procedure, though each fi|¬g must ﬁrst be constructed, which can be done in
time O(|fi| · |g|) [21]. The size of this BDD may in some cases be larger than the
size of fi, though it is typically smaller [21,63] and at worst |fi|¬g| ≤|fi| · |g|.
Consequently it can be decided in time O(|g|2 · N 2) whether g is implied by
RUPBDD. Finally if g is implied by RUPBDD then it is redundant with respect to
f1 ∧· · ·∧fn; in fact, it is a logical consequence (proof of the following is available
in the extended paper).
Proposition 4. If f1 ∧· · · ∧fn ⊢1 g, then f1 ∧· · · ∧fn ⊨g.
261
Non-clausal Redundancy Properties

262
L. A. Barnett, A. Biere
From RUPBDD the property PR can be directly generalized to this setting as
well. Speciﬁcally, we deﬁne the redundancy property PRBDD as follows.
Deﬁnition 6. Suppose f1, . . . , fn are BDDs and g is a non-constant BDD. Then
g is PRBDD with respect to n
i=1 fi if there is partial assignment {l1, . . . , lk} such
that g|ω = 1 and n
i=1 fi|¬g ⊢1 fj|ω for all 1 ≤j ≤n, where ω = k
i=1 li.
Proposition 2 shows if g is PRBDD with respect to f = f1 ∧· · · ∧fn then g is
redundant with respect to f, thus PRBDD is a redundancy property.
Notice these properties and derivations directly generalize their clausal equiv-
alents; for example, if C is PR with respect to a formula F, then (the BDD
expressing) C is PRBDD with respect to (the set of BDDs expressing) F. Decid-
ing whether a clause C is PR with respect to a formula F is NP-complete [37].
As PRBDD generalizes PR, then PRBDD is NP-hard as well. Further, checking
whether g is PRBDD with respect to f1 ∧· · · ∧fn by some candidate ω can be
done polynomially as argued above, thus the following holds.
Proposition 5. Deciding whether g is PRBDD with respect to f1∧· · ·∧fn, given
the BDDs g, f1, . . . , fn, is NP-complete.
In other words, the decision problems for PR and PRBDD are of equal complexity.
The properties RUPBDD and PRBDD as deﬁned in this section can be used
to show that a BDD can be added to a set of BDDs in a satisﬁability-preserving
way. Of course, any clause has a straightforward and simple representation as a
BDD, so that a formula can be easily represented this way as a set of BDDs. As
a result RUPBDD and PRBDD can be used as systems for refuting unsatisﬁable
formulas. In the following, we identify a clause with its representation as a BDD,
and a formula with its representation as a set of such BDDs.
To simplify the presentation of derivations based on RUPBDD and PRBDD
we introduce an additional redundancy property, allowing derivations to include
steps to directly derive certain BDDs path-wise in the following way.
Deﬁnition 7. f1 ∧· · · ∧fn implies g by RUPpath if (1) f1 ∧· · · ∧fn ⊢1 ¬c for
every c = l1 ∧· · · ∧lm such that l1, . . . , lm is a path from the root of g to the 0
terminal, and (2) |g| ≤log2(|f1| + · · · + |fn|).
If f1∧· · ·∧fn implies g by RUPpath then it is a logical consequence of f1∧· · ·∧fn,
as this checks that no assignment satisﬁes both ¬g and f1 ∧· · ·∧fn. The number
of paths in a BDD g can however be exponential in |g|, as in the BDD for an XOR
constraint, so the second condition ensures RUPpath is polynomially-checkable.
The property RUPpath is primarily useful as it allows the derivation of a
BDD g whose representation as a set of clauses is included in {f1, . . . , fn}: if c
corresponds to a path to 0 in g, the clause ¬c is included in the direct clausal
translation of g. In this context, the restrictive condition (2) in Deﬁnition 7 can
in fact be removed, since the number of paths in g is then at most n.
Deﬁnition 8. A sequence of BDDs g1, . . . , gn is a RUPBDD derivation from
a formula F if F ∧k−1
i=1 gi implies gk by RUPBDD, or by RUPpath, for all
1 ≤k ≤n. A sequence of BDD and assignment pairs (g1, ω1), . . . , (gn, ωn) is

a PRBDD derivation from a formula F if F ∧k−1
i=1 gi implies gk by RUPpath, or
ωk is a PRBDD-witness for gk with respect to F ∧k−1
i=1 gi, for all 1 ≤k ≤n.
As RUPBDD, RUPpath, and PRBDD are redundancy properties, any RUPBDD or
PRBDD derivation corresponds to a redundancy sequence of the same length.
Example 3. Consider the formula F = {a∨b, a∨c, b∨c, a∨d, b∨d, c∨d} and let
g be the BDD such that g(τ) = 1 if and only if τ satisﬁes at least 3 of a, b, c, d;
that is, g is the cardinality constraint {a, b, c, d} ≥3. As seen in Example 2, the
constraint g1 = {a, b, c} ≥2 is RUPBDD with respect to F; similarly so are the
constraints, g2 = {a, c, d} ≥2, and g3 = {b, c, d} ≥2. Now, ¬a ∈U (g3|¬g): for
any τ the assignment π¬g(τ) satisﬁes at most 2 of a, b, c, d, and if a is one of
them then π¬g(τ) surely falsiﬁes g3. As a result, (g3|¬g)|a = 0. In a similar way
¬b ∈U (g2|¬g). Since g1|¬g cofactored by the units ¬a and ¬b is falsiﬁed, then
UnitProp(g1|¬g, g2|¬g, g3|¬g) returns “conﬂict.” Consequently g is RUPBDD with
respect to F ∧g1 ∧g2 ∧g3, and g1, g2, g3, g is a RUPBDD derivation from F.
This example can be generalized to show that RUPBDD is capable of expressing
an inference rule for cardinality constraints called the diagonal sum [40]. For
L = {l1, . . . , ln} let Li = L \ {li}; the diagonal sum derives L ≥k + 1 from the
set of all n constraints Li ≥k.
While the properties and refutation systems RUPBDD and PRBDD easily ex-
tend their clausal counterparts, it is important to notice that redundancy-based
systems using BDDs can be deﬁned in other ways. For instance, say n
i=1 fi im-
plies g by IMPpair if fi|¬g ∧fj|¬g = 0 for some i, j. Then IMPpair is polynomially
checkable, computing the conjunction for each pair i, j. Moreover, it is clear that
f1 ∧f2 ⊨g if and only if f1 ∧f2 implies g by IMPpair. As many logical inference
rules have this form, it is possible that systems based on IMPpair are very strong.
5
Gaussian Elimination
Next, we show how the Gaussian elimination technique for simplifying XOR
constraints embedded in a formula is captured by the redundancy properties
deﬁned in the previous section. Speciﬁcally, if an XOR constraint X is derivable
from a formula F by Gaussian elimination, we show there is a RUPBDD derivation
from F including the BDD expressing X with only a linear size increase.
An XOR clause [x1, . . . , xn]p expresses the function f : BV →B, where
V = {x1, . . . , xn} and p is 0 or 1, such that f(τ) = 1 if and only if the number
of xi ∈V satisﬁed by τ is equal modulo 2 to p. In other words, p expresses the
parity of the positive literals xi an assignment must satisfy in order to satisfy
the XOR clause. As [x, y, y]p and [x]p express the same function, we assume no
variable occurs more than once in an XOR clause. Notice that [ ]0 expresses the
constant function 1, while [ ]1 expresses 0.
The Gaussian elimination procedure begins by detecting XOR clauses en-
coded in a formula F. The direct encoding D(X) of X = [x1, . . . , xn]p is the
collection of clauses of the form C = {l1, . . . , ln}, where each li is either xi or
263
Non-clausal Redundancy Properties

264
L. A. Barnett, A. Biere
¬xi and the number of negated literals in each C is not equal modulo 2 to p The
formula D(X) expresses the same function as X, containing the clauses prevent-
ing each assignment over the variables in X not satisfying X. As a result, D(X)
implies the BDD expressing X by RUPpath (see the extended paper for proof).
Lemma 2. D(X) implies X by RUPpath, for X = [x1, . . . , xn]p.
Similar to the approach of Philipp and Rebola-Pardo [56], we represent
Gaussian elimination steps by deriving the addition X ⊕Y of XOR clauses
X = [x1, . . . , xm, z1, . . . , zr]p and Y = [y1, . . . , yn, z1, . . . , zr]q, given by:
X ⊕Y = [x1, . . . , xm, y1, . . . , yn]p⊕q.
The following lemma shows that X ⊕Y is RUPBDD with respect to X ∧Y ; that
is, if a RUPBDD derivation includes X and Y then X ⊕Y can be derived as well.
This is a result of the following observation: while the precise cofactors of X and
Y by ¬(X ⊕Y ) depend on the variable order ≺, they are the negations of one
another (proof is included in the extended paper).
Lemma 3. Let v be the ≺-greatest variable in occurring in exactly one of X
and Y , and assume v occurs in Y . Then X|¬(X⊕Y ) = X, and Y |¬(X⊕Y ) = ¬X.
The above lemma shows that the procedure UnitProp(X|¬X⊕Y , Y |¬X⊕Y ) re-
turns “conﬂict” immediately, and as a result X ⊕Y is RUPBDD with respect to
f1 ∧· · · ∧fn ∧X ∧Y for any set of BDDs f1, . . . , fn.
Deﬁne a Gaussian elimination derivation Π from a formula F as a sequence of
XOR clauses Π = X1, . . . , XN, such that for all 1 ≤i ≤N, either Xi = Xj ⊕Xk
for j, k < i, or D(Xi) ⊆F. The size of the derivation is |Π| = N
i=1 si, where
si is the number of variables occurring in Xi. We show that Π corresponds to a
RUPBDD derivation with only a linear size increase. This size increase is a result
of the fact that the BDD expressing an XOR clause X = [x1, . . . , xn]p has size
2n + 1 (proof of the following theorem is in the extended paper).
Theorem 3. Suppose Π = X1, . . . , XN is a Gaussian elimination derivation
from a formula F. Then there is a RUPBDD derivation from F with size O(|Π|).
A consequence of this theorem is that RUPBDD includes short refutations
for formulas whose unsatisﬁability can be shown by Gaussian elimination. More
precisely, suppose a formula F includes the direct representations of an unsat-
isﬁable collection of XOR clauses. Then there is a polynomial-length Gaussian
elimination derivation of the unsatisﬁable XOR clause [ ]1 from F [62], and by
Theorem 3, a polynomial-length RUPBDD derivation of the unsatisﬁable BDD 0.
Notably, RUPBDD then includes short refutations of, for example, the Tseitin
formulas, for which no polynomial-length refutations exist in the resolution sys-
tem [64,66]. This limitation of resolution holds as well for the clausal RUP system,
without the ability to introduce new variables, as it can be polynomially simu-
lated by resolution [9,25]. As the translation into RUPBDD used to prove Theo-
rem 3 introduces no new variables, this demonstrates the strength of RUPBDD
compared to resolution and its clausal analog RUP.

p cnf 4 10
-3 -1
2 0
-3
1
2 0
3 -1 -2 0
3
1
2 0
-4 -2
1 0
-4
2 -1 0
4 -2 -1 0
4
2
1 0
-3 -4
0
3
4
0
Lingeling
x 1 2 3 0
x 3 4 0
x -1 2 4 0
d x 1 2 3 0
x 1 2 4 0
0
dxddcheck
Fig. 4: Usage of the tool dxddcheck, showing an example formula and refutation.
6
Results
To begin to assess the practical usefulness of the systems introduced in Section 4,
we have implemented in Python a prototype of a tool called dxddcheck1 for
checking refutations in a subset of RUPBDD. In particular we focus on the result
of Section 5, that Gaussian elimination is succinctly captured by RUPBDD.
We ran the SAT solver Lingeling (version bcp) on a collection of crafted
unsatisﬁable formulas, all of which can be solved using Gaussian elimination.
From Lingeling output we extract a list of XOR clause additions and deletions,
ending with the addition of the empty clause, as shown in Figure 4. This list is
passed directly to dxddcheck, which carries it out as a DRUPBDD refutation; that
is, a RUPBDD refutation also allowing steps which remove or “delete” BDDs from
the set. These deletion steps can be removed without aﬀecting the correctness of
the refutation, though their inclusion can decrease the time required for checking
it, as is the case with DRUP and RUP.
Formula
number of
variables
number of
clauses
solving
time (s)
proof
lines
proof
size (KB)
checking
time (s)
rpar_50
148
394
0.1
297
7
0.34
rpar_100
298
794
0.1
597
15
1.35
rpar_200
598
1594
0.2
1197
35
6.67
mchess_19
680
2291
0.0
1077
41
4.07
mchess_21
836
2827
0.1
1317
50
5.09
mchess_23
1008
3419
0.1
1581
63
6.42
urquhart-s5-b2
107
742
0.0
150
7
0.95
urquhart-s5-b3
121
1116
0.1
150
9
1.64
urquhart-s5-b4
114
888
0.0
150
8
1.20
For these experiments we used a 1.8 GHz Intel Core i5 CPU with 8 GB of
memory. The table shows the time Lingeling took to solve each formula, the
number of lines in the constructed proof and its size, and the time dxddcheck
took to construct and check the associated DRUPBDD proof. These benchmarks
1 Source code is available under the MIT license at http://fmv.jku.at/dxddcheck along
with the benchmarks used and our experimental data.
265
Non-clausal Redundancy Properties

266
L. A. Barnett, A. Biere
are well-known challenging examples in the contexts of XOR reasoning and proof
production. The rpar_ n formulas are compact, permuted encodings of two con-
tradictory parity constraints on n variables, described by Chew and Heule [18].
The mchess_ n formulas are encodings of the mutilated n × n-chessboard prob-
lem, as studied by Heule, Kiesl, and Biere [34] as well as Bryant and Heule [14].
The urquhart formulas [17,65] are examples of hard Tseitin formulas.
Lingeling solved each formula by Gaussian elimination almost instantly. We
ran Lingeling and Kissat [11], winner of the main track of the SAT competition
in 2020, on the benchmarks without Gaussian elimination, as is required for
producing clausal refutations, using an Intel Xeon E5-2620 v4 CPU at 2.10
GHz. Only rpar_50 was solved in under about 10 hours, producing signiﬁcantly
larger proofs; for instance, Kissat produced a refutation of size 6911 MB.
While methods to construct clausal proofs from Gaussian elimination have
been proposed, most are either lacking a public implementation or are limited in
scope [18,56]. An exception is the approach very recently proposed by Gocht and
Nordström using pseudo-Boolean reasoning [26], with which we are interested in
carrying out a thorough comparison of results in the future.
7
Conclusion
We presented a characterization of redundancy for Boolean functions, general-
izing the framework of clausal redundancy and eﬃcient clausal proof systems.
We showed this can be instantiated to design redundancy properties for func-
tions given by BDDs, and polynomially-checkable refutation systems based on
the conjunction of redundant BDDs, including the system PRBDD generalizing
the clausal system PR. The system PRBDD also generalizes RUPBDD, which can
express Gaussian elimination reasoning without extension variables or clausal
translations. The results of a preliminary implementation of a subset of RUPBDD
conﬁrms such refutations are compact and can be eﬃciently checked.
Examples 2 and 3 show RUPBDD reasoning over cardinality constraints, and
we are interested in exploring rules such as generalized resolution [39,40]. Other
forms of non-clausal reasoning may be possible using BDD-based redundancy
systems as well. We are particularly interested in exploring the property IMPpair.
While the system RUPBDD derives only constraints implied by the conjunc-
tion of the formula and previously derived constraints, PRBDD is capable of
interference-based reasoning [30], like its clausal analog PR; there are possibly
novel, non-clausal reasoning techniques taking advantage of this ability. Further,
RUPBDD and PRBDD are based on the conjunction of BDDs, though Theorem 2
is more general and could be used for other ways of expressing Boolean functions.
Finally we are interested in developing an optimized tool for checking proofs in
the system PRBDD, as well as a certiﬁed proof checker.
Acknowledgements. We extend our thanks to Marijn Heule for his helpful
comments on an earlier draft of this paper.

References
1. Abío,
I.,
Nieuwenhuis,
R.,
Oliveras,
A.,
Rodríguez-Carbonell,
E.,
Mayer-
Eichberger, V.: A new look at BDDs for pseudo-Boolean constraints. Journal of Ar-
tiﬁcial Intelligence Research 45, 443–480 (2012). https://doi.org/10.1613/jair.3653
2. Ajtai, M.: The complexity of the pigeonhole principle. Combinatorica 14(4), 417–
433 (1994). https://doi.org/10.1007/BF01302964
3. Akers, S.B.: Binary decision diagrams. IEEE Trans. Computers 27(6), 509–516
(1978). https://doi.org/10.1109/TC.1978.1675141
4. Balyo, T., Heule, M.J.H., Järvisalo, M.: SAT competition 2016: Recent develop-
ments. In: Singh, S.P., Markovitch, S. (eds.) 31st AAAI Conference on Artiﬁcial
Intelligence. pp. 5061–5063. AAAI Press (2017)
5. Barnett, L.A., Biere, A.: Non-clausal redundancy properties (extended version).
Tech. Rep. 21/2, Johannes Kepler University Linz, FMV Reports Series, Institute
for Formal Models and Veriﬁcation, Johannes Kepler University, Altenbergerstr.
69, 4040 Linz, Austria (2021). https://doi.org/10.35011/fmvtr.2021-2
6. Barnett, L.A., Cerna, D., Biere, A.: Covered clauses are not propagation redundant.
In: Peltier, N., Sofronie-Stokkermans, V. (eds.) 10th Intl. Joint Conference on
Automated Reasoning – IJCAR. LNCS, vol. 12166, pp. 32–47. Springer (2020).
https://doi.org/10.1007/978-3-030-51074-9_3
7. Barrett, C., Sebastiani, R., Seshia, S.A., Tinelli, C.: Satisﬁability modulo theories.
In: Biere, A., Heule, M., van Maaren, H., Walsh, T. (eds.) Handbook of Satisﬁa-
bility. pp. 1267–1329. IOS Press (2021). https://doi.org/10.3233/FAIA201017
8. Bayardo, R.J., Schrag, R.: Using CSP look-back techniques to solve real-world SAT
instances. In: Kuipers, B., Webber, B.L. (eds.) 14th AAAI National Conference on
Artiﬁcial Intelligence. pp. 203–208. AAAI Press (1997)
9. Beame, P., Kautz, H., Sabharwal, A.: Towards understanding and harnessing the
potential of clause learning. Journal of Artiﬁcial Intelligence Research 22(1), 319–
351 (2004). https://doi.org/10.1613/jair.1410
10. Biere, A.: CaDiCaL, Lingeling, Plingeling, Treengeling and YalSAT entering the
SAT competition 2018. In: Heule, M.J.H., Järvisalo, M., Suda, M. (eds.) Proc.
of SAT Competition 2018. pp. 13–14. Department of Computer Science Series of
Publications B, University of Helsinki (2018)
11. Biere, A., Fazekas, K., Fleury, M., Heisinger, M.: CaDiCaL, Kissat, Paracooba,
Plingeling and Treengeling entering the SAT Competition 2020. In: Balyo, T.,
Froleyks, N., Heule, M., Iser, M., Järvisalo, M., Suda, M. (eds.) Proc. of SAT
Competition 2020 – Solver and Benchmark Descriptions. Department of Computer
Science Report Series B, vol. B-2020-1, pp. 51–53. University of Helsinki (2020)
12. Biere, A., Järvisalo, M., Kiesl, B.: Preprocessing in SAT solving. In: Biere, A.,
Heule, M., van Maaren, H., Walsh, T. (eds.) Handbook of Satisﬁability. pp. 391–
435. IOS Press (2021). https://doi.org/10.3233/FAIA200992
13. Bryant,
R.E.:
Graph-based
algorithms
for
Boolean
function
manip-
ulation.
IEEE
Transactions
on
Computers
35(8),
677–691
(1986).
https://doi.org/10.1109/TC.1986.1676819
14. Bryant, R.E., Heule, M.J.H.: Generating extended resolution proofs with a BDD-
based SAT solver. In: Groote, J.F., Larsen, K.G. (eds.) 27th Intl. Conference on
Tools and Algorithms for the Construction and Analysis of Systems – TACAS.
LNCS, vol. 12651, pp. 76–93. Springer (2021). https://doi.org/10.1007/978-3-030-
72016-2_5
267
Non-clausal Redundancy Properties

268
L. A. Barnett, A. Biere
15. Burch, J.R., Clarke, E.M., Long, D.E., McMillan, K.L., Dill, D.L.: Symbolic model
checking for sequential circuit veriﬁcation. IEEE Trans. Comput. Aided Des. Integr.
Circuits Syst. 13(4), 401–424 (1994). https://doi.org/10.1109/43.275352
16. Buss, S., Thapen, N.: DRAT proofs, propagation redundancy, and extended reso-
lution. In: Janota, M., Lynce, I. (eds.) 22nd Intl. Conference on Theory and Ap-
plications of Satisﬁability Testing – SAT. LNCS, vol. 11628, pp. 71–89. Springer
(2019). https://doi.org/10.1007/978-3-030-24258-9_5
17. Chatalic, P., Simon, L.: Multi-resolution on compressed sets of clauses. In: 12th
IEEE Intl. Conference on Tools with Artiﬁcial Intelligence – ICTAI. pp. 2–10.
IEEE Computer Society (2000). https://doi.org/10.1109/TAI.2000.889839
18. Chew, L., Heule, M.J.H.: Sorting parity encodings by reusing variables. In:
Pulina, L., Seidl, M. (eds.) 23rd Intl. Conference on Theory and Applications
of Satisﬁability Testing – SAT. LNCS, vol. 12178, pp. 1–10. Springer (2020).
https://doi.org/10.1007/978-3-030-51825-7_1
19. Clarke, E., Biere, A., Raimi, R., Zhu, Y.: Bounded model checking using
satisﬁability solving. Formal Methods in System Design 19(1), 7–34 (2001).
https://doi.org/10.1023/A:1011276507260
20. Coudert, O., Berthet, C., Madre, J.C.: Veriﬁcation of synchronous sequential ma-
chines based on symbolic execution. In: Sifakis, J. (ed.) Intl. Workshop on Auto-
matic Veriﬁcation Methods for Finite State Systems. LNCS, vol. 407, pp. 365–373.
Springer (1990). https://doi.org/10.1007/3-540-52148-8_30
21. Coudert,
O.,
Madre,
J.C.:
A
uniﬁed
framework
for
the
formal
veriﬁ-
cation
of
sequential
circuits.
In:
IEEE
Intl.
Conference
on
Computer-
Aided
Design
–
ICCAD.
pp.
126–129.
IEEE
Computer
Society
(1990).
https://doi.org/10.1109/ICCAD.1990.129859
22. Coudert, O., Madre, J.C., Berthet, C.: Verifying temporal properties of sequential
machines without building their state diagrams. In: Clarke, E.M., Kurshan, R.P.
(eds.) 2nd Intl. Workshop on Computer Aided Veriﬁcation – CAV. LNCS, vol. 531,
pp. 23–32. Springer (1990). https://doi.org/10.1007/BFb0023716
23. Damiano, R.F., Kukula, J.H.: Checking satisﬁability of a conjunction of BDDs.
In: 40th Design Automation Conference – DAC. pp. 818–823. ACM (2003).
https://doi.org/10.1145/775832.776039
24. Franco, J., Kouril, M., Schlipf, J., Ward, J., Weaver, S., Dransﬁeld, M., Vanﬂeet,
W.M.: SBSAT: a state-based, BDD-based satisﬁability solver. In: Giunchiglia,
E., Tacchella, A. (eds.) 6th Intl. Conference on Theory and Applications of
Satisﬁability Testing – SAT. LNCS, vol. 2919, pp. 398–410. Springer (2004).
https://doi.org/10.1007/978-3-540-24605-3_30
25. Gelder, A.: Verifying RUP proofs of propositional unsatisﬁability. In: 10th Intl.
Symposium on Artiﬁcial Intelligence and Mathematics – ISAIM (2008)
26. Gocht, S., Nordström, J.: Certifying parity reasoning eﬃciently using pseudo-
Boolean proofs. In: 35th AAAI Conference on Artiﬁcial Intelligence. AAAI Press
(2021), to appear
27. Goldberg, E.I., Novikov, Y.: Veriﬁcation of proofs of unsatisﬁability for CNF for-
mulas. In: Conference on Design, Automation and Test in Europe– DATE. pp. 886–
891. IEEE Computer Society (2003). https://doi.org/10.1109/DATE.2003.10008
28. Goldberg, E.I., Prasad, M.R., Brayton, R.K.: Using SAT for combinational equiv-
alence checking. In: Nebel, W., Jerraya, A. (eds.) Conference on Design, Automa-
tion and Test in Europe – DATE. pp. 114–121. IEEE Computer Society (2001).
https://doi.org/10.1109/DATE.2001.915010

29. Groote, J.F., Tveretina, O.: Binary decision diagrams for ﬁrst-order pred-
icate
logic.
J.
Log.
Algebraic
Methods
Program.
57(1-2),
1–22
(2003).
https://doi.org/10.1016/S1567-8326(03)00039-0
30. Heule, M., Kiesl, B.: The potential of interference-based proof systems. In: Reger,
G., Traytel, D. (eds.) 1st Intl. Workshop on Automated Reasoning: Challenges,
Applications, Directions, Exemplary Achievements – ARCADE. EPiC Series in
Computing, vol. 51, pp. 51–54. EasyChair (2017)
31. Heule, M.J.H., Biere, A.: All about Proofs, Proofs for All, Mathematical Logic and
Foundations, vol. 55, chap. Proofs for Satisﬁability Problems, pp. 1–22. College
Publications (2015)
32. Heule, M.J.H., Järvisalo, M., Lonsing, F., Seidl, M., Biere, A.: Clause elimination
for SAT and QSAT. Journal of Artiﬁcial Intelligence Research 53(1), 127–168
(2015). https://doi.org/10.1613/jair.4694
33. Heule, M.J.H., Kiesl, B., Biere, A.: Short proofs without new variables. In:
de Moura, L. (ed.) 26th Intl. Conference on Automated Deduction – CADE. LNCS,
vol. 10395, pp. 130–147. Springer (2017). https://doi.org/10.1007/978-3-319-63046-
5_9
34. Heule, M.J.H., Kiesl, B., Biere, A.: Clausal proofs of mutilated chessboards. In:
Badger, J.M., Rozier, K.Y. (eds.) 11th NASA Formal Methods Symposium – NFM.
LNCS, vol. 11460, pp. 204–210. Springer (2019). https://doi.org/10.1007/978-3-
030-20652-9_13
35. Heule, M.J.H., Kiesl, B., Biere, A.: Encoding redundancy for satisfaction-driven
clause learning. In: Vojnar, T., Zhang, L. (eds.) 25th Intl. Conference on Tools and
Algorithms for the Construction and Analysis of Systems – TACAS. LNCS, vol.
11427, pp. 41–58. Springer (2019). https://doi.org/10.1007/978-3-030-17462-0_3
36. Heule, M.J.H., Kiesl, B., Biere, A.: Strong extension-free proof systems. Journal
of Automated Reasoning 64(3), 533–554 (2020). https://doi.org/10.1007/s10817-
019-09516-0
37. Heule, M.J.H., Kiesl, B., Seidl, M., Biere, A.: PRuning through satisfac-
tion.
In:
Strichman,
O.,
Tzoref-Brill,
R.
(eds.)
13th
Intl.
Haifa
Veriﬁca-
tion Conference – HVC. LNCS, vol. 10629, pp. 179–194. Springer (2017).
https://doi.org/10.1007/978-3-319-70389-3_12
38. Heule, M.J.H., Kullmann, O., Marek, V.W.: Solving and verifying the Boolean
Pythagorean triples problem via cube-and-conquer. In: Creignou, N., Le Berre, D.
(eds.) 19th Intl. Conference on Theory and Applications of Satisﬁability Testing –
SAT. LNCS, vol. 9710, pp. 228–245. Springer (2016). https://doi.org/10.1007/978-
3-319-40970-2_15
39. Hooker, J.N.: Generalized resolution and cutting planes. Annals of Operations
Research 12, 217–239 (1988). https://doi.org/10.1007/BF02186368
40. Hooker,
J.N.:
Generalized
resolution
for
0-1
linear
inequalities.
An-
nals
of
Mathematics
and
Artiﬁcial
Intelligence
6,
271–286
(1992).
https://doi.org/10.1007/BF01531033
41. Hosaka, K., Takenaga, Y., Kaneda, T., Yajima, S.: Size of ordered binary decision
diagrams representing threshold functions. Theor. Comput. Sci. 180(1-2), 47–60
(1997). https://doi.org/10.1016/S0304-3975(97)83807-8
42. Järvisalo, M., Biere, A., Heule, M.J.H.: Blocked clause elimination. In: Esparza,
J., Majumdar, R. (eds.) 16th Intl. Conference on Tools and Algorithms for the
Construction and Analysis of Systems – TACAS. LNCS, vol. 6015, pp. 129–144.
Springer (2010). https://doi.org/10.1007/978-3-642-12002-2_10
269
Non-clausal Redundancy Properties

270
L. A. Barnett, A. Biere
43. Järvisalo, M., Heule, M.J.H., Biere, A.: Inprocessing rules. In: Gramlich, B., Miller,
Dalea nd Sattler, U. (eds.) 6th Intl. Joint Conference on Automated Reasoning – IJ-
CAR. LNCS, vol. 7364, pp. 355–370. Springer (2012). https://doi.org/10.1007/978-
3-642-31365-3_28
44. Kaiss, D., Skaba, M., Hanna, Z., Khasidashvili, Z.: Industrial strength SAT-based
alignability algorithm for hardware equivalence veriﬁcation. In: 7th Intl. Confer-
ence on Formal Methods in Computer Aided Design – FMCAD. pp. 20–26. IEEE
Computer Society (2007). https://doi.org/10.1109/FAMCAD.2007.37
45. Kiesl, B., Seidl, M., Tompits, H., Biere, A.: Super-blocked clauses. In: Olivetti, N.,
Tiwari, A. (eds.) 8th Intl. Joint Conference on Automated Reasoning – IJCAR.
LNCS, vol. 9706, pp. 45–61. Springer (2016). https://doi.org/10.1007/978-3-319-
40229-1_5
46. Konev,
B.,
Lisitsa,
A.:
Computer-aided
proof
of
Erdős
dis-
crepancy
properties.
Artiﬁcial
Intelligence
224,
103–118
(2015).
https://doi.org/10.1016/j.artint.2015.03.004
47. Kuehlmann, A., Krohm, F.: Equivalence checking using cuts and heaps. In: Yoﬀa,
E.J., Micheli, G.D., Rabaey, J.M. (eds.) 34th Design Automation Conference –
DAC. pp. 263–268. ACM (1997). https://doi.org/10.1145/266021.266090
48. Kullmann, O.: On a generalization of extended resolution. Discrete Applied Math-
ematics 96-97, 149–176 (1999). https://doi.org/10.1016/S0166-218X(99)00037-2
49. Lee, C.Y.: Representation of switching circuits by binary-decision programs. The
Bell System Technical Journal 38(4), 985–999 (1959)
50. Manthey, N.: Coprocessor 2.0 – a ﬂexible CNF simpliﬁer. In: Cimatti, A., Se-
bastiani, R. (eds.) 15th Intl. Conference on Theory and Applications of Satis-
ﬁability Testing – SAT 2012. LNCS, vol. 7317, pp. 436–441. Springer (2012).
https://doi.org/10.1007/978-3-642-31612-8_34
51. Marques-Silva,
J.P.,
Sakallah,
K.A.:
GRASP
-
a
new
search
algorithm
for
satisﬁability.
In:
IEEE
Intl.
Conference
on
Computer
Aided
De-
sign
–
ICCAD.
pp.
220–227.
IEEE
Computer
Society
/
ACM
(1996).
https://doi.org/10.1109/ICCAD.1996.569607
52. Motter, D.B., Markov, I.L.: A compressed breadth-ﬁrst search for satisﬁability.
In: Mount, D.M., Stein, C. (eds.) 4th Intl. Workshop on Algorithm Engineer-
ing and Experiments – ALENEX. LNCS, vol. 2409, pp. 29–42. Springer (2002).
https://doi.org/10.1007/3-540-45643-0_3
53. Olivo, O., Emerson, E.A.: A more eﬃcient BDD-based QBF solver. In: Lee, J.
(ed.) 17th Intl. Conference on Principles and Practice of Constraint Programming
– CP. pp. 675–690. LNCS, Springer (2011). https://doi.org/10.1007/978-3-642-
23786-7_51
54. Pan, G., Vardi, M.Y.: Search vs. symbolic techniques in satisﬁability solving. In: 7th
Intl. Conference on Theory and Applications of Satisﬁability Testing – SAT. LNCS,
vol. 3542, pp. 235–250. Springer (2004). https://doi.org/10.1007/11527695_19
55. Papadimitriou, C., Yannakakis, M.: The complexity of facets (and some facets of
complexity). Journal of Computer and System Sciences 28(2), 244–259 (1984).
https://doi.org/10.1016/0022-0000(84)90068-0
56. Philipp, T., Rebola-Pardo, A.: DRAT proofs for XOR reasoning. In: Michael, L.,
Kakas, A.C. (eds.) 15th European Conference on Logics in Artiﬁcial Intelligence –
JELIA. LNCS, vol. 10021, pp. 415–429 (2016). https://doi.org/10.1007/978-3-319-
48758-8_27
57. Posegga, J., Ludäscher, B.: Towards ﬁrst-order deduction based on Shan-
non
graphs.
In:
Ohlbach,
H.J.
(ed.)
16th
German
Conference
on
Arti-

ﬁcial
Intelligence
–
GWAI.
LNCS,
vol.
671,
pp.
67–75.
Springer
(1992).
https://doi.org/10.1007/BFb0018993
58. Roussel, O., Manquinho, V.: Pseudo-Boolean and cardinality constraints. In: Biere,
A., Heule, M., van Maaren, H., Walsh, T. (eds.) Handbook of Satisﬁability. pp.
1087–1129. IOS Press (2021). https://doi.org/10.3233/978-1-58603-929-5-695
59. Sieling, D., Wegener, I.: Reduction of OBDDs in linear time. Information Process-
ing Letters 48(3), 139 – 144 (1993). https://doi.org/10.1016/0020-0190(93)90256-9
60. Sinz, C., Biere, A.: Extended resolution proofs for conjoining BDDs. In: Grigoriev,
D., Harrison, J., Hirsch, E.A. (eds.) Computer Science - Theory and Applications,
1st Intl. Computer Science Symposium in Russia – CSR. vol. 3967, pp. 600–611.
Springer (2006). https://doi.org/10.1007/11753728_60
61. Soos, M., Gocht, S., Meel, K.S.: Tinted, detached, and lazy CNF-XOR solving and
its applications to counting and sampling. In: Lahiri, S.K., Wang, C. (eds.) 32nd
Intl. Conference on Computer Aided Veriﬁcation – CAV. LNCS, vol. 12224, pp.
463–484. Springer (2020). https://doi.org/10.1007/978-3-030-53288-8_22
62. Soos, M., Nohl, K., Castelluccia, C.: Extending SAT solvers to cryptographic
problems. In: Kullmann, O. (ed.) 12th Intl. Conference on Theory and Appli-
cations of Satisﬁability Testing – SAT. pp. 244–257. LNCS, Springer (2009).
https://doi.org/10.1007/978-3-642-02777-2_24
63. Touati, H.J., Savoj, H., Lin, B., Brayton, R.K., Sangiovanni-Vincentelli, A.L.: Im-
plicit state enumeration of ﬁnite state machines using BDDs. In: IEEE Intl. Confer-
ence on Computer-Aided Design – ICCAD. pp. 130–133. IEEE Computer Society
(1990). https://doi.org/10.1109/ICCAD.1990.129860
64. Tseitin, G.S.: On the complexity of derivation in propositional calculus. In: Slis-
senko, A.O. (ed.) Studies in Constructive Mathematics and Mathematical Logic,
vol. 2, pp. 115–125. Steklov Mathematical Institute (1970)
65. Urquhart, A.: Hard examples for resolution. Journal of the ACM 34(1), 209–219
(1987). https://doi.org/10.1145/7531.8928
66. Urquhart, A.: The complexity of propositional proofs. Bulletin of Symbolic Logic
1(4), 425–467 (12 1995). https://doi.org/10.2307/421131
67. Voronkov, A.: AVATAR: The architecture for ﬁrst-order theorem provers. In: Biere,
A., Bloem, R. (eds.) 26th Intl. Conference on Computer Aided Veriﬁcation – CAV.
LNCS, vol. 8559, pp. 696–710. Springer (2014). https://doi.org/10.1007/978-3-319-
08867-9_46
68. Warners, J.P., Maaren, H.V., Warners, J.P., Maaren, H.V.: A two phase algorithm
for solving a class of hard satisﬁability problems. Operations Research Letters 23,
81–88 (1998). https://doi.org/10.1016/S0167-6377(98)00052-2
69. Wetzler, N., Heule, M.J.H., Hunt, W.A.: DRAT-trim: Eﬃcient checking and trim-
ming using expressive clausal proofs. In: Sinz, C., Egly, U. (eds.) 17th Intl. Confer-
ence on Theory and Applications of Satisﬁability Testing – SAT. LNCS, vol. 8561,
pp. 422–429. Springer (2014). https://doi.org/10.1007/978-3-319-09284-3_31
271
Non-clausal Redundancy Properties

272
L. A. Barnett, A. Biere
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Multi-Dimensional Interpretations for
Termination of Term Rewriting
National Institute of Advanced Industrial Science and Technology, Tokyo, Japan
Abstract. Interpretation methods constitute a foundation of termina-
tion analysis for term rewriting. From time to time remarkable instances
of interpretation methods appeared, such as polynomial interpretations,
matrix interpretations, arctic interpretations, and their variants. In this
paper we introduce a general framework, the multi-dimensional interpre-
tation method, that subsumes these variants as well as many previously
unknown interpretation methods as instances. Employing the notion of
derivers, we prove the soundness of the proposed method in an elegant
way. We implement the proposed method in the termination prover NaTT
and verify its signiﬁcance through experiments.
1
Introduction
Term rewriting [2] is a formalism for reasoning about function deﬁnitions or func-
tional programs. For instance, a term rewrite system (TRS) Rfact [7] consisting
of the following rewrite rules deﬁnes the factorial function:
fact(0) →s(0)
fact(s(x)) →mul(s(x), fact(p(s(x))))
p(s(x)) →x
assuming that s, p, and mul are interpreted respectively as the successor, pre-
decessor, and multiplication functions.
Analyzing whether a TRS terminates, meaning that the corresponding
functional program responds or the function is well deﬁned, has been an
active research area for decades. Consequently, several fully automatic termi-
nation provers have been developed, e.g., AProVE [10], TTT2 [20], CiME [5],
MU-TERM [23], and NaTT [34], and have been competing in the annual Ter-
mination Competitions (TermCOMP) [11].
Throughout their history, interpretation methods [25] have been foundational
in termination analysis. They are categorized by the choice of well-founded car-
riers and the class of functions as which symbols are interpreted. Polynomial
interpretations [22] use the natural numbers N as the carrier and interpretations
are monotone polynomials, i.e., every variable has coeﬃcient at least 1. Weakly
monotone polynomials, i.e., zero coeﬃcients, are allowed in the dependency pair
method [1]. Negative constants are allowed using the max operator [15]. Gen-
eral combinations of polynomials and the max operator are proposed in both the
standard [37] and the dependency pair settings [9]. Negative coeﬃcients and thus
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5_16
Akihisa Yamada
273–290, 2021.

274
Akihisa Yamada
non-monotone polynomials are also allowed, but in a more elaborated theoretical
framework [15,9].
These methods share the common carrier N. In contrast, matrix interpre-
tations [16,8] choose vectors over N as the carrier, and interpret symbols as
aﬃne maps over it. Although the carrier is generalized, matrix interpretations
do not properly generalize polynomial interpretations, since not all polynomi-
als are aﬃne. This gap can be ﬁlled by improved matrix interpretations, that
further generalize the carrier to square matrices [6], so that natural polynomial
interpretations can be subsumed by matrix polynomials over 1 × 1 matrices.
In arctic interpretations [19], the carrier consists of vectors over arctic naturals
(N ∪{−∞}) or integers (Z ∪{−∞}), and interpretations are aﬃne maps over it,
where aﬃnity is with respect to the max/plus semiring.
Having this many variations would be welcome if you are a user of a ter-
mination tool in which someone else has already implemented all of them. It
would not be so if you are the developer of a termination tool in which you
will have to implement all of them. Also, to ultimately trust termination tools,
one needs to formalize proof methods using proof assistants and obtain trusted
certiﬁer that validates outputs of termination tools, see, e.g., IsaFoR/CeTA [31]
or CoLoR/Rainbow [4] frameworks. Although some interpretation methods have
already been formalized [28,30], adding missing variants one by one would cost
a signiﬁcant eﬀort.
In this paper, we introduce a general framework for interpretation methods,
which subsumes most of the above-mentioned methods as instances, namely,
(max-)polynomial interpretations (with negative constants), (improved) matrix
interpretations, and arctic interpretations, as well as a syntactic method called
argument ﬁltering [1,21]. Moreover, we obtain a bunch of previously unexplored
interpretation methods as other instances.
After preliminaries, we start with a convenient fact about reduction pairs, a
central tool in termination proving with dependency pairs (Section 3).
The ﬁrst step to the main contribution is the use of derivers [24,33], which
allow us to abstract away the mathematical details of polynomials or max-
polynomials. We will obtain a key soundness result that derivers derive monotone
interpretations from monotone interpretations (Section 4).
The second step is to extend derivers to multi-dimensional ones. This setting
further generalizes (improved) matrix interpretations, so that max-polynomials,
negative constants, and negative entries are allowed (Section 5). It will also
be hinted that multi-dimensional derivers can emulate the eﬀect of negative
coeﬃcients, although theoretical comparison is left for future work. We also show
that our approach subsumes arctic interpretations by adding a treatment for −∞
(Section 6). Although the original formulation by Koprowski and Waldmann [19]
has some trickiness, we will show that our simpler formulation is suﬃcient.
As strict monotonicity is crucial for proving termination without dependency
pairs, and is still useful with dependency pairs, we will see how to ensure strict
monotonicity (Section 7). At this point, the convenient fact we have seen in
Section 3 becomes crucial.

Multi-Dimensional Interpretations for Termination of Term Rewriting
275
Finally, the proposed method is implemented in the termination prover NaTT,
and experimental results are reported (Section 8). We evaluate various instances
of our method, some corresponding to known interpretation methods and many
others not. We choose two new instances to integrate to the NaTT strategy. The
new strategy proved the termination of 20 more benchmarks than the old one,
and ﬁve of them were not proved by any tool in TermCOMP 2020.
2
Preliminaries
We start with order-sorted algebras. Let S = ⟨S, ⊑⟩be a partially ordered set,
where elements in S are called sorts and ⊑is called the subsort relation. An
S-sorted set is an S-indexed family A = {Aσ}σ∈S such that σ ⊑τ implies
Aσ ⊆Aτ. We write A(σ1,...,σn) for the set Aσ1 ×· · ·×Aσn. A sorted map between
S-sorted sets X and A is a mapping f, written f : X →A, such that x ∈Xσ
implies f(x) ∈Aσ.
An S-sorted signature is an S∗× S-indexed family F = {F⃗σ,τ}⟨⃗σ,τ⟩∈S∗×S of
function symbols.1 When f ∈F(σ1,...,σn),τ, we say f has rank (σ1, . . . , σn) →τ
and arity n in F. We may also view sorted sets and signatures as sets: having
a : σ ∈A means a ∈Aσ, and f : ⃗σ →τ ∈F means f ∈F⃗σ,τ.
Example 1. Consider sort Nat. We deﬁne the following {Nat}-sorted signatures:
– N := {0 : () →Nat, 1 : () →Nat, 2 : () →Nat, . . . }
– N* := N ∪{* : (Nat, Nat) →Nat}
– N+ := N ∪{+ : (Nat, Nat) →Nat}
– Nmax := N ∪{max : (Nat, Nat) →Nat}
Let us abbreviate unions of signatures by concatenations of subscripts: for in-
stance N*+max denotes N* ∪N+ ∪Nmax. Next consider sorts Neg and Int with
Nat, Neg ⊑Int. We deﬁne the following {Nat, Neg, Int}-sorted signatures:
– Z := N ∪{0 : () →Neg, -1 : () →Neg, -2 : () →Neg, . . . }
– Z* := Z ∪N* ∪{* : (Neg, Neg) →Nat, * : (Int, Int) →Int}
– Z+ := Z ∪N+ ∪{+ : (Neg, Neg) →Neg, + : (Int, Int) →Int}
– Zmax := Z ∪Nmax ∪
{max : (Nat, Int) →Nat, max : (Int, Nat) →Nat, max : (Int, Int) →Int}
For an S-sorted signature F, an F-algebra ⟨A, [·]⟩consists of an S-sorted set
A called the carrier and a family [·] of mappings called the interpretation such
that [f] : A⃗σ →Aτ whenever f ∈F⃗σ,τ.
Example 2. We consider the following standard interpretation ·:
· · ·
-2 := −2
-1 := −1
0 := 0
1 := 1
2 := 2
· · ·
*(a, b) := a · b
+(a, b) := a + b
max(a, b) := max(a, b)
Notice that ⟨N, ·⟩is an N*+max-algebra and ⟨Z, ·⟩is a Z*+max-algebra. Here,
the {Nat}-sorted set N is deﬁned by NNat := N and the {Nat, Neg, Int}-sorted
set Z is deﬁned by ZNat := N, ZNeg := {0, −1, −2, . . . } and ZInt := Z.
1 In the literature, sorted signatures are given more assumptions such as monotonicity
or regularity. For the purpose of this paper, these assumptions are not necessary.

276
Akihisa Yamada
Sorted Terms: Given an S-sorted signature F and an S-sorted set V of variables,
the S-sorted set T (F, V) of terms is inductively deﬁned as follows:
– v ∈T (F, V)σ if v ∈Vσ;
– f(s1, . . . , sn) ∈T (F, V)ρ if f ∈F⃗σ,τ, (s1, . . . , sn) ∈T (F, V)⃗σ, and τ ⊑ρ.
An interpretation [·] is extended over terms as follows: given α : V →A,
[x]α := α(x) if x ∈Vσ, and [f(s1, . . . , sn)]α := [f]([s1]α, . . . , [sn]α). The F-
algebra ⟨T (F, V), ·⟩(which interprets f as the mapping that takes (s1, . . . , sn)
and returns f(s1, . . . , sn)) is called the term algebra, and a sorted map θ : V →
T (F, V) is called a substitution. The term obtained by replacing every variable
x by θ(x) in s is thus sθ.
Term Rewriting: This paper is concerned with termination analysis for plain
term rewriting. In this setting, there is only one sort 1, and we may identify a
{1}-sorted set A and the set A1. The set of variables appearing in a term s is
denoted by Var(s). A context C is a term with a special variable □occurring
exactly once. We denote by C[s] the term obtained by substituting □by s in
C. A rewrite rule is a pair of terms l and r, written l →r, such that l /∈V
and Var(l) ⊇Var(r). A term rewrite system (TRS) is a set R of rewrite rules,
which induces the root rewrite step
ϵ−→
R
and the rewrite step −→
R
as the least
relations such that lθ
ϵ−→
R
rθ and C[lθ] −→
R
C[rθ], for any rule l →r ∈R,
substitution θ, and context C. A TRS R is terminating iﬀno inﬁnite rewriting
s1 −→
R s2 −→
R s3 −→
R · · · is possible.
The dependency pair (DP) framework [1,14,13] is a de facto standard among
automated termination provers for term rewriting. Here we brieﬂy recapitulate
its essence. The root symbol of a term s = f(s1, . . . , sn) is f and is denoted by
root(s). The set of deﬁned symbols in R is DR := {root(l) | l →r ∈R}. We
assume a fresh marked symbol f ♯for every f ∈DR, and write s♯to denote the
term f ♯(s1, . . . , sn) for s = f(s1, . . . , sn). A dependency pair of a TRS R is a
rule l♯→r♯such that root(r) ∈DR and l →C[r] ∈R for some context C. The
set of all dependency pairs of R is denoted by DP(R). A DP problem ⟨P, R⟩is
just a pair of TRSs.
Theorem 1 ([1]). A TRS R is terminating iﬀthe DP problem ⟨DP(R), R⟩is
ﬁnite, i.e., there is no inﬁnite chain s0
ϵ
−−−−→
DP(R) t0 −→
R
∗s1
ϵ
−−−−→
DP(R) t1 −→
R
∗· · · .
A number of techniques called DP processors that simplify or decompose DP
problems are proposed; see [13] for a list of such processors. Among them, the
central technique for concluding the ﬁniteness of DP problems is the reduction
pair processor, which will be reformulated in the next section.
3
Notes on Reduction Pairs
A reduction pair is a pair ⟨≿, ≻⟩of order-like relations over terms with some con-
ditions. Here we introduce two formulations of reduction pairs, one demanding

Multi-Dimensional Interpretations for Termination of Term Rewriting
277
natural assumptions of orderings, and the other, reduction pair seed, demanding
only essential requirements. The ﬁrst formulation is useful when proving prop-
erties of reduction pairs, while the latter is useful when devising new reduction
pairs. We will show that the two notions are essentially equivalent: one can al-
ways extend a reduction pair seed into a reduction pair of the former sense.
Existing formulations of reduction pairs lie strictly in between the two.
Deﬁnition 1 (reduction pair). A (quasi-)order pair ⟨≿, ≻⟩is a pair of a
quasi-order ≿and an irreﬂexive relation ≻⊆≿satisfying compatibility:
≿; ≻; ≿⊆≻. The order pair is well-founded if ≻is well-founded.
A reduction pair is a well-founded order pair ⟨≿, ≻⟩on terms, such that both
≿and ≻are closed under substitutions, and ≿is closed under contexts. Here, a
relation ⊐is closed under substitutions (resp. contexts) iﬀs ⊐t implies sθ ⊐tθ
for every substitution θ (resp. C[s] ⊐C[t] for every context C).
The above formulation of reduction pairs is strictly subsumed by standard
deﬁnitions (e.g., [1,14,13]), where ≻is not necessarily a subset of ≿, and com-
patibility is weakened to either ≿; ≻⊆≻or ≻; ≿⊆≻. Instead, ≻is required to
be transitive but this follows from our assumptions ≻⊆≿and compatibility:
≻; ≻⊆≿; ≻⊆≻. On one hand, this means that we can safely import existing
results of reduction pairs into our formulation.
Theorem 2 (reduction pair processor [14,13]). Let ⟨P, R⟩be a DP problem
and ⟨≿, ≻⟩be a reduction pair such that P∪R ⊆≿. Then the DP problem ⟨P, R⟩
is ﬁnite if and only if ⟨P \ ≻, R⟩is.
Example 3. Consider again the TRS Rfact of the introduction. Proving that
Rfact terminates in the DP framework boils down to ﬁnding a reduction pair
⟨≿, ≻⟩satisfying (considering usable rules [1]):
p(s(x)) ≿x
fact♯(s(x)) ≻fact♯(p(s(x)))
On the other hand, one may wonder whether Deﬁnition 1 might be too
restrictive. We justify our formulation by uniformly extending general “reduction
pairs” into reduction pairs that comply with Deﬁnition 1. This is possible for
even more general pairs of relations than standard reduction pairs.
Deﬁnition 2 (reduction pair seed). A well-founded order seed is a pair
⟨W, S⟩of relations such that S is well-founded and S; W ⊆S+. A reduction
pair seed is a well-founded order seed on terms such that both W and S are
closed under substitutions, and W is closed under contexts.
Now we show that every reduction pair seed ⟨W, S⟩can be extended to a
reduction pair ⟨≿, ≻⟩such that W ⊆≿and S ⊆≻. Before that, the assumption
S; W ⊆S+ of Deﬁnition 2 is generalized as follows.
Lemma 1. If ⟨W, S⟩is a well-founded order seed, then S; W ∗⊆S+.
Proof. By induction on the number of W steps.
⊓⊔

278
Akihisa Yamada
Theorem 3. Let ⟨W, S⟩be a well-founded order seed. Then ⟨≿, ≻⟩is a well-
founded order pair, where ≿:= (W ∪S)∗and ≻:= (W ∗; S)+.
Proof. It is trivial that ≿is a quasi-order and ≻⊆≿by deﬁnition. We show the
well-foundedness of ≻as follows: Suppose on the contrary we have an inﬁnite
sequence:
a1 W ∗b1 S a2 W ∗b2 S a3 W ∗b2 S · · ·
Then using Lemma 1 (S; W ∗⊆S+) we obtain a1 W ∗b1 S+ b2 S+ · · · , which
contradicts the well-foundedness of S.
Now we show compatibility. By deﬁnition we have ≿; ≻⊆≻, so it suﬃces to
show ≻; ≿⊆≻. By induction we reduce the claim to ≻; (W ∪S) ⊆≻, that is,
both ≻; W ⊆≻and ≻; S ⊆≻. Using S; W ⊆S+ = S; S∗we have
≻; W = (W ∗; S)+; W = (W ∗; S)∗; W ∗; S; W
⊆(W ∗; S)∗; W ∗; S; S∗⊆≻
The other case ≻; S ⊆≻is easy from the deﬁnition.
⊓⊔
Now we obtain the following corollary of Theorem 2 and Theorem 3.
Corollary 1. Let ⟨P, R⟩be a DP problem and ⟨W, S⟩a reduction pair seed such
that P ∪R ⊆W. Then ⟨P, R⟩is ﬁnite if and only if ⟨P \ S, R⟩is.
Notice that Deﬁnition 2 does not demand any order-like property, most no-
tably transitivity. This is beneﬁcial when developing new reduction pairs; for
instance, higher-order recursive path orders [17] are known to be non-transitive,
but form a reduction pair seed with their reﬂexive closure. Throughout the pa-
per we use Deﬁnition 1, since it provides more useful and natural properties of
orderings, which becomes crucial in Section 7.
4
Interpretation Methods as Derivers
Interpretation methods construct reduction pairs from F-algebras, where F is
the {1}-sorted signature of an input TRS or DP problem, and the carrier is a
mathematical structure where a well-founded ordering > is known. In the DP
framework, weakly monotone F-algebras play an important role.
Deﬁnition 3 (weakly monotone algebra). A mapping f : A1×· · ·×An →A
is monotone with respect to ⊐if f(a1, . . . , ai, . . . , an) ⊐f(a1, . . . , a′
i, . . . , an)
whenever a1 ∈A1, . . . , an ∈An, a′
i ∈Ai, and ai ⊐a′
i. A weakly monotone
F-algebra ⟨A, [·], ≥, >⟩consists of an F-algebra ⟨A, [·]⟩and an order pair ⟨≥, >⟩
such that every [f] is monotone with respect to ≥.
Example 4. Continuing Example 2, ⟨N, ·, ≥, >⟩is a weakly monotone N*+max-
algebra with the standard ordering ⟨≥, >⟩. Notice that ⟨Z, ·, ≥, >⟩is not a
weakly monotone Z*+max-algebra, since multiplication on integers is not neces-
sarily monotone. Nevertheless, it is a weakly monotone Z+max ∪N*-algebra.

Multi-Dimensional Interpretations for Termination of Term Rewriting
279
To ease presentation, from now on we assume that F is a {1}-sorted signature,
while G is an S-sorted signature. It is easy nevertheless to generalize our results
to an arbitrary order-sorted signature F.
Theorem 4 ([14]). Let ⟨A, [·], ≥, >⟩be a weakly monotone F-algebra such that
> is well-founded in A. Then ⟨[≥], [>]⟩is a reduction pair on T (F, V), where
s [⊐] t :⇐⇒∀α : V →A. [s]α ⊐[t]α.
Moreover, using the term algebra any reduction pair ⟨≿, ≻⟩on T (F, V) can be
seen as a well-founded F-algebra ⟨T (F, V), ·, ≿, ≻⟩.
Example 5. Continuing Example 4, ⟨≥, >⟩forms a reduction pair for signa-
ture N*+max. Notice that it does not for Z+max ∪N*, essentially because > is not
well-founded in Z.
In order to prove the ﬁniteness of a given DP problem, we need a weakly
monotone F-algebra for the signature F indicated by this problem, rather than
for a predeﬁned signature like N*+max. We ﬁll the gap by employing the notion
of derivers [24,33] to derive an F-algebra from one of another signature G.
Deﬁnition 4 (deriver). An F/G-deriver is a pair of a sort δ ∈S and a map-
ping d, such that d(f) ∈T (G, {x1 : δ, . . . , xn : δ})δ when f has arity n in F.
Given a base G-algebra ⟨A, [·]⟩, we deﬁne the derived F-algebra

Aδ, d[·]

by
d[f](a1, . . . , an) := [d(f)](x1 →a1, . . . , xn →an)
Example 6. Deﬁne a {fact♯, p, s : 1 →1}/Z+max-deriver ⟨Nat, d⟩by
d(fact♯) := x1
d(s) := x1 + 1
d(p) := max(x1 - 1, 0)
Note that d(p) has sort Nat, thanks to the rank (Int, Nat) →Nat of max in Zmax.
The order pair ⟨d≥, d>⟩satisﬁes the constraints given in Example 3.
Now we show that an F/G-deriver yields a weakly monotone F-algebra if the
base G-algebra is known to be weakly monotone. Thus, Example 6 proves that
Rfact is terminating. The next result about monotonicity is folklore:
Lemma 2. A mapping f : An →A is monotone with respect to a quasi-order ≥
if and only if a1 ≥b1, . . . , an ≥bn implies f(a1, . . . , an) ≥f(b1, . . . , bn).
Proof. The “if” direction is due to the reﬂexivity of ≥, and the “only if” direction
is easy by induction on n and the transitivity of ≥.
⊓⊔
Then monotonicity is carried over to the interpretation of terms, in the following
sense. For two sorted maps α : X →A and β : X →A, we write α ≥β to mean
that α(x) ≥β(x) for any x ∈Xσ and sort σ.
Lemma 3. Let ⟨A, [·], ≥, >⟩be a weakly monotone G-algebra and s ∈T (G, V)σ.
If α ≥β then [s]α ≥[s]β.

280
Akihisa Yamada
Proof. By structural induction on s. The claim is trivial if s is a variable. Con-
sider s = f(s1, . . . , sn). We have [si]α ≥[si]β for each i ∈{1, . . . , n} by induction
hypothesis. With Lemma 2 and the monotonicity of [f], we conclude:
[s]α = [f]([s1]α, . . . , [sn]α) ≥[f]([s1]β, . . . , [sn]β) = [s]β
⊓⊔
Lemma 4. Let ⟨δ, d⟩be an F/G-deriver and ⟨A, [·], ≥, >⟩a weakly monotone
G-algebra. Then

Aδ, d[·], ≥, >

is a weakly monotone F-algebra.
Proof. Suppose that f has arity n in F, and for every i ∈{1, . . . , n} that ai, bi ∈
Aδ and ai ≥bi. Then from Lemma 3,
d[f](a1, . . . , an) = [d(f)](x1 →a1, . . . , xn →an)
≥[d(f)](x1 →b1, . . . , xn →bn) = d[f](b1, . . . , bn)
With Lemma 2 we conclude that every d[f] is monotone with respect to ≥, and
hence

Aδ, d[·], ≥, >

is a weakly monotone F-algebra.
⊓⊔
Thus we conclude the soundness of the deriver-based interpretation method:
Theorem 5. If ⟨δ, d⟩is a F/G-deriver, ⟨A, [·], ≥, >⟩is a weakly monotone G-
algebra and > is well-founded in Aδ, then ⟨d[≥], d[>]⟩is a reduction pair.
Proof. Immediate consequence of Lemma 4 and Theorem 4.
⊓⊔
It should be clear that Theorem 5 with G = Z+max ∪N* subsumes the polyno-
mial interpretation method with negative constants [15, Lemma 4]. Their trick
is to turn integers into naturals by applying max(·, 0), as demonstrated in Ex-
ample 6 in a syntactic manner. Theorem 5 gives a slightly more general fact that
one can mix max and negative constants and still get a reduction pair. As far
as the author knows, this fact has not been reported elsewhere, although nat-
ural max-polynomials without negative constants are known to yield reduction
pairs [9, Section 4.1].
In addition, a syntactic technique known as argument ﬁltering [1,21] is also
a special case of Theorem 5. In the context of higher-order rewriting, Kop and
van Raamsdonk generalized argument ﬁlters into argument functions [18, Deﬁ-
nition 7.7], which, in the ﬁrst-order case, correspond to derivers with G being a
variant of F. In these applications, base signatures and algebras are not a priori
known, but are subject to be synthesized and analyzed.
5
Multi-Dimensional Interpretations
The matrix interpretation method [8] uses a well-founded weakly monotone al-
gebra ⟨Nm, [·]Mat, ≥≥, ≫⟩over natural vectors, with an aﬃne interpretation:
[f]Mat(⃗a1, . . . ,⃗an) = C1⃗a1 + · · · + Cn⃗an + ⃗c
where C1, . . . , Cn ∈Nm×m and ⃗c ∈Nm, and the following ordering:

Multi-Dimensional Interpretations for Termination of Term Rewriting
281
Deﬁnition 5 ([8,19]). Given an order pair ⟨≥, >⟩on A and a dimension m ∈
N, we deﬁne the order pair ⟨≥≥, ≫⟩on Am as follows:
(a1, . . . , am) ≥≥
(
) (b1, . . . , bm) :⇐⇒a1 ≥
(
) b1 ∧a2 ≥b2 ∧· · · ∧am ≥bm
Improved matrix interpretations [6] consider square matrices instead of vectors,
and thus, in principle, matrix polynomials can be considered. Now we generalize
these methods by extending derivers to multi-dimensional ones.
Deﬁnition 6 (multi-dimensional derivers). An m-dimensional F/G-deriver
consists of an m-tuple ⃗δ ∈Sm of sorts and a mapping ⃗d such that ⃗d(f) ∈
T (G, X)⃗δ, where X := {xi,j : (⃗δ)j | i ∈{1, . . . , n}, j ∈{1, . . . , m}} if f has arity
n in F. Given a G-algebra ⟨A, [·]⟩, the derived F-algebra

A⃗δ, ⃗d[·]

is deﬁned by
⃗d[f](⃗a1, . . . ,⃗an) :=
⃗d(f)

1

α, . . . ,
⃗d(f)

m

α

where α is deﬁned by α(xi,j) := (⃗ai)j.
Example 7 ([8, Example 1]). The TRS of the single rule f(f(x)) →f(g(f(x)))
can be shown terminating by the following 2-dimensional matrix interpretation:
[f]Mat(⃗a) =

1 1
0 0
	
⃗a +

0
1
	
[g]Mat(⃗a) =

1 0
0 0
	
⃗a +

0
0
	
The 2-dimensional {f, g}/N+-deriver

(Nat, Nat), ⃗d

deﬁned by
⃗d(f) =

x11 + x12
1
	
⃗d(g) =

x11
0
	
represents [·]Mat as ⃗d·, that is, [≥≥]Mat = ⃗d≥≥ and [≫]Mat = ⃗d≫.
Now we prove a counterpart of Theorem 5 for multi-dimensional derivers.
The following lemma is one of the main results of this paper, which is somewhat
surprisingly easy to prove.
Lemma 5. For an m-dimensional F/G-deriver
⃗δ, ⃗d

and a weakly monotone
G-algebra ⟨A, [·], ≥, >⟩,

A⃗δ, ⃗d[·], ≥≥, ≫

is a weakly monotone F-algebra.
Proof. Let f have arity n in F and ⃗a1, . . . ,⃗an,⃗b1, . . . ,⃗bn ∈A⃗δ satisfy ⃗ai ≥≥⃗bi.
Deﬁne α and β by α(xi,j) := (⃗ai)j and β(xi,j) :=
⃗bi

j. By assumption we have
α ≥β, and with Lemma 3 we have

⃗d[f](⃗a1, . . . ,⃗an)

j =
⃗d(f)

j

α ≥
⃗d(f)

j

β =

⃗d[f](⃗b1, . . . ,⃗bn)

j
for every j ∈{1, . . . , m}. Hence ⃗d[f](⃗a1, . . . ,⃗an) ≥≥⃗d[f](⃗b1, . . . ,⃗bn), and this
concludes the proof due to Lemma 2.
⊓⊔

282
Akihisa Yamada
Theorem 6. For a multi-dimensional F/G-deriver
⃗δ, ⃗d

and a weakly mono-
tone G-algebra ⟨A, [·], ≥, >⟩such that > is well-founded in A(⃗δ)1,
⃗d[≥≥], ⃗d[≫]

is a reduction pair.
Proof. Thanks to Lemma 5 and Theorem 4, it suﬃces to show that ≫is well-
founded in A⃗δ. Suppose on the contrary that there exists an inﬁnite sequence
⃗a1 ≫⃗a2 ≫· · · with ⃗a1,⃗a2, . . . ∈A⃗δ. Then we have (⃗a1)1 > (⃗a2)1 > · · · and
(⃗a1)1, (⃗a2)1, . . . ∈A(⃗δ)1, contradicting the well-foundedness of > in A(⃗δ)1.
⊓⊔
It should be clear that every m-dimensional (improved) matrix interpretation
can be expressed as an m-dimensional (or m2-dimensional) F/N*+-deriver. There
are two more important consequences of Theorem 6: First, we can interpret
symbols as non-aﬃne maps even including max-polynomials; and second, since >
is not required to be well-founded in A(⃗δ)2, . . . , A(⃗δ)m, examples that previously
required non-monotone interpretations—and hence a stronger condition than
Theorem 2—can be handled.
Example 8 (Excerpt of AProVE 08/log). Consider the TRS R/ consisting of
x - 0 →x
0 / y →0
s(x) - s(y) →x - y
s(x) / s(y) →(s(x) - s(y)) / s(y)
which deﬁnes (for simplicity, rounded up) natural division. Proving R/ termi-
nating using dependency pairs boils down to ﬁnding a reduction pair ⟨⪰, ≻⟩such
that (again considering usable rules)
x - 0 ⪰x
s(x) - s(y) ⪰x - y
s(x) /♯s(y) ≻(s(x) - s(y)) /♯s(y)
A polynomial interpretation [·]Pol with negative coeﬃcients such that
[0]Pol = 0
[s]Pol(x) = x + 1
[/♯]Pol(x, y) = x
[-]Pol(x, y) = max(x −y, 0)
satisﬁes the above constraints, but one must validate the requirements of [15,
Theorem 11]. In our setting, an F/Z+max-deriver ⟨(Nat, Neg), ⃗d⟩such that
⃗d(0) =

0
0
	
⃗d(s) =

x1,1 + 1
x1,2 - 1
	
⃗d(-) =
max(x1,1 + x2,2, 0)
0
	
⃗d(/♯) =
x1,1
0
	
yields a reduction pair satisfying the above constraints.
The intuition here is that the two dimensional interpretation of sn(0) records
n in the ﬁrst coordinate and −n in the second. Hence, one does not have to
reconstruct −n from n using the non-monotonic minus operation.
It seems plausible to the author that negative coeﬃcients can be eliminated
using the above idea; however, the increase of the dimension leads to more free-
dom in variables (the variable introduced to represent −n may take values other
than that) and so the ordering over terms may be diﬀerent. It is left for future
work to investigate whether this idea always works or not.

Multi-Dimensional Interpretations for Termination of Term Rewriting
283
6
Arctic Interpretations
An arctic interpretation [19] [·]A is a matrix interpretation on the arctic semir-
ing; that is, every interpretation [f]A(⃗x1, . . . , ⃗xn) is of the form
C1 ⊗⃗x1 ⊕· · · ⊕Cn ⊗⃗xn ⊕⃗c
(1)
where ⊗and ⊕denote the matrix multiplication and matrix addition in which
the scalar addition is replaced by the max operation, and the scalar multiplica-
tion by addition; and entries of Ci and ⃗c are arctic naturals (N−∞:= N∪{−∞})
or arctic integers (Z−∞:= Z ∪{−∞}). In addition, (1) must be absolute posi-
tive: (⃗c)1 ≥0, so that

N × Nm−1
−∞, [·]A, ≥≥, ≫

or

N × Zm−1
−∞, [·]A, ≥≥, ≫

forms
a well-founded weakly monotone algebra.
The above formulation deviates from the original [19] in two ways. First,
we do not introduce the special relation such that −∞≫−∞. Koprowski and
Waldmann demanded this to ensure closure under general substitutions, but
such a comparison cannot occur as we only need to consider substitutions that
respect the carrier N×Zm−1
−∞. Second, for arctic natural interpretations they relax
absolute positiveness to somewhere ﬁniteness: (⃗c)1 ̸= −∞or (Ci)1,1 ̸= −∞for
some i. However, the two assumptions turn out to be equivalent.
Proposition 1. Every arctic natural interpretation of form (1) is absolute pos-
itive iﬀit is somewhere ﬁnite.
Proof. Clearly, absolute positiveness implies somewhere ﬁniteness. For the other
direction, since (⃗c)1 ̸= −∞trivially implies absolute positiveness, suppose that
(⃗c)1 = −∞and (Ci)1,1 ̸= −∞for some i. We then know (⃗y)1 ≥0, where
⃗y := C1 ⊗⃗x1 ⊕· · · ⊕Cn ⊗⃗xn. Hence, by ⃗c′ := (0, (⃗c)2, . . . , (⃗c)m), we have
[f]A(⃗x1, . . . , ⃗xn) = ⃗y ⊕⃗c′, and this representation is absolute positive.
⊓⊔
One can easily obtain arctic interpretations via multi-dimensional derivers:
consider a sort ANat with Nat ⊑ANat and {Nat, ANat}-sorted signature N+max-oo,
extending N+max with
-oo : () →ANat
+ : (ANat, ANat) →ANat
max : (Nat, ANat) →Nat
max : (ANat, Nat) →Nat
max : (ANat, ANat) →ANat
and extend the standard interpretation · accordingly. We omit the easy proof
of the following fact and the counterpart for arctic integer interpretations.
Proposition 2. Every absolute positive arctic natural interpretation [·]A is rep-
resented as ⃗d· via an F/N+max-oo-deriver

(Nat, ANat, . . . , ANat), ⃗d

.
Notice that, in practice, this requires us to deal with −∞by ourselves since
there is no standard SMT theory [3] that supports arithmetic with −∞.

284
Akihisa Yamada
7
Strict Monotonicity
Before the invention of dependency pairs [1], strictly monotone algebras were
necessary for proving termination by interpretation methods, and they constitute
a sound and complete method for proving termination of TRSs.
Deﬁnition 7. A strictly monotone F-algebra is a weakly monotone F-algebra
⟨A, [·], ≥, >⟩such that ⟨A, [·]⟩is monotone with respect to both ≥and >.
Theorem 7 (cf. [36]). A TRS R is terminating if and only if there is a strictly
monotone well-founded F-algebra ⟨A, [·], ≥, >⟩such that R ⊆[>].
Moreover, strict monotonicity is a desirable property in the DP framework as it
allows one to remove not only dependency pairs but also rewrite rules.
Theorem 8 ([12]). A DP problem ⟨P, R⟩is ﬁnite if ⟨P \ [>], R \ [>]⟩is, where
⟨A, [·], ≥, >⟩is a strictly monotone well-founded F-algebra such that P∪R ⊆[≥].
We now state a criterion that ensures the strict monotonicity of multi-
dimensional interpretation obtained via derivers. Below we write di to mean
the mapping deﬁned by di(f) :=
⃗d(f)

i.
Theorem 9. Let
⃗δ, ⃗d

be an m-dimensional F/G-deriver and ⟨A, [·], ≥, >⟩a
weakly monotone G-algebra. Suppose that when f has arity n in F and i ∈
{1, . . . , n}, α(xi,1) > a implies [d1(f)]α > [d1(f)]α(xi,1 →a) for any α : X →A
and a ∈A. Then

A⃗δ, ⃗d[·], ≥≥, ≫

is a strictly monotone F-algebra.
Proof. We only prove strict monotonicity as we already know weak monotonicity
by Lemma 5. So suppose that f has arity n in F, ⃗a1, . . . ,⃗ai, . . . ,⃗an,⃗a′
i ∈A⃗δ and
⃗ai ≫⃗a′
i. For the ﬁrst coordinate, deﬁne α by α(xk,j) := (⃗ak)j. Then, ﬁrst using
the assumption, and then Lemma 3, we conclude
d1[f](⃗a1 . . . ,⃗ai, . . . ,⃗an) = [d1(f)]α
> [d1(f)]α(xi,1 →(⃗a′
i)1)
≥[d1(f)]α(xi,1 →(⃗a′
i)1, xi,2 →(⃗a′
i)2, . . . , xi,m →(⃗a′
i)m)
= d1[f](⃗a1, . . . ,⃗a′
i, . . . ,⃗an)
For the other coordinates, thanks to the “new” assumption > ⊆≥in Deﬁnition 1
we have ⃗ai ≥≥⃗a′
i. Then the weak monotonicity ensures ⃗d[f](⃗a1, . . . ,⃗ai, . . .⃗an) ≥≥
⃗d[f](⃗a1, . . . ,⃗a′
i, . . . ,⃗an), from which we deduce for each j ∈{2, . . . , m},
dj[f](⃗a1, . . . ,⃗ai, . . . ,⃗an) ≥dj[f](⃗a1, . . . ,⃗a′
i, . . . ,⃗an)
⊓⊔
Although the above result and proof do not look surprising, it would be worth
noticing that the statement is false in the standard formulation allowing > ̸⊆≥
(as even in [8]).

Multi-Dimensional Interpretations for Termination of Term Rewriting
285
Example 9. Consider the following apparently monotone matrix interpretation:
[f]

a1
a2
		
:=

1 0
1 0
	 
a1
a2
	
=

a1
a1
	
If one had a1 > b1 but a1 ≱b1, then
[f]

a1
a2
		
=

a1
a1
	
>
≱

b1
b1
	
= [f]

b1
a2
		
even though

a1
a2
	
≫

b1
a2
	
.
So [f] would not be monotone with respect to ≫.
8
Implementation and Experiments
Multi-dimensional interpretations are implemented in the termination prover
NaTT version 2.02, using a template-based approach.
Deﬁnition 8. An m-dimensional F/G-deriver template
⃗δ, ⃗d

with S-sorted
set W of template variables is deﬁned as in Deﬁnition 6, but allowing ⃗d(f) ∈
T (G, W ∪X)⃗δ. Its instance according to a substitution θ : W →T (G, ∅) is the
F/G-deriver
⃗δ, ⃗dθ

, deﬁned by ⃗dθ(f) := (d1(f)θ, . . . , dm(f)θ).
In the implementation, we ﬁx G = Z+max ∪N* and the base weakly monotone
G-algebra ⟨Z, ·, ≥, >⟩. Given an m-dimensional deriver template
⃗δ, ⃗d

with
W, our interest is now to ﬁnd θ : W →Z such that ⃗dθ[s] ≥⃗dθ[t] for every
(s, t) ∈P ∪R for the DP problem ⟨P, R⟩of concern, thanks to Theorem 6.
NaTT reduces this problem into an SMT problem and passes it to a backend
SMT solver. The page limit is not enough to detail the reduction; in short, the
constraint ⃗dθ[s] ≥≥⃗dθ[t] is reduced into a Boolean formula over atoms of form
a * ⟨v1, i1⟩* · · · * ⟨vn, in⟩≥b * ⟨v1, i1⟩* · · · * ⟨vn, in⟩, where a, b ∈T (G, W),
and ⟨v1, i1⟩. . . , ⟨vn, in⟩∈(Var(s) ∪Var(t)) × {1, . . . , m} are seen as variables.
Internally NaTT uses a distribution approach [30], whose soundness crucially
relies on the fact that the only rank of * is (Nat, Nat) →Nat in the signature
G. Then each atom is further reduced to (1) a = b if (⃗δ)ij = Int for some
j, (2) a ≥b if
{j | (⃗δ)ij = Neg}
 is even, and (3) a ≤b otherwise. Due
to the last step, having coordinates of sort Int leads to a stronger constraint
when ordering terms. Finally, the resulting formula, containing only template
variables, is passed to the SMT solver Z3 4.8.10 [26] and a satisfying solution
θ : W →Z is a desired substitution.
To verify the practical signiﬁcance of the method, we evaluated various tem-
plates in a simple dependency pair setting. For a function symbol f of arity
n ≥2, the k-th coordinate of template ⃗d(f) is chosen from
– sum: w + n
i=1(b * xi,k),
2 Available at https://www.trs.cm.is.nagoya-u.ac.jp/NaTT/

286
Akihisa Yamada
Table 1. Evaluation of 2-dimensional templates.
#
Coordinate 1
Coordinate 2
YES
New
Time
Known as
1
sum
Nat
-
-
512
-
00:36:12
polynomial [1]
2
sum
Int
-
-
559
-
00:52:37
negative constant [15]
3
sum-sum
Nat
sum-sum
Nat
636
-
04:18:05
matrix [8]
4
sum-sum
Int
sum
Neg
602
10
04:00:05
new
5
sum-sum
Int
sum-sum
Int
542
0
25:07:04
new
6
sum-sum
Int
max
Neg
585
8
14:58:41
new
7
max
Int
-
-
560
-
00:58:58
max-polynomial [9]3
8
max-max
Nat
max-max
Nat
552
3
12:33:43
arctic natural [19]4
9
max-max
Int
max-max
Int
580
2
22:35:29
arctic integer [19]4
10
max-max
Nat
sum
Nat
577
0
03:48:46
new
11
max-max
Int
sum
Neg
584
2
06:53:34
new
12
max-sum
Int
sum
Neg
592
4
06:59:22
new
13
heuristic
Int
sum
Neg
648
9
04:55:43
new
– max: maxn
i=1 b * (w + xi,k),
– sum-sum: w + n
i=1
m
j=1 b * xi,j,
– max-max: maxn
i=1 maxm
j=1 b * (w + xi,j),
– sum-max: n
i=1 maxm
j=1 b * (w + xi,j),
– max-sum: maxn
i=1(w + m
j=1 b * xi,j), and
– a heuristic choice [35] between sum-sum and max-sum,
where b and w introduce fresh template variables, b ranges over {0, 1} and the
sort of w is up to further choice. The sort of the ﬁrst coordinate is turned to Nat
by applying max(·, 0) if necessary.
Experiments are run on the StarExec environment [29], with timeout of 300
seconds. The benchmarks are the 1507 TRSs from the TRS Standard category
of the termination problem database 11 [32]. Due to the huge search space, we
evaluate templates of dimensions up to 2. A part of the results are summarized
in Table 1. Full details of the experiments are made available at http://www.
trs.cm.is.nagoya-u.ac.jp/NaTT/multi/.
In the table, each coordinate is represented by the template and the sort
of w. In terms of the number of successful termination proofs indicated in the
“YES” column, the classical matrix interpretations (row #3) are impressively
strong. Nevertheless, it is worth considering a negative coordinate (#4) as it
gives 10 termination proofs that the previous version of NaTT could not ﬁnd,
indicated in the “New” column. In contrast, considering whole integers in the
second coordinate (#5) does not look promising as the runtime grows signiﬁ-
cantly. Concerning “max”, we observe that its use in the second coordinate (#6)
3 This template is a subset of integer max-polynomials [9], although the fact that it
yields a reduction pair is new.
4 In our implementation, negative inﬁnity is not supported. Instead, similar eﬀect is
emulated by zero coeﬃcients.

Multi-Dimensional Interpretations for Termination of Term Rewriting
287
Table 2. Experiments with combined strategies
Strategy
YES
New to NaTT
New to TermCOMP
Time
Old Strategy
861
0
0
3:46:12
With #4
874
13
3
4:14:09
With #13
871
10
1
4:26:14
With #4 and #13
881
20
5
4:49:50
degrades the performance. Using “max” in both coordinates a la arctic inter-
pretations (#8, #9) gives a few new termination proofs, but the impact in the
runtime is signiﬁcant in the current implementation. The runtime improves by
replacing some occurrences of “max” by “sum” (#10–12), while the power does
not seem defected. In terms of the number of termination proofs, the heuristic
choice of “sum-sum” and “max-sum” in the ﬁrst coordinate (#13) performed
the best among the evaluated templates.
From these experiments, we pick templates #4 and #13 to incorporate in the
NaTT default strategy. The ﬁnal results are summarized in Table 2. Although the
runtime noticeably increases, adding both #4 and #13 gives 20 more examples
solved, and ﬁve of them (AProVE_09_Inductive/log and four in Transformed_
CSR_04/) were not solved by any tool in the TermCOMP 2020.
9
Conclusion
In this paper we introduced a deriver-based multi-dimensional interpretation
method. The author expects that the result makes the relationships between
existing interpretation methods cleaner, and eases the task of developing and
maintaining termination tools. Moreover, it yields many previously unknown
interpretation methods as instances, proving the termination of some standard
benchmarks that state-of-the-art termination provers could not.
Theoretical comparison with negative coeﬃcients is left for future work, and
the use of −∞is not implemented yet. Also since this work broadens the search
space, it is interesting to heuristically search for derivers rather than ﬁxing some
templates. Derivers of higher dimensions seem also interesting to explore. Finally,
although the proposed method is implemented in the termination prover NaTT,
there is no guarantee that the implementation is correct. In order to certify
termination proofs that use multi-dimensional derivers, one must formalize the
proofs in this paper, extend the certiﬁable proof format [27], and implement a
veriﬁed function to validate such proofs.
Acknowledgments The author would like to thank Aaron Stump and his team
for StarExec environment that ran experiments taking 40 days of node within a
day. The author also thanks the anonymous reviewers of previous versions of the
paper. This work was partly supported by the Austrian Science Fund (FWF)
projects Y757 and P27502, and the Japan Science and Technology Agency (JST)
project ERATO MMSD.

288
Akihisa Yamada
References
1. Arts, T., Giesl, J.: Termination of term rewriting using dependency pairs.
Theor. Compt. Sci. 236(1–2), 133–178 (2000). https://doi.org/10.1016/S0304-
3975(99)00207-8
2. Baader, F., Nipkow, T.: Term rewriting and all that. Cambridge University Press
(1998)
3. Barrett, C.W., Tinelli, C.: Satisﬁability modulo theories. In: Clarke, E.M., Hen-
zinger, T.A., Veith, H., Bloem, R. (eds.) Handbook of Model Checking, pp. 305–
343. Springer (2018). https://doi.org/10.1007/978-3-319-10575-8 11
4. Blanqui,
F.,
Koprowski,
A.:
CoLoR:
a
Coq
library
on
well-founded
rewrite relations and its application to the automated veriﬁcation of ter-
mination
certiﬁcates.
Math.
Struct.
Comput.
Sci.
21(4),
827–859
(2011).
https://doi.org/10.1017/S0960129511000120
5. Contejean, ´E., Courtieu, P., Forest, J., Pons, O., Urbain, X.: Automated certi-
ﬁed proofs with CiME3. In: Schmidt-Schauß, M. (ed.) RTA 2011. LIPIcs, vol. 10,
pp. 21–30. Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik, Dagstuhl, Germany
(2011). https://doi.org/10.4230/LIPIcs.RTA.2011.21
6. Courtieu, P., Gbedo, G., Pons, O.: Improved matrix interpretation. In: van
Leeuwen, J., Muscholl, A., Peleg, D., Pokorn´y, J., Rumpe, B. (eds.) SOFSEM 2010.
LNCS, vol. 5901, pp. 283–295. Springer (2010). https://doi.org/10.1007/978-3-642-
11266-9 24
7. Dershowitz, N.: 33 examples of termination. In: Comon, H., Jounnaud, J.P. (eds.)
Term Rewriting. pp. 16–26. Springer (1995). https://doi.org/10.1007/3-540-59340-
3 2
8. Endrullis, J., Waldmann, J., Zantema, H.: Matrix interpretations for proving
termination of term rewriting. J. Autom. Reason. 40(2-3), 195–220 (2008).
https://doi.org/10.1007/s10817-007-9087-9
9. Fuhs, C., Giesl, J., Middeldorp, A., Schneider-Kamp, P., Thiemann, R., Zankl,
H.: Maximal termination. In: Voronkov, A. (ed.) RTA 2008. LNCS, vol. 5117, pp.
110–125. Springer (2008). https://doi.org/10.1007/978-3-540-70590-1 8
10. Giesl, J., Brockschmidt, M., Emmes, F., Frohn, F., Fuhs, C., Otto, C., Pl¨ucker,
M., Schneider-Kamp, P., Str¨oder, T., Swiderski, S., Thiemann, R.: Proving termi-
nation of programs automatically with AProVE. In: Demri, S., Kapur, D., Wei-
denbach, C. (eds.) IJCAR 2014. LNCS, vol. 8562, pp. 184–191. Springer (2014).
https://doi.org/10.1007/978-3-319-08587-6 13
11. Giesl, J., Rubio, A., Sternagel, C., Waldmann, J., Yamada, A.: The termina-
tion and complexity competition. In: Beyer, D., Huisman, M., Kordon, F., Stef-
fen, B. (eds.) TACAS 2019 (3). LNCS, vol. 11429, pp. 156–166. Springer (2019).
https://doi.org/10.1007/978-3-030-17502-3 10
12. Giesl, J., Thiemann, R., Schneider-Kamp, P.: The dependency pair frame-
work: Combining techniques for automated termination proofs. In: Baader, F.,
Voronkov, A. (eds.) LPAR 2004. LNCS, vol. 3452, pp. 301–331. Springer (2004).
https://doi.org/10.1007/978-3-540-32275-7 21
13. Giesl, J., Thiemann, R., Schneider-Kamp, P., Falke, S.: Mechanizing and
improving
dependency
pairs.
J.
Autom.
Reason.
37(3),
155–203
(2006).
https://doi.org/10.1007/s10817-006-9057-7
14. Hirokawa, N., Middeldorp, A.: Dependency pairs revisited. In: van Oost-
rom, V. (ed.) RTA 2004. LNCS, vol. 3091, pp. 249–268. Springer (2004).
https://doi.org/10.1007/978-3-540-25979-4 18

Multi-Dimensional Interpretations for Termination of Term Rewriting
289
15. Hirokawa, N., Middeldorp, A.: Polynomial interpretations with negative coeﬃ-
cients. In: Buchberger, B., Campbell, J.A. (eds.) AISC 2004. LNAI, vol. 3249, pp.
185–198. Springer (2004). https://doi.org/10.1007/978-3-540-30210-0 16
16. Hofbauer, D., Waldmann, J.: Termination of string rewriting with matrix interpre-
tations. In: Pfenning, F. (ed.) RTA 2006. LNCS, vol. 4098, pp. 328–342. Springer
(2006). https://doi.org/10.1007/11805618 25
17. Jouannaud,
J.,
Rubio,
A.:
The
higher-order
recursive
path
order-
ing.
In:
LICS
1999.
pp.
402–411.
IEEE
Computer
Society
(1999).
https://doi.org/10.1109/LICS.1999.782635
18. Kop, C., van Raamsdonk, F.: Dynamic dependency pairs for algebraic functional
systems. Log. Methods Comput. Sci. 8(2) (2012). https://doi.org/10.2168/LMCS-
8(2:10)2012
19. Koprowski, A., Waldmann, J.: Max/plus tree automata for termination of term
rewriting. Acta Cybern. 19(2), 357–392 (2009)
20. Korp, M., Sternagel, C., Zankl, H., Middeldorp, A.: Tyrolean Termination Tool 2.
In: Treinen, R. (ed.) RTA 2009. LNCS, vol. 5595, pp. 295–304. Springer (2009).
https://doi.org/10.1007/978-3-642-02348-4 21
21. Kusakari, K., Nakamura, M., Toyama, Y.: Argument ﬁltering transformation. In:
Nadathur, G. (ed.) PPDP 1999. LNCS, vol. 1702, pp. 47–61. Springer (1999).
https://doi.org/10.1007/10704567 3
22. Lankford, D.: Canonical algebraic simpliﬁcation in computational logic. Tech. Rep.
ATP-25, University of Texas (1975)
23. Lucas, S.: MU-TERM: A tool for proving termination of context-sensitive rewrit-
ing. In: van Oostrom, V. (ed.) RTA 2004. LNCS, vol. 3091, pp. 200–209. Springer
(2004). https://doi.org/10.1007/978-3-540-25979-4 14
24. Lucas, S., Guti´errez, R.: Automatic synthesis of logical models for order-
sorted
ﬁrst-order
theories.
J.
Autom.
Reason.
60(4),
465–501
(2018).
https://doi.org/10.1007/s10817-017-9419-3
25. Manna, Z., Ness, S.: On the termination of Markov algorithms. In: the 3rd Hawaii
International Conference on System Science. pp. 789–792 (1970)
26. de Moura, L.M., Bjørner, N.: Z3: an eﬃcient SMT solver. In: Ramakrishnan, C.R.,
Rehof, J. (eds.) TACAS 2008. LNCS, vol. 4963, pp. 337–340. Springer (2008).
https://doi.org/10.1007/978-3-540-78800-3 24
27. Sternagel, C., Thiemann, R.: The certiﬁcation problem format. In: Benzm¨uller,
C., Paleo, B.W. (eds.) UITP 2014. EPTCS, vol. 167, pp. 61–72 (2014).
https://doi.org/10.4204/EPTCS.167.8
28. Sternagel, C., Thiemann, R.: Formalizing monotone algebras for certiﬁcation of
termination and complexity proofs. In: Dowek, G. (ed.) RTA-TLCA 2014. LNCS,
vol. 8560, pp. 441–455. Springer (2014). https://doi.org/10.1007/978-3-319-08918-
8 30
29. Stump, A., Sutcliﬀe, G., Tinelli, C.: StarExec: A cross-community infrastructure
for logic solving. In: Demri, S., Kapur, D., Weidenbach, C. (eds.) IJCAR. LNCS,
vol. 8562, pp. 367–373. Springer (2014). https://doi.org/10.1007/978-3-319-08587-
6 28
30. Thiemann, R., Sch¨opf, J., Sternagel, C., Yamada, A.: Certifying the Weighted
Path Order (Invited Talk). In: Ariola, Z.M. (ed.) FSCD 2020. LIPIcs, vol. 167, pp.
4:1–4:20. Schloss Dagstuhl–Leibniz-Zentrum f¨ur Informatik, Dagstuhl, Germany
(2020). https://doi.org/10.4230/LIPIcs.FSCD.2020.4
31. Thiemann, R., Sternagel, C.: Certiﬁcation of termination proofs using CeTA. In:
Berghofer, S., Nipkow, T., Urban, C., Wenzel, M. (eds.) TPHOLs 2009. LNCS,

290
Akihisa Yamada
vol. 5674, pp. 452–468. Springer (2009). https://doi.org/10.1007/978-3-642-03359-
9 31
32. The termination problem data base, http://termination-portal.org/wiki/TPDB
33. Watson, T., Goguen, J., Thatcher, J., Wagner, E.: An initial algebra approach
to the speciﬁcation, correctness, and implementation of abstract data types. In:
Current Trends in Programming Methodology. Prentice Hall (1976)
34. Yamada, A., Kusakari, K., Sakabe, T.: Nagoya Termination Tool. In: Dowek,
G. (ed.) RTA-TLCA 2014. LNCS, vol. 8560, pp. 466–475. Springer (2014).
https://doi.org/10.1007/978-3-319-08918-8 32
35. Yamada,
A.,
Kusakari,
K.,
Sakabe,
T.:
A
uniﬁed
order
for
ter-
mination
proving.
Sci.
Comput.
Program.
111,
110–134
(2015).
https://doi.org/10.1016/j.scico.2014.07.009
36. Zantema, H.: Termination of term rewriting: interpretation and type elimination.
J. Symb. Comput. 17(1), 23–50 (1994). https://doi.org/10.1006/jsco.1994.1003
37. Zantema, H.: The termination hierarchy for term rewriting. Appl. Algebr. Eng.
Comm. Compt. 12(1/2), 3–19 (2001). https://doi.org/10.1007/s002000100061
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/
4.0/), which permits use, sharing, adaptation, distribution and reproduction in any
medium or format, as long as you give appropriate credit to the original author(s) and
the source, provide a link to the Creative Commons license and indicate if changes
were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Finding Good Proofs for Description Logic
Entailments using Recursive Quality Measures
Theoretical Computer Science, TU Dresden, Dresden, Germany
Abstract. Logic-based approaches to AI have the advantage that their
behavior can in principle be explained to a user. If, for instance, a
Description Logic reasoner derives a consequence that triggers some
action of the overall system, then one can explain such an entailment by
presenting a proof of the consequence in an appropriate calculus. How
comprehensible such a proof is depends not only on the employed calculus,
but also on the properties of the particular proof, such as its overall size,
its depth, the complexity of the employed sentences and proof steps, etc.
For this reason, we want to determine the complexity of generating proofs
that are below a certain threshold w.r.t. a given measure of proof quality.
Rather than investigating this problem for a ﬁxed proof calculus and a
ﬁxed measure, we aim for general results that hold for wide classes of
calculi and measures. In previous work, we ﬁrst restricted the attention
to a setting where proof size is used to measure the quality of a proof.
We then extended the approach to a more general setting, but important
measures such as proof depth were not covered. In the present paper, we
provide results for a class of measures called recursive, which yields lower
complexities and also encompasses proof depth. In addition, we close
some gaps left open in our previous work, thus providing a comprehensive
picture of the complexity landscape.
1
Introduction
Explainability has developed into a major issue in Artiﬁcial Intelligence, particu-
larly in the context of sub-symbolic approaches based on Machine Learning [6].
In contrast, results produced by symbolic approaches based on logical reasoning
are “explainable by design” since a derived consequence can be formally justiﬁed
by showing a proof for it. In practice, things are not that easy since proofs may
be very long, and even single proof steps or stated sentences may be hard to com-
prehend for a user that is not an expert in logic. For this reason, there has been
considerable work in the Automated Deduction and Logic in AI communities on
how to produce “good” proofs for certain purposes, both for full ﬁrst-order logic,
but also for decidable logics such a Description Logics (DLs) [9]. We mention here
only a few approaches, and refer the reader to the introduction of our previous
work [2] for a more detailed review.
c⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5_17
Christian Alrabbaa
, Franz Baader
, Stefan Borgwardt
, Patrick
Koopmann
, and Alisa Kovtunova
291–308, 2021.

292
Alrabbaa, Baader, Borgwardt, Koopmann, Kovtunova
First, there is work that transforms proofs that are produced by an automated
reasoning system into ones in a calculus that is deemed to be more appropriate
for human consumption [11,22,23]. Second, abstraction techniques are used to
reduce the size of proofs by introducing deﬁnitions, lemmas, and more abstract
deduction rules [16,17]. Justiﬁcation-based explanations for DLs [10,14,28] can
be seen as a radical abstraction technique where the abstracted proof consists of
a single proof step, from a minimal set of stated sentences that implies a certain
consequence directly to this consequence. Finally, instead of presenting proofs in
a formal, logical syntax, one can also try to increase readability by translating
them into natural language text [12,25–27] or visualizing them [5].
The purpose of this work is of a more (complexity) theoretic nature. We want
to investigate how hard it is to ﬁnd good proofs, where the quality of a proof is
described by a measure m that assigns non-negative rational numbers to proofs.
More precisely, as usual we investigate the complexity of the corresponding
decision problem, i.e., the problem of deciding whether there is a proof P with
m(P) ≤q for a given rational number q. In order to abstract from speciﬁc logics
and proof calculi, we develop a general framework in which proofs are represented
as labeled, directed hypergraphs, whose hyperedges correspond to single sound
derivation steps. To separate the complexity of generating good proofs from the
complexity of reasoning in the underlying logic, we introduce the notion of a
deriver, which generates a so-called derivation structure. This structure consists
of possible proof steps, from which all proofs of the given consequence can be
constructed. Basically, such a derivation structure can be seen as consisting of all
relevant instantiations of the rules of a calculus that can be used to derive the
consequence. We restrict the attention to decidable logics and consider derivers
that produce derivation structures of polynomial or exponential size. Examples
of such derivers are consequence-based reasoners for the DLs EL [7, 21] and
ELI [9,18], respectively. In our complexity results, the derivation structure is
assumed to be already computed by the deriver,1 i.e., the complexity of this
step is not assumed to be part of the complexity of computing good proofs.
Our complexity results investigate the problem along the following orthogonal
dimensions: we distinguish between (i) polynomial and exponential derivers; and
(ii) whether the threshold value q is encoded in unary or binary. The obtained
complexity upper bounds hold for all instances of a considered setting, whereas
the lower bounds mean that there is an instance (usually based on EL or ELI)
for which this lower bound can be proved.
In our ﬁrst work in this direction [2], we focused our attention on size as
the measure of proof quality. We could show that the above decision problem
is NP-complete even for polynomial derivers and unary coding of numbers.
For exponential derivers, the complexity depends on the coding of numbers:
NP-complete (NExpTime-complete) for unary (binary) coding. For the related
measure tree size (which assumes that the proof hypergraphs are tree-shaped,
i.e. cannot reuse already derived consequences), the complexity turned out to
1 The highly eﬃcient reasoner ELK [21] for (an extension of) EL actually produces a
derivation structure, and thus is a deriver in our sense.

Good Proofs for DL Entailments
293
Table 1. Overview over existing and new complexity results for deciding the existence
of good proofs, w.r.t. polynomial/exponential derivers and unary/binary encoding of
the bound q (known results in gray).
Measure
polynomial
unary
polynomial
binary
exponential
unary
exponential
binary
Size
NP [2]
NP [2]
NExpTime [2]
NExpTime [2]
Monotone recursive
Φ-measures
≤P
≤P [Th.12] ≤ExpTime
≤ExpTime [Th.12]
Tree size
P [2]
P
NP [2]
PSpace [Th.17,18]
Depth
P [Th.14] P
PSpace [Th.16]
ExpTime [Th.14]
Logarithmic depth P [Cor.15] P
ExpTime [Cor.15] ExpTime
be considerably lower, due to the fact that a Dijkstra-like greedy algorithm can
be applied. In [3], we generalized the results by introducing a class of measures
called Ψ-measures, which contains both size and tree size and for which the same
complexity upper bounds as for size could be shown for polynomial derivers.
We also lifted the better upper bounds for tree size (for polynomial derivers)
to local Ψ-measures, a natural class of proof measures. In this paper, we extend
this line of research by providing a more general notion of measures, monotone
recursive Φ-measures, which now also allow to measure the depth of a proof.
We think that depth is an important measure since it measures how much of
the proof tree a (human or automated) proof checker needs to keep in memory
at the same time. We analyze these measures not only for polynomial derivers,
but this time also consider exponential derivers, thus giving insights on how
our complexity results transfer to more expressive logics. In addition to upper
bounds for the general class of monotone recursive Φ-measures, we show improved
bounds for the speciﬁc measures considering depth and tree size, in the latter
case improving results from [2]. Overall, we thus obtain a comprehensive picture
of the complexity landscape for the problem of ﬁnding good proofs for DL and
other entailments (see Table 1).
An extended version of this paper with detailed proofs can be found at [4].
2
Preliminaries
Most of our theoretical discussion applies to arbitrary logics L = (SL, |=L) that
consist of a set SL of L-sentences and a consequence relation |=L ⊆P(SL) × SL
between L-theories, i.e. subsets of L-sentences, and single L-sentences. We assume
that |=L has a semantic deﬁnition, i.e. for some deﬁnition of “model”, T |=L η
holds iﬀevery model of all elements in T is also a model of η. We also assume
that the size |η| of an L-sentence η is deﬁned in some way, e.g. by the number
of symbols in η. Since L is usually ﬁxed, we drop the preﬁx “L-” from now on.
For example, L could be ﬁrst-order logic. However, we are mainly interested in
proofs for DLs, which can be seen as decidable fragments of ﬁrst-order logic [9].
In particular, we use speciﬁc DLs to show our hardness results.

294
R0
C ⊑C
R⊤
C ⊑⊤
C ⊑D
R⊑
: D ⊑E ∈T
C ⊑E
C ⊑D ⊓E
R−
⊓,1
C ⊑D
C ⊑D ⊓E
R−
⊓,2
C ⊑E
C ⊑D
C ⊑E
R+
⊓
C ⊑D ⊓E
C ⊑∃r.D
D ⊑E
R∃
C ⊑∃r.E
Fig. 1. The inference rules for EL used in Elk [21].
The syntax of DLs is based on disjoint, countably inﬁnite sets NC and NR of
concept names A, B, . . . and role names r, s, . . . , respectively. Sentences of the
DL EL, called general concept inclusions (GCIs), are of the form C ⊑D, where
C and D are EL-concepts, which are built from concept names by applying the
constructors ⊤(top), C ⊓D (conjunction), and ∃r.C (existential restriction for a
role name r). The DL ELI extends EL by the role constructor r−(inverse role).
In DLs, ﬁnite theories are called TBoxes or ontologies.
The semantics of DLs is based on ﬁrst-order interpretations; for details,
see [9]. In Figure 1, we depict a simpliﬁed version of the inference rules for EL
from [21]. For example, {A ⊑∃r.B, B ⊑C, ∃r.C ⊑D} |= A ⊑D is a valid
inference in EL. Deciding consequences in EL is P-complete [7], and in ELI it is
ExpTime-complete [8].
2.1
Proofs
We formalize proofs as (labeled, directed) hypergraphs (see Figures 2, 3), which
are tuples (V, E, ℓ) consisting of a ﬁnite set V of vertices, a ﬁnite set E of
(hyper)edges of the form (S, d) with S ⊆V and d ∈V , and a vertex labeling
function ℓ: V →SL. Full deﬁnitions of such hypergraphs, as well as related
notions such as trees, unravelings, homomorphisms, cycles can be found in the
extended version [4]. For example, there is a homomorphism from Figure 3 to
Figure 2, but not vice versa, and Figure 3 is the tree unraveling of Figure 2.
B ⊑∃r.A
A ⊑B
A ⊑∃r.A
A ⊑B ⊓∃r.A
Fig. 2. An acyclic hypergraph/proof
B ⊑∃r.A
A ⊑B
A ⊑B
A ⊑∃r.A
A ⊑B ⊓∃r.A
Fig. 3. A tree hypergraph/proof
The following deﬁnition formalizes basic requirements for hyperedges to be
considered valid inference steps from a given ﬁnite theory.
Deﬁnition 1 (Derivation Structure). A derivation structure D = (V, E, ℓ)
over a ﬁnite theory T is a hypergraph that is
– grounded, i.e. every leaf v in D is labeled by ℓ(v) ∈T ; and
Alrabbaa, Baader, Borgwardt, Koopmann, Kovtunova

Good Proofs for DL Entailments
295
– sound, i.e. for every (S, d) ∈E, the entailment {ℓ(s) | s ∈S} |= ℓ(d) holds.
We deﬁne proofs as special derivation structures that derive a conclusion.
Deﬁnition 2 (Proof). Given a conclusion η and a ﬁnite theory T , a proof for
T |= η is a derivation structure P = (V, E, ℓ) over T such that
– P contains exactly one sink vη ∈V , which is labeled by η,
– P is acyclic, and
– every vertex has at most one incoming edge, i.e. there is no vertex w ∈V s.t.
there are (S1, w), (S2, w) ∈E with S1 ̸= S2.
A tree proof is a proof that is a tree. A subproof S of a hypergraph H is a
subgraph of H that is a proof s.t. the leaves of S are a subset of the leaves of H.
The hypergraphs in Figures 2 and 3 can be seen as proofs in the sense of
Deﬁnition 2, where the sentences of the theory are marked with a thick border.
Both proofs use the same inference steps, but have diﬀerent numbers of vertices.
They both prove A ⊑B ⊓∃r.A from T = {A ⊑B, B ⊑∃r.A}. The second proof
is a tree and the ﬁrst one a hypergraph without label repetition.
Lemma 3. Let P = (V, E, ℓ) be a proof for T |= η. Then
1. all paths in P are ﬁnite and all longest paths in P have vη as the target; and
2. T |= η.
Given a proof P = (V, E, ℓ) and a vertex v ∈V , the subproof of P with sink v
is the largest subgraph Pv = (Vv, Ev, ℓv) of P where Vv contains all vertices in V
that have a path to v in P.
2.2
Derivers
In practice, proofs and derivation structures are constructed by a reasoning
system, and in theoretical investigations, it is common to deﬁne proofs by means
of a calculus. To abstract from these details, we use the concept of a deriver as
in [2], which is a function that, given a theory T and a conclusion η, produces
the corresponding derivation structure in which we can look for an optimal proof.
However, in practice, it would be ineﬃcient and unnecessary to compute the
entire derivation structure beforehand when looking for an optimal proof. Instead,
we allow to access elements in a derivation structure using an oracle, which we
can ask whether given inferences are a part of the current derivation structure.
Similar functionality exists for example for the DL reasoner Elk [19], and may
correspond to checking whether the inference is an instance of a rule in the
calculus. Since reasoners may not be complete for proving arbitrary sentences
of L, we restrict the conclusion η to a subset CL ⊆SL of supported consequences.
Deﬁnition 4 (Deriver). A deriver D is given by a set CL ⊆SL and a function
that assigns derivation structures to pairs (T , η) of ﬁnite theories T ⊆SL and
sentences η ∈CL, such that T |= η iﬀD(T , η) contains a proof for T |= η. A

296
CR1
if A ∈K and K appears in T ′
K ⊑A
M ⊑A for all A ∈K, K ⊑C
CR2
if M appears in T ′
M ⊑C
M ⊑∃r.L
L ⊑∀r−.A
CR3
M ⊑A
L ⊑∃r.M
L ⊑∀r.A
CR4
L ⊑∃r.(M ⊓A)
Fig. 4. The inference rules for ELI [9]. Given a ﬁnite theory T in a certain normal form,
the rules produce a saturated theory T ′. Here, K, L, M are conjunctions of concept
names, A is a concept name, C is an ELI concept of the form A, ∃r.M, or ∀r.A, and r
is a role name or the inverse of a role name. In this calculus conjunctions are implicitly
viewed as sets, i.e. the order and multiplicity of conjuncts is ignored.
proof P for T |= η is called admissible w.r.t. D(T , η) if there is a homomorphism
h: P →D(T , η). We call D a polynomial deriver if there exists a polynomial p(x)
such that the size of D(T , η) is bounded by p(|T | + |η|). Exponential derivers are
deﬁned similarly by the restriction |D(T , η)| ≤2p(|T |+|η|).
Elk is an example of a polynomial deriver, that is, for a given EL theory T
and EL sentence η, Elk(T , η) contains all allowed instances of the rules shown
in Figure 1. As an example for an exponential deriver we use Eli, which uses
the rules from Figure 4 and is complete for ELI theories and conclusions of the
form A ⊑B, A, B ∈NC. The oracle access for a deriver D works as follows. Let
D = (V, E, ℓ) := D(T , η) and V = {v1, . . . , vm}. D is accessed using the following
two functions, where i, i1, . . . , il are indices of vertices and α is a sentence:
[D](i1, . . . , il, i) :=

true
if ({vi1, . . . , vil}, vi) ∈E,
false
otherwise;
[D](i, α) :=

true
if ℓ(vi) = α,
false
otherwise.
In this paper, we focus on polynomial and exponential derivers, for which we
further make the following technical assumptions: 1) D(T , η) does not contain
two vertices with the same label; 2) the number of premises in an inference is
polynomially bounded by |T | and |η|; and 3) the size of each label is polynomially
bounded by |T | and |η|. While 1) is without loss of generality, 2) and 3) are not.
If a deriver does not satisfy 2), we may be able to ﬁx this by splitting inference
steps. Assumption 3) would not work for derivers with higher complexity, but
is required in our setting to avoid trivial complexity results for exponential
derivers. We furthermore assume that for polynomial and exponential derivers,
the polynomial p from Deﬁnition 4 bounding the size of derivation structures is
known.
Alrabbaa, Baader, Borgwardt, Koopmann, Kovtunova

Good Proofs for DL Entailments
297
3
Measuring Proofs
To formally study quality measures for proofs, we developed the following deﬁni-
tion, which will be instantiated with concrete measures later. Our goal is to ﬁnd
proofs that minimize these measures, i.e. lower numbers are better.
Deﬁnition 5 (Φ-Measure). A (quality) measure is a function m: PL →Q≥0,
where PL is the set of all proofs over L and Q≥0 is the set of non-negative rational
numbers. We call m a Φ-measure if, for every P ∈PL, the following hold.
[P] m(P) is computable in polynomial time in the size of P.
[HI] Let h: P →H be any homomorphism, and P′ be any subproof of the
homomorphic image h(P) that is minimal (w.r.t. m) among all such sub-
proofs having the same sink. Then m(P′) ≤m(P).
Intuitively, a Φ-measure m does not increase when the proof gets smaller, either
when parts of the proof are removed (to obtain a subproof) or when parts
are merged (in a homomorphic image). For example, msize((V, E, ℓ)) := |V | is
a Φ-measure, called the size of a proof, and we have already investigated the
complexity of the following deicision problem for msize in [2].
Deﬁnition 6 (Optimal Proof). Let D be a deriver and m be a measure. Given
a ﬁnite theory T and a sentence η ∈CL s.t. T |= η, an admissible proof P w.r.t.
D(T , η) is called optimal w.r.t. m if m(P) is minimal among all such proofs. The
associated decision problem, denoted OP(D, m), is to decide, given T and η as
above and q ∈Q≥0, whether there is an admissible proof P w.r.t. D(T , η) with
m(P) ≤q.
For our complexity analysis, we distinguish the encoding of q with a subscript
(unary/binary), e.g. OPunary(D, m).
We ﬁrst show that if P is optimal w.r.t. a Φ-measure m and D(T , η), then the
homomorphic image of P in D(T , η) is also a proof. Thus, to decide OP(D, m)
we can restrict our search to proofs that are subgraphs of D(T , η).
Lemma 7. For any deriver D and Φ-measure m, if there is an admissible proof
P w.r.t. D(T , η) with m(P) ≤q for some q ∈Q≥0, then there exists a subproof
Q of D(T , η) for T |= η with m(Q) ≤q.
In particular, this shows that an optimal proof always exists.
Corollary 8. For any deriver D and Φ-measure m, if T |= η, then there is an
optimal proof for T |= η w.r.t. D and m.
Proof. By Deﬁnition 4, the derivation structure D(T , η) contains at least one
proof for T |= η. Since D(T , η) is ﬁnite, there are ﬁnitely many proofs for T |= η
contained in D(T , η). The ﬁnite set of all m-weights of these proofs always has
a minimum. Finally, if there were an admissible proof weighing less than this
minimum, it would contradict Lemma 7.
⊓⊔

298
3.1
Monotone Recursive Measures
Since the complexity of OP(D, m) for Φ-measures in general is quite high [2], in
this paper we focus on a subclass of measures that can be evaluated recursively.
Deﬁnition 9. A Φ-measure m is recursive if there exist
– a leaf function leafm : SL →Q≥0 and
– a partial edge function edgem, which maps (i) the labels (S, α) of a hyperedge
and (ii) a ﬁnite multiset Q of already computed intermediate weights in Q≥0
to a combined weight edgem

(S, α), Q

such that, for any proof P = (V, E, ℓ) with sink v, we have
m(P) =

leafm(ℓ(v))
if V = {v},
edgem

ℓ(S, v), {m(Pw) | w ∈S}

if (S, v) ∈E.
Such a measure is monotone if, for any multiset Q, whenever q ∈Q and
Q′ = (Q\{q})∪{q′} with q′ ≤q and both edgem

(S, α), Q′
and edgem

(S, α), Q

are deﬁned, then edgem

(S, α), Q′
≤edgem

(S, α), Q

.
Intuitively, a recursive measure m can be computed in a bottom-up fashion
starting with the weights of the leaves given by leafm. The function edgem is
used to recursively combine the weights of the direct subproofs into a weight
for the full proof. This function is well-deﬁned since in a proof every vertex
has at most one incoming edge. We require edgem to be deﬁned only for inputs

(S, α), Q

that actually correspond to a valid proof in L, i.e. where S |=L α and
Q consists of the weights of some proofs for the sentences in S. For example, if m
always yields natural numbers, we obviously do not need edgem to be deﬁned for
multisets containing fractional numbers.
In this paper, we are particularly interested in the following monotone recursive
Φ-measures.
– The depth mdepth of a proof is deﬁned by
leafmdepth(α) := 0 and edgemdepth

(S, α), Q

:= 1 + max Q.
– The tree size mtree is given by
leafmtree(α) := 1 and edgemtree

(S, α), Q

:= 1 +

Q.
What distinguishes tree size from size is that vertices are counted multiple
times if they are used in several subproofs. The name tree size is inspired by
the fact that it can be interpreted as the size of the tree unraveling of a given
proof (cf. Figures 2 and 3). In fact, we show in the extended version [4] that
all recursive Φ-measures are invariant under unraveling. This indicates that tree
size, depth and other monotone recursive Φ-measures are especially well-suited
for cases where proofs are presented to users in the form of trees. This is for
example the case for the proof plugin for Protégé [20].
Lemma 10. Depth and tree size are monotone recursive Φ-measures.
Alrabbaa, Baader, Borgwardt, Koopmann, Kovtunova

Good Proofs for DL Entailments
299
Algorithm 1: A Dijkstra-like algorithm
Input: A derivation structure D(T , η) = (V, E, ℓ), a monotone recursive
Φ-measure m
Output: An optimal proof of T |= η w.r.t. D(T , η) and m
1 Q := ∅
2 foreach e ∈E do k(e) := 0
3 foreach v ∈V do
4
if ℓ(v) ∈T then
5
P(v) := ({v}, ∅, ℓ|{v}); Q := Q ∪{v}
// ℓ(v) is in the theory
6
else if (∅, v) ∈E then
7
P(v) := ({v}, {(∅, v)}, ℓ|{v}); Q := Q ∪{v}
// ℓ(v) is a tautology
8
else
9
P(v) := undeﬁned
10 while Q ̸= ∅do
11
choose v ∈Q with minimal m(P(v))
// P(v) is optimal for ℓ(v)
12
Q := Q \ {v}
13
foreach e = (S, d) ∈E with v ∈S do
14
k(e) := k(e) + 1
15
if k(e) = |S| then
// all source vertices have been reached
16
P := (S ∪{d}, e, ℓS∪{d}) ∪
s∈S P(s)
// construct new proof
17
if P is acyclic then
18
if P(d) is undeﬁned or m(P(d)) > m(P) then
19
P(d) := P; Q := Q ∪{d}
// P is better for ℓ(d)
20 return P(vη), where ℓ(vη) = η
4
Complexity Results
We investigate the decision problem OP for monotone recursive Φ-measures. We
ﬁrst show upper bounds for the general case, and then consider measures for depth
and tree size, for which we obtain even lower bounds. An artiﬁcial modiﬁcation
of the depth measure gives a lower bound matching the general upper bound
even if unary encoding is used for the threshold q.
4.1
The General Case
Algorithm 1 describes a Dijkstra-like approach that is inspired by the algorithm
in [13] for ﬁnding minimal hyperpaths w.r.t. so-called additive weighting functions,
which represent a subclass of monotone recursive Φ-measures. The algorithm
progressively discovers proofs P(v) for ℓ(v) that are contained in D(T , η). If it
reaches a new vertex v in this process, this vertex is added to the set Q. In each
step, a vertex with minimal weight m(P(v)) is chosen and removed from Q. For
each hyperedge e = (S, d) ∈E, a counter k(e) is maintained that is increased
whenever a vertex v ∈S is chosen. Once this counter reaches |S|, we know that
all source vertices of e have been processed. The algorithm then constructs a
new proof P for ℓ(d) by joining the proofs for the source vertices using the

300
current hyperedge e. This proof P is then compared to the best previously known
proof P(d) for ℓ(d) and P(d) is updated accordingly. For Line 20, recall that we
assumed D(T , η) to contain no two vertices with the same label, and hence it
contains a unique vertex vη with label η.
Lemma 11. For any monotone recursive Φ-measure m and deriver D, Algo-
rithm 1 computes an optimal proof in time polynomial in the size of D(T , η).
Since we can actually compute an optimal proof in polynomial time in the
size of the whole derivation structure, it is irrelevant how the upper bound q in
the decision problem OP is encoded, and hence the following results follow.
Theorem 12. For any monotone recursive Φ-measure m and polynomial de-
river D, OPbinary(D, m) is in P. It is in ExpTime for all exponential derivers D.
4.2
Proof Depth
We now consider the measure mdepth in more detail. We can show lower bounds
of P and ExpTime for polynomial and exponential derivers, respectively, although
the latter only holds for upper bounds q encoded in binary.
Since our deﬁnition of OP(D, m) requires that the input entailment T |= η
already holds, we cannot use a straightforward reduction from the entailment
problem in EL or ELI, however. Instead, we show that ordinary proofs P for
T |= η satisfy m(P) ≤q for some q, and then extend the TBox to T ′ in order to
create an artiﬁcial proof P′ with m(P′) > q. In this way, we ensure that T ′ |= η
holds and can use q to distinguish the artiﬁcial from the original proofs.
For ELI, we can use an observation from [9, Example 6.29] for this purpose.
Proposition 13 ( [9]).
For every q ∈Q≥0 and ELI sentence of the form
A ⊑B, where A, B ∈NC, one can construct in time polynomial in q an ELI
theory T such T |= A ⊑B, and every proof for T |= A ⊑B in Eli is of depth
larger than 2q.
We can now reduce the entailment problems for EL and ELI to obtain the
claimed lower bounds.
Theorem 14. The problems OPunary(Elk, mdepth) and OPbinary(Eli, mdepth) are
P-hard and ExpTime-hard, respectively.
Proof. For the P-hardness, we provide a LogSpace-reduction from the entail-
ment problem of a GCI A ⊑B with two concept names A, B from an EL-theory T ,
which is P-hard [9]. To reduce this problem to OPunary(Elk, mtree), we need to
ﬁnd a theory T ′ and a number q such that T ′ |= A ⊑B holds, and moreover
T |= A ⊑B holds iﬀElk(T ′, A ⊑B) contains a proof of T ′ |= A ⊑B of depth
≤q (cf. Lemma 7).
First, observe that, since proofs must be acyclic, the depth of any proof
of A ⊑B from T is bounded by q := |Elk(T , A ⊑B)|, whose size in unary
encoding is polynomial in the size of T . We now construct
T ′ := T ∪{A ⊑A1, A1 ⊑A2, . . . , Aq+2 ⊑B},
Alrabbaa, Baader, Borgwardt, Koopmann, Kovtunova

Good Proofs for DL Entailments
301
where A1, . . . , Aq are concept names not occurring in T . Clearly, we have
T ′ |= A ⊑B. Furthermore, the existence of an admissible proof for T ′ |= A ⊑B
of depth at most q is equivalent to T |= A ⊑B, since any proof that uses the
new concept names must take q + 1 consecutive steps using rule R⊑, i.e. must
be of depth q + 1. Moreover, we can compute q (in binary representation) and
output it in unary representation using a logarithmically space-bounded Turing
machine, and similarly for T ′. Hence, the above construction constitutes the
desired LogSpace-reduction.
For the remaining result, we can use similar arguments about the exponential
deriver Eli, where entailment is ExpTime-hard [9]:
– the minimal depth of a proof in an exponential derivation structure is at most
exponential, and this exponential bound q can be computed in polynomial
time using binary encoding;
– by Proposition 13, there is an ELI theory T of size polynomial in the size of
the binary encoding of q such that T |= A ⊑B and any proof for T |= A ⊑B
must have at least depth q + 1.
⊓⊔
To demonstrate that the generic upper bounds from Theorem 12 are tight
even for unary encoding, we quickly consider the artiﬁcial measure mlog(depth)
(logarithmic depth), which simply computes the (binary) logarithm of the depth of
a given proof. This is also a monotone recursive Φ-measure, since the logarithmic
depth contains exactly the same information as the depth itself. It is easy to
obtain the following lower bounds from the previous results about mdepth.
Corollary 15. OPunary(Elk, mlog(depth)) is P-hard and OPunary(Eli, mlog(depth))
is ExpTime-hard.
Proof. For any deriver D, OPbinary(D, mdepth) can be LogSpace-reduced to
OPunary(D, mlog(depth)), because in order to ﬁnd a proof of depth at most q (with
q given in binary), one can equivalently look for a proof whose logarithmic depth
is bounded by the value log q. The unary encoding of log q has the same size as
the binary encoding of q and can be computed in LogSpace by ﬂipping all bits
of the binary encoding of q to 1.
⊓⊔
We now return to mdepth and cover the remaining case of exponential derivers
and unary encoding of the upper bound q.
Theorem 16. OPunary(D, mdepth) is in PSpace for any exponential deriver D.
It is PSpace-hard for the exponential deriver D = Eli.
Proof. For the upper bound, we employ a depth-ﬁrst guessing strategy: we guess
a proof of depth at most q, where at each time point we only keep one branch of
the proof in memory. As the length of this branch is bounded by q, and due to
our assumptions on derivers, this procedure only requires polynomial space.
For the lower bound, we provide a reduction from the PSpace-complete QBF
problem (satisﬁability of quantiﬁed Boolean formulas). Let Q1x1Q2x2 . . . Qmxm.φ
be a quantiﬁed Boolean formula, where for i ∈{1, . . . , m}, Qi ∈{∃, ∀}, and φ is

302
a formula over {x1, . . . , xm}. We assume φ to be in negation normal form, that is,
negation only occurs directly in front of a variable. We construct an ELI theory
T and a number q, both of size polynomial in the size of the formula, such that
T |= A ⊑B holds (cf. Deﬁnition 6) and T has a proof for A ⊑B of depth q
iﬀthe QBF formula is valid. We use two roles r1, r2 to deal with the variable
valuations, concept names A0, . . ., Am to count the quantiﬁer nesting, and a
concept name Aψ for every sub-formula ψ of φ. In addition, we use the concept
names A and B occurring in the conclusion, and two concept names B1 and B2.
The concept name A initializes the formula at quantiﬁer nesting level 0:
A ⊑A0
For every i ∈{1, . . . , m}, T contains the following sentence to select a truth
valuation for xi, increasing the nesting depth in each step.
Ai−1 ⊑∃r1.(Ai ⊓Axi)
(1)
Ai−1 ⊑∃r2.(Ai ⊓A¬xi).
(2)
To ensure truth valuations are kept along the role-successors, we use the following
sentences for every l ∈{xi, ¬xi | 1 ≤i ≤m}:
Al ⊑∀r1.Al
Al ⊑∀r2.Al
(3)
The following GCIs are now used to evaluate φ. For every conjunction ψ = ψ1∧ψ2
occurring in φ, we use:
Aψ1 ⊓Aψ2 ⊑Aψ,
(4)
and for every disjunction ψ = ψ1 ∨ψ2, we use:
Aψ1 ⊑Aψ
Aψ2 ⊑Aψ
(5)
Finally, the following GCIs are used to propagate the result of the evaluation
back towards the start.
Aφ ⊑B
(6)
Ai ⊓B ⊑∀r−
1 .B
Ai ⊓B ⊑∀r−
2 .B
if Qi = ∃(7)
Ai ⊓B ⊑∀r−
1 .B1
Ai ⊓B ⊑∀r−
2 .B2
B1 ⊓B2 ⊑B
if Qi = ∀(8)
One can now show that there exists a proof for A ⊑B from T of depth at most q
iﬀthe QBF formula is valid, where q is polynomial and determined by the size and
structure of φ. Finally, we can extend T with the sentences from Proposition 13
to ensure that T |= A ⊑B holds while retaining this equivalence.
⊓⊔
4.3
The Tree Size Measure
The tree size measure was discussed already in [2], where tight bounds were
provided for polynomial derivers and exponential derivers with unary encoding.
For the case of exponential derivers with binary encoding, only an ExpTime
upper bound was provided, and the precise complexity left open. We improve
this result by showing that OPbinary(D, mtree) can indeed be decided in PSpace.
Alrabbaa, Baader, Borgwardt, Koopmann, Kovtunova

Good Proofs for DL Entailments
303
a
b
c
d
e
f
g
h
i
j
k
l
m
n
o
a
b
c
d
e
f
g
h
i
j
k
l
m
n
o
ϵ
(b,7)
(i,7)
ϵ
(i,7)
(c,2)
(e,3)
(h,1)
Fig. 5. Illustration of the argument used for Theorem 17. On the top, the partially
guessed proof tree for two consecutive steps of the algorithm is shown, where the
dark nodes are what is currently kept in memory. On the bottom, we see how the
corresponding tuples are organized into a tree satisfying Conditions S1–S6.
Theorem 17. For any exponential deriver D, OPbinary(D, mtree) is in PSpace.
Proof (sketch). We describe a non-deterministic procedure for OPbinary(D, mtree),
in polynomial space. Let T be a theory, η the goal sentence, and q a rational
number in binary encoding. By Lemma 7, it suﬃces to ﬁnd a proof P for T |= η
in D(T , η) with mtree(P) ≤q. The procedure guesses such a proof starting from
the conclusion, while keeping in memory a set S of tuples (η′, q′), where η′ is a
sentence and q′ ≤q a rational number. Intuitively, such a tuple states: “We still
need to guess a proof for η′ of tree size at most q′.”
1. Initialize S := {(η, q)}.
2. While S ̸= ∅,
(a) select from S a tuple (η′, q′) such that for all tuples (η′′, q′′) ∈S it holds
that q′′ ≥q′;
(b) guess a hyperedge ({v1, . . . , vm}, v′) in D(T , η) (using the oracle access
described in Section 2.2) and m numbers q1, . . ., qm, such that ℓ(v′) = η′
and q1 + . . . + qm + 1 ≤q′; and
(c) replace (η′, q′) in S by the tuples (ℓ(v1), q1), . . ., (ℓ(vm), qm).
There is a proof for T |= η of tree size at most q iﬀevery step in the algorithm
is successful. To show that it only requires polynomial space, we show that during
the computation, the number of elements in S is always polynomially bounded.
For this, we show that the elements in S can always be organized into a tree
with the following properties:
S1 the root is labeled with ϵ,
S2 every other node is labeled with a distinct element from S,
S3 every node that is not the root or a leaf has at least 2 children,
S4 every node has at most p children, where p is the maximal number of premises
in any inference in D(T , η), which we assumed to be polynomial in the input,
S5 every node (η′, q′) has at most 1 child (η′′, q′′) that is not a leaf and for this
child it holds that q′′ < q′
2 ,

304
S6 for every node labeled (η′, q′) with children labeled (η1, q1), . . ., (ηm, qm), we
have q1 + . . . + qm < q′.
We prove this by induction on the steps of the algorithm, where in each step, we
either replace one tuple in the tree, or put the new tuples under the leaf with
the currently smallest value (see Fig.5). By S3 and because every number in S is
bounded by q, we can show that the tree has depth at most log2 q, which with S4
and S5 implies that it has at most p · log2 q nodes. S2 then implies that that
|S| ≤p · log2 q is always satisﬁed, and thus that S is polynomially bounded.
⊓⊔
A corresponding lower bound can be found for the exponential deriver Eli
by a reduction of the word problem for deterministic Turing machines with
polynomial space bound.
Theorem 18. For the exponential deriver Eli, OPbinary(Eli, mtree) is PSpace-
hard.
Proof (sketch). Let T = (Q, Γ,b, Σ, δ, q0, F) be a deterministic Turing machine,
where Q is the set of states, Γ the tape alphabet, b ∈Γ the blank symbol, Σ ⊆Γ
the input alphabet, δ : Q × Γ ̸→Q × Γ × {−1, 0, +1} the partial transition
function, q0 the initial state, and F ⊆Q the accepting states. We assume that T
is polynomially space bounded, that is, there is a polynomial p such that on input
words w ∈Σ∗, T only accesses the ﬁrst p(|w|) cells of the tape. For a word w,
we denote by w[i] its ith letter. For some ﬁxed word w, we construct a theory T
using the following names, where k = p(|w|):
– Start marks the inital and Accept an accepting conﬁguration;
– to denote that we are in state q ∈Q, we use a concept name Sq;
– for every a ∈Γ and i ∈{0, . . . , k}, we use a concept name Aa
i denoting that
the letter a is on tape position i;
– for every i ∈{0, . . . , k}, we use the concept name P +
i
to denote that the
head is currently on position i, and P −
i
to denote that it is not;
– the role r is used to express the transitions between the conﬁgurations.
For convenience, we present the theory not in the required normal form, but
aggregate conjunctions on the right. The following sentence describes the initial
conﬁguration.
Start ⊑Sq0 ⊓
|w|−1

i=0
Aw[i]
i
⊓
k
i=|w|
Ab
i ⊓P +
0 ⊓
k
i=1
P −
i
(9)
The transition from one conﬁguration to the next is encoded with the following
sentences for every i ∈{0, . . . , k} and every (q, a) ∈Q×Γ with δ(q, a) = (q′, b, d):
Sq ⊓Aa
i ⊓P +
i ⊑∃r.Sq′ ⊓∀r.Ab
i ⊓∀r.P +
i+d ⊓

j∈{0,...,k}\{i+d}
∀r.P −
j
(10)
Aa
i ⊓P −
i
⊑∀r.Aa
i
(11)
Alrabbaa, Baader, Borgwardt, Koopmann, Kovtunova

Good Proofs for DL Entailments
305
Finally, we use the following sentences to detect accepting conﬁgurations and
propagate the information of acceptance back to the initial conﬁguration
Sf ⊑Accept for all f ∈F,
(12)
Accept ⊑∀r−.Accept
(13)
One can ﬁnd a number q exponential in k and the size of T s.t. that there is
a proof for T |= Start ⊑Accept with tree size at most q iﬀT accepts w. Using
Proposition 13, we can extend T to a theory T ′ s.t. T ′ |= Start ⊑Accept, while
a proof of tree size q exists iﬀT accepts w (observe that mtree(P) ≥mdepth(P)
holds for all proofs P).
⊓⊔
5
Conclusion
We have investigated the complexity of ﬁnding optimal proofs w.r.t. quality
measures that satisfy the property of being monotone recursive. Two important
examples of this class of measures, depth and tree size, have been considered in
detail in combination with exponential and polynomial derivers. The obtained
results are promising: given a deriver, the search for an optimal proof for an
entailment can be easier than producing all of the proofs by this deriver. The
algorithms used to show the upper bounds can serve as building blocks for ﬁnding
an optimal proof w.r.t. to a monotone recursive measure automatically.
We conjecture that weighted versions of tree size and depth, where sentences or
inference steps can have associated rational weights, are also monotone recursive,
and the generic upper bounds established in this paper can be straightforwardly
applied to them. However, a more thorough study is required here, since the
complexity of the decision problem depends on the exact way in which the
weights are employed. This step towards weighted measures is motivated by user
studies [1, 15, 24], demonstrating that diﬀerent types of sentences and logical
inferences can be more or less diﬃcult to understand.
Acknowledgements This work was supported by the DFG in grant 389792660 as
part of TRR 248 (https://perspicuous-computing.science), and QuantLA, GRK
1763 (https://lat.inf.tu-dresden.de/quantla).
References
1. Alharbi, E., Howse, J., Stapleton, G., Hamie, A., Touloumis, A.: The eﬃcacy of
OWL and DL on user understanding of axioms and their entailments. In: d’Amato,
C., Fernández, M., Tamma, V.A.M., Lécué, F., Cudré-Mauroux, P., Sequeda,
J.F., Lange, C., Heﬂin, J. (eds.) ISWC 2017 - 16th International Semantic Web
Conference, Proceedings. Lecture Notes in Computer Science, vol. 10587, pp. 20–36.
Springer (2017). https://doi.org/10.1007/978-3-319-68288-4_2
2. Alrabbaa, C., Baader, F., Borgwardt, S., Koopmann, P., Kovtunova, A.: Finding
small proofs for description logic entailments: Theory and practice. In: Albert, E.,

306
Kovacs, L. (eds.) LPAR-23: 23rd International Conference on Logic for Programming,
Artiﬁcial Intelligence and Reasoning. EPiC Series in Computing, vol. 73, pp. 32–67.
EasyChair (2020). https://doi.org/10.29007/nhpp
3. Alrabbaa, C., Baader, F., Borgwardt, S., Koopmann, P., Kovtunova, A.: On the
complexity of ﬁnding good proofs for description logic entailments. In: Borgwardt,
S., Meyer, T. (eds.) Proceedings of the 33rd International Workshop on Description
Logics (DL 2020). CEUR Workshop Proceedings, vol. 2663. CEUR-WS.org (2020),
http://ceur-ws.org/Vol-2663/paper-1.pdf
4. Alrabbaa, C., Baader, F., Borgwardt, S., Koopmann, P., Kovtunova, A.:
Finding good proofs for description logic entailments using recursive quality
measures (extended technical report) (2021), https://arxiv.org/abs/2104.13138,
arXiv:2104.13138 [cs.AI]
5. Alrabbaa, C., Baader, F., Dachselt, R., Flemisch, T., Koopmann, P.: Visualising
proofs and the modular structure of ontologies to support ontology repair. In: DL
2020: International Workshop on Description Logics. CEUR Workshop Proceedings,
vol. 2663. CEUR-WS.org (2020), http://ceur-ws.org/Vol-2663/paper-2.pdf
6. Arrieta, A.B., Diaz-Rodriguez, N., Ser, J.D., Bennetot, A., Tabik, S., Barbado,
A., Garcia, S., Gil-Lopez, S., Molina, D., Benjamins, R., Chatila, R., Herrera, F.:
Explainable Artiﬁcial Intelligence (XAI): Concepts, taxonomies, opportunities and
challenges toward responsible AI. Information Fusion 58, 82–115 (2020). https:
//doi.org/10.1016/j.inﬀus.2019.12.012
7. Baader, F., Brandt, S., Lutz, C.: Pushing the EL envelope. In: Kaelbling, L.P., Saf-
ﬁotti, A. (eds.) Proc. of the 19th Int. Joint Conf. on Artiﬁcial Intelligence (IJCAI’05).
pp. 364–369. Professional Book Center (2005), http://ijcai.org/Proceedings/09/
Papers/053.pdf
8. Baader, F., Brandt, S., Lutz, C.: Pushing the EL envelope further. In: Clark, K.,
Patel-Schneider, P.F. (eds.) Proc. of the 4th Workshop on OWL: Experiences and Di-
rections. pp. 1–10 (2008), http://webont.org/owled/2008dc/papers/owled2008dc_
paper_3.pdf
9. Baader, F., Horrocks, I., Lutz, C., Sattler, U.: An Introduction to Description Logic.
Cambridge University Press (2017). https://doi.org/10.1017/9781139025355
10. Baader, F., Suntisrivaraporn, B.: Debugging SNOMED CT using axiom pinpointing
in the description logic EL+. In: Proc. of the 3rd Conference on Knowledge Repre-
sentation in Medicine (KR-MED’08): Representing and Sharing Knowledge Using
SNOMED. CEUR-WS, vol. 410 (2008), http://ceur-ws.org/Vol-410/Paper01.pdf
11. Borgida, A., Franconi, E., Horrocks, I.: Explaining ALC subsumption. In: ECAI
2000, Proceedings of the 14th European Conference on Artiﬁcial Intelligence, Berlin,
Germany, August 20-25, 2000. pp. 209–213 (2000), http://www.frontiersinai.com/
ecai/ecai2000/pdf/p0209.pdf
12. Fiedler, A.: Natural language proof explanation. In: Mechanizing Mathematical
Reasoning, Essays in Honor of Jörg H. Siekmann on the Occasion of His 60th
Birthday. pp. 342–363 (2005). https://doi.org/10.1007/978-3-540-32254-2_20
13. Gallo, G., Longo, G., Pallottino, S.: Directed hypergraphs and applications.
Discrete Applied Mathematics 42(2), 177–201 (1993). https://doi.org/10.1016/
0166-218X(93)90045-P
14. Horridge, M.: Justiﬁcation Based Explanation in Ontologies. Ph.D. thesis, University
of Manchester, UK (2011), https://www.research.manchester.ac.uk/portal/ﬁles/
54511395/FULL_TEXT.PDF
Alrabbaa, Baader, Borgwardt, Koopmann, Kovtunova

Good Proofs for DL Entailments
307
15. Horridge, M., Bail, S., Parsia, B., Sattler, U.: Toward cognitive support for OWL
justiﬁcations. Knowl. Based Syst. 53, 66–79 (2013). https://doi.org/10.1016/j.
knosys.2013.08.021, https://doi.org/10.1016/j.knosys.2013.08.021
16. Horridge, M., Parsia, B., Sattler, U.: Justiﬁcation oriented proofs in OWL. In: The
Semantic Web - ISWC 2010 - 9th International Semantic Web Conference, ISWC
2010, Shanghai, China, November 7-11, 2010, Revised Selected Papers, Part I. pp.
354–369 (2010). https://doi.org/10.1007/978-3-642-17746-0_23
17. Huang, X.: Reconstruction proofs at the assertion level. In: Proceedings of the
12th International Conference on Automated Deduction. p. 738–752. CADE-12,
Springer-Verlag (1994). https://doi.org/10.1007/3-540-58156-1_53
18. Kazakov, Y.: Consequence-driven reasoning for horn SHIQ ontologies. In: Boutilier,
C. (ed.) IJCAI 2009, Proceedings of the 21st International Joint Conference on
Artiﬁcial Intelligence, Pasadena, California, USA, July 11-17, 2009. pp. 2040–2045
(2009), http://ijcai.org/Proceedings/09/Papers/336.pdf
19. Kazakov, Y., Klinov, P.: Goal-directed tracing of inferences in EL ontologies. In:
Mika, P., Tudorache, T., Bernstein, A., Welty, C., Knoblock, C.A., Vrandecic,
D., Groth, P.T., Noy, N.F., Janowicz, K., Goble, C.A. (eds.) Proc. of the 13th
International Semantic Web Conference (ISWC 2014). Lecture Notes in Com-
puter Science, vol. 8797, pp. 196–211. Springer (2014). https://doi.org/10.1007/
978-3-319-11915-1_13
20. Kazakov, Y., Klinov, P., Stupnikov, A.: Towards reusable explanation services in
Protege. In: Artale, A., Glimm, B., Kontchakov, R. (eds.) Proc. of the 30th Int.
Workshop on Description Logics (DL’17). CEUR Workshop Proceedings, vol. 1879
(2017), http://www.ceur-ws.org/Vol-1879/paper31.pdf
21. Kazakov, Y., Krötzsch, M., Simancik, F.: The incredible ELK – from polynomial
procedures to eﬃcient reasoning with EL ontologies. J. Autom. Reasoning 53(1),
1–61 (2014). https://doi.org/10.1007/s10817-013-9296-3
22. Lingenfelder, C.: Structuring computer generated proofs. In: Proceedings of the 11th
International Joint Conference on Artiﬁcial Intelligence. Detroit, MI, USA, August
1989. pp. 378–383 (1989), http://ijcai.org/Proceedings/89-1/Papers/060.pdf
23. McGuinness, D.L.: Explaining Reasoning in Description Logics. Ph.D. thesis, Rut-
gers University, NJ, USA (1996). https://doi.org/10.7282/t3-q0c6-5305
24. Nguyen, T.A.T., Power, R., Piwek, P., Williams, S.: Measuring the understandabil-
ity of deduction rules for OWL. In: Proceedings of the First International Workshop
on Debugging Ontologies and Ontology Mappings, WoDOOM 2012, Galway, Ire-
land, October 8, 2012. pp. 1–12 (2012), http://www.ida.liu.se/~patla/conferences/
WoDOOM12/papers/paper4.pdf
25. Nguyen, T.A.T., Power, R., Piwek, P., Williams, S.: Predicting the understandability
of OWL inferences. In: The Semantic Web: Semantics and Big Data, 10th Interna-
tional Conference, ESWC 2013, Montpellier, France, May 26-30, 2013. Proceedings.
pp. 109–123 (2013). https://doi.org/10.1007/978-3-642-38288-8_8
26. Schiller, M.R.G., Glimm, B.: Towards explicative inference for OWL. In: Informal
Proceedings of the 26th International Workshop on Description Logics, Ulm, Ger-
many, July 23 - 26, 2013. pp. 930–941 (2013), http://ceur-ws.org/Vol-1014/paper_
36.pdf
27. Schiller, M.R.G., Schiller, F., Glimm, B.: Testing the adequacy of automated
explanations of EL subsumptions. In: Proceedings of the 30th International
Workshop on Description Logics, Montpellier, France, July 18-21, 2017. (2017),
http://ceur-ws.org/Vol-1879/paper43.pdf

308
28. Schlobach, S., Cornet, R.: Non-standard reasoning services for the debugging of
description logic terminologies. In: Gottlob, G., Walsh, T. (eds.) Proc. of the 18th Int.
Joint Conf. on Artiﬁcial Intelligence (IJCAI 2003). pp. 355–362. Morgan Kaufmann,
Acapulco, Mexico (2003), http://ijcai.org/Proceedings/03/Papers/053.pdf
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium or
format, as long as you give appropriate credit to the original author(s) and the source,
provide a link to the Creative Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.
Alrabbaa, Baader, Borgwardt, Koopmann, Kovtunova

Computing Optimal Repairs of
Quantiﬁed ABoxes w.r.t. Static EL TBoxes⋆
Theoretical Computer Science, TU Dresden, Dresden, Germany
firstname.lastname@tu-dresden.de
Abstract. The application of automated reasoning approaches to De-
scription Logic (DL) ontologies may produce certain consequences that
either are deemed to be wrong or should be hidden for privacy reasons.
The question is then how to repair the ontology such that the unwanted
consequences can no longer be deduced. An optimal repair is one where
the least amount of other consequences is removed. Most of the previ-
ous approaches to ontology repair are of a syntactic nature in that they
remove or weaken the axioms explicitly present in the ontology, and
thus cannot achieve semantic optimality. In previous work, we have ad-
dressed the problem of computing optimal repairs of (quantiﬁed) ABoxes,
where the unwanted consequences are described by concept assertions of
the lightweight DL EL. In the present paper, we improve on the results
achieved so far in two ways. First, we allow for the presence of termino-
logical knowledge in the form of an EL TBox. This TBox is assumed to
be static in the sense that it cannot be changed in the repair process. Sec-
ond, the construction of optimal repairs described in our previous work
is best case exponential. We introduce an optimized construction that
is exponential only in the worst case. First experimental results indicate
that this reduces the size of the computed optimal repairs considerably.
1
Introduction
Description Logics [3] are a well-investigated family of logic-based knowledge
representation languages, which are frequently used to formalize ontologies for
application domains such as biology and medicine [17]. As the size of ontolo-
gies grows, the likelihood of them containing errors increases as well. This is
particularly problematic if the data, stored in the ABox, are automatically ex-
tracted from text or other sources using natural language processing or machine
learning. The reasoning services of DL systems [22,12,33,15], which derive im-
plicit consequences from the explicitly represented knowledge, are not only useful
once an ontology is deployed, but can also be employed for debugging purposes
by exhibiting consequences that are not supposed to hold in the application
⋆funded by DFG in project number 430150274 and TRR 248 (cpec, grant 389792660).
c⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5_18
Franz Baader
, Patrick Koopmann
, Francesco Kriegel
, and
309–326, 2021.
Adrian Nuradiansyah

310
F. Baader, P. Koopmann, F. Kriegel, and A. Nuradiansyah
domain. Another reason why one might want to remove a consequence is that
it reveals private information that is supposed to be hidden [14,5]. Once such
an unwanted consequence is detected, it is often not easy to see how to repair
the ontology in order to get rid of this consequence. Classical repair approaches
based on axiom pinpointing [31,29,27,32,21,8] compute maximal subsets of the
ontology that do not have the consequence. The obtained result thus strongly
depends on the syntactic form of the axioms. For example, it is well-known that,
for expressive DLs, a ﬁnite set of terminological axioms can be expressed by a
single axiom. If the given terminology (TBox) is of this shape, then the only
possible classical repair is the empty TBox. To alleviate this problem, repair
approaches have been developed that replace certain axioms by weaker ones (in
the sense that they have less consequences) instead of removing them completely
[18,24,34,6]. However, these approaches usually do not produce optimal repairs.
In fact, it was shown in [6] that, even for the inexpressive DL EL, optimal repairs
need not exist. The abstract example given there can be rephrased as follows.
Assume that the TBox deﬁnes humans to be exactly those individuals that have
a human parent, and that the ABox says that Sam is a human. After we ﬁnd
out that Sam is in fact not human [9], we want to get rid of the latter assertion,
but keep the (correct) consequences saying that Sam has an unbounded chain
of ancestors (of undetermined species). If the TBox is assumed to be ﬁxed, then
there is no optimal repair of the ABox since we can add only a ﬁnite number of
parent assertions.
To avoid such problems, our previous work on computing optimal repairs (for-
mulated in the guise of achieving compliance with privacy policies) restricted the
attention to the case without TBox. In [5] the ABox was additionally restricted
to be a so-called instance store [19], i.e., an ABox without role assertions. The
privacy policy (specifying which consequences are to be removed) was given as
EL instance queries. In this setting, optimal repairs always exist and can be com-
puted in exponential time, which is optimal since there may be exponentially
many optimal repairs of exponential size.
In [7] these results were extended to ABoxes with role assertions. More
precisely, we considered quantiﬁed ABoxes in which some individuals are
anonymized by viewing them as existentially quantiﬁed variables. For example,
assume that the ABox contains the information that Ben has a parent, Jerry, that
is both rich and famous, and we want to remove the consequence
E
parent.(Rich⊓
Famous)(BEN). Classical repairs can be obtained by removing one of the asser-
tions Rich(JERRY ), Famous(JERRY ), and parent(BEN, JERRY ). If instead
we replace the ﬁrst assertion with Rich(x) and parent(BEN, x) for an existen-
tially quantiﬁed variable x, then we retain more consequences. Note that we could
not have used an individual name (i.e., constant) ANNE instead of x since infor-
mation like Rich(ANNE) about Anne does not follow from the original ABox.
We show in [7] that in this setting all optimal repairs can be computed by an
exponential-time algorithm with access to an NP-oracle. The oracle is needed
since our algorithm ﬁrst computes a superset of the set of optimal repairs, from
which non-optimal ones need to be removed using the (NP-complete) entail-

Optimal Repairs w.r.t. Static TBoxes
311
ment test between (potentially exponentially large) quantiﬁed ABoxes. We also
consider a modiﬁed version of entailment (called IQ-entailment) in [7], where
quantiﬁed ABoxes are compared w.r.t. which EL instance relationships they
imply. Using this notion, no NP-oracle is needed for computing the set of all
IQ-optimal repairs since IQ-entailment can be decided in polynomial time.
In the present paper, we improve on these results in two respects. On the one
hand, we allow for the presence of terminological knowledge in the form of an
EL TBox, which is assumed to be correct, and thus is not changed by the repair.
To deal with a TBox, the approach from [7] for computing optimal repairs must
be extended in two ways. First, the ABox needs to be saturated w.r.t. the TBox
before applying our repair approach. The saturated ABox has the same conse-
quences as the original one has together with the TBox. In our Ben and Jerry
example, assume that the assertion Rich(JERRY ) does not belong to the original
ABox, but the TBox contains the axiom Famous ⊑Rich. Then the ABox on its
own does not have the unwanted consequence
E
parent.(Rich ⊓Famous)(BEN),
but together with the TBox it does. Saturation adds the assertion Rich(JERRY )
to the ABox. For arbitrary TBoxes, saturation need not terminate. We consider
two ways to remedy this problem: either allow for arbitrary TBoxes, but con-
sider IQ-entailment, or use classical entailment, but consider cycle-restricted
TBoxes [1]. In both cases, saturation always terminates; in the former in poly-
nomial and in the latter in exponential time. One might be tempted to assume
that, after saturation, one can simply apply the repair approach of [7] unchanged.
This is not true, however, since the TBox may re-add assertions that have been
removed or replaced by the repair. In our example, where Rich(JERRY ) is re-
placed, but Famous(JERRY ) is left untouched in the repair, the repaired ABox
together with the TBox would still have the unwanted consequence. Thus, the
repair approach needs to be changed to take this possibility into account.
On the other hand, the construction of optimal repairs described in our pre-
vious work [5,7], and extended in this paper such that it can deal with TBoxes,
is best case exponential. The second contribution of this paper is the design of a
new construction, both for classical and IQ-entailment, that is exponential only
in the worst case. We also report on ﬁrst experimental results, which indicate
that this reduces the size of the computed optimal repairs considerably.
Detailed proofs of our results can be found in [4].
2
Preliminaries
Throughout this paper, we assume that Σ is a signature, which is a disjoint
union of sets ΣO, ΣC, and ΣR of object names, concept names, and role names.
We use symbols t, u, v, w to denote object names, A, B to denote concept names,
and r, s to denote role names, all of them possibly with sub- or superscripts.
As in [7], a quantiﬁed ABox (qABox)
E
X.A over Σ consists of a ﬁnite subset
X of ΣO, the elements of which are called variables, and a matrix A, which is
a ﬁnite set of concept assertions A(u) where u ∈ΣO and A ∈ΣC, and of role
assertions r(u, v) where u, v ∈ΣO and r ∈ΣR. An non-variable object name in

312
E
X.A is called an individual name, and the set of all these names is denoted as
ΣI(
E
X.A). We further set ΣO(
E
X.A) := ΣI(
E
X.A)∪X. Traditional DL ABoxes
are qABoxes where X = ∅; we then write A instead of
E
∅.A. The matrix of a
qABox is such a traditional ABox.
An interpretation I of Σ is a pair (ΔI, ·I), where the domain ΔI is a non-
empty set and the interpretation function ·I maps each u ∈ΣO to an element uI
of ΔI, each A ∈ΣC to a set AI ⊆ΔI, and each r ∈ΣR to a binary relation rI
over ΔI. The interpretation I of Σ is a model of a qABox
E
X.A over Σ if there
is an interpretation J such that ΔI = ΔJ , the interpretation functions ·I and
·J coincide on Σ \ X, and uJ ∈AJ for each A(u) ∈A as well as (uJ , vJ ) ∈rJ
for each r(u, v) ∈A.
Following [7], we deﬁne EL atoms and EL concept descriptions over Σ by
simultaneous induction as follows. An EL atom is either a concept name A ∈ΣC
or an existential restriction
E
r.C for some role name r ∈ΣR and an EL concept
description C. An EL concept description is a conjunction  C where C is a
ﬁnite set of EL atoms. An EL concept inclusion is of the form C ⊑D for EL
concept descriptions C and D, and an EL TBox is a ﬁnite set of such concept
inclusions. An EL concept assertion is an expression C(u), where C is an EL
concept description and u ∈ΣO.
For each interpretation I of Σ, we extend the interpretation function ·I to
EL atoms and EL concept descriptions in the following manner:
– (
E
r.C)I := { δ | there exists some γ such that (δ, γ) ∈rI and γ ∈CI },
– ( C)I := { CI | C ∈C } where  ∅= ΔI.
The interpretation I is a model of the concept inclusion C ⊑D (the concept
assertion C(u)) if CI ⊆DI (uI ∈CI), and of the TBox T if it is a model of
each concept inclusion in T .
To make the syntax introduced above more akin to the one usually em-
ployed for EL, we denote the empty conjunction  ∅as ⊤(top concept), single-
ton conjunctions {C} as C, and conjunctions  C for |C| ≥2 as C1 ⊓. . . ⊓Cn,
where C1, . . . , Cn is an enumeration of the elements of C in an arbitrary or-
der. Since we do not distinguish between the singleton conjunction {C} and
the atom C, each atom is also a concept description. The set Sub(C) of sub-
concepts of an EL concept description C is deﬁned as follows: Sub(A) := {A},
Sub(
E
r.C) := {
E
r.C} ∪Sub(C), and Sub( C) := { C} ∪{ Sub(D) | D ∈C }.
The set Atoms(C) consists of all atoms contained in Sub(C). These two notions
are extended to TBoxes and sets of concept assertions in the obvious way.
Let α, β be qABoxes, concept inclusions, or concept assertions (possibly not
both of the same kind), and T an EL TBox. Then we write I |= α if the
interpretation I is a model of α. We say that α entails β w.r.t. T (written
α |=T β) if every model of α and T is a model of β. Furthermore, α and β
are equivalent w.r.t. T (written α ≡T β), if α |=T β and β |=T α. In case
T = ∅, we will sometimes write |= instead of |=∅. If
E
∅.∅|=T C ⊑D, then
we also write C ⊑T D and say that C is subsumed by D w.r.t. T ; in case
T = ∅we simply say that C is subsumed by D. Two EL concept descriptions are
equivalent w.r.t. T (written C ≡T D) if they subsume each other w.r.t. T . We
F. Baader, P. Koopmann, F. Kriegel, and A. Nuradiansyah

Optimal Repairs w.r.t. Static TBoxes
313
write C ⊏T D to indicate that C ⊑T D, but C ̸≡T D. If
E
X.A |=T C(a), then
a is called an instance of C w.r.t.
E
X.A and T . For EL, the subsumption and
the instance problem are decidable in polynomial time [2]. However, entailment
between qABoxes is NP-complete even w.r.t. the empty TBox [7].
We also use the reduced form Cr of EL concept descriptions C [23], which is
obtained by removing redundant subdescriptions (see [7] for details). Adapting
the results in [23], one can show that C ≡∅Cr and that C ≡∅D implies Cr = Dr.
3
A Tale of Two Entailments
DL-based ontologies are usually accessed through appropriate query languages,
where for the purpose of this paper it is suﬃcient to assume that a query lan-
guage is given by a fragment of ﬁrst-order logic. Instead of comparing ontologies
w.r.t. the models they have, it thus makes sense to compare them w.r.t. the
answers to queries they entail [25]. Given such a query language QL and an EL
TBox T , we say that the qABox
E
X.A QL-entails the qABox
E
Y.B w.r.t. T
(written
E
X.A |=T
QL
E
Y.B) if for each query ϕ(x1, . . . , xk) ∈QL and each tu-
ple of individuals (a1, . . . , ak) we have that T ∧
E
Y.B |= ϕ(a1, . . . , ak) implies
T ∧
E
X.A |= ϕ(a1, . . . , ak), where we view the TBox and the ABox as ﬁrst-order
formulae and |= is classical ﬁrst-order entailment (see [25] for more details). We
say that two qABox are QL-equivalent w.r.t. T if they QL-entail each other
w.r.t. T , and denote this equivalence relation as ≡T
QL.
For EL ontologies, one usually considers instance queries (IQ) or conjunc-
tive queries (CQ). The former are given by EL concept descriptions, viewed as
ﬁrst-order formulae with one free variable. The latter are basically qABoxes of
the form
E
X.A, but with the elements of ΣI(
E
X.A) viewed as free variables.
Replacing these free variables with a tuple of individuals thus yields a qABox in
the sense introduced above. In particular, this means that CQ-entailment cor-
responds to entailment of the same qABoxes (see [7] for more details regarding
the connection between conjunctive queries and qABoxes).
3.1
Classical Entailment and CQ-Entailment
Due to the close connection between conjunctive queries and qABoxes men-
tioned above, it is easy to see that the classical entailment relation |=T between
qABoxes, as introduced in the previous section, actually coincides with CQ-
entailment |=T
CQ. To keep the notation more uniform and to distinguish this
kind of entailment explicitly from IQ-entailment, we will usually talk about CQ-
entailment and write |=T
CQ.
Whenever we compare two qABoxes
E
X.A and
E
Y.B, we assume without
loss of generality that they are renamed apart, which means that X is disjoint
with ΣO(
E
Y.B) and Y is disjoint with ΣO(
E
X.A), and we further assume that
the two qABoxes speak about the same set of individual names ΣI := ΣI(
E
X.A)∪
ΣI(
E
Y.B). For the case of an empty TBox, it was shown in [7] that
E
X.A |=∅
CQ
E
Y.B iﬀthere is a homomorphism from
E
Y.B to
E
X.A. A homomorphism from

314
⊓-rule. If (C1 ⊓· · · ⊓Cn)(t) ∈A, then remove this assertion from A, and add the
assertions C1(t), · · · , Cn(t) to A.
E
-rule. If (
E
r.C)(t) ∈A, then remove this assertion from A, add the two assertions
r(t, x) and C(x) to A, and add x to X, where x is a fresh variable not occurring
in A or X.
⊑-rule. If t ∈ΣO(
E
X.A), C ⊑D ∈T , A |= C(t), and A ̸|= D(t), then add the
assertion D(t) to A.
The ⊓-rule has highest priority and the ⊑-rule has lowest priority.
Fig. 1: The CQ-saturation rules.
E
Y.B to
E
X.A is a mapping h: ΣO(
E
Y.B) →ΣO(
E
X.A) such that h(a) = a
for each a ∈ΣI, A(h(u)) ∈A for each A(u) ∈B, and r(h(u), h(v)) ∈A for each
r(u, v) ∈B. In order to obtain a similar characterization of entailment for the
case of a non-empty TBox T , we need to saturate the given qABox w.r.t. T .
Basically, this saturation performs what is called the chase in the database
community [26,20,10]. Given an EL TBox T and a qABox
E
X.A, it extends the
ABox by new assertions that are implied by the TBox. The rules that realize
this are described in Fig. 1. Their rôle is two-fold: whereas the ⊑-rule adds new
concept assertions that are implied by the ABox together with the TBox, the
other two rules break down the complex concept assertions added by this rule
into smaller parts.
In general, applying these rules need not terminate; e.g., if applied to the
qABox
E
∅.{A(a)} for the TBox {A ⊑
E
r.A}. There are various suﬃcient con-
ditions that guarantee termination of the chase [13]. Here, we use a condition
introduced in [1] in the context of uniﬁcation in EL.
Deﬁnition 1. The EL TBox T is cycle-restricted if there is no non-empty
sequence of role names r1, . . . , rk and EL concept description C such that
C ⊑T
E
r1. · · ·
E
rk.C.
As shown in [1], it can be decided in time polynomial whether a given EL TBox
is cycle-restricted or not. For cycle-restricted TBoxes, CQ-saturation always ter-
minates.
Theorem 2. Let T be a cycle-restricted EL TBox and
E
X.A a qABox. Then
exhaustive application of the CQ-saturation rules terminates in exponential time
in the size of
E
X.A and T , and yields a qABox satT
CQ(
E
X.A) such that the
following statements are equivalent for all qABoxes
E
Y.B:
–
E
X.A |=T
CQ
E
Y.B,
– satT
CQ(
E
X.A) |=∅
CQ
E
Y.B,
– there is a homomorphism from
E
Y.B to satT
CQ(
E
X.A).
We can show that there are examples where the CQ-saturation of a qABox w.r.t.
a cycle-restricted TBox is of exponential size, and thus its computation must take
exponential time. Nevertheless, the entailment relation |=T
CQ can still be decided
within NP by adapting results for conjunctive query answering in EL [30].
F. Baader, P. Koopmann, F. Kriegel, and A. Nuradiansyah

Optimal Repairs w.r.t. Static TBoxes
315
⊓-rule. If (C1 ⊓. . . ⊓Cn)(t) ∈A, then remove this assertion from A and add the
assertions C1(t), . . . , Cn(t) to A.
E
-rule. If (
E
r.C)(t) ∈A, then remove this assertion from A, add the two assertions
r(t, xC) and C(xC) to A, and add xC to X if it is not already there.
⊑-rule. If t ∈ΣO(
E
X.A), C ⊑D ∈T , A |= C(t), and A ̸|= D(t), then add the
assertion D(t) to A.
The ⊓-rule has higher precedence than the
E
-rule, and the latter has higher precedence
than the ⊑-rule.
Fig. 2: The IQ-saturation rules.
3.2
IQ-Entailment
Recall that the qABox
E
X.A IQ-entails the qABox
E
Y.B w.r.t. the EL TBox T if
every concept assertion C(a) entailed w.r.t. T by the latter is also entailed w.r.t.
T by the former. In the following we assume again that these two qABoxes
are renamed apart. For the case of an empty TBox, it was shown in [7] that
E
X.A |=∅
IQ
E
Y.B iﬀthere is a simulation from
E
Y.B to
E
X.A. A simulation from
E
Y.B to
E
X.A is a relation S ⊆ΣO(
E
Y.B) × ΣO(
E
X.A) such that (a, a) ∈S
for each a ∈ΣI and, for each (u, v) ∈S, A(u) ∈B implies A(v) ∈A and
r(u, u′) ∈B implies that there exists an object v′ ∈ΣI ∪X such that (u′, v′) ∈S
and r(v, v′) ∈A. Since checking the existence of a simulation can be done in
polynomial time [16], we conclude that IQ-entailment between qABoxes can be
decided in polynomial time for the case of an empty TBox.
To extend these results to the case of a non-empty TBox, we again need
to saturate the ABox w.r.t. the TBox. But now the saturation rules, given in
Fig. 2, are more parsimonious w.r.t. the introduction of new objects. To be more
precise, for each existential restriction
E
r.C ∈Sub(T ), we assume that xC is
a fresh variable not contained in the initial qABox
E
X.A. When applying the
E
-rule to an assertion of the form (
E
r.C)(t), we always use this variable for
the successor object. Due to this restriction, IQ-saturation always terminates,
i.e., it is not necessary to impose any restrictions on the TBox. Also note that
IQ-saturation basically generates a qABox representation of what is called the
canonical model in [25, Section 5.2].
Theorem 3. Let T be an EL TBox and
E
X.A a qABox. Then exhaustive ap-
plication of the IQ-saturation rules terminates in polynomial time in the size of
E
X.A and T , and yields a qABox satT
IQ(
E
X.A) such that the following state-
ments are equivalent for all qABoxes
E
Y.B:
–
E
X.A |=T
IQ
E
Y.B,
– satT
IQ(
E
X.A) |=∅
IQ
E
Y.B,
– there is a simulation from
E
Y.B to satT
IQ(
E
X.A).
Since satT
IQ(
E
X.A) can be computed in polynomial time and the existence of a
simulation can be decided in polynomial time, this shows that the entailment
relation |=T
IQ can be decided in polynomial time.

316
4
Canonical Repairs
We specify what is to be repaired by a ﬁnite set of EL concept assertions, which
we call a repair request. A repair is a qABox that does not have any of these
assertions as a consequence. This generalizes previous repair approaches [6] in
that more than one consequence speciﬁed as unwanted is removed in one step.
It also encompasses the notion of a privacy policy, as introduced in [7], which
speciﬁes forbidden concepts, with the meaning that one should not be able to
derive that any of the individuals occurring in the qABox is an instance of such
a concept. We assume that the TBox is static (i.e., may not be changed by the
repair) and consider both CQ- and IQ-entailment for comparing qABoxes.
Deﬁnition 4. Let T be an EL TBox and QL ∈{CQ, IQ}.
– An EL repair request is a ﬁnite set of EL concept assertions.
– Given a qABox
E
X.A and an EL repair request R, a QL-repair of
E
X.A for
R w.r.t. T is a qABox
E
Y.B such that
E
X.A |=T
QL
E
Y.B and
E
Y.B ̸|=T C(a)
for all C(a) ∈R.
– Such a repair
E
Y.B is optimal if there is no QL-repair
E
Z.C of
E
X.A for
R w.r.t. T such that
E
Z.C |=T
QL
E
Y.B and
E
Z.C ̸≡T
QL
E
Y.B.
Intuitively, a repair is a qABox that has no new consequences of the speciﬁed
type (instance relationships or answers to conjunctive queries), and no longer
has the consequences forbidden by the repair request. In an optimal repair, a
minimal amount of consequences of the speciﬁed type is lost. Since there are
diﬀerent options for what to change when repairing a qABox, there may exist
several non-equivalent optimal repairs.
In the following, let QL ∈{CQ, IQ} and let T be a ﬁxed TBox, which is
assumed to be cycle-restricted if QL = CQ. In addition, let R be a repair request
and
E
X.A be the qABox to be QL-repaired for R w.r.t. T . We assume that
R does not contain an assertion of the form C(a) such that ⊤⊑T C since
the presence of such an assertions would preclude the existence of a repair. If R
satisﬁes this restriction, then the empty qABox
E
∅.∅is always a repair. However,
as mentioned in the introduction, this does not imply that there is an optimal
repair. We will show that, for the case of IQ-entailment, optimal repairs always
exist. For CQ-entailment, this is the case if the TBox T is cycle-restricted. In
both cases, the set of optimal repairs covers all repairs in the sense that each
repair is entailed by some optimal repair.
As mentioned in the introduction, to deal with TBoxes, the approach for
computing so-called canonical repairs from [7] needs to be adapted in two ways.
First, one needs to QL-saturate the given qABox w.r.t. the TBox. Second, when
computing canonical repairs from satT
QL(
E
X.A), the construction needs to ensure
that the TBox does not reintroduce consequences that have been removed by
the repair. The main idea underlying the construction of canonical repairs is to
introduce variables as copies of the objects occurring in satT
QL(
E
X.A). Such a
variable is of the form yu,K, where the ﬁrst component of the subscript says that
this is a copy of the object u. The second component K is a set of atoms, with
F. Baader, P. Koopmann, F. Kriegel, and A. Nuradiansyah

Optimal Repairs w.r.t. Static TBoxes
317
the intuitive meaning that yu,K must not be an instance of any element of K. To
avoid introducing unnecessary copies, certain restrictions were imposed in [7] on
the sets K. We add a further restriction that takes care of the TBox.
To be more precise, let Sub(R, T ) be the set of subconcepts of concept de-
scriptions occurring in R or T , and let Atoms(R, T ) be the set of atoms occurring
in Sub(R, T ). The set K in a variable yu,K must be a repair type for u.
Deﬁnition 5. Let
E
Y.B := satT
QL(
E
X.A) and let u be an object name occurring
in B. A repair type for u is a subset K of Atoms(R, T ) that satisﬁes the following:
1. B |=∅C(u) for each atom C ∈K,
2. if C, D are distinct atoms in K, then C ̸⊑∅D,
3. K is premise-saturated w.r.t. T , i.e., for all C ∈Sub(R, T ) with B |=∅C(u)
and C ⊑T D for some D ∈K, there is E ∈K such that C ⊑∅E.
The ﬁrst two conditions coincide with the ones in [7]. Basically, 1. says that
we only need to remove instance relationships explicitly if they are really there.
Condition 2. corresponds to the fact that preventing D(yu,K) as a consequence
also prevents C(yu,K) if D subsumes C, and thus C ∈K would be redundant if
D ∈K. Condition 3. ensures that instance relationships that are removed due to
K cannot be re-introduced by the TBox. It is easy to see that the set of repair
types for u can be computed in exponential time.
Similarly to the approach in [7], canonical repairs are induced by seed func-
tions. Such a function determines, for each individual, which instance relation-
ships should be prevented in order to obtain a repair.
Deﬁnition 6. A repair seed function is a function s that maps each individual
name b ∈ΣI(
E
X.A) to a repair type s(b) for b that satisﬁes the following:
– if C(b) ∈R and satT
QL(
E
X.A) |= C(b), then s(b) contains an atom D such
that C ⊑∅D.
Using our general assumption that the repair request R does not contain a
concept assertion C(a) with ⊤⊑T C, we can show that there is always at least
one repair seed function. Each repair seed function induces a repair as follows.
Deﬁnition 7. Given a repair seed function s, we deﬁne the canonical QL-repair
repT
QL(
E
X.A, s) induced by s as the qABox
E
Y.B where
1. the set Y consists of the variables yu,K for all object names u occurring in
satT
QL(
E
X.A) and all repair types K for u, except for the case where u is an
individual name and K = s(u), and
2. the matrix B consists of the following assertions, where we use yb,s(b) as a
synonym for the individual name b:
– A(yu,K) ∈B for each concept assertion A(u) in satT
QL(
E
X.A) such
that A ̸∈K,
– r(yu,K, yv,L) ∈B for each role assertion r(u, v) in satT
QL(
E
X.A) such
that the following holds for each
E
r.C ∈K: if the matrix of satT
QL(
E
X.A)
entails C(v), then the set L contains an atom that subsumes C.

318
Our construction of canonical repairs based on seed functions is sound and
complete in the following sense.
Proposition 8. For each repair seed function s, the induced canonical repair
repT
QL(
E
X.A, s) is a QL-repair of
E
X.A for R w.r.t. T . Conversely, if
E
Y.B is
a QL-repair of
E
X.A for R w.r.t. T , then there is a repair seed function s such
that repT
QL(
E
X.A, s) |=T
QL
E
Y.B.
We deﬁne the set of all canonical QL-repairs of
E
X.A for R w.r.t. T as
RepairsT
QL(
E
X.A, R) := { repT
QL(
E
X.A, s) | s is a repair seed function }.
As an easy consequence of Proposition 8 we obtain that RepairsT
QL(
E
X.A, R)
contains all optimal repairs (up to equivalence). However, as in the case with-
out a TBox, it may also contain non-optimal repairs [7]. To compute the set
of optimal repairs, one thus needs to remove such non-optimal elements from
RepairsT
QL(
E
X.A, R). Since the entailment test required for this is NP-complete
for QL = CQ and polynomial for QL = IQ, we obtain the following theorem.
Theorem 9. There is a (deterministic) algorithm that computes the set of all
optimal QL-repairs of
E
X.A for R w.r.t. T and runs in exponential time. If
QL = CQ, then this algorithm needs access to an NP oracle, whereas no such
oracle is required for QL = IQ.
5
Optimized Repairs
The construction of the canonical repair induced by a seed function described in
the previous section usually introduces an exponential number of copies for the
objects occurring in the saturated qABox. The following example demonstrates
that this is not always necessary to obtain an optimal repair.
Example 10. Let T := ∅and consider the repair request {(
E
r.(A1⊓. . . ⊓An))(a)}
for the qABox
E
{x}.{r(a, x), A1(x), . . . , An(x)}. There is only one repair seed
function s, which assigns {
E
r.(A1 ⊓. . . ⊓An)} to a. Both for the CQ and the
IQ case, the canonical repair induced by s contains 2n copies of x, namely all
the variables yx,K for K ⊆{A1, . . . , An}. However, most of these copies are
redundant. In fact, we will see below that there are optimal repairs equivalent
to the canonical one that contain only linearly many variables in n, both for the
CQ and the IQ case.
The idea is now to construct, for a given seed function, a set of variables that
is a (hopefully small) subset of the set Y introduced in Deﬁnition 7, which is
nevertheless suﬃcient to obtain a repair equivalent to the canonical one. Note,
however, that in general an exponential blow-up cannot be avoided, as already
shown in [5] for the case of EL instance stores. Throughout this section, we
assume that QL, T , R, and
E
X.A satisfy the properties assumed in the previous
section. In addition, we assume that the repair request R is reduced, i.e., every
F. Baader, P. Koopmann, F. Kriegel, and A. Nuradiansyah

Optimal Repairs w.r.t. Static TBoxes
319
concept occurring in a concept assertion in R is reduced, and if R contains C(a)
and D(a) for distinct concept descriptions C, D, then C ̸⊑∅D, and we further
assume that each concept occurring in the TBox T is reduced. Before we can
describe our construction of the set of relevant variables, we must introduce some
notation and show an auxiliary result.
Given two sets of concept descriptions K and L, we say that L covers K
(written K ≤L) if each concept in K is subsumed by some concept in L.
Now, let s be a repair seed function and set
E
Y.B := repT
QL(
E
X.A, s).
Recall that, according to Deﬁnition 7, a role assertion r(yt,K, yu,L) belongs
to the matrix B iﬀthe saturation satT
QL(
E
X.A) contains the role assertion
r(t, u) and the repair type L covers the set Succ(K, r, u) := { C |
E
r.C ∈
K and the matrix of satT
QL(
E
X.A) entails C(u) }.
If L does not satisfy this requirement, there might be another repair type
L′ such that the canonical repair contains the assertion r(yt,K, yu,L′), and thus
our optimized repair needs to contain an appropriate variable to which yu,L′ can
be mapped by a homomorphism or simulation. We generate such variables by
looking for repair types M that cover both L and Succ(K, r, u). The set of all
such repair types can eﬀectively be computed, though it might be empty. For
our purposes, it is suﬃcient to use only the ones that are minimal w.r.t. the
cover relation ≤.
Lemma 11. The set of all ≤-minimal repair types for u that cover L ∪
Succ(K, r, u) can be computed in exponential time.
In general, this computation may produce exponentially many repair types, but
this is not always the case. For instance, consider a = ya,s(a) and yx,∅in Exam-
ple 10. We have Succ(s(a), r, x) = {A1⊓. . .⊓An} and thus the assertion r(a, yx,∅)
is not in B since ∅clearly does not cover Succ(s(a), r, x). The ≤-minimal repair
types covering Succ(s(a), r, x) are exactly the sets {Ai} for i = 1, . . . , n.
In the following, we construct a sequence Y0, Y1, . . . , Ym of subsets Yi of Y
such that
E
Y.B is QL-equivalent to its sub-qABox
E
Ym.Bm where Bm contains
only those assertions in B involving object names in ΣI ∪Ym. Recall that we use
ya,s(a) as synonyms for the individuals a ∈ΣI.
We start with the set Y0, which is empty if QL = IQ, and equal to the set
{ yt,∅| t is an object name occurring in satT
CQ(
E
X.A) } if QL = CQ.
The subsequent sets are obtained by exhaustively applying one of the follow-
ing rules, depending on whether QL = CQ or QL = IQ.
CQ-construction rule. If yt,K and yu,L are elements of ΣI ∪Yi, the satu-
ration satT
CQ(
E
X.A) contains the role assertion r(t, u), the repair type L
does not cover Succ(K, r, u), and M is a ≤-minimal repair type for u that
covers L ∪Succ(K, r, u), but yu,M is not contained in ΣI ∪Yi, then set
Yi+1 := Yi ∪{yu,M}.
IQ-construction rule. If yt,K is an element of ΣI ∪Yi, the saturation
satT
IQ(
E
X.A) contains the role assertion r(t, u), and M is a ≤-minimal
repair type for u that covers Succ(K, r, u), but yu,M is not contained in
ΣI ∪Yi, then set Yi+1 := Yi ∪{yu,M}.

320
The sets Yi are all subsets of the set Y of variables in the canonical repair. Since
each rule application adds a variable, the exhaustive application of rules must
terminate after ﬁnitely many steps with a set of variables Ym ⊆Y .
Let us illustrate this construction using Example 10, ﬁrst for the IQ case.
We have a = ya,s(a) ∈ΣI and the assertion r(a, x) belongs to the saturation,
which is equal to the original qABox. As mentioned above, the ≤-minimal repair
types covering Succ(s(a), r, x) are exactly the sets {Ai} for i = 1, . . . , n. Thus,
repeated applications of the IQ-construction rule add the variables yx,{Ai}, and
the construction ends with Y IQ
m = { yx,{Ai} | i = 1, . . . , n }. In the CQ case, the
initial set of variables is Y CQ
0
= {ya,∅, yx,∅}. In this example, the CQ-construction
rule then generates the same variables as the IQ rule, though this need not be
the case in general. We end up with the ﬁnal set Y IQ
m ∪Y CQ
0
.
Deﬁnition 12. Let s be a repair seed function and Ym ⊆Y be the set of
variables obtained by an exhaustive application of the QL-construction rule.
The optimized QL-repair of
E
X.A for R w.r.t. T induced by s, denoted by
orepT
QL(
E
X.A, s), is the qABox
E
Ym.Bm where the matrix Bm contains all as-
sertions in B involving only object names in ΣI ∪Ym.
Note that, to compute Bm, we need not compute the larger matrix B ﬁrst.
Instead, we just apply the deﬁnition of the matrix in Deﬁnition 7 to the object
names in ΣI ∪Ym.
In our example, the optimized IQ-repair is the qABox
E
Y IQ
m .Bm with
Bm = { r(a, yx,{Ai}) | 1 ≤i ≤n } ∪{ Aj(yx,{Ai}) | j ̸= i and 1 ≤i, j ≤n }.
In the optimized CQ-repair, the quantiﬁer preﬁx additionally contains the
variables ya,∅and yx,∅, and the matrix additionally contains the assertions
r(ya,∅, yx,∅) and Ai(yx,∅) for i = 1, . . . , n. Note that, without these assertions,
the positive answer to the Boolean conjunctive query
E
y, z.(r(y, z) ∧A1(z) ∧
. . . ∧An(z)) would be lost.
Coming back to the general case, we ﬁrst observe that the canonical QL-
repair induced by s QL-entails the optimized QL-repair induced by s due to the
inclusion relationship between these two qABoxes. The entailment in the other
direction also holds, but this is harder to show, in particular for QL = CQ.
Proposition 13. For each repair seed function s, the optimized QL-repair in-
duced by s QL-entails the canonical QL-repair induced by s.
Proof sketch. For QL = IQ, the proposition can be proved by showing that the
following relation S is a simulation from
E
Y.B to
E
Ym.Bm:
S := { (yt,K, yt,K′) | yt,K ∈ΣO(
E
Y.B), yt,K′ ∈ΣO(
E
Ym.Bm), and K′ ≤K }.
For QL = CQ, we introduce a sequence of mappings h0, h1, . . . , hn : ΣO(
E
Y.B) →
ΣO(
E
Ym.Bm), starting with h0(yt,K) = yt,s(t) if t ∈ΣI and s(t) ≤K and
h0(yt,K) = yt,∅otherwise. The initial mapping h0 need not be a homomorphism
F. Baader, P. Koopmann, F. Kriegel, and A. Nuradiansyah

Optimal Repairs w.r.t. Static TBoxes
321
since role assertions may not be preserved. In the step-wise construction of the
mappings hi such defects are corrected, one by one. We can show that this con-
struction always terminates after ﬁnitely many steps, yielding a homomorphism
hn from
E
Y.B to
E
Ym.Bm.
⊓⊔
Summing up, we have thus shown the following theorem, which implies that
the optimized repairs also satisfy the properties stated in Proposition 8.
Theorem 14. For each repair seed function s, the canonical QL-repair induced
by s and the optimized QL-repair induced by s are QL-equivalent.
6
Evaluation
To ﬁnd out whether the repair approaches introduced in this paper are in prin-
ciple viable for non-trivial ontologies, we made experiments for both IQ and CQ-
repairs with a ﬁrst, rather unoptimized implementation. In addition to checking
how often the implementation was able to compute a repair within a certain
timeout, we also compared the sizes of optimized repairs with those of canonical
repairs. We considered two diﬀerent repair scenarios: repairing a single unwanted
consequence for a single individual (S1), and repairing a single unwanted conse-
quence for 10% of the individuals occurring in the ABox (S2). We report here
the main results—more details and discussions can be found in [4].
As corpus for our evaluation, we chose the ontologies used in the 2015 OWL
Reasoner Competition for the track OWL EL Realisation [28], since they contain
a substantial amount of ABox assertions. These 109 ontologies were converted
into pure EL by applying standard transformations and afterwards ﬁltering out
unsupported axioms. From these ontologies, we kept those that had at most
100,000 axioms in total. The resulting corpus contained 80 ontologies.
We implemented our methods in Java, using the OWL-API1 for parsing
OWL ontologies, and ELK [22] for precomputing any subsumption relationships
entailed with and without the TBox potentially relevant for our repair approach.
The code is available online.2 All experiments were performed on an Intel(R)
Core(TM) i5-4590 CPU with 4 cores and 32 GB RAM, of which we assigned 16
GB as maximal heap space to the Java VM.
Since it is a precondition of our repair approach, we ﬁrst saturated the on-
tologies using the IQ-saturation rules of Figure 2, and the CQ-saturation rules
of Figure 1. The CQ-saturation rules were implemented using the rule engine
VLog [11] through the Java facade Rulewerk.3 As CQ-saturation only termi-
nates for cycle-restricted TBoxes, we only considered those ontologies for the
CQ-saturation whose IQ-saturation did not introduce cycles between introduced
variables. We used a timeout of 60 minutes for every saturation. This way, we
successfully computed IQ-saturations of every ontology, and 62 CQ-saturations.
1 http://owlapi.sourceforge.net
2 https://github.com/de-tu-dresden-inf-lat/abox-repairs-wrt-static-tbox
3 https://github.com/knowsys/rulewerk

322
The size of the saturated ABox was usually not much larger than that of the
original one, and always less than two orders of magnitude larger. Interestingly,
the successful CQ-saturations were rarely larger than the IQ-saturations, and
often even of the same size, because no variables were added.
Scenario S1 was about repairing a single faulty entailment A |=T C(a). Since
we did not have information about whether any entailments from the considered
ontologies are faulty, we generated such assertions randomly. For this, we looked
at entailments of the form A |=T C(a), where C ∈Sub(T ). To make the repair
requests more interesting, we furthermore required that C is not of the form
A or
E
r.⊤, where A is a concept name. This requirement already ruled out 54
of the IQ-saturated ontologies, and 44 of the CQ-saturated ontologies, as they
did not have any complex entailments of the required form. For Scenario S2, we
randomly selected some concept C ∈Sub(T ) which had at least one instance
(surprisingly, although C was not required to be complex, this ruled out 12 on-
tologies, including 4 of the CQ-saturated ones), together with a random selection
of 10% of the individuals in A, and built the repair request consisting of all as-
sertions C(a) where a ranges over the selected individuals. For both scenarios,
we selected a random seed function for the obtained repair request.
For each ontology, scenario, and QL ∈{IQ, CQ}, we attempted to compute
optimised QL-repairs for 50 diﬀerent repair requests. We also tried to compute
the set of objects that would be included in the canonical repairs, to get an idea
of the impact of our optimisation. For each such repair computation, we used a
timeout of 10 minutes. Since all repair requests used only concept descriptions
that were already in the input ontology, the number of objects in the canoni-
cal repair was independent of the repair request. We thus performed the latter
computation only once for each ontology. The success rates were as follows:
– The objects included in the canonical IQ- and CQ-repair could be computed
within the timeout and without memory exceptions for respectively only
52.9 % and 62.1 % of the ontologies.
– For S1, we could compute the optimized IQ-repair in 99.9 %, and the opti-
mised CQ-repair in 100.0 % of all attempts.
– For S2, 98.9 % of IQ-repairs and 99.9 % of CQ-repairs were successful.
This shows that the optimizations introduced in Section 5 have a very positive
impact on the viability of our repair approach.
Fig. 3 gives more information on the number of objects and assertions in the
computed repairs. On the left, we consider canonical and optimised IQ-repairs
for scenario S2: speciﬁcally, we look at the diﬀerence in numbers of individuals
occurring in the repair compared to the input ABox. In the middle and on the
right, we visualise the diﬀerence between the number of assertions in the opti-
mized IQ- and CQ-repairs, compared to the input ABoxes, for the scenarios S1
and S2, respectively. By construction, CQ-repairs cannot contain less assertions
than the input ontologies. Sometimes the CQ-repairs were smaller than the cor-
responding IQ-repairs, which is due to the diﬀerent saturation methods: variables
introduced by the IQ-saturation could be connected to more individuals than for
the CQ-saturation.
F. Baader, P. Koopmann, F. Kriegel, and A. Nuradiansyah

Optimal Repairs w.r.t. Static TBoxes
323
Can. vs Opt. S2, IQ
Optimised S1
Optimised S2
102
103
104
105
105
103
101
0
−101
−103
.
n.
cann
a
can
a
c n
c n
can
an
an
ca
ca
ca
ca
ca
can
c n
an
a
c n
ca .
n
ca
ca
ca
can
ca
ca
caa
ca
ca
ca
ca
ca
ca
c n.
a .
n
ca
ca
ca
ca
ca
ca
ca
ca
ca
ca
ca
ca
ca
ca
c n.
n.
n.
n.
n
a
c n
opt.
p
102
103
104
105
IQ
IQ
CQQ
102
103
104
105
IQQ
IQ
IQ
IQ
IQQ
IQ
IQ
IQQ
IQ
IQ
IQ
IQ
IQ
IQ
IQ
IQ
IQ
IQ
IQ
IQQ
IQQ
IQ
IQ
IQ
IQ
IQ
IQ
IQ
IQ
IQQ
IQ
IQ
IQ
IQ
IQ
IQ
IQ
IQ
IQ
I
CQQ
CQ
Fig. 3: Evaluation results. On the left, we show the diﬀerence of the number of ob-
ject names in the canonical IQ-repairs (purple triangle) with the same diﬀerence,
but restricted to objects occurring in assertions, for the optimised IQ-repairs (red
circle) for S2. The other two graphs consider optimised IQ- and CQ-repairs for
S1 and S2. In each graph, the x-axis shows the number of assertions in the input
ontology, and the y-axis the observed diﬀerence.
7
Conclusion
This paper presents approaches for repairing DL-based ontologies, in the sense
that they allow to get rid of unwanted consequences. In contrast to most of the
other work on ontology repair, our goal is to compute optimal repairs, i.e., ones
that lose the least amount of other consequences. As relevant consequences to
be preserved, we consider both answers to conjunctive queries (CQ) and answers
to EL instance queries (IQ). The presented results improve on our previous work
in this direction in two respects. First, we allow for the presence of a TBox,
which is assumed to be static (i.e., cannot be changed by the repair), whereas
before we assumed that the TBox is empty. Second, we develop a more eﬃcient
construction of optimal repairs, which is exponential only in the worst case. Our
experimental results show that this optimization makes our repair approach
viable also for fairly large ontologies, at least for the IQ case.
One question for future research is how to lift the restriction to cycle-
restricted TBoxes in the CQ case. Since optimal repairs need not longer ex-
ist then, one can ask whether the existence question is decidable, and how to
compute optimal repairs if they exist. We have already noticed in our ﬁrst at-
tempts to tackle this problem that optimal repairs may then become larger than
single-exponential.
In this and in our previous work, we have assumed that unwanted conse-
quences are speciﬁed as EL instance relationships. Another interesting open
question is whether our results can be generalized to a setting where unwanted
consequences are speciﬁed as answers to conjunctive queries, as e.g. in [14].4
4 Note that no TBox is considered in [14], and the notion of optimality used there is
diﬀerent from ours (see the introduction of [7] for a discussion of the diﬀerences).

324
References
1. Baader, F., Borgwardt, S., Morawska, B.: Extending uniﬁcation in EL towards
general TBoxes. In: Proc. of the 13th Int. Conf. on Principles of Knowledge Rep-
resentation and Reasoning (KR 2012). pp. 568–572. AAAI Press/The MIT Press
(2012)
2. Baader, F., Brandt, S., Lutz, C.: Pushing the EL envelope. In: Kaelbling, L.P.,
Saﬃotti, A. (eds.) IJCAI-05, Proceedings of the Nineteenth International Joint
Conference on Artiﬁcial Intelligence, Edinburgh, Scotland, UK, July 30 - August
5, 2005. pp. 364–369. Professional Book Center (2005)
3. Baader, F., Horrocks, I., Lutz, C., Sattler, U.: An Introduction to Description
Logic. Cambridge University Press (2017)
4. Baader, F., Koopmann, P., Kriegel, F., Nuradiansyah, A.: Computing optimal
repairs of quantiﬁed ABoxes w.r.t. static EL TBoxes (extended version). LTCS-
Report 21-01, Chair of Automata Theory, Institute of Theoretical Computer Sci-
ence, Technische Universität Dresden, Dresden, Germany (2021), https://lat.inf.
tu-dresden.de/research/reports/2021/BaKoKrNu-LTCS-21-01.pdf
5. Baader, F., Kriegel, F., Nuradiansyah, A.: Privacy-preserving ontology publishing
for EL instance stores. In: Calimeri, F., Leone, N., Manna, M. (eds.) Logics in
Artiﬁcial Intelligence - 16th European Conference, JELIA 2019, Rende, Italy, May
7-11, 2019, Proceedings. Lecture Notes in Computer Science, vol. 11468, pp. 323–
338. Springer (2019)
6. Baader, F., Kriegel, F., Nuradiansyah, A., Peñaloza, R.: Making repairs in descrip-
tion logics more gentle. In: Thielscher, M., Toni, F., Wolter, F. (eds.) Principles of
Knowledge Representation and Reasoning: Proceedings of the Sixteenth Interna-
tional Conference, KR 2018, Tempe, Arizona, 30 October - 2 November 2018. pp.
319–328. AAAI Press (2018)
7. Baader, F., Kriegel, F., Nuradiansyah, A., Peñaloza, R.: Computing compliant
anonymisations of quantiﬁed aboxes w.r.t. EL policies. In: Pan, J.Z., Tamma,
V.A.M., d’Amato, C., Janowicz, K., Fu, B., Polleres, A., Seneviratne, O., Kagal,
L. (eds.) The Semantic Web - ISWC 2020 - 19th International Semantic Web Con-
ference, Athens, Greece, November 2-6, 2020, Proceedings, Part I. Lecture Notes
in Computer Science, vol. 12506, pp. 3–20. Springer (2020)
8. Baader, F., Suntisrivaraporn, B.: Debugging SNOMED CT using axiom pinpoint-
ing in the description logic EL+. In: Proceedings of the International Conference
on Representing and Sharing Knowledge Using SNOMED (KR-MED’08). Phoenix,
Arizona (2008)
9. Boyle, T.C.: Talk to Me. Bloomsbury Publishing (2021), To appear.
10. Calì, A., Lembo, D., Rosati, R.: On the decidability and complexity of query an-
swering over inconsistent and incomplete databases. In: Neven, F., Beeri, C., Milo,
T. (eds.) Proceedings of the Twenty-Second ACM SIGACT-SIGMOD-SIGART
Symposium on Principles of Database Systems, June 9-12, 2003, San Diego, CA,
USA. pp. 260–271. ACM (2003)
11. Carral, D., Dragoste, I., González, L., Jacobs, C.J.H., Krötzsch, M., Urbani, J.:
Vlog: A rule engine for knowledge graphs. In: Ghidini, C., Hartig, O., Maleshkova,
M., Svátek, V., Cruz, I.F., Hogan, A., Song, J., Lefrançois, M., Gandon, F. (eds.)
The Semantic Web - ISWC 2019 - 18th International Semantic Web Conference.
Lecture Notes in Computer Science, vol. 11779, pp. 19–35. Springer (2019)
12. Glimm, B., Horrocks, I., Motik, B., Stoilos, G., Wang, Z.: Hermit: An OWL 2
reasoner. J. Autom. Reason. 53(3), 245–269 (2014)
F. Baader, P. Koopmann, F. Kriegel, and A. Nuradiansyah

Optimal Repairs w.r.t. Static TBoxes
325
13. Grau, B.C., Horrocks, I., Krötzsch, M., Kupke, C., Magka, D., Motik, B., Wang,
Z.: Acyclicity notions for existential rules and their application to query answering
in ontologies. J. Artif. Intell. Res. 47, 741–808 (2013)
14. Grau, B.C., Kostylev, E.V.: Logical foundations of linked data anonymisation. J.
Artif. Intell. Res. 64, 253–314 (2019)
15. Haarslev, V., Hidde, K., Möller, R., Wessel, M.: The RacerPro knowledge repre-
sentation and reasoning system. Semantic Web 3(3), 267–277 (2012)
16. Henzinger, M.R., Henzinger, T.A., Kopke, P.W.: Computing simulations on ﬁnite
and inﬁnite graphs. In: 36th Annual Symposium on Foundations of Computer Sci-
ence, Milwaukee, Wisconsin, USA, 23-25 October 1995. pp. 453–462. IEEE Com-
puter Society (1995)
17. Hoehndorf, R., Schoﬁeld, P.N., Gkoutos, G.V.: The role of ontologies in biological
and biomedical research: A functional perspective. Brief. Bioinform. 16(6), 1069–
1080 (2015)
18. Horridge, M., Parsia, B., Sattler, U.: Laconic and precise justiﬁcations in OWL.
In: Sheth, A.P., Staab, S., Dean, M., Paolucci, M., Maynard, D., Finin, T.W.,
Thirunarayan, K. (eds.) The Semantic Web - ISWC 2008, 7th International Se-
mantic Web Conference, ISWC 2008, Karlsruhe, Germany, October 26-30, 2008.
Proceedings. Lecture Notes in Computer Science, vol. 5318, pp. 323–338. Springer
(2008)
19. Horrocks, I., Li, L., Turi, D., Bechhofer, S.: The instance store: DL reasoning
with large numbers of individuals. In: Haarslev, V., Möller, R. (eds.) Proceedings
of the 2004 International Workshop on Description Logics (DL2004), Whistler,
British Columbia, Canada, June 6-8, 2004. CEUR Workshop Proceedings, vol. 104.
CEUR-WS.org (2004)
20. Johnson, D.S., Klug, A.C.: Testing containment of conjunctive queries under func-
tional and inclusion dependencies. In: Ullman, J.D., Aho, A.V. (eds.) Proceedings
of the ACM Symposium on Principles of Database Systems, March 29-31, 1982,
Los Angeles, California, USA. pp. 164–169. ACM (1982)
21. Kalyanpur, A., Parsia, B., Horridge, M., Sirin, E.: Finding all justiﬁcations of
OWL DL entailments. In: Proc. of ISWC’07. Lecture Notes in Computer Science,
vol. 4825, pp. 267–280. Springer-Verlag (2007)
22. Kazakov, Y., Krötzsch, M., Simancik, F.: The incredible ELK - from polynomial
procedures to eﬃcient reasoning with EL ontologies. Journal of Automed Reasoning
53(1), 1–61 (2014)
23. Küsters, R.: Non-standard Inferences in Description Logics, Lecture Notes in Ar-
tiﬁcial Intelligence, vol. 2100. Springer-Verlag (2001)
24. Lam, J.S.C., Sleeman, D.H., Pan, J.Z., Vasconcelos, W.W.: A ﬁne-grained approach
to resolving unsatisﬁable ontologies. J. Data Semant. 10, 62–95 (2008)
25. Lutz, C., Wolter, F.: Deciding inseparability and conservative extensions in the
description logic EL. J. Symb. Comput. 45(2), 194–228 (2010)
26. Maier, D., Mendelzon, A.O., Sagiv, Y.: Testing implications of data dependencies.
ACM Trans. Database Syst. 4(4), 455–469 (1979)
27. Meyer, T., Lee, K., Booth, R., Pan, J.Z.: Finding maximally satisﬁable terminolo-
gies for the description logic ALC. In: Proc. of the 21st Nat. Conf. on Artiﬁcial
Intelligence (AAAI 2006). AAAI Press/The MIT Press (2006)
28. Parsia, B., Matentzoglu, N., Gonçalves, R.S., Glimm, B., Steigmiller, A.: The OWL
Reasoner Evaluation (ORE) 2015 competition report. Journal of Automed Reason-
ing 59(4), 455–482 (2017)

326
29. Parsia, B., Sirin, E., Kalyanpur, A.: Debugging OWL ontologies. In: Ellis, A.,
Hagino, T. (eds.) Proc. of the 14th International Conference on World Wide Web
(WWW’05). pp. 633–640. ACM (2005)
30. Rosati, R.: On conjunctive query answering in EL. In: Calvanese, D., Franconi,
E., Haarslev, V., Lembo, D., Motik, B., Turhan, A., Tessaris, S. (eds.) Proceed-
ings of the 2007 International Workshop on Description Logics (DL2007), Brixen-
Bressanone, near Bozen-Bolzano, Italy, 8-10 June, 2007. CEUR Workshop Pro-
ceedings, vol. 250. CEUR-WS.org (2007)
31. Schlobach, S., Cornet, R.: Non-standard reasoning services for the debugging of
description logic terminologies. In: Gottlob, G., Walsh, T. (eds.) Proc. of the 18th
Int. Joint Conf. on Artiﬁcial Intelligence (IJCAI 2003). pp. 355–362. Morgan Kauf-
mann, Los Altos, Acapulco, Mexico (2003)
32. Schlobach, S., Huang, Z., Cornet, R., Harmelen, F.: Debugging incoherent termi-
nologies. J. Automated Reasoning 39(3), 317–349 (2007)
33. Steigmiller, A., Liebig, T., Glimm, B.: Konclude: System description. J. Web Se-
mant. 27-28, 78–85 (2014)
34. Troquard, N., Confalonieri, R., Galliani, P., Peñaloza, R., Porello, D., Kutz, O.:
Repairing ontologies via axiom weakening. In: McIlraith, S.A., Weinberger, K.Q.
(eds.) Proceedings of the Thirty-Second AAAI Conference on Artiﬁcial Intelligence,
(AAAI-18), the 30th innovative Applications of Artiﬁcial Intelligence (IAAI-18),
and the 8th AAAI Symposium on Educational Advances in Artiﬁcial Intelligence
(EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018. pp. 1981–1988.
AAAI Press (2018)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.
F. Baader, P. Koopmann, F. Kriegel, and A. Nuradiansyah

Generalized Completeness for SOS Resolution
and its Application to a New Notion of
Relevance
Fajar Haifani
1,2, Sophie Tourret
1,3, and Christoph Weidenbach
1
1 Max Planck Institute for Informatics, Saarland Informatics Campus, Saarbr¨ucken
Germany
2 Graduate School of Computer Science, Saarbr¨ucken, Germany
3 Universit´e de Lorraine, CNRS, Inria, LORIA, Nancy, France
Abstract. We prove the SOS strategy for ﬁrst-order resolution to be
refutationally complete on a clause set N and set-of-support S if and only
if there exists a clause in S that occurs in a resolution refutation from N ∪
S. This strictly generalizes and sharpens the original completeness result
requiring N to be satisﬁable. The generalized SOS completeness result
supports automated reasoning on a new notion of relevance aiming at
capturing the support of a clause in the refutation of a clause set. A clause
C is relevant for refuting a clause set N if C occurs in every refutation of
N. The clause C is semi-relevant, if it occurs in some refutation, i.e., if
there exists an SOS refutation with set-of-support S = {C} from N \{C}.
A clause that does not occur in any refutation from N is irrelevant, i.e., it is
not semi-relevant. Our new notion of relevance separates clauses in a proof
that are ultimately needed from clauses that may be replaced by diﬀerent
clauses. In this way it provides insights towards proof explanation in
refutations beyond existing notions such as that of an unsatisﬁable core.
1
Introduction
Shortly after the invention of ﬁrst-order resolution [14] its ﬁrst complete reﬁne-
ment was established: set-of-support (SOS) resolution [18]. The idea of the SOS
strategy is to split a current clause set into two sets, namely N and S and re-
strict resolution inferences to have one parent from the set-of-support S. Wos
et al. [18] proved the SOS strategy complete if N is satisﬁable. The motivation
by Wos et. al. for the SOS strategy was getting rid of “irrelevant” inferences.
If N deﬁnes a theory and S contains the negation of a conjecture (goal) to be
refuted, the strategy puts emphasis on resolution inferences with the conjecture.
This can be beneﬁcial, because resolution is deductively complete (modulo sub-
sumption) [11,13], i.e., resolution inferences solely performed on clauses from N
will enumerate all semantic consequences, not necessarily only consequences that
turn out to be useful in refuting N ∪S. Even in more restrictive contexts, the
SOS strategy can be shown complete, e.g., if N is saturated by superposition
and does not contain the empty clause, then the SOS strategy is also complete
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5 19
327–343, 2021.

in the context of the strong superposition inference restrictions on N and a
set-of-support S [2].
In this paper, we generalize and sharpen the original completeness result for
the SOS strategy: The resolution calculus with the SOS strategy is complete if and
only if there is at least one clause in S that is contained in a resolution refutation
from N ∪S, Theorem 11. The proof is performed via proof transformation. Any
(non SOS) refutation from N ∪S can be transformed into an SOS refutation
with SOS S, if the original refutation contains at least one clause from S.
The generalized SOS completeness result supports our new notion of relevance
that is meant to be a ﬁrst stop towards explaining the gist of a refutation. A
clause C ∈N is relevant if it is needed for any refutation of the clause set N.
The clause C is semi-relevant if there is a refutation from N using C and C is
irrelevant otherwise, Deﬁnition 12. Applying our generalized SOS completeness
result, a clause C ∈N is semi-relevant if and only if there is an SOS refutation
from N \ {C} with SOS {C}.
The interest in semi-relevant clauses comes from real-world applications. In
an industrial scenario where diﬀerent products are built out of a building set,
the overall product portfolio is often deﬁned by a set of clauses (rules). Roughly,
every clause describes the integration of some part out of the building set in a
product. Diﬀerent proofs for the existence of some product correspond to diﬀerent
builds of the product. For example, answering a question like “Can we build car
x with part y?” from the automotive world boils down to the semi-relevance
of the clauses deﬁning part y in a refutation showing the existance of a car x.
All German car manufacturers maintain such clause sets deﬁning their product
portfolio [6,17].
Our new notion of relevance is related to other notions capturing aspects of
a refutation. A minimal unsatisﬁable core of an unsatisﬁable clause set contains
only semi-relevant clauses. The intersection of all minimal unsatisﬁable cores is
the set of relevant clauses. The notion of a minimal unsatisﬁable core does not
provide a test for semi-relevance of a speciﬁc clause. There are various notions
from the description logic community related to unsatisﬁable cores of a translation
to ﬁrst-order and/or to our notion of relevance [1,4,8,16]. An in-depth discussion
of these relationships can be found in our description logic workshop paper [7].
The notion of relevant clauses is also related to what has been studied in the
ﬁeld of propositional satisﬁability under the name of lean kernels [9,10]: Given
an unsatisﬁable set N of propositional clauses, the lean kernel consists exactly
of those clauses that are involved in at least one refutation proof of N in the
resolution calculus, and thus, in our terminology, the set of semi-relevant clauses. A
diﬀerent notion of relevance was previously deﬁned in the context of propositional
abduction [5]. The authors provide algorithms and complexity results for various
abduction settings in the propositional logic context. In addition to the fact
that our notion of relevance is deﬁned with respect to ﬁrst-order clauses, in their
context of propositional abduction, if a propositional variable is relevant, it must
be satisﬁability preserving when added to the theory (clause set). In our case, if
328
F. Haifani et al.

a clause C ∈N is (semi-)relevant, then N is unsatisﬁable and N \ {C} may be
unsatisﬁable as well.
The paper is organized as follows. After ﬁxing some notations and notions at
the beginning of Section 2 we introduce our proof transformation technique. First
on an example, Figure 1, then in general. The following Section 3 proves important
properties of the transformation, yielding our generalized completeness result for
SOS, Theorem 11. We then link the SOS completeness result to our notion of
semi-relevance in Section 4. The paper ends with a summary, a discussion of the
contributions, and directions for future work, Section 5.
2
Resolution Proof Transformation
After ﬁxing some common notions and notation, this section introduces our proof
transformation technique. First on an example and afterwards on resolution
refutations in general.
We assume a ﬁrst-order language without equality where N denotes a clause
set; C, D denote clauses; L, K denote literals; A, B denote atoms; P, Q, R, T
denote predicates; t, s terms; f, g, h functions; a, b, c constants; and x, y, z vari-
ables, all possibly indexed. Atoms, literals, clauses and clause sets are consid-
ered as usual. Clauses are disjunctions of literals. The complement of a lit-
eral is denoted by the function comp. Semantic entailment |= considers vari-
ables in clauses to be universally quantiﬁed. Substitutions σ, τ are total map-
pings from variables to terms, where dom(σ) := {x | xσ ̸= x} is ﬁnite and
codom(σ) := {t | xσ = t, x ∈dom(σ)}. A renaming σ is a bijective substitution.
The application of substitutions is extended to literals, clauses, and sets/sequences
of such objects in the usual way. The function mgu denotes the most general
uniﬁer of two terms, atoms, literals if it exists. We assume that any mgu of two
terms or literals does not introduce any fresh variables and is idempotent.
The resolution calculus consists of two inference rules: Resolution and Fac-
toring [14, 15]. The rules operate on a state (N, S) where the initial state for
a classical resolution refutation from a clause set N is (∅, N) and for an SOS
refutation with clause set N and initial SOS S the initial state is (N, S). We
describe the rules in the form of abstract rewrite rules operating on states (N, S).
As usual we assume for the resolution rule that the involved clauses are variable
disjoint. This can always be achieved by applying renamings to fresh variables.
Resolution (N, S ⊎{C ∨K}) ⇒RES (N, S ∪{C ∨K, (D ∨C)σ})
provided (D ∨L) ∈(N ∪S) and σ = mgu(L, comp(K))
Factoring
(N, S ⊎{C ∨L ∨K}) ⇒RES (N, S ∪{C ∨L ∨K} ∪{(C ∨L)σ})
provided σ = mgu(L, K)
The clause (D ∨C)σ is called the result of a Resolution inference between
its parents. The clause (C ∨L)σ is called the result of a Factoring inference
of its parent. A sequence of rule applications (N, S) ⇒∗
RES (N, S′) is called a
Generalized Completeness for SOS Resolution and its Application
329

resolution derivation. It is called an SOS resolution derivation if N ̸= ∅. In case
⊥∈S′ it is a called a (SOS) resolution refutation.
Theorem 1 (Soundness and Refutational Completeness of (SOS) Res-
olution [14, 18]). Resolution is sound and refutationally complete [14]. If for
some clause set N and initial SOS S, N is satisﬁable and N ∪S is unsatisﬁable,
then there is a derivation of ⊥from (N, S) [18].
Where a resolution derivation (N, S) ⇒∗
RES (N, S′) shows how new clauses
can be derived from (N, S), a deduction presents the minimal derivation of a
single clause, e.g., the empty clause ⊥in case of a refutation. For deductions we
require every clause to be used exactly once, so deductions always have a tree
form. This is a purely technical restriction, see Corollary 5, that facilitates our
deduction transformation technique that then needs not to take care of variable
renamings except for input clauses.
Deﬁnition 2 (Deduction). A deduction πN = [C1, . . . , Cn] of a clause Cn
from some clause set N is a ﬁnite sequence of clauses such that for each Ci the
following holds:
1.1 Ci is a renamed, variable-fresh version of a clause in N, or
1.2 there is a clause Cj ∈πN, j < i s.t. Ci is the result of a Factoring inference
from Cj, or
1.3 there are clauses Cj, Ck ∈πN, j < k < i s.t. Ci is the result of a Resolution
inference from Cj and Ck,
and for each Ci ∈πN, i < n:
2.1 there exists exactly one factor Cj of Ci with j > i, or
2.2 there exists exactly one Cj and Ck such that Ck is a resolvent of Ci and Cj
and i, j < k.
We omit the subscript N in πN if the context is clear.
A deduction π′ of some clause C ∈π, where π, π′ are deductions from
N is a subdeduction of π if π′ ⊆π, where for the latter subset relation we
identify sequences with multisets. A deduction πN = [C1, . . . , Cn−1, ⊥] is called
a refutation.
Note that variable renamings are only applied to clauses from N such that
all clauses from N that are introduced in the deduction are variable disjoint.
Deﬁnition 3 (SOS Deduction). A deduction πN∪S = [C1, . . . , Cn] is called
an SOS deduction if the derivation (N, S0) ⇒∗
RES (N, Sm) is an SOS derivation
where C′
1, . . . , C′
m is the subsequence from [C1, . . . , Cn] with input clauses removed,
S0 = S, and Si+1 = Si ∪C′
i+1.
Deﬁnition 4 (Overall Substitution of a Deduction). Given a deduction π
of a clause Cn the overall substitution τπ,i of Ci ∈π is recursively deﬁned by
1 if Ci is a factor of Cj with j < i and mgu σ, then τπ,i = τπ,j ◦σ,
330
F. Haifani et al.

2 if Ci is a resolvent of Cj and Ck with j < k < i and mgu σ, then τπ,i =
(τπ,j ◦τπ,k) ◦σ,
3 if Ci is an initial clause, then τπ,i = ∅,
and the overall substitution of the deduction is τπ = τπ,n. We omit the subscript
π if the context is clear.
Overall substitutions are well-deﬁned, because clauses introduced from N
into the deduction are variable disjoint and each clause is used exactly once in
the deduction. A grounding of an overall substitution τ of some deduction π is
a substitution τδ such that codom(τδ) only contains ground terms and dom(δ)
is exactly the variables from codom(τ).
Corollary 5 (Deduction Refutations versus Resolution Refutations).
There exists a resolution refutation (N, S) ⇒∗
RES (N, S′ ∪{⊥}) if and only if
there exists a deduction refutation π(N∪S) = [C1, . . . , Cn−1, ⊥] where Ci ∈(N∪S′)
for all i, modulo variable renaming.
We prove the generalized completeness result of SOS by transforming non-
SOS refutations into SOS refutations. For illustration of our proof transformation
technique, consider the below unsatisﬁable set of clauses N. Literals are labeled
in N by a singleton set of a unique natural number [12]. We will refer to the
literal labels during proof transformation in order to identify resolution and
factorization steps. The labels are inherited in a resolution inference and united
for the factorized literal in a factoring inference. See the factoring inference on
clause (3), Figure 1.
N = {(1):{1}¬Q(x3,f(a)) ∨{2}P(f(a)),
(2):{3}¬P(x4) ∨{4}¬Q(b,x4),
(5):{5}¬Q(b,a) ∨{6}Q(x1,f(x6)),
(6):{7}Q(b,x2) ∨{8}R(x2) ∨{9}T(c,x1),
(9):{10}¬R(x5),
(11):{11}¬T(c, b)}
Figure 1 shows a resolution refutation
π = [(5), (6), (7), (1), (2), (3), (4), (8), (9), (10), (11), (12)]
from N. This resolution refutation is also an SOS refutation with SOS S =
{(2), (5)} and remaining clause set N \ S. It is not an SOS refutation with SOS
S = {(5)} and the remaining clause set N \S because the resolution step between
clauses (1) and (2) is not an SOS step. The shaded part of the tree belongs to
an SOS deduction with S = {(5)}.
The transformation identiﬁes a clause closest to the leaves of the tree, obtained
by resolution, that has one parent that can be derived by the SOS strategy, but
the other parent is not in the SOS nor an input clause. For our example with
starting SOS S = {(5)} this is clause (8). The parent (7) can be derived via SOS
from S but the other parent (4) is not part of an SOS derivation. The overall
grounding substitution of π is τ = {x1 →b, x2 →a, x3 →b, x4 →f(a), x5 →
a, x6 →a}. Now the idea of a single transformation step is to perform the
Generalized Completeness for SOS Resolution and its Application
331

(12):⊥
(11):{11}¬T (c, b)
(10):{9}T (c,b)
(8):{8}R(a) ∨{9}T (c,b)
(4):{1, 4}¬Q(b,f(a))
(3):{1}¬Q(x3,f(a)) ∨{4}¬Q(b,f(a))
(2):{3}¬P (x4) ∨{4}¬Q(b,x4)
(1):{1}¬Q(x3,f(a)) ∨{2}P (f(a))
(7):{6}Q(x1,f(x6)) ∨{8}R(a) ∨{9}T (c,x1)
(6):{7}Q(b,x2) ∨{8}R(x2) ∨{9}T (c,x1)
(5):{5}¬Q(b,a) ∨{6}Q(x1,f(x6))
(9):{10}¬R(x5)
{x3 →b}
{x4 →f(a)}
{x1 →b, x6 →a}
{x2 →a}
{x5 →a}
Fig. 1. Refutation of π of N
resolution step on the labelled literal {1, 4}¬Q(b,f(a)) and the respective literal
{6}Q(x1,f(x6)) of the SOS derivable clause (7) already on the respective literals
from the input clauses yielding (8), here clauses (1) and (2). To this end the
derivation [(5), (6), (7)] is copied with fresh variables, see Figure 2, yielding the
clauses (7) and (7′) used in the refutation π′ below, see also Figure 3.
(7):{6}Q(x7,f(x9)) ∨{8}R(a) ∨{9}T (c,x7)
(6):{7}Q(b,x8) ∨{8}R(x8) ∨{9}T (c,x7)
(5):{5}¬Q(b,a) ∨{6}Q(x7,f(x9))
{x8 →a}
Fig. 2. The copied subdeductions deriving (7)
The two freshly renamed copies (7) and (7′) are resolved with the respective
input clauses (1) and (2). Finally, the rest of the deduction yielding clause (8)
is simulated with the resolved input clauses, see Figure 3. Now (8′′′) is exactly
clause (8) from the original deduction π, but (8′′′) is derived by an SOS deduction.
The deduction can then be continued the same way it was done in π and in this
case will already yield an SOS refutation.
π′ = [(5), (6), (7), (5′), (6′), (7′), (1), (1′), (2), (2′), (8′), (8′′), (8′′′),
(9), (10), (11), (12)].
The example motivates our use of literal labels. Firstly, they tell us which literals
from input clauses need to be resolved: here the literals {1}¬Q(x3,f(a)) and
{4}¬Q(b,x4) that are factorized in π to {1, 4}¬Q(b,f(a)). Secondly, they guide
additional factoring steps in π′ during the simulation of the non-SOS part from
π: here the factoring between the two literals labelled {8} in clause (8′) and
332
F. Haifani et al.

(8′′′):{8}R(a) ∨{9}T (c,b)
(8′′):{8}R(a) ∨{9}T (c,x3) ∨{9}T (c,b)
(8′):{8}R(a) ∨{9}T (c,x3) ∨{8}R(a) ∨{9}T (c,b)
(2′):{8}R(a) ∨{9}T (c,b) ∨{4}¬P (f(x11))
(2):{3}¬P (x4) ∨{4}¬Q(b,x4)
(7′):{6}Q(x10,f(x11)) ∨{8}R(a) ∨{9}T (c,x10)
(1′):{8}R(a) ∨{9}T (c,x3) ∨{2}P (f(a))
(7):{6}Q(x7,f(x9)) ∨{8}R(a) ∨{9}T (c,x7)
(1):{1}¬Q(x3,f(a)) ∨{2}P (f(a))
{x3 →b}
{x11 →a}
{x4 →f(x11)}
{x10 →b}
{x8 →a, x7 →x3}
Fig. 3. The new SOS deduction yielding a copy of clause (8)
the two literals with label {9} in clause (8′′). The transformation always works
because the overall grounding substitution of the initial refutation π is preserved
by the transformation. It just needs to be extended to the extra variables added
by freshly renamed copies of clauses.
The above example shows the importance of keeping track of the occurrences
of literals in a deduction. A labeled literal is a pair ML where M is a ﬁnite
non-empty set of natural numbers called the label and L is a literal. We identify
literals with labeled literals and refer explicitly to the label of a labeled literal by
the function lb. The function lb is extended to clauses via union of the respective
literal labels. We extend the notion of a clause to that of a labeled clause built on
labeled literals in the straightforward way. We call a deduction πN label-disjoint
if the clauses from N in the deduction have unique singleton labels. Labels are
inherited in a deduction as follows: in case of a resolution inference, the labels of
the parent clauses are inherited and in case of the factoring inference, the label
of the remaining literal is the union of labels of the factorized literals.
In general, we need to identify the parts of a deduction that are already
contained in an SOS deduction, this is called the partial SOS of a deduction, Def-
inition 6. Then this information can be used to perform the above transformation
on any deduction π.
Deﬁnition 6 (PSOS of a Deduction). Let π be a deduction from N ⊎S,
then the partial SOS (PSOS) O∗of ⟨π, N, S⟩is deﬁned as O∗= m
i=0 Oi, where
O0 = S, Oi+1 = Oi ∪{Cj} provided Cj ∈π, Cj ̸∈Oi and Cj is either the factor
of some clause in Oi or the resolvent of two clauses in π where at least one parent
is from Oi, and where Om is such that there is no longer such a Cj in π.
The partial SOS is well-deﬁned because the resulting O∗is independent of
the sequence Oi used. For example, for the deduction π from N presented in
Generalized Completeness for SOS Resolution and its Application
333

Figure 1 the set O∗= {(5), (6), (7)} is the PSOS of ⟨π, N, {5}⟩. Next we present
a criterion when the PSOS of a deduction actually signals an SOS deduction.
Lemma 7 (SOS Deduction). Let O∗be the PSOS of ⟨π, N, S⟩. Then π is
an SOS deduction if O∗\ S = π \ (N ∪S)4, i.e., all inferred clauses in π are
contained in O∗.
Proof. Let πN∪S = [C1, . . . , Cn] and [C′
1, . . . , C′
m] be the subsequence of πN∪S
with input clauses removed. Let O∗be the PSOS of ⟨π, N, S⟩. Then [C′
1, . . . , C′
m] =
O∗\ S = π \ (N ∪S) by assumption. We show that (N, S0) ⇒∗
RES (N, Sm) is
an SOS derivation, following Deﬁnition 3 by induction on m. If m = 0 then π
only consists of input clauses and there is nothing to show. For the case m = 1,
the clause C′
1 is the result of a factoring inference from S or the result of a
resolution inference from N ∪S such that at least one parent is in S as for
otherwise C′
1 ̸∈(O∗\ S). So (N, S0) ⇒∗
RES (N, S0 ∪{C′
1}) is an SOS derivation.
For the induction case, assume the property holds for i. If C′
i+1 is the result
of a factoring inference, then its parent C′′ is contained in Si because other-
wise C′′ ∈N because π being a deduction, and, therefore C′
i+1 ̸∈(O∗\ S), a
contradiction. If C′
i+1 is the result of a resolution inference, then again all its
parents are contained in N ∪Si because π is a deduction. If both parents are
from N, then C′
i+1 ̸∈(O∗\ S), a contradiction. So, by the induction hypothesis,
(N, S0) ⇒∗
RES (N, Si) ⇒RES (N, Si+1) is an SOS derivation.
The rest of this section is devoted to describing the transformation in detail.
In the next section, we then prove the new completeness result for SOS.
Let π be a label-disjoint deduction from N ∪S and let Ck ∈π be a clause of
minimal index such that Ck is the result of a resolution inference from clauses
Cj ∈O∗and Ci ̸∈(N ∪O∗). Let τ be an overall ground substitution for π.
We transform π into π′ by changing the deduction of Ci such that the overall
deduction gets “closer” to an SOS derivation and preserves τ. Let
Cj = C′
j ∨L
Ci = C′
i ∨K
Ck = (C′
i ∨C′
j)σ
(1)
where σ = mgu(K, comp(L)). Without loss of generality we assume that
π = [C1, . . . , Ci, Ci+1, . . . , Cj, Ck, Ck+1, . . . , Cn]
(2)
where [C1, . . . , Ci] and [Ci+1, . . . , Cj] are subdeductions of π, and the preﬁxes
of these sequences are exactly the introduced renamed copies of input clauses from
N that are used to derive Ci and Cj, respectively. The transformed derivation
will be
π′ = [C1
i+1, . . . , C1
j , . . . , Cm
i+1, . . . , Cm
j , D1, . . . , Dl, C′
k+1, . . . , C′
n]
(3)
where
4 Here we refer to the removal of all input clauses from O∗and π, respectively.
334
F. Haifani et al.

(a) the subsequences [Co
i+1, . . . , Co
j ] are freshly variable-renamed copies of the
sequence [Ci+1, . . . , Cj] where m = | lb(K)|. For the copies [Co
i+1, . . . , Co
j ] we
keep the labels of literals of the original sequence [Ci+1, . . . , Cj] for reference
in the transformation. The clauses Co
j are decomposed into C′o
j ∨L′, in
the same way that the clause Cj is decomposed into C′
j ∨L. Thus, for
each clause from N in the sequence [C1, . . . , Ci] containing a literal K′ with
lb(K′) ⊆lb(K) we add a deduction deriving a renamed copy of Cp
j ; let δp
be the renaming substitution from the old to the freshly renamed sequence,
then we extend τ to τ ′ as follows: τ ′
0 = τ, τ ′
p+1 = τ ′
p ◦{xδp+1 →t | x ∈
dom(δp+1), t = xτ} for 1 ≤p ≤m yielding the overall new grounding
substitution τ ′ = τ ′
m for π′;
(b) the clauses D1, . . . , Dl are generated by simulating the deduction [C1, . . . , Ci]
eventually producing Ck, up to possible variable renamings: Let Cp be the cur-
rent clause out of this deduction and let D1, . . . , Dq be the clauses generated
so far until Cp−1;
(i) if Cp is an input clause not containing a literal K′ with lb(K′) ⊆lb(K),
then Dq+1 = Cp and we associate Dq+1 with Cp;
(ii) if Cp is an input clause containing a literal K′ with lb(K′) ⊆lb(K), then
Dq+1 = Cp and Dq+2 is the resolvent between Dq+1 and a so far unused
clause Co
j on the literals K′ ∈Dq+1 and L′ ∈Co
j where lb(K′) ⊆lb(K)
and lb(L′) = lb(L) and we associate Dq+2 with Cp;
(iii) if Cp is the resolvent between two clauses Ci′, Cj′ then we perform the
respective resolution step between the associated clauses and respective
associated literals from Dq′, Dq′′ yielding Dq+1 and associate Dq+1 with
Cp;
(iv) if Cp is the factor on some literal K′ with lb(K′) ⊆lb(K), then we perform
the respective factoring steps Dq+1, . . . , Dq+s for respective literals with
labels from C′
j, where s = |C′
j| and we associate Dq+s with Cp,
(v) if Cp is the factor on some literal K′ with lb(K′) ̸⊆lb(K), then we perform
the respective factoring step on the respective literals with identical labels
from clause Dq′ yielding Dq+1 and we associate Dq+1 with Cp;
(c) the clauses C′
k+1, . . . , C′
n are obtained by simulating the generation of clauses
Ck+1, . . . , Cn where Ck is substituted with Dl.
Note that by assumption, the generation of clauses Ck+1, . . . , Cn does not
depend on clauses C1, . . . , Ci, Ci+1, . . . , Cj but only on Ck and the input clauses.
We will prove that Ckτ = Ckτ ′ = Dlτ ′ which is then suﬃcient to prove Cnτ =
Cnτ ′ = C′
nτ ′ and for the above to be well-deﬁned. In general, the clause Dl is
not identical to Ck because we introduce fresh variables in π′ and do not make
any speciﬁc assumptions on the uniﬁers used to derive Dl.
Mapping the transformation to our running example, Figure 1: Cj = (7),
Ci = (4), and Ck = (8). We need two copies of (7) because K = {1, 4}¬Q(b, f(a))
so m = |{1, 4}| = 2 and L = {6}Q(x1, f(x6)).
Generalized Completeness for SOS Resolution and its Application
335

3
A Generalized Completeness Proof for SOS
In this section, we prove that repeated applications of the transformation intro-
duced in the previous section can actually transform an arbitrary deduction into
an SOS deduction, given that at least one clause from the SOS occurs in the
original deduction. Firstly, we show that associated clauses of the transformed
deduction preserve main properties of the original deduction. The extended sub-
stitution is identical to the original substitution on old clauses and the changed
part of the deduction ends in exactly the same clause.
Lemma 8 (Properties of Associated Clauses). Let Cj, Ci, Ck, L, K, π,
π′, τ, τ ′ be as deﬁned in (1), (2), and (3), page 334. For each clause C out of
[C1, . . . , Ci] and clause D associated with C:
1. Cτ = Cτ ′,
2. K′τ ′ = L′τ ′ if lb(K′) = lb(L′) for any K′, L′ occurring in either π or π′,
3. lb(C) \ lb(K) = lb(D) \ lb(C′o
j ) and lb(C′o
j ) ⊆lb(D) if there is K′ ∈C with
lb(K′) ⊆lb(K),
4. Cτ \ {K′τ ∈C | lb(K′) ⊆lb(K)} = Dτ ′ \ {L′τ ′ ∈Dτ ′ | lb(L′) ∈lb(C′o
j )}
and C′o
j τ ′ ⊆Dτ ′ if there is K′ ∈C with lb(K′) ⊆lb(K),
5. Ckτ = Dlτ ′.
Proof. 1. By deﬁnition of τ ′ the additional variables in τ ′ do not occur in C
while τ ′ is identical to τ on the variables of C, hence Cτ = Cτ ′.
2. By induction on the generation of π′. For the base case, every literal occurring
in N ∪S has a unique label and any renamed clause Co
m for some Cm ∈(N ∪S)
has the labels kept. So, for any two literals K′ and L′ in any non inferred clauses
in π and π′, K′τ ′ = L′τ ′ when the labels are equal. For the induction step, for
inferred clauses, lb(K′) = lb(L′) happens when the label of K′ is inherited from
L′ through an inference. The inference uses an mgu which is compatible with τ ′
due to τ ′ being an overall ground substitution, so K′τ ′ = L′τ ′.
3. We prove this property by induction on the length of the derivation [C1, . . . , Ci].
Let C = Cp, 1 ≤p ≤i, and let D1, . . . , Dq be the clauses generated until Cp−1
for which, by the induction hypothesis the property already holds.
(i) If C is an input clause not containing a literal K′ with lb(K′) ⊆lb(K), we
have C = Cp = Dq+1 = D and {K′ ∈Cτ | lb(K′) ⊆lb(K)} = {L′ ∈Dqτ ′ |
lb(L′) ⊆lb(C′o
j )} = ∅.
(ii) If C is an input clause containing a literal K′ with lb(K′) ⊆lb(K) then
D = Dq+2 results from a resolution inference between C = Cp and an unused
Co
j on the literals K′ and L′ ∈Co
j with lb(L′) = lb(L). Let C = C′ ∨K′.
Then Dτ ′ = (C′ ∨C′o
j )τ ′ and hence lb(C) \ lb(K) = lb(D) \ lb(C′o
j ) because
lb(C) ∩lb(Co
j ) = ∅as π is a label-disjoint deduction and lb(Cj) = lb(Co
j ) by
construction.
(iii) If C is a resolvent of Ci′ = C′
i′ ∨L′
i′ and Cj′ = C′
j′ ∨L′
j′ on literals L′
i′, L′
j′,
then Cτ = C′
i′τ ∨C′
j′τ, and Dq+1 is a resolvent of some Dq′ = D′
q′ ∨L′′
q′
and Dq′′ = D′
q′′ ∨L′′
q′′ associated with Ci′ and Cj′ respectively. We have
336
F. Haifani et al.

lb(L′
i′) = lb(L′′
q′′) and lb(L′
j′) = lb(L′′
q′′) and none of these literals has a
label from lb(K) or lb(C′o
j ). Hence, the conjecture holds by the induction
hypothesis.
(iv) If C results from a factoring on K′ from Cp−1, we get Dq+s by a sequence
of s factoring inferences from Dq+1 associated with Cp−1. Any factorings
on Cp−1 and Dq+1 do not change literal labels because we factorize literals
of identical label. So, this property holds by the induction hypothesis. This
holds regardless of whether lb(K′) ⊆lb(K).
4. From Lemma 8.3 we know that lb(C) \ lb(K) = lb(D) \ lb(C′o
j ) and lb(C′o
j ) ⊆
lb(D) if there is K′ ∈C with lb(K′) ⊆lb(K). Since the labels coincide, using
Lemma 8.2, we have Cτ ′ \ {K′ ∈Cτ ′ | lb(K′) ⊆lb(K)} = Dτ ′ \ {L′ ∈Dτ ′ |
lb(L′) ∈lb(C′o
j )} and C′o
j τ ′ ⊆Dτ ′ if there is K′ ∈C with lb(K′) ⊆lb(K). This
hypothesis holds by applying Lemma 8.1 on literals and clauses from π in the
equation.
5. The clause Ck is the result of a resolution inference between Ci and Cj upon
K and L: Ckτ = C′
iτ ∪C′
jτ. By translation and because {K′ ∈Ci | lb(K′) ⊆
lb(K)} = {K}, the clause Ci is associated with Dl ∈π′ and Ciτ \ {Kτ} =
Dlτ ′ \ {L′ ∈Dlτ ′ | lb(L′) ∈lb(C′o
j )}. Since C′o
j τ ′ = C′
jτ = Cjτ \ {Lτ}, we have
{L′′ ∈Dlτ ′ | lb(L′′) ⊆lb(L′) for some L′ ∈C′o
j } = Dlτ ′ ∩Co
j \{Lτ} = Cj \{Lτ}.
So Ci \ {Kτ} = Dlτ ′ \ (Dlτ ′ ∩Cj \ {Lτ}) = Dlτ ′ \ (Cj \ {Lτ}). We can add
Cjτ \ {Lτ} to both sides and get Ckτ = Ciτ ∪Cjτ \ {Kτ, Lτ} ⊇Dlτ ′. In
addition, since lb(K) ⊆lb(K), this means Cjτ = C′o
j τ ′ ⊆Dqτ ′. Therefore
Ckτ = Ciτ ∪Cjτ \ {Kτ, Lτ} = Dlτ ′.
Next we need a well-founded measure that decreases with every transformation
step and in case of reaching its minimum signals an SOS deduction. Given a
clause set N and an initial SOS S, the SOS measure of a deduction π is μ(π) where
μ(π) = 
Ci∈π μ(Ci, π) and μ(Ci, π) = 0 if Ci ∈N ∪O∗otherwise μ(Ci, π) = 1.
Lemma 9 (Properties of μ). Given a clause set N, an initial SOS S, and a
deduction π that contains at least one resolution step,
1. μ(π) ≥0, and
2. if μ(π) = 0 then π is an SOS deduction.
Proof. 1. Obvious.
2. Towards contradiction, suppose π = [C1, . . . , Cn] is not an SOS deduction.
This means O∗\ S ⊊π \ (N ∪S) by Lemma 7. Consider a clause Ci ∈(π \ (N ∪
S)) \ (O∗\ S) of minimal index. Then Ci must be the result of an inference on
some Cj and Ck such that both are not in O∗. This means Ci ̸∈(N ∪O∗). For
this clause, μ assigns a nonzero value: μ(Ci, π) > 0. Therefore, μ(π) ̸= 0.
Next we combine the properties of associated clauses on one transformation
step with the properties of the measure resulting in an overall deduction trans-
formation that can be recursively applied and deduces the same clause modulo
some grounding.
Generalized Completeness for SOS Resolution and its Application
337

Lemma 10 (Properties of the Transformation). Given a deduction π of a
clause Cn from N ∪S that contains at least one resolution step such that π∩S ̸= ∅,
an overall ground substitution τ of π and the transformed deduction π′ of a clause
C′
n as deﬁned in (1), (2), and (3) with overall ground substitution τ ′, we have:
1. π′ is a deduction from N ∪S,
2. Cnτ = C′
nτ ′, and
3. μ(π′) < μ(π).
Proof. 1. We show that π′ is a deduction following Deﬁnition 2. These properties
will be carried over from π. Observe that, if π1 is a deduction of Ck from N ∪S
and π2 is a deduction from N ∪S ∪{Ck} using Ck only once, their concatenation
π1 ◦π2 is a deduction from N ∪S. Firstly, the subsequences [Co
i+1, . . . , Co
j ] are
deductions of Co
j from N ∪S since they are only the renamed copies of the
subdeduction [Ci+1, . . . Cj] of π. Secondly, the subsequence [Ck, . . . , Cn] is a
deduction of Cn from N ∪S ∪{Ck} since the clauses after Ck do not use any
clauses before Ck by the way π is represented as a sequence. Now, by showing
that [C1
j , . . . , Cm
j , D1, . . . , Dl, Ck] is a deduction of Ck from N ∪S ∪{Co
j }o∈[1,m],
the sequence [D1, . . . , Dl] would then connect the initial copied sequences and
the tailing subsequence. Each Co
j is used for exactly one resolution inference
producing some Dq, the other required clauses are copied, and the later resolution
and factoring steps in [D1, . . . , Dl] are sound while the deduction properties of
[C1, . . . , Ci] are preserved in its associated clauses: for an inference where Cp′
(and Cp′′) generates Cp, we have a unique inference between their associated
clauses Dq′, (Dq′′,) Dq+1 where Dq′ (and Dq′′) generates Dq+1, possibly with
additional factoring inferences in between. If Cp is an input clause not containing
a literal K′ with lb(K′) ⊆lb(K), then Dq+1 = Cp ∈N. The clause Dq+1 is used
in π′ as Cp is used in π; if Cp is an input clause containing a literal K′ with
lb(K′) ⊆lb(K), the resolution between Dq+1 and a so far unused clause Co
j is
sound as K′ and comp(L′) are uniﬁable by τ ′. Here, all Co
j will be eventually used
as there are m = | lb(K)| literals in the clauses from N; if Cp is the resolvent
between two clauses Ci′, Cj′ then the respective resolution step between the
associated clauses Dq′, Dq′′ upon the respective associated literals K′ and L′
is sound because we can get K′τ ′ = comp(L′)τ ′ using Lemma 8; if Cp is the
factor on some literal K′ with lb(K′) ⊆lb(K), then the respective factoring
steps Dq+1, . . . , Dq+s are also sound: each pair of the s associated literals M and
M ′ from Co
j and Co′
j
are uniﬁable because Mτ ′ = M ′τ ′; if Cp is the factor of
Cp−1 upon some literal K′ and L′ with {lb(K′), lb(L′)} ̸⊆lb(K), the respective
factoring step on the associated clause Dq′ is also sound by Lemma 8. Therefore
π is a deduction from N ∪S.
2. By Lemma 8.5, Ckτ = Dlτ ′. The derivation of clauses Ck, Ck+1, . . . , Cn only
depends on the input clauses by assumption. By an inductive argument we get
Ck+1τ = C′
k+1τ ′ yielding Cnτ = C′
nτ ′.
3. The clauses in [Co
i+1, . . . , Co
j ] have the measure 0 as their original ones in
[Ci+1, . . . , Cj] because they are in N ∪O∗. The clauses in [Ck, . . . , Cn] also retain
their original measures. The clauses in [D1, . . . , Dl] are s.t. Σl
k=1μ(π′, Dk) <
338
F. Haifani et al.

Σi
k=1μ(π′, Ck). More speciﬁcally, any C ∈[C1, . . . , Ci] that is not in N ∪O∗(with
measure μ(C, π) ≥1) and containing K′ with lb(K′) ⊆lb(K) is associated
with Dq ∈O∗\ N having the measure μ(Dq, π′) = 0, while all other clauses in
[D1, . . . , Dl] are either copied from π with the same measure as before or new in
π′ but have the measure 0.
By induction on the length of the sequence [C1, . . . , Ci] we prove the following
property: if D is associated with a clause C ∈[C1, . . . , Ci] and C contains some
literal in {K′ | lb(K′) ⊆lb(K)}, then D ∈N ∪O∗and μ(D, π′) = 0. Let C = Cp.
Let D1, . . . , Dq be the clauses generated until Cp−1 s.t. the property already
holds.
(i) If Cp is an input clause with no literals in {K′ | lb(K′) ⊆lb(K)}, it is
associated with Dq = Cp s.t. μ(Cp, π) = μ(Dq, π′) = 0;
(ii) If Cp is an input clause containing {K′ | lb(K′) ⊆lb(K)}, it is resolved with
some Co
j ∈O∗resulting in Dq+1 ∈O∗. Here we have μ(Cp, π) = μ(Dq, π′) =
0;
(iii) If Cp is the resolvent between two clauses Ci′, Cj′ then we perform the
respective resolution step between the associated clauses Dq′, Dq′′ yielding
the clause Dq associated with Cp. If either Ci′ or Cj′ contains some literal
from {K′ | lb(K′) ⊆lb(K)} then Cp contains this literal as well and either
Dq′ ∈O∗or Dq′′ ∈O∗by the induction hypothesis. So, we get Dq ∈O∗and
μ(Dq, π′) = 0. Otherwise, μ(Dq, π′) = μ(Cp, π) = 1;
(iv) If Cp is the factor of Cp−1 on some literal K′ with lb(K′) ⊆lb(K), then
we have the respective factoring steps Dq+1, . . . , Dq+s where Dq+1 is as-
sociated with Cp−1. By the induction hypothesis, Dq+1 ∈O∗. Therefore
Dq+1, . . . , Dq+s ∈O∗with μ(Dq+t, π′) = 0 for 1 ≤t ≤s;
(v) If Cp is the factor of Cp−1 (associated with Dq) on some literal K′ and L′ with
{lb(K′), lb(L′)} ̸⊆lb(K), the factoring happens to the associated clauses in
π′ with similar measure.
Finally, by the choice of Ci, Cj, and Ck, there must exist at least one Cp with
some literal from {K′ | lb(K′) ⊆lb(K)} but associated with some D such that
D ∈O∗from case (iii) or (iv) before. This also means μ(D, π′) = 0. The clause
Ci has this property as it contains K. In addition, any Cp has a nonzero measure
because Ci ̸∈N ∪O∗and Cp is used to prove Ci. Therefore, we have μ(Cp, π) >
μ(D, π′) = 0. As these clauses are never copied to π′, μ(π′) < μ(π).
Eventually, by an inductive argument we prove our main result.
Theorem 11 (Generalized SOS Completeness). There is an SOS resolu-
tion refutation from (N, S) if and only if there is resolution refutation from N ∪S
that contains at least one clause from S.
Proof. “⇒”: Obvious: If there is no refutation from N ∪S using a clause S then
there can also not be any SOS resolution refutation from (N, S).
“⇐”: If there is a deduction refutation π from N ∪S that contains at least one
clause from S, then by an inductive argument on μ it can be transformed into
Generalized Completeness for SOS Resolution and its Application
339

an SOS deduction refutation with SOS S, and the result follows by Corollary 5.
If μ(π) = 0 then π is already an SOS deduction, Lemma 9. For otherwise, we
transform the deduction π into a deduction π′ according to (1), (2), and (3). A
refutation always contains at least one resolution step, so by Lemma 10, π′ is also
a refutation from N ∪S and μ(π′) < μ(π). Eventually, π′ can be transformed
into a label-disjoint deduction by assigning fresh labels to all used clauses from
N ∪S.
As an example for the “⇒” direction consider the propositional logic clause
set N = {P, ¬P} and SOS S = {Q}. Obviously, there is no refutation of N ∪
S using Q and there is no SOS refutation. Theorem 11 also guarantees that
the consecutive application of the proof transformation steps (1), (2), and (3),
page 334, results in an eﬀective recursive procedure that transforms non-SOS
refutations into SOS refutations.
4
A new Notion of Relevance
The idea of our notion of relevance is to separate clauses that are ultimately
needed in a refutation proof called relevant, from clauses that are useful called
semi-relevant, from clauses that are not needed called irrelevant.
Deﬁnition 12 (Relevance). Given an unsatisﬁable set of clauses N, a clause
C ∈N is relevant if for all deduction refutations π of N it holds that C ∈π. A
clause C ∈N is semi-relevant if there exists a deduction refutation π of N in
which C ∈π. A clause C ∈N is irrelevant if there is no deduction refutation π
of N in which C ∈π.
With respect to our example clause set N from Section 2 and its refutation,
Figure 1, clause (5) is semi-relevant but not relevant, because the clauses (1), (2),
(6), (9), (11) are already unsatisﬁable. The clauses (1), (2), (6), (9), (11) are all
relevant.
Lemma 13 (Relevance). Given an unsatisﬁable set of clauses N, the clause
C ∈N is relevant if and only if N \ {C} is satisﬁable.
Proof. Obvious: if N \{C} is satisﬁable there is no resolution refutation and since
N is unsatisﬁable C must occur in all refutations. If C occurs in all refutations
there is no refutation without C so N \ {C} is satisﬁable.
Lemma 14 (Semi-Relevance Test). Given a set of clauses N, and a clause
C ∈N, C is semi-relevant if and only if (N \{C}, {C}) ⇒∗
RES (N \{C}, S∪{⊥}).
Proof. If (N\{C}, {C}) ⇒∗
RES (N\{C}, S∪{⊥}) then we have found a refutation
containing C. On the other hand, by Theorem 11, Lemma 7 and Corollary 5, if
there is a refutation containing C, then there is also an SOS refutation with SOS
{C}.
340
F. Haifani et al.

An immediate consequence of the above test and completeness of resolution
for ﬁrst-order logic is the following corollary.
Corollary 15 (Complexity of the Semi-Relevance Test). Testing semi-
relevance in ﬁrst-order logic is semi-decidable. It is decidable for all fragments
where resolution constitutes a decision procedure.
Fragments where our semi-relevance test is guaranteed to terminate are for
example ﬁrst-order fragments enjoying the bounded model property, such as the
Bernays-Schoenﬁnkel fragment [3].
5
Conclusion
We have extended and sharpened the original completeness result for SOS resolu-
tion [18], Theorem 11. The generalized SOS completeness result can actually be
used to eﬀectively test clauses for semi-relevance in case resolution constitutes a
decision procedure for the respective clause set. This is for example the case for all
fragments enjoying the bounded model property, such as the Bernays-Schoenﬁnkel
fragment [3]. In general, our approach yields a semi-decision procedure for semi-
relevance.
Our proof is based on deductions having an a priori tree structure. However,
this is not a principle restriction. It just simpliﬁes the transformation introduced
in Section 2: renamings have only to be considered on input clauses. In a setting
where proofs forming directed acyclic graphs are considered, renamings have to be
carried all over a deduction, adding further technicalities to our transformation.
It is well-known that changing the ordering of resolution steps in a resolution
deduction may exponentially increase or exponentially decrease the length of the
deduction. Therefore, our transformation of a deduction into an SOS deduction
may also yield an exponential growth in the length of the deduction. It may also be
the other way round if, e.g, subsumption is added to the transformation. It is also
not diﬃcult to ﬁnd examples where the transformation of Section 2 introduces
redundant clauses. Recall that we have not made any assumption with respect to
redundancy on deductions. So an open question is whether corresponding results
hold on non-redundant deductions and what they actually mean for a respective
notion of relevance.
An open problem is the question whether a test for semi-relevance can be
established with more restricted resolution calculi such as ordered resolution. In
general, the SOS strategy is not complete with ordered resolution. However, it
is complete with respect to a clause set saturated by ordered resolution. The
technical obstacle here is that a saturated clause set may already contain the
empty clause, because for our generalized completeness result and the respective
relationship to semi-relevance, the set N may still be unsatisﬁable without the
clause C to be tested for semi-relevance.
Acknowledgments: This work was funded by DFG grant 389792660 as part of
TRR 248. We thank our reviewers for their valuable comments.
Generalized Completeness for SOS Resolution and its Application
341

References
1. Baader, F., Pe˜naloza, R.: Axiom pinpointing in general tableaux. J. Log. Comput.
20(1), 5–34 (2010)
2. Bachmair, L., Ganzinger, H.: Rewrite-based equational theorem proving with selec-
tion and simpliﬁcation. Journal of Logic and Computation 4(3), 217–247 (1994),
revised version of Max-Planck-Institut f¨ur Informatik technical report, MPI-I-91-
208, 1991
3. Bernays, P., Sch¨onﬁnkel, M.: Zum entscheidungsproblem der mathematischen logik.
Mathematische Annalen 99, 342–372 (1928)
4. Bourgaux, C., Ozaki, A., Pe˜naloza, R., Predoiu, L.: Provenance for the description
logic elhr. In: Bessiere, C. (ed.) Proceedings of the Twenty-Ninth International
Joint Conference on Artiﬁcial Intelligence, IJCAI 2020. pp. 1862–1869. ijcai.org
(2020)
5. Eiter, T., Gottlob, G.: The complexity of logic-based abduction. Journal of the
ACM 42(1), 3–42 (1995)
6. Fetzer, C., Weidenbach, C., Wischnewski, P.: Compliance, functional safety and
fault detection by formal methods. In: Margaria, T., Steﬀen, B. (eds.) Leveraging
Applications of Formal Methods, Veriﬁcation and Validation: Discussion, Dissemi-
nation, Applications - 7th International Symposium, ISoLA 2016, Imperial, Corfu,
Greece, October 10-14, 2016, Proceedings, Part II. Lecture Notes in Computer
Science, vol. 9953, pp. 626–632 (2016)
7. Haifani, F., Koopmann, P., Tourret, S., Weidenbach, C.: On a notion of relevance.
In: Borgwardt, S., Meyer, T. (eds.) Proceedings of the 33rd International Workshop
on Description Logics (DL 2020) co-located with the 17th International Conference
on Principles of Knowledge Representation and Reasoning (KR 2020), Online Event
[Rhodes, Greece], September 12th to 14th, 2020. CEUR Workshop Proceedings,
vol. 2663. CEUR-WS.org (2020)
8. Kalyanpur, A., Parsia, B., Horridge, M., Sirin, E.: Finding all justiﬁcations of OWL
DL entailments. In: Aberer, K., Choi, K., Noy, N.F., Allemang, D., Lee, K., Nixon,
L.J.B., Golbeck, J., Mika, P., Maynard, D., Mizoguchi, R., Schreiber, G., Cudr´e-
Mauroux, P. (eds.) The Semantic Web, 6th International Semantic Web Conference,
2nd Asian Semantic Web Conference, ISWC 2007 + ASWC 2007, Busan, Korea,
November 11-15, 2007. Lecture Notes in Computer Science, vol. 4825, pp. 267–280.
Springer (2007)
9. Kleine B¨uning, H., Kullmann, O.: Minimal unsatisﬁability and autarkies. In: Biere,
A., Heule, M., van Maaren, H., Walsh, T. (eds.) Handbook of Satisﬁability, Frontiers
in Artiﬁcial Intelligence and Applications, vol. 185, pp. 339–401. IOS Press (2009)
10. Kullmann, O.: Investigations on autark assignments. Discret. Appl. Math. 107(1-3),
99–137 (2000)
11. Lee, C.T.: A Completeness Theorem and a Computer Program for Finding Theo-
rems Derivable from Given Axioms. Phd thesis, University of Berkeley, California,
Department of Electrical Engineering (1967)
12. Lev-Ami, T., Weidenbach, C., Reps, T.W., Sagiv, M.: Labelled clauses. In: Pfen-
ning, F. (ed.) Automated Deduction - CADE-21, 21st International Conference on
Automated Deduction, Bremen, Germany, July 17-20, 2007, Proceedings. LNCS,
vol. 4603, pp. 311–327. Springer (2007)
13. Nienhuys-Cheng, S., de Wolf, R.: The equivalence of the subsumption theorem and
the refutation-completeness for unconstrained resolution. In: Kanchanasut, K., L´evy,
J. (eds.) Algorithms, Concurrency and Knowledge: 1995 Asian Computing Science
342
F. Haifani et al.

Conference, ACSC ’95, Pathumthani, Thailand, December 11-13, 1995, Proceedings.
Lecture Notes in Computer Science, vol. 1023, pp. 269–285. Springer (1995)
14. Robinson, J.A.: A machine-oriented logic based on the resolution principle. Journal
of the ACM 12(1), 23–41 (January 1965)
15. Robinson, J.A., Voronkov, A. (eds.): Handbook of Automated Reasoning (in 2
volumes). Elsevier and MIT Press (2001)
16. Schlobach, S., Cornet, R.: Non-standard reasoning services for the debugging of
description logic terminologies. In: Gottlob, G., Walsh, T. (eds.) IJCAI-03, Pro-
ceedings of the Eighteenth International Joint Conference on Artiﬁcial Intelligence,
Acapulco, Mexico, August 9-15, 2003. pp. 355–362. Morgan Kaufmann (2003)
17. Walter, R., Felfernig, A., K¨uchlin, W.: Constraint-based and sat-based diagnosis
of automotive conﬁguration problems. J. Intell. Inf. Syst. 49(1), 87–118 (2017)
18. Wos, L., Robinson, G., Carson, D.: Eﬃciency and completeness of the set of support
strategy in theorem proving. Journal of the ACM 12(4), 536–541 (1965)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium or
format, as long as you give appropriate credit to the original author(s) and the source,
provide a link to the Creative Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.
Generalized Completeness for SOS Resolution and its Application
343

A Unifying Splitting Framework
Gabriel Ebner1
( ), Jasmin Blanchette1,2,3
, and Sophie Tourret2,3
1 Vrije Universiteit Amsterdam, Amsterdam, the Netherlands
{g.e.ebner,j.c.blanchette}@vu.nl
2 Université de Lorraine, CNRS, Inria, LORIA, Nancy, France
{jasmin.blanchette,sophie.tourret}@inria.fr
3 Max-Planck-Institut für Informatik, Saarland Informatics Campus,
Saarbrücken, Germany
{jasmin.blanchette,stourret}@mpi-inf.mpg.de
Abstract. AVATAR is an elegant and eﬀective way to split clauses in a
saturation prover using a SAT solver. But is it refutationally complete?
And how does it relate to other splitting architectures? To answer these
questions, we present a unifying framework that extends a saturation
calculus (e.g., superposition) with splitting and embeds the result in a
prover guided by a SAT solver. The framework also allows us to study
locking, a subsumption-like mechanism based on the current propositional
model. Various architectures are instances of the framework, including
AVATAR, labeled splitting, and SMT with quantiﬁers.
1
Introduction
One of the great strengths of saturation calculi such as superposition [1] is
that they avoid case distinctions. Derived clauses hold unconditionally, and
the prover can stop as soon as it derives the empty clause, without having to
backtrack. The drawback is that these calculi often generate long, unwieldy
clauses that slow down the prover. A remedy is to partition the search space by
splitting a multiple-literal clause C1 ∨· · ·∨Cn into variable-disjoint subclauses Ci.
Splitting approaches include splitting with backtracking [24], splitting without
backtracking [20], labeled splitting [10], and AVATAR [22].
The SAT-based AVATAR architecture is of particular interest because it is
so successful. Voronkov reported that an AVATAR-enabled Vampire could solve
421 TPTP [21] problems that had never been solved before by any system [22,
Sect. 9], a mind-boggling number. AVATAR works well in combination with
the superposition calculus because it combines superposition’s strong equality
reasoning with the SAT solver’s strong clausal reasoning. It is also appealing
theoretically, because it gracefully generalizes traditional saturation provers and
yet degenerates to a SAT solver if the problem is propositional.
Example 1. To illustrate the approach, we follow the key steps of an AVATAR-
enabled resolution prover on the initial clause set containing ¬p(a), ¬q(z, z), and
p(x) ∨q(y, b). The disjunction can be split into p(x) ←{[p(x)]} and q(y, b) ←
{[q(y, b)]}, where C ←{[C]} indicates that the clause C is enabled only in models
in which the associated propositional variable [C] is true. A SAT solver is then
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5_20
344–360, 2021.

A Unifying Splitting Framework
345
run to choose a model J of [p(x)] ∨[q(y, b)]. Suppose J makes [p(x)] true and
[q(y, b)] false. Then resolving p(x) ←{[p(x)]} with ¬p(a) produces ⊥←{[p(x)]},
which closes the branch. Next, the SAT solver makes the right disjunct true,
and resolving q(y, b) ←{[q(y, b)]} with ¬q(z, z) yields ⊥←{[q(y, b)]}. The SAT
solver then reports “unsatisﬁable,” concluding the refutation.
What about refutational completeness? Far from being a purely theoretical
concern, establishing completeness—or ﬁnding counterexamples—could yield
insights and perhaps lead to an even stronger AVATAR. Before we can answer
this open question, we must mathematize splitting. Our starting point is the
saturation framework by Waldmann, Tourret, Robillard, and Blanchette [23],
based on Bachmair and Ganzinger [2]. It covers a wide array of techniques,
but “the main missing piece of the framework is a generic treatment of clause
splitting” [23, p. 332]. We provide that missing piece, in the form of a splitting
framework, and use it to show the completeness of an AVATAR-like architecture.
Our framework has ﬁve layers, linked by reﬁnement. The ﬁrst layer consists
of a refutationally complete base calculus, such as resolution or superposition. It
must be presentable as an inference system and a redundancy criterion.
From a base calculus, we derive a splitting calculus (Sect. 3). This extends
the base calculus with splitting and inherits the base’s completeness. It works on
A-clauses or A-formulas C ←A, where A is a set of propositional literals.
Using the saturation framework, we can prove the dynamic completeness of an
abstract prover, formulated as a transition system, that implements the splitting
calculus. However, this ignores a vital component of AVATAR: the SAT solver.
AVATAR considers only inferences involving A-formulas whose assertions are
true in the current propositional model. The role of the third layer is to reﬂect
this behavior. A model-guided prover operates on states of the form (J,N), where
J is a propositional model and N is a set of A-formulas (Sect. 4).
The fourth layer introduces AVATAR’s locking mechanism (Sect. 5). With
locking, an A-formula D ←B can be temporarily disabled by another A-formula
C ←A if C subsumes D, even if A ̸⊆B. Here we make a ﬁrst discovery: AVATAR-
style locking compromises completeness and must be curtailed.
Finally, the ﬁfth layer is an AVATAR-based prover (Sect. 6). This reﬁnes the
locking model-guided prover of the fourth layer with the given clause procedure,
which saturates an A-formula set by distinguishing between active and passive
A-formulas. Here we make another discovery: Selecting A-formulas fairly is not
enough to guarantee completeness. We need a stronger criterion.
In a hypothetical tête-à-tête with the designers of labeled splitting, they might
gently point out that by pioneering the use of a propositional model, including
locking, they almost invented AVATAR themselves. Likewise, developers of
SMT solvers might be tempted to claim that Voronkov merely reinvented SMT.
To investigate such questions, we apply our framework to splitting without
backtracking, labeled splitting, and SMT with quantiﬁers (Sect. 7). This gives us
a solid basis for comparison as well as some new theoretical results.
A technical report [8] is available with the proofs, several counterexamples,
and further details. A formalization using Isabelle/HOL [16] is underway.

346
G. Ebner, J. Blanchette, and S. Tourret
2
Preliminaries
Our framework is parameterized by abstract notions of formulas, consequence rela-
tions, inferences, and redundancy. We largely follow the conventions of Waldmann
et al. [23]. A-formulas generalize Voronkov’s A-clauses [22].
Formulas. A set F of formulas is a set that contains a distinguished element ⊥
denoting falsehood. A consequence relation |= ⊆(P(F))2 has the following
properties for all M, N, P, Q ⊆F and C, D ∈F: (D1) {⊥} |= ∅; (D2) {C} |= {C};
(D3) if M ⊆N and P ⊆Q, then M |= P implies N |= Q; (D4) if M |= P and
N |= Q ∪{C} for every C ∈M and N ∪{D} |= Q for every D ∈P, then N |= Q.
The intended meaning of M |= N is M −■→N. From |=, we can easily derive
a relation understood as M −■→N, as required by the saturation framework.
The |= notation can be extended to allow negation on either side. Let F∼
be deﬁned as F ⊎{∼C | C ∈F∼} such that ∼∼C = C. Given M, N ⊆F∼, we
have M |= N if and only if {C ∈F | C ∈M} ∪{C ∈F | ∼C ∈N} |= {C ∈F |
∼C ∈M} ∪{C ∈F | C ∈N}.
Following the saturation framework [23, p. 318], we distinguish between the
consequence relation |= used for stating refutational completeness and a possibly
stronger consequence relation |≈for soundness. We require that |≈is compact.
Example 2. In clausal ﬁrst-order logic with equality, the formulas in F consist of
clauses over a signature Σ. Each clause C is a ﬁnite multiset of literals L1, . . . , Ln
written C = L1 ∨· · · ∨Ln. Each literal L is either an atom or its negation (¬),
and each atom is an unoriented equation s ≈t. We have M |= N if and only if
every Σ-model of M also satisﬁes at least one clause in N.
Calculi and Derivations. A refutational calculus (Inf , Red) combines a set of
inferences Inf and a redundancy criterion Red. We refer to Waldmann et al. [23]
for the precise deﬁnitions. Recall in particular that Inf (N) is the set of inferences
from N, Inf (N, M) = Inf (N ∪M) \ Inf (N \ M), N is saturated w.r.t. Inf and
RedI if Inf (N) ⊆RedI(N), and (Inf , Red) is statically (refutationally) complete
(w.r.t. |=) if ⊥∈N for every N |= {⊥} saturated w.r.t. Inf and RedI.
Let (Xi)i be a sequence of sets. Its limit inferior is X∞= lim infj→∞Xj =

i

j≥i Xj, and its limit superior is X∞= lim supj→∞Xj = 
i

j≥i Xj. The
elements of X∞are called persistent. A sequence (Ni)i over P(F) is weakly fair
w.r.t. Inf and RedI if Inf (N∞) ⊆
i RedI(Ni) and strongly fair if (Inf (Ni))∞⊆

i RedI(Ni). Given a relation ▷, a ▷-derivation is an inﬁnite sequence such that
xi ▷xi+1 for every i. Finite runs can be extended to derivations via stuttering.
Let ▷RedF ⊆(P(F))2 be the relation such that M ▷RedF N if and only
if M \ N ⊆RedF(N). The calculus (Inf , Red) is dynamically (refutationally)
complete (w.r.t. |=) if for every ▷RedF-derivation (Ni)i that is weakly fair w.r.t.
Inf and RedI and such that N0 |= {⊥}, we have ⊥∈Ni for some i.
A-Formulas. We ﬁx throughout a countable set V of propositional variables
v0, v1, . . . . For each v ∈V, let ¬v ∈¬V denote its negation, with ¬¬v = v. We
assume that a formula fml(v) ∈F is associated with each v ∈V. Intuitively, v

A Unifying Splitting Framework
347
approximates fml(v) at the propositional level. This deﬁnition is extended so
that fml(¬v) = ∼fml(v). An assertion a ∈A = V ∪¬V is either a propositional
variable v or its negation ¬v. Given a formula C ∈F∼, let asn(C) denote the set
of assertions a ∈A such that {fml(a)} |≈{C} and {C} |≈{fml(a)}.
A propositional interpretation J ⊆A is a set such that for every v ∈V,
exactly one of v ∈J and ¬v ∈J holds. We reserve the letter J for interpretations,
and deﬁne fml(J) = {fml(a) | a ∈J}.
An A-formula over a set F of base formulas and an assertion set A is a pair
C = (C, A) ∈AF = F×Pﬁn(A), written C ←A, where C is a formula and A is a
ﬁnite set of assertions {a1, . . . , an} understood as an implication a1∧· · ·∧an −■→C.
We identify C ←∅with C and deﬁne the projection ⌊C ←A⌋= C. Moreover,
N⊥is the set consisting of all A-formulas of the form ⊥←A ∈N. We call such
A-formulas propositional clauses. Note the use of calligraphic letters (e.g., C, N)
to range over A-formulas and sets of A-formulas.
We say that C←A ∈AF is enabled in J if A ⊆J. A set of A-formulas is enabled
in J if all of its members are enabled in J. The enabled projection NJ ⊆⌊N⌋
consists of the projections ⌊C⌋of all A-formulas C enabled in J. Analogously,
the enabled projection Inf J ⊆⌊Inf ⌋of a set Inf of AF-inferences consists of the
projections ⌊ι⌋of all inferences ι ∈Inf whose premises are all enabled in J.
A propositional interpretation J is a propositional model of N⊥, written
J |= N⊥, if ⊥/∈(N⊥)J. Moreover, we write J |≈N⊥if ⊥/∈(N⊥)J or fml(J) |≈{⊥}.
A set N⊥is propositionally satisﬁable if there exists an interpretation J such
that J |= N⊥. In contrast to consequence relations, propositional modelhood |=
interprets the set N⊥conjunctively: J |= N⊥is understood as J |=  N⊥.
Finally, we lift |= and |≈from P(F) to P(AF): M |= N if and only if
MJ |= ⌊N⌋for every J in which N is enabled, and M |≈N if and only if
fml(J) ∪MJ |≈⌊N⌋for every J in which N is enabled.
Example 3. In the original AVATAR [22], the connection between ﬁrst-order
clauses and assertions takes the form of a function [ ] : F →A. The encoding is
such that [¬C] = ¬[C] for every ground unit clause C and [C] = [D] if and only if
C is syntactically equal to D up to variable renaming. This can be supported in
our framework by letting fml(v) = C for some C such that [C] = v, for every v.
3
Splitting Calculi
Let F be a set of base formulas equipped with ⊥, |=, and |≈. The relation |≈is
assumed to be nontrivial: (D5) ∅̸|≈∅. Let A be a set of assertions over V and AF
be the set of A-formulas over F and A. Let (FInf , FRed) be a base calculus for F,
where FRed is a redundancy criterion that additionally satisﬁes (1) an inference
is FRedI-redundant if one of its premises is FRedF-redundant; (2) ⊥/∈FRedF(N)
for every N ⊆F; and (3) C ∈FRedF({⊥}) for every C ̸= ⊥. These requirements
can easily be met by a well-designed redundancy criterion [1, Sect. 4.3].
Below, we will deﬁne the splitting calculus induced by the base calculus. We
will see that it not only is statically and dynamically complete w.r.t. |=, but also
meets stronger, “local completeness” criteria that capture model switching.

348
G. Ebner, J. Blanchette, and S. Tourret
The Inference Rules. We start with the mandatory inference rules.
Deﬁnition 4. The splitting inference system SInf consists of all instances of
(Ci ←Ai)n
i=1
Base
D ←A1 ∪· · · ∪An
(⊥←Ai)n
i=1 Unsat
⊥
For Base, the side condition is (Cn, . . . , C1, D) ∈FInf . For Unsat, the side
condition is that {⊥←A1, . . . , ⊥←An} is propositionally unsatisﬁable.
In addition, the following optional inference rules can be used:
C ←A
Split
⊥←{¬a1, . . . , ¬an} ∪A
(Ci ←{ai})n
i=1
(⊥←Ai)n
i=1
C ←A
Collect
(⊥←Ai)n
i=1
(⊥←Ai)n
i=1
C ←A ∪B
Trim
(⊥←Ai)n
i=1
C ←B
(⊥←Ai)n
i=1 StrongUnsat
⊥
C ←A
Approx
⊥←{¬a} ∪A
Tauto
C ←A
The following side conditions apply. For Split: C ̸= ⊥is splittable into C1, . . . ,
Cn and ai ∈asn(Ci) for each i. A formula C is splittable into two or more
formulas C1, . . . , Cn if {C} |≈{C1, . . . , Cn} and C ∈FRedF({Ci}) for each i.
For Collect: C ̸= ⊥and {⊥←Ai}n
i=1 |≈{⊥←A}. For Trim: C ̸= ⊥and
{⊥←Ai}n
i=1 ∪{⊥←A} |≈{⊥←B}. For StrongUnsat: {⊥←Ai}n
i=1 |≈{⊥}.
For Approx: a ∈asn(C). For Tauto: |≈{C ←A}.
The three rules identiﬁed by double bars are simpliﬁcations; they replace
their premises with their conclusions in the current A-formula set. The premises’
removal is justiﬁed by SRedF, deﬁned below. Also note that Base preserves the
soundness of FInf w.r.t. |≈and that the other rules are sound w.r.t. |≈.
The Split rule performs an n-way case split on C. Each case Ci is approxi-
mated by an assertion ai. The ﬁrst conclusion expresses that the case distinction
is exhaustive. The n other conclusions assume Ci if its approximation ai is true.
In a clausal prover, typically C = C1 ∨· · · ∨Cn, where the subclauses Ci have
mutually disjoint sets of variables and form a maximal split.
Collect and Trim do some garbage collection. StrongUnsat is a variant
of Unsat that uses |≈instead of |=. It might correspond to invoking an SMT
solver [3] (|≈) with a time limit, falling back on a SAT solver (|=). Approx can be
used to make any derived A-formula visible to |≈. Tauto allows communication
in the other direction, from the SAT solver to the calculus.
Example 5. Suppose the base calculus is ﬁrst-order resolution [2] and the initial
clauses are ¬p(a), ¬q(z, z), and p(x) ∨q(y, b), as in Example 1. Split replaces
the last clause by ⊥←{¬v0, ¬v1}, p(x) ←{v0}, and q(y, b) ←{v1}. Two Base
inferences then generate ⊥←{v0} and ⊥←{v1}. Finally, Unsat generates ⊥.

A Unifying Splitting Framework
349
The Redundancy Criterion. Next, we lift the base redundancy criterion.
Deﬁnition 6. The splitting redundancy criterion SRed = (SRedI, SRedF) is
speciﬁed as follows. An A-formula C ←A ∈AF is redundant w.r.t. N, written
C ←A ∈SRedF(N), if (1) C ∈FRedF(NJ) for every propositional interpretation
J ⊇A or (2) there exists an A-formula C ←B ∈N with B ⊂A. An inference
ι ∈SInf is redundant w.r.t. N, written ι ∈SRedI(N), if (1) ι is a Base inference
and {ι}J ⊆FRedI(NJ) for every J or (2) ι is an Unsat inference and ⊥∈N.
SRed qualiﬁes as a redundancy criterion. It can justify the deletion of A-
formulas that are propositionally tautological. It also allows other simpliﬁcations,
as long as the assertions on A-formulas used to simplify a given C ←A are
contained in A. If the base criterion FRedF supports subsumption, this also
extends to A-formulas: D ←B ∈SRed F({C ←A}) if D is strictly subsumed by C
and B ⊇A, or if C = D and B ⊃A.
Local Saturation. It is not diﬃcult to show that if (FInf , FRed) is statically
complete, then (SInf , SRed) is statically and hence dynamically complete. How-
ever, this result fails to capture a key aspect of most splitting architectures.
Since ▷SRedF-derivations have no notion of current split branch or model J, they
must also perform disabled inferences. To respect enabledness, we need a weaker
notion of saturation. If an A-formula set is consistent, it should suﬃce to saturate
w.r.t. a single propositional model. In other words, if no A-formula ⊥←A ⊆J is
derivable for some model J |= N⊥, the prover should be allowed to give a verdict
of “consistent.” We will call such model-speciﬁc saturations local.
Deﬁnition 7. A set N ⊆AF is locally saturated w.r.t. SInf and SRedI if either
⊥∈N or there exists J |= N⊥such that NJ is saturated w.r.t. FInf and FRedI.
Theorem 8 (Strong static completeness). Assume (FInf , FRed) is stati-
cally complete. Given a set N ⊆AF that is locally saturated w.r.t. SInf and
SRedI and such that N |= {⊥}, we have ⊥∈N.
Example 9. Consider the A-clause set {⊥←{¬[p(x)], ¬[q(y)]}, p(x)←{[p(x)]},
q(y) ←{[q(y)]}, ¬q(a)} expressed using AVATAR conventions. It is not saturated
for resolution, because the conclusion ⊥←{[q(y)]} of resolving the last two
A-clauses is missing, but it is locally saturated with J ⊇{[p(x)], ¬[q(y)]}.
Deﬁnition 10. A sequence (Ni)i of sets of A-formulas is locally fair w.r.t. SInf
and SRedI if either ⊥∈Ni for some i or there exists J |= (N∞)⊥such that
FInf ((N∞)J) ⊆
i FRedI((Ni)J).
Theorem 11 (Strong dynamic completeness). Assume (FInf , FRed) is
statically complete. Given an ▷SRedF-derivation (Ni)i that is locally fair w.r.t.
SInf and SRedI and such that N0 |= {⊥}, we have ⊥∈Ni for some i.
In Sects. 4 to 6, we will review three transition systems of increasing complexity,
culminating with an idealized speciﬁcation of AVATAR. They will be linked by a
chain of stepwise reﬁnements, like pearls on a string. All derivations using these
will correspond to ▷SRedF-derivations, and their fairness criteria will imply local
fairness. Consequently, by Theorem 11, they will all be complete.

350
G. Ebner, J. Blanchette, and S. Tourret
4
Model-Guided Provers
AVATAR and other splitting architectures maintain a model of the propositional
clauses, which represents the split tree’s current branch. We can capture this
abstractly by reﬁning ▷SRedF-derivations to incorporate a propositional model.
The states are now pairs (J, N), where J is a propositional model and N ⊆AF.
Initial states have the form (J, N), where N ⊆F. The model-guided prover MG
is deﬁned by the following transition rules:
Derive
(J, N ⊎M) =⇒MG (J, N ⊎M′)
if M ⊆SRedF(N ⊎M′)
Switch
(J, N) =⇒MG (J′, N)
if J′ |= N⊥
StrongUnsat
(J, N) =⇒MG (J, N ∪{⊥})
if N⊥|≈{⊥}
From an =⇒MG-derivation, we obtain an ▷SRedF-derivation by simply erasing
the J components. The Derive rule can add new A-formulas and delete redundant
A-formulas. J should be a model of N⊥most of the time; when it is not, Switch
can be used to switch model or StrongUnsat to ﬁnish the refutation.
Example 12. Let us revisit Example 5. Initially, let J0 = {¬v0, ¬v1}. After the
split, we have ¬p(a), ¬q(z, z), p(x) ←{v0}, q(y, b) ←{v1}, and ⊥←{¬v0, ¬v1}.
The natural option is to switch model. We take J1 = {v0, ¬v1}. We then derive
⊥←{v0}. Since J1 ̸|= ⊥←{v0}, we switch to J2 = {¬v0, v1}, where we derive
⊥←{v1}. Finally, we detect that the propositional clauses are unsatisﬁable.
We need a fairness criterion for MG that implies local fairness of the underlying
▷SRedF-derivation. The latter requires a witness J but gives us no hint as to
where to look for one. Our solution involves a topological concept: J is a limit
point in (Ji)i if there exists a subsequence (J′
i)i of (Ji)i such that J = J′
∞= J′∞.
Example 13. Let (Ji)i be the sequence such that J2i ∩V = {v1, v3, . . . , v2i−1}
(i.e., v1, v3, . . . , v2i−1 are true and the other variables are false) and J2i+1 =
(J2i\{¬v2i})∪{v2i}. Although it is not in the sequence, the interpretation J∩V =
{v1, v3, . . .} is a limit point. The associated split tree is shown in Fig. 1. The
direct path from the root to a node Ji speciﬁes the assertions that are true in Ji.
Example 14. Let (Ji)i be such that J0 ∩V = ∅, J4i+1 ∩V = {v0} ∪{v4j+3 |
j < i}, J4i+2 ∩V = {v0, v4i+2}∪{v4j+3 | j < i}, J4i+3 ∩V = {v4j+1 | j ≤i}, and
J4i+4 ∩V = {v4j+1 | j ≤i} ∪{v4i+4}. This sequence has two limit points: J′ =
lim infi→∞J4i+1 and J′′ = lim infi→∞J4i+3. The split tree is depicted in Fig. 2.
Basic topology tells us that every sequence has a limit point. No matter how
erratically the prover switches branches, it will fully explore at least one of them.
It then suﬃces to perform the base FInf -inferences fairly in that branch:
Deﬁnition 15. An =⇒MG-derivation (Ji, Ni)i is fair if either (1) ⊥∈Ni for
some i or (2) Ji |= (Ni)⊥for inﬁnitely many indices i and there exists a limit
point J of (Ji)i such that FInf ((N∞)J) ⊆
i FRedI((Ni)J).
Fairness of an =⇒MG-derivation implies local fairness of the underlying ▷SRedF-
derivation. A well-behaved propositional solver, as in labeled splitting, always
gives rise to a single limit point J∞, which can be taken for J in Deﬁnition 15.

A Unifying Splitting Framework
351
J0
J1
v0
J2
J3
v2
J4
J5
v4
...
J
v3
v1
Fig. 1: A split tree with a
single inﬁnite branch
J0
J1
J2
v2
J5
J6
v6
...
J′
v3
v0
J3
J4
v4
J7
J8
v8
...
J′′
v5
v1
Fig. 2: A split tree with two inﬁnite
branches
By contrast, an unconstrained solver, as supported by AVATAR, can produce
multiple limit points. Then it is more challenging to ensure fairness.
Example 16. Consider the consistent set consisting of ¬p(x), p(a) ∨q(a), and
¬q(y) ∨p(f(y)) ∨q(f(y)). Splitting the second clause into p(a) and q(a) and
resolving q(a) with the third clause yields p(f(a)) ∨q(f(a)). This process can be
iterated. Now suppose that v2i and v2i+1 are associated with p(fi(a)) and q(fi(a)),
respectively. If we split every emerging p(fi(a))∨q(fi(a)) and the SAT solver always
makes v2i true ﬁrst, we end up with the situation of Example 13 and Fig. 1. For
the limit point J, all FInf -inferences are performed. Thus, the derivation is fair.
Example 17. We build a clause set from two copies of Example 16, where each
clause C from each copy i ∈{1, 2} is extended to ¬ri ∨C. We add the clause
r1 ∨r2 and split it as our ﬁrst move. From there, each branch imitates Example 16.
A SAT solver might jump back and forth, as in Example 14 and Fig. 2. Even
if A-clauses get disabled and re-enabled inﬁnitely often, we must perform all
nonredundant inferences in at least one of the two limit points (J′ or J′′).
5
Locking Provers
Next, we reﬁne the model-guided prover into a locking prover that temporarily
locks away A-formulas that are redundant locally w.r.t. some J but not globally.
means that C ←A is “locally redundant” in interpretations J ⊇B. The function
  erases the locks: L = {C | (B, C) ∈L for some B}. Initial states have the
form (J, N, ∅), where N ⊆F. The locking prover is deﬁned by these two rules:
Lift
(J, N, L) =⇒L (J′, N ′ ∪U, L \ U)
if (J, N) =⇒MG (J′, N ′) and U = {(B, C ←A) ∈L | B ̸⊆J′ and A ⊆J′}
Lock
(J, N ⊎{C ←A}, L) =⇒L (J, N, L ∪{(B, C ←A)})
if B ⊆J and C ∈FRed F(NJ′) for all J′ ⊇A ∪B
We note that =⇒L-derivations reﬁne =⇒MG-derivations, with states (J, N, L)
mapped to (J, N ∪L).
The states are triples (J, N, L), with L ⊆Pﬁn(A)×AF. Intuitively, (B, C←A)∈L

352
G. Ebner, J. Blanchette, and S. Tourret
Locking can cause incompleteness, because an A-formula can be locally
redundant at every point in the derivation and yet not be so at any limit point,
thereby breaking local saturation. For example, if we have derived p(x) ←{¬vk}
for every k, then p(c) is locally redundant in any J that contains ¬vk. For
the models Ji = {v1, . . . , vi, ¬vi+1, . . .}, the clause p(c) would always be locally
redundant and ignored. Yet p(c) might not be locally redundant at the unique
limit point J = V. We could rule out this counterexample by requiring that
derivations are strongly fair—that is, every inference possible inﬁnitely often
must eventually be made redundant. However, we have found a counterexample
showing that strong fairness does not ensure completeness [8, Example 46]. It
would seem that this counterexample could arise with Vampire if the underlying
SAT solver produces this speciﬁc sequence of interpretations.
Our solution is as follows. Let (Ji, Ni, Li)i be an =⇒L-derivation, let (J′
j)j
be a subsequence of (Ji)i, and let (N ′
j)j be the corresponding subsequence of
(Ni)i. To achieve fairness, we now consider N ′
∞, the A-formulas persistent in the
unlocked subsequence (N ′
j)j. By contrast, fairness of =⇒MG-derivations used N∞.
Deﬁnition 18. An =⇒L-derivation (Ji, Ni, Li)i is fair if either (1) ⊥∈
i Ni or
(2) Ji |= (Ni)⊥for inﬁnitely many indices i and there exists a subsequence (J′
j)j
converging to a limit point J such that FInf ((N ′
∞)J ∪((lim supj→∞L′
j)J \
L′∞)J) ⊆
i FRedI((Ni ∪Li)J), where (N ′
j)j and (L′
j)j correspond to (J′
j)j.
Fairness of an =⇒L-derivation implies fairness of the corresponding =⇒MG-
derivation. The condition on the sets L′
j ensures that inferences from A-formulas
that are locked inﬁnitely often, but not inﬁnitely often with the same lock, are
redundant at the limit point. In particular, if we know that each A-formula is
locked at most ﬁnitely often, then lim supj→∞L′
j = L′∞ and the inclusion
in the deﬁnition above simpliﬁes to FInf ((N ′
∞)J) ⊆
i FRedI((Ni ∪Li)J).
6
AVATAR-Based Provers
AVATAR was unveiled in 2014 by Voronkov [22]. Since then, he and his colleagues
studied many options and extensions [3,17]. A second implementation, in Lean’s
super tactic, is due to Ebner [9]. Here we attempt to capture AVATAR’s essence.
The abstract AVATAR-based prover we deﬁne in this section extends the
locking prover L with a given clause procedure [13]. A-formulas are moved in
turn from the passive to the active set, where inferences are performed. The
heuristic for choosing the next given A-formula to move is guided by timestamps
indicating when the A-formulas were derived, to ensure fairness.
Let TAF = AF × N be the set of timestamped A-formulas. Given N ⊆TAF,
we deﬁne N = {C | (C, t) ∈N for some t}, and we overload existing notations
to erase timestamps. Thus, ⌊N⌋= ⌊N⌋, N⊥= N⊥, and so on. Note that
we use a new set of calligraphic letters (e.g., C, N) to range over timestamped
A-formulas and A-formulas sets. Using the saturation framework [23, Sect. 3],
we lift (SInf , SRed) to a calculus (TSInf , TSRed) on TAF with the tiebreaker
order > on timestamps, so that (C, t + k) ∈TSRedF({(C, t)}) for any k > 0.

A Unifying Splitting Framework
353
where A, P, and Q are respectively the sets of active, passive, and other (disabled
or propositional) timestamped A-formulas, and L is the set of locked time-
stamped A-formulas such that (1) A⊥= P⊥= ∅, (2) A ∪P is enabled in J, and
(3) QJ ⊆{⊥}. The AVATAR-based prover AV is deﬁned as follows:
Infer
(J, A, P ⊎{C}, Q, L) =⇒AV (J, A ∪{C}, P′, Q′, L)
if TSInf (A, {C}) ⊆TSRedI(A ∪{C} ∪P′ ∪Q′), P ⊆P′,
and Q ⊆Q′
Process
(J, A, P, Q, L) =⇒AV (J, A′, P′, Q′, L)
if A ⊇A′
and (A\A′) ∪(P\P′) ∪(Q\Q′) ⊆TSRedF(A′ ∪P′ ∪Q′)
Switch
(J, A, P, Q, L) =⇒AV (J′, A′, P′ ∪U, Q′, L \ U)
if J ̸|= Q⊥, J′ |= Q⊥, A′ = {C ∈A | C is enabled in J′},
U = {(B, (C ←A, t)) ∈L | B ̸⊆J′ and A ⊆J′}, and
A ∪P ∪Q = A′ ∪P′ ∪Q′
StrongUnsat
(J, A, P, Q, L) =⇒AV (J, A, P, Q ∪{(⊥, t)}, L)
if Q⊥|≈⊥
LockA
(J, A ⊎{(C ←A, t)}, P, Q, L) =⇒AV
(J, A, P, Q, L ∪{(B, (C ←A, t))})
if B ⊆J and C ∈FRedF((A ∪P)J′) for every J′ ⊇A ∪B
There is also a LockP rule that is identical to LockA except that it starts in
the state (J, A, P ⊎{(C ←A, t)}, Q, L). An AV-derivation is well timestamped if
every A-formula introduced by a rule is assigned a unique timestamp.
Let (Ji, Ai, Pi, Qi, Li)i be an =⇒AV-derivation. It is easy to see that it reﬁnes
the =⇒L-derivation (Ji, Ai ∪Pi ∪Qi, Li)i and that the saturation invariant
TSInf (Ai) ⊆TSRedI(Ai ∪Pi ∪Qi ∪Li) holds if A0 = ∅.
In contrast with nonsplitting provers, for AV, fairness w.r.t. formulas does
not imply fairness w.r.t. inferences. A problematic scenario involves two premises
C, D of an inference ι and four transitions repeated forever, possibly with other
steps interleaved: Infer makes C active; Switch disables it; Infer makes D
active; Switch disables it. Even though C and D are selected in a strongly fair
fashion, ι is never performed. We need an even stronger fairness criterion.
Deﬁnition 19. An =⇒AV-derivation (Ji, Ai, Pi, Qi, Li)i is fair if (1) ⊥∈
i Qi
or (2) Ji |= (Qi)⊥for inﬁnitely many indices i and there exists a subsequence (J′
j)
converging to a limit point J′
∞such that (3) lim infj→∞TSInf (A′
j, P′
j) = ∅and
(4) (lim supj→∞L′
j)J \ L′∞J ⊆
i FRedF((Ai ∪Pi ∪Qi ∪Li)J).
Condition (3) ensures that all inferences involving passive A-formulas are
redundant at the limit point. It would not suﬃce to require P′
∞= ∅because
A-formulas can move back and forth between A, P, and Q, as we just saw.
Condition (4) is similar to the condition on locks in Deﬁnition 18. If the =⇒AV-
derivation is fair, the corresponding =⇒L-derivation is also fair.
Many selection strategies are combinations of basic strategies, such as choosing
the smallest formula by weight or the oldest by age. We capture such strategies
using selection orders ⋖. Intuitively, C ⋖D if the prover will always select C
A state is a tuple (J, A, P, Q, L) ∈P(A) × P(TAF)3 × P(Pﬁn(A) × TAF),

354
G. Ebner, J. Blanchette, and S. Tourret
before D if both are present. We use two selection orders: ⋖TAF, based on
timestamps, must be followed inﬁnitely often; ⋖F must be followed otherwise.
For the ﬁrst one, we can use ⋖age deﬁned so that (C, t) ⋖age (C′, t′) if t < t′.
Deﬁnition 20. Let X be a set. A selection order ⋖on X is an irreﬂexive and
transitive relation such that {y | y ̸⋗x} is ﬁnite for all x ∈X.
The intersection of two orders ⋖1 and ⋖2 corresponds to the nondeterministic
alternation between them. The prover may choose either a ⋖1-minimal or a
⋖2-minimal A-formula, at its discretion.
To ensure completeness, we must restrict the inferences that the prover may
perform; otherwise, it could derive inﬁnitely many A-formulas with diﬀerent
assertions, causing it to switch between two branches of the split tree without
making progress. Given N ⊆AF, let ⌈N⌉= {A | C ←A ∈N for some C}.
Deﬁnition 21. A function F : P(AF) →P(AF) is strongly ﬁnitary if ⌊F(N)⌋
and ⌈F(N)⌉\ ⌈N⌉are ﬁnite for any N ⊆AF such that ⌊N⌋is ﬁnite.
Intuitively, a strongly ﬁnitary function F returns ﬁnitely many base formulas
and ﬁnitely many new assertions, although it may return inﬁnitely many A-
formulas. Clearly, F(N) is ﬁnite for any ﬁnite N ⊆AF. If FInf (N) is ﬁnite for any
ﬁnite N ⊆F, then performing SInf -inferences is strongly ﬁnitary. Deterministic
Split rules, such as AVATAR’s, are also strongly ﬁnitary. We can lift a strongly
ﬁnitary F to any N ⊆TAF by taking FTAF(N) = F(N) × N. If F and G are
strongly ﬁnitary, then so is N →F(N) ∪G(N).
Simpliﬁcation rules used by the prover must be restricted even more to ensure
completeness, because they can lead to new splits and assertions. For example,
simplifying p(x ∗0) ∨p(x) to p(0) ∨p(x) transforms an unsplittable clause into
a splittable one. If simpliﬁcations were to produce inﬁnitely many such clauses,
the prover might split and switch models forever without making progress.
Deﬁnition 22. Let ≺be a well-founded relation on F, and let ⪯be its reﬂexive
closure. A function S : AF →P(AF) is a strongly ﬁnitary simpliﬁcation bound
for ≺if N →
C∈N S(C) is strongly ﬁnitary and ⌊C′⌋⪯⌊C⌋for all C′ ∈S(C).
The prover may simplify an A-formula C to C′ only if C′ ∈S(C). It may also
delete C. Strongly ﬁnitary simpliﬁcation bounds are closed under unions, allowing
the combination of simpliﬁcation techniques based on ≺. For superposition, a
natural choice for ≺is the clause order. The key property of strongly ﬁnitary
simpliﬁcation bounds is that if we saturate a ﬁnite set of A-formulas w.r.t.
simpliﬁcations, the saturation is also ﬁnite.
Example 23. Let F be the set of ﬁrst-order clauses and S(C ←A) = {C′ ←A′ |
C′ is a subclause of C and A′ ⊆A}. Then S is a strongly ﬁnitary simpliﬁcation
bound. This S covers many simpliﬁcation techniques, including elimination of
duplicate literals, deletion of resolved literals, and subsumption resolution.
Example 24. If the Knuth–Bendix order [12] is used and all weights are positive,
then S(C ←A) = {C′ ←A′ | C′ ≺C and A′ ⊆A} is a strongly ﬁnitary
simpliﬁcation bound. This can be used to cover demodulation.

A Unifying Splitting Framework
355
Equipped with the above deﬁnitions, we introduce a fairness criterion that is
more concrete and easier to apply than fairness of =⇒AV-derivations. We could
reﬁne AV further and use this criterion to show the completeness of an imperative
procedure such as Voronkov’s extended Otter loop [22, Fig. 3], thus showing that
Vampire with AVATAR is complete if locking is suﬃciently restricted.
Lemma 25. Let I be a strongly ﬁnitary function, and let S be a strongly ﬁni-
tary simpliﬁcation bound. Then a well-timestamped =⇒AV-derivation (Ji, Ai, Pi,
Qi, Li)i is fair if all of the following conditions hold:
1. ⋖TAF is a selection order on 
i Pi, and ⋖F is a selection order on F;
2. A0 = L0 = ∅and P0 ∪Q0 is ﬁnite;
3. for every Infer transition, either C is ⋖TAF-minimal in P or ⌊C⌋is ⋖F-
minimal in ⌊P⌋;
4. for every Infer transition, P′ ∪Q′ ⊆ITAF(A ∪{C});
5. for every Process transition, P′ ∪Q′ ⊆STAF(A ∪P ∪Q ∪L);
6. if Ji ̸|= (Qi)⊥, then eventually Switch or StrongUnsat occurs;
7. if Pi ̸= ∅, then eventually Infer, Switch or StrongUnsat occurs;
8. there are inﬁnitely many indices i such that either Pi = ∅or Infer chooses
a ⋖TAF-minimal C at i;
9. (lim supj→∞L′
j)J \ L′∞J ⊆
i FRedF((Ai ∪Pi ∪Qi ∪Li)J) for every
subsequence converging to a limit point.
7
Application to Other Architectures
AVATAR may be the most natural application of our framework, but it is not
the only one. Below we complete the picture by studying splitting without
backtracking, labeled splitting, and SMT with quantiﬁers.
Splitting without Backtracking. Before AVATAR, Riazanov and Voronkov
[20] had already experimented with splitting in Vampire in a lighter variant
without backtracking. They based their work on ordered resolution O with
selection [2]. Weidenbach [24, end of Sect. 4.5] independently outlined the same
technique. The basic idea is to extend the signature Σ with a countable set P
of nullary predicate symbols and to augment the base calculus with a binary
splitting rule that replaces a
-clause C ∨D with twoΣP-clauses C ∨p and D∨¬p.
Riazanov and Voronkov require that the precedence ≺makes all P-literals smaller
than the Σ-literals. Binary splitting is then a simpliﬁcation. They also extend
the selection function of the base calculus to support P-literals. Their parallel
selection function imitates as much as possible the original selection function.
The calculus OP is closely related to an instance of our framework. Let F be
the set of Σ-clauses, with the empty clause as ⊥. Let O = (FInf , FRed) be the
base calculus. We take V = P. Let LA = (SInf , SRed), whose name stands for
lightweight AVATAR, be the induced splitting calculus. Lightweight AVATAR
amounts to the splitting architecture Cruanes implemented in Zipperposition [7,
Sect. 2.5]. Binary splitting can be realized in LA as a Split-like simpliﬁcation
ΣP

356
G. Ebner, J. Blanchette, and S. Tourret
rule. The calculi OP and LA disagree slightly because OP’s order ≺can break ties
using P-literals and because LA can detect unsatisﬁability early using the Unsat
rule. Despite its slightly weaker order, LA is tighter than OP in the sense that
saturation w.r.t. OP implies saturation w.r.t. LA but not vice versa.
Labeled Splitting. Labeled splitting, as originally described by Fietzke and
Weidenbach [10] and implemented in SPASS, is a ﬁrst-order resolution-based
calculus with binary splitting that traverses the split tree in a depth-ﬁrst way,
using an elaborate backtracking mechanism inspired by CDCL [15]. It works on
states (Ψ, N), where Ψ is a stack storing the current state of the split tree and N
is a set of labeled clauses—clauses annotated with ﬁnite sets of natural numbers.
We model labeled splitting as an instance of the locking prover L based
on the splitting calculus LS = (SInf , SRed) induced by the resolution calculus
R = (FInf , FRed), where |= and |≈are as in Example 2 and V = 
i∈N{li, ri, si}.
A-clauses correspond to labeled clauses. Splits are identiﬁed by unique split levels.
Given a split on C ∨D with level k, lk ∈asn(C) and rk ∈asn(D) represent the
left and right branches. In practice, the prover would dynamically extend fml
to ensure that fml(lk) = C and fml(rk) = D.
When splitting, if we simply added ⊥←{¬lk, ¬rk}, we would always need to
consider either C ←{lk} or D ←{rk}, depending on the interpretation. However,
labeled splitting can undo splits when backtracking. Yet fairness would require us
to perform inferences with either C or D even when labeled splitting would not.
We solve this as follows. Let ⊤= ∼⊥. We introduce the variable sk ∈asn(⊤) so
that we can enable or disable the split. The StrongUnsat rule then knows that
sk is true, but we can still switch to propositional models that disable both C
and D. A-clauses are then split using the following binary variant of Split:
C ∨D ←A
SoftSplit
⊥←{¬lk, ¬rk, sk}
C ←A ∪{lk}
D ←A ∪{rk}
where C and D share no variables and k is the next split level. Unlike AVATAR,
labeled splitting keeps the premise and might split it again with another level.
To emulate the original, the locking prover based on LS must repeatedly apply
the following three steps in any order until saturation:
1. Apply Base to perform an inference from the enabled A-clauses. If an enabled
⊥←A is derived with A ⊆
i{li, ri}, apply Switch or StrongUnsat.
2. Apply Derive to simplify or delete an enabled A-clause. Use Lock if
necessary to remove the original A-clause. If an enabled ⊥←A is derived
with A ⊆
i{li, ri}, apply Switch or StrongUnsat.
3. Apply SoftSplit with split level k on an A-clause C. Then use Switch to
enable the left branch and apply Lock on C with sk as the lock.
Switch is powerful enough to support all of Fietzke and Weidenbach’s back-
tracking rules, but to explore the tree in the same order as they do, we must
choose the new model carefully. If a left branch is closed, the model must be
updated so as to disable the splits that were not used to close this branch and
to enable the right branch. If a right branch is closed, the split must be disabled,

A Unifying Splitting Framework
357
and the model must switch to the right branch of the closest enabled split above
it with an enabled left branch. If a right branch is closed but there is no split
above with an enabled left branch, the entire tree has been visited. Then, a
propositional clause ⊥←A with A ⊆
i{si} is |=-entailed by the A-clause set,
and StrongUnsat can ﬁnish the refutation by exploiting fml(si) = ⊤.
The above strategy helps achieve fairness, because it ensures that there exists
exactly one limit point. It also uses locks in a well-behaved way. This means we
can considerably simplify the notion of fairness for =⇒L-derivations and obtain a
criterion that is almost identical to, but slightly more liberal than, Fietzke and
Weidenbach’s—thereby re-proving the completeness of labeled splitting.
For terminating derivations, their fairness criterion coincides with ours. For
diverging derivations, Fietzke and Weidenbach construct a limit subsequence (Φ′
i,
N ′
i)i of the derivation (Φi, Ni)i and require that every persistent inference in
it be made redundant, exactly as we do for =⇒L-derivations. The subsequence
consists of all states that lie on the split tree’s unique inﬁnite branch. Locks are
well behaved, with lim supj→∞L′
j = L′∞, because with the strategy above,
once an A-clause is enabled on the rightmost branch, it remains enabled forever.
Our deﬁnition of fairness allows more subsequences, although this is diﬃcult to
exploit without bringing in all the theoretical complexity of AVATAR.
SMT with Quantiﬁers. Satisﬁability modulo theories (SMT) solvers based on
DPLL(T) [15] combine a SAT solver with theory solvers. In the classical setup,
the theories are decidable, and the SMT solver is a decision procedure for the
union of the theories. Some SMT solvers also support quantiﬁed formulas via
instantiation at the expense of decidability.
Complete instantiation strategies have been developed for various fragments of
ﬁrst-order logic [11,18,19]. In particular, enumerative quantiﬁer instantiation [18]
is complete under some conditions. An SMT solver following such a strategy ought
to be refutationally complete, but this has never been proved. Although SMT is
quite diﬀerent from the architectures considered above, we can instantiate our
framework to show the completeness of an abstract SMT solver. The model-guided
prover MG will provide a suitable starting point.
Let F be the set of ﬁrst-order Σ-formulas. We represent the SMT solver’s
underlying SAT solver by the Unsat rule and complement it with an inference
system FInf that includes rules for clausiﬁcation outside quantiﬁers, theory rea-
soning, and instantiation. The clausiﬁcation rules derive C and D from a premise
C ∧D, among others; the theory rules derive ⊥from some Σ-formula set N such
that N |= {⊥}, ignoring quantiﬁers; and the instantiation rules derive ϕ(u) from
premises ∀x. ϕ(x), where u is a ground term. For FRed, we take an arbitrary
instance of standard redundancy. Its only purpose is to split disjunctions destruc-
tively. We deﬁne the “theories with quantiﬁers” calculus TQ = (FInf , FRed). For
|= and |≈, we use entailment in the supported theories including quantiﬁers.
We use the same approximation function as in AVATAR (Example 3). Let us
call C ←A a subunit if C is not a disjunction. Whenever a (ground) disjunction
C ∨D←A emerges, we immediately apply Split. This delegates clausal reasoning
to the SAT solver. It then suﬃces to assume that TQ is complete for subunits.

358
G. Ebner, J. Blanchette, and S. Tourret
Theorem 26 (Dynamic completeness). Assume TQ is statically complete
for subunit sets. Let (Ji, Ni)i be a fair =⇒MG-derivation based on TQ. If N0 |= {⊥}
and N∞contains only subunits, then ⊥∈Nj for some j.
Like AVATAR-based provers, SMT solvers will typically not perform all SInf -
inferences, not even up to SRedI. Given a ≈b←{v0}, b ≈c←{v1}, a ≈d←{v2},
c ≈d ←{v3}, and a ̸≈c ←{v4}, an SMT solver will ﬁnd only one of the conﬂicts
⊥←{v0, v1, v4} or ⊥←{v2, v3, v4} but not both. For decidable theories, a practical
fair strategy is to instantiate quantiﬁers only if no other rules are applicable.
Our mathematization of AVATAR and SMT with quantiﬁers exposes their
dissimilarities. With SMT, splitting is mandatory, and there is no subsumption or
simpliﬁcation, locking, or active and passive sets. And of course, theory inferences
are n-ary and quantiﬁer instantiation is unary, whereas superposition is binary.
Nevertheless, their completeness follows from the same principles.
8
Conclusion
Our framework captures splitting calculi and provers in a general way, indepen-
dently of the base calculus. Users can conveniently derive a dynamic refutational
completeness result for a splitting prover based on a given statically refutation-
ally complete calculus. As we developed the framework, we faced some tension
between constraining the SAT solver’s behavior and the saturation prover’s.
It seemed preferable to constrain the prover, because the prover is typically
easier to modify than an oﬀ-the-shelf SAT solver. To our surprise, we discovered
counterexamples related to locking, formula selection, and simpliﬁcation, which
may aﬀect Vampire’s AVATAR implementation, depending on the SAT solver
used. We proposed some restrictions, but alternatives could be investigated.
We found that labeled splitting can be seen as a variant of AVATAR where
the SAT solver follows a strict strategy and propositional variables are not
reused across branches. A beneﬁt of the strict strategy is that locking preserves
completeness. As for the relationship between AVATAR and SMT, there are some
glaring diﬀerences, including that splitting is necessary to support disjunctions in
SMT but fully optional in AVATAR. For future work, we could try to complete
the picture by considering other related architectures [4–6,14].
Acknowledgment. Petar Vukmirović greatly helped us design the abstract notions
related to A-formulas. Giles Reger patiently explained AVATAR and revealed some of its
secrets. Simon Cruanes did the same regarding lightweight AVATAR. Simon Robillard,
Andrei Voronkov, Uwe Waldmann, Christoph Weidenbach discussed splitting with
us. Haniel Barbosa, Pascal Fontaine, Andrew Reynolds, and Cesare Tinelli explained
some ﬁne points of SMT. Natarajan Shankar pointed us to his work on the Shostak
procedure. Ahmed Bhayat, Mark Summerﬁeld, Dmitriy Traytel, Petar Vukmirović, and
the anonymous reviewers suggested textual improvements. We thank them all.
This research has received funding from the European Research Council (ERC)
under the European Union’s Horizon 2020 research and innovation program (grant
agreement No. 713999, Matryoshka). The research has also received funding from the
Nederlandse Organisatie voor Wetenschappelijk Onderzoek (NWO) under the Vidi
program (project No. 016.Vidi.189.037, Lean Forward).

A Unifying Splitting Framework
359
References
1. Bachmair, L., Ganzinger, H.: Rewrite-based equational theorem proving with
selection and simpliﬁcation. J. Log. Comput. 4(3), 217–247 (1994)
2. Bachmair, L., Ganzinger, H.: Resolution theorem proving. In: Robinson, A.,
Voronkov, A. (eds.) Handbook of Automated Reasoning, vol. I, pp. 19–99. Elsevier
(2001)
3. Bjø[r]ner, N., Reger, G., Suda, M., Voronkov, A.: AVATAR modulo theories. In:
Benzmüller, C., Sutcliﬀe, G., Rojas, R. (eds.) GCAI 2016. EPiC Series in Computing,
vol. 41, pp. 39–52. EasyChair (2016)
4. Bonacina, M.P., Graham-Lengrand, S., Shankar, N.: Satisﬁability modulo theories
and assignments. In: de Moura, L. (ed.) CADE-26. LNCS, vol. 10395, pp. 42–59.
Springer (2017)
5. Bonacina, M.P., Lynch, C., de Moura, L.: On deciding satisﬁability by DPLL(Γ+T)
and unsound theorem proving. In: Schmidt, R.A. (ed.) CADE-22. LNCS, vol. 5663,
pp. 35–50. Springer (2009)
6. Bonacina, M.P., Plaisted, D.A.: SGGS theorem proving: An exposition. In: Schulz,
S., de Moura, L., Konev, B. (eds.) PAAR-2014. EPiC Series in Computing, vol. 31,
pp. 25–38. EasyChair (2014)
7. Cruanes, S.: Extending Superposition with Integer Arithmetic, Structural Induction,
and Beyond. Ph.D. thesis, École polytechnique (2015)
8. Ebner, G., Blanchette, J., Tourret, S.: A unifying splitting framework (techni-
cal report). Technical report (2021), https://matryoshka-project.github.io/pubs/
splitting_report.pdf
9. Ebner, G., Ullrich, S., Roesch, J., Avigad, J., de Moura, L.: A metaprogramming
framework for formal veriﬁcation. Proc. ACM Program. Lang. 1(ICFP), 34:1–34:29
(2017)
10. Fietzke, A., Weidenbach, C.: Labelled splitting. Ann. Math. Artif. Intell. 55(1–2),
3–34 (2009)
11. Ge, Y., de Moura, L.: Complete instantiation for quantiﬁed formulas in satisﬁabiliby
modulo theories. In: Bouajjani, A., Maler, O. (eds.) CAV 2009. LNCS, vol. 5643,
pp. 306–320. Springer (2009)
12. Knuth, D.E., Bendix, P.B.: Simple word problems in universal algebras. In: Leech, J.
(ed.) Computational Problems in Abstract Algebra. pp. 263–297. Pergamon Press
(1970)
13. McCune, W., Wos, L.: Otter—the CADE-13 competition incarnations. J. Autom.
Reason. 18(2), 211–220 (1997)
14. de Moura, L., Jovanović, D.: A model-constructing satisﬁability calculus. In: Gia-
cobazzi, R., Berdine, J., Mastroeni, I. (eds.) VMCAI 2013. LNCS, vol. 7737, pp.
1–12. Springer (2013)
15. Nieuwenhuis, R., Oliveras, A., Tinelli, C.: Solving SAT and SAT modulo theories:
From an abstract Davis–Putnam–Logemann–Loveland procedure to DPLL(T). J.
ACM 53(6), 937–977 (2006)
16. Nipkow, T., Klein, G.: Concrete Semantics: With Isabelle/HOL. Springer (2014)
17. Reger, G., Suda, M., Voronkov, A.: Playing with AVATAR. In: Felty, A.P., Middel-
dorp, A. (eds.) CADE-25. LNCS, vol. 9195, pp. 399–415. Springer (2015)
18. Reynolds, A., Barbosa, H., Fontaine, P.: Revisiting enumerative instantiation.
In: Beyer, D., Huisman, M. (eds.) TACAS 2018. LNCS, vol. 10806, pp. 112–131.
Springer (2018)

360
G. Ebner, J. Blanchette, and S. Tourret
19. Reynolds, A., Tinelli, C., Goel, A.,
, S.: Finite model ﬁnding in SMT. In:
Sharygina, N., Veith, H. (eds.) CAV 2013. LNCS, vol. 8044, pp. 640–655. Springer
(2013)
20. Riazanov, A., Voronkov, A.: Splitting without backtracking. In: Nebel, B. (ed.)
IJCAI 2001. pp. 611–617. Morgan Kaufmann (2001)
21. Sutcliﬀe, G.: The TPTP problem library and associated infrastructure—from CNF
to TH0, TPTP v6.4.0. J. Autom. Reason. 59(4), 483–502 (2017)
22. Voronkov, A.: AVATAR: The architecture for ﬁrst-order theorem provers. In: Biere,
A., Bloem, R. (eds.) CAV 2014. LNCS, vol. 8559, pp. 696–710. Springer (2014)
23. Waldmann, U., Tourret, S., Robillard, S., Blanchette, J.: A comprehensive framework
for saturation theorem proving. In: Peltier, N., Sofronie-Stokkermans, V. (eds.)
IJCAR 2020, Part I. LNCS, vol. 12166, pp. 316–334. Springer (2020)
24. Weidenbach, C.: Combining superposition, sorts and splitting. In: Robinson, A.,
Voronkov, A. (eds.) Handbook of Automated Reasoning, vol. II, pp. 1965–2013.
Elsevier and MIT Press (2001)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium or
format, as long as you give appropriate credit to the original author(s) and the source,
provide a link to the Creative Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.
Krstić

Integer Induction in Saturation
Petra Hozzov´a1
, Laura Kov´acs1
, and Andrei Voronkov2,3
1 TU Wien, Vienna, Austria
{petra.hozzova, laura.kovacs}@tuwien.ac.at, andrei@voronkov.com
2 University of Manchester, Manchester, UK
3 EasyChair, Manchester, UK
Abstract. Integers are ubiquitous in programming and therefore also in
applications of program analysis and veriﬁcation. Such applications often
require some sort of inductive reasoning. In this paper we analyze the
challenge of automating inductive reasoning with integers. We introduce
inference rules for integer induction within the saturation framework of
ﬁrst-order theorem proving. We implemented these rules in the theorem
prover Vampire and evaluated our work against other state-of-the-art
theorem provers. Our results demonstrate the strength of our approach
by solving new problems coming from program analysis and mathemat-
ical properties of integers.
1
Introduction
One of the most commonly used data types in imperative/functional programs
are integers. For example, iterating over arrays in imperative programs or recur-
sively computing sums in functional programs include integer-valued program
variables, as illustrated in Figure 1. While for many uses of integers in program-
ming we only need to consider non-negative integers, there are also applications
where integers are essential, for example, reasoning about memory. To formally
prove functional correctness of such and similar programs, reasoning about in-
tegers is indispensable but so is handling some sort of induction over integers.
In this paper we address these two reasoning challenges and fully automate in-
ductive reasoning with integers within saturation-based theorem proving.
Induction in saturation-based theorem proving is a new exciting direction
in the automation of induction, recently introduced in [5, 10, 16]. This work
focused on induction on inductively deﬁned data types, also called algebraic
data types [12], such as natural numbers or lists. However, automating integer
induction, that is, induction on integers, has not yet been addressed suﬃciently.
While natural numbers have a well-founded order and induction over this
order is very useful in automated inductive theorem proving, the standard order
on integers is not well-founded, so it cannot be directly used as the induction
ordering. In this paper we will use the observation that the standard ordering
< is well-founded on every set of integers having a lower bound b and likewise,
the inverse > of this ordering is well-founded on every set of integers having an
upper bound b. This gives us two induction rules on such integer subsets: induc-
tion (with the base case b) using < and induction (with the base case b) using >,
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5_21
361–377, 2021.

362
P. Hozzov´a, L. Kov´acs and A. Voronkov
respectively, to prove that a property holds for all integers ≥b and, respectively,
≤b. We deﬁne these induction rules as upward, respectively, downward induc-
tion rules with symbolic bounds. We also consider two variations of these rules
over integer intervals and refer to such rules as interval upward, respectively,
downward induction rules with symbolic bounds.
For natural numbers, 0 is an obvious base case candidate, which also turns
out to be successful in the theorem proving practice. It is also a natural base case
candidate for induction. In this paper we will give some natural problems for
which neither 0 nor any concrete integer is a good base case. Our paper focuses
on the following three issues:
1. proofs of properties of integers by induction on bounded sets of integers in
saturation theorem proving, using (interval) downward/upward induction
rules with symbolic bounds;
2. techniques for discovering a suitable base case;
3. implementation techniques.
This paper is organized as follows. In Section 2 we illustrate our approach
by considering properties of the functional and imperative programs of Figure 1.
Then in Section 3 we deﬁne four induction rules over integers, called (interval)
downward, respectively upward, induction rules with symbolic bounds, and prove
their soundness. Section 4 introduces an extension of superposition calculus by
our new integer induction rules. We demonstrate that, using this extension, su-
perposition provers can prove integer properties similarly to how humans would
do. This extension is especially successful when used together with the AVATAR
architecture [19], since AVATAR helps in reasoning eﬃciently using constraints
coming out of the integer induction rules.
We implemented our work in the Vampire theorem prover [13] and compare
our implementation with other relevant provers, including Vampire without in-
teger induction (Section 5). Our experiments show that integer induction can
solve many new problems that could not so far be solved by any prover. For ex-
ample, 75 problems coming from program analysis and/or mathematical integer
properties could be solved only by Vampire with the new induction rules.
Contributions. This paper makes the following contributions:
• We introduce four new inference rules for automating integer induction: (in-
terval) downward, respectively upward, induction rules with symbolic bounds
(Section 3).
• Based on these rules, we introduce corresponding inference rules for integer
induction in the superposition calculus (Section 4). These rules are formu-
lated in the context of saturation-based theorem proving in a way that avoids
an immediate combinatorial explosion of the search space.
• We implement and evaluate the new rules in the theorem prover Vampire.
Our experimental results show that our implementation can solve a number
of problems previously unsolved by any prover (Section 5).
• We introduce a large collection of new inductive benchmarks, publicly avail-
able at https://github.com/vprover/inductive_benchmarks.

Integer Induction in Saturation
363
fun sum(n, m) =
if n = m then n
else n + sum(n + 1, m);
assert
∀n, m ∈Z.(n ≤m →
2 · sum(n, m) =
m · (m + 1) −n · (n −1))
(a) Sum of integers
from [n, m].
assume 0 ≤pos < A.size
i := pos;
while i + 1 < A.size do
A[i + 1] := A[i];
i := i + 1;
inv ∀j ∈Z.(pos ≤j < i →valA(j + 1) = valA(j))
end
assert
∀j ∈Z.(pos ≤j < A.size →valA(j) = valA(pos))
(b) Array initialization, with valA(j) denoting A[j].
Fig. 1. Motivating examples for inductive reasoning with integers.
2
Motivating Examples
2.1
Preliminaries
We assume familiarity with standard many-sorted ﬁrst-order logic with equal-
ity. For details we refer to [13]. Throughout this paper we denote variables by
x, y, e, j, n, m, constants by c, c′, Skolem constants by σ, all possibly with indices.
We denote terms by t, literals by L, formulas by F and clauses by C. We denote
the equality predicate by = and write t1 ̸= t2 for the literal ¬(t1 = t2).
We will focus on integer induction. To this end, we assume a distinguished
integer sort, denoted by Z. When we use standard integer predicates <, ≤, >,
≥, functions +, −, . . . and constants 0, 1, 2, . . . , we assume that they denote the
corresponding interpreted integer predicates and functions with their standard
interpretations. All other symbols are uninterpreted. We will write quantiﬁers
like ∀x ∈Z to denote that x has the integer sort.
In what follows, we will sometimes write “this problem requires integer in-
duction”. This should not be regarded as a formal statement: this property is
not easy to formalize in general and it is possible that some of these problems
can be proved by certain combinations of decision procedures, ﬁrst-order the-
orem proving with uninterpreted functions, and axiomatization of interpreted
functions on integers. However, when we make such statements, one can see that
these problems have relatively simple proofs involving induction and cannot be
proved by existing provers without induction.
2.2
Examples
To illustrate problems arising in automating integer induction, let us consider
the programs of Figure 1. Properties of both programs are speciﬁed using as-
sertions expressed in ﬁrst-order logic, with pre- and post-conditions speciﬁed by
the keywords assume and assert, respectively.

364
P. Hozzov´a, L. Kov´acs and A. Voronkov
Functional programs. The ML-style functional program of Figure 1(a) computes
the sum sum(n, m) of integers in the interval [n, m], that is m
i=n i, where m ≥n.
The function deﬁnition uses the following axioms of sum:
∀n ∈Z.(sum(n, n) = n);
(1)
∀n, m ∈Z.(n ̸= m →sum(n, m) = n + sum(n + 1, m)).
(2)
We should prove the assertion
∀n, m ∈Z.(n ≤m →2 · sum(n, m) = m · (m + 1) −n · (n −1)).
(3)
Formally proving (3) requires inductive reasoning with both integers and quan-
tiﬁers. Let F[x] be a formula with one or more occurrences of an integer variable
x and b an integer term not containing x. Consider the following formula:
F[b] ∧∀x ∈Z.(x ≤b ∧F[x] →F[x −1]) →∀x ∈Z.(x ≤b →F[x]).
(4)
This formula is valid. It is similar to the standard induction on natural numbers,
yet with two essential diﬀerences. First, we use x−1 instead of x+1 and second,
we use the term b where for the standard induction we would use 0. Note that b
does not have to be a concrete integer, it can be any term. In the sequel we will
refer to such terms b used in induction rules as symbolic bounds.
For proving (3) using a theorem prover, we ﬁrst negate and skolemize (3),
obtaining the following formula, where σn, σm are fresh skolem constants:
σn ≤σm ∧2 · sum(σn, σm) ̸= σm · (σm + 1) −σn · (σn −1)
(5)
Modern theorem provers implementing linear integer arithmetic and quantiﬁers
can prove unsatisﬁability of (1), (2) and (5) in a relatively straightforward way
if we also add an instance of induction rule (4) with
F[x]
def
= 2 · sum(x, σm) = σm · (σm + 1) −x · (x −1);
b
def
= σm.
Here and in the sequel
def
= means “equal by deﬁnition” or “deﬁned as”. If we
want to automate this kind of reasoning, the main question is ﬁnding the cor-
responding instance of induction rule (4), that is, ﬁnding the induction formula
F[x] and the (symbolic) bound b.
Imperative programs. The C-style imperative program of Figure 1(b) initializes
an integer-valued array A starting at the index pos. We should prove the asser-
tion stating that all array elements at indices greater than or equal to pos are
equal to each other. Proving such assertions typically requires loop invariants
“summarizing” the loop behavior. One such invariant I is shown in the loop
after the keyword inv. This invariant I could be derived by existing approaches
to invariant generation [8,9].

Integer Induction in Saturation
365
The assertion of Figure 1(b) is then proved using I, by establishing that the
post-condition
∀j ∈Z.(pos ≤j < A.size →valA(j) = valA(pos))
(6)
is a logical consequence of the invariant I and the negation of the loop condition:
∀j ∈Z.(pos ≤j < i →valA(j + 1) = valA(j));
¬(i + 1 < A.size).
(7)
Interestingly, modern theorem provers cannot perform such proofs. Similar to
the ﬁrst example, we can use an induction rule for integers formulated as follows:

F[b1] ∧∀x ∈Z.(b1 ≤x < b2 ∧F[x] →F[x + 1])

→∀x ∈Z.(b1 ≤x ≤b2 →F[x]).
(8)
If we add an instance of this rule deﬁned as follows:
F[x]
def
= valA(x) = valA(pos);
b1
def
= pos;
b2
def
= A.size −1,
then state-of-the-art theorem provers can easily prove that (6) is a logical con-
sequence of (7) and the corresponding instance of (8). For example, Cvc4 [1],
Z3 [6] and Vampire prove such an instance in essentially no time. However, sim-
ilarly to the example of Figure 1(a), in order to ﬁnd such proofs automatically
using the induction rule of (8), we need to be able to discover, during the proof
search, the induction formula F[x] and the symbolic bounds b1, b2. In what fol-
lows, we describe our solution to automating this discovery by integrating integer
induction within saturation-based theorem proving.
3
Integer Induction
In this section we deﬁne four induction rules, or induction schemas, on integers.
Two of them were already considered in Section 2 – namely (4) and (8).
Deﬁnition 1 (Downward/Upward Induction). A downward, respectively
upward, induction axiom with symbolic bounds is any formula of the form
F[b] ∧∀x.(x ≤b ∧F[x] →F[x −1]) →∀x.(x ≤b →F[x]);
(downward)
F[b] ∧∀x.(x ≥b ∧F[x] →F[x + 1]) →∀x.(x ≥b →F[x]),
(upward)
respectively, where F[x] is a formula with one or more occurrences of an integer
variable x and b is an integer term not containing x.
⊓⊔
Note that (4) is a downward induction axiom with symbolic bounds.

366
P. Hozzov´a, L. Kov´acs and A. Voronkov
Deﬁnition 2 (Interval Downward/Upward Induction). An interval down-
ward, respectively upward, induction axiom with symbolic bounds is any formula
of the form
F[b2] ∧∀x.(b1 < x ≤b2 ∧F[x] →F[x −1]) →∀x.(b1 ≤x ≤b2 →F[x]); (down.)
F[b1] ∧∀x.(b1 ≤x < b2 ∧F[x] →F[x + 1]) →∀x.(b1 ≤x ≤b2 →F[x]),
(up.)
respectively, where F[x] is a formula with one or more occurrences of an integer
variable x and b1, b2 are integer terms not containing x.
⊓⊔
Note that (8) is an interval upward induction axiom with symbolic bounds.
The main motivation for interval induction rules is their utility in reasoning
about loops, as illustrated by the example of Figure 1(a). While interval induc-
tion can be captured by induction with one bound, it would require additional
case analysis, which is not eﬃcient in saturation-based proving practice.
In the sequel, we will refer to the integer terms of b, b1, b2 from Deﬁnitions 1-2
as symbolic bounds and the formulas F[x] from the induction axioms of Deﬁni-
tions 1-2 as induction formulas.
Deﬁnition 3 (Downward/Upward Induction Rules). The downward (re-
spectively, upward) induction rule with symbolic bounds, or simply downward
(respectively, upward) induction rule is the inference rule whose instances are all
downward (respectively, upward) induction axioms with symbolic bounds.
Likewise, the interval downward (respectively, upward) induction rule with
symbolic bounds, or simply interval downward (respectively, upward) induction
rule is the inference rule whose instances are all interval downward (respectively,
upward) induction axioms with symbolic bounds.
⊓⊔
It is easy to see that the following theorem holds.
Theorem 1 (Soundness). The (interval) downward/upward induction rules
of Deﬁnition 3 are sound, that is, all corresponding induction axioms from Def-
initions 1-2 are valid.
⊓⊔
4
Integer Induction in Saturation-Based Proof Search
Our next aim is to deﬁne analogues of the induction rules introduced in Sec-
tion 3 that can be used in superposition theorem provers and their saturation
algorithms. For a general discussion of superposition and saturation we refer
to [13]. In this section we use □to denote the empty clause and write CNF(F)
to mean (any) clausal normal form of a formula F. We refer to the set of clauses
on which a saturation algorithm operates as the search space.
The most general way to introduce our new induction rules at the calculus
level is to add clausal forms of our new induction axioms to the search space.
That is, for every induction axiom F from Section 3, we add the rule
CNF(F)
.

Integer Induction in Saturation
367
However, we cannot eﬃciently implement such a calculus, as any formula with
one variable can be used as an induction formula. We will therefore introduce
diﬀerent, more specialized, rules, which still correspond to the previously deﬁned
induction rules. The new rules use variations of the following three ideas:
1. Use only simple induction formulas, for example literals;
2. To ﬁnd an induction formula, generalize a subgoal occurring in the search
space. Then the derived induction formula can be immediately used to prove
this subgoal;
3. Use (symbolic) bounds that correspond to bounds already occurring in the
search space.
The ﬁrst two ideas were already used in the ﬁrst papers underlying our approach
to induction in saturation theorem proving [10, 16]. For example, they can be
implemented by using only induction formulas that are obtained from ground
literals L[t] in the search space, where t is a ground term. The corresponding
induction formula will be ¬L[x]. The idea is that, when we prove the induction
formula, ¬L[x] will be resolved against L[t].
The third idea is new. Note that, if we use the ﬁrst two ideas and the upward
induction rule, instead of ¬L[x] we will derive b ≤x →¬L[x]. When we resolve
this against L[t], we obtain the clause ¬(b ≤t). However, if we already previously
derived b ≤t, we can also resolve away ¬(b ≤t). This gives us the idea to only
apply the upward induction rules when we have b ≤t.4
Based on the three ideas above, we introduce the following four induction
rules on clauses. In these rules t is a ground term, b is a constant and L[x] is a
literal containing at least one occurrence of a variable x and no other variables.
The rules depend on which comparisons among t ≥b, t > b, t ≤b and t < b
already occur in the current search space:
¬L[t] ∨C
t ≥b
CNF

L[b] ∧∀x.(x ≥b ∧L[x] →L[x + 1])

→∀y.(y ≥b →L[y])
 (IntInd≥)
¬L[t] ∨C
t > b
CNF

L[b] ∧∀x.(x ≥b ∧L[x] →L[x + 1])

→∀y.(y > b →L[y])
 (IntInd>)
¬L[t] ∨C
t ≤b
CNF

L[b] ∧∀x.(x ≤b ∧L[x] →L[x −1])

→∀y.(y ≤b →L[y])
 (IntInd≤)
¬L[t] ∨C
t < b
CNF

L[b] ∧∀x.(x ≤b ∧L[x] →L[x −1])

→∀y.(y < b →L[y])
 (IntInd<)
Note that IntInd≥and IntInd> are upward induction rules, whereas
IntInd≤and IntInd< are downward induction rules. One can also introduce
non-ground analogues of these rules but we do not consider them in this paper.
4 Using the AVATAR architecture [19], we can easily obtain valid literals b ≤t.

368
P. Hozzov´a, L. Kov´acs and A. Voronkov
Similarly to the above rules on the clausal level, we also introduce the interval
upward/downward induction rules on clauses to be used in saturation algorithms
for the superposition calculus. Since these rules are similar to each other, here
we only deﬁne one rule IntInd[≥] for interval upward induction. For a ground
term t, constants b1, b2, and L[x] a literal containing at least one occurrence of a
variable x and no other variables, an interval upward induction rule on clauses:
¬L[t] ∨C
t ≥b1
t ≤b2
CNF

L[b1] ∧∀x.(b1 ≤x < b2 ∧L[x] →L[x + 1])

→∀y.(b1 ≤y ≤b2 →L[y])

(IntInd[≥])
In view of Theorem 1, all induction rules of Section 3 are sound. Assuming
that our CNF function preserves satisﬁability, we conclude that all our induction
rules IntInd≥, IntInd>, IntInd≤, IntInd< and IntInd[≥] on the clausal level
are sound.
Theorem 2 (Soundness). For every satisﬁability preserving CNF function,
the induction rules from Deﬁnition 3 are sound.
⊓⊔
Example 1. To illustrate again how the choice of induction formulas allows us
to have shorter clauses, consider IntInd≤. The CNF in its conclusion consists
of three clauses:
¬L[b] ∨σ ≤b ∨¬y ≤b ∨L[y]
¬L[b] ∨L[σ] ∨¬y ≤b ∨L[y]
¬L[b] ∨¬L[σ −1] ∨¬y ≤b ∨L[y]
(9)
These clauses can be resolved against premises of IntInd≤, yielding the fol-
lowing clauses:
¬L[b] ∨σ ≤b ∨C
¬L[b] ∨L[σ] ∨C
¬L[b] ∨¬L[σ −1] ∨C
(10)
They have an especially simple form when C is the empty clause □. In this case
we have three clauses:
¬L[b] ∨σ ≤b
¬L[b] ∨L[σ]
¬L[b] ∨¬L[σ −1]
(11)
which subsume the original three longer clauses and are ground. Since they are
ground, they can be handled eﬃciently by AVATAR.
⊓⊔
Example 2. Let us now demonstrate how the downward induction rule IntInd≤
works for refuting the inductive property (3) from our motivating example of
Figure 1(a). We use literals from (5) as the premises of the IntInd≤rule. The
corresponding instance of the downward induction rule is deﬁned by
b
def
= σm;
t
def
= σn;
L[x]
def
= 2 · sum(x, σm) = σm · (σm + 1) −x · (x −1).

Integer Induction in Saturation
369
This instance of IntInd≤is:
2 · sum(σn, σm) ̸= σm · (σm + 1) −σn · (σn −1)
σn ≤σm
CNF

2 · sum(σm, σm) = σm · (σm + 1) −σm · (σm −1)
∧∀x.(x ≤σm →2 · sum(x, σm) = σm · (σm + 1) −x · (x −1)
→2 · sum(x −1, σm) = σm · (σm + 1) −(x −1) · ((x −1) −1))

→∀y.(y ≤σm →2 · sum(y, σm) = σm · (σm + 1) −y · (y −1))

(IntInd≤)
This single instance of the induction rule does the magic. By adding its
conclusion to the search space we can obtain a contradiction in a few steps by
applying a few superposition rules and using ground reasoning in linear integer
arithmetic with uninterpreted functions (as evidenced by the results for the ﬁrst
problem subset, x all of sum, in Table 3).
We ﬁnally note that functional correctness of Figure 1(b) is proved by the
interval upward induction rule IntInd[≥], in a similar way as above (and as
evidenced by the results of Table 3 for declared unint ax-ﬁn conj-ﬁn in val).
⊓⊔
What we ﬁnd especially interesting in Example 2 is that the induction axiom
used in it (and discovered by our implementation of induction in Vampire) uses
the induction argument that would probably be used by a majority of humans
who would try to argue why the program property holds.
5
Implementation and Experiments
5.1
Implementation
We implemented our integer induction rules IntInd≥, IntInd>, IntInd≤,
IntInd< as well as IntInd[≥] and the other corresponding interval induc-
tion rules in Vampire. Further, we also implemented a more general induc-
tion rule IntInd that does not require bounds to be in the search space
and uses 0 as the lower or the upper bound. Our implementation in Vam-
pire, consisting of approximately 1,200 lines of new C++ code, is available at
https://github.com/vprover/vampire. The size of this additional code is rel-
atively small because Vampire has libraries for indexing and chaining inference
rules that could be used oﬀthe shelf.
Our (interval) downward/upward induction rules described in Section 4 can
be applied when either (i) the comparison literal (e.g., t ≥b for the IntInd≥
rule) is selected and the corresponding clause ¬L[t] ∨C was already selected as
an induction candidate before, or (ii) if ¬L[t] ∨C is selected as an induction
candidate and the corresponding comparison literal was already selected before.
To implement these rules eﬃciently, we should be able to eﬃciently retrieve
comparison literals and literals selected for induction. To do so, we extended
the indexing mechanism of Vampire to index such literals. We do not apply
induction when the induction formula L[x] is a comparison having x as a top
level argument, for example, x ≤t, and allow to apply it to all other induction
formulas deemed to be suitable by other user-speciﬁed options.

370
P. Hozzov´a, L. Kov´acs and A. Voronkov
assume e ≥1
fun power(x, 1) = x
| power(x, e) = x · power(x, e −1);
assert ∀x, y ∈Z.(power(x · y, e) = power(x, e) · power(y, e))
Fig. 2. ML-like functional program computing integer powers for positive exponents.
Our (interval) downward/upward induction rules in Vampire are enabled
by the new option --induction int. The options --int induction interval
infinite and --int induction interval finite limit the enabled rules to
downward/upward only, and interval downward/upward only, respectively. Fur-
ther, --int induction default bound on enables the more general rule which
does not require bounds to be in the search space. Our new induction rules
can also be controlled by other Vampire options for well-founded/structural
induction, such as --induction on complex terms on, which enables apply-
ing induction on any ground complex term. To improve Vampire’s per-
formance for integer induction, we combined our new induction rules with
--induction on complex terms on and also other options not speciﬁc for in-
duction. We extended Vampire with a new mode scheduling various op-
tion conﬁgurations for integer induction, switched on by the option --mode
portfolio --schedule integer induction. Additionally, we introduced the
option --schedule induction which uses either the integer induction conﬁgu-
rations as for --schedule integer induction, or structural induction conﬁg-
urations, or both, depending on the data types used in the problem/property to
be proved.
5.2
Benchmarks
We used two sets of examples: (i) benchmark sets LIA and UFLIA from the
SMT-LIB collection [2], consisting of, respectively, 607 and 10,137 examples,
and (ii) 120 new benchmarks similar to our motivating examples from Section 2.
To the best of our knowledge, the state-of-the-art systems implementing in-
ductive reasoning have so far not yet considered inductive reasoning over integers,
with two exceptions: [17], which mainly focuses on induction over inductively
deﬁned data types but mentions induction on non-negative integers and [11],
which supports inductive reasoning using recursive function deﬁnitions without
any special treatment for integers.
Since integer induction has not yet attracted enough attention in theorem
proving, there is no signiﬁcant collection of benchmarks for integer induction. To
properly carry out experiments, we therefore created a set of 120 new benchmarks
based on variations of our motivating examples from Section 2 and on properties
of computing integer powers. One example is the function correctness of the

Integer Induction in Saturation
371
Set
Variant tag
Description
sum
x / y
sum(x, y) for x > y deﬁned as x+sum(x+1, y) or y+sum(x, y−1)
all / geq / leq the conjecture holds for all x, y where x ≤y, or only for x ≤y =
c, or only for c = x ≤y; where c ∈Z is an interpreted constant
val
declared /
deﬁned
val was either not deﬁned, only declared and axiomatized (as
in (6)), or deﬁned as a total computable function (as in (14))
inter / unint
/ mixed
the axiom and conjecture use concrete interpreted constants, or
uninterpreted constants, or a mix of both
ax-ﬁn/ax-all/
ax-leq/ax-geq
the axiom holds for integers in an interval [c, c′), or for all x ∈Z,
or only for x ≤c, or only for x ≥c; where c, c′ ∈Z are constants
conj-ﬁn/conj-
all/conj-leq
/conj-geq
the conjecture holds for integers in an interval [c, c′], or for all
integers, or only for integers ≤c, or only for integers ≥c; where
c, c′ ∈Z are constants
power
0 / 1
power deﬁned starting with power(x, 0) = 1 or power(x, 1) = x
all / pos / neg the conjecture holds either for all x, y, or only for x, y ≥0, or
only for x, y ≤0
Table 1. Description of our benchmark set of 120 new examples.
program of Figure 2, which is formalized as follows:
axioms:
∀x ∈Z.(power(x, 1) = x)
∀x, e ∈Z.(2 ≤e →power(x, e) = x · power(x, e −1))
conjecture:
∀x, y, e.(1 ≤e →power(x · y, e) = power(x, e) · power(y, e))
(12)
Our set of 120 new benchmarks is described in Table 1 and available online at:
https://github.com/vprover/inductive_benchmarks
To conﬁrm that our new benchmarks require the use of inductive reasoning,
we tested them on the SMT solver Z3 [6] that does not support induction.
Z3 could not solve any of the 120 problems from our benchmark set. Names of
subsets of our new benchmarks are constructed by joining variant tags described
in Table 1. For example, problem (6) belongs to the category declared unint ax-
ﬁn conj-ﬁn of the set val. The following benchmark:
axiom:
∀x ∈Z.(val(x) = val(x + 1))
conjecture:
∀x, y ∈Z.(val(x) = val(y))
(13)
belongs to declared unint ax-all conj-all of val and the below example is from
deﬁned inter ax-geq conj-geq of val:
axioms:
∀x ∈Z.(x ≤0 →val(x) = 0)
∀x ∈Z.(0 < x →val(x) = val(x −1))
conjecture:
∀x ∈Z.(0 ≤x →val(x) = val(0))
(14)
While 9 of the benchmarks (all in val) use ﬁnite intervals in both the asser-
tion and the invariant (ax-ﬁn conj-ﬁn), the remaining 111 benchmarks require
inductive reasoning over inﬁnite intervals.

372
P. Hozzov´a, L. Kov´acs and A. Voronkov
Problem
set
Total
count
Cvc4
Z3
Vampire Vampire-I new compared
to Vampire
new compared
to Vampire,
Cvc4 and Z3
LIA
607
553
435
216
214
10
1
UFLIA
10137
7002
6705
6116
5796
99
44
Table 2. Comparison of solvers on SMT-LIB benchmarks.
5.3
Experimental Setup
We ran our experiments on computers with 32 cores (AMD Epyc 7502, 2.5
GHz) and 1 TB RAM. In all experiments we used the memory limit of 16 GB
per problem. For the new benchmarks we used a 300 seconds time limit. For the
experiments on the larger LIA and UFLIA sets we used a 10 seconds time limit.
In what follows, Vampire refers to the (default) version of Vampire, as
in [10,16]. By Vampire-I we denote our new version of Vampire, using integer
induction rules (--induction int). Vampire-I* refers to the portfolio mode
of Vampire-I, scheduling various option conﬁgurations for integer induction
(--mode portfolio --schedule induction).
For experiments with the new benchmarks, we note that Vampire with-
out integer induction cannot solve any of the problems. In this set of
experiments, we therefore compared Vampire-I to the provers Cvc4 [17]
and Acl2 [11], which are, to the best of our knowledge, the only two
automated
solvers
supporting
inductive
reasoning
with
integers
in
ad-
dition to
reasoning with
theories and
quantiﬁers.
For
Cvc4,
we
used
the ig conﬁguration from [17]: --quant-ind --quant-cf --conjecture-gen
--conjecture-gen-per-round=3 --full-saturate-quant. For Acl2, we used
its default conﬁguration and translated our new problem set into the functional
program encoding syntax of Acl2. In the experiments with the LIA and UFLIA
benchmark sets of SMT-LIB, we also used Z3 [6] in the default conﬁguration.
We ran Cvc4, Z3, Vampire and Vampire-I on problems encoded in the
SMT-LIB2 syntax [2]. For running Acl2 on the new benchmarks, we translated
problems into the functional program encoding syntax of Acl2.
5.4
Experimental Results
SMT-LIB Benchmarks. First, we evaluated the improvements of integer induc-
tion in Vampire-I when compared to Vampire, Cvc4 and Z3 on the LIA and
UFLIA sets of SMT-LIB [2]. We aimed to verify that Vampire-I’s performance
does not deteriorate due to adding integer induction, check whether Vampire-I
can solve problems that could not be solved automatically before, and to identify
the best values for options related to integer induction. To this end, we picked
ﬁve diﬀerent strategies (e.g. using diﬀerent saturation algorithms and selection
functions) and used diﬀerent combinations of induction options. Table 2 sum-
marizes our results, showcasing that integer induction enabled Vampire-I to

Integer Induction in Saturation
373
Problem set
Problem subset
Count
Acl2
Cvc4
Vampire-I*
sum
x all
1
0
0
1
y all
1
0
0
1
x leq
5
0
0
4
y geq
5
0
5
5
subset total
12
0
5
11
val
declared mixed ax-ﬁn conj-ﬁn
6
0
1
4
declared unint ax-ﬁn conj-ﬁn
3
0
0
3
declared inter ax-all conj-all
5
0
0
3
declared inter ax-all conj-geq
9
0
9
9
declared inter ax-all conj-leq
9
0
0
9
declared inter ax-geq conj-geq
13
0
13
10
declared inter ax-leq conj-leq
13
0
0
11
declared unint ax-all *
7
0
0
7
declared unint ax-geq conj-geq
2
0
0
2
declared unint ax-leq conj-leq
2
0
0
2
deﬁned inter ax-all conj-all
3
1
0
3
deﬁned inter ax-geq conj-geq
3
2
3
3
deﬁned inter ax-leq conj-leq
3
2
0
3
deﬁned unint *
6
0
0
6
subset total
84
5
26
75
power
0 all
4
0
0
4
0 pos
4
0
0
4
0 neg
4
0
0
4
1 all
4
0
0
2
1 pos
4
0
0
4
1 neg
4
0
0
2
subset total
24
0
0
20
all sets
combined total
120
5
31
106
all sets
uniquely solved
-
0
3
75
Table 3. Experiments with our new benchmarks from Table 1.
solve over 100 new problems that Vampire could not solve before (last but one
column of Table 2). Moreover, 45 of these problems were also new compared to
Cvc4 and Z3 (last column of Table 2), which most likely means that no theorem
prover was able to prove them before.
In problems solved using integer induction, the integer induction rules were
applied often: at least one of the interval induction rules was used in nearly
99% of problems, while one of the induction rules with one bound was used in
nearly all problems. The interval induction and induction rules were used on
average 4559 and 1191 times, respectively. 89% of the proofs employed interval
induction (67% upward, 29% downward), while 27% of the proofs used induction
with one bound (22% upward, 8% downward). Additionally, over 64% of proofs
only required one application of any induction rule.

374
P. Hozzov´a, L. Kov´acs and A. Voronkov
Experiments with 120 New Benchmarks. Comparison results for Vampire-I,
Acl2 and Cvc4 on our new benchmarks are displayed in Table 3, aggregated
by benchmark subsets, as described in Table 1. We do not show Vampire in the
table, since without integer induction it cannot solve any of the problems.
The results show that in some cases Acl2 can perform upward and downward
induction on integers, but only when using interpreted constants as a base case
(that is, it cannot handle symbolic bounds). However, it can only do so if it also
proves termination of the recursively deﬁned function. It also has issues with
reasoning about multiplication.
Cvc4 has limited support for integer induction: it can apply upward induc-
tion but only when the base case is an interpreted constant. Since some problems
seem to require induction with symbolic bounds, Cvc4 is mostly able to either
solve all problems in a subset, or none of them. The only exception is the subset
declared mixed ax-ﬁn conj-ﬁn, in which Cvc4 solves one problem, which can be
solved using upward induction with an interpreted constant as the base case.
Vampire-I* does not have any conceptual problems with solving the bench-
marks. However, since it uses axioms and inference rules rather than dedicated
decision procedures for handling integers, it sometime has issues with solving
problems with large integer values. For example, for the inﬁnite interval subset
of the val benchmark set, the only problems Vampire-I* did not solve were those
containing the interpreted constant 100 or -100. Similarly, in the power bench-
mark set, the unsolved problems contained large numbers. Finally, in the de-
clared mixed ax-ﬁn conj-ﬁn subset, the two problems Vampire-I* did not solve
also required more sophisticated arithmetic reasoning. However, inability of ef-
ﬁciently dealing with large numbers is not an intrinsic problem of superposition
theorem provers. Reasoning with quantiﬁers and theories is still in its infancy
and major improvements are underway. For example, there are recent parallel
developments in superposition and linear arithmetic [15] that should improve
this kind of reasoning in Vampire.
6
Related Work
Previous works on automating induction mainly focused on inductive reason-
ing for inductively deﬁned data types, for example in inductive theorem provers
Acl2 [11], IsaPlanner [7], HipSpec [4], Zeno [18] and Imandra [14]; superposi-
tion theorem provers Zipperposition [5] and Vampire [16]; and the SMT solver
Cvc4 [17]. While most of these solvers support reasoning with integers, only
Acl2 and Cvc4 implement some form of induction over integers.
The Acl2 approach [11] generates induction schemas based on recursive
function calls in the property to be proved. Hence, it can only use induction to
solve problems properties of recursively deﬁned functions. On the other hand, the
SMT-based setting of Cvc4 [17] applies induction by inductive strengthening of
SMT properties in combination with subgoal discovery. As noted in Section 5,
Cvc4 is limited to induction with concrete base cases and upward induction.

Integer Induction in Saturation
375
While downward integer induction can be considered a straightforward gener-
alization of upward integer induction and does not solve many more problems in
our benchmark sets, symbolic bounds provide a very powerful generalization, as
witnessed by experimental results. In automated reasoning, the power provided
by more general rules comes with the price of uncontrollable blowup of the search
space. To harness this power we came up with deﬁning (interval) upward/down-
ward induction rules with symbolic bounds in the superposition calculus in such
a way that they result in most cases in the addition of very simple clauses, which
can be eﬃciently handled within the AVATAR architecture.
We believe that variants of our induction rules deﬁned in Section 4 can also
be successfully used by SMT solvers. The idea is to apply them, like we do, only
when there is a suitable bound in the current candidate model. One can also
combine this with the observation made in Example 1: one can resolve added
induction formulas against literals already occurring in the search space to add
only ground formulas.
The benchmark suite we propose and use in this paper is new and can be
used to complement existing benchmarks: the TIP library [3] and the examples
of [17]. Our 120 new examples are however more focused on integer properties,
whereas [3,17] contain a variety of problems mostly requiring induction over in-
ductively deﬁned types. Speciﬁcally, out of more than 500 inductive problems in
TIP [3], only 3 use integers and no inductive data types. The examples from [17]
contain 311 inductive benchmarks translated into three encodings, (i) using only
inductive data types, (ii) using integers instead of natural numbers, but also
other inductive data types (such as lists or trees), and (iii) using both integers
and natural numbers to express the same properties, alongside other inductive
data types. Problems from (iii) are also included in SMT-LIB [2]. Note that
there is a substantial diﬀerence between our benchmarks and benchmarks from
(ii). The latter mostly require inductive reasoning only for inductive data types
(or no induction at all): they contain integers but only a few of them require
inductive reasoning over integers, while most of our benchmarks require proper
integer induction. For example, Vampire can solve 131 of 306 benchmarks in
(ii) without using integer induction.
7
Conclusions
We introduced new inference rules for automating inductive reasoning with inte-
gers within saturation-based theorem proving. Many problems in program analy-
sis and mathematical problems of integers previously unsolvable by any theorem
prover can now be solved completely automatically. We believe our results can
progress automated program analysis and automation of mathematics, where
integers are universally used.
Acknowledgments. We thank M´arton Hajd´u and Giles Reger for fruitful dis-
cussions. This work was partially funded by the ERC CoG ARTIST 101002685,
the ERC StG SYMCAR 639270, the EPSRC grant EP/P03408X/1 and the FWF
grant LogiCS W1255-N23.

376
P. Hozzov´a, L. Kov´acs and A. Voronkov
References
1. Barrett, C., Conway, C.L., Deters, M., Hadarean, L., Jovanovi´c, D., King, T.,
Reynolds, A., Tinelli, C.: CVC4. In: Gopalakrishnan, G., Qadeer, S. (eds.) Proc.
of CAV. LNCS, vol. 6806, pp. 171–177. Springer (2011). https://doi.org/10.
1007/978-3-642-22110-1_14
2. Barrett, C., Fontaine, P., Tinelli, C.: The Satisﬁability Modulo Theories Library
(SMT-LIB). www.SMT-LIB.org (2016)
3. Claessen, K., Johansson, M., Ros´en, D., Smallbone, N.: TIP: Tons of Inductive
Problems. In: Kerber, M., Carette, J., Kaliszyk, C., Rabe, F., Sorge, V. (eds.)
Proc. of CICM. LNCS, vol. 9150, pp. 333–337. Springer (2015). https://doi.
org/10.1007/978-3-319-20615-8_23
4. Claessen, K., Johansson, M., Ros´en, D., Smallbone, N.: Automating Inductive
Proofs using Theory Exploration. In: Bonacina, M.P. (ed.) Proc. of CADE.
LNCS, vol. 7898, pp. 392–406. Springer (2013). https://doi.org/10.1007/
978-3-642-38574-2_27
5. Cruanes, S.: Superposition with Structural Induction. In: Dixon, C., Finger, M.
(eds.) Proc. of FRoCoS. LNCS, vol. 10483, pp. 172–188. Springer (2017). https:
//doi.org/10.1007/978-3-319-66167-4_10
6. De Moura, L., Bjørner, N.: Z3: An Eﬃcient SMT Solver. In: Ramakrishnan, C.R.,
Rehof, J. (eds.) Proc. of TACAS. LNCS, vol. 4963, pp. 337–340. Springer (2008).
https://doi.org/10.1007/978-3-540-78800-3_24
7. Dixon, L., Fleuriot, J.: Higher Order Rippling in IsaPlanner. In: Slind, K., Bunker,
A., Gopalakrishnan, G. (eds.) Proc. of TPHOLs. LNCS, vol. 3223, pp. 83–98.
Springer (2004). https://doi.org/10.1007/978-3-540-30142-4_7
8. Fedyukovich, G., Prabhu, S., Madhukar, K., Gupta, A.: Quantiﬁed Invariants
via Syntax-Guided Synthesis. In: Dillig, I., Tasiran, S. (eds.) Proc. of CAV.
LNCS, vol. 11561, pp. 259–277. Springer (2019). https://doi.org/10.1007/
978-3-030-25540-4_14
9. Georgiou, P., Gleiss, B., Kov´acs, L.: Trace Logic for Inductive Loop Reason-
ing. In: Ivrii, A., Strichman, O. (eds.) Proc. of FMCAD. Conference Series:
FMCAD, vol. 1, pp. 255–263 (2020). https://doi.org/10.34727/2020/isbn.
978-3-85448-042-6_33
10. Hajd´u, M., Hozzov´a, P., Kov´acs, L., Schoisswohl, J., Voronkov, A.: Induction with
Generalization in Superposition Reasoning. In: Benzm¨uller, C., Miller, B. (eds.)
Proc. of CICM. LNCS, vol. 12236, pp. 123–137. Springer (2020). https://doi.
org/10.1007/978-3-030-53518-6_8
11. Kaufmann,
M.,
Manolios,
P.,
Moore,
J.S.:
Computer-Aided
Reasoning:
An
Approach,
vol.
3.
Springer
(06
2000).
https://doi.org/10.1007/
978-1-4615-4449-4
12. Kov´acs, L., Robillard, S., Voronkov, A.: Coming to Terms with Quantiﬁed Rea-
soning. In: Castagna, G., Gordon, A.D. (eds.) Proc. of POPL. ACM SIGPLAN
Notices, vol. 52, pp. 260–270. ACM (2017). https://doi.org/10.1145/3093333.
3009887
13. Kov´acs, L., Voronkov, A.: First-Order Theorem Proving and Vampire. In: Shary-
gina, N., Veith, H. (eds.) Proc. of CAV. LNCS, vol. 8044, pp. 1–35. Springer (2013).
https://doi.org/10.1007/978-3-642-39799-8_1
14. Passmore, G., Cruanes, S., Ignatovich, D., Aitken, D., Bray, M., Kagan, E., Kani-
shev, K., Maclean, E., Mometto, N.: The Imandra Automated Reasoning System.
In: Peltier, N., Sofronie-Stokkermans, V. (eds.) Proc. of IJCAR. LNCS, vol. 12167,
pp. 464–471. Springer (2020). https://doi.org/10.1007/978-3-030-51054-1_30

Integer Induction in Saturation
377
15. Reger, G., Schoisswohl, J., Voronkov, A.: Making Theory Reasoning Simpler. In:
Groote, J.F., Larsen, K. (eds.) Proc. of TACAS. LNCS, vol. 12652, pp. 164–180.
Springer (2021). https://doi.org/10.1007/978-3-030-72013-1_9
16. Reger, G., Voronkov, A.: Induction in Saturation-Based Proof Search. In: Fontaine,
P. (ed.) Proc. of CADE. LNCS, vol. 11716, pp. 477–494. Springer (2019). https:
//doi.org/10.1007/978-3-030-29436-6_28
17. Reynolds, A., Kuncak, V.: Induction for SMT Solvers. In: D’Souza, D., Lal, A.,
Larsen, K.G. (eds.) Proc. of VMCAI. LNCS, vol. 8931, pp. 80–98. Springer (2015).
https://doi.org/10.1007/978-3-662-46081-8_5
18. Sonnex, W., Drossopoulou, S., Eisenbach, S.: Zeno: An Automated Prover for
Properties of Recursive Data Structures. In: Flanagan, C., K¨onig, B. (eds.) Proc.
of TACAS. LNCS, vol. 7214, pp. 407–421. Springer (2012). https://doi.org/10.
1007/978-3-642-28756-5_28
19. Voronkov, A.: AVATAR: The Architecture for First-Order Theorem Provers. In:
Biere, A., Bloem, R. (eds.) Proc. of CAV. LNCS, vol. 8559, pp. 696–710. Springer
(2014). https://doi.org/10.1007/978-3-319-08867-9_46
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium or
format, as long as you give appropriate credit to the original author(s) and the source,
provide a link to the Creative Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Superposition with First-class Booleans and
Inprocessing Clausiﬁcation
Visa Nummelin1
, Alexander Bentkamp1
,
Sophie Tourret2,3
, and Petar Vukmirović1
1 Vrije Universiteit Amsterdam, Amsterdam, The Netherlands
visa.nummelin@vu.nl
a.bentkamp@vu.nl
p.vukmirovic@vu.nl
2 Université de Lorraine, CNRS, Inria, LORIA, Nancy, France
sophie.tourret@inria.fr
3 Max-Planck-Institut für Informatik, Saarland Informatics Campus, Saarbrücken,
Germany
Abstract. We present a complete superposition calculus for ﬁrst-order
logic with an interpreted Boolean type. Our motivation is to lay the foun-
dation for refutationally complete calculi in more expressive logics with
Booleans, such as higher-order logic, and to make superposition work ef-
ﬁciently on problems that would be obfuscated when using clausiﬁcation
as preprocessing. Working directly on formulas, our calculus avoids the
costly axiomatic encoding of the theory of Booleans into ﬁrst-order logic
and oﬀers various ways to interleave clausiﬁcation with other derivation
steps. We evaluate our calculus using the Zipperposition theorem prover,
and observe that, with no tuning of parameters, our approach is on a par
with the state-of-the-art approach.
1
Introduction
Superposition is a calculus for equational ﬁrst-order logic that works on problems
given in clausal normal form. Its immense success made preprocessing clausiﬁca-
tion a predominant mechanism in modern automatic theorem proving. However,
this preprocessing is not without drawbacks. Clausiﬁcation can transform sim-
ple problems, such as s →s where s is a large formula, in a way that hides
its original simplicity from the superposition calculus. Ganzinger and Stuber’s
superposition-like calculus [13] operates on clauses that contain formulas as well
as terms and replaces preprocessing clausiﬁcation by inprocessing—meaning pro-
cessing during the operation of the calculus itself. Inprocessing clausiﬁcation
allows superposition’s powerful simpliﬁcation engine to work on formulas. For
example, unit equalities can rewrite formulas s and t in s ↔t before clausiﬁ-
cation duplicates the occurrences into s →t and t →s. Whole formulas rather
than simple literals can be removed by rules such as subsumption resolution [4].
Another issue with Boolean reasoning in the standard superposition calculus
is that, in ﬁrst-order logic, formulas cannot appear inside terms although this is
often desirable for problems coming from software veriﬁers or proof assistants.
Instead, authors of such tools need to resort to translations. Kotelnikov et al.
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5_22
378–395, 2021.

studied eﬀects of these translations in detail. They showed that simple axioms
such as the domain cardinality axiom for Booleans (∀(x : o). x ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨x ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) can
severely slow down superposition provers. To support more eﬃcient reasoning on
problems with ﬁrst-class Booleans, they describe the FOOL logic, which admits
functions that take arguments of Boolean type and quantiﬁcation over Booleans.
They further describe two approaches to reason in FOOL: The ﬁrst one [17]
requires an additional rule in the superposition calculus, whereas the second
one [16] is completely based on preprocessing.
Our calculus combines complementary advantages of Ganzinger and Stuber’s
and of Kotelnikov et al.’s work. Following Kotelnikov et al., our logic (Sect. 2)
is similar to FOOL and supports nesting formulas inside terms, as well as quan-
tifying over Booleans. Following Ganzinger and Stuber, our calculus (Sect. 3)
reasons with formulas and supports inprocessing clausiﬁcation.
Our calculus also extends the two approaches. To reduce the number of
possible inferences, we generalize Ganzinger and Stuber’s Boolean selection
functions, which allow us to restrict the Boolean subterms in a clause on which
inferences can be performed. The term order requirements of our calculus are
less restrictive than Ganzinger and Stuber’s. In addition to the lexicographic
path order (LPO), we also support the Knuth-Bendix order (KBO) [15], which
is known to work better with superposition in practice.
Our proof of refutational completeness (Sect. 4) lays the foundation for com-
plete calculi in more complex logics with Booleans. Indeed, Bentkamp et al. [8]
devised a refutationally complete calculus for higher-order logic based on our
completeness theorem. Our theorem incorporates a powerful redundancy crite-
rion that allows for a variety of inprocessing clausiﬁcation methods (Sect. 5).
We implemented our approach in the Zipperposition theorem prover (Sect. 6)
and evaluated it on thousands of problems that target our logic ranging from
TPTP to SMT-LIB to Sledgehammer-generated benchmarks (Sect. 7). Without
ﬁne-tuning, our new calculus performs as well as known techniques. Exploring
the strategic choices that our calculus opens should lead to further performance
improvements. In addition, we corroborate the claims of Ganzinger and Stuber
concerning applicability of formula-based superposition reasoning: We ﬁnd a set
of 17 TPTP problems (out of 1000 randomly selected) that Zipperposition can
solve only using the techniques described in this paper. We refer to our technical
report [25] for more details on our calculus and the complete completeness proof.
2
Logic
Our logic is a ﬁrst-order logic with an interpreted Boolean type. It is essentially
identical to the UF logic of SMT-LIB [5], including the Core theory, but without
if-then-else and let expressions, which can be supported through simple transla-
tions. It also closely resembles Kotelnikov et al.’s FOOL [17], which additionally
supports if-then-else and let expressions.
Our logic requires an interpreted Boolean type o and allows for an arbitrary
number of uninterpreted types. The set of symbols must contain the logical
Superposition with First-class Booleans and Inprocessing Clausiﬁcation
379

380
V. Nummelin et al.
symbols ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥: o; ¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬ : o →o; ∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧, ∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨, →
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→: (o × o) →o; and the overloaded symbols
≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈, ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈: (τ × τ) →o for each type τ. The logical symbols are printed in bold
to distinguish them from the notation used for clauses below. Throughout the
paper, we write tuples (a1, . . . , an) as ¯an or ¯a.
The set of terms is deﬁned inductively as follows. Every variable is a term. If
f : ¯τn →υ is a symbol and ¯tn : ¯τn is a tuple of terms, then the application f(¯tn)
(or simply f if n = 0) is a term of type υ. If x is a variable and t : o a Boolean
term, then the quantiﬁed terms ∀x. t and ∃x. t are terms of Boolean type. We
view quantiﬁed terms modulo α-renaming. A formula is a term of Boolean type.
The root of a term is f if the term is an application f(¯tn); it is x if the term
is a variable x; and it is ∀or ∃if the term is a quantiﬁed term ∀x. t or ∃x. t. A
variable occurrence is free in a term if it is not bound by ∀or ∃. A term is ground
if it contains no free variables. Substitutions are deﬁned as usual in ﬁrst-order
logic and they rename quantiﬁed variables to avoid capture.
A literal s ˙≈t is an equation s ≈t or a disequation s ̸≈t. Unlike terms
constructed using the function symbols ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈and ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈, literals are unoriented. A clause
L1 ∨· · · ∨Ln is a ﬁnite multiset of literals Lj. The empty clause is written as
⊥. Terms t of Boolean type are not literals. They must be encoded as t ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
and t ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, which we call predicate literals. Both are considered positive literals
because they are equations, not disequations.
We have considered excluding negative literals s ̸≈t by encoding them as
(s ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈t) ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, following Ganzinger and Stuber. However, this approach requires
an additional term order condition to make the conclusion of equality factoring
small enough, excluding KBO. To support both KBO and LPO, we allow neg-
ative literals. Regardless, our simpliﬁcation mechanism will allow us to simplify
negative literals of the form t ̸≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥and t ̸≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤into t ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤and t ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, respectively,
thereby eliminating redundant representations of predicate literals.
The semantics is a straightforward extension of standard ﬁrst-order logic only
adding the interpretation of the Boolean type as a two element domain, as in
Kotelnikov et al.’s FOOL logic. Some of our calculus rules introduce Skolem sym-
bols, which are intended to be interpreted as witnesses for existentially quantiﬁed
terms. Still, our semantics treats them as uninterpreted symbols. To achieve a
satisﬁability-preserving calculus, we assume that these symbols do not occur in
the input problem. More precisely, we inductively extend the signature of the
input problem by a symbol sk∀¯y.∃z.t : ¯τ →υ for each term of the form ∃z. t over
the extended signature, where υ is the type of z and ¯y : ¯τ are the free variables
occurring in ∃z. t, in order of ﬁrst appearance.
3
The Calculus
Following standard superposition, our calculus employs a term order and a literal
selection function to restrict the search space. To accommodate for quantiﬁed
Boolean terms, we impose additional requirements on the term order. To support
ﬂexible reasoning with Boolean subterms, in addition to the literal selection
function, we introduce a Boolean subterm selection function.

Term Order The calculus is parameterized by a strict well-founded order ≻
on ground terms that fulﬁlls: (O1) u ≻⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≻⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤for any term u that is not ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤or
⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥;
(O2) ∀x. t ≻{x →u}t and ∃x. t ≻{x →u}t for any term u whose only
Boolean subterms are ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤and ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥;
(O3) subterm property;
(O4) compatibility
with contexts (not necessarily below ∀and ∃);
(O5) totality.
The order is
extended to literals, clauses, and nonground terms as usual [2]. The nonground
order then also enjoys (O6) stability under grounding substitutions.
Ganzinger and Stuber’s term order restrictions are similar but incompatible
with KBO. Using an encoding of our terms into untyped ﬁrst-order logic we
describe how both LPO and the transﬁnite variant of KBO [19] can satisfy
conditions (O1)–(O6).
Our encoding represents bound variables by De Bruijn indices, which become
new constant symbols dbn for n ∈N. Quantiﬁers are represented by two new
unary function symbols, also denoted by ∀and ∃. All other symbols are simply
identiﬁed with their untyped counterpart. Regardless of symbol precedence or
symbol weights, KBO and LPO enjoy properties (O3)–(O6) when applied to the
encoded terms. They are even compatible with contexts below quantiﬁers.
To satisfy (O1) and (O2), let the precedence for LPO be ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤< ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥< f < ∀<
∃< db0 < db1 < · · · where f is any other symbol. For KBO, we can use the same
symbol precedence and a symbol weight function W that assigns each symbol
ordinal weights (of the form ωa + b with a, b ∈N), where W(⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤) = W(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) =
1, W(∀) = W(∃) = ω, and W(f) ∈N \ {0} for any other symbol f.
Selection and Eligibility Following an idea of Ganzinger and Stuber, we
parameterize our calculus with two selection functions: one selecting literals and
one selecting Boolean subterms.
Deﬁnition 1 (Selection functions). The calculus is parameterized by a lit-
eral selection function FLSel and a Boolean subterm selection function FBSel.
The function FLSel maps each clause to a subset of its literals. The selection
function FBSel maps each clause to a subset of its Boolean subterms. The
literals FLSel(C) and the subterms FBSel(C) are selected in C. The following
restrictions apply: (S1) A literal can only be selected if it is negative or of the
form s ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥. (S2) A Boolean subterm can only be selected if it is not ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, or
a variable. (S3) A Boolean subterm can only be selected if its occurrence is not
below a quantiﬁer. (S4) The topmost terms on either side of a positive literal
cannot be selected.
The interplay of maximality w.r.t. term order, literal and Boolean selection
functions gives rise to a new notion of eligibility:
Deﬁnition 2 (Eligibility). A literal L is (strictly) eligible w.r.t. a substitution
σ in C if it is selected in C or there are no selected literals and no selected Boolean
subterms in C and σL is (strictly) maximal in σC. The eligible subterms of a
clause C w.r.t. a substitution σ are inductively deﬁned as follows: (E1) Any
selected subterm is eligible. (E2) If a literal s ˙≈t with σs ̸⪯σt is either eligible
and negative or strictly eligible and positive, then s is eligible. (E3) If a subterm
381
Superposition with First-class Booleans and Inprocessing Clausiﬁcation

382
V. Nummelin et al.
is eligible and its root is not ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈, ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈, ∀, or ∃, all of its direct subterms are also
eligible. (E4) If a subterm is eligible and of the form s ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈t or s ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈t, then s is
eligible if σs ̸⪯σt and t is eligible if σs ̸⪰σt. The substitution σ is left implicit
if it is the identity substitution.
The Core Inference Rules The following inference rules form our calculus:
D
D′ ∨t ≈t′
C[u]
Sup
σ(D′ ∨C[t′])
C
C′ ∨u′ ≈v′ ∨u ≈v
Factor
σ(C′ ∨v ̸≈v′ ∨u ≈v′)
C
C′ ∨u ̸≈u′
Irrefl
σC′
C
C′ ∨s ≈t
⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥Elim
σC′
C[u]
BoolRw
σC[t′]
C[∀z. v]
∀Rw
C[{z 7→sk∀¯y.∃z.¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬v(¯y)}v]
C[∃z. v]
∃Rw
C[{z 7→sk∀¯y.∃z.v(¯y)}v]
C[u]
BoolHoist
C[⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥] ∨u ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
C[s ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈t]
≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈Hoist
C[⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥] ∨s ≈t
C[s ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈t]
̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈Hoist
C[⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤] ∨s ≈t
C[∀x. t]
∀Hoist
C[⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥] ∨{x 7→y}t ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
C[∃x. t]
∃Hoist
C[⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤] ∨{x 7→y}t ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥
The rules are subject to the following side conditions:
Sup (1) σ = mgu(t, u); (2) u is not a variable; (3) σt ̸⪯σt′; (4) D ≺C[u];
(5) u is eligible in C w.r.t. σ; (6) t ≈t′ is strictly eligible in D w.r.t. σ;
(7) the root of t is not a logical symbol; (8) if σt′ = ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, the subterm u is at
the top level of a positive literal.
Factor (1) σ = mgu(u, u′); (2) σu ̸≈t ̸∈σC for any term t; (3) no Boolean
subterm and no literal is selected in C; (4) σu is a maximal term in σC;
(5) σv is maximal in {t | σu ≈t ∈σC}.
Irrefl (1) σ = mgu(u, u′); (2) u ̸≈u′ is eligible in C w.r.t. σ.
⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥Elim (1) σ = mgu(s ≈t, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤); (2) s ≈t is strictly eligible in C w.r.t. σ.
BoolRw (1) (t, t′) is one of the following pairs, where x is a fresh variable:
(¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥), (⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥), (⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥), (⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥), (⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥),
(⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥), (⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤),
(⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (x ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈x, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (x ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈x, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥); (2) σ = mgu(t, u); (3) u is not a
variable; (4) u is eligible in C w.r.t. σ.
⋆Rw (where ⋆∈{∀, ∃}) (1) v is a term that may refer to z; (2) ¯y are the
free variables occurring in ∀z. v and ∃z. v, respectively, in order of ﬁrst
appearance; (3) the indicated subterm is eligible in C; (4) for ∀Rw, C[⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤] is
not a tautology; (5) for ∃Rw, C[⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥] is not a tautology. (In an implementation,
the tautology check can be approximated by checking if the aﬀected literal
is of the form ∀z. v ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤or ∃z. v ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥.)

BoolHoist (1) u is a Boolean term whose root is an uninterpreted predicate;
(2) u is eligible in C; (3) u is not a variable; (4) u is not at the top level of
a positive literal.
⋆Hoist (where ⋆∈{≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈, ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈, ∀, ∃}) (1) the indicated subterm is eligible in C; (2) y
is a fresh variable.
Rationale for the Rules Our calculus is a graceful generalization of superpo-
sition: if the input clauses do not contain any Boolean terms, it coincides with
standard superposition. In addition to the standard superposition rules Sup,
Factor, and Irrefl, our calculus contains various rules to deal with Booleans.
For each logical symbol and quantiﬁer, we must consider the case where it is true
and the case where it is false. Whenever possible, we prefer rules that rewrite
the Boolean subterm in place (with names ending in Rw). When this cannot be
done in a satisﬁability-preserving way, we resort to rules hoisting the Boolean
subterm into a dedicated literal (with names ending in Hoist). For terms rooted
by an uninterpreted predicate, the rule BoolHoist only deals with the case that
the term is false. If it is true, we rely on Sup to rewrite it to ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤eventually.
Example 3. The clause a ∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤can be refuted by the core inferences as
follows. First we derive a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤(displayed on the left) and then we use it to
derive ⊥(displayed on the right). In this and the following example, we assume
eager selection of literals whenever the selection restrictions allow it.
a ∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
BoolHoist
⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
BoolHoist
⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤BoolRw
⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤BoolRw
⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥Elim
a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤Factor
⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤̸≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤Irrefl
a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
a ∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤Sup
⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬a ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤Sup
⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤BoolRw
⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤BoolRw
⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥Elim
⊥
The derivation illustrates how BoolHoist and Sup replace uninterpreted predi-
cates by ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤and ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥to allow BoolRw to eliminate the surrounding logical symbols.
Example 4. The clause (∃x. ∀y. y ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈x) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤can be refuted as follows:
(∃x. ∀y. y ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈x) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
∃Rw
(∀y. y ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈sk∃x.∀y.y̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸≈x) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
∀Hoist
⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨(y′ ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈sk∃x.∀y.y̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸≈x) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥Elim
(y′ ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈sk∃x.∀y.y̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸≈x) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈Rw
⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥Elim
⊥
383
Superposition with First-class Booleans and Inprocessing Clausiﬁcation

384
V. Nummelin et al.
Redundancy Criterion In standard superposition, a clause is deﬁned as re-
dundant if all of its ground instances follow from smaller ground instances of
other clauses. We keep this deﬁnition, but use a nonstandard notion of ground
instances, inspired by constraint superposition [23]. In our completeness proof,
this new notion of ground instances ensures that ground instances of the con-
clusion of ∀Rw, ∃Rw, ∀Hoist, and ∃Hoist inferences are smaller than the
corresponding instances of their premise by property (O2).
Deﬁnition 5 (Redundancy of clauses). The ground instances of a clause C
are all ground clauses of the form γC where γ is a substitution such that for all
variables x, the only Boolean subterms of γx are ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥and ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤. A ground clause C
is redundant w.r.t. a ground clause set N if there exist clauses C1, . . . , Ck ∈N
such that C1, . . . , Ck |= C and C ≻Ci for all 1 ≤i ≤k. A nonground clause C
is redundant w.r.t. clauses N if C is strictly subsumed by a clause in N or every
ground instance of C is redundant w.r.t. ground instances of N.
In standard superposition, an inference is deﬁned as redundant if all its
ground instances are, and a ground inference is deﬁned as redundant if its con-
clusion follows from other clauses smaller than the main premise. We keep this
deﬁnition as well, but we use a nonstandard notion of ground instances for some
of the Boolean rules. In our report, we deﬁne a slightly stronger variant of in-
ference redundancy via an explicit ground calculus, but the following notion is
also strong enough to justify the few prover optimizations based on inference
redundancy we know from the literature (e.g., simultaneous superposition [7]).
Deﬁnition 6 (Redundancy of inferences). A ground instance of a ∀Rw,
∃Rw, ∀Hoist, or ∃Hoist inference is an inference obtained by applying a
grounding substitution to premise and conclusion, regardless of whether the
result is a valid ∀Rw, ∃Rw, ∀Hoist, or ∃Hoist inference. A ground instance of
an inference ι of other rules is an inference ι′ of the same rule such that premises
and conclusion of ι′ are ground instances of the respective premises and conclu-
sion of ι. For ι′, we use selection functions that select the ground literals and
Boolean subterms corresponding to the ones selected in the nonground premises.
A ground inference with main premise C, side premises C1, . . . , Cn, and conclu-
sion D is redundant w.r.t. N if there exist clauses D1, . . . , Dk ≺C in N such
that D1, . . . , Dk, C1, . . . , Cn |= D. A nonground inference is redundant if all its
ground instances are redundant.
A clause set N is saturated if every inference from N is redundant w.r.t. N.
Simpliﬁcation Rules The redundancy criterion is a graceful generalization of
the criterion of standard superposition. Thus, the standard simpliﬁcation and
deletion rules, such as deletion of trivial literals and clauses, subsumption, and
demodulation, can be justiﬁed. Demodulation below quantiﬁers is justiﬁed if the
term order is compatible with contexts below quantiﬁers.
Some calculus rules can act as simpliﬁcations. ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥Elim can always be a simpli-
ﬁcation. Given a clause on which both ⋆Rw and ⋆Hoist apply, where ⋆∈{∀, ∃},
the clause can be replaced by the conclusions of these rules. If ⋆Rw does not

apply because of condition 4 or 5, ⋆Hoist alone can be a simpliﬁcation. Also
justiﬁed by redundancy, the rules BoolHoist and ⋆Hoist can simultaneously
replace all occurrences of the eligible subterm they act on. For example, applying
≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈Hoist to p(x ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈y) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨q(x ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈y) ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥yields p(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨q(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨x ≈y.
While experimenting with our implementation, we have observed that the
following simpliﬁcation rule from Vampire [18] can substantially shorten proofs:
s ̸≈t ∨C[s]
LocalRw
s ̸≈t ∨C[t]
In this rule, we require s ≻t.
Interpreting literals of the form s ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤as s ̸≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥and s ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥as s ̸≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤we
can apply the rule even to these positive literals. This especially convenient with
rules such as BoolHoist. Consider the clause C = pi(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨q ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, assume
no literal is selected and the Boolean selection function always selects a subterm
p(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥). Applying BoolHoist to C we get p(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨pi−1(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨q ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥. This
can then be simpliﬁed to a tautological clause p(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨p(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨q ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥
using i −2 LocalRw steps. If we did not use LocalRw, BoolHoist would
produce i −2 intermediary clauses starting from C, none of which would be
recognized as a tautology.
Many rules of our calculus replace subterms with ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤or ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥. After this replace-
ment, resulting terms can be simpliﬁed using Boolean equivalences that specify
the behavior of logical operations on ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤and ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥. To this end, we use the rule
BoolSimp [33], similar to simp of Leo-III [27, Sect. 4.2.1]:
C[s]
BoolSimp
C[t]
This rule replaces s with t whenever s ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈t is contained in a predeﬁned
set of tautological equations. In addition to all equations that Leo-III uses
for simp, we also include more complex ones, such as (¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬u →
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→u) ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈u and
(u1 →
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→· · · →
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→un →
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→v1 ∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨· · · ∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨vm) ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤where ui = vj for some i and j. The
exhaustive list is given in our technical report. Using BoolSimp and ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥Elim,
the twelve steps of Example 3 can be replaced by just two simpliﬁcation steps.
BoolSimp simpliﬁes terms with logical symbol roots if one argument is either
⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤or ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥or if two arguments are identical. Thus, after simpliﬁcation, BoolRw
applies only in two remaining cases: if all arguments of a logical symbol are
distinct variables and if the sides of a (dis)equation are diﬀerent and uniﬁable.
This observation can be used to streamline the implementation of BoolRw.
4
Refutational Completeness
Our calculus is dynamically refutationally complete. All the rules that do not
introduce Skolem symbols are also sound.
385
Superposition with First-class Booleans and Inprocessing Clausiﬁcation

386
V. Nummelin et al.
Completeness Theorem 7. Let S0 be an unsatisﬁable set of clauses. Let
(Si)∞
i=0 be a fair derivation—i.e., a derivation where ∞
i=0
∞
j=i Sj is saturated.
Then ⊥∈Si for some i.
We outline some key parts of the proof here and refer to our technical
report [25] for the details. We ﬁrst deﬁne a ground version of our calculus
with standardly inherited redundancy criterion and prove it complete. Devising
suitable ground analogues of the rules ∀Rw and ∃Rw was diﬃcult because the
arguments of the Skolems depend on the variables occurring in the premise.
Therefore, we parameterize the ground calculus by a function that provides
ground Skolem terms in the ground versions of these rules. When lifting the
completeness result to the nonground level, we instantiate the parameter with
a speciﬁc function that allows us to lift the ∀Rw and ∃Rw inferences.
To prove the ground calculus complete, we employ the framework for reduc-
tion of counterexamples [3]. It requires us to construct an interpretation I given
a saturated unsatisﬁable clause set that does not contain ⊥. Then we must show
that any counterexample—i.e., a clause that does not hold in I—can be reduced
to a smaller (≺) counterexample by some inference.
The interpretation I is deﬁned by a normalizing rewrite system as in the
standard completeness proof of superposition. To ensure a correct interpretation
of Booleans, we incrementally add Boolean rewrite rules along with the rules
produced by clauses as usual. If a counterexample can be rewritten by a Boolean
rule, we reduce it by a ⋆Rw or ⋆Hoist inference. If it can be rewritten by a rule
produced by a clause, we reduce it by a Sup inference.
We derive the dynamic completeness of our nonground calculus using the
saturation framework [35]. It gives us a nonground clause set N to work with.
We then have to choose the parameters of our ground calculus such that all of
its inferences from the grounding of N are redundant or liftable. We show that
inferences rewriting below variables are redundant. Other inferences we show to
be liftable—i.e., they are a ground instance of some inference from N.
5
Inprocessing Clausiﬁcation Methods
Our calculus makes preprocessing clausiﬁcation unnecessary: A problem speciﬁed
by a formula f can be represented as a clause f ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤. Our redundancy criterion
allows us to add various sets of rules to steer the inprocessing clausiﬁcation.
Without any additional rules, our core calculus rules perform all the neces-
sary reasoning about formulas. We call this method inner delayed clausiﬁcation
because the calculus rules tend to operate on the inner Boolean subterms ﬁrst.
The outer delayed clausiﬁcation method adds the following rules to the cal-
culus, which are guided by the outermost logical symbols. Let s and t be Boolean
terms. Below, we let s+ range over literals of the form s ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤and s ̸≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, and s−
over literals of the form s ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥and s ̸≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤.

s+ ∨C
+OuterClaus
oc(s, C)
s−∨C
−OuterClaus
oc(¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬s, C)
s ≈t ∨C
≈OuterClaus
s ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨t ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨C
s ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨t ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨C
s ̸≈t ∨C
̸≈OuterClaus
s ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨t ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨C
s ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨t ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨C
The rules +OuterClaus and −OuterClaus are applicable to any term
s whose root is a logical symbol, whereas the rules ≈OuterClaus and
̸≈OuterClaus are only applicable if neither s nor t is ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤or ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥. Clearly,
our redundancy criterion allows us to replace the premise of all Outer-
Claus-rules with their conclusions. Nonetheless, the rules ≈OuterClaus and
̸≈OuterClaus are not used as simpliﬁcation rules since destructing equiva-
lences disturbs the syntactic structure of the formulas, as noted by Ganzinger
and Stuber [13]. The function oc(s, C) analyzes the shape of the formula s and
distributes it over the clause C. For example, oc(s1 →
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→s2, C) = {s1 ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨s2 ≈
⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨C}, and oc(¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬(s1 ∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨s2), C) = {s1 ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨C, s2 ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨C}. This function also
replaces quantiﬁed terms by either a fresh free variable or a Skolem in the body
of the quantiﬁed term, depending on the polarity. The full deﬁnition of oc(s, C)
is speciﬁed in our technical report.
A third inprocessing clausiﬁcation method is immediate clausiﬁcation. It ﬁrst
preprocesses the input problem using a standard ﬁrst-order clausiﬁcation proce-
dure such as Nonnengart and Weidenbach’s [24]. Then, during the proof search,
when a clause C appears on which OuterClaus rules could be applied, we
apply the standard clausiﬁcation procedure on the formula ∀¯x. C instead (where
¯x are the free variables of C), and replace C with the clausiﬁcation results.
With this method, the formulas are clausiﬁed in one step, making intermediate
clausiﬁcation results inaccessible to the simpliﬁcation machinery.
Renaming Common Formulas Following Tseitin [31], clausiﬁcation proce-
dures usually rename common formulas to prevent a possible combinatorial ex-
plosion caused by naive clausiﬁcation. In our two delayed clausiﬁcation methods,
we realize this idea using the following rule:
C1[σ1f]
· · ·
Cn[σnf]
Rename
C1[σ1p(¯x)]
· · ·
Cn[σnp(¯x)]
R1
· · ·
Rm
Here, the formula f has a logical root, ¯x are the distinct free variables in f,
p is a fresh symbol, σi is a substitution, and the clauses R1, . . . , Rm are the
result of simplifying a deﬁnition clause R = p(¯x) ≈f as described below. The
rule avoids exponential explosion by replacing n positions in which results of
f’s clausiﬁcation will appear into a single position in R. Optimizations such as
polarity-aware renaming [24, Sect. 4] also apply to Rename.
387
Superposition with First-class Booleans and Inprocessing Clausiﬁcation

388
V. Nummelin et al.
Several issues arise with Rename as an inprocessing rule. We need to ensure
that in R, f ≻p(¯x), since otherwise demodulation might reintroduce a formula
f in the simpliﬁed clauses. This can be achieved by giving the fresh symbol p
a precedence smaller than that of all symbols initially present in the problem
(other than ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤and ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥). To ensure the precedence is well founded, the precedence
of p must be greater than that of symbols previously introduced by the calculus.
For KBO, we additionally set the weight of p to the minimal possible weight.
For Rename to be used as a simpliﬁcation rule, we need to ensure that the
conclusions are smaller than the premises. This is trivially true for all clauses
other than the clause R. For example, let Ci = f ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤(σi is the identity). Clearly,
R is larger than Ci. However, we can view the deﬁnition clause R as two clauses
R+ = p(¯x) ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨f ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤and R−= p(¯x) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨f ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥. Then, we can apply
a single step of the OuterClaus rules to R+ and R−(on their subformula
f), which further results in clauses R1, . . . , Rm. Inspecting the OuterClaus
rules, it is clear that m ≤4, which makes enforcing this simpliﬁcation tolerable.
Furthermore, as f is simpliﬁed in each of R1, . . . , Rm, they are smaller than any
premise Ci.
Another potential source of a combinatorial explosion in our calculus are
formulas that occur deep in the arguments of uninterpreted predicates. Consider
the clause C = pi(x) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨qj(y) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤where i, j > 2. If the ﬁrst and the second
literal are eligible in C, any clause pi1(x) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨pi2(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨· · · ∨pik(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ≈
⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨qj1(y) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨qj2(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨· · · ∨qjl(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤(where i1+· · ·+ik = i and j1+
· · · + jl = j) , resulting from multiple BoolHoist applications, can be obtained
in many diﬀerent ways. This explosion can be avoided using the following rule:
s ≈t ∨C
RenameDeep
p(x) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨C
R1
· · ·
R4
where p is a fresh symbol, ¯x are all free variables occurring in s ≈t, the clauses
R1, . . . , R4 result from simplifying R = p(¯x) ≈(s ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈t) as described above, and
we impose the same precedence and weight restrictions on p as for Rename. Fi-
nally, we require that both s ≈t and C contain deep Booleans where a Boolean
subterm u|p of a term u is a deep Boolean if there are at least two distinct proper
preﬁxes q of the position p such that the root of u|q is an uninterpreted predicate.
Similarly to Rename, the deﬁnition clause R can be larger than the premise.
As OuterClaus-rules might not apply to s ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈t, we need a diﬀerent solution:
C[u]
BoolHoistSimp
C[⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥] ∨u ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
C[⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤] ∨u ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥
In this rule u is a non-variable Boolean subterm, diﬀerent from ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤and ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, whose
indicated occurrence is not in a literal u ≈b where b is ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥or a variable.
Clearly, both conclusions of BoolHoistSimp are smaller than the premise. As
before, observing that R is equivalent to two clauses R+ = p(¯x) ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨s ≈t and
R−= p(¯x) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨s ̸≈t, we simplify R+ and R−into clauses that are guaranteed
to be smaller than the premise. This is achieved by applying BoolHoistSimp

to one of the deep Boolean occurrences in both R+ and R−, which produces
R1, . . . , R4 and reduces the size of resulting clauses enough for them to be smaller
than the premise of RenameDeep. The RenameDeep rule can be applied
analogously to negative literals s ̸≈t.
6
Implementation
Zipperposition [11] is an automatic theorem prover designed for easy prototyping
of various extensions of superposition. So far, it has been extended to support
induction, arithmetic, and various fragments of higher-order logic. We have im-
plemented our calculus and its extensions described above in Zipperposition.
Zipperposition has long supported λ as the only binder. Because introducing
new binders would signiﬁcantly complicate the implementation, we decided to
represent the terms ∀x. t and ∃x. t as ∀(λx. t) and ∃(λx. t), respectively.
We introduced a normalized presentation of predicate literals as either s ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
or s ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥. As Zipperposition previously encoded them as s ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤or s ̸≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤,
enforcing the new encoding was a source of tedious implementation eﬀort.
Factor inferences happen even when the maximal literal is selected since
the discovery of condition (3) as described in Sect. 3 came after the evaluation.
Zipperposition’s existing selection functions were not designed with Boolean
subterm selection in mind. For instance, a function that selects a literal L with
a selectable Boolean subterm s can make s eligible, even if the Boolean selection
function did not select s. To mitigate this issue, we can optionally block selection
of literals that contain selectable Boolean subterms.
We implemented four Boolean selection functions: selecting the leftmost in-
nermost, leftmost outermost, syntactically largest or syntactically smallest se-
lectable subterm. Ties are broken by selecting the leftmost term. Additionally,
we implemented a Boolean selection function that does not select any subterm.
Vukmirović and Nummelin [33, Sect. 3.4] explored inprocessing clausiﬁcation
as part of their pragmatic approach to higher-order Boolean reasoning. They
describe in detail how the formula renaming mechanism is implemented. We
reuse their mechanism, and simplify deﬁnition clauses as described in Sect. 5.
7
Evaluation
The goal of our evaluation was to answer the following questions:
1. How does our approach compare to preprocessing?
2. How do the diﬀerent inprocessing clausiﬁcation methods compare?
3. Is there an overhead of our calculus on problems without ﬁrst-class Booleans?
4. What eﬀect do Boolean selection, LocalRw, and BoolHoistSimp have?
We ﬁltered TPTP [29] and SMT-LIB [5] to get ﬁrst-order benchmarks that
actually do use the Boolean type. In TPTP THF we found 145 such problems
(TPTP Bool) and in the UF section of SMT-LIB 5507 such problems. Martin
389
Superposition with First-class Booleans and Inprocessing Clausiﬁcation

390
V. Nummelin et al.
Desharnais and Jasmin Blanchette generated 1253 Sledgehammer problems that
target our logic. To measure the overhead of our calculus, we randomly chose
1000 FOF and CNF problems from the TPTP (TPTP FO). Even with this
sample the experiment could take up to (145+5507+1253+1000) × #modes ×
300 s ≈9 CPU months. On StarExec servers, evaluation roughly took three days
under low load. Otherwise evaluating on all 13 000 FOF and CNF problems could
have taken 2.5 times longer.
SMT-LIB interprets the symbol ite as the standard if-then-else function [5,
Sect. 3.7.1]. Whenever a term s = ite(t1, t2, t3) of type τ occurs in a problem, we
replace s with fτ(t1, t2, t3), where fτ is a fresh symbol denoting the ite function
of a particular return type. To comply with SMT-LIB, we add the following
axioms: ∀x y. fτ(⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, x, y) ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈x and ∀x y. fτ(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, x, y) ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈y. SMT-LIB allows the use
of let variable bindings [5, Sect. 3.6.1]. We simply replace each variable with
its deﬁnition in the body of the let bindings.
Currently, among competing superposition-based provers only E and Vampire
support ﬁrst-order logic with interpreted Booleans, and they do so through pre-
processing. We could not evaluate Vampire in the ﬁrst-order mode with FOOL
preprocessing because it yielded unsound results on TPTP Bool benchmarks.
We were able to run E on all benchmarks, except for the ones in SMT syntax.
We used Zipperposition’s ﬁrst-order portfolio, which invokes the prover se-
quentially with up to 13 conﬁgurations in diﬀerent time slices.
To compare
diﬀerent features, we ran diﬀerent modes that enable a given feature in all of the
portfolio conﬁgurations. All experiments were performed on the StarExec Iowa
servers [28], equipped with Intel Xeon E5-2609 0 CPUs clocked at 2.40 GHz. We
set the CPU time limit to 300 s. Figure 1 displays the results. An empty cell
indicates that a mode is not evaluated on that benchmark set. An archive with
the raw evaluation data is publicly available.4
A preprocessing transformation that removes all Boolean subterms occurring
as arguments of symbols [34, Sect. 8], similar to Kotelnikov et al.’s FOOL clausi-
ﬁcation approach [16], is implemented in Zipperposition. To answer question 1,
we enabled preprocessing and compared it to our new calculus parameterized
with the Boolean selection function that selects the smallest selectable subterm.
The mode using our new calculus performs immediate inprocessing clausiﬁca-
tion, and we call it base, while the mode that preprocesses Boolean subterms is
denoted by preprocess in Figure 1.
The obtained results do not give a conclusive answer to question 1. On both
TPTP Bool and Sledgehammer problems, some conﬁguration of our new calculus
manages to prove one problem more than preprocessing. On SMT-LIB bench-
marks, the best conﬁguration of our calculus matches preprocessing. This shows
that our calculus already performs roughly as well as previously known tech-
niques and suggests that it will be able to outperform preprocessing techniques
after tuning of its parameters.
For context, we provide the evaluation of E on supported benchmarks. On
TPTP FO benchmarks it solves 643 problems, on TPTP Bool benchmarks 144
4 https://doi.org/10.5281/zenodo.4550787

Fig. 1: Number of problems solved per benchmark set and Zipperposition mode.
The x-axes start from the number of problems solved by all evaluated modes.
problems, and on Sledgehammer benchmarks 674 problems. Note that there is
no straightforward way to compare these results with Zipperposition.
Our base mode uses immediate inprocessing clausiﬁcation. To answer ques-
tion 2, we compared base with a variant of base with outer delayed clausiﬁcation
(base+outer) and with a variant with inner delayed clausiﬁcation (base+inner).
In the delayed modes, we invoke the Rename rule on formulas that are discov-
ered to occur more than four times in the proof state.
The results show that inner delayed clausiﬁcation, which performs the laziest
form of clausiﬁcation, gives the worst results on most benchmark sets. Outer
delayed clausiﬁcation performs roughly as well as immediate clausiﬁcation on
problems targeting our logic. On purely ﬁrst-order problems, it performs slightly
worse than immediate clausiﬁcation. However, outer delayed clausiﬁcation solves
17 problems not solved by immediate clausiﬁcation on these problems. This
suggests that it opens new possibilities for ﬁrst-order reasoning that need to be
explored further with specialized strategies and additional rules.
We found a problem with a conjecture of the form s →
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→s that only the de-
layed clausiﬁcation modes can prove: the TPTP problem SWV122+1. The subfor-
mula renaming mechanism of immediate clausiﬁcation obfuscates this problem,
whereas delayed clausiﬁcation allows BoolSimp to convert the negated conjec-
ture to ⊥directly, completing the proof in half a second.
To answer question 3, we compared the mode of Zipperposition in which all
rules introduced by our calculus are disabled (oﬀ) with base on purely ﬁrst-order
problems. Our results show that both modes perform roughly the same.
To answer question 4, we evaluated the Boolean selection functions we have
implemented: syntactically smallest selectable term (used in base), syntactically
largest selectable term (selmax), leftmost innermost selectable term (selli), left-
most outermost selectable term (sello), and no Boolean selection (sel∅). We also
391
Superposition with First-class Booleans and Inprocessing Clausiﬁcation

392
V. Nummelin et al.
evaluated two modes in which the rules LocalRw and BoolHoistSimp (BHS)
are enabled. None of the selection functions inﬂuences the performance greatly.
Similarly, we observe no substantial diﬀerence regardless of whether the rules
LocalRw and BoolHoistSimp are enabled.
8
Related Work and Conclusion
The research presented in this paper extends superposition in two directions:
with inprocessing clausiﬁcation and with ﬁrst-class Booleans. The ﬁrst direc-
tion has been explored before by Ganzinger and Stuber [13], and others have
investigated it in the context of other superposition-related calculi [1,4,9,20,21].
The other direction has been explored before by Kotelnikov et al., who devel-
oped two approaches to cope with ﬁrst-class Booleans [16,17]. For the quantiﬁed
Boolean formula fragment of our logic, Seidl et al. developed a translation into
eﬀectively propositional logic [26]. More general approaches to incorporate theo-
ries into superposition include superposition for ﬁnite domains [14], hierarchic
superposition [6], and superposition with (co)datatypes [10].
For SMT solvers [22], supporting ﬁrst-class Booleans is a widely accepted
standard [5]. In contrast, the TPTP TFX format [30], intended to promote ﬁrst-
class Booleans in the rest of the automated reasoning community, has yet to gain
traction. Software veriﬁcation tools could clearly beneﬁt from its popularization,
as some of them identify terms and formulas in their logic, e.g., Why3 [12].
In conclusion, we devised a refutationally complete superposition calculus
for ﬁrst-order logic with interpreted Booleans. Its redundancy criterion allows
us to ﬂexibly add inprocessing clausiﬁcation and other simpliﬁcation rules. We
believe our calculus is an excellent choice for the basis of new superposition
provers: it oﬀers the full power of standard superposition, while supporting rich
input languages such as SMT-LIB and TPTP TFX. Even with unoptimized
implementation and basic strategies, our calculus matches the performance of
earlier approaches. In addition, the freedom it oﬀers in term order, literal and
Boolean subterm selection opens possibilities that are yet to be explored. Overall,
our calculus appears as a solid foundation for richer logics in which the Boolean
type cannot be eﬃciently preprocessed, such as higher-order logic [8]. In future
work, we plan to tune the parameters and would ﬁnd it interesting to combine
our calculus with clause splitting techniques, such as AVATAR [32].
Acknowledgment Martin Desharnais and Jasmin Blanchette generated the
Sledgehammer benchmarks. Simon Cruanes helped us with the implementation.
The anonymous reviewers, Ahmed Bhayat, Jasmin Blanchette, and Uwe Wald-
mann suggested textual improvements. The maintainers of StarExec Iowa let us
use their service. We thank them all. Nummelin’s research has received fund-
ing from the Netherlands Organization for Scientiﬁc Research (NWO) under
the Vidi program (project No. 016.Vidi.189.037, Lean Forward). Bentkamp and
Vukmirović’s research has received funding from the European Research Coun-
cil (ERC) under the European Union’s Horizon 2020 research and innovation
program (grant agreement No. 713999, Matryoshka).

References
[1] Leo Bachmair and Harald Ganzinger. Non-clausal resolution and superposition
with selection and redundancy criteria. In Andrei Voronkov, editor, Logic Pro-
gramming and Automated Reasoning (LPAR’92), volume 624 of LNCS, pages
273–284. Springer, 1992.
[2] Leo Bachmair and Harald Ganzinger. Rewrite-based equational theorem proving
with selection and simpliﬁcation. J. Log. Comput., 4(3):217–247, 1994.
[3] Leo Bachmair and Harald Ganzinger. Resolution theorem proving. In John Alan
Robinson and Andrei Voronkov, editors, Handbook of Automated Reasoning, vol-
ume I, pages 19–99. Elsevier and MIT Press, 2001.
[4] Leo Bachmair, Harald Ganzinger, David A. McAllester, and Christopher Lynch.
Resolution theorem proving. In Handbook of Automated Reasoning, pages 19–99.
Elsevier and MIT Press, 2001.
[5] Clark Barrett, Pascal Fontaine, and Cesare Tinelli.
The SMT-LIB Standard:
Version 2.6. Technical report, Department of Computer Science, The University
of Iowa, 2017. Available at www.SMT-LIB.org.
[6] Peter Baumgartner and Uwe Waldmann.
Hierarchic superposition with weak
abstraction. In Maria Paola Bonacina, editor, CADE-24, volume 7898 of LNCS,
pages 39–57. Springer, 2013.
[7] Dan Benanav. Simultaneous paramodulation. In Mark E. Stickel, editor, CADE-
10, volume 449 of LNCS, pages 442–455. Springer, 1990.
[8] Alexander Bentkamp, Jasmin Blanchette, Sophie Tourret, and Petar Vukmirović.
Superposition for full higher-order logic. In André Platzer and GeoﬀSutcliﬀe,
editors, CADE-28, LNCS. Springer, 2021.
[9] Christoph Benzmüller.
Extensional higher-order paramodulation and RUE-
resolution. In Harald Ganzinger, editor, CADE-16, volume 1632 of LNCS, pages
399–413. Springer, 1999.
[10] Jasmin Christian Blanchette, Nicolas Peltier, and Simon Robillard. Superposi-
tion with datatypes and codatatypes. In Didier Galmiche, Stephan Schulz, and
Roberto Sebastiani, editors, IJCAR 2018, volume 10900 of LNCS, pages 370–387.
Springer, 2018.
[11] Simon Cruanes. Extending Superposition with Integer Arithmetic, Structural In-
duction, and Beyond. Ph.D. thesis, École polytechnique, 2015.
[12] Jean-Christophe Filliâtre and Andrei Paskevich. Why3—where programs meet
provers.
In Matthias Felleisen and Philippa Gardner, editors, European Sym-
posium on Programming (ESOP 2013), volume 7792 of LNCS, pages 125–128.
Springer, 2013.
[13] Harald Ganzinger and Jürgen Stuber. Superposition with equivalence reasoning
and delayed clause normal form transformation.
Inf. Comput., 199(1-2):3–23,
2005.
[14] Thomas Hillenbrand and Christoph Weidenbach. Superposition for bounded do-
mains. In Maria Paola Bonacina and Mark E. Stickel, editors, Automated Rea-
soning and Mathematics, volume 7788 of LNCS, pages 68–100. Springer, 2013.
[15] D. E. Knuth and P. B. Bendix.
Simple word problems in universal algebras.
In J. Leech, editor, Computational Problems in Abstract Algebra, pages 263–297.
Pergamon Press, 1970.
[16] Evgenii Kotelnikov, Laura Kovács, Martin Suda, and Andrei Voronkov. A clausal
normal form translation for FOOL. In Christoph Benzmüller, GeoﬀSutcliﬀe, and
Raúl Rojas, editors, Global Conference on Artiﬁcial Intelligence (GCAI 2016),
volume 41 of EPiC, pages 53–71. EasyChair, 2016.
393
Superposition with First-class Booleans and Inprocessing Clausiﬁcation

394
V. Nummelin et al.
[17] Evgenii Kotelnikov, Laura Kovács, and Andrei Voronkov. A ﬁrst class Boolean
sort in ﬁrst-order theorem proving and TPTP.
In Manfred Kerber, Jacques
Carette, Cezary Kaliszyk, Florian Rabe, and Volker Sorge, editors, Intelligent
Computer Mathematics (CICM 2015), volume 9150 of LNCS, pages 71–86.
Springer, 2015.
[18] Laura Kovács and Andrei Voronkov. First-order theorem proving and Vampire.
In Natasha Sharygina and Helmut Veith, editors, Computer Aided Veriﬁcation
(CAV 2013), volume 8044 of LNCS, pages 1–35. Springer, 2013.
[19] Michel Ludwig and Uwe Waldmann. An extension of the Knuth-Bendix ordering
with LPO-like properties.
In Nachum Dershowitz and Andrei Voronkov, edi-
tors, Logic Programming and Automated Reasoning (LPAR 2007), volume 4790
of LNCS, pages 348–362. Springer, 2007.
[20] Zohar Manna and Richard J. Waldinger. A deductive approach to program syn-
thesis. ACM Trans. Program. Lang. Syst., 2(1):90–121, 1980.
[21] Neil V. Murray. Completely non-clausal theorem proving. Artif. Intell., 18(1):67–
85, 1982.
[22] Robert Nieuwenhuis, Albert Oliveras, and Cesare Tinelli. Solving SAT and SAT
modulo theories: From an abstract Davis–Putnam–Logemann–Loveland proce-
dure to DPLL(T). J. ACM, 53(6):937–977, 2006.
[23] Robert Nieuwenhuis and Albert Rubio. Basic superposition is complete. In Bernd
Krieg-Brückner, editor, European Symposium on Programming (ESOP ’92), vol-
ume 582 of LNCS, pages 371–389. Springer, 1992.
[24] Andreas Nonnengart and Christoph Weidenbach. Computing small clause normal
forms. In Handbook of Automated Reasoning, pages 335–367. Elsevier and MIT
Press, 2001.
[25] Visa Nummelin, Alexander Bentkamp, Sophie Tourret, and Petar Vukmirović.
Superposition with ﬁrst-class Booleans and inprocessing clausiﬁcation (techni-
cal report). Technical report, 2021. https://matryoshka-project.github.io/pubs/
boolsup_report.pdf.
[26] Martina Seidl, Florian Lonsing, and Armin Biere.
qbf2epr: A tool for gener-
ating EPR formulas from QBF.
In Pascal Fontaine, Renate A. Schmidt, and
Stephan Schulz, editors, Practical Aspects of Automated Reasoning (PAAR-2012),
volume 21 of EPiC Series in Computing, pages 139–148. EasyChair, 2012.
[27] Alexander Steen.
Extensional Paramodulation for Higher-order Logic and Its
Eﬀective Implementation Leo-III.
Dissertationen zur künstlichen Intelligenz.
Akademische Verlagsgesellschaft AKA GmbH, 2018.
[28] Aaron Stump, GeoﬀSutcliﬀe, and Cesare Tinelli. Starexec: A cross-community
infrastructure for logic solving.
In IJCAR 2014, volume 8562 of LNCS, pages
367–373. Springer, 2014.
[29] GeoﬀSutcliﬀe. The TPTP problem library and associated infrastructure—from
CNF to TH0, TPTP v6.4.0. J. Autom. Reason., 59(4):483–502, 2017.
[30] GeoﬀSutcliﬀe and Evgenii Kotelnikov. TFX: the TPTP extended typed ﬁrst-
order form. In Boris Konev, Josef Urban, and Philipp Rümmer, editors, Practical
Aspects of Automated Reasoning (PAAR-2018), volume 2162 of CEUR Workshop
Proceedings, pages 72–87. CEUR-WS.org, 2018.
[31] Grigori Tseitin. On the complexity of derivation in propositional calculus. In
Automation of reasoning: Classical Papers on Computational Logic, volume 2,
pages 466–483. Springer, 1983.
[32] Andrei Voronkov. AVATAR: the architecture for ﬁrst-order theorem provers. In
CAV 2014, volume 8559 of LNCS, pages 696–710. Springer, 2014.

[33] Petar Vukmirović and Visa Nummelin. Boolean reasoning in a higher-order su-
perposition prover. In Pascal Fontaine, Konstantin Korovin, Ilias S. Kotsireas,
Philipp Rümmer, and Sophie Tourret, editors, Practical Aspects of Automated
Reasoning (PAAR-2020), volume 2752 of CEUR Workshop Proceedings, pages
148–166. CEUR-WS.org, 2020.
[34] Petar Vukmirović, Jasmin Blanchette, Simon Cruanes, and Stephan Schulz. Ex-
tending a brainiac prover to lambda-free higher-order logic. Accepted in Interna-
tional Journal on Software Tools for Technology Transfer.
[35] Uwe Waldmann, Sophie Tourret, Simon Robillard, and Jasmin Blanchette.
A
comprehensive framework for saturation theorem proving. In Nicolas Peltier and
Viorica Sofronie-Stokkermans, editors, IJCAR 2020, LNCS. Springer, 2020.
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.
395
Superposition with First-class Booleans and Inprocessing Clausiﬁcation

Superposition for Full Higher-order Logic
Alexander Bentkamp1
, Jasmin Blanchette1,2,3
,
Sophie Tourret2,3
, and Petar Vukmirovi´c1
1 Vrije Universiteit Amsterdam, Amsterdam, the Netherlands
{a.bentkamp,j.c.blanchette,p.vukmirovic}@vu.nl
2 Université de Lorraine, CNRS, Inria, LORIA, Nancy, France
sophie.tourret@inria.fr
3 Max-Planck-Institut für Informatik, Saarland Informatics Campus, Saarbrücken, Germany
Abstract. We recently designed two calculi as stepping stones towards super-
position for full higher-order logic: Boolean-free λ-superposition and superposi-
tion for ﬁrst-order logic with interpreted Booleans. Stepping on these stones, we
ﬁnally reach a sound and refutationally complete calculus for higher-order logic
with polymorphism, extensionality, Hilbert choice, and Henkin semantics. In ad-
dition to the complexity of combining the calculus’s two predecessors, new chal-
lenges arise from the interplay between λ-terms and Booleans. Our implementa-
tion in Zipperposition outperforms all other higher-order theorem provers and is
on a par with an earlier, pragmatic prototype of Booleans in Zipperposition.
1
Introduction
Superposition is a leading calculus for ﬁrst-order logic with equality. We have been
wondering for some years whether it would be possible to gracefully generalize it to
extensional higher-order logic and use it as the basis of a strong higher-order auto-
matic theorem prover. Towards this goal, we have, together with colleagues, designed
superposition-like calculi for three intermediate logics between ﬁrst-order and higher-
order logic. Now we are ﬁnally ready to assemble a superposition calculus for full
higher-order logic. The ﬁliation of our new calculus from Bachmair and Ganzinger’s
standard ﬁrst-order superposition is as follows:
Standard superposition
Bachmair and Ganzinger [2] (Sup)
Superposition with ←→and delayed CNF
Ganzinger and Stuber [16] (←→Sup)
Superposition with Booleans
Nummelin et al. [23] (oSup)
Boolean-free λ-free superposition
Bentkamp et al. [7] (λfSup)
Boolean-free λ-superposition
Bentkamp et al. [6] (λSup)
Boolean λ-superposition
This paper (oλSup)
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliffe (Eds.): CADE 2021, LNAI 12699, pp. 396–412, 2021.
https://doi.org/10.1007/978-3-030-79876-5_23

Our goal was to devise an efﬁcient calculus for higher-order logic. To achieve it, we
pursued two objectives. First, the calculus should be refutationally complete. Second,
the calculus should coincide as much as possible with its predecessors oSup and λSup
on the respective fragments of higher-order logic (which in turn essentially coincide
with Sup on ﬁrst-order logic). Achieving these objectives is the main contribution of
this paper. We made an effort to keep the calculus simple, but often the refutational
completeness proof forced our hand to add conditions or special cases.
Like oSup, our calculus oλSup operates on clauses that can contain Boolean sub-
terms, and it interleaves clausiﬁcation with other inferences. Like λSup, oλSup eagerly
βη-normalizes terms, employs full higher-order uniﬁcation, and relies on a ﬂuid sub-
term superposition rule (FLUIDSUP) to simulate superposition inferences below applied
variables—i.e., terms of the form yt1 ...tn for n ≥1.
Because oSup contains several superposition-like inference rules for Boolean sub-
terms, our completeness proof requires dedicated ﬂuid Boolean subterm hoisting rules
(FLUIDBOOLHOIST, FLUIDLOOBHOIST), which simulate Boolean inferences below
applied variables, in addition to FLUIDSUP, which simulates superposition inferences.
Due to restrictions related to the term order that parameterizes superposition, it is
difﬁcult to handle variables bound by unclausiﬁed quantiﬁers if these variables occur
applied or in arguments of applied variables. We solve the issue by replacing such quan-
tiﬁed terms ∀y.t by equivalent terms (λy.t) ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈(λy. ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤) in a preprocessing step.
We implemented our calculus in the Zipperposition prover and evaluated it on TPTP
and Sledgehammer benchmarks. The new Zipperposition outperforms all other higher-
order provers and is on a par with an ad hoc implementation of Booleans in the same
prover by Vukmirovi´c and Nummelin [30]. We refer to the technical report [8] for the
completeness proof and a more detailed account of the calculus and its evaluation.
2
Logic
Our logic is higher-order logic (simple type theory) with rank-1 polymorphism, Hilbert
choice, and functional and Boolean extensionality. Its syntax mostly follows Gordon
and Melham [17]. We use the notation ¯an or ¯a to stand for the tuple (a1,...,an) where
n ≥0. Deviating from Gordon and Melham, type arguments are explicit, written as
c⟨¯τm⟩for a symbol c : Π¯αm. υ and types ¯τm. In the type signature Σty, we require the
presence of a nullary Boolean type constructor o and a binary function type constructor
→. In the term signature Σ, we require the presence of the logical symbols ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬, ∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧,
∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨, →
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→, ∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀, ∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃, ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈, and ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈. The logical symbols are shown in bold to distinguish them from
the notation used for clauses below. Moreover, we require the presence of the Hilbert
choice operator ε ∈Σ. Although ε is interpreted in our semantics, we do not consider
it a logical symbol. Our calculus will enforce the semantics of ε by an axiom, whereas
the semantics of the logical symbols will be enforced by inference rules. We write V for
the set of (term) variables. We use Henkin semantics, in the style of Fitting [15], with
respect to which we can prove our calculus refutationally complete. In summary, our
logic essentially coincides with the TPTP TH1 format [20].
We generally view terms modulo αβη-equivalence. When deﬁning operations that
need to analyze the structure of terms, however, we use a custom normal form as the
Superposition for Full Higher-order Logic
397

398
A. Bentkamp et al.
default representative of a βη-equivalence class: The βηQη-normal form t↓βηQη of a
term t is obtained by bringing the term into η-short β-normal form and ﬁnally apply-
ing the rewrite rule Q⟨τ⟩s −■
→Qη Q⟨τ⟩(λx. s x) exhaustively whenever s is not a λ-
expression. Here and elsewhere, Q stands for either ∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀or ∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃.
On top of the standard higher-order terms, we install a clausal structure that allows
us to formulate calculus rules in the style of ﬁrst-order superposition. A literal s ˙≈t is
an equation s ≈t or disequation s ̸≈t of terms s and t; both equations and disequations
are unordered pairs. A clause L1 ∨···∨Ln is a ﬁnite multiset of literals Lj. The empty
clause is written as ⊥. This clausal structure does not restrict the logic, because an
arbitrary term t of Boolean type can be written as the clause t ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤.
We considered excluding negative literals by encoding them as (s ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈t) ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, fol-
lowing ←→Sup [16]. However, this approach would make the conclusion of the equality
factoring rule (EFACT) too large for our purposes. Regardless, the simpliﬁcation ma-
chinery will allow us to reduce negative literals t ̸≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥and t ̸≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤to t ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤and t ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥,
respectively, thereby eliminating redundant representations of nonequational literals.
We let CSU(s,t) denote an arbitrary (preferably, minimal) complete set of uniﬁers
for two terms s and t on the set of free variables of the clauses in which s and t occur.
To compute such sets, Huet-style preuniﬁcation [18] is not sufﬁcient, and we must re-
sort to a full uniﬁcation procedure [19, 29]. To cope with the nontermination of such
procedures, we use dovetailing as described by Vukmirovi´c et al. [28, Sect. 5].
Some of the rules in our calculus introduce Skolem symbols, representing objects
mandated by existential quantiﬁcation. We assume that these symbols do not occur in
the input problem. More formally, given a problem over a term signature Σ, our calculus
operates on a Skolem-extended term signature Σsk that, in addition to all symbols from
Σ, inductively contains symbols skΠ¯α. ∀¯x.∃z.t z : Π¯α. ¯τ →υ for all types υ, variables z : υ,
and terms t : υ →o over Σsk, where ¯α are the free type variables occurring in t and ¯x : ¯τ
are the free term variables occurring in t, both in order of ﬁrst occurrence.
3
The Calculus
The oλSup calculus closely resembles λSup, augmented with rules for Boolean reason-
ing that are inspired by oSup. As in λSup, superposition-like inferences are restricted
to certain ﬁrst-order-like subterms, the green subterms, which we deﬁne inductively as
follows: Every term t is a green subterm of t, and for all symbols f ∈Σ \ {∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀,∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃}, if t is
a green subterm of ui for some i, then t is a green subterm of f⟨¯τ⟩¯u. For example, the
green subterms of f (g(¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬p))(∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀⟨τ⟩(λx.q))(ya)(λx.hb) are the term itself, g(¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬p), ¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬p,
p, ∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀⟨τ⟩(λx.q), ya, and λx.hb. We write s t to denote a term s with a green subterm t
and call the ﬁrst-order-like context s
a green context.
Following λSup, we call a term t ﬂuid if (1) t↓βηQη is of the form y ¯un where n ≥1,
or (2) t↓βηQη is a λ-expression and there exists a substitution σ such that tσ↓βηQη is
not a λ-expression (due to η-reduction). Intuitively, ﬂuid terms are terms whose normal
form can change radically as a result of instantiation.
We deﬁne deeply occurring variables as in λSup, but exclude λ-expressions directly
below quantiﬁers: A variable occurs deeply in a clause C if it occurs inside an argument
of an applied variable or inside a λ-expression that is not directly below a quantiﬁer.

Preprocessing. Our completeness theorem requires that quantiﬁed variables do not
appear in certain higher-order contexts. We use preprocessing to eliminate problematic
occurrences of quantiﬁers. The rewrite rules ∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀≈and ∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃≈, which we collectively denote
by Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈, are deﬁned as ∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀⟨τ⟩−■
→∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀≈λy.y ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈(λx. ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤) and ∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃⟨τ⟩−■
→∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃≈λy.y ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈(λx. ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) where
the rewritten occurrence of Q⟨τ⟩is unapplied or has an argument of the form λx.v such
that x occurs as a nongreen subterm of v. If either of these rewrite rules can be applied
to a given term, the term is Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-reducible; otherwise, it is Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normal.
For example, the term λy.∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃⟨ι →ι⟩(λx.g xy(zy)(f x)) is Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normal. A term may be
Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-reducible because a quantiﬁer appears unapplied (e.g., g ∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃⟨ι⟩); a quantiﬁed variable
occurs applied (e.g., ∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃⟨ι →ι⟩(λx. x a)); a quantiﬁed variable occurs inside a nested λ-
expression (e.g., ∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀⟨ι⟩(λx. f (λy. x))); or a quantiﬁed variable occurs in the argument
of a variable, either a free variable (e.g., ∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀⟨ι⟩(λx. z x)) or a variable bound above the
quantiﬁer (e.g., λy. ∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃⟨ι⟩(λx.y x)).
A preprocessor Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normalizes the input problem. Although inferences may pro-
duce Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-reducible clauses, we do not Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normalize during the derivation process it-
self. Instead, Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-reducible ground instances of clauses will be considered redundant by
the redundancy criterion. Thus, clauses whose ground instances are all Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-reducible
can be deleted. However, there are Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-reducible clauses, such as x ∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀⟨ι⟩≈a, that nev-
ertheless have Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normal ground instances. Such clauses must be kept because the
completeness proof relies on their Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normal ground instances.
In principle, we could omit the side condition of the Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-rewrite rules and eliminate
all quantiﬁers. However, the calculus (especially, the redundancy criterion) performs
better with quantiﬁers than with λ-expressions, which is why we restrict Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normaliza-
tion as much as the completeness proof allows. Extending the preprocessing to elimi-
nate all Boolean terms as in Kotelnikov et al. [21] does not work for higher-order logic
because Boolean terms can contain variables bound by enclosing λ-expressions.
Term Order. The calculus is parameterized by a well-founded strict total order ≻on
ground terms satisfying these four criteria: (O1) compatibility with green contexts—
i.e., s′ ≻s implies t s′ ≻t s ; (O2) green subterm property—i.e. t s ⪰s where ⪰is
the reﬂexive closure of ≻; (O3) u ≻⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≻⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤for all terms u /∈{⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤,⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥}; (O4) Q⟨τ⟩t ≻t u
for all types τ, terms t, and terms u such that Q⟨τ⟩t and u are Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normal and the only
Boolean green subterms of u are ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤and ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥. The restriction of (O4) to Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normal terms
ensures that term orders fulﬁlling the requirements exist, but it forces us to preprocess
the input problem. We extend ≻to literals and clauses via the multiset extensions in the
standard way [2, Sect. 2.4].
For nonground terms, ≻is required to be a strict partial order such that t ≻s implies
tθ ≻sθ for all grounding substitutions θ. As in λSup, we also introduce a nonstrict
variant ≿for which we require that tθ ⪰sθ for all grounding substitutions θ whenever
t ≿s, and similarly for literals and clauses.
To construct a concrete order fulﬁlling these requirements, we deﬁne an encoding
into untyped ﬁrst-order terms, and compare these using a variant of the Knuth–Bendix
order. In a ﬁrst step, denotedO, the encoding translates ﬂuid terms t as fresh variables zt;
nonﬂuid λ-expressions λx:τ. u as lam(O(τ),O(u)); applied quantiﬁers Q⟨τ⟩(λx:τ. u) as
Q1(O(τ),O(u)); and other terms f⟨¯τ⟩¯uk as fk(O(¯τ),O(¯uk)). Bound variables are encoded
as constants dbi corresponding to De Bruijn indices. In a second step, denoted P, the
399
Superposition for Full Higher-order Logic

400
A. Bentkamp et al.
encoding replaces Q1 by Q′
1 and variables z by z′ whenever they occur below lam. For
example, ∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀⟨ι⟩(λx.pyy(λu.f yy(∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀⟨ι⟩(λv.u)))) is encoded as ∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀1(ι,p3(y,y,lam(o,f3(y′,y′,
∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀′
1(ι,db1))))). The ﬁrst-order terms can then be compared using a transﬁnite Knuth–
Bendix order ≻kb [22]. Let the weight of ∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀1 and ∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃1 be ω, the weight of ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤0 and ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥0
be 1, and the weights of all other symbols be less than ω. Let the precedence > be
total and ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥0,⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤0 be the symbols of lowest precedence, with ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥0 > ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤0. Then let t ≻s if
O(P(t)) ≻kb O(P(s)) and t ≿s if O(P(t)) ⪰kb O(P(s)).
Selection Functions. The calculus is also parameterized by a literal selection function
and a Boolean subterm selection function. We deﬁne an element x of a multiset M to be
⊵-maximal for some relation ⊵if for all y ∈M with y⊵x, we have y = x. It is strictly
⊵-maximal if it is ⊵-maximal and occurs only once in M.
The literal selection function HLitSel maps each clause to a subset of selected lit-
erals. A literal may not be selected if it is positive and neither side is ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥. Moreover, a
literal L y may not be selected if y ¯un, with n ≥1, is a ⪰-maximal term of the clause.
The Boolean subterm selection function HBoolSel maps each clause C to a subset
of selected subterms in C. Selected subterms must be green subterms of Boolean type.
Moreover, a subterm s must not be selected if s = ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, if s = ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, if s is a variable-headed
term, if s is at the topmost position on either side of a positive literal, or if s contains a
variable y as a green subterm, and y ¯un, with n ≥1, is a ⪰-maximal term of the clause.
Eligibility. A literal L is (strictly) eligible w.r.t. a substitution σ in C if it is selected
in C or there are no selected literals and no selected Boolean subterms in C and Lσ is
(strictly) ≿-maximal in Cσ.
The eligible subterms of a clause C w.r.t. a substitution σ are inductively deﬁned as
follows: Any selected subterm is eligible. If a literal L = s ˙≈t with sσ ̸≾tσ is either
eligible and negative or strictly eligible and positive, then the subterm s is eligible. If a
subterm t is eligible and the head of t is not ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈or ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈, all direct green subterms of t are
eligible. If a subterm t is eligible and t is of the form u ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈v or u ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈v, then u is eligible if
uσ ̸≾vσ and v is eligible if uσ ̸≿vσ.
The Core Inference Rules. The calculus consists of the following core inference rules.
The ﬁrst ﬁve rules stem from λSup, with minor adaptions concerning Booleans:
D



D′ ∨t ≈t′
C u
SUP
(D′ ∨C t′ )σ
C



C′ ∨u ̸≈u′
ERES
C′σ
C



C′ ∨u′ ≈v′ ∨u ≈v
EFACT
(C′ ∨v ̸≈v′ ∨u ≈v′)σ
D



D′ ∨t ≈t′
C u
FLUIDSUP
(D′ ∨C zt′ )σ
C



C′ ∨s ≈s′
ARGCONG
C′σ ∨sσ ¯xn ≈s′σ ¯xn
SUP 1. u is not ﬂuid; 2. u is not a variable deeply occurring in C; 3. if u is a variable y,
there must exist a grounding substitution θ such that tσθ ≻t′σθ and Cσθ ≺C′′σθ,
where C′′ = C{y →t′}; 4. σ ∈CSU(t,u); 5. tσ ̸≾t′σ; 6. u is eligible in C w.r.t. σ;
7. Cσ ̸≾Dσ; 8. t ≈t′ is strictly eligible in D w.r.t. σ; 9. tσ is not a fully applied
logical symbol; 10. if t′σ = ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, the subterm u is at the top level of a positive literal.

ERES 1. σ ∈CSU(u,u′); 2. u ̸≈u′ is eligible in C w.r.t. σ.
EFACT 1. σ ∈CSU(u,u′); 2. uσ ̸≾vσ; 3. (u ≈v)σ is ≿-maximal in Cσ; 4. uσ ̸≾vσ;
5. nothing is selected in C.
FLUIDSUP 1. u is a variable deeply occurring in C or u is ﬂuid; 2. z is a fresh variable;
3. σ ∈CSU(zt, u); 4. (zt′)σ ̸= (zt)σ; 5.–10. as for SUP.
ARGCONG 1. n > 0; 2. σ is the most general type substitution that ensures well-
typedness of the conclusion for a given n; 3. ¯xn is a tuple of distinct fresh variables;
4. the literal s ≈s′ is strictly eligible in C w.r.t. σ.
The following rules are concerned with Boolean reasoning and originate from oSup.
They have been adapted to support polymorphism and applied variables.
C u
BOOLHOIST
(C ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨u ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤)σ
C u
EQHOIST
(C ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨x ≈y)σ
C u
NEQHOIST
(C ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨x ≈y)σ
C u
FORALLHOIST
(C ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨y x ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤)σ
C u
EXISTSHOIST
(C ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨y x ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥)σ
C



C′ ∨s ≈s′
FALSEELIM
C′σ
C u
BOOLRW
C t′ σ
C u
FORALLRW
C y(skΠ¯α. ∀¯x.∃z.¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬yσz⟨¯α⟩¯x) σ
C u
EXISTSRW
C y(skΠ¯α. ∀¯x.∃z.yσz⟨¯α⟩¯x) σ
BOOLHOIST 1. σ is a type uniﬁer of the type of u with the Boolean type o (i.e., the
identity if u is Boolean or {α →o} if u is of type α for some type variable α);
2. the head of u is neither a variable nor a logical symbol; 3. u is eligible in C;
4. the occurrence of u is not at the top level of a positive literal.
EQHOIST, NEQHOIST, FORALLHOIST, EXISTSHOIST 1. σ ∈CSU(u, x ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈y), σ ∈
CSU(u, x ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈y), σ ∈CSU(u, ∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀⟨α⟩y), or σ ∈CSU(u, ∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃⟨α⟩y), respectively; 2. x,
y, and α are fresh variables; 3. u is eligible in C w.r.t. σ; 4. if the head of u is
a variable, it must be applied and the affected literal must be of the form u ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤,
u ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, or u ≈v where v is a variable-headed term.
FALSEELIM 1. σ ∈CSU(s ≈s′, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤); 2. s ≈s′ is strictly eligible in C w.r.t. σ.
BOOLRW 1. σ ∈CSU(t,u) and (t,t′) is one of the following pairs, where y is a fresh
variable: (¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥), (⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥), (⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥), (⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥), (⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤),
(⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥), (⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥), (⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (y ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈y, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), (y ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈y, ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥); 2. u is not a variable; 3. u is eligible in
C w.r.t. σ; 4. if the head of u is a variable, it must be applied and the affected literal
must be of the form u ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, u ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, or u ≈v where v is a variable-headed term.
FORALLRW, EXISTSRW 1. σ ∈CSU(∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀⟨β⟩y, u) and σ ∈CSU(∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃⟨β⟩y, u), respectively,
where β is a fresh type variable, y is a fresh term variable, ¯α are the free type vari-
ables and ¯x are the free term variables occurring in yσ in order of ﬁrst occurrence;
401
Superposition for Full Higher-order Logic

402
A. Bentkamp et al.
2. u is not a variable; 3. u is eligible in C w.r.t. σ; 4. if the head of u is a variable, it
must be applied and the affected literal must be of the form u ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, u ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, or u ≈v
where v is a variable-headed term; 5. for FORALLRW, the indicated occurrence of
u is not in a literal u ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, and for EXISTSRW, the indicated occurrence of u is not
in a literal u ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥.
Like SUP, also the Boolean rules must be simulated in ﬂuid terms. The following
rules are Boolean counterparts of FLUIDSUP:
C u
FLUID-
BOOLHOIST
(C z ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨x ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤)σ
C u
FLUID-
LOOBHOIST
(C z ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨x ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥)σ
FLUIDBOOLHOIST 1. u is ﬂuid; 2. z and x are fresh variables; 3. σ ∈CSU(z x, u);
4. (z ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥)σ ̸= (z x)σ; 5. xσ ̸= ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤and xσ ̸= ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥; 6. u is eligible in C w.r.t. σ.
FLUIDLOOBHOIST Like the above but with ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥replaced by ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤in condition 4.
In addition to the inference rules, our calculus relies on two axioms, below. Ax-
iom (EXT), from λSup, embodies functional extensionality; the expression diﬀ⟨α,β⟩
abbreviates skΠαβ. ∀zy.∃x.z x̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸̸≈y x⟨α,β⟩. Axiom (CHOICE) characterizes the Hilbert choice
operator ε.
z(diﬀ⟨α,β⟩zy) ̸≈y(diﬀ⟨α,β⟩zy) ∨z ≈y
(EXT)
y x ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨y(ε⟨α⟩y) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
(CHOICE)
Rationale for the Rules. Most of the calculus’s rules are adapted from its precursors.
SUP, ERES, and EFACT are already present in Sup, with slightly different side con-
ditions. Notably, as in λfSup and λSup, SUP inferences are required only into green
contexts. Other subterms are accessed indirectly via ARGCONG and (EXT).
The rules BOOLHOIST, EQHOIST, NEQHOIST, FORALLHOIST, EXISTSHOIST,
FALSEELIM, BOOLRW, FORALLRW, and EXISTSRW, concerned with Boolean rea-
soning, stem from oSup, which was inspired by ←→Sup. Except for BOOLHOIST and
FALSEELIM, these rules have a condition stating that “if the head of u is a variable, it
must be applied and the affected literal must be of the form u ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤, u ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥, or u ≈v
where v is a variable-headed term.” The inferences at variable-headed terms permitted
by this condition are our form of primitive substitution [1,18], a mechanism that blindly
substitutes logical connectives and quantiﬁers for variables z with a Boolean result type.
Example 1. Our calculus can prove that Leibniz equality implies equality (i.e., if two
values behave the same for all predicates, they are equal) as follows:
a ̸≈b
za ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨zb ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
EQHOIST
(xa ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈ya) ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨xb ≈yb
BOOLRW
⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨wabb ≈wbab
FALSEELIM
⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨wabb ≈wbab
FALSEELIM
wabb ≈wbab
SUP
a ̸≈a
ERES
⊥

The EQHOIST inference, applied on zb, illustrates how our calculus introduces logical
symbols without a dedicated primitive substitution rule. Although ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈does not appear in
the premise, we still need to apply EQHOIST on z b with CSU(z b, x0 ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈y0) = {{z →
λv. x v ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈y v, x0 →x b, y0 →yb}}. Other calculi [1,9,18,26] would apply an explicit
primitive substitution rule instead, yielding essentially (xa ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈ya) ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨(xb ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈yb) ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤.
However, in our approach this clause is subsumed and could be discarded immediately.
By hoisting the equality to the clausal level, we bypass the redundancy criterion.
Next, BOOLRW can be applied to xa ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈ya with CSU(xa ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈ya, y0 ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈y0) = {{x →
λv.wavv, y →λv.wvav, y0 →waaa}}. The two FALSEELIM steps remove the ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
literals. Then SUP is applicable with the uniﬁer {w →λx1 x2 x3. x2} ∈CSU(b, wabb),
and ERES derives the contradiction.
Like in λSup, the FLUIDSUP rule is responsible for simulating superposition in-
ferences below applied variables, other ﬂuid terms, and deeply occurring variables.
Complementarily, FLUIDBOOLHOIST and FLUIDLOOBHOIST simulate the various
Boolean inference rules below ﬂuid terms. Initially, we considered adding a ﬂuid ver-
sion of each rule that operates on Boolean subterms, but we discovered that FLUID-
BOOLHOIST and FLUIDLOOBHOIST sufﬁce to achieve refutational completeness.
Example 2. The clause set consisting of h(yb) ̸≈h(g ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ∨h(ya) ̸≈h(g ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤) and a ̸≈b
highlights the need for FLUIDBOOLHOIST and its companion. The set is unsatisﬁ-
able because the instantiation {y →λx.g (x ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈a)} produces the clause h(g (b ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈a)) ̸≈
h(g ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ∨h(g (a ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈a)) ̸≈h(g ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤), which is unsatisﬁable in conjunction with a ̸≈b.
The literal selection function can select either literal in the ﬁrst clause. ERES is
applicable in either case, but the uniﬁers {y →λx.g ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥} and {y →λx.g ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤} do not lead
to a contradiction. Instead, we need to apply FLUIDBOOLHOIST if the ﬁrst literal is
selected or FLUIDLOOBHOIST if the second literal is selected. In the ﬁrst case, the
derivation is as follows:
a ̸≈b
h(yb) ̸≈h(g ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ∨h(ya) ̸≈h(g ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤)
FLUIDBOOLHOIST
h(z′ b ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ̸≈h(g ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥) ∨h(z′ a(x′a)) ̸≈h(g ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤) ∨x′ b ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
ERES
h(g (x′ a)) ̸≈h(g ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤) ∨x′ b ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
EQHOIST
h(g (x′′ a ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈x′′′ a)) ̸≈h(g ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤) ∨⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨x′′ b ≈x′′′ b
SUP
h(g (a ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈x′′′ a)) ̸≈h(g ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤) ∨⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨a ̸≈x′′′ b
BOOLRW
h(g ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤) ̸≈h(g ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤) ∨⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨a ̸≈a
ERES
⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨a ̸≈a
ERES
⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
FALSEELIM
⊥
The FLUIDBOOLHOIST inference uses the uniﬁer {y →λu.z′ u(x′ u), z →λu.z′ bu,
x →x′ b} ∈CSU(z x, yb). We apply ERES to the ﬁrst literal of the resulting clause, with
uniﬁer {z′ →λuv. g v} ∈CSU(h (z′ b ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥), h (g ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥)). Next, we apply EQHOIST with the
uniﬁer {x′ →λu. x′′ u ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈x′′′ u, w →x′′ b, w′ →x′′′ b} ∈CSU(x′ b, w ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈w′) to the literal
403
Superposition for Full Higher-order Logic

404
A. Bentkamp et al.
created by FLUIDBOOLHOIST, effectively performing a primitive substitution. The re-
sulting clause can superpose into a ̸≈b with the uniﬁer {x′′ →λu. u} ∈CSU(x′′ b, b).
The two sides of the interpreted equality in the ﬁrst literal can then be uniﬁed, allowing
us to apply BOOLRW with the uniﬁer {y →a, x′′′ →λu. a} ∈CSU(y ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈y, a ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈x′′′ b).
Finally, applying ERES twice and FALSEELIM once yields the empty clause.
Remarkably, none of the provers that participated in the CASC-J10 competition can
solve this two-clause problem within a minute. Satallax ﬁnds a proof after 72 s and
LEO-II after over 7 minutes. Our new Zipperposition implementation solves it in 3 s.
The Redundancy Criterion. In ﬁrst-order superposition, a clause is considered re-
dundant if all its ground instances are entailed by ≺-smaller ground instances of other
clauses. In essence, this will also be our deﬁnition, but we will use a different notion of
ground instances and a different notion of entailment.
Given a clause C, let its ground instances G(C) be the set of all clauses of the form
Cθ for some substitution θ such that Cθ is ground and Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normal, and for all variables x
occurring in C, the only Boolean green subterms of xθ are ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤and ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥. The rationale of this
deﬁnition is to ensure that ground instances of the conclusion of FORALLHOIST, EX-
ISTSHOIST, FORALLRW, and EXISTSRW inferences are smaller than the correspond-
ing instances of their premise by property (O4).
The redundancy criterion’s notion of entailment is deﬁned via an encoding into a
weaker logic, following λfSup and λSup. In this paper, the weaker logic is ground ﬁrst-
order logic with interpreted Booleans—the ground fragment of the logic of oSup. Its
signature (Σty,ΣGF) is derived from our higher-order signature (Σty,Σ) as follows. The
type constructors Σty are the same in both signatures, but →is an uninterpreted type
constructor in ﬁrst-order logic. For each ground instance f⟨¯υ⟩: τ1 →··· →τn →τ of a
symbol f ∈Σ, we introduce a ﬁrst-order symbol f ¯υ
j ∈ΣGF with argument types ¯τj and
result type τj+1 →··· →τn →τ, for each j. Moreover, for each ground term λx.t, we
introduce a symbol lamλx.t ∈ΣGF of the same type. The symbols ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥0, ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤0, ¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬1, ∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧∧2, ∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨2,
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→2, ≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈τ
2, and ̸≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≉≈τ
2 are identiﬁed with the corresponding ﬁrst-order logical symbols.
We deﬁne an encoding F of Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normal ground higher-order terms into this ground
ﬁrst-order logic recursively as follows: F(∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀⟨τ⟩(λx.t)) = ∀x.F(t) and F(∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃⟨τ⟩(λx.t)) =
∃x.F(t) for applied quantiﬁers; F(λx.t) = lamλx.t for λ-expressions; and F(f⟨¯υ⟩¯sj) =
f ¯υ
j (F(¯sj)) for other terms. For quantiﬁed variables, we deﬁne F(x) = x. Here, Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-
normality is crucial to ensure that bound variables do not occur applied or within λ-
expressions. The deﬁnition of green subterms is devised such that green subterms cor-
respond to ﬁrst-order subterms via the encoding F , with the exception of ﬁrst-order
subterms below quantiﬁers. The encoding F is extended to clauses by mapping each
literal and each side of a literal individually. From the entailment relation |= for the
ground ﬁrst-order logic, we derive an entailment relation |=F on Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normal ground
higher-order clauses by deﬁning M |=F N if F(M) |= F(N). This relation is weaker
than standard higher-order entailment; for example, {f ≈g} ̸|=F {f a ≈g a} (because
of the subscripts added by F ) and {p (λx. ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤)} ̸|=F {p (λx. ¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬ ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥)} (because of the lam
symbols used by F ).
Using |=F , we deﬁne a clause C to be redundant w.r.t. a clause set N if for every
D ∈G(C), we have {E ∈G(N) | E ≺D} |=F D or there exists a clause C′ ∈N such that
C ⊐C′ and D ∈G(C′). The tiebreaker ⊐can be an arbitrary well-founded partial order

on clauses; in practice, we use a well-founded restriction of the ill-founded strict sub-
sumption relation [6, Sect. 3.4]. We denote the set of redundant clauses w.r.t. a clause set
N by RedC(N). Note that |=F is weak enough to ensure that the ARGCONG inference
rule and axiom (EXT) are not immediately redundant and can fulﬁll their purpose.
For ﬁrst-order superposition, an inference is considered redundant if for each of
its ground instances, a premise is redundant or the conclusion is entailed by clauses
smaller than the main premise. For most inference rules, our deﬁnition follows this idea,
using |=F for entailment; other rules need nonstandard notions of ground instances and
redundancy. The deﬁnition of inference redundancy presented below is simpler than the
more sophisticated notion in our technical report. Nonetheless, the redundant inferences
below are a strict subset of the redundant inferences of our report and thus completeness
also holds using the notion below. For the few prover optimizations based on inference
redundancy that we know about (e.g., simultaneous superposition [4]), the following
criterion sufﬁces.
For SUP, ERES, EFACT, BOOLHOIST, FALSEELIM, EQHOIST, NEQHOIST, and
BOOLRW, we deﬁne ground instances as usual: Ground instances are all inferences
obtained by applying a grounding substitution to premises and conclusion such that the
result adheres to the conditions of the given rule w.r.t. selection functions that select lit-
erals and subterms as in the original premise. For FLUIDSUP and FLUIDBOOLHOIST,
we deﬁne ground instances in the same way except that we require that ground in-
stances adhere to the conditions of SUP or BOOLHOIST, respectively. For FORALLRW,
EXISTSRW, FORALLHOIST, EXISTSHOIST, which do not have ground instances in the
sense above, we deﬁne a ground instance as any inference that is obtained by applying
the uniﬁer σ to the premise and then applying a grounding substitution to premise and
conclusion, regardless of whether the resulting inference is an inference of our calculus.
For all rules except FLUIDLOOBHOIST and ARGCONG, we deﬁne an inference to
be redundant w.r.t. a clause set N if for each ground instance ι, a premise of ι is re-
dundant w.r.t. G(N) or the conclusion of ι is entailed w.r.t. |=F by clauses from G(N)
that are smaller than the main (i.e., rightmost) premise of ι. For the rules FLUIDLOOB-
HOIST and ARGCONG, as well as axioms (EXT) and (CHOICE)—viewed as premise-
less inferences—we deﬁne an inference to be redundant w.r.t. a clause set N if all
ground instances of its conclusion are contained in G(N) or redundant w.r.t. G(N).
We denote the set of redundant inferences w.r.t. N by RedI(N).
Simpliﬁcation Rules. Our redundancy criterion is strong enough to support counter-
parts of most simpliﬁcation rules implemented in Schulz’s ﬁrst-order E [25, Sect. 2.3.1
and 2.3.2]. Deletion of duplicated literals, deletion of resolved literals, syntactic tau-
tology deletion, negative simplify-reﬂect, and clause subsumption adhere to our re-
dundancy criterion. Positive simplify-reﬂect, equality subsumption, and rewriting (de-
modulation) of positive and negative literals are supported if they are applied on green
subterms or on other subterms that are encoded into ﬁrst-order subterms by G and F .
Semantic tautology deletion can be applied as well, using |=F ; moreover, for positive
literals, the rewriting clause must be smaller than the rewritten clause.
Under some circumstances, inference rules can be applied as simpliﬁcations. The
FALSEELIM and BOOLRW rules can be applied as a simpliﬁcation if σ is the identity.
If the head of u is ∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀∀, FORALLHOIST and FORALLRW can both be applied and, together,
405
Superposition for Full Higher-order Logic

406
A. Bentkamp et al.
serve as one simpliﬁcation rule. The same holds for EXISTSHOIST and EXISTSRW if
the head of u is ∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃∃. For all of these rules, the eligibility conditions can be ignored.
Clausiﬁcation. Like oSup, our calculus does not require the input problem to be clausi-
ﬁed during the preprocessing, and it supports higher-order analogues of the three inpro-
cessing clausiﬁcation methods introduced by Nummelin et al. Inner delayed clausi-
ﬁcation relies on our core calculus rules to destruct logical symbols. Outer delayed
clausiﬁcation adds the following clausiﬁcation rules to the calculus:
s ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨C
POSOUTERCLAUS
oc(s,C)
s ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨C
NEGOUTERCLAUS
oc(¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬s,C)
s ≈t ∨C
EQOUTERCLAUS
s ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨t ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨C
s ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨t ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨C
s ̸≈t ∨C
NEQOUTERCLAUS
s ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨t ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨C
s ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨t ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨C
The double bars identify simpliﬁcation rules (i.e., the conclusions make the premise
redundant and can replace it). The ﬁrst two rules require that s has a logical symbol
as its head, whereas the last two require that s and t are Boolean terms other than ⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤
and ⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥. The function oc distributes the logical symbols over the clause C—e.g., oc(s →
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
t, C) = {s ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨t ≈⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤⊤∨C}, and oc(¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬¬(s ∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨t), C) = {s ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨C,t ≈⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥⊥∨C}. It is
easy to check that our redundancy criterion allows us to replace the premise of the
OUTERCLAUS rules with their conclusion. Nonetheless, we apply EQOUTERCLAUS
and NEQOUTERCLAUS as inferences because the premises might be useful in their
original form.
Besides the two delayed clausiﬁcation methods, a third inprocessing clausiﬁcation
method is immediate clausiﬁcation. This clausiﬁes the input problem’s outer Boolean
structure in one swoop, resulting in a set of higher-order clauses. If unclausiﬁed Boolean
terms rise to the top during saturation, the same algorithm is run to clausify them.
Unlike delayed clausiﬁcation, immediate clausiﬁcation is a black box and is un-
aware of the proof state other than the Boolean term it is applied to. Delayed clausiﬁca-
tion, on the other hand, clausiﬁes the term step by step, allowing us to interleave clausiﬁ-
cation with the strong simpliﬁcation machinery of superposition provers. It is especially
powerful in higher-order contexts: Examples such as ypq ̸≈(p ∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨∨q) can be refuted di-
rectly by equality resolution, rather than via more explosive rules on the clausiﬁed form.
4
Refutational Completeness
Our calculus is dynamically refutationally complete for problems in Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normal form.
The full proof can be found in our technical report [8].
Theorem 3 (Dynamic refutational completeness). Let (Ni)i be a derivation—i.e.,
Ni\Ni+1 ⊆RedC(Ni+1) for all i. Let N0 be Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normal and such that N0 |= ⊥. Moreover,
assume that (Ni)i is fair—i.e., all inferences from clauses in the limit inferior 
i

j≥i Nj
are contained in 
i RedI(Ni). Then we have ⊥∈Ni for some i.

Following the completeness proof of λSup, our proof is structured in three levels of
logics. For each, we deﬁne a calculus and show that it is refutationally complete: ground
monomorphic ﬁrst-order logic with an interpreted Boolean type (GF); the Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normal
ground fragment of higher-order logic (GH); and higher-order logic (H).
The logic of the GF level is the ground fragment of oSup’s logic. The GF calculus
is a ground version of oSup, which Nummelin et al. showed refutationally complete. It
consists of ground ﬁrst-order equivalents of our rules, excluding ARGCONG, FLUID-
BOOLHOIST, and FLUIDLOOBHOIST, which are speciﬁc to higher-order logic. The
counterparts to FORALLHOIST and EXISTSHOIST enumerate ground terms instead of
producing free variables, to stay within the ground fragment. For compatibility with the
nonground level, the conclusions of FORALLRW and EXISTSRW cannot contain con-
crete Skolem functions. Instead, the GF calculus is parameterized by a witness function
that can assign an arbitrary term to each occurrence of a quantiﬁer in a clause. This wit-
ness function is used to retrieve the Skolem terms in the GF equivalents of FORALLRW
and EXISTSRW.
On the next level, the GH calculus includes inference rules isomorphic to the GF
rules, transferred to higher-order logic via F −1. Moreover, it contains an ARGCONG
variant that enumerates ground terms instead of introducing fresh variables, as well as
rules enumerating ground instances of axioms (EXT) and (CHOICE). We prove refu-
tational completeness of the GH calculus by constructing a higher-order interpretation
based on the model constructed for the completeness proof of the GF level. This proof
step is analogous to the corresponding step in λSup’s proof, but we must also consider
Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normality and the logical symbols.
To lift completeness to the H level, we use the saturation framework of Waldmann et
al. [31]. The main proof obligation it leaves us to show is that nonredundant GH infer-
ences can be lifted to corresponding nonground H inferences. For this lifting, we must
choose a suitable GH witness function and appropriate GH selection functions for liter-
als and Boolean subterms, given a saturated clause set at the H level and the H selection
functions. Then the saturation framework guarantees static refutational completeness
w.r.t. Herbrand entailment, which is the entailment relation induced by the grounding
function G. We then show that this implies dynamic refutational completeness w.r.t. |=
for Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normal initial clause sets.
5
Implementation
We implemented our calculus in the Zipperposition prover [14], whose OCaml source
code makes it convenient to prototype calculus extensions. Except for the presence
of axioms (EXT) and (CHOICE), the new code gracefully extends Zipperposition’s
implementation of oSup in the sense that oλSup coincides with oSup on ﬁrst-order
problems. The same cannot be said w.r.t. λSup on Boolean-free problems because of
the FLUIDBOOLHOIST and FLUIDLOOBHOIST rules, which are triggered by any ap-
plied variable. From the implementation of λSup, we inherit the given clause proce-
dure, which supports inﬁnitely branching inferences, as well as calculus extensions and
heuristics [28]. From the implementation of oSup, we inherit the simpliﬁcation rule
BOOLSIMP, a mainstay of our Boolean simpliﬁcation machinery.
407
Superposition for Full Higher-order Logic

408
A. Bentkamp et al.
As in the implementation of λSup, we approximate ﬂuid terms as terms that are ei-
ther nonground λ-expressions or terms of the form x ¯sn with n > 0. Two slight, acciden-
tal discrepancies are that we also count variable occurrences below quantiﬁers as deep
and perform EFACT inferences even if the maximal literal is selected. Since we expect
FLUIDBOOLHOIST and FLUIDLOOBHOIST to be highly explosive, we penalize them
and all of their offspring. In addition to various λSup extensions [6, Sect. 5], we also
use all the rules for Boolean reasoning described by Vukmirovi´c and Nummelin [30]
except for the BOOLEF rules.
6
Evaluation
We evaluate the calculus implementation in Zipperposition and compare it with other
higher-order provers. Our experiments were performed on StarExec Miami servers
equipped with Intel Xeon E5-2620 v4 CPUs clocked at 2.10 GHz. We used all 2606
TH0 theorems from the TPTP 7.3.0 library [27] and 1253 “Judgment Day” problems
[12] generated using Sledgehammer (SH) [24] as our benchmark set. An archive con-
taining the benchmarks and the raw evaluation results is publicly available [5].
Calculus Evaluation. In this ﬁrst part, we evaluate selected parameters of Zipperposi-
tion by varying only the studied parameter in a ﬁxed well-performing conﬁguration.
This base conﬁguration disables axioms (CHOICE) and (EXT) and the FLUID- rules. It
uses the uniﬁcation procedure of Vukmirovi´c et al. [29] in its complete variant—i.e.,
the variant that produces a complete set of uniﬁers. It uses none of the early Boolean
rules described by Vukmirovi´c and Nummelin [30]. The preprocessor Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈is disabled
as well. All of the completeness-preserving simpliﬁcation rules listed in Sect. 3 are en-
abled. The conﬁguration uses immediate clausiﬁcation. We set the CPU time limit to
30 s in all three experiments.
In the ﬁrst experiment, we assess the overhead incurred by the FLUID- rules. These
rules unify with a term whose head is a fresh variable. Thus, we expected that they
needed to be tightly controlled to achieve good performance. To test our hypothesis,
we simultaneously modiﬁed the parameters of these three rules. In Figure 1, the off
mode simply disables the rules, the pragmatic mode uses a terminating incomplete uni-
ﬁcation algorithm (the pragmatic variant of Vukmirovi´c et al. [29]), and the complete
mode uses a complete uniﬁcation algorithm. The results show that disabling FLUID-
rules altogether achieves the best performance. However, on TPTP problems, complete
ﬁnds 35 proofs not found by off, and pragmatic ﬁnds 22 proofs not found by off. On
Sledgehammer benchmarks, this effect is much weaker, likely because the Sledgeham-
mer benchmarks require less higher-order reasoning: complete ﬁnds only one new proof
over off, and pragmatic ﬁnds only four.
In the second experiment, we explore the clausiﬁcation methods introduced at the
end of Sect. 3: inner delayed clausiﬁcation, outer delayed clausiﬁcation, and immediate
clausiﬁcation. The modes inner and outer employ oSup’s RENAME rule, which renames
Boolean terms headed by logical symbols using a Tseitin-like transformation if they
occur at least four times in the proof state. Vukmirovi´c and Nummelin [30] observed
that outer clausiﬁcation can greatly help prove higher-order problems, and we expected

off
pragmatic
complete
TPTP
1642
1591
1619
SH
467
431
437
Fig. 1. Evaluation of FLUID- rules
inner
outer
immediate
TPTP
1323
1670
1642
SH
406
470
467
Fig. 2. Evaluation of clausiﬁcation method
off
p = 64 p = 16 p = 4 p = 1
TPTP 1642
1617
1613
1615 1594
SH
467
458
458
459
445
Fig. 3. Evaluation of axiom (CHOICE)
TPTP ofSH SH
CVC4 1.8
1796
680 619
Leo-III 1.5.2
2104
681 621
Vampire 4.5
2131
692 681
Satallax 3.5
2162
573 587
Zip (CASC-J10)
2301
734 736
New Zip
2320
724 720
Fig. 4. Evaluation of all competitive higher-
order provers
it to perform well for our calculus, too. The results are shown in Figure 2. The results
conﬁrm our hypothesis: The outer mode outperforms immediate on both TPTP and
Sledgehammer benchmarks. The inner mode performs worst, but on Sledgehammer
benchmarks, it proves 17 problems beyond the reach of the other two. Interestingly,
several of these problems contain axioms of the form φ →
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→
→ψ, and applying superposition
and demodulation to these axioms is preferable to clausifying them.
In the third experiment, we investigate the effect of axiom (CHOICE), which is nec-
essary to achieve refutational completeness. To evaluate (CHOICE), we either disabled it
in a conﬁguration labeled off or set the axiom’s penalty p to different values. In Zipper-
position, penalties are propagated through inference and simpliﬁcation rules and are
used to increase the heuristic weight of clauses, postponing the selection of penalized
clauses. The results are shown in Figure 3. As expected, disabling (CHOICE), or at least
penalizing it heavily, improves performance. Yet enabling (CHOICE) can be crucial: For
19 TPTP problems, the proofs are found when (CHOICE) is enabled and p = 4, but not
when the rule is disabled. On Sledgehammer problems, this effect is weaker, with only
two new problems proved for p = 4.
Prover Comparison. In this second part, we compare Zipperposition’s performance
with other higher-order provers. Like at CASC-J10, the wall-clock time limit was 120 s,
the CPU time limit was 960 s, and the provers were run on StarExec Miami. We used
the following versions of all systems that took part in the THF division: CVC4 1.8 [3],
Leo-III 1.5.2 [26], Satallax 3.5 [13], and Vampire 4.5 [11]. The developers of Vampire
have informed us that its higher-order schedule is optimized for running on a single
core. As a result, the prover suffers some degradation of performance when running on
multiple cores. We evaluate both the version of Zipperposition that took part in CASC-
J10 (Zip) and the updated version of Zipperposition that supports our new calculus (New
Zip). Zip’s portfolio of prover conﬁgurations is based on λSup and techniques described
by Vukmirovi´c and Nummelin [30]. New Zip’s portfolio is specially designed for our
409
Superposition for Full Higher-order Logic

410
A. Bentkamp et al.
new calculus and optimized for TPTP problems. To assess the performance of Boolean
reasoning, we used Sledgehammer benchmarks generated both with native Booleans
(SH) and with an encoding into Boolean-free higher-order logic (ofSH). For technical
reasons, the encoding also performs λ-lifting, but this minor transformation should have
little impact on results [6, Sect. 7].
The results are shown in Figure 4. The two versions of Zipperposition are ahead
of all other provers on both benchmark sets. This shows that, with thorough parameter
tuning, higher-order superposition outperforms tableaux, which had been the state of
the art in higher-order reasoning for a decade. The updated version of New Zip beats
Zip on TPTP problems but lags behind Zip on Sledgehammer benchmarks as we have
yet to further explore more general heuristics that work well with our new calculus. The
Sledgehammer benchmarks fail to demonstrate the superiority of native Booleans rea-
soning compared with an encoding, and in fact CVC4 and Leo-III perform dramatically
better on the encoded Boolean problems, suggesting that there is room for tuning.
7
Conclusion
We have created a superposition calculus for higher-order logic that is refutationally
complete. Most of the key ideas have been developed in previous work by us and col-
leagues, but combining them in the right way has been challenging. A key idea was to
Q≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈≈-normalize away inconvenient terms.
Unlike earlier refutationally complete calculi for full higher-order logic based on
resolution or paramodulation, our calculus employs a term order, which restricts the
proof search, and a redundancy criterion, which can be used to add various simpliﬁca-
tion rules while keeping refutational completeness. These two mechanisms are undoubt-
edly major factors in the success of ﬁrst-order superposition, and it is very fortunate that
we could incorporate both in a higher-order calculus. An alternative calculus with the
same two mechanisms could be achieved by combining oSup with Bhayat and Reger’s
combinatory superposition [10]. The article on λSup [6, Sect. 8] discusses related work
in more detail.
The evaluation results show that our calculus is an excellent basis for higher-order
theorem proving. In future work, we want to experiment further with the different pa-
rameters of the calculus (for example, with Boolean subterm selection heuristics) and
implement it in a state-of-the-art prover such as E.
Acknowledgment. Uwe Waldmann provided advice and carefully checked the com-
pleteness proof. Visa Nummelin led the design of the oSup calculus. Simon Cruanes
helped us with the implementation. Martin Desharnais generated the Sledgehammer
benchmarks. Christoph Benzmüller, Ahmed Bhayat, Mathias Fleury, Herman Geuvers,
Giles Reger, Alexander Steen, Mark Summerﬁeld, Geoff Sutcliffe, and the anonymous
reviewers helped us in various ways. We thank them all.
Bentkamp, Blanchette, and Vukmirovi´c’s research has received funding from the
European Research Council (ERC) under the European Union’s Horizon 2020 research
and innovation program (grant agreement No. 713999, Matryoshka). Blanchette’s re-
search has received funding from the Netherlands Organization for Scientiﬁc Research
(NWO) under the Vidi program (project No. 016.Vidi.189.037, Lean Forward).

References
[1] Andrews, P.B.: On connections and higher-order logic. J. Autom. Reason. 5(3), 257–291
(1989)
[2] Bachmair, L., Ganzinger, H.: Rewrite-based equational theorem proving with selection and
simpliﬁcation. J. Log. Comput. 4(3), 217–247 (1994)
[3] Barrett, C.W., Conway, C.L., Deters, M., Hadarean, L., Jovanovic, D., King, T., Reynolds,
A., Tinelli, C.: CVC4. In: CAV. LNCS, vol. 6806, pp. 171–177. Springer (2011)
[4] Benanav, D.: Simultaneous paramodulation. In: Stickel, M.E. (ed.) CADE-10. LNCS,
vol. 449, pp. 442–455. Springer (1990)
[5] Bentkamp, A., Blanchette, J., Tourret, S., Vukmirovi´c, P.: Superposition for full higher-
order logic (supplementary material), https://doi.org/10.5281/zenodo.4534759
[6] Bentkamp, A., Blanchette, J., Tourret, S., Vukmirovi´c, P., Waldmann, U.: Superposition
with lambdas, accepted in J. Autom. Reason. Preprint at https://arxiv.org/abs/2102.00453v1
(2021)
[7] Bentkamp, A., Blanchette, J.C., Cruanes, S., Waldmann, U.: Superposition for lambda-free
higher-order logic. In: Galmiche, D., Schulz, S., Sebastiani, R. (eds.) IJCAR 2018. LNCS,
vol. 10900, pp. 28–46. Springer (2018)
[8] Bentkamp, A., Blanchette, J.C., Tourret, S., Vukmirovi´c, P.: Superposition for full higher-
order logic (technical report). Technical report (2021), https://matryoshka-project.github.
io/pubs/hosup_report.pdf
[9] Benzmüller, C., Paulson, L.C., Theiss, F., Fietzke, A.: LEO-II—A cooperative automatic
theorem prover for higher-order logic. In: Armando, A., Baumgartner, P., Dowek, G. (eds.)
IJCAR 2008. LNCS, vol. 5195, pp. 162–170. Springer (2008)
[10] Bhayat, A., Reger, G.: Set of support for higher-order reasoning. In: Konev, B., Urban, J.,
Rümmer, P. (eds.) PAAR-2018. CEUR Workshop Proceedings, vol. 2162, pp. 2–16. CEUR-
WS.org (2018)
[11] Bhayat, A., Reger, G.: A combinator-based superposition calculus for higher-order logic.
In: Peltier, N., Sofronie-Stokkermans, V. (eds.) IJCAR 2020, Part I. LNCS, vol. 12166, pp.
278–296. Springer (2020)
[12] Böhme, S., Nipkow, T.: Sledgehammer: Judgement Day. In: Giesl, J., Hähnle, R. (eds.)
IJCAR 2010. LNCS, vol. 6173, pp. 107–121. Springer (2010)
[13] Brown, C.E.: Satallax: An automatic higher-order prover. In: Gramlich, B., Miller, D., Sat-
tler, U. (eds.) IJCAR 2012. LNCS, vol. 7364, pp. 111–117. Springer (2012)
[14] Cruanes, S.: Extending Superposition with Integer Arithmetic, Structural Induction, and
Beyond. Ph.D. thesis, École polytechnique (2015)
[15] Fitting, M.: Types, Tableaus, and Gödel’s God. Kluwer (2002)
[16] Ganzinger, H., Stuber, J.: Superposition with equivalence reasoning and delayed clause
normal form transformation. Information and Computation 199(1–2), 3–23 (2005)
[17] Gordon, M.J.C., Melham, T.F. (eds.): Introduction to HOL: A Theorem Proving Environ-
ment for Higher Order Logic. Cambridge University Press (1993)
[18] Huet, G.P.: A mechanization of type theory. In: Nilsson, N.J. (ed.) IJCAI-73. pp. 139–146.
William Kaufmann (1973)
[19] Jensen, D.C., Pietrzykowski, T.: Mechanizing ω-order type theory through uniﬁcation.
Theor. Comput. Sci. 3(2), 123–171 (1976)
[20] Kaliszyk, C., Sutcliffe, G., Rabe, F.: TH1: The TPTP typed higher-order form with rank-1
polymorphism. In: Fontaine, P., Schulz, S., Urban, J. (eds.) PAAR-2016. CEUR Workshop
Proceedings, vol. 1635, pp. 41–55. CEUR-WS.org (2016)
[21] Kotelnikov, E., Kovács, L., Suda, M., Voronkov, A.: A clausal normal form translation for
FOOL. In: Benzmüller, C., Sutcliffe, G., Rojas, R. (eds.) GCAI 2016. EPiC, vol. 41, pp.
53–71. EasyChair (2016)
411
Superposition for Full Higher-order Logic

412
A. Bentkamp et al.
[22] Ludwig, M., Waldmann, U.: An extension of the Knuth-Bendix ordering with LPO-like
properties. In: Dershowitz, N., Voronkov, A. (eds.) LPAR-14. LNCS, vol. 4790, pp. 348–
362. Springer (2007)
[23] Nummelin, V., Bentkamp, A., Tourret, S., Vukmirovi´c, P.: Superposition with ﬁrst-class
Booleans and inprocessing clausiﬁcation. In: Platzer, A., Sutcliffe, G. (eds.) CADE-28.
LNCS, Springer (2021)
[24] Paulson, L.C., Blanchette, J.C.: Three years of experience with Sledgehammer, a practi-
cal link between automatic and interactive theorem provers. In: Sutcliffe, G., Schulz, S.,
Ternovska, E. (eds.) IWIL-2010. EPiC, vol. 2, pp. 1–11. EasyChair (2012)
[25] Schulz, S.: E - a brainiac theorem prover. AI Commun. 15(2-3), 111–126 (2002)
[26] Steen, A., Benzmüller, C.: The higher-order prover Leo-III. In: Galmiche, D., Schulz, S.,
Sebastiani, R. (eds.) IJCAR 2018. LNCS, vol. 10900, pp. 108–116. Springer (2018)
[27] Sutcliffe, G.: The TPTP problem library and associated infrastructure—from CNF to TH0,
TPTP v6.4.0. J. Autom. Reason. 59(4), 483–502 (2017)
[28] Vukmirovi´c, P., Bentkamp, A., Blanchette, J., Cruanes, S., Nummelin, V., Tourret, S.: Mak-
ing higher-order superposition work. In: Platzer, A., Sutcliffe, G. (eds.) CADE-28. LNCS,
Springer (2021)
[29] Vukmirovi´c, P., Bentkamp, A., Nummelin, V.: Efﬁcient full higher-order uniﬁcation. In:
Ariola, Z.M. (ed.) FSCD 2020. LIPIcs, vol. 167, pp. 5:1–5:17. Schloss Dagstuhl—Leibniz-
Zentrum für Informatik (2020)
[30] Vukmirovi´c, P., Nummelin, V.: Boolean reasoning in a higher-order superposition prover.
In: PAAR-2020. CEUR Workshop Proceedings, vol. 2752, pp. 148–166. CEUR-WS.org
(2020)
[31] Waldmann, U., Tourret, S., Robillard, S., Blanchette, J.: A comprehensive framework for
saturation theorem proving. In: Peltier, N., Sofronie-Stokkermans, V. (eds.) IJCAR 2020,
Part I. LNCS, vol. 12166, pp. 316–334. Springer (2020)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which per-
mits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as
you give appropriate credit to the original author(s) and the source, provide a link to the Creative
Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s Creative
Commons license, unless indicated otherwise in a credit line to the material. If material is not in-
cluded
in
the
chapter’s
Creative
Commons
license
and
your
intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain
permission directly from the copyright holder.

Implementation and Application

Making Higher-Order Superposition Work
Petar Vukmirovi´c1
, Alexander Bentkamp1
, Jasmin Blanchette1,2,3
,
Simon Cruanes4
, Visa Nummelin1
, and Sophie Tourret2,3
1 Vrije Universiteit Amsterdam, Amsterdam, the Netherlands
{p.vukmirovic,a.bentkamp,j.c.blanchette,visa.nummelin}@vu.nl
2 Universit´e de Lorraine, CNRS, Inria, LORIA, Nancy, France
sophie.tourret@inria.fr
3 Max-Planck-Institut f¨ur Informatik, Saarbr¨ucken, Germany
4 Aesthetic Integration, Austin, Texas, USA
simon@imandra.ai
Abstract. Superposition is among the most successful calculi for ﬁrst-
order logic. Its extension to higher-order logic introduces new challenges
such as inﬁnitely branching inference rules, new possibilities such as rea-
soning about formulas, and the need to curb the explosion of speciﬁc
higher-order rules. We describe techniques that address these issues and
extensively evaluate their implementation in the Zipperposition theorem
prover. Largely thanks to their use, Zipperposition won the higher-order
division of the CASC-J10 competition.
1
Introduction
In recent decades, superposition-based ﬁrst-order automatic theorem provers
have emerged as useful reasoning tools. They dominate at the annual CASC [45]
theorem prover competitions, having always won the ﬁrst-order theorem divi-
sion. They are also used as backends to proof assistants [13, 25, 35], automatic
higher-order theorem provers [42], and software veriﬁers [17]. The superposi-
tion calculus has only recently been extended to higher-order logic, resulting
in λ-superposition [6], which we developed together with Waldmann, as well as
combinatory superposition [10] by Bhayat and Reger.
Both higher-order superposition calculi were designed to gracefully extend
ﬁrst-order reasoning. As most steps in higher-order proofs tend to be essentially
ﬁrst-order, extending the most successful ﬁrst-order calculus to higher-order logic
seemed worth trying. Our ﬁrst attempt at corroborating this conjecture was in
2019: Zipperposition 1.5, based on λ-superposition, ﬁnished third in the higher-
order theorem division of CASC-27 [47], 12 percentage points behind the winner,
the tableau prover Satallax 3.4 [11].
Studying the competition results, we discovered that higher-order tableaux
have some advantages over higher-order superposition. To bridge the gap, we de-
veloped techniques and heuristics that simulate the behavior of a tableau prover
in the context of saturation. We implemented them in Zipperposition 2, which
took part in CASC-J10 in 2020. This time, Zipperposition won the division,
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5 24
415–432, 2021.

416
P. Vukmirovi´c et al.
solving 84% of problems, a whole 20 percentage points ahead of the next best
prover, Satallax 3.4. In this paper, we describe the main techniques that explain
this reversal of fortunes. They range from preprocessing to backend integration.
Interesting patterns can be observed in various higher-order encodings of
problems. We show how we can exploit these to simplify problems (Sect. 3). By
working on formulas rather than clauses, tableau techniques take a more holistic
view of a higher-order problem. Delaying the clausiﬁcation through the use of
calculus rules that act on formulas achieves the same eﬀect in superposition. We
further explore the beneﬁts of this approach (Sect. 4).
The main drawback of λ-superposition compared with combinatory super-
position is that it relies on rules that enumerate possibly inﬁnite sets of uniﬁers.
We describe a mechanism that interleaves performing inﬁnitely branching in-
ferences with the standard saturation process (Sect. 5). The prover retains the
same behavior as before on ﬁrst-order problems, smoothly scaling with increas-
ing numbers of higher-order clauses. We also propose some heuristics to curb the
explosion induced by highly proliﬁc λ-superposition rules (Sect. 6).
Using ﬁrst-order backends to ﬁnish the proof is common practice in higher-
order reasoning. Since λ-superposition coincides with standard superposition on
ﬁrst-order clauses, invoking backends may seem redundant; yet Zipperposition is
nowhere as eﬃcient as E [38] or Vampire [28], so invoking a more eﬃcient backend
does make sense. We describe how to achieve a balance between allowing native
higher-order reasoning and delegating reasoning to a backend (Sect. 7).
Finally, we compare Zipperposition 2 with other provers on all monomorphic
higher-order TPTP benchmarks [46] to perform a more extensive evaluation than
at CASC (Sect. 8). Our evaluation corroborates the competition results.
2
Background and Setting
We focus on monomorphic higher-order logic, but the techniques can easily be ex-
tended with polymorphism. Indeed, Zipperposition already supports some tech-
niques polymorphically.
Higher-Order Logic. We deﬁne terms s, t, u, v inductively as free variables
F, X, bound variables x, y, z, . . . , constants f, g, a, b, . . . , applications s t, and λ-
abstractions λx. s. The syntactic distinction between free and bound variables
gives rise to loose bound variables (e.g., y in λx. y a) [32]. We let s tn stand for
s t1 . . . tn and λxn. s for λx1. . . . λxn. s. Every β-normal term can be written
as λxm. s tn, where s is not an application; we call s the head of the term.
If the type of a term t is of the form τ1 →· · · →τn →o, where o is the
distinguished Boolean type and n ≥0, we call t a predicate. A literal l is an
equation s ≈t or a disequation s ̸≈t. A clause is a ﬁnite multiset of literals,
interpreted and written disjunctively l1 ∨· · · ∨ln. Logical symbols that may
occur within terms are written in boldface: ¬¬¬,∧∧∧,∨∨∨,→
→
→,↔
↔
↔, . . . . Predicate literals
are encoded as (dis)equations with ⊤⊤⊤based on their sign; for example, even(x)
becomes even(x) ≈⊤⊤⊤, and ¬ even(x) becomes even(x) ̸≈⊤⊤⊤.

Making Higher-Order Superposition Work
417
Higher-Order Calculi. The λ-superposition calculus is a refutationally com-
plete inference system and redundancy criterion for Boolean-free extensional
polymorphic clausal higher-order logic. The calculus relies on complete sets of
uniﬁers (CSUs). The CSU for s and t with respect to a set of variables V , denoted
by CSUV (s, t), is a set of uniﬁers such that for any uniﬁer ϱ of s and t, there exist
substitutions σ ∈CSUV (s, t) and θ such that ϱ(X) = σ(θ(X)) for all variables
X ∈V . The set X is used to distinguish between important and auxiliary vari-
ables. We usually omit it. A pragmatic, incomplete extension of λ-superposition
with interpreted Booleans is described by Vukmirovi´c and Nummelin [51]. This
forms the basis of most of this work. Recently, a refutationally complete exten-
sion was developed by Bentkamp et al. [5]; it is not considered here.
By contrast, the combinatory superposition calculus avoids CSUs by using a
form of ﬁrst-order uniﬁcation, but essentially it enumerates higher-order terms
using rules that instantiate applied variables with partially applied combinators
from the complete combinator set {S, K, B, C, I}. This calculus is the basis of
Vampire 4.5 [10], which ﬁnished closely behind Satallax 3.4 at CASC-J10.
A diﬀerent, very successful calculus is Satallax’s SAT-guided tableaux [2].
Satallax was the leading higher-order prover of the 2010s. Its simple and el-
egant tableaux avoid deep superposition-style rewriting inferences. Neverthe-
less, our working hypothesis for the past six years has been that superposition
would likely provide a stronger basis for higher-order reasoning. Other competing
higher-order calculi include SMT (implemented in CVC4 [3,4]) and extensional
paramodulation (implemented in Leo-III [42]).
Zipperposition. Zipperposition [6,12] is a higher-order theorem prover based
on a pragmatic extension of λ-superposition. It was conceived as a testbed for
rapidly experimenting with extensions of ﬁrst-order superposition, but over time,
it has assimilated many of E’s techniques and heuristics. Zipperposition 2 also
implements combinatory superposition.
Several of our techniques extend the given clause procedure [30, Section 2.3],
the standard saturation procedure. It partitions the proof state into a set P
of passive clauses and a set A of active clauses. Initially, P contains all input
clauses, and A is empty. At each iteration, a given clause C from P is moved to A
(i.e., it is activated), all inferences between C and clauses in A are performed, and
the conclusions are added to P. Because Zipperposition fully simpliﬁes clauses
only when they are activated, it implements a DISCOUNT-style loop [14].
Experimental Setup. To assess our techniques, we carried out experiments
with Zipperposition 2. We used all 2606 monomorphic higher-order problems
from the TPTP library [46], version 7.2.0, as benchmarks. Although some tech-
niques support polymorphism, we uniformly used the monomorphic benchmarks.
We ﬁxed a base conﬁguration of Zipperposition parameters as a baseline for all
comparisons. Then, in each experiment, we varied the parameters associated with
a speciﬁc technique to evaluate it. The experiments were run on StarExec [43]
servers, equipped with Intel Xeon E5-2609 CPUs clocked at 2.40 GHz. Unless

418
P. Vukmirovi´c et al.
otherwise stated, we used a CPU time limit of 20 s, roughly the time each con-
ﬁguration is given in the portfolio mode used for CASC. The raw evaluation
results are available online.5
3
Preprocessing Higher-Order Problems
The TPTP library contains thousands of higher-order problems. Despite their
diversity, they have a markedly diﬀerent ﬂavor from the TPTP ﬁrst-order prob-
lems. Notably, they extensively use the definition role to identify universally
quantiﬁed equations (or equivalences) that deﬁne symbols.
Deﬁnitions can be replaced by rewrite rules, using the orientation given in
the input problem. If there are multiple deﬁnitions for the same symbol, only the
ﬁrst one is replaced by a rewrite rule. Then, whenever a clause is picked in the
given clause procedure, it will be rewritten using the collected rules. Since the
TPTP format enforces no constraints on deﬁnitions, rewriting might diverge. To
ensure termination, we limit the number of applied rewrite steps. In practice,
most TPTP problems are well behaved: Only one deﬁnition is given for each
symbol, and the deﬁnitions are acyclic. Instead of rewriting a clause when it is
activated, we can rewrite the input formulas as a preprocessing step. This ensures
that the input clauses will be fully simpliﬁed when the proving process starts
and no deﬁned symbols will occur in clauses, which usually helps the heuristics.
Eagerly unfolding the deﬁnitions and β-reducing can eliminate all of a prob-
lem’s higher-order features, making it amendable to ﬁrst-order methods. How-
ever, this can inﬂate the problem beyond recognition and compromise the refu-
tational completeness of superposition.
To keep completeness, we can try to orient the deﬁnitions using the term order
that parameterized superposition and rely on demodulation to simplify the proof
state. Usually, the Knuth–Bendix order (KBO) [26] is used. It compares terms by
ﬁrst comparing their weights, which is the sum of all the weights assigned to the
symbols it contains. Given a symbol weight assignment W, we can update it so
that it orients acyclic deﬁnitions from left to right assuming that they are of the
form f Xm ≈λyn. t, where the only free variables in t are Xm, no free variable
repeats or appears applied in t, and f does not occur in t. Then we traverse the
symbols f that are deﬁned by such equations following the dependency relation,
starting with a symbol f that does not depend on any other deﬁned symbol. For
each f, we set W(f) to w + 1, where w is the maximum weight of the right-hand
sides of f’s deﬁnitions, computed using W. By construction, for each equation
the left-hand side is heavier. Thus, the equations are orientable from left to right.
Evaluation and Discussion. The base conﬁguration treats axioms anno-
tated with definition as rewrite rules, and it preprocesses the formulas us-
ing the rewrite rules. We also tested the eﬀects of disabling this preprocessing
(−preprocess), disabling the special treatment of definition axioms (−RW),
and disabling the special treatment of definition while using adjusted KBO
5 https://doi.org/10.5281/zenodo.4534829

Making Higher-Order Superposition Work
419
base
−preprocess
−RW
−RW+KBO
1638
1627
1303
1324
Fig. 1: Eﬀect of the deﬁnition rewriting
methods
+LA
−LA
IC
1624
1638
DCI
1496
1531
DCS
1659
1710
Fig. 2: Eﬀect of clausiﬁcation
and lightweight AVATAR
weights as described above (−RW+KBO). The results are given in Figure 1. In
all of the ﬁgures in this paper, each cell gives the number of proved problems;
the highest number is typeset in bold. Clearly, treating definition axioms as
rewrite rules greatly improves performance. Using adjusted KBO weights is not
as strong, although it proves 15 problems not proved using other conﬁgurations.
4
Reasoning about Formulas
Higher-order logic identiﬁes terms and formulas. To prove a problem, we often
need to instantiate a variable with the right predicate. Finding this predicate can
be easier if the problem is not clausiﬁed. Consider the conjecture ∃f. f p q ↔
↔
↔p∧∧∧q.
Expressed in this form, the formula is easy to prove by taking f := λx y. x ∧∧∧y.
By contrast, guessing the right instantiation for the negated, clausiﬁed form
F p q ̸≈⊤⊤⊤∨p ̸≈⊤⊤⊤∨q ̸≈⊤⊤⊤, F p q ≈⊤⊤⊤∨p ≈⊤⊤⊤, F p q ≈⊤⊤⊤∨q ≈⊤⊤⊤is more
challenging. One of the strengths of higher-order tableau provers is that they do
not clausify the input problem. This might explain Satallax’s dominance in the
THF division of CASC competitions until CASC-J10.
We studied techniques to incrementally clausify formulas during proof search
in incomplete [51] and complete [5] extensions of λ-superposition. Both ap-
proaches include the same set of (outer) delayed clausiﬁcation rules that clausify
top-level logical symbols, proceeding outside in; for example, a clause C′ ∨
(p ∧∧∧q) ̸≈⊤⊤⊤is transformed into C′ ∨p ̸≈⊤⊤⊤∨q ̸≈⊤⊤⊤. The complete approach
requires additional inference rules; it also supports inner delayed clausiﬁcation.
We focus on the pragmatic, incomplete approach and do not consider inner
clausiﬁcation due to its poor performance [5].
Delayed clausiﬁcation rules can be used as inference rules (which add con-
clusions to the passive set) or as simpliﬁcation rules (which delete premises and
add conclusions to the passive set). Inferences are more ﬂexible because they
produce all intermediate clausiﬁcation states, whereas simpliﬁcations produce
fewer clauses. Since clausifying equivalences can destroy a lot of syntactic struc-
ture [18], we never apply simplifying clausiﬁcation rules on them.
We discuss two tableau-inspired approaches for reasoning about formulas.
First, we study how clause-splitting techniques interfere with delayed clausiﬁca-
tion. Second, we discuss heuristic instantiation of quantiﬁers during saturation.
Zipperposition supports a lightweight variant of AVATAR [49], an architec-
ture that partitions the search space by splitting clauses into variable-disjoint

420
P. Vukmirovi´c et al.
subclauses. This variant of AVATAR is described by Ebner et al. [15]. Combin-
ing lightweight AVATAR and delayed clausiﬁcation makes it possible to split a
clause (ϕ1 ∨∨∨· · ·∨∨∨ϕn) ≈⊤⊤⊤, where the ϕi’s are arbitrarily complex formulas that
share no free variables with each other, into clauses ϕi ≈⊤⊤⊤.
To ﬁnish the proof, it suﬃces to derive ⊥under each assumption ϕi ≈⊤⊤⊤.
Since the split is performed at the formula level, this technique resembles tab-
leaux, but it exploits the strengths of superposition, such as its powerful redun-
dancy criterion and simpliﬁcation machinery, to close the branches.
Interleaving clausiﬁcation and saturation allows us to simulate another tab-
leau technique. Whenever dynamic clausiﬁcation replaces the predicate variable
x in a clause of the form (∀∀∀x. ϕ) ≈⊤⊤⊤∨C with a fresh variable X, resulting in
ϕ{x →X} ≈⊤⊤⊤∨C, we can create additional clauses in which x is replaced
with t ∈Inst, where Inst is a set of heuristically chosen terms. This set contains
λ-abstractions whose bodies are formulas and which occur in activated clauses,
and primitive instantiations [51]—that is, imitations (in the sense of higher-order
uniﬁcation) of logical symbols that approximate the shape of a predicate that
can instantiate a predicate variable.
However, as a new term t can be added to Inst after a clause with a quantiﬁed
variable of the same type as t has been activated, we must also keep track of the
clauses ϕ{x →X} ≈⊤⊤⊤∨C, so that when Inst is extended, we instantiate the
saved clauses. Conveniently, instantiated clauses are not recognized as subsumed,
since Zipperposition uses an optimized but incomplete subsumption algorithm.
Given a disequation f sn ̸≈f tn, the abstraction of si is λx. u ≈≈≈v, where u is
obtained by replacing si with x in f sn and v is obtained by replacing si with x
in f tn. For f sn ≈f tn, the analogous abstraction is λx.¬¬¬ (u ≈≈≈v).
Adding abstractions of the conjecture literals to Inst can provide useful in-
stantiations for formulas such as induction principles for datatypes. As the con-
jecture is negated, the equation’s polarity is inverted in the abstraction. Con-
sider the TPTP problem DAT056^2 [44], whose clausiﬁed negated conjecture
is ap xs (ap ys zs) ̸≈ap (ap xs ys) zs, where ap is the append operator deﬁned re-
cursively on its ﬁrst argument and xs, ys, and zs are of list type. Abstracting xs
from the disequation yields t = λx. ap x (ap ys zs) ≈≈≈ap (ap x ys) zs, which is added
to Inst. Included in the problem is the induction axiom for the list datatype:
∀∀∀p. (p nil ∧∧∧(∀∀∀x xs. p xs →
→
→p (cons x xs))) →
→
→∀∀∀xs. p xs, where nil and cons have the
usual meanings. Instantiating p with t and using the ap deﬁnition, we can prove
∀∀∀x. ap x (ap ys zs) ≈≈≈ap (ap x ys) zs, from which we easily derive a contradiction.
Evaluation and Discussion. The base conﬁguration uses immediate clausi-
ﬁcation (IC), an approach that applies a standard clausiﬁcation algorithm [33]
both as a preprocessing step and whenever predicate variables are instantiated.
Zipperposition’s lightweight AVATAR is disabled in the base conﬁguration. To
test the merits of delayed clausiﬁcation, we vary base’s parameters along two
axes: We choose immediate clausiﬁcation (IC), delayed clausiﬁcation as inference
(DCI), or delayed clausiﬁcation as simpliﬁcation (DCS), and we either enable
(+LA) or disable (−LA) the lightweight AVATAR. The base conﬁguration does
not use instantiation with terms from Inst.

Making Higher-Order Superposition Work
421
Figure 2 shows that using delayed clausiﬁcation as simpliﬁcation greatly in-
creases the success rate, while using delayed clausiﬁcation as inference has the
opposite eﬀect. Manually inspecting the proofs found by the DCS conﬁguration,
we noticed that a main reason for its success is that it does not simplify away
equivalences. Overall, the lightweight AVATAR harms performance, but the sets
of problems proved with and without it are vastly diﬀerent. For example, the
IC+LA conﬁguration proves 60 problems not proved by IC−LA.
The Boolean instantiation technique presented above requires delayed clausi-
ﬁcation. To test its eﬀects, we enabled it in the best conﬁguration from Figure 2,
DCS−LA. With this change, Zipperposition proves 1744 problems, 36 of which
cannot be proved by any other conﬁguration in the same ﬁgure. Boolean instanti-
ation is the only way in which Zipperposition 2 can prove higher-order problems
requiring reasoning about induction axioms (e.g., DAT056^2).
5
Enumerating Inﬁnitely Branching Inferences
As an optimization and to simplify the implementation, Leo-III [40] and Vampire
4.4 [9] (which uses a predecessor of combinatory superposition) compute only a
ﬁnite subset of the possible conclusions for inferences that require enumerating
a CSU. Not only is this a source of incompleteness, but choosing the cardinality
of the computed subset is a diﬃcult heuristic choice. Small sets can result in
missing the uniﬁer necessary for the proof, whereas large sets make the prover
spend a long time in the uniﬁcation procedure, generate useless clauses, and
possibly get sidetracked into the wrong parts of the search space.
We propose a modiﬁcation to the given clause procedure to seamlessly inter-
leave uniﬁer computation and proof state exploration. Given a complete uniﬁ-
cation procedure, which may yield inﬁnite streams of uniﬁers, our modiﬁcation
fairly enumerates all conclusions of inferences relying on elements of a CSU.
Under some reasonable assumptions, it behaves exactly like the standard given
clause procedure on purely ﬁrst-order problems. We also describe heuristics that
help achieve a similar performance as when using incomplete, terminating uni-
ﬁcation procedures without sacriﬁcing completeness.
Given the undecidability of the question as to whether there exists a next
CSU element in a stream of uniﬁers, the request for the next conclusion might
not terminate, eﬀectively bringing the theorem prover to a halt. Our modiﬁed
given clause procedure expects the uniﬁcation procedure to return a lazily com-
puted stream [34, Sect. 4.2], each element of which is either ∅or a singleton set
containing a uniﬁer. To avoid getting stuck waiting for a uniﬁer that may not
exist, the uniﬁcation procedure should return ∅after it performs a number of
operations without ﬁnding a uniﬁer.
The complete uniﬁcation procedure by Vukmirovi´c et al. [52] returns such a
stream. Other procedures such as Huet’s [22] and Jensen and Pietrzykowski’s [23]
can easily be adapted to meet this requirement. Based on the stream of uniﬁers
interspersed with ∅, we can construct a stream of inferences similarly interspersed
with ∅of which any ﬁnite preﬁxes can be computed in ﬁnite time.

422
P. Vukmirovi´c et al.
To support such streams in the given clause procedure, we extend it to rep-
resent the proof state not only by the active (A) and passive (P) clause sets, but
also by a priority queue Q containing the inference streams. Each stream is asso-
ciated with a weight, and Q is sorted in order of increasing weight. Elsewhere [6],
Bentkamp et al. described an older version of this extension. Here we present
a newer version in more detail, including heuristics to postpone unpromising
streams. The pseudocode of the modiﬁed procedure is as follows:
function ExtractClause(Q, stream)
maybe clause ←pop and compute the ﬁrst element of stream
if stream is not empty then add stream to Q with an increased weight
return maybe clause
function HeuristicProbe(Q)
(collected clauses, i) ←(∅, 0)
while i < Kbest and Q is not empty do
(maybe clause, j) ←(∅, 0)
while j < Kretry and Q is not empty and maybe clause = ∅do
stream ←pop the lowest weight stream in Q
maybe clause ←ExtractClause(Q, stream)
j ←j + 1
collected clauses ←collected clauses ∪maybe clause
i ←i + 1
return collected clauses
function FairProbe(Q, num oldest)
collected clauses ←∅
oldest streams ←pop num oldest oldest streams from Q
for stream in oldest streams do
collected clauses ←collected clauses ∪ExtractClause(Q, stream)
return collected clauses
function ForceProbe(Q)
collected clauses ←∅
while Q is not empty and collected clauses = ∅do
collected clauses ←FairProbe(Q, |Q|)
if Q and collected clauses are empty then status ←Satisﬁable
else status ←Unknown
return (status, collected clauses)
function GivenClause(P, A, Q)
(status, i) ←(Unknown, 0)
while status = Unknown do
if P is not empty then
given ←pop a chosen clause from P and simplify it
if given is the empty clause then status ←Unsatisﬁable

Making Higher-Order Superposition Work
423
else
A ←A ∪{given}
for stream in streams of inferences between given and other ∈A do
if stream is not empty then P ←P∪ExtractClause(Q, stream)
i ←i + 1
if i mod Kfair = 0 then P ←P ∪FairProbe(Q, ⌊i/Kfair⌋)
else P ←P ∪HeuristicProbe(Q)
else
(status, forced clauses) ←ForceProbe(Q)
P ←P ∪forced clauses
return status
Initially, all input clauses are put into P, and A and Q are empty. Unlike in
the standard given clause procedure, inference results are represented as clause
streams. The ﬁrst element is inserted into P, and the rest of the stream is stored
in Q with some positive integer weight computed from the inference rule.
To eventually consider inference conclusions from streams in Q as given
clauses, we extract elements from, or probe, streams and move any obtained
clauses to P. Analogously to the traditional pick–given ratio [30, 37], we use a
parameter Kfair (by default, Kfair = 70) to ensure fairness: Every Kfairth itera-
tion, FairProbe probes an increasing number of oldest streams, which achieves
dovetailing. In all other iterations, HeuristicProbe attempts to extract up to
Kbest clauses from the most promising streams (by default, Kbest = 7). In each
attempt, the most promising stream in Q is chosen. If its ﬁrst element is ∅, the
rest of the stream is inserted into Q, and a new stream is chosen. This is repeated
until either Kretry occurrences of ∅have been met (by default, Kretry = 20) or
the stream yields a singleton set. Setting Kretry > 0 increases the chance that
HeuristicProbe will return Kbest clauses, as desired. Finally, if P becomes
empty, ForceProbe searches relentlessly for a clause in Q, as a fallback.
The function ExtractClause extracts an element from a nonempty stream
not in Q and inserts the remaining stream into Q with an increased weight, calcu-
lated as follows. Let n be the number of times the stream was chosen for probing.
If probing results in ∅, the stream’s weight is increased by max {2, n −16}. If
probing results in a clause C whose penalty is p, the stream’s weight is increased
by p · max {1, n −64}. The penalty of a clause is a number assigned by Zip-
perposition based on features such as the depth of its derivation and the rules
used in it. The constants 16 and 64 increase the chance that newer streams are
picked, which is desirable because their ﬁrst clauses are expected to be useful.
All three probing functions are invoked by GivenClause, which forms the
body of the saturation loop. It diﬀers from the standard given clause procedure in
three ways: First, the proof state includes Q in addition to P and A. Second, new
inferences involving the given clause are added to Q instead of being performed
immediately. Third, inferences in Q are periodically performed lazily to ﬁll P.
GivenClause eagerly stores the ﬁrst element of a new inference stream in
P to imitate the standard given clause procedure. If the underlying uniﬁcation

424
P. Vukmirovi´c et al.
procedure behaves like the standard ﬁrst-order uniﬁcation algorithm on higher-
order logic’s ﬁrst-order fragment, our given clause procedure coincides with the
standard one. The uniﬁcation procedure by Vukmirovi´c et al. terminates on the
ﬁrst-order and other fragments [32], and for problems outside these fragments,
it immediately returns ∅to avoid computing complicated uniﬁers eagerly.
Evaluation and Discussion. When the uniﬁcation procedure of Vukmirovi´c
et al. was implemented in Zipperposition, it was observed that Zipperposition is
the only competing higher-order prover that proves all Church numeral problems
from the TPTP, never spending more than 5 seconds on the problem [52].
Consider the TPTP problem NUM800^1, which requires ﬁnding a function F
such that F c1 c2 ≈≈≈c2 ∧∧∧F c2 c3 ≈≈≈c6, where cn abbreviates the Church numeral
for n, λs z. sn(z). To prove it, it suﬃces to take F to be the multiplication
operator λx y s z.x (y s) z. However, this uniﬁer is only one out of many available
for each occurrence of F.
In an independent evaluation setup on the same set of 2606 problems used
in this paper, Vukmirovi´c et al. compared a complete, nonterminating variant
and a pragmatic, terminating variant of the uniﬁcation procedure [52, Sect. 7].
The pragmatic variant was used directly—all the inference conclusions were put
immediately in P, bypassing Q. The complete variant, which relies on possibly
inﬁnite streams and is much more proliﬁc, proved only 15 problems less than
the most competitive pragmatic variant. Furthermore, it proved 19 problems not
proved by the pragmatic variant. This shows that our given clause procedure,
with its heuristics, allows the prover to defer exploring less promising branches of
the uniﬁcation and uses the full power of a complete higher-order uniﬁer search
to solve uniﬁcation problems that cannot be solved by a crippled procedure.
Among the competing higher-order theorem provers, only Satallax uses in-
ﬁnitely branching calculus rules. It maintains a queue of “commands” that con-
tain instructions on how to create a successor state in the tableau. One command
describes inﬁnite enumeration of all closed terms of a given function type. Each
execution of this command makes progress in the enumeration. Unlike evaluation
of streams representing elements of CSU, each command execution is guaranteed
to make progress in enumerating the next closed functional term, so there is no
need to ever return ∅.
6
Controlling Proliﬁc Rules
To support higher-order features such as function extensionality and quantiﬁca-
tion over functions, many refutationally complete calculi employ highly proliﬁc
rules. For example, λ-superposition uses a rule FluidSup [6] that very often
applies to two clauses if one of them contains a term of the form F sn, where
n > 0. We describe three mechanisms to keep rules like these under control.
First, we limit applicability of the proliﬁc rules. In practice, it often suﬃces to
apply proliﬁc higher-order rules only to initial or shallow clauses—clauses with
a shallow derivation depth. Thus, we added an option to forbid the application
of a rule if the derivation depth of any premise exceeds a limit.

Making Higher-Order Superposition Work
425
Second, we penalize the streams of expensive inferences. The weight of each
stream is given an initial value based on characteristics of the inference premises
such as their derivation depth. For proliﬁc rules such as FluidSup, we increment
this value by a parameter Kincr. Weights for less proliﬁc variants of this rule,
such as DupSup [6], are increased by a fraction of Kincr (e.g., ⌊Kincr/3⌋).
Third, we defer the selection of proliﬁc clauses. To select the given clause,
most saturating provers evaluate clauses according to some criteria and select
the clause with the lowest evaluation. For this choice to be eﬃcient, passive
clauses are organized into a priority queue ordered by their evaluations. Like
E, Zipperposition maintains multiple queues, ordered by diﬀerent evaluations,
that are visited in a round-robin fashion. It also uses E’s two-layer evaluation
functions, a variant of which has recently been implemented in Vampire [19].
The two layers are clause priority and clause weight. Clauses with higher pri-
ority are preferred, and the weight is used for tie-breaking. Intuitively, the ﬁrst
layer crudely separates clauses into priority classes, whereas the second one uses
heuristic weights to prefer clauses within a priority class. To control the selec-
tion of proliﬁc clauses, we introduce new clause priority functions that take into
account features speciﬁc to higher-order clauses.
The ﬁrst new priority function PreferHOSteps (PHOS) assigns a higher pri-
ority if rules speciﬁc to λ- or combinatory superposition were used in the clause
derivation. Since most of the other clause priority functions tend to defer higher-
order clauses, having a clause queue that prefers the results of higher-order in-
ferences might be necessary to ﬁnd a proof more eﬃciently. A simpler function,
which prefers clauses containing λ-abstractions, is PreferLambda (PL).
We also introduce the priority function ByNormalizationFactor (BNF), in-
spired by the observation that a higher-order inference that applies a compli-
cated substitution to a clause is usually followed by a βη-normalization step. If
βη-normalization greatly reduces the size of a clause, it is likely that this sub-
stitution simpliﬁes the clause (e.g., by removing a variable’s arguments). Thus,
this function prefers clauses that were produced by βη-normalization, and among
those it prefers the ones with larger size reductions.
Another new priority function is PreferShallowAppVars (PSAV). This prefers
clauses with lower depths of the deepest occurrence of an applied variable—that
is, C[X a] is preferred over C[f (X a)]. This function tries to curb the explosion
of both λ- and combinatory superposition: Applying a substitution to a top-level
applied variable often reduces this applied variable to a term with a constant
head, which likely results in a less explosive clause. Among the functions that rely
on properties of applied variables we implemented PreferDeepAppVars (PDAV),
which returns the priority opposite of PSAV, and ByAppVarNum (BAVN), which
prefers clauses with fewer occurrences of applied variables.
Evaluation and Discussion. In the base conﬁguration, Zipperposition visits
several clause queues, one of which uses the constant priority function ConstPrio
(CP). To evaluate the new priority functions, we replaced the queue ordered by
CP with the queue ordered by one of the new functions, leaving the clause weight
intact. The results are shown in Figure 3. It shows that the expensive priority

426
P. Vukmirovi´c et al.
base (CP)
BAVN
PL
PSAV
PHOS
BNF
PDAV
1638
1640
1637
1637
1632
1594
1520
Fig. 3: Eﬀect of the priority function on performance
base (∞)
16
8
4
2
1
1638
1619
1621
1618
1612
1610
Fig. 4: Eﬀect of the FluidSup weight increment Kincr on performance
functions PHOS and BNF, which require inspecting the proof of clauses, hardly
help. Simple functions such as PL are more eﬀective: Compared with base, PL
loses one problem overall but proves 22 new problems.
FluidSup is disabled in base because it is so explosive. To test if increas-
ing inference stream weights makes a diﬀerence on the success rate, we enabled
FluidSup and used diﬀerent weight increments Kincr for FluidSup inference
queues. The results are shown in Figure 4. As expected, using a low incre-
ment with FluidSup is detrimental to performance. However, as the column
for Kincr = 16 shows, nor should we use too high an increment, since that delays
useful FluidSup inferences. Interestingly, even though the conﬁguration with
Kincr = 1 proves the least problems overall, it proves 7 problems not proved by
base, which is more than any other conﬁguration we tried.
7
Controlling the Use of Backends
Cooperation with eﬃcient ﬁrst-order theorem provers is an essential feature of
higher-order theorem provers such as Leo-III [40, Sect. 4.4] and Satallax [11].
Those provers invoke ﬁrst-order backends repeatedly during a proof attempt
and spend a substantial amount of time in backend collaboration. Since λ-super-
position generalizes a highly eﬃcient ﬁrst-order calculus, we expect that future
eﬃcient λ-superposition implementations will not beneﬁt much from backends.
Experimental provers such as Zipperposition can still gain a lot. We present
some techniques for controlling the use of backends.
In his thesis [40, Sect. 6.1], Steen extensively evaluates the eﬀects of using dif-
ferent ﬁrst-order backends on the performance of Leo-III. His results suggest that
adding only one backend already substantially improves the performance. To re-
duce the eﬀort required for integrating multiple backends, we chose Ehoh [50] as
our single backend. Ehoh is an extension of the highly optimized superposition
prover E with support for higher-order features such as partial application, ap-
plied variables, and interpreted Booleans. On the one hand, Ehoh provides the
eﬃciency of E while easing the translation from full higher-order logic: The only
missing syntactic feature is λ-abstraction. On the other hand, Ehoh’s higher-

Making Higher-Order Superposition Work
427
base
0.1
0.25
0.5
0.75
1638
1936
1935
1934
1923
Fig. 5: Eﬀect of the backend invo-
cation point Ktime
base
lifting
SKBCI
omitted
1638
1935
1867
1855
Fig. 6: Eﬀect of the method used
to translate λ-abstractions
base
16
32
64
128
256
512
1638
1936
1935
1939
1928
1925
1912
Fig. 7: Eﬀect of the number of selected clauses Ksize
order reasoning capabilities are limited. Its uniﬁcation algorithm is essentially
ﬁrst-order and it cannot synthesize λ-abstractions.
In a departure from Leo-III and other cooperative provers, we invoke the
backend at most once during a run of the prover. This is because most competi-
tive higher-order provers use a portfolio mode in which many conﬁgurations are
run for a short time, and we want to leave enough time for native higher-order
reasoning. Moreover, multiple backend invocations tend to be wasteful, because
currently each invocation starts with no knowledge of the previous ones.
Only a carefully chosen subset of the available clauses are translated and sent
to Ehoh. Let I be the set of input clauses. Given a proof state, let M = P ∪A,
and let Mho denote the subset of M that contains only clauses that were derived
using at least one λ-superposition-speciﬁc inference rule. We order the clauses in
Mho by increasing derivation depth, using syntactic weight to break ties. Then
we choose all clauses in I and the ﬁrst Ksize clauses from Mho for use with the
backend reasoner. We leave out clauses in M\(I∪Mho) because Ehoh can rederive
them. We also expect large clauses with deep derivations to be less useful.
The remaining step is the translation of λ-abstractions. We support two
translation methods: λ-lifting [24] and SKBCI combinators [48]. For SKBCI, we
omit the combinator deﬁnition axioms, because they are very explosive [10]. A
third mode simply omits clauses containing λ-abstractions.
Evaluation and Discussion. In Zipperposition, we can adjust the CPU time
allotted to Ehoh, Ehoh’s own proof search parameters, the point when Ehoh is
invoked, the number Ksize of selected clauses from Mho, and the λ translation
method. We ﬁx the time limit to 5 s, use Ehoh in auto mode, and focus on the
last three parameters. In base, collaboration with Ehoh is disabled.
Ehoh is invoked after Ktime·t CPU seconds, where 0 ≤Ktime < 1 and t is the
total CPU time allotted to Zipperposition. Figure 5 shows the eﬀect of varying
Ktime when Ksize = 32 and λ-lifting is used. The evaluation conﬁrms that using
a highly optimized backend such as Ehoh greatly improves the performance of a
less optimized prover such as Zipperposition. The ﬁgure indicates that it is prefer-
able to invoke the backend early. We have indeed observed that if the backend

428
P. Vukmirovi´c et al.
Uncoop
Coop
CVC4
1810
–
Leo-III
1641
2108
Satallax
2089
2224
Vampire
2096
–
Zipperposition
2223
2307
Fig. 8: Comparison of competing higher-order theorem provers
is invoked late, small clauses with deep derivations tend to be present by then.
These clauses might have been used to delete important shallow clauses already.
But due to their derivation depth, they will not be translated. In such situations,
it is better to invoke the backend before the important clauses are deleted.
Figure 6 quantiﬁes the eﬀects of the three λ-abstraction translation methods.
We ﬁxed Ktime = 0.25 and Ksize = 32. The clear winner is λ-lifting. Omitting
clauses with λ-abstractions performs comparably to SKBCI combinators.
Figure 7 shows the eﬀect of Ksize on performance, with Ktime = 0.25 and
λ-lifting. We ﬁnd that including a small number of higher-order clauses with the
lowest weight performs better than including a large number of such clauses.
8
Comparison with Other Provers
Diﬀerent choices of parameters lead to noticeably diﬀerent sets of proved prob-
lems. In an attempt to use Zipperposition 2 to its full potential, we have created
a portfolio mode that runs up to 50 conﬁgurations in parallel during the allot-
ted time. To provide some context, we compare Zipperposition 2 with the latest
versions of all higher-order provers that competed at CASC-J10: CVC4 1.8 [4],
Leo-III 1.5 [42], Satallax 3.5 [11], and Vampire 4.5 [10]. Note that Vampire’s
higher-order schedule is optimized for running on a single core.
We use the same 2606 monomorphic higher-order TPTP 7.2.0 problems as
elsewhere in this paper, but we try to replicate the CASC setup more faithfully.
CASC-J10 was run on 8-core CPUs with a 120 s wall-clock limit and a 960 s
CPU limit. Since we run the experiments on 4-core CPUs, we set the wall-clock
limit to 240 s and keep the same CPU limit. Leo-III, Satallax, and Zipperposition
are cooperative provers. We also run them in uncooperative mode, without their
backends, to measure their intrinsic strength. Figure 8 summarizes the results.
Among the cooperative provers, Zipperposition is the one that depends the
least on its backend, and its uncooperative mode is only one problem behind
Satallax’s cooperative mode. This conﬁrms our hypothesis that λ-superposition is
a suitable basis for automatic higher-order reasoning. This also suggests that the
implementation of this calculus in a modern ﬁrst-order superposition prover such
as E or Vampire would achieve markedly better results. Moreover, we believe that
there are still techniques inspired by tableaux, SAT solving, and SMT solving
that could be adapted and integrated in saturation provers.

Making Higher-Order Superposition Work
429
9
Discussion and Conclusion
Back in 1994, Kohlhase [27, Sect. 1.3] was optimistic about the future of higher-
order automated reasoning:
The obstacles to proof search intrinsic to higher-order logic may well be
compensated by the greater expressive power of higher-order logic and
by the existence of shorter proofs. Thus higher-order automated theorem
proving will be practically as feasible as ﬁrst-order theorem proving is
now as soon as the technological backlog is made up.
For higher-order superposition, the backlog consisted of designing calculus ex-
tensions, heuristics, and algorithms that mitigate its weaknesses. In this paper,
we presented such enhancements, justiﬁed their design, and evaluated them. We
explained how each weak point in the higher-order proving pipeline could be im-
proved, from preprocessing to reasoning about formulas, to delaying unpromis-
ing or explosive inferences, to invoking a backend. Our evaluation indicates that
higher-order superposition is now the state of the art in higher-order reasoning.
Higher-order extensions of ﬁrst-order superposition have been considered by
Bentkamp et al. [6,7] and Bhayat and Reger [9,10]. They introduced proof cal-
culi, proved them refutationally complete, and suggested optional rules, but they
hardly discussed the practical aspects of higher-order superposition. Extensions
of SMT are discussed by Barbosa et al. [3]. Bachmair and Ganzinger [1], Manna
and Waldinger [29], and Murray [31] have studied nonclausal resolution calculi.
In contrast, there is a vast literature on practical aspects of ﬁrst-order rea-
soning using superposition and related calculi. The literature evaluates various
procedures and techniques [21,36], literal and term order selection functions [20],
and clause evaluation functions [19,39], among others. Our work joins the select
club of papers devoted to practical aspects of higher-order reasoning [8,16,41,53].
As a next step, we plan to implement the described techniques in Ehoh [50],
the λ-free higher-order extension of E. We expect the resulting prover to be sub-
stantially more eﬃcient than Zipperposition. Moreover, we want to investigate
the proofs found by provers such as CVC4 and Satallax but missed by Zipper-
position. Finding the reason behind why Zipperposition fails to prove speciﬁc
problems will likely result in useful new techniques.
Acknowledgment. We are grateful to the maintainers of StarExec for letting us use
their service. Ahmed Bhayat and Giles Reger guided us through details of Vampire 4.5.
Ahmed Bhayat, Michael F¨arber, Mathias Fleury, Predrag Janiˇci´c, Mark Summerﬁeld,
and the anonymous reviewers suggested content, textual, and typesetting improve-
ments. We thank them all.
Vukmirovi´c, Bentkamp, and Blanchette’s research has received funding from the
European Research Council (ERC) under the European Union’s Horizon 2020 research
and innovation program (grant agreement No. 713999, Matryoshka). Blanchette and
Nummelin’s research has received funding from the Netherlands Organization for Sci-
entiﬁc Research (NWO) under the Vidi program (project No. 016.Vidi.189.037, Lean
Forward) and the Incidental Financial Support scheme.

430
P. Vukmirovi´c et al.
References
1. Bachmair, L., Ganzinger, H.: Non-clausal resolution and superposition with selec-
tion and redundancy criteria. In: Voronkov, A. (ed.) LPAR ’92. LNCS, vol. 624,
pp. 273–284. Springer (1992)
2. Backes, J., Brown, C.E.: Analytic tableaux for higher-order logic with choice. J.
Autom. Reason. 47(4), 451–479 (2011)
3. Barbosa, H., Reynolds, A., Ouraoui, D.E., Tinelli, C., Barrett, C.W.: Extending
SMT solvers to higher-order logic. In: Fontaine, P. (ed.) CADE-27. LNCS, vol.
11716, pp. 35–54. Springer (2019)
4. Barrett, C.W., Conway, C.L., Deters, M., Hadarean, L., Jovanovi´c, D., King, T.,
Reynolds, A., Tinelli, C.: CVC4. In: Gopalakrishnan, G., Qadeer, S. (eds.) CAV
2011. LNCS, vol. 6806, pp. 171–177. Springer (2011)
5. Bentkamp, A., Blanchette, J., Tourret, S., Vukmirovi´c, P.: Superposition for full
higher-order logic. In: Platzer, A., Sutcliﬀe, G. (eds.) CADE-28. LNCS, Springer
(2021), to appear
6. Bentkamp, A., Blanchette, J., Tourret, S., Vukmirovi´c, P., Waldmann, U.: Super-
position with lambdas. J. Autom. Reason. To appear, preprint at https://arxiv.
org/abs/2102.00453 (2021)
7. Bentkamp, A., Blanchette, J.C., Cruanes, S., Waldmann, U.: Superposition for
lambda-free higher-order logic. In: Galmiche, D., Schulz, S., Sebastiani, R. (eds.)
IJCAR 2018. LNCS, vol. 10900, pp. 28–46. Springer (2018)
8. Benzm¨uller, C., Sorge, V., Jamnik, M., Kerber, M.: Can a higher-order and a ﬁrst-
order theorem prover cooperate? In: Baader, F., Voronkov, A. (eds.) LPAR 2004.
LNCS, vol. 3452, pp. 415–431. Springer (2004)
9. Bhayat, A., Reger, G.: Restricted combinatory uniﬁcation. In: Fontaine, P. (ed.)
CADE-27. LNCS, vol. 11716, pp. 74–93. Springer (2019)
10. Bhayat, A., Reger, G.: A combinator-based superposition calculus for higher-order
logic. In: Peltier, N., Sofronie-Stokkermans, V. (eds.) IJCAR 2020, Part I. LNCS,
vol. 12166, pp. 278–296. Springer (2020)
11. Brown, C.E.: Reducing higher-order theorem proving to a sequence of SAT prob-
lems. J. Autom. Reason. 51(1), 57–77 (2013)
12. Cruanes, S.: Extending superposition with integer arithmetic, structural induction,
and beyond. Ph.D. thesis, ´Ecole polytechnique (2015)
13. Czajka, L., Kaliszyk, C.: Hammer for Coq: Automation for dependent type theory.
J. Autom. Reason. 61(1-4), 423–453 (2018)
14. Denzinger, J., Kronenburg, M., Schulz, S.: DISCOUNT—a distributed and learning
equational prover. J. Autom. Reason. 18(2), 189–198 (1997)
15. Ebner, G., Blanchette, J., Tourret, S.: Unifying splitting. In: Platzer, A., Sutcliﬀe,
G. (eds.) CADE-28. LNCS, Springer (2021), to appear
16. F¨arber, M., Brown, C.E.: Internal guidance for Satallax. In: Olivetti, N., Tiwari,
A. (eds.) IJCAR 2016. LNCS, vol. 9706, pp. 349–361. Springer (2016)
17. Filliˆatre, J., Paskevich, A.: Why3—where programs meet provers. In: Felleisen, M.,
Gardner, P. (eds.) ESOP 2013. LNCS, vol. 7792, pp. 125–128. Springer (2013)
18. Ganzinger, H., Stuber, J.: Superposition with equivalence reasoning and de-
layed clause normal form transformation. In: Baader, F. (ed.) CADE-19. LNCS,
vol. 2741, pp. 335–349. Springer (2003)
19. Gleiss, B., Suda, M.: Layered clause selection for theory reasoning (short paper).
In: Peltier, N., Sofronie-Stokkermans, V. (eds.) IJCAR 2020, Part I. LNCS, vol.
12166, pp. 402–409. Springer (2020)

Making Higher-Order Superposition Work
431
20. Hoder, K., Reger, G., Suda, M., Voronkov, A.: Selecting the selection. In: Olivetti,
N., Tiwari, A. (eds.) IJCAR 2016. LNCS, vol. 9706, pp. 313–329. Springer (2016)
21. Hoder, K., Voronkov, A.: Comparing uniﬁcation algorithms in ﬁrst-order theorem
proving. In: Mertsching, B., Hund, M., Aziz, M.Z. (eds.) KI 2009. LNCS, vol. 5803,
pp. 435–443. Springer (2009)
22. Huet, G.P.: A uniﬁcation algorithm for typed lambda-calculus. Theor. Comput.
Sci. 1(1), 27–57 (1975)
23. Jensen, D.C., Pietrzykowski, T.: Mechanizing omega-order type theory through
uniﬁcation. Theor. Comput. Sci. 3(2), 123–171 (1976)
24. Johnsson, T.: Lambda lifting: Transforming programs to recursive equations. In:
Jouannaud, J. (ed.) FPCA 1985. LNCS, vol. 201, pp. 190–203. Springer (1985)
25. Kaliszyk, C., Urban, J.: HOL(y)Hammer: Online ATP service for HOL Light.
Math. Comput. Sci. 9(1), 5–22 (2015)
26. Knuth, D.E., Bendix, P.B.: Simple word problems in universal algebras. In: Leech,
J. (ed.) Computational Problems in Abstract Algebra, pp. 263–297. Pergamon
(1970)
27. Kohlhase, M.: A mechanization of sorted higher-order logic based on the resolution
principle. Ph.D. thesis, Universit¨at des Saarlandes, Saarbr¨ucken, Germany (1994)
28. Kov´acs, L., Voronkov, A.: First-order theorem proving and Vampire. In: Sharygina,
N., Veith, H. (eds.) CAV 2013. LNCS, vol. 8044, pp. 1–35. Springer (2013)
29. Manna, Z., Waldinger, R.: A deductive approach to program synthesis. In:
Buchanan, B.G. (ed.) IJCAI-79. pp. 542–551. William Kaufmann (1979)
30. McCune, W., Wos, L.: Otter—the CADE-13 competition incarnations. J. Autom.
Reason. 18(2), 211–220 (1997)
31. Murray, N.V.: Completely non-clausal theorem proving. Artif. Intell. 18(1), 67–85
(1982)
32. Nipkow, T.: Functional uniﬁcation of higher-order patterns. In: Best, E. (ed.) LICS
1993. pp. 64–74. IEEE Computer Society (1993)
33. Nonnengart, A., Weidenbach, C.: Computing small clause normal forms. In: Robin-
son, J.A., Voronkov, A. (eds.) Handbook of Automated Reasoning, pp. 335–367.
Elsevier and MIT Press (2001)
34. Okasaki, C.: Purely functional data structures. Cambridge University Press (1999)
35. Paulson, L.C., Blanchette, J.C.: Three years of experience with Sledgehammer, a
practical link between automatic and interactive theorem provers. In: Sutcliﬀe, G.,
Schulz, S., Ternovska, E. (eds.) IWIL-2010. EPiC Series in Computing, vol. 2, pp.
1–11. EasyChair (2010)
36. Reger, G., Suda, M., Voronkov, A.: Playing with AVATAR. In: Felty, A.P., Mid-
deldorp, A. (eds.) CADE-25. LNCS, vol. 9195, pp. 399–415. Springer (2015)
37. Schulz, S.: E—a brainiac theorem prover. AI Commun. 15(2-3), 111–126 (2002)
38. Schulz, S., Cruanes, S., Vukmirovi´c, P.: Faster, higher, stronger: E 2.3. In: Fontaine,
P. (ed.) CADE-27. LNCS, vol. 11716, pp. 495–507. Springer (2019)
39. Schulz, S., M¨ohrmann, M.: Performance of clause selection heuristics for saturation-
based theorem proving. In: Olivetti, N., Tiwari, A. (eds.) IJCAR 2016. LNCS,
vol. 9706, pp. 330–345. Springer (2016)
40. Steen, A.: Extensional paramodulation for higher-order logic and its eﬀective im-
plementation Leo-III. Ph.D. thesis, Free University of Berlin, Dahlem, Germany
(2018)
41. Steen, A., Benzm¨uller, C.: There is no best β-normalization strategy for higher-
order reasoners. In: Davis, M., Fehnker, A., McIver, A., Voronkov, A. (eds.) LPAR-
20. LNCS, vol. 9450, pp. 329–339. Springer (2015)

432
P. Vukmirovi´c et al.
42. Steen, A., Benzm¨uller, C.: The higher-order prover Leo-III. In: Galmiche, D.,
Schulz, S., Sebastiani, R. (eds.) IJCAR 2018. LNCS, vol. 10900, pp. 108–116.
Springer (2018)
43. Stump, A., Sutcliﬀe, G., Tinelli, C.: Starexec: A cross-community infrastructure
for logic solving. In: Demri, S., Kapur, D., Weidenbach, C. (eds.) IJCAR 2014.
LNCS, vol. 8562, pp. 367–373. Springer (2014)
44. Sultana, N., Blanchette, J.C., Paulson, L.C.: LEO-II and Satallax on the Sledge-
hammer test bench. J. Appl. Log. 11(1), 91–102 (2013)
45. Sutcliﬀe, G.: The CADE ATP System Competition—CASC. AI Magazine 37(2),
99–101 (2016)
46. Sutcliﬀe, G.: The TPTP problem library and associated infrastructure—from CNF
to TH0, TPTP v6.4.0. J. Autom. Reason. 59(4), 483–502 (2017)
47. Sutcliﬀe, G.: The CADE-27 automated theorem proving system competition—
CASC-27. AI Commun. 32(5-6), 373–389 (2019)
48. Turner, D.A.: Another algorithm for bracket abstraction. J. Symb. Log. 44(2),
267–270 (1979)
49. Voronkov, A.: AVATAR: the architecture for ﬁrst-order theorem provers. In: Biere,
A., Bloem, R. (eds.) CAV 2014. LNCS, vol. 8559, pp. 696–710. Springer (2014)
50. Vukmirovi´c, P., Blanchette, J.C., Cruanes, S., Schulz, S.: Extending a brainiac
prover to lambda-free higher-order logic. In: Vojnar, T., Zhang, L. (eds.) TACAS
2019, Part I. LNCS, vol. 11427, pp. 192–210. Springer (2019)
51. Vukmirovi´c, P., Nummelin, V.: Boolean reasoning in a higher-order superposition
prover. In: Fontaine, P., Korovin, K., Kotsireas, I.S., R¨ummer, P., Tourret, S. (eds.)
PAAR-2020. CEUR Workshop Proceedings, vol. 2752, pp. 148–166. CEUR-WS.org
(2020)
52. Vukmirovi´c, P., Bentkamp, A., Nummelin, V.: Eﬃcient full higher-order uniﬁca-
tion. In: Ariola, Z.M. (ed.) FSCD. LIPIcs, vol. 167, pp. 5:1–5:17. Schloss Dagstuhl—
Leibniz-Zentrum f¨ur Informatik (2020)
53. Wisniewski, M., Steen, A., Kern, K., Benzm¨uller, C.: Eﬀective normalization tech-
niques for HOL. In: Olivetti, N., Tiwari, A. (eds.) IJCAR 2016. LNCS, vol. 9706,
pp. 362–370. Springer (2016)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Dual Proof Generation for Quantiﬁed Boolean Formulas
with a BDD-based Solver
Randal E. Bryant ()
and Marijn J. H. Heule
Computer Science Department
Carnegie Mellon University, Pittsburgh, PA, United States
{Randy.Bryant, mheule}@cs.cmu.edu
Abstract. Existing proof-generating quantiﬁed Boolean formula (QBF) solvers
must construct a different type of proof depending on whether the formula is
false (refutation) or true (satisfaction). We show that a QBF solver based on or-
dered binary decision diagrams (BDDs) can emit a single dual proof as it oper-
ates, supporting either outcome. This form consists of a sequence of equivalence-
preserving clause addition and deletion steps in an extended resolution frame-
work. For a false formula, the proof terminates with the empty clause, indicating
conﬂict. For a true one, it terminates with all clauses deleted, indicating tautology.
Both the length of the proof and the time required to check it are proportional to
the total number of BDD operations performed. We evaluate our solver using a
scalable benchmark based on a two-player tiling game.
1
Introduction
Adding quantiﬁers to Boolean formulas, yielding the logic of quantiﬁed Boolean for-
mulas (QBFs), greatly extends their expressive power [11], but it presents several chal-
lenges, including verifying the output of a QBF solver. Unlike a satisﬁable Boolean
formula, there is no satisfying assignment for a QBF—the formula is simply false or
true. Instead, a proof-generating QBF solver must provide a full proof in either case: a
refutation proof if the formula is false, or a satisfaction proof if the formula is true.
Currently, there is little standardization of the proof capabilities or the proof sys-
tems supported by different QBF solvers [21]. Some solvers can generate syntactic
certiﬁcates—ones that can be directly checked by a proof checker. For a false formula,
these can be expressed in clausal proof frameworks that augment resolution with rules
for universal quantiﬁcation [18]. For a true formula, several QBF solvers can generate
term resolution proofs [12], effectively reasoning about a negated version of the input
formula represented in disjunctive form. These require the proof checker to support an
entirely different set of proof rules.
An even larger number of solvers can generate semantic certiﬁcates in the form of
Herbrand functions for false formulas and Skolem functions for true ones, describing
how to instantiate either the universal or the existential variables [21]. These can be
used to expand the original formula into a (often much larger) Boolean formula that is
checked with a SAT solver [22] or with a high-degree polynomial algorithm [25]. Per-
forming the check often requires far more effort than does running the solver. These ap-
proaches, along with others involving syntactic certiﬁcates, require at least two passes—
one to determine whether the formula is true or false and one to generate the proof.
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliffe (Eds.): CADE 2021, LNAI 12699, pp. 433–449, 2021.
https://doi.org/10.1007/978-3-030-79876-5 25

434
R. E. Bryant and M. J. H. Heule
This paper describes a new approach to proof generation for QBF, where the solver
generates a dual proof, serving as either a refutation or a satisfaction proof depending
on whether the solver determines the formula to be false or true. A dual proof consists
of a sequence of clause addition and deletion steps, each preserving equivalence to the
original formula. If the proof terminates with the addition of the empty clause, then it
demonstrates that the original formula was contradictory and therefore false. If the proof
terminates with all clauses removed, then it demonstrates that the original formula was
equivalent to a tautology and is therefore true. The proofs are expressed in a clausal
proof framework that incorporates extended resolution, as well as rules for universal
and existential quantiﬁcation [13,14].
We have implemented a QBF solver PGBDDQ based on ordered binary decision di-
agrams (BDDs) that can generate dual proofs as it operates. As optimizations, PGBDDQ
can be directed to generate refutation or satisfaction proofs, and these can be somewhat
shorter and take less time to check than dual proofs. Refutation proofs follow the tradi-
tional format of a series of truth-preserving steps leading to an empty clause. Satisfac-
tion proofs follow the novel format of a series of falsehood-preserving steps leading to
an empty set of clauses. This approach for satisfaction proofs has been previously used
as part of a QBF preprocessor [13, 14], but, to the best of our knowledge, ours is the
ﬁrst use in a complete QBF solver. Whether dual, refutation, or satisfaction, the proofs
generated by PGBDDQ have length proportional to the number of BDD operations and
can readily be validated by a simple proof checker.
For the case of refutation proofs, PGBDDQ builds on the work of Jussila, et al. [17],
whose BDD-based QBF solver EBDDRES could generate refutation proofs in an ex-
tended resolution framework. Whereas their solver, as well as all other published BDD-
based QBF solvers [23,24], require the BDD variable ordering to be the inverse of the
quantiﬁcation ordering, PGBDDQ allows independent choices for the two orderings. As
will be shown, this can lead to an exponential advantage on some benchmarks.
We evaluate the performance of PGBDDQ using a scalable benchmark based on a
two-player tiling game. We show that, with the right combination of Tseitin variable
placement, BDD variable ordering and elimination variable ordering, a BDD-based
QBF solver can achieve performance that scales polynomially with the problem size.
In these cases, PGBDDQ can readily outperform state-of-the-art search-based solvers,
while having the added beneﬁt that it generates a checkable proof.
2
Background Preliminaries
A literal l is either a variable y or its complement y. We denote the underlying variable
for literal l as Var(l), while l denotes the complement of literal l.
A clause is a set of literals, representing the disjunction of a set of complemented
and uncomplemented variables. The empty clause, indicating logical falsehood, is writ-
ten ⊥. We consider only proper clauses, where a literal can only occur once in a clause,
and a clause cannot contain both a variable and its complement. Logical truth, or tau-
tology, is denoted ⊤and represented by an empty set of clauses. For clarity, we write
clauses as Boolean formulas, such as x ∧y →z for the clause {x, y, z}. As a special
case, the unit clause consisting of literal l is simply written as l.

ITE: For Boolean values a, b, and c, the ITE operation (short for “If-Then-Else”) is
deﬁned as: ITE(a, b, c) = (a∧b)∨(¬a∧c). This can be also be written as a conjunction
of clauses: ITE(a, b, c) = (a →b) ∧(¬a →c).
QBF: We consider quantiﬁed formulas in prenex normal form over a set of input vari-
ables X, with input formula ΦI having the form ΦI = Q1X1 Q2X2 · · · QmXm ψI.
The quantiﬁer preﬁx QI = Q1X1 Q2X2 · · · QmXm consists of a series of quantiﬁer
blocks. Each block j has an associated quantiﬁer Qj ∈{∀, ∃} and a set of variables
Xj ⊆X, such that the sets X1, X2, . . . , Xm form a partitioning of X. The formula
matrix ψI is given as a set of clauses referred to as the input clauses. An input variable
x occurring in some partition Xj is said to be universal (respectively, existential) when
Qj = ∀(resp., Qj = ∃) and is said to be at quantiﬁcation level j. The type and level of
each literal l matches that of its underlying variable Var(l).
Resolution: Let C and D be clauses, where C contains variable y and D contains its
complement y. We also require that there can be no literal l ∈C, with l ̸= y, such
that l ∈D. The resolvent clause is then deﬁned as Res(C, D) = C ∪D −{y, y}.
When C and D do not satisfy the above requirements, then Res(C, D) is undeﬁned.
This deﬁnition does not allow the resolvent to be a tautology.
The resolution operation extends to linear chains and sets of clauses, as well. For a
clause sequence C1, C2, . . . , Ck, we deﬁne its resolvent as:
Res(C1, C2, . . . , Ck) = Res(C1, Res(C2, · · · , Res(Ck−1, Ck) · · · ))
The sequence C1, C2, . . . , Ck is termed the antecedent. Again, the operation is unde-
ﬁned if any individual application of the operation is undeﬁned. For a set of clauses
ψ, we deﬁne Res(ψ) as the set of all resolvents that can be generated from sequences
comprised of clauses from ψ with each clause used at most once per sequence.
As a separate notation, for a set of clauses ψ, we let Resy(ψ) be the set of all deﬁned
resolvents Res(C, D) with C, D ∈ψ, y ∈C, and y ∈D.
Extension: Extended resolution [28] allows the introduction of extension variables to
serve as a shorthand notation for other formulas. Generalizing extended resolution to
quantiﬁed formulas requires additional considerations regarding 1) the distinction be-
tween existentially and universally quantiﬁed variables, and 2) the position of the ex-
tension variables within the quantiﬁcation ordering. In particular, as extension variables
are generated, they must be classiﬁed as existential and be inserted into intermediate
positions in the ordering [3, 17]. To support this capability, we associate a quantiﬁca-
tion level λ(y) with each input and extension variable y. For input variable x, where
x ∈Xj, we deﬁne λ(x) = 2j −1. Input variables will therefore have odd values for
λ. Each extension variable e will be assigned an even value for λ(e) according to rules
deﬁned below. For literal l, we deﬁne λ(l) = λ(Var(l)).
As clauses are added and deleted, and as extension variables are introduced, a for-
mula will be maintained with an overall form
Φ = Q1X1 ∃E1 Q2X2 ∃E2 · · · QmXm ∃Em ψ
(1)
where E1, E2, . . . , Em is a partitioning of the set of extension variables. The quantiﬁer
preﬁx Q in (1) is therefore an alternation of input and extension variables, with all
extension variables being existentially quantiﬁed. We can also view the quantiﬁer preﬁx
Dual Proof Generation for QBF with a BDD-based Solver
435

436
R. E. Bryant and M. J. H. Heule
as simply being a set of variables y, being ordered by the values of λ(y), and where y
is universal when λ(y) = 2j −1 with Qj = ∀. Otherwise, y is existential. We use
set notation when referring to the quantiﬁer preﬁx, recognizing that the partitioning of
variables into quantiﬁer blocks and the associated quantiﬁer types, are deﬁned implicitly
by the function λ.
Two quantiﬁer preﬁxes Q and Q′, each with m input variable blocks, are said to be
compatible when Qj = Q′
j for 1 ≤j ≤m, and λ(y) = λ′(y) for all y ∈Q ∩Q′,
where the unprimed and primed symbols correspond to Q and Q′, respectively.
Extension introduces existential variable e by adding a set of deﬁning clauses θ to
the matrix and adding e to the quantiﬁer preﬁx. Consider QBF Φ = Q ψ. Let e be a
fresh variable (i.e., e ̸∈Q) and let θ be a set of clauses that are blocked on e [5]. That
is, each clause in θ must contain either e or e, and for any clauses C, D ∈θ for which
e ∈C and e ∈D, there must be some other literal l ∈C such that l ∈D, and therefore
Rese(θ) = ∅. Deﬁne Φ′ = Q′ ψ′ as follows. Variable e is assigned quantiﬁcation level
λ(e) = max{Even(λ(y))|y ∈Var(θ), y ̸= e}, where Var(θ) is deﬁned to be the
set of all variables occurring in the clauses in θ. Function Even rounds a number up
to the next higher even value, i.e., Even(a) = 2 ⌈a/2⌉. This deﬁnition guarantees that
λ(e) is even and that every variable y occurring in θ will have λ(y) ≤λ(e). Letting
Q′ = Q∪{e} and ψ′ = ψ∪θ, it can be shown that Φ′ is true if and only if Φ is true [17].
Boolean Functions: The restriction of Boolean function f with respect to variable x,
denoted f|x is deﬁned as the function that results when variable x is assigned value 1.
Similarly, f|x is deﬁned as the function that results when x is assigned value 0.
The Shannon expansion relates a Boolean function to its restrictions with respect to
a variable and its complement. For a function f and variable x:
f = ITE

x, f|x, f|x

=

x →f|x

∧

x →f|x

(2)
We will ﬁnd clausal form (2) to be of use in generating satisfaction proofs.
For Boolean function f and variable x we can deﬁne the existential and universal
quantiﬁcations of f with respect to x as projection operations that eliminate the depen-
dency on x through either disjunction or conjunction:
∃x f = f|x ∨f|x
(3)
∀x f = f|x ∧f|x
(4)
BDDs: A reduced, ordered binary decision diagram (BDD) provides a canonical form
for representing a set of Boolean functions, and an associated set of algorithms for
constructing them and testing their properties [1,7,8]. A set of functions is represented
as a directed acyclic graph, with each function indicated by a pointer to its root node.
We will therefore use the symbol u to refer at times to 1) a node in the BDD, 2) the
subgraph of the BDD having u as its root, 3) the function represented by this subgraph,
and 4) an extension variable associated with the node.
The ordered BDD representation requires deﬁning a total ordering of the variables.
Unlike other BDD-based QBF solvers [17,23,24], PGBDDQ allows this ordering to be
independent of the ordering of variables in the quantiﬁer preﬁx. The two leaf nodes

are denoted L0 and L1, representing the constant functions 0 and 1, respectively. Each
nonterminal node u has an associated variable and two children indicating branches for
the two possible values of the variable.
BDD packages support multiple operations for constructing and testing the prop-
erties of Boolean functions represented by a BDD. A number of these are based on
the Apply algorithm [6]. Given root nodes u and v representing functions f and g, re-
spectively, and a Boolean operation (e.g., AND), the algorithm generates a root node
w representing the result of applying the operation to those functions (e.g., f ∧g).
It operates by traversing its arguments via a series of recursive calls, using a table to
cache previously computed results. Variants of the Apply algorithm can also perform
restriction and quantiﬁcation.
QBF Solving with a BDD: With the ability to perform disjunction, conjunction, and
quantiﬁcation of Boolean functions, there is a straightforward algorithm for solving a
QBF with a BDD. It starts by computing a representation of the formula matrix using
the Apply algorithm with operation ∨for each clause and conjuncting these using the
Apply algorithm with operation ∧. Then, quantiﬁers are eliminated by working from
the innermost quantiﬁer block Xm and working outward, using either universal or exis-
tential quantiﬁer operations. At the end, the BDD will be reduced to either L0 indicating
that the formula is false, or L1 indicating that the formula is true. This basic algorithm
can be improved by deferring some of the conjunctions and by carefully selecting the
order of quantiﬁcation within each quantiﬁer block [23,24].
3
Logical Foundations
A clausal proof consists of a sequence of steps starting with the clauses in the input
formula ΦI. Each step either adds a set of clauses, and possibly an extension variable,
or it removes a set of clauses. These additions and removals deﬁne a sequence of QBFs
Φ1, Φ2, . . . , Φt, with Φ1 = ΦI and each Φi of the form Qi ψi.
For a refutation proof, each step i must preserve truth, i.e., Φi →Φi+1, and it must
end with ⊥∈ψt. This construction serves as a proof that ΦI = Φ1 →Φ2 →· · · →
Φt = ⊥, and therefore the input formula is false. A satisfaction proof follows the same
general format, except that it requires each step i to preserve falsehood: Φi+1 →Φi, and
it reaches a ﬁnal result with ψt = ∅. This construction serves as a proof that ⊤= Φt →
Φt−1 →· · · →Φ1 = ΦI, and therefore the input formula is true. A dual proof requires
that each step preserves equivalence: Φi ↔Φi+1, i.e., it is both truth and falsehood
preserving. Only the ﬁnal step with ψt ∈{⊥, ⊤} determines whether it is a refutation
or a satisfaction proof.
3.1
Inference Rules
Table 1 shows the equivalence-preserving inference rules we use in our proofs. These
are based on redundant clauses—cases where there are two sets of clauses ψ and θ such
that Q ψ ↔Q′ (ψ ∪θ), for compatible preﬁxes Q and Q′. Thus, adding clauses θ to
the matrix ψ deﬁnes an equivalence-preserving addition rule, while deleting them from
the matrix ψ ∪θ deﬁnes an equivalence-preserving removal rule.
437
Dual Proof Generation for QBF with a BDD-based Solver

438
R. E. Bryant and M. J. H. Heule
Table 1. Inference rules where clause set θ is redundant with respect to the clauses in ψ.
Addition
Removal
Requirements
Resolution addition
Resolution deletion θ ⊆Res(ψ).
Universal reduction
—
θ = {C}. l universal. λ(l′) < λ(l) for all existential
l′ ∈C. C ∪{l} ∈ψ.
Extension
Existential
elimination
y existential. y ̸∈Var(ψ). y ∈Var(C) for all C ∈
θ.Resy(θ) ⊆ψ. λ(y′) ≤λ(y) for all y′ ∈Var(θ).
We have already described resolution in Section 2. Universal reduction (also known
as “forall reduction” [4,17]) is the standard rule for eliminating universal variables in a
QBF refutation proof [18].
The extension rule forms the basis for adding extension variable y = e and its
deﬁning clauses θ. For this case, the clauses in θ are blocked with respect to y, and
therefore Resy(θ) = ∅. As a deletion rule, the existential elimination rule is used to
remove extension variables and their deﬁning clauses, as well as to remove the existen-
tial input variables. It is a generalization of blocked clause elimination [5] in that the
clauses in θ need not be blocked, as long as ψ contains all of the resolvents with respect
to variable y. The redundancies used by the resolution, extension, and existential elimi-
nation rules are special cases of the quantiﬁed resolution asymmetric tautology (QRAT)
property [13,14].
3.2
Integrating Proof Generation into BDD Operations
As described in [16, 17, 26] and [9], we use a BDD to represent Boolean functions
deﬁned by applying Boolean operations to the input variables X. When creating node
u, we introduce an extension variable, also referred to as u, with up to four deﬁning
clauses. For node u with variable x, and children nodes u1 and u0, these clauses encode
the formula u ↔ITE(x, u1, u0). As described in Section 2, we will have λ(u) =
max{λ(x) + 1, λ(u1), λ(u0)}.
As in [9], we associate leaf nodes L0 and L1 directly with logical values ⊥and ⊤.
When constructing node u, if either u1 or u0 is a leaf node, the deﬁning clauses may
be simpliﬁed, and some may degenerate to tautologies. By deﬁning λ(⊥) = λ(⊤) = 0,
we can still use the above formula to deﬁne the value of λ(u), such that λ(u1) ≤λ(u),
λ(u0) ≤λ(u), and λ(x) < λ(u). This guarantees that the value of λ(u) is greater or
equal to that of any node or variable occurring in the subgraph with root u.
For node u, deﬁne its support set S(u) as the set of variables occurring at some node
in the subgraph with root u. Based on our construction, any node u will have λ(u) = 2j
if and only if there is some j and some x for which x ∈Xj ∩S(u), and this property
does not hold for any j′ > j.
As a ﬁnal notation, let θ(u) denote the set consisting of the deﬁning clauses for all
nodes in the subgraph with root u.
The BDD package implements the set of operations shown in the Table 2. Each
generates a result node w, and it also generates sets of clauses forming extended reso-

Table 2. Required BDD Operations. Each generates a root node plus a set of proofs.
Operation
Arguments
Result
Proved Properties
Truth Preserving
Falsehood Preserving
FROMCLAUSE
C
u = 
l∈C l
C, θ(u) ⊢u
u, θ(u) ⊢C
APPLYAND
u, v
w = u ∧v
u ∧v →w
w →u, w →v
APPLYOR
u, v
w = u ∨v
u →w, v →w
w →u ∨v
RESTRICT
u, l
w = u|l
l ∧u →w
l ∧w →u
lution proofs of some properties relating the result to the arguments. As shown, some
of these properties are truth preserving, while others are falsehood preserving. In each
of these, C indicates a clause, u, v, and w are BDD nodes (or their associated extension
variables), and l is a literal of an input variable.
These operations serve the following roles:
– FROMCLAUSE generates the BDD representation u of a clause C. It also generates
a set of resolution steps proving that the unit clause u is logically entailed by the
input clause and deﬁning clauses: u ∈Res({C} ∪θ(u)), and the converse: C ∈
Res({u} ∪θ(u)).
– APPLYAND generates the BDD representation w of the conjunction of its argu-
ments. It also generates a proof that the extension variables for the argument and
result nodes satisfy u ∧v →w, as well as a proof of the converse: w →u and
w →v, and therefore w →u ∧v.
– APPLYOR generates the BDD representation w of the disjunction of its arguments.
Its generated proofs include u →w and v →w, implying that u ∨v →w, as well
as the converse: w →u ∨v.
– RESTRICT generates the restriction w of argument u with respect to literal l. It
generates proofs that the operation satisﬁes downward implication: l ∧u →w,
and also upward implication: l ∧w →u. This operation has the property that for
x = Var(l), variable x will not occur in the subgraph with root w, i.e., x ̸∈S(w).
4
Integrating Proof Generation into a QBF Solver
PGBDDQ solves a QBF by maintaining a set T of root nodes, which we refer to as
“terms.” Each term is the result of conjuncting and applying elimination operations
to some subset of the input clauses. T initially contains the root nodes for the BDD
representations of the input clauses. The solver repeatedly removes one or two terms
from T, performs a quantiﬁcation or conjunction operation, and adds the result to T,
except that terms with value L1 are not added. Quantiﬁers are eliminated in reverse
order, starting with block Xm and continuing through X1. The process continues until
either some generated term is the leaf value L0, indicating that the formula is false, or
the set becomes empty, indicating that the formula is true. The solver simultaneously
generates proof steps, including ones that add a unit clause u for each node u ∈T.
Our presentation describes the general requirements for applying conjunction and
elimination operations. These operations can be used to implement the basic method
439
Dual Proof Generation for QBF with a BDD-based Solver

440
R. E. Bryant and M. J. H. Heule
described in Section 2, as well as more sophisticated strategies that defer conjunctions
until they are required before performing some of the elimination operations [23,24].
Universal quantiﬁcation commutes with conjunction and so can be applied to the
terms independently. Applying existential quantiﬁcation, on the other hand, requires
performing conjunction operations until the variables to be quantiﬁed occur only in a
single term.
4.1
Dual Proof Generation
For both technical and implementation reasons, which we explain below, we require the
input formula to have only a single variable in each quantiﬁer block. This restriction can
be satisﬁed by rewriting an arbitrary QBF, such that a quantiﬁer block with k variables
is serialized, splitting it into a sequence of k distinct quantiﬁcation levels.
When generating a dual proof, the solver generates steps proving that each update
to the set of terms T preserves equivalence with the input formula. More formally,
consider a matrix ψ containing the following clauses: 1) unit clause u for each u ∈T,
plus 2) all of the deﬁning clauses θ(u) for the subgraph rooted by each node u ∈
T. Let Q be the compatible quantiﬁer preﬁx formed by augmenting input preﬁx QI
with the extension variables associated with the nodes in these subgraphs. Then each
update preserves the invariant that QI ψI ↔Q ψ. Furthermore, the solver takes care to
systematically delete clauses once they are no longer needed, using the removal rules
listed in Table 1. That enables it to ﬁnish with an empty set of clauses in the event the
formula is true. The initial set of terms T consists of a root node u for each input clause
C, and the solver uses the proof that C, θ(u) ⊢u to justify adding unit clause u to the
proof. It then uses this unit clause, plus the proof that u, θ(u) ⊢C to justify deleting
input clause C.
Each step proceeds by generating new terms and by adding and removing clauses
in the proof. Suppose the step involves computing results with root nodes w1, ..., wn
based on argument terms u1, . . . , uk. If any of the result nodes is BDD leaf L0, then
the formula is false. The solver can use truth-preserving rules generated by the BDD
operations to justify adding an empty clause. Otherwise, the solver removes the argu-
ment terms from T and adds the result nodes, except for any equal to BDD leaf L1. The
solver uses the existing unit clauses plus the truth-preserving rules to justify adding unit
clauses for each newly added term. It then uses the falsehood-preserving rules and the
newly added unit clauses to justify deleting the unit clauses associated with the argu-
ment terms. It must also explicitly generate rules to remove some intermediate clauses
that are added during these proof constructions. Other clauses, including the deﬁning
clauses for the BDD nodes and the clauses added during the BDD operations get re-
moved by a separate process described in Section 4.2. The net effect for each step then
is to replace the argument terms in T by the non-constant result terms, maintaining a
unit clause for each term in T as part of the proof.
Conjunction operations. For u, v ∈T, the solver computes w = APPLYAND(u, v).
For the case where w = L0 the generated truth-preserving proof will be the clause u∨v,
which resolves with unit clauses u and v to generate the empty clause—the solver has
proved that the formula is false.

Otherwise, the solver sets T to be T −{u, v} ∪w. The proof for adding unit clause
w follows by resolving the unit clauses u and v with the generated clause u ∨v ∨w,
(i.e., u ∧v →w). The generated clauses w →u and w →v each resolve with unit
clause w to justify deleting unit clauses u and v.
Universal elimination operation. This operation is performed when Qj = ∀, and by
our restriction, we must have Xj = {x} for some universal variable x. We also require
that the input variables for blocks Xj′ such that j′ > j have already been eliminated.
Since universal quantiﬁcation commutes with conjunction, the solver can quantify
each term individually and let subsequent conjunction operations perform the conjunc-
tion indicated in (4). That is, for each u ∈T such that x ∈S(u), operation RESTRICT
is used to compute the two restrictions wx = u|x and wx = u|x. These will generate
proofs of two downward implications: l ∧u →wl for l ∈{x, x}, as well as proofs of
two upward implications: l ∧wl →u.
If wl equals leaf node L0 for either l = x or l = x, then the corresponding down-
ward implication will be a clause of the form l∧u →⊥= l∨u. Resolving this with the
unit clause u and applying universal reduction generates the empty clause—the solver
has proved that the formula is false.
Consider the general case, where neither wx nor wx is a leaf node. The solver sets
T = T ∪{wx, wx} −{u}. The downward implications l ∧u →wl can be resolved
with unit clause u to yield the clause l →wl for l ∈{x, x}. We can be certain that
λ(wl) < λ(x) for both values of l, since x ̸∈S(wl). Applying universal reduction to
the two generated clauses then yields the unit clauses wx and wx. Resolving each unit
clause wl with the upward implication l∧wl →u gives the clause l →u, for l ∈{x, x}.
Resolving these with each other justiﬁes deleting unit clause u. Intermediate clauses
x →w, x →w, x →wx, and x →wx are removed by resolution deletion.
The case where one of the restrictions is the leaf node L1 is handled similarly to the
general case, except that this node is not added to T.
Our implementation applies the conjunction operation to terms wx and wx imme-
diately after they are generated to avoid causing the number of terms to expand by a
factor of 2k when the formula contains a sequence of k universal quantiﬁers.
Existential elimination operations. This operation is performed when Qj = ∃. We
can assume that Xj = {x} for some existential variable x. We require that the input
variables for blocks Xj′ such that j′ > j have already been eliminated. We also require
the conjunction operations to have reduced T to contain at most one node u such that
x ∈S(u). The solver proceeds as follows to existentially quantify x from u yielding a
new term w and creating the justiﬁcation for adding unit clause w. It also removes unit
clause u, as well as some intermediate clauses. Note that w can equal L1, but not L0.
1. Compute ux = RESTRICT(u, x) and ux = RESTRICT(u, x), generating proofs of
the downward implications x ∧u →ux and x ∧u →ux, as well as the upward
implications x∧ux →u and x∧ux →u. Resolving the two downward implications
with the unit clause u justiﬁes adding clauses Cx = x →ux and Cx = x →ux.
These clauses form the Shannon expansions (2) of u with respect to variable x.
2. For l ∈{x, x}, resolving clause Cl with the upward implication l∧ul →u justiﬁes
adding clauses x →u and x →u. Resolving these with each other justiﬁes deleting
unit clause u. This step completes the replacement of u by its Shannon expansion.
441
Dual Proof Generation for QBF with a BDD-based Solver

442
R. E. Bryant and M. J. H. Heule
3. Apply clause removal to remove every clause containing a literal l such that λ(l) >
λ(x) = 2j −1. This is described in Section 4.2.
4. Cx and Cx are the only clauses remaining that contain either x or x. Resolving
these with each other justiﬁes adding clause ux ∨ux. The existential elimination
rule can now be applied to justify deleting Cx and Cx, with the result that there will
be no further clauses containing any literal l with λ(l) ≥λ(x).
5. Compute w = APPLYOR(ux, ux), generating three proofs: ux →w, ux →w, and
w →ux ∨ux.
6. If w is leaf node L1, then the falsehood-preserving proof generated by APPLYOR
derives the clause ux ∨ux. This proof justiﬁes deleting the instance of this clause
added in step 5. If w is a nonleaf node, then the ﬁrst two proofs from Step 5 can be
resolved with the clause ux ∨ux to justify adding unit clause w, and the third can
be resolved with this unit clause to justify deleting clause ux ∨ux. This completes
the replacement of u by the disjunction of its two restrictions, as in (3).
7. If w is leaf node L1, then set T to T −{u}. Otherwise, set it to T −{u} ∪{w}.
Overall Operation: For a false formula, the solver will terminate with the generation
of leaf value L0 during a conjunction or universal quantiﬁcation operation. These cases
will cause the proof to terminate with the addition of an empty clause. For a true for-
mula, the solver will ﬁnish with T equal to the empty set, since it never adds a leaf node
to T. A ﬁnal clause removal operation with quantiﬁcation level 0 then yields ψt = ∅.
We can see now why we impose the restriction that any quantiﬁer block Xj with
Qj = ∀contain only one variable. Without it, the universal variable elimination opera-
tion may not be possible. Suppose Xj = {x, x′}. Attempting to perform the universal
quantiﬁcation operation on variable x could yield a BDD node wl, with either l = x or
l = x, that depends on x′. That would require that λ(wl) > λ(x′) = λ(x), and so the
universal reduction rule could not be applied. Serializing the universal blocks avoids
this difﬁculty, without limiting the generality of the solver.
4.2
Clause Removal
As a dual proof proceeds, the BDD operations cause clauses to be added as extension
variables are introduced and as inferences are made via resolution. Other clauses are
added and removed explicitly by the proof steps, including the unit clauses for each
term and the intermediate clauses generated by the steps. In order to support having the
outcome of the solver be true, the deﬁning and resolution clauses must be removed in
order to ultimately end up with an empty set of clauses. The solver must justify their
removal, since clause deletion is not, in general, equivalence preserving.
Clause removal is triggered when performing existential quantiﬁcation, just before
applying the variable elimination rule with variable x to remove clauses Cx and Cx
(step 3). We must ﬁrst ensure that there are no other clauses containing x or x.
Our method is to remove any clause C containing a literal l for which λ(l) >
λ(x) = 2j −1. Clause removal can proceed by stepping through the clauses in the
reverse order from how they were added. If a clause that was added by resolution con-
tains a literal l with λ(l) ≥2j, it can be removed via resolution deletion, using the same
antecedent as was used when it was added.

Suppose the solver encounters the deﬁning clauses for a node u with λ(u) ≥2j.
It can be certain that all clauses added by resolution that contain either u or u have
already been removed, since these must have followed the introduction of u in the clause
ordering. Similarly, any parent node v of u must have already had its deﬁning clauses
removed, since the deﬁning clauses for v must occur after those for u. The existential
elimination rule can therefore be used to remove the deﬁning clauses for u.
Working through the set of clauses in reverse order, the solver may encounter clauses
added by resolution and deﬁning clauses containing only literals l with λ(l) < 2j −1.
These need not be removed, and indeed they can prove useful (clauses added by reso-
lution) or necessary (some deﬁning clauses) for subsequent proof steps. They will be
deleted by clause removal during later phases.
We can see now why we impose the restriction that any quantiﬁer block Xj with
Qj = ∃contain only one variable. It enables the use of the λ values to determine
which clauses should be removed to eliminate any dependency on existential variable x.
Serializing the existential quantiﬁer blocks allows this scheme to work without limiting
the generality of the solver.
4.3
Specializing to Refutation or Satisfaction Proofs
Dual proofs have the advantage that they can be generated as a single pass, without
knowing in advance whether the formula is true or false. On the other hand, they are,
by necessity, somewhat longer and require more time to generate and to check. Another
approach is to know (or guess) what the outcome will be and then direct the solver to
generate a pure refutation or satisfaction proof. Specializing the proof generation to one
of these forms is straightforward, and it can take advantage of more efﬁcient ways to
perform some of the quantiﬁcations.
A refutation proof need only justify that each step preserves truth. This enables sev-
eral optimizations. Observe that deleting a clause always preserves truth, because it can
only cause the set of satisfying solutions for the matrix to expand. Therefore clause
deletion can be performed without any justiﬁcation and instead be incorporated into
the BDD garbage collection process [9]. Second, the BDD package need not gener-
ate the falsehood-preserving proofs shown in Table 2, reducing the number of clauses
generated. Finally, the existential operation of (3) is inherently truth preserving. BDD
packages can implement the quantiﬁcation of a function by an entire set of variables via
a variant of the Apply algorithm. If the quantiﬁcation of root node u generates result
node w, then the solver can run an implication test after the BDD computation has been
performed to prove that u →w, as is done with our SAT solver [9]. This avoids the
need to serialize existential quantiﬁer blocks and to have the solver generate low-level
proof steps for each existential variable.
Conversely, a satisfaction proof need only justify that each step preserves falsehood.
Adding a clause always preserves falsehood, since it can only reduce the set of satis-
fying solutions for the matrix, and therefore clause addition can be performed without
any justiﬁcation. In addition, the BDD package need not generate the truth-preserving
proofs shown in Table 2. Finally, universal quantiﬁcation can be performed on an en-
tire block of variables producing node w from argument u. The solver can then run an
implication test to generate a proof that w →u.
443
Dual Proof Generation for QBF with a BDD-based Solver

444
R. E. Bryant and M. J. H. Heule
5
Experimental Results
PGBDDQ1 is written entirely in Python and consists of around 3350 lines of code, in-
cluding a BDD package, support for generating extended-resolution proofs, and the
overall QBF solver. By comparison, our proof-generating BDD-based SAT solver re-
quired around 2130 lines of code [9]. PGBDDQ can generate proofs in either the QRAT
format [13,14] or in a format we call QPROOF that supports just the proof rules given
in Table 1. The latter format requires explicit lists of antecedents, and therefore each
step can be checked without any search.
The overall control of PGBDDQ is based on a form of bucket elimination [10], where
each quantiﬁer block Xj deﬁnes a bucket. It starts by generating BDD representations
of the input clauses. The resulting terms are inserted into buckets according to the value
of λ(u) for each root node u. As described in Section 3.2, this value will be 2j when
u contains a variable from block Xj in its support, and it has no variables at higher
quantiﬁcation levels.
Processing proceeds from the highest numbered bucket downward. For a universal
level, quantiﬁcation is performed for each bucket element individually with the results
placed into buckets according to their values for λ. For an existential level, the elements
are conjuncted and then existential quantiﬁcation is performed. The result is placed into
a bucket according to its value of λ.
We can see that this approach defers conjunction as long as possible, only operating
on terms at some quantiﬁcation level j that truly depend on one or more variables in Xj.
Similar techniques have been used in other BDD-based QBF solvers [23,24]. However,
other implementations place terms into buckets according to the BDD level of their root
nodes, requiring the BDD variables to be ordered as the inverse of the quantiﬁcation
ordering. By labeling each node with its value of λ, we can determine the appropriate
bucket from the root node without regard to the BDD variable ordering.
We have tested PGBDDQ on a number of scalable benchmark problems, ﬁnding it
performs well in some cases, scaling polynomially, and poorly in others, scaling expo-
nentially. Here we present results for a problem based on a two-player game. It provides
insights into how polynomial scaling can be achieved, as well as the performance of the
solver and two checkers.
Two-player games provide a rich set of benchmarks for QBF solvers, with each turn
being translated into a quantiﬁcation level. To encode the game from the perspective
of the ﬁrst player (Player A), A’s turns are encoded with existential quantiﬁers, while
the second player’s (Player B) turns are encoded with universal quantiﬁers. The formula
will be true if the game has a guaranteed winning strategy for A. The encoding of a game
into QBF constrains the two players to only make legal moves. It also expresses the
conditions under which A is the winner, namely that the game consist of t consecutive
moves, for an odd value of t. Conversely, we can encode the formula where B has a
winning strategy by reversing the quantiﬁers and expressing that the game must consist
of an even number of consecutive moves. For a game where no draws are possible, these
two formulas will be complementary.
1 A demonstration version, complete with solver, checker, and benchmarks, is available at
https://github.com/rebryant/pgbddq-artifact.

Consider a game played on a 1 × N grid of squares with a set of dominos, each of
which can cover two squares. Players alternate turns, each placing a domino to cover
two adjacent squares. The game completes when no more moves are possible, taking at
most ⌊N/2⌋turns. The ﬁrst player who cannot place a domino loses. This linear domino
placement game is isomorphic to the object-removal game “Dawson’s Kales” [2]. It can
be shown that player B has a winning strategy for N ∈{0, 1, 15, 35} as well as for all
values of the form 34 i + c where i ≥0 and c ∈{5, 9, 21, 25, 29} [27].
The game is encoded as a QBF by introducing a set of N −1 input variables for each
possible move, each corresponding to the boundary between a pair of adjacent squares.
A set of N −1 Tseitin variables encodes the board state after each move, and sets of
clauses enforce the conditions that 1) each move should cover exactly one boundary,
and 2) neither that boundary nor the two adjacent ones should have been covered pre-
viously. In all, there are around N 2/4 universal input variables, N 2/4 existential input
variables, and 3N 2/2 Tseitin variables. The number of clauses grows as Θ(N 3) due
to the quadratic number of clauses to enforce the exactly-one constraints on the input
variables for each move.
To achieve polynomial performance, we found that several problem-speciﬁc tech-
niques are required. First, the Tseitin variables for a given move are placed in an exis-
tential quantiﬁer block immediately following the block for the input variables for the
move. This is logically equivalent to the usual convention of placing all Tseitin vari-
ables in an innermost quantiﬁer block, but it enables the bucket elimination algorithm
to process the clauses for each move in sequence, rather than expanding the formulas in
terms of only the input variables at the outset. Second, all variables are ordered for the
BDD in “boundary-major” ordering. That is, all variables, including input and Tseitin
variables, for the ﬁrst boundary on the board are included from the ﬁrst quantiﬁcation
level to the last. The variables for the second boundary follow similarly, and so on for
all N −1 boundaries. This ordering has the effect that, when processing the clauses for
some move, the variables encoding the next, and previous state for a boundary, as well
as the proposed change to its state, are localized within the ordering. Finally, when split-
ting a quantiﬁer block into a series of single-variable blocks, we ordered them according
to their BDD variable ordering. Since the solver eliminates variables in the reverse of
their quantiﬁer ordering, this convention causes the disjunction and conjunction opera-
tions of Equations (3) and (4) to be performed mainly on subgraphs of the BDD below
the variables being quantiﬁed. This enables greater use of previously computed results
via the operation cache.
Table 3 shows the performance of PGBDDQ, two checkers, and two other QBF
solvers on the domino placement game as functions of N. It shows ﬁrst cases where
the encoded player has a winning strategy, and therefore the formula is true, and then
cases where the encoded player’s opponent has a winning strategy, and therefore the
formula is false. Dual proofs were generated for both cases. For measurements with
sufﬁcient data points, we show the scaling trends, obtained by performing a linear re-
gression on the logarithms of data generated for each value of N in increments of 5.
All measurements were performed on a 4.2 GHz Intel Core i7 (I7-7700K) processor
with 32 GB of memory running the MacOS operating system. Times are measured in
elapsed seconds.
445
Dual Proof Generation for QBF with a BDD-based Solver

446
R. E. Bryant and M. J. H. Heule
Table 3. Experimental Results for Dual Proof Generation with Linear Domino Placement Game.
The ﬁrst data series are for proofs of true formulas, and the second are for false formulas. Entries
shown as “—” indicate cases where the program exceeded a 7200-second time limit.
N
Winner/
Input
PGBDDQ
Other solvers
Player Clauses Total Clauses
Solve
Qproof
QRAT-TRIM DEPQBF GHOSTQ
10
A/A
666
132,138
3.1
3.3
3.4
0.1
0.0
15
B/B
1,725
628,392
15.2
15.7
43.8
3.8
1.3
20
A/A
3,880
2,572,139
67.3
65.5
605.0
1896.6
57.9
25
B/B
6,637
7,098,146
202.6
199.5
4265.6
—
—
40
A/A
24,010
83,736,352
3358.6
3479.5
—
—
—
Trend
N 2.7
N 4.5
N 4.8
N 4.8
10
A/B
664
132,403
3.1
3.2
7.3
0.1
0.0
15
B/A
1,728
629,530
15.2
15.5
108.7
3.6
1.0
20
A/B
3,885
2,580,284
67.2
66.7
1521.5
—
49.1
25
B/A
6,631
7,083,515
205.1
190.0
—
—
6942.2
40
A/B
24,000
83,662,168
3279.2
3457.4
—
—
—
Trend
N 2.7
N 4.5
N 4.8
N 4.8
As indicated in the column labeled “Input Clauses,” the number of clauses grows
as N 2.7, not quite reaching the asymptotic value of N 3. The number of proof clauses
generated by PGBDDQ are nearly the same for both true and false formulas, with growth
rates of N 4.5. The time taken by the solver (labeled “Solve”) , and by our own checker
(“Qproof”) scale at about the same rate as the number of proof clauses.
We also benchmarked the QBF proof checker QRAT-TRIM [13, 14]. This program
was already equipped to handle our forms of refutation and satisfaction proofs, and it
can handle dual proofs without modiﬁcation. The only concession to the idiosyncrasies
of PGBDDQ was to serialize the universal quantiﬁer blocks in the preﬁx of false formu-
las. This is required to enable application of the universal reduction rule. The existential
blocks can stay intact, since our only reason to serialize these is to guide the clause re-
moval process. Although the scaling of QRAT-TRIM is poor, it is encouraging that the
solver can be veriﬁed by a checker that predates it by a number of years.
For comparison, we evaluated the performance of two other QBF solvers on this
benchmark: DEPQBF, version 6.0 [20], and GHOSTQ [15,19]. We found they are both
very fast for smaller values of N but then reach a narrow range of values for which
they transition from running in just a few seconds to exceeding the timeout limit of
7200 seconds. For DEPQBF, this transition occurs as N ranges from 17 to 21, and for
GHOSTQ, as N ranges from 21 to 26. PGBDDQ is much slower for small values of N,
but it keeps scaling without hitting a sudden cutoff.
Although we did not run EBDDRES [17], we can use PGBDDQ to evaluate the im-
pact of having the BDD variable ordering be the inverse of the quantiﬁer ordering. Our
experiments show that this ordering causes the runtime and proof sizes to scale expo-
nentially in N. With N = 14 and B as the player, PGBDDQ runs for 4100 seconds to
generate a refutation proof with 114,157,025 clauses. By contrast, a boundary-major
ordering requires just 6 seconds and generates a proof with 309,387 clauses.

Table 4. Experimental Results for Specialized Proof Generation with Linear Domino Placement
Game. The ﬁrst data series are for satisfaction proofs, and the second are for refutation proofs.
N
Winner/Player Input Clauses
Total Clauses
Solve
Qproof
10
A/A
666
90,924
1.8
1.4
20
A/A
3,880
1,516,756
36.4
24.0
30
A/A
11,166
10,466,168
346.0
192.6
40
A/A
24,010
44,874,662
1990.3
1254.8
45
A/A
32,241
74,891,554
4033.4
2760.8
Trend
N 2.7
N 4.4
N 4.8
N 4.7
10
A/B
664
126,127
2.4
1.8
20
A/B
3,885
1,232,252
27.3
18.6
30
A/B
11,159
7,084,367
180.0
121.6
40
A/B
24,010
26,150,238
773.9
565.0
50
A/B
43,904
85,077,630
2955.4
2151.4
Trend
N 2.7
N 4.0
N 4.3
N 4.3
Table 4 shows the advantage of generating specialized proofs when the formula is
known in advance to be true or false. Comparing the columns labeled “Total Clauses” in
Tables 3 and 4, we can see especially that refutation proofs are asymptotically shorter.
These can take advantage of the more efﬁcient approach to existential quantiﬁcation in
handling the large number of Tseitin variables. Again, the solution and checking time
track the proof sizes. These optimizations allowed us to solve larger instances of the
problem—up to N = 45 for true instances and N = 50 for false ones.
6
Conclusions
We have demonstrated that a QBF solver can emit a single proof as it operates, leading
to either an empty clause for a false formula or an empty set of clauses for a true one.
Both the proof and the time required to check it scale as the number of BDD operations
performed. Moreover, a BDD-based QBF solver can allow the choice of BDD variable
ordering to be made independently from the quantiﬁer ordering. This feature can be
critical to obtaining performance that scales polynomially with the problem size.
Our prototype is only a start in implementing a fully automated QBF solver. Such
a solver must be able to choose a BDD variable ordering based on the input formula
structure. It must also be able to identify and move Tseitin variables to earlier positions
in the quantiﬁer ordering, generating proof steps justifying that this transformation is
equivalence preserving.
The underlying operation of PGBDDQ has potential applications beyond QBF solv-
ing. The program could stop the process described in Section 4.1 at any point and gen-
erate a QBF that is provably equivalent to the input formula. PGBDDQ could therefore
be used as a preprocessor for other solvers, and for other applications that require rea-
soning about Boolean formulas with quantiﬁers.
Acknowledgements. The second author is supported by NSF grant CCF-2010951.
447
Dual Proof Generation for QBF with a BDD-based Solver

448
R. E. Bryant and M. J. H. Heule
References
1. Andersen, H.R.: An introduction to binary decision diagrams. Tech. rep., Technical Univer-
sity of Denmark (October 1997)
2. Berlekamp, E.R., Conway, J.H., Guy, R.K.: Winning Ways for your Mathematical Plays:
Volume 1, Second edition. CRC Press (2001)
3. Beyersdorff, O., Chew, L., Janota, M.: Extension variables in QBF resolution. In: AAAI
Workshop on Beyond NP (2016)
4. Biere, A.: Resolve and expand. In: Theory and Applications of Satisﬁability Testing (SAT).
LNCS, vol. 3542, pp. 59–70 (2005)
5. Biere, A., Lonsing, F., Seidl, M.: Blocked clause elimination for QBF. In: Conference on
Automated Deduction (CADE). LNCS, vol. 6803, pp. 101–115. Springer (2011)
6. Bryant, R.E.: Graph-based algorithms for Boolean function manipulation. IEEE Trans. Com-
puters 35(8), 677–691 (1986)
7. Bryant, R.E.: Symbolic Boolean manipulation with ordered binary decision diagrams. ACM
Computing Surveys 24(3), 293–318 (September 1992)
8. Bryant, R.E.: Binary decision diagrams. In: Clarke, E.M., Henzinger, T.A., Veith, H., Bloem,
R. (eds.) Handbook of Model Checking, pp. 191–217. Springer (2018)
9. Bryant, R.E., Heule, M.J.H.: Generating extended resolution proofs with a BDD-based SAT
solver. In: Tools and Algorithms for the Construction and Analysis of Systems (TACAS)
(2021)
10. Dechter, R.: Bucket elimination: A unifying framework for reasoning. Artiﬁcial Intelligence
113(1–2), 41–85 (1999)
11. Garey, M.R., Johnson, D.S.: Computers and Intractability: A Guide to the Theory of NP-
Completeness. W. H. Freeman (1979)
12. Giunchiglia, E., Narizzano, M., Tacchella, A.: Clause/term resolution and learning in the
evaluation of quantiﬁed Boolean formulas. Journal of AI Research 26, 371–416 (2006)
13. Heule, M.J.H., Seidl, M., Biere, A.: A uniﬁed proof system for QBF preprocessing. In: Inter-
national Joint Conference on Automated Reasoning (IJCAR). LNCS, vol. 8562, pp. 91–106
(2014)
14. Heule, M.J.H., Seidl, M., Biere, A.: Solution validation and extraction for QBF. Journal of
Automated Reasoning 58, 97–125 (2017)
15. Janota, M., Klieber, W., Marques-Silva, J.a.P., Clarke, E.M.: Solving QBF with counterex-
ample guided reﬁnement. Artiﬁcial Intelligence 234, 1–25 (2016)
16. Jussila, T., Sinz, C., Biere, A.: Extended resolution proofs for symbolic SAT solving with
quantiﬁcation. In: Theory and Applications of Satisﬁability Testing (SAT). LNCS, vol. 4121,
pp. 54–60 (2006)
17. Jussila, T., Sinz, C., Biere, A., Kr¨oning, D., Wintersteiger, C.M.: A ﬁrst step towards a uniﬁed
proof checker for QBF. In: Theory and Applications of Satisﬁability Testing (SAT). LNCS,
vol. 4501, pp. 201–714 (2007)
18. Kleine B¨uning, H., Karpinski, M., Fl¨ogel, A.: Resolution for quantiﬁed Boolean formulas.
Information and Computation 117(1), 12–18 (1995)
19. Klieber, W.: GhostQ system description. Journal on Satisﬁability, Boolean Modeling, and
Computation 11, 65–72 (2019)
20. Lonsing, F., Egly, U.: DepQBF 6.0: A search-based QBF solver beyond traditional QCDCL.
In: Conference on Automated Deduction (CADE). LNCS, vol. 10395, pp. 371–384 (2017)
21. Narizzano, M., Peschiera, C., Pulina, L., Tacchella, A.: Evaluating and certifying QBFs: A
comparison of state-of-the-art tools. AI Communications 22(4), 191–210 (2009)
22. Niemetz, A., Preiner, M., Lonsing, F., Seidl, M., Biere, A.: Resolution-based certiﬁcate
extraction for QBF. In: Theory and Applications of Satisﬁability Testing (SAT). LNCS,
vol. 7317, pp. 430–435 (2012)

23. Olivo, O., Emerson, E.A.: A more efﬁcient BDD-based QBF solver. In: Principles and Prac-
tice of Constraint Programming (CP). LNCS, vol. 6876, pp. 675–690 (2011)
24. Pan, G., Vardi, M.Y.: Symbolic decision procedures for QBF. In: Principles and Practice of
Constraint Programming (CP). LNCS, vol. 3258, pp. 453–467 (2004)
25. Peitl, T., Slivovsky, F., Szeider, S.: Polynomial-time validation of QCDCL certiﬁcates. In:
Theory and Applications of Satisﬁability Testing (SAT). LNCS, vol. 10929, pp. 253–269
(2018)
26. Sinz, C., Biere, A.: Extended resolution proofs for conjoining BDDs. In: Computer Science
Symposium in Russia (CSR). LNCS, vol. 3967, pp. 600–611 (2006)
27. Sloane, N.J.A., The OEIS Foundation: The on-line encyclopedia of integer sequences (2012),
http://oeis.org/A215721, sequence A215721
28. Tseitin, G.S.: On the complexity of derivation in propositional calculus. In: Automation of
Reasoning: 2: Classical Papers on Computational Logic 1967–1970. pp. 466–483. Springer
(1983)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which per-
mits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as
you give appropriate credit to the original author(s) and the source, provide a link to the Creative
Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s Creative
Commons license, unless indicated otherwise in a credit line to the material. If material is not in-
cluded
in
the
chapter’s
Creative
Commons
license
and
your
intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain
permission directly from the copyright holder.
449
Dual Proof Generation for QBF with a BDD-based Solver

Reliable Reconstruction of Fine-grained Proofs
in a Proof Assistant
Hans-J¨org Schurr1
, Mathias Fleury2,3
, and Martin Desharnais4
1 University of Lorraine, CNRS, Inria, and LORIA, Nancy, France
hans-jorg.schurr@inria.fr
2 Johannes Kepler University Linz, Linz, Austria
mathias.fleury@jku.at
3 Max-Planck Institute f¨ur Informatik, Saarland Informatics Campus, Saarbr¨ucken,
Germany
4 Universit¨at der Bundeswehr M¨unchen, M¨unchen, Germany
martin.desharnais@unibw.de
Abstract. We present a fast and reliable reconstruction of proofs gener-
ated by the SMT solver veriT in Isabelle. The ﬁne-grained proof format
makes the reconstruction simple and eﬃcient. For typical proof steps,
such as arithmetic reasoning and skolemization, our reconstruction can
avoid expensive search. By skipping proof steps that are irrelevant for
Isabelle, the performance of proof checking is improved. Our method
increases the success rate of Sledgehammer by halving the failure rate
and reduces the checking time by 13%. We provide a detailed evaluation
of the reconstruction time for each rule. The runtime is inﬂuenced by
both simple rules that appear very often and common complex rules.
Keywords: automatic theorem provers · proof assistants ·
proof veriﬁcation
1
Introduction
Proof assistants are used in veriﬁcation and formal mathematics to provide
trustworthy, machine-checkable formal proofs of theorems. Proof automation
reduces the burden of ﬁnding proofs and allows proof assistant users to focus on
the core of their arguments instead of technical details. A successful approach
implemented by “hammers,” like Sledgehammer for Isabelle [15], is to heuristically
selects facts from the background; use an external automatic theorem prover,
such as a satisﬁability modulo theories (SMT) solver [12], to ﬁlter facts needed
to discharge the goal; and to use the ﬁltered facts to ﬁnd a trusted proof.
Isabelle does not accept proofs that do not go through the assistant’s inference
kernel. Hence, Sledgehammer attempts to ﬁnd the fastest internal method that
can recreate the proof (preplay). This is often a call of the smt tactic, which runs
an SMT solver, parses the proof, and reconstructs it through the kernel. This
reconstruction allows the usage of external provers. The smt tactic was originally
developed for the SMT solver Z3 [18,34].
© The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5 26
450–467, 2021.

The SMT solver CVC4 [10] is one of the best solvers on Sledgehammer
generated problems [14], but currently does not produce proofs for problems with
quantiﬁers. To reconstruct its proofs, Sledgehammer mostly uses the smt tactic
based on Z3. However, since CVC4 uses more elaborate quantiﬁer instantiation
techniques, many problems provable for CVC4 are unprovable for Z3. Therefore,
Sledgehammer regularly fails to ﬁnd a trusted proof and the user has to write the
proofs manually. veriT [19] (Sect. 2) supports these techniques and we extend
the smt tactic to reconstruct its proofs. With the new reconstruction (Sect. 3),
more smt calls are successful. Hence, less manual labor is required from users.
The runtime of the smt method depends on the runtime of the reconstruction
and the solver. To simplify the reconstruction, we do not treat veriT as a black
box anymore, but extend it to produce more detailed proofs that are easier
to reconstruct. We use detailed rules for simpliﬁcations with a combination of
propositional, arithmetic, and quantiﬁer reasoning. Similarly, we add additional
information to avoid search, e.g., for linear arithmetic and for term normalization.
Our reconstruction method uses the newly provided information, but it also has
a step skipping mode that combines some steps (Sect. 4).
A very early prototype of the extension was used to validate the ﬁne-grained
proof format itself [7, Sect. 6.2, second paragraph]. We also published some details
of the reconstruction method and the rules [25] before adapting veriT to ease
reconstruction. Here, we focus on the new features.
We optimize the performance further by tuning the search performed by veriT.
Multiple options inﬂuence the execution time of an SMT solver. To ﬁne-tune
veriT’s search procedure, we select four diﬀerent combinations of options, or
strategies, by generating typical problems and selecting options with complemen-
tary performance on these problems. We extend Sledgehammer to compare these
four selected strategies and suggest the fastest to the user. We then evaluate the
reconstruction with Sledgehammer on a large benchmark set. Our new tactic
halves the failure rate. We also study the time required to reconstruct each rule.
Many simple rules occur often, showing the importance of step skipping (Sect. 5).
Finally, we discuss related work (Sect. 6). Compared to the prototype [25],
the smt tactic is now thoroughly tested. We ﬁxed all issues revealed during
development and improved the performance of the reconstruction method. The
work presented here is integrated into Isabelle version 2021; i.e., since this version
Sledgehammer can also suggest veriT, without user interaction. To simplify future
reconstruction eﬀorts, we document the proof format and all rules used by veriT.
The resulting reference manual is part of the veriT documentation [40].
2
veriT and Proofs
The SMT solver veriT is an open source solver based on the CDCL(T ) calculus.
In proof-production mode, it supports the theories of uninterpreted functions
with equality, linear real and integer arithmetic, and quantiﬁers. To support
quantiﬁers veriT uses quantiﬁer instantiation and extensive preprocessing.
Reliable Reconstruction of Fine-grained Proofs in a Proof Assistant
451

452
Schurr, Fleury, and Desharnais
veriT’s proof syntax is an extension of SMT-LIB [11] which uses S-expressions
and preﬁx notation. The proofs are refutation proofs, i.e., proofs of K. A proof
is an indexed list of steps. Each step has a conclusion clause (cl ..) and is
annotated with a rule, a list of premises, and some rule-dependent arguments.
veriT distinguishes 90 rules [40]. Subproofs are the key feature of the proof format.
They introduce an additional context. Contexts are used to reason about binders,
e.g., preprocessing steps like transformation under quantiﬁers.
The conclusions of rules with contexts are always equalities. The context
models a substitution into the free variables of the term on the left-hand side
of the equality. Consider the following proof fragment that renames the variable
name x to vr, as done during preprocessing:
(assume a0 (exists (x A) (f x))
(anchor :step t3 :args (:= x vr))
(step t1 (cl (= x vr)) :rule refl)
(step t2 (cl (= (f x) (f vr))) :rule cong :premises (t1))
(step t3 (cl (= (exists (x A) (f x))
(exists (vr A) (f vr))) :rule bind)
The assume command repeats input assertions or states local assumptions. In
this fragment the assumption a0 is not used. Subproofs start with the anchor
command that introduces a context. Semantically, the context is a shorthand for
a lambda abstraction of the free variable and an application of the substituted
term. Here the context is x ÞÑ vr and the step t1 means pλx. xq vr “ vr. The
step is proven by congruence (rule cong). Then congruence is applied again (step
t2) to prove that pλx. f xq vr “ f vr and step t3 concludes the renaming.
During proof search each module of veriT appends steps onto a list. Once
the proof is completed, veriT performs some cleanup before printing the proof.
First, a pruning phase removes branches of the proof not connected to the root K.
Second, a merge phase removes duplicated steps. The ﬁnal pass prepares the
data structures for the optional term sharing via name annotations.
3
Overview of the veriT-Powered smt Tactic
Isabelle is a generic proof assistant based on an intuitionistic logic framework,
Pure, and is almost always only used parameterized with a logic. In this work we
use only Isabelle/HOL, the parameterization of Isabelle with higher-order logic
with rank-1 (top level) polymorphism. Isabelle adheres to the LCF [26] tradition.
Its kernel supports only a small number of inferences. Tactics are programs that
prove a goal by using only the kernel for inferences. The LCF tradition also
means that external tools, like SMT solvers, are not trusted.
Nevertheless, external tools are successfully used. They provide relevant facts
or a detailed proof. The Sledgehammer tool implements the former and passes
the ﬁltered facts to trusted tactics during preplay. The smt tactic implements
the latter approach. The provided proof is checked by Isabelle. We focus on the
smt tactic, but we also extended Sledgehammer to also suggest our new tactic.

The smt tactic translates the current goal to the SMT-LIB format [11], runs
an SMT solver, parses the proof, and replays it through Isabelle’s kernel. To
choose the smt tactic the user applies (smt (z3)) to use Z3 and (smt (verit))
to use veriT. We will refer to them as z-smt and v-smt. The proof formats of Z3
and veriT are so diﬀerent that separate reconstruction modules are needed. The
v-smt tactic performs four steps:
1. It negates the proof goal to have a refutation proof and also encodes the goal
into ﬁrst-order logic. The encoding eliminates lambda functions. To do so, it
replaces each lambda function with a new function and creates app operators
corresponding to function application. Then veriT is called to ﬁnd a proof.
2. It parses the proof found by veriT (if one is found) and encodes it as a
directed acyclic graph with K as the only conclusion.
3. It converts the SMT-LIB terms to typed Isabelle terms and also reverses the
encoding used to convert higher-order into ﬁrst-order terms.
4. It traverses the proof graph, checks that all input assertions match their
Isabelle counterpart and then reconstructs the proof step by step using the
kernel’s primitives.
4
Tuning the Reconstruction
To improve the speed of the reconstruction method, we create small and well-
deﬁned rules for preprocessing simpliﬁcations (Sect. 4.1). Previously, veriT implic-
itly normalized every step; e.g., repeated literals were immediately deleted. It now
produces proofs for this transformation (Sect. 4.2). Finally, the linear-arithmetic
steps contain coeﬃcients which allow Isabelle to reconstruct the step without
relying on its limited arithmetic automation (Sect. 4.3). On the Isabelle side, the
reconstruction module selectively decodes the ﬁrst-order encoding (Sect. 4.4). To
improve the performance of the reconstruction, it skips some steps (Sect. 4.5).
4.1
Preprocessing Rules
During preprocessing SMT solvers perform simpliﬁcations on the operator level
which are often akin to simple calculations; e.g., a ˆ 0 ˆ fpxq is replaced by 0.
To capture such simpliﬁcations, we create a list of 17 new rules: one rule per
arithmetic operator, one to replace boolean operators such as XOR with their
deﬁnition, and one to replace n-ary operator applications with binary applica-
tions. This is a compromise: having one rule for every possible simpliﬁcation
would create a longer proof. Since preprocessing uses structural recursion, the
implementation simply picks the right rule in each leaf case. The example above
now produces a prod simplify step with the conclusion a ˆ 0 ˆ fpxq “ 0. Previ-
ously, a single step of the connect equiv rule collected all those simpliﬁcations
and no list of simpliﬁcations performed by this rule existed. The reconstruction
relied an experimentally created list of tactics to be fast enough.
On the Isabelle side, the reconstruction is fast, because we can direct the
search instead of trying automated tactics that can also work on other parts of
453
Reliable Reconstruction of Fine-grained Proofs in a Proof Assistant

454
Schurr, Fleury, and Desharnais
the formula. For example, the simpliﬁer handles the numeral manipulations of
the prod simplify rule and we restrict it to only use arithmetic lemmas.
Moreover, since we know the performed transformations, we can ignore some
parts of the terms by generalizing, i.e., replacing them by constants [18]. Because
generalized terms are smaller, the search is more directed and we are less likely
to hit the search-depth limitation of Isabelle’s auto tactic as before. Overall, the
reconstruction is more robust and easier to debug.
4.2
Implicit Steps
To simplify reconstruction, we avoid any implicit normal form of conclusions. For
example, a rule concluding t_P for any formula t can be used to prove P _P. In
such cases veriT automatically normalizes the conclusion P _ P to P. Without
a proof of the normalization, the reconstruction has to handle such cases.
We add new proof rules for the normalization and extend veriT to use them.
Instead of keeping only the normalized step, both the original and the normalized
step appear in the proof. For the example above, we have the step P _ P and
the normalized P. To remove a double negation ␣␣t we introduce the tautology
␣␣␣t _ t and resolve it with the original clause. Our changes do not aﬀect any
other part of veriT. The solver now also prunes steps concluding J.
On the Isabelle side, the reconstruction becomes more regular with fewer
special cases and is more reliable. The reconstruction method can directly re-
construct rules. To deal with the normalization, the reconstruction used to ﬁrst
generate the conclusion of the theorem and then ran the simpliﬁer to match the
normalized conclusion. This could not deal with tautologies.
We also improve the proof reconstruction of quantiﬁer instantiation steps. One
of the instantiation schemes, conﬂicting instances [8,36], only works on clausiﬁed
terms. We introduce an explicit quantiﬁed-clausiﬁcation rule qnt cnf issued
before instantiating. While this rule is not detailed, knowing when clausiﬁcation
is needed improves reconstruction, because it avoids clausifying unconditionally.
The clausiﬁcation is also shared between instantiations of the same term.
4.3
Arithmetic Reasoning
We use a proof witness to handle linear arithmetic. When the propositional
model is unsatisﬁable in the theory of linear real arithmetic, the solver creates
la generic steps. The conclusion is a tautological clause of linear inequalities
and equations and the justiﬁcation of the step is a list of coeﬃcients so that
the linear combination is a trivially contradictory inequality after simpliﬁcation
(e.g., 0 ě 1). Farkas’ lemma guarantees the existence of such coeﬃcients for reals.
Most SMT solvers, including veriT, use the simplex method [21] to handle linear
arithmetic. It calculates the coeﬃcients during normal operation.
The real arithmetic solver also strengthens inequalities on integer variables
before adding them to the simplex method. For example, if x is an integer the
inequality 2x ă 3 becomes x ď 1. The corresponding justiﬁcation is the rational
coeﬃcient 1{2. The reconstruction must replay this strengthening.

The complete linear arithmetic proof step 1 ă x _ 2x ă 3 looks like
(step t11 (cl (< 1 x) (< (* 2 x) 3))
:rule la_generic :args (1 (div 1 2)))
The reconstruction of an la generic step in Isabelle starts with the goal
Ž
i ␣ci where each ci is either an equality or an inequality. The reconstruction
method ﬁrst generalizes over the non-arithmetic parts. Then it transforms the
lemma into the equivalent formulation c1 ñ ¨ ¨ ¨ ñ cn ñ K and removes all
negations (e.g., by replacing ␣a ď b with b ą a).
Next, the reconstruction method multiplies the equation by the corresponding
coeﬃcient. For example, for integers, the equation A ă B, and the coeﬃcient p{q
(with p ą 0 and q ą 0), it strengthens the equation and multiplies by p to get
p ˆ pA div qq ` p ˆ pif B mod q “ 0 then 1 else 0q ď p ˆ pB div qq.
The if-then-else term pif B mod q “ 0 then 1 else 0q corresponds to the strength-
ening. If B mod q “ 0, the result is an equation of the form A1 ` 1 ď B1, i.e.,
A1 ă B1. No strengthening is required for the corresponding theorem over reals.
Finally, we can combine all the equations by summing them while being
careful with the equalities that can appear. We simplify the resulting (in)equality
using Isabelle’s simpliﬁer to derive K.
To replay linear arithmetic steps, Isabelle can also use the tactic linarith as
used for Z3 proofs. It searches the coeﬃcients necessary to verify the lemma.
The reconstruction used it previously [25], but the tactic can only ﬁnd integer
coeﬃcients and fails if strengthening is required. Now the rule is a mechanically
checkable certiﬁcate.
4.4
Selective Decoding of the First-order Encoding
Next, we consider an example of a rule that shows the interplay of the higher-order
encoding and the reconstruction. To express function application, the encoding
introduces the ﬁrst-order function app and constants for encoded functions. The
proof rule eq congruent expresses congruence on a ﬁrst-order function: pt1 ‰
u1q _ . . . _ ptn ‰ unq _ fpt1, . . . , tnq “ fpu1, . . . , unq. With the encoding it can
conclude f ‰ f 1 _ x ‰ x1 _ apppf, xq “ apppf 1, x1q. If the reconstruction unfolds
the entire encoding, it builds the term f ‰f 1 _x‰x1 _fx“f 1x1. It then identiﬁes
the functions and the function arguments and uses rewriting to prove that if
f “ f 1 and x “ x1, then fx “ f 1x1.
However, Isabelle β-reduces all terms implicitly, changing the term structure.
Assume f :“ λx. x “ a and f 1 :“ λx. a “ x. After unfolding all constructs that
encode higher-order terms and after β-reduction, we get pλx. x “ aq ‰ pλx. a “
x1q _ px ‰ x1q _ px “ aq “ pa “ y1q. The reconstruction method cannot identify
the functions and function arguments anymore.
Instead, the reconstruction method does not unfold the encoding including
app. This eliminates the need for a special case to detect lambda functions. Such
a case was used in the previous prototype, but the code was very involved and
hard to test (such steps are rarely used).
455
Reliable Reconstruction of Fine-grained Proofs in a Proof Assistant

456
Schurr, Fleury, and Desharnais
4.5
Skipping Steps
The increased number of steps in the ﬁne-grained proof format slows down recon-
struction. For example, consider skolemization from Dx. P x. The proof from Z3
uses one step. veriT uses eight steps—ﬁrst renaming it to pDx. P xq “ pDv. P vq
(with a subproof of at least 2 steps), then concluding the renaming to get pDv. P vq
(two steps), then pDv. P vq “ P pϵv. P vq (with a subproof of at least 2 steps),
and ﬁnally P pϵv. P vq (two steps).
To reduce the number of steps, our reconstruction skips two kinds of steps.
First, it replaces every usage of the or rule by its only premise. Second, it skips
the renaming of bound variables. The proof format treats @x. P x and @y. P y
as two diﬀerent terms and requires a detailed proof of the conversion. Isabelle,
however, uses De Bruijn indices and variable names are irrelevant. Hence, we
replace steps of the form p@x. P xq ô p@y. P yq by a single application of
reﬂexivity. Since veriT canonizes all variable names, this eliminates many steps.
We can also simplify the idiom “equiv pos2; th resolution”. veriT gener-
ates it for each skolemization and variable renaming. Step skipping replaces it
by a single step which we replay using a specialized theorem.
On proof with quantiﬁers, step skipping can remove more than half of the
steps—only four steps remain in the skolemization example above (where two
are simply reﬂexivity). However, with step skipping the smt method is not an
independent checker that conﬁrms the validity of every single step in a proof.
5
Evaluation
During development we routinely tested our proof reconstruction to ﬁnd bugs. As
a side eﬀect, we produced SMT-LIB ﬁles corresponding to the calls. We measure
the performance of veriT with various options on them and select ﬁve diﬀerent
strategies (Sect. 5.1). We also evaluate the repartition of the tactics used by
Sledgehammer for preplay (Sect. 5.2), and the impact of the rules (Sect. 5.3).
We performed the strategy selection on a computer with two Intel Xeon
Gold 6130 CPUs (32 cores, 64 threads) and 192 GiB of RAM. We performed
Isabelle experiments with Isabelle version 2021 on a computer with two AMD
EPYC 7702 CPUs (128 cores, 256 threads) and 2 TiB of RAM.
5.1
Strategies
veriT exposes a wide range of options to ﬁne-tune the proof search. In order
to ﬁnd good combinations of options (strategies), we generate problems with
Sledgehammer and use them to ﬁne-tune veriT’s search behavior. Generating
problems also makes it possible to test and debug our reconstruction.
We test the reconstruction by using Isabelle’s Mirabelle tool. It reads theories
and automatically runs Sledgehammer [14] on all proof steps. Sledgehammer
calls various automatic provers (here the SMT solvers CVC4, veriT, and Z3 and
the superposition prover E [38]) to ﬁlter facts and chooses the fastest tactic that
can prove the goal. The tactic smt is used as a last resort.

Table 1. Options corresponding to the diﬀerent veriT strategies
Name
Options
default
(no option)
del insts
--index-sorts --index-fresh-sorts --ccfv-breadth --inst-deletion
--index-SAT-triggers --inst-deletion-loops --inst-deletion-track-var
ccfv SIG --triggers-new --index-SIG --triggers-sel-rm-speciﬁc
ccfv insts --triggers-new --index-sorts --index-fresh-sorts --triggers-sel-rm-speciﬁc
--triggers-restrict-combine --inst-deletion-loops --index-SAT-triggers
--inst-deletion-track-vars --ccfv-index=100000 --ccfv-index-full=1000
--inst-sorts-threshold=100000 --ematch-exp=10000000 --inst-deletion
best
--triggers-new --index-sorts --index-fresh-sorts --triggers-sel-rm-speciﬁc
To generate problems for tuning veriT, we use the theories from HOL-Library
(an extended standard library containing various developments) and from the
formalizations of Green’s theorem [2,3], the Prime Number Theorem [23], and
the KBO ordering [13]. We call Mirabelle with only veriT as a fact ﬁlter. This
produces SMT ﬁles for representative problems Isabelle users want to solve and
a series of calls to v-smt. For failing v-smt calls three cases are possible: veriT
does not ﬁnd a proof, reconstruction times out, or reconstruction fails with an
error. We solved all reconstruction failures in the test theories.
To ﬁnd good strategies, we determine which problems are solved by several
combination of options within a two second timeout. We then choose the strategy
which solves the most benchmarks and three strategies which together solve the
most benchmarks. For comparison, we also keep the default strategy.
The strategies are shown in Table 1 and mostly diﬀer in the instantiation
schemes. The strategy del insts uses instance deletion [6] and uses a breadth-
ﬁrst algorithm to ﬁnd conﬂicting instances. All other strategies rely on extended
trigger inference [29]. The strategy ccfv SIG uses a diﬀerent indexing method for
instantiation. It also restricts enumerative instantiation [35], because the options
--index-sorts and --index-fresh-sorts are not used. The strategy ccfv insts increases
some thresholds. Finally, the strategy best uses a subset of the options used by
the other strategies. Sledgehammer uses best for fact ﬁltering.
We have also considered using a scheduler in Isabelle as used in the SMT
competition. The advantage is that we do not need to select the strategy on
the Isabelle side. However, it would make v-smt unreliable. A problem solved by
only one strategy just before the end of its time slice can become unprovable on
slower hardware. Issues with z-smt timeouts have been reported on the Isabelle
mailing list, e.g., due to an antivirus delaying the startup [27].
5.2
Improvements of Sledgehammer Results
To measure the performance of the v-smt tactic, we ran Mirabelle on the full HOL-
Library, the theory Prime Distribution Elementary (PDE) [22], an executable
resolution prover (RP) [37], and the Simplex algorithm [30]. We extended Sledge-
hammer’s proof preplay to try all veriT strategies and added instrumentation for
457
Reliable Reconstruction of Fine-grained Proofs in a Proof Assistant

458
Schurr, Fleury, and Desharnais
Table 2. Outcome of Sledgehammer calls showing the total success rate (SR, higher is
better) of one-liner proof preplay, the number of suggested v-smt (OLv) and z-smt (OLz)
one-liners, and the number of preplay failures (PF, lower is better), in percentages of
the unique goals.
HOL-Library
PNT
RP
Simplex
(13 562 goals)
(1 715 goals)
(1 658 goals)
(1 982 goals)
SR OLv OLz PF SR OLv OLz PF SR OLv OLz PF SR OLv OLz PF
Fact-ﬁlter prover: CVC4
z-smt 54.5
2.7 1.5 33.1
3.7 0.8 64.8
1.3 0.8 51.6
1.6 0.9
both
55.5 2.5
1.1 0.5 33.6 3.6
0.6 0.3 65.3 1.4
0.4 0.3 52.1 1.1
1.0 0.4
Fact-ﬁlter prover: E
z-smt 55.5
1.1 1.7 36.0
0.3 1.7 61.7
0.7 1.2 49.8
1.4 0.7
both
56.0 0.8
0.7 1.3 36.4 0.6
0.1 1.3 62.1 0.9
0.2 0.8 49.9 0.3
1.3 0.5
Fact-ﬁlter prover: veriT
z-smt 48.5
1.7 1.2 26.1
1.5 0.5 58.2
0.9 0.7 46.7
0.9 1.0
both
49.4 1.6
0.9 0.4 26.5 1.4
0.4 0.2 58.6 1.1
0.3 0.2 47.4 1.0
0.6 0.3
Fact-ﬁlter prover: Z3
z-smt 50.8
2.5 0.8 27.9
2.7 0.4 60.4
0.8 0.7 48.3
0.9 0.3
both
51.3 1.9
1.1 0.3 28.2 2.5
0.5 0.1 60.9 1.1
0.1 0.2 48.4 0.4
0.6 0.2
the time of all tried tactics. Sledgehammer and automatic provers are mostly non-
deterministic programs. To reduce the variance between the diﬀerent Mirabelle
runs, we use the deterministic MePo fact ﬁlter [33] instead of the better perform-
ing MaSh [28] that uses machine learning (and depends on previous runs) and
underuse the hardware to minimize contention. We use the default timeouts of
30 seconds for the fact ﬁltering and one second for the proof preplay. This is
similar to the Judgment Day experiments [17]. The raw results are available [1].
Success Rate. Users are not interested in which tactics are used to prove a goal,
but in how often Sledgehammer succeeds. There are three possible outcomes:
(i) a successfully preplayed proof, (ii) a proof hint that failed to be preplayed
(usually because of a timeout), or (iii) no proof. We deﬁne the success rate as
the proportion of outcome (i) over the total number of Sledgehammer calls.
Table 2 gathers the results of running Sledgehammer on all unique goals and
analyzing its outcome using diﬀerent preplay conﬁgurations where only z-smt
(the baseline) or both v-smt and z-smt are enabled. Any useful preplay tactic
should increase the success rate (SR) by preplaying new proof hints provided by
the fact-ﬁlter prover, reducing the preplay failure rate (PF).
Let us consider, e.g., the results when using CVC4 as fact-ﬁlter prover. The
success rate of the baseline on the HOL-Library is 54.5% and its preplay failure
rate is 1.5%. This means that CVC4 found a proof for 54.5%`1.5% “ 56% of the
goals, but that Isabelle’s proof methods failed to preplay many of them. In such

cases, Sledgehammer gives a proof hint to the user, which has to manually ﬁnd a
functioning proof. By enabling v-smt, the failure rate decreases by two thirds, from
1.5% to 0.5%, which directly increases the success rate by 1 percentage point: new
cases where the burden of the proof is moved from the user to the proof assistant.
The failure rate is reduced in similar proportions for PNT (63%), RP (63%), and
Simplex (56%). For these formalizations, this improvement translates to a smaller
increase of the success rate, because the baseline failure rate was smaller to begin
with. This conﬁrms that the instantiation technique conﬂicting instances [8,36]
is important for CVC4.
When using veriT or Z3 as fact-ﬁlter prover, a failure rate of zero could
be expected, since the same SMT solvers are used for both fact ﬁltering and
preplaying. The observed failure rate can partly be explained by the much smaller
timeout for preplay (1 second) than for fact ﬁltering (30 seconds).
Overall, these results show that our proof reconstruction enables Sledgeham-
mer to successfully preplay more proofs. With v-smt enabled, the weighted average
failure rate decreases as follows: for CVC4, from 1.3% to 0.4%; for E, from 1.5%
to 1.2%; for veriT, from 1.0% to 0.3%; and for Z3, from 0.7% to 0.3%. For the
user, this means that the availability of v-smt as a proof preplay tactic increases
the number of goals that can be fully automatically proved.
Saved time. Table 3 shows a diﬀerent view on the same results. Instead of the
raw success rate, it shows the time that is spent reconstructing proofs. Using
the baseline conﬁguration, preplaying all formalizations takes a total of 250.1 `
33.4 ` 37.2 ` 42.8 “ 363.5 seconds. When enabling v-smt, some calls to z-smt
are replaced by faster v-smt calls and the reconstruction time decreases by 13%
to 212.6 ` 28.4 ` 34.4 ` 41.6 “ 317 seconds. Note that the per-formalization
improvement varies considerably: 15% for HOL-Library, 15% for PNT, 7.5% for
RP, and 4.0% for Simplex.
For the user, this means that enabling v-smt as a proof preplay tactic may
signiﬁcantly reduce the veriﬁcation time of their formalizations.
Impact of the Strategies. We have also studied what happens if we remove a
single veriT strategy from Sledgehammer (Table 4). The most important one
is best, as it solves the highest number of problems. On the contrary, default is
nearly entirely covered by the other strategies. ccfv SIG and del insts have a
similar number where they are faster than Z3, but the latter has more unique
goals and therefore, saves more time. Each strategy has some uniquely solved
problems that cannot be reconstructed using any other. The results are similar
for the other theories used in Table 3.
5.3
Speed of Reconstruction
To better understand what the key rules of our reconstruction are, we recorded the
time used to reconstruct each rule and the time required by the solver over all calls
attempted by Sledgehammer including the ones not selected. The reconstruction
ratio (reconstruction over search time) shows how much slower reconstructing
459
Reliable Reconstruction of Fine-grained Proofs in a Proof Assistant

460
Schurr, Fleury, and Desharnais
Table 3. Preplayed proofs (Pr.) and their execution time (s) when using CVC4 as
fact-ﬁlter prover. Shared proofs are found with and without v-smt and new proofs
are found only with v-smt. The proofs and their associated timings are categorized in
one-liners using v-smt (OLv), z-smt (OLz), or any other Isabelle proof methods (OLo).
Total
Shared proofs
New proofs
Total
=
OLv
+
OLz
+
OLo
OLv
Pr.
Time “ Time (Pr.) ` Time (Pr.) ` Time ( Pr. ) Time ( Pr. )
HOL-
Library
z-smt 7 409
250.1 “
85.0 (362) ` 165.1 (7 047)
both
7 545
212.6 “
27.9 (211) `
19.6 (152) ` 165.1 (7 047)
34.7 ( 135)
PNT
z-smt
569
33.4 “
14.8 ( 64) `
18.5 ( 505)
both
577
28.4 “
7.7 ( 54) `
2.1 ( 10) `
18.5 ( 505)
3.4 (
8)
RP
z-smt 1 077
37.2 “
8.7 ( 22) `
28.5 (1 055)
both
1 085
34.4 “
4.5 ( 16) `
1.4 (
6) `
28.5 (1 055)
2.2 (
8)
Simplex z-smt 1 024
42.8 “
6.7 ( 32) `
36.0 ( 992)
both
1 033
41.6 “
2.4 ( 13) `
3.2 ( 19) `
36.0 ( 992)
3.0 (
9)
Table 4. Reconstruction time and number of solved goals when removing a single
strategy (HOL-Library results only), using CVC4 as fact ﬁlter.
Shared proofs
New proofs
OLv
OLz
OLv
Time
Proofs
Time
Proofs
Time
Proofs
No best
16.5
119
50.6
244
25.9
94
No ccfv SIG
27.0
198
22.6
164
33.5
123
No ccfv threshold
28.3
211
19.6
152
33.9
130
No del insts
27.4
201
21.8
162
32.9
124
No default
27.9
207
20.1
156
33.8
134
Baseline
27.9
211
19.6
152
34.7
135
compared to ﬁnding a proof is. For the 25% of the proofs, Z3’s concise format
is better and the reconstruction is faster than proof ﬁnding (ﬁrst quartile: 0.9
for v-smt vs. 0.1 for z-smt). The 99th percentile of the proofs (18.6 vs. 27.2)
shows that veriT’s detailed proof format reduces the number of slow proofs. The
reconstruction is slower than ﬁnding proofs on average for both solvers.
Fig. 1 shows the distribution of the time spent on some rules. We remove the
slowest and fastest 5% of the applications, because garbage collection can trigger
at any moment and even trivial rules can be slow. Fig. 2 gives the sum of all
reconstruction times over all proofs. We call parsing the time required to parse
and convert the veriT proof into Isabelle terms.
Overall, there are two kinds of rules: (1) direct application of a sequence of
theorems—e.g., equiv pos2 corresponds to the theorem ␣pa ô bq _ ␣a _ b—
and (2) calls to full-blown tactics—like qnt cnf (Sect. 4.2).
First, direct application of theorems are usually fast, but they occur so often
that the cumulative time is substantial. For example, cong only needs to unfold

assumptions and apply reﬂexivity and symmetry of equality. However, it appears
so often and sometimes on large terms, that it is an important rule.
Second, rules which require full-blown tactics are the slowest rules. For qnt
cnf (CNF under quantiﬁers, see Sect. 4.2), we have not written a specialized
tactic, but rely on Isabelle’s tableau-based blast tactic. This rule is rather slow,
but is rarely used. It is similar to the rule la generic: it is slow on average, but
searching the coeﬃcients takes even more time.
We can also see that the time required to check the simpliﬁcation steps that
were formerly combined into the connect equiv rule is not signiﬁcant anymore.
We have performed the same experiments with the reconstruction of the SMT
solver Z3. In contrast to veriT, we do not have the amount of time required for
parsing. The results are shown in Figs. 3 and 4. The rule distribution is very
diﬀerent. The nnf-neg and nnf-pos rules are the slowest rules and take a huge
amount of time in the worst case. However, the coarser quantiﬁer instantiation
step is on average faster than the one produced by veriT. We suspect that
reconstruction is faster because the rule, which is only an implication without
choice terms, is easier to check (no equality reordering).
6
Related Work
The SMT solvers CVC4 [10], Z3 [34], and veriT [19] produce proofs. CVC4
does not record quantiﬁer reasoning in the proof, and Z3 uses some macro rules.
Proofs from SMT solvers have also been used to ﬁnd unsatisﬁability cores [20],
and interpolants [32]. They are also useful to debug the solver itself, since unsound
steps often point to the origin of bugs. Our work also relates to systems like
Dedukti [5] that focuses on translating proof steps, not on replaying them.
Proof reconstruction has been implemented in various systems, including
CVC4 proofs in HOL Light [31], Z3 in HOL4 and Isabelle/HOL [18], and veriT [4]
and CVC4 [24] in Coq. Only veriT produces detailed proofs for preprocessing and
skolemization. SMTCoq [4,24] currently supports veriT’s version 1 of the proof
output which has diﬀerent rules, does not support detailed skolemization rules,
and is implemented in the 2016 version of veriT, which has worse performance.
SMTCoq also supports bit vectors and arrays.
The reconstruction of Z3 proofs in HOL4 and Isabelle/HOL is one of the
most advanced and well tested. It is regularly used by Isabelle users. The Z3
proof reconstruction succeeds in more than 90% of Sledgehammer benchmarks [14,
Section 9] and is eﬃcient (an older version of Z3 was used). Performance numbers
are reported [16,18] not only for problems generated by proof assistants (including
Isabelle), but also for preexisting SMT-LIB ﬁles from the SMT-LIB library.
The performance study by B¨ohme [16, Sect. 3.4] uses version 2.15 of Z3,
whereas we use version 4.4.0 which currently ships with Isabelle. Since version
2.15, the proof format changed slightly (e.g., th-lemma-arith was introduced),
fulﬁlling some of the wishes expressed by B¨ohme and Weber [18] to simplify
reconstruction. Surprisingly, the nnf rules do not appear among the ﬁve rules
that used the most runtime. Instead, the th-lemma and rewrite rules were the
461
Reliable Reconstruction of Fine-grained Proofs in a Proof Assistant

462
Schurr, Fleury, and Desharnais
0
5
10
15
20
25
30
35
cong
resolution
th-resolution
forall-inst
contraction
bool-simplify
comp-simplify
sko-ex
eq-simplify
sko-forall
connective-def
qnt-cnf
ite-intro
prod-simplify
onepoint
ac-simp
sum-simplify
minus-simplify
bfun-elim
la-generic
parsing
time (ms) (lower is better)
Fig. 1. Timing, sorted by the median, of a subset of veriT’s rules. From left to right,
the lower whisker marks the 5th percentile, the lower box line the ﬁrst quartile, the
middle of the box the median, the upper box line the third quartile, and the upper
whisker the 95th percentile.
0
2
4
6
8
10
12
14
16
cong
resolution
th-resolution
forall-inst
contraction
bool-simplify
comp-simplify
sko-ex
eq-simplify
sko-forall
connective-def
qnt-cnf
ite-intro
prod-simplify
onepoint
ac-simp
sum-simplify
minus-simplify
bfun-elim
la-generic
parsing
Percentage of time
Fig. 2. Total percentage spent on each rule for the SMT solver veriT in the same order
as Fig. 1. This graph maps the rules already shown in Fig. 1 to the total amount of
time. The slowest rules are th resolution (14.7%), parsing (10.3%), and cong (9.77%).

0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
sk
intro-def
asserted
apply-def
iﬀ-true
iﬀ-false
symm
mp„
hypothesis
mp
commutativity
trans
reﬂ
rewrite
elim-unused
lemma
and-elim
monotonicity
def-axiom
nnf-pos
unit-resolution
quant-inst
not-or-elim
quant-intro
pull-quant
nnf-neg
th-lemma-arith
parsing
time (ms) (lower is better)
Fig. 3. Timing of some of Z3’s rules sorted by median. From left to right, the lower
whisker marks the 5th percentile, the lower box line the ﬁrst quartile, the middle of the
box the median, the upper box line the third quartile, and the upper whisker the 95th
percentile. nnf-neg’s 95th percentile is 87 ms, nnf-pos’s is 33 ms, and parsing’s is 25 ms.
0
5
10
15
20
25
30
sk
asserted
intro-def
apply-def
iﬀ-true
iﬀ-false
mp„
symm
hypothesis
mp
commutativity
trans
reﬂ
rewrite
elim-unused
lemma
and-elim
monotonicity
def-axiom
nnf-pos
unit-resolution
quant-inst
not-or-elim
quant-intro
pull-quant
nnf-neg
th-lemma-arith
parsing
Percentage of time
Fig. 4. Total amount of time per rule for the SMT solver Z3. nnf-neg takes 39% of the
reconstruction time.
463
Reliable Reconstruction of Fine-grained Proofs in a Proof Assistant

464
Schurr, Fleury, and Desharnais
slowest. Similarly to veriT, the cong rule was among the most used (without
accounting for the most time), but it does not appear in our Z3 tests.
CVC4 follows a diﬀerent philosophy compared to veriT and Z3: it produces
proofs in a logical framework with side conditions [39]. The output can contain
programs to check certain rules. The proof format is ﬂexible in some aspects and
restrictive in others. Currently CVC4 does not generate proofs for quantiﬁers.
7
Conclusion
We presented an eﬃcient reconstruction of proofs generated by a modern SMT
solver in an interactive theorem prover. Our improvements address reconstruction
challenges for proof steps of typical inferences performed by SMT solvers.
By studying the time required to replay each rule, we were able to compare the
reconstruction for two diﬀerent proof formats with diﬀerent design directions. The
very detailed proof format of veriT makes the reconstruction easier to implement
and allows for more specialization of the tactics. On slow proofs, the ratio of time
to reconstruct and time to ﬁnd a proof is better for our more detailed format.
Integrating our reconstruction in Isabelle halves the number of failures from
Sledgehammer and nicely completes the existing reconstruction method with Z3.
Our work is integrated into Isabelle version 2021. Sledgehammer suggests the
veriT-based reconstruction if it is the fastest tactic that ﬁnds the proof; so users
proﬁt without action required on their side. We plan to improve the reconstruction
of the slowest rules and remove inconsistencies in the proof format. The developers
of the SMT solver CVC4 are currently rewriting the proof generation and plan
to support a similar proof format. We hope to be able to reuse the current
reconstruction code by only adding support for CVC4-speciﬁc rules. Generating
and reconstructing proofs from the veriT version with higher-order logic [9]
could also improve the usefulness of veriT on Isabelle problems. The current
proof rules [40] should accommodate the more expressive logic.
Acknowledgment We would like to thank Haniel Barbosa for his support with
the implementation in veriT. We also thank Haniel Barbosa, Jasmin Blanchette,
Pascal Fontaine, Daniela Kaufmann, Petar Vukmirovi´c, and the anonymous re-
viewers for many fruitful discussions and suggesting many textual improvements.
The ﬁrst and third authors have received funding from the European Research
Council (ERC) under the European Union’s Horizon 2020 research and inno-
vation program (grant agreements No. 713999, Matryoshka, and No. 830927,
Concordia). The second author is supported by the LIT AI Lab funded by the
State of Upper Austria. The training presented in this paper was carried out
using the Grid’5000 testbed, supported by a scientiﬁc interest group hosted by
Inria and including CNRS, RENATER and several Universities as well as other
organizations (see https://www.grid5000.fr).

References
1. Reliable Reconstruction of Fine-Grained Proofs in a Proof Assistant. Zenodo (Apr
2021). https://doi.org/10.5281/zenodo.4727349
2. Abdulaziz, M., Paulson, L.C.: An Isabelle/HOL formalisation of Green’s theorem.
Archive of Formal Proofs (Jan 2018), https://isa-afp.org/entries/Green.html,
formal proof development
3. Abdulaziz, M., Paulson, L.C.: An Isabelle/HOL formalisation of Green’s theorem.
Journal of Automated Reasoning 63(3), 763–786 (Nov 2019).
https://doi.org/10.1007/s10817-018-9495-z
4. Armand, M., Faure, G., Gr´egoire, B., Keller, C., Th´ery, L., Werner, B.: A modular
integration of SAT/SMT solvers to Coq through proof witnesses. In: Jouannaud,
J.P., Shao, Z. (eds.) CPP 2011. LNCS, vol. 7086, pp. 135–150. Springer Berlin
Heidelberg (2011). https://doi.org/10.1007/978-3-642-25379-9 12
5. Assaf, A., Burel, G., Cauderlier, R., Delahaye, D., Dowek, G., Dubois, C., Gilbert,
F., Halmagrand, P., Hermant, O., Saillard, R.: Expressing theories in the
λπ-calculus modulo theory and in the Dedukti system. In: TYPES: Types for
Proofs and Programs. Novi SAd, Serbia (May 2016)
6. Barbosa, H.: Eﬃcient instantiation techniques in SMT (work in progress).
vol. 1635, pp. 1–10. CEUR-WS.org (Jul 2016),
http://ceur-ws.org/Vol-1635/#paper-01
7. Barbosa, H., Blanchette, J.C., Fleury, M., Fontaine, P.: Scalable ﬁne-grained
proofs for formula processing. Journal of Automated Reasoning (Jan 2019).
https://doi.org/10.1007/s10817-018-09502-y
8. Barbosa, H., Fontaine, P., Reynolds, A.: Congruence closure with free variables.
In: Legay, A., Margaria, T. (eds.) TACAS 2017. LNCS, vol. 10206, pp. 214–230.
Springer Berlin Heidelberg (2017). https://doi.org/10.1007/978-3-662-54580-5 13
9. Barbosa, H., Reynolds, A., Ouraoui, D.E., Tinelli, C., Barrett, C.W.: Extending
SMT solvers to higher-order logic. In: Fontaine, P. (ed.) CADE 27. LNCS, vol.
11716, pp. 35–54. Springer International Publishing (2019).
https://doi.org/10.1007/978-3-030-29436-6 3
10. Barrett, C., Conway, C.L., Deters, M., Hadarean, L., Jovanovi´c, D., King, T.,
Reynolds, A., Tinelli, C.: CVC4. In: Gopalakrishnan, G., Qadeer, S. (eds.) CAV
2011. LNCS, vol. 6806, pp. 171–177. Springer Berlin Heidelberg (2011).
https://doi.org/10.1007/978-3-642-22110-1 14
11. Barrett, C., Fontaine, P., Tinelli, C.: The SMT-LIB Standard: Version 2.6. Tech.
rep., Department of Computer Science, The University of Iowa (2017), available at
12. Barrett, C.W., Tinelli, C.: Satisﬁability modulo theories. In: Clarke, E.M.,
Henzinger, T.A., Veith, H., Bloem, R. (eds.) Handbook of Model Checking, pp.
305–343. Springer International Publishing, Cham (2018).
https://doi.org/10.1007/978-3-319-10575-8 11
13. Becker, H., Blanchette, J.C., Waldmann, U., Wand, D.: Formalization of
Knuth–Bendix orders for lambda-free higher-order terms. Archive of Formal
Proofs (Nov 2016), https://isa-afp.org/entries/Lambda Free KBOs.html, formal
proof development
14. Blanchette, J.C., B¨ohme, S., Fleury, M., Smolka, S.J., Steckermeier, A.:
Semi-intelligible Isar proofs from machine-generated proofs. Journal of Automated
Reasoning 56(2), 155–200 (2016). https://doi.org/10.1007/s10817-015-9335-3
www.SMT-LIB.org
465
Reliable Reconstruction of Fine-grained Proofs in a Proof Assistant

466
Schurr, Fleury, and Desharnais
15. Blanchette, J.C., B¨ohme, S., Paulson, L.C.: Extending Sledgehammer with smt
solvers. In: Bjørner, N., Sofronie-Stokkermans, V. (eds.) CADE 23. LNCS,
vol. 6803, pp. 116–130. Springer Berlin Heidelberg (2011).
https://doi.org/10.1007/978-3-642-22438-6 11
16. B¨ohme, S.: Proving Theorems of Higher-Order Logic with SMT Solvers. Ph.D.
thesis, Technische Universit¨at M¨unchen (2012),
http://mediatum.ub.tum.de/node?id=1084525
17. B¨ohme, S., Nipkow, T.: Sledgehammer: Judgement day. In: Giesl, J., H¨ahnle, R.
(eds.) IJCAR 2010. pp. 107–121. Springer Berlin Heidelberg (2010).
https://doi.org/10.1007/978-3-642-14203-1 9
18. B¨ohme, S., Weber, T.: Fast LCF-style proof reconstruction for Z3. In: Kaufmann,
M., Paulson, L.C. (eds.) ITP 2010. LNCS, vol. 6172, pp. 179–194. Springer Berlin
Heidelberg (2010). https://doi.org/10.1007/978-3-642-14052-5 14
19. Bouton, T., de Oliveira, D.C.B., D´eharbe, D., Fontaine, P.: veriT: An open,
trustable and eﬃcient SMT-solver. In: Schmidt, R.A. (ed.) CADE 22. LNCS,
vol. 5663, pp. 151–156. Springer Berlin Heidelberg (2009).
https://doi.org/10.1007/978-3-642-02959-2 12
20. D´eharbe, D., Fontaine, P., Guyot, Y., Voisin, L.: SMT solvers for Rodin. In:
Derrick, J., Fitzgerald, J.A., Gnesi, S., Khurshid, S., Leuschel, M., Reeves, S.,
Riccobene, E. (eds.) ABZ 2012. LNCS, vol. 7316, pp. 194–207. Springer Berlin
Heidelberg (Jun 2012). https://doi.org/10.1007/978-3-642-30885-7 14
21. Dutertre, B., de Moura, L.: Integrating simplex with DPLL(T). Tech. rep., SRI
International (May 2006),
http://www.csl.sri.com/users/bruno/publis/sri-csl-06-01.pdf
22. Eberl, M.: Elementary facts about the distribution of primes. Archive of Formal
Proofs (Feb 2019), https://isa-afp.org/entries/Prime Distribution
Elementary.html, formal proof development
23. Eberl, M., Paulson, L.C.: The prime number theorem. Archive of Formal Proofs
(Sep 2018), https://isa-afp.org/entries/Prime Number Theorem.html, formal
proof development
24. Ekici, B., Mebsout, A., Tinelli, C., Keller, C., Katz, G., Reynolds, A., Barrett,
C.W.: SMTCoq: A plug-in for integrating SMT solvers into Coq. In: Majumdar,
R., Kuncak, V. (eds.) CAV 2017. LNCS, vol. 10427, pp. 126–133. Springer
International Publishing (2017). https://doi.org/10.1007/978-3-319-63390-9 7
25. Fleury, M., Schurr, H.: Reconstructing veriT proofs in Isabelle/HOL. In: Reis, G.,
Barbosa, H. (eds.) PxTP 2019. EPTCS, vol. 301, pp. 36–50 (2019).
https://doi.org/10.4204/EPTCS.301.6
26. Gordon, M.J.C., Milner, R., Wadsworth, C.P.: Edinburgh LCF: A Mechanised
Logic of Computation, LNCS, vol. 78. Springer Berlin Heidelberg (1979).
https://doi.org/10.1007/3-540-09724-4
27. Immler, F.: Re: [isabelle] Isabelle2019-RC2 sporadic smt failures. Email (May
2019),
https://lists.cam.ac.uk/pipermail/cl-isabelle-users/2019-May/msg00130.html
28. K¨uhlwein, D., Blanchette, J.C., Kaliszyk, C., Urban, J.: Mash: Machine learning
for Sledgehammer. In: ITP. LNCS, vol. 7998, pp. 35–50. Springer (2013)
29. Leino, K.R.M., Pit-Claudel, C.: Trigger selection strategies to stabilize program
veriﬁers. In: Chaudhuri, S., Farzan, A. (eds.) CAV 2016. LNCS, vol. 9779, pp.
361–381. Springer International Publishing (2016).
https://doi.org/10.1007/978-3-319-41528-4 20

30. Mari´c, F., Spasi´c, M., Thiemann, R.: An incremental simplex algorithm with
unsatisﬁable core generation. Archive of Formal Proofs (Aug 2018),
https://isa-afp.org/entries/Simplex.html, formal proof development
31. McLaughlin, S., Barrett, C., Ge, Y.: Cooperating theorem provers: A case study
combining HOL-Light and CVC Lite. Electronic Notes in Theoretical Computer
Science 144(2), 43–51 (2006). https://doi.org/10.1016/j.entcs.2005.12.005
32. McMillan, K.L.: Interpolants from Z3 proofs. In: FMCAD 2011. pp. 19–27.
FMCAD Inc, Austin, Texas (2011)
33. Meng, J., Paulson, L.C.: Lightweight relevance ﬁltering for machine-generated
resolution problems. J. Appl. Log. 7(1), 41–57 (2009)
34. de Moura, L., Bjørner, N.: Z3: An eﬃcient SMT solver. In: Ramakrishnan, C.R.,
Rehof, J. (eds.) TACAS 2008. LNCS, vol. 4963, pp. 337–340. Springer Berlin
Heidelberg (2008). https://doi.org/10.1007/978-3-540-78800-3 24
35. Reynolds, A., Barbosa, H., Fontaine, P.: Revisiting enumerative instantiation. In:
Beyer, D., Huisman, M. (eds.) TACAS 2018. LNCS, vol. 10806, pp. 112–131.
Springer International Publishing (2018).
https://doi.org/10.1007/978-3-319-89963-3 7
36. Reynolds, A., Tinelli, C., de Moura, L.: Finding conﬂicting instances of quantiﬁed
formulas in SMT. In: FMCAD 2014. pp. 195–202. IEEE (2014).
https://doi.org/10.1109/FMCAD.2014.6987613
37. Schlichtkrull, A., Blanchette, J.C., Traytel, D., Waldmann, U.: Formalization of
Bachmair and Ganzinger’s ordered resolution prover. Archive of Formal Proofs
(Jan 2018), https://isa-afp.org/entries/Ordered Resolution Prover.html, formal
proof development
38. Schulz, S.: E - a brainiac theorem prover. AI Communications 15(2-3), 111–126
(2002), http://content.iospress.com/articles/ai-communications/aic260
39. Stump, A., Oe, D., Reynolds, A., Hadarean, L., Tinelli, C.: SMT proof checking
using a logical framework. Formal Methods in System Design 42(1), 91–118 (Feb
2013). https://doi.org/10.1007/s10703-012-0163-3
40. The veriT Team and Contributors: Proofonomicon: A reference of the veriT proof
format. Software Documentation (2021),
https://www.verit-solver.org/documentation/proofonomicon.pdf, last Accessed:
April 2021
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.
467
Reliable Reconstruction of Fine-grained Proofs in a Proof Assistant

An Automated Approach to the Collatz Conjecture⋆
Emre Yolcu1
, Scott Aaronson2, and Marijn J. H. Heule1,3
1 Carnegie Mellon University, Pittsburgh, PA 15213, USA
{emreyolcu,marijn}@cmu.edu
2 University of Texas at Austin, Austin, TX 78712, USA
scott@scottaaronson.com
3 Amazon Scholar
Abstract. We explore the Collatz conjecture and its variants through the lens of
termination of string rewriting. We construct a rewriting system that simulates
the iterated application of the Collatz function on strings corresponding to mixed
binary–ternary representations of positive integers. Termination of this rewriting
system is equivalent to the Collatz conjecture. To show the feasibility of our ap-
proach in proving mathematically interesting statements, we implement a minimal
termination prover that uses the automated method of matrix/arctic interpretations
and we perform experiments where we obtain proofs of nontrivial weakenings of
the Collatz conjecture. Finally, we adapt our rewriting system to show that other
open problems in mathematics can also be approached as termination problems
for relatively small rewriting systems. Although we do not succeed in proving
the Collatz conjecture, we believe that the ideas here represent an interesting new
approach.
1
Introduction
Let N = {0, 1, 2, . . .} denote the natural numbers and N+ = {1, 2, 3, . . .} denote the
positive integers. We deﬁne the Collatz function C : N+ →N+ as
C(n) =

n/2
if n ≡0
(mod 2)
3n + 1
if n ≡1
(mod 2).
Given a function f and a number k ∈N, the function f k denotes the kth iterate of f.
The well-known Collatz conjecture is the following:
Conjecture 1. For all n ∈N+, there exists some k ∈N such that Ck(n) = 1.
This is a longstanding open problem and there is a vast literature dedicated to its study.
For its history, we refer the reader to the comprehensive surveys by Lagarias [17–19].
Deﬁnition 1 (Convergent function). Consider a function f : X →X. Given x ∈X,
the sequence of iterates fτ(x) := (x, f(x), f 2(x), . . .) is called the f-trajectory of x.
For some designated element z ∈X, if for all x ∈X the trajectory fτ(x) contains z,
the function f is called convergent.
⋆The full version is available at https://www.cs.cmu.edu/~eyolcu/research/rewriting-collatz.pdf.
© The Author(s) 2021
A. Platzer and G. Sutcliffe (Eds.): CADE 2021, LNAI 12699, pp. 468-484, 2021.
https://doi.org/10.1007/978-3-030-79876-5_27

An Automated Approach to the Collatz Conjecture
469
In this paper, we describe an approach based on termination of string rewriting to
automatically search for a proof of the Collatz conjecture. Although trying to prove
the Collatz conjecture via automated deduction is clearly a moonshot goal, there are
two recent technological advances that provide reasons for optimism that at least some
interesting variants of the problem might be solvable. First, the invention of the method
of matrix interpretations and its variants such as arctic interpretations turns the quest
of ﬁnding a ranking function to witness termination into a problem that is suitable for
systematic search. Second, the progress in satisﬁability (SAT) solving makes it possible
to solve many seemingly difﬁcult combinatorial problems efﬁciently in practice. Their
combination, i.e., using SAT solvers to ﬁnd interpretations, has so far been effective in
solving challenging termination problems. We make the following contributions:
– We show how a generalized Collatz function can be expressed as a rewriting system
that is terminating if and only if the function is convergent.
– We show that translations into rewriting systems that use non-unary representations
of numbers are empirically more amenable to automation compared with their
previously and more commonly studied counterparts that use unary representations.
– We automatically prove various weakenings of the Collatz conjecture and observe
that only relatively large matrix/arctic interpretations exist for some generalized
Collatz functions. Existing termination tools often limit their default strategies to
search for small interpretations as they are tailored for the setting where the task is
to quickly solve a large quantity of relatively easy problems. We make the point that,
given more resources, the interpretation method has the potential to scale.
– We observe that the phase-saving heuristic used in modern SAT solvers degrades the
performance of CDCL solvers on formulas encoding the existence of matrix/arctic
interpretations, whereas using negative branching improves solver performance.
– We present adaptations of our rewriting system that allow reformulating several
more open problems in mathematics as termination problems of small size.
2
Preliminaries
2.1
String Rewriting Systems
Deﬁnition 2 (String rewriting system). Let Σ be an alphabet, i.e., a set of symbols. A
string rewriting system (SRS) over Σ is a relation R ⊆Σ∗× Σ∗. Elements (ℓ, r) ∈R
are called rewrite rules and are usually written as ℓ→r. The system R induces a rewrite
relation →R := {(sℓt, srt) | s, t ∈Σ∗, ℓ→r ∈R} on the set Σ∗of strings.
Deﬁnition 3 (Termination). A relation →on A is terminating (denoted SN(→)) if
there is no inﬁnite sequence s0, s1, . . . ∈A such that si →si+1 for all i ≥0.
We conﬂate an SRS R with the rewrite relation it induces, writing “R is terminating”
instead of “→R is terminating”. The following is a useful generalization of termination:
Deﬁnition 4 (Relative termination). For SRSs R and S, the system R is said to be
terminating relative to S (denoted SN(R/S)) if every sequence of rewrites for the system
R ∪S applies the rules from R at most ﬁnitely many times.

470
Emre Yolcu, Scott Aaronson, and Marijn J. H. Heule
Relative termination allows proofs to be broken into steps as codiﬁed by the following.
Lemma 1 (Rule removal [29, Theorem 1]). Let R be an SRS. If there exists a subset
T ⊆R such that SN(T/R) and SN(R \ T), then SN(R).
This lemma allows us to “remove rules” in the following way. When proving SN(R),
if we succeed at ﬁnding a subset T satisfying SN(T/R), the proof obligation becomes
weakened to SN(R\T), where the rules of T are no longer present. This removal of rules
can be repeated until no rules remain, thus producing a stepwise proof of termination.
Another useful technique is reversal:
Lemma 2 (Rule reversal [29, Lemma 2]). For a string s = s1 . . . sn ∈Σ∗, denote
srev := sn . . . s1 and deﬁne the reversal of an SRS R as Rrev := {ℓrev →rrev | ℓ→
r ∈R}. For SRSs R and S, we have SN(R/S) if and only if SN(Rrev/Srev).
Reversal is of interest because methods for proving termination are not necessarily
invariant under reversal, that is, a given technique may fail to show termination of a
system R while succeeding for its reversal Rrev.
Yet another important notion is top termination:
Deﬁnition 5 (Top termination). Let R be an SRS over Σ. The top rewrite relation
induced by R is deﬁned as →Rtop := {(ℓs, rs) | s ∈Σ∗, ℓ→r ∈R}. If →Rtop is
terminating, R is said to be top terminating.
In plain language, top termination allows rewrites to be performed only at the leftmost end
of a string. As we will see in the next section (Theorem 1), top termination problems can
admit proofs of a more relaxed form compared to termination. Relative top termination,
i.e., proving SN(Rtop/S) for SRSs R and S, is a crucial component in the dependency
pair approach [1] which reduces a termination problem to a relative top termination
problem that is often easier to solve. In order to avoid requiring familiarity with the
dependency pair approach, we omit its discussion, and instead prove a self-contained
result (Lemma 4) that encapsulates dependency pairs in a more elementary manner for
the speciﬁc rewriting systems that we consider in this paper.
2.2
Interpretation Method
We state (at a high level) the key results on matrix/arctic interpretations that we use in
our implementation. For more details we refer the reader to existing work [2,6,10,15,26].
With the interpretation method, the main idea is to ﬁnd a ranking function that assigns
a value to each string such that it decreases strictly when the string is modiﬁed by an
application of a rewrite rule. If for all strings the value is bounded from below, then it
cannot decrease indeﬁnitely, ruling out the existence of an inﬁnite sequence of rewrites.
Formally, we search for an instance of the following:
Deﬁnition 6 (Extended/weakly monotone algebra). Let Σ be an alphabet, A a set,
[σ]: A →A an interpretation for every σ ∈Σ, > and ≳order relations over A such
that > is well-founded and ≳satisﬁes > · ≳⊆>. Letting [·]Σ := {[σ] | σ ∈Σ},
the structure (A, [·]Σ, >, ≳) is a weakly monotone Σ-algebra if for every σ ∈Σ the
interpretation [σ] is monotone with respect to ≳. It is an extended monotone Σ-algebra
if, additionally, for every σ ∈Σ the interpretation [σ] is monotone with respect to >.

An Automated Approach to the Collatz Conjecture
471
We extend the interpretation from symbols to strings s = s1 . . . sn ∈Σ∗as [s] :=
[s1] ◦· · · ◦[sn]. The following general theorem characterizes relative termination (resp.
top termination) as the existence of extended (resp. weakly) monotone algebras.
Theorem 1 ([6, Theorem 2]). Let R and S be SRSs over the alphabet Σ. We have
SN(R/S) (resp. SN(Rtop/S)) if and only if there exists an extended (resp. weakly)
monotone Σ-algebra (A, [·]Σ, >, ≳) such that
– for each rule ℓ→r ∈R we have [ℓ](x) > [r](x) for all x ∈A,
– for each rule ℓ→r ∈S we have [ℓ](x) ≳[r](x) for all x ∈A.
An effective way to prove relative (top) termination is to try to satisfy the conditions
of the above theorem by ﬁxing (A, >, ≳) and algorithmically searching for appropriate
interpretations of symbols. Matrix interpretations is an instance of this method. We ﬁx
a dimension d, set A = Nd, deﬁne ⃗x ≳⃗y ⇐⇒xi ≥yi for all i ∈{1, . . . , d}, and
deﬁne ⃗x > ⃗y
⇐⇒
⃗x ≳⃗y ∧x1 > y1. For interpreting each symbol σ ∈Σ, we
consider an afﬁne function [σ](⃗x) = Mσ⃗x+vσ. In this way, the structure (Nd, [·]Σ, >, ≳)
satisﬁes the requirements of Deﬁnition 6 for a weakly monotone algebra. Additionally
setting (Mσ)1,1 = 1 satisﬁes the requirements for an extended monotone algebra. Matrix
interpretations can also be adapted to the max–plus algebra of arctic numbers A :=
N∪{−∞} as coefﬁcients with different arithmetic operations and order relations [15,26].
Example 1. Let R = {aa →aba} and S = {b →bb}. The following functions
constitute a matrix interpretations proof that shows SN(R/S).
[a](⃗x) =

1 1
0 0

⃗x +

0
1

[b](⃗x) =

1 0
0 0

⃗x +

0
0

It can be checked that the above interpretations give an extended monotone algebra and
that they satisfy the following for all ⃗x ∈N2, which implies SN(R/S) via Theorem 1.
[aa](⃗x) =

1 1
0 0

⃗x +

1
1

>

1 1
0 0

⃗x +

0
1

= [aba](⃗x)
[b](⃗x) =
1 0
0 0

⃗x +
0
0

≳
1 0
0 0

⃗x +
0
0

= [bb](⃗x)
In order to automate the search for the interpretations given a rewriting system R, an
effective approach is to encode all of the aforementioned constraints as a propositional
formula in CNF and use a SAT solver to look for a satisfying assignment. This addition-
ally involves ﬁxing a ﬁnite domain for the coefﬁcients that can occur in the interpretations
and encoding arithmetic over the chosen ﬁnite domain using propositional variables.
2.3
Generalized Collatz Functions
We consider instances of the following generalization of the Collatz function. Its variants
have commonly appeared in the literature [3,12,14,16,21,24,27].
Deﬁnition 7 (Generalized Collatz function). Let X be one of N, N+, or Z and deﬁne
X⊥:= X ∪{⊥}. A function f : X⊥→X⊥is a generalized Collatz function if f(⊥) =

472
Emre Yolcu, Scott Aaronson, and Marijn J. H. Heule
⊥and there exist an integer d ≥2 and rational numbers q0, . . . , qd−1, r0, . . . , rd−1
such that for all 0 ≤i ≤d −1 and all n ∈X, we have
f(n) = qin + ri
if n ≡i
(mod d)
or
f(n) = ⊥
if n ≡i
(mod d).
In the above, we allow the representation of a partially deﬁned function by mapping to
⊥in the undeﬁned cases. We call a partial f convergent if all f-trajectories contain ⊥.
Note that the Collatz function corresponds to a generalized one with d = 2, q0 = 1/2,
r0 = 0, q1 = 3, r1 = 1. Although the Collatz function is by far the most widely studied
case, there are several other concrete examples of generalized Collatz functions the
convergence of which is worth studying due to their connections to open problems in
number theory and computability theory. We discuss these cases in Section 5.
3
Rewriting the Collatz Function
We start with systems that use unary representations and then demonstrate via examples
that mixed base representations can be more suitable for use with automated methods.
3.1
Rewriting in Unary
The following system of Zantema [29] simulates iterated application of the Collatz
function to a number represented in unary, and terminates upon reaching 1.
Example 2. Z denotes the following SRS, consisting of 5 symbols and 7 rules.
h11 →1h
11h⋄→11s⋄
1s →s1
⋄s →⋄h
h1⋄→t11⋄
1t →t111
⋄t →⋄h
This system can be seen as encoding the execution of a Turing machine with cells that
can be contracted/expanded. The symbols 1 and ⋄(blank) form the tape alphabet, while
the symbols h (half), s (shift), t (triple) indicate the head along with the state of the
machine. Through the following result, the Collatz conjecture can be reformulated as
termination of string rewriting.
Theorem 2 ([29]). Z is terminating if and only if the Collatz conjecture holds.
While the forward direction of the above theorem is easy to see (since ⋄h12n⋄→∗
Z
⋄h1n⋄for n > 1 and ⋄h12n+1⋄→∗
Z ⋄h13n+2⋄for n ≥0), the backward direction is
far from obvious because not every string corresponds to a valid conﬁguration of the
underlying machine.
As another example, consider the system W = {h11 →1h, 1h⋄→1t⋄, 1t →
t111, ⋄t →⋄h} (originally due to Zantema4). Termination of this system has yet to be
proved via automated methods. Nevertheless, there is a simple reason for its termination:
4 https://www.lri.fr/~marche/tpdb/tpdb-2.0/SRS/Zantema/z079.srs

An Automated Approach to the Collatz Conjecture
473
It simulates iterated application of a partial generalized Collatz function W : N+
⊥→N+
⊥
deﬁned as follows, which is easily seen to be convergent.
W(n) =

3n/2
if n ≡0
(mod 2)
⊥
if n ≡1
(mod 2)
If a proof of the Collatz conjecture is to be produced by some automated method
that relies on rewriting, then that method better be able to prove a statement as simple as
the convergence of W. With this in mind, we describe an alternative rewriting system
that simulates the Collatz function and terminates upon reaching 1. We then provide
examples where the alternative system is more suitable for use with termination tools
(for instance allowing an automated proof of the convergence of W).
3.2
Rewriting in Mixed Base
In the mixed base scheme, the overall idea is as follows. Given a number n ∈N+, we
write a mixed binary–ternary representation for it (noting that this representation is not
unique). With this representation, as long as the least signiﬁcant digit is binary, the parity
of the number can be recognized by checking only this digit, as opposed to scanning
the entire string when working in unary. This allows us to easily determine the correct
case when applying the Collatz function. If the least signiﬁcant digit is ternary, then
the representation is rewritten (while preserving its decimal value) to make this digit
binary. Afterwards, since computing n/2 corresponds to erasing a trailing binary 0 and
computing 3n + 1 corresponds to inserting a trailing ternary 1, applying the Collatz
function takes a single rewrite step. We explain this scheme more formally below.
A mixed base numeral system is a numeral system where the base changes across
positions, which we deﬁne as follows. Note that unary is not a positional numeral system,
so we require the bases to be greater than 1.
Deﬁnition 8 (Mixed base representation). Let B ⊆N>1 be a set of bases and let
N = n1b1n2b2 . . . nkbk be a string where ni ∈N. If we have for each 1 ≤i ≤k that
bi ∈B and 0 ≤ni < bi, then N is called a mixed B-ary representation.
The string N from above represents the decimal number N10 = k
i=1 ni
k
j=i+1 bj.
Observing that the addition of leading zeros to a string does not change its decimal value,
we may assume without loss of generality that n1 > 0. Furthermore, b1 does not affect
the decimal value of the string, so we may omit it.
Now, deﬁne βn
b (x) := bx + n. After rearranging, we see that the decimal value of
the B-ary string N = n1n2b2 . . . nkbk may also be written as N10 = (βnk
bk ◦βnk−1
bk−1 ◦
· · ·◦βn2
b2 )(n1). This gives us a string and a function view of the same representation, and
we will switch between them as appropriate. In doing so, we also conﬂate the symbols
and the corresponding functions, referring to βn
b as nb.
As the last ingredient before describing the rewriting system, we observe that we can
write (βn
b ◦βm
c )(x) = bcx+bm+n equivalently as another composition (βm′
c ◦βn′
b )(x) =
cbx + cn′ + m′ for some suitable 0 ≤n′ < b and 0 ≤m′ < c. This allows us to swap
the bases of adjacent positions while preserving the decimal value of the string.

474
Emre Yolcu, Scott Aaronson, and Marijn J. H. Heule
From this point on, we constrain ourselves to the mixed {2, 3}-ary (binary–ternary)
representations as we shift our focus to simulating the Collatz function (noting that it
is possible to adapt the rewriting system that we will end up with to other instances of
the general case). More precisely, we simulate the following redeﬁnition of the Collatz
function where the odd case incorporates an additional division by 2.
T(n) =

n
2
if n ≡0
(mod 2)
3n+1
2
if n ≡1
(mod 2)
We will describe an SRS T over the symbols {f, t, 0, 1, 2, ◁, ▷} that simulates
iterated application of the Collatz function and terminates upon reaching 1. The symbols
f, t correspond to binary digits 02, 12; and 0, 1, 2 to ternary digits 03, 13, 23. The
symbol ◁marks the beginning of a string while also standing for the most signiﬁcant
digit (without loss of generality assumed to be 1) and ▷marks the end of a string.
Consider the functional view of these symbols:
f(x) = 2x
t(x) = 2x + 1
0(x) = 3x
1(x) = 3x + 1
2(x) = 3x + 2
◁(x) = 1
▷(x) = x
(1)
Each positive natural number can be expressed as some composition of these functions,
which corresponds to a string as per our previous discussion.
Example 3. Allowing the inclusion of a redundant trailing symbol ▷to mixed base
representations, we can write 19 = (◁0f1▷)10 = ▷(1(f(0(◁(x))))). The string rep-
resentation ends with a ternary symbol, so we will rewrite it. With the function view,
we have 1(f(x)) = 3(2x) + 1 = 6x + 1 = 2(3x) + 1 = t(0(x)). This shows
that we could also write 19 = (◁00t▷)10, which now ends with the binary digit 12.
This gives us the rewrite rule f1 →0t. We can now apply the Collatz function to
this representation by rewriting only the rightmost two symbols of the string since
T(▷(t(x))) = 3(2x+1)+1
2
= 6x+4
2
= 3x + 2 = (▷(2(x))). This gives us the rewrite
rule t▷→2▷. After applying this rule, we indeed obtain T(19) = 29 = (◁002▷)10.
In the manner of the above example, we compute all the necessary transformations
and obtain the following 11-rule SRS T .
DT =
 f▷→▷
t▷→2▷

A =
⎧
⎨
⎩
f0 →0f
f1 →0t
f2 →1f
t0 →1t
t1 →2f
t2 →2t
⎫
⎬
⎭
B =
⎧
⎨
⎩
◁0 →◁t
◁1 →◁ff
◁2 →◁ft
⎫
⎬
⎭
This SRS is split into subsystems DT (dynamic rules for T) and X = A ∪B (auxiliary
rules). The two rules in DT encode the application of the Collatz function T, while
the rules in X serve to push binary symbols towards the rightmost end of the string by
swapping the bases of adjacent positions without changing the represented value.
Example 4 (Rewrite sequence of T ). Consider the string s = ◁ff0▷that represents
the number 12. Below is a possible rewrite sequence of T that starts from s, with the

An Automated Approach to the Collatz Conjecture
475
corresponding decimal values (under the interpretations from (1)) displayed above the
strings. Underlines indicate the parts of the strings where the rules are applied.
12
12
6
6
3
3
5
◁ff0▷→A ◁f0f▷→DT ◁f0▷→A ◁0f▷→DT
◁0▷
→B ◁t▷→DT ◁2▷
5
8
8
8
4
2
1
→B ◁ft▷→DT
◁f2▷
→A ◁1f▷→B ◁fff▷→DT ◁ff▷→DT ◁f▷→DT
◁▷
The trajectory of T continues upon reaching 1, however, in order to be able to formulate
the Collatz conjecture as a termination problem, T is made in such a way that its rewrite
sequences stop upon reaching the string representation ◁▷of 1 since no rule is applicable.
Termination of the subsystems of T with B or DT removed is easily seen. However,
since we have matrix interpretations at our disposal, let us give a compact proof.
Lemma 3. SN(T \ B) and SN(T \ DT ).
Proof. It is easily checked that the interpretations below show SN((T \ B)rev), which
implies SN(T \ B) by Lemma 2.
[f](x) = [t](x) = 2x + 1
[▷] = x
[0](x) = [1](x) = [2](x) = 2x
Below interpretations show SN((T \ DT )rev), which implies SN(T \ DT ) by Lemma 2.
[f](x) = [t](x) = [◁](x) = x + 1
[0](x) = [1](x) = [2](x) = 4x
⊓⊔
As a whole, the system T simulates the iterated application of T (except at 1).
Theorem 3. T is terminating if and only if T is convergent.
Proof (sketch). We observe that the rules of T do not change the number of occurrences
of ◁or ▷in a string and that the rewrite sequences operate strictly on one side of these
symbols. Thus, we may view a given string as split into blocks delimited by ◁or ▷
and consider the termination of each block separately. In this way, we conclude that
there exists a nonterminating rewrite sequence for a string if and only if it contains a
block of the canonical form ◁(f|t|0|1|2)∗▷that can be rewritten indeﬁnitely, since the
rewrite sequences that start on blocks of all other forms are already seen to terminate by
Lemma 3. Furthermore, under the interpretations in (1), the sequences of values attained
by the rewrites of the blocks in canonical form correspond directly to Collatz trajectories,
since the rules in X do not change the value of the block and the rules in DT change the
value of the block in exactly the same way as the Collatz function T.
⊓⊔
When trying to remove a rule in DT or B it sufﬁces to show relative top termination,
allowing us to use weakly (instead of extended) monotone algebras when applying
Theorem 1 and take advantage of the more relaxed constraints when searching for
matrix/arctic interpretations. The lemma below encapsulates dependency pairs, and it
can in fact be automatically proved via the dependency pair framework [9].
Lemma 4. For each subset R ⊆B, if SN(Rtop/T ) then SN(R/T ). And, for each
subset R ⊆DT , if SN(Rrev
top/T rev) then SN(Rrev/T rev).

476
Emre Yolcu, Scott Aaronson, and Marijn J. H. Heule
Proof (sketch). Without loss of generality, assume we start with a string of the canonical
form ◁(f|t|0|1|2)∗▷(resp. its reversal). Then, the rules in B (resp. DT
rev) can only
be applied at the top level. As we know from Lemma 3 that T \ B (resp. T \ DT ) is
terminating, any inﬁnite sequence of rewrites in T (resp. its reversal) would require
inﬁnitely many applications of the rules from B (resp. DT
rev). As these rules can only
be applied at the top level, this would imply relative top nontermination.
⊓⊔
4
Automated Proofs
We adapt the rewriting system T to different generalized Collatz functions to explore the
effectiveness of the mixed base scheme on weakened variants of the Collatz conjecture.
The rewriting systems, scripts to reproduce the experiments, and our implementation of
a termination prover are available at https://github.com/emreyolcu/rewriting-collatz.
Most top-tier termination tools, such as AProVE, Matchbox, and TTT2, use the SAT
solver MiniSat [5] to search for matrix/arctic interpretations. This choice is somewhat
surprising as MiniSat has not been updated since 2008 and the performance of SAT
solvers has improved signiﬁcantly in the last decade. The use of MiniSat in these provers
is motivated by its observed effectiveness in ﬁnding interpretations. We investigated the
reason for this, which turned out to be a heuristic that MiniSat disables in its default
conﬁguration. MiniSat uses negative branching [5], which explores the “false” branch
ﬁrst for all decision variables. Modern SAT solvers use phase-saving [22] which ﬁrst
explores the branch corresponding to the truth value to which the variable was forced to
most recently during unit propagation. In our case, enabling negative branching improves
solver performance for formulas that encode the existence of interpretations.
4.1
Convergence of W
With the mixed binary–ternary scheme, the function W from Section 3.1 can be seen
to be simulated by the system W′ = {f▷→0▷} ∪X. A small matrix interpretations
proof is found for this system in less than a second, in contrast to its variant W that uses
unary representations for which no automated proof is known.
Theorem 4. SN(W′).
Proof. The interpretations below prove SN({▷f →▷0}/X rev):
[f](⃗x) =

1 0
0 1

⃗x +

1
1

[t](⃗x) =

1 0
0 0

⃗x +

1
0

[◁](⃗x) =

1 0
0 0

⃗x
[▷](⃗x) =

1 2
0 0

⃗x
[0](⃗x) =

1 0
0 1

⃗x +

2
0

[1](⃗x) =

1 0
1 0

⃗x +

2
2

[2](⃗x) =

1 0
1 0

⃗x +

2
2

By Lemmas 3 and 2, X rev is terminating. As a result, W′rev is terminating, which
by Lemma 2 implies that W′ is terminating.
⊓⊔

An Automated Approach to the Collatz Conjecture
477
4.2
Farkas’ Variant
Let 2N + 1 = {1, 3, 5, . . .} denote the odd natural numbers. Farkas [8] studied a slight
modiﬁcation F ′ : 2N + 1 →2N + 1 of the Collatz function which can be proved
convergent via induction. We consider automatically proving the convergence of this
function as another test case for the mixed base scheme that is easier than the Collatz
conjecture without being entirely trivial. We refer the reader to [8] for the original
deﬁnition of F ′. Below, we deﬁne another function F : N →N that resembles the
Collatz function more closely than Farkas’ F ′ (with respect to the deﬁnitions of the
cases) while being equivalent to F ′ in terms of convergence. This variant is obtained by
introducing an additional case in the Collatz function for n ≡1 (mod 3) and applying
T otherwise. Its deﬁnition and a set DF of dynamic rules are shown below.
F(n) =
⎧
⎪
⎨
⎪
⎩
n−1
3
if n ≡1
(mod 3)
n
2
if n ≡0 or n ≡2
(mod 6)
3n+1
2
if n ≡3 or n ≡5
(mod 6)
DF =
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
1▷→▷
0f▷→0▷
1f▷→1▷
1t▷→12▷
2t▷→22▷
⎫
⎪
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎪
⎭
Termination of the rewriting system F = DF ∪X is equivalent to the convergence of F.
The proof of the equivalence is essentially the same as that of Theorem 3. Farkas gave
an inductive proof of convergence for F ′ via case analysis, and we found an automated
proof that F is terminating via arctic interpretations. It is worth mentioning that the
default conﬁgurations of the existing termination tools (e.g., AProVE, Matchbox) are
too conservative to prove termination of this system, but after their authors tweaked the
strategies they were also able to ﬁnd automated proofs via arctic interpretations.
Theorem 5. For all n ∈N+, the trajectory Fτ(n) contains 1.
Proof. We will show SN(F). By Lemmas 3 and 2, we have SN(X rev). The arctic in-
terpretations below (with the empty cells standing for −∞) prove SN(DF
rev
top/X rev) by
Theorem 1, which implies SN(DF
rev/X rev) by Lemma 4. As we know X rev is termi-
nating, by Lemma 1 we conclude SN(DF
rev ∪X rev), implying SN(F) via Lemma 2.
[f](⃗x) =
⎡
⎢⎢⎢⎢⎣
2
2 0
2
⎤
⎥⎥⎥⎥⎦
⃗x +
⎡
⎢⎢⎢⎢⎣
0⎤
⎥⎥⎥⎥⎦
[t](⃗x) =
⎡
⎢⎢⎢⎢⎣
2
0 2 0
0
2
2
⎤
⎥⎥⎥⎥⎦
⃗x +
⎡
⎢⎢⎢⎢⎣
0⎤
⎥⎥⎥⎥⎦
[◁](⃗x) =
⎡
⎢⎢⎢⎢⎣
0
2
4
⎤
⎥⎥⎥⎥⎦
[▷](⃗x) =
⎡
⎢⎢⎢⎢⎣
0
⎤
⎥⎥⎥⎥⎦
⃗x
[0](⃗x) =
⎡
⎢⎢⎢⎢⎣
0 4 0
4
4 0
0 3 0
⎤
⎥⎥⎥⎥⎦
⃗x
[1](⃗x) =
⎡
⎢⎢⎢⎢⎣
1
4 0
4 0
0
0 3 0
⎤
⎥⎥⎥⎥⎦
⃗x
[2](⃗x) =
⎡
⎢⎢⎢⎢⎣
0
0
4
0
1
0
0
0
0
⎤
⎥⎥⎥⎥⎦
⃗x

478
Emre Yolcu, Scott Aaronson, and Marijn J. H. Heule
4.3
Subsets of T
It is also interesting to consider whether we can automatically prove terminations of
proper subsets of T . Speciﬁcally, we considered the 11 subsystems obtained by leaving
out a single rewriting rule from T , and we found proofs via matrix/arctic interpretations
for all of the 11 subproblems. The reason for our interest in these problems is threefold:
1. Termination of T implies the terminations of all of its subsystems, so proving its
termination is at least as difﬁcult a task as proving terminations of the 11 subsystems.
Therefore, the subproblems serve as additional sanity checks that an automated
approach aspiring to succeed for the Collatz conjecture ought to be able to pass.
2. When proving termination in a stepwise manner, we solve a sequence of relative
termination problems. Having proved the terminations of all 11 subsystems is a
partial solution to the full problem, since it implies that for any single rule ℓ→r ∈
T , proving SN({ℓ→r}/T ) settles the Collatz conjecture.
3. After the removal of a rule, the termination of the remaining system still encodes
a valid mathematical question about the Collatz trajectories. The question of ter-
mination of a proper subset is equivalent to asking if every corresponding Collatz
trajectory that does not require the use of the left-out rule is convergent.
Example 5. As an instance of leaving out a rule, consider the subsystem T \{f1 →0t}.
There is a single-step matrix interpretations proof that this system is terminating:
[f](⃗x) =

1 1
1 0

⃗x
[t](⃗x) =

1 3
3 4

⃗x +

1
1

[◁](⃗x) =

1 5
0 0

⃗x
[▷](⃗x) =

1 0
1 0

⃗x +

1
1

[0](⃗x) =

7 2
2 5

⃗x +

2
1

[1](⃗x) =

2 1
1 1

⃗x +

1
0

[2](⃗x) =

2 2
2 4

⃗x +

0
2

With the above interpretations, we can show for instance that the Collatz trajectory
starting at 3 (represented as ◁t▷) is convergent, because the missing rule is not used in
any derivation of 1 (◁▷) from 3. Below is an example derivation along with the decimal
values each string represents and a vector value of each string under the interpretations
above (setting ⃗x = (0, 0) for the purpose of demonstration). We omit the subscripts from
the rewrite relations and simply write →.
3
5
5
8
8
8
4
2
1
◁t▷→◁2▷→◁ft▷→◁f2▷→◁1f▷→◁fff▷→◁ff▷→◁f▷→
◁▷

79
0

>

78
0

>

68
0

>

62
0

>

41
0

>

40
0

>

26
0

>

14
0

>

12
0

Table 1 shows the parameters for the proofs that we found for the termination of each
subsystem. For each rule ℓ→r that is left out, we searched for a stepwise proof to show
that B\{ℓ→r} is terminating relative to T \{ℓ→r} (freely utilizing weakly monotone

An Automated Approach to the Collatz Conjecture
479
Table 1. Smallest proofs found for terminations of subsystems of T in under 120 seconds. The
columns show the matrix dimension d and the maximum number v of distinct coefﬁcients that
appear in the matrices, along with the median time to ﬁnd an entire termination proof across 10
repetitions for the ﬁxed d and v.
Matrix
Arctic
Rule removed
d v Time
d v Time
f▷→▷
3 4
4s
3 5
19s
t▷→2▷
1 2
<1s
1 3
<1s
◁0 →◁t
2 2
<1s
2 3
<1s
◁1 →◁ff
3 3
1s
3 4
1s
◁2 →◁ft
4 4
8s
4 3
4s
Matrix
Arctic
Rule removed
d v Time
d v Time
f0 →0f
4 2
1s
3 4
3s
f1 →0t
1 3
1s
1 4
1s
f2 →1f
1 2
<1s
1 3
<1s
t0 →1t
4 3
2s
3 4
1s
t1 →2f
5 2
1s
4 3
1s
t2 →2t
4 4
28s
2 5
1s
algebras due to Lemma 4). Such a proof requires at most three steps since there are at
most three rules in B \ {ℓ→r}. On the table, we report the smallest parameters (in
terms of matrix dimension) that work for all of these steps. As we already know that
SN(T \ B) holds (by Lemma 3), the interpretations found allow us to conclude the
termination of each subsystem. This is not the only way to prove the terminations of the
subsystems, however, we chose this uniform strategy for the sake of comparison.
4.4
Odd Trajectories
In the originally deﬁned Collatz function C, applying 2n + 1 →6n + 4 produces
an even number, so we incorporate a single division by 2 into the deﬁnition of the
odd case and obtain the function T with the same overall dynamics as C. Taking
this idea further by performing as many divisions by 2 as possible leads to the so-
called Syracuse function Syr: 2N + 1 →2N + 1, deﬁned as Syr(n) = 3n+1
2k
where
k = max{k ∈N+ | 2k divides 3n + 1}.
Expressing the Syracuse function as a generalized Collatz function would require
inﬁnitely many cases to account for all of the possible appearances of 2k as the denomi-
nator with different values of k. As a result, we are unable to simulate it with a ﬁnite
rewriting system. Nevertheless, we may compromise and accelerate the Collatz function
by a constant amount. We ﬁrst observe that if n ≡1 (mod 8) then Syr(n) = 3n+1
4
and if n ≡3 (mod 4) then Syr(n) = 3n+1
2
. Furthermore, for any n ∈N we have
Syr(8n + 5) = Syr(2n + 1) since 3(8n + 5) + 1 = 24n + 16 = 4(6n + 4) =
4(3(2n + 1) + 1). Putting these observations together, we can deﬁne a generalized
Collatz function S : 2N + 1 →2N + 1 as follows.
S(n) =
⎧
⎪
⎨
⎪
⎩
3n+1
4
if n ≡1
(mod 8)
n−1
4
if n ≡5
(mod 8)
3n+1
2
if n ≡3
(mod 4)
S is convergent if and only if C (or T) is convergent, and the number of steps that
S takes to converge is between that of T and Syr. In a manner similar to before, we

480
Emre Yolcu, Scott Aaronson, and Marijn J. H. Heule
4
2
6
3
0
5
1
7
4
3
6
7
0
5
1
2
1
3
5
7
Fig. 1. Transition graphs of the iterates in the Collatz trajectories across residue classes modulo 8
for the functions C (left), T (middle), S (right). For each function f, the edge u →v is part of its
transition graph if and only if there exists some n ≡u (mod 8) such that f(n) ≡v (mod 8).
Bold edges indicate transitions where f(n) > n.
can translate S into a rewriting system S = {ff• →0•, tf• →•, t• →2•} ∪X.
Since we are working with odd numbers we used a new symbol • to mark the end of
a string, viewed functionally as •(x) = 2x + 1. Termination of the rewriting system
S is equivalent to the convergence of S. Similar to T , proving the termination of S is
currently beyond our reach, although it may potentially be an easier path to the Collatz
conjecture (compared to proving SN(T )). Failing to prove the termination of S itself,
we considered the subsystems of S as we did for T in Section 4.3. With matrix/arctic
interpretations, the terminations of all but two of the 11-rule subsystems of S were
automatically proved. Despite devoting thousands of CPU hours, we were not able to
ﬁnd interpretations to prove that S1 = S \ {ff• →0•} or S2 = S \ {tf• →•} is
terminating, so we leave them as challenges for automated termination proving.
4.5
Collatz Trajectories Modulo 8
Let m be a power of 2. Given k ∈{0, 1, . . . , m−1}, is it the case that all nonconvergent
Collatz trajectories contain some n ≡k (mod m)? For several values of k this can be
proved to hold by inspecting the transitions of the iterates in the Collatz trajectories
across residue classes modulo m (shown on Figure 1 for m = 8). These questions can
also be formulated as the terminations of some rewriting systems. With this approach we
found automated proofs for several cases:
Theorem 6. If there exists a nonconvergent Collatz trajectory, it cannot avoid the
residue classes of 2, 3, 4, 6 modulo 8.
It remains open whether the above holds for the residue classes of 0, 1, 5, 7 modulo 8.
5
More Problems to Approach via Rewriting
Mahler’s 3/2 Problem. Let ξ ∈R>0 be a real number. It is called a Z-number if for
all k ∈N we have frac

ξ
 3
2
k
< 1
2, where frac(·) denotes the fractional part of the

An Automated Approach to the Collatz Conjecture
481
number. Mahler [20] conjectured that there are no Z-numbers. Moreover, he considered
a generalized Collatz function M : N+ →N+, deﬁned as follows.
M(n) =
⎧
⎪
⎨
⎪
⎩
3n
2
if n ≡0
(mod 2)
3n+1
2
if n ≡1
(mod 4)
⊥
if n ≡3
(mod 4)
He related the behaviors of M-trajectories to the existence of Z-numbers:
Theorem 7. For n ∈N+, if a Z-number exists in the interval [n, n + 1), then there is
no k ∈N for which M k(n) ≡3 (mod 4).
Thus, the nonexistence of Z-numbers can be established by proving that M is convergent,
which is equivalent to the termination of M = {f▷→0▷,ft▷→10▷} ∪X. In order
to ensure termination at the case n ≡3 (mod 4), there is no rule with the LHS tt▷.
Halting Problem for Busy Beaver-5. The busy beaver problem concerns ﬁnding binary-
alphabet Turing machines with n states that, when given an input tape of all 0s, write
the largest number of 1s on the tape upon halting. For each n, the machine that achieves
this is called the “Busy Beaver-n”. Note that this deﬁnition only requires the machines
to halt on all-0 inputs, leaving the behavior on other inputs unspeciﬁed and allowing
them not to halt in general. Michel [21] observed that for n ∈{2, 3, 4}, the busy beaver
machines are all total Turing machines, i.e., they halt on all inputs, and moreover proved
that they all simulate some generalized Collatz function. It is an open problem whether
all busy beavers are total. In particular, it is unknown whether the current Busy Beaver-
5 candidate is total. Michel showed that the Busy Beaver-5 candidate simulates the
following generalized Collatz function.
B(n) =
⎧
⎪
⎨
⎪
⎩
5n+18
3
if n ≡0
(mod 3)
5n+22
3
if n ≡1
(mod 3)
⊥
if n ≡2
(mod 3)
Convergence of the above function can be studied via the termination of a rewriting
system obtained by a mixed {3, 5}-ary (ternary–quinary) translation scheme. We were
unable to prove the termination of the resulting system.
Ternary Expansions of 2n. Erd˝os [7] asked: When does the ternary expansion of 2n
omit the digit 2? This is the case for 20 = (1)3, 22 = (11)3, and 28 = (100111)3. He
conjectured that it does not happen for n > 8. This conjecture can be proved by showing
that the rewriting system E = {0▷→▷, 1▷→▷, ◁▷→◁▷}∪{r →ℓ| ℓ→r ∈X} is
terminating on all initial strings of the form ◁f8f+▷. Given a string that corresponds to
the binary representation of a power of 2, this system essentially rewrites the string into
ternary by pushing ternary symbols to the right without altering the value that the string
represents, and removes the occurrences of the ternary digits 0 and 1 (but not 2). If the
ternary expansion does not contain the digit 2 then all digits will be removed, resulting in
the string ◁▷that can then be rewritten to itself indeﬁnitely. This problem, as described,
is an instance of “local termination” [28] since it is concerned with termination on not
all possible strings but a subset of them. We have not performed experiments with this
system or local termination yet and we leave this for future work.

482
Emre Yolcu, Scott Aaronson, and Marijn J. H. Heule
6
Related Work
To our knowledge, Zantema [29], with his system Z that we saw in Section 3.1, was the
ﬁrst to attempt using an automated method and string rewriting to search for a proof of
the Collatz conjecture. In addition, although we independently discovered the mixed
binary–ternary system described in Section 3.2, Scollo [25] had essentially the same
idea, the difference being that he adopted a functional view of the digits that is slightly
different than in (1). Scollo was not concerned with proving termination, though, and
proposed rewriting primarily as a formalism that forgoes the arithmetic interpretation of
the iterates and instead emphasizes its dynamic/computational behavior.
De Mol [4] showed the existence of a small 2-tag system [23] with the following rules
that simulates the iterated application of the Collatz function given a unary representation:
{1 ⇀◁▷, ◁⇀1, ▷⇀111}. This tag system halts if and only if the Collatz conjecture
holds, giving yet another formulation of the problem.
Kari [11] designed 1D cellular automata that perform multiplication by 3 and 3/2 in
base 6, and reformulated both the Collatz conjecture and Mahler’s 3/2 problem as sets
of constraints to be satisﬁed by the space-time diagrams of these cellular automata.
Kauffman [13] developed a formalism to perform arithmetic that he called string
arithmetic, and expressed the Collatz conjecture within it. This formalism works with
unary representations of numbers, and uses the three symbols 1, ◁, ▷. Letting ϵ denote
the empty string and N be any string representing a number, string arithmetic consists of
the following bidirectional rewrite rules (or “identities”) to convert between different
strings representing the same number: {▷◁←→ϵ, 11 ←→◁1▷, 1N ←→N1}. Then, the
Collatz function is encoded by the following two rules: {◁N▷→N, ◁N▷1 →◁N1▷N}.
The Collatz conjecture is equivalent to the question of whether for strings of 1s of all
lengths there exists a rewrite sequence using the ﬁve rules above to reach the string 1.
7
Future Work
Several extensions to this work can further our understanding of the potential of rewriting
techniques for answering mathematical questions. For instance, although matrix/arctic
interpretations lead to automated proofs of several weakened variants discussed in
this paper, it might still be the case that there exists no matrix/arctic interpretation to
establish the termination of the Collatz system T . Proving nonexistence would provide
guidance as to where to focus our efforts when searching for a proof. Another issue
is the matter of representation, speciﬁcally, it is worth exploring whether there exists
a suitable translation of the Collatz conjecture into a term, instead of string, rewriting
system since many automated termination proving techniques are generalized to term
rewriting. Finally, injecting problem-speciﬁc knowledge into the rewriting systems or
the termination techniques would be helpful as there exists a wealth of information about
the Collatz conjecture that could simplify proof search.
Acknowledgments. We thank Jeffrey Lagarias, Florian Frohn, Johannes Waldmann,
Carsten Fuhs, Jürgen Giesl, Luke Schaeffer, and Chris Lynch for discussions. We thank
Jeremy Avigad, Jasmin Blanchette, and reviewers of CADE for their detailed comments
on an earlier draft. This work was supported by NSF under grant CCF-2006363.

An Automated Approach to the Collatz Conjecture
483
References
1. Arts, T., Giesl, J.: Termination of term rewriting using dependency pairs. Theoretical Computer
Science 236(1), 133–178 (2000)
2. Baader, F., Nipkow, T.: Term Rewriting and All That. Cambridge University Press (1998)
3. Buttsworth, R.N., Matthews, K.R.: On some Markov matrices arising from the generalized
Collatz mapping. Acta Arithmetica 55(1), 43–57 (1990)
4. De Mol, L.: Tag systems and Collatz-like functions. Theoretical Computer Science 390(1),
92–101 (2008)
5. Eén, N., Sörensson, N.: An extensible SAT-solver. In: Giunchiglia, E., Tacchella, A. (eds.)
Theory and Applications of Satisﬁability Testing (SAT), Lecture Notes in Computer Science,
vol. 2919, pp. 502–518. Springer (2004)
6. Endrullis, J., Waldmann, J., Zantema, H.: Matrix interpretations for proving termination of
term rewriting. Journal of Automated Reasoning 40(2), 195–220 (2008)
7. Erd˝os, P.: Some unconventional problems in number theory. Mathematics Magazine 52(2),
67–70 (1979)
8. Farkas, H.M.: Variants of the 3N + 1 conjecture and multiplicative semigroups. In: Geometry,
Spectral Theory, Groups, and Dynamics, Contemporary Mathematics, vol. 387, pp. 121–127.
American Mathematical Society (2005)
9. Giesl, J., Thiemann, R., Schneider-Kamp, P., Falke, S.: Mechanizing and improving depen-
dency pairs. Journal of Automated Reasoning 37(3), 155–203 (2006)
10. Hofbauer, D., Waldmann, J.: Termination of string rewriting with matrix interpretations.
In: Pfenning, F. (ed.) Term Rewriting and Applications (RTA), Lecture Notes in Computer
Science, vol. 4098, pp. 328–342. Springer (2006)
11. Kari, J.: Cellular automata, the Collatz conjecture and powers of 3/2. In: Yen, H., Ibarra,
O.H. (eds.) Developments in Language Theory (DLT), Lecture Notes in Computer Science,
vol. 7410, pp. 40–49. Springer (2012)
12. Kašˇcák, F.: Small universal one-state linear operator algorithm. In: Havel, I.M., Koubek, V.
(eds.) Mathematical Foundations of Computer Science (MFCS), Lecture Notes in Computer
Science, vol. 629, pp. 327–335. Springer (1992)
13. Kauffman, L.H.: Arithmetic in the form. Cybernetics and Systems 26(1), 1–57 (1995)
14. Kohl, S.: Wildness of iteration of certain residue-class-wise afﬁne mappings. Advances in
Applied Mathematics 39(3), 322–328 (2007)
15. Koprowski, A., Waldmann, J.: Max/plus tree automata for termination of term rewriting. Acta
Cybernetica 19(2), 357–392 (2009)
16. Lagarias, J.C.: The 3x + 1 problem and its generalizations. The American Mathematical
Monthly 92(1), 3–23 (1985)
17. Lagarias, J.C.: The Ultimate Challenge: The 3x+1 Problem. American Mathematical Society
(2010)
18. Lagarias, J.C.: The 3x + 1 problem: An annotated bibliography (1963–1999) (2011),
arXiv:math/0309224
19. Lagarias, J.C.: The 3x + 1 problem: An annotated bibliography, II (2000–2009) (2012),
arXiv:math/0608208
20. Mahler, K.: An unsolved problem on the powers of 3/2. Journal of the Australian Mathemati-
cal Society 8(2), 313–321 (1968)
21. Michel, P.: Problems in number theory from busy beaver competition. Logical Methods in
Computer Science 11(4:10), 1–35 (2015)
22. Pipatsrisawat, K., Darwiche, A.: A lightweight component caching scheme for satisﬁability
solvers. In: Marques-Silva, J., Sakallah, K.A. (eds.) Theory and Applications of Satisﬁability
Testing (SAT), Lecture Notes in Computer Science, vol. 4501, pp. 294–299. Springer (2007)

484
Emre Yolcu, Scott Aaronson, and Marijn J. H. Heule
23. Post, E.L.: Formal reductions of the general combinatorial decision problem. American
Journal of Mathematics 65(2), 197–215 (1943)
24. Rawsthorne, D.A.: Imitation of an iteration. Mathematics Magazine 58(3), 172–176 (1985)
25. Scollo, G.: ω-rewriting the Collatz problem. Fundamenta Informaticae 64(1-4), 405–416
(2005)
26. Sternagel, C., Thiemann, R.: Formalizing monotone algebras for certiﬁcation of termination
and complexity proofs. In: Dowek, G. (ed.) Rewriting and Typed Lambda Calculi (RTA-
TLCA), Lecture Notes in Computer Science, vol. 8560, pp. 441–455. Springer (2014)
27. Wagon, S.: The Collatz problem. The Mathematical Intelligencer 7(1), 72–76 (1985)
28. Waldmann, J., de Vrijer, R., Endrullis, J.: Local termination: Theory and practice. Logical
Methods in Computer Science 6(3) (2010)
29. Zantema, H.: Termination of string rewriting proved automatically. Journal of Automated
Reasoning 34(2), 105–139 (2005)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits
use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you
give appropriate credit to the original author(s) and the source, provide a link to the Creative
Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s Creative
Commons license, unless indicated otherwise in a credit line to the material. If material is not in-
cluded
in
the
chapter’s
Creative
Commons
license
and
your
intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain
permission directly from the copyright holder.

Veriﬁed Interactive Computation of Deﬁnite
Integrals
Runqing Xu1,2 ID , Liming Li1 ID , Bohua Zhan1,2()
ID
1SKLCS, Institute of Software, Chinese Academy of Sciences, Beijing, China
2University of Chinese Academy of Sciences, Beijing, China
{xurq, lilm, bzhan}@ios.ac.cn
Abstract. Symbolic computation is involved in many areas of math-
ematics, as well as in analysis of physical systems in science and en-
gineering. Computer algebra systems present an easy-to-use interface
for performing these calculations, but do not provide strong guarantees
of correctness. In contrast, interactive theorem proving provides much
stronger guarantees of correctness, but requires more time and exper-
tise. In this paper, we propose a general framework for combining these
two methods, and demonstrate it using computation of deﬁnite integrals.
It allows the user to carry out step-by-step computations in a familiar
user interface, while also verifying the computation by translating it to
proofs in higher-order logic. The system consists of an intermediate lan-
guage for recording computations, proof automation for simpliﬁcation
and inequality checking, and heuristic integration methods. A prototype
is implemented in Python based on HolPy, and tested on a large collec-
tion of examples at the undergraduate level.
Keywords: Symbolic integration, User interface, Proof automation
1
Introduction
Symbolic computation is an important tool in mathematics, science, and engi-
neering. It forms a key part of many mathematical proofs. On the engineering
side, justiﬁcations for the design of signal processing and control systems con-
tain extensive symbolic computations [6,33], involving derivatives and integrals,
Laplace and Fourier transforms, and various special functions.
Typically, these computations can be performed using computer algebra sys-
tems such as Mathematica, Maple, and Maxima. Given the complexity of the
task, it is not surprising that even the best of these systems are liable to errors.
One famous example is
 1
−1
√
x2 dx, which an early version of Maple evaluates to
zero [23] (the error has been ﬁxed in the more recent versions). Bugs in Math-
ematica have also been observed by mathematicians [15], including evaluation
of determinants of matrices with large integer entries, and several evaluations
of integrals (also ﬁxed in the most recent version). While some errors are sim-
ply implementation mistakes, more systematic errors in symbolic computation
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5 28
485–503, 2021.

486
R. Xu, L. Li, et al.
may arise due to neglect of checking side conditions, involving concepts such
as well-deﬁnedness of expressions, singularities, convergence, and so on. While
individual bugs can be reported and ﬁxed, completely eliminating the possibility
of error would require a more systematic approach.
Formalization of mathematics in interactive theorem provers promises to
eventually achieve this goal. There is already a lot of work on formalization
of analysis and linear algebra in interactive theorem provers, as well as veri-
ﬁed computations based on the formalized theories. They provide much stronger
guarantees of correctness, and also allow users to specify more detailed steps, en-
abling computations that are too diﬃcult to be found automatically by computer
algebra systems. However, a major disadvantage (for now) is that interactive the-
orem proving requires a great deal of time and expertise on the part of the user,
making it diﬃcult to apply on a much larger scale.
It is therefore natural to try to combine the advantages of computer algebra
systems with theorem proving. There have already been many works in this
direction. A common approach, proposed by Harrison and Th´ery [20,23], is to
invoke a computer algebra system for computations that are diﬃcult to perform,
but whose results can be veriﬁed more easily. This greatly extends the capability
of proof assistants for tasks such as factorization [23], linear arithmetic [28],
etc. However, to use such a system, the user still needs expertise in the use of
proof assistants, and the range of applicability is limited by the simple proof
automation that is available for checking results.
In this paper, we propose a more general framework for veriﬁed symbolic com-
putation in theorem provers, and demonstrate it using computation of deﬁnite
integrals. The resulting system allows users to perform calculations of deﬁnite
integrals step-by-step, in a user interface similar to that of a computer algebra
system, but with the computations veriﬁed by automatic translation to proofs
in higher-order logic. We choose deﬁnite integration for demonstration purposes,
due to the great variety of techniques that can be used, but we intend the idea
to be applicable to other kinds of symbolic computations.
The framework consists of several components. At the top, a graphical user
interface displays the current computation and allows user actions. The user
interface produces computations in a standard format. Next, proof automation is
used to reconstruct from the computation a proof in higher-order logic. Finally,
the proof depends on theorems in mathematics, e.g. (in the case of deﬁnite
integration) those concerning continuity, derivatives, and integrals.
We implement a prototype based on HolPy, a new interactive theorem prover
written in Python [49]. The SymPy package for symbolic computation in Python
is used at various places for untrusted computations. The user interface is written
in JavaScript as a web application, using Python as backend for convenient
invocation of HolPy and SymPy libraries. The underlying theorems in analysis
are mostly translated to HolPy from HOL Light (with some modiﬁcations). Their
proofs have not been fully formalized in HolPy, hence the statements of these
theorems still need to be trusted.

Veriﬁed Interactive Computation of Deﬁnite Integrals
487
We now give an outline for the rest of this paper. Section 2 presents the
overall framework. Section 3 describes the intermediate format for recording
computations of deﬁnite integrals. In Section 4 and 5, we describe respectively
the user interface and the proof reconstruction process. In Section 6 we present
an evaluation of the system, along with some interesting examples. Finally, we
conclude in Section 7 with discussion of possible future work.
Related work. There is a huge body of work on formal veriﬁcation of continuous
and hybrid systems, based on reachability checking [4], computation of invari-
ants [36,41], deductive methods [34,35,47], and so on. In particular, KeYmaera
X [18] provides a user interface for verifying hybrid systems using diﬀerential dy-
namic logic, with automatic generation of proofs checkable in Isabelle [9]. Most
of this work focuses on automatic veriﬁcation and/or logical formalisms. Our
work can be seen as complementary, focusing on verifying symbolic reasoning
about mathematical concepts such as special functions and integration, which
can also form a part of the justiﬁcation of control systems.
Harrison and Th´ery proposed the “skeptical” approach for combining theo-
rem provers with computer algebra systems [20,23]. Some common applications
include factorization of polynomials, which is further applied to verify antideriva-
tives involving sine and cosine [23]. More recently, this technique is used by
Chyzak et al. to formalize the proof of irrationality of ζ(3) [14], and by Harrison
to verify proofs of hypergeometric sums found using the WZ method [22]. Similar
approaches are implemented in Isabelle [8], PVS [3] and Lean [28]. Compared to
this work, we present more complex proof automation for reconstructing proofs,
as well as a user interface for allowing users to perform multi-step computations
in a more familiar setting. Other user interfaces for proof assistants with support
for displaying mathematical computations include Theorema [11] and jsCoq [5].
The theory of integration has been formalized in every major proof assis-
tant [12,24,31,40,43]. Recently, more advanced concepts that are important in
science and engineering have been formalized, including the work by Hasan et
al. on Fourier and Laplace transforms [37,38,46], and Immler et al. on ordinary
diﬀerential equations [25,26]. Work has also been done on formalizing advanced
concepts in linear algebra [29], with applications in analyzing mechanical sys-
tems [13,44]. Of course, formalized symbolic computation can be applied in many
other domains. For example, Selsam et al. [42] veriﬁed in Lean the correctness
of stochastic backpropagation, an important algorithm in deep learning.
Slagle initiated the study of automatic integration with a heuristic method
[45]. Later research focused more on methods that are complete for certain types
of integrands, such as Risch’s algorithm [19]. More recently, Rubi (rule-based in-
tegration) has been demonstrated to be a powerful technique [39]. However, none
of these work focuses on formal veriﬁcation. A veriﬁed computation of asymp-
totics for real-valued functions is implemented by Eberl [16]. Veriﬁed numerical
computation of deﬁnite integrals is implemented by Mahboubi et al. [30].
Acknowledgements. This work was partially supported by the National Natural
Science Foundation of China under Grant Nos. 62002351, 62032024, and the

488
R. Xu, L. Li, et al.
Chinese Academy of Sciences Pioneer 100 Talents Program under Grant No.
Y9RC585036.
2
Overall Architecture
In this section, we describe the overall architecture of the system, leaving descrip-
tions of its components to the following sections. We focus on deﬁnite integrals
of continuous functions in one variable over closed intervals. In particular, we
consider expressions given by the following syntax:
e := v | c | e1 op e2 | f(e) | Deriv(e, v) | Integral(e, v, a, b)
Here v is a variable; c is a constant (either a rational number or π); op is an
arithmetic operation (+, −, ×, ÷ and exponentiation); f is a special function
(such as logarithms, exponentials, or trigonometric functions); Deriv(e, v) de-
notes the derivative of e with respect to variable v; Integral(e, v, a, b) denotes the
deﬁnite integral of e with respect to variable v over the interval [a, b]. In the rest
of this paper, we will use both concrete syntax and LATEX form of expressions.
We use locations to point to particular subexpressions. A location is given by
a sequence of natural numbers (written in the form n1.n2 . . . nk, with each ni
starting from zero), specifying the path to a subtree in the abstract syntax tree
of an expression. For example, in the expression
1 + Integral(1 + sin3(x), x, 0, 1)
the location of sin3(x) is given by 1.0.1.
A computation is represented as a list of steps, with each step specifying a
rewriting of the current expression. Each step should provide suﬃcient informa-
tion so that both checking its correctness and proof generation can be performed
relatively easily. A computation begins with the integral to be evaluated, and
ends with an expression in simpliﬁed closed form. Each step contains the name
of the rule used, the location in the expression at which it is applied, and the
expected result of applying the step. A step may contain additional parameters
and certiﬁcates needed for veriﬁcation. Rules of integration include substitution,
integration by parts, use of a trigonometric identity, and so on (described in
detail in Section 3). For example, integration by parts takes as parameters two
expressions u and v, such that f · dx = u · dv where f is the integrand of the
integral at the given location.
A graphical user interface allows the user to specify a computation in ways
similar to using a computer algebra system. The user interface displays the
computation in LATEX or in text form. At each step, the user selects part of the
current expression to focus on, then selects an action from the menu. Depending
on the selected action, the user may need to enter some of the parameters, while
the other parameters are automatically inferred by the system. After checking
validity of inputs, the user interface computes the result of the action. A package
for symbolic computation may be invoked at this step.

Veriﬁed Interactive Computation of Deﬁnite Integrals
489
There are many side conditions that need to hold in order for a computa-
tion step to be correct, some of which may not be caught at the user interface.
Translation of the computation to proofs in higher-order logic greatly increases
our conﬁdence in the computation and can point out potential errors. In this
work, we translate the computation to higher-order logic proofs in HolPy. One
main diﬃculty is implementing suﬃciently powerful proof automation for sim-
pliﬁcation of expressions, inequality checking, and other side conditions. We
demonstrate that the API for proof automation in HolPy is suﬃciently powerful
for this purpose. However, note the representation of a computation is indepen-
dent from any particular proof assistant, so additional proof translation may be
implemented for other proof assistants.
Finally, various algorithms for integration (such as Slagle’s method [45]) may
be implemented to perform several steps of computation at once. We imple-
mented Slagle’s method and have it as one of the options at the user interface.
The overall framework is shown in the following diagram.
User interface
Computation
Slagle’s method
Proof automation
Analysis library
Other algorithms
Isabelle
Coq
· · ·
HolPy
Here solid boxes and arrows indicate parts that are implemented for this paper.
The analysis library is only partially formalized. Dotted arrows indicate possible
future extensions.
This layered design can be viewed as a separation of concerns. At the top, the
user only need to think about how to evaluate an integral in general mathemati-
cal terms. The implementation of integration algorithms only involves computer
algebra. Proof automation involves algorithms for constructing proofs in the un-
derlying logic. Finally, building a library in analysis involves working with a
proof assistant. All these are put together to enable veriﬁcation of potentially
diﬃcult symbolic integration by producing proofs in higher-order logic or other
logical formalisms. In the following three sections, we describe the top three
layers of the system in more detail.
3
Integration Rules
Rules of integration deﬁne the language for recording computations. Each rule
may take additional parameters (as described below), as well as a location pa-
rameter specifying the subexpression the rule is applied on.

490
R. Xu, L. Li, et al.
3.1
Simpliﬁcation
The rule Simpliﬁcation rewrites an expression to an equivalent simpler form.
The details of simpliﬁcation depends on the implementation. Here we only spec-
ify in broad terms what is and is not simpliﬁed. These choices are made mainly
considering the ease of performing simpliﬁcations, and having a clearly deﬁned
“simpliﬁed form”. We do expand products of polynomials and combine terms
(e.g. from (x + 1)(x −1) to x2 −1). We do not reduce quotients of polynomials
(e.g. from (x3 + 1)/(x2 + 1) to x −(x −1)/(x2 + 1), and from 2/(x2 −1) to
1/(x −1) −1/(x + 1)). We do not automatically expand powers (e.g. (x + 1)5).
We do simplify values of trigonometric functions (e.g. from sin( π
4 ) to
√
2/2, and
from sin( π
2 −x) to cos x), but do not use other trigonometric identities. We do
evaluate derivatives and apply a ﬁxed list of basic integrals, including linearity,
powers, sine, cosine, exponential, and derivatives of trigonometric functions.
One complication is that certain rewrite rules contain side conditions. For
example, it is only possible to simplify √xy to √x · √y when both x and y are
nonnegative. Likewise (x2)
1
2 can be simpliﬁed to x2· 1
2 = x only if x is nonnega-
tive (otherwise the mistake mentioned in the introduction would result). When
simplifying an integrand of an integral in x, we assume that x is within the open
domain of integration, and perform simpliﬁcation only if it is allowed by this
assumption.
3.2
Trigonometric Identities
Application of trigonometric identities can be very tricky. It is often necessary
to use trigonometric identities to rewrite an expression to a more complex form,
in order to prepare for a substitution or integration by parts.
We use the classiﬁcation of trigonometric identities by Fu et al. [17], which is
implemented in SymPy (sympy.simplify.fu). In this scheme, trigonometric identi-
ties are classiﬁed into several groups with names of the form TRi. Some com-
monly used groups are shown below (rewriting from left to right):
– TR5: sin2 x = 1 −cos2 x.
– TR6: cos2 x = 1 −sin2 x.
– TR7: cos2 x = 1
2(1 + cos 2x).
– TR9: sin x + sin y = 2 sin
 x+y
2

cos
 x−y
2

, etc.
– TR11: sin 2x = 2 sin x cos x, cos 2x = cos2 x −sin2 x, etc.
The Rewrite trigonometric rule rewrites using one group of trigonometric
identities, followed by simpliﬁcation. It takes a parameter rule which speciﬁes
the name of the rule used. For example, applying with rule = TR5 on 2−2 sin2 x
yields 2 cos2 x.
3.3
Substitution
Substitution makes use of the following theorem known from ﬁrst-year calculus:
 b
a
f(g(x))g′(x) dx =
 g(b)
g(a)
f(u) du.

Veriﬁed Interactive Computation of Deﬁnite Integrals
491
There are two possible directions for applying the theorem, corresponding to two
rules Substitution I and Substitution II.
Forward substitution. The rule Substitution I assumes the integral is in
the form f(g(x))g′(x). Typically in informal writing, only g(x) is provided, and
f(x) is found by a sometimes magical process. To see the possible complexity
involved, consider the integral
 1
3
4
1
√1 −x −1 dx
The required substitution is u = √1 −x. The usual explanation continues as
follows. Compute du = −1
2(1 −x)−1/2 dx = −1
2u−1 dx. So dx = −2u · du. The
values of u at the boundary points are 1
2 and 0. So the integral can be rewritten
as
 0
1/2 −2u/(u −1) du =
 1/2
0
2u/(u −1) du.
Heurstic methods are needed for ﬁnding a suitable function f. Hence, we
require the Substitution I rule to specify both f and g as parameters. The
rule checks that f(g(x))g′(x) and the original integrand become the same after
simpliﬁcation. We also restrict g to be monotonic (equivalently g′(x) ≥0 or
g′(x) ≤0 in the open interval (a, b))1. For example, the previous substitution is
given by f(u) = 2u/(u −1) and g(x) = √1 −x.
Backward substitution. The rule Substitution II applies substitution in
the other direction. In informal writing, it is usually expressed as substituting
x by some expression g(t). Then f is the original integrand, but the values of a
and b need to be found by the reader. Our rule requires specifying a and b so
that g(a) and g(b) equals the original limits of integration, and g is monotonic
in the range (a, b). For example, the step
 1
0

1 −x2 dx =

π
2
0

1 −sin2 t cos t dt
is represented as g = sin(t), a = 0 and b = π/2.
3.4
Integration by Parts
The Integration by parts rule applies the theorem
 b
a
u(x)v′(x) dx = u(x)v(x)|b
a −
 b
a
u′(x)v(x) dx
Typically in informal writing, both u and v are provided. These are recorded
as parameters of the rule. The rule checks that f · dx = u · dv, where f is the
original integrand. For example, the step
 2
−1
xex dx = xex|2
−1 −
 2
−1
ex dx
is represented as u = x and v = ex.
1 It is possible to relax this assumption, but the process for reconstructing the proof
would be more involved.

492
R. Xu, L. Li, et al.
3.5
Rewriting
The Rewrite rule provides more ﬂexibility for rewriting than simpliﬁcation.
It allows rewriting an expression to any equivalent form as the preparation for
applying other rules. The rule takes a parameter rhs specifying the intended
right side of the rewrite, and another expression denom, defaulting to 1. The
rule checks that denom is nonzero in the domain of integration, and the original
expression and rhs have the same simpliﬁcation after multiplying by denom.
The presence of denom means polynomial division and partial fraction de-
composition can be speciﬁed. For example, when integrating x3/(x2 + 1), the
ﬁrst step is to divide the numerator by the denominator, yielding x−x/(x2 +1).
Simpliﬁcation as we have implemented is not strongly enough to show their
equivalence. However, after multiplying both sides by denom = x2 + 1, the ex-
pressions x3 and x(x2 + 1) −x become the same after simpliﬁcation.
3.6
Splitting an Integral
Sometimes it is necessary to split the domain of integration into two or more
parts. This is needed to deal with absolute values, and non-monotonic functions g
in a substitution. The rule Split region takes a parameter c satisfying a ≤c ≤b,
and split the integral
 b
a f(x) dx into
 c
a f(x) dx+
 b
c f(x) dx. For example, when
integrating
 1
−1
√
x2 dx (the example from the introduction), the ﬁrst step is
to split with c = 0, resulting in
 0
−1
√
x2 dx +
 1
0
√
x2 dx, which can then be
simpliﬁed to
 0
−1 −x dx +
 1
0 x dx.
3.7
Solving Equations
One particularly interesting technique for integration involves solving for the
value of the integral in an equation2. If an integral I can be written in the form
X −cI, where X is any expression (containing no or simpler integrals), and c is
a constant not equal to −1, then we can solve the equation I = X −cI to obtain
I = X/(c+1). Common uses of this technique include integrating expressions of
the form eax sin bx and eax cos bx (apply integration by parts twice, then solve
equation). The rule Solve equation is applied only to the whole expression,
and takes two parameters: the index id of a previous step and a coeﬃcient
coeﬀ. Let I be the integral before step id. The rule adds coeﬀ· I to the current
expression, then divide by coeﬀ+ 1 and simplify. For example, in the evaluation
of
 π/2
0
e2x cos x dx, after some steps we get −2 + eπ −4
 π/2
0
e2x cos x dx. Then,
applying Solve equation with id = 1 and coeﬀ= 4 yields the answer 1
5(−2+eπ).
4
User Interface
Above the level of representation of a computation, the graphical user interface
helps the user to specify a computation in several ways. Compared to editing a
computation directly, the user interface provides the following conveniences:
2 This is valid as long as the integral exists. In our setting this holds as long as the
integrand is continuous.

Veriﬁed Interactive Computation of Deﬁnite Integrals
493
– Display of all expressions in LATEX format.
– Selection of actions and subexpressions to perform the action on.
– Automatically generate some parameters of steps.
– Access to automatic integration algorithms such as Slagle’s method.
In the remainder of this section, we describe the last two functionalities in
more detail. A screenshot of the user interface is shown in Figure 1.
Fig. 1. Screenshot of the user interface, showing the computation of Example 2 in
Section 6.
4.1
Substitution
As discussed in Section 3.3, the Substitution I rule requires both f and g as
parameters, while typically only g is speciﬁed in informal arguments. Finding the
function f can be a nontrivial process. We try two heuristic methods for ﬁnding
f. First, if the substitution u = g(x) can be solved for x, yielding a function
h such that x = h(u), then f can be found by dividing the integrand by g′(x),
then substituting h(u) for x and simplify. Both solving and simpliﬁcation can
be done without checking well-deﬁnedness of intermediate expressions, since in
the end one only need f(g(x))g′(x) to equal the integrand. For the implementa-
tion, we use SymPy’s solve function to attempt to ﬁnd h. The second heuristic
simply replaces all expressions equal to g(x) by u, then hope that all remaining
occurrences of x is in a single g′(x) in the numerator. Note that the user can
always ﬁrst rewrite the expression into a form where the second heuristic can be
applied.
4.2
Rational Functions
Polynomial division or partial fraction decomposition is a common ﬁrst step for
integrating rational functions. From the user interface, the user can invoke these

494
R. Xu, L. Li, et al.
actions. Then SymPy’s apart method is used to obtain the results, For example,
starting from the integral
 1/2
1/3
x
1−x4 dx, the user may choose partial fraction de-
composition from the menu, which turns the integral into
 1/2
1/3
x
2(x2+1) −
1
4(x+1) −
1
4(x−1) dx. The Rewrite rule with appropriate denom parameter is generated
from this step.
4.3
Trigonometric Identities
For the application of trigonometric identities, the user does not need to remem-
ber names of any rules in Fu’s method. Instead, the user selects a subexpression
to rewrite. Then, each of Fu’s rules are applied in turn using SymPy. In case the
application of any rule modiﬁes the expression, the new expression is displayed,
and the user can select from the displayed options. The selected action is then
recorded with the corresponding name.
4.4
Slagle’s Method
We implement a heuristic integration method due to Slagle [45]. There are two
main reasons why we choose Slagle’s method. First, it is simple but eﬀective for
college-level problems. Second, it can output human-readable reasoning steps.
This method maintains a search tree consisting of AND-nodes and OR-nodes.
Each node contains an integral, with the root containing the original integral. An
AND-node speciﬁes that the integral at the node would be solved if each of its
child nodes are solved. An OR-node speciﬁes that the integral at the node would
be solved if one of its child nodes is solved. The method iteratively expands the
tree using a list of algorithmic and heuristic rules. Algorithmic rules involve basic
normalization operations such as simpliﬁcation and polynomial division, they are
always applied to each node. In contrast, heuristic rules are more exploratory,
such as guessing potential expressions for substitution, and count as one step in
the search.
Our implementation is mostly faithful to the original presentation [45], with
some modiﬁcations to ﬁt better with our framework. The output of Slagle’s
method (if successful) is a list of applications of algorithmic and heuristic rules.
Each rule can then be converted to one or more computation steps described in
Section 3.
5
Proof Translation
We now describe the process for translating a computation to a proof in higher-
order logic. This requires suﬃciently strong proof automation for verifying the
application of each integration rule. The main components of the automation
include showing two expressions are equal by simpliﬁcation, inequality checking,
and showing continuity, diﬀerentiability, and integrability of functions. The proof
automation is implemented in Python based on HolPy. However, it should be
possible to implement it in other proof assistants, and one aim of this section is
to provide details to facilitate this process.

Veriﬁed Interactive Computation of Deﬁnite Integrals
495
5.1
Introduction to HolPy
HolPy [49] is a new system for interactive theorem proving implemented in
Python. Like Isabelle [32], HOL Light [21], and HOL4 [1], it uses higher-order
logic as the logical foundation. The design of HolPy centers around explicit proof
terms that can be generated and checked as Python objects, and written to a ﬁle
in JSON format. Macros are used pervasively to control the size of proof terms.
An API for proof automation facilitates implementation of procedures generating
proof terms, in a manner similar to writing proof automation in the ML family
of languages, but in the setting of an imperative programming language.
5.2
Background Library
For the background library in analysis, we ported statements of over a thousand
theorems from HOL Light, of which about 40% are proved using the point-and-
click based user interface [49]. However, major parts of the theory are yet to be
formalized, including the construction of real numbers, the gauge integral, and
the fundamental theorem of calculus. At present, the statements of the theorems
need to be trusted. Finishing the formalization of the analysis library is planned
as future work.
5.3
Structure of Proof Automation
The procedure for translating a computation is as follows. For each step in the
computation, all expressions involved are ﬁrst translated into terms in higher-
order logic. Depending on the rule used, the automation applies the appropriate
conversion to the input term, with the parameters of the rule serving as addi-
tional arguments to the conversion. Next, the automation attempts to show the
equality between the result of the conversion and the expected output of the step
by simplifying both sides. Hence, there does not need to be perfect agreement in
the expected output and what is computed by proof automation. The transla-
tion is successful as long as proof automation is able to show their equivalence.
In this way, we allow additional ﬂexibility in the implementations.
We now discuss the overall structure of proof automation, which bears some
similarity to the structure of auto and simp tactics in Isabelle [48]. We maintain
two tables: a table of proof rules and a table of simpliﬁcation rules. Each table
is indexed by the head of the predicate or term the rule expects. There may be
multiple rules associated to the same head term.
– A prove rule for a predicate p takes as input a goal whose head is p and
a list of assumptions, and attempts to prove the goal. A simple way to
specify a prove rule is from a list of theorems whose conclusion matches the
given predicate. The corresponding prove rule attempts to apply each of the
theorems in order. In case a theorem has assumptions, it recursively applies
the overall prove procedure (described below) to discharge each assumption.

496
R. Xu, L. Li, et al.
– A simpliﬁcation rule for a function f takes as input a term whose head is f
and a list of assumptions, and computes the simpliﬁcation of the term under
these assumptions. A simple way to specify a simpliﬁcation rule is from a list
of theorems whose conclusion is an equality, where the left side has head f.
The corresponding simpliﬁcation rule attempts to rewrite using each of the
equalities in order. Assumptions in the theorem are discharged by recursive
calls to prove as in the previous case.
The overall procedure is deﬁned as a mutual recursion between two functions
prove and norm. The norm function receives a term and a list of assumptions as
input. It ﬁrst recursively applies itself to the subterms of the term. Next, it looks
for simpliﬁcation rules associated to the head of the term and applies them in
turn. If the head changes, the process is repeated. Note the prove function may
be called to discharge assumptions of rewrite rules. This continues until the term
is not changed by the simpliﬁcation rules. The prove function takes a goal and a
list of assumptions as input. It ﬁrst simpliﬁes the goal, then look for prove rules
associated to the head term and applies each of them in turn. The case where
the goal is an equality reduces to simplifying both sides and then comparing
whether they are the same.
5.4
Inequality Checking
A major task of proof automation is checking inequalities in one variable x
constrained to lie in an interval [a, b] or (a, b). For example, if one wishes to
simplify

f(x)2 to f(x) in the integrand, where the integral is from a to b,
one needs to check f(x) ≥0 in the open interval (a, b). Here f may involve the
usual arithmetic operations, as well as logarithm, exponential, and trigonometric
functions.
The general problem of inequality checking is undecidable when special func-
tions are involved. Hence, we can only hope for methods that can solve most of
the inequality goals that appear in practice. There are many heuristic methods [7]
as well as decision procedures for inequalities. For our purposes, we found the
following, which can be considered as a simpliﬁed version of interval arithmetic,
to be both simple and eﬀective: starting from the assumption that x lies in a cer-
tain interval, iteratively deduce the intervals constraining each of the subterms
in the expression. The derivation for each subterm depends on the head of the
subterm. Of course, this method is incomplete as it tends to over-approximate
the intervals of terms formed from binary operators. Implementation of more
advanced inequality checking methods is a goal for the future.
5.5
Simpliﬁcation
Simpliﬁcation for arithmetic operations follows the same principle as in Section
3.1: expand the expression into polynomial form, but do not expand powers.
We also do not reduce rational functions. This is similar to the normalization of
polynomials in other implementations of proof automation [7].

Veriﬁed Interactive Computation of Deﬁnite Integrals
497
More precisely, deﬁne a monomial to be a term of the form c·(ap1
1 ap2
2 · · · apk
k ),
where c is a rational number, and each ai is either a prime number or a term
whose head is not an arithmetic operator. If ai is a prime number, then the
corresponding pi must be either non-constant or a rational number between 0
and 1 exclusive. The ai’s are distinct and sorted in a pre-determined order. A
rational number is a special case of a monomial, with k = 0. We call c the
coeﬃcient of a monomial and ap1
1 ap2
2 · · · apk
k
its body. A polynomial is a sum of
monomials, whose bodies are all distinct and in sorted order. It is clear that
any expression can be simpliﬁed into this form. For example,
√
6
√
2(x + 32/3) is
simpliﬁed to
61/221/2x + 61/221/232/3 = 21/231/221/2x + 21/231/221/232/3 = 2 · 31/2x + 6 · 31/6
Simpliﬁcation of polynomials is implemented in the simpliﬁcation rules for +,
× and power. a −b and a/b are simply reduced to a + (−1) · b and a · b−1,
respectively.
For logarithms and exponentials, we apply the standard simpliﬁcation rules
log 1 = 0, log(ex) = x and e0 = 1, x > 0 −→elog x = x. Simplifying trigonometric
functions applied to special values is trickier, as we may need to add or subtract
multiples of π. For example, cos 7π
3 is ﬁrst rewritten to cos π
3 and then to 1
2.
When simplifying an integral over the closed interval [a, b], we apply the
following congruence rule:
∀x ∈(a, b). f(x) = g(x) −→
 b
a
f(x) dx =
 b
a
g(x) dx.
This allows us to assume x ∈(a, b) when simplifying f(x).
5.6
Applying Theorems
For proving continuity and diﬀerentiability, we set up the corresponding prove
rules using lists of introduction rules. Some of these rules require assumptions
that are discharged recursively. For example, the introduction rule for division
is as follows:
 continuous on S f, continuous on S g, ∀x ∈S. g(x) ̸= 0 
−→continuous on S (λx. f(x)/g(x))
Application of this rule involves recursively proving the three assumptions, in-
cluding the use of inequality checking from Section 5.4.
Substitution and integration by parts are implemented by applying the cor-
responding theorems. This is simple because the parameters of the rule already
contain instantiations for all function variables.
6
Evaluation and Examples
We evaluated our prototype implementation3 on problems taken from exam
preparation books (Tongji), online problem lists by D. Kouba [27] (Kouba) and
3 The code and examples are available online at https://github.com/bzhan/
holpy.

498
R. Xu, L. Li, et al.
the MIT Integration Bee [2] (MIT). We also compared our results with Maple
and WolframAlpha. Statistics from the evaluation are shown in Table 1.
Problem set
Total
Solved
Ratio
Slagle
Ratio
Maple
WolframAlpha
Tongji
36
36
100%
26
72%
32
35
Kouba/Substitution
18
17
94%
13
72%
18
18
Kouba/Exponentials
12
7
58%
7
58%
12
11
Kouba/Trigonometric
27
22
81%
11
41%
18
22
Kouba/ByParts
23
22
96%
17
74%
23
23
Kouba/LogArcTangent
22
21
95%
13
59%
21
21
Kouba/PartialFraction
20
16
80%
8
40%
18
20
MIT/2013
25
20
80%
14
56%
20
24
Total
183
161
88%
109
60%
162
174
Table 1. Statistics on the problem lists. “Solved” indicates the number of problems
for which proofs can be successfully reconstructed from human-provided computations.
“Slagle” indicates the number of problems that can be solved by Slagle’s method, with
successful proof reconstruction. “Maple” represents the number of problems solved by
Maple. “WolframAlpha” represents the number of problems which WolframAlpha can
give step-by-step solutions without exceeding its time limit.
The Kouba problem lists are divided into diﬀerent categories based on tech-
niques used. With human-provided computation steps, we can reconstruct proofs
for all of the Tongji problems, most of the problems in D. Kouba’s list, while
problems from the MIT Integration Bee are more challenging (with the later
years increasing in diﬃculty). Most of the failures are due to unable to show
equality after simpliﬁcation, and during inequality checking. Some are due to
unsupported functions.
We show two interesting examples from our case studies. SymPy (version 1.5)
returns a wrong answer on the ﬁrst example and times out on the second. The
second example takes a long time even for Mathematica, and cannot be solved by
its online version WolframAlpha. These examples demonstrate that our system
avoids the common errors, and since the user can guide the computation step-
by-step, is also able to verify integrals that are diﬃcult even for sophisticated
computer algebra systems.
The ﬁrst example (Tongji, #27) demonstrates the splitting of domain of in-
tegration, as well as use of trigonometric identities. The integral is
 π
0
√
1 + cos 2x dx
This integral is incorrectly evaluated by SymPy as 0. It is correctly evaluated
by Mathematica almost instantly.
The evaluation begins with application of trigonometric identities, rewriting
the integrand to

1 + cos2 x −sin2 x and then to
√
2 cos2 x. For this, the user
simply needs to select cos 2x and then sin2 x, and choose the desired rewrite
targets. The resulting situation is similar to the example given in the introduc-
tion. It is then necessary to split the domain of integration where cos x = 0. The
system is able to automatically determine x = π
2 . The full computation is:

Veriﬁed Interactive Computation of Deﬁnite Integrals
499
I =
 π
0

1 + cos2 x −sin2 x dx
(Rewrite trig. rule TR11)
=
 π
0
√
2 cos2 x dx =
√
2
 π
0
| cos x| dx
(Rewrite trig. rule TR5, Simpliﬁcation)
=
√
2

π
2
0
| cos x| dx +
 π
π
2
| cos x| dx

(Split region with c = π
2 )
= 2
√
2
(Elim absolute value, Simpliﬁcation)
The second example comes from MIT Integration Bee 2019, problem #14:
I =
 π/100
0
sin(20x) + sin(19x)
cos(20x) + cos(19x) dx
It is simple if one notices to apply the sum-to-product identity ﬁrst, but almost
impossible otherwise. WolframAlpha fails to ﬁnd the symbolic answer. Using
Mathematica oﬄine, it takes about 15 seconds to return an answer, which is
however much more complicated than necessary.
The full computation using our tool is:
I =
 π/100
0
sin
 39
2 x

cos
 39
2 x
 dx
(Rewrite trigonometric, rule TR9)
=
 1
cos( 39π
200 )
2
39
1
t dt
(Substitution I with g = cos
39
2 x
	
)
= −2
39 log

cos 39π
200
	
(Simpliﬁcation).
7
Conclusion
In this paper, we proposed a framework for verifying symbolic computation
of deﬁnite integrals, where the user can perform computations in an interface
familiar from computer algebra systems, but with results veriﬁed by automatic
translation to proofs in higher-order logic. The design of the framework follows a
layered approach, with each layer focusing on a diﬀerent aspect of the problem:
methods for solving integrals, computer algebra, and proof reconstruction. We
implemented a prototype system based on HolPy, and evaluated it on a test
suite consisting of publicly available problem lists at the undergraduate level,
showing its eﬀectiveness on a large majority of cases.
One immediate piece of future work is to secure the foundation of the higher-
order logic proof, by formalizing the proofs of the required theorems. Another
gap is the arithmetic computation and comparison of real constants, which, in
the case of comparisons, would require approximation techniques [10].
Our prototype implementation focuses on deﬁnite integrals of one-variable
functions. However, the idea can be applied more generally, by suitably extending
the language of integration rules. For applications in the engineering domain,
some extensions that would be of high value include linear algebra, improper
integrals (including Laplace and Fourier transforms), and vector calculus.

500
R. Xu, L. Li, et al.
References
1. The HOL 4 system. http://hol.sourceforge.net/
2. MIT Integration Bee. http://www.mit.edu/˜pax/integrationbee.html,
accessed: 2020-1-22
3. Adams, A., Dunstan, M., Gottliebsen, H., Kelsey, T., Martin, U., Owre, S.: Com-
puter algebra meets automated theorem proving: Integrating Maple and PVS. In:
Boulton, R.J., Jackson, P.B. (eds.) Theorem Proving in Higher Order Logics. Lec-
ture Notes in Computer Science, vol. 2152, pp. 27–42. Springer Berlin Heidelberg,
Berlin, Heidelberg (2001)
4. Althoﬀ, M., Frehse, G., Girard, A.: Set propagation techniques for reachability
analysis. Annual Review of Control, Robotics, and Autonomous Systems 4(1)
(2021)
5. Arias, E.J.G., Pin, B., Jouvelot, P.: jsCoq: Towards hybrid theorem proving in-
terfaces. In: Autexier, S., Quaresma, P. (eds.) Proceedings of the 12th Workshop
on User Interfaces for Theorem Provers, UITP 2016, Coimbra, Portugal, 2nd July
2016. EPTCS, vol. 239, pp. 15–27 (2016)
6. Astr¨om, K.J., Murray, R.M.: Feedback Systems: An Introduction for Scientists and
Engineers. Princeton University Press, Princeton (2008)
7. Avigad, J., Lewis, R.Y., Roux, C.: A heuristic prover for real inequalities. J. Autom.
Reasoning 56(3), 367–386 (2016)
8. Ballarin, C., Homann, K., Calmet, J.: Theorems and algorithms: An interface be-
tween Isabelle and Maple. In: Levelt, A.H.M. (ed.) Proceedings of the 1995 Inter-
national Symposium on Symbolic and Algebraic Computation. p. 150–157. ISSAC
’95, Association for Computing Machinery, New York, NY, USA (1995)
9. Bohrer, B., Rahli, V., Vukotic, I., V¨olp, M., Platzer, A.: Formally veriﬁed diﬀer-
ential dynamic logic. In: Bertot, Y., Vafeiadis, V. (eds.) Proceedings of the 6th
ACM SIGPLAN Conference on Certiﬁed Programs and Proofs, CPP 2017, Paris,
France, January 16-17, 2017. pp. 208–221 (2017)
10. Br´ehard, F., Mahboubi, A., Pous, D.: A certiﬁcate-based approach to formally
veriﬁed approximations. In: Harrison, J., O’Leary, J., Tolmach, A. (eds.) 10th
International Conference on Interactive Theorem Proving, ITP 2019, September
9-12, 2019, Portland, OR, USA. LIPIcs, vol. 141, pp. 8:1–8:19 (2019)
11. Buchberger, B., Jebelean, T., Kutsia, T., Maletzky, A., Windsteiger, W.: Theorema
2.0: Computer-assisted natural-style mathematics. J. Formaliz. Reason. 9(1), 149–
185 (2016)
12. Butler, R.W.: Formalization of the integral calculus in the PVS theorem prover.
J. Formalized Reasoning 2(1), 1–26 (2009)
13. Chen, S., Wang, G., Li, X., Zhang, Q., Shi, Z., Guan, Y.: Formalization of camera
pose estimation algorithm based on rodrigues formula. Formal Aspects Comput.
32(4-6), 417–437 (2020)
14. Chyzak, F., Mahboubi, A., Sibut-Pinote, T., Tassi, E.: A computer-algebra-based
formal proof of the irrationality of ζ(3). In: Klein, G., Gamboa, R. (eds.) Interactive
Theorem Proving. Lecture Notes in Computer Science, vol. 8558, pp. 160–176.
Springer International Publishing, Cham (2014)
15. Dur´an, A.J., P´erez, M., Varona, J.L.: The misfortunes of a trio of mathematicians
using computer algebra systems. can we trust in them? Notices Amer. Math. Soc.
61(10), 1249–1252 (2014)
16. Eberl, M.: Veriﬁed real asymptotics in Isabelle/HOL. In: Davenport, J.H., Wang,
D., Kauers, M., Bradford, R.J. (eds.) Proceedings of the 2019 on International

Veriﬁed Interactive Computation of Deﬁnite Integrals
501
Symposium on Symbolic and Algebraic Computation, ISSAC 2019, Beijing, China,
July 15-18, 2019. pp. 147–154. ACM (2019)
17. Fu, H., Zhong, X., Zeng, Z.: Automated and readable simpliﬁcation of trigono-
metric expressions. Mathematical and Computer Modelling 44(11-12), 1169–1177
(2006)
18. Fulton, N., Mitsch, S., Quesel, J., V¨olp, M., Platzer, A.: KeYmaera X: an ax-
iomatic tactical theorem prover for hybrid systems. In: Felty, A.P., Middeldorp,
A. (eds.) Automated Deduction - CADE-25 - 25th International Conference on
Automated Deduction, Berlin, Germany, August 1-7, 2015, Proceedings. Lecture
Notes in Computer Science, vol. 9195, pp. 527–538 (2015)
19. Geddes, K.O., Czapor, S.R., Labahn, G.: The Risch Integration Algorithm, pp.
511–573. Springer US, Boston, MA (1992)
20. Harrison, J.: Theorem proving with the real numbers. CPHC/BCS distinguished
dissertations, Springer (1998)
21. Harrison, J.: HOL Light: An overview. In: Berghofer, S., Nipkow, T., Urban, C.,
Wenzel, M. (eds.) Theorem Proving in Higher Order Logics. Lecture Notes in Com-
puter Science, vol. 5674, pp. 60–66. Springer Berlin Heidelberg, Berlin, Heidelberg
(2009)
22. Harrison, J.: Formal proofs of hypergeometric sums - dedicated to the memory of
Andrzej Trybulec. J. Autom. Reasoning 55(3), 223–243 (2015)
23. Harrison, J., Th´ery, L.: A skeptic’s approach to combining HOL and Maple. J.
Autom. Reason. 21(3), 279–294 (1998)
24. H¨olzl, J., Heller, A.: Three chapters of measure theory in Isabelle/HOL. In: van
Eekelen, M., Geuvers, H., Schmaltz, J., Wiedijk, F. (eds.) Interactive Theorem
Proving - Second International Conference, ITP 2011, Berg en Dal, The Nether-
lands, August 22-25, 2011. Proceedings. Lecture Notes in Computer Science,
vol. 6898, pp. 135–151 (2011)
25. Immler, F.: A veriﬁed ODE solver and the Lorenz attractor. J. Autom. Reason.
61(1-4), 73–111 (2018)
26. Immler, F., Traut, C.: The ﬂow of ODEs. In: Blanchette, J.C., Merz, S. (eds.) Inter-
active Theorem Proving - 7th International Conference, ITP 2016, Nancy, France,
August 22-25, 2016, Proceedings. Lecture Notes in Computer Science, vol. 9807,
pp. 184–199 (2016)
27. Kouba, D.A.: The calculus page problems list. https://www.math.ucdavis.
edu/˜kouba/ProblemsList.html, accessed: 2020-1-22
28. Lewis, R.Y.: An extensible ad hoc interface between Lean and Mathematica. In:
Dubois, C., Paleo, B.W. (eds.) Proceedings of the Fifth Workshop on Proof eX-
change for Theorem Proving, PxTP 2017, Bras´ılia, Brazil, 23-24 September 2017.
EPTCS, vol. 262, pp. 23–37 (2017)
29. Li, L., Shi, Z., Guan, Y., Zhang, Q., Li, Y.: Formalization of geometric algebra in
HOL Light. J. Autom. Reasoning 63(3), 787–808 (2019)
30. Mahboubi, A., Melquiond, G., Sibut-Pinote, T.: Formally veriﬁed approximations
of deﬁnite integrals. J. Autom. Reason. 62(2), 281–300 (2019)
31. Mhamdi, T., Hasan, O., Tahar, S.: On the formalization of the Lebesgue integra-
tion theory in HOL. In: Kaufmann, M., Paulson, L.C. (eds.) Interactive Theorem
Proving, First International Conference, ITP 2010, Edinburgh, UK, July 11-14,
2010. Proceedings. Lecture Notes in Computer Science, vol. 6172, pp. 387–402
(2010)
32. Nipkow, T., Paulson, L.C., Wenzel, M.: Isabelle/HOL - A Proof Assistant for
Higher-Order Logic, Lecture Notes in Computer Science, vol. 2283. Springer (2002)

502
R. Xu, L. Li, et al.
33. Oppenheim, A.V., Willsky, A.S.: Signals and Systems. Prentice Hall, Upper Saddle
River, New Jersey (1996)
34. Platzer, A.: Diﬀerential dynamic logic for hybrid systems. J. Autom. Reason. 41(2),
143–189 (2008)
35. Platzer, A.: A complete uniform substitution calculus for diﬀerential dynamic logic.
J. Autom. Reason. 59(2), 219–265 (2017)
36. Prajna, S., Jadbabaie, A.: Safety veriﬁcation of hybrid systems using barrier certiﬁ-
cates. In: Alur, R., Pappas, G.J. (eds.) Hybrid Systems: Computation and Control,
7th International Workshop, HSCC 2004, Philadelphia, PA, USA, March 25-27,
2004, Proceedings. Lecture Notes in Computer Science, vol. 2993, pp. 477–492
(2004)
37. Rashid, A., Hasan, O.: On the formalization of Fourier transform in higher-order
logic. In: Blanchette, J.C., Merz, S. (eds.) Interactive Theorem Proving. Lecture
Notes in Computer Science, vol. 9807, pp. 483–490. Springer International Pub-
lishing, Cham (2016)
38. Rashid, A., Hasan, O.: Formal analysis of continuous-time systems using Fourier
transform. J. Symb. Comput. 90, 65–88 (2019)
39. Rich, A.D., Scheibe, P., Abbasi, N.M.: Rule-based integration: An extensive system
of symbolic integration rules. J. Open Source Softw. 3(32), 1073 (2018)
40. Richter, S.: Formalizing integration theory with an application to probabilistic
algorithms. In: Slind, K., Bunker, A., Gopalakrishnan, G. (eds.) Theorem Prov-
ing in Higher Order Logics, 17th International Conference, TPHOLs 2004, Park
City, Utah, USA, September 14-17, 2004, Proceedings. Lecture Notes in Computer
Science, vol. 3223, pp. 271–286 (2004)
41. Sankaranarayanan, S., Sipma, H., Manna, Z.: Constructing invariants for hybrid
systems. In: Alur, R., Pappas, G.J. (eds.) Hybrid Systems: Computation and Con-
trol, 7th International Workshop, HSCC 2004, Philadelphia, PA, USA, March 25-
27, 2004, Proceedings. Lecture Notes in Computer Science, vol. 2993, pp. 539–554
(2004)
42. Selsam, D., Liang, P., Dill, D.L.: Developing bug-free machine learning systems
with formal mathematics. In: Precup, D., Teh, Y.W. (eds.) Proceedings of the
34th International Conference on Machine Learning, ICML 2017, Sydney, NSW,
Australia, 6-11 August 2017. Proceedings of Machine Learning Research, vol. 70,
pp. 3047–3056 (2017)
43. Shi, Z., Gu, W., Li, X., Guan, Y., Ye, S., Zhang, J., Wei, H.: The gauge integral
theory in HOL4. J. Applied Mathematics 2013, 160875:1–160875:7 (2013)
44. Shi, Z., Wu, A., Yang, X., Guan, Y., Li, Y., Song, X.: Formal analysis of the kine-
matic Jacobian in screw theory. Formal Aspects Comput. 30(6), 739–757 (2018)
45. Slagle, J.R.: A heuristic program that solves symbolic integration problems in
freshman calculus. J. ACM 10(4), 507–520 (1963)
46. Taqdees, S.H., Hasan, O.: Formalization of Laplace transform using the multivari-
able calculus theory of HOL-Light. In: McMillan, K., Middeldorp, A., Voronkov, A.
(eds.) Logic for Programming, Artiﬁcial Intelligence, and Reasoning - 19th Inter-
national Conference, LPAR-19, Stellenbosch, South Africa, December 14-19, 2013.
Proceedings. Lecture Notes in Computer Science, vol. 8312, pp. 744–758 (2013)
47. Wang, S., Zhan, N., Zou, L.: An improved HHL prover: An interactive theorem
prover for hybrid systems. In: Butler, M., Conchon, S., Za¨ıdi, F. (eds.) Formal
Methods and Software Engineering - 17th International Conference on Formal En-
gineering Methods, ICFEM 2015, Paris, France, November 3-5, 2015, Proceedings.
Lecture Notes in Computer Science, vol. 9407, pp. 382–399 (2015)

Veriﬁed Interactive Computation of Deﬁnite Integrals
503
48. Wenzel, M.: The Isabelle/Isar reference manual. http://isabelle.in.tum.
de/doc/isar-ref.pdf
49. Zhan, B., Ji, Z., Zhou, W., Xiang, C., Hou, J., Sun, W.: Design of point-and-click
user interfaces for proof assistants. In: Ait-Ameur, Y., Qin, S. (eds.) Formal Meth-
ods and Software Engineering - 21st International Conference on Formal Engineer-
ing Methods, ICFEM 2019, Shenzhen, China, November 5-9, 2019, Proceedings.
Lecture Notes in Computer Science, vol. 11852, pp. 86–103 (2019)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/
by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in
any medium or format, as long as you give appropriate credit to the original author(s)
and the source, provide a link to the Creative Commons license and indicate if changes
were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

ATP and AI

Conﬁdences for Commonsense Reasoning
1 Applied Artiﬁcial Intelligence Group,
Tallinn University of Technology, Tallinn, Estonia
{tanel.tammet,priit.jarv1}@taltech.ee
2 Information Systems Group, Tallinn University of Technology, Tallinn, Estonia
dirk.draheim@taltech.ee
Abstract. Commonsense reasoning has long been considered one of the
holy grails of artiﬁcial intelligence. Our goal is to develop a logic-based
component for hybrid – machine learning plus logic – commonsense ques-
tion answering systems. A critical feature for the component is estimating
the conﬁdence in the statements derived from knowledge bases contain-
ing uncertain contrary and supporting evidence obtained from diﬀerent
sources. Instead of computing exact probabilities or designing a new cal-
culus we focus on extending the methods and algorithms used by the
existing automated reasoners for full classical ﬁrst-order logic. The pa-
per presents the CONFER framework and implementation for conﬁdence
estimation of derived answers.
1
Introduction
The mainstream approaches for “commonsense reasoning” (CSR) before this
century focused on rule based reasoning and building suitable logical systems.
During the last ten years the focus has switched to machine learning and neural
networks. Both of these approaches appear to be limited. A promising approach
to practical question answering is building hybrid systems like Watson [17] which
complement the current machine learning systems for natural language with
logic-based reasoning systems specialized for CSR. In particular, hybrid systems
have a good potential for progress towards explainable A.I. See Marcus [26] for
an overview of the current work in the area. Our goal is to build upon the existing
theory and reasoning systems for ﬁrst order logic (FOL) to develop a framework
and practical systems using FOL reasoners which could be incorporated into
a hybrid system containing both machine learning components and rule-based
reasoning components. This approach will also provide step-by-step proofs for
the answers found, useful for building explainable systems.
We will present the design and implementation of the CONFER framework
for extending existing automated reasoning systems with conﬁdence calculation
capabilities. We will not focus on other, arguably even more critical issues for
CSR and question answering, like handling natural language itself, dialogues,
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5 29
Tanel Tammet1(B)
, Dirk Draheim2
, and Priit J¨arv1
507–524, 2021.

508
T. Tammet et al.
rules with exceptions and default logic [31] or circumscription, knowledge rep-
resentation for space/time, epistemic reasoning, using context, building and col-
lecting suitable rules, machine learning etc.
The speciﬁc CSR task targeted by the current paper is question answering:
given either a knowledge base of facts and rules or a large corpora of texts (or
both), plus optionally a situation description (assumptions) for the questions,
answer questions posed either in logic or natural language.
Historically, the longest-going CSR project has been the logic-based CYC
project [25], already in 1985 stating the focus on CSR. Despite several successes,
the approach taken in the CYC project has often been viewed as problematic ([8],
[10]) and has been repeatedly used as an argument against logic-based methods
in CSR. Beltagy et al [5] experiment with Markov Logic Network for combining
logical and distributional representations of natural language meaning. Domin-
gos et al note in [13] that the CYC project has used Markov Logic for making
a part of their knowledge base probabilistic. Khot et al [24] experiment with
Markov Logic Networks for NLP question answering. Furbach et al [20] describe
research and experiments with a system for natural language question answer-
ing, converting natural language sentences to logic and then performing proof
search, using diﬀerent existing FOL knowledge bases. The authors note a num-
ber of diﬃculties, with the most crucial being the lack of suﬃciently rich FOL
knowledge bases. The closest current approach to ours appears to be the Braid
system [23] built by the team previously involved with the Watson system.
2
Interpretation and Encoding of Uncertainty
Reasoning under uncertainty has been thoroughly investigated for at least a
century, leading to a proliferation of diﬀerent theories and mechanisms. A classic
example is the MYCIN system [6]. For newer approaches see, for example, [32]
and [9]. Each of these is well suited for certain kinds of problems and ill-suited
for other kinds. Underlying this is the philosophical complexity of interpreting
probability: see [22] for an overview, see also [16], pp. 5-7.
Most of the previous work on combining logic with uncertainty has targeted
propositional logic. First order logic is then handled by creating a ﬁnite set of
weighted ground instances of formulas. This is the approach taken, for example,
by the probabilistic logic programming systems ProbLog2 [18], PRISM [34] and
the implementation of Markov Logic Networks [12,11] by the Alchemy 2 system
[1]. These systems pose diﬀerent restrictions to the FOL formulas and while well-
suited for small domains in cases the restrictions can be followed, the approach
becomes unfeasible if the domain is large or formulas complex. For example,
neither the ProbLog 2 nor Alchemy 2 implementations manage to answer queries
like 1.0::p(a). 1.0::p(i(a,b)). 1.0::p(Y) :- p(X), p(i(X,Y)).
query(p(b)). The implementation of ProbLog2 [29] fails, presumably due to
inﬁnite recursion in searching for possible groundings for the variables, while
Alchemy 2 does not allow function terms in grounded facts.

Conﬁdences for Commonsense Reasoning
509
Previous approaches to full ﬁrst order logic tend to fall into one of the three
camps: either using fuzzy logic [41], representing probabilities as an interval
(see [15] for the axiomatic derivation of Dempster-Schafer rules) or interpreting
probabilities via many worlds similarly to modalities [4].
For the sake of this work, we largely follow the subjective interpretation of
probability as a degree of belief, originating from Ramsey and De Finetti. We
use the word conﬁdence to denote our rough adherence to this interpretation. We
avoid using complex measures such as intervals, distributions or fuzzy functions.
In the context of question answering we assume that conﬁdences are typically
used for sorting a list of candidate answers by their calculated conﬁdence and
optionally applying a ﬁlter to eliminate answers with a conﬁdence under a certain
threshold. Answers provided may be also annotated with a conﬁdence number. If
we are given or can calculate several diﬀerent conﬁdences for the same answer,
we always prefer the higher conﬁdence. The question of calculating a correct
probability rarely arises or is considered to be unfeasible.
2.1
Sources, Representation and Meaning of Statements,
Conﬁdences and Dependencies
We assume that the conﬁdence in a fact or rule in our common sense knowledge
base (KB in the following) typically arises from a large number of human users
via crowd-sourcing like in ConceptNet [35,7], NLP-analyzed scraped text from
the web like NELL [27], and/or combining diﬀerent knowledge bases with weights
like in [14] and [7] or assigned to the equivalence of name pairs in the vocabulary
like in [28] and [19]. There is recent progress towards making knowledge bases
for common sense reasoning where the relation strengths (typicality, saliency)
have been empirically evaluated [7,33].
To each FOL statement S we will assign both a conﬁdence c and a set L
of unique identiﬁers of (non-derived) input statements used for deriving this
statement: a triple ⟨S, c, L⟩. Lists of such triples are then treated as sets. The
dependency lists L are used in the formula estimating the cumulated conﬁdence.
The algorithm for calculating conﬁdences c for derivations will be presented
later.
To be more exact, we will not allow assigning conﬁdences to arbitrary state-
ments. Instead, we will assume that the FOL statements are converted to a
conjunctive normal form: a conjunction of Skolemized disjunctions, where each
disjunction only consists of atomic statements (a predicate applied to arguments)
or negations of atomic statements. Such disjunctions are called clauses. We will
not allow nested triples, i.e. S is always a pure FOL clause not containing any
conﬁdence or dependency information usable by the presented algorithms. How-
ever, for each single FOL clause S there may be many diﬀerent derivable triples
⟨S, c, L⟩for diﬀerent c and L, stemming from diﬀerent derivation trees of S. They
are assumed to be independent statements, possibly allowing the calculation of
the cumulative conﬁdence for S higher than max(c, c′) where c and c′ come from
diﬀerent triples.

510
T. Tammet et al.
A KB may contain logical contradictions and identical FOL clauses with
diﬀerent conﬁdences given by diﬀerent sources. For example, the following is
a logically contradictory KB containing several copies of the same clause with
diﬀerent conﬁdences. The CONFER algorithm presented later gives us the con-
ﬁdence of bird(a) : 0.682 from this KB:
⟨bird(X), 0.1, L1⟩, ⟨bird(a), 0.8, L2⟩, ⟨bird(a), 0.9, L3⟩, ⟨¬bird(a), 0.3, L4⟩
We interpret the conﬁdence as estimating the lower limit of the probability
of a statement, i.e., ⟨S, c, L⟩is interpreted as “statements L support the claim
that probability(S) ≥c”. Thus two diﬀerent conﬁdence statements for the same
clause are never contradictory, even if given by the same source.
3
The CONFER Extension Framework for CSR
In the following we will present the CONFER framework of extensions to the
mainstream resolution-based search methods. We expect that the same frame-
work can be adapted to search methods diﬀerent from resolution, i.e. the speciﬁc
aspects of resolution are not relevant for the main principles of the approach.
The intuition behind CONFER is preserving ﬁrst order classical logic (FOL)
intact as an underlying machinery for derivations in CSR. The core methods of
automated reasoning used by most of the high-performance automated reason-
ing systems remain usable as core methods for CSR. Essentially, FOL with the
resolution method produces all combinations of derivable sentences (modulo sim-
pliﬁcations like subsumption) which could lead to a proof. The main diﬀerence
between strict FOL and CONFER extensions is in the handling of constructed
proof trees: the outcome of a CONFER reasoner is a set of combined FOL proofs
with the conﬁdence measures added.
Importantly, the framework does not generally calculate the exact maximal
conﬁdence for derived statements, since this is, in nontrivial cases, either im-
possible or unfeasible. Our goal is to give a practically useful estimation of the
maximal conﬁdence without causing a large overhead on the FOL proof search
and avoiding combinatorial explosion while calculating the conﬁdences.
3.1
Resolution Method
In the following we will assume that the underlying ﬁrst order reasoner uses the
resolution method, see [3] for details. The rest of the paper assumes familiarity
with the basic concepts, terminology and algorithms of the resolution method.
3.2
Queries and Answers
We assume the question posed is in one of two forms: (1) Is the statement Q
true? (2) Find values V for existentially bound variables in Q so that Q is true.
For simplicity’s sake we will assume that the statement Q is in the preﬁx form,
i.e., no quantiﬁers occur in the scope of other logical connectives.

Conﬁdences for Commonsense Reasoning
511
In the second case, it could be that several diﬀerent value vectors can be
assigned to the variables, essentially giving diﬀerent answers. We also note that
an answer could be a disjunction, giving possible options instead of a single
deﬁnite answer. However, as shown in [38], in case a single deﬁnite answer exists,
it will be derived eventually.
A widely used machinery in resolution-based theorem provers for extracting
values of existentially bound variables in Q is to use a special answer predicate,
converting a question statement Q to a formula
∃X1, ..., ∃Xn(Q(X1, ..., Xn)&¬answer(X1, ..., Xn))
for existentially quantiﬁed variables in Q [21]. Whenever a clause is derived which
consists of only answer predicates, it is treated as a contradiction (essentially,
answer) and the arguments of the answer predicate are returned as the values
looked for. A common convention is to call such clauses answer clauses. We will
require that the proof search does not stop whenever an answer clause is found,
but will continue to look for new answer clauses until a predetermined time limit
is reached. See [37] for a framework of extracting multiple answers.
We also assume that queries take a general form (KB&A) ⇒Q where KB is
a commonsense knowledge base, A is an optional set of precondition statements
for this particular question and Q is a question statement.
Since we assume the use of the resolution method for proof search, the whole
general query form is negated and converted to clauses, i.e., disjunctions of lit-
erals (positive or negative atoms). We will call the clauses stemming from the
question statement question clauses.
3.3
Top Level of the Algorithm
Calculating conﬁdences for question answering requires, at least, the ability to
calculate (a) the decreasing conﬁdence of a conjunction of clauses as performed
by the resolution and paramodulation rule, (b) the increasing conﬁdence of a
disjunction of clauses for cumulating evidence, (c) the decreasing conﬁdence of
considering negative evidence for a clause.
While the systems based on, say, Bayes networks and Markov logic, perform
these operations in a combined manner, our framework will split the whole search
into separate phases for each. First we perform a modiﬁed resolution search we
call c-resolution calculating the decreasing conﬁdence and potentially giving a
large number of diﬀerent answers and proofs. Next we will combine the diﬀerent
proofs using the cumulation operation. Finally we will collect negative evidence
for all the answers obtained so far, separately for each individual answer. The
latter search is also split into the c-resolution phase and the cumulating phase.
Since we assume the use of full FOL, the c-resolution search will not necessar-
ily terminate, thus we will use a time limit. The top level of the algorithm is
presented in the following section as Algorithm 1.

512
T. Tammet et al.
Algorithm 1 CONFER algorithm
Input: Common sense knowledge base KB, question Q, time limit t.
Output: Set of answers R with attached conﬁdences.
1: Let R={}.
2: Find
a
set
of
initial
positive
answers
with
conﬁdences
and
dependencies
IPA={⟨A1, c1, L1⟩, ..., ⟨Ap, cp, Lp⟩} for Q from KB using c-resolution with the time
limit t/2.
3: Calculate a set of cumulative positive answers CPA={⟨B1, d1, E1⟩, ..., ⟨Br, dr, Er⟩}
from IPA.
4: Let i = 1.
5: while i <= r do
6:
Form the negated question NQi from ¬Q with a substition s given by Bi
7:
Find a set of initial negative answers Ni with conﬁdences and dependencies for
NQi from KB using c-resolution with the time limit t/(2 ∗r).
8:
if Ni is empty then
9:
Let nci = 0.
10:
else
11:
Calculate the cumulative negative conﬁdence nci from Ni.
12:
end if
13:
Add a pair ⟨Bi, (ci −nci)⟩to R.
14:
Let i = i + 1.
15: end while
16: For each pair ⟨Bi, di⟩, ⟨Bj, dj⟩in R where i ̸= j, Bi = Bj and di >= dj, remove
Bj : dj from R.
17: Remove from R all elements ⟨Bi, di⟩where di <= 0.
18: return the set of answers with conﬁdences R.
3.4
C-Resolution
The core part of the algorithm described above is c-resolution: a relatively sim-
ple modiﬁcation of the resolution method calculating and keeping track of the
(multiplied) conﬁdences of premisses of each step along with the union of their
dependencies.
Deﬁnition 1 (C-Resolution). A modiﬁcation of the resolution method com-
puting an ever-increasing set of diﬀerent proofs for diﬀerent answers (substi-
tutions to the question clauses) while employing the relevance ﬁlter (deﬁnition
2), performing basic conﬁdence calculation for resolution steps (deﬁnition 3),
assigning the union of the dependency lists of premisses to each derived clause,
restricting subsumption to c-subsumption (deﬁnition 5) and restricting simpliﬁ-
cation steps according to c-subsumption.
Inconsistencies. A KB with a nontrivial structure may contain inconsistencies
in the sense that a contradiction can be derived from the KB. Looking at existing
KBs mentioned earlier, we observe that they either are already inconsistent (for
example, the largest FOL version of OpenCyc [30] in TPTP [40] is inconsistent)
or would become inconsistent in case intuitively valid inequalities are added,

Conﬁdences for Commonsense Reasoning
513
for example, inequalities of classes such as “a cat is not a dog”, “a male is
not a female” or default rules such as “birds can ﬂy”, “dead birds cannot ﬂy”,
“penguins cannot ﬂy”. We note that several large existing KBs do not contain
such inequalities explicitly, although they are necessary for nontrivial question
answering under the open-world assumption.
Since classical FOL allows to derive anything from a contradiction, it is
clearly unsuitable for a large subset of KB-s. Two possible ways of overcoming
this issue are: (a) using some version of relevance logic or other paraconsistent
logics or (b) deﬁning a ﬁlter for eliminating irrelevant classical proofs. We argue
that despite a lot of theoretical work in the area, only little work has been done
in automated proving for relevance logic, thus using it directly is likely to create
signiﬁcant complexities. Instead, we introduce a simple relevance ﬁlter:
Deﬁnition 2 (Relevance Filter). Each resolution derivation of a contradic-
tion not containing any answer clauses is discarded.
Since a standard resolution derivation of a contradiction does not lead to any
further derivations, this ﬁlter is completeness-preserving in the sense that all
resolution derivations containing an answer clause are still found.
Conﬁdences of Derived Clauses. We take the approach of (a) providing a
simple sensible baseline algorithm for calculating conﬁdences of derived clauses,
and (b) leaving open ways to modify this algorithm for speciﬁc cases as need
arises. We will use a single rational number in the range 0...1 as a measure of a
conﬁdence of a clause, with 1 standing for perfect conﬁdence and 0 standing for
no information. Conﬁdence of an atomic clause not holding is represented as a
conﬁdence of the negation of the clause.
As a baseline we use the standard approach of computing uncertainties of
clauses derived from independent parent clauses A and B as:
P(A ∧B) = P(A) ∗P(B)
Notice that for dependent parent clauses this formula under-estimates the con-
ﬁdence of the result.
Deﬁnition 3 (Basic Conﬁdence Calculation for Resolution Steps). For
binary resolution and paramodulation steps, the conﬁdence of a result is obtained
by multiplying the conﬁdences of the premises. For the factorization step, the
conﬁdence of the result is the conﬁdence of the premise, unchanged. Question
clauses have a conﬁdence 1.
A simple example employing forward reasoning (concretely, negative ordered
resolution):
0.8:: bird(tweety).
0.9:: bird(X) => canfly(X).
0.7:: canfly(X) => fast(X).
1.0:: fast(X) => answer(X).

514
T. Tammet et al.
leads to a sequential derivation of
0.72:: canfly(tweety).
0.504:: fast(tweety).
0.504:: answer(tweety).
Recall that the conﬁdences are assumed to be lower bounds of probabili-
ties. Notice that the possible dependence of the premises could be taken into
account, as in the following section for cumulative evidence. This would result
in higher conﬁdence numbers for derivations with dependent premises. Consider
the following example:
0.9:: bird(X) => canfly(X).
0.1:: -bird(X) => canfly(X).
Using the basic calculation step we can derive that anything can ﬂy:
0.09:: canfly(X). However, since anything is either a bird or is not a bird, the
conﬁdence of canfly(X) should be at least 0.1, and possibly higher, depending
on the ratio of birds to non-birds.
Generally, we can use the minimization operation leading to a higher conﬁ-
dence value than the multiplication of the conﬁdences of premises in the follow-
ing special case. The standard resolution inference rule used by a large class of
automated reasoners is deﬁned as
A1 ∨A2 ∨... ∨An
¬B1 ∨B2 ∨... ∨Bm
(A2 ∨... ∨An ∨B2 ∨... ∨Bm)σ
where σ is the most general uniﬁer of A1 and B1. A clause A subsumes a clause
B if the literals of Aδ are a subset of literals of B for some substitution δ.
Deﬁnition 4 (Extended Conﬁdence Calculation for Resolution Steps).
If (A2 ∨... ∨An)σ subsumes (B2 ∨... ∨Bm)σ in the resolution inference deﬁned
above then the conﬁdence of the result is the minimum of the conﬁdences of
premises.
C-Subsumption and Simpliﬁcations. Since standard subsumption used by
resolution provers to clean up search space may remove clauses with a higher
conﬁdence or fewer dependencies than the subsuming clause, it may cause the
prover to lose derivations potentially leading to a higher conﬁdence. Thus we
use c-subsumption instead of the standard subsumption:
Deﬁnition 5 (C-Subsumption).
A triple T1 = ⟨A1, c1, L1⟩consisting
of a clause A1, conﬁdence c1 and a dependency list L1 c-subsumes a triple
T2 = ⟨A2, c2, L2⟩if and only if A1 subsumes A2, c1 ≥c2 and L1 ⊆L2.
We can prove the following lemma:
Lemma 1 (C-Subsumption Preserves Completeness).
When a
c-resolution proof can be found without using subsumption, it can be also found
with c-subsumption.

Conﬁdences for Commonsense Reasoning
515
The proof holds for strategies of resolution for which standard subsumption is
complete for ordinary proof search without conﬁdences.
We restrict the simpliﬁcation operations like demodulation and subsuming
resolution accordingly: a derivation step must keep the original premiss P if the
result has a lower conﬁdence or a longer list of dependencies than P.
3.5
Cumulative Conﬁdence
We will now look at the situation with additional evidence for the derived answer.
In our context, using additional evidence is possible if a clause C can be derived
in diﬀerent ways, giving two diﬀerent derivations d1 and d2 with conﬁdences c1
and c2. In case the derivations d1 and d2 are independent, we could apply the
standard formula
P(A ∨B) = P(A) + P(B) −P(A ∧B)
to c1 and c2 to calculate the cumulative conﬁdence for C.
What would it mean for derivations to be “independent”? In the context
of commonsense reasoning we cannot expect to have an exact measure of in-
dependence. However, suppose the derivations d1 and d2 consist of exactly the
same initial clauses, but used in a diﬀerent order. In this case c1 = c2 and the
cumulative conﬁdence should intuitively be also just c1: no additional evidence
is provided. On the other hand, in case that the non-question input clauses of
d1 are d2 are mutually disjoint, then the derivations are also independent (as-
suming all the input clauses are mutually independent), and we should apply
the previous rule for P(A ∨B) for computing the cumulative conﬁdence.
We will estimate the independence i of two derivations d1 and d2 simply as
1 −number of shared input clauses of d1 and d2
total number of input clauses in d1 and d2
(1)
Thus, if no clauses are shared between d1 and d2, then i = 1 and if all the clauses
are shared, then i = 0.
In addition, we also know that it is highly unlikely that all the input clauses
are mutually independent. Again, lacking a realistic way to calculate the depen-
dencies, we give a heuristic estimate h in the range 0...1 to the overall indepen-
dence of the input clause set, where 1 stands for total independence and 0 for
total dependence.
Finally, we will calculate the overall independence of two derivations d1 and
d2 as i ∗h. Next, we will postulate a heuristic rule for the combination of these
two independence measures as follows.
Deﬁnition 6 (Conﬁdence Calculation for Cumulative Evidence). Given
two derivations d1 and d2 of the search result C with conﬁdences c1 and c2,
calculate the updated conﬁdence of C as
max(c1 + c2 ∗i ∗h, c1 ∗i ∗h + c2) −c1 ∗c2 ∗i ∗h
where

516
T. Tammet et al.
– independence of derivations i is deﬁned as 1 above,
– h is the heuristic estimate of the independence of the total set of input clauses
from 1 for total independence to 0 for total dependence.
The formula satisﬁes the following intuitive requirements for cumulative ev-
idence:
– If d1 and d2 do not share non-question input clauses and all the input clauses
are mutually independent, i∗h = 1 and the formula turns into c1 +c2 −(c1 ∗
c2).
– If d1 and d2 have the same non-question input clauses or the total set of
input clauses is mutually totally dependent, i ∗h = 0 and the formula turns
into max(c1, c2).
3.6
Negative Evidence
Recall the standard mechanism employed in FOL provers for ﬁnding concrete
answers: transforming existentially quantiﬁed goal clauses to clauses containing a
special answer predicate and treating clauses containing only answer predicates
as actual answers to the question found.
Once negation is present, the reasoning system using the CONFER frame-
work has to attempt to ﬁnd both positive and negative evidence for any potential
answer. This cannot be easily done in a single proof search run.
Observe that giving a general search question containing variables like
bird(X) ∨answer(X) may produce a diﬀerent set of answers than the positive
question ¬bird(X) ∨answer(X). Also observe that the potential set of answers
may be huge for both positive and negative answers: in a large KB there may
be millions of statements about birds and our reasoning system will be able to
derive only a small fraction of potential answers in any given time slot. Thus,
even if negative evidence is potentially derivable for some positive answer, the
system is unlikely to ﬁnd it.
A reasonable solution to this problem is to run the searches for negative evi-
dence only for the concrete instances of positive answers found. More concretely,
we conduct additional proof search for the negations of two types of questions
Q: (a) If Q contains no existentially quantiﬁed variables, is the statement ¬Q
true? (b) For all i vectors of values C1i, ..., Cni found for existentially bound vari-
ables X1, ...Xn in Q making Q true, is ¬Q true when we substitute the values in
C1i, ..., Cni for corresponding variables in Q?. The ﬁnal conﬁdence of an answer
to Q is calculated by subtracting from the conﬁdence of the positive answer the
conﬁdence of the answer to the corresponding negated instance of the question.
Using negative evidence may lead to unexpected results. Consider the fol-
lowing trivial example in the ProbLog syntax:
0.5::bird(a). 0.5::not bird(a). query(bird(a)).
CONFER gives us conﬁdence 0, which we interpret as “no information”, not as
“false”. However, ProbLog2 gives conﬁdence 0.25, which is explained by one of

Conﬁdences for Commonsense Reasoning
517
the authors in private correspondence thus: an atom (head) is satisﬁed if any of
the rules that make it true ﬁre and none of the rules that make it false ﬁre. In
this example ProbLog2 gets 0.5 ∗(1 −0.5) = 0.25. On the other hand, the three
diﬀerent algorithms of the Alchemy 2 system – MC-SAT explained in [12], exact
and approximate probabilistic theorem proving explained in [11] – give answers
0.015, 0 and 0.082, respectively. To be concrete, we are using the Alchemy 2
versions from [2]. For this and the following Alchemy 2 examples we prepared
an MLN ﬁle with no weights and a training data ﬁle with some generated facts
for each example. Then we ran the learnwts program with default parameters,
which created the MLN ﬁle with weights for each example.
Next, consider a previous example augmented with the “birds ﬂy” rule:
0.5::bird(a).
0.5::not bird(a).
0.9:: flies(X) :- bird(X).
query(flies(_)).
Here CONFER gives us 0.45, which is inconsistent with the result of the previ-
ous example. ProbLog2, on the other hand, gives 0.225, which is unintuitive, but
consistent with the unintuitive result of ProbLog2 in the previous example. The
three algorithms of Alchemy 2 mentioned above give us 0.047, 0 and 0.98. The
issue arising in this example is similar to nonmonotonic reasoning like default
logic: adding negative evidence to being a bird should block previously deriv-
able facts. We know that since FOL is not decidable, such checks would make
derivation steps generally not computable. As a ﬁnal twist to the example we
augment the ruleset by giving more details about the distribution:
0.5::bird(a).
0.5::not bird(a).
0.9:: flies(X) :- bird(X).
0.1:: not flies(X) :- bird(X).
%% 0.1:: flies(X) :- not bird(X). %% commented out
0.9:: not flies(X) :- not bird(X).
query(flies(_)).
Here CONFER gives us an acceptable 0.014 (positive evidence 0.490 and
negative evidence 0.476), while ProbLog2 gives 0.2025. The results of Alchemy 2
are 0.047, 0 and 0.976. Adding the rule we have commented out makes CONFER
to give -0.008 while ProbLog2 complains that the example is not acceptable.
Alchemy 2 gives us 0.056, 0 and 0.509.
4
Implementation and Experimental Results
The ﬁrst author has implemented the CONFER framework as an extended
version of his high-performance open-source automated reasoning system gkc
[39] for FOL, performing fairly well in the yearly CASC competition for au-
tomated reasoners [36], see http://www.tptp.org/CASC/. The implementation
is written in C like gkc. The compiled executable can be downloaded from
http://logictools.org/confer/ along with a number of examples.
Several algorithms, strategies and optimizations present in the gkc system are
currently switched oﬀ, due to the need for additional modiﬁcations and testing.

518
T. Tammet et al.
In particular, parallel processing is switched oﬀ, as well as the crucial algorithms
for selecting a list of suitable search strategies and performing search by batches
with iteratively increasing time limits.
Importantly, we have not yet implemented any specialized strategies for using
the attached conﬁdences and dependencies for directing and optimizing search.
It is clear that the added information gives ample potential opportunities for
directing the search.
We will give an overview of the experiments with the implementation in two
sections. First we will look at the conﬁdences calculated and compare these,
where possible, with the values given by ProbLog2 and Alchemy 2. Next we will
look at the performance of the system on nontrivial problems.
The inputs and outputs for the CONFER implementation and the systems
compared to are given on the web page http://logictools.org/confer/. The set of
examples given contains over 30 case studies and can be run using the command-
line implementation provided on the same web page as a single executable ﬁle.
The implementation is self-contained, not dependent on other systems or exter-
nal libraries. It should run on any 64-bit Linux system.
4.1
Comparing Conﬁdences
We will compare the conﬁdences calculated by CONFER on small selected ex-
amples with these of ProbLog2 and Alchemy 2. The ﬁrst two are presented in the
ProbLog2 tutorial. When CONFER can perform neither cumulation nor collec-
tion of evidence, the values calculated are the same as of ProbLog2. The cumula-
tion operation of CONFER produces, as expected, slightly diﬀerent values than
ProbLog2 or Alchemy 2. For the following examples the overall independence
estimate h is assigned 1 (maximum). Since the principles of handling negative
evidence are fundamentally diﬀerent between the two systems, this operation
causes the most signiﬁcant changes. It is worth noticing that more often than
not, the results of ProbLog2 and Alchemy 2 also diﬀer.
First, a simple version of the well-known social networks of smokers example
in the ProbLog syntax. CONFER uses a diﬀerent syntax, but the clauses and
conﬁdences given are exactly the same. We have also built the corresponding
data- and rulesets for Alchemy 2, which uses a fairly diﬀerent input method
than CONFER or ProbLog.
0.8::stress(ann).
0.4::stress(bob).
0.6::influences(ann,bob).
0.2::influences(bob,carl).
smokes(X) :- stress(X).
smokes(X) :- influences(Y,X), smokes(Y).
query(smokes(carl)).
For this example, ProbLog2 gives an answer 0.1376 and CONFER gives
0.1201, cumulating values 0.096 and 0.08. The three diﬀerent algorithms of
Alchemy 2 – MC-SAT inference (see [12]), exact and approximate lifted inference
explained in [11] – give 0.135, 0 and 0.741, respectively. In the following tables we

Conﬁdences for Commonsense Reasoning
519
will refer to these three as Alch i, Alch e and Alch a. Removing the input clause
0.4::stress(bob) also removes the cumulation possibility and both CONFER
and ProbLog2 give 0.096 as an answer.
Next, the well-known earthquake example. CONFER performs both cumu-
lation and collecting negative evidence.
person(john).
person(mary).
0.7::burglary.
0.2::earthquake.
0.9::alarm :- burglary, earthquake.
0.8::alarm :- burglary, \+earthquake.
0.1::alarm :- \+burglary, earthquake.
0.8::calls(X) :- alarm, person(X).
0.1::calls(X) :- \+alarm, person(X).
evidence(calls(john),true).
evidence(calls(mary),true).
query(burglary).
query(earthquake).
We will present the ProbLog2 and CONFER results with both the positive
and negative evidence components (columns CONFER + and CONFER -) given
by CONFER. Importantly, by default CONFER will try to ﬁnd up to 10 diﬀerent
proofs: increasing or decreasing these limits has a noticeable eﬀect on the results
as well as running time.
query
CONFER CONFER + CONFER - Problog Alch i Alch e
Alch a
burglary
0.8713
0.97650
0.1051
0.9819 0.709
0 0.905095
earthquake
0.1648
0.8854
0.7206
0.2268 0.204
0
0.888
Finally we bring the famous penguin example from default logic. We will
formulate it using conﬁdences instead of defaults. We state that penguins form
a tiny subset of birds. The CONFER implementation collects both positive and
negative evidence, but there are no cumulation possibilities.
1.0::bird(tweety).
1.0::penguin(pennie).
1.0:: bird(X) :- penguin(X).
0.001:: penguin(X) :- bird(X).
0.9:: flies(X) :- bird(X).
1.0:: not flies(X) :- penguin(X).
query(flies(_)).
query
CONFER CONFER + CONFER - Problog
Alch i Alch e Alch a
ﬂies(pennie)
-0.1
0.9
1.0
0 0.00001
0
0
ﬂies(tweety)
0.899
0.9
0.001
0.8991
0.064
0
0.873

520
T. Tammet et al.
4.2
Performance
We will investigate the performance of our CONFER implementation on the
following nontrivial example FOL problems from the TPTP collection [40]. Due
to restrictions in the language or the principles of the search algorithm, ProbLog2
cannot handle any of these examples even if they are converted to clauses in
ProbLog syntax. Thus we will compare the performance of the CONFER system
on several modiﬁcations of the problems against the conventional FOL prover
gkc used as a base for building the CONFER system.
The results are given for the following problems with the TPTP identiﬁer
and ratings: 0 means all the provers tested by the TPTP maintaners ﬁnd a
proof, 1 means no prover manages to ﬁnd a proof. Steamroller (PUZ031+1,
rating 0) is a puzzle without equality. Dreadbury (PUZ001+2.p, rating 0.23) is a
puzzle using also equality. Lukasiewicz (LCL047-1.p, rating 0) is an example in
logical calculi. Commonsense reasoning problems from CYC are taken from the
largest consistent CYC version in TPTP: CSR025+5, CSR035+5,CSR045+5,
CSR055+5 (ratings 0.67, 0.83, 0.97, 0.87).
The CYC problems CSR025+5 . . . CSR055+5 contain ca half a million for-
mulae, but the proofs are relatively short. The ﬁrst three problems are relatively
small, but their proofs are signiﬁcantly longer. The Steamroller, Dreadbury and
the CYC CSR035+5 problems have been augmented with a question asking for
answer substitutions, while for the other CYC problems and the Lukasiewicz
problems the conjectures do not contain the existence quantiﬁer, thus we just
try to prove these. For comparison purposes the CONFER proof searches are
restricted to ﬁnding only the ﬁrst answer (thus no cumulation is possible) and
not collecting negative evidence.
We consider both the versions of problems with all clauses assigned a conﬁ-
dence between 0.6 . . . 0.99 cyclically with a step 0.01 (column CONFER in the
following table) and all the conﬁdences assigned 1.0 (column CONFER 1.0). It
is important to note that the CONFER system uses conventional subsumption
and simpliﬁcation for clauses with the conﬁdence 1.0, i.e. in the “CONFER 1”
column proof search is reduced to the ordinary resolution search. The gkc col-
umn gives the pure search time of the gkc prover used as a base for building the
CONFER system, for the original TPTP versions (without a question of sub-
stitutions being asked). As a special case, variations 0 . . . 4 of the Lukasiewicz
problem are formed by attaching conﬁdences below 1 to respectively 1 . . . 4 input
clauses and letting other conﬁdences have value 1.0. (the Lukasiewicz problem
consists of ﬁve clauses, one of these being the clause to be proved).
The columns CONFER . . . “gkc pure” contain the pure proof search time in
seconds using negative ordered resolution for all the problems except CYC and
the set of support resolution for CYC. The gkc column gives the pure search
time for the gkc prover used as a base for building the CONFER system, for the
original TPTP versions (without a question of substitutions being asked). Pure
search time does not include printing, parsing and clausifying the problem and
indexing the formed clauses. The ﬁnal column “gkc full” gives full wall clock
time for gkc.

Conﬁdences for Commonsense Reasoning
521
Problem
CONFER CONFER 1.0 gkc pure gkc full
Steamroller
0.0018
0.0015
0.001
0.06
Dreadbury
0.0017
0.0011
0.001
0.06
Lukasz 0
0.0916
0.093
0.22
Lukasz 1
0.913
Lukasz 2
23
Lukasz 3
19
Lukasz 4
16
CSR025+5
0.0004
0.0001
0.0001
4.5
CSR035+5
0.0001
0.0001
0.07
4.6
CSR045+5
3.418
1.4
1.3
5.8
CSR055+5
0.0001
0.0001
0.0001
4.5
We can observe that the conﬁdence and dependency collecting calculations
along with the restricted c-subsumption do not have a noticeable eﬀect on per-
formance for most of these problems. However, adding conﬁdences below 1 to
the Lukasziewicz problem do incur a signiﬁcant penalty, which – surprisingly
– diminishes somewhat when all the clauses have such conﬁdences. The conﬁ-
dences incur a noticeable penalty to CSR045+5, which has the longest proof
among our CYC examples. Our hypotheses is that for these examples the c-
subsumption along with restricted simpliﬁcation changes the direction of the
search signiﬁcantly.
5
Summary and Future Work
We have presented a novel framework CONFER along with the implementation
for reasoning with approximate conﬁdences for full, unrestricted ﬁrst order logic.
The presented examples demonstrate that the conﬁdences found by our imple-
mentation are similar to the conﬁdences found by the leading probabilistic Prolog
and Markov logic implementations ProbLog2 [18] and Alchemy 2 [1]. CONFER
is based on conventional ﬁrst order theorem proving theory and algorithms not
requiring saturation, diﬀerently from the systems using weighted ground satu-
ration of FOL formulas like ProbLog2 and Alchemy 2. We have shown that this
enables the CONFER implementation to eﬃciently solve large nontrivial FOL
problems with attached conﬁdences.
We plan to continue work on the CONFER implementation in several di-
rections: ﬁnding and removing bugs, improving the functionality and devising
search strategies specialized for the FOL formulas with associated conﬁdences.
We expect to integrate machine learning approaches, in particular using seman-
tic similarities for reasoning with analogies and estimating the relevance of input
clauses for proof search guidance. The goal of this work is creating a practically
usable component for logic-based question answering from large commonsense
knowledge bases.

522
T. Tammet et al.
References
1. Alchemy 2 system. https://code.google.com/archive/p/alchemy-2/
2. Alchemy 2 system repository. https://github.com/PhDP/alchemy2
3. Bachmair, L., Ganzinger, H.: Resolution theorem proving. In: Robinson, A.,
Voronkov, A. (eds.) Handbook of Automated Reasoning, vol. I, ch. 2. pp. 19–99.
Elsevier (2001)
4. Baltag, A., Smets, S.: Keep changing your beliefs, aiming for the truth. Erkenntnis
75(2), 255–270 (2011)
5. Beltagy, I., Chau, C., Boleda, G., Garrette, D., Erk, K., Mooney, R.: Montague
meets Markov: Deep semantics with probabilistic logical form. In: Diab, M., Bald-
win, T., Baroni, M. (eds.) Proc. of *SEM’12 – the 2nd Joint Conference on Lexical
and Computational Semantics. pp. 11–21. Association for Computational Linguis-
tics (2013)
6. Buchanan, B., Shortliﬀe, E.: Rule-Based Expert Systems: The MYCIN Experi-
ments of the Stanford Heuristic Programming Project. Addison Wesley (1984)
7. Chalier, Y., Razniewski, S., Weikum, G.: Joint reasoning for multi-faceted common-
sense knowledge. CoRR abs/2001.04170 (2020), https://arxiv.org/abs/2001.04170
8. Conesa, J., Storey, V., Sugumaran, V.: Usability of upper level ontologies: The case
of ResearchCyc. Data and Knowledge Engineering 69(4), 343–356 (2010)
9. de Salvo Braz, R., Amir, E., Roth, D.: Lifted ﬁrst-order probabilistic inference. In:
Kaelbling, L.P., Saﬃotti, A. (eds.) Proc. of IJCAI’05 – the 19th Intl. Joint Conf.
on Artiﬁcial intelligence. pp. 1319–1325. Professional Book Center (2005)
10. Domingos, P.: The Master Algorithm: How the Quest for the Ultimate Learning
Machine Will Remake Our World. Basic Books (2015)
11. Domingos, P., Gogate, V.: Probabilistic theorem proving. In: Cozman, F., Pfeﬀer,
A. (eds.) Proc. of UAI’11 – the 27th Conf. on Uncertainty in Artiﬁcial Intelligence.
pp. 256–265. AUAI (2011)
12. Domingos, P., Kok, S., Poon, H., Richardson, M., Singla, P.: Unifying logical and
statistical AI. In: Cohn, A. (ed.) Proc. of AAAI’06 – the 21st National Conf. on
Artiﬁcial Intelligence. pp. 2–9. AAAI (2006)
13. Domingos, P.M. amd Kok, S., Lowd, D., Poon, H., Richardson, M., Singla, P.:
Markov Logic. In: De Raedt, L., Frasconi, P., Kersting, K., Muggleton, S. (eds.)
Probabilistic Inductive Logic Programming: Theory and Applications. LNCS,
vol. 4911, pp. 92–117. Springer (2008)
14. Dong, X., Gabrilovich, E., Heitz, G., Horn, W., Lao, N., Murphy, K., Strohmann,
T., Sun, S., Zhang, W.: Knowledge vault: a Web-scale approach to probabilistic
knowledge fusion. In: Macskassy, S.A., Perlich, C., Leskovec, J., Wang, W., Ghani,
R. (eds.) Proc. of KDD’14 – the 20th ACM SIGKDD Intl. Conf. on Knowledge
Discovery and Data Mining. pp. 601–610. ACM (2014)
15. Draheim, D., Tammet, T.: From sensors to Dempster-Shafer theory and back:
The axiom of ambiguous sensor correctness and its applications. In: Hartmann, S.,
K¨ung, J., Kotsis, G., Tjoa, A.M., Khalil, I. (eds.) Proc. of DEXA’2020 – the 31st
Intl. Conf. on Database and Expert Systems Applications. LNCS, vol. 12391, pp.
3–19. Springer (2020)
16. Draheim, D.: Generalized Jeﬀrey Conditionalization – A Frequentist Semantics of
Partial Conditionalization. Springer (2017)
17. Ferrucci, D.A.: Introduction to “This is Watson”. IBM Journal of Research and
Development 56(3.4), 1–15 (2012)

Conﬁdences for Commonsense Reasoning
523
18. Fierens, D., den Broeck, V., G., Renkens, J., Shterionov, D., Gutmann, D., Thon,
I., Janssens, G., De Raedt, L.: Inference and learning in probabilistic logic pro-
grams using weighted Boolean formulas. Theory and Practice of Logic Program-
ming 15(3), 358–401 (2015)
19. Formato, F., Gerla, G., Sessa, M.: Similarity-based uniﬁcation. Fundamenta Infor-
maticae 41(4), 393–414 (2000)
20. Furbach, U., Kr¨amer, T., Schon, C.: Names are not just sound and smoke: Word
embeddings for axiom selection. In: Fontaine, P. (ed.) Proc. of CADE’2019 – the
27th Intl. Conf. on Automated Deduction. LNCS, vol. 11716, pp. 250–268. Springer
(2019)
21. Green, C.: Theorem proving as a basis for question-answering systems. Machine
Intelligence 4, 183–205 (1969)
22. H´ajek, A.: Interpretations of Probability. In: Stanford Encyclopedia of Philosophy
(2019), https://plato.stanford.edu/entries/probability-interpret/
23. Kalyanpur, A., Breloﬀ, T., Ferrucci, D.A., Lally, A., Jantos, J.: Braid: Weav-
ing symbolic and statistical knowledge into coherent logical explanations. CoRR
abs/2011.13354 (2020), https://arxiv.org/abs/2011.13354
24. Khot, T., Balasubramanian, N., Gribkoﬀ, E., Sabharwal, E., Clark, P., Etzioni,
O.: Exploring Markov Logic Networks for question answering. In: M`arquez, L.,
Callison-Burch, C., Su, J. (eds.) Proc. of EMNLP’2015 – the 2015 Conference on
Empirical Methods in Natural Language Processing. pp. 685–694. Association for
Computational Linguistics (2015)
25. Lenat, D., Prakash, M., Shepherd, M.: Using common sense knowledge to overcome
brittleness and knowledge acquisition bottlenecks. AI Magazine 6(4), 65–85 (1985)
26. Marcus, G.: The next decade in AI: four steps towards robust artiﬁcial intelligence.
CoRR abs/2002.06177 (2020), https://arxiv.org/abs/2002.06177
27. Mitchell, T., Cohen, W., Hruschka, E., Talukdar, P., Yang, B., Betteridge, J., Carl-
son, A., Dalvi, B., Gardner, M., Kisiel, B.: Never-ending learning. Communications
of the ACM 61(5), 103–115 (2018)
28. Pileggi, S.F.: Web of similarity. Journal of Computational Science 36(100578), 1–7
(2019)
29. Problog2. https://dtai.cs.kuleuven.be/problog/
30. Ramachandran, D., Reagan, P., Goolsbey, K.: First-orderized researchcyc: Expres-
sivity and eﬃciency in a common-sense ontology. In: AAAI workshop on contexts
and ontologies: theory, practice and applications. pp. 33–40 (2005)
31. Reiter, R.: A logic for default reasoning. Artiﬁcial Intelligence 13(1–2), 81–132
(1980)
32. Richardson, M., Domingos, P.: Markov Logic Networks. Machine Learning 62(1–2),
107–136 (2006)
33. Romero, J., Razniewski, S., Pal, K., Pan, J.Z., Sakhadeo, A., Weikum, G.: Com-
monsense properties from query logs and question answering forums. In: Zhu, W.,
Tao, D., Cheng, X., Cui, P., Rundensteiner, E.A., Carmel, D., He, Q., Yu, J.X.
(eds.) Proc. of CIKM’19 – the 28th ACM Intl. Conf. on Information and Knowledge
Management. pp. 1411–1420. ACM (2019)
34. Sato, T.: Generative modeling by PRISM. In: Hill, P.M., Warren, D.S. (eds.) Proc.
ICLP’2009 – the 25th Intl. Conf. on Logic Programming. LNCS, vol. 5649, pp.
24–35. Springer (2009)
35. Speer, R., Chin, J., Havasi, C.: ConceptNet 5.5: An open multilingual graph of
general knowledge. In: Singh, S.P., Markovitch, S. (eds.) Proc. of AAAI’2017 – the
31st AAAI Conf. on Artiﬁcial Intelligence. pp. 4444–4451. AAAI (2017)

524
T. Tammet et al.
36. Sutcliﬀe, G.: The CADE ATP system competition – CASC. AI Magazine 37(2),
99–101 (2016)
37. Sutcliﬀe, G., Yerikalapudi, A., Trac, S.: Multiple answer extraction for question
answering with automated theorem proving systems. In: Lane, H.C., Guesgen,
H.W. (eds.) Proc. of FLAIRS’22 – the 22nd Intl. Florida Artiﬁcial Intelligence
Research Society Conference. AAAI (2009)
38. Tammet, T.: Completeness of resolution for deﬁnite answers. Journal of Logic and
Computation 5(4), 449–71 (1995)
39. Tammet, T.: GKC: A reasoning system for large knowledge bases. In: Fontaine, P.
(ed.) Proc. of CADE’2019 – the 27th Intl. Conf. on Automated Deduction. LNCS,
vol. 11716, pp. 538–549. Springer (2019)
40. TPTP homepage. http://www.tptp.org
41. Zadeh, L.: Fuzzy logic. Computer 21(4), 94–102 (1988)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Neural Precedence Recommender
Filip Bártek1,2
and Martin Suda1
1 Czech Institute of Informatics, Robotics and Cybernetics
2 Faculty of Electrical Engineering
Czech Technical University in Prague, Czech Republic
{filip.bartek,martin.suda}@cvut.cz
Abstract. The state-of-the-art superposition-based theorem provers for ﬁrst-or-
der logic rely on simpliﬁcation orderings on terms to constrain the applicability
of inference rules, which in turn shapes the ensuing search space. The popular
Knuth-Bendix simpliﬁcation ordering is parameterized by symbol precedence—a
permutation of the predicate and function symbols of the input problem’s signa-
ture. Thus, the choice of precedence has an indirect yet often substantial impact
on the amount of work required to complete a proof search successfully.
This paper describes and evaluates a symbol precedence recommender, a machine
learning system that estimates the best possible precedence based on observations
of prover performance on a set of problems and random precedences. Using the
graph convolutional neural network technology, the system does not presuppose
the problems to be related or share a common signature. When coupled with the
theorem prover Vampire and evaluated on the TPTP problem library, the recom-
mender is found to outperform a state-of-the-art heuristic by more than 4 % on
unseen problems.
Keywords: saturation-based theorem proving · simpliﬁcation ordering · symbol
precedence · machine learning · graph convolutional network
1
Introduction
Modern saturation-based Automatic Theorem Provers (ATPs) such as E [34], SPASS
[40], or Vampire [21] employ the superposition calculus [4,24] as their underlying in-
ference system. Integrating the ﬂavors of resolution [5], paramodulation [30], and the
unfailing completion [3], superposition is a powerful calculus with native support for
equational reasoning. The calculus is parameterized by a simpliﬁcation ordering on
terms and uses it to constrain the applicability of inferences, with a signiﬁcant impact
on performance.
Both main classes of simpliﬁcation orderings used in practice, the Knuth-Bendix
ordering [19] and the lexicographic path ordering [16], are speciﬁed with the help of
a symbol precedence, an ordering on the signature symbols. While the superposition
calculus is refutationally complete for any simpliﬁcation ordering [4], the choice of the
precedence has a signiﬁcant impact on how long it takes to solve a given problem.
It is well known that giving the highest precedence to the predicate symbols in-
troduced as sub-formula names during clausiﬁcation [25] can immediately make the
saturation produce the exponential set of clauses that the transformation is designed to
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliffe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5_30
525–542, 2021.

526
F. Bártek, M. Suda
avoid [29]. Also, certain orderings help to make the superposition a decision procedure
on speciﬁc fragments of ﬁrst-order logic (see, e.g., [11,14]). However, the precise way
by which the choice of a precedence inﬂuences the follow-up proof search on a general
problem is extremely hard to predict.
Several general-purpose precedence generating schemes are available to ATP users,
such as the successful invfreq scheme in E [33], which orders the symbols by the
number of occurrences in the input problem. However, experiments with random prece-
dences indicate that the existing schemes often fail to come close to the optimum prece-
dence [28], suggesting room for further improvements.
In this work, we propose a machine learning system that learns to predict for an
ATP whether one precedence will lead to a faster proof search on a given problem than
another. Given a previously unseen problem, it can then be asked to recommend the best
possible precedence for an ATP to run with. Relying only on the logical structure of the
problems, the system generalizes the knowledge about favorable precedences across
problems with different signatures.
Our recommender uses a relational graph convolutional neural network [32] to rep-
resent the problem structure. It learns from the ATP performance on selected problems
and pairs of randomly sampled precedences. This information is used to train a symbol
cost model, which then realizes the recommendation by simply sorting the problem’s
symbols according to the obtained costs.
This work strictly improves on our previous experiments with linear regression
models and simple hand-crafted symbol features [6] and is, to the best of our knowl-
edge, the ﬁrst method able to propose good symbol precedences automatically using a
non-linear transformation of the input problem structure.
The rest of this paper is organized as follows. Section 2 exposes the basic termi-
nology used throughout the remaining sections. Section 3 proposes a structure of the
precedence recommender that can be trained on pairs of symbol precedences, as de-
scribed in Sect. 4. Section 5 summarizes and discusses experiments performed using an
implementation of the precedence recommender. Section 6 compares the system pro-
posed in this work with notable related works. Section 7 concludes the investigation
and outlines possible directions for future research.
2
Preliminaries
2.1
Saturation-Based Theorem Proving
A ﬁrst-order logic (FOL) problem consists of a set of axiom formulas and a conjec-
ture formula. In a refutation-based automated theorem prover (ATP), proving that the
axioms entail the conjecture is reduced to proving that the axioms together with the
negated conjecture entail a contradiction. The most popular ﬁrst-order logic (FOL) au-
tomated theorem provers (ATPs), such as Vampire [21], E [34], or SPASS [40], start the
proof search by converting the input FOL formulas to an equisatisﬁable representation
in clause normal form (CNF) [25,13]. We denote the problem in clause normal form
(CNF) as P = (Σ, Cl), where Σ is a list of all non-logical (predicate and function)
symbols in the problem called the signature, and Cl is the set of clauses of the problem
(including the negated conjecture).

Neural Precedence Recommender
527
Given a problem P in CNF, a saturation-based ATP searches for a refutational proof
by iteratively applying the inference rules from the given calculus to infer new clauses
entailed by Cl. As soon as the empty clause, denoted by □, is inferred, the prover
concludes that the premises entail the conjecture. The sequence of those inferences
leading up from the input clauses Cl to the discovered □constitutes a proof. If the
premises do not entail the conjecture, the proof search continues until the set of inferred
clauses is saturated with respect to the inference rules. In the standard setting of time-
restricted proof search, a time limit may end the process prematurely.
Since the space of derivable clauses is typically very large, the efﬁcacy of the prover
depends on the order in which the inferences are applied. The standard saturation-based
ATPs order the inferences by maintaining two classes of inferred clauses: processed and
unprocessed [34]. In each iteration of the saturation loop, one clause (so-called given
clause) is combined with all the processed clauses for inferences. The resulting new
clauses and the given clause are added to the unprocessed set and the processed set,
respectively. Finishing the proof in few iterations of the saturation loop is important
because the number of inferred clauses typically grows exponentially during the proof
search.
2.2
Superposition Calculus
The superposition calculus is of particular interest because it is used in the most suc-
cessful contemporary FOL ATPs. A simpliﬁcation ordering on terms [4] constrains the
inferences of the superposition calculus.
The simpliﬁcation ordering on terms inﬂuences the superposition calculus in two
ways. First, the inferences on each clause are limited to the selected literals. In each
clause, either a negative literal or all maximal literals are selected. The maximality is
evaluated according to the simpliﬁcation ordering. Second, the simpliﬁcation ordering
orients some of the equalities to prevent superposition and equality factoring from in-
ferring redundant complex conclusions. In each of these two roles, the simpliﬁcation
ordering may impact the direction and, in effect, the length of the proof search.
The Knuth-Bendix ordering (KBO) [19], a commonly used simpliﬁcation ordering
scheme, is parameterized by symbol weights and a symbol precedence, a permutation3
of the non-logical symbols of the input problem. In this work, we focus on the task
of ﬁnding a symbol precedence which leads to a good performance of an ATP when
plugged into the Knuth-Bendix ordering (KBO), leaving all the symbol weights at the
default value 1 as set by the ATP Vampire.
2.3
Neural Networks
A feedforward artiﬁcial neural network [12] is a directed acyclic graph of modules.
Each module is an operation that consumes a numeric (input) vector and outputs a
numeric vector. Each of the components of the output vector is called a unit of the
3 The deﬁnition of KBO does not require the precedence to be total. However, for use in ATPs,
the more symbols and thus also terms we can compare, the better.

528
module. The output of each module is differentiable with respect to the input almost
everywhere.
The standard modules include the fully connected layer, which performs an afﬁne
transformation, and non-linear activation functions such as the Rectiﬁed Linear Unit
(ReLU) or sigmoid.4 A fully connected layer with a single unit is called the linear unit.
Some of the modules are parameterized by numeric parameters. For example, the
fully connected layer that transforms the input x by the afﬁne transformation Wx+b is
parameterized by the weight matrix W and the bias vector b. If the output of a module
is differentiable with respect to a parameter, that parameter is considered trainable.
In a typical scenario, the neural network is trained by gradient descent on a training
set of examples. In such a setting, the network outputs a single numeric value called
loss when evaluated on a batch of examples. The loss of a batch is typically computed
as a weighted sum of the losses of the individual examples. Since each of the modules is
differentiable with respect to its input and trainable parameters, the gradient of the loss
with respect to all trainable parameters of the neural network can be computed using the
back-propagation algorithm [12]. The trainable parameters are then updated by taking
a small step against the gradient—in the direction that is expected to reduce the loss.
An epoch is a sequence of iterations that updates the trainable parameters using each
example in the training set exactly once.
A graph convolutional network (GCN) is a special case of feedforward neural net-
work. The modules of a GCN transform messages that are passed along the edges of
a graph encoded in the input example. A particular architecture of a GCN used promi-
nently in this work is discussed in Sect. 3.2.
3
Architecture
A symbol precedence recommender is a system that takes a CNF problem P = (Σ, Cl)
as the input, and produces a precedence π∗over the symbols Σ as the output. For the
recommender to be useful, it should produce a precedence that likely leads to a quick
search for a proof. In this work, we use the number of iterations of the saturation loop
as a metric describing the effort required to ﬁnd a proof.
The recommender described in this section ﬁrst uses a neural network to compute a
cost value for each symbol of the input problem, and then orders the symbols by their
costs in a non-increasing order. In this manner, the task of ﬁnding good precedences is
reduced to the task of training a good symbol cost function, as discussed in Sect. 4.
The recommender consists of modules that perform speciﬁc sub-tasks, each of
which is described in detail in one of the following sections (see also Fig. 1).
3.1
Graph Constructor: From CNF to Graphs
As the ﬁrst step of the recommender processing pipeline, the input problem is converted
from a CNF representation to a heterogeneous (directed) graph [41]. Each of the nodes
of the graph is labeled with a node type, and each edge is labeled with an edge type,
4 These are, respectively, f(x) = max{0, x} and g(x) =
1
1+e−x .
F. Bártek, M. Suda

Neural Precedence Recommender
529
Precedence 
Loss function
Precedence 
Problem P
Graph constructor
Graph
GCN
Symbol embeddings
Output layer
Symbol costs
Sort
Precedence *
Loss value
Fig. 1. Recommender architecture overview. When recommending a precedence, the input is
problem P and the output is precedence π∗. When training, the input is problem P and prece-
dences π and ρ, and the output is the loss value. The trainable modules and the edges along which
the loss gradient is propagated are emphasized by bold lines.
deﬁning the heterogeneous nature of the graph. Each node corresponds to one of the
elements that constitute the CNF formula, such as a clause, an atom, or a predicate
symbol. Each such category of elements corresponds to one node type. The edges rep-
resent the (oriented) relations between the elements, for example, the incidence relation
between a clause and one of its (literals’) atoms, or the relation between an atom and
its predicate symbol. R denotes the set of all relations in the graph. Figure 2 shows the
types of nodes and edges used in our graph representation. Figure 3 shows an example
of a graph representation of a simple problem.
The graph representation exhibits, namely, the following properties:
– Lossless: The original problem can be faithfully reconstructed from the correspond-
ing graph representation (up to logical equivalence).
– Signature agnostic: Renaming the symbols and variables in the input problem yields
an isomorphic graph.
– For each relation r ∈R, its inverse r−1 is also present in the graph, typicallyrep-
resented by a different edge type.
– The polarity of the literals is expressed by the type of the edge (pos or neg)
connecting the respective atom to the clause it occurs in.
– For every non-equality atom and term, the order of its arguments is captured by a
sequence of argument nodes chained by edges [27].
– The two operands of equality are not ordered. This reﬂects the symmetry of equal-
ity.
– Sub-expression sharing [8,26,27]: Identical atoms and terms share a node represen-
tation.
3.2
GCN: From Graphs to Symbol Embeddings
For each symbol in the input problem P, we seek to ﬁnd a vector representation, i.e., an
embedding, that captures the symbol’s properties that are relevant for correctly ranking
the symbol in the symbol precedences over P.

530
problem
clause
 contains 
non-equality atom
 pos 
 neg 
equality atom
 pos 
 neg 
variable
 binds 
predicate
 atom_applies
argument
 atom_has 
term
 equalizes 
 equalizes 
 precedes 
 is 
 is 
 term_has 
function
 term_applies 
Fig. 2. CNF graph schema
The symbol embeddings are output by a relational graph convolutional network
(R-GCN) [32], which is a stack of graph convolutional layers. Each layer consists of
a collection of differentiable modules—one module per edge type. The computation
of the GCN starts with assigning each node an initial embedding and then iteratively
updates the embeddings by passing them through the convolutional layers.
The initial embedding h(0)
a
of a node a is a concatenation of two vectors: a feature
vector speciﬁc for that node (typically empty) and a trainable vector shared by all nodes
of the same type. In our particular implementation, feature vectors are used in nodes
that correspond to clauses and symbols. Each clause node has a feature vector with
a one-hot encoding of the role of the clause, which can be either axiom, assumption,
or negated conjecture [38,36]. Each symbol node has a feature vector with two bits of
data: whether the symbol was introduced into the problem during preprocessing (most
notably during clausiﬁcation), and whether the symbol appears in a conjecture clause.
One pass through the convolutional layer updates the node embeddings by passing
a message along each of the edges. For an edge of type r ∈R going from source node s
to destination node d at layer l, the message is composed by converting the embedding
of the source node h(l)
s
using the module associated with the edge type r. In the simple
case that the module is a fully connected layer with weight matrix W (l)
r
and bias vector
b(l)
r , the message is W (l)
r h(l)
s + b(l)
r . Each message is then divided by the normalization
constant cs,d =

|N rs |

|N r
d | [18], where N r
a is the set of neighbors of node a under
the relation r.
Once all messages are computed, they are aggregated at the destination nodes to
form new node embeddings. Each node d aggregates all the incoming messages of a
given edge type r by summation, then passes the sum through an activation function
F. Bártek, M. Suda

Neural Precedence Recommender
531
problem
a=b  f(a,b)f(b,b)
clause
a=b
clause
f(a,b)f(b,b)
equality atom
a=b
 pos 
equality atom
f(a,b)=f(b,b)
 neg 
term
a
term
b
term
f(a,b)
term
f(b,b)
function
f
argument
1
argument
1
function
a
function
b
argument
2
argument
2
Fig. 3. Graph representation of the CNF formula a = b ∧f(a, b) ̸= f(b, b)
σ such as the ReLU, and ﬁnally aggregates the messages across the edge types by
summation, yielding the new embedding h(l+1)
d
.
The following formula captures the complete update of the embedding of node d by
layer l:
h(l+1)
d
=

r∈R
σ
⎛
⎝
s∈N r
d
1
cs,d
(W (l)
r h(l)
s + b(l)
r )
⎞
⎠
3.3
Output Layer: From Symbol Embeddings to Symbol Costs
The symbol cost of each symbol is computed by passing the symbol’s embedding
through a linear output unit, which is an afﬁne transformation with no activation func-
tion.
It is possible to use a more complex output layer in place of the linear unit, e.g.,
a feedforward network with one or more hidden layers. Our experiments showed no
signiﬁcant improvement when a hidden layer was added, likely because the underlying
GCN learns a sufﬁciently complex transformation.
Let θ denote the vector of all parameters of the whole neural network consist-
ing of the GCN and the output unit. Given an input problem P with signature Σ =
(s1, . . . , sn), we denote the cost of symbol si predicted by the network as c(i, P; θ).
In the rest of this text, we refer to the predicted cost of si simply as c(i) because the
problem P and the parameters θ are ﬁxed in each respective context.

532
3.4
Sort: From Symbol Costs to Precedence
The symbol precedence heuristics commonly used in the ATPs sort the symbols by
some numeric syntactic property that is inexpensive to compute, such as the number
of occurrences in the input problem, or the symbol arity. In our precedence recom-
mender, we sort the symbols by their costs c produced by the neural network described
in Sects. 3.2 and 3.3. An advantage of this scheme is that sorting is a fast operation.
Moreover, as we show in Sect. 4, it is possible to train the underlying symbol costs
by gradient descent.
4
Training Procedure
In Sect. 3 we described the structure of a recommender system that generates a symbol
precedence for an arbitrary input problem. The efﬁcacy of the recommender depends
on the quality of the underlying symbol cost function c. In theory, the symbol cost
function can assign the costs so that sorting the symbols by their costs yields an opti-
mum precedence. This is because, at least in principle, all the information necessary to
determine the optimum precedence is present in the graph representation of the input
problem thanks to the lossless property of the graph encoding. Our approach to deﬁning
an appropriate symbol cost function is based on statistical learning from executions of
an ATP on a set of problems with random precedences.
To train a useful symbol cost function c, we deﬁne a precedence cost function C
using the symbol cost function c in a manner that ensures that minimizing C corre-
sponds to sorting the symbols by c. Finding a precedence that minimizes C can then be
done efﬁciently and precisely. We proceed to train C on the proxy task of ranking the
precedences.
4.1
Precedence Cost
We extend the notion of cost from symbols to precedences by taking the sum of the
symbol costs weighted by their positions in the given precedence π:
C(π) = Zn
n

i=1
i · c(π(i))
Zn =
2
n(n+1) is a normalization factor that ensures the commensurability of prece-
dence costs across signature sizes. More precisely, normalizing by Zn makes the ex-
pected value of the precedence cost on a given problem independent of the problem’s
signature size n, provided the expected symbol cost Ei[c(i)] does not depend on n:
Eπ[C(π)] = Eπ

Zn
n

i=1
i · c(π(i))
	
= Zn
n

i=1
i · Eπ[c(π(i))]
= Zn

 n

i=1
i

Ei[c(i)] =
2
n(n + 1)
n(n + 1)
2
Ei[c(i)] = Ei[c(i)]
F. Bártek, M. Suda

Neural Precedence Recommender
533
When C is deﬁned in this way, the precedence produced by the recommender (see
Sect. 3.4) minimizes C.
Lemma 1. The precedence cost C is minimized by any precedence that sorts the sym-
bols by their costs in non-increasing order:
argmin
ρ
C(ρ) = argsort−(c(1), . . . , c(n))
where argminρ C(ρ) is the set of all precedences that minimize precedence cost C for
a given symbol cost c, and argsort−(x) is the set of all permutations π that sort vector
x in non-increasing order (xπ(1) ≥xπ(2) ≥. . . ≥xπ(n)).
Proof. We prove direction “argminρ C(ρ) ⊆argsort−(c(1), . . . , c(n))” by contradic-
tion. Let π minimize C and let π not sort the costs in non-increasing order. Then there
exist k < l such that c(π(k)) < c(π(l)). Let ¯π be a precedence obtained from π by
swapping the elements k and l. Then we obtain
C(¯π) −C(π)
Zn
= kc(¯π(k)) + lc(¯π(l)) −kc(π(k)) −lc(π(l))
= kc(π(l)) + lc(π(k)) −kc(π(k)) −lc(π(l))
= k(c(π(l)) −c(π(k))) −l(c(π(l)) −c(π(k)))
= (k −l)(c(π(l)) −c(π(k)))
< 0
The ﬁnal inequality is due to k −l < 0 and c(π(l)) −c(π(k)) > 0. Clearly, Zn > 0 for
any n ≥0. Thus, C(¯π) < C(π), which contradicts the assumption that π minimizes C.
To prove the other direction of the equality, ﬁrst observe that all precedences π
that sort the symbol costs in a non-increasing order necessarily have the same prece-
dence cost C(π). Since ∅̸= argminρ C(ρ) ⊆argsort−(c(1), . . . , c(n)), each of
the precedences in argsort−(c(1), . . . , c(n)) has the cost minρ C(ρ). It follows that
argsort−(c(1), . . . , c(n)) ⊆argminρ C(ρ).
⊓⊔
4.2
Learning to Rank Precedences
Our ultimate goal is to train the precedence cost function C so that it is minimized by
the best precedence, measuring the quality of a precedence by the number of iterations
of the saturation loop taken to solve the problem.
Approaching this task directly, as a regression problem, runs into the difﬁculty of
establishing sensible target cost values for the precedences in the training dataset, es-
pecially when a wide variety of input problems is covered. Approaching the task as
a binary classiﬁcation of precedences seems possible, but it is not clear which prece-
dences should be a priori labeled as positive and which as negative, to give a guarantee
that a precedence minimizing the precedence cost (i.e. the one obtained by sorting)
would be among the best in any good sense.
We cast the task as an instance of score-based ranking problem [23,7] by training
a classiﬁer to decide which of a pair of precedences is better based on their costs. We

534
train the classiﬁer in a way that ensures that better precedences are assigned lower costs.
The motivation for learning to order pairs of precedences is that it allows learning on
easy problems, and that it may allow the system to generalize to precedences that are
better than any of those seen during training.
Training Data. Each training example has the form (P, π, ρ), where P = (Σ, Cl) is
a problem and π, ρ are precedences over Σ such that the prover using π solves P in
fewer iterations of the saturation loop than with ρ, denoted as π ≺P ρ.
Loss Function. Let (P, π, ρ) be a training example (π ≺P ρ). The precedence cost
classiﬁes this example correctly if C(π) < C(ρ), or alternatively S(π, ρ) = C(ρ) −
C(π) > 0. We approach this problem as an instance of binary classiﬁcation with the
logistic loss [23], a loss function routinely used in classiﬁcation tasks in machine learn-
ing:
ℓ(P, π, ρ) = −log sigmoid S(π, ρ) = −log sigmoid(C(ρ) −C(π))
= −log sigmoid Zn
n

i=1
i(c(ρ(i)) −c(π(i)))
Note that the classiﬁer cannot simply train S to output a positive number on all pairs
of precedences because S is deﬁned as a difference of two precedence costs. Intuitively,
by training on the example (P, π, ρ) we are pushing C(π) down and C(ρ) up.
The loss function is clearly differentiable with respect to the symbol costs, and the
symbol cost function c is differentiable with respect to its trainable parameters. This
enables the use of gradient descent to ﬁnd the values of the parameters of c that locally
minimize the loss value.
Figure 1 shows how the loss function is plugged into the recommender for training.
5
Experimental Evaluation
To demonstrate the capacity of the trainable precedence recommender described in
Sects. 3 and 4, we performed a series of experiments. In this section, we describe the de-
sign and conﬁguration of the experiments, and then compare the performance of several
trained models to a baseline heuristic.
The scripts that were used to generate the training data and to train and evaluate the
recommender are available online.5
5.1
Environment
System. All experiments were run on a computer with the CPU Intel Xeon Gold 6140
(72 cores @ 2.30 GHz) and 383 GiB RAM.
5 https://github.com/filipbartek/vampire-ml/tree/cade28
F. Bártek, M. Suda

Neural Precedence Recommender
535
Solver. The empirical evaluation was performed using a modiﬁed version of the ATP
Vampire 4.3.0 [21]. The prover was used to generate the training data and to evalu-
ate the trained precedence recommender. To generate the training data, Vampire was
modiﬁed to output CNF representations of the problems and annotated problem signa-
tures in a machine-readable format. For the evaluation of the precedences generated by
the recommender, Vampire was modiﬁed to allow the user to supply explicit predicate
and function symbol precedences for the proof search (normally, the user only picks a
precedence generation heuristic). The modiﬁed version of Vampire is available online.6
We run Vampire with a ﬁxed strategy7 and a time limit of 10 seconds. To increase the
potential impact of predicate precedences, we used a simple transﬁnite Knuth-Bendix
ordering (TKBO) [22,20] that compares atoms according to the predicate precedence
ﬁrst, using the regular KBO to break ties between atoms and to compare terms (using
the Vampire option --literal_comparison_mode predicate).
5.2
Dataset Preparation
The training data consists of examples of the form (P, π, ρ), where P is a CNF problem
and π, ρ are precedences of symbols of problem P such that out of the two precedences,
π yields a proof in fewer iterations of the saturation loop (see Sect. 2.1).
Since the TKBO never compares a predicate symbol with a function symbol, two
separate precedences can be considered for each problem: a predicate precedence and a
function precedence. We trained a predicate precedence recommender separately from
a function precedence recommender to simplify the training process and to isolate the
effects of the predicate and function precedences. This section describes how the train-
ing data for the case of training a predicate precedence recommender was generated.
Data for training the function precedence recommender was generated analogously.
Base Problem Set. The input problems were assumed to be speciﬁed in the CNF or the
ﬁrst-order form (FOF) fragment of the TPTP language [36]. FOF problems were ﬁrst
converted into equisatisﬁable CNF problems by Vampire.
We used the problem library TPTP v7.4.0 [36] as the source of problems for training
and evaluation of the recommender. We denote the set of all problems available for
training and evaluation as P0 (|P0| = 17 053).
Node Feature Extraction. In addition to the signature and the structure of the prob-
lem, some metadata was extracted from the input problem to allow training a more
efﬁcient recommender. First, each clause was annotated with its role in the problem,
which could be either axiom, assumption, or negated conjecture. Second, each sym-
bol was annotated with two bits of data: whether the symbol was introduced into the
problem during preprocessing, and whether the symbol appeared in a conjecture clause.
This metadata was used to construct the initial embeddings of the respective nodes in
the graph representation of the problem (see Sect. 3.2).
6 https://github.com/filipbartek/vampire/tree/cade28
7 Saturation algorithm: DISCOUNT, age to weight ratio: 1:10, AVATAR [39]: disabled, literal
comparison mode: predicate; all other options left at their default values.

536
Examples Generation. The examples were generated by an iterative sampling of P0.
In each iteration, a problem P ∈P0 was chosen and Vampire was executed twice on
P with two (uniformly) random predicate precedences and one common random func-
tion precedence. The “background” random function precedence served as additional
noise (in addition to the variability contained in TPTP) and made sure that the predicate
precedence recommender would not be able to rely on any speciﬁcity that would come
from ﬁxing function precedences in the training data.
The two executions were compared in terms of performance: the predicate prece-
dence π was recognized as better than the predicate precedence ρ, denoted as π ≺P ρ,
if the proof search ﬁnished successfully with π and if the number of iterations of the
saturation loop with π was smaller than with ρ. If one of the two precedences was
recognized as better, the example (P, π, ρ) would be produced, where π was the better
precedence, and ρ was the other precedence. Otherwise, for example, if the proof search
timed out on both precedences, we would go back to sampling another problem.
To ensure the efﬁciency of the sampling, we interpreted the process as an instance
of the Bernoulli multi-armed bandit problem [37], with the reward of a trial being 1 in
case an example is produced, and 0 otherwise.
We employed adaptive sampling to balance exploring problems that have been tried
relatively scarcely and exploiting problems that have yielded examples relatively often.
For each problem P ∈P0, the generator kept track of the number of times the problem
has been tried nP , and the number of examples generated from that problem sP . The ra-
tio sP
nP corresponded to the average reward of problem P observed so far. The problems
were sampled using the allocation strategy UCB1 [1] with a parallelizing relaxation.
First, the values of nP and sP for each problem P were bootstrapped by sampling
the problem a number of times equal to a lower bound on the ﬁnal value of nP (at least
1).8 In each subsequent iteration, the generator sampled the problem P that maximized
sP
nP +

2 ln n
nP , where n = 
P ∈P0 nP was the total number of tries on all problems.
The parallelizing relaxation means that the sP values were only updated once in 1000
iterations, allowing up to 2000 parallel solver executions.
The sampling continued until 1 000 000 examples were generated when training
a predicate precedence recommender, or 800 000 examples in the case of a function
precedence recommender. For example, while generating 1 000 000 examples for the
predicate precedence dataset, 5349 out of the 17 053 problems yielded at least one ex-
ample, while the least explored problem was tried 19 times, and the most exploited
problem 504 times.
Validation Split. The 17 053 problems in P0 were ﬁrst split roughly in half to form the
training set and the validation set. Next, both training and validation sets were restricted
to problems whose graph representation consisted of at most 100 000 nodes to limit the
memory requirements of the training. Approximately 90 % of the problems ﬁt into this
limit and there were 7648 problems in the resulting validation set Pval. The training
8 The number of tries each problem was bootstrapped with is n0 = ⌈
2 log N
(1+

2 log N|P0|
N
)2 ⌉, where
N is the ﬁnal number of examples to be generated. For example, if N = 1 000 000 and
|P0| = 17 053, then n0 = 10.
F. Bártek, M. Suda

Neural Precedence Recommender
537
set Ptrain was further restricted to problems that correspond to at least one training ex-
ample, resulting in 2571 problems when training a predicate precedence recommender,
and 1953 problems when training a function precedence recommender.
5.3
Hyperparameters
We used a GCN described in Sect. 3.2 with depth 4, message size 16, ReLU activation
function, skip connections [41], and layer normalization [2]. We tuned the hyperparam-
eters by a small manual exploration.
5.4
Training Procedure
A symbol cost model was trained by gradient descent on the precedence ranking task
(see Sect. 4.2) using the examples generated from Ptrain. To avoid redundant com-
putations, all examples generated from any given problem were processed in the same
training batch. Thus, each training batch contained up to 128 problems and all examples
generated from these problems. The symbol cost model was trained using the Adam op-
timizer [17]. The learning rate started at 1.28 × 10−3 and was halved each time the loss
on Ptrain stagnated for 10 consecutive epochs.
The examples were weighted. Each of the examples of problem P contributed to the
training with the weight
1
sP , where sP was the number of examples of problem P in
the training set. This ensured that each problem contributed to the training to the same
degree irrespective of the relative number of examples.
We continued the training until the validation accuracy stopped increasing for 100
consecutive epochs.
5.5
Final Evaluation
After the training ﬁnished, we performed a ﬁnal evaluation of the most promising in-
termediate trained model on the whole Pval. The model that manifested the best solver
performance on a sample of 1000 validation problems was taken as the most promising.
5.6
Results
A predicate precedence recommender was trained on approximately 500 000 exam-
ples, and a function precedence recommender was trained on approximately 400 000
examples. For each problem P ∈Pval, a predicate and a function precedences were
generated by the respective trained recommender, and Vampire was run using these
precedences with a wall clock time limit of 10 seconds. The results are averaged over 5
runs to reduce the effect of noise due to the wall clock time limit. As a baseline, the per-
formance of Vampire with the frequency precedence heuristic9 was evaluated with
the same time limit. For comparison, the two trained recommenders were evaluated sep-
arately, with the predicate precedence recommender using the frequency heuristic
to generate the function precedences, and vice versa.
9 This is Vampire’s analogue of the invfreq scheme in E [33].

538
To generate a precedence for a problem, the recommender ﬁrst converts the prob-
lem to a machine-friendly CNF format, then converts the CNF to a graph, then predicts
symbol costs using the GCN model and ﬁnally orders the symbols by their costs to pro-
duce the precedence. To simplify the experiment, the time limit of 10 seconds was only
imposed on the Vampire run, excluding the time taken by the recommender to generate
the precedence. When run with 2 threads, the preprocessing of a single problem took
at most 1.26 seconds for 80 % of the problems by extrapolation from a sample of 1000
problems.10 Table 1 shows the results of the ﬁnal evaluation.
Table 1. Results of the evaluation of symbol precedence heuristics based on various symbol cost
models on Pval (|Pval| = 7648). Means and standard deviations over 5 runs are reported. The
GCN models were trained according to the description in Sects. 3 to 5. The model Simple is
the ﬁnal linear model from our previous work [6]. The models that used machine learning only
for the predicate precedence used the frequency heuristic for the function precedence, and
vice versa. The frequency model uses the standard frequency heuristic for both predicate and
function precedence.
Symbol cost model
Successes on Pval Improvement over baseline
Mean
Std
Absolute Relative
GCN (predicate and function) 3951.6 1.62
+182.0 1.048
GCN (predicate only)
3923.6 2.24
+154.0 1.041
GCN (function only)
3874.2 1.83
+104.6 1.028
Simple (predicate only)
3827.2 1.94
+57.6 1.015
Frequency (baseline)
3769.6 3.07
0.0 1.000
The results show that the GCN-based model outperformed the frequency heuris-
tic by a signiﬁcant margin. Since the predicate precedence recommender was trained
with randomly distributed function precedences, it was expected to perform well irre-
spective of the function precedence heuristic it is combined with, and conversely. Com-
bining the trained recommenders for predicate and function precedences manifested
better performance than any of the two in combination with the standard frequency
heuristic, outperforming the frequency heuristic by approximately 4.8 %.
We have conﬁrmed our earlier conjecture [6] that using a graph neural network
(GNN) may outperform the “simple” linear predicate precedence heuristic trained in
[6].11
6
Related Work
Our previous text [6] marked the initial investigation of applying techniques of machine
learning to generating good symbol precedences. The neural recommender presented
here uses a GNN to model symbol costs, while [6] used a linear combination of symbol
features readily available in the ATP Vampire. The GNN-based approach yields more
performant precedences at the cost of longer training and preprocessing time.
10 The remaining 20 % of the problems either ﬁnished preprocessing within 5 seconds, or were
omitted from preprocessing due to exceeding the node count limit.
11 The measurements presented in Table 1 are not directly comparable with those reported in [6]
due to differences in the validation problem sets and the computation environments.
F. Bártek, M. Suda

Neural Precedence Recommender
539
In [26], [15] and [27], the authors propose similar GNN architectures to solve tasks
on FOL problems. They use the GNNs to solve classiﬁcation tasks such as premise
selection. While our system is trained on a proxy classiﬁcation task, the main task it is
evaluated on is the generation of useful precedences.
The problem of learning to rank objects represented by scores trainable by gradient
descent was explored in [7]. Our work can be seen to apply the approach of [7] to rank
permutations represented by weighted sums of symbol costs.
7
Conclusion and Future Work
We have described a system that extracts useful symbol precedences from the graph
representations of CNF problems. Comparison with a conventional symbol precedence
heuristic shows that using a GCN to consider the whole structure of the input problem
is beneﬁcial.
A manual analysis of the trained recommender could produce new insights into
how the choice of the symbol precedence inﬂuences the proof search, which could in
turn help design new efﬁcient precedence generating schemes. Indeed, a trained cost
model summarizes the observed behaviors of an ATP with random precedences and
is able to discover patterns in them (as we know implicitly from its accuracy) despite
their seemingly chaotic behavior as perceived by a human observer. The challenge is to
extract these patterns in a human-understandable form.
In addition to the symbol precedence, KBO is determined by symbol weights. In this
work, we keep the symbol weights ﬁxed to the value 1. Learning to recommend sym-
bol weights in addition to the precedences represents an interesting avenue for future
research.
The same applies to the idea of learning to recommend both the predicate and func-
tion precedences using a single GCN. The joint learning, although more complex to
design, could additionally discover interdependencies between the effects of function
precedence and predicate precedence on the proof search, while the current setup im-
plicitly assumes that the effects are independent. Finally, a higher training data efﬁ-
ciency could be achieved by considering all pairs of measured executions on a problem
in one training batch.
Acknowledgments
This work was generously supported by the Czech Science Foundation project no. 20-
06390Y (JUNIOR grant), the project RICAIP no. 857306 under the EU-H2020 pro-
gramme, and the Grant Agency of the Czech Technical University in Prague, grant
no. SGS20/215/OHK3/3T/37.
References
1. Auer,
P.,
Cesa-Bianchi,
N.,
Fischer,
P.:
Finite-time
analysis
of
the
multi-
armed
bandit
problem.
Machine
Learning
47(2-3),
235–256
(May
2002).
https://doi.org/10.1023/A:1013689704352

540
2. Ba, J.L., Kiros, J.R., Hinton, G.E.: Layer normalization (Jul 2016), http://arxiv.org/
abs/1607.06450
3. Bachmair, L., Derschowitz, N., Plaisted, D.A.: Completion without failure. In: Aït-
Kaci, H., Nivat, M. (eds.) Rewriting Techniques, pp. 1–30. Academic Press (1989).
https://doi.org/10.1016/B978-0-12-046371-8.50007-9
4. Bachmair,
L.,
Ganzinger,
H.:
Rewrite-based
equational
theorem
proving
with
selection
and
simpliﬁcation.
J.
Log.
Comput.
4(3),
217–247
(1994).
https://doi.org/10.1093/logcom/4.3.217
5. Bachmair, L., Ganzinger, H.: Resolution theorem proving. In: Robinson and Voronkov [31],
pp. 19–99. https://doi.org/10.1016/b978-044450813-3/50004-7
6. Bártek, F., Suda, M.: Learning precedences from simple symbol features. In: Fontaine et al.
[10], pp. 21–33, http://ceur-ws.org/Vol-2752/paper2.pdf
7. Burges, C., Shaked, T., Renshaw, E., Lazier, A., Deeds, M., Hamilton, N., Hullender, G.:
Learning to rank using gradient descent. In: ICML 2005 - Proceedings of the 22nd Interna-
tional Conference on Machine Learning. pp. 89–96. ACM Press, New York, New York, USA
(2005). https://doi.org/10.1145/1102351.1102363
8. Chvalovský, K., Jakub˚uv, J., Suda, M., Urban, J.: ENIGMA-NG: Efﬁcient neural and
gradient-boosted inference guidance for E. In: Fontaine [9]. https://doi.org/10.1007/978-3-
030-29436-6_12
9. Fontaine, P. (ed.): Automated Deduction - CADE 27, LNCS, vol. 11716. Springer, Cham
(2019). https://doi.org/10.1007/978-3-030-29436-6
10. Fontaine, P., Korovin, K., Kotsireas, I.S., Rümmer, P., Tourret, S. (eds.): Joint Proceedings
of the 7th Workshop on Practical Aspects of Automated Reasoning (PAAR) and the 5th
Satisﬁability Checking and Symbolic Computation Workshop (SC-Square) Workshop, 2020
co-located with the 10th International Joint Conference on Automated Reasoning (IJCAR
2020). No. 2752 in CEUR Workshop Proceedings, CEUR-WS.org, Aachen (2020), http:
//ceur-ws.org/Vol-2752
11. Ganzinger, H., de Nivelle, H.: A superposition decision procedure for the guarded fragment
with equality. In: 14th Annual IEEE Symposium on Logic in Computer Science. pp. 295–
303. IEEE Computer Society (1999). https://doi.org/10.1109/LICS.1999.782624
12. Goodfellow, I.J., Bengio, Y., Courville, A.C.: Deep Learning. Adaptive computation and
machine learning, MIT Press (2016), http://www.deeplearningbook.org/
13. Harrison, J.: Handbook of Practical Logic and Automated Reasoning. Cambridge University
Press, Cambridge (2009). https://doi.org/10.1017/CBO9780511576430
14. Hustadt, U., Konev, B., Schmidt, R.A.: Deciding monodic fragments by temporal resolution.
In: Nieuwenhuis, R. (ed.) Automated Deduction – CADE-20. LNCS, vol. 3632, pp. 204–218.
Springer, Berlin, Heidelberg (2005). https://doi.org/10.1007/11532231_15
15. Jakub˚uv, J., Chvalovský, K., Olšák, M., Piotrowski, B., Suda, M., Urban, J.: ENIGMA
Anonymous: Symbol-independent inference guiding machine (system description). In:
Peltier, N., Sofronie-Stokkermans, V. (eds.) Automated Reasoning. LNCS, vol. 12167, pp.
448–463. Springer, Cham (Jul 2020). https://doi.org/10.1007/978-3-030-51054-1_29
16. Kamin, S.N., Lévy, J.: Two generalizations of the recursive path ordering (1980), http:
//www.cs.tau.ac.il/~nachumd/term/kamin-levy80spo.pdf, unpublished
letter to Nachum Dershowitz
17. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization (Dec 2014), http://
arxiv.org/abs/1412.6980
18. Kipf, T.N., Welling, M.: Semi-supervised classiﬁcation with graph convolutional networks.
In: 5th International Conference on Learning Representations, ICLR 2017 (Sep 2017),
https://openreview.net/forum?id=SJU4ayYgl
19. Knuth, D.E., Bendix, P.B.: Simple word problems in universal algebras. In: Siekmann and
Wrightson [35], pp. 342–376. https://doi.org/10.1007/978-3-642-81955-1_23
F. Bártek, M. Suda

Neural Precedence Recommender
541
20. Kovács, L., Moser, G., Voronkov, A.: On transﬁnite Knuth-Bendix orders. In: Bjørner,
N., Sofronie-Stokkermans, V. (eds.) Automated Deduction – CADE-23. LNCS, vol. 6803,
pp. 384–399. Springer, Berlin, Heidelberg (2011). https://doi.org/10.1007/978-3-642-22438-
6_29
21. Kovács, L., Voronkov, A.: First-order theorem proving and Vampire. In: Sharygina, N., Veith,
H. (eds.) Computer Aided Veriﬁcation. LNCS, vol. 8044, pp. 1–35. Springer, Berlin, Heidel-
berg (2013). https://doi.org/10.1007/978-3-642-39799-8_1
22. Ludwig, M., Waldmann, U.: An extension of the Knuth-Bendix ordering with LPO-like
properties. In: Dershowitz, N., Voronkov, A. (eds.) Logic for Programming, Artiﬁcial In-
telligence, and Reasoning. LNCS, vol. 4790, pp. 348–362. Springer, Berlin, Heidelberg (Oct
2007). https://doi.org/10.1007/978-3-540-75560-9_26
23. Mohri, M., Rostamizadeh, A., Talwalkar, A.: Foundations of Machine Learning. MIT Press,
2 edn. (2018), https://cs.nyu.edu/~mohri/mlbook/
24. Nieuwenhuis, R., Rubio, A.: Paramodulation-based theorem proving. In: Robinson and
Voronkov [31], pp. 371–443. https://doi.org/10.1016/b978-044450813-3/50009-6
25. Nonnengart, A., Weidenbach, C.: Computing small clause normal forms. In: Robinson and
Voronkov [31], pp. 335–367. https://doi.org/10.1016/b978-044450813-3/50008-4
26. Olšák, M., Kaliszyk, C., Urban, J.: Property invariant embedding for automated reason-
ing. In: Giacomo, G.D., Catalá, A., Dilkina, B., Milano, M., Barro, S., Bugarín, A.,
Lang, J. (eds.) ECAI 2020 – 24th European Conference on Artiﬁcial Intelligence. Fron-
tiers in Artiﬁcial Intelligence and Applications, vol. 325, pp. 1395–1402. IOS Press (2020).
https://doi.org/10.3233/FAIA200244
27. Rawson, M., Reger, G.: Directed graph networks for logical reasoning (extended abstract).
In: Fontaine et al. [10], pp. 109–119, http://ceur-ws.org/Vol-2752/paper8.
pdf
28. Reger, G., Suda, M.: Measuring progress to predict success: Can a good proof strategy be
evolved? In: AITP 2017. pp. 20–21 (2017), http://aitp-conference.org/2017/
aitp17-proceedings.pdf
29. Reger, G., Suda, M., Voronkov, A.: New techniques in clausal form generation. In:
Benzmüller, C., Sutcliffe, G., Rojas, R. (eds.) GCAI 2016. 2nd Global Conference on
Artiﬁcial Intelligence. EPiC Series in Computing, vol. 41, pp. 11–23. EasyChair (2016).
https://doi.org/10.29007/dzfz
30. Robinson, G., Wos, L.: Paramodulation and theorem-proving in ﬁrst-order theories with
equality. In: Siekmann and Wrightson [35], pp. 298–313. https://doi.org/10.1007/978-3-642-
81955-1_19
31. Robinson, J.A., Voronkov, A. (eds.): Handbook of Automated Reasoning (in 2 volumes).
Elsevier and MIT Press (2001)
32. Schlichtkrull, M.S., Kipf, T.N., Bloem, P., van den Berg, R., Titov, I., Welling, M.: Modeling
relational data with graph convolutional networks. In: Gangemi, A., Navigli, R., Vidal, M.,
Hitzler, P., Troncy, R., Hollink, L., Tordai, A., Alam, M. (eds.) The Semantic Web. LNCS,
vol. 10843, pp. 593–607. Springer, Cham (2018). https://doi.org/10.1007/978-3-319-93417-
4_38
33. Schulz, S.: E 2.4 user manual. EasyChair preprint no. 2272, Manchester (2020), https:
//easychair.org/publications/preprint/8dss
34. Schulz, S., Cruanes, S., Vukmirovi´c, P.: Faster, higher, stronger: E 2.3. In: Fontaine [9], pp.
495–507. https://doi.org/10.1007/978-3-030-29436-6_29
35. Siekmann, J.H., Wrightson, G. (eds.): Springer, Berlin, Heidelberg (1983)
36. Sutcliffe, G.: The TPTP problem library and associated infrastructure. Journal of Automated
Reasoning 59(4) (Dec 2017). https://doi.org/10.1007/s10817-017-9407-7
37. Sutton, R.S., Barto, A.G.: Reinforcement Learning: An Introduction. The MIT Press, 2 edn.
(2018), http://incompleteideas.net/book/the-book-2nd.html

542
38. TPTP syntax, http://www.tptp.org/TPTP/SyntaxBNF.html
39. Voronkov, A.: AVATAR: The architecture for ﬁrst-order theorem provers. In: Biere, A.,
Bloem, R. (eds.) Computer Aided Veriﬁcation. LNCS, vol. 8559, pp. 696–710. Springer,
Cham (2014). https://doi.org/10.1007/978-3-319-08867-9_46
40. Weidenbach, C., Dimova, D., Fietzke, A., Kumar, R., Suda, M., Wischnewski, P.: SPASS
version 3.5. In: Schmidt, R.A. (ed.) Automated Deduction - CADE-22. LNCS, vol. 5663,
pp. 140–145. Springer, Berlin, Heidelberg (2009). https://doi.org/10.1007/978-3-642-02959-
2_10
41. Zhou, J., Cui, G., Zhang, Z., Yang, C., Liu, Z., Wang, L., Li, C., Sun, M.: Graph neural
networks: A review of methods and applications (Dec 2018), http://arxiv.org/abs/
1812.08434
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/
4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or
format, as long as you give appropriate credit to the original author(s) and the source, provide a
link to the Creative Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s Creative
Commons license, unless indicated otherwise in a credit line to the material. If material is not in-
cluded
in
the
chapter’s
Creative
Commons
license
and
your
intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain
permission directly from the copyright holder.
F. Bártek, M. Suda

Improving ENIGMA-style Clause Selection
Czech Technical University in Prague, Prague, Czech Republic
martin.suda@cvut.cz
Abstract. We re-examine the topic of machine-learned clause selection
guidance in saturation-based theorem provers. The central idea, recently
popularized by the ENIGMA system, is to learn a classiﬁer for recogniz-
ing clauses that appeared in previously discovered proofs. In subsequent
runs, clauses classiﬁed positively are prioritized for selection. We pro-
pose several improvements to this approach and experimentally conﬁrm
their viability. For the demonstration, we use a recursive neural network
to classify clauses based on their derivation history and the presence
or absence of automatically supplied theory axioms therein. The auto-
matic theorem prover Vampire guided by the network achieves a 41 %
improvement on a relevant subset of SMT-LIB in a real time evaluation.
Keywords: Saturation-based theorem proving · Clause Selection · Ma-
chine Learning · Recursive Neural Networks.
1
Introduction
The idea to improve the performance of saturation-based automatic theorem
provers (ATPs) with the help of machine learning (ML), while going back at
least to the early work of Schulz [8, 30], has recently been enjoying a renewed
interest. Most notable is the ENIGMA system [16,17] extending the ATP E [31]
by machine learned clause selection guidance. The architecture trains a binary
classiﬁer for recognizing as positive those clauses that appeared in previously
discovered proofs and as negative the remaining selected ones. In subsequent
runs, clauses classiﬁed positively are prioritized for selection.
A system such as ENIGMA needs to carefully balance the expressive power
of the used ML model with the time it takes to evaluate its advice. For example,
Loos et al. [22], who were the ﬁrst to integrate state-of-the-art neural networks
with E, discovered their models to be too slow to simply replace the traditional
clause selection mechanism. In the meantime, the data-hungry deep learning ap-
proaches motivate researchers to augment training data with artiﬁcially crafted
theorems [1]. Yet another interesting aspect is what features we allow the model
to learn from. One could speculate that the recent success of ENIGMA on the
Mizar dataset [7, 18] can at least partially be explained by the involved prob-
lems sharing a common source and encoding. It is still open whether some new
form of general “theorem proving knowledge” could be learned to improve the
performance of an ATP across, e.g., the very diverse TPTP library.
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5 31
Martin Suda
543–561, 2021.
while Learning From History

544
M. Suda
In this paper, we propose several improvements to ENIGMA-style clause
selection guidance and experimentally test their viability in a novel setting:
– We lay out a set of possibilities for integrating the learned advice into the
ATP and single out the recently developed layered clause selection [10,11,36]
as particularly suitable for the task.
– We speed up evaluation by a new lazy evaluation scheme under which many
generated clauses need not be evaluated by the potentially slow classiﬁer.
– We demonstrate the importance of “positive bias”, i.e., of tuning the classiﬁer
to rather err on the side of false positives than on the side of false negatives.
– Finally, we propose the use of “negative mining” for improving learning from
proofs obtained while relying on previously learned guidance.
To test these ideas, we designed a recursive neural network to classify clauses
based solely on their derivation history and the presence or absence of automati-
cally supplied theory axioms therein. This allows us to test here, as a byproduct
of the conducted experiments, whether the human-engineered heuristic for con-
trolling the amount of theory reasoning presented in our previous work [11] can
be matched or even overcome by the automatically discovered neural guidance.
The rest of the paper is structured as follows. Sect. 2 recalls the necessary
ATP theory, explains clause selection and how to improve it using ML. Sect. 3
covers layered clause selection and the new lazy evaluation scheme. In Sect. 4, we
describe our neural architecture and in Sect. 5 we bring everything together and
evaluate the presented ideas, using the prover Vampire as our workhorse and a
relevant subset of SMT-LIB as the testing grounds. Finally, Sect. 6 concludes.
2
ATPs, Clause Selection, and Machine Learning
The technology behind the modern automatic theorem provers (ATPs) for ﬁrst-
order logic (FOL), such as E [31], SPASS [40], or Vampire [21], can be roughly
outlined by using the following three adjectives.
Refutational:
The task of the prover is to check whether a given conjecture G
logically follows from given axioms A1, . . . , An, i.e. whether
A1, . . . , An |= G,
(1)
where G and each Ai are FOL formulas. The prover starts by negating the con-
jecture G and transforming ¬G, A1, . . . , An into an equisatisﬁable set of clauses
C. It then applies a sound logical calculus to iteratively derive further clauses,
logical consequence of C, until the obvious contradiction in the form of the empty
clause ⊥is derived. This refutes the assumption that ¬G, A1, . . . , An could be
satisﬁable and thus conﬁrms (1).
Superposition-based:
The most popular calculus used in this context is super-
position [3,23], an extension of ordered resolution [4] with a built-in support for
handling equality. It consists of several inference rules, such as the resolution
rule, factoring, subsumption, superposition, or demodulation.

Inference rules in general determine how to derive new clauses from old ones,
where by old clauses we mean either the initial clauses C or clauses derived pre-
viously. The clauses that need to be present for a rule to be applicable are called
the premises and the newly derived clause is called the conclusion. By applying
the inference rules the prover gradually constructs a derivation, a directed acyclic
(hyper-)graph (DAG), with the initial clauses forming the leaves and the derived
clauses (labeled by the respective applied rules) forming the internal nodes. A
proof is the smallest sub-DAG of a derivation containing the ﬁnal empty clause
and for every derived clause the corresponding inference and its premises.
Saturation-based:
A saturation algorithm is the concrete way of organizing the
process of deriving new clauses, such that every applicable inference is eventually
considered. Modern saturation-based ATPs employ some variant of the given-
clause algorithm, in which clauses are selected for inferences one by one [27].
The process employs two sets of clauses, often called the active set A and the
passive set P. At the beginning all the initial clauses are put to the passive set.
Then in every iteration, the prover selects and removes a clause C from P, inserts
it into A, and performs all the applicable inferences with premises in A such that
at least one of the premises is C. The conclusions of these inferences are then
inserted into P. This way the prover maintains (at the end of each iteration) the
invariant that inferences among the clauses in the active set have been performed.
The selected clause C is sometimes also called the “given clause”.
During a typical prover run, P grows much faster than A (the growth is
roughly quadratic). Analogously, although for diﬀerent reasons, when a proof is
discovered, its clauses constitute only a fraction of A. Notice that every clause
C ∈A that is in the end not part of the proof did not need to be selected and
represents a wasted eﬀort. This explains why clause selection, i.e. the procedure
for picking in each iteration the next clause to process, is one of the main heuristic
decision points in the prover, which hugely aﬀects its performance [32].
2.1
Traditional Approaches to Clause Selection
There are two basic criteria that have been identiﬁed as generally correlating
with the likelihood of a clause contributing to the yet-to-be discovered proof.
One is clause’s age or, more precisely, its “date of birth”, typically imple-
mented as an ever increasing timestamp. Preferring for selection old clauses to
more recently derived ones corresponds to a breadth-ﬁrst strategy and ensures
fairness. The other criterion is clause’s size, referred to as weight in the ATP
lingo, and is realized by some form of symbol counting. Preferring for selection
small clauses to large ones is a greedy strategy, based on the observation that
small conclusions typically belong to inferences with small premises and that the
ultimate conclusion—the empty clause—is the smallest of all. The best results
are achieved when these two criteria (or their variations) are combined [32].
To implement eﬃcient clause selection by numerical criteria such as age and
weight, an ATP represents the passive set P as a set of priority queues. A
queue contains (pointers to) the clauses in P ordered by its respective criterion.
Selection typically alternates between the available queues under a certain ratio.
Improving ENIGMA-style Clause Selection while Learning From History
545

546
M. Suda
A successful strategy is, for instance, to select 10 clauses by weight for every
clause selected by age, i.e., with an age-to-weight ratio of 1:10.
2.2
ENIGMA-style Machine-Learned Clause Selection Guidance
The idea to improve clause selection by learning from previous prover experience
goes, to the best of our knowledge, back to Schulz [8,30] and has more recently
been successfully employed by the ENIGMA system and others [7,15–17,22].
The experience is collected from successful prover runs, where each selected
clause constitutes a training example and the example is marked as positive, if
the clause ended-up in the discovered proof, and negative otherwise. A machine
learning (ML) algorithm is then used to ﬁt this data and produce a model M
for classifying clauses into positive and negative, accordingly. A good learning
algorithm produces a model M which not only accurately classiﬁes the training
data but also generalizes well to unseen examples. The computational costs of
both training and evaluation are also important.
While clauses are logical formulas, i.e., discrete objects forming a countable
set, ML algorithms, rooted in mathematical statistics, are primarily equipped
to dealing with ﬁxed-seized real-valued vectors. Thus the question of how to
represent clauses for the learning is the ﬁrst obstacle that needs to be overcome,
before the whole idea can be made to work. In the beginning, the authors of
ENIGMA experimented with various forms of hand-crafted numerical clause
features [16,17]. An attractive alternative explored in later work [7,15,22] is the
use of artiﬁcial neural networks, which can be understood as extracting the most
relevant features automatically.
An important distinction can in both cases be made between approaches
which have access to the concrete identity of predicate and function symbols (i.e.,
the signature) that make up the clauses, and those that do not. For example:
Is the ML algorithm allowed to assume that the symbol grp mult is used to
represent the multiplication operation in a group or does it only recognize a
general binary function? The ﬁrst option can be much more powerful, but we
need to ensure that the signature symbols are aligned and used consistently
across the problems in our benchmark. Otherwise the learned advice cannot
meaningfully cary over to previously unsolved problems. While the assumption
of aligned signature has been employed by the early systems [16, 22], the most
recent version of ENIGMA [15,24] can work in a “signature agnostic” mode.
In this work we represent clauses solely by their derivation history, deliber-
ately ignoring their logical content. Thus we do not require the assumption of
an aligned signature, per se. However, we rely on a ﬁxed set of distinguished
axioms to supply features in the derivation leaves.
2.3
Integrating the Learned Advice
Once we have a trained model M, an immediate possibility for integrating it
into the clause selection procedure is to introduce a new queue that will order
the clauses using M. Two basic versions of this idea have been described:

“Priority”:
The ordering puts all the clauses classiﬁed by M as positive before
those classiﬁed negatively. Within the two classes, older clauses are preferred.
Let us for the purposes of future reference denote this scheme M1,0. It has
been successfully used by the early ENIGMAs [7,16,17].
“Logits”:
Even models oﬃcially described as binary classiﬁers typically inter-
nally compute a real-valued estimate L of how much “positive” or “negative” an
example appears to be and only turn this estimate into a binary decision in the
last step, by comparing it against a ﬁxed threshold t, most often 0. A machine
learning term for this estimate L is the logit.1
The second version orders the clauses on the new queue by the “raw” logits
produced by a model. We denote it M−R to stress that clauses with high L are
treated as small from the perspective of the selection and therefore preferred.
This scheme has been used by Loos et al. [22] and in the latest ENGIMA [15,37].
Combining with a traditional strategy.
While it is possible to rely exclusively
on selection governed by the model, it turns out to be better [7] to combine it
with the traditional heuristics. The most natural choice is to take S, the original
strategy that was used to generate the training data, and extend it by adding
the new queue, be it M1,0 or M−R, next to the already present queues. We
then again supply a ratio under which the original selection from S and the new
selection based on M get alternated. We will denote this kind of combination
with the original strategy as S ⊕M1,0 and S ⊕M−R, respectively.
3
Layered Clause Selection and Lazy Model Evaluation
Layered clause selection (LCS) is a recently developed method [10, 11, 36] for
smoothly incorporating a categorical preference for certain clauses into a base
clause selection strategy S. In this paper, we will readily use it in combination
with the binary classiﬁer advice from a trained model M.
When we instantiate LCS to our particular case,2 its function can be sum-
marized by the expression
S ⊕S[M1].
In words, the base selection strategy S is alternated with S[M1], the same
selection scheme S but applied only to clauses classiﬁed positively by M. Implicit
here is a convention that whenever there is no positively classiﬁed passive clause,
a fallback to plain S occurs. Additionally, we again specify a “second-level” ratio
to govern the alternation between pure S and S[M1].
The main advantage of LCS, compared to the options outlined in the previous
section, is that the original, typically well-tuned, base selection mechanism S is
also applied to M1, the clauses classiﬁed positively by M.
1 A logit can be turned into a (formal) probability, i.e. a value between 0 and 1, by
passing it, as is typically done, through the sigmoid function σ(x) = 1/(1 + e−x).
2 We rely here on the monotone mode of split; there is also a disjoint mode [10].
547
Improving ENIGMA-style Clause Selection while Learning From History

548
M. Suda
3.1
Lazy Model Evaluation
It is often the case that evaluating a clause by the model M is a relatively
expensive operation [22]. As we explain here, however, this operation can be
avoided in many cases, especially when using LCS to integrate the advice.
We propose the following lazy evaluation approach to be used with S⊕S[M1].
Every clause entering the passive set P is initially inserted to both S and S[M1]
without being evaluated by M. Then, whenever (as governed by the second-level
ratio) it is the moment to select a clause from S[M1], the algorithm
1. picks (as usual, according to S) the best clause C in S[M1],
2. only then evaluates C by M, and
3. if C gets classiﬁed as negative, it forgets C, a goes back to 1.
This repeats until the ﬁrst positively classiﬁed clause is found, which is then
returned. Note that this way the “observable behaviour” of S[M1] is preserved.
The power of lazy evaluation lies in the fact that not every clause needs to be
evaluated before a proof is found. Indeed, recall the remark that the passive set
P is typically much larger than the active set A, which also holds on a typical
successful termination. Every clause left in passive at that moment is a clause
that did not need to be evaluated by M thanks to lazy evaluation.
We remark that lazy evaluation can similarly be used with the integration
mode M1,0 based on priorities.
We experimentally demonstrate the eﬀect of the technique in Sect. 5.4.
4
A Neural Classiﬁcation of Clause Derivations
In this work we choose to represent a clause, for the purpose of learning, solely by
its derivation history. Thus a clause can only be distinguished by the axioms from
which it was derived and by the precise way in which these axioms interacted
with each other through inferences in the derivation. This means we deliberately
ignore the clause’s logical content.
We decided to focus on this representation, because it promises to be fast.
Although an individual clause’s derivation history may be large, it is a sim-
ple function of its parents’ histories (just one application of an inference rule).
Moreover, before a clause with a complicated history can be selected, most of its
ancestors will have been selected already.3 This guarantees the amortised cost
of evaluating a single clause to be constant.
A second motivation comes from our recent work [11], where we have shown
that theory reasoning facilitated by automatically adding theory axioms for ax-
iomatising theories, while in itself a powerful technique, often leads the prover
to unpromising parts of the search space. We developed a heuristic for control-
ling the amount of theory reasoning in the derivation of a clause [11]. Our goal
here is to test whether a similar or even stronger heuristic can be automatically
discovered by a neural network.
3 Exceptions are caused by simplifying inferences applied eagerly outside of the gov-
ernance of the main clause selection mechanism.

Examples of axioms that Vampire uses to axiomatise theories include the
commutativity or associativity axioms for the arithmetic operations, an axiom-
atization of the theory of arrays [6] or of the theory of term algebras [20]. For us
it is mainly important that the axioms are introduced internally by the prover
and can therefore be consistently identiﬁed across individual problems.
4.1
Recursive Neural Networks
A recursive neural network (RvNN) is a network created by recursively compos-
ing a ﬁnite set of neural building blocks over a structured input [12]. A general
neural block is a function Nθ : Rk →Rl depending on a vector of parameters θ
that can be optimized during training (see below in Section 4.3).
In our case, the structured input is a clause derivation, i.e. a DAG with nodes
identiﬁed with the derived clauses. To enable a recursion, an RvNN represents
each node C by a real vector vC (of a ﬁxed dimension n) called a (learnable)
embedding. During training a network learns to embed the space of derivable
clauses into Rn in some a priori unknown, but still useful way.
We assume that each initial clause C, a leaf of the derivation DAG, is labeled
as belonging to one of the automatically added theory axioms or coming from
the user input. Let these labels form a ﬁnite set of axiom origin labels LA.
Furthermore, let the applicable inference rules that label the internal nodes of
the DAG form a ﬁnite set of inference rule labels LR. The speciﬁc building blocks
of our neural architecture are the following three (indexed families of) functions:
– for every axiom label l ∈LA, a nullary init function Il ∈Rn which to an
initial clause C labeled by l assigns its embedding vC := Il,
– for every inference rule r ∈LR, a deriv function, Dr : Rn × · · · × Rn →Rn
which to a conclusion clause Cc derived by r from premises (C1, . . . , Ck) with
embeddings vC1, . . . , vCk assignes the embedding vCc := Dr(vC1, . . . , vCk),
– and, ﬁnally, a single eval function E : Rn →R which evaluates an embedding
vC such that the corresponding clause C is classiﬁed as positive whenever
E(vC) ≥t, with the threshold t set, by default, to 0.
By recursively composing the init and deriv functions, any derived clause C
can be assigned an embedding vC and also evaluated by E to see whether the
network recommends it as positive, that should be preferred in proof search.
4.2
Architecture Details
Here we outline the details of our architecture for the beneﬁt of neural network
practitioners. All the used terminology is standard (see, e.g., [13]).
We realized each init function Il as an independent learnable vector. Similarly,
each deriv function Dr was independently deﬁned. For a rule of arity two, such
as resolution, we used:
Dr(v1, v2) = LayerNorm(y), y = W r
2 · x + br
2, x = ReLU(W r
1 · [v1, v2] + br
1),
where [·, ·] denotes vector concatenation, ReLU is the rectiﬁed linear unit non-
linearity (f(x) = max{0, x}) applied component-wise, and the learnable matrices
549
Improving ENIGMA-style Clause Selection while Learning From History

550
M. Suda
W r
1 , W r
2 and vectors br
1, br
2 are such that x ∈R2n and y ∈Rn. (We took inspira-
tion from Sandler et al. [29] for doubling the embedding size before applying the
non-linearity.) Finally, LayerNorm is a layer normalization [2] module, without
which training often became numerically unstable for deeper derivation DAGs.4
For unary inference rules, such as factoring, we used an equation analogous
to the above, except for the concatenation operation. We did not need to model
an inference rule with a variable number of premises, but one option would be
to arbitrarily “bracket” its arguments into a tree of binary applications.
Finally, the eval function was E(v) = W2 ·ReLU(W1 ·v+b)+c with trainable
W1 ∈Rn×n, b ∈Rn, W2 ∈R1×n, and c ∈R.
4.3
Training the Network
To train a network means to ﬁnd values for the trainable parameters such that
it accurately classiﬁes the training data and ideally also generalises to unseen
future cases. We follow a standard methodology for training our RvNN.
In particular, we use the gradient descent (GD) optimization algorithm (with
the Adam optimiser [19]) minimising the typical binary cross-entropy loss, com-
posed as a sum of contributions, for every selected clause C, of the form
−yC · log(σ(E(vC))) −(1 −yC) · log(1 −σ(E(vC))),
with yC = 1 for the positive and yC = 0 for the negative examples.
These contributions are weighted such that each derivation DAG (corre-
sponding to a prover run on a single problem) receives equal weight. Moreover,
within each DAG we re-scale the inﬂuence of positive versus the negative exam-
ples such that these two categories contribute evenly. The scaling is important
as our training data is highly unbalanced (cf. Sect. 5.1).
We split the available successful derivations into a training set and a valida-
tion set, and only train on the ﬁrst set using the second to observe generalisation
to unseen examples. As the GD algorithm progresses, iterating over the training
data in rounds called epochs, we evaluate the loss on the validation set and stop
the process early if this loss does not decrease for a speciﬁed period. This early
stopping criterion was important to produce a model that generalizes well.
As another form of regularisation, i.e. a technique for preventing overﬁtting
to the training data, we employ dropout [35] (independently for each “read” of
a clause embedding by one of the deriv or eval functions). Dropout means that
at training time each component vi of the embedding v has a certain probability
of being zero-ed out. This “voluntary brain damage” makes the network more
robust as it prevents neurons from forming too complex co-adaptations [35].
Finally, we experimented with using non-constant learning rates as suggested
by Smith et al. [33,34]. In the end, we used a schedule with a linear warmup for
the ﬁrst 50 epochs followed by a hyperbolic cooldown [38] (cf. Fig. 1 in Sect. 5.2).
4
We also tried to skip LayerNorm and replace ReLU by the hyperbolic tangent
function. This restores stability, but does not train or classify so well.

4.4
An Abstraction for Compression and Caching
Since our representation of clauses deliberately discards information, we end
up encountering distinct clauses indistinguishable from the perspective of the
network. For example, every initial clause C originating from the input problem
(as opposed to being added as a theory axiom) receives the same embedding
vC = Iinput. Indistinguishable clauses also arise as conclusions of an inference
that can be applied in more than one way to certain premises.
Mathematically, we deal with an equivalence relation ∼on clauses based on
“having the same derivation tree”: C1 ∼C2 ↔derivation(C1) = derivation(C2).
The “ﬁngerprint” derivation(C) of a clause could be deﬁned as a formal expres-
sion recording the derivation history of C using the labels from LA as nullary
operators and those from LR as operators with arities of the corresponding in-
ference rules. For example: Resolution(thax inverse assoc, Factoring(input)).
We made use of this equivalence in our implementation in two places:
1. When preparing the training data. We “compressed” each derivation DAG
as a factorisation by ∼, keeping only one representative of each class. A class
containing a positive example was marked as a positive example.
2. When interfacing the trained model from the ATP. We cached the embed-
dings (and evaluated logits) for the already encountered clauses under their
class identiﬁer. Sect. 5.4 evaluates the eﬀect of this technique.
5
Experiments
We implemented the infrastructure for training an RvNN clause derivation clas-
siﬁer (as described in Sect. 4) in Python, relying on the PyTorch (version 1.7)
library [25] and its TorchScript extension for interfacing the trained model from
C++. We modiﬁed the automatic theorem prover Vampire (version 4.5.1) to (1)
optionally record to a log ﬁle the constructed derivation, including information
on selected clauses and clauses found in the discovered proof (the logging-mode),
(2) to be able to load a trained TorchScript model and use it for clause selection
guidance under various modes of integration (detailed in Sects. 2.3 and 3).5
We took the same subset of 20 795 problems from the SMT-LIB library [5]
as in previous work [11]: formed as the largest set of problems in a fragment
supported by Vampire, excluding problems known to be satisﬁable and those
provable by Vampire’s default strategy in 10 s either without adding theory ax-
ioms or while performing clause selection by age only.
As the baseline strategy S we took Vampire’s implementation of the DIS-
COUNT saturation loop under the age-to-weight ratio 1:10 (which typically
performs well with DISCOUNT), keeping all other settings default, including
the enabled AVATAR architecture. We later enhanced this S with various forms
of guidance. All the benchmarking was done using a 10 s time limit.6
5 Supplementary materials can be found at https://git.io/JtHNl.
6 Running on an Intel(R) Xeon(R) Gold 6140 CPUs @ 2.3 GHz server with 500 GB
RAM, using no more than 30 of the available 72 cores to reduce mutual inﬂuence.
551
Improving ENIGMA-style Clause Selection while Learning From History

552
M. Suda
5.1
Data Preparation
During an initial run, the baseline strategy S was able to solve 734 problems
under the 10 s time limit. We collected the corresponding successful derivations
using the logging-mode (and lifting the time limit, since the logging causes a
non-negligible overhead) and processed them into a form suitable for training
a neural model. The derivations contained approximately 5.0 million clauses in
total (the overall context), out of which 3.9 million were selected7 (the training
examples) and 30 thousand of these appeared in a proof (the positive examples).
In these derivations, Vampire used 31 distinct theory axioms to facilitate theory
reasoning. Including the “user input” label for clauses coming from the actual
problem ﬁles, there were in total 32 distinct labels for the derivation leaves.
In addition, we recorded 15 inference rules, such as resolution, superposition,
backward and forward demodulation or subsumption resolution and including
one rule for the derivation of a component clause in AVATAR [26,39]. Thus we
obtained 15 distinct labels for the internal nodes.
We compressed these derivations identifying clauses with the same “abstract
derivation history” dictated by the labels, as described in Sect. 4.4. This reduced
the derivation set to 0.7 million nodes (i.e. abstracted clauses) in total. Out of
the 734 derivations 242 were still larger than 1000 nodes (the largest had 6426
nodes) and each of these gave rise to a separate “mini-batch”. We grouped the
remaining 492 derivations to obtain an approximate size of 1000 nodes per mini-
batch (the maximum was 12 original derivations grouped in one mini-batch). In
total, we obtained 412 mini-batches and randomly singled out 330 (i.e., 80 %) of
these for training, keeping 82 aside for validation.
5.2
Training
Since the size of the training set is relatively small, we instantiated the architec-
ture described in Sect. 4.2 with embedding size n = 64 and dropout probability
p = 0.3. We trained for 100 epochs, with a non-constant learning rate peaking at
α = 2.5 × 10−4 in epoch 50. Every epoch we computed the loss on the validation
set and selected the model which minimizes this quantity. This was the model
from epoch 45 in our case, which we will denote M here.
The development of the training and validation loss throughout training, as
well as that of the learning rate, is plotted in Fig. 1. Additionally, the right
side of the ﬁgure allows us to compare the validation loss—an ML estimate of
the model’s ability to generalize—with the ultimate metric of practical gener-
alization, namely the number of in-training-unseen problems solved by Vam-
pire equipped with the corresponding model for guidance.8 We can see that the
“proxy” (i.e. the minimisation of the validation loss) and the “target” (i.e. the
maximisation of ATP performance) correspond quite well, at least to the degree
that we measured the highest ATP gain with the validation-loss-minimizing M.
7 Ancestors of selected clauses are sometimes not selected clauses themselves if they
arise through immediate simpliﬁcations or through reductions.
8 Integrated using the layered scheme with a second level ratio 2:1 (cf. Sect. 5.3).

Fig. 1. Training the neural model. Red: the training (left) and validation (right) loss
as a function training time; shaded: per problem weighted standard deviations. Blue
(left): the supplied non-constant learning rate (cf. Sect. 4.3). Green (right): in training
unseen problems solved by Vampire equipped with the corresponding model.
We remark that this assurance was not cheap to obtain. While the whole
100 epoch training took 45 minutes to complete (using 20 workers and 1 master
process in a parallel training setup), each of the 20 ATP evaluation data points
corresponds to approximately 2 hours of 30 core computation.
5.3
Advice Integration
In this part of the experiment we tested the various ways of integrating the learnt
advice as described in Sects. 2.3 and 3. Let us recall that these are the single
queue schemes M−R and M1,0 based on the raw logits and the binary decision,
respectively, their combinations S ⊕M−R and S ⊕M1,0 with the base strategy
S under some second level ratio, and, ﬁnally, S ⊕S[M1], the integration of the
guidance by the layered clause selection scheme.
Our results are shown in Table 1. It starts by reporting on the performance of
the baseline strategy S and then compares it to the other strategies (the gained
and lost columns are w.r.t. the original run of S).9 We can see that the two single
queue approaches are quite weak, with the better M1,0 solving only 25 % of the
baseline. Nor can the combination S ⊕M−R be considered a success, as it only
solves more problems when less and less advice is taken, seemingly approaching
the performance of S from below. This trend repeats with S ⊕M1,0, although
here an interesting number of problems not solved by the baseline is gained by
strategies which rely on the advice more than half of the time.
With our model M, only the layered clause selection integration S ⊕S[M1]
is able to improve on the performance of the baseline strategy S. In fact, it
9 We had to switch to a diﬀerent machine after producing the training data. There,
a rerun of S gave a slightly better performance than the 734 solved problems used
for training. We still used the original run’s results to compute the gained and lost
values here; the percentage solved is with respect to the new run of S.
553
Improving ENIGMA-style Clause Selection while Learning From History

554
M. Suda
Table 1. Performance results of various forms of integrating the model advice.
strategy
ratio M eval. time% #solved (percent S) gained lost
S
−
0 %
756
100 %
26
4
M−R
−
25 %
55
7 %
25
704
M1,0
−
13 %
190
25 %
30
574
S ⊕M−R
5:1
57 %
543
71 %
86
277
2:1
48 %
445
58 %
78
367
1:1
41 %
335
44 %
54
453
1:2
32 %
248
32 %
39
525
1:5
32 %
140
18 %
28
622
S ⊕M1,0 10:1
11 %
686
90 %
80
128
2:1
14 %
602
79 %
112
244
1:1
14 %
555
73 %
111
290
1:2
14 %
519
68 %
132
347
1:10
14 %
520
68 %
132
346
S ⊕S[M1]
2:1
27 %
855
113 %
210
89
1:1
32 %
1032
136 %
411
113
1:2
33 %
1036
137 %
430
128
1:3
30 %
1026
135 %
428
136
1:5
25 %
989
130 %
405
150
Table 2. Performance decrease caused by turning oﬀabstraction caching and lazy
evaluation, and both; demonstrated on S ⊕S[M1] under the second level ratio 1:2.
M eval. time% #solved (percent S)
both techniques enabled
33 %
1036
137 %
without abstraction caching
45 %
1007
133 %
without lazy evaluation
58 %
905
119 %
both techniques disabled
73 %
782
103 %
improves on it very signiﬁcantly: with the second level ratio of 1:2 we achieve
137 % performance of the baseline and gain 430 problems unsolved by S.
5.4
Evaluation Speed, Lazy Evaluation, and Abstraction Caching
Table 1 also shows the percentage of computation time the individual strategies
spent evaluating the advice, i.e. interfacing M.
A word of warning ﬁrst. These number are hard to interpret across diﬀerent
strategies. It is because diﬀerent guidance steers the prover to diﬀerent parts
of the search space. For example, notice the seemingly paradoxical situation
most pronounced with S ⊕M−R, where the more often is the advice from M
nominally requested, the less time the prover spends interfacing M. Looking
closely at a few problems, we discovered that in strategies relying a lot on M−R,
such as S ⊕M−R under the ratio 1:5, most of the time is spent performing
forward subsumption. An explanation is that the guidance becomes increasingly
bad and the prover slows down, processing larger and larger clauses for which
the subsumption checks are expensive and dominate the runtime.10
10 A similar experience with bad guidance has been made by the authors of ENIGMA.

Fig. 2. The receiver operating characteristic curve (left) and a related plot with explicit
threshold (right) for the selected model M; both based on validation data.
When the guidance is the same, however, we can use the eval. time percent-
age to estimate the eﬃciency of the integration. The results shown in Table 1
were obtained using both lazy evaluation11 and abstraction caching (as described
in sections 3.1 and 4.4). Taking the best performing S ⊕S[M1] under the sec-
ond level ratio 1:2, we selectively disabled: ﬁrst abstraction caching, then lazy
evaluation and ﬁnally both techniques, obtaining the values shown in Table 2.
We can see that the techniques considerably contribute to the overall per-
formance. Indeed, without them Vampire would spend the whole 73 % of com-
putation time evaluating the network (compared to only 33 %) and the strategy
would barely match (with 103 %) the performance of the baseline S.
5.5
Positive Bias
Two important characteristics, from a machine learning perspective, of an ob-
tained model are the true positive rate (TPR) (also called sensitivity) and the
true negative rate (TNR) (also speciﬁcity). TPR is deﬁned as the fraction of
positively labeled examples which the model also classiﬁes as such. TNR is,
analogously, the fraction of negatively labeled examples. Our model M achieves
(on the validation set) 86 % TPR and 81 % TNR.
The ﬁnal judgement of a neural classiﬁer follows from a comparison to a
threshold value t, set by default to t = 0 (recall Sect. 4.1). Changing this thresh-
old allows us to trade TPR for TNR and vice versa in straightforward way. The
interdependence of these two values on the varied threshold is traditionally cap-
tured by the so called receiver operating characteristic (ROC) curve, shown for
our model in Fig. 2 (left). The tradition dictates that the x axis be labeled by the
false positive rate (FPR) (also called fall-out) which is simply 1 −TNR. Under
such presentation, one generally strives to pick a threshold value at which the
11 With the exception of the M−R guidance, with which it is incompatible.
555
Improving ENIGMA-style Clause Selection while Learning From History

556
M. Suda
Table 3. The performance of S⊕S[M1] under the second level ratio 1:2 while changing
the logit threshold. A smaller threshold means more clauses classiﬁed as positive.
threshold #solved (percent S) gained lost
−0.50
1063
140 %
427
98
−0.25
1066
141 %
439
107
0.00
1036
137 %
430
128
0.25
945
125 %
375
164
0.50
825
109 %
278
187
curve is the closest to the upper left corner of the plot.12 However, this is not
necessarily the best conﬁguration for every application.
In the Fig. 2 (right), we “decompose” the ROC curve by using the threshold
t for the independent axis x. We also highlight, for every problem (again, in
the validation set), what is the minimal logit value across all positively labeled
examples belonging to that problem. In other words, what is the logit of the
“least positively classiﬁed” clause from the problem’s proof. We can see that
for the majority of the problems these minima are below the threshold t = 0.
This means that for those problems at least one clause from the original proof
is getting classiﬁed as negative by M under t = 0.
These observations motivated us to experiment with non-zero values of the
threshold in an ATP evaluation. Particularly promising seemed the use of a
threshold t smaller than zero with the intention of classifying more clauses as
positive. The results of the experiment are in shown Table 3. Indeed, we could
further improve the best performing strategy from Table 1 with both t = −0.25
and t = −0.5. It can be seen that smaller values lead to fewer problems lost, but
even the ATP gain is better with t = −0.25 than with the default t = 0, leading
to the overall best improvement of 141 % with respect to the baseline S.
5.6
Learning from Guided Proofs and Negative Mining
As previously unsolved problems get proven with the help of the trained guid-
ance, the new proofs can be used to enrich the training set and potentially help
obtaining even better models. This idea of alternating the training and the ATP
evaluation steps in a reinforcing loop has been proposed and successfully real-
ized by the authors of ENIGMA on the Mizar dataset [18]. Here we propose an
enhancement of the idea and repeat an analogous experiment in our setting.
By collecting proofs discovered by a selection of 8 diﬀerent conﬁgurations
tested in the previous sections, we grew our set of solved problems from 734 to
1528. We decided to keep one proof per problem, strictly extending the origi-
nal training set. We then repeated the same training procedure as described in
Sect. 5.2 on this new set and on an extension of this set obtained as follows.
Negative mining:
We suspected that the successful derivations obtained with
the help of M might not contain enough “typical wrong decisions” from the
12 Minimizing the standard cross entropy loss should actually automatically “bring the
curve” close to that corner for the threshold t = 0.

Table 4. The performance of new models learned from guided proofs. U is the set of
1528 problems used for the training. The gained and lost counts are here w.r.t. U.
#solved (percent S) (percent |U|) gained lost
plain
1268
167 %
82 %
90
350
with negative mining
1394
184 %
91 %
140
274
perspective of S to provide for good enough training. We therefore logged the
failing runs of S on the (1528 −734) problems only solved by one of the guided
strategies and augmented the corresponding derivations with these.13
Table 4 conﬁrms14 that negative mining indeed helps to produce a better
model. Mainly, however, it shows that training from additional derivations fur-
ther dramatically improves the performance of the obtained strategy.
6
Conclusion
We revisited the topic of ENIGMA-style clause selection guidance by a machine
learned binary classiﬁer and proposed four improvements to previous work: (1)
the use of layered clause selection for integrating the advice, (2) the lazy evalu-
ation trick to reduce the overhead of interfacing a potentially expensive model,
(3) the “positive bias” idea suggesting to be really careful not to discard poten-
tially useful clauses, and (4) the “negative mining” technique to provide enough
negative examples when learning from proofs obtained with previous guidance.
We have also shown that a strong advice can be obtained by looking just
at the derivation history to discriminate a clause. The automatically discovered
neural guidance signiﬁcantly improves upon the human-engineered heuristic [11]
under identical conditions. Rerunning S with the theory heuristic enabled in its
default form [10] resulted here in 816 (107 %) solved problems.
By deliberately focusing of the representation of clauses by their derivations,
we obtained some nice properties, such as relative speed of evaluation. However,
in situations where theory reasoning by automatically added theory axioms is
not prevalent, such as on most of the TPTP library, we expect guidance based
on derivations with just a single axiom origin label, the input, to be quite weak.
Still, we see a great opportunity in using statistical methods for analyzing
ATP behaviour; not only for improving prover performance with a black box
guidance, but also as a tool for discovering regularities that could be exploited
to improve our understanding of the technology on a deeper level.
Acknowledgement
This work was supported by the Czech Science Foundation project 20-06390Y
and the project RICAIP no. 857306 under the EU-H2020 programme. We also
thank the anonymous reviewers for suggesting numerous improvements.
13 Negative mining has, for instance, been previously used when training deep models
for the premise selection task [14].
14 The ATP eval was again integrating via S ⊕S[M1] under the second level ratio 1:2.
557
Improving ENIGMA-style Clause Selection while Learning From History

558
M. Suda
References
1. Ayg¨un, E., Ahmed, Z., Anand, A., Firoiu, V., Glorot, X., Orseau, L., et al.: Learn-
ing to prove from synthetic theorems. CoRR abs/2006.11259 (2020)
2. Ba, L.J., Kiros, J.R., Hinton, G.E.: Layer normalization. CoRR abs/1607.06450
(2016)
3. Bachmair,
L.,
Ganzinger,
H.:
Rewrite-based
equational
theorem
proving
with
selection
and
simpliﬁcation.
J.
Log.
Comput.
4(3),
217–247
(1994).
https://doi.org/10.1093/logcom/4.3.217
4. Bachmair, L., Ganzinger, H.: Resolution theorem proving. In: Robinson and
Voronkov [28], pp. 19–99. https://doi.org/10.1016/b978-044450813-3/50004-7
5. Barrett, C., Fontaine, P., Tinelli, C.: The Satisﬁability Modulo Theories Library
(SMT-LIB) (2016), www.SMT-LIB.org
6. Bradley, A.R., Manna, Z., Sipma, H.B.: What’s decidable about arrays? In: Emer-
son, E.A., Namjoshi, K.S. (eds.) Veriﬁcation, Model Checking, and Abstract In-
terpretation, 7th International Conference, VMCAI 2006, Charleston, SC, USA,
January 8-10, 2006, Proceedings. LNCS, vol. 3855, pp. 427–442. Springer (2006).
https://doi.org/10.1007/11609773 28
7. Chvalovsk´y, K., Jakubuv, J., Suda, M., Urban, J.: ENIGMA-NG: eﬃcient neu-
ral and gradient-boosted inference guidance for E. In: Fontaine [9], pp. 197–215.
https://doi.org/10.1007/978-3-030-29436-6 12
8. Denzinger, J., Schulz, S.: Learning Domain Knowledge to Improve Theorem Prov-
ing. In: McRobbie, M., Slaney, J. (eds.) Proc. of the 13th CADE, New Brunswick.
pp. 62–76. No. 1104 in LNAI, Springer (1996)
9. Fontaine, P. (ed.): Automated Deduction - CADE 27 - 27th International Con-
ference on Automated Deduction, Natal, Brazil, August 27-30, 2019, Proceedings,
LNCS, vol. 11716. Springer (2019). https://doi.org/10.1007/978-3-030-29436-6
10. Gleiss, B., Suda, M.: Layered clause selection for saturation-based theorem prov-
ing. In: Fontaine, P., Korovin, K., Kotsireas, I.S., R¨ummer, P., Tourret, S. (eds.)
Joint Proceedings of the 7th Workshop on Practical Aspects of Automated Rea-
soning (PAAR) and the 5th Satisﬁability Checking and Symbolic Computation
Workshop (SC-Square), co-located with the 10th International Joint Conference
on Automated Reasoning (IJCAR 2020), Paris, France, June-July, 2020 (Vir-
tual). CEUR Workshop Proceedings, vol. 2752, pp. 34–52. CEUR-WS.org (2020),
http://ceur-ws.org/Vol-2752/paper3.pdf
11. Gleiss, B., Suda, M.: Layered clause selection for theory reasoning - (short
paper). In: Peltier, N., Sofronie-Stokkermans, V. (eds.) Automated Reasoning
- 10th International Joint Conference, IJCAR 2020, Paris, France, July 1-4,
2020, Proceedings, Part I. LNCS, vol. 12166, pp. 402–409. Springer (2020).
https://doi.org/10.1007/978-3-030-51074-9 23
12. Goller, C., K¨uchler, A.: Learning task-dependent distributed representations by
backpropagation through structure. In: Proceedings of International Conference
on Neural Networks (ICNN’96), Washington, DC, USA, June 3-6, 1996. pp. 347–
352. IEEE (1996). https://doi.org/10.1109/ICNN.1996.548916
13. Goodfellow, I.J., Bengio, Y., Courville, A.C.: Deep Learning. Adaptive computa-
tion and machine learning, MIT Press (2016), http://www.deeplearningbook.org/
14. Irving,
G.,
Szegedy,
C.,
Alemi,
A.A.,
E´en,
N.,
Chollet,
F.,
Urban,
J.:
Deepmath
-
deep
sequence
models
for
premise
selection.
In:
Lee,
D.D.,
Sugiyama, M., von Luxburg, U., Guyon, I., Garnett, R. (eds.) Advances
in Neural Information Processing Systems 29: Annual Conference on Neu-
ral Information Processing Systems 2016, December 5-10, 2016, Barcelona,

Spain. pp. 2235–2243 (2016), https://proceedings.neurips.cc/paper/2016/hash/
f197002b9a0853eca5e046d9ca4663d5-Abstract.html
15. Jakubuv, J., Chvalovsk´y, K., Ols´ak, M., Piotrowski, B., Suda, M., Urban, J.:
ENIGMA anonymous: Symbol-independent inference guiding machine (system de-
scription). In: Peltier, N., Sofronie-Stokkermans, V. (eds.) Automated Reason-
ing - 10th International Joint Conference, IJCAR 2020, Paris, France, July 1-
4, 2020, Proceedings, Part II. LNCS, vol. 12167, pp. 448–463. Springer (2020).
https://doi.org/10.1007/978-3-030-51054-1 29
16. Jakubuv, J., Urban, J.: ENIGMA: eﬃcient learning-based inference guiding ma-
chine. In: Geuvers, H., England, M., Hasan, O., Rabe, F., Teschke, O. (eds.) Intel-
ligent Computer Mathematics - 10th International Conference, CICM 2017, Edin-
burgh, UK, July 17-21, 2017, Proceedings. LNCS, vol. 10383, pp. 292–302. Springer
(2017). https://doi.org/10.1007/978-3-319-62075-6 20
17. Jakubuv, J., Urban, J.: Enhancing ENIGMA given clause guidance. In: Rabe, F.,
Farmer, W.M., Passmore, G.O., Youssef, A. (eds.) Intelligent Computer Math-
ematics - 11th International Conference, CICM 2018, Hagenberg, Austria, Au-
gust 13-17, 2018, Proceedings. LNCS, vol. 11006, pp. 118–124. Springer (2018).
https://doi.org/10.1007/978-3-319-96812-4 11
18. Jakubuv, J., Urban, J.: Hammering Mizar by learning clause guidance (short pa-
per). In: Harrison, J., O’Leary, J., Tolmach, A. (eds.) 10th International Confer-
ence on Interactive Theorem Proving, ITP 2019, September 9-12, 2019, Portland,
OR, USA. LIPIcs, vol. 141, pp. 34:1–34:8. Schloss Dagstuhl - Leibniz-Zentrum f¨ur
Informatik (2019). https://doi.org/10.4230/LIPIcs.ITP.2019.34
19. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. In: Bengio,
Y., LeCun, Y. (eds.) 3rd International Conference on Learning Representations,
ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings
(2015), http://arxiv.org/abs/1412.6980
20. Kov´acs,
L.,
Robillard,
S.,
Voronkov,
A.:
Coming
to
terms
with
quanti-
ﬁed reasoning. In: Castagna, G., Gordon, A.D. (eds.) Proceedings of the
44th ACM SIGPLAN Symposium on Principles of Programming Languages,
POPL 2017, Paris, France, January 18-20, 2017. pp. 260–270. ACM (2017).
https://doi.org/10.1145/3009837.3009887
21. Kov´acs, L., Voronkov, A.: First-order theorem proving and Vampire. In: Shary-
gina, N., Veith, H. (eds.) Computer Aided Veriﬁcation - 25th International Con-
ference, CAV 2013, Saint Petersburg, Russia, July 13-19, 2013. Proceedings. LNCS,
vol. 8044, pp. 1–35. Springer (2013). https://doi.org/10.1007/978-3-642-39799-8 1
22. Loos, S.M., Irving, G., Szegedy, C., Kaliszyk, C.: Deep network guided proof search.
In: Eiter, T., Sands, D. (eds.) LPAR-21, 21st International Conference on Logic
for Programming, Artiﬁcial Intelligence and Reasoning, Maun, Botswana, May
7-12, 2017. EPiC Series in Computing, vol. 46, pp. 85–105. EasyChair (2017).
https://doi.org/10.29007/8mwc
23. Nieuwenhuis, R., Rubio, A.: Paramodulation-based theorem proving. In: Robinson
and Voronkov [28], pp. 371–443. https://doi.org/10.1016/b978-044450813-3/50009-
6
24. Ols´ak, M., Kaliszyk, C., Urban, J.: Property invariant embedding for auto-
mated reasoning. In: Giacomo, G.D., Catal´a, A., Dilkina, B., Milano, M., Barro,
S., Bugar´ın, A., Lang, J. (eds.) ECAI 2020 - 24th European Conference on
Artiﬁcial Intelligence, 29 August-8 September 2020, Santiago de Compostela,
Spain, August 29 - September 8, 2020 - Including 10th Conference on Pres-
tigious Applications of Artiﬁcial Intelligence (PAIS 2020). Frontiers in Artiﬁ-
559
Improving ENIGMA-style Clause Selection while Learning From History

560
M. Suda
cial Intelligence and Applications, vol. 325, pp. 1395–1402. IOS Press (2020).
https://doi.org/10.3233/FAIA200244
25. Paszke,
A.,
Gross,
S.,
Massa,
F.,
Lerer,
A.,
Bradbury,
J.,
Chanan,
G.,
et al.: Pytorch: An imperative style, high-performance deep learning library.
In: Wallach, H., Larochelle, H., Beygelzimer, A., dAlch´e-Buc, F., Fox, E.,
Garnett, R. (eds.) Advances in Neural Information Processing Systems 32,
pp. 8024–8035. Curran Associates, Inc. (2019), http://papers.neurips.cc/paper/
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf
26. Reger, G., Suda, M., Voronkov, A.: Playing with AVATAR. In: Felty, A.P., Middel-
dorp, A. (eds.) Automated Deduction - CADE-25 - 25th International Conference
on Automated Deduction, Berlin, Germany, August 1-7, 2015, Proceedings. LNCS,
vol. 9195, pp. 399–415. Springer (2015). https://doi.org/10.1007/978-3-319-21401-
6 28
27. Riazanov, A., Voronkov, A.: Limited resource strategy in resolution theorem prov-
ing. J. Symb. Comput. 36(1-2), 101–115 (2003). https://doi.org/10.1016/S0747-
7171(03)00040-3
28. Robinson, J.A., Voronkov, A. (eds.): Handbook of Automated Reasoning (in 2
volumes). Elsevier and MIT Press (2001)
29. Sandler, M., Howard, A.G., Zhu, M., Zhmoginov, A., Chen, L.: Mobilenetv2:
Inverted residuals and linear bottlenecks. In: 2018 IEEE Conference on Com-
puter Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT,
USA,
June
18-22,
2018.
pp.
4510–4520.
IEEE
Computer
Society
(2018).
https://doi.org/10.1109/CVPR.2018.00474
30. Schulz, S.: Learning Search Control Knowledge for Equational Deduction. No. 230
in DISKI, Akademische Verlagsgesellschaft Aka GmbH Berlin (2000)
31. Schulz, S., Cruanes, S., Vukmirovic, P.: Faster, higher, stronger: E 2.3. In: Fontaine
[9], pp. 495–507. https://doi.org/10.1007/978-3-030-29436-6 29
32. Schulz, S., M¨ohrmann, M.: Performance of clause selection heuristics for saturation-
based theorem proving. In: Olivetti, N., Tiwari, A. (eds.) Automated Reason-
ing - 8th International Joint Conference, IJCAR 2016, Coimbra, Portugal, June
27 - July 2, 2016, Proceedings. LNCS, vol. 9706, pp. 330–345. Springer (2016).
https://doi.org/10.1007/978-3-319-40229-1 23
33. Smith, L.N.: Cyclical learning rates for training neural networks. In: 2017 IEEE
Winter Conference on Applications of Computer Vision, WACV 2017, Santa
Rosa, CA, USA, March 24-31, 2017. pp. 464–472. IEEE Computer Society (2017).
https://doi.org/10.1109/WACV.2017.58
34. Smith, L.N., Topin, N.: Super-convergence: Very fast training of residual networks
using large learning rates. CoRR abs/1708.07120 (2017)
35. Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.:
Dropout: a simple way to prevent neural networks from overﬁtting. J. Mach. Learn.
Res. 15(1), 1929–1958 (2014), http://dl.acm.org/citation.cfm?id=2670313
36. Tammet, T.: GKC: A reasoning system for large knowledge bases. In: Fontaine [9],
pp. 538–549. https://doi.org/10.1007/978-3-030-29436-6 32
37. Urban, J.: personal communication
38. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N.,
et al.: Attention is all you need. In: Guyon, I., von Luxburg, U., Bengio, S.,
Wallach, H.M., Fergus, R., Vishwanathan, S.V.N., Garnett, R. (eds.) Advances
in Neural Information Processing Systems 30: Annual Conference on Neural
Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA,
USA. pp. 5998–6008 (2017), https://proceedings.neurips.cc/paper/2017/hash/
3f5ee243547dee91fbd053c1c4a845aa-Abstract.html

39. Voronkov, A.: AVATAR: the architecture for ﬁrst-order theorem provers. In: Biere,
A., Bloem, R. (eds.) Computer Aided Veriﬁcation - 26th International Conference,
CAV 2014, Held as Part of the Vienna Summer of Logic, VSL 2014, Vienna, Aus-
tria, July 18-22, 2014. Proceedings. LNCS, vol. 8559, pp. 696–710. Springer (2014).
https://doi.org/10.1007/978-3-319-08867-9 46
40. Weidenbach, C., Dimova, D., Fietzke, A., Kumar, R., Suda, M., Wischnewski,
P.: SPASS version 3.5. In: Schmidt, R.A. (ed.) Automated Deduction - CADE-
22, 22nd International Conference on Automated Deduction, Montreal, Canada,
August 2-7, 2009. Proceedings. LNCS, vol. 5663, pp. 140–145. Springer (2009).
https://doi.org/10.1007/978-3-642-02959-2 10
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.
561
Improving ENIGMA-style Clause Selection while Learning From History

System Descriptions

A Normative Supervisor for Reinforcement
Learning Agents
1 TU Wien, Vienna, Austria
2 Data61, CSIRO, Melbourne, Australia
Abstract. We introduce a modular and transparent approach for aug-
menting the ability of reinforcement learning agents to comply with a
given norm base. The normative supervisor module functions as both
an event recorder and real-time compliance checker w.r.t. an external
norm base. We have implemented this module with a theorem prover for
defeasible deontic logic, in a reinforcement learning agent that we task
with playing a “vegan” version of the arcade game Pac-Man.
1
Introduction
Autonomous agents are an increasingly integral part of modern life. While
performing activities formerly reserved for human agents, they must possess
the ability to adapt to (potentially unpredictable) changes in their environment;
reinforcement learning (RL) has proven a successful method for teaching agents
this behaviour (see, e.g. [16,13]). Performing human roles further requires that
agents align themselves with the ethical standards their human counterparts are
subject to, introducing a requirement for ethical reasoning. RL has been employed
to enforce such standards as well (see, e.g., [14]); agents can be trained to act
in line with further rewards/penalties assigned according to the performance
of ethical/unethical behaviour through a reward function. However, this does
not provide a guarantee of the desired behaviour. Moreover, such techniques are
not well equipped to handle the complexities of ethical reasoning. In general,
like other black-box machine learning methods, RL cannot transparently explain
why a certain policy is compliant or not. Additionally, when the ethical values
are embedded in the learning process, a small change in their deﬁnition would
require us to retrain the policy from scratch.
To obviate the limitations of RL to represent ethical norms, the approach
we follow in this paper combines RL with Deontic Logic, the branch of formal
logic that is concerned with prescriptive statements; we implement a normative
supervisor to inform a trained RL agent of the ethical requirements in force in a
given situation. Since the pioneering works [17,15], it has been well understood
that Deontic Logic can be applied to model ethical norms; the diﬀerence between
ethical and legal norms is indeed only on how they emerge, not what normative
consequences are entailed by them. We implement our normative supervisor using
1
This work was partially supported by WWTF project MA16-28 and the DC-RES run by the TU
Wien’s Faculty of Informatics and the FH-Technikum Wien.
© The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5 32
Emery Neufeld1
, Ezio Bartocci1
, Agata Ciabattoni1
, and Guido
Governatori2
565–576, 2021.

566
E. Neufeld et al.
defeasible deontic logic [8,9]. This is a simple and computationally feasible, yet
expressive, logic allowing for defeasible reasoning, and can easily accommodate
changes to the norm base, should the ethical requirements become more complex
(see Sect. 3.4 for a brief walk-through). Moreover, the constructive nature of this
logic allows us to determine how a given conclusion has been reached.
By embedding the normative supervisor into the RL agent architecture, the
agent can follow near-optimal learned policies while enforcing ethical actions
in a modular and transparent way. The supervisor functions as both an event
recorder and real-time compliance checker; it corrects the choice of a given action
from the policy only when this violates a norm. It is furthermore used as an
event logger to identify and extract new sets of (ethical) norms to promote
particular goals. We demonstrate our approach on an RL agent that plays a
“vegan” version of Pac-Man, with an “ethical” constraint forbidding Pac-Man
from eating ghosts. Already used as a case study in [14,10], the Pac-Man game
is a closed environment for testing with clearly deﬁned game mechanics and
parameters which are easy to isolate, manipulate, and extend with variably
intricate rule sets. We successfully evaluated our approach with several tests,
consisting of “vegan” games and a “vegetarian” version of the game where the
agent can eat only one type of ghost. The achievement of full compliance in the
latter case was possible with the introduction of additional norms identiﬁed via
the event recorder.
Related Work. The papers [14] and [10] on Pac-Man motivated our work. The
former employs multi-objective RL with policy orchestration to impose normative
constraints on vegan Pac-Man. It seamlessly combines ethically compliant be-
haviour and learned optimal behaviour; however, the ethical reasoning performed
is still to a degree implicit, it does not provide justiﬁcations for the choices
made, and it is not clear how the approach would remain reasonably transpar-
ent with more complex norm sets. [10] takes steps to integrate more complex
constraints on a RL agent, but as they are embedded in the learned policy, it
lacks the transparency of a logic-based implementation. [1] and [2] address the
problem of transparency in the implementation of ethical behaviours in AI, but
their approach has not been implemented and tested yet. Symbolic reasoning
for implementing ethically compliant behaviour in autonomous agents has been
used in many frameworks, such as [5], which models the behaviour from a BDI
perspective. This approach does not allow for defeasible reasoning, and focuses on
avoiding ethical non-compliance at the planning level. Non-monotonic logic-based
approaches that extend BDI with a normative component appear in [6,9], whose
solutions remain only at the theoretical level. These papers belong to the related
ﬁeld of Normative Multi-Agent Systems, which is not speciﬁcally concerned with
the ethical behaviour of agents [3], and whose introduced formalisms and tools
(e.g. [12]) have not yet been used in combination with RL.
2
Background
Normative Reasoning. Normative reasoning diﬀers from the reasoning cap-
tured by classical logic in that the focus is not on true or false statements, but
rather the imposition of norms onto such statements.

567
We will deal with two types of norms: constitutive and regulative norms
(see [4] for the terminology). Regulative norms describe obligations, prohibitions
and permissions. Constitutive norms regulate instead the creation of institutional
facts as well as the modiﬁcation of the normative system itself; their content is a
relation between two concepts, and they will typically take the form “in context
c, concept x counts as concept y”, where x refers to a more concrete concept (e.g.,
walking) and y to a more abstract one (e.g., moving). We say concept x is at a
lower level of abstraction than concept y in context c if there is a constitutive
norm with context c asserting that x counts as y (henceforth denoted C(x,y)).
Reinforcement Learning (RL). RL refers to a class of algorithms specialized
in learning how an agent should act in its environment to maximize the expected
cumulative reward. Given a function that assigns rewards/penalties to each state
and successor state pair (or state-action pairs), the RL algorithm learns an
optimal policy, a function from states to actions that can govern its behaviour.
In our case study we chose Q-learning [18] with function approximation as
a RL algorithm. In Q-learning, the RL algorithm ﬁrst learns a function Q(s,a)
to predict the expected cumulative reward (Q-value) from state s taking action
a. The learned policy picks the action argmaxa∈possible Q(s,a) with the highest
Q-value over a list of possible actions. The function Q is approximated as a linear
function which is the weighted sum of features describing some elements of the
environment (e.g., the distance between the agent and object X); the features
which are most relevant to predicting the agent success are weighted most heavily.
Vegan Pac-Man. In the arcade game Pac-Man, an eponymous agent is situated
inside a maze over a grid, where some cells contain a ‘food pellet’ which Pac-Man
will eat if it moves inside the cell. Pac-Man’s goal is to maximize his score; when
Pac-Man eats a food pellet he gains a reward (+10 points), but there is also a
time penalty (−1 point for every time step). Pac-Man wins when he has eaten
all the food pellets in the maze (resulting in +500 points), and he loses if he
collides with one of the ghost agents wandering around the maze (resulting in
−500 points). However, after eating a ‘power pellet’ (of which there are two), the
ghosts become ‘scared’, and Pac-Man can eat them (for +200 points).
Inspired by [14], we consider a variation of the UC Berkeley AI Pac-Man
implementation [7], where Pac-Man cannot eat ghosts (only blue ghosts in the
vegetarian version). Our Pac-Man agent utilizes a Q-learning policy; for the
utility function we use the game’s score, and we take the game states as states.
We use the same game layout as in [14]; this is a 20 × 11 maze populated with 97
food pellets and two ghosts (blue and orange) which follow random paths, where
the maximum score available is 2170, and 1370 when eating ghosts is forbidden.
3
The Normative Supervisor
The key component of our approach is a normative supervisor whose architecture
is illustrated in Fig. 1. This module consists of a normative reasoning engine (we
use the SPINdle theorem prover [11]), and of other components that encode the
A Normative Supervisor for Reinforcement Learning Agents

568
E. Neufeld et al.
norms and environmental data into defeasible deontic logic rules, and translate
the conclusions of the reasoning engine into instructions for the agent.
Norm 
Base
Agent’s State
Possible Actions
Translator
Reasoner
Normative
Prescriptions
Normative Supervisor
Translator
Legal Actions
Environment
Localization
Normative 
Supervisor
Possible 
Actions
Translator
Policy
Legal 
Actions
Execute the
Best Action
Reinforcement Learning Agent
Observe 
State
Fig. 1. Key components and placement of the Normative Supervisor.
We place the normative supervisor in the already-trained agent’s control loop
between the localization and policy module. The localization module identiﬁes
the current agent’s state with respect to its environment and returns a list of
possible actions to the normative supervisor. This module ﬁlters out all the
actions that are not compliant with the norms. The policy will then identify,
among the pool of the compliant actions, the optimal one for generating the next
game state. If there are no available compliant actions the normative supervisor
will select the ’lesser evil’ action. This module additionally enables the logging of
events during the game for later scrutiny.
3.1
Conﬁguring the Norm Base
We start with a simple normative prescription, consisting only of the behavioral
constraint proposed in [14] that “Pac-Man must not eat ghosts”2, represented as
vegan ∶F(eat(pacman,ghost)), where F denotes prohibition.
If this norm base is to inform our agent’s actions, it needs to reference concepts
that correspond to the information directly processed by the agent, which is
limited to the locations of game entities and the actions that Pac-Man can
perform, which we denote as North, South, East, West, and Stop. The only
way eat(pacman,ghost) can be done is if (a) the ghost is in a ‘scared’ state,
and (b) Pac-Man and the ghost move into the same cell. These are expressed
as scared(ghost) and inRange(pacman,ghost) respectively. Pac-Man does not
know which direction the ghost will move in, but we will assume a “cautious”
model of action where Pac-Man is not to perform any action that could constitute
eating a ghost; that is, if Pac-Man takes an action that could reasonably lead
to him violating a norm, we will consider that norm violated. Since Pac-Man’s
next action determines what is in range, we will actually need ﬁve entities
to express inRange(pacman,ghost), one corresponding to each action. These
concepts are used to construct a constitutive norm, or a kind of strategy, regarding
eating, strategyNorth ∶C(North,eat(pacman,ghost)), which is applicable in
the context {scared(ghost),inNorthRange(pacman,ghost)}.
2 For the time being we generalize the blue and the orange ghosts as ghost.

569
For inNorthRange(pacman,ghost), we have access to the positions of Pac-
Man and the ghosts, so we can create another set of constitutive norms for
this, which apply in the context {pacman(i,j)}, rangeNorth ∶C(ghost(k,l),
inNorthRange(pacman,ghost)), where (k,l) has a Manhattan distance of one
or fewer cells from (i,j + 1).
Finally, we need to consider additional relationships between norms and
concepts. For this norm base, we only have one regulative norm, so a mechanism
for conﬂict resolution is not needed. However, as Pac-Man can only execute one
action at a time, we have a non-concurrence relation between every action. This
amounts to an inability to comply with multiple obligations over distinct actions.
However, since Vegan Pac-Man does not deal with any obligations, additional
rules will not be needed.
Representing the Norm Base. We need a formal language – equipped with
an automated theorem prover – capable of eﬀectively representing and reasoning
with the norm base; we chose defeasible deontic (propositional) logic (DDPL
for short) [8]. DDPL is deﬁned over literals and modal literals, and the key
ingredient is the rules we can construct from them. For the purposes of this paper
we only consider one deontic modality (obligation O) and deﬁne prohibition and
permission as F(p) ≡O(¬p) and P(p) ≡¬O(¬p).
Deﬁnition 1. A rule is an expression r∶A(r) ↪∗N(r) where r is a label uniquely
identifying the rule, A(r) = {a1,...,an} is the antecedent, N(r) is the consequent,
↪∗∈{→∗,⇒∗,⇝∗}, and the mode of each rule is designated with ∗∈{C,O}.
Rules labelled by C and O are constitutive and regulative rules, respectively. Strict
rules (→∗) are rules where the consequent strictly follows from the antecedent
without exception. Defeasible rules (⇒∗) are rules where the consequent typically
follows from the antecedent, unless there is evidence to the contrary. Defeaters
(⇝∗) are rules that only prevent a conclusion from being reached by a defeasible
rule; regulative defeaters are used to encode permissive rules (see [8]).
The central concept of DDPL (and our application of it) is:
Deﬁnition 2. A defeasible theory D is a tuple ⟨F,RO,RC,>⟩, where F is a set
of literals (facts), RO and RC are sets of regulative and constitutive rules, and >
is a superiority relation over rules.
These tools will be utilized to map Pac-Man’s to a defeasible theory; the environ-
ment translated to a set of facts and the norm base to a set of rules.
3.2
Automating Translation
We are now dealing with three kinds of syntax: our informal representation of the
norm base, the input and output of the host process, and the formal language
of the reasoner (DDPL and its theorem prover SPINdle [11]). If we frame the
reasoner as a central reasoning facility, the agent as a front-end, and the norm
base as a back-end, we can implement this dynamic as a translator with two
faces, one front-facing and one back-facing, feeding information into the reasoner
from the agent and the norm base respectively.
A Normative Supervisor for Reinforcement Learning Agents

570
E. Neufeld et al.
Front End Translation. The front-end translator will be continuously in use,
sending new data to be translated and requiring translated proposed actions
as the environment changes. This will be an algorithm that transforms input
data from the agent into propositions which assert facts about the agent or
the environment, and then logical conclusions into instructions the agent will
understand. Each cell of the Pac-Man grid can contain characters (Pac-Man or
one of the ghosts), an object (a wall or a food pellet), or nothing at all. Walls
are accounted for during the localization stage of Pac-Man’s algorithm and food
pellets are not an entity that appears in the norm base, so we will need to reason
only about the characters. Hence we have two sets of variables in each game;
pacmani,j and ghosti,j (along with scared(ghost) if the ghost is in a scared
state) assert the current coordinates of Pac-Man and of each ghost, and appear
in a set Facts in the defeasible theory GameState = ⟨Facts,RC,RO,>⟩.
Actions will be represented as deontic literals, in the set
Actions = {North,South,East,West,Stop}
A query from Pac-Man to the reasoner will be accompanied by a representation
of the current game state, along with a list of possible actions, possible, which
will be translated to the corresponding literal in Actions.
Back End Translation. In this critical task it is crucial to ensure that norms
dictate the same behaviour once translated into this language. Besides making
sure that each component of the norm can be represented by the language, we
must also analyse our translated norm base with respect to how the available
metadata is accommodated by the reasoner’s rules of inference.
We represent the regulative norm of Vegan Pac-Man (vegan) as:
⇒O ¬eatpacman,ghost ∈RO
where defeasibility is given as a precautionary measure, in case we want to add
(potentially conﬂicting) norms later.
Note that if moving North counts as eating a ghost, an obligation to go
North counts as being obligated to eat a ghost, and a prohibition to eat a
ghost implies a prohibition to move North. So we can rewrite strategyNorth as
C(O(¬eat(pacman,ghost)),O(¬North)), or with the applicable context as:
scaredghost,inNorthRangepacman,ghost,O(¬eatpacman,ghost) ⇒O ¬North ∈RO
Note that though this a constitutive rule, in DDPL it will be in RO. This will
work for all of the constitutive norms attached to a prohibited action, where
we place the context and the prohibition in question in the antecedent, and the
prohibition of the concrete action in the strategy is the consequent.
For the remaining constitutive norms, we have a rather simple conversion.
These norms will be generated w.r.t. the input from the agent; for example, if
the agent (Pac-Man) tells us that he is at (2,3), the rule rangeNorth will be:
pacman2,3,ghost2,4 →C inNorthRangepacman,ghost ∈RC
We have found that it is more time-eﬃcient to generate these constitutive
norms anew whenever the fact set changes, instead of generating every possible
constitutive norm ahead of time, and having SPINdle deal with all at once.

571
3.3
Classify and Assess Conclusions
Once we understand how various concepts are represented in the reasoner lan-
guage, we need to parse the possible outputs of the reasoning engine into indicators
as to which actions in the agent’s arsenal are compliant with the norm base.
Compliant Solutions. Ideally, we will want to locate a compliant solution – an
action that constitutes a possible course of action for the agent that does not
violate any norms – from the conclusions yielded by the reasoner.
Deﬁnition 3. A set of compliant solutions is: (1) non-empty, and consisting
only of (2) solutions composed of possible actions, (3) solutions that do not violate
any norms, and (4) solutions that are internally consistent.
The manner in which we construct such a set is heavily inﬂuenced by the
output (conclusions) yielded by SPINdle. Conclusions in DDPL are established
over proofs and can be classiﬁed as defeasible or deﬁnite, and positive or negative.
A positive conclusion means that the referenced literal holds, while a negative
indicates that this literal has been refuted. A deﬁnite conclusion is obtained by
using only strict rules and facts using forward chaining of rules. A conclusion holds
defeasibly (denoted by +∂C for a factual conclusion and +∂O for an obligation) if
there is an applicable rule for it and the rules for the opposite cannot be applied
or are defeated. Over the course of a proof, each rule will be classiﬁed as either
applicable (i.e., the antecedent holds and the consequent follows), discarded (i.e.,
the rule is not applied because the antecedent doesn’t fully hold), or defeated
by a defeater or a higher priority rule. For a set of rules R, R[p], RO and Rsd
are, respectively, the subsets of: the rules for p, regulative rules, and strict or
defeasible rule. The deﬁnition of provability for defeasible obligations [8] (we
deﬁne only defeasible conclusions, because in our formalization regulative norms
were expressed as defeasible rules) is:
Deﬁnition 4. Given a defeasible theory D, if D ⊢+∂O p, then:
1. ∃r ∈Rsd
O [p] that is applicable defeasible, and
2. ∀s ∈RO[¬p] either: (a) s is discarded, or (b) s ∈Rsd and ∃t ∈RO[p] s.t. t is
applicable, t > s, or (c) s is a defeater, ∃t ∈Rsd
O [p] s.t. t is applicable, t > s
A derivation in DDPL has a three phase argumentation structure, where argu-
ments are simply applicable rules: (1) we need an argument for the conclusion we
want to prove, (2) we analyse all possible counter-arguments, and (3) we rebut
the counter-arguments. An argument can be rebutted when it is not applicable or
when it is defeated by a stronger applicable argument. If we exclude the undercut
case, in every phase the arguments attack the arguments in the previous phase.
A rule attacks another rule if the conclusions of the two rules are contradictory
(note that P(q) and P(¬q) are not a deontic contradiction). Accordingly, any
regulative rule for q attacks a strict or defeasible regulative rule for ¬q. However, a
regulative defeater for q is not attacked by a regulative defeater for ¬q (condition
2(c) above).
We parse out a solution set by: (1) if we do not receive a full set of conclusions
from SPINdle, we return an empty set; (2) we remove all conclusions that do
A Normative Supervisor for Reinforcement Learning Agents

572
E. Neufeld et al.
not reference a literal in possible; (3) any action corresponding to a defeasibly
proved positive literal occurs in every solution; and (4) any action corresponding
to a defeasibly proved negative literal is discarded from every solution.
Claim: the above procedure yields either an empty set or a compliant solution.
Proof sketch: If our solution is not internally consistent, we can prove both +δO a
and +δO¬a for some action a. In this case SPINdle will return neither, and the
above procedure leads to an empty set in step (1). Only possible actions will
occur in a solution as per step (2), and any solutions which fail to comply with an
obligation or prohibition will be excluded through step (3) and (4) respectively.
‘Lesser of two Evils’ Solutions. If the above procedure leaves us with an
empty solution set, we want to identify which non-compliant actions constitute
the “best” choice (i.e. are minimally non-compliant). Our characterization of
degrees of non-compliance depends on the way the reasoner constructs solutions,
and what information it logs during this process. SPINdle has an inference logger
that classiﬁes every rule in the theory as discarded, applicable, or defeated. For
our agent, the chosen degree is a score derived from the of norms that have been
applied versus those that have been defeated (discarded norms are ignored):
score ∶= #complied −#violated = #applied −#defeated
This score is computed through the theory GameStatea, which is constructed
by adding a fact O(a) to GameState. Recall that a rule will be defeated when
its defeasible theory includes a fact that conﬂicts with the head of this rule.
So when we add O(a) to GameState, all norms that prescribed F(a) = O(¬a)
for GameState are defeated and any prescribing O(a) is applied. To compute
the score, we use SPINdle in a rather unconventional way, ignoring conclusions
yielded and checking the inference log to count which rules have been applied
during reasoning (#applied) and which were defeated (#defeated) and set
score = #applied −#defeated. This procedure is completed for every action in
possible, and we select the action(s) with the highest score. If there are multiple
actions with a highest score, we send multiple solutions to the agent and it will
pick the best action according to its policy.
Claim: computing scores for all possible actions is completed in polynomial time.
Proof sketch: As shown in [8], conclusions in DDPL can be computed in linear
time with respect to the the number of literal occurrences plus the number of
the rules in the theory. The claim holds since every action in possible is a literal,
and the above procedure is completed ∣possible∣times.
3.4
Revising the Norm Base
We demonstrate the advantages of our approach – modularity, conﬁgurability,
and capability as an event recorder – through revising our norm base.
Inherent to Pac-Man’s environment is the possibility of encountering a state
where no compliant action is possible; in this section we explore how to address
cases like this through adding or removing rules to the norm base.
When playing “vegan” Pac-Man, we may encounter the case depicted in
Fig. 2(a). In absence of additional information Pac-Man will eat whichever ghost

573
(a)
(b)
(c)
Food pellet
Power pellet
Fig. 2. Pac-Man trapped between two ghosts (a) or in a corner (b). In (c) Pac-Man
consumes the power pellet and eats the ghost at the same time.
the policy indicates it should, and a violation report is generated. Each violation
report is saved as a timestamped ﬁle accompanied with the representation of
the current game state. This report can be used to retroactively examine the
context in which violations occur, and we can thereby revise our norm base
which is independent from the agent’s RL policy. In the case of “vegan” Pac-Man,
these reports make it clear that this version of the game will be susceptible to
somewhat regular violations in the form of Fig. 2(a).
If we consider instead “vegetarian” Pac-Man, we can restrict our norm base
to the vegan rule only applied to the blue ghost. However, situations in which
compliance is not possible can still occur; for instance the one depicted in Fig. 2(b),
or the case where Pac-Man consumes a power pellet and the blue ghost at the
same time, as shown in Fig. 2(c). In the latter case, the violation occurs because,
prior to Pac-Man’s consumption of the power pellet, the blue ghost is not scared
and Pac-Man’s strategy to comply with vegan will not be triggered. This is
roughly analogous to an agent committing an unethical act because it has no
way of recognizing that it is unethical.
Summarily, the violation reports show that there are four points in the maze
where Pac-Man, potentially, cannot comply, given the information he has access
to; in response, we add a norm danger steering Pac-Man away from these areas:
⇒O ¬enterpacman,danger
which is accompanied by constitutive norms deﬁning the abstract action of
“entering danger” (for some pre-deﬁned location denoted as danger), such as:
inNorthRangepacman,danger,inRangeghost,danger ⇒O ¬North
4
Evaluation and Conclusion
We have presented a modular and transparent approach that enables an au-
tonomous agent in pursuing ethical goals, while still running an RL policy that
maximizes its cumulative reward. Our approach was evaluated on six tests3,
in batches of 100 games. The results are displayed in the following table and
discussed below; we give data on both game performance (average score and
% games won) and ethical performance (ghosts eaten). Refer to Sec. 2 for a
thorough description of the testing environment.
The ﬁrst two baseline tests measured the performance of Pac-Man using two
diﬀerent (ethically agnostic) RL policies without the normative supervisor; this
establishes a baseline for Pac-Man’s game performance. We refer to the ﬁrst
3 We use a laptop with Intel i5-8250U CPU (4 cores, 1.60 GHz) and 8GB RAM, running
Ubuntu 18.04, Java 8, Python 2.7.
A Normative Supervisor for Reinforcement Learning Agents

574
E. Neufeld et al.
Test
Won Score (Avg [Max])
Avg ghosts eaten
RL policies without Normative Supervisor (Baseline tests)
1a – Safe
88 %
1189.4 [1526]
0.02 (blue)/0.03 (orange)
1b – Hungry
87 %
1503.5 [2133]
0.89 (blue)/ 0.81 (orange)
RL policies with Normative Supervisor
2a – SafeVegan
89 %
1193.39 [1526]
0.01 (blue)/0.02 (orange)
2b – HungryVegan 92 %
1211.67 [1350]
0.00 (blue)/0.00 (orange)
3 – Vegetarian
94 %
1413.8 [1742]
0.01 (blue)/0.79 (orange)
4 – SafeVegetarian 87 %
1336.2 [1747]
0.00 (blue)/0.88 (orange)
RL policy (in Test 1a) as safe because the algorithm used to train it does not
diﬀerentiate between regular ghosts and scared ghosts, learning how to avoid
them altogether. We refer to the other RL policy (in Test 1b) as hungry because
the corresponding algorithm diﬀerentiates between regular ghosts and scared
ghosts, and the agent learns how to eat the scared ghosts. The results for Test 1b
(average score of 1503.5 maximum score of 2133) were comparable to the baseline
version in [14] (average score of 1675.9, max score of 2144).
Tests 2a, 2b, 3, and 4 make use of the normative supervisor. In 2a and 2b, we
subject Pac-Man to a “vegan” norm base, prohibiting eating all ghosts (for both
the safe and hungry policies respectively). The results obtained for test 2a were
comparable to those in [14]: the average number of violations was the same in
both tests (0.03 ghosts), and our average score was only slightly smaller (1193.39
instead of 1268.5). Compared with the baseline, the game performance did not
suﬀer. For test 2b we obtained instead full compliance. Test 3 and 4 both use the
hungry policy. In test 3 we subject Pac-Man to a “vegetarian” norm base, where
only eating blue ghosts is forbidden. Allowing Pac-Man to eat one of the ghosts
allows him to further maximize his score and avoid the violations depicted in
Fig. 2(a). Test 4 addresses the two edge cases of non-compliance occurring in
Test 3 as depicted in Fig. 2(b) and Fig. 2(c) by adding the new rules deﬁned
in Sec. 3.4, steering Pac-Man away from entering the “dangerous” areas. Here,
violations were completely eliminated.
These tests, along with the analysis of the violation reports created in non-
compliant cases, yielded several insights. The module did not cause Pac-Man’s
game performance to suﬀer, and could successfully identify non-compliant be-
haviour. It implemented compliant behaviour in most cases, with the exception
of situations where compliance was not possible. The violation reports allowed us
to identify such situations with ease.
The game used in this paper oﬀers limited opportunities to work with mean-
ingful (ethical) norms. We aim to explore alternative case studies with more
options to deﬁne multiple (and possibly conﬂicting) ethical goals to test the
interactions between RL and a normative supervisor based on DDPL.

575
References
1. Aler Tubella, A., Dignum, V.: The glass box approach: Verifying contextual ad-
herence to values. In: Proc. of AISafety@IJCAI: Workshop on Artiﬁcial Intelli-
gence Safety co-located with the 28th International Joint Conference on Artiﬁ-
cial Intelligence. CEUR Workshop Proceedings, vol. 2419. CEUR-WS.org (2019),
http://ceur-ws.org/Vol-2419/paper 18.pdf
2. Aler Tubella, A., Theodorou, A., Dignum, F., Dignum, V.: Governance by glass-box:
Implementing transparent moral bounds for AI behaviour. In: Proc. of IJCAI 2019:
the 28th International Joint Conference on Artiﬁcial Intelligence. pp. 5787–5793.
ijcai.org (2019). https://doi.org/10.24963/ijcai.2019/802
3. Andrighetto, G., Governatori, G., Noriega, P., van der Torre, L.W.N. (eds.): Nor-
mative Multi-Agent Systems, Dagstuhl Follow-Ups, vol. 4. Schloss Dagstuhl -
Leibniz-Zentrum fuer Informatik (2013), http://drops.dagstuhl.de/opus/portals/
dfu/index.php?semnr=13003
4. Boella, G., van der Torre, L.: Regulative and constitutive norms in normative
multiagent systems. In: Proc. of KR 2004: the 9th International Conference on
Principles of Knowledge Representation and Reasoning. pp. 255–266. AAAI Press
(2004), http://www.aaai.org/Library/KR/2004/kr04-028.php
5. Bremner, P., Dennis, L.A., Fisher, M., Winﬁeld, A.F.T.: On proactive, transparent,
and veriﬁable ethical reasoning for robots. Proc. IEEE 107(3), 541–561 (2019).
https://doi.org/10.1109/JPROC.2019.2898267
6. Broersen, J., Dastani, M., Hulstijn, J., Huang, Z., van der Torre, L.: The boid archi-
tecture: conﬂicts between beliefs, obligations, intentions and desires. In: Proceedings
of the ﬁfth international conference on Autonomous agents. pp. 9–16 (2001)
7. DeNero, J., Klein, D.: UC Berkeley CS188 intro to AI – course materials (2014)
8. Governatori, G., Olivieri, F., Rotolo, A., Scannapieco, S.: Computing strong and
weak permissions in defeasible logic. Journal of Phil. Logic 42(6), 799–829 (2013).
https://doi.org/10.1007/s10992-013-9295-1
9. Governatori, G., Rotolo, A.: BIO logical agents: Norms, beliefs, intentions in
defeasible logic. Journal of Autonomous Agents and Multi Agent Systems 17(1),
36–69 (2008). https://doi.org/10.1007/s10458-008-9030-4
10. Hasanbeig, M., Kantaros, Y., Abate, A., Kroening, D., Pappas, G.J., Lee, I.: Rein-
forcement learning for temporal logic control synthesis with probabilistic satisfaction
guarantees. In: Proc. of CDC 2019: the 58th IEEE Conference on Decision and
Control. pp. 5338–5343 (2019). https://doi.org/10.1109/CDC40024.2019.9028919
11. Lam, H.P., Governatori, G.: The making of SPINdle. In: Proc. of RuleML 2009:
International Symposium on Rule Interchange and Applications. LNCS, vol. 5858,
pp. 315–322. Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-642-04985-
9
12. Lam, H.P., Governatori, G.: Towards a model of UAVs navigation in urban canyon
through defeasible logic. Journal of Logic and Computation 23(2), 373–395 (2013).
https://doi.org/10.1007/978-3-642-04985-9
13. Levine, S., Finn, C., Darrell, T., Abbeel, P.: End-to-end training of deep visuomotor
policies. Journal of Machine Learning Research 17, 39:1–39:40 (2016), http://jmlr.
org/papers/v17/15-522.html
14. Noothigattu, R., Bouneﬀouf, D., Mattei, N., Chandra, R., Madan, P., Varshney,
K.R., Campbell, M., Singh, M., Rossi, F.: Teaching ai agents ethical values using
reinforcement learning and policy orchestration. In: Proceedings of the Twenty-
Eighth International Joint Conference on Artiﬁcial Intelligence, IJCAI-19. pp. 6377–
A Normative Supervisor for Reinforcement Learning Agents

576
E. Neufeld et al.
6381. International Joint Conferences on Artiﬁcial Intelligence Organization (7 2019).
https://doi.org/10.24963/ijcai.2019/891, https://doi.org/10.24963/ijcai.2019/891
15. Nowell-Smith, P.H., Lemmon, E.J.: Escapism: The logical basis of ethics. Mind
69(275), 289–300 (1960)
16. Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez,
A., Hubert, T., Baker, L., Lai, M., Bolton, A., Chen, Y., Lillicrap, T.P., Hui,
F., Sifre, L., van den Driessche, G., Graepel, T., Hassabis, D.: Mastering the
game of Go without human knowledge. Nature 550(7676), 354–359 (2017).
https://doi.org/10.1038/nature24270
17. Von Wright, G.H.: An essay in deontic logic and the general theory of action. Acta
Philosophica Fennica 21 (1968)
18. Watkins, C.J.C.H.: Learning from Delayed Rewards. Ph.D. thesis, King’s College,
Cambridge, UK (May 1989), http://www.cs.rhul.ac.uk/∼chrisw/new thesis.pdf
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium or
format, as long as you give appropriate credit to the original author(s) and the source,
provide a link to the Creative Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Automatically Building Diagrams for Olympiad
Geometry Problems
1 University of Oxford, Oxford, UK
2 University of Pittsburgh, Pittsburgh PA, USA
3 Microsoft Research, Redmond WA, USA
Abstract. We present a method for automatically building diagrams
for olympiad-level geometry problems and implement our approach in
a new open-source software tool, the Geometry Model Builder (GMB).
Central to our method is a new domain-speciﬁc language, the Geometry
Model-Building Language (GMBL), for specifying geometry problems
along with additional metadata useful for building diagrams. A GMBL
program speciﬁes (1) how to parameterize geometric objects (or sets
of geometric objects) and initialize these parameterized quantities, (2)
which quantities to compute directly from other quantities, and (3) ad-
ditional constraints to accumulate into a (diﬀerentiable) loss function.
A GMBL program induces a (usually) tractable numerical optimization
problem whose solutions correspond to diagrams of the original prob-
lem statement, and that we can solve reliably using gradient descent.
Of the 39 geometry problems since 2000 appearing in the International
Mathematical Olympiad, 36 can be expressed in our logic and our sys-
tem can produce diagrams for 94% of them on average. To the best of
our knowledge, our method is the ﬁrst in automated geometry diagram
construction to generate models for such complex problems.
1
Introduction
Automated theorem provers for Euclidean geometry often use numerical models
(i.e. diagrams) for heuristic reasoning, e.g. for conjecturing subgoals, pruning
branches, checking non-degeneracy conditions, and selecting auxiliary construc-
tions. However, modern solvers rely on diagrams that are either supplied man-
ually [7,24] or generated automatically via methods that are severely limited in
scope [12]. Motivated by the IMO Grand Challenge, an ongoing eﬀort to build
an AI that can win a gold medal at the International Mathematical Olympiad
(IMO), we present a method for expressing and solving olympiad-level systems
of geometric constraints.
Historically, algebraic methods are the most complete and performant for
automated geometry diagram construction but suﬀer from degenerate solutions
© The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
88
https://doi.org/10.1007/978-3-030-79876-5 33
Ryan Krueger1
, Jesse Michael Han2, and Daniel Selsam3
577–588, 2021.

578
R. Krueger et al.
Fig. 1: An example GMBL program and corresponding diagram generated by
the GMB for IMO 2010 Problem 2.
and, in the numerical case, non-convexity. These methods are restricted to rela-
tively simple geometric conﬁgurations as poor local minima arise via large num-
bers of parameters. Moreover, degenerate solutions manifest as poor distribu-
tions for the vertices of geometric objects (e.g. a non-sensical triangle) as well
as intersections of objects at more than one point (e.g. lines and circles, circles
and circles).
We constructed a domain-speciﬁc language (DSL), the Geometry Model-
Building Language (GMBL), to express geometry problems whose semantics
induce tractable numerical optimization problems. The GMBL includes a set
of commands with which users introduce geometric objects and constraints be-
tween these objects. There is a direct interpretation from these commands to the
parameterization of geometric objects, the computation of geometric quantities
from existing ones, and additional numerical constraints. The GMBL employs
root selector declarations to disambiguate multiple solution problems, reparam-
eterizations both to reduce the number of parameters and increase uniformity in
model variance, and joint distributions for geometric objects that are susceptible
to degeneracy (i.e. triangles and polygons). Our DSL treats points, lines, and
circles as ﬁrst-class citizens, and the language can be easily extended to support
additional high-level features in terms of these primitives.
We provide an implementation of our method, the Geometry Model Builder
(GMB), that compiles GMBL programs into Tensorﬂow computation graphs [1]
and generates models via oﬀ-the-shelf, gradient-based optimization. Figure 2
demonstrates an overview of this implementation. Experimentally, we ﬁnd that
the GMBL suﬃciently reduces the parameter space and mitigates degeneracy to
make our target geometry amenable to numerical optimization. We tested our
method on all IMO geometry problems since 2000 (n = 39), of which 36 can
be expressed as GMBL programs. Using default parameters, the GMB ﬁnds a
single model for 94% of these 36 problems in an average of 27.07 seconds. Of
the problems for which our program found a model and the goal of the problem
could be stated in our DSL, the goal held in the ﬁnal model 86% of the time.

Automatically Building Diagrams for Olympiad Geometry Problems
579
All code is available on GitHub4 with which users can write GMBL programs
and generate diagrams. Our program can be run both as a command-line tool
for integration with theorem provers or as a locally-hosted web server.
2
Background
Here we provide an overview of olympiad-level geometry problem statements, as
well as several challenges presented by the associated constraint problems.
2.1
Olympiad-Level Geometry Problem Statements
IMO geometry problems are stated as a sequential introduction of potentially-
constrained geometric objects, as well as additional constraints between entities.
Such constraints can take one of two forms: (1) geometric constraints describe
the relative position of geometric entities (e.g. two lines are parallel) while (2)
dimensional constraints enforce speciﬁc numerical values (e.g. angle, radius).
Lastly, problems end with a goal (or set of goals) typically in the form of geo-
metric or dimensional constraints. The following is an example from IMO 2009:
Let ABC be a triangle with circumcentre O. The points P and Q are
interior points of the sides CA and AB, respectively. Let K, L, and M
be the midpoints of the segments BP, CQ, and PQ, respectively, and
let Γ be the circle passing through K, L, and M. Suppose that the line
PQ is tangent to the circle Γ. Prove that OP = OQ.
(IMO 2009 P2)
This problem introduces ten named geometric objects and has a single goal.
Note that this class of problems does not admit a mathematical description
but rather is deﬁned empirically (i.e. as those problems selected for olympiads).
The overwhelming majority of these problems are of a particular type – plane
geometry problems that can be expressed as problems in nonlinear real arith-
metic (NRA). However, while NRA is technically decidable, olympiad problems
tend to be littered with order constraints and complex constructions (e.g. mixti-
linear incenter) and be well beyond the capability of existing algebraic methods.
On the other hand, they are selected to admit elegant, human-comprehensible
proofs. It is this class of problems for which the GMBL was designed to express;
though rare, any particular olympiad geometry problem is not guaranteed to be
of this type and therefore is not necessarily expressible in the GMBL.
2.2
Challenge: Globally Coupled Constraints
A na¨ıve approach to generate models would incrementally instantiate objects
via their immediate constraints. For (IMO 2009 P2), this would work as follows:
1. Sample points A, B, and C.
4 https://github.com/rkruegs123/geo-model-builder

580
R. Krueger et al.
Fig. 2: An overview of our method. Our program takes as input a GMBL program
and translates it to a set of real-valued parameters and diﬀerentiable losses in the
form of a static computation graph. We then apply gradient-based optimization
to obtain numerical models and display them as diagrams.
2. Compute O as the circumcenter of ΔABC.
3. Sample P and Q on the segments CA and AB, respectively.
4. Compute K, L, and M as the midpoints of BP, CQ, and PQ, respectively.
5. Compute Γ as the circle deﬁned by K, L, and M.
Immediately we see a problem – there is no guarantee that PQ is tangent to Γ
in the ﬁnal model. Indeed, the constraints of (IMO 2009 P2) are quite globally
coupled – the choice of P partially determines the circle Γ to which PQ must
be tangent, and every choice of ΔABC does not even admit a pair P and Q
satisfying this constraint. This is an example of the frequent non-constructive
nature of IMO geometry problems. When there is no obvious reparameterization
to avoid downstream eﬀects, all constraints must be considered simultaneously
rather than incrementally or as a set of smaller local optimization problems.
2.3
Challenge: Root Resolution
Even in the constructive case, local optimization is not necessarily suﬃcient given
that multiple solutions can exist for algebraic constraints. More speciﬁcally, two
circles or a circle and a line intersect at up to two distinct points and in a
problem that speciﬁes each distinct intersection point, the correct root to assign
is generally not locally deducible. Without global information, this can lead to
poor initializations becoming trapped in local minima. The GMBL accounts for
this by including a set of explicit root selectors as described in Section 3.3. These
root selectors provide global information for selecting the appropriate point from
a set of multiple solutions to a system of equations.
3
Methods
In this section we present the GMBL and GMB in detail. In our presentation,
we make use of the following notation and deﬁnitions:
– The type of a geometric object can be one of (1) point, (2) line, or (3)
circle. We denote the type of a real-valued number as number.
– We use <> to denote an instance of a type.
– A name is a string value that refers to a geometric object.

Automatically Building Diagrams for Olympiad Geometry Problems
581
3.1
GMBL: Overview
The GMBL is a DSL for expressing olympiad-level geometry problems that loss-
lessly induces a numerical optimization problem. It consists of four commands,
each of which has a direct interpretation regarding the accumulation of (1) real-
valued parameters and (2) diﬀerentiable losses in terms of these parameters:
1. param: assigns a name to a new geometric object parameterized either by a
default or optionally supplied parameterization
2. define: assigns a name to an object computed in terms of existing ones
3. assert: imposes an additional constraint (i.e. diﬀerentiable loss value)
4. eval: evaluates a given constraint in the ﬁnal model(s)
Table 1 provides a summary of their usage. The GMBL includes an extensible
library of functions and predicates with which commands are written. Notably,
this library includes a notion of root selection to explicitly resolve the selection
of roots to systems of equations with multiple solutions.
3.2
GMBL: Commands
In the following, we describe in more detail the usage of each command and their
roles in constructing a tractable numerical optimization problem.
param accepts as arguments a string, a type, and an optional parameter-
ization. This introduces a geometric object that is parameterized either by the
default parameterization for <type> or by the supplied method. Each primitive
geometric type has the following default parameterization:
– point: parameterized by its x- and y-coordinates
– line: parameterized by two points that deﬁne the line
– circle: parameterized by its origin and radius
Optional parameterizations embody our method’s use of reparameterization to
decrease the number of parameters and increase model diversity. For example,
consider a point C on the line ←→
AB that is subject to additional constraints. Rather
than optimizing over the x- and y-coordinates of C, we can express C in terms
of a single value z that scales C’s placement on the line ←→
AB.
In addition to the standard usage of param outlined above, the GMBL in-
cludes an important variant of this command to introduce sets of points that
form triangles and polygons. This variant accepts as arguments (1) a list of point
names, and (2) a required parameterization (see Table 1). This joint parameter-
ization of triangles and polygons further prevents degeneracy. For example, to
initialize a triangle ΔABC, we can sample the vertices from normal distribu-
tions with means at distinct thirds of the unit circle. This method minimizes the
sampling of triangles with extreme angle values, as well as allows for explicit con-
trol over the distribution of acute vs. obtuse triangles by adjusting the standard
deviations. Appendix C includes a list of all available parameterizations.5
5 All appendices can be found in the long version of this paper [15].

582
R. Krueger et al.
Table 1: An overview of usage for the four commands.
Command
Usage
param
(param <string> <type> <optional-parameterization>)
or
(param (<string>, ..., <string>) <parameterization>)
define
(define <string> <type> <value>)
assert
(assert <predicate>)
eval
(eval <predicate>)
define accepts as arguments a string, a type, and a value that is one
of <point>, <line>, or <circle>. This command serves as a basic assignment
operator and is useful for caching commonly used values. The functions described
in Section 3.3 are used to construct <value> from existing geometric objects.
assert accepts a single predicate and imposes it as an additional constraint
on the system. This is achieved by translating the predicate to a set of algebraic
values and registering them as losses. This command does not introduce any new
geometric objects and can only refer to those already introduced by param or
define. Notably, dimensional constraints and negations are always enforced via
assert. Detail on supported predicates is presented in Section 3.3.
eval, like assert, accepts a single predicate and therefore does not in-
troduce any new geometric objects. However, unlike assert, the corresponding
algebraic values are evaluated and returned with the ﬁnal model rather than
registered as losses and enforced via optimization. This command is most useful
for those interested in integrating the GMBL with theorem provers.
3.3
GMBL: Functions and Predicates
The second component of our DSL is a set of functions and predicates for con-
structing arguments to the commands outlined above. Functions construct new
geometric objects and numerical values whereas predicates describe relationships
between them. Our DSL includes high-level abstractions for common geometric
concepts in olympiad geometry (e.g. excircle, isotomic conjugate).
Functions in the GMBL employ a notion of root selectors to address the
“multiple solutions problem” described in Section 2.3. In plane geometry, this
problem typically manifests with multiple candidate point solutions, such as the
intersection between a line and a circle. Root selectors control for this by allowing
users to specify the appropriate point for functions with multiple solutions.
Figure 3 demonstrates their usage in the functions inter-lc (intersection of a
line and circle) and inter-cc (intersection of two circles).
Importantly, arguments to predicates and functions can be speciﬁed with
functions rather than named geometric objects. For a list of supported functions,
predicates, and root selectors, refer to Appendices A, B, and C, respectively.

Automatically Building Diagrams for Olympiad Geometry Problems
583
(a) A GMBL program that uses root selectors.
(b) A corresponding diagram.
Fig. 3: An example usage of root selectors to resolve the intersections of lines
and circles, and circles and circles.
3.4
Auxiliary Losses
The optimization problem encoded by a GMBL progran includes three additional
loss values. Foremost, for every instance of a circle intersecting a line or other
circle, we impose a loss value that ensures the two geometric objects indeed
intersect. The ﬁnal two, albeit opposing losses are intended to minimize global
degeneracy. We impose one loss that minimizes the mean of all point norms
to prevent exceptionally separate objects and a second to enforce a suﬃcient
distance between points to maintain distinctness.
3.5
Implementation
We built the GMB, an open-source implementation that compiles GMBL pro-
grams to optimization problems and generates models. The GMB takes as input
a GMBL program and processes each command in sequence to accumulate real-
valued parameters and diﬀerentiable losses in a Tensorﬂow computation graph.
After registering auxiliary losses , we apply oﬀ-the-shelf gradient-based local op-
timization to produce models of the constraint system. In summary, to generate
N numerical models, our optimization procedure works as follows:
1. Construct computation graph by sequentially processing commands.
2. Register auxiliary losses.
3. Sample sets of initial parameter values and rank via loss value.
4. Choose (next) best initialization and optimize via gradient descent.
5. Repeat (4) until obtaining N models or the maximum # of tries is reached.
Our program accepts as arguments (1) the # of models desired (default = 1),
(2) the # of initializations to sample (default = 10), and (3) the max # of
optimization tries (default = 3). Our program also accepts the standard suite
of parameters for training a Tensorﬂow model, including an initial learning rate
(default = 0.1), a decay rate (default = 0.7), the max # of iterations (default =
5000), and an epsilon value (default = 0.001) to determine stopping criteria.

584
R. Krueger et al.
Table 2: An evaluation of our method’s ability to generate a single model for
each of the 36 IMO problems encoded in our DSL. For each problem, 10 sets of
initial parameters were sampled over which our program optimized up to three.
All data shown are the average of three trials. The ﬁrst row demonstrates results
using default parameters (ϵ = 0.001, learning rate = 0.1, # iterations = 5, 000).
ϵ
Learning
Rate
Iterations
% Success
% Goal
Satisfaction
Time per Problem (s)
All
Fail
Success
0.001
0.1
5,000
93.52
85.84
27.07
223.51
14.72
0.01
0.1
5,000
92.60
84.71
26.86
229.71
14.43
0.001
0.01
5,000
88.88
86.32
27.54
137.85
14.33
0.001
0.1
10,000
92.59
86.02
34.78
287.51
15.43
4
Results
In this section, we present an evaluation of our method’s proﬁciency in three
areas of expressing and solving olympiad-level geometry problems:
1. Expressing olympiad-level geometry problems as GMBL programs.
2. Generating models for these programs.
3. Preserving truths (up to tolerance) that are not directly optimized for.
Table 2 contains a summary of our results.
Our evaluation considers all 39 IMO geometry problems since 2000. Of these
39 problems, 36 can be expressed in our DSL. Those that we cannot encode
involve variable numbers of geometric objects. For 32 of these 36 problems, we
can express the goals as eval commands in the corresponding GMBL programs.
The goals of the additional four problems are not expressible in our DSL, e.g.
our DSL cannot express goals of the form “Find all possible values of ∠ABC.”
To evaluate (2) and (3), we conducted three trials in which we ran our pro-
gram on each of the 36 encodings with varying sets of arguments. With default
arguments, our program generated a single model for (on average) 94% of these
problems. Our program ran for an average of 27.07 seconds for each problem but
there is a stark diﬀerence between time to success and time to failure (14.72 vs
223.51 seconds) as failure entails completing all optimization attempts whereas
successful generation of a model terminates the program. We achieve similar
success rates with more forgiving training arguments or a higher tolerance.
For use in automated theorem proving, it is essential that models generated
by our tool not only satisfy the constraint problem up to tolerance but also any
other truths that follow from the set of input constraints. The most immediate
example of such a truth is the goal of a problem statement. Therefore, we used
the goals of IMO geometry problems as a proxy for this ability by only checking
the satisfaction of the goal in the ﬁnal model (i.e. with an eval statement)

Automatically Building Diagrams for Olympiad Geometry Problems
585
rather than directly optimizing for it. In our experiments, we considered such a
goal satisﬁed if it held up to ϵ ∗10 as it is reasonable to expect slightly higher
ﬂoating-point error without explicit optimization. Using default parameters, the
goal held up to tolerance in 86% of problems for which we found a model and
could express the goal. This rate was similar across all other sets of arguments.
5
Future Work
Here we discuss various opportunities for improvement of our method.
Firstly, improvements could be made to our method of numerical optimiza-
tion. While Tensorﬂow oﬀers a convenient way of caching terms via a static
computation graph and optimizing directly over this representation, there is not
explicit support for constrained optimization. Because of this, arbitrary weights
have to be assigned to each loss value. Though rare, this can result in false
positives and negatives for the satisfaction of a constraint. Using an explicit
constrained-optimization method (e.g. SLSQP) would enable the separation of
soft constraints (e.g. maximizing the distance between points) and hard con-
straints (e.g. those enforced by assert), removing the need for arbitrary weights.
Secondly, cognitive overhead could be reduced as users are currently required
to determine degrees of freedom; it would be far easier to write problem state-
ments using only declarations of geometric objects and constraints between them,
e.g. using only assert. This could be accomplished by treating our DSL as a
low-level “instruction set” to which a higher-level language could be compiled.
The main challenge of such a compiler would be appropriately identifying op-
portunities to reduce the degrees of freedom. To achieve this, the compiler would
require a decision procedure for line and circle membership.
Lastly, we could improve our current treatment of distinctness. To prevent
degenerate solutions, our method optimizes for object distinctness and rejects
models with duplicates. However, there is the occasional problem for which a
local optimum encodes two provably distinct points as equal up to ﬂoating point
tolerance. There are many techniques that could be applied to this problem (e.g.
annealing) though we do not consider them here as the issue is rare.
6
Related Work
Though many techniques for mechanized geometry diagram construction have
been introduced over the decades, no method, to the best of our knowledge, can
produce models for more than a negligible fraction of olympiad problems. There
exist many systems, built primarily for educational purposes, for interactively
generating diagrams using ruler-and-compass constructions, e.g. GCLC [13], Ge-
oGebra [11], Geometer’s Sketchpad [20], and Cinderella [19]. There are also non-
interactive methods for deriving such constructions, e.g. GeoView [2] and pro-
gram synthesis [9,12]. However, as discussed in Section 2.2, very few olympiad
problems can be described in such a form. Alternatively, Penrose is an early-
stage system for translating mathematical descriptions to diagrams that relies

586
R. Krueger et al.
on constrained numerical optimization and therefore does not suﬀer from this
expressivity limitation [25]. However, this system lacks support for constraints
with multiple roots, e.g. intersecting circles. There are more classical methods
that similarly depart from constructive geometry. MMP/Geometer [8] translates
the problem to a set of algebraic equations and uses numerical optimization
(e.g. BFGS) and GEOTHER [22, 23] ﬁrst translates a predicate speciﬁcation
into polynomial equations, decomposes this system into representative triangu-
lar sets, and obtains solutions for each set numerically. Neither of these programs
are available to evaluate though we did test similar approaches using modern li-
braries (speciﬁcally: sympy [17] and scipy [21]) and both numerical and symbolic
methods would almost always timeout on relatively simple olympiad problems.
Generating models for systems of geometric constraints is also a challenge
in computer-aided design (CAD) for engineering diagram drawing. Recent ef-
forts focus on graph-based synthetic methods, a subset of techniques concerned
with ruler-and-compass constructions [3,5,6,10,14,16,18]. Most relevant to our
method are Bettig and Shah’s “solution selectors” which, similar to root selec-
tors in the GMBL, allow users to specify the conﬁguration of a CAD model [4].
However, these solution selectors are purpose-built and do not generalize.
7
Conclusion
It is standard in GTP to rely on diagrams for heuristic reasoning but the scale
of automatic diagram construction is limited. To enable eﬀorts to build a solver
for IMO geometry problems, we developed a method for building diagrams for
olympiad-level geometry problems. Our method is based on the GMBL, a DSL
for expressing geometry problems that induces (usually) tractable numerical op-
timization problems. The GMBL includes a set of commands that have a direct
interpretation for accumulating real-valued parameters and diﬀerentiable losses.
Arguments to these commands are constructed with a library of functions and
predicates that includes notions of root selection, joint distributions, and repa-
rameterizations to minimize degeneracy and the number of parameters. We im-
plemented our approach in an open-source tool that translates GMBL programs
to diagrams. Using this program, we evaluated our method on all IMO geometry
problems since 2000. Our implementation reliably produces models; moreover,
known truths that are not directly optimized for typically hold up to tolerance.
By handling conﬁgurations of this complexity, our system clears a roadblock in
GTP and provides a critical tool for undertakers of the IMO Grand Challenge.
References
1. M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghe-
mawat, G. Irving, M. Isard, et al. Tensorﬂow: A system for large-scale machine
learning. In 12th USENIX symposium on operating systems design and implemen-
tation (OSDI 16), pages 265–283, 2016.

Automatically Building Diagrams for Olympiad Geometry Problems
587
2. Y. Bertot, F. Guilhot, and L. Pottier. Visualizing geometrical statements with
GeoView. Electronic Notes in Theoretical Computer Science, 103:49–65, 2004.
3. B. Bettig and C. M Hoﬀmann.
Geometric constraint solving in parametric
computer-aided design.
Journal of computing and information science in engi-
neering, 11(2), 2011.
4. B. Bettig and J. Shah. Solution selectors: a user-oriented answer to the multiple
solution problem in constraint solving. J. Mech. Des., 125(3):443–451, 2003.
5. B. N. Freeman-Benson, J. Maloney, and A. Borning. An incremental constraint
solver. Communications of the ACM, 33(1):54–63, 1990.
6. I. Fudos. Constraint solving for computer aided design. PhD thesis, Verlag nicht
ermittelbar, 1995.
7. W. Gan, X. Yu, T. Zhang, and M. Wang. Automatically proving plane geometry
theorems stated by text and diagram. International Journal of Pattern Recognition
and Artiﬁcial Intelligence, 33(07):1940003, 2019.
8. X.-S. Gao and Q. Lin. Mmp/geometer–a software package for automated geometric
reasoning. In International Workshop on Automated Deduction in Geometry, pages
44–66. Springer, 2002.
9. S. Gulwani, V. A. Korthikanti, and A. Tiwari. Synthesizing geometry construc-
tions. ACM SIGPLAN Notices, 46(6):50–61, 2011.
10. C. M. Hoﬀmann and R. Joan-Arinyo. Parametric modeling. In Handbook of com-
puter aided geometric design, pages 519–541. Elsevier, 2002.
11. M. Hohenwarter and M. Hohenwarter. GeoGebra.
12. S. Itzhaky, S. Gulwani, N. Immerman, and M. Sagiv.
Solving geometry prob-
lems using a combination of symbolic and numerical reasoning. In International
Conference on Logic for Programming Artiﬁcial Intelligence and Reasoning, pages
457–472. Springer, 2013.
13. P. Janiˇci´c. GCLC—a tool for constructive euclidean geometry and more than that.
In International Congress on Mathematical Software, pages 58–73. Springer, 2006.
14. G. A. Kramer. Solving geometric constraint systems. In AAAI, pages 708–714,
1990.
15. R. Krueger, J. M. Han, and D. Selsam.
Automatically Building Diagrams for
Olympiad Geometry Problems. arXiv preprint arXiv:2012.02590, 2020.
16. R. S. Latham and A. E. Middleditch. Connectivity analysis: a tool for processing
geometric constraints. Computer-Aided Design, 28(11):917–928, 1996.
17. A. Meurer, C. P. Smith, M. Paprocki, O. ˇCert´ık, S. B. Kirpichev, M. Rocklin,
A. Kumar, S. Ivanov, J. K. Moore, S. Singh, et al. SymPy: symbolic computing in
Python. PeerJ Computer Science, 3:e103, 2017.
18. J. C. Owen. Algebraic solution for geometry from dimensional constraints. In Pro-
ceedings of the ﬁrst ACM symposium on Solid modeling foundations and CAD/-
CAM applications, pages 397–407, 1991.
19. J. Richter-Gebert and U. H. Kortenkamp. The Cinderella. 2 Manual: Working with
The Interactive Geometry Software. Springer Science & Business Media, 2012.
20. D. Scher. Lifting the curtain: The evolution of the Geometer’s Sketchpad. The
Mathematics Educator, 10(2), 1999.
21. P. Virtanen, R. Gommers, T. E. Oliphant, M. Haberland, T. Reddy, D. Courna-
peau, E. Burovski, P. Peterson, W. Weckesser, J. Bright, et al. SciPy 1.0: fundamen-
tal algorithms for scientiﬁc computing in Python. Nature methods, 17(3):261–272,
2020.
22. D. Wang. Geother 1.1: Handling and proving geometric theorems automatically.
In International Workshop on Automated Deduction in Geometry, pages 194–215.
Springer, 2002.

588
R. Krueger et al.
23. D. Wang. Automated generation of diagrams with Maple and Java. In Algebra,
Geometry and Software Systems, pages 277–287. Springer, 2003.
24. K. Wang and Z. Su. Automated geometry theorem proving for human-readable
proofs. In Twenty-Fourth International Joint Conference on Artiﬁcial Intelligence,
2015.
25. K. Ye, W. Ni, M. Krieger, D. Ma’ayan, J. Wise, J. Aldrich, J. Sunshine, and
K. Crane.
Penrose: from mathematical notation to beautiful diagrams.
ACM
Transactions on Graphics (TOG), 39(4):144–1, 2020.
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

The Fusemate Logic Programming System
Data61/CSIRO and The Australian National University, Canberra, Australia
Peter.Baumgartner@data61.csiro.au
Abstract. Fusemate is a logic programming system that implements the possible
model semantics for disjunctive logic programs. Its input language is centered
around a weak notion of stratiﬁcation with comprehension and aggregation oper-
ators on top of it. Fusemate is implemented as a shallow embedding in the Scala
programming language. This enables using Scala data types natively as terms, a
tight interface with external systems, and it makes model computation available
as an ordinary container data structure constructor. The paper describes the above
features and implementation aspects. It also demonstrates them with a non-trivial
use-case, the embedding of the description logic ALCIF into Fusemate’s input
language.
1
Introduction
Fusemate1 is a logic programming system for computing possible models of disjunctive
logic programs [23,24]. A Fusemate logic program consists of (typically) non-ground
if-then rules with stratiﬁed default negation in the body [21]. Stratiﬁcation entails that a
true default-negated body literal remains true in the course of deriving new conclusions.
Fusemate was introduced in [7] for modelling systems that evolve over time and
for analysing their current state based on the events so far. Such tasks are often sub-
sumed under the terms of stream processing, complex event recognition, and situational
awareness, and have been addressed (also) with logic-based approaches [2,9,4,5].
To my knowledge, Fusemate is unique among all these and other logic programming
systems [12,1,13,26,16] (and theorem provers) in the way it is implemented. Fusemate is
implemented by shallow embedding in a full-ﬂedged programming language, Scala [25].
Essentially, the user writes a syntactically sugared Scala program utilizing familiar
logic programming notation, and the program’s execution returns models. This has
advantages and disadvantages. The main disadvantages is that it is more diﬃcult to
implement performance boosting measures like term indexing. The main advantage is
that interfacing with data structure libraries and with external systems is easy, an aspect
whose importance has been emphasized for virtually all of the above systems. In fact,
Fusemate is motivated in parts by exploring how far the embedding approach can be
pushed and to what beneﬁt.
The earlier Fusemate paper [7] focused on the model computation calculus with a
belief revision operator as the main novelty. It utilized a certain notion of stratiﬁcation
1 Fusemate is available at https://bitbucket.csiro.au/users/bau050/repos/fusemate/.
© The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5_34
Peter Baumgartner
589–601, 2021.

590
P. Baumgartner
by time (SBT) for making the calculus eﬀective and useful in the intended application
areas. This system description focuses on the advantages of the shallow embedding
approach as boosted by new language features introduced here. These new language
features are (a) non-standard comprehension and aggregation operators, among others,
and (b) a weaker notion of stratiﬁcation by time and predicates (SBTP). In brief, SBTP
is a lexicographic combination of stratiﬁcation by time and the standard stratiﬁcation
in terms of the call-graph of the program. Section 5 has an example that demonstrates
the need for (a) and (b) in combination, and Section 4 discusses the shallow embedding
approach and its advantages on a more general level.
Here is an excerpt from a Fusemate program that previews some of the new features:
1 type Time = java.time.LocalDateTime
2 val allIds = 1 to 10
3 case class Change(time:Time, id:Int, color:String) extends Atom
4 case class State(time:Time, id:Int, color:String) extends Atom
5 case class FullState(time:Time, drive:Set[Int], stop:Set[Int]) extends Atom
6 State(time, id, color) :- Now(time), CHOOSE(id:Int, allIds), Change(t <= time, id, color)
7 FullState(time, drive.toSet, stop.toSet) :- State(time,_,_),
8
COLLECT(drive:List[Int], id STH State(time, id, "green")),
9
COLLECT(stop:List[Int], id STH (State(time, id, color), color=="red" || color=="yellow"))
10 MovingState(time) :- FullState(time, drive, stop), stop.size < drive.size
11 Faulty(time, id, since) :- State(time, id, "red"), Change(since < time, id, "green"),
12
NOT (Change(t, id, "yellow"), since < t, t < time)
The scenario comprises traﬃc lights identiﬁed by numbers 1 to 10 (line 2). In the
course of time the traﬃc lights change their colors, and each such event is recorded as
a corresponding Change atom (line 3). The rule on line 6 computes a State at a current
time Now(time) as a snapshot of the current colors of all traﬃc lights. For that, the
comprehension Change(t <=time,id,color) on line 6 ﬁnds the latest Change event before or
at time for a ﬁxed id chosen from allIds, and binds that time to the (unused) variable t. A
FullState aggregates the separate State facts at a time partitioned as (Scala) sets of ids of
“drive” and “stop” colors. In that, the COLLECT special form collects in a Scala List-typed
variable the speciﬁed terms that satisfy the body behind STH. Notice that all atoms in
FullState refer to the same time, yet the program is SBTP because State comes before
FullState in predicate stratiﬁcation. (Predicate stratiﬁcation is computed automatically
by Fusemate with Tarjan’s algorithm.) The rule on line 10 demonstrates the use of the
Scala Set method size in the body. Line 11 demonstrates the use of default negation in
combination with comprehension. When applied to a given sequence of Change events,
Fusemate computes models, one-at-a-time, each as Scala set of atoms.
2
Fusemate Programs
For the purpose of this paper, a brief summary of the syntactic notions underlying
Fusemate programs is suﬃcient; see [7] for details. Terms and atoms of a given signature
are deﬁned as usual. Let var(𝑧) denote the set of variables occurring in an expression
𝑧. We say that 𝑧is ground if var(𝑧) = ∅. We write 𝑧𝜎for applying a substitution 𝜎to

𝑧. The domain of 𝜎is denoted by dom(𝜎). A substitution 𝛾is a grounding substitution
for 𝑧iﬀdom(𝛾) = var(𝑧) and 𝑧𝛾is ground. In this case we simply say that 𝛾is for 𝑧.
Let T be a countably inﬁnite discrete set of time points equipped with a total strict
ordering < (“earlier than”), e.g., the integers. Assume that the time points, comparison
operators = and ≤, and a successor time function +1 are part of the signature and
interpreted in the intended way. A time term is a (possibly non-ground) term over the
sub-signature T ∪{+1}.
The signature may contain other “built-in” predicate and function symbols for pre-
deﬁned types such as strings, arithmetic data types, sets, etc. We only informally assume
that all terms are built in a well-sorted way and that built-in operators over ground terms
can be evaluated eﬀectively.
An ordinary atom (with time term 𝑡) is of the form 𝑝(𝑡, 𝑡1, . . . , 𝑡𝑛) where 𝑝is an
ordinary predicate (i.e., neither a time predicate nor built-in), 𝑡is a time term and
𝑡1, . . . , 𝑡𝑛terms. A (Fusemate) rule is an implication written in Prolog-like syntax as
𝐻:- 𝑏1, . . . , 𝑏𝑘, not 𝑏𝑘+1, . . . , not 𝑏𝑛.
(1)
In (1), a rule head 𝐻is either (a) a disjunction ℎ1 ∨· · · ∨ℎ𝑚of ordinary atoms, for
some 𝑚≥1, or (b) the expression fail.2 In case (a) the rule is ordinary and in case
(b) it is a fail rule. A rule body 𝐵, the part to the right of :-, is deﬁned by mutual
recursion as follows. A positive body literal is one of the following: (a) an ordinary
atom, (b) a comprehension atom (with time term 𝑥) of the form 𝑝(𝑥◦𝑡, 𝑡1, . . . , 𝑡𝑛) sth 𝐵,
where 𝑥is a variable, ◦∈{<, ≤, >, ≥} and 𝐵is a body, (c) a built-in call , i.e., an
atom with a built-in predicate symbol, or (d) a special form let(𝑥, 𝑡), choose(𝑥, ts),
match(𝑡, 𝑠) or collect(𝑥, 𝑡sth 𝐵) where 𝑥is a variable, 𝑠, 𝑡are terms, ts is a list of terms,
and 𝐵is a body. A positive body is a list 𝑏= 𝑏1, . . . , 𝑏𝑘of positive body literals with
𝑘≥0. If 𝑘= 0 then 𝑏is empty otherwise it is non-empty. A negative body literal is
an expression of the form not 𝑏, where 𝑏is a non-empty positive body. A body is a list
𝐵= 𝑏1, . . . , 𝑏𝑘, not 𝑏𝑘+1, . . . , not 𝑏𝑛comprised of a (possibly empty) positive body and
(possibly zero) negative body literals. It is variable free if var(𝑏1, . . . , 𝑏𝑘) = ∅.
Let 𝑟be a rule (1). We say that 𝑟is range-restricted iﬀvar(𝐻) ⊆var(𝑏). Compared
to the usual notion of range-restrictedness [18], Fusemate rules may contain extra
variables in negative body literals. For example, p(𝑡, 𝑥) :- q(𝑡, 𝑥), not(𝑠< 𝑡, r(𝑠, 𝑥, 𝑦))
is range-restricted in our sense with extra variables 𝑠and 𝑦. The extra variables are
implicitly existentially quantiﬁed within the not expression. The example corresponds to
the formula q(𝑡, 𝑥)∧¬∃𝑠, 𝑦.(𝑠< 𝑡∧r(𝑠, 𝑥, 𝑦)) →p(𝑡, 𝑥). Semantically and operationally
this will cause no problems thanks to stratiﬁcation, introduced next.
Fusemate programs – sets of rules – need to be “stratiﬁed by time and by predicates”
(SBTP). The standard notion of stratiﬁcation by predicates means that the call graph
of the program contains no cycles going through negative body literals. The edges of
this call graph are the “depends on” relation between predicate symbols such that 𝑝
positively (negatively) depends on 𝑞if there is a rule with a 𝑝-atom in its head and
a 𝑞-atom in its positive (negative) body. For disjunctive heads, all head predicates are
2 This deﬁnition of head is actually simpliﬁed as Fusemate oﬀers an additional head operator for
belief revision, see [7]. This is ignored here.
The Fusemate Logic Programming System
591

592
P. Baumgartner
deﬁned to depend positively on each other. Every strongly connected component of the
call graph is called a stratum, and in predicate stratiﬁed programs negative body literals
can occur only in strata lower than the head stratum.
SBTP is deﬁned as follows: for every rule (1) in a given program, (a) there is a
variable time that is the time term of some ordinary 𝑏∈𝑏, (b) if 𝐻is an ordinary head
then every head literal must have a time term constrained to be ≥than time, and (c) for
all rule bodies 𝐵occurring in the rule:
(i) the time term of every ordinary or comprehension body literal in 𝐵must be con-
strained to be ≤than time, and
(ii) for every negative body literal not 𝑏in 𝐵(including the top-level body of (1)) and
every ordinary or comprehension literal 𝑏∈𝑏, the time term of 𝑏must constrained
to be (i) < than time or (ii) ≤than time and the predicate symbol of 𝑏is in a lower
stratum than 𝐻.
For the purpose of this paper we only informally assume that all rules contain constraints
for enforcing the required time ordering properties. There are similar stratiﬁcation
requirements for comprehension atoms and special forms so that their evaluation satisﬁes
the counterpart of condition (ii) (see below for collect). A fully formal deﬁnition could
be given by modifying the spelled-out deﬁnition of SBT in [7].
As an example, if r belongs to a lower stratum than p then the following ﬁve rules
all are SBTP, while only the ﬁrst two rules are SBT.
p(time, 𝑥) :- q(time, 𝑥), r(𝑡, 𝑦), 𝑡≤time
(2)
p(time, 𝑥) :- q(time, 𝑥), not(r(𝑡, 𝑦), 𝑡< time)
(3)
p(time, 𝑥) :- q(time, 𝑥), not(r(𝑡, 𝑦), 𝑡≤time)
(4)
p(time + 1, 𝑥) :- q(time, 𝑥), not(r(𝑡, 𝑦), 𝑡≤time)
(5)
p(time, 𝑥) :- q(time, 𝑥), (p(𝑡< time, 𝑦) sth 𝑞(𝑡, 𝑦)), r(𝑡, 𝑦)
(6)
Finally, a (Fusemate) program is a set of range-restricted rules that is SBTP.
3
Model Computation
The possible model semantics of disjunctive logic programs [23,24] associates to a given
disjunctive program a certain set of normal programs (i.e., without disjunctive heads)
and takes the intended model(s) of these normal programs as the possible models of
the given program. These “split” programs represent all possible ways of making one
or more head literals true, for every disjunctive rule. As a propositional example, the
program {𝑎:- 𝑏, 𝑎∨𝑐:- 𝑏, 𝑏:- } is associated to the split programs {𝑎:- 𝑏, 𝑏:- } and
{𝑎:- 𝑏, 𝑐:- 𝑏, 𝑏:- }. The possible models, hence, are {𝑎, 𝑏} and {𝑎, 𝑏, 𝑐}
Fusemate computes possible models by bottom-up ﬁxpoint computation and dy-
namic grounding the program rules in the style of hyper tableaux [8]. The model
computation procedure is implemented as a variant of the well-known given-clause
algorithm, which seeks to avoid deriving the same conclusion from the same premises
twice. It exhausts inferences in an outer loop/inner loop fashion according to the given

program’s stratiﬁcation by time and by predicates. The main data structure is a set of
paths, where each path represents a partial model candidate computed so far (see [7] for
more details). Paths are selected, extended, split and put back into the set until exhausted,
for a depth-ﬁrst, left-to right inference strategy. Paths carry full status information, which
is instrumental for implementing incrementality, such that facts with current or later time
can be added at any stage without requiring model recomputation from scratch. This,
however, necessitated keeping already exhausted paths for continued inferences later.
The proof procedure’s core operation is computing a body matcher, i.e., a substitution
𝛾for a rule’s positive body variables so that the rule body becomes satisﬁed in the current
partial model candidate. Formally, let 𝐼be a set of ordinary ground atoms, representing
the obvious interpretation that assigns true to exactly the members of 𝐼. Let 𝐵be a body.
A body matcher for 𝐵is a substitution 𝛾for the positive body of 𝐵, written as 𝐼, 𝛾|= 𝐵,
such that the following holds (𝑏, 𝐵means the sequence of head 𝑏and rest body 𝐵):
𝐼, 𝜀|= 𝜖
(𝜖is the empty body and 𝜀is the empty substitution)
𝐼, 𝛾𝜎|= 𝑏, 𝐵
iﬀ𝛾is for 𝑏, 𝑏𝛾∈𝐼and 𝐼, 𝜎|= 𝐵𝛾, with 𝑏ordinary atom
𝐼, 𝛾𝜎|= (𝑝(𝑥
≤< 𝑡, 𝑡1, . . . , 𝑡𝑛) sth 𝐶), 𝐵iﬀ𝛾is for 𝑝(𝑥, 𝑡1, . . . , 𝑡𝑛) and
(1) 𝑝(𝑥, 𝑡1, . . . , 𝑡𝑛)𝛾∈𝐼, 𝑥𝛾< 𝑡and 𝐼, 𝛿|= 𝐶𝛾for some 𝛿,
(2) there is no 𝛾′ for 𝑝(𝑥, 𝑡1, . . . , 𝑡𝑛) and no 𝛿such that
𝑝(𝑥, 𝑡1, . . . , 𝑡𝑛)𝛾′ ∈𝐼, 𝑥𝛾< 𝑥𝛾′ ≤< 𝑡and 𝐼, 𝛿|= 𝐶𝛾′, and
(3) 𝐼, 𝜎|= 𝐵𝛾
𝐼, 𝜎|= 𝑎, 𝐵
iﬀ𝑎evaluates to true and 𝐼, 𝜎|= 𝐵where 𝑎is ground built-in
𝐼, 𝛾𝜎|= let(𝑥, 𝑡), 𝐵iﬀ𝛾= [𝑥↦→𝑡] and 𝐼, 𝜎|= 𝐵𝛾
𝐼, 𝛾𝜎|= choose(𝑥, ts), 𝐵iﬀ𝛾= [𝑥↦→𝑡] and 𝐼, 𝜎|= 𝐵𝛾for some 𝑡∈ts
𝐼, 𝛾𝜎|= match(𝑡, 𝑠), 𝐵iﬀ𝛾is for 𝑡, 𝑡𝛾= 𝑠and 𝐼, 𝜎|= 𝐵𝛾
𝐼, 𝛾𝜎|= collect(𝑥, 𝑡sth 𝐶), 𝐵iﬀ𝛾= [𝑥↦→{𝑡𝛿| 𝐼, 𝛿|= 𝐶}] and 𝐼, 𝜎|= 𝐵𝛾
𝐼, 𝜎|= not 𝑏, 𝐵
iﬀthere is no 𝛿such that 𝐼, 𝛿|= 𝑏, and 𝐴, 𝜎|= 𝐵
A comprehension atom 𝑝(𝑥◦𝑡, 𝑡1, . . . , 𝑡𝑛) sth 𝐵stands for the subset of all ground
𝑝-instances in 𝐼such that 𝐵is satisﬁed and with a time 𝑥as close as possible to 𝑡wrt.
< or ≤. The cases for > and ≥are dual and not spelled out above to save space. The
collect special form collects in the variable 𝑥the set of all instances of term 𝑡such that
the body 𝐶is satisﬁed in 𝐼. We require comprehension atoms and collects to be used in a
stratiﬁed way, so that their results do not change later in a derivation when 𝐼is extended.
The requirements are the same as with not and can be enforced by ordering constraints.
The deﬁnition above extends the earlier deﬁnition of body matchers in [7] with
the new comprehension construct and the let, choose, match, collect operators. It
now also enforces left-to-right evaluation of 𝐵because the new binding operators de-
pend on a ﬁxed order guarantee to be useful. An example is the (nonsensical) body
CHOOSE (x: Int, List(1, 2, 3)), LET(xxx: Int, 3*x), xxx % 2 ==0 which relies on this order. Un-
deﬁned cases, e.g., when evaluation of a non-ground built-in is attempted, or when a
binder variable has already been used before are detected as compile time syntax errors.
593
The Fusemate Logic Programming System

594
P. Baumgartner
4
Shallow Embedding in Scala
Fusemate is implemented as a shallow embedding into Scala [25]. It has three conceptual
main components: a signature framework, a Scala compiler plugin, and an inference
engine for ﬁxpoint computation as explained in Section 3. The signature framework
provides a set of Scala class deﬁnitions as the syntactical basis for writing Fusemate
programs. It is parameterized in a type Time, which can be any Scala or Java type that is
equipped with an ordering and an addition function for time increments, for example Int
or java.time.OffsetDataTime. The programmer then reﬁnes an abstract class Atom of the
Time-instantiated signature framework with deﬁnitions of predicate symbols and their
(Scala-)sorted arities. See lines (3)-(5) in the program in the introduction for an example.
These atoms then can be used in Fusemate rules, see lines (6)–(12) in the example.
While written in convenient syntax, rules are syntactically ill-formed Scala. This
problem is solved by the compiler plugin, which intercepts the compilation of the input
ﬁle at an early stage and transforms the rules into valid Scala source code.3 More
precisely, a rule is transformed into a curried partial function that is parameterized in
an interpretation context I. The curried parameters are Scala guarded pattern matching
expression and correspond to the rule’s positive body literals, in order. For example, the
Faulty rule on lines (11) and (12), with the condition since < time ignored, for simplicity,
is (roughly) translated into the function 𝑓
1 (I: Interpretation) => { case State(time, id, "red") => {
2
case Change(since, id1, "green") if id == id1 &&
3
({ case Change(t, id2, "yellow") if id == id2 && since < t && t < time => FAIL} failsOn I) =>
4
Faulty(time, id, since) } }
Notice the renaming of repeated occurrences of the id variable, which is needed for the
correct semantics. Notice also that a Scala Boolean-valued expression in an ordinary
body literal position (e.g., t < time) simply becomes a guard in a pattern.
The code above can be understood with body matcher computation in mind. Suppose
the inference engine selects an interpretation 𝐼from the current set of paths. For exhaust-
ing 𝑓on 𝐼, the inference engine combinatorially chooses literals 𝑙1, 𝑙2 ∈𝐼and collects
the evaluation results of 𝑓(𝐼)(𝑙1)(𝑙2), if deﬁned. Observe that by the transformation
into Scala pattern matching, body matchers are only implicitly computed by the Scala
runtime system. Each evaluation result, hence, is a body-matcher instantiated head.
The rule’s negative body literal is translated into the code on line (3) and conjoined
to the guard of the preceding ordinary literal. In general, a negative literal NOT body is
treated by translating FAIL :- NOT body and evaluating the resulting Scala code on 𝐼by
means of the failsOn method. If FAIL is not derivable then NOT body is satisﬁed. Again,
appropriate bindings for the variables bound outside of body are held implicitly by the
Scala runtime system. The translation of the special forms and comprehension is not
explained here for space reasons. Fusemate can show the generated code, though.
3 Early experiments showed it is cumbersome and error-prone to write the Scala code by hand, so
this was not an option. The compiler plugin is written in Scala and operates at the abstract syntax
tree level. This was conveniently be done thanks to a sophisticated quasiquote mechanism.

Properties and Advantages
The shallow embedding approach enables introspection capabilities and interfacing
between the rule language and the host language beyond what is implemented in other
systems. In Fusemate, the terms of the logical language are nothing but Scala objects.
As a consequence, any available Scala type or library data structure can be used as a
built-in without extending an “interface” to an extension language – simply because
there is none. Dually, the embedding of the rule language into the host language Scala
is equally trivial because rules, atoms and interpretations are Scala objects, too.
It is this “closed loop” that makes an aggregation operator (collect) possible that
returns a list of Scala objects as speciﬁed by the programmer, e.g., a list of terms or
atoms.4 This list can be further analysed or manipulated by the rules. See the description
logic embedding in Section 5, which critically depends on this feature. This introspection
capability stands out in comparison to the logic programming systems mentioned in the
introduction. For instance, aggregation in systems like DLV [1], and IDB [12] is limited
to predeﬁned integer-valued aggregates for sum, count, times, max and min.
Most logic programming systems can be called from a (traditional) host program-
ming language and can call external systems or utilize libraries for data structures. The
DLV system, for instance, interfaces with C++ and Python [22], Prova [16] with Java,
and IDP with the Lua scripting language. Systems based on grounding (e.g., DLV and
IDP) face the problem of “value invention” by external calls, i.e., having to deal with
terms that are not part of the input speciﬁcation [10].
The main issue, however, from the Fusemate perspective is that these systems’
external interfaces are rather heavy-handed (boilerplate code, mapping logic terms
to/from the host language, String representation of logic programs) and/or limited to
a predeﬁned set of data structures. In contrast, Fusemate’s seamless integration with
Scala encourages a more integrated and experimental problem solving workﬂow. The
following Scala program demonstrates this point with the traﬃc light example:
1 List("2020-07-02T10:00:00,1,green", .., "2020-07-02T10:02:15,2,red")
2
.map { _.split(",") } // Split CSVs intos triple, represented as Java array
3
.map { // Convert String triple to positive Change literals
4
case Array(date,id,color) => Change(LocalDateTime.parse(date), id.toInt, color) }
5
.saturate { rules } // saturate is the Fusemate call, computes all models of the rules
6
.head // Select the first model
7
.toList // Convert to Scala List because we want to sort elements by time:
8
.sortBy { _.time }
9
.flatMap { // Analyze literals in model and retain only Faulty ones as CSV
10
case Faulty(time, id, since) => List(s"$time,$id,$since")
11
case _ => List() }
From a workﬂow perspective, this program integrates Fusemate as a list operator (on a
list of Change instances) in an otherwise unremarkable functional program.
4 Technically, this is possible because the current interpretation is available in the rule body
through the parameter I (see the transformation example above). One could directly access I,
e.g., as in CHOOSE(a: atom, I), MATCH(State(t,3,c), a), t>10, c !="red"
595
The Fusemate Logic Programming System

596
P. Baumgartner
For a more realistically sized experiment I tried a combined Fusemate/Scala work-
ﬂow for analysing the data of the DEBS 2015 Grand Challenge.5 The data comprises
two millions taxi rides in New York City in terms of start/end times, and start/end GPS
coordinates, among others. The problem considered was to detect anomalies where a
taxi driver drivers away from a busy hotspot without a passenger. Solving the problem
required clustering locations by pickup/drop-oﬀactivity for determining hotspots, and
then analysing driver behavior given their pickups/drop-oﬀs at these hotspots.
Two million data points were too much for Fusemate alone and required Scala
preprocessing, e.g., for ﬁlling a grid abstraction of New York coordinates, data cleansing
and ﬁltering out little active drivers. Fusemate was used for computing clusters with
rules similar to transitive closure computation. Input to Fusemate calls were Scala
precomputed point clouds. The computed clusters were used to analyze Scala preﬁltered
taxi rides for anomaly detection based on the clusters. This involved three moderately
complex rules, for ﬁrst identifying gaps and then analysing them. The comprehension
operator was useful to ﬁnd “the most recent ride predating a given start”, among others.
The longest Fusemate run was 0.31sec for 64 rides (with 39 clusters ﬁxed), most other
runs took less than 0.15sec. Fusemate’s performance was perfectly acceptable in this
experiment thanks to a combined workﬂow.
5
Embedding Description Logic ALCIF
ALCIF is the well-known description logic ALC extended with inverse roles and
functional roles. (See [3] for background on description logics.) This section describes
how to translate an ALCIF knowledge base to Fusemate rules and facts for satisﬁa-
bility checking.
This is our example knowledge base, TBox on the left, ABox on the right:
Person ⊑Rich ⊔Poor
Anne : Person ⊓Poor
Person ⊑∃father.Person
(Anne, Fred) : father
Rich ⊑∀father−1.Rich
Bob : Person
Rich ⊓Poor ⊑⊥
(Bob, Fred) : father
The father role is declared as functional, i.e., as a right-unique relation, and father−1
denotes its inverse “child” relation. The third GCI says that all children of a rich father
are rich as well. In all models of the knowledge base Fred is Poor. This follows from the
given fact that his child Anne is poor, functionality of father and the third CGI. However,
there are models where Bob is Rich and models where Bob is Poor.
Translating description logic into rule-based languages has been done in many ways,
see e.g. [20,17,14,11]. An obvious starting point is taking the FOL version of a given
knowledge base. Concept names become unary predicates, role names become binary
predicates, and GCIs (general concept inclusions) are translated into implications. By
polynomial transformations, the implications can be turned into clausal form (if-then
rules over literals), except for existential quantiﬁcation in a positive context, which
5 http://www.debs2015.org/call-grand-challenge.html

causes unbounded Skolem terms in derivations when treated naively (for example, the
third CGI above is problematic in this sense). This is why many systems and also the
transformation to Fusemate below avoid Skolemization.
The ﬁrst GCI corresponds to the clause Person(𝑥) →Rich(𝑥) ∨Poor(𝑥), and the
second corresponds to the “almost” clause Person(𝑥) →∃𝑦.(father(𝑥, 𝑦) ∧Person(𝑦)).
Fusemate works with the reiﬁed rule versions of these, with an IsA-predicate for concept
instances, and a HasA-predicate for role instances. For the whole TBox one obtains the
following, where RN stands for “role name” and CN stands for “concept name”.6
1 IsA(x, Exists(RN("father"), CN("Person")), time) :- IsA(x, CN("Person"), time)
2 IsA(x, CN("Rich"), time) OR IsA(x, CN("Poor"), time) :- IsA(x, CN("Person"), time)
3 IsA(x, Forall(Inv(RN("father")), CN("Rich")), time) :- IsA(x, CN("Rich"), time)
4 FAIL :- IsA(x, CN("Poor"), time), IsA(x, CN("Rich"), time)
5 functionalRoles = Set(RN("father"))
Every GCI can be converted into rules like the above without problems. For that,
starting from its NNF, ∃-quantiﬁcations in the premise of a rule can be expanded in
place, and ∀-quantiﬁcations can be moved to the head as the ∃-quantiﬁcation of the
NNF of the negated formula. Similarly for negated concept names. See [20] for such
transformation methods. The ABox is represented similarly. Its ﬁrst element, for instance,
is IsA(Name("Anne"), And2( CN("Person"), CN("Poor")), 0).
In addition, some more general “library” rules for the tableau calculus are needed:
1 IsA(x, c1, time) AND IsA(x, c2, time) :- IsA(x, And2(c1, c2), time)
2 IsA(x, c1, time) OR IsA(x, c2, time) :- IsA(x, Or2(c1, c2), time)
3 // Expansion rules for quantifiers
4 IsA(y, c, time) :- Neighbour(x, r, y, time), IsA(x, Forall(r, c), time)
5 HasA(x, r, rSuccOfx, time+1) AND IsA(rSuccOfx, c, time+1): @preds("TimePlus1") :-
6
IsA(x, Exists(r, c), time), ! (functionalRoles contains r),
7
NOT( Neighbour(x, r, y, time), IsA(y, c, time) ), NOT( Blocked(x, _, time) ),
8
LET(rSuccOfx: Individual, Succ(r, x))
10 HasA(x, r, rSuccOfx, time+1) AND IsA(rSuccOfx, c, time+1): @preds("TimePlus1") :- (
11
IsA(x, Exists(r, c), time), functionalRoles contains r,
12
NOT( Neighbour(x, r, y, time) ), NOT( Blocked(x, _, time) ),
13
LET(rSuccOfx: Individual, Succ(r, x))
15 IsA(y, c, time) :-
16
IsA(x, Exists(r, c), time), functionalRoles contains r,
17
Neighbour(x, r, y, time)
The expansion rules on lines 1 and 2 deal with the ALC binary Boolean connectives
And2 and Or2 in the obvious way. Supposing NNF of embedded formulas, no other
cases can apply. The remaining rules can be understood best with the standard tableau
algorithm for ALCIN in mind, which includes blocking to guarantee termination.
They follow the terminology in [6, Chapter 4]. The Neighbour relation abstracts from
the HasA relation, left away for space reasons. The expansion rule for ∃comes for three
cases. The ﬁrst case (line 5), for example, applies to non-functional roles as per the
Scala builtin test on line 6. The expansion of the given ∃-formula only happens if it
6 See the Fusemate web page for the full, runnable code.
597
The Fusemate Logic Programming System

598
P. Baumgartner
is not yet satisﬁed and in a non-blocked situation (line 7). In this case the rule derives
a Skolem object deﬁned on line 8 for satisfying the ∃-formula. Notice the annotation
@preds("TimePlus1") which makes sure that the head is on the highest stratum. This way,
the rule will be applied after, in particular, the rules for blocking. Furthermore, with
the time stamp time +1 the Skolem object is kept separate from the computations in the
current iteration time. The blocking rules are deﬁned as follows:
1 // Collect all concepts that an individual x isA, at a given time
2 Label(x, cs.toSet, time) :- IsA(x, _, time), COLLECT(cs: List[Concept], c STH IsA(x, c, time))
3 // Ancestor relation of Skolem objects introduced by exists-right
4 Anc(x, Succ(r, x), time) :- HasA(x, r, Succ(r, x), time)
5 Anc(x, Succ(r, z), time) :- HasA(z, r, Succ(r, z), time), Step(time, prev), Anc(x, z, prev)
6 // Blocked case 1: y is blocked by some individual x
7 Blocked(y, x, time) :- Label(y, yIsAs, time), Anc(x, y, time), Label(x, xIsAs, time), yIsAs == xIsAs
8 // Blocked case 2: y is blocked by some ancestor
9 Blocked(y, x, time) :- Anc(x, y, time), Blocked(x, _, time)
Some additional rules are needed for dealing with basic inconsistencies and for
carrying over IsA and HasA facts between iterations. They are not shown here.
The expansion rules and blocking rules follow the tableau calculus description in [6,
Chapter 4]. One important detail is that the expansion rule for ∃must be applied
with lowest priority. This is straightforward thanks to Fusemate’s stratiﬁcation and
aggregation construct. Equally important is the access to (Scala) data structures via
built-ins and using them as terms of the logical language. This made it easy to program
Skolemization and the Label relation for collecting sets of concepts of an individual.
6
Conclusions
This paper described recent developments around the Fusemate logic programming
system. It included new technical improvements for a weaker form of stratiﬁcation, which
enabled useful aggregation and comprehension language constructs. It also argued for
the advantages of the tight integration with Fusemate’s host language, Scala, in terms
of data structures and usability.
Answer set solvers like DLV and SModels are designed to solve NP-complete or
higher complexity search problems as fast as possible. Fusemate is not motivated as a
competitive such system, it is motivated for "well-behaved" knowledge representation
applications, similarly to description logic reasoners, whose (often) NExpTime com-
plete solving capabilities are not expected to be typically needed. (Some more work is
needed, though, e.g., on improving the current term indexing techniques to speed up
model computation.) More speciﬁcally, the main intended application of Fusemate is
for the runtime analysis of systems that evolve over time. The taxi rides data experiment
explained in Section 4 is an example for that. It suggests that Fusemate is currently best
used in a combined problem solving workﬂow if scalability is an issue.
As for future work, the next steps are to make the description logic reasoner of
Section 5 callable from within Fusemate rules in a DL-safe way [19] and to embed a
temporal reasoning formalism. The event calculus [15] seems to be a good ﬁt.
Acknowledgements. I am grateful to the reviewers for their helpful comments.

References
1. Alviano, M., Faber, W., Leone, N., Perri, S., Pfeifer, G., Terracina, G.: The Disjunctive Datalog
System DLV. In: de Moor, O., Gottlob, G., Furche, T., Sellers, A.J. (eds.) Datalog Reloaded
- First International Workshop, Datalog 2010, Oxford, UK, March 16-19, 2010. Revised
Selected Papers. Lecture Notes in Computer Science, vol. 6702, pp. 282–301. Springer
(2010). https://doi.org/10.1007/978-3-642-24206-9_17
2. Artikis,
A.,
Skarlatidis,
A.,
Portet,
F.,
Paliouras,
G.:
Logic-Based
Event
Recognition.
Knowledge
Engineering
Review
27(4),
469–506
(2012).
https://doi.org/10.1017/S0269888912000264
3. Baader, F., Calvanese, D., McGuinness, D., Nardi, D., Patel-Schneider, P. (eds.): Description
Logic Handbook. Cambridge University Press (2002)
4. Baader, F., Bauer, A., Baumgartner, P., Cregan, A., Gabaldon, A., Ji, K., Lee, K., Ra-
jaratnam, D., Schwitter, R.: A Novel Architecture for Situation Awareness Systems. In:
Giese, M., Waaler, A. (eds.) Automated Reasoning with Analytic Tableaux and Re-
lated Methods (TABLEAUX 2009). LNAI, vol. 5607, pp. 77–92. Springer (July 2009).
https://doi.org/10.1007/978-3-642-02716-1_7
5. Baader, F., Borgwardt, S., Lippmann, M.: Temporal Conjunctive Queries in Expressive
Description Logics with Transitive Roles. In: Pfahringer, B., Renz, J. (eds.) AI 2015: Ad-
vances in Artiﬁcial Intelligence - 28th Australasian Joint Conference, Canberra, ACT, Aus-
tralia, November 30 - December 4, 2015, Proceedings. Lecture Notes in Computer Science,
vol. 9457, pp. 21–33. Springer (2015). https://doi.org/10.1007/978-3-319-26350-2_3
6. Baader, F., Horrocks, I., Lutz, C., Sattler, U.: An Introduction to Description Logic. Cambridge
University Press (2017)
7. Baumgartner, P.: Possible Models Computation and Revision – A Practical Approach. In:
Peltier, N., Sofronie-Stokkermans, V. (eds.) International Joint Conference on Automated
Reasoning. LNAI, vol. 12166, pp. 337–355. Springer International Publishing, Cham (2020).
https://doi.org/10.1007/978-3-030-51074-9_19
8. Baumgartner, P., Furbach, U., Niemelä, I.: Hyper Tableaux. In: Logics in Artiﬁcial Intelligence
(JELIA ’96). Lecture Notes in Artiﬁcial Intelligence, vol. 1126. Springer (1996)
9. Beck,
H.,
Dao-Tran,
M.,
Eiter,
T.:
LARS:
A
Logic-based
framework
for
Analytic
Reasoning
over
Streams.
Artiﬁcial
Intelligence
261,
16–70
(2018).
https://doi.org/10.1016/j.artint.2018.04.003
10. Calimeri, F., Cozza, S., Ianni, G.: External sources of knowledge and value invention in logic
programming. Annals of Mathematics and Artiﬁcial Intelligence 50, 333–361 (08 2007).
https://doi.org/10.1007/s10472-007-9076-z
11. Carral, D., Krötzsch, M.: Rewriting the Description Logic ALCHIQ to Disjunctive Ex-
istential Rules. In: Bessiere, C. (ed.) Proceedings of the Twenty-Ninth International
Joint Conference on Artiﬁcial Intelligence, IJCAI 2020. pp. 1777–1783. ijcai.org (2020).
https://doi.org/10.24963/ijcai.2020/246
12. Cat, B.D., Bogaerts, B., Bruynooghe, M., Janssens, G., Denecker, M.: Predicate logic as
a modeling language: the IDP system. In: Michael Kifer and Yanhong Annie Liu (ed.)
Declarative Logic Programming: Theory, Systems, and Applications, pp. 279–323. ACM /
Morgan & Claypool (2018). https://doi.org/10.1145/3191315.3191321
13. Gebser, M., Kaminski, R., Kaufmann, B., Schaub, T.: Clingo = ASP + Control: Preliminary
Report. CoRR abs/1405.3694 (2014), http://arxiv.org/abs/1405.3694
14. Grosof, B.N., Horrocks, I., Volz, R., Decker, S.: Description Logic Programs: Combining
Logic Programs with Description Logic. In: Hencsey, G., White, B., Chen, Y.R., Kovács,
L., Lawrence, S. (eds.) Proceedings of the Twelfth International World Wide Web Con-
ference, WWW 2003, Budapest, Hungary, May 20-24, 2003. pp. 48–57. ACM (2003).
https://doi.org/10.1145/775152.775160
599
The Fusemate Logic Programming System

600
P. Baumgartner
15. Kowalski, R.A., Sergot, M.J.: A Logic-based Calculus of Events. New Generation Computing
4(1), 67–95 (1986). https://doi.org/10.1007/BF03037383
16. Kozlenkov, A., Peñaloza, R., Nigam, V., Royer, L., Dawelbait, G., Schroeder, M.: Prova:
Rule-Based Java Scripting for Distributed Web Applications: A Case Study in Bioin-
formatics. In: EDBT Workshops. LNCS, vol. 4254, pp. 899–908. Springer (2006).
https://doi.org/10.1007/11896548_68
17. Lukácsy,
G.,
Szeredi,
P.:
Eﬃcient
description
logic
reasoning
in
Prolog:
The
DLog system. Theory and Practice of Logic Programming 9(3), 343–414 (2009).
https://doi.org/10.1017/S1471068409003792
18. Manthey, R., Bry, F.: SATCHMO: a theorem prover implemented in Prolog. In: Lusk, E.,
Overbeek, R. (eds.) Proceedings of the 9𝑡ℎConference on Automated Deduction, Argonne,
Illinois, May 1988. Lecture Notes in Computer Science, vol. 310, pp. 415–434. Springer
(1988)
19. Motik, B., Sattler, U., Studer, R.: Query Answering for OWL-DL with Rules. In: McIlraith,
S.A., Plexousakis, D., van Harmelen, F. (eds.) The Semantic Web – ISWC 2004. pp. 549–563.
Springer Berlin Heidelberg, Berlin, Heidelberg (2004)
20. Motik, B., Shearer, R., Horrocks, I.: Hypertableau Reasoning for Description Logics. Journal
of Artiﬁcial Intelligence Research 36, 165–228 (2009). https://doi.org/10.1613/jair.2811
21. Przymusinski, T.C.: On the Declarative Semantics of Deductive Databases and Logic Pro-
grams. In: Minker, J. (ed.) Foundations of Deductive Databases and Logic Programming, pp.
193 – 216. Morgan Kaufmann (1988). https://doi.org/10.1016/B978-0-934613-40-8.50009-9
22. Redl, C.: The DLVHEX System for Knowledge Representation: Recent Advances
(System Description). Theory and Practice of Logic Programming 16 (07 2016).
https://doi.org/10.1017/S1471068416000211
23. Sakama, C.: Possible Model Semantics for Disjunctive Databases. In: Kim, W., Nicholas,
J.M., Nishio, S. (eds.) Proceedings First International Conference on Deductive and Object-
Oriented Databases (DOOD-89). pp. 337–351. Elsevier Science Publishers B.V. (North–
Holland) Amsterdam (1990)
24. Sakama, C., Inoue, K.: An Alternative Approach to the Semantics of Disjunctive Logic
Programs and Deductive Databases. Journal of Automated Reasoning 13, 145–172 (1994)
25. The Scala Programming Language, https://www.scala-lang.org
26. Syrjänen, T., Niemelä, I.: The Smodels System. In: Eiter, T., Faber, W., Truszczynski, M. (eds.)
Logic Programming and Nonmonotonic Reasoning, 6th International Conference, LPNMR
2001, Vienna, Austria, September 17-19, 2001, Proceedings. Lecture Notes in Computer
Science, vol. 2173, pp. 434–438. Springer (2001). https://doi.org/10.1007/3-540-45402-0_38

Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which per-
mits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as
you give appropriate credit to the original author(s) and the source, provide a link to the Creative
Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s Creative
Commons license, unless indicated otherwise in a credit line to the material. If material is not in-
cluded
in
the
chapter’s
Creative
Commons
license
and
your
intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need to ob-
tain permission directly from the copyright holder.
601
The Fusemate Logic Programming System

Twee: An Equational Theorem Prover
Department of Computer Science and Engineering,
Chalmers University of Technology, Gothenburg, Sweden
nicsma@chalmers.se
Abstract. Twee is an automated theorem prover for equational logic. It
implements unfailing Knuth-Bendix completion with ground joinability
testing and a connectedness-based redundancy criterion. It came second
in the UEQ division of CASC-J10, solving some problems that no other
system solved. This paper describes Twee’s design and implementation.
Keywords: Automated theorem proving · unit equality · completion
1
Introduction
Twee is an automated theorem prover for equational logic, available as open-
source software [17]. It features good performance (coming second in the UEQ
division of CASC-J10), low memory use, and human-readable proof output.
Twee’s general architecture is quite traditional: it uses a DISCOUNT loop
[7] implementing unfailing Knuth-Bendix completion [3]. However, it has a few
characteristics which are unusual in a high-performance theorem prover:
Fixed heuristics. Twee does not adjust its strategy based on the input problem.
It uses a ﬁxed term order, a ﬁxed critical pair scoring function, and so on. Rather
than detecting the kind of problem, Twee uses general-purpose strategies that
work for all sorts of problems (Section 2).
Strong redundancy tests. Rather than using special strategies for associative-
commutative functions, Twee builds in strong redundancy tests, based on ground
joinability and connectedness (Section 3). These handle not just AC functions
but many kinds of unorientable equations, in particular permutative ones (where
both sides are almost the same but with variables in a diﬀerent order).
A high-level language. Twee consists of 5300 lines of Haskell code, whereas for
example Waldmeister [12] is 65000 lines of C. As such, it is easy to experiment
with. Despite the choice of programming language, Twee is quite fast at raw
deduction steps, thanks to careful coding of low-level term operations (Section 4).
Despite the ﬁxed heuristics and high-level language, Twee comes close in
performance to E [14] and Waldmeister [12]. It is strong in many problem classes,
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
https://doi.org/10.1007/978-3-030-79876-5 35
Nicholas Smallbone
602–613, 2021.
3

including LAT (lattices) and REL (relation algebra) from TPTP, which feature
many commutative operators where Twee’s redundancy tests shine, and on
unusual problems, where no prover has special heuristics. Twee is however poor
at RNG (rings), where it seems important to choose a good term order. The rest of
the paper describes Twee’s design in detail, focusing on the three aspects above.
Notation. We use t ” u to mean that t and u are syntactically equal.
2
Architecture
Twee natively supports only unit equality problems with ground goals, but the
frontend also supports arbitrary quantiﬁcation, Horn formulas, and many-sorted
logic. These features are eliminated using the external tool Jukebox [16], which:
– Clausiﬁes the problem to eliminate conjunction and quantiﬁers.
– Encodes Horn clauses as equations [5].
– Encodes sorts using extra functions [4].
At this point, the goal can still contain existentially-quantiﬁed variables, which
must be eliminated. To do so, we use an old trick, also used by Waldmeister: if
the goal t “ u is non-ground, we add new function symbols eq, true and false,
and two axioms @X. eqpX, Xq “ true and eqpt, uq “ false, and replace the goal
with true “ false. Now we have a unit equality problem with a ground goal.
The main proof loop is shown in Algorithm 1. It implements unfailing com-
pletion [3] using a DISCOUNT loop [7]. The state consists of R, a set of rewrite
rules and unorientable equations (the active set, initially empty); Q, the set of
unprocessed critical pairs formed from R (the passive set, initially containing all
the axioms); J, a set of ground joinable equations used for subsumption checking
(following [1]); and the goal. The main loop removes the best critical pair from Q
(see below), and if it is not redundant, adds it to R (oriented if possible) and adds
all its critical pairs to Q. Every so often, the rules in R are reduced with respect
to one another and redundant rules are removed. The goal is kept normalised
with respect to R and the prover succeeds if the goal becomes trivial.1
The passive set is normally quadratic in the size of the active set: typical
numbers are |R| « 10, 000 and |Q| « 10, 000, 000. Hence we must process each
passive critical pair at high speed, but can spend time on each new rewrite rule.
Term ordering. We always use KBO, with all functions having weight 1, and
ordered so that more frequently-occuring functions are smaller.
Critical pair selection. When a critical pair is added to Q, it is ﬁrst normalised
and then assigned a score; the proof loop selects the critical pair with the lowest
score. The score function’s job is to pick out promising critical pairs, and the
choice of score function can make or break the prover. However, as it is applied
to every critical pair, it also needs to be fast. We compute scores as follows:
1 An equation is considered trivial if it is of the form t “ t.
Twee: An Equational Theorem Prover
603

604
N. Smallbone
Algorithm 1 The main proof loop
pR, J, Qq “ pH, H, Aq
while Q ‰ H do
P “ remove lowest-scoring element of Q
if P’s parent rules are still present in R then
normalise P using R to get t “ u
if t ı u and t “ u is not connected and t “ u is not subsumed by J then
if t “ u is ground joinable then
add t “ u to J
else
orient t “ u and add it to R
for all critical pairs cp of t “ u and R do
normalise cp using only the oriented rules in R
if cp is non-trivial then add cp to Q end if
end for
normalise goal using R
if goal is trivial then return “theorem” end if
simplify rules in R wrt each other, but limit this step to 5% of total runtime
end if
end if
end if
end while
return “countersatisﬁable”
– We start with a weighted sum of the size of the two terms. By default we take
4 weightptq`weightpuq, where t is the bigger term and u the smaller. In other
words, the size of the bigger term is most important. Variables are weighted
slightly less than function symbols, to encourage ﬁnding more general rules.
– To encourage Twee to use all the axioms, we add the critical pair’s depth,
where axioms have depth 0, critical pairs of the axioms have depth 1, etc.
– If a term contains the same subterm multiple times, only one occurrence of
that subterm is counted; the other occurrences get a nominal weight of one
symbol. In eﬀect we measure the weight as if the term was a DAG rather
than a tree. The idea is that identical subterms form the same critical pairs,
and tend to get rewritten at the same time: they come and go together.
– Finally, any critical pair of the form eqpv, wq “ false (where eq is the function
used to encode existential goals) with v and w uniﬁable is given a ﬁxed cost
of 1, because selecting it will immediately prove the goal. This trick is also
used by Waldmeister, and is vital in practice for existential goals.
Proof production and checking. Twee uses an LCF-style kernel [9] to guarantee
soundness. Every member of the active set comes with a proof object, which
is veriﬁed by a trusted proof checker (consisting of about a page of code). The
proofs are low-level and thus easy to check: the only proof steps allowed are
reﬂexivity, symmetry, transitivity, congruence and applying an axiom or lemma.
It is not possible to add a rule to the active set without supplying a proof, and

any invalid proof step causes a fatal runtime error. The key to making this fast
is that only the active set, not the passive set, includes proof objects.
Once the goal is proved, we transform the proof object into a human-readable
proof, consisting of a ﬂat sequence of rewrite steps. We also introduce lemmas,
to avoid exponentially-sized proofs: any active rewrite rule is a candidate lemma.
Our approach is similar to [8], but simpler as our proof steps are smaller; but
their lemma selection strategy is smarter than ours and produces fewer lemmas.
Goal transformation. Twee’s frontend can optionally transform the problem to
make the prover more goal-directed. The transformation is simple, but strange.
For every function term fp. . .q appearing in the goal, we introduce a fresh
constant symbol a and add the axiom fp. . .q “ a. For example, if the goal is
fpgpaq, bq “ hpcq, we add the axioms fpgpaq, bq “ d1, gpaq “ d2, and hpcq “ d3.
Simpliﬁcation will rewrite the ﬁrst axiom to fpd2, bq “ d1 and the goal to d1 “ d3.
By doing this transformation, (1) any subterm of the goal gets normalised to
a constant, so critical pairs containing goal terms get a lower score, and (2) new
critical pairs involving these constants appear, which are likely to be relevant to
the goal. We evaluate this transformation in Section 5.
Weak rewrite rules. Completion sometimes deduces equations where both sides
have a variable not occurring on the other side, such as fpx, yq “ gpx, zq. Such
equations are awkward for rewriting: suppose we want to use this equation to
rewrite the term fpt, uq—what value should we choose for z?
Twee splits this equation into nicely-behaved rewrite rules instead. To do so,
we introduce the concept of a weak rewrite rule. A weak rewrite rule t ù u is
like an ordinary rewrite rule, except that it only satisﬁes t ě u, not t ą u.2 Weak
rewrite rules form critical pairs and participate in rewriting just like any other
rewrite rule, except that to ensure termination, we may only perform the rewrite
step tσ ù uσ if tσ ı uσ, i.e. tσ and uσ are syntactically diﬀerent terms.3
Using weak rewrite rules, Twee splits fpx, yq “ gpx, zq into the two rules
fpx, yq Ñ gpx, Kq and gpx, zq ù gpx, Kq, where K is the minimal term in the
term ordering. Note that gpx, zq ù gpx, Kq is a valid weak rewrite rule because
gpx, zq ě gpx, Kq, with equality exactly when z ” K.
As another example, the equation fpx, x, y, zq “ gpx, y, y, wq is split into
fpx, x, y, Kq “ gpx, y, y, Kq, fpx, x, y, zq ù fpx, x, y, Kq and gpx, y, y, wq ù
gpx, y, y, Kq. In this case, we are still left with an unorientable rule afterwards,
but since it has the same variables on both sides it is unproblematic for rewriting.
It is always possible and safe to split an equation into an equivalent set of:
– ordinary rewrite rules t Ñ u with t ą u,
– weak rewrite rules t ù u with t ě u, and
– unorientable equations t “ u where both sides have the same set of variables.
Twee does this whenever an equation is about to be added to R.
2 t ě u means: for all grounding substitutions σ, either tσ ą uσ or tσ ” uσ.
3 This is diﬀerent from e.g. constrained rewriting: we can perform the rewrite even if t
and u are uniﬁable, as long as they are not the same term right now.
605
Twee: An Equational Theorem Prover

606
N. Smallbone
3
Redundancy Criteria
The basic redundancy criterion of Knuth-Bendix completion is joinability: a
critical pair can be discarded if both sides normalise to the same term. Joinability
runs into problems when we have unorientable equations. For example, consider
a rewrite system for an associative-commutative operator “`”:
x ` y “ y ` x
(1)
px ` yq ` z Ñ x ` py ` zq
(2)
x ` py ` zq “ y ` px ` zq
(3)
From (1) and (2) we get the critical pair x`py`zq
(2)
ÐÝÝ px`yq`z
(1)
ÝÝÑ z`px`yq,
which cannot be rewritten any further so it is not joinable. However, the critical
pair is redundant, because the above rewrite system is ground conﬂuent. We
would like to detect redundant but non-joinable critical pairs.
This section presents the redundancy criteria that Twee uses to handle
unorientable equations: our take on the well-known approach of ground joinability
testing [6], and a novel (we believe) approach based on connectedness [2]. Unlike
the standard techniques for associative-commutative functions [1], our criteria
handle any kind of permutative equation; we evaluate our approach in Section 5.
3.1
Ground Joinability Testing
Although the critical pair x ` py ` zq Ð px ` yq ` z Ñ z ` px ` yq is not joinable,
all ground instances of it are joinable, and we say that the critical pair is ground
joinable. For example, the instance a ` pb ` cq Ð pa ` bq ` c Ñ c ` pa ` bq, with
a ă b ă c, can be joined since c ` pa ` bq
(3)
ÝÝÑ a ` pc ` bq
(1)
ÝÝÑ a ` pb ` cq. Any
ground joinable critical pair is redundant.
Martin and Nipkow [13] suggest an approach for checking ground joinability:
– Consider all possible orderings between the variables of the critical pair, such
as x ă y ă z, y ă x ” z, x ” y ă z, and so on.
– For each ordering, show that the critical pair is joinable when the variables
have that order. Formally, this means showing that all ground instances
satisfying the ordering are joinable. For example, the rewrite proof above
shows our critical pair joinable for any ground instance satisfying x ă y ă z.
Their algorithm eﬀectively does a case analysis on all possible variable order-
ings, but it is ineﬃcient because there are so many possible orderings.
Our algorithm is similar, but tries to minimise the number of cases it considers.
It does so by allowing orderings that: (1) constrain only a subset of the variables,
such as x ă y, and (2) use ď, as in x ď y ă z. It works as follows:
1. Choose a strict total order on all the variables, using only ă; e.g., x ă y ă z.
2. Show that the critical pair is joinable under that ordering. Formally, we show
that all ground instances satisfying the ordering are joinable.

3. We have now shown that the critical pair is joinable in one speciﬁc case. Now
generalise that case, by: (1) removing variables from the ordering, and (2)
replacing ă with ď in the ordering, as long as the critical pair is joinable
under the resulting ordering. (This may e.g. generalise x ă y ă z to x ď z.)
4. Repeat, but pick an ordering that is not covered by any of the cases so far.
5. When all variable orderings involving only ă have been covered, all the ones
that remain must involve ”. For each such ordering, take the critical pair,
unify all equal variables, and recursively call the ground joinability check.
Example. Take the critical pair x`py`zq Ð px`yq`z Ñ z`px`yq and suppose
that we choose the ordering x ă y ă z. It can be joined when this order holds, as
for any instance where x ă y ă z, we have z`px`yq
(3)
ÝÝÑ x`pz`yq
(1)
ÝÝÑ x`py`zq.
Having joined the critical pair in one case, we now generalise the case. We
ﬁrst try to remove each variable in turn, i.e. to join the critical pair in the three
cases x ă y, y ă z, and x ă z in turn. None of these attempts succeeds.
Now we try replacing a ă with a ď, to get x ă y ď z. We must check if all
ground instances satisfying x ă y ď z are joinable, but how? We might think of
splitting this into two cases x ă y ă z and x ă y ” z, but instead we are going
to ﬁnd one rewrite proof that works for both.
Consider the rewrite proof above. In it, the step x ` pz ` yq Ñ x ` py ` zq is
ﬁne if y ă z, but does not seem to be allowed if y ” z. But in fact it is ﬁne: if
y ” z, the terms x`pz `yq and x`py `zq are identical, so this rewrite step does
nothing and can just be dropped. That is, the proof works both when x ă y ă z
and x ă y ” z, and shows joinability for the case x ă y ď z. We generalise the
other ă similarly, showing that the critical pair is joinable in the case x ď y ď z.
Next, we pick another total order on the variables, but not one in which
x ď y ď z. We might pick, for example, z ă y ă x. The process repeats: we show
ground joinability under this ordering, and generalise it to z ď y ď x. We repeat
until all cases are covered, and the ground joinability test succeeds.
Although our algorithm can be expensive in theory, in practice it needs to
consider only a few orderings, and a small number of variables. Step (5) can
occasionally be expensive, but by generalising ă to ď we can usually avoid it.
The general case. Here is how we test joinability under a given variable ordering.
First, we parameterise our term order. Given an ordering C, we deﬁne t ěC u to
mean that, for all grounding substitutions σ, if σ satisﬁes C then tσ ě uσ.
In the example, we weakened a ă to a ď. To do so, we used a rewrite step
that, in some ground instances, rewrote a term to the same term. To allow these
kind of steps, we loosen our deﬁnition of rewriting: we may perform a rewrite
t Ñ u under C as long as t ěC u and t ı u. Rewriting terminates because given
a rewrite proof t ěC u ěC v ěC . . ., there is always a ground instance where
t1 ąC u1 ąC v1 ąC . . ., since C was constructed as a strict order in step (1).
With this deﬁnition, normalising z`px`yq using the ordering C :“ x ď y ď z
yields z ` px ` yq Ñ x ` pz ` yq Ñ x ` py ` zq, where e.g. the ﬁrst step is allowed
because z ` x ěC x ` z and z ` x ı x ` z. Thus we can join our example critical
pair under a given variable ordering just by normalising both sides, as we want.
607
Twee: An Equational Theorem Prover

608
N. Smallbone
The last ingredient is to implement a test for t ěC u, which we have done for
KBO. The tricky part is checking whether weightptq ě weightpuq, which can be
solved by taking the expression weightptq ´ weightpuq, a linear combination of
the weights of t’s and u’s variables, and computing its minimum possible value.
One nice property is that the rest of the ground joining code is independent
of the term order. To support e.g. LPO, one just needs to implement ěC for it.
Why not allow arbitrary ordering constraints? Some critical pairs can only be
ground joined by using ordering constraints on arbitrary terms (e.g. x ` y ă z).
We do not support these, as they make everything enormously more complex:
– The number of possible orderings becomes inﬁnite. You can get stuck enu-
merating more and more cases of a case split which never ends. In our design,
there are ﬁnitely many orderings and the algorithm clearly terminates.
– Computing ěC for KBO becomes NP-complete [10]. In our setting, it takes
polynomial time, and we expect it can be done in linear time following [11].
3.2
Connectedness
Ground joinability testing is rather heavyweight, constructing and analysing a
sometimes large case split, and sometimes it fails because it only supports case
splits on variables. Twee also supports a simpler, complementary method that
works well when an unorientable equation is applied under another function.
The method makes use of connectedness. A critical pair s Ð t Ñ u is connected
if there is a rewrite proof s “ t1 “ . . . “ tn “ u such that each ti is strictly less
than t [2]. In Knuth-Bendix completion, any connected critical pair is redundant.
In other words, when joining s Ð t Ñ u, we can do rewrite steps that increase
the term, as long as the result is always strictly less than t.
Here is how we use connectedness. Let σ be a substitution that grounds s
and u. When joining s Ð t Ñ u, we may want to perform a rewrite step v Ñ w
using an unoriented equation, but we don’t know if v ě w. We allow the rewrite
step v Ñ w as long as: (1) w ă t, and (2) vσ ą wσ. Condition (1) ensures
connectedness, and condition (2) ensures that rewriting eventually terminates.
For example, suppose we take the earlier rules for “`” and add a function f:
fpx ` y, z ` wq Ñ fpx, fpz, fpy, wqqq
(4)
fpx, fpy, zqq “ fpy, fpx, zqq
(5)
Assume KBO with both f and ` having weight 1. One critical pair is
fpy, fpz, fpx, wqqq
(4)
ÐÝÝ fpy ` x, z ` wq
(1)
ÐÝÝ fpx ` y, z ` wq
(4)
ÝÝÑ fpx, fpz, fpy, wqq.
We can show this to be connected using σ “ tx  Ñ a, y  Ñ b, z  Ñ c, w  Ñ du,
a ă b ă c ă d. The left term fpy, fpz, fpx, wqqq rewrites to fpy, fpx, fpz, wqqq
using (5), because fpy, fpx, fpz, wqqq ă fpx ` y, z ` wq (connectedness) and
fpb, fpc, fpa, dqqq
ą
fpb, fpa, fpc, dqqq (termination); and that rewrites to
fpx, fpy, fpz, wqqq similarly. The right term fpx, fpz, fpy, wqqq also rewrites to
fpx, fpy, fpz, wqqq. Thus the critical pair is redundant.

In general we try two choices of σ: one where the ﬁrst variable in s “ u is
mapped to a1, the second to a2, and so on (with a1 ă . . . ă an); and another
where the variables are mapped in reverse order. The critical pair is redundant
if either choice of σ works. This is not a principled choice—most likely, some
critical pairs need a diﬀerent σ—but we do not know how to ﬁnd the “best” σ.
4
Implementation
Twee consists of 5300 lines of Haskell code, comprising: terms, uniﬁcation etc.
(1150 lines); the frontend (850 lines); proof output (700 lines); general data
structures (700 lines); the main proof loop (600 lines); joining, ground joining
and connectedness (500 lines); critical pairs and the passive set (400 lines); term
indexing (250 lines); and KBO (150 lines). This does not include TPTP parsing,
clausiﬁcation, etc., which are provided by the 4000-line Jukebox [16] program.
Most of Twee is written in a high-level, Haskell-idiomatic, somewhat ineﬃcient
style. Performance-critical parts (term manipulation, term indexing, and the
passive set) are coded more carefully, and are described below. The bottleneck is
usually normalising the many millions of critical pairs that are generated.
4.1
Terms
The simplest way to represent terms in Haskell, as trees, is not ideal: it creates
pressure on the garbage collector, and core operations such as matching and
uniﬁcation become heavily recursive and needlessly slow.
Instead, we represent terms as ﬂatterms—the term is ﬂattened into a list of
symbols and stored in an array. In order to preserve the structure of the term,
each symbol is paired with a number giving the size of the subterm rooted at
that symbol. For example, the term fpx, gpx, yqq is represented as:
f : 5 x : 1 g : 3 x : 1 y : 1
where e.g. g : 3 indicates a subterm with root g that is 3 symbols long (g, x, y).
In addition, each function and variable has an ID number, and the term stores
those ID numbers, rather than a pointer to the function or variable. So, in the
array above, the “f” really means the ID number of f. Functions have positive ID
numbers, and variables negative, so they can be easily told apart, and there is a
separate global array which maps ID numbers to functions. This design allows us
to represent a term as a simple array of integers, so that pressure on the garbage
collector is reduced. Also, comparing two terms for equality just amounts to a
bytewise comparison of the arrays (a C memcmp). What’s more, by using array
slicing, we can view a term’s subterms as ﬂatterms in their own right.
On top of this we build a higher-level API. There are two types, terms and
termlists, both implemented as ﬂatterms. With the help of Haskell’s user-deﬁned
patterns, they are exposed to the user as ordinary algebraic datatypes. We can
use normal pattern matching to e.g. check if a term is a function or variable,
access its children (as a termlist), iterate through it a symbol or subterm at a
609
Twee: An Equational Theorem Prover

610
N. Smallbone
time, etc. All these operations turn into a few machine instructions. Matching
and uniﬁcation are implemented using this API as eﬃcient tail-recursive loops.
4.2
Indexing
Rewriting uses a perfect discrimination tree [15], including Waldmeister’s reﬁne-
ments [12]. The implementation takes care not to create backtracking points
unless needed. There is no uniﬁcation index, since this is not usually a bottleneck.
4.3
The Passive Set
Early versions of Twee often ran out of memory after about 30 minutes. The
reason is the passive set—it grows quadratically in the number of active rules,
because any pair of rules can have a critical pair. In typical prover runs it contains
anywhere between a million and a hundred million critical pairs.
Twee now uses a space-eﬃcient passive set representation adapted from
Waldmeister [12]. The main idea is to throw away all terms involved in the
critical pair, and only remember: (1) the ID numbers of the two rules involved,
(2) the position of the overlap, and (3) the score of the critical pair. When a
critical pair is selected, the ID numbers and position are used to reconstruct
the critical pair. This design uses about 12 bytes of memory per critical pair, so
Twee can run for many hours without running out of memory.
5
Evaluation
In this section we report on two evaluations: one investigating the eﬀect of the
diﬀerent redundancy criteria of Section 3, and one comparing the performance
of Twee against E 2.5 and Waldmeister. In both cases we ran Twee on all 981
unsatisﬁable UEQ problems from TPTP 7.4.0, with a time limit of 5 minutes.
Redundancy criteria. Figure 1a shows how the performance of Twee varies
depending on which redundancy criteria are enabled. The x-axis shows the
number of problems solved (starting from problem 600) and the y-axis shows
the runtime for that problem. The combination of ground joinability testing and
connectedness is much stronger than either on their own—it seems that each
catches cases that the other misses. It is clearly best to have both switched on.
The ﬁgure also includes a variant of Twee which implements the heuristic
for AC functions described in [1] (and no other redundancy criterion), which
solves fewer problems than our approach. This is perhaps not surprising, as our
approach handles a wider class of functions.
Twee, E, Waldmeister. Figure 1b compares Twee’s performance against E and
Waldmeister. Twee is run in three variations: with and without the goal-directed
transformation from Section 2, and as a timesliced version which runs the other
two versions for 150s each. By far the best choice for Twee is to timeslice, when
it comes close to Waldmeister’s performance. This suggests that Twee with and
without the goal transformation solve somewhat diﬀerent sets of problems.

 0
 50
 100
 150
 200
 250
 300
 600
 650
 700
 750
 800
 850
 900
No connectedness, no ground joining
Connectedness only
Ground joining only
Connectedness + ground joining
Waldmeister-style AC heuristic
(a) Diﬀerent redundancy criteria.
 0
 50
 100
 150
 200
 250
 300
 600
 650
 700
 750
 800
 850
 900
Twee
Twee with goal transformation
Twee with timeslicing
Waldmeister
E
(b) Compared against Waldmeister and E.
Fig. 1: Benchmarks.
6
Future Work
Knuth-Bendix completion pays little attention to the goal: it simply completes
the rewrite system until the goal becomes trivial. We plan to search for ways
to make Twee more goal-directed, for example by rewriting the goal backwards
somewhat in the style of [18]. The success of the goal transformation shows that
goal direction ought to be important.
Twee uses a ﬁxed term ordering, which is clearly a weakness on certain
problem kinds such as RNG. We do not want to choose a term order based on
syntactic analysis of the problem, but would like to choose it dynamically based
on the state of the proof, perhaps by incorporating ideas from MædMax [19].
7
Conclusion
Twee is a unit equality prover implemented in 5300 lines of Haskell code. Its
performance is good, thanks to a careful implementation, strong redundancy
criteria and a transformation to help goal-directness. It performs particularly
strongly on problems involving permutative laws, such as those in LAT and REL.
Its main weaknesses are that it always uses a ﬁxed term order, and has only weak
goal direction. We hope that a future version of Twee, with real goal direction
and a smart choice of term order, will be even stronger.
Acknowledgements. This work was supported by the Swedish Research Council
(VR) grant 2016-06204, Systematic Testing of Cyber-Physical Systems (SyTeC).
We thank the reviewers for their many helpful comments.
611
Twee: An Equational Theorem Prover

612
N. Smallbone
References
1. Avenhaus, J., Hillenbrand, T., L¨ochner, B.: On using ground joinable equations
in equational theorem proving. Journal of Symbolic Computation 36(1), 217–233
(2003), https://doi.org/10.1016/S0747-7171(03)00024-5
2. Bachmair, L., Dershowitz, N.: Critical pair criteria for completion. Journal of
Symbolic Computation 6(1), 1–18 (1988), https://doi.org/10.1016/S0747-7171(88)
80018-X
3. Bachmair, L., Dershowitz, N., Plaisted, D.A.: Completion without failure. In: A¨ıt-
Kaci, H., Nivat, M. (eds.) Rewriting Techniques, pp. 1–30. Academic Press (1989),
https://doi.org/10.1016/B978-0-12-046371-8.50007-9
4. Claessen, K., Lilliestr¨om, A., Smallbone, N.: Sort it out with monotonicity. In:
Bjørner, N., Sofronie-Stokkermans, V. (eds.) Automated Deduction – CADE-23.
Lecture Notes in Computer Science, vol. 6803, pp. 207–221. Springer (2011), https:
//doi.org/10.1007/978-3-642-22438-6 17
5. Claessen, K., Smallbone, N.: Eﬃcient encodings of ﬁrst-order Horn formulas in
equational logic. In: Galmiche, D., Schulz, S., Sebastiani, R. (eds.) Automated
Reasoning - 9th International Joint Conference, IJCAR 2018, Held as Part of the
Federated Logic Conference, FloC 2018, Oxford, UK, July 14-17, 2018, Proceedings.
Lecture Notes in Computer Science, vol. 10900, pp. 388–404. Springer (2018),
https://doi.org/10.1007/978-3-319-94205-6 26
6. Comon, H., Narendran, P., Nieuwenhuis, R., Rusinowitch, M.: Deciding the conﬂu-
ence of ordered term rewrite systems. ACM Transactions on Computational Logic
4(1), 33–55 (Jan 2003), https://doi.org/10.1145/601775.601777
7. Denzinger, J., Kronenburg, M., Schulz, S.: DISCOUNT - a distributed and learning
equational prover. Journal of Automated Reasoning 18(2), 189–198 (Apr 1997),
https://doi.org/10.1023/A:1005879229581
8. Denzinger, J., Schulz, S.: Recording and analysing knowledge-based distributed
deduction processes. Journal of Symbolic Computation 21(4), 523–541 (1996),
https://doi.org/10.1006/jsco.1996.0029
9. Gordon, M.J., Milner, R., Wadsworth, C.P.: Edinburgh LCF. A mechanised logic
of computation. Springer, Berlin, Heidelberg (1979), https://doi.org/10.1007/
3-540-09724-4
10. Korovin, K., Voronkov, A.: A decision procedure for the existential theory of term
algebras with the Knuth-Bendix ordering. In: Proceedings of the 15th Annual IEEE
Symposium on Logic in Computer Science. pp. 291–302. LICS ’00, IEEE Computer
Society, Los Alamitos, CA, USA (2000), https://doi.org/10.1109/LICS.2000.855777
11. L¨ochner, B.: Things to know when implementing KBO. Journal of Automated
Reasoning 36(4), 289–310 (Apr 2006), https://doi.org/10.1007/s10817-006-9031-4
12. L¨ochner, B., Hillenbrand, T.: A phytography of WALDMEISTER. AI Communica-
tions 15(2,3), 127–133 (Aug 2002)
13. Martin, U., Nipkow, T.: Ordered rewriting and conﬂuence. In: Stickel, M.E.
(ed.) 10th International Conference on Automated Deduction. pp. 366–380.
Springer Berlin Heidelberg, Berlin, Heidelberg (1990), https://doi.org/10.1007/
3-540-52885-7 100
14. Schulz, S., Cruanes, S., Vukmirovi´c, P.: Faster, higher, stronger: E 2.3. In: Fontaine,
P. (ed.) Automated Deduction – CADE 27. pp. 495–507. Springer International
Publishing, Cham (2019), https://doi.org/10.1007/978-3-030-29436-6 29

15. Sekar, R., Ramakrishnan, I., Voronkov, A.: Chapter 26 - Term indexing. In:
Robinson, A., Voronkov, A. (eds.) Handbook of Automated Reasoning, pp. 1853–
1964. Handbook of Automated Reasoning, North-Holland, Amsterdam (2001),
https://doi.org/10.1016/B978-044450813-3/50028-X
16. Smallbone, N.: Jukebox. https://github.com/nick8325/jukebox/ (2018)
17. Smallbone, N.: Twee, an equational theorem prover. https://nick8325.github.io/
twee/ (2021)
18. Socher-Ambrosius, R.: A goal oriented strategy based on completion. In: Kirchner,
H., Levi, G. (eds.) Algebraic and Logic Programming. pp. 435–445. Springer Berlin
Heidelberg, Berlin, Heidelberg (1992), https://doi.org/10.1007/BFb0013842
19. Winkler, S., Moser, G.: MædMax: A maximal ordered completion tool. In: Galmiche,
D., Schulz, S., Sebastiani, R. (eds.) Automated Reasoning. pp. 472–480. Springer
International Publishing, Cham (2018), https://doi.org/10.1007/978-3-319-94205-6
31
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium or
format, as long as you give appropriate credit to the original author(s) and the source,
provide a link to the Creative Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.
613
Twee: An Equational Theorem Prover

The Isabelle/Naproche Natural Language
Proof Assistant
1 University of Bonn, Bonn, Germany, https://www.math.uni-bonn.de/ag/logik
2 Augsburg, Germany, https://sketis.net
Abstract aproche is an emerging natural proof assistant that accepts
input in the controlled natural language ForTheL. aproche is included
in the current version of the Isabelle/PIDE which allows comfortable
editing and asynchronous proof-checking of ForTheL texts. The .tex
dialect of ForTheL can be typeset by LATEX into documents that approx-
imate the language and appearance of ordinary mathematical texts.
1
Introduction
aproche (for Natural Proof Checking) is an emerging natural proof assistant
that accepts input in a controlled natural language, approximating ordinary
mathematical language and texts. The system uses
– the dedicated input language ForTheL (Formula Theory Language),
– natural language processing for texts with symbolic material,
– strong automatic theorem proving (ATP) for ﬁlling in implicit or obvious
proof steps.
The current version of aproche also introduces a LATEX dialect of ForTheL so
that high-quality mathematical typesetting is readily available. aproche allows
the formalization and proof-checking of advanced mathematics in a style that is
immediately readable by mathematicians. Example formalizations from various
domains of undergraduate mathematics are included.
aproche ships as a component in the latest release of the Isabelle prover
platform [8]. When editing a ForTheL ﬁle in Isabelle/jEdit Prover IDE (PIDE),
there is an auxiliary aproche server in the background to quickly answer re-
quests for checking ForTheL texts, with an internal cache to avoid repeated
checking of unchanged text segments. The implementation uses programming in-
terfaces of Isabelle/PIDE that allow user-deﬁned ﬁle formats to participate in the
concurrent document model. A second auxiliary server allows the aproche pro-
gram to run external prover processes under the control of Isabelle, with explicit
timeouts. This works reliably on the usual platforms (Linux, Windows, macOS)
c
⃝The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp. 614 624, 2021.
https://doi.org/10.1007/978-3-030-79876-5_36
Adrian De Lon1
, Peter Koepke1
, Anton Lorenzen1
, Adrian Marti1
,
Marcel Schütz1
, and Makarius Wenzel2
–

by re-using external provers of Isabelle/Sledgehammer [17]. From the perspect-
ive of logic, there is no connection of aproche with Isabelle/Sledgehammer or
any other Isabelle/HOL tools.
In this paper we brieﬂy discuss the need for natural proof assistants, provide
some general information on Isabelle/Naproche, and give an overview of meth-
ods employed in the system, using an excerpt from a formalization of Euclid’s
inﬁnitude of primes as a running example. To conclude we compare aproche to
other projects in formal mathematics with natural language input and indicate
ways to further extend aproche’s naturalness and eﬃciency.
2
Natural Proof Assistants
While state-of-the-art interactive theorem provers have been successfully used to
prove and certify highly non-trivial research mathematics, they are still, accord-
ing to Lawrence Paulson [16] “unsuitable for mathematics. Their formal proofs
are unreadable.”
Natural proof assistants intend to bridge the wide gap between intuitive
mathematical texts and the formal rigour of logical calculi. We propose the
following criteria for natural proof assistants:
– Input languages should be close to the mathematical vernacular, includ-
ing support for common grammatical conventions and symbolic expressions.
These languages should support familiar text structurings, such as the usual
deﬁnition-theorem-proof style.
– Proofs should consist of natural argumentative phrases for various proof
tactics, allowing for a more declarative style.
– The system should use familiar logics and mathematical ontologies.
– Tedious details and obvious proof gaps should be ﬁlled in automatically.
– An intuitive editor should allow for interactive text and theory development,
where incremental proof checking can guide the formalization.
We expect that naturalness will be crucial for the adoption of formal mathem-
atics by the wider mathematical community. This is in line with some ongoing
large-scale projects in formal mathematics. For instance, the ALEXANDRIA
project by Paulson [16] stipulates:
ALEXANDRIA will be based on legible structured proofs. Formal proofs
should be not mere code, but a machine-checkable form of communication
between mathematicians.
The Formal Abstracts project of Thomas Hales [5] intends to
– give a statement of the main theorem of each published mathematical paper
in a language that is both human and machine readable,
– link each term in theorem statements to a precise deﬁnition of that term
(again in human/machine readable form).
The Isabelle/Naproche Natural Language Prooof Assistant
615

3
Isabelle/Naproche
The aproche proof assistant stems from two long-term eﬀorts aiming towards
naturalness: the Evidence Algorithm (EA) and System for Automated Deduc-
tion (SAD) projects at the universities of Kiev and Paris [14,15,20,21], and
the Naproche project at Bonn [1,2,3,10]. aproche extends the input language
ForTheL of SAD and embeds it into LATEX, allowing mathematical typesetting;
the original proof-checking mechanisms of SAD have been made more eﬃcient
and varied.
The ﬁrst experimental integration of the then Naproche-SAD prover into
the Isabelle Prover IDE was done in 2018 by Frerix and Wenzel [23, §1.2]. The
current (reﬁned and extended) version has now become a bundled component
of Isabelle2021 [8]. After downloading and unpacking the Isabelle distribution,
Isabelle/Naproche becomes immediately accessible in the Documentation panel,
section Examples, entry $ISABELLE_NAPROCHE/Intro.thy. Isabelle and its add-
on components work directly without manual installation, but this comes at
the cost of substantial resource requirements: on Linux the total size is 1.2 GB,
which includes Java 15 (330 MB), E prover 2.5 (30 MB), and aproche (20 MB).
The bulk of other Isabelle components are required for Isabelle/HOL theory and
proof development, but aproche has no logical connection to that.
The aproche prover is invoked automatically when editing ForTheL ﬁles
with .ftl or .ftl.tex extensions. Further examples and an introductory tu-
torial are linked in the Isabelle theory ﬁle $ISABELLE_NAPROCHE/Intro.thy: as
usual for Isabelle/jEdit and other IDEs, following a link works by a mouse click
combined with the keyboard modiﬁer CTRL (Linux, Windows) or CMD (macOS).
The examples deal with results from undergraduate number theory, geometry,
and set theory; most are available in the classic ASCII style as well as in LATEX
style and typeset in PDF.
The ForTheL library FLib [13] contains a variety of formalizations for earlier
versions of aproche. Some substantial texts have been written as undergraduate
student projects and cover, e.g., group theory up to Sylow theorems, initial
chapters from Walter Rudin’s Analysis, or set theory up to Silver’s theorem
in cardinal arithmetic. These texts will soon be upgraded to the new version
of aproche and included in an interlinked formalized library of readable and
proof-checked mathematical texts.
4
Formalizing in ForTheL
4.1
Example
The following screenshot shows a proof of the inﬁnitude of prime numbers in the
Isabelle/Naproche Prover IDE taken from the bundled tutorial which itself is a
proof-checked ForTheL text:
616
A. De Lon et al.

The editor buﬀer contains the ForTheL source, which also happens to conform
to standard LATEX format. (The “Contradiction” lemma, now deactivated by a %,
is a left-over of a typical check for hidden inconsistencies in the axiomatic setup.)
The Output panel contains feedback from the aproche prover about the source
document: “veriﬁcation successful” and some statistics; the most relevant mes-
sages are also shown in-line over the source as squiggly underline with popup on
mouse-hovering. The Sidekick/latex structure overview is provided by standard
plugins of the underlying text editor. This piece of mathematics is typeset by
LATEX as follows:
Euclid’s Theorem
Signature. P is the class of prime natural numbers.
Theorem. P is inﬁnite.
Proof. Assume that r is a natural number and p is a sequence of length r
and {p1, . . . , pr} is a subclass of P. [...]
⊓⊔
4.2
The ForTheL Language
The mathematical controlled language ForTheL has been developed over several
decades in the Evidence Algorithm (EA) / System for Automated Deduction
(SAD) project. It is carefully designed to approximate the weakly typed nat-
ural language of mathematics whilst being eﬃciently translatable to ﬁrst-order
logic. In ForTheL, standard mathematical types are called notions, and these
are internally represented as predicates with a distinguished variable, which are
treated as unary predicates with the other variables used as parameters (“types
as predicates”). This leads to a ﬂexible dependent type system where number
The Isabelle/Naproche Natural Language Prooof Assistant
617

systems can be cumulative (N ⊆R), and notions can depend on parameters
(subsets of N, divisors of n).
First-order languages of notions, constants, relations, and functions can be
introduced and extended by signature and deﬁnition commands. The formaliz-
ation of Euclid’s theorem, e.g., sets out like:
Signature. A natural number is a small object.
Let . . . m, n . . . denote natural numbers.
Signature. 0 is a natural number.
· · ·
Signature. m + n is a natural number.
5
Architecture of the aproche System
aproche follows standard principles of interactive theorem proving, but with
a strong emphasis on the naturalness aspects explained above. The general in-
formation processing in the system is described in the following diagram. The
core aproche program is implemented in Haskell.
In the sequel we shall describe main components of aproche.
5.1
Tokenizing and Parsing
aproche uses a standard tokenizing algorithm for cutting text up into a list of
meaningful tokens, with precise source positions to enable PIDE messages and
markup, e.g., by colours for free and bound variables. When using LATEX syntax,
the tokenizer also takes care of expanding certain TEX commands (see the next
subsection).
Parsing is carried out in Haskell’s monadic style with parser combinators.
We allow ambiguous parsing, since it better ﬁts natural language. Currently the
translation into tagged ﬁrst-order logic is already part of the parsing process. The
following translation of our example snippet was obtained by running aproche
from the command line with the -T (translate) option:
618
A. De Lon et al.

......
hypothesis.
assume forall v0 ((HeadTerm :: v0 = Primes) implies
(aClass(v0) and forall v1 (aElementOf(v1,v0)
iff (aNaturalNumber(v1) and isPrime(v1))))).
conjecture Euclid.
isInfinite(Primes).
proof.
assume ((aNaturalNumber(r) and aSequenceOfLength(p,r)) and
aSubsetOf(Set{p}{1}{r},Primes)).
n = Prod{p}{1}{r}+1.
......
In order to make aproche more versatile we plan on parsing into an abstract
syntax tree instead, so that diﬀerent logical back-ends could translate into dif-
ferent logics. We have already made some experiments on translating ForTheL
to Lean [12].
Moreover, with the input language growing, we shall eventually turn to some
grammatical framework to speed up language development without hard-coding
vocabulary or grammar rules into the aproche code.
5.2
LATEX Processing
We have extended aproche to support a .ftl.tex format, in addition to the
original .ftl format. Files in .ftl.tex format are intended to be readable by
both aproche for logical checking and by LATEX for typesetting.
The LATEX tokenizer ignores the whole document, except what is inside
forthel environments of the form
\begin{forthel}
% Insert what you want Naproche to process here
\end{forthel}
In a forthel environment, standard LATEX syntax can be used for declaring text
environments for theorems and deﬁnitions.
In aproche, users can deﬁne their own operators and phrases by deﬁning lin-
guistic and symbolic patterns. This mechanism has been adapted to allow LATEX
constructs in patterns. In the Euclid text we use the pattern \Set{p}{1}{r} for
the ﬁnite set {p1, . . . , pr}. By deﬁning \Set as a LATEX macro we can arrange
that the ForTheL pattern will be printed in the familiar set notation:
\newcommand{\Set}[3]{\{#1_{#2},\dots,#1_{#3}\}}
There are some primitive concepts in aproche, such as the logical operators ∨,
∧, ∃that are directly recognized in the LATEX source and expanded to corres-
ponding internal tokens.
The Isabelle/Naproche Natural Language Prooof Assistant
619

The current release of aproche does not diﬀerentiate between math mode
and text mode in LATEX, since it re-uses much of the parsing machinery of the
original .ftl format. Future releases shall make such a distinction to increase the
robustness of the parser, improve error messages and resolve some ambiguities
in the current grammar.
5.3
Logical Processing
The ﬁrst-order formulas derived from ForTheL statements are put into an in-
ternal ProofText data type consisting of blocks of formulae, arranged in a tree-
like fashion. The tree structure mirrors the logical structure of a text, where a
statement can be seen as a node to which a subtext, e.g., its proof is attached.
Since statements in a proof can have their own subproofs this leads to a recurs-
ive tree structure, on which the further checking is performed along a depth-ﬁrst
left-to-right traversal.
5.4
Ontological Checking by the aproche Reasoner
An innocent mathematical statement like a2 + b2 = c2 contains a number of
implicit proof tasks, even if the whole statement is not to be proved, but part of
a deﬁnition or an assumption. One has to check that a, b, c are (numerical) terms
to which the squaring operation can be applied, and that the resulting squares
can be subjected to addition and equality. These checks are called “ontological”,
and they roughly correspond to type checking in type-orientated systems. The
situation here is however more complicated, as types (i.e. notions) and operations
may involve ﬁrst-order deﬁnitions with preconditions, which cannot be decided
during the parsing process but only during proof-checking. So in the checking
process each node of the aforementioned tree is ﬁrst checked ontologically; if the
node formula itself is marked as a conjecture, it is logically checked.
5.5
Logical Checking by the aproche Reasoner
The various checks are organized by the aproche reasoner module. In simple
cases the reasoner itself can supply a proof; if not, the reasoner constructs proof
tasks for the ATP. Since deﬁnitions in ﬁrst-order logic are formally symmetric
equivalences, they may lead to circularities in proof searches. Instead deﬁnitions
are successively unfolded by replacing the deﬁniendum by the deﬁniens. This
process may be iterated when proof attempts fail.
The ATP is given certain timeouts to search for proofs. Ontological checking
is supposed to be easier than proper mathematical proving. So the default time
for each ontological check is set to 1 sec, whereas proving gets 3 sec and can be
iterated for several rounds of deﬁnition unfolding.
620
A. De Lon et al.

5.6
Communication with an External ATP
Proof tasks are translated into the generic TPTP ﬁrst-order format for ATPs.
These can be viewed in the Output window of Isabelle/jEdit, after inserting the
directive [dump on] into the ForTheL source. The ﬁnal proof task in checking
Euclid’s proof ends with the TPTP lines:
fof(m_,hypothesis,( ! [W0] : (aClass(W0) =>
(isInfinite(W0) <=> ( ~ isFinite(W0)))))).
fof(m_,hypothesis,(aClass(szPzrzizmzezs) &
( ! [W0] : (aElementOf(W0,szPzrzizmzezs)
<=> (aNaturalNumber(W0) & isPrime(W0)))))).
fof(m__,conjecture,
......
(aElementOf(W4,szSzeztlcdtrclcz1rclcdtrc(W0,W1)) <=>
(aNaturalNumber(W4) & isPrime(W4))))))))))))) =>
isInfinite(szPzrzizmzezs))).
By default aproche uses E prover [19] as external ATP, but one may switch to
other provers available in the Isabelle distribution.
6
Integration into Isabelle
The initial integration of aproche into the Isabelle Prover IDE happened in
2018 and is brieﬂy reported as an example in the PIDE overview article [23]
based on Isabelle2019 (June 2019). The main idea was to turn the existing
Haskell command-line program into a TCP server that can answer concurrent
requests for checking ForTheL texts in a purely functional manner, with proper
handling of cancel messages (for interrupts caused by user editing); this required
to remove a few low-level system operations, like reading physical ﬁles or exit
of the process. Afterwards, the semantic operation forthel_ﬁle in Isabelle –
to check ForTheL text and produce markup messages according to the PIDE
protocol – was implemented as Isabelle/Isar command in Isabelle/ML as usual,
but the main work is delegated to the aproche server. Its implementation uses
the Isabelle/Haskell library for common Isabelle/PIDE message formats, source
positions, markup etc. – it is maintained within the Isabelle distribution.
The current version of Isabelle/Naproche reﬁnes this approach in various
respects. In particular, Isabelle2021 now provides a standard mechanism for
user-deﬁned Isabelle/Scala services: this is both relevant for Isabelle command-
line tools to build and test Isabelle/Naproche, and the Prover IDE support of
ForTheL ﬁles to connect the Isabelle/jEdit front-end to the aproche back-end.
Moreover, the Java process running the Prover IDE provides an additional
TCP server to launch external provers that are already distributed with Isabelle
(thanks to Isabelle/Sledgehammer): aproche applications mainly use the cur-
rent E prover 2.5 [19], but SPASS and Vampire are available for experiments.
The Isabelle/Naproche Natural Language Prooof Assistant
621

The existing management of processes in Isabelle/Scala involves considerable ef-
forts to robustly support interrupts and timeouts in a concurrent environment;
this works on all platforms supported by Isabelle (using special tricks for Win-
dows/Cygwin, and macOS/Rosetta on Apple Silicon).
The documentation ﬁle $ISABELLE_NAPROCHE/Intro.thy gives further hints
on implementation near the end, with hyperlinks to the sources. A lot of technical
Isabelle infrastructure is re-used by Isabelle/Naproche, but there is presently no
connection to Isabelle/HOL, which is a much larger and better-known applica-
tion of the same Isabelle framework [18].
7
Related and Future Work
Bridging the gap between mathematical practice and fully formal methods has
always been a central concern in formal mathematics. The development of the
Mizar system [11] was accompanied or even driven by the stepwise adaptation of
its language to standard mathematical proof methods and logical foundations.
In contrast, most interactive theorem provers feature formal tactic languages,
with tactics scripts that can hardly be understood without stepwise tracing and
reconstructing internal logical states.
The Mizar language has been a role model for other proof languages. There
are, e.g., "Mizar modes" for HOL [6,25] and Coq [4] and the widely used Isar
language for Isabelle [24,22]. These language can be read by mathematicians,
with some eﬀort, but they retain a strong bias toward computer science customs.
A survey of input languages for formalization on a scale between formal and
natural can be found in [9].
Only a few formal mathematics projects have aimed at processing actual
mathematical language. These projects have operated in isolation and seem to
be mostly inactive now. The paper [7] by Muhammad Humayoun and Christophe
Raﬀalli, e.g., describes the MathNat project and also surveys other related at-
tempts.
The Naproche approach can be viewed in the Mizar tradition: use a rich
controlled language for mathematics, increase the proving capabilities by strong
automated theorem proving, and, eventually, create an extensive library of basic
mathematics and specialized theories, which simultaneously can be used as a
library for human readers.
The readability and naturalness of texts which proof-check in the aproche
system motivate signiﬁcant further extensions of the project where ad hoc meth-
ods are to be replaced by principled and established approaches:
1. the input language ForTheL has to be extended for wide mathematical
coverage; ForTheL needs an extensive formal grammar and vocabulary to be
processed by strong linguistic methods; the vocabulary may also encompass
standard LATEX symbols and semantic information;
2. methods of type derivation and elaboration should be provided;
3. Isabelle/Sledgehammer-like methods should lead to eﬃcient premise selec-
tion in large texts and theories;
622
A. De Lon et al.

4. the creation of libraries of ForTheL documents requires import and ex-
port mechanisms corresponding to quoting and referencing in the mathematical
literature;
5. the natural text processing of aproche should be interfaced with other
proof assistants to leverage their strengths and libraries. We shall in particular
work on a “aproche mode” for Isabelle.
References
1. Cramer, M.: Proof-checking mathematical texts in controlled natural language.
Ph.D. thesis, University of Bonn (2013), http://hdl.handle.net/20.500.11811/5780
2. Cramer, M., Koepke, P., Kühlwein, D., Schröder, B.: The Naproche system (2009),
https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.211.3401
3. Frerix, S., Koepke, P.: Automatic proof-checking of ordinary mathematical texts.
Proceedings of the Workshop Formal Mathematics for Mathematicians (2018),
http://ceur-ws.org/Vol-2307/paper13.pdf
4. Giero, M., Wiedijk, F.: MMode, a Mizar mode for the proof assistant Coq (2003),
https://www.cs.ru.nl/~freek/mmode/mmode.pdf
5. Hales, T.: Formal abstracts (2020), https://formalabstracts.github.io
6. Harrison, J.: A Mizar mode for HOL. In: von Wright, J., Grundy, J., Harrison,
J. (eds.) Theorem Proving in Higher Order Logics: 9th International Conference,
TPHOLs’96. Lecture Notes in Computer Science, vol. 1125, pp. 203–220. Springer-
Verlag, Turku, Finland (1996)
7. Humayoun, M., Raﬀalli, C.: MathNat - mathematical text in a controlled natural
language. Journal on Research in Computing Science 46 (2010)
8. Isabelle contributors: The Isabelle2021 release (2021), https://isabelle.in.tum.de
9. Kaliszyk, C., Rabe, F.: A survey of languages for formalizing mathematics. In:
Benzmüller, C., Miller, B. (eds.) Intelligent Computer Mathematics. pp. 138–156.
Springer International Publishing, Cham (2020). https://doi.org/10.1007/978-3-
030-53518-6_9
10. Koepke, P.: Textbook mathematics in the Naproche-SAD system. In: Brady, E.,
Davenport, J., Farmer, W.M., Kaliszyk, C., Kohlhase, A., Kohlhase, M., Müller,
D., Pąk, K., Coen, C.S. (eds.) Joint Proceedings of the FMM and LML Workshops
(2019), http://ceur-ws.org/Vol-2634/FMM4.pdf
11. Mizar, http://www.mizar.org/
12. de Moura, L.M., Kong, S., Avigad, J., van Doorn, F., von Raumer, J.: The
Lean Theorem Prover (system description). In: Felty, A.P., Middeldorp, A.
(eds.) Automated Deduction – CADE-25 – 25th International Conference on
Automated Deduction, Berlin, Germany, August 1-7, 2015, Proceedings. Lec-
ture Notes in Computer Science, vol. 9195, pp. 378–388. Springer (2015).
https://doi.org/10.1007/978-3-319-21401-6_26
13. Naproche contributors: FLib, https://github.com/naproche-community/FLib
14. Paskevich, A.: Méthodes de formalisation des connaissances et des raisonnements
mathématiques: aspects appliqués et théoriques. Ph.D. thesis, Université Paris 12
(2007), http://tertium.org/papers/thesis-07.fr.pdf
15. Paskevich, A.: The syntax and semantics of the ForTheL language (2007), http:
//nevidal.org/download/forthel.pdf
16. Paulson, L.C.: ALEXANDRIA: Large-scale formal proof for the working mathem-
atician, https://www.cl.cam.ac.uk/~lp15/Grants/Alexandria
The Isabelle/Naproche Natural Language Prooof Assistant
623

17. Paulson, L.C., Blanchette, J.C.: Three years of experience with Sledgehammer, a
practical link between automatic and interactive theorem provers. In: Sutcliﬀe, G.,
Schulz, S., Ternovska, E. (eds.) IWIL 2010. The 8th International Workshop on the
Implementation of Logics. EPiC Series in Computing, vol. 2, pp. 1–11. EasyChair
(2012). https://doi.org/10.29007/36dt
18. Paulson, L.C., Nipkow, T., Wenzel, M.: From LCF to Isabelle/HOL. Formal
Aspects of Computing 31, 675–698 (September 2019), https://doi.org/10.1007/
s00165-019-00492-1, Springer, London
19. Schulz, S.: The E Theorem Prover, https://eprover.org
20. Verchinine, K., Lyaletski, A., Paskevich, A.: System for automated deduction
(SAD): a tool for proof veriﬁcation. Automated Deduction–CADE-21 pp. 398–403
(2007). https://doi.org/10.1007/978-3-540-73595-3_29
21. Verchinine, K., Lyaletski, A., Paskevich, A., Anisimov, A.: On correctness of
mathematical texts from a logical and practical point of view. In: Autexier, S.,
Campbell, J., Rubio, J., Sorge, V., Suzuki, M., Wiedijk, F. (eds.) International
Conference on Intelligent Computer Mathematics. pp. 583–598. Springer (2008).
https://doi.org/10.1007/978-3-540-85110-3_47
22. Wenzel, M.: The Isar proof language in 2016 (2016), http://sketis.net/wp-content/
uploads/2016/08/Isabelle_Workshop_2016_Isar.pdf
23. Wenzel, M.: Interaction with formal mathematical documents in Isabelle/PIDE.
In: Kaliszyk, C., Brady, E., Kohlhase, A., Sacerdoti Coen, C. (eds.) Intelligent
Computer Mathematics (CICM 2019). Lecture Notes in Artiﬁcial Intelligence, vol.
11617. Springer (2019). https://doi.org/10.1007/978-3-030-23250-4_1
24. Wenzel, M.: Isar — a generic interpretative approach to readable formal proof
documents. In: Bertot, Y., Dowek, G., Théry, L., Hirschowitz, A., Paulin, C. (eds.)
Theorem Proving in Higher Order Logics. pp. 167–183. Springer Berlin Heidelberg,
Berlin, Heidelberg (1999)
25. Wiedijk, F.: Mizar light for HOL light. In: Boulton, R.J., Jackson, P.B. (eds.)
TPHOLs: International Conference on Theorem Proving in Higher Order Logics.
pp. 378–393. Springer (2001)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.
624
A. De Lon et al.

Programming Language
1 Microsoft Research, Redmond WA, USA
leonardo@microsoft.com
2 Karlsruhe Institute of Technology, Karlsruhe, Germany
sebastian.ullrich@kit.edu
Abstract. Lean 4 is a reimplementation of the Lean interactive theo-
rem prover (ITP) in Lean itself. It addresses many shortcomings of the
previous versions and contains many new features. Lean 4 is fully extensi-
ble: users can modify and extend the parser, elaborator, tactics, decision
procedures, pretty printer, and code generator. The new system has a hy-
gienic macro system custom-built for ITPs. It contains a new typeclass
resolution procedure based on tabled resolution, addressing signiﬁcant
performance problems reported by the growing user base. Lean 4 is also
an eﬃcient functional programming language based on a novel program-
ming paradigm called functional but in-place. Eﬃcient code generation
is crucial for Lean users because many write custom proof automation
procedures in Lean itself.
1
Introduction
The Lean project3 started in 2013 [9] as an interactive theorem prover based on
the Calculus of Inductive Constructions [4] (CIC). In 2017, using Lean 3, a com-
munity of users with very diﬀerent backgrounds started the Lean mathematical
library project mathlib [13]. At the time of this writing, mathlib has roughly half
a million lines of code, and contains many nontrivial mathematical objects such
as Schemes [2]. Mathlib is also the foundation for the Perfectoid Spaces in Lean
project [1], and the Liquid Tensor challenge [11] posed by the renowned mathe-
matician Peter Scholze. Mathlib contains not only mathematical objects but also
Lean metaprograms that extend the system [5]. Some of these metaprograms
implement nontrivial proof automation, such as a ring theory solver and a de-
cision procedure for Presburger arithmetic. Lean metaprograms in mathlib also
extend the system by adding new top-level command and features not related
to proof automation. For example, it contains a package of semantic linters that
alert users to many commonly made mistakes [5]. Lean 3 metaprograms have
3 http://leanprover.github.io
Leonardo de Moura1(B)
and Sebastian Ullrich2
The Lean 4 Theorem Prover and
© The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp. 625–635, 2021.
https://doi.org/10.1007/978-3-030-79876-5_37

626
L. de Moura, S. Ullrich
been also instrumental in building standalone applications, such as a SQL query
equivalence checker [3].
We believe the Lean 3 theorem prover’s success is primarily due to its exten-
sibility capabilities and metaprogramming framework [6]. However, users cannot
modify many parts of the system without changing Lean 3 source code written
in C++. Another issue is that many proof automation metaprograms are not
competitive with similar proof automation implemented in programming lan-
guages with an eﬃcient compiler such as C++ and OCaml. The primary source
of ineﬃciency in Lean 3 metaprograms is the virtual machine interpretation
overhead.
Lean 4 is a reimplementation of the Lean theorem prover in Lean itself4.
It is an extensible theorem prover and an eﬃcient programming language. The
new compiler produces C code, and users can now implement eﬃcient proof au-
tomation in Lean, compile it into eﬃcient C code, and load it as a plugin. In
Lean 4, users can access all internal data structures used to implement Lean
by merely importing the Lean package. Lean 4 is also a platform for developing
eﬃcient domain-speciﬁc automation. It has a more robust and extensible elab-
orator, and addresses many other shortcomings of Lean 3. We expect the Lean
community to extend and add new features without having to change the Lean
source code. We released Lean 4 at the beginning of 2021, it is open source, the
community is already porting mathlib, and the number of applications is quickly
growing. It includes a translation veriﬁer for Reopt5, a package for supporting
inductive-inductive types6, and a car controller7.
2
Lean by Example
In this section, we introduce the Lean language using a series of examples. The
source code for the examples is available at https://github.com/leanprover/
lean4/blob/cade2021/doc/BoolExpr.lean. For additional details and instal-
lation instructions, we recommend the reader consult the online manual8.
We deﬁne functions by using the def keyword followed by its name, a pa-
rameter list, return type, and body. The parameter list consists of successive
parameters that are separated by spaces. We can specify an explicit type for
each parameter. If we do not specify a speciﬁc argument type, the elaborator
tries to infer the function body’s type. The Boolean or function is deﬁned by
pattern-matching as follows
def or (a b : Bool) :=
match a with
| true
=> true
| false => b
4 http://github.com/leanprover/lean4
5 https://github.com/GaloisInc/reopt-vcg
6 https://github.com/javra/iit
7 https://github.com/GaloisInc/lean4-balance-car
8 http://leanprover.github.io/lean4/doc

The Lean 4 Theorem Prover and Programming Language
627
We can use the command #check <term> to inspect the type of term, and #eval
<term> to evaluate it.
#check or true false -- Bool (this is a comment in Lean)
#eval
or true false -- true
Lean has a hygienic macro system and comes equipped with many macros for
commonly used idioms. For example, we can also deﬁne the function or using
def or : Bool →Bool →Bool
| true, _
=> true
| false, b => b
The notation above is a macro that expands into a match-expression. In Lean,
a theorem is a deﬁnition whose result type is a proposition. For an example,
consider the following simple theorem about the deﬁnition above
theorem or_true (b : Bool) : or true b = true :=
rfl
The constant rfl has type ∀{α : Sort u} {a : α}, a = a, the curly braces
indicate that the parameters α and a are implicit and should be inferred by
solving typing constraints. In the example above, the inferred values for α and a
are Bool and or true b, respectively, and the resulting type is or true b = or
true b. This is a valid proof because or true b is deﬁnitionally equal to b. In
dependent type theory, every term has a computational behavior, and supports
a notion of reduction. In principle, two terms that reduce to the same value are
called deﬁnitionally equal. In the following example, we use pattern matching to
prove that or b b = b
theorem or_self : ∀(b : Bool), or b b = b
| true
=> rfl
| false => rfl
Note that or b b does not reduce to b, but after pattern matching we have that
or true true (or false false) reduces to true (false).
In the following example, we deﬁne the recursive datatype BoolExpr for rep-
resenting Boolean expressions using the command inductive.
inductive BoolExpr where
| var (name : String)
| val (b : Bool)
| or
(p q : BoolExpr)
| not (p : BoolExpr)
This command generates constructors BoolExpr.var, BoolExpr.val, BoolExpr.or,
and BoolExpr.not. The Lean kernel also generates an inductive principle for the
new type BoolExpr. We can write a basic “simpliﬁer” for Boolean expressions as
follows
def simplify : BoolExpr →BoolExpr
| BoolExpr.or p q => mkOr (simplify p) (simplify q)
| BoolExpr.not p
=> mkNot (simplify p)

628
L. de Moura, S. Ullrich
| e
=> e
where
mkOr : BoolExpr →BoolExpr →BoolExpr
| p, BoolExpr.val true
=> BoolExpr.val true
| p, BoolExpr.val false
=> p
| BoolExpr.val true, p
=> BoolExpr.val true
| BoolExpr.val false, p
=> p
| p, q
=> BoolExpr.or p q
mkNot : BoolExpr →BoolExpr
| BoolExpr.val b => BoolExpr.val (not b)
| p
=> BoolExpr.not p
The function simplify is a simple bottom-up simpliﬁer. We use the where clause
to deﬁne two local auxiliary functions mkOr and mkNot for constructing “simpliﬁed”
or and not expressions respectively. Their global names are simplify.mkOr and
simplify.mkNot.
Given a context that maps variable names to Boolean values, we deﬁne a “de-
notation” function (or evaluator) for Boolean expressions. We use an association
list to represent the context.
abbrev Context := AssocList String Bool
def denote (ctx : Context) : BoolExpr →Bool
| BoolExpr.or p q => denote ctx p || denote ctx q
| BoolExpr.not p
=> !denote ctx p
| BoolExpr.val b => b
| BoolExpr.var x => if let some b := ctx.find? x then b else false
In the example above, p || q is notation for or p q, !p for not p, and if let
p := t then a else b is a macro that expands into match t with | p => a | _
=> b. The term ctx.find? x is syntax sugar for AssocList.find? ctx x.
As in previous versions, we can use tactics for constructing proofs and terms.
We use the keyword by to switch into tactic mode. Tactics are user-deﬁned or
built-in procedures that construct various terms. They are all implemented in
Lean itself. The simp tactic implements an extensible simpliﬁer, and is one of
the most popular tactics in mathlib. Its implementation 9 can be extended and
modiﬁed by Lean users.
. . .
@[simp] theorem denote_mkOr (ctx : Context) (p q : BoolExpr)
: denote ctx (simplify.mkOr p q) = denote ctx (or p q) :=
. . .
def denote_simplify (ctx : Context) (p : BoolExpr)
: denote ctx (simplify p) = denote ctx p :=
by induction p with
| or p q ih1 ih2 => simp [ih1, ih2]
9 https://github.com/leanprover/lean4/blob/cade21/src/Lean/Meta/Tactic/
Simp/Main.lean.

The Lean 4 Theorem Prover and Programming Language
629
| not p ih
=> simp [ih]
| _
=> rfl
In the example above, we use the induction tactic, its syntax is similar to a match-
expression. The variables ih1 and ih2 are the induction hypothesis for p and q in
the ﬁrst alternative for the case p is a BoolExpr.or. The simp tactic uses any theo-
rem marked with the @[simp] attribute as a rewriting rule (e.g., denote_mkOr). We
explicitly provide the induction hypotheses as additional rewriting rules inside
square brackets.
Typeclass Resolution. Typeclasses [16] provide an elegant and eﬀective way of
managing ad-hoc polymorphism in both programming languages and interactive
proof assistants. Then we can declare particular elements of a typeclass to be
instances. These provide hints to the elaborator: any time the elaborator is
looking for an element of a typeclass, it can consult a table of declared instances
to ﬁnd a suitable element. What makes typeclass inference powerful is that one
can chain instances, that is, an instance declaration can in turn depend on other
instances. This causes class inference to recurse through instances, backtracking
when necessary. The Lean typeclass resolution procedure can be viewed as a
simple λ-Prolog interpreter [8], where the Horn clauses are the user declared
instances.
For example, the standard library deﬁnes a typeclass Inhabited to enable
typeclass inference to infer a “default” or “arbitrary” element of types that contain
at least one element.
class Inhabited (α : Sort u) where
default : α
def arbitrary [Inhabited α] : α :=
Inhabited.default
The annotation [Inhabited α] at arbitrary indicates that this implicit parame-
ter should be synthesized from instance declarations using typeclass resolution.
We can deﬁne an instance for our BoolExpr type deﬁned earlier as follows
instance : Inhabited BoolExpr where
default := BoolExpr.val false
This instance speciﬁes that the “default” element for BoolExpr is BoolExpr.val
false. The following declaration shows that if two types α and β are inhabited,
then so is their product:
instance [Inhabited α] [Inhabited β] : Inhabited (α × β) where
default := (arbitrary, arbitrary)
The standard library has many builtin classes such as Repr α and DecidableEq
α. The class Repr α is similar to Haskell’s Show α typeclass, and DecidableEq α
is a typeclass for types that have decidable equality. Lean 4 also provides code
synthesizers for many builtin classes. The command deriving instructs Lean to
auto-generate an instance.

630
L. de Moura, S. Ullrich
deriving instance DecidableEq for BoolExpr
#eval decide (BoolExpr.val true = BoolExpr.val false) -- false
In the example above, the deriving command generates the instance
(a b : BoolExpr) →Decidable (a = b)
The function decide evaluates decidable propositions. Thus, the last command
returns false since BoolExpr.val true is not equal to BoolExpr.val false.
The increasingly sophisticated uses of typeclasses in mathlib have exposed a
few limitations in Lean 3: unnecessary overhead due to the lack of term indexing
techniques, and exponential running times in the presence of diamonds. Lean 4
implements a new procedure [12], tabled typeclass resolution, that solves these
problems by using discrimination trees10. for better indexing and tabling, which
is a generalization of memoizing introduced initially to address similar limitations
of early logic programming systems11.
The hygienic macro system. In interactive theorem provers (ITPs), Lean in-
cluded, extensible syntax is not only crucial to lower the cognitive burden of
manipulating complex mathematical objects, but plays a critical role in devel-
oping reusable abstractions in libraries. Lean 3 support such extensions in the
form of restrictive “syntax sugar” substitutions and other ad hoc mechanisms,
which are too rudimentary to support many desirable abstractions. As a result,
libraries are littered with unnecessary redundancy. The Lean 3 tactic languages
is plagued by a seemingly unrelated issue: accidental name capture, which often
produces unexpected and counterintuitive behavior. Lean 4 takes ideas from the
Scheme family of programming languages and solves these two problems simul-
taneously by use of a hygienic, i.e. capture-avoiding, macro system custom-built
for ITPs [15].
Lean 3’s “mixﬁx” notation system is still supported in Lean 4, but based
on the much more general macro system; in fact, the Lean 3 notation keyword
itself has been reimplemented as a macro, more speciﬁcally as a macro-generating
macro. By providing such a tower of abstractions for writing syntax sugars, of
which we will see more levels below, we want to enable users to work in the
simplest model appropriate for their respective use case while always keeping
open the option to switch to a lower, more expressive level.
As an example, we deﬁne the inﬁx notation Γ ⊢p, with precedence 50, for
the function denote deﬁned earlier.
infix:50 "⊢" => denote
The infix command expands to
notation:50 Γ "⊢" p:50 => denote Γ p
10 https://github.com/leanprover/lean4/blob/cade21/src/Lean/Meta/
DiscrTree.lean.
11 https://github.com/leanprover/lean4/blob/cade21/src/Lean/Meta/
SynthInstance.lean.

The Lean 4 Theorem Prover and Programming Language
631
which itself expands to the macro declaration
macro:50 Γ:term "⊢" p:term:50
: term => `(denote $Γ $p)
where the syntactic category (term) of placeholders and of the entire macro is
now speciﬁed explicitly, implying that macros can also be written for/using other
categories such as the top-level command. The right-hand side uses an explicit
syntax quasiquotation to construct the syntax tree, with syntax placeholders
(antiquotations) preﬁxed with $. As suggested by the explicit use of quotations,
the right-hand side may now be an arbitrary Lean term computing a syntax
object, allowing for procedural macros as well.
macro itself is another command-level macro that, for our notation example,
expands to two commands
syntax:50 term "⊢" term:50 : term
macro_rules
| `($Γ ⊢$e) => `(denote $Γ $e)
that is, a pair of parser extension and syntax transformer. By separating these
two steps at this abstraction level, it becomes possible to deﬁne (mutually) re-
cursive macros and to reuse syntax between macros. Using macro_rules, users
can even extend existing macros with new rules. In general, separating pars-
ing and expansion means that that we can obtain a well-structured syntax tree
pre-expansion, i.e. a concrete syntax tree, and use it to implement source code
tooling such as auto-completion, go-to-deﬁnition, and refactorings.
We can use the syntax command for deﬁning embedded domain-speciﬁc lan-
guages. In simple cases, we can reuse existing syntactic categories for this but
assign them new semantics, such as in the following notation for constructing
BoolExpr objects.
syntax "`[BExpr|" term "]" : term
macro_rules
| `(`[BExpr| true])
=> `(BoolExpr.val true)
| `(`[BExpr| false])
=> `(BoolExpr.val false)
| `(`[BExpr| $x:ident]) => `(BoolExpr.var $(quote x.getId.toString))
| `(`[BExpr| $p ∨$q])
=> `(BoolExpr.or `[BExpr| $p] `[BExpr| $q])
| `(`[BExpr| ¬ $p])
=> `(BoolExpr.not `[BExpr| $p])
#check `[BExpr| p ∨true]
-- BoolExpr.or (BoolExpr.var "p") (BoolExpr.val true) : BoolExpr
The macro_rules command above speciﬁes how to convert a subset of the builtin
syntax for terms into constructor applications for BoolExpr. The term $(quote
x.getId.toString) converts the identiﬁer x into a string literal.
As a ﬁnal example, we modify the notation Γ ⊢p. In the following version, Γ
is not an arbitrary term anymore, but a comma-separated sequence of entries of
the form var →value, and the right-hand side is now interpreted as a BoolExpr
term by reusing our macro from above.
syntax entry := ident " →" term:max
syntax entry,* "⊢" term : term

632
L. de Moura, S. Ullrich
macro_rules
| `( $[$xs:ident →$vs:term],* ⊢$p:term ) =>
let xs := xs.map fun x => quote x.getId.toString
`(denote (List.toAssocList [$[( $xs , $vs )],*]) `[BExpr| $p])
#eval a →false, b →true ⊢b ∨a
-- true
We use the antiquotation splice $[$xs:ident →$vs:term],* to deconstruct the
sequence of entries into two arrays xs and vs containing the variable names and
values, respectively, adjust the former array, and combine them again in a second
splice.
3
The Code Generator
The Lean 4 code generator produces eﬃcient C code. It is useful for building
both eﬃcient Lean extensions and standalone applications. The code genera-
tor performs many transformations, and many of them are based on techniques
used in the Haskell compiler GHC [7]. However, in contrast to Haskell, Lean is a
strict language. We control code inlining and specialization using the attributes
@[inline] and @[specialize]. They are crucial for eliminating the overhead in-
troduced by the towers of abstractions used in our source code. Before emitting
C code, we erase proof terms and convert Lean expressions into an intermediate
representation (IR). The IR is a collection of Lean data structures,12 and users
can implement support for backends other than C by writing Lean programs
that import Lean.Compiler.IR. Lean 4 also comes with an interpreter for the IR,
which allows for rapid incremental development and testing right from inside the
editor. Whenever the interpreter calls a function for which native, ahead-of-time
compiled code is available, it will switch to that instead, which includes all func-
tions from the standard library. Thus the interpretation overhead is negligible
as long as e.g. all expensive tactics are precompiled.
Functional but in-place. Most functional languages rely on garbage collection
for automatic memory management. They usually eschew reference counting in
favor of a tracing garbage collector, which has less bookkeeping overhead at run-
time. On the other hand, having an exact reference count of each value enables
optimizations such as destructive updates [14]. When performing functional up-
dates, objects often die just before creating an object of the same kind. We
observe a similar phenomenon when we insert a new element into a purely func-
tional data structure, such as binary trees, a theorem prover rewrites formulas,
a compiler applies optimizations by transforming abstract syntax trees, or the
function simplify deﬁned earlier. We call it the resurrection hypothesis: many
objects die just before creating an object of the same kind. The Lean mem-
ory manager uses reference counting and takes advantage of this hypothesis,
and enables pure code to perform destructive updates in all scenarios described
12 https://github.com/leanprover/lean4/blob/cade21/src/Lean/Compiler/IR/
Basic.lean

The Lean 4 Theorem Prover and Programming Language
633
above when objects are not shared. It also allows a novel programming paradigm
that we call functional but in-place (FBIP) [10]. Our preliminary experimental
results demonstrate our new compiler produces competitive code that often out-
performs the code generated by high-performance compilers such as ocamlopt
and GHC [14]. As an example, consider the function map f as that applies a
function f to each element of a list as. In this example, [] denotes the empty
list, and a::as the list with head a followed by the tail as.
def map : (α →β) →List α →List β
| f, []
=> []
| f, a::as => f a :: map f as
If the list referenced by as is not shared, the code generated by our compiler does
not allocate any memory. Moreover, if as is a nonshared list of list of integers,
then map (map inc) as will not allocate any memory either. In contrast to
static linearity systems, allocations are also avoided even if only a preﬁx of the list
is not shared. FBIP also allows Lean users to use data structures, such as arrays
and hashtables, in pure code without any performance penalty when they are not
shared. We believe this is an attractive feature because hashtables are frequently
used to implement decision procedures and nontrivial proof automation.
4
The User Interface
Our system implements the Language Server Protocol (LSP) using the task ab-
straction provided by its standard library. The Lean 4 LSP server is incremental
and is continuously analyzing the source text and providing semantic informa-
tion to editors implementing LSP. Our LSP server implements most LSP features
found in advanced IDEs, such as hyperlinks, syntax highlighting, type informa-
tion, error handling, auto-completion, etc. Many editors implement LSP, but VS
Code is the preferred editor by the Lean user community. We provide extensions
for visualizing the intermediate proof states in interactive tactic blocks, and we
want to port the Lean 3 widget library for constructing interactive visualizations
for their proofs and programs.
5
Conclusion
Lean 4 aims to be a fully extensible interactive theorem prover and functional
programming language. It has an expressive logical foundation for writing mathe-
matical speciﬁcations and proofs and formally veriﬁed programs. Lean 4 provides
many new unique features, including a hygienic macro-system, an eﬃcient type-
class resolution procedure based on tabled resolution, eﬃcient code generator,
and abstractions for sealing low-level optimizations. The new elaboration proce-
dure is more general and eﬃcient than those implemented in previous versions.
Users may also extend and modify the elaborator using Lean itself. Lean has a
relatively small trusted kernel, and the rich API allows users to export their de-
velopments to other systems and implement their own reference checkers. Lean

634
L. de Moura, S. Ullrich
is an ongoing and long-term eﬀort, and future plans include integration with
external SMT solvers and ﬁrst-order theorem provers, new compiler backends,
and porting the Lean 3 Mathematical Library.
Acknowledgments. We are grateful to Marc Huisinga and Wojciech Nawrocki
for developing the LSP server, Daniel Selsam for working with us on the new
typeclass resolution procedure and interesting design discussions, Daan Leijen,
Nikhil Swamy, Sebastian Graf, Simon Peyton Jones, and Max Wagner for advice
and design discussions, Joe Hendrix, Andrew Kent, Rob Dockins, and Simon
Winwood from Galois Inc for being early Lean 4 adopters, and providing useful
feedback and suggestions, and the whole Lean community for all their excitement
and pushing Lean forward.
References
1. Buzzard, K., Commelin, J., Massot, P.: Formalising Perfectoid Spaces. In:
Proceedings of the 9th ACM SIGPLAN International Conference on Cer-
tiﬁed
Programs
and
Proofs.
p.
299–312.
CPP
2020,
New
York,
NY,
USA
(2020).
https://doi.org/10.1145/3372885.3373830,
https://doi.org/10.
1145/3372885.3373830
2. Buzzard, K., Hughes, C., Lau, K., Livingston, A., Mir, R.F., Morrison, S.: Schemes
in Lean. https://arxiv.org/abs/2101.02602 (2021), arXiv:2101.02602
3. Chu, S., Murphy, B., Roesch, J., Cheung, A., Suciu, D.: Axiomatic foundations
and algorithms for deciding semantic equivalences of SQL queries. Proc. VLDB
Endow. 11(11), 1482–1495 (Jul 2018). https://doi.org/10.14778/3236187.3236200,
https://doi.org/10.14778/3236187.3236200
4. Coquand, T., Huet, G.: The calculus of constructions. Inform. and Comput. 76(2-
3), 95–120 (1988)
5. van Doorn, F., Ebner, G., Lewis, R.Y.: Maintaining a library of formal mathemat-
ics. In: Benzmüller, C., Miller, B. (eds.) Intelligent Computer Mathematics. pp.
251–267. Springer International Publishing, Cham (2020)
6. Ebner, G., Ullrich, S., Roesch, J., Avigad, J., de Moura, L.: A metaprogramming
framework for formal veriﬁcation. Proc. ACM Program. Lang. 1(ICFP) (Sep 2017).
https://doi.org/http://dx.doi.org/10.1145/3110278
7. Jones, S.L.P.: Compiling Haskell by program transformation: a report from the
trenches. In: In Proc. European Symp. on Programming. pp. 18–44. Springer-
Verlag (1996)
8. Miller, D., Nadathur, G.: Programming with Higher-Order Logic. Cambridge
(2012)
9. de Moura, L., Kong, S., Avigad, J., Van Doorn, F., von Raumer, J.: The Lean
theorem prover. In: International Conference on Automated Deduction. pp. 378–
388. Springer (2015)
10. Reinking, A., Xie, N., de Moura, L., Leijen, D.: Perceus: Garbage free reference
counting with reuse. Tech. Rep. MSR-TR-2020-42, Microsoft Research (2020)
11. Scholze, P.: Liquid tensor experiment. https://xenaproject.wordpress.com/
2020/12/05/liquid-tensor-experiment
(2020), project repository
https://
github.com/leanprover-community/lean-liquid
12. Selsam, D., Ullrich, S., de Moura, L.: Tabled typeclass resolution. https://arxiv.
org/abs/2001.04301 (2020), arXiv:2001.04301

The Lean 4 Theorem Prover and Programming Language
635
13. The mathlib Community: The Lean mathematical library. In: Proceedings
of
the
9th
ACM
SIGPLAN
International
Conference
on
Certiﬁed
Pro-
grams and Proofs. p. 367–381. CPP 2020, New York, NY, USA (2020).
https://doi.org/10.1145/3372885.3373824,
https://doi.org/10.1145/3372885.
3373824
14. Ullrich, S., de Moura, L.: Counting immutable beans: Reference counting optimized
for purely functional programming. In: 31st Symposium on Implementation and
Application of Functional Languages (2019)
15. Ullrich, S., de Moura, L.: Beyond notations: Hygienic macro expansion for theo-
rem proving languages. In: Peltier, N., Sofronie-Stokkermans, V. (eds.) Automated
Reasoning. pp. 167–182. Cham (2020)
16. Wadler, P., Blott, S.: How to make ad-hoc polymorphism less ad hoc. In: Proceed-
ings of the 16th ACM SIGPLAN-SIGACT symposium on Principles of program-
ming languages. pp. 60–76. ACM (1989)
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/
4.0/), which permits use, sharing, adaptation, distribution and reproduction in any
medium or format, as long as you give appropriate credit to the original author(s) and
the source, provide a link to the Creative Commons license and indicate if changes
were made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Harpoon: Mechanizing Metatheory Interactively
McGill University, Montreal, Canada
{jacob.errington, junyoung.jang}@mail.mcgill.ca, bpientka@cs.mcgill.ca
Abstract. Beluga is a proof checker that provides sophisticated in-
frastructure for implementing formal systems with the logical framework
LF and proving metatheoretic properties as total, recursive functions
transforming LF derivations. In this paper, we describe Harpoon, an
interactive proof engine built on top of Beluga. It allows users to de-
velop proofs interactively using a small, ﬁxed set of high-level actions
that safely transform a subgoal. A sequence of actions elaborates into a
(partial) proof script that serves as an intermediate representation de-
scribing an assertion-level proof. Last, a proof script translates into a
Beluga program which can be type-checked independently. Harpoon
is available on GitHub. We have used Harpoon to replay a wide array
of examples covering all features supported by Beluga. In particular,
we have used it for normalization proofs, including the recently proposed
POPLMark reloaded challenge.
1
Introduction
Mechanizing formal systems and proofs about them plays an important role in
establishing trust in programming languages and verifying software systems in
general. Key questions in this setting are how to represent variables, (simulta-
neous) substitutions, assumptions, and derivations that depend on assumptions.
Higher-order abstract syntax (HOAS) provides an elegant and unifying answer
to these questions, relieving users from having to write boilerplate code.
Beluga is a proof checker with built-in support for HOAS encodings of for-
mal systems based on the logical framework LF [13]. Metatheoretic inductive
proofs are implemented as recursive, dependently-typed functions that manip-
ulate and transform HOAS representations [21,4,25]. In this paper, we describe
the interactive proof engine Harpoon which is built on top of Beluga. A
Harpoon user modularly and incrementally develops a metatheoretic proof by
solving independent subgoals via a ﬁxed set of high-level actions. An action elim-
inates the subgoal on which it is executed, ﬁlling it with a proof that possibly
contains new subgoals to be resolved. The actions we support are: introduction of
assumptions, case-analysis, inductive reasoning, and both forward and backward
reasoning styles.
© The Author(s) 2021
A. Platzer and G. Sutcliﬀe (Eds.): CADE 2021, LNAI 12699, pp.
48, 2021.
https://doi.org/10.1007/978-3-030-79876-5 38
Jacob Errington
, Junyoung Jang
, and Brigitte Pientka
636–6

Mechanizing Metatheory Interactively
637
While our ﬁxed set of actions is largely inspired by similar systems such
as Twelf [20,28,27] and Abella [11], Harpoon advances the state of the art in
interactively developing mechanized proofs about HOAS representations in two
ways: 1. We treat subgoals as ﬁrst-class and characterize them using contextual
types that pair their goal types together with the contexts in which they are
meaningful; a contextual substitution property guarantees that each step of proof
development correctly reﬁnes the partial proof under construction [8]. 2. Rather
than simply record the sequence of actions given by the user, we elaborate this
sequence into an assertion-level proof [15], represented as what we call a proof
script. The proof script is what we record as output of an interactive session. It
can be both typechecked directly and translated into a Beluga program.
We have used Harpoon (see https://beluga-lang.readthedocs.io/) on a wide
range of representative examples from the Beluga library: normalization proofs
for the simply-typed lambda calculus [6], benchmarks for reasoning about binders
[9,10], and the recent POPLMark Reloaded challenge [1]. These examples involve
numerous concerns that arise in proof development, and cover all the domain-
speciﬁc abstractions that Beluga provides. Our experience shows that Har-
poon lowers the entry barrier for users: they only need to understand how to
represent formal systems and derivations using HOAS encodings and can then
manipulate the HOAS representations directly via the high-level actions which
correspond closely to how proofs are developed on paper. As such, we believe
that Harpoon eases the task of proving metatheoretic statements.
2
Proof Development in Harpoon
We introduce the main features of Harpoon by interactively developing the
proof of two lemmas that play a central role in the proof of weak normalization
of the simply-typed lambda calculus. For a more detailed description, see [6].
2.1
Initial setup: encoding the language
We begin by deﬁning the simply-typed lambda-calculus in the logical framework
LF [13] using an intrinsically typed encoding. In typical HOAS style, lambda
abstraction takes an LF function representing the abstraction of a term over a
variable. There is no case for variables, as they are treated implicitly. We remind
the reader that this is a weak, representational function space – there is no case
analysis or recursion, so only genuine lambda terms can be represented.
LF tp : type =
| unit: tp
| arr : tp →tp →tp;
LF tm : tp →type =
| lam : (tm T1 →tm T2) →tm (arr T1 T2)
| app : tm (arr T1 T2) →tm T1 →tm T2;
Free variables such as T1 and T2 are implicitly universally quantiﬁed (see [23])
and programmers subsequently do not supply arguments for implicitly quantiﬁed
parameters when using a constructor.

638
J. Errington et al.
Next, we deﬁne a small-step operational semantics for the language. For
simplicity, we use a call-by-name reduction strategy and do not reduce under
lambda-abstractions. Note that we use LF application to encode the object-level
substitution in the s_beta rule.
LF step : tm T →tm T →type =
| s_app : step M M’
→step (app M N) (app M’ N)
| s_beta: step (app (lam M) N) (M N);
LF steps : tm T →tm T →type =
| next : step M M’ →steps M’ N
→steps M N
| refl: steps M M;
Using this deﬁnition, we deﬁne a notion of termination: a term halts if it
reduces to a value. This is captured by the constructor halts/m.
LF val : tm T →type = v_lam: val (lam M);
LF halts : tm T →type = halts/m : val V →steps M V →halts M;
2.2
Termination Property: intros, split, unbox, and solve
As the ﬁrst short lemma, we show the Termination property: if M’ is known to
halt and steps M M’, then M also halts. We start our interactive proof session by
loading the signature and deﬁning the name of the theorem and the statement
that we want to prove.
Name of theorem: halts_step
Statement of theorem: [ ⊢step M M’] →[ ⊢halts M’] →[ ⊢halts M]
We pair each LF object such as step M M’ together with the LF context in
which it is meaningful [21,26,19]. We refer to such an object as a contextual ob-
ject and embed contextual types, written as
_ ⊢_ , into Beluga types using the
“box” syntax. In this example, the LF context, written on the left of ⊢, is empty,
as we consider closed LF objects. As before, the free variables M and M’ are implic-
itly quantiﬁed at the outside. They themselves stand for contextual objects and
have contextual type ( ⊢tm T). The theorem statements are hence statements
about contextual LF objects and directly correspond to Beluga types.
The proof begins with a single subgoal whose type is simply the statement
of the theorem under no assumptions. Since this subgoal has a function type,
Harpoon will automatically apply the intros action, which introduces assump-
tions as follows: First, the (implicitly) universally quantiﬁed variables M, M’ are
added to the meta-context. This context collects parameters introduced by uni-
versal quantiﬁers. This is in contrast with the computational context, which col-
lects assumptions introduced by the simple function space. In particular, the
second phase of the intros action adds the assumptions s : [⊢step M M’] and
h : [⊢halts M’] to the computational context. Observe that since M and M’ have
type tm T, intros also adds T to the meta-context, although it is implicit in the
deﬁnitions of step and halts and is not visible at all in the theorem statement
(see the meta-context Fig. 1 step 1).
The proof proceeds by inversion on h. Using the split action, we add the
two new assumptions S:(⊢steps M’ M2) and V:(⊢val M2) to the meta-context

Mechanizing Metatheory Interactively
639
Step 1
Step 2
Step 3
Meta-context:
T : ( ⊢tp)
M : ( ⊢tm T)
M’ : ( ⊢tm T)
Computational context:
s : [ ⊢step M M’]
h : [ ⊢halts M’]
[ ⊢halts M]
> split h
Meta-context:
T : ( ⊢tp)
M : ( ⊢tm T)
M’ : ( ⊢tm T)
M2 : ( ⊢tm T)
S : ( ⊢steps M’ M2)
V : ( ⊢val M2)
Computational context:
s : [ ⊢step M M’]
h : [ ⊢halts M’]
[ ⊢halts M]
> unbox s as S’
Meta-context:
T : ( ⊢tp)
M : ( ⊢tm T)
M’ : ( ⊢tm T)
M2 : ( ⊢tm T)
S : ( ⊢steps M’ M2)
V : ( ⊢val M2)
S’ : ( ⊢step M M’)
Computational context:
s : [ ⊢step M M’]
h : [ ⊢halts M’]
[ ⊢halts M]
> solve [⊢halts/m (next S’ S) V]
Fig. 1. Interactive session of the proof for the halts_step lemma.
(see Fig. 1, step 1.). To build a proof for [⊢halts M], we need to show that
there is a step from M to some value M2. To build such a derivation, we use
ﬁrst the unbox action on the computation-level assumption s to obtain an as-
sumption S’ in the meta-context which is accessible to the LF layer (inside a
box) (see Fig. 1, step 2.). Finally, we can ﬁnish the proof by supplying the term
[ ⊢halts/m (next S’ S) V] with the solve action (see Fig. 1, step 3). This is
similar to the exact tactic in Coq.
The resulting proof script is given below. Assertions are written in boldface
and curly braces denote new scopes, listing the full meta-context and the full
computational context. Using an erasure we can then generate a translated pro-
gram in the external syntax, i.e. the syntax a user would use when implementing
the proof directly, rather than the internal syntax. It is hence much more com-
pact than the actual proof script. This program can then be seamlessly combined
with hand-written Beluga programs and can also independently type-checked.
Theorem halts_step:[ ⊢step M M’] →[ ⊢halts M’] →[ ⊢halts M]
Proof Script
Erased program (external syntax)
intros
{ T : ( ⊢tp), M : ( ⊢tm T), M’ : ( ⊢tm T)
| s : [ ⊢step M M’], h : [ ⊢halts M’]
; split h as
case halts/m:
{ T : ( ⊢tp), M : ( ⊢tm T), M’ : ( ⊢tm T),
M2 : ( ⊢tm T), S : ( ⊢steps M’ M2), V : ( ⊢val M2)
| s : [ ⊢step M M’], h : [ ⊢halts M’]
; by s as S’ unboxed
; solve [ ⊢halts/m (next S’ S) V]
}
}
fn s => fn h =>
let [ ⊢halts/m S V] = h in
let [ ⊢S’] = s in
[ ⊢halts/m (next S’ S) V]
2.3
Setup continued: reducibility
We now consider one of the key lemmas in the weak normalization proof, called
the backwards closed lemma, i.e. if M’ is reducible at some type T and M steps to

640
J. Errington et al.
M’, then M is also reducible at T. We begin to deﬁne a set of terms reducible at a
type T. All reducible terms are required to halt, and reducible terms at an arrow
type are required to produce reducible output given reducible input. Concretely,
a term M is reducible at type (arr T1 T2), if for all terms N:tm T1 where N is
reducible at type T1, then (app M N) is reducible at type T2. Reducibility cannot
be directly encoded on the LF layer, as it is not merely describing the syntax
of an expression or derivation. Instead, we encode the set of reducible terms
using the stratiﬁed type Reduce which is recursively deﬁned on the type T in
Beluga (see [16]). Note that we write { } for explicit universal quantiﬁcation
over contextual objects.
stratified Reduce : {T : (⊢
tp)} [⊢
tm T] →ctype =
| Unit: [⊢halts M] →Reduce [⊢unit] [⊢M]
| Arr : [⊢halts M]
→({N:(⊢tm T1)} Reduce [⊢T1] [⊢N] →Reduce [⊢T2] [⊢app M N])
→Reduce [⊢arr T1 T2] [⊢M];
2.4
Backwards Closed Property: msplit, suffices, and by
We can now state the backwards closed lemma formally as follows: if M’ is re-
ducible at some type T and M steps to M’, then M is also reducible at T. We prove
this lemma by induction on T. This is speciﬁed by referring to the position of
the induction variable in the statement.
Name of theorem: bwd_closed
Statement of theorem:
{T : (⊢tp)} {M : (⊢tm T)} {M’ : (⊢tm T)}
[⊢step M M’] →Reduce [⊢T] [⊢M’] →Reduce [⊢T] [⊢M]
Induction order: 1
After Harpoon automatically introduces the metavariables T, M, and M’ to-
gether with an assumption s : [⊢step M M’] and r : Reduce [⊢T] [⊢M’], we
use msplit T to split the proof into two cases (see Fig. 2, step 1). Whereas split
case analyzes a Beluga type, msplit considers the cases for a (contextual) LF
type. In reality, msplit is implemented in terms of the split action.
The case for T = unit is straightforward (see Fig. 2, steps 2 and 3). First,
we use the split action to invert the premise r : Reduce [⊢unit] [⊢M’]. Then,
we use the by action to invoke the halts_step lemma (see Sec. 2.2) to obtain an
assumption h : [⊢halts M]. We solve this case by supplying the term Unit h
(see Fig. 2 step 3).
In the case for T = arr T1 T2, we begin similarly by inversion on r us-
ing the split action (see Fig. 3 step 4). We observe that the goal type is
Reduce [⊢arr T1 T2] [⊢M], which can be produced by using the Arr constructor
if we can construct a proof for each of the user-speciﬁed types, [⊢halts M] and
{N:(⊢tm T1)} Reduce [⊢T1] [⊢N] →Reduce [⊢T2] [⊢app M N]. Such back-
wards reasoning is accomplished via the suffices action. The user supplies a
term representing an implication whose conclusion is compatible with the cur-
rent goal and proceeds to prove its premises as speciﬁed (see Fig.3 step 5).

Mechanizing Metatheory Interactively
641
Step 1
Step 2
Step 3
Meta-context:
T : ( ⊢tp )
M : ( ⊢tm T )
M’ : ( ⊢tm T )
Computational context:
s : [⊢step M M’]
r : Reduce [⊢T] [⊢M’]
Reduce [⊢T] [⊢M]
> msplit T
Meta-context:
M : ( ⊢tm unit )
M’: ( ⊢tm unit )
Computational context:
s : [⊢step M M’]
r : Reduce [⊢unit] [⊢M’]
Reduce [⊢unit] [⊢M]
> split r
Meta-context:
M : ( ⊢tm unit )
M’: ( ⊢tm unit )
Computational context:
s : [⊢step M M’]
h’: [⊢halts M’ ]
r : Reduce [⊢unit] [⊢M’]
Reduce [⊢unit] [⊢M]
> by halts_step s h’ as h;
solve Unit h
Fig. 2. Backwards Closed Lemma. Step 1: Case analysis of the type T; Steps 2 and 3:
Base case (T = unit).
To prove the ﬁrst premise, we apply the halts_step lemma (see Fig. 3 step
6). As for the second premise, Harpoon ﬁrst automatically introduces the
variable N:(⊢tm T1) and the assumption r1:Reduce [⊢T1] [⊢N], so it remains
to show Reduce [⊢T2] [⊢app M N]. We deduce r’:Reduce [⊢T2] [⊢app M’ N]
using the assumption
rn. Using
s:[⊢step M M’], we build a derivation
s’:[⊢step (app M N) (app M’ N)] using s_app. Finally, we appeal to the induc-
tion hypothesis. Using the by action, we refer to the recursive call to complete
the proof (see Fig. 3 step 7). The resulting proof script (of around 70 lines) can
again be translated into a compact program.
Note that Harpoon allows users to use underscores to stand for arguments
that are uniquely determined (see Harpoon Proof 3 step 7). We enforce that
these underscores stand for uniquely determined objects in order to guarantee
that the contexts and the goal type of every subgoal are closed. This ensures
modularity: solving one subgoal does not aﬀect any other open subgoals. As a
consequence, users are not restricted in their proof development. As they would
on paper, users can work on goals in any order, mix forward and backward
reasoning, erase wrong parts, and replace them by correct steps.
Using the explained actions, one can now prove the fundamental lemma and
the weak normalization theorem. For a more detailled description of this proof
in Beluga see [5,6].
Additional actions. Harpoon supports some additional features not dis-
cussed in this paper; see https://beluga-lang.readthedocs.io/ for a complete list
of actions. In general, these actions add no expressive power, but enable more
precise expression of a user’s intent. For example, the invert action splits on
the type of a given term, ensuring that there is a unique case to consider. It is
implemented simply as the split action followed by an additional check.
3
Implementation of Harpoon
Harpoon is a front end that allows users to construct a proof for a theorem
statement represented as a Beluga type. Types in Beluga include universal

642
J. Errington et al.
Step 4
Step 5
Meta-context:
T1 : (⊢tp)
T2 : (⊢tp)
M
: (⊢tm (arr T1 T2))
M’ : (⊢tm (arr T1 T2))
Computational context:
s
: [⊢step M M’]
r
: Reduce [⊢arr T1 T2][⊢M’]
Reduce [⊢arr T1 T2][⊢M]
> split r
Meta-context:
T1 : (⊢tp)
T2 : (⊢tp)
M
: (⊢tm (arr T1 T2))
M’ : (⊢tm (arr T1 T2))
Computational context:
s
: [⊢step M M’]
rn : {N : ( ⊢tm T)}Reduce [⊢N][⊢T]
→Reduce [⊢T2][⊢app M’ N]
h’ : [⊢halts M’]
r
: Reduce [⊢arr T1 T2][⊢M’]
Reduce [⊢arr T1 T2][⊢M]
> suffices by Arr toshow
[⊢halts M],
{N : ( ⊢tm T1)}Reduce [⊢T1][⊢N]
→Reduce [⊢T2][⊢app M N]
Step 6
Step 7
Meta-context:
T1 : (⊢tp)
T2 : (⊢tp)
M
: (⊢tm (arr T1 T2))
M’ : (⊢tm (arr T1 T2))
Computational context:
s
: [⊢step M M’]
rn : {N : ( ⊢tm T)} Reduce [⊢N][⊢T]
→Reduce [⊢T2] [⊢app M’ N]
h’ : [⊢halts M’]
r
: Reduce [⊢arr T1 T2][⊢M’]
[⊢halts M]
> by halts_step s h’ as h
Meta-context:
T1 : (⊢tp)
T2 : (⊢tp)
M
: (⊢tm (arr T1 T2))
M’ : (⊢tm (arr T1 T2))
N
: (⊢tm T1)
Computational context:
s
: [⊢step M M’]
rn : {N : ( ⊢tm T)} Reduce [⊢N][⊢T]
→Reduce [⊢T2] [⊢app M’ N]
h’ : [⊢halts M’]
r
: Reduce [⊢arr T1 T2][⊢M’]
r1 : Reduce [⊢T1] [⊢
N]
Reduce [⊢T2] [⊢app M N]
>
by (rn [⊢N] r1) as r’;
unbox s as S;
by (bwd_closed _ _ _ [⊢s_app S] r’) as ih
Fig. 3. Backwards Closed Lemma: Step Case
quantiﬁcation over contextual types (dependent function space, written with
curly braces), implications (simple function space), boxed contextual types, and
stratiﬁed/recursive types (written as c −→
C where C stands for a contextual ob-
ject). In addition, Beluga supports quantiﬁcation over LF contexts and even
LF substitutions relating two LF contexts. We omit these below for simplicity,
although they are also supported in Harpoon. In essence, Beluga types cor-
respond to statements in ﬁrst-order logic over a domain consisting of contextual
objects, LF contexts, and LF substitutions. We can view c −→
C and [Ψ ⊢A] as
atomic propositions.
Types
τ ::= c −→
C | [Ψ ⊢A] | {X:(Ψ ⊢A)} τ | τ1 →τ2
Meta-Context Δ ::= · | Δ, X::(Ψ ⊢A)
Context
Γ ::= · | Γ, x:τ
Users construct a natural deduction proof for a theorem statement where
Γ, the computation context, contains hypotheses introduced from the simple
function space and where Δ, the meta-context, holds parameters introduced

Mechanizing Metatheory Interactively
643
from the universal quantiﬁer (curly-brace syntax) or by lifting an assumption
[Ψ ⊢A] from Γ (box-elimination rule).
A subgoal in Harpoon is a typed hole in the proof that remains to be ﬁlled
by the user. Such a hole is represented by a subgoal variable, the type of which is a
contextual type (Δ; Γ ⊢τ) that captures the typechecking state at the point the
variable occurs [19,3]: it remains to construct a proof for τ with the parameters
from Δ and the assumptions from Γ. Subgoal variables in the proof script are
collected into a subgoal context and substitution of subgoal variables is type-
preserving [8]. Interactive actions are implemented with subgoal substitutions,
so the correctness of interactive proof reﬁnement is a consequence of the subgoal
substitution property. Note that a subgoal’s type cannot itself contain subgoals –
the subgoal type must be fully determined, so solving one subgoal cannot aﬀect
any other subgoal. Furthermore, subgoal variables may be introduced only in
positions where we must construct a normal term (written e); these are terms
that we must check against a given type. This given type becomes part of the
subgoal’s type. Subgoal variables stand thus in contrast with ordinary variables,
which are neutral terms (written i). (See [14,26,16] for examples of this so-called
bi-directional characterization of normal and neutral proof terms in Beluga.)
An action is executed on a subgoal to eliminate it, while possibly introducing
new subgoals. Actions emphasize the bi-directional nature of interactive proof
construction: some demand normal terms e and others demand neutral terms i.
To execute an action, the system synthesizes a proof script fragment from it, and
substitutes that fragment for the current subgoal. Any subgoal variables present
in the fragment become part of the subgoal context, and the user will have to
solve them later. When no subgoals remain, the proof script is closed and can be
translated straightforwardly to a Beluga program in internal (fully elaborated)
syntax. We employ an erasure to display the program to the user. These are the
essential actions for proof development, omitting our so-called “administrative”
actions (such as undo):
Actions α ::= intros | solve e | by i as x | unbox i as X | split i | suffices i by −→τ
intros introduces all assumptions from function types in the current goal;
solve closes the current subgoal with a given a normal term, introducing no
new subgoals. This action trivially makes Harpoon complete, as a full Beluga
program could be given via solve to eliminate the initial subgoal of any proof.
The action by enables introducing an intermediate result, often from a lemma or
an induction hypothesis, demanding a neutral term i and binding it to a given
name; unbox is the same as by, but it binds the result as a variable in the meta-
context; split considers a covering set of cases for a neutral term (typically a
variable) and generates possible induction hypotheses based on the speciﬁed in-
duction order, (for details on coverage, see [24]); suffices allows programmers
to reason backwards by supplying a neutral term i of function type and the types
−→τ of arguments to construct for this function.

644
J. Errington et al.
4
Empirical evaluation of Harpoon
We give a summary of representative case studies that we replayed using Har-
poon in Table 1. In porting these proofs to Harpoon, we use solve e only when
e is atomic, i.e. it describes either a contextual LF term or a constant applied
to all its arguments (either e = M, e = [C] or e = c −→
C e1 . . . en). We list in the
table the number of commands used to complete the proof and what particular
features made the selected case study interesting for testing Harpoon. The ﬁrst
Case study
Main feature tested
MiniML value soundness
Automatic solving of trivial goals
MiniML compilation completeness
Unboxing program variables
STLC type preservation
Automatic solving of trivial goals
STLC type uniqueness [22]
Open term manipulation; (Contexts, Parame-
ter variables)
STLC weak normalization [6]
Case analysis on LF contexts, substitution vari-
ables, parameter variables, and inductive and
stratiﬁed types.
STLC strong normalization [1]
Larger development (310 commands), all forms
of case analysis as above.
STLC alg. equality completeness [6]
Larger development (180 commands), all forms
of case analysis as above.
Table 1. Summary of proofs ported to Harpoon from Beluga.
four examples proceed by straightforward induction, but the remaining examples
are less direct since they feature logical relations. The STLC strong normaliza-
tion and algorithmic equality completeness examples are larger developments,
totalling 38 and 26 theorems respectively. Crucially, these case studies make use
of Beluga’s domain-speciﬁc abstractions, by splitting on contexts, reasoning
about object-language variables, and exploiting the built-in equational theory of
substitutions. We have since used Harpoon to replay the meta-theoretic proofs
about Standard ML from [18].
This evaluation gives us conﬁdence in the robustness and expressive power
of Harpoon.
5
Related work
There are several approaches to specify and reason about formal systems.
Beluga and hence Harpoon belong to the lineage of the Twelf system [20],
which also implements the logical framework LF. Metatheoretic proofs in Twelf
are implemented as relations. Totality checking then ensures that these relations
correspond to actual proofs. As Twelf is limited to proving Π1 formulas (“forall-
exists” statements), normalization proofs using logical relations cannot be di-
rectly encoded. Although Harpoon’s actions are largely inspired by the internal
actions of Twelf’s (experimental) fully-automated metatheorem prover [28,27],
Harpoon supports user interaction, more expressive theorem statements, and

Mechanizing Metatheory Interactively
645
generation of proof witnesses, in the form of both the generated proof script and
Beluga program resulting from translation.
The Abella system [11] also provides an interactive theorem prover for rea-
soning about speciﬁcations using HOAS. First, its theoretical basis is quite dif-
ferent from Beluga’s: Abella’s reasoning logic extends ﬁrst-order logic with
a ∇quantiﬁer [12] that is used to express properties about variables. Second,
Abella’s interactive mode provides a ﬁxed set of tactics, similar to the actions we
describe in this paper. However, these tactics only loosely connect to the actual
theoretical foundation of Abella and no proof terms are generated as witnesses
by the Abella system.
We can also reason about formal systems in general purpose proof assistants
such as Coq. The general philosophy in such systems is that users should be
in the position of writing complex domain-speciﬁc tactics to facilitate proof
construction using languages such as LTac [7] or MTac(2) [29,17]. Although
this is an extremely ﬂexible approach, we believe that the tactic-centric view
often obscures the actual line of reasoning in the proof. The proofs themselves
can often be illegible and incomprehensible. Further, strong static guarantees
about interactive proof construction are lacking; for example, dynamic checks
enforce variable dependencies. In contrast, our goal is to enable mechanized proof
development in a style close to that of a proof on paper. Thus we provide a ﬁxed
set of tactics suitable for a wide array of proofs, so users can concentrate on proof
development instead of tactic development. As such, our work draws inspiration
from [2] where the authors describe high-level actions within the tutorial proof
checker Tutch. Our work extends and adapts this view to the mechanization of
inductive metatheoretic proofs based on HOAS representations.
6
Conclusion
We have presented Harpoon, an interactive command-driven front-end of Bel-
uga for mechanizing meta-theoretic proofs based on high-level actions. The
sequence of interactive actions is elaborated into a proof script behind the
scenes that represents an assertion-level proof. Last, proof scripts can soundly be
translated to Beluga programs. We have evaluated Harpoon on several case-
studies, ranging from purely syntactic arguments to proofs by logical relations.
Our experience is that Harpoon lowers the entry barrier for users to develop
meta-theoretic proofs about HOAS encodings.
In the future, we aim to extend Harpoon with additional high-level actions
that support further automation. A natural ﬁrst step is to support an action
trivial which would attempt to automatically close an open sub-goal.
Acknowledgments. Jacob Errington and Junyoung Jang acknowledge support
from Fonds de Recherche du Qu´ebec – Nature et technologies (FRQNT). Brigitte
Pientka acknowledges support from National Science and Engineering Research
Council (NSERC).

646
J. Errington et al.
References
1. Abel, A., Allais, G., Hameer, A., Pientka, B., Momigliano, A., Sch¨afer, S., Stark,
K.: POPLMark Reloaded: Mechanizing Proofs by Logical Relations. J. Funct. Pro-
gram. 29, e19 (2019). https://doi.org/10.1017/S0956796819000170
2. Abel, A., Chang, B.Y.E., Pfenning, F.: Human-readable machine-veriﬁable proofs
for teaching constructive logic. In: Egly, U., Fiedler, A., Horacek, H., Schmitt, S.
(eds.) Proceedings of the Workshop on Proof Transformation and Presentation and
Proof Complexities (PTP’01). pp. 33–48. Siena, Italy (2001), http://www2.tcs.iﬁ.
lmu.de/∼abel/ptp01.pdf
3. Boespﬂug, M., Pientka, B.: Multi-level contextual modal type theory. In: Na-
dathur, G., Geuvers, H. (eds.) 6th International Workshop on Logical Frameworks
and Meta-languages: Theory and Practice (LFMTP’11). Electronic Proceedings in
Theoretical Computer Science (EPTCS), vol. 71, pp. 29–43 (2011)
4. Cave, A., Pientka, B.: Programming with binders and indexed data-types. In: 39th
ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages
(POPL’12). pp. 413–424. ACM Press (2012)
5. Cave, A., Pientka, B.: First-class substitutions in contextual type theory. In:
8th ACM SIGPLAN International Workshop on Logical Frameworks and Meta-
Languages: Theory and Practice (LFMTP’13). pp. 15–24. ACM Press (2013)
6. Cave, A., Pientka, B.: Mechanizing Proofs with Logical Relations – Kripke-
style. Mathematical Structures in Computer Science 28(9), 1606–1638 (2018).
https://doi.org/10.1017/S0960129518000154
7. Delahaye, D.: A tactic language for the system Coq. In: Parigot, M., Voronkov,
A. (eds.) 7th International Conference on Logic for Programming and Automated
Reasoning (LPAR’00). Lecture Notes in Computer Science, vol. 1955, pp. 85–95.
Springer (2000). https://doi.org/10.1007/3-540-44404-1 7
8. Errington, J.: Mechanizing metatheory interactively. Master’s thesis, McGill Uni-
versity (2020)
9. Felty, A.F., Momigliano, A., Pientka, B.: Benchmarks for reasoning with syntax
trees containing binders and contexts of assumptions. Math. Struct. in Comp.
Science 28(9), 1507–1540 (2018). https://doi.org/10.1017/S0960129517000093
10. Felty, A.P., Momigliano, A., Pientka, B.: The next 700 challenge problems for rea-
soning with higher-order abstract syntax representations: Part 2 - a survey. Journal
of Automated Reasoning 55(4), 307–372 (2015). https://doi.org/10.1007/s10817-
015-9327-3
11. Gacek, A.: The Abella interactive theorem prover (System Description). In: Ar-
mando, A., Baumgartner, P., Dowek, G. (eds.) 4th International Joint Conference
on Automated Reasoning. Lecture Notes in Artiﬁcial Intelligence, vol. 5195, pp.
154–161. Springer (2008)
12. Gacek, A., Miller, D., Nadathur, G.: Combining generic judgments with recursive
deﬁnitions. In: Pfenning, F. (ed.) 23rd Symposium on Logic in Computer Science.
IEEE Computer Society Press (2008)
13. Harper, R., Honsell, F., Plotkin, G.: A framework for deﬁning logics. Journal of
the ACM 40(1), 143–184 (January 1993)
14. Heilala, S., Pientka, B.: Bidirectional decision procedures for the intuitionistic
propositional modal logic is4. In: Pfenning, F. (ed.) 21st International Conference
on Automated Deduction (CADE’07). pp. 116–131. Lecture Notes in Computer
Science (LNCS 4603), Springer (2007)

Mechanizing Metatheory Interactively
647
15. Huang, X.: Reconstruction proofs at the assertion level. In: Bundy, A. (ed.) Pro-
ceedings of the 12th International Conference on Automated Deduction (CADE-
12). Lecture Notes in Computer Science, vol. 814, pp. 738–752. Springer (1994).
https://doi.org/10.1007/3-540-58156-1 53
16. Jacob-Rao, R., Pientka, B., Thibodeau, D.: Index-stratiﬁed types. In: Kirchner,
H. (ed.) 3rd International Conference on Formal Structures for Computation and
Deduction (FSCD’18). pp. 19:1–19:17. LIPIcs, Schloss Dagstuhl - Leibniz-Zentrum
f¨ur Informatik (January 2018)
17. Kaiser, J., Ziliani, B., Krebbers, R., R´egis-Gianas, Y., Dreyer, D.: Mtac2: typed
tactics for backward reasoning in coq. Proc. ACM Program. Lang. 2(ICFP), 78:1–
78:31 (2018). https://doi.org/10.1145/3236773
18. Lee, D.K., Crary, K., Harper, R.: Towards a mechanized metatheory of Standard
ML. In: 34th ACM SIGPLAN-SIGACT Symposium on Principles of Programming
Languages (POPL’07). pp. 173–184. ACM Press (2007)
19. Nanevski, A., Pfenning, F., Pientka, B.: Contextual modal type theory. ACM
Transactions on Computational Logic 9(3), 1–49 (2008)
20. Pfenning, F., Sch¨urmann, C.: System description: Twelf — A Meta-Logical Frame-
work for Deductive Systems. In: Ganzinger, H. (ed.) 16th International Conference
on Automated Deduction (CADE-16). pp. 202–206. Lecture Notes in Artiﬁcial In-
telligence (LNAI 1632), Springer (1999)
21. Pientka, B.: A type-theoretic foundation for programming with higher-order ab-
stract syntax and ﬁrst-class substitutions. In: 35th ACM SIGPLAN-SIGACT Sym-
posium on Principles of Programming Languages (POPL’08). pp. 371–382. ACM
Press (2008)
22. Pientka, B.: Programming inductive proofs: a new approach based on contextual
types. In: Siegler, S., Wasser, N. (eds.) Veriﬁcation, Induction, Termination Anal-
ysis - Festschrift for Christoph Walther on the Occasion of his 60th Birthday. pp.
1–16. Lecture Notes in Computer Science (LNCS 6463), Springer (2010)
23. Pientka, B.: An insider’s look at LF type reconstruction: Everything you (n)ever
wanted to know. Journal of Functional Programming 1(1–37) (2013)
24. Pientka, B., Abel, A.: Structural recursion over contextual objects. In: Altenkirch,
T. (ed.) 13th International Conference on Typed Lambda Calculi and Applications
(TLCA’15). pp. 273–287. Leibniz International Proceedings in Informatics (LIPIcs)
of Schloss Dagstuhl (2015)
25. Pientka, B., Cave, A.: Inductive Beluga: Programming Proofs (System Descrip-
tion). In: Felty, A.P., Middeldorp, A. (eds.) 25th International Conference on Au-
tomated Deduction (CADE-25). pp. 272–281. Lecture Notes in Computer Science
(LNCS 9195), Springer (2015)
26. Pientka, B., Dunﬁeld, J.: Programming with proofs and explicit contexts. In: ACM
SIGPLAN Symposium on Principles and Practice of Declarative Programming
(PPDP’08). pp. 163–173. ACM Press (2008)
27. Sch¨urmann, C.: Automating the Meta Theory of Deductive Systems. Ph.D. thesis,
Department of Computer Science, Carnegie Mellon University (2000), CMU-CS-
00-146
28. Sch¨urmann, C., Pfenning, F.: Automated theorem proving in a simple meta-logic
for LF. In: Kirchner, C., Kirchner, H. (eds.) Proceedings of the 15th International
Conference on Automated Deduction (CADE-15). pp. 286–300. Springer-Verlag
Lecture Notes in Computer Science (LNCS) 1421, Lindau, Germany (Jul 1998)
29. Ziliani, B., Dreyer, D., Krishnaswami, N.R., Nanevski, A., Vafeiadis, V.: Mtac: A
monad for typed tactic programming in Coq. Journal of Functional Programming
25 (2015)

648
J. Errington et al.
Open Access This chapter is licensed under the terms of the Creative Commons
Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/),
which permits use, sharing, adaptation, distribution and reproduction in any medium
or format, as long as you give appropriate credit to the original author(s) and the
source, provide a link to the Creative Commons license and indicate if changes were
made.
The images or other third party material in this chapter are included in the chapter’s
Creative Commons license, unless indicated otherwise in a credit line to the material. If
material is not included in the chapter’s Creative Commons license and your intended
use is not permitted by statutory regulation or exceeds the permitted use, you will need
to obtain permission directly from the copyright holder.

Author Index
Aaronson, Scott
468
Alrabbaa, Christian
291
Baader, Franz
291, 309
Barnett, Lee A.
252
Barrett, Clark
148
Bártek, Filip
525
Bartocci, Ezio
565
Baumgartner, Peter
589
Bentkamp, Alexander
378, 396, 415
Bibel, Wolfgang
58
Biere, Armin
252
Blanchette, Jasmin
344, 396, 415
Borgwardt, Stefan
291
Brauße, Franz
113
Bryant, Randal E.
433
Chaudhuri, Kaustuv
200
Ciabattoni, Agata
565
Cimatti, Alessandro
131
Cohen, Liron
3
Cruanes, Simon
415
De Lon, Adrian
614
Desharnais, Martin
450
Dixon, Clare
76
Draheim, Dirk
507
Ebner, Gabriel
344
Echenim, Mnacho
183
Errington, Jacob
636
Fiorentini, Camillo
217
Fleury, Mathias
450
Goli´nska-Pilarek, Joanna
41
Governatori, Guido
565
Griggio, Alberto
131
Haifani, Fajar
327
Han, Jesse Michael
577
Heule, Marijn J. H.
433, 468
Hozzová, Petra
361
Hustadt, Ullrich
76
Huuskonen, Taneli
41
Iosif, Radu
183
Jang, Junyoung
636
Järv, Priit
507
Kim, Dohan
166
Koepke, Peter
614
Koopmann, Patrick
291, 309
Korovin, Konstantin
113
Korovina, Margarita V.
113
Kovács, Laura
361
Kovtunova, Alisa
291
Kriegel, Francesco
309
Krueger, Ryan
577
Li, Liming
485
Lorenzen, Anton
614
Lynch, Christopher
166
Marti, Adrian
614
Moura, Leonardo de
625
Müller, Norbert Th.
113
Nalon, Cláudia
76
Neufeld, Emery
565
Nigam, Vivek
234
Nipkow, Tobias
93
Nummelin, Visa
378, 415
Nuradiansyah, Adrian
309
Papacchini, Fabio
76
Peltier, Nicolas
183
Pientka, Brigitte
636
Rabe, Markus N.
25
Rahmouni, Samar
234
Redondi, Gianluca
131
Reis, Giselle
234
Reynolds, Andrew
148
Ringeissen, Christophe
148
Roßkopf, Simon
93
Ruess, Harald
234

650
Author Index
Schurr, Hans-Jörg
450
Schütz, Marcel
614
Selsam, Daniel
577
Sheng, Ying
148
Smallbone, Nicholas
602
Suda, Martin
525, 543
Szegedy, Christian
25
Tammet, Tanel
507
Tinelli, Cesare
148
Tourret, Sophie
327, 344, 378, 396, 415
Ullrich, Sebastian
625
Voronkov, Andrei
361
Vukmirovi´c, Petar
378, 396, 415
Weidenbach, Christoph
327
Wenzel, Makarius
614
Wernhard, Christoph
58
Xu, Runqing
485
Yamada, Akihisa
273
Yolcu, Emre
468
Zawidzki, Michał
41
Zhan, Bohua
485
Zohar, Yoni
148

