Toma SUSI
University of Vienna
and the Initiative for Science in Europe (ISE)

But we must recognize the need for reform
Open Science needs no martyrs

Why Open Science?
UNESCO 2021 (CC BY-SA 3.0 IGO) https://en.unesco.org/science-sustainable-future/open-science/recommendation
Diversity of 
practices, not only 
publications!

Aspirations for Open Science…
Policy statements and recommendations
• 2019: “Open science is a policy priority for the European Commission and the standard 
method of working under its research and innovation funding programmes as it 
improves the quality, efficiency and responsiveness of research. 
When researchers share knowledge and data as early as possible in the research 
process with all relevant actors it helps diffuse the latest knowledge.”
– European Commission
• 2018: “For Open Science to be successful, it must become embedded at every level 
and in every aspect of the scientific endeavour and not be perceived as separate from (or 
even in competition with) current practice.
…To enable this, all stakeholders in research and its communication need to take 
responsibility for supporting Open Science activities.”
– Open Science Policy Platform, recommendation report
https://ec.europa.eu/info/research-and-innovation/strategy/goals-research-and-innovation-policy/open-science_en
https://ec.europa.eu/research/openscience/pdf/integrated_advice_opspp_recommendations.pdf

… and reality for researchers
Journal prestige prominent, open science… not so much
• 2018: “That faculty hiring and advancement at top institutions requires papers 
published in journals with the highest JIF (e.g., Nature, Science, Cell) is more than 
just a myth circulating among postdoctoral students.”
• 2019: “A university that pledged not to judge professors on the journals in which they 
publish has apologized for posting a job advertisement calling for a postdoc who had 
published in a title such as Nature or Science.”
• 2020: “Mention of alternative metrics for sharing research (3%; n=3) and data 
sharing (1%; 1) was rare, and three criteria (publishing in open access mediums, 
registering research, and adhering to reporting guidelines) were not found in any 
guidelines reviewed [for promotion and tenure in biomedical sciences faculties in the 
US].“
• 2021: “Open Science in academic assessment: In 34% of institutions, none of the 
Open Science elements examined by the survey were included in academic 
assessments.” – 2020-2021 EUA Open Science Survey
https://doi.org/10.1371/journal.pbio.2004089
https://doi.org/10.1136/bmj.m2081
www.insidehighered.com/news/2019/06/28/university-vowed-not-consider-journal-quality-hiring-does-just
https://eua.eu/downloads/publications/2021%20os%20survey%20report.pdf

Research institutions
Inappropriate metrics flow downhill 
rankings & aggregated indices 
metrics (Journal Impact Factor and Quartile Ranks, h-indices)
Governments
Individual researchers
Strategy
Recruitment,
promotion
Public funding

Does the evaluation capture the 
actual impact and diversity of 
research institutions? 
Does the evaluation
successfully cover the 
innovation capacity? 
Competition over 
collaboration 
Prestige-driven
publication choices
Feeding a very costly publishing
landscape with public €€€!
Metrics are outsourced to 
commercial entities
Governments
Individual researchers
Research institutions
Most pernicious problem: misuse of journal-based impact metrics
Stress, burnout, 
leaky pipelines
Easy-to-use and globalising system, but… 

...creating dilemmas for researchers 
(especially for early-career researchers!)
We need to reform research assessment
...and change the evaluation culture!
Career incentives
• Publish (a lot and fast) or perish
• Strategic journal choices over 
innovative publishing models
Idealistic thinking
• Open data, software, methods…
• Slow-paced innovative approaches
• Collaborative review systems… and more
Generated by Toma Susi via https://imgflip.com/i/635mqx
Inspired by http://twitter.com/fdsayre/status/1374756832279810048
Photo © Reuters

Game Over
Empower Early Career Researchers to Improve Research Quality
De Herde, Véronique, Mattias Björnmalm, and Toma Susi. 2021. “Game Over: Empower Early Career Researchers to Improve Research Quality”. Insights 34 (1): 
15. (CC-BY) DOI: http://doi.org/10.1629/uksg.548

How can we change the system?
First, as a research community, among researchers across all career stages, we
need to take a hard, realistic and honest look at the current reward system and its
flaws, regardless of how well it may have served us. 
Second, beyond localized examples of evolving practices of research evaluation […] 
a broader internal dialogue is needed within the research community to focus on 
what is important, what should be rewarded and how individuals are evaluated at 
different stages of their research careers. 
To this end…
De Herde, Véronique, Mattias Björnmalm, and Toma Susi. 2021. “Game Over: Empower Early Career Researchers to Improve Research Quality”. Insights 34 
(1): 15. (CC-BY) DOI: http://doi.org/10.1629/uksg.548

Full report released online:
https://initiative-se.eu/paper-research-assessment
The centrality of researchers in reforming research assessment
Routes to improve research by aligning rewards with Open Science practices
ISE Open Science WG report
Toma Susi, Monica Heintz, Eva Hnatkova, Wolfram Koch, Maria Leptin, 
Martin Andler, Marco Masia, Michele Garfinkel
In addition to the authors, the following representatives to ISE served on the Open Science Task Force:
Apostolos Chamos, Renaud Jolivet, Giulia Malaguernera, Enrique Sanchez, Jaishree Subrahmaniam, Moniek Tromp, Peter Svensson, Konstantinos 
Yeles
Based on a two-day workshop in March 2021
Diverse set of stakeholders + expert interviews

This report explores how and at which levels change can happen, and which routes can be taken to reach a 
comprehensive change that could be applied across the research system while respecting valid 
disciplinary or other relevant sectoral differences. 
Several policy options for each stakeholder are proposed.
For research communities, it is urgent and vital to concretely consider how they wish evaluation 
systems to be adapted to eliminate pernicious incentives and to reward pertinent Open Science practices in 
their diverse circumstances. 
There is a serious risk that if they cannot make concrete proposals on how to replace currently 
prevalent prestige indicators such as journal impact factors and quartile ranks, these will either continue 
to be (mis)used or new indicators will be imposed without the communities’ participation.
The time to act is years ago now
https://initiative-se.eu/paper-research-assessment/

Four essential principles
https://initiative-se.eu/paper-research-assessment/
Engage researchers in all decisions regarding changes to research assessment: 
all stakeholders should liaise more with researchers and researcher organisations and include them from the 
beginning in their decision-making processes.
End the use of inappropriate metrics: 
all stakeholders should abide by the principles previously outlined in the San Francisco Declaration on Research 
Assessment and the Leiden Manifesto.
Agree on appropriate ways of assessing research and researchers: 
identify suitable discipline-specific means of evaluation; establish an appropriate balance between qualitative and 
quantitative evaluation; evaluate which metrics or indicators, if any, are suitable.
Recognise that reforming assessment requires resources: 
to facilitate Open Science practices, funders, governments, and 
universities should provide additional targeted funding.

Changing entrenched mindsets is hard…
”I recently published a cool piece of science from my ERC project that I was quite proud of (as 
open access, including data). 
We tried to initially submit to a very prestigious journal but they said it’s not novel enough – a 
subjective judgment – and we ended up publishing this paper in a respected journal, just not as 
prestigious. 
The research didn’t change, it was exactly the same article. Yet I caught myself thinking “Oh, it’s 
not worth a press release, because it’s not such an impressive journal”...
...but then I said to myself “No, it doesn’t matter, it’s the same research, and I’m going to do it.” 
Luckily, the university agreed.
So yes, it is hard and this mentality change will take time. I’m not sure if people who are now 
decades into their scientific careers and never thought about these problems can change their 
minds.”
ERC Magazine interview: “Open science needs no martyrs, but we must recognize the need for reform“ https://erc.europa.eu/news-
events/magazine/open-science-needs-no-martyrs-we-must-recognize-need-reform

Unlike publishing, evaluation is largely done by
and to the 
research community itself… 
thus we CAN change it! 
Let us reform research assessment, together –
researchers, learned societies, policymakers, 
universities, funders… starting now!
Copyright © ScruffyToto (Deviantart)
https://www.deviantart.com/scruffytoto/art/Stop-Hitting-Yourself-162754503
…but it is time to stop doing this to ourselves.

