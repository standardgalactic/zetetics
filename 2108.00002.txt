Bayesian Optimization in Materials Science: A
Survey
Lars Kotthoﬀ
Hud Wahab
Patrick A. Johnson
Center for Artiﬁcially Intelligent Manufacturing
University of Wyoming
August 3, 2021
Abstract
Bayesian optimization is used in many areas of AI for the optimization
of black-box processes and has achieved impressive improvements of the
state of the art for a lot of applications. It intelligently explores large and
complex design spaces while minimizing the number of evaluations of the
expensive underlying process to be optimized. Materials science considers
the problem of optimizing materials’ properties given a large design space
that deﬁnes how to synthesize or process them, with evaluations requir-
ing expensive experiments or simulations – a very similar setting. While
Bayesian optimization is also a popular approach to tackle such problems,
there is almost no overlap between the two communities that are investi-
gating the same concepts. We present a survey of Bayesian optimization
approaches in materials science to increase cross-fertilization and avoid
duplication of work. We highlight common challenges and opportunities
for joint research eﬀorts.
1
Introduction
In many areas of AI, decades of research have resulted in many diﬀerent ap-
proaches for solving hard problems. Perhaps the best example is machine learn-
ing, where dozens of diﬀerent approaches just to classiﬁcation are available, with
little guidance on what to use for a particular problem. While random forests are
usually a good choice, there are many problems where other approaches provide
better performance. Even human experts struggle to choose the best approach
for a given problem without signiﬁcant experimentation though. Worse, once a
particular approach is chosen, its hyperparameters need to be set for optimal
performance – or is a diﬀerent approach actually better once its hyperparame-
ters have been optimized?
This issue is not unique to machine learning – the optimization of the hy-
perparameters of processes is a ubiquitous problem in AI and many other areas,
1
arXiv:2108.00002v1  [cond-mat.mtrl-sci]  29 Jul 2021

including materials science. While this can be done eﬃciently for some appli-
cations, for example because gradients are available or other knowledge about
the optimized process can be leveraged, there are many scenarios where noth-
ing is known about the process – it is a black box that can be evaluated, but
whose inner workings are not suﬃciently understood to aid in the optimization
process. Such black boxes are much harder to optimize in practice.
Black-box processes are optimized by repeatedly evaluating them for diﬀer-
ent hyperparameter settings and observing the eﬀect changes in hyperparameter
values have – much like scientists have studied natural phenomena for millennia.
In many cases, these evaluations are expensive and it is crucial to minimize their
number as the optimization would otherwise use too many resources. Bayesian
optimization (BO) is a methodology that allows for just that. It is a sample-
eﬃcient optimization method that, in general, does not require a large number
of samples to obtain good results and is thus particularly suitable for black-box
functions that are extremely expensive to evaluate, as found in many areas of
AI, engineering, and materials science, where an evaluation may entail synthe-
sizing and testing a new material and require specialized equipment and skilled
operators.
At the heart of modern Bayesian optimization approaches are machine-
learning-induced surrogate models, that learn to emulate the black-box process
to be optimized based on a small number of evaluations. Such surrogate models
have a long tradition in materials science where they helped in the develop-
ment of new materials and designs long before the advent of machine learning.
Traditionally, models were based on ﬁrst-principles understanding and physical
laws that were painstakingly developed by scientists rather than the data-driven
approaches we see today.
Bayesian optimization, like surrogate models, is not a new concept, nor did
it originate in AI – its origins can be traced back decades to engineering ap-
plications. It has gained increasing popularity in materials science in the last
decade, similar to popularity gains in AI in the same time period. However,
research in both ﬁelds proceeds almost entirely independently, with no cross-
fertilization taking place even though the problems solved are the same in many
cases. This survey aims to bridge this gap and increase awareness in the AI
community on relevant research and approaches being developed in materials
science. We provide an overview of relevant recent research and highlight chal-
lenges in materials science that AI research can help with and open problems
that may beneﬁt from joint eﬀorts.
2
Background
In modern Bayesian optimization, a surrogate model is ﬁt based on the results of
evaluating the black-box process at diﬀerent points in the hyperparameter space.
Such an initial design could be random, or based on another design of experi-
ments approach. In most cases, this surrogate model is induced by a machine
learning algorithm; Gaussian Processes and random forests are popular choices.
2

An acquisition function then determines the next point in hyperparameter space
to evaluate the expensive black-box process at, based on the predictions of the
cheap-to-evaluate surrogate model and possibly uncertainty quantiﬁcations of
those predictions. This acquisition function balances exploitation, i.e. evaluating
the neighborhood of points known to yield good performance, and exploration,
i.e. evaluating points that are far from regions of the hyperparameter space with
known performance to avoid getting stuck in local optima. Commonly-used ac-
quisition functions include expected improvement and maximum uncertainty,
which always explores.
The expensive black-box function is then evaluated at the point proposed in
this way to obtain ground-truth data that is combined with the data from the
initial design. The updated data is used to obtain the surrogate model for the
next iteration of the optimization process. The incremental augmentation of the
data the surrogate model takes into account iteratively improves and reﬁnes it
for the areas of interest, yielding more accurate approximations of the black-box
function and better optimization results. The Bayesian optimization process can
be stopped at any time when the desired quality is achieved or resources are
exhausted. While this makes it convenient to deploy in practice, there are no
guarantees of convergence to a global optimum except if an inﬁnite number of
evaluations of the black-box function are allowed. As we make no assumptions
about the optimization landscape, the quality of the result cannot be guaranteed
or even assessed except by comparison to the results other methods or repeated
BO runs achieve.
Figure 1 illustrates surrogate model and acquisition function for one iteration
of a toy example.
There are many variations of this general approach and
hybrid methods that incorporate techniques from other areas of AI have been
developed, for example meta-learning to leverage known good hyperparameter
conﬁgurations from similar applications. A complete exposition is beyond the
scope of this survey. For more details on Bayesian optimization, we refer the
interested reader to Jones et al. [1998], Mockus and Mockus [1991] and Forrester
et al. [2008] for Bayesian optimization in engineering in particular.
3
Bayesian Optimization in AI
The optimization of black-box processes is relevant in many areas of AI; in
particular for the automated hyperparameter tuning of algorithms. For many
applications, software to solve problems have hyperparameters that allow to
choose and tune, for example; a search heuristic, a stopping criterion, or a
pruning mechanism. These choices provide added ﬂexibility and enable adapta-
tion of a generic algorithm to a particular problem, but setting them to achieve
good performance in a speciﬁc setting is a diﬃcult task even for human experts.
There are numerous approaches that apply Bayesian optimization methods
to automated hyperparameter tuning in AI, for example Hutter et al. [2011],
who introduce the SMAC system and demonstrate its power tuning the hyper-
parameters of SAT and MIP solvers. Snoek et al. [2012] propose the spearmint
3

G
G
G
G
G
y
ei
−1.0
−0.5
0.0
0.5
1.0
0.0
0.4
0.8
0.000
0.002
0.004
0.006
x
type
G init
prop
seq
type
y
yhat
ei
Iter = 3, Gap = 1.9909e−01
Figure 1: Example Bayesian optimization iteration. The horizontal axis shows the
parameter space, projected into one dimension.
In the top panel, the solid line is
the true objective function; the dashed line is its surrogate-model-based approxima-
tion. The gray-shaded areas indicate the uncertainty of predictions of the surrogate
model. Red circles represent evaluated conﬁgurations used to build the initial surro-
gate model; green squares conﬁgurations evaluated and added to the training data for
the surrogate model in previous iterations; and the blue triangle the proposed next
conﬁguration to evaluate. The bottom panel shows the expected improvement over
the best conﬁguration found so far; the highest peak coincides with the proposed next
conﬁguration. Illustration generated with the mlrMBO package Bischl et al. [2017].
system and automatically tune the hyperparameters of a machine learning algo-
rithm, whereas Feurer et al. [2015], Kotthoﬀet al. [2017] automatically choose
the machine learning approach and pre- and post-processing methods in addi-
tion to tuning its hyperparameters.
Bischl et al. [2017] propose a general and ﬂexible system for hyperparamter
tuning using Bayesian optimization, and Falkner et al. [2018] combine Bayesian
optimization with bandit-based methods. The need for hyperparameter tuning
in machine learning has resulted in the ﬁeld of automated machine learning (Au-
toML), which relies to a signiﬁcant part on Bayesian optimization and related
methods. We refer the interested reader to a recent book Hutter et al. [2019]
for more.
4

4
Bayesian Optimization in Materials Science
A large application area of Bayesian optimization in materials science is similar
to how it is applied in AI – the optimization of the hyperparameters of computa-
tionally expensive processes. In particular, Density Functional Theory (DFT)
simulations can compute properties of interest for a given material, but may
take weeks to complete. DFT calculations are used to determine the electronic
structure of systems composed of many atoms or molecules, in particular the
spatially dependent density of electrons, from which properties of the modeled
material can be derived. Such simulations rely only on ﬁrst-principles knowledge
in quantum physics and are widely applicable to many diﬀerent types of ma-
terials. DFT and similar ﬁrst-principles-based simulations are the cornerstone
in many areas of materials science. Note that the DFT simulations themselves
are not optimized, i.e. BO is not applied to improve the simulation itself, but
the underlying material – DFT is used to avoid having to synthesize and exper-
imentally evaluate a material.
Kiyohara et al. [2016], Kikuchi et al. [2018], Bondevik et al. [2019] use BO
to optimize the grain boundary structure in polycrystalline materials instead
of exhaustively evaluating the design space for the materials. They all demon-
strate that results of similar quality to exhaustive evaluation can be achieved
at signiﬁcantly lower cost, with an increase in eﬃciency by up to two orders of
magnitude. Similarly, Ueno et al. [2016] optimize the grain boundary energy
over several thousand precomputed hyperparameter conﬁgurations, which al-
lows them to compare the performance of diﬀerent approaches. Talapatra et al.
[2018] employ BO in a similar setting by evaluating its performance on a set of
a few hundred precomputed results. They optimize the elastic properties of a
material and demonstrate that BO is quickly able to identify the optimal hy-
perparameters in their relatively small approximation of the real search space.
Balachandran et al. [2016] investigate the same application and in subsequent
publications demonstrate the eﬀectiveness of BO to optimize shape memory al-
loys Xue et al. [2016], the band gap in perovskites, an important material in the
creation of solar cells Pilania et al. [2017], and the band gap in compounds for
luminescent materials Lookman et al. [2019]. Ling et al. [2017] demonstrate the
utility of BO to optimize the DFT-calculated magnetic deformation of a mate-
rial, superconductors, thermoelectricity, and the strength of steel. Hankins et al.
[2019] apply BO to the problem of creating new materials via a parameterized
generator for patterns that describe the structure of the material. They opti-
mize the interfacial area of the material, which can be computed directly and
very cheaply compared to numerical simulations, but the large hyperparameter
space still necessitates a more eﬃcient hyperparameter optimization approach
than exhaustive search. Dehghannasiri et al. [2017] design materials with low
energy dissipation by optimizing a dopant (an impurity introduced into a pure
material of a diﬀerent type) and its concentration using BO, showing improve-
ments over random search and pure exploitation.
Seko et al. [2014] perform one of the earliest investigations into whether BO
is suitable for optimizing the properties of materials that are evaluated using
5

DFT. In particular, they focus on the performance of the surrogate model that
replaces the DFT calculations, a crucial prerequisite for applying BO. They
predict and optimize the melting temperature of solid compounds and ﬁnd
that support vector regression in particular provides high-quality predictions
of the DFT results. However, they use Gaussian Processes in a BO framework
to optimize the melting temperature, demonstrating better performance than
random search. A subset of the authors provide additional applications in a
later study Tanaka and Seko [2016] that more explicitly distinguishes between
high-throughput approaches where an exhaustive grid search is performed and
applications where this is infeasible and the use of BO or a similar technique is
necessary.
In contrast to most areas of AI, a lot of materials science is not only computa-
tional, but involves physical experiments that synthesize and evaluate materials.
While DFT and similar simulations are increasingly accurate, their results are
often only approximations of what happens in the real world due to diﬀerent
scales or a lack of ﬁrst-principles understanding – DFT calculations can only
consider relatively small numbers of atoms or molecules that may not accurately
represent materials deployed in practical applications. Even more so than for
computational simulations, BO is useful to reduce experimental eﬀort in the
optimization of materials that requires not only physical resources, but also in
many cases specialized equipment and the time of a skilled operator.
Ren et al. [2018] use a manual version of BO to discover metallic glasses.
They train a random forest model to predict whether a particular composition
of precursor materials results in the formation of a glass based on prior exper-
imental results. The model is then used to manually identify the region with
the highest promise for gathering additional data through high-throughput ex-
perimentation, allowing for many evaluations in a short amount of time. The
experimental results obtained in this way are used to reﬁne the model. The
authors iterate this process three times and discover several new glass-forming
systems. H¨ase et al. [2018] use BO to optimize the conditions for a chemical
reaction to achieve a certain stability condition. While the optimized experi-
mental conditions could be evaluated through actual experiments, the authors
use a simulator to achieve higher throughput and obtain more data. They show
that BO is not only able to obtain the desired results quickly, but also does
so more robustly than other approaches, namely particle swarm optimization
and CMA-ES. Kotthoﬀet al. [2019] optimize the reduction of graphene oxide to
graphene in the context of creating nano-circuits and ﬂexible electronics. The
evaluations of the black-box function rely on physical experiments that are per-
formed manually and thus the number of data points is only a few dozen. How-
ever, the authors demonstrate that even in this case, signiﬁcant improvements
of the experimental outcome over human experts can be achieved. Wigley et al.
[2016] optimize the production of Bose-Einstein condensates with BO, which
they refer to as machine learning online optimization, with an order of magni-
tude fewer evaluations than previous approaches. Ren et al. [2020] optimize the
eﬃciency of solar cells by tuning the growth temperature of gallium arsenide
cells. Their customized BO approach is able to achieve improvements after only
6

ﬁve experimental evaluations. Vellanki et al. [2017] optimize alloy casting and
the production of polymer ﬁbers in a constrained batch process, but do not
provide a baseline comparison for their results.
Some approaches combine computational simulations with experiments or
diﬀerent types of simulations with diﬀerent ﬁdelities and costs for multiple layers
of screening. This allows to improve the outcomes of the optimization process
while reducing the costs for evaluations of the black box functions.
Indeed,
this is a major diﬀerence to applications of BO in AI, where usually there is
only a single way of evaluating the black box function to be optimized. The
closest to evaluations at multiple levels are techniques like early stopping, used
for example in SMAC, that stop the evaluation if the hyperparameter setting
under conﬁguration does not show promise on a subset of the data, e.g. a fraction
of the folds for a machine learning problem or a subset of the problem instances
for a combinatorial optimization algorithm.
G´omez-Bombarelli et al. [2016] optimize the design of OLEDs. They pre-
screen designs using a machine learning surrogate model, then perform DFT
calculations on the remaining candidates, and ﬁnally synthesize and experimen-
tally evaluate the candidate designs that pass this second screening. While the
authors do not use BO directly, they demonstrate the power of a multi-level,
multi-ﬁdelity approach in eﬃciently exploring a large search space. Pilania et al.
[2017] combine diﬀerent types of DFT simulations, one low-ﬁdelity simulation
that can be computed quickly, and one high-ﬁdelity simulation, to optimize the
bandgap of solids. They use a modiﬁed Gaussian Process that is able to take
information at multiple ﬁdelities into account directly as a surrogate model and
demonstrate better outcomes than when using only the high-ﬁdelity data. Patra
et al. [2020] apply the same approach to optimizing the bandgap of polymers
and demonstrate similar results, noting that their multi-ﬁdelity surrogate model
is able to generalize better to a larger design space than surrogate models that
use only high-ﬁdelity data.
The majority of approaches in both AI and materials science consider single-
objective BO, as multi-objective optimization increases complexity considerably
and multiple objectives can be combined into a single objective. However, a few
approaches apply multi-objective BO to avoid requiring the user to specify how
to weight diﬀerent objectives and being able to choose the trade-oﬀafter the
optimization from points on the Pareto front. Talapatra et al. [2018] consider
the two competing objectives of shear and bulk modulus, which quantify the
eﬀect external forces have on the material. The authors use expected hypervol-
ume improvement as the acquisition function and show that they can eﬃciently
identify the points on the Pareto front. Solomou et al. [2018] consider the si-
multaneous optimization of up to three properties of a particular type of alloy
based on computational simulations. They also use expected hypervolume im-
provement as the acquisition function and demonstrate the eﬀectiveness of their
approach. Ragasa et al. [2019] scale up to 10 objectives, but use a custom non-
BO approach, though inspired by Bayesian optimization, that iteratively reﬁnes
the hyperparameter search space based on found Pareto-optimal conﬁgurations.
In many applications, it may be desirable to batch evaluations of the black
7

box function to be optimized, i.e. have the BO process predict multiple hyper-
parameter conﬁgurations at once. This can facilitate the parallel evaluation of
conﬁgurations to make optimal use of available resources. This is common to
both AI and materials science, though there are few approaches that do it. H¨ase
et al. [2018] propose batches of conﬁgurations to evaluate by optimizing the ac-
quisition functions for diﬀerent values of a parameter that trades oﬀexploration
and exploitation. The authors demonstrate that this batch evaluation improves
overall performance, as the correct setting for this parameter is unclear and
varies over time. A unique issue in BO for materials science that does not usu-
ally come up in an AI setting is that the ﬁrst hyperparameter conﬁguration to
evaluate may constrain subsequent conﬁgurations. Vellanki et al. [2017] give the
examples of heat treatment of alloys, where multiple samples can be processed
at the same time in an oven but at a ﬁxed temperature, and the production
of polymer ﬁbers, where diﬀerent values for polymer ﬂow and coagulant speed
can be evaluated at the same time but within a ﬁxed geometry. They propose
a nested BO approach that optimizes the hyperparameters that are subject to
constraints in an outer loop and, given the optimized values, the unconstrained
hyperparameters in an inner loop.
In many applications of BO in materials science, standard BO approaches,
usually with Gaussian Processes as surrogate models and expected improve-
ment as acquisition function, are used. There are a few exceptions; for example
H¨ase et al. [2018] use Bayesian Neural Networks as a surrogate model with a
custom acquisition function and Pilania et al. [2017], Patra et al. [2020] use
custom Gaussian Processes that can take information at multiple ﬁdelities into
account, with an acquisition function that takes the cost diﬀerence of the diﬀer-
ent ﬁdelities into account. Dehghannasiri et al. [2017] use mean objective cost
of uncertainty as the acquisition function, which quantiﬁes how much worse an
outcome is because of uncertainty. Ren et al. [2020] replace the traditional BO
approach with multiple layers of surrogate models of Bayesian networks infused
with background knowledge that constrains the (intermediate) outputs to phys-
ically feasible ones, combined with a neural network that serves as a surrogate
for expensive numerical simulations. Vellanki et al. [2017] propose a nested ap-
proach that runs a series of BO processes to propose a batch of hyperparameter
conﬁgurations to evaluate. Talapatra et al. [2018] use Bayesian model averaging
inside the BO process to select the most suitable surrogate model at the same
time as optimizing the black-box process. Ueno et al. [2016] augment BO with
automated hyperparameter tuning and a few changes to be able to sample and
optimize the surrogate model more eﬃciently with thousands of features.
Most publications compare their approaches only to a grid or random search,
but some study the eﬀect variations of the BO process have. Ling et al. [2017]
propose a BO framework that uses random forests as surrogate models with
three diﬀerent acquisition functions and demonstrate that using likelihood of
improvement instead of expected improvement performs better on their case
studies. Balachandran et al. [2016] on the other hand compare the performance
of diﬀerent surrogate models with the same acquisition function. They note
8

that models that quantify the uncertainty of their predictions show better per-
formance than those that do not, and ﬁnd that support vector regression with
an RBF kernel gives the best surrogate models, similar to the ﬁndings of Seko
et al. [2014].
In most cases, BO approaches in materials science are developed without
awareness of similar eﬀorts in AI. A notable exception is H¨ase et al. [2018], who
compare to SMAC [Hutter et al., 2011] and spearmint [Snoek et al., 2012], as well
as non-BO optimization methods. They demonstrate that their proposed system
Phoenics achieves better performance, diﬀering from the other BO approaches
in a diﬀerent surrogate model (Bayesian Neural Networks) and an acquisition
function based on kernel densities.
5
Research Directions
The application of Bayesian optimization in materials science is guided by the
domain. In particular, this means that achieving performance improvements is
perhaps not as important as in AI, and there is more emphasis on understanding
the models and being able to incorporate additional constraints that encode
the physical knowledge governing the application, as many of the approaches
mentioned above do.
Explainable AI has emerged as an important research area in AI with the
increasing deployment of AI models that facilitate decision making. In partic-
ular deep neural network models are diﬃcult to understand, with real-world
ramiﬁcations on their performance. Almost all publications in materials sci-
ence incorporate some analysis of what surrogate models have learned, often
with respect to the importance of the features used to characterize the opti-
mized process (e.g. Kotthoﬀet al. [2019]). To the best of our knowledge, these
approaches are relatively straightforward and more sophisticated techniques de-
veloped by the AI community, for example the SHAP framework Lundberg and
Lee [2017], have not been applied yet.
Another aspect that is emphasized more in materials science than in AI is
the quantiﬁcation of the uncertainties of a surrogate model, which Ling et al.
[2017] speciﬁcally develop for random forest surrogate models. This may be
the reason that Gaussian Processes remain the most popular surrogate model,
although diﬀerent authors have observed that support vector machine models
achieve better predictive accuracy. This is a potential research direction for the
AI community that would beneﬁt materials science directly.
Lookman et al. [2016] highlight the successes machine learning in general
has had in materials science, but conclude that more applications are required
to give the community guidelines on how to apply BO and machine learning in
the wider sense in the context of materials science. While, as outlined above, a
standard incarnation of BO with Gaussian Processes as surrogate models and
expected improvement as acquisition function is emerging as a reasonable place
to start, there is likely no single approach that will perform best in all settings –
a fact that has been known in AI for decades and leveraged in the emerging ﬁeld
9

of automated machine learning Hutter et al. [2019] for example. While some
approaches in materials science are already taking advantage of these powerful
techniques, a more ubiquitous integration of AutoML techniques into materials
science tools would likely increase the uptake of BO in this area.
de Pablo et al. [2019] identify a lack of systematic methods for reporting the
performance of machine learning approaches and baselines to compare to as one
of the challenges in materials science. This is again an area where AI research
can help, as the same issues are relevant and have been investigated longer.
The authors note that “[e]stablished approaches from the statistics and com-
puter science communities combined with new methods developed speciﬁcally
for materials data issues must be disseminated to the materials community[. . . ]”
– a challenge for our community to reach out more and organize interdisciplinary
events. Similarly, they note that most research in machine learning focuses on
large datasets which are usually not available in materials science. Especially
since the advent of deep learning, such small data problems have been some-
what neglected by the AI community and there are opportunities to develop
new approaches at the intersection of materials and AI.
Kalidindi [2019] mentions similar concerns and in particular notes that a
signiﬁcant issue in materials science is the fragmented storage and availability
of the relevant data. Similar issues have been tackled by the AI community and
resulted in standard data formats and repositories that may be applicable in a
materials context as well, for example the OpenML project Vanschoren et al.
[2013]. The author further highlights the challenge of integrating the governing
physical laws into a BO process and proposes a framework to tackle this. Similar
eﬀorts to include background knowledge in machine learning and data mining
have been undertaken in AI, for example in the ICON project Bessi`ere et al.
[2016], but no joint eﬀorts exist to the best of our knowledge.
While most research proceeds independently in AI and materials science,
there are a few joint eﬀorts, notably Vellanki et al. [2017], which propose con-
strained batch optimization and evaluate their approach both for a machine
learning and materials science applications. This demonstrates that both ﬁelds
can beneﬁt from advances and makes a strong case for increased collaboration
between AI and materials science researchers.
6
Conclusion
We have presented an overview of applications of Bayesian optimization in ma-
terials science, where researchers want to optimize poorly-understood black-box
processes to achieve desired properties of materials. Similar to applications of
BO in AI, the focus is on minimizing the number of evaluations of the expensive
black-box function while maximizing the quality of the result, and similar results
have been achieved, ﬁrmly establishing Bayesian optimization as a state-of-the-
art method that should be in the toolkit of every materials science researcher.
A lot of recent progress in materials science has been enabled by Bayesian
optimization. However, a lot of work remains to be done to improve BO in
10

practice and scale to more diﬃcult problems, in particular ones with multiple
objectives and large numbers of features, and integrate data-driven methodolo-
gies with ﬁrst-principles knowledge.
Materials science presents some unique challenges to applying Bayesian opti-
mization that can stimulate research in AI and, ultimately, beneﬁt applications
of BO in AI as well. Research to date has progressed almost independently in
both application domains, and we hope that this survey will stimulate interdis-
ciplinary eﬀorts and joint projects that advance either and both ﬁelds.
References
Prasanna V. Balachandran, Dezhen Xue, James Theiler, John Hogden, and
Turab Lookman. Adaptive Strategies for Materials Design using Uncertain-
ties. Scientiﬁc Reports, 6:19660, January 2016. URL https://doi.org/10.1038/
srep19660.
Christian Bessi`ere, Luc De Raedt, Lars Kotthoﬀ, Siegfried Nijssen, Barry
O’Sullivan, and Dino Pedreschi, editors. Data Mining and Constraint Pro-
gramming: Foundations of a Cross-Disciplinary Approach, volume 10101 of
Lecture Notes in Artiﬁcial Intelligence. Springer, 1 edition, 2016. ISBN 978-
3-319-50137-6.
Bernd Bischl, Jakob Richter, Jakob Bossek, Daniel Horn, Janek Thomas, and
Michel Lang. mlrMBO: A Modular Framework for Model-Based Optimization
of Expensive Black-Box Functions. March 2017. arXiv: 1703.03373.
Tarjei Bondevik, Akihide Kuwabara, and Ole Martin Løvvik. Application of
machine learning-based selective sampling to determine bazro3 grain bound-
ary structures.
Computational Materials Science, 164:57–65, 2019.
ISSN
0927-0256.
Juan J. de Pablo, Nicholas E. Jackson, Michael A. Webb, Long-Qing Chen,
Joel E. Moore, Dane Morgan, Ryan Jacobs, Tresa Pollock, Darrell G. Schlom,
Eric S. Toberer, James Analytis, Ismaila Dabo, Dean M. DeLongchamp, Gre-
gory A. Fiete, Gregory M. Grason, Geoﬀroy Hautier, Yifei Mo, Krishna Ra-
jan, Evan J. Reed, Efrain Rodriguez, Vladan Stevanovic, Jin Suntivich, Kat-
suyo Thornton, and Ji-Cheng Zhao. New frontiers for the materials genome
initiative. npj Computational Materials, 5(1):41, April 2019. ISSN 2057-3960.
doi: 10.1038/s41524-019-0173-4.
Roozbeh Dehghannasiri, Dezhen Xue, Prasanna V. Balachandran, Moham-
madmahdi R. Youseﬁ, Lori A. Dalton, Turab Lookman, and Edward R.
Dougherty.
Optimal experimental design for materials discovery.
Com-
putational Materials Science, 129:311–322, 2017.
ISSN 0927-0256.
doi:
https://doi.org/10.1016/j.commatsci.2016.11.041.
11

Stefan Falkner, Aaron Klein, and Frank Hutter. BOHB: Robust and Eﬃcient
Hyperparameter Optimization at Scale. In 35th International Conference on
Machine Learning, volume 80, pages 1437–1446, July 2018.
Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Springenberg,
Manuel Blum, and Frank Hutter. Eﬃcient and Robust Automated Machine
Learning. In Advances in Neural Information Processing Systems 28, pages
2944–2952. Curran Associates, Inc., 2015.
Alexander I. J. Forrester, Andras Sobester, and Andy J. Keane. Engineering
Design via Surrogate Modelling - A Practical Guide.
Wiley, 2008.
ISBN
978-0-470-06068-1.
Rafael G´omez-Bombarelli, Jorge Aguilera-Iparraguirre, Timothy D. Hirzel,
David Duvenaud, Dougal Maclaurin, Martin A. Blood-Forsythe, Hyun Sik
Chae, Markus Einzinger, Dong-Gwang Ha, Tony Wu, Georgios Markopou-
los, Soonok Jeon, Hosuk Kang, Hiroshi Miyazaki, Masaki Numata, Sunghan
Kim, Wenliang Huang, Seong Ik Hong, Marc Baldo, Ryan P. Adams, and Al´an
Aspuru-Guzik. Design of eﬃcient molecular organic light-emitting diodes by
a high-throughput virtual screening and experimental approach. Nature Ma-
terials, 15:1120, August 2016. URL https://doi.org/10.1038/nmat4717.
Sarah Hankins, Lars Kotthoﬀ, and Ray S. Fertig.
Bio-like Composite Mi-
crostructure Designs for Enhanced Damage Tolerance via Machine Learn-
ing. In American Society for Composites 34th Annual Technical Conference,
September 2019.
Frank Hutter, Holger H. Hoos, and Kevin Leyton-Brown. Sequential Model-
Based Optimization for General Algorithm Conﬁguration. In LION 5, pages
507–523, 2011.
Frank Hutter, Lars Kotthoﬀ, and Joaquin Vanschoren, editors. Automated Ma-
chine Learning: Methods, Systems, Challenges. The Springer Series on Chal-
lenges in Machine Learning. Springer, 2019. ISBN 978-3-030-05317-8.
Florian H¨ase, Lo¨ıc M. Roch, Christoph Kreisbeck, and Al´an Aspuru-Guzik.
Phoenics: A Bayesian Optimizer for Chemistry.
ACS Central Science, 4
(9):1134–1145, September 2018. ISSN 2374-7943. doi: 10.1021/acscentsci.
8b00307.
Donald R. Jones, Matthias Schonlau, and William J. Welch. Eﬃcient Global
Optimization of Expensive Black-Box Functions.
J. of Global Optimiza-
tion, 13(4):455–492, December 1998.
ISSN 0925-5001.
doi:
10.1023/A:
1008306431147.
Surya R. Kalidindi. A bayesian framework for materials knowledge systems.
MRS Communications, 9(2):518–531, 2019. doi: 10.1557/mrc.2019.56.
12

Shun Kikuchi, Hiromi Oda, Shin Kiyohara, and Teruyasu Mizoguchi. Bayesian
optimization for eﬃcient determination of metal oxide grain boundary struc-
tures. Physica B: Condensed Matter, 532:24–28, 2018. ISSN 0921-4526. Spe-
cial issue on Frontiers in Materials Science: Condensed Matters.
Shin Kiyohara, Hiromi Oda, Koji Tsuda, and Teruyasu Mizoguchi. Acceleration
of stable interface structure searching using a kriging approach.
Japanese
Journal of Applied Physics, 55(4):045502, March 2016. doi: 10.7567/jjap.55.
045502.
Lars Kotthoﬀ, Chris Thornton, Holger H. Hoos, Frank Hutter, and Kevin
Leyton-Brown. Auto-WEKA 2.0: Automatic model selection and hyperpa-
rameter optimization in WEKA. Journal of Machine Learning Research, 18
(25):1–5, 2017.
Lars Kotthoﬀ, Vivek Jain, Alexander Tyrrell, Hud Wahab, and Patrick Johnson.
AI for Materials Science: Tuning Laser-Induced Graphene Production. In
Data Science Meets Optimisation Workshop at IJCAI 2019, August 2019.
Julia Ling, Maxwell Hutchinson, Erin Antono, Sean Paradiso, and Bryce
Meredig. High-Dimensional Materials and Process Optimization Using Data-
Driven Experimental Design with Well-Calibrated Uncertainty Estimates. In-
tegrating Materials and Manufacturing Innovation, 6(3):207–217, September
2017. ISSN 2193-9772. doi: 10.1007/s40192-017-0098-z.
Turab Lookman, P. V. Balachandran, D. Xue, G. Pilania, T. Shearman,
J. Theiler, J. E. Gubernatis, J. Hogden, K. Barros, E. BenNaim, and Fran-
cis J. Alexander. A Perspective on Materials Informatics: State-of-the-Art
and Challenges. In Turab Lookman, Francis J. Alexander, and Krishna Rajan,
editors, Information Science for Materials Discovery and Design, pages 3–12.
Springer International Publishing, Cham, 2016. ISBN 978-3-319-23871-5. doi:
10.1007/978-3-319-23871-5 1.
Turab Lookman, Prasanna V. Balachandran, Dezhen Xue, and Ruihao Yuan.
Active learning in materials science with emphasis on adaptive sampling us-
ing uncertainties for targeted design. npj Computational Materials, 5(1):21,
February 2019. ISSN 2057-3960. doi: 10.1038/s41524-019-0153-8.
Scott M Lundberg and Su-In Lee. A Uniﬁed Approach to Interpreting Model
Predictions. In Advances in Neural Information Processing Systems, pages
4765–4774, 2017.
Jonas B. Mockus and Linas J. Mockus. Bayesian approach to global optimiza-
tion and application to multiobjective and constrained problems.
Journal
of Optimization Theory and Applications, 70(1):157–172, July 1991. ISSN
1573-2878. doi: 10.1007/BF00940509.
Abhirup Patra, Rohit Batra, Anand Chandrasekaran, Chiho Kim, Tran Doan
Huan, and Rampi Ramprasad. A multi-ﬁdelity information-fusion approach
13

to machine learn and predict polymer bandgap.
Computational Materials
Science, 172:109286, 2020. ISSN 0927-0256.
Ghanshyam Pilania, James E. Gubernatis, and Turab Lookman. Multi-ﬁdelity
machine learning models for accurate bandgap predictions of solids. Com-
putational Materials Science, 129:156–163, 2017.
ISSN 0927-0256.
doi:
https://doi.org/10.1016/j.commatsci.2016.12.004.
Eugene J. Ragasa, Christopher J. O’Brien, Richard G. Hennig, Stephen M.
Foiles, and Simon R. Phillpot. Multi-objective optimization of interatomic
potentials with application to MgO.
Modelling and Simulation in Mate-
rials Science and Engineering, 27(7):074007, August 2019.
doi: 10.1088/
1361-651x/ab28d9.
Fang Ren, Logan Ward, Travis Williams, Kevin J. Laws, Christopher Wolver-
ton, Jason Hattrick-Simpers, and Apurva Mehta. Accelerated discovery of
metallic glasses through iteration of machine learning and high-throughput
experiments. Science Advances, 4(4), 2018. doi: 10.1126/sciadv.aaq1566.
Zekun Ren, Felipe Oviedo, Maung Thway, Siyu I. P. Tian, Yue Wang, Han-
song Xue, Jose Dario Perea, Mariya Layurova, Thomas Heumueller, Erik
Birgersson, Armin G. Aberle, Christoph J. Brabec, Rolf Stangl, Qianxiao
Li, Shijing Sun, Fen Lin, Ian Marius Peters, and Tonio Buonassisi. Embed-
ding physics domain knowledge into a Bayesian network enables layer-by-layer
process innovation for photovoltaics. npj Computational Materials, 6(1):1–
9, January 2020. ISSN 2057-3960. doi: 10.1038/s41524-020-0277-x. URL
https://www.nature.com/articles/s41524-020-0277-x.
Atsuto Seko, Tomoya Maekawa, Koji Tsuda, and Isao Tanaka. Machine learning
with systematic density-functional theory calculations: Application to melt-
ing temperatures of single- and binary-component solids. Phys. Rev. B, 89
(5):054303, 2014. doi: 10.1103/PhysRevB.89.054303.
Jasper Snoek, Hugo Larochelle, and Ryan P. Adams. Practical Bayesian Opti-
mization of Machine Learning Algorithms. In Advances in Neural Information
Processing Systems 25, pages 2951–2959, 2012.
Alexandros Solomou, Guang Zhao, Shahin Boluki, Jobin K. Joy, Xiaoning Qian,
Ibrahim Karaman, Raymundo Arr´oyave, and Dimitris C. Lagoudas. Multi-
objective bayesian materials discovery: Application on the discovery of pre-
cipitation strengthened niti shape memory alloys through micromechanical
modeling. Materials and Design, 160:810–827, 2018. ISSN 0264-1275.
Anjana Talapatra, Shahin Boluki, Thien Duong, Xiaoning Qian, Edward
Dougherty, and Raymundo Arr´oyave. Autonomous eﬃcient experiment design
for materials discovery with Bayesian model averaging. Phys. Rev. Materials,
2(11):113803, 2018. doi: 10.1103/PhysRevMaterials.2.113803.
14

Isao Tanaka and Atsuto Seko. Toward Materials Discovery with First-Principles
Datasets and Learning Methods. In Turab Lookman, Francis J. Alexander,
and Krishna Rajan, editors, Information Science for Materials Discovery and
Design, pages 173–186. Springer International Publishing, 2016. doi: 10.1007/
978-3-319-23871-5 9.
Tsuyoshi Ueno, Trevor David Rhone, Zhufeng Hou, Teruyasu Mizoguchi, and
Koji Tsuda. COMBO: An eﬃcient Bayesian optimization library for materials
science. Materials Discovery, 4:18–21, 2016. ISSN 2352-9245. doi: https:
//doi.org/10.1016/j.md.2016.04.001.
Joaquin Vanschoren, Jan N. van Rijn, Bernd Bischl, and Luis Torgo. OpenML:
Networked Science in Machine Learning. SIGKDD Explorations, 15(2):49–60,
2013. doi: 10.1145/2641190.2641198.
Pratibha Vellanki, Santu Rana, Sunil Gupta, David Rubin, Alessandra Sutti,
Thomas Dorin, Murray Height, Paul Sanders, and Svetha Venkatesh. Process-
constrained batch bayesian optimisation. In I. Guyon, U. V. Luxburg, S. Ben-
gio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Ad-
vances in Neural Information Processing Systems, pages 3414–3423. Curran
Associates, Inc., 2017.
Paul B. Wigley, Patrick J. Everitt, Anton van den Hengel, John W. Bastian, Ma-
hasen A. Sooriyabandara, Gordon D. McDonald, Kyle S. Hardman, Ciaron D.
Quinlivan, Manju Perumbil, Carlos C. N. Kuhn, Ian R. Petersen, Andre N.
Luiten, Joseph J. Hope, Nicholas P. Robins, and Michael R. Hush.
Fast
machine-learning online optimization of ultra-cold-atom experiments. Scien-
tiﬁc reports, 6:25890–25890, 2016. ISSN 2045-2322. doi: 10.1038/srep25890.
Dezhen Xue, Prasanna V. Balachandran, John Hogden, James Theiler, Deqing
Xue, and Turab Lookman. Accelerated search for materials with targeted
properties by adaptive design. Nature Communications, 7:11241, April 2016.
URL https://doi.org/10.1038/ncomms11241.
15

