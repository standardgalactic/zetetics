Active Self-Supervised Learning:
A Few Low-Cost Relationships Are All You Need
Vivien Cabannes*
Meta AI
Leon Bottou
Meta AI
Yann Lecun
Meta AI
Randall Balestriero*
Meta AI
Abstract
Self-Supervised Learning (SSL) has emerged as the so-
lution of choice to learn transferable representations from
unlabeled data.
However, SSL requires to build sam-
ples that are known to be semantically akin, i.e. positive
views. Requiring such knowledge is the main limitation of
SSL and is often tackled by ad-hoc strategies e.g. apply-
ing known data-augmentations to the same input. In this
work, we generalize and formalize this principle through
Positive Active Learning (PAL) where an oracle queries se-
mantic relationships between samples. PAL achieves three
main objectives. First, it unveils a theoretically grounded
learning framework beyond SSL, that can be extended to
tackle supervised and semi-supervised learning depending
on the employed oracle. Second, it provides a consistent al-
gorithm to embed a priori knowledge, e.g. some observed
labels, into any SSL losses without any change in the train-
ing pipeline. Third, it provides a proper active learning
framework yielding low-cost solutions to annotate datasets,
arguably bringing the gap between theory and practice of
active learning that is based on simple-to-answer-by-non-
experts queries of semantic relationships between inputs.
1. Introduction
Learning representations of data that can be used to
solve multiple tasks, out-of-the-box, and with minimal post-
processing is one of the main goals of current AI research
[39, 35, 24].
Such representations are generally found
by processing given inputs through Deep Networks (DNs).
The main question of interest around which contemporary
research focuses on deals with the choice of the training set-
ting that is employed to tune the DN’s parameters. A few
different strategies have emerged such as layerwise [6], re-
construction based [48], and more recently, based on Self-
Supervised Learning (SSL) [14, 37]. In fact, due to the cost
of labeling and the size of datasets constantly growing, re-
*Equal contribution.
cent methods have tried to drift away from traditional super-
vised learning [42]. From existing training solutions, joint-
embedding SSL has emerged as one of the most promising
ones [34]. It consists in learning representations that are in-
variant along some known transformations while preventing
dimensional collapse of the representation. Such invariance
is enforced by applying some known Data-Augmentation
(DA), e.g. translations for images, to the same input and
making sure that their corresponding representations are the
same.
Despite tremendous progress, two main limitations re-
main in the way of a widespread deployment of SSL. First,
it separates itself entirely from supervised learning i.e. pro-
gresses made in each of those ﬁelds do not transfer to one
another. Second, it is not clear how to incorporate a priori
knowledge into SSL frameworks beyond the usual tweaking
of the loss and DAs being employed. For example, if one
has access to (some) label information, [16, 53] propose to
use SSL for pretraining, and to then ﬁne-tune with super-
vised learning; alternatively, [52] proposes to use the label
information to sample the positive pairs during SSL training
although without guarantee that this variant provides any
beneﬁt into the trained DN.
In this study, we propose to alleviate those two pitfalls
by redeﬁning existing SSL and supervised losses in terms
of a similarity graph –where nodes represent data samples
and edges reﬂect known inter-sample relationships.
Our
ﬁrst contribution stemming from this formulation provides a
generic framework to think about learning in terms of sim-
ilarity graph: it yields a spectrum on which SSL and su-
pervised learning can be seen as two extremes. Within this
realm, those two extremes are connected through the sim-
ilarity matrix, and in fact can be made equivalent by vary-
ing the similarity graph. In particular, we will obtain that
when that similarity graph aligns with the underlying la-
bels, SSL variants such as VICReg [3], BarlowTwins [51]
and SimCLR [14] learn representation akin to mean-square
error, discriminant analysis [32], and cross-entropy super-
vised learning respectively. Our second contribution natu-
rally emerges from using such a similarity graph to deﬁne
the SSL and supervised training losses, unveiling an elegant
arXiv:2303.15256v1  [cs.LG]  27 Mar 2023

Active Learning
Given an input, return its label e.g. for Imagenet:
- Tinca tinca
- Carassius auratus
- Carcharodon carcharias
- ...
query1
query2
response1
aligator
response2
aligator
Expansive oracle (expert knowledge)
Positive Active Learning (PAL)
Given inputs, choose if they are semantically related: yes/no
query1
and
response1
yes
query2
and
response2
no
Low-cost relationships information (reduced expertise)
or (recaptcha)
Figure 1. Active Self-Supervised Learning introduces PAL (right box), an alternative to active learning (left box) where the oracle is asked
if a collection of inputs are semantically related or not. As opposed to active learning, expert knowledge is reduced as one need not to know
all the possible classes but only how to distinguish inputs from the same class. As such, PAL proves to be a low-cost alternative acting
upon the similarity graph G (recall Eq. (8)); by querying enough samples, the learned representations of SSL or supervised learning are
identical (recall Theorem 2). PAL querying is ﬂexible, as an illustrative example we exhibit an `a la captcha, version where a given input is
presented along with a collection of other inputs, and the oracle can select among those inputs the positive ones.
framework to reduce the cost and expert requirement of ac-
tive learning summarized by:
Tell me who your friends are,
and I will tell you who you are.
Active learning, which aims to reduce supervised learning
cost by only asking an oracle for sample labels when needed
[41, 20, 26, 30], can now be formulated in term of relative
sample comparison, rather than absolute sample labeling.
This much more efﬁcient and low-cost approach is exactly
the active learning strategy stemming from our framework:
rather than asking for labels, one rather asks if two (or more)
inputs belong to the same classes or not, as depicted in
Fig. 1. We coin such a strategy as Positive Active Learning
(PAL), and we will present some key analysis on the bene-
ﬁts of PAL over traditional active learning. We summarize
our contributions below:
• We provide a uniﬁed learning framework based on the
concept of similarity graph, which encompasses both
self-supervised learning, supervised learning, as well
as semi-supervised learning and many variants.
• We derive a generic PAL algorithm based on an oracle
to query the underlying similarity graph Algorithm 1.
The different learning frameworks (SSL, supervised,
and so forth) are recovered by different oracles, who
can be combined to beneﬁt from each framework dis-
tinction.
• We show how PAL extends into an active learn-
ing framework based on similarity queries that pro-
vides low-cost efﬁcient strategies to annotate a dataset
(Fig. 1).
All statements of this study are proven in Appendix B,
code to reproduce experiments is provided at https://
github.com/VivienCabannes/rates.
2. Background on Self-Supervised Learning
This section provides a brief reminder of the main self-
supervised learning (SSL) methods, their associated losses,
and common notations for the remainder of the study.
A common strategy to learn a model in machine learn-
ing is to curate labeled examples (xn, yn)n, and to learn a
model that given xn ∈X ≜RD as input, outputs yn ∈[C],
hoping that this model will learn to recognize patterns and
relations that generalizes to new, unseen input data. Yet, as
the dataset grew larger, and annotating data has become a
major bottleneck, machine learning has shifted its attention
to learning methods that do not require knowledge of yn.
SSL has emerged as a powerful solution to circumvent the
need for expensive and time-consuming labeling. It learns a
embedding f : X →RK for a small K by enforcing either
reconstruction properties, or some invariance and symme-
try onto a learned representation. SSL also relies on a set
of observations X = {xn}N
n=1 ∈RN×D, yet instead of
labels yn, it requires known pairwise positive relation that
indicates whether two samples are semantically similar or

supervised
semi-sup.
PAL
Figure 2. Left: Depiction of the “knowledge graph” arising from binary classiﬁcation, notice the two connected components, each cor-
responding to a single class. Each sample is associated with a node of the graph (blue circle) and the known positive relation between
samples is represented by an edge. This knowledge is summarized into the G matrix depicted on the bottom row. Right: Examples of the
N ×N symmetric adjacency matrices G for the case of binary classiﬁcation (same as at the top row). Each nonzero entry (G)i,j represents
the known positive relation between sample i and j. The insight that will play a key role in our analysis is that knowing G is equivalent to
knowing the underlying per-sample labels. As such, when PAL is employed (right column) and all the entries are recovered, SSL training
will lead to the same representation as supervised training. Any a priori knowledge e.g. as in semi-supervised learning (middle column)
can be incorporated into G prior PAL.
not. For simplicity, we shall focus on the joint-embedding
framework, where those positive pairs are artiﬁcially gener-
ated on the ﬂy by applying Data Augmentations (DA), e.g.
adding white noise, masking, on the same input. Let denote
T1, T2 : X →X the generators of two (random) DAs T1(x)
and T2(x) from an input x, fθ : RD →RK the parametric
model to be learned, and
Z(1) ≜


fθ(T1(x1))
...
fθ(T1(xN))

, Z(2) ≜


(fθ(T2(x1))
...
(fθ(T2(xN))

,
(1)
where (z(1)
n , z(2)
n ), the nth row of Z(1) and Z(2) respec-
tively, form the nth positive pair associated to sample xn.
Using (1), different SSL losses will employ different mea-
sures of invariance and dimensional collapse. Typically, the
losses are minimized with gradient descent and backpropa-
gation to learn θ.
VICReg. With the above notations, the VICReg loss [3]
reads, with hyper-parameter α, β > 0,
LVIC = α
K
X
k=1
ReLU

1 −
p
Ck,k

+ β
X
k̸=l
C2
k,l
+ 1
N ∥Z(1) −Z(2)∥2
2,
C ≜Cov(
Z(1)
Z(2)

).
(2)
SimCLR. The SimCLR loss [14] with temperature
hyper-parameter τ > 0 reads
LSim = −
N
X
i=1
Ci,i
τ
+ log


N
X
i̸=j
exp
Ci,j
τ

,
Ci,j ≜CoSim(Z(1), Z(2))ij ≜
D
z(1)
i
, z(2)
j
E
∥z(1)
i
∥∥z(2)
j ∥
,
(3)
BarlowTwins. BarlowTwins [51] is built on the cross-
correlation matrix Cij = CoSim(Z(1)⊤, Z(2)⊤), with the
hyper-parameter λ it reads
LBT =
K
X
k=1
(1 −Cii)2 + λ
X
i̸=j
C2
ij.
(4)
Spectral Contrastive Loss. Finally, the spectral con-
trastive loss [27] is theory-friendly proxy for SSL reading
LVIC2 = −2
D
Z(1), Z(2)E
+ 1
N
X
i̸=j
D
z(1)
i
, z(2)
j
E2
.
(5)
In particular, as proven in Appendix B.1.1, (5) recovers
VICReg (2) when the ReLU-hinge loss is replaced by the
mean-square error, hence the denomination VIC2.
The Commonality between SSL Losses. All the above
Eqs. (2) to (5) losses combine two terms: (i) a matching
term between positive pairs, and (ii) a term to avoid collapse
towards predicting a constant solution for all inputs. (i) can
take different forms such as the squared norm between Z(1)
and Z(2) (2), the opposite of their scalar product (5), or of
their cosine (3), or the square norm between the centered-
cosine and one (4). (ii) can also take different forms such as
the infoNCE softmax (5), or an energy that enforces rich-
ness of the learn feature, such as the variance-covariance
regularization in (2) forcing the different coordinates of fθ
to be orthogonal [12].
While at face-value those losses seem distinct, they actu-
ally all simply consist and combine some variants of (i) and
(ii), and even more importantly, they all rely on the exact
same information of positive inter-sample relation for (i).
This is exactly what the next Section 3 will dive into, as a
means to unify SSL losses, along with supervised losses.

3. The Ubiquity of Similarity Graphs
The goal of this section is to unify SSL and supervised
learning through the introduction of a special object: a sim-
ilarity graph.
3.1. The Graphs for (Self-)Supervised Learning
Throughout this study, a similarity graph denotes a graph
for which nodes represent data samples, and edges reﬂect
similarity relationships. Formally, such a graph is expressed
through its symmetric adjacency matrix G ∈RN×N, the
semantic relation between inputs i and j being encoded
in the real entry Gi,j. The remainder of this section will
demonstrate how (i) SSL losses are implicitly based on a
similarity graph (ii) how those losses tackle the supervised
learning problem when provided a richer graph G.
Supervised learning. In addition to the N input samples
X ∈RN×D, supervised learning has access to paired labels
y ≜[y1, . . . , yN]. For clarity, we focus here on categorical
labels i.e. yn belongs to {1, . . . , C} for C the number of
classes.1 The one-hot encoding of y will be denoted by
the matrix Y ∈RN×C. In terms of the similarity graph
G, the label-based relation becomes naturally encoded as
Gi,j = 1{yi̸=yj}, or equivalently
G(Y ) = Y Y ⊤
(6)
A key observation that we must emphasize is that the graph
G almost explicitly encodes for the labels Y , which will be
made explicit with Theorem 2.
Multiple Epochs with Data Augmentation. When DA
is employed, and training is carried for E epochs, the orig-
inal N input samples are transformed into N × E “aug-
mented” samples. For more generality, since DA will also
be used in SSL, let’s denote by A ∈N∗the number of aug-
mentations –where here A = E. We now have the aug-
mented dataset
X(A) ≜[T (x1), . . . , T (x1)
|
{z
}
repeated A times
, . . . , T (xN), . . . , T (xN)]⊤,
where each T has its own randomness. When available,
i.e. for supervised learning, the corresponding “augmented”
labels Y (A) are given by repeating A times each row of
Y , formally written with the Kronecker product Y (sup) ≜
Y ⊗1A, and from that, we can now deﬁne the supervised
dataset and associated graph extending (6) to the case of
multiple epochs and DA training
X(sup) ≜X(E),
G(sup) ≜Y (sup)⊤Y (sup).
(7)
1While we focus here on classiﬁcation for simplicity, our approach is
easily extendable for generic problems involving a loss ℓby deﬁning the
graph as Gij = −ℓ(yi, yj). In the classiﬁcation, ℓcould be the zero-
one loss ℓ(yi, yj) = 1{yi̸=yj}, and Gij ≃1 −ℓ(yi, yj). See Ap-
pendix B.2.1 for details.
The resulting graph (7) is depicted on the left part of Fig. 2.
Self-Supervised Learning. SSL does not rely on labels,
but on positive pairs/tuples/views generated at each epoch.
Let us denote by V the number of positive views generated,
commonly V = 2 for positive pairs as modeled in (1). With
E the total number of epochs, SSL produces V ×E samples
semantically related to each original sample xn through the
course of training i.e. in SSL A = V × E while in super-
vised learning A = E. The total number of samples is thus
N × E × V , deﬁning the dataset and associated graph
X(ssl) ≜X(V ×E), G(ssl)
i,j
= 1{⌊i/V E⌋=⌊j/V E⌋},
(8)
where the associated similarity graph G(ssl) –now of size
NEV × NEV – captures if two samples were generated as
DA of the same original input.
3.2. Self-Supervised Learning on a Graph
This section reformulates the different SSL losses
through the sole usage of the similarity graph G(ssl). To
lighten notations, and without loss of generality, we rede-
ﬁne X ∈RN×D to denote the full dataset, i.e. N ←NEV
with X = X(sup) for supervised learning with V × E
epochs, or with X = X(ssl) in SSL with E epochs with
V views for the SSL case. The model embedding is short-
ened to Z ≜fθ(X) ∈RN×K as per Eq. (1).
Theorem 1. VICReg (2), SimCLR (3), and BarlowTwins (4)
losses can be expressed in term of the graph G (8)
LVIC2(Z; G) =∥ZZT −G∥2
F ,
LSim(Z; G) = −
X
i,j∈[N]
Gi,j log
 
exp(˜z⊤
i ˜zj)
P
k∈[N] exp(˜z⊤
i ˜zk)
!
,
LBT(Z; G) =
 ˜Z⊤G ˜Z −I

2
,
where D = diag(G1) is the degree matrix of G; with
˜z ≜z/ ∥z∥and ˜Z the column normalized Z so that each
column has unit norm.
From Theorem 1, we obtain the direct observation that
VICReg is akin to Laplacian Eigenmaps or multidimen-
sional scaling, SimCLR is akin to Cross-entropy and Bar-
lowTwins is akin to Canonical Correlation Analysis; ob-
servations already discovered in the literature [2] and re-
inforced above.
Beyond recovering such representation learning losses,
our goal is to go one step further and to tie SSL and super-
vised learning through the lens of G, which follows in the
next section.

3.3. Self-Supervised is a G Away from Supervised
What happens if one takes the different SSL losses, but
replaces the usual SSL graph G(ssl) with the supervised one
G(sup)?
It turns out that the learned representations emerging
from such losses are identical –up to some negligible sym-
metries that can be corrected for when learning a linear
probe– to the one hot-encoding of Y . To make our for-
mal statement (Theorem 2) clearer, we introduce a the set
of optimal representations that minimize a given loss:
Smethod(G) ≜arg min
Z∈RN×K Lmethod(Z; G),
where “method” refers to the different losses.
Theorem 2 (Interpolation optimum). When K ≥C, and
Z = fθ(X) is unconstrained (e.g. interpolation regime
with a rich functions class), the SSL losses as per Theorem 1
with the supervised graph (7) solve the supervised learning
problem with:
SVIC2(G(sup)) =

Y R
 R ∈RC×K; RR⊤= IC
	
,
SSim(G(sup)) =

DY RM −1  D ∈diag+, R ∈O
	
,
SBT(G(sup)) =

Y RD
 D ∈diag+, R ∈O
	
,
where R ∈O means that R is a rotation matrix as de-
ﬁned for the VICReg loss, diag+ = diag(RN
+) are the set
of diagonal matrix with positive entries, i.e. renormaliza-
tion matrices, and M is a matrix that maps a deformation
of the simplex into the canonical basis. Moreover, provided
class templates, i.e. C data points associated with each of
the C classes, Y is easily retrieved from any methods and
Z ∈Smethod.
In essence, Theorem 2 states that SSL losses solve the
supervised learning problem when the employed graph G
is G(sup).
Moreover, the matrix D appearing in Theo-
rem 2 captures the fact that SimCLR solutions are invari-
ant to rescaling logit and is akin to the cross-entropy loss,
while BarlowTwin is invariant to column renormalization
of Z and is akin to discriminant analysis. Lastly, VICReg
might be thought of as a proxy for the least-squares loss.
At a high-level, Theorem 2 suggests fruitful links between
spectral embedding techniques captured in Theorem 1 and
supervised learning.
We let for future work the investi-
gation of this link and translation of spectral embedding
results in the realm of supervised learning. While Theo-
rem 2 describes what we have coined as the “interpolation
optimum”, i.e. solution in the interpolation regime with
rich models, we ought to highlight that classical statistical
learning literature analyzes losses under the light of “Bayes
optimum”, i.e. solutions in noisy context-free setting [4].
Those Bayes optima do not make as much sense for losses
that intrinsically relate different inputs, yet for complete-
ness we provide such a proposition on Bayes optimum in
Appendix B.3.
4. PAL: Positive Active Learning
Now that we demonstrated how one should focus on the
graph G, rather than the (self-)supervised loss, we turn our
focus into getting that graph G. In particular, we propose
an active learning framework that discovers G through efﬁ-
cient, low-cost queries.
4.1. One Framework to Rule Them All
From our understanding (Theorem 2), the difﬁculties of
both supervised learning and SSL are the same: they need
a correct graph G, i.e they need to identify samples that
are semantically similar, either through label annotations or
through the right design of DA.
Algorithm 1: PAL framework with oracle
Data: X ∈RN×D; unknown graph G = G(sup).
Result: Embedding fθ : RD →RK.
Initialization: weights θ0, scheduler (γt); T ∈N;
for t ∈[T] do
Collect It, Jt ←from sampler;
Collect (Gij = 1{yi=yj})(i,j)∈It from labelers;
Update θt+1 ←θt −γt∇θL(θt; G, It, Jt).
Our framework suggests a generic way to proceed, hav-
ing ﬁxed the samples X in advance, and without much
a priori knowledge on the similarity graph G. In an ac-
tive learning spirit, one would like to design a query strat-
egy to discover G, and an update rule for the learned pa-
rameter θ. To ground the discussion, let us focus on VI-
CReg. The variance-covariance term can be rewritten with
R(a, b) = (a⊤b)2 −∥a∥2 −∥b∥2, this leads to the formula,
proven in Appendix B.1.1,
LVIC2(θ; G, I, J) =
X
(i,j)∈I
Gi,j ∥fθ(xi) −fθ(xj)∥2 (9)
+
X
(i,j)∈J
R(fθ(xi), fθ(xj)),
(10)
where I = J = [N]2. An oracle would typically consider
two small sets of indices I, J ⊂[N]2, asks labelers to pro-
vide Gij for i, j ∈I, and, given a step size γt, update the
weights with
θt+1 = θt −γt∇θL(θt; G, I, J),
(11)
which could be performed with the sole access to
(Gij)(i,j)∈I.
The pairs in J are used to compute the

variance-covariance regularization term. The complete pic-
ture leads to PAL, Algorithm 1. A particularly useful fea-
tures of SGD for active learning is its robustness to labeling
noise [10]. In other terms, Algorithm 1 is robust to noise in
the query answers.
We will now dive more in-depth into two variants of or-
acles: passive and active ones. As we will see, passive or-
acles can recover traditional SSL as special cases, but will
be much less efﬁcient in learning good representation than
active strategies.
4.2. Passive Oracles
Passive variations of the PAL algorithm consist in ﬁxing
the oracle behavior at iterations t ∈[T] before starting the
training. This formulation, under which the oracle does not
leverage any information collected along training, recovers
both SSL and supervised learning, based on the different
querying strategies.
Self-Supervised Oracle. Probably the simplest oracle to
describe is the one corresponding to the SSL strategy. The
original VICReg algorithm [3] is made of t gradient updates
over T = N0E iterations with N = N0V E samples, where
N0 is the number of original samples, E is the number of
epochs, V the number of views. At time t ∈[T], It is
chosen as {(2t + 1, 2(t + 1))}, describing a positive pairs
generated on the ﬂy from one original sample xi for i =
t mod. N0; and Jt is chosen as some mini-batch to estimate
the covariance matrix of the features at the current epoch.
Because it has been built to remove human feedback, SSL
actually does not need to ask for labelers to query Gs,s+1
(where s = 2t + 1), since it is known by construction that
those entries are going to be one.
Supervised Oracle. When it comes to a supervised
learning oracle, the supervised learning loss provided in
Theorem 1 –which is known to recover Y (given class tem-
plates) as per Theorem 2– is easily minimized with gradi-
ent descent based on (10). Hence a simple oracle to solve
the supervised learning problem based on stochastic gradi-
ent descent: at time t, consider a random pair of indices
(it, jt) and set It = Jt ←{(it, jt)}. The querying of
Git,jt can either be done on the ﬂy, or if the dataset is al-
ready annotated, it can be deduced from the knowledge of
Git,jt = 1{yit=yjt}.
Algorithm 2: Passive Oracle Speciﬁcations
SSL oracle:
Sampler: It =

(i2t+1, i2(t+1))
	
, Jt a minibatch,
Labeler: G2t+1,2(t+1) = 1.
Supervised oracle:
Sampler: It = Jt = {(it, jt)} random in [N]2,
Labeler: Gi,j = 1{yi=yj}.
Theoretical Remarks. Remarking that (10) is an unbi-
ased formulation of VICReg, in the sense that
LVIC2(Z) = EI,J∼U([N]2) [LVIC2(Z; I, J)] .
As a consequence, when θ 7→
fθ(X)fθ(X)⊤−G
2 is
strongly convex, Algorithm 3 with either the self-supervised
or the supervised oracle will converge to the minimizer
of the VICReg loss in O(1/T) [8]. Moreover, while this
results holds for the empirical loss with resampling, it is
equally possible to get a similar result for the minimization
of the inﬁnite-data (aka population) version of the VICReg
loss and the recovery of the ideal embedding representation,
when performing a single pass over the data. In particular,
by making sure that J only charges pairs (i, j) for i and j
in two disjoint subsets of [N], one can prove convergence
rates in O(1/N) (Theorem 3 in [12]).
Moreover, because the VICReg loss in Theorem 2 is
nothing but a matrix factorization problem, one can directly
translate results from this literature body into PAL. In par-
ticular, recent works have derived theoretical results regard-
ing the matrix factorization problem based on toy models
of neural networks, which might be plugged directly in here
to claim theoretical results about the soundness of the PAL
algorithm with neural networks [50, 22, 28]. Since those
results hold for any graph G, such results directly apply to
both SSL and supervised learning, highlighting how PAL
jointly derives results for SSL and supervised learning.
4.3. Active Oracles
Seen through the eyes of PAL, supervised and SSL –
which employ passive querying– can be improved by reﬁn-
ing the oracle to choose the next indices It and Jt to process
at time t.
Low-Cost and Efﬁcient Active Learning. A crucial
point of this study is that the active learning framework
stemming from PAL differs fundamentally from classic ac-
tive learning. In the latter, at time t, one asks for a fresh
label yit for some chosen index it. Instead, PAL consid-
ers a batch of data It and asks for pairwise comparisons
1{yi∼yj} for (i, j) ∈I. Rather than asking labelers for
ﬁne-grained labels, such as “caracal” or “numbﬁsh” on Im-
ageNet, PAL would rather asks labelers if two images are re-
lated, or even to spot outliers in a set of images compared to
a template, as illustrated on Fig. 1.2 This is particularly use-
ful when the cost of spotting a few outliers in a batch of M
images is much less costly than annotating M data points.
On such instances, Criteo engineers found that batches of
15 images was a sweet spot in terms of labeling efﬁciency
[5]; while ImageNet was annotated by querying images on
2This “spot-the-outliers” strategy is formalized with It = {(it, j) | j ∈
˜It} for it representing the class template, and ˜It capturing the batch of
data to spot outliers in.

Level lines of e3⊤fθ at snapshots (learned with VICReg)
Optimal linear probe w⊤fθ for downstream task
0
200
400
600
800
Number of queries
0.0
0.2
0.4
0.6
Test error
active
passive
Figure 3. Comparison the active oracle of Algorithm 3 and the
passive supervised one of Algorithm 2. Given q queries made,
and the consequent reconstructed graph Gq, we learn fθt : X →
RC by minimizing LVIC2, and plot the downstream mean-square
error of the optimal a linear classiﬁer w⊤fθt for the best w ∈
RC. Here X = R2, and y ∈[4] spans four concentric circles
(represented by the blue, red, green and orange classes), N = 100,
query batches are chosen of size 10 and results are average over
100 trials (standard deviations being represented by the colorized
regions). Snapshots at different points on the curve show the third
coordinates of the reconstructed fθt, and the ideal linear classiﬁer
that can be learned based on this embedding.
search engines, and spotting outliers among the results [21].
Meanwhile, reCaptcha (illustrated on Fig. 1) is said to have
helped annotate millions of images [9]. We refer the curious
reader to [43] and references therein regarding the design of
efﬁcient user interfaces for those labeling tasks.
Zoo of Active Learning Strategies. By introducing
PAL, we open a way to match the practice of active learn-
ing and its theory through a grounded framework that en-
compasses current heuristics to annotate big chunks of data.
While the optimal oracle depends on the problem idiosyn-
crasies, as well as the labeling cost model, the vast literature
body on active learning provides many heuristics to design
sophisticated or intricate oracles under different structural
assumptions. One could query information based on the
least certain predictions [26, 1]; based on the distance to the
decision boundaries [44]; by comparing predictions made
by different methods in an ensemble [7, 17]; or by ﬁnding
the queries whose answers are the most likely to modify the
current guess for fθ [49, 33, 30]. Throughout reviews, adap-
tations to PAL, ablation studies and comparisons on differ-
ent benchmarks of those strategies is left for future work.
PAL `a la Captcha. A natural and easy property to lever-
age in order to build active learning strategies is the fact that
the N 2-entry matrix G is actually derived from the NC-
entry matrix Y . In particular, one can recover the full graph
G = G(sup) with less than NC pairwise queries, and in the
best case only N queries –compare this to the N 2-entries
that are queried by the supervised learning oracle.
This
idea is captured formally with the oracle described in Al-
gorithm 3, where the matrix Q remembered past queries,
and illustrated on Fig. 3. At time t, this oracle chooses to
query against the class with the least numbers of known in-
stances, and choose M data points, ask if they match this
class, and update known labels as a consequence. An ad-
vantage of the query strategy of Algorithm 3 is that one can
stop at any time t and have a balanced labeled dataset to
learn with.
Algorithm 3: Oracle `a la Captcha
Data: Class templates (µ1, · · · , µC) ∈X C,
Q ∈RN×C initialized at zero.
Choose the class with least known examples
j = arg minj 1⊤Qtej ∈[C];
Collect pairwise comparison Qij ←1{xi∼µj} for i
in a batch B ⊂[N] \ Kt where Kt remove queries
with known results based on Qt;
Sampler: It = Jt all the new entries deduced in G.
Labeler: Human feedback Qij; deduction to ﬁll G.
The basic Algorithm 3 can be improved in several ways.
First, class templates can be deduced based on initial
queries: the ﬁrst data point µ1 = x1 provides a ﬁrst class
template; after querying 1{x2∼x1} if the answer is negative,
µ2 = x2 provides a second class template (otherwise it is
part of class one); so forth and so on (if 1{x=µ1} = · · · =
1{x=µk} = 0, set µk+1 = x). Those templates could be re-
ﬁned during training by deﬁning the templates as the exam-
ple the most at the center of the classes examples with some
well-thought notion of distance (either in the input space
or the embedding space). Second, when classes are unbal-
anced and class probabilities are roughly known, one should
rather choose y(t) to be the class that minimizes the number
of known examples in this class divided by the probability
of this class. Third, if C the number of classes is small, ran-
dom sampling of the batch B will work well enough. Yet,
when C is big, random sampling will mainly lead to nega-
tive observations and too few positive ones. In this situation,
the algorithm is improved by training a classiﬁer based on
known labels at time t (eventually incorporating unlabeled
data with semi-supervised learning techniques), and query-
ing labels that were classiﬁed as the same class. Finally,

Modality
Oracle
1 accuracy
5 accuracy
Passive
SimCLR [15]
71.7
-
Passive
VICReg [3]
73.2
91.1
Active
NNCLR [23]
75.6
92.4
Table 1. Best known performance on ImageNet for state-of-the-
art SSL methods. Notice how NNCLR [23] derives states of the
art performance on ImageNet thanks to an active rule for labelers
in Algorithm 1, which consists in deﬁning positive pairs as near-
est neighbors in the embedding space as detailed in Algorithm 4.
This rule allows to beat the passive strategy that are provided by
SimCLR and VICReg.
to avoid only getting negative pairs on datasets with many
classes, one could leverage hierarchy in the labels: if deal-
ing with the classes of ImageNet, one can ﬁrst ask reviewers
coarse-grained information, e.g. ﬂag pictures that are not
ﬁshes; before going deeper in the taxonomy.
5. Experiments
This section provides experimental details to validate the
various theoretical results derived in previous sections. In
order to remove confounding effects linked with architec-
ture, optimization, data curation and other design choices
that might impact the different empirical validation we fo-
cus here on closed-form solution based on kernel methods
with synthetic dataset. Further real-world empirical vali-
dations are provided in Appendix C. In particular, Table 1
reminds the reader how NNCLR [23] succeed to beat state-
of-the-art SSL methods on ImageNet thanks to an active la-
beler oracle, which deﬁnes positive pairs as nearest neigh-
bors in the embedding space fθt(X).
Kernel methods are rich “linear” parametric models de-
ﬁned as fθ
= θ⊤φ(x), for φ(x) and θ belonging to
a separable Hilbert space H.
Because those model can
approximate any function [36], it is important to regu-
larize θ in practice, either with early stopping in SGD,
or with Tikhonov regularization, which can be written as
λ Tr(Z⊤K−1Z) where λ > 0 is a regularization parame-
ter and K ∈RN×N is the kernel matrix deﬁned as Kij =
k(xi, xj) = φ(xi)⊤φ(xj).
In this setting, rather than
matching the top of the spectral decomposition of G, the so-
lution recovered by VICReg amounts to the top spectral de-
composition of G−λK−1 [12]. This allows to compute the
ideal representation of fθ in closed-form given any graph
G based on the regularized kernel model fθ = θ⊤φ(x),
hence ablating the effects that are unrelated to the theory
described in this study. In this controlled setting, the su-
periority of active algorithms is undeniable, and illustrated
on Fig. 3, where we illustrate the optimal downstream error
one can achieve with linear probing of the minimizer fθ of
the VICReg loss. Experimental details and more extensive
validations are provided in Appendix C: in particular, the
use of non-contrastive versus contrastive graphs, i.e. that
set Gij = −1 when yi ̸= yj, is studied on Fig. 7; the ability
to incorporate label knowledge in SSL methods is the ob-
ject of Fig. 4; robustness to noise is shown on Fig. 8; and
relations between test error and the number of connected
components of the reconstructed G is analyzed on Fig. 9.
0
50
100
150
200
Number of labels
0.0
0.2
0.4
0.6
Test error
α = 0.5
α = 10−3
α = 10−6
Figure 4.
A major motivation of this paper is to be able to add
prior information on sample relationships in SSL methods, and
more in particular, to have a simple way to leverage known la-
bels. We do by considering Y containing one-hot encoding of
known labels, and rows being zero otherwise and the mixed graph
G = (1−α)·G(ssl) +α· ˆY ˆY ⊤. The setting is the same as Fig. 5
with N = 200 and two augmentations per sample. When zero
labels are known (left of the plot), we are in the full SSL regime,
while when all the 200 labels are known (right of the plot), we re-
cover supervised learning performance. When few labels are given
the effect of the supervised graph can be counterproductive if the
mixing coefﬁcient α is too big. However, when mixed properly,
adding prior label information in SSL methods allows to improve
performance.
6. Conclusions
This work introduces PAL, a learning framework that re-
volves around the central concept of similarity graph. We
ﬁrst showed how similarity graphs are the implicit backbone
of self-supervised learning methods, and how this concept
extends to tackle supervised learning problems. This ob-
servation does not solely unveil a rich learning framework,
but also provides a single algorithm based on a querying
oracle that can describe both SSL and supervised learn-
ing techniques, opening the way to new oracles that ben-
eﬁt from techniques stemming from both the supervised
and self-supervised learning literature. Finally, PAL leads
to an efﬁcient formalization of active learning as performed
in practice to annotate large datasets, potentially enabling
fruitful exchanges between the practice and the theory of
active learning. Promising directions for future works in-
clude empirical validations on large-scale datasets, as well
as theoretical study of the newly introduced active learning
framework.

References
[1] Jordan Ash, Chicheng Zhang, Akshay Krishnamurthy, John
Langford, and Alekh Agarwal. Deep batch active learning
by diverse, uncertain gradient lower bounds. In ICLR, 2020.
7, 11
[2] Randall Balestriero and Yann LeCun.
Contrastive and
non-contrastive self-supervised learning recover global
and local spectral embedding methods.
arXiv preprint
arXiv:2205.11508, 2022. 4
[3] Adrien Bardes, Jean Ponce, and Yann LeCun.
Vi-
creg: Variance-invariance-covariance regularization for self-
supervised learning. arXiv preprint arXiv:2105.04906, 2021.
1, 3, 6, 8
[4] Peter Bartlett, Michael Jordan, and Jon McAuliffe. Convex-
ity, classiﬁcation, and risk bounds. Journal of the American
Statistical Association, 2006. 5
[5] Renaud Bauvin. Lessons learned from annotating 5 million
images, 2019. Medium. 6
[6] Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo
Larochelle.
Greedy layer-wise training of deep networks.
Advances in neural information processing systems, 19,
2006. 1
[7] Mustafa Bilgic, Lilyana Mihalkova, and Lise Getoor. Active
learning for networked data. In ICML, 2010. 7
[8] S´ebastien Bubeck.
Convex optimization: Algorithms and
complexity. Foundations and Trends in Machine Learning,
pages 231–357, 2015. 6
[9] ByteBridge. Data annotation: By typing captcha, you are
actually helping ai model training, 2021. Medium. 7
[10] Vivien Cabannes, Francis Bach, Vianney Perchet, and
Alessandro Rudi. Active labeling: streaming stochastic gra-
dients. In NeurIPS, 2022. 6
[11] Vivien Cabannes, Alberto Bietti, and Randall Balestriero. On
minimal variations for unsupervised representation learning.
In ICASSP, 2023. 12
[12] Vivien Cabannes, Bobak T Kiani, Randall Balestriero, Yann
LeCun, and Alberto Bietti. The SSL interplay: Augmen-
tations, inductive bias, and generalization.
arXiv preprint
arXiv:2302.02774, 2023. 3, 6, 8
[13] Nicol`o Cesa-Bianchi, Claudio Gentile, and Luca Zaniboni.
Incremental algorithms for hierarchical classiﬁcation. Jour-
nal of Machine Learning Research, 2006. 11
[14] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Ge-
offrey Hinton. A simple framework for contrastive learning
of visual representations. In International conference on ma-
chine learning, pages 1597–1607. PMLR, 2020. 1, 3
[15] Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad
Norouzi, and Geoffrey Hinton. Big self-supervised models
are strong semi-supervised learners. In NeurIPS, 2020. 8
[16] Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad
Norouzi, and Geoffrey E Hinton. Big self-supervised mod-
els are strong semi-supervised learners. Advances in neural
information processing systems, 33:22243–22255, 2020. 1
[17] Kashyap Chitta, Jose Alvarez, Elmar Haussmann, and
Clement Farabet. Training data subset search with ensem-
ble active learning. IEEE Transactions on Intelligent Trans-
portation Systems, 2021. 7, 11
[18] Timoth´ee Cour, Benjamin Sapp, and Ben Taskar. Learning
from partial labels. Journal of Machine Learning Research,
2011. 11
[19] Thomas Cover and Joy Thomas. Elements of Information
Theory. Wiley, 1991. 18
[20] Sanjoy Dasgupta. Two faces of active learning. Theoretical
Computer Science, 412(19):1767–1781, 2011. 2
[21] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Fei-Fei Li. Imagenet: A large-scale hierarchical image
database.
In Conference on Computer Vision and Pattern
Recognition, 2009. 7
[22] Simon Du, Wei Hu, and Jason Lee. Algorithmic regular-
ization in learning deep homogeneous models: Layers are
automatically balanced. In NeurIPS, 2018. 6
[23] Debidatta Dwibedi, Yusuf Aytar, Jonathan Tompson, Pierre
Sermanet, and Andrew Zisserman. With a little help from my
friends: Nearest-neighbor contrastive learning of visual rep-
resentations. In Proceedings of the IEEE/CVF International
Conference on Computer Vision, pages 9588–9597, 2021. 8,
11
[24] Nanyi Fei, Zhiwu Lu, Yizhao Gao, Guoxing Yang, Yuqi Huo,
Jingyuan Wen, Haoyu Lu, Ruihua Song, Xin Gao, Tao Xi-
ang, Hao Sun, and Ji-Rong Wen.
Towards artiﬁcial gen-
eral intelligence via a multimodal foundation model. Nature
Communications, 2022. 1
[25] Tanner Fiez, Lalit Jain, Kevin G Jamieson, and Lillian
Ratliff.
Sequential Experimental Design for Transductive
Linear Bandits. In Advances in Neural Information Process-
ing Systems, 2019. 11
[26] Steve Hanneke. Theory of disagreement-based active learn-
ing. Foundations and Trends in Machine Learning, pages
131–309, 2014. 2, 7
[27] Jeff Z HaoChen, Colin Wei, Adrien Gaidon, and Tengyu Ma.
Provable guarantees for self-supervised deep learning with
spectral contrastive loss. Advances in Neural Information
Processing Systems, 34, 2021. 3
[28] Liwei Jiang, Yudong Chen, and Lijun Ding. Algorithmic reg-
ularization in model-free overparametrized asymmetric ma-
trix factorization. In ArXiv, 2022. 6
[29] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom
Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec
Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for
neural language models. In ArXiv, 2020. 11
[30] Mina Karzand and Robert Nowak. Maximin active learn-
ing in overparameterized model classes. IEEE Journal on
Selected Areas in Information Theory, 2020. 2, 7
[31] Bobak T Kiani, Randall Balestriero, Yubei Chen, Seth Lloyd,
and Yann LeCun.
Joint embedding self-supervised learn-
ing in the kernel regime. arXiv preprint arXiv:2209.14884,
2022. 12
[32] William R Klecka, Gudmund R Iversen, and William R
Klecka. Discriminant analysis, volume 19. Sage, 1980. 1
[33] Donald Knuth. The computer as master mind. Journal of
Recreational Mathematics, 1977. 7
[34] Yann LeCun. A path towards autonomous machine intelli-
gence. In ArXiv, 2022. 1

[35] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep
learning. nature, 521(7553):436–444, 2015. 1
[36] Charles Micchelli, Yuesheng Xu, and Haizhang Zhang. Uni-
versal kernels. Journal of Machine Learning Research, 2006.
8
[37] Ishan Misra and Laurens van der Maaten. Self-supervised
learning of pretext-invariant representations. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pat-
tern Recognition, pages 6707–6717, 2020. 1
[38] Alex Nowak-Vila, Francis Bach, and Alessandro Rudi.
Sharp analysis of learning with discrete losses. In Artiﬁcial
Intelligence and Statistics, 2019. 14
[39] Sinno Jialin Pan and Qiang Yang. A survey on transfer learn-
ing. IEEE Transactions on knowledge and data engineering,
22(10):1345–1359, 2010. 1
[40] Alexander Ratner, Stephen Bach, Henry Ehrenberg, Jason
Fries, Sen Wu, and Christopher R´e. Snorkel: rapid training
data creation with weak supervision.
The VLDB Journal,
2020. 11
[41] Burr Settles.
Active learning literature survey.
Technical
report, University of Wisconsin-Madison, 2010. 2
[42] Burr Settles. From theories to queries: Active learning in
practice. In Active learning and experimental design work-
shop in conjunction with AISTATS 2010, pages 1–18. JMLR
Workshop and Conference Proceedings, 2011. 1
[43] Patrice Simard, Saleema Amershi, David Chickering, Ali-
cia Edelman Pelton, Soroush Ghorashi, Christopher Meek,
Gonzalo Ramos, Jina Suh, Johan Verwey, Mo Wang, and
John Wernsing.
Machine teaching: A new paradigm for
building machine learning systems. In ArXiv, 2017. 7
[44] Ben Sorscher, Robert Geirhos, Shashank Shekhar, Surya
Ganguli, and Ari Morcos. Beyond neural scaling laws: beat-
ing power law scaling via data pruning. In NeurIPS, 2022.
7, 11
[45] Petru Soviany, Radu Tudor Ionescu, Paolo Rota, and Nicu
Sebe. Curriculum learning: A survey. International Journal
of Computer Vision, 2022. 11
[46] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, Timoth´ee Lacroix, Baptiste
Rozi`ere, Naman Goyal, Eric Hambro, Faisal Azhar, Aure-
lien Rodriguez, Armand Joulin, Edouard Grave, and Guil-
laume Lample. Llama: Open and efﬁcient foundation lan-
guage models. In ArXiv, 2023. 11
[47] Rom Varshamov. Estimate of the number of signals in error
correcting codes. Doklady Akademii Nauk SSSR, 1957. 18
[48] Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and
Pierre-Antoine Manzagol. Extracting and composing robust
features with denoising autoencoders. In Proceedings of the
25th international conference on Machine learning, pages
1096–1103, 2008. 1
[49] Zhilin Yang, William Cohen, , and Ruslan Salakhutdinov.
Semi-supervised learning with graph embeddings. In ICML,
2016. 7
[50] Tian Ye and Simon Du.
Global convergence of gradient
descent for asymmetric low-rank matrix factorization.
In
ArXiv, 2021. 6
[51] Jure Zbontar, Li Jing, Ishan Misra, Yann LeCun, and
St´ephane Deny. Barlow twins: Self-supervised learning via
redundancy reduction.
arXiv preprint arXiv:2103.03230,
2021. 1, 3
[52] Xiaohua Zhai, Avital Oliver, Alexander Kolesnikov, and Lu-
cas Beyer. S4l: Self-supervised semi-supervised learning. In
Proceedings of the IEEE/CVF international conference on
computer vision, pages 1476–1485, 2019. 1
[53] Evgenii Zheltonozhskii, Chaim Baskin, Avi Mendelson,
Alex M Bronstein, and Or Litany. Contrast to divide: Self-
supervised pre-training for learning with noisy labels.
In
Proceedings of the IEEE/CVF Winter Conference on Appli-
cations of Computer Vision, pages 1657–1667, 2022. 1

A. Active Learning Algorithms
NNCLR oracle. State-of-the-art the year of its release, [23] proposes a variation of SSL, that does not need human
feedback but does update the similarity graph based on past observation. This furnishes strong evidence for the usefulness
of active learning algorithms, even without human feedback. The NNCLR oracle consists in setting It = Jt equals to some
minibatch at time t, but to labels positive pairs in Gij only for nearest neighbors, i.e.
G(t)
ij = 1{zi∈N(zj,I)} ≜1{∥zi−zj∥=minj∈It∥zi−zk∥}.
We describe the corresponding active oracle in Algorithm 4.
Algorithm 4: Active Oracle with No Human Feedback as per [23]
NNCLR oracle:
Sampler: It = Jt is some minibatch,
Labeler: Gi,j = 1{zi∈N(zj;I)} where N(z; I) design the nearest neighbor of z in the batch I.
The New Rise of Active Learning. Recently, active learning has become a focus of the machine learning community
when training big models, as those models performance are known to depend on the order they process data [45], as well
as in the percentage of data of different type they ingests [46]. In particular, the best paper award at NeurIPS last year [44]
has suggested that the distance to the decision boundary could be leveraged smartly to reduce the number of data needed by
current AI algorithms to train state of the art models (as compared to the scaling law of [29]). We describe their sampling
oracle in Algorithm 5. Note that in the original paper, they query the exact labels of the selected points, while PAL only
needs to query pairwise comparison. In the meantime, [17] suggested using ensemble active learning, while [1] suggested a
model based uncertain predictions through gradient computation in deep learning models.
Algorithm 5: Active Oracle with Data Pruning as per [44]
Perform k-means clustering on Zt = fθt.
For each unlabeled points, compute cosine distance to its cluster center.
if Few examples have been labels then
It = Jt ←points near cluster centers,
else
It = Jt ←points far from cluster centers.
From Coarse to Fine-grained Query. While active learning usually assumes that the cost of answering any questions
is constant, in practice, some queries might be easier to answer than others. For example, if a child has never seen some
objects, such as a sophisticated designer chair, they might not easily provide pairwise comparison regarding those objects,
e.g. they would be puzzled by the designer chair, and would hesitate to say that this is a chair. Similarly, it might be easier for
human labelers to recognize attributes in an image, e.g. sandy fur, desert background, tufted ear, feline; rather than precise
species, such as “caracal”. This has been the basis for weakly supervised learning [18, 40]. It has also motivated some bandit
models, such as [13, 25]. More generally, it suggests that one could efﬁciently learn by ﬁrst querying weak, coarse-grained
information, before reﬁning queries to get precise, ﬁne-grained feedback. We illustrate this high-level idea with Algorithm 6.
Algorithm 6: Active Oracle with Hierarchical Taxonomy
Samplers: Your favorite active learning sampler.
if fθt has not formed strong opinions on clusters then
Labelers: Human feedback for coarse-grained information (e.g. click on all animals with fur...),
else
Labelers: Human feedback with ﬁne-grained information (e.g. click on ﬁshes that match a precise species).

B. Proofs
B.1. Proof of Theorem 1
B.1.1
VICReg Loss and Spectral Contrastive
This subsection will both identify the VICReg with the spectral contrastive one through their matrix formulation.
Let us begin by reformulating the invariance term in VICReg. For Z deﬁned in (1), it is generalized to multiple pairs
through
LVIC−INV =
X
i,j∈[N]
Gij ∥zi −zj∥2 =
X
i,j∈[N]
2Gij ∥zi∥2 −2Gij ⟨zi, zj⟩
=
X
i,j∈[N]
2Gij[ZZ⊤]ii −2Gij[ZZ⊤]ji =
X
i∈[N]
2[DZZ⊤]ii −2[GZZ⊤]ii
= 2 Tr
 (D −G)ZZ⊤
= 2 Tr
 Z⊤(D −G)Z

where D is the degree matrix deﬁned as a diagonal matrix, with A the number of augmented samples per original input
Dij = 1{i=j} ·
X
k∈[N]
Gik = A1{i=j}.
The variance-covariance term can be simpliﬁed by replacing the the Hinge loss for the variance by a squared norm [31], by
setting β = α = 1 and replacing A by N in D to regularize diagonal terms a bit more. Those simpliﬁcations lead to a more
principled regularization term that enforces orthogonality over the dataset of the different features learned by the network fθ
[11]. The consequent regularization reads
Z⊤Z/N −IK
2. As a consequence, VICReg can be understood as solving for
NLVIC ≈
Z⊤Z −NIN
2 + 2 Tr(Z⊤(NIN −G)Z).
For the spectral contrastive Loss, it is useful to incorporate negative pairs that are sampled for the same augmentations for
two different samples
D
Z(1)
i
, Z(1)
j
E
in the repulsive term. Moreover adding
Z(v)
i
 on both the positive part and the negative
part will not change much since −2x + x2 is minimized for x = 1. Those modiﬁcations lead to
LVIC2 = −2
X
i,j∈[N]
Gijz⊤
i zj +
X
i,j∈[N]
(z⊤
i zj)2 = −2
X
i,j∈[N]
Gij[ZZ⊤]ij +
X
i,j∈[N]
[ZZ⊤]2
ij
= −2 Tr(GZZ⊤) + Tr(ZZ⊤ZZ⊤) = Tr(ZZ⊤ZZ⊤−2GZZ⊤+ G2) −Tr(G2)
= Tr((ZZ⊤−G)2) −Tr(G2) =
ZZ⊤−G
2
F + cst.
The last term being a ﬁnite constant, it can be removed from the loss.
Indeed, one can relate both the spectral contrastive loss and VICReg, by remarking that
Z⊤Z −NIN
2 + 2 Tr(Z⊤(NIN −G)Z)
= Tr(ZZ⊤ZZ⊤−2NINZ⊤Z + N 2IN) + 2 Tr(Z⊤(NIN −G)Z)
= Tr(ZZ⊤ZZ⊤−2GZZ⊤) + N 3 = Tr((ZZ⊤−G)2) −G2) + N 3
=
ZZ⊤−G
2
F + cst.
Finally, the variance covariance term can be written as
ZZ⊤/N −I
2 =

X
i∈[N]
ziz⊤
i −I

2
= Tr

X
i,j∈[N]
zjz⊤
j ziz⊤
i −2
X
i∈[N]
ziz⊤
i + I


=
X
i,j∈[N]
(z⊤
j zi)2 −
X
i,j∈[N]
(z⊤
i zi + z⊤
j zj) + cst =
X
i,j∈[N]
R(zi, zj) + cst,
where R(a, b) = (a⊤b)⊤−∥a∥2 −∥b∥2.

B.1.2
The SimCLR Loss
SimCLR can be seen as a generalized linear model, where two variables A, B are observed and the probability observing B
knowing A is given by
pij = P(B = j | A = i) ∝exp

z⊤
i zj
∥zi∥∥zj∥

.
For simplicity, let us deﬁne ˜z = z/ ∥z∥. SimCLR tries to maximize the likelihood of (A, B) denoting random pairs coming
from the same augmentations based on the observation of the graph
Y
ij∈[N]
pGij
ij
= exp

X
ij∈[N]
Gij log
 
exp
 ˜z⊤
i ˜zj

P
k∈[N] exp(˜z⊤
i ˜zk)
!
.
The SimCLR loss is nothing but the inverse of the log likelihood.
LSimCLR = −
X
ij∈[N]
Gij log
 
exp
 ˜z⊤
i ˜zj

P
k∈[N] exp(˜z⊤
i ˜zk)
!
.
B.1.3
Barlow Twins
When λ = 1, which we will consider for simplicity, the BarlowTwins loss simpliﬁes as
LBT =
X
i
(1 −Cii)2 +
X
i̸=j
C2
ij = ∥C −Ik∥2
F .
Because cross-correlations are normalized cross-covariances, it is useful to introduce ˜Z the column normalized version of
Z. Formally written in normalized matrix with the Hadamard product notation as
˜Zij =
zij
qP
k z2
kj
=
zij
[(Z ⊗Z)1]1/2
j
i.e.
˜Z = Z diag(Z⊗21)−1/2
The way the cross-correlation is built can be generalized to multiple positive pairs as
Cij =
P
kl Gklzkizlj
pP
k z2
ki
qP
l z2
lj
=
X
kl
Gkl˜zki˜zlj = [ ˜Z⊤G ˜Z]ij.
As a consequence, the BarlowTwins loss can be rewritten with the sole use of G as
LBT =
 ˜Z⊤GZ −IK

2
F .
B.2. The SSL Losses for Supervised Learning
This subsection is devoted to the proof of Theorem 2.
B.2.1
Recovery Lemma
The backbone of Theorem 2 is following Lemma.
Lemma 1 (Equivalence between Y and G). Given any supervised classiﬁcation similarity matrix G = Y Y ⊤(6), one can
recover the corresponding one-hot label encoding Y , up to an orthogonal transformation R, as
∃R ∈O(C),
s.t.
Y = P
√
DR,
where P DP T is the eigenvalue decomposition of the adjacency matrix G(Y ). Moreover the rotation R is easily recovered
by specifying the labels of C samples associated with each of the C different classes.

Proof. Lemma 1 follows from the fact that G = Y Y ⊤so that Y is a square root of G, and that any two square roots of a
matrix are isometric. In particular, if the SVD of Y is written as
Y = P
√
DR,
P ∈O(N), R ∈O(C), D =
D1
0
∈RN×C, D1 = diag(σ2
1, · · · σ2
C),
the decomposition G = PDP ⊤is an eigenvalue decomposition of G. The part P
√
D is unique up to the application of a
rotation on the right, which could be absorbed in R.
In order to recover Y from G, notice that up to a permutation of lines and columns, G has a block diagonal structure
where each block corresponds to one label. If each one label is given to each block, this allows to retrieve exactly Y hence
to identify R afterwards by solving for R = (P
√
mD)−1Y .
While lemma 1 describes the classiﬁcation case, in the generic case, if the y are categorical, yet the loss ℓ(y, z) is not the
zero-one loss, it is natural to deﬁne the similarity matrix as
G ≜(−ℓ(yi, yj))i,j∈[N] ∈RC×C.
(12)
For example, yi could be rankings modeled with yi ∈Sm where m! = C, i.e. m = Γ−1(C) −1, and ℓcould be the Kendall
loss. In this setting,
G = Y LY ,
where
L ≜(−ℓ(y, z))y,z∈[C] ∈RC×C,
and Y is retrieved through Y = P
√
DRL1/2, where P DP ⊤is the eigenvalue decomposition of G, and R ∈RC×C is
an unknown rotation matrix, that might be identiﬁed by specifying at most C labels associated with each of the C different
classes, but might be identiﬁed with a smaller number of samples if ℓhas a strong structure implying that L is low-rank (see
Eq. (11) in [38]). Indeed, the fact that compared to (6), the graph (12) could be much lower rank, could lead to more efﬁcient
algorithm to image it in the active learning framework. In essence, it would better leverage the structure encoded by the loss
ℓ.
Finally, in the regression setting, one can choose Gij = −y⊤
i yj.
B.2.2
The VICReg Loss
The VICReg loss is characterized as
LVIC−2 =
ZZ⊤−G
2
F + cst.
So, it is minimized for Z being a square root of the matrix G. This is possible when the rank of G which is at most C since
G = Y Y ⊤is less than the rank of Z which is K. In this setting, since Y and Z are two square roots of G, we get
∃R ∈O(C, K),
Z = Y R,
where we deﬁne the rotation O(C, K) as
O(C, K) =

R ∈RC×K  RR⊤= IC
	
.
(13)
B.2.3
The SimCLR Loss
The probabilistic interpretation of SimCLR states that the SimCLR losses tries to maximize the likelihood of the events
∪ij∈[N] {Gij = 1} ∩{Y = i & X = j} ,
which translate as a loss in the minimization of
LSimCLR = −
X
ij∈[N]
Gij log
 
exp
 ˜z⊤
i ˜zj

P
k∈[N] exp(˜z⊤
i ˜zk)
!
.
This is the cross entropy between Gij and pij deﬁned in the proof of the characterization of SimCLR. If the minimization
with respect to pij was unconstrained, then one should match pij ∝Gij. Yet, the form of pij ∈[exp(−1), exp(1)] constraints
it to go for a slightly different solution.

Remark that for two ˜zi, ˜zj whose index i and j belongs to different clusters deﬁned by the graph G, the loss is a increasing
function of the quantity exp(˜zi ˜zj). By symmetry, we deduce that all the ˜zi ˜zj = cos(zi, zj) should be one for all (i, j) such
that Gij = 1. On the other hand, the loss is a decreasing function of the exp(˜z⊤
i ˜zj) when Gij = 1. When the number of
sample per class is constant, we deduce by symmetry that the different anchors for the different classes should be put at the
extremity of the simplex with C vertices centered at the origin and rotate with an arbitrary matrix R ∈O(C −1), which
allow to recover the different classes (without their explicit labels if not provided). When the different class have different
number of samples Ni with P
i∈[C] Ni = N, and their anchor in the output space is c ∈RK, we are trying to minimize
X
j∈[C]
Nj log

X
i∈[C]
Ni exp(c⊤
i cj)

,
(14)
which will deform the simplex to have bigger angles between classes that are highly represented. For example, when N1 =
N2 ≈N/2, we will have c1 ≈−c2 while the other anchors are orthogonal to one another and to c1. Denoting M ∈RC the
matrix that maps the anchor of the class i for one solution of (14) to the i-th element of the canonical basis ei as viM = ei,
we get that the solution
Z = DY RM −1,
with
D ∈diag(RN
+); R ∈O(K, C).
The fact that Z is invariant by scaling each vector z reminds us of implementation of the cross-entropy, where to avoid
divergence to inﬁnity (since the sigmoid is optimized at inﬁnity) one has to normalize the solution. The SimCLR loss is
actually built on the same generalized linear model as the cross-entropy, and one can roughly think of SimCLR as the SSL
version of the cross-entropy.
B.2.4
BarlowTwins
To minimize the BarlowTwins loss
LBT =
 ˜Z⊤G ˜Z −IK

2
F ,
we want ˜Z to be a square root of the inverse of G. To be more precise, introduce the eigenvalue decomposition of G
as G = P SP ⊤where P ∈RN×C and S ∈RC×C since G is at most of rank C. The minimizer of BarlowTwins is
˜Z = [P S−1/2, 0N×(K−C)]. Since ˜Z is the column normalized version of Z, Z can be reconstructed for any diagonal
matrix D ∈diag(RK
+ ) as Z = ˜ZD. Incorporating [S−1, 0] in D, we get that the minimizer of the BarlowTwins loss are
exactly the matrices Z = P S1/2[D, 0K−C] for D ∈diag RC
+. Moreover, since both P S1/2 and Y are square root of G,
we know that the exists a rotation matrix R ∈O(K) such that P S1/2 = Y R. All together, we get that the minimizer of the
BarlowTwins loss are exactly the
Z = Y RD,
for
R ∈OC,K, D ∈diag(RC
+)
The fact that BarlowTwins do not care about the amplitude of the solution Z reminds us of discriminant analysis that learns
classiﬁers by optimizing ratio and angles.
B.3. Bayes optimum
For completeness, we now state a Bayes optimum proposition regarding the VICReg loss of the paper.
Proposition 1 (Bayes optimum). When K ≥C and there is no context, i.e. xi = x0 for all i ∈[N], and yi are sampled
according to a noisy distribution (y | x = x0), the naive study of the VICReg Bayes optimum is meaningless, since
arg min
z∈RK LVIC−2(


z
...
z

; G) =

z ∈RK  ∥z∥= 1
	
.
Yet, if one free the variable Z ∈RN×K, we have
arg min
Z∈RN×K LVIC−2(Z; G) = N 1/2 ·
n
(P(Y = i)1/2ei)i∈[C] · R
 R ∈O(C, K)
o
,
where (ei)i∈[K] is the canonical basis of RK.

Proof. For the ﬁrst part of the proof, remark that the invariance term in VICReg will be zero for any z, so VICReg loss is
minimized for any vector that minimized the variance-covariance term
zz⊤−I
2, which is done for any unit vector.
For the second part, remark that G = Y Y ⊤has C connected components, that are all full cliques, i.e. the adjacency is
ﬁlled with one. As a consequence, the eigenvectors of G associated with non-zeros elements are exactly the (1{}yi = y)i∈[N]
for y ∈[C], and the corresponding eigenvalues are Ny where Ny = P
i∈[N] 1{yi=y} = N P(Y = i) are the number
of element in the class i ∈[C]. As a consequence, a square root of G is N 1/2(P(Y = i)1/2δij)i∈[C],j∈[K], hence the
proposition following the fact that all the square root of G are isomorphic.
C. Additional experimental details
C.1. Essential Code
SSL Graph
1 G = torch.zeros(N * V, N * V)
#
X in Rˆ{Np x D}, V views
2 i = torch.arange(0, N * V).repeat_interleave(V - 1)
# row indices
3 j = (i + torch.arange(1, V).repeat(N * V) * N).remainder(p * V) # column indices
4 G[i,j] = 1
# unweighted graph
Sup Graph
1 Y = torch.nn.functional.one_hot(labels, num_classes=num_classes).float()
2 G = Y @ Y.T
VICReg.
1 C = torch.cov(Z.t())
# Z in Rˆ{N x K}
2 reg_loss = torch.nn.functional.mse_loss(C, torch.eye(K))
3 reg_loss *= out_dim ** 2
# correct for mean vs sum
4 i,j = G.nonzero(as_tuple=True)
5 inv_loss = torch.nn.functional.mse_loss(Z[i], Z[j])
# pairwise L2 weighted by G_{i,j}
6 inv_loss *= out_dim
7 loss = beta * inv_loss + reg_loss
SimCLR
1 Z_renorm = torch.nn.functional.normalize(Z, dim=1)
# Z \in \mathbb{R}ˆ{N \times K}
2 cosim = Z_renorm @ Z_renorm.t() / tau
# N x N matrix, tau is the temperature
3 mask = 1 - torch.eye(N, N, device=Z.device, dtype=Z.dtype)
4 loss = (G * (torch.logsumexp(cosim*mask, dim=1, keepdim=True) - cosim)).mean()
SCL
1 Z = torch.nn.functional.normalize(Z, dim=1)
2 loss = torch.nn.functional.mse_loss(G, Z@Z.T)
C.2. Controlled experiments
C.2.1
Setup
The train and test set of Figure 3 is shown on Fig. 5. The similarity graphs corresponding to the different snapshots on Fig. 3
are shown on Fig. 6. In all the experiments, we consider K = C + 1 = 5.
Training data
Testing data
Figure 5. Setup for the controlled experiments of Fig. 3. The dataset is made of four concentric circles that corresponds to four different
classes represented by different colors. The training dataset is made of one hundred random points, with some noise.

Figure 6. Graphs G corresponding to the different snapshot taken on Fig. 3. Grey indicates zeros, white indicates negative observations,
and black means positive ones. The main strength of the active strategy in Algorithm 3 is that, by leveraging the underlying structure of
the graph, is able to deduce much faster the full graph G than the naive passive implementation that only asks for random query pairs.
Basically a positive observation is turned into many negative observations.
C.2.2
Contrastive vs. Non-Contrastive
Intuitively, it is useful to distinguish more explicitly between positive, negative and unknown relations, which we test on
Fig. 7. To do so, the graph G is modiﬁed to encode semantically similar elements as positive edges, dissimilar ones as
negative edges, while unknown relationships are going to be represented by zeros.
Gij =



1
if xi ∼xj has been observed,
−1
if xi ̸∼xj has been observed,
0
otherwise.
(15)
One might wonder if this really improves performance. The comparison is the object of Fig. 7
0
200
400
600
800
Number of queries
0.00
0.25
0.50
0.75
Test error
contrastive
non-contrastive
Figure 7. Comparison of contrastive (Gij ∈{−1, 0, 1}) and non-contrastive (Gij ∈{0, 1}) variation of VICReg with N = 300. The
setting is the same as Fig. 3 with Algorithm 3. We remark the usefulness to distinguish between negative pairs and unknown pairs, although
some instability issues seem to appear when few entries are known for the contrastive method.
C.2.3
The Beneﬁts of Incorporating Known Labels
A major motivation of this paper is to be able to add prior information on sample relationships in SSL methods, and more
in particular, to have a simple way to leverage known labels. Let us denote by ˆY ∈RN×D the one-hot matrix (yi)i∈[N]
where yi is the one-hot vector of the label yi, such that if yi is unknown yi = 0. The knowledge of some coefﬁcients of the
real Y , leads to the knowledge of a few coefﬁcient of G(sup) = Y Y ⊤, those could be added to the SSL graph to add useful
connection deduced from the labels, leading to
G = (1 −α) · G(ssl) + α · ˆY ˆY ⊤,
where α ∈[0, 1] is a mixing coefﬁcient stating how much the supervised information should weigh in the similarity matrix.
Naively, we could set α = 1/2, yet when only few labels are given this would destabilize the spectral decomposition of G
too much, and we observe on Figure 4 that a small mixing coefﬁcient is better. An explanation could be that the relations
encoded by SSL are quite local and subtle, while the connections suggested by supervised learning are quite global and brutal
on it suggested to fold the input space, hence need to be dampened when mixing the SSL and supervised graphs.

0
100
200
300
Number of corrupted labels
0.0
0.2
0.4
0.6
Test error
Figure 8. Study of the effect of labeling noise. The setup is the same as Fig. 3 yet with N = 300 points. We consider having full access
to Y thus to G = Y Y ⊤yet we assume that a certain number of labels yi are corrupted. We see that the algorithm is somewhat robust to
noise.
C.2.4
Robustness to noise
As mentioned in the last part of the paper, depending on the algorithm used, the effect of noise in queries answers might lead
to dramatic performance loss. In the main text, we were careful to describe algorithms that are robust to noise. The effect
of noise in the labels for Algorithm 3 is studied in Fig. 8. Because of its structure, noise in the query for Algorithm 3 is
equivalent to noise in the label y. This explains the setup of the ﬁgure.
C.2.5
The Importance to Recover Connected Components
An interesting experiments is provided by Fig. 9, which compares the test error and the number of connected components of
the graph G as a function of the number of missing entries of G = G(sup). In our synthetic experiment, G(sup) has four
connected components corresponding to the four classes in the dataset, e.g. Fig. 2. Typically, based on transitivity of the
similarity relation ∼, one can hope to only need O(1/N) = O(NC/N 2) queries, i.e. reconstructed entries of G, to have
a good sense of the global G, hence to learn fθ. Moreover, on Fig. 9, the test error can be relatively well-predicted by the
number of connected components of the graph G. This suggests creative ways to design active learning strategies based on
search to optimize the number of connected components of G. However, leveraging transitivity of the similarity relationship
to ﬁll G efﬁciently might be limited when queries answers are noisy, although literature on error correcting codes might be
useful [47, 19]. Moreover, the binary (and transitive) nature of similarity can be questioned when SSL sometimes uses DA
that provides iconoclast unrealistic images, and one might prefer to assign similarity scores. Problems that do not occur with
the transitivity agnostic Algorithm 3.
0.6
0.8
1.0
Percentage missing entries
0.0
0.2
0.4
0.6
Test error
Downstream error
Connected components
0
20
40
60
Num. Con. Comp.
Figure 9. Comparison between the test error and number of connected components in the graph G as a function of the percentage of missing
entries in G. The test error is reported as in Fig. 3, but it is reported as a function of missing entries of the supervised learning graph G(sup).
The standard deviation for the red curve is not represented here as the number of connected components is highly concentrated around its
mean.
C.2.6
Mixture of Gaussian
One can question if the ﬁndings presented so far are speciﬁc to the concentric circles datasets. In order to assert the validity
of those ﬁndings, we consider a second dataset, made of mixture of Gaussian, formally
X = Y + σE,
where
Eij ∼N(0, 1),

0
200
400
600
800
Number of queries
0.0
0.2
0.4
Test error
active
passive
0.6
0.8
1.0
Percentage missing entries
0.0
0.2
0.4
Test error
Downstream error
Connected components
0
200
400
600
800
Number of queries
0.0
0.2
0.4
Test error
contrastive
non-contrastive
0
50
100
150
200
Number of labels
0.0
0.2
0.4
0.6
Test error
α = 0.5
α = 10−3
0
100
200
300
Number of corrupted labels
0.05
0.10
0.15
0.20
Test error
Figure 10. Same ﬁgures as before with a mixture of Gaussians dataset. The mixture dataset has the particularity that the downstream task
can be solved with any orthogonal basis of RC. When no queries has been made, G = IN, and the spectral decomposition of this graph
will lead to a representation that can solve the downstream task, explaining why when no queries have been made, or when all the entries
of G are removed, the downstream task can be solved.
given a label y ∈[C], x is generated according to N(ey, σIC). The results are reported on Fig. 10 with σ = .3.
C.3. Real-world experiment
While it is hard to control all the factors that come into play when training a neural network on real data, our experiments
suggested that what we have seen in controlled experiments transfer to real-world problems. In particular, we consider the
CIFAR-10 dataset, with a resnet 18 architecture. A ﬁrst stage was representation learning, where we used the VICReg loss to
learn representation with the CIFAR-10 training set. In particular, we removed the classiﬁer head of the resnet and replaced
it with two fully connected layers with batch norms. The number of output dimensions was set to K = 16, and the number
of hidden neurons was set to 4K. After the representation was learned, we replaced the classiﬁer head by a linear layer with
K = C output dimension and ﬁt this last layer on the CIFAR-10 training set. The resulting network was then tested on the
CIFAR-10 testing set. Regarding hyperparameters (network, DA, optimizer), we ﬁxed them in accordance with tutorial online
(in particular the pytorch-lightning tutorial) in order to achieve high performance results on CIFAR with SSL. In our ﬁrst
experiments, we stopped after two epochs of training for pretraining (since the output dimension is quite small, there is no
need to go really far away in training), and twenty epochs downstream. The pretraining task consisted in all the training data of
CIFAR-10 tackle, We found that the representation learned with SSL was achieving 28 % accuracy on CIFAR-10 with linear
probing, while the representation learned directly with the supervised graph was achieving 63 % accuracy. In the meanwhile,
training a resnet with classiﬁer head to be made of 60 hidden neurons and 10 output dimensions with the ground truth labels
and the mean-square error in the exact same setting leads to a performance of 63% too. In other terms, in these simple

experiments, one can use the VICReg technique we derived here, or the MSE loss and get the same performance. Training
for tens epochs for the upstream task (the minimization of the VICReg loss), and one hundred for the downstream one (the
linear head ﬁtting), we improved performance to 62% for SSL and 66% for the supervised learning graph. Furthermore, we
did not perform extensive hyperparameter tuning, which suggests that the supervised learning performance could be even
more competitive, since we took parameters that are known to be good for the self-supervised learning techniques. All the
code is available to reproduce our experiments.

