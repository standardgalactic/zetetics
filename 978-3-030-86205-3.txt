Boris Konev
Giles Reger (Eds.)
 123
LNAI 12941
13th International Symposium, FroCoS 2021
Birmingham, UK, September 8–10, 2021
Proceedings
Frontiers of 
Combining Systems

Lecture Notes in Artiﬁcial Intelligence
12941
Subseries of Lecture Notes in Computer Science
Series Editors
Randy Goebel
University of Alberta, Edmonton, Canada
Yuzuru Tanaka
Hokkaido University, Sapporo, Japan
Wolfgang Wahlster
DFKI and Saarland University, Saarbrücken, Germany
Founding Editor
Jörg Siekmann
DFKI and Saarland University, Saarbrücken, Germany

More information about this subseries at http://www.springer.com/series/1244

Boris Konev
• Giles Reger (Eds.)
Frontiers of
Combining Systems
13th International Symposium, FroCoS 2021
Birmingham, UK, September 8–10, 2021
Proceedings
123

Editors
Boris Konev
University of Liverpool
Liverpool, UK
Giles Reger
The University of Manchester
Manchester, UK
ISSN 0302-9743
ISSN 1611-3349
(electronic)
Lecture Notes in Artiﬁcial Intelligence
ISBN 978-3-030-86204-6
ISBN 978-3-030-86205-3
(eBook)
https://doi.org/10.1007/978-3-030-86205-3
LNCS Sublibrary: SL7 – Artiﬁcial Intelligence
© Springer Nature Switzerland AG 2021
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the
material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now
known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this book are
believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors
give a warranty, expressed or implied, with respect to the material contained herein or for any errors or
omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in
published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
These proceedings contain the papers selected for presentation at the 13th International
Symposium on Frontiers of Combining Systems (FroCoS 2021). The symposium was
held during September 8–10, 2021 in Birmingham, UK, at Birmingham University. It
was co-located with the 30th International Conference on Automated Reasoning with
Analytic Tableaux and Related Methods (TABLEAUX 2021).
FroCoS is the main international event for research on the development of tech-
niques and methods for the combination and integration of formal systems, their
modularization and analysis. Previous FroCoS meetings were organized in Munich
(Germany, 1996), Amsterdam (The Netherlands, 1998), Nancy (France, 2000), Santa
Margherita Ligure (Italy, 2002), Cork (Ireland, 2004, as part of the International Joint
Conference on Automated Reasoning, IJCAR), Vienna (Austria, 2005), Seattle (USA,
2006, as part of IJCAR), Liverpool (UK, 2007, co-located with the International
Workshop on First-Order Theorem Proving, FTP), Sydney (Australia, 2008, as part of
IJCAR), Trento (Italy, 2009), Edinburgh (UK, 2010, as part of IJCAR), Saarbrücken
(Germany, 2011), Manchester (UK, 2012, as part of IJCAR), Nancy (France, 2013,
co-located with TABLEAUX), Vienna (Austria, 2014, as part of IJCAR), Wrocław
(Poland, 2015, co-located with TABLEAUX), Coimbra (Portugal, 2016, as part of
IJCAR), Brasilia (Brazil, 2017, co-located with TABLEAUX), Oxford (UK, 2018, as
part of IJCAR), London (UK 2019, co-located with TABLEAUX) and Paris (France
2020, as part of IJCAR).
FroCoS 2021 received 23 high-quality paper submissions, which were evaluated by
the Program Committee on the basis of their signiﬁcance, novelty, technical soundness,
and appropriateness for the FroCoS audience. Reviewing was single-blind and each
paper was subject to at least three reviews, followed by a discussion within the Program
Committee. In the end, 16 papers were selected for presentation at the symposium and
publication. We have grouped them in this volume according to the following topic
classiﬁcation: (1) calculi and uniﬁcation, (2) description logics, (3) interactive theorem
proving, (4) machine learning, (5) satisﬁability modulo theories, and (6) veriﬁcation.
We were delighted to have four outstanding invited speakers.
– Michael Benedikt, University of Oxford (joint with TABLEAUX 2021)
– Vijay Ganesh, University of Waterloo
– Chantal Keller, Université Paris-Sud
– Renate Schmidt, University of Manchester (joint with TABLEAUX 2021)
We would like to thank all the people who contributed to making FroCoS 2021 a
success. In particular, we thank the invited speakers for their inspiring talks, the authors
for providing their high-quality contributions, and the Program Committee members
and the external reviewers for their careful, competent reviewing and discussion of the
submissions on quite a tight schedule. We extend our thanks to the University of
Birmingham for hosting FroCoS, especially to Anupam Das.

We gratefully acknowledge ﬁnancial support from Springer and the University of
Birmingham. Finally, we are grateful to EasyChair for allowing us to use their excellent
conference management system.
September 2021
Boris Konev
Giles Reger
vi
Preface

Organization
Program Committee Chairs
Boris Konev
University of Liverpool, UK
Giles Reger
University of Manchester, UK
Steering Committee
Franz Baader (chair)
TU Dresden, Germany
Clare Dixon
University of Manchester, UK
Marcelo Finger
University of Sao Paulo, Brazil
Andreas Herzig
IRIT, Université Paul Sabatier, France
Carsten Lutz
Universität Bremen, Germany
Andrei Popescu
University of Shefﬁeld, UK
Silvio Ranise
University of Trento and Fondazione Bruno Kessler,
Italy
Program Committee
Takahito Aoto
Niigata University, Japan
Carlos Areces
Universidad Nacional de Córdoba, Argentina
Alessandro Artale
Free University of Bozen-Bolzano, Italy
Franz Baader
TU Dresden, Germany
Peter Baumgartner
CSIRO, Australia
Christoph Benzmüller
Freie Universität Berlin, Germany
Jasmin Blanchette
Vrije Universiteit Amsterdam, The Netherlands
Clare Dixon
University of Manchester, UK
Pascal Fontaine
Université de Liège, Belgium
Didier Galmiche
LORIA, Université de Lorraine, France
Silvio Ghilardi
Università degli Studi di Milano, Italy
Jürgen Giesl
RWTH Aachen University, Germany
Andreas Herzig
IRIT, Université Paul Sabatier, France
Jean Christoph Jung
Universität Bremen, Germany
Roman Kontchakov
Birkbeck, University of London, UK
Aina Niemetz
Stanford University, USA
Andrei Popescu
University of Shefﬁeld, UK
Silvio Ranise
University of Trento and Fondazione Bruno Kessler,
Italy
Andrew Reynolds
University of Iowa, USA
Christophe Ringeissen
LORIA, Université de Lorraine, France
Philipp Ruemmer
Uppsala University, Sweden
Uli Sattler
University of Manchester, UK

Roberto Sebastiani
University of Trento, Italy
Viorica
Sofronie-Stokkermans
University of Koblenz-Landau, Germany
Martin Suda
Czech Technical University in Prague, Czech Republic
Christoph Weidenbach
Max Planck Institute for Informatics, Germany
Additional Reviewers
Alessandro Gianola
Alexander Bentkamp
Andrea Mazzullo
Chencheng Liang
Filip Bártek
Florian Rabe
Haniel Barbosa
Joseph Scott
Manfred Schmidt-Schauss
Martin Bromberger
Petar Vukmirović
Santiago Escobar
Yannick Chevalier
viii
Organization

Abstracts of Invited Talk

The Strange Career of Interpolation
and Deﬁnability
Michael Benedikt
University of Oxford
michael.benedikt@gmail.com
Beth Deﬁnability, Craig Interpolation, and their variants have long been seen as an
important topic in commputational logic, telling us something about logical simpliﬁ-
cation. But the rationale for their signiﬁcance has varied over time, and it is not even
clear whether they should be best seen as a property of a logic or of a proof system. In
this talk I will look back at the somewhat twisty evolution of the topic, highlighting
some issues that have been underexplored. I'll also present some current work (joint
with Pierre Pradic) aimed at ﬁlling some of the gaps. No background on interpolation
or deﬁnability will be assumed in the talk.

On the Unreasonable Effectiveness of SAT
Solvers
Vijay Ganesh
University of Waterloo
vganesh@uwaterloo.ca
Over the last two decades, software engineering (broadly construed to include testing,
analysis, synthesis, veriﬁcation, and security) has witnessed a silent revolution in the
form of Boolean SAT and SMT solvers. These solvers are now integral to many
testing, analysis, synthesis, and veriﬁcation approaches. This is largely due to a dra-
matic improvement in the scalability of these solvers vis-a-vis large real-world for-
mulas. What is surprising is that the Boolean satisﬁability problem is NP-complete,
believed to be intractable, and yet these solvers easily solve industrial instances con-
taining millions of variables and clauses in them. How can that be?
In my talk, I will address this question of why SAT solvers are so efﬁcient through
the lens of machine learning (ML) as well as ideas from (parameterized) proof com-
plexity. While the focus of my talk is almost entirely empirical, I will show how we can
leverage theoretical ideas to not only deepen our understanding but also to build better
SAT solvers. I will argue that SAT solvers are best viewed as proof systems, composed
of two kinds of sub-routines, ones that implement proof rules and others that are
prediction engines that optimize some metric correlated with solver running time.
These prediction engines can be built using ML techniques, whose aim is to structure
solver proofs in an optimal way. Thus, two major paradigms of AI, namely machine
learning and logical deduction, are brought together in a principled way in order to
design efﬁcient SAT solvers. A result of my research is the MapleSAT solver that has
been the winner of several recent international SAT competitions and is widely used in
industry and academia.

General Automation in Coq Through Modular
Transformations and SMT Solving
Chantal Keller
Université Paris-Sud
Chantal.Keller@lri.f
The subject of the SMTCoq project is to signiﬁcantly enhance automation in the Coq
proof assistant. At the heart of SMTCoq is a Coq plugin that offers a way to use
automatic provers with the same degree of trust as Coq itself. On top of it, we deﬁne a
framework called Sniper to progressively encode Coq’s logic into ﬁrst-order logic,
through modular and ﬁne-grained logical transformations that can be composed. Our
objective is to obtain automatic while expressive tactics for Coq.
In this talk, I will concisely introduce the communication between Coq and external
provers, before presenting the new framework of logical transformations. I will report
on work in progress of examples of transformations in this framework.
This is a collaboration with Valentin Blot, Louise Dubois de Prisque, and Pierre
Vial.e

Forgetting and Subontology Generation
for the Medical Ontology SNOMED CT
Renate A. Schmidt
Department of Computer Science, The University of Manchester, UK
Renate.Schmidt@manchester.ac.uk
In this talk I discuss efforts in developing systems to provide automated support for
content extraction for the medical ontology SNOMED CT. SNOMED CT is a large
knowledge base of standardised, precise deﬁnitions of clinical terms and medical codes
for use in electronic health records to allow consistent data capture at the point of care
and meaningful processing of data across health care sectors. Since SNOMED CT is so
large, it has long been an aim to have the capability to compute smaller extracts of the
ontology that are self-contained but restricted to a narrow focus, for example, kidney
diseases, dentistry or vocabulary relevant for nursing. Such subontologies would make
it easier to reuse and share content, to assist with new ontology creation, quality
assurance, ontology update, and debugging. In addition, reasoning tasks such as
querying and classiﬁcation take less time to execute over a smaller extract than over the
original ontology.
The aim of our research is to compute extracts that are semantically complete in
that they faithfully capture the knowledge in an ontology about a user-speciﬁed focus
signature. This is a challenging problem, because the knowledge of an ontology is not
only given by the explicitly stated axioms in the ontology but also all implicit
knowledge that can be inferred from these axioms. Forgetting creates a compact rep-
resentation of the implicit knowledge of an ontology over speciﬁed focus concepts and
relations by performing inferences on the non-focus (forgetting) signature. A number of
PhD projects in our group have developed a series of forgetting tools and adaptations
for use in applications such as logical difference computation and abduction in the
context of description logic-based ontologies. These tools provided the basis for a
series of industry projects in which we applied and further developed these for use
cases of the medical ontology SNOMED CT. A workﬂow of different modularisation
and forgetting methods was devised and thoroughly evaluated. With this workﬂow, we
managed to signiﬁcantly improve the performance and success rates of our tools and
provide a feasible way to compute faithful extracts of SNOMED CT.
Building on these experiences, in a current joint project with SNOMED Intl., we
have developed a new bespoke approach and prototype for computing subontologies of
SNOMED CT. This approach is deﬁnition, driven and returns concise encodings of
descriptions of the speciﬁed focus concepts in a normal form according to modelling
guidelines of SNOMED Intl. These can be efﬁciently computed and are signiﬁcantly
smaller than both forgetting solutions and subontologies computed by modularisation
methods.
The talk will give an overview of this research spanning several years, focussing on
key ideas, ﬁndings, experiences, and practical challenges encountered.

Contents
Calculi and Unification
A Datalog Hammer for Supervisor Verification Conditions Modulo Simple
Linear Arithmetic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
Martin Bromberger, Irina Dragoste, Rasha Faqeh, Christof Fetzer,
Markus Krötzsch, and Christoph Weidenbach
Non-disjoint Combined Unification and Closure by
Equational Paramodulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
Serdar Erbatur, Andrew M. Marshall, and Christophe Ringeissen
Symbol Elimination and Applications to Parametric Entailment Problems. . . .
43
Dennis Peuter and Viorica Sofronie-Stokkermans
On the Copy Complexity of Width 3 Horn Constraint Systems. . . . . . . . . . .
63
K. Subramani, P. Wojciechowski, and Alvaro Velasquez
Description Logics
Restricted Unification in the DL FL0 . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
Franz Baader, Oliver Fernández Gil, and Maryam Rostamigiv
Combining Event Calculus and Description Logic Reasoning
via Logic Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
98
Peter Baumgartner
Semantic Forgetting in Expressive Description Logics . . . . . . . . . . . . . . . . .
118
Mostafa Sakr and Renate A. Schmidt
Interactive Theorem Proving
Improving Automation for Higher-Order Proof Steps. . . . . . . . . . . . . . . . . .
139
Antoine Defourné
JEFL: Joint Embedding of Formal Proof Libraries. . . . . . . . . . . . . . . . . . . .
154
Qingxiang Wang and Cezary Kaliszyk
Machine Learning
Fast and Slow Enigmas and Parental Guidance . . . . . . . . . . . . . . . . . . . . . .
173
Zarathustra A. Goertzel, Karel Chvalovský, Jan Jakubův,
Miroslav Olšák, and Josef Urban

Vampire with a Brain Is a Good ITP Hammer . . . . . . . . . . . . . . . . . . . . . .
192
Martin Suda
Satisfiability Modulo Theories
Optimization Modulo Non-linear Arithmetic via Incremental Linearization . . .
213
Filippo Bigarella, Alessandro Cimatti, Alberto Griggio, Ahmed Irfan,
Martin Jonáš, Marco Roveri, Roberto Sebastiani, and Patrick Trentin
Quantifier Simplification by Unification in SMT. . . . . . . . . . . . . . . . . . . . .
232
Pascal Fontaine and Hans-Jörg Schurr
Verification
Algorithmic Problems in the Symbolic Approach to the Verification
of Automatically Synthesized Cryptosystems . . . . . . . . . . . . . . . . . . . . . . .
253
Hai Lin, Christopher Lynch, Andrew M. Marshall,
Catherine A. Meadows, Paliath Narendran, Veena Ravishankar,
and Brandon Rozek
Formal Analysis of Symbolic Authenticity . . . . . . . . . . . . . . . . . . . . . . . . .
271
Hai Lin and Christopher Lynch
Formal Verification of a Java Component Using the
RESOLVE Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
287
Laine Rumreich and Paolo A. G. Sivilotti
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
307
xvi
Contents

Calculi and Uniﬁcation

A Datalog Hammer for Supervisor
Veriﬁcation Conditions Modulo Simple
Linear Arithmetic
Martin Bromberger1(B), Irina Dragoste2, Rasha Faqeh2, Christof Fetzer2,
Markus Kr¨otzsch2, and Christoph Weidenbach1
1 Max Planck Institute for Informatics, Saarland Informatics Campus,
Saarbr¨ucken, Germany
{mbromber,weidenb}@mpi-inf.mpg.de
2 TU Dresden, Dresden, Germany
Abstract. The Bernays-Sch¨onﬁnkel ﬁrst-order logic fragment over sim-
ple linear real arithmetic constraints BS(SLR) is known to be decidable.
We prove that BS(SLR) clause sets with both universally and existen-
tially quantiﬁed veriﬁcation conditions (conjectures) can be translated
into BS(SLR) clause sets over a ﬁnite set of ﬁrst-order constants. For the
Horn case, we provide a Datalog hammer preserving validity and satisﬁa-
bility. A toolchain from the BS(LRA) prover SPASS-SPL to the Datalog
reasoner VLog establishes an eﬀective way of deciding veriﬁcation con-
ditions in the Horn fragment. This is exempliﬁed by the veriﬁcation of
supervisor code for a lane change assistant in a car and of an electronic
control unit for a supercharged combustion engine.
1
Introduction
Modern dynamic dependable systems (e.g., autonomous driving) continuously
update software components to ﬁx bugs and to introduce new features. However,
the safety requirement of such systems demands software to be safety certiﬁed
before it can be used, which is typically a lengthy process that hinders the dynamic
update of software. We adapt the continuous certiﬁcation approach [15] of variants
of safety critical software components using a supervisor that guarantees impor-
tant aspects through challenging, see Fig. 1. Speciﬁcally, multiple processing units
run in parallel – certiﬁed and updated not-certiﬁed variants that produce output
as suggestions and explications. The supervisor compares the behavior of variants
and analyses their explications. The supervisor itself consists of a rather small
set of rules that can be automatically veriﬁed and run by a reasoner. The rea-
soner helps the supervisor to check if the output of an updated variant is in agree-
ment with the output of a respective certiﬁed variant. The absence of discrepancy
between the two variants for a long-enough period of running both variants in par-
allel allows to dynamically certify it as a safe software variant.
While supervisor safety conditions formalized as existentially quantiﬁed prop-
erties can often already be automatically veriﬁed, conjectures about invariants
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 3–24, 2021.
https://doi.org/10.1007/978-3-030-86205-3_1

4
M. Bromberger et al.
Suggest 
Actions 
& provide
Explications
s
n
oit
a
v
r
e
s
b
O
 Execute Action  
Raw Data
Environment
Sensors
Processing 
units
P1
...
Supervisor
Reasoner
Actuators
A1
Am
...
...
Request 
Action 
Pn
Facts + Rules
New Facts
Fig. 1. The supervisor architecture.
formalized as universally quantiﬁed properties are a further challenge. In this
paper we show that supervisor safety conditions and invariants can be automat-
ically proven by a Datalog hammer. Analogous to the Sledgehammer project [7]
of Isabelle [30] translating higher-order logic conjectures to ﬁrst-order logic (mod-
ulo theories) conjectures, our Datalog hammer translates ﬁrst-order Horn logic
modulo arithmetic conjectures into pure Datalog programs, equivalent to Horn
Bernays-Sch¨onﬁnkel clause fragment, called HBS.
More concretely, the underlying logic for both formalizing supervisor behav-
ior and formulating conjectures is the hierarchic combination of the Bernays-
Sch¨onﬁnkel ﬁrst-order fragment with real linear arithmetic, BS(LRA), also
called Superlog for Supervisor Eﬀective Reasoning Logics [15]. Satisﬁability of
BS(LRA) clause sets is undecidable [13,21], in general, however, the restriction
to simple linear real arithmetic BS(SLR) yields a decidable fragment [17,20].
Our ﬁrst contribution is decidability of BS(SLR) with respect to universally
quantiﬁed conjectures, Sect. 3, Lemma 10.
Inspired by the test point method for quantiﬁer elimination in arithmetic [25]
we show that instantiation with a ﬁnite number of ﬁrst-order constants is suﬃ-
cient to decide whether a universal/existential conjecture is a consequence of a
BS(SLR) clause set.
For our experiments of the test point approach we consider two case studies:
veriﬁcation conditions for a supervisor taking care of multiple software variants of
a lane change assistant in a car and a supervisor for a supercharged combustion
engine, also called an ECU for Electronical Control Unit. The supervisors in
both cases are formulated by BS(SLR) Horn clauses, the HBS(SLR) fragment.
Via our test point technique they are translated together with the veriﬁcation
conditions to Datalog [1] (HBS). The translation is implemented in our Superlog
reasoner SPASS-SPL. The resulting Datalog clause set is eventually explored by
the Datalog engine VLog [11]. This hammer constitutes a decision procedure for
both universal and existential conjectures. The results of our experiments show
that we can verify non-trivial existential and universal conjectures in the range
of seconds while state-of-the-art solvers cannot solve all problems in reasonable
time. This constitutes our second contribution, Sect. 5.

A Datalog Hammer for Supervisor Veriﬁcation Conditions
5
Related Work: Reasoning about BS(LRA) clause sets is supported by SMT
(Satisﬁability Modulo Theories) [28,29]. In general, SMT comprises the com-
bination of a number of theories beyond LRA such as arrays, lists, strings, or
bit vectors. While SMT is a decision procedure for the BS(LRA) ground case,
universally quantiﬁed variables can be considered by instantiation [34]. Rea-
soning by instantiation does result in a refutationally complete procedure for
BS(SLR), but not in a decision procedure. The Horn fragment HBS(LRA) out
of BS(LRA) is receiving additional attention [6,18], because it is well-suited for
software analysis and veriﬁcation. Research in this direction also goes beyond
the theory of LRA and considers minimal model semantics in addition, but is
restricted to existential conjectures. Other research focuses on universal conjec-
tures, but over non-arithmetic theories, e.g., invariant checking for array-based
systems [12] or considers abstract decidability criteria incomparable with the
HBS(LRA) class [33]. Hierarchic superposition [2] and Simple Clause Learn-
ing over Theories [9] (SCL(T)) are both refutationally complete for BS(LRA).
While SCL(T) can be immediately turned into a decision procedure for even
larger fragments than BS(SLR) [9], hierarchic superposition needs to be reﬁned
by speciﬁc strategies or rules to become a decision procedure already because of
the Bernays-Sch¨onﬁnkel part [19]. Our Datalog hammer translates HBS(SLR)
clause sets with both existential and universal conjectures into HBS clause
sets which are also subject to ﬁrst-order theorem proving. Instance generat-
ing approaches such as iProver [23] are a decision procedure for this fragment,
whereas superposition-based [2] ﬁrst-order provers such as E [37], SPASS [41],
Vampire [35], have additional mechanisms implemented to decide HBS. In our
experiments, Sect. 5, we will discuss the diﬀerences between all these approaches
on a number of benchmark examples in more detail.
The paper is organized as follows: after a section on preliminaries, Sect. 2,
we present the theory of our new Datalog hammer in Sect. 3. Section 4 intro-
duces our two case studies followed by experiments on respective veriﬁcation
conditions, Sect. 5. The paper ends with a discussion of the obtained results and
directions for future work, Sect. 6. Binaries of our tools and all benchmark prob-
lems can be found under https://github.com/knowsys/eval-datalog-arithmetic
and an extended version of this paper including proofs on arXiv [8].
2
Preliminaries
We brieﬂy recall the basic logical formalisms and notations we build upon. We
use a standard ﬁrst-order language with constants (denoted a, b, c), without non-
constant function symbols, variables (denoted w, x, y, z), and predicates (denoted
P, Q, R) of some ﬁxed arity. Terms (denoted t, s) are variables or constants. We
write ¯x for a vector of variables, ¯a for a vector of constants, and so on. An atom
(denoted A, B) is an expression P(¯t) for a predicate P of arity n and a term list
¯t of length n. A positive literal is an atom A and a negative literal is a negated
atom ¬A. We deﬁne comp(A) = ¬A, comp(¬A) = A, |A| = A and |¬A| = A.
Literals are usually denoted L, K, H.

6
M. Bromberger et al.
A clause is a disjunction of literals, where all variables are assumed to be
universally quantiﬁed. C, D denote clauses, and N denotes a clause set. We write
atoms(X) for the set of atoms in a clause or clause set X. A clause is Horn if
it contains at most one positive literal, and a unit clause if it has exactly one
literal. A clause A1 ∨. . .∨An ∨¬B1 ∨. . .∨¬Bm can be written as an implication
A1 ∧. . .∧An →B1 ∨. . .∨Bm, still omitting universal quantiﬁers. If Y is a term,
formula, or a set thereof, vars(Y ) denotes the set of all variables in Y , and Y is
ground if vars(Y ) = ∅. A fact is a ground unit clause with a positive literal.
Datalog and the Bernays-Sch¨onﬁnkel Fragment: The Bernays-Sch¨onﬁnkel
fragment (BS) comprises all sets of clauses. The more general form of BS in
ﬁrst-order logic allows arbitrary formulas over atoms, i.e., arbitrary Boolean
connectives and leading existential quantiﬁers. However, both can be polynomi-
ally removed with common syntactic transformations while preserving satisﬁa-
bility and all entailments that do not refer to auxiliary constants and predicates
introduced in the transformation [31]. Sometimes, we still refer explicitly to for-
mulas when it is more beneﬁcial to apply these transformations after some other
processing steps. BS theories in our sense are also known as disjunctive Datalog
programs [14], speciﬁcally when written as implications. A set of Horn clauses is
also called a Datalog program. (Datalog is sometimes viewed as a second-order
language. We are only interested in query answering, which can equivalently be
viewed as ﬁrst-order entailment or second-order model checking [1]). Again, it is
common to write clauses as implications in this case.
Two types of conjectures, i.e., formulas we want to prove as consequences of
a clause set, are of particular interest: universal conjectures ∀¯xφ and existential
conjectures ∃¯xφ, where φ is any Boolean combination of BS atoms that only
uses variables in ¯x.
A substitution σ is a function from variables to terms with a ﬁnite domain
dom(σ) = {x | xσ ̸= x} and codomain codom(σ) = {xσ | x ∈dom(σ)}. We
denote substitutions by σ, δ, ρ. The application of substitutions is often written
postﬁx, as in xσ, and is homomorphically extended to terms, atoms, literals,
clauses, and quantiﬁer-free formulas. A substitution σ is ground if codom(σ) is
ground. Let Y denote some term, literal, clause, or clause set. σ is a grounding
for Y if Y σ is ground, and Y σ is a ground instance of Y in this case. We denote
by gnd(Y ) the set of all ground instances of Y , and by gndB(Y ) the set of
all ground instances over a given set of constants B. The most general uniﬁer
mgu(Z1, Z2) of two terms/atoms/literals Z1 and Z2 is deﬁned as usual, and we
assume that it does not introduce fresh variables and is idempotent.
We assume a standard ﬁrst-order logic model theory, and write A |= φ if
an interpretation A satisﬁes a ﬁrst-order formula φ. A formula ψ is a logical
consequence of φ, written φ |= ψ, if A |= ψ for all A such that A |= φ. Sets
of clauses are semantically treated as conjunctions of clauses with all variables
quantiﬁed universally.
BS with Linear Arithmetic: The extension of BS with linear arithmetic over
real numbers, BS(LRA), is the basis for the formalisms studied in this paper. For
simplicity, we assume a one-sorted extension where all terms in BS(LRA) are

A Datalog Hammer for Supervisor Veriﬁcation Conditions
7
of arithmetic sort LA, i.e., represent numbers. The language includes free ﬁrst-
order logic constants that are eventually interpreted by real numbers, but we
only consider initial clause sets without such constants, called pure clause sets.
Satisﬁability of pure BS(LRA) clause sets is semi-decidable, e.g., using hierarchic
superposition [2] or SCL(T) [9]. Impure BS(LRA) is no longer compact and
satisﬁability becomes undecidable, but it can be made decidable when restricting
to ground clause sets [16], which is the result of our grounding hammer.
Example 1. The following BS(LRA) clause from our ECU case study compares
the values of speed (Rpm) and pressure (KPa) with entries in an ignition table
(IgnTable) to derive the basis of the current ignition value (IgnDeg1):
x1 < 0 ∨x1 ≥13 ∨x2 < 880 ∨x2 ≥1100 ∨¬KPa(x3, x1) ∨
¬Rpm(x4, x2) ∨¬IgnTable(0, 13, 880, 1100, z) ∨IgnDeg1(x3, x4, x1, x2, z)
(1)
Terms of sort LA are constructed from a set X of variables, a set of ﬁrst-
order arithmetic constants, the set of integer constants c ∈Z, and binary function
symbols + and −(written inﬁx). Atoms in BS(LRA) are either ﬁrst-order atoms
(e.g., IgnTable(0, 13, 880, 1100, z)) or (linear) arithmetic atoms (e.g., x2 < 880).
Arithmetic atoms may use the predicates ≤, <, ̸=, =, >, ≥, which are written
inﬁx and have the expected ﬁxed interpretation. Predicates used in ﬁrst-order
atoms are called free. First-order literals and related notation is deﬁned as before.
Arithmetic literals coincide with arithmetic atoms, since the arithmetic predi-
cates are closed under negation, e.g., comp(x2 ≥1100) = x2 < 1100.
BS(LRA) clauses and conjectures are deﬁned as for BS but using BS(LRA)
atoms. We often write clauses in the form Λ ∥C where C is a clause solely built
of free ﬁrst-order literals and Λ is a multiset of LRA atoms. The semantics of
∥is implication where Λ denotes a conjunction, e.g., the clause x > 1 ∨y ̸=
5 ∨¬Q(x) ∨R(x, y) is also written x ≤1, y = 5||¬Q(x) ∨R(x, y). For Y a term,
literal, or clause, we write ints(Y ) for the set of all integers that occur in Y .
A clause or clause set is pure if it does not contain ﬁrst-order arithmetic
constants, and it is abstracted if its ﬁrst-order literals contain only variables.
Every clause C is equivalent to an abstracted clause that is obtained by replacing
each non-variable term t that occurs in a ﬁrst-order atom by a fresh variable x
while adding an arithmetic atom x ̸= t to C. We assume abstracted clauses
for theory development, but we prefer non-abstracted clauses in examples for
readability,e.g., a fact P(3, 5) is considered in the development of the theory as
the clause x = 3, x = 5||P(x, y), this is important when collecting the necessary
test points.
The semantics of BS(LRA) is based on the standard model ALRA of linear
arithmetic, which has the domain LAALRA = R and which interprets all arith-
metic predicates and functions in the usual way. An interpretation of BS(LRA)
coincides with ALRA on arithmetic predicates and functions, and freely inter-
prets free predicates and ﬁrst-order arithmetic constants. For pure clause sets
this is well-deﬁned [2]. Logical satisfaction and entailment is deﬁned as usual,
and uses similar notation as for BS.

8
M. Bromberger et al.
Simpler Forms of Linear Arithmetic: The main logic studied in this paper
is obtained by restricting BS(LRA) to a simpler form of linear arithmetic. We
ﬁrst introduce a simpler logic BS(SLR) as a well-known fragment of BS(LRA)
for which satisﬁability is decidable [17,20], and then present the generalization
BS(LRA) PP of this formalism that we will use.
Deﬁnition 2 The Bernays-Sch¨onﬁnkel fragment over simple linear arithmetic,
BS(SLR), is a subset of BS(LRA) where all arithmetic atoms are of form x◁c
or d◁c, such that c ∈Z, d is a (possibly free) constant, x ∈X, and ◁∈

≤, <,
̸=, =, >, ≥

.
Example 3 The ECU use case leads to BS(LRA) clauses such as
x1 < y1 ∨x1 ≥y2 ∨x2 < y3 ∨x2 ≥y4 ∨¬KPa(x3, x1) ∨
¬Rpm(x4, x2) ∨¬IgnTable(y1, y2, y3, y4, z) ∨IgnDeg1(x3, x4, x1, x2, z). (2)
This clause is not in BS(SLR), e.g., since x1 > x5 is not allowed in BS(SLR).
However, clause (1) of Example 1 is a BS(SLR) clause that is an instance of
(2), obtained by the substitution {y1 →0, y2 →13, y3 →880, y4 →1100}. This
grounding will eventually be obtained by resolution on the IgnTable predicate,
because it occurs only positively in ground unit facts.
Example 3 shows that BS(SLR) clauses can sometimes be obtained by instan-
tiation. Relevant instantiations can be found by resolution, in our case by hierar-
chic resolution, which supports arithmetic constraints: given clauses Λ1 ∥L∨C1
and Λ2 ∥K ∨C2 with σ = mgu(L, comp(K)), their hierarchic resolvent is
(Λ1, Λ2 ∥C1 ∨C2)σ. A refutation is the sequence of resolution steps that pro-
duces a clause Λ ∥⊥with ALRA |= Λδ for some grounding δ. Hierarchic res-
olution is sound and refutationally complete for pure BS(LRA), since every set
N of pure BS(LRA) clauses N is suﬃciently complete [2], and hence hierarchic
superposition is sound and refutationally complete for N [2,5]. Resolution can
be used to eliminate predicates that do not occur recursively:
Deﬁnition 4 (Positively Grounded Predicate). Let N be a set of BS(LRA)
clauses. A free ﬁrst-order predicate P is a positively grounded predicate in N if
all positive occurrences of P in N are in ground unit clauses (also called facts).
For a positively grounded predicate P in a clause set N, let elim(P, N) be the
clause set obtained from N by resolving away all negative occurrences of P in N
and ﬁnally eliminating all clauses where P occurs negatively. We need to keep
the P facts for the generation of test points. Then N is satisﬁable iﬀelim(P, N)
is satisﬁable. We can extend elim to sets of positively grounded predicates in
the obvious way. If n is the number of P unit clauses in N, m the maximal
number of negative P literals in a clause in N, and k the number of clauses in
N with a negative P literal, then | elim(P, N)| ≤|N| + k · nm, i.e., elim(P, N) is
exponential in the worst case.

A Datalog Hammer for Supervisor Veriﬁcation Conditions
9
We further assume that elim simpliﬁes LRA atoms until they contain at most
one integer number and that LRA atoms that can be evaluated are reduced to
true and false and the respective clause simpliﬁed. For example, given the pure
and abstracted BS(LRA) clause set N = {IgnTable(0, 13, 880, 1100, 2200), x1 ≤
x2 ∨z2 ≥z1 ∥¬IgnTable(x1, x2, y1, y2, z1) ∨R(z2)}, the predicate IgnTable
is positively grounded. Then elim(IgnTable, N) = {z2 ≥2200 ∥R(z2)} where
the uniﬁer σ = {x1 →0, x2 →13, y1 →880, y2 →110, z1 →2200} is used to
eliminate the literal ¬IgnTable(x1, x2, y1, y2, z1) and (x1 ≤x2)σ becomes true
and can be removed.
Deﬁnition 5 (Positively Grounded BS(SLR): BS(SLR) P). A clause set N
is out of the fragment positively grounded BS(SLR), BS(SLR) P if elim(S, N)
is out of the BS(SLR) fragment, where S is the set of all positively grounded
predicates in N.
Pure BS(SLR) P clause sets are called BS(SLR) PP and are the starting point
for our Datalog hammer.
3
The Theory of the Hammer
We deﬁne two hammers that help us solve BS(SLR) PP clause sets with both
universally and existentially quantiﬁed conjectures. Both are equisatisﬁability
preserving and allow us to abstract BS(SLR) PP formulas into less complicated
logics with eﬃcient and complete decision procedures.
The ﬁrst hammer, also called grounding hammer, translates any BS(SLR) PP
clause set N with a universally/existentially quantiﬁed conjecture into an equi-
satisﬁable ground and no longer pure BS(SLR) clause set over a ﬁnite set of
ﬁrst-order constants called test points. This means we reduce a quantiﬁed prob-
lem over an inﬁnite domain into a ground problem over a ﬁnite domain. The size
of the ground problem grows worst-case exponentially in the number of variables
and the number of numeric constants in N and the conjecture. For the Horn case,
HBS(SLR) PP, we deﬁne a Datalog hammer, i.e. a transformation into an equi-
satisﬁable Datalog program that is based on the same set of test points but
does not require an overall grounding. It keeps the original clauses almost one-
to-one instead of greedily computing all ground instances of those clauses over
the test points. The Datalog hammer adds instead a ﬁnite set of Datalog facts
that correspond to all theory atoms over the given set of test points. With the
help of these facts and the original rules, the Datalog reasoner can then derive
the same conclusions as it could have done with the ground HBS(SLR) clause
set, however, all groundings that do not lead to new ground facts are neglected.
Therefore, the Datalog approach is much faster in practice because the Datalog
reasoner wastes no time (and space) on trivially satisﬁed ground rules that would
have been part of the greedily computed ground HBS(SLR) clause set. Moreover,
Datalog reasoners are well suited to the resulting structure of the problem, i.e.
many facts but a small set of rules.

10
M. Bromberger et al.
Note that we never compute or work on elim(S, N) although the discussed
clause sets are positively grounded. We only refer to elim(S, N) because it allows
us to formulate our theoretical results more concisely. We avoid working on
elim(S, N) because it often increases the number of non-fact clauses (by orders of
magnitude) in order to simplify the positively grounded theory atoms to variable
bounds. This is bad in practice because the number of non-fact clauses has a high
impact on the performance of Datalog reasoners. Our Datalog hammer resolves
this problem by dealing with the positively grounded theory atoms in a diﬀerent
way that only introduces more facts instead of non-fact clauses. This is better in
practice because Datalog reasoners are well suited to handling a large number
of facts. Since the grounding hammer is meant primarily as a stepping stone
towards the Datalog hammer, we also deﬁned it in such a way that it avoids
computing and working on elim(S, N).
Hammering BS(SLR) Clause Sets with a Universal Conjecture: Our
ﬁrst hammer, takes a BS(SLR) PP clause set N and a universal conjecture ∀¯y.φ
as input and translates it into a ground BS(SLR) formula. We will later show
that the cases for no conjecture and for an existential conjecture can be seen as
special cases of the universal conjecture. Since φ is a universal conjecture, we
assume that φ is a quantiﬁer-free pure BS(SLR) formula and vars(φ) = vars(¯y).
Moreover, we denote by S the set of positively grounded predicates in N and
assume that none of the positively grounded predicates from S appear in φ.
There is not much diﬀerence developing the hammer for the Horn or the non-
Horn case. Therefore, we present it for the general non-Horn case, although our
second Datalog hammer is restricted to Horn. Note that a conjecture ∀¯y.φ is
a consequence of N, i.e. N |= ∀¯y.φ, if ∀¯y.φ is satisﬁed by every interpretation
A that also satisﬁes N, i.e. ∀A.(A |= N →∀¯y.φ). Conversely, ∀¯y.φ is not a
consequence of N if there exists a counter example, i.e. one interpretation A
that satisﬁes N but does not satisfy ∀¯y.φ, or formally: ∃A.(A |= N ∧∃¯y.¬φ).
Our hammer is going to abstract the counter example formulation into a
ground BS(SLR) formula. This means the hammered formula will be unsat-
isﬁable if and only if the conjecture is a consequence of N. The abstraction
to the ground case works because we can restrict our solution space from the
inﬁnite reals to a ﬁnite set of test points and still preserve satisﬁability. To
be more precise, we partition R into intervals such that any variable bound in
elim(S, N) and φ either satisﬁes all points in one such interval I or none. Then
we pick m = max(1, | vars(φ)|) test points from each of those intervals because
any counter example, i.e. any assignment for ¬φ, contains at most m diﬀerent
points per interval.
We get the interval partitioning by ﬁrst determining the necessary set of
interval borders based on the variable bounds in elim(S, N) and φ. Then, we
sort and combine the borders into actual intervals. The interval borders are
extracted as follows: We turn every variable bound x◁c with ◁∈{≤, <, >, ≥} in
elim(S, N) and φ into two interval borders. One of them is the interval border
implied by the bound itself and the other its negation, e.g., x ≥5 results in the
interval border [5 and the interval border of the negation 5). Likewise, we turn

A Datalog Hammer for Supervisor Veriﬁcation Conditions
11
every variable bound x◁c with ◁∈{=, ̸=} into all four possible interval borders
for c, i.e. c), [c, c], and (c. The set of interval endpoints C is then deﬁned as
follows:
C = {c], (c | x ◁c ∈atoms(elim(S, N)) ∪atoms(φ) where ◁∈{≤, =, ̸=, >}} ∪
{c), [c | x ◁c ∈atoms(elim(S, N)) ∪atoms(φ) where ◁∈{≥, =, ̸=, <}} ∪{(−∞, ∞)}
It is not necessary to compute elim(S, N) to compute C. It is enough to iterate
over all theory atoms in N and compute all of their instantiations in elim(S, N)
based on the facts in N for predicates in S. This can be done in O(nt · nA · nnv
S ),
where nv is the maximum number of variables in any theory atom in N, nA is
the number of theory atoms in N, nS is the number of facts in N for predicates
in S, and nt is the size of the largest theory atom in N with respect to the
number of symbols.
The intervals themselves can be constructed by sorting C in an ascending
order such that we ﬁrst order by the border value—i.e. δ < ϵ if δ ∈{c), [c, c], (c},
ϵ ∈{d), [d, d], (d}, and c < d—and then by the border type—i.e. c) < [c <
c] < (c. The result is a sequence [. . . , δl, δu, . . .], where we always have one
lower border δl, followed by one upper border δu. We can guarantee that an
upper border δu follows a lower border δl because C always contains c) together
with [c and c] together with (c for c ∈Z, so always two consecutive upper and
lower borders. Together with (−∞and ∞) this guarantees that the sorted C
has the desired structure. If we combine every two subsequent borders δl, δu
in our sorted sequence [. . . , δl, δu, . . .], then we receive our partition of inter-
vals I. For instance, if x < 5 and x = 0 are the only variable bounds in
elim(S, N) and φ, then C = {5), [5, 0), [0, 0], (0, (−∞, ∞)} and if we sort it we
get {(−∞, 0), [0, 0], (0, 5), [5, ∞)}.
Corollary 6. Let ◁∈{<, ≤, =, ̸=, ≥, >}. For each interval I ∈I, every two
points a, b ∈I, and every variable bound x ◁c ∈atoms(elim(S, N)) ∪atoms(φ),
a ◁c if and only if b ◁c.
The above Corollary states that two points a, b ∈I belonging to the same
interval I ∈I satisfy the same theory atoms in elim(S, N) and φ. However,
two points a, b ∈I do not necessarily satisfy the same non-theory atom under
an arbitrary interpretation A; not even if A satisﬁes N ∧∃¯y.¬φ. E.g., A may
evaluate P(a) to true and P(b) to false. Sometimes this is even necessary or we
would be unable to ﬁnd a counter example:
Example 7. Let φ = (0 ≤x, x ≤1, 0 ≤y, y ≤1||¬P(x)∨P(y)) be our conjecture
and N = ∅be our clause set. Informally, the property ∀x, y.φ states that P must
be uniform over the interval [0, 1], i.e. either all points in the interval [0, 1] satisfy
P or none do. As a result, all interpretations that are uniform over [0, 1] ∈I also
satisfy ∀x, y.φ. However, there still exist counter examples that are not uniform,
e.g., P A = {0}, which satisﬁes N but not ∀x, y.φ because it evaluates P(0) to
true and P(a) to false for all a ∈[0, 1]\{0}.
To better understand the above example, let us look again at the counter
example formulation N ∧∃¯y.¬φ. This formula is satisﬁable, i.e. we have a counter

12
M. Bromberger et al.
example to our conjecture ∀¯y.φ if there exists an interpretation A and a ground-
ing ρ for φ (also called an assignment for φ) such that A satisﬁes N and ¬φρ. In
the worst case, the assignment ρ maps to m = | vars(φ)| diﬀerent points in one of
the intervals I ∈I. Each of those m points may “act” diﬀerently in the interpre-
tation A although it belongs to the same interval. On the one hand, this means
that we need in the worst case m = | vars(φ)| diﬀerent test points for each interval
in I. On the other hand, we will show in the proof of Lemma 9 that we can always
ﬁnd a counter example, where (i) no more than m points per interval act diﬀer-
ently and (ii) the actual value of a point does not matter as long as it belongs to
the same interval I ∈I. This is owed mainly to Corollary 6, i.e. that the points
in an interval act at least the same in the theory atoms. We ensure that a test
point a belongs to a certain interval I by adding a set of variable bounds to our
formula. We deﬁne these bounds with the functions ilbd and iubd that turn inter-
vals into lower and upper bounds: ilbd((−∞, u), x) = ∅, ilbd((−∞, u], x) = ∅,
ilbd((l, u), x) = {l < x}, ilbd((l, u], x) = {l < x}, ilbd([l, u), x) = {l ≤x},
ilbd([l, u], x) = {l ≤x} for l ̸= −∞; iubd((l, ∞), x) = ∅, iubd([l, ∞), x) = ∅,
iubd((l, u), x) = {x < u}, iubd((l, u], x) = {x ≤u}, iubd([l, u), x) = {x < u},
iubd([l, u], x) = {x ≤u} for u ̸= ∞.
Note that this test point scheme would no longer be possible if we were to
allow general inequalities. Even allowing diﬀerence constraints, i.e., inequalities
of the form x −y ≤c, would turn the search for a counter example into an
undecidable problem [13,21], because variables can now interact both on the
ﬁrst-order and the theory side.
As a result of these observations, we construct the hammered formula ψ, also
called the ﬁnite abstraction of N ∧∃¯y.¬φ, as follows. First we ﬁx the following
notations for the remaining subsection: I is the interval partition for N and φ;
I= = {I ∈I | I = [l, l]} is the set of all intervals from I that are just points;
I∞= I\I= is the set of all intervals that are not just points and therefore
contain inﬁnitely many values; m = max(1, | vars(φ)|) is the number of test
points needed per interval with inﬁnitely many values; B = {aI,1|I ∈I=} ∪
{aI,j|I ∈I∞and j = 1, . . . , m} is the set of test points for our abstraction such
that we have one test point per interval I ∈I= and m diﬀerent test points
for each interval I ∈I∞; idef(B) = 
aI,i∈B ilbd(I, aI,i) ∪
aI,i∈B iubd(I, aI,i)
is a set of bounds that deﬁnes to which interval each constant belongs; and
ψ = gndB(N)∪idef(B)∧(
ρ:vars(φ)→B ¬φρ) is the ﬁnite abstraction of N∧∃¯y.¬φ.
The hammered formula ψ contains gndB(N), i.e. a ground clause (Λ ∥C)σ
for every clause (Λ ∥C) ∈N and every assignment σ : vars(Λ ∥C) →B. This
means any deduction over the tests points B we could have performed with the
set of clauses N can also be performed with the set of clauses gndB(N) in ψ.
Similarly, 
ρ:vars(φ)→B ¬φρ is a big disjunction over all assignments of ρ for φ
that assign its variables to test points. Hence, ψ is satisﬁable if there exists a
counter example for N ∧∃¯y.¬φ that just uses the test points B. Although the
ﬁnite abstraction is restricted to the test points B, it is easy to extend any of
its interpretations to all of R and our original formula. We just have to interpret
all values in an interval that are not test points like one of the test points:

A Datalog Hammer for Supervisor Veriﬁcation Conditions
13
Lemma 8. Let A′ be an interpretation satisfying the ﬁnite abstraction ψ of
N ∧∃¯y.¬φ. Moreover, let ρ : vars(φ) →B be a substitution such that A′ satisﬁes
¬φρ. Then the interpretation A satisﬁes N ∧∃¯y.¬φ if it is constructed as follows:
P A = {¯a ∈Rn | P(¯a) ∈N} if P ∈S and P A = {¯a ∈Rn | ¯aσ ∈P A′} if
P ̸∈S and σ = {a →aA′
I,1 | I ∈I and a ∈I\{aA′
I,2, . . . , aA′
I,m}}.
Similarly, we can extend any interpretation A satisfying N ∧∃¯y.¬φ into an
interpretation satisfying ψ. We just have to pick one assignment ρ′ : vars(φ) →R
such that A satisﬁes ¬φρ′ and pick one test point B for each point in codom(ρ′)
and interpret it as its corresponding point in codom(ρ′).
Lemma 9. Let A be an interpretation satisfying the formula N ∧∃¯y.¬φ. Then
we can construct an interpretation A′ that satisﬁes its ﬁnite abstraction ψ.
If we combine both results, we get that N ∧∃¯y.¬φ is equisatisﬁable to ψ:
Lemma 10. N ∧∃¯y.¬φ has a satisfying interpretation if and only if its ﬁnite
abstraction ψ has a satisfying interpretation.
The ﬁnite abstraction for the case with a universal conjecture can also be
used to construct a ﬁnite abstraction for the case without a conjecture and the
case with an existential conjecture. Let N be a BS(SLR) PP clause set and let
S be the set of all positively grounded predicates in N. N is satisﬁable if and
only if N ̸|= ⊥. Hence, we get a ﬁnite abstraction for N if we build one for
N |= ⊥, which can be treated as a universal conjecture because all variables in
⊥are universally quantiﬁed. The existential case works similarly: N |= ∃¯y.φ if
and only if N ∪N ′ |= ⊥, where N ′ is the universal BS(SLR) clause set we get
from applying a CNF transformation [31] to ∀¯y.¬φ.
A Datalog Hammer for HBS(SLR) PP: The set gndB(N) grows expo-
nentially with regard to the maximum number of variables nC in any clause
(Λ ∥C) ∈N, i.e. O(| gndB(N)|) = O(|N| · |B|nC). Since B is large for realis-
tic examples (e.g., in our examples the size of B ranges from 15 to 1609 con-
stants), the ﬁnite abstraction is often too large to be solvable in reasonable time.
As an alternative approach, we propose a Datalog hammer for the Horn frag-
ment of BS(SLR) PP clause sets, called HBS(SLR)PP. This hammer exploits the
ideas behind the ﬁnite abstraction and will allow us to make the same ground
deductions, but instead of grounding everything, we only need to (i) ground the
negated conjecture over our test points and (ii) provide a set of ground facts
that deﬁne which theory atoms are satisﬁed by our test points. As a result, the
hammered formula is much more concise and we need no actual theory reasoning
to solve the formula. In fact, we can solve the hammered formula by greedily
resolving with all facts (from our set of clauses and returned as a result of this
process) until this produces the empty clause—which would mean the conjecture
is implied—or no more new facts—which would mean we have found a counter
example. (In practice, greedily applying resolution is not the best strategy and
we recommend to use more advanced techniques for instance those used by a
state-of-the-art Datalog reasoner.)

14
M. Bromberger et al.
The Datalog hammer takes as input (i) a HBS(SLR)PP clause set N (where
S is the set of all positively grounded predicates in N) and (ii) optionally a
universal conjecture ∀¯y.P(¯y) where P ̸∈S. Restricting the conjecture to a single
positive literal may seem like a drastic restriction, but we will later show that we
can transform any universal conjecture into this form if it contains only positive
atoms. Given this input, the Datalog hammer ﬁrst computes the same interval
partition I and test point/constant set B needed for the ﬁnite abstraction. Then
it computes an assignment β for the constants in B that corresponds to the
interval partition, i.e. aI,iβ ∈I and aI,iβ ̸= aI,jβ if i ̸= j. Next, it computes
three clause sets that will make up the Datalog formula. The ﬁrst set trenN(N)
is computed out of N by replacing each theory atom A in N with a literal
PA(¯x), where vars(A) = vars(¯x) and PA is a fresh predicate. This is necessary to
eliminate all non-constant function symbols (e.g., +, −) in positively grounded
theory atoms because Datalog does not support non-constant function symbols.
(It is possible to reduce the number of fresh predicates needed, e.g., by reusing
the same predicate for two theory atoms that are equivalent up to variable
renaming.) The second set is empty if we have no universal conjecture or it
contains the ground and negated version φ of our universal conjecture ∀¯y.P(¯y).
Since we restricted the conjecture to a single positive literal, φ has the form
Cφ →⊥, where Cφ contains all literals P(¯y)ρ for all groundings ρ : vars(¯y) →B.
We cannot skip this grounding but the worst-case size of Cφ is O(gndB(N)) =
O(|B|nφ), where nφ = |¯y|, which is in our applications typically much smaller
than the maximum number of variables nC contained in any clause in N. The
last set is denoted by tfacts(N, B) and contains a fact trenN(A) for every ground
theory atom A contained in the theory part Λ of a clause (Λ ∥C) ∈gndB(N)
such that Aβ simpliﬁes to true. (Alternatively, it is also possible to use a set
of axioms and a smaller set of facts and let the Datalog reasoner compute all
relevant theory facts for itself.) The set tfacts(N, B) can be computed without
computing gndB(N) if we simply iterate over all theory atoms A in all constraints
Λ of all clauses (Λ ∥C) ∈N and compute all groundings τ : vars(A) →B such
that Aτβ simpliﬁes to true. This can be done in time O(μ(nv) · nL · |B|nv) and
the resulting set tfacts(N, B) has worst-case size O(nA · |B|nv), where nL is
the number of literals in N, nv is the maximum number of variables | vars(A)|
in any theory atom A in N, nA is the number of diﬀerent theory atoms in
N, and μ(x) is the time needed to simplify a theory atom over x variables to
a variable bound. Please note that already satisﬁability testing for BS clause
is NEXPTIME-complete in general, and DEXPTIME-complete for the Horn
case [24,32]. So when abstracting to a polynomially decidable clause set (ground
HBS) an exponential factor is unavoidable.
Lemma 11. N ∧∃¯y.¬P(¯y) is equisatisﬁable to its hammered version ND =
trenN(N) ∪tfacts(N, B) ∪{φ}. N is equisatisﬁable to its hammered version
trenN(N) ∪tfacts(N, B).
Note that trenN(N) ∪tfacts(N, B) ∪{φ} is actually a HBS clause set over a
ﬁnite set of constants B and not yet a Datalog input ﬁle. It is well known that

A Datalog Hammer for Supervisor Veriﬁcation Conditions
15
such a formula can be transformed easily into a Datalog problem by adding a
nullary predicate Goal and adding it as a positive literal to any clause without
a positive literal. Querying for the Goal atom returns true if the HBS clause set
was unsatisﬁable and false otherwise.
Positive Conjectures: One of the seemingly biggest restrictions of our Data-
log hammer is that it only accepts universal conjectures over a single positive
literal ∀¯y.P(¯y). We made this restriction because it is the easiest way to guar-
antee that our negated and ﬁnitely abstracted goal takes the form of a Horn
clause. However, there is a way to express any positive universal conjecture—i.e.
any universal conjecture where all atoms have positive polarity—as a universal
conjecture over a single positive literal. (Note that any negative theory literal
can be turned into a positive theory literal by changing the predicate symbol,
e.g., ¬(x ≤5) ≡(x > 5)). Similarly as in a typical ﬁrst-order CNF transfor-
mation [31], we can simply rename all subformulas, i.e. recursively replace all
subformulas with some fresh predicate symbols and add suitable Horn clause def-
initions for these new predicates to our clause set N. A detailed algorithm for this
ﬂattening process and a proof of equisatisﬁability can be found in the extended
version of this paper. Using the same technique, we can also express any posi-
tive existential conjecture—i.e. any existential conjecture where all atoms have
positive polarity—as additional clauses in our set of input clauses N.
4
Two Supervisor Case Studies
We consider two supervisor case studies: a lane change assistant and the ECU
of a supercharged combustion engine; both using the architecture in Fig. 1.
Lane Assistant: This use case focuses on the lane changing maneuver in
autonomous driving scenario i.e., the safe lane selection and the speed. We run
two variants of software processing units (updated and certiﬁed) in parallel with
a supervisor. The variants are connected to diﬀerent sensors that capture the
state of the freeway such as video or LIDAR signal sensors. The variants pro-
cess the sensors’ data and suggest the safe lanes to change to in addition to the
evidence that justify the given selection. The supervisor is responsible for the
selection of which variant output to forward to other system components i.e.,
the execution units (actuators) that perform the maneuver. Variants categorize
the set of available actions for each time frame into safe/unsafe actions and pro-
vide explications. The supervisor collects the variants output and processes them
to reason about (a) if enough evidence is provided by the variants to consider
actions safe (b) ﬁnd the actions that are considered safe by all variants.
Variants formulate their explications as facts using ﬁrst-order predicates. The
supervisor uses a set of logical rules formulated in BS(SLR) PP to reason about
the suggestions and the explications (see List 1.1). In general, the rules do not
belong to the BS(SLR) PP fragment, e.g., the atom = (xh1, −(xes, 1)) includes
even an arithmetic calculation. However, after grounding with the facts of the
formalization, only simple bounds remain.

16
M. Bromberger et al.
1 ## Exclude actions per variant if safety disproved or declared unsafe.
2 SuggestionDisproven(xv, xa), VariantName(xv) -> ExcludedAction(xv, xa).
3 VariantName(xv), LaneNotSafe(xv, xl, xa)
-> ExcludedAction(xv, xa).
4 ## Exclude actions for all variants if declared unsafe by the certified
5 CertifiedVariant(xv1), UpdatedVariant(xv2), LaneNotSafe(xv1, xl, xa)
6
-> ExcludedAction(xv2,xa).
7
8 ## A safe action is disproven
9 SafeBehindDisproven(xv, xenl, xecl, xecs, xes, xa), LaneSafe(xv, xl, xa),
10
SuggestedAction(xv, xa)
-> SuggestionDisproven(xv, xa).
11 SafeFrontDisproven(xv, xenl, xecl, xecs, xes, xa),
LaneSafe(xv, xl, xa),
12
SuggestedAction(xv, xa)
-> SuggestionDisproven(xv, xa).
13
14 ## Unsafe left lane: speed decelerated and unsafe distance front
15 >(xh1, xfd), !=(xecl, xenl),
=(xh1,-(xes,1)) ||
16
LaneSafe(xv, xenl, adecelerateleft), EgoCar(xv, xecl, xecs, xes),
17
DistanceFront(xv, xenl, xofp, xfd, adecelerateleft),
18
SpeedFront(xv, xenl, xofp, xofs, adecelerateleft)
19
-> SafeFrontDisproven(xv, xenl, xecl, xecs, xes, adecelerateleft).
List. 1.1. The rules snippets for the lane changing use case in BS(SLR) PP.
Variants Explications: The SuggestedAction predicate encodes the actions
suggested by the variants. LaneSafe and LaneNotSafe specify the lanes that
are safe/unsafe to be used with the diﬀerent actions. DistanceFront and
DistanceBehind provide the explications related to the obstacle position, while
their speeds are SpeedFront and SpeedBehind. EgoCar predicate reports the
speed and the position of the ego vehicle.
Supervisor reasoning:
To select a safe action, the supervisor must exclude
all unsafe actions. The supervisor considers actions to be excluded per vari-
ant (ExcludedAction) if (a) SuggestionDisproven; the variant fails to prove
that the suggested action is safe (line 2), or (b) the action is declared unsafe
(line 3). The supervisor declares an action to be excluded cross all variants
if the certiﬁed variant declares it unsafe (lines 5–6). To consider an action as
SuggestionDisproven, the supervisor must check for each LaneSafe the exis-
tence of unsafe distances between the ego vehicle in the given lane and the other
vehicles approaching either from behind (SafeBehindDisproven) or in front
(SafeFrontDisproven). The rule SafeFrontDisproven (lines 15–19) checks in
the left lane, if using the ego vehicle decelerated speed (=(xh1,-(xes,1))) the
distance between the vehicles is not enough (>(xh1, xfd)). The supervisor
checks ExcludeAction for all variants. If all actions are excluded, the super-
visor uses an emergency action as no safe action exists. Otherwise, selects a safe
action from the not-excluded actions suggested by the updated variant, if not
found, by the certiﬁed.
ECU: The GM LSJ Ecotec engine (https://en.wikipedia.org/wiki/GM Ecotec
engine) is a supercharged combustion engine that was almost exclusively
deployed in the US, still some of those run also in Europe. The main sensor

A Datalog Hammer for Supervisor Veriﬁcation Conditions
17
inputs of the LSJ ECU consist of an inlet air pressure and temperature sensor
(in KPa and in degree Celsius), a speed sensor (in Rpm), a throttle pedal sensor,
a throttle sensor, a coolant temperature sensor, oxygen sensors, a knock sensor,
and its main actuators controlling the engine are ignition and injection timing,
and throttle position. For the experiments conducted in this paper we have taken
the routines of the LSJ ECU that compute ignition and injection timings out
of inlet air pressure, inlet air temperature, and engine speed. For this part of
the ECU this is a two stage process where ﬁrstly, basic ignition and injection
timings are computed out of engine speed and inlet air pressure and secondly,
those are adjusted with respect to inlet air temperature. The properties we prove
are safety properties, e.g., certain injection timings are never generated and also
invariants, e.g., the ECU computes actuator values for all possible input sensor
data and they are unique. Clause 2, page 5, is an actual clause from the ECU
case study computing the base ignition timing.
5
Implementation and Experiments
We have implemented the Datalog hammer into our BS(LRA) system SPASS-
SPL and combined it with the Datalog reasoner Rulewerk. The resulting
toolchain is the ﬁrst implementation of a decision procedure for HBS(SLR) with
positive conjectures.
SPASS-SPL is a new system for BS(LRA) based on some core libraries of
the ﬁrst-order theorem prover SPASS [41] and including the CDCL(LA) solver
SPASS-SATT [10] for mixed linear arithmetic. Eventually, SPASS-SPL will
include a family of reasoning techniques for BS(LRA) including SCL(T) [9], hier-
archic superposition [2,5] and hammers to various logics. Currently, it comprises
the Datalog hammer described in this paper and hierarchic UR-resolution [26]
(Unit Resulting resolution) which is complete for pure HBS(LRA). The Datalog
hammer can produce the clause format used in the Datalog system Rulewerk
(described below), but also the SPASS ﬁrst-order logic clause format that can
then be translated into the ﬁrst-order TPTP library [38] clause format. Moreover,
it can be used as a translator from our own input language into the SMT-LIB
2.6 language [4] and the CHC competition format [36].
Note that our implementation of the Datalog hammer is of prototypi-
cal nature. It cannot handle positively grounded theory atoms beyond simple
bounds, unless they are variable comparisons (i.e., x◁y with ◁∈{≤, <, ̸=, =, >
, ≥}). Moreover, positive universal conjectures have to be ﬂattened until they
have the form Λ ∥P(¯x). On the other hand, we already added some improve-
ments, e.g., we break/eliminate symmetries in the hammered conjecture and we
exploit the theory atoms Λ in a universal conjecture Λ ∥P(¯x) so the hammered
conjecture contains only groundings for P(¯x) that satisfy Λ.
Rulewerk (formerly VLog4j) is a rule reasoning toolkit that consists of a Java
API and an interactive shell [11]. Its current main reasoning back-end is the
rule engine VLog [39], which supports Datalog and its extensions with stratiﬁed

18
M. Bromberger et al.
Fig. 2. Benchmark results and statistics
negation and existential quantiﬁers, respectively. VLog is an in-memory reasoner
that is optimized for eﬃcient use of resources, and has been shown to deliver
highly competitive performance in benchmarks [40].
We have not speciﬁcally optimized VLog or Rulewerk for this work, but we
have tried to select Datalog encodings that exploit the capabilities of these tools.
The most notable impact was observed for the encoding of universal conjectures.
A direct encoding of (grounded) universal claims in Datalog leads to rules with
many (hundreds of thousands in our experiments) ground atoms as their pre-
condition. Datalog reasoners (not just VLog) are not optimized for such large
rules, but for large numbers of facts. An alternative encoding in plain Datalog
would therefore specify the expected atoms as facts and use some mechanism to
iterate over all of them to check for goal. To accomplish this iteration, the facts
that require checking can be endowed with an additional identiﬁer (given as a
parameter), and an auxiliary binary successor relation can be used to specify
the iteration order over the facts. This approach requires only few rules, but the
number of rule applications is proportional to the number of expected facts.
In Rulewerk/VLog, we can encode this in a simpler way using nega-
tion. Universal conjectures require us to evaluate ground queries of the form
entailed(¯c1) ∧. . . ∧entailed(¯cℓ), where each entailed(¯ci) represents one ground-
ing of our conjecture over our set of test points. If we add facts expected(¯ci)
for the constant vectors ¯c1, . . . , ¯cℓ, we can equivalently use a smaller (ﬁrst-
order) query ∀¯x.(expected(¯x) →entailed(¯x)), which in turn can be written as
¬

∃¯x.(expected(¯x)∧¬entailed(¯x))

. This can be expressed in Datalog with nega-
tion and the rules expected(¯x) ∧¬entailed(¯x) →missing and ¬missing →Goal,
where Goal encodes that the query matches. This use of negation is stratiﬁed,
i.e., not entwined with recursion [1]. Note that stratiﬁed negation is a form
of non-monotonic negation, so we can no longer read such rules as ﬁrst-order
formulae over which we compute entailments. Nevertheless, implementation is
simple and stratiﬁed negation is a widely supported feature in Datalog engines,
including Rulewerk. The encoding is particularly eﬃcient since the rules using
negation are evaluated only once.

A Datalog Hammer for Supervisor Veriﬁcation Conditions
19
Benchmark Experiments: To test the eﬃciency of our toolchain, we ran
benchmark experiments on the two real world HBS(SLR) PP supervisor veri-
ﬁcation conditions. The two supervisor use cases are described in Sect. 4. The
names of the problems are formatted so the lane change assistant examples
start with lc and the ECU examples start with ecu. The lc problems with exis-
tential conjectures test whether an action suggested by an updated variant is
contradicted by a certiﬁed variant. The lc problems with universal conjectures
test whether an emergency action has to be taken because we have to exclude
all actions for all variants. The ecu problems with existential conjectures test
safety properties, e.g., whether a computed actuator value is never outside of
the allowed safety bounds. The ecu problems with universal conjectures test
whether the ecu computes an actuator value for all possible input sensor data.
Our benchmarks are prototypical for the complexity of HBS(SLR) reasoning in
that they cover all abstract relationships between conjectures and HBS(SLR)
clause sets. With respect to our two case studies we have many more examples
showing respective characteristics. We would have liked to run benchmarks from
other sources too, but we could not ﬁnd any suitable HBS(SLR) problems in the
SMT-LIB or CHC-COMP benchmarks.
For comparison, we also tested several state-of-the-art theorem provers
for related logics (with the best settings we found): the satisﬁability mod-
ulo theories (SMT) solver cvc4-1.8 [3] with settings --multi-trigger-cache
--full-saturate-quant; the SMT solver z3-4.8.10 [27] with its default set-
tings; the constrained horn clause (CHC) solver spacer [22] with its default
settings; and the ﬁrst-order theorem prover vampire-4.5.1 [35] with settings
--memory_limit 8000 -p off, i.e., with memory extended to 8 GB and without
proof output.
For the experiments, we used a Debian Linux server with 32 Intel Xeon Gold
6144 (3.5 GHz) processors and 754 GB RAM. Our toolchain employs no parallel
computing, except for the java garbage collection. The other tested theorem
provers employ no parallel computing at all. Each tool got a time limit of 40 min
for each problem.
The table in Fig. 2 lists for each benchmark problem: the name of the problem
(Problem); the type of conjecture (Q), i.e., whether the conjecture is existential
∃or universal ∀; the status of the conjecture (Status), i.e., true if the conjecture
is a consequence and false otherwise; the maximum number of variables in any
clause (X); the number of variables in the conjecture (Y ); the number of test
points/constants introduced by the Hammer (B); the size of the formula in kilo-
byte before and after the hammering (Size); the total time (in s) needed by our
toolchain to solve the problem (t-time); the time (in s) spent on hammering the
input formula (h-time); the time (in s) spent on parsing the hammered formula
by Rulewerk (p-time); the time (in s) Rulewerk actually spent on reasoning (r-
time). The remaining four columns list the time in s needed by the other tools
to solve the benchmark problems. An entry “N/A” means that the benchmark
example cannot be expressed in the tools input format, e.g., it is not possible to
encode a universal conjecture (or, to be more precise, its negation) in the CHC
format. An entry “timeout” means that the tool could not solve the problem in

20
M. Bromberger et al.
the given time limit of 40 min. Rulewerk is connected to SPASS-SPL via a ﬁle
interface. Therefore, we show parsing time separately.
The experiments show that only our toolchain solves all the problems in rea-
sonable time. It is also the only solver that can decide in reasonable time whether
a universal conjecture is not a consequence. This is not surprising because to our
knowledge our toolchain is the only theorem prover that implements a decision
procedure for HBS(SLR). On the other types of problems, our toolchain solves
all of the problems in the range of seconds and with comparable times to the
best tool for the problem. For problems with existential conjectures, the CHC
solver spacer is the best, but as a trade-oﬀit is unable to handle universal con-
jectures. The instantiation techniques employed by cvc4 are good for proving
some universal conjectures, but both SMT solvers seem to be unable to disprove
conjectures. Vampire performed best on the hammered problems among all ﬁrst-
order theorem provers we tested, including iProver [23], E [37], and SPASS [41].
We tested all provers in default theorem proving mode, but adjusted the memory
limit of Vampire, because it ran out of memory on ecu u4 with the default set-
ting. The experiments with the ﬁrst-order provers showed that our hammer also
works reasonably well for them, e.g., they can all solve all lane change problems
in less than a second, but they are simply not specialized for the HBS fragment.
6
Conclusion
We have presented several new techniques that allow us to translate BS(SLR) PP
clause sets with both universally and existentially quantiﬁed conjectures into
logics for which eﬃcient decision procedures exist. The ﬁrst set of translations
returns a ﬁnite abstraction for our clause set and conjecture, i.e., an equisatis-
ﬁable ground BS(LRA) clause set over a ﬁnite set of test points/constants that
can be solved in theory by any SMT solver for linear arithmetic. The abstraction
grows exponentially in the maximum number of variables in any input clause.
Realistic supervisor examples have clauses with 10 or more variables and the
basis of the growth exponent is also typically large, e.g., in our examples it
ranges from 15 to 1500, so this leads immediately to very large clause sets. An
exponential growth in grounding is also unavoidable, because the abstraction
reduces a NEXPTIME-hard problem to an NP-complete problem (ground BS,
i.e., SAT). As an alternative, we also present a Datalog hammer, i.e., a trans-
lation to an equisatisﬁable HBS clause set without any theory constraints. The
hammer is restricted to the Horn case, i.e., HBS(SLR) PP clauses, and the con-
jectures to positive universal/existential conjectures. Its advantage is that the
formula grows only exponentially in the number of variables in the universal con-
jecture. This is typically much smaller than the maximum number of variables
in any input clause, e.g., in our examples it never exceeds three.
We have implemented the Datalog hammer into our BS(LRA) system SPASS-
SPL and combined it with the Datalog reasoner Rulewerk. The resulting
toolchain is an eﬀective way of deciding veriﬁcation conditions for supervisors if
the supervisors can be modeled as HBS(SLR) clause sets and the conditions as
positive BS(SLR) conjectures. To conﬁrm this, we have presented two use cases

A Datalog Hammer for Supervisor Veriﬁcation Conditions
21
for real-world supervisors: (i) the veriﬁcation of supervisor code for the electrical
control unit of a super-charged combustion engine and (ii) the continuous cer-
tiﬁcation of lane assistants. Our experiments show that for these use cases our
toolchain is overall superior to existing solvers. Over existential conjectures, it is
comparable with existing solvers (e.g., CHC solvers). Moreover, our toolchain is
the only solver we are aware of that can proof and disproof universal conjectures
for our use cases.
For future work, we want to further develop our toolchain in several direc-
tions. First, we want SPASS-SPL to produce explications that prove that its
translations are correct. Second, we plan to exploit specialized Datalog expres-
sions and techniques (e.g., aggregation and stratiﬁed negation) to increase the
eﬃciency of our toolchain and to lift some restrictions from our input formulas.
Third, we want to optimize the selection of test points. For instance, we could
partition all predicate argument positions into independent sets, i.e., two argu-
ment positions are dependent if they are assigned the same variable in the same
rule. For each of these partitions, we should be able to create an independent
and much smaller set of test points because we only have to consider theory
constraints connected to the argument positions in the respective partition. In
many cases, this would lead to much smaller sets of test points and therefore
also to much smaller hammered and ﬁnitely abstracted formulas.
Acknowledgments. This
work
was
funded
by
DFG
grant
389792660
as
part
of
TRR 248 (CPEC),
by
BMBF
in
project
ScaDS.AI,
and
by
the
Center for Advancing Electronics Dresden (cfaed). We thank Pascal Fontaine, Alberto
Griggio, Andrew Reynolds, Stephan Schulz and our anonymous reviewers for discussing
various aspects of this paper.
References
1. Abiteboul, S., Hull, R., Vianu, V.: Foundations of Databases. Addison Wesley,
Reading (1994)
2. Bachmair, L., Ganzinger, H., Waldmann, U.: Refutational theorem proving for
hierarchic ﬁrst-order theories. Appl. Algebra Eng. Commun. Comput. (AAECC)
5(3/4), 193–212 (1994). https://doi.org/10.1007/BF01190829
3. Barrett, C., et al.: CVC4. In: Gopalakrishnan, G., Qadeer, S. (eds.) CAV 2011.
LNCS, vol. 6806, pp. 171–177. Springer, Heidelberg (2011). https://doi.org/10.
1007/978-3-642-22110-1 14
4. Barrett, C., Fontaine, P., Tinelli, C.: The SMT-LIB standard: version 2.6. Technical
report, Department of Computer Science, The University of Iowa (2017). http://
www.SMT-LIB.org/
5. Baumgartner, P., Waldmann, U.: Hierarchic superposition revisited. In: Lutz, C.,
Sattler, U., Tinelli, C., Turhan, A.-Y., Wolter, F. (eds.) Description Logic, Theory
Combination, and All That. LNCS, vol. 11560, pp. 15–56. Springer, Cham (2019).
https://doi.org/10.1007/978-3-030-22102-7 2
6. Bjørner, N., Gurﬁnkel, A., McMillan, K., Rybalchenko, A.: Horn clause solvers for
program veriﬁcation. In: Beklemishev, L.D., Blass, A., Dershowitz, N., Finkbeiner,
B., Schulte, W. (eds.) Fields of Logic and Computation II. LNCS, vol. 9300, pp.
24–51. Springer, Cham (2015). https://doi.org/10.1007/978-3-319-23534-9 2

22
M. Bromberger et al.
7. B¨ohme, S., Nipkow, T.: Sledgehammer: judgement day. In: Giesl, J., H¨ahnle, R.
(eds.) IJCAR 2010. LNCS (LNAI), vol. 6173, pp. 107–121. Springer, Heidelberg
(2010). https://doi.org/10.1007/978-3-642-14203-1 9
8. Bromberger, M., Dragoste, I., Faqeh, R., Fetzer, C., Kr¨otzsch, M., Weidenbach,
C.: A datalog hammer for supervisor veriﬁcation conditions modulo simple linear
arithmetic. CoRR abs/2107.03189 (2021). https://arxiv.org/abs/2107.03189
9. Bromberger, M., Fiori, A., Weidenbach, C.: Deciding the Bernays-Schoenﬁnkel
fragment over bounded diﬀerence constraints by simple clause learning over the-
ories. In: Henglein, F., Shoham, S., Vizel, Y. (eds.) VMCAI 2021. LNCS, vol.
12597, pp. 511–533. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-
67067-2 23
10. Bromberger, M., Fleury, M., Schwarz, S., Weidenbach, C.: SPASS-SATT. In:
Fontaine, P. (ed.) CADE 2019. LNCS (LNAI), vol. 11716, pp. 111–122. Springer,
Cham (2019). https://doi.org/10.1007/978-3-030-29436-6 7
11. Carral, D., Dragoste, I., Gonz´alez, L., Jacobs, C., Kr¨otzsch, M., Urbani, J.: VLog:
a rule engine for knowledge graphs. In: Ghidini, C., et al. (eds.) ISWC 2019. LNCS,
vol. 11779, pp. 19–35. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-
30796-7 2
12. Cimatti, A., Griggio, A., Redondi, G.: Universal invariant checking of parametric
systems with quantiﬁer-free SMT reasoning. In: Proceedings of CADE-28 (2021,
to appear)
13. Downey, P.J.: Undecidability of presburger arithmetic with a single monadic predi-
cate letter. Technical report, Center for Research in Computer Technology, Harvard
University (1972)
14. Eiter, T., Gottlob, G., Mannila, H.: Disjunctive datalog. ACM Trans. Database
Syst. 22(3), 364–418 (1997)
15. Faqeh, R., et al.: Towards dynamic dependable systems through evidence-based
continuous certiﬁcation. In: Margaria, T., Steﬀen, B. (eds.) ISoLA 2020. LNCS,
vol. 12477, pp. 416–439. Springer, Cham (2020). https://doi.org/10.1007/978-3-
030-61470-6 25
16. Fiori, A., Weidenbach, C.: SCL with theory constraints. CoRR abs/2003.04627
(2020). https://arxiv.org/abs/2003.04627
17. Ge, Y., de Moura, L.: Complete instantiation for quantiﬁed formulas in satisﬁ-
abiliby modulo theories. In: Bouajjani, A., Maler, O. (eds.) CAV 2009. LNCS,
vol. 5643, pp. 306–320. Springer, Heidelberg (2009). https://doi.org/10.1007/978-
3-642-02658-4 25
18. Grebenshchikov, S., Lopes, N.P., Popeea, C., Rybalchenko, A.: Synthesizing soft-
ware veriﬁers from proof rules. In: Vitek, J., Lin, H., Tip, F. (eds.) ACM SIGPLAN
Conference on Programming Language Design and Implementation, PLDI 2012,
Beijing, China, 11–16 June 2012, pp. 405–416. ACM (2012)
19. Hillenbrand, T., Weidenbach, C.: Superposition
for bounded domains. In:
Bonacina, M.P., Stickel, M.E. (eds.) Automated Reasoning and Mathematics.
LNCS (LNAI), vol. 7788, pp. 68–100. Springer, Heidelberg (2013). https://doi.
org/10.1007/978-3-642-36675-8 4
20. Horbach, M., Voigt, M., Weidenbach, C.: On the combination of the Bernays–
Sch¨onﬁnkel–Ramsey fragment with simple linear integer arithmetic. In: de Moura,
L. (ed.) CADE 2017. LNCS (LNAI), vol. 10395, pp. 77–94. Springer, Cham (2017).
https://doi.org/10.1007/978-3-319-63046-5 6
21. Horbach, M., Voigt, M., Weidenbach, C.: The universal fragment of pres-
burger arithmetic with unary uninterpreted predicates is undecidable. CoRR
abs/1703.01212 (2017)

A Datalog Hammer for Supervisor Veriﬁcation Conditions
23
22. Komuravelli, A., Gurﬁnkel, A., Chaki, S.: SMT-based model checking for recursive
programs. In: Biere, A., Bloem, R. (eds.) CAV 2014. LNCS, vol. 8559, pp. 17–34.
Springer, Cham (2014). https://doi.org/10.1007/978-3-319-08867-9 2
23. Korovin, K.: iProver – an instantiation-based theorem prover for ﬁrst-order logic
(system description). In: Armando, A., Baumgartner, P., Dowek, G. (eds.) IJCAR
2008. LNCS (LNAI), vol. 5195, pp. 292–298. Springer, Heidelberg (2008). https://
doi.org/10.1007/978-3-540-71070-7 24
24. Lewis, H.R.: Complexity results for classes of quantiﬁcational formulas. J. Comput.
Syst. Sci. 21(3), 317–353 (1980)
25. Loos, R., Weispfenning, V.: Applying linear quantiﬁer elimination. Comput. J.
36(5), 450–462 (1993)
26. McCharen, J., Overbeek, R., Wos, L.: Complexity and related enhancements for
automated theorem-proving programs. Comput. Math. Appl. 2, 1–16 (1976)
27. de Moura, L., Bjørner, N.: Z3: an eﬃcient SMT solver. In: Ramakrishnan, C.R.,
Rehof, J. (eds.) TACAS 2008. LNCS, vol. 4963, pp. 337–340. Springer, Heidelberg
(2008). https://doi.org/10.1007/978-3-540-78800-3 24
28. de Moura, L.M., Bjørner, N.: Satisﬁability modulo theories: introduction and appli-
cations. Commun. ACM 54(9), 69–77 (2011)
29. Nieuwenhuis, R., Oliveras, A., Tinelli, C.: Solving SAT and SAT modulo theories:
from an abstract Davis-Putnam-Logemann-Loveland procedure to DPLL(T). J.
ACM 53, 937–977 (2006)
30. Nipkow, T., Wenzel, M., Paulson, L.C. (eds.): Isabelle/HOL—A Proof Assistant
for Higher-Order Logic. LNCS, vol. 2283. Springer, Heidelberg (2002). https://doi.
org/10.1007/3-540-45949-9
31. Nonnengart, A., Weidenbach, C.: Computing small clause normal forms. In: Hand-
book of Automated Reasoning, pp. 335–367. Elsevier and MIT Press (2001)
32. Plaisted, D.A.: Complete problems in the ﬁrst-order predicate calculus. J. Comput.
Syst. Sci. 29, 8–35 (1984)
33. Ranise, S.: On the veriﬁcation of security-aware e-services. J. Symb. Comput.
47(9), 1066–1088 (2012)
34. Reynolds, A., Barbosa, H., Fontaine, P.: Revisiting enumerative instantiation. In:
Beyer, D., Huisman, M. (eds.) TACAS 2018. LNCS, vol. 10806, pp. 112–131.
Springer, Cham (2018). https://doi.org/10.1007/978-3-319-89963-3 7
35. Riazanov, A., Voronkov, A.: The design and implementation of VAMPIRE. AI
Commun. 15(2–3), 91–110 (2002)
36. R¨ummer, P.: Competition report: CHC-COMP-20. In: Fribourg, L., Heizmann, M.
(eds.) Proceedings of the 8th International Workshop on Veriﬁcation and Program
Transformation and 7th Workshop on Horn Clauses for Veriﬁcation and Synthesis,
VPT/HCVS@ETAPS 2020, Dublin, Ireland, 25–26 April 2020, vol. 320, pp. 197–
219. EPTCS (2020)
37. Schulz, S., Cruanes, S., Vukmirovi´c, P.: Faster, higher, stronger: E 2.3. In: Fontaine,
P. (ed.) CADE 2019. LNCS (LNAI), vol. 11716, pp. 495–507. Springer, Cham
(2019). https://doi.org/10.1007/978-3-030-29436-6 29
38. Sutcliﬀe, G.: The TPTP problem library and associated infrastructure - from CNF
to TH0, TPTP v6.4.0. J. Autom. Reason. 59(4), 483–502 (2017)
39. Urbani, J., Jacobs, C., Kr¨otzsch, M.: Column-oriented Datalog materialization for
large knowledge graphs. In: Schuurmans, D., Wellman, M.P. (eds.) Proceedings of
the 30th AAAI Conference on Artiﬁcial Intelligence (AAAI 2016), pp. 258–264.
AAAI Press (2016)

24
M. Bromberger et al.
40. Urbani, J., Kr¨otzsch, M., Jacobs, C., Dragoste, I., Carral, D.: Eﬃcient model con-
struction for horn logic with VLog. In: Galmiche, D., Schulz, S., Sebastiani, R.
(eds.) IJCAR 2018. LNCS (LNAI), vol. 10900, pp. 680–688. Springer, Cham (2018).
https://doi.org/10.1007/978-3-319-94205-6 44
41. Weidenbach, C., Dimova, D., Fietzke, A., Kumar, R., Suda, M., Wischnewski,
P.: SPASS version 3.5. In: Schmidt, R.A. (ed.) CADE 2009. LNCS (LNAI), vol.
5663, pp. 140–145. Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-
642-02959-2 10

Non-disjoint Combined Uniﬁcation and
Closure by Equational Paramodulation
Serdar Erbatur1
, Andrew M. Marshall2
, and Christophe Ringeissen3(B)
1 University of Texas at Dallas, Richardson, USA
2 University of Mary Washington, Fredericksburg, USA
3 Universit´e de Lorraine, CNRS, Inria, LORIA, 54000 Nancy, France
Christophe.Ringeissen@loria.fr
Abstract. Closure properties such as forward closure and closure via
paramodulation have proven to be very useful in equational logic, espe-
cially for the formal analysis of security protocols. In this paper, we
consider the non-disjoint uniﬁcation problem in conjunction with these
closure properties. Given a base theory E, we consider classes of theory
extensions of E admitting a uniﬁcation algorithm built in a hierarchi-
cal way. In this context, a hierarchical uniﬁcation procedure is obtained
by extending an E-uniﬁcation algorithm with some additional inference
rules to take into account the rest of the theory. We look at hierar-
chical uniﬁcation procedures by investigating an appropriate notion of
E-constructed theory, deﬁned in terms of E-paramodulation. We show
that any E-constructed theory with a ﬁnite closure by E-paramodulation
admits a terminating hierarchical uniﬁcation procedure. We present
modularity results for the uniﬁcation problem modulo the union of E-
constructed theories sharing only symbols in E. Finally, we also give suf-
ﬁcient conditions for obtaining terminating (combined) hierarchical uni-
ﬁcation procedures in the case of regular and collapse-free E-constructed
theories.
1
Introduction
Uniﬁcation plays a central role in all logic-based tools using the resolution prin-
ciple, for instance to perform new deductions using superposition and paramod-
ulation inferences implemented in equational provers. Both superposition and
paramodulation aim at deducing a new equality from two equalities that can
overlap via (syntactic) uniﬁcation. In this context, a syntactic uniﬁcation algo-
rithm computing a most general uniﬁer is ubiquitous. More generally, we may
consider equational uniﬁcation, where the problem is deﬁned modulo an equa-
tional theory E, such as the famous example of Associativity-Commutativity.
Equational uniﬁcation, called E-uniﬁcation, is undecidable in general, but uni-
ﬁcation algorithms are known for particular classes, like for instance: (1) the
class SH of shallow theories [8] deﬁned by axioms whose variables can occur
at depth at most 1; (2) the class PC of theories with a ﬁnite paramodulation
closure [21]; (3) the class FVP of theories deﬁned by convergent term rewrite
systems with the Finite Variant Property [9,17]. FVP and PC can be related
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 25–42, 2021.
https://doi.org/10.1007/978-3-030-86205-3_2

26
S. Erbatur et al.
since FVP coincides with the class FC of theories with a ﬁnite forward clo-
sure [6], a particular closure similar to paramodulation closure but dedicated
to convergent terms rewrite systems. SH , PC, and FVP are particular classes
of syntactic theories (see respectively [8], [21], [11]). When a theory is syntac-
tic [20,25], it is possible to apply a rule-based uniﬁcation procedure extending
the one known for syntactic uniﬁcation with some additional mutation rules. In
general, being syntactic is not a suﬃcient condition to ensure the termination of
this uniﬁcation procedure. Fortunately, SH , PC, and FVP admit terminating
instances of this mutation-based uniﬁcation procedure (see respectively [8], [21],
[11]).
In many practical applications, E is a component in a union of theories, say
F ∪E. In that case, it is quite natural to solve the F ∪E-uniﬁcation problem in a
modular way thanks to the uniﬁcation algorithms known for F and for E. There
are terminating and complete combination procedures when F and E have dis-
joint signatures [3,27]. These combination procedures can be extended to some
non-disjoint unions of theories sharing only constructor symbols, but it is quite
diﬃcult to identify particular cases where these procedures terminate [10,26]. A
terminating case has been identiﬁed in [5] by investigating a notion of bounded
theory over the constructor symbols. More recently, a hierarchical uniﬁcation
approach [11,12,15] has been initiated when F ∪E-uniﬁcation can be considered
as a conservative extension of E-uniﬁcation while some symbols of E may occur
as constructors in F. In that scenario, hierarchical uniﬁcation consists in using
an E-uniﬁcation algorithm plus some mutation-based uniﬁcation procedure to
manage the remaining part of F ∪E. In [15], we have shown that the hierarchi-
cal uniﬁcation approach is particularly well-suited to tackle E-convergent term
rewrite systems in which all the symbols in E are constructors. In particular,
it is possible to get a terminating hierarchical uniﬁcation procedure when such
constructed-based rewrite system has a ﬁnite forward closure [11].
In this paper, we investigate the possible use of hierarchical uniﬁcation
for a class of theories deﬁned via an E-paramodulation closure, where E-
paramodulation generalizes the classical paramodulation inference by replac-
ing syntactic uniﬁcation with E-uniﬁcation. In that direction, we introduce the
notion of E-syntacticness, a useful property to study a possible mutation-based
uniﬁcation procedure modulo the base theory E. To obtain a complete hierar-
chical uniﬁcation procedure, it is required that the E-uniﬁcation algorithm is
applicable without loss of completeness to solve any F ∪E-uniﬁcation prob-
lem expressed over the signature of E. To fulﬁll this requirement, we intro-
duce the class of E-constructed theories. These theories are deﬁned using E-
paramodulation and generalize the E-convergent term rewrite systems for which
all the symbols of E are constructors. The class of E-constructed theories is
particularly interesting in the context of non-disjoint combination. Actually, a
union of E-constructed theories sharing only E is a union of non-disjoint theories
without any overlap between the component theories. We study two classes of
E-constructed theories: (i) a class of regular collapse-free E-constructed theories
F such that F ∪E admits a hierarchical uniﬁcation algorithm; (ii) the class

Combined Uniﬁcation and Closure by Equational Paramodulation
27
of E-constructed theories closed by E-paramodulation. We show the following
modularity result: let C be any class (i) or (ii), if F1 and F2 are two theories in C
sharing only the symbols in E, then F1 ∪F2 is a theory in C. In both cases, there
exists a hierarchical uniﬁcation algorithm for F1 ∪F2 ∪E. Compared to [15], we
consider equational theories that are not necessarily presented by E-convergent
term rewrite systems, and we go beyond the subterm collapse-free assumption
of [15]. For example, in the class (i) the combined hierarchical uniﬁcation algo-
rithm applies without loss of completeness to theories that are assumed to be
regular and collapse-free but not necessarily subterm collapse-free. The regular-
ity and the collapse-freeness of a theory is trivially checked by examining its
axioms, while the subterm collapse-freeness is a property that can be diﬃcult to
check.
Motivating Examples from Security Protocols. Let us consider a theory used in
practice to model a group messaging protocol [7]. For this protocol, the theory
modeling the intruder can be deﬁned [24] as a combination R=
ENC ∪K where
K = {keyexch(x, pk(x′), y, pk(y′)) = keyexch(x′, pk(x), y′, pk(y))}, and
R=
ENC =

adec(aenc(m, pk(sk)), sk) = m
checksign(sign(m, sk), m, pk(sk)) = ok
getmsg(sign(m, sk)) = m
sdec(senc(m, k), k) = m

The equational theories R=
ENC and K share the absolutely free constructor
pk and they are both closed by paramodulation. Thanks to a modularity result
developed in this paper, we can show that R=
ENC ∪K is closed by paramodulation
too. Thus, R=
ENC ∪K admits a (hierarchical) uniﬁcation algorithm.
Let us now consider a theory for dealing with member keys in a group of
users and an overall group key [22]. Member keys can be kept in a tree like
structure with the group key being the root. A pick function is included to
retrieve the group key. In [22], the group is modeled thanks to a constructor
with some equational properties, ideally a set union operator. Here, we con-
sider E1 = {pick(x, tree(y, x ∪m)) = y, add(x, tree(y, m)) = tree(y, x ∪m)}
where ∪is an AC-constructor used to build multisets. This theory is closed
by AC-paramodulation, and so it admits a hierarchical uniﬁcation algorithm
built over an AC-uniﬁcation algorithm. To model homomorphic encryption or
exponentiation, we can use axioms such as e(x ∗y, z) = e(x, z) ∗e(y, z) and
e(e(x, y), z) = e(x, y ⊛z), where ⊛is an AC-symbol. In [15], it has been shown
that two distributive theories including these axioms admit a hierarchical uniﬁca-
tion algorithm. These regular and collapse-free theories satisfy the assumptions
needed to get a terminating combined uniﬁcation procedure.
Outline. After this introduction and the next section on preliminaries, the
paper is organized as follows. Section 3 presents the E-paramodulation closure
and then the E-constructed theories. In Sect. 4, we introduce the notion of
E-syntacticness. In Sect. 5, a hierarchical uniﬁcation procedure is given as a
rule-based system including some classical puriﬁcation rules, an E-uniﬁcation
algorithm encapsulated in a solving rule, plus a couple of mutation rules.

28
S. Erbatur et al.
The uniﬁcation problem and the related modularity properties are investigated
in Sect. 6 for the class (i) and in Sect. 7 for the class (ii). Omitted proofs can be
found in [16].
2
Preliminaries
We use the standard notation of equational uniﬁcation [4] and term rewriting
systems [1]. Given a ﬁrst-order signature Σ and a (countable) set of variables
V , the set of Σ-terms over variables V is deﬁned in the usual way. The set of
variables in a term t is denoted by Var(t). A term t is ground if Var(t) = ∅.
For any position p in a term t (including the root position ϵ), t(p) is the symbol
at position p, t|p is the subterm of t at position p, and t[u]p is the term t
in which t|p is replaced by u. A substitution is an endomorphism of the Σ-
structure of terms over V such that only ﬁnitely many variables are not mapped
to themselves, denoted by σ = {x1 →t1, . . . , xm →tm}, where the domain
and the range of σ are respectively Dom(σ) = {x1, . . . , xm} and Ran(σ) =
{t1, . . . , tm}. Application of a substitution σ to t is written tσ.
Equational Theories. Given a set E of Σ-axioms (i.e., pairs of Σ-terms, denoted
by l = r), the equational theory =E is the congruence closure of E under the law
of substitutivity (by a slight abuse of terminology, E is often called an equational
theory). Equivalently, =E can be deﬁned as the reﬂexive transitive closure ↔∗
E
of an equational step ↔E deﬁned as follows: s ↔E t if there exist a position p of
s, l = r (or r = l) in E, and substitution σ such that s|p = lσ and t = s[rσ]p. An
axiom l = r is regular if Var(l) = Var(r). An axiom l = r is collapse-free if l and
r are non-variable terms. An equational theory is regular (resp., collapse-free) if
all its axioms are regular (resp., collapse-free). A term t is subterm collapse-free
modulo E if it is not the case that t =E u where u is any strict subterm of t.
An equational theory E is subterm collapse-free if for any term t, t is subterm
collapse-free modulo E.
A theory E is syntactic if it has a ﬁnite resolvent presentation S, deﬁned
as a ﬁnite set of axioms S such that each equality t =E u has an equational
proof t ↔∗
S u with at most one equational step ↔S applied at the root position.
One can easily check that C = {x ∗y = y ∗x} (Commutativity) and AC =
{x∗(y ∗z) = (x∗y)∗z, x∗y = y ∗x} (Associativity-Commutativity) are regular,
collapse-free, and linear (variables occur only once). Moreover, C and AC are
syntactic [20]. An axiom l = r is shallow if variables can only occur at a position
at depth at most 1 in both l and r. An equational theory is shallow if all its
axioms are shallow. For example, C is shallow, but A is not. It has been shown
in [8] that shallow theories are syntactic.
Equational Uniﬁcation. A Σ-equation is a pair of Σ-terms denoted by s =? t or
simply s = t when it is clear from the context that we do not refer to an axiom.
A ﬂat Σ-equation is either an equation between variables or a non-variable ﬂat
Σ-equation of the form x0 = f(x1, . . . , xn) where x0, x1, . . . , xn are variables and

Combined Uniﬁcation and Closure by Equational Paramodulation
29
f is a function symbol in Σ. An E-uniﬁcation problem is a set of Σ-equations,
G = {s1 =? t1, . . . , sn =? tn}, or equivalently a conjunction of Σ-equations. The
set of variables in G is denoted by Var(G). A solution to G, called an E-uniﬁer,
is a substitution σ such that siσ =E tiσ for all 1 ≤i ≤n, written E |= Gσ. A
substitution σ is more general modulo E than θ on a set of variables V , denoted
as σ ≤V
E θ, if there is a substitution τ such that xστ =E xθ for all x ∈V . σ|V
denotes the substitution σ restricted to the set of variables V . A Complete Set
of E-Uniﬁers of G, denoted by CSUE(G), is a set of substitutions such that
each σ ∈CSUE(G) is an E-uniﬁer of G, and for each E-uniﬁer θ of G, there
exists σ ∈CSUE(G) such that σ ≤Var(G)
E
θ. An E-uniﬁcation algorithm is an
algorithm that computes a ﬁnite CSUE(G) for all E-uniﬁcation problems G.
An inference rule G ⊢G′ for E-uniﬁcation is sound if each E-uniﬁer of G′ is
an E-uniﬁer of G; and complete if for each E-uniﬁer σ of G, there exists an
E-uniﬁer σ′ of G′ such that σ′ ≤Var(G)
E
σ. An inference system for E-uniﬁcation
is sound if all its inference rules are sound; and complete if for each E-uniﬁcation
problem G on which an inference applies and each E-uniﬁer σ of G, there exist
an E-uniﬁcation problem G′ inferred from G and an E-uniﬁer σ′ of G′ such that
σ′ ≤Var(G)
E
σ. Thus, the set of E-uniﬁers is preserved by a sound and complete
inference system for E-uniﬁcation. The deﬁnition of complete inference system
adopted here allows us to take into account the rules that need to be applied
with a don’t know nondeterministic choice in order to preserve the set of E-
uniﬁers. When a don’t know nondeterminism is necessary to apply some rules,
we mention it explicitly. By default, the inference rules are applied using a don’t
care nondeterminism: when several rules are applicable, it is suﬃcient to apply
one of them.
A set of equations G = {x1 =? t1, . . . , xn =? tn} is said to be in tree
solved form if each xi is a variable occurring once in G. Given an idempotent
substitution σ = {x1 →t1, . . . , xn →tn} (such that σσ = σ), ˆσ denotes the
corresponding tree solved form. A set of equations is said to be in dag solved
form if they can be arranged as a list x1 =? t1, . . . , xn =? tn where (a) each
left-hand side xi is a distinct variable, and (b) ∀1 ≤i ≤j ≤n: xi does not
occur in tj. A set of equations {x1 =? t1, . . . , xn =? tn} is a cycle if for any
i ∈[1, n −1], xi+1 ∈Var(ti), x1 ∈Var(tn), and there exists j ∈[1, n] such that
tj is not a variable. Given two disjoint signatures Σ0 and Σ1 and any i = 1, 0,
Σi-terms (including the variables) and Σi-equations (including the equations
between variables) are called Σi-pure. A term t is called a Σi-rooted term if its
root symbol is in Σi. An alien subterm of a Σi-rooted term t is a Σj-rooted
subterm s of t (i ̸= j) such that all superterms of s are Σi-rooted. Given a
Σ0-theory E, a theory F ∪E is a conservative extension of E if =F ∪E and =E
coincide on Σ0-terms. When F ∪E is a conservative extension of E, E-uniﬁcation
is said to be complete for solving the Σ0-fragment of F ∪E-uniﬁcation if for any
Σ0-pure F ∪E-uniﬁcation problem G, any CSUE(G) is a CSUF∪E(G). If F and
E have disjoint signatures, E-uniﬁcation is known to be complete for solving the
Σ0-fragment of F ∪E-uniﬁcation.

30
S. Erbatur et al.
Equational Rewrite Relations. Given a signature Σ, an oriented Σ-axiom is
called a rewrite rule of the form l →r if l is not a variable and Var(r) ⊆Var(l).
Given a set R of rewrite rules and an Σ-equational theory E, A term s R, E-
rewrites to a term t, denoted by s →R,E t, if there exist a position p of s,
l →r ∈R, and substitution σ such that s|p =E lσ and t = s[rσ]p. The term
s is said to be R, E-reducible, and s|p is called a redex. The symmetric relation
←R,E ∪→R,E ∪=E is denoted by ←→R∪E. The rewrite relation →R,E is
Church-Rosser modulo E if ←→∗
R∪E is included in →∗
R,E ◦=E ◦←∗
R,E. When
=E ◦→R,E ◦=E is terminating, the following properties are equivalent [18]:
(1) →R,E is Church-Rosser modulo E; (2) for any terms t, t′, t ←→∗
R∪E t′ if and
only if t ↓=E t′ ↓, where t ↓(resp., t′ ↓) denotes any normal form w.r.t →R,E
of t (resp., t′). The rewrite relation →R,E is E-convergent if =E ◦→R,E ◦=E
is terminating and →R,E is Church-Rosser modulo E. A function symbol that
does not occur in {l(ϵ) | l →r ∈R} is called a constructor for R. Let Σ0 be the
subsignature of Σ that consists of all function symbols occurring in the axioms
of E. An E-convergent rewrite relation →R,E is said to be E-constructed if all
symbols in Σ0 are constructors for R. When →R,E is clear from the context, a
normal form w.r.t →R,E is said to be normalized. A substitution σ is normalized
if, for every variable x in the domain of σ, xσ is normalized. An instance lσ →rσ
of a rule l →r ∈R is a right-reduced instance if σ|V ar(r) is normalized. A term
t is an innermost redex if no subterm of t is a redex. An E-convergent →R,E is
IR1 if every innermost redex is R, E-reducible to a normal form in one step.
When R is a ﬁnite set of rules, the pair (R, E) is called an equational term
rewrite system (TRS). We say that a property is satisﬁed by an equational TRS
(R, E) if this property is satisﬁed by →R,E. Given a TRS (R, E), R= denotes
the set of equalities {l = r | l →r ∈R}, and R= ∪E is the equational theory of
(R, E). For sake of brevity, we may use R ∪E instead of R= ∪E.
To simplify the notation, we often use tuples of terms, like ¯u = (u1, . . . , un),
¯v = (v1, . . . , vn). Applying a substitution σ to ¯u is the tuple ¯uσ = (u1σ, . . . , unσ).
The tuples ¯u and ¯v are said to be E-equal, denoted by ¯u =E ¯v, if u1 =E
v1, . . . , un =E vn. Similarly, ¯u →∗
R ¯v if u1 →∗
R v1, . . . , un →∗
R vn, ¯u is normalized
if u1, . . . , un are normalized, and ¯u =? ¯v is {u1 =? v1, . . . , un =? vn}.
3
Closure by Equational Paramodulation
From now on, let E be a regular and collapse-free Σ0-theory, and F a Σ-theory
such that Σ0 ⊆Σ. We assume a reduction ordering > on terms such that
> is E-compatible, meaning that s′ =E s > t =E t′ implies s′ > t′. It is
important to note that a single reduction ordering > is used even in the context
of a union of theories. In that case, > is assumed to be deﬁned on terms built
over the combined signature. Given a set of equalities F, Gr(F) denotes the
set of ground instances of F. A set F of ground equalities is >-orientable if
each equality in F can be oriented into a rule l →r such that l > r and l is
Σ\Σ0-rooted. A set F of equalities is >-orientable if Gr(F) is >-orientable. A
ground equality s = t is optimally joinable w.r.t a >-orientable set F of ground

Combined Uniﬁcation and Closure by Equational Paramodulation
31
equalities if for F > = {l →r | l > r, l = r or r = l in F} there exists a rewrite
proof s →∗
F >,E s′ =E t′ ←∗
F >,E t for which each rewrite step u →F >,E v in
s →∗
F >,E s′ and in t →∗
F >,E t′ is applied at a position p such that u|p is an
innermost redex and v|p is in normal form w.r.t →F >,E. An equality s = t is
optimally joinable w.r.t a >-orientable set F of equalities if each ground instance
of s = t is optimally joinable w.r.t Gr(F). Given a ﬁnite set of equalities F,
the E-paramodulation closure of F is inductively deﬁned as follows as a partial
function:
—If F is >-orientable, then PC0(F) = F; otherwise PC0(F) is undeﬁned.
—For any k ≥0, assume PCk(F) is deﬁned. Let PE be the set of all equalities
e obtained by:
E-Paramodulation g = d[l′], l = r ⊢(g = d[r])σ
where l′ is not a variable, σ ∈CSUE(l′ =? l), and lσ ̸< rσ
using premises in PCk(F) and such that e is not optimally joinable w.r.t
PCk(F). If PE is >-orientable, then PCk+1(F) = PCk(F) ∪PE; otherwise
PCk+1(F) is undeﬁned. If PCk(F) is deﬁned for any k ≥0, then PC(F) =

k≥0 PCk(F); otherwise PC(F) is undeﬁned.
Example 1. Consider the equational theory E2 = {rm(x, x ∪m) = m} where ∪
is an AC-symbol. Notice that the left-to-right orientation of E2 provides an AC-
compatible reduction ordering for which we have PC(E2) = E2 because there is
no non-variable overlap between a left-hand side of a rule and a right-hand side.
Deﬁnition 1 (E-constructed theory). Let E be a regular and collapse-free
theory. A ﬁnite set of equalities F is said to be an E-constructed theory if there
exists an E-compatible reduction ordering > such that PC(F) is deﬁned; F is
closed by E-paramodulation if PC(F) = F.
Given an E-constructed theory F and Gr = Gr(PC(F)), we deﬁne the fol-
lowing sets of ground rules for any s = t or t = s in Gr such that s > t:
– Is=t =
∅,
if s or t is R<s=t, E-reducible
{s →t}, otherwise
– R<s=t = 
(u=v)<(s=t) Iu=v, where the equalities are ordered by treating them
as multisets of terms: (u = v) < (s = t) iﬀ{s, t} is strictly greater than {u, v}
w.r.t the multiset extension of >,
– RF = 
s=t∈Gr Is=t.
Theorem 1. Let RF be the set of ground rules introduced in Deﬁnition 1 for
an E-constructed theory F. Then, all the symbols of E are constructors for RF ,
the rewrite relation →RF ,E is E-convergent on ground terms and for any ground
terms s, t, s =F ∪E t iﬀs ↓RF ,E=E t ↓RF ,E.
Proof (Sketch). Assume →RF ,E is not Church-Rosser modulo E on ground
terms. In that case, there exists a non-joinable critical pair possibly generated
by E-Paramodulation, provided that it is not optimally joinable. This crit-
ical pair cannot be optimally joinable, otherwise it would be joinable. Thus
E-Paramodulation applies, and this contradicts the deﬁnition of RF .
⊓⊔

32
S. Erbatur et al.
Note that we overlap with non-maximal sides in E-Paramodulation. This
allows us to build a rewrite relation →RF ,E which is both E-convergent and IR1.
The next lemma is a direct consequence of Deﬁnition 1.
Lemma 1. Let (R, E) be any E-constructed TRS and > the reduction ordering
deﬁned by s > t if s →+
R,E t. Then, R= is an E-constructed theory. If →R,E is
IR1, then R= is an E-constructed theory closed by E-paramodulation.
Lemma 1 provides us a way to get an E-constructed theory closed by E-
paramodulation starting from any forward-closed E-constructed TRS since any
E-constructed TRS is forward-closed iﬀit is IR1 [15,19].
Lemma 2. If F is an E-constructed theory, then E-uniﬁcation is complete for
solving the Σ0-fragment of F ∪E-uniﬁcation.
A proof of Lemma 2 is developed in [16].
Example 2. Consider the Group Keys example from Sect. 1. Since E1 is closed by
AC-paramodulation E1 = PC(E1). In addition, since Σ0 = {∪}, the conditions
of Deﬁnition 1 are satisﬁed. Orienting the rule of E1 from left to right we obtain
a ground AC-convergent system →E1,AC. Finally, from Lemma 1 we have an
AC-constructed theory.
4
Equational Syntacticness
In this section, we introduce an equational extension of the classical notion of
syntactic theory.
Deﬁnition 2 (E-syntactic theory). Consider a Σ0-theory E and a Σ-theory
F ∪E. Let S be a ﬁnite set of F ∪E-equalities l = r such that l or r is Σ\Σ0-
rooted. The set S is said to be an E-resolvent presentation of F ∪E if for any F ∪
E-equality t =F ∪E t′ there exists an equational proof t ↔∗
S∪E t′ with the following
property: if there is an S-equational step applied at the root position, then it is
the only S ∪E-equational step applied at the root position. The equational theory
F ∪E is said to be E-syntactic if there exists an E-resolvent presentation of
F ∪E.
When E is the empty theory over an empty signature Σ0, an E-syntactic
theory (resp., an E-resolvent presentation) corresponds to the classical deﬁnition
of a syntactic theory (resp., a resolvent presentation) [20,25].
Lemma 3. Assume F ∪E is E-syntactic. Consider any terms ¯s, ¯t and any
function symbols f, g such that f(¯s) or g(¯t) is Σ\Σ0-rooted. Then, f(¯s) =F ∪E
g(¯t) iﬀeither f, g ∈Σ\Σ0, f = g and ¯s =F ∪E ¯t, or there exist f(¯l) = g(¯r) ∈S
and a substitution σ such that ¯s =F ∪E ¯lσ and ¯t =F ∪E ¯rσ.

Combined Uniﬁcation and Closure by Equational Paramodulation
33
Proof. This follows from Deﬁnition 2. Consider the proof of f(¯s) =S∪E g(¯t)
where S is the E-resolvent presentation of F ∪E. Since S is an E-resolvent
presentation and f(¯s) or g(¯t) is Σ\Σ0-rooted, there can only be one or no S-
equational steps at the root position and no E-equational steps. If there is no
S-equational step at the root position, then f = g and ¯s =S∪E ¯t which implies
¯s =F ∪E ¯t. If there is an S-equational step at the root position, then it is the
only step applied at the root position. Thus, there exist f(¯l) = g(¯r) ∈S and a
substitution σ such that ¯s =S∪E ¯lσ and ¯t =S∪E ¯rσ, which implies the result. ⊓⊔
The following lemma states the connection between syntacticness and the
partial form of syntacticness represented by E-syntacticness.
Lemma 4. Let F be any E-constructed theory. Then, F ∪E is syntactic iﬀ
F ∪E is E-syntactic and E is syntactic.
Proof. For both directions, we proceed by induction on the size of F ∪E-
equalities, where the size of an equality is deﬁned as the number of function
symbols occurring in the equality.
For the only-if direction, consider SF ∪E is a resolvent presentation of a
theory F ∪E such that F is E-constructed. Let SE = {l = r | l = r ∈
SF ∪E, and l, r are Σ0-terms}. By induction on the size of F ∪E-equalities
between Σ0-terms, we can prove that, for any t =F ∪E t′ where t and t′ are Σ0-
terms, there exists an equational proof t ←→∗
SE t′ with at most one step applied
at the root position. Since =E and =F ∪E coincide on Σ0-terms, SE is resolvent
presentation of E. Let S = {l = r | l = r ∈SF ∪E, {l(ϵ), r(ϵ)} ∩(Σ\Σ0) ̸= ∅}.
Since F is E-constructed, there exist some particular F ∪E-equational proofs
(cf. [16]) which permit us to prove the following statement by induction on the
size of F ∪E-equalities: for any t =F ∪E t′ there exists an equational proof
t ←→∗
S∪E t′ such that any S-equational step applied at the root position is nec-
essarily the unique S ∪E-equational step applied at the root position. Therefore,
S is an E-resolvent presentation of F ∪E.
For the if-direction, consider SE is a resolvent presentation of E and S is an
E-resolvent presentation of a theory F ∪E such that F is E-constructed. Let
SF ∪E = S ∪SE. Thanks to the same particular F ∪E-equational proofs as the
ones used above (cf. [16]), we can prove the following statement by induction on
the size of F ∪E-equalities: for any t =F ∪E t′ there exists an equational proof
t ←→∗
SF ∪E t′ with at most one step applied at the root position. Therefore, SF ∪E
is a resolvent presentation of F ∪E.
⊓⊔
5
Hierarchical Uniﬁcation
We present a general result to build a hierarchical uniﬁcation procedure for
E-syntactic theories. The rules in Fig. 1 provide the skeleton of the type of
hierarchical procedure we are looking for. The procedure is parameterized by
an E-uniﬁcation algorithm and an inference system U like the one given in

34
S. Erbatur et al.
Fig. 2. The rules, Coalesce, Split, Flatten, and VA are used to separate the
equations, U is used to simplify the Σ\Σ0-equations, and ﬁnally, Solve, is used
to apply the E-uniﬁcation algorithm on Σ0-equations.
Coalesce {x = y} ∪G
x = y} ∪(G{x
y})
where x and y are distinct variables occurring both in G.
Split {f(¯v) = t} ∪G
x = f(¯v), x = t} ∪G
where f ∈Σ\Σ0, t is a non-variable term and x is a fresh variable.
Flatten {v = f(. . . , u, . . . )} ∪G
v = f(. . . , x, . . . ), x = u} ∪G
where f ∈Σ\Σ0, v is a variable, u is a non-variable term, and x is a fresh variable.
VA {s = t[u]} ∪G
s = t[x], x = u} ∪G
where t is Σ0-rooted, u is an alien subterm of t, and x is a fresh variable.
Solve G ∪G0
G ∪ˆσ0
where G is a set of Σ\Σ0-equations, G0 is a set of Σ0-equations, G0 is E-uniﬁable and
not in tree solved form, ˆσ0 is the tree solved form associated to σ0 ∈CSUE(G0), and
w.l.o.g for any x ∈Dom(σ0), xσ0 ∈Var(G0) if xσ0 is a variable.
Fig. 1. HE rules
Dec {x = f(¯v), x = f( ¯w)} ∪G
x = f(¯v), ¯v = ¯w} ∪G
where f ∈Σ\Σ0.
MutS {x = f(¯v), x = g( ¯w)} ∪G
x = f(¯v), ¯v = ¯l, ¯w = ¯r} ∪G
where f(¯l) = g(¯r) ∈S.
Fig. 2. DMS rules
Deﬁnition 3 (Hierarchical uniﬁcation procedure).
Assume a Σ0-theory
E, an E-uniﬁcation algorithm computing a ﬁnite CSUE(G0) for all E-uniﬁcation
problems G0, a Σ-theory F ∪E for which E-uniﬁcation is complete for solving
the Σ0-fragment of F ∪E-uniﬁcation, and an inference system U satisfying the
following assumptions: U transforms only non-variable ﬂat Σ\Σ0-equations; U
is sound and complete for F ∪E-uniﬁcation; U is parameterized by some ﬁnite
set S of F ∪E-equalities such that the soundness of each inference ⊢U follows
from at most one equality in S. Under these assumptions, HE(U) is the inference
system deﬁned as the repeated application of some inference from HE (cf. Fig. 1)
or U, using the following order of priority: Coalesce, Split, Flatten, VA, U,
Solve. An F ∪E-uniﬁcation problem is separate, also called in separate form,
if it is a normal form w.r.t HE\{Solve}. HE(U) is a hierarchical uniﬁcation
procedure for F ∪E if the F ∪E-uniﬁable normal forms w.r.t HE(U) are the
separate dag solved forms.

Combined Uniﬁcation and Closure by Equational Paramodulation
35
Note that when we speak of an inference system, U, this is not just a set
of rules but also a strategy for apply those rules, for instance to avoid non-
termination [13]. The theory-speciﬁc rules in {Solve} ∪U are applied using a
don’t know nondeterminism. From now on, an inference system HE(U) always
denotes a hierarchical uniﬁcation procedure.
Lemma 5. Any hierarchical uniﬁcation procedure for F ∪E is a sound and
complete F ∪E-uniﬁcation procedure.
Proof. Let HE(U) be a hierarchical uniﬁcation procedure as given in Deﬁnition 3.
All the rules in HE\{Solve} are always sound and complete, independently from
the underlying equational theory. By assumption on F∪E and U, HE(U) is sound
and complete. Since the F ∪E-uniﬁable normal forms w.r.t HE(U) are assumed
to be the separate dag solved forms, collecting all the separate dag solved forms
reached by HE(U) provides a complete set of F ∪E-uniﬁers.
⊓⊔
It will now be useful to consider an E-syntactic theory F ∪E for which all
the Σ\Σ0-rooted terms are subterm collapse-free modulo F ∪E. This allows us
to get a possible instantiation of the hierarchical uniﬁcation procedure.
Lemma 6. Assume a Σ0-theory E, an E-uniﬁcation algorithm, a Σ-theory
F ∪E such that F is E-constructed, F ∪E is E-syntactic with an E-resolvent
presentation S, and all the Σ\Σ0-rooted terms are subterm collapse-free mod-
ulo F ∪E. Given E, F ∪E and DMS the inference system from Fig. 2, all the
assumptions of Deﬁnition 3 are satisﬁed to get a hierarchical uniﬁcation pro-
cedure HE(DMS), and HE(DMS) is a sound and complete F ∪E-uniﬁcation
procedure.
Proof. By Lemma 2, Solve is sound and complete. By Lemma 3, DMS is sound
and complete. Moreover, the soundness of each inference rule in DMS follows
from at most one equality in S.
Consider any separate form G1 ∧G0 containing a cycle with at least one
equation in G1. By assumption, this cycles has no solution in F ∪E. Conse-
quently, the separate dag solved forms are the F ∪E-uniﬁable normal forms
w.r.t HE(DMS). Hence, all the assumptions of Deﬁnition 3 are satisﬁed and
Lemma 5 applies.
⊓⊔
In Lemma 6, one can notice that E is necessarily collapse-free and E-
uniﬁcation is ﬁnitary. So, E is syntactic according to [20]. By Lemma 4, F ∪E
is not only E-syntactic but syntactic when Lemma 6 applies.
In the following, we focus on combinations of E-constructed theories admit-
ting terminating hierarchical uniﬁcation procedures. The case of regular and
collapse-free E-constructed theories is studied in Sect. 6. The class of E-
constructed theories closed by E-paramodulation is considered in Sect. 7.

36
S. Erbatur et al.
6
Combination of Regular Collapse-Free Theories
In this section we extend the approach initiated in [15] moving from the restricted
case of subterm collapse-free theories to the less restrictive regular and collapse-
free theories. Let us consider a union F1 ∪F2 ∪E of regular collapse-free theories
such that F1 and F2 are E-constructed theories. The signatures of E, F1 and F2
are respectively denoted by Σ0, Σ1 and Σ2. The theories F1 and F2 are assumed
to share only the symbols of E, meaning that Σ0 = Σ1 ∩Σ2. We can show that,
for any i = 1, 2, Fi ∪E-uniﬁcation is complete for solving the Σi-fragment of
F1 ∪F2 ∪E-uniﬁcation (cf. [16]). This paves the way of building a combined
procedure for F1 ∪F2 ∪E, but some additional restrictions on F1 ∪F2 ∪E are
needed. The theory F1∪F2∪E is said to be a simple combination if the following
two conditions hold: First, for any Σ1\Σ0-rooted term t1 and any Σ2\Σ0-rooted
term t2, t1 cannot be equal to t2 modulo F1 ∪F2 ∪E. Second, for any term t
and any position p in t such that 
q≤p{t(q)} contains at least both a symbol in
Σ1\Σ0 and a symbol in Σ2\Σ0, t cannot be equal to t|p modulo F1 ∪F2 ∪E.
These two conditions mean that there are no solutions to conﬂicts of theories
and no solutions to compound cycles. Let us now introduce a technical lemma
which is useful to get a hierarchical uniﬁcation procedure for F1 ∪F2 ∪E.
Lemma 7. Let Σ1 and Σ2 be two signatures such that Σ0 = Σ1 ∩Σ2. Consider
E is a Σ0-theory and for i = 1, 2, Fi is an E-constructed Σi-theory such that
Fi ∪E admits a sound and complete uniﬁcation procedure of the form HE(Ui).
If F1 ∪F2 ∪E is a simple combination, then we have that
– HE(U1 ∪U2) is a sound and complete F1 ∪F2 ∪E-uniﬁcation procedure,
– if for i = 1, 2, Si is an E-resolvent presentation of Fi ∪E, then S1 ∪S2 is an
E-resolvent presentation of (F1 ∪F2) ∪E.
Proof. According to the assumptions, any normal form w.r.t HE(U1 ∪U2) is
F1 ∪F2 ∪E-uniﬁable iﬀit is in dag solved form. Then, Lemma 5 applies.
Assume now Si is an E-resolvent presentation of Fi ∪E for i = 1, 2. In that
case, S1 ∪S2 is an E-resolvent presentation of (F1 ∪F2)∪E since by assumption
it is not possible to have t1 =F1∪F2∪E t2 for some Σ1\Σ0-rooted term t1 and
some Σ2\Σ0-rooted term t2.
⊓⊔
We study below a possible way to satisfy the assumptions of Lemma 7, thanks
to a property on the shape of normal forms.
Deﬁnition 4 (E-capped theory). Let F be an E-constructed theory over the
signature Σ. A Σ-term t is said to be E-capped if there exist a constant-free Σ0-
term u and a substitution σ such that t = uσ, Dom(σ) = V ar(u) and Ran(σ) is
a set of Σ\Σ0-rooted terms. The E-constructed theory F is said to be E-capped
if any normal form w.r.t →RF ,E of any Σ\Σ0-rooted ground term is E-capped.
In Deﬁnition 4, the term u can be a variable, to take into account the case
where the normal form of a Σ\Σ0-rooted ground term remains Σ\Σ0-rooted.

Combined Uniﬁcation and Closure by Equational Paramodulation
37
Example 3. Consider Σ0 = {∗} and the Σ0-theory E deﬁned by an emptyset of
Σ0-axioms.
First, let (RD, E) be the E-constructed TRS where RD = {h(x ∗y) →h(x) ∗
h(y)}. The term h(x)∗h(y) is E-capped because h(x)∗h(y) = uσ for the Σ0-term
with no constants u = v ∗w and the substitution σ = {v →h(x), w →h(y)}.
Notice that h(x) is also E-capped since h(x) = uσ for u = v and σ = {v →h(x)}.
By induction on the length of outermost derivations, we can show that any
normal form w.r.t (RD, E) of any term rooted by h is E-capped. Thus, R=
D is
E-capped.
Second, let (RD1, E) be the E-constructed TRS where RD1 = {f(x ∗y, z) →
f(x, z) ∗f(y, z)}. In a way similar to R=
D, we can show that R=
D1 is E-capped.
Lemma 8. Assume E is a Σ0-theory. If for i = 1, 2, Fi is a regular collapse-free
E-capped Σi-theory, and Σ1 ∩Σ2 = Σ0, then F1 ∪F2 is a regular collapse-free
E-capped Σ1 ∪Σ2-theory such that F1 ∪F2 ∪E is a simple combination.
Proof (Sketch). Let us consider the height of layers of a term t, inductively
deﬁned as follows: ht(t) = 0 if t is a variable; ht(t) = 1 if t is a non-variable pure
term; ht(t) = 1 + max{ht(u) | u is an alien subterm of t} if t is not pure.
By contradiction, assume there exist a term t and a position p such that
t =F1∪F2∪E t|p and the path from ϵ to p contains both a symbol in Σ1\Σ0 and
a symbol in Σ2\Σ0. Let u = t|p and let t′ and u′ be the respective normal forms
w.r.t →RF1∪RF2,E of t and u (viewed as ground terms). Since t′ =E u′ and E is
regular collapse-free, t′ and u′ have the same height of layers. By the E-capped
assumption, t and t′ have the same height of layers, as well as u and u′. Thus
t and u have the same height of layers, which leads to a contradiction since the
path from ϵ to p includes both a symbol in Σ1\Σ0 and a symbol in Σ2\Σ0.
Assume there exist some Σ1\Σ0-rooted term t1 and some Σ2\Σ0-rooted term
t2 such that t1 =F1∪F2∪E t2. Then, t′
1 =E t′
2 where t′
1 and t′
2 are the respective
normal forms w.r.t →RF1∪RF2,E of t1 and t2 (viewed as ground terms). The
E-capped assumption implies that t′
i must still contain a symbol in Σi\Σ0 for
i = 1, 2. Since E is regular collapse-free, it is impossible to have t′
1 =E t′
2.
⊓⊔
By Lemma 8, the two assumptions of Lemma 7 can be satisﬁed, and this
leads to the following hierarchical uniﬁcation procedure.
Corollary 1. Assume E is a Σ0-theory; for i = 1, 2, Fi is a regular collapse-
free E-capped Σi-theory, all the Σi\Σ0-rooted terms are subterm collapse-free
modulo Fi ∪E, Si is an E-resolvent presentation of Fi ∪E; and Σ1 ∩Σ2 = Σ0.
Then F1∪F2 is a regular collapse-free E-capped theory, S1∪S2 is an E-resolvent
presentation of F1 ∪F2 ∪E, and HE(DMS1 ∪DMS2) is a sound and complete
F1 ∪F2 ∪E-uniﬁcation procedure.
Proof. By Lemmas 8, 7, 6 and the fact that HE(DMS1∪S2) coincides with
HE(DMS1 ∪DMS2).
⊓⊔
Example 4. (Example 3 continued) There exists an E-resolvent presentation SD
(resp., SD1) of RD ∪E (resp., RD1 ∪E). By Corollary 1, HE(DMSD ∪DMSD1)
is a sound and complete RD ∪RD1 ∪E-uniﬁcation procedure.

38
S. Erbatur et al.
To study the termination of the combined hierarchical uniﬁcation procedure
given in Lemma 7, we reuse the notion of decreasingness initiated in [15].
Deﬁnition 5 (Decreasingness). Consider a complexity measure deﬁned as a
mapping C from separate forms to natural numbers. A HE(U) inference system
is said to be C-decreasing if for any separate form G ∪G0 we have that
– for any G′ such that G ∪G0 ⊢U G′ ∪G0, the separate form of G′ ∪G0 does
not increase C;
– for any G′
0 such that G ∪G0 ⊢Solve G ∪G′
0, then either the separate form of
G ∪G′
0 is in normal form w.r.t HE(U), or it decreases C.
HE(U) is terminating if there exists some C such that HE(U) is C-decreasing.
Theorem 2. Assume a theory E, an E-uniﬁcation algorithm, and a complexity
measure C deﬁned on separate forms. Let F1 and F2 be two regular collapse-
free E-capped theories sharing only symbols in E such that, for i = 1, 2, Fi ∪E
admits a C-decreasing uniﬁcation algorithm of the form HE(Ui). Then F1 ∪F2
is a regular collapse-free E-capped theory such that F1 ∪F2 ∪E admits a C-
decreasing uniﬁcation algorithm of the form HE(U1 ∪U2).
Proof. F1 ∪F2 is a regular collapse-free E-capped theory by Lemma 8. In addi-
tion, Lemma 7 and Lemma 5 can be applied. Hence, HE(U1 ∪U2) provides a
sound and complete F1 ∪F2 ∪E-uniﬁcation procedure. Moreover, HE(U1 ∪U2)
is C-decreasing and so it is terminating.
⊓⊔
This theorem subsumes a similar result from [15]. The advantage now is that
we don’t need to check the subterm-collapse freeness property, which can be a
diﬃcult task. Rather, we need only to check regularity and collapse-freeness,
and this can be trivially achieved by examining the axioms. For example, Theo-
rem 2 allows us to obtain a combined hierarchical uniﬁcation algorithm for the
exponentiation theories from Sect. 1.
7
Combination of Theories Closed by E-Paramodulation
In this section, we focus on E-constructed theories F such that PC(F) = F.
The next lemma follows from a very similar argument to Lemma 3.
Lemma 9. Let F be an E-constructed theory closed by E-paramodulation. For
each ground equality u =F ∪E v such that u is Σ\Σ0-rooted and v is normalized
w.r.t →RF ,E, one of the following is true: (1) u = f(¯u), v = f(¯v) and ¯u =F ∪E ¯v;
(2) u = f(¯u), there exist f(¯s) = t ∈F and a substitution σ normalized w.r.t
→RF ,E such that ¯u =F ∪E ¯sσ, v =E tσ and ¯sσ, tσ are normalized w.r.t →RF ,E.
The inference system BSM F given in Fig. 3 can be used to show the existence
of a hierarchical uniﬁcation algorithm for the class of E-constructed theories
closed by E-paramodulation. One can notice that each inference rule in BSM F
generates some boxed terms. This particular annotation of terms, detailed in [11,
21], allows us to control the rule applications, disregarding needless inferences
on boxed terms in such a way that the termination is guaranteed.

Combined Uniﬁcation and Closure by Equational Paramodulation
39
Imit
i{x = f(¯vi)} ∪G
x = f(¯y) } ∪
i{¯y = ¯vi} ∪G
where f ∈Σ\Σ0, i > 1, ¯y are fresh variables and there are no more equations
x = f(. . . ) in G.
MutConﬂictF
{x = f(¯v)} ∪G
x = t , ¯s = ¯v} ∪G
where f ∈Σ\Σ0, f(¯s) = t is a fresh instance of an equality in F, f(¯v) is unboxed, and
(there is another equation x = u in G with a non-variable term u or x = f(¯v) occurs
in a cycle).
ImitCycle {x = f(¯v)} ∪G
x = f(¯y) , ¯y = ¯v} ∪G
where f ∈Σ\Σ0, f(¯v) is unboxed, ¯y are fresh variables and x = f(¯v) occurs in a cycle.
Fig. 3. BSM F rules
Theorem 3. Consider any E-constructed theory F closed by E-paramodulation
and the inference system BSM F given in Fig. 3. Then, F ∪E is an E-syntactic
theory admitting a uniﬁcation algorithm of the form HE(BSM F ).
Proof. F ∪E is E-syntactic since an E-resolvent presentation of F ∪E is F ∪
{lσ = gσ | l = r, g = d ∈F, lσ ̸< rσ, gσ ̸< dσ, σ ∈CSUE(r =? d), lσ ̸= gσ}. By
Lemma 9, BSM F satisﬁes the assumption of Deﬁnition 3. Since the separate dag
solved forms are the F ∪E-uniﬁable normal forms w.r.t HE(BSM F ), Lemma 5
applies and so HE(BSM F ) is a sound and complete F ∪E-uniﬁcation procedure.
Moreover HE(BSM F ) can be proved terminating using the same proof as the one
developed in [11,15] for forward-closed E-constructed TRSs. Thus, HE(BSM F )
is a sound and complete terminating F ∪E-uniﬁcation procedure.
⊓⊔
Theorem 4. If F1 and F2 are two E-constructed theories closed by E-
paramodulation and sharing only symbols in E, then F1 ∪F2 is an E-constructed
theory closed by E-paramodulation.
Proof (Sketch). The maximal sides of equalities in Fi are necessarily Σi\Σ0-
rooted for i = 1, 2. Therefore, it is impossible to apply E-Paramodulation
with one premise in F1 and the other one in F2.
⊓⊔
Corollary 2. If for i = 1, 2, Fi is an E-constructed Σi-theory closed by E-
paramodulation, and Σ1 ∩Σ2 = Σ0, then F1 ∪F2 ∪E is an E-syntactic theory
admitting a uniﬁcation algorithm of the form HE(BSM F1 ∪BSM F2).
Proof. By Theorems 4, 3, and the fact that HE(BSM F1∪F2) coincides with
HE(BSM F1 ∪BSM F2).
⊓⊔
Example 5. Continuing Example 2 and Example 1, we can notice that E1 and E2
are both AC-constructed and closed by AC-paramodulation. By Theorem 4, E1∪
E2 is closed by AC-paramodulation. Furthermore, E1 ∪E2 is an AC-syntactic
theory admitting a uniﬁcation algorithm of the form HAC(BSME1 ∪BSME2).
Theorem 4 can be applied to IR1 E-constructed TRSs combined with some
particular shallow theories.

40
S. Erbatur et al.
Deﬁnition 6 (Shallow extension). Let (R, E) be an E-constructed TRS over
the signature Σ, and Σ′ a signature extension of Σ. A shallow extension of
(R, E) is an equational Σ′-theory F ∪R= where F is a ﬁnite set of shallow
Σ′-equalities l = r such that l(ϵ), r(ϵ) ∈(Σ′\Σ) ∪X and all the ground terms
occurring in F are Σ-terms in normal form w.r.t (R, E).
A shallow extension F ∪R= of (R, E) can be viewed as a union of two E-
constructed theories sharing only symbols in E (plus, some additional constants).
The ﬁrst theory, say F ′, is obtained from F by performing a constant abstraction
of maximal ground terms rooted by symbols deﬁned by R. The second theory
is given by a set of rules, say R′, deﬁned as R plus all the rules t →c for
each abstracted ground term t, c being the constant that abstracts t. We can
show that F ′ admits a ﬁnite closure by E-paramodulation. If (R, E) is an IR1
E-constructed TRS, then so is (R′, E), and R′= is closed by E-paramodulation
according to Lemma 1. Then, Theorem 4 can be applied to get:
Theorem 5. Assume (R, E) is any E-constructed TRS such that →R,E is IR1,
F ∪R= is any shallow extension of (R, E), and > is a reduction ordering includ-
ing →R,E such that PC(F) is deﬁned. Then, PC(F ∪R=) is ﬁnite.
8
Conclusion
Assuming a regular collapse-free theory E and an E-uniﬁcation algorithm, we
have studied the (combined) uniﬁcation problem in (unions of) E-constructed
theories. Our notion of constructor seems to be closely related to the one used
in [5] but this remains to be formally shown.
As future work, it would be interesting to apply our hierarchical approach
to uniﬁcation in order-sorted equational theories, to handle for instance order-
sorted AC-convergent rewrite systems with the Finite Variant Property that can
be used for homomorphic encryption [28]. In the near future, we plan to reuse
the notion of E-constructed theory in order to investigate the possible extension
of the combination methods developed in [14] for two knowledge problems of
particular interest in the analysis of protocols. These combination methods have
been initially developed for the case of theories sharing only absolutely free
constructors and we believe that the framework above will be useful to lift these
methods to the case of theories sharing only constructors modulo E.
In a longer term, we envision to study the possible development of a hier-
archical approach to solve the disuniﬁcation problem modulo theories closed
by E-paramodulation. The disuniﬁcation problem has been already successfully
considered for forward-closed rewrite systems [23]. Since paramodulation-closed
theories bear similarities with forward-closed rewrite systems, investigating a
hierarchical approach to solve the disuniﬁcation problem [2,23] appears to be a
promising research direction.

Combined Uniﬁcation and Closure by Equational Paramodulation
41
References
1. Baader, F., Nipkow, T.: Term Rewriting and All That. Cambridge University Press,
Cambridge (1998)
2. Baader, F., Schulz, K.U.: Combination techniques and decision problems for dis-
uniﬁcation. Theor. Comput. Sci. 142(2), 229–255 (1995)
3. Baader, F., Schulz, K.U.: Uniﬁcation in the union of disjoint equational theories:
combining decision procedures. J. Symb. Comput. 21(2), 211–243 (1996)
4. Baader, F., Snyder,W.: Uniﬁcation theory. In: Robinson, J.A., Voronkov, A. (eds.)
Handbook of Automated Reasoning (in 2 volumes), pp. 445–532. Elsevier and MIT
Press (2001)
5. Baader, F., Tinelli, C.: Combining decision procedures for positive theories sharing
constructors. In: Tison, S. (ed.) RTA 2002. LNCS, vol. 2378, pp. 352–366. Springer,
Heidelberg (2002). https://doi.org/10.1007/3-540-45610-4 25
6. Bouchard, C., Gero, K.A., Lynch, C., Narendran, P.: On forward closure and the
ﬁnite variant property. In: Fontaine, P., Ringeissen, C., Schmidt, R.A. (eds.) Fro-
CoS 2013. LNCS (LNAI), vol. 8152, pp. 327–342. Springer, Heidelberg (2013).
https://doi.org/10.1007/978-3-642-40885-4 23
7. Cohn-Gordon, K., Cremers, C., Garratt, L., Millican, J., Milner, K.: On ends-to-
ends encryption: asynchronous group messaging with strong security guarantees.
In: Lie, D., Mannan, M., Backes, M., Wang, X. (eds.) Proceedings of the 2018
ACM SIGSAC Conference on Computer and Communications Security, CCS 2018,
Toronto, ON, Canada, 15–19 October 2018, pp. 1802–1819. ACM (2018)
8. Comon, H., Haberstrau, M., Jouannaud, J.-P.: Syntacticness, cycle-syntacticness,
and shallow theories. Inf. Comput. 111(1), 154–191 (1994)
9. Comon-Lundh, H., Delaune, S.: The ﬁnite variant property: how to get rid of some
algebraic properties. In: Giesl, J. (ed.) RTA 2005. LNCS, vol. 3467, pp. 294–307.
Springer, Heidelberg (2005). https://doi.org/10.1007/978-3-540-32033-3 22
10. Domenjoud, E., Klay, F., Ringeissen, C.: Combination techniques for non-disjoint
equational theories. In: Bundy, A. (ed.) CADE 1994. LNCS, vol. 814, pp. 267–281.
Springer, Heidelberg (1994). https://doi.org/10.1007/3-540-58156-1 19
11. Eeralla, A.K., Erbatur, S., Marshall, A.M., Ringeissen, C.: Rule-based uniﬁcation
in combined theories and the ﬁnite variant property. In: Mart´ın-Vide, C., Okhotin,
A., Shapira, D. (eds.) LATA 2019. LNCS, vol. 11417, pp. 356–367. Springer, Cham
(2019). https://doi.org/10.1007/978-3-030-13435-8 26
12. Erbatur, S., Kapur, D., Marshall, A.M., Narendran, P., Ringeissen, C.: Hierarchical
combination. In: Bonacina, M.P. (ed.) CADE 2013. LNCS (LNAI), vol. 7898, pp.
249–266. Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-38574-
2 17
13. Erbatur, S., Marshall, A.M., Kapur, D., Narendran, P.: Uniﬁcation over distribu-
tive exponentiation (sub)theories. J. Autom. Lang. Comb. 16(2–4), 109–140 (2011)
14. Erbatur, S., Marshall, A.M., Ringeissen, C.: Notions of knowledge in combinations
of theories sharing constructors. In: de Moura, L. (ed.) CADE 2017. LNCS (LNAI),
vol. 10395, pp. 60–76. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-
63046-5 5
15. Erbatur, S., Marshall, A.M., Ringeissen, C.: Terminating non-disjoint combined
uniﬁcation. In: Fern´andez, M. (ed.) LOPSTR 2020. LNCS, vol. 12561, pp. 113–
130. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-68446-4 6
16. Erbatur, S., Marshall, A.M., Ringeissen, C.: Non-disjoint combined uniﬁcation and
closure by equational paramodulation (extended version). Research report (2021).
http://hal.inria.fr

42
S. Erbatur et al.
17. Escobar, S., Sasse, R., Meseguer, J.: Folding variant narrowing and optimal variant
termination. J. Log. Algebr. Program. 81(7–8), 898–928 (2012)
18. Jouannaud, J.-P., Kirchner, H.: Completion of a set of rules modulo a set of equa-
tions. SIAM J. Comput. 15(4), 1155–1194 (1986)
19. Kim, D., Lynch, C., Narendran, P.: Reviving basic narrowing modulo. In: Herzig,
A., Popescu, A. (eds.) FroCoS 2019. LNCS (LNAI), vol. 11715, pp. 313–329.
Springer, Cham (2019). https://doi.org/10.1007/978-3-030-29007-8 18
20. Kirchner, C., Klay, F.: Syntactic theories and uniﬁcation. In: Proceedings of the
Fifth Annual Symposium on Logic in Computer Science (LICS 1990), Philadelphia,
Pennsylvania, USA, 4–7 June 1990, pp. 270–277. IEEE Computer Society (1990)
21. Lynch, C., Morawska, B.: Basic syntactic mutation. In: Voronkov, A. (ed.) CADE
2002. LNCS (LNAI), vol. 2392, pp. 471–485. Springer, Heidelberg (2002). https://
doi.org/10.1007/3-540-45620-1 37
22. Lynch, C., Morawska, B.: Faster Basic Syntactic Mutation with sorts for some
separable equational theories. In: Giesl, J. (ed.) RTA 2005. LNCS, vol. 3467, pp.
90–104. Springer, Heidelberg (2005). https://doi.org/10.1007/978-3-540-32033-3 8
23. Meseguer, J.: Variant-based satisﬁability in initial algebras. Sci. Comput. Program.
154, 3–41 (2018)
24. Nguyen, K.: Formal veriﬁcation of a messaging protocol. Internship report (2019).
Work done under the supervision of Vincent Cheval and V´eronique Cortier
25. Nipkow, T.: Proof transformations for equational theories. In: Proceedings of the
Fifth Annual Symposium on Logic in Computer Science (LICS 1990), Philadelphia,
Pennsylvania, USA, 4–7 June 1990, pp. 278–288. IEEE Computer Society (1990)
26. Ringeissen, C.: Uniﬁcation in a combination of equational theories with shared
constants and its application to primal algebras. In: Voronkov, A. (ed.) LPAR
1992. LNCS, vol. 624, pp. 261–272. Springer, Heidelberg (1992). https://doi.org/
10.1007/BFb0013067
27. Schmidt-Schauß, M.: Uniﬁcation in a combination of arbitrary disjoint equational
theories. J. Symb. Comput. 8(1/2), 51–99 (1989)
28. Yang, F., Escobar, S., Meadows, C.A., Meseguer, J., Narendran, P.: Theories of
homomorphic encryption, uniﬁcation, and the ﬁnite variant property. In: Chitil,
O., King, A., Danvy, O. (eds.) Proceedings of the 16th International Symposium
on Principles and Practice of Declarative Programming, Kent, Canterbury, United
Kingdom, 8–10 September 2014, pp. 123–133. ACM (2014)

Symbol Elimination and Applications
to Parametric Entailment Problems
Dennis Peuter and Viorica Sofronie-Stokkermans(B)
University Koblenz-Landau, Koblenz, Germany
{dpeuter,sofronie}@uni-koblenz.de
Abstract. We analyze possibilities of second-order quantiﬁer elimina-
tion for formulae containing parameters – constants or functions. For
this, we use a constraint resolution calculus obtained from specializing
the hierarchical superposition calculus. If saturation terminates, we ana-
lyze possibilities of obtaining weakest constraints on parameters which
guarantee satisﬁability. If the saturation does not terminate, we identify
situations in which ﬁnite representations of inﬁnite saturated sets exist.
We identify situations in which entailment between formulae expressed
using second-order quantiﬁcation can be eﬀectively checked. We illustrate
the ideas on a series of examples from wireless network research.
1
Introduction
The main motivation for this work was a study of models for graph classes nat-
urally occurring in wireless network research – in which nodes that are close are
always connected, nodes that are far apart from each other are never connected
and any other node pairs can, but do not need to be connected. Transformations
can be applied to such graphs to make them symmetric; this way we can deﬁne
further graph classes. When checking inclusion between graph classes described
using transformations we need to check entailment of second-order formulae. In
addition, many such graph class descriptions are parametric in nature, so the
goal is, in fact, to obtain (weakest) conditions on the parameters used in such
descriptions that guarantee that graph classes are non-empty or that inclusions
hold. This can be achieved by eliminating “non-parametric” constants or func-
tion symbols used in the description of such classes.
In this paper we combine methods for general symbol elimination (which
we use for eliminating existentially quantiﬁed predicates) with methods for
property-directed symbol elimination (which we use for obtaining conditions on
“parameters” under which formulae are satisﬁable or second-order entailment
holds). For general second-order quantiﬁer elimination we use a form of ordered
resolution similar to that proposed in [19]. For property-directed symbol elim-
ination we use a method we proposed in [40]. The advantage of using such a
two-layered approach is that it avoids non-termination that might occur if using
only general symbol elimination methods. The main application area we con-
sider in this paper is the analysis of inclusions between graph classes arising in
wireless network research. Our main contributions are:
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 43–62, 2021.
https://doi.org/10.1007/978-3-030-86205-3_3

44
D. Peuter and V. Sofronie-Stokkermans
– We analyze theories used in modeling graph classes and prove locality of
theories of “distances” occurring in this context.
– We analyze possibilities of general symbol elimination, using a simple special-
ization HResP
≻of the hierarchical superposition calculus (a form of ordered
resolution) for eliminating a predicate symbol P.
– If saturation terminates, we analyze possibilities of obtaining weakest con-
straints on parameters occurring in the clauses which guarantee satisﬁability,
using methods for property-directed symbol elimination.
– If the saturation does not terminate, we study possibilities of representing an
(inﬁnite) saturated set as a set of constrained clauses in which the constraints
are interpreted in the minimal model of a set of constrained Horn clauses.
– We analyze possibilities of eﬀectively checking entailment between formulae
expressed using second-order quantiﬁcation.
– We illustrate the ideas on examples related to the study of wireless networks.
Related Work. The study of second-order quantiﬁer elimination goes back to the
beginning of the 20th century (cf. [10] and [2,3]). Most of its known applications
are in the study of modal logics or knowledge representation [20,21]; in many
cases second-order quantiﬁer elimination is proved only for very restricted frag-
ments (cf. e.g. [41]). In [19], Gabbay and Ohlbach proposed a resolution-based
algorithm for second-order quantiﬁer elimination which is implemented in the
system SCAN. In [5], Bachmair et al. mention that hierarchical superposition
(cf. [8,9] for further reﬁnements) can be used for second-order quantiﬁer elim-
ination modulo a theory. In [33] and [23], Hoder et al. study possibilities of
symbol elimination in inference systems (e.g. the superposition calculus and its
extension with ground linear rational arithmetic and uninterpreted functions).
The main challenge when using saturation approaches for symbol elimination is
the fact that the saturated sets might be inﬁnite. Sometimes ﬁnite representa-
tions of possibly inﬁnite sets of clauses exist: for this, Horbach and Weidenbach
introduced a melting calculus [26], later used in [24,25] and [17]. Similar aspects
were explored in the study of acceleration for program veriﬁcation modulo Pres-
burger arithmetic by Boigelot, Finkel and Leroux [14,18], in relationship with
array systems by [4], or in the study of constrained Horn clauses (cf. [12]). We
analyze possibilities of representing inﬁnite saturated sets as sets of constrained
clauses in which the constraints are interpreted in the minimal model of a set of
constrained Horn clauses.
Orthogonal to this direction of study is what we call “property-directed”
symbol elimination: There, given a theory T and a ground formula G satisﬁable
w.r.t. T , the goal is to derive a (weakest) universal formula Γ over a subset of
the signature, such that Γ ∧G is unsatisﬁable w.r.t. T . We devised methods for
solving such problems in [40] and used them for interpolant computation [40],
and invariant generation [37]. We here use these results in a diﬀerent context.
We are not aware of other similar approaches to the area of computational
(geometric) graph theory. Existing approaches use a logical representation of
graphs based on monadic second-order logic (cf. e.g. [15]) or higher-order theorem
provers like Isabelle/HOL (cf. e.g. [1]). Our approach is orthogonal; it allows a
reduction of many problems to satisﬁability modulo a suitable theory.

Symbol Elimination and Applications
45
Structure of the Paper. In Sect. 1.1 we present the motivation for our research. In
Sect. 2 we introduce the results on (local) theory extensions needed in the paper
and prove the locality of theories of distance functions. In Sect. 3 we present
the HResP
≻calculus we use for eliminating predicate P, and analyze possibilities
of giving ﬁnite representations for inﬁnite saturated sets and of investigating
the satisﬁability of the saturated sets. In Sect. 4 we use these ideas for checking
entailment. In Sect. 5 we present conclusions and plans for future work.
The details of the proofs and additional examples can be found in the extended
version of the paper [36].
1.1
Motivation
Graph classes important in wireless network research are: The class UDG of unit
disk graphs (two nodes are connected iﬀthey are diﬀerent and their distance is
≤1); the class QUDG(r) of quasi unit disk graphs, for r ∈(0, 1] (two distinct
nodes with distance ≤r are always connected and nodes with distance > 1 are
never connected); the class DTG(r, r) of directed transmission graphs for r > 0
(every node v has a maximum communication distance r(v) ≤r; an edge from
v to w exists iﬀv ̸= w and the distance between v and w is ≤r(v)).
Many graph classes C(p) (where p is a sequence of symbols denoting parame-
ters) can be described using inclusion, exclusion and transfer axioms. The inclu-
sion axioms specify under which conditions an edge from u to v has to exist; the
conditions are described by a formula πi
C(u, v); inclusion axioms have the form:
(1)
∀u, v (πi
C(u, v) →E(u, v)).
The exclusion axioms specify under which condition an edge from u to v is not
allowed to exist; the conditions are described by a formula πe
C(u, v), so exclusion
axioms have the form:
(2)
∀u, v (πe
C(u, v) →¬E(u, v)).
The transfer axioms specify under which conditions an edge from u to w must
exist as a consequence of the existence of an edge from u to v; the conditions
are described by a formula πt
C(u, v, w), so the transfer axioms we consider here
have the form:
(3)
∀u, v, w (πt
C(u, w, v) ∧E(u, v) →E(u, w)).
We can deﬁne more general versions of the classes MinDG(r), MaxDG(r)
and CRG used in the literature, in which we assume that every vertex v has a
maximum communication distance r(v), using axioms:
– MinDG(r): axiom (1), where πi
r(u, v) is the formula u ̸= v ∧d(u, v) ≤r(u);
– MaxDG(r): axiom (2), where πe
r(u, v) is the formula d(u, v) > r(u);
– CRG: axiom (3), where πt(u, w, v) is the formula u ̸= w ∧d(u, w) ≤d(u, v).

46
D. Peuter and V. Sofronie-Stokkermans
In the case when r(v) = r for all v, where r ∈R, we use the constant r
when describing the classes instead of the function r. For instance, UDG =
MinDG(1) ∩MaxDG(1) is axiomatized by MinDG(1) ∧MaxDG(1). We may
want to check whether a graph class C(p) has non-empty models, or determine
(weakest) conditions on the parameters p under which this is the case.
We can deﬁne transformations γ on graphs that transform the edges, and
form classes γ(C) = {γ(G) | G ∈C}. Two examples of transformations are
·+ and ·−: Given a graph G = (V, E), we can build the symmetric supergraph
G+ = (V, E+) resp. symmetric subgraph G−= (V, E−), deﬁned by:
∀x, y(E+(x, y) ↔(E(x, y)∨E(y, x))) and ∀x, y(E−(x, y) ↔(E(x, y)∧E(y, x))).
We can thus deﬁne the classes C+ and C−. The class of quasi unit disk graphs
[7,34] can be described as QUDG(r) = (MinDG(r)∩MaxDG(1))−. We might
want to obtain an axiomatization for QUDG(r) that depends only on the predi-
cates πi
r(x, y), πe
1(x, y) or test whether the class is the same as the class described
by (MinDG(r) ∩MaxDG(1))+.
To ﬁnd an axiomatization of a graph class γ(C), where γ is a transformation,
we need to ﬁnd a ﬁrst-order formula equivalent to ∃E′(NE′ ∩Tr(E′, E)), where
NE′ is a class of clauses describing class C and Tr is a formula describing the way
the edges of the graph (V, E) = γ(V, E′) can be obtained from the description
of the graph (V, E′). If we can ﬁnd such formulae for two graph classes, then we
can also check containment (provided the formulae belong to decidable theory
fragments). In this paper we analyze situations in which this is possible.
2
Local Extensions; Hierarchical Symbol Elimination
We assume known the basic notions in (many-sorted) ﬁrst-order logic. We con-
sider signatures of the form Π = (S, Σ, Pred), where S is a set of sorts, Σ is a fam-
ily of function symbols and Pred a family of predicate symbols, such that for every
function symbol f (resp. predicate symbol p) their arity a(f) = s1 . . . sn →s
(resp. a(p) = s1 . . . sm), where s1, . . . , sn, s ∈S, is speciﬁed. If C is a ﬁxed
countable set of fresh constants, we denote by ΠC the extension of Π with
constants in C. We assume known standard deﬁnitions from ﬁrst-order logic
such as Π-structure, model, satisﬁability, unsatisﬁability. If Π ⊆Π′ and A is a
Π′-structure, we denote its reduct to Π by A|Π.
Notation. We will denote with (indexed versions of) x, y, z variables and with
(indexed versions of) a, b, c, d constants; x will stand for a sequence of variables
x1, . . . , xn, and c for a sequence of constants c1, . . . , cn.
Theories. Theories can be deﬁned by specifying a set of axioms, or by specifying
a class of structures (the models of the theory). If F and G are formulae we write
F |= G (resp. F |=T G – also written as T ∪F |= G) to express the fact that
every model of F (resp. every model of F which is also a model of T ) is a model
of G. We denote “falsum” with ⊥. F |=⊥means that F is unsatisﬁable; F |=T ⊥
means that there is no model of T in which F is true.

Symbol Elimination and Applications
47
A theory T over a signature Π allows quantiﬁer elimination (QE) if for every
formula φ over Π there exists a quantiﬁer-free formula φ∗over Π which is equiv-
alent to φ modulo T . Examples of theories which allow quantiﬁer elimination
are rational and real linear arithmetic (LI(Q), LI(R)), the theory of real closed
ﬁelds, and the theory of absolutely-free data structures.
Sometimes, in order to deﬁne more complex theories we can consider theory
extensions and combinations thereof. Let Π0=(Σ0, Pred) be a signature, and T0
be a “base” theory with signature Π0. We consider extensions T := T0 ∪K of T0
with new function symbols Σ (extension functions) whose properties are axiom-
atized using a set K of (universally closed) clauses in the extended signature
Π = (Σ0 ∪Σ, Pred), such that each clause in K contains function symbols in Σ.
Especially well-behaved are the Ψ-local theory extensions, i.e. theory extensions
T0 ⊆T0∪K as deﬁned above, in which checking ground satisﬁability can be done
using a ﬁnite instantiation scheme described by a suitable closure operator Ψ,
without loss of completeness. We express this with the following condition:
(LocΨ
f )
For every ﬁnite set G of ground ΠC-clauses (for an additional set C of
constants) it holds that T0 ∪K ∪G |= ⊥if and only if T0 ∪K[ΨK(G)] ∪G
is unsatisﬁable.
where, for every set G of ground ΠC-clauses, K[ΨK(G)] is the set of instances
of K in which the terms starting with a function symbol in Σ are in ΨK(G) =
Ψ(est(K, G)), where est(K, G) is the set of ground terms starting with a function
in Σ occurring in G or K. Ψ-local extensions can be recognized by showing that
certain partial models embed into total ones [29,38]. Especially well-behaved are
theory extensions with the property (CompΨ
f ) which requires that every partial
model of T whose reduct to Π0 is total and the “set of deﬁned terms” is ﬁnite
and closed under Ψ embeds into a total model of T with the same support (cf.
[27,29]). If Ψ is the identity, we denote LocΨ
f by Locf and CompΨ
f by Compf.
Theorem 1 [27]. The following theory extensions have property (Compf), so
are local: (i) The extension of a theory T0 with uninterpreted function symbols.
(ii) The extension of a theory T0 (containing a predicate ≤which is reﬂexive)
with a function f satisfying the axioms K = {∀x φi(x)→Li(x) | i = 1, . . . , n}
where φi are Π0-formulae with φi(x)∧φj(x)|=⊥if i̸=j (n can be 1 and φ1 can be
⊤), and Li(x) has the form (1) si ≤f(x) or (2) f(x) ≤ti or (3) si ≤f(x) ≤ti,
where si, ti are Π0-terms and in case (3) φi |=T0 si ≤ti.
Theorem 2 [38]. Let K be a set of clauses. Assume that T0 ⊆T1 = T0∪K is a Ψ-
local theory extension. For any ﬁnite set G of ground ΠC-clauses, let K0∪G0∪Def
be obtained from K[ΨK(G)] ∪G by introducing, in a bottom-up manner, new
constants ct ∈C for subterms t=f(c1, . . . , cn) where f∈Σ and ci are constants,
together with deﬁnitions ct=f(c1, . . . , cn) (included in Def) and replacing the cor-
responding terms t with the constants ct in K and G. Then T1∪G |=⊥if and only
if T0∪K0∪G0∪Con0 |=⊥, where Con0={
n

i=1
ci≈di →c≈d | f(c1, . . . , cn)≈c∈Def
f(d1, . . . , dn)≈d∈Def }.

48
D. Peuter and V. Sofronie-Stokkermans
Algorithm 1. Symbol elimination in theory extensions [39][40]
Input:
Theory extension T0 ∪K with signature Π = Π0 ∪Σ1, where Σ1 = Σ ∪Σpar
where Σpar is a set of parameters
G: set of ground ΠC-clauses; T: set of ground ΠC-terms with ΨK(G) ⊆T
Output: ∀yΓT (y) (universal Π0 ∪Σpar-formula)
Step 1 Purify K[T]∪G as described in Theorem 2 (with set of extension symbols Σ1).
Let K0 ∪G0 ∪Con0 be the set of ΠC
0 -clauses obtained this way.
Step 2 Let G1 = K0 ∪G0 ∪Con0. Among the constants in G1, we identify
(i) the constants cf, f ∈Σpar, where cf is a constant parameter or cf is introduced
by a deﬁnition cf ≈f(c1, . . . , ck) in the hierarchical reasoning method,
(ii) all constants cp occurring as arguments of functions in Σpar in such deﬁnitions.
Replace all the other constants c with existentially quantiﬁed variables x (i.e.
replace G1(cp, cf, c) with ∃xG1(cp, cf, x)).
Step 3 Construct a formula Γ1(cp, cf) equivalent to ∃xG1(cp, cf, x) w.r.t. T0 using a
method for quantiﬁer elimination in T0.
Step 4 Replace each constant cf introduced by deﬁnition cf = f(c1, . . . , ck) with
the term f(c1, . . . , ck) in Γ1(cp, cf). Let Γ2(cp) be the formula obtained this way.
Replace cp with existentially quantiﬁed variables y.
Step 5 Let ∀yΓT (y) be ∀y¬Γ2(y).
Property-Directed Symbol Elimination. In [40] we proposed a method for
property-directed symbol elimination described in Algorithm 1. We present a
slight generalization (the proof is similar to the proof in [40]; it is presented in
detail in the extended version of this paper [36]).
Theorem 3 [39,40]. Let T0 be a Π0-theory allowing quantiﬁer elimination1,
Σpar be a set of parameters (function and constant symbols) and Π = (S, Σ, Pred)
be such that Σ ∩(Σ0 ∪Σpar) = ∅. Let K be a set of clauses in the signature
Π0∪Σpar∪Σ in which all variables occur also below functions in Σ1 = Σpar ∪Σ.
Assume T ⊆T0 ∪K satisﬁes condition (CompΨ
f ) for a suitable closure operator
Ψ with est(G) ⊆ΨK(G) for every set G of ground ΠC-clauses. Then, for T =
ΨK(G), Algorithm 1 yields a universal Π0 ∪Σpar-formula ∀xΓT (x) such that
T0 ∪∀xΓT (x) ∪K ∪G |=⊥which is entailed by every universal formula Γ with
T0 ∪Γ ∪K ∪G |=⊥.
2.1
Locality of Theories of Distances
The theories related to wireless networks used in Sect. 1.1 refer to cost or distance
functions. Axiomatizations for such functions deﬁne local theory extensions.
1 If T0 does not allow QE but has a model completion T ∗
0 which does, and if we use
QE in T ∗
0 in Alg. 1, T0 ∧∀xΓT (x) ∪G |= ⊥, but ∀xΓT (x) might not the weakest
universal formula Γ with the property that T0 ∪Γ ∪K |= ⊥.

Symbol Elimination and Applications
49
Theorem 4. Let T0 be the disjoint combination of the theory E of pure equality
(sort p) and linear real arithmetic (sort num). The following extensions of T0
with a function d (sort p×p→num) are Ψ-local for a suitable closure operator Ψ:
(1) T m
d
= T0 ∪Km, where Km are axioms of a metric, is Ψm-local, where
Ψm(T) = T ∪{d(a, b) | a, b constants of sort p occurring in T}.
(2) T n
d
= T0 ∪Kn, where Kn contains all axioms of a metric except for the
triangle inequality, is Ψn-local, where Ψn(T) = T ∪{d(b, a) | d(a, b) ∈T} ∪
{d(a, a) | a constant of sort p occurring in T}.
(3) T u
d , the extension of T0 with an uninterpreted function d, and T p
d = T0 ∪Kp,
where Kp = ∀x, y d(x, y) ≥0, are Ψ-local, where Ψ(T) = T.
Proof: For proving locality, it is suﬃcient to prove that the theory extensions
satisfy condition CompΨ
f , where Ψ is the corresponding closure operator. Due to
the form of the closure operators, the non-linearity of the symmetry axiom or of
the triangle inequality is not problematic for guaranteeing Ψ-locality. A detailed
proof is given in the extended version of this paper [36].
□
3
Second-Order Quantiﬁer Elimination
Let T be a theory with signature Π = (S, Σ, Pred) and P1, . . . , Pn, Q1, . . . , Qm
be predicate symbols which are not in Pred. Let Π′ = (S, Σ, Pred∪{P1, . . . , Pn})
and Π′′ = (S, Σ, Pred∪{Q1, . . . , Qm}); F be a Π′-formula and G a Π′′-formula.
A Π-structure A is a model of ∃P1 . . . Pn F (notation: A |= ∃P1 . . . Pn F) if
there exists a Π′-structure B such that B |= F and B|Π = A.
We say that ∃P1 . . . Pn F entails ∃Q1 . . . Qm G w.r.t. T (and use the notation:
∃P1 . . . Pn F |=T ∃Q1 . . . Qm G) iﬀfor every Π-structure A which is a model of
T , if A |= ∃P1 . . . Pn F then A |= ∃Q1 . . . Qm G.
If there exists a ﬁrst-order formula F0 over the signature Π such that for every
model A of T , A |= F0 iﬀA |= ∃P1 . . . Pn F, we say that F0 and ∃P1 . . . Pn F
are equivalent w.r.t. T (and write F0 ≡T ∃P1 . . . Pn F).
We consider here only the elimination of one predicate; for formulae of the
form ∃P1 . . . Pn F the process can be iterated. Let T be a theory with signature
Π = (S, Σ, Pred) and let Π′ = (S, Σ, Pred ∪{P}), where P ̸∈Pred.
Let F be a universal ﬁrst-order Π′-formula. Our goal is to compute, if possi-
ble, a ﬁrst-order Π-formula G such that G ≡T ∃P F. We adapt the hierarchical
superposition calculus proposed in [8,9] to this case.
We consider theories T over many-sorted signatures Π = (S, Σ, Pred), where
the set of sorts S = Si ∪Su, consists of a set Si of interpreted sorts and
a set Su of uninterpreted sorts. The models of the theories are Π-structures
A = ({As}s∈S, {fA}f∈Σ, {pA}p∈Pred), where each support of interpreted sort is
considered to be ﬁxed. Following the terminology used in [8,9], we will refer to
elements in the ﬁxed domain of sort s ∈Si as domain elements of sort s.
Let F be a universal ﬁrst-order formula over signature Π′ = (S, Σ, Pred ∪
{P}). We can assume, without loss of generality, that F is a set of clauses of the

50
D. Peuter and V. Sofronie-Stokkermans
form ∀x D(x) ∨C(x), where D(x) is a clause over the signature Π and C(x) is
a clause containing literals of the form (¬)P(x1, . . . , xn), where x1, . . . , xn are
variables2. Such clauses can also be represented as constrained clauses in the
form ∀x φ(x) || C(x), where φ(x) := ¬D(x). We will refer to clauses of this
form as constrained P-clauses.
Let ≻be a strict, well-founded ordering on terms that is compatible with
contexts and stable under substitutions. As in [9] we assume that ≻has the
following properties3: (i) ≻is total on ground terms, (ii) t ≻d for every domain
element d of interpreted sort s and every ground term t that is not a domain
element. Let HResP
≻be the calculus containing the following ordered resolution
and factorization rules for constrained P-clauses:
φ1 || P(x) ∨C
φ2 || ¬P(y) ∨D
(φ1 ∧φ2)σ || (C ∨D)σ
φ || P(x) ∨P(y) ∨C
φσ || (P(x) ∨C)σ
where (i) σ = mgu(P(x), P(y))
(i) σ = mgu(P(x), P(y))
(ii) P(x)σ is strictly maximal in (P(x) ∨C)σ (ii) P(x)σ is maximal in
(iii) ¬P(y)σ is maximal in (¬P(y) ∨D)σ.
(P(x) ∨C)σ
Redundancy. The inference rules are supplemented by a redundancy criterion
R = (Rc, Ri) meant to specify a set Rc of redundant clauses (which can be
removed) and a set Ri of redundant inferences (which do not need to be com-
puted). We say that a set of clauses N ∗is saturated up to R-redundancy w.r.t.
HResP
≻if every HResP
≻inference with premises in N ∗is redundant (i.e. in Ri).
The following notion of redundancy R0
c for clauses is often used: A (con-
strained) clause is redundant w.r.t. a set N of clauses if all its ground instances
are entailed w.r.t. T by ground instances of clauses in N which are strictly
smaller w.r.t. ≻. We will use the following notion of redundancy for inferences:
If Rc is a redundancy criterion for clauses, we say that an inference ι on ground
clauses is redundant w.r.t. N if either one of its premises is redundant w.r.t. N
and Rc or, if C0 is the conclusion of ι then there exist clauses C1, . . . , Cn ∈N
that are smaller w.r.t. ≻than the maximal premise of ι and C1, . . . , Cn |= C0.
A non-ground inference is redundant if all its ground instances are redundant.
Example 1 (Semantic
T -entailment;
redundancy
criterion
RT ).
A constrained P-clause ∀x (φ(x) || C(x)) is T -semantically entailed by
∀x (ψ(x) || D(x)) if (i) C
= D, (ii) T
|= ∀x φ(x) →ψ(x) and (iii)
¬φ(x)σ ≻¬ψ(x)σ for every ground substitution σ. We say that a clause C
is RT -redundant w.r.t. a set N of clauses if it is T -semantically entailed by a
clause in N. (If C1=(φ(x)||C(x)) is T -semantically entailed by C2=(ψ(x)||D(x))
2 We can bring the clauses to this form using variable abstraction.
3 These conditions are satisﬁed by an LPO with an operator precedence in which the
predicate symbol P (which can be regarded as function symbol with output sort
bool) is larger than the other operators and domain elements are minimal w.r.t. ≻
which is supposed to be well-founded on the domain elements.

Symbol Elimination and Applications
51
then C1σ ≻C2σ and C2σ |=T C1σ for every ground substitution σ, so RT -
redundant clauses are R0
c-redundant.) We call the notion of redundancy induced
on inferences also RT -redundancy.
■
Let R = (Rc, Ri) be a redundancy criterion with Rc ⊆R0
c.
Theorem 5. Let N be a set of constrained P-clauses over background theory T ,
N ∗its saturation (up to R-redundancy) under HResP
≻, and N ∗
0 the set of clauses
in N ∗not containing P. For every model A of T the following are equivalent:
(1) A is a model of N ∗
0 .
(2) There exists a Π′-structure B with B |= N and B|Π = A.
Proof: Note that for constrained P-clauses the hierarchical superposition cal-
culus specializes to HResP
≻: With the terminology used in [5,8,9], the back-
ground signature is Π; the only foreground symbol is P. Since there are no
“background”-sorted terms starting with a “foreground” function symbol and
no foreground terms, sets of P-clauses are suﬃciently complete and all substitu-
tions are simple.
(2) ⇒(1) follows from the soundness of the hierarchical superposition calculus.
(1) ⇒(2) is proved with a model construction similar to the one used for proving
completeness of hierarchical superposition. For details cf. [36].
□
Case 1: Saturation is Finite. If the saturation N ∗of N under HResP
≻(up to
R-redundancy) is ﬁnite and N ∗
0 is the set of clauses in N ∗not containing P
then, by Theorem 5, the universal closure of the conjunction of the clauses in
N ∗
0 is equivalent to ∃P N.
Example 2. Consider a class of graphs described by the following set N of
constrained E-clauses:
{(1)πi(u, v)||E(u, v),
(2)πt(u, w, v)||E(u, v) →E(u, w),
(3)πe(u, v)||¬E(u, v)}
For arbitrary predicates πi, πe and πt we can generate with HResE
≻an inﬁnite
set of clauses including, e.g., all clauses of the form:
(4n) πi(u, v) ∧πt(u, w1, v) ∧πt(u, w2, w1) ∧· · · ∧πt(u, wn, wn−1) || E(u, wn)
If we assume that πi, πe, πt satisfy the additional axioms deﬁning a theory Tπ:
(c1)
∀u, v, w
πi(u, v) ∧πt(u, w, v) →πi(u, w)
(c2)
∀u, v, w
πe(u, w) ∧πt(u, w, v) →πe(u, v)
(c3) ∀u, v, w, x
πt(u, w, v) ∧πt(u, x, w) →πt(u, x, v)
then all inferences by resolution between clauses (1) and (2), (2) and (3) are Tπ-
redundant. The inferences between (2) and (2) are also Tπ-redundant: Consider
a ground instance of such an inference (the maximal literals are underlined):
πt(c1, c2, c3)||E(c1, c3) →E(c1, c2)
πt(c1, c3, c4)||E(c1, c4) →E(c1, c3)
πt(c1, c2, c3), πt(c1, c3, c4)||E(c1, c4) →E(c1, c2)

52
D. Peuter and V. Sofronie-Stokkermans
The ground instance C of (2) πt(c1, c2, c4)||E(c1, c4) →E(c1, c2) diﬀers from
the conclusion of the inference above only in the background part and is smaller
than the ﬁrst premise of the inference. If (c3) holds then C entails the conclusion
of the inference above, which makes the inference redundant w.r.t. Tπ.
Thus, only the inference of clauses (1) and (3) yields a non-redundant
resolvent:
(4)
πi(u, v) ∧πe(u, v)||⊥
so N ∗= N ∪{(4)} is saturated up to Tπ-redundancy. By Theorem 5, N is
satisﬁable iﬀ∀u, v(πi(u, v) ∧πe(u, v) →⊥) is satisﬁable w.r.t. Tπ.
■
When modelling concrete situations, the predicates πi, πe and πt might not be
arbitrary, but might have deﬁnitions using other symbols with given properties.
Example 3. The theory Tπ might be actually described in a detailed way. Let
C(r1, r2) be a graph class described by the set N of axioms in Example 2, where
πi, πe, πt are deﬁned by the axioms:
Defπ(r1, r2) = { ∀u, v πi(u, v) ↔u̸=v ∧d(u, v)≤r1(u),
∀u, v πe(u, v) ↔d(u, v)>r2(u),
∀u, v, w πt(u, w, v) ↔u̸=w ∧d(u, w)≤d(u, v)},
where d is a distance or cost function. We can regard the theory extension
T ⊆Tπ = T ∪UIF {r1,r2} ∪Defπ, where T is one of the theories T u
d , T p
d , T n
d or
T m
d
introduced in Theorem 4 and UIF {r1,r2} indicates that r1, r2 are regarded
as uninterpreted function symbols, so T ∪UIF {r1,r2} can be represented as a
local extension of the disjoint combination of a theory of real numbers and of
pure equality. We can use the hierarchical reduction in Theorem 2 to check that
(c1), (c2) and (c3) are valid w.r.t. T .
■
In applications we might not be interested in checking the satisﬁability of N
or the satisﬁability of ∀u, v(πi(u, v) ∧πe(u, v) →⊥) w.r.t. Tπ, but in a speciﬁc
model A satisfying Tπ (we refer to it as “canonical model”).
This is the case, for instance, in the applications in wireless network theory
analyzed in Sect. 1.1: The vertices of the graphs considered in this context are
very often points in the Euclidean space, and the distance is a concrete function
which can be, for instance, the Euclidean metric, or a concrete cost function
which might satisfy additional properties (for instance positivity or symmetry).
If we want to analyze such graph classes in full generality, we might assume that
the properties of some of the functions are not fully speciﬁed.
Let A be a model of a theory T describing properties of function symbols in a
set Σ we want to model. We assume that Σ contains a set of “parameters” Σpar
(function symbols whose properties are “underspeciﬁed” in T ). If we are given
a set N of constrained clauses, we might be interested in obtaining (weakest)
universal conditions Γ on Σpar such that for every ﬁxed model A of T which also
satisﬁes Γ, there exists an interpretation for P in A for which N is satisﬁed, i.e.
A |= ∃P N. We present a situation in which this is possible.

Symbol Elimination and Applications
53
Theorem 6. Let T be a theory with signature Π = (S, Σ, Pred), N a set of
constrained P-clauses. Assume that the saturation N ∗of N up to T -redundancy
w.r.t. HResP
≻is ﬁnite; let N ∗
0 be the set of clauses in N ∗not containing P.
Let Σpar ⊆Σ be a set of parameters. If (i) T allows quantiﬁer elimination
or (ii) T0 ⊆T = T0 ∪K is a local theory extension satisfying condition (CompΨ
f )
and T0 allows quantiﬁer elimination, then we can use Algorithm 1 to obtain a
(weakest) universal constraint Γ on the parameters such that every model A of
T ∪Γ is a model of (the universal closure of) N ∗
0 , hence A |= ∃P N.
Proof: Follows from Theorem 5 and Theorem 3. A proof is given in [36].
□
Example 4. Consider again the situation described in Example 3. We show
how one can use Theorem 3 and Algorithm 1 to derive constraints Γ on the
parameters r1, r2 under which for every model A of T u
d ∪UIF {r1,r2} ∪Γ
πi(u, v) ∧πe(u, v) = (u ̸= v ∧d(u, v) ≤r1(u)) ∧(d(u, v) > r2(u))
is unsatisﬁable in A (we consider the case in which d is an uninterpreted function;
other axioms for d can be analyzed as well). The formula above is unsatisﬁable
in any model A of T u
d ∪UIF {r1,r2} whose support of sort p has cardinality 1. If
we only consider models A with |Ap| ≥2 then we can proceed as follows:
Step 1: We purify the formula by introducing new constants: cd := d(u, v), c1 =
r1(u), c2 = r2(u) and obtain: (u ̸= v ∧cd ≤c1 ∧cd > c2).
Step 2: We quantify existentially all constants not denoting terms starting with
– or used as arguments of – r1, r2 and obtain: ∃v, ∃cd(u ̸= v ∧cd ≤c1 ∧cd > c2).
Step 3: After quantiﬁer elimination in a combination of LI(R) and the theory
of equality with models with ≥2 elements [37] we obtain Γ1(c1, c2, u) : c2 < c14.
Step 4: We replace the constants c1, c2 with the terms they denote and quantify
the arguments existentially and obtain: ∃u(r2(u) < r1(u)).
Step 5: We negate this condition and obtain: ∀u(r1(u) ≤r2(u)).
■
Example 5. We ﬁnd an axiomatization for the graph class C−= {G−| G ∈
C}, when class C is described by the set N of constrained clauses in Example 2
and πi, πe and πt satisfy conditions (c1), (c2), (c3). Let N ∗= N ∪{(4)} be
obtained by saturating N under HResE
≻up to redundancy. A graph H = (V, F) ∈
C−iﬀthere exists a graph G = (V, E) ∈C such that H = G−. This condition
can be described by M = N ∗∪Tr(E, F), where Tr(E, F) = {∀x, y (F(x, y) ↔
E(x, y) ∧E(y, x))}, which can be written in the form of constrained clauses as:
Tr(E, F) = {F(x, y)||E(x, y), F(x, y)||E(y, x), ¬F(x, y)||¬E(x, y) ∨¬E(y, x)}
The base theory is T ∪UIF F , the extension of T with the uninterpreted
symbol F, with signature ΠF = (Σ, Pred ∪{F}). We can saturate M under
4 We can consider only models A whose support of sort p is inﬁnite. The theory that
formalizes this is the model completion of the theory E of pure equality which allows
quantiﬁer elimination. We can then use the method for quantiﬁer elimination in
combinations of theories with QE described in [37].

54
D. Peuter and V. Sofronie-Stokkermans
HResE
≻up to redundancy (we used SCAN [19] cf. also Sect. 5 and [36]). The set
of clauses not containing E in M ∗is N ∗∪N −
F , where
N −
F = { F(x, y) →F(y, x),
F(y, x) ∧πe(x, y) →⊥,
F(x, y) ∧πe(x, y) →⊥,
πi(x, y) ∧πi(y, x) →F(y, x), πi(x, y) ∧πt(y, x, z) ∧F(y, z) →F(x, y),
πt(x, y, z) ∧F(x, z) ∧πt(y, x, u) ∧F(y, u) →F(y, x)}.
The universal closure G of the conjunction of these clauses is equivalent w.r.t.
T ∪UIF F to the formula ∃E(N ∗∪Tr(E, F)), and thus axiomatizes C−.
■
Case 2: Finite Representation of Possibly Inﬁnite Saturated Sets. The
saturation of a set N of constrained P-clauses up to redundancy under HResP
≻
might be inﬁnite. We here consider a very special case under which a ﬁnite
set of constrained P-clauses N = {φi(x) || Ci(x) | i = 1, . . . , n} can have a
saturation that can be ﬁnitely described: The situation in which the set of clauses
{C1, . . . , Cn} can be ﬁnitely saturated under ordered resolution.
Theorem 7. Let N = {φi(x)||Ci(x) | i = 1, . . . , n} be a ﬁnite set of constrained
P-clauses and NP = {C1, . . . , Cn}. Assume that the saturation of NP under
ordered resolution is ﬁnite, N ∗
P = {C1, . . . , Cn, Cn+1, . . . , Cn+k}, and the set
IP of all possible inferences used for deriving these clauses is ﬁnite and can be
eﬀectively described. If ⊥̸∈N ∗
P , then ∃P N ≡T ⊤. Assume now that ⊥∈N ∗
P . Let
A be a model of T , TA the theory with A as canonical model (i.e. TA = Th(A)).
Let NA be the set of all instances of N in which the variables are replaced with
elements in A (seen as constants). Then:
(1) The saturation N ∗
A of NA up to RT -redundancy can be described as N ∗
A =
{μA
i (a) || Ci(a) | i = 1, . . . , n + k, a elements of A}, where (μA
i )i=1,n+k are
given by the minimal model of the constrained Horn clauses CHN w.r.t. TA:
CHN = { φi(x) →μi(x) | i ∈{1, . . . , n}}
∪{ (μi(x) ∧μj(y))σ →μk(z) | Ck(z) is obtained by a resolution
inference in IP from Ci(x) and Cj(y) with m.g.u. σ}
∪{ μi(x)σ →μk(z) | Ck(z) is obtained by a factorization inference
in IP from Ci(x) with m.g.u. σ}.
(2) Let Aμ be the extension of A with predicates (μi)i whose interpretation
is given by (μA
i )i. Let j be such that ⊥= Cj. Then A |= ∃P N iﬀ
CHN∪{¬μj(x)} is satisﬁable w.r.t. TA.
Proof: (Idea): (1) follows from the fact that the computation of the minimal
model of CHN using a canonical model construction (cf. e.g. [12]) parallels the
saturation process for the ground instances of the clauses in N ∗
A.
(2) follows from (1) and the fact A |= ∃P N iﬀA is a model of the set N ∗
0 of
clauses in N ∗not containing P iﬀAμ |= ∀x¬μj(x) iﬀAμ |= CHN ∪{¬μj(x)}.
To check this, it is suﬃcient to check whether CHN ∪{¬μA
j (x)} is satisﬁable
w.r.t. TA. For a detailed proof cf. [36].
□

Symbol Elimination and Applications
55
If T has only one (canonical) model and is supported by μZ [22], we can use
μZ for checking whether N is satisﬁable5.
Example 6. Consider the set N consisting of the following constrained P-
clauses:
(1) x = y||P(x, y),
(2) y = x + 1||P(y, z) →P(x, z),
(3) n(x, y)||¬P(x, y)
over the theory of integers without multiplication with model Z. Saturating N
without any simpliﬁcation strategy yields the inﬁnite set N ∗consisting of:
(1k)
k
i=1
xi=xi−1+1 || P(x0, xk)
(2k)
k
i=1
xi=xi−1+1 || P(xk, z) →P(x0, z)
(3k) n(x0, y) ∧
k
i=1
xi=xi−1+1 || ¬P(xk, y) (4k)
k
i=1
xi=xi−1+1 ∧n(x0, xk) || ⊥, k ∈N
(i) We ﬁrst show how Theorem 7 can be used in this case. Let NP = {C1, C2, C3},
where C1 = P(x1, y1), C2 = P(y2, z1) →P(x1, z1), and C3 = ¬P(x3, y3). We
can saturate NP as follows: From C1 and C3 we can derive C4 =⊥; from C1
and C2 we can derive a clause of type C1, from C2 and C2 a clause of type C2
and from C2 and C3 a clause of type C3. We obtain N ∗
P = {C1, C2, C3, C4}. By
Theorem 7, the saturation of N is N ∗:
{μ1(x, y)||P(x, y), μ2(x, y, z)||P(y, z)→P(x, z), μ3(x, y)||¬P(x, y), μ4(x, y)|| ⊥},
where μ1, μ2, μ3, μ4 are given by the minimal model M of CHN:
CHN= {x = y →μ1(x, y),
y = x + 1 →μ2(x, y, z),
n(x, y) →μ3(x, y),
μ1(x, y) ∧μ2(u, x, y) →μ1(u, y),
μ3(x, y) ∧μ2(x, u, y) →μ3(u, y),
μ2(x, y, z) ∧μ2(u, x, z) →μ2(u, y, z),
μ1(x, y) ∧μ3(x, y) →μ4(x, y)}
μZ cannot check whether this set of Horn constraints is satisﬁable because of the
parameter n. If we replace n(x, y) with x > y μZ yields the following solution:
μ1(x, y) = x ≤y, μ2(x, y, z) = (y > z) ∨(x < z), μ3(x, y) = x > y, μ4 =⊥.
(ii) Alternatively, note that if we use the fact that ∃x1 . . . xk−1
k
i=1 xi=xi−1+1
is equivalent to xk = x0 + k we obtain an inﬁnite set of clauses consisting of:
(1′
k) y = x + k||P(x, y)
(2′
k) y = x + k||P(y, z) →P(x, z)
(3′
k) n(x, y) ∧z = x + k||¬P(z, y) (4′
k) y = u + k ∧n(u, y)|| ⊥
k ∈N
If we regard k in each clause as a universally quantiﬁed variable (with additional
condition k ≥0) we obtain:
N ′ = { y = x + k ∧k ≥0||P(x, y), y = x + k ∧k ≥0||P(y, z),
n(x, y) ∧z = x + k ∧k ≥0||¬P(z, y), y = u + k ∧k ≥0 ∧n(u, y)|| ⊥}.
If A = (Z, nA), A |= ∃P N ′ iﬀA |= ∀u, y, k (k ≥0 ∧y = u + k →¬n(u, y)).
5 If the set N of constrained P-clauses (hence the set of constrained Horn clauses
CHN) contains at least one parameter then μZ often returns “unknown”. In addi-
tion, if μZ can prove satisﬁability of CHN ∪{¬μj(x)} for a non-parametric problem,
the model it returns is not guaranteed to be minimal in general, and cannot be
used for representing the saturated set of clauses. By Theorem 7 (2), satisﬁability of
CHN ∪{¬μj(x)} is suﬃcient for proving the satisﬁability of N in this case.

56
D. Peuter and V. Sofronie-Stokkermans
Note that the interpretations of (μi)1≤i≤4 in the minimal model of CHN w.r.t.
the model A = (Z, nA), for a ﬁxed interpretation of n (say as nA(x, y) = (x > y))
are: μ1(x, y) = μ2(x, y, z) = ∃k(k ≥0∧y = x+k), μ3(x, y) = ∃z∃k(n(z, y)∧x =
z + k) and μ4(x, y) = μ1(x, y) ∧μ3(x, y). This shows the link to (i).
■
Example 6(ii) uses acceleration techniques, in particular the following result:
Theorem 8 [14,18]. Let N be a set of constrained clauses of the form:
N = {φ0(x) || R(x),
φ(x) ∧y = M · x + v || R(x) →R(y)}
where x, y describe vectors of n variables, v a vector of n constants in Z, φ0 is a
condition expressible in Presburger arithmetic and M = (mi,j)1≤i,j≤n is a n × n
matrix over Z, and φ(x1, . . . , xn) = k
i=1(n
j=1 aijxj ≤bi), where aij, bi ∈Z.
The interpretation of R in the minimal model of N is Presburger deﬁnable
if ⟨M⟩= {M n | n ∈N} is ﬁnite. If φ = ⊤then the interpretation of R in the
minimal model of N is Presburger deﬁnable iﬀ⟨M⟩= {M n | n ∈N} is ﬁnite.
Acceleration techniques have been investigated e.g. for fragments of theories of
arrays with read and write in the presence of iterators and selectors in [4]. Similar
ideas are used in the superposition calculus in [17,26], and in approaches which
combine superposition and induction [30] or use solutions for recurrences in loop
invariant generation [31,32]. We plan to analyze such aspects in future work.
4
Checking Entailment
Let T be a theory with signature Π = (S, Σ, Pred), and let P 1 = P 1
1 , . . . , P 1
n1
and P 2 = P 2
1 , . . . , P 2
n2 be ﬁnite sequences of diﬀerent predicate symbols with
P i
j ̸∈Pred, and Πi = (Σ, Pred ∪{P i
j | 1 ≤j ≤ni}) for i = 1, 2.
Let F1 be a universal Π1-formula and F2 be a universal Π2-formula. We analyze
the problem of checking whether “∃P 1 F1 entails ∃P 2 F2 w.r.t. T ” holds.
Example 7. Such questions arise in the graph-theoretic problems discussed in
Sect. 1.1. Let A be a class of graphs described by axioms AxA and B be a class
of graphs described by axioms AxB. Let T be a theory used for expressing these
axioms. Consider the ·+ and ·−transformations described in Sect. 1.1. Then
A+ ⊆B−(i.e. for every graph H = (V, F) ∈A+ we have H ∈B−) if and only
if ∃EA (AxA ∧Tr+(EA, F)) |=T ∃EB (AxB ∧Tr−(EB, F)).
■
Assume that there exist Π-formulae G1 and G2 such that G1 ≡T ∃P 1F1 and
G2 ≡T ∃P 2F2. Such formulae can be found either by saturation6 by successively
eliminating P1, . . . , Pn, or by using acceleration techniques or other methods. In
this case, ∃P 1 F1 |=T ∃P 2 F2 iﬀG1 |=T G2 (which is the case iﬀG1∧¬G2 |=T ⊥).
6 We can iterate the application of HResP
≻for variables P i
1, . . . , P i
n (in this order). This
corresponds to a variant of ordered resolution which we denote by HRes
P i
1,...,P i
n
≻
; if
saturation terminates the conjunction of clauses not containing P i
1, . . . , P i
n is equiv-
alent to ∃P i
1, . . . , P i
n NFi, where NFi is the clause form of Fi.

Symbol Elimination and Applications
57
The problem of checking whether G1 ∧¬G2 |=T ⊥is in general undecidable,
even if G1 and G2 are universal formulae and T is the extension of Presburger
arithmetic or real arithmetic with a new function or predicate symbol (cf. [42]).
If G1∧¬G2 is in a fragment of T for which checking satisﬁability is decidable,
then we can eﬀectively check whether ∃P 1 F1 |=T ∃P 2 F2. This is obviously the
case when T is a decidable theory. We will show that a similar condition can be
obtained for local theory extensions of theories allowing quantiﬁer elimination if
G1 and G2 are universal formulae and the extensions satisfy a certain “ﬂatness
property” which allows ﬁnite complete instantiation and that in both cases we
can also generate constraints on “parameters” under which entailment holds.
Theorem 9. Assume that there exist Π-formulae G1 and G2 such that G1 ≡T
∃P 1F1 and G2 ≡T ∃P 2F2. If T is a decidable theory then we can eﬀectively check
whether ∃P 1 F1 |=T ∃P 2 F2. If T has quantiﬁer elimination and the formulae
F1, F2 contain parametric constants, we can use quantiﬁer elimination in T to
derive conditions on these parameters under which ∃P 1 F1 |=T ∃P 2 F2.
Theorem 10. Assume that there exist universal Π-formulae G1 and G2 such
that G1 ≡T
∃P 1F1 and G2 ≡T
∃P 2F2, and that T
= T0 ∪K, where T0
is a decidable theory with signature Π0 = (S0, Σ0, Pred0) where S0 is a set
of interpreted sorts and K is a set of (universally quantiﬁed) clauses over
Π = (S0 ∪S1, Σ0 ∪Σ1, Pred0 ∪Pred1), where (i) S1 is a new set of uninter-
preted sorts, (ii) Σ1, Pred1 are sets of new function, resp. predicate symbols which
have only arguments of uninterpreted sort ∈S1, and all function symbols in Σ1
have interpreted output sort ∈S0. Assume, in addition, that all variables and
constants of sort ∈S1 in K, G1 and ¬G2 occur below function symbols in Σ1.
Then:
(1) We can use the decision procedure for T0 to eﬀectively check whether G1 ∧
¬G2 |=T ⊥(hence if ∃P 1 F1 |=T ∃P 2 F2).
(2) If T0 allows quantiﬁer elimination and the formulae F1, F2 (hence also
G1, G2) contain parametric constants and functions, we can use Algorithm 1
for obtaining constraints on the parameters under which ∃P 1 F1 |=T ∃P 2 F2.
Proof: Let C be the set of constants of uninterpreted sort s ∈S1 occurring
in K, G1 and ¬G2. Note that G1 ∧¬G2 is satisﬁable w.r.t. T = T0 ∪K iﬀ
(K ∧G1)[C] ∧¬G2 is satisﬁable, where (K ∧G1)[C] is the set of all instances of
K ∧G1 in which the variables of sort s ∈S1 are replaced with constants of sort
s in C. (1) The hierarchical reasoning method in Theorem 2 allows us to reduce
testing whether G1 ∧¬G2 |=T ⊥to a satisﬁability test w.r.t. T0. (2) If T0 allows
QE we can use Theorem 3.
□
We illustrate how Theorem 10 can be used for checking one of the class inclusions
mentioned in Sect. 1.1.

58
D. Peuter and V. Sofronie-Stokkermans
Example 8. Let QUDG(r) = (MinDG(r) ∩MaxDG(1))−, be axiomatized
by MinDG(r) ∧MinDG(1) ∧Tr−(E, F), where r is a function symbol (where r(v)
models the maximum communication distance of node v), and:
MinDG(r) : ∀x, y πi
r(x, y) →E(x, y)
where πi
r(x, y) = x ̸= y ∧d(x, y) ≤r(x)
MaxDG(1) : ∀x, y πe(x, y) →¬E(x, y) where πe(x, y) = d(x, y) > 1
Tr−(E, F) : ∀x, y (F(x, y) ↔E(x, y) ∧E(y, x)) .
We want to check7 whether A(r) ⊆B(r), where A(r) = QUDG(r) and B(r) =
(MinDG(r)∩MaxDG(1))+ is described by MinDG(r)∧MinDG(1)∧Tr+(E, F).
We obtain axiomatizations G1 ≡∃E(MinDG(r)∧MinDG(1)∧Tr−(E, F)) for A(r)
and G2 ≡∃E(MinDG(r)∧MinDG(1)∧Tr+(E, F)) for B(r) by eliminating E:
G1
∀x, y πi
r(x, y) ∧πe(x, y) →
⊥
∀x, y πi
r(x, y) ∧πi
r(y, x) →
F(y, x)
∀x, y πe(x, y)
→¬F(x, y)
∀x, y πe(x, y)
→¬F(y, x)
∀x, y F(x, y)
→
F(y, x)
G2
∀x, y πi
r(x, y) ∧πe(x, y) →
⊥
∀x, y πe(x, y) ∧πe(y, x) →¬F(y, x)
∀x, y πi
r(x, y)
→
F(x, y)
∀x, y πi
r(x, y)
→
F(y, x)
∀x, y F(x, y)
→
F(y, x)
∀x
πe(x, x)
→¬F(x, x)
We check whether G1 |=T G2, i.e. whether G1 ∧¬G2 is unsatisﬁable w.r.t. T ,
where ¬G2 is the disjunction of the following ground formulae (we ignore the
negation of the ﬁrst clause obviously implied by G1):
(g1) πe(a, b) ∧πe(b, a) ∧F(b, a) (g2) πe(a, a) ∧F(a, a)
(g3) F(a, b) ∧¬F(b, a)
(g4) πi
r(a, b) ∧¬F(a, b)
(g5) πi
r(a, b) ∧¬F(b, a)
By Theorem 10 (2), we can consider the set of all instances of G1 in which
the variables of sort p are replaced with the constants a, b, then use a method
for checking ground satisﬁability of G1[T] ∧gi w.r.t. Td ∪UIF r, where Td ∈
{T u
d , T p
d , T s
d , T m
d }. For this, we use H-PILoT [28]. This allows us to check
that G1[T] ∧gi is unsatisﬁable for i ∈{1, 2, 3}, but satisﬁable for i ∈{4, 5}
(this is so for all four theories). For cases 4 and 5 we can use Algorithm 1
to derive conditions on parameters under which G1[T] ∧gi is unsatisﬁable.
If e.g. we consider d and r to be parameters, for T m
d
we obtain condition
Cd,r = ∀x, y(x ̸= y ∧d(x, y) ≤1 ∧d(x, y) ≤r(x) →d(y, x) ≤r(y)). For
further details cf. [36].
■
5
Conclusions
In this paper, we analyzed possibilities of combining general second-order symbol
elimination and property-directed symbol elimination for analyzing the satisﬁa-
bility of formulae w.r.t. models in a theory T and for checking entailment between
formulae expressed using second-order quantiﬁcation. In particular, these meth-
ods proved useful for obtaining (weakest) constraints Γ on “parameters” used
in the description of the theory T such that satisﬁability or entailment is guar-
anteed in models satisfying Γ. We tested the methods we proposed on several
examples. Since the implementations of the hierarchical superposition calculus
7 To check that the inclusion holds in one given model A we can choose T = Th(A).

Symbol Elimination and Applications
59
we are aware of have as background theory linear arithmetic and in our examples
we had more complex theories, we used a form of abstraction ﬁrst: We renamed
the constraints over more complex theories with new predicate symbols, and
used SCAN [19] for second-order quantiﬁer elimination. For satisﬁability check-
ing we used H-PILoT [28] with Z3 [11,13] and Redlog [16] as external provers;
for obtaining the constraints on parameters we used Algorithm 1 [40], imple-
mented in an extension of H-PILoT, sehpilot, by P. Marohn [35]. Some tests can
be found in [36]. H-PILoT uses eager instantiation, so provers like CVC4 [6]
or Z3 [11,13] are in general faster in proving unsatisﬁability. The advantage of
using H-PILoT is that knowing the instances needed for a complete instantiation
allows us to correctly detect satisﬁability (and generate models) in situations in
which e.g. CVC4 returns “unknown”, and use property-directed symbol elimina-
tion to obtain additional constraints on parameters which ensure unsatisﬁability.
For checking the satisﬁability of families of constrained Horn clauses we used the
ﬁxpoint package of Z3 [22]. In future work we would like to identify other sit-
uations in which second-order quantiﬁer elimination yields ﬁnite formulae. We
would like to analyze possibilities of checking entailment when the second-order
quantiﬁer elimination method returns a ﬁxpoint and not a formula. (The main
obstacle when working on this problem was that μZ returns “unknown” in the
presence of parameters.)
Acknowledgments. We thank Hannes Frey and Lucas B¨oltz for the numerous dis-
cussions we had on the problems in wireless networks discussed in Sect. 1.1, Renate
Schmidt for maintaining a website where one can run SCAN online and for sending
us the executables and instructions for running them, and to the anonymous reviewers
for their helpful comments.
References
1. Abdulaziz, M., Mehlhorn, K., Nipkow, T.: Trustworthy graph algorithms (invited
talk). In: Rossmanith, P., Heggernes, P., Katoen, J. (eds.) Proceedings 44th Inter-
national Symposium on Mathematical Foundations of Computer Science (MFCS
2019), volume 138 of LIPIcs, pp. 1:1–1:22. Schloss Dagstuhl - Leibniz-Zentrum f¨ur
Informatik (2019)
2. Ackermann, W.: Untersuchungen ¨uber das Eliminationsproblem der mathematis-
chen Logik. Mathematische Annalen 110, 390–413 (1935)
3. Ackermann, W.: Zum Eliminationsproblem der mathematischen Logik. Mathema-
tische Annalen 111, 61–63 (1935)
4. Alberti, F., Ghilardi, S., Sharygina, N.: Deﬁnability of accelerated relations in
a theory of arrays and its applications. In: Fontaine, P., Ringeissen, C., Schmidt,
R.A. (eds.) FroCoS 2013. LNCS (LNAI), vol. 8152, pp. 23–39. Springer, Heidelberg
(2013). https://doi.org/10.1007/978-3-642-40885-4 3
5. Bachmair, L., Ganzinger, H., Waldmann, U.: Refutational theorem proving for
hierarchic ﬁrst-order theories. Appl. Algebra Eng. Commun. Comput. 5, 193–212
(1994)
6. Barrett, C.W., et al.: CVC4. In: Gopalakrishnan, G., Qadeer, S. (eds.) CAV 2011.
LNCS, vol. 6806, pp. 171–177. Springer, Heidelberg (2011). https://doi.org/10.
1007/978-3-642-22110-1 14

60
D. Peuter and V. Sofronie-Stokkermans
7. Barri`ere, L., Fraigniaud, P., Narayanan, L., Opatrny, J.: Robust position-based
routing in wireless ad hoc networks with irregular transmission ranges. Wirel.
Commun. Mobile Comput. 3(2), 141–153 (2003)
8. Baumgartner, P., Waldmann, U.: Hierarchic superposition with weak abstraction.
In: Bonacina, M.P. (ed.) CADE 2013. LNCS (LNAI), vol. 7898, pp. 39–57. Springer,
Heidelberg (2013). https://doi.org/10.1007/978-3-642-38574-2 3
9. Baumgartner, P., Waldmann, U.: Hierarchic superposition revisited. In: Lutz, C.,
Sattler, U., Tinelli, C., Turhan, A.-Y., Wolter, F. (eds.) Description Logic, Theory
Combination, and All That. LNCS, vol. 11560, pp. 15–56. Springer, Cham (2019).
https://doi.org/10.1007/978-3-030-22102-7 2
10. Behmann, H.: Beitr¨age zur Algebra der Logik, insbesondere zum Entschei-
dungsproblem. Mathematische Annalen 86(3–4), 163–229 (1922)
11. Bjørner, N., de Moura, L., Nachmanson, L., Wintersteiger, C.M.: Programming
Z3. In: Bowen, J.P., Liu, Z., Zhang, Z. (eds.) SETSS 2018. LNCS, vol. 11430, pp.
148–201. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-17601-3 4
12. Bjørner, N., Gurﬁnkel, A., McMillan, K., Rybalchenko, A.: Horn clause solvers for
program veriﬁcation. In: Beklemishev, L.D., Blass, A., Dershowitz, N., Finkbeiner,
B., Schulte, W. (eds.) Fields of Logic and Computation II. LNCS, vol. 9300, pp.
24–51. Springer, Cham (2015). https://doi.org/10.1007/978-3-319-23534-9 2
13. Bjørner, N., Nachmanson, L.: Navigating the universe of Z3 theory solvers. In:
Carvalho, G., Stolz, V. (eds.) SBMF 2020. LNCS, vol. 12475, pp. 8–24. Springer,
Cham (2020). https://doi.org/10.1007/978-3-030-63882-5 2
14. Boigelot, B.: Symbolic Methods for Exploring Inﬁnite State Spaces. Ph.D. thesis,
Universit´e de Li`ege (1998)
15. Courcelle, B.: The expression of graph properties and graph transformations in
monadic second-order logic. In: Rozenberg, G. (ed.) Handbook of Graph Grammars
and Computing by Graph Transformations, Volume 1: Foundations, pp. 313–400.
World Scientiﬁc (1997)
16. Dolzmann, A., Sturm, T.: REDLOG: computer algebra meets computer logic.
SIGSAM Bull. 31(2), 2–9 (1997)
17. Fietzke, A., Kruglov, E., Weidenbach, C.: Automatic generation of invariants for
circular derivations in SUP(LA). In: Bjørner, N., Voronkov, A. (eds.) LPAR 2012.
LNCS, vol. 7180, pp. 197–211. Springer, Heidelberg (2012). https://doi.org/10.
1007/978-3-642-28717-6 17
18. Finkel, A., Leroux, J.: How to compose Presburger-accelerations: applications to
broadcast protocols. In: Agrawal, M., Seth, A. (eds.) FSTTCS 2002. LNCS, vol.
2556, pp. 145–156. Springer, Heidelberg (2002). https://doi.org/10.1007/3-540-
36206-1 14
19. Gabbay, D.M., Ohlbach, H.J.: Quantiﬁer elimination in second-order predicate
logic. In: Nebel, B., Rich, C., Swartout, W. (eds.) Principles of Knowledge Rep-
resentation and Reasoning (KR92), pp. 425–435. Morgan Kaufmann. Also pub-
lished as a Technical Report MPI-I-92-231, Max-Planck-Institut f¨ur Informatik,
Saarbr¨ucken, and in the South African Computer Journal (1992)
20. Gabbay, D.M., Schmidt, R.A., Szalas, A.: Second-Order Quantiﬁer Elimination -
Foundations, Computational Aspects and Applications, volume 12 of Studies in
logic: Mathematical logic and foundations. College Publications (2008)
21. Goranko, V., Hustadt, U., Schmidt, R.A., Vakarelov, D.: SCAN is complete for
all Sahlqvist formulae. In: Berghammer, R., M¨oller, B., Struth, G. (eds.) RelMiCS
2003. LNCS, vol. 3051, pp. 149–162. Springer, Heidelberg (2004). https://doi.org/
10.1007/978-3-540-24771-5 13

Symbol Elimination and Applications
61
22. Hoder, K., Bjørner, N., de Moura, L.: μZ– an eﬃcient engine for ﬁxed points
with constraints. In: Gopalakrishnan, G., Qadeer, S. (eds.) CAV 2011. LNCS, vol.
6806, pp. 457–462. Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-
642-22110-1 36
23. Hoder, K., Kov´acs, L., Voronkov, A.: Interpolation and symbol elimination in Vam-
pire. In: Giesl, J., H¨ahnle, R. (eds.) IJCAR 2010. LNCS (LNAI), vol. 6173, pp.
188–195. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-14203-
1 16
24. Horbach, M., Sofronie-Stokkermans, V.: Obtaining ﬁnite local theory axiomatiza-
tions via saturation. In: Fontaine, P., Ringeissen, C., Schmidt, R.A. (eds.) FroCoS
2013. LNCS (LNAI), vol. 8152, pp. 198–213. Springer, Heidelberg (2013). https://
doi.org/10.1007/978-3-642-40885-4 14
25. Horbach, M., Sofronie-Stokkermans, V.: Locality transfer: from constrained axiom-
atizations to reachability predicates. In: Demri, S., Kapur, D., Weidenbach, C.
(eds.) IJCAR 2014. LNCS (LNAI), vol. 8562, pp. 192–207. Springer, Cham (2014).
https://doi.org/10.1007/978-3-319-08587-6 14
26. Horbach, M., Weidenbach, C.: Deciding the inductive validity of ∀∃∗queries. In:
Gr¨adel, E., Kahle, R. (eds.) CSL 2009. LNCS, vol. 5771, pp. 332–347. Springer,
Heidelberg (2009). https://doi.org/10.1007/978-3-642-04027-6 25
27. Ihlemann, C., Jacobs, S., Sofronie-Stokkermans, V.: On local reasoning in veriﬁca-
tion. In: Ramakrishnan, C.R., Rehof, J. (eds.) TACAS 2008. LNCS, vol. 4963, pp.
265–281. Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-540-78800-
3 19
28. Ihlemann, C., Sofronie-Stokkermans, V.: System description: H-PILoT. In:
Schmidt, R.A. (ed.) CADE 2009. LNCS (LNAI), vol. 5663, pp. 131–139. Springer,
Heidelberg (2009). https://doi.org/10.1007/978-3-642-02959-2 9
29. Ihlemann, C., Sofronie-Stokkermans, V.: On hierarchical reasoning in combinations
of theories. In: Giesl, J., H¨ahnle, R. (eds.) IJCAR 2010. LNCS (LNAI), vol. 6173,
pp. 30–45. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-14203-
1 4
30. Kersani, A., Peltier, N.: Combining superposition and induction: A practical real-
ization. In: Fontaine, P., Ringeissen, C., Schmidt, R.A. (eds.) FroCoS 2013. LNCS
(LNAI), vol. 8152, pp. 7–22. Springer, Heidelberg (2013). https://doi.org/10.1007/
978-3-642-40885-4 2
31. Kov´acs, L.: Invariant generation for P-solvable loops with assignments. In: Hirsch,
E.A., Razborov, A.A., Semenov, A., Slissenko, A. (eds.) CSR 2008. LNCS, vol.
5010, pp. 349–359. Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-
540-79709-8 35
32. Kov´acs, L.: Reasoning algebraically about P-solvable loops. In: Ramakrishnan,
C.R., Rehof, J. (eds.) TACAS 2008. LNCS, vol. 4963, pp. 249–264. Springer, Hei-
delberg (2008). https://doi.org/10.1007/978-3-540-78800-3 18
33. Kov´acs, L., Voronkov, A.: Interpolation and symbol elimination. In: Schmidt, R.A.
(ed.) CADE 2009. LNCS (LNAI), vol. 5663, pp. 199–213. Springer, Heidelberg
(2009). https://doi.org/10.1007/978-3-642-02959-2 17
34. Kuhn, F., Wattenhofer, R., Zollinger, A.: Ad hoc networks beyond unit disk graphs.
Wirel. Networks 14(5), 715–729 (2008)
35. Marohn, P.: Veriﬁkation und Constraint-Generierung in parametrisierten Syste-
men. BSC Thesis, University Koblenz-Landau (2021)
36. Peuter, D., Marohn, P., Sofronie-Stokkermans, V.: Symbol elimination for para-
metric second-order entailment problems (with applications to problems in wireless
network theory) (2021). https://arxiv.org/abs/2107.02333

62
D. Peuter and V. Sofronie-Stokkermans
37. Peuter, D., Sofronie-Stokkermans, V.: On invariant synthesis for parametric sys-
tems. In: Fontaine, P. (ed.) CADE 2019. LNCS (LNAI), vol. 11716, pp. 385–405.
Springer, Cham (2019). https://doi.org/10.1007/978-3-030-29436-6 23
38. Sofronie-Stokkermans, V.: Hierarchic reasoning in local theory extensions. In:
Nieuwenhuis, R. (ed.) CADE 2005. LNCS (LNAI), vol. 3632, pp. 219–234. Springer,
Heidelberg (2005). https://doi.org/10.1007/11532231 16
39. Sofronie-Stokkermans, V.: On interpolation and symbol elimination in theory
extensions. In: Olivetti, N., Tiwari, A. (eds.) IJCAR 2016. LNCS (LNAI), vol.
9706, pp. 273–289. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-
40229-1 19
40. Sofronie-Stokkermans, V.: On interpolation and symbol elimination in theory
extensions. Log. Methods Comput. Sci. 14(3) (2018)
41. Voigt, M.: Towards elimination of second-order quantiﬁers in the separated frag-
ment. In: Koopmann, P., Rudolph, S., Schmidt, R.A., Wernhard, C. (eds.) Pro-
ceedings of the Workshop on Second-Order Quantiﬁer Elimination and Related
Topics (SOQE 2017), Dresden, Germany, 6–8 December, 2017, volume 2013 of
CEUR Workshop Proceedings, pp. 67–81. CEUR-WS.org (2017)
42. Voigt, M.: Decidable fragments of ﬁrst-order logic and of ﬁrst-order linear
arithmetic with uninterpreted predicates. Ph.D. thesis, Saarland University,
Saarbr¨ucken, Germany (2019)

On the Copy Complexity of Width 3
Horn Constraint Systems
K. Subramani1(B), P. Wojciechowski1, and Alvaro Velasquez2
1 LDCSEE, West Virginia University, Morgantown, WV, USA
k.subramani@mail.wvu.edu, pwojciec@mix.wvu.edu
2 Air Force Research Laboratory, Rome, NY, USA
alvaro.velasquez.1@us.af.mil
Abstract. In this paper, we analyze the copy complexity of unsatisﬁ-
able width 3 Horn constraint systems, under the ADD refutation system.
Recall that a linear constraint of the form n
i=1 ai · xi ≥b, is said to be
a Horn constraint if all the ai ∈{0, 1, −1} and at most one of the ais
is positive. A conjunction of such constraints is called a Horn constraint
system (HCS). An HCS is said to have width 3, if there are at most 3
variables with non-zero coeﬃcients per constraint. Horn constraints arise
in a number of domains including but not limited to program veriﬁca-
tion, power systems, econometrics, and operations research. The ADD
refutation system is both sound and complete. Additionally, it is the
simplest and most natural refutation system for refuting the feasibility
of a system of linear constraints. The copy complexity of an infeasible
linear constraint system (not necessarily Horn) in a refutation system is
the minimum number of times each constraint needs to be replicated, in
order to obtain a read-once refutation. In this paper, we analyze width 3
HCSs from the perspective of copy complexity.
1
Introduction
This paper is concerned with the problem of determining bounds on the copy
complexity of Horn constraint systems (HCSs) under the ADD refutation sys-
tem [10]. A linear constraint of the form n
i=1 ai · xi ≥b, b ∈Z, is said to be
Horn, if ∀i, ai ∈{0, 1, −1} and at most one of the ai = 1. A conjunction of such
constraints is called a Horn constraint system (HCS). Horn constraints arise
in a number of application domains such as program veriﬁcation [2,3], lattice
programming [9] and econometrics. The ADD refutation system is a refutation
system with a single inference rule, viz., if two constraints l1 and l2 are part of
the HCS or can be inferred from the HCS, then so can their sum. It is well-known
that the ADD refutation system is both sound and complete from the perspective
of establishing infeasibility in polyhedral constraint systems [10]. Furthermore,
K. Subramani—This research was supported in part by the Air-Force Oﬃce of Scien-
tiﬁc Research through Grant FA9550-19-1-0177 and in part by the Air-Force Research
Laboratory, Rome through Contract FA8750-17-S-7007.
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 63–78, 2021.
https://doi.org/10.1007/978-3-030-86205-3_4

64
K. Subramani et al.
this system enables the extraction of the actual refutation. When it comes to
establishing infeasibility, the goal is clearly to ﬁnd “short” certiﬁcates, since such
certiﬁcates can be eﬀectively veriﬁed. However, not all constraint systems have
compact certiﬁcates in the ADD refutation system. In our quest for compact-
ness, we attempt to minimize the number of times a constraint can be used by
the refutation system, in order to infer a contradiction. This leads to the notion
of copy complexity of a constraint system under the ADD refutation system. For
the rest of the paper, we will assume that the constraint system under consider-
ation is Horn and that the refutation system is the ADD refutation system (see
Sect. 2). Accordingly, we will use the phrase “copy complexity” without reference
to the accompanying refutation system.
The problem of determining the copy complexity of an HCS is known to be
NP-hard [8].
In this paper, we investigate width 3 HCSs. In most program veriﬁcation
applications, the width of Horn clauses or constraints is bounded by a small
constant. Accordingly, this investigation is well-motivated.
2
Statement of Problems
In this section, we deﬁne the problems studied in this paper.
Deﬁnition 1. A system of constraints A · x ≥b is said to be a Horn Constraint
system (HCS) if:
1. The entries in A belong to the set {0, 1, −1}.
2. Each row of A contains at most one positive entry.
3. x is a real valued vector.
4. b is an integral vector.
In the constraint a · x ≥bj, bj is called the deﬁning constant. If a Horn
constraint has at most w non-zero coeﬃcients, then it is called a width w Horn
constraint. A system of width w Horn constraints is known as a width w HCS.
In a Horn constraint we refer to the terms xi and −xi as literals.
If a Horn constraint has only one non-zero coeﬃcient, then it is called an
absolute constraint. If that coeﬃcient is 1, then it is called a positive absolute
constraint.
We are interested in certiﬁcates of infeasibility. In this paper, we utilize an
inference rule known as the ADD rule [10]. This inference rule derives a new
constraint by summing a pair of constraints (either from the original system or
derived by previous inferences) and is deﬁned as follows:
ADD :
n
i=1 ai · xi ≥b1
n
i=1 a′
i · xi ≥b2
n
i=1(ai + a′
i) · xi ≥b1 + b2
(1)
This inference rule plays a similar role to the role played by resolution in
clausal formulas.
Using Rule (1), we can now deﬁne a linear refutation.

Copy Complexity of Width 3 Horn Constraint Systems
65
Deﬁnition 2. A linear refutation is a sequence of applications of the ADD rule
that results in a contradiction of the form 0 ≥b, b > 0.
The form of refutation deﬁned in Deﬁnition 2 is both sound and complete
when used as a proof system for linear feasibility. It is sound since any assignment
that satisﬁes the constraints used by an application of the ADD rule also satisﬁes
the constraint derived by that application. Additionally, ADD rule based linear
refutation is complete. This means that repeated application of the ADD rule
will eventually result in a contradiction of the form: 0 ≥b, b > 0 for any linearly
infeasible system. The completeness of ADD rule based linear refutations was
established by Farkas [4], in a lemma that is famously known as Farkas’ Lemma
for systems of linear inequalities [12].
Of particular interest is a restricted form of refutation known as read-once
refutation.
Deﬁnition 3. A read-once refutation is a refutation in which each constraint,
l, can be used in only one inference. This applies to constraints present in the
original systems and those derived as a result of previous inferences.
Example 1. Consider the HCS H deﬁned by System (2).
l1 : x1 −x2 −x3 ≥0
l2 : x2 −x3 ≥−1
l3 : x3 −x1 ≥1
l4 : x3 ≥1
(2)
System (2) has the following read-once refutation:
1. Apply the ADD rule to l1 and l2 to get l5 : x1 −2 · x3 ≥−1.
2. Apply the ADD rule to l5 and l3 to get l6 : −x3 ≥0.
3. Apply the ADD rule to l6 and l4 to get the contradiction 0 ≥1.
We can now deﬁne copy complexity in terms of read-once refutations.
Deﬁnition 4. A HCS H has copy complexity k if k is the smallest integer
for which there exists a multi-set of Horn constraints, H′ such that:
1. Every constraint in H appears at most k times in H′.
2. Every constraint in H′ appears in H.
3. H′ has a read-once refutation using the ADD rule.
In this paper, we examine the following problems related to copy complexity:
Deﬁnition 5. The copy complexity (CCD) problem: given an HCS H and an
integer k, is the copy complexity of H at most k?
Deﬁnition 6. The optimal copy complexity (CCOpt) problem: given an HCS H,
what is the smallest k such that the copy complexity of H is at most k?
In this paper, we focus on these problems in width 3 HCSs, for the most part.
The principal contributions of this paper are as follows:

66
K. Subramani et al.
1. Establishing a lower bound on the copy complexity of bounded width HCSs
(Theorem 2).
2. Establishing that the CCD problem for width 3 HCSs is NP-complete (The-
orem 4).
3. Establishing that no algorithm for the CCD problem for width 3 HCSs can run
in time 2o(n) unless the Exponential Time Hypothesis (ETH) fails (Theorem
6).
4. Establishing that the CCOpt problem for width 3 HCSs is NPO-complete [7]
(Theorem 7).
3
Observations on Copy Complexity
In this section, we observe several properties of the copy complexity of bounded
width HCSs.
First, we show that the copy complexity of a width w HCS with ((w−1)·n′+1)
variables can be as large as 2(w−2)·n′.
Theorem 1. For each integer n′ ≥0, there exists a width w HCS H with ((w −
1) · n′ + 1) variables such that H has copy complexity 2(w−2)·n′.
Proof. Let H be the HCS constructed as follows:
1. The constraint l1 is −x1 ≥1.
2. For r = 2, . . . , (w −1) · n′ + 1, the constraint lr is
xr−1 −
⌈r−1
w−1⌉·(w−1)+1

j=r
xj ≥0.
3. The constraint l(w−1)·n′+2 is x(w−1)·n′+1 ≥0.
We will show that for each i = 0 . . . n′, the constraint l(w−1)·i+2 must be used
at least 2(w−2)·i times by any linear refutation of H.
Note that constraint l1 is the only constraint in H that has a positive deﬁning
constant. Thus, l1 must be in any linear refutation of H. Additionally, the only
constraint in H with the literal x1 is l2. Thus, the constraint l2 must be used at
least 20 times by any linear refutation of H.
Now assume that the constraint l(w−1)·i+2 must be used at least 2(w−2)·i
times by any linear refutation of H. Note that this constraint contains the literal
−x(w−1)·i+2 and that this is the only constraint in H containing that literal. The
only constraint in H with the literal x(w−1)·i+2 is l(w−1)·i+3. Thus, this constraint
must also be used at least 2(w−2)·i times by any linear refutation of H.
Both constraints l(w−1)·i+2 and l(w−1)·i+3 contain the literal −x(w−1)·i+3 and
these are the only constraints in H containing that literal. Thus, the literal
−x(w−1)·i+3 is used by at least 2(w−2)·i+1 constraints in any linear refutation
of H.

Copy Complexity of Width 3 Horn Constraint Systems
67
For each j = 1 . . . w −1, the constraints l(w−1)·i+2 through l(w−1)·i+j+1 con-
tain the literal −x(w−1)·i+j+1 and these are the only constraints in H containing
that literal. Thus, the literal −x(w−1)·i+j+1 is used by at least 2(w−2)·i+j−1 con-
straints in any linear refutation of H.
Note that the only constraint in H with the literal x(w−1)·i+w
=
x(w−1)·(i+1)+1 is l(w−1)·(i+1)+2. Thus, any linear refutation of H must use the
constraint l(w−1)·(i+1)+2 at least 2(w−2)·(i+1) times as desired.
Thus, for each i = 0 . . . n′, the constraint l(w−1)·i+2 must be used at least
2(w−2)·i times by any linear refutation of H. In particular, the constraint
l(w−1)·n′+2 must be used at least 2(w−2)·n′ times by any linear refutation
of H.
We can construct a linear refutation of H by using each constraint lr,
2r−1−⌊r−1
w−1⌋times.
⊓⊔
From, Theorem 1, there is a width w HCS H with n ≡1 mod (w −1) vari-
ables such that H has copy complexity at least 2(w−2)· n−1
w−1 . Utilizing a diﬀerent
construction, we can obtain a tighter bound based on a generalization of the
Fibonacci Sequence.
Recall that the Fibonacci Sequence Fn is the sequence in which each element
is the sum of the two previous elements. More formally, the Fibonacci Sequence
is deﬁned as follows: F0 = 0, F1 = 1, and Fn = Fn−1 + Fn−2 for n ≥2. We
can generalize this deﬁnition by having each element depend on more than just
the previous two elements. Our result on width w HCSs utilizes the following
generalization of the Fibonacci Sequence.
For each w ≥1, the width w Fibonacci Sequence Fw,n is deﬁned as follows:
Fw,0 = 0, Fw,1 = 1, Fw,n = n−1
i=max{0,n−w} Fw,i for n ≥2. Thus, in the width w
Fibonacci Sequence each element depends on the sum of the previous w elements,
not just the previous 2 elements. Note that the width 2 Fibonacci Sequence is
simply the regular Fibonacci Sequence.
We now make a structural observation about Fw,n.
Lemma 1. For w ≥1 and 2 ≤n ≤w + 1, Fw,n = 2n−2.
Proof. Let w be a positive integer. By deﬁnition, Fw,0 = 0 and Fw,1 = 1. Addi-
tionally, for n = 2 . . . w, Fw,n = n−1
i=0 Fw,i. Since Fw,0 = 0, we have that for
n = 2 . . . w + 1, Fw,n = n−1
i=1 Fw,i.
When n = 2, we have
Fw,n = Fw,2 = Fw,0 + Fw,1 = 1 = 2n−2.
Let n be an integer such that 2 ≤n ≤w + 1. Assume that Fw,i = 2i−2 for
2 ≤i < n. Recall that,
Fw,n =
n−1

i=1
Fw,i = 1 +
n−1

i=2
2i−2 = 1 + (2n−2 −1) = 2n−2.
Thus, for w ≥1 and 2 ≤n ≤w + 1, Fw,n = 2n−2.
⊓⊔

68
K. Subramani et al.
We will now utilize width w Fibonacci Sequences to establish a stronger lower
bound on the copy complexity of HCSs with bounded constraint width.
Theorem 2. For each w ≥2 and n ≥2, there exists a width w HCS Hw,n with
n variables such that the copy complexity of Hw,n is 2 · F(w−1),n.
Proof. For each w ≥2 and n ≥2, Let Hw,n be the HCS constructed as follows:
1. The constraint l0 is −x1 −x2 −. . . −xw ≥1.
2. For r = 1, . . . , n −1, the constraint lr is xr −min{r+w−1,n}
j=r+1
xj ≥0.
3. The constraint ln is xn ≥0.
Let R be a linear refutation of Hw,n and let C(li) be the number of times
the constraint li is used by R. We will show that for any refutation R of Hw,n,
C(li) ≥2 · F(w−1),i for i = 2 . . . n.
We make the following observations about R and the structure of Hw,n:
1. l0 is the only constraint with positive deﬁning constant. Thus, l0 must be
used by R and C(l0) ≥1
2. For each i = 1 . . . n, the constraint li is the only constraint to use the literal
xi. Additionally, the constraints li−w+1 through li−1 are the only constraints
in Hw,n to use the literal −xi. The only exception to this is the literal −xw
which also appears in the constraint l0.
Since R is a refutation of Hw,n, the number of constraints in R that use the
literal xi and the number of constraints in R that use the literal −xi are equal.
Thus, for i = 1 . . . n, i ̸= w we have that C(li) = i−1
j=max{0,i−w+1} C(lj) and
C(lw) = w−1
j=0 C(lj).
3. For i = 1 . . . w, C(li) = i−1
j=0 C(lj). Thus, C(li) ≥2i−1. From Lemma 1,
we have that for i = 2 . . . w, F(w−1),i = 2i−2. Thus, for i = 2 . . . w, C(li) ≥
2 · F(w−1),i.
4. Let i be an integer such that w < i ≤n. Assume that for each j = 2 . . . i −1,
C(lj) ≥2·F(w−1),j. We have that C(li) = i−1
j=i−w+1 C(lj). Since (i−w+1) ≥
2, i−1
j=i−w+1 C(lj) ≥i−1
j=i−w+1 2 · F(w−1),j = 2 · F(w−1),i. Thus, C(li) ≥
2 · F(w−1),i as desired.
From the above observations, for each i = 2 . . . n, C(li) ≥2 · F(w−1),i. In
particular, C(ln) ≥2 · F(w−1),n. Thus, the copy complexity of Hw,n is at least
2 · F(w−1),n.
Let R be such that C(l0) = 1, C(l1) = 1, and for each i = 2 . . . n, C(li) =
2 · F(w−1),i. It can be algebraically veriﬁed that R is a linear refutation of Hw,n.
Thus, copy complexity of Hw,n is 2 · F(w−1),n as desired.
⊓⊔
Let Sl be the following set of constraints:
l1 : x2·l+1 −x2·l −x2·l−1 ≥0
l2 : x2·l −x2·l−1 ≥0
l3 : x2·l−1 −x2·l−2 −x2·l−3 ≥0
l4 : x2·l−2 −x2·l−3 ≥0
. . .
l2·l−1 : x3 −x2 −x1 ≥0
l2·l : x2 −x1 ≥0
l2·l+1 : x1 ≥0
Theorem 1, when applied to width 3 HCSs, can be extended to the following
result which will be utilized later in the paper.

Copy Complexity of Width 3 Horn Constraint Systems
69
Theorem 3. Let H be an HCS and let {x1, . . . , x2·l+1} be a subset of the vari-
ables in H such that for each i = 1 . . . (2 · l + 1), the only constraint in H that
uses the literal xi belongs to the set Sl. If a linear refutation R of H uses a
constraint x −
i∈S xi ≥b for some set S ⊆{1, 3, . . . , 2 · l + 1}, then R must
use the constraint x1 ≥0 at least 
2·i+1∈S 2i times.
Proof. Let H be an appropriately constructed HCS. For some subset S ⊆
{1, 3, . . . , 2 · l + 1} let x −
i∈S xi ≥b be a constraint in H used by a linear
refutation R of H.
Let xi be a variable such that 2 · i + 1 ∈S. By the deﬁnition of H, the only
constraint in H with the literal x2·i+1 is x2·i+1 −x2·i −x2·i−1 ≥0. Thus, this
constraint must be used by R. Observe the following:
1. The constraint x2·i −x2·i−1 ≥0 is the only constraint with the literal x2·i.
Thus, it needs to be in R. Consequently, R has at least 2 constraints with the
literal −x2·i−1.
2. The constraint x2·i−1−x2·i−2−x2·i−3 ≥0 is the only constraint with the literal
x2·i−1. Thus, R needs to use this constraint at least 2 times. Consequently,
R has at least 2 constraints with the literal −x2·i−2.
3. The constraint x2·i−2−x2·i−3 ≥0 is the only constraint with the literal x2·i−2.
Thus, R needs to use this constraint at least 2 times. Consequently, R has at
least 4 constraints with the literal −x2·i−3.
4. For each r, R uses at least 2r constraints with the literal −x2·(i−r)+1. Thus,
the constraint x2·(i−r)+1 −x2·(i−r) −x2·(i−r−1)+1 ≥0 needs to be in the
refutation at least 2r times. Consequently, R uses at least 2r constraints with
the literal −x2·(i−r).
5. For each r, R uses at least 2r constraints with the literal −x2·(i−r). Thus,
the constraint x2·(i−r) −x2·(i−r−1)+1 ≥0 needs to be in the refutation at
least 2r times. Consequently, R uses at least 2r+1 constraints with the literal
−x2·(i−r−1)+1.
6. The constraint x1 ≥0 needs to be used at least 2i times by R.
Thus, for each 2·i+1 ∈S, R must use the constraint x1 ≥0 at least 2i times.
Consequently, R must use the constraint x1 ≥0 at least 
2·i+1∈S 2i times.
⊓⊔
4
Computational Complexity of the CCD Problem
In this section, we explore the computational and approximation complexities
of the copy complexity problem for width 3 HCSs.
First, we show that the problem of determining the copy complexity of an
HCS is NP-complete even when each constraint in the HCS has at most 3
non-zero coeﬃcients.
Let Φ be a 3-CNF formula with m′ clauses over n′ variables and let H be
the HCS constructed as follows:
1. For each variable xi of Φ, create the variables xi and yi. Create the constraints
−x1 −y1 ≥0, y1 −x2 −y2 ≥0, . . . , yn′−2 −xn′−1 −yn′−1 ≥0, yn′−1 −x′
n ≥
1−m′. These constraints are equivalent to the constraint −n′
i=1 xi ≥1−m′.

70
K. Subramani et al.
2. For each clause φj ∈Φ, create the variable cj. Additionally, create the con-
straints cj ≥1, cj ≥0, and cj ≥0.
3. For each clause φj ∈Φ and each variable xi in clause φj, create the variable
zi,j. Since each clause has at most 3 literals, there are at most 3 · m′ such
variables.
4. For each variable xi, let Pos(i) = {φj1, . . . , φj|P os(i)|} be the set of clauses
containing the literal xi. Create the constraints xi −zi,j1 ≥0, zi,j1 −cj1 −
zi,j2 ≥0, . . . , zi,j|P os(i)| −cj|P os(i)| ≥0. This is equivalent to the constraint
xi −
φj∈P os(i) cj ≥0.
5. For each variable xi, let Neg(i) = {φj′
1, . . . , φj′
|Neg(i)|} be the set of clauses
containing the literal ¬xi. Create the constraints xi −zi,j′
1 ≥0, zi,j′
1 −cj′
1 −
zi,j′
2 ≥0, . . . , zi,j′
|Neg(i)| −cj′
|Neg(i)| ≥0. This is equivalent to the constraint
xi −
φj∈Neg(i) cj ≥0.
Note that H has n ≤(4 · m′ + 2 · n′) variables.
We now show that a 3-CNF formula Φ has a solution if and only if the HCS
H has a copy complexity of 1.
Lemma 2. Let Φ be a 3-CNF formula and let H be the HCS constructed from
Φ. Φ has a solution if and only if H has a copy complexity of 1.
Proof. First, assume that Φ has a solution x. We will show that H has copy
complexity 1 by showing that H has a read-once linear refutation R.
We construct R as follows:
1. Add the constraints −x1 −y1 ≥0, . . . , yn′−1 −x′
n ≥1 −m′ to R. Note that
summing these constraints results in the constraint −n′
i=1 xi ≥1 −m′.
2. For each variable xi, if xi is assigned true by x, then add the constraints
xi −zi,j1 ≥0, . . . , zi,j|P os(i)| −cj|P os(i)| ≥0 to R. If xi is assigned false by x,
then add the constraints xi −zi,j′
1 ≥0, . . . , zi,j′
|Neg(i)| −cj′
|Neg(i)| ≥0 to R.
3. For each clause φr ∈Φ, let C(r) be the number of times the literal −cr is
used by a constraint in R so far. Since φr has at most 3 literals, C(r) ≤3.
Additionally, since x satisﬁes Φ, the clause φr must contain a literal T(r) set
to true by x.
4. If T(r) is the literal xi, then the variable xi is assigned true by x. Thus, by
construction, R contains the equivalent of the constraint xi −
φr∈P os(i) cr ≥
0. Since Φr ∈Pos(i), the literal −cr is used by a constraint in R. Thus,
C(r) ≥1.
5. If T(r) is the literal ¬xi, then the variable xi is assigned false by x. Thus, by
construction, R contains the equivalent of the constraint xi−
φr∈Neg(i) cr ≥
0. Since Φr ∈Neg(i), the literal −cr is used by a constraint in R. Thus,
C(r) ≥1. Consequently, for each clause φr ∈Φ, 1 ≤C(r) ≤3.
6. For each clause φr ∈Φ, add the constraint cr ≥1 and (C(r) −1) copies of
the constraint cr ≥0 to R. Note that H has 2 copies of the constraint cr ≥0
and that 0 ≤C(r) −1 ≤2.

Copy Complexity of Width 3 Horn Constraint Systems
71
It is easy to see that summing all of the constraints in R results in a contra-
diction of the form 0 ≥1. Thus, R is a read-once refutation of H.
Now assume that H has a refutation R that uses no constraint more than
once. We construct an assignment x to Φ as follows: for each variable xi, if R
contains a constraint of the form xi −zi,j1 ≥0 such that φj1 ∈Pos(xi), then set
xi to true. Otherwise set xi to false.
We make the following observations about R:
1. If the constraint −x1 −y1 ≥0 is removed from H, then H is feasible. Thus,
this constraint must be used by R. To cancel each yi variable, all of the
constraints −x1 −y1 ≥0, . . . , yn′−1 −x′
n ≥1 −m′ must be in R. These
constraints are equivalent to the constraint −n′
i=1 xi ≥1 −m′.
2. To get a contradiction, the deﬁning constant of the derived constraint must
be positive. Note that the only constraints with positive deﬁning constant in
H are of the form cr ≥1. There are m′ such constraints, thus they must all
be used by R.
3. Consider the constraint cr ≥1. The only constraints with −cr in H are of
the form zi,r −cr −zi,r′ ≥0 where φr ∈Pos(i) or φr ∈Neg(i). Thus, R must
contain a constraint of this form.
4. If R contains a constraint of the form zi,r −cr −zi,r′ ≥0 where φr ∈Pos(i),
then to cancel all the zi,r variables R must contain the constraints xi−zi,j1 ≥
0, . . . , zi,j|P os(i)| −cj|P os(i)| ≥0. Thus, xi is set to true by x. Note that φr ∈
Pos(i) if and only if φr contains the literal xi. Thus, φr is satisﬁed by x.
5. If R contains a constraint of the form zi,r −cr −zi,r′ ≥0 where φj ∈Neg(i),
then to cancel all the zi,r variables R must contain the constraints xi −
zi,j′
1 ≥0, . . . , zi,j′
|Neg(i)| −cj′
|Neg(i)| ≥0. By construction, H has only one
constraint with the literal −xi. Thus, R cannot contain both the constraint
xi −zi,j′
1 ≥0 and a constraint of the form xi −zi,j1 ≥0 such that φj1 ∈
Pos(xi). Consequently, xi is set to false by x. Note that φr ∈Neg(i) if and
only if φr contains the literal ¬xi. Thus, φr is satisﬁed by x.
Note that x satisﬁes every clause in Φ. Thus, Φ is satisﬁable.
⊓⊔
Theorem 4. The CCD problem for width 3 HCSs is NP-complete.
Proof. For each integer k we can establish that the copy complexity of a width 3
HCS is at most k by providing a Farkas vector y such that ||y||∞≤k. Note
that ||y||∞is the largest element of y and is called the L∞norm of y. Thus, the
CCD problem for width 3 HCSs is in NP.
From Lemma 2, we have that given a 3-CNF formula Φ, we can construct a
width 3 HCS H such that H has copy complexity 1 if and only if Φ is feasible.
Thus, the CCD problem for width 3 HCSs is NP-complete.
⊓⊔
The result in Theorem 4, relies on the fact that the problem of determining
if a width 3 HCS has copy complexity 1 is NP-complete. However, this result
can be extended to any ﬁxed positive integer C.

72
K. Subramani et al.
Theorem 5. Let C be a positive integer. The problem of determining if a width 3
HCS has copy complexity at most C is NP-complete.
Proof. Let Φ be a 3-CNF formula and let H be the HCS constructed from Φ.
From Lemma 2, we know that H has copy complexity 1 if and only if Φ is
satisﬁable.
We can construct an HCS H′ from H as follows:
1. Initially, H′ = H.
2. Let E ⊆N be such that 
i∈E 2i = C. For each k = 1 . . . |E|, let E(k) be the
kth element of E.
3. For each constraint lj of H:
(a) Create the variables gj,1 through gj,2·⌊log C⌋+1 and the constraint gj,1 ≥0.
Additionally, create the constraints
gj,2·l+1 −gj,2·l −gj,2·l−1 ≥0 and gj,2·l −gj,2·l−1 ≥0 for l = 1 . . . ⌊log C⌋.
Let Sj denote this set of constraints.
(b) Create the variables ej,k for k = 0 . . . |E|. Additionally, create the con-
straints ej,0 −ej,1 ≥0, ej,1 −gj,2·E(1)+1 −ej,2 ≥0, . . . , ej,|E|−1 −
gj,2·E(|E|−1)+1 −ej,|E| ≥0, and ej,|E| −gj,2·E(|E|)+1 ≥0.
(c) Add the literal −ej,0 to the constraint lj.
We will now show that H′ has copy complexity at most C if and only if H
has copy complexity 1.
First assume that H has copy complexity 1. Let R be a read-once refutation
of H. We construct a refutation R′ of H′ as follows:
1. Add each constraint used by R to R′.
2. For each constraint lj used by R, add the constraints ej,0−ej,1 ≥0, . . . , ej,|E|−
gj,2·E(|E|)+1 ≥0 to R′. Additionally, add enough copies of the constraints in Sj
to cancel all of the gj,l variables. From Theorem 3, this requires 
i∈E 2i = C
copies of the constraint gj,1 ≥0.
Note that R′ is a refutation of H′ that uses each constraint at most C times.
Thus, H′ has copy complexity at most C.
Now assume that H′ has a refutation that uses no constraint more than C
times. We construct a read-once refutation R of H as follows: for each constraint
lj in H′ used by R′ add the corresponding constraint lj from H to R. By con-
struction, the remaining constraints in R′ are used to eliminate the variable ej,0
from each constraint lj. Since these variables do not exist in H, R is a refutation
of H. All that remains is to show that no constraint lj is used more than once
by R′.
Assume that for some j, the constraint lj is used r > 1 times by R′. Thus,
by construction, the constraint ej,0 −ej,1 ≥0 must also be used r times by R′.
From Theorem 3, this means that the constraint gj,1 ≥0 needs to be used at
least r · C > C times by R′. This contradicts the fact that R used no constraint
more than C times. Thus, each constraint lj is used at most once. Consequently,
R is a read-once refutation of H.
⊓⊔

Copy Complexity of Width 3 Horn Constraint Systems
73
Since the CCD problem is in NP, there exists a 2p(m,n) algorithm for this
problem, where p(m, n) is some polynomial in m and n. We now show that there
cannot be a 2o(n) algorithm for the CCD problem for width 3 HCSs unless the
Exponential Time Hypothesis (ETH) fails [5,6].
The ETH states that for each k ≥3, there exists a constant sk > 0 such that
k-SAT cannot be solved in time less than O(2sk·n). In particular, this precludes
a 2o(n) time algorithm for 3-SAT. We now utilize the reduction used by Lemma 2
to establish a likely lower bound on the running time on any algorithm for solving
the copy complexity problem for width 3 HCSs.
Theorem 6. There cannot be a 2o(n) algorithm for the CCD problem for width 3
HCSs unless the ETH fails.
Proof. From Lemma 2, if there is a 2o(n) time algorithm for the copy complexity
problem for HCSs, then there is a 2o(n′+m′) algorithm for 3-CNF feasibility. This
violates the ETH [5,6]. Thus, it is unlikely that a 2o(n) time algorithm exists for
the CCD problem for HCSs.
⊓⊔
We now show that the problem of ﬁnding the copy complexity of a width 3
HCS is NPO complete [1]. We do this by a reduction from the Weighted
Min-Ones problem.
The Weighted Min-Ones problem is deﬁned as follows: Given a 3CNF formula
Φ and positive integer valued variable weight function w, what is the satisfying
assignment to Φ with least weight of variables set to true. This problem is known
to be NPO-complete [11].
Let Φ be a CNF formula with m clauses over n variables where each variable
xi has weight w(i). Additionally, let W be the target weight. We construct the
corresponding HCS H as follows:
1. Let wmax be the largest weight of any variable xi of Φ. Additionally let
f = ⌊log wmax⌋.
2. For each variable xi of Φ, create the variables xi, ti and y+
i .
3. Create the constraints −x1−t1 ≥0, t1−x2−t2 ≥0, . . . , tn−2−xn−1−tn−1 ≥
0, and tn−1 −xn ≥1 −m. Let S be the set containing these constraints.
Note that these constraints are the only constraints to use the variables ti
for i = 1 . . . (n−1). If any constraint in S is used more times by a refutation
R of H than any other constraint in S, then there would be a variable ti
left over in the resultant constraint. Thus, any refutation of H must use
all of these constraints an equal number of times. Note that together these
constraints are equivalent to the constraint −n
i=1 xi ≥m −1.
4. For each variable xi, let P(i) be the number of clauses in Φ containing the
literal xi, and let N(i) be the number of clauses in Φ containing the literal
¬xi. Create the variables z+
i,l and t+
i,l for l = 1 . . . P(i) and the variables z−
i,l
and t−
i,l for l = 1 . . . N(i).

74
K. Subramani et al.
5. For each variable xi of Φ, create the constraints xi ≥0, xi −t−
i,1 ≥0,
t−
i,1 −z−
i,1 ≥0, t−
i,1 −z−
i,1 −t−
i,2 ≥0, . . . , t−
i,N(i)−1 −z−
i,N(i)−1 ≥0, t−
i,N(i)−1 −
z−
i,N(i)−1 −t−
i,N(i) ≥0, and t−
i,N(i) −z−
i,N(i) ≥0. For each l = 0 . . . N(i), let
S−
i,l be the set:
{xi −t−
i,1 ≥0, t−
i,1 −z−
i,1 −t−
i,2 ≥0, . . . , t−
i,l −z−
i,l ≥0}.
Note that the constraints in S−
i,l are equivalent to the constraint
xi −l
j=1 z−
i,j ≥0.
6. For each variable xi of Φ, create the constraints xi−y+
i ≥0, xi−y+
i −t+
i,1 ≥0,
t+
i,1 −z+
i,1 ≥0, t+
i,1 −z+
i,1 −t+
i,2 ≥0, . . . , t+
i,P (i)−1 −z+
i,P (i)−1 ≥0, t+
i,P (i)−1 −
z+
i,P (i)−1 −t+
i,P (i) ≥0, and t+
i,P (i) −z+
i,P (i) ≥0. For each l = 0 . . . P(i), let S+
i,l
be the set:
{xi −y+
i −t+
i,1 ≥0, t+
i,1 −z+
i,1 −t+
i,2 ≥0, . . . , t+
i,l −z+
i,l ≥0}.
Note that the constraints in S+
i,l are equivalent to the constraint xi −y+ −
l
j=1 z+
i,j ≥0.
7. For each clause φj ∈Φ, create the variables cj and dj. Additionally, create
the constraint cj −dj ≥1.
8. For each clause φj ∈Φ, create the variables dj,1 through dj,2·⌊log W ⌋+1 and
the constraint dj,1 ≥0. Additionally, create the constraints
dj,2·l+1 −dj,2·l −dj,2·l−1 ≥0 and dj,2·l −dj,2·l−1 ≥0 for l = 1 . . . ⌊log W⌋.
Let S′
j denote this set of constraints.
9. Let EW ⊆N be such that 
j∈EW 2j = W. For each k = 1 . . . |EW |, let
E(W, k) be the kth element of EW . For each clause φj, create the variables
hj,k for k = 1 . . . |EW |. Additionally, create the constraints dj −hj,1 ≥0,
hj,1−dj,2·E(W,1)+1−hi,2 ≥0, . . . , hj,|EW |−1−dj,2·E(W,|EW |−1)+1−hj,|EW | ≥0,
and hj,|EW | −dj,2·E(W,|EW |)+1 ≥0.
10. For each clause φj ∈Φ and each variable xi, if the literal xi appears in the
clause φj, add the constraints z+
i,l −cj ≥0 for l = 1 . . . P(i) to H. If the
literal ¬xi appears in the clause φj, add the constraints z−
i,l −cj ≥0 for
l = 1 . . . N(i) to H.
11. Create the variables g1 through g2·f+1 and the constraint g1 ≥0. Addition-
ally, create the constraints
g2·l+1 −g2·l −g2·l−1 ≥0 and g2·l −g2·l−1 ≥0 for l = 1 . . . f. Let Sf denote
this set of constraints.
12. For each variable xi of Φ, let Ei ⊆N be such that 
j∈Ei 2j = w(i). For
each k = 1 . . . |Ei|, let E(i, k) be the kth element of Ei. Create the variables
ei,k for k = 1 . . . |Ei|. Additionally, create the constraints y+
i −ei,1 ≥0,
ei,1 −g2·E(i,1)+1 −ei,2 ≥0, . . . , ei,|Ei|−1 −g2·E(i,|Ei|−1)+1 −ei,|Ei| ≥0, and
ei,|Ei| −g2·E(i,|Ei|)+1 ≥0.
We now show that a CNF formula Φ has a solution in which the total weight
of true variables is at most W if and only if the HCS H has a copy complexity
of at most W.

Copy Complexity of Width 3 Horn Constraint Systems
75
Lemma 3. Let Φ be a CNF formula with weighted variables and let H be the
HCS constructed from Φ. Φ has a solution in which the total weight of true
variables is at most W if and only if H has a copy complexity of at most W.
Proof. First, assume that Φ has a solution x such that W ∗= 
xi:xi=true w(i) ≤
W. We will show that H has copy complexity at most W by showing that H
has a refutation R that uses each constraint at most W ∗times. We construct R
as follows:
1. Add the constraints in S to R. Recall that these constraints are equivalent to
−n
i=1 xi ≥1 −m.
2. For each clause φj ∈Φ let T(j) be a literal in φj set to true by x.
3. For each variable xi, let Pos(i) = {φj : T(j) = xi}, and let Neg(i) = {φj :
T(j) = ¬xi}.
4. For each variable xi, if xi is assigned true by x, then add the constraints
in S+
i,|P os(i)| to R. If xi is assigned false by x, then add the constraints in
S−
i,|Neg(i)| to R.
5. For each variable xi set to true by x, add the constraints y+
i −ei,1 ≥
0, . . . , ei,|Ei| −g2·E(i,|Ei|)+1 ≥0 to R. Additionally, add enough copies of
the constraints in Sf to cancel all of the gl variables. From Theorem 3, this
requires 
j∈Ei 2j = w(i) copies of the constraint g1 ≥0.
6. For each variable xi set to true by x and for each l = 1 . . . |Pos(i)|, let φj be
the lth element of Pos(i). Add the constraint z+
i,l −cj ≥0 to R.
7. For each variable xi set to false by x and for each l = 1 . . . |Neg(i)|, let φj
be the lth element of Neg(i). Add the constraint z−
i,l −cj ≥0 to R.
8. Add the constraints c1 −d1 ≥1 through cm −dm ≥1 to R.
9. For each clause φj, add the constraints dj −hj,1
≥
0, . . . , hj,|EW | −
dj,2·E(W,|EW |)+1 ≥0 to R. Additionally, add enough copies of the con-
straints in S′
j to cancel all of the dj,l variables. From Theorem 3, this requires

l∈EW 2l = W copies of the constraint dj,1 ≥0.
It is easy to see that summing all of the constraints in R results in a contra-
diction of the form 0 ≥1. Thus, R is a refutation of H. Note that the constraints
reused by R belong to the sets Sf and S′
j for j = 1 . . . m. From Theorem 3, the
constraints reused the most are the constraint g1 ≥0 and the constraints dj,1 ≥0
for j = 1 . . . m. These constraints are each used at most W times as desired.
Now assume that H has a refutation that uses no constraint more than W
times. Thus, H has a refutation R such that the constraint g1 ≥0 is used
W ∗≤W times. We construct an assignment x to Φ as follows: for each variable
xi, if R contains the constraint xi −y+
i ≥0 or xi −y+
i −t+
i,1 ≥0, then set xi to
true. Otherwise set xi to false.
We make the following observations about R:
1. If the constraints in S are removed from H, then H is feasible, thus these
constraints must be used by R. Recall that these constraints are equivalent
to −n
i=1 xi ≥1 −m.

76
K. Subramani et al.
2. To get a contradiction, the deﬁning constant of the derived constraint must
be positive. Note that the only constraints with positive deﬁning constant in
H are of the form cj −dj ≥1. As noted previously, eliminating dj from each
of these constraints requires W copies of the constraint dj,1 ≥0. Thus, each
of these constraints is used at most once by R. There are m such constraints,
thus they must all be used by R. Consequently, the constraints in S can be
each used at most once by R.
3. Consider the constraint cj −dj ≥1. The only constraints with −cj in H are
of the form z−
i,l −cj ≥0 and z+
i,l −cj ≥0. Thus, R must contain a constraint
of this form.
4. If R contains a constraint of the form z−
i,l −cj ≥0, then it must contain the
constraint t−
i,l −z−
i,l ≥0 or t−
i,l −z−
i,l −t−
i,l+1 ≥0. To cancel the t−
i,l variables, R
must include the constraint xi −t−
i,1 ≥0. This constraint cancels the variable
xi from the constraint −n
i=1 xi ≥1 −m. Thus, the constraints xi −y+
i ≥0
and xi −y+
i −t+
i,1 ≥0 cannot be in R. This means that xi is set to false by
x. Note that the constraint z−
i,l −cj ≥0 is in H if and only if φj contains the
literal ¬xi. Thus, φj is satisﬁed by x.
5. If R contains a constraint of the form z+
i,l −cj ≥0, then it must contain the
constraint t+
i,l −z+
i,l ≥0 or t+
i,l −z+
i,l −t+
i,l+1 ≥0. To cancel the t+
i,l variables,
R must include the constraint xi −y+
i −t+
i,1 ≥0. This means that xi is set
to true by x. Note that the constraint z−
i,l −cj ≥0 is in H if and only if φj
contains the literal ¬xi. Thus, φj is satisﬁed by x.
6. As observed previously, canceling y+
i from the constraint xi −y+
i −z+
i,1 ≥0
takes at least w(i) uses of the constraint g1 ≥0. Thus,

xi:xi=true w(i) ≤W ∗≤W as desired.
⊓⊔
Using Lemma 3, we now show that the CCOpt problem for width 3 HCSs is
NPO-complete.
Theorem 7. The CCOpt problem for width 3 HCSs is NPO-complete.
Proof. The copy complexity of an HCS can be veriﬁed in polynomial time by
providing the Farkas vector. Thus, the CCOpt problem is in NPO. All that
remains is to show NPO-hardness.
Let Φ be a CNF formula with m clauses over n variables where each variable
xi has weight w(i). Using the construction in this section, we can construct a
corresponding width 3 HCS H. From Theorem 3, this HCS has a copy complex-
ity of at most W if and only if Φ has a solution in which the total weight of
true variables is at most W. This is a strict (and hence) PTAS reduction [11].
Consequently, the CCOpt problem for width 3 HCSs is NPO-complete.
⊓⊔
Since the CCOpt problem for width 3 HCSs is NPO-complete, this problem
cannot be approximated to within a polynomial factor unless P = NP [7].

Copy Complexity of Width 3 Horn Constraint Systems
77
5
Conclusion
In this paper, we analyzed the problem of determining bounds on the copy com-
plexity bounds of HCSs. We showed that for any HCS, the copy complexity
cannot exceed 2n−1, where n is the number of variables in the HCS. We also
showed that for each n, there exists a family of width 3 HCSs with copy com-
plexity 2⌊n
2 ⌋. Additionally, we showed that the CCD problem for width 3 HCSs
is NP-complete.
From our perspective, the following avenues are worth pursuing:
1. The focus of this paper has been copy complexity with respect to the ADD
refutation system. However, additional inference rules exist which allow for
constraints to be multiplied by and divided by positive integers. We hope
to replicate the analysis in this paper when we allow for the use of these
additional inference rules.
2. The goal of this paper was to focus on the copy complexity of HCSs. In some
refutation models, the goal is not so much to minimize the copy complex-
ity, but to minimize the total number of distinct constraint replications. In
other words, the ﬁrst replication has a cost associated with it, but all other
replications are gratis. It would be interesting to study HCSs in this model.
References
1. Ausiello, G., Crescenzi, P., Gambosi, G., Kann, V., Marchetti-Spaccamela, A., Pro-
tasi, M.: Complexity and Approximation: Combinatorial Optimization and their
Approximability Properties, 1st edn. Springer, Cham (1999). https://doi.org/10.
1007/978-3-642-58412-1
2. Bakhirkin, A., Monniaux, D.: Combining forward and backward abstract inter-
pretation of horn clauses. In: Ranzato, F. (ed.) SAS 2017. LNCS, vol. 10422, pp.
23–45. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-66706-5 2
3. Bjørner, N., Gurﬁnkel, A., McMillan, K., Rybalchenko, A.: Horn clause solvers for
program veriﬁcation. In: Beklemishev, L.D., Blass, A., Dershowitz, N., Finkbeiner,
B., Schulte, W. (eds.) Fields of Logic and Computation II. LNCS, vol. 9300, pp.
24–51. Springer, Cham (2015). https://doi.org/10.1007/978-3-319-23534-9 2
4. Farkas, G.: ¨Uber die Theorie der Einfachen Ungleichungen. J. f¨ur die Reine und
Angewandte Mathematik 124(124), 1–27 (1902)
5. Impagliazzo, R., Paturi, R.: Complexity of k-sat. In: Proceedings. Fourteenth
Annual IEEE Conference on Computational Complexity, pp. 237–240 (1999)
6. Impagliazzo, R., Paturi, R., Zane, F.: Which problems have strongly exponential
complexity? J. Comput. Syst. Sci. 63(4), 512–530 (2001)
7. Kann, V.: On the Approximability of NP-complete Optimization Problems. PhD
thesis, Royal Institute of Technology Stockholm (1992)
8. Kleine B¨uning, H., Wojciechowski, P.J., Subramani, K.: New results on cutting
plane proofs for Horn constraint systems. In: 39th IARCS Annual Conference on
Foundations of Software Technology and Theoretical Computer Science, FSTTCS
2019, 11–13 December, 2019, Bombay, India, pp. 43:1–43:14 (2019)
9. LiCalzi, M., Veinott, A.: Subextremal functions and lattice programming. SSRN
Electron. J. 10, 367 (2005)

78
K. Subramani et al.
10. Nemhauser, G.L., Wolsey, L.A.: Integer and Combinatorial Optimization. John
Wiley & Sons, New York (1999)
11. Orponen, P., Mannila, H.: On approximation preserving reductions: Complete
problems and robust measures. Technical Report, Department of Computer Sci-
ence, University of Helsinki (1987)
12. Schrijver, A.: Theory of Linear and Integer Programming. John Wiley and Sons,
New York (1987)

Description Logics

Restricted Uniﬁcation in the DL FL0
Franz Baader1(B)
, Oliver Fern´andez Gil1
, and Maryam Rostamigiv2
1 Theoretical Computer Science, TU Dresden, Dresden, Germany
{franz.baader,oliver.fernandez}@tu-dresden.de
2 D´epartement d’Informatique, Paul Sabatier University, Toulouse, France
Maryam.Rostamigiv@irit.fr
Abstract. Uniﬁcation in the Description Logic (DL) FL0 is known
to be ExpTime-complete and of uniﬁcation type zero. We investigate
whether a lower complexity of the uniﬁcation problem can be achieved
by either syntactically restricting the role depth of concepts or semanti-
cally restricting the length of role paths in interpretations. We show that
the answer to this question depends on whether the number formulat-
ing such a restriction is encoded in unary or binary: for unary coding,
the complexity drops from ExpTime to PSpace. As an auxiliary result,
we prove a PSpace-completeness result for a depth-restricted version of
the intersection emptiness problem for deterministic root-to-frontier tree
automata. Finally, we show that the uniﬁcation type of FL0 improves
from type zero to unitary (ﬁnitary) for uniﬁcation without (with) con-
stants in the restricted setting.
1
Introduction
Uniﬁcation of concept patterns has been proposed as an inference service in
Description Logics that can, for example, be used to detect redundancies in
ontologies. For the DL FL0, which has the concept constructors conjunction
(⊓), value restriction (∀r.C), and top concept (⊤), uniﬁcation was investigated
in detail in [6]. It was shown there that uniﬁcation in FL0 corresponds to uni-
ﬁcation modulo the equational theory ACUIh since (modulo equivalence) con-
junction is associative (A), commutative (C), idempotent (I) and has top as
a unit (U), and value restrictions behave like homomorphisms for conjunction
and top (h). For this equational theory, it had already been shown in [1] that
it has uniﬁcation type zero, which means that a solvable uniﬁcation problem
need not have a minimal complete set of uniﬁers, and thus in particular not a
ﬁnite one. From the DL point of view, the decision problem is, however, more
interesting than the uniﬁcation type. Since ACUIh is a commutative/monoidal
theory [1,14], solvability of ACUIh uniﬁcation problems (and thus of uniﬁcation
problems in FL0) can be reduced to solvability of systems of linear equations in
a certain semiring, which for the case of ACUIh consists of ﬁnite languages over
a ﬁnite alphabet, with union as semiring addition and concatenation as semiring
multiplication [6]. By a reduction to the emptiness problem for root-to-frontier
tree automata (RFAs), it was then shown in [6] that solvability of the language
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 81–97, 2021.
https://doi.org/10.1007/978-3-030-86205-3_5

82
F. Baader et al.
equations corresponding to an FL0 uniﬁcation problem can be decided in expo-
nential time. In addition, ExpTime-hardness of this problem was proved in [6]
by reduction from the intersection emptiness problem for deterministic RFAs
(DRFAs) [16].
In the present paper, we investigate two kinds of restrictions on uniﬁcation in
FL0. On the one hand, we syntactically restrict the role depth (i.e., the maximal
nesting of value restrictions) in the concepts obtained by applying a uniﬁer to
be bounded by a natural number k ≥1. This restriction was motivated by a
similar restriction used in research on least common subsumers (lcs) [15], where
imposing a bound on the role depth guarantees existence of the lcs also in the
presence of a (possibly cyclic) terminology. Also note that such a restriction was
used in [11] for the theory ACh, for which uniﬁcation is known to be undecidable
[13]. It is shown in [11] that the problem becomes decidable if a bound on the
maximal nesting of applications of homomorphisms is imposed. On the other
hand, we consider a semantic restriction where only interpretations for which
the length of role paths is bounded by a given number k are considered when
deﬁning the semantics of concepts. A similar restriction (for k = 1) was employed
in [9] to improve the uniﬁcation type for the modal logic K from type zero [10]
to unitary or ﬁnitary for K + □□⊥.
In the present paper we show that both the syntactic and the semantic restric-
tion ensures that the uniﬁcation type of FL0 (and equivalently, of the theory
ACUIh) improves from type zero to unitary for uniﬁcation without constants
and ﬁnitary for uniﬁcation with constants. Regarding the decision problem, we
can show that the complexity depends on whether the bound k is assumed to
be encoded in unary or binary1. For binary encoding of k, the complexity stays
ExpTime, whereas for unary coding it drops from ExpTime to PSpace. This is
again the case both for the syntactic and the semantic restriction. As an auxil-
iary result we prove that a depth-restricted variant of the intersection emptiness
for DRFAs is PSpace-complete.
Showing these results requires combining methods and results from knowl-
edge representation, uniﬁcation theory, and automata theory. Due to space
restrictions, we cannot give detailed proofs here. They can be found in [3].
2
The DL FL0 and Restrictions
Starting with mutually disjoint countably inﬁnite sets NC and NR of concept
and role names, respectively, the set of FL0 concepts is inductively deﬁned as
follows:
– ⊤(top concept) and every concept name A ∈NC is an FL0 concept,
– if C, D are FL0 concepts and r ∈NR is a role name, then C⊓D (conjunction)
and ∀r.C (value restriction) are FL0 concepts.
1 For unary coding, the size of the input k is the number k, whereas for binary coding
it is the size of its binary encoding, i.e., log k.

Restricted Uniﬁcation in the DL FL0
83
The semantics of FL0 concepts is deﬁned using ﬁrst-order interpretations I =
(DI, ·I) consisting of a non-empty domain DI and an interpretation function
·I that assigns a set AI ⊆DI to each concept name A, and a binary relation
rI ⊆DI × DI to each role name r. This function is extended to FL0 concepts
as follows:
⊤I = DI and (C ⊓D)I = CI ∩DI,
(∀r.C)I = {x ∈DI | ∀y ∈DI: (x, y) ∈rI ⇒y ∈CI}.
Given two FL0 concepts C and D, we say that C is subsumed by D (written
C ⊑D) if CI ⊆DI holds for all interpretations I, and that C is equivalent to D
(written C ≡D) if C ⊑D and D ⊑C. It is well known that subsumption (and
thus also equivalence) of FL0 concepts can be decided in polynomial time [12].
Note that, up to equivalence, conjunction is associative, commutative, and
idempotent, and has the unit element ⊤. In addition, the following equivalences
hold for value restrictions: ∀r.⊤≡⊤and ∀r.(C ⊓D) ≡∀r.C ⊓∀r.D. Due to
these equivalences, one can transform FL0 concepts into a normal form that uses
formal languages over the alphabet of role names to represent value restrictions
that end with the same concept name. In fact, using these equivalences as rewrite
rules from left to right, every FL0 concept can be transformed into an equivalent
one that is either ⊤or a conjunction of concepts of the form ∀r1. · · · ∀rn.A,
where r1, . . . , rn are role names and A is a concept name. Such a concept can be
abbreviated as ∀w.A, where w = r1 . . . rn is a word over the alphabet NR. Note
that n = 0 means that w is the empty word ε, and thus ∀ε.A corresponds to A.
Furthermore, a conjunction of the form ∀w1.A ⊓. . . ⊓∀wm.A can be written as
∀L.A where L ⊆N ∗
R is the ﬁnite language {w1, . . . , wm}. We use the convention
that ∀∅.A corresponds to the top concept ⊤. Thus, any two FL0 concepts C, D
containing only the concept names A1, . . . , Aℓcan be represented as
C ≡∀K1.A1 ⊓. . . ⊓∀Kℓ.Aℓand D ≡∀L1.A1 ⊓. . . ⊓∀Lℓ.Aℓ,
(1)
where K1, L1, . . . , Kℓ, Lℓare ﬁnite languages over the alphabet of role names NR.
We call this representation the language normal form (LNF) of C, D. If C, D
have the LNF shown in (1), then C ≡D holds iﬀL1 = K1, . . . , Lℓ= Kℓ(see
Lemma 4.2 of [6]).
2.1
Syntactically Restricting the Role Depth
The role depth of an FL0 concept is the maximal nesting of value restrictions
in this concept. Since occurrences of ⊤within value restrictions can increase
the role depth artiﬁcially, we assume without loss of generality that FL0 con-
cepts diﬀerent from ⊤do not contain any occurrences of ⊤. We will make this
assumption in the rest of the paper without mentioning it explicitly.
The role depth rd(C) of an FL0 concept C is deﬁned by induction:
– rd(⊤) = rd(A) = 0 for all A ∈NC,
– rd(C ⊓D) = max(rd(C), rd(D)) and rd(∀r.C) = 1 + rd(C).

84
F. Baader et al.
It is easy to see that (under the above assumption) the role depth of FL0 con-
cepts is preserved under equivalence.
We are now ready to deﬁne our ﬁrst restricted version of subsumption and
equivalence in FL0. For an integer k ≥1 and FL0 concepts C and D, we deﬁne
subsumption and equivalence restricted to concepts of role depth ≤k as follows:
– C ⊑k
syn D if C ⊑D and max(rd(C), rd(D)) ≤k,
– C ≡k
syn D if C ⊑k
syn D and D ⊑k
syn C.
The eﬀect of this deﬁnition is that subsumption and equivalence can only hold for
concepts that satisfy the restriction of the role depth by k. For concepts satisfying
this syntactic restriction, the relations ⊑k
syn and ≡k
syn coincide with the classical
subsumption and equivalence relations on FL0 concepts. Using the language
normal form of FL0 concepts, the equivalence ≡k
syn can be characterized as
follows: if C, D have the LNF shown in (1), then C ≡k
syn D
iﬀ
L1 = K1 ⊆
N ≤k
R , . . . , Lℓ= Kℓ⊆N ≤k
R , where N ≤k
R
denotes the set of words over NR of
length at most k.
2.2
Semantically Restricting the Length of Role Paths
For an integer n ≥1 and a given interpretation I = (DI, ·I), a role path of
length n is a sequence d0, r1, d1, . . . , dn−1, rn, dn, where d0, . . . , dn are elements
of DI, r1, . . . , rn are role names, and (di−1, di) ∈rI
i holds for all i = 1, . . . , n.
The interpretation I is called k-restricted if it does not contain any role paths
of length > k.
For an integer k ≥1 and FL0 concepts C and D, we deﬁne subsumption and
equivalence restricted to interpretations with role paths of length ≤k as follows:
– C ⊑k
sem D if CI ⊆DI holds for all k-restricted interpretations I,
– C ≡k
sem D if C ⊑k
sem D and D ⊑k
sem C.
The eﬀect of this notion of equivalence is that all concepts occurring at a role
depth > k can be replaced by ⊤. To be more precise, we deﬁne the restriction
of a concept C to role depth n ≥0 by induction on n as follows:
– A|n = A for A ∈NC ∪{⊤} and (C ⊓D)|n = C|n ⊓D|n for all n ≥0;
– (∀r.C)|0 = ⊤and (∀r.C)|n = ∀r.(C|n−1) for all n ≥1.
For example, (∀r.∀r.∀r.A)|4 = ∀r.∀r.∀r.A = (∀r.∀r.∀r.A)|3 and (∀r.∀r.∀r.A)|2 =
∀r.∀r.⊤≡⊤. In the language normal form, restricting to role depth n means
that all words that are longer than n can simply be removed.
It is easy to see that C ≡k
sem D iﬀC|k ≡D|k, which yields the following
characterization of the equivalence ≡k
sem: if C, D have the LNF shown in (1),
then C ≡k
sem D iﬀL1 ∩N ≤k
R
= K1 ∩N ≤k
R , . . . , Lℓ∩N ≤k
R
= Kℓ∩N ≤k
R .

Restricted Uniﬁcation in the DL FL0
85
3
Uniﬁcation in FL0
In uniﬁcation, we consider concepts that may contain variables, which can be
replaced by concepts. More formally, we introduce a countably inﬁnite set NV of
concept variables, which is disjoint with NC and NR. An FL0 concept pattern
is an FL0 concept that is constructed using NC ∪NV as concept names. The
semantics of concept patterns is deﬁned as for concepts, i.e., concept variables are
treated like concept names when deﬁning the semantics. This way, the notions
of subsumption and equivalence (both in the restricted and in the unrestricted
setting) transfer from concepts to concept patterns in the obvious way.
A substitution σ is a mapping from NV into the set of all FL0 concept
patterns such that dom(σ) := {X ∈NV | σ(X) ̸= X} is ﬁnite. This mapping is
extended to concept patterns in the obvious ways:
– σ(A) := A for all A ∈NC ∪{⊤},
– σ(C ⊓D) := σ(C) ⊓σ(D) and σ(∀r.C) := ∀r.σ(C).
An FL0 uniﬁcation problem is an equation of the form C ?≡D where C, D are
FL0 concept patterns. A uniﬁer of this equation is a substitution σ such that
σ(C) ≡σ(D).
It was shown in [6] that the question of whether a given FL0 uniﬁcation
problem has a uniﬁer or not can be reduced to solving linear language equations,
i.e., equations of the form
S0 ∪S1·X1 ∪· · · ∪Sn·Xn = T0 ∪T1·X1 ∪· · · ∪Tn·Xn,
(2)
where S0, . . . , Sn, T0, . . . , Tn are ﬁnite languages of words over an alphabet Δ =
{1, . . . , ρ}2 and X1, . . . , Xn are variables that can be replaced by ﬁnite languages
over Δ. A solution of the Eq. (2) is an assignment θ of ﬁnite languages θ(Xi) to
the variables Xi (for i = 1, . . . , n) such that
S0 ∪S1·θ(X1) ∪· · · ∪Sn·θ(Xn) = T0 ∪T1·θ(X1) ∪· · · ∪Tn·θ(Xn),
(3)
where ∪is interpreted as union and · as concatenation of languages. Strictly
speaking, a given FL0 uniﬁcation problem yields one such language equation
for every concept name occurring in the problem. But since these equations do
not share variables, they can be solved separately. Also note that solvability of
language equations of the form (2) can in turn be reduced in polynomial time
to FL0 uniﬁcation.
A word w = i1 . . . iℓoccurring in a solution of the form (3) corresponds to a
conjunct ∀ri1. · · · ∀riℓ.A in the uniﬁed concept σ(C) ≡σ(D). Thus, the length
of the word w is equal to the role depth of the corresponding sequence of value
restrictions.
2 Intuitively, ρ is the number of diﬀerent role names occurring in the uniﬁcation prob-
lem and each letter i, 1 ≤i ≤ρ, stands for a role name ri.

86
F. Baader et al.
Example 1. Consider the FL0 uniﬁcation problem ∀r1.∀r1.A⊓∀r1.∀r1.X ?≡X ⊓
∀r1.∀r1.∀r1.Y . The substitution σ with σ(X) = ∀r1.∀r1.A and σ(Y ) = ∀r1.A is
one of the uniﬁers of this problem. The language equation induced by this uniﬁ-
cation problem is {11} ∪{11}·X = {ε}·X ∪{111}·Y . The uniﬁer σ corresponds
to the following solution θ of this problem: θ(X) = {11} and θ(Y ) = {1}.
3.1
Syntactically Restricted Uniﬁcation in FL0
For an integer k ≥1, a syntactically k-restricted uniﬁcation problem is an equa-
tion of the form C ?≡
k
syn D, where C, D are FL0 concept patterns. A uniﬁer of
this equation is a substitution σ such that σ(C) ≡k
syn σ(D).
Due to the LNF characterization of ≡k
syn and the correspondence between
role depth and word length mentioned above, solvability of a given syntactically
k-restricted uniﬁcation problem can be reduced to checking whether language
equations of the form (2) have solutions θ such that
S0 ∪S1·θ(X1) ∪· · · ∪Sn·θ(Xn) = T0 ∪T1·θ(X1) ∪· · · ∪Tn·θ(Xn) ⊆Δ≤k, (4)
where Δ≤k denotes the set of words over Δ of length at most k.
The uniﬁer σ of the FL0 uniﬁcation problem in Example 1 is not a syntacti-
cally 3-restricted uniﬁer of this problem since the uniﬁed concept σ(∀r1.∀r1.A ⊓
∀r1.∀r1.X) = ∀r1.∀r1.A ⊓∀r1.∀r1.∀r1.∀r1.A = σ(X ⊓∀r1.∀r1.∀r1.Y ) has role
depth 4. This is reﬂected on the language equation side by the fact that
{11} ∪{11}·{11} = {11, 1111} = {ε}·{11} ∪{111}·{1} ̸⊆Δ≤3. In fact, it is
easy to see that this problem does not have a syntactically 3-restricted uniﬁer.
3.2
Semantically Restricted Uniﬁcation in FL0
For an integer k ≥1, a semantically k-restricted uniﬁcation problem is an equa-
tion of the form C ?≡
k
sem D, where C, D are FL0 concept patterns. A uniﬁer of
this equation is a substitution σ such that σ(C) ≡k
sem σ(D).
Whereas in the syntactically restricted case a sequence of value restrictions
of depth > k (a word of length > k) destroys the property of being a uni-
ﬁer (solution), in the semantically restricted case one can simply ignore such
sequences (words). Thus, one can reduce the question of whether a given seman-
tically k-restricted uniﬁcation problem has a uniﬁer or not to checking whether,
for language equations of the form (2), there is an assignment θ such that
(S0 ∪S1·θ(X1) ∪· · · ∪Sn·θ(Xn)) ∩Δ≤k
= (T0 ∪T1·θ(X1) ∪· · · ∪Tn·θ(Xn)) ∩Δ≤k.
(5)
Note that, in general, such an assignment need not be a solution of (2), but
clearly any solution θ of (2) satisfying (3) also satisﬁes (5).
Example 2. The FL0 uniﬁcation problem ∀r1.A ⊓∀r1.∀r1.X ?≡X induces the
language equation {1}∪{11}·X = {ε}·X. This language equation does not have

Restricted Uniﬁcation in the DL FL0
87
a solution in the classical sense, but it has a semantically 3-restricted solution.
In fact, for the assignment θ with θ(X) = {1, 111} we have {1} ∪{11}·θ(X) =
{1, 111, 11111} and {ε}·θ(X) = {1, 111}. Intersecting these two sets with Δ≤3
yields the same set {1, 111}. Thus, the above uniﬁcation problem does not have
a uniﬁer, but it has a semantically 3-restricted uniﬁer.
4
Root-to-Frontier Tree Automata
It was shown in [6] that checking solvability of linear language equations can be
reduced to testing emptiness of tree automata. More precisely, the tree automata
employed in [6] work on ﬁnite node-labelled trees, going from the root to the
leaves. Such automata are called root-to-frontier tree automata (RFAs) in [6].
Basically, given a linear language equation, one can construct an RFA whose
size is exponential in the size of the language equation, and which accepts some
tree iﬀthe language equation has a solution. Since the emptiness problem for
RFAs is polynomial, this yields an ExpTime upper bound for solvability of lin-
ear language equations. The matching ExpTime lower bound was proved in [6]
by reduction from the intersection emptiness problem for deterministic RFAs
(DRFAs). In this section, we formally introduce (D)RFAs and the trees they
accept, and recall the ExpTime-completeness result for the intersection empti-
ness problem for DRFAs from [16]. We then state our new result that a depth-
restricted version of this problem is PSpace-complete.
We consider trees with labels in a ranked alphabet Σ, where the number of
successors of a node is determined by the rank of its label.
Deﬁnition 1. Let Σ be a ﬁnite alphabet, where each f ∈Σ is associated with a
rank, denoted as rank(f), such that rank(f) ≥0, and let ρ be the maximal rank
of the elements of Σ. A (ﬁnite) Σ-tree is a mapping t : dom(t) →Σ such that
dom(t) is a ﬁnite subset of {1, . . . , ρ}∗such that
– the empty word ε belongs to dom(t);
– for all u ∈{1, . . . , ρ}∗and i ∈{1, . . . , ρ}, we have ui ∈dom(t) iﬀu ∈dom(t)
and i ≤rank(t(u)).
The elements of dom(t) are the nodes of the tree t, and t(u) is called the label of
node u. The empty word ε is the root of t, and the nodes u such that ui ̸∈dom(t)
for all i = 1, . . . , ρ are the leaves of t. By the above deﬁnition, the leaves are
the nodes labeled with a symbol of rank zero, i.e., rank(t(u)) = 0 iﬀu is a leaf
of t. We denote the set of symbols of rank 0 by Σ0 := {f ∈Σ | rank(f) = 0}.
We always assume Σ0 ̸= ∅since otherwise there is no ﬁnite Σ-tree. Nodes of t
that are not leaves are called inner nodes. The depth of a node u ∈dom(t) is
just the length of the word u. The depth of the tree t, denoted as depth(t), is the
maximal depth of a node in dom(t).
Deﬁnition 2. A (non-deterministic) root-to-frontier tree automaton (RFA)
that works on Σ-trees is a 5-tuple A = (Σ, Q, I, T, F), where

88
F. Baader et al.
– Σ is a ﬁnite, ranked alphabet,
– Q is a ﬁnite set of states,
– I ⊆Q is the set of initial states,
– T assigns to each f ∈Σ \ Σ0 of rank n a transition relation T(f) ⊆Q × Qn,
– F : Σ0 →2Q assigns to each c ∈Σ0 a set of ﬁnal states F(c) ⊆Q.
A run of A on the tree t is a mapping r : dom(t) →Q such that
– (r(u), r(u1), . . . , r(un)) ∈T(t(u)) for all inner nodes u of rank n.
The run r is called successful if
– r(ε) ∈I (root condition),
– r(u) ∈F(t(u)) for all leaves u (leaf condition).
The tree language accepted by A is deﬁned as
L(A) := {t | there exists a successful run of A on t}.
The emptiness problem for A is the question whether L(A) = ∅.
These automata are called root-to-frontier automata since they start at the root
with an initial state, and then label successor nodes with states according to
the transition relation, until they reach the leaves (also called the frontier),
which must be labeled by ﬁnal states to yield a successful run. Frontier-to-root
automata (FRAs) work in the other direction. It is well-known that both types
of automata accept the same class of tree languages, but only FRAs can be
determinized, i.e., deterministic RFAs are weaker than general ones, whereas
deterministic FRAs accept the same class of tree languages as general FRAs.
It is well-known that the emptiness problem for RFAs is decidable in poly-
nomial time (see, e.g., [17]). It is also known that, if an RFA A accepts a tree,
then it also accepts one of depth at most q, where q is the number of states
of A. In contrast to the emptiness problem, the intersection emptiness problem
is ExpTime-complete even for deterministic RFAs [16].
Deﬁnition 3. The RFA A = (Σ, Q, I, T, F) is a deterministic root-to-frontier
automaton (DRFA) if
– the set I of initial states consists of a single initial state q0,
– for all states q ∈Q and all symbols f of rank n > 0 there exists exactly one
n-tuple (q1, . . . , qn) such that (q, q1, . . . , qn) ∈T(f).
For deterministic automata it is often more convenient to use a transition
function δ in place of the (functional) transition relations. This function is
deﬁned as δ(q, f) := (q1, . . . , qn), where (q1, . . . , qn) is the unique tuple satis-
fying (q, q1, . . . , qn) ∈T(f).
Given a collection A1, . . . , An of DRFAs, the intersection emptiness problem
asks whether L(A1) ∩. . . ∩L(An) = ∅. For a natural number k, the k-restricted
intersection emptiness problem asks, for given DFRAs A1, . . . , An, whether there
is a tree t with depth(t) ≤k such that t ∈L(A1) ∩. . . ∩L(An).

Restricted Uniﬁcation in the DL FL0
89
The complexity of the k-restricted intersection emptiness problem depends
on the encoding of the number k. A proof of the following theorem can be found
in [3]. The most challenging task is proving PSpace-hardness for the unary case.
Theorem 1. The k-restricted intersection emptiness problem for DRFAs is
ExpTime-complete if the number k is encoded in binary, and PSpace-complete if
the number k is encoded in unary.
5
Solving Linear Language Equations Using RFAs
As mentioned in Sect. 3, checking solvability of linear language equations was
reduced in [6] to testing emptiness of RFAs. However, this approach cannot
directly treat equations of the form (2). It needs equations where the variables
Xi are in front of the coeﬃcients Si. Fortunately, such equations can easily
be obtained from the ones of the form (2) by considering the mirror images
of the involved languages. For a word w = i1 . . . iℓ∈Δ∗, its mirror image is
deﬁned as wmi := iℓ. . . i1, and for a ﬁnite set of words L = {w1, . . . , wm},
its mirror image is Lmi := {wmi
1 , . . . , wmi
m }. Obviously, the assignment θ with
θ(X1) = L1, . . . , θ(Xn) = Ln is a solution of (2) iﬀθmi with θmi(X1) =
Lmi
1 , . . . , θmi(Xn) = Lmi
n
is a solution of the corresponding mirrored equation
Smi
0
∪X1·Smi
1
∪· · · ∪Xn·Smi
n
= T mi
0
∪X1·T mi
1
∪· · · ∪Xn·T mi
n .
(6)
Finite languages over the alphabet Δ = {1, . . . , ρ} can be represented by
Σ-trees for the ranked alphabet Σ = {f0, f1, c0, c1}, where f0, f1 are ρ-ary and
c0, c1 nullary symbols. A given Σ-tree t represents the ﬁnite language
Lt = {u ∈dom(t) | t(u) ∈{c1, f1}}.
Given an equation of the form (6), it is shown in [6] how to construct an RFA
A = (Σ, Q, I, T, F) of size exponential in the size of the equation that satisﬁes
the following property.
Lemma 1 (Lemma 6.3 in [6]). For a Σ-tree t, the following are equivalent:
1. The tree t is accepted by A.
2. There are ﬁnite sets of words θ(X1), . . . , θ(Xn) such that
Smi
0
∪θ(X1)·Smi
1
∪· · · ∪θ(Xn)·Smi
n
= Lt
= T mi
0
∪θ(X1)·T mi
1
∪· · · ∪θ(Xn)·T mi
n .
Consequently, Eq. (2) has a solution iﬀequation (6) has a solution iﬀthe RFA
A constructed from (6) accepts some tree. Since the size of A = (Σ, Q, I, T, F) is
exponential in the size of (2), and the emptiness problem for RFAs is decidable
in polynomial time, this yields an ExpTime decision procedure for solvability
of equations of the form (2), and thus for uniﬁability in FL0. As mentioned
in Sect. 4, it is also shown in [6] by reduction from the intersection emptiness
problem for DRFAs, that these problems are actually ExpTime-hard.

90
F. Baader et al.
Theorem 2 [6]. Uniﬁability in FL0 as well as solvability of language equations
of the forms (2) and (6) are ExpTime-complete problems.
In the restricted setting, we consider equations of the form (2) and are look-
ing for solutions θ satisfying (4) for the syntactically restricted setting or satis-
fying (5) for the semantically restricted setting. Since clearly (Δ≤k)mi = Δ≤k,
the respective restrictions apply unchanged to the mirrored equation (6).
5.1
The Syntactically Restricted Case
In this case we are thus looking for solutions θ of (6) satisfying
Smi
0
∪θ(X1)·Smi
1
∪· · · ∪θ(Xn)·Smi
n
= T mi
0
∪θ(X1)·T mi
1
∪· · · ∪θ(Xn)·T mi
n
⊆Δ≤k.
(7)
Intuitively, for the trees accepted by the automaton A this means that we want
to check whether A accepts a tree of depth ≤k. This can be achieved by adding a
counter that is decremented whenever we go from a node in the tree to a successor
node. As soon as the counter reaches 0, no more transitions are possible.
To be more precise, let A = (Σ, Q, I, T, F) be the RFA constructed from
(6), as described in [6]. For an integer k ≥1, we deﬁne the automaton Ak
syn =
(Σ, Qk
syn, Ik
syn, T k
syn, F k
syn) as follows:
– Qk
syn = Q × {0, 1, . . . , k},
– Ik
syn = I × {k},
– T k
syn(f) = {((q, i), (q1, i−1), . . . , (qρ, i−1)) | (q, q1, . . . , qρ) ∈T(f) and i ≥1}
for f ∈{f0, f1},
– F k
syn(c) = F(c) × {0, 1, . . . , k} for c ∈{c0, c1}.
Basically, Ak
syn works like A, but once it has reached a node at depth k in the
tree, it cannot make any transition. Thus, it accepts exactly the trees that have
depth at most k and are accepted by A. Since nodes at a depth i correspond to
words of this length i, we obtain the following lemma.
Lemma 2. The automaton Ak
syn accepts a tree t iﬀ(6) has a solution θ that
satisﬁes (7).
Proof. If (6) has a solution θ that satisﬁes (7), then there is a tree t of depth at
most k that represents this solution in the sense that it satisﬁes 2. of Lemma 1.
The tree t then also satisﬁes 1. of Lemma 1, i.e., it is accepted by A. Since t has
depth at most k, it is then also accepted by Ak
syn.
Conversely, if the tree t is accepted by Ak
syn, then it is also accepted by A
and has depth at most k. The former implies, by Lemma 1, that 2. of Lemma 1
holds, and the latter yields that L(t) ⊆Δ≤k. Thus, the sets θ(X1), . . . , θ(Xn)
provided by 2. of Lemma 1 satisfy (7).
⊓⊔
As an easy consequence of this lemma and the connection between syntac-
tically k-restricted uniﬁcation and the problem of ﬁnding solutions of (6) that
satisfy (7), we obtain the following complexity results (see [3] for detailed proofs).

Restricted Uniﬁcation in the DL FL0
91
Theorem 3. Given an integer k ≥1 and FL0 concepts C, D as input, the
problem of deciding whether the syntactically k-restricted uniﬁcation problem
C ?≡
k
syn D has a uniﬁer or not is ExpTime-complete if the number k is assumed
to be encoded in binary, and PSpace-complete if k is assumed to be encoded in
unary.
The ExpTime upper bound is an immediate consequence of the fact that
the size of Ak
syn is exponentially bounded by the size of the input equation
and the binary representation of k. The ExpTime lower bound can be shown
using the fact that the automaton A accepts a tree iﬀit accepts one of depth
linear in the size of A (which is exponential in the size of the input equation).
Regarding the PSpace upper bound, one cannot construct the exponentially large
modiﬁed automaton Ak
syn before testing it for emptiness, but rather constructs
the relevant parts of Ak
syn while doing the emptiness test on-the-ﬂy. This needs
only polynomial space since the depth of the run to be constructed is linear in the
size of the unary representation of k. The PSpace lower bound can be shown by
reduction of the k-restricted intersection emptiness problem for DRFAs, based
on the reduction for the unrestricted case given in [6].
5.2
The Semantically Restricted Case
In this case, to solve the mirrored equation (6), we are looking for assignments
θ satisfying
(Smi
0
∪θ(X1)·Smi
1
∪· · · ∪θ(Xn)·Smi
n ) ∩Δ≤k
= (T mi
0
∪θ(X1)·T mi
1
∪· · · ∪θ(Xn)·T mi
n ) ∩Δ≤k.
(8)
The existence of such a solution can again be tested by building an RFA that
extends the automaton A = (Σ, Q, I, T, F) constructed from (6), as described
in [6], by a counter. But now, we allow the automaton to make transitions where
the value of the counter becomes −1. States that have counter value −1 are
ﬁnal states since they indicate that the word represented by this node of the
tree is longer than k, and thus it is not relevant for deciding whether the tree
represents a solution or not. To be more precise, for an integer k ≥1, we deﬁne
the automaton Ak
sem = (Σ, Qk
sem, Ik
sem, T k
sem, F k
sem) as follows:
– Qk
sem = Q × {−1, 0, 1, . . . , k},
– Ik
sem = I × {k},
– T k
sem(f) = {((q, i), (q1, i−1), . . . , (qρ, i−1)) | (q, q1, . . . , qρ) ∈T(f) and i ≥0}
for f ∈{f0, f1},
– F k
sem(c) = (F(c) × {0, 1, . . . , k}) ∪{(q, −1) | q ∈Q} for c ∈{c0, c1}.
The following lemma, whose proof can be found in [3], states correctness of this
construction.
Lemma 3. The automaton Ak
sem accepts a tree t iﬀthere is an assignment θ
that satisﬁes (8).

92
F. Baader et al.
Based on this lemma, the complexity upper bounds stated in the following
theorem can be shown analogously to the proof of Theorem 3. The PSpace lower
bound can be shown by reduction from syntactically k-restricted uniﬁcation (see
[3] for a proof).
Theorem 4. Given an integer k ≥1 and FL0 concepts C, D as input, the
problem of deciding whether the semantically k-restricted uniﬁcation problem
C ?≡
k
sem D has a uniﬁer or not is in ExpTime if the number k is assumed to be
encoded in binary, and PSpace-complete if k is assumed to be encoded in unary.
If k is encoded in binary, then the reduction used for the unary case is no
longer polynomial. It is an open problem whether, for the case of binary coding,
the ExpTime upper bound in Theorem 4 is tight.
6
The Uniﬁcation Type
Until now, we were mainly interested in the complexity of deciding solvability of
uniﬁcation problems. For this, it is suﬃcient to consider ground uniﬁers. Now,
we want to investigate the question of whether all uniﬁers of a given uniﬁcation
problem can be represented as instances of a ﬁnite set of (non-ground) uniﬁers.
In the unrestricted setting, the instance relation between FL0 uniﬁers is
deﬁned as follows. Let C ?≡D be an FL0 uniﬁcation problem, V the set of
concept variables occurring in C and D, and σ, θ two uniﬁers of this problem.
We deﬁne
σ ≤• θ if there is a substitution λ such that θ(X) ≡λ(σ(X)) for all X ∈V.
If σ ≤• θ, then we say that θ is an instance of σ.
Deﬁnition 4. Let C?≡D be an FL0 uniﬁcation problem. The set of substitutions
M is called a complete set of uniﬁers for C ?≡D if it satisﬁes
1. every element of M is a uniﬁer of C ?≡D;
2. if θ is a uniﬁer of C ?≡D, then there exists a uniﬁer σ ∈M such that σ ≤• θ.
The set M is a minimal complete set of uniﬁers for C ?≡D if it additionally
satisﬁes
3. if σ, θ ∈M, then σ ≤• θ implies σ = θ.
The uniﬁcation type of a given uniﬁcation problem is determined by the
existence and cardinality of such a minimal complete set.
Deﬁnition 5. Let C ?≡D be an FL0 uniﬁcation problem. This problem has
type unitary ( ﬁnitary, inﬁnitary) if it has a minimal complete set of uniﬁers of
cardinality 1 (ﬁnite cardinality, inﬁnite cardinality). If C ?≡D does not have a
minimal complete set of uniﬁers, then it is of type zero.

Restricted Uniﬁcation in the DL FL0
93
The uniﬁcation types can be ordered as follows:
unitary < ﬁnitary < inﬁnitary < type zero.
Basically, the uniﬁcation type of FL0 is the maximal type of an FL0 uniﬁca-
tion problem. However, in uniﬁcation theory, one usually distinguishes between
uniﬁcation with and without constants [8]. In an FL0 uniﬁcation problem with
constants, no restrictions are put on the concepts C and D to be uniﬁed. In
an FL0 uniﬁcation problem without constants, C and D must not contain con-
cept names from NC. The uniﬁcation type of FL0 for uniﬁcation with (without)
constants is the maximal type of an FL0 uniﬁcation problem with (without)
constants.
It was shown in [6] that equivalence of FL0 concepts can be axiomatized by
the equational theory
ACUIh := { (x ∧y) ∧z = x ∧(y ∧z), x ∧y = y ∧x, x ∧x = x, x ∧1 = x }
∪{ hr(x ∧y) = hr(x) ∧hr(y), hr(1) = 1 | r ∈NR },
where ∧, hr, and 1 in the terms respectively correspond to ⊓, ∀r., and ⊤in the
concepts. These identities say that ∧is associative (A), commutative (C), and
idempotent (I) with unit 1 (U), and that the unary function symbols behave like
homomorphisms (h) for ∧and 1.
The uniﬁcation type of an equational theory is deﬁned analogously to the
deﬁnitions given above for FL0 (see [8] for details). It was shown in [1] that
the uniﬁcation type of the theory ACUIh (called AIMH in [1]) is zero, even if
one has only one homomorphism h and considers uniﬁcation without constants.
Thus, uniﬁcation in FL0 is also of type zero for uniﬁcation without constants,
and thus also for uniﬁcation with constants. We will show in this section that this
is no longer the case if we consider restricted uniﬁcation. For the semantically
restricted case, this is an easy consequence of general results about commuta-
tive/monoidal theories [1,14].
6.1
The Semantically Restricted Case
The equivalence ≡k
sem can be axiomatized by adding identities to ACUIh that
say that nesting of homomorphisms of depth > k produces the unit. Given a
word u = r1r2 . . . rn ∈N ∗
R, we denote a term of the form hr1(hr2(· · · hrn(t) · · · ))
as hu(t). It is now easy to see that ≡k
sem is axiomatized by
ACUIhk := ACUIh ∪{hu(x) = 1 | u ∈N ∗
R with |u| = k + 1}.
Both ACUIh and ACUIhk are so-called commutative/monoidal theory [1,7,14],
for which uniﬁcation can be reduced to solving linear equations over a cor-
responding semiring. For ACUIh this semiring consists of ﬁnite languages
over the alphabet Δ with union as addition and concatenation as multiplica-
tion [6]. As shown in [3], the semiring corresponding to ACUIhk consists of

94
F. Baader et al.
the subsets of Δ≤k, with union as addition and the following multiplication:
L1·kL2 = (L1·L2) ∩Δ≤k.
According to [14], uniﬁcation without constants in a monoidal theory E is
unitary if the semiring SE corresponding to E is ﬁnite. In [1], the same result
is shown for commutative theories E under the assumption that the ﬁnitely
generated E-free algebras are ﬁnite. It is easy to see that these two conditions
actually coincide for commutative theories [7]. In addition to uniﬁcation without
constants, also uniﬁcation with constants is considered in [1], and it is shown
that, if the ﬁnitely generated E-free algebras are ﬁnite, then uniﬁcation with con-
stants in the commutative theory E is at most ﬁnitary (i.e., unitary or ﬁnitary).
The following theorem is an easy consequence of these results.
Theorem 5. Uniﬁcation in ACUIhk, and thus also semantically k-restricted
uniﬁcation in FL0, is unitary for uniﬁcation without constants and ﬁnitary for
uniﬁcation with constants.
Proof. It is easy to see that the semiring corresponding to ACUIhk is ﬁnite
since its elements are all the subsets of the ﬁnite set Δ≤k. Thus, the results
in [1,14] yield that ACUIhk is unitary for uniﬁcation without constants and at
most ﬁnitary for uniﬁcation with constants. The following example shows that
the theory is not unitary for uniﬁcation with constants: if x is a variable and a a
constant, then the terms x ∧a and a have (restricted to x) exactly two ACUIhk
uniﬁers {x →1} and {x →a}, which are not in any instance relationship.
⊓⊔
6.2
The Syntactically Restricted Case
To deal with the syntactically restricted case, the results on the uniﬁcation type
for commutative/monoidal theories cannot be applied directly, but we can show
the same results as for the semantically restricted case, using the ideas underlying
the proofs in [1,14]. We will formulate our proof using the syntax of FL0 rather
than the equational theory variant.
Let C, D be FL0 concepts and σ a syntactically k-restricted uniﬁer of C and
D. Let X1, . . . , Xn be the concept variables occurring in C, D and A1, . . . , Aℓ
the concept constants. First, note that we can assume that σ does not introduce
new concept constants since otherwise one could get a more general uniﬁer by
replacing such a constant by a new variable. Let Y1, . . . , Ym be the concept
variables in the range of σ, where we assume without loss of generality that they
are diﬀerent from the variables X1, . . . , Xn. For i = 1, . . . , n, the LNF of the
concept σ(Xi) is of the form
σ(Xi) = Ki ⊓∀Li,1.Y1 ⊓. . . ⊓∀Li,m.Ym,
(9)
where Ki is a concept of role depth ≤k not containing concept variables and only
concept constants in {A1, . . . , Aℓ} and the Li,j are subsets of Δ≤k. Recall that
∀Li,j.Yj abbreviates the conjunction of the value restrictions ∀w.Yj for w ∈Li,j,
which in turn is an abbreviation for ∀r1. · · · ∀rν.Yj if w = r1 . . . rν.

Restricted Uniﬁcation in the DL FL0
95
Now, consider for every variable Yj, 1 ≤j ≤m, the tuple of languages
L(Yj) = (L1,j, . . . , Ln,j), and assume that there are indices j ̸= j′ such that
L(Yj) = L(Yj′). Let θj′ be the substitution that replaces Yj′ with ⊤and leaves
all other variable Yμ unchanged. Then σj′ = σθj′ is an instance of σ, which is
still a syntactically k-restricted uniﬁer of C and D, but introduces one variable
less. Conversely, using the substitution λj,j′ = {Yj →Yj ⊓Yj′}, we obtain σ as
an instance of σj′ since σ = σj′λj,j′.
Let c denote the (ﬁnite) cardinality of Δ≤k. Then there are at most 2c·n
diﬀerent n-tuples of subsets of Δ≤k. Thus, if a syntactically k-restricted uniﬁer
of C and D introduces more than 2c·n variables, it is an instance of a syntactically
k-restricted uniﬁer of C and D that introduces at least one variable less. This
observation can be used to show the following lemma.
Lemma 4. There is a complete set of syntactically k-restricted uniﬁers of C and
D that consists of uniﬁers whose range contains at most the variables Y1, . . . , Ym
for m = 2c·n.
Once we have restricted the uniﬁers in the complete set to ones using only
ﬁnitely many variables, we know that there can be only ﬁnitely many uniﬁers in
this set. In fact, if we consider (9), then we see that the Ki and Li,j range over
ﬁnite sets. This proves the following theorem.
Theorem 6. Syntactically k-restricted uniﬁcation with constants in FL0 is
ﬁnitary.
To show that uniﬁcation with constants is not unitary, we can use the same
example as in the semantically restricted case. Uniﬁcation without constants is
again unitary.
Corollary 1. Syntactically k-restricted uniﬁcation without constants in FL0 is
unitary.
Proof. By the previous theorem, there is a ﬁnite complete set {σ1, . . . , σκ} of
syntactically k-restricted uniﬁers of C, D. Without loss of generality, we can
assume that the variables occurring in the ranges of these uniﬁers are disjoint
and that no concept constant occurs in the range. The latter assumption can be
made since the uniﬁcation problem itself does not contain such constants. Under
these assumptions, the substitution σ deﬁned as
σ(Xi) = σ1(Xi) ⊓. . . ⊓σκ(Xi) for i = 1, . . . , n
is also a syntactically k-restricted uniﬁer of C, D, and it has the substitutions
σ1, . . . , σκ as instances (see [3] for a proof of these two claims). This shows that
{σ} is a complete set of uniﬁers.
⊓⊔

96
F. Baader et al.
7
Conclusion
We have investigated both a semantically and a syntactically restricted variant
of uniﬁcation in FL0, where either the role depth of concepts or the length of
role paths in interpretations is restricted by a natural number k ≥1. These
restrictions lead to a considerable improvement of the uniﬁcation type from the
worst possible type to unitary/ﬁnitary for uniﬁcation without/with constants.
For the complexity of the decision problem, we only obtain an improvement if k
is assumed to be encoded in unary.
While these results are mainly of (complexity) theoretic interest, they could
also have a practical impact. In fact, in our experiments with the system UEL,
which implements several uniﬁcation algorithms for the DL EL [4], we have
observed that the algorithms usually yield many diﬀerent uniﬁers, and it is hard
to choose one that is appropriate for the application at hand (e.g., when gener-
ating new concepts using uniﬁcation [2]). For this reason, we added additional
constraints to the uniﬁcation problem to ensure that the generated concepts are
of a similar shape as the concepts already present in the ontology [2]. It makes
sense also to use a restriction on the role depth as such an additional constraint
since the role depth of the (unfolded) concepts occurring in real-world ontolo-
gies is usually rather small. This claim is supported by our experiments with
the medical ontology SNOMED CT3, which has a maximal role depth of 10, and
the acyclic ontologies in Bioportal 20174, where a large majority also has a role
depth of at most 10.
As future work, we will investigate whether the ExpTime upper bound in
Theorem 4 for the case of binary coding of k is tight. In addition, we will consider
similar restrictions for other DLs. For example, the uniﬁcation type of the DL
EL is also known to be zero, and the decision problem is NP-complete [5]. We
conjecture that, for EL, the restricted variants will not lead to an improvement
of uniﬁcation type or complexity.
In [11], a syntactically restricted version of uniﬁcation in the theory ACh
was shown to be decidable, but neither the uniﬁcation type nor the complexity
of the decision problem was determined. It would be interesting to investigate
these problems and also consider a semantically restricted variant. Note that,
with the exception of the missing unit, ACh is commutative/monoidal, but the
main diﬀerence to ACUIh is that already the semiring corresponding to the sub-
theory without homomorphisms is inﬁnite, whereas the semiring corresponding
to ACUI is ﬁnite.
Acknowledgements. Franz Baader was partially supported by DFG TRR 248 (cpec,
grant 389792660), Oliver Fern´andez Gil by DFG in project number 335448072, and
Maryam Rostamigiv by a DAAD Short-Term Grant, 2021 (57552336). The authors
should like to thank Patrick Koopmann for determining the maximal role depth of
concepts in ontologies from Bioportal 2017 and in SNOMED CT.
3 https://www.snomed.org/.
4 https://zenodo.org/record/439510.

Restricted Uniﬁcation in the DL FL0
97
References
1. Baader, F.: Uniﬁcation in commutative theories. J. Symbolic Comput. 8(5), 479–
497 (1989)
2. Baader, F., Borgwardt, S., Morawska, B.: Constructing SNOMED CT concepts
via disuniﬁcation. LTCS-Report 17–07, Chair for Automata Theory, Institute
for Theoretical Computer Science, Technische Universit¨at Dresden, Dresden,
Germany
(2017).
https://lat.inf.tu-dresden.de/research/reports/2017/BaBM-
LTCS-17-07.pdf
3. Baader, F., Fern´andez Gil, O., Rostamigiv, M.: Restricted uniﬁcation in the DL FL0
(extended version). LTCS-Report 21–02, Chair of Automata Theory, Institute of
Theoretical Computer Science, Technische Universit¨at Dresden, Dresden, Germany
(2021). https://lat.inf.tu-dresden.de/research/reports/2021/BaGiRo21.pdf
4. Baader, F., Mendez, J., Morawska, B.: UEL: uniﬁcation solver for the description
logic EL – system description. In: Gramlich, B., Miller, D., Sattler, U. (eds.) IJCAR
2012. LNCS (LNAI), vol. 7364, pp. 45–51. Springer, Heidelberg (2012). https://
doi.org/10.1007/978-3-642-31365-3 6
5. Baader, F., Morawska, B.: Uniﬁcation in the description logic EL. Logical Methods
Comput. Sci. 6(3), 350–364 (2010)
6. Baader, F., Narendran, P.: Uniﬁcation of concept terms in description logics. J.
Symbolic Comput. 31(3), 277–305 (2001)
7. Baader, F., Nutt, W.: Combination problems for commutative/monoidal theories:
how algebra can help in equational reasoning. J. Appl. Algebra Eng. Commun.
Comput. 7(4), 309–337 (1996)
8. Baader, F.: Uniﬁcation theory. In: Schulz, K.U. (ed.) IWWERT 1990. LNCS,
vol. 572, pp. 151–170. Springer, Heidelberg (1992). https://doi.org/10.1007/3-540-
55124-7 5
9. Balbiani, P., Gencer, C., Rostamigiv, M., Tinchev, T.: About the uniﬁcation type
of K + □□⊥. In: Proceedings of the 34th International Workshop on Uniﬁcation
(UNIF 2020), pp. 4:1–4:6. RISC-Linz (2020)
10. Jerabek, E.: Blending margins: the modal logic K has nullary uniﬁcation type. J.
Logic Comput. 25(5), 1231–1240 (2015)
11. Ajay Kumar Eeralla and Christopher Lynch: Bounded ACh uniﬁcation. Math.
Struct. Comput. Sci. 30(6), 664–682 (2020)
12. Levesque, H.J., Brachman, R.J.: Expressiveness and tractability in knowledge rep-
resentation and reasoning. Comput. Intell. 3, 78–93 (1987)
13. Narendran, P.: Solving linear equations over polynomial semirings. In: Proceedings
of the 11th Annual IEEE Symposium on Logic in Computer Science (LICS 1996),
pp. 466–472. IEEE Computer Society (1996)
14. Nutt, W.: Uniﬁcation in monoidal theories. In: Stickel, M.E. (ed.) CADE 1990.
LNCS, vol. 449, pp. 618–632. Springer, Heidelberg (1990). https://doi.org/10.1007/
3-540-52885-7 118
15. Pe˜naloza, R., Turhan, A.-Y.: A practical approach for computing generalization
inferences in EL. In: Antoniou, G., et al. (eds.) ESWC 2011. LNCS, vol. 6643, pp.
410–423. Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-642-21034-
1 28
16. Seidl, H.: Haskell overloading is DEXPTIME-complete. Inf. Process. Lett. 52, 57–
60 (1994)
17. Thomas, W.: Automata on inﬁnite objects. In: Handbook of Theoretical Computer
Science, volume B, chapter 4, pp. 134–189. Elsevier Science Publishers (North-
Holland), Amsterdam (1990)

Combining Event Calculus and Description
Logic Reasoning via Logic Programming
Peter Baumgartner(B)
Data61/CSIRO and The Australian National University, Canberra, Australia
Peter.Baumgartner@data61.csiro.au
Abstract. The paper introduces a knowledge representation language
that combines the event calculus with description logic in a logic pro-
gramming framework. The purpose is to provide the user with an expres-
sive language for modelling and analysing systems that evolve over time.
The approach is exempliﬁed with the logic programming language as
implemented in the Fusemate system. The paper extends Fusemate’s rule
language with a weakly DL-safe interface to the description logic ALCIF
and adapts the event calculus to this extended language. This way, time-
stamped ABoxes can be manipulated as ﬂuents in the event calculus. All
that is done in the frame of Fusemate’s concept of stratiﬁcation by time.
The paper provides conditions for soundness and completeness where
appropriate. Using an elaborated example it demonstrates the interplay
of the event calculus, description logic and logic programming rules for
computing possible models as plausible explanations of the current state
of the modelled system.
1
Introduction
This paper presents an expressive logical language for modelling systems that
evolve over time. The language is intended for model computation: given a his-
tory of events until “now”, what are the system states at these times, in par-
ticularly “now”, expressed as logical models. This is a useful reasoning service
in application areas with only partially observed events or incomplete domain
knowledge. By making informed guesses and including its consequences, the
models are meant to provide plausible explanations for helping understand the
current issues, if any, as a basis for further decision making.
For example, transport companies usually do not keep detailed records of what
goods went on what vehicle for a transport on a particular day. Speculating the
whereabouts of a missing item can be informed by taking known locations of other
goods of the same batch on that day into account; problems observed with goods
on delivery site, e.g., low quality of fresh goods, may or may not be related to the
transport conditions, and playing through diﬀerent scenarios may lead to plausible
explanations while eliminating others (truck cooling problems? tampering?).
There are numerous approaches for modelling and analysing systems that
evolve over time. They are often subsumed under the terms of stream process-
ing, complex event recognition, and situational awareness, temporal veriﬁcation
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 98–117, 2021.
https://doi.org/10.1007/978-3-030-86205-3_6

Combining Event Calculus and Description Logic Reasoning
99
among others, see [1–4,14] for some logic-based methods. Symbolic event recog-
nition, for instance, accepts as input a stream of time-stamped low-level events
and identiﬁes high-level events – collections of events that satisfy some pattern [1].
See [36] for a recent sophisticated event calculus. Other approaches utilize descrip-
tion logics in a temporalized setting of ontology-based data access (OBDA) [30].
For instance, [29] describes a method for streaming data into a sequence of ABoxes,
which can be queried in an SQL-like language with respect to a given ontology.
The knowledge representation language put forward in this paper combines
Kowalski’s event calculus (EC) with description logics (DL) in a logic program-
ming framework. The rationale is, DLs have a long history of developments for
representing structured domain knowledge and for oﬀering reliable (decidable)
reasoning services. The EC provides a structured way of representing actions
and their eﬀects, represented as ﬂuents that may change their truth value over
time. For the intended model computation applications mentioned above, the
EC makes it easy to take snapshots of the ﬂuents at any time. The full system
state at a chosen time then is derived from the ﬂuent snapshot and DL reason-
ing. The logic programming rules orchestrate their integration and serve other
purposes, such as diagnosis.
This paper uses the Fusemate logic programming language and system
[11,12]. Fusemate computes possible models of stratiﬁed disjunctive logic pro-
grams [33,34], see Sect. 2 for details. Fusemate was introduced in [11] with the
same motivation as here. In [12] it was extended with novel language operators
improved with a weaker form of stratiﬁcation. Their usefulness in combination
was demonstrated by application to description logic reasoning. In [12] it was
shown how to transform an ALCIF 1 knowledge base into a set of Fusemate
rules and facts that is satisﬁable if and only if the knowledge base is ALCIF -
satisﬁable. All of that is used in this paper.
Paper Contributions. This paper builds on the Fusemate developments summa-
rized above and extends them in the following ways:
1. Integration of the description logic reasoner of [12] as a subroutine callable
from Fusemate rules. Section 3 details the semantics of the combination and
conditions for its soundness and completeness. This is an original contribution
in its own right which exploits advantages of a stratiﬁed setting.
2. A version of the event calculus [20] that ﬁts Fusemate’s model computation
and notion of stratiﬁcation. Details are in Sect. 4.
3. Integrating DL and EC by means of rules, and utilizing rules for KR aspects
not covered by either. Details in particular in Sect. 5
4. Providing an elaborated example the integrated EC/DL/rules language. It is
included in the Fusemate distribution which is available at https://bitbucket.
csiro.au/users/bau050/repos/fusemate/.
To the best of my knowledge, a combination of DL with EC has not been con-
sidered before. Given the long history of applying DL reasoning (also) for time
1 ALCIF is the well-known description logic ALC extended with inverse roles and
functional roles. See [5] for background on description logics.

100
P. Baumgartner
evolving systems, I ﬁnd this surprising. From that perspective, a main contribu-
tion of this paper is to ﬁll the gap and to argue that the proposed combination
makes sense.
There is work is on integrating DLs into the situation calculus (SitCalc) and
similar methods [8–10,15]. SitCalc [23] is a ﬁrst-order logic formalism for specify-
ing state transitions in terms of pre- and post-conditions of actions. Its is mostly
used for planning and related applications that require reachability reasoning for
state transitions. Indeed, the papers [9] and [15] investigate reasoning tasks (exe-
cutability and projection, ABox updates) that are relevant in that context. Both
approaches are restricted to acyclic TBoxes. In [10], actions are speciﬁed as sets of
conditional eﬀects, where conditions are based on epistemic queries over the knowl-
edge base (TBox and ABox), and eﬀects are expressed in terms of new ABoxes. The
paper investigates veriﬁcation of temporal properties. As a diﬀerence to the EC,
none of these approaches supports a quantitative notion of time.
2
Stratiﬁed Logic Programs and Model Computation
This paper uses the extended “Fusemate” rule language introduced in [12] with-
out the earlier belief revision operator introduced in [11]. This section com-
plements the earlier paper [12] with a rigorous deﬁnition of the semantics of
the extended language. It also provides soundness and completeness arguments,
under certain conditions, wrt. abstract ﬁxpoint iteration and wrt. Fusemate’s
procedure more concretely.
Terms and atoms of a given ﬁrst-order signature with “free” ordinary func-
tion and predicate symbols are deﬁned as usual. Let T be a countably inﬁnite
discrete set of time points equipped with a well-founded total strict ordering <
(strictly earlier), e.g., the natural numbers. Assume that the time points, com-
parison operators =, ≤(earlier), and a next time function +1 are also part of
the signature and interpreted in the obvious way. A time term is a (possibly non-
ground) term over the sub-signature T∪{+1}. The signature may contain other
“built-in” interpreted predicate and function symbols for predeﬁned types such
as strings, arithmetic data types, sets, etc. We only informally assume that all
terms are built in a well-sorted way, and that interpreted operators over ground
terms can be evaluated eﬀectively to a value represented by a term.
Let var(e) denote the set of variables occurring in a term or atom e. We say
that e is ground if var(e) = ∅. We write eσ for applying a substitution σ to e. The
domain of σ is denoted by dom(σ). A substitution γ is a grounding substitution
for a ﬁnite set of variables X iﬀdom(γ) = X. In the following, the letters x, y, z
stand for variables, time for a time term variable, s, t for terms, and tt for a
time term, possibly indexed. Lists of terms or other expressions are written as
vectors, e.g., ⃗t is a list of terms t1, . . . , tn for some n >= 0. A (Fusemate) rule is
an implication written in Prolog-like syntax as
H :– b1, . . . , bk, not⃗b1, . . . , not⃗bn.
(1)

Combining Event Calculus and Description Logic Reasoning
101
In (1), the rule head H is either (a) ordinary, a disjunction h1 ∨· · · ∨hm of
ordinary atoms, for some m ≥1, or (b) the expression fail.2 In case (a) the rule
is ordinary and in case (b) it is a fail rule. The list to the right of :– is the rule
body. Bodies are deﬁned by recursion as follows, along with associated sets fvar
(free variables).
Name
Form
fvar
Comment
Ordinary atom
p(tt,⃗t)
var(tt,⃗t)
tt time term, p free predicate
Comprehension
with time term x
p(x ◦tt,⃗t) sth B
{x} ∪var(tt,⃗t) ◦∈{<, ≤, >, ≥}, B is a body
Built-in call
p(⃗t)
var(⃗t)
p is built-in predicate
Time comparison
s ◦t
var(s, t)
s, t time terms, ◦∈{<, ≤, >, ≥}
Let special form
let(x, t)
{x} ∪var(t)
Choose special form
choose(x, ts)
{x} ∪var(ts)
ts is a set of terms
Collect special form
collect(x, t sth B) {x}
Positive body ⃗b
b1, . . . , bk
∪i=1..kfvar(bi) k ≥0, bi is one of above
Negative body literal not⃗b
∅
⃗b is non-empty positive body
Body B
⃗b, not⃗b1, . . . , not⃗bn fvar(⃗b)
n ≥0, and ⃗b, ⃗bj positive bodies
A positive body literal is of one of the forms up to collect. Examples are
below.
Note 1 (Implicit quantiﬁcation). In a body B, the variables fvar(B) are implic-
itly existentially quantiﬁed in front of that B.3 Rules may contain extra
variables in negative body literals. An example is the rule p(time, x)
:–
q(time, x, y), not(z < time, r(x, y, z)) which corresponds to the (universal quan-
tiﬁcation of the) formula q(time, x, y) ∧¬∃z.(z < time ∧r(x, y, z)) →p(time, x).
The extra variable z will be picked up for existential quantiﬁcation after ground
instantiating the rule body’s fvars {time, x, y}. If γ is such a grounding sub-
stitution then indeed fvar((z < time, r(x, y, z))γ) = {z} as desired. The formal
deﬁnition of the possible model semantics below will make this precise.
⊓⊔
A normal rule is an ordinary rule with one head literal (m = 1 in (1)). A Horn
rule is a normal rule or a fail rule. A fact is an ordinary rule with empty body
(k, n = 0 in (1)) and is simply written as H. A rule H :– B is range-restricted iﬀ
var(H) ⊆fvar(B). A (Fusemate) program is a ﬁnite set of range-restricted and
stratiﬁed rules.
Stratiﬁcation. The standard notion of stratiﬁcation (“by predicates”) means that
the call graph of a program has no cycles going through negative body lit-
erals [31]. Every strongly connected component of the call graph is called a
stratum and contains the predicates that are deﬁned (in rule heads) mutually
2 This deﬁnition of head is actually simpliﬁed as Fusemate oﬀers an additional head
operator for belief revision, see [11]. This is ignored here.
3 The variables var(t) in the collect special form have to be excluded from that because
they are quantiﬁed within their “sth B” body scope. To avoid name conﬂicts, we
assume that var(t) ∩fvar(B′) = ∅for all bodies B′ such that B = B′ or B occurs
in B′.

102
P. Baumgartner
recursive with each other. All head predicates of the same rule are put into the
same stratum. Fusemate employs a weaker stratiﬁcation by time and by predi-
cates (SBTP) [12]. With SBTP, every ordinary non-fact rule (1) must have an
ordinary body literal bi, for some 1 ≤i ≤k, with a pivot variable time, such
that every other time term in the head (body) is syntactically constrained to
≥(≤, respectively) than time, and the literals within negative body literals are
syntactically constrained to be (a) < than time or (b) ≤than time and must
be in a stratum strictly lower than the head stratum. For example, the rule
p(time, x) :– q(time, x), not(r(t, y), t ≤time) is SBTP if r is in a strictly lower
stratum than p, and p(time, x) :– q(time, x), not(r(t, y), t < time) is SBTP even
if r is in the same stratum as p. This has the eﬀect that model computation can
be done in time/stratum layers in increasing (lexicographic) order using only
already derived atoms.
Comprehension and collect must be stratiﬁed for the same reason. For the
purpose of SBTP, a comprehension p(x ◦tt,⃗t) sth B is taken as if p(x,⃗t) and
B were negative body literals, and collect(x, t sth B) is taken as if B were a
negative body literal.
2.1
Possible Models
We need some preliminaries pertaining to the semantics of rules before formally
deﬁning “possible models”. A (rule) closure is a pair (H :– B, β) such that β is
a grounding substitution for fvar(B) called body matcher in this context. For a
program P, its full closure cl(P) is the set of all closures of all rules in P.
Full closures supplant the usual full ground instantiation of programs. They
make it easy to deﬁne rule semantics in presence of the special forms, compre-
hension operators, and implicit existential quantiﬁcation without full grounding.
This works as follows.
An interpretation I is a (possibly inﬁnite) set of ordinary atoms. Let I be an
interpretation and β a grounding substitution for some set of variables. Let B be
a body as in (1). If fvar(Bβ) = ∅deﬁne I, β |= B iﬀI, β |= bi for all i = 1..k and
I, β |= not⃗bj for all j = 1..n, where the following table provides the deﬁnitions
for body literals:
Name
Form
Def
Ordinary atom
I, β |= p(tt,⃗t)
iﬀp(tt,⃗t)β ∈I
Comprehension
with time term x
I, β |= p(x < tt,⃗t) sth B iﬀxβ is the maximal (latest) time point s.th.
xβ < ttβ, I, β |= p(x,⃗t) and I, β |= ∃B.
Accordingly for ≥, <, ≤
Built-in call
I, β |= p(⃗t)
iﬀp(⃗t)β evaluates to true
Time comparison
I, β |= s ◦t
iﬀsβ ◦tβ
Let special form
I, β |= let(x, t)
iﬀxβ = tβ
Choose special form I, β |= choose(x, ts)
iﬀxβ ∈tsβ
Collect special form I, β |= collect(x, t sth B) iﬀxβ = {tγ | I, βγ |= B for some
grounding substitution γ for fvar(Bβ)}
In that table, deﬁne I, β |= ∃B iﬀthere is a grounding substitution γ for
fvar(Bβ) such that I, βγ |= B (βγ is β extended with bindings for the implicitly

Combining Event Calculus and Description Logic Reasoning
103
existentially quantiﬁed variables in Bβ). For closures deﬁne I |= (H :– B, β)
iﬀI, β ̸|= B or else H is an ordinary head h1 ∨· · · hm and hiβ ∈I for some
1 ≤i ≤m. In this case we say that I satisﬁes (H :– B, β). An interpretation I
is a model of a set C of closures, written as I |= C iﬀI satisﬁes every closure
in C. It is minimal iﬀJ ̸|= C for every J ⊊I. It is supported iﬀfor every a ∈I
there is a (h :– B, β) ∈C such that a = hβ and I, β |= B.
Note 2 (Fixpoint iteration for DLPs [33]). The possible model semantics [33,34]
assigns to a disjunctive logic program sets of Horn programs and takes their
intended models as the possible models of the disjunctive program. The Horn
programs represent all possible ways of making one or more head literals true,
for every disjunctive rule. As a propositional example, the disjunctive program
{a :– b, a ∨c :– b, b :– not d} is split into the Horn programs {a :– b, b :– not d}
and {a :– b, c :– b, b :– not d}. The possible models are {a, b} and {a, b, c}.
Non-ground programs have to be fully ground-instantiated using the program’s
(possibly inﬁnite) Herbrand base ﬁrst.
As explained in [33], the possible models of such ground-instantiated strat-
iﬁed programs can be constructed by iterated ﬁxpoint computation along the
program’s stratiﬁcation. For each stratum, in ascending order, the rules with a
head predicate from that stratum are evaluated in the model so far, up to that
stratum, and, only if necessary, made true by adding the head to the model,
until ﬁxpoint. In general this construction requires transﬁnite induction with a
limit ordinal at each stratum.
⊓⊔
From a practical (Fusemate) perspective we are mostly interested in ﬁnite ﬁx-
points for making model computation eﬀective. We start with a deﬁnition for
the possible models splitting operator in terms of closures.
Deﬁnition 1 (Split program closure).
Let P be a program and cl(P) its
full closure. A split program closure of P is obtained from cl(P) by replacing
every closure (h1 ∨· · · ∨hm ←B, β) in cl(P) by the split closures (h ←B, β),
for every h ∈S, where S is some non-empty subset of {h1, . . . , hm}.
Deﬁnition 2 (Possible model, adapted from [33]). An interpretation I is
a possible model of P if I is a minimal supported model of some split program
closure of P.
2.2
Fusemate Soundness and Completeness
We wish to apply the ﬁxpoint model construction (Note 2) to Fusemate pro-
grams. For this to work, rules must be monotonic and compact.
Deﬁnition 3. Let (H :– B, β) be an ordinary rule closure. It is monotonic iﬀ
for all I and J ⊇I such that every atom in J \ I is in the same stratum as Hβ,
if I, β |= B then J, β |= B. It is compact iﬀfor all I, if I, β |= B then J, β |= B
for some ﬁnite J ⊆I.

104
P. Baumgartner
In general, monotonicity of an operator guarantees the existence of a least ﬁx-
point, and compactness guarantees that it can be found by ﬁxpoint iteration. For
satisﬁable Horn programs, monotonicity entails the “model intersection property”
which entails the existence of a unique minimal model. These are all well-known
standard results [24], and the above deﬁnitions are formulated in a way to make
these results applicable.
Fusemate rules are always monotonic. For comprehension and collect this is
due to stratiﬁcation. However collect is not always compact. Given a body literal
collect(x, t sth B), there could be inﬁnitely many substitutions γ in the compre-
hension {tγ |I, βγ |=B for some grounding substitution γ for fvar(Bβ)}. Because
inﬁnite sets have no term representation, such a collect literal renders its rule body
always unsatisﬁed, resulting in incompleteness. One possible way out is to make
sure that the variables in t range only over ﬁnite domains, e.g., sets of constants.
With this ﬁx, it follows that ﬁxpoint iteration (Note 2) wrt. SBTP is sound and
complete for possible models of Fusemate programs (Deﬁnition 2). The proof is
an adaptation of the corresponding one in [33].
Soundness and completeness of ﬁxpoint iteration holds in particular for
ﬁnite models. This suggests another “ﬁx”: thanks to stratiﬁcation, the mentioned
incompleteness can occur only when I itself is inﬁnite at a limit step in the ﬁx-
point iteration. Because computing (rather, ﬁnitely representing) inﬁnite models
is out of scope anyway, it is safe to ignore the compactness problem for ﬁnite
model computation.
Fusemate. Fusemate implements a bottom-up model computation procedure in
the style of hyper tableaux [13] in a stratiﬁed way (SBTP). The Fusemate main
loop computes body matchers β of bodies B of program rules H :– B against
a current branch (a model candidate) and closes it or branches out according
to possible models splitting. Each new branch is for a set S in Deﬁnition 1 and
receives all hβ for h ∈S.4 This constructs tableau in a depth-ﬁrst left-to-right
order. Body matcher computation is made more practical by guaranteed left-
to-right evaluation of bodies. This helps to avoid unexpected undeﬁnedness of
comprehensions and special forms. For example, in the body of r(time, xs) :–
q(time, y), collect(xs, x sth(p(time, x), x > y)) the collect special form binds the
variable xs to the list of all x such that p(time, x) and x > y hold, where y has
already been bound by the preceding q(time, y). See [12] for a formal deﬁnition
of left-to-right body matcher computation.
Other than that, Fusemate model computation follows the abstract ﬁx-
point computation procedure (see Note 2) for ﬁnite interpretations. This entails
ﬁnite model soundness: if Fusemate terminates on a program P with an open
exhausted branch then this branch contains a ﬁnite possible model of P. It also
entails ﬁnite model completeness: if every possible model of P is ﬁnite then
Fusemate will compute each of them in its open exhausted branches. A formal
4 Body matcher are represented internally in the Scala runtime system without explicit
grounding.

Combining Event Calculus and Description Logic Reasoning
105
theorem for these results could be given but is not stated here because it would
require more formalization.
Fusemate’s termination behavior could be improved with a breadth-ﬁrst
strategy, however at the expense of one-branch-at-a-time space eﬃciency. In
the programs below this is not a problem.
3
Description Logic Interface
Fusemate can be used as a description logic (DL) reasoner by mapping a DL
knowledge base into a logic program and running that program for satisﬁabil-
ity [12]. This section makes that reasoner callable from rules, but other DL rea-
soners could be coupled, too. It describes the syntax, semantics, and soundness
and completeness properties of the coupling, and it discusses related work.
The DL terminology follows [5]. To summarize, a DL knowledge base KB
consists of a TBox and an ABox. A TBox T is a set of GCIs (general concept
inclusions), each of the form C ⊑D where C and D are DL concept expressions,
or just concepts. An ABox A is a set of ABox assertions, i.e., concept asser-
tions and role assertions of the forms a : C and (a, b) : r, respectively, where a
and b are individuals and r is a role. Fusemate currently implements ALCIF ,
which is ALC extended with inverse roles and functional roles. A role, hence,
is either a role name n or an inverse role name n−1. Roles can be declared as
functional (right-unique). As usual, KB-satisﬁability is assumed to be decidable
and concept formation must be closed under negation, so that query entailment
can be reduced to KB unsatisﬁability as follows. Given a KB (A, T) and an
ABox Q, the (ground) query, deﬁne (A, T) |=DL Q iﬀthe KB entails Q wrt.
the usual ﬁrst-order logic semantics of description logics, or, equivalently: for all
a : C ∈Q the KB (A ∪{a : ¬C}, T) is unsatisﬁable and for all (a, b) : r ∈Q the
KB (A ∪{a : ∀r.¬B, b : B}, T) is unsatisﬁable, where B is a fresh concept name.
The coupling between the rules and the DL reasoner is two-way and dynamic:
it is two-way in the sense that rules can not only call the DL reasoner wrt. a
ﬁxed ABox and a TBox, the rules can also construct ABoxes during model
computation, individually in each possible model. It is dynamic in the sense
that ABox assertions are time-stamped, like ordinary atoms, and also all earlier
ABoxes are accessible by the rules.
Syntax. Concepts and roles are treated as constants by the rule language while
any free ground term can be a DL individual. More precisely, assume a DL
signature whose concept and role names are disjoint with the signature of the
rule language. Let t, t1, t2 be free possibly non-ground terms, C a concept, r a
role and tt a time term. An untimed DL-atom is of the form t : C or (t1, t2) : r. Let
IsAAt/3 and HasAAt/4 be distinguished ordinary predicate symbols. A timed DL-
atom is an ordinary atom IsAAt(t, C, tt) or HasAAt(t1, r, t2, tt), usually written as
t : C@tt or (t1, t2) : r@tt, respectively. Timed DL-atoms can appear in heads (and
bodies) of ordinary rules. This allows to create time-stamped ABoxes initially
as sets of facts and dynamically during program execution. For calling the DL

106
P. Baumgartner
reasoner, the rule language is extended by the following DL-call special forms,
where T is a TBox, A is an ABox, and ⃗q (“query”) is a list of untimed DL-atoms.
T |= ⃗q
DLISSAT(T)
DLISUNSAT(T)
(A, T) |= ⃗q
DLISSAT(A, T)
DLISUNSAT(A, T)
The free variables are fvar(⃗q) in the left column cases, otherwise empty.
Semantics.
Logic programming considers syntactically diﬀerent terms as
unequal. This is not enforced in DLs. Indeed, e.g., if A = {(a, c) : r, (a, b) : r}
and r is a functional role then A is satisﬁable by making b and c equal. To avoid
such discrepancies, DL individuals are explicitly equipped with a unique name
assumption, as follows.
Given an ABox A, let K(A) = {a1, . . . an} be the set of all (“known”) individ-
uals mentioned in A and deﬁne UNA(A) = {ai : N(ai,aj), aj : ¬N(ai,aj) | ai, aj ∈
K(A) and 1 ≤i < j ≤n}. In that, N(ai,aj) are fresh concept names. The set
UNA(A) speciﬁes that all individuals in A must be pairwise unequal (a, b and c
in the example).
The deﬁnition of rule semantics in Sect. 2 is extended by DL-calls as follows:
I, β |= ((A, T) |= ⃗q) iﬀ(A∪UNA(A)∪UNA(⃗qβ), T) |=DL ⃗qβ (⃗qβ as a set); I, β |=
DLISSAT(A, T) iﬀ(A ∪UNA(A), T) is satisﬁable; I, β |= DLISUNSAT(A, T) iﬀ
(A ∪UNA(A), T) is unsatisﬁable.
For the DL-calls on the ﬁrst line, let time be the pivot variable of the rule
containing the DL-call and take A = abox(I, time β) for the corresponding def-
inition with explicit A, where abox(I, d) = {t : C | t : C @ d ∈I} ∪{(t1, t2) : r |
(t1, t2) : r @ d ∈I} is the induced ABox from I at time d. Intuitively, such a DL-
call gets its ABox from the current interpretation by projection from its timed
DL-atoms at the current time.
Notice the implicit dependency of an induced ABox on timed DL-atoms at
pivot time. This is why for the purpose of stratiﬁcation every line one DL-call
stands for the two subgoals IsAAt(_, _, time) and HasAAt(_, _, _, time). For
constant ABoxes on the second line stratiﬁcation is not an issue. (As such they
are not very useful - but see Example 2 and the example in Sect. 5 below.)
With all that in place, the possibly model semantics for stratiﬁed programs
deﬁned in Sect. 2.1 carries over to the DL coupling without change. Notice that
the semantics of the coupling is agnostic of the notion of (un)satisﬁability and
entailment in the DL part. This way, the coupling respects the usual open world
semantics of DL reasoning. Notice also that it is possible that a program has
a possible model I whose induced ABox is unsatisﬁable with some TBox T. If
this is not desirable it is easy to reject such a model with a fail rule utilising a
DLISUNSAT(T) call.
Soundness and Completeness. Soundness and completeness carries over from
Sect. 2.2 with some caveats. Incompleteness can arise due to potentially inﬁnite
ABoxes induced at limit ordinals. With an interest in ﬁnite models only, this
issue can safely be ignored, as before. A more relevant issue is monotonicity
(Deﬁnition 3). DLISSAT calls can be non-monotonic because ﬁrst-order logic

Combining Event Calculus and Description Logic Reasoning
107
satisﬁability is, of course, not always preserved when a KB grows. This can
lead to both incompleteness/unsoundness, depending on a positive/negative call
context. The other two forms are based on unsatisﬁability, hence monotonic, and
cause no problem. With those only, iterated ﬁxpoint computation and Fusemate
model computation are both sound and complete for ﬁnite possible models.
Related Work. According to the classiﬁcation in [16], ours is a hybrid approach
with a loose coupling between the description logic and the rule reasoner. The
coupling is done in a DL-safe way [27], in fact, essentially, in a weakly DL-safe [32]
way as in DL+Log. DL+log [32] is among the most expressive languages that
combines rules with ontologies. DL+log rules can query a DL reasoner by taking
concept/role names as unary/binary predicates and using (in our terms) extra
existentially quantiﬁed variables in queries. With Fusemate rules one would
equivalently use existential role restrictions. Unlike DL+log, Fusemate allows
DL-calls within default negation, cf. Example 2. Most other hybrid languages,
like the one in [27] and dl+Programs [17] do not allow DL atoms in the head.
Unlike as in the other approaches, concepts and roles are terms here and, hence,
can be quantiﬁed over in rules. This is advantageous for writing domain inde-
pendent rules involving concepts and roles, such as the event calculus in Sect. 4.
3.1
Example
As a running example we consider a highly simpliﬁed transport scenario. Boxes
containing goods are loaded onto a truck, moved to a destination, and unloaded
again. The boxes can contain perishable goods that require cooling, fruits, or
non-perishable goods, toys. Boxes of the former kind (and only those) can be
equipped with temperature sensors and provide a temperature value, which is
classiﬁed as low (unproblematic) or high (problematic). A part of this domain
is modelled in the description logic ALC extended with functional roles. The
following KB has a TBox on box properties (left), and an ABox on temperature
classes (middle) and box properties (right):
Box ⊑∀Temp.TempClass
Low : TempClass
Box0 : FruitBox
FruitBox ⊑∃Temp.TempClass
High : TempClass
Box1 : FruitBox
ToyBox ⊑¬∃Temp.TempClass
Box2 : Box
FruitBox ⊑Box
Box3 : ToyBox
ToyBox ⊑Box
Box4 : Box ⊓∀Temp.¬TempClass
Temp is a functional role
Box5 : Box ⊓∃Temp.TempClass
Example 1. The ABox assertions can be represented as a program with facts
timed at, say, 0 (“beginning of time”), e.g., Box(5) : Box ⊓∃Temp.TempClass@0.5
Let tbox denote the TBox above. Some example rules with DL-calls are
5 The concrete Fusemate syntax is IsAAt(Box(5), And(Box,Exists(Temp,TempClass)), 0)
but we stick with the better readable “:”-syntax. TBoxes have similar syntax and
are typically bound to (Scala) variables like tbox in the example. In concrete syntax,
free constant, function and predicate symbols start with a capital letter, variables
with a lower case letter. An underscore _ is an anonymous variable.

108
P. Baumgartner
The ﬁrst rule materializes the Box concept. Any known individual at a given
time that is provable a Box will explicitly become a Box individual at time. While
this is redundant for DL-reasoning, it comes in handy for rules. For example,
the second rule applies to explicitly given Boxes at time that provably have
a Temp attribute. Thanks to the ﬁrst rule, TempBox(0,Box(i)) is derivable for
i ∈{0, 1, 5}. (Recall that the ABox in the DL-call is formed from the timed
DL-atoms at pivot time.) The third rule is a variation of the second rule and
tests if a box has a concrete Temp attribute Low or High instead of some.
⊓⊔
Example 2. This is an example for a stratiﬁed DL-call within default negation
and explicit ABox:
According to this rule, a box is a ColdBox at a given time if it never provably was
a Box in the past with a High temperature. The (Scala) expression I.aboxAt(t)
can be used in Fusemate to retrieve the induced abox at time t from the current
interpretation I.6 Notice that t is strictly earlier than time which renders the
DL-call stratiﬁed.
An
example
for
the
DLISUNSAT
DL-call
is
in
the
rule
fail
:-
Now(time), DLISUNSAT(tbox). This rule abandons a current model candidate
if its induced abox at the current time “Now” is inconsistent with tbox.
⊓⊔
4
Event Calculus Embedding
The event calculus (EC) is a logical language for representing and reasoning
about actions and their eﬀects [20,35]. At its core, eﬀects are ﬂuents, i.e., state-
ments whose truth value can change over time, and the event calculus provides
a framework for specifying the eﬀects of actions in terms of initiating or termi-
nating ﬂuents.
Many versions of the EC exists, see [26] for a start. The approach below
makes do with a basic version that is inspired by the discrete event calculus
in [28] with integer time. The event calculus of [28] is operationalized by trans-
lation to propositional SAT. Its implementation in the “decreasoner” is geared
for eﬃciency and can be used to solve planning and diagnosis tasks, among oth-
ers. The version below is tailored for the model computation tasks mentioned
6 Access to I is unusual for logic programming systems. See [12] for a discussion of
this features.

Combining Event Calculus and Description Logic Reasoning
109
in the introduction, where a ﬁxed sequence of events at given timepoints can
be supposed.7 It rests on minimal model semantics and stratiﬁed default nega-
tion. Most of it is not overly speciﬁc to Fusemate, and answer set programming
encodings of the event calculus, e.g. [21], should be applicable as well.
The rest of this section explains the EC/DL integration grouped into “axiom
sets”:
– Domain independent EC axioms: principles of actions initiating/terminating
ﬂuents
– Domain independent EC/DL integration axioms: ABox assertions as ﬂuents
– Domain dependent axioms: initial situation and concrete actions eﬀects
– Concrete actions: events driving the model computation
– Fusemate speciﬁc rules
Domain Independent Axioms. The EC main syntactic categories are Fluents and
Actions, both given via designated sub-signatures of the term signature. They
are used with EC-predicates in intended sorting as follows:
Initiates : T × Action × Fluent
Initiated : T × Fluent
Terminates : T × Action × Fluent
Terminated : T × Fluent
StronglyTerminates : T × Action × Fluent
StronglyTerminated : T × Fluent
HoldsAt : T × Fluent
Happens : T × Action
The EC was originally introduced as a Prolog logic program. The following
domain independent rules are similar but modiﬁed for stratiﬁed bottom-up
model computation. Some rules use a “strong negation” operator neg which
can be applied to ordinary atoms in the body or the head. Fusemate imple-
ments the usual semantic [18] which amounts to adding the rules fail :–
p(time, ⃗x), neg p(time, ⃗x) for every ordinary predicate p.
7 Actually, events can be inserted in retrospect using Fusemate’s revision operator,
restarting the model computation from there. The paper [11] already has a “supply-
chain” example for that.

110
P. Baumgartner
In the rules above, the variable f stands for ﬂuents and a for actions. The
axioms H1 – H3 specify the dependencies between ﬂuents and actions in gen-
eral. The distinction between Initiates and Initiated was made for being able to
distinguish between initiation by actions (“loading a box on a truck initiates the
box being on the truck”) and initiation as a matter of circumstances or their
consequences (“smoke initiated alarm bell ringing”).
The core relation is HoldsAt(time,f) which can hold true at time because f is
Initiated at time (EC3), or was true at the previous time step but not terminated
(EC5, frame axiom). Similarly for the negated case. Notice the diﬀerence between
Terminated and StronglyTerminated. The former removes HoldsAt(time, f) from
the model, the latter inserts neg(HoldsAt(time,f)) into it. That is, this is a three-
valued logic. With default negation one can distinguish the three cases.
Notice that ﬂuents are initiated or terminated in H1 – H3 with a delay of
one time step. This was done so that the Initiates and Terminates predicates can
be deﬁned in a stratiﬁed way in terms of HoldsAt at the current time. Without
the delay SBTP would be violated in such cases. The increase in time will not
cause non-termination of model computation because H1 – H3 are conditioned
on events happening (as long as there are only ﬁnitely many events).
4.1
Linking Description Logic with the Event Calculus
Sect. 3 introduced timed DL-atoms for specifying (timestamped) ABoxes. Typ-
ically, ABox assertions should be preserved over time unless there is reason for
change. Examples are the initial ABox assertions in Example 1 and role asser-
tions in Example 4 below. This immediately suggests to utilize the event calculus
for treating ABox assertions as ﬂuents. The following explains this in more detail.
Domain Independent Axioms. From now on, untimed DL-atoms are allowed
in ﬂuent positions. Untimed DL-atoms are enough because ﬂuents occur within
EC-predicate atoms which by themselves provide the time. The following axioms
are added as domain independent axioms to restore the timed DL-atom versions
of the ﬂuents:
1 x : c @ time :– HoldsAt(time, x : c) // DL1
2 x : Neg(c) @ time :– neg(HoldsAt(time, x : c)) // DL2
3 (x, y): r @ time :– HoldsAt(time,(x, y) : r) //DL3
Notice the use of variables c and r in concept and role positions, which makes it
possible to formulate these axioms independent of a concrete DL KB. The DL2
axiom expresses strongly negated concept membership equivalently by member-
ship in the negated concept.
The axioms DL1 – DL3 are obviously reasonable in any domain. Their con-
verse is not, however. Not everything holding true at a point in time should by
default extend into the future, e.g., a person’s birthday.

Combining Event Calculus and Description Logic Reasoning
111
Domain Dependent Axioms. Domain dependent axioms comprise ﬂuents that
hold initially and speciﬁcations of action eﬀects in terms of initiation and termi-
nation of ﬂuents. An example for the former is the fact for Box(5) in Example 1,
which could be rewritten as HoldsAt(0, Box(5) : Box ⊓∃Temp.TempClass).
Example 3. The following rules specify the eﬀects of Load and Unload actions of
boxes in terms of these boxes being OnTruck.
1 Initiates(time, Load(box), OnTruck(box)) :– box : Box @ time
2 StronglyTerminates(time, Unload, OnTruck(box)) :– HoldsAt(time, OnTruck(box))
The ﬁrst rule makes sure in its body that only boxes that exist at a time can
be loaded. The second rule concludes that all boxes loaded will deﬁnitely not be
not on the truck after unload. All other boxes are untouched. Notice that the
OnTruck ﬂuent is not a DL concept (it doesn’t have to be).
⊓⊔
Concrete Actions. What is still missing are concrete actions happening for trig-
gering the model computation in the combined Rules/DL/EC domain model. In
the running example we consider the following scenario unfolding:
Time
10
20
30
40
50
Action
Load Box0
Load Box1
Load Box2
Load Box3
Load Box4
Unload
Sensor
Box0 : −10◦
Box2 : 10◦
Box0 : 2◦
Box0 : 20◦
These
actions
are
easily
represented
as
facts,
e.g.,
Happens(10,
Load(Box(0))). The temperature measurement at time 20 for Box(2) becomes
Happens(20, SensorEvent(Box(2), 10)).
Concrete Domains. Real-world applications require reasoning with concrete
domains (numeric types, strings, etc.). Extending DLs with concrete domains
while preserving satisﬁability is possible only under tight expressivity bounds.
See [25] for a survey. One way to mitigate this problem is to use rules and built-
ins for concrete domains and to pass symbolic abstractions to the DL reasoner.
Example 4. This rule demonstrates abstracting a concrete box temperature sen-
sor reading as a Temp attribute.
1 Initiates(time, SensorEvent(box, temp), (box, High) : Temp) and
2
Terminates(time, SensorEvent(box, temp), (box, Low) : Temp) ) :–
3
Happens(time, SensorEvent(box, temp)), temp > 0
The given action Happens(20, SensorEvent(Box(2), 10)) with the rule above and
rules H1 and H6 will derive HoldsAt(21, (Box(2),High) : Temp). From that, with
DL1 and the rules in Example 1, Box(2) will become a TempBox and even a
KnownTempBox from time 21 onwards.
⊓⊔

112
P. Baumgartner
Fusemate Speciﬁc Rules. Fusemate provides the user with a number of non-
standard operators, see [12]. One of them is the aggregation operator COLLECT.
Example 5. Consider the rule
1 Unloaded(time+1, boxes) :–
2
Happens(time, Unload),
3
COLLECT(boxes, box STH HoldsAt(time, OnTruck(box)))
This rule aggregates all unloaded boxes into one set, boxes, one tick after
Unload time. It is not formulated as a ﬂuent to make it a timepoint
property. In the example, the Unload happens at time 50, which leads to
Unloaded(51, Set(Box(0), Box(1), Box(2), Box(3), Box(4)). Notice that these are
exactly the boxes loaded over time, at timepoints 10, 20, and 30.
⊓⊔
4.2
Ramiﬁcation Problem
The ramiﬁcation problem is concerned with indirect consequences of an action.
Such consequences could be in conﬂict with facts holding at the time of the
action or other consequences. This problem is particularly prominent in the
combination with DL, where eﬀects (i.e., ﬂuents) can be entailed implicitly by
the DL KB, and possibly in an opaque way. Trying to terminate such a ﬂuent
can be futile, as it could be re-instated implicitly or explicitly by materialization.
A good example is the entailment of TempBox(0, Box(0)) as discussed in
Example 1. Suppose we wish to re-purpose Box(0) and no longer use it for
temperature sensitive transport. In terms of the modelling, Box(0) shall no longer
belong to the (entailed) concept ∃Temp.TempClass.
The ramiﬁcation problem has been extensively researched in the EC liter-
ature, see [35]. For instance, one could impose state constraints, if-and-only if
conditions, so that terminating an entailed ﬂuent propagates down; or one could
use eﬀect constraints that propagate termination of actions to other actions. A
ﬁrst attempt in this direction is a rule that terminates a ﬂuent that entails the
property to be removed:
1 Terminated(time+1, (box, temp) : Temp)) :–
2
RemoveTemp(time, box), // Some condition for removing box Temp
3
(box, temp) : Temp @ time // Attribute to be removed
This rule works as expected for Box2 after explicitly having received a Temp-
attribute at time 20, cf. Example 4. It does not work, however, for, e.g., Box0.
As a FruitBox, Box0 has a Temp attribute implied by the TBox.
One way to ﬁx this problem in the running example is to terminate all con-
cept assertions for the box as any of them might entail a Temp attribute, and
only retain that it is a Box:
1 (Terminated(time, box : concept) and Initiated(time, box : Box)):–
2
RemoveTemp(time, box), // Some condition for removing box Temp
3
box : concept @ time, concept != Box // Concept to be removed
4 // Similar rule for removing role assertions omitted

Combining Event Calculus and Description Logic Reasoning
113
While this measure achieves the desired eﬀect, it may also remove box properties
that could be retained, e.g., the size of the box (if it were part of the example,
that is).
The KB revision problem has been studied extensively in database and AI set-
tings. For DLs, there are algorithms for instance level updates of an ABox, where,
in ﬁrst-order logic terms, the ABox is a set of ground atoms over known individ-
uals, see [19]. Very recently, Baader etal [6,7] devised algorithms for semantically
optimally revising ABoxes that may contain quantiﬁers (e.g. Box5 in the running
example). All these result are for lightweight description logics, though.
5
Putting It All Together
This section completes the running example with rules for diagnostic reasoning.
Suppose a given subset of the boxes {Box0, . . . , Box5} is unloaded at the destina-
tion. We are interested in determining the status of the delivery and computing
possible models as explanations under these constraints:
1. If there is no unloaded box with known high temperature then the status is
OK.
2. If some unloaded box has a known high temperature then this box has been
tampered with or the truck cooling is broken.
3. If some unloaded box has a known low temperature then the truck cooling is
not broken (because a broken cooling would aﬀect all boxes).
4. If all unloaded boxes with a temperature sensor can consistently be assumed
to have high temperature then box tampering can be excluded (because bro-
ken cooling is the more likely explanation).
The following rules determine the status of the delivery as “ok” or “anomalous”.
There are two cases of anomalies, (a) the truck cooling is broken or (b) some box
has been tampered with. The rules feature disjunctive heads, strong negation,
DL-calls, Scala builtin calls and the set datatype.
1 OK(time) :– Unloaded(time, boxes), not Anomaly(time, _)
3 Anomaly(time, TamperedBox(box)) or Anomaly(time, BrokenCooling) :–
4
Unloaded(time, boxes),
5
(box, High) : Temp @ time,
6
boxes ∋box
8 neg(Anomaly(time, BrokenCooling)) and neg(Anomaly(time, TamperedBox(box))) :–
9
Unloaded(time, boxes),
10
(box, Low) : Temp @ time,
11
boxes ∋box
13 fail :–
Anomaly(time, TamperedBox(box)),
14
Unloaded(time, unloadedBoxes),
15
COLLECT(boxes, box STH (TempBox(time, box), unloadedBoxes ∋box)),
16
LET(assertions, boxes map { (_, High) : Temp }), // unloaded boxes ascribed High
Temp
17
DLISSAT(I.aboxAt(time) ++ assertions, tbox)

114
P. Baumgartner
The ﬁrst rule makes the delivery ok in absence of any anomaly. The second rule
observes an anomaly if some unloaded box has a High temperature. The anomaly
could be either type, or both, this rule makes a guess. The third and the fourth
rule are eliminating guesses. The third rule says that the truck cooling is not
broken if evidenced by the existence of a Low temperature box. Moreover, each of
these boxes has not been tampered with. The fourth rule is the most interesting
one. It eliminates a tampered-box anomaly by considering all unloaded boxes
that are known to be equipped with temperature sensors. The rationale is that
if all these boxes can consistently be assumed to have High temperature then
box tampering is unlikely (broken cooling is more likely).
This reasoning is achieved by collecting in line 15 in the boxes variable the
mentioned boxes (TempBox was deﬁned is Example 1). Line 16 assigns to a
variable assertions the value of the stated Scala expression for constructing High
temperature role assertions for boxes. Finally, the DL-call on line 17 checks the
satisﬁability of the KB consisting of the current abox temporarily extended with
assertions and the static TBox. It is important to know that fail rules are always
tried last for a ﬁxed current time, after all ordinary rules. This way, the usages
of COLLECT and DLISSAT in the last rule are stratiﬁed.
The correct diagnosis is Anomaly(51, BrokenCooling). In the course of events,
the TempBoxes are Box0, Box1, Box2, and Box5 (Box2 becomes one only at time
20.) The unloaded boxes at time 50 are Box0, Box1, Box2, and Box4. In their inter-
section, Box0 and Box2 have High Temp values, which gives rise to an anomaly.
Only the box Box1 has an unknown Temp value, which is consistent with High
and, hence, excludes a TamperedBox anomaly. Moreover, for every box, neither
a TamperedBox anomaly nor a negated TamperedBox anomaly is derived.
If the Box0 sensor reading at time 40 is changed from 10 to -10 then the
diagnosis is
1 Anomaly(51, TamperedBox(Box(2)))
2 neg(Anomaly(51, TamperedBox(Box(0))))
3 neg(Anomaly(51, BrokenCooling))
Both diagnosis are the only possible models in each case and nothing is known
about Box1. The Fusemate runtime is approx. 4 s in each case on a modern PC.
The main bottleneck is lack of performance of the coupled DL-reasoner, which
is a proof-of-concept implementation only.
6
Conclusions
This paper introduced a knowledge representation language that, for the ﬁrst
time, combines the event calculus with description logic in a logic programming
framework for model computation. The paper demonstrated the interplay of
these three components by means of an elaborated example.
Results are in parts at an abstract level. They include conditions for ﬁnite-
model soundness and completeness of the rules/DL reasoner coupling that are
re-usable in other systems that support stratiﬁcation in a similar way ([37], e.g.).

Combining Event Calculus and Description Logic Reasoning
115
The diagnosis rules in Sect. 5, among others, utilized Fusemate’s speciﬁc set
comprehension operator (COLLECT) and might be hard to emulate in other
systems. It might be possible to run the example in this paper with an expressive
system like DLV [22] without too many changes.
The modelling in the example emphasised the possibility to distinguish
between absent, unknown or known attribute values, which was enabled by the
description logics/rules integration. One might want to go a step further and
add “dynamic existentials” to the picture. These are unknown or implicit actions
that must have existed to cause observed eﬀects. Recovered or speculating such
actions can be expressed already with the (implemented) belief revision frame-
work of [11]. Experimenting with that within the framework here is future work.
The perhaps most pressing open issue is the EC ramiﬁcation problem
(Sect. 4.2), which is particularly pronounced with the DL integration into the
EC. Recent advances on ABox updates might help [6,7].
Acknowledgement. I am grateful to the reviewers for their constructive feedback.
References
1. Artikis, A., Skarlatidis, A., Portet, F., Paliouras, G.: Logic-based event recognition.
Knowl. Eng. Rev. 27(4), 469–506 (2012)
2. Baader, F., et al.: A novel architecture for situation awareness systems. In: Giese,
M., Waaler, A. (eds.) TABLEAUX 2009. LNCS (LNAI), vol. 5607, pp. 77–92.
Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-642-02716-1_7
3. Baader, F., Borgwardt, S., Lippmann, M.: Temporal conjunctive queries in expres-
sive description logics with transitive roles. In: Pfahringer, B., Renz, J. (eds.) AI
2015. LNCS (LNAI), vol. 9457, pp. 21–33. Springer, Cham (2015). https://doi.org/
10.1007/978-3-319-26350-2_3
4. Baader, F., Ghilardi, S., Lutz, C.: LTL over description logic axioms. ACM Trans.
Comput. Logic - TOCL 13, 1–32 (2008)
5. Baader, F., Horrocks, I., Lutz, C., Sattler, U.: An Introduction to Description
Logic. Cambridge University Press, Cambridge (2017)
6. Baader, F., Koopmann, P., Kriegel, F., Nuradiansyah, A.: Computing optimal
repairs of quantiﬁed ABoxes w.r.t. static EL TBoxes. In: Platzer, A., Sutcliﬀe, G.
(eds.) CADE 2021. LNCS (LNAI), vol. 12699, pp. 309–326. Springer, Cham (2021).
https://doi.org/10.1007/978-3-030-79876-5_18
7. Baader, F., Kriegel, F., Nuradiansyah, A., Peñaloza, R.: Computing compliant
anonymisations of quantiﬁed ABoxes w.r.t. EL policies. In: Pan, J.Z., et al. (eds.)
ISWC 2020. LNCS, vol. 12506, pp. 3–20. Springer, Cham (2020). https://doi.org/
10.1007/978-3-030-62419-4_1
8. Baader, F., Lippmann, M., Liu, H.: Using causal relationships to deal with the ram-
iﬁcation problem in action formalisms based on description logics. In: Fermüller,
C.G., Voronkov, A. (eds.) LPAR 2010. LNCS, vol. 6397, pp. 82–96. Springer, Hei-
delberg (2010). https://doi.org/10.1007/978-3-642-16242-8_7
9. Baader, F., Lutz, C., Miličic, M., Sattler, U., Wolter, F.: Integrating description
logics and action formalisms: ﬁrst results. In: Proceedings of the 20th National
Conference on Artiﬁcial Intelligence, AAAI 2005, vol. 2, pp. 572–577. AAAI Press
(2005)

116
P. Baumgartner
10. Bagheri Hariri, B., Calvanese, D., De Giacomo, G., Masellis, R., Felli, P., Montali,
M.: Description logic knowledge and action bases. J. Artif. Intell. Res. 46, 651–686
(2013)
11. Baumgartner, P.: Possible models computation and revision – a practical approach.
In: Peltier, N., Sofronie-Stokkermans, V. (eds.) IJCAR 2020. LNCS (LNAI), vol.
12166, pp. 337–355. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-
51074-9_19
12. Baumgartner, P.: The Fusemate logic programming system. In: Platzer, A., Sut-
cliﬀe, G. (eds.) CADE 2021. LNCS (LNAI), vol. 12699, pp. 589–601. Springer,
Cham (2021). https://doi.org/10.1007/978-3-030-79876-5_34
13. Baumgartner, P., Furbach, U., Niemelä, I.: Hyper tableaux. In: Alferes, J.J.,
Pereira, L.M., Orlowska, E. (eds.) JELIA 1996. LNCS, vol. 1126, pp. 1–17. Springer,
Heidelberg (1996). https://doi.org/10.1007/3-540-61630-6_1
14. Beck, H., Dao-Tran, M., Eiter, T.: LARS: a logic-based framework for analytic
reasoning over streams. Artif. Intell. 261, 16–70 (2018)
15. Drescher, C., Thielscher, M.: Integrating action calculi and description logics. In:
Hertzberg, J., Beetz, M., Englert, R. (eds.) KI 2007. LNCS (LNAI), vol. 4667, pp.
68–83. Springer, Heidelberg (2007). https://doi.org/10.1007/978-3-540-74565-5_8
16. Eiter, T., Ianni, G., Krennwallner, T., Polleres, A.: Rules and ontologies for the
semantic web. In: Baroglio, C., Bonatti, P.A., Małuszyński, J., Marchiori, M.,
Polleres, A., Schaﬀert, S. (eds.) Reasoning Web. LNCS, vol. 5224, pp. 1–53.
Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-540-85658-0_1
17. Eiter, T., Ianni, G., Lukasiewicz, T., Schindlauer, R., Tompits, H.: Combining
answer set programming with description logics for the Semantic Web. Artif. Intell.
172(12), 1495–1539 (2008)
18. Gelfond, M., Lifschitz, V.: Classical negation in logic programs and disjunctive
databases. New Gener. Comput. 9, 365–385 (1991)
19. Giacomo, G.D., Oriol, X., Rosati, R., Savo, D.F.: Instance-level update in DL-lite
ontologies through ﬁrst-order rewriting. J. Artif. Intell. Res. 70, 1335–1371 (2021)
20. Kowalski, R.A., Sergot, M.J.: A logic-based calculus of events. New Gener. Comput.
4(1), 67–95 (1986)
21. Lee, J., Palla, R.: Reformulating the situation calculus and the event calculus in
the general theory of stable models and in answer set programming. J. Artif. Intell.
Res. 43, 571–620 (2012)
22. Leone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., Perri, S., Scarcello, F.: The
DLV system for knowledge representation and reasoning. ACM Trans. Comput.
Logic 7(3), 499–562 (2006)
23. Lin, F.: Situation calculus. In: van Harmelen, F., Lifschitz, V., Porter, B.W. (eds.)
Handbook of Knowledge Representation, Foundations of Artiﬁcial Intelligence, vol.
3, pp. 649–669. Elsevier (2008)
24. Lloyd, J.: Foundations of Logic Programming. Symbolic Computation. Second
extended edn. Springer, Heidelberg (1987). https://doi.org/10.1007/978-3-642-
83189-8
25. Lutz, C.: Description logics with concrete domains - a survey. In: Balbiani, P.,
Suzuki, N., Wolter, F., Zakharyaschev, M. (eds.) Advances in Modal Logic 4,
Papers from the Fourth Conference on “Advances in Modal Logic”, pp. 265–296.
King’s College Publications (2002)
26. Miller, R., Shanahan, M.: Some alternative formulations of the event calculus.
In: Kakas, A.C., Sadri, F. (eds.) Computational Logic: Logic Programming and
Beyond. LNCS (LNAI), vol. 2408, pp. 452–490. Springer, Heidelberg (2002).
https://doi.org/10.1007/3-540-45632-5_17

Combining Event Calculus and Description Logic Reasoning
117
27. Motik, B., Sattler, U., Studer, R.: Query answering for OWL-DL with rules. In:
McIlraith, S.A., Plexousakis, D., van Harmelen, F. (eds.) ISWC 2004. LNCS, vol.
3298, pp. 549–563. Springer, Heidelberg (2004). https://doi.org/10.1007/978-3-
540-30475-3_38
28. Mueller, E.T.: Event calculus reasoning through satisﬁability. J. Logic Comput.
14(5), 703–730 (2004)
29. Özçep, Ö.L., Möller, R., Neuenstadt, C.: A stream-temporal query language for
ontology based data access. In: Lutz, C., Thielscher, M. (eds.) KI 2014. LNCS
(LNAI), vol. 8736, pp. 183–194. Springer, Cham (2014). https://doi.org/10.1007/
978-3-319-11206-0_18
30. Poggi, A., Lembo, D., Calvanese, D., De Giacomo, G., Lenzerini, M., Rosati, R.:
Linking data to ontologies. In: Spaccapietra, S. (ed.) Journal on Data Semantics
X. LNCS, vol. 4900, pp. 133–173. Springer, Heidelberg (2008). https://doi.org/10.
1007/978-3-540-77688-8_5
31. Przymusinski, T.C.: On the declarative and procedural semantics of logic programs.
J. Autom. Reasoning 5(2), 167–205 (1989)
32. Rosati, R.: DL+log: tight integration of description logics and disjunctive datalog.
In: Doherty, P., Mylopoulos, J., Welty, C.A. (eds.) Proceedings, Tenth Interna-
tional Conference on Principles of Knowledge Representation and Reasoning, Lake
District of the United Kingdom, 2–5 June 2006, pp. 68–78. AAAI Press (2006)
33. Sakama, C.: Possible model semantics for disjunctive databases. In: Kim, W.,
Nicholas, J.M., Nishio, S. (eds.) Proceedings First International Conference on
Deductive and Object-Oriented Databases (DOOD-89), pp. 337–351. Elsevier
(1990)
34. Sakama, C., Inoue, K.: An alternative approach to the semantics of disjunctive
logic programs and deductive databases. J. Autom. Reasoning 13, 145–172 (1994)
35. Shanahan, M.: The event calculus explained. In: Wooldridge, M.J., Veloso, M.
(eds.) Artiﬁcial Intelligence Today. LNCS (LNAI), vol. 1600, pp. 409–430. Springer,
Heidelberg (1999). https://doi.org/10.1007/3-540-48317-9_17
36. Tsilionis, E., Artikis, A., Paliouras, G.: Incremental event calculus for run-time rea-
soning. In: Proceedings of the 13th ACM International Conference on Distributed
and Event-Based Systems, DEBS 2019, pp. 79–90. Association for Computing
Machinery, New York (2019)
37. Zaniolo, C.: Expressing and supporting eﬃciently greedy algorithms as locally
stratiﬁed logic programs. In: Technical Communications of ICLP 2015 1433 (01
2015)

Semantic Forgetting in Expressive
Description Logics
Mostafa Sakr(B)
and Renate A. Schmidt
University of Manchester, Manchester, UK
{Mostafa.Sakr,Renate.Schmidt}@manchester.ac.uk
Abstract. Forgetting is an important ontology extraction technology.
We present a semantic forgetting method for ALC ontologies. The method
forgets concept names, and captures the semantic content over the remain-
ing vocabulary of an ontology, possibly, by introducing helper concept
symbols. In an evaluation, the method performed well on large-scale
ontologies when forgetting 10–50% of the vocabulary and the number of
helper symbols occurring in the extracts decreased as the number of for-
getting symbols increased. Against the forgetting tool Fame(Q), good per-
formance was achieved while more semantic content was preserved.
1
Introduction
Ontologies are often large-scale, formalizing several related topics of some domain.
For example, the SNOMED CT ontology contains more than 340K axioms mod-
elled over 361K concept and role names, and formalizes several topics from medical
and biomedical domains such as diseases, symptoms, medicines, procedures, and
organisms. Working with large-scale ontologies is a challenge due to their sheer
size, while in reality, only small extracts are needed. This presses for ontology
extraction methods such as forgetting [7–11,17,18,28].
The aim of forgetting is extracting an ontology, hereafter called a forget-
ting view, that is inseparable from the original ontology in terms of the captured
knowledge relative to some keep vocabulary (the unforgotten subset of the vocab-
ulary of the original ontology) [6,18,19,29]. Forgetting uses reasoning to elimi-
nate, or forget, the unwanted vocabulary and capture the knowledge relative to
the keep vocabulary, possibly by introducing new axioms.
Two diﬀerent languages LV and LC should be diﬀerentiated when considering
forgetting. These are, respectively, the language of the extracted ontology, and
the language of the captured consequences. Diﬀerent forms of forgetting vary on
their choices of LV and LC [6,19]. A variant of particular interest to this paper
is semantic forgetting [25,36–38] in which the meaning of the keep vocabulary is
preserved in the semantic forgetting view. That is, for every model of the original
ontology there is a model of the semantic forgetting view and vice versa, such
that both models interpret the keep vocabulary in the same way. It has been
shown that in this case, both ontologies agree on all second-order consequences
over the keep vocabulary [6,18]. That is, LC is the language of all second-order
consequences of the original ontology relative to the keep vocabulary.
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 118–136, 2021.
https://doi.org/10.1007/978-3-030-86205-3_7

Semantic Forgetting in Expressive Description Logics
119
Despite its high precision, semantic forgetting is not suﬃciently studied in
the literature. In the context of ﬁrst-order logic (FOL), predicate symbols can
be forgotten by quantifying over them [12,25,26]. Since elimination of second-
order quantiﬁers is not always possible [1,13], the generated semantic forgetting
view of a ﬁrst-order theory is not always representable in FOL but it is always
representable in second-order logic. For the ALC fragment of FOL, examples
can be constructed to show that the semantic forgetting view of an ALC ontol-
ogy cannot be represented as a set of ALC axioms formulated over the keep
vocabulary [21]. Attempts were made to formulate the semantic forgetting view
of ALC ontologies using the description logic ALCOQ¬,⊔,⊓[42] which extends
ALC with nominals (O), qualiﬁed number restrictions (Q), role negation (¬),
role disjunction (⊔), and role conjunction (⊓). However, even for acyclic ontolo-
gies, ALCOQ¬,⊔,⊓is not expressive enough to formulate the complete semantic
forgetting view of ALC ontologies over the keep vocabulary. At present, there
are no complete semantic forgetting methods for ALC ontologies.
Taking ideas from [25], we present a complete semantic forgetting method for
the description logic ALC. The method forgets concept names from ALC ontolo-
gies. As in [25], we have the perspective that forgetting symbols are second-order
predicate symbols, and use fresh helper symbols to capture the complete seman-
tic forgetting view. However, we use helper symbols diﬀerently. Whereas [25]
replaces the forgetting symbols with fresh helper symbols, our proposed method
uses them to represent the role ﬁllers in which the forgetting symbols occur.
The idea of our method is to eliminate the forgetting symbols and as many of
the introduced helper symbols as is possible. Eliminating the introduced helper
symbols completely is however not possible in some cases. Thus, in general, the
language LV in which the semantic forgetting view is expressed is the language
of all ALC-axioms formulated over the keep vocabulary augmented with a set of
fresh helper concept symbols. Using helper symbols in this way gives advantages
over [25] in that our method is directly applicable to description logic syntax
and is better tailored towards the purpose of ontology extraction. An advan-
tage of our method over other methods in the literature [12,14,20–22,27,39–43]
is that the semantic forgetting view preserves the form of the input ontology,
thus making it more readable and convenient for ontology development, and
debugging.
The use of helper symbols is debatable since they are second-order. However,
because they are existentially quantiﬁed, and because only ALC constructs are
used to formulate the axioms of the semantic forgetting view, most standard
reasoning tasks, such as satisﬁability checking, classiﬁcation, and query answer-
ing, can be performed on the semantic forgetting view using the standard ALC
tools. Additionally, reduction in complexity of these reasoning tasks is obtained
when the number of the helper symbols is less than the number of symbols being
forgotten. Helper symbols are increasingly being used in diﬀerent applications
to increase the expressive power of the used language [16,20].
Complexity of forgetting is studied in [28] where it is shown that the forget-
ting view of an ALC ontology is in the worst case triple exponential in the size

120
M. Sakr and R. A. Schmidt
of the input ontology. We show that using our method the size of the seman-
tic forgetting view is single exponential in the size of the input ontology and
double exponential in the number of forgetting symbols. This reduction in the
theoretical size complexity can be attributed to the use of helper symbols.1
2
Getting Started
The vocabulary of an ontology consists of concept and role names. Assume they
belong respectively to two disjoint sets Nc and Nr. ALC concepts are deﬁned
inductively by the grammar: C, D := ⊤| ⊥| A | ¬C | C ⊓D | C ⊔D | ∃r.C | ∀r.C
where A ∈Nc and r ∈Nr. An ontology, or TBox, is a set of axioms of the forms
C ⊑D and C ≡D, where C, D are concepts. An equivalence axiom C ≡D is
short-hand for the two subsumption axioms C ⊑D and D ⊑C.
Concepts can be referred to using their position inside the axiom [32]. A
position is a word over natural numbers. Let α = C ⊙D be an ALC axiom where
⊙∈{⊑, ≡}, then the positions of C and D relative to α are 1 and 2 respectively,
in symbols: α|1 = C and α|2 = D. Consider a general ALC concept ψ. Let pos(ψ)
be the set of positions of the sub-concepts occurring in ψ. A sub-concept φ of ψ
is referred to by α|i.π where i is position of ψ relative to the axiom α and
π ∈pos(ψ) is the position of φ relative to ψ. The deﬁnition of pos(ψ) is given
inductively as follows:
1. i.π ∈pos(ψ) if ψ = φ1 ⊙φ2 ⊙· · · ⊙φn where ⊙∈{⊔, ⊓}, π ∈pos(φi) and
1 ≤i ≤n.
2. 1.π ∈pos(ψ) if ψ takes any of the forms: ¬φ, ∃r.φ, or ∀r.φ and π ∈pos(φ).
We write α[ι/ψ] to denote the axiom generated by replacing the sub-concept φ
at position ι relative to α with the concept ψ.
The polarity of a concept occurring at position ι in a subsumption axiom α
is denoted by pol(α, ι), where pol(α, 1) = −1, pol(α, 2) = 1, and:
1. pol(α, i.π) = pol(α, i) if α|i is a conjunction, disjunction, or a concept of the
form ∃r.C or ∀r.C.
2. pol(α, i.π) = −pol(α, i) if α|i is a concept of the form ¬C.
A concept is positive in an axiom if it occurs with polarity 1, and negative if it
occurs with polarity −1.
An interpretation I in ALC is a pair ⟨ΔI, ·I⟩where the domain ΔI is a
nonempty set, and ·I is an interpretation function that assigns to each concept
symbol A ∈Nc a subset of ΔI, and to each r ∈Nr a subset of ΔI × ΔI. ALC
concepts and axioms can be interpreted by translation to FOL [2,15]. First, we
interpret concept and role names respectively as unary and binary predicates in
FOL. Then, we deﬁne two translation functions πx and πy that inductively trans-
late ALC concepts to FOL formulae with the free variable x and y, respectively:
1 Proofs omitted from this paper are available in the long version at https://github.
com/e73898ms/SemanticForgettinginExpressiveDescriptionLogics.

Semantic Forgetting in Expressive Description Logics
121
πx(⊤) = πy(⊤) = TRUE
πx(⊥) = πy(⊥) = FALSE
πx(A) = A(x)
πy(A) = A(y)
πx(¬C) = ¬πx(C)
πy(¬C) = ¬πy(C)
πx(C ⊓D) = πx(C) ∧πx(D)
πy(C ⊓D) = πy(C) ∧πy(D)
πx(C ⊔D) = πx(C) ∨πx(D)
πy(C ⊔D) = πy(C) ∨πy(D)
πx(∃r.C) = ∃y (r(x, y) ∧πy(C))
πy(∃r.C) = ∃x (r(y, x) ∧πx(C))
πx(∀r.C) = ∀y (r(x, y) →πy(C))
πy(∀r.C) = ∀x (r(y, x) →πx(C))
Let C and D be any ALC concepts. Deﬁne the translation function π which
translates axioms to ﬁrst-order formulae with one free variable.
π(C ≡D) = (πx(C) ↔πx(D))
π(C ⊑D) = (πx(C) →πx(D))
An ontology O, or a set of axioms, is translated as:
π(O) =

C≡D∈O
∀x π(C ≡D) ∧

C⊑D∈O
∀x π(C ⊑D)
(1)
In the presented forgetting method we use FOL formulas on the form (1). To
simplify the notation, we allow the conjunction (disjunction) of axioms to mean
the conjunction (disjunction) of their FOL translations:
(C1 ⊑D1) ∧(C2 ⊑D2)
means
π(C1 ⊑D1) ∧π(C2 ⊑D2)
(C1 ⊑D1) ∨(C2 ⊑D2)
means
π(C1 ⊑D1) ∨π(C2 ⊑D2)
Let O be an ontology, and α an axiom. We say α is satisﬁable with respect
to O if there is a model I of O such that I |= α. We say α is a consequence
of O, in symbols, O |= α, if for every model I of O it holds that I |= α.
Let C be an ALC concept, we denote by sig(C) the set of concept and role
names appearing in C. For an ontology O, sig(O) = 
C⊙D∈O sig(C) ∪sig(D),
where ⊙∈{⊑, ≡}. The size of O, in symbols size (O), is the number of axioms
occurring on O.
Deﬁnition 1. Let F be a set of concept names, and I and J two models such
that ΔI = ΔJ . We write I ∼F J if and only if pI = pJ for every concept and
role name, except possibly for p ∈F.
Deﬁnition 2. Let O be an ALC ontology and F ⊆sig(O)∩Nc be the forgetting
signature. We say that the ALC ontology V is a semantic forgetting view of O
w.r.t. F iﬀthe following both hold:
1. sig(V) ⊆sig(O)\F;
2. for every model I of O, there is a model J of V, and vice versa, such that
I ∼F J .
The keep vocabulary is the set of concept and role symbols in sig(O)\F.

122
M. Sakr and R. A. Schmidt
The following example suggests that the semantic view of an ALC ontology
is not in general representable in ALC.
Example 1. Let O = {A ⊑∃r.B ⊓∃r.¬B} and F = {B}. In FOL with Skolem
functions, the semantic forgetting view V of O with respect to F is:
∀x∀y((¬A(x) ∨r(x, f(x))) ∧(¬A(y) ∨r(y, g(y)))∧
(¬A(x) ∨¬A(y) ∨f(x) ̸≈g(y)))
(2)
This was computed with the second-order quantifer elimination method
in [12]. f and g are function symbols introduced by Skolemisation [3,12]
to represent existential quantiﬁcation. Since (2) cannot be back-translated to
FOL without function symbols, representing (2) in the ALC fragment is not
possible [5].
Even the more expressive description logic ALCOQ¬,⊔,⊓is insuﬃcient to capture
the semantic view [42]. The following example illustrates this observation.
Example 2. Consider O and F from Example 1. The forgetting view generated
by the methods [21,42] is V = {A ⊑≥2r.⊤}, which models the information
that every element in A has at least two diﬀerent successors via r. Let I be a
model with domain of interpretation Δ = {a1, a2, a3, b1, b2, b3},
AI = {a1, a2, a3}, and rI = {(a1, b1), (a1, b2), (a2, b1), (a2, b3), (a3, b2), (a3, b3)}.
I is a model of V but there is no extension of I that is a model of O because no
interpretation of B can separate {b1, b2, b3} into two disjoint sets where every
element in A is connected to at least one element from each set.
The proposed method captures the semantic view by relaxing the ﬁrst condi-
tion of Deﬁnition 2 and allowing fresh helper concept symbols to be used in the
semantic forgetting view. Fresh here means that the introduced helper symbols
do not occur in the vocabulary of the original ontology.
Example 3. Consider O and F from Example 1. The ontology V = {A ⊑∃r.D1⊓
∃r.D2, D1 ⊓D2 ⊑⊥} is a semantic forgetting view of O with respect to F where
D1 and D2 are fresh concept symbols.
In the presented method, we use helper symbols to represent role ﬁllers. In
Example 3, D1 and D2 represent two disjoint subsets of the set {y ∈ΔI|(x, y) ∈
rI ∧x ∈AI}, where I is a model of V. Precise interpretations of D1 and D2
cannot be given without knowledge of the forgotten symbol B. So, helper symbols
can be seen as second-order existentially quantiﬁed symbols.
When ontology extraction is required to replace the original ontology with a
smaller one in reasoning applications, these applications are unperturbed if the
extracted ontology contains helper symbols in its vocabulary. This is at least
correct for standard reasoning applications such as classiﬁcation, satisﬁability
checking and query answering. The reasons that the original ontology can be
safely replaced by the semantic forgetting view which uses helper symbols are:

Semantic Forgetting in Expressive Description Logics
123
1. The introduced helper symbols are implicitly existentially quantiﬁed. Thus,
existing inference systems that operate on the original ontology are suﬃcient.
That is, inference systems which allow for universally quantiﬁed symbols are
not needed.
2. Using helper symbols, the semantic forgetting view can be formulated using
ALC syntax. Thus, ALC reasoning methods can operate directly on the
semantic forgetting view.
Let us explain this using a query answering problem. For query answering tasks,
forgetting can be used to replace the original ontology with a simpler forgetting
view such that the vocabulary of the asked queries is a subset of the vocabulary
of the forgetting view [19].
Example 4. Consider the ontology O = {A1 ⊑∀r.B, A2 ⊑∀r.¬B}, and V =
{A1 ⊑∀r.D1, A2 ⊑∀r.D2, D1 ⊓D2 ⊑⊥} which is the semantic forgetting view
with respect to {B} where D1 and D2 are helper symbols. Both ontologies model
the information that the r-successors of the elements in the interpretation of A1
are disjoint from the r-successors of the elements in the interpretation of A2.
Suppose O is used in a Boolean conjunctive query task (O, A) |= r(a2, b) where
A = {A1(a1), A2(a2), r(a1, b)} is a database, and (O, A) is the knowledge-base
consisting of O and A. An answer to this query is yes if (O, A) |= r(a2, b),
and no if (O, A) ̸|= r(a2, b). Evidently, the answer to this query is no, which
can be computed by observing that (O, A) ̸|= r(a2, b) iﬀ(O, A), ¬r(a2, b) ̸|= ⊥.
Replacing O with V, i.e., answering (V, A) |= r(a2, b), yields the same result,
which can also be computed using the satisﬁability checking method used above.
In this computation, full interpretations of the helper symbols are not required.
3
Forgetting Method
We now present a method to compute the semantic forgetting view of ALC
ontologies. The method uses helper symbols to capture the semantic forgetting
view. It proceeds in three stages. The ﬁrst stage iteratively eliminates deﬁned
forgetting symbols. A concept symbol B is deﬁned if an axiom of the form B ≡C
exists, and B ̸∈sig(C). Elimination of B is performed by replacing B everywhere
in the ontology with C. We call this, deﬁnition expansion.
Example 5. Let O = {A ⊑B, B ≡C} and F = {B}. The semantic view of O
with respect to F is V = {A ⊑C} obtained by replacing B by C in O.
The second stage of the method eliminates the remaining forgetting symbols.
Forgetting is deﬁned by an adaptation of the following formula:
Forget(O, B) = O⊤
B ∨O⊥
B
(3)
often attributed to [4]. O⊤
B(O⊥
B) denotes the result of replacing B by ⊤(⊥)
everywhere in O. Applied iteratively, (3) provides a method to forget proposi-
tional variables from propositional theories [24]. It does not, however, extend to

124
M. Sakr and R. A. Schmidt
description logics [8–10,25]. Our method integrates (3) with structural transfor-
mation [32] to perform forgetting for ALC ontologies.
Structural transformation extracts forgetting symbols appearing under role
restriction and exposes them to resolution. Before applying structural transfor-
mation we replace every equivalence axiom C ≡D that contains a forgetting
symbol by the two subsumption axioms C ⊑D and D ⊑C. Structural transfor-
mation is applied as follows:
Deﬁnition 3. Let B be a forgetting symbol and C be a concept such that B ∈
sig(C). We say C is a B-concept if C is on the form of B ⊙E or ¬B ⊙E,
where E is an ALC concept and ⊙∈{⊔, ⊓}.
Deﬁnition 4. Let O be an ontology, B a forgetting symbol, α an axiom in O,
and C = α|ι a concept of the form Qr.E, where E is a B-concept, r is a role
name, Q ∈{∃, ∀}, and C is a concept that occurs in α at position ι. We say α
is structurally transformed when replacing it with axiom α[ι/Qr.D], and adding
the following axiom to the ontology:
def(ι, α, D) =

D ⊑E
if pol(α, ι) = 1;
E ⊑D
if pol(α, ι) = −1,
where D is a fresh concept symbol, i.e., D ̸∈sig(O). We say O is structurally
transformed if the above transformation is applied exhaustively on all axioms
until no forgetting symbol appears under role restriction.
Example 6. Let O = {A ⊑∃r.(B ⊓C), ∃r.B ⊑E, E ⊑¬∃r.F}, and F = {B, F}.
Then O is transformed into {A ⊑∃r.D1, D1 ⊑B ⊓C, ∃r.D2 ⊑E, B ⊑D2, E ⊑
∃r.D3, F ⊑D3} where D1, D2 and D3 are fresh concept symbols.
The concept symbols introduced by structural transformation are called helper
symbols. These must be fresh, i.e., they are not in the vocabulary of the ontology
when they are introduced. We denote by Nh the set of introduced helper symbol.
Lemma 1. Let O1 be an ontology, and O2 the result of applying the above struc-
tural transformation with respect to some forgetting signature F. Let Nh be the
set of introduced helper symbols. Then, for every model I of O1 there is a model
J of O2, and vice versa, such that I ∼Nh J .
Following structural transformation, the forgetting symbols F are forgotten
iteratively using the rules of the calculus given in Fig. 1. In each iteration, the
subset of axioms of the ontology containing the forgetting symbol B is extracted
and viewed as a ﬁrst-order formula φB. The Resolution rule in Fig. 1 is applied
to φB. The rule creates a disjunction of the two ﬁrst-order formulas φ⊤
B and φ⊥
B
where the forgetting symbol is replaced by ⊤and ⊥, respectively. The Normal-
ization and Disjunction Elimination rules eliminate the disjunction between φ⊤
B
and φ⊥
B; thus prepare the result of the Resolution rule to be restored to a set of
DL axioms. The Normalization rule distributes disjunction between φ⊤
B and φ⊥
B

Semantic Forgetting in Expressive Description Logics
125
inwards. The Disjunction Elimination rule then converts the disjunction of two
formulas into a single formula that can be expressed as a DL axiom. In addition
to the rules in Fig. 1, we eagerly eliminate tautologous axioms and formulas.
Resolution (Res)
φB
φ⊤
B ∨φ⊥
B
where φB is a ﬁrst-order formula representing the set of axioms of the ontology
that contain the symbol B.
Normalization (Norm)
(A1
1 ∧· · · ∧A1
n) ∨(A2
1 ∧· · · ∧A2
m)
(A1
1 ∨A2
1) ∧· · · ∧(A1n ∨A2m)
where A1
1, . . . , A1
n, A2
1, . . . , A2
m are formulas.
Disjunction Elimination (DElim)
(C1 ⊑D1) ∨(C2 ⊑D2)
(C1 ⊓C2) ⊑D1 ⊔D2
where C1, D1, C2, and D2 are concepts.
Fig. 1. Forgetting calculus
Deﬁnition 5. An axiom (formula) is a tautology if it takes any of the following
forms: ⊥⊑C (π(⊥⊑C)), C ⊑⊤(π(C ⊑⊤)), and A⊓C ⊑A⊔D, where A, C
and D are general concepts.
A tautologous axiom is eliminated by removing it from the ontology, and a
tautologous formula is eliminated by replacing it with ⊤.
Example 7. Consider the ontology O = {A ⊑∃r.D1, D1 ⊑B ⊓C, ∃r.D2 ⊑
E, B ⊑D2} after structural transformation, and suppose we want to forget B.
φB = (D1 ⊑B ⊓C) ∧(B ⊑D2)
φ⊤
B = (D1 ⊑C) ∧(⊤⊑D2),
φ⊥
B = (D1 ⊑⊥) ∧(⊥⊑D2) ≡D1 ⊑⊥
φ⊤
B ∨φ⊥
B = ((D1 ⊑C) ∧(⊤⊑D2)) ∨(D1 ⊑⊥)
Res
≡((D1 ⊑C) ∨(D1 ⊑⊥)) ∧((⊤⊑D2) ∨(D1 ⊑⊥))
Norm
≡(D1 ⊑C) ∧(D1 ⊑D2)
DElim
The resulting formula is translated to the set of DL axioms {D1 ⊑C, D1 ⊑
D2} and added to the remaining axioms of O. The semantic forgetting view is
therefore V = {A ⊑∃r.D1, ∃r.D2 ⊑E, D1 ⊑C, D1 ⊑D2}.

126
M. Sakr and R. A. Schmidt
Deﬁnition 6. Suppose B is the forgetting symbol. Consider the forgetting rules
in Fig. 1. We say that a rule is sound if and only if for every model I of the
premise there is a model J of the conclusion, and vice versa, such that I ∼B J .
Theorem 1. The rules in Fig. 1 are sound.
Theorem 2. The size of the semantic forgetting view is, in the worst case,
exponential in the size of the original ontology and double exponential in the size
of the forgetting signature.
4
Eliminating Helper Symbols
In the third stage of the method, the goal is to attempt to eliminate the helper
symbols introduced in the vocabulary of the semantic forgetting view. Since it
is not always possible to represent the semantic forgetting view in ALC, com-
plete elimination of helper symbols is not guaranteed. The elimination of helper
symbols is done by reversing the structural transformation process.
Deﬁnition 7. Let D be a helper symbol. We denote by def(D) the set of all
axioms that can be put in the forms D ⊑C or C ⊑D.
Deﬁnition 8. Let D be a helper symbol and consider any α ∈def(D). Then, α
is improper if:
1. α can be put equivalently in the forms D ⊓¯D ⊑C or C ⊑D ⊔¯D for any
¯D ∈Nh where ¯D ̸= D and C is a general ALC concept; or
2. α can be put equivalently in the forms D ⊑C or C ⊑D and Qr.D occurs in
C where Q ∈{∃, ∀}, and r is any role name.
Otherwise, the deﬁnition axiom is proper. def(D) is proper if all axioms α ∈
def(D) are proper, otherwise, def(D) is improper.
Example 8. Let D1 and D2 be two helper symbols. Consider the axioms α1 =
D1 ⊑C, α2 = D1 ⊓D2 ⊑C, α3 = D1 ⊑D2, α4 = ∀r.D1 ⊑D1. The axioms α1 is
a proper axiom of def(D1), and α3 is a proper axiom of def(D1) and def(D2). The
axiom α2 is improper because it satisﬁes the ﬁrst condition of Deﬁnition 8. The
axiom α4 is also improper because it satisﬁes the second condition of Deﬁnition 8.
A helper symbol D for which def(D) is improper cannot be eliminated.
Improper axioms satisfying Deﬁnition 8.8 have been investigated in [33] where it
was shown that eliminating these helper symbols leads to loss of semantic infor-
mation that we want to preserve. Deﬁnition 8.8 is the case when the ontology
contains a cycle over a subset of the forgetting vocabulary. The helper symbol
in this case functions as a witness to the cycle. Eliminating this helper symbol
requires extending the language of the semantic view with ﬁxpoints [20,31,35].
A helper symbol D for which def(D) is proper can be eliminated. The elimina-
tion rules of D are presented in Fig. 2. The NDef and the PDef rules replace the
set def(D) in the ontology with the semantically equivalent conclusion axioms.

Semantic Forgetting in Expressive Description Logics
127
The Negative Ackermann Substitution and the Positive Ackermann Substitution
rules eliminate D using the Ackermann approach [1,34]. The premise C ⊑D
(D ⊑C) of the Positive (Negative) Ackermann Substitution rule is usually the
result generated by the PDef (NDef) rule.
NDef
(D ⊓C1 ⊑E1) ∧· · · ∧(D ⊓Cn ⊑En)
D ⊑((¬C1 ⊔E1) ⊓· · · ⊓(¬Cn ⊔En))
where D is a helper symbol, and the axioms D ⊓Ci ⊑Ei are proper axioms in
def(D) with 1 ≤i ≤n.
PDef
(C1 ⊑D ⊔E1) ∧· · · ∧(Cn ⊑D ⊔En)
((C1 ⊓¬E1) ⊔· · · ⊔(Cn ⊓¬En)) ⊑D
where D is a helper symbol, and the axioms Ci ⊑D ⊔Ei are proper axioms in
def(D) with 1 ≤i ≤n.
Negative Ackermann Substitution (NAck)
O ∪(D ⊑C)
O[D/C]
where D is a helper symbol and may occur in O only positively.
Positive Ackermann Substitution (PAck)
O ∪(C ⊑D)
O[D/C]
where D is a helper symbol and may occur in O only negatively.
Fig. 2. Helper symbol elimination rules
Lemma 2. Let O1 be an ontology and let O2 be the ontology after eliminating
a helper symbol D using the rules in Fig. 2. Then, for every model I of O1 there
is a model J of O2, and vice versa, such that I ∼D J .
Theorem 3. Let O be an ontology, F a forgetting signature, and V be the
semantic forgetting view generated as described in Sects. 3 and 4. For every model
I of O there is a model J of V, and vice versa, such that I ∼F∪Nh J , where
Nh is the set of helper symbols in V.
5
Discussion of the Forgetting Method
The presented forgetting method implicitly views the forgetting symbols as exis-
tentially quantiﬁed second-order symbols. In order to completely eliminate the

128
M. Sakr and R. A. Schmidt
forgetting symbols, the method introduces helper symbols which can also be
seen as existentially quantiﬁed second-order symbols. Therefore, the language of
the generated semantic view can be viewed as a fragment of second-order logic
(SOL). An alternative method [25] which also generates a semantic forgetting
view in SOL is to quantify over the forgetting symbols. Using this approach, the
semantic forgetting view of the ontology O with respect to {B} is ∃¯B O[B/ ¯B],
where O[B/ ¯B] is the result of replacing B by the helper symbol ¯B everywhere
in O. Since ¯B can be renamed to B, this is equivalent to ∃B O. Therefore, a sim-
pler form of the semantic forgetting view generated by [25] is ∃B1∃B2 . . . ∃Bn O
where B1, B2, . . . , Bn are the forgetting symbols.
Our presented method can be seen as a non-trivial extension of the method
in [25], because it introduces further existentially quantiﬁed symbols. Extending
the forgetting method in this way is necessary to make the method suitable for
ontology extraction and applicable to DL syntax.
Example 9. Let O = {A ⊑∃r.(B ⊔C) ⊓∃r.(¬B ⊔¬C)}, and F = {B}. The
semantic forgetting view V1 obtained by quantifying over B is ∃B (A ⊑∃r.(B ⊔
C)⊓∃r.(¬B⊔¬C)). The equivalent semantic forgetting view is V2 = {A ⊑∃r.⊤}
which is generated by our method. In essence, V1 is syntactically the same as O.
So, only quantifying over the forgetting symbol returns the original ontology
and fails to extract the expected ontology. With our method, we can obtain the
expected semantic forgetting view.
The above example shows that the method in [25] is not suitable for ontol-
ogy extraction. To make it suitable to this purpose, augmenting the method
in [25] with a second-order quantiﬁer elimination method such as formula (3) is
required. While second-order quantiﬁer elimination is suﬃcient in the syntax of
FOL [12,13], it is not directly applicable to DL ontologies.
Example 10. Let O = {A ⊑∃r.B ⊓∃r.¬B} and F = {B}. By quantifying
over B, we get the semantic forgetting view V1 = ∃B (A ⊑∃r.B ⊓∃r.¬B)
Applying the calculus in Fig. 1 directly to V1 gives: V2 = {A ⊑∃r.⊤} which is
not the correct semantic forgetting view of O with respect to F. Our method
solves this problem by applying structural transformation prior to the calculus
in Fig. 1. The correct semantic forgetting view generated by our method is {A ⊑
∃r.D1 ⊓∃r.D2, D1 ⊓D2 ⊑⊥}.
6
Preserving Ontology Structure
A common criticism of existing forgetting methods, e.g. [12,20–22,27,39–42], is
that they do not preserve the form of the original ontology. This reduces the
readability of the extracted ontology, and makes it harder for human inspection
and debugging.
Example 11. Let O1 = {A ⊑B ⊓C ⊓D}, O2 = {A ≡B, B ≡C ⊓D}, and O3 =
{∀r.B ⊑C, A ⊑B}. Consider the forgetting signature F = {B}. The forgetting
views with respect to F generated by the methods [20–22,39–42] of O1, O2, and

Semantic Forgetting in Expressive Description Logics
129
O3 respectively are: V1 = {⊤⊑¬A ⊔C, ⊤⊑¬A ⊔D}, V2 = {⊤⊑¬A ⊔C, ⊤⊑
¬A⊔D, ⊤⊑¬C ⊔¬D ⊔A}, and V3 = {⊤⊑C ⊔∃r.¬A}. Our forgetting method
produces: V′
1 = {A ⊑C ⊓D} (instead of V1), V′
2 = {A ≡C ⊓D} (instead of V2),
and V′
3 = {∀r.A ⊑C} (instead of V3).
It may be observed that the forgetting views generated by our method are more
readable and preserve the forms of the original ontologies. They:
1. Reuse concepts of the original ontology: V′
1 consists of one subsumption axiom
which reuses the concept C ⊓D whereas the concept C ⊓D does not occur
in V1.
2. Preserve equivalence axioms: V′
2 consists of one equivalence axiom whereas V2
consists of three subsumption axioms.
3. Preserve position and polarity of concepts: Similar to O3, V′
3 has the universal
quantiﬁer on the left hand side of the output axiom, whereas V3 contains an
existential quantiﬁer on the right hand side of the axiom. In general, axioms
of V1, V2, and V3 appear on the form ⊤⊑E which is not the case for V′
1, V′
2,
and V′
3.
These properties are achieved in the following ways: (1) The initial deﬁnition
expansion step avoids unnecessary conversion of equivalence axioms into sub-
sumption axioms. (2) The forgetting calculus does not require the input axioms
to be transformed to a special normal or clausal form (like other methods [12,20–
22,27,39–42]). For example, while traditional resolution requires the premises in
disjunctive clausal form, we use a non-traditional form of resolution which only
replaces a forgetting symbol with ⊤and ⊥. (3) The Disjunction Elimination rule
reuses the concept expressions of the premise axioms in the generated axiom,
and preserves their position relative to the subsumption operator. (4) Although
eﬀort has been put into eliminating the helper symbols, some helper symbols
may be present in the returned semantic forgetting view only to preserve the
form of the original ontology.
Example 12. Consider the ontology O1 = {∀r.B ⊑∃r.B} and the forgetting
signature F = {B}. The semantic forgetting view of O1 with respect to F
computed by e.g. the method of [42] is V1 = {⊤⊑∃r.⊤}. However, the result
generated by our method is {∀r.D ⊑∃r.D} where D is a helper symbol. The
helper symbol D allows the form of the original ontology to be preserved.
In the next example, we show that even for semantically equivalent ontologies,
the number of helper symbols in the language of the semantic view may diﬀer.
Example 13. Consider the ontology O2 = {⊤⊑∃r.B ⊔∃r.¬B} which is a
syntactic variant of O1 in Example 12. Let F = {B}. The semantic for-
getting view of O2 with respect to F generated by the proposed method is:
V2 = {⊤⊑∃r.D1 ⊔∃r.D2, D1 ⊓D2 ⊑⊥} where D1 and D2 are helper symbols.
Thus, the method uses two helper symbols to represent the semantic forgetting
view instead of one helper symbol as in Example 12. Note that the semantic
forgetting view of O2 generated by [42] is V1 as in Example 12.

130
M. Sakr and R. A. Schmidt
The above examples show that the preservation of the original ontology form
is valued by the proposed method over the elimination of the helper symbols.
This is an advantage of our method over the other methods [12,20–22,39–42] as
it preserves the syntactic modeling choices made in the original ontology. This
is beneﬁcial for domains such as medical ontologies where often strict modelling
guidelines must be followed.
Table 1. Statistics of the used BioPortal ontologies and forgetting signatures.
Maximum Minimum Average Median
Ontology size (axioms)
133290
40
24760
4653
Forgetting signature size (concepts)
36697
1
3526
771
Fig. 3. Chart A: Average execution times (seconds) of the proposed method. Chart B:
Breakdown of the execution time into the time consumed eliminating forgetting sym-
bols and the time consumed eliminating helper symbols. Chart C: Average number of
helper symbols introduced by structural transformation. Chart D: Average number of
helper symbols remaining in the semantic forgetting view.
7
Empirical Evaluation
We conducted experiments on popular ontologies from the NCBO BioPortal
repository [30]. Starting with 40 ontologies, three experiments were run on each
ontology in a total of 120 experiments. The forgetting signatures F1, F2, and F3
of these three experiments respectively were selected such that F1 ⊂F2 ⊂F3.
Statistics about the sizes of the ontologies and forgetting signatures are presented
in Table 1. Each experiment was assigned 2 GB memory and ran on a x64-based
processor Intel(R) Core(TM) i5 CPU @ 2.7 GHz with a 64-bit operating system
(macOS Catalina 10.15.7). Results gathered from the experiments are shown
in Fig. 3. Chart A of Fig. 3 shows the average running time of the experiments
across the three settings of forgetting 10%, 30%, and 50% of the signature. The
chart shows a polynomial increase in the average running times (369, 699, and
1091 s in the 10%, 30%, and 50% settings respectively).
A breakdown of the average running times is shown in Chart B of Fig. 3. The
chart shows the average time consumed for eliminating the forgetting symbols
using the rules in Fig. 1, and the average time consumed for eliminating the
helper symbol using the rules in Fig. 2, relative to the average execution time of

Semantic Forgetting in Expressive Description Logics
131
the whole forgetting process. We found that the time consumed for eliminating
the helper symbols occupied the majority of the time of the whole forgetting
process. However, we noticed a decreasing trend in the time consumed for elimi-
nating the helper symbols. Execution of the rules in Fig. 1 consumed on average
13%, 33%, and 40% of the time of the whole forgetting process in the 10%, 30%,
and 50% settings respectively, whereas execution of the rules in Fig. 2 consumed
on average 87%, 67%, and 60% of the time. This suggests that helper symbols
not only simplify the forgetting method, but also the cost of eliminating them
becomes less signiﬁcant when forgetting large subsets of the vocabulary.
In Chart C of Fig. 3 we measured the trend of introducing helper symbols
by structural transformation. We observed a linear increase in the average num-
ber of introduced helper symbols. On average there were 1530, 2750, and 3708
introduced helper symbols in the 10%, 30%, and 50% settings respectively. This
increase was expected given the increase in the number of forgetting symbols.
We also measured the number of introduced helper symbols as a ratio to the for-
getting signature. On average, the helper symbols introduced by the structural
transformation process were 107%, 56%, and 47% of the forgetting signature in
the 10%, 30%, and 50% settings respectively. We may conclude that a factor of
the downward trend in the time consumed by the elimination of helper symbols
was the relative decrease in the number forgetting symbols which caused new
helper symbols to be introduced.
We observed that in some cases the above factor also reduced the number
of helper symbols that remained in the semantic forgetting view. The following
example shows the idea.
Example 14. Let O = {A1 ⊑C ⊔∃r.B, A2 ⊑∃r.¬B}, F1 = {B}, and F2 =
{B, C}. The semantic forgetting view of O with respect to F1 is V1 = {A1 ⊑
C ⊔∃r.D1, A2 ⊑∃r.D2, D1 ⊓D2 ⊑⊥}. The semantic forgetting view of O with
respect to F2 is V2 = {A2 ⊑∃r.⊤}. The concept name C does not appear under
role restriction in O, and does not lead to introducing a helper symbol. If only B
is forgotten from O, then the helper symbols D1 and D2 appear in the semantic
forgetting view. Forgetting additionally the concept name C prevents D1 and
D2 from occurring in the semantic forgetting view.
The observation illustrated by the example explains Chart D in Fig. 3. Chart D
shows the average number of helper symbols that appeared in the vocabulary
of the ﬁnal forgetting view. While on average 80 helper symbols appeared in
the forgetting views of the 10% setting, on average only 3 and 2 helper symbols
appeared respectively in the forgetting views of the 30% and 50% settings.
Next we compared the performance of our method with the Fame(Q)
tool [43], a Java implementation of the method of [42]. While Fame(Q) does not
produce the complete semantic view (see Example 2), it captures the semantic
information that is representable in ALCOQ¬,⊔,⊓. We tried executing the above
experiments using Fame(Q). However, we observed memory issues in 52 experi-
ments. This happened more often in experiments with large forgetting signatures
and ontologies. Instead we constructed our own ontologies and experiments. The

132
M. Sakr and R. A. Schmidt
ontologies are constructed such that: (1) They are extracted from real life ontolo-
gies; and (2) they model one or several related topics. Construction was done in
the following way: (1) Collect a set of random concept names Σ from the Inter-
linking Ontology for Biological Concepts (IOBC) ontology [23]. (2) Retrieve from
the NCBO Bioportal the related ontologies where the symbols in Σ appeared
more frequently. (3) From the retrieved ontologies, extract and combine into a
single ontology, the subsets of the axioms containing symbols in Σ.
Table 2. Statistics of the constructed ontologies and forgetting signatures.
Maximum Minimum Average Median
Ontology size (axioms)
1422
78
302
201
Forgetting signature size (concepts)
324
1
27
10
Fig. 4. Chart A: Execution time(seconds) comparison with Fame. Chart B: Average
number of helper symbols introduced by structural transformation. Chart C: Average
number of the introduced helper symbols as a ratio to the number of forgetting symbols.
The construction guaranteed that each generated ontology contained infor-
mation that described the concept names (topics) extracted from the IOBC
ontology. Since these concepts were extracted from the same ontology, i.e., the
IOBC ontology, they were semantically related. In total, 28 ontologies were con-
structed using the method described above. In each construction, at least 25%
of the input ontologies were expressed in ALC or a more expressive logic. Next,
we used the constructed ontologies in three diﬀerent experimental settings: Low,
Moderate, and High with a total of 84 experiments. Each setting corresponded
to a diﬀerent choice of the forgetting signature. The Low setting meant that at
least half of the axioms of the ontology contained a forgetting symbol, and the
probability of two forgetting symbols appearing in the same axiom was low. The
Moderate setting meant that all axioms of the ontology contained a forgetting
symbol, and at least one axiom contained two or more forgetting symbols. The
High setting meant that all axioms of the ontology contained a forgetting symbol,
and at least half of the axioms contained two or more forgetting symbols.
The occurrence of several forgetting symbols in the same axiom means axioms
generated from one forgetting round are processed in subsequent rounds, because
each round in the proposed method and Fame(Q) eliminates only one forgetting

Semantic Forgetting in Expressive Description Logics
133
symbol. This made the experiments computationally more challenging for both
methods, and avoided the drawbacks of reducing the size of the input ontologies.
Statistics about the ontologies and the forgetting signatures are presented in
Table 2. Statistics gathered from the experiments are shown in Fig. 4. Chart A
in Fig. 4 compares the average execution times of Fame(Q) and our proposed
method. In general we found the execution time of Fame(Q) stable across the
Low, Moderate, and High settings. The average execution times of Fame(Q) were
12, 14, 13 s respectively in the three settings. In contrast, the time consumed
by our method grew polynomially over the diﬀerent settings. This growth was
expected since more more semantic information was captured by our method
as the forgetting problem becomes harder. Since Fame(Q) is not complete, we
do not see the same increase in the time consumed by Fame(Q). We notice
in the Low and Moderate settings that our method consumed less time than
Fame(Q), which is not expected since it should still preserve more information
than Fame(Q). We found that Fame(Q) used a reasoner to perform some opti-
mizations the output, which resulted in consuming more time than our method.
We measured the number of introduced helper symbols across the three set-
tings in the same way as before. Chart B in Fig. 4 shows an increase in the
number introduced helper symbols as we moved to harder settings. On average,
149, 173, and 223 helper symbols were introduced by structural transformation
in the Low, Moderate, and High settings respectively. This increase was expected
since the number of forgetting symbols increased. However, as shown in Chart C
of Fig. 4, the average number of introduced helper symbols as a ratio to the num-
ber of forgetting symbols decreased as we went to harder settings. This agreed
with the ratios of 107%, 56%, and 47% that were found before when forgetting
was applied directly on the original BioPortal ontologies.
8
Conclusions
We developed a semantic forgetting method for ontologies in the context of the
description logic ALC. Our method captures the semantic forgetting view by
possibly allowing helper symbols in the vocabulary of the generated semantic
view. Although helper symbols can be seen as second-order predicate symbols,
because they are only existentially quantiﬁed, and because only ALC constructs
are used to formulate the axioms of the semantic forgetting view, most standard
reasoning tasks, such as satisﬁability checking, classiﬁcation, and query answer-
ing, can be performed on the semantic forgetting view using the standard ALC
tools. An important feature of our method is that it preserves the syntactic form
of the original ontology, which increases the readability of the semantic view.
Experimental evaluation validated that our method performed well on large-
scale ontologies. The method consumed 6, 11, and 18 min on average to forget
respectively 10%, 30%, and 50% of the vocabulary of a dataset of large-scale
ontologies with on average 25K axioms. The evaluation also showed that the
number of helper symbols that are used in the extracted semantic forgetting
view decreases as the number of forgetting symbols increases. We additionally

134
M. Sakr and R. A. Schmidt
compared our method with Fame(Q), a tool that forgets concept and role names
in ALCOQ¬,⊔,⊓, in three settings of hardness: Low, Moderate, and High. While
Fame(Q) does not capture the complete semantic forgetting view, experiments
showed that our method performed faster in the Low and Moderate settings. In
the High setting, Fame(Q) performed marginally faster than our method.
References
1. Ackermann, W.: Untersuchungen ¨uber das Eliminationsproblem der mathematis-
chen Logik. Math. Ann. 110, 390–413 (1935)
2. Baader, F., Horrocks, I., Sattler, U.: Description logics. In: Handbook of Knowledge
Representation, pp. 135–179. Elsevier, San Diego (2007)
3. Baaz, M., Egly, U., Leitsch, A.: Normal form transformations. In: Handbook of
Automated Reasoning, pp. 275–332. North-Holland (12 2001)
4. Boole, G.: An Investigation of the Laws of Thought: On Which Are Founded the
Mathematical Theories of Logic and Probabilities. Cambridge University Press,
Cambridge (1854)
5. Borgida, A.: On the relative expressiveness of description logics and predicate
logics. Artif. Intell. 82(1–2), 353–367 (1996)
6. Botoeva, E., Konev, B., Lutz, C., Ryzhikov, V., Wolter, F., Zakharyaschev, M.:
Inseparability and conservative extensions of description logic ontologies: A survey.
In: Reasoning Web: Logical Foundation of Knowledge Graph Construction and
Query Answering: 12th International Summer School. pp. 27–89. Springer (2017)
7. Chen, J., Alghamdi, G., Schmidt, R.A., Walther, D., Gao, Y.: Ontology extraction
for large ontologies via modularity and forgetting. In: Proceedings of the 10th
International Conference on Knowledge Capture (K-CAP 2019), pp. 45–52. ACM
(2019)
8. Delgrande, J.: A knowledge level account of forgetting. J. Artif. Intell. Res. 60,
1165–1213 (2017)
9. Delgrande, J.P.: Towards a knowledge level analysis of forgetting. In: Proceedings
of the 14th International Conference on Principles of Knowledge Representation
and Reasoning, pp. 606–609. AAAI Press, Palo Alto (2014)
10. Ditmarsch, H., Herzig, A., Lang, J., Marquis, P.: Introspective forgetting. In: Pro-
ceedings of the 21st Australasian Joint Conference on Artiﬁcial Intelligence. pp.
18–29. Springer (2008). https://doi.org/10.1007/s11229-009-9554-4
11. Eiter, T., Kern-Isberner, G.: A brief survey on forgetting from a knowledge repre-
sentation and reasoning perspective. KI - K¨unstliche Intelligenz 33(1), 9–33 (2019)
12. Gabbay, D.M., Ohlbach, H.J.: Quantiﬁer elimination in second-order predicate
logic. In: Proceedings of the Third International Conference on Principles of Knowl-
edge Representation and Reasoning, pp. 425–435. Morgan Kaufmann, San Mateo
(1992)
13. Gabbay, D.M., Schmidt, R.A., Szalas, A.: Second-Order Quantiﬁer Elimina-
tion: Foundations. College Publications, Computational Aspects and Applications
(2008)
14. Herzig, A., Mengin, J.: Uniform interpolation by resolution in modal logic. In:
H¨olldobler, S., Lutz, C., Wansing, H. (eds.) JELIA 2008. LNCS (LNAI), vol.
5293, pp. 219–231. Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-
540-87803-2 19

Semantic Forgetting in Expressive Description Logics
135
15. Hustadt, U., Schmidt, R.A., Georgieva, L.: A survey of decidable ﬁrst-order frag-
ments and description logics. J. Relat. Methods Comput. Sci. 1, 251–276 (2004)
16. Jung, J., Lutz, C., Pulcini, H., Wolter, F.: Logical separability of incomplete data
under ontologies. In: 17th International Conference on Principles of Knowledge
Representation and Reasoning, pp. 517–528 (2020)
17. Konev, B., Lutz, C., Walther, D., Wolter, F.: Formal properties of modularisation.
In: Stuckenschmidt, H., Parent, C., Spaccapietra, S. (eds.) Modular Ontologies.
LNCS, vol. 5445, pp. 25–66. Springer, Heidelberg (2009). https://doi.org/10.1007/
978-3-642-01907-4 3
18. Konev, B., Lutz, C., Walther, D., Wolter, F.: Model-theoretic inseparability and
modularity of description logic ontologies. Artif. Intell. 203, 66–103 (2013)
19. Konev, B., Walther, D., Wolter, F.: Forgetting and uniform interpolation in large-
scale description logic terminologies. In: Proceedings of the 21st International Joint
Conference on Artiﬁcial Intelligence, pp. 830–835. Morgan Kaufmann (2009)
20. Koopmann, P., Schmidt, R.A.: Uniform interpolation of ALC-ontologies using ﬁx-
points. In: Fontaine, P., Ringeissen, C., Schmidt, R.A. (eds.) FroCoS 2013. LNCS
(LNAI), vol. 8152, pp. 87–102. Springer, Heidelberg (2013). https://doi.org/10.
1007/978-3-642-40885-4 7
21. Koopmann, P., Schmidt, R.A.: Count and forget: uniform interpolation of SHQ-
ontologies. In: Automated Reasoning. Lecture Notes in Artiﬁcial Intelligence,
vol. 8562, pp. 434–448. Springer, Berlin (2014). https://doi.org/10.1007/3-540-
45470-5
22. Koopmann, P., Schmidt, R.A.: Saturation-based forgetting in the description logic
SIF. In: Proceedings of the 28th International Workshop on Description Logics,
vol. 1350. CEUR-WS.org (2015)
23. Kushida, T., Kozaki, K., Kawamura, T., Tateisi, Y., Yamamoto, Y., Takagi, T.:
Interconnection of biological knowledge using NikkajiRDF and interlinking ontol-
ogy for biological concepts. New Gen. Compu. 37, 1–25 (2019)
24. Lang, J., Liberatore, P., Marquis, P.: Propositional independence: formula-variable
independence and forgetting. J. Artif. Intell. Res. 18, 391–443 (2003)
25. Lin, F., Reiter, R.: Forget it!. Proc. AAAI 1994, 154–159 (1994)
26. Lin, F., Reiter, R.: How to progress a database (and why) I. logical foundations.
In: Principles of Knowledge Representation and Reasoning, pp. 425–436. Morgan
Kaufmann, Cambridge (1994)
27. Ludwig, M., Konev, B.: Towards practical uniform interpolation and forgetting for
ALC tboxes. In: Proceedings of the 26th International Workshop on Description
Logics. CEUR-WS (2013)
28. Lutz, C., Wolter, F.: Foundations for uniform interpolation and forgetting in
expressive description logics. In: IJCAI International Joint Conference on Arti-
ﬁcial Intelligence. AAAI Press (2011)
29. Lutz, C., Wolter, F.: Deciding inseparability and conservative extensions in the
description logic EL. J. Symbol. Comput. 45, 194–228 (2010)
30. Matentzoglu, N., Bail, S., Parsia, B.: A snapshot of the OWL web. In: The Semantic
Web - ISWC 2013, pp. 331–346. Springer (2013)
31. Nonnengart, A., Szalas, A.: A ﬁxpoint approach to second-order quantiﬁer elimi-
nation with applications to correspondence theory. In: Orlowska, E. (ed.) Logic at
Work: Essays Dedicated to the Memory of Helena Rasiowa (1999) vol. 24, January
1998
32. Nonnengart, A., Weidenbach, C.: Computing small clause normal forms. In: Hand-
book of Automated Reasoning, pp. 335–367. North-Holland, Amsterdam (2001)

136
M. Sakr and R. A. Schmidt
33. Sakr, M., Schmidt, R.A.: Fine-grained forgetting for the description logic ALC
(2021). http://www.cs.man.ac.uk/∼schmidt/publications/SakrSchmidt21a.pdf.
34. Schmidt, R.A.: The Ackermann approach for modal logic, correspondence theory
and second-order reduction. J. Appl. Logic 10(1), 52–74 (2012)
35. Tarski, A.: A lattice-theoretical ﬁxpoint theorem and its applications. Pacif. J.
Math. 5(2), 285–309 (1955)
36. Wernhard, C.: Projection and scope-determined circumscription. J. Symbol. Com-
put. 47, 1089–1108 (2012)
37. Wernhard, C.: Application patterns of projection/forgetting. In: Workshop on
Interpolation: From Proofs to Applications (iPRA 2014) (2014)
38. Zhang, Y., Zhou, Y.: Forgetting revisited. In: Twelfth International Conference on
the Principles of Knowledge Representation and Reasoning (2010)
39. Zhao, Y., Schmidt, R.A.: Concept forgetting in ALCOI-ontologies using an Acker-
mann approach. In: The Semantic Web, 14th International Semantic Web Confer-
ence. Lecture Notes in Computer Science, vol. 9366, pp. 587–602. Springer (2015).
https://doi.org/10.1007/b102467
40. Zhao,
Y.,
Schmidt,
R.A.:
Forgetting
concept
and
role
symbols
in
ALCOIHµ+(∇, ⊓)-ontologies. In: Proceedings of the Twenty-Fifth International
Joint Conference on Artiﬁcial Intelligence, pp. 1345–1352. AAAI Press/IJCAI
(2016)
41. Zhao, Y., Schmidt, R.A.: Role forgetting for ALCOQH(∇)-ontologies using an
Ackermann approach. In: Proceedings of the Twenty-Sixth International Joint
Conference on Artiﬁcial Intelligence, pp. 1354–1361. AAAI Press/IJCAI (2017)
42. Zhao, Y., Schmidt, R.A.: On concept forgetting in description logics with qualiﬁed
number restrictions. In: Proceedings of the Twenty-Seventh International Joint
Conference on Artiﬁcial Intelligence, pp. 1984–1990. AAAI Press/IJCAI (2018)
43. Zhao, Y., Schmidt, R.A.: FAME(Q): an automated tool for forgetting in description
logics with qualiﬁed number restrictions. In: Fontaine, P. (ed.) CADE 2019. LNCS
(LNAI), vol. 11716, pp. 568–579. Springer, Cham (2019). https://doi.org/10.1007/
978-3-030-29436-6 34

Interactive Theorem Proving

Improving Automation for Higher-Order
Proof Steps
Antoine Defourné(B)
Université de Lorraine, CNRS, Inria, LORIA, Nancy, France
antoine.defourne@inria.fr
Abstract. We have extended the TLA+ proof system TLAPS with
a new backend to improve the automation of proof steps that involve
higher-order reasoning. The current support for such steps is poor, requir-
ing the user to break down proofs into unnecessarily small steps. We
deﬁned a translation from TLA+ to THF, the TPTP dialect for higher-
order logic, and evaluated several higher-order solvers on proof obliga-
tions generated from the standard library of TLA+. Our results demon-
strate that the solvers are able to handle much coarser proof steps than
the other strategies provided by TLAPS, reducing the amount of neces-
sary user interactions by a signiﬁcant margin.
Keywords: Automated deduction · Higher-order theorem proving ·
TLA+ · TLAPS
1
Introduction
TLA+ is a speciﬁcation language for modelling and expressing properties of dis-
tributed systems [10]. Its core logic is the Temporal Logic of Actions (TLA) with
the operators and axioms of ZF set theory. The language admits a syntax for
expressing theorems and proofs in the hierarchical style of Leslie Lamport [9].
These proofs are treated by the TLA+ Proof System (TLAPS) tool, which dis-
patches the proof obligations it generates to an array of external solvers, among
which there are Isabelle, Zenon, and SMT solvers such as Z3 and CVC4 [6].
This article is about a particular problem that impacts the experience of
TLAPS users when writing proofs for TLA+. The language is often categorized
as a ﬁrst-order logic, but in the context of TLAPS, there are situations in which
a proof obligation cannot be directly expressed without second-order features.
More precisely, a lemma can be parameterized by a ﬁrst-order operator; when
such a lemma is invoked as part of a proof, a second-order uniﬁcation is necessary.
To dispatch obligations to the available backends, TLAPS uses encodings which
were almost all designed with ﬁrst-order logic as a target language. The exception
is Isabelle, which means only this solver is currently invoked on the higher-order
obligations of TLA+.
Although such higher-order obligations are not the primary kind of obliga-
tions one encounters in TLAPS, they are mandatory in some contexts, notably
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 139–153, 2021.
https://doi.org/10.1007/978-3-030-86205-3_8

140
A. Defourné
when any form of reasoning by induction is involved. The current support of
these obligations by TLAPS is poor: the generic tactics of Isabelle are often
unable to handle mildly complex obligations, which forces the user to break
down its proofs into smaller steps until they are simple enough for Isabelle. This
is a time-consuming process that we want to avoid.
We saw this issue as an opportunity to experiment with a higher-order solver
on some TLA+ proofs. Zipperposition was our initial choice for this experiment.
It is a superposition theorem prover for ﬁrst-order logic with equality and the-
ories, recently extended with support for higher-order logic [3,16,17], and the
winner of the 10th CASC competition (2020) in the THF category [14]. Our main
contribution is the implementation of a translation from TLA+ to THF, and the
integration of Zipperposition as a new backend for TLAPS. In this article, we
also consider other solvers that performed well in the THF division of CASC:
Satallax [5], Leo-III [13], Vampire [4] and CVC4 [2]. We evaluate these solvers
along with Zipperposition on the same THF problems that TLAPS generates.
The rest of this paper is outlined as follows: in Sect. 2, we present a TLA+
proof that illustrates the problem in more details; in Sect. 3, we present the
relevant aspects of the encoding into THF that was implemented; in Sect. 4, we
evaluate the solvers and measure how much proof steps we can remove from the
original proofs, compared to what is possible with only Isabelle.
2
The Diﬃculty of Second-Order Proofs in TLA+
The diﬃculties we are interested in arise mostly when dealing with induction in
some way. Our example is about deﬁning an operator by recursion in TLA+. We
deﬁne the operator Sum to represent ﬁnite sums over series. The term Sum(n, S)
represents n
i=1 S(i), where S is any TLA+ ﬁrst-order operator. The standard
library provides a module NaturalsInduction with facilities to deal with such deﬁ-
nitions, and a guideline example. Following these guidelines, this is the deﬁnition
we obtain:
sumF(S(_)) ==
LET sumRec[ m ∈Nat ] ==
IF m = 0 THEN 0 ELSE S(m) + sumRec[m - 1]
IN
sumRec
Sum(n, S(_)) == sumF(S)[n]
Before this deﬁnition can be used, a few lemmas need to be proven. The ﬁrst
lemma expresses the fact that a recursive function that matches the deﬁnition
does exist:
THEOREM SumDefConclusion ==
ASSUME NEW S(_)
PROVE NatInductiveDefConclusion(sumF(S), 0, LAMBDA v,n : S(n) + v)

Improving Automation for Higher-Order Proof Steps
141
TLA+ theorems are typically expressed in this manner. The keyword
“Assume” precedes a list of declarations and hypotheses, separated by com-
mas. Declarations are introduced by “New”, here the only declaration is of an
operator S. The keyword “Prove” precedes the actual goal. The content of
NatInductiveDefConclusion and the proof of this lemma (omitted here) are not
relevant to us. The next lemma reads:
THEOREM SumDef ==
ASSUME NEW S(_), NEW n ∈Nat
PROVE Sum(n, S) = IF n = 0 THEN 0 ELSE S(n) + Sum(n - 1, S)
BY SumDefConclusion DEF NatInductiveDefConclusion, Sum
This time we have included the proof, which consists of a single line. The
keyword “By” is followed by a list of proven facts to be invoked as hypotheses.
“Def” is followed by a list of deﬁned identiﬁers to expand (by default, operators
declared at the top level are not expanded). Here it suﬃces to invoke the previous
lemma, SumDefConclusion, and expand two deﬁnitions. As SumDefConclusion is
parameterized by an operator S, the resulting obligation for SumDef is higher-
order. Unfortunately, Isabelle is unable to solve it.
Inspecting the obligation, we notice that two higher-order instantiations are
in fact needed: one for the lemma, the other to instantiate an axiom schema
regarding functional application. The usual way to go around such issues is to
make an intermediate step to isolate each diﬃcult instantiation:
THEOREM SumDef ==
ASSUME NEW S(_),
NEW n ∈Nat
PROVE Sum(n, S) = IF n = 0 THEN 0 ELSE S(n) + Sum(n - 1, S)
<1>1 NatInductiveDefConclusion(sumF(S), 0, LAMBDA v,m : S(m) + v)
BY SumDefConclusion
<1> QED
BY <1>1 DEF NatInductiveDefConclusion, Sum
We have replaced the single-line proof by a two-steps proof. The intermediary
step is labelled “<1>1”, the last step’s goal is necessarily “QED” to refer to the
main goal. Each step must be justiﬁed by its own proof. Note that step <1>1 is
invoked as a proved fact for the last step. This time, Isabelle manages to solve
<1>1, but the ﬁnal step is still too diﬃcult. A potential reason for this is that
the required instance, sum(S), is too complex a term. We rearrange the proof
so that this term is a constant instead, inserting yet another step plus a local
deﬁnition. This time, Isabelle ﬁnishes the proof:
THEOREM SumDef ==
ASSUME NEW S(_),
NEW n ∈Nat
PROVE Sum(n, S) = IF n = 0 THEN 0 ELSE S(n) + Sum(n - 1, S)
<1> DEFINE f == sumF(S)
<1>1 SUFFICES f[n] = IF n = 0 THEN 0 ELSE S(n) + f[n - 1]
BY DEF Sum
<1>2 NatInductiveDefConclusion(f, 0, LAMBDA v,m : S(m) + v)

142
A. Defourné
BY SumDefConclusion
<1> HIDE DEF f
<1> QED
BY <1>2 DEF NatInductiveDefConclusion
The line starting with “Define” is not an intermediary step, but a local def-
inition. Operators declared locally are expanded by default. This is why we also
insert the other special line starting with “Hide Def”: this command makes the
operator opaque for the rest of the proof. The new step <1>1 is an intermediary
step that starts with the keyword “Suffices”. Such steps are used for backward
reasoning: instead of proving a new fact, they prove that the current goal can
be reformulated.
Not only have we gone from a single-line proof to an over-detailed script,
we have also lost time ﬁguring out what made the obligations too complex for
Isabelle, and trying diﬀerent ways to formulate the proof.
Proofs such as this one are typical of the diﬃcult higher-order obligations of
TLAPS. Working on these, the user is essentially wasting time trying to ﬁnd a
formulation that accommodates the solvers. This very case is especially prob-
lematic, since it was written in accordance with the guidelines provided at the
bottom of the module NaturalsInduction—thus it is representative of TLAPS
proofs. It would be desirable that the ﬁrst version, a single-line proof, be han-
dled by TLAPS, and after adding support for Zipperposition we found that the
new backend could solve it. Before we develop on the performances of Zipper-
position and other higher-order solvers, let us detail how the encoding to THF
was implemented.
3
The Encoding of TLA+ into THF
3.1
Overview
Each TLA+ obligation must be encoded into the input language of the relevant
backends. We encode the obligations into THF, the component of the TPTP
standard for representing problems of higher-order logic.
We ignore the temporal aspects of the logic and view TLA+ as an untyped
second-order logic with a standard theory on top (of sets, arithmetic, etc.) [10].
The only logical aspect of TLA+ that sets it apart from traditional logic is
the absence of the term/formula distinction. This will be discussed in the next
subsection. Although the implementation is new, it is largely inspired by the
SMT encoding of TLAPS [15].
The encoding of TLA+ consists in the following sequence of steps:
1. Disambiguate expressions. This is where the usual distinction between terms
and formulas is recovered.
2. Apply some elementary simpliﬁcations. Syntactic sugar is removed. Some
rewritings are applied to accommodate solvers.

Improving Automation for Higher-Order Proof Steps
143
3. Standardize expressions. This step only serves a technical purpose. It consists
in changing the internal representation of TLA+ primitives. These primitive
constructs are rewritten as ﬁrst- or second-order applications. For instance,
the expression {x ∈S : P(x)} is rewritten as SetSt(S, λx. P(x)), where SetSt
is a new operator.
4. Complement the problem with the necessary axioms. This eﬀectively makes the
operators added during the previous step behave like the original constructs.
For instance, the axiom of set comprehension will be added to specify SetSt.
Only the axioms that specify the operators that occur in the obligation are
included.
5. Translate the problem into THF. At this point the obligation has been pro-
cessed enough so that the translation can be direct.
In the next subsections, we give relevant details about the encoding, covering
mostly the steps 1 and 2 of this overview.
3.2
Recovering Formulas
First-order logic, even monosorted, still makes a distinction between terms and
formulas—we can characterize them with the respective sorts ι and o. The logic of
TLA+ can be largely derived from traditional logic, but the distinction between
term and formula is absent. All TLA+ expressions belong to the same sort ι,
even those that look like formulas.
An important consequence is that any expression can occur in a context where
a formula would normally be expected. The expression “2 ⇒¬5” is legitimate
in TLA+. As a particular case, any expression can be treated as a statement; it
is allowed to ask if “1 + 1” is true or false, for example. The problem arises more
commonly with statements of this kind:
ASSUME NEW P(_),
NEW a
PROVE P(a) => P(a)
In the absence of any syntactic indication, P cannot be assumed to denote a
predicate, even though it can be treated like one in the goal.
In the very ﬁrst phase of the encoding, expressions are transformed so that
the usual distinction between ι and o is recovered. To deﬁne this mapping we
need some understanding of the semantics of TLA+, which are described in [10,
sec. 16.1.3]. TLAPS follows the so-called liberal interpretation of TLA+, which
can be summarized as follows: if some e occurs in a boolean context (i.e. it
must be evaluated as a formula), then it is treated as e = ⊤. For instance, the
expression “2 ⇒¬5” is interpreted like “(2 = ⊤) ⇒¬(5 = ⊤)”, which happens
to be provable by 2 ̸= 5. The last example becomes:
ASSUME NEW P(_),
NEW a
PROVE ( P(a) = TRUE ) => ( P(a) = TRUE )

144
A. Defourné
This principle is implemented by the mappings [·]f and [·]t, deﬁned below.
The target language is ﬁrst-order logic with the sorts ι and o. Two operators
are introduced by this mapping: from_bool and tt. The former is an injector
of o into ι. The latter is the counterpart of ⊤in the domain of ι—it is needed
because ⊤is treated as a o in the target language, so rewriting e as “e = ⊤”
would result in an equality between a ι and a o.
The functions [·]f and [·]t map expressions of TLA+ to formulas and terms
(respectively) of ﬁrst-order logic. Variables are denoted by x, operators are
denoted by k.
[⊥]f ≜⊥
[x]t ≜x
[e1 ⇒e2]f ≜[e1]f ⇒[e2]f
[k(e1, . . . , en)]t ≜k([e1]t , . . . , [en]t)
[∀x. e]f ≜∀x. [e]f
[e]t ≜from_bool([e]f)
[e1 = e2]f ≜[e1]t = [e2]t
[e]f ≜[e]t = tt
The rules that introduce from_bool and tt are the ones that convert terms
and formulas into each other. These conversions rules are applied with lowest
priority. The actual implementation also accounts for second-order applications;
operator arguments are expected to take inputs from ι and return values from ι.
Some optimizations are applied: set membership is speciﬁed to be a predicate
in TLA+, so ∈is given a predicate type and no conversion is applied on mem-
bership statements; some constructs expect a predicate argument, for example
in “{x ∈S : P(x)}”, the function [·]f is called on “P(x)”.
The mapping [·]f is sound in the sense that if [e]f is valid in FOL, then e is
valid in TLA+. The mapping is made complete by enforcing the interpretations
of the new operators in the target language. This is done by adding a single
axiom to the problem:
from_bool(⊤) = tt ∧from_bool(⊥) ̸= tt
(B)
To summarize: for all TLA+ expression e, e is valid iﬀ[e]f is satisﬁed by all
models of (B) in FOL. The encoding applies [·]f to all top expressions and adds
the axiom (B) to the problem.
3.3
Arithmetic
TLA+ admits a number of primitive operators and axioms, which constitute its
standard theory. The main components of this theory are: set theory, functions,
and arithmetic. Our encoding simply makes the necessary standard declara-
tions and axioms explicit in the ﬁnal THF problem, but arithmetic is treated
diﬀerently.

Improving Automation for Higher-Order Proof Steps
145
The SMT encoding uses special axioms that make use of the sort Int of SMT-
LIB. That way, specialized reasoning implemented by the solvers for arithmetic
can be leveraged. But the version of Zipperposition that supports higher-order
reasoning does not also support arithmetic, so it is not possible to replicate the
method of the SMT encoding.
However, the purpose of using a higher-order solver for TLA+ is not to solve
arithmetical goals. The encoding must only be complete enough for goals that
involve higher-order reasoning. Therefore, the theory of arithmetic is discarded
for our needs; the encoding merely declares the operators it needs, giving them
a generic type according to their arities. That includes declaring constants for
each literal number that occurs in the obligation.
We don’t expect users to invoke the new backend for obligations that require
arithmetical reasoning. However, we inspected goals that Zipperposition would
not solve and found that simple arithmetical checks were often mandatory.
Checking that some value is a member of Int or Nat is a common case. We
chose a few axioms to include in the problem so that these checks can be made
and more goals can be proven. Here are the axioms we include in the THF ﬁle:
Typing axioms. Each literal number (constant that identiﬁes a number) is
speciﬁed to be a member of the set of integers:
0 ∈Int
1 ∈Int
2 ∈Int
· · ·
There is a typing axiom for almost all arithmetical operators, for instance:
∀z1, z2 ∈Int. (z1 + z2) ∈Int
Comparisons to 0. In complement to the typing axioms, we add an axiom for
each literal number:
z ≤0
if z is negative
0 ≤z
if z is positive
Only the operator for ≤is declared in the THF ﬁle. The other comparisons ≥,
< and > are rewritten so that only ≤occurs during the simpliﬁcation phase.
This is sound with respects to TLA+ semantics, as these operators are deﬁned
from each other this way, even for non-integer values.
Distinct literals. For every two distinct literals z1 and z2 that we declare, we
add the axiom:
z1 ̸= z2
3.4
Set Extensionality
Past experiences with the SMT encoding of TLA+ showed that encoding set
extensionality by including the axiom hardly ever worked, as it is diﬃcult to
determine how this axiom should be instantiated in practice. We followed the
example of SMT and omitted the axiom of set extensionality. However, while

146
A. Defourné
experimenting with our encoding we found that some obligations required set
extensionality to be solved. In order to solve more goals, we decided to partially
support the axiom by applying simple rewritings.
The axiom states
∀x, y. (∀z. z ∈x ⇔z ∈y) ⇒x = y
The converse implication is trivially true, so we may apply the axiom as the
following rewriting rule:
x = y −→∀z. z ∈x ⇔z ∈y
We determine which equalities are rewritten using polarities. A polarity can be
attributed to every subexpression of an expression: the top expression is positive;
the polarity is reversed by negation, or by implication for the left member. It is
only necessary to rewrite the positive equalities in a goal. These are the equalities
that need to be justiﬁed, while the negative ones serve as hypotheses and lead
to substitutions. For instance, in the goal
∀x, y. {x, y} = {y, x}
the equality occurs neither under a negation nor on the left of an implication,
so the rewrite rule is applied. However, in the goal
∀x, y. x = ∅⇒y /∈x
the equality occurs on the left of an implication. No rewriting is applied: the
goal is proven by substituting ∅for x on the right.
TLA+ is untyped and considers any object to be a set. That means set
extensionality is always applicable, and the rewriting rule is sound in every
context. But we would not want to rewrite an equality like “0 = 1”, for instance.
The rule is restricted to cases where one of the members of the equality is built
from a set-theoretical primitive (set enumeration, set comprehension, etc.)
This approach is obviously incomplete. Set extensionality may be needed
while there is not an equality to rewrite in the goal. For example, this goal
cannot be proven with our method:
ASSUME NEW F(_), NEW S
PROVE F(S \cup {}) = F(S)
Our treatments of set extensionality and arithmetic are the prime sources of
incompleteness in the encoding. We do not see this as a problem in the case of
arithmetic, as this backend is not intended to be called on arithmetical goals.
The lack of a complete support for set extensionality is more often a problem,
as it can be natural to write goals that require it when reasoning in terms of set.
4
Evaluation
4.1
Proof Simpliﬁcation
Having deﬁned and implemented an encoding of TLA+ into THF, we now turn
to the evaluation of the higher-order solvers. The purpose of this evaluation is

Improving Automation for Higher-Order Proof Steps
147
to show that proofs can be written with less details using a higher-order solver,
compared to what is currently possible with only Isabelle. Our method consists in
evaluating the solvers on simpler versions of existing proofs. Here by “simpler” we
mean: proofs carried out in fewer steps. As the proofs get simpler, the resulting
obligations must get more complex for the backends.
The general method we applied to evaluate a given solver can be outlined as
follows:
1. Select speciﬁcations that feature higher-order obligations and identify said
obligations;
2. Test the higher-order solver on those obligations, and the surrounding obli-
gations as well;
3. Simplify proofs by merging proof steps around the relevant obligations;
4. Evaluate the solver and Isabelle on the new obligations—we are mostly inter-
ested in the number of goals that are uniquely handled by the higher-order
solver.
The speciﬁcations were selected from the standard library of TLA+. An obli-
gation was considered higher-order if it featured one fact that is parameterized
by an operator (proving it requires higher-order uniﬁcation). Before we show the
results, let us brieﬂy explain how step 4.1 was carried out.
Consider the following proof:
THEOREM TailInductiveDef ==
ASSUME NEW S, NEW Def(_,_), NEW f, NEW f0,
TailInductiveDefHypothesis(f, S, f0, Def)
PROVE TailInductiveDefConclusion(f, S, f0, Def)
<1>. DEFINE Op(h,s) == IF s = <<>> THEN f0 ELSE Def(h[Tail(s)], s)
<1>1. StrictSuﬃxesDetermineDef(S, Op)
(* ... *)
<1>2. OpDeﬁnesFcn(f, Seq(S), Op)
BY DEF OpDeﬁnesFcn, TailInductiveDefHypothesis
<1>3. WFInductiveDeﬁnes(f, Seq(S), Op)
BY <1>1, <1>2, SuﬃxRecursiveSequenceFunctionDef
<1>. QED
BY <1>3 DEF WFInductiveDeﬁnes, TailInductiveDefConclusion
The higher-order step here is <1>3. Indeed, the statement of SuﬃxRecursiveSe-
quenceFunctionDef is:
THEOREM SuﬃxRecursiveSequenceFunctionDef ==
ASSUME NEW S, NEW Def(_,_), NEW f,
StrictSuﬃxesDetermineDef(S, Def),
OpDeﬁnesFcn(f, Seq(S), Def)
PROVE WFInductiveDeﬁnes(f, Seq(S), Def)
The lemma is parameterized by an operator Def(_, _), which makes the obli-
gation associated to <1>3 higher-order. Zipperposition was able to solve that
obligation. To ﬁnd potential simpliﬁcations, we test the solver on the surround-
ing obligations.

148
A. Defourné
Let us assume Zipperposition was able to solve step <1>2 and the QED step,
but not <1>1. We can merge <1>3 with <1>2 because the latter is referenced in
the proof of the former. We can also merge <1>3 with the QED step, for the
same reason. Merging proofs amounts to merging their lists of invoked facts and
deﬁnitions. After simpliﬁcation, the result is:
THEOREM TailInductiveDef ==
ASSUME NEW S, NEW Def(_,_), NEW f, NEW f0,
TailInductiveDefHypothesis(f, S, f0, Def)
PROVE TailInductiveDefConclusion(f, S, f0, Def)
<1>. DEFINE Op(h,s) == IF s = <<>> THEN f0 ELSE Def(h[Tail(s)], s)
<1>1. StrictSuﬃxesDetermineDef(S, Op)
(* ... *)
<1>. QED
BY <1>1, SuﬃxRecursiveSequenceFunctionDef
DEF OpDeﬁnesFcn, TailInductiveDefHypothesis,
WFInductiveDeﬁnes, TailInductiveDefConclusion
The new step still contains a reference to <1>1. As Zipperposition was not able
to solve this step, it would necessary fail if we merged QED with <1>1, so we
stop here. The new proof is 2 steps shorter than the original one, so we measure
that simpliﬁcation by “2 steps”. We took Zipperposition as an example, but the
same process must be carried out for every solver, resulting in several simpliﬁed
versions of each speciﬁcation.
Other simpliﬁcations may be applied in particular cases. Some proofs may
include inline facts to prove instead of a reference to a lemma or proof step. The
proof
<1> Cardinality(x \cup {}) = Cardinality(x)
BY x \cup {} = x, SomeLemma DEF SomeDef
is equivalent to
<1>1 x \cup {} = x
OBVIOUS
<1> Cardinality(x \cup {}) = Cardinality(x)
BY <1>1, SomeLemma DEF SomeDef
So the removal of “ ” counts as simpliﬁcation by one step.
It is also common to ﬁnd local deﬁnitions made opaque for a proof step in
order to facilitate uniﬁcation:
<1> DEFINE P(n) == (* ... *)
(* ... *)
<1> HIDE DEF P
<1> ∀n ∈Nat : P(n)
BY <1>1, <1>2, NatInduction
We counted as simpliﬁcation by one step the removal of the Hide command.
Removing this line equates to removing the local deﬁnition itself, since such a
deﬁnition is expanded by default.

Improving Automation for Higher-Order Proof Steps
149
Table 1. Proof obligations solved by each solver in original speciﬁcations
Speciﬁcation
# Solved higher-order obligations
Out of CVC4 Leo-III Satallax Vampire Zip.
SequenceOpTheorems 18
10
8
10
10
12
FiniteSetTheorems
9
7
0
8
8
8
FunctionTheorems
4
2
1
2
2
3
WellFoundedInduction 8
3
2
4
3
3
Total
39
22
11
24
23
26
4.2
Results
We used TLAPS to generate the necessary Isabelle and THF ﬁles from the
TLA+ speciﬁcations, and then evaluated the backends on these problem ﬁles.
Isabelle was always tested with the three tactics available in TLAPS: auto, blast
and force. The higher-order solvers were evaluated on the same TPTP ﬁles. All
solvers were run with a timeout of 30 s, the default conﬁguration for the Isabelle
backend. The experiment was carried out with an Intel Core i7-8650U with 4
cores at 1.90 GHz and 16 GB of RAM. All modules and problem ﬁles used for
the experiment are publicly available.1
The experiment was carried out in two phases, the results of which are sum-
marized in Tables 1 and 2. In the ﬁrst table, we report how many of the original
obligations were identiﬁed as higher-order and handled by each solver. These
obligations come from the standard library of TLA+, so Isabelle necessarily
solves all of them.
For each solver, based on the results of that ﬁrst phase, we edited the speciﬁ-
cations by removing a number of proof steps, following the process we described
in the previous section. Then, Isabelle and the considered solver were tested on
the new speciﬁcation. In the second table, we report how many proof steps were
removed (ﬁrst column), how many were handled by Isabelle (second column),
and how many of the remaining ones were handled by the solver (third column).
To compute the results for the last two columns, we searched how many proof
steps were removed to obtain each individual obligation. For instance, if one obli-
gation resulted from merging three steps together, it was counted as a reduction
by 2 steps. If that obligation was handled by Isabelle or another solved, that
would add 2 to its score. An empty cell indicates that the evaluation was not
run, because the result could not be other than 0.
4.3
Discussion
On the original speciﬁcations (Table 1), the performances of all higher-order
solvers compare, with only slight variations. Zipperposition solves a bit more
obligations, and Leo-III a bit less in general, except for the speciﬁcation Finite-
SetTheorems, on which it did not solve any goal.
1 https://github.com/adef-inr/Improving-TLAPS-Automation-Frocos-2021.git.

150
A. Defourné
Table 2. Proof steps that could be uniquely removed by each HO solver
Solver
Speciﬁcation
# Proof steps removed
Out of
Removed by Isa.
Uniq. removed by solver
CVC4
SequenceOpTheorems
6
0
6
FiniteSetTheorems
9
2
3
FunctionTheorems
1
1
–
WellFoundedInduction
5
1
4
Total
21
4
13
Leo-III
SequenceOpTheorems
2
0
0
FiniteSetTheorems
–
–
–
FunctionTheorems
2
0
0
WellFoundedInduction
2
0
2
Total
6
0
2
Satallax
SequenceOpTheorems
4
0
4
FiniteSetTheorems
10
3
3
FunctionTheorems
1
1
–
WellFoundedInduction
4
1
2
Total
19
5
9
Vampire
SequenceOpTheorems
6
0
4
FiniteSetTheorems
10
3
3
FunctionTheorems
1
1
–
WellFoundedInduction
4
1
3
Total
21
5
10
Zipperposition
SequenceOpTheorems
19
0
17
FiniteSetTheorems
10
3
4
FunctionTheorems
4
1
0
WellFoundedInduction
4
1
3
Total
37
5
24
The diﬀerences between solvers are more pronounced when we look at the
number of proof steps they allowed us to remove (Table 2). We could not make
much progress with Leo-III, with only 2 steps removed. CVC4, Vampire and
Satallax have similar results, with 9–13 proof steps removed. Zipperposition
let us remove 24 steps in total, which is signiﬁcantly higher than any other
solver. Out of these 24 steps, 17 come from SequenceOpTheorems, the biggest
speciﬁcation. These 17 steps are shared among only 4 diﬀerent obligations: two
that resulted from the removal of 2 steps each, one from 6 steps, and the last
from 7. These are the only cases of obligations resulting from the removal of more
than 4 steps. It should also be pointed that we attempted to remove 37 steps
with Zipperposition in total. This is higher than for the other solvers, which
indicates that Zipperposition could also solve the steps around a higher-order
step more often.
Overall, higher-order solvers prove to be helpful for proofs with a few inter-
mediary easy steps. It is often possible to remove a few steps with Zipperposition,
CVC4, Satallax or Vampire, and in some cases reduce the whole proof to a single
line, as is the case for the following proof:

Improving Automation for Higher-Order Proof Steps
151
THEOREM SuﬃxRecursiveSequenceFunctionType ==
ASSUME NEW S, NEW T, NEW Def(_,_), NEW f,
T # {},
StrictSuﬃxesDetermineDef(S, Def),
WFInductiveDeﬁnes(f, Seq(S), Def),
∀g ∈[Seq(S) -> T], s ∈Seq(S) : Def(g,s) ∈T
PROVE f ∈[Seq(S) -> T]
<1>1. IsWellFoundedOn(OpToRel(IsStrictSuﬃx, Seq(S)), Seq(S))
BY IsStrictSuﬃxWellFounded
<1>2. WFDefOn(OpToRel(IsStrictSuﬃx, Seq(S)), Seq(S), Def)
BY StrictSuﬃxesDetermineDef_WFDefOn
<1>. QED
BY <1>1, <1>2, WFInductiveDefType
An important portion of the original obligations are the application of some
induction principle. They are variations of this pattern:
<1> DEFINE P(n) == (* ... *)
<1>1 P(0)
<1>2 ∀n ∈Nat : P(n) => P(n + 1)
<1> HIDE DEF P
<1>3 ∀n ∈Nat : P(n) BY <1>1, <1>2, NatInduction (* The HO obligation *)
The induction can be on a diﬀerent structure, but the pattern is the same.
All solvers tended to fail on these obligations. When they did succeed, we only
removed the Hide line, but after doing so the solver would fail on the new obli-
gation. This is most likely due to the fact that NatInduction must be instantiated
with an arbitrary expression instead of the constant P, as P is expanded in the
goal when Hide is removed. In some cases, however, Isabelle was able to han-
dle the new obligation—these cases constitute the majority of removed steps
that are reported in the second column of table 2. They are especially preva-
lent in FiniteSetTheorems, as they represent 8 out of the 9 original obligations.
This may be the main reason for Leo-III’s poor performances on that particular
speciﬁcation.
5
Conclusion
Motivated by the most recent advances in higher-order theorem proving, and the
poor support for higher-order proof steps in TLAPS, we implemented an encod-
ing of TLA+ into THF and evaluated several higher-order solvers on a range
of proof obligations. Our experiment demonstrated that higher-order solvers are
indeed able to handle obligations more complex than TLAPS currently does.
Zipperposition in particular outperformed the others by a signiﬁcant margin,
and was integrated in TLAPS as a new backend.
This new backend was not intended to be general-purpose for TLA+, but
rather specialized in those obligations that involve a bit of higher-order rea-
soning. Thus the encoding of TLA+ we implemented is very simple and unopti-
mized. It appears however that we are unable to solve many obligations precisely

152
A. Defourné
because the encoding is lacking on some aspects. Our treatment of set exten-
sionality is insuﬃcient for solving goals such as Card(S ∪∅) = Card(S). Our
support of arithmetic is very limited, as we provide only a few theory axioms to
the solvers, and never consider the full theory. It should also be noted that the
encoding was primarily designed with Zipperposition in mind, and that we did
not fully explore the options that other solvers oﬀer. For instance, we are aware
that Vampire features a special rule for instantiating extensionality axioms, and
a set of support strategy for dealing with explicit theory axioms [7,12]. CVC4
features a decision procedure for reasoning about ﬁnite sets and cardinalities [1].
These are all potential leads for future improvements of TLA+ encodings, includ-
ing the general-purpose ones.
Acknowledgment. I thank Jasmin Blanchette, Pascal Fontaine and Stephan Merz
for their support and guidance through the development of this work. Peter Vuk-
mirović helped with the integration of Zipperposition in TLAPS and its conﬁgura-
tion. Simon Cruanes provided additional insights on Zipperposition. Martin Riener
tested and helped debugging the new backend. Damien Doligez and Ioannis Filip-
pidis explained to me the inner working of TLAPS, which helped in implementing the
extension. This research is funded by the European Research Council (ERC) under the
European’s Union Horizon 2020 research and innovation program (grant agreement
No. 713999, Matryoshka), and from the Région Grand Est.
References
1. Bansal, K., Reynolds, A., Barrett, C.W., Tinelli, C.: A new decision procedure for
ﬁnite sets and cardinality constraints in SMT. In: Proceedings of the Automated
Reasoning - 8th International Joint Conference (IJCAR 2016), Coimbra, Portugal,
June 27–July 2, 2016, pp. 82–98 (2016)
2. Barbosa, H., Reynolds, A., Ouraoui, D.E., Tinelli, C., Barrett, C.W.: Extending
SMT solvers to higher-order logic. In: Proceedings of the Automated Deduction -
CADE 27–27th International Conference on Automated Deduction, Natal, Brazil,
27–30 August 2019, pp. 35–54 (2019)
3. Bentkamp, A., Blanchette, J., Tourret, S., Vukmirovic, P., Waldmann, U.: Superpo-
sition with lambdas. In: Proceedings of the Automated Deduction - CADE 27–27th
International Conference on Automated Deduction, Natal, Brazil, August 27–30,
2019, pp. 55–73 (2019)
4. Bhayat, A., Reger, G.: A combinator-based superposition calculus for higher-order
logic. In: Proceedings of the Automated Reasoning - 10th International Joint Con-
ference, IJCAR 2020, Paris, France, July 1–4, 2020, Part I, pp. 278–296 (2020)
5. Brown, C.E.: Satallax: an automatic higher-order prover. In: Proceedings of the
Automated Reasoning - 6th International Joint Conference, IJCAR 2012, Manch-
ester, UK, June 26–29, 2012, pp. 111–117 (2012)
6. Cousineau, D., Doligez, D., Lamport, L., Merz, S., Ricketts, D., Vanzetto, H.: TLA+
Proofs. In: Giannakopoulou, D., Méry, D. (eds.) 18th International Symposium On
Formal Methods - FM 2012. Lecture Notes in Computer Science, vol. 7436, pp. 147–
154. Springer, Paris, France, August 2012. http://www.springerlink.com

Improving Automation for Higher-Order Proof Steps
153
7. Gupta, A., Kovács, L., Kragl, B., Voronkov, A.: Extensional crisis and proving
identity. In: Proceedings of the Automated Technology for Veriﬁcation and Analysis
- 12th International Symposium, ATVA 2014, Sydney, NSW, Australia, November
3–7, 2014, pp. 185–200 (2014)
8. Kotelnikov, E., Kovács, L., Voronkov, A.: A ﬁrst class boolean sort in ﬁrst-order
theorem proving and TPTP. In: Proceedings of the Intelligent Computer Math-
ematics - International Conference (CICM 2015), Washington, DC, USA, July
13–17, 2015, pp. 71–86 (2015)
9. Lamport, L.: How to write a proof. Am. Math. Monthly 102, 600–608 (1995)
10. Lamport, L.: Specifying Systems. Addison-Wesley, The TLA+ Language and Tools
for Hardware and Software Engineers (2002)
11. Mentré, D., Marché, C., Filliâtre, J., Asuka, M.: Discharging proof obligations from
atelier B using multiple automated provers. In: Proceedings of the Abstract State
Machines, Alloy, B, VDM, and Z - Third International Conference, ABZ 2012,
Pisa, Italy, June 18–21, 2012, pp. 238–251 (2012)
12. Reger, G., Suda, M.: Set of support for theory reasoning. In: IWIL@LPAR 2017
Workshop and LPAR-21 Short Presentations, Maun, Botswana, 7–12 May 2017
(2017)
13. Steen, A., Benzmüller, C.: The higher-order prover leo-iii. In: Proceedings of the
Automated Reasoning - 9th International Joint Conference, IJCAR 2018, Held
as Part of the Federated Logic Conference (FloC 2018), Oxford, UK, July 14–17,
2018, pp. 108–116 (2018)
14. Sutcliﬀe, G. (ed.): Proceedings of the 10th IJCAR ATP System Competition
(CASC-J10), July 2020
15. Vanzetto, H.: Proof automation and type synthesis for set theory in the context
of TLA+. (Automatisation de preuves et synthèse de types pour la théorie des
ensembles dans le contexte de TLA+). Ph.D. thesis, University of Lorraine, Nancy,
France (2014), https://tel.archives-ouvertes.fr/tel-01096518
16. Vukmirovic, P., Bentkamp, A., Nummelin, V.: Eﬃcient full higher-order uniﬁca-
tion. In: 5th International Conference on Formal Structures for Computation and
Deduction (FSCD 2020), June 29-July 6, 2020, Paris, France (Virtual Conference).
pp. 5:1–5:17 (2020)
17. Vukmirovic, P., Nummelin, V.: Boolean reasoning in a higher-order superposi-
tion prover. In: Joint Proceedings of the 7th Workshop on Practical Aspects of
Automated Reasoning (PAAR) and the 5th Satisﬁability Checking and Symbolic
Computation Workshop (SC-Square) Workshop, 2020 Co-located with the 10th
International Joint Conference on Automated Reasoning (IJCAR 2020), Paris,
France, June-July, 2020 (Virtual). pp. 148–166 (2020)

JEFL: Joint Embedding of Formal Proof
Libraries
Qingxiang Wang1 and Cezary Kaliszyk1,2(B)
1 University of Innsbruck, Innsbruck, Austria
cezary.kaliszyk@uibk.ac.at
2 University of Warsaw, Warsaw, Poland
Abstract. The heterogeneous nature of the logical foundations used in
diﬀerent interactive proof assistant libraries has rendered discovery of
similar mathematical concepts among them diﬃcult. In this paper, we
compare a previously proposed algorithm for matching concepts across
libraries with our unsupervised embedding approach that can help us
retrieve similar concepts. Our approach is based on the fasttext imple-
mentation of Word2Vec, on top of which a tree traversal module is
added to adapt its algorithm to the representation format of our data
export pipeline. We compare the explainability, customizability, and
online-servability of the approaches and argue that the neural embedding
approach has more potential to be integrated into an interactive proof
assistant.
Keywords: Unsupervised embedding · Concept alignments · Proof
formalization · System integration
1
Introduction
One of the challenges hindering massive formalization of mathematics is the
heterogeneous nature of the logical frameworks used in various interactive proof
assistants [8,11,13,27]. When formalizing proofs against one formal library, it is
informative to explore whether and how similar things are done in other libraries.
Such exploration has to be done manually and would usually require expertise
in the other proof assistants. It would be nice if a tool could let users more
systematically explore and discover commonality among formal libraries.
Not only can such a tool be an informative recommender when integrated
into an interactive proof assistant, but exploring commonalities among formal
libraries is also an interesting problem per se. Through time, multiple versions
of the same or similar mathematical concepts have been formalized separately,
resulting in repetitive work [21]. To the mathematically oriented, it is quite
irksome that identical mathematical concepts must require idiosyncratic formal-
izations in order to achieve assurance. We believe that by investigating their
commonalities, insights on improving interoperability among proof assistants
can be obtained, thereby advancing the frontiers of combining systems.
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 154–170, 2021.
https://doi.org/10.1007/978-3-030-86205-3_9

Joint Embedding of Formal Proof Libraries
155
Fig. 1. The architectural relationship between Gauthier’s approach and JEFL. At the
current stage, the exporters dump text in the tt format (Sect. 2). JEFL reuses the
IO/parsing
module
of
Gauthier
and
passes
s-expressions
to
the
fasttext
implementation.
Previous works [4,6] on this problem let us obtain a data export pipeline that
could transform data from six proof assistants into a common term representa-
tion format (Fig. 1), on top of which an iterative pattern-matching algorithm that
could output constant/theorem pairs with high similarity scores was invented by
Gauthier. The alignments between the concepts across multiple proof libraries
or within one library have been useful for tasks including conjecturing [7], brows-
ing multiple libraries simultaneously [25], and proof automation using learned
alignments [5].
The Gauthier approach, while being remarkably eﬀective and useful, lacks
explainability, customizability and online-servability that hamper its integration
into proof assistants. By these three notions we mean the lack of mathematical
intuitiveness, lack of room for customization, and lack of possibility for system
integration, respectively. We introduce an alternative embedding approach based
on the superb engineering of the fasttext implementation [1]. This new app-
roach could potentially overcome these drawbacks while providing competitive
performance. It could also serve as a highly conﬁgurable experiment platform
for studying the alignment of multiple proof assistant libraries. We coin this
research JEFL, as an acronym for Joint Embedding of Formal Libraries.

156
Q. Wang and C. Kaliszyk
2
Previous Works and the tt Format
Exchanging formal developments within or across formal systems has been stud-
ied through three strands of research. First, on the library translation side,
many tools that can partially translate proofs have been developed, including
those from HOL to Isabelle/HOL [26], HOL Light to Coq [20], HOL Light to
Isabelle/HOL [16], respectively. Second, on the ontology sharing side, Bortin [2],
Rabe [30], Hurd [14], So and Watt [32], and Carlisle et al. [3] each made their
own contribution translating speciﬁcations or formal proof objects between for-
mal or semi-formal mathematical representations. These two strands of research
mostly either solely provide guidelines on manual processing or require manual
work at a certain phase of their framework.
The third strand comes from enhancements of ITP systems. Heras and
Komendantskaya [12] implemented a recurrent term clustering algorithm to
ﬁnd proof similarities in Coq/SSReﬂect libraries. Urban [34] created tools for
large-scale retrieval of the Mizar Mathematical Library into a clausal format.
Kaliszyk and Urban [17] exported the core HOL Light library as well as the Fly-
speck [10] library to evaluate the relevance of lemmas by combining the power
of automated theorem provers. This work was later extended to a web service
[19] and experimented with using multiple representation formats and diﬀerent
automated theorem provers in [18].
A byproduct along [17–19] was a collection of exporting and post-processing
techniques speciﬁc to HOL Light, including a TPTP-style [33] data representa-
tion format which we internally called “the tt format”. The formalism of tt is
based on a simple term structure that is ﬂexible enough to represent the kernel
representations of formal data on diverse logical foundations, so there is a poten-
tial to export data from multiple proof assistants into this common format. Based
on the export of three HOL libraries (HOL Light, HOL4, and Isabelle/HOL),
Gauthier and Kaliszyk proposed the ﬁrst version of their scoring algorithm [4]
and used for various conjecturing and transfer learning tasks. A more compre-
hensive set of alignment experiments reﬁned the scoring algorithm, provided a
more uniform pattern-matching and guaranteed convergence, and was used on
six proof assistant libraries (adding Coq, Matita, and Mizar) [6].
Listing 2.1 and 2.2 illustrate the deﬁnition of the predecessor of the naturals
(PRE) of HOL Light being translated into a list of three tt items. The last
arguments of them can be parsed into term structures (Fig. 2) using the type
deﬁnition in Listing 2.3.
Listing 2.1. Deﬁnition of the predecessor of the naturals PRE in HOL Light.
-----------------------------------------------------------------------------
let PRE = new_recursive_definition
num_RECURSION
‘(PRE 0 = 0) /\
(!n. PRE (SUC n) = n)‘;;
-----------------------------------------------------------------------------

Joint Embedding of Formal Proof Libraries
157
Listing 2.2. PRE transformed to three tt items.
-----------------------------------------------------------------------------
01. tt(’const/arith/PRE ’, ty , (’type/nums/num ’ > ’type/nums/num ’)).
02. tt(’thm/arith/PRE_0 ’, ax ,
((’ const/arith/PRE ’ (’const/nums/NUMERAL ’ ’const/nums/_0 ’)) =
(’const/nums/NUMERAL ’ ’const/nums/_0 ’))).
03. tt(’thm/arith/PRE_1 ’, ax ,
(![n : ’type/nums/num ’]:
((’ const/arith/PRE ’ (’const/nums/SUC ’ n)) = n))).
-----------------------------------------------------------------------------
Listing 2.3. Type deﬁnition of tt term in OCaml for parsing.
-----------------------------------------------------------------------------
type
ttterm =
| Id of string (* may be a constant
or
variable
*)
| Comb of ttterm * ttterm
| Abs of string * ttterm * ttterm ;;
-----------------------------------------------------------------------------
The HOL Light and HOL4 exports directly use HOLyHammer’s export [18].
For Isabelle, an ML component was implemented that extracts all theorems of
the theory and writes them together with the declared constants and types in a
text ﬁle. The Coq export to the tt format was implemented by Gauthier as part
of his work [6]. For Mizar, we rely on Urban’s MPTP pipeline [35] and transform
the intermediate XML2 representation.
Fig. 2. Term structures of the deﬁnition of PRE. The tokens PRE, num, NUMERAL
and SUC are short for const/arith/PRE, type/nums/num, const/nums/NUMERAL and
const/nums/SUC, respectively. Note that the constant const/arith/PRE is included
into the term 01 with a type assignment operator ’:’. This allows embedding vectors
to be assigned to the deﬁnition constants.
3
The Architecture of JEFL
In this paper, we focus on the core similarity discovery algorithm. Our claim
on advantages in JEFL is with respect to the algorithmic part of the system.

158
Q. Wang and C. Kaliszyk
We leave the eventual integration of the whole framework into proof assistants,
with issues such as handling constants that have not been encountered during
training, as future work.
3.1
Similarity Through Embedding
A natural way to ﬁnd similarities among concepts is to treat our problem as a
distributed representation learning task. Generally speaking, given a structure
composed of atomic units, distributed representation learning seeks to represent
each of the atomic units with a low-dimensional vector. In eﬀect, all the units are
embedded into a Euclidean space, with their coordinates respecting the overall
structure. The notion distributedness comes from the fact that the vocabulary
size of a corpus is much larger than the dimension of a vector, and the information
of an atomic unit is distributed in the coordinates of a vector.
The vectors are learned by analyzing the context of each unit, i.e. the infor-
mation of units adjacent to or surrounding a target unit. Once vector represen-
tations for units are learned, similarity between units can then be computed by
cosine similarity with a range from [−1, 1]. For a set of units, vector represen-
tation can be computed by taking average of the vectors, and then similarity
between diﬀerent sets of units can also be computed using cosine similarity.
Notable unsupervised distributed representation learning algorithms include
Pennington et al.’s GloVe algorithm [28] and Mikolov et al.’s Word2Vec algo-
rithm [23,24]. In this paper, we use Mikolov’s Word2Vec algorithm. Word2Vec
works on texts or lists of word tokens. For each word in the training corpus, a
randomized span of words surrounding that word is picked to form the context
of that word. The context is then consumed by the Word2Vec model to conduct
one step of the stochastic gradient descent updates.
3.2
Adaptation of the tt Format in Word2Vec
To illuminate our technique, it is interesting to note that DeepWalk [29] and
Node2Vec [9], two methods on embedding large networks, also use Word2Vec
as their underlying algorithm. The data used by DeepWalk and Node2Vec are
single-graph datasets with nodes that contain heterogenous information such as
social proﬁle details. To ﬁt Word2Vec, ﬁrst the node information of the graph
has to be transformed into a dictionary through data processing. Then we per-
form random walks along the paths of the graph to generate node sequences
that resemble text corpus. For each node in a node sequence, the corresponding
context is generated as a span of nodes surrounding that node.
In our case, diﬀerent from DeepWalk and Node2Vec, the formal library data
in the tt format are not a single graph but a collection of trees. More precisely, in
order to compare two libraries, we need two lists of tt items from the two libraries
to provide as training data. The tt items are parsed as trees and then traversed
in diﬀerent ways to create sequences of node constants. Examples of traversals
include preorder, inorder, postorder traversals and their reverses, random walks
from the root to a leaf, or just dump the leaves of a tree in some order. With

Joint Embedding of Formal Proof Libraries
159
clever design, these traversals can also be combined to create hybrid orders.
At the current phase we implemented a simple weighted mechanism combining
preorder, inorder and postorder traversals. The weights of traversals are used to
control the learning rate for SGD updates and are hyperparameters determined
before training (Fig. 3). We anticipate further experimental insights when other
forms of traversals are implemented in the future.
Fig. 3. Preorder, inorder, and postorder traversals of a simple theorem ∀x
:
num. (x = x), with weights 0.5, 0.3, 0.2, respectively. Example illustrated by calling
the CBOW method of fasttext, where lr is the learning rate and the third argument
contains the token sequence above it. Inside the CBOW method, for each token, a
randomized span of words surrounding that token is obtained to compute the hidden
vector.
Both DeepWalk and Node2Vec directly use the Word2Vec implementation of
the Gensim [31] topic modeling library. For ease of future integration into proof
assistants we pick a dedicated Word2Vec implementation fasttext [15] as our
base platform. To make our customization less intrusive we add a custom tree
traversal module to the codebase of fasttext, also called the tt module (Fig. 1).
The tt module parses the terms in the tt format and builds corresponding trees
in the memory of JEFL.
3.3
The SGD Updates of Word2Vec
It remains to discuss the core Word2Vec algorithm, which is divided into two
aspects: 1. what is the probability model for Word2Vec training and 2. how the
loss function is computed. In the former, there are the continuous bag-of-words
model (CBOW) and the skip-gram model. They appear at the step of the train-
ing loop outside stochastic gradient descent (SGD) updates and determine how
data samples are used. In the latter, there are the softmax loss, the hierarchical
softmax loss, and the negative sampling loss. They compute the loss function,
at the same time determine the gradients and update the input and output

160
Q. Wang and C. Kaliszyk
matrices. The two training models are compatible with the three loss functions,
so there are in total six variations of the Word2Vec algorithm1.
As the full Word2Vec algorithm is extensive, we brieﬂy describe the diﬀer-
ence between skip-gram and CBOW using the simplest softmax case. We skip
detailed derivations and remind the reader of the abundance of study materials
of Word2Vec on the internet2.
Let C be the training corpus, V be the size of the dictionary of C, and D
be the dimension of a word vector. Denote M ∈RV ×D as the input matrix
which we use to store all the word vectors. Denote N ∈RV ×D as the output
matrix which we use to store customized data items depending on the loss func-
tion. Let w ∈{1, 2, . . . , V } be a word, or more precisely, the index of an actual
word in the dictionary. We denote Mw as the w-th row of the input matrix M.
Similarly we denote Nu as the u-th row of the output matrix N, given a word
u ∈{1, 2, . . . , V }. Both Mw and Nu are D-dimensional row vectors. For each
word w, denote context(w) as a randomized span of words surrounding w. Let
η > 0 be the learning rate.
From the probability modeling point of view, CBOW amounts to maximizing
the log-likelihood of the form
L = log

w∈C
P (w|context(w)) =

w∈C
log softmax(NhT )w,
where
h =
1
|context(w)|

u∈context(w)
Mu
is the hidden vector. The SGD updates are computed by taking increments of
the gradients of the objective (as we want to maximize the log-likelihood)3
Nu := Nu + η

δuw −softmax(NhT )u

h
for u ∈{1, . . . , V }
Mu := Mu +
η
|context(w)|
V

v=1

δvw −softmax(NhT )v

Nv
for u ∈context(w)
The skip-gram model amounts to maximizing the log-likelihood of the following
form
L = log

w∈C
P (context(w)|w) = log

w∈C

u∈context(w)
p(u|v)
=

w∈C

u∈context(w)
log softmax(NhT )u
1 As to writing of this paper, one more loss function (the one-vs-all, or the ova loss)
has been added to the latest version of fasttext, making in total eight variations.
2 The ﬁrst author ﬁnds this note https://github.com/renpengcheng-github/nlp/tree/
master/3.word2vec (in Chinese) particularly helpful in understanding Word2Vec.
3 We use the term stochastic gradient descent here for convention though we are in
fact doing stochastic gradient ascent.

Joint Embedding of Formal Proof Libraries
161
where
h = Mw
is a D-dimensional row vector. For each u ∈context(w), the SGD updates are
N 
w := N 
w + η

δ 
wu −softmax(NhT ) 
w

Mw
for w ∈{1, . . . , V }
Mw := Mw + η
V

v=1

δvu −softmax(NhT )v

Nv.
Algorithm 1. Full algorithm for CBOW and skip-gram with softmax loss
1: for w ∈C do
2:
Get sample (w, context(w)).
▷See Section 3.2
3:
if CBOW then
4:
h := 0
5:
for v ∈context(w) do
6:
h := h + Mv
7:
end for
8:
h := h/|context(w)|
▷1. Get hidden vector (cbow)
9:
g := 0
10:
for u ∈{1, . . . , V } do
▷Room for speedup
11:
s := softmax

NhT 
u
12:
α := η (δuw −s)
13:
g := g + αNu
▷2. Accumulate gradient (cbow)
14:
Nu := Nu + αh
▷3. Update output matrix (cbow)
15:
end for
16:
g := g/|context(w)|
17:
for u ∈context(w) do
18:
Mu := Mu + g
▷4. Update input rows (cbow)
19:
end for
20:
else
▷Skip-gram
21:
h := Mw
▷1. Get hidden vector (skipgram)
22:
for u ∈context(w) do
23:
g := 0
24:
for w ∈{1, . . . , V } do
▷Room for speedup
25:
s := softmax

NhT 

w
26:
α := η (δ 
wu −s)
27:
g := g + αN 
w
▷2. Accumulate gradient (skipgram)
28:
N 
w := N 
w + αh
▷3. Update output matrix (skipgram)
29:
end for
30:
Mw := Mw + g
▷4. Update input rows (skipgram)
31:
end for
32:
end if
33: end for

162
Q. Wang and C. Kaliszyk
3.4
The fasttext Implementation of Word2Vec
The full SGD update algorithm is shown in Algorithm 1. Notice that, for both
CBOW and skip-gram, in each round of model updates there are essentially four
identical steps: 1. obtain hidden vector, 2. accumulate gradient, 3. update rows
of the output matrix, and 4. update rows of the input matrix. This four-step
abstraction is general not only for softmax but also for hierarchical softmax and
negative sampling, which are speciﬁcally designed to speed up the calculation of
the inner loop in line 10, 24 of Algorithm 1.
The architecture of fasttext was inspired by this four-step abstraction.
Since its initial development in 2016, lots of advanced functionalities have been
added on top of the Word2Vec algorithm, including model quantization, auto-
tuning, python binding, etc. This makes the codebase large and many of those
functionalities are irrelevant to our research. Therefore we use an earlier commit
in late 2016 as our base4. In this commit, all six variations of Word2Vec have
been implemented and very few advanced functionalities are added. Two of them
worth mentioning are: 1. subsampling of most frequent words, and 2. subword
information enrichment trick. The ﬁrst is an extension of the Word2Vec algo-
rithm in [24] to ﬁlter out disproportionally frequent words in the training corpus.
This function is disabled since it is obvious in our dataset that the most frequent
tokens are always Comb, Id, and Abs, respectively, and they have to be included
to allow for correct parsing of tt items. The second is a feature in the fasttext
implementation [15] which breaks a word token into segments of character-level
n-gram tokens. This is also disabled since constants in our embedding task (e.g.
’const/arith/PRE’) constitute a unique and separate entity, and enabling this
feature would normally increase the size of a training model by more than a
hundred times. The original src directory of this commit contains 2054 lines of
C++ code written in C++11.
4
Experimenting with JEFL
The core algorithm part of JEFL consists of 8 modules of the original fasttext
plus a custom module for term parsing and traversal (Fig. 1 right). We ﬁnd that
the best way for customization is to add to the args module a new ﬂag (isTT)
to denote whether our training corpus is a list of tt items or plain texts. The
normal process ﬂow is not interrupted if this ﬂag is false, so JEFL can also train
on plain text. If isTT is true, then subsampling is suppressed when reading in
the input ﬁles. This allows all tokens of tt terms to be read so that term parsing
can be done correctly. The tt items are read, parsed and the parsed terms can
be reconstructed as trees in the C++ side. Helper functions are then called to
traverse a tree in diﬀerent orders, look up the index values of its constants from
a dictionary, and call fasttext’s original CBOW or skip-gram method for SGD
updates (Fig. 3).
4 c62abb89396a94520f009f9095874953735e0d75.

Joint Embedding of Formal Proof Libraries
163
We report our initial round of experiments with this platform and two formal
proof libraries, HOL4 and HOL Light, testing the performance of diﬀerent hyper-
parameter combinations. There are in total 18723 and 16874 lines of tt items
in HOL4 and HOL Light, respectively. We concatenate and shuﬄe the exported
theorems from the two libraries, and then write them out as s-expressions [22].5
We evaluate the performance by comparing against the 1000 highest-scoring
constant pairs, that have been manually checked by Gauthier in his work, and
considered here as a baseline.
Table 1. Comparison of theorem export formats. Tree-dump exports the whole tree
representation in the given order, while leaf-dump exports only the sequence of data
present in the leafs.
Top-1 Hit Top-3 Hit Top-10 Hit Top-20 Hit
Tree-Dump 51
101
188
261
Leaf-Dump 21
61
96
144
Table 2. Comparison of models skip-gram and continuous bag of words.
Top-1 Hit Top-3 Hit Top-10 Hit Top-20 Hit
Skip-Gram 54
108
264
283
CBOW
51
101
188
261
Table 3. Comparison of sampling hierarchical softmax vs. negative sampling
Top-1 Hit Top-3 Hit Top-10 Hit Top-20 Hit
Hierarchical Softmax 78
161
304
419
Negative Sampling
51
101
188
261
We present four sets of experiments for the initial comparison. We measure
JEFL’s performance against the Gauthier baseline by using the “Top-N Hit”
metric, which means the inclusion of the correct answer from the closest N
neighbors of the target constant. By default, we use leaf-dump (sequences of
data present in the leafs), CBOW, negative sampling, and equal (0.33, 0.33,
0.33) weights. For other key parameters of fasttext, we set vector dimension
as 100, learning rate 0.05, random uniform context window size 1 to 10, training
epoch 5 (for most experiments we see little training progress after epoch 5, so for
a fair evaluation we stick with 5 epochs for all evaluations), 5 negative samples
for negative sampling loss, and 4 training threads.
Experiment 1 (Table 1) tests the diﬀerence between tree-dump (dumping s-
expression) vs. leaf-dump (dumping leaves as token sequences). This experiment
is the ﬁrst one to test that our customization blends with the normal process
5 This gives a total of 35597 s-expressions for Word2Vec training.

164
Q. Wang and C. Kaliszyk
Table 4. Combination of the eﬀect of weights given to the diﬀerent traversals. The table
shows the weights given to pre-order, in-order, and post-order respectively, together
with their eﬀects on ﬁnding same constants across libraries.
(pre-, in-, post-order) Top-1 Hit Top-3 Hit Top-10 Hit Top-20 Hit
(0.33, 0.33, 0.33)
51
101
188
261
(0.5, 0.3, 0.2)
58
103
205
267
(1, 0, 0)
53
110
204
256
(0.5, 0.5, 0)
49
113
207
276
(0, 0.5, 0.5)
57
106
203
268
ﬂow of fasttext. We see that tree traversal gives better hit rates than just use
the leaves as the former uses more information in training.
Experiment 2 (Table 2) tests the diﬀerence between skip-gram and CBOW.
We see that skip-gram performs better than CBOW in all hit rates. However,
as noted in Sect. 3.3, skip-gram takes longer time to train (this depends on the
size of the contexts, and in our experiments skip-gram takes about ﬁve times
longer). For ease of experiment, we fall back to use CBOW as our default.
Experiment 3 (Table 3) shows a clear advantage of hierarchical softmax over
negative sampling. We see a 60% increase in all the hit rates. We speculate
that this improvement is due to the fact, that the Huﬀman tree computation
in hierarchical softmax might put an advantage in mining patterns in tree-like
data structures.
Experiment 4 (Table 4) explores diﬀerent combinations of weights in tree-
traversal. They all outperform leaf-dump, however, none of the combinations
performs signiﬁcantly better than others. We plan to explore other forms of
traversal such as random walks to see further results.
5
Comparison with Iterative Pattern-Matching
In this section, we shortly recall the iterative pattern-matching algorithm devel-
oped by Gauthier and Kaliszyk [6], and compare it with the work presented
here. The iterative pattern matching algorithm is based on the observation that
once mathematical information in diﬀerent formal libraries is represented in the
same tt format, similar theorems or typing judgements (as terms of tt) tend
to have identical term structures. Accordingly, similar constants (as leaves of
terms) tend to locate in corresponding slots of a term (Fig. 4). To abstract out
common term structure, Gauthier invented the notion pattern of a term. The
pattern of a term T is created by abstracting out, in a canonical order, all the
T’s non-logical constants. Two terms T1 and T2 sharing the same pattern form a
matching pair of terms. Corresponding slots of a matching pair of terms induce
a collection of matching pairs of constants.

Joint Embedding of Formal Proof Libraries
165
Fig. 4. T1 and T2 form a matching pair of terms with pattern P. Three matching
pairs of constants can be induced from this pattern. We treat equality = and universal
quantiﬁcation ! as logical constants. Bound variables are assumed to be normalized.
Given two formal libraries L1 and L2. Let {ti}1≤i≤m be the collection of all
matching pairs of terms, with ti = (ti1, ti2), ti1 ∈L1, and ti2 ∈L2. Let {cj}1≤j≤n
be the collection of all matching pairs of constants, with cj = (cj1, cj2). Let
g(x) = x/(x + 1) : R+ →[0, 1) be a strictly increasing normalization function.
Deﬁne an indicator function δ(cj, ti) and set δ(cj, ti) = 1 if constant pair cj can
be induced by term pair ti and 0 otherwise. Similarity scores between pairs of
terms and pairs of constants can be calculated using the following recurrence
relations
⎧
⎪
⎨
⎪
⎩
score0
c (cj) = 1,
j = 1, . . . , n.
scoreT
t (ti) = wt (ti) n
l=1 δ(cl, ti) scoreT −1
c
(cl),
i = 1, . . . , m.
scoreT
t (cj) = g

wc (cj) m
k=1 δ(cj, tk) scoreT
t (tk)

,
j = 1, . . . , n.
(1)
where T = 0, 1, 2, . . . is the iteration step and the weighting functions for terms
wt (ti) and constants wc (cj) are determined using heuristics
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
wt (ti) =
1
ln(2+p(ti))
1
ln(2+q(ti)),
i = 1, . . . , m.
wc (cj) =
1
ln(2+r(cj1)×r(cj2)),
j = 1, . . . , n.
p (ti) = #{term pairs sharing the same pattern as ti},
i = 1, . . . , m.
q (ti) = #{constant pairs induced by ti},
i = 1, . . . , m.
r (cjd) = #{terms containing cjd},
d = 1 or 2,
j = 1, . . . , n.
(2)

166
Q. Wang and C. Kaliszyk
By rewriting Eq. (1) with respect to scoreT
t (cj) and using properties of g, δ,
wt, and wc, Gauthier proved the convergence of this scoring algorithm (using
monotone convergence theorem coordinate-wise in [0, 1]n) [6].
5.1
Advantages and Drawbacks of Iterative Pattern Matching
Gauthier’s iterative pattern-matching algorithm is cleverly designed. Intuitively,
the existence of a pattern already indicates a strong correlation among term
pairs, and the existence of constant pairs at corresponding slots of a pattern
already indicates a strong correlation among those constant pairs; The indicator
function δ transports “similarity awards” among those pairs, while the weight-
ing functions wt and wc penalize frequently occurring patterns. Above all, the
normalization function g ensures the validity of the scores and is crucial for
convergence of the algorithm. All these components are intricately combined to
make the whole algorithm eﬀective in discovering identical or similar mathemat-
ical concepts.
Nevertheless, Gauthier’s algorithm possesses some inherent drawbacks. From
the explainability angle, the balance between the heuristics (wt, wc and their
components p, q, and r) in Eq. (2) and the score accumulation terms ( and δ)
in Eq. (1) is, to our mind, hard to explain clearly and diﬃcult to readjust. The
convergence of the algorithm is mostly due to the property of the normaliza-
tion function g but the link between this convergence and how similarity scores
are sorted is weak. The algorithm works on spaces of similarity scores between
matching pairs of terms and constants, so from its beginning, the information
on non-matching terms and constants is thrown away, losing the possibility to
look at the alignment of diﬀerent proof assistant libraries holistically.
Comparatively, our approach provides much more ﬂexibility and intuitive-
ness. Using distributed representation learning, all the constants are mov-
able points in Euclidean space and similarity between constants are naturally
described as cosine similarity between their coordinates. By using an embedding
approach, not only the “matching” pairs, but also similarity between all pairs of
constants can be retrieved and their computation is cheap.
From the customizability angle, the components of Gauthier’s algorithm are
so intricately combined that there seems little opportunity to adjust the algo-
rithm further. In the implementations of both [4] and [6], most of the extra
work is on preprocessing terms using combinations of rewriting rules to create a
varying set of patterns. These rewriting rules include, e.g. rewriting to conjunc-
tive normal forms, reordering commutative/associative connectives, substituting
subterms with deﬁnitions, as well as exposing various levels of typing informa-
tion. All these customizations are only allowed in the preprocessing phase and
limited to only employing rewriting rules. Some of the typing exposure rules
require speciﬁc knowledge of representing a library in the tt format. As these
rewriting-based customizations have already been thoroughly investigated in [6],
it seems to us that further investigation along this line is destined to a dimin-
ishing return.

Joint Embedding of Formal Proof Libraries
167
Comparatively, customization of JEFL can be done at diﬀerent phases of the
full training algorithm, such as the data generation phase, term traversal phase,
model update phase, etc. This multi-level customization can create combinato-
rially much more room for parameter-tuning and experimentation. Moreover,
except data generation, all other customizations that are within the algorithm
can be more uniformly done. Speciﬁcally, data ﬁelds and command parsing can
be added to the args module, and then used at desired places of the data ﬂow.
From the online-servability angle, despite the fact that Gauthier’s algorithm
is overall fast and eﬀective on small data, it is still quadratic on the size of the
input libraries, since it needs to enumerate all pairs of terms to ﬁnd patterns.
Being a batch program without a separated and instantaneous evaluation phase,
it is not tempting to integrate the whole algorithm into an actual interactive
proof assistant. Moreover, even if it were to be used as an online recommender,
the only information we can retrieve would be limited to only the matching pairs.
In JEFL, despite more computations are involved, training is linear with
respect to the size of the corpus. This makes JEFL more suitable for obtaining
similarity measurements on a large training corpus. JEFL provides a clear sepa-
ration between a training phase and an evaluation phase. The evaluation phase
is instant once the model is loaded. This allows JEFL to have more potential to
be integrated as a service. In the version of the fasttext commit used in JEFL,
if subword information is disabled, the size of most of the models dumped after
training are less than 5 MB. This is a negligible size comparing to the size of a
modern proof assistant.
6
Conclusion
In this paper, we identify the need for commonality discovery among formal
libraries. We introduce our data pipeline, especially its preceding works, and
elaborate our internal tt formalism. Methodologically, we describe the archi-
tecture of JEFL and make a series of ﬁrst experiments to test the eﬃcacy of
our experiment platform and provide a high-level comparative analysis with the
iterative pattern matching algorithm.
6.1
Limitations and Future Work
There are a lot of future possibilities in our JEFL platform. Continuing in the
current line of development, we still need to experiment on the other four libraries
and additionally explore similarity discovery of not only constants but also terms.
We could also explore the eﬀect of vector initialization in our discovery algo-
rithm. To go deeper we could implement custom “dragging” and “repelling”
steps using geometric manipulation and intersperse these custom steps with SGD
updates. We have focused on one pair of libraries, which could be extended to
an embedding of multiple libraries combined. This would provide further experi-
ment opportunities. We also plan to use the newly discovered samples from JEFL
to do tasks such as conjecturing [7], cross-browsing [25], and stronger learning

168
Q. Wang and C. Kaliszyk
for hammers [5]. Last but not least, we hope there could be use cases to inte-
grate our pipeline into an actual proof assistant and see improved formalization
productivity.
Acknowledgements. We are largely indebted to Thibault Gauthier for his work on
alignments and the various data exports that we re-use. We thank Josef Urban for the
Mizar export and his invitation to Prague to discuss research. We also thank Tom´aˇs
Mikolov for valuable insights for the current work. This work was supported by the
ERC grant no. 714034 SMART and by the University of Innsbruck PhD scholarship.
References
1. Bojanowski, P., Grave, E., Joulin, A., Mikolov, T.: Enriching word vectors with
subword information. Trans. Assoc. Comput. Linguist. 5, 135–146 (2017). https://
aclanthology.org/Q17-1010
2. Bortin, M., L¨uth, C.: Structured formal development with quotient types in
Isabelle/HOL. In: Autexier, S., et al. (eds.) CICM 2010. LNCS (LNAI), vol. 6167,
pp. 34–48. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-14128-
7 5
3. Carlisle, D., Davenport, J., Dewar, M., Hur, N., Naylor, W.: Conversion between
MathMl and OpenMath. Technical Report 24.969, The OpenMath Society (2001)
4. Gauthier, T., Kaliszyk, C.: Matching concepts across HOL libraries. In: Watt,
S.M., Davenport, J.H., Sexton, A.P., Sojka, P., Urban, J. (eds.) CICM 2014. LNCS
(LNAI), vol. 8543, pp. 267–281. Springer, Cham (2014). https://doi.org/10.1007/
978-3-319-08434-3 20
5. Gauthier, T., Kaliszyk, C.: Sharing HOL4 and HOL light proof knowledge. In:
Davis, M., Fehnker, A., McIver, A., Voronkov, A. (eds.) LPAR 2015. LNCS, vol.
9450, pp. 372–386. Springer, Heidelberg (2015). https://doi.org/10.1007/978-3-
662-48899-7 26
6. Gauthier, T., Kaliszyk, C.: Aligning concepts across proof assistant libraries. J.
Symbol. Comput. 90, 89–123 (2019). https://doi.org/10.1016/j.jsc.2018.04.005
7. Gauthier, T., Kaliszyk, C., Urban, J.: Initial experiments with statistical conjec-
turing over large formal corpora. In: Kohlhase, A. (ed.) Work in Progress at the
Conference on Intelligent Computer Mathematics 2016 (CICM-WiP 2016), CEUR,
vol. 1785, pp. 219–228. CEUR-WS.org (2016)
8. Grabowski, A., Kornilowicz, A., Naumowicz, A.: Mizar in a nutshell. J. Formalized
Reasoning 3(2), 153–245 (2010). https://doi.org/10.6092/issn.1972-5787/1980
9. Grover, A., Leskovec, J.: node2vec: scalable feature learning for networks (2016)
10. Hales, T.C.: Introduction to the Flyspeck project. In: Coquand, T., Lombardi, H.,
Roy, M.F. (eds.) Mathematics, Algorithms, Proofs, No. 05021 in Dagstuhl Seminar
Proceedings, Internationales Begegnungs- und Forschungszentrum f¨ur Informatik
(IBFI), Schloss Dagstuhl, Germany, Dagstuhl, Germany, pp. 1–11 (2006). http://
drops.dagstuhl.de/opus/volltexte/2006/432
11. Harrison, J.: HOL light: an overview. In: Berghofer, S., Nipkow, T., Urban, C.,
Wenzel, M. (eds.) TPHOLs 2009. LNCS, vol. 5674, pp. 60–66. Springer, Heidelberg
(2009). https://doi.org/10.1007/978-3-642-03359-9 4
12. Heras, J., Komendantskaya, E.: Proof pattern search in Coq/SSReﬂect. CoRR
abs/1402.0081 (2014). http://arxiv.org/abs/1402.0081

Joint Embedding of Formal Proof Libraries
169
13. Huet, G.P., Herbelin, H.: 30 years of research and development around Coq. In:
Jagannathan, S., Sewell, P. (eds.) ACM Symposium on Principles of Program-
ming Languages, POPL 2014, pp. 249–250. ACM (2014). https://doi.org/10.1145/
2535838.2537848
14. Hurd, J.: The OpenTheory standard theory library. In: Bobaru, M., Havelund,
K., Holzmann, G.J., Joshi, R. (eds.) NFM 2011. LNCS, vol. 6617, pp. 177–191.
Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-642-20398-5 14
15. Joulin, A., Grave, E., Bojanowski, P., Mikolov, T.: Bag of tricks for eﬃcient text
classiﬁcation. In: Proceedings of the 15th Conference of the European Chapter of
the Association for Computational Linguistics: Volume 2, Short Papers, Valencia,
Spain, pp. 427–431. Association for Computational Linguistics, April 2017. https://
www.aclweb.org/anthology/E17-2068
16. Kaliszyk, C., Krauss, A.: Scalable LCF-style proof translation. In: Blazy, S., Paulin-
Mohring, C., Pichardie, D. (eds.) ITP 2013. LNCS, vol. 7998, pp. 51–66. Springer,
Heidelberg (2013). https://doi.org/10.1007/978-3-642-39634-2 7
17. Kaliszyk, C., Urban, J.: Lemma mining over HOL Light. In: LPAR, pp. 503–517
(2013)
18. Kaliszyk, C., Urban, J.: Learning-assisted automated reasoning with Flyspeck.
J. Autom. Reasoning 53(2), 173–213 (2014). https://doi.org/10.1007/s10817-014-
9303-3
19. Kaliszyk, C., Urban, J.: HOL(y)Hammer: online ATP service for HOL Light. Math.
Comput. Sci. 9(1), 5–22 (2014). https://doi.org/10.1007/s11786-014-0182-0
20. Keller, C., Werner, B.: Importing HOL light into Coq. In: Kaufmann, M., Paulson,
L.C. (eds.) ITP 2010. LNCS, vol. 6172, pp. 307–322. Springer, Heidelberg (2010).
https://doi.org/10.1007/978-3-642-14052-5 22
21. Klein, G.: Proof engineering considered essential. In: Jones, C., Pihlajasaari, P.,
Sun, J. (eds.) FM 2014. LNCS, vol. 8442, pp. 16–21. Springer, Cham (2014).
https://doi.org/10.1007/978-3-319-06410-9 2
22. McCarthy, J.: Recursive functions symbolic expressions and their computation
by machine, Part I. Commun. ACM 3(4), 184–195 (1960). https://doi.org/
10/fvx5pv. http://dl.acm.org/citation.cfm?id=367177.367199. zSCC: NoCitation-
Data[s0]. ISBN 0001-0782
23. Mikolov, T., Chen, K., Corrado, G., Dean, J.: Eﬃcient estimation of word rep-
resentations in vector space. In: Bengio, Y., LeCun, Y. (eds.) 1st International
Conference on Learning Representations, ICLR 2013, Scottsdale, Arizona, USA,
2–4 May 2013, Workshop Track Proceedings (2013). http://arxiv.org/abs/1301.
3781
24. Mikolov,
T.,
Sutskever,
I.,
Chen,
K.,
Corrado,
G.S.,
Dean,
J.:
Dis-
tributed
representations
of
words
and
phrases
and
their
compositionality.
In: Burges, C.J.C., Bottou, L., Welling, M., Ghahramani, Z., Weinberger,
K.Q. (eds.) Advances in Neural Information Processing Systems. vol. 26.
Curran Associates, Inc. (2013). https://proceedings.neurips.cc/paper/2013/ﬁle/
9aa42b31882ec039965f3c4923ce901b-Paper.pdf
25. M¨uller, D., Gauthier, T., Kaliszyk, C., Kohlhase, M., Rabe, F.: Classiﬁcation of
alignments between concepts of formal mathematical systems. In: Geuvers, H.,
England, M., Hasan, O., Rabe, F., Teschke, O. (eds.) CICM 2017. LNCS (LNAI),
vol. 10383, pp. 83–98. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-
62075-6 7
26. Obua, S., Skalberg, S.: Importing HOL into Isabelle/HOL. In: Furbach, U.,
Shankar, N. (eds.) IJCAR 2006. LNCS (LNAI), vol. 4130, pp. 298–302. Springer,
Heidelberg (2006). https://doi.org/10.1007/11814771 27

170
Q. Wang and C. Kaliszyk
27. Paulson, L.C.: Isabelle: the next seven hundred theorem provers. In: Lusk, E.,
Overbeek, R. (eds.) CADE 1988. LNCS, vol. 310, pp. 772–773. Springer, Heidelberg
(1988). https://doi.org/10.1007/BFb0012891
28. Pennington, J., Socher, R., Manning, C.D.: GloVe: global vectors for word repre-
sentation. In: EMNLP, vol. 14, pp. 1532–1543 (2014)
29. Perozzi, B., Al-Rfou, R., Skiena, S.: DeepWalk: online learning of social repre-
sentations. In: Proceedings of the 20th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, August 2014. https://doi.org/10.1145/
2623330.2623732
30. Rabe, F.: The MMT API: a generic MKM system. In: Carette, J., Aspinall, D.,
Lange, C., Sojka, P., Windsteiger, W. (eds.) CICM 2013. LNCS (LNAI), vol.
7961, pp. 339–343. Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-
642-39320-4 25
31. ˇReh˚uˇrek, R., Sojka, P.: Software framework for topic modelling with large cor-
pora. In: Proceedings of the LREC 2010 Workshop on New Challenges for NLP
Frameworks, ELRA, Valletta, Malta, pp. 45–50, May 2010. http://is.muni.cz/
publication/884893/en
32. So, C.M., Watt, S.M.: On the conversion between content MathMl and Open-
Math. In: Proceedings of the Conference on the Communicating Mathematics in
the Digital Era (CMDE 2006), pp. 169–182 (2006)
33. Sutcliﬀe, G.: The TPTP world - infrastructure for automated reasoning. In: LPAR
(Dakar), pp. 1–12 (2010)
34. Urban, J.: MoMM - fast interreduction and retrieval in large libraries of formalized
mathematics. Int. J. Artif. Intell. Tools 15(1), 109–130 (2006). http://ktiml.mﬀ.
cuni.cz/∼urban/MoMM/momm.ps
35. Urban, J.: MPTP 0.2: design, implementation, and initial experiments. J. Autom.
Reasoning 37(1–2), 21–43 (2006). https://doi.org/10.1007/s10817-006-9032-3

Machine Learning

Fast and Slow Enigmas and Parental
Guidance
Zarathustra A. Goertzel1(B), Karel Chvalovsk´y1, Jan Jakub˚uv1,2,
Miroslav Olˇs´ak2, and Josef Urban1
1 Czech Technical University in Prague, Prague, Czech Republic
2 University of Innsbruck, Innsbruck, Austria
Abstract. We describe several additions to the ENIGMA system that
guides clause selection in the E automated theorem prover. First, we
signiﬁcantly speed up its neural guidance by adding server-based GPU
evaluation. The second addition is motivated by fast weight-based rejec-
tion ﬁlters that are currently used in systems like E and Prover9. Such
systems can be made more intelligent by instead training fast versions
of ENIGMA that implement more intelligent pre-ﬁltering. This results
in combinations of trainable fast and slow thinking that improves over
both the fast-only and slow-only methods. The third addition is based on
“judging the children by their parents”, i.e., possibly rejecting an infer-
ence before it produces a clause. This is motivated by standard evolution-
ary mechanisms, where there is always a cost to producing all possible
oﬀsprings in the current population. This saves time by not evaluating
all clauses by more expensive methods and provides a complementary
view of the generated clauses. The methods are evaluated on a large
benchmark coming from the Mizar Mathematical Library, showing good
improvements over the state of the art.
1
Introduction: The Fast and The Smart
Throughout the history of automated theorem proving, there have been two very
diﬀerent approaches to strengthening automated theorem provers (ATPs). The
ﬁrst one (the fast) relies on better engineering, such as improving the indexing
for inference and reduction rules and on optimized low-level implementations.
The gains achieved in this way can be quite high [9,15,22,28,31,38].
The second approach (the smart) relies on advanced strategies and heuris-
tics for guiding the proof search. This includes methods using extensive previous
knowledge, e.g., various kinds of symbolic machine learning, such as the hints
method in Otter [37] and Prover9 [19], and its watchlist [26] and proofwatch [6]
variants implemented in E [29,30]. With the recent advent of statistical machine
learning (ML), a number of knowledge-based ATP-guiding methods have been
created [3,10,11,17]. This is done by compiling (extracting, compressing, gener-
alizing) the previous knowledge into statistical ML predictors (models) that are
then used to predict the usefulness of inference steps in the proof search.
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 173–191, 2021.
https://doi.org/10.1007/978-3-030-86205-3_10

174
Z. A. Goertzel et al.
The smart approaches, while potentially sophisticated and AI-motivated,
may incur prohibitively high costs in their prediction modules, in particular
when naively implemented [21,36]. This can make them inferior in practice to
faster alternative approaches, such as various kinds of randomization [25] and
building of portfolios of complementary fast strategies [13,27,35]. This issue is
getting increasingly important as deep learning (DL) is used for ATP guidance,
sometimes with large cloud-based DL-predictors running on specialized hardware
that hides the amount of resources used. It also complicates rigorous comparisons
in established ATP competitions such as CASC/LTB [32,33].
Another issue related to the use of expensive predictors can be summarized
as the explore-exploit tradeoﬀintroduced in reinforcement learning research [5].
In short, running an ATP guided by a 100-times slower predictor that is only
slightly better (possibly due to insuﬃcient previous data for learning) will not
only typically solve fewer problems due to much more expensive backtracking
but also generate much less data for training the predictor in the next iteration.
Hence, given a global time limit allowing many proving/learning iterations over
a large set of related problems in a realistic problem-solving setup such as CASC
LTB, a faster predictor will in the same time generate much more data to learn
from. This in turn often leads to better performance: a slightly weaker ML system
trained on much more data will often ultimately outperform a slightly stronger
ML system trained on much less data.
1.1
Contributions
In this work we develop combinations of the fast(er) and smart(er) approaches in
the context of the learning-guided ENIGMA framework. After giving a summary
of ENIGMA in Sect. 2, Sect. 3 introduces our new methods.1
First, Sect. 3.1 describes a large increase in the speed of neural guidance in
ENIGMA. We add an eﬃcient server-based evaluation that uses dedicated GPUs
instead of a CPU. When using four commodity GPU cards, this speeds up the
neural evaluation of the clauses about four times in real time.
Section 3.2 describes the second addition, motivated by fast weight-based
rejection ﬁlters used in systems such as E and Prover9. Such methods can be
replaced by training fast predictors that implement more intelligent pre-ﬁltering.
In the context of ENIGMA, fast(er) is easy to implement by variously parame-
terized predictors based on gradient-boosted decision trees (GBDTs). Slow(er)
models are in those based on graph neural networks (GNNs).
Section 3.3 describes the third addition based on “judging the children by
their parents”, i.e., possibly rejecting an inference before it even produces a
clause. This grants the machine learning methods greater control of the proof
search and saves time by not evaluating all clauses by more expensive methods,
also providing a complementary view of the generated clauses.
1 The E and ENIGMA versions used in this paper can be found at https://github.
com/ai4reason/enigma-gpu-server.

Fast and Slow Enigmas and Parental Guidance
175
In Sect. 4 we describe the experimental setting and a large evaluation cor-
pus based on the Mizar Mathematical Library and its MPTP translation. We
also present our baseline methods there. Section 5 evaluates the new methods
and shows that even in relatively low time limits the methods provide good
performance improvements over the previous versions of ENIGMA.
2
Saturation Proving and Its Guidance by ENIGMA
State-of-the-art automated theorem provers (ATP), such as E, Prover9, and
Vampire [20], are based on the saturation loop paradigm and the given clause
algorithm [24]. The input problem, in ﬁrst-order logic (FOF), is translated into a
refutationally equivalent set of clauses, and a search for contradiction is initiated.
The ATP maintains two sets of clauses: processed (initially empty) and unpro-
cessed (initially the input clauses). At each iteration, one unprocessed clause is
selected (given), and all of the possible inferences with all the processed clauses
are generated (typically using resolution, paramodulation, etc.), extending the
unprocessed clause set. The selected clause is then moved to the processed clause
set. Hence the invariant holds that all the mutual inferences among the processed
clauses have been computed.
The selection of the “right” given clause is known to be vital for the success of
the proof search. The ENIGMA system [3,7,10–12,14] applies various machine
learning methods for given clause selection, learning from a large number of
previous successful proof searches. The training data consists of clauses processed
during a proof search, labeling the clauses that appear in the discovered proof
as positive, and the other (thus unnecessary) processed clauses as negative.
The ﬁrst ENIGMA [11] used fast linear classiﬁcation [4] with hand-crafted
clause features based on symbol names, representing clauses by ﬁxed-length
numeric vectors. Follow-up versions [3,7,12,14] introduced context-based clause
evaluation and fast dimensionality reduction by feature hashing, and employed
Gradient Boosting Decision Trees (GBDTs), implemented by the XGBoost and
LightGBM systems [2,18]), and Recursive Neural Networks (implemented in
PyTorch) as the underlying machine learning methods.
The latest version, ENIGMA Anonymous [10], abstracts from name-based
clause representations and provides the best results so far both with GBDTs
and Graph Neural Networks (GNNs) [1]. For GBDTs, clauses are again rep-
resented by ﬁxed-length vectors based on syntax trees and anonymization is
achieved by replacing symbol names by their arities. Our GNN [23] represents
clauses by variable-length numeric tensors encapsulating syntax trees as graph
structures with symbol names omitted. ENIGMA-GNN evaluates new clauses
jointly in larger batches (queries) and with respect to a large number of already
selected clauses (context). The GNN predicts the collectively most useful sub-
set of the clauses in several rounds (layers) of message passing. This means that
approximative inference rounds done by the GNN are eﬃciently interleaved with
precise symbolic inference rounds done inside E. The GBDT and GNN versions
have so far been used separately and only with CPU-based evaluation. In this

176
Z. A. Goertzel et al.
work, we add eﬃciently implemented GPU-based evaluation for the GNN and
start to use the two methods cooperatively.
3
Cooperative Filtering: Faster and Smarter
The set of generated clauses in saturation-style ATPs typically grows quadrati-
cally with the number of processed clauses. Each new given clause is combined
with all compatible previously processed clauses, followed by (possibly expen-
sive) evaluation of all newly generated clauses. In particular, the GNN predictors
typically incur a signiﬁcant evaluation cost per clause. The quadratic growth
means that longer ENIGMA-GNN runs may get very slow.
To avoid large memory consumption and similar expensive evaluations in long
hint-based Prover9 runs (often taking several days) on the AIM problems [19],
Veroﬀhas used weight-based ﬁltering, discarding immediately clauses that reach
a certain weight limit. This often helps, but counterexamples are common, and
in practice, such schemes often need to be made more complicated.2 The three
methods that we introduce below are instead targeting this issue by using faster
learning-based ﬁltering.
3.1
Fast GNN Evaluation Using a GPU Server
The main weakness of the GNN version of ENIGMA is its slow clause evaluation.
In our previous ENIGMA Anonymous experiments [10], we used GPUs for model
training, but during the proof search we evaluated the clauses on a single CPU
(per each E prover’s instance). This was partly to provide a fair comparison
with GBDTs which we also evaluate on a single CPU, but also to avoid large
start-up overheads when loading the neural models to a GPU and running with
low time limits. Here we instead develop a persistent multi-threaded GPU server
that evaluates clauses from multiple E prover runs using multiple GPUs.
The modiﬁcation is as follows. During the proof search, after computing the
tensor representation of the newly generated clauses, an E Prover client sends
the tensors (in a JSON text format) over a network socket to a remote server.
The client then waits for the server response which provides the scores (GNN
evaluations) of the new clauses. This means that the clients are inactive for some
time and more of them are needed to saturate the CPUs on the machines (see
the detailed experimental discussion in Sect. 5.1). This is typically not a problem
due to many instances of E running with diﬀerent premises and parameters
in hammering and CASC LTB scenarios, as well as in many iterations of the
learning/proving loop that attempt to solve harder and harder problems over a
large problem set.
The remote server, written in Python, is launched before the E clients, loading
the GNN model to the (multiple) GPUs in advance. Once the model is loaded
2 We thank Bob Veroﬀfor explaining that this is done by gradually lowering the weight
limit inside a single longer Prover9 run, and by raising the initial weight limit and
slowing down the weight reduction scheme across multiple Prover9 runs.

Fast and Slow Enigmas and Parental Guidance
177
to the GPUs, the server accepts tensor queries on a designated port, evaluates
them on the GPUs, and sends the clause evaluations back to the clients. In
more detail, the server is parameterized by the number N (our default is 28) of
independent worker threads, the batch size b (our default is 8) and the waiting
time T (our default is 0.01 s). The client queries are accumulated in a shared
queue that the N worker threads process. Each worker operates in two steps.
First, it checks the queue, and if it contains less than b queries, it waits for T
seconds. Then it evaluates the ﬁrst b queries on the queue, or less if there are not
enough of them available. Note that when the worker waits or evaluates queries,
other workers can process the queue.
The advantage is that the single GNN server amortizes the startup costs and
handles queries of many E prover clients and distributes them across multiple
GPUs. This means that much larger batches (containing clauses coming from
multiple clients) are typically loaded onto the GPUs, amortizing also the rela-
tively high cost of communication with the GPUs. This results in large real time
speed-ups over the CPU version, see Sect. 5.1. In our experiments, we run the
GPU server and the E clients on the same machine. Hence the network overhead
is low because the communication is done over a local loopback interface. In the
case of a remote connection, the architecture would beneﬁt from data compres-
sion and/or binary data formats to decrease the network overhead. See Sect. 5.1
for the current average sizes of the data exchanged.
3.2
Best of Both Worlds: GNN with GBDT Filtering
While the GPU server evaluation provides a considerable speed up, the evalua-
tion of clauses on a GPU is still relatively costly compared to the GBDT clause
evaluation. Hence we develop the following combination of the two methods,
where the GBDT is used to pre-ﬁlter the clauses for the GNN.
In more detail, the set of clauses to be evaluated by the GNN is ﬁrst evaluated
by a fast GBDT model.3 The GBDT model assigns a score between 0 and 1 to
each clause, and only the clauses with scores higher than a selected threshold are
sent to the GPU server for evaluation by the GNN. The clauses which are ﬁltered
out by the GBDT model are assigned a very high weight inside E Prover, which
makes them unlikely to ever be selected for processing. This way we prevent E
from incorrectly reporting satisﬁability when the good clauses run out.
Several requirements must be met for this ﬁltering to be eﬀective. First, the
GBDT ﬁltering model must be small enough so that the evaluation is fast, yet
precise enough so that the more important clauses are not mistakenly ﬁltered
out too often. Second, the score threshold must be properly ﬁne-tuned, which
typically requires experimental grid search on smaller samples. Experiments with
a GBDT pre-ﬁltering for a GNN are presented in Sect. 5.2.
3 This feature is implemented for the LightGBM models, which seem more easily
tunable for such tasks.

178
Z. A. Goertzel et al.
3.3
Parental Guidance: Pruning the Given Clause Loop
We deﬁne (clausal) parental guidance as clause evaluation based on the features
of the parents of a clause rather than on the clause itself. Such fast rejection ﬁlters
often help: in nature, mating is typically highly restricted by various features of
parents (e.g., their age, appearance, ﬁnances, etc.). Similarly, it does not often
happen that clauses from very diﬀerent parts of mathematics (e.g., diﬀerential
geometry and graph theory) need to be resolved.
Parental guidance can be seen as “just another ﬁlter” of the generated clauses,
but its motivation is more radical: The “good old”4 given clause loop [24] insists,
for completeness reasons, on performing all possible inferences between the pro-
cessed clauses and the given clause, typically leading to a quadratic growth of
the set of generated clauses. However, if we had perfect information about the
proof, this would be wasteful and could be replaced by just performing the infer-
ences needed for the proof in each given clause loop. With parental guidance, we
instead propose to prune the given clause loop in a soft way: a trained predic-
tor judges the likelihood of the particular inference being needed for the proof.
When an inference is deemed useless, the clause is still generated but immedi-
ately frozen so that it does not have to be evaluated by additional heuristics.
The parental guidance is implemented using GBDTs (our parental model),
and the ﬁlter is directly put inside E’s given clause loop as follows. When E selects
a given clause g, E uses term indexes to eﬃciently determine which clauses can
be combined with g to generate new clauses. After generating the clauses, E
performs simpliﬁcations, removes trivial clauses, evaluates the remaining clauses
with the clause evaluation functions, and inserts them into the unprocessed set.
The call to the parental model is executed after the clause generation and prior to
the simpliﬁcations. Clauses generated by paramodulation, which also implements
resolution in E, have two parents, and these are judged by the parental model.
Clauses whose parents are jointly scored below a chosen threshold are put into
the freezer set to avoid impairing the completeness of the proof search. Clauses
with good parents continue on to the unprocessed set. In case the unprocessed
set becomes empty, the frozen clauses are revived and treated as usual.
Note that a naive alternative way to implement parental guidance would be to
evaluate each given clause’s compatibility with all previously processed clauses.
This would, however, result in many unnecessary GBDT queries and evaluations.
Instead, our approach allows E’s indexing to ﬁnd the typically much smaller set
of potential inferences and to limit the parental evaluation to them.5
There are various ways to represent the pair of parent clauses for the learning
of the parental model. In this work, we evaluate two methods:
4 The given clause loop is almost 50 years old as of 2021.
5 The eﬃciency boost obtained by using intelligent indexing is analogous to the boost
obtained by using our structure-aware GNN for context-based neural clause selection
(Sect. 2) rather than oﬀ-the-shelf Transformer models. The latter would quadratically
consider interactions of all symbols in the context and query clauses, decreasing the
evaluation speed by orders of magnitude, resulting in a very ineﬃcient prover.

Fast and Slow Enigmas and Parental Guidance
179
1. Pfuse merges the feature vectors of the parent clauses into one vector, typically
by simply adding the feature counts6
2. Pcat concatenates the feature vectors of the parent clauses to preserve their
information in full.
An interesting future alternative is to include the diﬀerence of the parents’ fea-
ture vectors in addition to their union and concatenation, which allows the
GBDT to choose the most informative features.
4
Experimental Setting and Baselines
4.1
Evaluation Problems and Training Data
All our experiments are performed7 on a large benchmark of 57 880 problems8
originating from the Mizar Mathematical Library (MML) [16] exported to ﬁrst-
order logic by MPTP [34]. We make use of our ongoing extensive evaluation of
many AI/TP methods over this corpus9 that measures the overall improvement
on this large dataset over the last similar evaluation done in [16]. In these exper-
iments we have signiﬁcantly extended our previously published results [10].10
Proofs of 73.5% (more than 40k) Mizar problems have been so far found by
learning-guided ATPs, and numerous GBDT and GNN models for ATP guid-
ance have been trained.
In that experiment, all Mizar problems11 are split (in a 90-5-5% ratio) into
3 subsets: (1) 52k problems for training, (2) 2896 problems for development,
and (3) 2896 problems for ﬁnal evaluation (holdout). We use this split here, and
additionally we use a random subset of 5792 of the training problems to speed
up the training of various experimental methods.
4.2
Baseline ENIGMA Models
Out of the 52k training problems, we were previously able to prove more than
36k problems, obtaining varied numbers of proofs for each problem (ranging
from 1 to hundreds). On these 36k problems we train our baseline GBDT and
GNN predictors. To balance the contribution of diﬀerent problems during the
training of the predictors, we randomly choose at most 3 proofs for every proved
training problem. This yields a set of about 100k proofs, denoted further as the
large (training) set. When limited to the 5792 random subset of the training
problems, this yields 11 748 proofs, denoted further as the small training set.
6 In some special cases of features, we instead take their maximum/minimum.
7 On a server with 36 hyperthreading Intel(R) Xeon(R) Gold 6140 CPU @ 2.30 GHz
cores, 755 GB of memory, and 4 NVIDIA GeForce GTX 1080 Ti GPUs.
8 http://grid01.ciirc.cvut.cz/∼mptp/1147/MPTP2/problems small consist.tar.gz.
9 https://github.com/ai4reason/ATP Proofs.
10 The publication of this large evaluation is in preparation.
11 http://grid01.ciirc.cvut.cz/∼mptp/Mizar eval ﬁnal split.

180
Z. A. Goertzel et al.
On the large set we train the ﬁrst baseline predictor denoted by Dlarge. This
is a GBDT model (implemented by the LightGBM framework) trained using
the ENIGMA Anonymous clause representation (Sect. 2). The model consists of
150 decision trees of depth 40 with 2048 leaves. This model was selected as it
performed best in our previous experiments with standard GBDTs, being able to
prove 1377 of the holdout problems using a 5 s limit per problem. Additionally,
we train another model Dsmall only on the small set of training problems. The
model Dsmall is a LightGBM model with 150 trees of depth 30 and with 9728
leaves. The training of Dlarge took around 27 min and the training of Dsmall around
10 min, both on 30 CPUs. These are relatively low and practical times compared
to the training of neural networks.
We also train baseline GNN models on the same data, denoted Glarge and
Gsmall respectively. The training of Glarge for 45 epochs takes about 15 h on the
full set of 100k proofs on a high-end NVIDIA V100 GPU card.12 It would likely
take days when training with CPUs only. We choose for the ATP evaluation the
(39th) snapshot that achieves both the best loss (0.2063) and the best weighted
accuracy (0.9147) on 5% of the data that we do not use for training. The training
of Gsmall for 100 epochs takes about 4 h on the small set using the same GPU
card. We choose for the ATP evaluation the (56th) snapshot that achieves the
best loss (0.2988) on 5% of the data that we do not use for training. The weighted
accuracy on this set is 0.8685, which is also among the highest values.
In the evaluation we run all our baseline ENIGMA predictors in an equal
combination with a strong non-learning E strategy S. This means that the pro-
cessed clauses are selected in (equal) turns by ENIGMA and by S. This coop
mode has typically worked better than the solo mode, where only the ENIGMA
predictor is doing the clause selection.
4.3
Training of the Parental GBDT Models
The training data for the parental guidance models are generated by running E
using either Dlarge or Glarge on the 52k training problems with a 30 s time limit
and by printing the derivation of all clauses generated during the proof search.13
We considered the following two schemes to classify the good pairs of parents
and to generate the training data:
1. Pproof classiﬁes parents of only the proof clauses as positive and all other
generated clauses as negative.
2. Pgiven classiﬁes parents of all processed (selected) clauses as positive and the
unprocessed generated clauses as negative.
The rationale behind Pproof is that every non-proof clause should be pruned
if possible. The rationale behind Pgiven is that if an eﬀective clause selection
strategy, such as Dlarge, predicted a clause to be useful, then it is probably worth
12 We use the same GNN hyper-parameters as in [10,23] with the exception of the
number of layers that we increase here to 10.
13 Using E’s option “--full-deriv”.

Fast and Slow Enigmas and Parental Guidance
181
generating. However, such data may be confusing as it includes clauses that did
not contribute to the proof.
If a pair of parents produces both positive and negative clauses, we consider
the pair positive in our implementation. However, this does not happen very
often. Based on a survey on the small set labeled according to Pproof
fuse , 73% of the
problems have no conﬂict. There are 1519 parents of both positive and negative
clauses, 53 359 are positive, and 6086 414 are negative. Under Pgiven
fuse , 9798 of
the parents are mixed, 854 778 are positive, and 5178 592 are negative. In either
case, the primary learning task is to identify and prune as many negative clauses
as possible without ﬁltering a necessary proof clause by mistake.
One parameter to experimentally tune is the pos-neg ratio used in the GBDT
training: the ratio of positive and negative examples. The pos-neg ratio is 1:192
over the large Pproof
fuse data, which is more than ten times more than the ratio of the
training data for Dlarge and Glarge. Hence, reducing the pos-neg ratio by randomly
sampling negative examples could further boost the training performance.
The parental guidance models are trained using GBDTs. Trained models are
evaluated in combination with the GBDT or GNN clause evaluation heuristic
using either the Dlarge or Glarge model, see Sect. 5.3.
5
Evaluation of the New Methods
5.1
Speedup by Using a GPU Server
First we measure the speedup obtained by evaluating the ENIGMA GNN calls
on a separate GPU server. To avoid network latency and for a cleaner compar-
ison, we run both the clients (E/ENIGMA) and the GPU server on the same
machine equipped with four NVIDIA GeForce GTX 1080 GPU cards and 36
hyperthreading CPU cores. We conﬁgure the server to use all four GPU cards.
Its other important parameters are the number of worker threads and the batch
size. We experimentally set them to 28 and 8, and we use Glarge for all proof runs.
Comparison of the CPU-only and GPU-server versions is complicated by the
fact that the server-based GNN evaluations do not count towards the CPU time
taken by E, as reported by the operating system. Still, a comparison using the
CPU time is interesting and we include it, using 30 and 60 s CPU limits for the
CPU-only version, and a 30 s CPU limit for the client-server version.
Another way to compare the two is by using parallelization, i.e., running
many instances of E in parallel. In the client-server version the instances talk to
the GPU server simultaneously. We saturate the machine’s CPUs fully for both
versions, and run for approximately equal overall real time over the development
and holdout sets. This is roughly achieved by using 60 s time limit with 70-fold
parallelization for the CPU version, and 30 s time limit with 160-fold paralleliza-
tion for the client/server version. The CPU version then takes about 27.5 min
to ﬁnish on the 2896 problems, while the client-server takes about 34 min to
ﬁnish. Table 1 compares the number of solved problems on the development and
holdout sets. The GPU server improves the performance on the development
resp. holdout sets by 9.5% resp. 11.5%.

182
Z. A. Goertzel et al.
We also compare the average number of generated clauses on the problems
that timed out in both versions. In the 60 s CPU version it is 16 835, while in
the 30 s client-server it is 63 305. This is a considerable speedup, achieved by
employing the additional custom hardware—our four GPU cards. The average
number of GNN queries in the 1358 problems that timed out in the 30 s GPU
server runs is 243.8, and on average the communication with the GPU server took
155 MB in a timed-out problem. A single GNN query took on average 637 kB.
Table 1. Comparison of the CPU-only GNN ENIGMA with the client-server version
using GPUs. All runs are evaluating Glarge on the whole development (D) and holdout
(H) datasets. The percentage improvement is computed over the 60 s CPU version that
corresponds more closely in real time to the client-server version. All runs use queries
of size 256 and contexts of size 768.
Set Model Method Time Solved
D
Glarge
CPU
30
1311
D
Glarge
CPU
60
1380
D
Glarge
GPU
30
1511 (+9.5%)
Set Model Method Time Solved
H
Glarge
CPU
30
1301
H
Glarge
CPU
60
1371
H
Glarge
GPU
30
1529 (+11.5%)
5.2
Evaluation of 2-Phase ENIGMA
Small GBDT and Small GNN: In the ﬁrst experiment we use the GBDT
and GNN predictors Dsmall and Gsmall trained on the small subset of the training
dataset. We ﬁrst do a grid search over the parameters on a smaller dataset of
300 development problems. Then we evaluate the best parameters on the devel-
opment and holdout sets and compare them with the standalone performance of
Gsmall, which is the stronger of the two baselines (Table 2). The best combined
methods are then evaluated also in 60 s. This gives a relatively fair real-time
comparison to the standalone GNN, because the reported CPU times do not
include the time taken by the GPU server.14
Our best combined method solves (in real time) 10.4%, resp. 9.0%, more
problems on the development, resp. holdout, set than the standalone GNN. This
is a signiﬁcant improvement, which will likely get even more visible with higher
time limits, because of the quadratic growth of the set of generated clauses. The
performance improvement over the standalone GBDT model is even larger.
14 We have made this estimate based on a comparison of real and CPU times done on
a set of problems that time out in both methods.

Fast and Slow Enigmas and Parental Guidance
183
Table 2. Final evaluation of the best combination of Dsmall with Gsmall on the whole
development (D) and holdout (H) datasets.
Set Model
Thresh. Time Query Context Solved
D
Gsmall
–
30
256
768
1251
D
Dsmall
–
30
–
–
1011
D
Dsmall+Gsmall 0.01
60
512
1024
1381 (+10.4%)
D
Dsmall+Gsmall 0.03
60
512
1024
1371 (+9.6%)
D
Dsmall+Gsmall 0.03
30
512
1024
1341 (+7.2%)
D
Dsmall+Gsmall 0.01
30
512
1024
1339 (+7.0%)
H
Gsmall
–
30
256
768
1277
H
Dsmall
–
30
–
–
1002
H
Dsmall+Gsmall 0.01
60
512
1024
1392 (+9.0%)
H
Dsmall+Gsmall 0.03
60
512
1024
1387 (+8.6%)
H
Dsmall+Gsmall 0.01
30
512
1024
1361 (+6.6%)
H
Dsmall+Gsmall 0.03
30
512
1024
1353 (+6.0%)
Large GBDT and Small GNN: In the next experiment, we want to see how
much the training of the less expensive model (GBDT) on more data helps. I.e.,
we replace Dsmall with Dlarge and keep Gsmall. This has practical applications in
real time, because cheaper ML predictors such as GBDTs are faster to train than
more expensive ones such as the GNN. We again ﬁrst do a grid search over the
parameters on a small dataset of 300 development problems. Then we evaluate
the best models on the development and holdout sets and compare them with
the standalone performance of Dlarge and Gsmall (Table 3). The best combined
methods are then again evaluated also in 60 s, which makes it comparable in
real time to the standalone GNN model.
Table 3. Final evaluation of the best combination of Dlarge and Gsmall on the whole
development (D) and holdout (H) datasets.
Set Model
Thresh. Time Query Context Solved
D
Gsmall
–
30
256
768
1251
D
Dlarge
–
30
–
–
1397
D
Dlarge+Gsmall 0.3
60
2048
768
1527 (+9.3%)
D
Dlarge+Gsmall 0.3
30
2048
768
1496 (+7.1%)
H
Gsmall
–
30
256
768
1277
H
Dlarge
–
30
–
–
1390
H
Dlarge+Gsmall 0.3
60
2048
768
1494 (+7.5%)
H
Dlarge+Gsmall 0.3
30
2048
768
1467 (+5.5%)

184
Z. A. Goertzel et al.
Our best combined method solves (in CPU time) 7.1%, resp. 5.5%, more
problems on the development, resp. holdout, set than the standalone GBDT.
For the GNN, this is (in real time) 9.3% resp. 7.5%. These are smaller gains
than in the previous Dsmall + Gsmall scenario, most likely because the stronger
predictor dominates here. Also note that the large query (2048) used in our
strongest model is typically diminished a lot by the GBDT pre-ﬁlter, resulting
in average query sizes after the GBDT pre-ﬁltering of 256–512.
Large GBDT and Large GNN: Finally, we evaluate the large setting, using
the GBDT and GNN predictors Dlarge and Glarge trained on the full training
dataset. Again, we ﬁrst do a grid search over the parameters on the small set
of 300 development problems. Then we evaluate the best parameters on the
development and holdout sets, and we compare them with the standalone per-
formance of Dlarge and Glarge (Table 4). The improvements on the development,
resp. holdout, set is 9.1%, resp. 7.3%, in real time, and 6.9%, resp. 4.8%, when
using CPU time. The E auto-schedule solves in 30 s (CPU time) 1020 of the
holdout problems. Our strongest 2-phase method solves 1602 of these problems
in the same CPU time, i.e., 57.1% more problems.
Table 4. Final evaluation of the best combination of Dlarge and Glarge on the whole
development (D) and holdout (H) datasets.
Set Model
Thresh. Time Query Context Solved
D
Glarge
–
30
256
768
1511
D
Dlarge
–
30
–
–
1397
D
Dlarge+Glarge 0.1
60
1024
768
1648 (+9.1%)
D
Dlarge+Glarge 0.1
30
1024
768
1615 (+6.9%)
H
Glarge
–
30
256
768
1529
H
Dlarge
–
30
–
–
1390
H
Dlarge+Glarge 0.1
60
1024
768
1640 (+7.3%)
H
Dlarge+Glarge 0.1
30
1024
768
1602 (+4.8%)
5.3
Evaluation of the Parental Guidance Combined with Dlarge
The parameters for parental guidance models are explored via a series of grid
searches to reduce the number of combinations. Initially, we only use Dlarge in con-
junction with the parental models. First, the training data classiﬁcation schemes,
Pproof
fuse
and Pgiven
fuse , are compared with a grid search over the pos-neg reduction
ratio. The best combination of reduction ratio and classiﬁcation scheme is used
to perform a grid search over LightGBM parameters for Pfuse. Next, reduction
ratio and LightGBM parameter grid searches are done with the Pcat featuriza-
tion method data, starting with the best Pfuse parameters from the previous

Fast and Slow Enigmas and Parental Guidance
185
experiments. Every model is evaluated with the same set of nine parental ﬁlter-
ing thresholds {0.005, 0.01, 0.03, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5}. The grid searches are
done over the 300 problem development set and run for 30 s. On this dataset,
Dlarge solves 159 problems.
Pos-Neg Reduction Ratio Tuning (Merge): The ﬁrst grid search examines
the pos-neg reduction ratio denoted as ρ. Before the reduction, the average pos-
neg ratio for Pgiven
fuse
is 1:9.2 and the average for Pproof
fuse
is 1:191.8. We reduce
the pos-neg ratio to a given ρ by randomly sampling the negative examples on
a problem-speciﬁc basis. This means that the average pos-neg ratio over the
whole dataset is typically a bit smaller than ρ. For example, using ρ = 4 on the
Pproof
fuse
results in an average of 3.95 times more negative than positive examples.
Both Pgiven
fuse
and Pproof
fuse
are tested using ρ ∈{−, 1, 2, 4, 8, 16} where “−” denotes
using the full training dataset. We use the best LightGBM model parameters
discovered during prototyping of the parental guidance features: the parameters
are 50 trees of depth 13 with 1024 leaves.
Table 5 shows that the reduction ratio makes signiﬁcant diﬀerence for the
Pproof
fuse data and almost none for Pgiven
fuse data, which is probably because the Pgiven
fuse
data are already reasonably balanced. Moreover, parental guidance seems to
perform better with Pproof
fuse
data than Pgiven
fuse
data, probably because mistakes of
Dlarge are included in the training data. In the following experiments, only the
Pproof classiﬁcation scheme is used (so the preﬁx is dropped).
Table 5. The best threshold for each tested reduction ratio. The threshold of 0.03
was identical to 0.05 for all tested ratios with Pgiven
fuse , whereas there are no ties among
thresholds for Pproof
fuse .
ρgiven
fuse
−
1
2
4
8
16
Threshold 0.05 0.05 0.05 0.05 0.05 0.05
Solved
161 161
161
161
161
160
ρproof
fuse
−
1
2
4
8
16
Threshold 0.005 0.2
0.2
0.2
0.2
0.2
Solved
111
164 163 165 162 164
Table 6. The best threshold for each tested reduction ratio of Pcat.
ρcat
−
1
2
4
8
16
Threshold 0.5
0.1
0.05 0.3
0.1
0.05
Solved
117 168 170
168 173 169
LightGBM Parameter Tuning (Merge): Next we perform the second grid
search over the LightGBM training hyper-parameters for Pfuse, ﬁxing ρ = 4 as it
performed best. We try the following values for the three main hyper-parameters,
namely, for the number of trees in a model, the maximum number of tree leaves,
and the maximum tree depth:

186
Z. A. Goertzel et al.
trees ∈{50, 100, 150}
leaves ∈{1024, 2048, 4096, 8192, 16384}
depth ∈{13, 40, 60, 256}
The best model for Pfuse solves 171 problems and consists of 100 trees, with the
depth 40, and 8192 leaves, and a threshold of 0.05. Another eight models solve
169 problems. We also tested these parameters to ﬁnd a better model for Pgiven
fuse ,
which solves 163 problems with ρ = 8 and a threshold of 0.1.
Pos-Neg Reduction Ratio Tuning (Concat): This grid search uses the
best LightGBM hyper-parameters for Pfuse to test the same reduction ratios and
thresholds for Pcat. Table 6 shows that Pcat outperforms Pfuse and ρ = 8 is the
best. Reducing the negatives is even more important here.
LightGBM Parameter Tuning (Concat): The grid search for the Pcat data
is done over the following hyper-parameters:
trees ∈{50, 100, 150, 200}
leaves ∈{1024, 2048, 4096, 8192, 16384, 32768}
depth ∈{13, 40, 60, 256, 512}
The upper limits have increased compared to the Pfuse grid-search because one
of the best models had 150 trees of depth 256, placing it at the edge of the
grid. The best models solve 174–175 problems. These are evaluated on the full
development set (Table 7). The larger models seem to work best with a threshold
of 0.05 and the smaller models with a threshold of 0.2, which is likely because
they can be less precise. The full distribution of the results can be seen in Fig. 1.
The number of parameter conﬁgurations that outperform the baseline suggests
that parental guidance is an eﬀective method.
Table 7. The best Pcat models with ρ = 8.
Trees Depth Leaves Threshold Solved (300) Solved (D)
200
60
4096
0.05
175
1557
200
512
4096
0.05
175
1561
200
256
4096
0.05
174
1558
150
512
1024
0.2
174
1568
150
256
1024
0.2
174
1556
100
60
8192
0.05
174
1571
100
40
2048
0.2
174
1544
100
40
2048
0.1
174
1544

Fast and Slow Enigmas and Parental Guidance
187
Table 8. Final 30 s evaluation on small trains (T), development (D), and holdout (H)
compared with Dlarge.
Model
Threshold Solved (T)
Solved (D)
Solved (H)
Dlarge
–
3269
1397
1390
Pgiven
fuse +Dlarge 0.05
3302 (+1.0%) 1411 (+1.0%)
1417 (+1.9%)
Pproof
fuse +Dlarge 0.1
3389 (+3.7%) 1489 (+6.6%)
1486 (+6.9%)
Pcat+Dlarge
0.05
3452 (+5.6%) 1571 (+12.4%) 1553 (+11.7%)
Finally we evaluate the best models on the small training, development, and
holdout sets, and we compare them with the standalone performance of Dlarge
(Table 8). Parental guidance achieves a signiﬁcant improvement in performance
on all datasets, solving 11.7% more on the holdout set. It is interesting to note
that the improvement is greater on the development and holdout sets than on
the training set. For parental guidance it seems superior to classify only proof
clauses as positive examples. This is most likely due to LightGBM being con-
fused by processed clauses that did not contribute to any proof. The method
of concatenating the parent clause feature vectors (Pcat) seems far superior to
merging them (Pfuse). This is likely because merging the features is lossy and
the order of the parents matters when performing inferences.
The results indicate that pruning clauses prior to clause evaluation is helpful.
ENIGMA models tend to run best in equal combination with a strong E strat-
egy, but this means they have no control over 50% of the clauses selected for
processing. The ability to ﬁlter which clauses the strong E strategy can evaluate
and select may be part of the strength behind parental guidance.
5.4
Parental Guidance with Glarge and 3-Phase ENIGMAs
We also explore a limited number of the most useful hyper-parameters from
Sects. 5.3 and 5.2 to combine the parental ﬁltering with ENIGMA-GNN using
Glarge and to create a 3-phase ENIGMA. We train a new LightGBM parental
ﬁltering model on the Pcat data generated by running Glarge, using ρ = 8,
trees = 100, leaves = 8192, and depth = 60. The grid search on the 300 develop-
ment problems leads to the best threshold values of 0.005 and 0.01 when using
context = 768 and query = 256 for ENIGMA-GNN with Glarge.
The version with the 0.01 threshold then reaches so far the highest value of
1621 development problems in 30 s CPU time. This is 50 more than the best
parental result using Dlarge and 6 more than the best 2-phase result. On the
holdout set this setting yields 1623 problems, i.e., 70 more than the best Dlarge
parental result and 21 more than the best 2-phase result.
Finally, we explore 3-phase ENIGMAs, i.e., combinations of all the methods
developed in this work. This means that we ﬁrst use the parental guidance
ﬁltering, followed by the 2-phase evaluation which in turn uses the GPU server.
This implies a higher evaluation cost, since both the parental and the ﬁrst-stage
LightGBM models are loaded on startup and are used to ﬁlter the clauses.

188
Z. A. Goertzel et al.
Fig. 1. The number of settings (and runs) corresponding to each number of solutions
for the Pcat grid search. The black bar is 159, the number of problems solved by Dlarge.
Only 154 (20%) of the runs interfere with Dlarge’s performance and solve fewer problems.
These runs largely consist of the thresholds, {0.3, 0.4, 0.5}, but the only parameter
whose majority of runs score below Dlarge is a threshold of 0.5. The outliers tend to be
larger models.
We only tune the parental threshold and context and query values, keeping
the 2-phase threshold ﬁxed at 0.1. The best result is again obtained by setting
the parental threshold to 0.01, context = 768 and query = 256. This solves 1631
resp. 1632 of the development resp. holdout problems in 30 s CPU time. This is
our ultimate result, which is exactly 60% higher than the 1020 problems solved
by E’s auto-schedule in 30 s CPU time. It is also 17.4% higher than the best
ENIGMA result prior to this work (1390 by standalone Dlarge).
6
Conclusion and Examples
We have described several additions to the ENIGMA system. The new methods
combine fast(er) and smart(er) clause evaluation using ENIGMA’s parameter-
izable learning-based setting. The GPU server allows much faster runs of the
neurally-guided ENIGMA, improving its real-time performance by about 10%.
The parental guidance allows one to train clause evaluation diﬀerently from stan-
dard ENIGMA, providing an improvement of 11.7% on the holdout set. Both
when training on small and on large datasets, the 2-phase methods provide good
improvements on the holdout sets (9% and 7.3%) over the strongest standalone
methods. The methods are adjustable and they will likely lead to even higher
improvements in longer runtimes, due to the typically quadratic growth of the

Fast and Slow Enigmas and Parental Guidance
189
set of generated clauses in saturation-style ATPs. Our strongest 3-phase method
improves E’s auto-schedule on the holdout set by 60% in 30 s and our best prior
ENIGMA result by 17.4%.
Several examples of the new proofs produced only by the methods developed
here are available on our project’s web page. Theorem INTEGR13:2715 about
the diﬀerentiation of −cot(ln(x)) needed 3904 nontrivial given clause loops and
38826 nontrivial generated clauses, taking only 18 s with the 2-phase ENIGMA.
This can be compared to the previous related theorem FDIFF 7:3616 (diﬀerenti-
ation of exp(cos(x))) done in the old setting, taking 28.4 s to do only 1284 non-
trivial given clause loops and 13287 nontrivial generated clauses. Other examples
include a 486-long proof17 of a theorem about integrals done only in 41 s with the
2-phase ENIGMA evaluating 100k clauses, or a 259-long computational proof18
about Fermat primes found in 11 s while evaluating 52k clauses. Such proofs
are found despite hundreds of redundant axioms, by using new combinations of
faster and smarter trained ENIGMAs that eﬃciently guide the search.
Acknowledgments. This work was partially supported by the ERC Consolidator
grant AI4REASON no. 649043 (ZG, JJ, and JU), the European Regional Development
Fund under the Czech project AI&Reasoning no. CZ.02.1.01/0.0/0.0/15 003/0000466
(ZG, JU, KC), the ERC Starting Grant SMART no. 714034 (JJ, MO), and by the
Czech MEYS under the ERC CZ project POSTMAN no. LL1902 (JJ).
References
1. Abadi, M., et al.: TensorFlow: large-scale machine learning on heterogeneous dis-
tributed systems. arXiv preprint arXiv:1603.04467 (2016)
2. Chen, T., Guestrin, C.: XGBoost: a scalable tree boosting system. In: Proceedings
of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining, KDD 2016, pp. 785–794. ACM, New York (2016)
3. Chvalovsk´y, K., Jakub˚uv, J., Suda, M., Urban, J.: ENIGMA-NG: eﬃcient neural
and gradient-boosted inference guidance for E. In: Fontaine, P. (ed.) CADE 2019.
LNCS (LNAI), vol. 11716, pp. 197–215. Springer, Cham (2019). https://doi.org/
10.1007/978-3-030-29436-6 12
4. Fan, R.-E., Chang, K.-W., Hsieh, C.-J., Wang, X.-R., Lin, C.-J.: LIBLINEAR: a
library for large linear classiﬁcation. J. Mach. Learn. Res. 9, 1871–1874 (2008)
5. Gittins, J.C.: Bandit processes and dynamic allocation indices. J. Roy. Stat. Soc.
Ser. B (Methodol.) 41, 148–177 (1979)
6. Goertzel, Z., Jakub˚uv, J., Schulz, S., Urban, J.: ProofWatch: watchlist guidance
for large theories in E. In: Avigad, J., Mahboubi, A. (eds.) ITP 2018. LNCS, vol.
10895, pp. 270–288. Springer, Cham (2018). https://doi.org/10.1007/978-3-319-
94821-8 16
15 https://github.com/ai4reason/ATP Proofs/#diﬀerentiation---cot--ln-x--1--x--sin-
ln-x2-.
16 https://github.com/ai4reason/ATP Proofs/#diﬀerentiation-exp r--cos--x----
exp r--cos--x--sin-x.
17 https://github.com/ai4reason/ATP Proofs/#integral-chi-aa-is-integrable--
integral-chi-aa--vol-a-486-long-atp-proof-from-63-premises.
18 https://github.com/ai4reason/ATP Proofs/#17-is-prime.

190
Z. A. Goertzel et al.
7. Goertzel,
Z.,
Jakub˚uv,
J.,
Urban,
J.:
ENIGMAWatch:
ProofWatch
meets
ENIGMA. In: Cerrito, S., Popescu, A. (eds.) TABLEAUX 2019. LNCS (LNAI),
vol. 11714, pp. 374–388. Springer, Cham (2019). https://doi.org/10.1007/978-3-
030-29026-9 21
8. Gottlob, G., Sutcliﬀe, G., Voronkov, A. (eds.): Global Conference on Artiﬁcial
Intelligence, GCAI 2015, Tbilisi, Georgia, 16–19 October 2015, Volume 36 of EPiC
Series in Computing. EasyChair (2015)
9. Hillenbrand, T.: Citius altius fortius: lessons learned from the theorem prover
WALDMEISTER. ENTCS 86(1), 9–21 (2003)
10. Jakub˚uv, J., Chvalovsk´y, K., Olˇs´ak, M., Piotrowski, B., Suda, M., Urban, J.:
ENIGMA anonymous: symbol-independent inference guiding machine (system
description). In: Peltier, N., Sofronie-Stokkermans, V. (eds.) IJCAR 2020. LNCS
(LNAI), vol. 12167, pp. 448–463. Springer, Cham (2020). https://doi.org/10.1007/
978-3-030-51054-1 29
11. Jakub˚uv, J., Urban, J.: ENIGMA: eﬃcient learning-based inference guiding
machine. In: Geuvers, H., England, M., Hasan, O., Rabe, F., Teschke, O. (eds.)
CICM 2017. LNCS (LNAI), vol. 10383, pp. 292–302. Springer, Cham (2017).
https://doi.org/10.1007/978-3-319-62075-6 20
12. Jakub˚uv, J., Urban, J.: Enhancing ENIGMA given clause guidance. In: Rabe, F.,
Farmer, W.M., Passmore, G.O., Youssef, A. (eds.) CICM 2018. LNCS (LNAI),
vol. 11006, pp. 118–124. Springer, Cham (2018). https://doi.org/10.1007/978-3-
319-96812-4 11
13. Jakub˚uv, J., Urban, J.: Hierarchical invention of theorem proving strategies. AI
Commun. 31(3), 237–250 (2018)
14. Jakub˚uv, J., Urban, J.: Hammering Mizar by learning clause guidance. In: Harri-
son, J., O’Leary, J., Tolmach, A. (eds.) 10th International Conference on Interactive
Theorem Proving, ITP 2019, Portland, OR, USA, 9–12 September 2019, LIPIcs,
vol. 141, pp. 34:1–34:8. Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik (2019)
15. Kaliszyk, C.: Eﬃcient low-level connection tableaux. In: De Nivelle, H. (ed.)
TABLEAUX 2015. LNCS (LNAI), vol. 9323, pp. 102–111. Springer, Cham (2015).
https://doi.org/10.1007/978-3-319-24312-2 8
16. Kaliszyk, C., Urban, J.: MizAR 40 for Mizar 40. J. Autom. Reasoning 55(3), 245–
256 (2015)
17. Kaliszyk, C., Urban, J., Michalewski, H., Ols´ak, M.: Reinforcement learning of
theorem proving. In: Advances in Neural Information Processing Systems 31:
Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018,
Montr´eal, Canada, 3–8 December 2018, pp. 8836–8847 (2018)
18. Ke, G., et al.: LightGBM: a highly eﬃcient gradient boosting decision tree. In:
NIPS, pp. 3146–3154 (2017)
19. Kinyon, M., Veroﬀ, R., Vojtˇechovsk´y, P.: Loops with abelian inner mapping groups:
an application of automated deduction. In: Bonacina, M.P., Stickel, M.E. (eds.)
Automated Reasoning and Mathematics. LNCS (LNAI), vol. 7788, pp. 151–164.
Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-36675-8 8
20. Kov´acs, L., Voronkov, A.: First-order theorem proving and Vampire. In: Shary-
gina, N., Veith, H. (eds.) CAV 2013. LNCS, vol. 8044, pp. 1–35. Springer, Heidel-
berg (2013). https://doi.org/10.1007/978-3-642-39799-8 1
21. Loos, S.M., Irving, G., Szegedy, C., Kaliszyk, C.: Deep network guided proof search.
In: Eiter, T., Sands, D. (eds.) LPAR-21, 21st International Conference on Logic for
Programming, Artiﬁcial Intelligence and Reasoning, Maun, Botswana, 7–12 May
2017, EPiC Series in Computing, vol. 46, pp. 85–105. EasyChair (2017)

Fast and Slow Enigmas and Parental Guidance
191
22. McCune, W.: Experiments with discrimination-tree indexing and path indexing
for term retrieval. J. Autom. Reasoning 9(2), 147–167 (1992)
23. Ols´ak, M., Kaliszyk, C., Urban, J.: Property invariant embedding for automated
reasoning. In: De Giacomo, G., et al. (eds.) ECAI 2020–24th European Conference
on Artiﬁcial Intelligence, 29 August-8 September 2020, Santiago de Compostela,
Spain, 29 August–8 September 2020 - Including 10th Conference on Prestigious
Applications of Artiﬁcial Intelligence (PAIS 2020), Frontiers in Artiﬁcial Intelli-
gence and Applications, vol. 325, pp. 1395–1402. IOS Press (2020)
24. Overbeek, R.A.: A new class of automated theorem-proving algorithms. J. ACM
21(2), 191–200 (1974)
25. Raths, T., Otten, J.: randoCoP: randomizing the proof search order in the con-
nection calculus. In: Konev, B., Schmidt, R.A., Schulz, S. (eds.) Proceedings of
the First International Workshop on Practical Aspects of Automated Reasoning,
Sydney, Australia, 10–11 August 2008, CEUR Workshop Proceedings, vol. 373.
CEUR-WS.org (2008)
26. Ruhdorfer, C., Schulz, S.: Eﬃcient implementation of large-scale watchlists. In:
Fontaine, P., Korovin, K., Kotsireas, I.S., R¨ummer, P., Tourret, S. (eds.) Joint
Proceedings of the 7th Workshop on Practical Aspects of Automated Reasoning
(PAAR) and the 5th Satisﬁability Checking and Symbolic Computation Workshop
(SC-Square) Workshop, 2020 Co-Located with the 10th International Joint Con-
ference on Automated Reasoning (IJCAR 2020), Paris, France, June–July 2020
(Virtual), CEUR Workshop Proceedings, vol. 2752, pp. 120–133. CEUR-WS.org
(2020)
27. Sch¨afer, S., Schulz, S.: Breeding theorem proving heuristics with genetic algorithms.
In: Gottlob et al. [8], pp. 263–274
28. Schulz, S.: Fingerprint indexing for paramodulation and rewriting. In: Gramlich,
B., Miller, D., Sattler, U. (eds.) IJCAR 2012. LNCS (LNAI), vol. 7364, pp. 477–
483. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-31365-3 37
29. Schulz, S.: System description: E 1.8. In: McMillan, K., Middeldorp, A., Voronkov,
A. (eds.) LPAR 2013. LNCS, vol. 8312, pp. 735–743. Springer, Heidelberg (2013).
https://doi.org/10.1007/978-3-642-45221-5 49
30. Schulz, S., Cruanes, S., Vukmirovi´c, P.: Faster, higher, stronger: E 2.3. In: Fontaine,
P. (ed.) CADE 2019. LNCS (LNAI), vol. 11716, pp. 495–507. Springer, Cham
(2019). https://doi.org/10.1007/978-3-030-29436-6 29
31. Stickel, M.E.: The path-indexing method for indexing terms. Technical report, SRI
International Menlo Park CA Artiﬁcial Intelligence Center (1989)
32. Sutcliﬀe, G., Suttner, C.B.: The state of CASC. AI Commun. 19(1), 35–48 (2006)
33. Sutcliﬀe, G., Urban, J.: The CADE-25 automated theorem proving system com-
petition - CASC-25. AI Commun. 29(3), 423–433 (2016)
34. Urban, J.: MPTP 0.2: design, implementation, and initial experiments. J. Autom.
Reasoning 37(1–2), 21–43 (2006)
35. Urban, J.: BliStr: the blind strategymaker. In: Gottlob et al. [8], pp. 312–319
36. Urban, J., Vyskoˇcil, J., ˇStˇep´anek, P.: MaLeCoP machine learning connection
prover. In: Br¨unnler, K., Metcalfe, G. (eds.) TABLEAUX 2011. LNCS (LNAI),
vol. 6793, pp. 263–277. Springer, Heidelberg (2011). https://doi.org/10.1007/978-
3-642-22119-4 21
37. Veroﬀ, R.: Using hints to increase the eﬀectiveness of an automated reasoning
program: case studies. J. Autom. Reasoning 16(3), 223–239 (1996)
38. Voronkov, A.: The anatomy of Vampire implementing bottom-up procedures with
code trees. J. Autom. Reasoning 15(2), 237–265 (1995)

Vampire with a Brain Is a Good ITP
Hammer
Martin Suda(B)
Czech Technical University in Prague, Prague, Czech Republic
martin.suda@cvut.cz
Abstract. Vampire has been for a long time the strongest ﬁrst-order
automatic theorem prover, widely used for hammer-style proof automa-
tion in ITPs such as Mizar, Isabelle, HOL, and Coq. In this work, we con-
siderably improve the performance of Vampire in hammering over the full
Mizar library by enhancing its saturation procedure with eﬃcient neural
guidance. In particular, we employ a recently proposed recursive neural
network classifying the generated clauses based only on their derivation
history. Compared to previous neural methods based on considering the
logical content of the clauses, our architecture makes evaluating a single
clause much less time consuming. The resulting system shows good learn-
ing capability and improves on the state-of-the-art performance on the
Mizar library, while proving many theorems that the related ENIGMA
system could not prove in a similar hammering evaluation.
1
Introduction
The usability of interactive theorem provers (ITPs) is signiﬁcantly enhanced by
proof automation. In particular, employing so-called hammers [6], systems that
connect the ITP to an automatic theorem prover (ATP), may greatly speed up
the formalisation process.
There are two ingredients of the hammer technology that appear to be best
implemented using machine learning, especially while taking advantage of the
corresponding large ambient ITP libraries, which can be used for training. One
is the premise selection task, in which the system decides on a manageable sub-
set of the most relevant facts from the ITP library to be passed to the ATP as
axioms along with the current conjecture [1,2,10,29,44]. The other is the internal
guidance of the ATP’s proof search [11,42], where a machine-learned component
helps to resolve some form of don’t-care non-determinism in the prover algorithm
with the aim of speeding up the proof search. In the predominant saturation-based
proving paradigm, employed by the leading ATPs such as E [35], SPASS [45], or
Vampire [24], internal guidance typically focuses on the clause selection choice
point [20,26].
ENIGMA [7,19–21] is a system delivering internal proof search guidance
driven by state-of-the-art machine learning methods to the automatic theorem
prover E [35]. In 2019, the authors of ENIGMA announced [22] a 70% improve-
ment (in terms of the number of problems solved under a certain wall clock time
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 192–209, 2021.
https://doi.org/10.1007/978-3-030-86205-3_11

Vampire with a Brain Is a Good ITP Hammer
193
limit) of E on the Mizar mathematical library (MML) [17]. This was achieved
using gradient boosted trees coupled with a clause representation by eﬃciently
extracted manually designed features.
In our recent work [39], we presented an enhancement of the automatic the-
orem prover Vampire [24] by a new form of clause selection guidance. The idea
is to employ a recursive neural network [15] and to train it to classify clauses
based solely on their derivation history. This means we deliberately abstract
away the logical content of a clause, i.e. “what the clause says”, and only focus
on “where the clause is coming from (and how)”. There is a pragmatic appeal
in this design decision: evaluating a clause becomes relatively fast compared to
other approaches based on neural networks (cf., e.g., [7,26]). It is also very inter-
esting that such a simple approach works at all, let alone being able to match
or even improve on the existing “better informed” methods.
We originally developed and evaluated [39] the architecture in the experi-
mental setting of theory reasoning over the SMT-LIB library. In this paper, we
instead explore its utility for improving the performance of Vampire in the role of
an ITP hammer, focusing on the well-established Mizar benchmark [23]. Mizar
requires the architecture to be adapted to a diﬀerent set of features, notably a
much larger set of background axioms (used instead of theory axioms) and a
conjecture. While we previously [39] evaluated various modes of integrating the
learned guidance and some supporting techniques, here we conduct new experi-
ments that shed light on how the behaviour of the prover changes with varying
parameters of the network itself. Finally, our evaluation allows for a direct com-
parison with the ENIGMA work of Jakub˚uv and Urban [22].
In the rest of this paper, we ﬁrst recall (in Sect. 2) how the saturation-based
ATP technology can be enhanced by internal guidance learnt from previous
proofs. We then explain (in Sect. 3) how to construct and train recursive neural
networks as successful classiﬁers of clause derivations. While there is a certain
overlap with our previous work [39], the new benchmark allows for the incorpo-
ration of conjecture-related features (Sect. 3.2) and we also ﬁnd room to explain
how to eﬃciently train our networks using parallelisation (Sect. 3.4). Finally, we
report (in Sect. 4) on an experimental evaluation of our extension of Vampire
with the described techniques over the Mizar mathematical library.
2
Internal Guidance of an ATP Using Machine Learning
Modern automatic theorem provers (ATPs) for ﬁrst-order logic such as E [35],
SPASS [45], or Vampire [24] are one of the most mature tools for general rea-
soning in a variety of domains. In a nutshell, they work in the following way.
Given a list of axioms A1, . . . , Al and a conjecture G to prove, an ATP trans-
lates {A1, . . . , Al, ¬G} into an equisatisﬁable set of initial clauses C. It then tries to
derive a contradiction ⊥from C (thus showing that A1, . . . , Al |= G) using a logical
calculus, such as resolution or superposition [4,27]. The employed process of itera-
tively deriving (according to the inference rules of the calculus) new clauses, logical
consequences of C, is referred to as saturation and is typically implemented using

194
M. Suda
some variant of a given-clause algorithm [32]: in each iteration, a single clause
C is selected and inferences are performed between C and all previously selected
clauses. Deciding which clause to select next is known to be a key heuristical choice
point, hugely aﬀecting the performance of an ATP [36].
The idea to improve clause selection by learning from past prover experience
goes (to the best of our knowledge) back to Schulz [9,34] and has more recently
been successfully employed by the ENIGMA system [7,19–21] and variations
[3,8,26]. Experience is collected from successful prover runs, where each selected
clause constitutes a training example and the example is marked as positive if
the clause ended up in the discovered proof, and negative otherwise. A machine
learning (ML) algorithm is then used to ﬁt this data and produce a model M for
classifying clauses into positive and negative, accordingly. A good learning algo-
rithm produces a model M which accurately classiﬁes the training data but also
generalizes well to unseen examples; ideally, of course, with a low computational
cost of both (1) training and (2) evaluation.
When a model is prepared, we need to integrate its advice back to the prover’s
clause selection process. An ATP typically organizes this process by maintain-
ing a set of priority queues, each ordering the yet-to-be-processed clauses by a
certain criterion, and alternates—under a certain conﬁgurable ratio—between
selecting the best clause from each queue. One way of integrating the learnt
advice, adopted by ENIGMA, is to add another queue QM in which clauses are
ordered such that those positively classiﬁed by M precede the negatively clas-
siﬁed ones, and extend the mentioned ratio such that QM is used for, e.g., half
of the selections (while the remaining ones fall back to the original strategy).
In this work, we rely instead on the layered clause selection paradigm [13,14,
40], in which a clause selection mechanism inherited from an underlying strategy
is applied separately to the set A of clauses classiﬁed as positive by M and to the
set B of all yet-to-be-processed clauses (i.e., A ⊆B). A “second level” ratio then
dictates how often will the prover relay to select from either of these two sets.
For example, with a second-level ratio 2:1, the prover will select twice from A
(unless A is currently empty and a fallback to B happens) before selecting once
from B. An advantage of this approach is that the original, typically well-tuned,
selection mechanism is still applied within both A and B.1
3
Neural Classiﬁcation of Clause Derivations
In our previous work [39], we introduced a method for classifying clauses for
clause selection based on their derivation history, i.e., ignoring the logical content
of the clauses. Each clause is characterised by the initial clauses from which it
was derived, the inference rules by which it was derived, and the exact way
in which the rules were used to derive it. The method relies on a recursive
neural network (RvNN) as the machine learning architecture, with the recursion
running “along” the clause derivations, starting oﬀfrom the initial clauses.
1 We compared and empirically evaluated various modes of integrating the model
advice into the clause selection process in our previous work [39].

Vampire with a Brain Is a Good ITP Hammer
195
The previous work [39] focused on the SMT-LIB benchmark [5] and on the
aspect of theory reasoning in Vampire implemented by adding theory axioms to
formalise various theories of interest (arithmetic, arrays, data structures, . . . ).
Together with the actual problem formulation, i.e., the user-supplied axioms, the
theory axioms become the initial clauses to start oﬀthe recursion for a RvNN.
Because these theory axioms are added by Vampire itself, their use in derivations
can be traced and meaningfully compared across problems from diﬀerent sources
such as those comprising SMT-LIB.
In this paper, we adapt the method to work with a diﬀerent benchmark,
namely, the Mizar40 [23] problem set (see Sect. 4 for more details). There is no
explicit theory reasoning (in the sense of “satisﬁability modulo theories”) needed
to solve problems in this benchmark. On the other hand, many axioms appear in
many problems across the Mizar40 benchmark and they are consistently named.
We rely on these consistently named axioms to seed the recursion here.
In this section, we ﬁrst recall the general RvNN architecture for learning from
clause derivations. We then explain how this can be enhanced by incorporat-
ing information about the conjecture (which is missing in SMT-LIB). We avoid
repeating the technical details mentioned previously [39], but include a subsec-
tion on our parallel training setup that we believe is of independent interest.
3.1
A Recursive Neural Network Clause Derivation Classiﬁer
A recursive neural network (RvNN) is a network created by composing a ﬁnite
set of neural building blocks recursively over a structured input [15].
In our case, the structured input is a clause derivation: a directed acyclic
(hyper-)graph (DAG) with the initial clauses C ∈C as leaves and the derived
clauses as internal nodes, connected by (hyper-)edges labeled by the correspond-
ing applied inference rules. To enable the recursion, an RvNN represents each
node C by a real vector vC (of ﬁxed dimension n) called a (learnable) embedding.
During training, our network learns to embed the space of derivable clauses into
Rn in a priori unknown, but hopefully reasonable way.
We assume that each initial clause C can be identiﬁed with an axiom AC
from which it was obtained through clausiﬁcation (unless it comes from the
conjecture) and that these axioms form a ﬁnite set A, ﬁxed for the domain of
interest. Now, the speciﬁc building blocks of our architecture are (mainly; see
below) the following three (indexed families of) functions:
– for every axiom Ai ∈A, a nullary init function Ii ∈Rn which to an initial
clause C ∈C obtained through clausiﬁcation from the axiom Ai assigns its
embedding vC := Ii,
– for every inference rule r, a deriv function, Dr : Rn×· · ·×Rn →Rn which to a
conclusion clause Cc derived by r from premises (C1, . . . , Ck) with embeddings
vC1, . . . , vCk assigns the embedding vCc := Dr(vC1, . . . , vCk),
– and, ﬁnally, a single eval function E : Rn →R which evaluates an embedding
vC such that the corresponding clause C is classiﬁed as positive whenever
E(vC) ≥0 and negative otherwise.

196
M. Suda
By recursively composing these functions, any derived clause C can be assigned
an embedding vC and can be evaluated to see whether the network recommends
it as positive, that should be preferred in the proof search, or negative, which
will (according to the network) not likely contribute to a proof. Notice that the
amortised cost of evaluating a single clause by the network is low, as it amounts
to a constant number of function compositions.
3.2
Information Sources, the Conjecture, and SInE Levels
Let us ﬁrst spend some time here to consider what kind of information about a
clause can the network take into account to perform its classiﬁcation.
The assumption about a ﬁxed axiom set enables meaningfully carrying
between problems observations about which axioms and their combinations
quickly lead to good lemmas and which are, on the other hand, rarely useful. We
believe this is the main source of information for the network to classify well. How-
ever, it may not be feasible to represent in the network all the axioms available in
the benchmark. It is then possible to only reveal a speciﬁc subset to the network
and represent the remaining ones using a single special embedding Iunknown.
Another, less obvious, source of information are the inference rules. Since
there are distinct deriv functions Dr for every rule r, the network can also take
into account that diﬀerent inference rules give rise to conclusions of diﬀerent
degrees of usefulness. In Sect. 4.4, we dedicate an experiment to establishing
how much this aspect of the architecture helps clause classiﬁcation.
Finally, we always “tell the network” what the current conjecture G is by
marking the conjecture clauses using a special initial embedding Igoal.2 Focusing
search on the conjecture is a well-known theorem proving heuristic and we give
the network the opportunity to establish how strongly this heuristic should be
taken into account.
We actually implemented a stronger version of the conjecture-focus idea by
precomputing (and incorporating into the network) for every initial clause its
SInE level [13,18,38]. A SInE level is a heuristical distance of a formula from the
conjecture along a relation deﬁned by sharing signature symbols [38]. Roughly,
the SInE levels are computed as a byproduct of the iterative SInE premise selec-
tion algorithm [18], where we assign the level l to axiom A if the SInE algorithm
ﬁrst considers adding axiom A among the premises in its l-th iteration. Thus, the
conjecture itself is assigned level 0, and a typical conﬁguration of the algorithm
on a typical formula (as witnessed by our experiments) assigns levels between 1
to around 10 to the given axioms.
To incorporate SInE levels into our network, we pass the embedding I ∈Rn
produced by an init function through an additional (learnable) SInE embedder
function S : Rn × R →Rn. Thus, an initial clause C ∈C obtained through
clausiﬁcation from the axiom Ai and with a SInE level l receives an embedding
2 By special we mean “in principle distinct”. Since all the embeddings are learnable,
the network itself “decides” during training how exactly to distinguish Igoal and all
the other axioms embeddings Ii (and also the “generic” Iunknown).

Vampire with a Brain Is a Good ITP Hammer
197
S(Ii, l) ∈Rn. Also the eﬀect of enabling or disabling this extension is demon-
strated in the experiments in Sect. 4.4.
3.3
Training the Network
Our RvNN is parametrized by a tuple of learnable parameters
Θ
=
(θI, θD, θE, θS) which determine the corresponding init, deriv, eval, and SInE
embedder functions (please consult our previous work [39], Sect. 4.2, for addi-
tional details). To train the network means to ﬁnd suitable values for these
parameters such that it successfully classiﬁes positive and negative clauses from
the training data and ideally also generalises to unseen future cases.
We follow a standard methodology for training our networks. In particular,
we use the gradient descent (GD) optimization algorithm minimising a binary
cross-entropy loss [16]. Every clause in a derivation DAG selected by the sat-
uration algorithm constitutes a contribution to the loss, with the clauses that
participated in the found proof receiving the target label 1.0 (positive example)
and the remaining ones the label 0.0 (negative example). We weight these con-
tributions such that each derivation DAG (corresponding to a prover run on a
single problem) receives equal weight, and, moreover, within each DAG we scale
the importance of positive and negative examples such that these two categories
contribute evenly.
We split the available successful derivations into 90% training set and 10%
validation set, and only train on the ﬁrst set using the second to observe gener-
alisation to unseen examples. As the GD algorithm progresses, iterating over the
training data in rounds called epochs, typically, the loss on the training exam-
ples steadily decreases while the loss on the validation set at some point stops
improving or even starts getting worse. In our experiments, we always pick the
model with the smallest validation loss for evaluation with the prover, as these
models were shown to lead to the best performance in our previous work [39].
3.4
Implementation and the Parallel Training Setup
We implemented an infrastructure for training an RvNN clause derivation clas-
siﬁer in Python, using the PyTorch (version 1.7) library [28] and its TorchScript
extension for later interfacing the trained model from C++.3
PyTorch is built around the concept of dynamic computational graphs for the
calculation of gradient values required by the GD algorithm. This is an extremely
ﬂexible approach in which the computational graph is automatically constructed
while executing code that looks like simply performing the vector operations
pertaining to evaluating the network’s concrete instance on a concrete set of
training examples (corresponding, in our case, to a concrete clause derivation).
A downside of this approach is that the computational graph cannot be stored
and reused when the same example is to be evaluated and used for training in
the next epoch. As a consequence, most of the time of training an RvNN like
ours is spent on constructing computational graphs over and over again.
3 The implementation is available as a public repo at https://git.io/JOh6S.

198
M. Suda
Batching: One general way of speeding up the training of a neural network
amounts to grouping training examples into reasonably sized sets called batches
and processing them in parallel—in the sense of single instruction multiple data
(SIMD)—typically on a specialized hardware such as a GPU. However, this is
most easily done only when the training examples have the same shape and can
be easily aligned, such as, e.g., with images, and is not immediately available
with RvNNs.4
Because each clause derivation that we want to process in training is in
general of a unique shape, we do not attempt to align multiple derivations to
beneﬁt from SIMD processing. Instead, we create batches by merging multiple
derivations to simply create DAGs of comparable size (some derivations are
relatively small, while the largest we encountered were of the order of hundred
thousand nodes). By merging we mean: (1) putting several derivations next to
each other, and (2) identifying and collapsing nodes that are indistinguishable
from the point of view of the computation our RvNN performs.5 This means
that a batch contains at most one node for all initial clauses corresponding to
the conjecture or at most one node for all clauses derived from two such initial
clauses in a single step by resolution, etc. When collapsing nodes from diﬀerent
derivations, we make sure to compute the correct target labels and their weights
to preserve the semantics the network had before the merge.6
A Multi-process Training Architecture:
To utilise parallelism and speed up
the training in our case (i.e., with similarly sized but internally heterogenous
batches), we implemented a master-worker multiprocess architecture to be run
on a computer with multiple CPUs (or CPU cores).
The idea is that a master process maintains a single oﬃcial version of the
network (in terms of the learnable parameters Θ) and dispatches training tasks
to a set of worker processes. A training task is a pair (Θt, B) where Θt is the
current version of the network at time t (the moment when the task is issued by
the master process) and B is a selected batch. A worker process constructs the
computation graph corresponding to B, performs a back-propagation step, and
sends the obtained gradient ∇Θt(B) back to the master. The master dispatches
tasks and receives gradients from ﬁnished workers using two synchronization
queues. The master updates the oﬃcial network after receiving a gradient from
a worker via
ΘT +1 ←ΘT −α∇Θt(B),
where α is the learning rate.
A curious aspect of our architecture is that ΘT , the network the master
updates at moment T using ∇Θt(B), is typically a later version than Θt from
which the corresponding task has been derived. In other words, there is a certain
4 There exist non-trivial preprocessing techniques for achieving graph batching [25].
5 The latter is already relevant within a single derivation (c.f. [39], Sect. 4.4).
6 E.g., a node can be designated a positive example (label 1.0, weight w1) in one
derivation and a negative one (label 0.0, weight w2) in another. The corresponding
collapsed node receives the label w1/(w1 + w2) and weight (w1 + w2).

Vampire with a Brain Is a Good ITP Hammer
199
drift between the version of the network an update has been computed for and
the version the update is eventually applied to. This drift arises because the
master issues a task as soon as there is a free worker and receives an update as
soon as there is a ﬁnished worker. In a sense, such drift is necessary if we want
to keep the workers busy and capitalise on parallelisation at all.
Surprisingly, the drift seems to have a beneﬁcial eﬀect on learning in the
sense that it helps to prevent overﬁtting. Indeed, we were able to train models
with slightly smaller validation loss using parallelisation than without it.7
4
Experiments
We implemented clause selection guidance (Sect. 2) by a recursive neural network
classiﬁer for clause derivations (Sect. 3) in the automatic theorem prover Vampire
(version 4.5.1).8 In our previous work [39], we used the SMT-LIB benchmark [5]
and empirically compared several modes of integration of the learned advice into
the prover as well as several supporting techniques. In this paper, we set out with
the best conﬁguration identiﬁed therein9 and focus on evaluating various aspects
of the neural architecture itself and do that using the problems from the Mizar
mathematical library.
Following Jakub˚uv and Urban [22], we use the Mizar40 [23] benchmark con-
sisting of 57 880 problems from the MPTP [41] and, in particular, the small
(bushy, re-proving) version. This version emulates the scenario where some form
of premise selection has already occurred and allows us to directly focus on evalu-
ating internal guidance in an ATP. To enable a direct comparison with Jakub˚uv
and Urban’s remarkable results [22], we adopt the base time limit of 10 s per
problem and use comparable hardware for the evaluation.10
This section has several parts. First, we explain the details concerning the
initial run from which the training derivations got collected, describe the various
ways of setting up the training procedure we experimented with, and evaluate
the performance of the obtained models (Sects. 4.1–4.3). We then set out to
establish how the individual aspects of our architecture (as discussed in Sect. 3.2)
contribute to the overall performance (Sect. 4.4). Finally, we follow Jakub˚uv and
Urban [22] in training better and better models using the growing set of solved
problems for more training and compare with their results (Sect. 4.5).
4.1
Data Preparation
We ﬁrst identiﬁed a Vampire strategy (from among Vampire’s standard CASC
schedule) which performed well on the Mizar40 benchmark. We denote the strat-
egy here as V and use it as a baseline. This strategy solved a total of 20 197
problems under the base 10 s time limit.
7 This eﬀect has already been observed by researches in a related context [30].
8 Supplementary materials for the experiments can be found at https://git.io/JOY71.
9 This means layered clause selection with second-level ratio 2:1 (as explained in
Sect. 2) and lazy model evaluation and abstraction caching (see [39]).
10 A server with Intel(R) Xeon(R) Gold 6140 CPUs @ 2.3 GHz with 500 GB RAM.

200
M. Suda
Table 1. Training statistics of models in the ﬁrst experiment.
Model shorthand
Hn128 Mn64 Mn128 Mn256 Dn128
Revealed axioms m
500
1000
1000
1000
2000
Embedding size n
128
64
128
256
128
Wall training time per epoch (min) 42
32
48
74
58
Model size (MB)
4.6
1.6
5.0
17.9
5.8
Overall best epoch
69
52
60
60
46
Validation loss
0.475
0.455
0.455
0.452
0.467
True positive rate
0.947
0.952
0.954
0.949
0.948
True negative rate
0.872
0.870
0.868
0.874
0.858
The corresponding successful derivations amount to roughly 800 MB of disk
space when zipped. There are 43 080 named Mizar axioms occurring in them
(and in each also some conjecture clauses), and 12 inference rules including
resolution, factoring, superposition, forward and backward demodulation, sub-
sumption resolution, unit resulting resolution and AVATAR (which represents
the connection between a clause getting split and its components) [31,43].
As the total number of axioms seemed too large, we only took a subset of
size m of the most often occurring ones to be represented by distinct labels for
the network to distinguish and replaced the remaining ones in the dataset by the
single generic label unknown (c.f. Iunknown in Sect. 3.2). To evaluate the eﬀect
of this hyper-parameter on performance, we initially experimented with three
values of m, namely, 500, 1000, and 2000.
To ﬁnalize the preparation of the training dataset(s), we constructed merged
batches of approximately 20 thousand nodes each. 71 derivations were larger
than this threshold (the largest had 242 023 merged nodes), but a typical batch
merged 5–20 derivations. In the particular case of m = 1000, which we consider
the default, we constructed 2167 batches in total. We then randomly split these,
as mentioned, into 90% of training and 10% of validation examples.
4.2
Training
We trained our models using the parallel setup with 20 cores, for up to 100
epochs, in the end choosing the model with the best validation loss as the result.
Similarly to our previous work [39], we used a variable learning rate.11
In total, we ran ﬁve independent training attempts. In addition to the number
of revealed axioms m, we also set out to evaluate how the behaviour of the
network changes with the size of the embedding n. For the default number of
revealed axioms m = 1000, we tried the embedding sizes n = 64, 128, and 256.
11 The learning rate was set to grow linearly from 0 to a maximum value αm = 2.0 ×
10−4 in epoch 40: α(t) = t · αm/40 for t ∈(0, 40]; and then to decrease from that
value as the reciprocal function of time: α(t) = 40 · αm/t for t ∈(40, 100).

Vampire with a Brain Is a Good ITP Hammer
201
Table 2. Performance statistics of the base strategy V and ﬁve strategies enhancing
V with a clause selection guidance by the respective neural models from Table 1.
Strategy
V
Hn128
Mn64
Mn128
Mn256
Dn128
Solved
20 197 24 581
25 484
25 805
25 287
26 014
V%
+0%
+21.7% +26.1% +27.7% +25.2% +28.8%
V+
+0
+5022
+5879
+6129
+5707
+6277
V−
−0
−638
−592
−521
−617
−460
Model eval. time 0%
37.1%
32.9%
37.7%
48.6%
36.7%
The training statistics of the corresponding ﬁve models are summarized in
Table 1. For each of the tried combination of m and n, the table starts by giving
a shorthand to the best obtained model for later reference.
The next block documents the speed of training and the size of the obtained
models. We can see that the model sizes are dictated mainly by the embedding
size n and not so much by the number of revealed axioms m. (Roughly, Θ(n2) of
space is needed for storing the matrices representing the deriv and eval functions,
while Θ(n·m) space is required for storing the axiom embeddings.) We note that
the sizes are comparable to those of the gradient boosted trees used by Jakub˚uv
and Urban [22] (5.0 MB for a tree of size 9 in their main experiment). Concerning
the training times, the 48 min per epoch recorded for Mn128 corresponds in 100
epochs to approximately 3 days of 20 core computation and almost 70 single-
core days. Jakub˚uv and Urban [22] trained a similarly sized model in under 5
single-core days, which indicates that training neural networks is much more
computation intensive.
Finally, Table 1 also reports for each training process the epoch in which the
validation loss was in the end the lowest, the achieved validation loss and the
(weighted) true positive and negative rates (on the validation examples).12 The
true positive rate (TPR) is the fraction of positive examples that the network
identiﬁes as such. The true negative rate (TNR) is deﬁned analogously. In our
case, we use the same weighting formula as for computing the contributions of
each example to the loss (recall Sect. 3.3). It is interesting to observe that on
the Mizar benchmark here the training process automatically produces models
biased towards better TPR (c.f. [39], Sect. 5.5), while the weighting actually
strives for an equal focus on the positive and the negative examples.
4.3
Evaluation with the Prover
Next, we reran Vampire’s strategy V, now equipped with the obtained models
for guidance, again using the time limit of 10 s. The results are shown in Table 2.
12 Please note that the batches of training and validation examples for diﬀerent numbers
of revealed axioms were constructed and split independently, so meaningful compar-
isons are mainly possible between the values of the middle column (for m = 1000).

202
M. Suda
We can see that the highest number of problems is solved with the help of
Dn128, the model with the intermediate embedding size n = 128 but with the
largest tried number of revealed axioms m = 2000. The strategy equipped with
Dn128 solves 26 014 problems, which is 28.8% of the baseline V.
In addition to the solved counts and the percentages, Table 2 also shows
the number of gained (V+) and lost (V−) problems with respect to the base
strategy V. Note that the problems from V+ were not present in the training
set, so solving those is a sign of successful generalization. On the other hand,
the non-negligible number of no-longer-solved problems under V−reminds us of
the overhead connected with interfacing the network.
The last row of the table elaborates on this, presenting the average time spent
by the strategies on evaluating their respective models. The numbers indicate
that the evaluation time is mainly determined by the embedding size n, as the
models with n = 128 all spend approximately 37% on evaluating, while notable
diﬀerences appear with n getting varied.
It is now interesting to compare the evaluation time (i.e., how fast the advice
is) and the validation loss from Table 1 (i.e., how good the advice is) with the
observed ATP performance. It appears that Mn256 is too slow to capitalize on
its superior advice quality over Mn64 and Mn128. However, there must be limits
to how indicative the validation loss is for the ﬁnal performance, because this
metric does not help distinguish between Mn64 and Mn128 and yet the slower
to evaluate Mn128 eventually helps Vampire solve substantially more problems.
4.4
Information Source Performance Breakdown
So far, we observed how the performance of the guided prover changes when we
vary the two numerical parameters of our architecture, namely, the size of the
embedding n and the number of revealed axioms m. Here we want to shed more
light on how the performance arises from the contributions of our architecture’s
main information sources: the ability to distinguish the input axioms at all (i.e.,
the information channelled through the init functions), the ability to distinguish
individual inference rules (corresponding to the deriv functions), and the ability
to track relatedness to the conjecture via the SInE levels. We do this by disabling
these sources in turn and rerunning the prover.
No Distinguished Input Axioms. With each information source, we have in prin-
ciple two options. One option is to train a new network from scratch, but on
a dataset which does not contain the extra information corresponding to the
disabled source (e.g., with m = 0 revealed axioms). The other option is to use
an already trained model (we will use Mn128 for this), but to withhold the extra
information while evaluating the model in the prover. For this, we need to pro-
vide a default value for “masking out” the extra information. (When disabling
input axioms, we simply use Iunknown as the default to embed any input clause

Vampire with a Brain Is a Good ITP Hammer
203
Table 3. Performance decrease when no axiom information is a available (A0 and
MnoAx) and when inference rules are not distinguished (RdefR). All models used n =
128 and M stands for Mn128 from Tables 1 and 2. Further details in the main text.
Strategy M
A0
MnoAx
R
RdefR
Solved
25 805
21 400
21 011
25 686
24 544
M%
+0.0%
−17.0% −18.5% −0.4%
−4.8%
V%
+27.7% +5.9%
+4.0%
+27.1% +21.5%
except the conjecture ones.) Note that the two options are not equivalent and,
intuitively, the ﬁrst one should not perform worse than the second.13
We can observe the eﬀect of disabling access to the input axioms in Table 3.
Model A0 represents the just described option one, where the axiom information
was already witheld during training. The column MnoAx, on the other hand,
used the original model Mn128 (here dubbed simply M), but during evaluation
in the prover all axioms were deliberately presented as unknown.
Most important to notice is that both options perform much worse than
the original model M, which shows that the ability to distinguish the input
axioms is crucial for the good performance of our architecture. Nevertheless,
when compared to the baseline strategy V, the guided prover still solves around
5% more problems. This means the guidance is still reasonably good (given that
almost 40% of the proving time is spent evaluating the network). Finally, A0
performs slightly better than MnoAx, which conforms with our intuition.
No Distinguished Derivation Rules. There seems to be no obvious way to pick
a default inference rule for masking out the functionality of this information
source. The situation is further complicated by the fact that we need at least
two defaults based on the inference rule arity.14 To prepare such defaults,15 we
came up with a modiﬁcation of the training regime that we call swapout.16
Training with swapout means there is a nonzero probability p (we used p =
0.1 in the experiment) that an application of a particular inference rule r in
a derivation—i.e. applying the deriv function Dr to produce the next clause
embedding—will instead use a generic function Darity(r) shared by all rules of
the same arity as r. This is analogous to using Iunknown for axioms not important
enough to deserve their own init function, but decided probabilistically.
The right part of Table 3 presents the performance of a model obtained using
swapout. First, under R, the additionally trained generic deriv functions were
13 The ﬁrst option is like being born blind, learning during life how to live without the
missing sense, the second option is like losing a sense “just before the ﬁnal exam”.
14 Our architecture separately models arity one rules, binary rules, and rules with arity
of 3 and more for which a binary building block is iteratively composed with itself.
15 These could also be used whenever a trained model is combined with a strategy not
used to produce the training data, possibly invoking rules not present in training.
16 In honor of dropout [37], a well-know regularization technique that inspired this.

204
M. Suda
Table 4. The eﬀect of training without SInE levels information (S0) and of imposing
various ﬁxed SInE levels on M = Mn128.
Strategy M
S0
Ml=0
Ml=1
Ml=2
Ml=3
Ml=4
Ml=5
Solved
25 805
25 440 25 724
25 823 25 882 25 884 25 866 25 802
M%
+0.0%
−1.4% −0.3% +0.0% +0.2% +0.3% +0.2% −0.0%
V+
+6129 +5783
+5878
+6002
+6092
+6101
+6114
+6108
V−
−521
−540
−351 −376
−407
−414
−445
−503
ignored. This means that R uses the same full set of information sources as M.
We should remark that training with swapout took longer to reach the minimal
validation loss and the ﬁnal loss was lower than that of M (0.454 in epoch 95).
Nevertheless, R performs slightly worse than M.
Under RdefR, we see the performance of R where the trained generic deriv
functions are exclusively used to replace (based on arity) the speciﬁc ones. The
performance drops by approximately 5% compared to M, which shows that
there is value in the architecture being able to distinguish the derivation rules.
No SInE Levels. Let us ﬁnally move to the information source provided by
the SInE levels and a corresponding experiment documented in Table 4. In that
table, S0 is a model trained without access to this source, while the remaining
columns represent M with increasingly large values of the SInE level l uniformly
hardwired for evaluation in the prover.
Confusingly, all M-derived models fare better than S0 and some of them are
even better than M itself. We currently do not have a good general explanation
for this phenomenon, although an analogy with the success of “positive bias”
observed in our previous work on SMT-LIB can be drawn (c.f. [39], Sect. 5.5).
Hardwiring a low SInE level l means the network will consider many clauses to
be more related to the conjecture than they actually are, which will likely lead
to more clauses classiﬁed as positive. Then the general intuition would be that it
is more important for performance not to dismiss a clause needed for the proof
than to dismiss clauses that will not be needed.
It is worth pointing out that Ml=0 is the most “careful” conﬁguration of
these, scoring the lowest in terms of V−, the number of problems lost with
respect to the baseline strategy V. Additionally, M still scores the highest on
V+, the number of newly solved problems, not present in the training data,
although Ml=4 comes quite close. More analysis seems to be needed to fully
understand the eﬀect of the SInE levels on the architecture’s performance.
4.5
Looping to Get Even Better
When evaluating a strategy guided by a model leads to solving previously
unsolved problems, the larger set of proofs may be used for training a potentially
even better model to help solve even more problems. Jakub˚uv and Urban [22]
call this method looping and successfully apply it on Mizar for several iterations.

Vampire with a Brain Is a Good ITP Hammer
205
Table 5. Summary of the looping procedure. Collected stands for the number of deriva-
tions available for training. Performance refers to the best strategy of the loop (in 10 s).
Loop index Training
Evaluation
Collected m
Performance V%
%collected
0
–
–
20 197
+0.0%
–
1
20 197
500/1000/2000 26 014
+28.8% 128.8%
2
29 065
3000
27 348
+35.4% 94.0%
3
32 020
5000
28 947
+43.3% 90.4%
Here we report on applying looping to our neural architecture. We follow our
previous work and adhere to the following two rules when using the method:
First, we use exactly one successful derivation to train on for every previously
solved problem. Second, if a derivation was obtained with the help of previously
trained guidance, we augment the derivation with the unsuccessful run of plain
V on that problem. The ﬁrst rule ensures the dataset does not grow too large too
quickly. The second rule helps to create a suﬃcient pool of negative examples,
“typical bad decisions”, that might otherwise not be present in a derivation
obtained with some form of guidance already in place (c.f. [39], Sect. 5.6).
The results of looping are summarized in Table 5. We can already recognize
the values of the ﬁrst two rows: “Loop 0” means the run of the baseline strategy
V. Then, in loop 1, the obtained 20 197 successful derivations become available
for training (some actually get used for training, others for validation), and, as
we know from Table 2, the best model of this ﬁrst round of training was Dn128,
solving 26 014 Mizar40 problems under the 10 s time limit.
For the next loop—observing the two rules mentioned above—we collected
a total of 29 065 successful derivations and trained the next model using an
increased number of revealed axioms m = 3000. To create additional variability
in the runs and thus to increase the chances of collecting even more derivations
for the next loop, we varied the modes of interfacing a model, studied in more
detail in our previous work [39]. The best conﬁguration of loop 2 solved 27 348
problems and the union of solved problems grew to 32 020. Finally, training
using the corresponding successful derivations in loop 3, we were able to produce
a model B with n = 128, m = 5000 that can guide Vampire17 to solve 28 947
problems and thus improves over the baseline V by more than 43%.
As can be seen from Table 5, while the best strategy’s performance improves
with every loop, there is clearly an eﬀect of diminishing returns at play. In
particular, after loop 1 the best strategy is no longer able to solve more problems
than was the number of solutions used for training the corresponding model
and in loop 3 their percentage comparison (i.e., %collected) only reaches 90%.
Another observation is that our initial estimate m = 1000 for a reasonable
number of revealed axioms was too low. The additional capacity is paying oﬀ
17 Using again the here prevalent layered clause selection with second-level ratio 2:1.

206
M. Suda
even for B, which with its m = 5000 reaches a size of 8.8 MB (c.f. Table 1) and
40.1% running time spent on model evaluation (c.f. Table 2).
Let us conclude here by a comparison with the results of Jakub˚uv and Urban
[22]. They start oﬀwith a strategy of E [35] solving 14 933 Mizar40 problems
under a 10 s time limit and their best loop 4 model guides ENIGMA to solve
25 397 problems (i.e., +70%) under that time limit. The authors kindly provided
us with the precise set of problems solved by their runs. Their runs cover 27 425
problems. Our collection, that could be used for training in our next loop, counts
32 531 solved problems. Our architecture solved 6356 problems that ENIGMA
could not (and did not solve 1250 problems that ENIGMA could).
5
Conclusion
There is a new neural architecture for guiding clause selection in saturation-based
ATPs based solely on clause derivation history [39]. We adapted this architec-
ture to work in the context of a large library of formalized mathematics, in
particular the Mizar mathematical library (MML) [17], and conducted a series
of experiments on the Mizar40 export of the library [23] with the new architec-
ture interfaced from the ATP Vampire. We established how the performance of
the obtained system depends on parameters of the network and on its architec-
tural building blocks. We also compared its performance to that of ENIGMA
and saw our architecture further improve on ENIGMA’s remarkable results [22].
It is perhaps surprising that so much can be gained by simply paying atten-
tion to the clause’s pedigree while ignoring what it says as a logical formula. In
future work, we would like to have a closer look at the trained models (and thus,
implicitly, at the successful derivations) and employ the techniques of explain-
able AI to get a better understanding of the architecture’s success. We hope to
distill new general purpose theorem proving heuristics or, at least, contribute to
knowledge transfer from Mizar to other libraries of formalized mathematics.
Acknowledgement. This work was supported by the Czech Science Foundation
project 20-06390Y and the project RICAIP no. 857306 under the EU-H2020 pro-
gramme.
References
1. Alama, J., Heskes, T., K¨uhlwein, D., Tsivtsivadze, E., Urban, J.: Premise selection
for mathematics by corpus analysis and kernel methods. J. Autom. Reason. 52(2),
191–213 (2014). https://doi.org/10.1007/s10817-013-9286-5
2. Alemi, A.A., Chollet, F., Irving, G., Szegedy, C., Urban, J.: DeepMath - deep
sequence models for premise selection. CoRR abs/1606.04442 (2016)
3. Ayg¨un,
E.,
et
al.:
Learning
to
prove
from
synthetic
theorems.
CoRR
abs/2006.11259 (2020)
4. Bachmair, L., Ganzinger, H.: Resolution theorem proving. In: Robinson and
Voronkov [33], pp. 19–99. https://doi.org/10.1016/b978-044450813-3/50004-7

Vampire with a Brain Is a Good ITP Hammer
207
5. Barrett, C., Fontaine, P., Tinelli, C.: The Satisﬁability Modulo Theories Library
(SMT-LIB) (2016). www.SMT-LIB.org
6. Blanchette, J.C., Kaliszyk, C., Paulson, L.C., Urban, J.: Hammering towards
QED. J. Formaliz. Reason. 9(1), 101–148 (2016). https://doi.org/10.6092/issn.
1972-5787/4593
7. Chvalovsk´y, K., Jakubuv, J., Suda, M., Urban, J.: ENIGMA-NG: eﬃcient neural
and gradient-boosted inference guidance for E. In: Fontaine [12], pp. 197–215.
https://doi.org/10.1007/978-3-030-29436-6 12
8. Crouse, M., et al.: A deep reinforcement learning based approach to learning trans-
ferable proof guidance strategies. CoRR abs/1911.02065 (2019)
9. Denzinger, J., Schulz, S.: Learning domain knowledge to improve theorem proving.
In: McRobbie, M.A., Slaney, J.K. (eds.) CADE 1996. LNCS, vol. 1104, pp. 62–76.
Springer, Heidelberg (1996). https://doi.org/10.1007/3-540-61511-3 69
10. F¨arber, M., Kaliszyk, C.: Random forests for premise selection. In: Lutz, C., Ranise,
S. (eds.) FroCoS 2015. LNCS (LNAI), vol. 9322, pp. 325–340. Springer, Cham
(2015). https://doi.org/10.1007/978-3-319-24246-0 20
11. F¨arber, M., Kaliszyk, C., Urban, J.: Monte Carlo tableau proof search. In: de
Moura, L. (ed.) CADE 2017. LNCS (LNAI), vol. 10395, pp. 563–579. Springer,
Cham (2017). https://doi.org/10.1007/978-3-319-63046-5 34
12. Fontaine, P. (ed.): CADE 2019. LNCS (LNAI), vol. 11716. Springer, Cham (2019).
https://doi.org/10.1007/978-3-030-29436-6
13. Gleiss, B., Suda, M.: Layered clause selection for saturation-based theorem prov-
ing. In: Fontaine, P., Korovin, K., Kotsireas, I.S., R¨ummer, P., Tourret, S. (eds.)
Joint Proceedings of the 7th Workshop on Practical Aspects of Automated Rea-
soning (PAAR) and the 5th Satisﬁability Checking and Symbolic Computation
Workshop (SC-Square), co-located with the 10th International Joint Conference
on Automated Reasoning (IJCAR 2020), Paris, France, June–July, 2020 (Virtual).
CEUR Workshop Proceedings, vol. 2752, pp. 34–52. CEUR-WS.org (2020)
14. Gleiss, B., Suda, M.: Layered clause selection for theory reasoning. In: Peltier, N.,
Sofronie-Stokkermans, V. (eds.) IJCAR 2020, Part I. LNCS (LNAI), vol. 12166, pp.
402–409. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-51074-9 23
15. Goller, C., K¨uchler, A.: Learning task-dependent distributed representations by
backpropagation through structure. In: Proceedings of International Conference
on Neural Networks (ICNN 1996), Washington, DC, USA, 3–6 June 1996, pp.
347–352. IEEE (1996). https://doi.org/10.1109/ICNN.1996.548916
16. Goodfellow, I.J., Bengio, Y., Courville, A.C.: Deep Learning. Adaptive Computa-
tion and Machine Learning. MIT Press, Cambridge (2016)
17. Grabowski, A., Kornilowicz, A., Naumowicz, A.: Mizar in a nutshell. J. Formaliz.
Reason. 3(2), 153–245 (2010). https://doi.org/10.6092/issn.1972-5787/1980
18. Hoder, K., Voronkov, A.: Sine Qua non for large theory reasoning. In: Bjørner, N.,
Sofronie-Stokkermans, V. (eds.) CADE 2011. LNCS (LNAI), vol. 6803, pp. 299–
314. Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-642-22438-6 23
19. Jakub˚uv, J., Chvalovsk´y, K., Olˇs´ak, M., Piotrowski, B., Suda, M., Urban, J.:
ENIGMA anonymous: symbol-independent inference guiding machine (system
description). In: Peltier, N., Sofronie-Stokkermans, V. (eds.) IJCAR 2020, Part
II. LNCS (LNAI), vol. 12167, pp. 448–463. Springer, Cham (2020). https://doi.
org/10.1007/978-3-030-51054-1 29
20. Jakub˚uv, J., Urban, J.: ENIGMA: eﬃcient learning-based inference guiding
machine. In: Geuvers, H., England, M., Hasan, O., Rabe, F., Teschke, O. (eds.)
CICM 2017. LNCS (LNAI), vol. 10383, pp. 292–302. Springer, Cham (2017).
https://doi.org/10.1007/978-3-319-62075-6 20

208
M. Suda
21. Jakub˚uv, J., Urban, J.: Enhancing ENIGMA given clause guidance. In: Rabe, F.,
Farmer, W.M., Passmore, G.O., Youssef, A. (eds.) CICM 2018. LNCS (LNAI),
vol. 11006, pp. 118–124. Springer, Cham (2018). https://doi.org/10.1007/978-3-
319-96812-4 11
22. Jakubuv, J., Urban, J.: Hammering Mizar by learning clause guidance (short
paper). In: Harrison, J., O’Leary, J., Tolmach, A. (eds.) 10th International Confer-
ence on Interactive Theorem Proving, ITP 2019, Portland, OR, USA, 9–12 Septem-
ber 2019. LIPIcs, vol. 141, pp. 34:1–34:8. Schloss Dagstuhl - Leibniz-Zentrum f¨ur
Informatik (2019). https://doi.org/10.4230/LIPIcs.ITP.2019.34
23. Kaliszyk, C., Urban, J.: Mizar 40 for mizar 40. J. Autom. Reason. 55(3), 245–256
(2015). https://doi.org/10.1007/s10817-015-9330-8
24. Kov´acs, L., Voronkov, A.: First-order theorem proving and Vampire. In: Shary-
gina, N., Veith, H. (eds.) CAV 2013. LNCS, vol. 8044, pp. 1–35. Springer, Heidel-
berg (2013). https://doi.org/10.1007/978-3-642-39799-8 1
25. Looks, M., Herreshoﬀ, M., Hutchins, D., Norvig, P.: Deep learning with dynamic
computation graphs. In: 5th International Conference on Learning Representa-
tions, ICLR 2017, Toulon, France, 24–26 April 2017, Conference Track Proceed-
ings. OpenReview.net (2017)
26. Loos, S.M., Irving, G., Szegedy, C., Kaliszyk, C.: Deep network guided proof search.
In: Eiter, T., Sands, D. (eds.) LPAR-21, 21st International Conference on Logic for
Programming, Artiﬁcial Intelligence and Reasoning, Maun, Botswana, 7–12 May
2017. EPiC Series in Computing, vol. 46, pp. 85–105. EasyChair (2017)
27. Nieuwenhuis, R., Rubio, A.: Paramodulation-based theorem proving. In: Robin-
son and Voronkov [33], pp. 371–443. https://doi.org/10.1016/b978-044450813-3/
50009-6
28. Paszke, A., et al.: PyTorch: an imperative style, high-performance deep learning
library. In: Wallach, H., Larochelle, H., Beygelzimer, A., d’Alch´e-Buc, F., Fox, E.,
Garnett, R. (eds.) Advances in Neural Information Processing Systems, vol. 32, pp.
8024–8035. Curran Associates, Inc. (2019). http://papers.neurips.cc/paper/9015-
pytorch-an-imperative-style-high-performance-deep-learning-library.pdf
29. Piotrowski, B., Urban, J.: Stateful premise selection by recurrent neural networks.
In: Albert, E., Kov´acs, L. (eds.) LPAR 2020: 23rd International Conference on
Logic for Programming, Artiﬁcial Intelligence and Reasoning, Alicante, Spain, 22–
27 May 2020. EPiC Series in Computing, vol. 73, pp. 409–422. EasyChair (2020).
https://easychair.org/publications/paper/g38n
30. Recht, B., Re, C., Wright, S., Niu, F.: HOGWILD!: a lock-free approach to paral-
lelizing stochastic gradient descent. In: Shawe-Taylor, J., Zemel, R., Bartlett, P.,
Pereira, F., Weinberger, K.Q. (eds.) Advances in Neural Information Processing
Systems, vol. 24. Curran Associates, Inc. (2011). https://proceedings.neurips.cc/
paper/2011/ﬁle/218a0aefd1d1a4be65601cc6ddc1520e-Paper.pdf
31. Reger, G., Suda, M., Voronkov, A.: Playing with AVATAR. In: Felty, A.P., Mid-
deldorp, A. (eds.) CADE 2015. LNCS (LNAI), vol. 9195, pp. 399–415. Springer,
Cham (2015). https://doi.org/10.1007/978-3-319-21401-6 28
32. Riazanov, A., Voronkov, A.: Limited resource strategy in resolution theorem prov-
ing. J. Symb. Comput. 36(1–2), 101–115 (2003). https://doi.org/10.1016/S0747-
7171(03)00040-3
33. Robinson, J.A., Voronkov, A. (eds.): Handbook of Automated Reasoning (in 2
volumes). Elsevier and MIT Press (2001)
34. Schulz, S.: Learning Search Control Knowledge for Equational Deduction. No. 230
in DISKI, Akademische Verlagsgesellschaft Aka GmbH Berlin (2000)

Vampire with a Brain Is a Good ITP Hammer
209
35. Schulz, S., Cruanes, S., Vukmirovic, P.: Faster, higher, stronger: E 2.3. In: Fontaine
[12], pp. 495–507. https://doi.org/10.1007/978-3-030-29436-6 29
36. Schulz, S., M¨ohrmann, M.: Performance of clause selection heuristics for saturation-
based theorem proving. In: Olivetti, N., Tiwari, A. (eds.) IJCAR 2016. LNCS
(LNAI), vol. 9706, pp. 330–345. Springer, Cham (2016). https://doi.org/10.1007/
978-3-319-40229-1 23
37. Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.:
Dropout: a simple way to prevent neural networks from overﬁtting. J. Mach. Learn.
Res. 15(1), 1929–1958 (2014). http://dl.acm.org/citation.cfm?id=2670313
38. Suda, M.: Aiming for the goal with SInE. In: Kov´acs, L., Voronkov, A. (eds.)
Vampire 2018 and Vampire 2019. The 5th and 6th Vampire Workshops. EPiC
Series in Computing, vol. 71, pp. 38–44. EasyChair (2020). https://doi.org/10.
29007/q4pt
39. Suda, M.: Improving ENIGMA-style clause selection while learning from history.
In: Platzer, A., Sutcliﬀe, G. (eds.) Proceedings of the 28th CADE (2021, to appear).
https://arxiv.org/abs/2102.13564
40. Tammet, T.: GKC: a reasoning system for large knowledge bases. In: Fontaine [12],
pp. 538–549. https://doi.org/10.1007/978-3-030-29436-6 32
41. Urban, J.: MPTP 0.2: Design, implementation, and initial experiments. J. Autom.
Reason. 37(1–2), 21–43 (2006). https://doi.org/10.1007/s10817-006-9032-3
42. Urban, J., Vyskoˇcil, J., ˇStˇep´anek, P.: MaLeCoP machine learning connection
prover. In: Br¨unnler, K., Metcalfe, G. (eds.) TABLEAUX 2011. LNCS (LNAI),
vol. 6793, pp. 263–277. Springer, Heidelberg (2011). https://doi.org/10.1007/978-
3-642-22119-4 21
43. Voronkov, A.: AVATAR: the architecture for ﬁrst-order theorem provers. In: Biere,
A., Bloem, R. (eds.) CAV 2014. LNCS, vol. 8559, pp. 696–710. Springer, Cham
(2014). https://doi.org/10.1007/978-3-319-08867-9 46
44. Wang, M., Tang, Y., Wang, J., Deng, J.: Premise selection for theorem
proving by deep graph embedding. In: Guyon, I., et al. (eds.) Advances
in Neural Information Processing Systems 30: Annual Conference on Neu-
ral Information Processing Systems 2017, Long Beach, CA, USA, 4–9 Decem-
ber 2017, pp. 2786–2796 (2017). https://proceedings.neurips.cc/paper/2017/hash/
18d10dc6e666eab6de9215ae5b3d54df-Abstract.html
45. Weidenbach, C., Dimova, D., Fietzke, A., Kumar, R., Suda, M., Wischnewski,
P.: SPASS version 3.5. In: Schmidt, R.A. (ed.) CADE 2009. LNCS (LNAI), vol.
5663, pp. 140–145. Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-
642-02959-2 10

Satisﬁability Modulo Theories

Optimization Modulo Non-linear
Arithmetic via Incremental Linearization
Filippo Bigarella1, Alessandro Cimatti2, Alberto Griggio2, Ahmed Irfan1,2,
Martin Jon´aˇs2, Marco Roveri1, Roberto Sebastiani1(B), and Patrick Trentin1
1 DISI, University of Trento, Trento, Italy
roberto.sebastiani@unitn.it
2 Fondazione Bruno Kessler - FBK, Trento, Italy
Abstract. Incremental linearization is a conceptually simple, yet eﬀec-
tive, technique that we have recently proposed for solving SMT prob-
lems on the theories of non-linear arithmetic over the reals and the inte-
gers. Optimization Modulo Theories (OMT) is an important extension
of SMT which allows for ﬁnding models that optimize given objective
functions. In this paper, we show how incremental linearization can be
extended to OMT in a simple way, producing an incomplete though eﬀec-
tive OMT procedure. We describe the main ideas and algorithms, we
provide an implementation within the OptiMathSAT OMT solver, and
perform an empirical evaluation. The results support the eﬀectiveness of
the approach.
1
Introduction
Context. Satisﬁability Modulo Theories (SMT) is the problem of deciding the
satisﬁability of a ﬁrst-order formula with respect to some theories of interest
(e.g. theory of linear arithmetic, of arrays, of bit-vectors, ...) and combination
thereof [5]. Powerful and eﬀective SMT techniques and tools are available for a
large variety of theories, including the quantiﬁer-free theories1 of Uninterpreted
Functions (UF) and Linear Arithmetic (LA), either over the reals (LRA) or the
integers (LIA), as well as their combinations (UFLRA, UFLIA), of bit-vector
(BV) and ﬂoating-point arithmetic (FP).
When dealing with arithmetic, a fundamental challenge is to go beyond the
linear case, by introducing multiplications between variables, and hence between
complex terms – over the reals (NRA) or over theIn the following, we only
consider quantiﬁer-free theories, and we abuse the accepted notation and omit
the “QF ” preﬁx in the names of the theories. integers (NIA). (We also use the
term “NIRA” [resp. “LIRA”] when we do not distinguish between NRA and NIA
[resp. LRA and LIA].) Unfortunately, dealing with non-linearity is a very hard
1 In the following, we only consider quantiﬁer-free theories, and we abuse the accepted
notation and omit the “QF ” preﬁx in the names of the theories.
A. Irfan—The author’s contribution dates when he was still at FBK, Trento.
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 213–231, 2021.
https://doi.org/10.1007/978-3-030-86205-3_12

214
F. Bigarella et al.
challenge. Going from SMT(LRA) to SMT(NRA) yields a complexity gap that
results in a computational barrier in practice – most available complete solvers
rely on Cylindrical algebraic decomposition (CAD) techniques [15], which require
double exponential time in worst case. Reasoning in NIA is even undecidable [30].
Incremental Linearization. Recently, we have proposed a conceptually-simple,
incomplete yet eﬀective practical approach for SMT dealing with the quantiﬁer-
free theory of non-linear arithmetic over the reals, over the reals extended with
transcendental functions, and over integers, called Incremental Linearization
[13]. Its underlying idea is that of trading the use of expensive, exact solvers for
non-linear arithmetic for an abstraction-reﬁnement loop on top of much cheaper
solvers for linear arithmetic and uninterpreted functions.
Optimization Modulo Theories. Many SMT problems of interest, however,
require the capability of ﬁnding models that are optimum wrt. some objective
functions. These problems are grouped under the umbrella term of Optimiza-
tion Modulo Theories – OMT [8,32,34]. OMT techniques have been conceived
for a variety of theories, including LRA [8,34], LIA [8,36], BV [31], FP [39]. In
general, they work by performing sequences of incremental SMT calls, possibly
combined with theory-speciﬁc optimization techniques for the conjunctive frag-
ment of the given theory, which progressively tighten the range of values of the
objective function.
OMT by Incremental Linearization. In this paper, we show how incremental
linearization can be extended from SMT to OMT in a very simple way, produc-
ing an incomplete though eﬀective OMT procedure. As with the SMT case in
[13], the goal is to build an OMT(NIRA) solver on top of “cheap” ingredients:
SMT(UFLIRA) and OMT(UFLIRA) incremental calls driven by an abstraction-
reﬁnement loop, with no expensive solver or optimizer for non-linear arithmetic,
so that the task of progressing towards the optimum is performed by a combi-
nation of Boolean search and optimization in the abstract UFLIRA space. We
describe the main ideas and algorithms.
We have implemented the novel OMT(NIRA) algorithms within the OMT
solver OptiMathSAT [37], which is built on top of the MathSAT5 SMT
solver [14], where the incremental linearization for SMT(NIRA) procedures have
been implemented [13]. We have experimentally validated our algorithm with an
analysis of the performance of OptiMathSAT in dealing with OMT(NRA) and
OMT(NIA) problems, and compared these results with those of another state-of-
the-art OMT solver, Z3 [8], which oﬀers a limited support for OMT(NRA) and
OMT(NIA). Although quite preliminary to some extent, the results show that,
despite the simplicity of the implemented procedures, OptiMathSAT solves
the largest number of benchmarks overall, thus supporting the eﬀectiveness of
the approach.
Related Work. Eﬃcient SMT solving for non-linear arithmetic is an open research
problem for which a variety of approaches have been proposed; these are often
complementary with one another [13]. Methods for dealing with SMT(NRA)
are typically based on: cylindrical algebraic decomposition (CAD) [3,15,23,25],

Optimization Modulo Non-linear Arithmetic via Incremental Linearization
215
virtual substitution (VS) [40], interval constraint propagation (ICP) [6,21], bit-
blasting [20,41], linearization [9–11,19,28,33] and incremental linearization [13].
Methods for dealing with SMT(NIA) are based on the combination of branch-
and-bound search with some SMT(NRA) solving technique. See, for example,
[22] and [26] based on CAD and CAD+VS respectively, and [12] based on incre-
mental linearization.
OMT for non-linear arithmetic, instead, is a largely unexplored territory:
the Z3 [8] OMT solver does not oﬃcially support optimization with NIRA con-
straints or objective functions.2 However, in practice, it can compute optimal
solutions for some of these problems, albeit without providing any guarantees.
dReal is a SMT(NRA) solver based on the notion of δ-satisﬁability [21],
that basically guarantees that there exists a variant (within a user-speciﬁed δ
“radius”) of the original problem such that it is satisﬁable. Importantly, we notice
that the approach cannot guarantee that the original problem is satisﬁable, since
it relies on numerical approximation techniques that only compute safe over-
approximations of the solution space. dReal supports optimization with NRA
objective functions and/or in the presence of NRA constraints [24].
Content. The paper is organized as follows. In Sect. 2 we provide some back-
ground knowledge on OMT and incremental linearization; in Sect. 3 we present
our main ideas and new OMT(NIRA) procedures; in Sect. 4 we perform the
empirical evaluation, discussing the results; in Sect. 5 we draw some conclusions,
and illustrate possible future research directions.
2
Background
2.1
Optimization Modulo Theories
We assume the reader is familiar with the main theoretical and algorithmic con-
cepts in SAT and SMT solving (see e.g. [5,29]). Optimization Modulo Theories
(OMT) is an extension of SMT which addresses the problem of ﬁnding a model
for an input formula ϕ which is optimal wrt. some objective function obj [32,34].
(In this paper we consider optimization as minimization; the narration for max-
imization is dual.) A little more formally, given some theory T admitting some
total order “≤” over its domain, an OMT(T ) problem is given by a pair ⟨ϕ, obj⟩
where ϕ, obj are a formula and a term over T , and consists in ﬁnding a model for
ϕ (if any) which makes the value of obj minimum according to the order given
by ≤.3
The basic minimization strategy implemented in all state-of-the-art OMT
solvers, is known as linear-search strategy [32,34,35]. It requires solving an
SMT problem with a feasible space that is progressively tightened by learning a
2 https://github.com/Z3Prover/z3/issues/2247
https://github.com/Z3Prover/z3/issues/5339.
3 More generally the formula can be built on a combination of T with other theories,
see e.g. [35]. However, to simplify the narration and the notation, here we refer to
one single theory.

216
F. Bigarella et al.
sequence of unit clauses of the form (obj < ub), where ub is the current upper
bound of the optimization search. At each iteration, the SMT solver can either
ﬁnd a model M of ϕ whose value of obj, denoted with M[obj], is smaller than
the current upper bound ub, or discover that the stack of formulas has become
unsatisﬁable. In the ﬁrst case, the OMT solver invokes a T -speciﬁc minimiza-
tion procedure over the propositional truth assignment ψ induced by M on the
atoms of the formula, so as to generate a model M′ of ϕ such that the value of
M′[obj] is minimum for the given propositional assignment ψ. Then, the M′[obj]
becomes the new upper bound ub of the optimization search. The OMT search
terminates when such procedure ﬁnds that obj is unbounded or when the SMT
search is unsat, in which case the last model Mi of ϕ (if any) is the optimal
solution.
If, for some theory T , T -speciﬁc minimization is hard to implement (e.g. for
ﬂoating-point arithmetic [39]) or computationally too expensive (e.g., for linear
integer arithmetic [36]), then we can rely on other strategies.
One possible approach for the latter case is to implement a cheaper though
incomplete T -speciﬁc minimization procedure, which may only improve the value
of M[obj] with no guarantee to ﬁnd a minimum one for the given truth assign-
ment. This comes at the risk of generating and exploring the same truth assign-
ment more than once, overall trading arithmetic minimization search for extra
Boolean search [36].
An alternative minimization approach is the binary-search strategy described
in [34]. At the beginning of each binary search step, the OMT solver calls a func-
tion ComputePivot() to compute a pivoting value contained in the current search
interval. (In its simplest implementation, ComputePivot() returns the value of
(ub−lb)
2
, where lb and ub are the lower and the upper bound currently delim-
iting the optimization search respectively). Then, the OMT solver temporarily
assumes a unit-clause of the form (obj < pivot). This eﬀectively restricts the
search space so that it includes only satisﬁable truth assignments (if any) for
which obj has a value included in the interval [lb, pivot). If any such solution is
found by the OMT solver, the algorithm proceeds like in linear-search mode, and
updates the current upper bound ub. Otherwise, if no such solution exists, then
the pivoting unit-clause (obj < pivot) is replaced by its negation ¬(obj < pivot)
and pivot becomes the new lower bound. Notice that, in case of continuous
domains (e.g., LRA, NRA) the binary search alone may not terminate, so that
it is necessary to interleave binary-search steps with linear-search ones [35].
2.2
SMT(NIRA) via Incremental Linearization
The main idea of incremental linearization [13] is to trade the use of expensive,
exact solvers for non-linear arithmetic for an abstraction-reﬁnement loop on
top of much cheaper solvers for linear arithmetic and uninterpreted functions,
UFLIRA. The pseudo-code of the baseline procedure is shown in Fig. 1.
First, the input SMT(NIRA) formula ϕ is abstracted to the SMT(UFLIRA)
formula ϕ (called its UFLIRA-abstraction) by substituting every non-linear

Optimization Modulo Non-linear Arithmetic via Incremental Linearization
217
Fig. 1. Solving SMT(NIRA) via incremental linearization.
Fig. 2. The procedure checking whether ˆμ can be reﬁned into a model of ϕ.
multiplication term x ∗y with f∗(x, y), where both x and y are variables4 and
f∗is an uninterpreted function symbol (function SMT-Initial-Abstraction
in line 1). Then, the set of linearization lemmas Γ (i.e. UFLIRA-abstraction of
NIRA-valid multiplication lemmas in Fig. 3) is initialized to the empty set, and
the loop begins.5
First, the UFLIRA-satisﬁability of ϕ augmented with the linearization lem-
mas in Γ is checked. If the SMT(UFLIRA) check returns false, then the input
formula is NIRA-unsatisﬁable, because ϕ ∧ Γ is an over-approximation of ϕ
by construction (lines 4–6).
4 As in [13] and with no loss of generality, hereafter we assume that all multiplications
in ϕ are either between two variables or between one constant and one variable,
because more complex terms occurring in a multiplication can be renamed by fresh
variables. Notice that this assumption is not necessary in practice, but it simpliﬁes
the explanation.
5 In order to keep the narration simple, in Fig. 1 we have omitted some details. First,
the input formula can be simpliﬁed by some preprocessing steps. Furthermore, for
each fresh f∗(x, y) term, ˆϕ can be extended from the beginning with simple multi-
plication lemmas. We refer the reader to [13] for details.

218
F. Bigarella et al.
Otherwise, the abstract model ˆμ for ϕ is used to build an UFLIRA under-
approximation ψ∗of ϕ, with the aim of ﬁnding a model μ for ψ∗, and thus for
the original NIRA formula ϕ (function SMT-Check-Refine in line 7). If this
succeeds, then ϕ is also satisﬁable. Otherwise, SMT-Check-Refine returns a
set Γ
′ of linear lemmas which are suﬃcient to rule out the spurious model ˆμ. Γ
′
is then added to Γ, thus improving the precision of the abstraction, and another
iteration of the loop is performed.
The lemmas added are instances of the axioms of Fig. 3, obtained by replacing
the free variables with terms occurring in ϕ, selected among those that evaluate
to false under the current spurious model μ.
The pseudo-code of the model search procedure (SMT-Check-Refine) is
reported in Fig. 2. In particular, ψ∗is built by ﬁrst generating the truth assign-
ment ψ for the atoms in ϕ which is entailed by the current abstract model μ,
and then by adding multiplication line constraints that force all multiplications
in ψ to be linear (lines 1–2):
ˆψ =

[ ˆ
A∈atoms( ˆϕ) s.t. ˆμ|= ˆ
A]
ˆA ∧

[ ˆ
A∈atoms( ˆϕ) s.t. ˆμ̸|= ˆ
A]
¬ ˆA
(1)
ˆψ∗= ˆψ∧

f∗(x,y)∈ˆ
ψ
(x = ˆμ[x]∧f∗(x, y) = ˆμ[x]∗y))∨(y = ˆμ[y]∧f∗(x, y) = ˆμ[y]∗x)) (2)
Then the UFLIRA-satisﬁability of ψ∗is checked: if satisﬁable, then ϕ is NIRA-
satisﬁable and its model ˆμ
′ is also a model for ϕ (lines 3–5). Otherwise, a set Γ
of lemmas ruling out the spurious model ˆμ
′ is produced and returned (lines 6–8).
3
Optimization Modulo Non-linear Arithmetic
In this section, we present our novel Optimization Modulo Non-Linear Arith-
metic procedure based on the combination of the optimization schema described
in Sect. 2.1 and the incremental linearization approach described in Sect. 2.2. In
Sect. 3.1, we describe the basic version of this new algorithm, based on the linear
optimization search schema, and discuss the termination of the algorithm. Then,
in Sect. 3.2, we describe some simple improvements over the basic approach that
can signiﬁcantly improve the eﬀectiveness of the procedure, despite remaining
incomplete.
3.1
Linear Optimization Search
The pseudo-code of the basic approach to Optimization Modulo Non-Linear
Arithmetic, based on the linear optimization search schema, is shown in Fig. 4.

Optimization Modulo Non-linear Arithmetic via Incremental Linearization
219
v1 ∗v2 = (−v1 ∗−v2)
v1 ∗v2 = −(−v1 ∗v2)
v1 ∗v2 = −(v1 ∗−v2)
(v1 = 0 ∨v2 = 0) ↔v1 ∗v2 = 0
((v1 > 0 ∧v2 > 0) ∨(v1 < 0 ∧v2 < 0)) ↔v1 ∗v2 > 0
((v1 < 0 ∧v2 > 0) ∨(v1 > 0 ∧v2 < 0)) ↔v1 ∗v2 < 0
(v1 = 1 ∨v2 = 0) ↔v1 ∗v2 = v2
(v2 = 1 ∨v1 = 0) ↔v1 ∗v2 = v1
|v1 ∗v2| ≥|v2| ↔(|v1| ≥1 ∨v2 = 0)
|v1 ∗v2| ≤|v2| ↔(|v1| ≤1 ∨v2 = 0)
|v1 ∗v2| ≥|v1| ↔(|v2| ≥1 ∨v1 = 0)
|v1 ∗v2| ≤|v1| ↔(|v2| ≤1 ∨v1 = 0)
(v1 ∗v2 ▷◁v3 ∧v4 > 0) →v1 ∗v2 ∗v4 ▷◁v3 ∗v4
(v1 ∗v2 ▷◁v3 ∧v4 < 0) →v3 ∗v4 ▷◁v1 ∗v2 ∗v4
(|v1| ≤|v2| ∧|v3| ≤|v4|) →|v1 ∗v3| ≤|v2 ∗v4|
(|v1| < |v2| ∧|v3 ≤|v4| ∧v4 ̸= 0) →|v1 ∗v3| < |v2 ∗v4|
(|v1| ≤|v2| ∧|v3| < |v4| ∧v2 ̸= 0) →|v1 ∗v3| < |v2 ∗v4|
v1 = a →v1 ∗v2 = a ∗v2
v2 = b →v1 ∗v2 = b ∗v1
(v1 > a ∧v2 < b) →v1 ∗v2 < b ∗v1 + a ∗v2 −a ∗b
(v1 < a ∧v2 > b) →v1 ∗v2 < b ∗v1 + a ∗v2 −a ∗b
(v1 < a ∧v2 < b) →v1 ∗v2 > b ∗v1 + a ∗v2 −a ∗b
(v1 > a ∧v2 > b) →v1 ∗v2 > b ∗v1 + a ∗v2 −a ∗b
Fig. 3. Axioms of the multiplication function.
Input and Initialization. The algorithm takes as input an SMT(NIRA) formula
ϕ, a LIRA objective obj and a threshold precision value ϵ. (We can assume
wlog. that obj is a LIRA term because, if not so, we can rewrite ⟨ϕ, obj⟩into
⟨ϕ ∧(v = obj), v⟩, v being a fresh variable.) Lines 1–4 are part of the startup
phase of the OMT(NIRA) algorithm. First, the UFLIRA abstraction ˆϕ over-
approximating ϕ is computed at line 1. Next, the current best model M, the
set of optimization constraints Θ and the set of linearization lemmas Γ are
initialized to the empty set (lines 2–4).6
Main Loop. Given the current best model M, optimization constraints Θ and
linearization constraints Γ, the algorithm enters into its main loop (lines 5–19),
which can be virtually divided into two distinct blocks.
The ﬁrst block, lines 6–9, corresponds to a single application of the incre-
mental linearization schema presented in Fig. 1, lines 4–7. The goal of this phase
is to ﬁnd an initial abstract UFLIRA model ˆμ of ˆϕ ∧ Γ ∧ Θ that is reﬁned
into a NIRA model μ of ϕ ∧ Θ. This step can have three possible outcomes.
(i) SMT-UFLIRA-check fails to ﬁnd such ˆμ because ˆϕ ∧ Γ ∧ Θ is
UFLIRA-unsatisﬁable. This implies that ϕ∧ Θ is also NIRA-unsatisﬁable,
6 The same considerations as in Footnote 5 apply here as well.

220
F. Bigarella et al.
Fig. 4. A baseline schema of our OMT(NIRA) procedure, with linear search.
Fig. 5. The OMT counterpart of the SMT-Check-Refine in Fig. 5.
because the former is an over-approximation of the latter. Thus, there is
no better model than the current one (if any), so that the execution breaks
out of the loop (lines 6–8);
(ii) SMT-UFLIRA-check succeeds in ﬁnding an UFLIRA model ˆμ, but SMT-
Check-Refine fails to reﬁne ˆμ into a NIRA model μ for ϕ ∧ Θ (lines 6,

Optimization Modulo Non-linear Arithmetic via Incremental Linearization
221
9).7 If so, SMT-Check-Refine returns a set of UFLIRA constraints Γ
′
ruling out ˆμ (and other spurious solutions) from the feasible search space,
and the procedure skips the second block of lines 10–18, jumping directly
to line 19;
(iii) ˆμ is successfully reﬁned and rewritten into a NIRA model μ for ϕ ∧ Θ,
allowing for entering into the second block of lines 10–18.
The second block, lines 10–18, is responsible for advancing the optimization
search. First, the new current best NIRA model μ for ϕ ∧ Θ is stored into M
(line 11). Then the algorithm ﬁnds a new UFLIRA model ˆμ
′ for ˆϕ ∧ Γ ∧ Θ
with the best possible value of obj s.t. ˆμ
′ assigns the same truth values as μ
to the atoms in ˆϕ ∧ Γ ∧ Θ (lines 12–13). (The latter restriction forces the
minimization procedure to search for an improving solution in the same region
as the non-linear model μ.) To do this, the truth assignment ˆψ induced by μ on
the atoms in ˆϕ ∧ Γ ∧ Θ is extracted (line 12), and a standard minimization
algorithm for linear arithmetic is invoked on ˆψ to ﬁnd an UFLIRA model ˆμ
′ for
ˆψ which minimizes obj (line 13).
Notice that, ˆμ
′ is a model for ˆϕ∧ Γ ∧ Θ, but not necessarily so for ϕ∧Θ.
Therefore ˆμ
′ is checked for spuriousness with a call to a function OMT-Check-
Refine (see Fig. 5), the OMT counterpart of SMT-Check-Refine (line 14). If
the reﬁnement process succeeds, then M is updated with the new current best
NIRA model μ
′ (lines 15–16). Notice that ˆμ
′[obj] ≤μ
′[obj] ≤μ[obj], because
ˆμ
′[obj] is the lower bound for the value of obj in models sharing the same truth
assignment ˆψ. Otherwise, OMT-Check-Refine returns a set of UFLIRA con-
straints Γ
′ ruling out ˆμ
′ (and other spurious solutions) from the feasible search
space.
In either case, the optimization search is advanced by extending the set of
optimization constraints Θ with a fresh linear constraint of the form (obj < ub),
where ub is computed by an external call to Get-Upper-Bound (lines 17–18).
In its simplest form, Get-Upper-Bound simply returns the value of obj in
the current non-linear optimal model M. (A more sophisticate version will be
discussed later.)
At the end of each iteration of the loop (line 19), the set of linearization
constraints Γ is extended with the set of UFLIRA constraints Γ
′, generated by
either SMT-Check-Refine (line 9) or OMT-Check-Refine (line 14), so as
to permanently rule out spurious solutions that have already been encountered.
The control-ﬂow reaches lines 20–23 only after breaking the loop at line 8.
At this point the algorithm returns sat and the latest non-linear optimal model
M if available, and unsat plus an empty model otherwise.
OMT-Check-Refine in Fig. 5 is the OMT counterpart of SMT-Check-
Refine in Fig. 2. The only diﬀerence between these two functions is that OMT-
Check-Refine tries also to improve as much as possible the value of obj while
reﬁning the input model. This happens in line 3, where an UFLIRA OMT call
7 We stress the fact that SMT-Check-Refine returning false does not mean that
ˆϕ ∧ Θ is NIRA-unsatisﬁable, rather that it failed to prove it satisﬁable.

222
F. Bigarella et al.
is performed instead of an SMT one, so that the resulting model (if any) is the
best possible among those allowed by the multiplication line constraint in (2).
Notice that OMT-UFLIRA-Check-Minimize can even ﬁnd that obj is
unbounded, i.e., that ˆψ∗has models with arbitrarily big negative M[obj]. If
so, then the main procedure can return that obj is unbounded, because ˆψ∗is
an underapproximation of the original formula, s.t. the latter has models with
arbitrarily big negative M[obj] as well.
Progress. The progress towards an optimum solution within the same truth
assignment ˆψ is achieved in two distinct steps.
First, in Fig. 4 line 13, UFLIRA-Minimize searches for the best abstract
model ˆμ
′ which is compatible with the current truth assignment ˆψ, so that to
search for a reﬁned model μ
′ starting from a point ˆμ
′ which is positioned in the
direction indicated by obj.
Second, in Fig. 5 line 3, OMT-UFLIRA-Check-Minimize ﬁnds the best
possible among the possible reﬁnements of ˆψ allowed by the multiplication line
constraint in (2).
Termination. We notice that the algorithm in Fig. 4 is not guaranteed to termi-
nate, even when the objective function is lower-bounded.
First, the SMT(NIRA) decision procedure based on incremental linearization
is incomplete, as described in [13]. Therefore, it is possible for the algorithm to
get indeﬁnitely stuck in the main loop enumerating one spurious solution after
another.8
Second, whereas an OMT(NIRA) problem may admit irrational minimum
values for obj, the algorithm in Fig. 4 can return only rational values because it
is based only on UFLIRA SMT/OMT calls, so that it may produce an inﬁnite
sequence of rational solutions progressively approaching the irrational minimum
one.
Third, the linear search strategy in the algorithm of Fig. 4 is not guaranteed
to converge towards the optimum value of obj in ϕ. In fact, each linear step
may improve the value of the objective function by a negligible amount only (in
particular when working on a continuous domain), even maintaining the same
truth assignment ˆψ, i.e., without toggling the truth values of the atoms of ˆϕ
(and hence of ϕ) induced by the current models. As a result, the algorithm may
end up enumerating an inﬁnite sequence of improving solutions within the same
propositional branch of the search.
The latter fact deserves some more explanation. Let Δ
def
= M[obj] −ˆμ
′[obj]
be the diﬀerence between the optimization search upper bound ub computed
at line 17 by the basic implementation of Get-Upper-Bound (M[obj], i.e.
either μ
′[obj] or μ[obj]), and the UFLIRA-optimum ˆμ
′[obj] computed by OMT-
UFLIRA-minimize at line 13. Then Δ ≥0 because ˆμ
′[obj] ≤μ
′[obj] ≤μ[obj].
When Δ = 0, the unit clause (obj < ub) learned at line 18 forces the change
8 For the sake of simplicity, here we do not take into consideration the special termi-
nation condition based on a ﬁnite budget described in [13].

Optimization Modulo Non-linear Arithmetic via Incremental Linearization
223
to a new propositional branch ˆψ of the search because ˆψ ∧(obj < ub) is LIRA-
inconsistent, and moves the optimization search to explore a new region of the
search space. Instead, when Δ > 0 this is not the case, so that the OMT solver
may keep looking for an improving NIRA solution in the same region.
Early Termination. We remark that, when forced to terminate by external events
(e.g., a timeout), our procedure can return the current best result as a partial-
optimum solution.
3.2
Algorithm Improvements
Incrementality of SMT(UFLIRA) and OMT(UFLIRA) Calls. In the algorithms
of Fig. 4 and Fig. 5, all the calls to SMT(UFLIRA) and OMT(UFLIRA) (func-
tions SMT-UFLIRA-Check and OMT-UFLIRA-Check-Minimize) can be
performed incrementally (in our implementation, by exploiting the incremental
interface of OptiMathSAT), so that to avoid exploring the same portions of
the search space multiple times.
Linear-Search Strengthening. In order to increase the pruning power of the linear
search constraints learned during the optimization search, we modify the behav-
ior of the function Get-Upper-Bound called at line 17 in Fig. 4 as follows.
First, we compute
γ
def
=
|ˆμ
′[obj] −M[obj]|
max{|ˆμ
′[obj]|, |M[obj]|},
(3)
where M is the current best NIRA model for ϕ ∧ Θ and ˆμ
′ is the UFLIRA-
optimal model for ˆϕ ∧ Γ ∧ Θ. (We recall that ˆμ
′[obj] is the lower bound for
the value of obj in models sharing the same truth assignment ˆψ.)
If the value of γ is greater than the input threshold precision value ϵ, then
Get-Upper-Bound returns M[obj] as above. Otherwise, we are not interested
in further improving the current best solution in the interval [ˆμ
′[obj], M[obj]).
Therefore, Get-Upper-Bound returns ˆμ
′[obj] instead of M[obj] as the new
upper bound ub, which is such that ˆψ ∧(obj < ub) is UFLIRA-inconsistent.
Thus in the next loop the procedure is forced to search for models in a new
propositional branch.
Henceforth, M is considered the current best model unless/until some new
model M′ is found s.t. M′[obj] < ˆμ
′[obj]. If this is the case, then the search
proceeds. Otherwise, if the procedure concludes that no such model exists (line 8)
then M is returned as best model, within the relative error margin of γ (3).
Notice that, in this case, it is also possible to further reﬁne the search by
setting Θ := Θ\{(obj < ˆμ
′[obj])} ∪{¬(obj < ˆμ
′[obj]), (obj < M[obj])}, and then
proceed the search for a better solution within the interval [ˆμ
′[obj], M[obj]),
either by linear or binary search.

224
F. Bigarella et al.
Fig. 6. The ComputePivot function for OMT(NIRA) in OptiMathSAT.
Binary Search. We use the binary search strategy to gain some control on the
amount of progress that is made at each step of the optimization search. The
ComputePivot() procedure is displayed in Fig. 6.
If a lower bound lb ̸= −∞is available, then (lb+ub)/2 is returned (lines 1–2).
The main diﬀerence with the binary search strategy described in Sect. 2.1 is in
how an initial pivot is computed when no lower bound lb is available (lines 3–8).
In this case, the procedure determines the best pivoting value heuristically:
– if ˆμ
′[obj] ̸= −∞, then its value is returned as the new pivot (lines 3–4).
Intuitively, this results in a pivoting constraint that is just strong enough to
force the OMT solver to look for a model of ˆϕ ∧ Γ ∧ Θ on a diﬀerent
propositional branch;
– otherwise, if the current interval contains 0, then a pivoting step on 0 is
forced (lines 5–6). The idea is to discover as quickly as possible the sign of
the optimum solution;
– if none of the above apply, so that the actual optimal value of obj can be
anywhere within the negative interval (−∞, M[obj]], then the double of the
(negative) value of M[obj] is returned (lines 7–8). Doubling the negative value
at each iteration ensures that the search proceeds as quickly as possible to
the discovery of an initial lower bound, or to a concrete solution as close as
possible to −∞if no such lower bound exists.
4
Experimental Evaluation
Tools Under Test. We have implemented the novel OMT(NIRA) algorithm
described in Sect. 3 within the OMT solver OptiMathSAT [37]. We have exper-
imentally validated our algorithm with an analysis of the performance of Opti-
MathSAT in dealing with OMT(NRA) and OMT(NIA) problems, and com-
pared these results with the other available OMT solver, Z3 4.8.10 [8]. Although
Z3 does not oﬃcially support optimization with non-linear constraints, we use
it as a baseline for the evaluation of the presented approach as no other tools
can handle our benchmarks. We did not compare against dReal [21] because

Optimization Modulo Non-linear Arithmetic via Incremental Linearization
225
it supports neither OMT(NIA) problems, nor our generated OMT(NRA) prob-
lems coming from planning applications. We did not modify default options of
any of the tools, besides using the option smt.arith.solver=2 for Z3.9 We have
tested OptiMathSAT with two conﬁgurations: OptiMathSAT(lin), using lin-
ear search for optimization, and OptiMathSAT(bin), using binary search. For
OptiMathSAT we have set the relative-error value ϵ (see Sect. 3) to its default
value ϵ
def
= 10−6.
We have run the experimental evaluation on a cluster consisting of 20 identi-
cal machines. Each of the machines is equipped with Intel Xeon CPU E5-2440 0
2.40 GHz CPU and 96 GB of RAM. The time limit for ﬁnding the optimal solu-
tion was set to 300 s for each job pair. Memory limit per job pair was set to
8 GiB.
The benchmark-sets, the results and the scripts necessary to reproduce the
experiment are made publicly available and can be downloaded from [1].
Benchmark Sets. We have automatically generated OMT(NRA) benchmark set
using the tool OMTPlan [27] extended to dump OMT(NRA) problems in ﬁles
to enable experimenting with diﬀerent solvers.10 OMTPlan is an AI Planner,
which uses Z3 as backend OMT engine, that searches for a sequence of actions
of increasing length from one initial completely-speciﬁed condition to a goal
state, so that a given cost function is minimized. The tool encodes the search
for a given plan length leveraging on the Z3 Python API to build and solve the
OMT problem. To generate the OMT(NRA) problems, we took existing planning
problems from the AI planning literature, and we adapted them to include non-
linear constraints in action preconditions, eﬀects and cost functions. We then
ran the tool to generate OMT problem ﬁles corresponding to problem encodings
of increasing length (namely 10, 15, 20, 25, 35, 50, 75, 100). This yielded 752
OMT(NRA) benchmarks that were used for the evaluation.
To evaluate the proposed approach also on OMT(NIA), we have automati-
cally generated OMT(NIA) benchmark sets by starting from the SMT problems
contained in the SMT-LIBv2 repository [4]. First, we selected 6680 SMT(NIA)
instances that are marked as satisﬁable in the repository. In order to transform a
SMT instance into an OMT problem, we randomly select an arithmetic variable
and use it as the objective of the optimization search. We have repeated this step
up to 5 times for each instance, depending on the available number of variables,
and generated 33397 OMT(NIA) problems. The vast majority – 92.3% – of the
generated OMT(NIA) benchmarks comes from the benchmark family VeryMax.
Therefore, to keep the evaluation time reasonable, we randomly selected 10% of
the benchmarks from this family and evaluated the tools only on this subset.
We used all the benchmarks from the other families. In total, we thus evaluated
the tools on 5744 OMT(NIA) benchmarks.
9 This option has the eﬀect of enabling the legacy arithmetic solver. Without this
option, Z3 produced a signiﬁcant number of incorrect results.
10 The modiﬁed version of OMTPlan, together with the planning domain and prob-
lems used to generate this benchmark set, is available at [2].

226
F. Bigarella et al.
Fig. 7. Experimental results over the OMTPlan benchmark-set.
Veriﬁcation of Results. We have independently veriﬁed the correctness of the
optimal results found in this experiment using a portfolio of three SMT solvers:
CVC4 [38], MathSAT5 [14] and Z3 [17]. OptiMathSAT and Z3 produce in
output a minimum-cost value min.11 Thus, in order to verify the correctness of
such solution, we act as follows. For every OMT problem ⟨ϕ, obj⟩s.t. the solver
terminated and returned a model M with minimum value min
def
= M[obj], we
verify (i) that there exists indeed a solution of obj = min by checking if ϕ∧(obj =
min) is NIRA-satisﬁable and (ii) that min is a minimum solution by checking
that ϕ ∧(obj < min) is NIRA-unsatisﬁable. In some cases, OptiMathSAT and
Z3 can also decide that the optimization problem is unbounded. In these cases,
we checked whether the formula ϕ ∧(obj < −106) is NIRA-satisﬁable. Note
that this is not suﬃcient to prove that the problem indeed is unbounded; this
would require quantiﬁed reasoning. On the OMT(NRA) formulas, the solvers
can also decide that the optimum is inﬁnitesimally close to a given real number,
i.e., return an optimum k + ε. For these cases, we checked that (i) the formula
ϕ ∧(obj > k) ∧(obj < k + 10−6) is NIRA-satisﬁable and that (ii) the formula
ϕ ∧(obj ≤k) is NIRA-unsatisﬁable. Note that this would also require quantiﬁed
reasoning to conﬁrm the real optimum. If the result passes these checks, we
consider it as veriﬁed.
During the veriﬁcation, we imposed a timeout of 1200 s on the portfolio’s
execution for each problem, i.e., 600 s for checking (i) and 600 s for checking
(ii). To get more independent veriﬁcation results, we did not stop the portfolio
after the ﬁrst obtained result and let all the solvers ﬁnish. We did not observe
any incorrect results; unveriﬁed results are discussed in the presentation of the
results.
Result Tables and Scatter-Plots. The results of the experimental evaluation are
summarized in the two tables in Figs. 7 and 8. The columns list the total number
of instances (col. total), the number of timeouts (col. t/o), the number of time-
outs after which the solver was able to provide a partial minimum (col. partial),
the number of formulas decided as unsatisﬁable, if any (col. unsat.), the num-
ber of formulas with an unveriﬁed optimal result (col. unver.), the number of
formulas with a veriﬁed incorrect optimal result (col. incor.), the number of for-
mulas with a veriﬁed correct optimal result (col. correct), the total solving time
including all formulas solved correctly (col. time (s.)) and the number of formulas
11 Here we describe the case for minimization; the case for maximization is dual.

Optimization Modulo Non-linear Arithmetic via Incremental Linearization
227
Fig. 8. Experimental results over the OMT(NIA) benchmark-set.
that were uniquely solved by the given solver conﬁguration (col unique s.). (The
unique s. column for the v. best(OptiMathSAT) conﬁguration reports the
number of formulas that were solved only by one or both of OptiMathSAT
versions.)
In the scatter-plots (Fig. 9), we compare the size of the partial minima found
by OptiMathSAT(lin) and OptiMathSAT(bin) vs. those of Z3, when the
solvers were able to provide at least a partial minimum after the timeout, on
OMTPlan problems (1st row) and OMT(NIA) problems (2nd row) respectively.
The plots also include results where one of the solvers reported the minimum
but the other only ﬁnished with a partial minimum. As OMT(NIA) problems are
not bounded from below, their partial minima can happen to be arbitrarily big
negative numbers. We thus show partial minima smaller than −104 on the very
left and very bottom lines marked as < −10000. Because OMT(NIA) problems
are also discrete, we apply a small random jitter to their results, to better show
the number of benchmarks with identical results, which would otherwise overlap.
OMTPlan Results. Figure 7 presents the results for the OMTPlan benchmark
set. We note that the generated problems are very diﬃcult for all the solvers; only
17 benchmarks were solved by any of the solvers. On the whole, OptiMathSAT
solved the largest number of benchmarks within the timeout. On the other hand,
there is one benchmark12 that was correctly solved by Z3 but not by any of the
OptiMathSAT conﬁgurations.
While OptiMathSAT with linear search solves one more instance than with
binary search, our veriﬁcation portfolio solver was not able to verify the correct-
ness of this result. More generally, 16 out of 17 results of OptiMathSAT(lin)
were veriﬁed (7 by one solver, 2 by two solvers, and 7 by all three solvers);
all 16 results of OptiMathSAT(bin) were veriﬁed (7 by one solver, 2 by two
solvers, and 7 by all three solvers); and 7 out of 13 results of Z3 were veriﬁed
(all by all three solvers). The remaining 6 results of Z3 on which the veriﬁcation
did not ﬁnish were of form k + ε.
Note that by the nature of how the benchmarks were generated, some of
them are not satisﬁable. Although the numbers of unsatisﬁable benchmarks are
reported in the table, they are not relevant to the evaluation, as they depend
only on the performance of the base SMT(NRA) solver and do not compare
capabilities of its OMT(NRA) extension.
12 nl counters simple/fn-counters-simp instance 2 75.smt2.

228
F. Bigarella et al.
0 0
1
10
100
1000
10000
0
1
1
0
100
1000
10000
Z3
OptiMathSAT(LIN)
0 0
1
10
100
1000
10000
0
1
1
0
100
1000
10000
Z3
OptiMathSAT(BIN)
< −10000
−1000
−100
−10
−1
0
1
10
100
1000
< −10000 −1000
−100
−10
−10 1
10
100
1000
Z3
OptiMathSAT(LIN)
< −10000
−1000
−100
−10
−1
0
1
10
100
1000
< −10000 −1000
−100
−10
−10 1
10
100
1000
Z3
OptiMathSAT(BIN)
Fig. 9. Size of the partial minima found by OptiMathSAT(lin) (left) and Opti-
MathSAT(bin) (right) on Y axis vs. those of Z3 on X axis.
First row shows OMTPlan problems, second row shows OMT(NIA) problems.
Looking at the scatterplots (Fig. 9) we notice that, whereas OptiMathSAT
ﬁnds more minima, Z3 partial minima within the timeout are generally much
better than those of OptiMathSAT. We do not have a clear-cut explanation
of this apparently-contradictory fact.
OMT(NIA) Results. Figure 8 presents the results for the OMT(NIA) benchmark
set. In general, almost all the results produced by the solvers were veriﬁed to
be correct. For OptiMathSAT(lin), 3262 of total 3276 results were veriﬁed
(128 by one of the solvers, 1076 by two of the solvers, and 2058 by all three); for
OptiMathSAT(bin), 3247 of total 3258 results were veriﬁed (124 by one of the
solvers, 1078 by two of the solvers, and 2045 by all three); for Z3, 1957 of total
1975 results were veriﬁed (28 by one of the solvers, 518 by two of the solvers,
and 1411 by all three).
On the whole, OptiMathSAT solved the largest number of benchmarks
within the timeout. We note that there is not a signiﬁcant diﬀerence between
the performance of OptiMathSAT(lin) and OptiMathSAT(bin).

Optimization Modulo Non-linear Arithmetic via Incremental Linearization
229
Looking at the scatterplots (Fig. 9) we notice that, unlike with the OMTPlan,
there is no tool whose partial minima are deﬁnitely better than the others.
5
Conclusions and Future Work
In this paper, we have shown how incremental linearization can be extended
from SMT(NIRA) to OMT(NIRA) in a very simple way, producing an incom-
plete though eﬀective OMT procedure. We believe that this procedure, in its
simplicity, can also be used as a baseline for more elaborated procedures.
To this extent, we believe that many possible extension are possible. In a
short term, we plan to extend it to work also with transcendental functions,
exploiting the full expressive power of incremental-linearization approach in SMT
presented in [13], and then to test the eﬀectiveness of the procedures on real word
veriﬁcation problems, in particular of cyber-physical systems. In the middle term,
we plan to extend our encoders from MiniZinc to OMT and vice-versa [16] to
work with non-linear constraints, so that to be able to compare with tools and
problems coming from the Constraint Solving & Optimization community. In a
longer term, we plan to integrate our approach with more elaborated –though
possibly expensive– procedures.
References
1. https://es-static.fbk.eu/people/mjonas/papers/frocos21 oms/
2. https://github.com/roveri-marco/OMTNPlan
3. ´Abrah´am, E., Davenport, J.H., England, M., Kremer, G.: Deciding the consis-
tency of non-linear real arithmetic constraints with a conﬂict driven search using
cylindrical algebraic coverings. J. Log. Algebraic Methods Program. 119, 100633
(2021)
4. Barrett, C., Ranise, S., Stump, A., Tinelli, C.: The satisﬁability modulo theories
library (SMT-LIB) (2010). http://www.smtlib.org
5. Barrett, C., Sebastiani, R., Seshia, S.A., Tinelli, C.: Satisﬁability modulo theories,
chapter 26, pp. 825–885. Volume 185 of Biere et al. [7], February 2009
6. Benhamou, F., Granvilliers, L.: Continuous and interval constraints. In: Rossi, F.,
van Beek, P., Walsh, T. (eds.) Handbook of Constraint Programming, Volume 2
of Foundations of Artiﬁcial Intelligence, pp. 571–603. Elsevier (2006)
7. Biere, A., Heule, M.J.H., van Maaren, H., Walsh, T. (eds.): Handbook of Satisﬁa-
bility. IOS Press, February 2009
8. Bjørner, N., Phan, A.-D., Fleckenstein, L.: νZ - an optimizing SMT solver. In:
Baier, C., Tinelli, C. (eds.) TACAS 2015. LNCS, vol. 9035, pp. 194–199. Springer,
Heidelberg (2015). https://doi.org/10.1007/978-3-662-46681-0 14
9. Borralleras, C., Larraz, D., Rodr´ıguez-Carbonell, E., Oliveras, A., Rubio, A.:
Incomplete SMT techniques for solving non-linear formulas over the integers. ACM
Trans. Comput. Log. 20(4), 25:1–25:36 (2019)
10. Borralleras, C., Lucas, S., Oliveras, A., Rodr´ıguez-Carbonell, E., Rubio, A.: SAT
modulo linear arithmetic for solving polynomial constraints. J. Autom. Reason.
48(1), 107–131 (2012). https://doi.org/10.1007/s10817-010-9196-8

230
F. Bigarella et al.
11. Brauße, F., Korovin, K., Korovina, M., M¨uller, N.: A CDCL-style calculus for
solving non-linear constraints. In: Herzig, A., Popescu, A. (eds.) FroCoS 2019.
LNCS (LNAI), vol. 11715, pp. 131–148. Springer, Cham (2019). https://doi.org/
10.1007/978-3-030-29007-8 8
12. Cimatti, A., Griggio, A., Irfan, A., Roveri, M., Sebastiani, R.: Experimenting on
solving nonlinear integer arithmetic with incremental linearization. In: Beyersdorﬀ,
O., Wintersteiger, C.M. (eds.) SAT 2018. LNCS, vol. 10929, pp. 383–398. Springer,
Cham (2018). https://doi.org/10.1007/978-3-319-94144-8 23
13. Cimatti, A., Griggio, A., Irfan, A., Roveri, M., Sebastiani, R.: Incremental lin-
earization for satisﬁability and veriﬁcation modulo nonlinear arithmetic and tran-
scendental functions. ACM Trans. Comput. Log. 19(3), 19:1–19:52 (2018)
14. Cimatti, A., Griggio, A., Schaafsma, B.J., Sebastiani, R.: The MathSAT5 SMT
solver. In: Piterman, N., Smolka, S.A. (eds.) TACAS 2013. LNCS, vol. 7795, pp.
93–107. Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-36742-7 7
15. Collins, G.E.: Quantiﬁer elimination for real closed ﬁelds by cylindrical algebraic
decomposition-preliminary report. ACM SIGSAM Bull. 8(3), 80–90 (1974)
16. Contaldo, F., Trentin, P., Sebastiani, R.: From MiniZinc to optimization modulo
theories, and back. In: Hebrard, E., Musliu, N. (eds.) CPAIOR 2020. LNCS, vol.
12296, pp. 148–166. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-
58942-4 10
17. de Moura, L., Bjørner, N.: Z3: an eﬃcient SMT solver. In: Ramakrishnan, C.R.,
Rehof, J. (eds.) TACAS 2008. LNCS, vol. 4963, pp. 337–340. Springer, Heidelberg
(2008). https://doi.org/10.1007/978-3-540-78800-3 24
18. Dixon, C., Finger, M. (eds.): FroCoS 2017. LNCS (LNAI), vol. 10483. Springer,
Cham (2017). https://doi.org/10.1007/978-3-319-66167-4
19. Fontaine, P., Ogawa, M., Sturm, T., Vu, X.: Subtropical satisﬁability. In: Dixon
and Finger [18], pp. 189–206
20. Fuhs, C., Giesl, J., Middeldorp, A., Schneider-Kamp, P., Thiemann, R., Zankl, H.:
SAT solving for termination analysis with polynomial interpretations. In: Marques-
Silva, J., Sakallah, K.A. (eds.) SAT 2007. LNCS, vol. 4501, pp. 340–354. Springer,
Heidelberg (2007). https://doi.org/10.1007/978-3-540-72788-0 33
21. Gao, S., Kong, S., Clarke, E.M.: dReal: an SMT solver for nonlinear theories over
the reals. In: Bonacina, M.P. (ed.) CADE 2013. LNCS (LNAI), vol. 7898, pp. 208–
214. Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-38574-2 14
22. Jovanovi´c, D.: Solving nonlinear integer arithmetic with MCSAT. In: Bouajjani,
A., Monniaux, D. (eds.) VMCAI 2017. LNCS, vol. 10145, pp. 330–346. Springer,
Cham (2017). https://doi.org/10.1007/978-3-319-52234-0 18
23. Jovanovic, D., de Moura, L.: Solving non-linear arithmetic. ACM Commun. Com-
put. Algebra 46(3/4), 104–105 (2012)
24. Kong, S., Solar-Lezama, A., Gao, S.: Delta-decision procedures for exists-forall
problems over the reals. In: Chockler, H., Weissenbacher, G. (eds.) CAV 2018.
LNCS, vol. 10982, pp. 219–235. Springer, Cham (2018). https://doi.org/10.1007/
978-3-319-96142-2 15
25. Kremer, G., ´Abrah´am, E.: Fully incremental cylindrical algebraic decomposition.
J. Symb. Comput. 100, 11–37 (2020)
26. Kremer, G., Corzilius, F., ´Abrah´am, E.: A generalised branch-and-bound approach
and its application in SAT modulo nonlinear integer arithmetic. In: Gerdt, V.P.,
Koepf, W., Seiler, W.M., Vorozhtsov, E.V. (eds.) CASC 2016. LNCS, vol. 9890, pp.
315–335. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-45641-6 21

Optimization Modulo Non-linear Arithmetic via Incremental Linearization
231
27. Leofante, F., Giunchiglia, E., ´Abrah´am, E., Tacchella, A.: Optimal planning mod-
ulo theories. In: Bessiere, C. (ed.) Proceedings of the Twenty-Ninth International
Joint Conference on Artiﬁcial Intelligence, IJCAI 2020, pp. 4128–4134. ijcai.org
(2020)
28. Mar´echal, A., Fouilh´e, A., King, T., Monniaux, D., P´erin, M.: Polyhedral approx-
imation of multivariate polynomials using Handelman’s theorem. In: Jobstmann,
B., Leino, K.R.M. (eds.) VMCAI 2016. LNCS, vol. 9583, pp. 166–184. Springer,
Heidelberg (2016). https://doi.org/10.1007/978-3-662-49122-5 8
29. Marques-Silva, J.P., Lynce, I., Malik, S.: Conﬂict-driven clause learning SAT
solvers, chapter 4, pp. 131–153. Volume 185 of Biere et al. [7], February 2009
30. Matiyasevich, Y.V.: Hilbert’s Tenth Problem. Foundations of Computing, MIT
Press, Cambridge (1993)
31. Nadel, A., Ryvchin, V.: Bit-vector optimization. In: Chechik, M., Raskin, J.-F.
(eds.) TACAS 2016. LNCS, vol. 9636, pp. 851–867. Springer, Heidelberg (2016).
https://doi.org/10.1007/978-3-662-49674-9 53
32. Nieuwenhuis, R., Oliveras, A.: On SAT modulo theories and optimization problems.
In: Biere, A., Gomes, C.P. (eds.) SAT 2006. LNCS, vol. 4121, pp. 156–169. Springer,
Heidelberg (2006). https://doi.org/10.1007/11814948 18
33. Reynolds, A., Tinelli, C., Jovanovic, D., Barrett, C.W.: Designing theory solvers
with extensions. In: Dixon and Finger [33], pp. 22–40
34. Sebastiani, R., Tomasi, S.: Optimization in SMT with LA(Q) cost functions. In:
Gramlich, B., Miller, D., Sattler, U. (eds.) IJCAR 2012. LNCS (LNAI), vol.
7364, pp. 484–498. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-
642-31365-3 38
35. Sebastiani, R., Tomasi, S.: Optimization modulo theories with linear rational costs.
ACM Trans. Comput. Log. 16(2), 1–46 (2015)
36. Sebastiani, R., Trentin, P.: Pushing the envelope of optimization modulo theories
with linear-arithmetic cost functions. In: Baier, C., Tinelli, C. (eds.) TACAS 2015.
LNCS, vol. 9035, pp. 335–349. Springer, Heidelberg (2015). https://doi.org/10.
1007/978-3-662-46681-0 27
37. Sebastiani, R., Trentin, P.: OptiMathSAT: a tool for optimization modulo
theories. J. Autom. Reason. 64, 423–460 (2020). https://doi.org/10.1007/s10817-
018-09508-6
38. Stump, A., Barrett, C.W., Dill, D.L.: CVC: a cooperating validity checker. In:
Brinksma, E., Larsen, K.G. (eds.) CAV 2002. LNCS, vol. 2404, pp. 500–504.
Springer, Heidelberg (2002). https://doi.org/10.1007/3-540-45657-0 40
39. Trentin, P., Sebastiani, R.: Optimization modulo the theory of ﬂoating-point num-
bers. In: Fontaine, P. (ed.) CADE 2019. LNCS (LNAI), vol. 11716, pp. 550–567.
Springer, Cham (2019). https://doi.org/10.1007/978-3-030-29436-6 33
40. Weispfenning, V.: Quantiﬁer elimination for real algebra - the quadratic case and
beyond. Appl. Algebra Eng. Commun. Comput. 8(2), 85–101 (1997). https://doi.
org/10.1007/s002000050055
41. Zankl, H., Middeldorp, A.: Satisﬁability of non-linear (Ir)rational arithmetic. In:
Clarke, E.M., Voronkov, A. (eds.) LPAR 2010. LNCS (LNAI), vol. 6355, pp. 481–
500. Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-17511-4 27

Quantiﬁer Simpliﬁcation by Uniﬁcation
in SMT
Pascal Fontaine1,2
and Hans-J¨org Schurr1(B)
1 University of Lorraine, CNRS, Inria, and LORIA, Nancy, France
hans-jorg.schurr@inria.fr
2 Universit´e de Li`ege, Li`ege, Belgium
pascal.fontaine@uliege.be
Abstract. Quantiﬁer reasoning in SMT solvers relies on instantiation:
ground instances are generated heuristically from the quantiﬁed formulas
until a contradiction is reached at the ground level. Current instantia-
tion heuristics, however, often fail in presence of nested quantiﬁers. To
address this issue we introduce a uniﬁcation-based method that augments
the problem with shallow quantiﬁed formulas obtained from assertions
with nested quantiﬁers. These new formulas help unlocking the regu-
lar instantiation techniques, but parsimony is necessary since they might
also be misguiding. To mitigate this, we identify some eﬀective restricting
conditions. The method is implemented in the veriT solver, and tested
on benchmarks from the SMT-LIB. It allows the solver to prove more
formulas, faster.
Keywords: SMT · Quantiﬁer instantiation · Theorem proving
1
Introduction
Satisﬁability modulo theories (SMT) solvers are successfully used as back-ends
for formal method applications, within interactive proof assistants or veriﬁcation
platforms. SMT solvers based on the CDCL(T ) calculus [6] excel at handling
quantiﬁer-free problems with theories—SMT problems with thousands of asser-
tions are frequent. While originally SMT solvers were mostly applied on such
problems, an increasing number of applications require some support for quan-
tiﬁer reasoning. Their main approach to handle quantiﬁers is quantiﬁer instan-
tiation. This approach separates the quantiﬁed assertions from the ground part
of the problem. Whenever the solver ﬁnds a model for the ground part, it gen-
erates new ground instances of the quantiﬁed formulas. This is repeated until
the ground solver determines that the ground problem is unsatisﬁable. When
done fairly, this approach is refutationally complete for many theories and due
to the strength of ground solving it is also very powerful in practice. SMT solvers
use multiple instantiation strategies to ﬁnd these instances. The main challenge
is to ﬁnd the right instances without misguiding or overwhelming the solver.
Often one can observe some kind of butterﬂy eﬀect: if the instantiation methods
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 232–249, 2021.
https://doi.org/10.1007/978-3-030-86205-3_13

Quantiﬁer Simpliﬁcation by Uniﬁcation in SMT
233
are unlucky, the solver might be misguided to explore a large set of irrelevant
instances and reach the solving timeout. In this regard, every strategy has its
own strengths and weaknesses (Sect. 2).
If the problem contains a quantiﬁed lemma that also occurs, for example, as
an antecedent for another formula, the common instantiation methods often fail
to quickly produce the right instances. This structure is quite typical of problems
generated by interactive theorem provers—a domain to which the SMT solver
veriT has been successfully applied [10,20]. The following toy example illustrates
this issue. We will use it to illustrate various ideas.
Example 1.
∀x. P(x) →P(f(x, c))
(1)
∀y. ((∀z. P(z) →P(f(z, y))) →¬P(y))
(2)
P(c)
(3)
This problem is trivially unsatisﬁable: when y is set to c, Assertion 1 occurs
as the antecedent of the implication in Assertion 2, so ¬P(c) is a direct conse-
quence of the ﬁrst two assertions, in contradiction with the third. As described
in Sect. 2.3, all major instantiation techniques fail to directly produce the correct
instances for this problem. Because SMT solvers typically only perform very lim-
ited preprocessing on quantiﬁed formulas and especially do not calculate a full
clause normal form, the instantiation methods fail to recognize and exploit the
fact that Assertion 1 and the antecedent in Assertion 2 are so similar. Since the
instantiation methods do not produce the correct instances early, the SMT solver
will need multiple instantiation rounds to solve the problem. This can lead to the
butterﬂy eﬀect mentioned above. Real world examples are usually more complex.
For example, there are often many ground terms which mislead the instantia-
tion heuristics. Furthermore, the assertions in this example are Horn clauses and
could be handled by specialized reasoning. Practical problems, however, are not
restricted to Horn clauses.
In CDCL(T ) quantiﬁed formulas are considered black boxes, and are
abstracted as propositional variables in the propositional abstraction of the input
formula. These propositional literals are generally of no value to the ground
solver. We here make use of them to simplify larger formulas. To solve the exam-
ple above we identify the occurrence of the unit Assertion 1 within Assertion 2.
By using uniﬁcation we can eliminate this quantiﬁed subformula. The result after
simpliﬁcation is the ground formula ¬P(c). After this formula is conjoined to the
problem, it is trivially contradictory. In the general case, we use asserted quan-
tiﬁed formulas to soundly simplify nested formulas and augment the problem
with the result. We propose multiple variants of the core procedure (Sect. 3).
So far, techniques inspired by resolution-based theorem provers are under-
represented in SMT solvers. Systems such as DPLL(Γ) [15], DPLL(Γ + T ) [7],
and AVATAR [22] combine the inference system of theorem provers with the
CDCL(T) transition system on a fundamental level, but the combination is
coarse—in those systems the two worlds work side-by-side in tandem. Instead,

234
P. Fontaine and H.-J. Schurr
Instantiation Procedure
Ground Solver
Preprocessed Problem
Problem
UNSAT
Timeout
Fig. 1. The instantiation loop of an SMT solver refuting a problem.
our uniﬁcation-based method is a lightweight and easily implemented prepro-
cessing technique that solves some concrete shortcoming of current instantiation
techniques.
We implemented our method in the SMT solver veriT [8]. To ensure the
process is fast, we use a standard term index and uniﬁcation algorithm which
we extended to handle the presence of strongly quantiﬁed variables (Sect. 4).
The evaluation shows that our technique enables veriT to solve benchmarks
not solved by any strategy before. When applicable, the method often allows
veriT to solve problems within a short timeout. The diﬀerent variants of the
simpliﬁcation process are useful within a strategy schedule (Sect. 5).
2
CDCL(T ) and Quantiﬁer Instantiation
Figure 1 shows the operation of a typical SMT solver when refuting a problem.
It ﬁrst preprocesses the input problem (Sect. 2.2). Then two procedures together
refute the problem: the ground solver either refutes the problem on the ground
level, or ﬁnds a ground model. If a model is found the instantiation procedure
creates new ground lemmas (Sect. 2.3).
2.1
Preliminaries
We use the many-sorted ﬁrst-order logic with equality as deﬁned in the SMT-LIB
standard [5] and assume the reader is familiar with the notions of signature, term,
free and bound variable, quantiﬁed and ground formula, literal, and substitution.
We use x, y, z to denote variables; s, t to denote terms; ϕ, ψ to denote formulas
(i.e., terms of sort Bool); P to denote a predicate (i.e., a function with codomain
sort Bool); and c to denote constants. To denote the substitution which replaces
a variable x with a term t we write [t/x]. As usual, σ stands for a substitution.
We write ¯t for the sequence of terms t1, . . . , tn for an unspeciﬁed n ∈N+ that is
either irrelevant or clear from the context. Hence, ∀¯x.ϕ corresponds to a term
∀x1, . . . , xn. ϕ. We write free(t) to denote the free variables of a term t. The set
T (S) is the set of all subterms of the terms in S. We omit sorts when they are
clear from the context and assume that sort constraints are always respected,
e.g., substitutions only use terms of the same sort as the substituted variable.
Like in the SMT-LIB standard, the signature Σ always contains a sort Bool,
two constants ⊤and ⊥, the usual Boolean connectives, and a family of predicate
symbols (≈: τ × τ →Bool) interpreted as equality for each sort τ.
A trimmed formula is the generalization of the notion of atom to arbi-
trary formulas: trim(ϕ) is the formula ϕ after removing all leading negations.

Quantiﬁer Simpliﬁcation by Uniﬁcation in SMT
235
For example, trim(¬¬(ϕ1 ∨¬ϕ2)) is ϕ1 ∨¬ϕ2. The polarity pol(ϕ) ∈{+, −} of
a formula ϕ is −(negative) if trim(ϕ) removes an odd number of negations and
+ (positive) otherwise.
We write t[ ] for a term with a hole and t[u] for the term where the hole has
been replaced by u. Any term has at most one hole. We borrow the notions of
weak and strong quantiﬁers [2]: since we are working in a refutation context, a
positive occurrence of a quantiﬁer ∃¯x. ϕ or a negative occurrence of a quantiﬁer
∀¯x. ϕ is strong and a negative occurrence of a quantiﬁer ∃¯x. ϕ or a positive
occurrence of a quantiﬁer ∀¯x. ϕ is weak. We will call the subformula ψ of Q¯x.ψ,
where Q ∈{∀, ∃}, the matrix, even though ψ might not be in clausal normal
form. Without loss of generality, we assume that all quantiﬁed variables have
been renamed to be distinct.
To handle strong quantiﬁers we use the Skolemization operator sk. For a
formula Q¯x.ψ it is deﬁned as sk(Q¯x.ψ, ¯y) := ψ[s1(¯y)/x1] . . . [sn(¯y)/xn] and each
si is a fresh function symbol of correct arity. The strong quantiﬁer Q might not
be below a weak quantiﬁer. In this case, we write sk(Q¯x.ψ, ∅) and the fresh
symbols are constants.
2.2
Preprocessing
Given an input formula P (i.e., a term of sort Bool) a CDCL(T ) solver performs
multiple preprocessing steps before the solving phase is started. This produces
an equisatisﬁable problem P′ which is a conjunction of clauses.
To make eﬃcient use of the ground solver, ground formulas are classiﬁed.
Quantiﬁed formulas, however, are treated diﬀerently. Their are usually not put
in prenex form or clausiﬁed. Furthermore, strong quantiﬁers are usually not
fully Skolemized. This has the beneﬁt that the original structure of quantiﬁed
formulas is preserved, which is crucial for some instantiation techniques.
Preprocessing applies some light form of rewriting on quantiﬁed formulas. In
veriT, most rewriting steps apply to constants below arithmetic operators and
Boolean connectives. For example, the term f(5+c1 +3, c2 ∗(3−3)) is simpliﬁed
to f(8 + c1, 0) and (⊥→ϕ1) →ϕ2 is replaced by ϕ2. Rewriting also ensures
that certain global invariants of veriT are met: for instance, all occurrences of
bound variables are renamed to distinct variables, and quantiﬁers over Boolean
variables are removed by Shannon expansion.
Skolemization is another preprocessing step applied to quantiﬁed formu-
las. How Skolemization is applied is implementation dependent. The common
CDCL(T ) calculus [6] is only concerned with ground reasoning. While the SMT
solver Z3 [16] has a builtin tactic called nnf that fully applies Skolemization,
CVC4 [4] and veriT only Skolemize outermost strong quantiﬁers in their default
conﬁguration. The rewriter of veriT Skolemizes outermost strong quantiﬁers by
replacing the subformula trim(ℓ) of a formula ℓby sk(trim(ℓ), ∅) if trim(ℓ)
has the form Q¯x. ϕ, the quantiﬁer Q is strong, and ℓdoes not occur below any
quantiﬁer.
Due to the limited preprocessing of quantiﬁed formulas, some disjuncts of P ′
start with a weak quantiﬁer and contain complicated formulas. To clarify the

236
P. Fontaine and H.-J. Schurr
distinction, we call the disjuncts which start with a quantiﬁer, and are hence
black boxes to the ground solver, boxes. Without loss of generality, we assume
all boxes are universally quantiﬁed. Disjuncts which are not boxes are ground
literals. A unit-box is a clause with only one disjunct that is a box.
Example 2. The preprocessor will not perform any operations on Example 1.
We can illustrate the perspective of the ground solver by replacing quantiﬁed
formulas by frames. The resulting clause are:
1
,
2
, and P(c). The ﬁrst two
clause are unit-boxes and both boxes will be abstracted to diﬀerent propositional
variables for the SAT solver.
2.3
Instantiation Techniques
The instantiation loop (Fig. 1) starts with the ground solver. It either deter-
mines that the ground literals of the preprocessed problem P′ are unsatisﬁable
or produces a ground model M. If the ground problem is unsatisﬁable, then P
is unsatisﬁable. M is a set of formulas G ∪Q where G are ground literals, and
Q are boxes. M propositionally satisﬁes P′, and G is consistent with respect
to the used theories. The instantiation procedure will then generate lemmas
(∀¯x. ϕ) →ϕσ where (∀¯x. ϕ) ∈Q and σ is a substitution of ¯x with ground terms.
The generated lemmas are added conjunctively to P′ and the ground solver is
called again.
We now give an overview of common instantiation techniques and illustrate
why they cannot tackle Example 1 quickly. These techniques are presented in
the order they are used by veriT: it ﬁrst tries conﬂict-driven instantiation. If this
fails, it will try trigger-based instantiation. Should this produce no instances, it
will fall back to enumerative instantiation. Model-based quantiﬁer instantiation
is not implemented by veriT: it is crucial for satisﬁability, but veriT focuses on
proving unsatisﬁability.
Conﬂict-Driven Instantiation. This method tries to ﬁnd an instance that con-
tradicts the ground model M in the theory of equality and uninterpreted func-
tions (EUF) [3,18]. Hence, it searches for a box ∀¯x. ϕ ∈Q and a substitution
σ such that G ∧ϕσ ⊨EUF ⊥. It returns the instance ϕσ or fails. It can also
search for substitutions which solve multiple constraints simultaneously. Hence,
this method can ﬁnd a contradicting instance of a clause ψ1 ∨· · ·∨ψn by solving
G ∧ψ1σ ⊨EUF ⊥, . . . , G ∧ψnσ ⊨EUF ⊥, but all ψis must be quantiﬁer-free.
Conﬂict-driven instantiation is very helpful, since it only generates instances
that are immediately useful. It forces the ground solver to ﬁnd new models and
eliminates spurious models from the search space.
Since Assertion 2 of Example 1 contains a quantiﬁer, it cannot be instanti-
ated by conﬂict driven instantiation. Conﬂict driven instantiation also fails for
Assertion 1, because initially there is no ground formula that would be in con-
ﬂict with an instance of P(f(x, c)). Even if the second assertion was Skolemized,
conﬂict-driven instantiation would fail: since there is no ground instance of the
Skolem term, no conﬂicting instance can be found.

Quantiﬁer Simpliﬁcation by Uniﬁcation in SMT
237
Trigger-Based Instantiation. This instantiation scheme works by matching trig-
gers with the current ground model. Triggers associate with every box ∀¯x. ϕ ∈Q
one or more lists of quantiﬁer-free terms t1, . . . , tn such that free(t1) ∪· · · ∪
free(tn) = {¯x}. The triggers are either provided by the user or are heuristi-
cally generated. Trigger inference uses the structure of the quantiﬁed formulas
which is preserved by preprocessing. To construct instances of ϕ, trigger-based
instantiation searches for substitutions σ and terms g1, . . . , gn ∈T (G) such that
G ⊨EUF tiσ ≈gi. If the search is successful, it returns the instance ϕσ.
The process of matching terms within the theory of equality and uninter-
preted functions is called E-matching [9,11,14]. Due to the heuristic nature of
trigger-based instantiation, the generated instances might not be useful to solve
the problem. Instead they can slow down or mislead the solver.
In the case of Example 1, a trigger P(x) on Assertion 1 would produce
the useless instance P(c) →P(f(c, c)) and a trigger P(f(x, c)) initially cannot
match anything. The trigger P(y) on Assertion 2 would produce the instance
(∀z. P(z) →P(f(z, c))) →¬P(c). This instance is a step towards solving the
problem: the strong variable z is no longer below a quantiﬁer and will be Skolem-
ized to create the formula P(s1) →P(f(s1, c)) →¬P(c) where s1 is a fresh
constant. During the next instantiation round the trigger P(x) on Assertion 1
generates the instance P(s1) →P(f(s1, c)) which leads to the contradiction.
This technique is very sensitive to the availability of the right ground terms
in the ground model. In the above example, if the formula contained ∀x. P(x)
instead of P(c), trigger-based instantiation would have been helpless.
Enumerative Instantiation. While conﬂict driven instantiation is guided by the
ground model it tries to contradict, and trigger-based instantiation is guided by
the triggers, enumerative instantiation [17] is unguided. For a box with the form
∀¯x. ϕ ∈Q it creates all substitutions [¯t/¯x] where the terms ¯t are ground terms
from T (M). To limit the number of generated instances the procedure only
uses the ground terms minimal with respect to some term order and does not
return instances already implied by the ground model (i.e., it only returns ϕσ
if G ⊭EUF ϕσ). Enumerative instantiation ensures the theoretical completeness
of the SMT solver for the theory of uninterpreted functions. It can also ﬁnd the
small ground terms that are sometimes necessary to enable the two previous
techniques to work, and is thus a useful fallback strategy.
For Example 1, enumerative instantiation also needs at least two rounds.
First, the variable y of Assertion 2 is instantiated with c. Then, after Skolemiza-
tion, Assertion 1 can be instantiated with the new Skolem constant. Eventually,
the cooperation of enumerative instantiation and the above techniques would
succeed. However, in presence of many ground terms of the same sort as c, enu-
merative instantiation might have needed a lot of time to ﬁnd the right instance.
Model-Based Quantiﬁer Instantiation. Finally, model-based quantiﬁer instantia-
tion [12] extends heuristically the ground model M to a ﬁrst-order interpretation
I and tests if this interpretation is a model: if there exists a box of the form
∀¯x. ϕ ∈Q and a substitution σ of ¯x with terms from T (G) such that I ⊨¬ϕσ,

238
P. Fontaine and H.-J. Schurr
then M is not a true model of P′ and the ground instance ϕσ is produced. If
this is not the case, then I is a model of P′ and the input problem is satisﬁable.
This methods works for every fragment that has the ﬁnite model property.
For Example 1, model-based quantiﬁer instantiation fails to generate the right
instances in one round for the same reason that trigger-based and enumerative
instantiation fail: it might instantiate Assertion 2 with c for y, but other rounds
of instantiations will still be required to reach a contradiction.
3
Quantiﬁer Simpliﬁcation by Uniﬁcation
The essence of our technique is to simplify boxes by replacing a quantiﬁed sub-
formula of the box with the Boolean constant ⊤or ⊥. This can be done if the
matrix of this quantiﬁed subformula can be uniﬁed with the matrix of a unit-box.
Example 3. On our running Example 1, the ﬁrst assertion serves as unit-box,
whose matrix is uniﬁable with the matrix of the box in the second assertion. As
a result, the quantiﬁed subformula can be reduced to the Boolean constant ⊤,
for some instance of the second formula.
∀x. P(x) →P(f(x, c))
∀y. ((∀z. P(z) →P(f(z, y))) →¬P(y))
⊤→¬P(c)
The rewriter simpliﬁes the formula ⊤→¬P(c) to ¬P(c). Notice that, in this
example, the variable z must be Skolemized because its quantiﬁer is strong.
The SUB rule (Sect. 3.1) formalizes this derivation. An SMT solver can
use this rule to augment the problem with simpliﬁed formulas. It is care-
fully restricted to generate formulas which help the instantiation procedures
(Sect. 3.2). In Sect. 3.3 we propose several variants of the rule with diﬀerent
tradeoﬀs.
3.1
The Core Rule
The simpliﬁcation by uniﬁcation of subformulas (SUB) rule simpliﬁes a box by
replacing a quantiﬁed subformula with a Boolean constant. To be able to do so,
the rule uniﬁes the matrix of the subformula with a unit-box using a substitution.
The Boolean constant depends on the polarities of the matrices: if they have the
same polarity the subformula is replaced by ⊤, if they have diﬀerent polarity it
is replaced by ⊥. The conclusion of the rule is the pre-simpliﬁed formula and
will be fully simpliﬁed by the rewriter.
Deﬁnition 1 (SUB Rule).
∀x1, . . . , xn. ψ1
∀xn+1, . . . , xm. ϕ[Q¯y. ψ2]
SUB
∀xk1, . . . , xkj. ϕ[b]σ
where Q ∈{∃, ∀}, the subformula Q¯y. ψ2 appears only below the outermost uni-
versal quantiﬁer of ϕ, and σ is a substitution. The rule is subject to the condi-
tions:

Quantiﬁer Simpliﬁcation by Uniﬁcation in SMT
239
1. trim(ψ1)σ = trim(ψ2)σ, if Q¯y. ψ2 is weak;
2. trim(ψ1)σ = trim(sk(Q¯y. ψ2, xn+1 . . . xm))σ, if Q¯y. ψ2 is strong;
3. The bound variables of the conclusion {xk1, . . . , xkj} are exactly free(ϕ[b]σ);
4. b = ⊤if pol(ψ1) = pol(ψ2) or b = ⊥if pol(ψ1) ̸= pol(ψ2).
Example 4. In the running example the subformula ∀z. P(z) →P(f(z, y))
occurs negatively. Since Q = ∀, the formula must be Skolemized (Condition
2):
sk(∀z. P(z) →P(f(z, y)), y) = P(s1(y)) →P(f(s1(y), y))
Hence, the uniﬁer used in Example 3 is σ = [s1(c)/x][c/y].
Example 5. Ignoring Skolemization (Condition 2) leads to unsoundness:
∀x. P(x, x)
∀y. ¬(∀z. P(y, G(z)))
¬⊤
The result of Skolemization sk(∀z. P(y, G(z)), y)) = P(y, G(s1(y))) is not uniﬁ-
able with P(x, x). The rule is not applicable.
Example 6. The conclusion can contain variables from both premises. Here the
uniﬁer is σ = [G(x)/y1][c/z].
∀x. P(G(x), c)
∀y1, y2. (∀z. P(y1, z)) ∧P(y1, y2)
SUB
∀x, y2. ⊤∧P(G(x), y2)
Example 7. The above examples were cases where pol(ψ1) = pol(ψ2). This
example illustrates the other case:
∀x. ¬P(x, x)
∀y. G(c) ∧(∀z. P(y, z))
SUB
G(c) ∧⊥
In this case, the rewriter will simplify the pre-simpliﬁed formula G(c) ∧⊥to ⊥
and the SMT solver can directly deduce unsatisﬁability.
The SUB rule allows us to simply combine and restrict Skolemization, uni-
ﬁcation, and the replacement of subformulas with the appropriate constant. In
the next section we will see the role it has within an SMT solver. The rule
soundly combines these sound steps. First, it Skolemizes the variables ¯y. Second,
it applies the uniﬁer σ. Now the subformula of ψ1 corresponding to Q¯y. ψ2 in the
SUB rule is equivalent to trim(ψ1)σ and is replaced with a Boolean constant.
The constant is chosen appropriately according to the polarity of the formu-
las. This replacement is sound since ψ1σ always holds. Overall, the SUB rule,
together with applying the rewriter, somewhat resembles unit resolution where
∀x1, . . . , xn. ψ1 is the unit clause. In the case of SMT solvers, however, ϕ might
not be a clause. Furthermore, ψ1 and ψ2 will have the complex structure that
is preserved from the input, since most currently used instantiation techniques
have no advantage from applying full clausiﬁcation.

240
P. Fontaine and H.-J. Schurr
3.2
The Simpliﬁcation Within the SMT Solver
Since the SUB rule eliminates a quantiﬁed subformula, the conclusion is easier
to handle for the SMT solvers. In general, however, the conclusion does not
subsume the box serving as the second premise. Hence, this box cannot simply
be replaced by the conclusion. Instead, the problem must be augmented with
the derived box. As the evaluations show, augmenting the problem still helps
the SMT instantiation procedures to ﬁnd the appropriate ground instances.
I ←∅
Q is an empty queue.
for each clause C in P′ do
4
if C is unit-box with the box ℓthen I ←I ∪{ℓ}
5
if C contains a box then push(Q, C)
while Q is not empty do
ℓ1 ∨· · · ∨ℓn ←pop(Q)
8
if there is ψ ∈I and a box ℓi such that
ψ
ℓi
SUB
ℓ′
then
9
ℓ′ ←rewrite(ℓ′)
10
C′ ←ℓ1 ∨· · · ∨ℓi−1 ∨ℓ′ ∨ℓi+1 ∨· · · ∨ℓn
11
append C′ to P′
if C′ contains a box and is not an unit-box then
13
push(Q, C′)
Fig. 2. The augmentation procedure.
The pseudocode in Fig. 2 shows the loop which augments the problem. It is
executed after preprocessing ﬁnishes and before the ground solver starts. The
procedure ﬁrst iterates over the clauses in the preprocessed problem P′ to build a
set I of unit-boxes (Line 4) which can be used to simplify quantiﬁed subformulas.
At the same time, this loop collects in a queue Q all clauses containing boxes
(Line 5). Then the procedure takes a clause from the queue and tries to simplify
one of its boxes. To do so, it uses the SUB rule. If this succeeds, the conclusion
is the pre-simpliﬁed formula. The procedure then uses the rewriter to ﬁnish
the simpliﬁcation and the problem is augmented with the simpliﬁed formula by
adding it conjunctively to the problem (Lines 8 to 11). If the simpliﬁed clause
still contains a box, it is pushed back onto the queue (Line 13).
The procedure terminates since the queue Q will eventually be empty. Every
iteration removes a clause from the queue and adds at most one new clause.
When the test in line 8 fails, i.e., the SUB rule can not be applied, no new clause
is added. Otherwise, it adds a clause with fewer nested formulas that can serve
as Q¯y.ψ2 in the SUB rule. Hence, the SUB rule will eventually no longer apply
to any box left in the clauses in Q.
The approach of augmenting the problem with derived, but new, formu-
las bears the risk that the instantiation procedures create more useless ground
instances from the new formulas. To minimize this risk, the SUB rule is restricted

Quantiﬁer Simpliﬁcation by Uniﬁcation in SMT
241
to only apply when the result is likely to be helpful. First, the detection of sub-
formulas which can be eliminated only uses uniﬁcation instead of a more general
approach. Since preprocessing preserves the structure of quantiﬁed formulas,
uniﬁability can indicate the intention of the user. For example, the unit-box
might be a lemma that is used within the box that is simpliﬁed. Second, the ﬁrst
premise must be a box. In principle it could also be a ground literal, but ground
literals are already directly usable by the ground solver. Third, the simpliﬁed
subformula must start with a quantiﬁer because the instantiation procedures
struggle to instantiate the quantiﬁed subformula. One of the variants described
in the next section drops this restriction, but it is not as useful as the restricted
rule.
3.3
Variants
As the experimental evaluation (Sect. 5) shows, the above version of quantiﬁer
simpliﬁcation by uniﬁcation solves more instances at little cost. Nevertheless, we
also developed several variants with diﬀerent tradeoﬀs. We will call quantiﬁer
simpliﬁcation by uniﬁcation as presented so far the normal variant and will often
drop the phrase by uniﬁcation to avoid repetition.
Eager Simpliﬁcation. Since quantiﬁed subformulas block the instantiation pro-
cedures from creating the right instances quickly, the SUB rule is restricted to
only simplify quantiﬁed subformulas. This restriction, however, can be removed
to generate more simpliﬁed formulas. The eager SUB rule is the rule
∀x1, . . . , xn. ψ1
∀xn+1, . . . , xm. ϕ[ψ2] eager-SUB
∀xk1, . . . , xkj. ϕ[b]σ
and all side conditions of SUB are changed to read ψ2 in-place of Q¯x. ψ2.
The eager SUB rule can be applied on any subformula not below an extra
quantiﬁer. On the one hand, this corresponds to deriving general consequences
of unit-boxes in full ﬁrst-order logic, but on the other hand, it will generate many
more new formulas which potentially slow down or misguide the solver.
Solitary Variable Heuristic. To limit the potential downsides of eager simpliﬁ-
cation, we can limit the cases when the rule is applied: we apply the rule when
it potentially removes a variable from the outermost quantiﬁer of the second
premise. The resulting formula will produce fewer misleading instances.
A variable is removed from the pre-simpliﬁed formula if it is solitary: it
appears in the subformula ψ2, but not in any other subformula of ϕ. Hence, for
example, in the case ϕ = t1 ∨· · · ∨ti ∨· · · ∨tn we apply the rule with ψ2 = ti if
there is a variable x ∈free(ti) such that x ̸∈free(t1 ∨· · · ∨ti−1 ∨ti+1 ∨· · · ∨tn).

242
P. Fontaine and H.-J. Schurr
Deletion of Simpliﬁed Clauses. Another way to restrict the number of newly
created instances is to delete the clause that contains the box used as the second
premise of the SUB rule after it has been simpliﬁed. While this is no longer com-
plete, it can guide the solver towards solving the refutation problem. Especially,
within a strategy schedule this can be a valuable strategy.
This variant can be combined with the three other variants. Overall, this
results in six variants of quantiﬁer simpliﬁcation. The amount of clauses deleted
depends on the activity of the simpliﬁcation variant used. Especially in the case
of eager simpliﬁcation with deletion many input assertions will be deleted.
4
Implementation
Our implementation of quantiﬁer simpliﬁcation by uniﬁcation in veriT uses
a non-perfect discrimination tree as term index and a subsequent uniﬁability
check (Sect. 4.1). Both steps are amended to take strong variables into account
without explicit Skolemization and avoid the creation of unnecessary Skolem
symbols.
The implementation also does not apply the simpliﬁcation of clauses every-
where, but focuses on unit-boxes only: the queue Q will only be populated by
unit-boxes. This simpliﬁes the implementation, since we do not have to track
which boxes of a clause have already been simpliﬁed. It indeed appears that in
SMT-LIB benchmarks clauses with boxes are uncommon and quantiﬁed formulas
are usually unit-boxes (e.g., quantiﬁers range over entire disjunctions). A pro-
totype without this simpliﬁcation did not perform better on these benchmarks
than the simpliﬁed version.
4.1
Indexing and Uniﬁcation Without Skolemization
A key element to execute quantiﬁer simpliﬁcation, as shown in the algorithm
in Fig. 2, is the lookup of the unit-box ∀¯x. ψ1 from the index I. The trimmed
matrix of this box must be uniﬁable with the trimmed matrix of the quantiﬁed
subformula Q¯y. ψ2. To implement the search for uniﬁable formulas eﬃciently
we use a term index. We use non-perfect discrimination trees [21]. Non-perfect
means that the lookup is an over-approximation: some returned terms are not
uniﬁable with the query term and must be removed by a full uniﬁcation step.
For each unit-box ∀¯x. ψ1 (of I in the algorithm in Fig. 2) the index stores
trim(ψ1) together with pol(ψ1). For each possible subformula Q¯y. ψ2 the imple-
mentation uses trim(ψ2) as a query term and retrieves uniﬁcation candidates
and their polarity. Afterwards, it performs a full uniﬁcation to construct the
substitution σ when possible. If, however, the quantiﬁer of Q¯y. ψ2 is strong, the
subformula should be Skolemized.
To handle variables that would be replaced by Skolem terms, the lookup
process is enhanced: while normal variables are replaced by a variable placeholder
that can match any term, variables to be Skolemized act like constants and
can not match any other term. This embeds Skolemization into indexing, since

Quantiﬁer Simpliﬁcation by Uniﬁcation in SMT
243
Skolem terms start with fresh function symbols that can never match indexed
terms.
After the index returns a ﬁltered set of possible premises trim(ψ1) with their
polarities pol(ψ1) from I, the implementation must use full uniﬁcation [19] to
eliminate false positives and to build the uniﬁer σ. It has to solve the uniﬁcation
problem between trim(ψ1) and trim(ψ2), where trim(ψ2) can contain variables
that must be Skolemized.
To handle Skolemized variables during uniﬁcation, our implementation devi-
ates from the standard version in two ways. First, similarly to the term index,
it handles Skolemized variables as constants. Second, it considers a Skolemized
variable as an occurrence of all the variables its Skolem term would depend on.
The resulting uniﬁer σ cannot substitute a Skolem term into the quantiﬁed
variables xn+1, . . . , xm of the box that is simpliﬁed. Hence, the conclusion ϕ[b]σ is
free of any Skolem terms, and no Skolem term has ever to be constructed. Overall,
restricting quantiﬁer simpliﬁcation by uniﬁcation to not simplify formulas below
multiple nested quantiﬁers allows for this elegant implementation.
5
Evaluation
This section presents an empirical evaluation of quantiﬁer simpliﬁcation by uniﬁ-
cation and its variants as implemented in veriT.1 The default variant of quantiﬁer
simpliﬁcation solves more benchmarks than the default conﬁguration of veriT,
while losing few benchmarks. This justiﬁes the activation of our quantiﬁer sim-
pliﬁcation method in the default conﬁguration. Almost all other variants also
solve more benchmarks than the default conﬁguration. veriT exposes a wide
range of options to ﬁne-tune the instantiation module. A speciﬁc conﬁguration
is a strategy. Quantiﬁer simpliﬁcation solves benchmarks not solved by any veriT
strategy without this technique (Sect. 5.1).
In order to fully beneﬁt from the strategies available, veriT can use strategy
schedules. We generated strategy schedules with and without quantiﬁer simpli-
ﬁcation and evaluated their performance. The strategies with quantiﬁer sim-
pliﬁcation are an integral component of the generated schedules and increase
the number of solved benchmarks. They are especially useful for short timeouts
(Sect. 5.2).
We performed the experiments on the benchmarks from the SMT-LIB bench-
mark release 2021 [5]. Since quantiﬁer simpliﬁcation is only relevant for ﬁrst-
order formulas, we used the SMT-LIB logics supported by veriT which use
quantiﬁers, uninterpreted functions, or arrays. Those are the SMT-LIB log-
ics UF, UFLRA, UFLIA, UFIDL, ALIA, AUFLIA, and AUFLIRA. Since veriT is
purely refutational, we removed benchmarks known to be satisﬁable from the
analysis.2 Overall, the SMT-LIB contains 41 129 benchmarks using these logics.
1 The raw data is available on Zenodo [1].
2 Benchmarks known to be satisﬁable can identify soundness problems. Hence, we
included them in the experiments, but removed them from the data.

244
P. Fontaine and H.-J. Schurr
Table 1. Comparison with the default strategy and the theoretical best solver on 39 923
benchmarks.
vs. Default (solves 31 690)
N
E
S
Nd
Ed
Sd
Total
Solved
31 927 31 772 31 928 31 733
21 405
21 823 32 151
+237
+82 +238
+43 −10 285 −9 867
+461
Gained
282
315
285
291
115
255
475
Lost
45
233
47
248
10 400
10 122
14
vs. Theoretical Best (solves 32 633)
Gained
83
80
85
86
32
76
125
Of those, 1206 benchmarks are known to be satisﬁable. This leaves 39 923 rele-
vant benchmarks. We used the 2021.06-rmx release of veriT.
To interpret the numbers, the reader should keep in mind that veriT has no
array solver. It treats the functions of the SMT-LIB theory of arrays as uninter-
preted functions. Since veriT is restricted to refute benchmarks, this approach is
sound. Nevertheless, veriT can fail to solve easy benchmarks that require array
reasoning.
All experiments have been performed on computers with one Intel Xeon Gold
5220 processors with 18 cores and 96 GiB RAM. We ran one instance of veriT
per available core and used a memory limit of 6 GiB per instance.
5.1
Baseline Comparison
Table 1 shows the number of benchmark solved within a timeout of 180 s in com-
parison to the default strategy. The standard version of quantiﬁer simpliﬁcation
by uniﬁcation is denoted N, eager simpliﬁcation is denoted E, and the solitary
variable heuristic is denoted S. A suﬃx d denotes the deletion of simpliﬁed
clauses. Benchmarks are “Gained” if they are not solved by the default strategy
and “Lost” if they are solved by the default strategy, but not by the variant.
The column “Total” reports the union of the benchmarks solved by all variants.
The normal variant shows a good improvement by solving 237 benchmarks
more. Most other variants solve more benchmarks not solved by the default
strategy, but also lose many more. While the normal variant does not have the
highest gain, the small loss justiﬁes enabling it in the default strategy of veriT.
The huge number of lost benchmarks for the variants that use clause deletion
with either eager simpliﬁcation or the solitary variable heuristic is not surprising:
since most input assertions can be simpliﬁed in some way, clause deletion removes
much of the original problem. The result is often an unsolvable problem.
Compared to the union of benchmarks solved by any existing veriT strategy
(Theoretical Best), quantiﬁer simpliﬁcation by uniﬁcation shows good improve-
ment. We used a list of 43 strategies which are also used by veriT in the SMT
competition.3 The default conﬁguration of veriT is on this list. Overall, the
3 Competition website: https://smt-comp.github.io/.

Quantiﬁer Simpliﬁcation by Uniﬁcation in SMT
245
0
24
60
90
120 150 180
2 800
2 900
3 000
3 100
3 200
3 300
3 400
CPU Time
Solved Benchmarks
Only UF
180 s with simp.
24 s with simp.
CVC4
180 s
24 s
Vampire
0
24
60
90
120 150 180
31 000
31 500
32 000
32 500
33 000
CPU Time
All Logics
Fig. 3. CDF of diﬀerent schedules on UF only and all logics.
variants together are able to solve 125 benchmarks that veriT could not solve
before. While eager simpliﬁcation solves only 80 more, 18 of those are not solved
by any other quantiﬁer simpliﬁcation variant. Here, the two variants with clause
deletion that have a huge loss are somewhat redeemed: together they solve eight
benchmarks not solved by the theoretical best solver and the other quantiﬁer
simpliﬁcation variants.
To perform the quantiﬁer simpliﬁcation, veriT does not need much time: for
the normal variant, we measured a median runtime of 0.5 ms and mean of 3 ms.
5.2
Strategy Scheduling
Since quantiﬁer instantiation relies on heuristics, veriT exposes parameters that
can be set by the user in a strategy. Most benchmarks are solved by an appro-
priate strategy within a short timeout. Hence, it is sensible to execute many
strategies for short time intervals one after another in a schedule.
To evaluate the quantiﬁer simpliﬁcation technique within a strategy sched-
ule, we generated schedules with and without strategies extended with quantiﬁer
simpliﬁcation. An optimal schedule is the set of strategy–timeout pairs which
solves the most benchmarks. The list of possible strategies and timeouts is hand-
crafted. We use integer programming to solve this optimization problem. veriT
itself uses the logic of the problem to select a schedule.

246
P. Fontaine and H.-J. Schurr
To build strategies with quantiﬁer simpliﬁcation we picked six strategies from
the strategy list of 43 strategies: the default strategy, the strategy that solved the
most benchmarks overall, and four complementary strategies. The four comple-
mentary strategies were selected by ﬁnding a pair of strategies that together with
the best strategy maximize the number of solved benchmarks. We searched such
a pair on all logics and on ﬁrst-order logic with equality (UF) alone. We then
extended these six strategies with the six variants of quantiﬁer simpliﬁcation.
This resulted in 36 new strategies.
We generated schedules optimized for timeouts of 180 s and 24 s. The short
24 s timeout allows us to evaluate the value of quantiﬁer simpliﬁcation for appli-
cations such as interactive theorem provers, which require a short timeout. It
corresponds to the timeout used by the SMT competition to evaluate solvers for
this purpose. The longer 180 s timeout was arbitrarily chosen.
Figure 3 shows the number of benchmarks solved within a time limit on UF
alone and on all logics. On all logics, the schedule with quantiﬁer simpliﬁcation
solved 193 benchmarks more after 24 s than the original 24 s schedule. For the
180 s timeout, the 180 s schedule with quantiﬁer simpliﬁcation solves 191 more
than the one without. The 24 s schedule with quantiﬁer simpliﬁcation solves 18
benchmarks more than the 180 s schedule after 180 s. Hence, quantiﬁer simpliﬁ-
cation is very useful for short timeouts. Since the form of quantiﬁed lemmas that
quantiﬁer simpliﬁcation by uniﬁcation eliminates appear in problems generated
by interactive theorem provers, it is especially useful for this application.
To provide context the plots contain the results of two other systems: the
state-of-the-art SMT solver CVC4 and the superposition prover Vampire [13].
We used the oﬃcial builds of version 1.8 of CVC4 and version 4.5.1 of Vam-
pire. Vampire includes the SMT solver Z3, which aids theory reasoning. Since
CVC4 has no scheduler optimized for 24 s or 180 s, we ran the default strategy.4
For Vampire we used the SMT-COMP scheduler with a timeout of 180 s.5 We
discarded all “satisﬁable” results. Overall, CVC4 solves 70 benchmarks more
than veriT with quantiﬁer simpliﬁcation after 24 s and 26 after 180 s. veriT with
quantiﬁer simpliﬁcation after 180 s solves 595 benchmarks not solved by CVC4,
of which 107 are also not solved by veriT without quantiﬁer simpliﬁcation. Sur-
prisingly, Vampire solves fewer benchmarks than any other system on UF. This is
due to the nature of typical SMT benchmarks: they usually require little quanti-
ﬁer reasoning and are hence easier to solve for instantiation-based systems.6 This
conﬁrms that restricted methods, such as quantiﬁer simpliﬁcation by uniﬁcation,
are useful for SMT problems.
Figure 4 visualizes the schedules for the logic UF. Grey cells are strategies
that use quantiﬁer simpliﬁcation. Cells with the same number use the same base
strategy. Some base strategies appear both in the schedules with and without
4 Using: -L smt2.6 --no-incremental --no-type-checking --no-interactive
--full-saturate-quant.
5 Using: -t 180s -m 6000 --mode portfolio --schedule smtcomp --input syntax smtlib2
-om smtcomp -p oﬀ.
6 This has been conﬁrmed to us by the Vampire team in conversations.

Quantiﬁer Simpliﬁcation by Uniﬁcation in SMT
247
1
2
4
6
7
8
9
10
1
4
E
16
E Sd
Nd Sd
20
21 E
10
22
23
4
2
11
7
12
13
14
1
14
E
8
17 Nd
18 E
18 Sd
Nd
1
11
E
19 N
0
24
0
180
Fig. 4. Visualization of optimized UF schedules. The bottom rows are the schedules
with quantiﬁer simpliﬁcation. The numbers denote the base strategies.
quantiﬁer simpliﬁcation. The strategies with quantiﬁer simpliﬁcation tend to be
used for shorter time slices than the variants without.
6
Conclusion
We presented a new uniﬁcation-based simpliﬁcation technique for instantiation-
based SMT solvers. Its design is motivated by limitations of modern instantiation
methods, and it is eﬃcient. Problems where formulas can be simpliﬁed are often
solved much faster, despite the method creating new quantiﬁed formulas. We
plan to enable quantiﬁer simpliﬁcation by uniﬁcation by default in the next veriT
release. The release will also produce machine-checkable proofs for simpliﬁcations
performed by quantiﬁer simpliﬁcation by uniﬁcation.
We believe that the technique implemented here within veriT can be ported
easily into any instantiation-based SMT solver, and we are conﬁdent that it
would also enable mainstream solvers to tackle problems outside of reach with
other current strategies. We will investigate its potential in other solvers.
Our method is a step towards using techniques inspired by resolution-based
theorem provers within SMT solvers. It is currently only used as a preprocessing
technique, but we plan to investigate novel quantiﬁer instantiation techniques
which can directly handle nested strong quantiﬁers.
Acknowledgments. We are grateful to Haniel Barbosa, Jasmin Blanchette, Antoine
Defourn´e, Daniel El Ouraoui, Mathias Fleury, Martin Riener, and Ath´ena¨ıs Vaginay
for many fruitful discussions and suggestions to improve the text. We thank the anony-
mous reviewers for many good suggestions to improve the text. The second author
has received funding from the European Research Council (ERC) under the European
Union’s Horizon 2020 research and innovation program (grant agreement No. 713999,
Matryoshka). Experiments presented in this paper were carried out using the Grid’5000
testbed, supported by a scientiﬁc interest group hosted by Inria and including CNRS,
RENATER and several Universities as well as other organizations (see https://www.
grid5000.fr).
References
1. Quantiﬁer Simpliﬁcation by Uniﬁcation in SMT. Zenodo, July 2021. https://doi.
org/10.5281/zenodo.5088868

248
P. Fontaine and H.-J. Schurr
2. Baaz, M., Egly, U., Leitsch, A., Goubault-Larrecq, J., Plaisted, D.: Chapter 5 -
normal form transformations. In: Robinson, A., Voronkov, A. (eds.) Handbook of
Automated Reasoning, pp. 273–333. North-Holland, Amsterdam (2001). https://
doi.org/10.1016/B978-044450813-3/50007-2
3. Barbosa, H., Fontaine, P., Reynolds, A.: Congruence closure with free variables.
In: Legay, A., Margaria, T. (eds.) TACAS 2017. LNCS, vol. 10206, pp. 214–230.
Springer, Heidelberg (2017). https://doi.org/10.1007/978-3-662-54580-5 13
4. Barrett, C., et al.: CVC4. In: Gopalakrishnan, G., Qadeer, S. (eds.) CAV 2011.
LNCS, vol. 6806, pp. 171–177. Springer, Heidelberg (2011). https://doi.org/10.
1007/978-3-642-22110-1 14
5. Barrett, C., Fontaine, P., Tinelli, C.: The SMT-LIB Standard: Version 2.6. Tech-
nical report, Department of Computer Science, The University of Iowa (2017).
www.SMT-LIB.org
6. Barrett, C., Tinelli, C.: Satisﬁability modulo theories. In: Handbook of Model
Checking, pp. 305–343. Springer, Cham (2018). https://doi.org/10.1007/978-3-319-
10575-8 11
7. Bonacina, M.P., Lynch, C., de Moura, L.: On deciding satisﬁability by theorem
proving with speculative inferences. J. Autom. Reason. 47, 161–189 (2011). https://
doi.org/10.1007/s10817-010-9213-y
8. Bouton, T., Caminha B. de Oliveira, D., D´eharbe, D., Fontaine, P.: veriT: an open,
trustable and eﬃcient SMT-solver. In: Schmidt, R.A. (ed.) CADE 2009. LNCS
(LNAI), vol. 5663, pp. 151–156. Springer, Heidelberg (2009). https://doi.org/10.
1007/978-3-642-02959-2 12
9. Detlefs, D., Nelson, G., Saxe, J.B.: Simplify: a theorem prover for program checking.
J. ACM 52(3), 365–473 (2005). https://doi.org/10.1145/1066100.1066102
10. Ekici, B., et al.: SMTCoq: a plug-in for integrating SMT solvers into Coq. In:
Majumdar, R., Kunˇcak, V. (eds.) CAV 2017. LNCS, vol. 10427, pp. 126–133.
Springer, Cham (2017). https://doi.org/10.1007/978-3-319-63390-9 7
11. Ge, Y., Barrett, C., Tinelli, C.: Solving quantiﬁed veriﬁcation conditions using
satisﬁability modulo theories. In: Pfenning, F. (ed.) CADE 2007. LNCS (LNAI),
vol. 4603, pp. 167–182. Springer, Heidelberg (2007). https://doi.org/10.1007/978-
3-540-73595-3 12
12. Ge, Y., de Moura, L.: Complete instantiation for quantiﬁed formulas in satisﬁ-
abiliby modulo theories. In: Bouajjani, A., Maler, O. (eds.) CAV 2009. LNCS,
vol. 5643, pp. 306–320. Springer, Heidelberg (2009). https://doi.org/10.1007/978-
3-642-02658-4 25
13. Kov´acs, L., Voronkov, A.: First-order theorem proving and Vampire. In: Sharygina,
N., Veith, H. (eds.) CAV 2013. LNCS, vol. 8044, pp. 1–35. Springer, Heidelberg
(2013). https://doi.org/10.1007/978-3-642-39799-8 1
14. de Moura, L., Bjørner, N.: Eﬃcient E-matching for SMT solvers. In: Pfenning,
F. (ed.) CADE 2007. LNCS (LNAI), vol. 4603, pp. 183–198. Springer, Heidelberg
(2007). https://doi.org/10.1007/978-3-540-73595-3 13
15. de Moura, L., Bjørner, N.: Engineering DPLL(T) + saturation. In: Armando, A.,
Baumgartner, P., Dowek, G. (eds.) IJCAR 2008. LNCS (LNAI), vol. 5195, pp. 475–
490. Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-540-71070-7 40
16. de Moura, L., Bjørner, N.: Z3: an eﬃcient SMT solver. In: Ramakrishnan, C.R.,
Rehof, J. (eds.) TACAS 2008. LNCS, vol. 4963, pp. 337–340. Springer, Heidelberg
(2008). https://doi.org/10.1007/978-3-540-78800-3 24
17. Reynolds, A., Barbosa, H., Fontaine, P.: Revisiting enumerative instantiation. In:
Beyer, D., Huisman, M. (eds.) TACAS 2018. LNCS, vol. 10806, pp. 112–131.
Springer, Cham (2018). https://doi.org/10.1007/978-3-319-89963-3 7

Quantiﬁer Simpliﬁcation by Uniﬁcation in SMT
249
18. Reynolds, A., Tinelli, C., de Moura, L.: Finding conﬂicting instances of quantiﬁed
formulas in SMT. In: FMCAD 2014, pp. 195–202. IEEE (2014). https://doi.org/
10.1109/FMCAD.2014.6987613
19. Robinson, J.A.: A machine-oriented logic based on the resolution principle. J. ACM
12(1), 23–41 (1965). https://doi.org/10.1145/321250.321253
20. Schurr, H.-J., Fleury, M., Desharnais, M.: Reliable reconstruction of ﬁne-grained
proofs in a proof assistant. In: Platzer, A., Sutcliﬀe, G. (eds.) CADE 2021. LNCS
(LNAI), vol. 12699, pp. 450–467. Springer, Cham (2021). https://doi.org/10.1007/
978-3-030-79876-5 26
21. Sekar, R., Ramakrishnan, I.V., Voronkov, A.: Term Indexing, pp. 1853–1964. Else-
vier Science Publishers B. V., Amsterdam (2001). https://doi.org/10.5555/778522.
778535
22. Voronkov, A.: AVATAR: the architecture for ﬁrst-order theorem provers. In: Biere,
A., Bloem, R. (eds.) CAV 2014. LNCS, vol. 8559, pp. 696–710. Springer, Cham
(2014). https://doi.org/10.1007/978-3-319-08867-9 46

Veriﬁcation

Algorithmic Problems in the Symbolic
Approach to the Veriﬁcation of
Automatically Synthesized Cryptosystems
Hai Lin1
, Christopher Lynch1
, Andrew M. Marshall2(B)
,
Catherine A. Meadows3, Paliath Narendran4, Veena Ravishankar2(B)
,
and Brandon Rozek2
1 Clarkson University, Potsdam, NY, USA
2 University of Mary Washington, Fredericksburg, VA, USA
{amarsha2,vravisha}@umw.edu
3 Naval Research Laboratory, Washington, DC, USA
4 University at Albany–SUNY, Albany, NY, USA
Abstract. Automated methods can be used to generate cryptosystems
by combining the primitives in an arbitrary fashion, to weed out insecure
cryptosystems, and to prove the security of those that survive. In this
paper, we study several algorithmic problems arising from the veriﬁca-
tion of automatically synthesized cryptosystems built from block ciphers,
in a theory that includes ACUN. One of these is static equivalence to
an algorithm that produces a sequence of random terms. The other is
invertibility, the problem of determining whether, given an automatically
synthesized cryptosystem, built from block ciphers, and the ability to
compute inverses, is it always possible to compute the original plaintext
from the ciphertext? We show that static equivalence to random in this
theory is undecidable in general. In addition, we identify a reasonable
special case for which there is a decidable condition implying security,
along with an algorithm for verifying it. For invertibility, we identify a
reasonable class of cryptosystems for which invertibility is equivalent to
a simple syntactic condition that can be easily veriﬁed.
Keywords: Cryptographic modes of operation · Symbolic reasoning ·
Equational theories · Uniﬁcation
1
Introduction
In this paper we address symbolic analysis problems that arise from the auto-
matic generation and veriﬁcation of cryptosystems. In this approach one starts
with a class of cryptosystems that use a ﬁxed set of functions to combine a ﬁxed
set of primitives. Automated methods can be used to generate cryptosystems by
This work was funded by ONR Code 311. The work of Lin, Lynch, Marshall, Narendran,
Ravishankar, and Rozek, was funded via NRL grant number N00173-19-1-G012.
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 253–270, 2021.
https://doi.org/10.1007/978-3-030-86205-3_14

254
H. Lin et al.
combining the primitives in an arbitrary fashion, to weeding out insecure cryp-
tosystems, and proving the security of those that survive. Symbolic techniques
have proved particularly helpful in this process, because they give a compact
representation of cryptosystems that is amenable to automated analysis.
In this paper we apply a technique we are developing for the synthesis and
analysis of cryptographic modes of operation. Basic encryption algorithms such
as AES are generally block ciphers that map λ-bit blocks to λ-bit blocks. A
mode of operation combines multiple computations of block cipher encryption to
encrypt longer messages securely. We model this block cipher approach by deﬁn-
ing a protocol modeling the interaction between an adversary and an encryptor.
In this model the adversary sends plaintext blocks, which the encryptor then
processes according to some pre-determined method, e.g., the method of a par-
ticular cipher. When there are multiple actions that the encryptor can take, the
choice is made by the adversary. The encrypted blocks are then sent back to
the adversary based on some schedule, e.g. as soon as possible, or only after all
the plaintext has been received. It is shown in [6,12], that both the processing
method and the schedule are relevant to the security of the cryptosystem.
We consider two symbolic properties. The ﬁrst is static equivalence [2],
between a protocol in which a plaintext-adaptive adversary interacts with a real
encryptor, and one in which it interacts with a random encryptor that sends ran-
domly generated blocks. A plaintext-adaptive adversary is one that uses cipher-
text it has received previously from an encryptor to construct new plaintext.
Static equivalence between two symbolically deﬁned protocols, roughly speak-
ing, requires that, for any trace of one protocol, there is a trace of the other
protocol such that any adversarial-computable equation satisﬁed by the ﬁrst
trace is satisﬁed by the other, and vice versa. Static equivalence to random may
be thought of as the symbolic analog of IND$-CPA security [12], which requires
that the cipher text received by the adversary be indistinguishable from a string
of random bits.
The second symbolic property, invertibility, requires that a principal able to
compute f (the block encryption function) and its inverse be able to retrieve
plaintext from ciphertext.
Given one of the above symbolic properties, we can divide the questions we
ask about it into two classes. In the ﬁrst case, given a description of a class of
ciphertexts, one can ask whether or not any member has that property. In the
second, given a cryptosystem, one can ask whether all ciphertexts produced by
that cryptosystem have that property. In this paper we focus on the second,
more general, property.
Both questions about static equivalence to random are known to be undecid-
able for arbitrary convergent term rewriting systems [1,3]. In [8] Lin and Lynch
present an algorithm that can be used to answer the ﬁrst type of question for the
class of cryptosystems discussed in this paper. In this paper we devote ourselves
to the second type of question: given a mode, whether or not every possible
sequence of ciphertext produced by it satisﬁes static equivalence to random. In
Sect. 5.1 we show that this problem is undecidable for cryptographic modes of

Algorithmic Problems in the Symbolic Approach to the Veriﬁcation
255
operation in general. Then, in Sect. 5.2 we give a class of cryptosystems for which
there is a decidable property implying static equivalence to random, and we give
an algorithm for deciding that property.
The rest of the paper is organized as follows. Section 2 provides the necessary
background material. Section 3 deﬁnes MOO⊕-programs, which we use for sym-
bolic speciﬁcation of modes of encryption using the ⊕(xor) function. In Sect. 4
we identify a simple syntactically checkable condition for a class of recursively
deﬁned modes of encryption, which we show is equivalent to every ciphertext
produced by the mode being invertible. Section 5 considers the decision prob-
lems described above. Finally, Sect. 6 concludes the paper and describes some
open problems.
1.1
Implementation
We are currently developing a new tool designed to manipulate and analyze
Cryptographic Modes of Operation. The goal of this new tool is broad, to develop
not only a usable analysis tool for a broad family of cryptographic algorithms but
to also develop the underlying libraries which could be used in further analysis
or in other symbolic analysis tools (https://symcollab.github.io/CryptoSolve/).
As part of that tool, several of the algorithms developed in this paper have been
implemented. More details of each implementation are given below as appropri-
ate.
2
Preliminaries
2.1
Terms and Substitutions
Given a ﬁrst-order signature Σ, a countable set of variables N bound by ν, and a
countable set of variables X (s.t. X ∩N = ∅), the set of terms constructed in the
normal recursive manner from X, N, and Σ, is denoted by T(Σ, N ∪X). The set
of free variables in a term t is denoted by fv(t) and the set of bound variables in t
is denoted by fn(t). A term t is ground if fv(t) = ∅. In this paper, we follow the
convention of the applied pi calculus [2] and use variables bound by ν to stand
for randomly chosen bitstrings. For any position p in a term t (including the
root position ϵ), t(p) denotes the symbol at position p, t|p denotes the subterm
of t at position p, and t[u]p denotes the term t in which t|p is replaced by u.
The size of a term t is denoted by |t| and deﬁned in the usual [2] way as follows:
|f(t1, . . . , tn)| = 1 + n
i=1 |ti| if f is a n-ary function symbol with n ≥1, |c| = 1
if c ∈N, and |x| = 0 if x ∈X.
A substitution σ is an endomorphism of T(Σ, N ∪X) mapping free variables
to terms, with only ﬁnitely many variables not mapped to themselves, denoted
by σ = {x1 →t1, . . . , xm →tm}. Application of a substitution σ to a term
t is written tσ. Given two substitutions θ and σ, the composition σ ◦θ is the
substitution denoted here by θσ and deﬁned such that x(θσ) = (xθ)σ for any
x ∈X. The domain of σ is Dom(σ) = {x ∈X | xσ ̸= x}. The range of σ

256
H. Lin et al.
is Ran(σ) = {xσ | x ∈Dom(σ)}. When θ and σ are two substitutions with
disjoint domains and only ground terms in their ranges, then θσ = θ ∪σ. Given
a substitution σ and a ﬁnite set of free variables V ⊆X, the restriction of σ to
V is the substitution denoted by σ|V such that xσ|V = xσ for any x ∈V and
xσ|V = x for any x ∈X\V .
2.2
Equational Theories
Given a set E of Σ-axioms (i.e., pairs of Σ-terms, denoted by l = r), the equa-
tional theory =E is the congruence closure of E under the law of substitutivity.
For any Σ-term t, the equivalence class of t with respect to =E is denoted by [t]E.
Since Σ ∩N = ∅, the Σ-equalities in E do not contain any bound variables in N.
A theory E is trivial if x =E y, for two distinct variables x and y. In this paper,
all the considered theories are assumed non-trivial.
The Xor Equational Theory. In this paper we will primarily be concerned
with the equational theory of Xor, E⊕. This theory can be represented as a
combination of a rewrite system, R⊕, and an associative and commutative equa-
tional theory, AC. E⊕= R⊕∪AC: R⊕= {x⊕x →0, x⊕0 →x}, AC = AC(⊕),
over the signature, Σ⊕= {⊕, f, 0}. We will often use MOO⊕-term to denote a
term over Σ⊕.
A rewrite rule ℓ→r is applied to a term t by ﬁnding a subterm s of t and a
match σ of l and s, i.e., a uniﬁer of l and s that leaves s unchanged, and then
replacing s with rσ. We say that a term is in normal form if no rewrite rule can
be applied. We note that any term in the E⊕theory is reducible via a ﬁnite set
of rewrite rules to a normal form term that is unique up to AC equivalence. If S
is ﬁnite and S ⊂TE⊕(Σ⊕, N ∪X), and t ∈TE⊕(Σ⊕, N ∪X) we say that S ⊕t
if t can be derived by ⊕summing elements of S. In the remainder of this paper,
we assume that all E⊕terms mentioned are in normal form, unless explicitly
noted otherwise.
3
Modes of Operation
Most symmetric key ciphers are block ciphers that encrypt only ﬁxed-length
plaintext. In order to encrypt plaintexts longer than that ﬁxed length, the
encryptor divides it into a sequence of ﬁxed-length blocks and then encrypts it
using a cryptographic mode of operation. This is a sequence of recursively deﬁned
functions on plaintext blocks of ﬁxed length so that each function returns a block
of cipher text. To give an example, we demonstrate cipher block chaining (CBC)
in Fig. 1, where the block C0 returned by the encryptor is a random initializa-
tion vector iv, and block Ci = EK(mi ⊕Ci−1) for i > 0, where EK is the block
encryption method with key K.
We will be using part of the symbolic framework developed for the applied
π-calculus [2]. In this calculus, messages exchanged in a protocol are deﬁned
over a term algebra TE(Σ, N ∪X), where X is a set of free variables, and N

Algorithmic Problems in the Symbolic Approach to the Veriﬁcation
257
m1
Ek
C1
m2
Ek
C2
m3
Ek
C3
m4
Ek
C4
m5
Ek
C5
iv
M
C
Fig. 1. An example of a cryptographic mode of operation: cipher block chaining
is a set of variables bound by the quantiﬁer ν, standing for randomly chosen
bitstrings. Protocols are deﬁned using processes that describe communication
between principals. A sequence of messages produced by a protocol is described
using frames. A frame is a substitution φ from a set of free variables x1, . . . , xk,
to TE(Σ, N ∪X), i.e., xiφ describes the i’th message sent in the frame. We may
also denote a frame φ as νR.[t1, . . . , tk], where ti = xiφ and R is set of bound
variables in Ran(φ).
Static equivalence in the applied π-calculus is used to describe the case in
which the adversary cannot distinguish between two frames. Since all the adver-
sary can do is combine terms via function symbols and check for equality, static
equivalence is deﬁned in terms of those actions. In our case, we have to generalize
the deﬁnition slightly because, in the applied pi calculus it is assumed that the
adversary can apply any function symbol in Σ, while in our case the adversary
cannot compute f.
Deﬁnition 1. Let Ξ ⊆Σ. We say that two closed frames φ and ψ with range
TE(Σ, N) are Ξ-statically equivalent, if Dom(φ) = Dom(ψ) and, for all terms
M and N in TE(Ξ, N)that share no bound variables, Mφ =E Nφ if and only if
Mψ =E Nψ. We say that two closed processes (that is, two processes that pro-
duce only closed frames) are Ξ-statically equivalent if any closed frame produced
by one is Ξ-statically equivalent to some frame produced by the other.
For example, consider Σ⊕, and Ξ = {⊕, 0}. Then φ = νr1.r2.r3[r1, r2, r3]
is Ξ-statically equivalent to φ = νs1.s2.s3[s1, s2, s2 ⊕s3]. However it is not Ξ-
statically equivalent to φ′ = νs1.s2[s1, s2, s1 ⊕s2], because in ψ′ the third term
is the exclusive-or of the ﬁrst two, but the same does not hold for φ. Similarly, φ
is {⊕, 0}-equivalent to ρ = νu1.u2[u1, u2, f(u1 ⊕u2)], but it is not Σ⊕-statically
equivalent to ρ.
Note that, for the purpose of proving or disproving static equivalence, it is
enough to identify processes with the sets of frames they produce. Thus, for
cryptographic modes of operation that use exclusive-or, we deﬁne a MOO⊕-
process as the set of closed frames that describe all possible interactions between
an adversary and an encryptor in a given mode of operation.

258
H. Lin et al.
In order to prove {⊕, 0}-static equivalence to random, we consider frames in
which each block of plaintext submitted by the adversary is denoted by a fresh
free variable. We call such a frame a symbolic history. A mode is modeled as
a MOO⊕-program, which describes the set of all possible symbolic histories of
interaction between an adversary and an encryptor in the symbolic interaction.
Each such history is a frame whose image lies in TE⊕(Σ⊕, N ∪X) where f
stands for EK (i.e., a block encryption function EK(m) with ﬁxed key K). This
frame gives in order the plaintext and ciphertext blocks exchanged between
the adversary and the encryptor, where the plaintext blocks are represented
by free variables. For example, the following symbolic history describes the use
of the CBC mode of encryption to encrypt a two-block message: νr[r, x1, f(r ⊕
x1), x2, f(x2⊕f(r⊕x1))]. Each xi models a plaintext block sent by the adversary,
and all others are terms sent by the encryptor. We also note that a symbolic
history can represent the interleaving of several sessions between the adversary
and an encryptor, in which a session represents the interaction between the
adversary and the encryptor necessary to encrypt a single message.
The set of symbolic histories that can be produced by a mode does not by
itself give us a complete description of the closed frames that can be produced
by it. For that we need to specify what closed substitutions the adversary can
make. For this, we need the following deﬁnition:
Deﬁnition 2. Let H be a symbolic history, and let x be a free variable sent by
the adversary in H, i.e. H = H1, x, H2 where x does not appear in any term in
H1.
1. We deﬁne KNH,x to be the set of terms in H (including free variables sent by
the adversary) sent before the adversary sent x, i.e. KNH,x = {t | t ∈H1}.
2. We say that x >H t if KNH,x ⊢⊕t.
3. We say that a substitution σ on the free variables of H is computable, if for
each free variable x, xσ = tσ such that t <H x.
The restriction to computable substitutions captures the fact that, since the
adversary cannot predict the output of f on a given input, or the choice of a
random string generated by the encryptor, it can only use such outputs that
it has already seen when constructing its substitutions. Note that we do not
include bound variables the adversary has generated itself. Although these can
be represented in the applied π calculus, they turn out not to be necessary to
proving security (See Lemma 1).
Example 1. Consider the CBC mode of encryption illustrated in Fig. 1. The
initial cipher block is the iv, C0 →r where r is a random nonce, and the
second cipher block is the term C1 →f(x1 ⊕C0). So at this point, the symbolic
history, H, contains just two blocks, C0 and C1, and KHH,x is {r, f(x1 ⊕C0)}.
Continuing, the next block is added to H, C2 →f(x2 ⊕f(x1 ⊕C0)). We are able
to unify C1 and C2 with the computable substitution σ = {x1 →C0, x2 →f(0)}.
Notice that the adversary has seen C0 before x1, thus C0 <H x1 and by using
this mapping can compute f(0) before seeing x2.

Algorithmic Problems in the Symbolic Approach to the Veriﬁcation
259
We now formally deﬁne a property, symbolic security, and show that it is
equivalent to {⊕, 0}-statically equivalent to random. Symbolic security is the
property we will be proving in this paper.
Deﬁnition 3. We say that a mode is symbolically secure if, for any symbolic
history H, and any computable closed substitution σ on the free variables of H,
there is no subset S of the set of ciphertext blocks returned by the encryptor such
that 
t∈S ⊕t =⊕0.
Lemma 1. A mode is symbolically secure if and only if it is {⊕, 0}-statically
equivalent to random.
Proof (Sketch). Consider a mode Mreal. Let φ : y1, . . . yk →TE⊕(Σ,N∪X). be a
symbolic history from Mreal. Let P-Dom(φ) be the set of variables in Dom(φ)
mapped to variables standing for plaintext blocks, and let C-Dom(φ) be the set
of variables in Dom(φ) mapped to terms standing for ciphertext blocks. Let ψ
be such that Dom(ψ) = Dom(φ) and yiψ is a fresh bound variable if yi ∈C-
Dom(φ), and a fresh free variable if yi ∈P-Dom(φ). We deﬁne Mran to be the
mode whose symbolic histories consist of all such ψ. Thus Mran is a mode in
which the encryptor always returns fresh random strings.
We note that, for any computable frame σφ from Mreal there is a computable
frame σψ from Mran constructed as above, and any computable frame from Mran
can be obtained this way. It is clear from the deﬁnitions that if σφ and σψ are
{⊕, 0}-statically equivalent then σφ is symbolically secure. We now show that
for any such σφ and σψ that, if σφ is symbolically secure then σφ and σψ are
{⊕, 0}-statically equivalent. For that, it is enough to show that, if M and N are
the exclusive-or of elements of (Dom(φ), then 1) Mσφ =Σ⊕Nσφ if and only
if 2) Mσψ =Σ⊕Nσψ. We note that 2) is true if and only if each ciphertext
terms appears an even number of times as a summand of Mσψ ⊕Nσψ, and
since by hypothesis, the ciphertext terms returned by Mreal satisfy no nontrivial
⊕equation, the same conditions apply to 1).
We now consider the case in which the adversary may include bound vari-
ables, generated by itself, as summands of the plaintext. In the applied π calculus
this is done by prepending to the frame the sequence of bound variables gener-
ated by the adversary. It is then straightforward to reduce this to the computable
case with no adversary-generated bound variables.
⊓⊔
Given a cryptographic mode of operation, we can deﬁne several instances of
the security problem, based on combination of diﬀerent factors. These include
the schedule (e.g. are ciphertext blocks returned by the encryptor only after all
plaintext blocks are received (messagewise schedule), or as soon as the encryptor
can compute them (blockwise schedule)), and the bounds on session length and
number of sessions. We will use the following modes of operation as examples.
– Cipher Block Chaining (CBC) : The ith plain text is a ground MOO⊕-term
pi. The initial cipher block, the iv, is modeled by a bound variable, r. The ith
block of cipher text, Ci, is modeled by the term f(Ci−1 ⊕pi). This is secure
in the messagewise schedule, but not in the blockwise.

260
H. Lin et al.
– Cipher Feedback (CFB) : The ith plain text is modeled by a ground MOO⊕
term pi. The initial cipher block, the iv, is modeled by a bound variable, r.
The ith cipher block, Ci, is modeled by the term f(Ci−1) ⊕pi. This is secure
under both schedules.
– Similarly, Propagating Cipher Block Chaining (PCBC): C1 = f(p1 ⊕IV ),
Ci = f(pi ⊕pi−1 ⊕Ci−1). This is secure under the messagewise schedule but
not under the blockwise schedule.
4
The Invertibility Problem
A natural requirement of any cryptographic algorithm is that it be invertible;
that is, one can ﬁnd the original plaintext using the ciphertext and decryption
key. While this property would normally be “built-in” to a mode of operation, it
is not guaranteed to exist for all possible modes that can be automatically gener-
ated, even if these modes have other desirable properties such as symbolic secu-
rity. Therefore in the automatically generated setting, we will need methods for
checking if the invertibility property holds for any particular MOO⊕-program.
This leads to two diﬀerent questions.
– The ﬁrst is, given a set S of MOO⊕-terms with subterms designated as plain
text, can we tell if S is invertible? This bounded version of the problem follows
from the Abadi and Cortier’s [1] results on the decidability of deducability in
various equational theories and
– The second is: given a MOO⊕-program, can we tell if an arbitrary cipher
block is invertible? We explore this un-bounded version of the problem in
this section.
Let C = {C0, C1, . . . , Cn} represent the ciphertext blocks, Ci, produced by
the encryptor in the MOO⊕-program. We instantiate the variables represent-
ing plaintext in C to bound variables pi. Let P = {p0, p1, . . . , pn} be the set
representing the plaintext messages during a run of the MOO⊕-program. We
introduce a new symbol, f −1, where f is the symbolic encryption function, i.e.,
f = enc( , K), for some key K, and let f −1 model decryption, f −1 = dec( , K),
s.t. f −1(f(M)) = M. Then E−1 = E⊕∪{f −1(f(x)) = x}.
Lemma 2. Let t be a closed term over f, ⊕, 0 and let c ∈fn(t). Let S be a set
of terms consisting of t and every bound variable in t other than c. Then c can
be deduced from S if and only if c appears exactly once in t.
Proof. We ﬁrst prove the “if” part. If |t| = 1, then t = c. Assume c is deducible
for terms whose size is k or less. When size |t| = k + 1, the term either contains
an ⊕or f at the root, i.e., either t
=
f(t′) for some t′, or t
=
t1 ⊕t2
for some t1, t2 where t1 ⊕t2 cannot be further simpliﬁed. When t = f(t′), we
remove the f symbol by applying f −1. Then |t′| = k, and t′ contains c. By the
induction hypothesis c can be deduced for terms up to size k, i.e., from set S.
When t = t1⊕t2, without loss of generality we can assume that c appears exactly

Algorithmic Problems in the Symbolic Approach to the Veriﬁcation
261
once in t1, thus t2 is known. The size of t1 ≤k and by induction hypothesis c
can be derived from t1. The “only if” part follows from the fact that given a
known term t1 ⊕t2, neither t1 nor t2 can be deduced from it unless one of t1 or
t2 ∈S.
⊓⊔
Deﬁnition 4. Consider recursive deﬁnitions which satisfy the following restric-
tions:
1. The base case, C0, is the initial random nonce and the only nonce, i.e., a
bound variable that is computed by the encryptor.
2. Ci contains the ith plaintext pi, represented by a bound variable.
3. pi appears only once in Ci.
Directly from Lemma 2 and Deﬁnition 4 we obtain the following.
Theorem 1. Cryptosystems deﬁned using Deﬁnition 4 are invertible, i.e., for
all i ≥0, pi can be deduced from {C0, . . . , Ci}.
4.1
Implementation
Invertibility has been implemented via an algorithm based on Theorem 1. The
algorithm is restricted to the set of MOO⊕-programs of Deﬁnition 4. The beneﬁt
of this algorithm is that it doesn’t require the production of actual MOO⊕-terms,
but can be applied directly to the recursive deﬁnition of the cryptosystem.
5
Decision Problems for Symbolic Security
In this section we prove results concerning decidability of symbolic security. For
this we concentrate on modes of operation in which ciphertext blocks are of the
form x⊕G, where x is a free variable, and G contains no free variables. For such
a mode, proving symbolic security reduces to proving that there is no symbolic
history H containing a sequence x1⊕G1, . . . , xk⊕Gk such that k
i=1 ⊕Gi =E⊕0.
It is interesting to note that the problem is undecidable even when Gi contains
no free variables, which means deciding it only requires checking for equality,
not performing uniﬁcation. Indeed, not only is the problem undecidable, but it
is undecidable even when we bound some of the parameters, e.g. the number or
length of sessions. We use an approach similar to that of K¨usters and Truderung
in [7], in which the security of recursive protocols deﬁned in a term algebra that
is a superset of ours is shown to be undecidable.
5.1
Undecidable Decision Problems for Block Ciphers
Due to space we consider just one type of decision problem here, those with
sessions of an arbitrary or unbounded length but for which the number of sessions
is bounded. That is, we do not assume a bound on the length of the interaction
between the adversary and encryptor. However, we do assume a ﬁnite bound on

262
H. Lin et al.
the number of possible interleaved sessions the adversary may create. In fact,
since a single session is suﬃcient to obtain the undecidability results we will just
consider that case.
There are then two sub-cases of these unbounded length but bounded num-
ber of sessions problems. The cases are based on whether the MOO⊕-program
is modeled by a non-deterministic function or a deterministic function. In this
section we examine the non-deterministic case, where a session may have non-
deterministic choice points, and the adversary chooses which path is taken. The
second, deterministic case, and several additional related problems can be proven
in a similar manner.
Deﬁnition 5. Let α be a string a0a1 . . . am and let C be a block.
Then, F(α  C) = f(a0 ⊕f(a1 ⊕. . . f(am ⊕C) . . .)).
We will use the following method for constructing ciphertext blocks. The con-
struction encodes possible solutions to the Post Correspondence Problem (PCP).
Deﬁnition 6. Let PCP = ( α0
β0 ), ( α1
β1 ), . . . , ( αn
βn ). Let L = j0, j1, . . . , jk be a
sequence of integers such that 0 ≤ji ≤n, and let Li = [jk−i, . . . , jk]. (Thus,
L0 = [jk] and Lk = L.) For k ≥i > 0 let Ei,Li = [f(ri ⊕Ci,Li,1) ⊕xi,1, f(ri ⊕
Ci,Li,2) ⊕xi,2], 0 ≤j ≤n,
Ci,Li,1 = F(αji
 Ci−1,Li−1,1), and Ci,Li,2 =
F(βji
 Ci−1,Li−1,2). Where each ri is a fresh bound variable, and C0,L0,1 =
F(αj0
 0), C0,L0,2 = F(βj0
 0).
Essentially, the deﬁnition encodes any sequence of PCP blocks. Each Ei,Li
contains two strings. The ﬁrst string encodes a sequence of α strings, from the
tops of the PCP blocks, and the second string encodes a sequence of β strings,
from the bottoms of the PCP blocks. Thus, any solution to the PCP problem
can be encoded into a sequence of mode of encryption style cipher blocks (see
Example 2).
Based on the non-deterministic system of Deﬁnition 6 we can deﬁne the
following MOO⊕-program, which produces two equal cipherblocks which sum
to zero iﬀthe adversary ﬁnds a solution to the PCP.
Deﬁnition 7. Denote the following MOO⊕-program as PCPNDMOO1.
The program works as follows:
– The adversary non-deterministically picks a possible solution to the PCP,
[L = j0, j1, j2, . . . , jk].
– At the adversary’s ith turn, it sends index jk−i of the solution to the encryp-
tor, as well as two plaintext blocks, xi,1 and xi,2.
– At ith step the encryptor’s ith turn encodes a pair of ciphertext blocks Ei,Li =
[f(ri ⊕Ci,Li,1) ⊕xi,1, f(ri ⊕Ci,Li,2) ⊕xi,2], according to Deﬁnition 6 and
returns the pair to the adversary.
– After receiving each Ei,Li, the adversary sums f(ri ⊕Ci,Li,1) ⊕xi,1 with xi,1
and f(ri ⊕Ci,Li,2) ⊕xi,2 with xi,2 to obtain the blocks f(ri ⊕Ci,Li,1) and
f(ri ⊕Ci,Li,2).

Algorithmic Problems in the Symbolic Approach to the Veriﬁcation
263
– The program stops if f(ri ⊕Ci,Li,1) = f(ri ⊕Ci,Li,2) or the adversary stops
sending input to the encryptor.
Example 2. Consider the following PCP:
tile 1
  
 ba
baa
	
,
tile 2
  
ab
ba
	
,
tile 3
  

aaa
aa

One solution to this problem is [1, 3]. Let’s trace a run of the MOO⊕-program
PCPNDMOO1 where the adversary guesses the solution [1, 3]. In the ﬁrst step
the adversary sends 3 to the encryptor and receives: E0,[3] = [f(r0 ⊕C0,[3]1) ⊕
x0,1, f(r0 ⊕C0,[3],2) ⊕x0,2], C0,[3],1 = F(α3
 0) = (f(a ⊕f(a ⊕f(a ⊕0)))),
C0,[3],2 = F(β3
 0) = f(a ⊕f(a ⊕0)).
At the second step the adversary sends a 1 to the encryptor and receives
the following in return. E1,[1,3] = [f(r1 ⊕C1,[1,3],1) ⊕x1,1, f(r1, C1,[1,3],2) ⊕
x1,2], C1,[1,3],2
=
F(α1
 C0,[3],1)
=
f(b ⊕f(a ⊕C0,[3],1)), C1,[1,3],2
=
F(β1
 C0,[3],2) = f(b ⊕f(a ⊕f(a ⊕C0,[3],2))).
Notice that now after step 2 the adversary has two ciphertext blocks, C1,[1,3],1
and C1,[1,3].2, which are equal and therefore their sum will be equal to zero.
C1,[1,3],1 = f(b ⊕f(a ⊕f(a ⊕f(a ⊕f(a ⊕0))))), C1,[1,3],2 = f(b ⊕f(a ⊕f(a ⊕
f(a ⊕f(a ⊕0))))).
Lemma 3. A given PCP problem has a solution if and only if there is a sequence
L of indices of that problem such that the MOO⊕-program PCPNDMOO1 is
symbolically secure.
Proof (Sketch). Since each block returned by the encryptor is the sum of an
f-rooted term and a free variable, symbolic security is violated if and only if two
of these f-rooted terms are uniﬁed. Assume that two such terms are found to
be equal. Due to the random ri at each step the only blocks that are possibly
equal are blocks from the same step, Ci,Li1 and Ci,Li,2. If these blocks are equal
then there is a solution to the PCP. Conversely, suppose that [i1, i2, . . . , im] is
a solution to the PCP. Notice that during the mth step that the blocks Cm,[],1
and Cm,[],2 will fully encode this solution.
⊓⊔
Directly from Lemma 3 we obtain the following.
Theorem 2. Assume M is an arbitrary non-deterministic MOO⊕-program.
The problem of determining if M, executing with a bounded number of sessions
and unbounded session lengths, is symbolically secure is undecidable.
Several additional undecidability results can be proven using a similar reduc-
tion. These cases include deterministic unbounded session length, both determin-
istic and non-deterministic unbounded number of sessions with bounded session
length.

264
H. Lin et al.
5.2
An Algorithm for Checking Symbolic Security
While the question of symbolic security of modes of operation is undecidable
in general, this section explores a suﬃcient condition for symbolic security, and
gives an algorithm for checking symbolic security of modes of operation.
Let M be any mode of operation. Let H be a symbolic history of M, which
can be an interleaving of multiple sessions, each of which is used to encrypt
a single message of some plaintext blocks. M is deﬁned inductively as Cp,i =
tind, Cp,0 = t0. We call Cp,i a ciphertext variable, and use it to denote the ith
ciphertext block from the pth session. We call xp,i a plaintext variable, and use it
to denote the ith plaintext block from the pth session. If we unfold Cp,i, we get
tind. We assume that tind is a MOO⊕-term of the form f(t1)⊕. . .⊕f(tm)⊕xp,i.
We use top-f-terms(Cp,i) to denote {f(t1), . . . , f(tm)}. Each f(tj) (1 ≤j ≤m)
is called an f-rooted summand of Cp,i. We deﬁne sizef(Cp,i) to be the number
of f-rooted summands of Cp,i.
Let t1 and t2 be two MOO⊕-terms. If t1σ =⊕t2σ, then we say that t1 and
t2 are ⊕-uniﬁable under σ, or {t1
?= t2} is ⊕-uniﬁable under σ. Let Γ be a set
of equations. If each equation in Γ is ⊕-uniﬁable under σ, then we say that Γ is
⊕-uniﬁable under σ.
Example 3. We use MCBC to denote Cipher Feedback Mode, where
Cp,i = f(Cp,i−1) ⊕xp,i, Cp,0 = rp
(1) Here is a possible symbolic history of MCBC:
H = [r1, r2, x1,1, f(r1) ⊕x1,1, x2,1, f(r2) ⊕x2,1, x1,2, f(f(r1) ⊕x1,1) ⊕x1,2].
(2) Here is a computable substitution on H:
σ = {x1,1 →0, x2,1 →f(r1), x1,2 →f(r1) ⊕r2}.
Hσ = [r1, r2, 0, f(r1), f(r1), f(r2) ⊕f(r1), f(r1) ⊕r2, f(f(r1)) ⊕f(r1) ⊕r2].
Note that, in the above example, there are no ciphertext blocks in Hσ such
that they sum to 0. Here is the intuition. Let S be the set of all f-rooted sum-
mands of MOO⊕-terms in H. So S = {f(r1), f(r2), f(f(r1) ⊕x1,1)}. No two
MOO⊕-terms in S are uniﬁable under any computable substitution of H. We
formalize this observation using the following Deﬁnition 8.
Deﬁnition 8. Let M be a mode of operation. Consider any symbolic history H
of M. Let Cp,i and Cq,j be any two ciphertext blocks in H. M satisﬁes the unique-
ness property if for any two distinct MOO⊕-terms t1, t2 ∈top-f-terms(Cp,i) ∪
top-f-terms(Cp,j), there does not exist any computable substitution σ of H s.t.
t1σ =⊕t2σ.
The following lemma states that the uniqueness property implies symbolic
security.
Lemma 4. Let M be any mode of operation. If M satisﬁes the uniqueness prop-
erty, then M is symbolically secure.
Proof. Let M be a mode of operation. Consider any symbolic history H of M
and any computable substitution σ. Let S : Cp1,i1, . . . , Cpm,im be a subsequence

Algorithmic Problems in the Symbolic Approach to the Veriﬁcation
265
of H. By the uniqueness property, m
k=1 ⊕Cpk,ikσ = top-f-terms(Cpm,im)σ ⊕t
for some t.
⊓⊔
Let M be a mode of operation, H be any symbolic history of M. The following
Deﬁnition 9 deﬁnes the notion of a crucial pair of H. Intuitively, a crucial pair
is the earliest uniﬁable pair of f-rooted MOO⊕-terms in H. In order to show
that M satisﬁes the uniqueness property, we show that M does not admit any
symbolic history, where a crucial pair exists.
Γ ∪{f(t)
?= 0}
Γ
Elimf
Γ ∪{Cp,m ⊕Cq,n
?= 0}
Γ
ElimC
where i = j implies m = n.
Γ ∪{Cp,m ⊕f(t)
?= 0}
Γ
Occurs check
where Cp,m is a subterm of t.
Γ ∪{f(t1) ⊕. . . ⊕f(tn)
?= 0}
Γ ∪{tk ⊕t1
?= 0} ∪. . . {tk ⊕tk−1
?= 0} ∪{tk ⊕tk+1
?= 0} ∪. . . ∪{tk ⊕tn
?= 0}
Pickf
where k is chosen nondeterministically between 1 and n.
Γ ∪{Cp,m ⊕f(t1) ⊕. . . ⊕f(tn)
?= 0}
Γ ∪{tu
?= t1} ∪. . . {tu
?= tn}
PickC
where (1) f(tu) is an f-rooted summand of Cp,m. (2) sizef(Cp,m) ≤n. (3) Cp,m ∈C V ar(tm)∪
C V ar(tm ).
Γ ∪{Cp,m ⊕f(t1) ⊕. . . ⊕f(tn)
?= 0}
Γ
Pickfail
where sizef(Cp,m) > n.
Fig. 2. Inference system Ii,j,tm,tm′
Deﬁnition 9. Let M be a mode of operation, H be any symbolic history of M.
(1) Suppose that t1 is an f-rooted summand of Cp,i, t2 is an f-rooted summand
of Cq,j.
– If Cp,i appears no later than Cq,j in H, then t1 ⪯t2.
– If Cp,i appears earlier than Cq,j in H, then t1 ≺t2.
(2) t1 and t2 are a crucial pair of H w.r.t (i, j, σ) if
– There exist some Cp,i and Cq,j in H s.t. t1 is an f-rooted summand of
Cp,i, t2 is an f-rooted summand of Cq,j.
– σ is a computable substitution of H, and t1σ =⊕t2σ.

266
H. Lin et al.
– If t′
1 ≺t1 and t′
2 ⪯t2, or t′
1 ⪯t1 and t′
2 ≺t2, then for any computable
substitution σ of H, t′
1σ ̸=⊕t′
2σ.
In order to show that no crucial pair exists in a symbolic history H, we take
any two ciphertext blocks Cp,i and Cq,j in H. We then consider two diﬀerent
f-rooted summands tm and tm′ of Cp,i and Cq,j. We assume that tm and tm′
are a crucial pair of H, and try to derive a contradiction using the inference rules
in Ii,j,tm,tm′ (Fig. 2), starting from an initial set of equations {tm ⊕tm′
?= 0}.
Note that Ii,j,tm,tm′ is parameterized by i, j, tm and tm′, which are referred to
by ElimC and PickC. We use Ik
i,j,tm,tm′({tm ⊕tm′
?= 0}) to represent the set
of equations that we get after the kth inference step. We use Ii,j,tm,tm′({tm ⊕
tm′
?= 0}) to represent the ﬁnal result. We maintain the following invariant: If
we get a set of equations Γ at any step, and tm and tm′ are uniﬁable under
some computable substitution, then at least one of the equations in Γ must
hold. Intuitively, each equation in Γ represents a possibility that tm and tm′
are uniﬁable under a computable substitution, and Γ represents the set of all
possibilities. Our goal is to derive a contradiction, which is to make Γ empty.
The Elimf rule allows us to remove the possibility that an f-rooted MOO⊕-
term is 0. The ElimC rule allows us to remove the possibility that we somehow
ﬁnd an earlier pair of uniﬁable terms. Uniﬁcation of Cp,m with a MOO⊕-term
strictly containing it is impossible by the Occurs check rule. If the xor of some
f-rooted terms is 0, the Pickf rule nondeterministically picks one of them and
list all the possibilities that it can cancel with some other f-rooted MOO⊕-
term. If the number of f-rooted summands of Cp,m is greater than the number
of f-rooted terms in an equation, the Pickfail rule applies. The PickC rule ﬁrst
unfolds Cp,m, then picks an f-rooted summand of Cp,m and cancels it with some
f-rooted term. Note that the PickC rule rules out the possibility that two f-
rooted summands of Cp,m can cancel with each other. In order to apply the
PickC rule, Cp,m must be a ciphertext variable of either tm or tm′. We need
this condition for termination.
Algorithm 1. Checking Symbolic Security of Modes of Operation
Input: a recursive description of some mode of operation M.
Γ = top-f-terms(Cp,i) ∪top-f-terms(Cq,j)
for each pair of distinct terms tm and tm′ in Γ do
if Ii,j,tm,tm′({tm ⊕tm′
?= 0}) ̸= ∅then
return “unknown”
end if
end for
return “secure”
Deﬁnition 10. Given a MOO⊕-term t, C V ar(t) denotes the set of ciphertext
variables occurring in t. More formally,

Algorithmic Problems in the Symbolic Approach to the Veriﬁcation
267
(1) C V ar(Cp,i) = {Cp,i}, if Cp,i is a ciphertext variable. (2) C V ar(xp,i) =
∅, if xp,i is a plaintext variable. (3) C V ar(f(t)) = C V ar(t). (4) C V ar(t1 ⊕
t2) = C V ar(t1) ∪C V ar(t2).
The following Lemma 5 describes an important invariant of Ii,j,tm,tm′, which
implies the soundness of Algorithm 1.
Lemma 5. Let M be a mode of operation, H be any symbolic history of M.
Suppose that tm and tm′ are a crucial pair of H w.r.t. (i, j, σ). For all k, if
Ik
i,j,tm,tm′({tm ⊕tm′ ?= 0}) = Γ, at least one equation in Γ must be ⊕-uniﬁable
under σ.
Proof (Sketch). We prove this lemma by induction on k. When k = 0, the lemma
holds trivially. Assume that the lemma holds when k = l −1. We want to show
that the lemma also holds when k = l. Consider the lth inference step.
If Elimf, ElimC, Occurs check or Pickfail is used, an impossible case is
removed. For example, if ElimC is used, {Cp,m ⊕Cq,n
?= 0} is impossible, since
it contradicts with the assumption that tm and tm′ are a crucial pair of H w.r.t.
(i, j, σ). If Pickf or PickC is used, we nondeterministically guess an f-rooted
term and list all the possibilities that it can cancel with some other term.
⊓⊔
Theorem 3 (Soundness). For any mode of operation M, if Algorithm 1
returns “secure”, then M is symbolically secure.
Proof. Given a mode of operation M, if Algorithm 1 returns “secure”, then for
each pair of distinct terms tm and tm′ in top-f-terms(Cp,i)∪top-f-terms(Cq,j),
Ii,j,tm,tm′({tm ⊕tm′
?= 0}) = ∅. By Lemma 5, no pair of terms tm and tm′
are a crucial pair of H. This means that the uniqueness property holds for M.
Therefore, by Lemma 4, M is symbolically secure.
⊓⊔
To prove termination of Algorithm 1, we deﬁne the following relations: ≺E
and ⪯E are partial order relations on equations, ≺S is a partial order on sets of
equations.
Deﬁnition 11. Let eq be an equation of the form t1 ⊕. . . ⊕tm
?= 0, where each
ti (1 ≤i ≤m) is either f-rooted or a bound variable. Let eq′ be an equation of
the form t′
1 ⊕. . . ⊕t′
n
?= 0, where each t′
i (1 ≤i ≤n) is either f-rooted or a
bound variable. We say that eq ≺E eq′ if for all 1 ≤i ≤m, there exists j such
that ti is a strict subterm of t′
j. We say that eq ⪯E eq′ if eq ≺E eq′ or eq is the
same as eq′.
Let Γ = {eq1, . . . , eqm}, Γ ′ = {eq′
1, . . . , eq′
n}. We say that Γ ≺S Γ ′ if for all
1 ≤i ≤m, there exists j such that eqi ⪯E eq′
j, and at least one of the following
conditions is true: (1) |Γ| < |Γ ′|. (2) There exists i, j, s.t. eqi ≺E eq′
j.
Let Γ be a set of equations, let t and t′ be two MOO⊕-terms. We deﬁne the
following set. C V art,t′(Γ) is the set of ciphertext variables that must occur in
Γ, and also occur in either t or t′.
C V art,t′(Γ) = {Cu,v | Cu,v ∈C V ar(t) ∪C V ar(t′), Cu,v occurs in Γ}.

268
H. Lin et al.
Theorem 4 (Termination). For any mode of operation M, Algorithm 1
always terminates.
Proof. We show that for each tm and tm′, Ii,j,tm,tm′ always terminates. Consider
some inference step. Suppose that we apply Ii,j,tm,tm′ to Γ and get Γ ′. There
are 2 cases to consider.
Case 1: If PickC is used, |C V artm,tm′(Γ ′)| < |C V artm,tm′(Γ)|.
Case 2: If Elimf, ElimC, Occurs check, Pickf or Pickfail is used,
then |C V artm,tm′(Γ ′)| = |C V artm,tm′(Γ)| and Γ ′ ≺S Γ.
So either |C V artm,tm′(Γ ′)| < |C V artm,tm′(Γ)|, or |C V artm,tm′(Γ ′)| =
|C V art,t′(Γ)| and Γ ′ ≺S Γ. For each tm and tm′, Ii,j,tm,tm′ always terminates.
Therefore, Algorithm 1 always terminates.
⊓⊔
Here is an example of checking symbolic security using Algorithm 1.
Example 4. Let M be Cipher Feedback Mode, where: Cp,i = f(Cp,i−1) ⊕xp,i,
Cp,0 = rp. According to Algorithm 1, Γ = {f(Cp,i−1), f(Cq,j−1)}. Apply the
inference system Ii,j,f(Cp,i−1),f(Cq,j−1) to {f(Cp,i−1) ⊕f(Cq,j−1)
?= 0}.
{f(Cp,i−1) ⊕f(Cq,j−1)
?= 0}
{Cp,i−1 ⊕Cq,j−1
?= 0}
Pickf
{Cp,i−1 ⊕Cq,j−1
?= 0}
∅
ElimC
Algorithm 1 returns “secure”.
5.3
Implementation
The CryptoSolve tool can check for symbolic-security in several ways. The ﬁrst,
and most exhaustive, is via the P-uniﬁcation approach [8]. In this approach,
cipher blocks of the MOO-program under consideration are generated and the
appropriate P-uniﬁcation is used to check security (see [11]). The diﬃculty with
this approach is that it can be time consuming in practice, due to the need
to continually generate, then check new cipher blocks. However, the algorithm
speciﬁed in Sect. 5.2 doesn’t require the explicit generation of cipher blocks, but
only requires us to compare. This approach is not complete but works for many
cases. Thus, we are implementing it as a ﬁrst pass symbolic security check.
6
Conclusions
We have investigated two algorithmic problems arising from the symbolic analy-
sis of cryptographic modes of operation built using block ciphers and exclusive-
or: symbolic security and invertibility. We have given algorithmic results for both.
We also believe that we have learned something from treating the problems sep-
arately from each other. For example, one might ask if the restrictions imposed
by invertibility might narrow the class of cryptosystems to ones for which IND$-
security is decidable. Our results on undecidability of symbolic show that they

Algorithmic Problems in the Symbolic Approach to the Veriﬁcation
269
do not, because our embedding of the Post Correspondence Problem all produce
invertible cryptosystems.
There are many ways these results can be extended. We can, as mentioned in
the introduction, investigate algorithms for deciding combinations of properties.
We can investigate larger classes of modes that use additional primitives and
functions, such as hash functions, ﬁeld operations, concatenation, block ciphers
with tweaks, and the successor function, the latter two of which have already
been studied in [5,9] for the messagewise schedule. In addition, we can investigate
other classes of modes built using the same or similar primitives, e.g. hash func-
tions (studied in [10]), hash-based signatures, garbled circuits (studied in [4]),
and message authentication codes (studied in [5]). We also intend to determine
what other cryptosystems or classes of cryptosystems are amenable to symbolic
analyses and study them if feasible.
References
1. Abadi, M., Cortier, V.: Deciding knowledge in security protocols under equational
theories. Theoret. Comput. Sci. 367(1–2), 2–32 (2006)
2. Abadi, M., Fournet, C.: Mobile values, new names, and secure communication.
In: Proceedings of the 28th ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages, POPL 2001, pp. 104–115. ACM, New York (2001).
https://doi.org/10.1145/360204.360213
3. Borgstr¨om, J.: Static equivalence is harder than knowledge. In: Baeten, J.C.M.,
Phillips, I.C.C. (eds.) Proceedings of the 12th Workshop on Expressiveness on
Concurrency, EXPRESS 2005, San Francisco, CA, USA, 27 August 2005, pp. 45–
57. Electronic Notes in Theoretical Computer Science, Elsevier (2005). https://
doi.org/10.1016/j.entcs.2006.05.006
4. Carmer, B., Rosulek, M.: Linicrypt: a model for practical cryptography. In: Rob-
shaw, M., Katz, J. (eds.) CRYPTO 2016. LNCS, vol. 9816, pp. 416–445. Springer,
Heidelberg (2016). https://doi.org/10.1007/978-3-662-53015-3 15
5. Hoang, V.T., Katz, J., Malozemoﬀ, A.J.: Automated analysis and synthesis of
authenticated encryption schemes. In: Proceedings of the 22nd ACM SIGSAC
Conference on Computer and Communications Security, pp. 84–95. Association
for Computing Machinery, New York (2015). https://doi.org/10.1145/2810103.
2813636
6. Joux, A., Martinet, G., Valette, F.: Blockwise-adaptive attackers revisiting the
(in)security of some provably secure encryption modes: CBC, GEM, IACBC. In:
Yung, M. (ed.) CRYPTO 2002. LNCS, vol. 2442, pp. 17–30. Springer, Heidelberg
(2002). https://doi.org/10.1007/3-540-45708-9 2
7. K¨usters, R., Truderung, T.: On the automatic analysis of recursive security proto-
cols with XOR. In: Thomas, W., Weil, P. (eds.) STACS 2007. LNCS, vol. 4393, pp.
646–657. Springer, Heidelberg (2007). https://doi.org/10.1007/978-3-540-70918-
3 55
8. Lin, H., Lynch, C.: Local XOR uniﬁcation: deﬁnitions, algorithms and application
to cryptography. IACR Cryptol. ePrint Arch. 2020, 929 (2020). https://eprint.iacr.
org/2020/929
9. Malozemoﬀ, A.J., Katz, J., Green, M.D.: Automated analysis and synthesis of
block-cipher modes of operation. In: 2014 IEEE 27th Conference on Computer
Security Foundations Symposium (CSF), pp. 140–152. IEEE (2014)

270
H. Lin et al.
10. McQuoid, I., Swope, T., Rosulek, M.: Characterizing collision and second-preimage
resistance in Linicrypt. In: Hofheinz, D., Rosen, A. (eds.) TCC 2019. LNCS, vol.
11891, pp. 451–470. Springer, Cham (2019). https://doi.org/10.1007/978-3-030-
36030-6 18
11. Meadows, C.A.: Symbolic and computational reasoning about cryptographic modes
of operation. IACR Cryptol. ePrint Arch. 2020, 794 (2020). https://eprint.iacr.org/
2020/794
12. Rogaway, P.: Nonce-based symmetric encryption. In: 11th International Workshop
on Fast Software Encryption, FSE 2004, Delhi, India, 5–7 February 2004, Revised
Papers, pp. 348–359 (2004). https://doi.org/10.1007/978-3-540-25937-4 22

Formal Analysis of Symbolic Authenticity
Hai Lin(B)
and Christopher Lynch
Clarkson University, Potsdam, NY, USA
{hlin,clynch}@clarkson.edu
Abstract. Authenticated encryption schemes are ways of encrypting
messages which simultaneously assure the secrecy and authenticity of
data. Designing authenticated encryption schemes can be error-prone.
In this paper, we consider the authenticity of authenticated encryption
schemes . We introduce the notion of symbolic authenticity, and present
two inference systems for verifying symbolic authenticity. The ﬁrst infer-
ence system works for authenticated encryption schemes for messages
of ﬁxed length. It is sound, complete and terminating. The second one
works for authenticated encryption schemes for messages of arbitrary
length. It is sound, terminating, and complete under some condition.
These inference systems can be used to automatically synthesize authen-
ticated encryption schemes.
Keywords: Uniﬁcation · Authenticated encryption · Formal methods
1
Introduction
Authenticated encryption (AE) schemes (e.g. CCM [4], XCBC [5], OTR [12],
OCB [14], etc.) are ways of encrypting messages which simultaneously assure
the secrecy and authenticity of data. It is a nontrivial task to construct AE
schemes. Automated techniques have been used to verify and synthesize AE
schemes [6]. In this paper, we are interested in the authenticity property. Roughly
speaking, an AE scheme satisﬁes authenticity if an adversary cannot forge any
new valid ciphertext message after observing some valid ciphertext messages.
We consider two versions of AE schemes: a restricted version (ﬁxed-length AE
schemes), which handle messages of a ﬁxed length, and general AE schemes,
which handle messages of arbitrary length.
Motivated by the original work in [11], we propose to reason about authen-
ticity symbolically. For each version of the AE schemes, we deﬁne a notion of
symbolic authenticity in terms of a new uniﬁcation problem, and give an infer-
ence system for checking symbolic authenticity. The idea is that we use func-
tion symbols to model cryptographic operations (e.g. tweakable block cipher,
exclusive-or, etc.), use terms to model message blocks, and use an equational
theory to capture the properties of cryptographic operations and the properties
that valid ciphertext messages must satisfy.
The work is supported by NRL under contract N00173-19-1-G012.
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 271–286, 2021.
https://doi.org/10.1007/978-3-030-86205-3_15

272
H. Lin and C. Lynch
Formal methods have been used to analyze various cryptosystems, including
cryptographic modes of operation, authenticated encryption schemes, signature
schemes, garbled circuits, etc. [1–3,6–8,10]. In the literature, [6] is the closest to
our work. In [6], Hoang et al. consider AE schemes constructed from tweakable
block ciphers [9]. An AE scheme is viewed as a directed acyclic graph, and a type
system is developed. Hoang et al. show that “well-typed” graphs deﬁne secure
AE schemes. However, no completeness result is given. Our inference system
for ﬁx-length AE schemes is sound, terminating and complete. Our inference
system for general AE schemes is sound, terminating and complete under some
condition.
The rest of this paper is organized as follows. In Sect. 2, we introduce the
basics of tweakable block ciphers and authenticated encryption schemes. In
Sect. 3, we consider symbolic authenticity of ﬁxed-length AE schemes. In Sect. 4,
we consider symbolic authenticity of general AE schemes. We conclude and dis-
cuss future work in Sect. 5.
2
Preliminaries
In cryptography, a tweakable block cipher [9] on λ-bit strings with tweak space
T and key space K is a map E: K × T × {0, 1}λ →{0, 1}λ s.t. EK(T, ·) is
a permutation on {0, 1}λ for any K ∈K and T ∈T . Each combination of a
key and a tweak leads to a totally independent permutation. In this paper, we
consider some tweakable block cipher with a ﬁxed key K, which is not known to
the adversary.
An authenticated encryption scheme Π is a tuple (E, D, V) with key space
K, tweak space T and tag space G, where E is an encryption algorithm, D is a
decryption algorithm and V is a veriﬁcation equation, which checks authen-
ticity of ciphertext messages. l denotes the number of message blocks that
Π handles. E maps (K, Tk, M) ∈K × T × {0, 1}λ×l to a ciphertext message
(Tk, C, Tg) ∈T ×{0, 1}λ×l ×G. A ciphertext message (Tk, C, Tg) is valid if and
only if VK(Tk, C, Tg) returns true. D maps (K, Tk, C, Tg) ∈K×T ×{0, 1}∗×G
to either a message M ∈M if (Tk, C, Tg) is valid or an error otherwise. In
this paper, we only consider authenticated encryption schemes constructed from
tweakable block ciphers, and the tag is the output of some tweakable block
cipher.
Security Game. In order to check if an AE scheme satisﬁes authenticity, we
consider a game between an adversary A and an encryption oracle EK(·, ·). The
adversary queries the encryption oracle with plaintext messages, and gets back
valid ciphertext messages. The adversary can choose plaintext messages adap-
tively based on previous queries. They can have as many rounds of interaction
as they want. The adversary wins the game if and only if (s)he can forge a new
ciphertext message (Tk, C, Tg) s.t. VK(Tk, C, Tg) = True. An authenticated
encryption scheme satisﬁes authenticity if and only if the adversary can only
win the game with negligible probability.

Formal Analysis of Symbolic Authenticity
273
We consider a ﬁrst-order signature Σ = {e/2, d/2, n/1, ⊕/2, 0/0}, and e mod-
els encryption using a tweakable block cipher with some ﬁxed key. d models
decryption using the same tweakable block cipher with the same key. In tweak-
able block cipher, each tweak can only be used to process a single block. If tk is
the tweak for processing the ith block of some message, then n(tk) is the tweak
for processing the i+1th block of the same message. We use nk(t) as a shorthand
for applying n to t for k times. 0 represents a block of all 0’s.
In this paper, we consider two versions of AE schemes: ﬁxed-length AE
schemes, which handles messages of ﬁxed length; general AE schemes, which
handles messages of arbitrary length. Figure 1 illustrates the syntax of terms
considered in this paper. T denotes a set of terms, modelling the ﬁxed-length
AE schemes. N represents the set of all constants, X represents the set of all
variables, and Ttk represents the set of all tweaks. A term can be built up from
constants, variables, and tweaks using e, d, ⊕. We say that a term is f-rooted if
it is of the form f(t1, . . . , tu). The ﬁrst argument of an e-rooted term or a d-
rooted term has to be a tweak. We use the convention that variables start with
upper-case letters and constants start with lower-case letters.
T := N | X | e(Ttk, T) | d(Ttk, T) | T ⊕T
N := Ntk | Nc | Ntg | Nmeta
Ntk := tk1 | tk2 | . . . | tki | . . .
Nc := c1,1 | c1,2 | . . . | ci,1 | ci,2 | . . .
Ntg := tg1,1 | tg1,2 | . . . | tgi,1 | tgi,2 | . . .
X := XC | Tk | Tg
XC := C1 | C2 | . . . | Ci | . . .
Ttk := Ntk | Tk | n(Ttk)
T + := N | X | e(Ttk, T +) | d(Ttk, T +) | T + ⊕T + | Y
Y := Y1 | Y2 | . . . | Yj | . . .
Tmeta := Nmeta | e(Tmeta tk, T +) | d(Tmeta tk, T +) | e(Ttk, Tmeta) | d(Ttk, Tmeta) | T ⊕Tmeta
Tmeta tk := tki | n(Tmeta tk)
Nmeta := tgi,1 | tgi,2 | . . . | ci,1 | ci,2 | . . . | ci,j | . . .
Fig. 1. Syntax of terms
There are three types of constants: tweak constants (denoted by Ntk), cipher-
text constants (denoted by Nc) and tag constants (denoted by Ntg). For all
i, j ∈N, tki is a tweak constant, denoting the tweak for processing the ﬁrst block
of the ith message, tgi,j is a tag constant, denoting the tag of the ith ciphertext
message of length j, ci,j is a ciphertext constant, denoting the jth block of the
ith ciphertext message. There are three types of variables: Tk denotes a tweak,
Tg denotes a tag, and Ci denotes the ith block of a message.
In Fig. 1, T + represents a set of terms, modelling the general AE schemes. T +
augments T by some Y1, Y2, . . .. ∀j ∈N, Yj represents some accumulative state
after encrypting the jth block of a message. For example, Yj may be the exclusive-
or of the ﬁrst j ciphertext blocks. In order to model general AE schemes, we

274
H. Lin and C. Lynch
deﬁne Yj inductively in terms of Yk’s (k < j) and Ck’s (k ≤j). If the ith
message has l blocks, then the tag attached to that message is e(nl(tki), Yl).
If a term t contains (at least) a subterm with variable indices, t is called a
meta-term. In Fig. 1, we use Tmeta to represent the set of all meta-terms. Nmeta
represents the set of all meta-constants. Tmeta tk represents the set of meta-
tweak-constants. We can instantiate meta-terms. For example, ci,1 is a meta-term
representing the 1st block of some ith ciphertext message. If we instantiate i by
1, then ci,1 represents the 1st block of the 1st ciphertext message.
A substitution is a map: X →T −Tmeta. We use id to denote the identity
substitution. A meta substitution is a map: X →Tmeta. Throughout the rest of
this paper, ωl
i denotes the following meta-substitution.
ωl
i = {Tk →tki, C1 →ci,1, C2 →ci,2, . . . , Cl →ci,l}
We can instantiate meta-substitutions. Let γ1 and γ2 be two meta-
substitutions. γ1γ2 denotes the composition of γ1 and γ2. For example,
(1) ω2
i = {Tk →tki, C1 →ci,1, C2 →ci,2}
(2) ω2
1 = {Tk →tk1, C1 →c1,1, C2 →c1,2}
(3) ω2
i {C3 →ci,3} = {Tk →tki, C1 →ci,1, C2 →ci,2, C3 →ci,3}
3
Formal Analysis of Symbolic Authenticity of
Fixed-Length AE Schemes
In this section, we consider ﬁx-length AE schemes, which handle messages of
exactly l blocks, where l is a ﬁxed integer. In Sect. 3.1, we show how such schemes
can be modelled symbolically. In Sect. 3.2, we introduce the notion of symbolic
authenticity for such schemes, and deﬁne symbolic authenticity in terms of a
new uniﬁcation problem, which can be solved using the inference rules presented
in Sect. 3.3. We also give an algorithm for checking symbolic authenticity for
ﬁxed-length AE schemes in Sect. 3.3.
Fig. 2. A ﬁxed-length AE scheme Π1

Formal Analysis of Symbolic Authenticity
275
3.1
Modelling Fixed-Length AE Schemes
Any ﬁxed-length AE schemes can be modelled symbolically. We use the following
example to illustrate the idea.
Example 1. Consider the authenticated encryption scheme Π1 in Fig. 2. Π1 =
(E, D, V), where
EK(Tk, (M1, M2)) := (Tk, e(Tk, M1), e(n(Tk), M2), e(n2(Tk), C1 ⊕C2)).
VK(Tk, (C1, C2), Tg) := (e(n2(Tk), C1 ⊕C2) == Tg)
DK(Tk, (C1, C2), Tg) :=

(d(Tk, C1), d(n(Tk), C2))
if VK(Tk, C1, C2, Tg) is True
⊥
otherwise
Suppose that there are some rounds of interaction between an adversary
A and an encryption oracle EK(·, ·). At round i: The adversary A queries
the oracle with (mi,1, mi,2). EK(·, ·) replies with a valid ciphertext message
(tki, ci,1, ci,2, tgi,2).
There are many ways, in which the adversary can choose plaintext messages
adaptively. Here is one possible way, m2,1 is chosen as c1,1, m2,2 is chosen as
c1,1 ⊕c1,2. We have the following set of equations: E⊕, E1 and E2. E⊕captures
the properties of exclusive-or. E1 captures the fact that the ciphertext messages,
which A receives, are valid. E2 captures the fact that the adversary can choose
plaintext messages adaptively.
E⊕= {t ⊕t = 0, t ⊕0 = t} ∪AC(⊕)
E1 = {e(n2(tk1), c1,1 ⊕c1,2) = tg1,2, e(n2(tk2), c2,1 ⊕c2,2) = tg2,2, . . .}
E2 = {d(tk2, c2,1) = c1,1, d(n(tk2), c2,2) = c1,1 ⊕c1,2}
After the above two rounds of interaction, the adversary can output a new
valid ciphertext message: (tk1, c1,1 ⊕c1,2, 0, tg1,2). Therefore, Π1 does not satisfy
authenticity.
3.2
Symbolic Authenticity for Fixed-Length AE Schemes
In this section, we introduce a new uniﬁcation problem over terms in T, and
deﬁne the notion of symbolic authenticity in terms of this new uniﬁcation
problem.
First we deﬁne V El, which is the set of veriﬁcation equations that verify
the validity of messages containing l blocks. The “Consistency” property holds
since in tweakable block cipher, each tweak can only be used to process a unique
message block.
Deﬁnition 1. Let V be an equation over T, V ∈V El if (1) V is of the form
e(nl(Tk), t) = Tg. (lhs(V ) denotes e(nl(Tk), t).) (2) no Ck (k > l) occurs in V .
(3) V satisﬁes the following “Consistency” property.
(Consistency) (I) For all terms e(s, s′) and e(t, t′) that occur in V , if s = t,
then s′ = t′. (II) For all terms d(s, s′) and d(t, t′) that occur in V , if s = t, then
s′ = t′.

276
H. Lin and C. Lynch
We then formalize the notion of an FAE (Fixed-length Authenticated Encryp-
tion) theory w.r.t. some V ∈V El using the following deﬁnition. The idea is that
the adversary can take advantages of the equations in an FAE theory while try-
ing to forge a new valid message. An FAE theory contains two subsets of equa-
tions: The ﬁrst subset captures the fact that the ciphertext messages, which the
adversary receives in the security game, are valid. The second subset captures
the fact that the adversary can choose plaintext messages adaptively. In Example
1, E1 ∪E2 is an example of an FAE theory w.r.t. e(n2(Tk), C1 ⊕C2) == Tg.
Deﬁnition 2. Consider any V ∈V El. A set of equations EV over terms in T
is an FAE theory w.r.t. V if the following properties hold:
1. (Validity) ∀i ∈N, V (ωl
i ∪{Tg →tgi,l}) ∈EV .
2. (TBC PRP) ∀t ∈EV , if lhs(V )σ =⊕tσ, then ∃i s.t. Tkσ = tki.
3. (Consistency) (1) For all e(s, s′) and e(t, t′) that occur in EV , if s = t, then
s′ = t′. (2) For all d(s, s′) and d(t, t′) that occur in EV , if s = t, then s′ = t′.
4. (Stability) No equation in EV is of the form n(t) = t′.
We assume that, in the security game described in Sect. 2, the adversary
receives the following messages.
(tk1, c1,1, . . . , c1,l, tg1,l)
(tk2, c2,1, . . . , c2,l, tg2,l)
. . . . . .
In Deﬁnition 2, the “Validity” property says that all the above messages are
valid. The “Stability” property says that the tweaks are irreducible in EV . We
assume that the tag attached to any ciphertext message is the output of some
tweakable block cipher (TBC), and tweakable block ciphers are pseudorandom
permutations (PRP). The “TBC PRP” property says that if the adversary wants
to generate a valid message, (s)he has to choose one of the tweaks in the messages
that (s)he receives. (Otherwise, the tag is totally random to the adversary, and
(s)he has negligible probability of guessing it correctly.)
The following Deﬁnition 3 deﬁnes a new uniﬁcation problem, called (⊕, EV )-
uniﬁcation, where V ∈V El and EV is an FAE theory w.r.t. V . In Deﬁnition 4,
we then introduce the notion of symbolic authenticity based on this new uniﬁ-
cation problem.
Deﬁnition 3. σ is a computable substitution if it maps Tk to a term in Ttk,
and maps each Ci to the exclusive-or of terms in N ∪X.
Let V be an equation in V El, and EV be an FAE theory w.r.t. V . Consider
two terms t1, t2 ∈T s.t. t1ωl
i = t2. t1 and t2 are (⊕, EV )-uniﬁable under σ if (1)
t1σ =⊕,EV t2, and (2) σ is a computable substitution.
σ is called a (⊕, EV )-meta-uniﬁer of t1 and t2. σ∗is the most general
(⊕, EV )-meta-uniﬁer of t1 and t2 if for any (⊕, EV )-meta-uniﬁer σ of t1 and t2,
there exists some meta-substitution σ′ s.t. σ = σ∗σ′. Let P be a set of equations
over terms in T. σ is called a (⊕, EV )-meta-uniﬁer of P if σ is a (⊕, EV )-meta-
uniﬁer of each equation in P.

Formal Analysis of Symbolic Authenticity
277
To produce a valid message m : (Tk, C, Tg), the adversary needs to compute
some substitution σ s.t. V (Tkσ, Cσ, Tgσ) returns true. Due to the “Validity”
property, the adversary can pick σ to be ωl
i ∪{Tg →tgi,l} (∀i ∈N). But
that does not produce a new message, it is the ith message that the adversary
receives from the encryption oracle. Therefore, the adversary tries to ﬁnd some
other (⊕, EV )-meta-uniﬁer σ′ of lhs(V ) and lhs(V )ωl
i. If the adversary succeeds,
(Tkσ′, Cσ′, tgi,l) (∀i ∈N) is a new valid message. That is the idea behind the
following deﬁnition.
Deﬁnition 4. Let S be a ﬁxed-length AE scheme with veriﬁcation equation V ∈
V El. S is symbolically authentic if ωl
i is the only (⊕, EV )-meta-uniﬁer of lhs(V )
and lhs(V )ωl
i, where EV is any FAE theory w.r.t. V .
If an authenticated encryption scheme is symbolically authentic, there is no
way for the adversary to forge a new valid message symbolically.
3.3
Inference system
In this section, we present a sound, complete and terminating inference system
IB for solving the (⊕, EV )-uniﬁcation problem over terms in T. The diﬃculty
Decompose
{f(s1, . . . , su)
?= f(t1, . . . , tu)} ∪Γ; σ =⇒{s1
?= t1, . . . , su
?= tu} ∪Γ; σ
where f ̸= ⊕, and u can possibly be 0.
Decomposen
{nu(s)
?= nu(t)} ∪Γ; σ =⇒{s
?= t} ∪Γ; σ
ElimC
{Cj1 ⊕. . . ⊕Cju
?= ci,j1 ⊕. . . ⊕ci,ju} ∪Γ; σ =⇒Γσ′; σσ′
where σ′ = {Cj1 →Cj2 ⊕. . . ⊕Cju ⊕ci,j1 ⊕. . . ⊕ci,ju}.
ElimTk
{Tk
?= tki} ∪Γ; σ =⇒Γσ′; σσ′
where σ′ = {Tk →tki}.
Split
{s1 ⊕f(nu(s2), s3)
?= t1 ⊕f(nu(t2), t3)} ∪Γ; σ
=⇒{s1
?= t1, f(nu(s2), s3)
?= f(nu(t2), t3)} ∪Γ; σ
where f is either e or d.
Fig. 3. Inference system IB

278
H. Lin and C. Lynch
for designing such an inference system is that EV has an unbounded number of
equations.
The inference rules of IB are listed in Fig. 3. The Decompose rule is standard
as in [13]. The Decomposen rule is an optimization rule: If we have an equation
of the form nu(s)
?= nu(t), instead of applying the Decompose rule u times, we
can apply the Decomposen rule once. The V ariable Elimination rule in [13]
may not lead to computable substitutions. Instead, we have the ElimC rule and
the ElimT k rule, which always lead to computable substitutions. The Split rule
is the key rule in IB. The following example illustrates the idea behind the Split
rule.
Example 2. Let V be an equation in V E2, and EV be an FAE theory. Consider
the following inference steps:
– {C1⊕e(tk1, C2)
?= c1,1⊕e(tk1, c1,2)}
Split
=⇒{C1
?= c1,1, e(tk1, C2)
?= e(tk1, c1,2)}
The ﬁrst thing to observe is that: {C1 →e(tk1, C2) ⊕c1,1 ⊕e(tk1, c1,2)} is
not a computable substitution. If (C1 ⊕e(tk1, C2))σ =⊕,EV c1,1 ⊕e(tk1, c1,2),
there are two cases to consider:
(1) (e(tk1, C2))σ =⊕e(tk1, c1,2)
(2) (e(tk1, C2))σ =⊕t, where t ∈EV . Due to the “Validity” property,
e(tk1, c1,2) occurs in EV . Due to the “Consistency” property, e(tk1, c1,2) is
the only term in EV s.t. its ﬁrst argument is tk1.
In both cases, e(tk1, C2) =⊕e(tk1, c1,2), which implies that C1 =⊕c1,1.
– {C1 ⊕e(tki, C2)
?= ci,1 ⊕e(tki, ci,2)}
Split
=⇒{C1
?= ci,1, e(tki, C2)
?= e(tki, ci,2)}
The justiﬁcation for the above inference step can be generalized, and applies
to this inference step.
A uniﬁcation state is of the form P; τ, where P is a set of equations and τ is
a meta-substitution. Given t1, t2 ∈T, to check if t1 and t2 are (⊕, EV )-uniﬁable,
we start from the initial state: {t1
?= t2}; id, where id is the identity substitution.
We then apply the inference rules in IB. We use Ir
B({t1
?= t2}; id) to denote the
result after the rth inference step. In particular, we use I0
B({t1
?= t2}; id) to
denote the initial state. IB({t1
?= t2}; id) = τ ∗if and only if there exists q s.t.
Iq
B({t1
?= t2}; id) = ∅; τ ∗.
The inference rules in IB can be applied in a “don’t-care” nondetermin-
istic fashion. Given t1, t2 ∈T, IB(t1
?= t2; id) always returns the most gen-
eral (⊕, EV )-meta-uniﬁer of t1 and t2. Algorithm 1 checks symbolic authenticity
of ﬁxed-length AE schemes. The following theorems state that Algorithm 1 is
sound, complete and terminating.
Theorem 1 (Completeness). Let S be a ﬁxed-length AE scheme. If S is sym-
bolically authentic, then Algorithm 1 returns “authentic”.
Theorem 2 (Soundness). Let S be a ﬁxed-length AE scheme. If Algorithm 1
returns “authentic”, then S is symbolically authentic.

Formal Analysis of Symbolic Authenticity
279
Theorem 3 (Termination). Algorithm 1 always terminates for ﬁxed-length
AE schemes.
Example 3. The veriﬁcation equation of Π1 (Fig. 2) is the following:
e(n2(Tk), C1 ⊕C2) = Tg
According to Algorithm 1, we compute the most general (⊕, EV )-meta-uniﬁer
of e(n2(Tk), C1⊕C2) and e(n2(tki), ci,1⊕ci,2) using the following inference steps:
{e(n2(Tk), C1 ⊕C2)
?= e(n2(tki), ci,1 ⊕ci,2)}; id
=⇒{n2(Tk)
?= n2(tki), C1 ⊕C2
?= ci,1 ⊕ci,2}; id
(Decompose)
=⇒{Tk
?= tki, C1 ⊕C2
?= ci,1 ⊕ci,2}; id
(Decomposen)
=⇒{C1 ⊕C2
?= ci,1 ⊕ci,2}; {Tk →tki}
(ElimT k)
=⇒∅; {C1 →C2 ⊕ci,1 ⊕ci,2, Tk →tki}
(ElimC)
{C1 →C2 ⊕ci,1 ⊕ci,2, Tk →tki} ̸= ω2
i . Therefore, S is not symbolically
authentic. In fact, instantiating i using any natural number leads to a valid
new ciphertext message. For example, (tk1, C2 ⊕c1,1 ⊕c1,2, C2, tg1) is a valid
new ciphertext message, where C2 can be an arbitrary message block, and C1 is
C2 ⊕c1,1 ⊕c1,2.
Algorithm 1. Checking Symbolic Authenticity of Fixed AE Schemes
Input: a ﬁxed-length AE scheme S, whose veriﬁcation function is of the form
e(nl(Tk), t) = Tg.
if IB({e(nl(Tk), t)
?= e(nl(Tk), t)ωl
i}, id) == ωl
i then
return “authentic”
else
return “inauthentic”
end if
4
Formal Analysis of Symbolic Authenticity of General
AE Schemes
In this section, we consider general AE schemes, which handles messages of l
blocks (l is not ﬁxed). In Sect. 4.1, we show how such schemes can be modelled
symbolically. In Sect. 4.2, we introduce the notion of symbolic authenticity for
general AE schemes, in terms of a uniﬁcation problem, which can be solved using
the inference system given in Sect. 4.3. We also give an algorithm for checking
symbolic authenticity for general AE schemes in Sect. 4.3.

280
H. Lin and C. Lynch
4.1
Modelling General AE Schemes
In order to model general AE schemes, we consider the set of terms T + described
in Fig. 1. Any general AE scheme can be modelled symbolically, we use the
following example to illustrate the idea.
Fig. 4. A general AE scheme Π2
Example 4. Consider the general AE scheme in Fig. 4. Π2 = (E, D, V), where
– EK(Tk, (M1, M2, . . . , Ml))
:=
(Tk, e(Tk, M1), e(n(Tk), M2) ⊕M1, . . . , e(nl−1(Tk), Ml) ⊕Ml−1, e(nl(Tk), Ml))
– VK(Tk, (C1, . . . , Cl), Tg) := (e(nl(Tk), Yl) == Tg), where
• Y1 = d(Tk, C1)
• Yj = d(nj−1(Tk), Cj ⊕Yj−1)
(j > 1)
– DK(Tk, (C1, . . . , Cl), Tg)
:=

(M1, . . . , Ml)
if VK(Tk, (C1, . . . , Cl), Tg) == True
⊥
otherwise
As we discussed in Sect. 2, Yj (j ∈N) represents some accumulative state
after encrypting the jth block of a message. In this example, Yj = Mj. But
in general, this may not be the case. We will show that Π2 satisﬁes symbolic
authenticity.
4.2
Symbolic Authenticity for General AE Schemes
In this section, we introduce a uniﬁcation problem over terms in T +, and deﬁne
the notion of symbolic authenticity of general AE schemes in terms of this uni-
ﬁcation problem. Let S be any general AE scheme, we use VR to denote its
veriﬁcation equation. We assume that VR is of the following form.
e(nl(Tk), Yl) = Tg, where Yl is deﬁned by the following set of equations R:
– Y1 = tm1, . . . , Yr = tmr (No Yi occurs in tm1, . . . , tmr.)

Formal Analysis of Symbolic Authenticity
281
– Yj = tmj[Yj−r, . . . , Yj−1] (j > r)
∀j ∈N, Yj is a term that can be unfolded. We can apply a meta-substitution
to a term t ∈T + in the usual way, except that we require the following:
∀j, σ. Yjσ = Y σ
j .
The idea is that we remember that if we unfold Yj later on, we need to apply
σ to the unfolding of Yj.
Consider a term t ∈T +. unfoldR(t) unfolds all the occurrences of Yi’s in t,
based on R. We can unfold an equation by unfolding terms on both sides of the
equation. We can also unfold a set of equations by unfolding all the equations
in the set. We require the following.
∀j, σ. unfoldR(Y σ
j ) = unfoldR(Yj)σ
Example 5. Consider the general AE scheme in Fig. 4. Let σ = {C1 →ci,1, C2 →
ci,2}
(1) Y1 = d(Tk, C1)
(2) Y2 = d(n(Tk), C2 ⊕Y1)
(3) Y2σ = d(n(Tk), ci,2 ⊕Y σ
1 )
(4) unfoldR(Y2σ) = d(n(Tk), ci,2 ⊕d(Tk, ci,1))
Next we deﬁne V E, which is the set of veriﬁcation equations that verify the
validity of messages of arbitrary length, and a GAE theory using the following
deﬁnitions.
Deﬁnition 5. Let VR be an equation of the form e(nl(Tk), Yl) = Tg, where Yl
is deﬁned by the following set of equations R:
– Y1 = tm1, . . . , Yr = tmr (No Yi occurs in tm1, . . . , tmr.)
– Yj = tmj[Yj−r, . . . , Yj−1] (j > r)
VR ∈V E if and only if the following “Consistency” property holds:
(Consistency) (I) ∀l ∈N, if e(s, s′) and e(t, t′) both occur in unfoldR(Yl), and
s = t, then s′ = t′. (II) ∀l ∈N, if d(s, s′) and d(t, t′) both occur in unfoldR(Yl),
and s = t, then s′ = t′.
Deﬁnition 6. Let VR ∈V E. A set of equations EVR over terms in T + is a GAE
(General Authenticated Encryption) theory w.r.t. VR if the following properties
hold:
1. (Validity) ∀i, l ∈N, unfoldR(e(nl(Tk), Yl) = Tg)(ωl
i∪{Tk →tki,l}) ∈EVR.
2. (TBC PRP) ∀l ∈N, t ∈EVR, if unfoldR(e(nl(Tk), Yl))σ =⊕tσ, then
Tkσ = tki.

282
H. Lin and C. Lynch
3. (Consistency) (1) For all e(s, s′) and e(t, t′) that occur in EVR, if s = t,
then s′ = t′. (2) For all d(s, s′) and d(t, t′) that occur in EVR, if s = t, then
s′ = t′.
4. (Stability) No equation in EVR is of the form n(t) = t′.
We assume that, in the security game described in Sect. 2, the adversary
receives the following messages.
(tk1, c1,1, tg1,1), (tk1, c1,1, c1,2, tg1,2), . . . . . .
(tk2, c2,1, tg2,1), (tk2, c2,1, c2,2, tg2,2), . . . . . .
. . . . . .
In Deﬁnition 6, the “Validity” property says that all the above messages are
valid. The “TBC PRP”, “Consistency” and “Stability” properties are similar to
those in Deﬁnition 2, except that equations and terms are now over T +, and we
unfold terms in T +.
Deﬁnition 7. Let VR ∈V E, and EVR be a GAE theory w.r.t. VR. Consider
two terms t1, t2 ∈T + s.t. t1ωl
i = t2. t1 and t2 are (⊕, EVR)-uniﬁable under σ if
(1) t1σ =⊕,EVR t2σ, and (2) σ is a computable substitution.
σ is called a (⊕, EVR)-meta-uniﬁer of t1 and t2. σ∗is the most general
(⊕, EVR)-meta-uniﬁer of t1 and t2 if for any (⊕, EVR)-meta-uniﬁer σ of t1 and t2,
there exists some meta-substitution σ′ s.t. σ = σ∗σ′. Let P be a set of equations
over terms in T +. σ is called a (⊕, EVR)-meta-uniﬁer of P if σ is a (⊕, EVR)-
meta-uniﬁer of each equation in P.
Given some general AE scheme, to produce a valid ciphertext message m :
(Tk, C, Tg), the adversary needs to compute some substitution σ s.t. V (Tkσ, Cσ,
Tgσ) returns true. Due to the “Validity” property, we can pick σ to be ωl
i∪{Tg →
tgi,l}. But that does not give us a new message. Therefore, the adversary tries
to ﬁnd some other (⊕, EV )-meta-uniﬁer σ′ of e(nl(Tk), Yl) and e(nl(Tk), Yl)ωl
i.
If the adversary succeeds, (Tkσ′, Cσ′, tgi,l) is a new valid message. So we have
the following deﬁnition.
Deﬁnition 8. Let S be a general AE scheme with veriﬁcation equation VR ∈
V E. S is symbolically authentic if for all l, ωl
i is the only (⊕, EVR)-meta-uniﬁer
of unfoldR(e(nl(Tk), Yl) and unfoldR(e(nl(Tk), Yl)ωl
i, where EVR is any GAE
theory w.r.t. VR.
If a general AE scheme is symbolically authentic, the adversary cannot forge
any new valid ciphertext message symbolically.
4.3
Inference System
In this section, we present a sound, complete and terminating inference sys-
tem IU for solving the (⊕, EVR)-uniﬁcation problem over T +. The diﬃculty
for designing such an inference system is that EVR has an unbounded number
of equations. In addition, the terms being uniﬁed may contain Yj’s, which we
cannot fully unfold.

Formal Analysis of Symbolic Authenticity
283
The inference rules of IU are listed in Fig. 3. Compared with IB, IU contains
two new rules: the CancelY rule and the SplitY rule. The SplitY rule can be
considered as a generalization of the Split rule. A term is splittable if and only
if it is the exclusive-or of some e-rooted terms and d-rooted terms. Note that a
term t in T + is splittable if and only if unfoldR(t) is splittable. The CancelY
rule cancels Yu and Y
ωj
i
u , assuming that ωu
i is the only (⊕, EV )-meta-uniﬁer of
unfoldR(Yu) and unfoldR(Y
ωj
i
u ). We can have this assumption for the reason
described in the following paragraph.
Decompose
{f(s1, . . . , su)
?= f(t1, . . . , tu)} ∪Γ; σ =⇒{s1
?= t1, . . . , su
?= tu} ∪Γ; σ
where f ̸= ⊕, and u can possibly be 0.
Decomposen
{nu(s)
?= nu(t)} ∪Γ; σ =⇒{s
?= t} ∪Γ; σ
ElimC
{Cj1 ⊕. . . ⊕Cju
?= ci,j1 ⊕. . . ⊕ci,ju} ∪Γ; σ =⇒Γσ; σσ′
where σ′ = Cj1 →Cj2 ⊕. . . ⊕Cju ⊕ci,j1 ⊕. . . ⊕ci,ju
ElimTk
{Tk
?= tki} ∪Γ; σ =⇒Γσ′; σσ′
where σ′ = {Tk →tki}.
CancelY
{Yu
?= Y
ωj
i
u } ∪Γ; σ =⇒Γωu
i ; σωu
i
where j > u.
SplitY
{s ⊕Yr
?= t ⊕Y
ωj
i
r
} ∪Γ; σ =⇒{s
?= t, Yr
?= Y
ωj
i
r
} ∪Γ; σ
where unfoldR(Yr) is splittable.
Split
{s1 ⊕f(nu(s2), s3)
?= t1 ⊕f(nu(t2), t3)} ∪Γ; σ
=⇒{s1
?= t1, f(nu(s2), s3)
?= f(nu(t2), t3)} ∪Γ; σ
, where f can be either e or d.
Fig. 5. Inference system IU

284
H. Lin and C. Lynch
Given some general AE scheme S, our goal is to show that S is symbol-
ically secure. By Deﬁnition 8, we need to show that, for all l, ωl
i is the only
(⊕, EVR)-meta-uniﬁer of unfoldR(e(nl(Tk), Yl) and unfoldR(e(nl(Tk), Yl)ωl
i.
Here is the overall idea. We prove this by induction. As the base case, we
show that, ωk
i
is the only (⊕, EVR)-meta-uniﬁer of unfoldR(e(nk(Tk), Yk)
and unfoldR(e(nk(Tk), Yk)ωk
i
(1
≤
k
≤
r). As the inductive case, we
show that, ωj
i is the only (⊕, EVR)-meta-uniﬁer of unfoldR(e(nj(Tk), Yj) and
unfoldR(e(nj(Tk), Yj)ωj
i (j > r), assuming that for all u < j, ωu
i is the only
(⊕, EVR)-meta-uniﬁer of unfoldR(e(nu(Tk), Yu) and unfoldR(e(nu(Tk), Yu)ωj
i .
This
assumption
implies
that
ωu
i
is
the
only
(⊕, EVR)-meta-uniﬁer
of
unfoldR(Yu) and unfoldR(Y
ωj
i
u ) (u < j).
Recall from Sect. 3.3 that a uniﬁcation state is of the form P; τ, where P
is a set of equations and τ is a meta-substitution. Given two terms t1, t2 ∈
T +, to compute the most general (⊕, EVR)-meta-uniﬁer of unfoldR(t1) and
unfoldR(t2), we start from the initial state: {t1
?= t2}; id, where id is the identity
substitution. We then apply the inference rules in IU. We use Ir
U({t1
?= t2}; id)
to denote the result after the rth inference step. In particular, we use I0
U({t1
?=
t2}; id) to denote the initial uniﬁcation state. IU({t1
?= t2}; id) = τ ∗if and only
if there exists q s.t. Iq
U({t1
?= t2}; id) = ∅; τ ∗.
The inference rules in IU can be applied in a “don’t-care” nondeterministic
fashion, and IU(t1
?= t2; id) returns the most general (⊕, EVR)-meta-uniﬁer of t1
and t2 in T +. Algorithm 2 checks symbolic authenticity of general AE schemes.
Algorithm 2. Checking Symbolic Authenticity of General AE Schemes
Input: a general AE scheme S, whose veriﬁcation function is of the form e(nl(T k), Yl) = T g,
where
Y1 = tm1, . . . , Yr = tmr
Yj = tmj[Yj−r, . . . , Yj−1] (j > r)
cond1 := (IU({e(n(T k), tm1)
?= e(n(T k), tm1)ω1
i }; id) == ω1
i ) and unfoldR(Y1) is splittable
. . . . . .
condr := (IU({e(nr(T k), tmr)
?= e(nr(T k), tmr)ωr
i }; id) == ωr
i ) and unfoldR(Yr) is splittable
cond := (IU({e(nj(T k), tmj)
?= e(nj(T k), tmj)ωj
i }; id) == ωj
i ) and unfoldR(Yj) is splittable
if cond1 and . . . and condr and cond then
return “authentic”
else
return “inauthentic”
end if
The following theorems state that Algorithm 2 is sound, terminating and
complete under some condition.
Theorem 4 (Completeness). Let S be a general AE scheme with a veriﬁca-
tion equation e(nl(Tk), Yl) = Tg, where Yl is deﬁned recursively using a set of
equations R. If ∀l ∈N, unfoldR(Yl) is splittable, and S is symbolically authen-
tic, then Algorithm 2 returns “authentic”.

Formal Analysis of Symbolic Authenticity
285
Theorem 5 (Soundness). Let S be a general AE scheme. If Algorithm 2
returns “authentic”, then S is symbolically authentic.
Theorem 6 (Termination). Let S be a general AE scheme. Algorithm 2
always terminates.
Example 6. Consider the general AE scheme Π2 in Fig. 4. The veriﬁcation equa-
tion of Π2 is e(nl(Tk), Yl) = Tg, where
(1) Y1 = d(Tk, C1) (2) Yj = d(nj−1(Tk), Cj ⊕Yj−1) (j > 1).
1. The most general (⊕, EVR)-meta-uniﬁer of d(Tk, C1) and d(tki, ci,1) is ω1
i ,
according to the following inference steps:
{d(Tk, C1)
?= d(tki, ci,1)}; id
=⇒{Tk
?= tki, C1
?= ci,1}; id
=⇒{C1
?= ci,1}; {Tk →tki}
=⇒∅; {Tk →tki, C1 →ci,1}
2. The most general (⊕, EVR)-meta-uniﬁer of e(nj(Tk), d(nj−1(Tk), Cj ⊕
Yj−1)) and e(nj(tki), d(nj−1(tki), ci,j ⊕Y
ωj
i
j−1)) is ωj
i , according to the following
inference steps:
{e(nj(Tk), d(nj−1(Tk), Cj ⊕Yj−1))
?= e(nj(tki), d(nj−1(tki), ci,j ⊕Y
ωj
i
j−1))}; id
=⇒{nj(Tk)
?= nj(tki), d(nj−1(Tk), Cj ⊕Yj−1)
?= d(nj−1(tki), ci,j ⊕Y
ωj
i
j−1)}; id
=⇒{Tk
?= tki, d(nj−1(Tk), Cj ⊕Yj−1)
?= d(nj−1(tki), ci,j ⊕Y
ωj
i
j−1)}; id
=⇒{d(nj−1(tki), Cj ⊕Yj−1)
?= d(nj−1(tki), ci,j ⊕Y
ωj
i
j−1)}; {Tk →tki}
=⇒{nj−1(tki)
?= nj−1(tki), Cj ⊕Yj−1
?= ci,j ⊕Y
ωj
i
j−1}; {Tk →tki}
=⇒{tki
?= tki, Cj ⊕Yj−1
?= ci,j ⊕Y
ωj
i
j−1}; {Tk →tki}
=⇒{Cj ⊕Yj−1
?= ci,j ⊕Y
ωj
i
j−1}; {Tk →tki}
=⇒{Cj
?= ci,j, Yj−1
?= Y
ωj
i
j−1}; {Tk →tki}
=⇒{Yj−1
?= Y
ωj
i
j−1}; {Tk →tki, Cj →ci,j}
=⇒∅; {Tk →tki, C1 →ci,1, . . . , Cj−1 →ci,j−1, Cj →ci,j}
Both Y1 and Yj are splittable. Therefore, Algorithm 2 returns “authentic”.
5
Conclusions and Future Work
In this paper, we propose to model AE schemes symbolically. For ﬁxed-length
AE schemes, we give a decision procedure for checking symbolic authenticity.

286
H. Lin and C. Lynch
For general AE schemes, we give an inference system for checking symbolic
authenticity, which is sound, terminating and complete under some condition.
As future work, we will connect the symbolic world and the computational
world by showing that all AE schemes satisfy symbolic authenticity if and only
if they satisfy authenticity computationally. We will also consider the secrecy
property of AE schemes. Our goal is to develop methods that can synthesize
secure AE schemes automatically based on uniﬁcation techniques.
References
1. Akinyele, J.A., Green, M., Hohenberger, S.: Using SMT solvers to automate design
tasks for encryption and signature schemes. In: Sadeghi, A.-R., Gligor, V.D., Yung,
M. (eds.) 2013 ACM SIGSAC Conference on Computer and Communications Secu-
rity (CCS 2013), Berlin, Germany, November 4–8 2013, pp. 399–410. ACM (2013)
2. Ambrona, M., Barthe, G., Schmidt, B.: Automated unbounded analysis of cryp-
tographic constructions in the generic group model. In: Fischlin, M., Coron, J.-S.
(eds.) EUROCRYPT 2016. LNCS, vol. 9666, pp. 822–851. Springer, Heidelberg
(2016). https://doi.org/10.1007/978-3-662-49896-5 29
3. Carmer, B., Rosulek, M.: Linicrypt: A model for practical cryptography. In: 36th
Annual International Cryptology Conference, pp. 416–445 (2016)
4. Dworkin, M.: Recommendations for block cipher modes of operation: The CCM
mode for authentication and conﬁdentiality (2007)
5. Gligor, V.D., Donescu, P.: Fast encryption and authentication: XCBC encryption
and XECB authentication modes. In: Matsui, M. (ed.) FSE 2001. LNCS, vol. 2355,
pp. 92–108. Springer, Heidelberg (2002). https://doi.org/10.1007/3-540-45473-X 8
6. Hoang, V.T., Katz, J., Malozemof, A.J.: Automated analysis and synthesis of
authenticated encryption schemes. In: Proceedings of the 22nd ACM SIGSAC Con-
ference on Computer and Communications Security, pp. 84–95 (2015)
7. Li, B., Micciancio, D.: Equational security proofs of oblivious transfer protocols. In:
Abdalla, M., Dahab, R. (eds.) PKC 2018. LNCS, vol. 10769, pp. 527–553. Springer,
Cham (2018). https://doi.org/10.1007/978-3-319-76578-5 18
8. Li, B., Micciancio, D.: Symbolic security of garbled circuits. In: 31st IEEE Com-
puter Security Foundations Symposium (CSF 2018), Oxford, UK, July 9–12, 2018,
pp. 147–161. IEEE Computer Society (2018)
9. Liskov, M., Rivest, R.L., Wagner, D.: Tweakable block ciphers. Adv. Cryptol.-
Crypto 2002, 31–46 (2002)
10. Malozemoﬀ, A.J., Katz, J., Green, M.D.: Automated analysis and synthesis of
block-cipher modes of operation. In: Computer Security Foundations Symposium
(CSF), pp. 140–152 (2014)
11. Meadows, C.: Symbolic security criteria for blockwise adaptive secure modes of
encryption. IACR Cryptol. ePrint Arch. 2020, 794 (2020)
12. Minematsu, K.: Parallelizable rate-1 authenticated encryption from pseudorandom
functions. In: Nguyen, P.Q., Oswald, E. (eds.) EUROCRYPT 2014. LNCS, vol.
8441, pp. 275–292. Springer, Heidelberg (2014). https://doi.org/10.1007/978-3-
642-55220-5 16
13. Robinson, A., Voronkov. A.: Handbook of Automated Reasoning (2001)
14. Rogaway, P., Bellare, M., Black, J., Krovetz, T.: OCB: a block-cipher mode of oper-
ation for eﬃcient authenticated encryption. In: 8th ACM Conference on Computer
and Communications Security (CCS), pp. 196–205 (2001)

Formal Veriﬁcation of a Java Component
Using the RESOLVE Framework
Laine Rumreich(B) and Paolo A. G. Sivilotti
The Ohio State University, Columbus, OH, USA
rumreich.1@osu.edu, paolo@cse.ohio-state.edu
Abstract. A Binary Decision Diagram (BDD) is an eﬃcient represen-
tation of a Boolean formula with many applications in model checking,
SAT solving, networking, and artiﬁcial intelligence. This paper uses the
RESOLVE speciﬁcation and reasoning framework to formally verify the
functional correctness of a Java implementation of a BDD component.
RESOLVE uses rich mathematical abstractions and clean value-based
semantics for modular reasoning of assertive code. Java, on the other
hand, includes many language features that are inconsistent with this
notion of clean semantics and modular reasoning. Aliases, in particular,
are easily created via assignment, parameter passing, and iterators, so
reference-based semantics and points-to analysis are usually necessary
when reasoning about Java code. This paper demonstrates the combi-
nation of these two paradigms. The implementation uses Java, but in a
disciplined way and layered on a component catalog expressly designed
to support modular reasoning. The assertional aspects of the code use
RESOLVE, but are tailored to Java syntax and language constructs.
In the development of the correctness proof for the BDD component,
several errors in the original Java implementation were discovered and
corrected. These errors were present despite the implementation passing
an extensive test suite, exhibiting the value of the proof. The veriﬁcation
also exposed a limitation in the more general component design pattern
related to unreachable code.
Keywords: Formal veriﬁcation · Value semantics · Modularity ·
Binary Decision Diagram
1
Introduction
In order to be tractable, software veriﬁcation must be modular. That is, the
correctness of the entire system must follow from the correctness of its individual
components. Modularity allows for components to be veriﬁed in isolation and for
the cost of this veriﬁcation to be amortized over the re-use of these components
across multiple systems.
The work presented in this paper uses the RESOLVE (REusable SOftware
Language with Veriﬁability and Eﬃciency) framework [34], which is both an
integrated implementation and veriﬁcation system as well as a design discipline
c
⃝Springer Nature Switzerland AG 2021
B. Konev and G. Reger (Eds.): FroCoS 2021, LNAI 12941, pp. 287–305, 2021.
https://doi.org/10.1007/978-3-030-86205-3_16

288
L. Rumreich and P. A. G. Sivilotti
aimed to promote component re-use by easing client-side reasoning. The imple-
mentation notation uses assertional code with value semantics and the asso-
ciated veriﬁcation system uses extendable mathematical theories with custom
decision procedures for automated veriﬁcation. The discipline prescribes prin-
ciples for interface design, the tenets of which reduce overall software cost and
improve quality [40]. While the RESOLVE discipline is typically applied to soft-
ware components written in the RESOLVE language, elements of the discipline
could, in principle, also be adapted for use with industry-standard program-
ming languages such as Java. This combination of Java and RESOLVE would
leverage the strengths of both: the robust full-functional veriﬁcation possible in
RESOLVE and the practicality of an industry-standard programming language
such as Java. This paper considers the feasibility of such a combination.
The primary contribution of this work concerns the careful construction of a
proof that formally establishes the correctness of a Java-based Binary Deci-
sion Diagram component, the implementation of which is layered on top of
a RESOLVE-style component library with RESOLVE speciﬁcations. Because
industry-standard languages such as Java and C were not designed with ver-
iﬁcation in mind, they include many features that challenge the soundness of
modular reasoning, including: aliasing-by-default, reference semantics, ubiqui-
tous side-eﬀects, and concurrency. Because of these challenges, the veriﬁcation
of software written in these languages is often restricted to subsets of proper-
ties of interest (e.g., race detection) or limited in generality (e.g., reasoning over
memory locations rather than abstract mathematical values).
In contrast, the veriﬁcation eﬀort described in this paper entails both full-
functional correctness and value-based reasoning. As a result of this veriﬁcation,
several errors were identiﬁed in the original BDD component implementation.
In addition, we present several observations related to the success of adapting
RESOLVE for application in the context of the Java programming language.
2
Background
2.1
Previous Work
While the RESOLVE discipline is typically applied to programs written in
the RESOLVE programming language, there exists a substantial library of
RESOLVE-style components written in the Java programming language. None of
these components have been formally veriﬁed, however, despite their adherence
to the discipline. This paper describes the veriﬁcation of one of these components,
BooleanStructure, which implements a Binary Decision Diagram (BDD). BDDs
are frequently used and versatile data structures that represent Boolean formu-
las. BDDs have unique features that make them preferable to other common rep-
resentations of Boolean formulas such as truth tables and propositional formulas.
These features improve the eﬃciency of BDDs and make them more useful than
other common representations for solving complex problems with many vari-
ables. In 2018, Asim [2,3] developed a Binary Decision Diagram software com-
ponent in the Java programming language. Unlike existing BDD components,

Formal Veriﬁcation of a Java Component Using the RESOLVE Framework
289
this BDD was developed with veriﬁcation in mind, including behavioral spec-
iﬁcations. This component was carefully constructed following the RESOLVE
discipline, including the deﬁnition of an abstract mathematical model of state,
an interface supporting observability and controllability, and a layered imple-
mentation that separates core functionality from secondary operations. This
software component has been formally veriﬁed in this work and is accessible
on GitHub [35].
2.2
Existing BDD Implementations
Existing software packages with implementations of the BDD data structure
are available for commonly used programming languages such as Java, C, and
Python, including BuDDy [25], CuDD [37], CacBDD [28], SableJBDD [31], JDD
[38], Sylvan [11], and BeeDeeDee [27]. Of these packages, SableJBDD and JDD
are Java-based. None of these packages have been formally veriﬁed or include
formal speciﬁcations, however, so correctness guarantees cannot be made and
the formal veriﬁcation of these components would require substantial eﬀort.
2.3
Applications of BDDs
BDDs are useful data structures in a variety of contexts, including disciplines
where correctness is critical. Some examples of these disciplines include Boolean
satisﬁability, circuit design [24], formal veriﬁcation, symbolic model checking,
network analysis [39], and artiﬁcial intelligence [23,26].
BDDs have commonly been used in formal veriﬁcation and model checking,
which are highly relevant to this work due to their strict correctness require-
ments. Symbolic model checking based on BDDs was originally used in hardware
model checking but was later extended to the domain of software veriﬁcation.
Prior to the introduction of BDD-based symbolic model checking, practical hard-
ware veriﬁcation via model checking was limited to models with less than 106
reachable states [9]. BDDs enabled practical veriﬁcation of industrial systems
with state spaces of more than 1020 [8], which also allows for software veriﬁca-
tion. Since they were popularized, BDDs have been frequently used in formal
software veriﬁcation and symbolic model checking, including in the Berkeley
package HSIS for formal veriﬁcation [4].
Despite the popularity and frequent use of the data structure, existing BDD
components have not been formally veriﬁed. Thus, guarantees about their cor-
rectness cannot be made. This is particularly relevant for formal veriﬁcation and
symbolic model checking applications because the tools being used for veriﬁca-
tion purposes are not veriﬁed themselves.
2.4
Object-Oriented and Automatic Veriﬁcation
This work concerns the veriﬁcation of a Java software component consisting of
two interfaces, an abstract base class, and a concrete derived class. A substantial

290
L. Rumreich and P. A. G. Sivilotti
barrier to this veriﬁcation process and to reasoning about Java programs in
general is the presence of aliases. Reasoning about software with aliases is well-
known as a challenging problem [18]. Many techniques to control aliasing in
object-based languages have been proposed, including notions of ownership and
borrowing as in Rust [20], adding additional annotations just for aliasing [1],
and the use of separation logic [7]. Another approach is to modify the language
to prevent aliases altogether, such as requiring pointers to be unique [29] or
using swapping to avoid aliasing [22]. The RESOLVE discipline, which is used
in the component veriﬁed in this project, uses the notions of swapping and clean
semantics to avoid problems related to aliasing [21]. This paper demonstrates
some of the additional complexities of reasoning about aliasing in Java rather
than the RESOLVE programming language.
Considerable research exists in the area of automatic software veriﬁcation
toward the goal of eliminating programming errors. Despite signiﬁcant advances
in automated theorem provers, SAT solvers, and SMT solvers, the construc-
tion of a fully automatic verifying compiler remains a long-term challenge in
computer science. Challenges including aliasing, side-eﬀects, ﬁxed-width number
representations, and concurrency make veriﬁcation of object-oriented languages
especially challenging. There has been relative success in this area using custom
programming languages explicitly designed with veriﬁcation in mind. Veriﬁca-
tion engines for such languages have been built using Dafny [15], RESOLVE [33],
Why3 [12], and Whiley [30]. These verifying compilers leverage formal reasoning
constraints built into the programming language to simplify automatic veriﬁca-
tion. Some of these languages, such as RESOLVE and Why3, can be translated
to other languages such as C, Java, or Ada, but require that the program is
ﬁrst developed in the language designed for formal veriﬁcation. However, these
veriﬁers cannot be used for the BDD implementation because they were not
designed for components written in Java.
Advancement in the area of a verifying compiler for industry-standard pro-
gramming languages is also considerable but incomplete [6]. An inﬂuential verify-
ing compiler for the Java programming language is the Extended Static Checker
for Java (ESC/Java) [13]. Other successful prototype verifying compilers for
Java, C#, and C are the KeY prover [14], VeriFast [19], Spec# [5], and VCC
[10]. However, these verifying compilers use unique speciﬁcation notations and
thus cannot be used for the BDD component. For example, the KeY prover uses
Java Modeling Language (JML) for speciﬁcations. To use these tools with the
BDD component, the formal speciﬁcations would need to be reconstructed to
match the required notation. Additionally, all of the library components used in
the BDD component that were developed in the RESOLVE discipline would need
to be replaced or modiﬁed to use the formal speciﬁcations of the new veriﬁer.
Another challenge is that many of these speciﬁcation notations lack the clean
semantics, full modularity, and comprehensibility of the RESOLVE framework,
all of which ease veriﬁcation.

Formal Veriﬁcation of a Java Component Using the RESOLVE Framework
291
3
Combining Value and Reference Semantics
3.1
RESOLVE and Value-Based Semantics
At the center of this project is the RESOLVE design philosophy and discipline
for software components that allows for ease of use by clients, reusability of soft-
ware, and the ability to formally verify both the software itself and the client
code that uses it. This discipline describes the principles to design and com-
pose high-quality component-based software systems. RESOLVE is also an inte-
grated speciﬁcation and programming language designed for building veriﬁed,
component-based software. It is imperative and object-based and has a collec-
tion of components such as those found in the standard libraries for C++, C#,
and Java. Programs written in RESOLVE can be veriﬁed with an automated
prover. Figure 1 illustrates this automated veriﬁcation on a List component for
the Reverse procedure.
Fig. 1. A screenshot of the RESOLVE web IDE
Parameter Modes. An important construct in the RESOLVE discipline is the
deﬁnition of parameter modes for arguments in method contracts. Parameter
modes are used to deﬁne the modiﬁcation frame of a method or loop. That is,
they deﬁne whether a method or loop body can change the value of a formal
parameter or variable. There are four parameter modes:
– Clears: The parameter is cleared to an initial value of its type
– Updates: The parameter can change value and the behavior of the method
can depend on the parameter’s (initial) value
– Replaces: The parameter can change value and the behavior of the method
does not depend on the parameter’s (initial) value
– Restores: (Default) The parameter’s ﬁnal value is the same as its initial
value

292
L. Rumreich and P. A. G. Sivilotti
Mathematical Model. A mathematical model is an abstract deﬁnition of a
component’s state space. It is implementation-independent and deﬁnes a pre-
cise mathematical type that the client can use to reason about the component’s
behavior. A mathematical model is written in terms of base types or mathe-
matical subtypes. Math base types are either basic types such as integers or
booleans or composite types such as tuples, sets, or strings (i.e., sequences).
Math subtypes are deﬁned in terms of other math subtypes and base types.
Math types are related to types in Java but are not equivalent. For example, the
math type integer is inﬁnite, but a Java int is bounded.
The math model for BooleanStructure is based on the mathematical
type BOOLEAN STRUCTURE. Clients use this math type to reason about the
BooleanStructure component regardless of which implementation is used. The
formal deﬁnition for this math type, shown in Listing 1.1, deﬁnes BOOLEAN STRUC-
TURE as a pair containing a set of ASSIGNMENTs named sat and a string of integers
named vars.
Listing 1.1. BooleanStructure Mathematical Model
1
/**
2
* @mathsubtypes
3
* ASSIGNMENT is finite set of integer
4
*
5
* BOOLEAN_STRUCTURE is (sat: finite set of ASSIGNMENT ,
6
*
vars: string of integer)
7
*
8
* @mathmodel type BooleanStructureKernel is modeled by
BOOLEAN_STRUCTURE
9
*/
Correspondence and Convention.
The correspondence, which is also
referred to as the abstraction relation, deﬁnes how a particular implementa-
tion’s speciﬁc representation, and similarly its convention, relates to the math
model that applies to the general component interface that all implementations
are based on. This relationship between the math model of the component and
the mathematical representation of the concrete implementation allows a client
to ignore the details of the implementation and reason about the component
using only the mathematical model. Implementers are then able to reason about
the implementing class using the mathematical representation that relates to the
implementation details.
The convention, also referred to as the concrete invariant, deﬁnes constraints
on a speciﬁc implementation. The convention for the BooleanStructure imple-
mentation veriﬁed in this work, shown in Listing 1.2, shows that the component
has two constraints. The ﬁrst is that the concrete ﬁeld $this.sat does not con-
tain any variables other than the ones in the ﬁeld $this.vars. Note that the
symbol “$” is used as a preﬁx to this to form $this when referring to the con-
crete state, in contrast to the abstract state which simply refers to this. The
second constraint is that the $this.vars ﬁeld does not contain any duplicates.

Formal Veriﬁcation of a Java Component Using the RESOLVE Framework
293
The correspondence for this component is trivial because it maps the concrete
representation consisting of two ﬁelds, $this.sat and $this.vars, to the math
model consisting of a tuple containing sat and vars.
Listing 1.2. BooleanStructure Convention and Correspondence
1
/**
2
* @mathdefinitions
3
*
NO_EXTRANEOUS_VARIABLES (
4
*
s: set of ASSIGNMENT , t: string of integer
5
*
) : boolean satisfies
6
*
for all a: ASSIGNMENT where ( a is in s )
7
*
( a is subset of entries(t) )
8
*
9
*
NO_DUPLICATES_IN_VARS (
10
*
t: string of integer
11
*
) : boolean satisfies
12
*
| t | = | entries(t) |
13
*
14
* @convention
15
*
NO_EXTRANEOUS_VARIABLES($this.sat , $this.vars) and
16
*
NO_DUPLICATES_IN_VARS($this.vars) and
17
*
18
* @correspondence this = ($this.sat , $this.vars)
19
*/
3.2
RESOLVE with Object-Oriented Languages
The RESOLVE discipline deﬁnes guidelines for developing high-quality and ver-
iﬁable software and applies when reasoning about the behavior of programs.
However, these discipline guidelines must be modiﬁed for use in practical pro-
gramming languages such as Java or C++. For instance, the Java constructs of
interfaces and classes are leveraged to accommodate the separation of abstract
and concrete representations of a component necessary for the RESOLVE dis-
cipline [36]. Java components that use this discipline also commonly have more
than one implementing class in the component, each with diﬀerent time and
space performance proﬁles but otherwise interchangeable from a client’s per-
spective. In this way, each implementing class can have diﬀerent concrete imple-
mentations, but the client reasons about them in the exact same way using the
abstract representation, or math model, of the component. Another change to
the discipline is necessary because of the risks introduced by the presence of
inheritance in the Java programming language, since RESOLVE does not allow
this capability. This change is the separation of component methods into kernel
and secondary methods. Kernel methods are the minimal set of operations that
allow the client to give a variable of the type any allowable value (controllability)
and determine the value of a variable of the type (observability). Kernel methods
must be re-implemented for every implementing class in the component. Con-
versely, secondary layered methods are “layered” on top of kernel methods in an
abstract class and are implemented as a client of the component, so they only

294
L. Rumreich and P. A. G. Sivilotti
need to be implemented once but apply to all implementing classes. An illustra-
tion of the RESOLVE component design pattern that separates the kernel and
secondary methods of the BDD component is shown in Fig. 2. This illustration
also demonstrates the use of Java interfaces and classes to separate abstract
and concrete elements of the component. The methods of the BooleanStructure
component are also shown.
Fig. 2. BooleanStructure component diagram
The RESOLVE programming language has additional restrictions that are
not present in Java and must also be accommodated. For example, RESOLVE
uses call-by-swapping for parameter passing, unlike Java which allows references.
RESOLVE also lacks an assignment operator, which prohibits aliasing, so formal
veriﬁcation in a Java component must verify that any aliases generated by the
use of the assignment operator do not disrupt the soundness of the veriﬁcation.
The BooleanStructure component and all of the libraries used in it that follow
the RESOLVE discipline attempt to avoid the pitfalls of the assignment opera-
tor by implementing the methods transferFrom and copyFrom. These methods
are used in place of the assignment operator to transfer and copy objects while
avoiding the complexities of aliasing. The BDD implementation of the trans-
ferFrom method assigns the concrete private ﬁelds of the BDD to those of the

Formal Veriﬁcation of a Java Component Using the RESOLVE Framework
295
source BDD. The copyFrom method builds a copy of the source BDD by making
copies of primitive types to avoid aliasing.
4
Formal Veriﬁcation of the BDD Component
The full formal veriﬁcation of a component involves the generation of loop invari-
ants, reasoning tables, and proofs based on both the abstract and concrete com-
ponents of the software. The goal of each proof in this work is to verify the
correctness of a method in the BooleanStructure component. This veriﬁcation
requires proving that each method meets the requirements of its postcondition
and eventually terminates. Details of the proof of correctness for this component
are in [32].
4.1
Loop Invariants and Iteration
The construction of loop invariants allows loops to be traced in a veriﬁcation
proof without knowledge of how many times a loop will iterate during code
execution. A special case of loop invariants is when they involve iterators, which
require extra consideration in the veriﬁcation process. An example of the for-
each syntax in Java with a loop invariant can be seen in Listing 1.3. The loop
in this example builds a duplicate of the sequence this.vars called newOrder.
Correspondingly, the invariant for this loop maintains that the variable newOrder
is always equal to the items in the collection this.vars that have already been
iterated over. For veriﬁcation purposes, the elements of the iterator that have
been seen and unseen at a particular point in the loop can be accessed using the
“∼” operator, such as in ∼this.vars.seen. The parameter mode for the variable
∼this.vars is updates because the seen and unseen elements are changing each
iteration.
Listing 1.3. Example for-each Loop With Iterator
1
/**
2
* @updates newOrder , ˜this.vars
3
* @maintains newOrder = ˜this.vars.seen
4
* @decreases |˜this.vars.unseen|
5
*/
6
for (int elt : this.vars) {
7
newOrder.add(newOrder.length (), elt);
8
}
However, this for-each loop syntax requires additional eﬀort in the construc-
tion of proofs. An example of the challenge associated with loops in the for-each
format is that the loop body in Listing 1.3 cannot be used to prove that the
value of |∼this.vars.unseen| decreases from one loop iteration to the next
because the value of |∼this.vars.unseen| is never explicitly updated through
a call to an iterator’s next method. Similarly, ∼this.vars.seen is never explic-
itly updated within the loop. However, the behavior of a for-each loop dictates

296
L. Rumreich and P. A. G. Sivilotti
that the ﬁrst operation of each loop iteration is to update this variable. Now, in
the ﬁrst line of the reasoning table for this loop, the value of ∼this.vars.seen
must simultaneously be its value before and after the update from an implicit
call to next, which is undesirable.
To solve this problem, a strategy that maintains a close similarity to the
source code but still allows for proofs of the loop invariant and progress metric is
used, which is shown in Listing 1.4. This strategy is to add a comment containing
a call to the iterator’s next method at the beginning of the loop. This comment
solves the problem of the .seen variable having two simultaneous values because
in the reasoning table, .seen is updated after the commented call to next in line
7 of the listing. Thus, before line 7, the loop invariant is guaranteed to still hold,
but after line 7 this is no longer a guarantee and the value of the seen and unseen
elements of the collection have been updated.
Listing 1.4. Example for-each Loop With Iterator: Proof Equivalent
1
/**
2
* @updates newOrder , ˜this.vars
3
* @maintains newOrder = ˜this.vars.seen
4
* @decreases |˜this.vars.unseen|
5
*/
6
for (int elt : this.vars) {
7
// elt = this.vars.next();
8
newOrder.add(newOrder.length (), elt);
9
}
Due to the additional complexity of iterators, it is generally more desirable
to use libraries of veriﬁed components with built-in functionality to perform
tasks such as the one shown in Listing 1.3, which is to copy an object. These
library components help avoid the dangers involved with iteration, such as the
creation of aliases during iteration, but in this case the use of an iterator was
unavoidable. Iteration over containers with immutable types, as in this example,
does not threaten the validity of the proof, however.
4.2
Reasoning Tables and Proofs
A reasoning table is a method of organizing the facts and obligations, otherwise
known as veriﬁcation conditions, generated from the implementation body of a
method. The facts and veriﬁcation conditions are generated directly from spec-
iﬁcations, the implementation, and the mathematical model, and the facts are
used to conﬁrm that the required veriﬁcation conditions are met. The techniques
employed in the production of the reasoning tables in this work use “natural
reasoning” formulated by Heym [16] to aid in comprehensibility and usability.
This reasoning technique is based on generating a sequence of facts that can
be combined to form new facts to prove veriﬁcation conditions. An example of
a reasoning table for the BooleanStructure method apply, which applies the
unary operator not, can be seen in Table 1. Note that the initial facts in the
reasoning table are the convention and correspondence from Listing 1.2. Other

Formal Veriﬁcation of a Java Component Using the RESOLVE Framework
297
facts and veriﬁcation conditions in the table are generated directly from pre- and
postconditions of other component methods. The ﬁnal veriﬁcation conditions in
the table are generated from the method postcondition, shown in Listing 1.5,
and the restoration of the convention. The speciﬁcation in Listing 1.5 refers to
#this, where the “#” symbol refers to the state of the object before the method
call and this refers to the ﬁnal state.
Table 1. Unary apply sample reasoning table
State
Path
Facts
Obligations
public void apply(UnaryOperator op) {
0
this = ($this.sat, $this.vars)
NO EXTRANEOUS VARIABLES($this.sat0, $this.vars0)
NO DUPLICATES IN VARS($this.vars0)
if (op == UnaryOperator.NOT) {
1
op = NOT
Set<Set<Integer>> newSat = new Set2<Set<Integer>> ();
2
op = NOT
newSat2 = {}
|$this.vars0| = |entries($this.vars0)|
PowerStringElements allAssignments = new PowerStringElements(this.vars());
3
op = NOT
allAssignments = $this.vars0
entries(∼allAssignments.seen3)
\
$this.sat0 =
newSat2
∼allAssignments.seen * ∼allAssignments.seen
= POWER STRING(allAssignments)
∼allAssignments.seen3 =<>
/**
* @updates newSat, ∼allAssignments
* @maintains entries(∼allAssignments.seen) \
$this.sat = newSat
* @decreases | ∼allAssignments.unseen|
*/
for (Set<Integer> a : allAssignments) {
4
op = NOT
entries(∼allAssignments.seen4)
\
$this.sat0 = newSat4
| ∼allAssignments.unseen4| > 0
| ∼allA...unseen4| > 0
// a = allAssignments.next()
5
op = NOT
∼allAssignments.seen5 = ∼allAssignments.seen4 * <a>
NO EXTRANEOUS VARIABLES($this.sat0, $this.vars0)
<a> * ∼allAssignments.unseen5 = ∼allAssignments.unseen4
NO DUPLICATES IN VARS($this.vars0)
if (!(processAssignment(this.sat, this.vars, a))) {
6
op = NOT
not(a intersection...)
newSat.add(a);
7
op = NOT
newSat7 = newSat4 union {a}
not(a intersection...)
} // end if
8
op = NOT
a intersection entries($this.vars0) is in $this.sat0
entries(∼allAssignments.seen5)
\
$this.sat0 = newSat8
implies newSat8 = newSat4
not(a intersection entries($this.vars0) is in $this.sat0)
| ∼allAssignments.unseen5| < | ∼allAssignments.unseen4|
implies newSat8 = newSat7
} // end for
9
op = NOT
| ∼allAssignments.unseen9| = 0
NO EXTRANEOUS VARIABLES($this.sat9, $this.vars0)
entries(∼allAssignments.seen9) $this.sat0 = newSat9
this.sat.transferFrom(newSat);
10
op = NOT
$this.sat10 = newSat9
newSat10 = {}
} // end if
11
op = NOT implies $this.sat11 = $this.sat10
this.vars11 = this.vars0
for all p: ASSIGNMENT where ( p is subset of entries(this.vars11) )
op /= NOT implies $this.sat11 = $this.sat0
( p is in this.sat11 iﬀ
( ( if op = NOT then
not(p intersection entries(this.vars0) is in this.sat0) ) and
( if op = IDENTITY then
(p intersection entries(this.vars0) is in this.sat0) ) ) )
$this.vars11 = $this.vars0
NO EXTRANEOUS VARIABLES($this.sat11, $this.vars11)
NO DUPLICATES IN VARS($this.vars11)
} // end unary apply
Proofs of the veriﬁcation conditions in the reasoning tables were constructed
in a custom format but follow the general structure of a direct proof, other-
wise known as a proof by construction. Facts taken directly from a reasoning
table are the proof assumptions. A sequence of small, carefully justiﬁed steps
using these facts and mathematical axioms were used to construct new factual
statements or lemmas. These steps are small enough to be mechanically check-
able. This sequence eventually results in the veriﬁcation condition for the proof.

298
L. Rumreich and P. A. G. Sivilotti
Proofs of each veriﬁcation condition for the BooleanStructure component were
constructed to form a single proof of correctness for the entire component.
Listing 1.5. Unary apply Speciﬁcation
1
/**
2
* Apply the unary operator {@code op} to {@code this}
3
* without changing the total order of the variables of
4
* {@code this}.
5
*
6
* @param op
7
*
the unary operation to be applied on this
8
* @updates this
9
* @ensures
10
*
this.vars = #this.vars and
11
*
for all p: ASSIGNMENT where ( p is subset of
12
entries(this.vars) )
13
*
( p is in this.sat iff
14
*
( ( if op = NOT then not EVALUATION(#this , p) ) and
15
*
( if op = IDENTITY then EVALUATION(#this , p) ) ) )
16
*/
17
void apply(UnaryOperator op);
5
Limitation in the Component Design Pattern
The Java component design pattern discussed in Sect. 3 is used in a sizeable com-
ponent library which includes the BDD component veriﬁed in this work. During
the process of verifying this BDD component, a shortcoming in the testing capa-
bilities of this design pattern was discovered. This limitation was discovered in
a component library used to teach thousands of computer science students since
2012 and was previously never discovered. This lack of detection indicates it is
not an easily discoverable or obvious ﬂaw. Additionally, it is likely that Java
component design patterns similar to the one used in the BooleanStructure
component also suﬀer from this testing limitation.
This limitation is related to how the design pattern uses abstract classes and
overridden methods. Note that a component following the design pattern used
in the BooleanStructure component may contain any number of implement-
ing classes. For example, the BDD implementation illustrated in Fig. 3 contains
BooleanStructure1 and BooleanStructure2. Also note that these implement-
ing classes extend a single shared abstract class, BooleanStructureSecondary,
containing the layered method implementations.
The component design pattern is organized so that implementing classes are
interchangeable from a client’s perspective. Further, implementing classes may
override any number of the layered methods that are in the component’s abstract
class. This is a desirable quality because overriding these methods allows their
performance to be improved by leveraging direct access to concrete representa-
tion ﬁelds.

Formal Veriﬁcation of a Java Component Using the RESOLVE Framework
299
However, an undesirable consequence of this design pattern occurs when
every implementing class overrides a particular layered method. Figure 3 illus-
trates this issue by listing which secondary methods are implemented in each
class of the BooleanStructure component. Notice how four layered methods
in BooleanStructureSecondary, including expand, isTrueStructure, isFalseS-
tructure, and satAssignment, are overridden by all implementing classes of
BooleanStructure. Since abstract classes cannot be instantiated directly, only
instantiations of implementing classes can be tested by the test suite. As a con-
sequence, if all of the implementing classes override a particular layered imple-
mentation, then that implementation never has the opportunity to be tested.
This ﬂaw is not critical because this untested code is by deﬁnition never used
by any implementing classes so clients have no access to it. However, it is still
undesirable to have untested and unreachable code in a component. Further, a
future modiﬁcation to the component may result in a new implementing class
that does not override a previously hidden layered method, thus exposing the
untested code and potentially an error.
Fig. 3. BooleanStructure secondary method implementations
To correct this limitation in the BooleanStructure component, the imple-
mentation was modiﬁed to include a new reference class that does not override
any secondary methods. This design pattern limitation is an interesting exam-
ple of the challenges associated with veriﬁcation using a language like Java that

300
L. Rumreich and P. A. G. Sivilotti
allows inheritance and does not have the strict limitations of the RESOLVE
language.
6
Corrections to the Component
The unmodiﬁed BDD implementation contained 314 unit test cases in a test suite
with 96.3% code coverage. Despite the high quality of this test suite, two imple-
mentation errors were discovered during the veriﬁcation process. The detection
of these errors despite a rigorous test suite demonstrates the relevance of the for-
mal veriﬁcation process. This also demonstrates how the veriﬁcation process can
be practically carried out on a Java component with RESOLVE speciﬁcations.
Additionally, many errors in the speciﬁcations were discovered in this process.
Errors of this variety could lead to mistakes in client code due to a misrepre-
sentation of BooleanStructure behavior. The errors of this type were also not
revealed by the test suite.
copyFrom Runtime Exception. An error in the behavior of the copyFrom
method, which is shown in Listing 1.6, was discovered in the veriﬁcation process.
This error was likely not discovered previously because the method appears to
be correct and passed many test cases with one-hundred percent code coverage.
The copyFrom method is a secondary layered implementation, so it is not based
on the underlying implementation of the component. In the original method
implementation, a runtime exception occurs when there are no satisfying assign-
ments in the method argument BooleanStructure x but the number of vari-
ables is nonzero. An example of a Boolean formula with this quality is x1 ∧¬x1
because it has no possible satisfying assignments but it is over a nonzero num-
ber of variables. In this scenario, the precondition for the reorder method that
VARIABLES(newExp) = entries(newOrder) cannot be satisﬁed because the con-
ditional block after if (x.evaluate(t)) never executes when x.sat is empty.
Thus, the variables in newExp remain in the initial empty state, causing a runtime
exception in line 28 in the call to reorder.
Listing 1.6. copyFrom Original Implementation With Error
1
public void copyFrom(BooleanStructure x) {
2
// Generate a false structure with the same vars as x
3
BooleanStructure newExp = this.newInstance ();
4
newExp.negate ();
5
Sequence <Integer > order = x.vars();
6
7
// Take the disjunction of every assignment in x.sat
8
PowerStringElements allAssignments = new
PowerStringElements(order);
9
for (Set <Integer > t : allAssignments) {
10
if (x.evaluate(t)) {
11
// Conjunct terms in t and negations in not(t)
12
BooleanStructure term = this.newInstance ();
13
for (int v : order) {
14
BooleanStructure vExp = this.newInstance ();

Formal Veriﬁcation of a Java Component Using the RESOLVE Framework
301
15
vExp.setFromInt(v);
16
if (!t.contains(v)) vExp.negate ();
17
term.conj(vExp);
18
}
19
newExp.disj(term);
20
}
21
}
22
23
// Reorder variables in new structure to match x’s order
24
Sequence <Integer > newOrder = new Sequence1L <Integer >();
25
for (int v : order) {
26
newOrder.add(newOrder.length (), v);
27
}
28
newExp.reorder(newOrder);
29
30
this.transferFrom(newExp);
31
}
toStringTT Violation of Postcondition. The need for an additional constraint
in a method precondition was revealed when the formal veriﬁcation of the method
toStringTT could not be completed. This method constructs a truth table rep-
resentation of the BDD. The original implementation of this method performed
a left bit shift operation based on the number of variables in the structure. How-
ever, since the long type in Java is limited to 64 bits, the method produced
an erroneous result and violated the postcondition if the number of variables
exceeded this limit. The added constraint in the precondition of the method
requires that the number of variables is less than 64.
Inconsistent isEquivalent Math Deﬁnition. The speciﬁcation for the isE-
quivalent method, which compares the logical equivalence of two BDDs, had
to be modiﬁed because the implementation and speciﬁcation were inconsistent.
The original speciﬁcation compared the satisfying assignments and variables of
the BDDs to check for equality. A modiﬁcation to the speciﬁcation was required
because it did not consider logically equivalent BDDs with diﬀerent variables to
meet the speciﬁcation, but the implementation did.
Missing newOrder Speciﬁcations. The original newOrder private method,
which constructs a variable ordering that is compatible with two input order-
ings, had a postcondition that was too weak to be useful. It required that the
new ordering was compatible with the original two, but did not require anything
about the order entries. This is clearly too weak because an empty sequence
would always satisfy this postcondition. To correct this, additional postcondi-
tion requirements were added to require that the new ordering variables are
the union of the input variables. Further, the method required a strengthened
precondition to prove a compatible ordering requirement of the original post-
condition. In fact, a correct implementation of the speciﬁcation without this
precondition is impossible because a nontrivial compatible ordering of the result
and the two inputs is impossible if the two inputs are not already compatible.

302
L. Rumreich and P. A. G. Sivilotti
7
Conclusion
A contribution of this work is the identiﬁcation of a limitation of the testing
capabilities of the Java component design pattern used in the BDD implementa-
tion. The current structure of this design pattern allows for the possibility that
all implementing classes of a component override the layered implementations
of secondary methods, thus leaving these layered implementations unreachable
and untested. This limitation demonstrates one of the challenges associated with
combining an industry-standard language such as Java with formal veriﬁcation.
A second outcome is the construction of a proof that formally veriﬁes the
correctness of a reference implementation of a Java-based BDD component. The
resulting formally veriﬁed BDD component can now be used with a high level of
conﬁdence by clients. A third outcome resulting from the formal veriﬁcation of
the BDD component is the identiﬁcation and correction of errors. Errors were
discovered in both the speciﬁcations and implementation of the BDD component.
The errors discovered in the implementation are particularly notable because
they were not discovered by the comprehensive test suite. These errors were
discovered only in the formal veriﬁcation process, which indicates how critical
formally verifying software is for error-resistant software development.
An expansion of this work is to develop an automated theorem prover to
automate the veriﬁcation process of a Java-based component with RESOLVE
speciﬁcations. This veriﬁer would be uniquely practical and useful because of the
use of an industry-standard programming language with a speciﬁcation notation
that is particularly well-suited to client reasoning and modularity. This project
lays some groundwork for an automated prover of this type because it provides a
carefully constructed example of valid inputs and a corresponding ideal expected
output. A veriﬁer for a Java-based component with RESOLVE speciﬁcations
would require the construction of a tool to automate the generation of veriﬁcation
conditions in a modular fashion. Existing RESOLVE veriﬁers [17,33] could then
be leveraged with only slight modiﬁcations to discharge a substantial proportion
of the veriﬁcation conditions in an automated way.
Acknowledgement. The authors would like to acknowledge Saad Asim for his devel-
opment of the original BDD code base. Additionally, this work has beneﬁted from
extensive discussions with other the members of the Reusable Software Research Group.
References
1. Aldrich, J., Kostadinov, V., Chambers, C.: Alias annotations for program under-
standing. SIGPLAN Not. 37(11), 311–330 (2002). https://doi.org/10.1145/583854.
582448
2. Asim, S.: An exercise in design: the binary decision diagram. SIGSOFT Softw.
Eng. Notes 43(3), 19 (2018). https://doi.org/10.1145/3229783.3229801
3. Asim, S.: The binary decision diagram: abstraction and implementation. Master’s
thesis, The Ohio State University (2018)

Formal Veriﬁcation of a Java Component Using the RESOLVE Framework
303
4. Aziz, A., et al.: HSIS: a BDD-based environment for formal veriﬁcation. In: 1994
31st Design Automation Conference, Los Alamitos, CA, USA, pp. 454–459. IEEE
Computer Society (1994). https://doi.org/10.1145/196244.196467
5. Barnett, M., F¨ahndrich, M., Leino, K.R.M., M¨uller, P., Schulte, W., Venter, H.:
Speciﬁcation and veriﬁcation: the Spec# experience. Commun. ACM 54(6), 81–91
(2011). https://doi.org/10.1145/1953122.1953145
6. Beyer, D.: Advances in automatic software veriﬁcation: SV-COMP 2020. In:
TACAS 2020. LNCS, vol. 12079, pp. 347–367. Springer, Cham (2020). https://
doi.org/10.1007/978-3-030-45237-7 21
7. Brookes, S.: A semantics for concurrent separation logic. In: Gardner, P., Yoshida,
N. (eds.) CONCUR 2004. LNCS, vol. 3170, pp. 16–34. Springer, Heidelberg (2004).
https://doi.org/10.1007/978-3-540-28644-8 2
8. Burch, J., Clarke, E., McMillan, K., Dill, D., Hwang, L.: Symbolic model checking:
1020 States and beyond. Inf. Comput. 98(2), 142–170 (1992). https://doi.org/10.
1016/0890-5401(92)90017-A
9. Chaki, S., Gurﬁnkel, A.: BDD-based symbolic model checking. In: Clarke, E., Hen-
zinger, T., Veith, H., Bloem, R. (eds.) Handbook of Model Checking, pp. 219–245.
Springer, Cham (2018). https://doi.org/10.1007/978-3-319-10575-8 8
10. Cohen, E., et al.: VCC: a practical system for verifying concurrent C. In: Berghofer,
S., Nipkow, T., Urban, C., Wenzel, M. (eds.) TPHOLs 2009. LNCS, vol. 5674, pp.
23–42. Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-642-03359-9 2
11. van Dijk, T., van de Pol, J.: Sylvan: multi-core framework for decision diagrams.
Int. J. Softw. Tools Technol. Transf. 19, 675–696 (2016). https://doi.org/10.1007/
s10009-016-0433-2
12. Filliˆatre, J.-C., Paskevich, A.: Why3—where programs meet provers. In: Felleisen,
M., Gardner, P. (eds.) ESOP 2013. LNCS, vol. 7792, pp. 125–128. Springer, Hei-
delberg (2013). https://doi.org/10.1007/978-3-642-37036-6 8
13. Flanagan, C., Leino, K.R.M., Lillibridge, M., Nelson, G., Saxe, J.B., Stata, R.:
Extended static checking for Java. SIGPLAN Not. 37(5), 234–245 (2002). https://
doi.org/10.1145/543552.512558
14. H¨ahnle, R., Menzel, W., Schmitt, P.H.: Integrierter deduktiver software-entwurf.
K¨unstliche Intell. 12(4), 40–41 (1998)
15. Herbert, L., Leino, K.R.M., Quaresma, J.: Using Dafny, an automatic program
veriﬁer. In: Meyer, B., Nordio, M. (eds.) LASER 2011. LNCS, vol. 7682, pp. 156–
181. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-35746-6 6
16. Heym, W.: Computer program veriﬁcation: improvements for human reasoning.
Ph.D. thesis, Ohio State University (1995)
17. Hoﬀman, D.: Techniques for the speciﬁcation and veriﬁcation of enterprise appli-
cations. Ph.D. thesis, Ohio State University (2016)
18. Hogg, J., Lea, D., Wills, A., deChampeaux, D., Holt, R.: The Geneva convention
on the treatment of object aliasing. SIGPLAN OOPS Mess. 3(2), 11–16 (1992).
https://doi.org/10.1145/130943.130947
19. Jacobs, B., Smans, J., Philippaerts, P., Vogels, F., Penninckx, W., Piessens, F.:
VeriFast: a powerful, sound, predictable, fast veriﬁer for C and Java. In: Bobaru,
M., Havelund, K., Holzmann, G.J., Joshi, R. (eds.) NFM 2011. LNCS, vol. 6617,
pp. 41–55. Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-642-20398-
5 4
20. Klabnik, S., Nichols, C.: The Rust Programming Language. No Starch Press, San
Francisco (2018)

304
L. Rumreich and P. A. G. Sivilotti
21. Kulczycki, G., Sitaraman, M., Ogden, W., Leavens, G.: Preserving clean seman-
tics for calls with repeated arguments. Technical report RSRG-04-01, Depart-
ment of Computer Science, Clemson University (2003). http://www.cs.clemson.
edu/∼resolve
22. Kulczycki, G., Vasudeo, J.: Simplifying reasoning about objects with Tako. In: Pro-
ceedings of the 2006 Conference on Speciﬁcation and Veriﬁcation of Component-
Based Systems, SAVCBS 2006, pp. 57–64. Association for Computing Machinery,
New York (2006). https://doi.org/10.1145/1181195.1181207
23. Kurai, R., Minato, S., Zeugmann, T.: N-gram analysis based on zero-suppressed
BDDs. In: Washio, T., Satoh, K., Takeda, H., Inokuchi, A. (eds.) JSAI 2006. LNCS
(LNAI), vol. 4384, pp. 289–300. Springer, Heidelberg (2007). https://doi.org/10.
1007/978-3-540-69902-6 25
24. Lee, C.Y.: Representation of switching circuits by binary-decision programs. Bell
Syst. Tech. J. 38(4), 985–999 (1959). https://doi.org/10.1002/j.1538-7305.1959.
tb01585.x
25. Lind-Nielsen, J.: BuDDy - A Binary Decision Diagram Package (2003). http://
vlsicad.eecs.umich.edu/BK/Slots/cache/www.itu.dk/research/buddy/
26. Loekito, E., Bailey, J., Pei, J.: A binary decision diagram based approach for mining
frequent subsequences. Knowl. Inf. Syst. 24(2), 235–268 (2010). https://doi.org/
10.1007/s10115-009-0252-9
27. Lovato, A., Macedonio, D., Spoto, F.: A thread-safe library for binary decision
diagrams. In: Giannakopoulou, D., Sala¨un, G. (eds.) SEFM 2014. LNCS, vol. 8702,
pp. 35–49. Springer, Cham (2014). https://doi.org/10.1007/978-3-319-10431-7 4
28. Lv, G., Su, K., Xu, Y.: CacBDD: a BDD package with dynamic cache manage-
ment. In: Sharygina, N., Veith, H. (eds.) CAV 2013. LNCS, vol. 8044, pp. 229–234.
Springer, Heidelberg (2013). https://doi.org/10.1007/978-3-642-39799-8 15
29. Minsky, N.H.: Towards alias-free pointers. In: Cointe, P. (ed.) ECOOP 1996.
LNCS, vol. 1098, pp. 189–209. Springer, Heidelberg (1996). https://doi.org/10.
1007/BFb0053062
30. Pearce, D.J., Groves, L.: Designing a verifying compiler: lessons learned from devel-
oping whiley. Sci. Comput. Program. 113, 191–220 (2015). https://doi.org/10.
1016/j.scico.2015.09.006. Formal Techniques for Safety-Critical Systems
31. Qian, F.: SableJBDD: A Java Binary Decision Diagram Package (2004). http://
www.sable.mcgill.ca/∼fqian/SableJBDD/
32. Rumreich, L.: The binary decision diagram: formal veriﬁcation of a reference imple-
mentation. Master’s thesis, The Ohio State University (2021)
33. Sitaraman, M., et al.: Building a push-button RESOLVE veriﬁer: progress and
challenges. Formal Aspects Comput. 23(5), 607–626 (2011). https://doi.org/10.
1007/s00165-010-0154-3
34. Sitaraman, M., Weide, B.: Component-based software using RESOLVE. ACM SIG-
SOFT Softw. Eng. Notes 19(4), 21–22 (1994). https://doi.org/10.1145/190679.
199221
35. Sivilotti, P., Asim, S., Rumreich, L.: BDD: A Binary Decision Diagram Software
Component (2021). https://github.com/osu-rsrg/BDD
36. Sivilotti, P.A., Lang, M.: Interfaces ﬁrst (and foremost) with Java. In: Proceed-
ings of the 41st ACM Technical Symposium on Computer Science Education,
SIGCSE 2010, pp. 515–519. Association for Computing Machinery, New York
(2010). https://doi.org/10.1145/1734263.1734436
37. Somenzi, F.: CUDD: CU decision diagram package release 3.0.0 (2015). http://
vlsi.colorado.edu/fabio/CUDD/

Formal Veriﬁcation of a Java Component Using the RESOLVE Framework
305
38. Vahidi, A.: JDD: a pure Java BDD and Z-BDD library (2019). https://bitbucket.
org/vahidi/jdd/src/master/
39. Xing, L.: An eﬃcient binary-decision-diagram-based approach for network reliabil-
ity and sensitivity analysis. IEEE Trans. Syst. Man Cybern. Part A Syst. Hum.
38(1), 105–115 (2008). https://doi.org/10.1109/TSMCA.2007.909493
40. Zweben, S.H., Edwards, S.H., Weide, B.W., Hollingsworth, J.E.: The eﬀects of
layering and encapsulation on software development cost and quality. IEEE Trans.
Softw. Eng. 21(3), 200–208 (1995). https://doi.org/10.1109/32.372147

Author Index
Baader, Franz
81
Baumgartner, Peter
98
Bigarella, Filippo
213
Bromberger, Martin
3
Chvalovský, Karel
173
Cimatti, Alessandro
213
Defourné, Antoine
139
Dragoste, Irina
3
Erbatur, Serdar
25
Faqeh, Rasha
3
Fetzer, Christof
3
Fontaine, Pascal
232
Gil, Oliver Fernández
81
Goertzel, Zarathustra A.
173
Griggio, Alberto
213
Irfan, Ahmed
213
Jakub˚uv, Jan
173
Jonáš, Martin
213
Kaliszyk, Cezary
154
Krötzsch, Markus
3
Lin, Hai
253, 271
Lynch, Christopher
253, 271
Marshall, Andrew M.
25, 253
Meadows, Catherine A.
253
Narendran, Paliath
253
Olšák, Miroslav
173
Peuter, Dennis
43
Ravishankar, Veena
253
Ringeissen, Christophe
25
Rostamigiv, Maryam
81
Roveri, Marco
213
Rozek, Brandon
253
Rumreich, Laine
287
Sakr, Mostafa
118
Schmidt, Renate A.
118
Schurr, Hans-Jörg
232
Sebastiani, Roberto
213
Sivilotti, Paolo A. G.
287
Sofronie-Stokkermans, Viorica
43
Subramani, K.
63
Suda, Martin
192
Trentin, Patrick
213
Urban, Josef
173
Velasquez, Alvaro
63
Wang, Qingxiang
154
Weidenbach, Christoph
3
Wojciechowski, P.
63

