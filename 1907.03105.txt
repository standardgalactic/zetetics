Constraint-Based Type-Directed Program Synthesis
Extended Report∗
PETER-MICHAEL OSERA, Grinnell College, United States of America
We explore an approach to type-directed program synthesis rooted in constraint-based type inference tech-
niques. By doing this, we aim to more efficiently synthesize polymorphic code while also tackling advanced
typing features such as GADTs that build upon polymorphism. Along the way, we also present an imple-
mentation of these techniques in Scythe, a prototype live, type-directed programming tool for the Haskell
programming language and reflect on our initial experience with the tool.
CCS Concepts: • Software and its engineering →Semantics; Automatic programming; • Theory of
computation →Logic and verification;
Additional Key Words and Phrases: Functional Programming, Program Synthesis, Type Inference, Type Theory
1
INTRODUCTION
Functional programmers frequently comment how richly-typed functional programs just “write
themselves”.1 For example, consider writing down a function that obeys the type:
f :: a -> Maybe a -> a
Because the return type of the function, a, is polymorphic we can only produce a value from two
sources:
(1) The first argument to the function (of type a).
(2) The result of pattern matching on the second argument (in the Just case, its argument will
have type a).
These restrictions highly constrain the set of valid programs that will typecheck, giving the
impression that the function writes itself as long as the programmer can navigate the type system
appropriately. To do this, they must systematically check the context to see what program elements
are relevant to their final goal and try to put them together into a complete program. However, such
navigation is usually mechanical and tedious in nature. It would be preferable if a tool automated
some or all of this type-directed development process.
Such luxuries are part of the promise of type-directed program synthesis tools. Program synthesis
is the automatic generation of programs from specification. In this particular case, the specification
of our program is its rich type coupled with auxiliary information, e.g., concrete examples of
intended behavior.
1.1
From Typechecking to Program Synthesis
Type-directed synthesis techniques search the space of possible programs primarily through a
reinterpretation of the programming language’s type system [6, 19, 22]. Traditionally, type systems
are specified by defining a relation between a context, expression, and type, e.g., Γ ⊢e : τ declares
that e has type τ under context Γ. From this specification, we would like to extract a typechecking
algorithm for the language. However, because relations do not distinguish between inputs and
outputs, it is sometimes not clear how to extract such an algorithm. Bi-directional typechecking
systems [21] alleviate these concerns by making it explicit which components of the system are
∗This is an extended version of a paper that originally appeared in TyDe 2019 [18].
1Once you get over the complexity of the types!
Author’s address: Peter-Michael Osera, Department of Computer Science, Grinnell College, United States of America,
osera@cs.grinnell.edu.
arXiv:1907.03105v1  [cs.PL]  6 Jul 2019

2
Peter-Michael Osera
inputs and outputs of the system, typically by distinguishing the cases where we check that a term
has a type from the cases where we infer that a term has a type. In the former case, the type acts as
an input to the system where in the latter case, it is an output.
In both cases, the term being typechecked serves as an input to the typechecking algorithm.
However, with type-directed program synthesis, we instead view the term as an output and the
type as an input. For example, consider the standard function application rule found in most type
systems:
Γ ⊢e1 : τ1 →τ2
Γ ⊢e2 : τ1
Γ ⊢e1 e2 : τ2
While we can observe that the function application should be typed at the result type of the function
e1, it isn’t clear which parts of the relations are inputs and outputs and the order in which the
checks ought to be carried out. A bidirectional interpretation of this rule makes the inputs and
outputs explicit:
Γ ⊢e1 ⇒τ1 →τ2
Γ ⊢e2 ⇐τ1
Γ ⊢e1 e2 ⇒τ1 →τ2
Here, the relation Γ ⊢e1 ⇒τ1 →τ2 means that we infer that the type of e1 is τ1 →τ2. The relation
Γ ⊢e2 ⇐τ1 means that we check that the type of e2 is indeed τ1. With this, the procedure for type
checking a function application is clear: infer a function type τ1 →τ2 for e1 and then check that e2
has that input type τ1; the type of the overall application is then inferred to be the output type τ2.
With type-directed synthesis, we turn typechecking into term generation by reinterpreting the
inputs and outputs of the typechecking relation.
Γ ⊢τ1 →τ2 ⇒e1
Γ ⊢τ1 ⇒e2
Γ ⊢τ2 ⇒e1 e2
The relation Γ ⊢τ ⇒e asserts that whenever we have a goal type τ we can generate a term e of
that type. Now our term generation rule for function application says that whenever we have a goal
type τ2, we can generate a function application e1 e2 where the output of the function type agrees
with the goal. We can apply this pattern to the other rules of the type system to obtain a complete
term generation system for a language. We can further augment the system with type-directed
example decomposition [6, 19] or richer types such as refinements [22] to obtain true program
synthesis systems.
This type-theoretic interpretation of program synthesis gives us immediate insight into how to
synthesize programs for languages with rich type systems. Because rich types constrain the set
of possible programs dramatically, program synthesis with types can lead to superior synthesis
performance. On top of this, the type-directed synthesis style directly supports type-directed
programming, a hallmark of richly-typed functional programming languages.
1.2
The Perils of Polymorphism
However, in supporting rich types, in particular polymorphism, we run into a pair of problems that
deserve special attention.
• The type enumeration problem: when dealing with polymorphic types, we must first
instantiate them. However, there may be many possible instantiations of a polymorphic type.
For example, consider the map function of type (a -> b) -> [a] -> [b]. Even if we know
that we need to create a value of type [Bool], there is nothing directly constraining the type
variable a.

Constraint-Based Type-Directed Program Synthesis
3
σ
:: =
∀ai
i.τ
Type Schemes
τ
:: =
α | a | T τi
i | τ1 →τ2
Monotypes
e
:: =
x | K | λx.e | e1 e2 | case e of mj
j
Expressions
m
:: =
K xk
k →e
Match Branches
b
:: =
x = e
Top-level Bindings
C
:: =
{τi ∼τ ′
i
i}
Constraints
θ
:: =
· | [τ/a]θ | [τ/α]θ
Type Environments
Γ
:: =
· | x:σ, Γ | K:∀ai
i.C ⇒τk
k →T ai
i, Γ
Contexts
Fig. 1. Basic syntax of the object language.
Current systems that handle polymorphic synthesis simply enumerate and explore all the
possible types that can be created from the context. However, this may lead to an excessive
exploration of type combinations that do not work, e.g., choosing a to be Int but not having
any functions of type Int -> Bool available in the context. Furthermore, it may lead to
repeated checking of terms that are, themselves, polymorphic, e.g., the empty list [] :: [a]
for any type a. We would like to develop a system that systematically searches the space of
polymorphic instantiations while minimizing the work done as much as possible.
• Reasoning about richer types: polymorphic types are relatively easy to handle in an ad hoc
fashion. However, polymorphic types form the basis for a variety of advanced type features
such as generalized algebraic datatypes (GADTs) and typeclasses that are commonly used in
advanced functional programming languages. Rather than developing ad hoc solutions for
all these related features, it would be useful to have a single framework for tackling them all
at once.
1.3
Outline
In this paper we present a solution to the problems described above: a constraint-based approach
to type-directed program synthesis. Constraint-based typing is used primarily to specify type
inference systems which generate constraints between types in the program and then solves those
constraints to discover the types of unknown type variables. In the spirit of type-directed program
synthesis, we flip the inputs and outputs of the constraint-based typing system to arrive at a
synthesis system that tracks type constraints throughout the synthesis process. This embodies a
new strategy for synthesis—“infer types while synthesizing”—that allows for efficient synthesis
of polymorphic code while also giving us a framework to tackle GADTs and other advanced type
features built on polymorphism.
In section 2, we develop a constraint-based program synthesis based on a basic constraint-based
type inference system. In section 3, we extend the system to account for GADTs. In section 4, we
discuss our prototype implementation of this approach in our program synthesis tool, Scythe. And
finally in section 5 and section 6 we close by discussing future extensions and related work. The
extended version of this report which initially appeared in TyDe 2019 [18] includes several bug
fixes to the system as well as complete proofs of soundness in Appendix A.
2
CONSTRAINT-BASED PROGRAM SYNTHESIS
We first develop a constraint-based program synthesis system for a core functional programming
language featuring algebraic datatypes and polymorphism. To do this, we first present a standard

4
Peter-Michael Osera
Hindley-Milner style type inference system for the language and then show how to re-interpret it
as a program synthesis system, augmented with example propagation in the style of Myth [19].
Figure 1 gives the syntax of the object language. Types are composed of top-level type schemes
σ which introduce universally quantified type variables. The language of monotypes τ enclosed in
type schemes include type variables a, function types, and saturated algebraic datatypes T τj
j. The
constraint-generation process also generates unification variables α, β,γ, . . ., that are eventually
substituted away during the inference process. The context Γ records both the type of variables
and constructors K, enforcing that all constructors are (possibly) polymorphic functions whose
co-domain is their associated algebraic datatype. The co-domain is restricted to the universally
quantified type variables of the declaration; in section 3, we lift this restriction to enable generalized
algebraic datatypes.
The expression language is a standard typed, functional language with algebraic datatype
constructors and pattern matching restricted to one-level peeling of head constructors from their
arguments. Like Haskell, we treat constructors like function application and allow for partial
application of constructor values. Conspicuously absent from the expression language are let-
bindings. This is because we do not synthesize let-bindings (that are not top-level) during the
synthesis process. As we shall see shortly, there is no type-or-example-directed way to synthesize
such bindings in the general case, so we elide them from our object language.
Throughout this paper, we refer to sequences of objects either using ellipses, e.g., e1 . . .ek, or
using overbar notation ek
k where we use index variables i, j,k, . . . to represent the lengths of these
sequences. We denote nested sequences (i.e., sequences of sequences) using nested overbars and
both subscripts and superscripts to separate the lengths. For example, ei
j
ji
refers to a sequence (of
size i) of sequences (of size j) of expressions e denoted ei
j. Finally, whenever possible we use the
metavariables i, j, and k to denote the lengths of the following sequences:
• i: types, e.g., ∀ai
i.τ, T τi
i,
• j: examples, e.g., {Sj →χj}
j, and
• k: arguments (to constructors), e.g., K ek
k.
2.1
Type Inference
Figure 2 gives the type inference rules for the system. As is standard, our constraint-based type
inference system operates in two phases: type-and-constraint generation and constraint solving.
The primary judgment of the system Γ ⊢e : τ ⇒C infers that expression e has type τ under context
Γ and generates constraints C. Constraints in this system τ1 ∼τ2 assert equalities between types,
in particular, giving concrete types to unification variables α that are generated for unknown types
during the inference process. For example, in the case of an un-annotated lambda (infer-lam),
we do not immediately know the type of the argument to the lambda x. Thus, we create a fresh
unification variable α and use that variable as the type of the argument. In inferring the type of the
body of the lambda, we will generate constraints C that refine the type of α.
In addition to assigning unification variables to types, constraints also serve the purpose of
asserting expected equalities between types of sub-expressions. When inferring the type of a
function application (infer-app), we assert that the type of the head expression is indeed a function
type and the argument expression’s type is the domain of that function type (τ1 ∼τ2 →α). When
inferring the type of a case scrutinee (infer-case), we assert that the type of the scrutinee is indeed
an algebraic datatype with fresh unification variables in place of its arguments (τ ∼T αi
i). And
finally, we add constraints when inferring the overall type of a case expression stating that all of
the branches have the same type (β ∼τj
j).

Constraint-Based Type-Directed Program Synthesis
5
Γ ⊢e : τ ⇒C
infer-var
freshαi
i
x:∀ai
i.τ ∈Γ
Γ ⊢x : [αi/ai]
iτ ⇒·
infer-app
freshα
Γ ⊢e1 : τ1 ⇒C1
Γ ⊢e2 : τ2 ⇒C2
Γ ⊢e1 e2 : α ⇒C1 ∪C2 ∪{τ1 ∼τ2 →α}
infer-case
freshαi
i, β
Γ ⊢e : τ ⇒C
C′ = C ∪{τ ∼T αi
i}
Γ ⊢αi
i;bj : τj ⇒Cj
j
Γ ⊢case e of bj
j : β ⇒C′ ∪Cj
j ∪{β ∼τj
j}
infer-lam
freshα
x:α, Γ ⊢e : τ ⇒C
Γ ⊢λx.e : α →τ ⇒C
Γ ⊢αi
i;m : τ ⇒C
infer-match
K:∀ai
i.τk
k →T ai
i ∈Γ
xk:[αi/ai]
iτk
k
, Γ ⊢e : τ ⇒C
Γ ⊢αi
i;K xk
k →e : τ ⇒C
Γ ⊢b : σ
infer-bind
Γ ⊢e : τ ⇒C
unify(C) = θ
αi
i < fuvs(θ)
freshai
i
Γ ⊢f = e : ∀ai
i. [ai/αi]
iθτ
Fig. 2. Type inference system.
Polymorphic types interact with the inference system in two ways. The first is let-generalization
which occurs at top-level bindings f = e. After generating constraints C for the body of the binding,
we solve them using a standard unification algorithm to find a type substitution θ for each of the
unification variables found in C (infer-bind). Those unification variables with no substituting
types (∀αi
i < fuvs(θ)) become universal type variables in the final type scheme of f . The second
way lies in inferring the monotypes we use to instantiate the type schemes of variables. Rather
than requiring that the user provides the instantiation via a type application form or guessing the
instantiation upfront, we instantiate a type scheme with fresh unification variables αi
i that will be
later constrained based on how the the variable x is used by the program (infer-var).
2.2
Constraint-based Synthesis
Figure 3 gives the syntactic extensions to the core language to support type-and-example-directed
program synthesis in the style of Myth [6, 19]. We extend the language with example values χ
that the user provides as additional specification to the synthesizer. Intuitively, example values are
specifications of values at a particular type that can be decomposed into specifications for those

6
Peter-Michael Osera
v
:: =
c | λx.e | K vi
i
Values
χ
:: =
c | K χi
i | v ⇒χ
Examples
X
:: =
∀ci:ai
i. χj
j
Top-level Examples
S
:: =
[vi/xi]
i
Environments
W
:: =
[Sj 7→χj]
j
Example Worlds
Γ
:: =
· · · | c:a, Γ
Contexts
Fig. 3. Syntactic extensions for type-and-example-directed program synthesis.
values’ components. For example, each of the values vi of a saturated constructor example K vi
can become examples for synthesizing each of K’s arguments.
However, it is not immediately clear how to decompose values at function type, i.e., lambdas, in
a similar way. Like Myth, we introduce input-output pairs v ⇒χ as a distinguished example value
at function type. Such examples are easily decomposed and align with our intuition that we would
like to specify the behavior of a function through a collection of input-output examples (either
realized as test cases or documentation).
The synthesis system takes as input a context Γ, a goal type τ, and a set of examples, and produces
a program of that type that agrees with the set of examples. Ultimately, the system decomposes
the examples, assigning sub-values to generated binders—from lambdas and case expressions—as
the synthesizer generates them. These are recorded alongside the examples that generated them,
leading to the notion of an example world W as a pair of a (value) environment S and a example
goal χ for that world. When checking that a program agrees with these examples, we evaluate
the program closed with each example world’s environment and check that the resulting value
is consistent with that world’s example goal. We write the application of an environment S to an
expression e using juxtaposition: Se.
Figure 4 describes the complete synthesis system over the language. In the spirit of bidirectional
typechecking [21], we divide type-directed synthesis into two processes which are realized as a
pair of judgments in the system:
(1) Refinement, Γ ⊢τ ▷W ⇒e, decomposes a set of input examples according to their types.
(2) Generation, Γ ⊢τ ⇒e enumerates terms in a type-directed fashion in the absence of examples.
The separation is, in fact, a division of the syntax of the language into introduction forms and
elimination forms for refinement and generation, respectively. From a type inference perspective,
type information flows into introduction forms (i.e., we check against their expected types based on
their shape) and out of elimination forms (i.e., we infer their types based on their sub-components).
From a synthesis perspective, this means we can use the shape of an introduction form to determine
how to decompose examples whereas we have no such affordances in the general case for elimination
forms. Thus, we must resort to raw term enumeration for those forms.
As a final note, the system as described does not support recursive functions (note that in Figure 4,
refine-lam does not bind anything for the function itself) in order to make clear the details of
constraint propagation in the synthesis process. Recursion can be easily integrated into the system
in the same manner as Myth by treating the set of input-output examples for a function as a
partial function and using that function value as a binding for the function-being-synthesized.
This requires that the example set is trace complete so that any call to the function has a known
value [19] and is how the Scythe system discussed in section 4 implements recursion.

Constraint-Based Type-Directed Program Synthesis
7
Γ ⊢τ ▷W ⇒e
refine-guess
C; Γ ⊢τ ⇒e;C′
Sje ≡β χj
j
consistent(C′)
Γ ⊢τ ▷{Sj 7→χj
j} ⇒e
refine-lam
freshx
x:τ1, Γ ⊢τ2 ▷{[vj/x]Sj 7→χj
j} ⇒e
Γ ⊢τ1 →τ2 ▷{Sj 7→vj ⇒χj
j} ⇒λx.e
refine-data
K:∀ai
i.τk
k →T ai
i ∈Γ
θ = [τi/ai
i]
Wk = {Sj 7→χ j
k
j
}
k
Γ ⊢θτk ▷Wk ⇒ek
k
Γ ⊢T τi
i ▷{Sj 7→K χ j
k
k j
} ⇒K ek
k
refine-case
C; Γ ⊢T τi
i ⇒e;C′
Kj:∀ai
i.τ j
k
k
→T ai
i ∈Γ
j
Γ ⊢e;τi
i;Kj;τ ▷W ⇒mj
j
Γ ⊢τ ▷W ⇒case e of mj
j
Γ ⊢e;τi
i;K;τ ▷W ⇒m
refine-match
K:∀ai
i.τk
k →T ai
i ∈Γ
W K
e = {Sj 7→χj}
j
θ = [τi/ai]
i
Sje −→∗K vj
k
k j
freshxk
k
xk:θτk
k, Γ ⊢τ ▷{[vj
k/xk]
k
Sj 7→χj
j
} ⇒e′
Γ ⊢e;τi
i;K;τ ▷W ⇒K xk
k →e′
Γ ⊢σ ▷W ⇒e
refine-poly
Γ ⊢τ ▷{Sj 7→χj
j} ⇒e
Γ ⊢∀ai
i.τ ▷{Sj 7→∀ck:ak
k. χj
j
} ⇒e
C; Γ ⊢τ ⇒e;C′
gen-var
freshαi
i
x:∀ai
i.C′ ⇒τ ′ ∈Γ
θ = [αi/ai]
i
C′′ = C ∪θC′ ∪{τ ∼θτ ′}
consistent(C′′)
C; Γ ⊢τ ⇒x;C′′
gen-app
freshα
C; Γ ⊢α →τ ⇒e1;C1
C1; Γ ⊢α ⇒e2;C2
C; Γ ⊢τ ⇒e1 e2;C2
gen-unify
C ⊨τ1 ∼τ2
C; Γ ⊢τ2 ⇒e;C′
C; Γ ⊢τ1 ⇒e;C′
Fig. 4. Type-and-example program synthesis rules.
2.3
Refinement
The non-polymorphic refinement rules are largely identical to those found in Myth. The function
of each rule is to describe how to decompose a set of example worlds according to the goal type’s

8
Peter-Michael Osera
e ≡β v iff e −→∗v
λx:τ.e ≡β v ⇒χ iff (λx:τ.e) v ≡β χ.
W |K
e = {S →χ ∈W | Se −→∗K v1 · · · vk}
unify(C) = θ
(standard unification algorithm)
C ⊨C′ iff ∀τ ∼τ ′ ∈C′.θτ = θτ ′whereunify(C) = θ.
consistent(C) iff ∃θ. unify(C) = θ
Fig. 5. Auxiliary definitions for the synthesis system.
example form. For lambdas (refine-lam), we decompose a collection of worlds containing input-
output examples by assigning the lambda’s binder x the input and synthesizing the body of the
lambda with the output as the goal. For constructors (refine-data), if all the examples share the
same head K, then we can safely synthesize that constructor and divide up the examples’ arguments
into examples for each of that constructor’s arguments. For example, suppose that we have a
constructor K : Int →Bool →Int →T with example worlds W = w1,w2,w3:
w1 = S1 7→K 0 True 1
w2 = S2 7→K 2 False 3
w3 = S3 7→K 4 True 5
By refine-data, we will synthesize K ■1 ■2 ■3 with three synthesis sub-goals for each of K’s
arguments. Each of the sub-goals contains example worlds W1, W2, and W3 respectively:
W1 = S1 7→0,S2 7→2,S3 7→4
W2 = S1 7→True,S2 7→False,S3 7→True
W3 = S1 7→1,S2 7→3,S3 7→5
Notably with refinement, the fully specified goal type is required as input to the procedure, so there
is no need to reason about type constraints at this point in the system2.
Unlike other type-directed forms, case-expressions do not immediately imply a particular type.
Indeed the type of a case-expression is exactly the type shared by its match bodies. Nevertheless,
we can refine examples through case expressions as described by the refine-case rule:
(1) Generate a scrutinee expression e at some concrete datatype T τj.
(2) For each constructor K of T, create a match for that constructor using the example worlds
{Sj 7→χj
j} ⊆W where the scrutinee would evaluate to a value with head constructor K
(written using the filtering operator W |K
e defined in Figure 5).
When generating a scrutinee, we use the term-generation judgmentC; Γ ⊢τ ⇒e;C′ which produces
a set of type constraints C′ under which e typechecks at type τ. However, because we assume the
concrete datatype of type T τi
i up-front, we know that the type does not contain any unification
variables and thus we can ignore C′ for now. In theory this means that an implementation of the
system must explore all possible combinations of datatypes to arguments which is the exact problem
2Note that even with goal types elided, the examples make inference of the goal type trivial due to canonicity of types.
However, we may want to consider type-directed synthesis in the absence of any examples which we discuss in more detail
in section 5.

Constraint-Based Type-Directed Program Synthesis
9
we are trying to solve with constraint-based synthesis! But in practice, we heavily restrict the
kinds of expressions that appear as scrutinees already, e.g., to direct arguments of the synthesized
function, so such type search is tolerable in practice.
The helper judgment Γ ⊢e;τi
i;K;τ ▷W ⇒m is responsible for synthesizing match branches
from the scrutinee and candidate constructor. Its sole rule (refine-match) extracts and binds the
evaluated-to constructor values’ arguments in the filtered example worlds and continues synthesis
of the match’s body.
Finally, we connect refinement and term generation with the refine-guess rule which generates
a term e and then checks to see if, for each example world S 7→χ, that the closed term Se is
equivalent to the goal example χ according to the standard evaluation rules of the language (e ≡β v
whenever e −→∗v). The only non-standard case that can arise is the comparison of a lambda (a v)
to an input-output example (a χ). We thus define:
λx:τ.e ≡β v ⇒χ iff (λx:τ.e) v ≡β χ.
That is, we run the input of the input-output pair through the lambda and check to see the resulting
value is equivalent to the output of the pair.
Polymorphism in Refinement. We must consider polymorphic types at two points within refine-
ment. First, unlike the presentations of the case rule in prior work [19], constructors now have
(potentially) polymorphic types. However, because the type T τi
i is fully concrete, we can immedi-
ately instantiate the constructor’s polymorphic type (θ = [τi/ai
i]) and use that type substitution
on each of the types of the arguments of the constructor.
Secondly, top-level bindings are at type schemes σ, so we must provide examples at polymorphic
type for them. However, there is no type-directed syntactic form for polymorphic types! Further-
more, even an explicit term-level type abstraction, e.g., Λa. χ, does not provide much help! This is
because the type abstraction does not introduce values of the type variable a, and we need such
values to write down complete examples.
We therefore introduce a new top-level example value form X in Figure 3, the polymorphic
example ∀ci:ai
i. χj
j, which introduces a set of polymorphic constants ci at type variables ai. This
example form was first introduced in Osera’s thesis [17] in the context of synthesizing within
System F, and we have adapted it to this Haskell-like setting. For example, we might specify for a
goal type of ∀a. a →Maybe a →a:
∀c1:a,c2:a.c1 ⇒Nothing ⇒c1,
c1 ⇒Just c2 ⇒c2.
In these two examples, we introduce polymorphic constants c1 and c2 of type a and use them
throughout the input-output examples for the standard fromMaybe function.3
We refine polymorphic examples introduced at top-level bindings (refine-poly) by simply
stripping the top-level forall and synthesizing at the contained sub-example value. The binding
information for the polymorphic constant is only useful for typechecking the examples themselves;
they are not necessary for the synthesis process as the example values are simply carried around
as values bound to variables in an example world’s environment.
2.4
Generation
Like refinement, term generation takes as input a goal type. However, during the course of genera-
tion, we may need to instantiate types schemes when generating variables. Rather than committing
3The astute reader ought to notice that these examples are virtually the definition of fromMaybe already! We reflect on this
fact in more detail in section 4.

10
Peter-Michael Osera
■: [Bool]
■: α1 →[Bool]
■: α2 →(α1 →[Bool])
map
■: α2
■: γ1 →γ2
isEven
■: α1
■: [Int]
l
Fig. 6. Example generation derivation of map.
to a choice of a complete instantiation of a type scheme upfront (which requires us to systematically
search the space of possible types), we infer the instantiation as we generate the complete term. If
type-and-example-directed program synthesis captures the idea of “evaluating during enumera-
tion” [19], then our approach of integrating type inference into the term generation adds the idea
of “inferring during enumeration”.
To do so, we “invert” the appropriate rules from our type inference system (Figure 2) to create a
term generation system that infers types during the generation process. This judgment, written
C; Γ ⊢τ ⇒e;C′, takes a collection of constraints C, a context Γ, and type τ as input as produces a
program e and an updated constraint set C′ as output. In effect, we thread a set of type constraints
throughout the generation process which makes concrete the idea that a choice of a component in
one part of an expression might influence choices in the rest of the expression. It is worthwhile
to note that our rules are not an exact inversion of the type inference system defined in Figure 2
because the generation process is given a concrete goal type to work with as input.
While refinement handles the introduction forms of the language, generation concerns the
elimination forms, of which there are only variables and function application. With variable gener-
ation (gen-var), we speculatively choose a variable to generate and then create a new constraint
recording that the goal type must be equivalent to the type scheme of the variable instantiated with
fresh unification variables (τ ∼[αi/ai
i]τ ′). And with function application generation (gen-app), we
first speculatively generate a function under the constraint that its domain matches our eventual
argument type and the co-domain matches our goal type. We then generate function arguments
under the constraints accrued from generating the function.
While the initial goal type for generation is a concrete type, we will quickly introduce unknown
types, i.e., unification variables, through the process. We eliminate unification variables through
unification of the constraints during the generation process (gen-unify). If our goal type is some
τ1 (presumably a unification variable) and our current constraint set allows us to conclude that it is
equivalent to τ2 (C ⊨τ1 ∼τ2) then we can synthesize at this type τ instead.
As we generate constraints, we need to take care that these constraints are consistent. An
inconsistent set of constraints asserts that in-equal types are equal, e.g., Int ∼Bool. If at any point
we arrive at a set of inconsistent constraints, we know that the currently generated term is not
well-typed and should be rejected. In our formal system, this amounts to using the consistent
helper relation to check that whenever we output a constraint set from a rule that it is indeed
consistent. consistent(C) simply asserts that a unifier (i.e., type substitution) exists forC as described
in Figure 5.

Constraint-Based Type-Directed Program Synthesis
11
For example, consider generating a program of type [Bool] under the context:
Γ = map : ∀ab. (a →b) →[a] →[b],
isEven : Int →Bool,
l : [Int]
with goal type [Bool]. Figure 6 graphically shows one potential generation of a program of this
type.
Starting at the root, we first apply the gen-app rule which generates a fresh unification variable
α1 and two generation sub-goals at types α1 →[Bool] and α1. We apply gen-app again at the
first sub-goal which generates another unification variable α2 and two more sub-goals at types
α2 →(α1 →[Bool]) and α2.
At the first of these new sub-goals, we can apply gen-var and choose the map variable. This
generates the constraint
α2 →α1 →[Bool] ∼(γ1 →γ2) →[γ1] →[γ2]
for fresh unification variables γ1 and γ2. Now we can return to the sub-goal with goal type α2
and apply gen-unify to continue generating at type γ1 →γ2 since our constraint implies that
α2 ∼γ1 →γ2. This allows us to apply gen-var and choose theisEven variable, adding the constraint
γ1 →γ2 ∼Int →Bool.
Finally, we can return to the sub-goal with goal type α1, apply gen-unify to generate at type [Int]
(because α1 ∼[γ1] ∼[Int]), and the choose l via gen-var, generating a final, trivial constraint
[Int] ∼[Int].
Because we are ensuring that our generated constraint sets are consistent at every step, the order
in which we explore generation sub-goals doesn’t matter. However, the order heavily influences
how much backtracking we will need to perform because of “bad” choices of terms. For example, if
rather than synthesizing map first, we instead try to synthesize its arguments, we may make many
spurious choices if there are non-list types in the context. Thus, even though our constraint-based
synthesis system allows us to consider types in a more incremental fashion, we must still be
conscious of performance during implementation. In this particular case, it makes sense to attempt
to synthesize functions before their arguments since the function is more likely to prune the search
space of types than synthesizing one of its arguments.
3
SYNTHESIS WITH GADTS
Traditional algebraic types require that the output type of its constructors have the form T ai
i
where the ais are universally quantified type variables from the type of the constructor. Generalized
algebraic data types (GADTs) lift this restriction so that the type arguments of T may be any type,
not just type variables. While a seemingly insignificant change, GADTs strike a powerful balance
between power and complexity on the spectrum of rich type systems.
The quintessential example of GADTs-in-action is the tagless interpreter given below in Haskell:
data Exp a where
Lit
:: a -> Exp a
Plus :: Exp Int -> Exp Int -> Exp Int
Eq
:: Exp Int -> Exp Int -> Exp Bool
If
:: Exp Bool -> Exp a -> Exp a -> Exp a
eval :: Exp a -> a
eval (Lit x)
= x

12
Peter-Michael Osera
Γ
:: =
· · · | K:∀ai
i.C ⇒τk
k →T ai
i, Γ
Contexts
Fig. 7. Syntactic extensions for GADT synthesis.
eval (Plus e1 e2)
= eval e1 + eval e2
eval (Eq e1 e2)
= eval e1 == eval e2
eval (If e1 e2 e3) =
if eval e1 then eval e2 else eval e3
Here, we parameterize the type of Exp a by the type a that the expression evaluates to. This allows
us to give eval the rich type Exp a -> a which in turn allows us to write eval without any case
analyses on the values it produces.
How do GADTs complicate typechecking and consequently type-directed program synthesis?
For example, consider the Plus case of eval. If Plus was a regular algebraic datatype (say, with
type Exp -> Exp -> Exp), the body would not typecheck because (+) produces a value of numeric
type whereas the function expects a value of type a. To enable the body of Plus to typecheck, the
typechecker must deduce that because the input is a constructor that produces an Exp Int, then
a ∼Int and thus we must typecheck the body at type Int. In effect, consuming a GADT via a
pattern match introduces local type constraints into the environment that we must consider when
typechecking each branch [25].
With some minor changes, we can adapt the constraint-based framework we developed previously
to accommodate GADTs. In particular, we follow the presentation of OutsideIn [25] and represent
GADTs as standard polymorphic constructors coupled with constraints C on the type variables that
appear in the output type of the constructor. This allows us to avoid a step of unification during
type inference and synthesis to discover these constraints on our own. As an example, we can
rewrite the declaration of Exp above in this style:
data Exp a where
Lit
:: a -> Exp a
Plus :: (a ~ Int) =>
Exp Int -> Exp Int -> Exp a
Eq
:: (a ~ Bool) =>
Exp Int -> Exp Int -> Exp a
If
:: Exp Bool -> Exp a -> Exp a -> Exp a
With this style, our GADT constructor definitions obey the same restriction as regular algebraic
datatypes—the type arguments of the output type are type variables—but the addition of type
constraints allow us greater freedom as to what types the constructors produce.
Figure 8 gives the updated synthesis rules with generalized algebraic datatypes. Because GADTs
only affect datatype declarations and constructors, we only need to update the rules for refinement;
raw term generation is left untouched.
We update the refinement judgment to carry around the set of constraints C gained through case
analysis of GADT values. Unlike term generation, additional constraints gained through GADT
analysis are scoped to their matches. Because of this, we only need to thread constraints down the
refinement judgment as an input and not gather updated constraints as an output. Most rules simply
pass their constraints to their sub-refinement calls as in the case of lambdas (refine-gadt-lam)
or to raw term generation (refine-gadt-guess). At the top-level, we begin refinement with the
empty set of constraints (refine-gadt-binding).
Now when generating a case expression (refine-gadt-case), we also extract the constraints
associated with each constructor Ci and add it to the constraint set associated with synthesizing

Constraint-Based Type-Directed Program Synthesis
13
C; Γ ⊢τ ▷W ⇒e
refine-gadt-lam
freshx
C;x:τ1, Γ ⊢τ2 ▷{[vj/x]Sj 7→χj
j} ⇒e
C; Γ ⊢τ1 →τ2 ▷{Sj 7→vj ⇒χj
j} ⇒λx.e
refine-gadt-data
K:∀ai
i.C′ ⇒τk
k →T ai
i ∈Γ
θ = [τi/ai
i]
C ⊨θC′
Wk = {Sj 7→χ j
k
j
}
k
C; Γ ⊢θτk ▷Wk ⇒ek
k
C; Γ ⊢T τi
i ▷{Sj 7→K χ j
k
k j
} ⇒K ek
k
refine-gadt-case
C; Γ ⊢T τi
i ⇒e;C′
Kj:∀ai
i.Cj ⇒τ j
k
k
→T ai
i ∈Γ
j
C; Γ ⊢e;τi
i;Kj;τ ▷W ⇒mj
j
C; Γ ⊢τ ▷W ⇒case e of mj
j
refine-gadt-guess
C; Γ ⊢τ ⇒e;C′
Sje ≡β χj
j
consistent(C′)
C; Γ ⊢τ ▷{Sj 7→χj
j} ⇒e
refine-gadt-unify
C ⊨a ∼τ
C; Γ ⊢τ ▷W ⇒e
C; Γ ⊢a ▷W ⇒e
C; Γ ⊢e;τi
i;K;τ ▷W ⇒m
refine-gadt-match
K:∀ai
i.C′ ⇒τk
k →T ai
i ∈Γ
W |K
e = {Sj 7→χj}
j
θ = [τi/ai]
i
Sje −→∗K vj
k
k j
freshxk
k
C ∪θC′;xk:θτk
k, Γ ⊢τ ▷{[vj
k/xk]
k
Sj 7→χj
j
} ⇒e′
C; Γ ⊢e;τi
i;K;τ ▷W ⇒K xk
k →e′
Γ ⊢σ ▷X ⇒b
refine-gadt-binding
fresh x
ftvs(τ) ⊆ai
i
·;ck:ak
k, Γ ⊢τ ▷{· 7→χj
j} ⇒e
Γ ⊢∀ai
i.τ ▷∀ck:ak
k. χj
j ⇒x = e
Fig. 8. Extensions to synthesis system for GADTs.
that constructor’s match body. Notably, we instantiate the additional constraints Ci with the type
environment θ generated by unifying the type of the scrutinee with the output type of the con-
structors, written θCi. Constraints are utilized during refinement when synthesizing constructors
(refine-gadt-data). We ensure that we only synthesize a constructor if the current set of con-
straints C implies all of the (instantiated) constraints bundled with the constructor’s type. Note
that this stands in contrast to inconsistencies detected during case generation. If the constraints
of a constructor are inconsistent with the current set of constraints when synthesizing a match
alternative then the alternative is unreachable and can be elided as an optimization.
Finally, like with term generation, we need to use the constraints in refinement to refine the
goal type when appropriate. The unification rule for refinement (refine-gadt-unify) operates

14
Peter-Michael Osera
identically to its generation counterpart but at type variables: at a type variable a, we can use a’s
assigned type as recorded by C instead.
As an example of the system in action, consider how constraints are generated and utilized while
synthesizing part of the eval function introduced at the beginning of this section. After an initial
application of refine-gadt-binding and refine-gadt-lam, we arrive at the following refinement
state:
eval e = ■:: a ▷W
Γ = eval : ∀a. Exp a →a,e : Exp a
C = · .
At this point, we can apply the refine-gadt-case rule to synthesize a case analysis on e. Let’s just
focus on the Plus constructor which has type:
∀b. (b ∼Int) ⇒Exp Int →Exp Int →Exp b.
(We α-rename the constructor’s bound type variable to b in order to distinguish it from the type
variable from the overall type of the function a). Unifying the return type of Plus with e yields the
type substitution θ = [a/b] which then yields the final constraint a ∼Int which is added to the set
of constraints when synthesizing the body of Plus’s match at goal type a. This constraint is then
passed to term generation which is then used by gen-unify to change the type of the goal from a
to Int which then justifies synthesizing an application of the (+) function. When we go to generate
recursive function calls to eval, the constraint is also utilized when instantiating the polymorphic
type of eval to Exp a →a with a ∼Int.
3.1
Metatheory
There are two properties that we ought to consider of the synthesis system we have developed so
far:
• Soundness states that synthesized programs are consistent with their specification.
• Completeness states that we are able to synthesize all programs that meet a particular
specification.
Here, we briefly discuss these two properties. A summary of the complete system as well as detailed
proofs can be found in Appendix A.
Soundness. The kinds of specification we consider in this system are types and examples. Thus,
we can consider soundness with respect to each:4
Lemma 3.1 (Type Soundness). If C; Γ ⊢τ ▷W ⇒e then C; Γ ⊢e : τ.
Proof Sketch. By induction on the synthesis derivation. Intuitively, we synthesize terms in a type-
directed manner (the synthesis rules are derived directly from the typing rules of the system), so
we expect these terms to be well-typed.
□
Lemma 3.2 (Example Soundness). If C; Γ ⊢τ ▷W ⇒e then for all S 7→χ ∈W , Se ≡β χ.
Proof Sketch. By induction on the synthesis derivation. During refinement, we decompose examples
in such a way that example satisfaction of sub-components results in example satisfaction of the
whole program. During term generation, the refine-gadt-guess rule ensures example satisfaction
directly for generated terms.
□
4Note that, for brevity’s sake, we only state the relevant properties for expression refinement. Similar statements must be
made for each of the remaining judgments of the system—match synthesis and term generation.

Constraint-Based Type-Directed Program Synthesis
15
Completeness. This property states that our synthesis system is capable of generating all possible
programs given a fixed goal type and set of examples.
Lemma 3.3 (Completeness). If C; Γ ⊢e : τ and Γ ⊢W : τ then C; Γ ⊢τ ▷W ⇒e.
However, our system does not obey this property in the name of efficiency! For example, note
that gen-app does not allow for the generation of case expressions in the position of arguments.
But such cases are not terribly interesting with respect to completeness; a case nested in an
argument position of an application could instead be “bubbled up” to encase the entire application
(at the cost of code redundancy). Are there more interesting programs that the system is incapable
of synthesizing? We leave this exploration to future work.
4
INTEGRATING CONSTRAINT-BASED SYNTHESIS IN SCYTHE
We have implemented constraint-based synthesis for polymorphic types as described in section 2
in an in-development program synthesis tool called Scythe. Scythe supports live, type-directed
development for the Haskell programming language by extending prior work on GHC for typed
holes [7]. The typed holes facility of GHC allows users to annotate their program with holes. During
typechecking, GHC will report the inferred type of each hole and suggest possible variables from
the context to fill these holes. The search process currently in GHC is fairly naïve, only suggesting
individual components whose type matches the goal. Scythe provides a far more in-depth search
of the space of possible programs using the program synthesis techniques described in this work.
To do this, Scythe leverages the unmodified GHC API to interact with existing Haskell code
with a high degree of compatibility. It uses GHC to load external libraries and parse, typecheck,
interpret, and manipulate Haskell code. On the surface, this seems difficult to do since the type-
and-example-directed program synthesis process interweaves a number of compilation processes,
in particular, typechecking and partial evaluation. However with some engineering techniques
and compromises, we can adopt off-the-shelf compiler APIs to provide this rich kind of editing
experience, similar to the efforts of Merlin for OCaml [2].
As an example of the system in operation, here is the declaration of the fromMaybe example
from subsection 2.3 as realized in the prototype version of Scythe:
--
-- | {@
--
fromMaybe :: a -> Maybe a -> a
--
fromMaybe a1 Nothing
= a1
--
fromMaybe a1 (Just a2) = a2
--
@@
--
ctx=(Just, Nothing)
--
@}
fromMaybe :: a -> Maybe a -> a
fromMaybe s1 m1 = _
Scythe looks for special {@...@} sections in Haddock comments which denote Scythe example
blocks. These example blocks contain type-and-example information as well as options to control
the synthesizer such as the ctx option that allows the user to specify the components to consider
during synthesis. Note that like Haskell, Scythe infers the universal quantifier for polymorphic
example values; all variables of the form ak where a is a type variable introduced by the function
signature and k is a natural number are considered to be polymorphic constants of type a.
After finding the hole, Scythe offers the following single suggestion to complete it:

16
Peter-Michael Osera
> (ok) case m1 of
>
Nothing -> s1
>
Just a1 -> a1
4.1
Experience with Polymorphic Synthesis
To date, we have performed a preliminary investigation of how type-and-example-driven polymor-
phic synthesis performs within Scythe over small toy functions. We reflect on our experiences and
lessons learned so far from this investigation that are motivating our future work in this area.
Difficulties with Examples. Polymorphic example values give us great flexibility in how we specify
goals of polymorphic type. However, as discussed in subsection 2.3, a collection of polymorphic
example values can quickly become the actual function definition itself! This demonstrates the
power of combining polymorphism with example-based reasoning, but it makes the story for a
tool like Scythe less compelling at first glance.
This is certainly true when we are forced to give many examples in order to appease the
synthesizer. Early synthesizers such as Myth had the problematic requirement of trace completeness
that enough examples are provided so that the synthesizer can carry out execution of any recursive
function call made during the synthesis process without having the entire function formed.
However, Scythe lifts this restriction by not immediately rejecting candidate programs that fail
due to a lack of examples. A detailed discussion of this feature is beyond the scope of this paper,
but the importance of this fact is that Scythe can produce meaningful output with little-to-no
examples! As a result, polymorphic example values become much more appealing to use. For
example, Figure 9 shows how the system only requires a single example to synthesize the stutter
and append functions over lists. Note how the examples (1) in contrast to fromMaybe, don’t so
obviously imply the implementation of the function and (2) resemble the examples that you might
naturally write in documentation.
The Power of Free Theorems. The guarantees of polymorphic types are well-known [26] and
are one of the primary motivations for our work in automating type-directed programming with
synthesis techniques. Parametricity tells us that the very shape of a polymorphic type determines
very precisely the set of programs that inhabit that type. We witness this in Scythe when we
provide no examples to the system and rely on raw-term enumeration.5 For example, here is the
output from Scythe when no examples are given for fromMaybe:
> (?) case m1 of
>
Nothing -> s1
>
Just a1 -> a1
> (?) case m1 of
>
Nothing -> s1
>
Just a1 -> s1
> (?) s1
The question marks in the output denote that while each reported program has the right type,
they have not been found to be consistent with any examples (since we have not provided any!).
However, there are so few programs to report due to polymorphism, the user can simply review
each implementation to see if it matches the behavior they want for the function. This stands in
5By default Scythe limits the depth of nested function application and cases to avoid exponential blow-up in the search
space.

Constraint-Based Type-Directed Program Synthesis
17
-- | {@
--
stutter :: [a] -> [a]
--
stutter [a1, a2] = [a1, a1, a2, a2]
--
@@
--
recArg=0
--
@}
stutter :: [a] -> [a]
stutter l = _
> (ok) case l1 of
>
[] -> l1
>
(:) a1 l2 -> (:) a1 ((:) a1 (stutter l2))
-- | {@
--
append :: [a] -> [a] -> [a]
--
append [a1, a2] [a3, a4, a5] =
--
[a1, a2, a3, a4, a5]
--
@@
--
recArg=0
--
@}
append :: [a] -> [a] -> [a]
append l1 l2 = _
> (ok) case l1 of
>
[] -> l2
>
(:) a1 l3 -> (:) a1 (append l3 l2)
Fig. 9. Example Scythe runs for stutter and append
contrast to the shallower search that GHC’s hole-filling mechanism conducts which only suggests
s1 as a valid completion.6
It might be the case that some polymorphic function of interest is too complicated to be specified
with examples. This example shows that synthesis techniques like those used by Scythe still have
the potential to provide meaningful feedback, even when only types drive the synthesis process.
5
FURTHER EXTENSIONS
A constraint-based approach to program synthesis opens the doors to a number of additional
features that can greatly expand the scope and power of the system. We briefly reflect on them,
suggesting next steps forward based on the techniques developed in this paper.
Existential Types. One glaring omission from the system described in Figure 4 is the lack of
existential types. In Haskell, existential types are encoded as universal types in constructors that
are not mentioned in the output type of the constructor. The classic example of this are a type used
to box elements of a heterogeneous list:
data Obj where Obj :: Show a => a -> Obj
From this, we can create our heterogeneous list from a regular list of Obj, e.g.,
[Obj 1, Obj "hi", Obj True]. With this set up, we have no way of extracting the values from
6As of GHC version 8.6.4.

18
Peter-Michael Osera
their Obj wrappers—the Obj effectively seals the type variable a from the outside world—but the
typeclass constraint allows us to traverse and show the values.
When working with GADT types as in refine-gadt-case and refine-gadt-data, we must
take care to identify which of the type variables are truly universal (that appear in the output type
of the constructor) versus those that are existential (that do not appear in the output type of the
constructor). For example, if we were pattern matching on a value with type Obj, its sole match
would contain a binder for the existentially bound variable a. However, we must ensure that we do
not unify that variable with a concrete type as its type is really sealed! This can be accomplished
by calculating via a free variable check which type variables are universal or existential and then
skolemizing the existential variables so that they cannot participate in the unification process.
On top of this, we must also decide how to deal with examples at existential type. Can we get
away with representing existential types with polymorphic constants and relying on skolemization
to assign those constants appropriate types during synthesis or do we need a new example form
for existential values?
Typeclass Constraints. GADTs are only one way that type constraints are introduced in a Haskell
program. More common are typeclass constraints, for example, the standard association list lookup
function of type
lookup :: Eq a => a -> [(a, b)] -> Maybe b
constrains its first argument of type a to be an instance of the eq typeclass which in turns provides
the method (==) to compare as with. Typeclasses are ubiquitous in Haskell code, especially in
highly polymorphic code that mixes typeclass constraints with multiparamteter typeclasses and
functional dependencies [10].
While seemingly unrelated at first glance, Vytiniotis et al. demonstrate how the problems of
typeclass constraints and GADTs inference can be solved through their constraint-based type infer-
ence system, OutsideIn(X) and implication constraints [25]. In order to add typeclass constraints
to our synthesis system, we will likely need to adapt more of their constraint representation and
solving techniques.
Partial Type Information. One of the goals of this paper is taking the first steps towards under-
standing how to marry together constraint-based type inference techniques with program synthesis.
However, oddly enough, even though we’ve adopted a constraint-based approach to synthesis in
this work, we still have made the problems of type inference and program synthesis rather separate!
In particular, because we require that the top-level binding of our synthesis problem possesses a
fully annotated type, we only need to perform type inference in a very limited setting—instantiating
polymorphic types during term generation—which greatly simplified our approach.
A more ambitious marriage of constraint-based type inference and program synthesis would
not only leverage constraint-based reasoning techniques in synthesis but truly intertwine type
inference and program synthesis. This would involve removing restrictions of having concrete
types everywhere in the system (e.g., the scrutinee of refine-case) and reasoning more about how
to incrementally refine goal types in tandem with program discovery. Such a change would likely
impact performance of the synthesizer significantly but give greater flexibility to the user in terms
of specifying a program of interest when the types become complicated.
6
RELATED WORK
Program Synthesis with Types. Program synthesis, the automatic generation of programs from
specification, is an enormous field encompassing the programming languages, formal verification,
software engineering, and most recently the machine learning communities [8]. Many approaches

Constraint-Based Type-Directed Program Synthesis
19
are used to tackle this problem in a variety of contexts from general-purpose programming to highly-
specific domains. Utilizing types as a guiding principle for synthesis is a small, yet important, piece
of the puzzle, especially as it pertains to richly-typed functional programming languages and type-
directed programming. These approaches span the simply-typed, general-purpose domain [1, 19],
components [4, 5, 9, 12], and more richly-typed domains [6, 22]. Many of these prior efforts handle
polymorphism but in an ad hoc manner or using an “enumerate all possible types” approach. The
approach that we present in the paper is the first, to our knowledge, to attempt an “infer while
enumerate” approach to type instantiation.
Type Inference and GADTs. Our adaption of type inference is heavily rooted in the constraint-
based approached proposed by Odersky et al. with their HM(X) framework [14] as well as the
presentation of constraint-based typing found in TAPL [20].
GADT type inference, while an undecidable problem [24], has enjoyed continuous refinement in
order to develop inference algorithms that are tractable but also produce useful results [3, 10, 11, 13,
23–25]. While our system does not perform GADT type inference directly, its approach to GADT
type checking and constraint passing is inspired by Vytiniotis’s OutsideIn(X) framework [25].
Live Programming. Our exploration of constraint-based, type-directed program synthesis lives
in the context of live programming support for type-directed programming. This exploration
has begun to take shape in the PL community in several forms. First is the support for language
servers which provide efficient compilation services to live programming tools [2]. The second is
support for hole-based development that was exclusively found in dependently-typed programming
languages such as Coq, Agda, and Idris, but are now found in languages like Haskell [7]. The third
is theoretical explorations of hole-based, interactive development [15, 16].
ACKNOWLEDGMENTS
We thank the TyDe 2019 reviewers for their valuable feedback in improving this manuscript and
the students of the Grinnell Pioneer PL research group that have worked on Scythe in its various
forms over the last few years: Bogdan Abaev, List Berkowitz, Kevin Connors, Shelby Frazier, Reily
Grant, Andrew Mack, Griffin Mareske, Ankit Pandey, Dhruv Phumbhra, Jonathan Sadun, Zachary
Segall, and Zachary Susag.
This material is based upon work supported by the National Science Foundation under Grant
No. 1651817. Any opinions, findings, and conclusions or recommendations expressed in this material
are those of the author and do not necessarily reflect the views of the National Science Foundation.
REFERENCES
[1] Lennart Augustsson. 2004. [Haskell] Announcing Djinn, Version 2004-12-11, a Coding Wizard.
[2] Frédéric Bour, Thomas Refis, and Gabriel Scherer. 2018. Merlin: A Language Server for OCaml (Experience Report).
Proceedings of the ACM on Programming Languages 2, ICFP (July 2018), 103:1–103:15. https://doi.org/10.1145/3236798
[3] Sheng Chen and Martin Erwig. 2016. Principal Type Inference for GADTs. In Proceedings of the 43rd Annual ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages (POPL 2016). ACM Press, St. Petersburg, FL,
USA, 416–428. https://doi.org/10.1145/2837614.2837665
[4] Yu Feng, Ruben Martins, Yuepeng Wang, Isil Dillig, and Thomas W. Reps. 2017. Component-Based Synthesis for
Complex APIs. In Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages (POPL
2017). ACM Press, Paris, France, 599–612. https://doi.org/10.1145/3009837.3009851
[5] John K. Feser, Swarat Chaudhuri, and Isil Dillig. 2015. Synthesizing Data Structure Transformations from Input-Output
Examples. In Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation
(PLDI 2015). ACM Press, Portland, OR, USA, 229–239. https://doi.org/10.1145/2737924.2737977
[6] Jonathan Frankle, Peter-Michael Osera, David Walker, and Steve Zdancewic. 2016. Example-Directed Synthesis: A
Type-Theoretic Interpretation. In Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of
Programming Languages (POPL 2016). ACM, St. Petersburg, FL, USA. https://doi.org/10.1145/2914770.2837629

20
Peter-Michael Osera
[7] Matthías Páll Gissurarson. 2018. Suggesting Valid Hole Fits for Typed-Holes (Experience Report). In Proceedings of
the 11th ACM SIGPLAN International Symposium on Haskell (Haskell 2018). ACM Press, St. Louis, MO, USA, 179–185.
https://doi.org/10.1145/3242744.3242760
[8] Sumit Gulwani, Oleksandr Polozov, and Rishabh Singh. 2017. Program Synthesis. Foundations and Trends in Program-
ming Languages 4, 1-2 (2017), 1–119. https://doi.org/10.1561/2500000010
[9] Tihomir Gvero, Viktor Kuncak, Ivan Kuraj, and Ruzica Piskac. 2013. Complete Completion Using Types and Weights.
In Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI 2013),
Vol. 48. ACM Press, New York, NY, USA, 27–38. https://doi.org/10.1145/2499370.2462192
[10] Mark P. Jones. 1995. Functional Programming with Overloading and Higher-Order Polymorphism. In Advanced
Functional Programming, First International Spring School on Advanced Functional Programming Techniques-Tutorial
Text. Springer-Verlag, Berlin, Heidelberg, 97–136.
[11] Georgios Karachalias, Tom Schrijvers, Dimitrios Vytiniotis, and Simon Peyton Jones. 2015. GADTs Meet Their
Match: Pattern-Matching Warnings That Account for GADTs, Guards, and Laziness. In Proceedings of the 20th ACM
SIGPLAN International Conference on Functional Programming (ICFP 2015). ACM Press, Vancouver, BC, Canada, 424–436.
https://doi.org/10.1145/2784731.2784748
[12] Susumu Katayama. 2012. An Analytical Inductive Functional Programming System That Avoids Unintended Programs.
In Proceedings of the ACM SIGPLAN 2012 Workshop on Partial Evaluation and Program Manipulation (PEPM 2012). ACM
Press, Philadelphia, Pennsylvania, USA, 43. https://doi.org/10.1145/2103746.2103758
[13] Gabriela Moreira, Cristiano Vasconcellos, and Rodrigo Ribeiro. 2018. Type Inference for GADTs, Outsidein and
Anti-Unification. In Proceedings of the XXII Brazilian Symposium on Programming Languages (SBLP 2018). ACM Press,
Sao Carlos, Brazil, 51–58. https://doi.org/10.1145/3264637.3264644
[14] Martin Odersky, Martin Sulzmann, and Martin Wehr. 1999. Type Inference with Constrained Types. Theory and Practice
of Object Systems 5, 1 (Jan. 1999), 35–55. https://doi.org/10.1002/(SICI)1096-9942(199901/03)5:1<35::AID-TAPO4>3.0.
CO;2-4
[15] Cyrus Omar, Ian Voysey, Ravi Chugh, and Matthew A. Hammer. 2019. Live Functional Programming with Typed
Holes. Proceedings of the ACM on Programming Languages 3, POPL (Jan. 2019), 1–32. https://doi.org/10.1145/3290327
[16] Cyrus Omar, Ian Voysey, Michael Hilton, Jonathan Aldrich, and Matthew A. Hammer. 2017. Hazelnut: A Bidirectionally
Typed Structure Editor Calculus. In Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming
Languages (POPL 2017). ACM Press, Paris, France, 86–99. https://doi.org/10.1145/3009837.3009900
[17] Peter-Michael Osera. 2015. Program Synthesis with Types. PhD Thesis. University of Pennsylvania, Philadelphia, PA.
[18] Peter-Michael Osera. 2019. Constraint-Based Type-Directed Program Synthesis. In The 4th Workshop on Type-Driven
Development (TyDe 2019). ACM Press, Berlin, Germany.
[19] Peter-Michael Osera and Steve Zdancewic. 2015. Type-and-Example-Directed Program Synthesis. In Proceedings of
the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI 2015). ACM Press,
Portland, OR, USA, 619–630. https://doi.org/10.1145/2737924.2738007
[20] Benjamin C. Pierce. 2002. Types and Programming Languages. MIT Press, Cambridge, MA.
[21] Benjamin C. Pierce and David N. Turner. 2000. Local Type Inference. ACM Transactions on Programming Languages
and Systems 22, 1 (Jan. 2000), 1–44. https://doi.org/10.1145/345099.345100
[22] Nadia Polikarpova, Ivan Kuraj, and Armando Solar-Lezama. 2016. Program Synthesis from Polymorphic Refinement
Types. In Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design and Implementation
(PLDI 2016). ACM Press, Santa Barbara, CA, USA, 522–538. https://doi.org/10.1145/2908080.2908093
[23] Tom Schrijvers, Simon Peyton Jones, Martin Sulzmann, and Dimitrios Vytiniotis. 2009. Complete and Decidable Type
Inference for GADTs. In Proceedings of the 14th ACM SIGPLAN International Conference on Functional Programming
(ICFP 2009). ACM Press, Edinburgh, Scotland, 341. https://doi.org/10.1145/1596550.1596599
[24] Vincent Simonet and François Pottier. 2007. A Constraint-Based Approach to Guarded Algebraic Data Types. ACM
Transactions on Programming Languages and Systems 29, 1 (Jan. 2007), 1–es. https://doi.org/10.1145/1180475.1180476
[25] Dimitrios Vytiniotis, Simon Peyton Jones, Tom Schrijvers, and Martin Sulzmann. 2011. OutsideIn(X) Modular Type
Inference with Local Assumptions. Journal of Functional Programming 21, 4-5 (Sept. 2011), 333–412. https://doi.org/
10.1017/S0956796811000098
[26] Philip Wadler. 1989. Theorems for Free!. In Proceedings of the Fourth International Conference on Functional Programming
Languages and Computer Architecture (FPCA 1989). ACM Press, Imperial College, London, United Kingdom, 347–359.
https://doi.org/10.1145/99370.99404

Constraint-Based Type-Directed Program Synthesis
21
A
THE FORMALISM
A.1
The System
We give the complete syntax (Figure 10) and semantics (both typechecking, Figure 12, and synthesis,
Figure 13) of the constraint-based synthesis system presented in this work. Auxiliary definitions
that support these systems are found in Figure 11. This is the final version of the system as presented
in section 3 which includes generalized algebraic datatypes.
A.2
Metatheory
As mentioned in section 3, there are two main properties we might want to consider of our synthesis
system:
• Soundness states that synthesized programs are consistent with their specification.
• Completeness states that we are able to synthesize all programs that meet a particular
specification.
A.2.1
Soundness. We prove that the system is sound with respect to the two kinds of specification
under consideration: types (Theorem A.4 and Theorem A.5) and examples (Theorem A.7).
First we introduce a number of auxiliary lemmas about constraints and generation necessary to
prove generation type soundness.
Lemma A.1 (Constraint Monotonicity During Generation). If C; Γ ⊢τ ⇒e;C′ then C ⊆C′.
Proof. By a straightforward induction on the generation derivation for e. Note that all of the
generation rules only add to the input constraint set and never remove any constraints.
□
Lemma A.2 (Constraint Weakening During Solving). If C ⊨τ ∼τ ′, C ⊆C′, consistent(C),
and consistent(C′), then C′ ⊨τ ∼τ ′.
Proof. Suppose that C′ did not entail the desired equality. Because C ⊆C′, then C′ must have
some additional constraint that C does not have that refutes the equality. However, this additional
constraint would render C′ inconsistent, a contradiction.
□
Lemma A.3 (Constraint Weakening During Typing). If C; Γ ⊢e : τ, C ⊆C′, consistent(C),
and consistent(C′), then C′; Γ ⊢e : τ.
Proof. By a straightforward induction on the generation derivation for e. In particular, typing
depends entirely on constraints only for solving (C ⊨C′), and the constraint weakening during
solving lemma tells us that this is safe to do so under a weakened (extended) constraint set.
□
With these lemmas in hand, we can prove generation type soundness.
Theorem A.4 (Generation Type Soundness). If C; Γ ⊢τ ⇒e;C′ then C′; Γ ⊢e : τ.
Proof. By induction on the generation derivation of e. Term generation is derived from typing,
so we expect the assumptions gained by analysis of the term generation rules to coincide with the
proof obligations from the typing rules. What remains is ensuring that we manage our constraint
sets so that they contain the necessary constraints to type our generated terms appropriately.
• gen-var: By assumption, we know that τ generates x, x:∀ai
i.C′ ⇒τ ′ ∈Γ, and C′′ =
C ∪θC′ ∪{τ ∼θτ ′} is consistent. We must show that C′′; Γ ⊢x : τ. By type-unify, it suffices
to show that C′′ ⊨{τ ∼[αi/ai]
iτ ′} and C′′; Γ ⊢x : [αi/ai]
iτ ′. We know that the former
holds by assumption. The latter holds by type-var as long as C′′ ⊨[αi/ai]
i which is true
since C′′ is consistent and [αi/ai]
i is one of its constraints.

22
Peter-Michael Osera
• gen-app: By assumption, we know that we generate e1 at type α →τ and e2 at type α. By
our induction hypotheses, we know that e1 has type α1 under constraints C1 and e2 has type
α2 under constraints C2. By constraint monotonicity, we know that C ⊆C1 ⊆C2. And by
constraint weakening, since we know that C1 and C2 are consistent, e1 also has type α1 under
constraints C2. Finally, we can conclude by type-app that C2; Γ ⊢e1 e2 : τ.
• gen-unify: By assumption, we know that τ2 generates e under constraints C′, C ⊨τ1 ∼τ2,
and consistent(C′). By type-unify, it suffices to show that C′; Γ ⊢e;τ2 and C′ ⊨τ1 ∼τ2. The
former is true directly from our induction hypothesis. The latter is true because constraint
monotonicity tells us that C ⊆C′ and constraint weakening says that since C ⊨τ1 ∼τ2,
C′ ⊨τ1 ∼τ2 as well.
□
We can then tackle type soundness of the refinement portions of the system.
Theorem A.5 (Refinement Type Soundness).
(1) If C; Γ ⊢τ ▷W ⇒e then C; Γ ⊢e : τ.
(2) If K:∀ai
i.C′ ⇒τk
k →T;ai
i ∈Γ and C; Γ ⊢e;τi
i;K;τ ▷W ⇒m then C; Γ ⊢τi
i;m : τ.
Proof. By mutual induction on the two synthesis derivations. Like generation, refinement is
derived from typing, so we expect the assumptions gained by the refinement rules to coincide with
the proof obligations from the typing rules.
• refine-gadt-lam: By assumption, we refine e at type τ2 and by our induction hypothesis, e
is well-typed at τ2. Thus by type-lam, λx.e is well-typed at τ1 →τ2.
• refine-gadt-data: By assumption, we refine each of the k arguments of K, ek
k, at their
respective types τk
k. By our induction hypotheses, each ek
k is well-typed at τk
k. Thus, by
type-data, K ek
k is well-typed at T τi
i.
• refine-gadt-case: By assumption, we know that T τi
i generates e under constraints C′ and
for each of the j constructors Kj of T, we refine an appropriate match mj at type τ. By our
induction hypotheses, we know that the body of each mj has type τ, and by type-case we
can conclude that the entire case expression has type τ.
• refine-gadt-guess: By assumption, we know that C; Γ ⊢τ ⇒e;C′ and by refinement type
soundness for generation, we know that e has type τ under assumptions C′. By constraint
monotonicity, C ⊆C′. By inspecting our generation rules, we note that the only additional
constraints in C′ are added in gen-var. There are two kinds of constraints added:
(1) θC, the constraint that our overall constraint set satisfies the constraints introduced by
the variable. e must satisfy this constraint—otherwise we would have encountered an
inconsistent constraint set during generation and rejected e—and so we can safely remove
this constraint from C′.
(2) τ ∼θτ ′, the constraint that our goal type is equivalent to some instantiation of the variable’s
polymorphic type. e’s type by definition does not contain any unification constraints—these
are only created during term generation—and so these constraints do not can also be safely
removed.
Since both kinds of constraints can be safely removed from C′, we can conclude that e is also
well-typed under C.
• refine-gadt-unify: By assumption, we refine e at type τ and C ∪{τ ∼α} so by type-unify,
we can conclude that e is well-typed at type a.
• refine-gadt-match: By assumption, we know that τ generates the match K xk
k →e′ under
constraints C ∪θC′ and context xk:θτk
k, Γ. By our inductive hypothesis, the branch body e′
has type τ and by type-match, the overall match has type τ as well.

Constraint-Based Type-Directed Program Synthesis
23
□
And finally we can use Theorem A.4 and Theorem A.5 to prove the soundness of our top-level
synthesis judgment for bindings.
Theorem A.6 (Top-level Binding Type Soundness). If Γ ⊢σ ▷X ⇒b then Γ ⊢b : σ.
Proof. By induction on the refinement derivation of b. There is only one case, refine-gadt-
binding. By assumption, we know that we refine σ ▷W to x = e under the context Γ extended
with bindings for the polymorphic constants introduced in W and ftvs(τ) ⊆ai
i. By refinement
type soundness, we know that e is well-typed at some type τ and thus by type-binding, we know
that the overall binding has the desired polymorphic type.
□
Examples are only used during refinement, so we need only consider soundness of the refinement
portion of the system.
Theorem A.7 (Example Soundness). If Γ ⊢W : τ and ·; Γ ⊢τ ▷W ⇒e then for all S 7→χ ∈W ,
Se ≡β χ.
Proof. By induction on the refinement derivation of e. At a high level, we know refinement is
sound because example refinement coincides with a single step of evaluation based on the shape of
the expression being refined.
• refine-gadt-lam: By assumption we know λx.e refines at τ1 →τ2 ▷{Sj 7→vj ⇒χj}
j,
{Sj 7→vj ⇒χj}
j is well-typed at e, and e refines at τ2 ▷{[vj/x]Sj 7→χj}
j. By type-ex-io, we
know that v has type τ1 and χ has type τ2 and thus, we can apply our induction hypothesis
to conclude that e satisfies {[vj/x]Sj 7→χj}
j. We must show that ∀j. Sj(λx.e) ≡β vj ⇒χj;
consider a single such example world S 7→v ⇒χ. By definition S(λx.e) ≡β vj ⇒χj if
S(λx.e)vj →([vj/x]S)e ≡β χj. But we know this because e satisfies [v/x]S 7→χ from our
induction hypothesis.
• refine-gadt-data: By assumption we know K ek
k refines at T τi
i ▷{Sj 7→K χ j
k
k
}
j
, each
ek refines at θτk ▷{Sj 7→χ j
k
j
}, and the example worlds are well-typed at type T τi
i. By
type-var and an application of type-app for each of the k arguments of K, we know that
each χ j
k has type θτk. We must show that ∀j. Sj(K ek
k) ≡β K χk
k; consider one such example
world S 7→K χk
k. We know that Sj(K ek
k) = K Sjek
k so it suffices to show that ek
k ≡β χk.
However, we know this is true by applying our inductive hypothesis to each ek.
• refine-gadt-case: By assumption we know we refine case e ofmj
j at τ ▷W , we generate e
at type T τi
i, and that we refine each of the case matches at τ ▷W . Consider one of these
matches K xk
k →e′. By refine-gadt-match, we refine the body of this match e′ at type
τ ▷{[vj
k/xk]
k
Sj 7→χj}
j
where W |K
e = {Sj 7→χj}
j. And by type-case and type-match, we
know that e′ has type τ.
Overall, we must show that ∀j. Sj(case e ofmj
j) ≡β χj. For our chosen match branch with
constructor K, consider only example worlds W |K
e where the case expression evaluates to
this branch. Consider one such example world S 7→χ ∈W |K
e . By assumption Se −→∗K vk
k.
And so it is sufficient to show that (vk/xk
kS)e′ ≡β χ but we know this by our induction
hypothesis.

24
Peter-Michael Osera
Finally note that by construction, we include one match for each possible constructor of
datatype T. Thus, all example worlds are sent to exactly one of the branches of the case.
Therefore, we can conclude that our case expression satisfies the example worlds.
• refine-gadt-guess: By assumption, we already know that Sje ≡β χj for all j example worlds
of W .
• refine-gadt-unify: By assumption, we know that both a and τ refine to e and by our induc-
tion hypothesis, we know that e satisfies W .
□
Example soundness of the top-level judgment is an immediate consequence of example soundness
of the refinement judgment.
Theorem A.8 (Top-level Example Soundness). If Γ ⊢X : σ and Γ ⊢σ ▷∀ck:ak
k. χj
j ⇒x = e
then ∀j.e ≡β χj.
Proof. By induction on the synthesis derivation for the binding x = e. The sole rule is refine-
gadt-binding which means that we assume that x = e is refined by ∀ai
i.τ ▷∀ck:ak
k. χj
j, the
body e is refined by τ ▷{· 7→χj
j}, and the top-level examples have type ∀ai
i.τ. By type-ex-poly,
we know that each χj has type τ and so our induction hypothesis tells us that e satisfies each χj
immediately.
□
A.2.2
Completeness.
Theorem A.9 (Refinement Completeness). If ·; Γ ⊢e : τ and Γ ⊢W : τ then ·; Γ ⊢τ ▷W ⇒e.
Completeness does not hold for the system because we cannot synthesize all programs. Like its
predecessors [6, 19], the system searches for programs already in β-normal, η-long form, avoiding
consideration of obviously redundant programs such as (λx. x) True −→∗True. However, as
discussed in section 3, the system also does not allow for synthesis of expressions that involve cases
or lambdas in argument positions of function applications. In the case of case-expressions, nested
cases can be bubbled up to enclose the expressions that they were originally nested. However, with
lambdas, we might not be able to synthesize some meaningful programs, e.g., an application of map
to an increment function (in a system extended with support for integers): map (\x -> x + 1) l.
This reflects the implementation of the system in Scythe which also does not allow for generation
of lambdas in argument positions. Such generation is far less constrained than variable and function
application generation and thus significantly degrades performance. However, the restriction is
merely practical. One could add in term generation for lambdas and case-expressions which would
resemble the refinement judgment defined in Figure 13 but simply omits the portions of judgments
and premises related to examples. The existing proofs for soundness should be easily extended
with these new rules and then completeness could be analyzed similarly to the completeness of
λsyn, a synthesis system for a core lambda calculus [17].

Constraint-Based Type-Directed Program Synthesis
25
σ
:: =
∀ai
i.C ⇒τ
Type Schemes
τ
:: =
α | a | T τi
i | τ1 →τ2
Monotypes
e
:: =
c | x | K | λx.e | e1 e2 | case e of mj
j
Expressions
m
:: =
K xk
k →e
Match Branches
χ
:: =
c | K χi
i | v ⇒χ
Examples
X
:: =
∀ci:ai
i. χj
j
Top-level Examples
v
:: =
c | λx.e | K vi
i
Values
b
:: =
x = e
Top-level Bindings
C
:: =
{τi ∼τ ′
i
i}
Constraints
S
:: =
[vi/xi]
i
Environments
θ
:: =
· | [τ/a]θ | [τ/α]θ
Type Environments/Unifers
W
:: =
[Sj 7→χj]
i
Example Worlds
Γ
:: =
· | x:σ, Γ | K:∀ai
i.C ⇒τk
k →T ai
i, Γ | c:a, Γ
Contexts
Fig. 10. The complete system: syntax.
e ≡β v iff e −→∗v
λx:τ.e ≡β v ⇒χ iff (λx:τ.e) v ≡β χ.
W |K
e = {S →χ ∈W | Se −→∗K v1 · · · vk}
unify(C) = θ
(standard unification algorithm)
C ⊨C′ iff ∀τ ∼τ ′ ∈C′.θτ = θτ ′whereunify(C) = θ.
consistent(C) iff ∃θ. unify(C) = θ
Fig. 11. The complete system: auxiliary synthesis definitions.

26
Peter-Michael Osera
C; Γ ⊢e : τ
type-var
x:∀ai
i.C′ ⇒τ ∈Γ
C ⊨[τi/ai]
iC′
C; Γ ⊢x : [τi/ai]
iτ
type-lam
C;x:τ1, Γ ⊢e : τ2
C; Γ ⊢λx.e : τ1 →τ2
type-app
C; Γ ⊢e1 : τ1 →τ2
C; Γ ⊢e2 : τ1
C; Γ ⊢e1 e2 : τ2
type-case
C; Γ ⊢e : T τi
i
C; Γ ⊢τi
i;mj : τ
j
C; Γ ⊢case e of mj
j : τ
type-const
c:a ∈Γ
C; Γ ⊢c : a
type-unify
C ⊨{τ ∼τ ′}
C; Γ ⊢e : τ2
C; Γ ⊢e : τ1
C; Γ ⊢τi
i;m : τ
type-match
K:∀ai
i.C′ ⇒τk
k →T ai
i ∈Γ
[τi/ai]
i = θ
C ∪θC′;xk:θτk
k, Γ ⊢e : τ
C; Γ ⊢τi
i;K xk
k →e : τ
Γ ⊢χ : τ
type-ex-const
c:a ∈Γ
Γ ⊢c : a
type-ex-ctor
K:∀ai
i.C ⇒τk
k →T ai
i ∈Γ
[τi/ai]
i = θ
consistent(θC)
Γ ⊢χk : θτk
k
Γ ⊢K χk
k : T τi
i
type-ex-io
Γ ⊢v : τ1
Γ ⊢χ : τ2
Γ ⊢v ⇒χ : τ1 →τ2
Γ ⊢X : σ
type-ex-poly
ak
k ⊆ai
i
ck:ak
k, Γ ⊢χj : τ
j
Γ ⊢∀ck:ak
k. χj
j : ∀ai
i.τ
Γ ⊢b : σ
type-binding
·; Γ ⊢e : τ
ftvs(τ) ⊆ai
i
Γ ⊢x = e : ∀ai
i.τ
Fig. 12. The complete system: typechecking.

Constraint-Based Type-Directed Program Synthesis
27
C; Γ ⊢τ ▷W ⇒e
refine-gadt-lam
freshx
C;x:τ1, Γ ⊢τ2 ▷{[vj/x]Sj 7→χj
j} ⇒e
C; Γ ⊢τ1 →τ2 ▷{Sj 7→vj ⇒χj
j} ⇒λx.e
refine-gadt-data
K:∀ai
i.C′ ⇒τk
k →T ai
i ∈Γ
θ = [τi/ai
i]
C ⊨θC′
Wk = {Sj 7→χ j
k
j
}
k
C; Γ ⊢θτk ▷Wk ⇒ek
k
C; Γ ⊢T τi
i ▷{Sj 7→K χ j
k
k j
} ⇒K ek
k
refine-gadt-case
C; Γ ⊢T τi
i ⇒e;C′
Kj:∀ai
i.Cj ⇒τ j
k
k
→T ai
i ∈Γ
j
C; Γ ⊢e;τi
i;Kj;τ ▷W ⇒mj
j
C; Γ ⊢τ ▷W ⇒case e of mj
j
refine-gadt-guess
C; Γ ⊢τ ⇒e;C′
Sje ≡β χj
j
consistent(C′)
C; Γ ⊢τ ▷{Sj 7→χj
j} ⇒e
refine-gadt-unify
C ⊨a ∼τ
C; Γ ⊢τ ▷W ⇒e
C; Γ ⊢a ▷W ⇒e
C; Γ ⊢e;τi
i;K;τ ▷W ⇒m
refine-gadt-match
K:∀ai
i.C′ ⇒τk
k →T ai
i ∈Γ
W |K
e = {Sj 7→χj}
j
θ = [τi/ai]
i
Sje −→∗K vj
k
k j
freshxk
k
C ∪θC′;xk:θτk
k, Γ ⊢τ ▷{[vj
k/xk]
k
Sj 7→χj
j
} ⇒e′
C; Γ ⊢e;τi
i;K;τ ▷W ⇒K xk
k →e′
Γ ⊢σ ▷X ⇒b
refine-gadt-binding
fresh x
ftvs(τ) ⊆ai
i
·;ck:ak
k, Γ ⊢τ ▷{· 7→χj
j} ⇒e
Γ ⊢∀ai
i.τ ▷∀ck:ak
k. χj
j ⇒x = e
C; Γ ⊢τ ⇒e;C′
gen-var
freshαi
i
x:∀ai
i.C′ ⇒τ ′ ∈Γ
θ = [αi/ai]
i
C′′ = C ∪θC′ ∪{τ ∼θτ ′}
consistent(C′′)
C; Γ ⊢τ ⇒x;C′′
gen-app
freshα
C; Γ ⊢α →τ ⇒e1;C1
C1; Γ ⊢α ⇒e2;C2
C; Γ ⊢τ ⇒e1 e2;C2
gen-unify
C ⊨τ1 ∼τ2
C; Γ ⊢τ2 ⇒e;C′
C; Γ ⊢τ1 ⇒e;C′
Fig. 13. The complete system: synthesis semantics.

