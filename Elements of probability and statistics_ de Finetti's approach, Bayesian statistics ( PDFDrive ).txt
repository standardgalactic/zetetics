Francesca Biagini
Massimo Campanino
Elements 
of Probability 
and Statistics
UNITEXT
UNITEXT
An Introduction to Probability 
with de Finetti’s Approach 
and to Bayesian Statistics

UNITEXT - La Matematica per il 3+2
Volume 98
Editor-in-chief
A. Quarteroni
Series editors
L. Ambrosio
P. Biscari
C. Ciliberto
M. Ledoux
W.J. Runggaldier

More information about this series at http://www.springer.com/series/5418

Francesca Biagini
• Massimo Campanino
Elements of Probability
and Statistics
An Introduction to Probability
with de Finetti’s Approach
and to Bayesian Statistics
123

Francesca Biagini
Department of Mathematics
Ludwig-Maximilians-Universität
Munich
Germany
Massimo Campanino
Department of Mathematics
Università di Bologna
Bologna
Italy
ISSN 2038-5722
ISSN 2038-5757
(electronic)
UNITEXT - La Matematica per il 3+2
ISBN 978-3-319-07253-1
ISBN 978-3-319-07254-8
(eBook)
DOI 10.1007/978-3-319-07254-8
Library of Congress Control Number: 2015958841
Translation from the Italian language edition: Elementi di Probabilità e Statistica di Francesca Biagini e
Massimo Campanino, © Springer-Verlag Italia, Milano 2006. All rights reserved.
© Springer International Publishing Switzerland 2016
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, express or implied, with respect to the material contained herein or
for any errors or omissions that may have been made.
Cover design: Simona Colombo, Giochi di Graﬁca, Milano, Italy
Printed on acid-free paper
This Springer imprint is published by SpringerNature
The registered company is Springer International Publishing AG Switzerland

Nous ne possédons une ligne, un surface,
un volume que si notre amour l’occupe.
M. Proust

To Thilo and Oskar
Francesca Biagini
To my brother Vittorio
Massimo Campanino

Preface
This book is based on the lectures notes for the course, Probability and
Mathematical Statistics, taught for many years by one of the authors (M.C.) and
then, divided into two sections, by both authors at the University of Bologna (Italy).
We follow the approach of de Finetti, see de Finetti [1] for a complete detailed
exposition. Although de Finetti [1] was conceived as a textbook of probability for
mathematics students, it was also meant to illustrate the point of view of the author
on the foundations of probability and mathematical statistics and discuss it in
relation to prevalent approaches, resulting often of difﬁcult access for beginners.
This was the main reason that prompted us to arrange the lectures notes of our
courses into a more organic way and to write a textbook for an initial class on
probability and mathematical statistics.
The ﬁrst ﬁve chapters are devoted to elementary probability. After that in the
next three chapters we develop some elements of Markov chains in discrete and
continuous time also in connection with queueing processes, and introduce basic
concepts in mathematical statistics in the Bayesian approach. Then we propose six
chapters of exercises, which cover most of the topics treated in the theoretical
part. In the appendices we have inserted summary schemes and complementary
topics (two proofs of Stirling formula). We also informally recall some elements of
calculus, as this has often proved useful for the students.
This book offers a comprehensive but concise introduction to probability and
mathematical statistics without requiring notions of measure theory; hence it can be
used in basic classes on probability for mathematics students and is particularly
suitable for computer science, physics and engineering students.
ix

We are grateful to Springer for allowing us to publish the English version of the
book. We wish to thank Elisa Canova, Alessandra Cretarola, Nicola Mezzetti and
Quirin Vogel for their fundamental help with latex, for both the Italian and the
English version.
Munich
Francesca Biagini
Bologna
Massimo Campanino
June 2015
x
Preface

Contents
Part I
Probability
1
Random Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.1
Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
Events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.3
Expectation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.4
Probability of Events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
1.5
Uniform Distribution on Partitions . . . . . . . . . . . . . . . . . . . . .
12
1.6
Conditional Probability and Expectation . . . . . . . . . . . . . . . . .
14
1.7
Formula of Composite Expectation and Probability. . . . . . . . . .
15
1.8
Formula of Total Expectation and Total Probability . . . . . . . . .
16
1.9
Bayes Formula. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
1.10
Correlation Between Events. . . . . . . . . . . . . . . . . . . . . . . . . .
17
1.11
Stochastic Independence and Constituents . . . . . . . . . . . . . . . .
20
1.12
Covariance and Variance. . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
1.13
Correlation Coefﬁcient . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
1.14
Chebychev’s Inequality. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
1.15
Weak Law of Large Numbers . . . . . . . . . . . . . . . . . . . . . . . .
25
2
Discrete Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
2.1
Random Numbers with Discrete Distribution . . . . . . . . . . . . . .
27
2.2
Bernoulli Scheme. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
2.3
Binomial Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
2.4
Geometric Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
2.5
Poisson Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
2.6
Hypergeometric Distribution . . . . . . . . . . . . . . . . . . . . . . . . .
31
2.7
Independence of Partitions. . . . . . . . . . . . . . . . . . . . . . . . . . .
32
2.8
Generalized Bernoulli Scheme . . . . . . . . . . . . . . . . . . . . . . . .
33
2.9
Multinomial Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
2.10
Stochastic Independence for Random Numbers
with Discrete distribution . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
2.11
Joint Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
xi

2.12
Variance of Discrete Distributions . . . . . . . . . . . . . . . . . . . . .
36
2.13
Non-correlation and Stochastic Independence. . . . . . . . . . . . . .
38
2.14
Generating Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
3
One-Dimensional Absolutely Continuous Distributions . . . . . . . . . .
43
3.1
Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
3.2
Cumulative Distribution Function. . . . . . . . . . . . . . . . . . . . . .
43
3.3
Absolutely Continuous Distributions. . . . . . . . . . . . . . . . . . . .
44
3.4
Uniform Distribution in ½0; 1. . . . . . . . . . . . . . . . . . . . . . . . .
46
3.5
Uniform Distribution on an Arbitrary Interval ½a; b . . . . . . . . .
47
3.6
Exponential Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
3.7
A Characterization of Exponential Distribution. . . . . . . . . . . . .
49
3.8
Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
50
3.9
Normal Tail Estimate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
51
3.10
Gamma Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
52
3.11
χ2-Distribution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
3.12
Cauchy Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
55
3.13
Mixed Cumulative Distribution Functions . . . . . . . . . . . . . . . .
55
4
Multi-dimensional Absolutely Continuous Distributions . . . . . . . . .
57
4.1
Bidimensional Distributions. . . . . . . . . . . . . . . . . . . . . . . . . .
57
4.2
Marginal Cumulative Distribution Functions . . . . . . . . . . . . . .
58
4.3
Absolutely Continuous Joint Distributions . . . . . . . . . . . . . . . .
58
4.4
The Density of Z ¼ X þ Y. . . . . . . . . . . . . . . . . . . . . . . . . . .
60
4.5
Beta Distribution Bðα; βÞ . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
4.6
Student Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63
4.7
Multi-dimensional Distributions . . . . . . . . . . . . . . . . . . . . . . .
64
4.8
Absolutely Continuous Multi-dimensional Distributions . . . . . .
65
4.9
Multi-dimensional Gaussian Distribution . . . . . . . . . . . . . . . . .
66
5
Convergence of Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
5.1
Convergence of Cumulative Distribution Functions. . . . . . . . . .
73
5.2
Convergence of Geometric Distribution to Exponential
Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
75
5.3
Convergence of Binomial Distribution
to Poisson Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
76
5.4
De Moivre-Laplace Theorem . . . . . . . . . . . . . . . . . . . . . . . . .
77
6
Discrete Time Markov Chains . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
6.1
Homogeneous Discrete Time Markov Chains
with Finite State Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
6.2
Transition Probability in n Steps . . . . . . . . . . . . . . . . . . . . . .
83
6.3
Equivalence Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
6.4
Ergodic Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
xii
Contents

7
Continuous Time Markov Chains . . . . . . . . . . . . . . . . . . . . . . . . .
89
7.1
Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
7.2
Homogeneous Continuous Time Markov Chains
with Countable State Space . . . . . . . . . . . . . . . . . . . . . . . . . .
90
7.3
Poisson Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
7.4
Queueing Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
94
7.5
M=M=1 Queueing Systems . . . . . . . . . . . . . . . . . . . . . . . . .
95
7.6
M=M=1 Queueing Systems . . . . . . . . . . . . . . . . . . . . . . . . . .
97
7.7
M=M=n Queueing Systems . . . . . . . . . . . . . . . . . . . . . . . . . .
98
7.8
Queueing Systems in Stationary Regime
and Little’s Formulas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
8
Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
8.1
Bayesian Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
8.2
Conditional Density for Two Random Numbers . . . . . . . . . . . . 104
8.3
Statistical Induction on Bernoulli Distribution . . . . . . . . . . . . . 105
8.4
Statistical Induction on Expectation of Normal Distribution . . . . 107
8.5
Statistical Induction on Variance of Normal Distribution . . . . . . 108
8.6
Improper Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
8.7
Statistical Induction on Expectation and Variance
of Normal Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
8.8
Bayesian Conﬁdence Intervals and Hypotheses' Testing . . . . . . 111
8.9
Comparison of Expectations for Normal Distribution . . . . . . . . 111
Part II
Exercises
9
Combinatorics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
Exercise 9.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
Exercise 9.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
Exercise 9.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
Exercise 9.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
Exercise 9.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
Exercise 9.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
10
Discrete Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
Exercise 10.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
Exercise 10.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
Exercise 10.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
Exercise 10.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
Exercise 10.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
Exercise 10.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
Exercise 10.7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
Contents
xiii

11
One-Dimensional Absolutely Continuous Distributions . . . . . . . . . . 143
Exercise 11.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
Exercise 11.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
Exercise 11.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
Exercise 11.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
12
Absolutely Continuous and Multivariate Distributions . . . . . . . . . . 151
Exercise 12.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
Exercise 12.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
Exercise 12.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156
Exercise 12.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
Exercise 12.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
Exercise 12.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
Exercise 12.7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
Exercise 12.8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176
13
Markov Chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
Exercise 13.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
Exercise 13.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
Exercise 13.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188
Exercise 13.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
14
Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
Exercise 14.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
Exercise 14.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
Exercise 14.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
Exercise 14.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
Exercise 14.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
Exercise 14.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
Exercise 14.7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
Exercise 14.8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
Appendix A: Elements of Combinatorics . . . . . . . . . . . . . . . . . . . . . . . 213
Appendix B: Relations Between Discrete and Absolutely Continuous
Distributions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
Appendix C: Some Discrete Distributions . . . . . . . . . . . . . . . . . . . . . . 219
Appendix D: Some One-Dimensional Absolutely
Continuous Distributions . . . . . . . . . . . . . . . . . . . . . . . . 221
Appendix E: The Normal Distribution. . . . . . . . . . . . . . . . . . . . . . . . . 223
Appendix F: Stirling’s Formula. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
xiv
Contents

Appendix G: Elements of Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
Appendix H: Bidimensional Integrals . . . . . . . . . . . . . . . . . . . . . . . . . 235
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245
Contents
xv

Part I
Probability

Chapter 1
Random Numbers
1.1
Introduction
Probability Theory deals with the quantiﬁcation of our degree of uncertainty. Its main
object of interest are random entities and, in particular, random numbers. What is
meant by random number?
A random number is a well deﬁned number, whose value is not necessarily known.
For example we can use random numbers to describe the result of a determined exper-
iment, or the value of an option at a preﬁxed time, or the value of a meteorological
magnitude at a given time. All these quantities have a well deﬁned value, but may
not be known either because they refer to the future and there are no means to predict
their values with certainty or, even if they refer to the past, there is no available
information at the moment.
We shall denote random numbers with capital letters. Even if the value of a random
number is in general not known, we can speak about the set of its possible values,
that will be denoted by I (X). Certain numbers can be considered as particular cases
of random numbers, whose set of possible values consists of a single element.
Example 1.1.1 Let the random numbers X, Y represent respectively the results of
throwing a coin and a die. If we denote head and tail by 0 and 1 and the sides of the
die with the numbers from 1 to 6, we have:
I (X) = {0, 1} ,
I (Y) = {1, 2, 3, 4, 5, 6} .
The random number X is:
• upper bounded if I(X) is upper bounded (sup I (X) < +∞);
• lower bounded if I(X) is lower bounded (inf I (X) > −∞);
• bounded if I(X) is both upper and lower bounded (sup I (X) < +∞, inf I (X) >
−∞).
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_1
3

4
1
Random Numbers
Given two random numbers X and Y, we denote by I (X, Y) the set of pairs of
values that (X, Y) can attain. In general given n random numbers X1, . . . , Xn, we
denote by I (X1, . . . , Xn) the set of possible values that (X1, . . . , Xn) can attain.
The random numbers X and Y are said to be logically independent if
I (X, Y) = I (X) × I (Y) ,
where I (X) × I (Y) denotes the Cartesian product of I (X) and I (Y).
Similarly the random numbers (X1 . . . , Xn) are said to be logically independent
if I (X1, . . . , Xn) = I (X1) × · · · × I (Xn).
Example 1.1.2 In a lottery two balls are consecutively drawn without substitution
from an urn that contains 90 balls numerated from 1 to 90. Let X and Y represent
the random numbers corresponding respectively to the ﬁrst and the second drawing.
The set of possible pairs is then
I (X, Y) = {(i, j)|1 ≤i ≤90, 1 ≤j ≤90, i ̸= j}.
Clearly I (X, Y) ̸= I (X) × I (Y) as I (X, Y) does not contain pairs of the type (i, i),
with i ∈{1, . . . , 90}. The random numbers X and Y therefore are not logically
independent.
By using random numbers we can perform usual arithmetic operations, obtaining
again random numbers. We introduce the following operations that we will apply to
random numbers. For real x and y
1. x ∨y := max(x, y);
2. x ∧y := min(x, y);
3. ˜x := 1 −x.
As it is easy to verify, these operations satisfy the following properties:
1. distributive property
x ∨(y ∧z) = (x ∨y) ∧(x ∨z),
(1.1)
x ∧(y ∨z) = (x ∧y) ∨(x ∧z);
(1.2)
2. associative property
x ∨(y ∨z) = (x ∨y) ∨z,
(1.3)
x ∧(y ∧z) = (x ∧y) ∧z;
(1.4)
3. commutative property
x ∨y = y ∨x,
(1.5)
x ∧y = y ∧x;
(1.6)

1.1 Introduction
5
4. furthermore
˜˜x = x,
(1.7)
(x ∨y)˜ = ˜x ∧˜y,
(1.8)
(x ∧y)˜ = ˜x ∨˜y .
(1.9)
These properties are easily extended to operations to n real numbers x1, . . . , xn.
1.2
Events
Events are a particular case of random numbers. An event E is a random number
such that I (E) ⊆{0, 1}. In the case of two events E and F, E ∨F is called logical
sum and E ∧F logical product. It is easy to verify that:
1. E ∨F = E + F −E F;
2. E ∧F = E F.
Given an event E, one deﬁnes the complementary event E by
˜E = 1 −E.
From (1.7) we have ˜˜E = E. From (1.8) we have
(E ∨F)˜ = ˜E ∧˜F = (1 −E)(1 −F) = 1 −E −F + E F,
so that
E ∨F = E + F −E F.
Analogously
(E ∨F ∨G)˜ = ˜E ∧˜F ∧˜G = (1 −E)(1 −F)(1 −G)
= 1 −E −F −G + E F + EG + FG −E FG,
so that
E ∨F ∨G = E + F + G −E F −EG −FG + E FG.
Other two operations on events are:
1. Difference of E and F: E \ F = E −E F.
2. Symmetric difference of E and F: E △F = (E \ F) ∨(F \ E) = E + F(mod 2).
From now on we shall use the symbol ⊢to indicate that what follows is certainly
true. For example, ⊢X ≤Y indicates that I (X, Y) ⊂{(x, y)| x ≤y}.

6
1
Random Numbers
We use the notation
E ⊂F for ⊢E ≤F,
and
⊢E = F for E ≡F
that is equivalent to E ⊂F and F ⊂E. When an event E is equal to 1 we say that
E happens, when E is equal to 0 we say that it does not happen. The logical sum
E ∨F happens if and only if at least one of the events E and F takes place, whereas
the logical product E ∧F = E F happens if and only if both E and F take place. The
complementary event ˜E happens if and only if E does not happen. Note that E ⊂F
means that E implies F, i.e. when E takes place also F does.
Deﬁnition 1.2.1 We deﬁne the following relations for events:
1. incompatibility: E, F are said to be incompatible if ⊢E F = 0;
2. exhaustivity: E1,…, En are said to be exhaustive if ⊢E1 + · · · + En ≥1;
3. partition: E1,…, En are said to be a partition if ⊢E1 + · · · + En = 1 (i.e. they
are exhaustive and two by two incompatible).
Example 1.2.2 An event E and its complementary ˜E are a partition.
Given n events E1, . . . , En, we can always build up a partition combining them
and their complementary sets. This partition is called partition of constituents. We
introduce the following notation. Given an event E, we put
E∗
i =
 Ei
˜Ei .
A constituent of E1, . . . , En is a product
Q = E∗
1 · · · E∗
n .
It easy to check that the set of all constituents are a partition.
In general, not all constituents are possible. If I (Ei) = {0, 1} for i = 1, . . . , n,
all constituents are possible if and only if E1, . . . , En are logically independent. The
possible constituents are a partition. Indeed
1 = (E1 + ˜E1) . . . (En + ˜En) =

Q constituent
Q .
Impossible constituents can be obviously skipped in the sum.

1.2 Events
7
If E1, . . . , En are already a partition, then the possible constituents are:
E1 ˜E2 . . . ˜En,
˜E1E2 ˜E3 . . . ˜En,
· · · ,
˜E1 . . . ˜En−1En,
in this case the constituents can be identiﬁed with the events themselves.
Let us now introduce the concept of logical dependence and independence of an
event E from n given events E1, . . . , En. The constituents Q of E1, . . . , En can be
classiﬁed in the following way with respect to a given event E:
(i) constituent of I type if Q ⊂E;
(ii) constituent of II type if Q ⊂˜E;
(iii) constituent of III type otherwise.
We say that the event E is:
• logically dependent from E1,…,En if all constituents of E1,…,En are of I or II
type;
• logically independent from E1,…,En if all constituents of E1,…,En are of the III
type;
• logically semidependent from E1,…,En otherwise.
If E is logically dependent from E1,…,En, then we can write
E =

Q of I type
Q⊂E
Q .
Example 1.2.3 Let us consider two events E1, E2. The logical sum (E1 ∨E2) can
be written as
E1 ∨E2 = E1E2 + ˜E1E2 + E1 ˜E2 .
In general an event E is logically dependent from E1,…,En if and only if E can be
written as E = Φ(E1, . . . , En) for some function Φ.
Example 1.2.4 Let us throw ﬁve times a coin. Let Ei be the event that we get head
at the ith trial, i.e. Ei = 1. Set Y = E1 + E2 + E3 + E4 + E5 (Y is the total number
of heads in the ﬁve throws) and consider the event
E = (Y ≥3).

8
1
Random Numbers
Then E is logically semidependent from E1E2E3. Indeed there are constituents of
the
I type: E1E2E3 ⊂E;
II type: ˜E1 ˜E2 ˜E3 ⊂˜E;
III type: ˜E1E2 ˜E3.
1.3
Expectation
Given a random number X, we look for a non-random number that expresses our
evaluation of X. We call this quantity expectation of X. In economic terms, if we
think of the expectation of X as a non-random gain that we judge equivalent to X.
Following de Finetti [1] the expectation P(X) assigned to the random number X
can be deﬁned in an operative way as follows.
Two equivalent operative deﬁnitions can be used to deﬁne the expectation:
1. Bet method: we think of X as a random gain (or loss, if it is negative). We have
to choose a value P(X) (non-random) that we judge equivalent to X.
After this choice is made, we must accept any bet with gain (or loss) given by
λ(X −¯x),
where λ ∈R is a constant. The corresponding coherence principle is that no
choice is allowed for which there is a bet giving a certain loss. The chosen value
¯x is our evaluation for the expectation of X.
2. Penalty method: in this case we choose a value X −¯¯x and we accept to pay a
penalty given by
−λ(X −¯¯x)2,
where λ ∈R+ is a proportionality coefﬁcient. In this case the coherence principle
is that ¯¯x′ is not allowed if there exits a different value X −¯¯x′ such that λ(X −¯¯x′)2
is certainly less than λ(X −¯¯x)2. The value ¯¯x that we can choose is our evaluation
of the expectation P(X).
It can be shown that these two operative deﬁnitions are equivalent (see [1]).
Proposition 1.3.1 (Properties of the expectation) Given a random number X, the
expectation P(X) has the following properties:
1. monotonicity: inf I (X) ≤P(X) ≤sup I (X);
2. linearity: if X = α1X1 + · · · + αn Xn, then P(X) = α1P(X1) + · · · + αnP(Xn).
Proof
1. Monotonicity: Assume that ¯x < inf I (X), then for λ < 0:
⊢λ(X −¯x) < 0.

1.3 Expectation
9
If ¯x > sup I (X), then for λ > 0 we again get:
⊢λ(X −¯x) < 0 ,
i.e. a certain loss. It follows that these choices are not coherent according to the
ﬁrst criterium. If
inf I (X) ≤¯x ≤sup I (X),
then ⊢

X −¯¯x
2 < (X −inf I (x)) or ⊢

X −¯¯x
2 < (X −sup I (x)) respec-
tively. In this case these choices are not coherent according to the second cri-
terium.
2. Linearity: Let Z = X + Y. Assume that we choose ¯z = P(Z), ¯x = P(X), ¯y =
P(Y), then according to the bet method we are ready to accept any combination
of bets on X, Y and Z that gives a total gain
G = c1(X −¯x) + c2(Y −¯y) + c3(Z −¯z)
= (c1 + c3)X + (c2 + c3)Y −c1 ¯x −c2 ¯y −c3¯z
where c1, c2, c3 are arbitrary constants. If we choose
c1 = c2 = −c3,
(so that the random part of G cancels), then we have that the total gain is: G =
c3(¯x + ¯y −¯z). Then if ¯x + ¯y −¯z = 0, one can choose c3 so that ⊢G < 0. In this
case this choice is not coherent according to the ﬁrst criterium. On the other side
if we follow the penalty method we will pay a penalty proportional to
−[(X −¯x)2 +(Y −¯y)2 +(Z −¯z)2] = −[(X −¯x)2 +(Y −¯y)2 +(X +Y −¯z)2].
The orthogonal projection P′ of P = (¯x, ¯y, ¯z) on the plane z = x + y has a
distance less or equal to the distance of P from every possible (X, Y, Z), that lies
on the plane, with a strict inequality if P does not lie on the plane. Therefore by
the second criterium we obtain ¯z = ¯x + ¯y. The proof that Z = αX, α ∈R, by
the ﬁrst or the second criterium is completely analogous.
In general, if X = α1X1 + · · · + αn Xn, it follows that
P(X) = α1P(X1) + · · · + αnP(Xn).
□
The monotonicity of expectation implies that:
⊢X ≥c =⇒P(X) ≥c;
If c1 ≤c2, ⊢c1 ≤X ≤c2 =⇒c1 ≤P(X) ≤c2;
⊢X = c =⇒P(X) = c.

10
1
Random Numbers
Remark 1.3.2 For unbounded random numbers X (for which inf I (X) = −∞, or
sup I (X) = ∞, or both) an evaluation of P(X) is not necessarily ﬁnite or even may
not exist. We refer to [1] for a discussion on the deﬁnition of the expectation for
unbounded random numbers.
1.4
Probability of Events
If E is an event, i.e. a random number such that I (E) ⊂{1, 0}, then its expectation
P(E) is also called probability of E. From monotonicity it follows that:
1. the probability of an event E is a number between 0 and 1, 0 ≤P(E) ≤1;
2. E ≡0 =⇒P(E) = 0;
3. E ≡1 =⇒P(E) = 1.
When E ≡1, E is called certain event. If E ≡0, E is called impossible event.
Furthermore for any given events E1, E2 we have that
P(E1 ∨E2) = P(E1 + E2 −E1E2) ≤P(E1 + E2)
and that
P(E1 + E2) = P(E1) + P(E2).
In general for a partition E1, . . . , En, i.e. if ⊢E1 + · · · + En = 1, we have
n

i=1
P(Ei) = 1.
The function that assigns to the events of a partition their probabilities is called
probability distribution of the partition. If E is logically dependent from the events
{E1, . . . , En} of a partition, then we can express the probability of E in terms of the
probabilities of E1, . . . , En. Indeed we have
E =

Ei⊂E
Ei
so that
P(E) =

Ei⊂E
P(Ei).
Let us now compute the expectation of a random number X with a ﬁnite number of
possible values I (X) = {x1, . . . , xn} in terms of the probabilities of events Ei :=
(X = xi). We use the convention that some proposition within brackets represents a
quantity which is 1 when the proposition is true and 0 when it is false. We have:

1.4 Probability of Events
11
P(X) =
n

i=1
xiP(X = xi).
(1.10)
Indeed
P(X) = P(X(E1 + · · · + En))
= P(X E1) + · · · + P(X En)
=
n

i=1
P(X Ei) =
n

i=1
P(xi Ei)
=
n

i=1
xiP(Ei) =
n

i=1
xiP(X = xi),
where we have used the fact that X Ei is a random number that is equal to xi when
Ei = 1 and to 0 when Ei = 0, i.e. X Ei = xi Ei.
In general, if φ is any function φ : R →R, we have
P(φ(X)) =
n

i=1
φ(xi)P(X = xi).
(1.11)
Theproofiscompletelyanalogoustotheoneof (1.10),whichdealswiththeparticular
case φ(x) = x.
Example 1.4.1 Let X be a random number representing the result of throwing a
symmetric die with faces numbered from 1 to 6. By symmetry it is natural to assign
the same probability (that must be 1
6) to all possible values. In this case:
P(X) = 1
6
6

i=1
i = 6 · 7
6 · 2 = 7
2 .
Note that in this case the expectation does not coincide with one of the possible
values of X.
Example 1.4.2 Let us throw a symmetric coin. Let X = 1 if the result is head and
X = 0 if we obtain tail. Also in this case by symmetry it is natural to assign the same
probability (that must be equal to 1
2) to both values. In this case
P(X) = 1
2 · 0 + 1
2 · 1 = 1
2.

12
1
Random Numbers
1.5
Uniform Distribution on Partitions
In some situations, for reasons of symmetry, it is natural to assign the same prob-
ability to all events of a partition. This is the case of hazard games. If the events
E1, . . . , En are assigned the same probability, we say that the partition has the
uniform distribution. Since the probabilities of a partition add up to 1, we have then
P(Ei) = 1
n .
Let E an event which depends logically from the partition E1, . . . , En, then the
probability of E is given by:
P(E) = P
⎛
⎝
Ei⊂E
Ei
⎞
⎠= ♯{i|Ei ⊂E}
n
.
In the case of uniform distribution on the partition, we have
P(E) = {i| Ei ⊂E}
n
.
This formula is commonly expressed by saying that the probability is given by the
number of favorable cases (i.e. the elements Ei contained in E), divided by the
number of possible cases (i.e. the total number of Ei), as shown below:
P(E) = ♯f avorable cases
♯possible cases .
(1.12)
This identity is valid only if the events of the partition are judged equiprobable.
Example 1.5.1 A symmetric coin is thrown n times. Let X be the random number
that counts the number of heads in the n throws and let Ei be the event that the ith
throw gives head. We consider the event
E := (X = k) =

Q⊂E
Q,
where Q ranges over all constituents E∗
1 . . . E∗
n of E1, . . . , En. The symmetry of
the coin leads to assign the same probability to all constituents. The probability of
E is then obtained by formula (1.12). The possible cases are 2n since a constituent
is determined by n two-valued choices.

1.5 Uniform Distribution on Partitions
13
The favorable cases are

n
k

, since they are determined by choosing k elements
out of n where the result head is obtained. Therefore
P(E) =

 n
k
 1
2n .
It follows from the properties of binomial coefﬁcients that when n is even, the largest
value for P(E) is obtained for k = n
2. If n is odd, the largest value for P(E) is obtained
for k = n−1
2
and k = n+1
2 .
Example 1.5.2 We perform n drawings with replacement from an urn containing N
identical balls. In the urn there are H white balls and (N −H) black balls. Let X
be the random number of white balls which is obtained after n drawings. The set
I (x) of possible values of X is clearly {0, . . . , n}. In order to compute P(X = k) for
0 ⩽k ⩽n we can use formula (1.12), provided that we assign by symmetry reasons
the same probability to the N n sequences of length n that have exactly k white balls;
their number is

n
k

H k(N −H)n−k,
since the position of the k white balls can be chosen in

 n
k

ways and after that we
must choose a sequence of length k from the set of H white balls and one of lenght
n −k from the set of N −H black balls. We have therefore
P(X = k) =

n
k
 H k(N −H)n−k
N n
.
Let us now consider the same problem, in the case when the drawings are made
without replacement. In this case n must be less than or equal to N, as we cannot
perform more than N drawings without replacement. Also X has some extra con-
straints, as the number X of the extracted white balls must be less than or equal to H
and the number n −X of extracted black balls must be less than or equal to N −H.
Therefore
I (X) = {0 ∨(n −(N −H)), . . . , n ∧H}.
In this case the possible cases are represented by all possible sets of extracted balls.
An event corresponds to a set of extracted balls. The number of possible cases is then

 N
n

.

14
1
Random Numbers
Also here by symmetry it is natural to assign the same probability to all events. If
we do so, we can apply formula (1.12) and get
P(X = k) =

 H
k
 
 N −H
n −k


 N
n

,
for k ∈I (X), as the favorable cases are determined by a choice of k elements from
the H white balls and n −k from the N −H black balls.
We could instead consider as possible cases the set of sequences of length n with
distinct elements, i.e. we can take into account the order of the drawings. Of course
in this case we have to take into account the order also when we count the favorable
cases. The ﬁnal result is the same.
1.6
Conditional Probability and Expectation
Conditional expectation and probability are very important concepts of probability.
We now introduce the deﬁnition of expectation and probability under the condition
that an event takes place. Let X be a random number and H an event. Conditional
expectation can be deﬁned in an operative way as ordinary expectation using bets or
penalties.
1. Bet method: we have to choose a quantity with the agreement that we must be
ready to accept any bet with gain
G = cH(X −¯x) ,
where c is a constant (positive or negative). The chosen value is then our evaluation
of the conditional expectation of X given by H and denoted by P(X|H).
2. Penalty method: Here we have to choose a value ¯¯x with the condition that we
accept to pay a penalty.
P = λH(X −¯¯x)2 ,
where λ is a positive constant. Note that the penalty is null when the event H
does not take place, similarly as in the deﬁnition based on bets. According to this
deﬁnition ¯¯x is our evaluation of the conditional expectation P(X|H) of X.
It can be shown, as in the case of ordinary expectation, that the two deﬁnitions are
equivalent.
In the particular case when we consider an event E we speak about the conditional
probability P(E|H) of E given H.

1.6 Conditional Probability and Expectation
15
Let I (X|H) ⊆I (X) denote the set of possible values of X when H takes place.
Conditional expectation enjoys the same properties as ordinary expectation, i.e. for
X, Y random numbers, λ a constant and H an event, we have:
• inf I (X|H) ≤P(X|H) ≤sup I (X|H);
• P(X + Y|H) = P(X|H) + P(Y|H);
• P(λX|H) = λP(X|H),
as it is easily obtained from the coherence principles.
1.7
Formula of Composite Expectation and Probability
Let X be a random number and H an event, then
P(X H) = P(H)P(X|H).
(1.13)
We call (1.13) the formula of composite expectation. If X is also an event, (1.13)
is said to be the formula of composite probability. In order to show that it follows
from the coherence principle, let us put z = P(X H), x = P(H) and y = P(X|H).
Following the deﬁnition based on bets, this means that we are willing to accept any
combination of bets with total gain:
G = c1(H −x) + c2H(X −y) + c3(X H −z)
= H(c1 + (c2 + c3)X −c2y) −c1x −c3z ,
where c1, c2 and c3 are arbitrary constants. As in previous cases, let us ﬁx c1, c2 and
c3 in such a way that the random part of G cancels: c2 = −c3 and c1 = c2y. Then
G = −c1x −c3z = c2(z −xy).
If z ̸= xy, then it is possible to choose c2 so that ⊢G < 0. Therefore by coherence
principle
z = xy.
Analogously this equality follows by using the deﬁnition based on penalty. If P(H) >
0, then
P(X|H) = P(X H)
P(H) .
In the case of an event E the formula
P(E|H) = P(E H)
P(H)

16
1
Random Numbers
has a logical meaning, as E H is the logical product of E and H, i.e. the event that
both E and H take place. In particular:
1. E ⊂H
⇒
P(E|H) = P(E)
P(H);
2. H ⊂E, that means I (E|H) = {1}
⇒
P(E|H) = 1;
3. H ⊂˜E, that means I (E|H) = {0}
⇒
P(E|H) = 0.
1.8
Formula of Total Expectation and Total Probability
Given X a random number and H1, . . . , Hn a partition, then
P(X) =
n

i=1
P(X|Hi)P(Hi) .
(1.14)
We call (1.14) the fomula of total expectation. If X is also an event, (1.14) is said to
be the formula of total probability. Indeed,
P(X) = P(X · 1) = P(X(H1 + . . . + Hn))
= P(X H1 + X H2 + · · · + X Hn)
=
n

i=1
P(X Hi) =
n

i=1
P(X|Hi)P(Hi).
1.9
Bayes Formula
Let E, H beevents withP(H) > 0. Byapplyingtwicetheformulaof total probability
we obtain Bayes’ formula:
P(E|H) = P(E H)
P(H) = P(H|E)P(E)
P(H)
.
This formula is a fundamental tool in statistical inference.
Example 1.9.1 Consider an urn contain N identical balls of which some are white
and some are black. Let Y be the random number of the white balls present in the
urn (the composition of the urn is unknown).
The events Hi = (Y = i), for i = 0, . . . , N form a partition. Let E be the event
that we obtain a white ball in a drawing from the urn. Using the formula of total
probability (1.14) we obtain:

1.9 Bayes Formula
17
P(E) =
N

i=0
P(E|Hi)P(Hi) =
N

i=0
i
N P(Hi) .
Indeed if the composition of the urn is known, i.e. if we condition with respect to Hi
for some i, we can apply usual symmetry considerations and get P(E|Hi) =
i
N .
In the case we assign to the partition H0, . . . , HN the uniform distribution
P(Hi) =
1
N + 1, i = 0, . . . , N
we get
P(E) =
N

i=0
i
N(N + 1) = 1
2 .
Wenowevaluatetheprobabilitythat theurncontainsi whiteballs if wehaveextracted
a white ball. This question is answered by Bayes’ formula:
P(Hi|E) = P(E|Hi)P(Hi)
P(E)
=
i
N
1
N+1
1
2
=
2i
N(N + 1) .
We see that distribution on the partition conditional to the event that a white ball is
drawn is no longer uniform, but it gives higher probabilities to compositions with a
large number of white balls.
1.10
Correlation Between Events
An event E is said to be positively correlated with the the event H if
P(E|H) > P(E).
Analogously E is said to be negatively correlated with H if
P(E|H) < P(E).
If P(E|H) = P(E), we say that E is non-correlated with H.
If E is positively (resp. negatively) correlated with H, the information that H
takes place increases (resp. decreases) our evaluation of the probability of E. When
E is not correlated with H, our evaluation does not change.
When P(H) > 0 and P(E) > 0, one can give a symmetric formulation of
correlation as it follows from the formula of composite probability. E and H are said
to be:

18
1
Random Numbers
• positively correlated if P(E H) > P(E)P(H);
• negatively correlated if P(E H) < P(E)P(H);
• non-correlated if P(E H) = P(E)P(H).
If E is positively correlated with H, so is ˜E. Indeed in this case
P( ˜E|H) = 1 −P(E|H) < 1 −P(E) = P( ˜E).
In the same way, if E is non-correlated with H, so is ˜E.
Example 1.10.1 We consider an urn with H white balls and N −H black balls. We
perform two drawings. Let Ei be the event that a white ball is extracted at the ith
extraction, i = 1, 2. For drawings with replacement we have
P(E1) = P(E2) = H
N .
Indeed the urn composition in the two drawings is the same. In this case E1 and E2
are non-correlated, as by (1.12)
P(E1E2) = H 2
N 2 = P(E1)P(E2) .
Let us now consider the case of drawings without replacement. We use again formula
(1.12) to compute probabilities and conditional probabilities. We have P(E1) = H
N
and by the formula of total probability (1.14) applied to the event E2 and the partition
E1, ˜E1 we get
P(E2) = P(E2|E1)P(E1) + P(E2| ˜E1)P( ˜E1)
= H −1
N −1
H
N +
H
N −1(1 −H
N ) = H
N .
Here P(E1) and P(E2) are both equal to H
N and P(E1), P(E2) are negatively corre-
lated, as
P(E2|E1) = H −1
N −1 < H
N = P(E2)
if 0 < H < N.
We say that two events are stochastically independent if
P(E1E2) = P(E1)P(E2) .
When P(E1) > 0 and P(E2) > 0 this deﬁnition coincides with non-correlation.
When one or both of E1 and E2 have 0 probability, then E1 and E2 are stochastically
independent, as in this case P(E1)P(E2) = 0 and

1.10 Correlation Between Events
19
P(E1E2) ≤P(E1) ∧P(E2) = 0.
The deﬁnition of stochastic independence extends to the case of an arbitrary number
of events.
Deﬁnition 1.10.2 The events E1, . . . , En are said to be stochastically independent
if for every subset {i1, . . . , ik} in {1, . . . , n} we have
P(Ei1 · · · Eik) = P(Ei1) · · · P(Eik).
(1.15)
We remark that in general n events are not stochastically independent if the events
are only pairwise stochastically independent.
We shall see that if the events E1, . . . , En are stochastically independent, then
the events E∗
1, . . . , E∗
n are stochastically independent for every possible choice of
E∗
i between Ei and ˜Ei, for i = 1, . . . , n.
Deﬁnition 1.10.3 Let H = {H1, . . . , Hn} be a partition. The events E1, E2 are said
to be stochastically independent conditionally to the partition H if
P(E1E2|Hi) = P(E1|Hi)P(E2|Hi) for all i = 1, . . . n .
Example 1.10.4 Let us consider an urn with unknown composition containing N
identical balls, of which some are white and some are black. Let Y be the random
number of white balls in the urn. We perform two drawings with replacement. Let
Ei, i = 1, 2, be the event that in the ith drawing we extract a white ball.
Consider the partition
Hi = (Y = i)
i = 0, . . . N.
It is easy to see that the events E1 and E2 are stochastically independent conditionally
to the partition H. We want to see whether E1 and E2 are stochastically independent,
assuming that we assign the uniform distribution to H, i.e. P(Hi) =
1
N+1 for i =
0, 1, . . . , N. We compute:
1. the probability of the ﬁrst drawing:
P(E1) =
N

i=0
P(E1|Hi)P(Hi)
=
1
N + 1
N

i=0
i
N
=
1
N + 1
N(N + 1)
2N
= 1
2 ;

20
1
Random Numbers
2. the probability of the second drawing:
P(E2) = P(E1) = 1
2;
3. the probability that we draw a white ball in both drawings:
P(E1E2) =
N

i=0
P(E1E2|Hi)P(Hi)
=
1
N + 1
N

i=0
P(E1|Hi)P(E2|Hi)
=
1
N + 1
N

i=0
i2
N 2 .
Using the fact that
(i + 1)3 −i3 = 3i2 + 3i + 1
we have
N

i=0
i2 =
N

i=0
(i + 1)3 −i3
3
−
N

i=0
i −
N

i=0
1
3 = (N + 1)3
3
−N(N + 1)
2
−N
3 ,
and
P(E1E2) = (N + 1)2
3N 2
−1
2N −
1
3N(N + 1).
For N →+∞, P(E1E2) tends to 1
3. Therefore at least for large N, E1 and E2
are positively correlated. This shows that stochastic independence conditionally
to a partition does not imply stochastic independence.
1.11
Stochastic Independence and Constituents
Proposition 1.11.1 The events E1, . . . , En are stochastically independent if and
only if
P(Q) = P(E∗
1) · · · P(E∗
n)
(1.16)
for every constituent Q = E∗
1 · · · E∗
n of E1, . . . , En.

1.11 Stochastic Independence and Constituents
21
Proof
⇒) Let Q = E∗
1 · · · E∗
n be a constituent of E1, . . . , En. Developing the
products, we can express Q as a polynomial φ of E1, . . . , En where the degree in
every variable is 1:
E∗
1 · · · E∗
n = φ(E1, . . . , En).
For example, consider the constituent Q of the events E1, E2, E3 given by
Q = ˜E1E2E3 = (1 −E1)E2E3 = E2E3 −E1E2E3 .
Here φ(x1, x2, x3) = x2x3 −x1x2x3 = (1 −x1)x2x3.
If the events E1, . . . , En are stochastically independent, the probabilities of prod-
ucts factorize into products of probabilities so that
P(Q) = P (φ(E1, . . . , En))
= φ (P(E1), . . . , P(En))
= P(E∗
1) · · · P(E∗
n),
where the last equality is obtained by collecting terms in φ and using that P( ˜Ei) =
1 −P(Ei). In the example Q = ˜E1E2E3. We have
P(Q) = P

˜E1E2E3

= P (E2E3 −E1E2E3)
= P(E2)P(E3) −P(E1)P(E2)P(E3) = φ(P(E1), P(E2), P(E3))
= (1 −P(E1))P(E2)P(E3) = P( ˜E1)P(E2)P(E3).
⇐) We assume that (1.16) holds for all constituents of the events E1, . . . , En. Let
{i1, . . . , ik} ⊂{1, . . . , n} and { j1, . . . , jn−k} = {1, . . . , n} \ {i1, . . . , ik}. Then
P(Ei1 · · · Eik) = P
⎛
⎝

Q⊂Ei1···Eik
Q
⎞
⎠
= P(Ei1) · · · P(Eik)

P(E⋆
j1 . . . E⋆
jn−k)
where the sum ranges over all possible choices of E⋆
jl for l = 1, . . . , n −k. By
collecting terms we get:
P(Ei1 . . . Eik) = P(Ei1) . . . P(Eik)[(P(E j1) + P( ˜E j1)] . . . [P(E jn−k) + P( ˜E jn−k)]
= P(Ei1) . . . P(Eik),
since the last n −k factors are all equal to 1.
□

22
1
Random Numbers
1.12
Covariance and Variance
Given two random numbers X and Y, the covariance between X and Y is deﬁned by
cov(X, Y) = P ((X −P(X))(Y −P(Y))) .
X and Y are said to be:
• positively correlated if cov(X, Y) > 0;
• negatively correlated if cov(X, Y) < 0;
• non-correlated if cov(X, Y) = 0.
By developing the product in the deﬁnition of the covariance, we obtain:
cov(X, Y) = P(XY −P(X)Y −XP(Y) + P(X)P(Y)) = P(XY) −P(X)P(Y).
The variance of a random number X is deﬁned by
σ2(X) = cov(X, X).
Other notations for the variance of X are var(X) and D(X). From the two expressions
for the covariance we get two expressions for the variance: σ2(X) = P(X2)−P(X)2
and σ2(X) = P

(X −P(X))2
. From the second expression we see that
σ2(X) ≥0,
as it is the expectation of a non-negative random number. We also deﬁne:
• quadratic expectation:
PQ(X) =

P(X2);
• standart deviation:
σ(X) =

σ2(X) = PQ(X −P(X)).
Proposition 1.12.1 (Properties of covariance and variance) Covariance and vari-
ance satisfy the following properties:
1. bilinearity:
cov(X + Y, Z) = cov(X, Z) + cov(Y, Z);
(1.17)
2. behavior with respect to linear transformations:
cov(aX + b, cY + d) = ac cov(X, Y),
(1.18)
σ2(aX + b) = a2σ2(X).
(1.19)

1.12 Covariance and Variance
23
Proof
1. From the deﬁnition of covariance we have
cov(X + Y, Z) = P((X + Y) −P(X + Y), Z −P(Z)
= P((X + Y) −P(X) −P(Y))(Z −P(Z))
= P(((X −P(X))(Z −P(Z))) + P(((Y −P(Y))(Z −P(Z)))
= cov(X, Z) + cov(Y, Z) .
2. Again from the deﬁnition of covariance and the linearity of the expectation we
have:
cov(aX + b, cY + d) = P ((aX + b −P(aX + b)) (cY + d −P(cY + d)))
= P ((aX + b −aP(X) −b) (cY + d −cP(Y) −d))
= P (a (X −P(X)) c (Y −P(Y)))
= ac cov(X, Y).
□
Proposition 1.12.2 (Variance of the sum of random numbers) Let X1, . . . , Xn n be
random numbers, then:
σ2(X1 + · · · + Xn) =
n

i=1
σ2(Xi) +

i, j
i̸= j
cov(Xi, X j)
=
n

i=1
σ2(Xi) + 2

i< j
cov(Xi, X j).
Proof By the bilinearity property (1.17) we have:
σ2(X1 + · · · + Xn) = cov(X1 + · · · + Xn, X1 + · · · + Xn)
=
n

i=1
cov(Xi, Xi) +

i̸= j
cov(Xi, X j)
=
n

i=1
σ2(Xi) +

i, j
i̸= j
cov(Xi, X j).
□
1.13
Correlation Coefﬁcient
It is useful to introduce an index of the correlation of two random numbers X, Y,
called correlation coefﬁcient. As we shall see, it has the property that if X and Y
correspond to observed quantities, it does not depend on the units of measure of X
and Y.

24
1
Random Numbers
Deﬁnition 1.13.1 For X, Y random numbers with σ(X) > 0, σ(Y) > 0 the corre-
lation coefﬁcient of X and Y is deﬁned by
ρ(X, Y) = cov(X, Y)
σ(X) σ(Y).
Let us state two important properties of the correlation coefﬁcient:
1. If X, Y are random numbers with σ(X) > 0, σ(Y) > 0 and a, b, c, d are con-
stants with a ̸= 0 and c ̸= 0, we have
ρ(aX + b, cY + d) = sgn(ac) ρ(X, Y),
where sgn(x) = 1 for x > 0 and sgn(x) = −1 for x < 0.
Proof By using the properties (1.18) and (1.19) we get
ρ(aX + b, cY + d) =
cov(aX + b, cY + d)

σ2(aX + b) σ2(cY + d)
=
ac cov(X, Y)
|ac|

σ2(X) σ2(Y)
= sgn(ac) ρ(X, Y).
□
2. −1 ≤ρ(X, Y) ≤1.
Let
X∗= X −P(X)
σ(X)
,
Y ∗= Y −P(Y)
σ(Y)
.
These are the so-called standardized random numbers: they are obtained from
X, Y by means of suitable linear transformation such that P(X∗) = 0, P(Y ∗) = 0
and σ2(X∗) = 1, σ2(Y ∗) = 1 by using linearity of the expectation and (1.19).
By (1.18) we get
cov(X∗, Y ∗) = P (X∗Y ∗)
σ(X) σ(Y) = ρ(X, Y).
Computing the variance of X∗+ Y ∗using Proposition 1.12.1 we get:
0 ≤σ2(X∗+ Y ∗) = σ2(X∗) + σ2(Y ∗) + 2 cov(X∗, Y ∗)
= 2 + 2ρ(X, Y),

1.13 Correlation Coefﬁcient
25
so that ρ(X, Y) ≥−1. Similarly computing the variance of X∗−Y ∗, we obtain
0 ≤σ2(X∗−Y ∗) = σ2(X∗) + σ2(−Y ∗) + 2 cov(X∗, −Y ∗)
= 2 −2ρ(X, Y).
so that ρ(X, Y) ≤1.
1.14
Chebychev’s Inequality
The Chebychev’s inequality allows to estimate the probability that a random number
takes value far from its expectation. It can be formulated in two ways:
1. Let X be a random number with PQ(X) > 0. For every t > 0
P

|X| ≥t PQ(X)

≤1
t2 .
2. Let X be a random number with σ2(X) > 0. Let m = P(X), ∀t > 0:
P (|X −m| ≥σ(X)t) ≤1
t2 .
Proof
1. Let E be the event E =

|X| ≥t PQ(X)

. We compute P

X2
using the
formula of total expectation with respect to the partition E, ˜E:
P

X2
= P

X2|E

P(E) + P

X2| ˜E

P

˜E

.
Since X2 is non-negative, the last term on the right-hand side is non-negative.
Moreover inf I (X2|E) ≥t2. Then PQ(X)2 = t2P(X)2 in force of the deﬁn-
ition of E. Therefore we have P(X)2 ≥t2P(X2)P(E). This implies the ﬁrst
inequality.
2. The second inequality follows from the ﬁrst by applying it to the random number
Y = X −m and using that PQ(Y) = σ(X).
□
1.15
Weak Law of Large Numbers
Theorem 1.15.1 (Weak law of large numbers). Let (Xn)n=1,2,... be a sequence of
random numbers such that all have the same expectation, P(Xi) = m, the same
variance σ2(Xi) = σ2 and cov(Xi, X j) = 0, ∀i, j with i ̸= j. If we put Sn =
X1 + · · · + Xn, we have that for all λ > 0

26
1
Random Numbers
lim
n→+∞P

| Sn
n −m| ≥λ

= 0 .
Proof The proof is based on the second form of Chebychev’s inequality. First we
compute the expectation of Sn
n :
P

 Sn
n

= 1
n (P(X1) + · · · + P(Xn)) = m
and its variance
σ2

 Sn
n

= 1
n2 σ2(Sn) = 1
n2 (σ2(X1) + · · · + σ2(Xn)) = σ2
n ,
where we have used Proposition 1.12.2 and the fact that random numbers of the
sequence are pairwise uncorrelated. From the second form of Chebychev’s inequality
we get
P

| Sn
n −m| ≥σ
√n t

≤1
t2 .
Putting λ = σ
√n t, we obtain 1
t2 = σ2
nλ2 . Therefore
P

| Sn
n −m| ≥λ

≤σ2
nλ2 ,
that tends to 0 as n →+∞.
□
The quantity Sn
n = E1 + · · · + En
n
is called frequence. In this case the weak law
of large numbers shows that for a large sequence of trials (events) the frequence of
success is close to the probability of a single event with large probability.
Example 1.15.2 In particular one can apply the weak law of large numbers to the
case of a sequence of uncorrelated events (Ei)i=1,2,... with the same probability
P(Ei) = p. Note that for an event Ei,
σ2(Ei) = P(E2
i ) −P(Ei)2 = P(Ei) −P(Ei)2 = p(1 −p)
so the Ei’s have automatically the same variance. Hence for all λ > 0 we have
P

| Sn
n −p| ≥λ

→0
for n →∞.

Chapter 2
Discrete Distributions
2.1
Random Numbers with Discrete Distribution
The distribution of a random number X is said to be discrete if there is a ﬁnite or
enumerable set A ⊂I (X) such that P(X ∈A) = 1. This is obviously the case
when I (X) is itself ﬁnite or enumerable, since in this case we may take A = I (X).
Let A = {x1, x2, . . .} and deﬁne p(xi) = P(X = xi). In the examples of discrete
distributions that we shall consider, we always have
∞

i=1
p(xi) = 1 .
This property is not a consequence of the basic properties of expectation that
we have derived from the coherence principles (from linearity and monotonicity we
only get that ∞
i=1 p(xi) ≤1). It can be considered as a regularity property of the
expectation. See [dF] for a thorough discussion of this problem. In the following we
introduce some of the most common discrete distributions.
2.2
Bernoulli Scheme
A simple and useful model from which some discrete distributions can be derived is
the Bernoulli scheme. It can be thought of as a potentially inﬁnite sequence of trials,
each of them with two possible outcomes called success and failure. Each trial is
performed in the same known conditions and we assume that there is no inﬂuence
between different trials. Formally a Bernoulli scheme with parameter p, 0 < p < 1,
is a sequence E1, E2, . . . of stochastically independent equiprobable events with
P(E1) = p.
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_2
27

28
2
Discrete Distributions
Example 2.2.1 A concrete example for which one can use as a model a Bernoulli
scheme with p = 1
2 is a sequence of throws of a symmetric coin, where Ei is the
event that one gets head at the ith throw.
2.3
Binomial Distribution
Given a Bernoulli scheme (Ei)i∈N with P(Ei) = p, let Sn the random number of
successes in the ﬁrst n trials. Sn can be written as
Sn = E1 + · · · + En.
The set of possible values of Sn is I (Sn) = {0, . . . , n}.
Let us compute, using the constituents of the events E1, . . . , En, the probability
distribution of Sn:
P(Sn = k) =

Q⊂(Sn=k)
P(Q) .
We must determine the probability of a constituent of I type with respect to the event
(Sn = k). An example of such a constituent is
Q = E1 . . . Ek ˜Ek+1 . . . ˜En,
(2.1)
that is the event that k successes are obtained in the ﬁrstk trials, whereas the remaining
n −k trials yield failures.
Analogously,anyotherconstituentof I typewillbeaproductofthesamekindasin
(2.1). Since the events are stochastically independent, in force of Proposition 1.11.1,
every constituent Q of I type has the same probability, given by
P(Q) = p · · · p
  
k times
(1 −p) · · · (1 −p)



(n−k) times
= pk(1 −p)n−k .
In order to compute P(Sn = k) we must therefore multiply this value times the
number of constituents of I type. This is equal to
n
k
	
, that is the number of ways
of choosing a subset of k elements out of n trials. Therefore we have
P(Sn = k) =
n
k
	
pk(1 −p)n−k .
Sn is said to have binomial distribution Bn(n, p) with parameters n, p.
It is easy to check that n
k=0 P(Sn = k) = 1, as it must be since the events
(Sn = k), k = 0, . . . , n, make up a partition. Indeed, using Newton’s formula, we
have:

2.3 Binomial Distribution
29
1 = (p + 1 −p)n =
n

k=0
n
k
	
pk(1 −p)n−k .
The simplest way to compute the expectation of Sn is through the linearity of expec-
tation:
P(Sn) = P(E1 + · · · + En) =
n

i=1
P(Ei) = np .
Example 2.3.1 Consider an urn containing N identical balls, of which H are white
and N −H are black. We perform a sequence of n drawings with replacement.
It is easy to check that by symmetry the sequence of events (Ei)i = 1, 2, ... where
Ei = (a white ball is drawn at the ith drawing) makes up a Bernoulli scheme, with
parameters p = H
N . Indeed for 1 ≤i1 < i2 < . . . < ik
P(Ei1 . . . Ein) = H k
N k =
 H
N
	k
,
where the possible cases correspond to the N k sequences of balls that may be drawn in
the drawings i1, . . . , ik, whereas the favorable cases correspond to the H k sequences
where white balls are drawn.
2.4
Geometric Distribution
Let (Ei)i = 1, 2, ... be a Bernoulli scheme; let T be the random number representing
the number of the trial when the ﬁrst success is obtained, i.e. T = min{n | En = 1}.
The set of possible values of T is given by:
I (T ) = N \ {0} ∪{∞} .
It is easy to see that P(T = ∞) = 0 since for all n > 0, (T = ∞) ⊆˜E1 . . . ˜En
so that P(T = ∞) ≤P( ˜E1 . . . ˜En) = (1 −p)n for every n. Let us compute the
probability distribution of T for ﬁnite values:
P (T = i) = P

˜E1 . . . ˜Ei−1Ei

= P

˜E1

. . . P

˜Ei−1

P (Ei) = (1 −p)i−1 p .
T is said to have geometric distribution with parameter p. Using the formula for the
sum of geometric series (see Appendix G.1), one veriﬁes that
+∞

i=1
P(T = i) =
+∞

i=1
(1 −p)i−1 p = p
+∞

k=0
(1 −p)k = p ·
1
1 −(1 −p) = 1.

30
2
Discrete Distributions
The expectation of T can be computed by an extension of formula (1.10) to the case
of enumerable set of values. This can be justiﬁed (providing that the series converges)
as a regularity property, thinking that T can be approximated with random numbers
with a ﬁnite but arbitrarily large number of values. We then get
P(T ) =
+∞

i=1
iP(T = i) =
+∞

i=1
i(1 −p)i−1 p = p
+∞

i=1
i(1 −p)i−1 = p
p2 = 1
p ,
where we used that for |x| < 1
+∞

i=1
ixi−1 =
+∞

i=1
d
dx [xi] = d
dx
+∞

i=0
xi

= d
dx

1
1 −x
	
=
1
(1 −x)2 .
The geometric distribution is said to be “memoryless”. Indeed for m > 0, n > 0
P(T > m + n | T > n) = P(T > m),
i.e. the conditional probability of no success up and including the (m+n)th trial given
that there was no success up and including the nth trial is equal to the probability
of no success up and including the m trial: everything starts from scratch. We have
namely that
P(T > m + n | T > n) = P(T > m + n, T > n)
P(T > n)
= P(T > m + n)
P(T > n)
.
But P(T > n) = (1 −p)n since (T > n) = ˜E1 −˜En. Hence
P(T > m + n | T > n) = (1 −p)m+n
(1 −p)n
= (1 −p)m = P(T > m) .
2.5
Poisson Distribution
A random number X is said to have Poisson distribution with parameters λ, λ ∈R+,
if I (X) = N and
P(X = i) = λi
i! e−λ .
As in the case of a geometric distribution +∞
i=0 P(X = i) = 1. Indeed
+∞

i=0
P(X = i) =
+∞

i=0
λi
i! e−λ = e−λ
+∞

i=0
λi
i! = e−λeλ = 1 .

2.5 Poisson Distribution
31
In order to compute the expectation, we use the extension of the formula for random
numbers with a ﬁnite number of possible values to the case of a enumerable set of
possible values as we did for geometric distribution and as we will do in similar cases
(provided that the series is convergent). We obtain
P(X) =
+∞

i=0
iP(X = i) =
+∞

i=0
i λi
i! e−λ = λe−λ
+∞

i=1
λi−1
(i −1)!
= λe−λ
+∞

k=0
λk
k! = λe−λeλ = λ .
2.6
Hypergeometric Distribution
Consider an urn containing N balls of which H are white and N −H black, where
0 < H < N. We perform n drawings without replacement from the urn with n ≤N.
Let X be the random number that counts the number of white balls in the sample
that we draw.
Since we perform drawings without replacement, X is less than or equal to H and
n −X, the number of black balls in the sample, is less than or equal to N −H. From
this it follows that the set of possible values of X is given by
I (X) = {0 ∨n −(N −H), . . . , n ∧H} .
Let i ∈I (X). Due to the symmetry of the situation with respect to interchange of
balls, we evaluate P(X = i) using formula (1.12). When deﬁning possible cases and
consequently favorable cases, we can consider the set of the n drawn balls, i.e. we
can avoid to consider the order of drawings, as the event does not involve the order.
In this way the possible cases correspond to the subset of size n from a set of N
elements:
♯possible cases =
 N
n
	
.
A sample with i white balls contains (n −i) black balls. The number of favorable
cases that correspond to such samples is therefore given by:
♯f avorable cases =
 H
i
	  N −H
n −i
	
.
The random number X is said to have hypergeometric distribution with parameters
n, H, N. By the former discussion we have:

32
2
Discrete Distributions
P(X = i) =
 H
i
	  N −H
n −i
	
 N
n
	
.
In order to compute the expectation of X, it is convenient to decompose it as
X =
n

i=1
Ei
where Ei is the event that a white ball is chosen at ith drawing. Therefore by the
linearity of the expectation
P(X) = P(E1) + · · · + P(En).
In the evaluation of P(Ei) we can still use symmetry by interchange of balls, but when
deﬁning possible cases we must take into account the order, since the event depends
on the order of the drawings. Possible cases correspond to sequences of length n
of distinct elements from a set of N elements. Their number is DN
n
= (N)n =
N(N −1) −(N −n + 1). Favorable cases correspond to those sequences that have
a white ball at the ith place. This ball can be chosen in H ways. The remaining balls
form a sequence of lenght n −1 of distinct elements from a set of N −1 elements.
Therefore
P(Ei) = ♯f avorable cases
♯possible cases
= H DN−1
n−1
DNn
= H
N
and
P(X) = n H
N .
2.7
Independence of Partitions
Two partitions H = (H1, . . . , Hm), L = (L1, . . . , Ln) are said to be stochastically
independent if for every i, j with 1 ≤i ≤m, 1 ≤j ≤n
P

Hi L j

= P (Hi) P

L j

.
Stochastic independence can be extended to the case of r partitions H1, . . . , Hr.
Consider the partitions
Hl = (H (l)
1 , . . . , H (l)
nl )
for 1 ≤l ≤r. H1, . . . , Hr are said to be stochastically independent if for every
i1, . . . , ir with 1 ≤il ≤nl, . . . , 1 ≤l ≤r

2.7 Independence of Partitions
33
P

H (1)
i1 . . . H (r)
ir

= P

H (1)
i1

. . . P

H (r)
ir

.
Partitions can be thought as pluri-events, with a certain number of possible results,
such as in the case of drawings from an urn containing balls of several colors. In the
case of partitions with two events, one can select an event from each partition. In this
case stochastic independence of partitions is equivalent to stochastic independence
of the selected events.
2.8
Generalized Bernoulli Scheme
Let H1, H2, . . . be a sequence of partitions, each composed by r events, Hi =

E(i)
1 , . . . , E(i)
r

for i ≥1. We assume that H1, . . . , Hn are stochastically inde-
pendent for every n and that P(E(i)
k ) = pk, k = 1, . . . ,r, for all i ≥1, with
p1 + · · · + pr = 1. The sequence H1, H2, . . . is called a generalized Bernoulli
scheme. In the case r = 2 a generalized Bernoulli scheme is equivalent to the ordi-
nary Bernoulli scheme (F1, F2, . . .) where Fi = E(i)
1
with parameter p = p1. We
can represent a generalized Bernoulli scheme in an array:
E(1)
1 , . . . , E(1)
r
E(2)
1 , . . . , E(2)
r
... , . . . ,
...
... , . . . ,
...
E(n)
1 , . . . , E(n)
r ,
where the events belonging to the same column are equiprobable, whereas the events
of each row constitute stochastically independent partitions.
2.9
Multinomial Distribution
Starting from a generalized Bernoulli scheme, as deﬁned in Sect.2.2, we can now
deﬁne the multinomial distribution in the same way as the binomial distribution can
be deﬁned starting from an ordinary Bernoulli scheme. Given n > 0, let us consider
the random numbers Y1, . . . , Yr deﬁned by
Yl =
n

i=1
E(i)
l
, l = 1, . . . ,r .

34
2
Discrete Distributions
In the array of the previous section, the Yl’s are obtained by adding up the events
along the columns. We have
r

l=1
Yl =
r

l=1
n

i=1
E(i)
l
=
n

i=1
r

l=1
E(i)
l
  
1
= n .
The idea of constituents can be extended in a natural fashion from events to partitions.
A constituent of the partition H1, . . . , Hn is an event of the form
Q = n
i=1Hi
∗,
where Hi
∗is an event of the partition Hi. If H1, . . . , Hn are stochastically independent
(as in the case of generalized Bernoulli scheme) we have:
P(Q) = P(H 1
∗) . . . P(H n
∗) .
We want to compute
P (Y1 = k1, . . . , Yr = kr)
for k1 ≥0, kr ≥0 such that k1 + · · · + kr = n. We can decompose this probability
in terms of constituents of I type:
P(Y1 = k1, . . . , Yr = kr) =

Q
P(Q),
where Q varies among the constituents of I type contained in the event (Y1 =
k1, . . . , Yr = kr). In the product deﬁning a constituent of I type there will be kl
events of index l with 1 ≤l ≤r. Therefore since the partitions are stochastically
independent, the probability of a constituent of I type is given by:
P(Q) = pk1
1 , . . . , pkr
r .
The number of constituents of I type is equal to the way of partitioning a set of n
elements into r subsets with k1, . . . , kr elements, i.e.
n!
k1! . . . kr!. We have therefore:
P (Y1 = k1, . . . , Yr = kr) =

Q I type
P(Q) =
n!
k1! . . . kr!



number of constituents
pk1
1 . . . pkr
r



P(Q)
.
The multinomial distribution depends on the parameters r, p1, . . . , pr−1, since pr =
1 −r−1
i=1 pi. For r = 2 the multinomial distribution reduces to the binomial one.

2.10 Stochastic Independence for Random Numbers …
35
2.10
Stochastic Independence for Random Numbers
with Discrete distribution
Let X and Y be two random numbers with I (X) = {x1, . . . , xm} and I (Y) =
{y1, . . . , yn}. We consider the partitions H and K generated by the events Hi =
(X = xi), for i = 1, . . . , m, and K j = (Y = y j), for j = 1, . . . , n.
The random numbers X and Y are said to be stochastically independent if the
partitions H and K are stochastically independent.
2.11
Joint Distribution
Let us consider two random numbers X and Y, that we can look at as a random vector
(X, Y), assuming a ﬁnite number of possible values I (X, Y). If I (X) = {x1, . . . , xm}
and I (Y) = {y1, . . . , yn} we deﬁne the joint distribution of X and Y. This is the
function
p(xi, y j) = P(X = xi, Y = y j)
deﬁned on I (X) × I (Y). We can associate to it the matrix
⎛
⎜⎝
p(x1, y1) . . . p(x1, yn)
...
...
...
p(xm, y1) . . . p(xm, yn)
⎞
⎟⎠.
The marginal distribution of X is the function
p1(xi) = P(X = xi)
for i = 1, . . . , m. The marginal distribution can be obtained from the joint distribu-
tion:
p1(xi) = P(X = xi) =
n

j=1
P(Xi, Y j) =
n

j=1
p(xi, y j),
i.e. adding up the elements on the rows of the matrix. It is called marginal because it
is customarily written at the margin of the matrix. Similarly the marginal distribution
of Y is deﬁned by:
p2(y j) = P(Y = y j) =
m

i=1
p(xi, y j) .

36
2
Discrete Distributions
It follows that two random numbers X and Y are stochastically independent if and
only if
p(xi, y j) = p1(xi)p2(y j)
(2.2)
for i = 1, . . . , m and j = 1, . . . , n. Given ψ : R2 −→R, the expectation of the
random number Z = ψ(X, Y) can be obtained from the joint distribution of X, Y:
P(Z) = P(ψ(X, Y)) =
m

i=1
n

j=1
ψ(xi, y j)p(xi, y j) .
(2.3)
The proof is completely analogous to that one in the case of a single random number.
For example, we can compute P(XY):
P(XY) =
m

i=1
n

j=1
xi y j p(X = xi, Y = y j).
If X and Y are stochastically independent and φ1, φ2 are two real functions φi :
R −→R with i = 1, 2, we have that
P(φ1(X)φ2(Y)) = P(φ1(X))P(φ2(Y)).
(2.4)
Indeed
P(φ1(X)φ2(Y)) =
m

i=1
n

j=1
φ1(xi)φ2(y j)P(X = xi, Y = y j)
=

(xi,y j)∈I (X)×I (Y)
φ1(xi)φ2(y j)p1(xi)p2(y j)
=

xi∈I (X)
φ1(xi)p1(xi)

y j∈I (Y)
φ2(y j)p2(y j)
= P(φ1(X))P(φ2(Y)) .
2.12
Variance of Discrete Distributions
We compute the variances of the distributions that we have previously introduced.
1. Variance of an event:
σ2(E) = P

E2
−P (E)2 = P(E) −P(E)2 = P(E)(1 −P(E)) ,
where we use that for an event E2 = E since E can take only values 0 and 1.

2.12 Variance of Discrete Distributions
37
2. Binomial distribution: For X with binomial distribution with parameters nx and
p, we use the representation X = E1+. . . + En, where the Ei’s are stochastically
independent and hence pairwise uncorrelated. We get:
σ2(E1 + . . . + En) =
n

i=1
σ2(Ei) = np(1 −p) .
3. Geometric distribution: we need to compute P(X2) as we have already computed:
P(X) =
+∞

i=1
ip(1 −p)i−1 = 1
p .
Hence
P(X2) = p
+∞

i=1
i2(1 −p)i−1 =

p
+∞

i=1
i(i −1)(1 −p)i−1

+ p
+∞

i=1
i(1 −p)i−1
= p(1 −p)
+∞

i=2
i(i −1)(1 −p)i−2 + 1
p
= p(1 −p) d2
d2 p
+∞

i=2
(1 −p)i

+ 1
p
= p(1 −p)
 d2
d2 p
	 
1
1 −(1 −p) −1 −(1 −p)
	
+ 1
p
= 2(1 −p)
p2
+ 1
p
=
2
p2 −1
p .
Therefore the variance of the geometric distribution is given by
σ2(X) = P[X2] −P(X)2 = (1 −p)
p2
.
4. Poisson distribution: if X has Poisson distribution with parameter λ, we have:
P(X2) =
+∞

i=0
i2P(X = i) =
+∞

i=0
i2 λi
i! e−λ = e−λ
+∞

i=0
i(i −1)λi
i! + λe−λ
+∞

i=0
λi
i!
= λ2e−λ
+∞

i=2
λi−2
(i −2)! + λ = λ2e−λ
+∞

k=0
λk
k! + λ = λ2 + λ
where we have used the computation of the expectation of the Poisson distribution.

38
2
Discrete Distributions
We have then
σ2(X) = P(X2) −P(X)2 = λ2 + λ −λ2 = λ .
5. Hypergeometric distribution: with the notation of Sect.2.6, we use the represen-
tation X = E1+· · · + En. The events Ei’s in this case are not stochastically inde-
pendent and are actually pairwise negatively correlated. Indeed, for 0 < H < N
for every pair i, j with i ̸= j, we have:
cov(Ei, E j) = P(Ei E j) −P(Ei)P(E j) = H
N 2
H −N
N −1 < 0
as
P(Ei E j) = H(H −1)DN−2
n−2
DNn
= H(H −1)
N(N −1)
DN−2
n−2
DN−2
n−2
= H(H −1)
N(N −1) .
Here we have used formula (1.12); possible cases are sequences with no repetition
of length n from a set of N elements, whereas in counting favorable cases we
ﬁrst select two different white balls for the ith and the jth drawings and then the
remaining n −2 balls from a set of N −2 elements.
The variance of X is then obtained by means of the formula for the variance of
the sum of n random numbers:
σ2(X) =
n

i=1
σ2(Ei) +

i, j
i̸= j
cov(Ei, E j)
= n H
N (1 −H
N ) + n(n −1) H
N 2
H −N
N −1 = n N −n
N −1
H
N (1 −H
N ) ,
where n(n −1) is the number of ordered pairs i, j, with i ̸= j, which can be chosen
out of {1, . . . , n}.
2.13
Non-correlation and Stochastic Independence
Let us consider two random numbers X and Y with discrete joint distribution given
by:
p(Xi, Y j) = P(X = xi, Y = y j) = pi, j
and marginal distributions given by:
p1(xi) = P(X = xi) = pi
i = 1, . . . , m ,
p2(y j) = P(Y = y j) = q j
j = 1, . . . , n .

2.13 Non-correlation and Stochastic Independence
39
X and Y are non-correlated if
P(XY) = P(X)P(Y)
i.e. if

i

j
xi y j pi, j =

i
xi pi

j
y jq j .
Moreover, the following relations are satisﬁed:

i pi = 1 and 
j pi, j = pi for i = 1, . . . , m ,

j q j = 1 and 
i pi, j = q j for j = 1, . . . , n ,

i

j
pi, j = 1 .
Assume that we want to ﬁnd values pi, j of the joint distribution, such that X and Y are
non-correlated and have two ﬁxed marginal distributions {pi}i=1,...,m and

q j

j=1,...,n.
We observe ﬁrst of all that pi, j must satisfy the relation 
i, j pi, j = 1. In order to
determine the marginal distributions we must verify other additional (m−1)+(n−1)
linear relations. We have (m−1)+(n−1) and not m+n, since once (m−1)+(n−1)
relations are satisﬁed, the last two follow from the fact that 
i, j pi, j = 1, 
i pi = 1,

j q j = 1. Finally in order to impose non-correlation, an extra linear relation must
be veriﬁed on the pi, j’s:

i

j
pi, jxi y j = m1m2,
where m1 = m
i xi pi and m2 = n
j y jq j. We have therefore a system of 1 +
(m −1) + (n −1) + 1 = m + n linear equations for mn unknowns. This system has
the solution pi, j = piq j, for which X and Y are stochastically independent. This will
be the only solution if the number of linearly independent equations is equal to the
number of the unknowns, i.e. if m + n = mn, or mn−m−n = (m−1)(n−1)−1 = 0.
This happens only if m = n = 2. It follows that non-correlation does not imply in
general stochastic independence. If m = n = 2, then there is just one solution so
that non-correlation and stochastic independence coincide. This is the case of events:
two events are non-correlated if and only if they are stochastically independent.
In Sect.2.11 we have shown that stochastic independence implies non-correlation
and that in fact it implies non-correlation of any two functions of the random numbers.
2.14
Generating Function
Let X be a random number with discrete distribution on a subset of N. The generating
function of X is deﬁned for u ∈C, |u| ≤1, by

40
2
Discrete Distributions
φX(u) := P(u X) =

k∈I (X)
ukP(X = k).
(2.5)
The expectation of a complex random variable is deﬁned as the expectation of the
real part plus i times the expectation of the imaginary part. The condition |u| ≤1
guarantees that the series (2.5) is convergent in the case of inﬁnitely many possible
values. We will use characteristic functions just for real values of u. We have that
φX(0) = P(X = 0).
In general, computing the nth derivative of (2.5) in u = 0, we obtain
P(X = n) = 1
n!
dnφX(u)
dxn

u=0,
for every n ∈N. This shows that the probability distribution of X can be obtained
from its generating function.
Proposition 2.14.1 If P(X) = 
k∈I (X) kP(X
= k) < ∞, then P(X) =
limu→1−φ′
X(u). Moreover P(X) = 
k∈I (X) kP(X = k) = +∞if and only if
limu→1 φ′
X(u)= ∞.
This is a particular case of the following result.
Proposition 2.14.2 If P(X(X −1) . . . (X −k + 1)) = 
k∈I (X)(k(k −1) . . . (k −
n + 1))P(X = k) < ∞, then
P(X(X −1) . . . (X −k + 1)) = lim
u→1−φ(n)
X (u) .
Furthermore 
k∈I (X)(k(k −1) . . . (k −n + 1))P(X = k) = ∞if and only if
limu→1−φ(n)
X (u) = ∞.
Previous results are easily obtained by taking the derivatives of the generating func-
tion. In particular the variance of X can be obtained from the generating function:
σ2(X) = P(X2) −P(X)2 = lim
u→1−

φ′′
X(u) + φ′
X(u) −

φ′
X(u)
2
,
where φ′
X and φ′′
X denote respectively the ﬁrst and the second derivatives of φX.
Generating functions of some common discrete distributions are easily obtained:
1. Event E with probability p
φE(u) = up + (1 −p).

2.14 Generating Function
41
2. Binomial distribution Bn(n, p) with parameters n, p:
φX(u) =
n

k=0
uk
n
k
	
pk(1 −p)n−k
=
n

k=0
 n
k
	
(up)k(1 −p)n−k = (up + (1 −p))n ,
where Newton’s binomial formula has been used.
3. Geometric distribution with parameter p:
φX(u) =
∞

k=1
uk p(1 −p)k−1
= up
∞

k=1
[u(1 −p)]k−1 =
up
(1 −u(1 −p)),
where the formula for the sum of geometric series has been used.
4. Poisson distribution with parameter λ:
φX(u) =
∞

k=0
uk λk
k! e−λ
= e−λ
∞

k=0
(uλ)k
k!
= e−λ(1−u).
If X and Y are two stochastically independent random numbers with values in N, i.e.
P(X = i, Y = j) = P(X = i)P(Y = j) for all i, j ∈I (X) × I (Y), then it is easy
to show that
φX+Y(u) = φX(u)φY(u).
Indeed:
φX+Y(u) = P(u X+Y) = P(u XuY)
=

i

j
uiu jP(X = i, Y = j)
=

i

j
uiu jP(X = i)P(Y = j)
=

i
uiP(X = i)
 ⎛
⎝
j
u jP(Y = j)
⎞
⎠
= φX(u)φY(u) .

42
2
Discrete Distributions
Of course if we have n stochastically independent random numbers we obtain sim-
ilarly: φX1+···+Xn(u) = φX1(u) . . . φXn(u). One can also consider the case of the
sum of a random number N of stochastically independent random numbers. Let
X1, X2, . . . be an inﬁnite sequence of stochastically independent random numbers
with values in N. This means that if we take any ﬁnite number of them, they are
stochastically independent. We assume that X1, X2, . . . are identically distributed.
Let N be a random number with values in N, such that
N, X1, X2, . . .
are stochastically independent. Let SN be deﬁned by
SN = X1 + · · · + X N.
We now compute the generating function of SN:
φSN (u) = P(uSN ) =

k∈I (N)
P(uSN |N = k)P(N = k)
=

k∈I (N)
P(uSk)P(N = k)
=

k∈I (N)
P(N = k)P(u X1+···+Xk)
=

k∈I (N)
P(N = k)φX1(u) . . . φXk(u)
=

k∈I (N)
P(N = k)φX1(u)k
= φN

φX1(u)

,
where φN is the generating function of X and we have used the fact that the random
numbers Xi have the same distribution and hence the same generating function. See
e.g. [3] or [6] for a more complete treatment of generating functions.

Chapter 3
One-Dimensional Absolutely Continuous
Distributions
3.1
Introduction
For random numbers with discrete distribution, the distribution is completely spec-
iﬁed by the probabilities of taking single values. If we want to introduce random
numbers that take values on intervals or on the whole line, then the speciﬁcation
of the probabilities of taking single values is no longer sufﬁcient to determine their
distributions. For example for a random number corresponding to a random choice
in an interval [a, b], the probabilities of taking single values must be clearly equal
to 0, but that in no way speciﬁes the probability of taking value in a subinterval of
[a, b]. In the following we will see how it is possible to describe the distribution of
a random number in general.
3.2
Cumulative Distribution Function
Given a random number X, its cumulative distribution function (c.d.f) is deﬁned by:
F(x) = P(X ≤x), for x ∈R.
The cumulative distribution function F(x) veriﬁes the following properties:
1. 0 ≤F(x) ≤1 since it is the probability of an event.
2. It is non-decreasing: for a < b we have F(b) −F(a) = P(a < X ≤b) ≥0, so
that F(a) ≤F(b).
We introduce now some further properties that are usually assumed to be veriﬁed
by cumulative distribution function. They can be thought of as regularity properties,
as they state that the probability of an event E is equal to the limit of the sequence
P(En), where En is a monotonic sequence converging to E. In particular:
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_3
43

44
3
One-Dimensional Absolutely Continuous Distributions
1. continuity from the right: F(x) = lim
y→x+ F(y);
2. limit from the left: lim
y→x−F(y) = P(X < x);
3.
lim
x→+ ∞F(x) = 1;
4.
lim
x→−∞F(x) = 0.
In all examples of p.d.f.’s these extra properties will be satisﬁed, even if it is
possible to consider cases where they do not hold true. It follows from 1 and 2 that
P(X = x0) = P((X ≤x0) −(X < x0)) = F(x0) −F(x−
0 )
where F(x−
0 ) denotes limx→x−
0 F(x). This limit always exists as F(x) is bounded
non-decreasing.
Example 3.2.1 (Discrete case) In the case of a random number X with discrete
distribution I (X) = {x1, x2, . . .} one has:
F(x) = P(X ≤x) =

xi≤x
P(X = xi).
The probability that a random number X takes value in an interval (a, b] can be
obtained from its c.d.f. F by:
P(a < X ≤b) = P((X ≤b) −(X ≤a))
= P(X ≤b) −P(X ≤a)
= F(b) −F(a).
3.3
Absolutely Continuous Distributions
Let X be a random number. We say that X has absolutely continuous distribution
if there exists a function f : R →R+ with such that the c.d.f. F(x) of X can be
written as:
F(x) =
 x
−∞
f (t)dt.
The function f is the called a probability density function (p.d.f.) of X. Note that
f is not unique. Indeed if the values of f are changed on a ﬁnite set of points, the
new function is still a density of X, as its integrals are the same. It follows from
fundamental theorem of calculus that if x is a continuity point of f , then
f (x) = F′(x).

3.3 Absolutely Continuous Distributions
45
Since limx→∞F(x) = 1, then if f is a p.d.f. of X we have
 ∞
−∞
f (x)dx = lim
x→∞
 x
−∞
f (y)dy = lim
x→∞F(x) = 1.
If x is a continuity point of f , then f (x) ≥0. Indeed assume that f (x) < 0, then by
continuity there would be a neighborhood (a, b) of x where f is still strictly negative
but then
F(b) = F(a) +
 b
a
f (x)dx < F(a),
so that F would not be non-decreasing. We have that for a < b
P(a < X ≤b) = F(b) −F(a) =
 b
−∞
f (x)dx −
 a
−∞
f (x)dx =
 b
a
f (x)dx.
Let us now see how to compute the expectation of X from the p.d.f. f . We consider
the particular case when I (X) is contained in some interval [a, b] and the p.d.f.
f is continuous (and zero outside [a, b]). We subdivide [a, b] into n intervals Ii,
i = 1, . . . , n of length b−a
n . It is not important that the extremes are included: we
assume that the intervals are closed on the r.h.s. and open on the l.h.s. except for I1
that is closed on both sides. We deﬁne two random numbers with discrete distribution
X(n)
−and X(n)
+ : if X takes value in Ii, then X(n)
−is equal to the left endpoint of Ii,
X(n)
+ is equal to the right endpoint. Since X(n)
−and X(n)
+ have discrete distribution
with a ﬁnite number of possible values, we can compute their expectations using the
formula (1.10). They are given by:
P(X(n)
−) =
n−1

j=0

a + j b −a
n
  a+( j+1) b−a
n
a+ j b−a
n
f (x)dx;
P(X(n)
+ ) =
n−1

j=0

a + ( j + 1)b −a
n
  a+( j+1) b−a
n
a+ j b−a
n
f (x)dx.
Since X(n)
−≤X ≤X(n)
+ , then
P(X(n)
−) ≤P(X) ≤P(X(n)
+ ).
It is easy to see, using the continuity of f (x), that as n →∞both P(X(n)
−) and
P(X(n)
+ ) converge to
 b
a
x f (x)dx =

R
x f (x)dx,

46
3
One-Dimensional Absolutely Continuous Distributions
that is hence the value of P(X). Approximation arguments lead to extend this formula
to the case of a general X with absolutely continuous distribution with probability
density f (x) provided that

R
|x| f (x)dx < ∞,
(3.1)
i.e. one assume that, when (3.1) holds true, the expectation of X in the absolutely
continuous case is given by:
P(X) =
 +∞
−∞
x f (x)dx.
Analogously if ψ : R →R is a real function such that ψ(x) f (x) is integrable, we
are lead to assign to P(ψ(X)) the value
P(ψ(X)) =
 +∞
−∞
ψ(x) f (x)dx.
(3.2)
It follows that the variance can be obtained by:
σ2(X) = P(X2) −P(X)2
=
 +∞
−∞
x2 f (x) dx −
 +∞
−∞
x f (x) dx
2
,
provided that the integrals exist. In the following sections we shall introduce some
of the most common one-dimensional absolutely continuous distributions.
3.4
Uniform Distribution in [0, 1]
A random number X has uniform distribution in [0, 1] if its c.d.f. is given by:
F(x) =
⎧
⎨
⎩
0 x ≤0,
x 0 < x < 1,
1 x ≥1.
It is a continuous distribution since
P(X = x) = F(x) −F(x−) = 0
for every x ∈R. Indeed it is easy to check that it is an absolutely continuous distri-
bution with p.d.f. f (x) given by:

3.4 Uniform Distribution in [0,1]
47
f (x) =
⎧
⎨
⎩
0 x ≤0,
1 0 < x < 1,
0 x ≥1.
As in the following examples the values of the p.d.f. in discontinuity points can be
chosen in an arbitrary way. The expectation is given by
P(X) =

R
x f (x) dx =
 1
0
x dx =
	x2
2

1
0
= 1
2,
and the variance by
σ2(X) =
 1
0
x2 dx −1
4 =
	x3
3

1
0
−1
4 = 1
12.
3.5
Uniform Distribution on an Arbitrary Interval [a, b]
A random number X has uniform distribution in [a, b] if its c.d.f. is given by:
F(x) =
⎧
⎨
⎩
0
x ≤a,
c(x −a) a < x < b,
1
x ≥1.
In order to compute the constant c, we impose the continuity in the point x = b and
get c(b −a) = 1, that is:
c =
1
b −a .
The expectation is given by:
P(X) =
 b
a
x
b −a dx =
	
x2
2(b −a)

b
a
= a + b
2
,
and the variance by:
σ2(X) = P((X −P(X))2 =
 b
a
1
b −a

x −a + b
2
2
dx
=
1
b −a
1
3

x −a + b
2
3b
a
= (b −a)2
12
.

48
3
One-Dimensional Absolutely Continuous Distributions
3.6
Exponential Distribution
A random number X has exponential distribution with parameter λ if its c.d.f. is
given by:
F(x) =
1 −e−λx x ≥0,
0
x < 0.
If X is the time when a certain fact happens (for example when the atom of some
isotope decays), the exponential distribution has the property of absence of memory.
Given x, y ≥0 we have:
P(X > x + y | X > y) = P(X > x).
(3.3)
i.e. the probability that the fact does not occur for an extra amount of time x, given
that has not occurred up to time y, is the same as the probability starting from the
initial time. We obtain (3.3) by using the formula of composite probability:
P(X > x + y | X > y) = P(X > x + y, X > y)
P(X > y)
= P(X > x + y)
P(X > y)
= e−λ(x+y)
e−λy
= e−λx
= P(X > x).
In the following we shall see that the exponential distribution can be obtained as
limit of suitably rescaled geometric distributions. Geometric distribution has also the
property of absence of memory for discrete times, as we have remarked in Sect.2.4.
The expectation of exponential distribution with parameter λ is equal to
P(X) =
 +∞
0
λxe−λx dx =

−xe−λx+∞
0
+
 +∞
0
e−λx dx = 1
λ.
The variance is equal to
σ2(X) = P(X2) −P(X)2
=
 +∞
0
λx2e−λx dx −1
λ2
=

−x2e−λx+∞
0
+ 2
 +∞
0
xe−λx dx −1
λ2
= 2
λ2 −1
λ2
= 1
λ2 .

3.7 A Characterization of Exponential Distribution
49
3.7
A Characterization of Exponential Distribution
The exponential distribution can be characterized in terms of its hazard rate.
Given a non-negative random variable with absolutely continuous distribution
that describes the time of occurence of some fact, its hazard rate h(x) at time x is
deﬁned by:
h(x) = lim
h→0
P(x < X < x + h|X > x)
h
.
We can express h(x) in terms of the probability density. Let
F(x) = P(X ≤x) =
 x
−∞
f (y)dy.
Then
lim
h→0
P(x < X < x + h)
hP(X > x)
=
f (x)
1 −F(x) = −d
dx log(1 −F(x)).
For exponential distribution with parameter λ, it is easy to see that the hazard rate is
equal to λ for all x. Indeed:
h(x) =
f (x)
1 −F(x) = λe−λx
e−λx
= λ.
Exponential distribution can be characterized as the unique distribution with constant
hazard rate. To see that, we ﬁrst show that c.d.f. can be obtained from the hazard
rate.
Since X is assumed to be non-negative and with absolutely continuous distribu-
tion, we have: F(0) = P(X ≤0) = 0. Using that
h(x) = −d
dx log(1 −F(x)),
we have that for x ≥0
log(1 −F(x)) = −
 x
0
h(y)dy
(3.4)
= 1 −F(x) = exp

−
 x
0
h(y)dy

(3.5)
= F(x) = 1 −exp

−
 x
0
h(y)dy

.
(3.6)
If the hazard rate is constant equal to λ > 0, then
F(x) = 1 −e−λx,
x > 0,

50
3
One-Dimensional Absolutely Continuous Distributions
since X is non-negative, F(x) = 0 for x < 0. Therefore X has exponential distribu-
tion with parameter λ.
3.8
Normal Distribution
A random number X has standard normal distribution N(0, 1) if its probability
density function is:
n(x) = Ke−x2
2 , x ∈R.
Although the indeﬁnite integral of e−x2
2 cannot be expressed in terms of elementary
functions, it can still be computed over the whole line and so the constant K. We
have:
 +∞
−∞
e−x2
2 dx
2
=
 +∞
−∞
 +∞
−∞
e−x2
2 e−y2
2 dxdy
=
 
e−x2+y2
2
dxdy
=
 2π
0
 +∞
0
e−r2
2 r drdθ
= 2π
 +∞
0
e−r2
2 r dr
= 2π

−e−r2
2
+∞
0
= 2π,
where a change to polar coordinates x = r cos θ, y = r sin θ has been used. The
Jacobian determinant of this change of variable is r (see Appendix H).
It follows that
 +∞
−∞e−x2
2 =
√
2π and so
K =
1
√
2π
.
The cumulative distribution function will be denoted by N(x):
N(x) :=
 x
−∞
n(t) dt.
Since n is an even function and its integral over the whole line is equal to 1, we
have:
N(−x) = 1 −N(x).

3.8 Normal Distribution
51
Therefore in tables of N(x), only values for positive values of x are usually tabulated.
The expectation of standard normal distribution is
P(X) =
 +∞
−∞
x n(x) dx = 0,
as it follows immediately since f (x) = −f (x), where f (x) = xn(x), x ∈R. The
variance of standard normal distribution is obtained by integration by parts, using
the fact that n′(x) = −xn(x):
σ2(X) = P(X2) =
 +∞
−∞
x2n(x) dx = [−xn(x)]+∞
−∞+
 +∞
−∞
n(x) dx = 1.
We introduce now the general normal distribution which has two parameters m, σ2
and will be denoted by N(m, σ2). We start with X ∼N(0, 1) and consider Y =
m + σX, where σ > 0. Then Y has normal distribution N(m, σ2). The c.d.f. of Y is
given by:
FY(y) = P(Y ≤y)
= P(m + σX ≤y)
= P

X ≤y −m
σ

= N
 y −m
σ

.
The probability density function of Y is obtained by chain rule for the derivative of
a composite function:
fY(y) = d
dy N
 y −m
σ

= 1
σ n
 y −m
σ

=
1
σ
√
2π
e−(y−m)2
2σ2 .
The expectation and the variance of Y are obtained as follows:
P(Y) = P(σX + m) = σP(X) + m = m
σ2(Y) = σ2(σX + m) = σ2σ2(X) = σ2.
3.9
Normal Tail Estimate
As we have said, there is no formula in terms of elementary functions for N(x) and
therefore for the probability that a random number X ∼N(0, 1) is greater than some
x > 0. It is however possible to give asymptotic estimates for this probability as x
tends to inﬁnity.

52
3
One-Dimensional Absolutely Continuous Distributions
Proposition 3.9.1 Let X be a random number with standard normal distribution.
For every x > 0, we have:
n(x)
x
−n(x)
x3
< P(X ≥x) < n(x)
x
,
where n(x) :=
1
√
2π
e−x2
2 .
The upper bound is obtained by integration by parts:
P(X ≥x) =
 +∞
x
n(t) dt =
 +∞
x
t n(t)
t
dt
=
	
−n(t)
t

+∞
x



n(x)
x
−
 +∞
x
n(t)
t2

>0
dt < n(x)
x
.
A second integration by parts gives the lower bound:
P(X ≥x) = n(x)
x
−
 +∞
x
t n(t)
t3 dt
= n(x)
x
−
	
−n(t)
t3

+∞
x



n(x)
x3
+
 +∞
x
3n(t)
t4
  
>0
dt > n(x)
x
−n(x)
x3 .
3.10
Gamma Distribution
Let α and λ be strictly positive real numbers. The random number X is said to have
gamma distribution Γ (α, λ) if its probability density function is given by
gα,λ(x) =
 K xα−1 e−λx x > 0,
0
x ≤0.
Note that exponential distribution is a particular case of gamma distribution corre-
sponding to the choice α = 1.
The normalizing constant K can be expressed in terms of Euler’s gamma function
Γ (α):
Γ (α) =
 +∞
0
xα−1 e−x dx

3.10 Gamma Distribution
53
for α > 0. The function Γ satisﬁes the recursive property:
1. Γ (α + 1) = αΓ (α), since
Γ (α + 1) =
 +∞
0
xα e−x dx
=

−xα e−x+∞
0
+
 +∞
0
αxα−1 e−x dx
= α Γ (α).
2. It follows by iteration that for integer α > 0
Γ (α) = (α −1)!
since Γ (1) =
 +∞
0
e−xdx = 1.
Now for the p.d.f. gα,λ we have
1 =
 +∞
−∞
gα,λ(x) dx = K
 +∞
0
xα−1 e−λxdx = K
λα
 +∞
0
yα−1e−y dy = K
λα Γ (α).
Hence
K =
λα
Γ (α).
The expectation and the variance of the gamma distribution can be computed
using the recurrence property of gamma function:
P(X) =
 +∞
−∞
xgα,λ(x) dx
=
λα
Γ (α)
 +∞
0
xα e−λx dx
=
λα
Γ (α)
Γ (α + 1)
λα+1
= α
λ .
It follows that:
σ2(X) = P(X2) −P(X)2 = α(α + 1)
λ2
−α2
λ2 = α2
λ2 .

54
3
One-Dimensional Absolutely Continuous Distributions
3.11
χ2-Distribution
From the normal distribution we can derive another distribution of wide use in sta-
tistics, the χ2-distribution. In this section we introduce the χ2-distribution with
parameter ν = 1. In Chap.4 we shall consider general χ2-distributions with parame-
ter ν ∈N \ {0}.
Let X be a random number with standard normal distribution N(0, 1) and let
Y = X2. We ﬁrst consider the c.d.f. of Y. If y < 0
FY(y) = P(Y ≤y) = 0
since Y is non-negative. If y ≥0, then
FY(y) = P(Y ≤y) = P(X2 ≤y)
= P(−√y ≤X ≤√y)
= N(√y) −N(−√y)
= N(√y) −(1 −N(√y))
= 2N(√y) −1.
The c.d.f. of Y is therefore
FY(y) =
0
for y < 0,
2N(√y) −1 for y ≥0.
Let us compute the p.d.f. fY of Y (for y > 0):
fY(y) = F′
Y(y) = 2n(y) 1
√y
=
1
√
2π
1
√y e−y
2 =
1
√
2π
y
1
2 −1e−1
2 y,
where the derivative has been computed by using chain rule for the derivative of
composite functions. The density fY(y) is of course zero for negative y. It follows
that Y has distribution Γ ( 1
2, 1
2). Moreover by comparing the normalizing constants,
we get
1
√
2
1
√π =
1
2
 1
2
1
Γ
 1
2
,
so that
Γ
1
2

= √π.

3.11 χ2-Distribution
55
By using the recurrence formula Γ (α + 1) = αΓ (α), we have:
Γ
2k + 1
2

= (2k −1)(2k −3) · · · 1
2k
√π
2
for k = 1, 2, . . ..
3.12
Cauchy Distribution
We now consider a distribution for which the expectation deﬁned in Sect.3.3 does not
exist. This is the Cauchy distribution. This is the distribution of a random number
Y = tan Θ, where the random number Θ has uniform distribution in the interval
[−π
2 , π
2 ]. We have for y ∈R that:
FY(y) = P(Y ≤y) = P(tan Θ ≤y)
= P(Θ ≤arctan y).
The p.d.f. of Y fY is obtained by deriving FY:
fY(y) =
1
π

1 + y2.
The formula for the expectation of Y gives an integral

y
π

1 + y2dy
which is undeﬁned, as the integrand behaves like 1
y for y →∞.
3.13
Mixed Cumulative Distribution Functions
In addition to discrete and absolutely continuous c.d.f.’s, there are continuous but
not absolutely continuous c.d.f.’s. These will be not considered in this elementary
book. Here we brieﬂy speak about mixed c.d.f.’s that are convex linear combinations
of discrete and absolutely continuous c.d.f.’s.
For 0 < p < 1, let F1 be a discrete c.d.f. and F2 be an absolutely continuous c.d.f.
Then we can consider a c.d.f. F(x):
F(x) = pF1(x) + (1 −p)F2(x),

56
3
One-Dimensional Absolutely Continuous Distributions
which is neither of discrete nor of absolutely continuous type. F(x) is said to be
a mixed c.d.f. If X is a random number with c.d.f. F(x), it is easy to see that the
expectation of a function φ(X) is given by
P(φ(X)) = pP(φ(X1)) + (1 −p)P(φ(X2)),
where X1 and X2 are random numbers with c.d.f. F1 and F2 respectively, provided
that the terms on the right-hand side both make sense. The ﬁrst term is expressed by
a sum or a series, while the second by an integral.
An example of random number with mixed c.d.f is the time T of function of some
device, for example a lamp, when there is a positive probability p that the device
does not work already at the initial time and otherwise the distribution is absolutely
continuous, for example exponential with parameter λ. The c.d.f of T is then given
by:
FT (t) =

0
for t < 0,
p + (1 −p)(1 −e−λt) for t ≥0.
It is easy to check that P(T ) = 1 −p
λ
.

Chapter 4
Multi-dimensional Absolutely Continuous
Distributions
4.1
Bidimensional Distributions
Let X, Y be two random numbers that we can consider as a random vector (X, Y).
The joint cumulative distribution function ( j.c.d.f.) is deﬁned as:
F(x, y) = P(X ≤x, Y ≤y).
Then F is a map from R2 to [0, 1]:
F : R2 −→[0, 1].
The probability that (X, Y) belong to the rectangle (a1, b1] × (a2, b2] is given by:
P(a1 < X ≤b1, a2 < Y ≤b2) = P [((X ≤b1) −(X ≤a1)) ((Y ≤b2) −(Y ≤a2))]
= P(X ≤b1, Y ≤b2) −P(X ≤a1, Y ≤b2)
−P(X ≤b1, Y ≤a2) + P(X ≤a1, Y ≤a2)
= F(b1, b2) −F(a1, b2) −F(b1, a2) + F(a1, a2).
(4.1)
We shall always assume that the following continuity properties are veriﬁed:
1.
lim
x→+∞
y→+∞
F(x, y) = 1;
2.
lim
x→−∞F(x, y) =
lim
y→−∞F(x, y) = 0;
3.
lim
x→x+
0
y→y+
0
F(x, y) = F(x0, y0);
4. P(X = x0, Y = y0) = F(x0, y0) −F(x−
0 , y0) −F(x0, y−
0 ) + F(x−
0 , y−
0 ),
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_4
57

58
4
Multi-dimensional Absolutely Continuous Distributions
where F(x−
0 , y0) := limx→x−
0 F(x, y0), F(x0, y−
0 ) := limy→y−
0 F(x0, y) and F(x−
0 ,
y−
0 ) := lim
x→x−
0
y→y−
0
F(x, y).
Other analogous properties will also be assumed. We shall quote them when they
will be needed.
4.2
Marginal Cumulative Distribution Functions
Given two random numbers X, Y with j.c.d.f. F(x, y), the c.d.f.’s F1, F2 of X and
Y are called marginal cumulative distribution functions (m.c.d.f.’s).
The m.c.d.f. of X is obtained from the j.c.d.f. by taking the limit:
F1(x) = P(X1 ≤x) =
lim
y→+∞F(x, y),
as follows by usual continuity hypothesis. Similarly the m.c.d.f. of Y is obtained by:
F2(y) = P(Y ≤y) =
lim
x→+∞F(x, y).
Two numbers are said to be stochastically independent if:
F(x, y) = F1(x)F2(y)
for every (x, y) ∈R2.
4.3
Absolutely Continuous Joint Distributions
Two random numbers X, Y or equivalently the random vector (X, Y) has an
absolutely continuous distribution if there exists a function f
f : R2 −→R
such that the j.c.d.f. F of X, Y can be expressed as:
f (X, Y) =
 x
−∞
 y
−∞
f (s, t) dsdt.
Such function f is called joint probability density (j.p.d.). Applying formula (4.1)
for the probability that (X, Y) belong to a rectangle (a, b] × (c, d], we get:

4.3 Absolutely Continuous Joint Distributions
59
P(a < X ≤b, c < Y ≤d) = F(b, d) −F(a, d) −F(c, b) + F(a, c)
=
 b
∞
 d
∞
f (s, t) dsdt −
 a
∞
 d
∞
f (s, t) dsdt
−
 b
∞
 c
∞
f (s, t) dsdt +
 a
∞
 c
∞
f (s, t) dsdt
=
 b
a
 d
c
f (s, t) dsdt.
By usual limiting procedure one gets that the probability that a random vector
(X, Y) belongs to a sufﬁciently regular region A of R2 is given by the integral of the
j.p.d.f. over A, i.e.
P((X, Y) ∈A) =
 
A
f (s, t) dsdt.
Moreover, if ψ : R2 →R is a sufﬁciently regular function such that the function ψ f
is integrable, then, as in the one-dimensional case, we have that for Z = ψ(X, Y)
P(Z) =
 
R2 ψ(s, t) f (s, t) dsdt.
(4.2)
For example, if Z = XY we get
P(XY) =
 
R2 st f (s, t) dsdt,
if the integrand function st f (s, t) is integrable. In order to derive probability densities
of X and Y, that are called marginal probability densities, we start by deriving their
c.d.f.’s:
FX(x) = P(X ≤x) =
 +∞
−∞
 x
−∞
f (s, t) dsdt.
It follows that the marginal probability density of X is given by:
fX(x) =
 +∞
−∞
f (x, t) dt.
Analogously fY, the marginal probability density of Y, is given by
fY(y) =
 +∞
−∞
f (s, y) ds.
It is easy to check out that, if f (X, Y) can be expressed as a product of two functions,
f (x, y) = u(x)v(y),

60
4
Multi-dimensional Absolutely Continuous Distributions
then X and Y are stochastically independent and their marginal probability densities
are proportional to u(x) and v(y). Conversely if X and Y are stochastically indepen-
dent and their joint distribution is absolutely continuous, then their joint probability
density can be expressed as the product of their marginal probability densities:
f (x, y) = fX(x) fY(y).
(4.3)
As in the case of discrete distributions, it follows from (4.3) that if X, Y are
stochastically independent and φ1, φ2 are real functions such that φ1 fX and φ2 fY are
integrable, then by Fubini’s theorem we obtain:
P(φ1(X)φ2(Y)) = P(φ1(X))P(φ2(Y)).
4.4
The Density of Z = X + Y
Let X and Y be two random numbers with joint probability density f (x, y). We want
to determine the density of
Z = X + Y.
First we compute the c.d.f. of Z:
FZ(z) = P(Z ≤z) = P(X + Y ≤z) =
 +∞
−∞
 z−x
−∞
f (x, y) dydx
=
 +∞
−∞
 z
−∞
f (x, t −x) dtdx =
 z
−∞
 +∞
−∞
f (x, t −x) dxdt,
where we have made the change of variable t = x + y for ﬁxed x, that allows then
to exchange the order of integration in the ﬁnal equality. It follows from the last
expression that
fZ(z) =
 z
−∞
fz(t) dt
with
fZ(z) =
 +∞
−∞
f (x, z −x) dx,
i.e. fZ is the density of Z. In particular when X and Y are stochastically independent
and f (x, y) = fX(x) fY(y), then
fZ(z) =
 +∞
−∞
fX(x) fY(z −x) dx.

4.4 The Density of Z = X + Y
61
Hence fZ is obtained by the convolution of fX and fY and is denoted by fX ∗fY. An
example of application of this formula is the sum of two stochastically independent
gamma distributed random numbers with parameters respectively α, λ and β, λ.
Using the previous formula we obtain the probability density of Z = X + Y:
fZ(z) =
 +∞
−∞
fX(x) fY(z −x) dx
=
 +∞
−∞
λα
Γ (α) xα−1 e−λx I{x > 0}
λβ
Γ (β) (z −x)β−1 e−λ(z−x) I{(z−x) > 0} dx,
where IA denotes the indicator function of the set A. The integral can be written as
λα+β
Γ (α)Γ (β) e−λz
 z
0
xα−1(z −x)β−1dx
if z > 0 and it is equal to 0 if z ≤0. For z > 0 we make the change of variable
dx = zdt and obtain
fZ(z) =
λα+β
Γ (α)Γ (β) e−λz
 z
0
xα−1(z −x)β−1 dx
=
λα+β
Γ (α)Γ (β) e−λz
 1
0
(zt)α−1(z −zt)β−1z dt
=
λα+β
Γ (α)Γ (β) zα+β−1e−λz
 1
0
tα−1 (1 −t)β−1 dt
=
λα+β
Γ (α)Γ (β)
 1
0
tα−1 (1 −t)β−1 dt zα+β−1e−λz
= K zα+β−1e−λz,
with
K =
λα+β
Γ (α) Γ (β)
 1
0
tα−1 (1 −t)β−1 dt.
(4.4)
It follows that Z has distribution Γ (α + β, λ).
Remark 4.4.1 Since the constant K must be equal to the normalizing constant of the
distribution Γ (a + b, λ), by (4.4) we obtain
K =
λα+β
Γ (α + β)
 1
0
tα−1 (1 −t)β−1 dt =
λα+β
Γ (α + β),
so that
 1
0
tα−1 (1 −t)β−1 dt = Γ (α) Γ (β)
Γ (α + β) .

62
4
Multi-dimensional Absolutely Continuous Distributions
4.5
Beta Distribution B(α, β)
Let α > 0 and β > 0. A random number X is said to have beta distribution B(α, β)
if its density f (x) is given by
f (x) =
⎧
⎨
⎩
K xα−1 (1 −x)β−1 x ∈[0, 1],
0
otherwise.
It follows from the computation at the end of the previous section that
K =
1
 1
0 xα−1 (1 −x)β−1 dx
= Γ (α + β)
Γ (α) Γ (β).
(4.5)
The expectation can be obtained from the recursion property of Euler’s gamma
function. If X has B(α, β) distribution, then
P(X) = Γ (α + β)
Γ (α) Γ (β)
 1
0
x f (x) dx.
The value of the integral is obtained by (4.5) by replacing α with α + 1 so that
P(X) = Γ (α + β)
Γ (α) Γ (β)
Γ (α + 1)Γ (β)
Γ (α + β + 1) = αΓ (α)
Γ (α)
Γ (α + β)
(α + β)Γ (α + β) =
α
α + β .
Similarly we can compute P(X2):
P(X2) = Γ (α + β)
Γ (α) Γ (β)
 1
0
xα+1 (1 −x)β−1 dx
= Γ (α + β)
Γ (α) Γ (β)
Γ (α + 2) Γ (β)
Γ (α + β + 2) ,
where the integral is obtained by replacing α with α + 2 in formula (4.4). By using
the recursion property of the Gamma function we get
Γ (α + 2) = (α + 1)α Γ (α)
Γ (α + β + 2) = (α + β + 1) (α + β) Γ (α + β)
so that
P(X2) =
α(α + 1)
(α + β) (α + β + 1)

4.5 Beta Distribution B(α, β)
63
and
σ2(X) = P(X2) −P(X)2
=
(α + 1) α
(α + β + 1) (α + β) −
α2
(α + β)2 =
αβ
(α + β)2 (α + β + 1).
4.6
Student Distribution
We now introduce the Student distribution of parameter ν. Let Z and U be sto-
chastically independent random numbers. We assume that Z has standard normal
distribution and U has gamma distribution Γ
ν
2 , 1
2

where ν ∈N. The latter dis-
tribution is called χ2-distribution with ν degrees of freedom and plays an important
role in statistics. Let T = Z
U
ν
−1
2
. In order to obtain the probability density of
T , we ﬁrst derive its c.d.f.
FT (t) = P(T ≤t) = P(Z ≤t
	
U
ν ) =
 ∞
0
 √u
ν
−∞
f (z, u)dzdu,
where
f (z, u) =
1
2
ν
2 √
2πΓ

 ν
2
e−z2
2 u
ν
2 −1e−u
2 .
By taking the derivative of FT (t) with respect to t, it follows from the fundamental
calculus theorem that for density of the Student distribution is given for t > 0 by
fT (t) = F′
T (t) =
 ∞
0
f (t
	u
ν , u)
	u
ν du
=
1
2
ν
2 √
2πνΓ

 ν
2

 ∞
0
u
ν+1
2 −1e−u
2 (1+ t2
ν )du
=
Γ

 ν+1
2

√πνΓ

 ν
2
(1 + t2
ν )−ν+1
2 ,
where the integral has been computed by using the formula for the normalizing
constant of the gamma distribution. Note that for ν = 1 the Student distribution
coincides with the Cauchy distribution. Since
 +∞
−∞
|t|
(1 + t2
ν )
ν+1
2 dt

64
4
Multi-dimensional Absolutely Continuous Distributions
must be ﬁnite for the existence of P(T ), we have that P(T ) exists and is ﬁnite if and
only if ν > 1. We have that
P(T ) =
Γ

 ν+1
2

√πνΓ

 ν
2

 +∞
−∞
t(1 + t2
ν )−ν+1
2 dt = 0,
since the integrand is an odd function.To compute the variance, we calculate
σ(T ) = P(T 2) = P
νZ2
U

= νP(Z2)P
 1
U

= νP
 1
U

=
ν
2
ν
2 Γ

 ν
2

 ∞
0
1
u u
ν
2 −1e−u
2 du =
ν
2
ν
2 Γ

 ν
2

 ∞
0
u
ν−2
2 −1e−u
2 du
=
ν
2
ν
2 Γ

 ν
2
2
ν−2
2 Γ
ν −2
2

=
ν
ν −2.
Hence the variance exists ﬁnitely if ν > 2.
4.7
Multi-dimensional Distributions
Let (X1, X2, . . . , Xn) be an n-dimensional random vector. The function
F : Rn −→[0, 1]
deﬁned by:
F(x1, x2, . . . , xn) = P(X1 ≤x1, X2 ≤x2, . . . , Xn ≤xn)
is called joint cumulative distribution function (j.c.d.f.) of (X1, X2, . . . , Xn). In the
following we shall always assume that the following continuity properties are satis-
ﬁed by j.c.d.f.’s:
1.
lim
x1,...,xn→+∞F(x1, x2, . . . , xn) = 1;
2.
lim
xi→−∞F(x1, x2, . . . , xn) = 0
3. If {i1, . . . , ik} ⊂{1, 2, . . . , n} and { j1, . . . , jn−k} = {1, 2, . . . , n}\{i1, . . . , ik}
then
lim
x j1,...,x jn−k →+∞F(x1, . . . , xn) = P(Xi1 ≤xi1,...,Xik ≤xik).
Here Fi1,...,ik(xi1, . . . , xik) := P(Xi1 ≤xi1, . . . , Xik ≤xik), xi1, . . . , xik ∈R, is
called the marginal cumulative distribution function (m.c.d.f.) of Xi1, . . . , Xik. As in
the two-dimensional case the probability that X1, . . . , Xn belongs to some intervals
(a1, b1], . . . , (an, bn] can be computed using the j.c.d.f. Precisely:
P(a1 < X1 ≤b1, . . . , an < Xn ≤bn) =

c
(−1)ϵ(c) F(c1, . . . , cn)

4.7 Multi-dimensional Distributions
65
with c = (c1, . . . , cn), where ci can be ai or bi, and ϵ(c) is equal to the number of
i’s such that ci = ai. The proof of this formula is completely analogous to the one
for (4.1) in the two-dimensional case.
The random numbers X1, . . . , Xn are said to be stochastically independent if
F(x1, . . . , xn) = F1(x1) . . . Fn(xn),
where Fi is the m.c.d.f. of Xi for i = 1, . . . , n. If X1, . . . , Xn are stochastically
independent, then
P(a1 < X1 ≤b1, . . . , an < X1 ≤bn) =

c
(−1)ϵ(c)F1(c1) . . . Fn(cn)
= Πn
i = 1(Fi(bi) −Fi(ai))
= Πn
i = 1P(ai < Xi ≤bi).
4.8
Absolutely Continuous Multi-dimensional
Distributions
The random vector (X1, . . . , Xn) has an absolutely continuous distribution if there
exists a function
f : Rn −→R
such that the j.c.d.f. F of (X1, X2, . . . , Xn) is given by:
F(x1, . . . , xn) =
 x1
−∞
 x2
−∞
· · ·
 xn
−∞
f (t1, t2, . . . , tn) dt1dt2 . . . dtn.
It follows from Property 1 of Sect.4.7 that
 +∞
−∞
· · ·
 +∞
−∞
f (t1, . . . , tn) dt1 . . . dtn = 1.
Moreover it can be shown that one can always choose a non-negative f . The function
f is called joint probability density ( j.p.d.) of (X1, . . . , Xn). What we have said
about two-dimensional joint probability density generalizes in a natural way to the
n-dimensional case.
If A is a sufﬁciently regular region A ⊂Rn then
P((X1, . . . , Xn) ∈A) =

· · ·

A
f (t1, . . . , tn)dt1 · · · dtn.

66
4
Multi-dimensional Absolutely Continuous Distributions
If ψ is a function ψ : Rn −→R such that ψ f is integrable, then
P(ψ(X1, . . . , Xn)) =
 +∞
−∞
· · ·
 +∞
−∞
ψ(t1, . . . , tn)dt1 . . . dtn.
If f (t1, . . . , tn) = g1(t1) · · · gn(tn), then X1, . . . , Xn are stochastically independent
and the marginal density of Xi can be taken proportional to gi for i = 1, . . . , n.
Conversely if X1, . . . , Xn are stochastically independent with absolutely continuous
distribution,thej.p.d.of X1, . . . , Xn canbetakenas f (t1, . . . , tn) = f1(t1) . . . fn(tn),
where f1, . . . , fn are marginal probability density functions of X1, X2, . . . , Xn.
4.9
Multi-dimensional Gaussian Distribution
A random vector (X1, X2, . . . , Xn) has n-dimensional Gaussian distribution if its
density has the form:
f (x1, x2, . . . , xn) = Ke−1
2 Ax·x+b·x
where x = (x1, x2, . . . , xn)t ∈Rn, b = (b1, b2, . . . , bn)t ∈Rn and A ∈Rn × n is a
symmetric positive deﬁnite matrix.1 The symbol At denotes the transpose matrix of
A, with elements
[At]i, j = [A] j,i.
We remind that b · x is the scalar product of b and x, given by
b · x =
n

i=1
bixi
and that Ax is the vector with elements
[Ax]i =

j
ai jx j.
Let ai, j denote [A]i, j. The expression Ax · x is a quadratic form

i, j
ai jxix j.
1Recall that a matrix A ∈Rn × n is
• symmetric if At = A, i.e. ai j = a ji,
• positive deﬁnite if Ax · x > 0 for all x ̸= 0, x ∈R.

4.9 Multi-dimensional Gaussian Distribution
67
If we have a quadratic form
Bx · x =

i, j
bi jxix j
we can always replace the matrix B with a symmetric matrix A such that
Ax · x =

i, j
ai jxix j = Bx · x,
where ai j is deﬁned by
ai j =
⎧
⎨
⎩
bii
for i = j,
(bi j + b ji)/2 for i ̸= j.
We consider ﬁrst the simplest case:
Case 1: A diagonal and b = 0
Let
A =
⎛
⎜⎜⎜⎜⎝
λ1 0 · · · 0
0 λ2
... ...
... ... ... 0
0 · · · 0 λn
⎞
⎟⎟⎟⎟⎠
and b = 0. We obtain2
f (x1, x2, . . . , xn) = K exp

−

λ1
x2
1
2 + λ2
x2
2
2 + · · · + λn
x2
n
2

.
By computing the marginal densities, it is easy to get
f (x1, x2, . . . , xn) = fX1(x1) fX2(x2) · · · fXn(xn)
where
fXi(xi) =
	
λi
2π exp

−λi x2
i
2

2Here the notation exp (x) is introduced to denote the exponential function ex.

68
4
Multi-dimensional Absolutely Continuous Distributions
is the marginal density of Xi. It follows that
1. X1, . . . , Xn are stochastically independent;
2. Xi has gaussian density N

0, 1
λi

;
3. the normalizing constant is given by:
K =
	
λ1
2π
	
λ2
2π · · ·
	
λn
2π =

det A
(2π)n .
The expectation vector is given by
(P(X1), . . . , P(Xn)) = (0, . . . , 0)
and the covariance matrix is:
C =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
σ2(X1)
cov(X1, X2)
· · ·
cov(X1, Xn)
cov(X2, X1)
σ2(X2)
...
...
...
...
...
cov(Xn−1, Xn)
cov(Xn, X1)
· · ·
cov(Xn, Xn−1)
σ2(Xn)
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
=
⎛
⎜⎜⎜⎜⎝
1
λ1
0 · · · 0
0
1
λ2
... ...
... ... ... 0
0 · · · 0
1
λn
⎞
⎟⎟⎟⎟⎠
= A−1.
Case 2: Computation of the expectation vector in the general case
Let now A be symmetric and positive deﬁnite and b ̸= 0. By making a translation
we can reduce the density to the case b = 0. Let U = X −c with c ∈R. The j.c.d.f.
of the random vector U can be expressed in terms of that of X:
FU(u) = P(U ≤u) = P(X −c ≤u) = P(X ≤u + c) = FX(u + c).

4.9 Multi-dimensional Gaussian Distribution
69
It follows that the joint probability density can be similarly obtained from that
of X:
fU(u1, u2, . . . , un) = fX(u1 + c1, u2 + c2, . . . , un + cn)
= K ′ exp

−1
2 A(u + c) · (u + c) + b · (u + c)

= K ′ exp

−1
2 Au · u −1
2 Au · c −1
2 Ac · u −1
2 Ac · c + b · u + b · c

= K ′ exp

−1
2 Ac · c + b · c




constant
exp

−1
2 Au · u + (b −Ac) · u

,
where we have used the fact that
Ac · u = Au · c,
since A is symmetric. In order to reduce the density to the case b = 0, we must
choose c so that the ﬁrst degree part cancels, i.e.:
b −Ac = 0.
We choose therefore
c = A−1b.
Note that A is invertible since it is positive deﬁnite. For this choice of c the density
fU(u1, u2, . . . , un) is given by:
fU(u1, u2, . . . , un) = fX(u1 + c1, u2 + c2, . . . , un + cn)
= K ′ exp

A−1b · b −A(A−1b) · A−1b
2

exp

−1
2 Au · u

= K exp
1
2 A−1b · b




K ′
exp

−1
2 Au · u

= K ′ exp

−1
2 Au · u

.
It is easy to see that P(Ui) = 0 for i = 1, 2, . . . , n, since the density of −U and U
are the same. Using previous results, we obtain that
P(Xi) = P(Ui + ci) = P(Ui) + ci = ci = (A−1b)i,
i.e. in vectorial notation:
P(X) = A−1b ;

70
4
Multi-dimensional Absolutely Continuous Distributions
where the expectation of a random vector is deﬁned as the vector of the expectations
of its components. The normalizing constant is
K = K ′ exp
1
2 A−1b · b

,
where K ′ is the normalizing constant for the case with b = 0. The covariance matrix
of X is equal to one ofU, as a translation leaves variances and covariances unchanged:
C =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
σ2(X1)
cov(X1, X2)
· · ·
cov(X1, Xn)
cov(X2, X1)
σ2(X2)
...
...
...
...
...
cov(Xn−1, Xn)
cov(Xn, X1)
· · ·
cov(Xn, Xn−1)
σ2(Xn)
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
=
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
σ2(U1)
cov(U1,U2)
· · ·
cov(U1,Un)
cov(U2,U1)
σ2(U2)
...
...
...
...
...
cov(Un−1,Un)
cov(Un,U1)
· · ·
cov(Un,Un−1)
σ2(Un)
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
.
Case 3: computation of covariance matrix and normalization constant in the
general case
As it is shown we can reduce to the case b = 0 by making a translation. Since A
is symmetric, there exists an orthogonal matrix O, i.e. such that Ot AO = D, where
D is diagonal.
If U is the random vector U = O−1X, its density is given by
f (u1, . . . , un) = K exp

−1
2 A Ou · Ou

= K exp

−1
2 Ot AOu · u

= K exp

−1
2 Du · u

.

4.9 Multi-dimensional Gaussian Distribution
71
Now for U we are in the situation of a diagonal matrix that we have already consid-
ered. The covariance matrix of X, is given by:
C = P(X Xt) = P(OU (OU)t)
= O P(U U t) Ot = O D−1 Ot = A−1.
Here the expectation of a random matrix denotes a matrix whose entries are the
expectations of the corresponding entries. We have used the easily veriﬁable fact
that if Z is a random matrix and A, B are constant matrices, such that the product
AZ B is deﬁned, then P(AZ B) = AP(Z)B.
We have found that in the general case
1. the normalization constant is
K =

det A
(2π)n e−1
2 A−1b·b ;
2. the expectation is
P(X) = A−1b ;
3. the covariance matrix is
C = A−1.
Remark 4.9.1 It is easy to check that the marginal distribution of the Xi’s and of
subsets of the Xi’s are gaussian. In particular, if cov(Xi, X j) = 0 for some i, j i ̸= j,
thenthecovariancematrixof(Xi, X j)isdiagonal,sothat Xi and X j arestochastically
independent as it is shown in the next remark.
Remark 4.9.2 When n = 2, the covariance matrix is given by:
C =
⎛
⎝
σ2
1
ρ σ1σ2
ρ σ1σ2
σ2
2
⎞
⎠
where σ2
1 = σ2(X1), σ2
2 = σ2(X2) and ρ = ρ(X1, X2). The matrix A can be
obtained as:
A = C−1 =
1
det C
⎛
⎝
σ2
2
−ρ σ1σ2
−ρ σ1σ2
σ2
1
⎞
⎠
=
1
σ2
1σ2
2 −ρ2σ2
1σ2
2
⎛
⎝
σ2
2
−ρ σ1σ2
−ρ σ1σ2
σ2
1
⎞
⎠

72
4
Multi-dimensional Absolutely Continuous Distributions
=
1
1 −ρ2
⎛
⎜⎜⎜⎜⎝
1
σ2
1
−
ρ
σ1σ2
−
ρ
σ1σ2
1
σ2
2
⎞
⎟⎟⎟⎟⎠
.
The density of two-dimensional gaussian distribution with parameters m1 = P(X1),
m2 = P(X2), σ2
1 = σ2(X1), σ2
2 = σ2(X2), ρ = ρ(X1, X2) is therefore given by:
f (x, y) =
1
2πσ1σ2

1 −ρ2 ·
exp

−
1
2(1 −ρ2)
(x −m1)2
σ2
1
−2ρ(x −m1)(y −m2)
σ1σ2
+ (y −m2)2
σ2
2

.

Chapter 5
Convergence of Distributions
5.1
Convergence of Cumulative Distribution Functions
It is natural to introduce a notion of convergence for sequences of cumulative dis-
tribution functions, i.e. to give a meaning to the expression Fn →F. One possible
meaning could be pointwise convergence, i.e.: Fn(x) →F(x) for every x ∈R. How-
ever this notion of convergence turns out to be too restrictive. For example consider
the sequence Fn(x) deﬁned as:
Fn(x) =

1 for x ≥1
n ,
0 for x < 0.
If the random number Xn has c.d.f. Fn, then P(Xn =
1
n ) = 1. For a reasonable
convergence notion we should have Fn →F, where
F(x) =

1 for x ≥0,
0 for x < 0.
However it is not true in this case that Fn(x) →F(x) for every x ∈R. Indeed
Fn(0) = 0 for every n, whereas F(0) = 1. Therefore it is natural to introduce a
weaker deﬁnition of convergence.
Deﬁnition 5.1.1 We say that Fn →F for every x if for every ϵ > 0 there exists N
such that for n ≥N
F(x −ϵ) −ϵ < Fn(x) < F(x + ϵ) + ϵ.
If x is a continuity point of F, this deﬁnition implies that
lim
n→∞Fn(x) = F(x).
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_5
73

74
5
Convergence of Distributions
Conversely if for every continuity point x of F lim
n→∞Fn(x) = F(x), then Fn →F.
For a cumulative distribution, continuity points make up an everywhere dense set
since discontinuity points are denumerable. Indeed there cannot be more than n
discontinuity points with jump larger than or equal to 1
n because F is bounded by 1
from above. Let then x ∈R and ϵ > 0. There exist two continuity points x0, x of F
such that x −ϵ < x0 < x < x1 < x + ϵ. We have then
F(x −ϵ) ≤lim
n→∞Fn(x0) = F(x0)
and also
lim
n→∞Fn(x1) = F(x1) ≤F(x + ϵ).
On the other side for every n
Fn(x0) ≤Fn(x) ≤Fn(x1).
Therefore for n sufﬁciently large we have
F(x −ϵ) −ϵ < Fn(x) < F(x + ϵ) + ϵ.
It is easy to build up examples of sequences of absolutely continuous c.d.f.’s con-
verging to a discrete (pure jump) c.d.f. For example if Fn(x) = N(√nx), the c.d.f.
of normally distributed Xn with P(X) = 0 and σ2(Xn) = 1
n , then Fn →F with
F(x) =

1 for x ≥0,
0 for x < 0.
Conversely we can build up examples of discrete c.d.f’s converging to an absolutely
continuous c.d.f. For example if
Fn(x) =
⎧
⎪⎨
⎪⎩
0
for x ≤0,
[nx]
n
for 0 < x ≤1,
1
for x > 1,
where [x] denotes the integer part of x, then Fn →F, where F is the c.d.f. of the
uniform distribution in [0, 1]:
F(x) =
⎧
⎪⎨
⎪⎩
0
for x ≤0,
x
for 0 < x ≤1,
1
for x > 1.

5.2 Convergence of Geometric Distribution to Exponential Distribution
75
5.2
Convergence of Geometric Distribution to Exponential
Distribution
We have seen that geometric and exponential distributions share the property of
absence of memory, the former among discrete distributions, the latter among ab-
solutely continuous distributions. Let us now consider a sequence (Xn)n∈N of random
numbers with geometric distributions with parameters pn:
P(Xn = k) = pn(1 −pn)k−1,
∀k ≥1.
We assume that npn converges to λ > 0, as n →∞. We put Yn = Xn
n and denote by
FYn the c.d.f. of Yn. We have that
FYn →F,
where F is the c.d.f. of exponential distribution with parameter λ > 0, i.e.:
F(x) =

0
for x < 0,
1 −e−λx
for x ≥0.
Indeed for x < 0, FYn ≡0, as ⊢Yn ≥0. For x ≥0
FYn(x) = P(Yn ≤x) = P(Xn ≤nx)
= 1 −
∞

k=[nx]+1
pn(1 −pn)k−1
= 1 −pn(1 −pn)[nx]
∞

i=0
(1 −pn)i
= 1 −pn(1 −pn)[nx]
1
1 −(1 −pn)
= 1 −(1 −pn)[nx],
where we have used the formula for the sum of geometric series. We write
nx = [nx] + δn,
with 0 ≤δn < 1.
We obtain therefore
FYn(x) = 1 −(1 −pn)nx−δn,

76
5
Convergence of Distributions
which tends to 1 −e−λx for n →∞, since
log (1 −pn)nx = nx log (1 −pn) = −xnpn + o(npn)
which tends to −λx for n →∞, whereas
(1 −pn)δn −−−→
n→∞1,
as 0 ≤δn < 1 and pn −−−→
n→∞0.
5.3
Convergence of Binomial Distribution to Poisson
Distribution
We now provide an approximation of the binomial distribution when we consider
the number of successes in a large number of trials.
Let (Xn)n∈N be a sequence of binomially distributed random numbers with para-
meters n, pn such that npn →λ with λ > 0 as n →∞. For example Xn represent
the number of successes in n Bernoulli trials with parameter pn. As the number of
trials grows to inﬁnity we send to 0 the probability of success in a single trial. For
0 ≤k ≤n:
P(Xn = k) =
n
k
	
pk
n(1 −pn)n−k
=
n!
k!(n −k)! pk
n(1 −pn)n−k nk
nk



multiplication and division by nk
= 1
k!

1 −1
n
	
· · ·

1 −k −1
n
	
(npn)k(1 −pn)n−k.
We observe that:
•

1 −1
n
	
· · ·

1 −k −1
n
	
tends to 1 as n →∞;
• (npn)k tends to λk for n →∞;
• (1 −pn)−k tends to 1 for n →∞;
• (1 −pn)n tends to e−λ for n →∞as
log(1 −pn)n = nlog(1 −pn) = −npn + o(npn)
tends to −λ.

5.3 Convergence of Binomial Distribution to Poisson Distribution
77
It follows that for k ∈N
P(Xn = k) −−−→
n→∞
λk
k! e−λ,
and therefore the sequence of binomial c.d.f.’s with parameters n, pn tends to Poisson
c.d.f. with parameter λ.
5.4
De Moivre-Laplace Theorem
We consider now another type of convergence for sequences of binomial c.d.f’s. We
send the number of trials to inﬁnity but this time we keep ﬁxed the probability of
success in a single trial. In order to obtain convergence we need to perform a linear
rescaling.
Theorem 5.4.1 Let (Xn)n∈N be a sequence of random numbers with binomial dis-
tribution Bn(n, p) with 0 < p < 1 and let X∗
n be the corresponding standardized
random numbers given by
X∗
n = Xn −P(Xn)
σ(Xn)
= Xn −np

np ˜p
for n ∈N \ {0}. Where ˜p = 1 −p. Then we have for all n ∈N \ {0}
P(X∗
n = x) =
hn
√
2π
e−x2
2 eEn(x) ,
where hn =
1

np ˜p
and the error En(x) tends uniformly to 0 when x ranges on
I (X∗
n) [−K, K] for any ﬁxed constant K.
Proof The set I (Xn) of the possible values of Xn is I (Xn) = {0, 1, . . . , n}. Therefore
I (X∗
n) = {hn(−np), hn(1 −np), . . . , hn(n −np)}
where hn =
1

np ˜p
is the spacing between possible values of X∗
n.
We deﬁne φn(x) = log P(X∗
n = x) for x ∈I (X∗
n) and consider its incremental
ratio:
φn(x + hn) −φn(x)
hn
= 1
hn
log P(X∗
n = x + hn)
P(X∗n = x)
.

78
5
Convergence of Distributions
Putting k = np + x

np ˜p, we obtain
1
hn
log P(X∗
n = x + hn)
P(X∗n = x)
= 1
hn
log P(Xn = k + 1)
P(Xn = k)
= 1
hn
log (n −k)p
(k + 1) ˜p
=

np ˜plog
n ˜p −x

np ˜p
n + 1 + x

np ˜p
p
˜p
=

np ˜plog
1 −x
 p
n ˜p
1 + 1
np + x

˜p
np
.
Using the 1-order expansion of the logarithm log(1 + x) = x + O(x2), we obtain

np ˜plog
1 −x
 p
n ˜p
1 + 1
np + x

˜p
np
=

np ˜p

−x
 p
n ˜p + O(x2
n ) −x
 p
n ˜p + O(x2 + 1
n
)

= −xp −x ˜p + O(x2 + 1
√n
)
−x + O(x2 + 1
√n
) .
The function φn(x) is not deﬁned everywhere, but only for x in I (X∗
n). We can extend
it to values between two elements of I (X∗
n) by linear interpolation. In this way we
can write
φn(x) = φn(0) +
 x
0
φ′
n(y)dy .
If x ≤y ≤x +hn, then φ′
n(y) = hnφn(x) = −x +O(x2 + 1
√n
) = −y+O(x2 + 1
√n
)
so that:
φn(x) = φn(0) +
 x
0
φ′
n(y)dy
= φn(0) +
 x
0
(−y)dy + O(|x|3 + |x|
√n
)
= φn(0) −x2
2 + O(|x|3 + |x|
√n
) .

5.4 De Moivre-Laplace Theorem
79
Since φn(x) = log P(X∗
n = x), we obtain
log P(X∗
n = x) = eφn(0)e−x2
2 eEn(x)
where En(x) = O
|x|3 + |x|
√n
	
.
We can estimate eφn(0) in the following way: X∗
n is a standardized random number,
i.e. P(X∗
n) = 0 and σ2(X∗
n) = 1. By the Chebychev inequality, we have that:
P(|X∗
n| ≥K) ≤1
K 2 .
K can be chosen so that this probability is arbitrary small, that is for every ϵ > 0
there is K such that:
1 −ϵ = 1 −1
K 2 ≤P(|X∗
n| < K) ≤1.
Since P(|X∗
n| < K) = 
x,|x|<K P(|X∗
n| = x), it follows that:
1 −ϵ ≤

x,|x|<K
P(X∗
n = x) ≤1 .
Moreover
P(|X∗
n| < K) =

x,|x|<K
P(|X∗
n| = x) =

x,|x|<K
hne−x2
2 .
Since En(X) tends uniformly to 0 on bounded interval and 
x,|x|<K hne−x2
2 is the
Riemann sum for the function e−x2
2 and tends to
 K
−K e−x2
2 dx, we have for n sufﬁ-
ciently large that:
1 −2ϵ ≤eφn(0)
hn
 K
−K
e−x2
2 dx ≤1 .
Let K tending to inﬁnity, we obtain
1 −3ϵ ≤eφn(0)
hn
√
2π ≤1
so that
eφn(0)
hn
√
2π −−−→
n→∞1 .

80
5
Convergence of Distributions
It follows that
P(|X∗
n| = x) =
hn
√
2π
e−x2
2 eEn(x) ,
where En(x) is an error that tends uniformly to 0 for x ranging on the possible values
of X∗
n in a bounded interval.
As application of the theorem, one obtains an approximation of the c.d.f. of the
binomial distribution. Given a, b, a < b:
P(a ≤X∗
n ≤b) =

a≤x≤b
P(X∗
n = x) =

a≤x≤b
hn
√
2π
e−x2
2 eEn(x) .
This is the Riemann sum of n(x) =
1
√
2π
e−x2
2 , therefore it converges to
1
√
2π
 b
a
e−x2
2 dx = N(b) −N(a) ,
where N(x) is the c.d.f. of standard Gaussian distribution. The c.d.f. Fn(x) of X∗
n
converges to N(x) since
Fn(x) = P(X∗
n ≤x) = P(−k < X∗
n ≤x) + P(X∗
n ≤−k)
= N(x) −N(−k) + P(X∗
n ≤−k) + E′
n(x)
with lim
n→∞E′
n(x) = 0. The Chebychev inequality states that P(X∗
n ≤−k) can be
made arbitrarily small. Also N(−k) tends to 0 for k −→∞. Therefore the c.d.f. of
standardized binomial distributions tend to N.

Chapter 6
Discrete Time Markov Chains
6.1
Homogeneous Discrete Time Markov Chains
with Finite State Space
We deﬁne a homogeneous Markov chain with ﬁnite state space S ⊂R as a sequence
of random numbers (Xi)i∈N ⊂S for i ∈N such that:
P(X0 = s0, X1 = s1, . . . , Xn = sn) = ρs0 ps0,s1 ps1,s2 · · · psn−1,sn,
where
1. ρsi, si ∈S, is called initial distribution:
ρsi = P(X0 = si)
and

s∈S
ρs = 1 .
2. ps,s′ = [P]s,s′, are called transition probabilities and satisfy:
• 0 ≤pi j ≤1;
• 
s′∈S ps,s′ = 1
for every s ∈S.
They can be arranged in a matrix P called transition probability matrix of entries
[P]s,s′ =: ps,s′.
The Markov chain (Xi)i∈N can be seen as representing the evolution of a system that
moves from one state to another in a random fashion. We have assumed that S ⊂R,
but it may be convenient to consider in some situations a general ﬁnite set S. In this
case Xi are not random numbers, but random entities. However what follows goes
through without any change.
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_6
81

82
6
Discrete Time Markov Chains
We show now that ps,s′ is the probability to go from state s to state s′. Moreover
we show that the probability that Xr+1 = s′ conditional to all previous history
X0 = s0, . . . , Xr−1 = sr−1, Xr = s depends just on s and is equal to ps,s′ (Markov
property). Indeed:
P(Xr+1 = s′|Xr = s, Xr−1 = sr−1, . . . , X0 = s0)
= P(Xr+1 = s′, Xr = s, Xr−1 = sr−1, . . . , X0 = s0)
P(Xr = s, Xr−1 = sr−1, . . . , X0 = s0)
=
ρs0 ps0,s1 · · · psr−1,Ps,s′
ρs0 ps0,s1 · · · psr−1,s, ps,s′
= ps,s′,
provided that the probability of the conditioning event, which is at denominator, is
positive (this is required to compute the conditional probability).
Example 6.1.1 (Random walk). A random walk in an integer interval [a, b] ⊂Z,
with absorbing boundary conditions is a Markov chain with state space S = [a, b]
and transition probability matrix:
P =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
1
0
0
· · ·
· · · 0
1 −p 0
p
...
...
0
... ...
...
... ...
...
... ...
...
... 0
...
... 1 −p 0
p
0
· · · · · ·
0
0
1
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
,
where 0 < p < 1. Boundary conditions are determined by the transition probabil-
ities from state a and b. Other boundary conditions can be considered: reﬂecting,
mixed, …In the case p = 1
2 we speak of symmetric random walk.
Example 6.1.2 (Bernoulli-Laplace chain). Let us consider two urns A and B, each
containing N balls. The balls are assumed to be identical apart from their colors.
Among the balls there are N white balls and N black balls. At each integer time we
choose one ball from each urn and exchanges them.
Let Xi be the random number of white balls in A at time i. The state space is
S = {0, 1, . . . , N}.
The transition probability from state k to state l is given by:
pk,k = P(two white balls or two black balls are drawn)
= k
N
N −k
N
+ N −k
N
k
N = 2 k
N
N −k
N
;
(6.1)

6.1 Homogeneous Discrete Time Markov Chains with Finite State Space
83
pk,k+1 = P(1 black ball from urn A and 1 white ball from B )
= N −k
N
N −k
N
= (N −k)2
N 2
;
(6.2)
pk,k−1 = P(1 white ball from A and 1 black ball from B )
= k
N
k
N = k2
N 2 .
(6.3)
The transition probabilities to other states are zero. This applies also to the case k = 0
and k = N. The transition matrix is therefore:
P =
⎛
⎜⎜⎜⎜⎜⎜⎝
0
1
0
0
· · · 0
1
N 2
2(N−1)
N 2

 N−1
N
2
0
· · · 0
0
4
N 2
4(N−2)
N 2

 N−2
N
2 · · · 0
...
...
0
· · ·
0
· · ·
1 0
⎞
⎟⎟⎟⎟⎟⎟⎠
.
6.2
Transition Probability in n Steps
By using composite probability formula we can compute the probability for a Markov
chain to go from state s to state s′ in n steps. Let s0, s1, . . . , sm−1, s be a sequence of
states such that ρs0 ps0,s1 ps1,s2 · · · psm−1,s are strictly positive. We have:
P(Xm+n = s′|Xm = s, Xm−1 = sm−1, . . . , X0 = s0)
= P(Xm+n = s′, Xm = s, Xm−1 = sm−1, . . . , X0 = s0)
P(Xm = s, Xm−1 = sm−1, . . . , X0 = s0)
=

sm+1,...,sm+n−1
P(Xm+n = s′, Xm+n−1 = sm+n−1, . . . , X0 = s0)
P(Xm = s, Xm−1 = sm−1, . . . , X0 = s0)
=

sm+1,...,sm+n−1
ρs0 ps0,s1 · · · psm−1,s ps,sm+1 · · · psm+n−1,s′
ρs0 ps0,s1 ps1,s2 · · · psm−1,s
=

sm+1,...,sm+n−1
ps,sm+1 · · · psm+n−1,s′
=

Pn
s,s′ .

84
6
Discrete Time Markov Chains
Thisprobabilitydoesnot dependonm,butjustonn,thatisthenumberofintermediate
steps. It is obtained as the element with coordinates s, s′ of the n-th power of the
transition matrix P. In the following we will use the common notation p(n)
s,s′ for this
probability:
p(n)
s,s′ := P(Xm+n = s′|Xm = s) =

Pn
s,s′ .
By convention one deﬁnes:
p(0)
s,s′ := ps,s′ =
⎧
⎨
⎩
1 if s = s′,
0 otherwise.
6.3
Equivalence Classes
Let (Xi)i∈N be a homogeneous Markov chain. We say that the state s communicates
with the state s′ if there exists n > 0 such that
p(n)
s,s′ > 0,
that is if there exists a path s, s1, . . . , sn−1, s′ such that all transition probabilities
ps,s1, ps1,s2, . . . , psn−1,sn are strictly positive. We will use the notation s ≺s′ to
indicate that s communicates with s′.
Two states s, s′, are said to be equivalent if s ≺s′ and s′ ≺s. This is an equivalence
relation, i.e. it is reﬂexive, symmetric and transitive. The ﬁrst two properties are
evident. Transitivity follows from transitivity of communication. Assume that s ≺s′
and s′ ≺s′′. Then there are n1, n2 such that pn1
s,s′ > 0 and pn2
s′,s′′ > 0. It follows that
s ≺s′′. Indeed:
p(n1+n2)
s,s′′
=

Pn1+n2
s,s′′ =

s1
p(n1)
s,s1 p(n2)
s1,s′′ ≥p(n1)
s,s′

>0
p(n2)
s′,s′′

>0
> 0 .
The communication relation ≺between states can be extended without ambiguity
to equivalence classes. We indicate with [s] the equivalence class of the state s, i.e.
the set of all states s′ equivalent to s according to the previously introduced relation.
When s ≺s′ we say that s′ follows s. We say that [s] communicates with [s′] and
write [s] ≺[s′] if s ≺s′. Using the transitivity property it is easy to check that this is
a well-posed deﬁnition, i.e. it does not depend on the choices of the representatives
in the equivalence classes.
An equivalence class is said to be maximal if it is not followed by any other
class with respect to the communication relation. If a Markov time is in a state of
a maximal equivalence class, then at all subsequent times, it will be in states of the
same class with probability 1.

6.3 Equivalence Classes
85
Another characteristic of a state of a Markov chain is its period. Let s ∈S be a
state of a Markov chain and let:
A+
s = { n > 0 |p(n)
s,s > 0} .
If A+
s ̸= ∅, we deﬁne the period of s as the greatest common divisor (GCD) of the
elements of A+
s . If the period of s is 1, we say that s is an aperiodic state. For example,
in the random walk on the interval [a,b] with absorbing boundary conditions all states
s with a < s < b have period 2.
All states of an equivalence class have the same period. Therefore one can speak
of the period of an equivalence class.
Proof Let us consider two equivalent states s ∼s′, and q, q′ their periods. It is
enough to show that q′ divides every n ∈A+
s . In force of the equivalence, there is n1
such that p(n1)
s,s′ > 0 and there is n2 such that p(n2)
s′,s > 0. Then (n1 + n2) ∈A+
s since
p(n1+n2)
s,s
=

s1
p(n1)
s,s1
(n2)
s1,s ≥p(n1)
s,s′ p(n2)
s′,s > 0.
Similarly (n1 + n2) ∈A+
s′; hence q and q′ both divide (n1 + n2). Moreover for all
n ∈A+
s , (n + n1 + n2) ∈A+
s′, since
p(n+n1+n2)
s′,s′
≥p(n2)
s′,s p(n)
s,s p(n1)
s,s′ > 0 .
Hence, q and q′ divide (n + n1 + n2) for all n ∈A+
s and for all n ∈A+
s′. Since n1, n2
are divisible by q and by q′, q and q′ are both common divisors of A+
s and of A+
s′, so
that
q = q′ .
An equivalence class C of period q < ∞can be decomposed in q subsets:
C = C0 ∪C1 ∪· · · ∪Cq−1
with the property that if s ∈Ci, s′ ∈C j and p(n)
s,s′ > 0 then
n ≡( j −i) (mod q) .
If a maximal equivalence class C has period q, C0, C1, . . . , Cq−1 are cyclically visited
by the Markov chain: i.e. if X0 ∈Ci, then X1 ∈C[i+1]modq, X2 ∈C[i+2]modq with
probability 1, where we use the notation [k]q for the element of the set {0, . . . , q −1}
that is equivalent to k modulo q.

86
6
Discrete Time Markov Chains
6.4
Ergodic Theorem
We want to study the behavior of a Markov chain as time proceeds.
An important result states that a Markov chain with ﬁnite state space and a sin-
gle aperiodic equivalence class has the property that the distribution on state space
converges to a limit that does not depend on the initial state. This is the result of the
following theorem called ergodic theorem (see e.g. Gnedenko (1997) for a proof).
Theorem 6.4.1 (Ergodic theorem) Let (Xi)i∈N be a homogeneous Markov chain
with a ﬁnite state space. If the chain is irreducible (i.e. there is a unique equivalence
class) and aperiodic (i.e. the period is 1), then there is a probability distribution
Π = (πs)s∈S on the state space and constants C > 0 and 0 ≤δ < 1 such that for
all s′, s ∈S :
|p(n)
s′,s −πs| ≤Cδn .
In other words there are πs, s ∈S, such that:
1. 0 ≤πs ≤1;
2. 
s∈S πs = 1,
and ∀s′ ∈S
lim
n→+∞p(n)
s′,s = πs
with exponential speed.
This theorem can be used also in the case when the period q is strictly larger than 1,
by considering the Markov chain with transition matrix Pq. Indeed, the restriction of
this chain to each of the subsets C0, C1, . . . , Cq−1 satisﬁes the hypothesis of ergodic
theorem.
The probability distribution Π that appears in the statement of the ergodic theorem
is an invariant (or stationary) distribution for the Markov chain: this means that if
we take it as initial distribution, so that P(X0 = s) = πs for every s ∈S, then for
every s ∈S and for every n ≥0
P(Xn = s) = πs .
This property allows us to compute πs as the solution of a system of linear equations.
Indeed:
πs = P(X1 = s)
=

s′ ∈S
P(X0 = s′) ps′,s
=

s′ ∈S
πs′ ps′,s .

6.4 Ergodic Theorem
87
Moreover, since πs is a probability distribution, we have

s∈S
πs = 1 .
Under the hypothesis of the ergodic theorem one can show that there is one and
only one solution for this system of |S| + 1 equations in |S| unknowns; one of the
equations, in this case one of the ﬁrst |S| equations, is a linear combination of the
others and therefore it can be skipped in the solution of the system:
Πt = Πt P

πs∈S πs = 1 ,
(6.4)
where we have represented Π as |S|-dimensional vector. The ergodic theorem tells
us that as time advances the Markov chain forgets the initial state and reaches an
equilibrium. We show now the uniqueness of the invariant measure.
Proof Let us assume that (μs)s∈S is another probability distribution on the state space
satisfying system (6.4). We have
μt = μt P

s∈S μs = 1 ,
where we have represented the distribution (μs)s∈S as the |S|-dimensional column
vector μ. We have
μt = μt P
⇒
μt = μt P = μt P2 = · · · = μt Pn .
If n tends to inﬁnity, by ergodic theorem Pn converges to the matrix:
⎛
⎜⎜⎜⎝
π1 π2 · · · πn
π1 π2 · · · πn
...
...
...
π1 π2 · · · πn
⎞
⎟⎟⎟⎠
therefore for s ∈S
μs =

s′
μs′ ps′,s =

s′
μs′ p(n)
s′,s .
By taking the limit limn→+∞p(n)
s′,s = πs, we have
μs =

s′
μs′πs = πs

s′
μs′
  
1
= πs .

Chapter 7
Continuous Time Markov Chains
7.1
Introduction
In this chapter we shall introduce some simple queueing systems. For further reading,
we refer to [7, 8].
A queueing system can be described in terms of servers and a ﬂow of clients
who access servers and are served according to some pre-established rules. The
clients after service can either stay in the system or leave it, also according to some
established rules.
The simplest case is when there is a single set of servers and a ﬂow of clients
accessing to it. If there is at least one free server, then an incoming client is served
right away. Otherwise, i.e. if all servers are engaged, he is put in a queue and waits
for his turn. Once a client is served, he leaves the system.
Usual hypotheses are that service times are stochastically independent, identically
distributed, and moreover that they are stochastically independent from the ﬂow of
clients’ arrivals. One would like to obtain the probabilities that, at given times, there
are some numbers of clients in the system. For this one needs to introduce a random
number for each time t; this leads us to introduce the notion of stochastic process.
Deﬁnition 7.1.1 A stochastic process (Xt)t∈I with I interval of R, is a family of
random numbers with index varying in some interval I of R.
Speaking of stochastic processes therefore one refers to continuous index space,
where the index is usually interpreted as time. Markov chains, introduced in previous
chapter, can be considered as discrete time stochastic processes.
We model the ﬂow of incoming clients by a stochastic process Nt, representing
the number of clients arrived before time t, which is assumed to be stochastically
independent from service times. For ﬁxed t, Xt represents the random number of the
clients who are present in the system at time t.
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_7
89

90
7
Continuous Time Markov Chains
In order to characterize a system such as that we have described, one needs to
specify:
1. the stochastic process ruling the ﬂow of incoming clients;
2. the distribution of service times;
3. the number of servers.
It is customary to adopt the following notation to indicate the speciﬁcations of a
given queueing system:
1. M denotes the Poisson process for the ﬂow of incoming clients or exponential
distribution for service times;
2. Er denotes the Erlang distribution with parameter r for the inter-arrival times
of clients (that are supposed to be stochastically independent and identically
distributed) or for service times. The Erlang distribution with parameter r is the
distribution of a sum ofr stochastically independent exponential random numbers
with the same parameter;
3. D denotes deterministic (non-random) inter-arrival times or service times;
4. G indicates that one does not make any particular hypothesis on the inter-arrival
times or service times (that however are always assumed to be stochastically
independent).
A process of the type we have described will be indicated by three symbols separated
by two slashes. The ﬁrst symbol refers to the distribution of inter-arrival times, always
assumed to be stochastically independent and identically distributed (i.i.d.). The
second symbol refers to the distribution of service times. The third symbol indicates
the number of servers; it can possibly take the value ∞.
We shall consider three examples of queueing systems and precisely the systems
M/M/1, M/M/n with n > 1 and M/M/∞. Before that we shall speak about
continuoustimeMarkovchainswithcountablestatespace,andinparticularintroduce
the Poisson process Nt, t ≥0, that for these queueing systems represents the number
of clients who entered the system before time t.
7.2
Homogeneous Continuous Time Markov Chains
with Countable State Space
An homogeneous continuous time Markov chain is a stochastic process (Xt)t≥0 with
I (Xt) = N characterized by the initial distribution (ρs)s∈N, and for every t > 0 a
transition matrix p(t)s,s′ = [Π]ss′ (t). As in the case of discrete time case they must
respectively satisfy
0 ≤ρs ≤1,

s∈N
ρs = 1,
0 ≤p(t)s,s′ ≤1,

s′∈N
p(t)s,s′ = 1,

7.2 Homogeneous Continuous Time Markov Chains with Countable State Space
91
for every t > 0. If 0 = t0 < t1 < · · · < tn−1 < tn, then
P(X0 = s, Xt1 = s1, . . . , Xtn = sn)
= ρs0 ps0,s1(t1)ps1,s2(t2 −t1) . . . psn−1,sn(tn −tn−1).
It follows from conditions of compatibility that transition matrices are related by
Chapman-Kolmogorov equations that can be expressed in synthetic form by:
Π(t + t′) = Π(t) Π(t′)
∀t, t′ ≥0
or explicitly:
ps,s′(t + t′) =

s′′
ps,s′′(t) ps′′,s′(t′).
In order to treat interesting examples, such as those arising from queueing theory,
we need to consider the case of strictly denumerable state spaces. In this case Π(t)
is a matrix with inﬁnitely many rows and columns with non-negative entries, such
that the sum of the series of the elements of each row is equal to 1.
The product of two matrices of this kind can be deﬁned according to the usual row
times column rule, where the ﬁnite sum is replaced by a series. It is easy to check
that the result is still a matrix of this kind.
Inthecaseofdiscretetimethetransitionprobabilitiesinmorestepscanbeobtained
from those in one step. In the case of continuous time analogously transition prob-
abilities in a ﬁnite time t can be obtained starting from their behavior as t becomes
inﬁnitely small. The simplest case is the Poisson process.
7.3
Poisson Process
A Poisson process is a continuous time Markov chain with state space S = N. In the
following we shall use a Poisson process as a model for the ﬂow of clients entering a
queueing system. For the quantities that we shall consider the order in which clients
are served does not matter. A Poisson process N = (Nt)t≥0 with parameter λ, where
λ > 0, is characterized by the following properties:
1. ps,s(h) = 1 −λh + o(h);
2. ps,s+1(h) = λh + o(h);
3. ps,s′(h) = o(h) for s′ /∈{s, s + 1},
where o(h) is inﬁnitesimal of order larger than h, uniformly in s and s′.
Starting from this hypothesis we can obtain the Kolmogorov forward equations,
a system of inﬁnitely many differential equations for transition probabilities. Let us
ﬁx ¯s = 0 and the initial distribution ρ0 = 1, ρs = 0 for s ̸= 0, i.e. P(N0 = 0) = 1.

92
7
Continuous Time Markov Chains
We put:
μs(t) = p0,s(t) for s ∈N
and denote by μ′
s the ﬁrst derivative of μs. The functions μs verify the system of
equations:
μ′
0(t) = −λμ0(t)
μ′
s(t) = −λμs(t) + λμs−1(t) for s ≥1,
(7.1)
as we now show. Consider for s > 0 the incremental ratio μs(t + h) −μs(t)
h
for
h > 0. We have:
μs(t + h) −μs(t)
h
= p0,s(t + h) −p0,s(t)
h
=

j p0, j(t)p j,s(h) −p0,s(t)
h
= 1
h ((1 −λh + o(h))p0,s(t) + (λh + o(h))p0,s−1(t))
+ 1
h
⎛
⎜⎜⎜⎝

j
j̸=s, j̸=s−1
p0, j(t)p j,s(h) −p0,s(t)
⎞
⎟⎟⎟⎠
= −λp0,s(t) + λp0,s−1(t) + o(h)
h
= −λμs(t) + λμs−1(t) + o(h)
h
.
By taking the limit h ↓0, we obtain an equation for the right derivative:
μ′
s(t) = −λμs(t) + λμs−1(t) for s ≥1 ,
where we have used the notation for the derivative since it is easy to show that it
exists. For s = 0, we obtain for h > 0:
μ0(t + h) −μ0(t)
h
= p0,0(t + h) −p0,0(t)
h
=

j p0, j(t)p j,0(h) −p0,0(t)
h
=
(1 −λh + o(h))p0,0(t) + 
j̸=0 p0, j(t)p j,0(h) −p0,0(t)
h
= −λp0,0(t) + o(h)
h
= −λμ0(t) + o(h)
h

7.3 Poisson Process
93
that in the limit h ↓0 converges to the equation
μ′
0(t) = −λμ0(t).
As we show below the solution of the system is given by
μs(t) = p0,s(t) = (λt)s
s!
e−λt ,
i.e. for each t we have that Nt has Poisson distribution with parameter λt.
If we take ρ¯s = 1 and ρs = 0 for s ̸= ¯s i.e. assume that P(N0 = ¯s) for some
arbitrary state ¯s, then we obtain the transition probabilities starting from ¯s:
⎧
⎨
⎩
p¯s,s(t) = 0
for s < ¯¯s,
p¯s,s(t) = (λt)s−¯s
(s −¯s)! e−λt for s ≥¯¯s.
(7.2)
Let us prove that (7.2) provides a solution for the system with initial state ¯s. Let us
consider the generating function:
Φ(z, t) =

s
p¯s,s(t)zs.
We derive Φ(z, t) with respect to t. It is easy to see that the derivative can be
exchanged with the series. By applying the system of equation for μs(t) = p¯s,s(t),
we obtain
∂
∂t Φ(z, t) =

s
μ′
s(t)zs = −λ
∞

s=0
μs(t)zs + λ
∞

s=1
μs−1(t)zs = λ(z −1)Φ(z, t).
Therefore
1
Φ(z, t)
∂
∂t Φ(z, t) = ∂
∂t log Φ(z, t) = λ(z −1),
so that
log Φ(z, t) = λ(z −1)t + K,
that is Φ(z, t) = eKeλ(z−1)t. Since μ¯s(0) = 1 and μs(0) = 0 for s ̸= ¯s, we have
Φ(z, 0) = z¯s. We have therefore:
Φ(z, t) = z¯seλ(z−1)t = e−λtz¯seλzt = e−λt 
k
z¯s+k (λt)k
k! .

94
7
Continuous Time Markov Chains
Fig. 7.1 Scheme of Poisson
process with parameter λ
0
1
2
3
λ
λ
λ
λ
It follows that p¯s,s(t) = 0 for s < ¯s, p¯s,s(t) = (λt)s−¯s
(s −¯s)!e−λt for s ≥¯s. The Poisson
process is non-decreasing with probability 1. It can be represented as in Fig.7.1,
when an arrow connecting two states with superscript λ indicates that the transition
intensity from one state to the other one is equal to λ. We observe that an arrow
enters every state s with s ≥1. These two arrows, one in-coming and one exiting,
correspond to two terms, one with plus sign and one with minus sign, on the right-
hand side of the differential equation. For s = 0 there is just an out-coming arrow,
corresponding to the single term, with minus sign, on the right-hand side of the
differential equation.
If we indicate with Ps(t) = P(Nt = s) the probability that Poisson process at
time t is in the state s, then we have
Ps(t) =

s∈N
ρ¯s p¯s,s(t) ,
where ρs is the initial distribution. It follows that for every initial distribution the
functions (Ps(t))s∈N satisfy the same system of differential equations.
 P′
0(t) = −λP0(t)
P′
s(t) = −λPs(t) + λPs−1(t) for s ≥1.
The functions (p¯s,s(t))s∈N can be considered as particular cases in which ρ¯s = 1
and ρs = 0 for s ̸= ¯s.
7.4
Queueing Processes
We now consider some examples of continuous time Markov chains that serve as
models of queueing processes. As we have said in Sect.7.1, in queueing theory there
is a symbolic notation to indicate the type of a queueing system. In the examples we
consider the ﬂow of incoming clients follows a Poisson process with parameter λ.
Clients who ﬁnd a free server start a service time and after service leave the system.
When an arriving client ﬁnds all servers engaged, he is put in a queue. When a server
becomes free, if there are clients waiting in queue, one of them starts its service time.
For what we are interested in, the order in which clients access the service does
not matter; we can assume, for example, that the order is randomly chosen, but
other possible choices would not change the results. We assume that service times

7.4 Queueing Processes
95
are stochastically independent, identically distributed and stochastically independent
from the Poisson process ruling the ﬂow of arrivals. We also assume that service times
are exponentially distributed with some parameter μ.
A process of this type will be indicated with the symbol M/M/n. The ﬁrst M
means that the ﬂow of arrivals is Poisson, the second M means that service times are
exponentially distributed, while n denotes the number of servers and can vary from
1 to ∞(∞is an admissible value).
7.5
M/M/∞Queueing Systems
We consider an idealized situation in which there are inﬁnitely many servers. The
ﬂow of arrivals is ruled by a Poisson process with parameter λ and service times are
exponentially distributed with parameter μ.
Let X = (Xt)t≥0 be the process indicating the number of clients who are in the
system at time t. As initial distribution we assume that:
 P(X0 = 0) = 1 ,
P(X0 = i) = 0
for i > 0,
i.e. no client is present in the system at time 0. As stated in previous section, ser-
vice times are stochastically independent between themselves and from the arrivals’
process. In order to compute the intensity of service process, we obtain the probabil-
ity that a client is served in time interval (t, t + h), given that he has not been served
up to time t. If T is service time for a client, we have:
P(T ≤t + h|T > t) = P(t < T ≤t + h)
P(T > t)
= e−μt −e−μ(t+h)
e−μt
= 1 −e−μh
= 1 −(1 −μh + o(h))
= μh + o(h),
where we have used ﬁrst order expansion of the exponential e−μh = 1 −μh + o(h)
for small h. Assume that there are n clients in the system. If no one of them has been
served up to time t, the probability that at least one of them is served in time interval
(t, t + h) is then:
1 −P(T1 > t + h, . . . , Tn > t + h|T1 > t, . . . , Tn > t)
= 1 −P(T > t + h|T > t)n = 1 −e−nμh = nμh + o(h) ,

96
7
Continuous Time Markov Chains
Fig. 7.2 Graphical
representation of a M/M/∞
queueing system
0
1
2
3
λ
μ
2μ
λ
λ
3μ
λ
4μ
where T1, . . . , Tn denote the service times of the clients and we have used the fact
that they are stochastically independent and identically distributed. Therefore a client
exits the system with an intensity which is proportional to the number of clients
present in the system. The process can be represented as in Fig.7.2.
Putting p0,s(t) = μs(t), we can write forward Kolmogorov equations by using
the rule described in Sect.7.3:
μ′
0(t) = μμ1(t) −λμ0(t)
μ′
i(t) = −(λ + iμ) μi(t) + λ μi−1(t) + (i + 1)μ μi+1(t)
for i ≥1, where μ′
i(t) denotes the derivative of μi.
We have seen that n-steps transition probabilities of discrete time Markov chains
satisfying the hypothesis of ergodic theorem converge as n →∞to the stationary
distribution. Analogous results hold for continuous time Markov chains. Therefore
we look for a stationary solution (pi)i≥0 of the system of equations, that is a solution
which does not depend on the time. We impose μ′
i(t) = 0 so that μi(t) = pi and
obtain:
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
0 = μp1 −λp0
0 = −(λ + iμ)pi + λpi−1 + (i + 1)μpi+1,
for i ≥1
+∞

i=0
pi = 1 .
By adding up the equations up to the i-th one, we obtain the recursive formula:
pi = λ
iμ pi−1 = 1
i!
λ
μ
i
p0 .
By imposing the condition
+∞

i=0
1
i!
λ
μ
i
p0 = 1, we obtain:
p0
+∞

i=0
1
i!
λ
μ
i
= 1.

7.5
M/M/∞Queueing Systems
97
Since
+∞

i=0
1
i!
λ
μ
i
= e
λ
μ , therefore
pi = e−λ
μ
and
pi = 1
i!
λ
μ
i
e−λ
μ ,
which is Poisson distribution with parameter λ
μ. We come to the conclusion that for
M/M/∞the queueing system stationary distribution exists for all values of λ and μ.
7.6
M/M/1 Queueing Systems
Also for M/M/1 service times are assumed to be stochastically independent and
identically distributed with exponential distribution with parameter μ. The arrival
ﬂow of clients is ruled by a Poisson process with parameter λ which is stochastically
independent from service times.
For this system there is just one server. Therefore the intensity for a client to
exit the system is equal to μ independently from the number of clients present in
the system. M/M/1 queueing system can be graphically represented as shown in
Fig.7.3.
The system of differential equations for the function μs(t) = p¯s,s(t), where ¯s is
some ﬁxed state, is then:
 μ′
0(t) = μμ1(t) −λμ0(t)
μ′
1(t) = −(λ + μ) μ1(t) .
Also in this case we look for a stationary solution, i.e. such that μ′
i(t) = 0 for i ∈N
with μi(t) = pi, where pi is a probability distribution. We obtain then the system of
linear equations:
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
0 = μp1 −λp0
0 = −(λ + μ)pi + λpi−1 + μpi+1
+∞

i=0
pi = 1 .
Fig. 7.3 Scheme of M/M/1
queueing system
0
1
2
3
λ
μ
λ
λ
λ
μ
μ
μ

98
7
Continuous Time Markov Chains
From this system we obtain, by adding up the ﬁrst n equations, the recursive relation
pn = λ
μ pn−1 =
λ
μ
n
p0 .
By imposing the condition +∞
i=0 pi = 1, we obtain
 ∞

i=0
λ
μ
i 
p0 = 1.
This series is convergent if λ
μ < 1. In this case we get
p0 = 1 −λ
μ.
The stationary probability distribution is then
pi =
λ
μ
i 
1 −λ
μ

,
for i = λ
μ.
The stationary probability distribution is a shifted geometric distribution with para-
meter λ
μ (the set of possible values is N instead of N \ {0}). It exists if and only if
λ
μ < 1 or λ < μ, i.e. if the intensity of arrivals of clients is strictly less than the
parameter of the exponential distribution of service times.
7.7
M/M/n Queueing Systems
We ﬁnally consider M/M/n queueing systems with n ≥2, i.e. with a ﬁnite number
of servers larger than 1. From considerations similar to those developed for the
other cases we obtain the following system of equations for transition probabilities
μ′
s(t) = p¯s,s(t), where ¯s is some ﬁxed state:
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎩
μ′
0(t) = μμ1(t) −λμ0(t)
μ′
1(t) = −(λ + μ) μ1(t) + λ μ0(t) + 2μ μ2(t)
· · ·
μ′
n−1(t) = −(λ + (n −1)μ) μn−1(t) + λ μn−1(t) + nμ μn(t)
μ′
n(t) = −(λ + nμ) μn(t) + λ μn−1(t) + nμ μn+1(t)
μ′
n+1(t) = −(λ + nμ) μn+1(t) + λ μn(t) + nμ μn+2(t)
. . . ,

7.7
M/M/n Queueing Systems
99
λ
μ
μ
λ
λ
μ
0
1
2
3
λ
μ
2μ
λ
λ
3μ
n
n+2
n+1
n−1
n
n
n
Fig. 7.4 Scheme of a M/M/n queueing system with initial state in 0
where λ and μ are, as in previous cases, respectively the parameter of the Poisson
process ruling the arrival of clients and of the exponential distribution of service
times. The system is graphically represented in Fig.7.4.
Let us now look for the stationary distribution by imposing μ′
i(t) = 0 for all
i ∈N. If we denote pi ≡μi(t), we obtain the following system of linear equations:
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
0 = μp1 −λp0
0 = 2μp2 −λp1
· · ·
0 = (n −1)μpn−1 −λpn−2
0 = nμpn −λpn−1
0 = nμpn+1 −λpn
· · ·
+∞

i=0
pi = 1 .
We obtain the following recursive equations:
pi = λ
iμ pi−1
for i = 1, . . . , n;
pi = λ
nμ pi−1
for i ≥n + 1.
Therefore we have:
pi =
λ
μ
i 1
i! p0
for i = 0, . . . , n,
pi =
λ
μ
i
1
n!ni−n p0
for i ≥n + 1.
A solution of the system exists if
n−1

i=0
λ
μ
i 1
i! +
∞

i=n
λ
μ
i
1
n!ni−n < +∞.

100
7
Continuous Time Markov Chains
The ﬁrst term on the left-hand side is a ﬁnite sum. The series of the second term can
be rewritten by putting j = i −n as
1
n!
λ
μ
n
∞

j=0
 λ
nμ
 j
.
The condition of convergence is therefore λ
nμ < 1, i.e. λ < nμ. This result answers
the problem of how many servers are needed for a queueing system with some ﬁxed
Poisson ﬂow of incoming clients so that the queue stabilizes (so that a stationary
distribution exists). For λ < nμ we have:
p0 =
n−1

i=0
λ
μ
i 1
i! + 1
n!
λ
μ
n
1
1 −λ
nμ
−1
(7.3)
pi =
λ
μ
i 1
i! p0
for i = 1, . . . , n,
(7.4)
pi =
λ
μ
i
1
n!ni−n p0
for i ≥n + 1.
(7.5)
7.8
Queueing Systems in Stationary Regime and Little’s
Formulas
For Markov queueing systems introduced in the previous sections the existence of
an invariant distribution allows us to consider a stationary regime for the process X
representing the number of clients present in the system. In the stationary regime
probabilistic characteristics of the process don’t vary in time. The stationary regime
is obtained by taking as initial distribution the stationary distribution.
It can be shown that, when a stationary distribution exists, these queueing systems
evolve towards stationary regime and moreover temporal averages of observables
tend, as the length of the temporal interval tends to inﬁnity, to the expectations of
the observables computed in stationary regime. All this should be precisely stated
and supported with proofs. We limit ourselves to accept it and to reason at intuitive
level. We now consider some quantities or observables, which are relevant for the
study of queueing systems and their efﬁciency, and establish some useful relations.
From now on we shall always refer to queueing systems in stationary regime.
In order to evaluate the efﬁciency of a queueing system, we introduce the utiliza-
tion factor ρ. This quantity is deﬁned as the client’s average arrival rate λ times the
average service time ¯T divided by the number m of servers. It can be shown that the
utilization factor is equal to the average percentage rate of utilization of servers. For
a non-deterministic system in stationary regime it is known that ρ < 1, see also [12],

7.8 Queueing Systems in Stationary Regime and Little’s Formulas
101
i.e. that with probability one servers do not work full time. A server will be free for
a positive percentage of time. Other interesting quantities are:
1. the average number L of clients present in the system;
2. the average number Lq of clients waiting in queues;
3. the average time W that a client spends in the system;
4. the average time Wq that a client spends waiting in queues.
The last two quantities are related by the equation
W = Wq + ¯T ,
where ¯T is the equation of service time.
Let us assume that every client pays an amount equal to the time he spends in the
system. In a time interval of length t the expectation of the amount paid by clients is
given, apart from quantities of order smaller than t, by λt (expectation of the number
of clients entering the system in a time interval of length t) times W (expectation
of the time a client spends in the system). Alternatively the same quantity is given
by Lt. By equating the expressions and letting t tend to inﬁnity, we get ﬁrst Little’s
formula L = λW.
Analogously if we assume that a client pays an amount equal to the time he spends
in queue, we get the second Little’s formula Lq = λWq.
Little’s formulas apply to a large class of queueing systems in stationary regime.
Let us consider the case of M/M/1 queueing system. As we have seen, this system
has an invariant distribution if and only if λ < μ, where λ is the parameter of Poisson
process of incoming clients and μ is the parameter of the exponential distribution of
service time. In this case the stationary distribution for the number of clients present
in the system is given by:
ρk =
λ
μ
k 
1 −λ
μ

.
We have therefore
L =
∞

k=1
kρk =
∞

k=1
k
λ
μ
k 
1 −λ
μ

=
λ
μ −λ
and
Lq =
∞

k=2
(k −1)ρk =
∞

k=1
(k −1)
λ
μ
k 
1 −λ
μ

=
λ2
μ(μ −λ) .
Therefore by using Little’s formulas we have:
W =
1
μ −λ,
Wq =
λ
μ(μ −λ) ,

102
7
Continuous Time Markov Chains
that satisfy the equation W = Wc + ¯T , where ¯T = 1
μ (expectation of exponential
distribution with parameter μ).
In this case the utilization factor is λ
μ. We observe that, as ρ tends to 1, the average
number of clients present in the system and waiting in queue, as well as the average
time spent by a client in the system, all tend to inﬁnity. This is a general characteristics
of random queueing systems. If one tries to increase utilization factor, one has to pay
the price of an increase of the number of clients in queue and of their typical waiting
times. Value 1 for the utilization factor is not reachable by a random queueing system
in stationary regime, but it can be obtained by a deterministic system with one server
where clients arrive at regular time intervals equal to the service time.

Chapter 8
Statistics
We now introduce some basic notions in Bayesian statistics. For further reading, we
refer to [5, 9, 10].
8.1
Bayesian Statistics
Assume that we know the value xi of some characteristics, for example the height for
every individual i of a population i = 1, . . . , N. We can then build up a cumulative
distribution function F(x) deﬁned by
F(x) = ♯{i| xi ≤x}
N
.
F(x) can be interpreted as the c.d.f. of a random number X, where X is the height of
an individual randomly chosen from the population (every individual is chosen with
equal probability 1
N ). Some relevant quantities can be extracted from F(x), such as
the expectation, the variance, the median and others.
F(x) (called empirical c.d.f.) will always be of discrete type, but for large N it is
possible that it is well approximated by an absolutely continuous c.d.f. Similarly for
two quantities xi, yi for example height and weight relative to each individual, we
can obtain the joint c.d.f. F(x, y) deﬁned by
F(x, y) = ♯{i| xi ≤x, yi ≤y}
N
.
F(x, y) is the joint c.d.f. of the random vector (X, Y), where X and Y are respectively
the height and the weight of a randomly chosen individual in the population. Also
in this case relevant indices such as covariance, correlation coefﬁcient, etc. can be
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_8
103

104
8
Statistics
extracted from F(x, y). The study of empirical c.d.f.’s is part of descriptive statistics
and is obviously related to the study of probability distributions.
Often the data about the entire population we are interested in are not available. In
this case one tries to form an evaluation of the distributions of quantities in the whole
population starting from results obtained by sampling (that is by randomly extracting
a subset of individuals of the population). These methods are part of what is called
statistical inference or statistical induction, in the Bayesian approach, that we shall
follow in this chapter. They are an application of Bayes’ Formula and therefore are
part of Probability Theory. We deal here just with a few relevant examples in which
a model based on some distribution is assumed to be ﬁxed and one makes inference
on one or a certain number of unknown parameters, that in Bayesian approach are
treated as random numbers.
8.2
Conditional Density for Two Random Numbers
We now introduce the conditional density of a random number Y given another
random number X. Let f (x, y) be the joint probability density function of (X, Y)
and fX, fY the probability density functions of X, Y, respectively. The conditional
probability of the event (a ≤Y ≤b) given (x −h ≤X ≤x + h) is then given by
P(a ≤Y ≤b| x −h < X < x + h) =
 x+h
x−h
 b
a f (s, t)dsdt
P(x −h < X < x + h).
In order to give a meaning to the conditional probability given (X = x), we let h
tend to 0. Assume that f (x, y) satisﬁes the following conditions:
1. f (x, y) is continuous;
2. fX(x) is continuous.
Then it is easy to see that if fX(x) > 0
lim
h→0 P(a ≤Y ≤b| x −h < X < x + h) =
 b
a
f (x, t)
fX(x) dt.
Previous argument justiﬁes the deﬁnition of conditional density fX(y|x) of Y given
X = x under the condition fX(x) > 0 as given by
fY|X(y|x) = f (x, y)
fX(x)
We obtain then Bayes’ formula for densities. From
f (x, y) = fY|X(y|x) fX(x)

8.2 Conditional Density for Two Random Numbers
105
and
f (x, y) = fX|Y(x|y) fY(y),
we get
fY|X(y|x) = fY(y) fX|Y(x|y)
fX(x)
.
These formulas generalize to the n-dimensional case. Let X1, . . . , Xn be random
numberswithjointprobabilitydensity f (x1, . . . , xn).Let{i1, . . . , ik}beapropersub-
set of {1, . . . , n} and assume that the marginal density function fi1,...,ik(xi1, . . . , xik)
of Xi1, . . . , Xik is strictly positive at the point (xi1, . . . , xik). Let { j1, . . . , jn−k} =
{1, . . . , n}\{i1, . . . , ik}. Then the conditional density of X j1, . . . , Xn−k given (Xi1 =
xi1, . . . , Xik = xik), provided that fi1,...,xik (xi1, . . . , xik) > 0, is deﬁned by
f j1,..., jn−k|i1,...,ik(x j1, . . . , x jn−k|xi1, . . . , xik)
=
f (x1, . . . , xn)
fi1,...,ik(xi1, . . . , xik).
As in the two-dimensional case we get Bayes’ formula for densities
f j1,..., jn−k|i1,...,ik(x j1, . . . , x jn−k|xi1, . . . , xik)
= fi1,...,ik| j1,..., jn−t(xi1, . . . , xik|x j1, . . . , x jn−k) f j1,..., jn−k(x j1, . . . , x jn−k)
fi1,...,ik(xi1, . . . , xik)
This formula is applied to statistical inference in the Bayesian approach that will be
treated in following sections.
8.3
Statistical Induction on Bernoulli Distribution
Let us consider a sequence of events (Ei)i=1,2,... stochastically independent condi-
tionally on the knowledge of a parameter Θ such that
P(Ei = 1|Θ = θ) = θ
where 0 < θ < 1.
The events Ei can be thought of as the result of experiments; their stochastic
independence conditionally on the knowledge of the value of Θ means that
P(E1 = ϵ1, . . . , En = ϵn|Θ = θ) =
n
i=1
P(Ei = ϵi|Θ = θ)
for any ϵi ∈{0, 1} for i = 1, . . . , n.

106
8
Statistics
Let Θ have an a priori probability density. We want to ﬁnd out how the distribution
of Θ changes after n experiments are performed. Assume that the results are E1 =
ϵ1, . . . , En = ϵn. The conditional density of Θ given E1 = ϵ1, . . . , En = ϵn is
denoted by
πn(θ|E1 = ϵ1, . . . , En = ϵn)
and it is called a posteriori density. By the composite probability law we have, given
0 ≤a < b ≤1 that
P(θ ∈[a, b]|E1 = ϵ1, . . . , En = ϵn) = P(θ ∈[a, b], E1 = ϵ1, . . . , En = ϵn)
P(E1 = ϵ1, . . . , En = ϵn)
.
(8.1)
By using the formula of total probabilities, that can be easily extended to this
continuous case, and the conditional independence of E1, . . . , En given Θ = θ we
can rewrite the right-hand side of (8.1) as
 b
a θϵ1+···+ϵn (1 −θ)n−(ϵ1+···+ϵn) π0(θ)dθ
 1
0 θϵ1+···+ϵn (1 −θ)n−(ϵ1+···+ϵn) π0(θ)dθ
.
Therefore we have
πn(θ|E1 = ϵ1, . . . , En = ϵn)
= 1
c π0(θ)θϵ1+···+ϵn (1 −θ)n−ϵ1−···−ϵn
for 0 ≤θ ≤1 where
c = P(E1 = ϵ1, . . . , En = ϵn) =
 1
0
θϵ1+···+ϵn (1 −θ)n−ϵ1−···−ϵn π0(θ) d(θ).
In particular, if a priori distribution of Θ is beta B(α, β) with parameters α and β,
the a posteriori distribution will also be beta B(α′, β′) with parameters
α′ = α +
n

i=1
ϵi
and
β′ = β + n −
n

i=1
ϵi
where n
i=1 ϵi and n −n
i=1 ϵi are respectively the number of events that have and
have not taken place. Therefore
πn(θ|E1 = ϵ1, . . . , En = ϵn) =
⎧
⎨
⎩
Γ (α′+β′)
Γ (α′) Γ (β′) θ α′−1 (1 −θ)β′−1 θ ∈[0, 1],
0
otherwise.

8.4 Statistical Induction on Expectation of Normal Distribution
107
8.4
Statistical Induction on Expectation of Normal
Distribution
Let (Xi)i = 1,2,... be a sequence of random numbers that are stochastically independent
given the knowledge of a parameter Θ with conditional probability density
f (x|θ) =
1
σ
√
2π
exp

−(x −θ)2
2σ2

for some σ > 0.
By using Bayes’ formula for densities on X1, . . . , Xn, Θ we get an expression for
the a posteriori density of Θ, i.e. the conditional density given X1 = x1, . . . , Xn =
xn:
πn(θ|x1, . . . , xn) = π0(θ) n
i = 1 f (xi|θ) pn(x1, . . . , xn)
= K π0(θ)
n
i = 1
f (xi|θ),
where pn(x1, . . . , xn) is the marginal density of X1, . . . , Xn and we have denoted by a
constant K the quantity pn(x1, . . . , xn)−1, since it does not depend on θ and can there-
fore thought of as a normalizing constant for the probability density πn(θ|x1, . . . , xn).
In the future we shall denote any normalization constant by K, even if its value
changes from one formula to the other, in order not to introduce too many constants.
If the a priori distribution of Θ is Gaussian N(μ0, σ2
0), we obtain
πn(θ|x1, . . . , xn) :=
= Kπ0(θ)
n
i=1
f (xi|θ)
= Ke
−(θ −μ0)2
2σ2
0
exp

−
n

i=1
(xi −θ)2
2σ2

= K exp

−1
2

 1
σ2
0
+ n
σ2

θ2 −2θ

μ0
σ2
0
+
n
i=1 xi
σ2
 
= K exp

−1
2
(θ −mn)2
σ2n

,
where

108
8
Statistics
mn =
μ0
σ2
0
+
n
i=1 xi
σ2
1
σ2
0
+ n
σ2
,
σ2
n =

 1
σ2
0
+ n
σ2
−1
and K is the normalizing constant. If ¯x denotes the sample average ¯x = x1+···+xn
n
,
the a posteriori distribution of Θ is Gaussian
N

μ0σ−2
0
+ ¯xnσ−2
σ−2
0
+ nσ−2
,
1
σ−2
0
+ nσ−2

.
The expectation can be thought of as a weighted average of μ0 and ¯x with weights
σ−2
0
and nσ−2.
8.5
Statistical Induction on Variance of Normal
Distribution
We consider now statistical induction on the variance of normal distribution. It is
convenient to use as parameter the inverse of the variance, called precision; it is
clear that precision carries the same amount of information as the variance. The
term precision is related to the interpretation of random numbers as measurements
of some quantity. Let (Xn)n=1,2,... be a sequence of random numbers stochastically
independent conditionally on the knowledge of the value of the parameter Φ.
Assume that the conditional probability density of each of the Xi, given that
(Φ = φ), is equal to
f (x|φ) = f (xi|φ) =
φ
1
2
√
2π
exp

−φ
2 (x −μ)2

,
where μ is some constant. The conditional density of X1, . . . , Xn given (Φ = φ)
called the likelihood factor is given by
n
i=1
f (xi|φ) = Kφ
n
2 exp

−φ
2
n

i=1
(xi −μ)2

= Kφ
n
2 exp

−nS2φ
2

,
where
S2 :=
n
i=1(xi −μ)2
n

8.5 Statistical Induction on Variance of Normal Distribution
109
is the average of the squares of the deviations of the xi’s from μ. If we assume that
the a priori distribution of Φ is Γ (α0, λ0), then the a posteriori density of Φ, given
that X1 = x1, . . . , Xn = xn, is given by:
πn(φ|x1, . . . , xn) = Kφ
n
2 +α0−1 exp

−φ(λ0 + nS2
2 )

for φ > 0 and 0 otherwise. That is the a posteriori distribution of Φ is gamma
Γ (α0 + n
2, λ0 + nS2
2 ).
8.6
Improper Distributions
Let us go back to the induction on the expectation of normal distribution. We want
to describe a vague initial state of information. This can be achieved by choosing an
a priori distribution with large variance. We can let the variance tend to inﬁnity. In
the limit we do not get a probability distribution.
Nonetheless we observe that the corresponding a posteriori distributions converge.
The limiting a posteriori distribution can be alternatively obtained by introducing as
a priori distribution the so called uniform improper distribution density π0(θ) = K.
This π0 does not correspond to a probability distribution, but it must be interpreted
in terms of the limiting procedure we have just described.
8.7
Statistical Induction on Expectation and Variance
of Normal Distribution
Let us now consider the case of statistical induction on both expectation and variance
of a normal distribution. Assume that we are in a state of vague information, that, as
we have said, can be described by means of an improper distribution. We have now
two unknown parameters Θ and Φ, respectively the expectation and the precision,
that is the inverse of the variance. Since Φ can take only positive values, we con-
sider as a priori distribution an improper uniform distribution for Θ and log Φ. This
corresponds to the improper density:
π0(θ, φ) = Kφ−1,
(φ > 0).
Assume that we have a sequence of random numbers that are stochastically indepen-
dent conditionally on the event that Θ and Φ take some deﬁnite values θ and φ and
that their conditional density is:
f (x|θ, φ) =
1
√
2π
φ
1
2 exp

−φ
2 (x −θ)2

.

110
8
Statistics
The conditional joint density of X1, . . . , Xn, given Θ = θ, Φ = φ, which is called
likelihood factor, is then
f (x1, . . . , xn|θ, φ) = Kφ
n
2 exp

−φ
2
n

i=1
(xi −θ)2

= Kφ
n
2 exp

−φ
2

(¯x −θ)2 + νs2
,
where ¯x =
n
i=1 xi
n
, ν = n −1, s2 =
n
i=1(xi −¯x)2
ν
. The joint a posteriori density
of Θ, Φ is obtained by Bayes’ formula for densities and is given by:
πn(θ, φ|x1, . . . , xn) = Kφ
n
2 −1 exp

−φ
2

(¯x −θ)2 + νs2
.
From joint a posteriori probability density of Θ and Φ we can get their marginal
densities by integrating with respect to the other variable. The integral with respect
to φ reduces to the integral of the gamma function. After collecting in the constant
K all factors that do not depend on θ, we obtain
πn(θ|x1, . . . , xn) =
 +∞
0
πn(θ, φ|x1, . . . , xn)dφ =
K

(¯x −θ)2 + νs2.
From this it follows that the random number T = ¯x −θ
s√ν has Student t density with
ν degrees of freedom
fT (t) = K

1 + t2
ν
−ν + 1
2
.
Analogously we obtain the a posteriori density of Φ by integrating the conditional
density πn(θ, φ|x1, . . . , xn) with respect to θ. It is a Gaussian integral that, apart from
constant factors, gives a factor φ−1
2 . The a posteriori marginal probability density of
Φ is
πn(φ|x1, . . . , xn) =
 +∞
0
πn(θ, φ|x1, . . . , xn)dθ = Kφ
ν
2 −1 exp

−νs2φ
2

,
with φ > 0. By making a linear change of variable we see that the random number
νs2Φ has a posteriori distribution with density
Ku
ν
2 −1 exp

−u
2

,
with u > 0, i.e. is χ2-distribution with ν degrees of freedom. The normalizing
constant is therefore given by K =
1
2
ν
2 Γ ( ν
2).

8.8 Bayesian Conﬁdence Intervals and Hypotheses’ Testing
111
8.8
Bayesian Conﬁdence Intervals and Hypotheses’ Testing
A synthetic description of a posteriori distribution can be achieved by means of
conﬁdence intervals or, in the multidimensional case, conﬁdence regions. Given
0 < α < 1, an α-level conﬁdence interval or conﬁdence region is an interval
or respectively a region whose a posteriori probability is 1 −α. The choice of an
interval or a region with this property is clearly arbitrary. In concrete situations one
can base the choice on symmetry criteria if the a posteriori density is symmetric or
alternatively one can choose the region with minimal volume in parameters’ space.
In the Bayesian approach to statistics, hypotheses’ testing can be related to the
deﬁnitions of conﬁdence intervals or regions. The hypotheses that parameters have
a given value is rejected if the value does not belong to the conﬁdence interval or
region. This procedure, it must be stressed, is arbitrary, since, as we have said, the
interval or region can be arbitrarily chosen. Nevertheless, since in many situations
there is a preferential choice, the use of hypotheses’ testing in Bayesian approach
can be accepted as a shortened and less precise form of induction with respect to the
complete analysis based on a posteriori distribution.
8.9
Comparison of Expectations for Normal Distribution
Assume that we have two samples of size respectively n1 and n2 that, conditionally
on the knowledge that the parameters Θ1 and Θ2 are equal respectively to θ1 and
θ2, are stochastically independent samples with Gaussian distribution N(θ1, σ2
1) and
N(θ2, σ2
2) respectively. If the a priori density of Θ1 and Θ2 is uniform improper,
Θ1 and Θ2 are stochastically independent a posteriori with Gaussian distribution
N(¯x1, σ2
1
n ) and N(¯x2, σ2
2
n ) respectively, where ¯x1, ¯x2 are the sample averages of the
samples.
Indeed, since the samples are stochastically independent and Θ1 and Θ2 are sto-
chastically independent in the a priori distribution, we can separately apply to the
samples the results on the induction on the expectation of normal distribution in the
case of uniform improper a priori distribution. If we deﬁne Θ = Θ2 −Θ1, then the
a posteriori distribution of Θ is in N(¯x2 −¯x1, σ2
2
n2
+ σ2
1
n1
).
Let us now consider the case when there is an extra parameter Φ such that con-
ditionally on the knowledge that Φ = φ and Θ1 = θ1, Θ2 = θ2, the two sam-
ples are stochastically independent with distributions respectively N(θ1, φ−1) and
N(θ2, φ−1). The conditional probability densities of the random numbers of the ﬁrst
and the second sample are then respectively

112
8
Statistics
f1(x|θ1, θ2, φ) =
1
√
2π
φ
1
2 exp

−φ
2 (x −θ1)2

,
f2(x|θ1, θ2, φ) =
1
√
2π
φ
1
2 exp

−φ
2 (x −θ2)2

.
Also here we consider the case of improper a priori distribution and precisely we
assume that Θ1, Θ2, log Φ are stochastically independent with uniform improper
distribution on R. This corresponds for Θ1, Θ2, Φ to an a priori improper density
π0(θ1, θ2, φ) = Kφ−1
(φ > 0).
Consider ﬁrst statistical induction for Φ. Here we can apply without any essential
change what we have seen about the induction for normal distributions with two
unknown parameters and obtain that the a posteriori density of Φ is given by:
Kφ
ν1+ν2
2
−1 exp

−s2φ
2

,
where s2 = ν1s2
1 + ν2s2
1 with νi = ni −1, i = 1, 2,
s2
i =
ni
j=1(xi, j −¯xi)2
vi
,
and xi, j is the j-th value of the i-th sample. By combining these results we can obtain
the a posteriori probability density of Θ = Θ2 −Θ1 in the case when Φ is unknown.
Indeed we have:
π(θ|x1, x2) = K

R+ φ
1
2 exp
⎛
⎝−
φ
2

1
n1 + 1
n2
 (θ −(¯x2 −¯x1))2
⎞
⎠φ
ν1 + ν2
2
−1 exp

−s2φ
2

dφ
= K2
ν1 + ν2 + 1
2
⎡
⎣(θ −(¯x2 −¯x1))2

1
n1 +
1
n2

+ s2
⎤
⎦
−ν1 + ν2 + 1
2

R+ y
ν1 + ν2 + 1
2
−1e−ydy
= K2
ν1 + ν2 + 1
2
Γ (ν1 + ν2 + 1
2
)
⎡
⎣(θ −(¯x2 −¯x1))2

1
n1 + 1
n2

+ s2
⎤
⎦
−ν1 + ν2 + 1
2
,
= K(2/s2)
ν1+ν2+1
2
Γ (ν1 + ν2 + 1
2
)
⎡
⎣(θ −(¯x2 −¯x1))2
s2

1
n1 + 1
n2

+ 1
⎤
⎦
−ν1 + ν2+1
2

8.9 Comparison of Expectations for Normal Distribution
113
where we have used the change of variable y = 1
2

(θ−(¯x2−¯x1))2

1
n1 + 1
n2

+ s2

φ to express
the integral in terms of a Gamma function. We obtain
π(θ|¯x1, ¯x2) = K
⎡
⎣(θ −(¯x2 −¯x1))2
νs2

1
n1 + 1
n2
 + 1
⎤
⎦
−ν + 1
2
,
where ν = ν1 + ν2 and K is now a suitable normalization constant. If we deﬁne
T = θ −(¯x2 −¯x1)
s

1
n1 + 1
n2
 1
2 ,
we see that the a posteriori distribution of T is Student with ν = ν1 + ν2 degrees
of freedom. This allows us to use Student distribution’s table to obtain conﬁdence
intervals for Θ.

Part II
Exercises

Chapter 9
Combinatorics
Exercise 9.1 The game of bridge is played with 52 cards. Compute:
1. The number of different ways a player can receive an handful of 13 cards.
2. The number of different ways the cards can be distributed among 4 players.
3. The number of different ways a player can receive an handful of 13 cards all
different in values. Which is the number of different ways in which all 4 players
receive cards all different in values?
4. The number of different ways a player can receive ﬂush number cards of the same
sign. In how many ways can a player obtain at least 2 cards with equal value?
Solution 9.1
1. The number of different ways a player can receive an handful of
13 cards is given by the simple combinations
52
13

.
Namely one has to choose 13 elements out of 52 without repetitions and without
taking in account of the order.
2. For the ﬁrst player we have already computed the number of different ways she
can receive an handful of 13 cards. For the second player we can choose 13 cards
out of the 52 −13 = 39 remaining ones. Analogously for the third player. The
fourth player receives the remaining 13 cards. The number of different ways in
which all 4 players receive cards all different in values is then
 52
13
 39
13
 26
13
 13
13

=
52!
(13!)4 .
The multinomial coefﬁcient counts the number of ways of making 4 groups of
13 elements each out of a set of 52 cards.
3. Since the cards are all different in values, we can think that they are in increasing
order. For the ﬁrst card, we can choose one of the four aces. For the second one,
one of the 4 twos, and so on. The number of different ways a player can receive
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_9
117

118
9
Combinatorics
an handful of 13 cards all different in values is then in
4 · 4 · · · · · 4



13 times
= 413
different ways. If we consider all 4 players, we have that for the second player
the choices for each card will reduce to
3 · 3 · · · · · 3



13 times
= 313
different ways. Then the 4 players receive cards all different in values in
413 · 313 · 213 · 113 = (4!)13
different ways.
4. A player can receive ﬂush number cards of the same sign in 4 different ways,
since there exist ﬂush number cards of 4 different signs. If we consider 4 players,
the number of ways of assigning them ﬂush number cards of the same sign is
given by the number of permutations of the 4 signs, i.e.
4 · 3 · 2 · 1 = 4!.
The number of ways in which a player can obtain at least 2 cards with equal
value is equal to
52
13

−413
that is the number of all possible choices minus the number of ways of obtaining
an handful of all different cards.
⊓⊔
Exercise 9.2 At the ticket counter of a theatre there are available tickets with num-
bers from 1 to 100. The tickets are randomly distributed among the buyers. Four
friends A, B, C, D buy separately a ticket each.
1. Which is the probability that they have received the tickets with numbers
31, 32, 33 and 34?
2. Which is the probability that they have received the tickets 31, 32, 33 and 34 in
this order?
3. Which is the probability that they have received tickets with 4 consecutive num-
bers?
4. Which is the probability that A, B, C receive tickets with a number greater than
50?

9
Combinatorics
119
Solution 9.2
1. To compute this probability we use the formula
♯favorable cases
♯possible cases .
The possible cases are all the ways of choosing 4 numbers out of 100, i.e.
100
4

.
There exists only 1 favorable case, i.e. to choose the numbers 31, 32, 33 and
34. Hence the probability that the three friends have received the tickets with
numbers 31, 32, 33, 34 is given by
p =
1
100
4
.
2. Here the number of possible cases is given by
D100
4
= 100!
96! .
The probability that the 4 friends receive the tickets 31, 32, 33, 34 in this order
is then
p =
1
D100
4
=
96!
100!.
3. One can obtain tickets with consecutive numbers in
100 −3 = 97
different ways. We need also to consider the case {97, 98, 99, 100}. The proba-
bility of receiving 4 consecutive tickets is then
97
100
4
 = 97!4!
100! .
4. The probability that A, B and C receive tickets with numbers greater than 50 is
p =
50
100
49
99
48
98.
For the ﬁrst case the are 50 favorable cases (all tickets with number from 51
up to 100) out of 100. For the second ticket there are 49 possibilities out of the
99 tickets left. And so on.

120
9
Combinatorics
Exercise 9.3 A credit card PIN consists of 5 numbers. We assume that every
sequence of 5 digits is generated with the same probability. Compute:
1. The probability that the numbers composing the PIN are all different.
2. The probability that the PIN contains at least 2 numbers which are equal.
3. The probability that the numbers composing the PIN are all different if the ﬁrst
digit is different from 0.
4. The probability that the PIN contains exactly 2 numbers which are equal, if the
ﬁrst digit is different from 0.
Solution 9.3
1. A PIN differs from another one if the digits are in different order.
The possible cases are given by
105.
The favorable cases, when all digits are different, are
D10
5
= 10!
5! .
The probability that the numbers composing the PIN are all different is then
p1 = D10
5
105 .
2. The probability that the PIN contains at least 2 numbers which are equal is
p = 1 −p1 = 1 −
10!
5! 105 ,
where p1 is the probability that the numbers composing the PIN are different.
3. In this case the number of possible cases is
9 · 10 · 10 · 10 · 10.
For the ﬁrst digit we have 9 possibilities (all numbers from 1 to 9). We need to
choose the remaining digits without repetitions and taking in account the order:
we have D9
4 ways. The number of favorable cases is then
9 · 9 · 8 · 7 · 6 = 9 · D9
4.
The probability that the numbers composing the PIN are all different if the ﬁrst
digit is different from 0 is then
9 · D9
4
9 · 104 = D9
4
104 .

9
Combinatorics
121
4. The possible cases are still given by
9 · 104.
In order to compute the number of ways in which the PIN contains exactly 2
numbers which are equal, if the ﬁrst digit is different from 0, we can proceed as
follows:
(a) For the digit that is repeated: without loss of generality we can think that
it is equal to the ﬁrst digit in the string. There are 9 ways of choosing it
(remember: the 0 is now excluded).
(b) We choose the place of the repeated digit in the string: there are
4
1

positions where it can be placed.
(c) The other digits must be different from the ﬁrst one. They can be placed in
D9
3
different ways in the string.
In total we have
9 ·
 4
1

· D9
3
possibilities. The procedure illustrated in (a),(b), and (c) will be called in
the sequel the string rule.
(d) If the repeated digit is different from the ﬁrst one, we have
• 9 ways of choosing the ﬁrst digit;
• 9 ways of choosing the repeated digit;
•
 4
2

ways of choosing the place in the string;
• D8
2 ways of placing the remaining digits.
Totally we have
9 · 9 · D8
2 ·
 4
2

.
The total number of favorable cases is then
9 ·
4
1

· D9
3 + 9 · 9 · D8
2 ·
 4
2

= 9 ·
 4
1

+
 4
2
	
· D9
3 = 9 ·
 5
2

· D9
3 ,

122
9
Combinatorics
where we have used the formula
n
r

=
n −1
r

+
n −1
r −1

.
⊓⊔
Exercise 9.4 Four fair dice are thrown at the same time. Their faces are numbered
from 1 to 6. Compute:
(a) The probability of obtaining four different faces.
(b) The probability of obtaining at least 2 equal faces.
(c) The probability of obtaining exactly 2 equal faces.
(d) The probability that the sum of the faces is equal to 5.
(e) We throw only 2 dice. Compute the probability that the sum of the faces is an
odd number.
Solution 9.4 (a) To compute the probability we use the formula
p = ♯favorable cases
♯possible cases .
(9.1)
The possible cases are given by
possible cases = 6 · 6 · 6 · 6 = 64.
This is given by the number of all possible dispositions of 4 elements out of 6.
The favorable cases are given by the simple dispositions of 4 elements out of 6,
since the faces are required to be different from each other:
favorable cases = 6 · 5 · 4 · 3 = D6
4.
The probability of obtaining four different faces is then
P(all the thrown dies have different faces) = D6
4
64 = 5
18.
(b) The probability of obtaining at least 2 equal faces can be computed by using the
probability obtained above, since:
P(the thrown dice have at least 2 same faces)
= 1 −P(all the thrown dice have different faces)
= 1 −D6
4
64 = 13
18.

9
Combinatorics
123
c) Also in this case we use the string rule as in Exercise 9.3. The number of the
ways of obtaining exactly 2 equal faces is then:
 4
2

· 6 · D5
2,
where
 4
2

= ♯ways of choosing 2 dice with equal faces,
6 = ♯ways of choosing the face which is repeated,
D5
2 = ♯ways of choosing the remaining faces.
Recall that the remaining faces must be different among each other and with
respect to the one which is repeated.
(d) In order to have the sum of the faces equal to 5, the only possibility is that 3
faces present the number 1 and one the number 2, since we are dealing with 4
dice. We compute ﬁrst the favorable cases. After having chosen the places for
the number 1, it remains only one possibility for the number 2, i.e. we have
4
3

· 1 = 4
favorablecases.Thepossiblecasesaregivenby64 waysofhavingaconﬁguration
of 4 dice. Hence the probability that the sum of the faces is equal to 5 is given
by
p = 4
64 .
(e) The sum of the faces is odd if one of the faces presents an odd number and the
other one an even number. Hence
♯favorable cases =
2
1

· 3 · 3 = 18,
where
2
1

counts the number of ways for a die to come out with an even face.
Hence
P(the sum of the faces is given by an odd number) = 2 · 32
62
= 1
2.
More simply, one can consider that the sum of the faces can be either odd or
even. Hence:

124
9
Combinatorics
♯possible cases = 2
♯favorable cases = 1,
and consequently
P(the sum of the faces is given by an odd number) = 1
2.
⊓⊔
Exercise 9.5 Two factories A and B produce garments for the same trademark Y.
For the factory A, 5% of the garments present some production defect; for the
factory B, 7% of the garments present some production defect. Furthermore 75%
of the garments sold by Y derive from the the factory A, while the remaining 25%
comes from the factory B. We suppose that a garment is chosen randomly with equal
probability among all the garments on sale. Compute:
1. The probability of purchasing a garment of the trademark Y which presents some
production defect.
2. The probability that the garment comes from the factory A, subordinated to the
fact that it presents some production defect.
Solution 9.5 We denote by:
• with A the event
A = {the garment comes from the factory A};
• with B the event
B = {the garment comes from the factory B};
• with D the event
D = {the garment presents some production defect}.
1. The probability of purchasing a garment of the trademark Y which presents some
production defect can be computed with the formula of the total probabilities,
since we do not know whether it comes from factory A or B. Hence
P(D) = P(D|A) P(A) + P(D|B) P(B)
=
5
100
75
100 +
7
100
25
100 = 11
200.

9
Combinatorics
125
2. The probability that the garment comes from the factory A, if it presents some
production defect, is given by:
P(A|D) = P(D|A) P(A)
P(D)
= 15
22.
This subordinated probability has been computed with Bayes’ Formula.
⊓⊔
Exercise 9.6 We consider 3 different elementary schools E, M, S. The percentage
of pupils wearing glasses is 10% in the school E, 25% in the school M and 40% in
the school S. Compute:
1. The probability that by choosing randomly 3 pupils, one out of each school, at
least one of them wears glasses.
2. The probability that a pupil wears glasses, if we randomly choose her or him out
of the three schools (each school can be picked up with the same probability).
3. The probability that the pupil belongs to school E, if she wears glasses.
Solution 9.6
1. The quickest method to compute the probability that by choosing
by chance 3 pupils, one out of each school, at least one of them wears glasses, is
to evaluate the probability that none of them wears glasses. If B is the event that
at least one of the 3 pupils wears glasses, then
P(B) = 1 −P

˜B

.
In this case P

˜B

= 90
100
75
100
60
100 = 81
200, from which
P(B) = 1 −81
200 = 119
200.
2. Let O be the event
O = {the pupil wears glasses}.
Theprobabilityof O canbecomputedbyusingtheformulaofthetotalprobability,
since we do not know which school the pupil belongs to. We set
• E = {the pupil belongs to school E};
• M = {the pupil belongs to school M};
• S = {the pupil belongs to school S}.
We then have:
P(O) = P(O|E) P(E) + P(O|M) P(M) + P(O|S) P(S)
= 1
10
1
3 + 1
4
1
3 + 2
5
1
3 = 1
4.

126
9
Combinatorics
Note that we have assumed that each school can be picked up with the same
probability.
3. The probability that the pupil belongs to school E, if she wears glasses, can be
computed by using Bayes’ formula:
P(E|O) = P(O|E) P(E)
P(O)
= 2
15 .
⊓⊔

Chapter 10
Discrete Distributions
Exercise 10.1 Two friends A and B are playing with a deck of cards consisting of
52 cards, 13 for each sign. They choose out 2 cards each. Player A starts. In order to
win, the player has to be the ﬁrst to extract the ace of spade or 2 cards of diamonds.
After having chosen the 2 cards, they put the 2 cards back in the deck and mix it.
Compute the probability that:
(a) Player A wins after 3 trials (i.e. after each player has done 2 extractions).
(b) Player A wins, player B wins, nobody wins.
(c) Let T be the random number representing the number of the trial, when one of
the player ﬁrst wins. Compute the expectation of T .
(d) Which is the probability distribution of T ?
Solution 10.1 (a) The trials of the 2 players can be represented as a sequence of
stochastically independent and equally distributed random trials. The probability
that player A wins after 3 trials (i.e. after each player has done 2 extractions) is
then equal to the probability of ﬁrst success after
2 + 2 + 1 = 5
trials. The player A wins if she extracts the ace of spade or 2 cards of diamonds.
The probability of this event is given by
p =
51
52
2
 +
13
2

52
2

(10.1)
where we have used the fact that the events are incompatible and that:
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_10
127

128
10
Discrete Distributions
1. The probability of extracting the ace of spade, is given by
1·
⎛
⎝51
1
⎞
⎠
⎛
⎝52
2
⎞
⎠
.
2. The probability of extracting 2 cards of diamonds, is given by
⎛
⎝13
2
⎞
⎠
⎛
⎝52
2
⎞
⎠
.
Let T be the random number representing the ﬁrst time of success. The proba-
bility that A wins at the third trial is
P(T = 5) = p(1 −p)4 ,
where p is given by (10.1).
(b) If A wins, the game stops with an odd trial. The probability that A wins is then
P(A wins) =
∞

k=0
P(T = 2k + 1)
=
∞

k=0
p(1 −p)2k = p
1
1 −(1 −p)2 .
If B wins, the game stops with an even trial. The probability that B wins is then
P(B wins) =
∞

k=1
P(T = 2k)
= p
∞

k=1
(1 −p)2k−1
=
p
1 −p

1
1 −(1 −p)2 −1

=
p
1 −p
(1 −p)2
1 −(1 −p)2
=
p(1 −p)
1 −(1 −p)2 = 1 −p
2 −p .
The probability that nobody wins is given by

10
Discrete Distributions
129
P(nobody wins) = 1 −P(A wins) −P(B wins)
= 1 −
∞

k=0
P(T = 2k + 1) −
∞

k=1
P(T = 2k)
= 1 −
∞

k=1
P(T = k)
= 0 .
(c)–(d) The random number T that represents the time when the game is decided,
has a geometric distribution of parameter p since it denotes the ﬁrst time of
success in a sequence of stochastically independent and identically distrib-
uted trials. Hence the expectation of T is given by:
P(T ) = 1
p =
52
2

1 +
13
2
 .
⊓⊔
Exercise 10.2 Let X, Y be two stochastically independent random numbers with
Poisson distribution with parameters μ and σ, respectively.
1. Let Z = X + Y. Compute the expectation and the variance of Z.
2. What is the set I (Z) of possible values for Z?
3. Compute P(Z = i), for i ∈I (Z).
4. Compute cov(Z, X,).
5. Let u > 0; compute the generating function φZ(u) = P(uZ) of Z.
Solution 10.2
1. By the linearity of the expectation we obtain
P(Z) = P(X + Y) = P(X) + P(Y) = μ + σ .
To compute the variance, we use the formula of the variance of the sum
σ2(X + Y) = σ2(X) + σ2(Y) + 2 cov(X, Y) .
Since X, Y are stochastically independent, we have
cov(X, Y) = 0 .
Hence
σ2(X + Y) = σ2(X) + σ2(Y) = μ + λ .

130
10
Discrete Distributions
2. The set I (Z) of possible values for Z is given by
I (Z) = N = {inf(X) + inf(Y), . . . } .
3. We now compute the probability distribution of Z. The event {Z = i} can be
written as
{Z = i} = {X = 0, Y = i} + {X = 1, Y = i −1} + · · · + {X = i, Y = 0}
=
i
k=0
{X = k, Y = i −k},
since the events {X = k, Y = i −k} are disjoint for k = 0, . . . , i. By the linearity
of the expectation we obtain
P(Z = i) =
i
k=0
P(X = k, Y = i −k) .
Furthermore X, Y are stochastically independent, hence
P(X = k, Y = i −k) = P(X = k) P(Y = i −k),
so that
P(Z = i) =
i
k=0
P(X = k) P(Y = i −k)
=
i
k=0
μk
k! e−μ σ(i−k)
(i −k)! e−σ
= e−(μ+σ)
i!
i
k=0
i!
k! (i −k)! μk σ(i−k)
= (μ + σ)i
i!
e−(μ+σ) ,
where we have used Newton’s binomial formula. Therefore Z has Poisson distri-
bution with parameter μ + λ.
4. In order to compute the covariance between Z and X, we proceed as follows:
cov(Z, X) = P(Z X) −P(Z) P(X)
= P ((X + Y)X) −(P(X) + P(Y)) P(X)
= P(X2) + P(XY) −P(X)2 −P(Y)P(X)
= σ2(X)
= μ .

10
Discrete Distributions
131
5. For μ > 0, the generating function of Z is given by
φZ(u) = P(uZ) = P(u X+Y) .
Since X, Y are stochastically independent, we have
P(u X+Y) = P(u X · uY) = P(u X) · P(uY) .
We now compute P(u X) by using the formula for the expectation of a function
of X:
P(u X) =
+∞

i=0
uiP(X = i)
= e−μ
+∞

i=0
(uμ)i
i!
= e(u−1) μ,
where in the last step we have used the series:
+∞

i=0
xi
i! = ex.
It follows that
φZ(u) = P(u X) · P(uY)
= e(u−1) μ e(u−1) σ
= e(u−1) (μ+σ).
Since the generating function uniquely identiﬁes the distribution, this proves that
Z has Poisson distribution with the parameter μ + σ.
⊓⊔
Exercise 10.3 In a small village with 200 inhabitants, 5 inhabitants are affected by
a particular genetic disease. A sample of 3 individuals is chosen randomly among
the population (all subsets have the same probability of being chosen). Let X be the
number of individuals in the sample who are affected by the disease.
1. Determine the set I (X) of possible values for X.
2. Determine the probability distribution of X.
3. Compute the expectation and the variance of X.

132
10
Discrete Distributions
Solution 10.3
1. The possible values of X are 0, 1, 2 and 3, i.e. the minimum
number of people affected by the disease in the sample is 0 and the maximum
number is 3.
2. Consider the event {X = i}, i ∈I (X). To determine the probability distribution
of X, we need to compute
P(X = i),
i ∈I (X) .
To this purpose we use the formula
♯favorable cases
♯possible cases .
The number of possible cases is given by the number of ways of choosing 3
people out of 200 inhabitants, i.e.
200
3

.
The number of favorable cases is given by the number of ways of choosing i
people out of the group of inhabitants affected by the disease and (3 −i) people
out of the group of ‘healthy’ people, i.e.
 5
i
  195
3 −i

.
We obtain
P(X = i) =
 5
i
  195
3 −i

 200
3

.
The distribution of X is then hypergeometric.
3. We can compute directly the expectation of X, since I (X) consists only of 4
values:
P(X) =
3

i=0
i P(X = i)
=
1
 200
3


5
195
2

+ 20
195
1

+ 30

= 3
40 .

10
Discrete Distributions
133
For the variance the computations is analogous. It is sufﬁcient to apply the
formula
σ2(X) = P(X2) −P(X)2
and to compute P(X2) =
3

i=0
i2 P(X = i).
⊓⊔
Exercise 10.4 At a horse race there are 10 participants. Gamblers can win if they
correctly predict the ﬁrst 3 horses in order of arrival. We suppose that all the orders
have the same probability of occurrence and that the gamblers choose independently
of each other and with the same probability the 3 horses on which to bet.
1. Compute the probability that one of the gamblers wins.
2. If the gamblers are 100 in total, let X be the random numbers counting the number
of gamblers who win. Determine I (X) and P(X = i) for i = 1, 2, 3.
3. Compute expectation and variance of X.
4. Suppose that the gamblers are numbered from 1 to 100. Compute the probability
that there is at least one winner and that the winner with the minimal number has
a number greater or equal to 50.
Solution 10.4
1. The probability that a gambler wins can be computed with
the formula
♯favorable cases
♯possible cases .
In this case, the possible cases are given by the simple dispositions of 3 elements
out of 10. They represent the number of ways of assuming the ﬁrst 3 positions for
the 10 horses. Only one is the winning triplet, hence the probability of winning
for a gambler is given by
p =
1
D10
3
=
7!
10! =
1
720 .
2. If X is the random numbers counting the number of gamblers who win, we can
write
X = E1 + E2 + · · · + E100,
where the event Ei is veriﬁed if the i-th gambler wins. The events Ei, i =
1, . . . , 100, are stochastically independent and identically distributed since the
gamblers choose independently of each other and with the same probability the 3
horses on which to bet. Hence X has binomial distribution Bn(n, p) of parameters
n = 100 and p =
1
720. The set of possible values is then

134
10
Discrete Distributions
I (X) = {0, 1, . . . , 100}
and
P(X = i) =
 100
i
  1
720
i 
1 −
1
720
100−i
.
In particular, we obtain:
i = 1
P(X = 1) = 100 ·
1
720 ·
719
720
99
.
i = 2
P(X = 2) =
100
2
  1
720
2
·
719
720
98
.
i = 3
P(X = 3) =
 100
3
  1
720
3
·
719
720
97
.
3. The expectation of X is given by linearity by
P(X) = P(E1 + · · · + E100)
=
100

i=1
P(Ei) = 100 ·
1
720 = 5
36 .
Analogously by the formula of the variance of the sum of n random numbers, we
have:
σ2(X) = σ2(E1 + · · · + E100)
=
100

i=1
σ2(Ei) +
100

i, j=1
cov(Ei, E j)
	



0
= 100 ·
1
720 ·

1 −
1
720

.
Here we have used that the events Ei are stochastically independent.
4. In order to have a winner with minimal number greater than or equal to 50, we
need that the ﬁrst 49 gamblers do not win and that at least one of the gamblers
with number from 50 to 100 wins. Let E be the event that all the all the gamblers
with number from 1 to 49 lose and F the event that at least one of the gamblers

10
Discrete Distributions
135
with number from 50 to 100 wins. The probability that there is at least one winner
and that the winner with the minimal number has a number greater than or equal
to 50 is then
P(E F) = P(E)P(F) =
719
720
49 
1 −
719
720
51
,
where P(F) = 1 −P(F) and F is the event that no gambler with number from
50 to 100 wins.
⊓⊔
Exercise 10.5 In an opinion poll 100 people are asked to answer a questionnaire
with 5 questions. Each question can be answered only yes or no. For each person the
probability of all possible answers is the same and their choices are stochastically
independent. Let N be the number of interviewed people that answer yes to the ﬁrst
questions or answer yes at least to 4 questions.
1. Which is the probability distribution of N?
2. Compute the expectation, the variance and the generating function of N.
Solution 10.5
1. Let Ei be the event that the i-th interviewed person has answered
yes to the ﬁrst questions or yes at least to 4 questions. We can rewrite N as
N = E1 + E2 + · · · + E100 .
The events are stochastically independent and identically distributed since every
person answers independently of the other ones. Furthermore we have assumed
that the probability of all possible answers is the same. It is sufﬁcient to compute
the probability of each Ei. We put:
• Fi= {the i-th interviewed person answers yes to the ﬁrst question};
• Gi= {the i-th interviewed person answers yes at least to 4 questions}.
We obtain that Ei = Fi ∨Gi e
P(Ei) = P(Fi) + P(Gi) −P(Fi ∧Gi) .
The probability of Fi, Gi e Fi ∧Gi are given by:
(a)
P(Fi) = 1
2 · 1
2 = 1
4 .
For all question we have 2 possible cases (yes and no), while for the ﬁrst
question we have only one possible choice (yes).
(b)
P(Gi) =
 5
4
 1
2
5
+
5
5
 1
2
5
.

136
10
Discrete Distributions
A person answers yes at least to 4 questions if she answers yes to exactly 4
questions or to exactly 5 questions.
(c)
P(Fi ∧Gi) =
 3
2
 1
2
5
+
3
3
 1
2
5
.
In the case the events happen at the same time, we need to choose only the
other 2, respectively 3 questions to which the candidate answer yes.
Finally
P(Ei) = 1
4 +
 5
4
 1
25 + 1
25 −3
25 −1
25 =
1
22 + 1
24 =
5
16 .
We obtain that I (N) = {0, . . . , 100} and
P(N = i) =
100
i
  5
16
i 
1 −5
16
100−i
,
i.e. N has binomial distribution Bn(100, 5
16).
2. The expectation of N is given by
P(N) =
100

i=1
iP(Ei) = 100 · 5
16 = 125
4 .
The variance of N is given by
σ2(N) =
100

i=1
σ2(Ei) +
100

i, j=1
cov(Ei, E j)
	



0
= 100 · 5
16 ·

1 −5
16

.
The generating function of N is given by
φN(t) = P(t N)
=
100

i=0
 100
i

·
 5t
16
i
·

1 −5
16
100−i
=
 5t
16 + 1 −5
16
100
,
where we have used Newton’s binomial formula.
⊓⊔

10
Discrete Distributions
137
Exercise 10.6 A box contains 8 balls: 4 white and 4 black. We draw 4 balls. Let Ei
be the event that the i-th ball extracted is white. Let X = E1 + E2, Y = E3 + E4.
(a) Compute the joint distribution of X and Y.
(b) Compute P(X), P(Y), σ2(X), σ2(Y).
(c) Compute cov(X, Y), the correlation coefﬁcient ρ(X, Y). Are X and Y stochas-
tically independent?
Solution 10.6 (a) Consider the random vector (X, Y). The set of possible values
for (X, Y) is given by
I (X, Y) = {(i, j)| i = 0, 1, 2, j = 0, 1, 2} .
To compute the joint distribution of (X, Y), we need to calculate
P(X = i, Y = j) = P(Y = j| X = i)P(X = i)
for all (i, j) ∈I (X, Y). The probability of extracting a white ball in the ﬁrst 2
extractions is given by
P(X = i) =
4
i
 
4
2 −i

 8
2

.
Here the possible cases are
 8
2

since we consider only the ﬁrst 2 extractions.
Moreover
P(Y = j| X = i) =
4 −i
j
 4 −(2 −i)
2 −j

 6
2

=
4 −i
j
  2 + i
2 −j

 6
2

.
After the ﬁrst 2 extractions, only 6 balls are left in the box. We have to draw 2
more balls, j among the remaining white ones (4 −i) and (2 −j) among the
remaining black ones 4 −(2 −i) = 2 + i. The joint distribution of X and Y
is then

138
10
Discrete Distributions
P(X = i, Y = j) =
4 −i
j
  2 + i
2 −j

 6
2

·
 4
i
 
4
2 −i

 8
2

.
(b) To compute P(X) and P(Y) we use the fact that the events Ei have equal prob-
ability (but they are not stochastically independent!), hence
P(X) = P(E1) + P(E2) = 2 · 4
8 = 1
and
P(X) = P(Y) = 1 .
The events E1 and E2 (and consequently also E3 e E4) are negatively correlated
with covariance:
cov(E1, E2) = P(E1E2) −P(E1)P(E2)
= P(E2|E1)P(E1) −P(E1)P(E2)
= −1
28 .
The variance of X is then
σ2(X) = σ2(E1 + E2) = σ2(E1) + σ2(E2) + 2cov(E1, E2)
= 1
4 + 1
4 −1
28 = 13
28 .
Also in this case σ2(Y) = σ2(X) = 13
28.
(c) We have:
cov(X, Y) = cov(E1 + E2, E3 + E4)
= cov(E1, E3) + cov(E1, E4) + cov(E2, E3) + cov(E2, E4)
= 4 ·

−1
28

= −1
7 .
Here we have used that fact that the covariance is a bilinear function. Finally,
the coefﬁcient of correlation between X and Y is equal to:
ρ(X, Y) = cov(X, Y)
σ(X)σ(Y) =
−1
7

13
28 ·

13
28
= −4
13 .
⊓⊔

10
Discrete Distributions
139
Exercise 10.7 Let E1, E2, F1, F2 bestochasticallyindependenteventswithP(E1) =
P(E2) = 1
4, P(F1) = P(F2) = 1
3. Let X = E1 + E2, Y = F1 + F2.
(a) Compute the set of possible values and the probability distributions of X and Y.
(b) Compute P(X + Y), σ2(X + Y).
(c) Compute P(X = Y), P(X = −Y).
Solution 10.7 (a) Since E1, E2 are events, i.e. random numbers that can assume
only the values 0 and 1, we have that the set of possible values of X is given by
I (X) = {0, 1, 2} .
Analogously for Y
I (Y) = {0, 1, 2} .
To compute the probability distribution of X means that we have to calculate
with which probability X assumes each of the possible values. For example, we
have that
P(X = 0) = P(E1 + E2 = 0)
= P(E1 = E2 = 0) = P( ˜E1)P( ˜E2) = 9
16 .
Since X is equal to the sum of 2 stochastically independent events with the
same probability, we can immediately say that the distribution of X is binomial
Bn(n, p) with parameters n = 2 and p = 1
4. Analogously Y has binomial
distribution Bn(2, 1
3) and we have that
P(X = i) =
 2
i
 1
4
i 3
4
2−i
,
i = 0, 1, 2
P(Y = j) =
 2
j
 1
3
 j 2
3
2−j
,
j = 0, 1, 2 .
(b) To compute the expectation, we can use the linearity
P(X + Y) = P(E1 + E2 + F1 + F2)
= P(E1) + P(E2) + P(F1) + P(F2)
= 2 · 1
4 + 2 · 1
3 = 7
6 .
For the variance, we use the formula of the variance of a sum:
σ2(X + Y) = σ2(X) + σ2(Y) + 2 cov(X, Y).

140
10
Discrete Distributions
Since X and Y have binomial distribution, we have
σ2(X) = 2 · 1
4 · 3
4 = 3
8,
σ2(Y) = 2 · 1
3 · 2
3 = 4
9 .
To compute the covariance between X and Y we use the fact that the events
E1, E2, F1, F2 are stochastically independent in the following way:
cov(X, Y) = cov(E1 + E2, F1 + F2)
= cov(E1, F1) + cov(E1, F2) + cov(E2, F1) + cov(E2, F2)
= 0 .
Hence
σ2(X + Y) = 3
8 + 4
9 = 59
72 .
(c) To compute P(X = Y) we note that the event
(X = Y)
is given by
(X = Y) = (X = 0, X = 0) + (X = 1, Y = 1) + (X = 2, Y = 2) .
Hence
P(X = Y) =
2

i=0
P(X = i, Y = i)
=
2

i=0
P(X = i)P(Y = i)
=
2

i=0
2
i
 1
4
i 3
4
2−i 2
i
 1
3
i 2
3
2−i
=
2

i=0
2
i
2  1
12
i 1
2
2−i
= 1
4
2

i=0
2
i
2 1
6
i
= 61
144 .

10
Discrete Distributions
141
On the other side the event
(X = −Y)
is veriﬁed only if
(X = −Y) = (X = 0, Y = 0) .
Hence
P(X = −Y) = P(X = 0, Y = 0) = P(X = 0)P(Y = 0) = 1
4 .
⊓⊔

Chapter 11
One-Dimensional Absolutely Continuous
Distributions
Exercise 11.1 The random numbers X, Y and Z are stochastically independent with
exponential distribution of parameter λ = 2.
(a) Compute the density of the probability of X + Y and of X + Y + Z.
(b) Let E, F, G be the events E = (X ≤2), F = (X + Y > 2), G = (X + Y +
Z ≤3). Compute P(E), P(F), P(G) e P(E F).
(c) Determine if E, F and G are stochastically independent.
Solution 11.1 (a) The exponential distribution is a particular case of the gamma
distribution with parameter 1, λ. If X, Y and Z are stochastically independent
random numbers with exponential distribution of parameter λ = 2, i.e. Gamma
distribution Γ (1, 2), we can use the following property of the the sum of sto-
chastically independent random numbers with Gamma distribution
Γ (α, λ) + Γ (β, λ) ∼Γ (α + β, λ).
Hence W1 = X + Y has distribution Γ (2, 2). We can iterate this procedure and
obtain that
W2 = X + Y + Z = W1 + Z
has distribution Γ (3, 2).
(b) We have:
P(E) = P(X ≤2) =
 2
0
2e−2xdx
= 1 −e−4 ;
P(F) = P(X + Y > 2) =
 +∞
2
4xe−2xdx
=

−2xe−2x+∞
2
+ 2
 +∞
2
e−2xdx
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_11
143

144
11
One-Dimensional Absolutely Continuous Distributions
= 4e−4 +

−e−2x+∞
2
= 5e−4 ;
P(G) = P(X + Y + Z ≤3) =
 3
0
4x2e−2xdx
= 1 −
 +∞
3
4x2e−2xdx
= 1 −

−2x2e−2x+∞
3
+ 4
 +∞
3
xe−2xdx

= 1 −25e−6,
and
P(E F) = P(X ≤2, X + Y > 2)
= P(X ≤2, Y > 2 −X) = P(X ≤2, Y > 0)
= P(X ≤2)P(Y > 0) = P(X ≤2) .
Here we have used the fact that X and Y are assumed to be stochastically inde-
pendent, as well as that the product of 2 events denotes that both conditions must
be simultaneously satisﬁed.
(c) To determine if E, F, G are stochastically independent, we need to verify all the
following conditions:
P(E F) = P(E)P(F);
P(EG) = P(E)P(G);
P(FG) = P(F)P(G);
P(E FG) = P(E)P(F)P(G) .
If one of them is not veriﬁed, then the events are not stochastically independent.
We can immediately see that
P(E F) ̸= P(E)P(F)
by using the results above. Hence the three events are not stochastically inde-
pendent.
□
Exercise 11.2 Let X be a random number with standard normal distribution. Let
Y = 3X + 2 and Z = X2.
1. Compute the c.d.f. and the density of Y.
2. Estimate P(Y ≥y), where y > 0.
3. Compute the expectation and the variance of Z.
4. Compute the c.d.f. and the density of Z.

11
One-Dimensional Absolutely Continuous Distributions
145
Solution 11.2
1. Put
n(t) =
1
√
2 π
e−t2
2
We compute the c.d.f. FY of Y = 3X + 2. Given y ∈R
FY(y) = P(Y ≤y) = P(3X + 2 ≤y) =
P

X ≤y −2
3

=

y−2
3
−∞
n(t)dt =
 y
−∞
1
3
√
2π
e−(z−2)2
18 dz ,
where we have used the change of variable t = z −2
3
. The density fY of Y is
obtained by the derivation of FY:
fY(y) = d
dy FY(y) = 1
3
1
√
2 π
e−(y−2)2
2·9
.
It follows that Y has normal distribution N(2, 9).
2. To estimate the probability P(Y ≥y), y > 0, we use that
1
√
2 π
e−x2
2
1
x −1
x3

≤P(X ≥x) ≤1
x
1
√
2 π
e−x2
2 ,
if X has standard normal distribution. Since P(Y ≥y) = P
	
X ≥y−2
3

for
y > 0, we obtain
1
√
2 π
e−(y−2)2
2·9

3
y −2 −
27
(y −2)3

≤P(Y > y) ≤
3
y −2
1
√
2 π
e−(y−2)2
2·9
.
3. The expectation of Z is given by:
P(Z) = P(X2) =
 +∞
−∞
x2
1
√
2 π
e−x2
2 dx = σ2(X) = 1,
where we have used the formula P(ψ(x)) =

ψ(x) fX(x) dx. To compute the
variance of Z, we use the formula
σ2(Z) = P(Z2) −P(Z)2 .
It remains to compute

146
11
One-Dimensional Absolutely Continuous Distributions
P(Z2) = P((X2)2) = P(X4)
=
 +∞
−∞
x4
1
√
2 π
e−x2
2 dx
=

−x3
1
√
2 π
e−x2
2
+∞
−∞
+ 3
 +∞
−∞
x2
1
√
2 π
e−x2
2 dx
= 3.
4. To compute the c.d.f. FZ of Z, we proceed as above, i.e.
FZ(z) = P(Z ≤z) = P(X2 ≤z) .
Since Z = X2 is a non negative random number, we can distinguish 2 cases:
(a) for z < 0 we have that FZ(z) = 0;
(b) if z ≥0
FZ(z) = P

X2 ≤z

= P

−√z ≤X ≤√z

= P

X ≤√z

−P

X ≤−√z

=
 √z
−∞
1
√
2 π
e−t2
2 dt −
 −√z
−∞
1
√
2 π
e−t2
2 dt
=
 √z
−√z
1
√
2 π
e−t2
2 dt .
Finally we get
FZ(z) =
⎧
⎪⎪⎨
⎪⎪⎩
0
z < 0 ,
 √z
−√z
1
√
2 π
e−t2
2 dt
z ≥0.
To compute the density fZ, we can take the derivative of the c.d.f.. For z ≥0
fZ(z) = d
dz
 √z
−∞
1
√
2 π
e−t2
2 dt −
 −√z
−∞
1
√
2 π
e−t2
2 dt

= 1
2z−1
2 n(√z) −

−1
2z−1
2

n(−√z)
= z−1
2 · n(√z)
= z−1
2
1
√
2 π
e−z
2 .

11
One-Dimensional Absolutely Continuous Distributions
147
We obtain
fZ(z) =
⎧
⎪⎪⎨
⎪⎪⎩
0
z < 0 ,
1
√
2 π
z−1
2 e−z
2
z ≥0.
Hence Z has Gamma distribution of parameters Γ ( 1
2, 1
2), i.e. χ2-distribution of
parameter 1.
□
Exercise 11.3 Let X be a random number with exponential distribution with para-
meter λ = 2.
1. Compute the moments of order n of X, i.e. P(Xn), n ∈N.
2. Consider the family of random numbers Zu = euX, u < λ. Given a ﬁxed u < λ,
compute the expectation ΨX(u) = P(euX) of Zu. The function ΨX(u) is called
moment generating function of X.
Solution 11.3
1. The moment of order n ∈N for X can be computed with the
formula
P(Ψ (x)) =

Ψ (x) fX(x) dx ,
for a given function Ψ : R −→R such that the integral above exists and is ﬁnite.
In this case Ψ (x) = xn. We then obtain
P(Xn) =
 +∞
0
xn λ e−λx dx
= λ
 +∞
0
xne−λx dx = λΓ (n + 1)
λn+1
= n!
λn .
In particular for n = 1 we have that P(X) = 1
λ.
2. We compute the expectations of Zu = euX, u ∈R.
P(Zu) = P(euX)
=
 +∞
0
λ eux e−λx dx
=
 +∞
0
λ e(u−λ)x dx .

148
11
One-Dimensional Absolutely Continuous Distributions
Note that here u is a given parameter. The integral is well-deﬁned since u < λ.
We obtain that
P(Zu) =
λ
u −λ

e(u−λ)x+∞
0
=
λ
u −λ .
□
Exercise 11.4 The random number X has uniform distribution on the interval
[−1, 1].
(a) Write the density of X.
Let Z = log |X|.
(b) Compute I (Z) e P(Z).
(c) Compute the c.d.f. and the density of Z.
(d) Calculate P(Z < −1
2|X > −1
2).
Solution 11.4 (a) The density of X is equal to
f (x) =
 1
2 per x ∈(−1, 1),
0 otherwise.
(b) The random number X has as set of possible values
I (X) = [−1, 1],
hence the set of possible values for Z = log |X| is given by
I (Z) = (−∞, 0] .
The random number Z is not deﬁned if X assumes the value 0 ∈I (X). To
compute the expectation we can proceed as follows:
P(Z) = P(Z|X > 0)P(X > 0) + P(Z|X < 0)P(X < 0)
= P(log X|X > 0) · 1
2 + P(log(−X)|X < 0) · 1
2 ,
where we have used the fact that
P(X > 0) = P(X < 0) = 1
2 .
Verify this by direct computation!

11
One-Dimensional Absolutely Continuous Distributions
149
We need only to calculate
P(log X|X > 0) =
 1
0
log xdx
(11.1)
= [x log x −x]1
0 = −1 ,
P(log(−X)|X < 0) =
 0
−1
log(−x)dx
(11.2)
=
 1
0
log ydy = −1,
hence
P(Z) = P(log X) = −1 .
(c) To compute the c.d.f. of Z, we need to exclude again the value 0. We have
FZ(z) = P(Z ≤z)
= P(Z ≤z, X > 0) + P(Z ≤z, X < 0) .
If z ≥0, then FZ(z) = 1. Let z < 0. We obtain:
FZ(z) = P(log X ≤z, X > 0) + P(log(−X) ≤z, X < 0) .
We now compute
P(log X ≤z, X > 0) = P(X ≤ez, X > 0)
(11.3)
= P(0 < X ≤ez)
=
 ez
0
1
2dx = 1
2ez
and
P(log(−X) ≤z, X < 0) = P(X ≥−ez, X < 0)
(11.4)
= P(−ez ≤X < 0)
=
 0
−ez
1
2dx = 1
2ez .
Hence
FZ(z) = ez
if z < 0 .

150
11
One-Dimensional Absolutely Continuous Distributions
The density of Z is given by
fZ(z) =
ez for z < 0,
0 otherwise .
(d) We evaluate P(Z < −1
2|X > −1
2) by using the formula of the conditional prob-
ability:
P

Z < −1
2
X > −1
2

= P

Z < −1
2, X > −1
2

P

X > −1
2

,
where
P

Z < −1
2, X > −1
2

= P

log |X| < −1
2, X > −1
2

=
P

log X < −1
2, X > 0

+ P

log(−X) < −1
2, −1
2 < X < 0

,
Here we have used that

X > −1
2

= (X > 0) +

−1
2 < X < 0

.
It follows that
P

log X < −1
2, X > 0

= P
	
0 < X < e−1
2

= e−1
2
2
and furthermore
P

log(−X) < −1
2, −1
2 < X < 0

= P

X > −e−1
2 , −1
2 < X < 0

= P

−1
2 < X < 0

=
 0
−1
2
1
2dx = 1
4 .
Finally
P

Z < −1
2|X > −1
2

= 1
2
 1
√e + 1
2

.
□

Chapter 12
Absolutely Continuous and Multivariate
Distributions
Exercise 12.1 Let X be the random number with density
f (x) =
 K x2 for −1 ≤x ≤1,
0
otherwise.
(a) Compute K.
(b) Compute the c.d.f., the expectation and the variance of X.
(c) Let Y be a random number which is stochastically independent and has expo-
nential distribution with parameter λ = 2. Write the joint density function and
the joint c.d.f. of (X, Y).
Solution 12.1 (a) The normalization constant K is such that
 1
−1
K x2dx = 1 .
Hence
K =
1
 1
−1 x2dx
= 3
2 .
(b) The c.d.f. of X is given by
F(x) = P(X ≤x) =
 x
−∞
f (t)dt .
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_12
151

152
12
Absolutely Continuous and Multivariate Distributions
Hence
F(x) =
⎧
⎪⎪⎨
⎪⎪⎩
0
for x ≤1,
 x
−1
3
2t2dt = 1
2(x3 + 1) for x ∈[−1, 1]
1
for x ≥1.
Furthermore the expectation of X is equal to
P(X) =

R
t f (t)dt =
 1
−1
3
2 x3dx = 0 .
The variance is given by
σ2(X) = P(X2) −P(X)2
= P(X2) =
 1
−1
x2 · 3
2 x2dx
= 3
2
 1
−1
x4dx = 3
5 .
(c) The density of Y is given by
g(y) =
⎧
⎨
⎩
2e−2y for y ≥0,
0
otherwise.
If X and Y are stochastically independent, then the joint density is given by the
product of the marginal densities:
f (x, y) = fX(x)gY(y) =
⎧
⎪⎨
⎪⎩
2e−2y 3
2 x2 = 3e−2yx2 for x ∈[−1, 1] and y ≥0,
0
otherwise.
Analogously the joint c.d.f. coincides with the product of the marginal distribu-
tion functions:
F(x, y) = FX(x)FY(y) =
⎧
⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩
(1 −e−2y)x3 + 1
2
for x ∈[−1, 1] and y ≥0,
1 −e−2y
for x > 1 and y ≥0,
0
otherwise.
□

12
Absolutely Continuous and Multivariate Distributions
153
Exercise 12.2 Let (X, Y) be a random vector with uniform distribution on the disk
of radius 1 and center at the origin of the axes.
1. Compute the joint density function f (x, y) of (X, Y).
2. What is the marginal density fX of X?
3. Let Z = X2 + Y 2, compute P(1
4 ≤Z ≤1).
4. Compute the c.d.f. and the density of Z.
Solution 12.2
1. Since (X, Y) have uniform distribution on the disk
D1 =
	
(x, y) : x2 + y2 ≤1

.
the joint density f (x, y) is constant on D1 and 0 outside. We obtain that
f (x, y) =
⎧
⎪⎨
⎪⎩
1
area D1 = 1
π for (x, y) ∈D1 ,
0
otherwise.
The density domain is shown in Fig.12.1.
The value of the density f on D1 can be determined by imposing that
1 =
 
R2 f (x, y) dx dy =
 
D1
c dx dy,
i.e.
c =
1
 
D1 dx dy =
1
area D1
= 1
π .
2. To compute the marginal density of X, we distinguish 4 cases as follows.
Fig. 12.1 Representation of
the area D1 on the plane
x
y
O
D1

154
12
Absolutely Continuous and Multivariate Distributions
Fig. 12.2 Case 0 ≤x ≤1
x
y
O
x
Fig. 12.3 Case −1 ≤x ≤0
x
y
O
x
• Case x > 1: fX(x) = 0.
• Case 1 ≥x ≥0: set the x coordinate; y varies along the line orthogonal to
the x-axis and passing through (x, 0). The extremes are the points where this
line intersects the graph of D1 as shown in Fig.12.2. We obtain:
fX(x) =
 √
1−x2
−
√
1−x2 f (x, t) dt =
 √
1−x2
−
√
1−x2
1
π dt = 2
√
1 −x2
π
.
• Case −1 ≤x < 0: by symmetry, we obtain as shown in Fig.12.3, that
fX(x) = 2
√
1 −x2
π
.
• Case x < −1: also here we have fX(x) = 0.

12
Absolutely Continuous and Multivariate Distributions
155
Summing up:
fX(x) =
⎧
⎨
⎩
2
√
1−x2
π
for x ∈[−1, 1]
0
otherwise.
3. Let Z = X2 + Y 2; to compute P
 1
4 ≤Z ≤1

is equivalent to calculate the prob-
ability that the random vector (X, Y) belongs to the region A of the plane between
the disk with center O and radius 1
2 and the disk with center O and radius 1, i.e.
P
1
4 ≤Z ≤1

= P
1
4 ≤X2 + Y 2 ≤1

.
Hence
P
1
4 ≤X2 + Y 2 ≤1

=
 
A
f (x, y) dx dy .
We can compute this integral by passing to the polar coordinates
x = ρ cos θ,
y = ρ sin θ .
To perform the change of variables in the integral, we need to take account of
the absolute value of the Jacobian determinant (Fig.12.4). In the case of polar
coordinates, this is equal to
|J| = ρ .
Fig. 12.4 Area of the region
	
(x, y)| 1
4 ≤x2 + y2 ≤1

x
y
O
A

156
12
Absolutely Continuous and Multivariate Distributions
It follows that
 
A(x,y)
f (x, y) dx dy =
 
A(ρ,θ)
f (ρ, θ) dρ dθ
=
 2π
0
dθ
 1
1
2
1
π dρ =
 1
1
2
2ρ dρ =

ρ21
1
2 = 3
4 .
4. To compute the c.d.f. FZ(z) of Z we use again spherical symmetry.
• z < 0: In this case FZ(z) = 0.
• 1 ≥z ≥0:
FZ(z) = P(Z ≤z)
= P(X2 + Y 2 ≤z)
=
 
Dz
f (x, y) dx dy,
where Dz = {(x, y) : x2 + y2 ≤z}. It follows that
FZ(z) =
 2π
0
 √z
0
1
π ρ dρ dθ =
 √z
0
2ρ dρ =

ρ2√z
0
= z .
• z > 1: In this case FZ(z) = P

X2 + Y 2 ≤z

= 1.
Summing up:
FZ(z) =
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
0
for z < 0,
z for 0 ≤z < 1,
1
for z > 1 .
The density function of Z is given by
fZ(z) =
⎧
⎨
⎩
1 for 0 ≤z ≤1,
0
otherwise.
The random number Z has therefore a uniform density in [0, 1].
□
Exercise 12.3 Let (X, Y) be a random vector with joint density
f (x, y) =
⎧
⎨
⎩
k xy (x, y) ∈T,
0
otherwise.

12
Absolutely Continuous and Multivariate Distributions
157
where T = {(x, y) ∈R2| 0 ≤y ≤−x + 2, 0 < x < 2}.
1. Compute the normalization constant k.
2. ComputetheprobabilityP(X > 1, Y < 1
2)andtheconditionalprobabilityP(X >
1|Y < 1
2).
3. Let Z = X + Y. Compute the probability that P(0 < Z < 1).
4. Compute the p.d.f. and the density of Z.
Solution 12.3
1. To compute the normalization constant k we impose that
 
R2 f (x, y) dx dy = 1 .
The integral of f can be computed by using Fubini-Tonelli Theorem:
 
R2 f (x, y) dx dy = k
 2
0
x
 −x+2
0
y dy dx
= k
 2
0
x
 y2
2
−x+2
0
dx = k
 2
0
x 1
2 (2 −x)2 dx
= k
2
 2
0
(4x −4x2 + x3) dx = k
2

2x2 −4
3x3 + 1
4x4
2
0
= 2
3 k .
It follows that
k = 3
2 .
2. The probability P(X > 1, Y < 1
2) is given by the integral of the joint density on
the region D given by the intersection
D = {(x, y) ∈R2 | x > 1, y < 1
2} ∩T ,
see Figs.12.5 and 12.6.
To ﬁnd the extremes, it is easier this time to ﬁx y and let x vary. The extremes
are given by the intersection of the border of D with the line passing in (0, y)
which is parallel to the x-axis, as we can see in Fig.12.7.

158
12
Absolutely Continuous and Multivariate Distributions
Fig. 12.5 Representation of
the area T on the plane
x
y
O
T
Fig. 12.6 Representation of
the area D on the plane
y
O
x
T
E = {(x,y)| x>1, y<1/2}
D
Fig. 12.7 Extremes of
variation of x
y
O
x
y

12
Absolutely Continuous and Multivariate Distributions
159
P(X > 1, Y < 1
2) =
 
D
f (x, y) dx dy
=

1
2
0

y
 −y+2
1
3
2 x dx

dy
=

1
2
0
y
3
4 x2
−y+2
1
dy
= 3
4

1
2
0
y (3 −4y + y2) dy
= 3
4
3
2 y2 −4
3 y3 + 1
4 y4
 1
2
0
= 43
256 .
The conditional probability P(X > 1|Y < 1
2) can be obtained as follows:
P(X > 1|Y < 1
2) = P(X > 1, Y < 1
2)
P(Y < 1
2)
.
We simply need to compute P(Y < 1
2). To this purpose we do not necessarily
need to know the marginal density of Y. This probability is given by the integral
of the joint probability f (x, y) on the domain D1 given by the intersection of
E1 = {(x, y) ∈R2| y < 1
2} and of T , i.e.
D1 = E1 ∩T ,
see Fig.12.8.
We can obtain the probability that Y is less than 1
2 by computing the joint prob-
ability that there are no restrictions on X and that Y is less than 1
2. We obtain:
P(Y < 1
2) =
 
D1
f (x, y) dx dy
=

1
2
0
3
2 y
 −y+2
0
x dx dy = 3
4

1
2
0
y (4 −4y + y2) dy
= 3
4

2y2 −4
3 y3 + 1
4 y4
 1
2
0
= 67
256 .
The conditional probability is then given by
P(X > 1|Y < 1
2) = P(X > 1, Y < 1
2)
P(Y < 1
2)
= 43
67 .

160
12
Absolutely Continuous and Multivariate Distributions
Fig. 12.8 Representation of
the area D1 on the plane
y
O
x
E1
D1
T
3. We now consider the random number Z = X + Y. To compute the probability
P(0 < Z < 1) we can use the joint density of (X, Y). We obtain
P(0 < Z < 1) = P(0 < X + Y < 1)
= P(−Y < X < 1 −Y)
= P(0 < X < 1 −Y).
Note that in this case X and Y are both positive, hence the condition X > −Y
reduces to X > 0. In Fig.12.9 we represent the region where the integral of the
joint density of X, Y must be calculated to obtain P(0 < Z < 1).
Fig. 12.9 Region where
0 < Z < 1
y
O
x
D
X+Y=1

12
Absolutely Continuous and Multivariate Distributions
161
P(0 < X < 1 −Y) =
 1
0
3
2 y
 1−y
0
x dx dy
= 3
4
 1
0
y (1 −y)2 dy
= 3
4
 1
0
(y −2y2 + y3) dy
= 3
4
1
2 y2 −2
3 y3 + 1
4 y4
1
0
= 1
16 .
4. The m.d.f. of Z is given by
FZ(z) = P(Z ≤z) = P(X + Y ≤z) = P(X ≤z −Y) .
If we consider the line x + y −z = 0, the distribution function of Z is given by
the integral of the joint density of X, Y on the region R delimited by this line on
T , as shown by Fig.12.10.
We obtain:
• for z < 0: P(Z < z) = 0;
• for z > 2: P(Z < z) = 1;
• for 0 ≤z ≤2:
Fig. 12.10 Region R
y
O
x
D
X+Y=Z

162
12
Absolutely Continuous and Multivariate Distributions
P(Z < z) =
 z
0
3
2 y
 z−y
0
x dx dy
= 3
4
 z
0
y (z −y)2 dy
= 3
4
 z
0
(z2y −2zy2 + y3) dy
= 3
4
1
2 z2y2 −2
3 zy3 + 1
4 y4
z
0
= 3
4
1
2 z4 −2
3 z4 + 1
4 z4

= z4
16 .
Summing up:
FZ(z) =
⎧
⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩
0
for z < 0,
z4
16 for 0 ≤z ≤2,
1
for z > 2 .
The density can be obtained by deriving the distribution function
fZ(z) =
⎧
⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩
0
for z < 0,
z3
4
for 0 ≤z ≤2,
0
for z > 2,
or by means of the formula
fZ(z) =

R
f (x, z −x)dx .
□
Exercise 12.4 Let X, Y be two random numbers with joint distribution function
f (x, y) =
 K x for y ≤x ≤y + 1,
0 ≤y ≤2,
0
otherwise.
(a) Compute K.
(b) Compute the m.d.f. and the expectation of X.

12
Absolutely Continuous and Multivariate Distributions
163
−1
2
2
1
Fig. 12.11 Region R of deﬁnition of the density
(c) Compute cov(X, Y).
(d) Compute P(0 < X −Y < 1).
Solution 12.4 (a) As in previous exercises, ﬁrst we draw the picture of the region
R of deﬁnition of the joint density, as shown by Fig.12.11.
Since the integral of a density must be equal 1, the constant of normalization is
given by
K =
1
 
R2 xdxdy ,
where
 
R2 xdxdy =
 2
0
dy
 y+1
y
xdx
=
 2
0
x2
2
y+1
y
dy
=
 2
0
(y + 1)2
2
−y2
2

dy
= 1
6

(y + 1)3 −y32
0 = 3 .

164
12
Absolutely Continuous and Multivariate Distributions
x
Fig. 12.12 Extremes of variation y
We conclude that K = 1
3.
(b) To compute the marginal density of X we apply the formula
fX(x) =

R
f (x, y)dy .
To ﬁnd the extremes of integration, we apply the general method as shown in
Fig.12.1.
We have to pay attention, since the expressions for the extremes of integration
vary if 0 < x < 1, 1 < x < 2, 2 < x < 3 (see Fig.12.12).
We have that if 0 < x < 1, then y varies between the lines
y = 0 e
y = x .
If 1 < x < 2, then y varies between the lines
y = x −1 e
y = x .
If 2 < x < 3, then y varies between
y = x −1 and
y = 2.

12
Absolutely Continuous and Multivariate Distributions
165
• For 0 < x < 1:
fX(x) =
 x
0
1
3xdy = 1
3x2 .
• For 1 < x < 2:
fX(x) =
 x
x−1
1
3xdy = 1
3x .
• For 2 < x < 3:
fX(x) =
 2
x−1
1
3xdy = 1
3x(3 −x) .
Summing up:
fX(x) =
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
1
3x2
for 0 < x < 1,
1
3x
for 1 < x < 2,
1
3x(3 −x) for 2 < x < 3,
0
otherwise.
We now verify that fX(x) is a probability density. We need to have that

R
fX(x)dx = 1,
Indeed
 1
0
1
3x2dx +
 2
1
1
3xdx +
 3
2
1
3x(3 −x)dx =
=
1
9x3
1
0
+
1
6x2
2
1
+
x2
2 −x3
9
3
2
= 1 .
The expectation of X is given by:

166
12
Absolutely Continuous and Multivariate Distributions
P(X) =

R
x f (x)dx
=
 1
0
x 1
3x2dx +
 2
1
x 1
3xdx +
 3
2
x 1
3x(3 −x)dx
=
 1
12 x4
1
0
+
1
9x3
2
1
+
x3
3 −x4
12
3
2
= 16
9 .
(c) The covariance cov(X, Y) is given by:
cov(X, Y) = P(XY) −P(X)P(Y),
where
P(XY) =
 
R2 xy f (x, y)dxdy =
=
 2
0
dy
 y+1
y
xy 1
3xdx =
 2
0
1
9 y

(y + 1)3 −y3
dy
=
 1
12 y4 + 1
9 y3 + 1
18 y2
2
0
= 22
9 .
To compute the expectation of Y, we do not need to compute the marginal
distribution of Y. In fact it holds that
P(Y) =

R
y fY(y)dy
=

R

y

R
f (x, y)dx

dy
=
 
R
y f (x, y)dxdy .
Hence
P(Y) =
 
R
y f (x, y)dxdy
=
 2
0
dy
 y+1
y
1
3xydx
=
 2
0
y 1
6

(y + 1)2 −y2
dy
=
 y3
6 + y2
12
2
0
= 5
3 .

12
Absolutely Continuous and Multivariate Distributions
167
R1
R
Fig. 12.13 The region R1
We obtain
cov(X, Y) = 22
9 −11
12 × 5
3 = 11
12 ,
i.e. X and Y are positively correlated.
(d) To compute P(0 < X −Y < 1), we note that
P(0 < X −Y < 1) = P(Y < X < Y + 1) = 1 ,
since the region
R1 = {(x, y)| y < x < y + 1}
contains entirely the domain of deﬁnition of the density, see Fig.12.13.
□
Exercise 12.5 Let X, Y be two stochastically independent random numbers with
the following marginal density:
f (x) =
 K(x3 −1) for 1 ≤x ≤2,
0
otherwise.
(a) Compute K.
(b) Compute the joint c.d.f., the expectation, the variance and the covariance of X
and Y.

168
12
Absolutely Continuous and Multivariate Distributions
(c) Let Z = X2. Compute the c.d.f., the expectation and the variance of Z.
(d) Compute the correlation coefﬁcients ρ(X, Z), ρ(X + Y, Z).
Solution 12.5 (a) Since K is the normalization constant, we obtain
K =
1
 2
0 (x3 −1)dx
=
1

x4
4 −x
2
1
= 4
11 .
(b) Since the random numbers X and Y are stochastically independent, their joint
c.d.f. is given by the product of the marginal c.d.f.’s:
F(x, y) = P(X ≤x, Y ≤y) = FX(x)FY(y) .
It is sufﬁcient to compute
F(x) = P(X ≤x) =
 x
−∞
f (t)dt .
We obtain
FX(x) =
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
0
x < 1 ,
 x
1
4
11(t3 −1)dt = 4
11
x4
4 −x + 3
4

x ∈[1, 2],
1
x ≥2.
Hence
F(x, y) =
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
0
for x < 1 or y < 1,
 4
11
2 (x4 −x + 3
4)(y4 −y + 3
4) for (x, y) ∈[1, 2] × [1, 2],
4
11(x4 −x + 3
4)
for x ∈[1, 2], y > 2,
4
11(y4 −y + 3
4)
for x > 2, y ∈[1, 2],
1
for x > 2, y > 2 .
Since X and Y are stochastically independent, we have immediately
cov(X, Y) = 0 .

12
Absolutely Continuous and Multivariate Distributions
169
Finally, we compute the expectation and the variance as follows:
1. Expectation
P(X) = P(Y) =

R
t f (t)dt
= 4
11
 2
1
t(t3 −1)dt = 4
11
t5
5 −t2
2
2
1
= 94
55 .
2. For the variance, we need ﬁrst to calculate
P(X2) = P(Y 2) = 4
11
 2
1
t2(t3 −1)dt
= 4
11
t6
6 −t3
3
2
1
= 98
33 .
Hence
σ2(X) = P(X2) −P(X)2 = 98
33 −
94
55
2
.
(c) We now compute the c.d.f. of Z = X2:
FZ(z) = P(Z ≤z) = P(X2 ≤z) .
For z < 1, we have immediately FZ(z) = 0. For 1 ≤z < 4, i.e. for 1 ≤√z < 2,
we have
FZ(z) = P(Z ≤z) = P(X2 ≤z) = P(−√z ≤X ≤√z) =
4
11
 √z
1
(t3 −1)dt = 4
11
t4
4 −t
√z
1
= 1
11(z2 −4√z + 3) .
For z ≥4, FZ(z) = 1. Summing up:
FZ(z) =
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
0
for z < 1,
1
11(z2 −4√z + 3) for z ∈[1, 4],
1
for z ≥4.
The expectation of Z coincides with the expectation of X2, i.e.
P(Z) = P(X2) = 98
33 .

170
12
Absolutely Continuous and Multivariate Distributions
To compute the variance, we note that
P(Z2) = P(X4) =
 2
1
4
11t4(t3 −1)dt =
4
11
t8
8 −t5
5
2
1
= 1027
110 .
Hence the variance is given by
σ2(Z) = P(Z2) −P(Z)2 = 1027
110 −
98
33
2
.
(d) We now compute the correlation coefﬁcient ρ(X, Z):
ρ(X, Z) = cov(X, Z)
σ(X)σ(Z) .
Sincewehavealreadydeterminedσ2(X), σ2(Z),wehaveimmediatelythemean
square deviations σ(X), σ(Z). It remains to compute
cov(X, Z) = P(X Z) −P(X)P(Z)
= P(X3) −P(X)P(Z)
= 4
11
 2
1
t3(t3 −1)dt −94
55 × 98
33
= 4
11
t7
7 −t4
4
2
1
−94
55 × 98
33 = 403
77 −94
55 × 98
33 .
Finally to obtain the correlation coefﬁcient ρ(X + Y, Z) we simply note that
ρ(X + Y, Z) = ρ(X, Z) + ρ(Y, Z) = ρ(X, Z) ,
since X and Y (hence Z and Y) are stochastically independent.
□
Exercise 12.6 The random numbers X and Y are stochastically independent. The
probability density fX(x) of X is given by:
fX(x) =
2x for 0 ≤1,
0
otherwise,
while the probability density of Y is given by
fY(y) =
e−y for y ≥0,
0
otherwise .

12
Absolutely Continuous and Multivariate Distributions
171
(a) Compute P(X), P(Y), σ2(X), σ2(Y).
(b) Determine the joint c.d.f. and the joint density of (X, Y).
(c) Let Z = X + Y. Compute P(Z), σ2(Z) the c.d.f. and the density of Z.
Solution 12.6 (a) We compute the ﬁrst moments of X and Y:
P(X) =

R
x fX(x)dx =
 1
0
2x2dx = 2
3 ;
σ2(X) = P(X2) −P(X)2 =
 1
0
2x3dx −4
9 = 1
18 .
The random number Y has exponential density of parameter λ = 1, hence we
can immediately write
P(Y) = 1
λ = 1,
σ2(Y) = 1
λ2 = 1 .
(b) The random numbers X and Y are stochastically independent, hence their joint
density is equal to
f (x, y) = fX(x) fY(y),
i.e.
f (x, y) =
2xe−y for 0 ≤x ≤1 and y ≥0,
0
otherwise.
We compute the joint c.d.f.
F(x, y) =
 x
−∞
 y
−∞
f (s, t)dsdt
after having identiﬁed the domain D of deﬁnition of the joint density as shown
in Fig.12.14.
We obtain that
F(x, y) =
⎧
⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎩
 x
0
 y
0 2se−tdsdt = x2(1 −e−y) for 0 ≤x ≤1 e y ≥0,
 1
0
 y
0 2se−tdsdt = 1 −e−y
for x > 1 e y ≥0,
0
otherwise.
(c) Consider now Z = X + Y. To compute P(Z) e σ2(Z) we use:
(i) the linearity property of the expectation:
P(Z) = P(X) + P(Y) = 2
3 + 1 = 5
3 ;

172
12
Absolutely Continuous and Multivariate Distributions
Fig. 12.14 The domain D of
deﬁnition of the joint density
0
1
(ii) the formula for the variance of the sum of 2 random numbers:
σ2(Z) = σ2(X + Y) = σ2(X) + σ2(Y) + 2cov(X, Y)
= σ2(X) + σ2(Y) = 19
18 .
To compute the distribution function of Z = X + Y, we use the fact that
FZ(z) = P(Z ≤z) = P(X + Y ≤z)
= P(Y ≤z −X)
=
 
Dz
f (s, t)dsdt ,
where for all ﬁxed z, Dz is the region of the plane determined by the intersection
of the domain D of deﬁnition of the density and of the semi-plane
Sz = {(x, y)|y ≤z −x}.
Figures12.15 and 12.16 show the region intersected by Sz on D when z varies.
We obtain that:
(i) for z < 0, Fz(z) = 0;
(ii) for 0 < z < 1,
FZ(z) =
 z
0
2x
 z−x
0
e−ydydx
=
 z
0
2x

1 −e−(z−x)
dx = z2 + 2(1 −z) −2e−z ;

12
Absolutely Continuous and Multivariate Distributions
173
1
0
Fig. 12.15 Case 0 < z < 1
Fig. 12.16 Case z > 1
0
1

174
12
Absolutely Continuous and Multivariate Distributions
(iii) for z > 1
FZ(z) =
 1
0
 z−x
0
2xe−ydydx =
 1
0
2x

1 −e−(z−x)
dx = 1 −2e−z .
We obtain the density of Z by deriving the c.d.f. of Z, i.e.:
fZ(z) =
⎧
⎨
⎩
2z −2 + 2e−z for 0 ≤z < 1,
2e−z
for z > 1,
0
otherwise.
□
Exercise 12.7 The random numbers X and Y have bidimensional Gaussian density
p(x, y) =
1
2π e−1
2 (x2+y2) .
Let U = 2X + 3Y and V = X −Y. Compute:
1. The covariance matrix of U and V .
2. The joint density of U and V .
Solution 12.7
1. We compute the covariance matrix of U and V :
C =
⎛
⎝
σ2(U)
cov(U, V )
cov(U, V )
σ2(V )
⎞
⎠.
In order to compute C we use the formula of the variance of the sum of 2 random
numbers and the bilinearity of the covariance:
• σ2(U)
σ2(U) = σ2(2X + 3Y)
= 4 σ2(X) + 9 σ2(Y) + 2 × 6 cov(X, Y)
= 13 ;
• σ2(V )
σ2(V ) = σ2(X −Y)
= σ2(X) + σ2(Y) −2 cov(X, Y)
= 2 ;

12
Absolutely Continuous and Multivariate Distributions
175
• cov(U, V )
cov(U, V ) = cov(2X + 3Y, X −Y)
= 2 σ2(X) −2 cov(X, Y) + 3 cov(X, Y) −3 σ2(Y)
= −1 .
The covariance matrix is
C =
⎛
⎝
13
−1
−1
2
⎞
⎠.
2. To compute the joint density of (U, V ), we ﬁrst compute the joint c.d.f. of (U, V )
given by
F(u, v) = P(U ≤u, V ≤v) = P(2X + 3Y ≤u, X −Y ≤v) .
This probability is given by the integral of the joint density on the domain Du,v
of R2 where
Du,v = {(x, y) ∈R2 | 2x + 3y ≤u, x −y ≤v} .
We obtain
F(u, v) =
 
Du,v
f (x, y) dx dy.
To solve the integral, we perform the change of variables
z = 2x + 3y,
t = x −y ,
to transform the domain Du,v into the region
ˆDu,v = {(x, y) ∈R2 | z ≤u, t ≤v} .
with sides which are parallel to the axes. If we now compute x, y as function of
z and t, we obtain
x = 1
5 (z + 3t),
y = 1
5 (z −2t) .
It follows that the Jacobian matrix is equal to
JΨ =
⎛
⎝
∂Ψ1
∂z
∂Ψ1
∂t
∂Ψ2
∂z
∂Ψ2
∂t
⎞
⎠=
⎛
⎝
1
5
3
5
1
5 −2
5
⎞
⎠,

176
12
Absolutely Continuous and Multivariate Distributions
where (x, y) = Ψ (z, t) = (Ψ1(z, t), Ψ2(z, t)) =
z + 3t
5
, z −2t
5

, with
determinant
|det JΨ | = 1
5 .
We obtain:
F(u, v) =
 
Du,v
f (x, y) dx dy
=
 
ˆDu,v
f (ψ(z, t)) |det JΨ | dz dt
=
 u
−∞
 v
−∞
1
2π e
−1
2

( z+3t
5 )
2+( z−2t
5 )
2 1
5 dz dt
=
 u
−∞
 v
−∞
1
10π e−1
2 · 1
25 (2z2+13t2+2zt) dz dt .
The joint density of (U, V ) is then
1
10π e−1
50 (2z2+13t2+2zt), z, t ∈R2 .
Note that (U, V ) have again joint Gaussian distribution with covariance matrix
equal to C.
To verify these results, compute the inverse matrix of A, where
A =
⎛
⎝
2
25
1
25
1
25
13
25
⎞
⎠.
□
Exercise 12.8 A random vector (X, Y, Z) has joint density given by
f (x, y, z) = k e−1
2 (2x2−2xy+y2+z2+2x−6y) .
1. Compute k.
2. Compute the expectations P(X), P(Y) and P(Z).
3. Compute the density of the random vector (X, Z).
4. Compute the correlation coefﬁcient between X and Z and between X and Y.
5. Let W = X + Z; compute the probability density of W.

12
Absolutely Continuous and Multivariate Distributions
177
Solution 12.8
1. If we write the density in the standard form
f (x, y, z) = k e−1
2 Av·v+b·v
where A is the symmetric matrix
A =
⎛
⎜⎜⎜⎜⎝
2
−1
0
−1
1
0
0
0
1
⎞
⎟⎟⎟⎟⎠
,
b is the vector in R3
b =
⎛
⎝
−1
3
0
⎞
⎠,
and v is given by
v =
⎛
⎝
x
y
z
⎞
⎠.
We can compute the normalization constant k as follows:
k =

det A
(2π)3 e−1
2 A−1b·b .
It is now sufﬁcient to calculate the determinant and the inverse matrix of A. We
obtain:
det A = 1,
A−1 =
⎛
⎜⎜⎜⎜⎝
1
1
0
1
2
0
0
0
1
⎞
⎟⎟⎟⎟⎠
from which
A−1b =
⎛
⎝
2
5
0
⎞
⎠

178
12
Absolutely Continuous and Multivariate Distributions
and
k = e−1
2 A−1b·b

det A
(2π)3 = e−13
2

1
(2π)3 .
2. The expectations of X, Y, Z are given respectively by
P(X) =

A−1b

1 = 2 ,
P(Y) =

A−1b

2 = 5 ,
P(Z) =

A−1b

3 = 0 .
3. The random vector (X, Z) has bidimensional Gaussian density of covariance
matrix D given by
D =
⎛
⎝

A−1
11

A−1
13

A−1
31

A−1
33
⎞
⎠=
⎛
⎝
1
0
0
1
⎞
⎠
and vector d of expectations
d =
 2
0

.
To prove this, we derive the joint density fX,Z(x, z) from f (x, y, z) as follows:
fX,Z(x, z) =

R
f (x, y, z) dy
=

R
k e−1
2 (2x2−2xy+y2+z2+2x−6y) dy
= e−1
2 (2x2+z2+2x)

R
k e−1
2 (y2−2xy)+3y dy
= e−1
2 (2x2+z2)−x

R
k e−1
2 y2+(3+x)y dy .
Here we can consider
I =

R
k e−1
2 y2+(3+x)y dy
as the integral of a one-dimensional Gaussian distribution with coefﬁcients
depending on the parameter x. In the same notation as above, we obtain
A = 1
and
b = 3 + x ,

12
Absolutely Continuous and Multivariate Distributions
179
from which we obtain

R
k e−1
2 y2+(3+x)y dy =

2π
det Ae
1
2 A−1b·b
=
√
2πe
1
2 (3+x)2 .
We can obtain the same result also by completing the square
−1
2 y2 + (3 + x)y
in the integral I. It follows that
fX,Z(x, z) = k e−1
2 (2x2+z2)−x ·
√
2π e
1
2 (3+x)2
= e−13
2 + 9
2
2π
e−1
2 (x2+z2)+2x
= e−2
2π e−1
2 (x2+z2)+2x .
4. The correlation coefﬁcient between X and Z can be obtained by the formula
ρ(X, Z) = cov(X, Z)
σ(X) σ(Z) .
From the covariance matrix we have that
cov(X, Z) = 0 ,
hence
ρ(X, Y) =
1
√
2
√
1
=
√
2
2 .
5. The probability density of W can be computed via the formula
fW(w) =

R
fX,Z(x, w −x) dx .

180
12
Absolutely Continuous and Multivariate Distributions
Hence with the same method used above:
fW(w) =

R
e−2
2π e−1
2 (x2+(w−x)2)+2x dx
= e−2
2π e−1
2 w2 
R
e−1
2 (2x2)+(2+w)x dx
= e−2
2π e−1
2 w2 √πe
1
2 × 1
2 (2+w)2
= e−2+1
2√π e−1
4 w2+w
=
1
2√π e−1
4 (w−2)2 .
The random number W has normal density with expectation
P(W) = P(X) + P(Z) = 2
and variance
σ2(W) = σ2(X) + σ2(Z) + 2cov(X, Z) = 2 .
□

Chapter 13
Markov Chains
Exercise 13.1 A Markov chain (Xn)n ∈N with states S = {1, 2, 3, 4} has the
following transition matrix
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎝
1
4
3
4 0 0
0 0
2
3
1
3
1
4 0
3
4 0
0
1
3 0
2
3
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎠
and initial distribution
μ(1) = μ(2) = μ(3) = μ(4) = 1
4.
(a) Determine the equivalence classes of the states and their periods.
(b) Compute p(2)
2,1, p(2)
1,4, p(2)
1,1.
(c) Check the existence of the following limits and compute them, if they exist:
lim
n→∞p(n)
1,3
and
lim
n→∞P(Xn = 2).
Solution 13.1 (a) To determine equivalence classes of the states, we can draw a
graph of the transition probabilities by using the matrix P. We ﬁrst represent
the states (see Fig.13.1) and then connect with an arrow two states such that
the transition probability from one to the other is strictly positive. For example,
since
[P]1,2 = 3
4,
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_13
181

182
13
Markov Chains
Fig. 13.1 The states
4
1
2
3
Fig. 13.2 The chain has
positive probability of going
from 1 to 2
1
2
Fig. 13.3 The chain have
positive probability of
remaining in the state 1
1
Fig. 13.4 Graph of the
relations among the states
4
1
2
3
the chain has positive probability to go from the state 1 to the state 2 in one step.
We represent this on the graph by connecting 1 and 2 with an arrow going from
1 to 2, see Fig.13.2.
Analogously, [P]1,1 = 1
4 means that the chain has positive probability of remain-
ing in the state 1. This can be represented as illustrated in Fig.13.3.
By using this procedure we can construct the graph of Fig.13.4.
From the graph we deduce that all elements can communicate with each other,
i.e. there exists paths that connect each state to all the other ones with positive
probability. We conclude that there exists only one equivalence class [1].
Furthermore we can deduce from the graph that the period of the chain is 1, since
there exists a path of length 1 from state 1 to itself, i.e.
1 ∈{n | p(n)
1,1 > 0}.
(b) To compute p(2)
2,1, i.e. the probability of going in 2 steps from the state 2 to the
state 1, we write
p(2)
2,1 =

i∈S
p(1)
2,i p(1)
i,1 .
This formula shows how the probability of going in 2 steps from the state 2 to
the state 1 can be computed as the sum of the probabilities of all possible paths
from 2 to 1.
From the graph relative to the matrix P we obtain
p(2)
2,1 = p(1)
2,3 p(1)
3,1 = 2
3 · 1
4 = 1
6.

13
Markov Chains
183
Note that we can compute p(2)
2,1 by taking the product of the matrix column with
the matrix row
p(2)
2,1 = P2 · P1
where P2 denotes the second row and P1 the ﬁrst column of the matrix P.
Analogously we compute p(2)
1,4 and p(2)
1,1.
(c) Since the chain is irreducible and aperiodic, the ergodic theorem guarantees the
existence of the limit
lim
n→∞p(n)
1,3 = π3,
where π3 can be obtained by the solution of the linear system
π =
tπ P
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎩
π1 =  πi pi,1
π2 =  πi pi,2
π3 =  πi pi,3
π1 + π2 + π3 + π4 = 1.
In this case
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
π1 = 1
4π1 + 1
4π3
π2 = 3
4π1 + 1
3π4
π3 = 2
3π2 + 3
4π3
4

i=1
πi = 1.
By using standard methods for the solution of linear systems of equations, we
obtain:
π3 = 12
25.
Hence
lim
n→∞p(n)
1,3 = 12
25.

184
13
Markov Chains
To compute lim
n→∞P(Xn = 2), we note that
P(Xn = 2) =
4

i=1
P(Xn = 2|X0 = i)P(X0 = i) = 1
4
4

i=1
p(n)
i,2 .
Since for all i
lim
n→∞p(n)
i,2 = π2,
we have
lim
n→∞P(Xn = 2) = lim
n→∞
1
4
4

i=1
p(n)
i,2 = 1
4 · 4π2 = π2,
where π2 = 9
50.
⊓⊔
Exercise 13.2 A Markov chain Xn, n = 0, 1, 2 . . . with states
S = {1, 2, 3, 4, 5, 6}
has the following transition matrix
⎛
⎜⎜⎜⎜⎜⎜⎝
0
1
3 0
1
3 0
1
3
1
2 0
1
2 0 0 0
0
1
3 0
2
3 0 0
0 0
2
3 0
1
3 0
0 0 0
1
2 0
1
2
1
3 0
1
3 0
1
3 0
⎞
⎟⎟⎟⎟⎟⎟⎠
and initial distribution
μ(1) = 1
3, μ(2) = 2
3, μ(3) = μ(4) = μ(5) = μ(6) = 0.
1. Determine the equivalence classes of the states and their periods.
2. Check the existence of the following limits and compute them, if they exist:
lim
n→∞p(2n)
1,5 , lim
n→∞p(n)
3,5, lim
n→∞p(2n)
2,5 and lim
n→∞P(Xn = 5).
3. Compute P(X2 < 3).
Solution 13.2
1. As in the previous exercise, we draw the graph of the states as
in Fig.13.5, in order to determine the equivalence classes of the states and their
periods. We connect the states with an arrow in the case there exists a positive

13
Markov Chains
185
Fig. 13.5 Graph of the states
1
2
4
5
6
3
Fig. 13.6 Graph of the
probabilities of transition
1
2
4
5
6
3
probability to pass from the state, where the arrow starts, to the state where the
arrow ends.
By using the transition matrix P we obtain the graph shown in Fig.13.6, where
we can see that there exists only one equivalence class. We note that the number
of steps needed to come back to the state from where we started is always even.
Furthermore p(2)
1,1 > 0, hence it follows that the period of the equivalence class is
2. Namely
2 = MCD A+
s
where A+
s
= {n| p(n)
s,s > 0}.
2. Tostudythelimits,weconsidertheequivalenceclassesofthematrix P2;weobtain
two equivalence classes, each of period 1. To derive the equivalence classes, it
is not necessary to compute the whole matrix P2; for example, the equivalence
class of 1 will be given by all states that communicate with 1 with an even number
of steps. We obtain
[1] = {1, 3, 5},
[2] = {2, 4, 6}.
Since 2 and 5 do not communicate with an even number of steps, we immediately
have that
p(2n)
2,5
= 0
for all n, hence
lim
n→∞p(2n)
2,5
= 0.

186
13
Markov Chains
The state 5 belongs to the class [1] calculated with respect to P2. Hence we can
apply the ergodic theorem to that class, since it has period 1 with respect to P2.
The submatrix of P2 relative to [1] is given by:
⎛
⎜⎜⎜⎜⎝
5
18
9
18
2
9
1
6
11
18
2
9
1
6
1
2
1
3
⎞
⎟⎟⎟⎟⎠
.
By the ergodic theorem we have that
lim
n→∞p(2n)
1,5
= π5
where π5 is the solution of the system
⎧
⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎩
π1 =
5
18π1 + 1
6π3 + 1
6π5
π3 =
9
18π1 + 11
18π3 + 1
2π5
π1 + π3 + π5 = 1.
We obtain
π1 =
3
16
π3 =
9
16
π5 = 1
4.
Hence
lim
n→∞P(2n)
1,5
= 1
4.
To obtain the asymptotic behavior of p(n)
3,5 for n going to inﬁnity, we note that
(a) on the even steps, i.e. for n = 2k, we have
p(2k)
3,5 −−−→
k→∞π5;
(b) on the odd steps, i.e. for n = 2k + 1, we have
p(2k+1)
3,5
= 0
since the probability of going from the state 3 to the state 5 in an odd number of
steps is zero. Since the limit on two subsequences is different, we can conclude
that
lim
n→∞p(n)
3,5

13
Markov Chains
187
does not exist. To compute
lim
n→∞P(Xn = 5),
we use the formula of total probability:
P(Xn = 5) =
6

i=1
P(Xn = 5|X0 = i) P(X0 = i)
6

i=1
p(n)
i,5 μi = 1
3 p(n)
1,5 + 2
3 p(n)
2,5.
We need to distinguish the following 2 cases:
(a) what happens on the even steps, i.e. for n = 2k. We have:
1
3 p(2k)
1,5 + 2
3 p(2k)
2,5
= 1
3 p(2k)
1,5
−−−→
k→∞
π5
3 ;
(b) what happens on the odd steps, i.e. for n = 2k + 1. We have:
1
3 p(2k+1)
1,5
+ 2
3 p(2k+1)
2,5
= 2
3 p(2k+1)
2,5
= 2
3
6

i=1
p(1)
2,i p(2k)
i,5 ,
that tends to 2
3 π5
6

i=1
p(1)
2,i = 2
3π5 for k →∞, since we have that p(1)
2,i ̸= 0
for the i such that we have lim
k→∞p(2k)
i,5 = π5.
Since we obtain different limits, we can conclude that the limit
lim
n→∞P(Xn = 5)
does not exist.
3. To compute P(X2 < 3) we note that
P(X2 < 3) =
2

i=1
P(X2 = i),
since the event (X2 < 3) = (X2 = 1) + (X2 = 2). It is then sufﬁcient to compute

188
13
Markov Chains
P(X2 = 1) =
6

i=1
P(X2 = 1|X0 = i) P(X0 = i)
=
6

i=1
p(2)
i,1 μi
= 1
3 p(2)
1,1 + 2
3 p(2)
2,1 = 5
54
and
P(X2 = 2) =
6

i=1
P(X2 = 2|X0 = i) P(X0 = i)
=
6

i=1
p(2)
i,2 μi
= 1
3 p(2)
1,2 + 2
3 p(2)
2,2 = 2
9.
Finally, P(X2 < 3) = 17
54.
⊓⊔
Exercise 13.3 A Markov chain Xn, n = 0, 1, 2 . . . with states
S = {1, 2, 3, 4}
has the following transition matrix
P =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎝
0
1
2
1
2 0
2
3 0 0
1
3
1
6 0 0
5
6
0
3
4
1
4 0
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎠
and initial distribution
μ(1) = 1
3, μ(2) = 1
3, μ(3) = 1
3, μ(4) = 0.
1. Determine the equivalence classes of the states and their periods.
2. Compute P(X5 = 2|X2 = 3), p(2)
1,4 and P(X2).
3. Check the existence of the following limits and compute them, if they exist:
lim
n→∞p(2n)
1,3 , lim
n→∞p(2n)
1,4 , lim
n→∞p(n)
2,3 and lim
n→∞P(Xn = 2).

13
Markov Chains
189
Fig. 13.7 Graph of the states
1
2
4
3
Solution 13.3
1. To ﬁnd the equivalence classes we draw the graph of the states
as shown in Fig.13.7.
Since we can reach all other states by starting from the state 1 and the state 1
can be reached from all other states, there exists only one equivalence class.
Furthermore by starting from 1, we return to it always with only an even number
of steps and p(2)
1,1 > 0. We conclude that the period of the class is equal to 2.
2. To compute the conditional probability P(X5 = 2|X2 = 3) we use the fact that
the chain is homogeneous. It holds that
P(X5 = 2|X2 = 3) = p(3)
3,2 = [P3]3,2 = 0.
To compute this probability, we need to calculate the element on the row 3 and
column 2 of the matrix P3, We can obtain this element by multiplicating the third
row of P2 with the second column of P.
Anyways without any computation we can immediately state that the probability
of going from the state 3 to the state 2 in a odd number of steps is 0!
Furthermore
p(2)
1,4 = [P2]1,4 =
7
12.
We now compute the expectation of the state of the chain at time t = 2 by using
the formulas of the expectation of a random number with discrete distribution
and of the total probabilities:
P(X2) =
4

i=1
i P(X2 = i)
=
4

i=1
i
4

j=1
P(X2 = i|X0 = j) P(X0 = j)
=
4

i=1
i
3 (P(X2 = i|X0 = 1) + P(X2 = i|X0 = 2) + P(X2 = i|X0 = 3))
=
4

i=1
i
3

[P2]1,i + [P2]2,i + [P2]3,i

.

190
13
Markov Chains
The matrix of P2 is given by:
P2 =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎝
5
12
0
0
7
12
0
7
12
5
12
0
0
17
24
7
24
0
13
24
0
0
11
24
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎠
.
Hence the expectation of X2 is then:
P(X2) = 1
3
 5
12 + 2
 7
12 + 17
24

+ 3
 5
12 + 7
24

= 41
24.
3. We now compute the limits. The Markov chain observed on the even steps can
be considered as a Markov chain with transition matrix equal to P2. We can
immediately see that the state 3 cannot be reached from the state 1 with an even
number of steps. In fact, the equivalence classes relative to P2 are given by
[1] = {1, 4},
[2] = {2, 3}.
It follows that
lim
n→∞p(2n)
1,3
= 0.
The state 4 belongs to the equivalence class [1] relative to P2. This class has
period 1. Hence we can apply the ergodic theorem to this irreducible aperiodic
subchain to compute
lim
n→∞p(2n)
1,4 .
If we put π4 =
lim
n→∞p(2n)
1,4 and π1 =
lim
n→∞p(2n)
1,1 , by the ergodic theorem we
obtain
⎧
⎨
⎩
π1 + π4 = 1
5
12 π1 + 13
24 π4 = π1.

13
Markov Chains
191
The solution of the system is
π1 = 13
27,
π4 = 14
27.
It follows that
lim
n→∞p(2n)
1,4
= 14
27.
To compute lim
n→∞p(n)
2,3 we observe the behavior of the chain on the even steps and
on the odd ones.
(a) First we note that 2 ∈[3] relative to P2.
By the ergodic theorem we have that on the even steps (i.e. if n = 2k)
p(2k)
2,3
−−−→
k→∞π3
where π3 is the solution of the system
⎧
⎨
⎩
π2 + π3 = 1
5
12 π2 + 7
24 π3 = π3.
(b) There exists no path with an odd number of steps from the state 2 to the state
3, hence
p2,3(2k + 1) = 0
∀k.
We can obtain the same result by computing
p(2k+1)
2,3
=

j
p(2k)
2, j p j,3(1)
= p(2k)
2,1 p1,3(1) + p(2k)
2,4 p4,3(1) = 0.
Summing up
p(2k)
2,3 −−−→
k→∞π3 > 0
p(2k+1)
2,3
−−−→
k→∞0.
Hence the limit lim
n→∞p(n)
2,3 does not exist.

192
13
Markov Chains
Finally, to compute lim
n→∞P(Xn = 2) we proceed as in the previous case. First we
use the formula of the total probability to compute P(Xn = 2):
P(Xn = 2) =
4

i=1
P(Xn = 2|X0 = i) P(X0 = i)
= 1
3 (P(Xn = 2|X0 = 1) + P(Xn = 2|X0 = 2) + P(Xn = 2|X0 = 3))
= 1
3

p(n)
1,2 + p(n)
2,2 + p(n)
3,2

.
By using the results above, we obtain
(a) if n = 2k
1
3

p(2k)
1,2 + p(2k)
2,2 + p(2k)
3,2

= 1
3

p(2k)
2,2 + p(2k)
3,2

which tends to 2
3π2 for k →∞;
(b) if n = 2k + 1
1
3

p(2k+1)
1,2
+ p(2k+1)
2,2
+ p(2k+1)
3,2

= 1
3 p(2k+1)
1,2
= 1
3
4

i=1
p(1)
1,i p(2k)
i,2
= 1
3

p(1)
1,2 p(2k)
2,2 + p(1)
1,3 p(2k)
3,2

which tends to 1
3 π2

p(1)
1,2 + p(1)
1,3

= 1
3 π2 for k →∞.
Summing up, if we put pn = P(Xn = 2), we have that
p2n −−−→
n→∞
2
3π2,
p2n+1 −−−→
n→∞
1
3 π2,
i.e. the limit lim
n→∞P(Xn = 2) does not exist.
⊓⊔
Exercise 13.4 A Markov chain (Xn)n ∈N with states S = {1, 2, 3, 4, 5} has the fol-
lowing transition matrix

13
Markov Chains
193
Fig. 13.8 Graph of states
5
1
2
3
4
P =
⎛
⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝
0 1
2
1
2 0 0
1
2 0 1
2 0 0
0 2
3 0 1
3 0
0 0 2
3 0 1
3
2
3 0 0 1
3 0
⎞
⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠
and initial distribution
μ(1) = 0, μ(2) = 2
3, μ(3) = 1
3, μ(4) = μ(5) = 0.
(a) Determine the equivalence classes of the states and their periods.
(b) Check the existence of the following limits and, if they exist, compute them:
lim
n→∞p(n)
1,5, lim
n→∞p(n)
3,5, lim
n→∞(p(n)
2,3 + p(n)
3,5), lim
n→∞P(Xn = 5).
(c) Compute P(X1 ≤2) and P(X2 = 5).
Solution 13.4 (a) To determine the equivalence classes of the states and their peri-
ods we draw the graph of the states, see Fig.13.8.
We ﬁrst note that all the states comunicate among each other. Consider the set
A+
1 = {n| p(n)
11 > 0}
i.e. the set of the lengths of the paths that starts and ends in 1. We note that there
exists a path of length 2 (for example, from 1 to 2 and from 2 to 1) and of length
3 (from 1 to 3, from 3 to 2, from 2 to 1). We have
2, 3 ∈A+
1 .
The period d of the equivalence class [1] is given by
d = MC D(A+
1 ),

194
13
Markov Chains
hence d must be equal to 1 since it must divide 2 and 3. We conclude that there
exists only one equivalence class of period 1.
(b) By the ergodic theorem it follows that all the limits exist since the chain has a
unique equivalence class of period 1. First we note that
lim
n→∞p(n)
1,5 = lim
n→∞p(n)
3,5 = π5
since the starting state (1 to 3) does not count. Furthermore
lim
n→∞(p(n)
2,3 + p(n)
3,5) = lim
n→∞p(n)
2,3 + lim
n→∞p(n)
3,5
= π3 + π5
and ﬁnally
lim
n→∞P(Xn = 5) = lim
n→∞
5

i=1
P(Xn = 5|X0 = i)P(X0 = i)
= lim
n→∞
5

i=1
μ(i)p(n)
i,5
= π5
5

i=1
μ(i) = π5 · 1 = π5,
since lim
n→∞p(n)
i,5 = π5, ∀i = 1, . . . , 5 and 5
i=1 μ(i) = 1. To obtain πi, it is suf-
ﬁcient to solve the system
π = πt P
5
i=1 πi = 1
i.e.
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
π1 = 1
2π2 + 2
3π5
π2 = 1
2π1 + 2
3π3
π4 = 1
3π3 + 1
3π5
π5 = 1
3π4
5
i=1 πi = 1.
In this system we have already taken out a redundant equation. We obtain
π3 =
7
540
e π5 = 14
135.

13
Markov Chains
195
Hence, summing up
lim
n→∞p(n)
1,5 = lim
n→∞p(n)
3,5 = lim
n→∞P(Xn = 5) = π5 = 14
135,
lim
n→∞

p(n)
2,3 + p(n)
3,5

= π3 + π5 =
7
540 + 14
135 = 7
60.
(c) To compute the probabilities, we note that
P(X1 ≤2) = P(X1 = 1) + P(X1 = 2)
=
5

i=1
P(X1 = 1|X0 = i)μ(i) +
5

i=1
P(X1 = 2|X0 = i)μ(i)
= 2
3 p2,1 + 1
3 p3,1 + 2
3 p2,2 + 1
3 p3,2
= 1
3 + 2
9 = 5
9.
The second probability can be computed by using the formula of the total prob-
ability:
P(X2 = 5) =
5

i=1
P(X2 = 5|X0 = i)μ(i)
= 2
3 p(2)
2,5 + 1
3 p(2)
3,5
= 2
3[P2]2,5 + 1
3[P2]3,5
= 1
3 · 1
9 = 1
27.
⊓⊔

Chapter 14
Statistics
Exercise 14.1 The events E1, E2, . . . are stochastically independents subordinately
to the random parameter Θ with P(Ei|Θ = θ) = θ. The a priori density of Θ is
given by
π0 =
⎧
⎨
⎩
3 θ2 0 ≤θ ≤1,
0
otherwise.
We observe the values of the ﬁrst 4 events:
E1 = 0, E2 = 1, E3 = 1, E4 = 1.
1. Compute the a posteriori density π4(Θ|E1 = 0, E2 = 1, E3 = 1, E4 = 1) of Θ.
2. Compute the a priori probability that Θ belongs to the interval
1
2, 1

.
3. Compute the a posteriori probability that Θ belongs to the interval
1
2, 1

.
4. Compute arg max π4(Θ|E1 = 0, E2 = 1, E3 = 1, E4 = 1).1
5. Compute the a posteriori expectation of E = E5 ∧E6.
Solution 14.1
1. The a posteriori density can be computed by using the formula
π4(Θ|E1 = 0, E2 = 1, E3 = 1, E4 = 1)
= kP(E1 = 0, E2 = 1, E3 = 1, E4 = 1|Θ = θ)π0(θ).
1Here and in the sequel, for a given function f we denote by arg max( f ) the points where f achieves
its maximum.
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8_14
197

198
14
Statistics
Since the events Ei are stochastically independent subordinately to the random
parameter Θ, the probability
P(E1 = 0, E2 = 1, E3 = 1, E4 = 1|Θ = θ)
can be factorized in
P(E1 = 0, E2 = 1, E3 = 1, E4 = 1|Θ = θ)
= P(E1 = 0|Θ = θ) · P(E2 = 1|Θ = θ)P(E3 = 1|Θ = θ) · P(E4 = 1|Θ = θ)
= (1 −θ) · θ · θ · θ.
Hence the a posteriori density is given by
π4(Θ|E1 = 0, E2 = 1, E3 = 1, E4 = 1) = kθ5(1 −θ),
where k is a normalization constant. Since the a posteriori density π4 corresponds
to a beta distribution B(6, 2), we have
k =
Γ (6 + 2)
Γ (6)Γ (2) = 7!
5! = 42.
2. The a priori probability that Θ belongs to the interval
1
2, 1

is given by:
P(1
2 ≤Θ ≤1) =
 1
1
2
π0(θ) dθ
=
 1
1
2
3 θ2 dθ =

θ3	1
1
2 = 7
8.
3. The a posteriori probability that Θ belongs to the interval
1
2, 1

is given by:
P(1
2 ≤Θ ≤1|E1 = 0, E2 = E3 = E4 = 1)
=
 1
1
2
π4(θ|E1 = 0, E2 = E3 = E4 = 1) dθ
= 42
 1
1
2
(θ5 −θ6) dθ = 42
θ6
6 −θ7
7
1
1
2
= 15
16.
4. By calculating the derivative
d
dθπ4(θ|E1 = 0, E2 = 1, E3 = 1, E4 = 1) = 42 θ4(5 −6θ),

14
Statistics
199
we have that it is equal 0 in ¯θ = 5
6. Since
d2
d2θπ4


θ= 5
6 = 42 θ3(20 −30θ)


θ= 5
6 < 0,
we can conclude that arg max π4(Θ|E1 = 0, E2 = 1, E3 = 1, E4 = 1) = 5
6.
5. The a posteriori expectation of the event
E = E5 ∧E6 = min(E5, E6) = E5E6
coincides with its a posteriori probability
P(E5E6|E1 = 0, E2 = E3 = E4 = 1)
=
 1
0
P(E5E6|θ)P(θ|E1 = 0, E2 = E3 = E4 = 1) dθ
=
 1
0
P(E5E6|θ)π4(θ|E1 = 0, E2 = E3 = E4 = 1) dθ
=
 1
0
P(E5|θ)P(E6|θ) · 42 θ5 (1 −θ) dθ
=
 1
0
θ2 42 θ5 (1 −θ) dθ
= 42
 1
0
θ7 (1 −θ) dθ
=
Γ (8)
Γ (6) Γ (2) · Γ (8) Γ (2)
Γ (10)
= Γ (8)
Γ (6) · 7 · 6 · Γ (6)
9 · 8 · Γ (8)
= 7
12.
Here we have used the following formula2
 1
0
θα−1(1 −θ)β−1 dθ = Γ (α) Γ (β)
Γ (α + β) .
⊓⊔
Exercise 14.2 The events E1, E2, . . . are stochastically independents subordinately
to Θ with P(Ei|Θ = θ) = θ. The a priori density Θ is given by
2For this, see the proof for the density of the sum of Γ (α, λ) + Γ (β, λ), where Γ (α, λ), Γ (β, λ)
are stochastically independent.

200
14
Statistics
π0 =
⎧
⎨
⎩
K θ2 (1 −θ) 0 ≤θ ≤1,
0
otherwise.
We observe the values of the ﬁrst 5 events:
E1 = 0, E2 = 1, E3 = 1, E4 = 0, E5 = 1.
1. Compute the normalization constant K.
2. Compute the a posteriori density of the event Θ and the a posteriori probability
of (Θ < 1
2).
3. Compute the a posteriori expectation of X
=
E6 + E7 and the a posteriori
probabilities of E = E6E7 and F = E6 ∨E7.
Solution 14.2
1. To compute the constant k, we impose that the integral of the
density is equal to 1, i.e.
 1
0
π0(θ) dθ = 1.
It follows that
k =
1
 1
0 θ2 (1 −θ) dθ
.
The value of this integral is well-known and equal to:
 1
0
θ2 (1 −θ) dθ = Γ (3) Γ (2)
Γ (3 + 2) ,
hence
k =
Γ (3 + 2)
Γ (3) Γ (2) =
4!
2! · 1! = 12.
2. The a posteriori density is given by
π5(Θ|E1 = 0, E2 = E3 = 1, E4 = 0, E5 = 1)
= π0(θ)P(E1 = 0, E2 = E3 = 1, E4 = 0, E5 = 1|θ)
= π0(θ)P(E1 = 0|θ)P(E2 = 1|θ)P(E3 = 1|θ)P(E4 = 0|θ)P(E5 = 1|θ)
= c · θ2 (1 −θ) · (1 −θ)2 Θ3
= c · θ5 (1 −θ)3.
Here we denote with c the normalization constant of the a posteriori density. In
this case the a posteriori probability distribution is a beta B(6, 4). It follows that

14
Statistics
201
c =
Γ (6 + 4)
Γ (6) Γ (4) =
9!
5! 3! = 7 · 8 · 9 = 504.
If we put W =
˜E1 E2 E3 ˜E4 E5, the a posteriori density is given by
π5(θ) =
⎧
⎨
⎩
504 θ5 (1 −θ)3 0 ≤θ ≤1,
0
otherwise.
To ﬁnd the a posteriori probability of the event (Θ < 1
2) it is sufﬁcient to integrate
the a posteriori density between 0 and 1
2:
P(Θ < 1
2) = 504

1
2
0
θ5 (1−θ)3dθ = 504

1
2
0
(θ5 +3θ7 −3θ6 −θ8)dθ = 65
256.
3. The a posteriori expectation of X = E6 + E7 is given by
P(X|W) =
2

i=0
i P(X = i|W)
= P(X = 1|W) + 2 P(X = 2|W).
We obtain:
P(X = 1|W) = P(E6 = 1, E7 = 0|W) + P(E6 = 0, E7 = 1|W)
= 2
 1
0
P(E6 = 0, E7 = 1|Θ = θ)π5(Θ = θ|W) dθ
= 2
 1
0
Γ (10)
Γ (6) Γ (4)θ · (1 −θ) · θ5 · (1 −θ)3 dθ
= 2
Γ (10)
Γ (6) Γ (4)
 1
0
θ6(1 −θ)4 dθ
= 2
Γ (10)
Γ (6) Γ (4)
Γ (7) Γ (5)
Γ (12)
= 24
55
and
P(X = 2|W) = P(E6 = 1, E7 = 1|W)
=
 1
0
P(E6 = 1, E7 = 1|θ = Θ)π5(Θ = θ|W) dθ

202
14
Statistics
=
Γ (10)
Γ (6) Γ (4)
 1
0
θ2 · θ5 · (1 −θ)3 dθ
=
Γ (10)
Γ (6) Γ (4)
 1
0
θ7(1 −θ)3 dθ
=
Γ (10)
Γ (6) Γ (4)
Γ (8) Γ (4)
Γ (12)
= 21
55.
The a posteriori expectation of X is equal to
P(X|W) = 2 · 21
55 + 24
55 = 6
5.
Note that X = E6 + E7 is a random number, but not an event since it can assume
3 possible values: 0, 1 or 2.
The a posteriori probability of the events E = E6 E7 e F = E6 ∨E7 can be
calculated in the same way:
P(E|W) = P(E6E7 = 1|W) = P(E6 = E7 = 1|W) = 21
55
and
P(F|W) = P(E6 ∨E7 = 1|W)
= P(E6 = 1, E7 = 0|W)
+ P(E6 = 0, E7 = 1|W)
+ P(E6 = 1 = E7 = 1|W)
= 9
11.
⊓⊔
Exercise 14.3 The events E1, E2, . . . are stochastically independents subordinately
to Θ with P(Ei|Θ = θ) = θ. The a prior density Θ is given by
π0(θ) =
 Kθ2(1 −θ)2 for 0 ≤θ ≤1,
0
otherwise.
We observe the values of the ﬁrst 4 events: E1 = 0, E2 = 1, E3 = E4 = 1.
(a) Compute the normalization constant K.
(b) Compute the a posteriori density and the a posteriori expectation of Θ.
(c) Compute the a posteriori probability of the event F = E2
5 and the a posteriori
variance of expectation of ˜E6.

14
Statistics
203
Solution 14.3 (a) To compute K we impose that
 1
0
π0(θ)dθ = 1
i.e.
K =
1
 1
0 θ2(1 −θ)2dθ
,
since the integral of a probability density must be equal to 1. The integral appear-
ing at the denominator is well-known and equal to
 1
0
θ2(1 −θ)2dθ = Γ (3)2
Γ (6)
hence
K = Γ (6)
Γ (3)2 =
5!
(2!)2 = 30.
(b) The a posteriori density of Θ given the events E1 = 0, E2 = E3 = E4 = 1 is
given by the formula
π4(θ|E1 = 0, E2 = 1, E3 = 1, E4 = 1)
= Kπ0(θ)P(E1 = 0, E2 = 1, E3 = 1, E4 = 1|θ)
= P(E1 = 0|θ) · P(E2 = 1|θ) · P(E3 = 1|θ) · P(E4 = 1|θ)
= Kθ5(1 −θ)3,
where K =
Γ (10)
Γ (6)Γ (4) = 504 and θ ∈[0, 1]. For θ /∈[0, 1], the a posteriori
density is equal to 0. To compute the a posteriori expectation of Θ, we apply the
formula of the expectation for absolutely continuous distributions, i.e.
P(Θ|E1 = 0, E2 = E3 = E4 = 1)
=
 1
0
θπ4(θ|E1 = 0, E2 = 1, E3 = 1, E4 = 1)dθ
=
Γ (10)
Γ (6)Γ (4)
 1
0
θ6(1 −θ)3dθ
=
Γ (10)
Γ (6)Γ (4) · Γ (7)Γ (4)
Γ (11)
= 3
5.

204
14
Statistics
(c) The event F = E2
5 coincides with E5 since it assumes only the value 0 or 1. The
a posteriori probability of F is given by
P(F|E1 = 0, E2 = 1, E3 = 1, E4 = 1)
= P(E2
5|E1 = 0, E2 = 1, E3 = 1, E4 = 1)
= P(E5|E1 = 0, E2 = 1, E3 = 1, E4 = 1)
=
 1
0
θπ4(θ|E1 = 0, E2 = 1, E3 = 1, E4 = 1)dθ = 3
5.
To compute the a posteriori variance of ˜E6, we consider the usual formula for
the variance. To simplify the notations, we put A = E1E2E3E4. We obtain
σ2( ˜E6|E1E2E3E4)
= P( ˜E2
6|E1E2E3E4) −P( ˜E6|E1E2E3E4)2
= P( ˜E6|E1E2E3E4) −P( ˜E6|E1E2E3E4)2
= P( ˜E6|E1E2E3E4)(1 −P( ˜E6|E1E2E3E4)),
where we have used that
˜E2
6 = ˜E6.
We need only to compute the a posteriori expectation of ˜E6. For this purpose we
apply the formula of the total probabilities. Hence
P( ˜E2
6|E1E2E3E4) = P( ˜E6|E1E2E3E4)
= P( ˜E6E5|E1E2E3E4)
+ P( ˜E6 ˜E5|E1E2E3E4)
=
 1
0
P( ˜E6E5|θ)π4(θ|E1E2E3E4)dθ
+
 1
0
P( ˜E6 ˜E5|θ)π4(θ|E1E2E3E4)dθ
=
 1
0
θ(1 −θ)π4(θ|E1E2E3E4)dθ
+
 1
0
(1 −θ)(1 −θ)π4(θ|E1E2E3E4)dθ
=
 1
0
(1 −θ)[θ + 1 −θ]π4(θ|E1E2E3E4)dθ
=
 1
0
(1 −θ)π4(θ|E1E2E3E4)dθ

14
Statistics
205
= 1 −
 1
0
θπ4(θ|E1E2E3E4)dθ
= 2
5.
Note that the a posteriori probabilities of E5 and E6 coincide.
⊓⊔
Exercise 14.4 The events E1, E2, . . . are stochastically independent subordinately
to Θ with P(Ei|Θ = θ) = θ. The a priori density of Θ is given by
π0(θ) =

Kθ2√
1 −θ for 0 ≤θ ≤1,
0
otherwise.
We observe the values of the ﬁrst 4 events: E1 = 1, E2 = 0, E3 = 0, E4 = 1.
(a) Compute the normalization constant K.
(b) Compute the a posteriori density π4(θ|E1 = 1, E2 = E3 = 0, E4 = 1) of Θ
and arg max π4(θ|E1 = 1, E2 = E3 = 0, E4 = 1).
(c) Compute the a posteriori covariance of the events E6 and E7.
Solution 14.4 (a) The normalization constant K makes the integral of the density
equal to 1, hence
K =
1
 1
0 θ2(1 −θ)
1
2 dθ
.
We know that
 1
0
θ2(1 −θ)
1
2 dθ = Γ (3)Γ
 3
2

Γ

3 + 3
2
 ,
hence
K =
Γ
 9
2

Γ (3)Γ
 3
2
 =
7
2 · 5
2 · 3
2 · Γ
 3
2

2!Γ
 3
2

= 105
16 .
(b) We compute the a posteriori density by using the fact that the events are stochas-
tically independent subordinately to Θ. We have
π4(θ|E1 = 1, E2 = E3 = 0, E4 = 1)
= KP(E1 = 1, E2 = E3 = 0, E4 = 1|θ)π0(θ)
= KP(E1 = 1|θ) · P(E2 = 0|θ) · P(E3 = 0|θ) · P(E4 = 1|θ)π0(θ)
= Kθ4(1 −θ)
5
2 ,

206
14
Statistics
where
K = Γ

5 + 7
2

Γ (5)Γ
 7
2
 =
15
2 · 13
2 · 11
2 · 9
2Γ
 7
2

Γ (5)Γ
 7
2

= 6435
128 .
Hence
π4(θ|E1 = 1, E2 = E3 = 0, E4 = 1) =
⎧
⎪⎨
⎪⎩
6435
128 θ4(1 −θ)
5
2 θ ∈[0, 1],
0
otherwise.
The arg max can be computed by ﬁnding the zeros of the ﬁrst derivative. We
have
π′
4(θ|E1 = 1, E2 = E3 = 0, E4 = 1) = K

4θ3(1 −θ)
5
2 −5
2θ4(1 −θ)
3
2

= Kθ3(1 −θ)
3
2

4(1 −θ) −5
2θ

= K θ3
2 (1 −θ)
3
2 [8 −13θ].
The derivative is equal to 0 in the extremes of the interval as well in
¯θ = 8
13.
Since π′
4 > 0 for θ ∈

0, 8
13

and π′
4 < 0 for θ ∈
 8
13, 1

, we have that
arg max π4(θ|E1 = 1, E2 = E3 = 0, E4 = 1) = 8
13.
(c) The a posteriori covariance of the events E6 and E7 is given by
cov(E6, E7|E1 = 1, E2 = E3 = 0, E4 = 1)
= P(E6E7|E1 = 1, E2 = E3 = 0, E4 = 1)
−P(E6|E1 = 1, E2 = E3 = 0, E4 = 1)P(E7|E1 = 1, E2 = E3 = 0, E4 = 1).
In Exercise 14.3 we have proved that
P(E6|E1 = 1, E2 = E3 = 0, E4 = 1)
= P(E7|E1 = 1, E2 = E3 = 0, E4 = 1)
=
 1
0
θπ4(θ|E1 = 1, E2 = E3 = 0, E4 = 1)dθ = 10
17.

14
Statistics
207
Analogously
P(E6E7|E1 = 1, E2 = E3 = 0, E4 = 1)
=
 1
0
θ2π4(θ|E1 = 1, E2 = E3 = 0, E4 = 1)dθ = 120
323.
We conclude that
cov(E6, E7|E1 = 1, E2 = E3 = 0, E4 = 1) = 120
323 −
10
17
2
.
⊓⊔
Exercise 14.5 The random numbers X1, X2, . . . are stochastically independents
subordinately to Θ with the same conditional marginal density given by
f (x|θ) =
1
√
2π
exp

−(x −θ)2
2

,
x ∈R.
We assume that Θ has standard normal distribution. We observe the values of the
ﬁrst 4 experiments:
x1 = 0.1,
x2 = 2,
x3 = −1,
x4 = 0.5.
(a) Write the a priori density of Θ.
(b) Compute the a posteriori density π4(θ| x1 = 0.1, x2 = 2, x3 = −1, x4 = 0.5)
of Θ and arg max π4(θ| x1 = 0.1, x2 = 2, x3 = −1, x4 = 0.5).
(c) Compute the a posteriori expectation and variance of Θ.
Solution 14.5 (a) SinceΘ hasastandardnormaldistributionasaprioridistribution,
we can write immediately the a priori density
π0(θ) =
1
√
2π
e−θ2
2 ,
θ ∈R.
(b) We compute the a posteriori density by using the fact that the random numbers
are stochastically independent subordinately to Θ:
π4(θ| x1 = 0.1, x2 = 2, x3 = −1, x4 = 0.5)
= k f (x1, x2, x3, x4|θ)π0(θ)
= k4
i=1 f (xi|θ)π0(θ) = k exp

−
4
i=1(xi −θ)2 + θ2
2

= k exp

−5
2(θ −8
25)2

,

208
14
Statistics
Notethatallfactorswhichareindependentofθ arenowincludedintheconstantk.
We obtain that the a posteriori distribution is Gaussian N( 8
25, 1
5), hence
k =
√
5
√
2π
.
The graph of the a posteriori density is bell shaped with symmetry axis x = 8
25.
Then arg max π4(θ| x1 = 0.1, x2 = 2, x3 = −1, x4 = 0.5) =
8
25. Verify this by
computing the derivatives of the density function.
(c) The parameters of the a posteriori density provide us with:
1. the a posteriori expectation
P(Θ| x1 = 0.1, x2 = 2, x3 = −1, x4 = 0.5) = 8
25;
2. the a posteriori variance
σ2(Θ| x1 = 0.1, x2 = 2, x3 = −1, x4 = 0.5) = 1
5.
⊓⊔
Exercise 14.6 The random numbers X1, X2, . . . are stochastically independent sub-
ordinately to Θ with the same conditional marginal density given by
f (x|θ) =
1
2
√
2π
exp

−(x −θ)2
8

,
x ∈R.
The a priori distribution of Θ is given by
π0(θ) =
1
√
4π
exp

−(θ −1)2
4

,
θ ∈R.
We observe the values of the ﬁrst 3 experiments:
x1 = 1,
x2 = 0.5,
x3 = −1.
(a) Compute the likelihood factor.
(b) Compute the a posteriori density of Θ.
(c) Estimate the a posteriori probability of the event (Θ > 1000).

14
Statistics
209
Solution 14.6 (a) By deﬁnition, the likelihood factor is given by
f (x1, x2, x3|θ) = 3
i=1 f (xi|θ)
=
1
8

(2π)3 exp

−
3
i=1(xi −θ)2
8

=
1
8

(2π)3 exp

−1
8

3θ2 −θ + 9
4

.
(b) By the computations for the likelihood factor, we immediately obtain the a
posteriori density as follows
π3(θ| x1 = 1, x2 = 0.5, x3 = −1)
= k f (x1, x2, x3, x4|θ)π0(θ)
= k exp

−1
8

3θ2 −θ + 9
4

−(θ −1)2
4

= k exp

−5
8(θ −1
2)2

,
where we have put in the constant k all terms which are independent of θ. We
obtain that the a posteriori distribution is a normal distribution N(1
2, 4
5) with
normalization constant k =
√
5
2
√
2π
.
(c) To estimate the a posteriori probability of the event (Θ > 1000) we use the
tail estimation for the Gaussian distribution. To this purpose we need ﬁrst to
express Θ as function of a random variable Y with distribution N(0, 1). Since
the a posteriori distribution of Θ is Gaussian N(1
2, 4
5), we have
Θ = 2
√
5
5 Y + 1
2,
where Y ∼N(0, 1). Hence
P(Θ > 1000) = P(2
√
5
5 Y + 1
2 > 1000) = P(Y >
√
5
2 · 999, 5).
By the tail estimation of the standard normal distribution, we obtain that
n(x)
x
−n(x)
x3
< P(Y > x) < n(x)
x
,

210
14
Statistics
where x > 0, n(x) =
1
√
2π
e−x2
2 . To obtain an upper bound for P(Θ > 1000)
we can compute n(x)
x
in the point
x =
√
5
2 · 999, 5.
⊓⊔
Exercise 14.7 The random numbers X1, X2, . . . are stochastically independent sub-
ordinately to Φ with the same conditional marginal density given by
f (x|φ) =
1
√
2π
φ
1
2 exp

−φ(x −1)2
2

,
x ∈R.
The a priori distribution of Φ is given by a Gamma distribution Γ (2, 1). We observe
the values of the ﬁrst 3 experiments:
x1 = 1.5,
x2 = 0.5,
x3 = 2.
(a) Write the a priori density of Φ.
(b) Compute the a posteriori density π3(φ| x1 = 1.5, x2 = 0.5, x3 = 2) of Φ and
arg max π3(φ| x1 = 1.5, x2 = 0.5, x3 = 2).
(c) Compute the a posteriori expectation and variance of Φ.
Solution 14.7 (a) Since the a priori distribution of Φ is given by a Gamma distri-
bution Γ (2, 1), we can write immediately the a priori density:
π0(φ) =
φ e−φ φ ≥0,
0
φ < 0.
(b) The a posteriori density is given by
π3(φ| x1 = 1.5, x2 = 0.5, x3 = 2)
= k f (x1, x2, x3|φ)π0(φ)
= kφ
5
2 exp

−
3
i=1(xi −1)2
2
+ 1

φ

= kφ
5
2 e−7
4 φ
for φ ≥0, 0 otherwise. Note that we have put in the constant k all factors which
are independent of φ. The a posteriori distribution is then a Gamma distribution
Γ (7
2, 7
4) with normalization constant

14
Statistics
211
k =
7
4
 7
2
1
Γ ( 7
2) =
√
77
240√π .
Furthermore we have that
d
dφπ3(φ| x1 = 1.5, x2 = 0.5, x3 = 2) = kφ
3
2 e−7
4 φ(5
2 −7
4φ) = 0
if φ = 10
7 . We immediately obtain that arg max π3(φ| x1 = 1.5, x2 = 0.5, x3 =
2) = 10
7 by analyzing the sign of the ﬁrst derivative.
(c) The parameters of the a posteriori density provide us with
1. the a posteriori expectation
P(Φ| x1 = 1.5, x2 = 0.5, x3 = 2) = 2 ;
2. the a posteriori variance
σ2(Θ| x1 = 0.1, x2 = 2, x3 = −1, x4 = 0.5) = 8
7.
⊓⊔
Exercise 14.8 The random numbers X1, X2, . . . are stochastically independent sub-
ordinately to Φ with the same conditional marginal density given by
f (x|φ) =
1
√
2π
φ
1
2 exp

−φx2
2

,
x ∈R.
The a priori distribution of Φ is given by an exponential distribution with parameter
λ = 2. We observe the values of the ﬁrst 4 experiments:
x1 = 1,
x2 = 2,
x3 = 0.5,
x4 =
√
2.
(a) Write the a priori density of Φ and the a priori probability of the event (Φ > 2).
(b) Compute the a posteriori density of Φ and the a posteriori probability of the
event (Φ > 2).
(c) Compute the a posteriori expectation of Z = Φ2.
Solution 14.8 (a) Since the a priori distribution of Φ is given by an exponential
distribution with parameter λ = 2, i.e. a Gamma distribution Γ (1, 2), we can
write immediately the a priori density:
π0(φ) =
2e−2φ φ ≥0,
0
φ < 0.

212
14
Statistics
The a priori probability of the event (Φ > 2) is given by
P(Φ > 2) =
 +∞
2
2e−2φdφ = e−4.
(b) The a posteriori density is given by
π4(φ| x1 = 1, x2 = 2, x3 = 0.5, x4 =
√
2)
= k f (x1, x2, x3, x4|φ)π0(φ)
= kφ2 exp

−
4
i=1 x2
i
2
+ 2

φ

= kφ2e−45
8 φ
for φ ≥0, 0 otherwise. Note that we have put in the constant k all factors which
are independent of φ. The a posteriori distribution is then a Gamma distribution
Γ (α4, λ4) = Γ (3, 45
8 ) with normalization constant
k =
45
8
3
1
Γ (3) = 453
210 .
The a posteriori probability of the event (Φ > 2) is given by
P(Φ > 2| x1 = 1, x2 = 2, x3 = 0.5, x4 =
√
2)
=
 +∞
2
π4(φ| x1 = 1, x2 = 2, x3 = 0.5, x4 =
√
2)dφ
= k
 +∞
2
φ2e−45
8 φdφ
= k 8
45

−

φ2 + 2φ + 2

e−45
8 φ+∞
2
= 3453
26 e−45
4 .
(c) To compute the a posteriori expectation of Z = Φ2 it is sufﬁcient to note that
P(Φ2| x1 = 1, x2 = 2, x3 = 0.5, x4 =
√
2)
= σ2(Φ| x1 = 1, x2 = 2, x3 = 0.5, x4 =
√
2)
+ P(Φ| x1 = 1, x2 = 2, x3 = 0.5, x4 =
√
2)
= α4
λ2
4
+ α2
4
λ2
4
= 256
675.
⊓⊔

Appendix A
Elements of Combinatorics
Consider a set Ω = {a1, . . . , an} of n elements. We recall that the symbol
n
r

is
called binomial coefﬁcient and that
n
r

=
n!
r!n −r!.
A.1
Dispositions
We count the number of ways of choosing r elements out of a set of n elements with
repetitions and taking in account of their order, i.e. the number of dispositions of r
elements out of n. We have:
1st element −→n choices,
2nd elements −→n choices,
·
·
·
·
·
·
rth elements −→n choices .
Totally, the dispositions are n · n . . . n = nr. They count the number of functions
from a set of r elements to a set of n elements.
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
213

214
Appendix A: Elements of Combinatorics
A.2
Simple Dispositions
We count the number of ways of choosing r elements out of a set of n elements
without repetitions and taking in account of their order, i.e. the number of simple
dispositions of r elements out of n. We have:
1o element −→n choices,
2o elements −→(n −1) choices,
3o elements −→(n −2) choices,
·
·
·
·
·
·
ro elements −→(n −r + 1) choices .
Totally, the simple dispositions are n · (n −1) . . . (n −r + 1) =
n!
(n −r)! and are
denoted by the symbol Dn
r or (n)r. They count the number of injective functions from
a set of r elements to a set of n elements. If r = n, they are called permutations.
A.3
Simple Combinations
We count the number of ways of choosing r elements out of a set of n elements
without repetitions and without taking in account of their order, i.e. the number of
simple combinations ofr elements out of n. Given a simple combination ofr elements
out of n, we obtain r! dispositions by permutating the r elements. The number of
simple combinations is then
1
r! Dn
r =
n!
r!(n −r)! =
n
r

.
They count the number of injective functions from a set of r elements to a set of n
elements which have a different image.

Appendix A: Elements of Combinatorics
215
A.4
Combinations
Wecountthenumberofwaysofchoosingr elementsoutofasetofn elementswithout
taking in account of their order, i.e. the number of combinations of r elements out
of n. Given a combination {a1, . . . , ar}, without loss of generality, we can suppose
that a1 ≤· · · ≤ar. Starting from this combination, we now construct a simple
combination of r elements out of n + r −1 elements in the following way:
b1 = a1 ,
b2 = a2 + 1 ,
·
·
·
·
·
·
br = ar + r −1 .
On the other way round, we can always associate a combination to a simple com-
bination. Hence the r-combinations are as many as the r-simple combinations in
n + r −1, elements, i.e.
n + r −1
r

.
A.5
Multinomial Coefﬁcient
The number of ways of forming k groups of r1, . . . ,rk elements respectively, where
r1 + · · · + rk = n is given by the multinomial coefﬁcient
n!
r1!r2! . . .rk! .
To form the ﬁrst group of r1 elements, we have
 n
r1

possibilities. For the second
group, we have
n −r1
r2

ways. Analogously we proceed for the remaining groups.
We obtain
 n
r1
 n −r1
r2

· · ·
 n −r1 −· · · −rk−1
rk

=
n!
r1!r2! . . .rk! .

Appendix B
Relations Between Discrete and Absolutely
Continuous Distributions
In TableB.1 we summarize some analogies between discrete and absolutely contin-
uous distributions.
Table B.1 Some analogies between discrete and absolutely continuous distributions
C. Discrete
C. Abs. Continuous
Probability
Density
P(X = x)
−→
f (x)
Cumulative
distribution function
P(X ≤x)

i∈I (X),i≤x
P(X = i)
−→
 x
−∞f (s) ds
Expectation of X

i∈I (X)
i P(X = i)
−→
 +∞
−∞s f (s) ds
Expectation of
Y = Ψ (X)

i∈I (X)
Ψ (i) P(X = i)
−→
 +∞
−∞Ψ (s) f (s) ds
P(X ∈A)

i∈I (X),i∈A
P(X = i)
−→

A f (s) ds
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
217

Appendix C
Some Discrete Distributions
We present in Table C.1 an overview of the discrete distributions presented in Chap.2.
Table C.1 Some discrete distributions
Distribution
I (X)
P(X = k)
P(X)
σ2(X)
Bernoulli p
{0, 1}
P(X = 1) = p
p
p(1 −p)
Binomial
Bn(n, p)
{0, . . . , n}

n
k

pk (1 −p)n−k
np
np (1 −p)
Geometric p
{1, 2, . . . }
p (1 −p)k−1
1
p
1−p
p2
Hypergeometric
(n, N, b)
{0 ∨(n −(N −
b)), . . . , n ∧b}
⎛
⎝b
k
⎞
⎠
⎛
⎝N −b
n −k
⎞
⎠
⎛
⎝N
n
⎞
⎠
n b
N
n

N−n
N−1

b
N

1 −b
N

Poisson λ
N
λk
k! e−λ
λ
λ
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
219

Appendix D
Some One-Dimensional Absolutely
Continuous Distributions
We recall in Table D.1 the most common one-dimensional absolutely continuous
distributions.
Table D.1 Some one-dimensional absolutely continuous distributions
Distribution
I (X)
Density
P(X)
σ2(X)
Uniform [a, b]
[a, b]a
1
b−a I[a,b]
a+b
2
(b−a)2
12
Exponential λ
R+
λ e−λx I{x≥0}
1
λ
1
λ2
Std. normal N(0, 1)
R
1
√
2π e−x2
2
0
1
Gen. normal N(μ, σ2)
R
1
√
2πσ2 e−(x−μ)2
2σ2
μ
σ2
Gamma Γ (α, β)
R+
λα
Γ (α) xα−1e−λx I{x≥0}
α
λ
α
λ2
Beta B(α, β)
[0, 1]
Γ (α+β)
Γ (α)Γ (β) xα−1 (1−x)β−1
α
α+β
αβ
(α+β)2 (α+β+1)
ab > a
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
221

Appendix E
The Normal Distribution
We present in Table E.1 a summary on the normal distribution.
Table E.1 The normal distribution in a nutshell
Density
f (x1, . . . , xn) = k e(−1
2 Ax·x+b·x)
x =
⎛
⎜⎜⎝
x1
...
xn
⎞
⎟⎟⎠, A ∈S(n), b =
⎛
⎜⎜⎝
b1
...
bn
⎞
⎟⎟⎠
Normalization constant
k =

det A
(2π)n e−1
2 A−1b·b
Expectation
P(X) = A−1b ⇒P(Xi) = (A−1b)i
Variance and covariance matrix
C = A−1
Marginal distribution of Xi
Xi ∼N

(A−1b)i, [A−1]ii

© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
223

Appendix F
Stirling’s Formula
Inthis chapter wepresentStirling’s formula, whichdescribes theasymptoticbehavior
of n! with n increasing. It holds that:
Stirling’s formula: n! =
√
2π nn+ 1
2 e−n(1 + O(n−1)) .
Different kinds of proofs can be used to prove this formula. Here we present the
classical proof and a more general result, of which the Stirling’s formula represents
a particular case.
We start with the classical proof which can be found in [2]. Here we recall it for
reader’s convenience.
F.1
First Proof
Here we obtain Stirling’s formula modulo a multiplicative constant. This value can
be shown to be equal to
√
2π, as a consequence of Theorem 5.4.1 by approximating
the probability that a random number with binomial distribution Bn(2n, 1
2) assumes
the value n.
The Stirling’s formula is equivalent to
lim
n→∞
n!
√
2π nn+ 1
2 e−n = 1.
In order to compute this limit, we look for an estimation of
log n! = log(1 · 2 · . . . n) = log 1 + log 2 + · · · + log n .
Since log x is an increasing function, it can be approximated as follows:
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
225

226
Appendix F: Stirling’s Formula
 k
k−1
log xdx < log k · 1 <
 k+1
k
log xdx .
Hence summing up
n

k=1
 k
k−1
log xdx <
n

k=1
log k <
n

k=1
 k+1
k
log xdx,
we have
n log n −n < log n! < (n + 1) log(n + 1) −n .
This inequality suggests to use log n! to approximate
(n + 1
2) log n −n .
We can namely think that (n + 1
2) log n represents a sort of average. If we put
dn = log n! −

n + 1
2

log n −n = log

n!
nn+ 1
2 e−n

,
we have
dn −dn+1 =

n + 1
2

log
n + 1
n

−1,
(F.1)
however
n + 1
n
=
1 +
1
2n + 1
1 −
1
2n + 1
and
log(x + 1) =
∞

n=1
(−1)n+1 xn
n .
(F.2)
Since
log
n + 1
n

= log
⎛
⎜⎝
1 +
1
2n + 1
1 −
1
2n + 1
⎞
⎟⎠= log

1 +
1
2n + 1

−log

1 −
1
2n + 1

,
using (F.2) with x = ±
1
2n + 1 we obtain

Appendix F: Stirling’s Formula
227
dn −dn+1 = 1
2(2n + 1)

log

1 +
1
2n + 1

−log

1 −
1
2n + 1

−1
= 1
2(2n + 1)

2
(2n + 1) +
2
3(2n + 1)3 +
2
5(2n + 1)5 + · · ·

−1
=
1
3(2n + 1)2 +
1
5(2n + 1)4 + · · · ,
from which it follows
dn −dn+1 > 0 .
Hence dn is decreasing. It follows that the limit of dn exists (ﬁnite or inﬁnite). To
prove that the limit is ﬁnite, we note that
0 < dn −dn+1 < 1
3
∞

k=1

1
2n + 1
2k
= 1
3
⎡
⎢⎢⎣
1
1 −
1
(2n + 1)2
−1
⎤
⎥⎥⎦
= 1
3
1
(2n + 1)2 −1 =
1
12n −
1
12(n + 1),
i.e. the sequence
an = dn −
1
12n
is increasing. Since
an ≤dn
∀n ∈N, n ̸= 0,
and it holds that
lim
n→∞an = lim
n→∞

dn −
1
12n

= lim
n→∞dn,
we obtain that the limit of dn exists ﬁnite since the two sequences an e dn are bounded
by each other.
F.2
Proof by Using the Gamma Function
Consider the Gamma function given by
Γ (α) =
 +∞
0
xαe−xdx ,
where α > 0. It represents a generalization of factorial n, since for all α > 0 it holds
that

228
Appendix F: Stirling’s Formula
Γ (α + 1) = αΓ (α).
This can be easily veriﬁed by integration by parts. If α is a natural number, by iteration
we obtain
Γ (n + 1) = n!.
To prove Stirling’s formula we show the more general result that
Γ (α + 1) =
√
2π αα+ 1
2 e−α(1 + O(α−1)) .
We consider logarithm of φ(x) = log (xαe−x) = α log x −x. We compute the Taylor
expansion of φ(x) at the maximum point α:
φ(x) = α log α −α −1
2α(x −α)2 +
n

k=3
(−1)k−1
k
(x −α)k
αk−1
+α(−1)n
n + 1
(x −α)n+1
ξn+1
,
where ξ ∈[α, x]. In the integral we perform the change of variable
u = x −α
√α ,
dx = √αdu .
We obtain
Γ (α + 1) = αα+ 1
2 e−α
 +∞
−√α
e−u2
2 +ψ(u)du,
where
ψ(u) =
n

k=3
(−1)k−1
k
uk
α
k
2 −1 + α
n+3
2 (−1)n
n + 1
un+1
(α + ξ√α)n+1
with ξ ∈[0, u]. We divide the integral in three parts:
I1 = [−√α, −αδ],
I2 = [−αδ, αδ],
I3 = [αδ, +∞],
where δ > 0 s sufﬁciently small constant. For what concerns I1, I3 we note that φ(u)
is a concave function. Hence we obtain that also the function
θ(u) = −u2
2 + ψ(u),
obtained by φ by adding a constant and by a linear transformation of the underlying
variable, is concave. For u ≤−αδ we have
θ(u) ≤−u
αδ θ(−αδ)

Appendix F: Stirling’s Formula
229
and for u ≥αδ
θ(u) ≤u
αδ θ(αδ).
By the expansion of ψ(u) with n = 2 we note that for α sufﬁciently big and δ < 1
6
we have θ(−αδ) < −α2δ
4 , θ(αδ) < −α2δ
4
Hence for |u| ≥αδ it holds that
θ(u) ≤−|u| αδ
4 .
It follows that

I1
eθ(u)du +

I3
eθ(u)du ≤

|u|≥αδ e−|u| αδ
4 du
=

−8
αδ e−|u| αδ
4
+∞
αδ
= 8
αδ e−α2δ
4 .
We now consider I2. If we choose n = 3 we obtain
eψ(u) = exp
1
3
u3
α
1
2 −1
4
α3u4
(α + ξ√α)4

= 1 + 1
3
u3
α
1
2 + O(u4
α )
with ξ ∈[0, u] ⊂I2 and for |u| < αδ. It follows that

I2
e−u2
2 +ψ(u)du =

e−u2
2 du −

I c
2
e−u2
2 du + α−1
2
3
+

I2
u3e−u2
2 du + O(α−1)
=
√
2π + O(α−1)
and hence
Γ (α + 1) =
√
2π αα+ 1
2 e−α(1 + O(α−1)) .

Appendix G
Elements of Analysis
In this appendix we recall some deﬁnitions and results of analysis in one variable to
facilitate the theoretical comprehension and the execution of the exercises.
G.1
Limit of a Sequence
Let (an)n ∈N
be a sequence of real numbers. This is called
1. convergent if
lim
n→∞an = L < ∞,
i.e. if for all ϵ > 0 there exists N = N(ϵ)
such that for all n > N
|an −L| < ϵ ;
2. divergent if
lim
n→∞an = +∞,
i.e. if for all M > 0 there exists N = N(M)
such that for all n > N
an > M ,
or limn→∞an = −∞respectively, i.e. if for all M > 0 there exists N =
N(M)
such that for all n > N
an < M .
A sequence may neither be convergent nor divergent. For example, the sequence
an = (−1)n oscillates between 1 and −1.
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
231

232
Appendix G: Elements of Analysis
G.2
Limit of Functions
A function f : R −→R has:
1. ﬁnite limit in x if
lim
y→x f (y) = L < ∞,
i.e. if for all ϵ > 0 there exists δ = δ(ϵ)
such that for all y with |y −x| < δ
| f (y) −L| < ϵ ;
2. inﬁnite limit in x if
lim
y→x f (y) = +∞,
i.e. if for all M > 0 there exists δ = δ(M)
such that for all y with |y −x| < δ
f (y) > M ,
or limy→x f (y)
=
−∞meaning that, for all M > 0 there exists δ =
δ(M)
such that for all y with |y −x| < δ
f (y) < M .
G.3
Limits of Special Interest
We recall the following limits of special interest:
1.
lim
n→∞

1 + 1
n
n
= e ;
2. ∀x ∈R
lim
n→∞

1 + x
n
n
= ex ;
3.
lim
x→0
log(1 + x)
x
= 1 .

Appendix G: Elements of Analysis
233
G.4
Series
We recall the following series:
1. the geometric series
∞

n=0
xn =
1
1 −x
for all |x| < 1;
2. the series
∞

n=1
nxn−1 =
1
(1 −x)2
for all |x| < 1, which is obtained as derivative of the geometric series;
3. the exponential series
∞

n=0
xn
n! = ex
for all x ∈R.
G.5
Continuity
A function is said to be continuous in the point x0 if
lim
x→x−
0
f (x) = lim
x→x+
0
f (x) = f (x0) ,
where lim
x→x−
0
f (x), lim
x→x+
0
f (x) are called left limit and right limit respectively. The
left limit is taken over x < x0, the right limit is taken over x > x0.
G.6
Table of the Principal Rules of Derivation
We summarize the most common derivatives as well as the principal rules of deriva-
tion in Table G.1 and in Table G.2, respectively.

234
Appendix G: Elements of Analysis
Table G.1 Derivatives
Function f (x)
Derivative f ′(x)
xn
n xn−1
ex
ex
log x
1
x
sin x
cos x
cos x
−sin x
e−x2
2
−x e−x2
2
Table G.2 Rules of
derivation
d
dx [ f (x) + g(x)]
f ′(x) + g′(x)
d
dx [ f (x) g(x)]
f ′(x) g(x) + f (x) g′(x)
d
dx

f (x)
g(x)

f ′(x) g(x)−f (x) g′(x)
g2(x)
d
dx [ f (g(x))]
f ′(g(x)) · g′(x)
G.7
Integrals
1. Integration by parts formula
 b
a
f (x) g′(x) dx = [ f (x) g(x)]b
a −
 b
a
f ′(x) g(x) dx .
2. Change of variable
x = g(y) ⇒dx = g′(y) dy,
 b
a
f (x) dx =
 g−1(b)
g−1(a)
f (g(y)) g′(y) dy .

Appendix H
Bidimensional Integrals
In this appendix we recall some notions of analysis in several variables to facilitate
the comprehension of the text and the execution of the exercises.
H.1
Areas of Bidimensional Regions
Let A be a region of the plane (Fig.H.1). The area of A is given by
area A =
 
A
dxdy .
This is analogous to the one-dimensional case, where the length of a segment [a, b]
is given by
l([a, b]) =
 b
a
dx .
H.2
Integrals of Functions of Two Variables
Let f : R2 →R and put z = f (x, y). A function in two variables describes a surface
in R3 of coordinates (x, y, f (x, y)). We want to calculate the volume between the
surface described by the function and the plane xy. This volume is given by the
double integral
 
R2 f (x, y) dxdy ,
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
235

236
Appendix H: Bidimensional Integrals
Fig. H.1 A region of the
plane
x
y
O
if f is sufﬁciently regular (for example, if f is continuous). We can compute a double
integral as two nested one-dimensional integrals, i.e.

dx

f (x, y) dy =

dy

f (x, y) dx =
 
f (x, y) dxdy .
This result holds for sufﬁciently regular functions f (for example, if f is continuous)
and is known as Fubini-Tonelli theorem. We refer to [11] for further details.
Example H.2.1 Let A = {1 < x < 2, 3 < y < 4}. We compute the following
integral on A.
 
A
x2y dxdy =
 2
1
dx
 4
3
x2y dy

 !
"
x is a parameter!
=
 2
1
x2
 4
3
y dy

dx
=
 2
1
x2
1
2 y2
4
3
dx
= 7
2
 2
1
x2 dx
= 49
6 .

Appendix H: Bidimensional Integrals
237
Fig. H.2 The region B
x
y
O
B
Example H.2.2 Let B = {0 < x < 1, x −1 < y < x + 1}, see Fig.H.2.
We calculate the following integral on B.
 
B
e−y dxdy =
 1
0
dx
 x+1
x−1
e−y dy
=
 1
0
#
e−y$x+1
x−1 dx
=
 1
0

e−(x+1) −e−(x−1)
dx
=
 1
0

e−1 −e

e−xdx
=

e−1 −e
 
1 −e−1
.
Example H.2.3 To perform a double integral, it is convenient to divide the domain
of integration in a suitable way. Consider the example of Fig.H.3, where D = {0 <
y < 1, y −1 < x < −y + 1}.
We compute the integral of a function f (x, y), which is assumed to be sufﬁciently
regular, on D:
 
D
f (x, y) dxdy =
 1
0
dy
 −y+1
y−1
f (x, y) dx
=
 1
0
dx
 −x+1
0
f (x, y) dy +
 0
−1
dx
 x+1
0
f (x, y) dy.

238
Appendix H: Bidimensional Integrals
Fig. H.3 Region D
x
y
O
−1
1
1
y=x+1
y=−x+1
In the ﬁrst passage the extremes of integration can be found by drawing the parallels
to the x-axis and ﬁnding the intersections with the border of the domain D. In the
second step the integral has been split in two parts and the extremes have been found
by drawing the parallels to the y-axis.
H.3
Partial Derivatives with Respect to a Single Variable
Let f : R2 →R, z = f (x, y). We call partial derivative of f with respect to the
variable x and write ∂f
∂x the derivative of f obtained by considering the function as
depending only by the variable x and considering the other variables as parameters.
Analogously we can deﬁne the partial derivatives of a function with respect to the
other variables.
Example H.3.1 (Partial derivatives)
1.
f (x, y) = x2y:
∂f
∂x = 2xy , ∂f
∂y = x2 ;
2.
f (x, y) = log(xy):
∂f
∂x = 1
x , ∂f
∂y = 1
y .
H.4
Change of Variables
Let Ψ : R2 →R2, (x, y) = (Ψ1(x, y), Ψ2(x, y)). We call Jacobian Jψ of the
function ψ the matrix

Appendix H: Bidimensional Integrals
239
JΨ =
⎛
⎜⎝
∂Ψ1
∂x
∂Ψ1
∂y
∂Ψ2
∂x
∂Ψ2
∂y
⎞
⎟⎠.
A change of coordinates in R2 is given by a function
Ψ : R2 →R2
(u, v) −→(x, y)
with particular regularity properties (diffeomorphismus). To change the variables in
an integral, we use then the following rule:
 
A
f (x, y) dxdy =
 
Ψ −1(A)
f (Ψ (u, v)) |det JΨ | dxdy
with the help of the following diagram:
R2
(u,v)
f ◦Ψ









Ψ
 R2
(x,y)
f

R
Example H.4.1 In this example we consider the computation of the normalization
constant for the standard normal distribution in 2 dimension. To this purpose we need
Fig. H.4 Extremes of
integration as x varies
x
O
y

240
Appendix H: Bidimensional Integrals
Fig. H.5 Extremes of
integration as y varies
x
O
y
to use a change of variable (Figs.H.4 and H.5). Consider
 
R2 e−1
2 (x2+y2) dxdy .
To compute this integral, we use the polar coordinates:
x = ρ cos θ,
y = ρ sin θ
(θ, ρ)
Ψ→(x, y) = (ρ cos θ, ρ sin θ) .
The Jacobian of this transformation is given by
JΨ =
⎛
⎝
∂
∂θ ρ cos θ
∂
∂ρ ρ cos θ
∂
∂θ ρ sin θ
∂
∂ρ ρ sin θ
⎞
⎠=
⎛
⎝
−ρ sin θ
cos θ
ρ cos θ
sin θ
⎞
⎠.
The Jacobian determinant is then
det JΨ = −ρ (sin2 θ + cos2 θ) = −ρ,
i.e.
| det JΨ | = ρ .

Appendix H: Bidimensional Integrals
241
It follows that
 
R2 e−1
2 (x2+y2) dxdy =
 +∞
0
dρ
 2π
0
ρ e−1
2 ρ2 dθ
=
 +∞
0
ρ e−1
2 ρ2 dρ
 2π
0
dθ
= 2π

−e−1
2 ρ2+∞
0

 !
"
1
= 2π .
Hence
 +∞
−∞
e−x2
2 dx
2
=
 +∞
−∞
e−x2
2 dx
 +∞
−∞
e−Y2
2 dy
=
 
R2 e−1
2 (x2+y2) dxdy = 2π .
Finally
 +∞
−∞
e−x2
2 dx =
√
2π .

References
1. de Finetti, B.: Theory of Probability. A Critical Introduction Treatment, vol. 1, 2. Wiley,
New York (1974, 1975)
2. Feller, W.: An Introduction to Probability Theory and Its Applications, vol. 1. Wiley, New York
(1957)
3. Foatà, D., Fuchs, A.: Calcul des probabilités, 2nd edn. Dunod, Paris (1998)
4. Gnedenko, B.: The Theory of Probability. Gordon and Breach Science Publishers, Amsterdam
(1997)
5. Hogg, R.V., Tanis, E.A.: Probability and Statistical Inference. Prentice Hall, New York (2001)
6. Jacod, J., Protter, P.: Probability Essentials. Springer, Berlin (2003)
7. Kleinrock, L.: Queueing Systems 1. Wiley, New York (1975)
8. Kleinrock, L., Gail, R.: Queueing Systems: Problems and Solutions. Wiley, New York (1996)
9. Lee, P.M.: Bayesian Statistics: An Introduction. Edward Arnold, London (1994)
10. Lindley, D.V.: Introduction to Probability and Statistics, vol. 1, 2. Cambridge University Press,
New York (1965)
11. Munkres, J.R.: Analysis On Manifolds. Advanced Books Classics. Westview Press, Boulder
(1997)
12. Ross, S.M.: Introduction to Probability Models. Elsevier, New York (2010)
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
243

Index
A
Absolutely continuous distribution, 44
Absorbing boundary conditions, 82
Area, 235
B
Bayes’ formula, 16
Bernoulli scheme, 27
Bet, 8
Binomial distribution, 28
Bounded, 3
C
Change of variables, 239
Client, 89
Coefﬁcient
binomial, 213
multinomial, 215
Coherence, 8
Combinations, 215
Complementary, 5
Conditional probability, 14
Conﬁdence
intervals, 111
region, 111
Constituent, 6
Continuity, 233
Convergence for sequences of cumulative
distribution functions, 73
Covariance, 22
Cumulative distribution function, 43
D
Density
a posteriori, 106
conditional, 104
joint probability, 58
marginal probability, 59
Derivative, 234
Discrete distribution, 27
Dispositions, 213
simple, 214
Distribution
a priori, 106
beta, 62
Cauchy, 55
χ2, 54
exponential, 48
gamma, 52
Gaussian n-dimensional, 66
initial, 81
normal, 50
stationary, 96
Student, 63
Double integral, 235
E
Equations
Chapman-Kolmogorov, 91
Kolmogorov forward, 91
Event, 5
Exhaustivity, 6
Expectation, 8
F
Formula
of composite expectation, 15
Stirling’s, 225
Function
© Springer International Publishing Switzerland 2016
F. Biagini and M. Campanino, Elements of Probability and Statistics,
UNITEXT - La Matematica per il 3+2 98, DOI 10.1007/978-3-319-07254-8
245

246
Index
joint cumulative distribution, 57
marginal cumulative distribution, 58
G
Generating function, 39
Geometric distribution, 29
H
Homogeneous Markov chain, 81
Hypergeometric distribution, 31
I
Incompatibility, 6
J
Jacobian, 238
Joint distribution, 35
L
Law of large numbers, 25
Likelihood factor, 108
Limit, 231
Linearity, 8
Little’s formula, 101
Logical
product, 5
sum, 5
Logically
dependent event, 7
independent event, 7
semidependent event, 7
Lower bounded, 3
M
Marginal distribution, 35
Memoryless, 30
Monotonicity, 8
Multinomial distribution, 33
N
Negatively
correlated, 22
Non-correlated, 22
P
Partial derivatives, 238
Partition, 6
Penalty, 8
Permutations, 214
Pluri-events, 33
Poisson distribution, 30
Polar coordinates, 240
Positively
correlated, 22
Possible values, 3
Precision, 108
Process
Poisson, 91
stochastic, 89
Q
Queueing system, 89
R
Random
number, 3
vector, 35
walk, 82
S
Series, 233
Server, 89
Service times, 89
Simple combinations, 214
State space, 81
Stationary regime, 100
Statistical
induction, 104
inference, 104
Successes, 28
T
Theorem
De Moivre-Laplace, 77
Transition probability matrix, 81
U
Uniform distribution, 46
Upper bounded, 3

