Jonathan W. Siegel
Texas A&M University
Department of Mathematics
Blocker Building
College Station, TX 77840
Phone:
(909) 646-0941
Email:
jwsiegel@tamu.edu
Homepage:
https://jwsiegel2510.github.io
EDUCATION
University of California at Los Angeles
2013-2018
Ph.D. in Mathematics
Los Angeles, CA
Advisor: Russel E. Caﬂish
Thesis: “Accelerated First-Order Optimization with Orthogonality Constraints”
University of California at Santa Cruz
2009-2013
B.Sc. (Honors) in Mathematics
Santa Cruz, CA
ACADEMIC APPOINTMENTS
Assistant Professor
2022-present
Texas A&M University
College Station, TX
Assistant Research Professor
2021-2022
Pennsylvania State University
University Park, PA
Postdoctoral Scholar
2018-2021
Pennsylvania State University
University Park, PA
RESEARCH PAPERS
Published
• Greedy Training Algorithms for Neural Networks and Applications to PDEs. Journal of Compu-
tational Physics 484:112084, 2023. With Qingguo Hong, Xianlin Jin, Wenrui Hao, and Jinchao
Xu.
• Extended Regularized Dual Averaging Methods for Stochastic Optimization. Journal of Com-
putational Mathematics 41(3):525-541, 2023. With Jinchao Xu.
• Sharp Bounds on the Approximation Rates, Metric Entropy, and n-widths of Shallow Neural
Networks. Foundations of Computational Mathematics 1-57, 2022. With Jinchao Xu.
• Characterization of the Variation Spaces Corresponding to Shallow Neural Networks. Construc-
tive Approximation 1-24, 2023. With Jinchao Xu.
• Uniform Approximation Rates and Metric Entropy of Shallow Neural Networks. Research in the

Mathematical Sciences 9.3:1-21, 2022. With Limin Ma and Jinchao Xu.
• Optimal Convergence Rates for the Orthogonal Greedy Algorithm. IEEE Transactions on In-
formation Theory 68.5:3354-3361, 2022. With Jinchao Xu.
• Extensible Structure-Informed Prediction of Formation Energy with Improved Accuracy and
Usability employing Neural Networks. Computational Materials Science 208:111254, 2021. With
Adam Krajewski, Zi-Kui Liu, and Jinchao Xu.
• High-Order Approximation Rates for Shallow Neural Networks with Cosine and ReLUk Acti-
vation Functions. Computational and Applied Harmonic Analysis 58:1-26, 2022. With Jinchao
Xu.
• Approximation rates for neural networks with general activation functions.
Neural Networks
128:313-321, 2020. With Jinchao Xu.
• Accuracy, Eﬃciency and Optimization of Signal Fragmentation. Multiscale Modeling and Simu-
lation 18(2):737–757, 2020. With Russel Caﬂisch and Hung Hsu Chou
• Accelerated Optimization with Orthogonality Constraints. Journal of Computational Mathemat-
ics 39(2):207–226, 2020.
• Compact Support of L1 Penalized Variational Problems. Communications in Mathematical Sci-
ences 15(6):1771-1790, 2017. With Omer Tekin.
After First Revision
• Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev Spaces. Submitted
to Journal of Machine Learning Research, 2023.
Preprint available at: https://arxiv.org/abs/2211.14400
Under Review
• Weighted variation spaces and approximation by shallow ReLU networks. Submitted to Applied
and Computational Harmonic Analysis, 2023. With Ronald DeVore, Robert Nowak and Rahul
Parhi
Preprint available at: https://arxiv.org/abs/2307.15772
• Optimal Approximation of Zonoids and Uniform Approximation by Shallow Neural Networks.
to be Submitted, 2023.
Preprint available at: https://arxiv.org/abs/2307.15285
• Sharp Convergence Rates for Matching Pursuit. Submitted to IEEE Transactions on Information
Theory, 2023. With Jason Klusowski
Preprint available at: https://arxiv.org/abs/2307.07679
• Achieving acceleration despite very noisy gradients. Submitted to NeurIPS, 2023. With Kanan
Gupta and Stephan Wojtowytsch
Preprint available at: https://arxiv.org/abs/2302.05515
• Entropy-based convergence rates of greedy algorithms. Submitted to Mathematical Models and
Methods in Applied Sciences, 2023. With Yuwen Li

Preprint available at: https://arxiv.org/abs/2304.13332
• Sharp Lower Bounds on Interpolation by Deep ReLU Neural Networks at Irregularly Spaced
Data. Submitted to Machine Learning, 2023.
Preprint available at: https://arxiv.org/abs/2302.00834
• On the Activation Function Dependence of the Spectral Bias of Neural Networks. Submitted to
SIAM Journal on Scientiﬁc Computing, 2023. With Qingguo Hong, Qingyang Tan and Jinchao
Xu
Preprint available at: https://arxiv.org/abs/2208.04924
Preprints
• Training Sparse Neural Networks using Compressed Sensing, 2021. With Jianhong Chen, Pengchuan
Zhang and Jinchao Xu.
Preprint available at: https://arxiv.org/abs/2008.09661
• Accelerated First-Order Methods: Diﬀerential Equations and Lyapunov Functions, 2019.
Preprint available at: https://arxiv.org/abs/1903.05671
GRANTS
Penn State Institute for CyberScience Seed Grant (co-PI)
2018-2019
“Deep Learning for CALPHAD Database Development and Uncertainty Quantiﬁcation”
$35,000
NSF DMS-2111387 (co-PI)
2021-2024
“Comparative Study of Finite Element and Neural Networks Discretizations for Partial Diﬀerential
Equations”
$550,000
NSF DMS-2216799 (PI)
2022
“US Participation at the Twenty-sixth International Domain Decomposition Conference” $15,000
NSF CCF-2205004 (co-PI)
2022-2025
“CIF: Small: Interpretable Machine Learning based on Deep Neural Networks: A Source Coding
Perspective”
$600,000
TEACHING EXPERIENCE
Texas A&M University
Spring 2023
Instructor
College Station, TX
Math 667 - Foundations and Methods of Approximation (Graduate Course)
Texas A&M University
Fall 2022
Instructor
College Station, TX
Math 308H - Honors Diﬀerential Equations
Pennsylvania State University
Fall 2021
Instructor
University Park, PA

Math 141 - Integral Calculus
Pennsylvania State University
Spring 2021
Co-Instructor
University Park, PA
Math 555 - Optimization Theory (Graduate Course)
Pennsylvania State University
Fall 2020
Instructor
University Park, PA
Math 140 - Diﬀerential Calculus
Pennsylvania State University
Spring 2020
Instructor
University Park, PA
Math 251 - Diﬀerential Equations
Math 251H - Honors Diﬀerential Equations
Pennsylvania State University
Fall 2019
Instructor
University Park, PA
Math 141 - Integral Calculus
Pennsylvania State University/Peking University
Summer 2019
Co-Instructor
Beijing, China
Math 497 - Introduction to Deep Learning
Pennsylvania State University
Fall 2018
Instructor
University Park, PA
Math 141 - Integral Calculus
University of California, Los Angeles
2014-2017
Teaching Assistant
Los Angeles, CA
Math 32B - Integral Vector Calculus
Math 32A - Diﬀerential Vector Calculus
Math 110B - Finite Group Theory
INVITED SEMINAR AND CONFERENCE TALKS
Morgan State University
June 22, 2023
CBMS Conference on Deep Learning and Numerical PDEs
Texas A&M University
May 23, 2023
Inaugural CAMDA Conference
University of Texas at El Paso
February 17, 2023
Applied Mathematics Seminar
SUNY Albany
January 23, 2023

Data Science Seminar
Brown University
December 23, 2022
Crunch Seminar on Scientiﬁc Computing
Texas A&M University
December 8, 2022
TAMIDS Seminar
University of Oslo
December 1, 2022
Scientiﬁc and Machine Learning Seminar
King Abdullah University of Science and Technology (KAUST)
November 22, 2022
Mathematics and Computational Science Seminar
King Abdullah University of Science and Technology (KAUST)
November 15, 2022
Conference on Scientiﬁc Computing and Machine Learning
Texas State University
September 30, 2022
SyDATA Symposium
Texas A&M University
August 31, 2022
CAMDA Seminar
Czech Technical University in Prague
July 26, 2022
27th International Conference on Domain Decomposition Methods, Invited Plenary Talk
Princeton University
May 16, 2022
Wilks Seminar
Georgia Institute of Technology
April 4, 2022
Applied and Computational Mathematics (ACM) Seminar
Illinois Institute of Technology
January 21, 2022
Mathematics Department Colloquium
Texas A&M University
December 6, 2021
Mathematics Department Colloquium
University of South Carolina
November 29, 2021
Mathematics Department Colloquium
Rensselaer Polytechnic Institute
October 6, 2021
Mathematics in Imaging, Data and Optimization Seminar
RWTH Aachen
October 4, 2021

Applied Mathematics Group Lunch Seminar
ETH Zurich
June 2, 2021
FoMICS Seminar Talk and Lecture
University of Texas, Austin
May 21, 2021
Applied Mathematics Seminar
University of California, San Diego
May 11, 2021
CCoM Seminar
Purdue University
May 10, 2021
Mathematical Data Science Webinar
University of Notre Dame
April 15, 2021
ACMS Applied Mathematics Seminar
University of California, Irvine
March 15, 2021
Computational Mathematics Seminar
California Institute of Technology
February 17, 2021
CMX (Computational Mathematics) Seminar
Pennsylvania State University
December 15, 2020
CCMA Workshop on Mathematical Machine Learning and Applications
INVITED MINI-SYMPOSIUM TALKS
Foundations of Computational Mathematics Conference
June 19, 2023
Approximation Theory
Copper Mountain Conference on Multigrid Methods
April 17, 2023
Artiﬁcial intelligence and multilevel methods
SIAM Conference on the Mathematics of Data Science
September 27, 2022
Recent Advances in Machine Learning and Optimization
SIAM Conference on Uncertainty Quantiﬁcation
April 12, 2022
Recent Advances in Machine Learning and Data-Driven Methods for Physical Sciences and Engi-
neering
AMS Fall Western Sectional Meeting
October 23, 2021
Special Session on Theoretical and Applied perspectives in Machine Learning
SIAM Conference on Analysis of PDEs
March 16, 2021

Mathematics of Machine Learning Methods for PDEs
Kunming, China
August 15, 2019
International Multigrid Conference (IMG)
SERVICE
Students Co-Advised
• Jianhong Chen, Penn State Graduate Student, 2019-2020
• Xianlin Jin, Peking University Graduate student, 2021-present
• Kanan Gupta, Texas A&M University Graduate Student, 2022-present
Conferences Co-Organized
• CCMA Workshop on Mathematical Machine Learning and Applications, December 14-16, 2020.
Seminars Co-Organized
• Computational and Applied Mathematics (CAM) Colloquium at Penn State, Fall 2020-Fall 2021
Ad-Hoc Reviewer for
• Mathematical Programming, Neural Networks, AISTATS, Numerical Algorithms, Calculus of
Variations and Partial Diﬀerential Equations, Expert Systems with Applications, IEEE Transac-
tions on Neural Networks and Learning Systems, SIAM Journal on Optimization, SIAM Journal
on Numerical Analysis, SIAM Journal on Scientiﬁc Computing, SIAM Journal on Mathematics
of Data Science, Journal of Machine Learning Research
AWARDS AND SCHOLARSHIPS
University of California, Los Angeles
2018
• Paciﬁc Journal of Mathematics Dissertation Award
University of California, Los Angeles
2013-2014
• University of California Regents Fellow
University of California, Santa Cruz
2012
• Stephen M. Palais Award
University of California, Santa Cruz
2011
• Putnam Mathematical Competition Honorable Mention
AFFILIATIONS
American Mathematical Association (AMS)
2021-present
Society of Industrial and Applied Mathematicians (SIAM)
2021-present

INDUSTRY EXPERIENCE
Google Intern
June 6, 2016-August 26, 2016
Mountainview, CA
I worked with the Network Architecture team on improving the eﬃciency of a Monte Carlo network
reliability simulation. Speciﬁcally, I implemented importance sampling, which reduced the number
of samples required by a factor of 3.
Google Intern
June 12, 2017-September 1, 2017
Los Angeles, CA
I worked with the Budgetplanner Team (a division working on advertisement). I built a data pro-
cessing pipeline that collected and processed data which was scattered across multiple relational
databases to create training data for a machine learning model. Then I used TensorFlow to design
and test multiple machine learning models on the resulting dataset.
TECHNICAL STRENGTHS
Programming Skills: C/C++, Java, Matlab, Latex, Python

