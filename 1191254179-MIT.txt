The Bayesian Validation Metric: A Framework for
Probabilistic Model Calibration and Validation
by
Tony Tohme
Submitted to the Center for Computational Science and Engineering
in partial fulfillment of the requirements for the degree of
Master of Science in Computation for Design and Optimization
at the
MASSACHUSETTS INSTITUTE OF TECHNOLOGY
May 2020
c‚óãMassachusetts Institute of Technology 2020. All rights reserved.
Author . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Center for Computational Science and Engineering
May 20, 2020
Certified by. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Kamal Youcef-Toumi
Professor of Mechanical Engineering
Thesis Supervisor
Accepted by . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Youssef Marzouk
Associate Professor of Aeronautics and Astronautics
Co-Director, Center for Computational Science and Engineering

2

The Bayesian Validation Metric: A Framework for
Probabilistic Model Calibration and Validation
by
Tony Tohme
Submitted to the Center for Computational Science and Engineering
on May 20, 2020, in partial fulfillment of the
requirements for the degree of
Master of Science in Computation for Design and Optimization
Abstract
In model development, model calibration and validation play complementary roles
toward learning reliable models. In this thesis, we propose and develop the ‚ÄúBayesian
Validation Metric‚Äù (BVM) as a general model validation and testing tool. We show
that the BVM can represent all the standard validation metrics ‚Äì square error,
reliability, probability of agreement, frequentist, area, probability density comparison,
statistical hypothesis testing, and Bayesian model testing ‚Äì as special cases while
improving, generalizing and further quantifying their uncertainties. In addition, the
BVM assists users and analysts in designing and selecting their models by allowing
them to specify their own validation conditions and requirements. Further, we expand
the BVM framework to a general calibration and validation framework by inverting the
validation mathematics into a method for generalized Bayesian regression and model
learning. We perform Bayesian regression based on a user‚Äôs definition of model-data
agreement. This allows for model selection on any type of data distribution, unlike
Bayesian and standard regression techniques, that ‚Äúfail‚Äù in some cases. We show
that our tool is capable of representing and combining Bayesian regression, standard
regression, and likelihood-based calibration techniques in a single framework while
being able to generalize aspects of these methods. This tool also offers new insights
into the interpretation of the predictive envelopes in Bayesian regression, standard
regression, and likelihood-based methods while giving the analyst more control over
these envelopes.
Thesis Supervisor: Kamal Youcef-Toumi
Title: Professor of Mechanical Engineering
3

4

This thesis is dedicated to my family

6

Acknowledgments
This research was performed collaboratively with Dr. Kevin Vanslette under the
supervision of Professor Kamal Youcef-Toumi, and it was generously supported by the
Center for Complex Engineering Systems (CCES) at King Abdulaziz City for Science
and Technology (KACST) and the Massachusetts Institute of Technology (MIT).
I would like to express my sincere gratitude and deep appreciation to Kamal for
believing in me and inspiring me. His guidance and support have been invaluable
throughout this research.
Much credit for the work in this thesis goes to my fantastic friend, collaborator,
and mentor Kevin. His motivation and encouragement have been the driving force
behind this research. I honestly owe him tremendously.
I am highly indebted to Associate Provost Philip Khoury whose inspiration and
support made my journey at MIT superb and fruitful.
I was very fortunate to take a course with Professor Gilbert Strang. I am genuinely
blessed to have worked with him.
Many thanks to Professor Youssef Marzouk, Professor Nicolas Hadjiconstantinou,
and Kate Nelson for being behind the success of the Center for Computational Science
and Engineering (CCSE).
I am profoundly grateful to Tariq, Kathy, and my friends for being there for me
and celebrating with me every success.
Finally, words will never be enough to express my gratitude and love to my parents,
Mike and Nicole, my girlfriend Maria, my uncles, Georges and Ziad, my aunts, Simone,
Mona and Arlette, my granduncle Emile, and my grandparents, Salma, Yvette and
Pierre, for their endless support, encouragement, sacrifices and love; this thesis is
dedicated to them. Lastly, yet most importantly, I would like to thank God who has
given me the insight, strength, and perseverance to complete this work.
7

8

A Note on the Content
This thesis contains material which I authored or co-authored [58, 62].
Chapter 2 of this thesis is based on the following previous publication:
[62] Kevin Vanslette, Tony Tohme, and Kamal Youcef-Toumi. A general model
validation and testing tool. Reliability Engineering & System Safety, 195,
March 2020.
Chapter 3 of this thesis is based on the following manuscript:
[58] Tony Tohme, Kevin Vanslette, and Kamal Youcef-Toumi. Generalized bayesian
regression and model learning. arXiv preprint arXiv:1911.11715, 2019.
Chapter 1 and Chapter 4 contain material from both papers [58, 62].
9

10

Contents
1
Introduction
21
1.1
Introduction and Overview . . . . . . . . . . . . . . . . . . . . . . . .
21
1.2
Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
1.3
Objectives and Contributions
. . . . . . . . . . . . . . . . . . . . . .
25
1.4
Thesis Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
2
The Bayesian Validation Metric
29
2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
2.2
Notation and Overview . . . . . . . . . . . . . . . . . . . . . . . . . .
29
2.3
Formulation of the BVM . . . . . . . . . . . . . . . . . . . . . . . . .
31
2.3.1
Derivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
2.3.2
An Identical Representation . . . . . . . . . . . . . . . . . . .
33
2.3.3
Importance and Statistical Responsibility . . . . . . . . . . . .
33
2.4
Meeting the Desirable Validation Criterion . . . . . . . . . . . . . . .
34
2.4.1
Compound Booleans . . . . . . . . . . . . . . . . . . . . . . .
35
2.4.2
The BVM Under the Conditions of Exact Agreement . . . . .
35
2.4.3
Meeting Underrepresented Validation Criteria . . . . . . . . .
37
2.5
Representing and Generalizing the Known Validation Metrics with the
BVM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
2.5.1
Representing the Known Validation Metrics
. . . . . . . . . .
39
2.5.2
Generalizing the Known Validation Metrics . . . . . . . . . . .
42
2.6
BVM Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
2.6.1
The Statistical Power BVM
. . . . . . . . . . . . . . . . . . .
46
2.6.2
The
(Ô∏Ä
‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä
BVM . . . . . . . . . . . . . . . . . . . . . . . .
47
11

2.6.3
Exploring the BVM Ratio with the (ùõæ, ùúñ) BVM
. . . . . . . .
50
2.7
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
3
Generalized Bayesian Regression and Model Learning
57
3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
57
3.2
Background and Motivation . . . . . . . . . . . . . . . . . . . . . . .
57
3.2.1
Standard Regression
. . . . . . . . . . . . . . . . . . . . . . .
58
3.2.2
Likelihood-Based Methods . . . . . . . . . . . . . . . . . . . .
59
3.2.3
Bayesian Regression and Model Testing . . . . . . . . . . . . .
59
3.2.4
BVM Model Testing
. . . . . . . . . . . . . . . . . . . . . . .
63
3.2.5
The Improved Reliability Metric . . . . . . . . . . . . . . . . .
64
3.3
Generalized Bayesian Regression via the BVM . . . . . . . . . . . . .
65
3.4
Implementation and Examples . . . . . . . . . . . . . . . . . . . . . .
69
3.4.1
Computing the BVM Evidence
. . . . . . . . . . . . . . . . .
69
3.4.2
BVM Regression Examples . . . . . . . . . . . . . . . . . . . .
70
3.4.3
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
3.5
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
78
4
Conclusions and Recommendations
79
4.1
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
79
4.2
Recommendations . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
A Representing the Known Validation Metrics with the BVM
81
A.1 Reliability Metric and Probability of Agreement . . . . . . . . . . . .
81
A.2 Frequentist Validation Metric
. . . . . . . . . . . . . . . . . . . . . .
83
A.3 Area and Binned Probability Difference Metric . . . . . . . . . . . . .
84
A.4 Probability Density Function Comparison Metrics . . . . . . . . . . .
87
A.5 Statistical Hypothesis Testing . . . . . . . . . . . . . . . . . . . . . .
88
A.6 Bayesian Model Testing
. . . . . . . . . . . . . . . . . . . . . . . . .
92
B Likelihood-Based Methods
97
12

C Bayesian Model Testing
99
C.1 Normally Distributed Data . . . . . . . . . . . . . . . . . . . . . . . .
100
C.2 Uniformly Distributed Data . . . . . . . . . . . . . . . . . . . . . . .
101
C.3 Completely Certain Data . . . . . . . . . . . . . . . . . . . . . . . . .
102
D BVM Model Selection
103
D.1 Normally Distributed Data . . . . . . . . . . . . . . . . . . . . . . . .
104
D.2 Uniformly Distributed Data . . . . . . . . . . . . . . . . . . . . . . .
106
D.3 Completely Certain Data . . . . . . . . . . . . . . . . . . . . . . . . .
107
13

14

List of Figures
1-1
Illustrative example of theoretical success and failure cases of Bayesian
regression. In blue is a deterministic linear model (ùë¶= ùëéùë•+ ùëè) and in red
are the data probability distributions that may come from epistemic and/or
aleatoric uncertainty.
. . . . . . . . . . . . . . . . . . . . . . . . . . .
26
2-1
A common model validation scenario. The model line is trained on
noisy data (not depicted in the figure) and is to be compared to a set of
validation data.
As both the model line and the data are uncertain in
general, any quantitative measure (i.e. the comparison function) between
these comparison values inherits this uncertainty. Thus, any accept/reject
rule on the basis of these uncertain comparison function values is uncertain
as well. A visual inspection of this graph seems to indicate, up to statistical
fluctuation, that the comparison values of the model and data more or less (or
probably) agree, but this intuitive measure has yet to be quantified. Graphic
adapted from [44].
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
15

2-2
Comparison between statistical hypothesis testing and statistical
power BVM. (a) The shaded regions in Column A depict the 95% confidence
interval of each distribution, respectively. Because the data distribution is the
same in each figure and because the statistical hypothesis test is independent
of the proposed model due to assuming the hypothesis ùëÄ= ùê∑, each model
is equally valid by that test when it is clear that the model in row 2 is
preferable. (b) The shaded regions in Column B depict the statistical power
of the distributions ‚Äì the 95% confidence intervals from each distribution is
shaded (integrated) in the other‚Äôs pdf. The statistical power BVM (denoted
ùëÉ(ùê¥) in column B) is calculated for each model and indeed the model in row
2 is found to be preferable as it has the highest probability of agreement. .
47
2-3
Validating a deterministic model and an uncertain model accord-
ing to two Boolean agreement functions. (a) The deterministic model
satisfies the ‚ü®ùúñ‚ü©Boolean but fails to pass the
(Ô∏Ä
‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä
requirement given that
its 95% confidence interval has a width of zero. (b) The uncertain model
satisfies both the ‚ü®ùúñ‚ü©and
(Ô∏Ä
‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä
agreement requirements given that its 95%
confidence region has a nonzero width and represents better the uncertain
data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
2-4
Completely Certain Case: The BVM probability of agreement be-
tween each of the models and data plotted in the (ùõæ, ùúñ) space. Be-
cause here the models are deterministic, the BVM probability of agreement
for each (ùõæ, ùúñ) pair is either zero or one. (a) The results for model 1 (4th
order polynomial). (b) The results for model 2 (6th order polynomial). As
expected, model 2 better fits the data in the (ùõæ, ùúñ) space as it has more
BVM values equal to one than model 1, since it is overall closer to the
cosine function being the next nonzero order polynomial in the Taylor series
expansion. Neither model fits the data exactly as the BVM for both models
at (ùõæ= 100%, ùúñ= 0) is zero. . . . . . . . . . . . . . . . . . . . . . . . .
53
16

2-5
Uncertain Case: The BVM probability of agreement between each
of the models and the data plotted in the (ùõæ, ùúñ) space. Because the
model paths are uncertain, the BVM probability of agreement for each (ùõæ, ùúñ)
pair may take any value from zero to one. (a) The results for model 1 (4th
order polynomial). (b) The results for model 2 (6th order polynomial). As
expected, model 2 better fits the data in the (ùõæ, ùúñ) space as it has generally
larger BVM values than model 1; however, the BVM values are about equal in
cases of large values of ùúñand low values of ùõæ(since the definition of agreement
is less stringent and they both ‚Äúagree‚Äù) and in the case of demanding absolute
equality (ùúñ= 0) as neither model fits the data exactly. . . . . . . . . . . .
54
2-6
The BVM ratios for the uncertain models plotted in the (ùõæ, ùúñ) space.
Model 2 is generally favored over model 1 as there exist no values greater
than one on the plot. The amount the BVM ratio favors model 2 over model
1 decreases (i.e. the ratio increases and tends to one) as the metric becomes
less and less stringent (i.e. as ùõædecreases and ùúñincreases). The ùúñ= 0 line
was removed because neither model agrees with the data exactly. . . . . .
55
3-1
Truncated tail data distributions solution. Using BVM regression re-
sults in a nonzero probability of finding a model given the observed truncated
data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
3-2
Predictive envelopes of the model in the absence of data uncer-
tainty using the BVM. As tabulated in Table 3.3, Bayesian regression
fails to produce a candidate model solution as the data is completely certain
and standard regression produces a single deterministic solution with no
model uncertainty. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
17

3-3
Illustration of BVM Learning for the Monod model for decreasing
values of ùúñ. In the first row is the prior/posterior parameter distribution
in (ùõº1, ùõº2) space. The data points are shown by a blue circle in the second
row. The first column corresponds to the situation before any data point is
observed and shows a plot of the prior distribution in (ùõº1, ùõº2) space together
with six samples of the model response ùëÄ(ùë•; ‚Éóùõº) (red lines) in which the
values of ùõº1 and ùõº2 are randomly drawn from the prior. In the second, third
and fourth columns, we see the situation after running our BVM learning
using MCMC, with a tolerance ùúñ= 0.03, ùúñ= 0.025 and ùúñ= 0.02, respectively.
The posterior has now been influenced by the agreement tolerance ùúñ, this
gives a relatively compact posterior distribution. Samples from this posterior
distribution lead to the functions shown in red in the second row.
. . . .
73
3-4
Comparison between Bayesian regression and BVM regression. (a)
Bayesian regression under infinite tail data distribution. Note that the 95%
confidence interval is very narrow and standard regression method produces
a nearly identical result. (b) BVM regression using the compound Boolean.
In this case, the 95% confidence region is much wider and represents the data
more accurately. Note that this probabilistic model passes both agreement
conditions imposed by the compound Boolean ùêµ( ^ùëå, ùëå, ‚ü®ùúñ‚ü©, ^ùõº). Starting with
a very small ‚ü®ùúñ‚ü©in the MCMC simulation, we tune ‚ü®ùúñ‚ü©by gradually increasing
its value until both elements of the compound Boolean are naturally satisfied.
76
18

List of Tables
2.1
Specification of the four BVM inputs that give the other validation metrics
as special cases.
The column headings are the four BVM input values:
Comparison Values (^^ùëß, ùëß), Probabilities (ùúå(^ùëß|ùëÄ, ùê∑), ùúå(ùëß|ùê∑)), Comparison
Function ùëì= ùëì(^ùëß, ùëß), and the Boolean Agreement Function ùêµ(ùëì). The
row headings read: Reliability, Improved Reliability, Frequentist, Area, Pdf
Comparison Metrics, Statistical Hypothesis Testing, and Bayesian Model
Testing. The denoted data probability for the average in the frequentist
metric, Stud. ùë°, is the Student‚Äôs ùë°-distribution. . . . . . . . . . . . . . . .
40
2.2
BVM representation of the other validation metrics as special cases using
the comparison functions (the ùëì‚Äôs) specified in Table 2.1.
. . . . . . . . .
41
3.1
Some examples of agreement Boolean functions. . . . . . . . . . . . . . .
67
3.2
The observations we aim to fit. . . . . . . . . . . . . . . . . . . . . . . .
70
3.3
High probability of the model producing posterior parameter distributions and
predictive envelopes for different types of data distributions using the three
approaches. BVM regression is capable of producing posterior distributions
of the model parameters for any type of data distributions.
. . . . . . . .
71
19

20

Chapter 1
Introduction
1.1
Introduction and Overview
Engineering systems are often represented and described by computational models in
order to make predictions about the behavior of the system. Often, models possess
parameters that cannot be directly measured, and instead they are inferred based
on experimental data of relevant inputs and outputs, in a process known as model
calibration [22, 36, 60, 65]. Model calibration is the process of estimating and adjusting
model parameters to obtain a model representation of the system (or data) of interest
while satisfying a specific criterion (objective function). Once the parameters are
inferred, the designed model is tested with respect to real data-generating process, in
a task known as model validation [39, 55, 60].
In model development, model calibration comes in the stage prior to the validation
stage [52], and it usually consists of estimating model parameters given a set of
observed input-output data. Then, validation is performed on a different independent
data set called the validation data set. In what follows, we will use the terms ‚Äúmodel
calibration‚Äù, ‚Äúmodel learning‚Äù and ‚Äúregression‚Äù interchangeably.
We are interested in studying the calibration and validation of multivariate com-
putational models that represent uncertain situations and observations (or data). It is
understood that complete certainty is a special case of uncertainty as both may be
represented with probability distributions.
21

The uncertainty in a model or data set may originate from stochasticity, model
parameter and input data uncertainty, measurement uncertainty, or other possible
aleatoric or epistemic sources of uncertainty. Each of the following data modeling
schemes may include quantifiable amounts of uncertainty (or certainty) that we would
like to calibrate and then validate on the basis of a set of calibration and validation data:
neural networks and AI models, machine learning models, Gaussian Process Regression
models [18], polynomial chaos and other surrogate models [1, 7, 15, 21], spatial and
time series stochastic models, physics based models (usually solutions to differential
equations), engineering based models (which are sufficiently abstracted physics based
models), Monte Carlo simulation models [16, 35], and more. Model output uncertainties
may be quantified through uncertainty propagation techniques (that may or may not
include verification, calibration, and validation) [1, 7, 15, 18, 25, 31, 41, 49, 50, 52, 56].
1.2
Related Work
Model calibration techniques have been widely studied in the literature. Least squares
(or standard regression) [64], likelihood-based [9, 43], and Bayesian regression methods
[23, 24, 32, 40, 63] are often used for model parameter estimation. Nonprobabilistic
methods, such as parametric model regression, nonparametric neural networks, and
support vector machines (SVM) [4] are able to tackle these types of problems efficiently.
In Bayesian probability theory [29, 30, 53], Bayesian model testing and maximum
likelihood methods provide probabilistic features (i.e. mean, covariance, distribution)
for the parameters we aim to estimate, based on prior knowledge (i.e. prior distribution)
and the uncertainty of the data. Bayesian model testing, which uses Bayesian parameter
regression, was shown to be successful for signal detection, light sensor characterization
[20], exoplanet detection [46], extra-solar planet detection [45], laser peening process
[40], time series [59], astronomical data analyses [10], and cosmology and particle
physics [11].
Model validation techniques have also been extensively studied in the literature.
There exist several validation metrics. Each metric is designed to compare features of
22

a model-data pair to quantify validation: square error compares the difference in the
data and model values in a point to point or interval fashion [63], the reliability metric
[47] and the probability of agreement [57] compare continuous model outputs and data
expectation values (the model reliability metric was extended past expectation values
in [51]), the frequentist validation metric [38] and statistical hypothesis testing compare
data and model test statistics, the area metric compares the cumulative distribution of
the model to the estimated cumulative distribution of the data [12, 26, 27, 49, 65, 67],
probability density function (pdf) comparison metrics (such as the KL Divergence)
measure and represent ‚Äúcloseness‚Äù between pdfs, and Bayesian model testing compares
the posterior probability that each model would correctly output the observed data
[13, 14, 31, 45, 50, 53, 66]. A detailed review of the majority of these metrics may
be found in [22, 28, 34, 36] and the references therein. In particular, [34] is an up to
date review that considers many validation metrics in the cases of data and model
certainty, data uncertainty and model certainty, and data and model uncertainty.
To assist the comparison of the positive and negative aspects of the above validation
metrics, reference [28] outlines six ‚Äúdesirable validation criteria‚Äù that a validation
metric might have (they extend [12, 38]). One conclusion from [28] is that none of
the available metrics simultaneously satisfy all six desirable validation criteria. We
summarize the most important features of the desirable validation criteria with the
following validation criterion:
1. A validation metric should be a statistically quantified quantitative measure (as
opposed to a qualitative measure) of the agreement between (general) model
predictions and data pairs, in the presence or absence of uncertainty.
The desire for objectivity, ‚Äúthat a metric will produce the same assessment for every
analyst independent of their individual preferences‚Äù [28], is difficult to satisfy because
there are no rules in place to guide a modeler toward selecting one validation metric
over another. For this reason, the individual might simply choose a metric based on
their preferences, or worse, be tempted to base their decision on which validation
metric gives them the most favorable evaluation.
Given individuals may choose
23

different validation metrics for the same model-data pair, it is possible for individuals
to impose accuracy requirements that are incompatible with one another and arrive at
different conclusions regarding the validity of the same model-data pair. As the final
goal is objectivity, when possible, a map between the accuracy requirements should
be constructed such that the validation metrics yield consistent evaluations of the
model-data validity when applicable.
Further, Liu et al. [28] suggest that there is no agreed upon unified model-data
comparison function. Even including the results of this thesis, we expect this statement
to hold as it is extremely difficult to guess the prior information about the utility
of a model an analyst may be required to include in the validation of a model-data
pair. For instance, given arbitrary data, ‚ÄúWhat features of the data are relevant to
capture with a model?‚Äù, ‚ÄúOf these features, are some more relevant than others?‚Äù, and
‚ÄúWhat accuracy is required for the model to be valid?‚Äù. Agreement and validation
are ultimately human-made concepts designed for the purpose of expressing that ‚Äúin
general, not every feature or statistic between a model-data pair need to be equal
to conserve the utility of the model‚Äù. For some model-data pairs, all that may be
required is that the model and data averages closely match within uncertainty, while
for others, one may require that the model can accurately reproduce the probability
distribution of a data set as a whole (as one would do to physically model a noisy
measurement device). Given the wide variety of data and the large number of different
inferences (and thus models and hypotheses) that one may be interested in drawing
from a given data source (i.e. the context of the model-data pair), we do not expect
any single set of comparison functions, statistics, or values to be equally relevant and
maximally useful for all possible model-data contexts. This, however, does not stop
us from quantifying the validity of a model-data pair given any arbitrary comparison
function and with any arbitrary definition of agreement.
24

1.3
Objectives and Contributions
In this thesis, we propose and construct the ‚ÄúBayesian Validation Metric‚Äù (BVM) as a
general model validation and testing tool. We design the BVM to adhere to the desired
validation criterion (1.) by using ‚Äúfour BVM inputs‚Äù: the model and data comparison
values, the model output and data pdfs, the comparison value function, and the
agreement function. The comparison value function is a function of model output and
data comparison values that provides the desired quantitative comparison measure,
e.g. square difference. Using the model output pdf and the data pdf, the value of the
comparison value function is statistically quantified. In turn, the agreement function
provides an accept/reject rule and effectively wraps the previous three BVM inputs
together to give the BVM. From this, the BVM outputs ‚Äúthe probability the model
and data agree‚Äù, where agreement is a user-defined Boolean function that meets, or
does not meet, accuracy requirements between model and data comparison values.
Thus, the BVM meets the desired validation criterion (1.) for arbitrary comparison
value functions, arbitrary definitions of agreement, and in principle for arbitrary data
types such as integers, vectors, tensors, strings, pictures, or others.
The BVM can be used to represent all of the aforementioned validation metrics as
special cases. We find the conditions under which several of the current validation
metrics are effectively equal to one another, which improves the objectivity of the
current validation procedure. In brief we find that the frequentist metric (using natural
definitions of agreement) is equal to the reliability metric and the probabilities from
Bayesian model testing are equal to the probabilities of the improved model reliability
metric [51] when one demands exact equality of the (uncertain) model-data comparison
values. Because probability can represent both certain and uncertain situations, so
can the BVM. Thus, these ‚Äúspecial case‚Äù metrics can be generalized to quantify certain
or uncertain cases, and even be combined into more complex validation requirements
using the BVM framework. Thus, the BVM provides a standardized framework to
improve, generalize, or further quantify these validation metrics.
By constructing the ‚ÄúBVM ratio‚Äù, we generalize the Bayesian model testing frame-
25

work [53], in which one constructs the Bayes ratio to rank models according to the
ratio of their posterior probabilities given the data. We show that these posterior
probabilities are equal to a special case of the BVM under the definition of agreement
that requires these uncertain model outputs and data to match exactly. Thus, nothing
prevents us from extending the logic used in the Bayesian model testing framework to
our framework and we construct the BVM ratio for the purpose of model selection
under arbitrary definitions of agreement, i.e. for arbitrary validation scenarios.
Moving to Bayesian calibration techniques, we believe that the efficacy of para-
metric Bayesian regression, likelihood-based methods, and standard regression can be
improved. Bayesian regression calculates the Bayesian evidence, which is the proba-
bility the model could have produced the observed, usually over noisy or uncertain,
data. If this probability is nonzero, one can proceed to calculate posterior model
parameter probabilities using Bayes‚Äô Theorem. In practice, there are models and
parameters that may be of interest to the user that Bayesian regression fails to regress
and produce posterior parameter distributions ‚Äì Figure 1-1. For some of the instances
that Bayesian regression fails to provide a solution, standard regression may actually
succeed, but usually with some measure of expected error. How this error can translate
into parameter and model uncertainty in the presence of certain or uncertain data is
a problem that is largely omitted in the literature except for a few analytic cases.
(a) Bayesian regression works.
(b) Bayesian regression fails.
Figure 1-1: Illustrative example of theoretical success and failure cases
of Bayesian regression. In blue is a deterministic linear model (ùë¶= ùëéùë•+ ùëè)
and in red are the data probability distributions that may come from epistemic
and/or aleatoric uncertainty.
26

Figure 1-1a shows normally distributed data (infinite tails data distribution). In
this case, parametric Bayesian regression finds a linear model that sits in low probability
regions of the data. Figure 1-1b shows uniformly distributed data (truncated data
distribution). In this case, Bayesian regression cannot find a linear model solution
because no linear model can pass through each data distribution simultaneously ‚Äì
the model given the data is regarded as impossible. Standard regression methods
can provide linear model solutions here despite the model lying in a zero probability
region of the data. Although this solution may be considered ‚Äúwrong‚Äù because it is
not supported by the data, it successfully provides useful information to the modeler
(an increasing trend). The fact that, for the same model, the solution given by
the calibration method can differ from method to method supports the search for a
framework for their joint representation so they may be compared more concretely.
In this thesis, we represent least squares, likelihood-based, and Bayesian regression
(or calibration) methods by expanding the general validation framework (BVM) into
a general calibration and validation framework. Our method uses the BVM to guide
the regression of a model in a flexible way. Several of our examples use generalizations
of the improved reliability metric and thus reliability is automatically regressed into
our model solutions. Our method gives us better control over the predictive envelopes
of the model under question, which can be used to improve model reliability and
safety. By learning model parameters with the BVM, we are able to estimate and
construct model parameters distributions for any type of data distribution (Gaussian,
Uniform, Completely Certain), which addresses the concerns raised in Figure 1-1. This
construction gives us additional insight into the meaning of the predictive envelopes
of Bayesian regression methods.
We have found that a subset of our method shares mathematical features with Ap-
proximate Bayesian Computation (ABC) methods, which are also known as likelihood-
free techniques [2, 33]. ABC methods are used strictly as an approximation method
for nearly computationally intractable likelihoods in Bayesian regression. While our
method gains this feature in some cases, our method‚Äôs intention is not to approximate
Bayesian regression, but instead to generalize it for the purpose of robust and flexible
27

model calibration.
Our method is able to regress models over a multitude of different data distributions
by using likelihoods that are modified by user‚Äôs choice of a useful definition of agreement
between the data and the model ‚Äì leaning on the BVM formalism. This ‚Äúchoice‚Äù allows
the user to program safety requirements into the model learning process if they
desire. The nature of the BVM formalism forces one to express the model and data
assumptions explicitly and thus our method leads to improved model transparency
and safety. In our examples we show how such a procedure leads to a model that
better represents the uncertain data at hand than Bayesian and standard regression
techniques. This naturally improves the model‚Äôs reliability and safety in the presence
of uncertain data.
1.4
Thesis Outline
The remainder of the thesis is organized as follows. In Chapter 2, we derive and
construct the BVM by following our validation criterion. Through some edge cases,
we show that the BVM satisfies both the six desirable validation criteria from [28]
as well as our validation criterion (1.). We also summarize the results derived in
Appendix A, where we incorporate all of the above standard validation metrics as
special cases of the BVM, draw relationships between several of the validation metrics,
provide improvements and generalizations to these metrics as is suggested by the
functional form of the BVM, and construct the BVM ratio. We end the chapter by
representing three novel validation metrics using the BVM and comparing them to
similar metrics from the literature. We then move to Chapter 3, where we employ
the BVM framework to generalize Bayesian regression. This generalized Bayesian
regression method, namely the BVM model learning technique, works for different
types of data distributions and for arbitrary definitions of model-data agreement.
We then present a simulation application using the BVM model learning technique
on a nonlinear heuristic model, along with a compound Boolean agreement function
example. Chapter 4 is left for conclusions and recommendations.
28

Chapter 2
The Bayesian Validation Metric
2.1
Introduction
In this chapter, we introduce and develop the Bayesian Validation Metric (BVM) which
is a general model validation and testing tool [62]. We find the BVM to be capable of
representing all of the well-known validation metrics as special cases, while improving,
generalizing and further quantifying their uncertainties. The BVM has the capacity to
allow users to invent and select models according to novel validation requirements. We
formulate and test a few novel compound validation metrics that improve upon other
validation metrics in the literature. In addition, we propose and construct the BVM
Ratio for the purpose of quantifying model selection under user-specified definitions
of model-data agreement in the presence or absence of uncertainty. This construction
generalizes the Bayesian model testing framework.
2.2
Notation and Overview
For the remainder of the thesis, we will use the following notation and language. We will
let ^ùë¶denote the output of a model, ^ùëå= {^ùë¶1, ..., ^ùë¶ùëõ} a set of ùëõmodel outputs, ùë¶a data
point (or observed data), and ùëå= {ùë¶1, ..., ùë¶ùëõ} a set of ùëõdata points. The proposition
ùëÄessentially stands for ‚Äúthe model‚Äù or ‚Äúcoming from the model‚Äù, i.e. ^ùë¶= ùëÄ(ùë•; ‚Éóùõº),
where ùë•is the input and ‚Éóùõº= (ùõº1, . . . , ùõºùëö) represents a vector of ùëömodel parameters.
29

The proposition ùê∑stands for ‚Äúthe experiment‚Äù or ‚Äúcoming from the experiment‚Äù. We
let ^ùëßand ùëßrepresent the comparison quantities of interest, which pertain to the model
and the data respectively. Further, we let the comparison quantities take general
forms, such as multidimensional vectors, functions, or functionals (e.g. output values,
expectation values, pdfs, ...), so we can represent any such pair of quantities we
may wish to compare between the model and the data. When we refer to ‚Äúthe four
BVM inputs‚Äù we mean: the comparison values (^ùëß, ùëß), the model output and data
pdf ùúå(^ùëß, ùëß|ùëÄ, ùê∑), the comparison value function ùëì(^ùëß, ùëß), and the agreement function
ùêµ= ùêµ(ùëì(^ùëß, ùëß)). The (denoted) integrals may be integrals or sums depending on the
nature of the variable being summed or integrated over, which is to be understood from
the discrete or continuous context of the inference at hand. The dot ‚Äú ¬∑ ‚Äù represents
standard multiplication, which is mainly used to improve aesthetics. Finally, we let ùê¥
denote the agreement between the model output and the observed data.
Figure 2-1: A common model validation scenario.
The model line is
trained on noisy data (not depicted in the figure) and is to be compared to a
set of validation data. As both the model line and the data are uncertain in
general, any quantitative measure (i.e. the comparison function) between these
comparison values inherits this uncertainty. Thus, any accept/reject rule on the
basis of these uncertain comparison function values is uncertain as well. A visual
inspection of this graph seems to indicate, up to statistical fluctuation, that the
comparison values of the model and data more or less (or probably) agree, but
this intuitive measure has yet to be quantified. Graphic adapted from [44].
30

Performing uncertainty propagation through a model results in a model output
probability (density) distribution ùúå(^ùë¶|ùëÄ, ùê∑) that ultimately we would like to validate
by comparing it to an uncertain validation data source ùúå(ùë¶|ùê∑), to see if they agree
(as depicted in Figure 2-1). The immediate question is, however, ‚ÄúWhat values do
we want to compare and what do we mean by agree?‚Äù. Given the wide variety of
data and the large number of different inferences (and thus models and hypotheses)
that one may be interested in drawing from a given data source (i.e. the context
of the model-data pair), we do not expect any single set of comparison functions to
be equally relevant and maximally useful for all possible model-data contexts. In
light of this, we instead quantify the validity of a model-data pair given any arbitrary
comparison value function and according to any arbitrary definition of agreement.
2.3
Formulation of the BVM
In this section, we construct the Bayesian Validation Metric (BVM), we show its
different representations, and we discuss its importance and statistical responsibility.
2.3.1
Derivation
Here we start constructing the Bayesian Validation Metric (BVM). To capture the
concept of what we might mean by agree, we define ^ùëßand ùëßto agree, ùê¥, when the
Boolean expression, ùêµ, is true. Both ùê¥and ùêµare defined by the modeler and their
prior knowledge of the context of the model-data pair. Naturally then, the agreement
function ùêµ= ùêµ
(Ô∏Ä
ùëì(^ùëß, ùëß)
)Ô∏Ä
= ùêµ(^ùëß, ùëß) is some function or functional of a comparison
value function ùëì(^ùëß, ùëß).
Given the values of ^ùëßand ùëßare known, i.e. certain, we quantify agreement using a
probability distribution that assigns certainty,
ùëù(ùê¥|^ùëß, ùëÄ, ùëß, ùê∑) = Œò
(Ô∏Ä
ùêµ(^ùëß, ùëß)
)Ô∏Ä
.
(2.1)
The indicator function Œò
(Ô∏Ä
ùêµ
)Ô∏Ä
is defined to equal unity if ùêµevaluates to ‚Äútrue‚Äù (i.e.
31

‚Äúagreeing‚Äù) and equal to zero otherwise. Thus, in the completely certain case, we are
certain as to whether the model and data comparison values agree or do not agree, as
defined by ùêµand the deterministic evaluation of ùëì(^ùëß, ùëß).1 We will call ùëù(ùê¥|^ùëß, ùëÄ, ùëß, ùê∑)
the ‚Äúagreement kernel‚Äù.
Given that in general the comparison values are uncertain, and quantified by
ùúå(^ùëß, ùëß|ùëÄ, ùê∑), the probability the comparison values agree, as defined by ùêµand ùëì(^ùëß, ùëß),
is equal to,
ùëù(ùê¥|ùëÄ, ùê∑)
=
‚à´Ô∏Å
^ùëß,ùëß
ùëù(ùê¥|^ùëß, ùëÄ, ùëß, ùê∑) ¬∑ ùúå(^ùëß, ùëß|ùëÄ, ùê∑) ùëë^ùëßùëëùëß,
(2.2)
ùëñùëõùëë.
‚àí‚Üí
‚à´Ô∏Å
^ùëß,ùëß
ùúå(^ùëß|ùëÄ, ùê∑) ¬∑ Œò
(Ô∏Ä
ùêµ(^ùëß, ùëß)
)Ô∏Ä
¬∑ ùúå(ùëß|ùê∑) ùëë^ùëßùëëùëß,
(2.3)
which is a marginalization over the spaces of (^ùëß, ùëß).2 Equation (2.2) is the general
form of the Bayesian Validation Metric (BVM). Because ùê¥is discrete, the BVM is
a probability rather than a probability density and it therefore falls in the range
0 ‚â§ùëù(ùê¥|ùëÄ, ùê∑) ‚â§1. Equation (2.3) explicitly assumes that the uncertainty in the
data is independent of the model, i.e. ùúå(ùëß|ùëÄ, ^ùëß, ùê∑) = ùúå(ùëß|ùê∑), that the data ùê∑does
not take ^ùëßor the model ùëÄ(that it is currently being compared to) as inputs.3 This
is a relatively common scenario so it is stated explicitly. The BVM may be computed
using any of the well-known computational integration methods.
1This binary yet probabilistic definition of agreement turns out to be completely satisfactory for
our current purposes. As is briefly discussed later, the sharp boundaries of the indicator function can
be smoothed out without employing fuzzy logic by allowing parameters in the Boolean function to
themselves be uncertain and marginalized over.
2 Recall that the propositions in the probability distributions ùúå(ùëß|ùê∑) and ùúå(^ùëß|ùëÄ, ùê∑) are completely
arbitrary (in some cases requiring propagation from ùúå(ùë¶|ùê∑) and ùúå(^ùë¶|ùëÄ, ùê∑)), they could be both
continuous, discrete (with order), categorical variables (no well defined order, e.g. strings, pictures,...),
or a mix.
3In a controls system this may not be the case, as the model may interact with the system of
interest. In such a case this constraint may be lifted and one should use (2.2) instead. The joint
probability ùúå(^ùëß, ùëß|ùëÄ, ùê∑) can be used to account for the correlations between the model (the controller
or reference) and the data (the measured response of the system being controlled) in a controls
setting in principle.
32

2.3.2
An Identical Representation
In some cases, it is useful to work directly with the probability density ùúå(ùëì|ùëÄ, ùê∑),
which quantifies the probability the comparison value function ùëì(^ùëß, ùëß) takes the value ùëì
due to uncertainty in its inputs. This pdf is independent of any user-defined accuracy
requirement. We will call this pdf the comparison value probability density, which is
equal to,
ùúå(ùëì|ùëÄ, ùê∑) =
‚à´Ô∏Å
^ùëß,ùëß
ùõø(ùëì‚àíùëì(^ùëß, ùëß)) ¬∑ ùúå(^ùëß, ùëß|ùëÄ, ùê∑) ùëë^ùëßùëëùëß.
(2.4)
This is the net uncertainty propagated through the comparison value function ùëì(^ùëß, ùëß)
from the uncertain model and data comparison values. All of the expectation values
that are associated with ùëìmay be generated from this pdf.
If one imposes an accuracy requirement with a Boolean expression ùêµ= ùêµ(ùëì)
(i.e. defining agreement according to the value of ùëì), the resulting accumulated prob-
ability is the BVM. That is, the BVM, i.e. Equation (2.2), may equally be expressed as,
ùëù(ùê¥|ùëÄ, ùê∑) =
‚à´Ô∏Å
ùëì
ùúå(ùëì|ùëÄ, ùê∑) ¬∑ Œò
(Ô∏Ä
ùêµ(ùëì)
)Ô∏Ä
ùëëùëì,
(2.5)
which is proven through substitution and marginalization over ùëì,
ùëù(ùê¥|ùëÄ, ùê∑)
=
‚à´Ô∏Å
ùëì
(Ô∏Å‚à´Ô∏Å
^ùëß,ùëß
ùõø(ùëì‚àíùëì(^ùëß, ùëß)) ¬∑ ùúå(^ùëß, ùëß|ùëÄ, ùê∑) ùëë^ùëßùëëùëß
)Ô∏Å
¬∑ Œò(ùêµ(ùëì)) ùëëùëì
=
‚à´Ô∏Å
^ùëß,ùëß
Œò(ùêµ(^ùëß, ùëß)) ¬∑ ùúå(^ùëß, ùëß|ùëÄ, ùê∑) ùëë^ùëßùëëùëß.
(2.6)
2.3.3
Importance and Statistical Responsibility
The BVM allows the user to, in principle, quantify the probability the model and the
data agree with one another under arbitrary comparison value functions and with
arbitrary definitions of agreement. The BVM can therefore be used to fully quantify
the probability of agreement between arbitrary model and data types using novel or
existing comparison value functions and definitions of agreement. Thus, the problem
of model-data validation may be reduced to the problem of finding the four BVM
inputs in any model validation scenario.
33

When using the BVM framework, one should practice statistical responsibility by
explicitly stating the definition of agreement that is implemented in the validation
procedure. Although the flexibility of the BVM framework is a feature, different
validation metrics often have different amounts of tolerance as what constitutes
‚Äúagreement‚Äù. Agreement according to one metric does not in general imply agreement
according to another. Overly tolerant definitions of agreement have little resolution
power and can only be used responsibly if a large degree of non-exactness between
the model and data is permissible. In principle, the definition of agreement should
be just as strict or stricter than it needs to be. By explicitly stating the definition of
agreement alongside the BVM value, ùëù(ùê¥|ùëÄ, ùê∑) ‚â°ùëù(ùê¥|ùëÄ, ùê∑, ùêµ), one avoids statistical
misrepresentation by not hiding their definition of agreement.
2.4
Meeting the Desirable Validation Criterion
First we will describe how the BVM, Equations (2.2) and (2.5), precisely match our
validation criterion (1.). As can be seen by Equation (2.4), incorporated into the
BVM is a statistically quantified quantitative measure that compares data and model
outputs, ùúå(ùëì|ùëÄ, ùê∑). However, this pdf is in some sense lacking a context pertaining
to the model-data pair. Not until an accept/reject rule is imparted on ùúå(ùëì|ùëÄ, ùê∑) does
one define what is meant by agreement in the model-data context. Thus, the BVM
only becomes the probability of agreement between the data and the model when the
agreement function is also incorporated. The four BVM inputs are therefore adequate
to satisfy (1.) as the BVM is a ‚Äústatistically quantified quantitative measure (ùëì) of
agreement ùëù(ùê¥|ùëÄ, ùê∑) between model predictions and data pairs (^ùëß, ùëß), in the presence
or absence of uncertainty ùúå(^ùëß, ùëß|ùëÄ, ùê∑)‚Äù.
There are a few more BVM concepts worth discussing before moving forward. We
will show that the BVM is capable of handling general multidimensional model-data
comparisons and that there are no conceptual issues when agreement is exact, i.e. ùêµ
is true iff ^ùëß= ùëß, in the certain and uncertain cases. We will then make comments on
the sense in which the BVM adheres to the full set of six desirable validation criteria
34

given in [28] by discussing the criteria that are underrepresented in (1.).
2.4.1
Compound Booleans
Because Boolean operations between Boolean functions result in a Boolean function
itself, the BVM is capable of handling multidimensional model-data comparisons. We
will call a Boolean function with this property a ‚Äúcompound Boolean‚Äù. A compound
Boolean function results from and, ‚àß, conjunctions and or, ‚à®, disjunctions between a
set of Boolean functions, e.g.,
ùêµ({ùêµùëñ}) =
(Ô∏Å
ùêµ1(^ùëß, ùëß) ‚à®ùêµ2(^ùëß, ùëß)
)Ô∏Å
‚àß
(Ô∏Å
ùêµ3(^ùëß, ùëß) ‚à®ùêµ4(^ùëß, ùëß)
)Ô∏Å
¬∑ ¬∑ ¬∑
(2.7)
where each ùêµùëñ(^ùëß, ùëß) = ùêµùëñ(ùëìùëñ(^ùëß, ùëß)) may use a different comparison function ùëìùëñ(^ùëß, ùëß).
Compound Booleans using conjunctions quantify the validity of entire model functions
(random fields and/or multidimensional vectors) by assessing agreement between each
of the model-data comparison field points simultaneously, i.e over the comparison
points 1 and points 2 and so on. The compound Booleans may be factored into
their constituting Boolean functions using the standard product and sum rules of
probability theory after being mapped to probabilities with the agreement kernel. One
should be careful when defining an and Boolean; if one of the Booleans is false, then
the entire Boolean is false. If this strict ‚Äúall or nothing‚Äù validation requirement is not
needed then other more flexible definitions of agreement may be instantiated instead
(see the BVM examples in Section 2.6).
2.4.2
The BVM Under the Conditions of Exact Agreement
We can calculate the BVM under the conditions of exact agreement in the com-
pletely certain and uncertain cases. Because the BVM is a probability rather than
a probability density, the agreement kernel falls in the range [0, 1]. Under the con-
ditions of exact agreement, ùêµis only true when ^ùëß= ùëß, and the agreement kernel is
Œò(ùêµ) = Œò(^ùëß= ùëß) = ùõø^ùëß,ùëß, which is the Kronecker delta (i.e. it is 0 or 1) but with
continuous labels. As it is uncommon to deal with Kronecker delta‚Äôs having continuous
35

labels under integration, we will show that the BVM gives reasonable results under
the condition of exact agreement in the complete certainty as well as in the general
uncertain case.
Complete certainty and exact agreement
Complete certainty is represented using Dirac delta pdf functions over the model and
data comparison values. This gives the BVM,
ùëù(ùê¥|ùëÄ, ùê∑)
=
‚à´Ô∏Å
^ùëß,ùëß
ùúå(^ùëß|ùëÄ, ùê∑) ¬∑ Œò(^ùëß= ùëß) ¬∑ ùúå(ùëß|ùê∑) ùëë^ùëßùëëùëß
=
‚à´Ô∏Å
^ùëß,ùëß
ùõø(^ùëß‚àí^ùëß‚Ä≤) ¬∑ ùõø^ùëß,ùëß¬∑ ùõø(ùëß‚àíùëß‚Ä≤) ùëë^ùëßùëëùëß,
(2.8)
where we are considering the model-data pair to agree iff the comparison values are
exactly equal. Using the sifting property of the Dirac delta function, we find the
reasonable result that,
ùëù(ùê¥|ùëÄ, ùê∑) = ùõø^ùëß‚Ä≤,ùëß‚Ä≤,
(2.9)
which is equal to unity iff ^ùëß‚Ä≤ and ùëß‚Ä≤, the definite values of ^ùëßand ùëß, are equal.
Uncertainty and exact agreement
In the uncertain case under the condition of exact agreement, the BVM is
ùëù(ùê¥|ùëÄ, ùê∑) =
‚à´Ô∏Å
^ùëß,ùëß
ùúå(^ùëß|ùëÄ, ùê∑) ¬∑ ùõø^ùëß,ùëß¬∑ ùúå(ùëß|ùê∑) ùëë^ùëßùëëùëß.
(2.10)
We will do the following trick to correctly interpret this integral. We will first let
ùêµ(ùúñ) be true if ùëß‚àíùúñ‚â§^ùëß‚â§ùëß+ ùúñand then take the limit as ùúñ‚Üí0+ such that
limùúñ‚Üí0+ ùêµ(ùúñ) ‚Üíùêµwhen appropriate. With this Boolean expression, the BVM is,
ùëù(ùê¥|ùëÄ, ùê∑, ùúñ)
=
‚à´Ô∏Å
^ùëß,ùëß
ùúå(^ùëß|ùëÄ, ùê∑) ¬∑ Œò
(Ô∏Å
ùëß‚àíùúñ‚â§^ùëß‚â§ùëß+ ùúñ
)Ô∏Å
¬∑ ùúå(ùëß|ùê∑) ùëë^ùëßùëëùëß
=
‚à´Ô∏Å
ùëß
ùúå(ùëß|ùê∑)
(Ô∏Ç‚à´Ô∏Åùëß+ùúñ
ùëß‚àíùúñ
ùúå(^ùëß|ùëÄ, ùê∑) ùëë^ùëß
)Ô∏Ç
ùëëùëß.
(2.11)
In the limit ùúñ‚Üí0+, the term
‚à´Ô∏Äùëß+ùúñ
ùëß‚àíùúñùúå(^ùëß|ùëÄ, ùê∑)ùëë^ùëß‚Üíùëù(^ùëß= ùëß|ùëÄ, ùê∑) = ùúå(^ùëß= ùëß|ùëÄ, ùê∑)ùëë^ùëß
by the definition of probabilities. This gives,
36

ùëù(ùê¥|ùëÄ, ùê∑)
=
‚à´Ô∏Å
ùëß
ùúå(ùëß|ùê∑)
(Ô∏Å
ùëù(^ùëß= ùëß|ùëÄ, ùê∑)
)Ô∏Å
ùëëùëß=
(Ô∏Ç‚à´Ô∏Å
ùëß
ùúå(^ùëß= ùëß|ùëÄ, ùê∑) ¬∑ ùúå(ùëß|ùê∑)ùëëùëß
)Ô∏Ç
ùëë^ùëß
‚â°
ùúå(^ùëß‚â°ùëß|ùëÄ, ùê∑) ùëë^ùëß= ùëù(^ùëß‚â°ùëß|ùëÄ, ùê∑),
(2.12)
which is understood to be the sum of the model and the data probabilities that jointly
output exactly the same values. We see that the BVM in this case is proportional
to ùëë^ùëß, ùëù(ùê¥|ùëÄ, ùê∑) ‚Üíùúå(^ùëß‚â°ùëß|ùëÄ, ùê∑)ùëë^ùëß, in the general case of exact agreement, and
therefore the BVM goes to zero unless the pdf ùúå(^ùëß‚â°ùëß|ùëÄ, ùê∑) ‚àùùõø(. . .). Thus, we
recover the standard logical result for probability densities ùëù(ùë•) = ùúå(ùë•)ùëëùë•‚Üí0 unless
it is offset by ùúå(ùë•) ‚àùùõø(ùë•). This result is easily generalized to the dependent case
using ùúå(^ùëß, ùëß|ùëÄ, ùê∑) = ùúå(ùëß|ùëÄ, ùê∑)ùúå(^ùëß|ùëß, ùëÄ, ùê∑). The result, Equation (2.12), is no more
surprising than (2.9) in principle.
Due to the vast number of possibilities for continuous valued variables, having a
pathological definition of exact agreement between continuous variables does not occur
in practice. In a computational setting, ùëëùë•‚ÜíŒîùë•becomes a finite difference and
these infinitely improbable agreement conceptual issues are avoided. The Bayesian
model testing framework avoids these issues by evaluating posterior odds ratios, in
which case the measures, ùëë^ùëß, drop out.
2.4.3
Meeting Underrepresented Validation Criteria
Here we will discuss how the BVM also meets the validation criteria found in [28].
This is done by using the derived general and special cases of the BVM for each of
the criteria which are underrepresented in (1.).
Perhaps the primary underrepresented criterion from [28] is their second. It states
that ‚Äúthe criteria used for determining whether a model is acceptable or not should
not be a part of the metric which is expected to provide a quantitative measurement
only.‚Äù We argue that the functional form of the BVM presented in Equation (2.5)
clearly demonstrates this feature as it factors into ùúå(ùëì|ùëÄ, ùê∑) and Œò(ùêµ(ùëì)). The
37

comparison function ùëì(^ùëß, ùëß) represents the ‚Äúobjective quantitative measure‚Äù from their
first criterion that is separate from the accept/reject rule, which is our agreement
function ùêµ(ùëì) ‚Äì both of which require definition to ultimately evaluate the validity of
a model. We see it as advantageous to quantify the probability the model is accepted
or rejected through ùêµ(ùëì) due to the uncertainty in the value of ùëì, which is the general
case, and which gives the BVM as the result. As all of the validation metrics presented
in [28] (and more) will be shown to be representable with the BVM, and thus placed
on the same footing, we find our language of ‚Äúcomparison function‚Äù and ‚Äúagreement
function‚Äù to ultimately be more useful than a language that only considers comparison
functions (without accept/reject rules) to be the validation metrics.
The third criteria in [28] is that ideally the metric should ‚Äúdegenerate to the value
from a deterministic comparison between scalar values when uncertainty is absent‚Äù.
This is indeed the case as can be seen in Equation (2.1) or in Equations (2.2) and
(2.5) by utilizing Dirac delta pdfs similar to their application in Equation (2.8).
The fifth desirable validation criteria in [28] states that artificially widening proba-
bility distributions should not lead to higher rates of validation. They find all but
the frequentist metric to have this undesired feature; however, we later see that the
frequentist metric may be considered a special case of the reliability metric (when
reasonable accuracy requirements are imposed), meaning artificial widening can lead
to higher rates of validation for more general instances of the frequentist metric.
Further, we argue that artificially introducing uncertainty for the express purpose
of passing a validation test is indistinguishable from scientific misconduct. If there is
objective reason to include more uncertainty into the analysis or if the circumstance for
what constitutes validation has changed due to a change of context ‚Äì and it happens
to improve the rate of validation ‚Äì so be it. This is a different context, model, or state
of uncertainty than was originally proposed so different rates of acceptance should
be expected. Reducing the uncertainty of either the data or the model (the inputs)
through additional measurements or changing the model may later prove the model
valid or invalid when it may have been initially accepted. Thus, to meet this validation
criteria, we simply assume the user is not engaging in scientific misconduct.
38

Finally, due to the results of the Compound Booleans in Section 2.4.1, their sixth
criterion is met. Because the BVM (2.2) can be used to assess single or multidimensional
controllable settings (see footnote number 3) we can perform global function validity
(in or out of a controls setting). As they note, ‚ÄúThis last feature is critical from the
viewpoint of engineering design‚Äù.
Thus, the BVM satisfies both our validation criterion and the six desirable validation
criteria outlined in [28]. This was accomplished by representing model-data validation
as an inference problem using the four BVM inputs.
2.5
Representing and Generalizing the Known Vali-
dation Metrics with the BVM
This section is a review of the material found in Appendix A. The following validation
metrics will be represented with the BVM, which are then improved, generalized,
and/or commented on: reliability/probability of agreement, improved reliability metric,
frequentist, area metric, pdf comparison metrics, statistical hypothesis testing, and
Bayesian model testing.
2.5.1
Representing the Known Validation Metrics
Table 2.1 shows the values of the four BVM inputs that result in the BVM representing
the well-known validation metrics as special cases. The following notation is used for
the comparison values (^ùëß, ùëß). The brackets ‚ü®. . .‚ü©denote expectation values, ùúá‚Äôs denote
averaged values, ^ùë¶, ùë¶denote single values, ^ùëå, ùëådenote multidimensional values, ùêπ^ùë¶, ùêπùë¶
denote cumulative distribution functions
(Ô∏Ä
ùêπùë¶=
‚à´Ô∏Ä^ùë¶
‚àí‚àûùúå(^ùë¶|ùëÄ, ùê∑) ùëëùë¶
)Ô∏Ä
, ùëÜ^ùë¶, ùëÜùë¶denote test
statistics, and [‚àíùëêùõº, ùëêùõº] denotes the 1 ‚àíùõºconfidence interval of the data. In the
agreement function column, an element listed as ùêµ(ùëì) means the creators of the metric
intentionally left the definition of agreement unspecified; however, it is natural to
assume it is a function of the comparison function ùëì.
Table 2.1 shows the specification of the four BVM inputs that give the other
39

validation metrics as special cases. It also summarizes some of the similarities and
difference between the known validation metrics. In particular, by looking at the
validation metrics with the same type of comparison values, i.e. the reliability and
frequentist or the improved reliability and Bayesian model testing, we can compare
them directly. We see that if one lets the frequentist metric allow for more general
input probability distributions and the use of a reasonable agreement function (i.e.,
ùêµ(ùëì) is true if |ùëì| < ùúñ), then the frequentist metric is the reliability metric. Further,
in Bayesian model testing, if the agreement function ùêµ(ùëì) is loosened to accept ùëì< ùúñ,
then the pdfs that appear in the Bayesian model testing framework are equal to the
improved reliability metric. This information improves the objectivity of the current
validation procedure because we now have a map between validation metrics that were
originally thought to be different.
Comp. Values
Probs.
Comp. Func.
Agree. Func.
BVM
^ùëß
ùëß
ùúå(^ùëß|ùëÄ, ùê∑)
ùúå(ùëß|ùê∑)
ùëì(^ùëß, ùëß)
ùêµ(ùëì)
Reliability
‚ü®^ùë¶‚ü©
ùúáùë¶
ùúå(‚ü®^ùë¶‚ü©|ùëÄ, ùê∑)
ùúå(ùúáùë¶|ùê∑)
|‚ü®^ùë¶‚ü©‚àíùúáùë¶|
ùëì< ùúñ
Imp. Reli.
^ùëå
ùëå
ùúå( ^ùëå|ùëÄ, ùê∑)
ùúå(ùëå|ùê∑)
| ^ùëå‚àíùëå|
ùëì< ùúñ
Frequentist
‚ü®^ùë¶‚ü©
ùúáùë¶
ùõø(‚ü®^ùë¶‚ü©‚àí‚ü®^ùë¶‚ü©‚Ä≤)
Stud. ùë°
‚ü®^ùë¶‚ü©‚àíùúáùë¶
ùêµ(ùëì)
Area
ùêπ^ùë¶
ùêπùë¶
ùõø(ùêπ^ùë¶‚àíùêπ‚Ä≤
^ùë¶)
ùõø(ùêπùë¶‚àíùêπ‚Ä≤
ùë¶)
‚à´Ô∏Ä
^ùë¶|ùêπ^ùë¶‚àíùêπùë¶=^ùë¶|ùëë^ùë¶
ùêµ(ùëì)
Pdf Comp.
ùúåùëÄ
ùúåùê∑
ùõø(ùúåùëÄ‚àíùúå‚Ä≤
ùëÄ)
ùõø(ùúåùê∑‚àíùúå‚Ä≤
ùê∑)
ùê∫(ùúåùê∑||ùúåùëÄ)
ùêµ(ùëì)
Stat. Hyp.
ùëÜ^ùë¶
ùëÜùë¶
ùúå(ùëÜ^ùë¶|ùëÄ= ùê∑)
ùúå(ùëÜùë¶|ùê∑)
ùëÜ^ùë¶
ùëÜ^ùë¶‚àà[‚àíùëêùõº, ùëêùõº]
Bayes Model
^ùëå
ùëå
ùúå( ^ùëå|ùëÄ, ùê∑)
ùúå(ùëå|ùê∑)
| ^ùëå‚àíùëå|
ùëì= 0
Table 2.1: Specification of the four BVM inputs that give the other validation
metrics as special cases. The column headings are the four BVM input val-
ues: Comparison Values (^^ùëß, ùëß), Probabilities (ùúå(^ùëß|ùëÄ, ùê∑), ùúå(ùëß|ùê∑)), Comparison
Function ùëì= ùëì(^ùëß, ùëß), and the Boolean Agreement Function ùêµ(ùëì). The row
headings read: Reliability, Improved Reliability, Frequentist, Area, Pdf Compari-
son Metrics, Statistical Hypothesis Testing, and Bayesian Model Testing. The
denoted data probability for the average in the frequentist metric, Stud. ùë°, is the
Student‚Äôs ùë°-distribution.
Table 2.2 shows the resulting BVM using the specifications listed in Table 2.1.
The value ùëüis the standard notation for the reliability metric [47] and we use ùëüùëñ
for the improved reliability metric [51]. The BVM represents each of the known
40

validation metrics as a probability of agreement between the model and the data from
Equation (2.2). As no agreement function is specified directly for the frequentist and
area metric, the problem is under constrained so the agreement functions are left as
general functions over the comparison function ùêµ(ùëì). Thus, for any chosen agreement
function, the BVM quantifies their probability of agreement. The remaining metrics
all do specify (or indicate) an agreement function, and thus, have specified all of the
information required to compute the BVM.
BVM
BVM
‚à´Ô∏Ä
ùëìùúå(ùëì|ùëÄ, ùê∑) ¬∑ Œò(ùêµ(ùëì)) ùëëùëì
Reliability
‚à´Ô∏Ä
ùëìùúå(ùëì|ùëÄ, ùê∑) ¬∑ Œò(ùëì< ùúñ) ùëëùëì= ùëü
Imp. Reli.
‚à´Ô∏Ä
ùëìùúå(ùëì|ùëÄ, ùê∑) ¬∑ Œò(ùëì< ùúñ) ùëëùëì= ùëüùëñ
Frequentist
‚à´Ô∏Ä
ùúáùë¶ùúå(ùúáùë¶|ùê∑) ¬∑ Œò(ùêµ(ùëì(‚ü®^ùë¶‚ü©‚Ä≤, ùúáùë¶))) ùëëùúáùë¶
Area
Œò(ùêµ(ùëì(ùêπ‚Ä≤
^ùë¶, ùêπ‚Ä≤
ùë¶))
Pdf Comp.
Œò(ùêµ(ùëì(ùúå‚Ä≤
ùëÄ, ùúå‚Ä≤
ùê∑))
Stat. Hyp.
‚à´Ô∏Ä
ùëÜ^ùë¶ùúå(ùëÜ^ùë¶|ùëÄ= ùê∑) ¬∑ Œò(ùëÜ^ùë¶‚àà[‚àíùëêùõº, ùëêùõº]) ùëëùëÜ^ùë¶= 1 ‚àíùõº
Bayes Model
‚à´Ô∏Ä
ùëìùúå(ùëì|ùëÄ, ùê∑) ¬∑ Œò(ùëì= 0) ùëëùëì= ùëù( ^ùëå‚â°ùëå|ùëÄ, ùê∑)
Table 2.2: BVM representation of the other validation metrics as special cases
using the comparison functions (the ùëì‚Äôs) specified in Table 2.1.
Statistical hypothesis testing is perhaps a bit out of place among the validation
metrics. First, note that the comparison function for statistical hypothesis testing
is not a function of both the data and the model. Further, note that the model pdf
used for statistical hypothesis testing assumes the null hypothesis is true, which in
our language is the assumption that ùúå(ùëÜ^ùë¶|ùëÄ, ùê∑) = ùúå(ùëÜ^ùë¶|ùëÄ= ùê∑), i.e. that the pdf
of the model is equal to the pdf of the data. This shows how statistical hypothesis
testing is a bit out of place here among the validation metrics because here we are
attempting to validate a model, usually with its own quantified pdf, rather than,
perhaps irresponsibly, assuming it is equal to the data pdf before validating that
to be the case. This causes standard statistical hypothesis pitfalls, such as type I
(rejecting the null hypothesis when it is true) and type II errors (accepting the null
41

hypothesis when it is false), to be carried over into the BVM, which is unwanted.
Several comments are made in Appendix A.5 on this issue.
A perhaps surprising result is the proposed functional form of the BVM that rep-
resents Bayesian model testing ùëù(ùê¥|ùëÄ, ùê∑) = ùëù(^ùëå‚â°ùëå|ùëÄ, ùê∑), which is the Bayesian
evidence. This is the probability that the uncertain model and data output exactly
the same values. Usually what is discussed when reviewing Bayesian model testing is
the Bayes posterior odds ratio, i.e. the ‚ÄúBayes Ratio‚Äù,
ùëÖ= ùëù(ùëÄ|ùëå)
ùëù(ùëÄ‚Ä≤|ùëå) ‚àùùëù(ùëå|ùëÄ)
ùëù(ùëå|ùëÄ‚Ä≤),
which tests one model ùëÄ(i.e. for validation) against another model ùëÄ‚Ä≤. However,
in validation metric problems, we are first interested in considering the validation of
a single model ‚Äì the ratio is an extra bit of inference. In Appendix A.6, we show
that the BVM result of ùëù(^ùëå‚â°ùëå|ùëÄ, ùê∑) is exactly what we mean by ùëù(ùëå|ùëÄ) in the
numerator of the Bayes factor,4 which effectively quantifies the validation of a single
model against the data ùëå, all quantified under uncertainty.
2.5.2
Generalizing the Known Validation Metrics
The BVM offers several avenues to either generalize or improve many of the metrics.
The types of generalizations the BVM offer pertain to generalizing the comparison
values, comparison functions, definitions of agreement, and/or generalizing deter-
ministic comparison values and metrics to the uncertain case. These generalizations
are only useful if quantitative statements can be made on their behalf ‚Äì in such
a case, these generalizations are improvements. We will give a brief review of the
improvements we found below, but the full discussion is located in Appendix A. By
making generalizations or improvements to each of the known validation metrics as
implied by the BVM, each metric can be made to satisfy our validation criterion as
well as the six desirable validation criteria in [28], due to the results of Section 2.4.
4It should be noted that our notation for ùê∑differs from the notation typically used in Bayesian
model testing. Their ùê∑is equal to our data ùëå, while our ùê∑refers to context ‚Äúas having come from
the data or experiment rather than the model‚Äù.
42

Appendix A.1 uses the BVM to show that the reliability metric and the improved
reliability metric can be generalized to compare values without a unique order, such as
strings, in principle. This involves creating an agreement function over sets of values
(such as synonymous sets of strings), rather than continuous intervals, that may be
considered to ‚Äúagree‚Äù.
Appendix A.2 derives the frequentist validation metric and generalizes it to the
case where both the model and data expectation values are uncertain. The frequentist
metric assumes that the model outputs are known with certainty, which may or may
not be true. If a model is stochastic, the model pdfs may be estimated with Monte
Carlo or other uncertainty propagation methods that quantify the pdf directly.
Appendix A.3 shows that the area metric may be cast as a special case of the
BVM. The area metric involves quantifying the difference between model and data
cumulative distributions on a point to point basis; thus, the comparison values (^ùëß, ùëß)
are cumulative distributions themselves. The comparison values are assumed to be
known with complete certainty, which in the case of cumulative distributions of data
is often difficult to argue. Any quantifiable uncertainty in the cumulative distributions
may be integrated over, which generalizes the area metric to situations when the
model and/or the data cumulative distributions are uncertain. A drawback is that
the BVM in these cases may be very computationally intensive and would likely need
to be approximated using a random sampling or discretization scheme. A binned
pdf metric is put forward to potentially reduce the computational complexity toward
quantifying this generalized area validation metric. This applies similarly to the pdf
comparison metrics in Appendix A.4.
In Appendix A.5, we invent an improved statistical hypothesis test using the BVM,
called the ‚Äústatistical power BVM‚Äù, that takes into account both model and data
pdfs. Because in principle we have a model output pdf ùúå(^ùë¶|ùëÄ, ùê∑) in model validation
problems, we can use it (in place of assuming the null hypothesis is true) to avoid
both type I and type II errors.
In the statistical power BVM, the model and the data are defined to agree if both
their test statistics lie within one another‚Äôs confidence intervals (or ‚Äúconfidence sets‚Äù as
43

explained in Appendix A.5). The statistical power BVM becomes the product of the
statistical powers of the model and data, denoted ùëù(ùê¥|ùëÄ, ùê∑) =
(Ô∏Ä
1‚àíùõΩùëÄ(ùõº)
)Ô∏Ä
¬∑
(Ô∏Ä
1‚àíùõΩùê∑(^ùõº)
)Ô∏Ä
in Equation (A.18). Further comments are made about how systematic error (defined
as when a test statistic lies outside of its own confidence interval) may be removed.
It is concluded that the statistical power BVM has a relatively low resolving power
compared to other BVMs. This is because large confidence intervals imply large
tolerance intervals for acceptance. For this reason, statistical hypothesis testing should
only be used for validation in situations where a high degree of nonexactness between
model and data test statistics is permissible and the pdfs have very thin tails. This
BVM does, however, have a greater resolution than the classical hypothesis test as
was proved in Appendix A.5 and will be demonstrated in Section 2.6.
Appendix A.6 finds that Bayesian model testing has the highest possible resolving
power because the model and the data are defined to agree only if their values are
exactly equal. This is the reverse of what was concluded about statistical hypothesis
testing.
Further in Appendix A.6, we argue that, analogous to the Bayesian model testing
framework, nothing prevents us from constructing what we call the BVM factor. The
BVM factor is,
ùêæ(ùêµ) = ùëù(ùê¥|ùëÄ, ùê∑, ùêµ)
ùëù(ùê¥|ùëÄ‚Ä≤, ùê∑, ùêµ),
(2.13)
which is a ratio of the BVMs of two models under arbitrary definitions of agreement
ùêµ. Using Bayes‚Äô Theorem, ùëù(ùëÄ|ùê¥, ùê∑, ùêµ) = ùëù(ùê¥|ùëÄ, ùê∑, ùêµ)ùëù(ùëÄ|ùê∑, ùêµ)/ùëù(ùê¥|ùê∑, ùêµ), we
may further construct the BVM ratio,
ùëÖ(ùêµ) = ùëù(ùëÄ|ùê¥, ùê∑, ùêµ)
ùëù(ùëÄ‚Ä≤|ùê¥, ùê∑, ùêµ) = ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) ùëù(ùëÄ|ùê∑, ùêµ)
ùëù(ùê¥|ùëÄ‚Ä≤, ùê∑, ùêµ) ùëù(ùëÄ‚Ä≤|ùê∑, ùêµ) = ùêæ(ùêµ) ùëù(ùëÄ|ùê∑, ùêµ)
ùëù(ùëÄ‚Ä≤|ùê∑, ùêµ), (2.14)
for the purpose of comparative model selection under a general definition of agreement
ùêµ. The ratio ùëù(ùëÄ|ùê∑, ùêµ)/ùëù(ùëÄ‚Ä≤|ùê∑, ùêµ) is the ratio of prior probabilities of ùëÄand ùëÄ‚Ä≤.
Analogous to Bayesian model testing, if there is no reason to suspect that one model
is a priori more probable than another, one may let ùëù(ùëÄ|ùê∑, ùêµ)/ùëù(ùëÄ‚Ä≤|ùê∑, ùêµ) = 1, and
44

then ùëÖ(ùêµ) ‚Üíùêæ(ùêµ) in value.
Thus, using the BVM ratio, we can perform general model validation testing under
arbitrary definitions of agreement and with any reasonable set of comparison functions.
The BVM ratio therefore generalizes the Bayesian model testing framework. This will
be utilized in Section 2.6.
Finally we wanted to add a note about how one may mitigate the sharpness of the
indicator function without using fuzzy logic while also allowing close models to be some-
what accepted. As we have seen, it is natural to use a threshold Boolean parameter ùúñto
help define the boundary of agreement through ùêµ(ùëì‚â§ùúñ). Such a BVM takes the form,
ùëù(ùê¥|ùëÄ, ùê∑, ùúñ) =
‚à´Ô∏Å
ùëì
ùúå(ùëì|ùëÄ, ùê∑) ¬∑ Œò(ùêµ(ùëì‚â§ùúñ)) ùëëùëì,
(2.15)
where Œò(. . .) instantaneously drops to zero for ùëì> ùúñ. One may soften the boundary by
allowing ùúñitself to be an uncertain quantity, which means one allows their definition of
agreement to be somewhat uncertain (which can often be reasonably claimed). As an
example, let this uncertainty be ùúå(ùúñ) = ùúÜexp(‚àíùúÜ(ùúñ‚àíùúñ‚Ä≤)) for ùúñ‚Ä≤ > ùúñand zero otherwise,
where ùúÜis positive. Marginalizing over ùúñthen gives,
ùëù(ùê¥|ùëÄ, ùê∑)
=
‚à´Ô∏Å
ùúñ
ùëù(ùê¥|ùëÄ, ùê∑, ùúñ) ¬∑ ùúå(ùúñ) ùëëùúñ
=
‚à´Ô∏Å
ùëì
ùúå(ùëì|ùëÄ, ùê∑) ¬∑
(Ô∏Å
Œò
(Ô∏Ä
ùêµ(ùëì‚â§ùúñ‚Ä≤)
)Ô∏Ä
+ Œò
(Ô∏Ä
ùêµ(ùëì> ùúñ‚Ä≤)
)Ô∏Ä
ùëí‚àíùúÜ(ùëì‚àíùúñ‚Ä≤))Ô∏Å
ùëëùëì, (2.16)
which allows some ùëì‚Äôs to be accepted outside the agreement region defined by ùëì‚â§ùúñ‚Ä≤,
but with an exponentially decaying probability. Other potentially useful ùúñpdfs include,
but are not limited to: negative slope linear, Gaussian, or decaying sigmoid functions.
None of these ùúñtype distributions were needed to obtain the results of the previous
sections explicitly; however, these types of assumptions may have been part of the
decision process made implicitly by a practitioner while performing model validation.
45

2.6
BVM Examples
In this section, we invent and quantify three novel validation metrics using the BVM
to highlight the conceptual clarity, flexibility, and capacity of our framework.
2.6.1
The Statistical Power BVM
Here we consider the statistical power BVM proposed in Appendix A.5 and reviewed
in the previous section. This metric defines agreement as occurring when both the
model and data comparison values are within one another‚Äôs confidence intervals,
simultaneously. The BVM for this metric is the product of the statistical powers of
the model and the data ùëù(ùê¥|ùëÄ, ùê∑) =
(Ô∏Ä
1‚àíùõΩùëÄ(ùõº)
)Ô∏Ä
¬∑
(Ô∏Ä
1‚àíùõΩùê∑(^ùõº)
)Ô∏Ä
, which is calculated in
Equation (A.18). We contrast this with the standard statistical hypothesis test that,
after assuming the model is correct, ùëÄ= ùê∑, finds the probability that the model
lies within the data‚Äôs confidence interval equal to 1 ‚àíùõº. In statistical hypothesis
testing, one then proceeds to check the actual model output and speculates about
type I and type II errors. As discussed in Appendix A.5, we do not assume ùëÄ= ùê∑
before validation and therefore type I and type II errors are avoided. Rather, we let
the statistical power BVM decide whether or not the model is valid. This provides a
more informative validation procedure.
Figure 2-2 depicts a typical statistical hypothesis test scenario that is designed
to check the validity of an uncertain model average prediction ^ùúá(in blue) against
an uncertain data average prediction ùúá(in red). The data‚Äôs ùúáis ùë°-distributed (the
same distribution in each subfigure) according to ùëá(ùë¶, ùëõ‚àí1, ùë†) = ùëá(0, 10, 1.75) where
(ùë¶, ùëõ, ùë†) are the sample mean, the number of collected data points, and the sample
standard deviation, respectively. Each row depicts a normally distributed model
centered at 0, but with increasing model variance per row.
46

Figure 2-2:
Comparison between statistical hypothesis testing and
statistical power BVM. (a) The shaded regions in Column A depict the
95% confidence interval of each distribution, respectively. Because the data
distribution is the same in each figure and because the statistical hypothesis test
is independent of the proposed model due to assuming the hypothesis ùëÄ= ùê∑,
each model is equally valid by that test when it is clear that the model in row 2
is preferable. (b) The shaded regions in Column B depict the statistical power of
the distributions ‚Äì the 95% confidence intervals from each distribution is shaded
(integrated) in the other‚Äôs pdf. The statistical power BVM (denoted ùëÉ(ùê¥) in
column B) is calculated for each model and indeed the model in row 2 is found
to be preferable as it has the highest probability of agreement.
2.6.2
The
(Ô∏Ä
‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä
BVM
We invent a novel compound Boolean that defines agreement as when the model
passes an average square error threshold of ‚ü®ùúñ‚ü©and a check for probabilistic model
representation. The latter is imposed by requiring that 95%¬±4% of the uncertain data
lies inside the model‚Äôs 1 ‚àí^ùõº= 95% confidence interval, i.e. 1 ‚àíùõΩùê∑(^ùõº) ‚àº95%. The
¬±4% tolerance was chosen such that overly uncertain models would be marked as ‚Äúnot
agreeing‚Äù as they would be able to guarantee that 100% of the data lies within their
47

excessively wide confidence intervals. We call this compound Boolean the
(Ô∏Ä
‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä
Boolean. The BVM in this case is
ùëù(ùê¥|ùëÄ, ùê∑, ‚ü®ùúñ‚ü©, ùõΩùê∑) =
‚à´Ô∏Å
^ùëå,ùëå
ùúå(^ùëå|ùëÄ, ùê∑) ¬∑ Œò
(Ô∏Å
ùêµ
(Ô∏Ä^ùëå, ùëå, ‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä)Ô∏Å
¬∑ ùúå(ùëå|ùê∑) ùëë^ùëåùëëùëå, (2.17)
where the compound Boolean ùêµ
(Ô∏Ä^ùëå, ùëå, ‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä
is equal to,
ùêµ
(Ô∏Ç1
ùëõ
‚àëÔ∏Å
ùëñ
|^ùë¶ùëñ‚àíùë¶ùëñ| ‚â§‚ü®ùúñ‚ü©
)Ô∏Ç
‚àßùêµ
(Ô∏Ç
0.91 ‚â§1
ùëõ
‚àëÔ∏Å
ùëñ
Œò
(Ô∏Ä
ùë¶ùëñ‚àà[‚àíùëê^ùõº, ùëê^ùõº]ùëñ
)Ô∏Ä
‚â§0.99
)Ô∏Ç
,
(2.18)
where ùëõis the number of data points in {ùë¶ùëñ} = ùëå, and [‚àíùëê^ùõº, ùëê^ùõº]ùëñis the model‚Äôs
95% confidence interval at comparison location ùë•ùëñ. We treat the model‚Äôs confidence
intervals as certain quantities, which can be achieved effectively through enough Monte
Carlo (MC) simulation of the model output pdfs (although this stipulation can be
removed if needed).
Although the mathematical notation for the compound Boolean is a bit complicated,
it is relatively easy to implement using if statements. This ease of programming allows
the BVM to have a large capacity for representing complex and abstract validation
scenarios in practice.
Expressing the BVM as an expectation value over ùúå(ùëå|ùê∑)ùúå(^ùëå|ùëÄ, ùê∑),
ùëù(ùê¥|ùëÄ, ùê∑, ‚ü®ùúñ‚ü©, ùõΩùê∑) = ùê∏
[Ô∏Å
Œò
(Ô∏Å
ùêµ
(Ô∏Ä^ùëå, ùëå, ‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä)Ô∏Å]Ô∏Å
‚àº1
ùêæ
ùêæ
‚àëÔ∏Å
ùëò=1
Œò
(Ô∏Å
ùêµ
(Ô∏Ä^ùëå(ùëò), ùëå(ùëò), ‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä)Ô∏Å
,(2.19)
allows one to compute the integral using standard statistical methods like MC. We
use MC and ùêæ= 3000 samples in this toy example. In Figure 2-3, we implement the
(Ô∏Ä
‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä
Boolean and show that it is able to quantify both the average error and a
model‚Äôs probabilistic representation of the uncertain data, simultaneously.
We consider the data generated from,
ùë¶(ùë•) = 1 + ùë•ùëí‚àícos (10ùë•) + sin (10ùë•) + ùúñùëé(ùë•),
(2.20)
where ùúñùëé(ùë•) ‚àºùí©(0, 0.42) represents the aleatoric stochastic uncertainty due to the
inherent randomness of the system. An instance of the aleatoric data ùëåwithout
measurement uncertainty is depicted in red in Figures 2-3a and 2-3b. We consider the
48

data to have an additional epistemic measurement uncertainty ùúñùëí(ùë•) ‚àºùí©(0, 0.22) that
contributes to the probability of whether or not the model agrees with the plotted
instance of the aleatoric data ùëå.
The models plotted in Figures 2-3a and 2-3b are generated from,
^ùë¶(ùë•; ‚Éóùõº) = ùõº1 + ùõº2ùë•ùëí‚àíùõº3 cos (ùõº4ùë•) + ùõº5 sin (ùõº6ùë•),
(2.21)
where ‚Éóùõº= (ùõº1, ùõº2, ùõº3, ùõº4, ùõº5, ùõº6) is the vector of model parameters. In Figure 2-3a, a
deterministic model is considered and plotted in blue by treating the model parameters
as completely certain numbers ‚Éóùõº= (1, 1, 1, 10, 1, 10). In Figure 2-3b, we consider
an uncertain model by treating the model parameters as uncertain values drawn
from a multivariate Gaussian distribution having averages ùúá‚Éóùõº= (1, 1, 1, 10, 1, 10) and
standard deviations ùúé‚Éóùõº= (0.35, 0.3, 0.3, 0.3, 0.3, 0.3). We evaluate the probability
that these data and model pairs pass the ‚ü®ùúñ‚ü©Boolean versus the
(Ô∏Ä
‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä
Boolean by
calculating their respective BVMs.
Figure 2-3: Validating a deterministic model and an uncertain model
according to two Boolean agreement functions. (a) The deterministic
model satisfies the ‚ü®ùúñ‚ü©Boolean but fails to pass the
(Ô∏Ä
‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä
requirement given
that its 95% confidence interval has a width of zero. (b) The uncertain model
satisfies both the ‚ü®ùúñ‚ü©and
(Ô∏Ä
‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä
agreement requirements given that its 95%
confidence region has a nonzero width and represents better the uncertain data.
The deterministic model plotted in Figure 2-3a satisfies the average error validation
requirement with ùëÉ(ùê¥|‚ü®ùúñ‚ü©) = 0.99 when a threshold of ‚ü®ùúñ‚ü©= 0.46 is used. This result is
logical because the congregate standard deviation of the data is itself the combination of
49

the aleatoric and epistemic uncertainties, i.e.
‚àö
0.42 + 0.22 ‚âà0.45. This deterministic
model fails to predict the uncertain fluctuations of the data because determinisic
models have confidence intervals with zero width. Thus the deterministic model fails
to agree according to the (‚ü®ùúñ‚ü©, ùõΩùê∑) Boolean and one finds ùëÉ(ùê¥|‚ü®ùúñ‚ü©, ùõΩùê∑) = 0 for any
value of ‚ü®ùúñ‚ü©.
The uncertain model depicted in Figure 2-3b is able to pass both agreement
definitions; however, our choice to evaluate each probable model path (rather than
just the average model) against the epistemic uncertain data increases the threshold to
about ‚ü®ùúñ‚ü©= 0.9 before an agreement probability of about ùëÉ(ùê¥|‚ü®ùúñ‚ü©) = 0.96 is achieved.
When instead evaluating ‚ü®ùúñ‚ü©against the average model, we obtained similar results
to the deterministic model for this Boolean; ‚ü®ùúñ‚ü©‚àº0.46 and ùëÉ(ùê¥|‚ü®ùúñ‚ü©) = 0.99. The
(Ô∏Ä
‚ü®ùúñ‚ü©, ùõΩùê∑
)Ô∏Ä
BVM for the uncertain model is ùëÉ(ùê¥|‚ü®ùúñ‚ü©, ùõΩùê∑) = 0.93, because the uncertainty
in the data more or less agrees with the confidence interval provided by the model.
This model can be tested for agreement against other models or model parameter
distributions for their respective definitions of agreement.
2.6.3
Exploring the BVM Ratio with the (ùõæ, ùúñ) BVM
In this section, we invent an agreement function to represent the visual inspection an
engineer might perform graphically and use the BVM ratio for model selection under
this definition of agreement. By quantifying this, a practitioner could visually validate
a model without actually looking at the model-data pair, which can be helpful for
high dimensional spaces that are beyond human comprehension/visualizability. We
will proceed by introducing this agreement function and some simple models to test it
on. We will then quantify this measure using the BVM in the completely certain and
uncertain cases. The main purpose of this example is to explore the BVM Ratio while
showcasing the conceptual flexibility of the framework.
To quantify something resembling the visual inspection an engineer might make
graphically, we use two main criteria. We define the model to be accepted if most
of the model and data point pairs lie relatively close to one another and if none of
the point pairs deviate too far from one another. We therefore consider a compound
50

Boolean ùêµ(^ùëå, ùëå, ùõæ, ùúñ) that is true if a percentage larger than ùõæ% (‚àº90%) of the model
output points ^ùëålie within ùúñof the data points ùëåand 100% of the model output
points lie within some multiple ùëöùúñof the data points, which rules out obvious model
form error. We will call this compound Boolean the (ùõæ, ùúñ) Boolean. The values ùõæ%, ùúñ,
and ùëöcan be adjusted to the needs of the modeler. It should be noted that the ùúñin
this metric makes point by point evaluations as opposed to the average ‚ü®ùúñ‚ü©Boolean
used in the previous example. We will perform the analysis for a variety of ùõæand ùúñ
values to explore the limits of the metric.
We will calculate the BVM for two different order polynomial models that approxi-
mate ùëõdata points taken from the cosine function ùë¶ùëñ= cos(ùë•ùëñ), as an illustration. The
points are evenly spaced in the range ùë•ùëñ‚àà[0, ùúã]. The first model ^ùë¶(1)
ùëñ
= ùëÄ1(ùë•ùëñ; ‚Éóùõº) =
ùõº1 + ùõº2ùë•2
ùëñ+ ùõº3ùë•4
ùëñand the second model ^ùë¶(2)
ùëñ
= ùëÄ2(ùë•ùëñ; ‚Éóùõº) = ùõº1 + ùõº2ùë•2
ùëñ+ ùõº3ùë•4
ùëñ+ ùõº4ùë•6
ùëñ
have uncertain parameters (ùõº1, ùõº2, ùõº3, ùõº4).5
To formulate the BVM, we still need to formulate the model and data probabil-
ity distributions. Because the Boolean expression ùêµ(^ùëå, ùëå) is over the entire model
and data functions, the model probability distribution is ùëù(^ùëå|ùëÄ, ùê∑) and the data
probability distribution is ùëù(ùëå|ùê∑). These are joint probabilities over all of the points
(Ô∏Ä^ùëå= {^ùë¶ùëñ}, ùëå= {ùë¶ùëñ}
)Ô∏Ä
that constitute a particular path (^ùëå, ùëå) of the model or data, re-
spectively. Because both models are linear in the uncertain coefficients (ùõº1, ùõº2, ùõº3, ùõº4),
there is a one to one correspondence from the set of model parameters (ùõº1, ùõº2, ùõº3, ùõº4)
to the set of the possible paths ^ùëåùõº1,ùõº2,ùõº3,ùõº4 (given ùëõis greater than the number of
independent coefficients). This makes the uncertainty propagation from the uncertain
model parameters to the full joint probability of the points on a path simple and
results in the joint probability of the paths being equal to the joint probability of the
uncertain input model parameters. For simplicity, we will let
ùëù(ùõº1, ùõº2, ùõº3, ùõº4) = ùí©(ùúáùõº1, ùúéùõº1) ùí©(ùúáùõº2, ùúéùõº2) ùí©(ùúáùõº3, ùúéùõº3) ùí©(ùúáùõº4, ùúéùõº4),
where ùí©(ùúá, ùúé) is a normal distribution with a mean ùúáand a standard deviation ùúé.
5Note that ùõº4 = 0 for model 1.
51

Thus, for each model ùëÄùëó, we have,
ùëù(^ùëåùõº1,ùõº2,ùõº3,ùõº4|ùëÄùëó) = 1
ùëçexp
(Ô∏Ç
‚àí(ùõº1 ‚àíùúáùõº1)2
2ùúé2
ùõº1
‚àí(ùõº2 ‚àíùúáùõº2)2
2ùúé2
ùõº2
‚àí(ùõº3 ‚àíùúáùõº3)2
2ùúé2
ùõº3
‚àí(ùõº4 ‚àíùúáùõº4)2
2ùúé2
ùõº4
)Ô∏Ç
.
Because the problem is well understood, we discretize the integrals rather than es-
timating them with MC [61]. After discretization, the (ùõæ, ùúñ) BVM for each model ùëÄùëóis,
ùëù(ùê¥|ùëÄùëó, ùê∑, ùõæ, ùúñ) =
‚àëÔ∏Å
^ùëå,ùëå
ùëù(^ùëå|ùëÄùëó) ¬∑ Œò
(Ô∏Ä
ùêµ(^ùëå, ùëå, ùõæ, ùúñ)
)Ô∏Ä
¬∑ ùëù(ùëå|ùê∑).
(2.22)
In principle, ùúñ= (ùúñ1, .., ùúñùëõ) is an ùëõ-dimensional vector where each ùúñùëñmay be adjusted
to impose more or less stringent agreement conditions on a point to point basis,
which may be used to enforce reliability in regions of interest. In our example, we
let all the components ùúñùëñbe equal (i.e. ùúñùëñ= ùúñfor all ùëñ). If the standard devia-
tion of each data point ‚àº^ùúéùëñ(aleatoric and/or measurement uncertainty) in the joint
data pdf ùëù(ùëå|ùê∑) is much less than ùúñùëñ, and ùëõis large, one may approximate the BVM as,
ùëù(ùê¥|ùëÄùëó, ùê∑, ùõæ, ùúñ) ‚âà
‚àëÔ∏Å
^ùëå
ùëù(^ùëå|ùëÄùëó) ¬∑ Œò
(Ô∏Ä
ùêµ(^ùëå, ùëå‚Ä≤, ùõæ, ùúñ)
)Ô∏Ä
,
(2.23)
which can greatly reduce the number of combinations one must calculate by effec-
tively treating the data as known, deterministic, and equal to ùëå‚Ä≤. We will use this
approximation as it does not take away from the main point of this example.
We will use the following numerics. In the completely certain (deterministic)
case, we will let the parameters be the Taylor series coefficients (ùõº1, ùõº2, ùõº3, ùõº4) =
(Ô∏Ä
1, ‚àí1
2!, 1
4!, ‚àí1
6!
)Ô∏Ä
(ùõº4 = 0 for model 1), and in the uncertain case, we let each coefficient
have Gaussian uncertainty centered at their Taylor series coefficients with standard
deviations (ùúéùõº1, ùúéùõº2, ùúéùõº3, ùúéùõº4) = (0.1, 0.05, 0.005, 0.0005) (and where ùúéùõº4 = 0 for model
1). We let each model output path have ùëõ= 50 points and we allow for 20 possible
values per parameter (ùõº1, ùõº2, ùõº3, ùõº4), which results in 203 = 8000 possible paths for
model 1 and 204 = 160, 000 for model 2. We let ùõævary between 75% and 100% using
an increment of 1% and let ùúñvary between 0 and 1 using an increment of 0.01. The
value of ùëöwas chosen to be equal to 5, which imposes that no model path can have
points that are greater than 5ùúñaway while still be considered to agree with the data.
52

The BVM probability of agreement values as a function of the Boolean function
parameters (ùõæ, ùúñ) are plotted in Figure 2-4 for model 1 and model 2 in the completely
certain case:
Figure 2-4: Completely Certain Case: The BVM probability of agree-
ment between each of the models and data plotted in the (ùõæ, ùúñ) space.
Because here the models are deterministic, the BVM probability of agreement
for each (ùõæ, ùúñ) pair is either zero or one. (a) The results for model 1 (4th order
polynomial). (b) The results for model 2 (6th order polynomial). As expected,
model 2 better fits the data in the (ùõæ, ùúñ) space as it has more BVM values equal
to one than model 1, since it is overall closer to the cosine function being the
next nonzero order polynomial in the Taylor series expansion. Neither model fits
the data exactly as the BVM for both models at (ùõæ= 100%, ùúñ= 0) is zero.
For a single (ùõæ, ùúñ) pair, the BVM ratio (a priori the models are assumed to be
equally likely) is,
ùëÖ
(Ô∏Ä
ùêµ(ùõæ, ùúñ)
)Ô∏Ä
= ùëù(ùê¥|ùëÄ1, ùê∑, ùõæ, ùúñ)
ùëù(ùê¥|ùëÄ2, ùê∑, ùõæ, ùúñ),
(2.24)
which, because the numerator and denominator are either 0 or 1 in the deterministic
case, gives ùëÖ
(Ô∏Ä
ùêµ(ùõæ, ùúñ)
)Ô∏Ä
equal to 1, 0, ‚àû, or 0/0 meaning that both models agree, model
1 does not agree but model 2 agrees, model 1 agrees but model 2 does not agree,
or both models disagree, respectively. Thus, the BVM ratio for a single (ùõæ, ùúñ) pair
between two deterministic models with completely certain data is not particularly
insightful since they either agree or do not agree as defined by ùêµ. As it may not
always be clear precisely what values of (ùõæ, ùúñ) one should choose to define agreement,
one can meaningfully average (marginalize, analagous to (2.16)) over a viable volume
53

in the (ùõæ, ùúñ) space, with ùëù(ùõæ, ùúñ) = 1/ùëâ, and arrive at an averaged Boolean BVM ratio,
ùëÖ(ùêµ) =
‚àëÔ∏Ä
ùõæ,ùúñùëù(ùê¥|ùëÄ1, ùê∑, ùõæ, ùúñ)
‚àëÔ∏Ä
ùõæ,ùúñùëù(ùê¥|ùëÄ2, ùê∑, ùõæ, ùúñ) = ùëÅ1ùê¥
ùëÅ2ùê¥
,
(2.25)
which is simply a ratio of the number of agreements found for model 1, ùëÅ1ùê¥, to the
number of agreements found for model 2, ùëÅ2ùê¥, in the selected (ùõæ, ùúñ) volume. In our
deterministic example, ùëÖ(ùêµ) = 1108/2364 = 0.4687 as model 2 better fits the data, as
defined by ùêµ, for the chosen meaningful (ùõæ, ùúñ) volume (which is taken to be the whole
tested volume in this toy example). The BVM ratio or the averaged Boolean BVM
ratio may be used as a guide for selecting models in the deterministic case assuming
that reasonable regions are chosen.
The BVM probability of agreement values as a function of (ùõæ, ùúñ) are plotted in
Figure 2-5 for model 1 and model 2 in the uncertain model case:
Figure 2-5: Uncertain Case: The BVM probability of agreement be-
tween each of the models and the data plotted in the (ùõæ, ùúñ) space.
Because the model paths are uncertain, the BVM probability of agreement for
each (ùõæ, ùúñ) pair may take any value from zero to one. (a) The results for model
1 (4th order polynomial). (b) The results for model 2 (6th order polynomial).
As expected, model 2 better fits the data in the (ùõæ, ùúñ) space as it has generally
larger BVM values than model 1; however, the BVM values are about equal in
cases of large values of ùúñand low values of ùõæ(since the definition of agreement
is less stringent and they both ‚Äúagree‚Äù) and in the case of demanding absolute
equality (ùúñ= 0) as neither model fits the data exactly.
54

The BVM ratios ùëÖ
(Ô∏Ä
ùêµ(ùõæ, ùúñ)
)Ô∏Ä
= ùëù(ùê¥|ùëÄ1, ùê∑, ùõæ, ùúñ)/ùëù(ùê¥|ùëÄ2, ùê∑, ùõæ, ùúñ) for the uncertain
models are plotted as a function of (ùõæ, ùúñ) in Figure 2-6:
Figure 2-6: The BVM ratios for the uncertain models plotted in the
(ùõæ, ùúñ) space. Model 2 is generally favored over model 1 as there exist no values
greater than one on the plot. The amount the BVM ratio favors model 2 over
model 1 decreases (i.e. the ratio increases and tends to one) as the metric
becomes less and less stringent (i.e. as ùõædecreases and ùúñincreases). The ùúñ= 0
line was removed because neither model agrees with the data exactly.
The averaged Boolean BVM ratio for the uncertain models is,
ùëÖ(ùêµ) =
‚àëÔ∏Ä
ùõæ,ùúñùëù(ùê¥|ùëÄ1, ùê∑, ùõæ, ùúñ)
‚àëÔ∏Ä
ùõæ,ùúñùëù(ùê¥|ùëÄ2, ùê∑, ùõæ, ùúñ) = 0.7471,
(2.26)
which conforms to the notion that model 2 is, generally speaking, the preferable model,
and which may be communicated with this single number. We have given examples
of the BVM ratio correctly selecting models according to abstract and new forms of
validation.
55

2.7
Conclusion
This chapter presents the Bayesian Validation Metric (BVM) as a general model
validation and testing tool. This metric is flexible enough to be used in different
contexts for solving model validation problems. The BVM quantifies the probability of
agreement between some model of interest and observed data, according to arbitrary
quantified comparison functions of the model-data comparison values. Further, the
BVM obeys all of the desirable validation criteria [28] and represents all of the standard
validation metrics as special cases and generalizes them. Finally, using the BVM
ratio, one can perform model selection based on arbitrary comparisons and agreement
definitions. In other words, the BVM model testing framework generalizes the Bayesian
model testing framework to arbitrary model-data contexts.
56

Chapter 3
Generalized Bayesian Regression and
Model Learning
3.1
Introduction
In this chapter, we show how the BVM framework can be employed and expanded to
a general calibration and validation framework by proposing a method for generalized
Bayesian regression and model learning [58]. As we will see, this framework allows the
users to perform Bayesian regression on any type of data distribution and based on
arbitrary definitions of model-data agreement. This generalized approach has tackled
some technical gaps that were found in Bayesian and standard regression methods, and
is capable of representing and combining Bayesian regression, standard regression, and
likelihood-based calibration techniques in a single framework. Using this framework,
we give the users new insights into the interpretation of the predictive envelopes and
provide them with more freedom and control over their meaning.
3.2
Background and Motivation
In this section, we will review least squares, likelihood-based, and Bayesian regression
methods and discuss their advantages and disadvantages.
57

3.2.1
Standard Regression
Regression is the process of finding a model that fits some observed data based on a
specific mathematical criterion (through the use of an objective function). Regression
is one of the most important types of data analysis and is frequently used when making
data-driven decisions. The simplest regression technique is linear regression.
Standard regression type methods have several positive and negative attributes.
These methods are relatively easy to implement and can approximate model parameters
even for reasonably high dimensional data and model parameter spaces (given one is not
concerned with parameter or data uncertainty). When the data is uncertain, standard
regression methods can generate parameter estimations along with their variances and
covariances (analytically for simple cases and iteratively regressing randomly sampled
uncertain data in others). In machine learning, it is common practice to regularize the
objective function. Regularizing the objective function introduces bias in which the
parameter estimations change (i.e. become biased estimators), the parameter variances
become reduced, and the model‚Äôs predictive envelope becomes more narrow and less
representative of the data. Although this is not a problem for nonparametric models in
which the parameters do not have physical interpretations, we find that regularization
is problematic for parametric models because these parameters often represent physical
quantities, e.g. the predicted mass of an exoplanet, the predicted circuit resistance due
to the addition of an electrical load, or the predicted stiffness of a beam. It seems more
natural that larger acceptable training errors should be correlated with an increase
in the variance of a parameter rather a decrease because one is admitting that the
model is not perfect. Currently, regularization causes parameters to become biased as
well as ‚Äúmore certain‚Äù because the variance of the regressed model is reduced.
Finally, other than using generalization error type estimates (via training and
testing error statistics), these methods do not offer any other methods for model
selection in which one could easily include their prior knowledge in a principled way.
58

3.2.2
Likelihood-Based Methods
We give a brief review of likelihood-based methods below, but a more elaborate
discussion is located in Appendix B. Likelihood-based methods for calibration and
model learning use the likelihood function ‚Ñí(‚Éóùõº) to learn model parameters. The most
common likelihood-based method is the maximum likelihood method.
These methods have similar advantages and disadvantages to standard regression
methods. Likelihood-based methods do not allow the user to incorporate their prior
knowledge of the model parameters into the framework and, unless there is uncertainty
in the data, the learned parameters are point values. These methods also suffer the
same conceptual issue of interpreting the affect of regularization on parametric models.
One can however learn (or estimate) the prediction uncertainty of the model given
the data.
3.2.3
Bayesian Regression and Model Testing
In this section, we present Bayesian regression and model testing (BMT) while intro-
ducing some probability notations to be used throughout this chapter. In Bayesian
regression, rather than preforming regression to learn the model parameters, one
performs regression to learn the posterior probability distribution of the model pa-
rameters. That is, one estimates a set of parameters ‚Éóùõºin a model (or hypothesis)
ùëÄ‚â°ùëÄ(ùë•; ‚Éóùõº) for the data ùê∑(where ùë•is the model input). The defining equation of
Bayesian regression is the learning of the posterior parameter distribution from the
prior via Bayes‚Äô Rule,
ùúå(‚Éóùõº|ùëÄ)
*
‚àí‚Üíùúå(‚Éóùõº|ùê∑, ùëÄ) = ùúå(ùê∑|‚Éóùõº, ùëÄ) ùúå(‚Éóùõº|ùëÄ)
ùúå(ùê∑|ùëÄ)
,
(3.1)
where, for reasons that will become obvious, we have borrowed the more explicit
notation from Chapter 2. In Bayesian regression and model testing, these probabilities
are named as follows:
ùúå(‚Éóùõº|ùê∑, ùëÄ) ‚â°ùí´(‚Éóùõº) is the posterior probability of the parameter,
59

ùúå(ùê∑|‚Éóùõº, ùëÄ) ‚â°‚Ñí(‚Éóùõº) is the likelihood function,
ùúå(‚Éóùõº|ùëÄ)
‚â°ùúã(‚Éóùõº) is the prior probability,
ùúå(ùê∑|ùëÄ)
‚â°ùíµis the marginal likelihood or Bayesian evidence.
After learning the posterior distribution of the model parameters (given ‚Éóùõºis the vector
of parameters), we can evaluate the predictive distribution defined by:
ùúå(^ùë¶|ùê∑, ùëÄ) =
‚à´Ô∏Å
‚Éóùõº
ùúå(^ùë¶|‚Éóùõº, ùê∑, ùëÄ) ¬∑ ùúå(‚Éóùõº|ùê∑, ùëÄ) ùëë‚Éóùõº.
(3.2)
To perform Bayesian regression, one must calculate the Bayesian evidence, which is
the marginal likelihood over ‚Éóùõº,
ùíµ= ùúå(ùê∑|ùëÄ) =
‚à´Ô∏Å
‚Éóùõº
ùúå(ùê∑|‚Éóùõº, ùëÄ)
‚èü
 ‚èû
 
‚Ñí(‚Éóùõº)
¬∑ ùúå(‚Éóùõº|ùëÄ) ùëë‚Éóùõº
‚èü
 ‚èû
 
ùúã(‚Éóùõº) ùëë‚Éóùõº
.
(3.3)
After performing regression and solving for the model parameters‚Äô values, rather
than selecting the model with the lowest estimated generalization error as is done
in standard regression, one instead uses BMT to select the model with the highest
probability given the data. That is, for two Bayesian regressed models ùëÄ1 and ùëÄ2,
BMT uses the Bayes ratio, ùëÖ, and rank the data-informed posterior model probabilities.
It can be expressed in several ways using Bayes Rule,
ùëÖ‚â°ùëù(ùëÄ1|ùê∑)
ùëù(ùëÄ2|ùê∑) = ùúå(ùê∑|ùëÄ1) ùëù(ùëÄ1)
ùúå(ùê∑|ùëÄ2) ùëù(ùëÄ2) = ùíµ1
ùíµ2
ùëù(ùëÄ1)
ùëù(ùëÄ2).
If there is no reason to suspect that one model is more probable than another prior
to observing the data, we may set the ratio of the prior probabilities of the model
ùëù(ùëÄ1)/ùëù(ùëÄ2) = 1, a priori. In this case one gets,
ùëÖ‚Üíùíµ1
ùíµ2
‚â°ùêæ,
where ùêædenotes the Bayes factor and is the ratio of model evidences. The Bayes
factor is usually more accessible than ùëÖso it is usually used for model selection:
If ùêæ> 1, then the probability of ùëÄ1 given the observed data ùê∑is higher than the
60

probability of ùëÄ2 given ùê∑. In this case, we select model 1.
If ùêæ< 1, then the probability of ùëÄ2 given the observed data ùê∑is higher than the
probability of ùëÄ1 given ùê∑. In this case, we select model 2.
If ùêæ‚âà1, then the probability of ùëÄ1 given the observed data ùê∑is equal to the
probability of ùëÄ2 given ùê∑. In this case, both models are equally good or bad.
Bayesian regression has several positive and negative attributes. As a byproduct,
Bayesian regression can perform model selection in a principled way that allows one
to incorporate their prior knowledge into the selection process using BMT. Because
Bayesian regression requires regressing probability distributions rather than just single
model predictions, it can become intractable to calculate in general if the number
of dimensions are large (as would standard regression if uncertainty is taken into
account). Regularization in Bayesian regression is interpreted as coming from the
uncertainty of the data and the uncertainty present in the prior parameters [4], which
we view as being a potential drawback. If one wants to change the regularization it
would require changing either of these uncertainties, or both, ‚Äúartificially‚Äù because one
would be tuning their prior probabilities after regression, which is a bit anti-Bayesian.
Similar to standard regression, regularization can again lead to an unnatural reduction
of the posterior variances of the parameters for parametric models.
Further, we highlight some technical gaps found in Bayesian regression and model
testing. Although almost all instances of Bayesian regression use data probability
distributions that have infinite tails, truncated (or bounded) data probability density
functions (pdfs) are realistic in practice too. We find that truncated data pdfs are
potentially problematic for Bayesian regression if the model is deterministic. In the
extreme case of completely certain data, Bayesian regression methods usually do not
terminate because the Bayesian evidence is zero in (3.1) since there are no possible
combinations of parameter values that could exactly fit the data. This problem may
also arise if the data uncertainties are bounded. In principle, standard regression
methods can produce a solution regardless of the form of the data pdf. In what follows,
we assume we are given a set of inputs ùëã, a set of data points ùëå= ùê∑, and a set
of model outputs ^ùëå= ùëÄ(ùëã; ‚Éóùõº). All the sets are ùëõ-dimensional. In addition, we
61

assume that the ùëõdata points were collected through independent experiments. We
give explicit examples of the likelihoods below (see Appendix C) given the model is
deterministic:
Infinite Tail Data Distributions
Data distributions with infinite tails result in likelihoods with infinite tails in (3.3).
Some examples of infinite tail data distributions are Gaussian, Student-t, Laplace,
canonical, and Poisson. For example, Gaussian distributed data (see Figure 1-1a)
naturally has an infinite tailed likelihood function,
‚Ñí(‚Éóùõº) =
1
‚àöÔ∏Ä
(2ùúã)ùëõ|Œî|
ùëí‚àí1
2
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº) ‚àíùê∑
)Ô∏ÄùëáŒî‚àí1(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº) ‚àíùê∑
)Ô∏Ä
,
(3.4)
where Œî is the covariance matrix. Since the likelihood has infinite tails, the predicted
model response ùëÄ(ùë•ùëó; ‚Éóùõº) has probabilistic flexibility around its corresponding data
point ùê∑ùëóbecause it is uncertain. Even far from ùê∑, Bayesian regression is capable of
estimating the posterior probability distributions of the model parameters in question
as they are nonzero.
Truncated Tail Data Distributions
Data distributions with truncated tails naturally lead to truncated likelihoods in (3.3).
For example, if the uncertain data is bounded to a region and is uniformly distributed,
i.e. ùê∑ùëó‚àºùí∞(ùëéùëó, ùëèùëó) (see Figure 1-1b), then the likelihood function is,
‚Ñí(‚Éóùõº) =
ùëõ
‚àèÔ∏Å
ùëó=1
Œò
(Ô∏Ä
ùëéùëó‚â§ùëÄ(ùë•ùëó; ‚Éóùõº) ‚â§ùëèùëó
)Ô∏Ä
ùëèùëó‚àíùëéùëó
,
(3.5)
where Œò(¬∑) is the indicator function. In other words, for the likelihood ‚Ñí(‚Éóùõº) to be
nonzero, the predicted model response ùëÄ(ùë•ùëó; ‚Éóùõº) at ùë•ùëómust lie within the interval
[Ô∏Ä
ùëéùëó, ùëèùëó
]Ô∏Ä
for all ùëósimultaneously. The function space defined by the model and uncertain
parameters is constrained by the data. This can make the probability of estimating a
regressed posterior probability distribution of the model parameters very small, and
in some cases impossible, because the likelihood may evaluate to zero for almost all
combinations of ‚Éóùõº.
62

This point is exaggerated if the data is completely certain or deterministic, because
the likelihood function becomes
‚Ñí(‚Éóùõº) = ùõø
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº) ‚àíùê∑
)Ô∏Ä
,
(3.6)
where ùõø(¬∑) is the Dirac delta function. In this case, the model output and observed
data only agree if their values are exactly equal, i.e. ùëÄ(ùëã; ‚Éóùõº) ‚Üíùê∑for all ùëõpoints,
which in most cases, is only possible if we overfit the data or the model is perfect. Thus,
Bayesian regression will usually fail in this case, or if it succeeds, it only produces
singular posterior distributions of the model parameters (i.e. ùúé‚Éóùõº= 0). When Bayesian
regression fails, the Bayesian evidence is zero, which, although correct (the model
does not support/fit the data), may not be the most useful type of answer for the
modeler. It seems reasonable that a modeler would want both the benefits of Bayesian
and standard regression simultaneously.
3.2.4
BVM Model Testing
We recall the Bayesian Validation Metric (BVM) introduced in Chapter 2. The BVM
represents model to data validation in a general way using the probability of agreement,
ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) =
‚à´Ô∏Å
^ùëß,ùëß
ùëù(ùê¥|^ùëß, ùëÄ, ùëß, ùê∑, ùêµ) ¬∑ ùúå(^ùëß, ùëß|ùëÄ, ùê∑) ùëë^ùëßùëëùëß
=
‚à´Ô∏Å
^ùëß,ùëß
ùúå(^ùëß|ùëÄ, ùê∑) ¬∑ Œò
(Ô∏Ä
ùêµ(^ùëß, ùëß)
)Ô∏Ä
¬∑ ùúå(ùëß|ùê∑) ùëë^ùëßùëëùëß,
(3.7)
where ^ùëßand ùëßare the model and data comparison quantities, respectively. The
‚Äúagreement kernel‚Äù ùëù(ùê¥|^ùëß, ùëÄ, ùëß, ùê∑) = Œò
(Ô∏Ä
ùêµ(^ùëß, ùëß)
)Ô∏Ä
is the indicator function of a user
defined boolean function, ùêµ(^ùëß, ùëß), that defines the context of what is meant by ‚Äúmodel
to data agreement‚Äù, by being true when (^ùëß, ùëß) agree or false otherwise. For simplicity,
we will assume ^ùëß‚Üí^ùë¶and ùëß‚Üíùë¶are the model output and observed data respectively.
The BVM model testing framework was shown to generalize BMT where the
probability of agreement plays the role of the evidence,
63

ùíµ(ùêµ) = ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) =
‚à´Ô∏Å
‚Éóùõº
ùëù(ùê¥|‚Éóùõº, ùëÄ, ùê∑, ùêµ)
‚èü
 ‚èû
 
‚Ñí(‚Éóùõº, ùêµ)
¬∑ ùúå(‚Éóùõº|ùëÄ) ùëë‚Éóùõº
‚èü
 ‚èû
 
ùúã(‚Éóùõº) ùëë‚Éóùõº
,
(3.8)
where ùíµ(ùêµ) and ‚Ñí(‚Éóùõº, ùêµ) are the BVM evidence and likelihood, respectively, that have
been modified by a user‚Äôs definition of model-data agreement ùêµ. Equation (3.8) is
a key insight in [58]. Analogous to the Bayesian model testing framework, we can
perform BVM model testing between two models ùëÄ1 and ùëÄ2 using the probability of
agreement defined above as follows:
ùëÖ(ùêµ) ‚â°ùëù(ùëÄ1|ùê¥, ùê∑, ùêµ)
ùëù(ùëÄ2|ùê¥, ùê∑, ùêµ) = ùëù(ùê¥|ùëÄ1, ùê∑, ùêµ) ùëù(ùëÄ1|ùê∑, ùêµ)
ùëù(ùê¥|ùëÄ2, ùê∑, ùêµ) ùëù(ùëÄ2|ùê∑, ùêµ) = ùíµ1(ùêµ)
ùíµ2(ùêµ)
ùëù(ùëÄ1|ùê∑, ùêµ)
ùëù(ùëÄ2|ùê∑, ùêµ),
where ùëù(ùëÄ1|ùê∑, ùêµ)/ùëù(ùëÄ2|ùê∑, ùêµ) is the ratio of prior probabilities of ùëÄ1 and ùëÄ2, which
can often be set to unity, i.e. ùëù(ùëÄ1|ùê∑, ùêµ)/ùëù(ùëÄ2|ùê∑, ùêµ) = 1. In this case, we get
ùëÖ(ùêµ) ‚Üíùëù(ùê¥|ùëÄ1, ùê∑, ùêµ)
ùëù(ùê¥|ùëÄ2, ùê∑, ùêµ) = ùíµ1(ùêµ)
ùíµ2(ùêµ) = ùêæ(ùêµ),
where ùëÖ(ùêµ) denotes the BVM ratio and ùêæ(ùêµ) denotes the BVM factor, which is
analogous to the Bayes factor (as mentioned earlier in Chapter 2).
3.2.5
The Improved Reliability Metric
The reliability metric discussed in [47] is defined as the probability that the mean
of the model prediction is within a tolerance ùúñof the mean of the data. This metric
was later expanded in [51] to consider tolerances between each of the model and data
point pairs, |ùë¶ùëó‚àí^ùë¶ùëó| ‚â§ùúñùëófor ùëó= 1, ..., ùëõ, rather than comparing their means.
Consider a set of inputs ùëã, a set of model outputs ^ùëåand a set of observed data
points ùëå. Assume that all the sets are ùëõ-dimensional and that the data were collected
through independent experiments. The improved reliability metric ùëüùëñis,
ùëüùëñ=
‚à´Ô∏Å
ùëå
ùúå(ùëå|ùê∑)
(Ô∏Ç‚à´Ô∏Åùëå+ùúñ
ùëå‚àíùúñ
ùúå(^ùëå|ùëÄ) ùëë^ùëå
)Ô∏Ç
ùëëùëå,
(3.9)
64

which can always be rewritten as,
ùëüùëñ=
‚à´Ô∏Å
^ùëå,ùëå
ùúå(^ùëå|ùëÄ) ¬∑ Œò
(Ô∏Å‚Éí‚Éí^ùëå‚àíùëå
‚Éí‚Éí‚â§ùúñ
)Ô∏Å
¬∑ ùúå(ùëå|ùê∑) ùëë^ùëåùëëùëå.
(3.10)
This equation may be identified as a special case of the BVM (3.7) when,
Œò(ùêµ(^ùëß, ùëß)) ‚ÜíŒò
(Ô∏Ä
ùêµ(^ùëå, ùëå)
)Ô∏Ä
= Œò
(Ô∏Å‚Éí‚Éí^ùëå‚àíùëå
‚Éí‚Éí‚â§ùúñ
)Ô∏Å
=
ùëõ
‚àèÔ∏Å
ùëó=1
Œò
(Ô∏Å‚Éí‚Éí^ùë¶ùëó‚àíùë¶ùëó
‚Éí‚Éí‚â§ùúñùëó
)Ô∏Å
,
(3.11)
and where ^ùëß= ^ùëå, ùëß= ùëå(see Appendix A.1). Thus, this agreement kernel is based on
the ùúñ-Boolean. From (3.8) (see Appendix D for details), the BVM in this case is,
ùíµ(ùêµ) = ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) =
‚à´Ô∏Å
‚Éóùõº
(Ô∏Ç‚à´Ô∏Å
ùëå
Œò
(Ô∏Å‚Éí‚ÉíùëÄ(ùëã; ‚Éóùõº) ‚àíùëå
‚Éí‚Éí‚â§ùúñ
)Ô∏Å
¬∑ ùúå(ùëå|ùê∑) ùëëùëå
)Ô∏Ç
¬∑ ùúå(‚Éóùõº|ùëÄ) ùëë‚Éóùõº.
(3.12)
The ùúñ-Boolean participates in several of our BVM regression examples in the following
sections and thus reliability is automatically regressed into our model solutions through
the improved reliability metric.
3.3
Generalized Bayesian Regression via the BVM
This section introduces BVM regression, which generalizes Bayesian and standard
regression. This method has the ability to produce posterior parameter distributions
and predictive envelopes for any data distribution, include prior knowledge about
model parameters (if there is any), and regularize parameter solutions in a way that
parameter uncertainty increases rather than decreases (as discussed in Section 3.2.1).
BVM regression consists of learning the posterior of a set of parameters ‚Éóùõº, given
the agreement ùê¥and the Boolean function ùêµ, from the prior via Bayes‚Äô Rule,
ùúå(‚Éóùõº|ùëÄ)
*
‚àí‚Üíùí´(‚Éóùõº|ùê¥) ‚â°ùúå(‚Éóùõº|ùê¥, ùëÄ, ùê∑, ùêµ) = ùëù(ùê¥|‚Éóùõº, ùëÄ, ùê∑, ùêµ) ùúå(‚Éóùõº|ùëÄ)
ùëù(ùê¥|ùëÄ, ùê∑, ùêµ)
.
(3.13)
After learning the posterior distribution of the model parameters, we can evaluate the
predictive distribution defined by:
65

ùëù(^ùë¶|ùê¥, ùëÄ, ùêµ) =
‚à´Ô∏Å
‚Éóùõº
ùëù(^ùë¶|‚Éóùõº, ùê¥, ùëÄ, ùêµ) ¬∑ ùúå(‚Éóùõº|ùê¥, ùëÄ, ùê∑, ùêµ) ùëë‚Éóùõº.
(3.14)
Performing BVM regression requires evaluating the BVM probability of agreement. At
the beginning of Appendix D, we give a derivation showing that (3.8) can be written as,
ùíµ(ùêµ) = ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) =
‚à´Ô∏Å
‚Éóùõº
(Ô∏Ç‚à´Ô∏Å
ùëå
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº), ùëå
)Ô∏Ä)Ô∏Å
¬∑ ùúå(ùëå|ùê∑) ùëëùëå
)Ô∏Ç
¬∑ ùúå(‚Éóùõº|ùëÄ) ùëë‚Éóùõº, (3.15)
which is analogous to (3.3) in form,1 and where the comparison values are ^ùëß= ^ùëå=
ùëÄ(ùëã; ‚Éóùõº) and ùëß= ùëå(we assume we are dealing with a set of inputs, model outputs
(i.e. a set of ùëõpoints on a model curve), and ùëõobserved data points, where all the
data points were collected through independent experiments).
BVM regression can reproduce Bayesian regression, standard regression, and
likelihood-based methods as special cases. When the data and model outputs must
be exactly equal to agree with one another
(Ô∏Ä
i.e. ùõø(^ùëå‚àíùëå)
)Ô∏Ä
, the BVM produces
BMT as a special case and the regression solutions are given in Appendix C. Typical
likelihood-based methods follow from the same ‚Äúexactly equal‚Äù definition of model-
data agreement. We find that the boolean function ùêµùëÜ.ùëÖ(^ùëå(‚Éóùõº*), ùëå) that reproduces
standard regression is defined to be true iff ‚Éóùõº* = argmin
‚Éóùõº
‚Ñ∞
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº), ùëå
)Ô∏Ä
for some
objective function ‚Ñ∞(¬∑). This only gives nonsingular posterior parameter distributions
and predictive model envelopes if the data is uncertain and/or if ‚Ñ∞
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº), ùëå
)Ô∏Ä
does
not have a unique global minimum.
If the objective function is convex, then we have a single minimum which results
in one vector of parameters ‚Éóùõº* that makes ùêµùëÜ.ùëÖ(^ùëå(‚Éóùõº*), ùëå) true. However, when
the cost function is non-convex, then multiple parameter vectors ‚Éóùõº* corresponding
to different local minima, lead to a true ùêµùëÜ.ùëÖ(^ùëå(‚Éóùõº*), ùëå) and may be accepted due
to the approximate nature of non-convex optimization methods. This results in
multiple regressed solutions for the regression problem and approximates the posterior
1In terms of the BVM, the Bayesian evidence in BMT, i.e. Equation (3.3), may be interpreted as
the probability that the uncertain data and model output are exactly equal, i.e. ùúå(ùê∑|ùëÄ) ‚â°ùúå( ^ùëå‚â°
ùëå|ùëÄ, ùê∑) ‚â°ùúå(ùê¥|ùëÄ, ùê∑) which is Equation (C.1) derived in Appendix C.
66

parameters‚Äô distribution ùúå(‚Éóùõº|ùê¥) (analogous to the accepted parameter samples in the
Markov Chain Monte Carlo (MCMC) simulation). Marginalizing leads to the predictive
posterior model distribution ùëù(^ùë¶|ùê¥, ùëÄ, ùêµ) as in (3.14). Finding the predictive model
output average is analogous to the results obtained in the ensemble methods in machine
learning [8]. Because the BVM can reproduce these special cases and generate new
ones by extending, combining, and modulating Boolean agreement functions, BVM
regression may be seen as a generalized regression method.
Due to the flexibility of the BVM framework, there are many possible definitions of
agreement that the user can define. We discussed some of these definitions in Chapter
2. We summarize them in Table 3.1 below.
Agreement Boolean Function
ùúñ‚ÄìBoolean
True iff
‚Éí‚Éíùë¶ùëó‚àíùëÄ(ùë•ùëó; ‚Éóùõº)
‚Éí‚Éí‚â§ùúñùëó‚àÄùëó
(ùõæ, ùúñ, ‚Ñì)‚ÄìBoolean
True iff
‚Éí‚Éíùë¶ùëó‚àíùëÄ(ùë•ùëó; ‚Éóùõº)
‚Éí‚Éí‚â§‚Ñìùúñùëó‚àÄùëóand 1
ùëõ
‚àëÔ∏Ä
ùëóŒò
(Ô∏Å‚Éí‚Éíùë¶ùëó‚àíùëÄ(ùë•ùëó; ‚Éóùõº)
‚Éí‚Éí‚â§ùúñùëó
)Ô∏Å
‚â•ùõæ%
‚ü®ùúñ‚ü©‚ÄìBoolean
True iff 1
ùëõ
‚àëÔ∏Ä
ùëó
‚Éí‚Éíùë¶ùëó‚àíùëÄ(ùë•ùëó; ‚Éóùõº)
‚Éí‚Éí‚â§‚ü®ùúñ‚ü©
(‚ü®ùúñ‚ü©, ^ùõº)‚ÄìBoolean
True iff 1
ùëõ
‚àëÔ∏Ä
ùëó
‚Éí‚Éíùë¶ùëó‚àíùëÄ(ùë•ùëó; ‚Éóùõº)
‚Éí‚Éí‚â§‚ü®ùúñ‚ü©and 0.91 ‚â§1
ùëõ
‚àëÔ∏Ä
ùëóŒò(ùë¶ùëó‚àà[‚àíùëê^ùõº, ùëê^ùõº]ùëó) ‚â§0.99
Table 3.1: Some examples of agreement Boolean functions.
To address the concerns we raised about Bayesian and standard regression depicted
in Figure 1-1, consider using the ùúñ‚àíBoolean with the agreement kernel,
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùë•ùëó; ‚Éóùõº), ùë¶ùëó
)Ô∏Ä)Ô∏Å
=
‚éß
‚é™
‚é®
‚é™
‚é©
1,
if
‚Éí‚Éíùë¶ùëó‚àíùëÄ(ùë•ùëó; ‚Éóùõº)
‚Éí‚Éí‚â§ùúñùëó
0,
otherwise
for all ùëó= 1, . . . , ùëõ, where ùúñùëómay be adjusted and tuned to impose more or less strict
agreement conditions which may be used by the modeler to enforce reliability in some
region or to be more tolerant of training errors at instance ùë•ùëó. For simplicity, We
assume that ùúñùëó= ùúñfor all ùëó. Note that this is (3.11) in Section 3.2.5. In other words,
we use the special case of the BVM, the improved reliability metric with evidence
derived in (3.12), to derive our theoretical solutions.2 Utilizing this BVM definition
allows us to solve the truncated tail data distributions problem in Bayesian regression
2Note that by choosing to adopt a different agreement kernel (or Boolean function) as in Section
3.4.2, we generalize the results derived above; this is the power of the BVM.
67

in a simple way ‚Äì details in Appendix D.3
Truncated Tail Data Distributions Solution Summary
Let the data be known to have the truncated pdf ùë¶ùëó‚àºùí∞(ùëéùëó, ùëèùëó), for ùëó= 1, . . . , ùëõ. By
using the ùúñ-Boolean, we introduce leniency into the regression in that it no longer
needs to exactly pass through all intervals [ùëéùëó, ùëèùëó] simultaneously to count as a ‚Äúfit‚Äù.
This produces likelihood functions such as,
‚Ñí(‚Éóùõº, ùêµ) =
ùëõ
‚àèÔ∏Å
ùëó=1
ùë¢ùëó‚àíùëôùëó
ùëèùëó‚àíùëéùëó
,
(3.16)
where ùëôùëóand ùë¢ùëóare defined by the boundaries of the intersection of the data uncertainty
and the model‚Äôs tolerance ùúñ,
[Ô∏Å
ùëôùëó, ùë¢ùëó
]Ô∏Å
=
[Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) ‚àíùúñ, ùëÄ(ùë•ùëó; ‚Éóùõº) + ùúñ
]Ô∏Å
‚à©
[Ô∏Å
ùëéùëó, ùëèùëó
]Ô∏Å
ùëó= 1, . . . , ùëõ.
An illustration of how the BVM works with truncated data distributions is shown
in Figure 3-1 below. For example, at instance ùë•2, the interval
[Ô∏Ä
ùëô2, ùë¢2
]Ô∏Ä
is found by
intersecting the intervals
[Ô∏Ä
ùëé2, ùëè2
]Ô∏Ä
and
[Ô∏Ä
ùëÄ(ùë•2; ‚Éóùõº) ‚àíùúñ, ùëÄ(ùë•2; ‚Éóùõº) + ùúñ
]Ô∏Ä
. Note that this
applies to the instances ùë•ùëófor all ùëó. In this case, the likelihood is nonzero, resulting in
a nonzero evidence (3.15). Thus, given this agreement definition, the probability of
finding a model given the truncated data is nonzero.
Figure 3-1: Truncated tail data distributions solution. Using BVM re-
gression results in a nonzero probability of finding a model given the observed
truncated data.
3A complete derivation for the infinite tail Gaussian data distribution is given in Appendix D.1.
68

Now, if we consider the special case when the data is completely certain, determin-
istic, i.e. ùëå= ùê∑, then the likelihood function is
‚Ñí(‚Éóùõº, ùêµ) = Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº), ùê∑
)Ô∏Ä)Ô∏Å
,
(3.17)
which can be seen as a relaxed general form of the delta function adopted in the
Bayesian model testing (where ùúñ= 0), which implies that the model output must be
within ùúñfrom the observed measurements in order for them to agree. An analogous
ùúñ-Boolean solution exists for standard regression methods which leads to nonsingular
parameter distributions whether the regression is regularized or not.
Tolerant agreement as a new kind of regularization
The purpose of regularization is to better represent one‚Äôs expectations of unobserved
data using the chosen model or model class. Using BVM regression and nonzero
agreement tolerances (e.g. ùúñ> 0 in the ùúñ-Boolean), we can broaden the model‚Äôs
prediction envelope to better represent our expectations of the data. Increasing
agreement tolerances naturally increases the posterior variance of the parameters,
which differs from standard regularization methods and can be used to avoid conceptual
issues of interpreting regularized physical parameters. It should also be noted that
this is done without changing the prior distributions of the parameters nor the given
probability distributions of the data. This becomes a useful feature in our first example.
3.4
Implementation and Examples
3.4.1
Computing the BVM Evidence
Like the Bayesian evidence, the BVM evidence is computationally expensive to
calculate when one has many model parameters to learn. Several approaches were
adopted to solve this problem. Markov Chain Monte Carlo (MCMC) is a computational
technique used for Bayesian methods that has been widely studied and improved
[6, 17, 35, 37, 42, 48] as it is considered an indispensable tool for Bayesian inference.
69

Other techniques include the Nested Sampling method [10, 54] and the MultiNest
algorithm [11].
We will approximate the BVM evidence and generate the posterior model parameter
distributions (for the purpose of generating model‚Äôs predictive envelopes) using MCMC.
MCMC takes the following inputs: the likelihood function ‚Ñíand the prior distribution
ùúãof the model parameters, a model ùëÄand a set of input/output data points {ùëã, ùëå}.
The Bayesian terms (ùíµ, ‚Ñí) have analogous BVM terms (ùíµ(ùêµ), ‚Ñí(ùêµ)) and it is therefore
straightforward to extend the MCMC algorithm to BVM calculations to obtain
posterior parameter distributions. These distributions are used to generate a model‚Äôs
predictive envelope.
Any adaptation to the standard MCMC algorithm will be
discussed in text with their corresponding example.
3.4.2
BVM Regression Examples
Exploratory Example 1
We consider the case study investigated in [3] using a bacterial growth model. The
data is obtained by operating a continuous flow biological reactor at steady-state
conditions. The observations are as follows:
ùë•(mg/L COD)
28
55
83
110
138
225
375
ùë¶(1/h)
0.053
0.060
0.112
0.105
0.099
0.122
0.125
Table 3.2: The observations we aim to fit.
where ùë¶is the growth rate at substrate concentration ùë•. We replicate the results found
in [3] using the nonlinear Monod model to fit the data, i.e,
^ùë¶= ùëÄ(ùë•; ‚Éóùõº) =
ùõº1ùë•
ùõº2 + ùë•
(3.18)
where ùõº1 is the maximum growth rate (h‚àí1: per hour), and ùõº2 is the saturation
constant (mg/L COD: the Chemical Oxygen Demand, measured in milligrams per
liter).
70

We run MCMC on the likelihoods derived in (3.16) and (3.17) corresponding to the
different types of data distributions discussed above, i.e. bounded or truncated uniform
data distributions, and completely certain observation points (we also consider normal
or Gaussian data distributions with infinite tails). We assume that the vector of
parameters ‚Éóùõºhas some Gaussian prior distribution. We use the ùúñ‚àíBoolean agreement
function and find that BVM regression is able to construct posterior inferences of the
model parameters for each type of data measurement distributions, unlike Bayesian
model testing and standard regression techniques that fail at this task for truncated
and completely certain data, as discussed before. We summarize the results in Table
3.3 below.
Data Distribution
BVM regression
Standard regression
Bayesian regression
Infinite Tail



Truncated Tail



Completely Certain



Table 3.3: High probability of the model producing posterior parameter distribu-
tions and predictive envelopes for different types of data distributions using the
three approaches. BVM regression is capable of producing posterior distributions
of the model parameters for any type of data distributions.
Using the BVM regressed parameters‚Äô distributions, we can make predictions of
ùë¶for new values of ùë•, i.e., ùëù(^ùë¶|ùê¥, ùëÄ, ùêµ) from (3.14). In addition, instead of just
computing a point estimate of the fit, we should also study the predictive posterior
distribution of the model, (also called the predictive envelope). As an illustration
of the predictive posterior distribution of our BVM regressed model, we plot the
predictive envelopes of the nonlinear Monod model described in (3.18), treating the
data as completely certain and using the ùúñ-Boolean function with a tolerance ùúñ= 0.03.
71

Figure 3-2: Predictive envelopes of the model in the absence of data
uncertainty using the BVM. As tabulated in Table 3.3, Bayesian regression
fails to produce a candidate model solution as the data is completely certain
and standard regression produces a single deterministic solution with no model
uncertainty.
The black curve shows the predicted response, which is the model fit calculated
using the mean values of the parameters ùõº1 and ùõº2 in the chain. The gray shaded areas
correspond to 50%, 90%, 95%, and 99% predictive posterior regions (by computing
the model fit for a randomly selected subset of the chain). In other words, the gray
regions span 0.675, 1.645, 2, 3 standard deviations on either side of the mean response,
respectively. We will leave the interpretation of the predictive envelopes for our
compound Boolean agreement function example in Section 3.4.2.
The value of the tolerance ùúñchosen affects the shape of the model parameters‚Äô
distributions and thus the predictive envelope. A smaller tolerance implies stricter
agreement conditions between the model response and the observed data, which results
in less uncertainty in the predictive posterior distributions of the model parameters
and a narrower envelope. On the other hand, a larger tolerance implies a more flexible
agreement conditions, and results in more uncertainty in the predictive distributions,
a wider envelope and a less predictive power. Thus, increasing ùúñcan always result in
finding a model given the data. To avoid getting very wide envelopes relative to the
72

spread of the data, we start with a very small ùúñwhen running the MCMC simulation.
We then keep increasing ùúñuntil the MCMC algorithm starts achieving a reasonably
small acceptance rate for the new candidates in the chain.
Since this model has just two adaptive parameters, namely ùõº1 and ùõº2, we can
plot the prior and posterior distributions directly in parameter space. We explore
the dependence between the parameters‚Äô posterior distributions and the value of the
tolerance ùúñ. Figure 3-3 shows the results of BVM learning for the Monod model in
(3.18) as the value of ùúñis decreased. For comparison, the optimal parameter values
ùõº1 = 0.14542 and ùõº2 = 49.053 computed using standard regression are shown by a
yellow cross in the first row of Figure 3-3.
Figure 3-3: Illustration of BVM Learning for the Monod model for
decreasing values of ùúñ.
In the first row is the prior/posterior parameter
distribution in (ùõº1, ùõº2) space. The data points are shown by a blue circle in the
second row. The first column corresponds to the situation before any data point
is observed and shows a plot of the prior distribution in (ùõº1, ùõº2) space together
with six samples of the model response ùëÄ(ùë•; ‚Éóùõº) (red lines) in which the values of
ùõº1 and ùõº2 are randomly drawn from the prior. In the second, third and fourth
columns, we see the situation after running our BVM learning using MCMC,
with a tolerance ùúñ= 0.03, ùúñ= 0.025 and ùúñ= 0.02, respectively. The posterior
has now been influenced by the agreement tolerance ùúñ, this gives a relatively
compact posterior distribution. Samples from this posterior distribution lead to
the functions shown in red in the second row.
As Figure 3-3 shows, the smaller the tolerance is, the narrower and sharper the
posterior distributions of the parameters are, the closer the red lines get to each other,
and the lower the uncertainty is. This explains the shape of the predictive envelopes as
was discussed before. Thus, by varying ùúñ, one can tune the model response posterior
73

distribution to be more or less representative of the data. We will elaborate more
on this in Section 3.4.3. Note that in our example, when ùúñgoes below about 0.017,
no solution seems to be possible and hence the probability of finding a model given
the observed data becomes zero. In this case, the analyst may choose to work with
any tolerance beyond this threshold, depending on his specifications and agreement
requirements.
Once we generate the posterior distributions of the model parameters and the
predictive envelopes, we can measure and estimate the reliability and accuracy of our
computational model using a validation metric (including the BVM). By doing so, we
determine how accurate is our model representation of the real world.
Exploratory Example 2
After showing how the BVM can be used to perform regression on any type of data
distribution to generate posterior model parameters‚Äô distributions and predictive
envelopes, we now focus on how the user can choose the Boolean function to define
the model-data agreement.
In this example, we will use the compound Boolean as presented in Chapter 2,
Section 2.6.2.4 In that case, the definition of agreement requires the model to pass
an average square error threshold of ‚ü®ùúñ‚ü©as well as a check for probabilistic model
configuration. The latter states that 95% ¬± 4% of the uncertain observations (data)
should lie inside the model‚Äôs 1‚àí^ùõº= 95% confidence interval. Note that we impose the
¬±4% tolerance to prevent the scenario where all 100% of the data points lie within an
overly wide confidence interval, being marked as ‚Äúagreeing‚Äù. We denote this compound
Boolean function by ùêµ(^ùëå, ùëå, ‚ü®ùúñ‚ü©, ^ùõº) and it is equal to,
ùêµ
(Ô∏Ç1
ùëõ
‚àëÔ∏Å
ùëñ
|^ùë¶ùëñ‚àíùë¶ùëñ| ‚â§‚ü®ùúñ‚ü©
)Ô∏Ç
‚àßùêµ
(Ô∏Ç
0.91 ‚â§1
ùëõ
‚àëÔ∏Å
ùëñ
Œò(ùë¶ùëñ‚àà[‚àíùëê^ùõº, ùëê^ùõº]ùëñ) ‚â§0.99
)Ô∏Ç
,
(3.19)
where ùëõis the number of data points in the set ùëå, and [‚àíùëê^ùõº, ùëê^ùõº]ùëñis the model‚Äôs 95%
confidence interval at instance ùë•ùëñ(this is the (‚ü®ùúñ‚ü©, ^ùõº)‚ÄìBoolean function in Table 3.1).
4It should be noted that in Chapter 2, a model is simply validated according to this compound
metric ‚Äì here we calibrate the model with respect to it instead.
74

Note that, although this compound Boolean seems to be complex, it is relatively easy
to code and implement.
The BVM probability of agreement in this case can be expressed as,
ùíµ(ùêµ) = ùëù(ùê¥|ùëÄ, ùê∑, ùêµ, ‚ü®ùúñ‚ü©, ^ùõº) =
‚à´Ô∏Å
‚Éóùõº
(Ô∏Ç‚à´Ô∏Å
ùëå
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº), ùëå, ‚ü®ùúñ‚ü©, ^ùõº
)Ô∏Ä)Ô∏Å
¬∑ ùúå(ùëå|ùê∑) ùëëùëå
)Ô∏Ç
‚èü
 ‚èû
 
‚Ñí(‚Éóùõº, ùêµ)
¬∑ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
Note that the likelihood ‚Ñí(‚Éóùõº, ùêµ) can be expressed as an expectation value over ùúå(ùëå|ùê∑),
‚Ñí(‚Éóùõº, ùêµ) = ùê∏
[Ô∏Å
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº), ùëå, ‚ü®ùúñ‚ü©, ^ùõº
)Ô∏Ä)Ô∏Å]Ô∏Å
‚àº1
ùêæ
ùêæ
‚àëÔ∏Å
ùëò=1
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº), ùëå(ùëò), ‚ü®ùúñ‚ü©, ^ùõº
)Ô∏Ä)Ô∏Å
,
(3.20)
where ùëå(ùëò) denotes the ùëòùë°‚Ñéset of data points drawn randomly from the probability
distribution of ùëå. This allows us to approximate the integral using a statistical method
like Monte-Carlo (MC). In this example, we use MC with ùêæ= 50.
We implement the compound Boolean, ùêµ(^ùëå, ùëå, ‚ü®ùúñ‚ü©, ^ùõº), and show its ability to com-
bine and quantify the average error as well as the probabilistic model representation
of the uncertain data observations. We generated data using,
ùë¶(ùë•) = 1 + ùë•ùëí‚àícos (10ùë•) + sin (10ùë•) + ùúñùëé(ùë•),
where ùúñùëé(ùë•) ‚àºùí©(0, 0.42) for ùë•‚àà[0, 1.5] and ùúñùëé(ùë•) ‚àºùí©(0, 0.62) for ùë•‚àà[1.5, 3], which
represents the aleatoric stochastic uncertainty due to the system‚Äôs randomness. We
also assume the presence of epistemic measurement uncertainty in the data [50] with
an additional normal distribution ùí©(0, 0.52) about each data point.
To solve this example, we consider the following deterministic non-linear model,
^ùë¶= ùëÄ(ùë•; ‚Éóùõº) = ùõº1 + ùõº2ùë•ùëí‚àíùõº3 cos (ùõº4ùë•) + ùõº5 sin (ùõº6ùë•),
(3.21)
where ‚Éóùõº= (ùõº1, ùõº2, ùõº3, ùõº4, ùõº5, ùõº6) is the vector of model parameters having normally
distributed prior distributions with means ùúá‚Éóùõº= (0, 0, 0, 9, 0, 9) and standard deviations
ùúé‚Éóùõº= (1, 1, 1, 0.5, 1, 0.5). We then conduct two experimental simulations. We first
75

run the MCMC algorithm for 5000 iterations with 10% burn-in using Bayesian
regression and plot the results in Figure 3-4a. We then repeat the simulation using
the approximate likelihood ‚Ñí(‚Éóùõº, ùêµ) from (3.20) with a threshold of ‚ü®ùúñ‚ü©= 0.7. The
results are shown in Figure 3-4b.
(a) Bayesian regression.
(b) BVM regression.
Figure 3-4: Comparison between Bayesian regression and BVM regres-
sion. (a) Bayesian regression under infinite tail data distribution. Note that the
95% confidence interval is very narrow and standard regression method produces
a nearly identical result. (b) BVM regression using the compound Boolean. In
this case, the 95% confidence region is much wider and represents the data more
accurately. Note that this probabilistic model passes both agreement conditions
imposed by the compound Boolean ùêµ( ^ùëå, ùëå, ‚ü®ùúñ‚ü©, ^ùõº). Starting with a very small
‚ü®ùúñ‚ü©in the MCMC simulation, we tune ‚ü®ùúñ‚ü©by gradually increasing its value until
both elements of the compound Boolean are naturally satisfied.
The BVM regression framework offers new insights into the interpretation of the
predictive envelopes of Bayesian and standard regression. It is clear in Figure 3-4a
that the Bayesian and standard regression methods generate predictive envelopes that
would not accurately predict new target points. Surprisingly, these envelopes actually
quantify the uncertainties in the least square error solution due to the presence of
data uncertainty rather than a measure of predictive uncertainty. By being careful
in how we define the model-data agreement (as in Figure 3-4b), we were able to
construct predictive envelopes that satisfy our desire in representing new target points
probabilistically. In other words, using the BVM regression framework gives the user
more control over the predictive envelopes and what uncertainties they represent.
76

3.4.3
Discussion
As we have shown in the exploratory examples above, the results are sensitive to the
tolerance ùúñ. This arises from the fact that ùúñrepresents the modeler‚Äôs tolerance on
the difference between the model outputs and the observed data. Thus, any other
parameter that is included in the Boolean function ùêµdefined by the modeler will have
an effect on the parameters‚Äô posterior distributions and the predictive envelopes. As
shown in the previous examples, we can take advantage of this feature for modeling.
We analyse the effect of the tolerance ùúñas follows.
Changing the agreement
tolerance ùúñaffects the acceptance rate in the MCMC iterations, i.e. a larger tolerance
yields a larger variance of accepted ‚Äúcandidate‚Äù samples. The increased variance in the
accepted samples produces wider posterior model parameter distributions. A smaller
tolerance implies the converse.
Parameters not regressed inside the Boolean function ùêµ(ùúñin this case) play a role
similar to hyperparameters in Machine Learning. By tuning the hyperparameters,
the modeler can make the predictive envelopes more representative of the data, and
improve the overall performance of the model when compared to a randomly selected
test (or validation) data set.
Note that in the case of the ùúñ‚ÄìBoolean, the user can increase ùúñindefinitely and still
‚Äúregress‚Äù the model; although the predictive envelopes will be much wider than the
data spread and hence less representative of the data. While widening the predictive
envelopes can be useful for reliability and safety, if they are widened too much, the
model can lose some of its predictive utility. To balance the trade-off between safety
and utility, we regressed the model in (3.21) with respect to the compound Boolean
(3.19) in Section 3.4.2. This Boolean forced the model to be regressed in such a way
that 95%¬±4% of the (uncertain) data points lie within the model‚Äôs 95% confidence
region while simultaneously satisfying the ‚ü®ùúñ‚ü©requirement (for diversity we used ‚ü®ùúñ‚ü©
instead of ùúñalthough nothing prevents us from doing so in principle). As stated in the
caption of Figure 3-4, we gradually tuned the value of ‚ü®ùúñ‚ü©(hyperparameter tuning) to
simultaneously satisfy both requirements imposed by the compound Boolean function.
77

3.5
Conclusion
This chapter presents a generalized Bayesian regression and model learning technique
that is capable of probabilistically regressing (learning) model parameter distributions
while satisfying arbitrary definitions of model-data agreement within the BVM frame-
work. Using this technique, we can perform Bayesian regression based on any type of
data distribution and construct predictive envelopes that are more representative of
the data, which improves the overall performance of the model under question.
78

Chapter 4
Conclusions and Recommendations
4.1
Conclusions
This thesis presents the BVM, a general model validation and testing tool. We demon-
strated the versatility of the BVM toward expressing and solving model validation and
calibration problems. The BVM quantifies the probability that a model is valid for
arbitrary quantifiable definitions of model-data agreement using arbitrary comparison
functions of the model-data comparison values. The BVM was shown: to obey all of
the desired validation metric criteria [28] (which is a first), to be able to represent
all of the standard validation metrics as special cases, to supply improvements and
generalizations to those special cases, and to be a tool for quantifying the validity of a
model in novel model-data contexts. The latter was demonstrated by the validation
metrics we invented and quantified in our examples.
In addition, it was shown that one can perform model selection using the BVM
ratio. The BVM model testing framework was shown to generalize the Bayesian model
testing framework to arbitrary model-data contexts and with reference to arbitrary
comparisons and agreement definitions. That is, the BVM ratio may be used to rank
models directly in terms of the relevant model-data validation context. The problem
of model-data validation may be reduced to the problem of finding/defining the four
BVM inputs: (^ùëß, ùëß), ùúå(^ùëß, ùëß|ùëÄ, ùê∑), ùëì(^ùëß, ùëß), and ùêµ(ùëì), and computing their BVM value.
We find that the BVM is a useful tool for performing model validation and testing.
79

Finally, the BVM framework can be expanded to probabilistically regress model
parameter distributions that satisfy arbitrary definitions of agreement. Particularly, in
the calibration stage of model development, we can use the BVM to perform regression
and model learning on data with any type of uncertainty, generate posterior parameter
distributions, and model predictive envelopes, according to user-specified definitions
of model-data agreement. The BVM regression framework proved its potential in
offering new insights into the interpretation of the predictive envelopes of the Bayesian
regression, standard regression, and likelihood-based techniques, and hence providing
the analyst with more freedom and control over the predictive envelopes and their
meaning.
In short, we find the BVM to constitute a generalized framework for
probabilistic model calibration and validation allowing us to address several potential
shortcomings in the calibration and validation techniques found in the literature.
4.2
Recommendations
We provide some suggestions for researchers who are interested in building on the
contributions discussed in this thesis to improve and advance this area of research.
All the work presented in this thesis relies heavily on parametric models. Thus,
one possible future research topic is to expand the BVM framework to nonparametric
regression (e.g. Gaussian processes). Another line of research involves developing
neural networks within the BVM framework. Particularly, one can investigate and
explore ways to integrate the BVM probability of agreement into the loss function of
the neural networks.
Because the BVM is an open framework where the definition of agreement is
composable and user-defined, there is room for the quantification of further agree-
ment/validation requirements as the need arises in data analysis and model reliability.
Finally, we emphasize the importance of practicing statistical responsibility by
being explicit in the definition of agreement between the models and data in the field
of reliability. The BVM framework forces the modeler to be explicit in their definitions,
assumptions, and criteria when performing model calibration and validation.
80

Appendix A
Representing the Known Validation
Metrics with the BVM
In the following sections, we will show some of the special cases of the Bayesian
Validation Metric (BVM). Subsequent improvements or immediate generalizations
of the metrics using (2.2) are presented when applicable. A detailed review of the
majority of these metrics may be found in [28] and the references therein. Tables 2.1
and 2.2 in Section 2.5 outline the results.
A.1
Reliability Metric and Probability of Agreement
There are a few validation metrics related to the reliability metric present in the
literature. The reliability metric ùëü= ùëù(|‚ü®^ùë¶‚ü©‚àíùúáùë¶| < ùúñ) [47] is equal to the probability
that the data and the model expectation values are within a tolerance of size ùúñ.
Their ‚Äúprobability of agreement‚Äù introduced in [57] is closely related to ùëü, but instead
expresses the quantity as ‚Äúthe probability the data and the model expectation values
agree within a tolerance (or sliding tolerance) of ùúñ‚Äù. The reliability metric was expanded
in [51] to account for model outputs and data rather than simply comparing the mean
of the model prediction against the mean of the data. The improved reliability metric
81

is equal to,
ùëüùëñ=
‚à´Ô∏Å‚àû
‚àí‚àû
ùúå(ùëå|ùê∑)
‚à´Ô∏Åùëå+ùúñ(ùëå)
ùëå‚àíùúñ(ùëå)
ùúå(^ùëå|ùëÄ) ùëë^ùëåùëëùëå,
(A.1)
where ùúå(^ùëå|ùëÄ) and ùúå(ùëå|ùê∑) are the full joint probability distributions of the model
outputs and the data, respectively. This metric quantifies the probability that the
error is less than a value ùúñ(ùë¶) on a point to point basis.
The BVM is the reliability metric when the comparison values are ^ùëß= ‚ü®^ùë¶‚ü©and
ùëß= ùúáùë¶, and ùêµtakes the form of an inequality, being true if ‚àíùúñ‚â§‚ü®^ùë¶‚ü©‚àíùúáùë¶‚â§ùúñ. If we
would like to use a sliding interval of ‚Äútolerance‚Äù or ‚Äúerror acceptance‚Äù, denote it by
[Ô∏Ä
ùëê‚àí(ùúáùë¶), ùëê+(ùúáùë¶)
]Ô∏Ä
, where ùëê‚àí< ùëê+, and the BVM is,
ùëù(ùê¥|ùëÄ, ùê∑)
=
‚à´Ô∏Å
‚ü®^ùë¶‚ü©,ùúáùë¶
ùúå(‚ü®^ùë¶‚ü©|ùëÄ) ¬∑ Œò
(Ô∏Å
ùëê‚àí(ùúáùë¶) ‚â§‚ü®^ùë¶‚ü©‚â§ùëê+(ùúáùë¶)
)Ô∏Å
¬∑ ùúå(ùúáùë¶|ùê∑) ùëë‚ü®^ùë¶‚ü©ùëëùúáùë¶
=
‚à´Ô∏Å
ùúáùë¶
‚à´Ô∏Åùëê+(ùúáùë¶)
‚ü®^ùë¶‚ü©=ùëê‚àí(ùúáùë¶)
ùúå(‚ü®^ùë¶‚ü©|ùëÄ) ¬∑ ùúå(ùúáùë¶|ùê∑) ùëë‚ü®^ùë¶‚ü©ùëëùúáùë¶= ùëü.
(A.2)
This is the reliability metric if ùëê¬± = ùúáùë¶¬± ùúñis a constant and the sliding interval is
symmetric about ùúáùë¶.
The BVM is the improved reliability metric when ^ùëß= ^ùëå, ùëß= ùëå, and when the
Boolean ùêµ(^ùëß, ùëß) is true iff |^ùë¶‚àíùë¶| ‚â§ùúñ(ùë¶) for all ^ùë¶, ùë¶pairs. That is,
ùëù(ùê¥|ùëÄ, ùê∑) =
‚à´Ô∏Å
^ùëå,ùëå
ùúå( ^ùëå|ùê∑) ¬∑ ùúå(ùëå|ùëÄ) ¬∑
(Ô∏Å
‚àèÔ∏Å
^ùë¶,ùë¶pairs
Œò
(Ô∏Ä
|^ùë¶‚àíùë¶| ‚â§ùúñ(ùë¶)
)Ô∏Ä)Ô∏Å
ùëë^ùëåùëëùëå= ùëüùëñ.
(A.3)
The BVM quantifies the probability of square error (or difference) is less than
some ùúñby considering,
ùëù(ùê¥|ùëÄ, ùê∑) =
‚à´Ô∏Å
^ùëå,ùëå
ùúå(^ùëå|ùê∑) ¬∑ Œò
(Ô∏Ä
|^ùëå‚àíùëå| ‚â§ùúñ
)Ô∏Ä
¬∑ ùúå(ùëå|ùëÄ) ùëë^ùëåùëëùëå.
(A.4)
Nothing in the BVM requires the variables to be continuous or ordered, so the
natural generalization is to let the Boolean expression be true if ‚ÄúThe value ^ùëßis in the
subset ùëÜ(ùëß), which is the set of ^ùëß‚Äôs agreeing with ùëß‚Äù. For example, if ^ùëß‚Äôs are strings,
82

ùëÜ(ùëß) might be the set of words or phrases in ^ùëßthat are reasonably synonymous with
ùëß. This gives the straightforward generalization to accommodate arbitrary data types,
ùëù(ùê¥|ùëÄ, ùê∑) =
‚àëÔ∏Å
^ùëß,ùëß
ùëù(^ùëß|ùëÄ) ¬∑ Œò
(Ô∏Ä
^ùëß‚ààùëÜ(ùëß)
)Ô∏Ä
¬∑ ùëù(ùëß|ùê∑) =
‚àëÔ∏Å
ùëß
‚àëÔ∏Å
^ùëß‚ààùëÜ(ùëß)
ùëù(^ùëß|ùëÄ) ¬∑ ùëù(ùëß|ùê∑), (A.5)
by using sets rather than intervals.
A.2
Frequentist Validation Metric
To include the frequentist validation metric in the BVM, we will have to express
the comparison variables ^ùëßand ùëßand their respective probabilities. The result can
be replicated by letting: ùëß= ùúáùë¶be the Student‚Äôs ùë°-distribution and ^ùëß= ‚ü®^ùë¶‚ü©have a
Dirac delta distribution ùúå(^ùëß|ùëÄ, ùê∑) = ùúå(‚ü®^ùë¶‚ü©|ùëÄ, ùê∑) = ùõø
(Ô∏Ä
‚ü®^ùë¶‚ü©‚àí‚ü®^ùë¶‚ü©‚Ä≤)Ô∏Ä
where ‚ü®^ùë¶‚ü©‚Ä≤ is the
known value of the computational model‚Äôs expected output. Because the frequentist
validation metric does not force the modeler to define what is meant by agreement,
we represent this freedom by keeping ùêµ(^ùëß, ùëß) general. This gives,
ùëù(ùê¥|ùëÄ, ùê∑)
=
‚à´Ô∏Å
^ùëß,ùëß
ùúå(^ùëß|ùëÄ, ùê∑) ¬∑ Œò
(Ô∏Ä
ùêµ(^ùëß, ùëß)
)Ô∏Ä
¬∑ ùúå(ùëß|ùê∑) ùëë^ùëßùëëùëß
=
‚à´Ô∏Å
‚ü®^ùë¶‚ü©,ùúáùë¶
ùõø
(Ô∏Ä
‚ü®^ùë¶‚ü©‚àí‚ü®^ùë¶‚ü©‚Ä≤)Ô∏Ä
¬∑ Œò
(Ô∏Å
ùêµ
(Ô∏Ä
‚ü®^ùë¶‚ü©, ùúáùë¶
)Ô∏Ä)Ô∏Å
¬∑
(Ô∏É
Œì( ùúà+1
2 )
‚àöùúàùúãŒì( ùúà
2)
(Ô∏Ç
1 + (ùúáùë¶‚àíùë¶)2
ùúàùë†2/ùëÅ
)Ô∏Ç‚àíùúà+1
2 )Ô∏É
ùëë‚ü®^ùë¶‚ü©ùëëùúáùë¶,
where ùë¶(the population average), ùë†(the population standard deviation), and ùúà(the
degrees of freedom) are the parameters of the data‚Äôs ùë°-distribution. Making the
coordinate transformations ‚ü®^ùë¶‚ü©‚Üíùê∏= ‚ü®^ùë¶‚ü©‚àíùë¶and ùúáùë¶‚Üíùê∏= ‚ü®^ùë¶‚ü©‚àíùúáùë¶gives,
ùëù(ùê¥|ùëÄ, ùê∑)
=
‚à´Ô∏Å
ùê∏,ùê∏
ùõø
(Ô∏Ä
ùê∏‚àíùê∏
‚Ä≤)Ô∏Ä
¬∑ Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùê∏, ùê∏
)Ô∏Ä)Ô∏Å
¬∑
(Ô∏É
Œì(ùúà+1
2 )
‚àöùúàùúãŒì(ùúà
2)
(Ô∏Ç
1 + (ùê∏‚àíùê∏)2
ùúàùë†2/ùëÅ
)Ô∏Ç‚àíùúà+1
2
)Ô∏É
ùëëùê∏ùëëùê∏
=
Œì(ùúà+1
2 )
‚àöùúàùúãŒì(ùúà
2)
‚à´Ô∏Å
ùê∏‚Ä≤ Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùê∏
‚Ä≤, ùê∏‚Ä≤)Ô∏Ä)Ô∏Å
¬∑
(Ô∏Ç
1 + (ùê∏‚Ä≤ ‚àíùê∏
‚Ä≤)2
ùúàùë†2/ùëÅ
)Ô∏Ç‚àíùúà+1
2
ùëëùê∏‚Ä≤,
(A.6)
with ùê∏
‚Ä≤ = ‚ü®^ùë¶‚ü©‚Ä≤ ‚àíùë¶and ùê∏‚Ä≤ = ‚ü®^ùë¶‚ü©‚Ä≤ ‚àíùúáùë¶.
Given that judgments of agreement in
the frequentist validation metric are expected to be made based on the confidence
level 1 ‚àíùõºthat ùê∏‚Ä≤ is within the confidence interval, this may be factored into
ùêµ
(Ô∏Ä
ùê∏
‚Ä≤, ùê∏‚Ä≤)Ô∏Ä
‚Üíùêµ
(Ô∏Ä
ùê∏
‚Ä≤, ùê∏‚Ä≤, ùõº
)Ô∏Ä
, as well as other user-defined terms toward expressing
83

agreement. Equation (A.6) is thought to be the full BVM representation of the
frequentist validation metric.
The immediate generalization to the frequentist validation metric offered by the
BVM is to let the model output expectation value ^ùëß= ‚ü®^ùë¶‚ü©have some amount of
uncertainty. The uncertainty is perhaps Gaussian or Student‚Äôs ùë°-distributed in ùúá‚ü®^ùë¶‚ü©
(the true model expectation value) due to only having a finite number of Monte Carlo
samples and/or uncertainty induced by discretization error. Because ^ùëß= ùúá‚ü®^ùë¶‚ü©and
ùëß= ùúáùë¶are both uncertain in general, one generalizes to,
ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) =
‚à´Ô∏Å
ùúá‚ü®^ùë¶‚ü©,ùúáùë¶
ùúå(ùúá‚ü®^ùë¶‚ü©|ùëÄ, ùê∑) ¬∑ Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùúá‚ü®^ùë¶‚ü©, ùúáùë¶
)Ô∏Ä)Ô∏Å
¬∑ ùúå(ùúáùë¶|ùê∑) ùëëùúá‚ü®^ùë¶‚ü©ùëëùúáùë¶.
(A.7)
It is interesting to note the consequence of defining a reasonable Boolean expression
of agreement on the BVM representation of the frequentist metric. A natural agreement
function ùêµfor the metric is one that is true if ùê∏ùúá= |ùúá‚ü®^ùë¶‚ü©‚àíùúáùë¶| ‚â§ùúñ.
The BVM then gives,
ùëù(ùê¥|ùëÄ, ùê∑)
=
‚à´Ô∏Å
ùúá‚ü®^ùë¶‚ü©,ùúáùë¶
ùúå(ùúá‚ü®^ùë¶‚ü©|ùëÄ, ùê∑) ¬∑ Œò
(Ô∏Ä
ùê∏ùúá‚â§ùúñ
)Ô∏Ä
¬∑ ùúå(ùúáùë¶|ùê∑) ùëëùúá‚ü®^ùë¶‚ü©ùëëùúáùë¶
=
‚à´Ô∏Å
ùúá‚ü®^ùë¶‚ü©
‚à´Ô∏Å
ùúáùë¶=ùúá‚ü®^ùë¶‚ü©¬±ùúñ
ùúå(ùúá‚ü®^ùë¶‚ü©|ùëÄ, ùê∑) ¬∑ ùúå(ùúáùë¶|ùê∑) ùëëùúá‚ü®^ùë¶‚ü©ùëëùúáùë¶= ùëü.
(A.8)
Thus, the frequentist validation metric is the reliability metric [47] and the ‚Äúproba-
bility of agreement‚Äù [57] when reasonable accuracy requirements are imposed on the
acceptable difference between the expectation values.
A.3
Area and Binned Probability Difference Metric
The BVM is able to represent and generalize the area metric by letting the comparison
values (^ùëß, ùëß) be the cumulative distribution functions (cdfs) in question to be compared
(ùêπ(^ùë¶|ùëÄ), ùêπ(ùë¶|ùê∑)). The area metric is,
ùëë
[Ô∏Ä
ùêπ(^ùë¶|ùëÄ), ùêπ(ùë¶|ùê∑)
]Ô∏Ä
=
‚à´Ô∏Å‚àû
‚àí‚àû
‚Éí‚Éíùêπ(^ùë¶|ùëÄ) ‚àíùêπ(ùë¶= ^ùë¶|ùê∑)
‚Éí‚Éíùëë^ùë¶.
(A.9)
84

The area metric may be represented by the BVM in a simple way. First allow the
comparison value function to be the area metric functional,
ùëì(ùëß, ^ùëß) ‚â°ùëë
[Ô∏Ä
ùêπ(^ùë¶|ùëÄ), ùêπ(ùë¶|ùê∑)
]Ô∏Ä
,
(A.10)
and define agreement with a Boolean,
ùëù(ùê¥|ùëÄ, ùê∑) = Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëë[ùêπ(^ùë¶|ùëÄ), ùêπ(ùë¶|ùê∑)]
)Ô∏Ä)Ô∏Å
.
(A.11)
Here, the cdfs are treated as completely certain
(Ô∏Ä
ùõø(^ùëß‚àíùêπ(^ùë¶|ùëÄ)) and ùõø(ùëß‚àíùêπ(ùë¶|ùê∑))
are Dirac delta functionals
)Ô∏Ä
. The functional form of the Boolean may be decided
given the user‚Äôs specific validation requirements; however, satisfying some kind of ùúñ
threshold ùëë[ùêπ(^ùë¶|ùëÄ), ùêπ(ùë¶|ùê∑)] ‚â§ùúñseems logical. Generalizations to the area metric
may be represented analogously with the BVM.
When the values of the cdfs are uncertain, the BVM becomes,
ùëù(ùê¥|ùëÄ, ùê∑) ‚Üê
‚à´Ô∏Å
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëë[ùêπ(^ùë¶|ùëÄ), ùêπ(ùë¶|ùê∑)]
)Ô∏Ä)Ô∏Å
¬∑ ùúå
(Ô∏Ä
ùêπ(^ùë¶|ùëÄ), ùêπ(ùë¶|ùê∑)
)Ô∏Ä
ùëëùêπ(^ùë¶|ùëÄ) ùëëùêπ(ùë¶|ùê∑),
(A.12)
which may pose computational challenges and require random sampling; however, in
some cases it may be permissible to treat the model cdf as known. The extension
to uncertain cdfs is usually not considered in the literature; however, the theoretical
generalization to the uncertain case is apparent in the BVM framework. As an
approximation, one may consider discretizing the area metric by breaking it into ùêæ
comparison points,
ùëë
[Ô∏Ä
ùêπ(^ùë¶|ùëÄ), ùêπ(ùë¶= ^ùë¶|ùê∑)
]Ô∏Ä
‚âà
ùêæ
‚àëÔ∏Å
ùëñ=1
‚Éí‚Éíùêπ(^ùë¶ùëñ|ùëÄ) ‚àíùêπ(ùë¶ùëñ= ^ùë¶ùëñ|ùê∑)
‚Éí‚Éí.
(A.13)
The uncertainty in the cumulative distribution of the data ùúå(ùëß|ùê∑) is now a finite
joint product pdf ùúå
(Ô∏Ä
ùêπ(ùë¶1|ùê∑), . . . , ùêπ(ùë¶ùêæ|ùê∑)
‚Éí‚Éíùê∑
)Ô∏Ä
over possible cdf values in the ùêæbins,
constrained by ùêπ(ùë¶ùëñ|ùê∑) ‚â§ùêπ(ùë¶ùëñ+1|ùê∑). This metric may also be represented with the
BVM.
85

Alternatively, one may consider a binned probability difference comparison func-
tional,
ùëëùëö
[Ô∏Ä
ùëù(^ùë¶|ùëÄ), ùëù(ùë¶= ^ùë¶|ùê∑)
]Ô∏Ä
=
ùêæ
‚àëÔ∏Å
ùëñ=1
‚Éí‚Éíùëù(^ùë¶ùëñ|ùëÄ) ‚àíùëù(ùë¶ùëñ= ^ùë¶ùëñ|ùê∑)
‚Éí‚Éí.
(A.14)
Let
ùëù(ùëß|ùê∑) = ùëù
(Ô∏Ä
ùëùùë¶1, . . . , ùëùùë¶ùêæ
‚Éí‚Éíùê∑, ‚àëÔ∏Ä
ùëòùëùùë¶ùëò= 1
)Ô∏Ä
be the uncertainty for the probability estimate in each data bin due to the random
process. Given that the pdf of the model is set to a (presumably known) single pdf
function ùëù(^ùë¶|ùëÄ), the BVM is,
ùëù(ùê¥|ùëÄ, ùê∑)
=
‚à´Ô∏Å
^ùëß,ùëß
ùõø
(Ô∏Ä
^ùëß‚àí{ùëù(^ùë¶|ùëÄ)}
)Ô∏Ä
¬∑ Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëëùëö[^ùëß, ùëß]
)Ô∏Ä)Ô∏Å
¬∑ ùëù(ùëß|ùê∑) ùëë^ùëßùëëùëß
=
‚à´Ô∏Å
ùëùùë¶1,...,ùëùùë¶ùêæ
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëëùëö
[Ô∏Ä
{ùëù(^ùë¶|ùëÄ)}, {ùëù(ùë¶|ùê∑)}
]Ô∏Ä)Ô∏Ä)Ô∏Å
¬∑ ùëù(ùëùùë¶1, ..., ùëùùë¶ùêæ|ùê∑)
‚àèÔ∏Å
ùëñ
(ùëëùëùùë¶ùëñ).
Given the form of the distribution ùëù(ùëùùë¶1, . . . , ùëùùë¶ùêæ|ùê∑) is well-known (i.e. a Dirichlet
distribution after ùëõindependent observations of ùë¶), the BVM can be treated as an
expectation value,
ùëù(ùê¥|ùëÄ, ùê∑) = ùê∏
[Ô∏Å
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëëùëö
[Ô∏Ä
{ùëù(^ùë¶|ùëÄ)}, {ùëù(ùë¶|ùê∑)}
]Ô∏Ä)Ô∏Ä)Ô∏Å]Ô∏Å
{ùëù(ùë¶|ùê∑)}
(A.15)
and estimated with Monte Carlo.
When ùêæis large, we may face the curse of
dimensionality if the probabilities (bin heights) are themselves uncertain.
The number of bins ùêæplays a role similar to ùúñin that its choice affects the
definition/context of agreement represented by the BVM. The binned pdf metric is
most informative when ùêæis large because one is checking each region of the pdf for
agreement. On the other hand, perhaps when data is limited, there may be instances
when having ùêæ= 2 bins is useful, if for example one was interested in testing a
model for representing binary type probabilities (like pass/fail or positive/negative).
Using a favorable agreement in this simple binary context to imply that the model
works for otherwise untested ùêæ> 2 comparisons/contexts/validations, is statistical
misrepresentation and should be avoided (see Section 2.3.3). The BVM requires one
86

to explicitly state the comparison values, the comparison value function, and the
definition of agreement to compute ùëù(ùê¥|ùëÄ, ùê∑) such that confusion may be avoided
and model validation comparisons may be justified.
Thus, the choice of ùêæultimately determines the granularity of the definition of
agreement being tested. If one uses methods similar to [19] to select ùêæ, then one
is letting the complexity of the data and the number of data points determine the
stringency of the definition of agreement.
A.4
Probability Density Function Comparison Met-
rics
Another way to gauge the agreement between uncertain data and models is through
a pdf comparison metric, ùê∫(ùúåùê∑||ùúåùëÄ) [34]. Examples of ùê∫(ùúåùê∑||ùúåùëÄ) are the negative
relative entropy or KL divergence,
ùê∑ùêæùêø(ùúåùê∑||ùúåùëÄ) =
‚à´Ô∏Å
ùë¶
ùúå(ùë¶|ùê∑) log
(Ô∏Ç
ùúå(ùë¶|ùê∑)
ùúå(^ùë¶= ùë¶|ùëÄ)
)Ô∏Ç
ùëëùë¶,
(A.16)
the Symmetrized KL divergence ùëÜùêæùêø(ùúåùê∑, ùúåùëÄ) = ùê∑ùêæùêø(ùúåùê∑||ùúåùëÄ) + ùê∑ùêæùêø(ùúåùëÄ||ùúåùê∑), the
Jensen-Shannon divergence ùê∑ùêΩùëÜ(ùúåùê∑, ùúåùëÄ), the Hellinger Metric ùêª(ùúåùê∑, ùúåùëÄ), the Fisher
information distance ‚Ñì(ùúåùê∑, ùúåùëÄ), and the Wasserstein distance ùëä(ùúåùê∑, ùúåùëÄ). These
metrics give a notion of ‚Äúcloseness‚Äù between the pdfs that can be used for validation.
The BVM may represent these validation metrics by letting the comparison value
function ùëì(^ùëß, ùëß) be the pdf comparison metric,
ùëì(^ùëß, ùëß) ‚â°ùê∫(ùúåùê∑||ùúåùëÄ),
where ^ùëß‚â°ùúåùëÄand ùëß‚â°ùúåùê∑are the model and data pdfs, respectively. In the absence
of model and data uncertainty (i.e. the pdfs are treated as known functions, e.g. ùúåùê∑
87

is a gaussian with mean = 0 and variance = 1), the BVM is simply,
ùëù(ùê¥|ùëÄ, ùê∑) = Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëì(^ùëß, ùëß)
)Ô∏Ä)Ô∏Å
= Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùê∫(ùúåùê∑||ùúåùëÄ)
)Ô∏Ä)Ô∏Å
,
which either meets the specifications for them to agree (defined by ùêµ), or does not
(e.g. passing a tolerance threshold). Following the structure of the BVM, if there are
uncertainties in the functional forms of the pdfs, they may be included into the BVM,
ùëù(ùê¥|ùëÄ, ùê∑) ‚Üê
‚à´Ô∏Å
ùúåùê∑,ùúåùëÄ
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùê∫(ùúåùê∑||ùúåùëÄ)
)Ô∏Ä)Ô∏Å
¬∑ ùúå(ùúåùê∑, ùúåùëÄ) ùëëùúåùê∑ùëëùúåùëÄ.
Uncertainties in the data pdfs may come from a lack of data and uncertainties in the
model may come from parametric uncertainty
(Ô∏Ä
e.g. a Gaussian pdf model ùúåùëÄ|ùúáwith
an uncertain mean ùúå(ùúá)
)Ô∏Ä
.1 As with the area metric, these metrics may be discretized
from pdf to probability comparison metrics, and uncertainties in the pdfs themselves
are typically not discussed/quantified in the literature.
A.5
Statistical Hypothesis Testing
Normally when statistical hypothesis testing is performed, one constructs the pdf of
the relevant test statistic of the data ùúå(ùëß|ùê∑) and then assumes the null hypothesis
is true (ùëÄ= ùê∑) counterfactually, which is enforced by setting the ‚Äúto be tested
population‚Äù (the model outputs here) pdf to be equal to the pdf of the test statistic
of the data ùúå(^ùëß|ùëÄ) ‚Üíùúå(^ùëß|ùëÄ= ùê∑). However, in the present case, we are interested
in the general modeling case in which one is able to extract a pdf of the outputs of
the model, which we would like to test against data before assuming that they are
equal. We will first represent the classical statistical hypothesis test using the BVM
and then later supply a version that is more relevant to model validation problems.
1 One should note that here there is the potential for two different models.
One in which
ùúåùëÄ‚â°
‚à´Ô∏Ä
ùúåùëÄ|ùúáùúå(ùúá) ùëëùúáis marginalized over (in which case the model pdf is ‚Äúcertain‚Äù if integrated
analytically), and another in which the model pdf is gaussian ùúåùëÄ|ùúábut there is model parametric
uncertainty of the form ùúå(ùúá).
88

Classical statistical hypothesis testing.
In classical hypothesis testing, one
constructs the pdf of a relevant test statistic ùëÜùë¶‚â°ùëßof the data ùúå(ùëß|ùê∑). The null
hypothesis is that the model is equal to the data, which is enforced by setting
ùúå(^ùëß|ùëÄ) = ùúå(^ùëß|ùëÄ= ùê∑). Further, the null hypothesis is not rejected if the test statistic
from the model ^ùëßfalls within the critical region [‚àíùëêùõº, ùëêùõº] that corresponds to the
probability
‚à´Ô∏Äùëêùõº
‚àíùëêùõºùúå(ùëß|ùê∑) ùëëùëß= 1 ‚àíùõºof the data. The case of not rejecting the null
hypothesis is represented by the Boolean expression ùêµ(^ùëß), which is true if ‚àíùëêùõº‚â§^ùëß‚â§ùëêùõº
is true ‚Äì defining ‚Äúagreement‚Äù in this case. This results in the following BVM,
ùëù(ùê¥|ùëÄ= ùê∑, ùê∑)
=
‚à´Ô∏Å
^^ùëß,ùëß
ùúå(^ùëß|ùëÄ= ùê∑) ¬∑ Œò
(Ô∏Ä
ùêµ(^ùëß)
)Ô∏Ä
¬∑ ùúå(ùëß|ùê∑) ùëë^ùëßùëëùëß
=
‚à´Ô∏Å
^ùëß
ùúå(^ùëß|ùëÄ= ùê∑) ¬∑ Œò
(Ô∏Ä
‚àíùëêùõº‚â§^ùëß‚â§ùëêùõº
)Ô∏Ä
ùëë^ùëß= 1 ‚àíùõº, (A.17)
because the model was assumed to be equal to the data counterfactually in the null
hypothesis and ùêµ(^ùëß, ùëß) = ùêµ(^ùëß) only.
The probability of type I error, i.e. rejecting the counterfactually assumed true
null hypothesis when it is actually true, is equal to ùõº.
It should be noted that
this is not equal to the probability of finding the model value outside of the data‚Äôs
confidence interval because it is unknown if the null hypothesis
(Ô∏Ä
in what results
in ùúå(^ùëß|ùëÄ) ‚Üíùúå(^ùëß|ùëÄ= ùê∑)
)Ô∏Ä
is actually true, or not, because the null hypothesis
was merely assumed to be true counterfactually. It should further be noted that
with probability ùõºthe data‚Äôs test statistic is outside of its own confidence interval.
Thus, the probability ùõºboth indicates type I error and a systematic type error that
the wrong sort of comparison is being made, i.e. the wrong Boolean expression
was chosen, because, why would we care if the model is within a certain confidence
interval if the data is not even within that interval?2 The probability of type II
error, i.e. that the null hypothesis was accepted when it is actually false, is equal
to ùõΩùëÄ(ùõº) = 1 ‚àí
‚à´Ô∏Äùëêùõº
‚àíùëêùõºùúå(^ùëß|ùëÄ) ùëë^ùëß, which in the classical case is difficult to calculate
directly because one does not have access to the actual model pdf ùëù(^ùëß|ùëÄ) in frequentist
probability.
2Independent of whether or not the null hypothesis is true.
89

Improved statistical hypothesis testing for validation.
For the validation
cases we are interested in, both ùúå(^ùëß|ùëÄ) and ùúå(ùëß|ùê∑) are quantified, and therefore
assuming that ùúå(^ùëß|ùëÄ) ‚Üíùúå(^ùëß|ùëÄ= ùê∑) would irresponsibly throw away any information
sent through the model. We therefore offer the improved statistical hypothesis test
for validation using the BVM, which uses both the model and data pdfs. We call this
BVM the statistical power BVM.
For the modified statistical hypothesis test, let the definition of agreement be a
compound Boolean expression that is true iff both ‚àíùëêùõº‚â§^ùëß‚â§ùëêùõº, that the model
test statistic lies in the data‚Äôs confidence interval, and ‚àíùëê^ùõº‚â§ùëß‚â§ùëê^ùõºthat the data
statistic lies in the model‚Äôs confidence interval, which corresponds to the probability
‚à´Ô∏Äùëê^ùõº
‚àíùëê^ùõºùúå(^ùëß|ùëÄ) ùëë^ùëß= 1 ‚àí^ùõºof the model. By not assuming ùëÄ= ùê∑, we remove the
possibility that either type I or type II errors can occur; however, systematic errors,
that the Boolean expression meant to define agreement is nonsensical, still exist. Thus,
while more or less adhering to the type of tests one might perform for model validation
using statistical hypothesis testing, we get,
ùëù(ùê¥|ùëÄ, ùê∑)
=
‚à´Ô∏Å
^ùëß,ùëß
ùúå(^ùëß|ùëÄ, ùê∑) ¬∑ Œò
(Ô∏Ä
‚àíùëêùõº‚â§^ùëß‚â§ùëêùõº
)Ô∏Ä
¬∑ Œò
(Ô∏Ä
‚àíùëê^ùõº‚â§ùëß‚â§ùëê^ùõº
)Ô∏Ä
¬∑ ùúå(ùëß|ùê∑) ùëë^ùëßùëëùëß
=
(Ô∏Ä
1 ‚àíùõΩùëÄ(ùõº)
)Ô∏Ä
¬∑
(Ô∏Ä
1 ‚àíùõΩùê∑(^ùõº)
)Ô∏Ä
,
(A.18)
which is the probability that both the model and the data lie within one another‚Äôs
confidence intervals. The value 1 ‚àíùõΩ(ùõº) is called the statistical power of the test, but
here we have access to both the statistical power of the data and the model. The
probability the model and data do not agree as defined by ùêµis given by,
ùëù(ùê¥|ùëÄ, ùê∑) = 1 ‚àíùëù(ùê¥|ùëÄ, ùê∑) = ùõΩùê∑(^ùõº) + ùõΩùëÄ(ùõº) ‚àíùõΩùê∑(^ùõº)ùõΩùëÄ(ùõº),
(A.19)
which occurs if either ^ùëß, ùëß, or both are outside of one another‚Äôs confidence intervals.
The probability for systematic error (that ^ùëß, ùëß, or both are outside of their own
confidence intervals) is equal to ùõº+ ^ùõº‚àíùõº^ùõº; however, there is no conceptual issue
with setting ùõº, ^ùõº, or both equal to 0 as long as both distributions do not span the
90

entire range of possible values (as in such a case the model and data would always
agree, which means the test has zero resolving power). Setting ùõº= ^ùõº= 0 removes the
chance of systematic error from the analysis.
Overall, the use of confidence intervals is suboptimal unless both the model and
data pdfs are strictly unimodal. Therefore, rather than using a confidence interval,
one may use a ‚Äúconfidence set‚Äù, which we define as the smallest set of ^ùëß(as well as
for ùëß) values whose probability adds to 1 ‚àí^ùõº(and similarly 1 ‚àíùõº). Confidence sets
are generated by adding the largest probabilities of ^ùëß(ùëß) until a confidence level of
1 ‚àí^ùõº(1 ‚àíùõº) is met. A confidence interval is only equal to the confidence set if the
distribution is unimodal. As the confidence set is the smallest set of values adding
up to the confidence level, this set of values is more informative than a confidence
interval, which may include many 0 or low probability events. Using a confidence set
improves the resolving power of the metric further.
The statistical power BVM (A.18) is more informative than the classical statistical
hypothesis test (A.17) because it utilizes the model pdf while also removing type I,
type II, and (optionally) systematic errors from the test; however its overall resolving
power is weak when compared to other metrics. By rewriting the pair of overlapping
confidence intervals (or sets) as the set of values in a single ‚Äúoverlap interval‚Äù ùêº=
[‚àíùëêùõº, ùëêùõº]‚à©[‚àíùëê^ùõº, ùëê^ùõº], one may see that (A.18) is a particular case of (A.5) with ùëÜ(ùë¶) = ùêº
for ùë¶‚ààùêºand being the null set otherwise. Thus, the statistical power BVM may be
seen as a special case of the generalized reliability metric suggested by the BVM in
(A.5) that effectively has large and unvarying tolerance intervals (sets). The use of
confidence intervals as well as confidence sets in defining agreement effectively coarse
grain the probabilities, which removes their informative features. The most stringent
definition of agreement between the model and the data leads to Bayesian model
testing, which we prove in the next section, as it is indeed equal to the generalized
model reliability metric with a zero tolerance for differences ùúñ= 0.
91

A.6
Bayesian Model Testing
In Bayesian model testing, rather than assuming a particular model is true, one lets
the available data determine which model is most likely given that data. Represented
probabilistically, out of a set of possible models, Bayesian model testing selects the
model with the maximum posterior probability ùëù(ùëÄ|ùëå), i.e. the probability of a
(previously calibrated [52]) model ùëÄgiven the data set ùëå= {ùë¶ùëñ} from data source
ùê∑. As the selection rule for models requires comparing values of ùëù(ùëÄ|ùëå), one often
constructs the posterior odds ratio,
ùëÖ= ùëù(ùëÄ|ùëå)
ùëù(ùëÄ‚Ä≤|ùëå),
(A.20)
and selects the model ùëÄwith the highest value of ùëÖrelative to a chosen base model
ùëÄ‚Ä≤. Using Bayes‚Äô Theorem, the posterior odds ratio may be recast as,
ùëÖ= ùëù(ùëå|ùëÄ)ùëù(ùëÄ)
ùëù(ùëå|ùëÄ‚Ä≤)ùëù(ùëÄ‚Ä≤) = ùêæùëù(ùëÄ)
ùëù(ùëÄ‚Ä≤),
(A.21)
where ùêæ‚â°ùëù(ùëå|ùëÄ)/ùëù(ùëå|ùëÄ‚Ä≤) is known as the Bayes factor, which is the ratio of the
likelihoods of the models. The ratio of the prior model probabilities ùëù(ùëÄ)/ùëù(ùëÄ‚Ä≤) is
the ratio of the belief that model ùëÄis true prior to examining the data, relative to ùëÄ‚Ä≤.
If there is reason to believe that one model is more probable than another due to prior
(perhaps statistical) knowledge of the system under investigation, then the Bayesian
framework allows one to take this into account through the prior model probabilities.
As it is common for the ùëÖvalues to be potentially many orders of magnitude greater
than one, the prior model probabilities may be overwhelmed by the Bayes factor. In
any case, if there is no reason to prefer one model over another, one can let the prior
model probabilities be equal a priori.
Given we are testing some model function ^ùë¶= ùëÄ(‚Éóùë•, ‚Éóùõº), we have access to the
forward propagation of data and parameters through a given model, the problem
of calculating ùëÖmay be rerouted to the computation of ùêæ. Using the potentially
multidimensional inputs to our models (‚Éóùë•, ‚Éóùõº), which represent the input data and
92

the model parameters respectively, the Bayes factor is calculated through forward
propagation (marginalization) of these inputs through both models,
ùêæ= ùëù(ùëå|ùëÄ)
ùëù(ùëå|ùëÄ‚Ä≤) =
‚à´Ô∏Ä
‚Éóùë•,‚Éóùõºùëù(ùëå|‚Éóùë•, ‚Éóùõº, ùëÄ) ¬∑ ùúå(‚Éóùë•, ‚Éóùõº|ùëÄ) ùëë‚Éóùë•ùëë‚Éóùõº
‚à´Ô∏Ä
‚Éóùë•‚Ä≤,‚Éóùõº‚Ä≤ ùëù(ùëå|‚Éóùë•‚Ä≤, ‚Éóùõº‚Ä≤, ùëÄ‚Ä≤) ¬∑ ùúå(‚Éóùë•‚Ä≤, ‚Éóùõº‚Ä≤|ùëÄ‚Ä≤) ùëë‚Éóùë•‚Ä≤ ùëë‚Éóùõº‚Ä≤.
(A.22)
The prior probability of the inputs to the model ùúå(‚Éóùë•, ‚Éóùõº|ùëÄ) are the input probability
distributions used to propagate uncertainty through the model. The probability
ùëù(ùëå|‚Éóùë•, ‚Éóùõº, ùëÄ) is the probability of the data given by the knowledge of the model function
^ùë¶= ùëÄ(‚Éóùë•, ‚Éóùõº); however, it should be noted that in general the data ùëå= {ùë¶ùëñ} Ã∏= ^ùëå,
is not the set of model outputs ^ùëå, as the data ùëåwas collected from the experiment
rather than from model outputs. Thus, one must impose the assumptions under which
a model is built, i.e. it is built for the purpose of approximating ùë¶ùëñ‚âàùëÄ(ùë•ùëñ, ‚Éóùõº), as we
will see later. Thus, a more verbose representation of ùêæis,
ùêæ= ùëù( ^ùëå|ùëÄ)
ùëù( ^ùëå|ùëÄ‚Ä≤)
= ùúå( ^ùëå|ùëÄ)
ùúå( ^ùëå|ùëÄ‚Ä≤)
=
‚à´Ô∏Ä
‚Éóùë•,‚Éóùõºùúå( ^ùëå= ùëå|‚Éóùë•, ‚Éóùõº, ùëÄ) ¬∑ ùúå(‚Éóùë•, ‚Éóùõº|ùëÄ) ùëë‚Éóùë•ùëë‚Éóùõº
‚à´Ô∏Ä
‚Éóùë•‚Ä≤,‚Éóùõº‚Ä≤ ùúå( ^ùëå= ùëå|‚Éóùë•‚Ä≤, ‚Éóùõº‚Ä≤, ùëÄ‚Ä≤) ¬∑ ùúå(‚Éóùë•‚Ä≤, ‚Éóùõº‚Ä≤|ùëÄ‚Ä≤) ùëë‚Éóùë•‚Ä≤ ùëë‚Éóùõº‚Ä≤ ,
(A.23)
where ùëù(^ùëå|ùëÄ) is understood to be the sum of the model and the data probabilities
that jointly output the same values, i.e. the probability that any of the possible model
and data values turn out to be the same. The form of ùúå(^ùëå= ùëå|‚Éóùë•, ‚Éóùõº, ùëÄ) is usually
assumed to be something that works (and even better if it is also simple) [45], like the
product of Gaussian distributions,
ùúå(^ùëå= ùëå|‚Éóùë•, ‚Éóùõº, ùëÄ) = 1
ùëçexp
(Ô∏Ç
‚àí
1
2ùúé2
‚àëÔ∏Å
ùëñ
(Ô∏Ä
ùëÄ(ùë•ùëñ; ‚Éóùõº) ‚àíùë¶ùëñ
)Ô∏Ä2
)Ô∏Ç
,
(A.24)
where ùúé2 is interpreted as the measurement uncertainty of the data.3 One usually
computes the integrals in ùêæusing various sampling algorithms such as nested sampling
[10, 53] or another Markov Chain Monte Carlo technique. As an added bonus, Bayesian
model testing has an inbuilt Occam‚Äôs razor mechanism which penalizes needlessly
complex models, i.e. ones that would overfit the data by using a large number of
uncertain model parameters ‚Éóùõº. A clear explanation may be found in [5].
3The dependence on the data set/experiment ùê∑is therefore implied.
93

We can represent Bayesian model testing using the Bayesian Validation Metric.
Let the model comparison value ^ùëßbe ^ùëå= (^ùë¶1, . . . , ^ùë¶ùëõ) that in principle corresponds to
ùëß= ùëå= (ùë¶1, . . . , ùë¶ùëõ), a validation set of data. The Boolean expression ùêµis considered
to factor into a set of ‚Äúand‚Äù statements over the individual model output and data
points ùêµ(^ùëå, ùëå) = ùêµ(^ùë¶1, ùë¶1) ‚àß. . . ‚àßùêµ(^ùë¶ùëõ, ùë¶ùëõ), where each ùêµis true iff ^ùë¶ùëñ= ùë¶ùëñexactly.
The Bayesian Validation Metric in this case is then,
ùëù(ùê¥|ùëÄ, ùê∑)
=
‚à´Ô∏Å
^ùëå,ùëå
ùúå(^ùëå|ùëÄ, ùê∑) ¬∑ Œò
(Ô∏Ä
ùêµ(^ùëå, ùëå)
)Ô∏Ä
¬∑ ùúå(ùëå|ùê∑) ùëë^ùëåùëëùëå
=
‚à´Ô∏Å
^ùëå,ùëå
ùúå(^ùëå|ùëÄ, ùê∑) ¬∑ ùõø^ùëå,ùëå¬∑ ùúå(ùëå|ùê∑) ùëë^ùëåùëëùëå.
(A.25)
In general, computational models may be described by a model function ^ùëå= ùëÄ(‚Éóùë•, ‚Éóùõº),
and given the model pdf was constructed through forward propagation of the uncer-
tainties ùúå(‚Éóùë•, ‚Éóùõº), the model output pdf is
ùúå(^ùëå|ùëÄ, ùê∑) =
‚à´Ô∏Å
‚Éóùë•,‚Éóùõº
ùúå(^ùëå|‚Éóùë•, ‚Éóùõº, ùëÄ, ùê∑) ¬∑ ùúå(‚Éóùë•, ‚Éóùõº) ùëë‚Éóùë•ùëë‚Éóùõº.
(A.26)
Substituting (A.26) into (A.25), using the trick (2.11) and (2.12) ‚Äì that
‚à´Ô∏Åùëå+ùúñ
ùëå‚àíùúñ
ùúå(^ùëå|ùëÄ, ùê∑) ùëë^ùëå
ùúñ‚Üí0+
‚àí‚Üíùëù(^ùëå= ùëå|ùëÄ, ùê∑) = ùúå(^ùëå= ùëå|ùëÄ, ùê∑) ùëë^ùëå,
and integrating over ùëå, one finds,
ùëù(ùê¥|ùëÄ, ùê∑)
=
‚à´Ô∏Å
‚Éóùë•,‚Éóùõº,ùëå
ùëù(^ùëå= ùëå|‚Éóùë•, ‚Éóùõº, ùëÄ, ùê∑) ¬∑ ùúå(‚Éóùë•, ‚Éóùõº) ¬∑ ùúå(ùëå|ùê∑) ùëë‚Éóùë•ùëë‚Éóùõºùëëùëå
=
‚à´Ô∏Å
‚Éóùë•,‚Éóùõº
ùëù(^ùëå|‚Éóùë•, ‚Éóùõº, ùëÄ, ùê∑) ¬∑ ùúå(‚Éóùë•, ‚Éóùõº) ùëë‚Éóùë•ùëë‚Éóùõº
=
(Ô∏Ç‚à´Ô∏Å
‚Éóùë•,‚Éóùõº
ùúå(^ùëå|‚Éóùë•, ‚Éóùõº, ùëÄ, ùê∑) ¬∑ ùúå(‚Éóùë•, ‚Éóùõº) ùëë‚Éóùë•ùëë‚Éóùõº
)Ô∏Ç
ùëë^ùëå
=
ùúå
(Ô∏Ä^ùëå‚â°ùëå
‚Éí‚ÉíùëÄ, ùê∑
)Ô∏Ä
ùëë^ùëå,
(A.27)
which is what is meant by, and is equal to, the probability in the numerator of the
94

Bayes factor (A.23),
ùëù(ùê¥|ùëÄ, ùê∑) = ùúå
(Ô∏Ä^ùëå‚â°ùëå
‚Éí‚ÉíùëÄ, ùê∑
)Ô∏Ä
ùëë^ùëå‚â°ùëù
(Ô∏Ä^ùëå‚â°ùëå
‚Éí‚ÉíùëÄ
)Ô∏Ä
.
(A.28)
That is, we have shown that Bayesian model testing is a special case of the generalized
model reliability metric in the case of exact agreement (A.5), i.e. ùúñ= 0, as can be
seen by investigating (A.25).
Thus, a generalization of Bayesian model testing is to let the definition of agreement
have a tolerance ùúñ> 0 such that the Bayes factor becomes,
ùêæ= ùëù(ùê¥|ùëÄ, ùê∑)
ùëù(ùê¥|ùëÄ‚Ä≤, ùê∑)
‚àí‚Üíùêæ(ùúñ) = ùëù(ùê¥|ùëÄ, ùê∑, ùúñ)
ùëù(ùê¥|ùëÄ‚Ä≤, ùê∑, ùúñ),
(A.29)
where ùëù(ùê¥|ùëÄ, ùê∑, ùúñ) is Equation (A.2). This derivation suggests that the BVM can
be used analogously to Bayesian model testing, except with arbitrary definitions of
agreement ùúñ‚Üíùêµ, that is, we may construct the BVM factor,
ùêæ(ùêµ) = ùëù(ùê¥|ùëÄ, ùê∑, ùêµ)
ùëù(ùê¥|ùëÄ‚Ä≤, ùê∑, ùêµ).
(A.30)
Using Bayes‚Äô Theorem, ùëù(ùëÄ|ùê¥, ùê∑, ùêµ) = ùëù(ùê¥|ùëÄ, ùê∑, ùêµ)ùëù(ùëÄ|ùê∑, ùêµ)/ùëù(ùê¥|ùê∑, ùêµ), we may
further construct the BVM ratio,
ùëÖ(ùêµ) = ùëù(ùëÄ|ùê¥, ùê∑, ùêµ)
ùëù(ùëÄ‚Ä≤|ùê¥, ùê∑, ùêµ) = ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) ùëù(ùëÄ|ùê∑, ùêµ)
ùëù(ùê¥|ùëÄ‚Ä≤, ùê∑, ùêµ) ùëù(ùëÄ‚Ä≤|ùê∑, ùêµ) = ùêæ(ùêµ) ùëù(ùëÄ|ùê∑, ùêµ)
ùëù(ùëÄ‚Ä≤|ùê∑, ùêµ),
(A.31)
for the purpose of model testing under a general definition of agreement ùêµ, i.e. we
can do model selection under any definition of agreement with the BVM ratio. The
ratio ùëù(ùëÄ|ùê∑, ùêµ)/ùëù(ùëÄ‚Ä≤|ùê∑, ùêµ) is the ratio of prior probabilities of ùëÄand ùëÄ‚Ä≤. Again,
if there is no reason to suspect that one model is a priori more probable than another,
one may let ùëù(ùëÄ|ùê∑, ùêµ)/ùëù(ùëÄ‚Ä≤|ùê∑, ùêµ) = 1, and then ùëÖ(ùêµ) ‚Üíùêæ(ùêµ). With the BVM
ratio, one could in principle compare data and models with different data types to
perform model testing or selection.
95

96

Appendix B
Likelihood-Based Methods
Likelihood-based methods for calibration and model learning use the likelihood func-
tion ‚Ñí(‚Éóùõº) to learn model parameters. The most common likelihood-based method
is the max likelihood method, that, due to the monotonicity of the log function is cast as
‚Éóùõº* = arg max
‚Éóùõº
(Ô∏Å
‚àílog ‚Ñí(‚Éóùõº)
)Ô∏Å
.
(B.1)
Although the approach is rather general, in practice one considers likelihood functions
generated from stochastic model function
^ùë¶ùëñ= ùëÄ(ùë•ùëñ; ‚Éóùõº) = ùëÄ(ùë•ùëñ; ùõº1, . . . , ùõºùëö) + ùõº0,
(B.2)
where ùëÄ(ùë•ùëñ; ùõº1, . . . , ùõºùëö) is a deterministic model function, ùõº0 is drawn from ùõº0 ‚àº
ùí©(0, ùúé2
ùõº0), and ùúéùõº0 ‚àà‚Éóùõº‚Üê(ùúéùõº0, ùõº1, . . . , ùõºùëö) may be treated as a learnable parameter.
The likelihood of this data given the model (is the true underlying model) is then a
product of Gaussians,
‚Ñí(‚Éóùõº) = ùúå(ùê∑|‚Éóùõº, ùëÄ) =
ùëõ
‚àèÔ∏Å
ùëñ=1
ùí©
(Ô∏Ä
ùëÄ(ùë•ùëñ; ùõº1, . . . , ùõºùëö), ùúé2
ùõº0
)Ô∏Ä
,
(B.3)
which implicitly involves setting the certain data, ùëå= ùê∑, equal to the model output
exactly, ^ùëå= ùëå, as the true probability described by (B.2) is the model output
drawn from the model ^ùë¶ùëñ‚àºùí©
(Ô∏Ä
ùëÄ(ùë•ùëñ; ùõº1, ..., ùõºùëö), ùúé2
ùõº0
)Ô∏Ä
. If the observed data ùê∑has
measurement or other types of uncertainty, nothing prevents this uncertainty from
being built further into ‚Ñí(‚Éóùõº).
97

98

Appendix C
Bayesian Model Testing
We derive Equations (3.4) ‚Äì (3.6) mentioned in Section 3.2.3. In the Bayesian model
testing framework, the model output and the observed data are defined to agree
only if their values are exactly equal. Thus, Bayesian model testing is a special case
of the BVM where the agreement kernel is equal to the kronecker delta function
(exact agreement) with continuous indices, i.e. Œò
(Ô∏Ä
ùêµ(^ùëå, ùëå)
)Ô∏Ä
= ùõø^ùëå,ùëå= ‚àèÔ∏Äùëõ
ùëñ=1 ùõø^ùë¶ùëñ,ùë¶ùëñ.
Since Bayesian model testing deals with probability densities, we have the following
expression for the probability density of agreement (3.7):
ùúå(ùê¥|ùëÄ, ùê∑) = ùëù(ùê¥|ùëÄ, ùê∑)
ùëëùê¥
= 1
ùëëùê¥
‚à´Ô∏Å
^ùëå,ùëå
ùúå(^ùëå|ùëÄ, ùê∑) ¬∑ Œò
(Ô∏Ä
ùêµ(^ùëå, ùëå)
)Ô∏Ä
¬∑ ùúå(ùëå|ùê∑)ùëë^ùëåùëëùëå
=
‚à´Ô∏Å
^ùëå,ùëå
ùúå(^ùëå|ùëÄ, ùê∑) ¬∑
ùõø^ùëå,ùëå
ùëëùê¥¬∑ ùúå(ùëå|ùê∑)ùëë^ùëåùëëùëå.
The kronecker delta ùõø^ùëå,ùëåand the dirac delta ùõø(^ùëå‚àíùëå) functions are related as follows:
ùõø^ùëå,ùëå
ùëëùê¥= ùõø(^ùëå‚àíùëå) =
ùëõ
‚àèÔ∏Å
ùëñ=1
ùõø(^ùë¶ùëñ‚àíùë¶ùëñ).
99

Thus, the probability density of agreement becomes,
ùúå(ùê¥|ùëÄ, ùê∑) =
‚à´Ô∏Å
^ùëå,ùëå
ùúå(^ùëå|ùëÄ, ùê∑) ¬∑ ùõø(^ùëå‚àíùëå) ¬∑ ùúå(ùëå|ùê∑)ùëë^ùëåùëëùëå
=
‚à´Ô∏Å
^ùëå,ùëå
(Ô∏Ç‚à´Ô∏Å
‚Éóùõº
ùúå(^ùëå|‚Éóùõº, ùëÄ)ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
)Ô∏Ç
¬∑ ùõø(^ùëå‚àíùëå) ¬∑ ùúå(ùëå|ùê∑)ùëë^ùëåùëëùëå
=
‚à´Ô∏Å
‚Éóùõº
(Ô∏Ç‚à´Ô∏Å
^ùëå,ùëå
ùúå(^ùëå|‚Éóùõº, ùëÄ) ¬∑ ùõø(^ùëå‚àíùëå) ¬∑ ùúå(ùëå|ùê∑)ùëë^ùëåùëëùëå
)Ô∏Ç
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
=
‚à´Ô∏Å
‚Éóùõº
(Ô∏Ç‚à´Ô∏Å
^ùëå,ùëå
ùõø
(Ô∏Ä^ùëå‚àíùëÄ(ùëã; ‚Éóùõº)
)Ô∏Ä
‚èü
 ‚èû
 
^ùëå= ùëÄ(ùëã; ‚Éóùõº)
¬∑ ùõø(^ùëå‚àíùëå) ¬∑ ùúå(ùëå|ùê∑)ùëë^ùëåùëëùëå
)Ô∏Ç
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
=
‚à´Ô∏Å
‚Éóùõº
(Ô∏Ç‚à´Ô∏Å
ùëå
ùõø
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº) ‚àíùëå
)Ô∏Ä
¬∑ ùúå(ùëå|ùê∑)ùëëùëå
)Ô∏Ç
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº.
(C.1)
C.1
Normally Distributed Data
If we assume the data to be normally distributed, i.e. ùëå‚àºùí©(ùê∑, Œî), we get,
ùúå(ùëå|ùê∑) =
1
‚àöÔ∏Ä
(2ùúã)ùëõ|Œî|
ùëí‚àí1
2(ùëå‚àíùê∑)ùëáŒî‚àí1(ùëå‚àíùê∑),
where ùëõis the dimension of the training data set, Œî is the covariance matrix, and ùê∑
is the observed data values.
Therefore, using (C.1), we have,
ùúå(ùê¥|ùëÄ, ùê∑) =
‚à´Ô∏Å
‚Éóùõº
(Ô∏Ç‚à´Ô∏Å
ùëå
ùõø
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº) ‚àíùëå
)Ô∏Ä
¬∑
1
‚àöÔ∏Ä
(2ùúã)ùëõ|Œî|
ùëí‚àí1
2(ùëå‚àíùê∑)ùëáŒî‚àí1(ùëå‚àíùê∑)ùëëùëå
)Ô∏Ç
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº,
=
‚à´Ô∏Å
‚Éóùõº
1
‚àöÔ∏Ä
(2ùúã)ùëõ|Œî|
ùëí‚àí1
2
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº) ‚àíùê∑
)Ô∏ÄùëáŒî‚àí1(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº) ‚àíùê∑
)Ô∏Ä
‚èü
 ‚èû
 
‚Ñí(‚Éóùõº)
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
‚èü
 ‚èû
 
ùúã(‚Éóùõº)ùëë‚Éóùõº
.
Therefore, the likelihood function to be used in the MCMC algorithm is
‚Ñí(‚Éóùõº) =
1
‚àöÔ∏Ä
(2ùúã)ùëõ|Œî|
ùëí‚àí1
2
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº) ‚àíùê∑
)Ô∏ÄùëáŒî‚àí1(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº) ‚àíùê∑
)Ô∏Ä
,
which is Equation (3.4) presented in Section 3.2.3.
100

C.2
Uniformly Distributed Data
We first note that
ùëëùëå‚â°ùëëùëõùëå‚â°
ùëõ
‚àèÔ∏Å
ùëó=1
ùëëùë¶ùëó,
ùëó= 1, . . . , ùëõ.
(C.2)
Now, we assume the data to be uniformly distributed, i.e.
ùë¶ùëó‚àºùí∞(ùëéùëó, ùëèùëó),
ùëó= 1, . . . , ùëõ.
Then, the probability density ùúå(ùëå|ùê∑) becomes:
ùúå(ùëå|ùê∑) =
ùëõ
‚àèÔ∏Å
ùëó=1
ùúå(ùë¶ùëó|ùê∑) =
ùëõ
‚àèÔ∏Å
ùëó=1
Œò
(Ô∏Ä
ùëéùëó‚â§ùë¶ùëó‚â§ùëèùëó
)Ô∏Ä
ùëèùëó‚àíùëéùëó
.
(C.3)
Notice that we can generalize ùúå(ùë¶ùëó|ùê∑) =
ùëõ
‚àèÔ∏Å
ùëó=1
Œò
(Ô∏Ä
ùëéùëó‚â§ùë¶ùëó‚â§ùëèùëó
)Ô∏Ä
ùúå(ùë¶ùëó|ùê∑) to any bounded
probability density function (pdf). Therefore, using (C.1), we have,
ùúå(ùê¥|ùëÄ, ùê∑) =
‚à´Ô∏Å
‚Éóùõº
(Ô∏É
ùëõ
‚àèÔ∏Å
ùëó=1
‚à´Ô∏Å
ùë¶ùëó
ùõø
(Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) ‚àíùë¶ùëó
)Ô∏Å
¬∑ Œò
(Ô∏Ä
ùëéùëó‚â§ùë¶ùëó‚â§ùëèùëó
)Ô∏Ä
ùëèùëó‚àíùëéùëó
ùëëùë¶ùëó
)Ô∏É
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº,
=
‚à´Ô∏Å
‚Éóùõº
(Ô∏É
ùëõ
‚àèÔ∏Å
ùëó=1
Œò
(Ô∏Ä
ùëéùëó‚â§ùëÄ(ùë•ùëó; ‚Éóùõº) ‚â§ùëèùëó
)Ô∏Ä
ùëèùëó‚àíùëéùëó
)Ô∏É
‚èü
 ‚èû
 
‚Ñí(‚Éóùõº)
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
‚èü
 ‚èû
 
ùúã(‚Éóùõº)ùëë‚Éóùõº
.
Therefore, the likelihood function to be used in the MCMC algorithm is
‚Ñí(‚Éóùõº) =
ùëõ
‚àèÔ∏Å
ùëó=1
Œò
(Ô∏Ä
ùëéùëó‚â§ùëÄ(ùë•ùëó; ‚Éóùõº) ‚â§ùëèùëó
)Ô∏Ä
ùëèùëó‚àíùëéùëó
,
which is Equation (3.5) presented in Section 3.2.3.
101

C.3
Completely Certain Data
If we consider the data to be completely certain, deterministic, i.e. ùëå= ùê∑, then, the
probability density ùúå(ùëå|ùê∑) becomes ùúå(ùëå|ùê∑) = ùõø(ùëå‚àíùê∑), and thus, using (C.1), we
have,
ùúå(ùê¥|ùëÄ, ùê∑) =
‚à´Ô∏Å
‚Éóùõº
(Ô∏Ç‚à´Ô∏Å
ùëå
ùõø
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº) ‚àíùëå
)Ô∏Ä
¬∑ ùõø(ùëå‚àíùê∑)ùëëùëå
)Ô∏Ç
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
=
‚à´Ô∏Å
‚Éóùõº
ùõø
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº) ‚àíùê∑
)Ô∏Ä
‚èü
 ‚èû
 
‚Ñí(‚Éóùõº)
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
‚èü
 ‚èû
 
ùúã(‚Éóùõº)ùëë‚Éóùõº
.
Therefore, the likelihood function to be used in the MCMC algorithm is
‚Ñí(‚Éóùõº) = ùõø
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº) ‚àíùê∑
)Ô∏Ä
,
which is Equation (3.6) presented in Section 3.2.3.
102

Appendix D
BVM Model Selection
We derive Equations (3.15) ‚Äì (3.17) presented in Section 3.3. We show how we can
apply Bayesian model selection on any data distribution using the BVM probability
of agreement. Starting from the original definition of probability of agreement (3.7),
we have,
ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) =
‚à´Ô∏Å
^ùëå,ùëå
ùúå( ^ùëå|ùëÄ, ùê∑) ¬∑ Œò
(Ô∏Ä
ùêµ( ^ùëå, ùëå)
)Ô∏Ä
¬∑ ùúå(ùëå|ùê∑)ùëë^ùëåùëëùëå
=
‚à´Ô∏Å
^ùëå,ùëå
(Ô∏Ç‚à´Ô∏Å
‚Éóùõº
ùúå( ^ùëå|‚Éóùõº, ùëÄ)ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
)Ô∏Ç
¬∑ Œò
(Ô∏Ä
ùêµ( ^ùëå, ùëå)
)Ô∏Ä
¬∑ ùúå(ùëå|ùê∑)ùëë^ùëåùëëùëå
=
‚à´Ô∏Å
‚Éóùõº
(Ô∏Ç‚à´Ô∏Å
^ùëå,ùëå
ùúå( ^ùëå|‚Éóùõº, ùëÄ) ¬∑ Œò
(Ô∏Ä
ùêµ( ^ùëå, ùëå)
)Ô∏Ä
¬∑ ùúå(ùëå|ùê∑)ùëë^ùëåùëëùëå
)Ô∏Ç
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
=
‚à´Ô∏Å
‚Éóùõº
(Ô∏Ç‚à´Ô∏Å
^ùëå,ùëå
ùõø
(Ô∏Ä^ùëå‚àíùëÄ(ùëã; ‚Éóùõº)
)Ô∏Ä
¬∑ Œò
(Ô∏Ä
ùêµ( ^ùëå, ùëå)
)Ô∏Ä
¬∑ ùúå(ùëå|ùê∑)ùëë^ùëåùëëùëå
)Ô∏Ç
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
=
‚à´Ô∏Å
‚Éóùõº
(Ô∏Ç‚à´Ô∏Å
ùëå
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº), ùëå
)Ô∏Ä)Ô∏Å
¬∑ ùúå(ùëå|ùê∑)ùëëùëå
)Ô∏Ç
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº,
which is Equation (3.15) derived in Section 3.3. From (C.2), we know that
ùëëùëå‚â°ùëëùëõùëå‚â°
ùëõ
‚àèÔ∏Å
ùëó=1
ùëëùë¶ùëó,
ùëó= 1, . . . , ùëõ.
The probability density ùúå(ùëå|ùê∑) can be expressed as:
ùúå(ùëå|ùê∑) =
ùëõ
‚àèÔ∏Å
ùëó=1
ùúå(ùë¶ùëó|ùê∑).
103

We also note that the compound Boolean under question can be expressed as:
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº), ùëå
)Ô∏Ä)Ô∏Å
=
ùëõ
‚àèÔ∏Å
ùëó=1
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùë•ùëó; ‚Éóùõº), ùë¶ùëó
)Ô∏Ä)Ô∏Å
ùëó= 1, . . . , ùëõ.
Thus, we rewrite the BVM probability of agreement as follows:
ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) =
‚à´Ô∏Å
‚Éóùõº
(Ô∏É
ùëõ
‚àèÔ∏Å
ùëó=1
‚à´Ô∏Å
ùë¶ùëó
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùë•ùëó; ‚Éóùõº), ùë¶ùëó
)Ô∏Ä)Ô∏Å
¬∑ ùúå(ùë¶ùëó|ùê∑) ùëëùë¶ùëó
)Ô∏É
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº.
We will use the ùúñ‚àíBoolean indicator function defined as:
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùë•ùëó; ‚Éóùõº), ùë¶ùëó
)Ô∏Ä)Ô∏Å
=
‚éß
‚é™
‚é®
‚é™
‚é©
1,
if
‚Éí‚Éíùë¶ùëó‚àíùëÄ(ùë•ùëó; ‚Éóùõº)
‚Éí‚Éí‚â§ùúñ
0,
otherwise
where ùëó= 1, . . . , ùëõ.
Then, the indicator function can be rewritten as:
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùë•ùëó; ‚Éóùõº), ùë¶ùëó
)Ô∏Ä)Ô∏Å
= Œò
(Ô∏Å‚Éí‚Éíùë¶ùëó‚àíùëÄ(ùë•ùëó; ‚Éóùõº)
‚Éí‚Éí‚â§ùúñ
)Ô∏Å
= Œò
(Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) ‚àíùúñ‚â§ùë¶ùëó‚â§ùëÄ(ùë•ùëó; ‚Éóùõº) + ùúñ
)Ô∏Å
,
where ùëó= 1, . . . , ùëõ. Therefore, the BVM probability of agreement can be expressed as:
ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) =
‚à´Ô∏Å
‚Éóùõº
(Ô∏É
ùëõ
‚àèÔ∏Å
ùëó=1
‚à´Ô∏Å
ùë¶ùëó
Œò
(Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) ‚àíùúñ‚â§ùë¶ùëó‚â§ùëÄ(ùë•ùëó; ‚Éóùõº) + ùúñ
)Ô∏Å
¬∑ ùúå(ùë¶ùëó|ùê∑) ùëëùë¶ùëó
)Ô∏É
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº.
(D.1)
D.1
Normally Distributed Data
Note that the Boolean Œò
(Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) ‚àíùúñ‚â§ùë¶ùëó‚â§ùëÄ(ùë•ùëó; ‚Éóùõº) + ùúñ
)Ô∏Å
is equal to 1 only when
ùë¶ùëóbelongs to the interval
[Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) ‚àíùúñ, ùëÄ(ùë•ùëó; ‚Éóùõº) + ùúñ
]Ô∏Å
.
Thus, the BVM probability of agreement becomes:
ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) =
‚à´Ô∏Å
‚Éóùõº
(Ô∏É
ùëõ
‚àèÔ∏Å
ùëó=1
‚à´Ô∏Å
ùëÄ(ùë•ùëó;‚Éóùõº)+ùúñ
ùëÄ(ùë•ùëó;‚Éóùõº)‚àíùúñ
ùúå(ùë¶ùëó|ùê∑) ùëëùë¶ùëó
)Ô∏É
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº.
104

Now, we assume that the data is normally distributed, i.e.
ùë¶ùëó‚àºùí©(ùê∑ùëó, ùúé2
ùëó),
ùëó= 1, . . . , ùëõ.
Then, the probability density ùúå(ùëå|ùê∑) becomes:
ùúå(ùëå|ùê∑) =
ùëõ
‚àèÔ∏Å
ùëó=1
ùúå(ùë¶ùëó|ùê∑) =
ùëõ
‚àèÔ∏Å
ùëó=1
1
‚àö
2ùúãùúéùëó
e
‚àí1
2
(Ô∏Å
ùë¶ùëó‚àíùê∑ùëó
ùúéùëó
)Ô∏Å2
.
Thus, we rewrite the BVM probability of agreement as follows:
ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) =
‚à´Ô∏Å
‚Éóùõº
(Ô∏É
ùëõ
‚àèÔ∏Å
ùëó=1
‚à´Ô∏Å
ùëÄ(ùë•ùëó;‚Éóùõº)+ùúñ
ùëÄ(ùë•ùëó;‚Éóùõº)‚àíùúñ
ùúå(ùë¶ùëó|ùê∑) ùëëùë¶ùëó
)Ô∏É
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
=
‚à´Ô∏Å
‚Éóùõº
(Ô∏É
ùëõ
‚àèÔ∏Å
ùëó=1
‚à´Ô∏Å
ùëÄ(ùë•ùëó;‚Éóùõº)+ùúñ
ùëÄ(ùë•ùëó;‚Éóùõº)‚àíùúñ
1
‚àö
2ùúãùúéùëó
e
‚àí1
2
(Ô∏Åùë¶ùëó‚àíùê∑ùëó
ùúéùëó
)Ô∏Å2
ùëëùë¶ùëó
)Ô∏É
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
=
‚à´Ô∏Å
‚Éóùõº
ùëõ
‚àèÔ∏Å
ùëó=1
(Ô∏É
ùêπ
(Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) + ùúñ
)Ô∏Å
‚àíùêπ
(Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) ‚àíùúñ
)Ô∏Å)Ô∏É
‚èü
 ‚èû
 
‚Ñí(‚Éóùõº, ùêµ)
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
‚èü
 ‚èû
 
ùúã(‚Éóùõº)ùëë‚Éóùõº
,
where ùêπ(ùë•) is the cumulative distribution function (cdf) expressed as:
ùêπ(ùë•) = Œ¶
(Ô∏Çùë•‚àíùê∑
ùúé
)Ô∏Ç
,
where Œ¶(¬∑) is the cumulative distribution function of the standard normal distribution,
i.e. ùí©(0, 1), and expressed as:
Œ¶(ùë•) =
1
‚àö
2ùúã
‚à´Ô∏Åùë•
‚àí‚àû
e‚àíùë°2
2 ùëëùë°.
Therefore, the likelihood function to be used in the MCMC algorithm is
‚Ñí(‚Éóùõº, ùêµ) =
ùëõ
‚àèÔ∏Å
ùëó=1
(Ô∏É
ùêπ
(Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) + ùúñ
)Ô∏Å
‚àíùêπ
(Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) ‚àíùúñ
)Ô∏Å)Ô∏É
.
105

D.2
Uniformly Distributed Data
If we assume the data to be uniformly distributed (C.3), then the BVM probability of
agreement (D.1) becomes:
ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) =
‚à´Ô∏Å
‚Éóùõº
(Ô∏É
ùëõ
‚àèÔ∏Å
ùëó=1
‚à´Ô∏Å
ùë¶ùëó
Œò
(Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) ‚àíùúñ‚â§ùë¶ùëó‚â§ùëÄ(ùë•ùëó; ‚Éóùõº) + ùúñ
)Ô∏Å
¬∑ Œò
(Ô∏Ä
ùëéùëó‚â§ùë¶ùëó‚â§ùëèùëó
)Ô∏Ä
ùëèùëó‚àíùëéùëó
ùëëùë¶ùëó
)Ô∏É
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº.
Note that the product Œò
(Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) ‚àíùúñ‚â§ùë¶ùëó‚â§ùëÄ(ùë•ùëó; ‚Éóùõº) + ùúñ
)Ô∏Å
¬∑ Œò
(Ô∏Å
ùëéùëó‚â§ùë¶ùëó‚â§ùëèùëó
)Ô∏Å
is
equal to 1 only when ùë¶ùëóbelongs to both intervals
[Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) ‚àíùúñ, ùëÄ(ùë•ùëó; ‚Éóùõº) + ùúñ
]Ô∏Å
and
[Ô∏Å
ùëéùëó, ùëèùëó
]Ô∏Å
.
Let ùëôùëóand ùë¢ùëóbe such that
[Ô∏Å
ùëôùëó, ùë¢ùëó
]Ô∏Å
=
[Ô∏Å
ùëÄ(ùë•ùëó; ‚Éóùõº) ‚àíùúñ, ùëÄ(ùë•ùëó; ‚Éóùõº) + ùúñ
]Ô∏Å
‚à©
[Ô∏Å
ùëéùëó, ùëèùëó
]Ô∏Å
ùëó= 1, . . . , ùëõ
Thus, the BVM probability of agreement becomes:
ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) =
‚à´Ô∏Å
‚Éóùõº
(Ô∏É
ùëõ
‚àèÔ∏Å
ùëó=1
‚à´Ô∏Å
ùë¶ùëó
Œò
(Ô∏Ä
ùëôùëó‚â§ùë¶ùëó‚â§ùë¢ùëó
)Ô∏Ä
ùëèùëó‚àíùëéùëó
ùëëùë¶ùëó
)Ô∏É
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
=
‚à´Ô∏Å
‚Éóùõº
(Ô∏É
ùëõ
‚àèÔ∏Å
ùëó=1
‚à´Ô∏Å
ùë¢ùëó
ùëôùëó
1
ùëèùëó‚àíùëéùëó
ùëëùë¶ùëó
)Ô∏É
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
=
‚à´Ô∏Å
‚Éóùõº
(Ô∏É
ùëõ
‚àèÔ∏Å
ùëó=1
ùë¢ùëó‚àíùëôùëó
ùëèùëó‚àíùëéùëó
)Ô∏É
‚èü
 ‚èû
 
‚Ñí(‚Éóùõº, ùêµ)
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
‚èü
 ‚èû
 
ùúã(‚Éóùõº)ùëë‚Éóùõº
.
Therefore, the likelihood function to be used in the MCMC algorithm is
‚Ñí(‚Éóùõº, ùêµ) =
ùëõ
‚àèÔ∏Å
ùëó=1
ùë¢ùëó‚àíùëôùëó
ùëèùëó‚àíùëéùëó
,
which is Equation (3.16) presented in Section 3.3.
106

D.3
Completely Certain Data
If we consider the data to be completely certain, deterministic, i.e. ùëå= ùê∑, then, the
probability density ùúå(ùëå|ùê∑) becomes ùúå(ùëå|ùê∑) = ùõø(ùëå‚àíùê∑), and thus, using (3.15), we
have,
ùëù(ùê¥|ùëÄ, ùê∑, ùêµ) =
‚à´Ô∏Å
‚Éóùõº
(Ô∏Ç‚à´Ô∏Å
ùëå
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº), ùëå
)Ô∏Ä)Ô∏Å
¬∑ ùõø(ùëå‚àíùê∑)ùëëùëå
)Ô∏Ç
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
=
‚à´Ô∏Å
‚Éóùõº
Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº), ùê∑
)Ô∏Ä)Ô∏Å
‚èü
 ‚èû
 
‚Ñí(‚Éóùõº, ùêµ)
¬∑ ùúå(‚Éóùõº|ùëÄ)ùëë‚Éóùõº
‚èü
 ‚èû
 
ùúã(‚Éóùõº)ùëë‚Éóùõº
.
Therefore, the likelihood function to be used in the MCMC algorithm is
‚Ñí(‚Éóùõº, ùêµ) = Œò
(Ô∏Å
ùêµ
(Ô∏Ä
ùëÄ(ùëã; ‚Éóùõº), ùê∑
)Ô∏Ä)Ô∏Å
,
which is Equation (3.17) presented in Section 3.3.
107

108

Bibliography
[1] Brian M Adams, WJ Bohnhoff, KR Dalbey, JP Eddy, MS Eldred, DM Gay,
K Haskell, Patricia D Hough, and Laura P Swiler. Dakota, a multilevel parallel
object-oriented framework for design optimization, parameter estimation, uncer-
tainty quantification, and sensitivity analysis: version 5.0 user‚Äôs manual. Sandia
National Laboratories, Tech. Rep. SAND2010-2183, 2009.
[2] Mark A. Beaumont, Wenyang Zhang, and David J. Balding.
Approximate
bayesian computation in population genetics. Genetics, 162(4):2025‚Äì2035, 2002.
[3] Paul Mac Berthouex and Linfield C. Brown. Statistics for Environmental Engi-
neers. Lewis Publishers, 2002.
[4] Christopher M. Bishop. Pattern Recognition and Machine Learning (Information
Science and Statistics). Springer-Verlag, Berlin, Heidelberg, 2006.
[5] Ariel Caticha. Entropic inference and the foundations of physics. Brazilian
Chapter of the International Society for Bayesian Analysis-ISBrA, Sao Paulo,
Brazil, 2012.
[6] Radu V. Craiu and Jeffrey S. Rosenthal. Bayesian computation via markov chain
monte carlo. Annual Review of Statistics and Its Application, 1(1):179‚Äì201, 2014.
[7] Bert J Debusschere, Habib N Najm, Philippe P P√©bay, Omar M Knio, Roger G
Ghanem, and Olivier P Le Maƒ± tre. Numerical challenges in the use of polyno-
mial chaos representations for stochastic processes. SIAM journal on scientific
computing, 26(2):698‚Äì719, 2004.
[8] Thomas G. Dietterich. Ensemble methods in machine learning. In Multiple Clas-
sifier Systems, pages 1‚Äì15, Berlin, Heidelberg, 2000. Springer Berlin Heidelberg.
[9] Anthony William Fairbank Edwards. Likelihood. CUP Archive, 1984.
[10] F. Feroz and M. P. Hobson. Multimodal nested sampling: an efficient and robust
alternative to markov chain monte carlo methods for astronomical data analyses.
Monthly Notices of the Royal Astronomical Society, 384(2):449‚Äì463, Jan 2008.
[11] F. Feroz, M. P. Hobson, and M. Bridges. Multinest: an efficient and robust
bayesian inference tool for cosmology and particle physics. Monthly Notices of
the Royal Astronomical Society, 398(4):1601‚Äì1614, Oct 2009.
109

[12] Scott Ferson, William L. Oberkampf, and Lev Ginzburg. Model validation and
predictive capability for the thermal challenge problem. Computer Methods
in Applied Mechanics and Engineering, 197(29):2408 ‚Äì 2430, 2008. Validation
Challenge Workshop.
[13] A. E. Gelfand and D. K. Dey. Bayesian model choice: Asymptotics and exact
calculations. Journal of the Royal Statistical Society: Series B (Methodological),
56(3):501‚Äì514, 1994.
[14] John Geweke. Bayesian model comparison and validation. American Economic
Review, 97(2):60‚Äì64, May 2007.
[15] R Ghanem, D Higdon, and H Owhadi. The uncertainty quantification toolkit
(uqtk), handbook of uncertainty quantification, 2016.
[16] Walter R Gilks, Sylvia Richardson, and David Spiegelhalter. Markov chain Monte
Carlo in practice. Chapman and Hall/CRC, 1995.
[17] W. K. Hastings. Monte carlo sampling methods using markov chains and their
applications. Biometrika, 57(1):97‚Äì109, 1970.
[18] Marc C Kennedy and Anthony O‚ÄôHagan. Bayesian calibration of computer
models. Journal of the Royal Statistical Society: Series B (Statistical Methodology),
63(3):425‚Äì464, 2001.
[19] Kevin H Knuth. Optimal data-based binning for histograms. arXiv preprint
physics/0605197, 2006.
[20] Kevin H. Knuth, Michael Habeck, Nabin K. Malakar, Asim M. Mubeen, and
Ben Placek. Bayesian evidence and model selection. Digital Signal Processing,
47:50‚Äì67, Dec 2015.
[21] Olivier Le Ma√Ætre and Omar M Knio. Spectral methods for uncertainty quantifi-
cation: with applications to computational fluid dynamics. Springer Science &
Business Media, 2010.
[22] Guesuk Lee, Wongon Kim, Hyunseok Oh, Byeng D Youn, and Nam H Kim.
Review of statistical model calibration and validation‚Äîfrom the perspective of
uncertainty structures. Structural and Multidisciplinary Optimization, pages 1‚Äì26,
2019.
[23] Peter M Lee. Bayesian statistics. Arnold Publication, 1997.
[24] Thomas Leonard and John SJ Hsu. Bayesian methods: an analysis for statisticians
and interdisciplinary researchers, volume 5. Cambridge University Press, 2001.
[25] Chenzhao Li and Sankaran Mahadevan. Role of calibration, validation, and
relevance in multi-level uncertainty integration. Reliability Engineering & System
Safety, 148:32 ‚Äì 43, 2016.
110

[26] Wei Li, Wei Chen, Zhen Jiang, Zhenzhou Lu, and Yu Liu. New validation metrics
for models with multiple correlated responses. Reliability Engineering & System
Safety, 127:1 ‚Äì 11, 2014.
[27] You Ling and Sankaran Mahadevan. Quantitative model validation techniques:
New insights. Reliability Engineering & System Safety, 111:217 ‚Äì 231, 2013.
[28] Yu Liu, Wei Chen, Paul Arendt, and Hong-Zhong Huang. Toward a better under-
standing of model validation metrics. Journal of Mechanical Design, 133(7):071005,
2011.
[29] Scott M. Lynch. Introduction to Applied Bayesian Statistics and Estimation for
Social Scientists. Springer-Verlag, New York, 2007.
[30] David J. C. MacKay. Information Theory, Inference & Learning Algorithms.
Cambridge University Press, New York, NY, USA, 2002.
[31] Sankaran Mahadevan and Ramesh Rebba. Validation of reliability computational
models using bayes networks. Reliability Engineering & System Safety, 87(2):223
‚Äì 232, 2005.
[32] Alberto Malinverno and Victoria A Briggs. Expanded uncertainty quantification in
inverse problems: Hierarchical bayes and empirical bayes. Geophysics, 69(4):1005‚Äì
1016, 2004.
[33] Jean-Michel Marin, Pierre Pudlo, Christian P. Robert, and Robin J. Ryder. Ap-
proximate bayesian computational methods. Statistics and Computing, 22(6):1167‚Äì
1180, Nov 2012.
[34] Kathryn A Maupin, Laura P Swiler, and Nathan W Porter. Validation metrics
for deterministic and probabilistic data. Journal of Verification, Validation and
Uncertainty Quantification, 3(3):031002, 2018.
[35] Nicholas Metropolis, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H.
Teller, and Edward Teller. Equation of state calculations by fast computing
machines. The Journal of Chemical Physics, 21(6):1087‚Äì1092, 1953.
[36] Joshua Mullins, You Ling, Sankaran Mahadevan, Lin Sun, and Alejandro Strachan.
Separation of aleatory and epistemic uncertainty in probabilistic model validation.
Reliability Engineering & System Safety, 147:49 ‚Äì 59, 2016.
[37] Radford M. Neal. An improved acceptance procedure for the hybrid monte carlo
algorithm. Journal of Computational Physics, 111(1):194‚Äì203, March 1994.
[38] William L. Oberkampf and Matthew F. Barone. Measures of agreement between
computation and experiment: Validation metrics. Journal of Computational
Physics, 217(1):5 ‚Äì 36, 2006. Uncertainty Quantification in Simulation Science.
111

[39] William L Oberkampf, Timothy G Trucano, and Charles Hirsch. Verification,
validation, and predictive capability in computational engineering and physics.
Applied Mechanics Reviews, 57(5):345‚Äì384, 12 2004.
[40] Inseok Park, Hemanth K. Amarchinta, and Ramana V. Grandhi. A Bayesian
approach for quantification of model uncertainty. Reliability Engineering &
System Safety, 95(7):777‚Äì785, 2010.
[41] M Parno and A Davis. MUQ: MIT Uncertainty Quantification Library, 2018.
[42] Matthew D. Parno and Youssef M. Marzouk.
Transport map accelerated
markov chain monte carlo. SIAM/ASA Journal on Uncertainty Quantification,
6(2):645‚Äì682, Jan 2018.
[43] Yudi Pawitan. In all likelihood: statistical modelling and inference using likelihood.
Oxford University Press, 2001.
[44] Fabian Pedregosa, Ga√´l Varoquaux, Alexandre Gramfort, Vincent Michel,
Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, et al. Scikit-learn: Machine learning in python. Journal
of machine learning research, 12(Oct):2825‚Äì2830, 2011.
[45] Ben Placek. Bayesian detection and characterization of extra-solar planets via
photometric variations. PhD thesis, 2014.
[46] Ben Placek, Kevin H. Knuth, and Daniel Angerhausen. EXONEST: BAYESIAN
MODEL SELECTION APPLIED TO THE DETECTION AND CHARAC-
TERIZATION OF EXOPLANETS VIA PHOTOMETRIC VARIATIONS. The
Astrophysical Journal, 795(2):112, oct 2014.
[47] Ramesh Rebba and Sankaran Mahadevan. Computational methods for model
reliability assessment. Reliability Engineering & System Safety, 93(8):1197 ‚Äì 1207,
2008.
[48] Christian P. Robert, V√≠ctor Elvira, Nick Tawn, and Changye Wu. Accelerating
mcmc algorithms. Wiley Interdisciplinary Reviews: Computational Statistics,
10(5):e1435, 2018.
[49] Christopher J. Roy and William L. Oberkampf. A comprehensive framework for
verification, validation, and uncertainty quantification in scientific computing.
Computer Methods in Applied Mechanics and Engineering, 200(25):2131 ‚Äì 2144,
2011.
[50] Shankar Sankararaman and Sankaran Mahadevan. Model validation under epis-
temic uncertainty. Reliability Engineering & System Safety, 96(9):1232 ‚Äì 1241,
2011. Quantification of Margins and Uncertainties.
112

[51] Shankar Sankararaman and Sankaran Mahadevan. Assessing the reliability of
computational models under uncertainty. In 54th AIAA/ASME/ASCE/AHS/ASC
Structures, Structural Dynamics, and Materials Conference, page 1873, 2013.
[52] Shankar Sankararaman and Sankaran Mahadevan. Integration of model verifi-
cation, validation, and calibration for uncertainty quantification in engineering
systems. Reliability Engineering & System Safety, 138:194‚Äì209, 2015.
[53] D. S. Sivia and J. Skilling. Data Analysis - A Bayesian Tutorial. Oxford Science
Publications. Oxford University Press, 2nd edition, 2006.
[54] John Skilling. Nested sampling for general bayesian computation. Bayesian Anal.,
1(4):833‚Äì859, 12 2006.
[55] D. Sornette, A. B. Davis, K. Ide, K. R. Vixie, V. Pisarenko, and J. R. Kamm.
Algorithm for model validation: Theory and applications. Proceedings of the
National Academy of Sciences, 104(16):6562‚Äì6567, 2007.
[56] M Stefano and B Sudret. Uqlab user manual-polynomial chaos expansions. report
uqlab-v0. 9-104, chair of risk, safety and uncertainty quantification. ETH Zurich,
2015.
[57] Nathaniel Stevens.
Assessment and comparison of continuous measurement
systems. 2014.
[58] Tony Tohme, Kevin Vanslette, and Kamal Youcef-Toumi. Generalized bayesian
regression and model learning. arXiv preprint arXiv:1911.11715, 2019.
[59] Paul Troughton and Simon J. Godsill. Bayesian model selection for time series
using markov chain monte carlo. In ICASSP, pages 3733‚Äì3736, 1997.
[60] T.G. Trucano, L.P. Swiler, T. Igusa, W.L. Oberkampf, and M. Pilch. Calibration,
validation, and sensitivity analysis: What‚Äôs what. Reliability Engineering &
System Safety, 91(10):1331 ‚Äì 1357, 2006. The Fourth International Conference
on Sensitivity Analysis of Model Output (SAMO 2004).
[61] Kevin Vanslette, Abdullatif Al Alsheikh, and Kamal Youcef-Toumi. Why simple
quadrature is just as good as monte carlo. Monte Carlo Methods and Applications,
26(1), 2020.
[62] Kevin Vanslette, Tony Tohme, and Kamal Youcef-Toumi. A general model
validation and testing tool. Reliability Engineering & System Safety, 195, March
2020.
[63] Chong Wang and Hermann G. Matthies. Novel model calibration method via non-
probabilistic interval characterization and bayesian theory. Reliability Engineering
& System Safety, 183:84 ‚Äì 92, 2019.
[64] CJ Wild and GAF Seber. Nonlinear regression. New York: Wiley, 1989.
113

[65] Danqing Wu, Zhenzhou Lu, Yanping Wang, and Lei Cheng. Model validation and
calibration based on component functions of model output. Reliability Engineering
& System Safety, 140:59 ‚Äì 70, 2015.
[66] Ruoxue Zhang and Sankaran Mahadevan. Bayesian methodology for reliability
model acceptance. Reliability Engineering & System Safety, 80(1):95 ‚Äì 103, 2003.
[67] Lufeng Zhao, Zhenzhou Lu, Wanying Yun, and Wenjin Wang. Validation metric
based on mahalanobis distance for models with multiple correlated responses.
Reliability Engineering & System Safety, 159:80 ‚Äì 89, 2017.
114

