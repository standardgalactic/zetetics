The Bayesian Validation Metric: A Framework for
Probabilistic Model Calibration and Validation
by
Tony Tohme
Submitted to the Center for Computational Science and Engineering
in partial fulfillment of the requirements for the degree of
Master of Science in Computation for Design and Optimization
at the
MASSACHUSETTS INSTITUTE OF TECHNOLOGY
May 2020
câ—‹Massachusetts Institute of Technology 2020. All rights reserved.
Author . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Center for Computational Science and Engineering
May 20, 2020
Certified by. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Kamal Youcef-Toumi
Professor of Mechanical Engineering
Thesis Supervisor
Accepted by . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Youssef Marzouk
Associate Professor of Aeronautics and Astronautics
Co-Director, Center for Computational Science and Engineering

2

The Bayesian Validation Metric: A Framework for
Probabilistic Model Calibration and Validation
by
Tony Tohme
Submitted to the Center for Computational Science and Engineering
on May 20, 2020, in partial fulfillment of the
requirements for the degree of
Master of Science in Computation for Design and Optimization
Abstract
In model development, model calibration and validation play complementary roles
toward learning reliable models. In this thesis, we propose and develop the â€œBayesian
Validation Metricâ€ (BVM) as a general model validation and testing tool. We show
that the BVM can represent all the standard validation metrics â€“ square error,
reliability, probability of agreement, frequentist, area, probability density comparison,
statistical hypothesis testing, and Bayesian model testing â€“ as special cases while
improving, generalizing and further quantifying their uncertainties. In addition, the
BVM assists users and analysts in designing and selecting their models by allowing
them to specify their own validation conditions and requirements. Further, we expand
the BVM framework to a general calibration and validation framework by inverting the
validation mathematics into a method for generalized Bayesian regression and model
learning. We perform Bayesian regression based on a userâ€™s definition of model-data
agreement. This allows for model selection on any type of data distribution, unlike
Bayesian and standard regression techniques, that â€œfailâ€ in some cases. We show
that our tool is capable of representing and combining Bayesian regression, standard
regression, and likelihood-based calibration techniques in a single framework while
being able to generalize aspects of these methods. This tool also offers new insights
into the interpretation of the predictive envelopes in Bayesian regression, standard
regression, and likelihood-based methods while giving the analyst more control over
these envelopes.
Thesis Supervisor: Kamal Youcef-Toumi
Title: Professor of Mechanical Engineering
3

4

This thesis is dedicated to my family

6

Acknowledgments
This research was performed collaboratively with Dr. Kevin Vanslette under the
supervision of Professor Kamal Youcef-Toumi, and it was generously supported by the
Center for Complex Engineering Systems (CCES) at King Abdulaziz City for Science
and Technology (KACST) and the Massachusetts Institute of Technology (MIT).
I would like to express my sincere gratitude and deep appreciation to Kamal for
believing in me and inspiring me. His guidance and support have been invaluable
throughout this research.
Much credit for the work in this thesis goes to my fantastic friend, collaborator,
and mentor Kevin. His motivation and encouragement have been the driving force
behind this research. I honestly owe him tremendously.
I am highly indebted to Associate Provost Philip Khoury whose inspiration and
support made my journey at MIT superb and fruitful.
I was very fortunate to take a course with Professor Gilbert Strang. I am genuinely
blessed to have worked with him.
Many thanks to Professor Youssef Marzouk, Professor Nicolas Hadjiconstantinou,
and Kate Nelson for being behind the success of the Center for Computational Science
and Engineering (CCSE).
I am profoundly grateful to Tariq, Kathy, and my friends for being there for me
and celebrating with me every success.
Finally, words will never be enough to express my gratitude and love to my parents,
Mike and Nicole, my girlfriend Maria, my uncles, Georges and Ziad, my aunts, Simone,
Mona and Arlette, my granduncle Emile, and my grandparents, Salma, Yvette and
Pierre, for their endless support, encouragement, sacrifices and love; this thesis is
dedicated to them. Lastly, yet most importantly, I would like to thank God who has
given me the insight, strength, and perseverance to complete this work.
7

8

A Note on the Content
This thesis contains material which I authored or co-authored [58, 62].
Chapter 2 of this thesis is based on the following previous publication:
[62] Kevin Vanslette, Tony Tohme, and Kamal Youcef-Toumi. A general model
validation and testing tool. Reliability Engineering & System Safety, 195,
March 2020.
Chapter 3 of this thesis is based on the following manuscript:
[58] Tony Tohme, Kevin Vanslette, and Kamal Youcef-Toumi. Generalized bayesian
regression and model learning. arXiv preprint arXiv:1911.11715, 2019.
Chapter 1 and Chapter 4 contain material from both papers [58, 62].
9

10

Contents
1
Introduction
21
1.1
Introduction and Overview . . . . . . . . . . . . . . . . . . . . . . . .
21
1.2
Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
1.3
Objectives and Contributions
. . . . . . . . . . . . . . . . . . . . . .
25
1.4
Thesis Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28
2
The Bayesian Validation Metric
29
2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
2.2
Notation and Overview . . . . . . . . . . . . . . . . . . . . . . . . . .
29
2.3
Formulation of the BVM . . . . . . . . . . . . . . . . . . . . . . . . .
31
2.3.1
Derivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
2.3.2
An Identical Representation . . . . . . . . . . . . . . . . . . .
33
2.3.3
Importance and Statistical Responsibility . . . . . . . . . . . .
33
2.4
Meeting the Desirable Validation Criterion . . . . . . . . . . . . . . .
34
2.4.1
Compound Booleans . . . . . . . . . . . . . . . . . . . . . . .
35
2.4.2
The BVM Under the Conditions of Exact Agreement . . . . .
35
2.4.3
Meeting Underrepresented Validation Criteria . . . . . . . . .
37
2.5
Representing and Generalizing the Known Validation Metrics with the
BVM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
2.5.1
Representing the Known Validation Metrics
. . . . . . . . . .
39
2.5.2
Generalizing the Known Validation Metrics . . . . . . . . . . .
42
2.6
BVM Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
2.6.1
The Statistical Power BVM
. . . . . . . . . . . . . . . . . . .
46
2.6.2
The
(ï¸€
âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€
BVM . . . . . . . . . . . . . . . . . . . . . . . .
47
11

2.6.3
Exploring the BVM Ratio with the (ğ›¾, ğœ–) BVM
. . . . . . . .
50
2.7
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
3
Generalized Bayesian Regression and Model Learning
57
3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
57
3.2
Background and Motivation . . . . . . . . . . . . . . . . . . . . . . .
57
3.2.1
Standard Regression
. . . . . . . . . . . . . . . . . . . . . . .
58
3.2.2
Likelihood-Based Methods . . . . . . . . . . . . . . . . . . . .
59
3.2.3
Bayesian Regression and Model Testing . . . . . . . . . . . . .
59
3.2.4
BVM Model Testing
. . . . . . . . . . . . . . . . . . . . . . .
63
3.2.5
The Improved Reliability Metric . . . . . . . . . . . . . . . . .
64
3.3
Generalized Bayesian Regression via the BVM . . . . . . . . . . . . .
65
3.4
Implementation and Examples . . . . . . . . . . . . . . . . . . . . . .
69
3.4.1
Computing the BVM Evidence
. . . . . . . . . . . . . . . . .
69
3.4.2
BVM Regression Examples . . . . . . . . . . . . . . . . . . . .
70
3.4.3
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
3.5
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
78
4
Conclusions and Recommendations
79
4.1
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
79
4.2
Recommendations . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
A Representing the Known Validation Metrics with the BVM
81
A.1 Reliability Metric and Probability of Agreement . . . . . . . . . . . .
81
A.2 Frequentist Validation Metric
. . . . . . . . . . . . . . . . . . . . . .
83
A.3 Area and Binned Probability Difference Metric . . . . . . . . . . . . .
84
A.4 Probability Density Function Comparison Metrics . . . . . . . . . . .
87
A.5 Statistical Hypothesis Testing . . . . . . . . . . . . . . . . . . . . . .
88
A.6 Bayesian Model Testing
. . . . . . . . . . . . . . . . . . . . . . . . .
92
B Likelihood-Based Methods
97
12

C Bayesian Model Testing
99
C.1 Normally Distributed Data . . . . . . . . . . . . . . . . . . . . . . . .
100
C.2 Uniformly Distributed Data . . . . . . . . . . . . . . . . . . . . . . .
101
C.3 Completely Certain Data . . . . . . . . . . . . . . . . . . . . . . . . .
102
D BVM Model Selection
103
D.1 Normally Distributed Data . . . . . . . . . . . . . . . . . . . . . . . .
104
D.2 Uniformly Distributed Data . . . . . . . . . . . . . . . . . . . . . . .
106
D.3 Completely Certain Data . . . . . . . . . . . . . . . . . . . . . . . . .
107
13

14

List of Figures
1-1
Illustrative example of theoretical success and failure cases of Bayesian
regression. In blue is a deterministic linear model (ğ‘¦= ğ‘ğ‘¥+ ğ‘) and in red
are the data probability distributions that may come from epistemic and/or
aleatoric uncertainty.
. . . . . . . . . . . . . . . . . . . . . . . . . . .
26
2-1
A common model validation scenario. The model line is trained on
noisy data (not depicted in the figure) and is to be compared to a set of
validation data.
As both the model line and the data are uncertain in
general, any quantitative measure (i.e. the comparison function) between
these comparison values inherits this uncertainty. Thus, any accept/reject
rule on the basis of these uncertain comparison function values is uncertain
as well. A visual inspection of this graph seems to indicate, up to statistical
fluctuation, that the comparison values of the model and data more or less (or
probably) agree, but this intuitive measure has yet to be quantified. Graphic
adapted from [44].
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
15

2-2
Comparison between statistical hypothesis testing and statistical
power BVM. (a) The shaded regions in Column A depict the 95% confidence
interval of each distribution, respectively. Because the data distribution is the
same in each figure and because the statistical hypothesis test is independent
of the proposed model due to assuming the hypothesis ğ‘€= ğ·, each model
is equally valid by that test when it is clear that the model in row 2 is
preferable. (b) The shaded regions in Column B depict the statistical power
of the distributions â€“ the 95% confidence intervals from each distribution is
shaded (integrated) in the otherâ€™s pdf. The statistical power BVM (denoted
ğ‘ƒ(ğ´) in column B) is calculated for each model and indeed the model in row
2 is found to be preferable as it has the highest probability of agreement. .
47
2-3
Validating a deterministic model and an uncertain model accord-
ing to two Boolean agreement functions. (a) The deterministic model
satisfies the âŸ¨ğœ–âŸ©Boolean but fails to pass the
(ï¸€
âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€
requirement given that
its 95% confidence interval has a width of zero. (b) The uncertain model
satisfies both the âŸ¨ğœ–âŸ©and
(ï¸€
âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€
agreement requirements given that its 95%
confidence region has a nonzero width and represents better the uncertain
data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
2-4
Completely Certain Case: The BVM probability of agreement be-
tween each of the models and data plotted in the (ğ›¾, ğœ–) space. Be-
cause here the models are deterministic, the BVM probability of agreement
for each (ğ›¾, ğœ–) pair is either zero or one. (a) The results for model 1 (4th
order polynomial). (b) The results for model 2 (6th order polynomial). As
expected, model 2 better fits the data in the (ğ›¾, ğœ–) space as it has more
BVM values equal to one than model 1, since it is overall closer to the
cosine function being the next nonzero order polynomial in the Taylor series
expansion. Neither model fits the data exactly as the BVM for both models
at (ğ›¾= 100%, ğœ–= 0) is zero. . . . . . . . . . . . . . . . . . . . . . . . .
53
16

2-5
Uncertain Case: The BVM probability of agreement between each
of the models and the data plotted in the (ğ›¾, ğœ–) space. Because the
model paths are uncertain, the BVM probability of agreement for each (ğ›¾, ğœ–)
pair may take any value from zero to one. (a) The results for model 1 (4th
order polynomial). (b) The results for model 2 (6th order polynomial). As
expected, model 2 better fits the data in the (ğ›¾, ğœ–) space as it has generally
larger BVM values than model 1; however, the BVM values are about equal in
cases of large values of ğœ–and low values of ğ›¾(since the definition of agreement
is less stringent and they both â€œagreeâ€) and in the case of demanding absolute
equality (ğœ–= 0) as neither model fits the data exactly. . . . . . . . . . . .
54
2-6
The BVM ratios for the uncertain models plotted in the (ğ›¾, ğœ–) space.
Model 2 is generally favored over model 1 as there exist no values greater
than one on the plot. The amount the BVM ratio favors model 2 over model
1 decreases (i.e. the ratio increases and tends to one) as the metric becomes
less and less stringent (i.e. as ğ›¾decreases and ğœ–increases). The ğœ–= 0 line
was removed because neither model agrees with the data exactly. . . . . .
55
3-1
Truncated tail data distributions solution. Using BVM regression re-
sults in a nonzero probability of finding a model given the observed truncated
data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
3-2
Predictive envelopes of the model in the absence of data uncer-
tainty using the BVM. As tabulated in Table 3.3, Bayesian regression
fails to produce a candidate model solution as the data is completely certain
and standard regression produces a single deterministic solution with no
model uncertainty. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
17

3-3
Illustration of BVM Learning for the Monod model for decreasing
values of ğœ–. In the first row is the prior/posterior parameter distribution
in (ğ›¼1, ğ›¼2) space. The data points are shown by a blue circle in the second
row. The first column corresponds to the situation before any data point is
observed and shows a plot of the prior distribution in (ğ›¼1, ğ›¼2) space together
with six samples of the model response ğ‘€(ğ‘¥; âƒ—ğ›¼) (red lines) in which the
values of ğ›¼1 and ğ›¼2 are randomly drawn from the prior. In the second, third
and fourth columns, we see the situation after running our BVM learning
using MCMC, with a tolerance ğœ–= 0.03, ğœ–= 0.025 and ğœ–= 0.02, respectively.
The posterior has now been influenced by the agreement tolerance ğœ–, this
gives a relatively compact posterior distribution. Samples from this posterior
distribution lead to the functions shown in red in the second row.
. . . .
73
3-4
Comparison between Bayesian regression and BVM regression. (a)
Bayesian regression under infinite tail data distribution. Note that the 95%
confidence interval is very narrow and standard regression method produces
a nearly identical result. (b) BVM regression using the compound Boolean.
In this case, the 95% confidence region is much wider and represents the data
more accurately. Note that this probabilistic model passes both agreement
conditions imposed by the compound Boolean ğµ( ^ğ‘Œ, ğ‘Œ, âŸ¨ğœ–âŸ©, ^ğ›¼). Starting with
a very small âŸ¨ğœ–âŸ©in the MCMC simulation, we tune âŸ¨ğœ–âŸ©by gradually increasing
its value until both elements of the compound Boolean are naturally satisfied.
76
18

List of Tables
2.1
Specification of the four BVM inputs that give the other validation metrics
as special cases.
The column headings are the four BVM input values:
Comparison Values (^^ğ‘§, ğ‘§), Probabilities (ğœŒ(^ğ‘§|ğ‘€, ğ·), ğœŒ(ğ‘§|ğ·)), Comparison
Function ğ‘“= ğ‘“(^ğ‘§, ğ‘§), and the Boolean Agreement Function ğµ(ğ‘“). The
row headings read: Reliability, Improved Reliability, Frequentist, Area, Pdf
Comparison Metrics, Statistical Hypothesis Testing, and Bayesian Model
Testing. The denoted data probability for the average in the frequentist
metric, Stud. ğ‘¡, is the Studentâ€™s ğ‘¡-distribution. . . . . . . . . . . . . . . .
40
2.2
BVM representation of the other validation metrics as special cases using
the comparison functions (the ğ‘“â€™s) specified in Table 2.1.
. . . . . . . . .
41
3.1
Some examples of agreement Boolean functions. . . . . . . . . . . . . . .
67
3.2
The observations we aim to fit. . . . . . . . . . . . . . . . . . . . . . . .
70
3.3
High probability of the model producing posterior parameter distributions and
predictive envelopes for different types of data distributions using the three
approaches. BVM regression is capable of producing posterior distributions
of the model parameters for any type of data distributions.
. . . . . . . .
71
19

20

Chapter 1
Introduction
1.1
Introduction and Overview
Engineering systems are often represented and described by computational models in
order to make predictions about the behavior of the system. Often, models possess
parameters that cannot be directly measured, and instead they are inferred based
on experimental data of relevant inputs and outputs, in a process known as model
calibration [22, 36, 60, 65]. Model calibration is the process of estimating and adjusting
model parameters to obtain a model representation of the system (or data) of interest
while satisfying a specific criterion (objective function). Once the parameters are
inferred, the designed model is tested with respect to real data-generating process, in
a task known as model validation [39, 55, 60].
In model development, model calibration comes in the stage prior to the validation
stage [52], and it usually consists of estimating model parameters given a set of
observed input-output data. Then, validation is performed on a different independent
data set called the validation data set. In what follows, we will use the terms â€œmodel
calibrationâ€, â€œmodel learningâ€ and â€œregressionâ€ interchangeably.
We are interested in studying the calibration and validation of multivariate com-
putational models that represent uncertain situations and observations (or data). It is
understood that complete certainty is a special case of uncertainty as both may be
represented with probability distributions.
21

The uncertainty in a model or data set may originate from stochasticity, model
parameter and input data uncertainty, measurement uncertainty, or other possible
aleatoric or epistemic sources of uncertainty. Each of the following data modeling
schemes may include quantifiable amounts of uncertainty (or certainty) that we would
like to calibrate and then validate on the basis of a set of calibration and validation data:
neural networks and AI models, machine learning models, Gaussian Process Regression
models [18], polynomial chaos and other surrogate models [1, 7, 15, 21], spatial and
time series stochastic models, physics based models (usually solutions to differential
equations), engineering based models (which are sufficiently abstracted physics based
models), Monte Carlo simulation models [16, 35], and more. Model output uncertainties
may be quantified through uncertainty propagation techniques (that may or may not
include verification, calibration, and validation) [1, 7, 15, 18, 25, 31, 41, 49, 50, 52, 56].
1.2
Related Work
Model calibration techniques have been widely studied in the literature. Least squares
(or standard regression) [64], likelihood-based [9, 43], and Bayesian regression methods
[23, 24, 32, 40, 63] are often used for model parameter estimation. Nonprobabilistic
methods, such as parametric model regression, nonparametric neural networks, and
support vector machines (SVM) [4] are able to tackle these types of problems efficiently.
In Bayesian probability theory [29, 30, 53], Bayesian model testing and maximum
likelihood methods provide probabilistic features (i.e. mean, covariance, distribution)
for the parameters we aim to estimate, based on prior knowledge (i.e. prior distribution)
and the uncertainty of the data. Bayesian model testing, which uses Bayesian parameter
regression, was shown to be successful for signal detection, light sensor characterization
[20], exoplanet detection [46], extra-solar planet detection [45], laser peening process
[40], time series [59], astronomical data analyses [10], and cosmology and particle
physics [11].
Model validation techniques have also been extensively studied in the literature.
There exist several validation metrics. Each metric is designed to compare features of
22

a model-data pair to quantify validation: square error compares the difference in the
data and model values in a point to point or interval fashion [63], the reliability metric
[47] and the probability of agreement [57] compare continuous model outputs and data
expectation values (the model reliability metric was extended past expectation values
in [51]), the frequentist validation metric [38] and statistical hypothesis testing compare
data and model test statistics, the area metric compares the cumulative distribution of
the model to the estimated cumulative distribution of the data [12, 26, 27, 49, 65, 67],
probability density function (pdf) comparison metrics (such as the KL Divergence)
measure and represent â€œclosenessâ€ between pdfs, and Bayesian model testing compares
the posterior probability that each model would correctly output the observed data
[13, 14, 31, 45, 50, 53, 66]. A detailed review of the majority of these metrics may
be found in [22, 28, 34, 36] and the references therein. In particular, [34] is an up to
date review that considers many validation metrics in the cases of data and model
certainty, data uncertainty and model certainty, and data and model uncertainty.
To assist the comparison of the positive and negative aspects of the above validation
metrics, reference [28] outlines six â€œdesirable validation criteriaâ€ that a validation
metric might have (they extend [12, 38]). One conclusion from [28] is that none of
the available metrics simultaneously satisfy all six desirable validation criteria. We
summarize the most important features of the desirable validation criteria with the
following validation criterion:
1. A validation metric should be a statistically quantified quantitative measure (as
opposed to a qualitative measure) of the agreement between (general) model
predictions and data pairs, in the presence or absence of uncertainty.
The desire for objectivity, â€œthat a metric will produce the same assessment for every
analyst independent of their individual preferencesâ€ [28], is difficult to satisfy because
there are no rules in place to guide a modeler toward selecting one validation metric
over another. For this reason, the individual might simply choose a metric based on
their preferences, or worse, be tempted to base their decision on which validation
metric gives them the most favorable evaluation.
Given individuals may choose
23

different validation metrics for the same model-data pair, it is possible for individuals
to impose accuracy requirements that are incompatible with one another and arrive at
different conclusions regarding the validity of the same model-data pair. As the final
goal is objectivity, when possible, a map between the accuracy requirements should
be constructed such that the validation metrics yield consistent evaluations of the
model-data validity when applicable.
Further, Liu et al. [28] suggest that there is no agreed upon unified model-data
comparison function. Even including the results of this thesis, we expect this statement
to hold as it is extremely difficult to guess the prior information about the utility
of a model an analyst may be required to include in the validation of a model-data
pair. For instance, given arbitrary data, â€œWhat features of the data are relevant to
capture with a model?â€, â€œOf these features, are some more relevant than others?â€, and
â€œWhat accuracy is required for the model to be valid?â€. Agreement and validation
are ultimately human-made concepts designed for the purpose of expressing that â€œin
general, not every feature or statistic between a model-data pair need to be equal
to conserve the utility of the modelâ€. For some model-data pairs, all that may be
required is that the model and data averages closely match within uncertainty, while
for others, one may require that the model can accurately reproduce the probability
distribution of a data set as a whole (as one would do to physically model a noisy
measurement device). Given the wide variety of data and the large number of different
inferences (and thus models and hypotheses) that one may be interested in drawing
from a given data source (i.e. the context of the model-data pair), we do not expect
any single set of comparison functions, statistics, or values to be equally relevant and
maximally useful for all possible model-data contexts. This, however, does not stop
us from quantifying the validity of a model-data pair given any arbitrary comparison
function and with any arbitrary definition of agreement.
24

1.3
Objectives and Contributions
In this thesis, we propose and construct the â€œBayesian Validation Metricâ€ (BVM) as a
general model validation and testing tool. We design the BVM to adhere to the desired
validation criterion (1.) by using â€œfour BVM inputsâ€: the model and data comparison
values, the model output and data pdfs, the comparison value function, and the
agreement function. The comparison value function is a function of model output and
data comparison values that provides the desired quantitative comparison measure,
e.g. square difference. Using the model output pdf and the data pdf, the value of the
comparison value function is statistically quantified. In turn, the agreement function
provides an accept/reject rule and effectively wraps the previous three BVM inputs
together to give the BVM. From this, the BVM outputs â€œthe probability the model
and data agreeâ€, where agreement is a user-defined Boolean function that meets, or
does not meet, accuracy requirements between model and data comparison values.
Thus, the BVM meets the desired validation criterion (1.) for arbitrary comparison
value functions, arbitrary definitions of agreement, and in principle for arbitrary data
types such as integers, vectors, tensors, strings, pictures, or others.
The BVM can be used to represent all of the aforementioned validation metrics as
special cases. We find the conditions under which several of the current validation
metrics are effectively equal to one another, which improves the objectivity of the
current validation procedure. In brief we find that the frequentist metric (using natural
definitions of agreement) is equal to the reliability metric and the probabilities from
Bayesian model testing are equal to the probabilities of the improved model reliability
metric [51] when one demands exact equality of the (uncertain) model-data comparison
values. Because probability can represent both certain and uncertain situations, so
can the BVM. Thus, these â€œspecial caseâ€ metrics can be generalized to quantify certain
or uncertain cases, and even be combined into more complex validation requirements
using the BVM framework. Thus, the BVM provides a standardized framework to
improve, generalize, or further quantify these validation metrics.
By constructing the â€œBVM ratioâ€, we generalize the Bayesian model testing frame-
25

work [53], in which one constructs the Bayes ratio to rank models according to the
ratio of their posterior probabilities given the data. We show that these posterior
probabilities are equal to a special case of the BVM under the definition of agreement
that requires these uncertain model outputs and data to match exactly. Thus, nothing
prevents us from extending the logic used in the Bayesian model testing framework to
our framework and we construct the BVM ratio for the purpose of model selection
under arbitrary definitions of agreement, i.e. for arbitrary validation scenarios.
Moving to Bayesian calibration techniques, we believe that the efficacy of para-
metric Bayesian regression, likelihood-based methods, and standard regression can be
improved. Bayesian regression calculates the Bayesian evidence, which is the proba-
bility the model could have produced the observed, usually over noisy or uncertain,
data. If this probability is nonzero, one can proceed to calculate posterior model
parameter probabilities using Bayesâ€™ Theorem. In practice, there are models and
parameters that may be of interest to the user that Bayesian regression fails to regress
and produce posterior parameter distributions â€“ Figure 1-1. For some of the instances
that Bayesian regression fails to provide a solution, standard regression may actually
succeed, but usually with some measure of expected error. How this error can translate
into parameter and model uncertainty in the presence of certain or uncertain data is
a problem that is largely omitted in the literature except for a few analytic cases.
(a) Bayesian regression works.
(b) Bayesian regression fails.
Figure 1-1: Illustrative example of theoretical success and failure cases
of Bayesian regression. In blue is a deterministic linear model (ğ‘¦= ğ‘ğ‘¥+ ğ‘)
and in red are the data probability distributions that may come from epistemic
and/or aleatoric uncertainty.
26

Figure 1-1a shows normally distributed data (infinite tails data distribution). In
this case, parametric Bayesian regression finds a linear model that sits in low probability
regions of the data. Figure 1-1b shows uniformly distributed data (truncated data
distribution). In this case, Bayesian regression cannot find a linear model solution
because no linear model can pass through each data distribution simultaneously â€“
the model given the data is regarded as impossible. Standard regression methods
can provide linear model solutions here despite the model lying in a zero probability
region of the data. Although this solution may be considered â€œwrongâ€ because it is
not supported by the data, it successfully provides useful information to the modeler
(an increasing trend). The fact that, for the same model, the solution given by
the calibration method can differ from method to method supports the search for a
framework for their joint representation so they may be compared more concretely.
In this thesis, we represent least squares, likelihood-based, and Bayesian regression
(or calibration) methods by expanding the general validation framework (BVM) into
a general calibration and validation framework. Our method uses the BVM to guide
the regression of a model in a flexible way. Several of our examples use generalizations
of the improved reliability metric and thus reliability is automatically regressed into
our model solutions. Our method gives us better control over the predictive envelopes
of the model under question, which can be used to improve model reliability and
safety. By learning model parameters with the BVM, we are able to estimate and
construct model parameters distributions for any type of data distribution (Gaussian,
Uniform, Completely Certain), which addresses the concerns raised in Figure 1-1. This
construction gives us additional insight into the meaning of the predictive envelopes
of Bayesian regression methods.
We have found that a subset of our method shares mathematical features with Ap-
proximate Bayesian Computation (ABC) methods, which are also known as likelihood-
free techniques [2, 33]. ABC methods are used strictly as an approximation method
for nearly computationally intractable likelihoods in Bayesian regression. While our
method gains this feature in some cases, our methodâ€™s intention is not to approximate
Bayesian regression, but instead to generalize it for the purpose of robust and flexible
27

model calibration.
Our method is able to regress models over a multitude of different data distributions
by using likelihoods that are modified by userâ€™s choice of a useful definition of agreement
between the data and the model â€“ leaning on the BVM formalism. This â€œchoiceâ€ allows
the user to program safety requirements into the model learning process if they
desire. The nature of the BVM formalism forces one to express the model and data
assumptions explicitly and thus our method leads to improved model transparency
and safety. In our examples we show how such a procedure leads to a model that
better represents the uncertain data at hand than Bayesian and standard regression
techniques. This naturally improves the modelâ€™s reliability and safety in the presence
of uncertain data.
1.4
Thesis Outline
The remainder of the thesis is organized as follows. In Chapter 2, we derive and
construct the BVM by following our validation criterion. Through some edge cases,
we show that the BVM satisfies both the six desirable validation criteria from [28]
as well as our validation criterion (1.). We also summarize the results derived in
Appendix A, where we incorporate all of the above standard validation metrics as
special cases of the BVM, draw relationships between several of the validation metrics,
provide improvements and generalizations to these metrics as is suggested by the
functional form of the BVM, and construct the BVM ratio. We end the chapter by
representing three novel validation metrics using the BVM and comparing them to
similar metrics from the literature. We then move to Chapter 3, where we employ
the BVM framework to generalize Bayesian regression. This generalized Bayesian
regression method, namely the BVM model learning technique, works for different
types of data distributions and for arbitrary definitions of model-data agreement.
We then present a simulation application using the BVM model learning technique
on a nonlinear heuristic model, along with a compound Boolean agreement function
example. Chapter 4 is left for conclusions and recommendations.
28

Chapter 2
The Bayesian Validation Metric
2.1
Introduction
In this chapter, we introduce and develop the Bayesian Validation Metric (BVM) which
is a general model validation and testing tool [62]. We find the BVM to be capable of
representing all of the well-known validation metrics as special cases, while improving,
generalizing and further quantifying their uncertainties. The BVM has the capacity to
allow users to invent and select models according to novel validation requirements. We
formulate and test a few novel compound validation metrics that improve upon other
validation metrics in the literature. In addition, we propose and construct the BVM
Ratio for the purpose of quantifying model selection under user-specified definitions
of model-data agreement in the presence or absence of uncertainty. This construction
generalizes the Bayesian model testing framework.
2.2
Notation and Overview
For the remainder of the thesis, we will use the following notation and language. We will
let ^ğ‘¦denote the output of a model, ^ğ‘Œ= {^ğ‘¦1, ..., ^ğ‘¦ğ‘›} a set of ğ‘›model outputs, ğ‘¦a data
point (or observed data), and ğ‘Œ= {ğ‘¦1, ..., ğ‘¦ğ‘›} a set of ğ‘›data points. The proposition
ğ‘€essentially stands for â€œthe modelâ€ or â€œcoming from the modelâ€, i.e. ^ğ‘¦= ğ‘€(ğ‘¥; âƒ—ğ›¼),
where ğ‘¥is the input and âƒ—ğ›¼= (ğ›¼1, . . . , ğ›¼ğ‘š) represents a vector of ğ‘šmodel parameters.
29

The proposition ğ·stands for â€œthe experimentâ€ or â€œcoming from the experimentâ€. We
let ^ğ‘§and ğ‘§represent the comparison quantities of interest, which pertain to the model
and the data respectively. Further, we let the comparison quantities take general
forms, such as multidimensional vectors, functions, or functionals (e.g. output values,
expectation values, pdfs, ...), so we can represent any such pair of quantities we
may wish to compare between the model and the data. When we refer to â€œthe four
BVM inputsâ€ we mean: the comparison values (^ğ‘§, ğ‘§), the model output and data
pdf ğœŒ(^ğ‘§, ğ‘§|ğ‘€, ğ·), the comparison value function ğ‘“(^ğ‘§, ğ‘§), and the agreement function
ğµ= ğµ(ğ‘“(^ğ‘§, ğ‘§)). The (denoted) integrals may be integrals or sums depending on the
nature of the variable being summed or integrated over, which is to be understood from
the discrete or continuous context of the inference at hand. The dot â€œ Â· â€ represents
standard multiplication, which is mainly used to improve aesthetics. Finally, we let ğ´
denote the agreement between the model output and the observed data.
Figure 2-1: A common model validation scenario.
The model line is
trained on noisy data (not depicted in the figure) and is to be compared to a
set of validation data. As both the model line and the data are uncertain in
general, any quantitative measure (i.e. the comparison function) between these
comparison values inherits this uncertainty. Thus, any accept/reject rule on the
basis of these uncertain comparison function values is uncertain as well. A visual
inspection of this graph seems to indicate, up to statistical fluctuation, that the
comparison values of the model and data more or less (or probably) agree, but
this intuitive measure has yet to be quantified. Graphic adapted from [44].
30

Performing uncertainty propagation through a model results in a model output
probability (density) distribution ğœŒ(^ğ‘¦|ğ‘€, ğ·) that ultimately we would like to validate
by comparing it to an uncertain validation data source ğœŒ(ğ‘¦|ğ·), to see if they agree
(as depicted in Figure 2-1). The immediate question is, however, â€œWhat values do
we want to compare and what do we mean by agree?â€. Given the wide variety of
data and the large number of different inferences (and thus models and hypotheses)
that one may be interested in drawing from a given data source (i.e. the context
of the model-data pair), we do not expect any single set of comparison functions to
be equally relevant and maximally useful for all possible model-data contexts. In
light of this, we instead quantify the validity of a model-data pair given any arbitrary
comparison value function and according to any arbitrary definition of agreement.
2.3
Formulation of the BVM
In this section, we construct the Bayesian Validation Metric (BVM), we show its
different representations, and we discuss its importance and statistical responsibility.
2.3.1
Derivation
Here we start constructing the Bayesian Validation Metric (BVM). To capture the
concept of what we might mean by agree, we define ^ğ‘§and ğ‘§to agree, ğ´, when the
Boolean expression, ğµ, is true. Both ğ´and ğµare defined by the modeler and their
prior knowledge of the context of the model-data pair. Naturally then, the agreement
function ğµ= ğµ
(ï¸€
ğ‘“(^ğ‘§, ğ‘§)
)ï¸€
= ğµ(^ğ‘§, ğ‘§) is some function or functional of a comparison
value function ğ‘“(^ğ‘§, ğ‘§).
Given the values of ^ğ‘§and ğ‘§are known, i.e. certain, we quantify agreement using a
probability distribution that assigns certainty,
ğ‘(ğ´|^ğ‘§, ğ‘€, ğ‘§, ğ·) = Î˜
(ï¸€
ğµ(^ğ‘§, ğ‘§)
)ï¸€
.
(2.1)
The indicator function Î˜
(ï¸€
ğµ
)ï¸€
is defined to equal unity if ğµevaluates to â€œtrueâ€ (i.e.
31

â€œagreeingâ€) and equal to zero otherwise. Thus, in the completely certain case, we are
certain as to whether the model and data comparison values agree or do not agree, as
defined by ğµand the deterministic evaluation of ğ‘“(^ğ‘§, ğ‘§).1 We will call ğ‘(ğ´|^ğ‘§, ğ‘€, ğ‘§, ğ·)
the â€œagreement kernelâ€.
Given that in general the comparison values are uncertain, and quantified by
ğœŒ(^ğ‘§, ğ‘§|ğ‘€, ğ·), the probability the comparison values agree, as defined by ğµand ğ‘“(^ğ‘§, ğ‘§),
is equal to,
ğ‘(ğ´|ğ‘€, ğ·)
=
âˆ«ï¸
^ğ‘§,ğ‘§
ğ‘(ğ´|^ğ‘§, ğ‘€, ğ‘§, ğ·) Â· ğœŒ(^ğ‘§, ğ‘§|ğ‘€, ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§,
(2.2)
ğ‘–ğ‘›ğ‘‘.
âˆ’â†’
âˆ«ï¸
^ğ‘§,ğ‘§
ğœŒ(^ğ‘§|ğ‘€, ğ·) Â· Î˜
(ï¸€
ğµ(^ğ‘§, ğ‘§)
)ï¸€
Â· ğœŒ(ğ‘§|ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§,
(2.3)
which is a marginalization over the spaces of (^ğ‘§, ğ‘§).2 Equation (2.2) is the general
form of the Bayesian Validation Metric (BVM). Because ğ´is discrete, the BVM is
a probability rather than a probability density and it therefore falls in the range
0 â‰¤ğ‘(ğ´|ğ‘€, ğ·) â‰¤1. Equation (2.3) explicitly assumes that the uncertainty in the
data is independent of the model, i.e. ğœŒ(ğ‘§|ğ‘€, ^ğ‘§, ğ·) = ğœŒ(ğ‘§|ğ·), that the data ğ·does
not take ^ğ‘§or the model ğ‘€(that it is currently being compared to) as inputs.3 This
is a relatively common scenario so it is stated explicitly. The BVM may be computed
using any of the well-known computational integration methods.
1This binary yet probabilistic definition of agreement turns out to be completely satisfactory for
our current purposes. As is briefly discussed later, the sharp boundaries of the indicator function can
be smoothed out without employing fuzzy logic by allowing parameters in the Boolean function to
themselves be uncertain and marginalized over.
2 Recall that the propositions in the probability distributions ğœŒ(ğ‘§|ğ·) and ğœŒ(^ğ‘§|ğ‘€, ğ·) are completely
arbitrary (in some cases requiring propagation from ğœŒ(ğ‘¦|ğ·) and ğœŒ(^ğ‘¦|ğ‘€, ğ·)), they could be both
continuous, discrete (with order), categorical variables (no well defined order, e.g. strings, pictures,...),
or a mix.
3In a controls system this may not be the case, as the model may interact with the system of
interest. In such a case this constraint may be lifted and one should use (2.2) instead. The joint
probability ğœŒ(^ğ‘§, ğ‘§|ğ‘€, ğ·) can be used to account for the correlations between the model (the controller
or reference) and the data (the measured response of the system being controlled) in a controls
setting in principle.
32

2.3.2
An Identical Representation
In some cases, it is useful to work directly with the probability density ğœŒ(ğ‘“|ğ‘€, ğ·),
which quantifies the probability the comparison value function ğ‘“(^ğ‘§, ğ‘§) takes the value ğ‘“
due to uncertainty in its inputs. This pdf is independent of any user-defined accuracy
requirement. We will call this pdf the comparison value probability density, which is
equal to,
ğœŒ(ğ‘“|ğ‘€, ğ·) =
âˆ«ï¸
^ğ‘§,ğ‘§
ğ›¿(ğ‘“âˆ’ğ‘“(^ğ‘§, ğ‘§)) Â· ğœŒ(^ğ‘§, ğ‘§|ğ‘€, ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§.
(2.4)
This is the net uncertainty propagated through the comparison value function ğ‘“(^ğ‘§, ğ‘§)
from the uncertain model and data comparison values. All of the expectation values
that are associated with ğ‘“may be generated from this pdf.
If one imposes an accuracy requirement with a Boolean expression ğµ= ğµ(ğ‘“)
(i.e. defining agreement according to the value of ğ‘“), the resulting accumulated prob-
ability is the BVM. That is, the BVM, i.e. Equation (2.2), may equally be expressed as,
ğ‘(ğ´|ğ‘€, ğ·) =
âˆ«ï¸
ğ‘“
ğœŒ(ğ‘“|ğ‘€, ğ·) Â· Î˜
(ï¸€
ğµ(ğ‘“)
)ï¸€
ğ‘‘ğ‘“,
(2.5)
which is proven through substitution and marginalization over ğ‘“,
ğ‘(ğ´|ğ‘€, ğ·)
=
âˆ«ï¸
ğ‘“
(ï¸âˆ«ï¸
^ğ‘§,ğ‘§
ğ›¿(ğ‘“âˆ’ğ‘“(^ğ‘§, ğ‘§)) Â· ğœŒ(^ğ‘§, ğ‘§|ğ‘€, ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§
)ï¸
Â· Î˜(ğµ(ğ‘“)) ğ‘‘ğ‘“
=
âˆ«ï¸
^ğ‘§,ğ‘§
Î˜(ğµ(^ğ‘§, ğ‘§)) Â· ğœŒ(^ğ‘§, ğ‘§|ğ‘€, ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§.
(2.6)
2.3.3
Importance and Statistical Responsibility
The BVM allows the user to, in principle, quantify the probability the model and the
data agree with one another under arbitrary comparison value functions and with
arbitrary definitions of agreement. The BVM can therefore be used to fully quantify
the probability of agreement between arbitrary model and data types using novel or
existing comparison value functions and definitions of agreement. Thus, the problem
of model-data validation may be reduced to the problem of finding the four BVM
inputs in any model validation scenario.
33

When using the BVM framework, one should practice statistical responsibility by
explicitly stating the definition of agreement that is implemented in the validation
procedure. Although the flexibility of the BVM framework is a feature, different
validation metrics often have different amounts of tolerance as what constitutes
â€œagreementâ€. Agreement according to one metric does not in general imply agreement
according to another. Overly tolerant definitions of agreement have little resolution
power and can only be used responsibly if a large degree of non-exactness between
the model and data is permissible. In principle, the definition of agreement should
be just as strict or stricter than it needs to be. By explicitly stating the definition of
agreement alongside the BVM value, ğ‘(ğ´|ğ‘€, ğ·) â‰¡ğ‘(ğ´|ğ‘€, ğ·, ğµ), one avoids statistical
misrepresentation by not hiding their definition of agreement.
2.4
Meeting the Desirable Validation Criterion
First we will describe how the BVM, Equations (2.2) and (2.5), precisely match our
validation criterion (1.). As can be seen by Equation (2.4), incorporated into the
BVM is a statistically quantified quantitative measure that compares data and model
outputs, ğœŒ(ğ‘“|ğ‘€, ğ·). However, this pdf is in some sense lacking a context pertaining
to the model-data pair. Not until an accept/reject rule is imparted on ğœŒ(ğ‘“|ğ‘€, ğ·) does
one define what is meant by agreement in the model-data context. Thus, the BVM
only becomes the probability of agreement between the data and the model when the
agreement function is also incorporated. The four BVM inputs are therefore adequate
to satisfy (1.) as the BVM is a â€œstatistically quantified quantitative measure (ğ‘“) of
agreement ğ‘(ğ´|ğ‘€, ğ·) between model predictions and data pairs (^ğ‘§, ğ‘§), in the presence
or absence of uncertainty ğœŒ(^ğ‘§, ğ‘§|ğ‘€, ğ·)â€.
There are a few more BVM concepts worth discussing before moving forward. We
will show that the BVM is capable of handling general multidimensional model-data
comparisons and that there are no conceptual issues when agreement is exact, i.e. ğµ
is true iff ^ğ‘§= ğ‘§, in the certain and uncertain cases. We will then make comments on
the sense in which the BVM adheres to the full set of six desirable validation criteria
34

given in [28] by discussing the criteria that are underrepresented in (1.).
2.4.1
Compound Booleans
Because Boolean operations between Boolean functions result in a Boolean function
itself, the BVM is capable of handling multidimensional model-data comparisons. We
will call a Boolean function with this property a â€œcompound Booleanâ€. A compound
Boolean function results from and, âˆ§, conjunctions and or, âˆ¨, disjunctions between a
set of Boolean functions, e.g.,
ğµ({ğµğ‘–}) =
(ï¸
ğµ1(^ğ‘§, ğ‘§) âˆ¨ğµ2(^ğ‘§, ğ‘§)
)ï¸
âˆ§
(ï¸
ğµ3(^ğ‘§, ğ‘§) âˆ¨ğµ4(^ğ‘§, ğ‘§)
)ï¸
Â· Â· Â·
(2.7)
where each ğµğ‘–(^ğ‘§, ğ‘§) = ğµğ‘–(ğ‘“ğ‘–(^ğ‘§, ğ‘§)) may use a different comparison function ğ‘“ğ‘–(^ğ‘§, ğ‘§).
Compound Booleans using conjunctions quantify the validity of entire model functions
(random fields and/or multidimensional vectors) by assessing agreement between each
of the model-data comparison field points simultaneously, i.e over the comparison
points 1 and points 2 and so on. The compound Booleans may be factored into
their constituting Boolean functions using the standard product and sum rules of
probability theory after being mapped to probabilities with the agreement kernel. One
should be careful when defining an and Boolean; if one of the Booleans is false, then
the entire Boolean is false. If this strict â€œall or nothingâ€ validation requirement is not
needed then other more flexible definitions of agreement may be instantiated instead
(see the BVM examples in Section 2.6).
2.4.2
The BVM Under the Conditions of Exact Agreement
We can calculate the BVM under the conditions of exact agreement in the com-
pletely certain and uncertain cases. Because the BVM is a probability rather than
a probability density, the agreement kernel falls in the range [0, 1]. Under the con-
ditions of exact agreement, ğµis only true when ^ğ‘§= ğ‘§, and the agreement kernel is
Î˜(ğµ) = Î˜(^ğ‘§= ğ‘§) = ğ›¿^ğ‘§,ğ‘§, which is the Kronecker delta (i.e. it is 0 or 1) but with
continuous labels. As it is uncommon to deal with Kronecker deltaâ€™s having continuous
35

labels under integration, we will show that the BVM gives reasonable results under
the condition of exact agreement in the complete certainty as well as in the general
uncertain case.
Complete certainty and exact agreement
Complete certainty is represented using Dirac delta pdf functions over the model and
data comparison values. This gives the BVM,
ğ‘(ğ´|ğ‘€, ğ·)
=
âˆ«ï¸
^ğ‘§,ğ‘§
ğœŒ(^ğ‘§|ğ‘€, ğ·) Â· Î˜(^ğ‘§= ğ‘§) Â· ğœŒ(ğ‘§|ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§
=
âˆ«ï¸
^ğ‘§,ğ‘§
ğ›¿(^ğ‘§âˆ’^ğ‘§â€²) Â· ğ›¿^ğ‘§,ğ‘§Â· ğ›¿(ğ‘§âˆ’ğ‘§â€²) ğ‘‘^ğ‘§ğ‘‘ğ‘§,
(2.8)
where we are considering the model-data pair to agree iff the comparison values are
exactly equal. Using the sifting property of the Dirac delta function, we find the
reasonable result that,
ğ‘(ğ´|ğ‘€, ğ·) = ğ›¿^ğ‘§â€²,ğ‘§â€²,
(2.9)
which is equal to unity iff ^ğ‘§â€² and ğ‘§â€², the definite values of ^ğ‘§and ğ‘§, are equal.
Uncertainty and exact agreement
In the uncertain case under the condition of exact agreement, the BVM is
ğ‘(ğ´|ğ‘€, ğ·) =
âˆ«ï¸
^ğ‘§,ğ‘§
ğœŒ(^ğ‘§|ğ‘€, ğ·) Â· ğ›¿^ğ‘§,ğ‘§Â· ğœŒ(ğ‘§|ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§.
(2.10)
We will do the following trick to correctly interpret this integral. We will first let
ğµ(ğœ–) be true if ğ‘§âˆ’ğœ–â‰¤^ğ‘§â‰¤ğ‘§+ ğœ–and then take the limit as ğœ–â†’0+ such that
limğœ–â†’0+ ğµ(ğœ–) â†’ğµwhen appropriate. With this Boolean expression, the BVM is,
ğ‘(ğ´|ğ‘€, ğ·, ğœ–)
=
âˆ«ï¸
^ğ‘§,ğ‘§
ğœŒ(^ğ‘§|ğ‘€, ğ·) Â· Î˜
(ï¸
ğ‘§âˆ’ğœ–â‰¤^ğ‘§â‰¤ğ‘§+ ğœ–
)ï¸
Â· ğœŒ(ğ‘§|ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§
=
âˆ«ï¸
ğ‘§
ğœŒ(ğ‘§|ğ·)
(ï¸‚âˆ«ï¸ğ‘§+ğœ–
ğ‘§âˆ’ğœ–
ğœŒ(^ğ‘§|ğ‘€, ğ·) ğ‘‘^ğ‘§
)ï¸‚
ğ‘‘ğ‘§.
(2.11)
In the limit ğœ–â†’0+, the term
âˆ«ï¸€ğ‘§+ğœ–
ğ‘§âˆ’ğœ–ğœŒ(^ğ‘§|ğ‘€, ğ·)ğ‘‘^ğ‘§â†’ğ‘(^ğ‘§= ğ‘§|ğ‘€, ğ·) = ğœŒ(^ğ‘§= ğ‘§|ğ‘€, ğ·)ğ‘‘^ğ‘§
by the definition of probabilities. This gives,
36

ğ‘(ğ´|ğ‘€, ğ·)
=
âˆ«ï¸
ğ‘§
ğœŒ(ğ‘§|ğ·)
(ï¸
ğ‘(^ğ‘§= ğ‘§|ğ‘€, ğ·)
)ï¸
ğ‘‘ğ‘§=
(ï¸‚âˆ«ï¸
ğ‘§
ğœŒ(^ğ‘§= ğ‘§|ğ‘€, ğ·) Â· ğœŒ(ğ‘§|ğ·)ğ‘‘ğ‘§
)ï¸‚
ğ‘‘^ğ‘§
â‰¡
ğœŒ(^ğ‘§â‰¡ğ‘§|ğ‘€, ğ·) ğ‘‘^ğ‘§= ğ‘(^ğ‘§â‰¡ğ‘§|ğ‘€, ğ·),
(2.12)
which is understood to be the sum of the model and the data probabilities that jointly
output exactly the same values. We see that the BVM in this case is proportional
to ğ‘‘^ğ‘§, ğ‘(ğ´|ğ‘€, ğ·) â†’ğœŒ(^ğ‘§â‰¡ğ‘§|ğ‘€, ğ·)ğ‘‘^ğ‘§, in the general case of exact agreement, and
therefore the BVM goes to zero unless the pdf ğœŒ(^ğ‘§â‰¡ğ‘§|ğ‘€, ğ·) âˆğ›¿(. . .). Thus, we
recover the standard logical result for probability densities ğ‘(ğ‘¥) = ğœŒ(ğ‘¥)ğ‘‘ğ‘¥â†’0 unless
it is offset by ğœŒ(ğ‘¥) âˆğ›¿(ğ‘¥). This result is easily generalized to the dependent case
using ğœŒ(^ğ‘§, ğ‘§|ğ‘€, ğ·) = ğœŒ(ğ‘§|ğ‘€, ğ·)ğœŒ(^ğ‘§|ğ‘§, ğ‘€, ğ·). The result, Equation (2.12), is no more
surprising than (2.9) in principle.
Due to the vast number of possibilities for continuous valued variables, having a
pathological definition of exact agreement between continuous variables does not occur
in practice. In a computational setting, ğ‘‘ğ‘¥â†’Î”ğ‘¥becomes a finite difference and
these infinitely improbable agreement conceptual issues are avoided. The Bayesian
model testing framework avoids these issues by evaluating posterior odds ratios, in
which case the measures, ğ‘‘^ğ‘§, drop out.
2.4.3
Meeting Underrepresented Validation Criteria
Here we will discuss how the BVM also meets the validation criteria found in [28].
This is done by using the derived general and special cases of the BVM for each of
the criteria which are underrepresented in (1.).
Perhaps the primary underrepresented criterion from [28] is their second. It states
that â€œthe criteria used for determining whether a model is acceptable or not should
not be a part of the metric which is expected to provide a quantitative measurement
only.â€ We argue that the functional form of the BVM presented in Equation (2.5)
clearly demonstrates this feature as it factors into ğœŒ(ğ‘“|ğ‘€, ğ·) and Î˜(ğµ(ğ‘“)). The
37

comparison function ğ‘“(^ğ‘§, ğ‘§) represents the â€œobjective quantitative measureâ€ from their
first criterion that is separate from the accept/reject rule, which is our agreement
function ğµ(ğ‘“) â€“ both of which require definition to ultimately evaluate the validity of
a model. We see it as advantageous to quantify the probability the model is accepted
or rejected through ğµ(ğ‘“) due to the uncertainty in the value of ğ‘“, which is the general
case, and which gives the BVM as the result. As all of the validation metrics presented
in [28] (and more) will be shown to be representable with the BVM, and thus placed
on the same footing, we find our language of â€œcomparison functionâ€ and â€œagreement
functionâ€ to ultimately be more useful than a language that only considers comparison
functions (without accept/reject rules) to be the validation metrics.
The third criteria in [28] is that ideally the metric should â€œdegenerate to the value
from a deterministic comparison between scalar values when uncertainty is absentâ€.
This is indeed the case as can be seen in Equation (2.1) or in Equations (2.2) and
(2.5) by utilizing Dirac delta pdfs similar to their application in Equation (2.8).
The fifth desirable validation criteria in [28] states that artificially widening proba-
bility distributions should not lead to higher rates of validation. They find all but
the frequentist metric to have this undesired feature; however, we later see that the
frequentist metric may be considered a special case of the reliability metric (when
reasonable accuracy requirements are imposed), meaning artificial widening can lead
to higher rates of validation for more general instances of the frequentist metric.
Further, we argue that artificially introducing uncertainty for the express purpose
of passing a validation test is indistinguishable from scientific misconduct. If there is
objective reason to include more uncertainty into the analysis or if the circumstance for
what constitutes validation has changed due to a change of context â€“ and it happens
to improve the rate of validation â€“ so be it. This is a different context, model, or state
of uncertainty than was originally proposed so different rates of acceptance should
be expected. Reducing the uncertainty of either the data or the model (the inputs)
through additional measurements or changing the model may later prove the model
valid or invalid when it may have been initially accepted. Thus, to meet this validation
criteria, we simply assume the user is not engaging in scientific misconduct.
38

Finally, due to the results of the Compound Booleans in Section 2.4.1, their sixth
criterion is met. Because the BVM (2.2) can be used to assess single or multidimensional
controllable settings (see footnote number 3) we can perform global function validity
(in or out of a controls setting). As they note, â€œThis last feature is critical from the
viewpoint of engineering designâ€.
Thus, the BVM satisfies both our validation criterion and the six desirable validation
criteria outlined in [28]. This was accomplished by representing model-data validation
as an inference problem using the four BVM inputs.
2.5
Representing and Generalizing the Known Vali-
dation Metrics with the BVM
This section is a review of the material found in Appendix A. The following validation
metrics will be represented with the BVM, which are then improved, generalized,
and/or commented on: reliability/probability of agreement, improved reliability metric,
frequentist, area metric, pdf comparison metrics, statistical hypothesis testing, and
Bayesian model testing.
2.5.1
Representing the Known Validation Metrics
Table 2.1 shows the values of the four BVM inputs that result in the BVM representing
the well-known validation metrics as special cases. The following notation is used for
the comparison values (^ğ‘§, ğ‘§). The brackets âŸ¨. . .âŸ©denote expectation values, ğœ‡â€™s denote
averaged values, ^ğ‘¦, ğ‘¦denote single values, ^ğ‘Œ, ğ‘Œdenote multidimensional values, ğ¹^ğ‘¦, ğ¹ğ‘¦
denote cumulative distribution functions
(ï¸€
ğ¹ğ‘¦=
âˆ«ï¸€^ğ‘¦
âˆ’âˆğœŒ(^ğ‘¦|ğ‘€, ğ·) ğ‘‘ğ‘¦
)ï¸€
, ğ‘†^ğ‘¦, ğ‘†ğ‘¦denote test
statistics, and [âˆ’ğ‘ğ›¼, ğ‘ğ›¼] denotes the 1 âˆ’ğ›¼confidence interval of the data. In the
agreement function column, an element listed as ğµ(ğ‘“) means the creators of the metric
intentionally left the definition of agreement unspecified; however, it is natural to
assume it is a function of the comparison function ğ‘“.
Table 2.1 shows the specification of the four BVM inputs that give the other
39

validation metrics as special cases. It also summarizes some of the similarities and
difference between the known validation metrics. In particular, by looking at the
validation metrics with the same type of comparison values, i.e. the reliability and
frequentist or the improved reliability and Bayesian model testing, we can compare
them directly. We see that if one lets the frequentist metric allow for more general
input probability distributions and the use of a reasonable agreement function (i.e.,
ğµ(ğ‘“) is true if |ğ‘“| < ğœ–), then the frequentist metric is the reliability metric. Further,
in Bayesian model testing, if the agreement function ğµ(ğ‘“) is loosened to accept ğ‘“< ğœ–,
then the pdfs that appear in the Bayesian model testing framework are equal to the
improved reliability metric. This information improves the objectivity of the current
validation procedure because we now have a map between validation metrics that were
originally thought to be different.
Comp. Values
Probs.
Comp. Func.
Agree. Func.
BVM
^ğ‘§
ğ‘§
ğœŒ(^ğ‘§|ğ‘€, ğ·)
ğœŒ(ğ‘§|ğ·)
ğ‘“(^ğ‘§, ğ‘§)
ğµ(ğ‘“)
Reliability
âŸ¨^ğ‘¦âŸ©
ğœ‡ğ‘¦
ğœŒ(âŸ¨^ğ‘¦âŸ©|ğ‘€, ğ·)
ğœŒ(ğœ‡ğ‘¦|ğ·)
|âŸ¨^ğ‘¦âŸ©âˆ’ğœ‡ğ‘¦|
ğ‘“< ğœ–
Imp. Reli.
^ğ‘Œ
ğ‘Œ
ğœŒ( ^ğ‘Œ|ğ‘€, ğ·)
ğœŒ(ğ‘Œ|ğ·)
| ^ğ‘Œâˆ’ğ‘Œ|
ğ‘“< ğœ–
Frequentist
âŸ¨^ğ‘¦âŸ©
ğœ‡ğ‘¦
ğ›¿(âŸ¨^ğ‘¦âŸ©âˆ’âŸ¨^ğ‘¦âŸ©â€²)
Stud. ğ‘¡
âŸ¨^ğ‘¦âŸ©âˆ’ğœ‡ğ‘¦
ğµ(ğ‘“)
Area
ğ¹^ğ‘¦
ğ¹ğ‘¦
ğ›¿(ğ¹^ğ‘¦âˆ’ğ¹â€²
^ğ‘¦)
ğ›¿(ğ¹ğ‘¦âˆ’ğ¹â€²
ğ‘¦)
âˆ«ï¸€
^ğ‘¦|ğ¹^ğ‘¦âˆ’ğ¹ğ‘¦=^ğ‘¦|ğ‘‘^ğ‘¦
ğµ(ğ‘“)
Pdf Comp.
ğœŒğ‘€
ğœŒğ·
ğ›¿(ğœŒğ‘€âˆ’ğœŒâ€²
ğ‘€)
ğ›¿(ğœŒğ·âˆ’ğœŒâ€²
ğ·)
ğº(ğœŒğ·||ğœŒğ‘€)
ğµ(ğ‘“)
Stat. Hyp.
ğ‘†^ğ‘¦
ğ‘†ğ‘¦
ğœŒ(ğ‘†^ğ‘¦|ğ‘€= ğ·)
ğœŒ(ğ‘†ğ‘¦|ğ·)
ğ‘†^ğ‘¦
ğ‘†^ğ‘¦âˆˆ[âˆ’ğ‘ğ›¼, ğ‘ğ›¼]
Bayes Model
^ğ‘Œ
ğ‘Œ
ğœŒ( ^ğ‘Œ|ğ‘€, ğ·)
ğœŒ(ğ‘Œ|ğ·)
| ^ğ‘Œâˆ’ğ‘Œ|
ğ‘“= 0
Table 2.1: Specification of the four BVM inputs that give the other validation
metrics as special cases. The column headings are the four BVM input val-
ues: Comparison Values (^^ğ‘§, ğ‘§), Probabilities (ğœŒ(^ğ‘§|ğ‘€, ğ·), ğœŒ(ğ‘§|ğ·)), Comparison
Function ğ‘“= ğ‘“(^ğ‘§, ğ‘§), and the Boolean Agreement Function ğµ(ğ‘“). The row
headings read: Reliability, Improved Reliability, Frequentist, Area, Pdf Compari-
son Metrics, Statistical Hypothesis Testing, and Bayesian Model Testing. The
denoted data probability for the average in the frequentist metric, Stud. ğ‘¡, is the
Studentâ€™s ğ‘¡-distribution.
Table 2.2 shows the resulting BVM using the specifications listed in Table 2.1.
The value ğ‘Ÿis the standard notation for the reliability metric [47] and we use ğ‘Ÿğ‘–
for the improved reliability metric [51]. The BVM represents each of the known
40

validation metrics as a probability of agreement between the model and the data from
Equation (2.2). As no agreement function is specified directly for the frequentist and
area metric, the problem is under constrained so the agreement functions are left as
general functions over the comparison function ğµ(ğ‘“). Thus, for any chosen agreement
function, the BVM quantifies their probability of agreement. The remaining metrics
all do specify (or indicate) an agreement function, and thus, have specified all of the
information required to compute the BVM.
BVM
BVM
âˆ«ï¸€
ğ‘“ğœŒ(ğ‘“|ğ‘€, ğ·) Â· Î˜(ğµ(ğ‘“)) ğ‘‘ğ‘“
Reliability
âˆ«ï¸€
ğ‘“ğœŒ(ğ‘“|ğ‘€, ğ·) Â· Î˜(ğ‘“< ğœ–) ğ‘‘ğ‘“= ğ‘Ÿ
Imp. Reli.
âˆ«ï¸€
ğ‘“ğœŒ(ğ‘“|ğ‘€, ğ·) Â· Î˜(ğ‘“< ğœ–) ğ‘‘ğ‘“= ğ‘Ÿğ‘–
Frequentist
âˆ«ï¸€
ğœ‡ğ‘¦ğœŒ(ğœ‡ğ‘¦|ğ·) Â· Î˜(ğµ(ğ‘“(âŸ¨^ğ‘¦âŸ©â€², ğœ‡ğ‘¦))) ğ‘‘ğœ‡ğ‘¦
Area
Î˜(ğµ(ğ‘“(ğ¹â€²
^ğ‘¦, ğ¹â€²
ğ‘¦))
Pdf Comp.
Î˜(ğµ(ğ‘“(ğœŒâ€²
ğ‘€, ğœŒâ€²
ğ·))
Stat. Hyp.
âˆ«ï¸€
ğ‘†^ğ‘¦ğœŒ(ğ‘†^ğ‘¦|ğ‘€= ğ·) Â· Î˜(ğ‘†^ğ‘¦âˆˆ[âˆ’ğ‘ğ›¼, ğ‘ğ›¼]) ğ‘‘ğ‘†^ğ‘¦= 1 âˆ’ğ›¼
Bayes Model
âˆ«ï¸€
ğ‘“ğœŒ(ğ‘“|ğ‘€, ğ·) Â· Î˜(ğ‘“= 0) ğ‘‘ğ‘“= ğ‘( ^ğ‘Œâ‰¡ğ‘Œ|ğ‘€, ğ·)
Table 2.2: BVM representation of the other validation metrics as special cases
using the comparison functions (the ğ‘“â€™s) specified in Table 2.1.
Statistical hypothesis testing is perhaps a bit out of place among the validation
metrics. First, note that the comparison function for statistical hypothesis testing
is not a function of both the data and the model. Further, note that the model pdf
used for statistical hypothesis testing assumes the null hypothesis is true, which in
our language is the assumption that ğœŒ(ğ‘†^ğ‘¦|ğ‘€, ğ·) = ğœŒ(ğ‘†^ğ‘¦|ğ‘€= ğ·), i.e. that the pdf
of the model is equal to the pdf of the data. This shows how statistical hypothesis
testing is a bit out of place here among the validation metrics because here we are
attempting to validate a model, usually with its own quantified pdf, rather than,
perhaps irresponsibly, assuming it is equal to the data pdf before validating that
to be the case. This causes standard statistical hypothesis pitfalls, such as type I
(rejecting the null hypothesis when it is true) and type II errors (accepting the null
41

hypothesis when it is false), to be carried over into the BVM, which is unwanted.
Several comments are made in Appendix A.5 on this issue.
A perhaps surprising result is the proposed functional form of the BVM that rep-
resents Bayesian model testing ğ‘(ğ´|ğ‘€, ğ·) = ğ‘(^ğ‘Œâ‰¡ğ‘Œ|ğ‘€, ğ·), which is the Bayesian
evidence. This is the probability that the uncertain model and data output exactly
the same values. Usually what is discussed when reviewing Bayesian model testing is
the Bayes posterior odds ratio, i.e. the â€œBayes Ratioâ€,
ğ‘…= ğ‘(ğ‘€|ğ‘Œ)
ğ‘(ğ‘€â€²|ğ‘Œ) âˆğ‘(ğ‘Œ|ğ‘€)
ğ‘(ğ‘Œ|ğ‘€â€²),
which tests one model ğ‘€(i.e. for validation) against another model ğ‘€â€². However,
in validation metric problems, we are first interested in considering the validation of
a single model â€“ the ratio is an extra bit of inference. In Appendix A.6, we show
that the BVM result of ğ‘(^ğ‘Œâ‰¡ğ‘Œ|ğ‘€, ğ·) is exactly what we mean by ğ‘(ğ‘Œ|ğ‘€) in the
numerator of the Bayes factor,4 which effectively quantifies the validation of a single
model against the data ğ‘Œ, all quantified under uncertainty.
2.5.2
Generalizing the Known Validation Metrics
The BVM offers several avenues to either generalize or improve many of the metrics.
The types of generalizations the BVM offer pertain to generalizing the comparison
values, comparison functions, definitions of agreement, and/or generalizing deter-
ministic comparison values and metrics to the uncertain case. These generalizations
are only useful if quantitative statements can be made on their behalf â€“ in such
a case, these generalizations are improvements. We will give a brief review of the
improvements we found below, but the full discussion is located in Appendix A. By
making generalizations or improvements to each of the known validation metrics as
implied by the BVM, each metric can be made to satisfy our validation criterion as
well as the six desirable validation criteria in [28], due to the results of Section 2.4.
4It should be noted that our notation for ğ·differs from the notation typically used in Bayesian
model testing. Their ğ·is equal to our data ğ‘Œ, while our ğ·refers to context â€œas having come from
the data or experiment rather than the modelâ€.
42

Appendix A.1 uses the BVM to show that the reliability metric and the improved
reliability metric can be generalized to compare values without a unique order, such as
strings, in principle. This involves creating an agreement function over sets of values
(such as synonymous sets of strings), rather than continuous intervals, that may be
considered to â€œagreeâ€.
Appendix A.2 derives the frequentist validation metric and generalizes it to the
case where both the model and data expectation values are uncertain. The frequentist
metric assumes that the model outputs are known with certainty, which may or may
not be true. If a model is stochastic, the model pdfs may be estimated with Monte
Carlo or other uncertainty propagation methods that quantify the pdf directly.
Appendix A.3 shows that the area metric may be cast as a special case of the
BVM. The area metric involves quantifying the difference between model and data
cumulative distributions on a point to point basis; thus, the comparison values (^ğ‘§, ğ‘§)
are cumulative distributions themselves. The comparison values are assumed to be
known with complete certainty, which in the case of cumulative distributions of data
is often difficult to argue. Any quantifiable uncertainty in the cumulative distributions
may be integrated over, which generalizes the area metric to situations when the
model and/or the data cumulative distributions are uncertain. A drawback is that
the BVM in these cases may be very computationally intensive and would likely need
to be approximated using a random sampling or discretization scheme. A binned
pdf metric is put forward to potentially reduce the computational complexity toward
quantifying this generalized area validation metric. This applies similarly to the pdf
comparison metrics in Appendix A.4.
In Appendix A.5, we invent an improved statistical hypothesis test using the BVM,
called the â€œstatistical power BVMâ€, that takes into account both model and data
pdfs. Because in principle we have a model output pdf ğœŒ(^ğ‘¦|ğ‘€, ğ·) in model validation
problems, we can use it (in place of assuming the null hypothesis is true) to avoid
both type I and type II errors.
In the statistical power BVM, the model and the data are defined to agree if both
their test statistics lie within one anotherâ€™s confidence intervals (or â€œconfidence setsâ€ as
43

explained in Appendix A.5). The statistical power BVM becomes the product of the
statistical powers of the model and data, denoted ğ‘(ğ´|ğ‘€, ğ·) =
(ï¸€
1âˆ’ğ›½ğ‘€(ğ›¼)
)ï¸€
Â·
(ï¸€
1âˆ’ğ›½ğ·(^ğ›¼)
)ï¸€
in Equation (A.18). Further comments are made about how systematic error (defined
as when a test statistic lies outside of its own confidence interval) may be removed.
It is concluded that the statistical power BVM has a relatively low resolving power
compared to other BVMs. This is because large confidence intervals imply large
tolerance intervals for acceptance. For this reason, statistical hypothesis testing should
only be used for validation in situations where a high degree of nonexactness between
model and data test statistics is permissible and the pdfs have very thin tails. This
BVM does, however, have a greater resolution than the classical hypothesis test as
was proved in Appendix A.5 and will be demonstrated in Section 2.6.
Appendix A.6 finds that Bayesian model testing has the highest possible resolving
power because the model and the data are defined to agree only if their values are
exactly equal. This is the reverse of what was concluded about statistical hypothesis
testing.
Further in Appendix A.6, we argue that, analogous to the Bayesian model testing
framework, nothing prevents us from constructing what we call the BVM factor. The
BVM factor is,
ğ¾(ğµ) = ğ‘(ğ´|ğ‘€, ğ·, ğµ)
ğ‘(ğ´|ğ‘€â€², ğ·, ğµ),
(2.13)
which is a ratio of the BVMs of two models under arbitrary definitions of agreement
ğµ. Using Bayesâ€™ Theorem, ğ‘(ğ‘€|ğ´, ğ·, ğµ) = ğ‘(ğ´|ğ‘€, ğ·, ğµ)ğ‘(ğ‘€|ğ·, ğµ)/ğ‘(ğ´|ğ·, ğµ), we
may further construct the BVM ratio,
ğ‘…(ğµ) = ğ‘(ğ‘€|ğ´, ğ·, ğµ)
ğ‘(ğ‘€â€²|ğ´, ğ·, ğµ) = ğ‘(ğ´|ğ‘€, ğ·, ğµ) ğ‘(ğ‘€|ğ·, ğµ)
ğ‘(ğ´|ğ‘€â€², ğ·, ğµ) ğ‘(ğ‘€â€²|ğ·, ğµ) = ğ¾(ğµ) ğ‘(ğ‘€|ğ·, ğµ)
ğ‘(ğ‘€â€²|ğ·, ğµ), (2.14)
for the purpose of comparative model selection under a general definition of agreement
ğµ. The ratio ğ‘(ğ‘€|ğ·, ğµ)/ğ‘(ğ‘€â€²|ğ·, ğµ) is the ratio of prior probabilities of ğ‘€and ğ‘€â€².
Analogous to Bayesian model testing, if there is no reason to suspect that one model
is a priori more probable than another, one may let ğ‘(ğ‘€|ğ·, ğµ)/ğ‘(ğ‘€â€²|ğ·, ğµ) = 1, and
44

then ğ‘…(ğµ) â†’ğ¾(ğµ) in value.
Thus, using the BVM ratio, we can perform general model validation testing under
arbitrary definitions of agreement and with any reasonable set of comparison functions.
The BVM ratio therefore generalizes the Bayesian model testing framework. This will
be utilized in Section 2.6.
Finally we wanted to add a note about how one may mitigate the sharpness of the
indicator function without using fuzzy logic while also allowing close models to be some-
what accepted. As we have seen, it is natural to use a threshold Boolean parameter ğœ–to
help define the boundary of agreement through ğµ(ğ‘“â‰¤ğœ–). Such a BVM takes the form,
ğ‘(ğ´|ğ‘€, ğ·, ğœ–) =
âˆ«ï¸
ğ‘“
ğœŒ(ğ‘“|ğ‘€, ğ·) Â· Î˜(ğµ(ğ‘“â‰¤ğœ–)) ğ‘‘ğ‘“,
(2.15)
where Î˜(. . .) instantaneously drops to zero for ğ‘“> ğœ–. One may soften the boundary by
allowing ğœ–itself to be an uncertain quantity, which means one allows their definition of
agreement to be somewhat uncertain (which can often be reasonably claimed). As an
example, let this uncertainty be ğœŒ(ğœ–) = ğœ†exp(âˆ’ğœ†(ğœ–âˆ’ğœ–â€²)) for ğœ–â€² > ğœ–and zero otherwise,
where ğœ†is positive. Marginalizing over ğœ–then gives,
ğ‘(ğ´|ğ‘€, ğ·)
=
âˆ«ï¸
ğœ–
ğ‘(ğ´|ğ‘€, ğ·, ğœ–) Â· ğœŒ(ğœ–) ğ‘‘ğœ–
=
âˆ«ï¸
ğ‘“
ğœŒ(ğ‘“|ğ‘€, ğ·) Â·
(ï¸
Î˜
(ï¸€
ğµ(ğ‘“â‰¤ğœ–â€²)
)ï¸€
+ Î˜
(ï¸€
ğµ(ğ‘“> ğœ–â€²)
)ï¸€
ğ‘’âˆ’ğœ†(ğ‘“âˆ’ğœ–â€²))ï¸
ğ‘‘ğ‘“, (2.16)
which allows some ğ‘“â€™s to be accepted outside the agreement region defined by ğ‘“â‰¤ğœ–â€²,
but with an exponentially decaying probability. Other potentially useful ğœ–pdfs include,
but are not limited to: negative slope linear, Gaussian, or decaying sigmoid functions.
None of these ğœ–type distributions were needed to obtain the results of the previous
sections explicitly; however, these types of assumptions may have been part of the
decision process made implicitly by a practitioner while performing model validation.
45

2.6
BVM Examples
In this section, we invent and quantify three novel validation metrics using the BVM
to highlight the conceptual clarity, flexibility, and capacity of our framework.
2.6.1
The Statistical Power BVM
Here we consider the statistical power BVM proposed in Appendix A.5 and reviewed
in the previous section. This metric defines agreement as occurring when both the
model and data comparison values are within one anotherâ€™s confidence intervals,
simultaneously. The BVM for this metric is the product of the statistical powers of
the model and the data ğ‘(ğ´|ğ‘€, ğ·) =
(ï¸€
1âˆ’ğ›½ğ‘€(ğ›¼)
)ï¸€
Â·
(ï¸€
1âˆ’ğ›½ğ·(^ğ›¼)
)ï¸€
, which is calculated in
Equation (A.18). We contrast this with the standard statistical hypothesis test that,
after assuming the model is correct, ğ‘€= ğ·, finds the probability that the model
lies within the dataâ€™s confidence interval equal to 1 âˆ’ğ›¼. In statistical hypothesis
testing, one then proceeds to check the actual model output and speculates about
type I and type II errors. As discussed in Appendix A.5, we do not assume ğ‘€= ğ·
before validation and therefore type I and type II errors are avoided. Rather, we let
the statistical power BVM decide whether or not the model is valid. This provides a
more informative validation procedure.
Figure 2-2 depicts a typical statistical hypothesis test scenario that is designed
to check the validity of an uncertain model average prediction ^ğœ‡(in blue) against
an uncertain data average prediction ğœ‡(in red). The dataâ€™s ğœ‡is ğ‘¡-distributed (the
same distribution in each subfigure) according to ğ‘‡(ğ‘¦, ğ‘›âˆ’1, ğ‘ ) = ğ‘‡(0, 10, 1.75) where
(ğ‘¦, ğ‘›, ğ‘ ) are the sample mean, the number of collected data points, and the sample
standard deviation, respectively. Each row depicts a normally distributed model
centered at 0, but with increasing model variance per row.
46

Figure 2-2:
Comparison between statistical hypothesis testing and
statistical power BVM. (a) The shaded regions in Column A depict the
95% confidence interval of each distribution, respectively. Because the data
distribution is the same in each figure and because the statistical hypothesis test
is independent of the proposed model due to assuming the hypothesis ğ‘€= ğ·,
each model is equally valid by that test when it is clear that the model in row 2
is preferable. (b) The shaded regions in Column B depict the statistical power of
the distributions â€“ the 95% confidence intervals from each distribution is shaded
(integrated) in the otherâ€™s pdf. The statistical power BVM (denoted ğ‘ƒ(ğ´) in
column B) is calculated for each model and indeed the model in row 2 is found
to be preferable as it has the highest probability of agreement.
2.6.2
The
(ï¸€
âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€
BVM
We invent a novel compound Boolean that defines agreement as when the model
passes an average square error threshold of âŸ¨ğœ–âŸ©and a check for probabilistic model
representation. The latter is imposed by requiring that 95%Â±4% of the uncertain data
lies inside the modelâ€™s 1 âˆ’^ğ›¼= 95% confidence interval, i.e. 1 âˆ’ğ›½ğ·(^ğ›¼) âˆ¼95%. The
Â±4% tolerance was chosen such that overly uncertain models would be marked as â€œnot
agreeingâ€ as they would be able to guarantee that 100% of the data lies within their
47

excessively wide confidence intervals. We call this compound Boolean the
(ï¸€
âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€
Boolean. The BVM in this case is
ğ‘(ğ´|ğ‘€, ğ·, âŸ¨ğœ–âŸ©, ğ›½ğ·) =
âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğœŒ(^ğ‘Œ|ğ‘€, ğ·) Â· Î˜
(ï¸
ğµ
(ï¸€^ğ‘Œ, ğ‘Œ, âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€)ï¸
Â· ğœŒ(ğ‘Œ|ğ·) ğ‘‘^ğ‘Œğ‘‘ğ‘Œ, (2.17)
where the compound Boolean ğµ
(ï¸€^ğ‘Œ, ğ‘Œ, âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€
is equal to,
ğµ
(ï¸‚1
ğ‘›
âˆ‘ï¸
ğ‘–
|^ğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–| â‰¤âŸ¨ğœ–âŸ©
)ï¸‚
âˆ§ğµ
(ï¸‚
0.91 â‰¤1
ğ‘›
âˆ‘ï¸
ğ‘–
Î˜
(ï¸€
ğ‘¦ğ‘–âˆˆ[âˆ’ğ‘^ğ›¼, ğ‘^ğ›¼]ğ‘–
)ï¸€
â‰¤0.99
)ï¸‚
,
(2.18)
where ğ‘›is the number of data points in {ğ‘¦ğ‘–} = ğ‘Œ, and [âˆ’ğ‘^ğ›¼, ğ‘^ğ›¼]ğ‘–is the modelâ€™s
95% confidence interval at comparison location ğ‘¥ğ‘–. We treat the modelâ€™s confidence
intervals as certain quantities, which can be achieved effectively through enough Monte
Carlo (MC) simulation of the model output pdfs (although this stipulation can be
removed if needed).
Although the mathematical notation for the compound Boolean is a bit complicated,
it is relatively easy to implement using if statements. This ease of programming allows
the BVM to have a large capacity for representing complex and abstract validation
scenarios in practice.
Expressing the BVM as an expectation value over ğœŒ(ğ‘Œ|ğ·)ğœŒ(^ğ‘Œ|ğ‘€, ğ·),
ğ‘(ğ´|ğ‘€, ğ·, âŸ¨ğœ–âŸ©, ğ›½ğ·) = ğ¸
[ï¸
Î˜
(ï¸
ğµ
(ï¸€^ğ‘Œ, ğ‘Œ, âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€)ï¸]ï¸
âˆ¼1
ğ¾
ğ¾
âˆ‘ï¸
ğ‘˜=1
Î˜
(ï¸
ğµ
(ï¸€^ğ‘Œ(ğ‘˜), ğ‘Œ(ğ‘˜), âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€)ï¸
,(2.19)
allows one to compute the integral using standard statistical methods like MC. We
use MC and ğ¾= 3000 samples in this toy example. In Figure 2-3, we implement the
(ï¸€
âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€
Boolean and show that it is able to quantify both the average error and a
modelâ€™s probabilistic representation of the uncertain data, simultaneously.
We consider the data generated from,
ğ‘¦(ğ‘¥) = 1 + ğ‘¥ğ‘’âˆ’cos (10ğ‘¥) + sin (10ğ‘¥) + ğœ–ğ‘(ğ‘¥),
(2.20)
where ğœ–ğ‘(ğ‘¥) âˆ¼ğ’©(0, 0.42) represents the aleatoric stochastic uncertainty due to the
inherent randomness of the system. An instance of the aleatoric data ğ‘Œwithout
measurement uncertainty is depicted in red in Figures 2-3a and 2-3b. We consider the
48

data to have an additional epistemic measurement uncertainty ğœ–ğ‘’(ğ‘¥) âˆ¼ğ’©(0, 0.22) that
contributes to the probability of whether or not the model agrees with the plotted
instance of the aleatoric data ğ‘Œ.
The models plotted in Figures 2-3a and 2-3b are generated from,
^ğ‘¦(ğ‘¥; âƒ—ğ›¼) = ğ›¼1 + ğ›¼2ğ‘¥ğ‘’âˆ’ğ›¼3 cos (ğ›¼4ğ‘¥) + ğ›¼5 sin (ğ›¼6ğ‘¥),
(2.21)
where âƒ—ğ›¼= (ğ›¼1, ğ›¼2, ğ›¼3, ğ›¼4, ğ›¼5, ğ›¼6) is the vector of model parameters. In Figure 2-3a, a
deterministic model is considered and plotted in blue by treating the model parameters
as completely certain numbers âƒ—ğ›¼= (1, 1, 1, 10, 1, 10). In Figure 2-3b, we consider
an uncertain model by treating the model parameters as uncertain values drawn
from a multivariate Gaussian distribution having averages ğœ‡âƒ—ğ›¼= (1, 1, 1, 10, 1, 10) and
standard deviations ğœâƒ—ğ›¼= (0.35, 0.3, 0.3, 0.3, 0.3, 0.3). We evaluate the probability
that these data and model pairs pass the âŸ¨ğœ–âŸ©Boolean versus the
(ï¸€
âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€
Boolean by
calculating their respective BVMs.
Figure 2-3: Validating a deterministic model and an uncertain model
according to two Boolean agreement functions. (a) The deterministic
model satisfies the âŸ¨ğœ–âŸ©Boolean but fails to pass the
(ï¸€
âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€
requirement given
that its 95% confidence interval has a width of zero. (b) The uncertain model
satisfies both the âŸ¨ğœ–âŸ©and
(ï¸€
âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€
agreement requirements given that its 95%
confidence region has a nonzero width and represents better the uncertain data.
The deterministic model plotted in Figure 2-3a satisfies the average error validation
requirement with ğ‘ƒ(ğ´|âŸ¨ğœ–âŸ©) = 0.99 when a threshold of âŸ¨ğœ–âŸ©= 0.46 is used. This result is
logical because the congregate standard deviation of the data is itself the combination of
49

the aleatoric and epistemic uncertainties, i.e.
âˆš
0.42 + 0.22 â‰ˆ0.45. This deterministic
model fails to predict the uncertain fluctuations of the data because determinisic
models have confidence intervals with zero width. Thus the deterministic model fails
to agree according to the (âŸ¨ğœ–âŸ©, ğ›½ğ·) Boolean and one finds ğ‘ƒ(ğ´|âŸ¨ğœ–âŸ©, ğ›½ğ·) = 0 for any
value of âŸ¨ğœ–âŸ©.
The uncertain model depicted in Figure 2-3b is able to pass both agreement
definitions; however, our choice to evaluate each probable model path (rather than
just the average model) against the epistemic uncertain data increases the threshold to
about âŸ¨ğœ–âŸ©= 0.9 before an agreement probability of about ğ‘ƒ(ğ´|âŸ¨ğœ–âŸ©) = 0.96 is achieved.
When instead evaluating âŸ¨ğœ–âŸ©against the average model, we obtained similar results
to the deterministic model for this Boolean; âŸ¨ğœ–âŸ©âˆ¼0.46 and ğ‘ƒ(ğ´|âŸ¨ğœ–âŸ©) = 0.99. The
(ï¸€
âŸ¨ğœ–âŸ©, ğ›½ğ·
)ï¸€
BVM for the uncertain model is ğ‘ƒ(ğ´|âŸ¨ğœ–âŸ©, ğ›½ğ·) = 0.93, because the uncertainty
in the data more or less agrees with the confidence interval provided by the model.
This model can be tested for agreement against other models or model parameter
distributions for their respective definitions of agreement.
2.6.3
Exploring the BVM Ratio with the (ğ›¾, ğœ–) BVM
In this section, we invent an agreement function to represent the visual inspection an
engineer might perform graphically and use the BVM ratio for model selection under
this definition of agreement. By quantifying this, a practitioner could visually validate
a model without actually looking at the model-data pair, which can be helpful for
high dimensional spaces that are beyond human comprehension/visualizability. We
will proceed by introducing this agreement function and some simple models to test it
on. We will then quantify this measure using the BVM in the completely certain and
uncertain cases. The main purpose of this example is to explore the BVM Ratio while
showcasing the conceptual flexibility of the framework.
To quantify something resembling the visual inspection an engineer might make
graphically, we use two main criteria. We define the model to be accepted if most
of the model and data point pairs lie relatively close to one another and if none of
the point pairs deviate too far from one another. We therefore consider a compound
50

Boolean ğµ(^ğ‘Œ, ğ‘Œ, ğ›¾, ğœ–) that is true if a percentage larger than ğ›¾% (âˆ¼90%) of the model
output points ^ğ‘Œlie within ğœ–of the data points ğ‘Œand 100% of the model output
points lie within some multiple ğ‘šğœ–of the data points, which rules out obvious model
form error. We will call this compound Boolean the (ğ›¾, ğœ–) Boolean. The values ğ›¾%, ğœ–,
and ğ‘šcan be adjusted to the needs of the modeler. It should be noted that the ğœ–in
this metric makes point by point evaluations as opposed to the average âŸ¨ğœ–âŸ©Boolean
used in the previous example. We will perform the analysis for a variety of ğ›¾and ğœ–
values to explore the limits of the metric.
We will calculate the BVM for two different order polynomial models that approxi-
mate ğ‘›data points taken from the cosine function ğ‘¦ğ‘–= cos(ğ‘¥ğ‘–), as an illustration. The
points are evenly spaced in the range ğ‘¥ğ‘–âˆˆ[0, ğœ‹]. The first model ^ğ‘¦(1)
ğ‘–
= ğ‘€1(ğ‘¥ğ‘–; âƒ—ğ›¼) =
ğ›¼1 + ğ›¼2ğ‘¥2
ğ‘–+ ğ›¼3ğ‘¥4
ğ‘–and the second model ^ğ‘¦(2)
ğ‘–
= ğ‘€2(ğ‘¥ğ‘–; âƒ—ğ›¼) = ğ›¼1 + ğ›¼2ğ‘¥2
ğ‘–+ ğ›¼3ğ‘¥4
ğ‘–+ ğ›¼4ğ‘¥6
ğ‘–
have uncertain parameters (ğ›¼1, ğ›¼2, ğ›¼3, ğ›¼4).5
To formulate the BVM, we still need to formulate the model and data probabil-
ity distributions. Because the Boolean expression ğµ(^ğ‘Œ, ğ‘Œ) is over the entire model
and data functions, the model probability distribution is ğ‘(^ğ‘Œ|ğ‘€, ğ·) and the data
probability distribution is ğ‘(ğ‘Œ|ğ·). These are joint probabilities over all of the points
(ï¸€^ğ‘Œ= {^ğ‘¦ğ‘–}, ğ‘Œ= {ğ‘¦ğ‘–}
)ï¸€
that constitute a particular path (^ğ‘Œ, ğ‘Œ) of the model or data, re-
spectively. Because both models are linear in the uncertain coefficients (ğ›¼1, ğ›¼2, ğ›¼3, ğ›¼4),
there is a one to one correspondence from the set of model parameters (ğ›¼1, ğ›¼2, ğ›¼3, ğ›¼4)
to the set of the possible paths ^ğ‘Œğ›¼1,ğ›¼2,ğ›¼3,ğ›¼4 (given ğ‘›is greater than the number of
independent coefficients). This makes the uncertainty propagation from the uncertain
model parameters to the full joint probability of the points on a path simple and
results in the joint probability of the paths being equal to the joint probability of the
uncertain input model parameters. For simplicity, we will let
ğ‘(ğ›¼1, ğ›¼2, ğ›¼3, ğ›¼4) = ğ’©(ğœ‡ğ›¼1, ğœğ›¼1) ğ’©(ğœ‡ğ›¼2, ğœğ›¼2) ğ’©(ğœ‡ğ›¼3, ğœğ›¼3) ğ’©(ğœ‡ğ›¼4, ğœğ›¼4),
where ğ’©(ğœ‡, ğœ) is a normal distribution with a mean ğœ‡and a standard deviation ğœ.
5Note that ğ›¼4 = 0 for model 1.
51

Thus, for each model ğ‘€ğ‘—, we have,
ğ‘(^ğ‘Œğ›¼1,ğ›¼2,ğ›¼3,ğ›¼4|ğ‘€ğ‘—) = 1
ğ‘exp
(ï¸‚
âˆ’(ğ›¼1 âˆ’ğœ‡ğ›¼1)2
2ğœ2
ğ›¼1
âˆ’(ğ›¼2 âˆ’ğœ‡ğ›¼2)2
2ğœ2
ğ›¼2
âˆ’(ğ›¼3 âˆ’ğœ‡ğ›¼3)2
2ğœ2
ğ›¼3
âˆ’(ğ›¼4 âˆ’ğœ‡ğ›¼4)2
2ğœ2
ğ›¼4
)ï¸‚
.
Because the problem is well understood, we discretize the integrals rather than es-
timating them with MC [61]. After discretization, the (ğ›¾, ğœ–) BVM for each model ğ‘€ğ‘—is,
ğ‘(ğ´|ğ‘€ğ‘—, ğ·, ğ›¾, ğœ–) =
âˆ‘ï¸
^ğ‘Œ,ğ‘Œ
ğ‘(^ğ‘Œ|ğ‘€ğ‘—) Â· Î˜
(ï¸€
ğµ(^ğ‘Œ, ğ‘Œ, ğ›¾, ğœ–)
)ï¸€
Â· ğ‘(ğ‘Œ|ğ·).
(2.22)
In principle, ğœ–= (ğœ–1, .., ğœ–ğ‘›) is an ğ‘›-dimensional vector where each ğœ–ğ‘–may be adjusted
to impose more or less stringent agreement conditions on a point to point basis,
which may be used to enforce reliability in regions of interest. In our example, we
let all the components ğœ–ğ‘–be equal (i.e. ğœ–ğ‘–= ğœ–for all ğ‘–). If the standard devia-
tion of each data point âˆ¼^ğœğ‘–(aleatoric and/or measurement uncertainty) in the joint
data pdf ğ‘(ğ‘Œ|ğ·) is much less than ğœ–ğ‘–, and ğ‘›is large, one may approximate the BVM as,
ğ‘(ğ´|ğ‘€ğ‘—, ğ·, ğ›¾, ğœ–) â‰ˆ
âˆ‘ï¸
^ğ‘Œ
ğ‘(^ğ‘Œ|ğ‘€ğ‘—) Â· Î˜
(ï¸€
ğµ(^ğ‘Œ, ğ‘Œâ€², ğ›¾, ğœ–)
)ï¸€
,
(2.23)
which can greatly reduce the number of combinations one must calculate by effec-
tively treating the data as known, deterministic, and equal to ğ‘Œâ€². We will use this
approximation as it does not take away from the main point of this example.
We will use the following numerics. In the completely certain (deterministic)
case, we will let the parameters be the Taylor series coefficients (ğ›¼1, ğ›¼2, ğ›¼3, ğ›¼4) =
(ï¸€
1, âˆ’1
2!, 1
4!, âˆ’1
6!
)ï¸€
(ğ›¼4 = 0 for model 1), and in the uncertain case, we let each coefficient
have Gaussian uncertainty centered at their Taylor series coefficients with standard
deviations (ğœğ›¼1, ğœğ›¼2, ğœğ›¼3, ğœğ›¼4) = (0.1, 0.05, 0.005, 0.0005) (and where ğœğ›¼4 = 0 for model
1). We let each model output path have ğ‘›= 50 points and we allow for 20 possible
values per parameter (ğ›¼1, ğ›¼2, ğ›¼3, ğ›¼4), which results in 203 = 8000 possible paths for
model 1 and 204 = 160, 000 for model 2. We let ğ›¾vary between 75% and 100% using
an increment of 1% and let ğœ–vary between 0 and 1 using an increment of 0.01. The
value of ğ‘šwas chosen to be equal to 5, which imposes that no model path can have
points that are greater than 5ğœ–away while still be considered to agree with the data.
52

The BVM probability of agreement values as a function of the Boolean function
parameters (ğ›¾, ğœ–) are plotted in Figure 2-4 for model 1 and model 2 in the completely
certain case:
Figure 2-4: Completely Certain Case: The BVM probability of agree-
ment between each of the models and data plotted in the (ğ›¾, ğœ–) space.
Because here the models are deterministic, the BVM probability of agreement
for each (ğ›¾, ğœ–) pair is either zero or one. (a) The results for model 1 (4th order
polynomial). (b) The results for model 2 (6th order polynomial). As expected,
model 2 better fits the data in the (ğ›¾, ğœ–) space as it has more BVM values equal
to one than model 1, since it is overall closer to the cosine function being the
next nonzero order polynomial in the Taylor series expansion. Neither model fits
the data exactly as the BVM for both models at (ğ›¾= 100%, ğœ–= 0) is zero.
For a single (ğ›¾, ğœ–) pair, the BVM ratio (a priori the models are assumed to be
equally likely) is,
ğ‘…
(ï¸€
ğµ(ğ›¾, ğœ–)
)ï¸€
= ğ‘(ğ´|ğ‘€1, ğ·, ğ›¾, ğœ–)
ğ‘(ğ´|ğ‘€2, ğ·, ğ›¾, ğœ–),
(2.24)
which, because the numerator and denominator are either 0 or 1 in the deterministic
case, gives ğ‘…
(ï¸€
ğµ(ğ›¾, ğœ–)
)ï¸€
equal to 1, 0, âˆ, or 0/0 meaning that both models agree, model
1 does not agree but model 2 agrees, model 1 agrees but model 2 does not agree,
or both models disagree, respectively. Thus, the BVM ratio for a single (ğ›¾, ğœ–) pair
between two deterministic models with completely certain data is not particularly
insightful since they either agree or do not agree as defined by ğµ. As it may not
always be clear precisely what values of (ğ›¾, ğœ–) one should choose to define agreement,
one can meaningfully average (marginalize, analagous to (2.16)) over a viable volume
53

in the (ğ›¾, ğœ–) space, with ğ‘(ğ›¾, ğœ–) = 1/ğ‘‰, and arrive at an averaged Boolean BVM ratio,
ğ‘…(ğµ) =
âˆ‘ï¸€
ğ›¾,ğœ–ğ‘(ğ´|ğ‘€1, ğ·, ğ›¾, ğœ–)
âˆ‘ï¸€
ğ›¾,ğœ–ğ‘(ğ´|ğ‘€2, ğ·, ğ›¾, ğœ–) = ğ‘1ğ´
ğ‘2ğ´
,
(2.25)
which is simply a ratio of the number of agreements found for model 1, ğ‘1ğ´, to the
number of agreements found for model 2, ğ‘2ğ´, in the selected (ğ›¾, ğœ–) volume. In our
deterministic example, ğ‘…(ğµ) = 1108/2364 = 0.4687 as model 2 better fits the data, as
defined by ğµ, for the chosen meaningful (ğ›¾, ğœ–) volume (which is taken to be the whole
tested volume in this toy example). The BVM ratio or the averaged Boolean BVM
ratio may be used as a guide for selecting models in the deterministic case assuming
that reasonable regions are chosen.
The BVM probability of agreement values as a function of (ğ›¾, ğœ–) are plotted in
Figure 2-5 for model 1 and model 2 in the uncertain model case:
Figure 2-5: Uncertain Case: The BVM probability of agreement be-
tween each of the models and the data plotted in the (ğ›¾, ğœ–) space.
Because the model paths are uncertain, the BVM probability of agreement for
each (ğ›¾, ğœ–) pair may take any value from zero to one. (a) The results for model
1 (4th order polynomial). (b) The results for model 2 (6th order polynomial).
As expected, model 2 better fits the data in the (ğ›¾, ğœ–) space as it has generally
larger BVM values than model 1; however, the BVM values are about equal in
cases of large values of ğœ–and low values of ğ›¾(since the definition of agreement
is less stringent and they both â€œagreeâ€) and in the case of demanding absolute
equality (ğœ–= 0) as neither model fits the data exactly.
54

The BVM ratios ğ‘…
(ï¸€
ğµ(ğ›¾, ğœ–)
)ï¸€
= ğ‘(ğ´|ğ‘€1, ğ·, ğ›¾, ğœ–)/ğ‘(ğ´|ğ‘€2, ğ·, ğ›¾, ğœ–) for the uncertain
models are plotted as a function of (ğ›¾, ğœ–) in Figure 2-6:
Figure 2-6: The BVM ratios for the uncertain models plotted in the
(ğ›¾, ğœ–) space. Model 2 is generally favored over model 1 as there exist no values
greater than one on the plot. The amount the BVM ratio favors model 2 over
model 1 decreases (i.e. the ratio increases and tends to one) as the metric
becomes less and less stringent (i.e. as ğ›¾decreases and ğœ–increases). The ğœ–= 0
line was removed because neither model agrees with the data exactly.
The averaged Boolean BVM ratio for the uncertain models is,
ğ‘…(ğµ) =
âˆ‘ï¸€
ğ›¾,ğœ–ğ‘(ğ´|ğ‘€1, ğ·, ğ›¾, ğœ–)
âˆ‘ï¸€
ğ›¾,ğœ–ğ‘(ğ´|ğ‘€2, ğ·, ğ›¾, ğœ–) = 0.7471,
(2.26)
which conforms to the notion that model 2 is, generally speaking, the preferable model,
and which may be communicated with this single number. We have given examples
of the BVM ratio correctly selecting models according to abstract and new forms of
validation.
55

2.7
Conclusion
This chapter presents the Bayesian Validation Metric (BVM) as a general model
validation and testing tool. This metric is flexible enough to be used in different
contexts for solving model validation problems. The BVM quantifies the probability of
agreement between some model of interest and observed data, according to arbitrary
quantified comparison functions of the model-data comparison values. Further, the
BVM obeys all of the desirable validation criteria [28] and represents all of the standard
validation metrics as special cases and generalizes them. Finally, using the BVM
ratio, one can perform model selection based on arbitrary comparisons and agreement
definitions. In other words, the BVM model testing framework generalizes the Bayesian
model testing framework to arbitrary model-data contexts.
56

Chapter 3
Generalized Bayesian Regression and
Model Learning
3.1
Introduction
In this chapter, we show how the BVM framework can be employed and expanded to
a general calibration and validation framework by proposing a method for generalized
Bayesian regression and model learning [58]. As we will see, this framework allows the
users to perform Bayesian regression on any type of data distribution and based on
arbitrary definitions of model-data agreement. This generalized approach has tackled
some technical gaps that were found in Bayesian and standard regression methods, and
is capable of representing and combining Bayesian regression, standard regression, and
likelihood-based calibration techniques in a single framework. Using this framework,
we give the users new insights into the interpretation of the predictive envelopes and
provide them with more freedom and control over their meaning.
3.2
Background and Motivation
In this section, we will review least squares, likelihood-based, and Bayesian regression
methods and discuss their advantages and disadvantages.
57

3.2.1
Standard Regression
Regression is the process of finding a model that fits some observed data based on a
specific mathematical criterion (through the use of an objective function). Regression
is one of the most important types of data analysis and is frequently used when making
data-driven decisions. The simplest regression technique is linear regression.
Standard regression type methods have several positive and negative attributes.
These methods are relatively easy to implement and can approximate model parameters
even for reasonably high dimensional data and model parameter spaces (given one is not
concerned with parameter or data uncertainty). When the data is uncertain, standard
regression methods can generate parameter estimations along with their variances and
covariances (analytically for simple cases and iteratively regressing randomly sampled
uncertain data in others). In machine learning, it is common practice to regularize the
objective function. Regularizing the objective function introduces bias in which the
parameter estimations change (i.e. become biased estimators), the parameter variances
become reduced, and the modelâ€™s predictive envelope becomes more narrow and less
representative of the data. Although this is not a problem for nonparametric models in
which the parameters do not have physical interpretations, we find that regularization
is problematic for parametric models because these parameters often represent physical
quantities, e.g. the predicted mass of an exoplanet, the predicted circuit resistance due
to the addition of an electrical load, or the predicted stiffness of a beam. It seems more
natural that larger acceptable training errors should be correlated with an increase
in the variance of a parameter rather a decrease because one is admitting that the
model is not perfect. Currently, regularization causes parameters to become biased as
well as â€œmore certainâ€ because the variance of the regressed model is reduced.
Finally, other than using generalization error type estimates (via training and
testing error statistics), these methods do not offer any other methods for model
selection in which one could easily include their prior knowledge in a principled way.
58

3.2.2
Likelihood-Based Methods
We give a brief review of likelihood-based methods below, but a more elaborate
discussion is located in Appendix B. Likelihood-based methods for calibration and
model learning use the likelihood function â„’(âƒ—ğ›¼) to learn model parameters. The most
common likelihood-based method is the maximum likelihood method.
These methods have similar advantages and disadvantages to standard regression
methods. Likelihood-based methods do not allow the user to incorporate their prior
knowledge of the model parameters into the framework and, unless there is uncertainty
in the data, the learned parameters are point values. These methods also suffer the
same conceptual issue of interpreting the affect of regularization on parametric models.
One can however learn (or estimate) the prediction uncertainty of the model given
the data.
3.2.3
Bayesian Regression and Model Testing
In this section, we present Bayesian regression and model testing (BMT) while intro-
ducing some probability notations to be used throughout this chapter. In Bayesian
regression, rather than preforming regression to learn the model parameters, one
performs regression to learn the posterior probability distribution of the model pa-
rameters. That is, one estimates a set of parameters âƒ—ğ›¼in a model (or hypothesis)
ğ‘€â‰¡ğ‘€(ğ‘¥; âƒ—ğ›¼) for the data ğ·(where ğ‘¥is the model input). The defining equation of
Bayesian regression is the learning of the posterior parameter distribution from the
prior via Bayesâ€™ Rule,
ğœŒ(âƒ—ğ›¼|ğ‘€)
*
âˆ’â†’ğœŒ(âƒ—ğ›¼|ğ·, ğ‘€) = ğœŒ(ğ·|âƒ—ğ›¼, ğ‘€) ğœŒ(âƒ—ğ›¼|ğ‘€)
ğœŒ(ğ·|ğ‘€)
,
(3.1)
where, for reasons that will become obvious, we have borrowed the more explicit
notation from Chapter 2. In Bayesian regression and model testing, these probabilities
are named as follows:
ğœŒ(âƒ—ğ›¼|ğ·, ğ‘€) â‰¡ğ’«(âƒ—ğ›¼) is the posterior probability of the parameter,
59

ğœŒ(ğ·|âƒ—ğ›¼, ğ‘€) â‰¡â„’(âƒ—ğ›¼) is the likelihood function,
ğœŒ(âƒ—ğ›¼|ğ‘€)
â‰¡ğœ‹(âƒ—ğ›¼) is the prior probability,
ğœŒ(ğ·|ğ‘€)
â‰¡ğ’µis the marginal likelihood or Bayesian evidence.
After learning the posterior distribution of the model parameters (given âƒ—ğ›¼is the vector
of parameters), we can evaluate the predictive distribution defined by:
ğœŒ(^ğ‘¦|ğ·, ğ‘€) =
âˆ«ï¸
âƒ—ğ›¼
ğœŒ(^ğ‘¦|âƒ—ğ›¼, ğ·, ğ‘€) Â· ğœŒ(âƒ—ğ›¼|ğ·, ğ‘€) ğ‘‘âƒ—ğ›¼.
(3.2)
To perform Bayesian regression, one must calculate the Bayesian evidence, which is
the marginal likelihood over âƒ—ğ›¼,
ğ’µ= ğœŒ(ğ·|ğ‘€) =
âˆ«ï¸
âƒ—ğ›¼
ğœŒ(ğ·|âƒ—ğ›¼, ğ‘€)
âŸ
 â
 
â„’(âƒ—ğ›¼)
Â· ğœŒ(âƒ—ğ›¼|ğ‘€) ğ‘‘âƒ—ğ›¼
âŸ
 â
 
ğœ‹(âƒ—ğ›¼) ğ‘‘âƒ—ğ›¼
.
(3.3)
After performing regression and solving for the model parametersâ€™ values, rather
than selecting the model with the lowest estimated generalization error as is done
in standard regression, one instead uses BMT to select the model with the highest
probability given the data. That is, for two Bayesian regressed models ğ‘€1 and ğ‘€2,
BMT uses the Bayes ratio, ğ‘…, and rank the data-informed posterior model probabilities.
It can be expressed in several ways using Bayes Rule,
ğ‘…â‰¡ğ‘(ğ‘€1|ğ·)
ğ‘(ğ‘€2|ğ·) = ğœŒ(ğ·|ğ‘€1) ğ‘(ğ‘€1)
ğœŒ(ğ·|ğ‘€2) ğ‘(ğ‘€2) = ğ’µ1
ğ’µ2
ğ‘(ğ‘€1)
ğ‘(ğ‘€2).
If there is no reason to suspect that one model is more probable than another prior
to observing the data, we may set the ratio of the prior probabilities of the model
ğ‘(ğ‘€1)/ğ‘(ğ‘€2) = 1, a priori. In this case one gets,
ğ‘…â†’ğ’µ1
ğ’µ2
â‰¡ğ¾,
where ğ¾denotes the Bayes factor and is the ratio of model evidences. The Bayes
factor is usually more accessible than ğ‘…so it is usually used for model selection:
If ğ¾> 1, then the probability of ğ‘€1 given the observed data ğ·is higher than the
60

probability of ğ‘€2 given ğ·. In this case, we select model 1.
If ğ¾< 1, then the probability of ğ‘€2 given the observed data ğ·is higher than the
probability of ğ‘€1 given ğ·. In this case, we select model 2.
If ğ¾â‰ˆ1, then the probability of ğ‘€1 given the observed data ğ·is equal to the
probability of ğ‘€2 given ğ·. In this case, both models are equally good or bad.
Bayesian regression has several positive and negative attributes. As a byproduct,
Bayesian regression can perform model selection in a principled way that allows one
to incorporate their prior knowledge into the selection process using BMT. Because
Bayesian regression requires regressing probability distributions rather than just single
model predictions, it can become intractable to calculate in general if the number
of dimensions are large (as would standard regression if uncertainty is taken into
account). Regularization in Bayesian regression is interpreted as coming from the
uncertainty of the data and the uncertainty present in the prior parameters [4], which
we view as being a potential drawback. If one wants to change the regularization it
would require changing either of these uncertainties, or both, â€œartificiallyâ€ because one
would be tuning their prior probabilities after regression, which is a bit anti-Bayesian.
Similar to standard regression, regularization can again lead to an unnatural reduction
of the posterior variances of the parameters for parametric models.
Further, we highlight some technical gaps found in Bayesian regression and model
testing. Although almost all instances of Bayesian regression use data probability
distributions that have infinite tails, truncated (or bounded) data probability density
functions (pdfs) are realistic in practice too. We find that truncated data pdfs are
potentially problematic for Bayesian regression if the model is deterministic. In the
extreme case of completely certain data, Bayesian regression methods usually do not
terminate because the Bayesian evidence is zero in (3.1) since there are no possible
combinations of parameter values that could exactly fit the data. This problem may
also arise if the data uncertainties are bounded. In principle, standard regression
methods can produce a solution regardless of the form of the data pdf. In what follows,
we assume we are given a set of inputs ğ‘‹, a set of data points ğ‘Œ= ğ·, and a set
of model outputs ^ğ‘Œ= ğ‘€(ğ‘‹; âƒ—ğ›¼). All the sets are ğ‘›-dimensional. In addition, we
61

assume that the ğ‘›data points were collected through independent experiments. We
give explicit examples of the likelihoods below (see Appendix C) given the model is
deterministic:
Infinite Tail Data Distributions
Data distributions with infinite tails result in likelihoods with infinite tails in (3.3).
Some examples of infinite tail data distributions are Gaussian, Student-t, Laplace,
canonical, and Poisson. For example, Gaussian distributed data (see Figure 1-1a)
naturally has an infinite tailed likelihood function,
â„’(âƒ—ğ›¼) =
1
âˆšï¸€
(2ğœ‹)ğ‘›|Î”|
ğ‘’âˆ’1
2
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼) âˆ’ğ·
)ï¸€ğ‘‡Î”âˆ’1(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼) âˆ’ğ·
)ï¸€
,
(3.4)
where Î” is the covariance matrix. Since the likelihood has infinite tails, the predicted
model response ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) has probabilistic flexibility around its corresponding data
point ğ·ğ‘—because it is uncertain. Even far from ğ·, Bayesian regression is capable of
estimating the posterior probability distributions of the model parameters in question
as they are nonzero.
Truncated Tail Data Distributions
Data distributions with truncated tails naturally lead to truncated likelihoods in (3.3).
For example, if the uncertain data is bounded to a region and is uniformly distributed,
i.e. ğ·ğ‘—âˆ¼ğ’°(ğ‘ğ‘—, ğ‘ğ‘—) (see Figure 1-1b), then the likelihood function is,
â„’(âƒ—ğ›¼) =
ğ‘›
âˆï¸
ğ‘—=1
Î˜
(ï¸€
ğ‘ğ‘—â‰¤ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) â‰¤ğ‘ğ‘—
)ï¸€
ğ‘ğ‘—âˆ’ğ‘ğ‘—
,
(3.5)
where Î˜(Â·) is the indicator function. In other words, for the likelihood â„’(âƒ—ğ›¼) to be
nonzero, the predicted model response ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) at ğ‘¥ğ‘—must lie within the interval
[ï¸€
ğ‘ğ‘—, ğ‘ğ‘—
]ï¸€
for all ğ‘—simultaneously. The function space defined by the model and uncertain
parameters is constrained by the data. This can make the probability of estimating a
regressed posterior probability distribution of the model parameters very small, and
in some cases impossible, because the likelihood may evaluate to zero for almost all
combinations of âƒ—ğ›¼.
62

This point is exaggerated if the data is completely certain or deterministic, because
the likelihood function becomes
â„’(âƒ—ğ›¼) = ğ›¿
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼) âˆ’ğ·
)ï¸€
,
(3.6)
where ğ›¿(Â·) is the Dirac delta function. In this case, the model output and observed
data only agree if their values are exactly equal, i.e. ğ‘€(ğ‘‹; âƒ—ğ›¼) â†’ğ·for all ğ‘›points,
which in most cases, is only possible if we overfit the data or the model is perfect. Thus,
Bayesian regression will usually fail in this case, or if it succeeds, it only produces
singular posterior distributions of the model parameters (i.e. ğœâƒ—ğ›¼= 0). When Bayesian
regression fails, the Bayesian evidence is zero, which, although correct (the model
does not support/fit the data), may not be the most useful type of answer for the
modeler. It seems reasonable that a modeler would want both the benefits of Bayesian
and standard regression simultaneously.
3.2.4
BVM Model Testing
We recall the Bayesian Validation Metric (BVM) introduced in Chapter 2. The BVM
represents model to data validation in a general way using the probability of agreement,
ğ‘(ğ´|ğ‘€, ğ·, ğµ) =
âˆ«ï¸
^ğ‘§,ğ‘§
ğ‘(ğ´|^ğ‘§, ğ‘€, ğ‘§, ğ·, ğµ) Â· ğœŒ(^ğ‘§, ğ‘§|ğ‘€, ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§
=
âˆ«ï¸
^ğ‘§,ğ‘§
ğœŒ(^ğ‘§|ğ‘€, ğ·) Â· Î˜
(ï¸€
ğµ(^ğ‘§, ğ‘§)
)ï¸€
Â· ğœŒ(ğ‘§|ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§,
(3.7)
where ^ğ‘§and ğ‘§are the model and data comparison quantities, respectively. The
â€œagreement kernelâ€ ğ‘(ğ´|^ğ‘§, ğ‘€, ğ‘§, ğ·) = Î˜
(ï¸€
ğµ(^ğ‘§, ğ‘§)
)ï¸€
is the indicator function of a user
defined boolean function, ğµ(^ğ‘§, ğ‘§), that defines the context of what is meant by â€œmodel
to data agreementâ€, by being true when (^ğ‘§, ğ‘§) agree or false otherwise. For simplicity,
we will assume ^ğ‘§â†’^ğ‘¦and ğ‘§â†’ğ‘¦are the model output and observed data respectively.
The BVM model testing framework was shown to generalize BMT where the
probability of agreement plays the role of the evidence,
63

ğ’µ(ğµ) = ğ‘(ğ´|ğ‘€, ğ·, ğµ) =
âˆ«ï¸
âƒ—ğ›¼
ğ‘(ğ´|âƒ—ğ›¼, ğ‘€, ğ·, ğµ)
âŸ
 â
 
â„’(âƒ—ğ›¼, ğµ)
Â· ğœŒ(âƒ—ğ›¼|ğ‘€) ğ‘‘âƒ—ğ›¼
âŸ
 â
 
ğœ‹(âƒ—ğ›¼) ğ‘‘âƒ—ğ›¼
,
(3.8)
where ğ’µ(ğµ) and â„’(âƒ—ğ›¼, ğµ) are the BVM evidence and likelihood, respectively, that have
been modified by a userâ€™s definition of model-data agreement ğµ. Equation (3.8) is
a key insight in [58]. Analogous to the Bayesian model testing framework, we can
perform BVM model testing between two models ğ‘€1 and ğ‘€2 using the probability of
agreement defined above as follows:
ğ‘…(ğµ) â‰¡ğ‘(ğ‘€1|ğ´, ğ·, ğµ)
ğ‘(ğ‘€2|ğ´, ğ·, ğµ) = ğ‘(ğ´|ğ‘€1, ğ·, ğµ) ğ‘(ğ‘€1|ğ·, ğµ)
ğ‘(ğ´|ğ‘€2, ğ·, ğµ) ğ‘(ğ‘€2|ğ·, ğµ) = ğ’µ1(ğµ)
ğ’µ2(ğµ)
ğ‘(ğ‘€1|ğ·, ğµ)
ğ‘(ğ‘€2|ğ·, ğµ),
where ğ‘(ğ‘€1|ğ·, ğµ)/ğ‘(ğ‘€2|ğ·, ğµ) is the ratio of prior probabilities of ğ‘€1 and ğ‘€2, which
can often be set to unity, i.e. ğ‘(ğ‘€1|ğ·, ğµ)/ğ‘(ğ‘€2|ğ·, ğµ) = 1. In this case, we get
ğ‘…(ğµ) â†’ğ‘(ğ´|ğ‘€1, ğ·, ğµ)
ğ‘(ğ´|ğ‘€2, ğ·, ğµ) = ğ’µ1(ğµ)
ğ’µ2(ğµ) = ğ¾(ğµ),
where ğ‘…(ğµ) denotes the BVM ratio and ğ¾(ğµ) denotes the BVM factor, which is
analogous to the Bayes factor (as mentioned earlier in Chapter 2).
3.2.5
The Improved Reliability Metric
The reliability metric discussed in [47] is defined as the probability that the mean
of the model prediction is within a tolerance ğœ–of the mean of the data. This metric
was later expanded in [51] to consider tolerances between each of the model and data
point pairs, |ğ‘¦ğ‘—âˆ’^ğ‘¦ğ‘—| â‰¤ğœ–ğ‘—for ğ‘—= 1, ..., ğ‘›, rather than comparing their means.
Consider a set of inputs ğ‘‹, a set of model outputs ^ğ‘Œand a set of observed data
points ğ‘Œ. Assume that all the sets are ğ‘›-dimensional and that the data were collected
through independent experiments. The improved reliability metric ğ‘Ÿğ‘–is,
ğ‘Ÿğ‘–=
âˆ«ï¸
ğ‘Œ
ğœŒ(ğ‘Œ|ğ·)
(ï¸‚âˆ«ï¸ğ‘Œ+ğœ–
ğ‘Œâˆ’ğœ–
ğœŒ(^ğ‘Œ|ğ‘€) ğ‘‘^ğ‘Œ
)ï¸‚
ğ‘‘ğ‘Œ,
(3.9)
64

which can always be rewritten as,
ğ‘Ÿğ‘–=
âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğœŒ(^ğ‘Œ|ğ‘€) Â· Î˜
(ï¸âƒ’âƒ’^ğ‘Œâˆ’ğ‘Œ
âƒ’âƒ’â‰¤ğœ–
)ï¸
Â· ğœŒ(ğ‘Œ|ğ·) ğ‘‘^ğ‘Œğ‘‘ğ‘Œ.
(3.10)
This equation may be identified as a special case of the BVM (3.7) when,
Î˜(ğµ(^ğ‘§, ğ‘§)) â†’Î˜
(ï¸€
ğµ(^ğ‘Œ, ğ‘Œ)
)ï¸€
= Î˜
(ï¸âƒ’âƒ’^ğ‘Œâˆ’ğ‘Œ
âƒ’âƒ’â‰¤ğœ–
)ï¸
=
ğ‘›
âˆï¸
ğ‘—=1
Î˜
(ï¸âƒ’âƒ’^ğ‘¦ğ‘—âˆ’ğ‘¦ğ‘—
âƒ’âƒ’â‰¤ğœ–ğ‘—
)ï¸
,
(3.11)
and where ^ğ‘§= ^ğ‘Œ, ğ‘§= ğ‘Œ(see Appendix A.1). Thus, this agreement kernel is based on
the ğœ–-Boolean. From (3.8) (see Appendix D for details), the BVM in this case is,
ğ’µ(ğµ) = ğ‘(ğ´|ğ‘€, ğ·, ğµ) =
âˆ«ï¸
âƒ—ğ›¼
(ï¸‚âˆ«ï¸
ğ‘Œ
Î˜
(ï¸âƒ’âƒ’ğ‘€(ğ‘‹; âƒ—ğ›¼) âˆ’ğ‘Œ
âƒ’âƒ’â‰¤ğœ–
)ï¸
Â· ğœŒ(ğ‘Œ|ğ·) ğ‘‘ğ‘Œ
)ï¸‚
Â· ğœŒ(âƒ—ğ›¼|ğ‘€) ğ‘‘âƒ—ğ›¼.
(3.12)
The ğœ–-Boolean participates in several of our BVM regression examples in the following
sections and thus reliability is automatically regressed into our model solutions through
the improved reliability metric.
3.3
Generalized Bayesian Regression via the BVM
This section introduces BVM regression, which generalizes Bayesian and standard
regression. This method has the ability to produce posterior parameter distributions
and predictive envelopes for any data distribution, include prior knowledge about
model parameters (if there is any), and regularize parameter solutions in a way that
parameter uncertainty increases rather than decreases (as discussed in Section 3.2.1).
BVM regression consists of learning the posterior of a set of parameters âƒ—ğ›¼, given
the agreement ğ´and the Boolean function ğµ, from the prior via Bayesâ€™ Rule,
ğœŒ(âƒ—ğ›¼|ğ‘€)
*
âˆ’â†’ğ’«(âƒ—ğ›¼|ğ´) â‰¡ğœŒ(âƒ—ğ›¼|ğ´, ğ‘€, ğ·, ğµ) = ğ‘(ğ´|âƒ—ğ›¼, ğ‘€, ğ·, ğµ) ğœŒ(âƒ—ğ›¼|ğ‘€)
ğ‘(ğ´|ğ‘€, ğ·, ğµ)
.
(3.13)
After learning the posterior distribution of the model parameters, we can evaluate the
predictive distribution defined by:
65

ğ‘(^ğ‘¦|ğ´, ğ‘€, ğµ) =
âˆ«ï¸
âƒ—ğ›¼
ğ‘(^ğ‘¦|âƒ—ğ›¼, ğ´, ğ‘€, ğµ) Â· ğœŒ(âƒ—ğ›¼|ğ´, ğ‘€, ğ·, ğµ) ğ‘‘âƒ—ğ›¼.
(3.14)
Performing BVM regression requires evaluating the BVM probability of agreement. At
the beginning of Appendix D, we give a derivation showing that (3.8) can be written as,
ğ’µ(ğµ) = ğ‘(ğ´|ğ‘€, ğ·, ğµ) =
âˆ«ï¸
âƒ—ğ›¼
(ï¸‚âˆ«ï¸
ğ‘Œ
Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼), ğ‘Œ
)ï¸€)ï¸
Â· ğœŒ(ğ‘Œ|ğ·) ğ‘‘ğ‘Œ
)ï¸‚
Â· ğœŒ(âƒ—ğ›¼|ğ‘€) ğ‘‘âƒ—ğ›¼, (3.15)
which is analogous to (3.3) in form,1 and where the comparison values are ^ğ‘§= ^ğ‘Œ=
ğ‘€(ğ‘‹; âƒ—ğ›¼) and ğ‘§= ğ‘Œ(we assume we are dealing with a set of inputs, model outputs
(i.e. a set of ğ‘›points on a model curve), and ğ‘›observed data points, where all the
data points were collected through independent experiments).
BVM regression can reproduce Bayesian regression, standard regression, and
likelihood-based methods as special cases. When the data and model outputs must
be exactly equal to agree with one another
(ï¸€
i.e. ğ›¿(^ğ‘Œâˆ’ğ‘Œ)
)ï¸€
, the BVM produces
BMT as a special case and the regression solutions are given in Appendix C. Typical
likelihood-based methods follow from the same â€œexactly equalâ€ definition of model-
data agreement. We find that the boolean function ğµğ‘†.ğ‘…(^ğ‘Œ(âƒ—ğ›¼*), ğ‘Œ) that reproduces
standard regression is defined to be true iff âƒ—ğ›¼* = argmin
âƒ—ğ›¼
â„°
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼), ğ‘Œ
)ï¸€
for some
objective function â„°(Â·). This only gives nonsingular posterior parameter distributions
and predictive model envelopes if the data is uncertain and/or if â„°
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼), ğ‘Œ
)ï¸€
does
not have a unique global minimum.
If the objective function is convex, then we have a single minimum which results
in one vector of parameters âƒ—ğ›¼* that makes ğµğ‘†.ğ‘…(^ğ‘Œ(âƒ—ğ›¼*), ğ‘Œ) true. However, when
the cost function is non-convex, then multiple parameter vectors âƒ—ğ›¼* corresponding
to different local minima, lead to a true ğµğ‘†.ğ‘…(^ğ‘Œ(âƒ—ğ›¼*), ğ‘Œ) and may be accepted due
to the approximate nature of non-convex optimization methods. This results in
multiple regressed solutions for the regression problem and approximates the posterior
1In terms of the BVM, the Bayesian evidence in BMT, i.e. Equation (3.3), may be interpreted as
the probability that the uncertain data and model output are exactly equal, i.e. ğœŒ(ğ·|ğ‘€) â‰¡ğœŒ( ^ğ‘Œâ‰¡
ğ‘Œ|ğ‘€, ğ·) â‰¡ğœŒ(ğ´|ğ‘€, ğ·) which is Equation (C.1) derived in Appendix C.
66

parametersâ€™ distribution ğœŒ(âƒ—ğ›¼|ğ´) (analogous to the accepted parameter samples in the
Markov Chain Monte Carlo (MCMC) simulation). Marginalizing leads to the predictive
posterior model distribution ğ‘(^ğ‘¦|ğ´, ğ‘€, ğµ) as in (3.14). Finding the predictive model
output average is analogous to the results obtained in the ensemble methods in machine
learning [8]. Because the BVM can reproduce these special cases and generate new
ones by extending, combining, and modulating Boolean agreement functions, BVM
regression may be seen as a generalized regression method.
Due to the flexibility of the BVM framework, there are many possible definitions of
agreement that the user can define. We discussed some of these definitions in Chapter
2. We summarize them in Table 3.1 below.
Agreement Boolean Function
ğœ–â€“Boolean
True iff
âƒ’âƒ’ğ‘¦ğ‘—âˆ’ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼)
âƒ’âƒ’â‰¤ğœ–ğ‘—âˆ€ğ‘—
(ğ›¾, ğœ–, â„“)â€“Boolean
True iff
âƒ’âƒ’ğ‘¦ğ‘—âˆ’ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼)
âƒ’âƒ’â‰¤â„“ğœ–ğ‘—âˆ€ğ‘—and 1
ğ‘›
âˆ‘ï¸€
ğ‘—Î˜
(ï¸âƒ’âƒ’ğ‘¦ğ‘—âˆ’ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼)
âƒ’âƒ’â‰¤ğœ–ğ‘—
)ï¸
â‰¥ğ›¾%
âŸ¨ğœ–âŸ©â€“Boolean
True iff 1
ğ‘›
âˆ‘ï¸€
ğ‘—
âƒ’âƒ’ğ‘¦ğ‘—âˆ’ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼)
âƒ’âƒ’â‰¤âŸ¨ğœ–âŸ©
(âŸ¨ğœ–âŸ©, ^ğ›¼)â€“Boolean
True iff 1
ğ‘›
âˆ‘ï¸€
ğ‘—
âƒ’âƒ’ğ‘¦ğ‘—âˆ’ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼)
âƒ’âƒ’â‰¤âŸ¨ğœ–âŸ©and 0.91 â‰¤1
ğ‘›
âˆ‘ï¸€
ğ‘—Î˜(ğ‘¦ğ‘—âˆˆ[âˆ’ğ‘^ğ›¼, ğ‘^ğ›¼]ğ‘—) â‰¤0.99
Table 3.1: Some examples of agreement Boolean functions.
To address the concerns we raised about Bayesian and standard regression depicted
in Figure 1-1, consider using the ğœ–âˆ’Boolean with the agreement kernel,
Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼), ğ‘¦ğ‘—
)ï¸€)ï¸
=
â§
âª
â¨
âª
â©
1,
if
âƒ’âƒ’ğ‘¦ğ‘—âˆ’ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼)
âƒ’âƒ’â‰¤ğœ–ğ‘—
0,
otherwise
for all ğ‘—= 1, . . . , ğ‘›, where ğœ–ğ‘—may be adjusted and tuned to impose more or less strict
agreement conditions which may be used by the modeler to enforce reliability in some
region or to be more tolerant of training errors at instance ğ‘¥ğ‘—. For simplicity, We
assume that ğœ–ğ‘—= ğœ–for all ğ‘—. Note that this is (3.11) in Section 3.2.5. In other words,
we use the special case of the BVM, the improved reliability metric with evidence
derived in (3.12), to derive our theoretical solutions.2 Utilizing this BVM definition
allows us to solve the truncated tail data distributions problem in Bayesian regression
2Note that by choosing to adopt a different agreement kernel (or Boolean function) as in Section
3.4.2, we generalize the results derived above; this is the power of the BVM.
67

in a simple way â€“ details in Appendix D.3
Truncated Tail Data Distributions Solution Summary
Let the data be known to have the truncated pdf ğ‘¦ğ‘—âˆ¼ğ’°(ğ‘ğ‘—, ğ‘ğ‘—), for ğ‘—= 1, . . . , ğ‘›. By
using the ğœ–-Boolean, we introduce leniency into the regression in that it no longer
needs to exactly pass through all intervals [ğ‘ğ‘—, ğ‘ğ‘—] simultaneously to count as a â€œfitâ€.
This produces likelihood functions such as,
â„’(âƒ—ğ›¼, ğµ) =
ğ‘›
âˆï¸
ğ‘—=1
ğ‘¢ğ‘—âˆ’ğ‘™ğ‘—
ğ‘ğ‘—âˆ’ğ‘ğ‘—
,
(3.16)
where ğ‘™ğ‘—and ğ‘¢ğ‘—are defined by the boundaries of the intersection of the data uncertainty
and the modelâ€™s tolerance ğœ–,
[ï¸
ğ‘™ğ‘—, ğ‘¢ğ‘—
]ï¸
=
[ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) âˆ’ğœ–, ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) + ğœ–
]ï¸
âˆ©
[ï¸
ğ‘ğ‘—, ğ‘ğ‘—
]ï¸
ğ‘—= 1, . . . , ğ‘›.
An illustration of how the BVM works with truncated data distributions is shown
in Figure 3-1 below. For example, at instance ğ‘¥2, the interval
[ï¸€
ğ‘™2, ğ‘¢2
]ï¸€
is found by
intersecting the intervals
[ï¸€
ğ‘2, ğ‘2
]ï¸€
and
[ï¸€
ğ‘€(ğ‘¥2; âƒ—ğ›¼) âˆ’ğœ–, ğ‘€(ğ‘¥2; âƒ—ğ›¼) + ğœ–
]ï¸€
. Note that this
applies to the instances ğ‘¥ğ‘—for all ğ‘—. In this case, the likelihood is nonzero, resulting in
a nonzero evidence (3.15). Thus, given this agreement definition, the probability of
finding a model given the truncated data is nonzero.
Figure 3-1: Truncated tail data distributions solution. Using BVM re-
gression results in a nonzero probability of finding a model given the observed
truncated data.
3A complete derivation for the infinite tail Gaussian data distribution is given in Appendix D.1.
68

Now, if we consider the special case when the data is completely certain, determin-
istic, i.e. ğ‘Œ= ğ·, then the likelihood function is
â„’(âƒ—ğ›¼, ğµ) = Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼), ğ·
)ï¸€)ï¸
,
(3.17)
which can be seen as a relaxed general form of the delta function adopted in the
Bayesian model testing (where ğœ–= 0), which implies that the model output must be
within ğœ–from the observed measurements in order for them to agree. An analogous
ğœ–-Boolean solution exists for standard regression methods which leads to nonsingular
parameter distributions whether the regression is regularized or not.
Tolerant agreement as a new kind of regularization
The purpose of regularization is to better represent oneâ€™s expectations of unobserved
data using the chosen model or model class. Using BVM regression and nonzero
agreement tolerances (e.g. ğœ–> 0 in the ğœ–-Boolean), we can broaden the modelâ€™s
prediction envelope to better represent our expectations of the data. Increasing
agreement tolerances naturally increases the posterior variance of the parameters,
which differs from standard regularization methods and can be used to avoid conceptual
issues of interpreting regularized physical parameters. It should also be noted that
this is done without changing the prior distributions of the parameters nor the given
probability distributions of the data. This becomes a useful feature in our first example.
3.4
Implementation and Examples
3.4.1
Computing the BVM Evidence
Like the Bayesian evidence, the BVM evidence is computationally expensive to
calculate when one has many model parameters to learn. Several approaches were
adopted to solve this problem. Markov Chain Monte Carlo (MCMC) is a computational
technique used for Bayesian methods that has been widely studied and improved
[6, 17, 35, 37, 42, 48] as it is considered an indispensable tool for Bayesian inference.
69

Other techniques include the Nested Sampling method [10, 54] and the MultiNest
algorithm [11].
We will approximate the BVM evidence and generate the posterior model parameter
distributions (for the purpose of generating modelâ€™s predictive envelopes) using MCMC.
MCMC takes the following inputs: the likelihood function â„’and the prior distribution
ğœ‹of the model parameters, a model ğ‘€and a set of input/output data points {ğ‘‹, ğ‘Œ}.
The Bayesian terms (ğ’µ, â„’) have analogous BVM terms (ğ’µ(ğµ), â„’(ğµ)) and it is therefore
straightforward to extend the MCMC algorithm to BVM calculations to obtain
posterior parameter distributions. These distributions are used to generate a modelâ€™s
predictive envelope.
Any adaptation to the standard MCMC algorithm will be
discussed in text with their corresponding example.
3.4.2
BVM Regression Examples
Exploratory Example 1
We consider the case study investigated in [3] using a bacterial growth model. The
data is obtained by operating a continuous flow biological reactor at steady-state
conditions. The observations are as follows:
ğ‘¥(mg/L COD)
28
55
83
110
138
225
375
ğ‘¦(1/h)
0.053
0.060
0.112
0.105
0.099
0.122
0.125
Table 3.2: The observations we aim to fit.
where ğ‘¦is the growth rate at substrate concentration ğ‘¥. We replicate the results found
in [3] using the nonlinear Monod model to fit the data, i.e,
^ğ‘¦= ğ‘€(ğ‘¥; âƒ—ğ›¼) =
ğ›¼1ğ‘¥
ğ›¼2 + ğ‘¥
(3.18)
where ğ›¼1 is the maximum growth rate (hâˆ’1: per hour), and ğ›¼2 is the saturation
constant (mg/L COD: the Chemical Oxygen Demand, measured in milligrams per
liter).
70

We run MCMC on the likelihoods derived in (3.16) and (3.17) corresponding to the
different types of data distributions discussed above, i.e. bounded or truncated uniform
data distributions, and completely certain observation points (we also consider normal
or Gaussian data distributions with infinite tails). We assume that the vector of
parameters âƒ—ğ›¼has some Gaussian prior distribution. We use the ğœ–âˆ’Boolean agreement
function and find that BVM regression is able to construct posterior inferences of the
model parameters for each type of data measurement distributions, unlike Bayesian
model testing and standard regression techniques that fail at this task for truncated
and completely certain data, as discussed before. We summarize the results in Table
3.3 below.
Data Distribution
BVM regression
Standard regression
Bayesian regression
Infinite Tail



Truncated Tail



Completely Certain



Table 3.3: High probability of the model producing posterior parameter distribu-
tions and predictive envelopes for different types of data distributions using the
three approaches. BVM regression is capable of producing posterior distributions
of the model parameters for any type of data distributions.
Using the BVM regressed parametersâ€™ distributions, we can make predictions of
ğ‘¦for new values of ğ‘¥, i.e., ğ‘(^ğ‘¦|ğ´, ğ‘€, ğµ) from (3.14). In addition, instead of just
computing a point estimate of the fit, we should also study the predictive posterior
distribution of the model, (also called the predictive envelope). As an illustration
of the predictive posterior distribution of our BVM regressed model, we plot the
predictive envelopes of the nonlinear Monod model described in (3.18), treating the
data as completely certain and using the ğœ–-Boolean function with a tolerance ğœ–= 0.03.
71

Figure 3-2: Predictive envelopes of the model in the absence of data
uncertainty using the BVM. As tabulated in Table 3.3, Bayesian regression
fails to produce a candidate model solution as the data is completely certain
and standard regression produces a single deterministic solution with no model
uncertainty.
The black curve shows the predicted response, which is the model fit calculated
using the mean values of the parameters ğ›¼1 and ğ›¼2 in the chain. The gray shaded areas
correspond to 50%, 90%, 95%, and 99% predictive posterior regions (by computing
the model fit for a randomly selected subset of the chain). In other words, the gray
regions span 0.675, 1.645, 2, 3 standard deviations on either side of the mean response,
respectively. We will leave the interpretation of the predictive envelopes for our
compound Boolean agreement function example in Section 3.4.2.
The value of the tolerance ğœ–chosen affects the shape of the model parametersâ€™
distributions and thus the predictive envelope. A smaller tolerance implies stricter
agreement conditions between the model response and the observed data, which results
in less uncertainty in the predictive posterior distributions of the model parameters
and a narrower envelope. On the other hand, a larger tolerance implies a more flexible
agreement conditions, and results in more uncertainty in the predictive distributions,
a wider envelope and a less predictive power. Thus, increasing ğœ–can always result in
finding a model given the data. To avoid getting very wide envelopes relative to the
72

spread of the data, we start with a very small ğœ–when running the MCMC simulation.
We then keep increasing ğœ–until the MCMC algorithm starts achieving a reasonably
small acceptance rate for the new candidates in the chain.
Since this model has just two adaptive parameters, namely ğ›¼1 and ğ›¼2, we can
plot the prior and posterior distributions directly in parameter space. We explore
the dependence between the parametersâ€™ posterior distributions and the value of the
tolerance ğœ–. Figure 3-3 shows the results of BVM learning for the Monod model in
(3.18) as the value of ğœ–is decreased. For comparison, the optimal parameter values
ğ›¼1 = 0.14542 and ğ›¼2 = 49.053 computed using standard regression are shown by a
yellow cross in the first row of Figure 3-3.
Figure 3-3: Illustration of BVM Learning for the Monod model for
decreasing values of ğœ–.
In the first row is the prior/posterior parameter
distribution in (ğ›¼1, ğ›¼2) space. The data points are shown by a blue circle in the
second row. The first column corresponds to the situation before any data point
is observed and shows a plot of the prior distribution in (ğ›¼1, ğ›¼2) space together
with six samples of the model response ğ‘€(ğ‘¥; âƒ—ğ›¼) (red lines) in which the values of
ğ›¼1 and ğ›¼2 are randomly drawn from the prior. In the second, third and fourth
columns, we see the situation after running our BVM learning using MCMC,
with a tolerance ğœ–= 0.03, ğœ–= 0.025 and ğœ–= 0.02, respectively. The posterior
has now been influenced by the agreement tolerance ğœ–, this gives a relatively
compact posterior distribution. Samples from this posterior distribution lead to
the functions shown in red in the second row.
As Figure 3-3 shows, the smaller the tolerance is, the narrower and sharper the
posterior distributions of the parameters are, the closer the red lines get to each other,
and the lower the uncertainty is. This explains the shape of the predictive envelopes as
was discussed before. Thus, by varying ğœ–, one can tune the model response posterior
73

distribution to be more or less representative of the data. We will elaborate more
on this in Section 3.4.3. Note that in our example, when ğœ–goes below about 0.017,
no solution seems to be possible and hence the probability of finding a model given
the observed data becomes zero. In this case, the analyst may choose to work with
any tolerance beyond this threshold, depending on his specifications and agreement
requirements.
Once we generate the posterior distributions of the model parameters and the
predictive envelopes, we can measure and estimate the reliability and accuracy of our
computational model using a validation metric (including the BVM). By doing so, we
determine how accurate is our model representation of the real world.
Exploratory Example 2
After showing how the BVM can be used to perform regression on any type of data
distribution to generate posterior model parametersâ€™ distributions and predictive
envelopes, we now focus on how the user can choose the Boolean function to define
the model-data agreement.
In this example, we will use the compound Boolean as presented in Chapter 2,
Section 2.6.2.4 In that case, the definition of agreement requires the model to pass
an average square error threshold of âŸ¨ğœ–âŸ©as well as a check for probabilistic model
configuration. The latter states that 95% Â± 4% of the uncertain observations (data)
should lie inside the modelâ€™s 1âˆ’^ğ›¼= 95% confidence interval. Note that we impose the
Â±4% tolerance to prevent the scenario where all 100% of the data points lie within an
overly wide confidence interval, being marked as â€œagreeingâ€. We denote this compound
Boolean function by ğµ(^ğ‘Œ, ğ‘Œ, âŸ¨ğœ–âŸ©, ^ğ›¼) and it is equal to,
ğµ
(ï¸‚1
ğ‘›
âˆ‘ï¸
ğ‘–
|^ğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–| â‰¤âŸ¨ğœ–âŸ©
)ï¸‚
âˆ§ğµ
(ï¸‚
0.91 â‰¤1
ğ‘›
âˆ‘ï¸
ğ‘–
Î˜(ğ‘¦ğ‘–âˆˆ[âˆ’ğ‘^ğ›¼, ğ‘^ğ›¼]ğ‘–) â‰¤0.99
)ï¸‚
,
(3.19)
where ğ‘›is the number of data points in the set ğ‘Œ, and [âˆ’ğ‘^ğ›¼, ğ‘^ğ›¼]ğ‘–is the modelâ€™s 95%
confidence interval at instance ğ‘¥ğ‘–(this is the (âŸ¨ğœ–âŸ©, ^ğ›¼)â€“Boolean function in Table 3.1).
4It should be noted that in Chapter 2, a model is simply validated according to this compound
metric â€“ here we calibrate the model with respect to it instead.
74

Note that, although this compound Boolean seems to be complex, it is relatively easy
to code and implement.
The BVM probability of agreement in this case can be expressed as,
ğ’µ(ğµ) = ğ‘(ğ´|ğ‘€, ğ·, ğµ, âŸ¨ğœ–âŸ©, ^ğ›¼) =
âˆ«ï¸
âƒ—ğ›¼
(ï¸‚âˆ«ï¸
ğ‘Œ
Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼), ğ‘Œ, âŸ¨ğœ–âŸ©, ^ğ›¼
)ï¸€)ï¸
Â· ğœŒ(ğ‘Œ|ğ·) ğ‘‘ğ‘Œ
)ï¸‚
âŸ
 â
 
â„’(âƒ—ğ›¼, ğµ)
Â·ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
Note that the likelihood â„’(âƒ—ğ›¼, ğµ) can be expressed as an expectation value over ğœŒ(ğ‘Œ|ğ·),
â„’(âƒ—ğ›¼, ğµ) = ğ¸
[ï¸
Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼), ğ‘Œ, âŸ¨ğœ–âŸ©, ^ğ›¼
)ï¸€)ï¸]ï¸
âˆ¼1
ğ¾
ğ¾
âˆ‘ï¸
ğ‘˜=1
Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼), ğ‘Œ(ğ‘˜), âŸ¨ğœ–âŸ©, ^ğ›¼
)ï¸€)ï¸
,
(3.20)
where ğ‘Œ(ğ‘˜) denotes the ğ‘˜ğ‘¡â„set of data points drawn randomly from the probability
distribution of ğ‘Œ. This allows us to approximate the integral using a statistical method
like Monte-Carlo (MC). In this example, we use MC with ğ¾= 50.
We implement the compound Boolean, ğµ(^ğ‘Œ, ğ‘Œ, âŸ¨ğœ–âŸ©, ^ğ›¼), and show its ability to com-
bine and quantify the average error as well as the probabilistic model representation
of the uncertain data observations. We generated data using,
ğ‘¦(ğ‘¥) = 1 + ğ‘¥ğ‘’âˆ’cos (10ğ‘¥) + sin (10ğ‘¥) + ğœ–ğ‘(ğ‘¥),
where ğœ–ğ‘(ğ‘¥) âˆ¼ğ’©(0, 0.42) for ğ‘¥âˆˆ[0, 1.5] and ğœ–ğ‘(ğ‘¥) âˆ¼ğ’©(0, 0.62) for ğ‘¥âˆˆ[1.5, 3], which
represents the aleatoric stochastic uncertainty due to the systemâ€™s randomness. We
also assume the presence of epistemic measurement uncertainty in the data [50] with
an additional normal distribution ğ’©(0, 0.52) about each data point.
To solve this example, we consider the following deterministic non-linear model,
^ğ‘¦= ğ‘€(ğ‘¥; âƒ—ğ›¼) = ğ›¼1 + ğ›¼2ğ‘¥ğ‘’âˆ’ğ›¼3 cos (ğ›¼4ğ‘¥) + ğ›¼5 sin (ğ›¼6ğ‘¥),
(3.21)
where âƒ—ğ›¼= (ğ›¼1, ğ›¼2, ğ›¼3, ğ›¼4, ğ›¼5, ğ›¼6) is the vector of model parameters having normally
distributed prior distributions with means ğœ‡âƒ—ğ›¼= (0, 0, 0, 9, 0, 9) and standard deviations
ğœâƒ—ğ›¼= (1, 1, 1, 0.5, 1, 0.5). We then conduct two experimental simulations. We first
75

run the MCMC algorithm for 5000 iterations with 10% burn-in using Bayesian
regression and plot the results in Figure 3-4a. We then repeat the simulation using
the approximate likelihood â„’(âƒ—ğ›¼, ğµ) from (3.20) with a threshold of âŸ¨ğœ–âŸ©= 0.7. The
results are shown in Figure 3-4b.
(a) Bayesian regression.
(b) BVM regression.
Figure 3-4: Comparison between Bayesian regression and BVM regres-
sion. (a) Bayesian regression under infinite tail data distribution. Note that the
95% confidence interval is very narrow and standard regression method produces
a nearly identical result. (b) BVM regression using the compound Boolean. In
this case, the 95% confidence region is much wider and represents the data more
accurately. Note that this probabilistic model passes both agreement conditions
imposed by the compound Boolean ğµ( ^ğ‘Œ, ğ‘Œ, âŸ¨ğœ–âŸ©, ^ğ›¼). Starting with a very small
âŸ¨ğœ–âŸ©in the MCMC simulation, we tune âŸ¨ğœ–âŸ©by gradually increasing its value until
both elements of the compound Boolean are naturally satisfied.
The BVM regression framework offers new insights into the interpretation of the
predictive envelopes of Bayesian and standard regression. It is clear in Figure 3-4a
that the Bayesian and standard regression methods generate predictive envelopes that
would not accurately predict new target points. Surprisingly, these envelopes actually
quantify the uncertainties in the least square error solution due to the presence of
data uncertainty rather than a measure of predictive uncertainty. By being careful
in how we define the model-data agreement (as in Figure 3-4b), we were able to
construct predictive envelopes that satisfy our desire in representing new target points
probabilistically. In other words, using the BVM regression framework gives the user
more control over the predictive envelopes and what uncertainties they represent.
76

3.4.3
Discussion
As we have shown in the exploratory examples above, the results are sensitive to the
tolerance ğœ–. This arises from the fact that ğœ–represents the modelerâ€™s tolerance on
the difference between the model outputs and the observed data. Thus, any other
parameter that is included in the Boolean function ğµdefined by the modeler will have
an effect on the parametersâ€™ posterior distributions and the predictive envelopes. As
shown in the previous examples, we can take advantage of this feature for modeling.
We analyse the effect of the tolerance ğœ–as follows.
Changing the agreement
tolerance ğœ–affects the acceptance rate in the MCMC iterations, i.e. a larger tolerance
yields a larger variance of accepted â€œcandidateâ€ samples. The increased variance in the
accepted samples produces wider posterior model parameter distributions. A smaller
tolerance implies the converse.
Parameters not regressed inside the Boolean function ğµ(ğœ–in this case) play a role
similar to hyperparameters in Machine Learning. By tuning the hyperparameters,
the modeler can make the predictive envelopes more representative of the data, and
improve the overall performance of the model when compared to a randomly selected
test (or validation) data set.
Note that in the case of the ğœ–â€“Boolean, the user can increase ğœ–indefinitely and still
â€œregressâ€ the model; although the predictive envelopes will be much wider than the
data spread and hence less representative of the data. While widening the predictive
envelopes can be useful for reliability and safety, if they are widened too much, the
model can lose some of its predictive utility. To balance the trade-off between safety
and utility, we regressed the model in (3.21) with respect to the compound Boolean
(3.19) in Section 3.4.2. This Boolean forced the model to be regressed in such a way
that 95%Â±4% of the (uncertain) data points lie within the modelâ€™s 95% confidence
region while simultaneously satisfying the âŸ¨ğœ–âŸ©requirement (for diversity we used âŸ¨ğœ–âŸ©
instead of ğœ–although nothing prevents us from doing so in principle). As stated in the
caption of Figure 3-4, we gradually tuned the value of âŸ¨ğœ–âŸ©(hyperparameter tuning) to
simultaneously satisfy both requirements imposed by the compound Boolean function.
77

3.5
Conclusion
This chapter presents a generalized Bayesian regression and model learning technique
that is capable of probabilistically regressing (learning) model parameter distributions
while satisfying arbitrary definitions of model-data agreement within the BVM frame-
work. Using this technique, we can perform Bayesian regression based on any type of
data distribution and construct predictive envelopes that are more representative of
the data, which improves the overall performance of the model under question.
78

Chapter 4
Conclusions and Recommendations
4.1
Conclusions
This thesis presents the BVM, a general model validation and testing tool. We demon-
strated the versatility of the BVM toward expressing and solving model validation and
calibration problems. The BVM quantifies the probability that a model is valid for
arbitrary quantifiable definitions of model-data agreement using arbitrary comparison
functions of the model-data comparison values. The BVM was shown: to obey all of
the desired validation metric criteria [28] (which is a first), to be able to represent
all of the standard validation metrics as special cases, to supply improvements and
generalizations to those special cases, and to be a tool for quantifying the validity of a
model in novel model-data contexts. The latter was demonstrated by the validation
metrics we invented and quantified in our examples.
In addition, it was shown that one can perform model selection using the BVM
ratio. The BVM model testing framework was shown to generalize the Bayesian model
testing framework to arbitrary model-data contexts and with reference to arbitrary
comparisons and agreement definitions. That is, the BVM ratio may be used to rank
models directly in terms of the relevant model-data validation context. The problem
of model-data validation may be reduced to the problem of finding/defining the four
BVM inputs: (^ğ‘§, ğ‘§), ğœŒ(^ğ‘§, ğ‘§|ğ‘€, ğ·), ğ‘“(^ğ‘§, ğ‘§), and ğµ(ğ‘“), and computing their BVM value.
We find that the BVM is a useful tool for performing model validation and testing.
79

Finally, the BVM framework can be expanded to probabilistically regress model
parameter distributions that satisfy arbitrary definitions of agreement. Particularly, in
the calibration stage of model development, we can use the BVM to perform regression
and model learning on data with any type of uncertainty, generate posterior parameter
distributions, and model predictive envelopes, according to user-specified definitions
of model-data agreement. The BVM regression framework proved its potential in
offering new insights into the interpretation of the predictive envelopes of the Bayesian
regression, standard regression, and likelihood-based techniques, and hence providing
the analyst with more freedom and control over the predictive envelopes and their
meaning.
In short, we find the BVM to constitute a generalized framework for
probabilistic model calibration and validation allowing us to address several potential
shortcomings in the calibration and validation techniques found in the literature.
4.2
Recommendations
We provide some suggestions for researchers who are interested in building on the
contributions discussed in this thesis to improve and advance this area of research.
All the work presented in this thesis relies heavily on parametric models. Thus,
one possible future research topic is to expand the BVM framework to nonparametric
regression (e.g. Gaussian processes). Another line of research involves developing
neural networks within the BVM framework. Particularly, one can investigate and
explore ways to integrate the BVM probability of agreement into the loss function of
the neural networks.
Because the BVM is an open framework where the definition of agreement is
composable and user-defined, there is room for the quantification of further agree-
ment/validation requirements as the need arises in data analysis and model reliability.
Finally, we emphasize the importance of practicing statistical responsibility by
being explicit in the definition of agreement between the models and data in the field
of reliability. The BVM framework forces the modeler to be explicit in their definitions,
assumptions, and criteria when performing model calibration and validation.
80

Appendix A
Representing the Known Validation
Metrics with the BVM
In the following sections, we will show some of the special cases of the Bayesian
Validation Metric (BVM). Subsequent improvements or immediate generalizations
of the metrics using (2.2) are presented when applicable. A detailed review of the
majority of these metrics may be found in [28] and the references therein. Tables 2.1
and 2.2 in Section 2.5 outline the results.
A.1
Reliability Metric and Probability of Agreement
There are a few validation metrics related to the reliability metric present in the
literature. The reliability metric ğ‘Ÿ= ğ‘(|âŸ¨^ğ‘¦âŸ©âˆ’ğœ‡ğ‘¦| < ğœ–) [47] is equal to the probability
that the data and the model expectation values are within a tolerance of size ğœ–.
Their â€œprobability of agreementâ€ introduced in [57] is closely related to ğ‘Ÿ, but instead
expresses the quantity as â€œthe probability the data and the model expectation values
agree within a tolerance (or sliding tolerance) of ğœ–â€. The reliability metric was expanded
in [51] to account for model outputs and data rather than simply comparing the mean
of the model prediction against the mean of the data. The improved reliability metric
81

is equal to,
ğ‘Ÿğ‘–=
âˆ«ï¸âˆ
âˆ’âˆ
ğœŒ(ğ‘Œ|ğ·)
âˆ«ï¸ğ‘Œ+ğœ–(ğ‘Œ)
ğ‘Œâˆ’ğœ–(ğ‘Œ)
ğœŒ(^ğ‘Œ|ğ‘€) ğ‘‘^ğ‘Œğ‘‘ğ‘Œ,
(A.1)
where ğœŒ(^ğ‘Œ|ğ‘€) and ğœŒ(ğ‘Œ|ğ·) are the full joint probability distributions of the model
outputs and the data, respectively. This metric quantifies the probability that the
error is less than a value ğœ–(ğ‘¦) on a point to point basis.
The BVM is the reliability metric when the comparison values are ^ğ‘§= âŸ¨^ğ‘¦âŸ©and
ğ‘§= ğœ‡ğ‘¦, and ğµtakes the form of an inequality, being true if âˆ’ğœ–â‰¤âŸ¨^ğ‘¦âŸ©âˆ’ğœ‡ğ‘¦â‰¤ğœ–. If we
would like to use a sliding interval of â€œtoleranceâ€ or â€œerror acceptanceâ€, denote it by
[ï¸€
ğ‘âˆ’(ğœ‡ğ‘¦), ğ‘+(ğœ‡ğ‘¦)
]ï¸€
, where ğ‘âˆ’< ğ‘+, and the BVM is,
ğ‘(ğ´|ğ‘€, ğ·)
=
âˆ«ï¸
âŸ¨^ğ‘¦âŸ©,ğœ‡ğ‘¦
ğœŒ(âŸ¨^ğ‘¦âŸ©|ğ‘€) Â· Î˜
(ï¸
ğ‘âˆ’(ğœ‡ğ‘¦) â‰¤âŸ¨^ğ‘¦âŸ©â‰¤ğ‘+(ğœ‡ğ‘¦)
)ï¸
Â· ğœŒ(ğœ‡ğ‘¦|ğ·) ğ‘‘âŸ¨^ğ‘¦âŸ©ğ‘‘ğœ‡ğ‘¦
=
âˆ«ï¸
ğœ‡ğ‘¦
âˆ«ï¸ğ‘+(ğœ‡ğ‘¦)
âŸ¨^ğ‘¦âŸ©=ğ‘âˆ’(ğœ‡ğ‘¦)
ğœŒ(âŸ¨^ğ‘¦âŸ©|ğ‘€) Â· ğœŒ(ğœ‡ğ‘¦|ğ·) ğ‘‘âŸ¨^ğ‘¦âŸ©ğ‘‘ğœ‡ğ‘¦= ğ‘Ÿ.
(A.2)
This is the reliability metric if ğ‘Â± = ğœ‡ğ‘¦Â± ğœ–is a constant and the sliding interval is
symmetric about ğœ‡ğ‘¦.
The BVM is the improved reliability metric when ^ğ‘§= ^ğ‘Œ, ğ‘§= ğ‘Œ, and when the
Boolean ğµ(^ğ‘§, ğ‘§) is true iff |^ğ‘¦âˆ’ğ‘¦| â‰¤ğœ–(ğ‘¦) for all ^ğ‘¦, ğ‘¦pairs. That is,
ğ‘(ğ´|ğ‘€, ğ·) =
âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğœŒ( ^ğ‘Œ|ğ·) Â· ğœŒ(ğ‘Œ|ğ‘€) Â·
(ï¸
âˆï¸
^ğ‘¦,ğ‘¦pairs
Î˜
(ï¸€
|^ğ‘¦âˆ’ğ‘¦| â‰¤ğœ–(ğ‘¦)
)ï¸€)ï¸
ğ‘‘^ğ‘Œğ‘‘ğ‘Œ= ğ‘Ÿğ‘–.
(A.3)
The BVM quantifies the probability of square error (or difference) is less than
some ğœ–by considering,
ğ‘(ğ´|ğ‘€, ğ·) =
âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğœŒ(^ğ‘Œ|ğ·) Â· Î˜
(ï¸€
|^ğ‘Œâˆ’ğ‘Œ| â‰¤ğœ–
)ï¸€
Â· ğœŒ(ğ‘Œ|ğ‘€) ğ‘‘^ğ‘Œğ‘‘ğ‘Œ.
(A.4)
Nothing in the BVM requires the variables to be continuous or ordered, so the
natural generalization is to let the Boolean expression be true if â€œThe value ^ğ‘§is in the
subset ğ‘†(ğ‘§), which is the set of ^ğ‘§â€™s agreeing with ğ‘§â€. For example, if ^ğ‘§â€™s are strings,
82

ğ‘†(ğ‘§) might be the set of words or phrases in ^ğ‘§that are reasonably synonymous with
ğ‘§. This gives the straightforward generalization to accommodate arbitrary data types,
ğ‘(ğ´|ğ‘€, ğ·) =
âˆ‘ï¸
^ğ‘§,ğ‘§
ğ‘(^ğ‘§|ğ‘€) Â· Î˜
(ï¸€
^ğ‘§âˆˆğ‘†(ğ‘§)
)ï¸€
Â· ğ‘(ğ‘§|ğ·) =
âˆ‘ï¸
ğ‘§
âˆ‘ï¸
^ğ‘§âˆˆğ‘†(ğ‘§)
ğ‘(^ğ‘§|ğ‘€) Â· ğ‘(ğ‘§|ğ·), (A.5)
by using sets rather than intervals.
A.2
Frequentist Validation Metric
To include the frequentist validation metric in the BVM, we will have to express
the comparison variables ^ğ‘§and ğ‘§and their respective probabilities. The result can
be replicated by letting: ğ‘§= ğœ‡ğ‘¦be the Studentâ€™s ğ‘¡-distribution and ^ğ‘§= âŸ¨^ğ‘¦âŸ©have a
Dirac delta distribution ğœŒ(^ğ‘§|ğ‘€, ğ·) = ğœŒ(âŸ¨^ğ‘¦âŸ©|ğ‘€, ğ·) = ğ›¿
(ï¸€
âŸ¨^ğ‘¦âŸ©âˆ’âŸ¨^ğ‘¦âŸ©â€²)ï¸€
where âŸ¨^ğ‘¦âŸ©â€² is the
known value of the computational modelâ€™s expected output. Because the frequentist
validation metric does not force the modeler to define what is meant by agreement,
we represent this freedom by keeping ğµ(^ğ‘§, ğ‘§) general. This gives,
ğ‘(ğ´|ğ‘€, ğ·)
=
âˆ«ï¸
^ğ‘§,ğ‘§
ğœŒ(^ğ‘§|ğ‘€, ğ·) Â· Î˜
(ï¸€
ğµ(^ğ‘§, ğ‘§)
)ï¸€
Â· ğœŒ(ğ‘§|ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§
=
âˆ«ï¸
âŸ¨^ğ‘¦âŸ©,ğœ‡ğ‘¦
ğ›¿
(ï¸€
âŸ¨^ğ‘¦âŸ©âˆ’âŸ¨^ğ‘¦âŸ©â€²)ï¸€
Â· Î˜
(ï¸
ğµ
(ï¸€
âŸ¨^ğ‘¦âŸ©, ğœ‡ğ‘¦
)ï¸€)ï¸
Â·
(ï¸ƒ
Î“( ğœˆ+1
2 )
âˆšğœˆğœ‹Î“( ğœˆ
2)
(ï¸‚
1 + (ğœ‡ğ‘¦âˆ’ğ‘¦)2
ğœˆğ‘ 2/ğ‘
)ï¸‚âˆ’ğœˆ+1
2 )ï¸ƒ
ğ‘‘âŸ¨^ğ‘¦âŸ©ğ‘‘ğœ‡ğ‘¦,
where ğ‘¦(the population average), ğ‘ (the population standard deviation), and ğœˆ(the
degrees of freedom) are the parameters of the dataâ€™s ğ‘¡-distribution. Making the
coordinate transformations âŸ¨^ğ‘¦âŸ©â†’ğ¸= âŸ¨^ğ‘¦âŸ©âˆ’ğ‘¦and ğœ‡ğ‘¦â†’ğ¸= âŸ¨^ğ‘¦âŸ©âˆ’ğœ‡ğ‘¦gives,
ğ‘(ğ´|ğ‘€, ğ·)
=
âˆ«ï¸
ğ¸,ğ¸
ğ›¿
(ï¸€
ğ¸âˆ’ğ¸
â€²)ï¸€
Â· Î˜
(ï¸
ğµ
(ï¸€
ğ¸, ğ¸
)ï¸€)ï¸
Â·
(ï¸ƒ
Î“(ğœˆ+1
2 )
âˆšğœˆğœ‹Î“(ğœˆ
2)
(ï¸‚
1 + (ğ¸âˆ’ğ¸)2
ğœˆğ‘ 2/ğ‘
)ï¸‚âˆ’ğœˆ+1
2
)ï¸ƒ
ğ‘‘ğ¸ğ‘‘ğ¸
=
Î“(ğœˆ+1
2 )
âˆšğœˆğœ‹Î“(ğœˆ
2)
âˆ«ï¸
ğ¸â€² Î˜
(ï¸
ğµ
(ï¸€
ğ¸
â€², ğ¸â€²)ï¸€)ï¸
Â·
(ï¸‚
1 + (ğ¸â€² âˆ’ğ¸
â€²)2
ğœˆğ‘ 2/ğ‘
)ï¸‚âˆ’ğœˆ+1
2
ğ‘‘ğ¸â€²,
(A.6)
with ğ¸
â€² = âŸ¨^ğ‘¦âŸ©â€² âˆ’ğ‘¦and ğ¸â€² = âŸ¨^ğ‘¦âŸ©â€² âˆ’ğœ‡ğ‘¦.
Given that judgments of agreement in
the frequentist validation metric are expected to be made based on the confidence
level 1 âˆ’ğ›¼that ğ¸â€² is within the confidence interval, this may be factored into
ğµ
(ï¸€
ğ¸
â€², ğ¸â€²)ï¸€
â†’ğµ
(ï¸€
ğ¸
â€², ğ¸â€², ğ›¼
)ï¸€
, as well as other user-defined terms toward expressing
83

agreement. Equation (A.6) is thought to be the full BVM representation of the
frequentist validation metric.
The immediate generalization to the frequentist validation metric offered by the
BVM is to let the model output expectation value ^ğ‘§= âŸ¨^ğ‘¦âŸ©have some amount of
uncertainty. The uncertainty is perhaps Gaussian or Studentâ€™s ğ‘¡-distributed in ğœ‡âŸ¨^ğ‘¦âŸ©
(the true model expectation value) due to only having a finite number of Monte Carlo
samples and/or uncertainty induced by discretization error. Because ^ğ‘§= ğœ‡âŸ¨^ğ‘¦âŸ©and
ğ‘§= ğœ‡ğ‘¦are both uncertain in general, one generalizes to,
ğ‘(ğ´|ğ‘€, ğ·, ğµ) =
âˆ«ï¸
ğœ‡âŸ¨^ğ‘¦âŸ©,ğœ‡ğ‘¦
ğœŒ(ğœ‡âŸ¨^ğ‘¦âŸ©|ğ‘€, ğ·) Â· Î˜
(ï¸
ğµ
(ï¸€
ğœ‡âŸ¨^ğ‘¦âŸ©, ğœ‡ğ‘¦
)ï¸€)ï¸
Â· ğœŒ(ğœ‡ğ‘¦|ğ·) ğ‘‘ğœ‡âŸ¨^ğ‘¦âŸ©ğ‘‘ğœ‡ğ‘¦.
(A.7)
It is interesting to note the consequence of defining a reasonable Boolean expression
of agreement on the BVM representation of the frequentist metric. A natural agreement
function ğµfor the metric is one that is true if ğ¸ğœ‡= |ğœ‡âŸ¨^ğ‘¦âŸ©âˆ’ğœ‡ğ‘¦| â‰¤ğœ–.
The BVM then gives,
ğ‘(ğ´|ğ‘€, ğ·)
=
âˆ«ï¸
ğœ‡âŸ¨^ğ‘¦âŸ©,ğœ‡ğ‘¦
ğœŒ(ğœ‡âŸ¨^ğ‘¦âŸ©|ğ‘€, ğ·) Â· Î˜
(ï¸€
ğ¸ğœ‡â‰¤ğœ–
)ï¸€
Â· ğœŒ(ğœ‡ğ‘¦|ğ·) ğ‘‘ğœ‡âŸ¨^ğ‘¦âŸ©ğ‘‘ğœ‡ğ‘¦
=
âˆ«ï¸
ğœ‡âŸ¨^ğ‘¦âŸ©
âˆ«ï¸
ğœ‡ğ‘¦=ğœ‡âŸ¨^ğ‘¦âŸ©Â±ğœ–
ğœŒ(ğœ‡âŸ¨^ğ‘¦âŸ©|ğ‘€, ğ·) Â· ğœŒ(ğœ‡ğ‘¦|ğ·) ğ‘‘ğœ‡âŸ¨^ğ‘¦âŸ©ğ‘‘ğœ‡ğ‘¦= ğ‘Ÿ.
(A.8)
Thus, the frequentist validation metric is the reliability metric [47] and the â€œproba-
bility of agreementâ€ [57] when reasonable accuracy requirements are imposed on the
acceptable difference between the expectation values.
A.3
Area and Binned Probability Difference Metric
The BVM is able to represent and generalize the area metric by letting the comparison
values (^ğ‘§, ğ‘§) be the cumulative distribution functions (cdfs) in question to be compared
(ğ¹(^ğ‘¦|ğ‘€), ğ¹(ğ‘¦|ğ·)). The area metric is,
ğ‘‘
[ï¸€
ğ¹(^ğ‘¦|ğ‘€), ğ¹(ğ‘¦|ğ·)
]ï¸€
=
âˆ«ï¸âˆ
âˆ’âˆ
âƒ’âƒ’ğ¹(^ğ‘¦|ğ‘€) âˆ’ğ¹(ğ‘¦= ^ğ‘¦|ğ·)
âƒ’âƒ’ğ‘‘^ğ‘¦.
(A.9)
84

The area metric may be represented by the BVM in a simple way. First allow the
comparison value function to be the area metric functional,
ğ‘“(ğ‘§, ^ğ‘§) â‰¡ğ‘‘
[ï¸€
ğ¹(^ğ‘¦|ğ‘€), ğ¹(ğ‘¦|ğ·)
]ï¸€
,
(A.10)
and define agreement with a Boolean,
ğ‘(ğ´|ğ‘€, ğ·) = Î˜
(ï¸
ğµ
(ï¸€
ğ‘‘[ğ¹(^ğ‘¦|ğ‘€), ğ¹(ğ‘¦|ğ·)]
)ï¸€)ï¸
.
(A.11)
Here, the cdfs are treated as completely certain
(ï¸€
ğ›¿(^ğ‘§âˆ’ğ¹(^ğ‘¦|ğ‘€)) and ğ›¿(ğ‘§âˆ’ğ¹(ğ‘¦|ğ·))
are Dirac delta functionals
)ï¸€
. The functional form of the Boolean may be decided
given the userâ€™s specific validation requirements; however, satisfying some kind of ğœ–
threshold ğ‘‘[ğ¹(^ğ‘¦|ğ‘€), ğ¹(ğ‘¦|ğ·)] â‰¤ğœ–seems logical. Generalizations to the area metric
may be represented analogously with the BVM.
When the values of the cdfs are uncertain, the BVM becomes,
ğ‘(ğ´|ğ‘€, ğ·) â†
âˆ«ï¸
Î˜
(ï¸
ğµ
(ï¸€
ğ‘‘[ğ¹(^ğ‘¦|ğ‘€), ğ¹(ğ‘¦|ğ·)]
)ï¸€)ï¸
Â· ğœŒ
(ï¸€
ğ¹(^ğ‘¦|ğ‘€), ğ¹(ğ‘¦|ğ·)
)ï¸€
ğ‘‘ğ¹(^ğ‘¦|ğ‘€) ğ‘‘ğ¹(ğ‘¦|ğ·),
(A.12)
which may pose computational challenges and require random sampling; however, in
some cases it may be permissible to treat the model cdf as known. The extension
to uncertain cdfs is usually not considered in the literature; however, the theoretical
generalization to the uncertain case is apparent in the BVM framework. As an
approximation, one may consider discretizing the area metric by breaking it into ğ¾
comparison points,
ğ‘‘
[ï¸€
ğ¹(^ğ‘¦|ğ‘€), ğ¹(ğ‘¦= ^ğ‘¦|ğ·)
]ï¸€
â‰ˆ
ğ¾
âˆ‘ï¸
ğ‘–=1
âƒ’âƒ’ğ¹(^ğ‘¦ğ‘–|ğ‘€) âˆ’ğ¹(ğ‘¦ğ‘–= ^ğ‘¦ğ‘–|ğ·)
âƒ’âƒ’.
(A.13)
The uncertainty in the cumulative distribution of the data ğœŒ(ğ‘§|ğ·) is now a finite
joint product pdf ğœŒ
(ï¸€
ğ¹(ğ‘¦1|ğ·), . . . , ğ¹(ğ‘¦ğ¾|ğ·)
âƒ’âƒ’ğ·
)ï¸€
over possible cdf values in the ğ¾bins,
constrained by ğ¹(ğ‘¦ğ‘–|ğ·) â‰¤ğ¹(ğ‘¦ğ‘–+1|ğ·). This metric may also be represented with the
BVM.
85

Alternatively, one may consider a binned probability difference comparison func-
tional,
ğ‘‘ğ‘š
[ï¸€
ğ‘(^ğ‘¦|ğ‘€), ğ‘(ğ‘¦= ^ğ‘¦|ğ·)
]ï¸€
=
ğ¾
âˆ‘ï¸
ğ‘–=1
âƒ’âƒ’ğ‘(^ğ‘¦ğ‘–|ğ‘€) âˆ’ğ‘(ğ‘¦ğ‘–= ^ğ‘¦ğ‘–|ğ·)
âƒ’âƒ’.
(A.14)
Let
ğ‘(ğ‘§|ğ·) = ğ‘
(ï¸€
ğ‘ğ‘¦1, . . . , ğ‘ğ‘¦ğ¾
âƒ’âƒ’ğ·, âˆ‘ï¸€
ğ‘˜ğ‘ğ‘¦ğ‘˜= 1
)ï¸€
be the uncertainty for the probability estimate in each data bin due to the random
process. Given that the pdf of the model is set to a (presumably known) single pdf
function ğ‘(^ğ‘¦|ğ‘€), the BVM is,
ğ‘(ğ´|ğ‘€, ğ·)
=
âˆ«ï¸
^ğ‘§,ğ‘§
ğ›¿
(ï¸€
^ğ‘§âˆ’{ğ‘(^ğ‘¦|ğ‘€)}
)ï¸€
Â· Î˜
(ï¸
ğµ
(ï¸€
ğ‘‘ğ‘š[^ğ‘§, ğ‘§]
)ï¸€)ï¸
Â· ğ‘(ğ‘§|ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§
=
âˆ«ï¸
ğ‘ğ‘¦1,...,ğ‘ğ‘¦ğ¾
Î˜
(ï¸
ğµ
(ï¸€
ğ‘‘ğ‘š
[ï¸€
{ğ‘(^ğ‘¦|ğ‘€)}, {ğ‘(ğ‘¦|ğ·)}
]ï¸€)ï¸€)ï¸
Â· ğ‘(ğ‘ğ‘¦1, ..., ğ‘ğ‘¦ğ¾|ğ·)
âˆï¸
ğ‘–
(ğ‘‘ğ‘ğ‘¦ğ‘–).
Given the form of the distribution ğ‘(ğ‘ğ‘¦1, . . . , ğ‘ğ‘¦ğ¾|ğ·) is well-known (i.e. a Dirichlet
distribution after ğ‘›independent observations of ğ‘¦), the BVM can be treated as an
expectation value,
ğ‘(ğ´|ğ‘€, ğ·) = ğ¸
[ï¸
Î˜
(ï¸
ğµ
(ï¸€
ğ‘‘ğ‘š
[ï¸€
{ğ‘(^ğ‘¦|ğ‘€)}, {ğ‘(ğ‘¦|ğ·)}
]ï¸€)ï¸€)ï¸]ï¸
{ğ‘(ğ‘¦|ğ·)}
(A.15)
and estimated with Monte Carlo.
When ğ¾is large, we may face the curse of
dimensionality if the probabilities (bin heights) are themselves uncertain.
The number of bins ğ¾plays a role similar to ğœ–in that its choice affects the
definition/context of agreement represented by the BVM. The binned pdf metric is
most informative when ğ¾is large because one is checking each region of the pdf for
agreement. On the other hand, perhaps when data is limited, there may be instances
when having ğ¾= 2 bins is useful, if for example one was interested in testing a
model for representing binary type probabilities (like pass/fail or positive/negative).
Using a favorable agreement in this simple binary context to imply that the model
works for otherwise untested ğ¾> 2 comparisons/contexts/validations, is statistical
misrepresentation and should be avoided (see Section 2.3.3). The BVM requires one
86

to explicitly state the comparison values, the comparison value function, and the
definition of agreement to compute ğ‘(ğ´|ğ‘€, ğ·) such that confusion may be avoided
and model validation comparisons may be justified.
Thus, the choice of ğ¾ultimately determines the granularity of the definition of
agreement being tested. If one uses methods similar to [19] to select ğ¾, then one
is letting the complexity of the data and the number of data points determine the
stringency of the definition of agreement.
A.4
Probability Density Function Comparison Met-
rics
Another way to gauge the agreement between uncertain data and models is through
a pdf comparison metric, ğº(ğœŒğ·||ğœŒğ‘€) [34]. Examples of ğº(ğœŒğ·||ğœŒğ‘€) are the negative
relative entropy or KL divergence,
ğ·ğ¾ğ¿(ğœŒğ·||ğœŒğ‘€) =
âˆ«ï¸
ğ‘¦
ğœŒ(ğ‘¦|ğ·) log
(ï¸‚
ğœŒ(ğ‘¦|ğ·)
ğœŒ(^ğ‘¦= ğ‘¦|ğ‘€)
)ï¸‚
ğ‘‘ğ‘¦,
(A.16)
the Symmetrized KL divergence ğ‘†ğ¾ğ¿(ğœŒğ·, ğœŒğ‘€) = ğ·ğ¾ğ¿(ğœŒğ·||ğœŒğ‘€) + ğ·ğ¾ğ¿(ğœŒğ‘€||ğœŒğ·), the
Jensen-Shannon divergence ğ·ğ½ğ‘†(ğœŒğ·, ğœŒğ‘€), the Hellinger Metric ğ»(ğœŒğ·, ğœŒğ‘€), the Fisher
information distance â„“(ğœŒğ·, ğœŒğ‘€), and the Wasserstein distance ğ‘Š(ğœŒğ·, ğœŒğ‘€). These
metrics give a notion of â€œclosenessâ€ between the pdfs that can be used for validation.
The BVM may represent these validation metrics by letting the comparison value
function ğ‘“(^ğ‘§, ğ‘§) be the pdf comparison metric,
ğ‘“(^ğ‘§, ğ‘§) â‰¡ğº(ğœŒğ·||ğœŒğ‘€),
where ^ğ‘§â‰¡ğœŒğ‘€and ğ‘§â‰¡ğœŒğ·are the model and data pdfs, respectively. In the absence
of model and data uncertainty (i.e. the pdfs are treated as known functions, e.g. ğœŒğ·
87

is a gaussian with mean = 0 and variance = 1), the BVM is simply,
ğ‘(ğ´|ğ‘€, ğ·) = Î˜
(ï¸
ğµ
(ï¸€
ğ‘“(^ğ‘§, ğ‘§)
)ï¸€)ï¸
= Î˜
(ï¸
ğµ
(ï¸€
ğº(ğœŒğ·||ğœŒğ‘€)
)ï¸€)ï¸
,
which either meets the specifications for them to agree (defined by ğµ), or does not
(e.g. passing a tolerance threshold). Following the structure of the BVM, if there are
uncertainties in the functional forms of the pdfs, they may be included into the BVM,
ğ‘(ğ´|ğ‘€, ğ·) â†
âˆ«ï¸
ğœŒğ·,ğœŒğ‘€
Î˜
(ï¸
ğµ
(ï¸€
ğº(ğœŒğ·||ğœŒğ‘€)
)ï¸€)ï¸
Â· ğœŒ(ğœŒğ·, ğœŒğ‘€) ğ‘‘ğœŒğ·ğ‘‘ğœŒğ‘€.
Uncertainties in the data pdfs may come from a lack of data and uncertainties in the
model may come from parametric uncertainty
(ï¸€
e.g. a Gaussian pdf model ğœŒğ‘€|ğœ‡with
an uncertain mean ğœŒ(ğœ‡)
)ï¸€
.1 As with the area metric, these metrics may be discretized
from pdf to probability comparison metrics, and uncertainties in the pdfs themselves
are typically not discussed/quantified in the literature.
A.5
Statistical Hypothesis Testing
Normally when statistical hypothesis testing is performed, one constructs the pdf of
the relevant test statistic of the data ğœŒ(ğ‘§|ğ·) and then assumes the null hypothesis
is true (ğ‘€= ğ·) counterfactually, which is enforced by setting the â€œto be tested
populationâ€ (the model outputs here) pdf to be equal to the pdf of the test statistic
of the data ğœŒ(^ğ‘§|ğ‘€) â†’ğœŒ(^ğ‘§|ğ‘€= ğ·). However, in the present case, we are interested
in the general modeling case in which one is able to extract a pdf of the outputs of
the model, which we would like to test against data before assuming that they are
equal. We will first represent the classical statistical hypothesis test using the BVM
and then later supply a version that is more relevant to model validation problems.
1 One should note that here there is the potential for two different models.
One in which
ğœŒğ‘€â‰¡
âˆ«ï¸€
ğœŒğ‘€|ğœ‡ğœŒ(ğœ‡) ğ‘‘ğœ‡is marginalized over (in which case the model pdf is â€œcertainâ€ if integrated
analytically), and another in which the model pdf is gaussian ğœŒğ‘€|ğœ‡but there is model parametric
uncertainty of the form ğœŒ(ğœ‡).
88

Classical statistical hypothesis testing.
In classical hypothesis testing, one
constructs the pdf of a relevant test statistic ğ‘†ğ‘¦â‰¡ğ‘§of the data ğœŒ(ğ‘§|ğ·). The null
hypothesis is that the model is equal to the data, which is enforced by setting
ğœŒ(^ğ‘§|ğ‘€) = ğœŒ(^ğ‘§|ğ‘€= ğ·). Further, the null hypothesis is not rejected if the test statistic
from the model ^ğ‘§falls within the critical region [âˆ’ğ‘ğ›¼, ğ‘ğ›¼] that corresponds to the
probability
âˆ«ï¸€ğ‘ğ›¼
âˆ’ğ‘ğ›¼ğœŒ(ğ‘§|ğ·) ğ‘‘ğ‘§= 1 âˆ’ğ›¼of the data. The case of not rejecting the null
hypothesis is represented by the Boolean expression ğµ(^ğ‘§), which is true if âˆ’ğ‘ğ›¼â‰¤^ğ‘§â‰¤ğ‘ğ›¼
is true â€“ defining â€œagreementâ€ in this case. This results in the following BVM,
ğ‘(ğ´|ğ‘€= ğ·, ğ·)
=
âˆ«ï¸
^^ğ‘§,ğ‘§
ğœŒ(^ğ‘§|ğ‘€= ğ·) Â· Î˜
(ï¸€
ğµ(^ğ‘§)
)ï¸€
Â· ğœŒ(ğ‘§|ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§
=
âˆ«ï¸
^ğ‘§
ğœŒ(^ğ‘§|ğ‘€= ğ·) Â· Î˜
(ï¸€
âˆ’ğ‘ğ›¼â‰¤^ğ‘§â‰¤ğ‘ğ›¼
)ï¸€
ğ‘‘^ğ‘§= 1 âˆ’ğ›¼, (A.17)
because the model was assumed to be equal to the data counterfactually in the null
hypothesis and ğµ(^ğ‘§, ğ‘§) = ğµ(^ğ‘§) only.
The probability of type I error, i.e. rejecting the counterfactually assumed true
null hypothesis when it is actually true, is equal to ğ›¼.
It should be noted that
this is not equal to the probability of finding the model value outside of the dataâ€™s
confidence interval because it is unknown if the null hypothesis
(ï¸€
in what results
in ğœŒ(^ğ‘§|ğ‘€) â†’ğœŒ(^ğ‘§|ğ‘€= ğ·)
)ï¸€
is actually true, or not, because the null hypothesis
was merely assumed to be true counterfactually. It should further be noted that
with probability ğ›¼the dataâ€™s test statistic is outside of its own confidence interval.
Thus, the probability ğ›¼both indicates type I error and a systematic type error that
the wrong sort of comparison is being made, i.e. the wrong Boolean expression
was chosen, because, why would we care if the model is within a certain confidence
interval if the data is not even within that interval?2 The probability of type II
error, i.e. that the null hypothesis was accepted when it is actually false, is equal
to ğ›½ğ‘€(ğ›¼) = 1 âˆ’
âˆ«ï¸€ğ‘ğ›¼
âˆ’ğ‘ğ›¼ğœŒ(^ğ‘§|ğ‘€) ğ‘‘^ğ‘§, which in the classical case is difficult to calculate
directly because one does not have access to the actual model pdf ğ‘(^ğ‘§|ğ‘€) in frequentist
probability.
2Independent of whether or not the null hypothesis is true.
89

Improved statistical hypothesis testing for validation.
For the validation
cases we are interested in, both ğœŒ(^ğ‘§|ğ‘€) and ğœŒ(ğ‘§|ğ·) are quantified, and therefore
assuming that ğœŒ(^ğ‘§|ğ‘€) â†’ğœŒ(^ğ‘§|ğ‘€= ğ·) would irresponsibly throw away any information
sent through the model. We therefore offer the improved statistical hypothesis test
for validation using the BVM, which uses both the model and data pdfs. We call this
BVM the statistical power BVM.
For the modified statistical hypothesis test, let the definition of agreement be a
compound Boolean expression that is true iff both âˆ’ğ‘ğ›¼â‰¤^ğ‘§â‰¤ğ‘ğ›¼, that the model
test statistic lies in the dataâ€™s confidence interval, and âˆ’ğ‘^ğ›¼â‰¤ğ‘§â‰¤ğ‘^ğ›¼that the data
statistic lies in the modelâ€™s confidence interval, which corresponds to the probability
âˆ«ï¸€ğ‘^ğ›¼
âˆ’ğ‘^ğ›¼ğœŒ(^ğ‘§|ğ‘€) ğ‘‘^ğ‘§= 1 âˆ’^ğ›¼of the model. By not assuming ğ‘€= ğ·, we remove the
possibility that either type I or type II errors can occur; however, systematic errors,
that the Boolean expression meant to define agreement is nonsensical, still exist. Thus,
while more or less adhering to the type of tests one might perform for model validation
using statistical hypothesis testing, we get,
ğ‘(ğ´|ğ‘€, ğ·)
=
âˆ«ï¸
^ğ‘§,ğ‘§
ğœŒ(^ğ‘§|ğ‘€, ğ·) Â· Î˜
(ï¸€
âˆ’ğ‘ğ›¼â‰¤^ğ‘§â‰¤ğ‘ğ›¼
)ï¸€
Â· Î˜
(ï¸€
âˆ’ğ‘^ğ›¼â‰¤ğ‘§â‰¤ğ‘^ğ›¼
)ï¸€
Â· ğœŒ(ğ‘§|ğ·) ğ‘‘^ğ‘§ğ‘‘ğ‘§
=
(ï¸€
1 âˆ’ğ›½ğ‘€(ğ›¼)
)ï¸€
Â·
(ï¸€
1 âˆ’ğ›½ğ·(^ğ›¼)
)ï¸€
,
(A.18)
which is the probability that both the model and the data lie within one anotherâ€™s
confidence intervals. The value 1 âˆ’ğ›½(ğ›¼) is called the statistical power of the test, but
here we have access to both the statistical power of the data and the model. The
probability the model and data do not agree as defined by ğµis given by,
ğ‘(ğ´|ğ‘€, ğ·) = 1 âˆ’ğ‘(ğ´|ğ‘€, ğ·) = ğ›½ğ·(^ğ›¼) + ğ›½ğ‘€(ğ›¼) âˆ’ğ›½ğ·(^ğ›¼)ğ›½ğ‘€(ğ›¼),
(A.19)
which occurs if either ^ğ‘§, ğ‘§, or both are outside of one anotherâ€™s confidence intervals.
The probability for systematic error (that ^ğ‘§, ğ‘§, or both are outside of their own
confidence intervals) is equal to ğ›¼+ ^ğ›¼âˆ’ğ›¼^ğ›¼; however, there is no conceptual issue
with setting ğ›¼, ^ğ›¼, or both equal to 0 as long as both distributions do not span the
90

entire range of possible values (as in such a case the model and data would always
agree, which means the test has zero resolving power). Setting ğ›¼= ^ğ›¼= 0 removes the
chance of systematic error from the analysis.
Overall, the use of confidence intervals is suboptimal unless both the model and
data pdfs are strictly unimodal. Therefore, rather than using a confidence interval,
one may use a â€œconfidence setâ€, which we define as the smallest set of ^ğ‘§(as well as
for ğ‘§) values whose probability adds to 1 âˆ’^ğ›¼(and similarly 1 âˆ’ğ›¼). Confidence sets
are generated by adding the largest probabilities of ^ğ‘§(ğ‘§) until a confidence level of
1 âˆ’^ğ›¼(1 âˆ’ğ›¼) is met. A confidence interval is only equal to the confidence set if the
distribution is unimodal. As the confidence set is the smallest set of values adding
up to the confidence level, this set of values is more informative than a confidence
interval, which may include many 0 or low probability events. Using a confidence set
improves the resolving power of the metric further.
The statistical power BVM (A.18) is more informative than the classical statistical
hypothesis test (A.17) because it utilizes the model pdf while also removing type I,
type II, and (optionally) systematic errors from the test; however its overall resolving
power is weak when compared to other metrics. By rewriting the pair of overlapping
confidence intervals (or sets) as the set of values in a single â€œoverlap intervalâ€ ğ¼=
[âˆ’ğ‘ğ›¼, ğ‘ğ›¼]âˆ©[âˆ’ğ‘^ğ›¼, ğ‘^ğ›¼], one may see that (A.18) is a particular case of (A.5) with ğ‘†(ğ‘¦) = ğ¼
for ğ‘¦âˆˆğ¼and being the null set otherwise. Thus, the statistical power BVM may be
seen as a special case of the generalized reliability metric suggested by the BVM in
(A.5) that effectively has large and unvarying tolerance intervals (sets). The use of
confidence intervals as well as confidence sets in defining agreement effectively coarse
grain the probabilities, which removes their informative features. The most stringent
definition of agreement between the model and the data leads to Bayesian model
testing, which we prove in the next section, as it is indeed equal to the generalized
model reliability metric with a zero tolerance for differences ğœ–= 0.
91

A.6
Bayesian Model Testing
In Bayesian model testing, rather than assuming a particular model is true, one lets
the available data determine which model is most likely given that data. Represented
probabilistically, out of a set of possible models, Bayesian model testing selects the
model with the maximum posterior probability ğ‘(ğ‘€|ğ‘Œ), i.e. the probability of a
(previously calibrated [52]) model ğ‘€given the data set ğ‘Œ= {ğ‘¦ğ‘–} from data source
ğ·. As the selection rule for models requires comparing values of ğ‘(ğ‘€|ğ‘Œ), one often
constructs the posterior odds ratio,
ğ‘…= ğ‘(ğ‘€|ğ‘Œ)
ğ‘(ğ‘€â€²|ğ‘Œ),
(A.20)
and selects the model ğ‘€with the highest value of ğ‘…relative to a chosen base model
ğ‘€â€². Using Bayesâ€™ Theorem, the posterior odds ratio may be recast as,
ğ‘…= ğ‘(ğ‘Œ|ğ‘€)ğ‘(ğ‘€)
ğ‘(ğ‘Œ|ğ‘€â€²)ğ‘(ğ‘€â€²) = ğ¾ğ‘(ğ‘€)
ğ‘(ğ‘€â€²),
(A.21)
where ğ¾â‰¡ğ‘(ğ‘Œ|ğ‘€)/ğ‘(ğ‘Œ|ğ‘€â€²) is known as the Bayes factor, which is the ratio of the
likelihoods of the models. The ratio of the prior model probabilities ğ‘(ğ‘€)/ğ‘(ğ‘€â€²) is
the ratio of the belief that model ğ‘€is true prior to examining the data, relative to ğ‘€â€².
If there is reason to believe that one model is more probable than another due to prior
(perhaps statistical) knowledge of the system under investigation, then the Bayesian
framework allows one to take this into account through the prior model probabilities.
As it is common for the ğ‘…values to be potentially many orders of magnitude greater
than one, the prior model probabilities may be overwhelmed by the Bayes factor. In
any case, if there is no reason to prefer one model over another, one can let the prior
model probabilities be equal a priori.
Given we are testing some model function ^ğ‘¦= ğ‘€(âƒ—ğ‘¥, âƒ—ğ›¼), we have access to the
forward propagation of data and parameters through a given model, the problem
of calculating ğ‘…may be rerouted to the computation of ğ¾. Using the potentially
multidimensional inputs to our models (âƒ—ğ‘¥, âƒ—ğ›¼), which represent the input data and
92

the model parameters respectively, the Bayes factor is calculated through forward
propagation (marginalization) of these inputs through both models,
ğ¾= ğ‘(ğ‘Œ|ğ‘€)
ğ‘(ğ‘Œ|ğ‘€â€²) =
âˆ«ï¸€
âƒ—ğ‘¥,âƒ—ğ›¼ğ‘(ğ‘Œ|âƒ—ğ‘¥, âƒ—ğ›¼, ğ‘€) Â· ğœŒ(âƒ—ğ‘¥, âƒ—ğ›¼|ğ‘€) ğ‘‘âƒ—ğ‘¥ğ‘‘âƒ—ğ›¼
âˆ«ï¸€
âƒ—ğ‘¥â€²,âƒ—ğ›¼â€² ğ‘(ğ‘Œ|âƒ—ğ‘¥â€², âƒ—ğ›¼â€², ğ‘€â€²) Â· ğœŒ(âƒ—ğ‘¥â€², âƒ—ğ›¼â€²|ğ‘€â€²) ğ‘‘âƒ—ğ‘¥â€² ğ‘‘âƒ—ğ›¼â€².
(A.22)
The prior probability of the inputs to the model ğœŒ(âƒ—ğ‘¥, âƒ—ğ›¼|ğ‘€) are the input probability
distributions used to propagate uncertainty through the model. The probability
ğ‘(ğ‘Œ|âƒ—ğ‘¥, âƒ—ğ›¼, ğ‘€) is the probability of the data given by the knowledge of the model function
^ğ‘¦= ğ‘€(âƒ—ğ‘¥, âƒ—ğ›¼); however, it should be noted that in general the data ğ‘Œ= {ğ‘¦ğ‘–} Ì¸= ^ğ‘Œ,
is not the set of model outputs ^ğ‘Œ, as the data ğ‘Œwas collected from the experiment
rather than from model outputs. Thus, one must impose the assumptions under which
a model is built, i.e. it is built for the purpose of approximating ğ‘¦ğ‘–â‰ˆğ‘€(ğ‘¥ğ‘–, âƒ—ğ›¼), as we
will see later. Thus, a more verbose representation of ğ¾is,
ğ¾= ğ‘( ^ğ‘Œ|ğ‘€)
ğ‘( ^ğ‘Œ|ğ‘€â€²)
= ğœŒ( ^ğ‘Œ|ğ‘€)
ğœŒ( ^ğ‘Œ|ğ‘€â€²)
=
âˆ«ï¸€
âƒ—ğ‘¥,âƒ—ğ›¼ğœŒ( ^ğ‘Œ= ğ‘Œ|âƒ—ğ‘¥, âƒ—ğ›¼, ğ‘€) Â· ğœŒ(âƒ—ğ‘¥, âƒ—ğ›¼|ğ‘€) ğ‘‘âƒ—ğ‘¥ğ‘‘âƒ—ğ›¼
âˆ«ï¸€
âƒ—ğ‘¥â€²,âƒ—ğ›¼â€² ğœŒ( ^ğ‘Œ= ğ‘Œ|âƒ—ğ‘¥â€², âƒ—ğ›¼â€², ğ‘€â€²) Â· ğœŒ(âƒ—ğ‘¥â€², âƒ—ğ›¼â€²|ğ‘€â€²) ğ‘‘âƒ—ğ‘¥â€² ğ‘‘âƒ—ğ›¼â€² ,
(A.23)
where ğ‘(^ğ‘Œ|ğ‘€) is understood to be the sum of the model and the data probabilities
that jointly output the same values, i.e. the probability that any of the possible model
and data values turn out to be the same. The form of ğœŒ(^ğ‘Œ= ğ‘Œ|âƒ—ğ‘¥, âƒ—ğ›¼, ğ‘€) is usually
assumed to be something that works (and even better if it is also simple) [45], like the
product of Gaussian distributions,
ğœŒ(^ğ‘Œ= ğ‘Œ|âƒ—ğ‘¥, âƒ—ğ›¼, ğ‘€) = 1
ğ‘exp
(ï¸‚
âˆ’
1
2ğœ2
âˆ‘ï¸
ğ‘–
(ï¸€
ğ‘€(ğ‘¥ğ‘–; âƒ—ğ›¼) âˆ’ğ‘¦ğ‘–
)ï¸€2
)ï¸‚
,
(A.24)
where ğœ2 is interpreted as the measurement uncertainty of the data.3 One usually
computes the integrals in ğ¾using various sampling algorithms such as nested sampling
[10, 53] or another Markov Chain Monte Carlo technique. As an added bonus, Bayesian
model testing has an inbuilt Occamâ€™s razor mechanism which penalizes needlessly
complex models, i.e. ones that would overfit the data by using a large number of
uncertain model parameters âƒ—ğ›¼. A clear explanation may be found in [5].
3The dependence on the data set/experiment ğ·is therefore implied.
93

We can represent Bayesian model testing using the Bayesian Validation Metric.
Let the model comparison value ^ğ‘§be ^ğ‘Œ= (^ğ‘¦1, . . . , ^ğ‘¦ğ‘›) that in principle corresponds to
ğ‘§= ğ‘Œ= (ğ‘¦1, . . . , ğ‘¦ğ‘›), a validation set of data. The Boolean expression ğµis considered
to factor into a set of â€œandâ€ statements over the individual model output and data
points ğµ(^ğ‘Œ, ğ‘Œ) = ğµ(^ğ‘¦1, ğ‘¦1) âˆ§. . . âˆ§ğµ(^ğ‘¦ğ‘›, ğ‘¦ğ‘›), where each ğµis true iff ^ğ‘¦ğ‘–= ğ‘¦ğ‘–exactly.
The Bayesian Validation Metric in this case is then,
ğ‘(ğ´|ğ‘€, ğ·)
=
âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğœŒ(^ğ‘Œ|ğ‘€, ğ·) Â· Î˜
(ï¸€
ğµ(^ğ‘Œ, ğ‘Œ)
)ï¸€
Â· ğœŒ(ğ‘Œ|ğ·) ğ‘‘^ğ‘Œğ‘‘ğ‘Œ
=
âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğœŒ(^ğ‘Œ|ğ‘€, ğ·) Â· ğ›¿^ğ‘Œ,ğ‘ŒÂ· ğœŒ(ğ‘Œ|ğ·) ğ‘‘^ğ‘Œğ‘‘ğ‘Œ.
(A.25)
In general, computational models may be described by a model function ^ğ‘Œ= ğ‘€(âƒ—ğ‘¥, âƒ—ğ›¼),
and given the model pdf was constructed through forward propagation of the uncer-
tainties ğœŒ(âƒ—ğ‘¥, âƒ—ğ›¼), the model output pdf is
ğœŒ(^ğ‘Œ|ğ‘€, ğ·) =
âˆ«ï¸
âƒ—ğ‘¥,âƒ—ğ›¼
ğœŒ(^ğ‘Œ|âƒ—ğ‘¥, âƒ—ğ›¼, ğ‘€, ğ·) Â· ğœŒ(âƒ—ğ‘¥, âƒ—ğ›¼) ğ‘‘âƒ—ğ‘¥ğ‘‘âƒ—ğ›¼.
(A.26)
Substituting (A.26) into (A.25), using the trick (2.11) and (2.12) â€“ that
âˆ«ï¸ğ‘Œ+ğœ–
ğ‘Œâˆ’ğœ–
ğœŒ(^ğ‘Œ|ğ‘€, ğ·) ğ‘‘^ğ‘Œ
ğœ–â†’0+
âˆ’â†’ğ‘(^ğ‘Œ= ğ‘Œ|ğ‘€, ğ·) = ğœŒ(^ğ‘Œ= ğ‘Œ|ğ‘€, ğ·) ğ‘‘^ğ‘Œ,
and integrating over ğ‘Œ, one finds,
ğ‘(ğ´|ğ‘€, ğ·)
=
âˆ«ï¸
âƒ—ğ‘¥,âƒ—ğ›¼,ğ‘Œ
ğ‘(^ğ‘Œ= ğ‘Œ|âƒ—ğ‘¥, âƒ—ğ›¼, ğ‘€, ğ·) Â· ğœŒ(âƒ—ğ‘¥, âƒ—ğ›¼) Â· ğœŒ(ğ‘Œ|ğ·) ğ‘‘âƒ—ğ‘¥ğ‘‘âƒ—ğ›¼ğ‘‘ğ‘Œ
=
âˆ«ï¸
âƒ—ğ‘¥,âƒ—ğ›¼
ğ‘(^ğ‘Œ|âƒ—ğ‘¥, âƒ—ğ›¼, ğ‘€, ğ·) Â· ğœŒ(âƒ—ğ‘¥, âƒ—ğ›¼) ğ‘‘âƒ—ğ‘¥ğ‘‘âƒ—ğ›¼
=
(ï¸‚âˆ«ï¸
âƒ—ğ‘¥,âƒ—ğ›¼
ğœŒ(^ğ‘Œ|âƒ—ğ‘¥, âƒ—ğ›¼, ğ‘€, ğ·) Â· ğœŒ(âƒ—ğ‘¥, âƒ—ğ›¼) ğ‘‘âƒ—ğ‘¥ğ‘‘âƒ—ğ›¼
)ï¸‚
ğ‘‘^ğ‘Œ
=
ğœŒ
(ï¸€^ğ‘Œâ‰¡ğ‘Œ
âƒ’âƒ’ğ‘€, ğ·
)ï¸€
ğ‘‘^ğ‘Œ,
(A.27)
which is what is meant by, and is equal to, the probability in the numerator of the
94

Bayes factor (A.23),
ğ‘(ğ´|ğ‘€, ğ·) = ğœŒ
(ï¸€^ğ‘Œâ‰¡ğ‘Œ
âƒ’âƒ’ğ‘€, ğ·
)ï¸€
ğ‘‘^ğ‘Œâ‰¡ğ‘
(ï¸€^ğ‘Œâ‰¡ğ‘Œ
âƒ’âƒ’ğ‘€
)ï¸€
.
(A.28)
That is, we have shown that Bayesian model testing is a special case of the generalized
model reliability metric in the case of exact agreement (A.5), i.e. ğœ–= 0, as can be
seen by investigating (A.25).
Thus, a generalization of Bayesian model testing is to let the definition of agreement
have a tolerance ğœ–> 0 such that the Bayes factor becomes,
ğ¾= ğ‘(ğ´|ğ‘€, ğ·)
ğ‘(ğ´|ğ‘€â€², ğ·)
âˆ’â†’ğ¾(ğœ–) = ğ‘(ğ´|ğ‘€, ğ·, ğœ–)
ğ‘(ğ´|ğ‘€â€², ğ·, ğœ–),
(A.29)
where ğ‘(ğ´|ğ‘€, ğ·, ğœ–) is Equation (A.2). This derivation suggests that the BVM can
be used analogously to Bayesian model testing, except with arbitrary definitions of
agreement ğœ–â†’ğµ, that is, we may construct the BVM factor,
ğ¾(ğµ) = ğ‘(ğ´|ğ‘€, ğ·, ğµ)
ğ‘(ğ´|ğ‘€â€², ğ·, ğµ).
(A.30)
Using Bayesâ€™ Theorem, ğ‘(ğ‘€|ğ´, ğ·, ğµ) = ğ‘(ğ´|ğ‘€, ğ·, ğµ)ğ‘(ğ‘€|ğ·, ğµ)/ğ‘(ğ´|ğ·, ğµ), we may
further construct the BVM ratio,
ğ‘…(ğµ) = ğ‘(ğ‘€|ğ´, ğ·, ğµ)
ğ‘(ğ‘€â€²|ğ´, ğ·, ğµ) = ğ‘(ğ´|ğ‘€, ğ·, ğµ) ğ‘(ğ‘€|ğ·, ğµ)
ğ‘(ğ´|ğ‘€â€², ğ·, ğµ) ğ‘(ğ‘€â€²|ğ·, ğµ) = ğ¾(ğµ) ğ‘(ğ‘€|ğ·, ğµ)
ğ‘(ğ‘€â€²|ğ·, ğµ),
(A.31)
for the purpose of model testing under a general definition of agreement ğµ, i.e. we
can do model selection under any definition of agreement with the BVM ratio. The
ratio ğ‘(ğ‘€|ğ·, ğµ)/ğ‘(ğ‘€â€²|ğ·, ğµ) is the ratio of prior probabilities of ğ‘€and ğ‘€â€². Again,
if there is no reason to suspect that one model is a priori more probable than another,
one may let ğ‘(ğ‘€|ğ·, ğµ)/ğ‘(ğ‘€â€²|ğ·, ğµ) = 1, and then ğ‘…(ğµ) â†’ğ¾(ğµ). With the BVM
ratio, one could in principle compare data and models with different data types to
perform model testing or selection.
95

96

Appendix B
Likelihood-Based Methods
Likelihood-based methods for calibration and model learning use the likelihood func-
tion â„’(âƒ—ğ›¼) to learn model parameters. The most common likelihood-based method
is the max likelihood method, that, due to the monotonicity of the log function is cast as
âƒ—ğ›¼* = arg max
âƒ—ğ›¼
(ï¸
âˆ’log â„’(âƒ—ğ›¼)
)ï¸
.
(B.1)
Although the approach is rather general, in practice one considers likelihood functions
generated from stochastic model function
^ğ‘¦ğ‘–= ğ‘€(ğ‘¥ğ‘–; âƒ—ğ›¼) = ğ‘€(ğ‘¥ğ‘–; ğ›¼1, . . . , ğ›¼ğ‘š) + ğ›¼0,
(B.2)
where ğ‘€(ğ‘¥ğ‘–; ğ›¼1, . . . , ğ›¼ğ‘š) is a deterministic model function, ğ›¼0 is drawn from ğ›¼0 âˆ¼
ğ’©(0, ğœ2
ğ›¼0), and ğœğ›¼0 âˆˆâƒ—ğ›¼â†(ğœğ›¼0, ğ›¼1, . . . , ğ›¼ğ‘š) may be treated as a learnable parameter.
The likelihood of this data given the model (is the true underlying model) is then a
product of Gaussians,
â„’(âƒ—ğ›¼) = ğœŒ(ğ·|âƒ—ğ›¼, ğ‘€) =
ğ‘›
âˆï¸
ğ‘–=1
ğ’©
(ï¸€
ğ‘€(ğ‘¥ğ‘–; ğ›¼1, . . . , ğ›¼ğ‘š), ğœ2
ğ›¼0
)ï¸€
,
(B.3)
which implicitly involves setting the certain data, ğ‘Œ= ğ·, equal to the model output
exactly, ^ğ‘Œ= ğ‘Œ, as the true probability described by (B.2) is the model output
drawn from the model ^ğ‘¦ğ‘–âˆ¼ğ’©
(ï¸€
ğ‘€(ğ‘¥ğ‘–; ğ›¼1, ..., ğ›¼ğ‘š), ğœ2
ğ›¼0
)ï¸€
. If the observed data ğ·has
measurement or other types of uncertainty, nothing prevents this uncertainty from
being built further into â„’(âƒ—ğ›¼).
97

98

Appendix C
Bayesian Model Testing
We derive Equations (3.4) â€“ (3.6) mentioned in Section 3.2.3. In the Bayesian model
testing framework, the model output and the observed data are defined to agree
only if their values are exactly equal. Thus, Bayesian model testing is a special case
of the BVM where the agreement kernel is equal to the kronecker delta function
(exact agreement) with continuous indices, i.e. Î˜
(ï¸€
ğµ(^ğ‘Œ, ğ‘Œ)
)ï¸€
= ğ›¿^ğ‘Œ,ğ‘Œ= âˆï¸€ğ‘›
ğ‘–=1 ğ›¿^ğ‘¦ğ‘–,ğ‘¦ğ‘–.
Since Bayesian model testing deals with probability densities, we have the following
expression for the probability density of agreement (3.7):
ğœŒ(ğ´|ğ‘€, ğ·) = ğ‘(ğ´|ğ‘€, ğ·)
ğ‘‘ğ´
= 1
ğ‘‘ğ´
âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğœŒ(^ğ‘Œ|ğ‘€, ğ·) Â· Î˜
(ï¸€
ğµ(^ğ‘Œ, ğ‘Œ)
)ï¸€
Â· ğœŒ(ğ‘Œ|ğ·)ğ‘‘^ğ‘Œğ‘‘ğ‘Œ
=
âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğœŒ(^ğ‘Œ|ğ‘€, ğ·) Â·
ğ›¿^ğ‘Œ,ğ‘Œ
ğ‘‘ğ´Â· ğœŒ(ğ‘Œ|ğ·)ğ‘‘^ğ‘Œğ‘‘ğ‘Œ.
The kronecker delta ğ›¿^ğ‘Œ,ğ‘Œand the dirac delta ğ›¿(^ğ‘Œâˆ’ğ‘Œ) functions are related as follows:
ğ›¿^ğ‘Œ,ğ‘Œ
ğ‘‘ğ´= ğ›¿(^ğ‘Œâˆ’ğ‘Œ) =
ğ‘›
âˆï¸
ğ‘–=1
ğ›¿(^ğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–).
99

Thus, the probability density of agreement becomes,
ğœŒ(ğ´|ğ‘€, ğ·) =
âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğœŒ(^ğ‘Œ|ğ‘€, ğ·) Â· ğ›¿(^ğ‘Œâˆ’ğ‘Œ) Â· ğœŒ(ğ‘Œ|ğ·)ğ‘‘^ğ‘Œğ‘‘ğ‘Œ
=
âˆ«ï¸
^ğ‘Œ,ğ‘Œ
(ï¸‚âˆ«ï¸
âƒ—ğ›¼
ğœŒ(^ğ‘Œ|âƒ—ğ›¼, ğ‘€)ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
)ï¸‚
Â· ğ›¿(^ğ‘Œâˆ’ğ‘Œ) Â· ğœŒ(ğ‘Œ|ğ·)ğ‘‘^ğ‘Œğ‘‘ğ‘Œ
=
âˆ«ï¸
âƒ—ğ›¼
(ï¸‚âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğœŒ(^ğ‘Œ|âƒ—ğ›¼, ğ‘€) Â· ğ›¿(^ğ‘Œâˆ’ğ‘Œ) Â· ğœŒ(ğ‘Œ|ğ·)ğ‘‘^ğ‘Œğ‘‘ğ‘Œ
)ï¸‚
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
=
âˆ«ï¸
âƒ—ğ›¼
(ï¸‚âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğ›¿
(ï¸€^ğ‘Œâˆ’ğ‘€(ğ‘‹; âƒ—ğ›¼)
)ï¸€
âŸ
 â
 
^ğ‘Œ= ğ‘€(ğ‘‹; âƒ—ğ›¼)
Â· ğ›¿(^ğ‘Œâˆ’ğ‘Œ) Â· ğœŒ(ğ‘Œ|ğ·)ğ‘‘^ğ‘Œğ‘‘ğ‘Œ
)ï¸‚
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
=
âˆ«ï¸
âƒ—ğ›¼
(ï¸‚âˆ«ï¸
ğ‘Œ
ğ›¿
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼) âˆ’ğ‘Œ
)ï¸€
Â· ğœŒ(ğ‘Œ|ğ·)ğ‘‘ğ‘Œ
)ï¸‚
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼.
(C.1)
C.1
Normally Distributed Data
If we assume the data to be normally distributed, i.e. ğ‘Œâˆ¼ğ’©(ğ·, Î”), we get,
ğœŒ(ğ‘Œ|ğ·) =
1
âˆšï¸€
(2ğœ‹)ğ‘›|Î”|
ğ‘’âˆ’1
2(ğ‘Œâˆ’ğ·)ğ‘‡Î”âˆ’1(ğ‘Œâˆ’ğ·),
where ğ‘›is the dimension of the training data set, Î” is the covariance matrix, and ğ·
is the observed data values.
Therefore, using (C.1), we have,
ğœŒ(ğ´|ğ‘€, ğ·) =
âˆ«ï¸
âƒ—ğ›¼
(ï¸‚âˆ«ï¸
ğ‘Œ
ğ›¿
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼) âˆ’ğ‘Œ
)ï¸€
Â·
1
âˆšï¸€
(2ğœ‹)ğ‘›|Î”|
ğ‘’âˆ’1
2(ğ‘Œâˆ’ğ·)ğ‘‡Î”âˆ’1(ğ‘Œâˆ’ğ·)ğ‘‘ğ‘Œ
)ï¸‚
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼,
=
âˆ«ï¸
âƒ—ğ›¼
1
âˆšï¸€
(2ğœ‹)ğ‘›|Î”|
ğ‘’âˆ’1
2
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼) âˆ’ğ·
)ï¸€ğ‘‡Î”âˆ’1(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼) âˆ’ğ·
)ï¸€
âŸ
 â
 
â„’(âƒ—ğ›¼)
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
âŸ
 â
 
ğœ‹(âƒ—ğ›¼)ğ‘‘âƒ—ğ›¼
.
Therefore, the likelihood function to be used in the MCMC algorithm is
â„’(âƒ—ğ›¼) =
1
âˆšï¸€
(2ğœ‹)ğ‘›|Î”|
ğ‘’âˆ’1
2
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼) âˆ’ğ·
)ï¸€ğ‘‡Î”âˆ’1(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼) âˆ’ğ·
)ï¸€
,
which is Equation (3.4) presented in Section 3.2.3.
100

C.2
Uniformly Distributed Data
We first note that
ğ‘‘ğ‘Œâ‰¡ğ‘‘ğ‘›ğ‘Œâ‰¡
ğ‘›
âˆï¸
ğ‘—=1
ğ‘‘ğ‘¦ğ‘—,
ğ‘—= 1, . . . , ğ‘›.
(C.2)
Now, we assume the data to be uniformly distributed, i.e.
ğ‘¦ğ‘—âˆ¼ğ’°(ğ‘ğ‘—, ğ‘ğ‘—),
ğ‘—= 1, . . . , ğ‘›.
Then, the probability density ğœŒ(ğ‘Œ|ğ·) becomes:
ğœŒ(ğ‘Œ|ğ·) =
ğ‘›
âˆï¸
ğ‘—=1
ğœŒ(ğ‘¦ğ‘—|ğ·) =
ğ‘›
âˆï¸
ğ‘—=1
Î˜
(ï¸€
ğ‘ğ‘—â‰¤ğ‘¦ğ‘—â‰¤ğ‘ğ‘—
)ï¸€
ğ‘ğ‘—âˆ’ğ‘ğ‘—
.
(C.3)
Notice that we can generalize ğœŒ(ğ‘¦ğ‘—|ğ·) =
ğ‘›
âˆï¸
ğ‘—=1
Î˜
(ï¸€
ğ‘ğ‘—â‰¤ğ‘¦ğ‘—â‰¤ğ‘ğ‘—
)ï¸€
ğœŒ(ğ‘¦ğ‘—|ğ·) to any bounded
probability density function (pdf). Therefore, using (C.1), we have,
ğœŒ(ğ´|ğ‘€, ğ·) =
âˆ«ï¸
âƒ—ğ›¼
(ï¸ƒ
ğ‘›
âˆï¸
ğ‘—=1
âˆ«ï¸
ğ‘¦ğ‘—
ğ›¿
(ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) âˆ’ğ‘¦ğ‘—
)ï¸
Â· Î˜
(ï¸€
ğ‘ğ‘—â‰¤ğ‘¦ğ‘—â‰¤ğ‘ğ‘—
)ï¸€
ğ‘ğ‘—âˆ’ğ‘ğ‘—
ğ‘‘ğ‘¦ğ‘—
)ï¸ƒ
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼,
=
âˆ«ï¸
âƒ—ğ›¼
(ï¸ƒ
ğ‘›
âˆï¸
ğ‘—=1
Î˜
(ï¸€
ğ‘ğ‘—â‰¤ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) â‰¤ğ‘ğ‘—
)ï¸€
ğ‘ğ‘—âˆ’ğ‘ğ‘—
)ï¸ƒ
âŸ
 â
 
â„’(âƒ—ğ›¼)
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
âŸ
 â
 
ğœ‹(âƒ—ğ›¼)ğ‘‘âƒ—ğ›¼
.
Therefore, the likelihood function to be used in the MCMC algorithm is
â„’(âƒ—ğ›¼) =
ğ‘›
âˆï¸
ğ‘—=1
Î˜
(ï¸€
ğ‘ğ‘—â‰¤ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) â‰¤ğ‘ğ‘—
)ï¸€
ğ‘ğ‘—âˆ’ğ‘ğ‘—
,
which is Equation (3.5) presented in Section 3.2.3.
101

C.3
Completely Certain Data
If we consider the data to be completely certain, deterministic, i.e. ğ‘Œ= ğ·, then, the
probability density ğœŒ(ğ‘Œ|ğ·) becomes ğœŒ(ğ‘Œ|ğ·) = ğ›¿(ğ‘Œâˆ’ğ·), and thus, using (C.1), we
have,
ğœŒ(ğ´|ğ‘€, ğ·) =
âˆ«ï¸
âƒ—ğ›¼
(ï¸‚âˆ«ï¸
ğ‘Œ
ğ›¿
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼) âˆ’ğ‘Œ
)ï¸€
Â· ğ›¿(ğ‘Œâˆ’ğ·)ğ‘‘ğ‘Œ
)ï¸‚
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
=
âˆ«ï¸
âƒ—ğ›¼
ğ›¿
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼) âˆ’ğ·
)ï¸€
âŸ
 â
 
â„’(âƒ—ğ›¼)
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
âŸ
 â
 
ğœ‹(âƒ—ğ›¼)ğ‘‘âƒ—ğ›¼
.
Therefore, the likelihood function to be used in the MCMC algorithm is
â„’(âƒ—ğ›¼) = ğ›¿
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼) âˆ’ğ·
)ï¸€
,
which is Equation (3.6) presented in Section 3.2.3.
102

Appendix D
BVM Model Selection
We derive Equations (3.15) â€“ (3.17) presented in Section 3.3. We show how we can
apply Bayesian model selection on any data distribution using the BVM probability
of agreement. Starting from the original definition of probability of agreement (3.7),
we have,
ğ‘(ğ´|ğ‘€, ğ·, ğµ) =
âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğœŒ( ^ğ‘Œ|ğ‘€, ğ·) Â· Î˜
(ï¸€
ğµ( ^ğ‘Œ, ğ‘Œ)
)ï¸€
Â· ğœŒ(ğ‘Œ|ğ·)ğ‘‘^ğ‘Œğ‘‘ğ‘Œ
=
âˆ«ï¸
^ğ‘Œ,ğ‘Œ
(ï¸‚âˆ«ï¸
âƒ—ğ›¼
ğœŒ( ^ğ‘Œ|âƒ—ğ›¼, ğ‘€)ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
)ï¸‚
Â· Î˜
(ï¸€
ğµ( ^ğ‘Œ, ğ‘Œ)
)ï¸€
Â· ğœŒ(ğ‘Œ|ğ·)ğ‘‘^ğ‘Œğ‘‘ğ‘Œ
=
âˆ«ï¸
âƒ—ğ›¼
(ï¸‚âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğœŒ( ^ğ‘Œ|âƒ—ğ›¼, ğ‘€) Â· Î˜
(ï¸€
ğµ( ^ğ‘Œ, ğ‘Œ)
)ï¸€
Â· ğœŒ(ğ‘Œ|ğ·)ğ‘‘^ğ‘Œğ‘‘ğ‘Œ
)ï¸‚
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
=
âˆ«ï¸
âƒ—ğ›¼
(ï¸‚âˆ«ï¸
^ğ‘Œ,ğ‘Œ
ğ›¿
(ï¸€^ğ‘Œâˆ’ğ‘€(ğ‘‹; âƒ—ğ›¼)
)ï¸€
Â· Î˜
(ï¸€
ğµ( ^ğ‘Œ, ğ‘Œ)
)ï¸€
Â· ğœŒ(ğ‘Œ|ğ·)ğ‘‘^ğ‘Œğ‘‘ğ‘Œ
)ï¸‚
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
=
âˆ«ï¸
âƒ—ğ›¼
(ï¸‚âˆ«ï¸
ğ‘Œ
Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼), ğ‘Œ
)ï¸€)ï¸
Â· ğœŒ(ğ‘Œ|ğ·)ğ‘‘ğ‘Œ
)ï¸‚
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼,
which is Equation (3.15) derived in Section 3.3. From (C.2), we know that
ğ‘‘ğ‘Œâ‰¡ğ‘‘ğ‘›ğ‘Œâ‰¡
ğ‘›
âˆï¸
ğ‘—=1
ğ‘‘ğ‘¦ğ‘—,
ğ‘—= 1, . . . , ğ‘›.
The probability density ğœŒ(ğ‘Œ|ğ·) can be expressed as:
ğœŒ(ğ‘Œ|ğ·) =
ğ‘›
âˆï¸
ğ‘—=1
ğœŒ(ğ‘¦ğ‘—|ğ·).
103

We also note that the compound Boolean under question can be expressed as:
Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼), ğ‘Œ
)ï¸€)ï¸
=
ğ‘›
âˆï¸
ğ‘—=1
Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼), ğ‘¦ğ‘—
)ï¸€)ï¸
ğ‘—= 1, . . . , ğ‘›.
Thus, we rewrite the BVM probability of agreement as follows:
ğ‘(ğ´|ğ‘€, ğ·, ğµ) =
âˆ«ï¸
âƒ—ğ›¼
(ï¸ƒ
ğ‘›
âˆï¸
ğ‘—=1
âˆ«ï¸
ğ‘¦ğ‘—
Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼), ğ‘¦ğ‘—
)ï¸€)ï¸
Â· ğœŒ(ğ‘¦ğ‘—|ğ·) ğ‘‘ğ‘¦ğ‘—
)ï¸ƒ
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼.
We will use the ğœ–âˆ’Boolean indicator function defined as:
Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼), ğ‘¦ğ‘—
)ï¸€)ï¸
=
â§
âª
â¨
âª
â©
1,
if
âƒ’âƒ’ğ‘¦ğ‘—âˆ’ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼)
âƒ’âƒ’â‰¤ğœ–
0,
otherwise
where ğ‘—= 1, . . . , ğ‘›.
Then, the indicator function can be rewritten as:
Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼), ğ‘¦ğ‘—
)ï¸€)ï¸
= Î˜
(ï¸âƒ’âƒ’ğ‘¦ğ‘—âˆ’ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼)
âƒ’âƒ’â‰¤ğœ–
)ï¸
= Î˜
(ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) âˆ’ğœ–â‰¤ğ‘¦ğ‘—â‰¤ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) + ğœ–
)ï¸
,
where ğ‘—= 1, . . . , ğ‘›. Therefore, the BVM probability of agreement can be expressed as:
ğ‘(ğ´|ğ‘€, ğ·, ğµ) =
âˆ«ï¸
âƒ—ğ›¼
(ï¸ƒ
ğ‘›
âˆï¸
ğ‘—=1
âˆ«ï¸
ğ‘¦ğ‘—
Î˜
(ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) âˆ’ğœ–â‰¤ğ‘¦ğ‘—â‰¤ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) + ğœ–
)ï¸
Â· ğœŒ(ğ‘¦ğ‘—|ğ·) ğ‘‘ğ‘¦ğ‘—
)ï¸ƒ
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼.
(D.1)
D.1
Normally Distributed Data
Note that the Boolean Î˜
(ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) âˆ’ğœ–â‰¤ğ‘¦ğ‘—â‰¤ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) + ğœ–
)ï¸
is equal to 1 only when
ğ‘¦ğ‘—belongs to the interval
[ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) âˆ’ğœ–, ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) + ğœ–
]ï¸
.
Thus, the BVM probability of agreement becomes:
ğ‘(ğ´|ğ‘€, ğ·, ğµ) =
âˆ«ï¸
âƒ—ğ›¼
(ï¸ƒ
ğ‘›
âˆï¸
ğ‘—=1
âˆ«ï¸
ğ‘€(ğ‘¥ğ‘—;âƒ—ğ›¼)+ğœ–
ğ‘€(ğ‘¥ğ‘—;âƒ—ğ›¼)âˆ’ğœ–
ğœŒ(ğ‘¦ğ‘—|ğ·) ğ‘‘ğ‘¦ğ‘—
)ï¸ƒ
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼.
104

Now, we assume that the data is normally distributed, i.e.
ğ‘¦ğ‘—âˆ¼ğ’©(ğ·ğ‘—, ğœ2
ğ‘—),
ğ‘—= 1, . . . , ğ‘›.
Then, the probability density ğœŒ(ğ‘Œ|ğ·) becomes:
ğœŒ(ğ‘Œ|ğ·) =
ğ‘›
âˆï¸
ğ‘—=1
ğœŒ(ğ‘¦ğ‘—|ğ·) =
ğ‘›
âˆï¸
ğ‘—=1
1
âˆš
2ğœ‹ğœğ‘—
e
âˆ’1
2
(ï¸
ğ‘¦ğ‘—âˆ’ğ·ğ‘—
ğœğ‘—
)ï¸2
.
Thus, we rewrite the BVM probability of agreement as follows:
ğ‘(ğ´|ğ‘€, ğ·, ğµ) =
âˆ«ï¸
âƒ—ğ›¼
(ï¸ƒ
ğ‘›
âˆï¸
ğ‘—=1
âˆ«ï¸
ğ‘€(ğ‘¥ğ‘—;âƒ—ğ›¼)+ğœ–
ğ‘€(ğ‘¥ğ‘—;âƒ—ğ›¼)âˆ’ğœ–
ğœŒ(ğ‘¦ğ‘—|ğ·) ğ‘‘ğ‘¦ğ‘—
)ï¸ƒ
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
=
âˆ«ï¸
âƒ—ğ›¼
(ï¸ƒ
ğ‘›
âˆï¸
ğ‘—=1
âˆ«ï¸
ğ‘€(ğ‘¥ğ‘—;âƒ—ğ›¼)+ğœ–
ğ‘€(ğ‘¥ğ‘—;âƒ—ğ›¼)âˆ’ğœ–
1
âˆš
2ğœ‹ğœğ‘—
e
âˆ’1
2
(ï¸ğ‘¦ğ‘—âˆ’ğ·ğ‘—
ğœğ‘—
)ï¸2
ğ‘‘ğ‘¦ğ‘—
)ï¸ƒ
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
=
âˆ«ï¸
âƒ—ğ›¼
ğ‘›
âˆï¸
ğ‘—=1
(ï¸ƒ
ğ¹
(ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) + ğœ–
)ï¸
âˆ’ğ¹
(ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) âˆ’ğœ–
)ï¸)ï¸ƒ
âŸ
 â
 
â„’(âƒ—ğ›¼, ğµ)
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
âŸ
 â
 
ğœ‹(âƒ—ğ›¼)ğ‘‘âƒ—ğ›¼
,
where ğ¹(ğ‘¥) is the cumulative distribution function (cdf) expressed as:
ğ¹(ğ‘¥) = Î¦
(ï¸‚ğ‘¥âˆ’ğ·
ğœ
)ï¸‚
,
where Î¦(Â·) is the cumulative distribution function of the standard normal distribution,
i.e. ğ’©(0, 1), and expressed as:
Î¦(ğ‘¥) =
1
âˆš
2ğœ‹
âˆ«ï¸ğ‘¥
âˆ’âˆ
eâˆ’ğ‘¡2
2 ğ‘‘ğ‘¡.
Therefore, the likelihood function to be used in the MCMC algorithm is
â„’(âƒ—ğ›¼, ğµ) =
ğ‘›
âˆï¸
ğ‘—=1
(ï¸ƒ
ğ¹
(ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) + ğœ–
)ï¸
âˆ’ğ¹
(ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) âˆ’ğœ–
)ï¸)ï¸ƒ
.
105

D.2
Uniformly Distributed Data
If we assume the data to be uniformly distributed (C.3), then the BVM probability of
agreement (D.1) becomes:
ğ‘(ğ´|ğ‘€, ğ·, ğµ) =
âˆ«ï¸
âƒ—ğ›¼
(ï¸ƒ
ğ‘›
âˆï¸
ğ‘—=1
âˆ«ï¸
ğ‘¦ğ‘—
Î˜
(ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) âˆ’ğœ–â‰¤ğ‘¦ğ‘—â‰¤ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) + ğœ–
)ï¸
Â· Î˜
(ï¸€
ğ‘ğ‘—â‰¤ğ‘¦ğ‘—â‰¤ğ‘ğ‘—
)ï¸€
ğ‘ğ‘—âˆ’ğ‘ğ‘—
ğ‘‘ğ‘¦ğ‘—
)ï¸ƒ
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼.
Note that the product Î˜
(ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) âˆ’ğœ–â‰¤ğ‘¦ğ‘—â‰¤ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) + ğœ–
)ï¸
Â· Î˜
(ï¸
ğ‘ğ‘—â‰¤ğ‘¦ğ‘—â‰¤ğ‘ğ‘—
)ï¸
is
equal to 1 only when ğ‘¦ğ‘—belongs to both intervals
[ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) âˆ’ğœ–, ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) + ğœ–
]ï¸
and
[ï¸
ğ‘ğ‘—, ğ‘ğ‘—
]ï¸
.
Let ğ‘™ğ‘—and ğ‘¢ğ‘—be such that
[ï¸
ğ‘™ğ‘—, ğ‘¢ğ‘—
]ï¸
=
[ï¸
ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) âˆ’ğœ–, ğ‘€(ğ‘¥ğ‘—; âƒ—ğ›¼) + ğœ–
]ï¸
âˆ©
[ï¸
ğ‘ğ‘—, ğ‘ğ‘—
]ï¸
ğ‘—= 1, . . . , ğ‘›
Thus, the BVM probability of agreement becomes:
ğ‘(ğ´|ğ‘€, ğ·, ğµ) =
âˆ«ï¸
âƒ—ğ›¼
(ï¸ƒ
ğ‘›
âˆï¸
ğ‘—=1
âˆ«ï¸
ğ‘¦ğ‘—
Î˜
(ï¸€
ğ‘™ğ‘—â‰¤ğ‘¦ğ‘—â‰¤ğ‘¢ğ‘—
)ï¸€
ğ‘ğ‘—âˆ’ğ‘ğ‘—
ğ‘‘ğ‘¦ğ‘—
)ï¸ƒ
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
=
âˆ«ï¸
âƒ—ğ›¼
(ï¸ƒ
ğ‘›
âˆï¸
ğ‘—=1
âˆ«ï¸
ğ‘¢ğ‘—
ğ‘™ğ‘—
1
ğ‘ğ‘—âˆ’ğ‘ğ‘—
ğ‘‘ğ‘¦ğ‘—
)ï¸ƒ
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
=
âˆ«ï¸
âƒ—ğ›¼
(ï¸ƒ
ğ‘›
âˆï¸
ğ‘—=1
ğ‘¢ğ‘—âˆ’ğ‘™ğ‘—
ğ‘ğ‘—âˆ’ğ‘ğ‘—
)ï¸ƒ
âŸ
 â
 
â„’(âƒ—ğ›¼, ğµ)
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
âŸ
 â
 
ğœ‹(âƒ—ğ›¼)ğ‘‘âƒ—ğ›¼
.
Therefore, the likelihood function to be used in the MCMC algorithm is
â„’(âƒ—ğ›¼, ğµ) =
ğ‘›
âˆï¸
ğ‘—=1
ğ‘¢ğ‘—âˆ’ğ‘™ğ‘—
ğ‘ğ‘—âˆ’ğ‘ğ‘—
,
which is Equation (3.16) presented in Section 3.3.
106

D.3
Completely Certain Data
If we consider the data to be completely certain, deterministic, i.e. ğ‘Œ= ğ·, then, the
probability density ğœŒ(ğ‘Œ|ğ·) becomes ğœŒ(ğ‘Œ|ğ·) = ğ›¿(ğ‘Œâˆ’ğ·), and thus, using (3.15), we
have,
ğ‘(ğ´|ğ‘€, ğ·, ğµ) =
âˆ«ï¸
âƒ—ğ›¼
(ï¸‚âˆ«ï¸
ğ‘Œ
Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼), ğ‘Œ
)ï¸€)ï¸
Â· ğ›¿(ğ‘Œâˆ’ğ·)ğ‘‘ğ‘Œ
)ï¸‚
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
=
âˆ«ï¸
âƒ—ğ›¼
Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼), ğ·
)ï¸€)ï¸
âŸ
 â
 
â„’(âƒ—ğ›¼, ğµ)
Â· ğœŒ(âƒ—ğ›¼|ğ‘€)ğ‘‘âƒ—ğ›¼
âŸ
 â
 
ğœ‹(âƒ—ğ›¼)ğ‘‘âƒ—ğ›¼
.
Therefore, the likelihood function to be used in the MCMC algorithm is
â„’(âƒ—ğ›¼, ğµ) = Î˜
(ï¸
ğµ
(ï¸€
ğ‘€(ğ‘‹; âƒ—ğ›¼), ğ·
)ï¸€)ï¸
,
which is Equation (3.17) presented in Section 3.3.
107

108

Bibliography
[1] Brian M Adams, WJ Bohnhoff, KR Dalbey, JP Eddy, MS Eldred, DM Gay,
K Haskell, Patricia D Hough, and Laura P Swiler. Dakota, a multilevel parallel
object-oriented framework for design optimization, parameter estimation, uncer-
tainty quantification, and sensitivity analysis: version 5.0 userâ€™s manual. Sandia
National Laboratories, Tech. Rep. SAND2010-2183, 2009.
[2] Mark A. Beaumont, Wenyang Zhang, and David J. Balding.
Approximate
bayesian computation in population genetics. Genetics, 162(4):2025â€“2035, 2002.
[3] Paul Mac Berthouex and Linfield C. Brown. Statistics for Environmental Engi-
neers. Lewis Publishers, 2002.
[4] Christopher M. Bishop. Pattern Recognition and Machine Learning (Information
Science and Statistics). Springer-Verlag, Berlin, Heidelberg, 2006.
[5] Ariel Caticha. Entropic inference and the foundations of physics. Brazilian
Chapter of the International Society for Bayesian Analysis-ISBrA, Sao Paulo,
Brazil, 2012.
[6] Radu V. Craiu and Jeffrey S. Rosenthal. Bayesian computation via markov chain
monte carlo. Annual Review of Statistics and Its Application, 1(1):179â€“201, 2014.
[7] Bert J Debusschere, Habib N Najm, Philippe P PÃ©bay, Omar M Knio, Roger G
Ghanem, and Olivier P Le MaÄ± tre. Numerical challenges in the use of polyno-
mial chaos representations for stochastic processes. SIAM journal on scientific
computing, 26(2):698â€“719, 2004.
[8] Thomas G. Dietterich. Ensemble methods in machine learning. In Multiple Clas-
sifier Systems, pages 1â€“15, Berlin, Heidelberg, 2000. Springer Berlin Heidelberg.
[9] Anthony William Fairbank Edwards. Likelihood. CUP Archive, 1984.
[10] F. Feroz and M. P. Hobson. Multimodal nested sampling: an efficient and robust
alternative to markov chain monte carlo methods for astronomical data analyses.
Monthly Notices of the Royal Astronomical Society, 384(2):449â€“463, Jan 2008.
[11] F. Feroz, M. P. Hobson, and M. Bridges. Multinest: an efficient and robust
bayesian inference tool for cosmology and particle physics. Monthly Notices of
the Royal Astronomical Society, 398(4):1601â€“1614, Oct 2009.
109

[12] Scott Ferson, William L. Oberkampf, and Lev Ginzburg. Model validation and
predictive capability for the thermal challenge problem. Computer Methods
in Applied Mechanics and Engineering, 197(29):2408 â€“ 2430, 2008. Validation
Challenge Workshop.
[13] A. E. Gelfand and D. K. Dey. Bayesian model choice: Asymptotics and exact
calculations. Journal of the Royal Statistical Society: Series B (Methodological),
56(3):501â€“514, 1994.
[14] John Geweke. Bayesian model comparison and validation. American Economic
Review, 97(2):60â€“64, May 2007.
[15] R Ghanem, D Higdon, and H Owhadi. The uncertainty quantification toolkit
(uqtk), handbook of uncertainty quantification, 2016.
[16] Walter R Gilks, Sylvia Richardson, and David Spiegelhalter. Markov chain Monte
Carlo in practice. Chapman and Hall/CRC, 1995.
[17] W. K. Hastings. Monte carlo sampling methods using markov chains and their
applications. Biometrika, 57(1):97â€“109, 1970.
[18] Marc C Kennedy and Anthony Oâ€™Hagan. Bayesian calibration of computer
models. Journal of the Royal Statistical Society: Series B (Statistical Methodology),
63(3):425â€“464, 2001.
[19] Kevin H Knuth. Optimal data-based binning for histograms. arXiv preprint
physics/0605197, 2006.
[20] Kevin H. Knuth, Michael Habeck, Nabin K. Malakar, Asim M. Mubeen, and
Ben Placek. Bayesian evidence and model selection. Digital Signal Processing,
47:50â€“67, Dec 2015.
[21] Olivier Le MaÃ®tre and Omar M Knio. Spectral methods for uncertainty quantifi-
cation: with applications to computational fluid dynamics. Springer Science &
Business Media, 2010.
[22] Guesuk Lee, Wongon Kim, Hyunseok Oh, Byeng D Youn, and Nam H Kim.
Review of statistical model calibration and validationâ€”from the perspective of
uncertainty structures. Structural and Multidisciplinary Optimization, pages 1â€“26,
2019.
[23] Peter M Lee. Bayesian statistics. Arnold Publication, 1997.
[24] Thomas Leonard and John SJ Hsu. Bayesian methods: an analysis for statisticians
and interdisciplinary researchers, volume 5. Cambridge University Press, 2001.
[25] Chenzhao Li and Sankaran Mahadevan. Role of calibration, validation, and
relevance in multi-level uncertainty integration. Reliability Engineering & System
Safety, 148:32 â€“ 43, 2016.
110

[26] Wei Li, Wei Chen, Zhen Jiang, Zhenzhou Lu, and Yu Liu. New validation metrics
for models with multiple correlated responses. Reliability Engineering & System
Safety, 127:1 â€“ 11, 2014.
[27] You Ling and Sankaran Mahadevan. Quantitative model validation techniques:
New insights. Reliability Engineering & System Safety, 111:217 â€“ 231, 2013.
[28] Yu Liu, Wei Chen, Paul Arendt, and Hong-Zhong Huang. Toward a better under-
standing of model validation metrics. Journal of Mechanical Design, 133(7):071005,
2011.
[29] Scott M. Lynch. Introduction to Applied Bayesian Statistics and Estimation for
Social Scientists. Springer-Verlag, New York, 2007.
[30] David J. C. MacKay. Information Theory, Inference & Learning Algorithms.
Cambridge University Press, New York, NY, USA, 2002.
[31] Sankaran Mahadevan and Ramesh Rebba. Validation of reliability computational
models using bayes networks. Reliability Engineering & System Safety, 87(2):223
â€“ 232, 2005.
[32] Alberto Malinverno and Victoria A Briggs. Expanded uncertainty quantification in
inverse problems: Hierarchical bayes and empirical bayes. Geophysics, 69(4):1005â€“
1016, 2004.
[33] Jean-Michel Marin, Pierre Pudlo, Christian P. Robert, and Robin J. Ryder. Ap-
proximate bayesian computational methods. Statistics and Computing, 22(6):1167â€“
1180, Nov 2012.
[34] Kathryn A Maupin, Laura P Swiler, and Nathan W Porter. Validation metrics
for deterministic and probabilistic data. Journal of Verification, Validation and
Uncertainty Quantification, 3(3):031002, 2018.
[35] Nicholas Metropolis, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H.
Teller, and Edward Teller. Equation of state calculations by fast computing
machines. The Journal of Chemical Physics, 21(6):1087â€“1092, 1953.
[36] Joshua Mullins, You Ling, Sankaran Mahadevan, Lin Sun, and Alejandro Strachan.
Separation of aleatory and epistemic uncertainty in probabilistic model validation.
Reliability Engineering & System Safety, 147:49 â€“ 59, 2016.
[37] Radford M. Neal. An improved acceptance procedure for the hybrid monte carlo
algorithm. Journal of Computational Physics, 111(1):194â€“203, March 1994.
[38] William L. Oberkampf and Matthew F. Barone. Measures of agreement between
computation and experiment: Validation metrics. Journal of Computational
Physics, 217(1):5 â€“ 36, 2006. Uncertainty Quantification in Simulation Science.
111

[39] William L Oberkampf, Timothy G Trucano, and Charles Hirsch. Verification,
validation, and predictive capability in computational engineering and physics.
Applied Mechanics Reviews, 57(5):345â€“384, 12 2004.
[40] Inseok Park, Hemanth K. Amarchinta, and Ramana V. Grandhi. A Bayesian
approach for quantification of model uncertainty. Reliability Engineering &
System Safety, 95(7):777â€“785, 2010.
[41] M Parno and A Davis. MUQ: MIT Uncertainty Quantification Library, 2018.
[42] Matthew D. Parno and Youssef M. Marzouk.
Transport map accelerated
markov chain monte carlo. SIAM/ASA Journal on Uncertainty Quantification,
6(2):645â€“682, Jan 2018.
[43] Yudi Pawitan. In all likelihood: statistical modelling and inference using likelihood.
Oxford University Press, 2001.
[44] Fabian Pedregosa, GaÃ«l Varoquaux, Alexandre Gramfort, Vincent Michel,
Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, et al. Scikit-learn: Machine learning in python. Journal
of machine learning research, 12(Oct):2825â€“2830, 2011.
[45] Ben Placek. Bayesian detection and characterization of extra-solar planets via
photometric variations. PhD thesis, 2014.
[46] Ben Placek, Kevin H. Knuth, and Daniel Angerhausen. EXONEST: BAYESIAN
MODEL SELECTION APPLIED TO THE DETECTION AND CHARAC-
TERIZATION OF EXOPLANETS VIA PHOTOMETRIC VARIATIONS. The
Astrophysical Journal, 795(2):112, oct 2014.
[47] Ramesh Rebba and Sankaran Mahadevan. Computational methods for model
reliability assessment. Reliability Engineering & System Safety, 93(8):1197 â€“ 1207,
2008.
[48] Christian P. Robert, VÃ­ctor Elvira, Nick Tawn, and Changye Wu. Accelerating
mcmc algorithms. Wiley Interdisciplinary Reviews: Computational Statistics,
10(5):e1435, 2018.
[49] Christopher J. Roy and William L. Oberkampf. A comprehensive framework for
verification, validation, and uncertainty quantification in scientific computing.
Computer Methods in Applied Mechanics and Engineering, 200(25):2131 â€“ 2144,
2011.
[50] Shankar Sankararaman and Sankaran Mahadevan. Model validation under epis-
temic uncertainty. Reliability Engineering & System Safety, 96(9):1232 â€“ 1241,
2011. Quantification of Margins and Uncertainties.
112

[51] Shankar Sankararaman and Sankaran Mahadevan. Assessing the reliability of
computational models under uncertainty. In 54th AIAA/ASME/ASCE/AHS/ASC
Structures, Structural Dynamics, and Materials Conference, page 1873, 2013.
[52] Shankar Sankararaman and Sankaran Mahadevan. Integration of model verifi-
cation, validation, and calibration for uncertainty quantification in engineering
systems. Reliability Engineering & System Safety, 138:194â€“209, 2015.
[53] D. S. Sivia and J. Skilling. Data Analysis - A Bayesian Tutorial. Oxford Science
Publications. Oxford University Press, 2nd edition, 2006.
[54] John Skilling. Nested sampling for general bayesian computation. Bayesian Anal.,
1(4):833â€“859, 12 2006.
[55] D. Sornette, A. B. Davis, K. Ide, K. R. Vixie, V. Pisarenko, and J. R. Kamm.
Algorithm for model validation: Theory and applications. Proceedings of the
National Academy of Sciences, 104(16):6562â€“6567, 2007.
[56] M Stefano and B Sudret. Uqlab user manual-polynomial chaos expansions. report
uqlab-v0. 9-104, chair of risk, safety and uncertainty quantification. ETH Zurich,
2015.
[57] Nathaniel Stevens.
Assessment and comparison of continuous measurement
systems. 2014.
[58] Tony Tohme, Kevin Vanslette, and Kamal Youcef-Toumi. Generalized bayesian
regression and model learning. arXiv preprint arXiv:1911.11715, 2019.
[59] Paul Troughton and Simon J. Godsill. Bayesian model selection for time series
using markov chain monte carlo. In ICASSP, pages 3733â€“3736, 1997.
[60] T.G. Trucano, L.P. Swiler, T. Igusa, W.L. Oberkampf, and M. Pilch. Calibration,
validation, and sensitivity analysis: Whatâ€™s what. Reliability Engineering &
System Safety, 91(10):1331 â€“ 1357, 2006. The Fourth International Conference
on Sensitivity Analysis of Model Output (SAMO 2004).
[61] Kevin Vanslette, Abdullatif Al Alsheikh, and Kamal Youcef-Toumi. Why simple
quadrature is just as good as monte carlo. Monte Carlo Methods and Applications,
26(1), 2020.
[62] Kevin Vanslette, Tony Tohme, and Kamal Youcef-Toumi. A general model
validation and testing tool. Reliability Engineering & System Safety, 195, March
2020.
[63] Chong Wang and Hermann G. Matthies. Novel model calibration method via non-
probabilistic interval characterization and bayesian theory. Reliability Engineering
& System Safety, 183:84 â€“ 92, 2019.
[64] CJ Wild and GAF Seber. Nonlinear regression. New York: Wiley, 1989.
113

[65] Danqing Wu, Zhenzhou Lu, Yanping Wang, and Lei Cheng. Model validation and
calibration based on component functions of model output. Reliability Engineering
& System Safety, 140:59 â€“ 70, 2015.
[66] Ruoxue Zhang and Sankaran Mahadevan. Bayesian methodology for reliability
model acceptance. Reliability Engineering & System Safety, 80(1):95 â€“ 103, 2003.
[67] Lufeng Zhao, Zhenzhou Lu, Wanying Yun, and Wenjin Wang. Validation metric
based on mahalanobis distance for models with multiple correlated responses.
Reliability Engineering & System Safety, 159:80 â€“ 89, 2017.
114

