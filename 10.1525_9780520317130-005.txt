3 
Artificial-Intelligence Approaches 
to Problem Solving 
and Clinical Diagnosis* 
Herbert A. 
Simon 
I was asked to speak about the relation of artificial intelligence to 
medical diagnosis. As my paper developed, however, I realized that 
I was poaching on the territory of the session scheduled to precede 
this one, for my remarks are mainly about the nature and philosophy 
of medical diagnosis itself. Since I was presumably invited to this 
conference for my expertness on AI, and certainly not for my expert-
ness on medical matters, which is nonexistent, I feel I have to offer 
at least a brief explanation of why my analysis took the course that it 
did. 
Artificial intelligence is not very different from the real thing. (In 
fact, in my book The sciences of the artificial [1981] I argued that all 
intelligence belongs to the realm of the artificial.) Intelligence, whether 
natural or artificial, is directed toward the use of symbols, and of 
information processes applied to symbols, in order to solve problems. 
The methods available for doing this often depend much more on the 
nature of the problem-solving task and its environment than upon the 
characteristics of the problem solver—provided that the problem solver 
*This research was supported by Research Grant MH-07722 from the National Institute of 
Mental Health. 

Artificial Intelligence 
Approaches 
73 
is a more or less serial information-processing system, as both com-
puters and people are.1 To be sure, computers can store and retrieve 
numbers faster than people can, and perform much more elaborate 
arithmetic operations on them, but the asymmetry in the other direction 
is not nearly as striking. Increasingly, computers can be programmed 
to do the things that people do, using much the same methods that 
people use. 
So with artificial intelligence (and now I mean machine intelligence) 
we have a choice. We can use the computer's speed, arithmetic capa-
bilities, and vast memories to solve problems in ways that people 
cannot, or we can construct programs that imitate, more or less closely, 
the problem-solving methods we find people using. 
Elements of both of these approaches are represented in the auto-
mated medical-diagnosis schemes I shall discuss. People probably do 
not use anything closely resembling Bayesian decision theory in mak-
ing diagnoses. They probably do use processes that are somewhat more 
akin to the twenty-questions schemes and the causal-linkage schemes 
that I will develop below. I do not want to imply, by the way, that 
we have good empirical evidence as to exactly how people make 
diagnoses. The assertions I have just made are based on what we 
know in general about human information-processing capabilities 
and what we have learned about human problem-solving methods by 
studying chess playing, puzzle solving, theorem proving, and similar 
performances.2 
But the same issues must be faced in evaluating a diagnostic proce-
dure, independently of whether it is humanoid or not. Does it call for 
unconscionable amounts of computation? Does it rest on a sound view 
of the diagnostic task? Is it highly reliable? The contents of a paper 
on "Artificial-Intelligence Approaches to Diagnosis" would not need 
to be much changed if the first two words of its title were eliminated. 
The one difference that is consequential relates to the phrase uncon-
scionable 
amounts of computation. 
As I have already remarked, 
computers are able to carry out computations that would be utterly 
impossible for people. Hence, the range of design alternatives for an 
artificial-intelligence system to do diagnosis is wider than the range 
for people. From the very beginnings of artificial-intelligence research, 
the relative extents to which one should rely on machine power versus 
the imitation of human cunning has been a central issue. 
The initial impulse has usually been to exploit the computer's great 
comparative advantage in speed of symbol manipulation and to build 

74 
General 
Considerations 
brute-force schemes that would solve problems by undertaking vast 
amounts of search. Such schemes have often been swallowed up by 
the exponential expansion of the problem space with deeper and deeper 
search. This occurred, for example, in the 1960s in the case of chess-
playing programs and programs for proving mathematical theorems. 
The exponential explosion of the search space is countered by intro-
ducing selectivity—in either or both of two ways. On the one hand 
(as occurred in the case of theorem proving) the task domain may have 
a deep mathematical structure and correspondingly strong formal prop-
erties. These formal properties may be exploited by introducing rules 
for searching only part of the space without danger of missing the 
solution. A good example is the use of the simplex method to solve 
linear programming problems, which exploits certain properties of 
convexity and linearity to search only a small set of the boundary 
points of the space of feasible solutions. 
The other route to selectivity is to give up absolute guarantees of 
reaching the exact solution and to resort to various rules of thumb, or 
heuristics, as they are now usually called, that direct search to the most 
promising regions of the search space. A good example is the use of 
expert chess knowledge to incorporate a plausible move generator in 
a chess program, so that not all moves will have to be examined but 
only those that give promise of being good moves. 
The history of artificial intelligence in realms like theorem proving 
and chess (chess has been the Drosophila, 
the standard laboratory 
organism of the field) has been a continuing dialectic between machine 
power, on the one hand, and these two means for achieving selectivity, 
on the other. Moreover, there has been no clear verdict for the supe-
riority of either approach. As the potentiality of machine speed is 
exhausted, design moves toward new forms of selectivity. As machine 
technology moves forward rapidly to new levels of speed and memory 
capacity, the balance moves backward again. The best contemporary 
chess-playing programs (which have now reached the level of master 
play) find both speed of computation and chess knowledge indispens-
able. They look at enormous numbers of different possibilities (hun-
dreds of thousands or even millions), which are, however, only a tiny 
fraction of the legally admissible continuations of the game. The 
history of theorem-proving efforts has gone through the same oscilla-
tions and taught the same lessons. 
With these introductory comments out of the way, let me now turn 
to the specific topic of medical diagnosis. Space does not permit me 

Artificial Intelligence 
Approaches 
75 
to review the whole range of medical-diagnosis programs that have 
been proposed, or actually constructed, in the past twenty years. 
Instead I will organize my discussion in terms of the main conceptual 
frameworks that have been used in the design of such systems: problem 
solving, tree search, statistical decision theory, causal analysis, and 
biological modeling. The reader who wishes to learn more about early 
efforts in medical diagnosis by computer will find excellent surveys 
in Ledley 1962 and Kleinmuntz 1969. As for recent work, Szolovits 
and Pauker (1978) have provided a thoughtful comparison of four of 
the most prominent current systems: PIP, INTERNIST, CASNET, and 
MYCIN. Most of the literature of the field is listed in the bibliographies 
of one or another of these three sources. 
DIAGNOSIS AS PROBLEM SOLVING 
In one of their papers on the INTERNIST system for medical diagnosis 
(then called DIALOG), Pople, Myers, and Miller (1975) questioned 
whether diagnosis is problem solving at all. Instead, they suggested, 
it should be regarded as "problem formulation" or "problem finding." 
I am going to disregard their suggestion and try to characterize medical 
diagnosis as a form of problem solving, as that term is used in the 
discipline of artificial intelligence. I think this is a disagreement only 
in terminology and not in substance, but if I am mistaken in that, Harry 
Pople can correct me when it comes his time to speak. 
The usual definition of a problem runs like this (Newell and Simon 
1972, 74): Given a set U, to find a member of a subset of U having 
specified properties (called the goal set, G). As a first approximation 
in the case of medical diagnosis, we can take U as the set of all possible 
disease entities, G as the disease present in a particular patient (or the 
collection of his diseases, if he has more than one), and the "specified 
properties" as the indications, for example, a pathologist would use 
on autopsy to determine what the disease "really was." The perfor-
mance of an autopsy is not the critical element here but the presence 
of some retrospective, hindsight evidence that enables the correct 
diagnosis to be pinned down. Perhaps G is most simply conceived in 
terms of an omniscient being who holds not only a full knowledge of 
the patient's condition but a complete and correct theory of human 
physiology as well. In practice we have to settle for the autopsy as an 
approximation to this omniscient being. 

76 
General 
Considerations 
Now the information that is available to identify members of G is 
a set of manifestations or symptoms, ascertainable by examining the 
patient and/or submitting him to laboratory tests. A complete examina-
tion would disclose for the patient the presence or absence of every 
possible manifestation. The possibility of medical diagnosis rests on 
the premise that there is a unique mapping (a function) from sets of 
manifestations to disease entities. Notice that a particular disease en-
tity, in this formulation, may manifest itself in different ways, but a 
particular (complete) set of manifestations can point to only a single 
disease, or to a set of discriminable diseases from which the patient 
is suffering simultaneously. 
There is nothing simple about the mapping of symptoms on diseases. 
There are two main complications. First, a patient may be suffering 
from several diseases, all of which are to be identified from the 
symptoms. Second, individual symptoms may be unreliably associated 
with a disease, so that an accurate diagnosis can be made only on the 
basis of a constellation of manifestations, any single element of which 
may be present or absent in a particular instance of the disease. This 
second complication is often described as "unreliability" or "noisiness" 
of the symptomatic information, but I have treated it here as a matter 
of incompleteness rather than inaccuracy. (Nature cannot be inaccurate 
in describing herself, but she can be coy.) 
Of course, this rather formal characterization of diagnosis conceals 
the medical import of what is going on in the process. The physician 
is not interested in arbitrary mappings from sets of manifestations to 
labels called "disease entities." The latter have the further significance 
for him that they map onto alternative courses of treatment. The latter 
mapping may be pragmatic—it is known that a certain disease entity 
can usually be treated successfully with certain medication—or it may 
be based on a more or less deep understanding of the etiology of the 
symptoms. In either event the symptom-disease mapping is not arbi-
trary but reflects knowledge of treatment possibilities and/or the etiol-
ogy of diseases. I will have a good deal to say about these points a 
little later. 
DIAGNOSIS AS TWENTY QUESTIONS 
OR STATISTICAL DECISION THEORY 
The view of diagnosis as mapping symptoms onto diseases concep-
tualizes it as a taxonomic process, which might be organized and 

Artificial Intelligence 
Approaches 
77 
carried out as other taxonomic tasks are, in biology and elsewhere. 
Note that it is not the task of the diagnosis to discover the taxonomy 
of disease; that is presumed to be already given. Discovering and 
classifying disease entities and their identifying manifestations is quite 
a different task—an interesting and important one, but not one with 
which we will be concerned here. 
If we are given a taxonomy and asked to apply it to specimens, how 
do we go about it? A time-honored method (you can find it exemplified, 
for example, in your Gray's Botany) is the "twenty-questions" strategy: 
construct a taxonomic key that prompts the user down a branching list 
of questions the answers to which discriminate successively among 
groups of species until a unique identification has been made. 
(For examples of applications of the twenty-questions approach to 
medical diagnosis, see Kleinmuntz 1969, 244—260.) 
The twenty-questions strategy provides a not implausible basis for 
designing a medical-diagnosis program. Such a program would be 
large but not enormous. I suppose that there are not more than tens of 
thousands of identified distinct disease entities (fewer, say, than the 
number of distinct species of beetles in the United States). The number 
of dichotomous questions that would have to be asked, if the asking 
were organized efficiently, to identify a specimen in a system of N 
species is only log2 N, where log2 is the logarithm to base 2; and the 
total number of questions in the twenty-questions tree is only N. 
Moreover, there are various possibilities for organizing the tree 
efficiently. Questions that are cheaply and safely answered (e.g., that 
don't require expensive or dangerous laboratory tests) can be asked 
first, and the questioning stopped as soon as a unique diagnosis has 
been made. 
Why, then, have we not long since constructed a twenty-questions 
scheme to automate once and for all the process of medical diagnosis? 
We shall see presently that there are a number of reasons why this 
might not work very well, and why we probably would not be satisfied 
with it even if it did. But we shall see also that there is a good deal 
of the twenty-questions philosophy embedded in the existing successful 
medical-diagnosis schemes. In fact, the improvement of these schemes 
over earlier versions may lie less in their departures from the twenty-
questions strategy than in the fact that they embody larger data bases 
of manifestations and diseases and more accurate and sophisticated 
mappings of the former onto the latter than did their predecessors. 
The main reason usually given for departing from the simplest 
twenty-questions strategy is that symptoms are unreliable and noisy. 

78 
General 
Considerations 
A symptom, S, of disease D may be present in only some fraction of 
cases of D, and may also be present in some (usually smaller) fraction 
of cases of diseases other than D. This quite correct observation leads 
almost inexorably to the idea that the linkages between symptoms and 
disease entities should be expressed as probabilities. And it is only 
one step from viewing these linkages as probabilistic to the idea that 
the whole task of diagnosis should be represented as a problem in 
statistical decision theory instead of a twenty-questions problem. 
Decision-theoretic strategies are based upon Bayes' theorem.3 Every 
disease entity is conceived to have a certain probability of occurrence. 
When a patient appears in the physician's office, and before he has 
been examined, he is assumed to have disease D, with probability P r 
This probability is the so-called prior probability of Bayesian theory. 
(The "evoking-strength" parameter in INTERNIST plays roughly the 
role of a prior probability in that system.) There is nothing very 
questionable about such an assumption: actuarial tables of all sorts 
represent calculations of probabilities of exactly this kind. Moreover, 
in a well-designed Bayesian system it will turn out that the final 
diagnoses are quite insensitive to the exact values that are assigned to 
these prior probabilities. Mainly, they just provide a way to get the 
decision system started, so to speak. 
At the next step we must assign to each symptom-disease pair, Si; 
Dj, a conditional probability that if a patient is suffering from disease 
Dj, he will exhibit symptom Sj. We can represent this conditional 
probability as PtSj/Dj). (In INTERNIST the "import" parameter plays 
the role of this conditional probability.) Now if we know the values 
of these probabilities for all symptom-disease pairs, and if we know 
for a given patient which symptoms he is exhibiting (and which he is 
not exhibiting), we can calculate the posterior (conditional) probability, 
P(Bj/S,, . . ,SN), that he is suffering from disease Bj. The calculation 
is based straightforwardly on Bayes' formula, which I have no need 
to reproduce here (see Szolovits and Pauker 1978, 119). We can then 
identify the patient's condition with the disease entity that has the 
highest posterior probability. 
A number of questions about the practicality and even the validity 
of this scheme come readily to mind. First, in building the data base, 
all the symptom-disease probabilities must be estimated. If there are, 
say, 104 different disease entities and 104 manifestations (I don't know 
whether these numbers are realistic, but they are probably in the 

Artificial Intelligence 
Approaches 
79 
ballpark), then there are 108 probabilities to be estimated. Perhaps, 
however, all but a few of them are very small and can be set equal to 
zero. Second, in applying the scheme to the individual case the pres-
ence or absence of each symptom must be determined (at least in 
principle) and the values of all the nonvanishing probabilities for the 
pairs inserted in the formulas. Observe that the formula for the calcu-
lation includes the probability of the absence of each symptom, when 
it is found to be absent, as well as the probability of its presence, when 
present. Clearly the Bayesian formula involves a great deal more 
computation than going down a simple decision tree. 
But I don't want to exaggerate the practical difficulties. Numbers 
like 108 strike no terror into the heart of a modern computer. The best 
existing chess-playing programs, of master caliber, often examine 
several million possibilities before choosing a move, and do it in a 
matter of ten minutes or so. Many of us would regard a medical 
decision as comparable in importance with the choice of a chess move, 
and would not begrudge fifty dollars of computer time if that would 
guarantee its accuracy. Moreover, the symptom-disease linkages can 
be computed once and for all; they do not have to be recalculated for 
each individual case but can be simply plugged into Bayes' formula 
to compute the posterior probability for that case for each disease. This 
is a more modest task than estimating the linkages themselves. 
However, there are problems with the Bayesian analysis that go 
beyond computational difficulties. In the form in which it is usually 
used in diagnosis, the Bayesian formula assumes that the various 
conditional probabilities, P(S¡,Dj), appearing in numerator and de-
nominator are independent—that the presence or absence of one 
symptom does not affect the probability of the presence or absence of 
another. As has often been noticed, this is an unlikely assumption. In 
fact, we might well expect to find situations where the presence of a 
particular symptom is indicative of a disease in the presence of a 
second symptom but counterindicative in the absence of the latter. 
To handle the problem of nonindependence of the conditional prob-
abilities in its most general form, we should have to estimate not 
merely the probability of linkage between each symptom-disease pair 
but the probability of linkage between each possible set of symptoms 
and each disease. With N symptoms and M diseases, that would 
require the estimation of 2NxM probabilities, a formidable number 
even for N of modest size. As a practical matter, of course, we would 

80 
General 
Considerations 
not expect very many of the interactions to be important, but that is 
an empirical question to be decided on the basis of the evidence and 
not a priori. 
Thus the proper mode of application of Bayes' theorem to medical 
diagnosis is far from obvious, and in point of fact, it has seldom been 
incorporated in its pure, unadulterated form in medical-diagnosis pro-
grams. Rather, it has been used as a conceptual guide to the general 
shape of the program. In many if not most such programs there appear 
weights associated with symptoms that can be given at least metaphor-
ical interpretation as Bayesian conditional probabilities. These "prob-
abilities"—perhaps it would be better to call them "plausibilities" or 
"confidence indicators"—are then manipulated to produce judgments 
of the plausibility that the patient is suffering from one or another 
disease. The final diagnosis corresponds to the disease with highest a 
posteriori plausibility. 
Having reached this point, we can show that any result reached by 
a Bayesian scheme, even a sophisticated one taking account of the 
nonindependence of the conditional probabilities, can be reached in a 
quite straightforward way with a twenty-questions scheme. Although 
we introduced the probabilities to take care of the unreliability of 
individual symptoms, the twenty-questions game can also be played 
in such a way as to handle noisy data. Let us see how this can be done. 
The result of a Bayesian analysis is to rank disease entities according 
to their posterior probabilities in the light of the manifestations that 
are present and absent. The diagnosis assigns to the patient the disease 
or diseases highest on the list. For any given configuration of symptoms 
(i.e., presence or absence of all possible manifestations) the system 
will always assign the same probabilities and reach the same diagnosis. 
At the last step in the process the uncertainty disappears from it and 
the system makes some yes-or-no judgments. 
Now we could construct a simple table, with no probabilities what-
soever, associating with each symptom configuration the appropriate 
diagnosis (i.e., the diagnosis that would be assigned by the Bayesian 
procedure). We could also construct a decision tree for searching that 
table and could endeavor to "optimize" the decision tree so that diag-
noses could be reached after the smallest possible numbers of tests. 
The decision tree arrived at in this way would normally be larger than 
the one we would construct if our data were noise-free. We would be 
using the redundancy deriving from the large number of alternative 

Artificial Intelligence 
Approaches 
81 
manifestations of disease to eliminate the unreliability of depending 
upon individual symptoms. 
I must emphasize that the diagnoses obtained with this decision-tree 
method would be identical with those reached by the Bayesian method. 
(We could even use the Bayesian method as the first step in the 
construction of the decision tree.) The actual diagnostic process, how-
ever, would involve the computation of no probabilities or numerical 
weights, but a simple twenty-questions procedure. 
Now if we questioned a diagnostician who was using a decision 
tree, we might discover that he was, after all, a crypto-Bayesian. At 
a certain branching in the tree he might argue that certain disease 
entities could be ruled out as "extremely improbable in the light of the 
configuration of symptoms." If he felt uncertain about a diagnosis 
because of the unreliability of symptoms, he could always exploit the 
redundancy of nature by adding a few "confirming tests" to his diagnos-
tic tree. It is a nice philosophical question, which we probably don't 
have to answer here, whether the decision tree is simply a crystallized 
form of a Bayesian analysis or whether a Bayesian analysis is simply 
a rationalization of a decision tree. I myself lean toward the latter 
alternative. In self-observation I seldom catch myself calculating nu-
merical probabilities, conditional or otherwise, and my observations 
of my fellow men do not suggest that they (or I) are capable of much 
arithmetic. 
Before I leave the topic of statistical diagnosis, one other theoretical 
issue should be discussed. We have framed the decision problem (and 
so have the Bayesian diagnostic systems with which I am familiar) as 
if the task were to maximize the probability of reaching the correct 
diagnosis. Of course that is not what medicine is about at all. The 
diagnosis is simply a step toward treatment, and we would be perfectly 
willing to be wrong about the diagnosis as long as we were right about 
the treatment. More specifically, there are consequences attached to 
taking the right or the wrong measures (and not simply to making the 
right or the wrong diagnoses), and some of these consequences are far 
more serious than others. 
In statisticians' language, there are errors of two kinds: errors of 
accepting a hypothesis when it is false and errors of rejecting it when 
it is true. Suppose that a diagnostician is faced with the choice between 
disease A, which can be treated safely and effectively but which is 
fatal unless treated, and disease B, for which there is no good treatment 

82 
General 
Considerations 
but which also has no serious consequences. The choice between 
diagnosing a mole as malignant (A) or nonmalignant (B) would be a 
case of this kind. With equal probabilities on the evidence for both 
diagnoses, or even with a somewhat higher probability that B was the 
correct diagnosis, the diagnostician would be advised by decision 
theory to choose A—that is, to act as if the patient were suffering from 
A. Without the advice of statistical decision theory, the intelligent 
diagnostician would probably have arrived at the same conclusion. He 
has almost nothing to lose, even if he chooses A erroneously, and 
almost everything to gain if he avoids choosing B erroneously. 
To convert the usual Bayesian scheme into a statistical decision 
scheme taking account of consequences, we simply have to attach to 
each diagnosis numerical values representing the respective costs of 
the two kinds of errors. Then, instead of selecting the diagnosis that 
has the highest probability, we select the one that minimizes the 
expected loss from a mistake. The same kind of consideration of risks 
can be introduced into a decision-tree procedure, again without making 
the risks explicit, or representing them numerically. 
DIAGNOSIS AS CAUSAL ANALYSIS 
The approaches to diagnosis that have been discussed in the previous 
section represent a purely Baconian point of view. They incorporate 
no real theory of disease, only a set of empirical correlations between 
congeries of manifestations and disease entities. And a disease entity 
is itself a purely pragmatic construct: all the combinations of symptoms 
that yield to the same course of treatment may just as well be mapped 
onto a single disease entity. A disease, in such a scheme, has no 
existence apart from its symptoms and its treatments. 
This Baconian representation is probably not an entirely unsatisfac-
tory description of the approach of traditional medicine, which oper-
ated with nearly a complete lack of knowledge of physiological 
mechanisms, if with a somewhat better knowledge of anatomy. There 
are probably substantial areas of contemporary medicine where it is 
only a moderate caricature of the conceptualizations that are used, 
particularly if we look at everyday clinical practice rather than medical 
research. 
But Baconian systems don't satisfy us very deeply, whether in 

Artificial Intelligence 
Approaches 
83 
artificial intelligence, medical diagnosis, or science in general. We 
wish to know not only that certain things happen but why and how 
they happen. We would like to have a reasoned account of the relation 
between symptoms and disease. Lacking such understanding, we will 
hardly regard a taxonomic scheme as exhibiting intelligence, no matter 
what its practical utility may be. Thus, in modern taxonomic systems 
in biology, we are not satisfied to put species close together simply 
because they resemble each other in some arbitrary ways. Instead we 
seek a classification that reflects phylogeny, commonality of origins. 
We want not just any old tree but the actual family tree. 
The impulse toward explanation is not solely aesthetic. When strong 
theories are discovered, theoretical explanations are usually far more 
parsimonious, more powerful in prediction, and often more accurate 
than empirical correlations. Hence, we prefer the former to the latter 
when we can discover them. Of course it is a question of fact, in any 
particular domain and at any given stage of development of that 
domain, whether the available theory is actually more useful than the 
known empirical regularities. I shall return to this issue, as it applies 
to various domains of artificial intelligence, in a later section. 
Let us see how we might introduce more theory—more intelli-
gence—into a system for medical diagnosis. The first step amounts to 
a change in terminology. Instead of conceiving symptoms as being 
associated with disease entities, we think of them as being caused by 
diseases. That does not change our symptom-disease linkages, but it 
does induce us to interpret them a little differently and in the opposite 
direction from the previous one. Further, it takes one step toward 
realism, for it allows us to conceive of diseases as causing not only 
symptoms but other diseases as well. Hence, we can incorporate 
disease-disease links into the scheme, as has been done, for example 
in INTERNIST. Now, in cases where a patient is diagnosed as having 
more than one disease, we need not regard these as independent 
(although they may be) but can look for causal links between them. 
This will be important in treatment, where we will generally want to 
work upstream from symptoms to their fundamental causes. 
The causal links can, like the correlation links they replace, be 
empirically determined, or they can reflect such theoretical understand-
ing as we have of mechanisms. Although I don't know that this has 
been done, it would be perfectly possible to associate with each link 
in the system a theoretical account of the reason for that link—which 

84 
General 
Considerations 
might include an account of reasons for its unreliability. This might 
be an especially valuable feature in a system for teaching diagnosis if 
not in a clinical diagnostic system. 
Interpretation of the symptom-disease links as causal suggests a 
different diagnostic procedure from the Baconian one we have de-
scribed thus far. Instead of homing in on a diagnosis by step-by-step 
elimination of possibilities or by making a comparative Bayesian evalu-
ation of alternative possibilities, we can proceed in two steps, usually 
referred to as hypothesis and test. In the first step, prominent symptoms 
are used to evoke or hypothesize one or more candidate disease entities. 
In the second step, the hypotheses are tested by following the causal 
linkages in the reverse direction, testing whether the symptoms are 
present that would be expected to be present if the candidate disease 
were the actual cause of the pathology. INTERNIST makes important 
use of the hypothesis-and-test method (Pople, Myers, and Miller 
1975). 
Similar procedures, based on causal analysis, have cropped up in 
other domains of artificial intelligence, and have been observed, also, 
in human problem-solving behavior in complex task environments. A 
major finding of de Groot's (1946, 1978) pioneering studies of chess 
grand masters was that the grand master, facing the task of selecting 
a move, rather quickly but tentatively chose a "favorite," then spent 
most of the rest of his time verifying that the favorite was indeed a 
good move. Sometimes, of course, a flaw revealed itself in the course 
of the evaluation, and then another favorite had to be selected. In the 
very first seconds of his examining a new position, the grand master 
identified the three or four plausible candidate moves from which he 
then chose the favorite. This initial identification of plausible moves 
was made, it would appear, on the basis of prominent "diagnostic" 
features of the position that could be detected by a skilled player in a 
few seconds' examination of the board. 
The process described by de Groot differs only a little from the 
simplest hypothesize-and-test process. The hypothesizing is preceded 
by a very rapid recognition process, which may be regarded as a 
preliminary hypothesis-identification step based on the most obvious 
symptoms present. If these symptoms fail to point to the correct 
hypothesis among those selected for examination, then the validation 
step must be sufficiently thorough to detect the error and enlarge the 
set of candidate hypotheses. 

Artificial Intelligence 
Approaches 
85 
Causal Linkages versus Biological Models 
The network of nodes representing disease entities and symptoms, 
with the links between them interpreted causally, may be viewed as a 
primitive model of the etiology of disease. The model does not repre-
sent the normal working of the system but only deviations from normal-
ity. A disease refers to some subsystem that is behaving pathologically, 
and symptoms are the consequent pathological values of observable 
variables. Moreover, the model is very weak. It postulates connections 
between certain variables, but it does not have much to say about the 
strengths of those connections—the coefficients that we are accustomed 
to see modeled in a dynamic system. The model is also abstract. It 
does not represent organ systems (e.g., the heart or the lungs) directly, 
nor the main physiological processes (e.g., respiration, digestion). Of 
course, particular symptoms and particular diseases may be totally or 
largely confined to particular organs or processes, but this is implicit 
in the model. There is no explicit anatomy or physiology in it. 
Hence, while the causal model is, I think, a genuine biological 
theory, it does not much resemble the formal mathematical models 
that we are accustomed to build of systems—and which generally do 
provide an explicit representation of their concrete structure or at least 
their organization in terms of processes.4 On the other hand, this causal 
theory may be very much like the qualitative commonsense theories 
that we use in everyday life to reason about the complex systems with 
which we have to deal. Unless we are automobile mechanics, I would 
venture that our model of the operation of our car is of just this abstract 
kind. That is just a hunch; I know of no empirical evidence on this 
point, and it would be very useful to gather some. 
Let me provide a contrasting example of a different kind of model 
used in an artificial-intelligence system that was designed to handle 
diagnostic processes. John Seely Brown and his associates constructed 
a program, SOPHIE, to teach troubleshooting analysis of electronic 
circuits (Bobrow and Brown 1975). One component of SOPHIE is a 
set of equations for an actual, rather complex, circuit. Various mal-
functions (diseases) can be introduced into the circuit by changing 
certain parameters (e.g., short circuits) or by rendering certain compo-
nents inoperative. These malfunctions can be detected by reading the 
values of certain other circuit variables (symptoms). The student's task 
is to diagnose the malfunction by examining the symptoms and by 

86 
General 
Considerations 
making tests (altering various control variables) that could disclose 
other symptoms. SOPHIE is sufficiently sophisticated to be aware of 
the structure of the circuit, and can not only report to the student the 
results of the tests he performed but also tutor him by offering advice 
as to new observations and tests he could make. 
The SOPHIE model, in contrast with the causal-link models, con-
tains a full quantitative theory of the normally operating system. Mal-
functions and symptoms are represented as deviations from these nor-
mal values. The model is so constructed that the malfunctions do in 
fact induce, or cause, the symptoms: it actually behaves in a causal 
manner exactly as the real circuit would behave. Moreover, the various 
components of the modeled circuit can be identified as corresponding 
components of the mathematical model. Instead of using a system of 
inference rules to explore the consequences of the causal connections, 
SOPHIE simply solves and re-solves the equations of the system as 
the independent variables are manipulated. Straightforward numerical 
calculations replace qualitative inference rules as the tool of causal 
analysis. 
The contrast between a node-link causal structure and a SOPHIE-like 
system, between reasoning inferentially about causality and modeling 
the causal structure of a system, has long been of interest in artificial 
intelligence (Pople 1972; Simon 1972). The usual laws of the predicate 
calculus do not apply to reasoning about sentences containing causal 
language. McCarthy and Hayes (1968), among others, have attempted 
to construct special modal logics to handle causal predicates, but 
without great success. Simon (1972) has shown that the difficulties 
encountered are not superficial but are bound to arise whenever there 
are complex interactions among the components of the system under 
discussion (e.g., the nonindependence of the Bayesian probabilities). 
In the presence of such interactions a modal logic will be either too 
weak (will fail to support some valid inferences) or too strong (will 
permit invalid inferences). Nothing short of full modeling, in the 
manner of SOPHIE, will handle correctly all of the interactions of a 
complex system; and the tool of inference used with such a model is 
ordinary mathematical reasoning, that is, higher-order predicate cal-
culus (Simon 1977). 
The fact that only approximate relations in complex systems can be 
represented by causal-link models is not a condemnation of such 
models, which may, as experience with medical-diagnosis systems has 
shown, have great heuristic value. In fact, Pople (1972) has constructed 

Artificial intelligence 
Approaches 
87 
a GOL system that is capable both of modal reasoning and of model 
simulation. Its inferential machinery can be used to suggest hypotheses 
that are then tested by manipulation of the model. 
If validity of inferences cannot be guaranteed in a causal-link 
scheme, one might suppose that such schemes would be dubious 
mechanisms for medical diagnosis, where reliability is a main de-
sideratum. When such a system is used in hypothesize-and-test mode, 
however, the unreliability of inferences can be overcome by providing 
redundancy in symptoms. Stated otherwise, the causal linkage is not 
relied upon completely to reach definitive diagnosis but principally as 
a means of discovering candidate hypotheses for further consideration. 
By subsequently accumulating evidence until one hypothesis is favored 
decisively, protection is obtained against relying too heavily on single 
chains of inference. 
I do not wish to imply that the theoretical issues surrounding causal 
inference are all thoroughly understood. On the contrary, this is an 
area in which further clarification would be both welcome and impor-
tant for the future development of the theory and practice of diagnosis 
and taxonomy. 
Earlier I mentioned the utility of causal linkages for following 
symptoms "upstream" to their instigating conditions. From the 
standpoint of scientific curiosity and understanding we of course want 
to get as close as we can to fundamental causes. From the therapeutic 
or "troubleshooting" standpoint we want to follow the causal stream 
up to a point where intervention is possible. In the face of certain 
symptoms we might conclude "cirrhosis of the liver" or "alcoholism." 
Which is the more useful diagnosis will depend upon the means at our 
disposal for correcting the patient's bodily functions or changing his 
habits. 
Similar issues of localization of cause—to identify the precise spot 
for intervention—have arisen in a variety of artificial-intelligence sys-
tems. Pfefferkorn (1975), for example, constructed a system for ar-
ranging furniture or equipment in a room, subject to various relational 
constraints. The several items were sited one by one. If an impasse 
was reached, so that no appropriate location could be found for the 
next item, a causal analysis was instituted to find which items were 
causing the trouble (i.e., which constraints were hard to satisfy). The 
search was then reinitiated, reordering the items so as to site the 
difficult ones first. 
Designers of chess-playing programs are increasingly turning to 

88 
General 
Considerations 
causal analysis to avoid unnecessary analysis of worthless moves (Ber-
liner 1977). When a sequence of moves under investigation leads to 
a poor result, the sequence is not simply abandoned. Instead a causal 
analysis is initiated to trace the disaster upstream in order to identify 
the specific move in the sequence that was responsible for the poor 
outcome. If this move can be identified, then the other possible se-
quences of play descending from it need not be investigated but can 
be discarded without search. 
Finally, there is a close connection between causal reasoning and 
the means-ends analysis that is the backbone of many artificial-intelli-
gence problem-solving schemes. The idea of means-ends analysis is 
that if there is a set of differences between the current situation and 
the goal situation, appropriate operators should be applied to remove 
these differences, one by one (Newell and Simon 1972). The operator 
is the means for removing the difference (which is the end). The 
relation between operator and difference is clearly causal. Hence, 
means-ends search can be interpreted as heuristic causal inference. It 
does not escape the usual inadequacies of modal causal inference—that 
is, the inability to handle interactions—for it assumes that the differ-
ences can be removed independently, one at a time. Combined with 
best-first search methods, however, it has proved to be a powerful 
heuristic tool in a variety of problem-solving environments. 
THE EVALUATION OF 
DIAGNOSTIC SYSTEMS 
As in other domains of artificial intelligence, the initial goal of research 
on automated medical diagnosis has been to demonstrate feasibility, 
by constructing systems actually capable of making diagnoses at an 
acceptable quality level. The task has been to prove an existence 
theorem, so to speak. Since I think it fair to say that this has now been 
accomplished, several new tasks lie ahead. An obvious one is to 
improve the systems we have and bring them into actual application, 
in some symbiotic relation with the human components of the medical 
system, to improve medical technology. 
Another task, complementary to the first, is to understand why these 
systems work and to see what light they may cast, both on the nature 
of the diagnostic process and on the theory of artificial intelligence. 
Work toward those goals has hardly begun. Let me remind you of 

Artificial Intelligence 
Approaches 
89 
some of the main issues, which have already emerged in the course 
of my discussion. 
The Knowledge Base 
The best existing diagnostic schemes now provide us with an answer 
to the question of how much medical knowledge needs to be incorpo-
rated to yield diagnoses of professional quality. The answer (similar 
to the one we are getting in other applications of AI to professional 
problems) is "a great deal, but not an unmanageable amount." That is 
a rather vague answer: what it means is that the knowledge required 
is well within the memory capacities of modern computers and that 
the number of man-years of effort required to transfer the knowledge 
to those memories is quite moderate, even with our present crude 
methods for doing so. 
We do not know how much the performance of a program like 
INTERNIST would be improved if it had an order-of-magnitude more 
knowledge at its disposal, nor, I suspect, do we quite know how it 
could use that additional knowledge at all. 
Choice of Methods 
Up to the present time, little systematic effort has been devoted to 
exploring the relative efficacy of different basic methods. That is not 
to say that a wide variety of AI methods has not been employed in 
different medical-diagnosis schemes. Many of them, in fact, have been 
quite eclectic, with features borrowed from the twenty-questions, 
statistical-decision-theory, and causal-linkage schemes. So far as I am 
aware, no existing system uses biological modeling techniques more 
complex than causal linkages. 
What has not been investigated systematically, and what we do not 
know, is the relative contribution of these several components to the 
effectiveness of the systems. Among other difficulties in making such 
comparisons, no two systems have even remotely comparable data 
bases. In fact, a real case could be made for the position that it is the 
steady elaboration of the data bases, rather than the sophistication of 
the problem-solving methods, that has accounted for most of the 
progress in automatic medical diagnosis. The data bases, even the most 

90 
General 
Considerations 
complete, are hardly large enough to strain the capabilities of modern 
computers using relatively unsophisticated and unselective search 
methods. This is, of course, only a hypothesis, since we simply do 
not have the experimental data about comparative system performance 
that would permit us to test decisively whether it is correct. 
The size of the search space in medical diagnosis does appear, 
however, to be considerably smaller than the spaces in either chess or 
speech recognition. In both of those domains, sophisticated search has 
had to be combined with computing power to reach the goal. Moreover, 
in chess there has been enough experience with a variety of systems 
(Berliner 1977), and in speech recognition enough systematic explora-
tion of a family of systems (HEARSAY and HARPY among others: 
see Walker et al. 1977), to give us a pretty good feel for the improve-
ment in performance that would be bought with either an increment 
of machine speed or an increment of selectivity. 
My remarks about the dearth of performance data on medical-diag-
nosis systems should not be interpreted as criticism of the research that 
has been going on in this field. I would suppose that the total effort 
to date can be measured in terms of dozens, rather than hundreds or 
thousands, of man-years' work. That is a far cry from a moon shot or 
a Manhattan Project, and there is no more reason to expect costless 
miracles in this research domain than in any other. 
Medical Diagnosis and 
Biological Theory 
It is always something of a disappointment in AI research when brute-
force schemes or simple-minded selective procedures do the job. The 
disappointment is quite irrational, of course, but it does have several 
understandable roots. First, we would prefer the challenge of concep-
tualizing sophisticated techniques and capturing them in our programs. 
Second, we are always reluctant to concede that high-level human 
professional performances, that are achieved only after years of train-
ing and experience, can be imitated or replaced by simple programs. 
Pride in human accomplishment should not blind us to the facts, 
however. A growing body of experience in AI, over a considerable 
number of task domains, points increasingly to the possibility that it 
is the size and quality of his data base more than the sophistication of 
his methods for analyzing evidence that distinguishes the expert from 

Artificial Intelligence 
Approaches 
91 
the novice. This does not mean that the methods themselves or the 
organization of the data base are unimportant. It may mean that a small 
repertory of general methods, several of which have been discussed 
in this paper, are adequate to handle a wide range of professional data 
bases. 
If this is true, or even partly true, it has implications for the relation 
of fundamental biological theory to clinical practice. Even if we could 
model the human anatomy and physiology in some detail, and run our 
models dynamically, it is not clear that we would want to use such 
models directly for diagnostic purposes. They would be too detailed, 
too elaborate, too cumbersome for that. What is more likely is that we 
would extract from the models their important qualitative properties 
and convert these into systems of causal linkages that we could incor-
porate into our diagnostic-reasoning schemes. In its "ultimate" form 
the automatic diagnostic system would not be organized very differ-
ently from the causal-link schemes we are beginning to have today. 
This may be a general paradigm for the relation between theory and 
practice and for the way in which theory gets incorporated into every-
day professional analysis and reasoning. Of course there are excep-
tions. In civil engineering, at least in the final stages of design, we do 
employ the laws of mechanics directly, model our systems mathemat-
ically, and solve the equations explicitly. But the limited number of 
domains that are simple enough, and well enough understood, to 
permit us to do this may not provide the correct paradigm for the uses 
of theory in other parts of science. In any event the domain of medical 
diagnosis appears to be a promising field in which to explore the 
alternative design that I have sketched above. 
NOTES 
1. Of course both the eye and the ear are parallel information-processing 
systems, but there is little evidence for parallel processing in the central 
nervous system, once the initial perceptual encoding of sensory stimuli has 
been accomplished. Since diagnosis systems are not concerned with that 
initial encoding, we may treat such systems as essentially serial in their 
operation. For further discussion see Simon 1979. 
2. See Newell and Simon 1972; Simon 1979. 
3. Good brief explanations of Bayesian statistical analysis applied to 
medical diagnosis can be found in Ledley 1962, 342-344, and in Szolovits 
and Pauker 1978, 119-122. 

92 
General 
Considerations 
4. For an example of explicit modeling of the circulatory system, see 
Guy ton et al. 1973. 
REFERENCES 
Berliner, H. 1977. Search and knowledge. In Proceedings of the Fifth Inter-
national Joint Conference on Artificial Intelligence, 975-979. Pittsburgh: 
Dept. of Computer Science, Carnegie-Mellon University. 
Bobrow, R. J., and J. S. Brown. 1975. Systematic understanding: Synthesis, 
analysis and contingent knowledge in specialized understanding systems. 
In Representation and understanding, ed. D. Bobrow and A. Collins. New 
York: Academic Press. 
de Groot, A. D. 1946. Het denken van den schaker. Amsterdam: North-
Holland. 
. 1978. Thought and choice in chess. 2d. ed. The Hague: Mouton. 
Revised translation of de Groot 1946. 
Guyton, A. C., T. G. Coleman, A. W. Cowley, K. W. Scheel, R. D. 
Manning, and R. A. Norman. 1973. Arterial pressure regulation. In Hyper-
tension manual, ed. J. H. Laragh. New York: Dun-Donnelley. 
Kleinmuntz, B. 1969. Clinical information processing by computer. New 
York: Holt, Rinehart & Winston. 
Ledley, R. S. 1962. Programming and utilizing digital computers. New 
York: McGraw-Hill. 
McCarthy, J., and P. J. Hayes. 1968. Some philosophical problems from the 
standpoint of machine intelligence. In Machine intelligence 4, ed. B. 
Meitzer and D. Michie. Edinburgh: Edinburgh University Press. 
Newell, A., and H. A. Simon. 1972. Human problem solving. Englewood 
Cliffs, N.J.: Prentice-Hall. 
Pfefferkorn, C. 1975. The design problem solver. In Spatial synthesis in 
computer-aided building design, ed. C. M. Eastman. London: Applied 
Science Publishers. 
Pople, H. E. 1972. A goal-oriented language for the computer. In Represen-
tation and meaning, ed. H. A. Simon and L. Siklossy. Englewood Cliffs, 
N.J.: Prentice-Hall. 
Pople, H. E., J. D. Myers, and R. A. Miller. 1975. DIALOG: A model of 
diagnostic logic for internal medicine. In Proceedings of the Fourth Inter-
national Conference on Artificial Intelligence. Cambridge, Mass.: Artificial 
Intelligence Laboratory, M.I.T. 
Simon, H. A. 1981. The sciences of the artificial. Cambridge, Mass.: M.I.T. 
Press. 

Artificial Intelligence Approaches 
93 
. 1972. On reasoning about actions. In Representation and meaning, 
ed. H. A. Simon and L. Siklossy. Englewood Cliffs, N.J.: Prentice-Hall. 
. 1977. Models of discovery, chap. 3.1. Dordrecht: Reidel. 
. 1979. Models of thought. New Haven: Yale University Press. 
Szolovits, P., and S. G. Pauker. 1978. Categorical and probabilistic reasoning 
in medical diagnosis. Artificial Intelligence 11:115-144. 
Walker, D. E., L. D. Erman, A. Newell, N. J. Nilsson, W. H. Paxton, T. 
Winograd, and W. A. Woods. 1977. Speech understanding and AI. In 
Proceedings of the Fifth International Joint Conference on Artificial Intel-
ligence. Pittsburgh: Department of Computer Science, Carnegie-Mellon 
University. 

